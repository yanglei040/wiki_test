{"hands_on_practices": [{"introduction": "At the heart of Model-Agnostic Meta-Learning (MAML) is the simple yet powerful idea of rapid adaptation via gradient descent. This first practice breaks down this core mechanism to its most fundamental level: a single update step for a single neuron classifier. By deriving the condition for correcting a misclassification in one step [@problem_id:3180380], you will develop a concrete intuition for how the learning rate $\\alpha$ interacts with the initial prediction error and the geometry of the input data.", "problem": "Consider a binary classifier implemented as a single artificial neuron with affine score $s = \\mathbf{w}^{\\top}\\mathbf{x} + b$, where $\\mathbf{w} \\in \\mathbb{R}^{d}$ is the weight vector, $b \\in \\mathbb{R}$ is the bias, and $\\mathbf{x} \\in \\mathbb{R}^{d}$ is the input. The classifier predicts the class by the sign of $s$. In a meta-learning scenario such as Model-Agnostic Meta-Learning (MAML), you adapt $(\\mathbf{w}, b)$ to a new task using one labeled example $(\\mathbf{x}, y)$ with $y \\in \\{-1, +1\\}$ by taking a single gradient descent step on the logistic loss $L(\\mathbf{w}, b; \\mathbf{x}, y) = \\ln\\!\\big(1 + \\exp(-y(\\mathbf{w}^{\\top}\\mathbf{x} + b))\\big)$ with learning rate $\\alpha > 0$.\n\nStarting from the definition of the logistic loss and the gradient descent update rule, derive the one-step adapted parameters $(\\mathbf{w}', b')$ as functions of $(\\mathbf{w}, b, \\mathbf{x}, y, \\alpha)$. Then, analyze the condition under which a single update suffices to correct a misclassification of $\\mathbf{x}$, that is, when $y(\\mathbf{w}^{\\prime\\top}\\mathbf{x} + b') > 0$ given that initially $y(\\mathbf{w}^{\\top}\\mathbf{x} + b) < 0$. Your final task is to provide a closed-form expression for the minimal learning rate $\\alpha_{\\min}$ that guarantees the post-update score is correctly signed for this single example.\n\nProvide only the analytic expression for $\\alpha_{\\min}$ in your final answer. No numerical approximation or rounding is required.", "solution": "The problem asks for the minimal learning rate $\\alpha_{\\min}$ required for a single gradient descent step on the logistic loss to correct a misclassified example.\n\nFirst, we establish the necessary components of the problem.\nThe affine score is given by $s = \\mathbf{w}^{\\top}\\mathbf{x} + b$.\nThe logistic loss for a single example $(\\mathbf{x}, y)$ is $L(\\mathbf{w}, b; \\mathbf{x}, y) = \\ln(1 + \\exp(-y(\\mathbf{w}^{\\top}\\mathbf{x} + b))) = \\ln(1 + \\exp(-ys))$.\nThe parameters $(\\mathbf{w}, b)$ are updated using a single step of gradient descent with learning rate $\\alpha > 0$. The updated parameters are denoted $(\\mathbf{w}', b')$.\nThe update rules are:\n$$ \\mathbf{w}' = \\mathbf{w} - \\alpha \\nabla_{\\mathbf{w}} L $$\n$$ b' = b - \\alpha \\nabla_{b} L $$\n\nTo apply these rules, we must first compute the gradients of the loss function $L$ with respect to $\\mathbf{w}$ and $b$. We use the chain rule.\n\nThe gradient of $L$ with respect to the score $s$ is:\n$$ \\frac{\\partial L}{\\partial s} = \\frac{1}{1 + \\exp(-ys)} \\cdot \\frac{\\partial}{\\partial s}(1 + \\exp(-ys)) = \\frac{1}{1 + \\exp(-ys)} \\cdot (\\exp(-ys) \\cdot (-y)) = \\frac{-y \\exp(-ys)}{1 + \\exp(-ys)} $$\nThis can be expressed using the sigmoid function $\\sigma(z) = \\frac{1}{1 + \\exp(-z)}$:\n$$ \\frac{\\partial L}{\\partial s} = -y \\frac{\\exp(-ys)}{1 + \\exp(-ys)} = -y \\frac{1}{\\exp(ys) + 1} = -y \\sigma(ys) $$\nAlternatively, and more conveniently for this problem, we can express it as:\n$$ \\frac{\\partial L}{\\partial s} = -y \\sigma(-ys) $$\nWhere $\\sigma(-ys) = \\frac{1}{1 + \\exp(ys)}$.\n\nNow we compute the gradients with respect to $\\mathbf{w}$ and $b$:\n$$ \\nabla_{\\mathbf{w}} L = \\frac{\\partial L}{\\partial s} \\nabla_{\\mathbf{w}} s = \\frac{\\partial L}{\\partial s} \\cdot \\mathbf{x} = -y \\sigma(-ys) \\mathbf{x} $$\n$$ \\nabla_{b} L = \\frac{\\partial L}{\\partial b} = \\frac{\\partial L}{\\partial s} \\frac{\\partial s}{\\partial b} = \\frac{\\partial L}{\\partial s} \\cdot 1 = -y \\sigma(-ys) $$\n\nSubstituting these gradients into the update rules, we obtain the one-step adapted parameters $(\\mathbf{w}', b')$:\n$$ \\mathbf{w}' = \\mathbf{w} - \\alpha (-y \\sigma(-ys) \\mathbf{x}) = \\mathbf{w} + \\alpha y \\sigma(-ys) \\mathbf{x} $$\n$$ b' = b - \\alpha (-y \\sigma(-ys)) = b + \\alpha y \\sigma(-ys) $$\n\nNext, we calculate the post-update score, $s' = \\mathbf{w}^{\\prime\\top}\\mathbf{x} + b'$:\n$$ s' = (\\mathbf{w} + \\alpha y \\sigma(-ys) \\mathbf{x})^{\\top}\\mathbf{x} + (b + \\alpha y \\sigma(-ys)) $$\n$$ s' = \\mathbf{w}^{\\top}\\mathbf{x} + \\alpha y \\sigma(-ys) (\\mathbf{x}^{\\top}\\mathbf{x}) + b + \\alpha y \\sigma(-ys) $$\n$$ s' = (\\mathbf{w}^{\\top}\\mathbf{x} + b) + \\alpha y \\sigma(-ys) (\\mathbf{x}^{\\top}\\mathbf{x} + 1) $$\nRecognizing that $s = \\mathbf{w}^{\\top}\\mathbf{x} + b$ and $\\mathbf{x}^{\\top}\\mathbf{x}$ is the squared Euclidean norm of $\\mathbf{x}$, we have:\n$$ s' = s + \\alpha y \\sigma(-ys) (\\mathbf{x}^{\\top}\\mathbf{x} + 1) $$\n\nThe problem specifies an initial misclassification, which means the sign of the score does not match the label: $y s < 0$. We want to find the minimal learning rate $\\alpha_{\\min}$ such that the classification is corrected after one update, which means the new score $s'$ has the correct sign: $y s' > 0$.\n\nLet's substitute the expression for $s'$ into the target condition:\n$$ y \\left( s + \\alpha y \\sigma(-ys) (\\mathbf{x}^{\\top}\\mathbf{x} + 1) \\right) > 0 $$\nDistributing $y$ gives:\n$$ ys + \\alpha y^2 \\sigma(-ys) (\\mathbf{x}^{\\top}\\mathbf{x} + 1) > 0 $$\nSince $y \\in \\{-1, +1\\}$, we have $y^2 = 1$. The inequality becomes:\n$$ ys + \\alpha \\sigma(-ys) (\\mathbf{x}^{\\top}\\mathbf{x} + 1) > 0 $$\n\nNow, we solve for $\\alpha$:\n$$ \\alpha \\sigma(-ys) (\\mathbf{x}^{\\top}\\mathbf{x} + 1) > -ys $$\nThe terms multiplying $\\alpha$ are all positive: $\\sigma(z) > 0$ for all $z \\in \\mathbb{R}$, and $\\mathbf{x}^{\\top}\\mathbf{x} + 1 \\ge 1$. Thus, we can divide by the coefficient of $\\alpha$ without changing the direction of the inequality:\n$$ \\alpha > \\frac{-ys}{\\sigma(-ys) (\\mathbf{x}^{\\top}\\mathbf{x} + 1)} $$\n\nThe minimal learning rate $\\alpha_{\\min}$ is the value that defines the lower bound of this inequality.\n$$ \\alpha_{\\min} = \\frac{-ys}{\\sigma(-ys) (\\mathbf{x}^{\\top}\\mathbf{x} + 1)} $$\nGiven the initial condition $ys < 0$, the numerator $-ys$ is positive, ensuring that $\\alpha_{\\min} > 0$, which is consistent with the definition of a learning rate.\n\nTo obtain the final expression, we substitute the definition of the sigmoid function, $\\sigma(-ys) = \\frac{1}{1 + \\exp(ys)}$, and the score, $s = \\mathbf{w}^{\\top}\\mathbf{x} + b$:\n$$ \\alpha_{\\min} = \\frac{-ys}{\\left(\\frac{1}{1 + \\exp(ys)}\\right) (\\mathbf{x}^{\\top}\\mathbf{x} + 1)} $$\n$$ \\alpha_{\\min} = \\frac{-ys (1 + \\exp(ys))}{\\mathbf{x}^{\\top}\\mathbf{x} + 1} $$\nFinally, replacing $s$ with its definition provides the expression in terms of the given variables:\n$$ \\alpha_{\\min} = \\frac{-y(\\mathbf{w}^{\\top}\\mathbf{x} + b)(1 + \\exp(y(\\mathbf{w}^{\\top}\\mathbf{x} + b)))}{\\mathbf{x}^{\\top}\\mathbf{x} + 1} $$\nThis is the closed-form analytical expression for the minimal learning rate that guarantees a corrected classification for the example $(\\mathbf{x}, y)$ after a single update step.", "answer": "$$\\boxed{\\frac{-y(\\mathbf{w}^{\\top}\\mathbf{x} + b)(1 + \\exp(y(\\mathbf{w}^{\\top}\\mathbf{x} + b)))}{\\mathbf{x}^{\\top}\\mathbf{x} + 1}}$$", "id": "3180380"}, {"introduction": "While MAML's inner loop adapts to a task, its outer loop must learn a good initialization. This requires a 'meta-gradient' that differentiates through the inner adaptation process. This exercise [@problem_id:3100440] dives into the crucial distinction between the exact second-order meta-gradient and its widely used first-order approximation (FOMAML). By analytically isolating and calculating the \"lost\" second-order term, you will gain a precise, quantitative understanding of the approximation's nature and its implications for meta-optimization.", "problem": "Consider one step of inner-loop adaptation in Model-Agnostic Meta-Learning (MAML), where the updated parameter is defined by applying one step of gradient descent on a training loss. Let the parameter vector be two-dimensional, $\\boldsymbol{\\theta} \\in \\mathbb{R}^{2}$, and define the training loss and validation loss by\n$$\n\\mathcal{L}_{\\mathrm{tr}}(\\boldsymbol{\\theta}) = \\frac{1}{2}\\,\\boldsymbol{\\theta}^{\\top}\\mathbf{A}\\,\\boldsymbol{\\theta}, \n\\quad\n\\mathcal{L}_{\\mathrm{val}}(\\boldsymbol{\\theta}) = \\frac{1}{2}\\,\\boldsymbol{\\theta}^{\\top}\\mathbf{C}\\,\\boldsymbol{\\theta} + \\mathbf{r}^{\\top}\\boldsymbol{\\theta},\n$$\nwith\n$$\n\\mathbf{A}=\\begin{pmatrix}3 & 1 \\\\ 1 & 2\\end{pmatrix}, \n\\quad\n\\mathbf{C}=\\begin{pmatrix}2 & -1 \\\\ -1 & 4\\end{pmatrix}, \n\\quad\n\\mathbf{r}=\\begin{pmatrix}1 \\\\ -2\\end{pmatrix}.\n$$\nStarting from the initialization $\\boldsymbol{\\theta}=\\begin{pmatrix}1 \\\\ -1\\end{pmatrix}$, perform one inner update with step size $\\alpha=\\frac{1}{2}$:\n$$\n\\boldsymbol{\\theta}' \\;=\\; \\boldsymbol{\\theta} - \\alpha\\,\\nabla_{\\boldsymbol{\\theta}} \\mathcal{L}_{\\mathrm{tr}}(\\boldsymbol{\\theta}).\n$$\nThe outer (meta) objective is $\\mathcal{F}(\\boldsymbol{\\theta}) = \\mathcal{L}_{\\mathrm{val}}(\\boldsymbol{\\theta}')$. The true meta-gradient uses the chain rule,\n$$\n\\nabla_{\\boldsymbol{\\theta}} \\mathcal{F}(\\boldsymbol{\\theta}) \\;=\\; \\left(\\frac{\\partial \\boldsymbol{\\theta}'}{\\partial \\boldsymbol{\\theta}}\\right)^{\\top} \\nabla_{\\boldsymbol{\\theta}'} \\mathcal{L}_{\\mathrm{val}}(\\boldsymbol{\\theta}').\n$$\nSuppose instead that the inner-loop output $\\boldsymbol{\\theta}'$ is replaced by $\\mathrm{stop\\_grad}(\\boldsymbol{\\theta}')$ (that is, detached from the computational graph in automatic differentiation), and the first-order surrogate meta-gradient is taken to be\n$$\n\\mathbf{g}_{\\mathrm{FO}} \\;=\\; \\nabla_{\\boldsymbol{\\theta}'} \\mathcal{L}_{\\mathrm{val}}(\\boldsymbol{\\theta}').\n$$\nDefine the lost second-order contribution due to detaching as the difference\n$$\n\\Delta \\;=\\; \\mathbf{g}_{\\mathrm{FO}} - \\nabla_{\\boldsymbol{\\theta}} \\mathcal{F}(\\boldsymbol{\\theta}).\n$$\nUsing only the fundamental definitions of gradient, Hessian, and the multivariate chain rule from calculus, compute the squared Euclidean norm of the lost term, $\\|\\Delta\\|_{2}^{2}$, for the specified $\\mathcal{L}_{\\mathrm{tr}}$, $\\mathcal{L}_{\\mathrm{val}}$, $\\boldsymbol{\\theta}$, and $\\alpha$. Express your answer exactly as a rational number. No rounding is required.", "solution": "The problem asks for the squared Euclidean norm of the difference between the first-order surrogate meta-gradient and the true meta-gradient in a simplified Model-Agnostic Meta-Learning (MAML) setup. We must first validate the problem statement and, if valid, proceed with a rigorous derivation.\n\n### Problem Validation\nThe problem statement is self-contained and mathematically well-posed. All required variables, matrices, vectors, and initial conditions are explicitly provided.\n- **Parameters and Functions**: A two-dimensional parameter vector $\\boldsymbol{\\theta} \\in \\mathbb{R}^{2}$, quadratic training loss $\\mathcal{L}_{\\mathrm{tr}}(\\boldsymbol{\\theta})$, and quadratic validation loss $\\mathcal{L}_{\\mathrm{val}}(\\boldsymbol{\\theta})$.\n- **Constants**: Matrices $\\mathbf{A}$, $\\mathbf{C}$, vector $\\mathbf{r}$, initial parameter $\\boldsymbol{\\theta}$, and step size $\\alpha$. The matrices $\\mathbf{A}$ and $\\mathbf{C}$ are symmetric and positive definite (their determinants are $5$ and $7$, respectively, and their main diagonal elements are positive), ensuring the loss functions are convex, a standard property in optimization problems.\n- **Definitions**: The inner update rule $\\boldsymbol{\\theta}'$, the meta-objective $\\mathcal{F}(\\boldsymbol{\\theta})$, the true meta-gradient $\\nabla_{\\boldsymbol{\\theta}} \\mathcal{F}(\\boldsymbol{\\theta})$, the first-order surrogate $\\mathbf{g}_{\\mathrm{FO}}$, and the difference vector $\\Delta$ are all defined unambiguously.\n- **Scientific Grounding**: The problem is a standard, albeit simplified, representation of MAML, a well-established algorithm in machine learning. The use of gradients, Hessians, and the chain rule are fundamental calculus concepts correctly applied to this context.\n\nThe problem is valid as it is scientifically grounded, well-posed, objective, and contains no contradictions or ambiguities. We may proceed with the solution.\n\n### Step 1: Compute the Updated Parameter $\\boldsymbol{\\theta}'$\nThe inner-loop update is given by $\\boldsymbol{\\theta}' = \\boldsymbol{\\theta} - \\alpha\\,\\nabla_{\\boldsymbol{\\theta}} \\mathcal{L}_{\\mathrm{tr}}(\\boldsymbol{\\theta})$.\nThe training loss is a quadratic form $\\mathcal{L}_{\\mathrm{tr}}(\\boldsymbol{\\theta}) = \\frac{1}{2}\\,\\boldsymbol{\\theta}^{\\top}\\mathbf{A}\\,\\boldsymbol{\\theta}$. Since $\\mathbf{A}$ is a symmetric matrix, its gradient is $\\nabla_{\\boldsymbol{\\theta}} \\mathcal{L}_{\\mathrm{tr}}(\\boldsymbol{\\theta}) = \\mathbf{A}\\,\\boldsymbol{\\theta}$.\n\nWe are given the initial parameter vector $\\boldsymbol{\\theta}=\\begin{pmatrix}1 \\\\ -1\\end{pmatrix}$ and the matrix $\\mathbf{A}=\\begin{pmatrix}3 & 1 \\\\ 1 & 2\\end{pmatrix}$. First, we compute the gradient of the training loss at $\\boldsymbol{\\theta}$:\n$$\n\\nabla_{\\boldsymbol{\\theta}} \\mathcal{L}_{\\mathrm{tr}}(\\boldsymbol{\\theta}) = \\begin{pmatrix}3 & 1 \\\\ 1 & 2\\end{pmatrix} \\begin{pmatrix}1 \\\\ -1\\end{pmatrix} = \\begin{pmatrix}3(1) + 1(-1) \\\\ 1(1) + 2(-1)\\end{pmatrix} = \\begin{pmatrix}2 \\\\ -1\\end{pmatrix}.\n$$\nNow, we can compute the updated parameter $\\boldsymbol{\\theta}'$ using the step size $\\alpha=\\frac{1}{2}$:\n$$\n\\boldsymbol{\\theta}' = \\boldsymbol{\\theta} - \\alpha\\,\\nabla_{\\boldsymbol{\\theta}} \\mathcal{L}_{\\mathrm{tr}}(\\boldsymbol{\\theta}) = \\begin{pmatrix}1 \\\\ -1\\end{pmatrix} - \\frac{1}{2} \\begin{pmatrix}2 \\\\ -1\\end{pmatrix} = \\begin{pmatrix}1 \\\\ -1\\end{pmatrix} - \\begin{pmatrix}1 \\\\ -1/2\\end{pmatrix} = \\begin{pmatrix}0 \\\\ -1/2\\end{pmatrix}.\n$$\n\n### Step 2: Compute the First-Order Surrogate Meta-Gradient $\\mathbf{g}_{\\mathrm{FO}}$\nThe surrogate gradient is defined as $\\mathbf{g}_{\\mathrm{FO}} = \\nabla_{\\boldsymbol{\\theta}'} \\mathcal{L}_{\\mathrm{val}}(\\boldsymbol{\\theta}')$.\nThe validation loss is $\\mathcal{L}_{\\mathrm{val}}(\\boldsymbol{\\theta}) = \\frac{1}{2}\\,\\boldsymbol{\\theta}^{\\top}\\mathbf{C}\\,\\boldsymbol{\\theta} + \\mathbf{r}^{\\top}\\boldsymbol{\\theta}$. Since $\\mathbf{C}$ is a symmetric matrix, its gradient is $\\nabla_{\\boldsymbol{\\theta}} \\mathcal{L}_{\\mathrm{val}}(\\boldsymbol{\\theta}) = \\mathbf{C}\\,\\boldsymbol{\\theta} + \\mathbf{r}$.\nWe evaluate this gradient at the updated parameter $\\boldsymbol{\\theta}' = \\begin{pmatrix}0 \\\\ -1/2\\end{pmatrix}$, using $\\mathbf{C}=\\begin{pmatrix}2 & -1 \\\\ -1 & 4\\end{pmatrix}$ and $\\mathbf{r}=\\begin{pmatrix}1 \\\\ -2\\end{pmatrix}$:\n$$\n\\mathbf{g}_{\\mathrm{FO}} = \\mathbf{C}\\boldsymbol{\\theta}' + \\mathbf{r} = \\begin{pmatrix}2 & -1 \\\\ -1 & 4\\end{pmatrix} \\begin{pmatrix}0 \\\\ -1/2\\end{pmatrix} + \\begin{pmatrix}1 \\\\ -2\\end{pmatrix}.\n$$\n$$\n\\mathbf{g}_{\\mathrm{FO}} = \\begin{pmatrix}2(0) + (-1)(-1/2) \\\\ -1(0) + 4(-1/2)\\end{pmatrix} + \\begin{pmatrix}1 \\\\ -2\\end{pmatrix} = \\begin{pmatrix}1/2 \\\\ -2\\end{pmatrix} + \\begin{pmatrix}1 \\\\ -2\\end{pmatrix} = \\begin{pmatrix}3/2 \\\\ -4\\end{pmatrix}.\n$$\n\n### Step 3: Compute the Lost Second-Order Contribution $\\Delta$\nThe lost contribution is defined as the difference $\\Delta = \\mathbf{g}_{\\mathrm{FO}} - \\nabla_{\\boldsymbol{\\theta}} \\mathcal{F}(\\boldsymbol{\\theta})$, where $\\mathcal{F}(\\boldsymbol{\\theta}) = \\mathcal{L}_{\\mathrm{val}}(\\boldsymbol{\\theta}')$ is the meta-objective.\nThe true meta-gradient is given by the multivariate chain rule:\n$$\n\\nabla_{\\boldsymbol{\\theta}} \\mathcal{F}(\\boldsymbol{\\theta}) = \\nabla_{\\boldsymbol{\\theta}} \\mathcal{L}_{\\mathrm{val}}(\\boldsymbol{\\theta}'(\\boldsymbol{\\theta})) = \\left(\\frac{\\partial \\boldsymbol{\\theta}'}{\\partial \\boldsymbol{\\theta}}\\right)^{\\top} \\nabla_{\\boldsymbol{\\theta}'} \\mathcal{L}_{\\mathrm{val}}(\\boldsymbol{\\theta}').\n$$\nThe second term, $\\nabla_{\\boldsymbol{\\theta}'} \\mathcal{L}_{\\mathrm{val}}(\\boldsymbol{\\theta}')$, is precisely $\\mathbf{g}_{\\mathrm{FO}}$. The first term is the transpose of the Jacobian of $\\boldsymbol{\\theta}'$ with respect to $\\boldsymbol{\\theta}$.\nFrom the update rule $\\boldsymbol{\\theta}' = \\boldsymbol{\\theta} - \\alpha \\nabla_{\\boldsymbol{\\theta}} \\mathcal{L}_{\\mathrm{tr}}(\\boldsymbol{\\theta})$, we find the Jacobian:\n$$\n\\frac{\\partial \\boldsymbol{\\theta}'}{\\partial \\boldsymbol{\\theta}} = \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\left(\\boldsymbol{\\theta} - \\alpha \\mathbf{A}\\boldsymbol{\\theta}\\right) = \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\left((\\mathbf{I} - \\alpha \\mathbf{A})\\boldsymbol{\\theta}\\right) = \\mathbf{I} - \\alpha \\mathbf{A}.\n$$\nThe matrix $\\mathbf{A}$ is symmetric, so $(\\mathbf{I} - \\alpha \\mathbf{A})^{\\top} = \\mathbf{I} - \\alpha \\mathbf{A}$.\nSubstituting this into the expression for the true meta-gradient:\n$$\n\\nabla_{\\boldsymbol{\\theta}} \\mathcal{F}(\\boldsymbol{\\theta}) = (\\mathbf{I} - \\alpha \\mathbf{A}) \\mathbf{g}_{\\mathrm{FO}}.\n$$\nNow we can express $\\Delta$ as:\n$$\n\\Delta = \\mathbf{g}_{\\mathrm{FO}} - (\\mathbf{I} - \\alpha \\mathbf{A})\\mathbf{g}_{\\mathrm{FO}} = \\left(\\mathbf{I} - (\\mathbf{I} - \\alpha \\mathbf{A})\\right)\\mathbf{g}_{\\mathrm{FO}} = \\alpha \\mathbf{A} \\mathbf{g}_{\\mathrm{FO}}.\n$$\nThis simplification shows that the lost term is the result of applying the Hessian of the training loss (represented by $\\mathbf{A}$) to the validation gradient, scaled by the learning rate $\\alpha$.\nLet's compute $\\Delta$ using the values we have:\n$$\n\\Delta = \\frac{1}{2} \\begin{pmatrix}3 & 1 \\\\ 1 & 2\\end{pmatrix} \\begin{pmatrix}3/2 \\\\ -4\\end{pmatrix} = \\frac{1}{2} \\begin{pmatrix}3(3/2) + 1(-4) \\\\ 1(3/2) + 2(-4)\\end{pmatrix} = \\frac{1}{2} \\begin{pmatrix}9/2 - 8/2 \\\\ 3/2 - 16/2\\end{pmatrix} = \\frac{1}{2} \\begin{pmatrix}1/2 \\\\ -13/2\\end{pmatrix} = \\begin{pmatrix}1/4 \\\\ -13/4\\end{pmatrix}.\n$$\n\n### Step 4: Compute the Squared Euclidean Norm $\\|\\Delta\\|_{2}^{2}$\nThe final step is to compute the squared Euclidean norm of the vector $\\Delta$:\n$$\n\\|\\Delta\\|_{2}^{2} = \\left(\\frac{1}{4}\\right)^2 + \\left(-\\frac{13}{4}\\right)^2 = \\frac{1^2}{4^2} + \\frac{(-13)^2}{4^2} = \\frac{1}{16} + \\frac{169}{16} = \\frac{170}{16}.\n$$\nAs a final step, we simplify the fraction:\n$$\n\\|\\Delta\\|_{2}^{2} = \\frac{170 \\div 2}{16 \\div 2} = \\frac{85}{8}.\n$$", "answer": "$$\n\\boxed{\\frac{85}{8}}\n$$", "id": "3100440"}, {"introduction": "True meta-learning involves optimizing not just for one task, but for a whole distribution of them. This final practice elevates our perspective to the \"meta\" level, moving beyond single-task adaptation to the meta-optimization of hyperparameters. Here [@problem_id:3149768], you will derive and implement the logic for finding an inner-loop learning rate $\\alpha$ that is optimal across an entire family of tasks. This will solidify your understanding of how MAML prepares a model to perform well on average for future, unseen tasks and how sensitive it is to shifts between training and testing distributions.", "problem": "You are given a meta-learning scenario using Model-Agnostic Meta-Learning (MAML), where the inner loop performs a single-step Stochastic Gradient Descent (SGD) update with a scalar step size. Each task is a one-dimensional convex quadratic loss. Your goal is to rigorously derive, implement, and evaluate sensitivity to mis-specification of the inner-loop step size across different task distributions. You must base your derivations on first principles only, starting from gradient-based adaptation on convex quadratics and basic properties of expectations.\n\nAssumptions and setup:\n- The Model-Agnostic Meta-Learning (MAML) inner-loop performs a single gradient step from an initialization parameter $ \\theta \\in \\mathbb{R} $ using step size $ \\alpha \\ge 0 $.\n- Each task loss is parameterized as a one-dimensional quadratic $ L(\\theta; \\lambda, \\theta^\\star) = \\frac{1}{2} \\lambda (\\theta - \\theta^\\star)^2 $, where $ \\lambda > 0 $ is the task curvature and $ \\theta^\\star $ is the task-specific minimizer.\n- The gradient step is $ \\theta' = \\theta - \\alpha \\nabla_\\theta L(\\theta; \\lambda, \\theta^\\star) $.\n- At meta-train time, a single global step size $ \\alpha_{\\text{train}} $ is selected to minimize the expected post-update validation loss across a training curvature distribution for $ \\lambda $. At meta-test time, the curvature distribution for $ \\lambda $ may differ, rendering $ \\alpha_{\\text{train}} $ mis-specified.\n- Let $ c = \\mathbb{E}[(\\theta - \\theta^\\star)^2] $ be the expected squared displacement at adaptation start, assumed independent of $ \\lambda $ and constant across comparisons, so it cancels in ratios of expected losses.\n\nYour tasks:\n- Derive from first principles the expected validation loss after the single gradient step for a given step size $ \\alpha $ and a distribution over $ \\lambda $, and the expression for the meta-optimal step size that minimizes this expected loss under a given distribution of $ \\lambda $.\n- For a curvature distribution given by a Uniform distribution on $ [a,b] $ with $ 0 < a < b $, compute $ \\mathbb{E}[\\lambda^k] $ for $ k \\in \\{1,2,3\\} $ from first principles.\n- For a curvature distribution given by a finite discrete mixture with values $ \\{\\lambda_i\\}_{i=1}^n $ and weights $ \\{w_i\\}_{i=1}^n $ satisfying $ w_i \\ge 0 $ and $ \\sum_{i=1}^n w_i = 1 $, compute $ \\mathbb{E}[\\lambda^k] $ for $ k \\in \\{1,2,3\\} $ from first principles.\n- Define the meta-test performance degradation metric as a decimal:\n  $$ D(\\alpha_{\\text{given}} \\mid \\text{test}) = \\frac{\\mathbb{E}_{\\text{test}}\\left[ \\lambda (1 - \\alpha_{\\text{given}} \\lambda)^2 \\right]}{\\mathbb{E}_{\\text{test}}\\left[ \\lambda (1 - \\alpha_{\\text{test-opt}} \\lambda)^2 \\right]} - 1, $$\n  where $ \\alpha_{\\text{test-opt}} $ is the meta-optimal step size computed for the meta-test distribution of $ \\lambda $, and $ \\alpha_{\\text{given}} $ is the step size used at meta-test.\n- In all cases, $ \\alpha_{\\text{given}} = f \\cdot \\alpha_{\\text{train}} $, where $ f \\ge 0 $ is a specified multiplicative mis-specification factor.\n\nProgram requirements:\n- Implement a self-contained program that computes $ D(\\alpha_{\\text{given}} \\mid \\text{test}) $ for each test case below, using analytic expectations (no randomness).\n- Your program must:\n  1. Compute $ \\alpha_{\\text{train}} $ from the training distribution using your derived expression.\n  2. Form $ \\alpha_{\\text{given}} = f \\cdot \\alpha_{\\text{train}} $.\n  3. Compute $ \\alpha_{\\text{test-opt}} $ from the meta-test distribution using your derived expression.\n  4. Compute $ D(\\alpha_{\\text{given}} \\mid \\text{test}) $ as defined above, returning a decimal.\n- The final output must be a single line containing a comma-separated Python list of the six degradation values, in the exact format $ [d_1,d_2,d_3,d_4,d_5,d_6] $. Each $ d_i $ must be a float.\n\nTest suite:\n- Test case $1$ (happy path):\n  - Train distribution: Uniform on $ [1,3] $.\n  - Test distribution: Uniform on $ [1,3] $.\n  - Mis-specification factor: $ f = 1.0 $.\n- Test case $2$ (distribution shift):\n  - Train distribution: Uniform on $ [1,3] $.\n  - Test distribution: Uniform on $ [2,4] $.\n  - Mis-specification factor: $ f = 1.0 $.\n- Test case $3$ (compensatory scaling under shift):\n  - Train distribution: Uniform on $ [1,3] $.\n  - Test distribution: Uniform on $ [2,4] $.\n  - Mis-specification factor: $ f = 0.75 $.\n- Test case $4$ (mixture reweighting):\n  - Train distribution: Discrete values $ [0.5, 3.0] $ with weights $ [0.7, 0.3] $.\n  - Test distribution: Discrete values $ [0.5, 3.0] $ with weights $ [0.3, 0.7] $.\n  - Mis-specification factor: $ f = 1.0 $.\n- Test case $5$ (boundary: no adaptation):\n  - Train distribution: Uniform on $ [1,3] $.\n  - Test distribution: Uniform on $ [1,3] $.\n  - Mis-specification factor: $ f = 0.0 $.\n- Test case $6$ (boundary: aggressive overshoot):\n  - Train distribution: Uniform on $ [1,3] $.\n  - Test distribution: Uniform on $ [1,3] $.\n  - Mis-specification factor: $ f = 3.0 $.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example $ [d_1,d_2,d_3,d_4,d_5,d_6] $.\n- There are no physical units and no angles in this problem. All reported values must be decimals.", "solution": "The problem requires a rigorous derivation of the performance of a single-step Model-Agnostic Meta-Learning (MAML) algorithm on one-dimensional quadratic loss functions and an evaluation of its sensitivity to a mis-specified inner-loop step size, $ \\alpha $.\n\n### Step 1: Derivation of the Expected Post-Update Loss\n\nThe loss for a specific task is given by $ L(\\theta; \\lambda, \\theta^\\star) = \\frac{1}{2} \\lambda (\\theta - \\theta^\\star)^2 $, where $ \\theta \\in \\mathbb{R} $ is the model parameter, $ \\lambda > 0 $ is the task's curvature, and $ \\theta^\\star $ is the task's optimal parameter.\n\nThe gradient of the loss with respect to $ \\theta $ is:\n$$ \\nabla_\\theta L(\\theta; \\lambda, \\theta^\\star) = \\lambda (\\theta - \\theta^\\star) $$\nThe MAML inner loop performs a single gradient descent step to update the parameter from an initial value $ \\theta $ to a task-adapted value $ \\theta' $:\n$$ \\theta' = \\theta - \\alpha \\nabla_\\theta L(\\theta; \\lambda, \\theta^\\star) = \\theta - \\alpha \\lambda (\\theta - \\theta^\\star) $$\nwhere $ \\alpha \\ge 0 $ is the inner-loop step size.\n\nThe post-update or validation loss for the task is $ L(\\theta'; \\lambda, \\theta^\\star) = \\frac{1}{2} \\lambda (\\theta' - \\theta^\\star)^2 $. To analyze this, we first express the post-update error term, $ (\\theta' - \\theta^\\star) $, in terms of the pre-update error, $ (\\theta - \\theta^\\star) $:\n$$ \\theta' - \\theta^\\star = (\\theta - \\alpha \\lambda (\\theta - \\theta^\\star)) - \\theta^\\star = (\\theta - \\theta^\\star) - \\alpha \\lambda (\\theta - \\theta^\\star) = (1 - \\alpha \\lambda) (\\theta - \\theta^\\star) $$\nSubstituting this back into the post-update loss expression gives:\n$$ L(\\theta') = \\frac{1}{2} \\lambda \\left[ (1 - \\alpha \\lambda) (\\theta - \\theta^\\star) \\right]^2 = \\frac{1}{2} \\lambda (1 - \\alpha \\lambda)^2 (\\theta - \\theta^\\star)^2 $$\nThe meta-objective is to minimize the expected post-update loss over a distribution of tasks. A task is defined by the pair $ (\\lambda, \\theta^\\star) $. The expectation, denoted by $ \\mathbb{E}[\\cdot] $, is taken over this distribution.\n$$ \\mathbb{E}[L(\\theta')] = \\mathbb{E}_{\\lambda, \\theta^\\star} \\left[ \\frac{1}{2} \\lambda (1 - \\alpha \\lambda)^2 (\\theta - \\theta^\\star)^2 \\right] $$\nThe problem states that the initial expected squared displacement, $ c = \\mathbb{E}[(\\theta - \\theta^\\star)^2] $, is constant and independent of $ \\lambda $. This allows us to separate the expectations:\n$$ \\mathbb{E}[L(\\theta')] = \\frac{1}{2} \\mathbb{E}_{\\lambda} \\left[ \\lambda (1 - \\alpha \\lambda)^2 \\right] \\mathbb{E}_{\\theta^\\star} \\left[ (\\theta - \\theta^\\star)^2 \\right] = \\frac{c}{2} \\mathbb{E}_{\\lambda} \\left[ \\lambda (1 - \\alpha \\lambda)^2 \\right] $$\nSince our goal is to optimize with respect to $ \\alpha $, the constant factor $ \\frac{c}{2} $ can be ignored. We define the objective function to minimize as:\n$$ J(\\alpha) = \\mathbb{E}_{\\lambda} \\left[ \\lambda (1 - \\alpha \\lambda)^2 \\right] $$\nExpanding the term inside the expectation yields:\n$$ \\lambda (1 - \\alpha \\lambda)^2 = \\lambda (1 - 2\\alpha\\lambda + \\alpha^2\\lambda^2) = \\lambda - 2\\alpha\\lambda^2 + \\alpha^2\\lambda^3 $$\nBy linearity of expectation, the objective function becomes:\n$$ J(\\alpha) = \\mathbb{E}[\\lambda] - 2\\alpha\\mathbb{E}[\\lambda^2] + \\alpha^2\\mathbb{E}[\\lambda^3] $$\nThis is the expression for the (scaled) expected validation loss.\n\n### Step 2: Derivation of the Meta-Optimal Step Size\nTo find the meta-optimal step size, $ \\alpha_{\\text{opt}} $, that minimizes $ J(\\alpha) $, we differentiate $ J(\\alpha) $ with respect to $ \\alpha $ and set the result to zero.\n$$ \\frac{dJ(\\alpha)}{d\\alpha} = -2\\mathbb{E}[\\lambda^2] + 2\\alpha\\mathbb{E}[\\lambda^3] = 0 $$\nSolving for $ \\alpha $ gives the optimal step size:\n$$ 2\\alpha \\mathbb{E}[\\lambda^3] = 2\\mathbb{E}[\\lambda^2] \\implies \\alpha_{\\text{opt}} = \\frac{\\mathbb{E}[\\lambda^2]}{\\mathbb{E}[\\lambda^3]} $$\nThe second derivative, $ \\frac{d^2J(\\alpha)}{d\\alpha^2} = 2\\mathbb{E}[\\lambda^3] $, is positive since $ \\lambda > 0 $, confirming that this value of $ \\alpha $ corresponds to a minimum.\n\n### Step 3: Calculation of Moments for Required Distributions\n\nThe computation of $ \\alpha_{\\text{opt}} $ requires the second and third moments of the curvature distribution, $ p(\\lambda) $. The computation of $ J(\\alpha) $ additionally requires the first moment.\n\n#### Uniform Distribution\nFor $ \\lambda \\sim U[a,b] $ with $ 0 < a < b $, the probability density function is $ p(\\lambda) = \\frac{1}{b-a} $ for $ \\lambda \\in [a,b] $. The $ k $-th moment is given by:\n$$ \\mathbb{E}[\\lambda^k] = \\int_a^b \\lambda^k p(\\lambda) d\\lambda = \\frac{1}{b-a} \\int_a^b \\lambda^k d\\lambda = \\frac{1}{b-a} \\left[ \\frac{\\lambda^{k+1}}{k+1} \\right]_a^b = \\frac{b^{k+1} - a^{k+1}}{(k+1)(b-a)} $$\nFor $ k \\in \\{1, 2, 3\\} $, we have:\n- $ \\mathbb{E}[\\lambda] = \\frac{b^2 - a^2}{2(b-a)} = \\frac{a+b}{2} $\n- $ \\mathbb{E}[\\lambda^2] = \\frac{b^3 - a^3}{3(b-a)} = \\frac{a^2+ab+b^2}{3} $\n- $ \\mathbb{E}[\\lambda^3] = \\frac{b^4 - a^4}{4(b-a)} = \\frac{(a+b)(a^2+b^2)}{4} $\n\n#### Discrete Mixture Distribution\nFor a discrete distribution over values $ \\{\\lambda_i\\}_{i=1}^n $ with corresponding probabilities (weights) $ \\{w_i\\}_{i=1}^n $, where $ \\sum_{i=1}^n w_i = 1 $, the $ k $-th moment is given by the definition of expectation for a discrete random variable:\n$$ \\mathbb{E}[\\lambda^k] = \\sum_{i=1}^n \\lambda_i^k w_i $$\n\n### Step 4: Computational Procedure for the Degradation Metric\n\nThe degradation metric is defined as:\n$$ D(\\alpha_{\\text{given}} \\mid \\text{test}) = \\frac{\\mathbb{E}_{\\text{test}}\\left[ \\lambda (1 - \\alpha_{\\text{given}} \\lambda)^2 \\right]}{\\mathbb{E}_{\\text{test}}\\left[ \\lambda (1 - \\alpha_{\\text{test-opt}} \\lambda)^2 \\right]} - 1 = \\frac{J_{\\text{test}}(\\alpha_{\\text{given}})}{J_{\\text{test}}(\\alpha_{\\text{test-opt}})} - 1 $$\nwhere $ J_{\\text{dist}}(\\alpha) = \\mathbb{E}_{\\text{dist}}[\\lambda] - 2\\alpha\\mathbb{E}_{\\text{dist}}[\\lambda^2] + \\alpha^2\\mathbb{E}_{\\text{dist}}[\\lambda^3] $. The denominator, $ J_{\\text{test}}(\\alpha_{\\text{test-opt}}) $, represents the minimum achievable expected loss on the test distribution. This minimum can also be calculated by substituting $ \\alpha_{\\text{opt}} $ back into the expression for $ J(\\alpha) $:\n$$ J_{\\text{test}}(\\alpha_{\\text{test-opt}}) = \\mathbb{E}_{\\text{test}}[\\lambda] - \\frac{(\\mathbb{E}_{\\text{test}}[\\lambda^2])^2}{\\mathbb{E}_{\\text{test}}[\\lambda^3]} $$\nThe computational procedure for each test case is as follows:\n$1.$ Determine the training distribution (type and parameters) and compute its moments $ \\mathbb{E}_{\\text{train}}[\\lambda^2] $ and $ \\mathbb{E}_{\\text{train}}[\\lambda^3] $.\n$2.$ Calculate the meta-training optimal step size: $ \\alpha_{\\text{train}} = \\frac{\\mathbb{E}_{\\text{train}}[\\lambda^2]}{\\mathbb{E}_{\\text{train}}[\\lambda^3]} $.\n$3.$ Use the given mis-specification factor $ f $ to find the step size used at test time: $ \\alpha_{\\text{given}} = f \\cdot \\alpha_{\\text{train}} $.\n$4.$ Determine the test distribution and compute its first three moments: $ \\mathbb{E}_{\\text{test}}[\\lambda] $, $ \\mathbb{E}_{\\text{test}}[\\lambda^2] $, and $ \\mathbb{E}_{\\text{test}}[\\lambda^3] $.\n$5.$ Calculate the meta-test optimal step size: $ \\alpha_{\\text{test-opt}} = \\frac{\\mathbb{E}_{\\text{test}}[\\lambda^2]}{\\mathbb{E}_{\\text{test}}[\\lambda^3]} $.\n$6.$ Calculate the numerator of the degradation ratio: $ J_{\\text{test}}(\\alpha_{\\text{given}}) = \\mathbb{E}_{\\text{test}}[\\lambda] - 2\\alpha_{\\text{given}}\\mathbb{E}_{\\text{test}}[\\lambda^2] + \\alpha_{\\text{given}}^2\\mathbb{E}_{\\text{test}}[\\lambda^3] $.\n$7.$ Calculate the denominator of the degradation ratio: $ J_{\\text{test}}(\\alpha_{\\text{test-opt}}) = \\mathbb{E}_{\\text{test}}[\\lambda] - \\frac{(\\mathbb{E}_{\\text{test}}[\\lambda^2])^2}{\\mathbb{E}_{\\text{test}}[\\lambda^3]} $.\n$8.$ Compute the final degradation metric: $ D = \\frac{J_{\\text{test}}(\\alpha_{\\text{given}})}{J_{\\text{test}}(\\alpha_{\\text{test-opt}})} - 1 $.\nThis procedure will be implemented for each of the six specified test cases.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the meta-test performance degradation D for a series of test cases\n    based on the analytical framework of MAML on 1D quadratic losses.\n    \"\"\"\n\n    test_cases = [\n        # Test case 1: happy path\n        {'train_dist': ('uniform', (1.0, 3.0)), 'test_dist': ('uniform', (1.0, 3.0)), 'f': 1.0},\n        # Test case 2: distribution shift\n        {'train_dist': ('uniform', (1.0, 3.0)), 'test_dist': ('uniform', (2.0, 4.0)), 'f': 1.0},\n        # Test case 3: compensatory scaling under shift\n        {'train_dist': ('uniform', (1.0, 3.0)), 'test_dist': ('uniform', (2.0, 4.0)), 'f': 0.75},\n        # Test case 4: mixture reweighting\n        {'train_dist': ('discrete', ([0.5, 3.0], [0.7, 0.3])), 'test_dist': ('discrete', ([0.5, 3.0], [0.3, 0.7])), 'f': 1.0},\n        # Test case 5: boundary: no adaptation\n        {'train_dist': ('uniform', (1.0, 3.0)), 'test_dist': ('uniform', (1.0, 3.0)), 'f': 0.0},\n        # Test case 6: boundary: aggressive overshoot\n        {'train_dist': ('uniform', (1.0, 3.0)), 'test_dist': ('uniform', (1.0, 3.0)), 'f': 3.0},\n    ]\n\n    def get_moments(dist_type, params):\n        \"\"\"\n        Computes the first three moments (E[lambda^1], E[lambda^2], E[lambda^3])\n        for a given distribution of the curvature lambda.\n        \n        Args:\n            dist_type (str): 'uniform' or 'discrete'.\n            params (tuple): Distribution parameters.\n                For 'uniform': (a, b), the interval bounds.\n                For 'discrete': (values, weights), NumPy arrays of values and weights.\n        \n        Returns:\n            tuple: (E[lambda], E[lambda^2], E[lambda^3]).\n        \"\"\"\n        moments = []\n        if dist_type == 'uniform':\n            a, b = params\n            for k in range(1, 4):\n                # E[lambda^k] = (b^(k+1) - a^(k+1)) / ((k+1)*(b-a))\n                if b == a: # Avoid division by zero, though problem states a < b\n                    moments.append(a**k)\n                else:\n                    moments.append((b**(k + 1) - a**(k + 1)) / ((k + 1) * (b - a)))\n        elif dist_type == 'discrete':\n            values, weights = np.array(params[0]), np.array(params[1])\n            for k in range(1, 4):\n                # E[lambda^k] = sum(lambda_i^k * w_i)\n                moments.append(np.sum((values**k) * weights))\n        return tuple(moments)\n\n    results = []\n    for case in test_cases:\n        # 1. Compute alpha_train\n        train_dist_type, train_params = case['train_dist']\n        _, e2_train, e3_train = get_moments(train_dist_type, train_params)\n        alpha_train = e2_train / e3_train if e3_train != 0 else 0.0\n\n        # 2. Form alpha_given\n        f = case['f']\n        alpha_given = f * alpha_train\n\n        # 3. Compute moments and alpha_test_opt for the test distribution\n        test_dist_type, test_params = case['test_dist']\n        e1_test, e2_test, e3_test = get_moments(test_dist_type, test_params)\n        alpha_test_opt = e2_test / e3_test if e3_test != 0 else 0.0\n        \n        # 4. Compute the degradation metric D\n        \n        # Numerator: J_test(alpha_given)\n        # J(alpha) = E[lambda] - 2*alpha*E[lambda^2] + alpha^2*E[lambda^3]\n        J_given = e1_test - 2 * alpha_given * e2_test + (alpha_given**2) * e3_test\n\n        # Denominator: J_test(alpha_test_opt)\n        # This is the minimum value of the quadratic J(alpha)\n        # min J(alpha) = E[lambda] - (E[lambda^2])^2 / E[lambda^3]\n        if e3_test == 0:\n             # If E[lambda^3] is 0 (only possible if all lambdas are 0, which is ruled out),\n             # J(alpha) is linear. To avoid division by zero, handle this edge case.\n             # In this problem context, lambda > 0, so e3_test > 0.\n            J_opt = e1_test\n        else:\n            J_opt = e1_test - (e2_test**2) / e3_test\n\n        # Degradation metric\n        if J_opt == 0:\n            # Should not happen in this problem since lambda > 0 implies J_opt > 0 unless\n            # a degenerate case where J is minimized to 0.\n            degradation = float('inf') if J_given > 0 else 0.0\n        else:\n            degradation = (J_given / J_opt) - 1.0\n\n        results.append(degradation)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3149768"}]}