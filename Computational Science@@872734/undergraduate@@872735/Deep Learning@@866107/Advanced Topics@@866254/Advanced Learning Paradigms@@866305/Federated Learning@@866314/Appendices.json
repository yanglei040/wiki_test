{"hands_on_practices": [{"introduction": "Before models can be aggregated at the server, each client must perform its local training. This process is governed by a fundamental trade-off: using a larger mini-batch of data can produce a more accurate gradient estimate, but this comes at the cost of increased memory, computation time, and energy consumption. This practice ([@problem_id:3124684]) challenges you to navigate these real-world device constraints to find the optimal batch size, a crucial first step in designing efficient and practical federated systems.", "problem": "A single mobile device participates in Federated Learning (FL) by computing a local gradient estimate $\\hat{g}$ for one scalar model parameter using a mini-batch of size $B$ of independent and identically distributed data samples from its local dataset. Let each per-sample gradient be a scalar random variable $g_{i}$ with mean $\\mathbb{E}[g_{i}] = g$ and variance $\\mathrm{Var}(g_{i}) = \\sigma^{2}$, and assume the $g_{i}$ are independent. The device aims to choose $B$ as large as possible to reduce the variance of $\\hat{g}$, subject to resource constraints for a single training round:\n\n- Memory budget: the device has $M = 80$ MiB of free memory available for the training round. The loaded model occupies $m_{\\mathrm{model}} = 40$ MiB, the runtime overhead (activations, framework buffers) occupies $m_{\\mathrm{ov}} = 10$ MiB, and each data sample requires $m_{s} = 1$ MiB of memory while processing. Assume memory usage scales linearly in $B$ and that all quantities must be held simultaneously in memory.\n- Latency budget: each data sample requires $t_{s} = 3$ ms of compute time, and the device must finish the local computation within $T_{\\max} = 120$ ms.\n- Energy budget: each data sample requires $e_{s} = 7$ mJ of energy, and the device has $E_{\\max} = 250$ mJ available for the round.\n\nAssume the device processes samples sequentially, $B$ must be a positive integer, and ignore any parallelism or pipeline effects. Also assume that no additional noise (such as quantization or differential privacy) is introduced, so that the only source of randomness in $\\hat{g}$ is the sampling of the mini-batch.\n\nStarting from fundamental definitions of the sample mean and the properties of variance for independent random variables, derive an expression for $\\mathrm{Var}(\\hat{g})$ as a function of $B$. Then, given $\\sigma^{2} = 0.81$, determine the largest feasible $B$ that satisfies all three device constraints and compute the numerical value of $\\mathrm{Var}(\\hat{g})$ at that $B$. Express the final variance as a pure number without units. No rounding is required; report the exact value.", "solution": "The problem asks for two main results: first, a derivation of the variance of a gradient estimate, $\\mathrm{Var}(\\hat{g})$, as a function of the mini-batch size, $B$; second, the numerical value of this variance given a specific set of resource constraints that limit $B$.\n\nFirst, we derive the expression for $\\mathrm{Var}(\\hat{g})$. The local gradient estimate, $\\hat{g}$, is defined as the sample mean of $B$ independent and identically distributed (i.i.d.) per-sample gradients, denoted by $g_i$ for $i \\in \\{1, 2, \\dots, B\\}$.\n$$ \\hat{g} = \\frac{1}{B} \\sum_{i=1}^{B} g_i $$\nEach $g_i$ is a random variable with mean $\\mathbb{E}[g_{i}] = g$ and variance $\\mathrm{Var}(g_{i}) = \\sigma^{2}$. We can find the variance of $\\hat{g}$ by applying the properties of the variance operator.\n\nFor a constant $c$ and a random variable $X$, the variance operator follows the rule $\\mathrm{Var}(cX) = c^2 \\mathrm{Var}(X)$. In our case, the constant is $\\frac{1}{B}$.\n$$ \\mathrm{Var}(\\hat{g}) = \\mathrm{Var}\\left(\\frac{1}{B} \\sum_{i=1}^{B} g_i\\right) = \\left(\\frac{1}{B}\\right)^2 \\mathrm{Var}\\left(\\sum_{i=1}^{B} g_i\\right) = \\frac{1}{B^2} \\mathrm{Var}\\left(\\sum_{i=1}^{B} g_i\\right) $$\nFor a sum of independent random variables, the variance of the sum is equal to the sum of their individual variances. The problem states that the $g_i$ are independent.\n$$ \\mathrm{Var}\\left(\\sum_{i=1}^{B} g_i\\right) = \\sum_{i=1}^{B} \\mathrm{Var}(g_i) $$\nSince the samples are also identically distributed, the variance of each $g_i$ is the same: $\\mathrm{Var}(g_i) = \\sigma^2$.\n$$ \\sum_{i=1}^{B} \\mathrm{Var}(g_i) = \\sum_{i=1}^{B} \\sigma^2 = B \\sigma^2 $$\nSubstituting this result back into the expression for $\\mathrm{Var}(\\hat{g})$ yields the desired relationship.\n$$ \\mathrm{Var}(\\hat{g}) = \\frac{1}{B^2} (B \\sigma^2) = \\frac{\\sigma^2}{B} $$\n\nNext, we must determine the largest feasible integer value for the mini-batch size, $B$, subject to the three given resource constraints.\n\n1.  Memory Constraint: The total memory consumed must not exceed the available memory, $M = 80$ MiB. The total memory is the sum of the fixed model and overhead memory, $m_{\\mathrm{model}} = 40$ MiB and $m_{\\mathrm{ov}} = 10$ MiB, and the variable memory per data sample, $m_{s} = 1$ MiB, scaled by the batch size $B$.\n    $$ m_{\\mathrm{model}} + m_{\\mathrm{ov}} + B \\cdot m_{s} \\le M $$\n    Substituting the numeric values (units are consistent and can be omitted for the inequality):\n    $$ 40 + 10 + B \\cdot 1 \\le 80 $$\n    $$ 50 + B \\le 80 $$\n    $$ B \\le 30 $$\n\n2.  Latency Constraint: The total computation time must be within the maximum allowed latency, $T_{\\max} = 120$ ms. The total time is the per-sample compute time, $t_{s} = 3$ ms, multiplied by the batch size $B$.\n    $$ B \\cdot t_{s} \\le T_{\\max} $$\n    Substituting the numeric values:\n    $$ B \\cdot 3 \\le 120 $$\n    $$ B \\le \\frac{120}{3} $$\n    $$ B \\le 40 $$\n\n3.  Energy Constraint: The total energy consumed must not exceed the energy budget, $E_{\\max} = 250$ mJ. The total energy is the per-sample energy consumption, $e_{s} = 7$ mJ, multiplied by the batch size $B$.\n    $$ B \\cdot e_{s} \\le E_{\\max} $$\n    Substituting the numeric values:\n    $$ B \\cdot 7 \\le 250 $$\n    $$ B \\le \\frac{250}{7} $$\n    Since $B$ must be a positive integer, we must take the floor of this value: $B \\le \\lfloor \\frac{250}{7} \\rfloor = \\lfloor 35.714\\dots \\rfloor = 35$.\n    $$ B \\le 35 $$\n\nTo satisfy all three constraints simultaneously, $B$ must be less than or equal to the minimum of the three derived upper bounds.\n$$ B \\le \\min(30, 40, 35) $$\n$$ B \\le 30 $$\nThe problem asks for the largest possible $B$, so we select the maximum integer value that satisfies this condition, which is $B = 30$.\n\nFinally, we compute the numerical value of $\\mathrm{Var}(\\hat{g})$ using the derived formula $\\mathrm{Var}(\\hat{g}) = \\frac{\\sigma^2}{B}$, the determined batch size $B = 30$, and the given per-sample variance $\\sigma^2 = 0.81$.\n$$ \\mathrm{Var}(\\hat{g}) = \\frac{0.81}{30} $$\nThis can be computed exactly as a decimal fraction:\n$$ \\mathrm{Var}(\\hat{g}) = \\frac{81}{100} \\div 30 = \\frac{81}{100} \\times \\frac{1}{30} = \\frac{81}{3000} = \\frac{27 \\times 3}{1000 \\times 3} = \\frac{27}{1000} = 0.027 $$", "answer": "$$\\boxed{0.027}$$", "id": "3124684"}, {"introduction": "Once clients complete their local training, the server must intelligently combine their results into an updated global model. How should each client's contribution be weighted? This exercise ([@problem_id:3124727]) delves into the statistical principles behind model aggregation, prompting you to derive the theoretically optimal weighting scheme and compare it to practical heuristics. Through this analysis, you will gain a deeper appreciation for the design of aggregation strategies and their performance implications in diverse client environments.", "problem": "In a cross-device Federated Learning (FL) system, a central server combines local model parameters from $K$ clients into a single global parameter using a convex combination. Specifically, the server forms $w^{new} = \\sum_{i=1}^{K} \\alpha_i w_i$ with $\\sum_{i=1}^{K} \\alpha_i = 1$ and $\\alpha_i \\ge 0$. Two practical choices for the aggregation weights are considered: $\\alpha_i \\propto n_i$, where $n_i$ is the number of local training examples on client $i$ (as in Federated Averaging (FedAvg)), and $\\alpha_i \\propto 1/\\hat{\\sigma}_i$, where $\\hat{\\sigma}_i$ is an on-device estimate of the local stochastic noise level from training on client $i$. Assume the following modeling base for reasoning about expected error:\n- Each client performs local training to produce a local estimate $w_i$ of an underlying parameter $w^\\star$.\n- For the purpose of this question, consider the scalar case where $w^\\star \\in \\mathbb{R}$ and the $w_i$ are independent and unbiased estimators of $w^\\star$.\n- The variability of $w_i$ arises from stochastic optimization and data sampling, and can be modeled as $\\operatorname{Var}(w_i) = \\sigma_i^2 / n_i$, where $\\sigma_i^2$ is a client-specific noise scale and $n_i$ is the local sample size. This reflects the well-tested fact that, under mild conditions, the variance of an average of $n_i$ independent observations with variance $\\sigma_i^2$ scales as $\\sigma_i^2/n_i$.\n\nNow consider the following claims about the trade-offs between $\\alpha_i \\propto n_i$ and $\\alpha_i \\propto 1/\\hat{\\sigma}_i$. Select all statements that are correct.\n\nA. Under the assumptions above (independent, unbiased $w_i$ with $\\operatorname{Var}(w_i)=\\sigma_i^2/n_i$), choosing $\\alpha_i \\propto n_i$ minimizes the expected mean squared error $\\mathbb{E}\\!\\left[(w^{new}-w^\\star)^2\\right]$ among all convex combinations.\n\nB. Under the same assumptions, the aggregation rule that minimizes $\\mathbb{E}\\!\\left[(w^{new}-w^\\star)^2\\right]$ among all convex combinations uses weights proportional to $n_i / \\sigma_i^2$. Therefore, both $\\alpha_i \\propto n_i$ and $\\alpha_i \\propto 1/\\hat{\\sigma}_i$ are generally suboptimal when $\\sigma_i^2$ differ across clients.\n\nC. Consider $K=3$ clients with $(n_1,\\sigma_1)=(200,4)$, $(n_2,\\sigma_2)=(200,3)$, and $(n_3,\\sigma_3)=(10,1)$. Under the assumptions above and treating $\\hat{\\sigma}_i=\\sigma_i$, the expected mean squared error of $w^{new}$ is smaller with $\\alpha_i \\propto n_i$ than with $\\alpha_i \\propto 1/\\hat{\\sigma}_i$.\n\nD. If client data distributions are substantially different so that each client’s risk is minimized at a different $w_i^\\star \\neq w_j^\\star$, then weighting by $\\alpha_i \\propto n_i$ aligns aggregation with minimizing global empirical risk across all observed samples, whereas $\\alpha_i \\propto 1/\\hat{\\sigma}_i$ may bias $w^{new}$ toward clients that are less noisy but unrepresentative, potentially harming global generalization.\n\nChoose all that apply.", "solution": "The user wants me to validate the problem statement and, if valid, provide a detailed solution evaluating a set of claims about aggregation weights in Federated Learning.\n\n### Problem Validation\nThe problem statement is valid. It presents a well-defined statistical model for analyzing the aggregation step in Federated Learning.\n- **Givens**:\n    - Global parameter update rule: $w^{new} = \\sum_{i=1}^{K} \\alpha_i w_i$, with $\\sum_{i=1}^{K} \\alpha_i = 1$ and $\\alpha_i \\ge 0$.\n    - Weighting schemes: (1) $\\alpha_i \\propto n_i$, (2) $\\alpha_i \\propto 1/\\hat{\\sigma}_i$.\n    - Modeling assumptions: $w_i$ are independent, unbiased estimators of a true scalar parameter $w^\\star \\in \\mathbb{R}$, with $\\mathbb{E}[w_i] = w^\\star$.\n    - Variance model: $\\operatorname{Var}(w_i) = \\sigma_i^2 / n_i$.\n- **Validation Checklist**:\n    - **Scientifically Grounded**: The model is a standard application of statistical estimation theory (specifically, finding the Best Linear Unbiased Estimator or BLUE) to the context of federated learning. This is a sound and well-established approach.\n    - **Well-Posed**: The core of the problem involves minimizing the mean squared error of a linear combination of estimators, which is a classic, well-posed optimization problem with a unique solution.\n    - **Objective**: The language is precise and the assumptions are clearly stated.\n    - **Completeness**: The provided information is sufficient to derive the optimal weights and evaluate the claims.\n    - **Realism**: While a simplification (scalar parameter, known variance structure), the model captures the essential trade-offs and is not scientifically implausible.\n\nThe problem is valid and permits a rigorous mathematical and qualitative analysis.\n\n### Solution Derivation\n\nThe goal is to analyze the expected mean squared error (MSE) of the aggregated estimator, $\\mathbb{E}\\!\\left[(w^{new}-w^\\star)^2\\right]$, for different choices of weights $\\alpha_i$.\n\nFirst, we determine the bias of $w^{new}$.\n$$\n\\mathbb{E}[w^{new}] = \\mathbb{E}\\left[\\sum_{i=1}^{K} \\alpha_i w_i\\right] = \\sum_{i=1}^{K} \\alpha_i \\mathbb{E}[w_i]\n$$\nGiven that each $w_i$ is an unbiased estimator of $w^\\star$, $\\mathbb{E}[w_i] = w^\\star$.\n$$\n\\mathbb{E}[w^{new}] = \\sum_{i=1}^{K} \\alpha_i w^\\star = w^\\star \\sum_{i=1}^{K} \\alpha_i\n$$\nWith the constraint that the weights form a convex combination, $\\sum_{i=1}^{K} \\alpha_i = 1$, we have:\n$$\n\\mathbb{E}[w^{new}] = w^\\star\n$$\nThis shows that as long as the weights sum to $1$, the aggregated estimator $w^{new}$ is also unbiased.\n\nFor an unbiased estimator, the MSE is equal to its variance:\n$$\n\\mathbb{E}\\!\\left[(w^{new}-w^\\star)^2\\right] = \\mathbb{E}\\!\\left[(w^{new}-\\mathbb{E}[w^{new}])^2\\right] = \\operatorname{Var}(w^{new})\n$$\nNow, we compute the variance of $w^{new}$. Since the $w_i$ are assumed to be independent:\n$$\n\\operatorname{Var}(w^{new}) = \\operatorname{Var}\\left(\\sum_{i=1}^{K} \\alpha_i w_i\\right) = \\sum_{i=1}^{K} \\operatorname{Var}(\\alpha_i w_i) = \\sum_{i=1}^{K} \\alpha_i^2 \\operatorname{Var}(w_i)\n$$\nSubstituting the given model for variance, $\\operatorname{Var}(w_i) = \\sigma_i^2 / n_i$:\n$$\n\\operatorname{Var}(w^{new}) = \\sum_{i=1}^{K} \\alpha_i^2 \\frac{\\sigma_i^2}{n_i}\n$$\nThe problem of finding the best aggregation weights reduces to minimizing this variance subject to the constraint $\\sum_{i=1}^{K} \\alpha_i = 1$. We use the method of Lagrange multipliers. The Lagrangian is:\n$$\nL(\\alpha_1, \\dots, \\alpha_K, \\lambda) = \\sum_{i=1}^{K} \\alpha_i^2 \\frac{\\sigma_i^2}{n_i} - \\lambda \\left(\\sum_{i=1}^{K} \\alpha_i - 1\\right)\n$$\nTaking the partial derivative with respect to $\\alpha_i$ and setting it to zero:\n$$\n\\frac{\\partial L}{\\partial \\alpha_i} = 2 \\alpha_i \\frac{\\sigma_i^2}{n_i} - \\lambda = 0 \\implies \\alpha_i = \\frac{\\lambda}{2} \\frac{n_i}{\\sigma_i^2}\n$$\nThis shows that the optimal weights, $\\alpha_i^{\\text{opt}}$, must be proportional to $\\frac{n_i}{\\sigma_i^2}$. This quantity is the reciprocal of the variance of each estimator, $1/\\operatorname{Var}(w_i)$. To find the constant of proportionality, we use the constraint $\\sum \\alpha_i = 1$:\n$$\n\\sum_{j=1}^{K} \\alpha_j^{\\text{opt}} = \\sum_{j=1}^{K} \\frac{\\frac{\\lambda}{2} \\frac{n_j}{\\sigma_j^2}}{1} = 1 \\implies \\frac{\\lambda}{2} = \\frac{1}{\\sum_{j=1}^{K} \\frac{n_j}{\\sigma_j^2}}\n$$\nTherefore, the optimal weights that minimize the MSE are:\n$$\n\\alpha_i^{\\text{opt}} = \\frac{n_i / \\sigma_i^2}{\\sum_{j=1}^{K} n_j / \\sigma_j^2}\n$$\nThis is a classic result: the minimum-variance unbiased estimator is obtained by weighting each independent unbiased estimator by its inverse variance.\n\n### Option-by-Option Analysis\n\n**A. Under the assumptions above (independent, unbiased $w_i$ with $\\operatorname{Var}(w_i)=\\sigma_i^2/n_i$), choosing $\\alpha_i \\propto n_i$ minimizes the expected mean squared error $\\mathbb{E}\\!\\left[(w^{new}-w^\\star)^2\\right]$ among all convex combinations.**\nThis statement claims that weights proportional to the number of samples, $n_i$, are optimal. Our derivation shows the optimal weights are $\\alpha_i^{\\text{opt}} \\propto n_i / \\sigma_i^2$. The scheme $\\alpha_i \\propto n_i$ is only optimal in the special case where the client-specific noise scale $\\sigma_i^2$ is constant for all clients $i=1, \\dots, K$. Since the problem allows $\\sigma_i^2$ to vary between clients, this claim is not generally true.\n**Verdict: Incorrect.**\n\n**B. Under the same assumptions, the aggregation rule that minimizes $\\mathbb{E}\\!\\left[(w^{new}-w^\\star)^2\\right]$ among all convex combinations uses weights proportional to $n_i / \\sigma_i^2$. Therefore, both $\\alpha_i \\propto n_i$ and $\\alpha_i \\propto 1/\\hat{\\sigma}_i$ are generally suboptimal.**\nThe first part of this statement is a direct match with our derivation of the optimal weights, $\\alpha_i^{\\text{opt}} \\propto n_i / \\sigma_i^2$. The second part evaluates the two proposed schemes against this optimal rule.\n- The scheme $\\alpha_i \\propto n_i$ ignores the a client's noise level $\\sigma_i^2$.\n- The scheme $\\alpha_i \\propto 1/\\hat{\\sigma}_i$ (assuming $\\hat{\\sigma}_i \\approx \\sigma_i$) ignores the client's sample size $n_i$ and is proportional to the inverse standard deviation, not the inverse variance.\nBoth schemes are different from the optimal rule and thus will not, in general, minimize the MSE. They are suboptimal approximations.\n**Verdict: Correct.**\n\n**C. Consider $K=3$ clients with $(n_1,\\sigma_1)=(200,4)$, $(n_2,\\sigma_2)=(200,3)$, and $(n_3,\\sigma_3)=(10,1)$. Under the assumptions above and treating $\\hat{\\sigma}_i=\\sigma_i$, the expected mean squared error of $w^{new}$ is smaller with $\\alpha_i \\propto n_i$ than with $\\alpha_i \\propto 1/\\hat{\\sigma}_i$.**\nWe must calculate the MSE for both schemes using the provided data. The MSE is given by $\\sum_{i=1}^3 \\alpha_i^2 \\operatorname{Var}(w_i)$.\nFirst, calculate the variances:\n- $\\operatorname{Var}(w_1) = \\sigma_1^2 / n_1 = 4^2 / 200 = 16/200 = 0.08$.\n- $\\operatorname{Var}(w_2) = \\sigma_2^2 / n_2 = 3^2 / 200 = 9/200 = 0.045$.\n- $\\operatorname{Var}(w_3) = \\sigma_3^2 / n_3 = 1^2 / 10 = 1/10 = 0.1$.\n\nScheme 1: $\\alpha_i \\propto n_i$. Proportions are based on $(200, 200, 10)$.\n- Total $N = 200+200+10 = 410$.\n- Weights: $\\alpha_1 = 200/410$, $\\alpha_2 = 200/410$, $\\alpha_3 = 10/410$.\n- $MSE_n = \\left(\\frac{200}{410}\\right)^2(0.08) + \\left(\\frac{200}{410}\\right)^2(0.045) + \\left(\\frac{10}{410}\\right)^2(0.1)$\n- $MSE_n = \\frac{1}{410^2} [200^2(0.08) + 200^2(0.045) + 10^2(0.1)] = \\frac{3200 + 1800 + 10}{168100} = \\frac{5010}{168100} \\approx 0.02980$.\n\nScheme 2: $\\alpha_i \\propto 1/\\sigma_i$. Proportions are based on $(1/4, 1/3, 1/1)$.\n- Sum of proportions: $1/4 + 1/3 + 1 = 3/12 + 4/12 + 12/12 = 19/12$.\n- Weights: $\\alpha_1 = \\frac{1/4}{19/12} = \\frac{3}{19}$, $\\alpha_2 = \\frac{1/3}{19/12} = \\frac{4}{19}$, $\\alpha_3 = \\frac{1}{19/12} = \\frac{12}{19}$.\n- $MSE_\\sigma = \\left(\\frac{3}{19}\\right)^2(0.08) + \\left(\\frac{4}{19}\\right)^2(0.045) + \\left(\\frac{12}{19}\\right)^2(0.1)$\n- $MSE_\\sigma = \\frac{1}{19^2} [9(0.08) + 16(0.045) + 144(0.1)] = \\frac{0.72 + 0.72 + 14.4}{361} = \\frac{15.84}{361} \\approx 0.04388$.\n\nComparing the results: $MSE_n \\approx 0.02980 < 0.04388 \\approx MSE_\\sigma$. The claim is correct. This is because client $3$ has a very small sample size ($n_3=10$), making its estimate highly variable ($\\operatorname{Var}(w_3)=0.1$), yet the $1/\\sigma_i$ rule gives it the largest weight ($\\alpha_3 = 12/19 \\approx 63\\%$), which dramatically increases the total error. The $\\alpha_i \\propto n_i$ rule correctly down-weights this unreliable client.\n**Verdict: Correct.**\n\n**D. If client data distributions are substantially different so that each client’s risk is minimized at a different $w_i^\\star \\neq w_j^\\star$, then weighting by $\\alpha_i \\propto n_i$ aligns aggregation with minimizing global empirical risk across all observed samples, whereas $\\alpha_i \\propto 1/\\hat{\\sigma}_i$ may bias $w^{new}$ toward clients that are less noisy but unrepresentative, potentially harming global generalization.**\nThis statement shifts the context from a simple statistical estimation problem with a single $w^\\star$ to the more realistic Federated Learning challenge of non-IID data, where local objectives $L_i(w)$ are minimized at different points $w_i^\\star$.\n- The argument for $\\alpha_i \\propto n_i$: The canonical objective in FL is to minimize the global risk, often defined as a weighted average of local risks: $\\min_w L(w) = \\sum_{i=1}^K \\frac{n_i}{N} L_i(w)$, where $N = \\sum_j n_j$. The FedAvg algorithm, which uses weights $\\alpha_i=n_i/N$, is directly motivated by this formulation. The weighting scheme aligns the aggregation step with the goal of giving more influence to clients that contribute more data to the global objective. This reasoning is sound.\n- The critique of $\\alpha_i \\propto 1/\\hat{\\sigma}_i$: A client's local noise level $\\hat{\\sigma}_i$ may be low because its local data is very homogeneous (e.g., a single digit class in a digit recognition task). Such a client is \"unrepresentative\" of the global data distribution. Its local model $w_i$ will be a poor proxy for the desired global model. Weighting by $1/\\hat{\\sigma}_i$ would give this low-noise, but biased and unrepresentative, client a large weight, pulling the global model $w^{new}$ far from a good global solution and harming its generalization performance. This is a valid and well-known concern in FL.\nBoth parts of the statement represent standard, correct reasoning about the practical implications of these weighting schemes in a non-IID setting.\n**Verdict: Correct.**", "answer": "$$\\boxed{BCD}$$", "id": "3124727"}, {"introduction": "The standard \"one-size-fits-all\" global model can be a poor fit for clients with diverse, non-IID data. This final, code-based practice ([@problem_id:3124737]) guides you through implementing a powerful solution: personalized federated learning through client clustering. You will use the insight that initial gradients reveal underlying client objectives to group similar clients and train a specialized model for each cluster, demonstrating a practical approach to tackling one of FL's biggest challenges.", "problem": "Consider a federated learning setting with $C$ clients, each holding local data sampled independently from a linear model with additive noise. Each client $i$ has $n_i$ samples $\\{(x^{(i)}_t, y^{(i)}_t)\\}_{t=1}^{n_i}$ where $x^{(i)}_t \\in \\mathbb{R}^d$ is drawn i.i.d. from a zero-mean Gaussian distribution with identity covariance, and $y^{(i)}_t = (x^{(i)}_t)^\\top w^*_i + \\epsilon^{(i)}_t$ with $\\epsilon^{(i)}_t \\sim \\mathcal{N}(0, \\sigma^2)$. We train linear models $f_w(x) = x^\\top w$ with the empirical Mean Squared Error (MSE) loss on client $i$ given by\n$$\nL_i(w) = \\frac{1}{n_i} \\sum_{t=1}^{n_i} \\left((x^{(i)}_t)^\\top w - y^{(i)}_t\\right)^2.\n$$\nThe gradient of $L_i(w)$ with respect to $w$ is denoted $g_i(w) = \\nabla_w L_i(w)$. We define cosine similarity between two nonzero gradients $g_i$ and $g_j$ as\n$$\n\\mathrm{cos}(g_i, g_j) = \\frac{g_i^\\top g_j}{\\|g_i\\|_2 \\, \\|g_j\\|_2}.\n$$\nWhen either gradient is the zero vector, define the cosine similarity to be $0$.\n\nYou must implement the following procedure from first principles:\n- Compute each client's gradient at the shared initialization $w_0 = 0$, i.e., $g_i(w_0)$.\n- Cluster clients into connected components using a threshold $\\tau$: create an undirected graph on clients with an edge between $i$ and $j$ if $\\mathrm{cos}(g_i(w_0), g_j(w_0)) \\ge \\tau$, then take graph connected components as clusters.\n- Train two federated systems for $T$ communication rounds using Federated Averaging (FedAvg). In each round, every client performs $E$ steps of batch gradient descent with step size (learning rate) $\\eta$ on its local data starting from the current model it receives from the server. The server aggregates client model deltas by a weighted average proportional to $n_i$.\n    - Single global model: one shared model $w$ updated by aggregating all clients.\n    - Cluster-specific models: one model per cluster; each cluster's model is updated by aggregating only the clients in that cluster.\n- Evaluate the client-mean empirical MSE after training for both systems. For the single global model, every client uses the global $w$; for cluster-specific models, client $i$ uses its cluster's $w$. The evaluation metric is the arithmetic mean of per-client empirical MSE:\n$$\n\\overline{L}_\\mathrm{global} = \\frac{1}{C} \\sum_{i=1}^{C} L_i(w_\\mathrm{global}), \\quad\n\\overline{L}_\\mathrm{cluster} = \\frac{1}{C} \\sum_{i=1}^{C} L_i(w_{\\mathrm{cluster}(i)}).\n$$\nCompute the relative improvement as the decimal\n$$\n\\Delta = \\frac{\\overline{L}_\\mathrm{global} - \\overline{L}_\\mathrm{cluster}}{\\overline{L}_\\mathrm{global}}.\n$$\nReport $\\Delta$ for each test case.\n\nFundamental base to be used:\n- Empirical risk minimization definition for $L_i(w)$.\n- Gradient descent update $w \\leftarrow w - \\eta \\, g_i(w)$.\n- Weighted averaging for aggregating client updates proportional to $n_i$.\n- Cosine similarity definition for clustering by gradient directions.\n\nImplement a complete, runnable program that:\n- Simulates data as specified.\n- Computes initial gradients.\n- Forms clusters by thresholded cosine similarity and connected components.\n- Trains with Federated Averaging for both the single global model and cluster-specific models.\n- Evaluates and outputs the relative improvement $\\Delta$ for each test case.\n\nTest suite and parameters:\n- Test Case $1$ (happy path, two opposing clusters):\n    - Random seed $42$, $C = 8$, $d = 5$, client sample sizes $n_i = 200$ for all $i$, noise standard deviation $\\sigma = 0.1$.\n    - Ground-truth vectors: $w^*_1 = [1, 0, 0, 0, 0]^\\top$ for clients $1$ to $4$, and $w^*_2 = [-1, 0, 0, 0, 0]^\\top$ for clients $5$ to $8$.\n    - Clustering threshold $\\tau = 0.7$.\n    - FedAvg hyperparameters: $T = 15$, $E = 5$, $\\eta = 0.05$.\n- Test Case $2$ (no improvement expected, homogeneous clients):\n    - Random seed $123$, $C = 8$, $d = 5$, client sample sizes $n_i = 200$ for all $i$, noise standard deviation $\\sigma = 0.1$.\n    - Ground-truth vectors: $w^*_i = [1, 1, 0, 0, 0]^\\top$ for all clients $i$.\n    - Clustering threshold $\\tau = 0.7$.\n    - FedAvg hyperparameters: $T = 15$, $E = 5$, $\\eta = 0.05$.\n- Test Case $3$ (boundary clustering with $\\tau = 1.0$, singleton clusters):\n    - Random seed $7$, $C = 2$, $d = 3$, client sample sizes $n_1 = 300$, $n_2 = 300$, noise standard deviation $\\sigma = 0.1$.\n    - Ground-truth vectors: $w^*_1 = [1, 0, 0]^\\top$, $w^*_2 = [0, 1, 0]^\\top$.\n    - Clustering threshold $\\tau = 1.0$.\n    - FedAvg hyperparameters: $T = 20$, $E = 5$, $\\eta = 0.05$.\n- Test Case $4$ (noisy edge case, potential clustering ambiguity):\n    - Random seed $99$, $C = 6$, $d = 4$, client sample sizes $n_i = 50$ for all $i$, noise standard deviation $\\sigma = 0.5$.\n    - Ground-truth vectors: $w^*_1 = [1, 0, 0, 0]^\\top$ for clients $1$ to $3$, and $w^*_2 = [0, 1, 0, 0]^\\top$ for clients $4$ to $6$.\n    - Clustering threshold $\\tau = 0.5$.\n    - FedAvg hyperparameters: $T = 25$, $E = 5$, $\\eta = 0.05$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with the entries ordered by the four test cases described above, for example, $\\texttt{[r_1,r_2,r_3,r_4]}$ where each $r_k$ is the decimal relative improvement for Test Case $k$.", "solution": "The problem is deemed valid after a thorough review. It is scientifically grounded in the principles of federated learning, linear regression, and graph theory. It is well-posed, with all necessary parameters and conditions specified, ensuring a unique and reproducible outcome for each test case via fixed random seeds. The problem statement is objective and free of ambiguity or contradiction.\n\n### Theoretical Formulation\n\nThe core of this problem lies in addressing client heterogeneity in federated learning. When clients have different underlying data distributions or objectives, a single global model can be suboptimal for everyone. The proposed solution is to cluster clients based on their objectives and train a personalized model for each cluster.\n\n**1. Client Loss and Gradient**\nEach client $i$ seeks to minimize its local empirical Mean Squared Error (MSE) loss, given by:\n$$\nL_i(w) = \\frac{1}{n_i} \\sum_{t=1}^{n_i} \\left((x^{(i)}_t)^\\top w - y^{(i)}_t\\right)^2\n$$\nwhere $w \\in \\mathbb{R}^d$ is the model parameter vector. This is a convex optimization problem. The gradient of this loss function with respect to $w$, used for gradient descent, is:\n$$\ng_i(w) = \\nabla_w L_i(w) = \\frac{2}{n_i} \\sum_{t=1}^{n_i} \\left((x^{(i)}_t)^\\top w - y^{(i)}_t\\right)x^{(i)}_t\n$$\nIn matrix notation, with $X_i$ being the $n_i \\times d$ data matrix and $Y_i$ the $n_i \\times 1$ label vector, the gradient is:\n$$\ng_i(w) = \\frac{2}{n_i} X_i^\\top (X_i w - Y_i)\n$$\n\n**2. Gradient-Based Clustering Rationale**\nThe clustering heuristic is based on the initial gradients calculated at a shared starting point, $w_0 = 0$. At this initialization, the gradient for client $i$ simplifies to:\n$$\ng_i(w_0) = g_i(0) = -\\frac{2}{n_i} X_i^\\top Y_i\n$$\nSubstituting the true data-generating process, $y^{(i)}_t = (x^{(i)}_t)^\\top w^*_i + \\epsilon^{(i)}_t$, we get:\n$$\ng_i(0) = -\\frac{2}{n_i} \\sum_{t=1}^{n_i} x^{(i)}_t \\left((x^{(i)}_t)^\\top w^*_i + \\epsilon^{(i)}_t\\right) = -\\frac{2}{n_i} \\left( \\left(\\sum_{t=1}^{n_i} x^{(i)}_t (x^{(i)}_t)^\\top \\right) w^*_i + \\sum_{t=1}^{n_i} x^{(i)}_t \\epsilon^{(i)}_t \\right)\n$$\nBy the law of large numbers, for a sufficiently large number of samples $n_i$, the sample covariance matrix $\\frac{1}{n_i}\\sum_{t=1}^{n_i} x^{(i)}_t (x^{(i)}_t)^\\top$ approaches the true covariance matrix, which is the identity matrix $I_d$ since $x^{(i)}_t \\sim \\mathcal{N}(0, I_d)$. The noise term $\\frac{1}{n_i}\\sum_{t=1}^{n_i} x^{(i)}_t \\epsilon^{(i)}_t$ approaches its expectation, which is $E[x \\epsilon] = E[x]E[\\epsilon] = 0$. Therefore, we have the approximation:\n$$\ng_i(0) \\approx -2 (I_d w^*_i) = -2w^*_i\n$$\nThis reveals a critical insight: the initial gradient vector at the origin is approximately proportional to the negative of the client's true optimal parameter vector $w^*_i$. Consequently, the cosine similarity between the initial gradients of two clients, $i$ and $j$, approximates the cosine similarity of their true parameter vectors:\n$$\n\\mathrm{cos}(g_i(0), g_j(0)) \\approx \\mathrm{cos}(-2w^*_i, -2w^*_j) = \\mathrm{cos}(w^*_i, w^*_j)\n$$\nThus, clustering clients based on the cosine similarity of their initial gradients is a sound heuristic for grouping clients with similar underlying objectives ($w^*_i$).\n\n### Algorithmic Procedure\n\nThe solution is implemented by following the specified procedure from first principles.\n\n**1. Data Simulation**\nFor each client $i \\in \\{1, \\dots, C\\}$, we generate a local dataset.\n-   The feature vectors $\\{x^{(i)}_t\\}_{t=1}^{n_i}$ are drawn from $\\mathcal{N}(0, I_d)$.\n-   The labels $\\{y^{(i)}_t\\}_{t=1}^{n_i}$ are computed as $y^{(i)}_t = (x^{(i)}_t)^\\top w^*_i + \\epsilon^{(i)}_t$, where the noise terms $\\{\\epsilon^{(i)}_t\\}_{t=1}^{n_i}$ are drawn from $\\mathcal{N}(0, \\sigma^2)$.\nThe random seed is set for each test case to ensure reproducibility.\n\n**2. Client Clustering**\n-   Initialize the model parameters to the zero vector, $w_0 = 0$.\n-   For each client $i$, compute the initial gradient $g_i(w_0)$ using the formula derived above.\n-   Construct an undirected graph with $C$ vertices, representing the clients. An edge is placed between client $i$ and client $j$ if and only if their initial gradients are non-zero and their cosine similarity meets or exceeds the threshold $\\tau$:\n    $$\n    \\frac{g_i(w_0)^\\top g_j(w_0)}{\\|g_i(w_0)\\|_2 \\, \\|g_j(w_0)\\|_2} \\ge \\tau\n    $$\n    If either gradient is the zero vector, the similarity is defined as $0$ and no edge is created (unless $\\tau \\le 0$).\n-   The clusters are determined by finding the connected components of this graph. This is achieved by building an adjacency matrix and using the `scipy.sparse.csgraph.connected_components` function, which efficiently partitions the graph's vertices.\n\n**3. Federated Averaging (FedAvg) Training**\nWe simulate two separate training systems for $T$ communication rounds.\n\n-   **Single Global Model:** A single server manages one model, $w_{\\mathrm{global}}$, for all $C$ clients.\n    -   In each round, the server distributes $w_{\\mathrm{global}}$ to all clients.\n    -   Each client $i$ performs $E$ steps of local batch gradient descent, starting from $w_{\\mathrm{global}}$, using its local data and a learning rate $\\eta$.\n    -   The server aggregates the resulting updated local models into a new global model using a weighted average, where weights are proportional to client sample sizes $n_i$:\n        $$ w_{\\mathrm{global}} \\leftarrow \\frac{\\sum_{i=1}^C n_i w_i}{\\sum_{i=1}^C n_i} $$\n\n-   **Cluster-Specific Models:** For each identified cluster, an independent instance of FedAvg is run.\n    -   Each cluster has its own server and model, $w_{\\mathrm{cluster}(k)}$.\n    -   Training proceeds as with the global model, but aggregation for cluster $k$ only involves the clients belonging to that cluster. All models are initialized to $w_0 = 0$.\n\n**4. Evaluation**\nAfter $T$ rounds of training, the performance of both systems is evaluated.\n-   The client-mean empirical MSE for the global model, $\\overline{L}_\\mathrm{global}$, is calculated by averaging the final loss $L_i(w_\\mathrm{global})$ over all $C$ clients.\n-   The client-mean empirical MSE for the clustered system, $\\overline{L}_\\mathrm{cluster}$, is similarly calculated. For each client $i$, the loss $L_i(w_{\\mathrm{cluster}(i)})$ is computed using the final model of the cluster to which client $i$ belongs.\n-   The relative improvement $\\Delta$ is then computed as:\n    $$\n    \\Delta = \\frac{\\overline{L}_\\mathrm{global} - \\overline{L}_\\mathrm{cluster}}{\\overline{L}_\\mathrm{global}}\n    $$\nThis metric quantifies the performance gain achieved by clustering. A positive value indicates that the clustered approach yielded a lower average client loss.", "answer": "```python\nimport numpy as np\nfrom scipy.sparse import csr_matrix\nfrom scipy.sparse.csgraph import connected_components\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        {\n            \"seed\": 42, \"C\": 8, \"d\": 5, \"n_i\": [200] * 8, \"sigma\": 0.1,\n            \"w_star\": [np.array([1., 0, 0, 0, 0])] * 4 + [np.array([-1., 0, 0, 0, 0])] * 4,\n            \"tau\": 0.7, \"T\": 15, \"E\": 5, \"eta\": 0.05\n        },\n        {\n            \"seed\": 123, \"C\": 8, \"d\": 5, \"n_i\": [200] * 8, \"sigma\": 0.1,\n            \"w_star\": [np.array([1., 1, 0, 0, 0])] * 8,\n            \"tau\": 0.7, \"T\": 15, \"E\": 5, \"eta\": 0.05\n        },\n        {\n            \"seed\": 7, \"C\": 2, \"d\": 3, \"n_i\": [300, 300], \"sigma\": 0.1,\n            \"w_star\": [np.array([1., 0, 0]), np.array([0., 1, 0])],\n            \"tau\": 1.0, \"T\": 20, \"E\": 5, \"eta\": 0.05\n        },\n        {\n            \"seed\": 99, \"C\": 6, \"d\": 4, \"n_i\": [50] * 6, \"sigma\": 0.5,\n            \"w_star\": [np.array([1., 0, 0, 0])] * 3 + [np.array([0., 1, 0, 0])] * 3,\n            \"tau\": 0.5, \"T\": 25, \"E\": 5, \"eta\": 0.05\n        }\n    ]\n\n    results = []\n    for params in test_cases:\n        result = run_simulation(params)\n        results.append(result)\n\n    # Format output as [r1,r2,r3,r4] with 8 decimal places.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\ndef generate_data(C, d, n_i, w_star, sigma, rng):\n    \"\"\"Generates client data based on the problem specification.\"\"\"\n    client_data = []\n    for i in range(C):\n        n = n_i[i]\n        X = rng.normal(0, 1, size=(n, d))\n        epsilon = rng.normal(0, sigma, size=n)\n        y = X @ w_star[i] + epsilon\n        client_data.append({'X': X, 'y': y})\n    return client_data\n\ndef compute_gradient(client_data, w):\n    \"\"\"Computes the gradient of the MSE loss for a single client.\"\"\"\n    X, y = client_data['X'], client_data['y']\n    n = len(y)\n    if n == 0:\n        return np.zeros_like(w)\n    grad = 2/n * X.T @ (X @ w - y)\n    return grad\n\ndef find_clusters(initial_gradients, tau, C):\n    \"\"\"Forms clusters based on cosine similarity of initial gradients.\"\"\"\n    adj_matrix = np.zeros((C, C))\n    for i in range(C):\n        for j in range(i + 1, C):\n            g_i = initial_gradients[i]\n            g_j = initial_gradients[j]\n            norm_i = np.linalg.norm(g_i)\n            norm_j = np.linalg.norm(g_j)\n            \n            cosine_sim = 0.0\n            if norm_i > 0 and norm_j > 0:\n                cosine_sim = np.dot(g_i, g_j) / (norm_i * norm_j)\n            \n            if cosine_sim >= tau:\n                adj_matrix[i, j] = adj_matrix[j, i] = 1\n\n    graph = csr_matrix(adj_matrix)\n    n_components, labels = connected_components(\n        csgraph=graph, directed=False, return_labels=True\n    )\n    \n    clusters = [[] for _ in range(n_components)]\n    for client_idx, label in enumerate(labels):\n        clusters[label].append(client_idx)\n        \n    return clusters\n\ndef train_fedavg(client_data, client_indices, T, E, eta, d, n_i_all):\n    \"\"\"Runs the Federated Averaging algorithm for a given set of clients.\"\"\"\n    if not client_indices:\n        return np.zeros(d)\n        \n    w_server = np.zeros(d)\n    \n    sub_n_i = [n_i_all[i] for i in client_indices]\n    total_data_in_group = sum(sub_n_i)\n    \n    for _ in range(T):\n        local_models = []\n        for client_idx in client_indices:\n            w_local = w_server.copy()\n            data = client_data[client_idx]\n            for _ in range(E):\n                grad = compute_gradient(data, w_local)\n                w_local -= eta * grad\n            local_models.append(w_local)\n            \n        # Weighted aggregation\n        w_server = np.zeros(d)\n        for i, client_idx in enumerate(client_indices):\n            weight = n_i_all[client_idx] / total_data_in_group\n            w_server += weight * local_models[i]\n            \n    return w_server\n\ndef compute_loss(client_data, w):\n    \"\"\"Computes the empirical MSE loss.\"\"\"\n    X, y = client_data['X'], client_data['y']\n    n = len(y)\n    if n == 0:\n        return 0.0\n    error = X @ w - y\n    loss = np.mean(error**2)\n    return loss\n\ndef run_simulation(params):\n    \"\"\"Executes the full simulation for a single test case.\"\"\"\n    seed = params[\"seed\"]\n    C, d, n_i, sigma = params[\"C\"], params[\"d\"], params[\"n_i\"], params[\"sigma\"]\n    w_star, tau = params[\"w_star\"], params[\"tau\"]\n    T, E, eta = params[\"T\"], params[\"E\"], params[\"eta\"]\n\n    rng = np.random.default_rng(seed)\n    \n    # 1. Simulate data\n    all_client_data = generate_data(C, d, n_i, w_star, sigma, rng)\n\n    # 2. Compute initial gradients\n    w0 = np.zeros(d)\n    initial_gradients = [compute_gradient(all_client_data[i], w0) for i in range(C)]\n    \n    # 3. Form clusters\n    clusters = find_clusters(initial_gradients, tau, C)\n    client_to_cluster_map = {client: i for i, cluster in enumerate(clusters) for client in cluster}\n\n    # 4a. Train global model\n    all_clients = list(range(C))\n    w_global = train_fedavg(all_client_data, all_clients, T, E, eta, d, n_i)\n    \n    # 4b. Train cluster models\n    cluster_models = []\n    for cluster in clusters:\n        w_cluster = train_fedavg(all_client_data, cluster, T, E, eta, d, n_i)\n        cluster_models.append(w_cluster)\n\n    # 5. Evaluate final losses\n    total_loss_global = 0.0\n    for i in range(C):\n        total_loss_global += compute_loss(all_client_data[i], w_global)\n    mean_loss_global = total_loss_global / C\n\n    total_loss_cluster = 0.0\n    for i in range(C):\n        cluster_idx = client_to_cluster_map[i]\n        w_c = cluster_models[cluster_idx]\n        total_loss_cluster += compute_loss(all_client_data[i], w_c)\n    mean_loss_cluster = total_loss_cluster / C\n\n    # 6. Compute relative improvement\n    if mean_loss_global == 0:\n        # If global loss is zero, improvement is undefined unless cluster loss is also zero.\n        # This is highly unlikely with noise.\n        # A zero global loss implies a perfect model.\n        delta = 0.0 if mean_loss_cluster == 0.0 else -np.inf\n    else:\n        delta = (mean_loss_global - mean_loss_cluster) / mean_loss_global\n        \n    return delta\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3124737"}]}