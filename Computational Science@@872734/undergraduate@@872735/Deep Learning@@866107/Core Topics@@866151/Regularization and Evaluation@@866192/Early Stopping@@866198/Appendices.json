{"hands_on_practices": [{"introduction": "Early stopping is one of several techniques to select the best model during a training run. This exercise [@problem_id:3119093] sets up a controlled simulation to directly compare the classic validation-based early stopping with another popular method, checkpoint averaging. By implementing both within a simplified linear regression framework, you will gain a practical understanding of how different model selection strategies impact the generalization gap—the crucial difference between a model's performance on seen and unseen data.", "problem": "You are asked to implement and analyze two model selection strategies within a controlled deep learning simulation that uses a one-dimensional linear regression surrogate to mimic training dynamics and generalization behavior. The comparison metric is the expected generalization gap across random seeds, defined as the expectation of the difference between test loss and training loss at the selected model parameters. Your program must be a complete, runnable program.\n\nFundamental base and setup:\n- Consider a data-generating process where inputs $x$ are sampled independently from a standard normal distribution $x \\sim \\mathcal{N}(0,1)$, and outputs $y$ are generated by $y = \\theta^\\ast x + \\epsilon$, where the noise $\\epsilon \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2)$ is independent of $x$. The parameter $\\theta^\\ast$ is the true data-generating coefficient.\n- The training procedure is Empirical Risk Minimization (ERM) using batch Gradient Descent (GD) to minimize the Mean Squared Error (MSE) loss. For a parameter $\\theta$ and dataset $\\{(x_i, y_i)\\}_{i=1}^n$, the empirical loss is $L(\\theta) = \\frac{1}{n}\\sum_{i=1}^n (y_i - \\theta x_i)^2$. The gradient with respect to $\\theta$ is $\\nabla_\\theta L(\\theta) = \\frac{2}{n}\\sum_{i=1}^n x_i(\\theta x_i - y_i)$.\n- The GD update rule at epoch $t$ is $\\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta L(\\theta_t)$, where $\\eta$ is the learning rate and the initialization is $\\theta_0 = 0$.\n- Define the generalization gap at parameter $\\theta$ as $G(\\theta) = L_{test}(\\theta) - L_{train}(\\theta)$, where $L_{train}$ and $L_{test}$ are the empirical MSE computed on the training and test sets, respectively.\n- The expectation across seeds is the average over independent draws of datasets and noise controlled by a list of random seeds. For a selection rule that yields a parameter $\\theta_{sel}^{(s)}$ per seed $s$, the expected generalization gap is $\\mathbb{E}_s\\big[G(\\theta_{sel}^{(s)})\\big]$, approximated by the arithmetic mean over the given seeds.\n\nModel selection strategies to compare:\n1. Early Stopping (ES): Use a separate validation set to monitor the validation loss $L_{val}(\\theta_t)$ per epoch. Maintain the best validation loss seen so far and its epoch. If the validation loss does not strictly improve for $p$ consecutive epochs (the patience), stop selection and choose the parameter at the best epoch encountered before stopping. Formally, scan epochs $t=0,1,\\dots$; whenever $L_{val}(\\theta_t) < \\min_{u \\le t-1} L_{val}(\\theta_u)$, record $t$ as the new best epoch and reset a counter of non-improving epochs. Otherwise, increment the counter; if it exceeds $p$, terminate and select the last recorded best epoch. Compute the generalization gap $G(\\theta_{ES})$ for the selected parameter $\\theta_{ES}$.\n2. Checkpoint Averaging (CA): Train for a fixed total of $E$ epochs. Let the last $k$ parameters be $\\theta_{E-k+1}, \\dots, \\theta_E$. Define the averaged parameter as $\\bar{\\theta} = \\frac{1}{k}\\sum_{u=E-k+1}^E \\theta_u$. Compute the generalization gap $G(\\bar{\\theta})$.\n\nSimulation protocol per seed $s$:\n- Generate independent training, validation, and test datasets according to the given $n_{train}$, $n_{val}$, and $n_{test}$ using the seed $s$.\n- Perform batch GD for $E$ epochs using the training set, store $\\theta_t$ for each epoch $t$.\n- Compute $L_{train}(\\theta_t)$, $L_{val}(\\theta_t)$, and $L_{test}(\\theta_t)$ for each epoch $t$.\n- Apply ES to select $\\theta_{ES}$ and compute $G(\\theta_{ES})$.\n- Apply CA to compute $\\bar{\\theta}$ and $G(\\bar{\\theta})$.\n- Repeat across all seeds in the case and compute the mean of $G(\\theta_{ES})$ and the mean of $G(\\bar{\\theta})$.\n\nTest suite:\nImplement the above simulation for the following parameter sets. In all cases, the loss is dimensionless, and the final outputs must be floats. Round final outputs to $6$ decimal places.\n\n- Case $1$ (happy path):\n  - True parameter $\\theta^\\ast = 1.5$\n  - Training size $n_{train} = 50$\n  - Validation size $n_{val} = 100$\n  - Test size $n_{test} = 10000$\n  - Learning rate $\\eta = 0.05$\n  - Total epochs $E = 120$\n  - Patience $p = 5$\n  - Averaging window $k = 10$\n  - Noise standard deviation $\\sigma_\\epsilon = 0.5$\n  - Seeds: integers from $0$ to $19$ inclusive\n- Case $2$ (boundary: minimal patience, no averaging):\n  - True parameter $\\theta^\\ast = 1.5$\n  - Training size $n_{train} = 50$\n  - Validation size $n_{val} = 100$\n  - Test size $n_{test} = 10000$\n  - Learning rate $\\eta = 0.05$\n  - Total epochs $E = 120$\n  - Patience $p = 0$\n  - Averaging window $k = 1$\n  - Noise standard deviation $\\sigma_\\epsilon = 0.5$\n  - Seeds: integers from $20$ to $39$ inclusive\n- Case $3$ (boundary: average all checkpoints, low noise, larger data):\n  - True parameter $\\theta^\\ast = 1.5$\n  - Training size $n_{train} = 400$\n  - Validation size $n_{val} = 400$\n  - Test size $n_{test} = 10000$\n  - Learning rate $\\eta = 0.02$\n  - Total epochs $E = 200$\n  - Patience $p = 10$\n  - Averaging window $k = 200$\n  - Noise standard deviation $\\sigma_\\epsilon = 0.1$\n  - Seeds: integers from $40$ to $59$ inclusive\n- Case $4$ (edge: high noise, small data, different true parameter):\n  - True parameter $\\theta^\\ast = -0.8$\n  - Training size $n_{train} = 20$\n  - Validation size $n_{val} = 40$\n  - Test size $n_{test} = 10000$\n  - Learning rate $\\eta = 0.03$\n  - Total epochs $E = 150$\n  - Patience $p = 3$\n  - Averaging window $k = 20$\n  - Noise standard deviation $\\sigma_\\epsilon = 1.2$\n  - Seeds: integers from $60$ to $79$ inclusive\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one case and is itself a two-element list containing the expected generalization gap for Early Stopping and Checkpoint Averaging, respectively, both rounded to $6$ decimal places. For example, the shape must be like $\\big[ [g_{ES}^{(1)}, g_{CA}^{(1)}], [g_{ES}^{(2)}, g_{CA}^{(2)}], [g_{ES}^{(3)}, g_{CA}^{(3)}], [g_{ES}^{(4)}, g_{CA}^{(4)}] \\big]$.", "solution": "The problem statement is valid. It presents a well-posed, scientifically grounded, and objective simulation task relevant to the field of machine learning. The task involves comparing two common model selection strategies, Early Stopping (ES) and Checkpoint Averaging (CA), within a controlled one-dimensional linear regression setting. All parameters, procedures, and definitions are provided with sufficient clarity and without contradiction, enabling a unique and meaningful numerical solution.\n\nThe solution proceeds by first laying out the theoretical framework and then detailing the algorithmic implementation.\n\n### Theoretical Framework\n\n1.  **Data Generation and Model:** The problem is set in the context of a simple linear model. The data-generating process is defined by $y = \\theta^\\ast x + \\epsilon$, where inputs $x$ are drawn from a standard normal distribution, $x \\sim \\mathcal{N}(0,1)$, and the noise term $\\epsilon$ is also normally distributed, $\\epsilon \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2)$. The goal is to estimate the true parameter $\\theta^\\ast$ using a model $\\hat{y} = \\theta x$.\n\n2.  **Optimization:** The parameter $\\theta$ is optimized by minimizing the Mean Squared Error (MSE) on a training set $\\{(x_i, y_i)\\}_{i=1}^{n_{train}}$. The empirical loss function is $L_{train}(\\theta) = \\frac{1}{n_{train}}\\sum_{i=1}^{n_{train}} (y_i - \\theta x_i)^2$. The optimization method is batch Gradient Descent (GD), which iteratively updates the parameter according to the rule:\n    $$\n    \\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta L_{train}(\\theta_t)\n    $$\n    where $\\theta_0 = 0$ is the initialization, $\\eta$ is the learning rate, and $t$ is the epoch index. The gradient of the loss is:\n    $$\n    \\nabla_\\theta L_{train}(\\theta) = \\frac{2}{n_{train}}\\sum_{i=1}^{n_{train}} x_i(\\theta x_i - y_i)\n    $$\n    For a given training set, this process generates a deterministic trajectory of parameters $\\{\\theta_0, \\theta_1, \\dots, \\theta_E\\}$. The randomness in the simulation arises from the sampling of the datasets for each specified random seed.\n\n3.  **Generalization Gap:** The central metric for evaluation is the generalization gap, defined as the difference between the model's performance on unseen test data and its performance on the training data:\n    $$\n    G(\\theta) = L_{test}(\\theta) - L_{train}(\\theta)\n    $$\n    A large positive gap is a hallmark of overfitting, where the model has learned idiosyncrasies of the training set that do not generalize to the broader data distribution. The final comparison metric is the expected generalization gap, $\\mathbb{E}_s[G(\\theta_{sel})]$, approximated by averaging the gap over multiple independent simulations (seeds).\n\n4.  **Model Selection Strategies:**\n    *   **Early Stopping (ES):** This technique acts as a form of regularization by preventing the model from training for too long and overfitting. It works by monitoring the loss on a separate validation set, $L_{val}(\\theta_t)$. Training is virtually halted when the validation loss fails to show strict improvement for a specified number of epochs, known as patience ($p$). The parameter selected is not the one at which training stopped, but the one from the epoch that yielded the best (minimum) validation loss observed during the process. This strategy directly aims to select a model with good generalization performance, as proxied by the validation set.\n    *   **Checkpoint Averaging (CA):** This method involves training for a fixed number of epochs ($E$) and then averaging the parameters from the last $k$ epochs. The averaged parameter is $\\bar{\\theta} = \\frac{1}{k}\\sum_{u=E-k+1}^E \\theta_u$. The intuition behind this approach, related to Polyak-Ruppert averaging, is that the average of parameters over a portion of the optimization trajectory can lead to a more stable solution residing in a wider, flatter region of the loss landscape, which is often correlated with better generalization.\n\n### Algorithmic Implementation\n\nThe solution is implemented by a program that executes the simulation for each of the four specified cases.\n\n1.  **Main Loop:** The program iterates through each parameter case. For each case, it runs a series of simulations, one for each seed in the specified range.\n\n2.  **Per-Seed Simulation:** For a given seed $s$:\n    a.  **Data Generation:** A new random number generator is seeded with $s$. Independent training, validation, and test datasets of sizes $n_{train}$, $n_{val}$, and $n_{test}$ are generated according to the process $x \\sim \\mathcal{N}(0,1)$ and $y = \\theta^\\ast x + \\epsilon$, with $\\epsilon \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2)$.\n    b.  **Gradient Descent:** The GD algorithm is run for $E$ epochs, starting from $\\theta_0=0$. All intermediate parameters, $\\theta_0, \\theta_1, \\dots, \\theta_E$, are stored. The gradient calculation is vectorized for efficiency.\n    c.  **Loss Evaluation:** For each stored parameter $\\theta_t$, the MSE is computed on the training, validation, and test sets, yielding trajectories $L_{train}(\\theta_t)$, $L_{val}(\\theta_t)$, and $L_{test}(\\theta_t)$.\n    d.  **Early Stopping Selection:** The stored validation losses $L_{val}(\\theta_t)$ are scanned from $t=0$ to $E$. The epoch $t_{best}$ corresponding to the minimum validation loss seen so far is tracked. A patience counter is incremented for each epoch that does not yield a new strictly lower validation loss; it is reset upon improvement. If the counter exceeds the patience parameter $p$, the scan is terminated. The selected parameter is $\\theta_{ES} = \\theta_{t_{best}}$. The generalization gap $G(\\theta_{ES})$ is then calculated.\n    e.  **Checkpoint Averaging Selection:** The parameter $\\bar{\\theta}$ is computed by averaging the last $k$ parameters of the training trajectory, $\\{\\theta_{E-k+1}, \\dots, \\theta_E\\}$. The generalization gap $G(\\bar{\\theta})$ is then calculated.\n\n3.  **Averaging and Output:** After completing the simulations for all seeds in a case, the collected generalization gaps for ES and CA are separately averaged. These two mean values form the result for the case. The final program output collates the results from all four cases into the specified list-of-lists format, with each numerical value rounded to six decimal places.", "answer": "```python\nimport numpy as np\n\ndef mse(theta, x, y):\n    \"\"\"\n    Calculates the Mean Squared Error for a 1D linear model.\n    \"\"\"\n    if y.size == 0:\n        return 0.0\n    return np.mean((y - theta * x)**2)\n\ndef run_simulation_for_case(params):\n    \"\"\"\n    Runs the full simulation for one set of parameters.\n    \"\"\"\n    theta_star, n_train, n_val, n_test, eta, E, p, k, sigma_eps, seeds = params\n\n    es_gaps = []\n    ca_gaps = []\n\n    for seed in seeds:\n        rng = np.random.default_rng(seed)\n        \n        # 1. Data Generation\n        x_train = rng.standard_normal(n_train)\n        eps_train = rng.standard_normal(n_train) * sigma_eps\n        y_train = theta_star * x_train + eps_train\n        \n        x_val = rng.standard_normal(n_val)\n        eps_val = rng.standard_normal(n_val) * sigma_eps\n        y_val = theta_star * x_val + eps_val\n\n        x_test = rng.standard_normal(n_test)\n        eps_test = rng.standard_normal(n_test) * sigma_eps\n        y_test = theta_star * x_test + eps_test\n\n        # 2. Training (Batch Gradient Descent)\n        thetas = np.zeros(E + 1)\n        theta_t = 0.0\n        \n        mean_x_sq_train = np.mean(x_train**2)\n        mean_xy_train = np.mean(x_train * y_train)\n\n        for t in range(E):\n            grad = 2 * (theta_t * mean_x_sq_train - mean_xy_train)\n            theta_t = theta_t - eta * grad\n            thetas[t + 1] = theta_t\n\n        # 3. Loss Calculation\n        train_losses = np.array([mse(th, x_train, y_train) for th in thetas])\n        val_losses = np.array([mse(th, x_val, y_val) for th in thetas])\n        test_losses = np.array([mse(th, x_test, y_test) for th in thetas])\n\n        # 4. Early Stopping (ES)\n        best_val_loss = float('inf')\n        best_epoch = 0\n        patience_counter = 0\n\n        for t in range(E + 1):\n             current_val_loss = val_losses[t]\n             if current_val_loss < best_val_loss:\n                 best_val_loss = current_val_loss\n                 best_epoch = t\n                 patience_counter = 0\n             else:\n                 patience_counter += 1\n            \n             if patience_counter > p:\n                 break\n        \n        theta_es = thetas[best_epoch]\n        es_gap = test_losses[best_epoch] - train_losses[best_epoch]\n        es_gaps.append(es_gap)\n\n        # 5. Checkpoint Averaging (CA)\n        theta_ca_list = thetas[E - k + 1 : E + 1]\n        theta_ca = np.mean(theta_ca_list)\n        ca_gap = mse(theta_ca, x_test, y_test) - mse(theta_ca, x_train, y_train)\n        ca_gaps.append(ca_gap)\n\n    return [round(np.mean(es_gaps), 6), round(np.mean(ca_gaps), 6)]\n\ndef solve():\n    \"\"\"\n    Defines the test cases and formats the final output.\n    \"\"\"\n    case1 = (1.5, 50, 100, 10000, 0.05, 120, 5, 10, 0.5, range(0, 20))\n    case2 = (1.5, 50, 100, 10000, 0.05, 120, 0, 1, 0.5, range(20, 40))\n    case3 = (1.5, 400, 400, 10000, 0.02, 200, 10, 200, 0.1, range(40, 60))\n    case4 = (-0.8, 20, 40, 10000, 0.03, 150, 3, 20, 1.2, range(60, 80))\n    \n    test_cases = [case1, case2, case3, case4]\n\n    results = []\n    for case in test_cases:\n        result = run_simulation_for_case(case)\n        results.append(result)\n        \n    final_output_str = str(results).replace(\" \", \"\")\n    print(final_output_str)\n\nsolve()\n```", "id": "3119093"}, {"introduction": "While a simple patience counter is intuitive, its effectiveness can be hampered by noisy validation loss measurements. This practice [@problem_id:3119056] introduces a more principled approach by reframing early stopping as a statistical change-point detection problem. By implementing the Cumulative Sum (CUSUM) algorithm on the epoch-to-epoch changes in validation loss, you will learn to formally detect when the training process shifts from a regime of steady improvement to one of stagnation or overfitting, providing a more robust trigger for stopping.", "problem": "You are tasked with implementing a principled early stopping mechanism using Cumulative Sum (CUSUM) change-point detection on validation loss residuals. You must derive the detector from core statistical definitions and then implement it as a complete, runnable program that processes a fixed test suite and outputs the results in the specified format. The context is as follows.\n\nGiven a sequence of validation losses $\\{L_{\\text{val}}(t)\\}_{t=1}^{T}$, define the residuals by the first difference $r_t = L_{\\text{val}}(t) - L_{\\text{val}}(t-1)$ for $t \\in \\{2,\\dots,T\\}$. Interpret $r_t$ as the epoch-to-epoch change in validation loss. Assume that in the initial “in-control” regime (when the model is genuinely improving), the residuals are independent and identically distributed with mean $\\mu_0 < 0$. A regime shift corresponding to the end of genuine improvement is modeled as an increase in the mean residual to some $\\mu_1 > \\mu_0$ at an unknown time, which leads to reduced improvement or deterioration of validation loss. You are to construct a one-sided upper Cumulative Sum (CUSUM) detector to identify this upward shift and trigger early stopping.\n\nBase the detector on the following specifications grounded in standard sequential change detection:\n- Estimate the in-control mean $\\mu_0$ using the first $W$ residuals: $\\mu_0 = \\frac{1}{W}\\sum_{t=2}^{W+1} r_t$, where $W$ is a given integer window size satisfying $W \\ge 1$ and $W+1 \\le T$.\n- Define the one-sided upper Cumulative Sum statistic $\\{S_t\\}$ over residual times $t \\in \\{W+2,\\dots,T\\}$ recursively by $S_{W+1} = 0$ and $S_t = \\max\\{0, S_{t-1} + r_t - \\mu_0 - k\\}$, where $k > 0$ is a given reference value that sets the sensitivity to upward shifts.\n- Define the stopping time $\\tau$ as the smallest epoch index in the original validation loss time scale at which the statistic crosses the threshold, namely $\\tau = \\min\\{t \\in \\{W+2,\\dots,T\\} : S_t \\ge h\\}$, where $h > 0$ is a given threshold. If no such time exists, set $\\tau = -1$.\n- Return the integer epoch index $\\tau$ when the stopping is triggered. If no trigger occurs, return $-1$.\n\nImportant indexing convention: residual time $t$ corresponds to validation loss at epoch $t$, since $r_t$ uses $L_{\\text{val}}(t)$ and $L_{\\text{val}}(t-1)$. Therefore, when an alarm is raised at residual time $t$, the stopping epoch to be returned is exactly $t$.\n\nYour program must implement this detector for the test suite below without any user input. For each test case, you are given the validation loss sequence and parameters $W$, $k$, and $h$. For each case, output the stopping epoch $\\tau$ as an integer, or $-1$ if no detection occurs. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets.\n\nTest suite:\n- Case A (clear shift from improvement to deterioration): \n  - Sequence length $T = 20$. Validation losses $[1.00, 0.95, 0.90, 0.85, 0.80, 0.75, 0.70, 0.65, 0.60, 0.55, 0.50, 0.45, 0.465, 0.480, 0.495, 0.510, 0.525, 0.540, 0.555, 0.570]$.\n  - Parameters: $W = 6$, $k = 0.02$, $h = 0.10$.\n- Case B (continued improvement, no shift): \n  - Sequence length $T = 15$. Validation losses $[1.00, 0.97, 0.94, 0.91, 0.88, 0.85, 0.82, 0.79, 0.76, 0.73, 0.70, 0.67, 0.64, 0.61, 0.58]$.\n  - Parameters: $W = 6$, $k = 0.02$, $h = 0.10$.\n- Case C (noisy plateau, exact threshold hit): \n  - Sequence length $T = 11$. Validation losses $[1.00, 0.96, 0.92, 0.88, 0.84, 0.80, 0.76, 0.72, 0.71, 0.70, 0.69]$.\n  - Parameters: $W = 5$, $k = 0.01$, $h = 0.06$.\n- Case D (early anomaly inside baseline window, then continued improvement): \n  - Sequence length $T = 15$. Validation losses $[1.00, 0.95, 0.90, 0.85, 0.80, 0.82, 0.84, 0.79, 0.74, 0.69, 0.64, 0.59, 0.54, 0.49, 0.44]$.\n  - Parameters: $W = 6$, $k = 0.02$, $h = 0.10$.\n\nRequirements:\n- Implement the above detector precisely.\n- For each case, compute the integer epoch index $\\tau$ at which $S_t \\ge h$ first occurs, or $-1$ if never.\n- Final output format: a single line containing a list of the four results in order, formatted as $[\\tau_A,\\tau_B,\\tau_C,\\tau_D]$ with no extra spaces or text.", "solution": "The problem presented is valid, as it is scientifically grounded in the established statistical theory of Cumulative Sum (CUSUM) change-point detection, is well-posed with a complete and consistent set of definitions and data, and is computationally verifiable. We may therefore proceed with a solution.\n\nThe core task is to implement a one-sided upper CUSUM detector to identify a degradation in the improvement of a model's validation loss during training. This degradation is modeled as an upward shift in the mean of the epoch-to-epoch changes in validation loss.\n\nLet the sequence of validation losses be $\\{L_{\\text{val}}(t)\\}_{t=1}^{T}$, where $t$ is the epoch number and $T$ is the total number of epochs. The epoch-to-epoch change, or residual, is defined as $r_t = L_{\\text{val}}(t) - L_{\\text{val}}(t-1)$ for $t \\in \\{2, \\dots, T\\}$.\n\nIn the initial \"in-control\" phase of training, the model is improving, which implies the validation loss is consistently decreasing. We model this by assuming the residuals $r_t$ are sampled from a distribution with a negative mean, $\\mu_0 < 0$. Overfitting or the cessation of effective learning is characterized by a shift in this distribution, where the mean of the residuals increases to a value $\\mu_1 > \\mu_0$. This corresponds to a slower rate of loss decrease, a plateau, or an increase in loss. The CUSUM detector is designed to detect this specific shift.\n\nThe algorithm is specified as follows:\n$1$. **Residual Calculation**: First, we compute the sequence of residuals $\\{r_t\\}_{t=2}^{T}$ from the given validation loss sequence $\\{L_{\\text{val}}(t)\\}_{t=1}^{T}$.\n\n$2$. **Baseline Estimation**: The in-control mean $\\mu_0$ is estimated from an initial window of training. Using the first $W$ residuals, we calculate the sample mean:\n$$\n\\mu_0 = \\frac{1}{W}\\sum_{t=2}^{W+1} r_t\n$$\nThis establishes the baseline expectation for epoch-to-epoch improvement. The parameter $W$ must satisfy $W \\ge 1$ and $W+1 \\le T$.\n\n$3$. **CUSUM Statistic Update**: The one-sided upper CUSUM statistic, $S_t$, is designed to accumulate evidence of an upward deviation from the baseline mean $\\mu_0$. It is calculated recursively for epochs $t \\in \\{W+2, \\dots, T\\}$, starting with the initial condition $S_{W+1} = 0$. The update rule is:\n$$\nS_t = \\max\\{0, S_{t-1} + r_t - \\mu_0 - k\\}\n$$\nHere, the term $r_t - \\mu_0$ represents the deviation of the current residual from the expected baseline. The parameter $k > 0$ is a reference value, or \"slack,\" which allows for minor fluctuations. The statistic $S_t$ only increases if the deviation $r_t - \\mu_0$ exceeds this slack $k$. The $\\max\\{0, \\cdot\\}$ operation ensures that the CUSUM statistic does not accumulate \"negative evidence\" (i.e., periods of better-than-expected improvement) and resets to $0$ if the trend towards a shift dissipates.\n\n$4$. **Stopping Condition**: An alarm is triggered, and training is stopped, at the first epoch $t$ where the accumulated evidence $S_t$ crosses a predefined threshold $h > 0$. The stopping time $\\tau$ is thus defined as:\n$$\n\\tau = \\min\\{t \\in \\{W+2, \\dots, T\\} : S_t \\ge h\\}\n$$\nIf the CUSUM statistic never crosses the threshold $h$ by the final epoch $T$, no stopping is triggered, and we set $\\tau = -1$. The reported stopping time $\\tau$ corresponds to the epoch index in the original validation loss sequence.\n\nLet us walk through the calculation for **Case A**:\n- **Given**: Validation losses $\\{L_{\\text{val}}(t)\\}_{t=1}^{20}$ are $[1.00, 0.95, \\dots, 0.570]$. Parameters are $T=20$, $W=6$, $k=0.02$, and $h=0.10$.\n- **Step 1 (Residuals)**: We compute $r_t$ for $t \\in \\{2, \\dots, 20\\}$.\nThe residuals from $r_2$ to $r_{12}$ are all $-0.05$. Starting from $r_{13}$, the residuals become positive: $r_{13} = 0.465 - 0.45 = 0.015$, $r_{14} = 0.480 - 0.465 = 0.015$, and so on.\n- **Step 2 (Baseline)**: We use the first $W=6$ residuals ($r_2, \\dots, r_7$) to estimate $\\mu_0$.\n$$\n\\mu_0 = \\frac{1}{6} \\sum_{t=2}^{7} r_t = \\frac{1}{6} (r_2 + \\dots + r_7) = \\frac{1}{6} (6 \\times -0.05) = -0.05\n$$\n- **Step 3 & 4 (CUSUM Iteration and Stopping)**: We initialize $S_{W+1} = S_7 = 0$ and iterate from $t=W+2 = 8$ to $T=20$. We use $k=0.02$.\n- For $t=8, \\dots, 12$: $r_t = -0.05$. The update term is $r_t - \\mu_0 - k = -0.05 - (-0.05) - 0.02 = -0.02$. Thus, $S_t = \\max\\{0, S_{t-1} - 0.02\\}$. Since $S_7=0$, $S_8=\\max\\{0, -0.02\\}=0$, and subsequently $S_9=S_{10}=S_{11}=S_{12}=0$.\n- For $t=13$: $r_{13} = 0.015$. The update term is $r_{13} - \\mu_0 - k = 0.015 - (-0.05) - 0.02 = 0.045$.\n$$S_{13} = \\max\\{0, S_{12} + 0.045\\} = \\max\\{0, 0 + 0.045\\} = 0.045$$\nThis value is less than $h=0.10$.\n- For $t=14$: $r_{14} = 0.015$. The update term is again $0.045$.\n$$S_{14} = \\max\\{0, S_{13} + 0.045\\} = \\max\\{0, 0.045 + 0.045\\} = 0.09$$\nThis value is less than $h=0.10$.\n- For $t=15$: $r_{15} = 0.015$. The update term is again $0.045$.\n$$S_{15} = \\max\\{0, S_{14} + 0.045\\} = \\max\\{0, 0.09 + 0.045\\} = 0.135$$\nAt this point, $S_{15} = 0.135 \\ge h = 0.10$. The stopping condition is met.\n- **Result**: The stopping time is $\\tau = 15$.\n\nBy applying this same procedure to the other test cases, we find:\n- **Case B**: $\\mu_0 = -0.03$. For all subsequent epochs, $r_t = -0.03$. The CUSUM update term $r_t - \\mu_0 - k = -0.03 - (-0.03) - 0.02 = -0.02$ is always negative, so $S_t$ remains $0$. No stop is triggered. $\\tau = -1$.\n- **Case C**: $\\mu_0 = -0.04$. The CUSUM statistic gradually increases as residuals change from $-0.04$ to $-0.01$. At $t=11$, $S_{11}$ reaches exactly $0.06$, triggering the stop since $S_{11} \\ge h = 0.06$. $\\tau = 11$.\n- **Case D**: The baseline window includes anomalous positive residuals, resulting in a less negative $\\mu_0 \\approx -0.0267$. The subsequent residuals are all $-0.05$. The CUSUM update term $r_t - \\mu_0 - k \\approx -0.05 - (-0.0267) - 0.02 = -0.0433$ is always negative. Thus, $S_t$ remains $0$. No stop is triggered. $\\tau = -1$.\n\nThe final results for the test suite are $[15, -1, 11, -1]$.", "answer": "```python\nimport numpy as np\n\ndef cusum_early_stopping(losses, W, k, h):\n    \"\"\"\n    Implements a CUSUM-based early stopping detector.\n\n    Args:\n        losses (list or np.ndarray): Sequence of validation losses, 1-indexed by epoch.\n        W (int): Window size for estimating the in-control mean.\n        k (float): Reference value (slack) for the CUSUM statistic.\n        h (float): Threshold for triggering the stop.\n\n    Returns:\n        int: The stopping epoch tau, or -1 if no stop is triggered.\n    \"\"\"\n    losses = np.array(losses, dtype=float)\n    T = len(losses)\n\n    # Problem constraints on W\n    if not (W >= 1 and W + 1 <= T):\n        # This case should not occur with the given test suite\n        # but is good practice for a general function.\n        raise ValueError(\"W must satisfy 1 <= W and W+1 <= T.\")\n\n    # Step 1: Compute residuals r_t for t=2,...,T\n    # r_t = L(t) - L(t-1)\n    # The array `residuals` is 0-indexed, where residuals[i] corresponds to r_{i+2}.\n    # e.g., residuals[0] = losses[1] - losses[0] = r_2\n    residuals = np.diff(losses)\n\n    # Step 2: Estimate in-control mean mu_0 from the first W residuals\n    # These are r_2, ..., r_{W+1}, which correspond to residuals[0], ..., residuals[W-1]\n    mu_0 = np.mean(residuals[0:W])\n\n    # Step 3 & 4: CUSUM iteration and stopping check\n    # Initialize S_{W+1} = 0.\n    s_current = 0.0\n    \n    # Iterate for epochs t from W+2 to T.\n    # This corresponds to residual indices from W to T-2.\n    # The epoch t equals residual_index + 2.\n    for t_idx in range(W, T - 1):\n        r_t = residuals[t_idx]\n        \n        # Update CUSUM statistic: S_t = max(0, S_{t-1} + r_t - mu_0 - k)\n        s_current = max(0.0, s_current + r_t - mu_0 - k)\n        \n        # Check against threshold h\n        if s_current >= h:\n            # Stopping epoch tau is t = t_idx + 2\n            return t_idx + 2\n            \n    # If the loop completes without stopping\n    return -1\n\ndef solve():\n    \"\"\"\n    Runs the CUSUM detector on the provided test suite and prints the results.\n    \"\"\"\n    test_cases = [\n        {\n            \"id\": \"A\",\n            \"losses\": [1.00, 0.95, 0.90, 0.85, 0.80, 0.75, 0.70, 0.65, 0.60, 0.55, 0.50, 0.45, 0.465, 0.480, 0.495, 0.510, 0.525, 0.540, 0.555, 0.570],\n            \"W\": 6,\n            \"k\": 0.02,\n            \"h\": 0.10\n        },\n        {\n            \"id\": \"B\",\n            \"losses\": [1.00, 0.97, 0.94, 0.91, 0.88, 0.85, 0.82, 0.79, 0.76, 0.73, 0.70, 0.67, 0.64, 0.61, 0.58],\n            \"W\": 6,\n            \"k\": 0.02,\n            \"h\": 0.10\n        },\n        {\n            \"id\": \"C\",\n            \"losses\": [1.00, 0.96, 0.92, 0.88, 0.84, 0.80, 0.76, 0.72, 0.71, 0.70, 0.69],\n            \"W\": 5,\n            \"k\": 0.01,\n            \"h\": 0.06\n        },\n        {\n            \"id\": \"D\",\n            \"losses\": [1.00, 0.95, 0.90, 0.85, 0.80, 0.82, 0.84, 0.79, 0.74, 0.69, 0.64, 0.59, 0.54, 0.49, 0.44],\n            \"W\": 6,\n            \"k\": 0.02,\n            \"h\": 0.10\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        tau = cusum_early_stopping(case[\"losses\"], case[\"W\"], case[\"k\"], case[\"h\"])\n        results.append(tau)\n\n    # Print results in the required format: [tau_A,tau_B,tau_C,tau_D]\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Execute the solver\nsolve()\n```", "id": "3119056"}, {"introduction": "To take our analysis a level deeper, we can move beyond a single aggregate metric like validation loss and instead diagnose training by observing the behavior of individual examples. This advanced exercise [@problem_id:3119110] simulates training on a dataset with label noise and challenges you to implement a detector for the onset of memorization. By tracking the quantiles of the per-example loss distribution, you will develop a sophisticated stopping criterion that intervenes just as the model begins to fit incorrect labels, a critical failure mode in many real-world applications.", "problem": "You are given a stylized setting to study early stopping in deep learning under label noise. The base is empirical risk minimization (ERM), where a model with parameters $\\theta$ is trained to minimize the empirical risk $\\frac{1}{n}\\sum_{i=1}^{n}\\ell(y_i, f_\\theta(x_i))$ with a nonnegative per-example loss $\\ell_i(t)$ at training epoch $t$. Under symmetric label noise at rate $\\rho \\in [0,1]$, a fraction $\\rho$ of labels are corrupted uniformly at random, while the remaining fraction $1-\\rho$ are clean. It is widely observed that over training epochs, losses of clean examples decrease early, while noisy examples maintain high losses initially and only later begin to decrease when the model starts to memorize the noise. This induces a characteristic evolution in the histogram of per-example losses: the high-loss tail remains stable at first and then begins to shrink when memorization starts. Early stopping aims to select an epoch before the model fits the noisy tail.\n\nYou must implement a program that, given a synthetic but scientifically plausible generator of per-example losses $\\ell_i(t)$ and a histogram-based detection rule, outputs the detected early stopping epoch for several test cases. The detection rule must be specified using quantiles of the loss distribution as a stable proxy for the right-tail histogram mass.\n\nSynthetic loss generator. For each test case, you are given:\n- the number of training examples $n$,\n- a symmetric label noise rate $\\rho$,\n- a total number of training epochs $T$,\n- a random seed $s$,\n- clean decay rate $\\alpha > 0$,\n- noisy decay rate after memorization $\\beta > 0$,\n- a memorization onset epoch $t_m \\in \\{0,1,\\dots,T-1\\}$,\n- a Gaussian noise standard deviation $\\sigma > 0$ used to model stochasticity,\n- and detection hyperparameters defined below.\n\nFor reproducibility, you must draw all randomness from a pseudorandom number generator initialized with the given seed $s$. Generate per-example identities as noisy with probability $\\rho$ and clean with probability $1-\\rho$, independently across examples. For each example $j \\in \\{1,\\dots,n\\}$, draw a difficulty $d_j \\sim \\mathrm{Uniform}(0,1)$ once and reuse it across epochs. Define the following base values:\n- clean base $b^{\\mathrm{clean}}_j = 1.6 + 0.4 d_j$,\n- clean floor $f^{\\mathrm{clean}}_j = 0.05 + 0.05 d_j$,\n- noisy base $b^{\\mathrm{noisy}}_j = 2.2 + 0.4 d_j$,\n- noisy floor $f^{\\mathrm{noisy}}_j = 0.02 + 0.01 d_j$.\n\nFor each epoch $t \\in \\{0,1,\\dots,T-1\\}$ and example $j$, define the noise term $\\varepsilon_{j,t} \\sim \\mathcal{N}(0,\\sigma^2)$ independently across $j$ and $t$, and then define the per-example loss $\\ell_j(t)$ as follows:\n- If $j$ is clean:\n$$\n\\ell_j(t) = f^{\\mathrm{clean}}_j + \\bigl(b^{\\mathrm{clean}}_j - f^{\\mathrm{clean}}_j\\bigr)\\exp(-\\alpha t) + \\varepsilon_{j,t}.\n$$\n- If $j$ is noisy:\n$$\n\\ell_j(t) =\n\\begin{cases}\nb^{\\mathrm{noisy}}_j + \\varepsilon_{j,t}, & \\text{if } t < t_m, \\\\[6pt]\nf^{\\mathrm{noisy}}_j + \\bigl(b^{\\mathrm{noisy}}_j - f^{\\mathrm{noisy}}_j\\bigr)\\exp\\bigl(-\\beta (t - t_m)\\bigr), & \\text{if } t \\ge t_m.\n\\end{cases}\n$$\nFinally, clip losses below at zero so that $\\ell_j(t) \\leftarrow \\max\\{\\ell_j(t), 0\\}$.\n\nDetection rule from loss histogram dynamics. Let $q_p(t)$ denote the empirical $p$-quantile of $\\{\\ell_1(t),\\dots,\\ell_n(t)\\}$ at epoch $t$, for a fixed $p \\in (0,1)$ emphasizing the right tail (e.g., $p=0.9$). Define a moving average smoother of window length $w \\in \\mathbb{N}$ by\n$$\n\\widehat{q}_p(t) = \\frac{1}{w}\\sum_{k=0}^{w-1} q_p(t-k), \\quad \\text{defined for } t \\ge w-1.\n$$\nDefine the discrete slope\n$$\ns(t) = \\widehat{q}_p(t) - \\widehat{q}_p(t-1), \\quad \\text{defined for } t \\ge w.\n$$\nGiven a negative slope threshold $\\gamma > 0$ and a required number of consecutive epochs $s_{\\mathrm{consec}} \\in \\mathbb{N}$, and a warm-up $t_{\\mathrm{warm}} \\in \\mathbb{N}$, detect the earliest epoch $t^\\star$ such that $t^\\star \\ge \\max\\{w, t_{\\mathrm{warm}}\\}$ and\n$$\ns(t) \\le -\\gamma \\quad \\text{for all } t \\in \\{t^\\star, t^\\star + 1, \\dots, t^\\star + s_{\\mathrm{consec}} - 1\\}.\n$$\nIf such an epoch exists, output $t^\\star$; otherwise output $T$.\n\nYour program must implement the above generator and detection rule exactly as defined, using the provided test suite. There are no physical units in this problem. Angles are not involved. All proportions must be represented as decimals (e.g., write $0.3$ for thirty percent). The final output for all test cases must be a single line containing a comma-separated list of the detected epochs enclosed in square brackets.\n\nTest suite. Implement your program to run on the following parameter sets, in this order:\n\n- Case A (happy path, moderate noise, clear memorization onset):\n    - $n = 4000$, $\\rho = 0.3$, $T = 60$, $s = 42$, $\\alpha = 0.12$, $\\beta = 0.25$, $t_m = 25$, $\\sigma = 0.03$, $p = 0.9$, $w = 3$, $\\gamma = 0.04$, $s_{\\mathrm{consec}} = 2$, $t_{\\mathrm{warm}} = 5$.\n\n- Case B (boundary: no label noise, should not trigger detection with a sufficiently strict threshold):\n    - $n = 4000$, $\\rho = 0.0$, $T = 60$, $s = 123$, $\\alpha = 0.12$, $\\beta = 0.25$, $t_m = 25$, $\\sigma = 0.03$, $p = 0.9$, $w = 3$, $\\gamma = 0.2$, $s_{\\mathrm{consec}} = 2$, $t_{\\mathrm{warm}} = 5$.\n\n- Case C (high noise, later memorization onset):\n    - $n = 4000$, $\\rho = 0.6$, $T = 70$, $s = 7$, $\\alpha = 0.12$, $\\beta = 0.20$, $t_m = 40$, $\\sigma = 0.03$, $p = 0.9$, $w = 3$, $\\gamma = 0.03$, $s_{\\mathrm{consec}} = 2$, $t_{\\mathrm{warm}} = 5$.\n\n- Case D (edge: small dataset and very slow memorization, may not trigger detection):\n    - $n = 300$, $\\rho = 0.4$, $T = 50$, $s = 999$, $\\alpha = 0.08$, $\\beta = 0.05$, $t_m = 30$, $\\sigma = 0.04$, $p = 0.9$, $w = 4$, $\\gamma = 0.03$, $s_{\\mathrm{consec}} = 3$, $t_{\\mathrm{warm}} = 5$.\n\nRequired final output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result_A,result_B,result_C,result_D]\"), where each result is an integer epoch index as defined above for the corresponding case.", "solution": "The user has provided a problem that requires the implementation of a simulation and detection algorithm for early stopping in a deep learning context. The problem is scientifically grounded, well-posed, and all necessary parameters and definitions are provided. Therefore, the problem is deemed valid and a full solution will be developed.\n\nThe solution is divided into two main conceptual parts: the generation of synthetic per-example training losses over a series of epochs, and the application of a specific detection rule to these losses to determine an optimal early stopping epoch.\n\n### Part 1: Synthetic Per-Example Loss Generation\n\nThe first step is to generate the matrix of per-example losses, denoted as $\\ell_j(t)$ for example $j$ at epoch $t$. The dimensions of this process are defined by the number of examples $n$ and the total number of epochs $T$.\n\n1.  **Initialization and Randomness**: For reproducibility, all stochastic elements are derived from a pseudorandom number generator initialized with a given seed $s$.\n\n2.  **Example Identity and Difficulty**: Each of the $n$ examples is categorized as either \"clean\" or \"noisy\". An example is designated as noisy with a probability $\\rho$, and as clean with probability $1-\\rho$. This assignment is performed independently for each example. Concurrently, each example $j$ is assigned a static \"difficulty\" parameter $d_j$, drawn from a uniform distribution $\\mathrm{Uniform}(0, 1)$. This difficulty parameter modulates the loss characteristics for that specific example throughout the training process.\n\n3.  **Loss Characteristics**: Based on an example's identity (clean or noisy) and its difficulty $d_j$, four key values are defined:\n    -   Clean base loss: $b^{\\mathrm{clean}}_j = 1.6 + 0.4 d_j$\n    -   Clean floor loss: $f^{\\mathrm{clean}}_j = 0.05 + 0.05 d_j$\n    -   Noisy base loss: $b^{\\mathrm{noisy}}_j = 2.2 + 0.4 d_j$\n    -   Noisy floor loss: $f^{\\mathrm{noisy}}_j = 0.02 + 0.01 d_j$\n    The \"base\" values represent the initial high loss, while the \"floor\" values represent the minimal achievable loss after extensive training.\n\n4.  **Loss Evolution Dynamics**: The per-example loss $\\ell_j(t)$ for each example $j \\in \\{1, \\dots, n\\}$ and epoch $t \\in \\{0, \\dots, T-1\\}$ is modeled as follows.\n    -   For a **clean** example, the loss decays exponentially from its base value towards its floor value, governed by the decay rate $\\alpha$:\n        $$\n        \\ell_j(t) = f^{\\mathrm{clean}}_j + \\bigl(b^{\\mathrm{clean}}_j - f^{\\mathrm{clean}}_j\\bigr)\\exp(-\\alpha t) + \\varepsilon_{j,t}\n        $$\n    -   For a **noisy** example, the behavior is bifurcated based on the memorization onset epoch, $t_m$. Before this epoch, the model fails to fit the incorrect label, and the loss remains high. After this epoch, the model begins to \"memorize\" the noisy label, causing the loss to decrease. This is governed by the decay rate $\\beta$:\n        $$\n        \\ell_j(t) =\n        \\begin{cases}\n        b^{\\mathrm{noisy}}_j + \\varepsilon_{j,t}, & \\text{if } t < t_m, \\\\\n        f^{\\mathrm{noisy}}_j + \\bigl(b^{\\mathrm{noisy}}_j - f^{\\mathrm{noisy}}_j\\bigr)\\exp\\bigl(-\\beta (t - t_m)\\bigr), & \\text{if } t \\ge t_m.\n        \\end{cases}\n        $$\n    In both cases, $\\varepsilon_{j,t}$ is a stochastic noise term drawn from a zero-mean Gaussian distribution $\\mathcal{N}(0, \\sigma^2)$, added independently for each example and epoch to simulate the stochastic nature of training. Finally, since loss values must be non-negative, the calculated loss is clipped at zero: $\\ell_j(t) \\leftarrow \\max\\{\\ell_j(t), 0\\}$.\n\n### Part 2: Histogram-Based Early Stopping Detection\n\nThe second part of the process is to analyze the generated loss matrix to identify the optimal stopping epoch $t^\\star$. The phenomenon to be detected is the onset of memorization, which manifests as a sudden drop in the losses of the noisy examples. This drop causes the right tail of the loss distribution histogram to shrink.\n\n1.  **Quantile as a Proxy**: The right tail of the loss distribution is tracked using the empirical $p$-quantile, $q_p(t)$, of the set of losses $\\{\\ell_1(t), \\dots, \\ell_n(t)\\}$ at each epoch $t$. A value of $p$ close to $1$ (e.g., $p=0.9$) ensures that this metric is sensitive to the high-loss examples, which are predominantly the noisy ones before memorization begins.\n\n2.  **Smoothing**: To mitigate the effects of the stochastic noise $\\varepsilon_{j,t}$ and obtain a more stable signal, the raw quantile series $q_p(t)$ is smoothed using a moving average of window size $w$. The smoothed quantile, $\\widehat{q}_p(t)$, is defined for epochs $t \\ge w-1$:\n    $$\n    \\widehat{q}_p(t) = \\frac{1}{w}\\sum_{k=0}^{w-1} q_p(t-k)\n    $$\n\n3.  **Slope Calculation**: The onset of memorization is marked by a sharp decrease in the smoothed quantile. This is detected by calculating the discrete slope (or first-order difference) of the smoothed quantile series. The slope $s(t)$ is defined for epochs $t \\ge w$:\n    $$\n    s(t) = \\widehat{q}_p(t) - \\widehat{q}_p(t-1)\n    $$\n\n4.  **Detection Rule**: The early stopping epoch $t^\\star$ is identified based on a persistence condition. It is the earliest epoch $t^\\star$ that satisfies two criteria:\n    -   It must occur after a \"warm-up\" period, i.e., $t^\\star \\ge \\max\\{w, t_{\\mathrm{warm}}\\}$. The warm-up period $t_{\\mathrm{warm}}$ prevents premature stopping due to initial training transients. The condition $t^\\star \\ge w$ is necessary because the slope $s(t)$ is first defined at $t=w$.\n    -   The slope must be significantly negative for a sustained period. Specifically, the slope $s(t)$ must be less than or equal to a negative threshold $-\\gamma$ (where $\\gamma > 0$) for $s_{\\mathrm{consec}}$ consecutive epochs starting from $t^\\star$. That is, $s(t) \\le -\\gamma$ must hold for all $t \\in \\{t^\\star, t^\\star + 1, \\dots, t^\\star + s_{\\mathrm{consec}} - 1\\}$.\n\nIf an epoch $t^\\star$ satisfying these conditions is found, it is returned as the result. If the search completes without finding such an epoch, the algorithm returns the total number of epochs $T$, indicating that early stopping was not triggered.\n\nThis entire procedure is implemented and applied to each of the test cases specified in the problem statement.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_simulation(n, rho, T, s_seed, alpha, beta, t_m, sigma, p, w, gamma, s_consec, t_warm):\n    \"\"\"\n    Runs the simulation and detection algorithm for a single test case.\n    \"\"\"\n    # 1. Initialize random number generator for reproducibility.\n    rng = np.random.default_rng(s_seed)\n\n    # 2. Generate per-example identities and difficulties.\n    is_noisy = rng.choice([True, False], size=n, p=[rho, 1 - rho])\n    d = rng.uniform(0, 1, size=n)\n\n    # 3. Define base and floor values for losses.\n    b_clean = 1.6 + 0.4 * d\n    f_clean = 0.05 + 0.05 * d\n    b_noisy = 2.2 + 0.4 * d\n    f_noisy = 0.02 + 0.01 * d\n\n    # 4. Generate the T x n matrix of per-example losses over all epochs.\n    losses = np.zeros((T, n))\n    # Pre-generate all Gaussian noise for efficiency.\n    gaussian_noise = rng.normal(0, sigma, size=(T, n))\n\n    for t in range(T):\n        # Calculate base losses for clean examples at epoch t\n        loss_clean_t = f_clean + (b_clean - f_clean) * np.exp(-alpha * t)\n\n        # Calculate base losses for noisy examples at epoch t\n        if t < t_m:\n            loss_noisy_t = b_noisy\n        else:\n            loss_noisy_t = f_noisy + (b_noisy - f_noisy) * np.exp(-beta * (t - t_m))\n\n        # Combine based on whether an example is noisy or clean\n        epoch_losses = np.where(is_noisy, loss_noisy_t, loss_clean_t)\n        \n        # Add stochastic noise\n        epoch_losses += gaussian_noise[t, :]\n        \n        # Clip losses at zero\n        losses[t, :] = np.maximum(epoch_losses, 0)\n\n    # 5. Calculate the p-quantile of the loss distribution for each epoch.\n    if losses.shape[1] == 0:  # Handle edge case of n=0\n        q_p = np.zeros(T)\n    else:\n        q_p = np.quantile(losses, p, axis=1)\n\n    # 6. Compute the smoothed quantiles using a moving average.\n    q_p_hat = np.zeros_like(q_p)\n    # The moving average is defined for t >= w-1.\n    for t in range(w - 1, T):\n        q_p_hat[t] = np.mean(q_p[t - w + 1 : t + 1])\n\n    # 7. Compute the discrete slope of the smoothed quantiles.\n    slopes = np.zeros_like(q_p)\n    # The slope is defined for t >= w.\n    for t in range(w, T):\n        slopes[t] = q_p_hat[t] - q_p_hat[t - 1]\n\n    # 8. Search for the early stopping epoch t_star.\n    t_star = T\n    t_search_start = max(w, t_warm)\n\n    # The latest possible start of a valid sequence is T - s_consec.\n    # The loop should go up to and including this value.\n    for t_candidate in range(t_search_start, T - s_consec + 1):\n        # Check if the slope is below the threshold for s_consec consecutive epochs.\n        sub_slopes = slopes[t_candidate : t_candidate + s_consec]\n        if np.all(sub_slopes <= -gamma):\n            t_star = t_candidate\n            break  # Found the earliest such epoch\n    \n    return t_star\n\n\ndef solve():\n    \"\"\"\n    Defines the test suite and runs the simulation for each case.\n    \"\"\"\n    test_cases = [\n        # Case A (happy path, moderate noise, clear memorization onset)\n        {\"n\": 4000, \"rho\": 0.3, \"T\": 60, \"s_seed\": 42, \"alpha\": 0.12, \"beta\": 0.25, \n         \"t_m\": 25, \"sigma\": 0.03, \"p\": 0.9, \"w\": 3, \"gamma\": 0.04, \n         \"s_consec\": 2, \"t_warm\": 5},\n\n        # Case B (boundary: no label noise)\n        {\"n\": 4000, \"rho\": 0.0, \"T\": 60, \"s_seed\": 123, \"alpha\": 0.12, \"beta\": 0.25, \n         \"t_m\": 25, \"sigma\": 0.03, \"p\": 0.9, \"w\": 3, \"gamma\": 0.2, \n         \"s_consec\": 2, \"t_warm\": 5},\n\n        # Case C (high noise, later memorization onset)\n        {\"n\": 4000, \"rho\": 0.6, \"T\": 70, \"s_seed\": 7, \"alpha\": 0.12, \"beta\": 0.20, \n         \"t_m\": 40, \"sigma\": 0.03, \"p\": 0.9, \"w\": 3, \"gamma\": 0.03, \n         \"s_consec\": 2, \"t_warm\": 5},\n\n        # Case D (edge: small dataset and very slow memorization)\n        {\"n\": 300, \"rho\": 0.4, \"T\": 50, \"s_seed\": 999, \"alpha\": 0.08, \"beta\": 0.05, \n         \"t_m\": 30, \"sigma\": 0.04, \"p\": 0.9, \"w\": 4, \"gamma\": 0.03, \n         \"s_consec\": 3, \"t_warm\": 5},\n    ]\n\n    results = []\n    for params in test_cases:\n        result = run_simulation(**params)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3119110"}]}