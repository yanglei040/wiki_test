{"hands_on_practices": [{"introduction": "The best way to truly understand an algorithm is to build it from the ground up. This first exercise challenges you to implement the steepest descent (gradient descent) algorithm to find the minimum energy configuration of a diatomic molecule, described by the one-dimensional Morse potential. By coding the update rule and a backtracking line search for the step size, you will gain a practical understanding of how gradient descent navigates a potential energy landscape to find its minimum [@problem_id:2463075].", "problem": "You are given the diatomic Morse potential in one spatial dimension, defined for a bond length variable $r$ by\n$$\nV(r; D_e, a, r_e) = D_e \\left(1 - e^{-a \\, (r - r_e)}\\right)^2,\n$$\nwhere $D_e \\gt 0$ is the dissociation energy parameter, $a \\gt 0$ controls the curvature, and $r_e \\gt 0$ is the equilibrium bond length. All quantities are dimensionless for this problem. Consider an iterative sequence $\\{r_k\\}_{k=0}^{\\infty}$ initialized at $r_0$ and updated by\n$$\nr_{k+1} = r_k - \\alpha_k \\, \\frac{dV}{dr}(r_k),\n$$\nwith a step size $\\alpha_k \\gt 0$ chosen at each iteration to ensure that the energy sequence $\\{V(r_k)\\}$ is monotonically nonincreasing and terminates when either the gradient magnitude satisfies $\\left|\\frac{dV}{dr}(r_k)\\right| \\le \\varepsilon$ or a maximum number of iterations is reached. Let the sufficient decrease condition be\n$$\nV(r_k - \\alpha_k \\, \\tfrac{dV}{dr}(r_k)) \\le V(r_k) - c \\, \\alpha_k \\left(\\tfrac{dV}{dr}(r_k)\\right)^2,\n$$\nwith a contraction factor $\\rho \\in (0,1)$ used to reduce $\\alpha_k$ until the condition holds. Treat $c$ and $\\rho$ as given parameters per test case. Your task is to compute, for each test case, the final position $r_\\star$, the final energy $V(r_\\star)$, the number of iterations performed, whether the energy sequence was monotonically nonincreasing at all recorded iterates, and a sampled list of energies at iteration indices in the set $\\{0,1,2,4,8,16\\}$ that are within the performed iteration range (include only those indices that exist).\n\nUse the following test suite of parameter sets. For each case, all symbols and numbers are as defined above, and all quantities are dimensionless:\n- Case $1$ (highly compressed start): $D_e = 1.0$, $a = 1.5$, $r_e = 1.4$, $r_0 = 0.2$, initial trial step $= 1.0$, $c = 1.0 \\times 10^{-4}$, $\\rho = 0.5$, $\\varepsilon = 1.0 \\times 10^{-8}$, maximum iterations $= 2000$.\n- Case $2$ (equilibrium start): $D_e = 1.0$, $a = 1.5$, $r_e = 1.4$, $r_0 = 1.4$, initial trial step $= 1.0$, $c = 1.0 \\times 10^{-4}$, $\\rho = 0.5$, $\\varepsilon = 1.0 \\times 10^{-12}$, maximum iterations $= 100$.\n- Case $3$ (stretched start): $D_e = 1.0$, $a = 1.5$, $r_e = 1.4$, $r_0 = 4.0$, initial trial step $= 1.0$, $c = 1.0 \\times 10^{-4}$, $\\rho = 0.5$, $\\varepsilon = 1.0 \\times 10^{-10}$, maximum iterations $= 3000$.\n- Case $4$ (sharper potential, highly compressed start): $D_e = 2.0$, $a = 3.0$, $r_e = 1.2$, $r_0 = 0.1$, initial trial step $= 1.0$, $c = 1.0 \\times 10^{-4}$, $\\rho = 0.5$, $\\varepsilon = 1.0 \\times 10^{-8}$, maximum iterations $= 5000$.\n\nFor each test case, your program must compute:\n- $r_\\star$ as the final iterate,\n- $V(r_\\star)$,\n- the total number of iterations performed,\n- a boolean indicating that the full recorded energy sequence is monotonically nonincreasing,\n- the list of sampled energies at iteration indices in $\\{0,1,2,4,8,16\\}$ that are available for that case.\n\nFinal output format:\nYour program should produce a single line of output containing the results for all four test cases as a JSON array. The output must be a single JSON array with four elements, one per test case, where each element is itself a JSON array of the form\n$$\n[r_\\star, \\, V(r_\\star), \\, \\text{number\\_of\\_iterations}, \\, \\text{monotone\\_flag}, \\, \\text{sampled\\_energies}],\n$$\nwith $\\text{monotone\\_flag}$ a JSON boolean and $\\text{sampled\\_energies}$ a JSON array of floating-point values at the available indices in $\\{0,1,2,4,8,16\\}$. For example, a valid overall output shape is\n$$\n\\bigl[ [\\cdots], [\\cdots], [\\cdots], [\\cdots] \\bigr].\n$$\nAll computations use the dimensionless Morse potential defined above and the specified parameters. No plots are to be produced, and no user input is required. The single-line JSON array is the only output.", "solution": "The problem statement has been critically evaluated and is deemed valid. It is scientifically grounded, well-posed, objective, and contains all necessary information to proceed with a unique and verifiable solution. The task is to implement the steepest descent optimization algorithm with a backtracking line search to find the minimum of the one-dimensional Morse potential for several sets of parameters.\n\nThe Morse potential, which describes the potential energy of a diatomic molecule as a function of its internuclear distance $r$, is given by:\n$$\nV(r; D_e, a, r_e) = D_e \\left(1 - e^{-a \\, (r - r_e)}\\right)^2\n$$\nHere, $D_e  0$ is the well depth (dissociation energy), $a  0$ is a parameter controlling the width of the potential well, and $r_e  0$ is the equilibrium bond distance corresponding to the potential minimum.\n\nThe core of the task is to perform a geometry optimization, which in this one-dimensional case is equivalent to finding the value of $r$ that minimizes $V(r)$. The steepest descent method is an iterative optimization algorithm that updates the current position $r_k$ by taking a step in the direction opposite to the gradient of the function. The gradient, in this one-dimensional context, is the first derivative $\\frac{dV}{dr}$. The update rule is:\n$$\nr_{k+1} = r_k - \\alpha_k \\frac{dV}{dr}(r_k)\n$$\nwhere $\\alpha_k  0$ is the step size for iteration $k$.\n\nFirst, we must compute the analytical derivative of the Morse potential. Using the chain rule, we find:\n$$\n\\frac{dV}{dr}(r) = \\frac{d}{dr} \\left[ D_e \\left(1 - e^{-a \\, (r - r_e)}\\right)^2 \\right]\n$$\n$$\n\\frac{dV}{dr}(r) = 2 D_e \\left(1 - e^{-a \\, (r - r_e)}\\right) \\cdot \\frac{d}{dr} \\left(1 - e^{-a \\, (r - r_e)}\\right)\n$$\n$$\n\\frac{dV}{dr}(r) = 2 D_e \\left(1 - e^{-a \\, (r - r_e)}\\right) \\cdot \\left( -e^{-a \\, (r - r_e)} \\cdot (-a) \\right)\n$$\n$$\n\\frac{dV}{dr}(r) = 2 a D_e \\left(1 - e^{-a \\, (r - r_e)}\\right) e^{-a \\, (r - r_e)}\n$$\nThis gradient, let us call it $g_k = \\frac{dV}{dr}(r_k)$, determines the direction of steepest descent, $-g_k$.\n\nA crucial component of the algorithm is the determination of the step size $\\alpha_k$. An inappropriately large step size can cause the algorithm to overshoot the minimum and diverge, while an overly small step size can lead to excessively slow convergence. The problem specifies a backtracking line search strategy governed by the Armijo sufficient decrease condition. This condition ensures that the step taken provides a meaningful reduction in the potential energy. The condition is:\n$$\nV(r_{k+1}) \\le V(r_k) + c \\, \\alpha_k \\, \\nabla V(r_k)^T p_k\n$$\nIn our one-dimensional case with the search direction $p_k = -g_k = -\\frac{dV}{dr}(r_k)$, this becomes:\n$$\nV(r_k - \\alpha_k g_k) \\le V(r_k) - c \\, \\alpha_k g_k^2\n$$\nwhere $c$ is a small positive constant, given as $c = 1.0 \\times 10^{-4}$ for all test cases. The backtracking procedure begins with an initial trial step size, $\\alpha_{trial}$ (given as $1.0$), and repeatedly reduces it by a contraction factor $\\rho \\in (0,1)$ (given as $0.5$) until the Armijo condition is satisfied.\n\nThe overall algorithm for each test case proceeds as follows:\n$1$. Initialize the iteration counter $k=0$ and the position $r_0$ with the given starting value.\n$2$. Begin a loop that continues for a maximum number of iterations.\n$3$. At each iteration $k$, calculate the gradient $g_k = \\frac{dV}{dr}(r_k)$.\n$4$. Check for convergence: if the magnitude of the gradient $|g_k|$ is less than or equal to a specified tolerance $\\varepsilon$, the algorithm has converged. The loop terminates.\n$5$. If not converged, perform the backtracking line search to find a suitable step size $\\alpha_k$:\n    a. Initialize $\\alpha = \\alpha_{trial}$.\n    b. While $V(r_k - \\alpha g_k)  V(r_k) - c \\alpha g_k^2$, update $\\alpha \\leftarrow \\rho \\alpha$.\n    c. Set $\\alpha_k = \\alpha$.\n$6$. Update the position: $r_{k+1} = r_k - \\alpha_k g_k$.\n$7$. Store the energy $V(r_k)$ at each step to monitor the optimization progress and verify monotonicity.\n$8$. Increment the iteration counter, $k \\leftarrow k+1$.\n$9$. If the loop completes due to reaching the maximum number of iterations, the process terminates with the current state.\n\nUpon termination, the final position $r_\\star$, final energy $V(r_\\star)$, total number of iterations, a boolean flag for monotonicity of the energy sequence, and a list of sampled energies at specified iterations $(\\{0, 1, 2, 4, 8, 16\\})$ are compiled. The monotonicity check, $V(r_{i+1}) \\le V(r_i)$ for all $i$, is expected to pass due to the enforcement of the sufficient decrease condition.\n\nThis systematic procedure will be applied to each of the four specified test cases. Case $2$ serves as a useful diagnostic, as it starts at the exact minimum $r_0 = r_e = 1.4$, where the gradient is zero. The algorithm should correctly terminate at iteration $k=0$ with zero gradient.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Morse potential optimization problem for a suite of test cases\n    using the steepest descent algorithm with a backtracking line search.\n    \"\"\"\n\n    def morse_potential(r, De, a, re):\n        \"\"\"Calculates the Morse potential V(r).\"\"\"\n        return De * (1 - np.exp(-a * (r - re)))**2\n\n    def morse_gradient(r, De, a, re):\n        \"\"\"Calculates the gradient (derivative) of the Morse potential dV/dr.\"\"\"\n        exp_term = np.exp(-a * (r - re))\n        return 2 * a * De * (1 - exp_term) * exp_term\n\n    def run_steepest_descent(params):\n        \"\"\"\n        Performs the steepest descent optimization for a single test case.\n        \"\"\"\n        De = params['De']\n        a = params['a']\n        re = params['re']\n        r_current = params['r0']\n        initial_alpha = params['initial_alpha']\n        c = params['c']\n        rho = params['rho']\n        epsilon = params['epsilon']\n        max_iter = params['max_iter']\n\n        energies = []\n        sample_indices = {0, 1, 2, 4, 8, 16}\n        sampled_energies = []\n        \n        k = 0\n        while k  max_iter:\n            # Calculate energy and gradient at current position\n            V_current = morse_potential(r_current, De, a, re)\n            energies.append(V_current)\n\n            # Sample energy if current iteration index is in the sample set\n            if k in sample_indices:\n                sampled_energies.append(V_current)\n            \n            grad = morse_gradient(r_current, De, a, re)\n\n            # Check for convergence\n            if np.abs(grad) = epsilon:\n                break\n\n            # Backtracking line search to find step size alpha\n            alpha = initial_alpha\n            while True:\n                r_next = r_current - alpha * grad\n                V_next = morse_potential(r_next, De, a, re)\n                \n                # Armijo condition for sufficient decrease\n                if V_next = V_current - c * alpha * grad**2:\n                    break\n                alpha *= rho\n\n            # Update position\n            r_current = r_next\n            k += 1\n\n        # Final state after loop termination\n        r_star = r_current\n        V_star = morse_potential(r_star, De, a, re)\n        \n        # In case max_iter is reached, the last energy hasn't been added\n        if k == max_iter:\n            energies.append(V_star)\n            if k in sample_indices:\n                sampled_energies.append(V_star)\n\n        num_iterations = k\n        \n        # Check if the sequence of energies is monotonically nonincreasing\n        is_monotone = True\n        if len(energies)  1:\n            # Using a small tolerance for floating point comparisons\n            for i in range(len(energies) - 1):\n                if energies[i+1]  energies[i] + 1e-12: # V(k+1) should be = V(k)\n                    is_monotone = False\n                    break\n        \n        return [r_star, V_star, num_iterations, is_monotone, sampled_energies]\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'name': 'Case 1', 'De': 1.0, 'a': 1.5, 're': 1.4, 'r0': 0.2, 'initial_alpha': 1.0, 'c': 1.0e-4, 'rho': 0.5, 'epsilon': 1.0e-8, 'max_iter': 2000},\n        {'name': 'Case 2', 'De': 1.0, 'a': 1.5, 're': 1.4, 'r0': 1.4, 'initial_alpha': 1.0, 'c': 1.0e-4, 'rho': 0.5, 'epsilon': 1.0e-12, 'max_iter': 100},\n        {'name': 'Case 3', 'De': 1.0, 'a': 1.5, 're': 1.4, 'r0': 4.0, 'initial_alpha': 1.0, 'c': 1.0e-4, 'rho': 0.5, 'epsilon': 1.0e-10, 'max_iter': 3000},\n        {'name': 'Case 4', 'De': 2.0, 'a': 3.0, 're': 1.2, 'r0': 0.1, 'initial_alpha': 1.0, 'c': 1.0e-4, 'rho': 0.5, 'epsilon': 1.0e-8, 'max_iter': 5000},\n    ]\n\n    all_results = []\n    for case_params in test_cases:\n        result = run_steepest_descent(case_params)\n        all_results.append(result)\n\n    # Format the final output into a single JSON-like string.\n    result_strings = []\n    for res in all_results:\n        r_f, v_f, n_iter, mono, sampled_e = res\n        \n        # Format numbers to a consistent precision for clean output\n        r_f_str = f\"{r_f:.15f}\"\n        v_f_str = f\"{v_f:.15e}\"\n        sampled_e_str_list = [f\"{e:.15e}\" for e in sampled_e]\n        \n        mono_str = \"true\" if mono else \"false\"\n        sampled_str = f\"[{','.join(sampled_e_str_list)}]\"\n        result_strings.append(f\"[{r_f_str},{v_f_str},{n_iter},{mono_str},{sampled_str}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```", "id": "2463075"}, {"introduction": "While gradient descent is powerful, its success hinges on the careful selection of hyperparameters like the learning rate, $\\eta$. This thought experiment explores a classic failure mode where a fixed, inappropriately large step size causes the optimizer to become trapped in a limit cycle, bouncing between two points forever without converging to the minimum. This analysis [@problem_id:2463052] will provide sharp intuition for why adaptive or carefully tuned learning rates are essential for robust optimization.", "problem": "In computational chemistry, local geometry optimization is often performed by minimizing a potential energy surface (PES). Consider the two-dimensional potential energy surface (PES) that approximates a local quadratic well, given in nondimensionalized units by\n$$\nE(x,y) = \\tfrac{1}{2}\\big(x^{2} + 3\\,y^{2}\\big).\n$$\nApply the steepest descent algorithm (SD) with a constant step size parameter $s$ to minimize $E(x,y)$. By definition, the SD update for the coordinates $\\mathbf{r}_{k} = (x_{k},y_{k})$ is\n$$\n\\mathbf{r}_{k+1} = \\mathbf{r}_{k} - s\\,\\nabla E(\\mathbf{r}_{k}).\n$$\nAssume the initial condition $\\mathbf{r}_{0} = (0,y_{0})$ with $y_{0} \\neq 0$.\n\nDetermine the value of the constant step size $s$ (expressed as an exact, simplified fraction) for which the SD iterates are trapped in a non-convergent two-point limit cycle, alternating forever between $(0,y_{0})$ and $(0,-y_{0})$. Use nondimensionalized units and do not include units in your answer. No rounding is required.", "solution": "The problem as stated is well-posed and scientifically sound. We shall proceed with the derivation.\n\nThe potential energy surface (PES) is given by the function:\n$$\nE(x,y) = \\frac{1}{2}(x^{2} + 3y^{2})\n$$\nThe steepest descent (SD) algorithm updates the coordinates $\\mathbf{r}_{k} = (x_{k}, y_{k})$ according to the rule:\n$$\n\\mathbf{r}_{k+1} = \\mathbf{r}_{k} - s \\nabla E(\\mathbf{r}_{k})\n$$\nwhere $s$ is the constant step size.\n\nFirst, we must compute the gradient of the energy function, $\\nabla E(x,y)$. The partial derivatives are:\n$$\n\\frac{\\partial E}{\\partial x} = \\frac{\\partial}{\\partial x} \\left( \\frac{1}{2}x^{2} + \\frac{3}{2}y^{2} \\right) = x\n$$\n$$\n\\frac{\\partial E}{\\partial y} = \\frac{\\partial}{\\partial y} \\left( \\frac{1}{2}x^{2} + \\frac{3}{2}y^{2} \\right) = 3y\n$$\nThus, the gradient vector is:\n$$\n\\nabla E(x,y) = \\begin{pmatrix} x \\\\ 3y \\end{pmatrix}\n$$\nSubstituting the gradient into the SD update rule, we obtain the component-wise recurrence relations for the coordinates $(x_{k}, y_{k})$:\n$$\n\\begin{pmatrix} x_{k+1} \\\\ y_{k+1} \\end{pmatrix} = \\begin{pmatrix} x_{k} \\\\ y_{k} \\end{pmatrix} - s \\begin{pmatrix} x_{k} \\\\ 3y_{k} \\end{pmatrix}\n$$\nThis yields two independent equations:\n$$\nx_{k+1} = x_{k} - s x_{k} = (1 - s) x_{k}\n$$\n$$\ny_{k+1} = y_{k} - s (3y_{k}) = (1 - 3s) y_{k}\n$$\nThe initial condition is given as $\\mathbf{r}_{0} = (0, y_{0})$, where $y_{0} \\neq 0$.\n\nLet us analyze the behavior of the $x$-coordinate. With $x_{0} = 0$, the recurrence relation for $x$ gives:\n$$\nx_{1} = (1-s)x_{0} = (1-s)(0) = 0\n$$\nBy induction, it is trivial to show that $x_{k} = 0$ for all integers $k \\ge 0$. This is consistent with the specified limit cycle points $(0, y_{0})$ and $(0, -y_{0})$, which lie on the $y$-axis.\n\nNow, we analyze the behavior of the $y$-coordinate. The problem states that the system enters a two-point limit cycle, alternating between $(0, y_{0})$ and $(0, -y_{0})$. This implies that for even $k$, $\\mathbf{r}_{k} = (0, y_{0})$, and for odd $k$, $\\mathbf{r}_{k} = (0, -y_{0})$.\n\nLet's consider the first step of the iteration, from $k=0$ to $k=1$.\nWe start at $\\mathbf{r}_{0} = (0, y_{0})$. The next point must be $\\mathbf{r}_{1} = (0, -y_{0})$.\nUsing the recurrence relation for $y$ at $k=0$:\n$$\ny_{1} = (1 - 3s) y_{0}\n$$\nFor the iteration to match the limit cycle, we require $y_{1} = -y_{0}$. Therefore:\n$$\n-y_{0} = (1 - 3s) y_{0}\n$$\nSince it is given that $y_{0} \\neq 0$, we can divide both sides by $y_{0}$:\n$$\n-1 = 1 - 3s\n$$\nSolving this equation for the step size $s$:\n$$\n3s = 1 - (-1) = 2\n$$\n$$\ns = \\frac{2}{3}\n$$\nWe must verify that this value of $s$ sustains the limit cycle indefinitely. If $s = \\frac{2}{3}$, the recurrence for $y$ becomes:\n$$\ny_{k+1} = \\left(1 - 3 \\cdot \\frac{2}{3}\\right) y_{k} = (1 - 2) y_{k} = -y_{k}\n$$\nLet's examine the sequence of iterates:\nFor $k=0$: $\\mathbf{r}_{0} = (0, y_{0})$.\nFor $k=1$: $y_{1} = -y_{0}$, so $\\mathbf{r}_{1} = (0, -y_{0})$.\nFor $k=2$: $y_{2} = -y_{1} = -(-y_{0}) = y_{0}$, so $\\mathbf{r}_{2} = (0, y_{0})$.\nFor $k=3$: $y_{3} = -y_{2} = -y_{0}$, so $\\mathbf{r}_{3} = (0, -y_{0})$.\nThe sequence of points is $(0, y_{0}), (0, -y_{0}), (0, y_{0}), (0, -y_{0}), \\dots$, which is precisely the specified two-point limit cycle. The algorithm never converges to the minimum at $(0,0)$.\n\nThe value of the constant step size $s$ that produces this behavior is $\\frac{2}{3}$.", "answer": "$$\\boxed{\\frac{2}{3}}$$", "id": "2463052"}, {"introduction": "In many real-world optimization landscapes, particularly in deep learning, we encounter long, narrow \"valleys\" that cause standard gradient descent to converge very slowly. This practice introduces the \"Heavy-Ball\" momentum method, a foundational technique for accelerating convergence in such scenarios. By deriving and comparing the optimal parameters for both standard gradient descent and momentum on a classic narrow-valley problem [@problem_id:3186112], you will discover how \"remembering\" past updates can help overcome the challenge of ill-conditioned landscapes.", "problem": "Consider the strictly convex quadratic objective $f(x,y) = \\frac{1}{2}\\left(a x^{2} + b y^{2}\\right)$ with $a  b  0$ and $a \\gg b$. The gradient is $\\nabla f(x,y) = \\left(a x, b y\\right)$ and the Hessian is diagonal with eigenvalues $a$ and $b$. You will compare Gradient Descent (GD) and the Heavy-Ball momentum method (HB) on this objective from first principles.\n\nStarting only from the definitions of the iterative algorithms\n$$(\\text{GD})\\quad \\mathbf{z}_{t+1} = \\mathbf{z}_{t} - \\eta \\nabla f(\\mathbf{z}_{t}),$$\n$$(\\text{HB})\\quad \\mathbf{z}_{t+1} = \\mathbf{z}_{t} - \\eta \\nabla f(\\mathbf{z}_{t}) + \\beta\\left(\\mathbf{z}_{t} - \\mathbf{z}_{t-1}\\right),$$\nwhere $\\mathbf{z}_{t} = (x_{t}, y_{t})$, derive and analyze the one-dimensional recursions induced along each eigen-direction of the Hessian.\n\nYour tasks are:\n1. For GD, derive the scalar contraction factor along an eigenvalue $\\lambda \\in \\{a,b\\}$ and determine the learning rate $\\eta$ that minimizes the worst-case spectral radius over the set $\\{a,b\\}$. Express your result in terms of $a$ and $b$.\n2. For HB, derive the scalar second-order recursion along an eigenvalue $\\lambda \\in \\{a,b\\}$, and then select $\\eta$ and $\\beta$ to minimize the worst-case spectral radius across the set $\\{a,b\\}$ subject to stability. Use only the algorithm definitions above and fundamental linear dynamical system reasoning. Express your optimal $\\eta$ and $\\beta$ as closed-form analytic expressions in terms of $a$ and $b$, and state the corresponding minimized worst-case spectral radius achieved by HB as a function of $a$ and $b$.\n3. Discuss, in words, the overshoot and oscillation tradeoffs that arise when $a \\gg b$, including how $\\beta$ and $\\eta$ influence trajectory behavior in a narrow valley, and propose a concrete experiment: specify $(a,b)$ with $a \\gg b$, an initialization $(x_{0},y_{0})$ and $(x_{-1},y_{-1})$, and what metrics you would record to compare GD versus HB under your derived optimal parameters.\n\nReport your final answer as the optimal Heavy-Ball parameter pair $(\\eta^{\\star}, \\beta^{\\star})$ in terms of $a$ and $b$. No rounding is required. Format the pair as a $1 \\times 2$ row matrix using the LaTeX $\\texttt{pmatrix}$ environment.", "solution": "The problem asks for an analysis of Gradient Descent (GD) and the Heavy-Ball (HB) momentum method on a strictly convex quadratic objective function $f(x,y) = \\frac{1}{2}(ax^2 + by^2)$ where $a  b  0$. The analysis is to be performed from first principles by studying the one-dimensional recursions along the eigen-directions of the Hessian matrix.\n\nThe objective function can be written in vector form as $f(\\mathbf{z}) = \\frac{1}{2}\\mathbf{z}^T H \\mathbf{z}$, where $\\mathbf{z} = \\begin{pmatrix} x \\\\ y \\end{pmatrix}$ and $H = \\begin{pmatrix} a  0 \\\\ 0  b \\end{pmatrix}$. The gradient is $\\nabla f(\\mathbf{z}) = H\\mathbf{z}$. The eigenvalues of the Hessian $H$ are $\\lambda_1 = a$ and $\\lambda_2 = b$, with corresponding eigenvectors along the coordinate axes. The dynamics of the optimization algorithms decouple along these axes. We can analyze the convergence by studying the scalar recursion for a generic eigenvalue $\\lambda \\in \\{a,b\\}$.\n\n### 1. Gradient Descent (GD) Analysis\n\nThe GD update rule is given by:\n$$ \\mathbf{z}_{t+1} = \\mathbf{z}_{t} - \\eta \\nabla f(\\mathbf{z}_{t}) $$\nSubstituting $\\nabla f(\\mathbf{z}_t) = H\\mathbf{z}_t$, we get:\n$$ \\mathbf{z}_{t+1} = \\mathbf{z}_t - \\eta H \\mathbf{z}_t = (I - \\eta H) \\mathbf{z}_t $$\nThis is a linear dynamical system. For a component of $\\mathbf{z}_t$ along an eigenvector corresponding to an eigenvalue $\\lambda$ of $H$, the scalar update rule is:\n$$ z_{t+1}^{(\\lambda)} = (1 - \\eta \\lambda) z_t^{(\\lambda)} $$\nThe term $c(\\eta, \\lambda) = 1 - \\eta\\lambda$ is the contraction factor for this component. For an iterative method to converge, the magnitude of its contraction factor must be less than $1$ for all modes. The overall convergence rate is determined by the largest magnitude, which is the spectral radius of the iteration matrix $I - \\eta H$:\n$$ \\rho(I - \\eta H) = \\max_{\\lambda \\in \\{a, b\\}} |1 - \\eta \\lambda| $$\nFor convergence, we require $\\rho  1$, which implies $|1 - \\eta\\lambda|  1$ for both $\\lambda=a$ and $\\lambda=b$. This means $-1  1 - \\eta\\lambda  1$, which simplifies to $0  \\eta\\lambda  2$. Since $ab0$, this must hold for $\\lambda=a$, giving the stability condition $0  \\eta  \\frac{2}{a}$.\n\nOur goal is to find the learning rate $\\eta$ that minimizes the worst-case spectral radius:\n$$ \\eta^{\\star} = \\arg\\min_{\\eta} \\max(|1 - \\eta a|, |1 - \\eta b|) $$\nThe minimum of the maximum of two linear functions of $\\eta$ occurs when their absolute values are equal. That is, $|1 - \\eta a| = |1 - \\eta b|$. Since $\\eta  0$ and $a  b$, $1-\\eta a  1-\\eta b$. For their magnitudes to be equal, we must have:\n$$ 1 - \\eta b = -(1 - \\eta a) = \\eta a - 1 $$\nSolving for $\\eta$:\n$$ 2 = \\eta a + \\eta b = \\eta(a+b) $$\n$$ \\eta_{GD}^{\\star} = \\frac{2}{a+b} $$\nThis value of $\\eta$ is within the stability range since $a+b  a$, so $\\frac{2}{a+b}  \\frac{2}{a}$. The corresponding minimal spectral radius is:\n$$ \\rho_{GD} = \\left|1 - b \\left(\\frac{2}{a+b}\\right)\\right| = \\left|\\frac{a+b-2b}{a+b}\\right| = \\frac{a-b}{a+b} $$\nIn terms of the condition number $\\kappa = a/b$, this is $\\rho_{GD} = \\frac{\\kappa-1}{\\kappa+1}$.\n\n### 2. Heavy-Ball (HB) Momentum Analysis\n\nThe HB update rule is:\n$$ \\mathbf{z}_{t+1} = \\mathbf{z}_{t} - \\eta \\nabla f(\\mathbf{z}_{t}) + \\beta(\\mathbf{z}_{t} - \\mathbf{z}_{t-1}) $$\nSubstituting $\\nabla f(\\mathbf{z}_t) = H\\mathbf{z}_t$ and considering the scalar recursion for a mode corresponding to eigenvalue $\\lambda$:\n$$ z_{t+1} = z_t - \\eta \\lambda z_t + \\beta(z_t - z_{t-1}) $$\n$$ z_{t+1} = (1 - \\eta\\lambda + \\beta)z_t - \\beta z_{t-1} $$\nThis is a second-order linear homogeneous recurrence relation. Its dynamics are governed by the roots of its characteristic polynomial:\n$$ \\mu^2 - (1 - \\eta\\lambda + \\beta)\\mu + \\beta = 0 $$\nFor the system to be stable, the magnitudes of both roots, $\\mu_1$ and $\\mu_2$, must be less than $1$. The convergence rate is determined by $\\rho_\\lambda = \\max(|\\mu_1|, |\\mu_2|)$. The roots are:\n$$ \\mu = \\frac{1 - \\eta\\lambda + \\beta \\pm \\sqrt{(1 - \\eta\\lambda + \\beta)^2 - 4\\beta}}{2} $$\nThe nature of the roots depends on the discriminant $D = (1 - \\eta\\lambda + \\beta)^2 - 4\\beta$.\nIf $D \\ge 0$, the roots are real, and the spectral radius is $\\rho_\\lambda = \\frac{|1 - \\eta\\lambda + \\beta| + \\sqrt{D}}{2}$.\nIf $D  0$, the roots are a complex conjugate pair, and their magnitude is $|\\mu| = \\sqrt{\\text{product of roots}} = \\sqrt{\\beta}$. The spectral radius is $\\rho_\\lambda = \\sqrt{\\beta}$.\n\nTo minimize the worst-case spectral radius $\\max_{\\lambda \\in \\{a,b\\}} \\rho_\\lambda$, we seek to make the spectral radii for both $\\lambda=a$ and $\\lambda=b$ equal and as small as possible. The optimal solution occurs when the dynamics for both eigenvalues are in the complex root regime and on the boundary of the real root regime, i.e., when the discriminant is non-positive, and the spectral radius is $\\sqrt{\\beta}$ for both. This requires:\n$$ (1 - \\eta\\lambda + \\beta)^2 - 4\\beta \\le 0 \\quad \\text{for } \\lambda \\in \\{a,b\\} $$\n$$ |1 - \\eta\\lambda + \\beta| \\le 2\\sqrt{\\beta} $$\nThis is equivalent to $-2\\sqrt{\\beta} \\le 1 - \\eta\\lambda + \\beta \\le 2\\sqrt{\\beta}$, which rearranges to:\n$$ (1-\\sqrt{\\beta})^2 \\le \\eta\\lambda \\le (1+\\sqrt{\\beta})^2 $$\nTo minimize $\\beta$ (and thus the spectral radius $\\sqrt{\\beta}$), we want this interval to be as small as possible while still containing $[\\eta b, \\eta a]$. This is achieved by setting the endpoints of the intervals to match:\n$$ \\eta b = (1 - \\sqrt{\\beta})^2 $$\n$$ \\eta a = (1 + \\sqrt{\\beta})^2 $$\nDividing the second equation by the first gives:\n$$ \\frac{a}{b} = \\left(\\frac{1 + \\sqrt{\\beta}}{1 - \\sqrt{\\beta}}\\right)^2 $$\nTaking the square root and solving for $\\sqrt{\\beta}$:\n$$ \\sqrt{\\frac{a}{b}} = \\frac{1 + \\sqrt{\\beta}}{1 - \\sqrt{\\beta}} \\implies \\sqrt{a}(1-\\sqrt{\\beta}) = \\sqrt{b}(1+\\sqrt{\\beta}) $$\n$$ \\sqrt{a} - \\sqrt{a}\\sqrt{\\beta} = \\sqrt{b} + \\sqrt{b}\\sqrt{\\beta} $$\n$$ \\sqrt{a} - \\sqrt{b} = (\\sqrt{a} + \\sqrt{b})\\sqrt{\\beta} $$\nThis yields $\\sqrt{\\beta^{\\star}} = \\frac{\\sqrt{a}-\\sqrt{b}}{\\sqrt{a}+\\sqrt{b}}$. Since $ab0$, we have $0  \\sqrt{\\beta^{\\star}}  1$, which is a valid parameter. The optimal momentum parameter is:\n$$ \\beta^{\\star} = \\left(\\frac{\\sqrt{a}-\\sqrt{b}}{\\sqrt{a}+\\sqrt{b}}\\right)^2 $$\nNow, we find the optimal learning rate $\\eta^{\\star}$ using $\\eta a = (1+\\sqrt{\\beta})^2$. First, we compute $1+\\sqrt{\\beta^{\\star}}$:\n$$ 1+\\sqrt{\\beta^{\\star}} = 1 + \\frac{\\sqrt{a}-\\sqrt{b}}{\\sqrt{a}+\\sqrt{b}} = \\frac{(\\sqrt{a}+\\sqrt{b}) + (\\sqrt{a}-\\sqrt{b})}{\\sqrt{a}+\\sqrt{b}} = \\frac{2\\sqrt{a}}{\\sqrt{a}+\\sqrt{b}} $$\nSubstituting this into the equation for $\\eta$:\n$$ \\eta^{\\star} a = \\left(\\frac{2\\sqrt{a}}{\\sqrt{a}+\\sqrt{b}}\\right)^2 = \\frac{4a}{(\\sqrt{a}+\\sqrt{b})^2} $$\n$$ \\eta^{\\star} = \\frac{4}{(\\sqrt{a}+\\sqrt{b})^2} $$\nWith these optimal parameters, the spectral radius for both modes is $\\sqrt{\\beta^{\\star}}$, so the worst-case spectral radius for HB is:\n$$ \\rho_{HB} = \\frac{\\sqrt{a}-\\sqrt{b}}{\\sqrt{a}+\\sqrt{b}} $$\nIn terms of the condition number $\\kappa=a/b$, this is $\\rho_{HB} = \\frac{\\sqrt{\\kappa}-1}{\\sqrt{\\kappa}+1}$. This rate is significantly better than GD's rate of $\\frac{\\kappa-1}{\\kappa+1}$, especially for large $\\kappa$.\n\n### 3. Discussion and Experiment Proposal\n\nWhen $a \\gg b$, the objective function $f(x,y)$ has a long, narrow valley shape. The condition number $\\kappa = a/b$ is large. The contours of $f$ are highly elongated ellipses. The gradient is steep in the $x$-direction (eigenvalue $a$) and shallow in the $y$-direction (eigenvalue $b$).\n\nFor GD, the optimal learning rate $\\eta_{GD}^{\\star} = \\frac{2}{a+b} \\approx \\frac{2}{a}$ is very small, constrained by the largest eigenvalue $a$ to ensure stability. This small learning rate leads to very slow progress along the flat valley ($y$-direction), as the update $- \\eta \\nabla_y f = -\\eta b y$ is tiny. The algorithm exhibits a characteristic zig-zagging behavior, oscillating across the narrow valley while slowly crawling along its floor toward the minimum.\n\nFor HB, the momentum term $\\beta(\\mathbf{z}_t - \\mathbf{z}_{t-1})$ acts as a memory of past updates. For the optimal parameters with $a \\gg b$, we have $\\beta^{\\star} \\approx (1 - 2\\sqrt{b/a})^2 \\approx 1 - 4\\sqrt{b/a}$, which is close to $1$. This high value of $\\beta$ ensures that updates are averaged over many steps. The oscillating gradient components across the valley (in the $x$-direction) tend to cancel out over time, while the consistent, small gradient components along the valley (in the $y$-direction) accumulate, building up velocity and accelerating progress. The optimal learning rate $\\eta_{HB}^{\\star} = \\frac{4}{(\\sqrt{a}+\\sqrt{b})^2} \\approx \\frac{4}{a}$ is roughly twice that of GD. This larger learning rate is stabilized by the momentum term. The trade-off is potential overshoot; the momentum can cause the iterate to \"fly past\" the minimum and oscillate around it with a larger amplitude than GD, but the overall trajectory is smoother and convergence is much faster.\n\nA concrete experiment to compare the methods would be as follows:\n- **Problem Setup**: Let $a=100$ and $b=1$. This gives a condition number of $\\kappa=100$. The objective is $f(x,y) = 50x^2 + 0.5y^2$.\n- **Algorithm Parameters**:\n  - GD: $\\eta_{GD}^{\\star} = \\frac{2}{100+1} = \\frac{2}{101} \\approx 0.0198$.\n  - HB:\n    - $\\beta^{\\star} = \\left(\\frac{\\sqrt{100}-\\sqrt{1}}{\\sqrt{100}+\\sqrt{1}}\\right)^2 = \\left(\\frac{9}{11}\\right)^2 = \\frac{81}{121} \\approx 0.6694$.\n    - $\\eta^{\\star} = \\frac{4}{(\\sqrt{100}+\\sqrt{1})^2} = \\frac{4}{11^2} = \\frac{4}{121} \\approx 0.0331$.\n- **Initialization**: Start at a point that is off-center in the steep direction and far from the minimum in the shallow direction, e.g., $\\mathbf{z}_0 = (x_0, y_0) = (1, 10)$. For HB, initialize with zero velocity by setting $\\mathbf{z}_{-1} = \\mathbf{z}_0$.\n- **Metrics**: Run both algorithms for a fixed number of iterations (e.g., $N=100$). For each iteration $t=0, 1, \\dots, N$, record:\n  1. The iterate position $\\mathbf{z}_t = (x_t, y_t)$.\n  2. The objective function value $f(\\mathbf{z}_t)$.\n  3. The norm of the gradient $\\|\\nabla f(\\mathbf{z}_t)\\|_2$.\n- **Analysis**:\n  - Plot the trajectories $(\\mathbf{z}_0, \\mathbf{z}_1, \\dots, \\mathbf{z}_N)$ for both GD and HB on a 2D contour plot of $f(x,y)$. This will visualize the zig-zagging of GD versus the smoother, faster path of HB.\n  - Plot $f(\\mathbf{z}_t)$ versus $t$ for both methods on a semi-logarithmic scale (logarithm of $f$ vs. linear $t$). This will clearly show the linear convergence rates and demonstrate that HB's convergence slope is much steeper, indicating faster convergence.\n  - Plot $\\|\\nabla f(\\mathbf{z}_t)\\|_2$ versus $t$ on a semi-log scale, which provides another view of the convergence to the critical point.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{4}{(\\sqrt{a}+\\sqrt{b})^{2}}  \\left(\\frac{\\sqrt{a}-\\sqrt{b}}{\\sqrt{a}+\\sqrt{b}}\\right)^{2} \\end{pmatrix}}\n$$", "id": "3186112"}]}