{"hands_on_practices": [{"introduction": "The learning rate you set is the most direct, but not the only, factor controlling the optimization step. Regularization techniques like weight decay also modify the update, changing the effective step size applied to the loss gradient. This first practice challenges you to look beneath the surface by deriving a schedule from the first principles of proximal optimization, giving you precise control over the optimization trajectory by maintaining a constant *effective* step size [@problem_id:3142924].", "problem": "You are asked to design and implement a learning rate scheduling function for Stochastic Gradient Descent (SGD) with weight decay regularization. Begin from a principle-based model of discrete-time optimization: treat weight decay as an implicit proximal step for a squared norm penalty. The base objective is $J(\\mathbf{w}) = L(\\mathbf{w}) + \\frac{\\lambda}{2}\\lVert \\mathbf{w} \\rVert_2^2$, where $L(\\mathbf{w})$ is the data-fitting term, $\\mathbf{w} \\in \\mathbb{R}^d$ are the parameters, and $\\lambda \\ge 0$ is the weight decay coefficient. Consider the implicit-proximal update at iteration $t$ with learning rate $\\eta_t$:\n$$\n\\mathbf{w}_{t+1} \\in \\arg\\min_{\\mathbf{w}} \\left\\{ \\frac{1}{2}\\left\\lVert \\mathbf{w} - \\left(\\mathbf{w}_t - \\eta_t \\nabla L(\\mathbf{w}_t)\\right)\\right\\rVert_2^2 + \\frac{\\eta_t \\lambda}{2} \\lVert \\mathbf{w} \\rVert_2^2 \\right\\}.\n$$\nDefine the effective step in weight space as the scalar that multiplies the negative gradient direction in the resulting update rule at iteration $t$. Your design goal is to keep this effective step equal to a target constant $s_{\\mathrm{target}}$ during an early warm-up window of iterations $t \\in \\{0,1,\\dots,T_{\\mathrm{warm}}-1\\}$, then smoothly reduce it to a smaller value $s_{\\min}$ by the end of training at $t = T_{\\mathrm{total}}-1$ using a monotone exponential decay that exactly attains $s_{\\min}$ at the final iteration. Your schedule must respect positivity and stability constraints: the learning rate must satisfy $0  \\eta_t \\le \\eta_{\\max}$, where $\\eta_{\\max} = \\frac{2}{L_g}$ and $L_g  0$ is a provided Lipschitz constant bound for the gradient of $L(\\mathbf{w})$. If the unconstrained value required to keep the effective step equal to $s_{\\mathrm{target}}$ (or its exponentially decaying continuation) violates $0  \\eta_t \\le \\eta_{\\max}$, replace it by $\\eta_{\\max}$.\n\nTasks:\n1. Starting only from the implicit-proximal update definition and the notion of the effective step as the coefficient of $-\\nabla L(\\mathbf{w}_t)$ in the resulting update rule, derive the expression for the effective step at iteration $t$ and invert it to obtain $\\eta_t$ as a function of the desired effective step at iteration $t$ and $\\lambda$.\n2. Specify a piecewise effective-step schedule $s(t)$ that equals $s_{\\mathrm{target}}$ for $t \\in \\{0,1,\\dots,T_{\\mathrm{warm}}-1\\}$ and decays exponentially to $s_{\\min}$ at $t = T_{\\mathrm{total}}-1$. Determine the exponential decay constant so that the endpoint condition is met exactly.\n3. Combine the above to produce a learning rate schedule $\\eta_t$ under the constraint $0  \\eta_t \\le \\eta_{\\max}$ for all $t$.\n4. Implement a self-contained program that computes and returns the learning rate values at specified evaluation iterations for each of the following four test cases. If $T_{\\mathrm{total}} - T_{\\mathrm{warm}} - 1 \\le 0$, treat the decay interval length as $1$ for the purpose of defining the exponential schedule.\n\nTest suite (each case specifies $(T_{\\mathrm{total}}, T_{\\mathrm{warm}}, s_{\\mathrm{target}}, s_{\\min}, \\lambda, L_g, \\text{eval times})$):\n- Case A: $(100, 40, 0.01, 0.002, 0.1, 50, [0, 20, 40, 60, 99])$.\n- Case B: $(60, 20, 0.02, 0.005, 0, 100, [0, 19, 20, 59])$.\n- Case C: $(80, 30, 0.01, 0.003, 80, 50, [0, 29, 30, 79])$.\n- Case D: $(50, 0, 0.05, 0.01, 0.5, 200, [0, 25, 49])$.\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list of lists enclosed in square brackets (for example, $[[\\text{list for Case A}],[\\text{list for Case B}],[\\text{list for Case C}],[\\text{list for Case D}]]$)).\n- Each inner list must contain the learning rate values $\\eta_t$ at the specified evaluation times for that case, in the same order as provided.\n- All returned values must be real numbers (floats). No physical units are used; angles are not used; do not use percentages anywhere.", "solution": "The user-provided problem statement is valid. It is scientifically grounded in optimization theory, specifically proximal gradient methods, and is directly relevant to learning rate scheduling in deep learning. The problem is well-posed, with all necessary parameters, definitions, and constraints provided to derive a unique solution. The language is objective and precise.\n\n### Step 1: Derivation of the Update Rule and Effective Step\n\nThe problem begins with the implicit-proximal update rule for the weight vector $\\mathbf{w}$ at iteration $t$:\n$$\n\\mathbf{w}_{t+1} \\in \\arg\\min_{\\mathbf{w}} \\left\\{ F(\\mathbf{w}) = \\frac{1}{2}\\left\\lVert \\mathbf{w} - \\left(\\mathbf{w}_t - \\eta_t \\nabla L(\\mathbf{w}_t)\\right)\\right\\rVert_2^2 + \\frac{\\eta_t \\lambda}{2} \\lVert \\mathbf{w} \\rVert_2^2 \\right\\}\n$$\nwhere $L(\\mathbf{w})$ is the data-fitting loss, $\\eta_t$ is the learning rate, and $\\lambda$ is the weight decay coefficient. The objective function $F(\\mathbf{w})$ is a strictly convex quadratic function of $\\mathbf{w}$, so its minimum can be found by setting its gradient with respect to $\\mathbf{w}$ to zero.\n\nLet $\\mathbf{c}_t = \\mathbf{w}_t - \\eta_t \\nabla L(\\mathbf{w}_t)$. The objective is:\n$$\nF(\\mathbf{w}) = \\frac{1}{2} (\\mathbf{w} - \\mathbf{c}_t)^T (\\mathbf{w} - \\mathbf{c}_t) + \\frac{\\eta_t \\lambda}{2} \\mathbf{w}^T \\mathbf{w}\n$$\nThe gradient $\\nabla_{\\mathbf{w}} F(\\mathbf{w})$ is:\n$$\n\\nabla_{\\mathbf{w}} F(\\mathbf{w}) = (\\mathbf{w} - \\mathbf{c}_t) + \\eta_t \\lambda \\mathbf{w}\n$$\nSetting the gradient to zero at $\\mathbf{w} = \\mathbf{w}_{t+1}$:\n$$\n(\\mathbf{w}_{t+1} - \\mathbf{c}_t) + \\eta_t \\lambda \\mathbf{w}_{t+1} = \\mathbf{0}\n$$\n$$\n\\mathbf{w}_{t+1}(1 + \\eta_t \\lambda) = \\mathbf{c}_t\n$$\n$$\n\\mathbf{w}_{t+1} = \\frac{1}{1 + \\eta_t \\lambda} \\mathbf{c}_t\n$$\nSubstituting back the definition of $\\mathbf{c}_t$:\n$$\n\\mathbf{w}_{t+1} = \\frac{1}{1 + \\eta_t \\lambda} \\left(\\mathbf{w}_t - \\eta_t \\nabla L(\\mathbf{w}_t)\\right)\n$$\n$$\n\\mathbf{w}_{t+1} = \\frac{1}{1 + \\eta_t \\lambda} \\mathbf{w}_t - \\frac{\\eta_t}{1 + \\eta_t \\lambda} \\nabla L(\\mathbf{w}_t)\n$$\nThis equation represents the standard Stochastic Gradient Descent (SGD) update with weight decay, where the weight decay term $\\frac{1}{1 + \\eta_t \\lambda}$ and the learning rate are coupled.\n\nThe problem defines the \"effective step\" $s_t$ as the scalar multiplying the negative gradient direction $-\\nabla L(\\mathbf{w}_t)$. From the derived update rule, we can identify $s_t$:\n$$\ns_t = \\frac{\\eta_t}{1 + \\eta_t \\lambda}\n$$\nTo control the schedule, we need to express the learning rate $\\eta_t$ as a function of the desired effective step $s_t$. We invert the aforementioned relationship:\n$$\ns_t (1 + \\eta_t \\lambda) = \\eta_t\n$$\n$$\ns_t + s_t \\eta_t \\lambda = \\eta_t\n$$\n$$\ns_t = \\eta_t (1 - s_t \\lambda)\n$$\n$$\n\\eta_t = \\frac{s_t}{1 - s_t \\lambda}\n$$\nFor $\\eta_t$ to be positive and well-defined, we must have $s_t  0$ and $1 - s_t \\lambda  0$, which implies $s_t \\lambda  1$.\n\n### Step 2: Design of the Effective Step Schedule $s(t)$\n\nThe effective step schedule $s(t)$ is piecewise.\n1.  **Warm-up Phase:** For iterations $t \\in \\{0, 1, \\dots, T_{\\mathrm{warm}}-1\\}$, the effective step is constant.\n    $$\n    s(t) = s_{\\mathrm{target}} \\quad \\text{for } t  T_{\\mathrm{warm}}\n    $$\n2.  **Decay Phase:** For iterations $t \\in \\{T_{\\mathrm{warm}}, T_{\\mathrm{warm}}+1, \\dots, T_{\\mathrm{total}}-1\\}$, the effective step undergoes a \"monotone exponential decay\". This is modeled as a geometric progression connecting $s(T_{\\mathrm{warm}}) = s_{\\mathrm{target}}$ to $s(T_{\\mathrm{total}}-1) = s_{\\min}$.\n\nLet the decay phase be defined on the interval $[T_{\\mathrm{warm}}, T_{\\mathrm{total}}-1]$. We require a function $s(t)$ such that $s(T_{\\mathrm{warm}}) = s_{\\mathrm{target}}$ and $s(T_{\\mathrm{total}}-1) = s_{\\min}$. An exponential function (geometric progression) that satisfies these boundary conditions is:\n$$\ns(t) = s_{\\mathrm{target}} \\cdot \\left(\\frac{s_{\\min}}{s_{\\mathrm{target}}}\\right)^{\\frac{t - T_{\\mathrm{warm}}}{(T_{\\mathrm{total}}-1) - T_{\\mathrm{warm}}}}\n$$\nThis is valid when the denominator $D = (T_{\\mathrm{total}}-1) - T_{\\mathrm{warm}} = T_{\\mathrm{total}} - T_{\\mathrm{warm}} - 1$ is positive.\n\nWe must handle edge cases:\n-   If $T_{\\mathrm{total}} - T_{\\mathrm{warm}} - 1  0$: The above formula applies.\n-   If $T_{\\mathrm{total}} - T_{\\mathrm{warm}} - 1 = 0$, i.e., $T_{\\mathrm{total}} = T_{\\mathrm{warm}} + 1$: The decay phase consists of a single point, $t=T_{\\mathrm{warm}}$. Since $t=T_{\\mathrm{warm}}$ is also the final iteration $T_{\\mathrm{total}}-1$, the value must be $s_{\\min}$. This creates a discontinuity at $t=T_{\\mathrm{warm}}$. So, $s(T_{\\mathrm{warm}}) = s_{\\min}$.\n-   If $T_{\\mathrm{total}} - T_{\\mathrm{warm}} - 1  0$, i.e., $T_{\\mathrm{total}} \\le T_{\\mathrm{warm}}$: The decay phase is empty. All iterations $t \\in \\{0, \\dots, T_{\\mathrm{total}}-1\\}$ fall into the warm-up phase, as $t  T_{\\mathrm{total}} \\le T_{\\mathrm{warm}}$. Thus, $s(t) = s_{\\mathrm{target}}$ for all relevant $t$.\n\n### Step 3: The Complete Learning Rate Schedule $\\eta_t$\n\nThe final learning rate schedule $\\eta_t$ is constructed by combining the above elements and applying the upper-bound constraint. For any given iteration $t \\in \\{0, 1, \\dots, T_{\\mathrm{total}}-1\\}$:\n1.  Determine the effective step $s(t)$ using the piecewise schedule defined in Step 2.\n2.  Calculate the unconstrained learning rate, $\\eta_t^{\\text{unconstrained}} = \\frac{s(t)}{1 - s(t) \\lambda}$.\n3.  Determine the maximum allowed learning rate, $\\eta_{\\max} = \\frac{2}{L_g}$.\n4.  The final learning rate is the unconstrained value clipped at $\\eta_{\\max}$:\n    $$\n    \\eta_t = \\min(\\eta_t^{\\text{unconstrained}}, \\eta_{\\max})\n    $$\n\n### Step 4: Implementation\n\nThe following self-contained program implements the derived learning rate schedule and computes the required values for the provided test cases. The logic is encapsulated in a function that computes $\\eta_t$ for a given $t$ and set of parameters, which is then called for each specified evaluation time in the test suite. The final output is formatted as a list of lists.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It computes the learning rate at specified iterations for each case\n    and prints the results in the required format.\n    \"\"\"\n    test_cases = [\n        # (T_total, T_warm, s_target, s_min, lambda, L_g, eval_times)\n        (100, 40, 0.01, 0.002, 0.1, 50, [0, 20, 40, 60, 99]),\n        (60, 20, 0.02, 0.005, 0, 100, [0, 19, 20, 59]),\n        (80, 30, 0.01, 0.003, 80, 50, [0, 29, 30, 79]),\n        (50, 0, 0.05, 0.01, 0.5, 200, [0, 25, 49]),\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        T_total, T_warm, s_target, s_min, lambd, L_g, eval_times = case\n        \n        eta_max = 2.0 / L_g\n        \n        # Pre-calculate constants for the decay phase\n        decay_duration_denominator = float(T_total - 1 - T_warm)\n        if decay_duration_denominator > 0:\n            ratio = s_min / s_target\n\n        case_results = []\n        for t in eval_times:\n            # 1. Determine the effective step s(t)\n            s_t = 0.0\n            if t  T_warm:\n                s_t = s_target\n            else: # t >= T_warm\n                if decay_duration_denominator = 0:\n                    # This case corresponds to T_total = T_warm + 1.\n                    # As per the derived logic, if the decay phase has one point,\n                    # its value must be s_min. This occurs at t = T_total - 1.\n                    # For t > T_warm but t  T_total - 1 in this scenario (which is impossible),\n                    # we would continue s_target, but since the only valid t is T_total - 1,\n                    # the value is simply s_min.\n                    s_t = s_min\n                else:\n                    # Standard exponential decay\n                    exponent = (t - T_warm) / decay_duration_denominator\n                    s_t = s_target * (ratio ** exponent)\n\n            # 2. Calculate the unconstrained learning rate\n            # Denominator is 1 - s_t * lambda. This should be > 0.\n            # It is guaranteed by problem constraints and schedule design (s(t) = s_target).\n            eta_unconstrained = s_t / (1.0 - s_t * lambd)\n\n            # 3. Apply the upper-bound constraint\n            eta_t = min(eta_unconstrained, eta_max)\n            case_results.append(eta_t)\n            \n        all_results.append(case_results)\n\n    # Final print statement in the exact required format.\n    # We manually format the lists to avoid spaces.\n    inner_lists_str = []\n    for res_list in all_results:\n        # Use a high-precision format for floating point numbers\n        inner_lists_str.append(f\"[{','.join(f'{val:.17g}' for val in res_list)}]\")\n    \n    print(f\"[{','.join(inner_lists_str)}]\")\n\nsolve()\n```", "id": "3142924"}, {"introduction": "While pre-defined schedules are powerful, the most robust training pipelines react to a model's live performance. This exercise guides you through building an adaptive scheduler that monitors a synthetic validation loss, using moving averages to detect plateaus and signs of overfitting [@problem_id:3142901]. You will implement a system that automatically reduces the learning rate, mimicking popular library functions and learning to quantify its reliability.", "problem": "You are tasked with designing and testing a learning rate (LR) scheduling policy that is triggered by early stopping (ES) style detectors and validated by validation moving average (MA) crossovers, while quantifying the rate of false positives. The objective is to implement the detector logic from first principles and apply it to synthetic but scientifically plausible validation loss sequences. The schedule should reduce the learning rate during cooldown phases whenever the evidence suggests training stagnation or deterioration. Your program must output a compact summary for a small test suite of cases.\n\nBase principles to use and build on:\n- Gradient-based learning uses updates of the form $x_{t+1} = x_t - \\eta_t g_t$, where $x_t$ is the parameter vector at epoch $t$, $g_t$ is the gradient estimate, and $\\eta_t \\gt 0$ is the learning rate (LR) at epoch $t$. The schedule controls $\\eta_t$.\n- Early stopping (ES) monitors a validation criterion to detect the absence of improvement over a patience window. A detector is a logical predicate driven by observable validation statistics.\n- Moving averages (MAs) serve as noise-reduction statistics. The Simple Moving Average (SMA) of a validation sequence $(y_t)$ over window size $w$ at time $t$ is the mean of the last $w$ available values (use a shorter window if fewer than $w$ values exist), that is\n$$\n\\operatorname{SMA}_w(t) = \\frac{1}{m}\\sum_{i=t-m+1}^{t} y_i,\\quad m=\\min(w, t+1).\n$$\n\nSchedule definitions to implement:\n- Let the initial learning rate be $\\eta_0 \\gt 0$. Each time the scheduler triggers, multiply the current LR by a decay factor $\\gamma$ with $0 \\lt \\gamma \\lt 1$, and enter a cooldown phase lasting $c$ epochs. During cooldown, no new triggers are allowed. The LR persists at its most recently decayed value after cooldowns.\n- Maintain two Simple Moving Averages: a short-term SMA with window $w_s$ and a long-term SMA with window $w_\\ell$, with $w_s \\lt w_\\ell$. Denote them by $S_t = \\operatorname{SMA}_{w_s}(t)$ and $L_t = \\operatorname{SMA}_{w_\\ell}(t)$.\n- Maintain the best smoothed value observed so far, $B_t = \\min_{0 \\le i \\le t} S_i$. An improvement at time $t$ occurs if $S_t \\lt B_{t-1} - \\varepsilon$, where $\\varepsilon \\ge 0$ is a tolerance. When an improvement occurs, update $B_t = S_t$ and record the epoch $t$ as the most recent improve time.\n- Define the Early Stopping (ES) condition at time $t$ to hold if no improvements have occurred in the last $p$ epochs, i.e., $t - \\text{last\\_improve} \\ge p$.\n- Define the crossover confirmation condition at time $t$ to hold if $(S_i - L_i) \\ge \\delta$ has been true for at least the most recent $k$ consecutive epochs (including $t$), for some $\\delta \\ge 0$ and integer $k \\ge 1$.\n- Trigger rule: when not in cooldown, if both the ES condition and the crossover confirmation condition hold at time $t$, then trigger a cooldown starting at epoch $t$, set $\\eta \\leftarrow \\gamma \\eta$, and block further triggers until the cooldown elapses.\n\nFalse positive definition:\n- A trigger at epoch $t_0$ is a false positive if within the next $q$ epochs $(t_0+1,\\dots,\\min(T-1, t_0+q))$ there exists a new best raw validation loss strictly below the best raw validation loss observed up to $t_0$ by at least $\\varepsilon$. Formally, let $y_t$ be the raw validation loss, $b_{\\text{raw}}(t_0) = \\min_{0 \\le i \\le t_0} y_i$. The trigger is a false positive if\n$$\n\\min_{t_0+1 \\le j \\le \\min(T-1, t_0+q)} y_j \\le b_{\\text{raw}}(t_0) - \\varepsilon.\n$$\n\nValidation loss generator:\n- For a sequence length $T$, define for epochs $t \\in \\{0,1,\\dots,T-1\\}$ the raw validation loss\n$$\ny_t = a + b \\exp\\!\\left(-\\frac{t}{\\tau}\\right) + u \\cdot \\frac{\\max(0,\\, t - t_u)}{T} + \\epsilon_t,\n$$\nwhere $\\epsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$. Use a Pseudo-Random Number Generator (PRNG) with a specified integer seed for reproducibility. The term with $u$ introduces a gentle upward drift after $t_u$ to simulate overfitting.\n\nTask:\n- Implement the schedule and detector as specified, driven by the synthetic validation loss. Use epoch indexing starting at $t=0$. Use Simple Moving Averages computed over available samples near the beginning as described above. When a trigger occurs at epoch $t$, include that epoch as the first epoch of the cooldown of length $c$.\n- For each test case below, compute:\n    1. The total number of cooldown triggers (an integer).\n    2. The number of false positives (an integer).\n    3. The final learning rate (a float), starting from $\\eta_0$ and multiplying by $\\gamma$ for each trigger.\n\nTest suite:\n- Use initial learning rate $\\eta_0 = 0.1$ for all cases.\n\n- Case A (happy path with mild overfitting tail):\n    - Sequence parameters: $T = 60$, $a = 0.2$, $b = 0.9$, $\\tau = 16$, $\\sigma = 0.008$, $u = 0.12$, $t_u = 45$, seed $= 0$.\n    - Schedule parameters: $\\gamma = 0.5$, $c = 5$, $p = 5$, $w_s = 3$, $w_\\ell = 9$, $k = 2$, $\\delta = 0.002$, $\\varepsilon = 0.0005$, $q = 4$.\n\n- Case B (continued improvement, no drift):\n    - Sequence parameters: $T = 40$, $a = 0.1$, $b = 0.8$, $\\tau = 30$, $\\sigma = 0.005$, $u = 0.0$, $t_u = 100$, seed $= 1$.\n    - Schedule parameters: $\\gamma = 0.5$, $c = 6$, $p = 7$, $w_s = 2$, $w_\\ell = 8$, $k = 3$, $\\delta = 0.001$, $\\varepsilon = 0.0005$, $q = 5$.\n\n- Case C (noisy flat region to probe false positives):\n    - Sequence parameters: $T = 50$, $a = 0.5$, $b = 0.0$, $\\tau = 1$, $\\sigma = 0.02$, $u = 0.0$, $t_u = 0$, seed $= 2$.\n    - Schedule parameters: $\\gamma = 0.5$, $c = 4$, $p = 3$, $w_s = 1$, $w_\\ell = 6$, $k = 1$, $\\delta = 0.0$, $\\varepsilon = 0.0025$, $q = 5$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Aggregate the results for all cases into a single list of lists, one inner list per case in the order A, B, C. Each inner list must be of the form $[\\text{num\\_cooldowns},\\text{num\\_false\\_positives},\\text{final\\_lr}]$. The final string must contain no spaces. For example, a valid output form is\n\"[[1,0,0.05],[0,0,0.1],[3,2,0.0125]]\".", "solution": "The user requires the design and implementation of a learning rate (LR) scheduling policy based on early stopping (ES) principles and moving average (MA) crossovers. The task involves simulating the scheduler's behavior on synthetic validation loss data and quantifying its performance, specifically the number of LR reductions and the rate of false positives.\n\nThe solution is developed by first principles as a discrete-time simulation over a series of epochs $t \\in \\{0, 1, \\dots, T-1\\}$.\n\n**1. Synthetic Validation Loss Generation**\n\nFor each test case, a sequence of raw validation losses, denoted by $y_t$, is generated for a total of $T$ epochs. The function used to generate this data is:\n$$\ny_t = a + b \\exp\\left(-\\frac{t}{\\tau}\\right) + u \\cdot \\frac{\\max(0, t - t_u)}{T} + \\epsilon_t\n$$\nThis model is scientifically plausible for representing validation loss curves during model training:\n- The constant term $a$ represents the irreducible error or the asymptotic loss value.\n- The term $b \\exp(-t/\\tau)$ models the initial phase of learning, where the loss decreases exponentially with a time constant $\\tau$.\n- The term $u \\cdot \\frac{\\max(0, t - t_u)}{T}$ simulates the onset of overfitting after epoch $t_u$, introducing a linear upward drift in the loss, scaled by a factor $u$.\n- The term $\\epsilon_t$ is a random noise component, sampled from a normal distribution $\\mathcal{N}(0, \\sigma^2)$, which represents the stochasticity inherent in mini-batch gradient descent and validation.\n\nReproducibility is ensured by using a specific integer seed for the pseudo-random number generator (PRNG) for each case. The entire sequence of $\\{y_t\\}_{t=0}^{T-1}$ is generated upfront before the main scheduler simulation begins.\n\n**2. Scheduler Design and State Evolution**\n\nThe scheduler's logic is executed at each epoch $t$. Its behavior is determined by a set of internal state variables and predefined rules.\n\n- **State Variables**:\n    - $\\eta_t$: The learning rate at epoch $t$, initialized to $\\eta_0$.\n    - Cooldown period: A state indicating whether the scheduler is temporarily inactive. We track `cooldown_until`, the first epoch after the cooldown period where the scheduler becomes active again.\n    - $B_t$: The best (lowest) smoothed validation loss observed so far. It is initialized to $B_{-1} = \\infty$.\n    - `last_improve_epoch`: The epoch $t$ at which the last significant improvement in smoothed loss occurred.\n    - Crossover streak counter: Tracks the number of consecutive epochs the crossover condition has been met.\n\n- **Moving Averages (SMAs)**: At each epoch $t$, two Simple Moving Averages of the raw loss $y_t$ are computed to smooth out noise:\n    - Short-term SMA: $S_t = \\operatorname{SMA}_{w_s}(t) = \\frac{1}{\\min(w_s, t+1)}\\sum_{i=t-\\min(w_s, t+1)+1}^{t} y_i$\n    - Long-term SMA: $L_t = \\operatorname{SMA}_{w_\\ell}(t) = \\frac{1}{\\min(w_\\ell, t+1)}\\sum_{i=t-\\min(w_\\ell, t+1)+1}^{t} y_i$\n    where $w_s  w_\\ell$ are the respective window sizes. The short-term SMA $S_t$ is more responsive to recent changes, while the long-term SMA $L_t$ reflects the broader trend.\n\n- **Simulation Loop (Epoch $t = 0, \\dots, T-1$)**:\n    1. **Compute SMAs**: Calculate $S_t$ and $L_t$ from the historical raw loss data $\\{y_i\\}_{i=0}^{t}$.\n    2.  **Check for Improvement**: An improvement is registered if the current short-term SMA $S_t$ is significantly better than the best value seen so far, $B_{t-1}$. The condition is $S_t  B_{t-1} - \\varepsilon$, where $\\varepsilon \\ge 0$ is a minimum improvement threshold. If this condition is met, the state is updated: $B_t = S_t$ and `last_improve_epoch` is set to $t$. Otherwise, $B_t = B_{t-1}$. At $t=0$, an improvement is assumed, so $B_0=S_0$ and `last_improve_epoch` is set to $0$.\n    3.  **Check for Trigger**: A trigger for LR reduction can only occur if the scheduler is not in a cooldown period (i.e., $t \\ge \\text{cooldown\\_until}$). The trigger requires two conditions to be met simultaneously:\n        -   **Early Stopping (ES) Condition**: No significant improvement has been observed for a specified number of epochs. This is true if $t - \\text{last\\_improve\\_epoch} \\ge p$, where $p$ is the patience parameter.\n        -   **Crossover Confirmation Condition**: The short-term SMA has been consistently above the long-term SMA, indicating a potential reversal of the learning trend (i.e., loss starting to increase). This is true if the condition $(S_i - L_i) \\ge \\delta$ has held for the last $k$ consecutive epochs (from $t-k+1$ to $t$), where $\\delta \\ge 0$ is a tolerance and $k \\ge 1$ is the confirmation length.\n    4.  **Trigger Action**: If both conditions are met, a trigger event occurs at epoch $t$. The learning rate is reduced by a multiplicative factor $\\gamma$ (i.e., $\\eta \\leftarrow \\gamma \\cdot \\eta$), and a new cooldown period of $c$ epochs is initiated. This prevents further triggers until epoch $t+c$. The epoch of the trigger is recorded for later analysis.\n\n**3. False Positive Analysis**\n\nAfter the simulation over all $T$ epochs is complete, a post-hoc analysis is performed to identify false positives among the recorded triggers. A trigger at epoch $t_0$ is defined as a false positive if, despite the scheduler's decision to reduce the LR, the model would have achieved a new best raw validation loss within a short lookahead window of $q$ epochs.\n\nFormally, for each trigger epoch $t_0$, we compute:\n- The best raw loss up to the trigger: $b_{\\text{raw}}(t_0) = \\min_{0 \\le i \\le t_0} y_i$.\n- The minimum raw loss in the subsequent $q$ epochs: $\\min_{t_0+1 \\le j \\le \\min(T-1, t_0+q)} y_j$.\n\nThe trigger at $t_0$ is counted as a false positive if:\n$$\n\\min_{t_0+1 \\le j \\le \\min(T-1, t_0+q)} y_j \\le b_{\\text{raw}}(t_0) - \\varepsilon\n$$\nThis condition means that a new raw loss, strictly better by at least the tolerance $\\varepsilon$, was found shortly after the LR was reduced, suggesting the reduction may have been premature.\n\nThe final implementation encapsulates this entire logic into a function that is executed for each provided test case, and the results — total triggers, false positives, and final LR — are aggregated.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the simulation.\n    \"\"\"\n\n    def run_case(T, a, b, tau, sigma, u, t_u, seed,\n                 eta_0, gamma, c, p, w_s, w_ell, k, delta, epsilon, q):\n        \"\"\"\n        Runs a single simulation case for the LR scheduler.\n\n        Returns:\n            A list containing [num_triggers, num_false_positives, final_lr].\n        \"\"\"\n        # 1. Generate the full raw validation loss sequence\n        rng = np.random.default_rng(seed)\n        epochs = np.arange(T)\n        noise = rng.normal(0, sigma, T)\n        drift = u * np.maximum(0, epochs - t_u) / T\n        y_raw = a + b * np.exp(-epochs / tau) + drift + noise\n\n        # 2. Initialize scheduler state variables\n        lr = eta_0\n        cooldown_until = 0\n        trigger_epochs = []\n        \n        best_smooth_loss = np.inf\n        last_improve_epoch = 0\n        consecutive_crossover_count = 0\n        \n        # 3. Main simulation loop over epochs\n        for t in range(T):\n            # Compute Short-term and Long-term Simple Moving Averages (SMAs)\n            m_s = min(w_s, t + 1)\n            S_t = np.mean(y_raw[t - m_s + 1 : t + 1])\n\n            m_ell = min(w_ell, t + 1)\n            L_t = np.mean(y_raw[t - m_ell + 1 : t + 1])\n\n            # Check for improvement in smoothed loss\n            if t == 0:\n                best_smooth_loss = S_t\n                last_improve_epoch = 0\n            else:\n                if S_t  best_smooth_loss - epsilon:\n                    best_smooth_loss = S_t\n                    last_improve_epoch = t\n\n            # Check for trigger conditions if not in cooldown\n            if t >= cooldown_until:\n                # Early Stopping condition: patience exceeded\n                es_holds = (t - last_improve_epoch) >= p\n\n                # Crossover confirmation condition\n                if (S_t - L_t) >= delta:\n                    consecutive_crossover_count += 1\n                else:\n                    consecutive_crossover_count = 0\n                \n                crossover_holds = consecutive_crossover_count >= k\n\n                # If both conditions hold, trigger LR reduction\n                if es_holds and crossover_holds:\n                    lr *= gamma\n                    cooldown_until = t + c\n                    trigger_epochs.append(t)\n        \n        num_triggers = len(trigger_epochs)\n\n        # 4. Post-hoc analysis for false positives\n        num_false_positives = 0\n        for t0 in trigger_epochs:\n            best_raw_loss_at_trigger = np.min(y_raw[:t0 + 1])\n            \n            j_start = t0 + 1\n            j_end_inclusive = min(T - 1, t0 + q)\n            \n            # Check if lookahead window is valid\n            if j_start > j_end_inclusive:\n                continue\n                \n            future_losses = y_raw[j_start : j_end_inclusive + 1]\n            min_future_loss = np.min(future_losses)\n\n            if min_future_loss = best_raw_loss_at_trigger - epsilon:\n                num_false_positives += 1\n\n        return [num_triggers, num_false_positives, lr]\n\n    # Define the test suite as specified in the problem\n    test_cases = [\n        # Case A: Happy path with mild overfitting tail\n        dict(\n            T=60, a=0.2, b=0.9, tau=16, sigma=0.008, u=0.12, t_u=45, seed=0,\n            eta_0=0.1, gamma=0.5, c=5, p=5, w_s=3, w_ell=9, k=2, delta=0.002,\n            epsilon=0.0005, q=4\n        ),\n        # Case B: Continued improvement, no drift\n        dict(\n            T=40, a=0.1, b=0.8, tau=30, sigma=0.005, u=0.0, t_u=100, seed=1,\n            eta_0=0.1, gamma=0.5, c=6, p=7, w_s=2, w_ell=8, k=3, delta=0.001,\n            epsilon=0.0005, q=5\n        ),\n        # Case C: Noisy flat region to probe false positives\n        dict(\n            T=50, a=0.5, b=0.0, tau=1, sigma=0.02, u=0.0, t_u=0, seed=2,\n            eta_0=0.1, gamma=0.5, c=4, p=3, w_s=1, w_ell=6, k=1, delta=0.0,\n            epsilon=0.0025, q=5\n        ),\n    ]\n\n    # Run all test cases and collect results\n    results = [run_case(**case) for case in test_cases]\n\n    # Format the final output string as required\n    print(str(results).replace(' ', ''))\n\nsolve()\n```", "id": "3142901"}, {"introduction": "Let's explore a novel way to think about scheduling by modeling the training process itself. In this final practice, you will implement a scheduler as a Finite-State Machine (FSM) with states like \"explore,\" \"exploit,\" and \"consolidate,\" where transitions are governed by the recent behavior of the loss function [@problem_id:3142941]. This exercise encourages you to conceptualize optimization as a sequence of discrete phases, providing a structured, rule-based alternative to continuous decay schedules.", "problem": "You are asked to formalize a principled, adaptive learning rate scheduler as a Finite-State Machine (FSM) and to compare its emitted learning rates against a continuous schedule. Begin from the core iterative update law of gradient-based optimization used in deep learning, which is the Stochastic Gradient Descent (SGD) step, given by the well-tested formula\n$$\n\\theta_{t+1} = \\theta_t - \\eta_t \\, g_t,\n$$\nwhere $\\theta_t$ denotes the parameter vector at iteration $t$, $g_t$ is the gradient of the loss, and $\\eta_t$ is the learning rate at iteration $t$. The scheduler you implement will not have access to gradients; instead, it must infer when it is safe to increase exploration (larger learning rate), when to exploit a good direction (moderate learning rate), or when to consolidate around a local basin (small learning rate), using only recent loss observations and their discrete trend and curvature. You will also implement two well-tested continuous schedules and compare their emitted learning rates to those of the FSM.\n\nDefinitions to use:\n- Consider a scalar loss sequence $\\{L_t\\}_{t=0}^{T-1}$ observed over discrete iterations $t \\in \\{0,1,\\dots,T-1\\}$.\n- Define first differences (trend proxies) by $d_t = L_t - L_{t-1}$ for $t \\ge 1$. A negative $d_t$ indicates decreasing loss.\n- Define second differences (curvature proxies) by $e_t = d_t - d_{t-1}$ for $t \\ge 2$. A positive $e_t$ indicates that the loss decrease is decelerating (curving upward), while a negative $e_t$ indicates acceleration in the decrease (curving downward).\n- Over a sliding window of $W$ consecutive loss values ending at time $t$ (i.e., $\\{L_{t-W+1},\\dots,L_t\\}$ with $t \\ge W-1$), define the averaged trend and curvature:\n$$\ns_t = \\frac{1}{W-1} \\sum_{j=t-W+2}^{t} d_j, \\quad\nk_t = \\frac{1}{W-2} \\sum_{j=t-W+3}^{t} e_j,\n$$\nwhere $W \\in \\mathbb{N}$ and $W \\ge 3$.\n- Define the number of sign changes in the recent trend over the last $W-1$ first differences as the count of index pairs $(j-1,j)$ with $d_{j-1} \\cdot d_j  0$ within the window; this captures oscillatory behavior.\n\nFinite-State Machine (FSM) model:\n- States $\\mathcal{S} = \\{\\text{explore}, \\text{exploit}, \\text{consolidate}\\}$, encoded as integers $\\{0,1,2\\}$ respectively.\n- Associated state learning rates are constants: $\\eta_{\\text{explore}} = 0.1$, $\\eta_{\\text{exploit}} = 0.02$, $\\eta_{\\text{consolidate}} = 0.005$.\n- Window size $W = 4$.\n- Trend threshold $\\alpha = 0.02$ and curvature threshold $\\beta = 0.005$.\n- Initialization: at $t=0$ the FSM is in state $\\text{explore}$.\n- At each time step $t$:\n  - If $t  W-1$, the scheduler cannot compute $s_t$ and $k_t$; it must keep the current state unchanged and emit the learning rate associated with the current state.\n  - If $t \\ge W-1$, compute $s_t$ and $k_t$ using the definitions above, and let $\\text{osc}_t$ be the number of sign changes of $\\{d_{t-W+2},\\dots,d_t\\}$.\n  - Apply the following transition rules to determine the state for time $t$, then emit the learning rate of the resulting state for time $t$:\n    - From $\\text{explore}$ (state $0$):\n      - If $s_t \\le -\\alpha$ and $k_t  \\beta$, transition to $\\text{exploit}$ (state $1$).\n      - Else if $s_t \\ge 0$, remain in $\\text{explore}$.\n      - Else if $-\\alpha  s_t  0$ and $k_t \\ge \\beta$, transition to $\\text{consolidate}$ (state $2$).\n      - Else remain in $\\text{explore}$.\n    - From $\\text{exploit}$ (state $1$):\n      - If $s_t \\le -\\alpha$ and $k_t  \\beta$, remain in $\\text{exploit}$.\n      - Else if $s_t \\ge 0$, transition to $\\text{consolidate}$.\n      - Else if $-\\alpha  s_t  0$ and $k_t \\ge \\beta$, transition to $\\text{consolidate}$.\n      - Else remain in $\\text{exploit}$.\n    - From $\\text{consolidate}$ (state $2$):\n      - If $s_t \\le -\\alpha$ and $k_t  \\beta$, transition to $\\text{exploit}$.\n      - Else if $s_t \\ge 0$ and $\\text{osc}_t \\ge 2$, transition to $\\text{explore}$.\n      - Else remain in $\\text{consolidate}$.\n\nContinuous schedules for comparison:\n- Exponential decay from $\\eta_0 = \\eta_{\\text{explore}}$ to $\\eta_{\\text{end}} = \\eta_{\\text{consolidate}}$ over $T$ steps:\n$$\n\\eta_t^{\\text{exp}} = \\eta_0 \\left(\\frac{\\eta_{\\text{end}}}{\\eta_0}\\right)^{\\frac{t}{\\max(1,T-1)}}, \\quad t \\in \\{0,\\dots,T-1\\}.\n$$\n- Cosine annealing from $\\eta_0$ to $\\eta_{\\text{end}}$ over $T$ steps using the standard $\\cos$ function in radians:\n$$\n\\eta_t^{\\cos} = \\eta_{\\text{end}} + \\frac{1}{2}(\\eta_0 - \\eta_{\\text{end}})\\left(1 + \\cos\\left(\\pi \\cdot \\frac{t}{\\max(1,T-1)}\\right)\\right).\n$$\n\nComparison metric:\n- For a given loss sequence and scheduler pair, compute the mean absolute difference (MAD) between the FSM-emitted learning rate sequence $\\{\\eta_t^{\\text{FSM}}\\}_{t=0}^{T-1}$ and the continuous schedule sequence $\\{\\eta_t^{\\text{cont}}\\}_{t=0}^{T-1}$:\n$$\n\\text{MAD} = \\frac{1}{T} \\sum_{t=0}^{T-1} \\left| \\eta_t^{\\text{FSM}} - \\eta_t^{\\text{cont}} \\right|.\n$$\n\nTask:\n- Implement a program that, for each test case below, constructs the FSM learning rate sequence and the continuous schedule sequence, computes the MAD, counts the number of state transitions executed by the FSM, and reports the final FSM state and final FSM learning rate.\n\nTest suite:\n- Use the constants specified above: $W=4$, $\\alpha=0.02$, $\\beta=0.005$, $\\eta_{\\text{explore}}=0.1$, $\\eta_{\\text{exploit}}=0.02$, $\\eta_{\\text{consolidate}}=0.005$.\n- Angle inputs to $\\cos(\\cdot)$ must be in radians.\n- Test cases are given as $(\\{L_t\\}_{t=0}^{T-1}, \\text{schedule})$ pairs with $\\text{schedule} \\in \\{\\text{\"exp\"}, \\text{\"cosine\"}\\}$:\n  1. $([1.0, 0.95, 0.87, 0.75, 0.59, 0.38, 0.11], \\text{\"exp\"})$.\n  2. $([1.0, 1.0, 1.005, 1.003, 1.006, 1.010], \\text{\"cosine\"})$.\n  3. $([1.0, 0.95, 0.92, 0.90, 0.89, 0.885, 0.883], \\text{\"exp\"})$.\n  4. $([1.0, 0.98, 0.96], \\text{\"cosine\"})$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where the $i$-th element corresponds to test case $i$ and is itself a list with four entries:\n  - Final FSM state code as an integer in $\\{0,1,2\\}$.\n  - Mean absolute difference as a real number rounded to six decimal places.\n  - Number of state transitions as a nonnegative integer.\n  - Final FSM learning rate as a real number rounded to six decimal places.\n- Concretely, your output must be a single line like\n$$\n[\\,[\\text{state}_1, \\text{mad}_1, \\text{trans}_1, \\text{final\\_lr}_1],\\; [\\text{state}_2, \\text{mad}_2, \\text{trans}_2, \\text{final\\_lr}_2],\\; [\\text{state}_3, \\text{mad}_3, \\text{trans}_3, \\text{final\\_lr}_3],\\; [\\text{state}_4, \\text{mad}_4, \\text{trans}_4, \\text{final\\_lr}_4]\\,],\n$$\nwith all real numbers rounded to six decimals. No other text should be printed.", "solution": "The problem statement has been meticulously validated and is determined to be valid. It is scientifically grounded in the principles of numerical optimization for deep learning, is well-posed with unambiguous definitions and rules, and is presented objectively. The task is to formalize and implement a rule-based learning rate scheduler as a Finite-State Machine (FSM) and compare its output to two standard continuous schedules.\n\nThe solution proceeds by first implementing the FSM scheduler, then the continuous schedulers, and finally the comparison metric. The entire process is executed for each provided test case.\n\n### 1. Finite-State Machine (FSM) Scheduler\n\nThe FSM is designed to adapt the learning rate $\\eta_t$ based on local properties of the loss function $L_t$, estimated using a sliding window of recent loss values.\n\n**State Representation and Parameters:**\nThe FSM operates with three states, encoded as integers:\n- State $0$: $\\text{explore}$ (high learning rate, $\\eta_{\\text{explore}} = 0.1$)\n- State $1$: $\\text{exploit}$ (medium learning rate, $\\eta_{\\text{exploit}} = 0.02$)\n- State $2$: $\\text{consolidate}$ (low learning rate, $\\eta_{\\text{consolidate}} = 0.005$)\n\nThe key parameters controlling the FSM's behavior are the window size $W=4$, the trend threshold $\\alpha=0.02$, and the curvature threshold $\\beta=0.005$.\n\n**FSM Dynamics:**\nThe FSM's state evolves over time $t=0, 1, \\dots, T-1$. Let $S_t$ be the state at iteration $t$.\n- **Initialization**: At $t=0$, the FSM starts in the $\\text{explore}$ state, so $S_0 = 0$.\n- **State Evolution**: For each subsequent time step $t0$, the state $S_t$ is determined based on the previous state $S_{t-1}$ and, if enough data is available, on computed metrics.\n  - If $t  W-1$ (i.e., $t \\in \\{1, 2\\}$ for $W=4$), there are not enough loss values to form a full window. The FSM remains in its previous state: $S_t = S_{t-1}$.\n  - If $t \\ge W-1$ (i.e., $t \\ge 3$), we can compute the local trend and curvature metrics. We use the loss values from the window $\\{L_{t-W+1}, \\dots, L_t\\}$, which are $\\{L_{t-3}, L_{t-2}, L_{t-1}, L_t\\}$ for $W=4$.\n    - The first differences are $d_j = L_j - L_{j-1}$. We need $d_{t}, d_{t-1}, d_{t-2}$.\n    - The second differences are $e_j = d_j - d_{j-1}$. We need $e_{t}, e_{t-1}$.\n    - The averaged trend is $s_t = \\frac{1}{W-1} \\sum_{j=t-W+2}^{t} d_j = \\frac{1}{3}(d_{t-2} + d_{t-1} + d_t)$.\n    - The averaged curvature is $k_t = \\frac{1}{W-2} \\sum_{j=t-W+3}^{t} e_j = \\frac{1}{2}(e_{t-1} + e_t)$.\n    - The trend oscillation count $\\text{osc}_t$ is the number of times the sign of $d_j$ changes in the sequence $\\{d_{t-2}, d_{t-1}, d_t\\}$.\n\nThe state $S_t$ is then determined by applying the transition rules to the previous state $S_{t-1}$ using the computed values of $s_t$, $k_t$, and $\\text{osc}_t$. The learning rate for the current step, $\\eta_t^{\\text{FSM}}$, is the one associated with the *new* state $S_t$. A state transition is counted if $S_t \\neq S_{t-1}$.\n\n### 2. Continuous Learning Rate Schedules\n\nFor comparison, two standard continuous schedules are implemented. Both decay from an initial learning rate $\\eta_0 = \\eta_{\\text{explore}} = 0.1$ to a final rate $\\eta_{\\text{end}} = \\eta_{\\text{consolidate}} = 0.005$ over $T$ total iterations. Let $N = \\max(1, T-1)$ be the number of decay steps.\n\n- **Exponential Decay**: The learning rate decays exponentially according to the formula:\n  $$ \\eta_t^{\\text{exp}} = \\eta_0 \\left(\\frac{\\eta_{\\text{end}}}{\\eta_0}\\right)^{\\frac{t}{N}} $$\n- **Cosine Annealing**: The learning rate follows a cosine trajectory:\n  $$ \\eta_t^{\\cos} = \\eta_{\\text{end}} + \\frac{1}{2}(\\eta_0 - \\eta_{\\text{end}})\\left(1 + \\cos\\left(\\pi \\frac{t}{N}\\right)\\right) $$\n\n### 3. Comparison and Output Metrics\n\nFor each test case, we compute the following four metrics:\n1.  **Final FSM State**: The integer code of the state $S_{T-1}$ at the last iteration.\n2.  **Mean Absolute Difference (MAD)**: This measures the average deviation between the FSM's learning rate sequence and the corresponding continuous schedule's sequence:\n    $$ \\text{MAD} = \\frac{1}{T} \\sum_{t=0}^{T-1} \\left| \\eta_t^{\\text{FSM}} - \\eta_t^{\\text{cont}} \\right| $$\n3.  **Number of State Transitions**: The total count of times the FSM changed its state, i.e., $\\sum_{t=1}^{T-1} \\mathbb{I}(S_t \\neq S_{t-1})$, where $\\mathbb{I}(\\cdot)$ is the indicator function.\n4.  **Final FSM Learning Rate**: The learning rate $\\eta_{T-1}^{\\text{FSM}}$ emitted at the last iteration.\n\nThe program iterates through each test case, performs these calculations, and formats the results as specified. A key part of the implementation is the careful handling of indices and conditions, especially for the FSM state updates which depend on a sliding window of historical data.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function that processes all test cases and prints the final result.\n    \"\"\"\n    \n    # Define constants from the problem description\n    ETA_EXPLORE = 0.1\n    ETA_EXPLOIT = 0.02\n    ETA_CONSOLIDATE = 0.005\n    W = 4\n    ALPHA = 0.02\n    BETA = 0.005\n    \n    # State-to-LR mapping\n    LR_MAP = {0: ETA_EXPLORE, 1: ETA_EXPLOIT, 2: ETA_CONSOLIDATE}\n\n    # Test cases from the problem statement\n    test_cases = [\n        (np.array([1.0, 0.95, 0.87, 0.75, 0.59, 0.38, 0.11]), \"exp\"),\n        (np.array([1.0, 1.0, 1.005, 1.003, 1.006, 1.010]), \"cosine\"),\n        (np.array([1.0, 0.95, 0.92, 0.90, 0.89, 0.885, 0.883]), \"exp\"),\n        (np.array([1.0, 0.98, 0.96]), \"cosine\"),\n    ]\n\n    def process_case(losses, schedule_type):\n        \"\"\"\n        Processes a single test case.\n        \"\"\"\n        T = len(losses)\n        states = np.zeros(T, dtype=int)\n        lrs_fsm = np.zeros(T, dtype=float)\n        \n        # Initialization\n        states[0] = 0  # explore\n        lrs_fsm[0] = LR_MAP[states[0]]\n        transitions = 0\n        \n        # FSM state evolution\n        for t in range(1, T):\n            prev_state = states[t-1]\n            \n            if t  W - 1:\n                current_state = prev_state\n            else: # t >= W - 1\n                # Compute s_t, k_t, osc_t\n                d = np.diff(losses[t-W+1 : t+1]) # d_t-2, d_t-1, d_t\n                \n                s_t = np.mean(d) # Sum over 3 elements, divided by W-1=3\n                \n                e = np.diff(d) # e_t-1, e_t\n                k_t = np.mean(e) # Sum over 2 elements, divided by W-2=2\n\n                osc_t = 0\n                if d[0] * d[1]  0:\n                    osc_t += 1\n                if d[1] * d[2]  0:\n                    osc_t += 1\n\n                # Apply transition rules\n                current_state = prev_state # Default to remain\n                if prev_state == 0: # explore\n                    if s_t = -ALPHA and k_t  BETA:\n                        current_state = 1\n                    elif s_t >= 0:\n                        current_state = 0\n                    elif -ALPHA  s_t  0 and k_t >= BETA:\n                        current_state = 2\n                    else: # -ALPHA  s_t  0 and k_t  BETA\n                        current_state = 0\n                elif prev_state == 1: # exploit\n                    if (s_t >= 0) or (-ALPHA  s_t  0 and k_t >= BETA):\n                        current_state = 2\n                    else: # (s_t = -ALPHA) or (-ALPHA  s_t  0 and k_t  BETA)\n                        current_state = 1\n                elif prev_state == 2: # consolidate\n                    if s_t = -ALPHA and k_t  BETA:\n                        current_state = 1\n                    elif s_t >= 0 and osc_t >= 2:\n                        current_state = 0\n                    else:\n                        current_state = 2\n                        \n            states[t] = current_state\n            if states[t] != prev_state:\n                transitions += 1\n            lrs_fsm[t] = LR_MAP[states[t]]\n\n        # Compute continuous schedule\n        lrs_cont = np.zeros(T, dtype=float)\n        eta_0 = ETA_EXPLORE\n        eta_end = ETA_CONSOLIDATE\n        N = max(1, T - 1)\n        t_steps = np.arange(T)\n\n        if schedule_type == \"exp\":\n            lrs_cont = eta_0 * (eta_end / eta_0) ** (t_steps / N)\n        elif schedule_type == \"cosine\":\n            lrs_cont = eta_end + 0.5 * (eta_0 - eta_end) * (1 + np.cos(np.pi * t_steps / N))\n            \n        # Compute metrics\n        mad = np.mean(np.abs(lrs_fsm - lrs_cont))\n        final_state = states[-1]\n        final_lr = lrs_fsm[-1]\n        \n        return [final_state, mad, transitions, final_lr]\n\n    # Process all cases and format output\n    results_list = [process_case(L, sched) for L, sched in test_cases]\n\n    formatted_results = []\n    for res in results_list:\n        state, mad, trans, lr = res\n        formatted_str = f\"[{state},{mad:.6f},{trans},{lr:.6f}]\"\n        formatted_results.append(formatted_str)\n    \n    final_output = f\"[{','.join(formatted_results)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3142941"}]}