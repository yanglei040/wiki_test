{"hands_on_practices": [{"introduction": "Before we can update our model, we must first organize our data. This exercise [@problem_id:2186998] walks you through the essential first step of mini-batch gradient descent: partitioning a large dataset into smaller, manageable mini-batches. Mastering this simple calculation is crucial for correctly structuring the training epochs and ensuring every data point is used for learning.", "problem": "In the field of machine learning, training a neural network often involves an iterative optimization process called mini-batch gradient descent. In this process, the entire training dataset is partitioned into smaller, equally-sized subsets called mini-batches. The model's parameters are updated after processing each mini-batch. One complete pass through all the mini-batches, covering the entire training dataset, is known as an epoch.\n\nA data science team is training a convolutional neural network to classify astronomical images. Their training dataset consists of a total of $N = 50,000$ distinct images. They have chosen to use a mini-batch size of $b = 128$ images. When the total number of training examples $N$ is not perfectly divisible by the batch size $b$, it is standard practice for the final mini-batch of the epoch to simply contain all the remaining samples.\n\nCalculate the total number of mini-batches that will be processed in one epoch, and determine the size of the very last mini-batch for that epoch. Provide your answer as two integers: the total number of mini-batches and the size of the final mini-batch, in that order.", "solution": "Let $N$ denote the total number of training examples and $b$ the mini-batch size. Write $N$ in Euclidean division form as\n$$\nN = qb + r,\\quad 0 \\leq r < b,\n$$\nwhere $q = \\left\\lfloor \\frac{N}{b} \\right\\rfloor$ and $r = N - qb$.\nThe total number of mini-batches in one epoch is\n$$\nm = \\begin{cases}\nq, & r=0,\\\\\nq+1, & r>0,\n\\end{cases}\n$$\nsince a nonzero remainder requires one additional (smaller) mini-batch. The size of the final mini-batch is\n$$\nL = \\begin{cases}\nb, & r=0,\\\\\nr, & r>0.\n\\end{cases}\n$$\nWith $N=50000$ and $b=128$, compute $q$ by bounding:\n$$\n128 \\times 390 = 49920,\\quad 128 \\times 391 = 50048 > 50000 \\;\\Rightarrow\\; q = 390.\n$$\nThen\n$$\nr = N - qb = 50000 - 128 \\times 390 = 50000 - 49920 = 80.\n$$\nSince $r>0$, the total number of mini-batches is\n$$\nm = q + 1 = 391,\n$$\nand the size of the final mini-batch is\n$$\nL = r = 80.\n$$\nThus, the total number of mini-batches is $391$ and the size of the final mini-batch is $80$.", "answer": "$$\\boxed{\\begin{pmatrix}391 & 80\\end{pmatrix}}$$", "id": "2186998"}, {"introduction": "With a mini-batch of data, we can estimate the error gradient and take a small step to improve our model. This practice [@problem_id:2187026] focuses on the heart of the gradient descent algorithm: the parameter update rule. By performing a single update, you will gain a concrete understanding of how the learning rate and the gradient work together to iteratively refine your model's parameters.", "problem": "A computational science student is training a simple predictive model. The model's behavior is controlled by a single dimensionless parameter, $\\theta$. The goal is to find the value of $\\theta$ that minimizes the model's prediction error, which is measured by a cost function $J(\\theta)$.\n\nThe student employs a numerical optimization technique known as gradient descent. The process starts with an initial guess for the parameter and iteratively refines it. Each update step is designed to move the parameter value in the direction opposite to the cost function's gradient. The magnitude of each step is determined by a parameter called the learning rate.\n\nThe student initializes the parameter at $\\theta_0 = 2$. For the first iteration, they use a subset of their data to compute the gradient of the cost function with respect to the parameter at this initial point. The computation yields a gradient value of $\\nabla J(\\theta_0) = 4$. The learning rate for the optimization process is set to $\\eta = 0.01$.\n\nCalculate the updated value of the parameter, $\\theta_1$, after this first iteration. Report your answer to three significant figures.", "solution": "We use the standard gradient descent update rule for a single parameter:\n$$\n\\theta_{k+1} = \\theta_{k} - \\eta \\frac{dJ}{d\\theta}\\bigg|_{\\theta=\\theta_{k}}.\n$$\nFor the first iteration with $k=0$, the given values are $\\theta_{0} = 2$, learning rate $\\eta = 0.01$, and gradient $\\nabla J(\\theta_{0}) = 4$. Substituting these into the update rule gives:\n$$\n\\theta_{1} = \\theta_{0} - \\eta \\nabla J(\\theta_{0}) = 2 - 0.01 \\times 4.\n$$\nCompute the product:\n$$\n0.01 \\times 4 = 0.04,\n$$\nso\n$$\n\\theta_{1} = 2 - 0.04 = 1.96.\n$$\nRounded to three significant figures, the value is $1.96$.", "answer": "$$\\boxed{1.96}$$", "id": "2187026"}, {"introduction": "While the basic update rule is powerful, modern optimizers often incorporate \"momentum\" to accelerate learning and navigate complex loss landscapes. This exercise [@problem_id:2187015] explores a fascinating scenario to reveal the core benefit of momentum. You'll see how past updates can influence the current step, allowing the optimization to continue progressing even when the gradient on the current mini-batch is zero.", "problem": "An engineer is training a simple linear regression model of the form $h_{\\theta}(x) = \\theta_0 + \\theta_1 x$ using mini-batch gradient descent with a momentum term. The optimization algorithm updates the parameters $\\theta = (\\theta_0, \\theta_1)$ at each step $t$ according to the following rules:\n\n1.  $v_t = \\gamma v_{t-1} + \\eta \\nabla_{\\theta} J_B(\\theta_{t-1})$\n2.  $\\theta_t = \\theta_{t-1} - v_t$\n\nwhere $\\theta_{t-1}$ are the parameter values from the previous step, $v_t$ is the current velocity vector, $v_{t-1}$ is the previous velocity vector, $\\gamma$ is the momentum coefficient, $\\eta$ is the learning rate, and $\\nabla_{\\theta} J_B(\\theta_{t-1})$ is the gradient of the loss function computed on the current mini-batch $B$ using the parameters $\\theta_{t-1}$.\n\nThe loss function is the Mean Squared Error (MSE), defined for a mini-batch $B$ with $m_B$ samples as:\n$J_B(\\theta) = \\frac{1}{2m_B} \\sum_{(x^{(i)}, y^{(i)}) \\in B} (h_{\\theta}(x^{(i)}) - y^{(i)})^2$\n\nAt the beginning of the current iteration (step $t$), the state of the model is as follows:\n- Parameters: $\\theta_{t-1} = (\\theta_0, \\theta_1) = (1.0, 2.0)$\n- Previous velocity vector: $v_{t-1} = (v_{0, t-1}, v_{1, t-1}) = (0.1, -0.2)$\n\nThe hyperparameters are set to:\n- Learning rate: $\\eta = 0.01$\n- Momentum coefficient: $\\gamma = 0.9$\n\nFor the current update step, the algorithm uses the following mini-batch $B$, which contains two data points:\n$B = \\{(1, 3), (3, 7)\\}$\n\nCalculate the updated value of the parameter $\\theta_1$ at the end of this iteration, denoted as $\\theta_{1,t}$.", "solution": "The goal is to find the updated parameter $\\theta_{1,t}$ after a single step of mini-batch gradient descent with momentum.\n\nThe update rule for the parameters $\\theta$ is given by a two-step process:\n1. Update the velocity vector: $v_t = \\gamma v_{t-1} + \\eta \\nabla_{\\theta} J_B(\\theta_{t-1})$\n2. Update the parameters: $\\theta_t = \\theta_{t-1} - v_t$\n\nWe are interested in the parameter $\\theta_1$. Let's write the update rules specifically for this parameter:\n$v_{1,t} = \\gamma v_{1,t-1} + \\eta \\frac{\\partial J_B(\\theta_{t-1})}{\\partial \\theta_1}$\n$\\theta_{1,t} = \\theta_{1,t-1} - v_{1,t}$\n\nThe first step is to compute the partial derivative of the loss function $J_B$ with respect to $\\theta_1$, evaluated at $\\theta_{t-1} = (1.0, 2.0)$.\n\nThe loss function is $J_B(\\theta) = \\frac{1}{2m_B} \\sum_{(x^{(i)}, y^{(i)}) \\in B} ((\\theta_0 + \\theta_1 x^{(i)}) - y^{(i)})^2$.\nThe partial derivative with respect to $\\theta_1$ is:\n$\\frac{\\partial J_B}{\\partial \\theta_1} = \\frac{1}{m_B} \\sum_{(x^{(i)}, y^{(i)}) \\in B} ((\\theta_0 + \\theta_1 x^{(i)}) - y^{(i)}) x^{(i)}$\n\nThe mini-batch is $B = \\{(1, 3), (3, 7)\\}$, so the mini-batch size is $m_B=2$. The current parameters are $\\theta_0 = 1.0$ and $\\theta_1 = 2.0$.\n\nLet's calculate the error term, $(\\theta_0 + \\theta_1 x^{(i)}) - y^{(i)}$, for each point in the mini-batch.\nFor the first point $(x^{(1)}, y^{(1)}) = (1, 3)$:\nPrediction: $h_{\\theta}(x^{(1)}) = \\theta_0 + \\theta_1 x^{(1)} = 1.0 + 2.0 \\cdot 1 = 3.0$\nError: $h_{\\theta}(x^{(1)}) - y^{(1)} = 3.0 - 3 = 0.0$\n\nFor the second point $(x^{(2)}, y^{(2)}) = (3, 7)$:\nPrediction: $h_{\\theta}(x^{(2)}) = \\theta_0 + \\theta_1 x^{(2)} = 1.0 + 2.0 \\cdot 3 = 1.0 + 6.0 = 7.0$\nError: $h_{\\theta}(x^{(2)}) - y^{(2)} = 7.0 - 7 = 0.0$\n\nNow, substitute these errors into the expression for the partial derivative:\n$\\frac{\\partial J_B}{\\partial \\theta_1} = \\frac{1}{2} \\left[ (0.0) \\cdot x^{(1)} + (0.0) \\cdot x^{(2)} \\right]$\n$\\frac{\\partial J_B}{\\partial \\theta_1} = \\frac{1}{2} \\left[ (0.0) \\cdot 1 + (0.0) \\cdot 3 \\right] = 0.0$\nThe gradient component for $\\theta_1$ is exactly zero.\n\nNext, we calculate the new velocity component for $\\theta_1$, which is $v_{1,t}$, using the given hyperparameters and previous velocity.\nThe given values are $\\gamma = 0.9$, $\\eta = 0.01$, and the previous velocity component for $\\theta_1$ is $v_{1,t-1} = -0.2$.\n$v_{1,t} = \\gamma v_{1,t-1} + \\eta \\frac{\\partial J_B}{\\partial \\theta_1}$\n$v_{1,t} = (0.9)(-0.2) + (0.01)(0.0)$\n$v_{1,t} = -0.18 + 0 = -0.18$\n\nFinally, we update the parameter $\\theta_1$. The current value is $\\theta_{1,t-1} = 2.0$.\n$\\theta_{1,t} = \\theta_{1,t-1} - v_{1,t}$\n$\\theta_{1,t} = 2.0 - (-0.18)$\n$\\theta_{1,t} = 2.0 + 0.18 = 2.18$\n\nSo, even though the gradient for the current mini-batch was zero, the parameter $\\theta_1$ still changed due to the momentum term carrying over velocity from the previous update step.", "answer": "$$\\boxed{2.18}$$", "id": "2187015"}]}