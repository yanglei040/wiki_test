{"hands_on_practices": [{"introduction": "To truly appreciate the power of bidirectional processing, we begin with a conceptual challenge. This exercise [@problem_id:3103026] presents a synthetic task where a correct prediction is logically impossible without access to future information. By deriving the performance limits of a forward-only model versus an ideal bidirectional one, you will gain a fundamental, first-principles understanding of why Bidirectional RNNs are indispensable for certain sequence problems.", "problem": "You are given a synthetic sequence classification task designed to isolate the benefit of bidirectionality in recurrent neural networks. Consider a sequence of binary tokens $\\{x_t\\}_{t=1}^L$ where each $x_t \\in \\{0,1\\}$ is an independent and identically distributed draw from a Bernoulli distribution with parameter $p$, that is $x_t \\sim \\mathrm{Bernoulli}(p)$ for all $t$. For each interior position $t$ (i.e., all $t$ such that $2 \\le t \\le L-1$), you must assign a label $y_t \\in \\{0,1\\}$ according to the following neighbor-constrained identity rule: $y_t = 1$ if and only if $x_t$ equals the logical AND of its two neighbors, that is $x_t = x_{t-1} \\land x_{t+1}$, and $y_t = 0$ otherwise.\n\nFundamental base: a Recurrent Neural Network (RNN) is a causal model where the hidden state $h_t$ at time $t$ is a function of the current input $x_t$ and the previous hidden state $h_{t-1}$, and the output $o_t$ depends on $h_t$. A Bidirectional Recurrent Neural Network (BiRNN) processes the sequence in both forward and backward directions, computing hidden states $h_t^{\\rightarrow}$ and $h_t^{\\leftarrow}$, and forms an output $o_t$ as a function of both $h_t^{\\rightarrow}$ and $h_t^{\\leftarrow}$. Consequently, a forward-only causal model that predicts at time $t$ cannot depend on $x_{t+1}$, whereas a bidirectional model’s prediction at time $t$ may depend on both $x_{t-1}$ and $x_{t+1}$.\n\nYour task is to derive, from first principles and without relying on pre-provided target formulas, the expected classification accuracy for two idealized predictors evaluated only on interior positions $t \\in \\{2,3,\\dots,L-1\\}$:\n\n- The best possible forward-only causal predictor that, at time $t$, has access to $x_{t-1}$ and $x_t$ and the distribution parameter $p$, but not to $x_{t+1}$. This predictor must decide $\\hat{y}_t \\in \\{0,1\\}$ using only information that does not violate causality with respect to $t+1$. Its expected accuracy should be computed under the data-generating process described above.\n- An idealized bidirectional predictor that, at time $t$, has access to $x_{t-1}$, $x_t$, and $x_{t+1}$ and the parameter $p$. Its expected accuracy should be computed under the same data-generating process.\n\nYou must write a complete, runnable program that, for each test case, computes three quantities as floats: the expected accuracy of the forward-only causal predictor on interior positions, the expected accuracy of the bidirectional predictor on interior positions, and the accuracy gain defined as the difference between the bidirectional and forward-only expected accuracies. Angles and physical units do not apply in this task.\n\nTest suite:\n- $(L,p) = (3,0)$\n- $(L,p) = (3,1)$\n- $(L,p) = (5,0.5)$\n- $(L,p) = (9,0.25)$\n- $(L,p) = (9,0.9)$\n- $(L,p) = (12,0.5)$\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a sub-list of three floats in the order described above. For example, the output must look like $[\\,[a_1,b_1,c_1],\\,[a_2,b_2,c_2],\\,\\dots\\,]$ with no additional text. All values should be computed exactly from the derivation and reported as standard decimal floats.", "solution": "The problem is valid as it is scientifically grounded, well-posed, and objective. It presents a formalizable task in statistical decision theory and probability, directly relevant to understanding the functional differences between causal and non-causal models like unidirectional and bidirectional RNNs. All necessary information is provided, and the problem is free from contradictions or ambiguities.\n\nWe will now derive the expected classification accuracy for the two specified predictors. The derivation is performed for an arbitrary interior position $t$, where $2 \\le t \\le L-1$. As the tokens $x_t$ are independent and identically distributed (i.i.d.), the result will be independent of the specific choice of $t$ and the sequence length $L$.\n\nThe data-generating process is defined by a sequence of binary tokens $\\{x_t\\}_{t=1}^L$, where each token $x_t \\in \\{0,1\\}$ is a draw from a Bernoulli distribution with parameter $p$:\n$$ P(x_t=1) = p $$\n$$ P(x_t=0) = 1-p $$\nThe true label $y_t \\in \\{0,1\\}$ for an interior position $t$ is determined by the rule:\n$$ y_t = 1 \\text{ if and only if } x_t = (x_{t-1} \\land x_{t+1}) $$\nwhere $\\land$ represents the logical AND operator. Otherwise, $y_t=0$.\n\nThe accuracy of a predictor $\\hat{y}_t$ is the probability of it matching the true label $y_t$, which is $P(\\hat{y}_t = y_t)$. We seek the expected accuracy, which for this stationary process is simply this probability. An optimal predictor, given a set of information, maximizes this probability by choosing the label with the highest posterior probability.\n\n**1. Idealized Bidirectional Predictor**\n\nThe idealized bidirectional predictor has access to the complete triplet $(x_{t-1}, x_t, x_{t+1})$ at time $t$. The labeling rule $y_t = 1 \\iff x_t = (x_{t-1} \\land x_{t+1})$ depends exclusively on these three values. With full knowledge of this triplet, the predictor can compute the value of $x_{t-1} \\land x_{t+1}$ and compare it to $x_t$. The outcome for $y_t$ is therefore deterministic for the predictor.\n\nFor any given triplet, the predictor can set its prediction $\\hat{y}_t$ to be exactly equal to the true label $y_t$. For example, if it observes $(x_{t-1}, x_t, x_{t+1}) = (1, 1, 1)$, it computes $x_{t-1} \\land x_{t+1} = 1 \\land 1 = 1$. Since this equals $x_t=1$, the true label is $y_t=1$, and the predictor sets $\\hat{y}_t=1$. If it observes $(x_{t-1}, x_t, x_{t+1}) = (1, 0, 1)$, it computes $x_{t-1} \\land x_{t+1} = 1$. This does not equal $x_t=0$, so the true label is $y_t=0$, and the predictor sets $\\hat{y}_t=0$.\n\nSince the prediction $\\hat{y}_t$ can always be made equal to the true label $y_t$, the probability of a correct prediction is $1$.\n$$ P(\\hat{y}_t = y_t | x_{t-1}, x_t, x_{t+1}) = 1 $$\nThe expected accuracy, $A_{bi}$, is the expectation of this conditional probability over all possible triplets, which is simply $1$.\n$$ A_{bi} = E[P(\\hat{y}_t = y_t | x_{t-1}, x_t, x_{t+1})] = 1 $$\n\n**2. Best Possible Forward-Only Causal Predictor**\n\nThe forward-only causal predictor has access to $(x_{t-1}, x_t)$ and the parameter $p$, but not $x_{t+1}$. The best possible predictor will choose the label $\\hat{y}_t$ that maximizes the posterior probability given the available information:\n$$ \\hat{y}_t = \\arg\\max_{k \\in \\{0,1\\}} P(y_t=k | x_{t-1}, x_t) $$\nThe accuracy of this optimal strategy is $P(\\hat{y}_t = y_t)$. We compute this by summing the conditional accuracies over the four possible observed pairs for $(x_{t-1}, x_t)$, weighted by the probability of each pair.\n\nLet's analyze the four cases for the observed pair $(x_{t-1}, x_t)$:\n\n**Case A: $(x_{t-1}, x_t) = (0, 0)$**\nThe condition for $y_t=1$ is $x_t = (x_{t-1} \\land x_{t+1})$. Substituting the known values, we get $0 = (0 \\land x_{t+1})$. Since $0 \\land x_{t+1}$ is always $0$ regardless of $x_{t+1}$, this simplifies to $0=0$, which is always true. Thus, $y_t$ is deterministically $1$.\nThe optimal prediction is $\\hat{y}_t=1$. The accuracy in this case is $1$.\nThe probability of this case is $P(x_{t-1}=0, x_t=0) = (1-p)(1-p) = (1-p)^2$.\n\n**Case B: $(x_{t-1}, x_t) = (0, 1)$**\nThe condition for $y_t=1$ is $1 = (0 \\land x_{t+1})$, which simplifies to $1=0$. This is always false. Thus, $y_t$ is deterministically $0$.\nThe optimal prediction is $\\hat{y}_t=0$. The accuracy in this case is $1$.\nThe probability of this case is $P(x_{t-1}=0, x_t=1) = (1-p)p$.\n\n**Case C: $(x_{t-1}, x_t) = (1, 0)$**\nThe condition for $y_t=1$ is $0 = (1 \\land x_{t+1})$, which simplifies to $0 = x_{t+1}$. Therefore, $y_t=1$ if $x_{t+1}=0$, and $y_t=0$ if $x_{t+1}=1$. Since $x_{t+1}$ is unknown, we use its probability distribution.\n$P(y_t=1 | x_{t-1}=1, x_t=0) = P(x_{t+1}=0) = 1-p$.\n$P(y_t=0 | x_{t-1}=1, x_t=0) = P(x_{t+1}=1) = p$.\nThe optimal predictor chooses $\\hat{y}_t=1$ if $1-p > p$ (i.e., $p  0.5$), and $\\hat{y}_t=0$ if $p > 1-p$ (i.e., $p > 0.5$). If $p=0.5$, either choice yields the same accuracy. The accuracy in this case is the probability of the majority class, which is $\\max(p, 1-p)$.\nThe probability of this case is $P(x_{t-1}=1, x_t=0) = p(1-p)$.\n\n**Case D: $(x_{t-1}, x_t) = (1, 1)$**\nThe condition for $y_t=1$ is $1 = (1 \\land x_{t+1})$, which simplifies to $1 = x_{t+1}$. Therefore, $y_t=1$ if $x_{t+1}=1$, and $y_t=0$ if $x_{t+1}=0$.\n$P(y_t=1 | x_{t-1}=1, x_t=1) = P(x_{t+1}=1) = p$.\n$P(y_t=0 | x_{t-1}=1, x_t=1) = P(x_{t+1}=0) = 1-p$.\nThe optimal predictor's accuracy in this case is again the probability of the majority class, $\\max(p, 1-p)$.\nThe probability of this case is $P(x_{t-1}=1, x_t=1) = p \\cdot p = p^2$.\n\n**Total Expected Accuracy of the Forward-Only Predictor ($A_{fwd}$)**\nWe sum the accuracies from each case, weighted by their probabilities:\n$$ A_{fwd} = 1 \\cdot (1-p)^2 + 1 \\cdot p(1-p) + \\max(p, 1-p) \\cdot p(1-p) + \\max(p, 1-p) \\cdot p^2 $$\nFactoring the terms:\n$$ A_{fwd} = ((1-p)^2 + p(1-p)) + \\max(p, 1-p) \\cdot (p(1-p) + p^2) $$\n$$ A_{fwd} = (1-p)(1-p+p) + \\max(p, 1-p) \\cdot p(1-p+p) $$\n$$ A_{fwd} = (1-p) \\cdot 1 + \\max(p, 1-p) \\cdot p \\cdot 1 $$\n$$ A_{fwd} = (1-p) + p \\cdot \\max(p, 1-p) $$\nWe can express this as a piecewise function of $p$:\n- If $p  0.5$, $\\max(p, 1-p) = 1-p$. $A_{fwd} = (1-p) + p(1-p) = (1-p)(1+p) = 1-p^2$.\n- If $p \\ge 0.5$, $\\max(p, 1-p) = p$. $A_{fwd} = (1-p) + p(p) = 1-p+p^2$.\n\n**3. Accuracy Gain**\n\nThe accuracy gain is the difference between the bidirectional and forward-only expected accuracies.\n$$ \\text{Gain} = A_{bi} - A_{fwd} = 1 - [(1-p) + p \\cdot \\max(p, 1-p)] $$\n$$ \\text{Gain} = p - p \\cdot \\max(p, 1-p) = p(1 - \\max(p, 1-p)) $$\nUsing the identity $1 - \\max(a,b) = \\min(1-a, 1-b)$, we have:\n$$ \\text{Gain} = p \\cdot \\min(p, 1-p) $$\n- If $p  0.5$, $\\min(p, 1-p) = p$. $\\text{Gain} = p \\cdot p = p^2$.\n- If $p \\ge 0.5$, $\\min(p, 1-p) = 1-p$. $\\text{Gain} = p(1-p)$.\n\nThese derived formulae allow for the direct computation of the required quantities for each test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the expected accuracies for forward-only and bidirectional predictors\n    on a synthetic sequence task.\n    \"\"\"\n    # Test suite: each tuple is (L, p)\n    # L is not used in the calculation since the expected accuracy for any\n    # interior position is independent of sequence length for an i.i.d. process.\n    test_cases = [\n        (3, 0.0),\n        (3, 1.0),\n        (5, 0.5),\n        (9, 0.25),\n        (9, 0.9),\n        (12, 0.5),\n    ]\n\n    results = []\n    for L, p in test_cases:\n        # Calculate the expected accuracy of the best possible forward-only predictor.\n        # The derived formula is A_fwd = (1-p) + p * max(p, 1-p).\n        # This can be written as a piecewise function:\n        # if p  0.5, A_fwd = 1 - p**2\n        # if p = 0.5, A_fwd = 1 - p + p**2\n        if p  0.5:\n            acc_fwd = 1.0 - p**2\n        else:\n            acc_fwd = 1.0 - p + p**2\n\n        # The idealized bidirectional predictor has access to all necessary information\n        # (x_{t-1}, x_t, x_{t+1}) to determine the label y_t with certainty.\n        # Therefore, its accuracy is always 1.0.\n        acc_bi = 1.0\n\n        # The accuracy gain is the difference between the two.\n        accuracy_gain = acc_bi - acc_fwd\n\n        # Append the results for this test case.\n        results.append([acc_fwd, acc_bi, accuracy_gain])\n\n    # Format the output string as required: [[a1,b1,c1],[a2,b2,c2],...]\n    sublist_strings = []\n    for sublist in results:\n        # Convert each float in the sublist to a string and join with commas\n        # Enclose the result in square brackets\n        sublist_strings.append(f\"[{','.join(map(str, sublist))}]\")\n    \n    # Join all sublist strings with commas and enclose in the final brackets\n    final_output_string = f\"[{','.join(sublist_strings)}]\"\n\n    print(final_output_string)\n\nsolve()\n```", "id": "3103026"}, {"introduction": "Having established the need for bidirectionality, we now delve into the mechanics of how a BiRNN combines information from its two passes. This practice [@problem_id:3103018] models the forward and backward hidden states as noisy observations of a true underlying signal. You will use statistical principles to derive the optimal linear combination of these states, providing a theoretical foundation for the fusion mechanisms seen in modern network architectures.", "problem": "Consider a Bidirectional Recurrent Neural Network (BRNN) where the forward hidden state $h_t^{\\rightarrow}$ and the backward hidden state $h_t^{\\leftarrow}$ at time $t$ are used to estimate an unobserved latent signal $s_t$. Assume a linear Gaussian generative model in which each hidden state is an unbiased noisy observation of $s_t$:\n$$\nh_t^{\\rightarrow} = s_t + \\epsilon_t^{\\rightarrow}, \\quad h_t^{\\leftarrow} = s_t + \\epsilon_t^{\\leftarrow},\n$$\nwhere $\\epsilon_t^{\\rightarrow}$ and $\\epsilon_t^{\\leftarrow}$ are jointly Gaussian noise terms with zero mean, variances $\\operatorname{Var}(\\epsilon_t^{\\rightarrow}) = \\sigma_{\\rightarrow,t}^{2}$ and $\\operatorname{Var}(\\epsilon_t^{\\leftarrow}) = \\sigma_{\\leftarrow,t}^{2}$, and covariance $\\operatorname{Cov}(\\epsilon_t^{\\rightarrow}, \\epsilon_t^{\\leftarrow}) = c_t$. Consider a linear fusion estimator\n$$\n\\hat{s}_t(g_t) = g_t\\, h_t^{\\rightarrow} + \\left(1 - g_t\\right) h_t^{\\leftarrow},\n$$\nwith scalar fusion weight $g_t \\in \\mathbb{R}$. Starting from the definition of mean squared error (MSE), derive the value of $g_t$ that minimizes the expected squared error $\\mathbb{E}\\big[(\\hat{s}_t(g_t) - s_t)^{2}\\big]$ under the model above.\n\nThen, evaluate the derived expression at the following noise statistics:\n$$\n\\sigma_{\\rightarrow,t}^{2} = 0.36, \\quad \\sigma_{\\leftarrow,t}^{2} = 0.81, \\quad c_t = 0.12.\n$$\nSeparately, suppose a learned gating mechanism in the BRNN defines\n$$\ng_t^{\\mathrm{learn}} = \\sigma\\!\\left(w_{\\rightarrow} h_t^{\\rightarrow} + w_{\\leftarrow} h_t^{\\leftarrow} + b\\right),\n$$\nwhere $\\sigma(x)$ is the logistic sigmoid function $\\sigma(x) = \\frac{1}{1 + \\exp(-x)}$. For a particular time $t$, let\n$$\nh_t^{\\rightarrow} = 1.4, \\quad h_t^{\\leftarrow} = 0.6, \\quad w_{\\rightarrow} = 0.5, \\quad w_{\\leftarrow} = 0.25, \\quad b = \\ln(3) - 0.85.\n$$\nCompute $g_t^{\\mathrm{learn}}$ and compare it to the analytically optimal $g_t$ you derived above. Your final answer must be the absolute difference\n$$\n\\left|g_t^{\\mathrm{learn}} - g_t^{\\star}\\right|,\n$$\nexpressed as a pure number. Round your final answer to four significant figures.", "solution": "The user wants to find the absolute difference between an optimally derived fusion weight and a learned gate value in the context of a Bidirectional Recurrent Neural Network (BRNN).\n\nFirst, I will validate the problem statement.\n\n### Step 1: Extract Givens\n- Forward hidden state: $h_t^{\\rightarrow}$\n- Backward hidden state: $h_t^{\\leftarrow}$\n- Latent signal: $s_t$\n- Generative model: $h_t^{\\rightarrow} = s_t + \\epsilon_t^{\\rightarrow}$ and $h_t^{\\leftarrow} = s_t + \\epsilon_t^{\\leftarrow}$.\n- Noise properties: $\\epsilon_t^{\\rightarrow}, \\epsilon_t^{\\leftarrow}$ are jointly Gaussian with $\\mathbb{E}[\\epsilon_t^{\\rightarrow}] = 0$, $\\mathbb{E}[\\epsilon_t^{\\leftarrow}] = 0$, $\\operatorname{Var}(\\epsilon_t^{\\rightarrow}) = \\sigma_{\\rightarrow,t}^{2}$, $\\operatorname{Var}(\\epsilon_t^{\\leftarrow}) = \\sigma_{\\leftarrow,t}^{2}$, and $\\operatorname{Cov}(\\epsilon_t^{\\rightarrow}, \\epsilon_t^{\\leftarrow}) = c_t$.\n- Linear fusion estimator: $\\hat{s}_t(g_t) = g_t\\, h_t^{\\rightarrow} + \\left(1 - g_t\\right) h_t^{\\leftarrow}$ with $g_t \\in \\mathbb{R}$.\n- Objective: Minimize the mean squared error (MSE), $\\mathbb{E}\\big[(\\hat{s}_t(g_t) - s_t)^{2}\\big]$.\n- Numerical values for noise statistics: $\\sigma_{\\rightarrow,t}^{2} = 0.36$, $\\sigma_{\\leftarrow,t}^{2} = 0.81$, $c_t = 0.12$.\n- Learned gate: $g_t^{\\mathrm{learn}} = \\sigma\\!\\left(w_{\\rightarrow} h_t^{\\rightarrow} + w_{\\leftarrow} h_t^{\\leftarrow} + b\\right)$, with $\\sigma(x) = \\frac{1}{1 + \\exp(-x)}$.\n- Numerical values for learned gate: $h_t^{\\rightarrow} = 1.4$, $h_t^{\\leftarrow} = 0.6$, $w_{\\rightarrow} = 0.5$, $w_{\\leftarrow} = 0.25$, $b = \\ln(3) - 0.85$.\n- Final answer: Compute $|g_t^{\\mathrm{learn}} - g_t^{\\star}|$, rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in statistical estimation theory and its application to neural networks. A linear Gaussian model is a standard framework for analysis. Minimizing the MSE to find an optimal linear estimator is a fundamental and well-posed problem. The structure of the learned gate is typical of gating mechanisms in RNNs. All necessary constants and conditions are provided, and there are no contradictions. The problem is objective and formalizable.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will now proceed to the solution.\n\nThe first part of the problem is to derive the optimal fusion weight $g_t^{\\star}$ that minimizes the MSE. The estimation error is given by $e_t = \\hat{s}_t(g_t) - s_t$.\nSubstituting the expressions for $\\hat{s}_t$, $h_t^{\\rightarrow}$, and $h_t^{\\leftarrow}$:\n$$\ne_t = \\left( g_t h_t^{\\rightarrow} + (1 - g_t) h_t^{\\leftarrow} \\right) - s_t\n$$\n$$\ne_t = g_t (s_t + \\epsilon_t^{\\rightarrow}) + (1 - g_t) (s_t + \\epsilon_t^{\\leftarrow}) - s_t\n$$\n$$\ne_t = g_t s_t + g_t \\epsilon_t^{\\rightarrow} + s_t - g_t s_t + \\epsilon_t^{\\leftarrow} - g_t \\epsilon_t^{\\leftarrow} - s_t\n$$\n$$\ne_t = g_t \\epsilon_t^{\\rightarrow} + (1 - g_t) \\epsilon_t^{\\leftarrow}\n$$\nThe MSE is the expected value of the squared error, $\\mathbb{E}[e_t^2]$.\n$$\n\\text{MSE}(g_t) = \\mathbb{E}\\left[ \\left( g_t \\epsilon_t^{\\rightarrow} + (1 - g_t) \\epsilon_t^{\\leftarrow} \\right)^2 \\right]\n$$\nExpanding the square and using the linearity of expectation:\n$$\n\\text{MSE}(g_t) = g_t^2 \\mathbb{E}[(\\epsilon_t^{\\rightarrow})^2] + (1 - g_t)^2 \\mathbb{E}[(\\epsilon_t^{\\leftarrow})^2] + 2 g_t (1 - g_t) \\mathbb{E}[\\epsilon_t^{\\rightarrow} \\epsilon_t^{\\leftarrow}]\n$$\nGiven that the noise terms have zero mean, the expectations correspond to variances and covariance:\n$$\n\\mathbb{E}[(\\epsilon_t^{\\rightarrow})^2] = \\operatorname{Var}(\\epsilon_t^{\\rightarrow}) = \\sigma_{\\rightarrow,t}^2\n$$\n$$\n\\mathbb{E}[(\\epsilon_t^{\\leftarrow})^2] = \\operatorname{Var}(\\epsilon_t^{\\leftarrow}) = \\sigma_{\\leftarrow,t}^2\n$$\n$$\n\\mathbb{E}[\\epsilon_t^{\\rightarrow} \\epsilon_t^{\\leftarrow}] = \\operatorname{Cov}(\\epsilon_t^{\\rightarrow}, \\epsilon_t^{\\leftarrow}) = c_t\n$$\nThus, the MSE as a function of $g_t$ is:\n$$\n\\text{MSE}(g_t) = g_t^2 \\sigma_{\\rightarrow,t}^2 + (1 - g_t)^2 \\sigma_{\\leftarrow,t}^2 + 2 g_t (1 - g_t) c_t\n$$\nTo find the value of $g_t$ that minimizes the MSE, we differentiate with respect to $g_t$ and set the derivative to zero:\n$$\n\\frac{d}{dg_t}\\text{MSE}(g_t) = 2 g_t \\sigma_{\\rightarrow,t}^2 + 2 (1 - g_t)(-1) \\sigma_{\\leftarrow,t}^2 + 2(1 - 2g_t) c_t\n$$\nSetting the derivative to zero:\n$$\n2 g_t \\sigma_{\\rightarrow,t}^2 - 2 (1 - g_t) \\sigma_{\\leftarrow,t}^2 + 2(1 - 2g_t) c_t = 0\n$$\n$$\n2 g_t \\sigma_{\\rightarrow,t}^2 - 2 \\sigma_{\\leftarrow,t}^2 + 2 g_t \\sigma_{\\leftarrow,t}^2 + 2 c_t - 4 g_t c_t = 0\n$$\nGroup the terms containing $g_t$:\n$$\ng_t (2 \\sigma_{\\rightarrow,t}^2 + 2 \\sigma_{\\leftarrow,t}^2 - 4 c_t) = 2 \\sigma_{\\leftarrow,t}^2 - 2 c_t\n$$\nSolving for the optimal weight $g_t^{\\star}$:\n$$\ng_t^{\\star} = \\frac{2 \\sigma_{\\leftarrow,t}^2 - 2 c_t}{2 \\sigma_{\\rightarrow,t}^2 + 2 \\sigma_{\\leftarrow,t}^2 - 4 c_t} = \\frac{\\sigma_{\\leftarrow,t}^2 - c_t}{\\sigma_{\\rightarrow,t}^2 + \\sigma_{\\leftarrow,t}^2 - 2c_t}\n$$\nNext, we evaluate this expression using the given noise statistics: $\\sigma_{\\rightarrow,t}^{2} = 0.36$, $\\sigma_{\\leftarrow,t}^{2} = 0.81$, and $c_t = 0.12$.\n$$\ng_t^{\\star} = \\frac{0.81 - 0.12}{0.36 + 0.81 - 2(0.12)} = \\frac{0.69}{1.17 - 0.24} = \\frac{0.69}{0.93} = \\frac{69}{93} = \\frac{23}{31}\n$$\nNow, we compute the value of the learned gate $g_t^{\\mathrm{learn}}$. The input to the sigmoid function is $z = w_{\\rightarrow} h_t^{\\rightarrow} + w_{\\leftarrow} h_t^{\\leftarrow} + b$.\nUsing the provided values $h_t^{\\rightarrow} = 1.4$, $h_t^{\\leftarrow} = 0.6$, $w_{\\rightarrow} = 0.5$, $w_{\\leftarrow} = 0.25$, and $b = \\ln(3) - 0.85$:\n$$\nz = (0.5)(1.4) + (0.25)(0.6) + (\\ln(3) - 0.85)\n$$\n$$\nz = 0.7 + 0.15 + \\ln(3) - 0.85\n$$\n$$\nz = 0.85 + \\ln(3) - 0.85 = \\ln(3)\n$$\nThe value of the gate is $g_t^{\\mathrm{learn}} = \\sigma(z) = \\sigma(\\ln(3))$.\n$$\ng_t^{\\mathrm{learn}} = \\frac{1}{1 + \\exp(-\\ln(3))} = \\frac{1}{1 + \\exp(\\ln(3^{-1}))} = \\frac{1}{1 + \\frac{1}{3}} = \\frac{1}{\\frac{4}{3}} = \\frac{3}{4}\n$$\nFinally, we compute the absolute difference $|g_t^{\\mathrm{learn}} - g_t^{\\star}|$.\n$$\n\\left| \\frac{3}{4} - \\frac{23}{31} \\right| = \\left| \\frac{3 \\times 31}{4 \\times 31} - \\frac{23 \\times 4}{31 \\times 4} \\right| = \\left| \\frac{93 - 92}{124} \\right| = \\frac{1}{124}\n$$\nTo provide the final answer, we convert this fraction to a decimal and round to four significant figures.\n$$\n\\frac{1}{124} \\approx 0.008064516...\n$$\nThe first significant figure is $8$. The first four significant figures are $8$, $0$, $6$, and $4$. The next digit is $5$, so we round the last significant figure up.\nThe result is $0.008065$.", "answer": "$$\\boxed{0.008065}$$", "id": "3103018"}, {"introduction": "While future context is powerful, it is not always reliable. This final exercise [@problem_id:3103010] explores a critical trade-off: how can a model learn to trust its past-derived knowledge when faced with potentially misleading future signals? Through a simplified, deterministic BiRNN, you will investigate how a gating-like parameter, $\\alpha$, can dynamically arbitrate between the forward and backward states, ensuring robust performance even when context is corrupted.", "problem": "You are given a discrete-time sequence classification scenario defined using a Bidirectional Recurrent Neural Network (BiRNN). The objective is to construct a task where wrong future context is introduced at inference, and to test whether the model can recover by relying more on the forward hidden state $h^{\\rightarrow}$. The problem is formulated entirely in mathematical terms.\n\nFundamental base: A Recurrent Neural Network (RNN) is defined by the state recursion $h_t = \\phi\\left(W_x x_t + W_h h_{t-1} + b\\right)$, where $h_t$ is the hidden state at time index $t$, $x_t$ is the input at time index $t$, $W_x$ and $W_h$ are weight matrices, $b$ is a bias vector, and $\\phi$ is an elementwise nonlinearity. A Bidirectional Recurrent Neural Network (BiRNN) computes two hidden state sequences: a forward state $h^{\\rightarrow}_t$ using information from the past, and a backward state $h^{\\leftarrow}_t$ using information from the future. In this problem, to make the analysis exact and fully deterministic, we consider the special case $\\phi(u) = u$ (identity function) with scalar states and inputs; with appropriately chosen $W_x$, $W_h$, and $b$, the recursions reduce to counting a specific cue in the sequence.\n\nTask definition:\n- Input alphabet is $\\{0,1,2\\}$. The model’s cue is the occurrence of the token $2$.\n- For a sequence $\\{x_1, x_2, \\dots, x_L\\}$ of length $L$, define the forward hidden state as the count of cue occurrences in the prefix up to index $t$: \n$$h^{\\rightarrow}_t = \\sum_{i=1}^{t} \\mathbf{1}[x_i = 2],$$\nand the backward hidden state as the count of cue occurrences in the suffix starting at index $t$:\n$$h^{\\leftarrow}_t = \\sum_{i=t}^{L} \\mathbf{1}[x_i = 2],$$\nwhere $\\mathbf{1}[\\cdot]$ is the indicator function.\n- At a chosen target index $t^\\*$, form a scalar representation by mixing the forward and backward states:\n$$z_{t^\\*}(\\alpha) = \\alpha \\, h^{\\rightarrow}_{t^\\*} + (1 - \\alpha) \\, h^{\\leftarrow}_{t^\\*},$$\nwith trade-off parameter $\\alpha \\in [0,1]$ controlling reliance on the forward state.\n- Define the ground truth label at $t^\\*$ to depend only on the past (prefix) cue presence:\n$$y = \\mathbf{1}\\left[h^{\\rightarrow}_{t^\\*}  0\\right].$$\n- Define the predicted label from the BiRNN mixture as:\n$$\\hat{y} = \\mathbf{1}\\left[z_{t^\\*}(\\alpha) \\ge 0.5\\right].$$\n\nWrong future context at inference:\n- At inference, you will optionally corrupt the future context by forcing exactly one position $t^\\* + 1$ to be the cue token $2$, regardless of the original sequence. That is, for corruption, set $x_{t^\\*+1} \\leftarrow 2$ if $t^\\* + 1 \\le L$. This simulates wrong future context that should not affect the ground truth label $y$, which depends only on the prefix.\n\nYour program must implement the above logic exactly and evaluate whether the model output $\\hat{y}$ matches the ground truth $y$ for a provided test suite. For each test case, the program must compute a boolean indicating whether $\\hat{y} = y$.\n\nTest suite (each case is a tuple containing $(\\text{sequence}, t^\\*, \\alpha, \\text{corruption flag})$):\n1. Happy path with correct future context:\n   - Sequence: $[1,0,2,0,0,1,0,0]$, $L = 8$.\n   - Target index: $t^\\* = 4$.\n   - Trade-off: $\\alpha = 0.5$.\n   - Corruption: $\\text{False}$.\n   - Expected behavior: $\\hat{y}$ should match $y$.\n2. Wrong future context introduced, low reliance on $h^{\\rightarrow}$:\n   - Sequence: $[0,1,1,0,0,0,0,0]$, $L = 8$.\n   - Target index: $t^\\* = 4$.\n   - Trade-off: $\\alpha = 0.2$.\n   - Corruption: $\\text{True}$ (force $x_{5} \\leftarrow 2$).\n   - Expected behavior: With wrong future, low $\\alpha$ should cause $\\hat{y} \\ne y$.\n3. Wrong future context introduced, high reliance on $h^{\\rightarrow}$:\n   - Sequence: $[0,1,1,0,0,0,0,0]$, $L = 8$.\n   - Target index: $t^\\* = 4$.\n   - Trade-off: $\\alpha = 0.8$.\n   - Corruption: $\\text{True}$ (force $x_{5} \\leftarrow 2$).\n   - Expected behavior: With wrong future, high $\\alpha$ should cause $\\hat{y} = y$.\n4. Boundary case, full reliance on $h^{\\rightarrow}$:\n   - Sequence: $[2,0,0,0,0,0,0,0]$, $L = 8$.\n   - Target index: $t^\\* = 4$.\n   - Trade-off: $\\alpha = 1.0$.\n   - Corruption: $\\text{True}$ (force $x_{5} \\leftarrow 2$).\n   - Expected behavior: $\\hat{y}$ should match $y$ regardless of wrong future.\n5. Boundary case, full reliance on $h^{\\leftarrow}$:\n   - Sequence: $[0,0,0,0,0,0,0,0]$, $L = 8$.\n   - Target index: $t^\\* = 4$.\n   - Trade-off: $\\alpha = 0.0$.\n   - Corruption: $\\text{True}$ (force $x_{5} \\leftarrow 2$).\n   - Expected behavior: $\\hat{y} \\ne y$ due to wrong future context overpowering.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $[r_1,r_2,r_3,r_4,r_5]$, where each $r_i$ is a boolean indicating whether $\\hat{y} = y$ for the corresponding test case.", "solution": "The problem presents a deterministic and simplified model of a Bidirectional Recurrent Neural Network (BiRNN) to analyze its behavior under normal and corrupted input conditions. The task is to evaluate whether the model's prediction, which mixes information from past and future context, aligns with a ground truth label that depends solely on past context.\n\nThe core components of the model are defined as follows, for a given input sequence $\\{x_1, x_2, \\dots, x_L\\}$ with length $L$ and elements from the alphabet $\\{0, 1, 2\\}$. The special cue token is $2$.\n\n1.  **Forward Hidden State**: The forward state at a time index $t$ is the count of cue tokens in the prefix of the sequence up to and including index $t$.\n    $$h^{\\rightarrow}_t = \\sum_{i=1}^{t} \\mathbf{1}[x_i = 2]$$\n    where $\\mathbf{1}[\\cdot]$ is the indicator function. This represents information accumulated from the past.\n\n2.  **Backward Hidden State**: The backward state at time index $t$ is the count of cue tokens in the suffix of the sequence starting from and including index $t$.\n    $$h^{\\leftarrow}_t = \\sum_{i=t}^{L} \\mathbf{1}[x_i = 2]$$\n    This represents information accumulated from the future.\n\n3.  **Ground Truth Label**: The ground truth label $y$ at a target index $t^\\*$ is defined based only on the forward state, reflecting a task where the future is irrelevant to the correct answer.\n    $$y = \\mathbf{1}\\left[h^{\\rightarrow}_{t^\\*}  0\\right]$$\n    Crucially, this is calculated using the original, uncorrupted sequence.\n\n4.  **Mixed Representation and Prediction**: The model combines the forward and backward states at the target index $t^\\*$ into a single representation $z_{t^\\*}(\\alpha)$, controlled by a parameter $\\alpha \\in [0, 1]$.\n    $$z_{t^\\*}(\\alpha) = \\alpha \\, h^{\\rightarrow}_{t^\\*} + (1 - \\alpha) \\, h^{\\leftarrow}_{t^\\*}$$\n    The predicted label $\\hat{y}$ is then derived by thresholding this value.\n    $$\\hat{y} = \\mathbf{1}\\left[z_{t^\\*}(\\alpha) \\ge 0.5\\right]$$\n    For prediction, the states $h^{\\rightarrow}_{t^\\*}$ and $h^{\\leftarrow}_{t^\\*}$ are computed on the potentially corrupted sequence.\n\nThe analysis proceeds by applying these definitions to each test case. The problem uses 1-based indexing for mathematical formulation, which corresponds to 0-based indexing in the implementation (e.g., $x_i$ corresponds to `sequence[i-1]`).\n\n**Test Case Analysis**\n\n**Case 1:**\n-   Input: sequence_1 = $[1,0,2,0,0,1,0,0]$, $L=8$, $t^\\*=4$, $\\alpha=0.5$, corruption=`False`.\n-   The sequence is not modified.\n-   Ground Truth $y$: The prefix for the ground truth is $[x_1, x_2, x_3, x_4] = [1,0,2,0]$.\n    $h^{\\rightarrow}_{4}(\\text{original}) = \\mathbf{1}[x_3=2] = 1$.\n    $y = \\mathbf{1}[1  0] = 1$.\n-   Prediction $\\hat{y}$:\n    $h^{\\rightarrow}_{4} = 1$ (from prefix $[1,0,2,0]$).\n    $h^{\\leftarrow}_{4} = \\sum_{i=4}^{8} \\mathbf{1}[x_i=2] = 0$ (from suffix $[0,0,1,0,0]$).\n    $z_{4}(0.5) = 0.5 \\cdot 1 + (1-0.5) \\cdot 0 = 0.5$.\n    $\\hat{y} = \\mathbf{1}[0.5 \\ge 0.5] = 1$.\n-   Result: $y = \\hat{y}$. The output is `True`.\n\n**Case 2:**\n-   Input: sequence_2 = $[0,1,1,0,0,0,0,0]$, $L=8$, $t^\\*=4$, $\\alpha=0.2$, corruption=`True`.\n-   Corruption: The token at index $t^\\*+1=5$ is set to $2$. The processed sequence becomes $x_{\\text{proc}} = [0,1,1,0,2,0,0,0]$.\n-   Ground Truth $y$: Based on the original prefix $[0,1,1,0]$.\n    $h^{\\rightarrow}_{4}(\\text{original}) = 0$.\n    $y = \\mathbf{1}[0  0] = 0$.\n-   Prediction $\\hat{y}$: Based on $x_{\\text{proc}}$.\n    The prediction's prefix, $[0,1,1,0]$, is unaffected by the future corruption. $h^{\\rightarrow}_{4} = 0$.\n    The prediction's suffix is $[x_4, \\dots, x_8] = [0,2,0,0,0]$. $h^{\\leftarrow}_{4} = 1$.\n    $z_{4}(0.2) = 0.2 \\cdot 0 + (1-0.2) \\cdot 1 = 0.8$.\n    $\\hat{y} = \\mathbf{1}[0.8 \\ge 0.5] = 1$.\n-   Result: $y \\ne \\hat{y}$. The output is `False`. The low value of $\\alpha$ causes the model to rely heavily on the misleading future context.\n\n**Case 3:**\n-   Input: Same as Case 2, but with $\\alpha=0.8$.\n-   Corruption: $x_{\\text{proc}} = [0,1,1,0,2,0,0,0]$.\n-   Ground Truth $y$: Same as Case 2. $y=0$.\n-   Prediction $\\hat{y}$: States are the same as Case 2: $h^{\\rightarrow}_{4}=0$, $h^{\\leftarrow}_{4}=1$.\n    $z_{4}(0.8) = 0.8 \\cdot 0 + (1-0.8) \\cdot 1 = 0.2$.\n    $\\hat{y} = \\mathbf{1}[0.2 \\ge 0.5] = 0$.\n-   Result: $y = \\hat{y}$. The output is `True`. The high value of $\\alpha$ correctly biases the model towards the past context, ignoring the corruption.\n\n**Case 4:**\n-   Input: sequence_4 = $[2,0,0,0,0,0,0,0]$, $L=8$, $t^\\*=4$, $\\alpha=1.0$, corruption=`True`.\n-   Corruption: $x_{\\text{proc}} = [2,0,0,0,2,0,0,0]$.\n-   Ground Truth $y$: Based on original prefix $[2,0,0,0]$.\n    $h^{\\rightarrow}_{4}(\\text{original}) = 1$.\n    $y = \\mathbf{1}[1  0] = 1$.\n-   Prediction $\\hat{y}$:\n    With $\\alpha=1.0$, $z_{4}(1.0) = h^{\\rightarrow}_{4}$.\n    The prefix is $[2,0,0,0]$, so $h^{\\rightarrow}_{4}=1$.\n    $z_4(1.0) = 1$.\n    $\\hat{y} = \\mathbf{1}[1 \\ge 0.5] = 1$.\n-   Result: $y = \\hat{y}$. The output is `True`. With $\\alpha=1.0$, the model is purely a forward RNN and is immune to future context manipulations.\n\n**Case 5:**\n-   Input: sequence_5 = $[0,0,0,0,0,0,0,0]$, $L=8$, $t^\\*=4$, $\\alpha=0.0$, corruption=`True`.\n-   Corruption: $x_{\\text{proc}} = [0,0,0,0,2,0,0,0]$.\n-   Ground Truth $y$: Based on original prefix $[0,0,0,0]$.\n    $h^{\\rightarrow}_{4}(\\text{original}) = 0$.\n    $y = \\mathbf{1}[0  0] = 0$.\n-   Prediction $\\hat{y}$:\n    With $\\alpha=0.0$, $z_{4}(0.0) = h^{\\leftarrow}_{4}$.\n    The suffix is $[x_4, \\dots, x_8] = [0,2,0,0,0]$, so $h^{\\leftarrow}_{4}=1$.\n    $z_{4}(0.0) = 1$.\n    $\\hat{y} = \\mathbf{1}[1 \\ge 0.5] = 1$.\n-   Result: $y \\ne \\hat{y}$. The output is `False`. With $\\alpha=0.0$, the model only considers future context and is completely misled by the corruption.\n\nSummary of results:\n-   Case 1: $y=1, \\hat{y}=1 \\implies$ `True`\n-   Case 2: $y=0, \\hat{y}=1 \\implies$ `False`\n-   Case 3: $y=0, \\hat{y}=0 \\implies$ `True`\n-   Case 4: $y=1, \\hat{y}=1 \\implies$ `True`\n-   Case 5: $y=0, \\hat{y}=1 \\implies$ `False`", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef evaluate_case(sequence, t_star, alpha, corruption):\n    \"\"\"\n    Evaluates a single test case according to the problem's BiRNN formulation.\n\n    Args:\n        sequence (list): The input sequence of tokens {0, 1, 2}.\n        t_star (int): The 1-based target time index.\n        alpha (float): The trade-off parameter for mixing forward/backward states.\n        corruption (bool): Flag to indicate if wrong future context is introduced.\n\n    Returns:\n        bool: True if the predicted label matches the ground truth, False otherwise.\n    \"\"\"\n    L = len(sequence)\n    cue = 2\n\n    # --- 1. Calculate Ground Truth Label (y) ---\n    # The ground truth depends only on the original prefix.\n    # h_forward_gt is calculated on the prefix up to and including t_star.\n    # Python slice sequence[0:t_star] includes indices 0 to t_star-1.\n    original_prefix = np.array(sequence[:t_star])\n    h_forward_gt = np.sum(original_prefix == cue)\n    y = 1 if h_forward_gt > 0 else 0\n\n    # --- 2. Apply Corruption for Prediction ---\n    # A copy of the sequence is made to apply optional corruption.\n    x_proc = list(sequence)\n    if corruption:\n        # Corruption is applied at index t*+1 (1-based), which is t_star (0-based).\n        # This is valid only if the index is within the sequence bounds.\n        if t_star  L:\n            x_proc[t_star] = cue\n    \n    x_proc_np = np.array(x_proc)\n    \n    # --- 3. Calculate States for Prediction (h_forward, h_backward) ---\n    # h_forward is calculated on the prefix of the (potentially corrupted) sequence.\n    # The prefix is not affected by the specified corruption at t*+1.\n    h_forward_pred = np.sum(x_proc_np[:t_star] == cue)\n\n    # h_backward is calculated on the suffix starting from t_star.\n    # This corresponds to the slice from index t_star-1 to the end.\n    h_backward_pred = np.sum(x_proc_np[t_star-1:] == cue)\n\n    # --- 4. Calculate Mixed Representation (z) and Predicted Label (y_hat) ---\n    z = alpha * h_forward_pred + (1 - alpha) * h_backward_pred\n    y_hat = 1 if z >= 0.5 else 0\n\n    # --- 5. Compare and Return Result ---\n    return y == y_hat\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple: (sequence, t*, alpha, corruption flag)\n    test_cases = [\n        ([1, 0, 2, 0, 0, 1, 0, 0], 4, 0.5, False),\n        ([0, 1, 1, 0, 0, 0, 0, 0], 4, 0.2, True),\n        ([0, 1, 1, 0, 0, 0, 0, 0], 4, 0.8, True),\n        ([2, 0, 0, 0, 0, 0, 0, 0], 4, 1.0, True),\n        ([0, 0, 0, 0, 0, 0, 0, 0], 4, 0.0, True),\n    ]\n\n    results = []\n    for case in test_cases:\n        seq, t_star, alpha, corrup = case\n        result = evaluate_case(seq, t_star, alpha, corrup)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3103010"}]}