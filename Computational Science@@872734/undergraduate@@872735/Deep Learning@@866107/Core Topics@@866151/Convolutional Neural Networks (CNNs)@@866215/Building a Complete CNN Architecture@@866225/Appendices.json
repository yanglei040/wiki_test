{"hands_on_practices": [{"introduction": "Modern architectures for tasks like object detection must process information at multiple scales. Feature Pyramid Networks (FPNs) are a canonical solution, combining high-resolution, semantically weak features with low-resolution, semantically strong features via a top-down pathway. This exercise [@problem_id:3103702] provides essential practice in tracing tensor shapes and calculating parameters through such a network, a fundamental skill required to design, understand, and debug any complex CNN architecture.", "problem": "A Convolutional Neural Network (CNN) backbone processes an input image of size $640 \\times 640$ and produces three feature maps at successive stages, denoted $C_3$, $C_4$, and $C_5$. These maps have spatial strides $8$, $16$, and $32$ relative to the input, with shapes given by:\n- $C_3$: $80 \\times 80 \\times 128$,\n- $C_4$: $40 \\times 40 \\times 256$,\n- $C_5$: $20 \\times 20 \\times 512$.\n\nA Feature Pyramid Network (FPN) is constructed via lateral and top-down pathways:\n- Each $C_i$ is first passed through a lateral $1 \\times 1$ convolution with stride $1$ and zero padding, mapping to $F$ channels, with $F = 192$. Assume biases are included in every convolution.\n- Define $M_5 = \\text{Conv}_{1 \\times 1}(C_5)$, $M_4 = \\text{Conv}_{1 \\times 1}(C_4) + \\text{Upsample}_{\\times 2}(M_5)$, and $M_3 = \\text{Conv}_{1 \\times 1}(C_3) + \\text{Upsample}_{\\times 2}(M_4)$, where $\\text{Upsample}_{\\times 2}$ denotes nearest-neighbor upsampling by a factor of $2$ in height and width.\n- Each $M_i$ is then passed through a $3 \\times 3$ convolution with stride $1$ and padding $1$, producing $P_i = \\text{Conv}_{3 \\times 3}(M_i)$ with $F$ output channels.\n\nUse the following foundational facts:\n- For a convolution with kernel size $K_h \\times K_w$, input channels $C_{\\text{in}}$, and output channels $C_{\\text{out}}$, the number of trainable parameters (including biases) is $K_h \\cdot K_w \\cdot C_{\\text{in}} \\cdot C_{\\text{out}} + C_{\\text{out}}$.\n- Nearest-neighbor upsampling by a factor of $2$ maps a tensor of shape $H \\times W \\times C$ to $2H \\times 2W \\times C$.\n- Element-wise addition of tensors requires identical shapes in height, width, and channels.\n- With stride $1$ and appropriate zero padding, a $1 \\times 1$ convolution preserves spatial dimensions; a $3 \\times 3$ convolution with padding $1$ preserves spatial dimensions.\n\nTasks:\n1. Derive the shapes of $M_5$, $M_4$, and $M_3$, ensuring tensor addition in the lateral pathway is shape-aligned.\n2. Derive the shapes of $P_5$, $P_4$, and $P_3$.\n3. Compute the total number of trainable parameters used by all six convolutions in this FPN pathway (the three $1 \\times 1$ lateral convolutions and the three $3 \\times 3$ convolutions applied to $M_5$, $M_4$, and $M_3$). Express your final answer as a single exact integer. No rounding is required.", "solution": "The problem requires the calculation of feature map shapes and the total number of trainable parameters in a specified Feature Pyramid Network (FPN) architecture. The solution will be derived by sequentially addressing the three tasks given in the problem statement. All shapes are presented in the format Height $\\times$ Width $\\times$ Channels.\n\n### Task 1: Derive Shapes of $M_5$, $M_4$, and $M_3$\n\nThe FPN is constructed from a set of backbone feature maps, $C_3$, $C_4$, and $C_5$, with the following shapes:\n- $S(C_3) = 80 \\times 80 \\times 128$\n- $S(C_4) = 40 \\times 40 \\times 256$\n- $S(C_5) = 20 \\times 20 \\times 512$\n\nThe FPN pathway maps each $C_i$ to a common channel dimension $F=192$.\n\n**Shape of $M_5$**:\n$M_5$ is defined as $M_5 = \\text{Conv}_{1 \\times 1}(C_5)$.\nThe input is $C_5$ with shape $20 \\times 20 \\times 512$. The convolution is a $1 \\times 1$ layer with stride $1$ and zero padding, which preserves the spatial dimensions. The number of output channels is $F=192$.\nTherefore, the shape of $M_5$ is $20 \\times 20 \\times 192$.\n\n**Shape of $M_4$**:\n$M_4$ is defined as $M_4 = \\text{Conv}_{1 \\times 1}(C_4) + \\text{Upsample}_{\\times 2}(M_5)$.\nTo find the shape of $M_4$, we must first determine the shapes of the two tensors being added.\n1.  The first term is $\\text{Conv}_{1 \\times 1}(C_4)$. The input is $C_4$ with shape $40 \\times 40 \\times 256$. The $1 \\times 1$ convolution preserves spatial dimensions and maps the channels to $F=192$. The shape of this term is $40 \\times 40 \\times 192$.\n2.  The second term is $\\text{Upsample}_{\\times 2}(M_5)$. The input is $M_5$ with shape $20 \\times 20 \\times 192$. Nearest-neighbor upsampling by a factor of $2$ doubles the height and width. The shape of this term is $(2 \\times 20) \\times (2 \\times 20) \\times 192$, which is $40 \\times 40 \\times 192$.\n\nSince both terms have the identical shape $40 \\times 40 \\times 192$, the element-wise addition is valid. The shape of the resulting tensor $M_4$ is $40 \\times 40 \\times 192$.\n\n**Shape of $M_3$**:\n$M_3$ is defined as $M_3 = \\text{Conv}_{1 \\times 1}(C_3) + \\text{Upsample}_{\\times 2}(M_4)$.\nFollowing the same logic:\n1.  The first term is $\\text{Conv}_{1 \\times 1}(C_3)$. The input is $C_3$ with shape $80 \\times 80 \\times 128$. The $1 \\times 1$ convolution maps this to a shape of $80 \\times 80 \\times 192$.\n2.  The second term is $\\text{Upsample}_{\\times 2}(M_4)$. The input is $M_4$ with shape $40 \\times 40 \\times 192$. Upsampling by a factor of $2$ yields a shape of $(2 \\times 40) \\times (2 \\times 40) \\times 192$, which is $80 \\times 80 \\times 192$.\n\nBoth terms have the identical shape $80 \\times 80 \\times 192$. The addition is valid, and the shape of the resulting tensor $M_3$ is $80 \\times 80 \\times 192$.\n\n### Task 2: Derive Shapes of $P_5$, $P_4$, and $P_3$\n\nThe pyramid feature maps $P_i$ are produced by applying a $3 \\times 3$ convolution to each $M_i$, i.e., $P_i = \\text{Conv}_{3 \\times 3}(M_i)$. This convolution has a stride of $1$ and padding of $1$, which preserves spatial dimensions. The number of output channels is $F=192$.\n\n**Shape of $P_5$**:\nThe input is $M_5$ with shape $20 \\times 20 \\times 192$. The $3 \\times 3$ convolution preserves spatial dimensions and the number of channels. Thus, the shape of $P_5$ is $20 \\times 20 \\times 192$.\n\n**Shape of $P_4$**:\nThe input is $M_4$ with shape $40 \\times 40 \\times 192$. The $3 \\times 3$ convolution preserves spatial dimensions and the number of channels. Thus, the shape of $P_4$ is $40 \\times 40 \\times 192$.\n\n**Shape of $P_3$**:\nThe input is $M_3$ with shape $80 \\times 80 \\times 192$. The $3 \\times 3$ convolution preserves spatial dimensions and the number of channels. Thus, the shape of $P_3$ is $80 \\times 80 \\times 192$.\n\n### Task 3: Compute the Total Number of Trainable Parameters\n\nThe number of trainable parameters for a convolutional layer (including biases) is given by the formula $K_h \\cdot K_w \\cdot C_{\\text{in}} \\cdot C_{\\text{out}} + C_{\\text{out}}$, where $K_h$ and $K_w$ are the kernel dimensions, $C_{\\text{in}}$ is the number of input channels, and $C_{\\text{out}}$ is the number of output channels.\n\nWe calculate the parameters for the six convolutions in the FPN pathway.\n\n**Parameters for the three lateral $1 \\times 1$ convolutions:**\nThe kernel size is $1 \\times 1$ and $C_{\\text{out}} = F = 192$.\n1.  Convolution on $C_5$: $C_{\\text{in}} = 512$.\n    Parameters = $1 \\cdot 1 \\cdot 512 \\cdot 192 + 192 = 98304 + 192 = 98496$.\n2.  Convolution on $C_4$: $C_{\\text{in}} = 256$.\n    Parameters = $1 \\cdot 1 \\cdot 256 \\cdot 192 + 192 = 49152 + 192 = 49344$.\n3.  Convolution on $C_3$: $C_{\\text{in}} = 128$.\n    Parameters = $1 \\cdot 1 \\cdot 128 \\cdot 192 + 192 = 24576 + 192 = 24768$.\n\nTotal parameters for lateral convolutions = $98496 + 49344 + 24768 = 172608$.\n\n**Parameters for the three $3 \\times 3$ convolutions:**\nThese convolutions are applied to $M_5$, $M_4$, and $M_3$ to produce $P_5$, $P_4$, and $P_3$.\nThe kernel size is $3 \\times 3$. For all three, the input and output channel dimensions are $C_{\\text{in}} = F = 192$ and $C_{\\text{out}} = F = 192$.\nTherefore, all three convolutions have the same number of parameters.\nParameters per convolution = $3 \\cdot 3 \\cdot 192 \\cdot 192 + 192 = 9 \\cdot (192^2) + 192 = 9 \\cdot 36864 + 192 = 331776 + 192 = 331968$.\n\nTotal parameters for the three $3 \\times 3$ convolutions = $3 \\times 331968 = 995904$.\n\n**Total Trainable Parameters in the FPN Pathway:**\nThe total is the sum of parameters from both sets of convolutions.\nTotal Parameters = (Parameters of lateral convolutions) + (Parameters of $3 \\times 3$ convolutions)\nTotal Parameters = $172608 + 995904 = 1168512$.", "answer": "$$\\boxed{1168512}$$", "id": "3103702"}, {"introduction": "Encoder-decoder architectures, such as the U-Net, owe their success to skip connections that merge deep, semantic information with shallow, high-resolution details. However, successive strided convolutions can create spatial dimension mismatches, leading to \"off-by-one\" errors that prevent clean feature fusion. This practice [@problem_id:3103688] challenges you to diagnose this critical alignment issue and select the correct upsampling strategy to ensure pixel-perfect concatenation, a vital skill for building robust segmentation models.", "problem": "A Convolutional Neural Network (CNN) encoder-decoder is being built for semantic segmentation. The input image has spatial size $129 \\times 129$. The encoder uses two successive two-dimensional convolutions, each with kernel size $3 \\times 3$, stride $s=2$, and padding chosen so that the convolution is \"same\" in the sense that the output size along each spatial dimension is $\\lceil N/s \\rceil$. Assume unit dilation and that all convolutions are centered in the usual discrete sense for odd kernels. Thus, the first downsampling produces a feature map of size $65 \\times 65$, and the second downsampling produces a bottleneck feature map of size $33 \\times 33$. A skip connection is taken from the first downsampling stage ($65 \\times 65$) to be concatenated with the decoder output of the same spatial size.\n\nYou are tasked with choosing the decoder upsampling block that upsamples the $33 \\times 33$ bottleneck feature map to exactly $65 \\times 65$ and preserves pixel-center alignment with the $65 \\times 65$ skip feature map so that concatenation does not require cropping and does not introduce an off-by-one spatial shift. Pixel-center alignment here means that the set of output pixel-center coordinates, when expressed back in the coordinate system of the original input, coincide with those of the encoder’s $65 \\times 65$ skip map.\n\nUse the following well-tested facts and definitions as your starting point:\n\n- For a standard convolution with input length $N$, kernel size $K$, stride $s$, padding $P$ (zero padding on both sides), and dilation $d=1$, the output length is $N_{\\text{out}} = \\left\\lfloor \\frac{N + 2P - K}{s} \\right\\rfloor + 1$. The \"same\" padding convention for stride $s$ guarantees $N_{\\text{out}} = \\lceil N/s \\rceil$ and, for odd $K$, anchors output centers at input centers separated by steps of $s$ without fractional offsets.\n- For a transposed convolution (also called a fractionally strided or deconvolution) with input length $N$, kernel size $K$, stride $s$, padding $P$, and output padding $OP$, the output length is $N_{\\text{out}} = (N-1)s - 2P + K + OP$.\n- Nearest-neighbor upsampling by a factor $r$ duplicates pixel values so that output pixel-center indices are integer refinements of the input grid.\n- Bilinear upsampling with \"align corners\" set to $\\text{True}$ uses the coordinate mapping $u = q \\cdot \\frac{N_{\\text{in}} - 1}{N_{\\text{out}} - 1}$ from output index $q$ to continuous input coordinate $u$, aligning the first and last centers of input and output; with \"align corners\" set to $\\text{False}$, the mapping is $u = \\left( q + \\frac{1}{2} \\right) \\cdot \\frac{N_{\\text{in}}}{N_{\\text{out}}} - \\frac{1}{2}$, which avoids corner alignment and introduces a half-pixel offset relative to the input grid in general.\n\nConsider the following candidate decoder blocks (each applied to the $33 \\times 33$ bottleneck fmap) aimed at producing an output concatenable with the $65 \\times 65$ skip map:\n\nA. A transposed convolution with kernel size $4 \\times 4$, stride $2$, padding $1$, output padding $0$.\n\nB. A transposed convolution with kernel size $3 \\times 3$, stride $2$, padding $1$, output padding $1$.\n\nC. Nearest-neighbor upsampling by a scale factor $2$, followed by a convolution with kernel size $3 \\times 3$, stride $1$, and \"same\" padding.\n\nD. Bilinear upsampling by a scale factor $2$ with \"align corners\" disabled, followed by a convolution with kernel size $3 \\times 3$, stride $1$, and \"same\" padding.\n\nE. Bilinear upsampling to explicit target size $65 \\times 65$ with \"align corners\" enabled, followed by a convolution with kernel size $3 \\times 3$, stride $1$, and \"same\" padding.\n\nWhich option(s) produce an output of exactly $65 \\times 65$ with pixel-center alignment matching the $65 \\times 65$ encoder skip map, so that concatenation is valid without cropping and without off-by-one center mismatch? Select all that apply.", "solution": "The problem asks us to identify which of the proposed decoder upsampling blocks can correctly upsample a $33 \\times 33$ feature map to a $65 \\times 65$ feature map while ensuring perfect pixel-center alignment with a corresponding skip connection of size $65 \\times 65$.\n\n### Step 1: Extract Givens\n- Input image size: $N_0 = 129 \\times 129$.\n- Encoder, 1st conv: Input size $N_0=129$, kernel $K=3$, stride $s=2$. Output is a \"same\" convolution of size $N_1 = \\lceil N_0/s \\rceil = \\lceil 129/2 \\rceil = 65$. This is the skip-connection feature map.\n- Encoder, 2nd conv: Input size $N_1=65$, kernel $K=3$, stride $s=2$. Output is a \"same\" convolution of size $N_2 = \\lceil N_1/s \\rceil = \\lceil 65/2 \\rceil = 33$. This is the bottleneck feature map.\n- Decoder task: Upsample the $N_2=33 \\times 33$ bottleneck map to match the $N_1=65 \\times 65$ skip map in size and pixel-center alignment.\n- Convolution output size formula: $N_{\\text{out}} = \\left\\lfloor \\frac{N + 2P - K}{s} \\right\\rfloor + 1$.\n- Transposed convolution output size formula: $N_{\\text{out}} = (N-1)s - 2P + K + OP$.\n- Bilinear upsampling (`align_corners=True`) coordinate map: $u = q \\cdot \\frac{N_{\\text{in}} - 1}{N_{\\text{out}} - 1}$.\n- Bilinear upsampling (`align_corners=False`) coordinate map: $u = \\left( q + \\frac{1}{2} \\right) \\cdot \\frac{N_{\\text{in}}}{N_{\\text{out}}} - \\frac{1}{2}$.\n\n### Step 2: Validate Problem Statement\nThe problem statement is well-defined, scientifically grounded in the principles of deep learning, and internally consistent. The downsampling calculations are correct based on the provided \"same\" convolution rule: from an input of size $129$, the output is $\\lceil 129/2 \\rceil = 65$; from an input of size $65$, the output is $\\lceil 65/2 \\rceil = 33$. The provided formulas for convolution, transposed convolution, and interpolation are standard or clearly defined for the context of the problem. The core task is to reverse the geometric transformation of a strided convolution, which is a practical and well-posed problem in CNN design. The problem is valid.\n\n### Step 3: Derivation and Option Analysis\n\nFirst, we establish the coordinate systems. Let the pixel centers of the $65 \\times 65$ skip map be at integer coordinates $\\{0, 1, 2, \\dots, 64\\}$ along one dimension. The problem states that the strided convolution (with odd kernel and, as is standard for \"same\" padding, symmetric padding) samples from this grid. A stride of $s=2$ means the centers of the resulting $33 \\times 33$ bottleneck map correspond to the coordinates $\\{0 \\cdot 2, 1 \\cdot 2, \\dots, 32 \\cdot 2\\} = \\{0, 2, 4, \\dots, 64\\}$ in the $65 \\times 65$ map's coordinate system.\n\nThe goal of the upsampling block is to take the $33 \\times 33$ map (whose centers are at physical locations $\\{0, 2, \\dots, 64\\}$) and produce a $65 \\times 65$ map whose centers are at physical locations $\\{0, 1, 2, \\dots, 64\\}$. This ensures perfect alignment for concatenation.\n\nWe will now evaluate each option against two criteria:\n1.  **Output Size**: The block must produce a feature map of size $65 \\times 65$.\n2.  **Pixel-Center Alignment**: The centers of the output pixels must align with the integer grid $\\{0, 1, \\dots, 64\\}$.\n\nThe input size for all candidate blocks is $N_{\\text{in}} = 33$.\n\n**A. A transposed convolution with kernel size $4 \\times 4$, stride $2$, padding $1$, output padding $0$.**\nWe use the provided formula for the output length of a transposed convolution: $N_{\\text{out}} = (N_{\\text{in}}-1)s - 2P + K + OP$.\nHere, $N_{\\text{in}}=33$, $s=2$, $K=4$, $P=1$, and $OP=0$.\n$$N_{\\text{out}} = (33-1) \\cdot 2 - 2 \\cdot 1 + 4 + 0 = 32 \\cdot 2 - 2 + 4 = 64 - 2 + 4 = 66$$\nThe output size is $66 \\times 66$, not $65 \\times 65$. This option fails the size requirement.\n**Verdict: Incorrect.**\n\n**B. A transposed convolution with kernel size $3 \\times 3$, stride $2$, padding $1$, output padding $1$.**\nWe use the same formula. Here, $N_{\\text{in}}=33$, $s=2$, $K=3$, $P=1$, and $OP=1$.\n$$N_{\\text{out}} = (33-1) \\cdot 2 - 2 \\cdot 1 + 3 + 1 = 32 \\cdot 2 - 2 + 3 + 1 = 64 - 2 + 4 = 66$$\nThe output size is $66 \\times 66$, not $65 \\times 65$. This option also fails the size requirement.\n**Verdict: Incorrect.**\n\n**C. Nearest-neighbor upsampling by a scale factor $2$, followed by a convolution with kernel size $3 \\times 3$, stride $1$, and \"same\" padding.**\nThe first step is nearest-neighbor upsampling. Upsampling an input of size $N$ by a scale factor $r$ typically produces an output of size $N \\cdot r$.\nFor $N_{\\text{in}} = 33$ and $r=2$, the output size is $33 \\cdot 2 = 66$.\nThe second step is a convolution with $s=1$ and \"same\" padding, which is designed to preserve the spatial dimensions of its input. Thus, the final output size is $66 \\times 66$. This fails the size requirement.\n**Verdict: Incorrect.**\n\n**D. Bilinear upsampling by a scale factor $2$ with \"align corners\" disabled, followed by a convolution with kernel size $3 \\times 3$, stride $1$, and \"same\" padding.**\nSimilar to option C, upsampling by a scale factor of $r=2$ on an input of size $N_{\\text{in}}=33$ results in an intermediate feature map of size $33 \\cdot 2 = 66$. The subsequent \"same\" convolution with $s=1$ preserves this size. The final output is $66 \\times 66$, which fails the size requirement. Furthermore, a bilinear upsampling with `align_corners` set to `False` introduces a half-pixel shift in its coordinate mapping, which would disrupt the pixel-center alignment even if the size were correct.\n**Verdict: Incorrect.**\n\n**E. Bilinear upsampling to explicit target size $65 \\times 65$ with \"align corners\" enabled, followed by a convolution with kernel size $3 \\times 3$, stride $1$, and \"same\" padding.**\nThe first step explicitly resizes the $33 \\times 33$ input to a $65 \\times 65$ feature map. The subsequent convolution with $s=1$ and \"same\" padding preserves the $65 \\times 65$ dimensions. Thus, this option satisfies the size requirement.\n\nNow, we must check for pixel-center alignment. The `align_corners=True` mode uses the coordinate mapping $u = q \\cdot \\frac{N_{\\text{in}} - 1}{N_{\\text{out}} - 1}$, where $q$ is an output pixel index and $u$ is the corresponding continuous coordinate in the input's index space.\nHere, $N_{\\text{in}}=33$ and $N_{\\text{out}}=65$. Let $q \\in \\{0, 1, \\dots, 64\\}$ be an index in the output grid.\n$$u(q) = q \\cdot \\frac{33 - 1}{65 - 1} = q \\cdot \\frac{32}{64} = \\frac{q}{2}$$\nThis means that to compute the value at output index $q$, we sample the input feature map at index-coordinate $u=q/2$. The input feature map indices are $\\{0, 1, \\dots, 32\\}$, and we established that the physical coordinate of input index $k$ is $2k$. Therefore, the physical coordinate corresponding to the continuous input index $u$ is $2u$.\nThe physical coordinate of the center of output pixel $q$ is thus:\n$$ \\text{Physical Coordinate}(q) = 2 \\cdot u(q) = 2 \\cdot \\left(\\frac{q}{2}\\right) = q $$\nAs the output index $q$ ranges from $0$ to $64$, the physical coordinates of the output pixel centers are $\\{0, 1, 2, \\dots, 64\\}$. This perfectly matches the grid of the $65 \\times 65$ skip connection feature map. The subsequent stride-1 \"same\" convolution does not alter this spatial alignment.\n**Verdict: Correct.**", "answer": "$$\\boxed{E}$$", "id": "3103688"}, {"introduction": "In real-world applications, model design is not just about maximizing performance; it is a balancing act constrained by computational budgets for memory and speed. This exercise frames architecture design as a constrained optimization problem, where choices about kernel size, stride, and channel depth have competing effects on a model's receptive field, resolution, and total parameter count. By searching for an optimal design under a fixed parameter budget [@problem_id:3103767], you will develop a powerful intuition for the engineering trade-offs inherent in building efficient networks and gain insight into the core ideas behind Neural Architecture Search (NAS).", "problem": "You are tasked with designing an algorithmic selector for a Convolutional Neural Network (CNN) architecture under a strict parameter budget, using foundational definitions of discrete convolution. The selector must choose, for each convolutional layer, the kernel size $k$, stride $s$, padding $p$, and number of output channels $C_{\\text{out}}$, subject to a total parameter constraint, and must maximize a mathematically specified surrogate for accuracy that depends on the receptive field and the spatial resolution across layers. Your program must not use any external data or machine learning libraries; it must compute all quantities algorithmically from the provided definitions and constraints.\n\nFundamental definitions to use:\n- A convolutional layer with kernel size $k$, input channels $C_{\\text{in}}$, and output channels $C_{\\text{out}}$ has parameter count\n$$\nP_{\\text{layer}} = k^2 \\, C_{\\text{in}} \\, C_{\\text{out}} + C_{\\text{out}},\n$$\nwhere the last term accounts for one bias per output channel.\n- Given an input spatial dimension $H \\times W$, the output spatial dimension $(H', W')$ of a two-dimensional convolution with stride $s$ and padding $p$ (applied identically along both dimensions) is\n$$\nH' = \\left\\lfloor \\frac{H + 2p - k}{s} \\right\\rfloor + 1, \\quad W' = \\left\\lfloor \\frac{W + 2p - k}{s} \\right\\rfloor + 1.\n$$\n- The receptive field size along one spatial dimension after a stack of layers obeys the recursion\n$$\nR_0 = 1, \\quad J_0 = 1,\n$$\n$$\nR_\\ell = R_{\\ell-1} + (k_\\ell - 1)\\,J_{\\ell-1}, \\quad J_\\ell = J_{\\ell-1} \\, s_\\ell,\n$$\nfor layer index $\\ell = 1,2,\\dots$, where $R_\\ell$ is the receptive field and $J_\\ell$ is the effective stride (\"jump\") relative to the input.\n\nSurrogate accuracy objective:\n- Define the surrogate accuracy score $S$ for an architecture with $L$ layers as\n$$\nS = \\sum_{\\ell=1}^{L} \\left[ \\ln\\!\\big(1 + C_{\\ell}\\big) \\cdot \\left( w_c \\cdot \\min\\!\\left(1, \\frac{R_\\ell}{R_{\\text{target}}}\\right) + w_r \\cdot \\frac{H_\\ell W_\\ell}{H_0 W_0} \\right) \\right],\n$$\nwhere $C_{\\ell}$ is the number of output channels at layer $\\ell$, $(H_\\ell, W_\\ell)$ are the spatial dimensions after layer $\\ell$, $(H_0, W_0)$ are the input spatial dimensions, $R_\\ell$ is the receptive field after layer $\\ell$, $R_{\\text{target}}$ is a target receptive field, and $w_c = 0.5$, $w_r = 0.5$ weight the coverage and resolution contributions equally. The natural logarithm is used for the channel utility term.\n\nConstraints and search space:\n- Padding must be \"same-style\" in the sense $p_\\ell = \\left\\lfloor \\frac{k_\\ell}{2} \\right\\rfloor$ for every layer $\\ell$. This ensures intuitive control over spatial dimensions when $s_\\ell = 1$.\n- All layers must have valid positive spatial dimensions, that is $H_\\ell \\ge 1$ and $W_\\ell \\ge 1$.\n- Let the total parameter budget be $B$. Architectures are feasible if the sum of parameters over all layers\n$$\nP_{\\text{total}} = \\sum_{\\ell=1}^{L} \\left( k_\\ell^2 \\, C_{\\ell-1} \\, C_{\\ell} + C_\\ell \\right)\n$$\nsatisfies $P_{\\text{total}} \\le B$, where $C_0$ is the input channel count.\n- The search space for each layer is discrete: $k_\\ell \\in \\{1,3,5\\}$, $s_\\ell \\in \\{1,2\\}$, and $C_\\ell$ drawn from a specified set per test case. Padding is fixed by $k_\\ell$ as above.\n\nObjective:\n- Among all architectures that satisfy the constraints, choose one that maximizes $S$. In case of ties in $S$ to within numerical tolerance, prefer architectures with smaller $P_{\\text{total}}$. If a tie persists, prefer lexicographically smaller layer specifications when flattened to the sequence $(k_1,s_1,p_1,C_1,k_2,s_2,p_2,C_2,\\dots)$.\n\nYour program must implement the exact computational pipeline defined above and solve the following test suite. For each test case, the program must search over all allowed numbers of layers $L$ and all allowed per-layer choices, subject to the budget and validity constraints, and report the best architecture.\n\nTest suite:\n- Test case $1$ (\"happy path\"):\n    - Input spatial dimensions: $(H_0, W_0) = (32, 32)$.\n    - Input channels: $C_0 = 3$.\n    - Budget: $B = 2000$.\n    - Target receptive field: $R_{\\text{target}} = 16$.\n    - Allowed number of layers: $L \\in \\{3\\}$.\n    - Allowed output channels per layer: $C_\\ell \\in \\{8,16,32\\}$ for all $\\ell$.\n- Test case $2$ (boundary small budget):\n    - Input spatial dimensions: $(H_0, W_0) = (32, 32)$.\n    - Input channels: $C_0 = 3$.\n    - Budget: $B = 110$.\n    - Target receptive field: $R_{\\text{target}} = 8$.\n    - Allowed number of layers: $L \\in \\{2\\}$.\n    - Allowed output channels per layer: $C_\\ell \\in \\{8,16\\}$ for all $\\ell$.\n- Test case $3$ (larger budget):\n    - Input spatial dimensions: $(H_0, W_0) = (64, 64)$.\n    - Input channels: $C_0 = 3$.\n    - Budget: $B = 5000$.\n    - Target receptive field: $R_{\\text{target}} = 32$.\n    - Allowed number of layers: $L \\in \\{3\\}$.\n    - Allowed output channels per layer: $C_\\ell \\in \\{16,32,64\\}$ for all $\\ell$.\n- Test case $4$ (edge small input):\n    - Input spatial dimensions: $(H_0, W_0) = (8, 8)$.\n    - Input channels: $C_0 = 3$.\n    - Budget: $B = 800$.\n    - Target receptive field: $R_{\\text{target}} = 8$.\n    - Allowed number of layers: $L \\in \\{2\\}$.\n    - Allowed output channels per layer: $C_\\ell \\in \\{8,16,32\\}$ for all $\\ell$.\n\nOutput specification:\n- For each test case, output a list of the form\n$$\n[\\; S^\\star,\\; P_{\\text{total}}^\\star,\\; [[k_1,s_1,p_1,C_1],\\,[k_2,s_2,p_2,C_2],\\,\\dots]\\;],\n$$\nwhere $S^\\star$ is the maximized surrogate score rounded to $4$ decimal places, $P_{\\text{total}}^\\star$ is the total parameter count of the chosen architecture as an integer, and the innermost list enumerates the chosen layer hyperparameters in order. If multiple values of $L$ are allowed for a test case, the selected architecture may have any $L$ in that set.\n- Your program should produce a single line of output containing the results for all four test cases as a comma-separated list enclosed in square brackets with no spaces, for example\n$$\n[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4].\n$$\nFor this problem, each $\\text{result}_i$ must itself be formatted with no spaces, including the nested lists, exactly as\n$$\n[\\text{score},\\text{params},[[k_1,s_1,p_1,C_1],\\dots]].\n$$", "solution": "The problem requires the design of an algorithmic selector for a Convolutional Neural Network (CNN) architecture. The selector must operate under a strict parameter budget and aim to maximize a given surrogate accuracy score, $S$. The selection process involves choosing the kernel size $k$, stride $s$, and number of output channels $C_{\\text{out}}$ for each layer in the network. The problem is a constrained optimization task over a discrete and finite search space.\n\nThe solution proceeds first by a rigorous validation of the problem statement, followed by the design and implementation of an exhaustive search algorithm to find the optimal architecture.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n- **Parameter Count per Layer**: $P_{\\text{layer}} = k^2 \\, C_{\\text{in}} \\, C_{\\text{out}} + C_{\\text{out}}$\n- **Output Spatial Dimension**: $H' = \\left\\lfloor \\frac{H + 2p - k}{s} \\right\\rfloor + 1$, $W' = \\left\\lfloor \\frac{W + 2p - k}{s} \\right\\rfloor + 1$\n- **Receptive Field Recursion**:\n  - $R_0 = 1, J_0 = 1$\n  - $R_\\ell = R_{\\ell-1} + (k_\\ell - 1)\\,J_{\\ell-1}$\n  - $J_\\ell = J_{\\ell-1} \\, s_\\ell$\n- **Surrogate Accuracy Score**: $S = \\sum_{\\ell=1}^{L} \\left[ \\ln\\!\\big(1 + C_{\\ell}\\big) \\cdot \\left( w_c \\cdot \\min\\!\\left(1, \\frac{R_\\ell}{R_{\\text{target}}}\\right) + w_r \\cdot \\frac{H_\\ell W_\\ell}{H_0 W_0} \\right) \\right]$, with $w_c = 0.5, w_r = 0.5$.\n- **Constraints**:\n  1.  Padding: $p_\\ell = \\left\\lfloor \\frac{k_\\ell}{2} \\right\\rfloor$ for every layer $\\ell$.\n  2.  Valid Spatial Dimensions: $H_\\ell \\ge 1, W_\\ell \\ge 1$ for all $\\ell$.\n  3.  Parameter Budget: $P_{\\text{total}} = \\sum_{\\ell=1}^{L} P_{\\text{layer}}(\\ell) \\le B$, where $P_{\\text{layer}}(\\ell) = k_\\ell^2 \\, C_{\\ell-1} \\, C_{\\ell} + C_\\ell$.\n- **Search Space**:\n  - Kernel size: $k_\\ell \\in \\{1,3,5\\}$\n  - Stride: $s_\\ell \\in \\{1,2\\}$\n  - Output channels: $C_\\ell$ from a specified set for each test case.\n- **Objective**: Maximize $S$.\n- **Tie-Breaking Rules**:\n  1.  Prefer smaller total parameters $P_{\\text{total}}$.\n  2.  If still tied, prefer lexicographically smaller flattened layer specification sequence $(k_1,s_1,p_1,C_1, k_2, \\dots)$.\n- **Test Cases**: Four specific test cases are provided with values for $(H_0, W_0)$, $C_0$, $B$, $R_{\\text{target}}$, allowed $L$, and allowed $C_\\ell$.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem statement is analyzed against the validation criteria.\n\n- **Scientifically Grounded**: The definitions for parameter count, output dimension calculation, and receptive field propagation are standard and fundamental in the field of deep learning. The surrogate accuracy score $S$ is a synthetic objective function, but it is mathematically well-defined and constructed from plausible heuristics: rewarding networks for effective receptive field coverage, preservation of spatial information (resolution), and increased feature complexity (channel count). The problem is free of pseudoscience and adheres to established mathematical and computational principles.\n- **Well-Posed**: The task is to find the maximum of a function $S$ over a discrete search space. For each test case, the number of layers $L$, and the sets of possible values for $k_\\ell$, $s_\\ell$, and $C_\\ell$ are all finite. This results in a finite, albeit potentially large, number of possible architectures. The problem is a well-defined constrained optimization problem. The explicit tie-breaking rules ensure that a unique solution exists.\n- **Objective**: The problem is specified entirely in formal mathematical language. The objective function, constraints, and search space are all defined with precision, leaving no room for subjectivity or ambiguity.\n\n**Step 3: Verdict and Action**\n\nThe problem is determined to be **valid**. It is scientifically sound, well-posed, objective, and self-contained. The provided data and constraints are consistent and sufficient to determine a unique solution for each test case. Therefore, a computational solution will be developed.\n\n### Algorithmic Design and Implementation\n\nThe core of the solution is an exhaustive search (brute-force) algorithm that explores all possible network architectures allowed by the discrete search space for each test case. Given the finite and manageably small size of the search spaces, this approach is guaranteed to find the true optimal architecture as defined by the problem.\n\nThe algorithm proceeds as follows for each test case:\n\n1.  **Initialization**: The parameters for the test case—$(H_0, W_0)$, $C_0$, $B$, $R_{\\text{target}}$, allowed number of layers $L \\in \\mathcal{L}$, and allowed channel counts $C_\\ell \\in \\mathcal{C}$—are extracted. A data structure is initialized to store the best architecture found so far, tracking its score $S^\\star$, parameter count $P^\\star$, and layer specifications. This is initialized with a score of $-1$ to ensure any valid architecture will be selected.\n\n2.  **Architecture Generation**: The algorithm iterates through each permitted number of layers $L \\in \\mathcal{L}$. For a fixed $L$, the set of all possible single-layer configurations $(k, s, C)$ is formed. The set of all possible architectures with $L$ layers is then the $L$-th Cartesian power of this single-layer set. This systematic generation ensures every single combination is considered.\n\n3.  **Architecture Evaluation**: Each generated architecture, which is a sequence of $L$ layer configurations, is evaluated sequentially.\n    - Starting with the input state ($H_0, W_0, C_0, R_0=1, J_0=1$), the algorithm processes one layer at a time.\n    - For each layer $\\ell$:\n        a. The required layer parameters $(k_\\ell, s_\\ell, C_\\ell)$ are taken from the architecture specification. Padding $p_\\ell$ is calculated as $p_\\ell = \\lfloor k_\\ell / 2 \\rfloor$.\n        b. The parameter cost of the layer, $P_\\ell$, is calculated and added to the total, $P_{\\text{total}}$. If $P_{\\text{total}} > B$, the architecture violates the budget constraint and is immediately discarded.\n        c. The output spatial dimensions $(H_\\ell, W_\\ell)$ are calculated. If either $H_\\ell < 1$ or $W_\\ell < 1$, the architecture is invalid and discarded.\n        d. The new receptive field $R_\\ell$ and effective stride $J_\\ell$ are computed using the provided recurrence relations.\n        e. The layer's contribution to the surrogate score $S$ is calculated and added to the total score, $S_{\\text{total}}$.\n        f. The state variables $(H, W, C_{\\text{in}}, R, J)$ are updated for the next layer.\n\n4.  **Selection and Tie-Breaking**: If an architecture is processed successfully through all its layers without violating any constraints, its final score $S_{\\text{total}}$ and parameter count $P_{\\text{total}}$ are compared against the best-so-far architecture.\n    - If $S_{\\text{total}}$ is greater than the current best score $S^\\star$ (within a small numerical tolerance), the new architecture becomes the best.\n    - If $S_{\\text{total}}$ is effectively equal to $S^\\star$, the tie-breaking rules are applied in order:\n        1.  If $P_{\\text{total}}$ is less than the current best $P^\\star$, the new architecture is chosen.\n        2.  If $P_{\\text{total}}$ is also equal, the layer specifications are flattened into a single sequence of numbers, and the new architecture is chosen if its sequence is lexicographically smaller than the current best.\n\n5.  **Output Formatting**: After iterating through all possible architectures for a given test case, the details of the final optimal architecture ($S^\\star$, $P_{\\text{total}}^\\star$, and layer specifications) are formatted into the precise string format required by the problem statement, rounding the score to four decimal places and removing all whitespace from the list representations. This process is repeated for all test cases, and the final results are concatenated into a single output line.\n\nThis brute-force search combined with rigorous evaluation and rule-based selection guarantees finding the unique optimal architecture for each case as defined by the problem's objective and constraints.", "answer": "[[11.4116,1992,[[3,2,1,8],[3,1,1,16],[3,1,1,32]]],[4.7675,97,[[1,1,0,8],[1,1,0,8]]],[15.3400,4960,[[3,2,1,16],[3,1,1,32],[1,2,0,64]]],[7.6186,776,[[3,2,1,8],[5,1,2,16]]]]", "id": "3103767"}]}