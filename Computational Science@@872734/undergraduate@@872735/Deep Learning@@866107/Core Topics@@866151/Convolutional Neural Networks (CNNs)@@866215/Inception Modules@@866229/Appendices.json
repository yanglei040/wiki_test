{"hands_on_practices": [{"introduction": "This practice serves as a foundational analysis of a key design choice in modern convolutional networks. We will dissect the trade-offs between using a single large convolutional kernel versus stacking smaller ones, a principle that is central to the efficiency and performance of Inception modules. By comparing a $5 \\times 5$ convolution to two stacked $3 \\times 3$ convolutions, you will gain hands-on insight into receptive fields, computational cost, and the role of nonlinearities [@problem_id:3137618].", "problem": "Consider a branch in an Inception module that is implemented in two alternative ways on an input feature map of spatial size $H \\times W$ with $C_{\\text{in}}$ input channels and $F$ output channels. Variant $1$ uses a single two-dimensional convolution with kernel size $5 \\times 5$, stride $1$, no dilation, and \"same\" zero padding, mapping $C_{\\text{in}} \\rightarrow F$. Variant $2$ uses two stacked two-dimensional convolutions, each of kernel size $3 \\times 3$, stride $1$, no dilation, and \"same\" zero padding, where the first convolution maps $C_{\\text{in}} \\rightarrow F$ and the second maps $F \\rightarrow F$. A Rectified Linear Unit (ReLU) nonlinearity is applied immediately after each convolution. Assume standard dense convolutions (no groups and no depthwise separations), and ignore bias costs and nonlinear activation costs in the operation counting.\n\nUsing only the definition of discrete convolution, the fact that composing stride-$1$ convolutions aggregates index shifts additively, and counting Multiplyâ€“Accumulate (MAC) operations per output spatial location from the summations inherent in convolution, reason from first principles to establish the following properties:\n\n- Whether the two designs have equal receptive field size under the stated conditions.\n- The algebraic condition on $C_{\\text{in}}$ and $F$ under which the per-location MAC count of Variant $2$ equals that of Variant $1$.\n- For the top-left output spatial position under \"same\" padding, how many contributing terms in the summations involve padded inputs for Variant $1$ versus Variant $2$.\n- How many nonlinearities a signal experiences along a single input-to-output path in each variant.\n\nSelect all statements that are true:\n\nA. Under stride $1$ and no dilation, two stacked $3 \\times 3$ convolutions have the same receptive field size as one $5 \\times 5$ convolution, namely $5 \\times 5$.\n\nB. The per-location MAC counts are equal between Variant $1$ and Variant $2$ exactly when $C_{\\text{in}} = \\dfrac{9}{16} F$, given that Variant $2$ uses $C_{\\text{in}} \\rightarrow F$ then $F \\rightarrow F$ convolutions and biases are ignored.\n\nC. With \"same\" zero padding at each convolution, for the top-left output position, Variant $2$ aggregates $81$ second-order kernel contributions, of which $45$ involve padded inputs, whereas Variant $1$ aggregates $25$ contributions, of which $16$ involve padded inputs; thus Variant $2$ involves a larger absolute number of padding-influenced computations at the border.\n\nD. Because two kernels are composed, the receptive field of Variant $2$ becomes $7 \\times 7$.\n\nE. If a Rectified Linear Unit (ReLU) is placed after each convolution, the number of nonlinearities applied along an input-to-output path is the same in Variant $1$ and Variant $2$.", "solution": "The problem statement has been validated and found to be scientifically sound, well-posed, objective, and self-contained. We proceed with the solution.\n\nThe problem asks for an analysis of two alternative convolutional branch designs (Variant $1$ and Variant $2$) based on four properties: receptive field size, computational cost (MACs), influence of padding, and the number of nonlinearities. We will derive each property from first principles.\n\nLet the input feature map have dimensions $H \\times W \\times C_{\\text{in}}$. Both variants produce an output feature map of size $H \\times W \\times F$.\n\n-   **Variant 1**: One $5 \\times 5$ convolution, mapping $C_{\\text{in}} \\rightarrow F$, with stride $1$.\n-   **Variant 2**: Two stacked $3 \\times 3$ convolutions, both with stride $1$. The first maps $C_{\\text{in}} \\rightarrow F$, and the second maps $F \\rightarrow F$.\n\n### 1. Receptive Field Size\n\nThe receptive field of a neuron is the region of the input space that affects its value. For a sequence of convolutions with stride $1$, the receptive field size grows additively. The general formula for the receptive field size $R_i$ after layer $i$ with kernel size $k_i$ is $R_i = R_{i-1} + k_i - 1$, where $R_0 = 1$ (a single input pixel).\n\n-   **Variant 1**: We have a single layer with a kernel of size $k_1 = 5$. The receptive field size is $R_1 = R_0 + k_1 - 1 = 1 + 5 - 1 = 5$. The receptive field is $5 \\times 5$.\n\n-   **Variant 2**: We have two stacked layers, both with kernel size $k=3$.\n    -   After the first convolution ($k_1 = 3$): The receptive field size is $R_1 = R_0 + k_1 - 1 = 1 + 3 - 1 = 3$. An intermediate neuron sees a $3 \\times 3$ patch of the input.\n    -   After the second convolution ($k_2 = 3$): The receptive field size of the final output neuron is $R_2 = R_1 + k_2 - 1 = 3 + 3 - 1 = 5$. An output neuron sees a $3 \\times 3$ patch of the intermediate feature map, where the receptive field of each of those intermediate neurons was already $3 \\times 3$. The total receptive field with respect to the original input is $5 \\times 5$.\n\nTherefore, both variants have the same receptive field size of $5 \\times 5$.\n\n### 2. Per-Location Multiply-Accumulate (MAC) Count\n\nThe number of MAC operations to compute a single spatial location of the output feature map is the product of the number of output channels, input channels, and the kernel's spatial size ($K \\times K$). Bias costs are ignored.\n\n-   **Variant 1**:\n    -   Kernel size: $5 \\times 5 = 25$.\n    -   Input channels: $C_{\\text{in}}$.\n    -   Output channels: $F$.\n    -   MACs per location (V1) = $C_{\\text{in}} \\times F \\times 5 \\times 5 = 25 C_{\\text{in}} F$.\n\n-   **Variant 2**: The total cost is the sum of the costs of the two convolutional layers.\n    -   **First convolution**:\n        -   Kernel size: $3 \\times 3 = 9$.\n        -   Input channels: $C_{\\text{in}}$.\n        -   Output channels: $F$.\n        -   MACs (Conv1) = $C_{\\text{in}} \\times F \\times 3 \\times 3 = 9 C_{\\text{in}} F$.\n    -   **Second convolution**:\n        -   Kernel size: $3 \\times 3 = 9$.\n        -   Input channels: $F$ (output from the first layer).\n        -   Output channels: $F$.\n        -   MACs (Conv2) = $F \\times F \\times 3 \\times 3 = 9 F^2$.\n    -   **Total MACs per location (V2)** = MACs(Conv1) + MACs(Conv2) = $9 C_{\\text{in}} F + 9 F^2$.\n\nTo find the condition for equal MAC counts, we set MACs(V1) = MACs(V2):\n$$25 C_{\\text{in}} F = 9 C_{\\text{in}} F + 9 F^2$$\nAssuming $F \\neq 0$, we can divide by $F$:\n$$25 C_{\\text{in}} = 9 C_{\\text{in}} + 9 F$$\n$$16 C_{\\text{in}} = 9 F$$\n$$C_{\\text{in}} = \\frac{9}{16} F$$\n\n### 3. Padded Input Contributions for the Top-Left Output\n\nWe analyze the computation for the output at spatial position $(0, 0)$. \"Same\" padding adds rows/columns of zeros to ensure the output spatial dimensions match the input. For a kernel of size $K \\times K$ with stride $1$, the necessary padding is $P = (K-1)/2$ on each side.\n\n-   **Variant 1**: Kernel size $K = 5$, so padding is $P = (5-1)/2 = 2$. The $5 \\times 5$ kernel, when computing the output at $(0,0)$, covers an area in the padded input that corresponds to original input indices from $-2$ to $2$.\n    -   The total number of spatial terms in the sum is $5 \\times 5 = 25$. These are the \"contributions\".\n    -   The input values with non-negative indices are from the original feature map. For the top-left position, this corresponds to indices $(i,j)$ where $i,j \\in \\{0, 1, 2\\}$. This is a $3 \\times 3$ grid, so there are $9$ non-padded contributions.\n    -   The number of contributions from padded zeros is $25 - 9 = 16$.\n\n-   **Variant 2**: This involves two $3 \\times 3$ convolutions. Let the kernels be $W_1$ (first layer) and $W_2$ (second layer). An output pixel $Y$ is a function of the input $X$ via the intermediate map $I$. Schematically, $Y \\sim W_2 \\star I = W_2 \\star (W_1 \\star X)$. Ignoring the ReLU and channel dimensions for structural analysis, this is equivalent to $Y \\sim (W_2 \\star W_1) \\star X$, where $W_{\\text{eff}} = W_2 \\star W_1$ is an effective kernel of size $(3+3-1) \\times (3+3-1) = 5 \\times 5$.\n    -   The computation of an output pixel value can be expanded as a sum of terms, each being a product of one weight from $W_1$, one from $W_2$, and one input pixel value $X$.\n    $Y_{i,j} = \\sum_{p,q} W_2(p,q) I_{i-p, j-q} = \\sum_{p,q} W_2(p,q) \\left( \\sum_{r,s} W_1(r,s) X_{i-p-r, j-q-s} \\right)$.\n    -   The total number of such \"second-order kernel contributions\" for a single output pixel is the product of the number of weights in each kernel: $3 \\times 3 \\times 3 \\times 3 = 81$.\n    -   We need to count how many of these $81$ terms use a padded input for the output at $(0,0)$. A term involves a padded input if the input index $(i,j)$ has $i<0$ or $j<0$. The input index is given by $(-p-r, -q-s)$ where $p,q,r,s \\in \\{-1, 0, 1\\}$ (if kernel indices are relative to center). It is easier to count the non-padded terms, where $-p-r \\ge 0$ and $-q-s \\ge 0$, which is equivalent to $p+r \\le 0$ and $q+s \\le 0$.\n    -   Let's count pairs $(k_1, k_2)$ from $\\{-1,0,1\\}$ where $k_1+k_2 \\le 0$:\n        -   If $k_1 = -1$, $k_2$ can be $-1, 0, 1$ ($3$ choices).\n        -   If $k_1 = 0$, $k_2$ can be $-1, 0$ ($2$ choices).\n        -   If $k_1 = 1$, $k_2$ can be $-1$ ($1$ choice).\n        -   Total choices = $3+2+1=6$.\n    -   The number of non-padded terms is where both indices are non-negative, so we have $6$ choices for the row index pair $(p,r)$ and $6$ choices for the column index pair $(q,s)$. Total non-padded terms = $6 \\times 6 = 36$.\n    -   The number of terms involving padded inputs is the total minus the non-padded: $81 - 36 = 45$.\n    -   Comparing the two variants, Variant $1$ has $16$ padding-influenced computations at the border, while Variant $2$ has $45$. Thus, $45 > 16$, and Variant $2$ involves a larger number of such computations.\n\n### 4. Number of Nonlinearities on an Input-to-Output Path\n\nA \"single input-to-output path\" refers to the sequence of operations a signal undergoes from an input neuron to an output neuron. A Rectified Linear Unit (ReLU) is applied after each convolution.\n\n-   **Variant 1**: The path is Input $\\rightarrow$ Convolution $\\rightarrow$ ReLU $\\rightarrow$ Output. The signal passes through one nonlinearity.\n\n-   **Variant 2**: The path is Input $\\rightarrow$ Conv1 $\\rightarrow$ ReLU1 $\\rightarrow$ Conv2 $\\rightarrow$ ReLU2 $\\rightarrow$ Output. The signal passes through the first ReLU, is then processed by the second convolution, and finally passes through the second ReLU. The total number of nonlinearities experienced is two.\n\nTherefore, the number of nonlinearities is not the same in the two variants.\n\n### Evaluation of Options\n\n**A. Under stride $1$ and no dilation, two stacked $3 \\times 3$ convolutions have the same receptive field size as one $5 \\times 5$ convolution, namely $5 \\times 5$.**\nOur derivation in section 1 shows that the receptive field for two stacked $3 \\times 3$ convolutions is $5 \\times 5$, which is identical to that of a single $5 \\times 5$ convolution.\n**Verdict: Correct.**\n\n**B. The per-location MAC counts are equal between Variant $1$ and Variant $2$ exactly when $C_{\\text{in}} = \\dfrac{9}{16} F$, given that Variant $2$ uses $C_{\\text{in}} \\rightarrow F$ then $F \\rightarrow F$ convolutions and biases are ignored.**\nOur derivation in section 2 confirms this exact algebraic condition. The calculation $25 C_{\\text{in}} F = 9 C_{\\text{in}} F + 9 F^2$ directly leads to $C_{\\text{in}} = \\frac{9}{16}F$.\n**Verdict: Correct.**\n\n**C. With \"same\" zero padding at each convolution, for the top-left output position, Variant $2$ aggregates $81$ second-order kernel contributions, of which $45$ involve padded inputs, whereas Variant $1$ aggregates $25$ contributions, of which $16$ involve padded inputs; thus Variant $2$ involves a larger absolute number of padding-influenced computations at the border.**\nOur analysis in section 3 confirms all numerical claims. Variant 1: $25$ total contributions, $16$ padded. Variant 2: $81$ second-order contributions, $45$ padded. The conclusion that Variant $2$ involves a larger number of padding-influenced computations ($45 > 16$) is also correct.\n**Verdict: Correct.**\n\n**D. Because two kernels are composed, the receptive field of Variant $2$ becomes $7 \\times 7$.**\nThis is incorrect. As shown in section 1, the receptive field size is $5 \\times 5$. A $7 \\times 7$ receptive field would require, for example, three stacked $3 \\times 3$ convolutions.\n**Verdict: Incorrect.**\n\n**E. If a Rectified Linear Unit (ReLU) is placed after each convolution, the number of nonlinearities applied along an input-to-output path is the same in Variant $1$ and Variant $2$.**\nThis is incorrect. As shown in section 4, Variant 1 has one nonlinearity, while Variant 2 has two.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{ABC}$$", "id": "3137618"}, {"introduction": "While powerful, multi-branch architectures introduce subtle challenges, especially at image boundaries where standard padding can create artifacts. This exercise moves from theory to a practical coding challenge, where you will investigate how different kernel sizes interact with zero-padding and cause discrepancies between branches near the edges. You will implement a more principled \"padding-aware\" normalization to mitigate these effects, providing a deeper understanding of the nuts and bolts of convolutional layers [@problem_id:3137620].", "problem": "You are asked to study cross-branch boundary effects in multi-branch Inception-style modules and to design a padding-aware normalization that reduces discrepancies near image edges. Work in a purely two-dimensional, single-channel, discrete setting, with no stochastic components. The computational goal is to implement functions that quantify the cross-branch variance at each pixel location for different convolution branches and to compare the naive zero-padded response to a padding-aware normalized response.\n\nYou will model an Inception-style block as a set of branches that each compute a uniform local average over a square receptive field of size $k \\times k$, where $k \\in \\{\\,1,3,5,7\\,\\}$. The input is a single-channel image represented as a real-valued matrix of height $H$ and width $W$. Each branch uses zero-padding to produce a \"same\" output of shape $H \\times W$. The local average of a branch at location $(i,j)$ with kernel size $k$ is defined as the arithmetic mean of the values in its $k \\times k$ receptive field centered at $(i,j)$. With naive zero-padding, out-of-bounds positions contribute the value $0$ to the arithmetic mean. This naive averaging introduces a location-dependent bias near the image boundary because the number of valid in-bounds contributions is smaller than $k^2$.\n\nYour task is to derive and implement a padding-aware normalization that removes this bias using only fundamental definitions. Start from the definition of discrete two-dimensional convolution and the arithmetic mean. Treat the boundary as an absence of data rather than the presence of zeros: for each pixel location, conceptually average only over those positions within the receptive field that lie inside the image domain. Use this principle to define a normalized branch response at each location and for each $k$. For each method (naive and padding-aware), compute the variance across branches at every pixel location, where the variance is defined as the population variance over the set of branch responses at that location. Denote by $B$ the number of branches and by $y_b(i,j)$ the response of branch $b$ at $(i,j)$; then the cross-branch variance at $(i,j)$ is the arithmetic mean of squared deviations from the cross-branch mean.\n\nDefine the \"edge band\" as all pixel locations within a Chebyshev distance less than or equal to $p_{\\max}$ from the boundary, where $p_{\\max} = \\lfloor \\max(K)/2 \\rfloor$ and $K = \\{\\,1,3,5,7\\,\\}$. Formally, this edge band is the set of $(i,j)$ such that $i \\lt p_{\\max}$ or $i \\ge H - p_{\\max}$ or $j \\lt p_{\\max}$ or $j \\ge W - p_{\\max}$. The complement inside the image is the interior.\n\nProgram specification:\n- Implement the naive zero-padded local average for each $k \\in \\{\\,1,3,5,7\\,\\}$.\n- Implement the padding-aware normalized local average for each $k$ by averaging exclusively over in-bounds pixels of each receptive field at every location, as derived from first principles. Do not infer or assume any specialized \"shortcut\" formulas beyond basic counting and the definition of the arithmetic mean.\n- For each method, compute the per-pixel cross-branch variance.\n- For each test image below, compute the mean of the cross-branch variance over the edge band only (exclude the interior), for both methods.\n- For each test image, return three real numbers: the mean edge variance for the naive method, the mean edge variance for the padding-aware method, and the ratio of the latter divided by the former. If the denominator is $0$, define the ratio to be $0$.\n- Round each reported real number to exactly six digits after the decimal point.\n\nUse the following four test images, each deterministic and defined purely in mathematical terms:\n- Test case $1$ (constant field): $H = 7, W = 7$, and $I(i,j) = 3$ for all $0 \\le i \\lt H, 0 \\le j \\lt W$.\n- Test case $2$ (additive gradient): $H = 8, W = 5$, and $I(i,j) = i + j$ for all $0 \\le i \\lt H, 0 \\le j \\lt W$.\n- Test case $3$ (impulse): $H = 3, W = 3$, and $I(i,j) = 1$ if $(i,j) = (1,1)$ and $I(i,j) = 0$ otherwise.\n- Test case $4$ (checkerboard): $H = 6, W = 6$, and $I(i,j) = 1$ if $(i + j)$ is even and $I(i,j) = 0$ if $(i + j)$ is odd.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The results must be in the order of the test cases, with three rounded floats per test case: $[\\text{naive}_1,\\text{norm}_1,\\text{ratio}_1,\\text{naive}_2,\\text{norm}_2,\\text{ratio}_2,\\text{naive}_3,\\text{norm}_3,\\text{ratio}_3,\\text{naive}_4,\\text{norm}_4,\\text{ratio}_4]$.\n- All numbers must be printed with exactly six digits after the decimal point.", "solution": "The problem statement is valid. It is scientifically grounded in the principles of discrete convolution and statistical variance, well-posed with specific inputs and deterministic objectives, and objectively defined.\n\nThe task is to analyze and mitigate boundary artifacts in a simplified multi-branch convolutional module, akin to an Inception block in deep learning. The module comprises four parallel branches, each performing a local averaging operation with a different square kernel size $k \\in K = \\{1, 3, 5, 7\\}$. We will derive and implement two methods for this averaging: a naive zero-padded approach and a proposed padding-aware normalized approach. Subsequently, we will quantify the discrepancy between branches by computing the cross-branch variance at each pixel and analyzing its mean value within a defined \"edge band.\"\n\n### 1. Mathematical Formulation of Local Averaging Methods\n\nLet the input be a single-channel image represented by a real-valued matrix $I$ of size $H \\times W$. The output of a branch with kernel size $k$ is a matrix $Y_k$ of the same dimensions. Let $p = \\lfloor k/2 \\rfloor$ be the padding required for a symmetric $k \\times k$ kernel to produce a \"same\" output.\n\n#### a. Naive Zero-Padded Local Average\n\nIn standard zero-padded convolution, any part of the receptive field that falls outside the image domain is treated as having a value of $0$. The local average is computed by summing the values in the $k \\times k$ receptive field and dividing by the total area of the kernel, $k^2$.\n\nLet $I_{\\text{padded}}(u,v)$ be a function that returns $I(u,v)$ if the coordinates $(u,v)$ are within the image bounds ($0 \\le u < H$, $0 \\le v < W$) and $0$ otherwise. The naive response $Y_k^{\\text{naive}}(i,j)$ at location $(i,j)$ is:\n$$ Y_k^{\\text{naive}}(i,j) = \\frac{1}{k^2} \\sum_{u=i-p}^{i+p} \\sum_{v=j-p}^{j+p} I_{\\text{padded}}(u,v) $$\nThis method introduces a systematic bias near the image boundaries because the denominator $k^2$ remains constant while the number of actual image pixels contributing to the sum decreases. This leads to an artificial darkening or lightening effect at the edges, depending on the image content and fill value.\n\n#### b. Padding-Aware Normalized Local Average\n\nA more principled approach is to compute the arithmetic mean using only the valid pixel data available within the receptive field at each location. The zeros from padding represent an absence of data and should not be included in the averaging calculation.\n\nLet $\\mathcal{D} = [0, H-1] \\times [0, W-1]$ be the image domain. For a kernel of size $k$ centered at $(i,j)$, the receptive field is $\\mathcal{R}_k(i,j) = [i-p, i+p] \\times [j-p, j+p]$. The set of valid pixels is the intersection $\\mathcal{V}_k(i,j) = \\mathcal{R}_k(i,j) \\cap \\mathcal{D}$. The padding-aware normalized response $Y_k^{\\text{norm}}(i,j)$ is defined by the true arithmetic mean over this valid set:\n$$ Y_k^{\\text{norm}}(i,j) = \\frac{\\sum_{(u,v) \\in \\mathcal{V}_k(i,j)} I(u,v)}{\\left| \\mathcal{V}_k(i,j) \\right|} $$\nHere, the sum is taken only over pixels within the image boundaries, and the denominator is the exact count of such pixels. This definition ensures that the local average is not biased by out-of-bounds regions, correctly reflecting the mean of the available data. For example, on a constant image $I(i,j)=C$, this method yields $Y_k^{\\text{norm}}(i,j)=C$ everywhere, unlike the naive method.\n\n### 2. Implementation via Integral Images\n\nTo implement these calculations efficiently without specialized libraries, we use the integral image, or summed-area table (SAT). A SAT allows the sum over any rectangular region to be computed in constant time. We construct a SAT, denoted $\\text{sat}(I)$, for an image $I$.\n\nFor the **naive method**, we first create a zero-padded image $I_{\\text{pad}}$ with a border of width $p_{\\max} = \\lfloor \\max(K)/2 \\rfloor = 3$. We then compute its SAT. The sum over any $k \\times k$ window can be queried from this SAT to calculate $Y_k^{\\text{naive}}$.\n\nFor the **padding-aware method**, we compute two SATs from the original image $I$: one for the image itself, $\\text{sat}(I)$, and one for a matrix of ones of the same size, $\\text{sat}(\\mathbf{1}_{H \\times W})$. For each pixel $(i,j)$ and kernel $k$, we determine the valid rectangular sub-window $\\mathcal{V}_k(i,j)$ and use $\\text{sat}(I)$ to find the sum of its elements and $\\text{sat}(\\mathbf{1}_{H \\times W})$ to find its area (pixel count).\n\n### 3. Cross-Branch Variance and Edge Analysis\n\nAfter computing the responses $\\{Y_k^{\\text{naive}}\\}$ and $\\{Y_k^{\\text{norm}}\\}$ for all $k \\in K$, we quantify the disagreement between branches. At each pixel $(i,j)$, we have a set of four responses, $\\mathcal{Y}(i,j) = \\{Y_k(i,j)\\}_{k \\in K}$. The cross-branch variance is the population variance of this set:\n$$ V(i,j) = \\frac{1}{4} \\sum_{k \\in K} \\left( Y_k(i,j) - \\mu_{\\mathcal{Y}}(i,j) \\right)^2, \\quad \\text{where} \\quad \\mu_{\\mathcal{Y}}(i,j) = \\frac{1}{4} \\sum_{k \\in K} Y_k(i,j) $$\nThis calculation yields two variance maps, $V^{\\text{naive}}$ and $V^{\\text{norm}}$.\n\nFinally, we compute the mean of these variance values over the specified \"edge band,\" which includes all pixels $(i,j)$ such that $i < p_{\\max}$ or $i \\ge H - p_{\\max}$ or $j < p_{\\max}$ or $j \\ge W - p_{\\max}$, with $p_{\\max} = 3$. This allows us to aggregate the boundary effect into a single scalar metric for each method and compare their performance via their ratio.", "answer": "```python\nimport numpy as np\n\ndef _compute_sat(matrix):\n    \"\"\"Computes the summed-area table (integral image) for a 2D matrix.\"\"\"\n    H, W = matrix.shape\n    sat = np.zeros((H + 1, W + 1), dtype=np.float64)\n    sat[1:, 1:] = np.cumsum(np.cumsum(matrix, axis=0), axis=1)\n    return sat\n\ndef _query_sat(sat, r1, c1, r2, c2):\n    \"\"\"Queries the sum of a rectangle (r1, c1) to (r2, c2) inclusive.\"\"\"\n    # The SAT is padded, so coordinates correspond directly.\n    # sat[r, c] stores sum of matrix[0:r, 0:c]\n    if r1 > r2 or c1 > c2:\n        return 0.0\n    # Correct indexing for the padded SAT\n    # sum = D - B - C + A\n    # A = sat[r1, c1], B = sat[r1, c2+1], C = sat[r2+1, c1], D = sat[r2+1, c2+1]\n    return sat[r2 + 1, c2 + 1] - sat[r1, c2 + 1] - sat[r2 + 1, c1] + sat[r1, c1]\n\ndef _process_image(I):\n    \"\"\"\n    Computes naive and normalized edge variances for a given image.\n    \"\"\"\n    H, W = I.shape\n    kernels = [1, 3, 5, 7]\n    p_max = max(kernels) // 2\n\n    # --- 1. Naive Zero-Padded Method ---\n    I_padded = np.pad(I, pad_width=p_max, mode='constant', constant_values=0)\n    sat_padded = _compute_sat(I_padded)\n    \n    naive_responses = []\n    for k in kernels:\n        p_k = k // 2\n        Y_k_naive = np.zeros((H, W), dtype=np.float64)\n        for i in range(H):\n            for j in range(W):\n                # Window coordinates in the padded image\n                r1_pad, c1_pad = i + p_max - p_k, j + p_max - p_k\n                r2_pad, c2_pad = r1_pad + k - 1, c1_pad + k - 1\n                \n                window_sum = _query_sat(sat_padded, r1_pad, c1_pad, r2_pad, c2_pad)\n                Y_k_naive[i, j] = window_sum / (k * k)\n        naive_responses.append(Y_k_naive)\n    \n    # --- 2. Padding-Aware Normalized Method ---\n    sat_I = _compute_sat(I)\n    sat_ones = _compute_sat(np.ones_like(I, dtype=np.float64))\n\n    norm_responses = []\n    for k in kernels:\n        p_k = k // 2\n        Y_k_norm = np.zeros((H, W), dtype=np.float64)\n        for i in range(H):\n            for j in range(W):\n                # Window coordinates in the original image, need to be clipped\n                r1, c1 = i - p_k, j - p_k\n                r2, c2 = i + p_k, j + p_k\n                \n                # Clipped coordinates for valid region\n                r1_clip, c1_clip = max(0, r1), max(0, c1)\n                r2_clip, c2_clip = min(H - 1, r2), min(W - 1, c2)\n                \n                window_sum = _query_sat(sat_I, r1_clip, c1_clip, r2_clip, c2_clip)\n                pixel_count = _query_sat(sat_ones, r1_clip, c1_clip, r2_clip, c2_clip)\n                \n                if pixel_count > 0:\n                    Y_k_norm[i, j] = window_sum / pixel_count\n        norm_responses.append(Y_k_norm)\n\n    # --- 3. Variance and Edge Analysis ---\n    naive_stack = np.stack(naive_responses, axis=0)\n    norm_stack = np.stack(norm_responses, axis=0)\n\n    V_naive = np.var(naive_stack, axis=0)\n    V_norm = np.var(norm_stack, axis=0)\n\n    rows, cols = np.ogrid[:H, :W]\n    edge_mask = (rows < p_max) | (rows >= H - p_max) | \\\n                (cols < p_max) | (cols >= W - p_max)\n    \n    if not np.any(edge_mask): # Should not happen with given test cases\n        mean_V_naive_edge = 0.0\n        mean_V_norm_edge = 0.0\n    else:\n        mean_V_naive_edge = np.mean(V_naive[edge_mask])\n        mean_V_norm_edge = np.mean(V_norm[edge_mask])\n\n    ratio = 0.0\n    if mean_V_naive_edge != 0:\n        ratio = mean_V_norm_edge / mean_V_naive_edge\n\n    return mean_V_naive_edge, mean_V_norm_edge, ratio\n\ndef solve():\n    test_cases_defs = [\n        {'H': 7, 'W': 7, 'func': lambda i, j: 3.0},\n        {'H': 8, 'W': 5, 'func': lambda i, j: i + j},\n        {'H': 3, 'W': 3, 'func': lambda i, j: 1.0 * ((i == 1) & (j == 1))},\n        {'H': 6, 'W': 6, 'func': lambda i, j: 1.0 * ((i + j) % 2 == 0)}\n    ]\n\n    results = []\n    for case_def in test_cases_defs:\n        H, W = case_def['H'], case_def['W']\n        image_func = case_def['func']\n        image = np.fromfunction(np.vectorize(image_func), (H, W), dtype=int).astype(np.float64)\n        \n        naive_var, norm_var, ratio = _process_image(image)\n        \n        results.append(naive_var)\n        results.append(norm_var)\n        results.append(ratio)\n        \n    # Format output as specified: comma-separated list in brackets, 6 decimal places.\n    # The f-string formatting handles rounding appropriately for display.\n    formatted_results = [f\"{val:.6f}\" for val in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3137620"}, {"introduction": "Designing an effective Inception module involves not just choosing which branches to include, but also how to allocate computational resources among them. This advanced practice elevates your design thinking by framing resource allocation as a formal optimization problem. You will use the method of Lagrange multipliers to determine the optimal number of channels for each branch to maximize a utility function under a strict computational budget (FLOPs), mirroring the real-world constraints faced by network architects [@problem_id:3137632].", "problem": "Consider a single Inception module with three parallel convolutional branches operating on the same input feature map. The input feature map has $H = 10$ and $W = 10$ spatial dimensions and $c_{\\text{in}} = 10$ input channels. The three branches use kernels of spatial size $k_{1} = 1$, $k_{2} = 3$, and $k_{3} = 5$ respectively, and produce $c_{1}$, $c_{2}$, and $c_{3}$ output channels. Assume that the output spatial dimensions match the input spatial dimensions (same padding and unit stride). Treat the channel counts $c_{i}$ as continuous nonnegative real variables to enable calculus-based optimization.\n\nAs a fundamental base, use the standard convolutional operation count: for a two-dimensional convolution with kernel size $k \\times k$, input channels $c_{\\text{in}}$, and output channels $c_{\\text{out}}$, applied over $H \\times W$ spatial locations, the total number of Floating Point Operations (FLOPs) is proportional to $H W \\, c_{\\text{in}} \\, c_{\\text{out}} \\, k^{2}$. Let the total FLOPs across the three branches be denoted by $B$, and suppose there is a hard budget $B = 150000$ FLOPs that must be exactly met.\n\nDefine the effective receptive field coverage utility to capture diminishing returns across branches and scale preference as the concave function\n$$U(c_{1}, c_{2}, c_{3}) = w_{1} \\ln(c_{1} k_{1}) + w_{2} \\ln(c_{2} k_{2}) + w_{3} \\ln(c_{3} k_{3}),$$\nwith weights $w_{1} = 1$, $w_{2} = 2$, and $w_{3} = 3$. The aim is to maximize $U$ subject to the FLOPs budget.\n\nFormulate and solve the constrained optimization problem of choosing $(c_{1}, c_{2}, c_{3})$ to maximize $U$ subject to the equality constraint\n$$H W \\, c_{\\text{in}} \\left(c_{1} k_{1}^{2} + c_{2} k_{2}^{2} + c_{3} k_{3}^{2}\\right) = B.$$\nDerive the optimal allocation using first principles and the method of Lagrange multipliers. Express your final answer as a single row vector of the optimal channel allocations $\\left(c_{1}^{\\star}, c_{2}^{\\star}, c_{3}^{\\star}\\right)$ in exact form (no rounding).", "solution": "The problem is first validated against the specified criteria.\n\n**Step 1: Extract Givens**\n- Input feature map dimensions: $H = 10$, $W = 10$.\n- Input channels: $c_{\\text{in}} = 10$.\n- Number of parallel branches: $3$.\n- Kernel sizes for the three branches: $k_{1} = 1$, $k_{2} = 3$, $k_{3} = 5$.\n- Output channels for the three branches: $c_{1}, c_{2}, c_{3}$ (continuous non-negative real variables).\n- Total FLOPs budget: $B = 150000$.\n- FLOPs constraint equation: $H W \\, c_{\\text{in}} \\left(c_{1} k_{1}^{2} + c_{2} k_{2}^{2} + c_{3} k_{3}^{2}\\right) = B$.\n- Utility function to maximize: $U(c_{1}, c_{2}, c_{3}) = w_{1} \\ln(c_{1} k_{1}) + w_{2} \\ln(c_{2} k_{2}) + w_{3} \\ln(c_{3} k_{3})$.\n- Weights for the utility function: $w_{1} = 1$, $w_{2} = 2$, $w_{3} = 3$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is well-grounded in the field of deep learning. It models a common design choice in neural architecture, specifically the allocation of computational resources (FLOPs) among parallel branches of an Inception-style module. The FLOPs approximation is standard, and using a concave utility function to model diminishing returns is a valid and common technique in optimization.\n- **Well-Posed:** The task is to maximize a strictly concave function ($U$ is a sum of logarithmic functions) subject to a linear equality constraint. This is a classic convex optimization problem, which guarantees the existence of a unique, stable, and meaningful solution.\n- **Objective:** The problem is stated using precise mathematical language, with all terms and variables clearly defined.\n- **Consistency and Completeness:** The problem provides all necessary information and conditions for a unique solution. There are no contradictions.\n\n**Step 3: Verdict and Action**\nThe problem is valid as it is scientifically grounded, well-posed, objective, complete, and consistent. The solution process may proceed.\n\nThe problem is a constrained optimization problem. We aim to maximize the utility function $U(c_{1}, c_{2}, c_{3})$ subject to a budget constraint on the total FLOPs. The method of Lagrange multipliers is appropriate for this task.\n\nThe objective function is\n$$U(c_{1}, c_{2}, c_{3}) = w_{1} \\ln(c_{1} k_{1}) + w_{2} \\ln(c_{2} k_{2}) + w_{3} \\ln(c_{3} k_{3})$$\nThe constraint is given by the equation\n$$H W \\, c_{\\text{in}} \\left(c_{1} k_{1}^{2} + c_{2} k_{2}^{2} + c_{3} k_{3}^{2}\\right) = B$$\nLet's define the constraint function $g(c_{1}, c_{2}, c_{3})$ as\n$$g(c_{1}, c_{2}, c_{3}) = H W \\, c_{\\text{in}} \\left(c_{1} k_{1}^{2} + c_{2} k_{2}^{2} + c_{3} k_{3}^{2}\\right) - B = 0$$\nThe Lagrangian function $\\mathcal{L}$ is formed by combining the objective function and the constraint function with a Lagrange multiplier $\\lambda$:\n$$\\mathcal{L}(c_{1}, c_{2}, c_{3}, \\lambda) = U(c_{1}, c_{2}, c_{3}) - \\lambda g(c_{1}, c_{2}, c_{3})$$\n$$\\mathcal{L}(c_{1}, c_{2}, c_{3}, \\lambda) = \\sum_{i=1}^{3} w_{i} \\ln(c_{i} k_{i}) - \\lambda \\left[ H W \\, c_{\\text{in}} \\left(\\sum_{i=1}^{3} c_{i} k_{i}^{2}\\right) - B \\right]$$\nTo find the optimal values $(c_{1}^{\\star}, c_{2}^{\\star}, c_{3}^{\\star})$, we must find the critical points of the Lagrangian by taking the partial derivatives with respect to each variable ($c_{1}, c_{2}, c_{3}, \\lambda$) and setting them to zero.\n\nThe partial derivatives with respect to $c_{i}$ for $i=1, 2, 3$ are:\n$$\\frac{\\partial \\mathcal{L}}{\\partial c_{i}} = \\frac{\\partial}{\\partial c_{i}} \\left( w_{i} \\ln(c_{i} k_{i}) \\right) - \\lambda \\frac{\\partial}{\\partial c_{i}} \\left( H W \\, c_{\\text{in}} c_{i} k_{i}^{2} \\right)$$\nUsing the chain rule, $\\frac{d}{dx} \\ln(ax) = \\frac{1}{ax} \\cdot a = \\frac{1}{x}$. So, $\\frac{\\partial}{\\partial c_i} (w_i \\ln(c_i k_i)) = w_i \\frac{1}{c_i k_i} \\cdot k_i = \\frac{w_i}{c_i}$.\n$$\\frac{\\partial \\mathcal{L}}{\\partial c_{i}} = \\frac{w_{i}}{c_{i}} - \\lambda H W c_{\\text{in}} k_{i}^{2} = 0$$\nThis gives us a system of three equations:\n1. $\\frac{w_{1}}{c_{1}} - \\lambda H W c_{\\text{in}} k_{1}^{2} = 0$\n2. $\\frac{w_{2}}{c_{2}} - \\lambda H W c_{\\text{in}} k_{2}^{2} = 0$\n3. $\\frac{w_{3}}{c_{3}} - \\lambda H W c_{\\text{in}} k_{3}^{2} = 0$\n\nFrom these equations, we can express each $c_{i}$ in terms of $\\lambda$:\n$$c_{i} = \\frac{w_{i}}{\\lambda H W c_{\\text{in}} k_{i}^{2}}$$\nThe fourth equation comes from the partial derivative with respect to $\\lambda$, which simply recovers the constraint:\n$$\\frac{\\partial \\mathcal{L}}{\\partial \\lambda} = -\\left[ H W \\, c_{\\text{in}} \\left(\\sum_{i=1}^{3} c_{i} k_{i}^{2}\\right) - B \\right] = 0$$\n$$H W \\, c_{\\text{in}} \\left(c_{1} k_{1}^{2} + c_{2} k_{2}^{2} + c_{3} k_{3}^{2}\\right) = B$$\nNow, substitute the expressions for $c_{i}$ into the constraint equation to solve for $\\lambda$:\n$$H W \\, c_{\\text{in}} \\sum_{i=1}^{3} \\left( \\frac{w_{i}}{\\lambda H W c_{\\text{in}} k_{i}^{2}} \\right) k_{i}^{2} = B$$\nThe terms $k_{i}^{2}$ cancel out:\n$$H W \\, c_{\\text{in}} \\sum_{i=1}^{3} \\left( \\frac{w_{i}}{\\lambda H W c_{\\text{in}}} \\right) = B$$\nFactor out the common term $1/(\\lambda H W c_{\\text{in}})$:\n$$H W \\, c_{\\text{in}} \\frac{1}{\\lambda H W c_{\\text{in}}} \\sum_{i=1}^{3} w_{i} = B$$\nThe term $H W c_{\\text{in}}$ cancels, leaving:\n$$\\frac{1}{\\lambda} \\sum_{i=1}^{3} w_{i} = B$$\nSolving for $\\lambda$:\n$$\\lambda = \\frac{\\sum_{i=1}^{3} w_{i}}{B}$$\nNow we substitute this value of $\\lambda$ back into the expressions for $c_{i}$:\n$$c_{i}^{\\star} = \\frac{w_{i}}{\\left(\\frac{\\sum_{j=1}^{3} w_{j}}{B}\\right) H W c_{\\text{in}} k_{i}^{2}} = \\frac{w_{i} B}{\\left(\\sum_{j=1}^{3} w_{j}\\right) H W c_{\\text{in}} k_{i}^{2}}$$\nThis is the general solution for the optimal channel allocation $c_{i}^{\\star}$.\n\nWe can now substitute the given numerical values:\n- $H=10, W=10 \\implies HW = 100$\n- $c_{\\text{in}} = 10$\n- $B = 150000$\n- $k_{1}=1, k_{2}=3, k_{3}=5 \\implies k_{1}^{2}=1, k_{2}^{2}=9, k_{3}^{2}=25$\n- $w_{1}=1, w_{2}=2, w_{3}=3 \\implies \\sum_{j=1}^{3} w_{j} = 1+2+3 = 6$\n\nLet's calculate the common factor in the expression for $c_{i}^{\\star}$:\n$$\\frac{B}{\\left(\\sum_{j=1}^{3} w_{j}\\right) H W c_{\\text{in}}} = \\frac{150000}{6 \\cdot 10 \\cdot 10 \\cdot 10} = \\frac{150000}{6000} = \\frac{150}{6} = 25$$\nNow we can compute each optimal channel count:\n$$c_{1}^{\\star} = \\frac{w_{1}}{k_{1}^{2}} \\cdot 25 = \\frac{1}{1} \\cdot 25 = 25$$\n$$c_{2}^{\\star} = \\frac{w_{2}}{k_{2}^{2}} \\cdot 25 = \\frac{2}{9} \\cdot 25 = \\frac{50}{9}$$\n$$c_{3}^{\\star} = \\frac{w_{3}}{k_{3}^{2}} \\cdot 25 = \\frac{3}{25} \\cdot 25 = 3$$\nThe optimal allocation is therefore $(c_{1}^{\\star}, c_{2}^{\\star}, c_{3}^{\\star}) = (25, 50/9, 3)$.\n\nTo verify the result, we can check if the FLOPs budget is met:\n$$H W c_{\\text{in}} (c_{1}^{\\star} k_{1}^{2} + c_{2}^{\\star} k_{2}^{2} + c_{3}^{\\star} k_{3}^{2}) = 10 \\cdot 10 \\cdot 10 \\left( 25 \\cdot 1^{2} + \\frac{50}{9} \\cdot 3^{2} + 3 \\cdot 5^{2} \\right)$$\n$$= 1000 \\left( 25 + \\frac{50}{9} \\cdot 9 + 3 \\cdot 25 \\right)$$\n$$= 1000 (25 + 50 + 75) = 1000(150) = 150000$$\nThis matches the budget $B$, confirming the correctness of the solution.\n\nThe final answer is the row vector of optimal channel allocations.", "answer": "$$ \\boxed{ \\begin{pmatrix} 25 & \\frac{50}{9} & 3 \\end{pmatrix} } $$", "id": "3137632"}]}