{"hands_on_practices": [{"introduction": "This practice explores the two fundamental bottlenecks that limit performance on a superscalar processor: the inherent data dependencies in the code and the finite hardware resources. By analyzing a simple dependency chain alongside independent instructions, you will derive the core relationship between critical path length, issue width, and achievable Instructions Per Cycle ($IPC$), providing a foundational model for all instruction-level parallelism analysis. This exercise [@problem_id:3661275] is key to understanding the theoretical limits of processor performance.", "problem": "Consider a superscalar multiple-issue processor with issue width $W=4$ that can dispatch up to $W$ instructions per cycle subject to dependencies. Assume a fully pipelined Arithmetic Logic Unit (ALU) where each ALU instruction has a single-cycle latency and forwarding ensures that an instruction dependent on the previous result can be issued in the very next cycle without stalls. The processor implements out-of-order execution (OoOE) with perfect register renaming, perfect branch prediction, and no cache or memory stalls, so only true data dependencies and the finite issue width limit the schedule.\n\nYou are given a micro-kernel consisting of a pure dependence chain of $D=10$ ALU instructions, where each instruction depends on the result of the immediately preceding one. There are no other instructions in the kernel for part one. For part two, suppose we additionally have $k$ more ALU instructions that are completely independent of all other instructions and can be interleaved arbitrarily to maximize throughput, still under the same hardware assumptions.\n\n- Derive, from first principles and core definitions of issue width and instruction-level parallelism, the minimal number of cycles required to complete the $D=10$-instruction dependence chain on this $W=4$ processor.\n- Then, derive a closed-form expression for the best-achievable improvement in Instructions Per Cycle (IPC), defined as the IPC with the $D+k$ instruction mix divided by the IPC of the $D$-only baseline, as a function of $k$.\n\nProvide your final results as a single integer for the minimal cycles in part one and a single closed-form analytic expression in $k$ for the IPC improvement in part two. No rounding is required, and no physical units apply. Express the final answer as specified.", "solution": "The problem asks for two results concerning the performance of a superscalar processor. First, the time to execute a strict dependency chain. Second, the IPC improvement when independent instructions are added. We begin by analyzing the constraints and capabilities of the processor as described.\n\nThe processor has an issue width of $W=4$, meaning it can dispatch up to $4$ instructions per cycle. The execution is out-of-order with perfect register renaming, which eliminates all but true data (Read-After-Write) dependencies. The problem simplifies the environment by assuming perfect branch prediction and no memory stalls, so performance is limited only by instruction dependencies and the finite issue width. ALU instructions have a $1$-cycle latency, and full forwarding allows a dependent instruction to be issued in the cycle immediately following the issuance of the instruction it depends on.\n\n### Part 1: Minimal Cycles for the D-instruction Chain\n\nLet the pure dependence chain of $D=10$ instructions be denoted by $I_1, I_2, \\dots, I_{10}$. The dependency structure is that instruction $I_{j+1}$ requires the result of $I_j$ for $j \\in \\{1, 2, \\dots, 9\\}$.\n\nThe processor's ability to handle dependencies is key. A $1$-cycle latency combined with full forwarding is specified to mean \"an instruction dependent on the previous result can be issued in the very next cycle\". Let's trace the execution of the chain based on this rule:\n\n- In cycle $c=1$, instruction $I_1$ can be issued.\n- In cycle $c=2$, since $I_2$ depends on $I_1$, it can be issued. The processor's out-of-order capabilities and forwarding logic make the result of $I_1$ available for $I_2$ to proceed.\n- This pattern continues. For any instruction $I_j$ in the chain, it can be issued in cycle $c=j$.\n\nTherefore, the instructions are issued as follows:\n- $I_1$ in cycle $1$.\n- $I_2$ in cycle $2$.\n- ...\n- $I_{10}$ in cycle $10$.\n\nThe issue width $W=4$ does not allow for accelerating this sequence because there is no instruction-level parallelism (ILP) within the chain itself. At any given cycle, only one instruction in the sequence is ready to be issued. The other $W-1=3$ issue slots for that cycle will remain unused.\n\nThe problem asks for the number of cycles to *complete* the chain. An ALU instruction has a $1$-cycle latency. Assuming this means an instruction issued in cycle $c$ completes its execution by the end of cycle $c$, the completion time of the entire sequence is determined by the completion of the last instruction, $I_{10}$.\n\nSince $I_{10}$ is issued in cycle $10$, it completes at the end of cycle $10$. Consequently, the minimal number of cycles required to complete the $D=10$ instruction chain is $10$.\n\nIn general, for a dependency chain of length $D$ where each link has a latency of $1$ cycle for issuance, the total time is $D$ cycles.\nFor this part, with $D=10$, the number of cycles is $10$.\n\n### Part 2: IPC Improvement with k Independent Instructions\n\nFirst, we establish the baseline performance with only the $D=10$ instruction chain.\n- Number of instructions, $N_{\\text{base}} = D = 10$.\n- Number of cycles, $C_{\\text{base}} = D = 10$ (from Part 1).\n- Baseline Instructions Per Cycle, $\\text{IPC}_{\\text{base}} = \\frac{N_{\\text{base}}}{C_{\\text{base}}} = \\frac{10}{10} = 1$.\n\nNext, we analyze the new scenario with $k$ additional, fully independent ALU instructions.\n- Total number of instructions, $N_{\\text{new}} = D+k = 10+k$.\n- We must find the minimal number of cycles, $C_{\\text{new}}$, to execute this mix of $D+k$ instructions.\n\nThe execution time for a block of code on a superscalar processor is fundamentally constrained by two factors: the critical path length (depth/span) and the total work required (work).\n1.  **Depth Constraint:** The execution time must be at least the length of the longest chain of dependent computations. In this case, the critical path is the $D$-instruction chain, which, as determined in Part 1, requires $D$ cycles. Thus, $C_{\\text{new}} \\ge D$.\n2.  **Work Constraint:** The processor can execute a maximum of $W$ instructions per cycle. To execute a total of $N_{\\text{new}} = D+k$ instructions, the number of cycles must be at least the total instruction count divided by the issue width. Thus, $C_{\\text{new}} \\ge \\lceil \\frac{D+k}{W} \\rceil$.\n\nCombining these two lower bounds, the minimal possible number of cycles is the maximum of the two:\n$$C_{\\text{new}} \\ge \\max\\left(D, \\left\\lceil \\frac{D+k}{W} \\right\\rceil\\right)$$\nWith an ideal out-of-order scheduler, this lower bound is achievable. The scheduler can prioritize instructions on the critical path ($I_j$) while using the remaining issue slots to execute the independent instructions.\n- In each cycle $j \\in \\{1, \\dots, D\\}$, the scheduler issues $I_j$. This consumes one issue slot.\n- The remaining $W-1$ issue slots in each of these $D$ cycles can be used for the $k$ independent instructions.\n- If $D \\ge \\lceil \\frac{D+k}{W} \\rceil$, which simplifies to $k \\le D(W-1)$, there are enough \"free\" slots within the first $D$ cycles to execute all $k$ independent instructions. The execution finishes when $I_D$ completes, so $C_{\\text{new}} = D$.\n- If $D < \\lceil \\frac{D+k}{W} \\rceil$, which simplifies to $k > D(W-1)$, the total number of instructions is the limiting factor. All $D$ critical path instructions and $D(W-1)$ independent instructions are issued within the first $D$ cycles. The remaining $k - D(W-1)$ independent instructions are issued in subsequent cycles using all $W$ issue slots. The total time is dictated by the work constraint. Thus, $C_{\\text{new}} = \\lceil \\frac{D+k}{W} \\rceil$.\n\nThese two cases are perfectly captured by the expression:\n$$C_{\\text{new}}(k) = \\max\\left(D, \\left\\lceil \\frac{D+k}{W} \\right\\rceil\\right)$$\nNow, we can calculate the new IPC with the $D+k$ instruction mix:\n$$\\text{IPC}_{\\text{new}}(k) = \\frac{N_{\\text{new}}}{C_{\\text{new}}(k)} = \\frac{D+k}{\\max\\left(D, \\left\\lceil \\frac{D+k}{W} \\right\\rceil\\right)}$$\nThe problem asks for the IPC improvement, defined as the ratio $\\frac{\\text{IPC}_{\\text{new}}}{\\text{IPC}_{\\text{base}}}$.\nSince $\\text{IPC}_{\\text{base}}=1$, the improvement $I(k)$ is simply $\\text{IPC}_{\\text{new}}(k)$.\n$$I(k) = \\frac{D+k}{\\max\\left(D, \\left\\lceil \\frac{D+k}{W} \\right\\rceil\\right)}$$\nSubstituting the given values $D=10$ and $W=4$, we obtain the closed-form expression for the IPC improvement as a function of $k$:\n$$I(k) = \\frac{10+k}{\\max\\left(10, \\left\\lceil \\frac{10+k}{4} \\right\\rceil\\right)}$$\nThis expression is the answer for the second part of the problem.\n\nFinal summary of results:\n- Part 1: Minimal cycles = $10$.\n- Part 2: IPC Improvement $I(k) = \\frac{10+k}{\\max\\left(10, \\left\\lceil \\frac{10+k}{4} \\right\\rceil\\right)}$.", "answer": "$$\\boxed{\\begin{pmatrix} 10 & \\frac{10+k}{\\max\\left(10, \\left\\lceil \\frac{10+k}{4} \\right\\rceil\\right)} \\end{pmatrix}}$$", "id": "3661275"}, {"introduction": "Building on the theoretical limits, this practice delves into the concrete mechanics of instruction scheduling. You will act as the processor's scheduler, manually mapping a Directed Acyclic Graph (DAG) of operations onto a machine with specific functional unit constraints (ALUs and a memory unit). This hands-on scheduling task [@problem_id:3661333] will make the abstract concepts of resource contention and critical path management tangible and highlight how efficiently utilizing all available hardware is crucial for performance.", "problem": "A multiple-issue processor can initiate up to $W=3$ operations per cycle and contains two Arithmetic Logic Units (ALUs) and one memory unit (MEM). Consider a program fragment represented as a Directed Acyclic Graph (DAG) with $25$ nodes $v_1, v_2, \\dots, v_{25}$, where each node is a single operation that occupies exactly one cycle on its required resource and produces its output at the end of that cycle. An edge $v_i \\to v_j$ denotes a Read-After-Write (RAW) dependency: node $v_j$ may be scheduled only in a strictly later cycle than $v_i$. The machine can, in any cycle, issue up to two ALU operations and up to one MEM operation; no other structural hazards exist.\n\nEach node $v_i$ has an operation type $T(v_i) \\in \\{\\mathrm{ALU}, \\mathrm{MEM}\\}$ as follows:\n- Chain nodes and types: $T(v_1)=\\mathrm{MEM}$, $T(v_2)=\\mathrm{ALU}$, $T(v_3)=\\mathrm{ALU}$, $T(v_4)=\\mathrm{MEM}$, $T(v_5)=\\mathrm{ALU}$, $T(v_6)=\\mathrm{MEM}$, $T(v_7)=\\mathrm{ALU}$, $T(v_8)=\\mathrm{ALU}$, $T(v_9)=\\mathrm{MEM}$, $T(v_{10})=\\mathrm{ALU}$, $T(v_{11})=\\mathrm{MEM}$, $T(v_{12})=\\mathrm{ALU}$.\n- Off-chain nodes and types: $T(v_{13})=\\mathrm{ALU}$, $T(v_{14})=\\mathrm{ALU}$, $T(v_{15})=\\mathrm{ALU}$, $T(v_{16})=\\mathrm{ALU}$, $T(v_{17})=\\mathrm{MEM}$, $T(v_{18})=\\mathrm{ALU}$, $T(v_{19})=\\mathrm{ALU}$, $T(v_{20})=\\mathrm{MEM}$, $T(v_{21})=\\mathrm{ALU}$, $T(v_{22})=\\mathrm{ALU}$, $T(v_{23})=\\mathrm{MEM}$, $T(v_{24})=\\mathrm{ALU}$, $T(v_{25})=\\mathrm{ALU}$.\n\nThe RAW dependencies (directed edges) are:\n- Chain edges: $v_1 \\to v_2 \\to v_3 \\to v_4 \\to v_5 \\to v_6 \\to v_7 \\to v_8 \\to v_9 \\to v_{10} \\to v_{11} \\to v_{12}$.\n- Off-chain edges: $v_1 \\to v_{13}$, $v_1 \\to v_{14}$, $v_2 \\to v_{15}$, $v_2 \\to v_{16}$, $v_2 \\to v_{17}$, $v_4 \\to v_{21}$, $v_5 \\to v_{24}$, $v_8 \\to v_{22}$, $v_9 \\to v_{23}$, $v_{11} \\to v_{25}$. Nodes $v_{18}$, $v_{19}$, and $v_{20}$ have no incoming edges.\n\nAll operations have one-cycle execution latency, produce their results at the end of that cycle, and occupy only the resource corresponding to their type for that one cycle. No operation may be scheduled in the same cycle as any of its predecessors.\n\nTask: Under these constraints, construct a valid schedule that minimizes the completion time (makespan), then compute:\n- The total number of cycles required to complete all $25$ nodes.\n- The resource utilization fractions for the ALU and MEM resources, defined respectively as\n  the ratio of total ALU-operation cycles executed to the total ALU capacity ($2$ units for each cycle over the full schedule), and\n  the ratio of total MEM-operation cycles executed to the total MEM capacity ($1$ unit for each cycle over the full schedule).\nExpress the utilization values as decimals or fractions with no percent sign. Report your final answer in the order: $(\\text{total cycles}, \\text{ALU utilization}, \\text{MEM utilization})$.", "solution": "The goal is to find a schedule for the $25$ operations that minimizes the total execution time (makespan), subject to data dependency and resource constraints. The solution involves three main parts: calculating the lower bounds on the makespan, constructing an optimal schedule, and then calculating the required metrics.\n\n**1. Lower Bounds on Makespan**\n\nThe makespan $T$ is limited by several factors: the critical path length, resource limitations, and issue width. The makespan must be greater than or equal to the maximum of these lower bounds.\n\n-   **Dependency Bound (Critical Path)**: The length of the longest path in the dependency DAG determines the minimum time dictated by data dependencies.\n    -   The primary chain is $v_1 \\to v_2 \\to \\dots \\to v_{12}$. This path involves $12$ nodes. Since each operation takes one cycle and a dependent operation can only start in the next cycle, the length of this path is $12$ cycles.\n    -   We must check if any path involving off-chain nodes is longer. For example, the path $v_1 \\to v_2 \\to \\dots \\to v_{11} \\to v_{25}$ also has a length of $12$ nodes.\n    -   No other path is longer than $12$ nodes. For instance, $v_1 \\to \\dots \\to v_9 \\to v_{23}$ is $10$ nodes long.\n    -   Thus, the critical path length is $12$ cycles. This gives a lower bound $T \\ge 12$.\n\n-   **Resource Bounds**:\n    -   Count of operation types:\n        -   ALU operations: $v_2, v_3, v_5, v_7, v_8, v_{10}, v_{12}, v_{13}, v_{14}, v_{15}, v_{16}, v_{18}, v_{19}, v_{21}, v_{22}, v_{24}, v_{25}$. Total ALU ops = $17$.\n        -   MEM operations: $v_1, v_4, v_6, v_9, v_{11}, v_{17}, v_{20}, v_{23}$. Total MEM ops = $8$.\n    -   ALU resource bound: With $17$ ALU operations and $2$ ALU units, the minimum time is $\\lceil \\frac{17}{2} \\rceil = \\lceil 8.5 \\rceil = 9$ cycles.\n    -   MEM resource bound: With $8$ MEM operations and $1$ MEM unit, the minimum time is $\\lceil \\frac{8}{1} \\rceil = 8$ cycles.\n\n-   **Issue Width Bound**: With $25$ total operations and an issue width of $3$, the minimum time is $\\lceil \\frac{25}{3} \\rceil = \\lceil 8.33 \\rceil = 9$ cycles.\n\nCombining these, the makespan must be at least $T \\ge \\max(12, 9, 8, 9) = 12$ cycles. The challenge is to find a schedule that achieves this lower bound.\n\n**2. Schedule Construction**\n\nWe construct a schedule cycle by cycle using a list scheduling algorithm, prioritizing operations on the critical path. A node is \"ready\" if all its predecessors have been completed.\n\n-   **Cycle 1**:\n    -   Ready nodes: $v_1$ (MEM), $v_{18}$ (ALU), $v_{19}$ (ALU), $v_{20}$ (MEM).\n    -   Available resources: $2$ ALU, $1$ MEM.\n    -   Schedule: $\\{ v_1, v_{18}, v_{19} \\}$. ($v_1$ is on the critical path).\n\n-   **Cycle 2**:\n    -   Ready nodes: $v_2$ (ALU), $v_{13}$ (ALU), $v_{14}$ (ALU) (from $v_1$ completion), and $v_{20}$ (MEM).\n    -   Schedule: $\\{ v_2, v_{13}, v_{20} \\}$. ($v_2$ is on the critical path; we use $1$ ALU slot for $v_2$, the second for $v_{13}$, and the MEM slot for $v_{20}$).\n\n-   **Cycle 3**:\n    -   Ready nodes: $v_3$ (ALU), $v_{15}$ (ALU), $v_{16}$ (ALU), $v_{17}$ (MEM) (from $v_2$ completion), and $v_{14}$ (ALU) (from previous cycle).\n    -   Schedule: $\\{ v_3, v_{14}, v_{17} \\}$. ($v_3$ is on the critical path).\n\n-   **Cycle 4**:\n    -   Ready nodes: $v_4$ (MEM) (from $v_3$ completion), and $v_{15}$ (ALU), $v_{16}$ (ALU) (from previous cycle).\n    -   Schedule: $\\{ v_4, v_{15}, v_{16} \\}$. ($v_4$ is on the critical path).\n\n-   **Cycle 5**:\n    -   Ready nodes: $v_5$ (ALU), $v_{21}$ (ALU) (from $v_4$ completion).\n    -   Schedule: $\\{ v_5, v_{21} \\}$. ($v_5$ is on the critical path).\n\n-   **Cycle 6**:\n    -   Ready nodes: $v_6$ (MEM), $v_{24}$ (ALU) (from $v_5$ completion).\n    -   Schedule: $\\{ v_6, v_{24} \\}$. ($v_6$ is on the critical path).\n\n-   **Cycle 7**:\n    -   Ready nodes: $v_7$ (ALU) (from $v_6$ completion).\n    -   Schedule: $\\{ v_7 \\}$.\n\n-   **Cycle 8**:\n    -   Ready nodes: $v_8$ (ALU) (from $v_7$ completion).\n    -   Schedule: $\\{ v_8 \\}$.\n\n-   **Cycle 9**:\n    -   Ready nodes: $v_9$ (MEM), $v_{22}$ (ALU) (from $v_8$ completion).\n    -   Schedule: $\\{ v_9, v_{22} \\}$.\n\n-   **Cycle 10**:\n    -   Ready nodes: $v_{10}$ (ALU), $v_{23}$ (MEM) (from $v_9$ completion).\n    -   Schedule: $\\{ v_{10}, v_{23} \\}$.\n\n-   **Cycle 11**:\n    -   Ready nodes: $v_{11}$ (MEM) (from $v_{10}$ completion).\n    -   Schedule: $\\{ v_{11} \\}$.\n\n-   **Cycle 12**:\n    -   Ready nodes: $v_{12}$ (ALU), $v_{25}$ (ALU) (from $v_{11}$ completion).\n    -   Schedule: $\\{ v_{12}, v_{25} \\}$.\n\nAll $25$ operations are completed in $12$ cycles. Since this matches the critical path lower bound, this schedule is optimal.\n\n**3. Calculation of Metrics**\n\n-   **Total Cycles (Makespan)**:\n    The makespan of the optimal schedule is $12$ cycles.\n\n-   **ALU Utilization**:\n    -   Total ALU operations performed = $17$.\n    -   Total ALU capacity over the schedule = (Number of ALU units) $\\times$ (Makespan) = $2 \\times 12 = 24$ ALU-cycles.\n    -   ALU Utilization = $\\frac{\\text{Total ALU operations}}{\\text{Total ALU capacity}} = \\frac{17}{24}$.\n\n-   **MEM Utilization**:\n    -   Total MEM operations performed = $8$.\n    -   Total MEM capacity over the schedule = (Number of MEM units) $\\times$ (Makespan) = $1 \\times 12 = 12$ MEM-cycles.\n    -   MEM Utilization = $\\frac{\\text{Total MEM operations}}{\\text{Total MEM capacity}} = \\frac{8}{12} = \\frac{2}{3}$.\n\nThe final results are: a makespan of $12$ cycles, an ALU utilization of $\\frac{17}{24}$, and a MEM utilization of $\\frac{2}{3}$.", "answer": "$$\\boxed{\\begin{pmatrix} 12 & \\frac{17}{24} & \\frac{2}{3} \\end{pmatrix}}$$", "id": "3661333"}, {"introduction": "Finally, we zoom out to consider the large-scale architectural structures that enable aggressive out-of-order execution. This exercise examines how finite resources like the Reorder Buffer (ROB) and the Physical Register File (PRF) constrain the amount of instruction-level parallelism a processor can actually exploit from a loop. By calculating the number of in-flight iterations and the impact of branch mispredictions, you will model a realistic commit-bound performance scenario [@problem_id:3661308] and see how the back-end of the processor can become the ultimate bottleneck.", "problem": "Consider an out-of-order, multiple-issue processor executing a tight loop. The core has a Reorder Buffer (ROB) of size $Q=64$ entries and a physical register rename file of size $R=128$ integer registers. The loop body consists of $10$ independent accumulator updates (each update is a single-cycle integer addition to a distinct accumulator register), one loop-counter increment, and one conditional branch that checks the loop counter. Assume the following microarchitectural properties:\n- The pipelines support up to $8$ instructions per cycle at decode, issue, and commit.\n- Integer additions have a latency of $1$ cycle and sufficient functional units are present to avoid structural hazards other than the width limit.\n- The branch predictor has a misprediction rate of $m=0.02$ per dynamic branch, and a misprediction incurs a recovery penalty of $F=12$ cycles during which no instructions are committed.\n- The memory system introduces no stalls and there are no cache misses.\n- Register renaming allocates one physical register per destination until the corresponding instruction commits, after which the old physical register is freed.\n- The branch instruction itself produces no destination register.\n\nUse the fundamental constraints imposed by the ROB and the rename file to determine how many loop iterations can be simultaneously in flight. Then, using the definitions of Instruction-Level Parallelism (ILP) and Instructions Per Cycle (IPC), determine the sustained $IPC$ when the ROB saturates. Round your final $IPC$ to four significant figures. Express the final answer as a pure number without units.", "solution": "The first step is to determine the maximum number of loop iterations that can be simultaneously in flight. This quantity, denoted by $K$, is constrained by the size of the Reorder Buffer (ROB) and the Physical Register File (PRF).\n\nThe provided parameters are:\n- ROB size: $Q = 64$ entries\n- PRF size: $R = 128$ registers\n- Processor width (decode, issue, commit): $W = 8$ instructions/cycle\n- Branch misprediction rate: $m = 0.02$\n- Branch misprediction penalty: $F = 12$ cycles\n\nThe loop body consists of:\n- $10$ independent accumulator updates (integer additions).\n- $1$ loop-counter increment (integer addition).\n- $1$ conditional branch.\n\nFirst, we analyze the resource requirements per loop iteration.\nThe total number of instructions per iteration is $N_{inst} = 10 + 1 + 1 = 12$.\nThe number of instructions that write to a destination register is the sum of accumulator updates and the loop-counter increment, so $N_{reg} = 10 + 1 = 11$. The branch instruction does not have a destination register.\n\nNext, we evaluate the constraints on the number of in-flight iterations, $K$.\n\n1.  **ROB Constraint**: The ROB must hold an entry for every instruction in flight. With $K$ iterations, the total number of instructions is $K \\times N_{inst}$. This must not exceed the ROB size $Q$.\n    $$K \\times N_{inst} \\le Q$$\n    $$K \\times 12 \\le 64$$\n    $$K \\le \\frac{64}{12} \\approx 5.333$$\n    Since $K$ must be an integer, the maximum number of iterations constrained by the ROB is $K_{ROB} = \\lfloor 5.333 \\rfloor = 5$.\n\n2.  **PRF Constraint**: The PRF must contain registers for both the committed architectural state and the speculative results of in-flight instructions. The problem specifies that the loop modifies $N_{reg} = 11$ distinct architectural registers (10 accumulators and 1 loop counter). The number of physical registers required is the sum of those needed for the last committed state and those for the new speculative values. For each of the $N_{reg}$ architectural registers, there is one committed value and $K$ speculative future values from the $K$ in-flight iterations. A standard model for the required physical register count is $N_{reg} \\times (K+1)$. A more common and simpler model states that the PRF size $R$ must accommodate the architectural registers plus the speculative registers, where the number of speculative registers equals the number of in-flight instructions with destinations. Let's assume the relevant architectural state space consists only of the $N_{reg}$ registers manipulated by the loop, so the number of architectural registers to track is $N_{AR} = 11$. Thus, the total physical registers needed are $N_{AR} + K \\times N_{reg}$.\n    $$N_{AR} + K \\times N_{reg} \\le R$$\n    $$11 + K \\times 11 \\le 128$$\n    $$11 \\times (K + 1) \\le 128$$\n    $$K + 1 \\le \\frac{128}{11} \\approx 11.636$$\n    $$K \\le 10.636$$\n    Since $K$ must be an integer, the maximum number of iterations constrained by the PRF is $K_{PRF} = \\lfloor 10.636 \\rfloor = 10$.\n\nThe overall number of simultaneously in-flight iterations is limited by the stricter of these two constraints:\n$$K = \\min(K_{ROB}, K_{PRF}) = \\min(5, 10) = 5$$\nThe processor is therefore limited by the ROB size and can sustain $5$ iterations in flight. With $N_{inst}=12$ instructions per iteration, this corresponds to $5 \\times 12 = 60$ instructions in the ROB, which confirms the condition that the \"ROB saturates\".\n\nWith the ROB saturated, the processor's performance is limited by the rate at which instructions can be committed, which frees up ROB entries for new instructions. This is a commit-bound scenario. The sustained Instructions Per Cycle (IPC) is determined by the commit width and any stalls that halt commitment.\n\nThe commit width is $W = 8$ instructions per cycle. In the absence of any stalls, the average number of cycles required to commit one iteration's worth of instructions ($N_{inst} = 12$) would be:\n$$C_{commit} = \\frac{N_{inst}}{W} = \\frac{12}{8} = 1.5 \\text{ cycles/iteration}$$\nHowever, the processor also experiences stalls due to branch mispredictions. The problem states that a misprediction incurs a penalty of $F = 12$ cycles, during which no instructions are committed. Each iteration contains one branch, and the misprediction rate is $m = 0.02$. The average penalty in cycles per iteration is:\n$$C_{penalty} = m \\times F = 0.02 \\times 12 = 0.24 \\text{ cycles/iteration}$$\nThe total average number of cycles per iteration, $C_{iter}$, is the sum of the cycles needed for commit and the average penalty cycles.\n$$C_{iter} = C_{commit} + C_{penalty} = 1.5 + 0.24 = 1.74 \\text{ cycles/iteration}$$\nThe sustained IPC is the number of instructions per iteration divided by the average number of cycles per iteration.\n$$IPC = \\frac{N_{inst}}{C_{iter}} = \\frac{12}{1.74}$$\n$$IPC \\approx 6.8965517...$$\nThe problem requires rounding the final answer to four significant figures.\n$$IPC \\approx 6.897$$\nThis value represents the sustained throughput of the processor when executing this specific loop under the given architectural constraints. The calculation of $K=5$ was crucial to confirm that the processor has enough in-flight work to become commit-bound, justifying this throughput-based analysis.", "answer": "$$\\boxed{6.897}$$", "id": "3661308"}]}