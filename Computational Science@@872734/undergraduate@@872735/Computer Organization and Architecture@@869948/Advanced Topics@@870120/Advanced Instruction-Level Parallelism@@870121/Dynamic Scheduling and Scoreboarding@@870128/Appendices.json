{"hands_on_practices": [{"introduction": "Understanding a scoreboard requires getting into the details of cycle-by-cycle execution. This first exercise [@problem_id:3638650] challenges you to trace a short program on a processor with a classic scoreboard. By meticulously tracking each instruction through the pipeline, you will see precisely how the hardware enforces data dependency rules and stalls for specific hazards like Write-After-Write (WAW) and Write-After-Read (WAR).", "problem": "Consider a toy Instruction Set Architecture (ISA) with three-address integer instructions and a classic scoreboard-based dynamic scheduler. The machine supports out-of-order execution subject to the scoreboard’s hazards and stage rules. The ISA and microarchitectural rules are as follows.\n\n- Instruction Set Architecture (ISA): Instructions have the form $\\mathrm{OP}\\;R_{d}, R_{s1}, R_{s2}$, with semantics $R_{d} \\leftarrow R_{s1}\\;\\mathrm{OP}\\;R_{s2}$. Supported operations and latencies:\n  - $\\mathrm{ADD}$ on an Integer Arithmetic Logic Unit (ALU): latency $L_{A} = 2$ cycles.\n  - $\\mathrm{MUL}$ on a Multiplier: latency $L_{M} = 5$ cycles.\n  - $\\mathrm{LD}$ on a Load Unit: format $\\mathrm{LD}\\;R_{d}, [R_{s1}]$ with latency $L_{L} = 3$ cycles. Assume addresses are formed by using the value in $R_{s1}$; there are no memory bank conflicts.\n\n- Microarchitecture and Scoreboard:\n  - Functional Units (FU): $2$ ALUs, $1$ Multiplier, $1$ Load Unit. Each FU can host at most one instruction at a time; an FU is reserved at the Issue stage and is released after the Write Result stage.\n  - Pipeline stages per instruction: Issue $\\rightarrow$ Read Operands $\\rightarrow$ Execute $\\rightarrow$ Write Result. Issue and Read Operands each take $1$ cycle; Execute takes $L$ cycles depending on operation; Write Result takes $1$ cycle.\n  - Stage ordering within a cycle: First perform all eligible Write Result actions, then all eligible Read Operands actions, then perform a single Issue of at most one instruction. Operand readiness for Read Operands is evaluated at the beginning of the cycle, prior to any writes in that cycle; a value written in cycle $t$ becomes available to be read no earlier than cycle $t+1$.\n  - Hazards enforced by the scoreboard:\n    - Write-After-Write (WAW): At Issue, stall if any active (issued but not yet completed) instruction has destination register equal to the incoming instruction’s destination.\n    - Read-After-Write (RAW): At Read Operands, stall until every source register is ready (i.e., its last earlier writer has completed Write Result).\n    - Write-After-Read (WAR): At Write Result, stall if any earlier active instruction has not yet performed Read Operands and uses the writer’s destination register as one of its sources.\n  - Result bus: There is a single global write port; at most one Write Result can occur per cycle. If more than one instruction is ready to write in the same cycle, all but one are structurally stalled. For the question below, these structural stalls on the write port must not be counted toward WAW or WAR stalls.\n\n- Initial conditions: At cycle $1$, all architectural registers $R_{0}, R_{1}, \\dots$ have valid initial values (i.e., they are considered ready) except for registers that will be defined by the program itself. There are no cache misses or additional memory delays beyond $L_{L}$, and there are no branch instructions.\n\nProgram to execute (in program order, with instruction identifiers $I_{1}$ through $I_{5}$):\n1. $I_{1}: \\mathrm{LD}\\;R_{9}, [R_{10}]$\n2. $I_{2}: \\mathrm{ADD}\\;R_{7}, R_{5}, R_{9}$\n3. $I_{3}: \\mathrm{ADD}\\;R_{5}, R_{1}, R_{2}$\n4. $I_{4}: \\mathrm{MUL}\\;R_{5}, R_{3}, R_{4}$\n5. $I_{5}: \\mathrm{ADD}\\;R_{8}, R_{5}, R_{6}$\n\nNotes:\n- The two instructions $I_{3}$ and $I_{4}$ both write to $R_{5}$, creating destination aliasing.\n- The instruction $I_{2}$ reads $R_{5}$ but must wait for $R_{9}$ from $I_{1}$, which interacts with WAR constraints when a later instruction attempts to write $R_{5}$.\n- Schedule the execution as aggressively as allowed by the rules to minimize total time: each stage should occur at the earliest cycle permitted by scoreboard constraints and FU availability.\n\nTask:\nCompute the total number of stall cycles that are attributed exclusively to Write-After-Write (WAW) and Write-After-Read (WAR) hazards during the complete execution of $I_{1}$ through $I_{5}$ under the above model. Do not count stall cycles caused by Read-After-Write (RAW) hazards or by structural constraints such as the single write port or FU availability. Express your final answer as a single integer. No rounding is required.", "solution": "The user wants me to determine the total number of stall cycles caused exclusively by Write-After-Write (WAW) and Write-After-Read (WAR) hazards for a given code sequence on a scoreboard-based processor.\n\n### Step 1: Problem Validation\n\n**1. Extract Givens:**\n*   **Instruction Set and Latencies:**\n    *   $\\mathrm{OP}\\;R_{d}, R_{s1}, R_{s2}$ with $R_{d} \\leftarrow R_{s1}\\;\\mathrm{OP}\\;R_{s2}$.\n    *   $\\mathrm{ADD}$: Latency $L_{A} = 2$ cycles.\n    *   $\\mathrm{MUL}$: Latency $L_{M} = 5$ cycles.\n    *   $\\mathrm{LD}\\;R_{d}, [R_{s1}]$: Latency $L_{L} = 3$ cycles.\n*   **Microarchitecture:**\n    *   Functional Units (FUs): $2$ ALUs, $1$ Multiplier, $1$ Load Unit. FUs are busy from Issue to Write Result.\n    *   Pipeline Stages: Issue ($1$ cycle), Read Operands ($1$ cycle), Execute ($L$ cycles), Write Result ($1$ cycle).\n    *   Intra-cycle Stage Order: 1. Write Result, 2. Read Operands, 3. Issue.\n    *   Operand Forwarding: A result written in cycle $t$ is available for Read Operands in cycle $t+1$.\n    *   Write Port: Single write port, allowing at most one Write Result per cycle.\n*   **Hazard Rules:**\n    *   **WAW (Write-After-Write):** Stall Issue if an active instruction has the same destination register.\n    *   **RAW (Read-After-Write):** Stall Read Operands until source registers are ready.\n    *   **WAR (Write-After-Read):** Stall Write Result if an earlier active instruction, which has not yet read its operands, uses the destination register as a source.\n*   **Initial Conditions:**\n    *   All registers are ready at cycle $1$ except those defined by the program.\n*   **Program Sequence:**\n    1.  $I_{1}: \\mathrm{LD}\\;R_{9}, [R_{10}]$\n    2.  $I_{2}: \\mathrm{ADD}\\;R_{7}, R_{5}, R_{9}$\n    3.  $I_{3}: \\mathrm{ADD}\\;R_{5}, R_{1}, R_{2}$\n    4.  $I_{4}: \\mathrm{MUL}\\;R_{5}, R_{3}, R_{4}$\n    5.  $I_{5}: \\mathrm{ADD}\\;R_{8}, R_{5}, R_{6}$\n\n**2. Validate Using Extracted Givens:**\n*   **Scientific Grounding:** The problem is a classic exercise in computer architecture, based on the well-established principles of scoreboard-based dynamic scheduling. All rules and concepts are standard in this domain.\n*   **Well-Posedness:** The problem provides a complete and deterministic set of rules, latencies, and a program sequence. The objective is to calculate a specific, verifiable quantity. A unique solution exists.\n*   **Objectivity:** The problem is stated in precise, formal language without any subjective or ambiguous terms.\n*   **Completeness and Consistency:** All necessary parameters (latencies, FU counts, hazard rules) are specified. The rules are internally consistent and allow for a step-by-step simulation of the processor's execution.\n*   **Other Flaws:** The problem is not trivial, metaphorical, or outside the scope of scientific analysis. It directly addresses the topic of dynamic scheduling.\n\n**3. Verdict and Action:**\nThe problem is valid and well-posed. I will proceed with a detailed, cycle-by-cycle simulation to solve it.\n\n### Step 2: Cycle-by-Cycle Execution Analysis\n\nTo determine the number of stall cycles, we will construct a pipeline timing chart. Each instruction progresses through the stages: Issue (I), Read Operands (RO), Execute (E), and Write Result (WR). A stall is denoted by '(S)'. The execution of an instruction with latency $L$ takes $L$ cycles, finishing at the end of the $L$-th cycle. Note that the problem asks to count only WAW and WAR stalls.\n\n**Instruction Dependencies:**\n*   $I_2$ has a RAW dependency on $I_1$ for register $R_9$.\n*   $I_3$ has a WAR dependency on $I_2$ for register $R_5$ ($I_2$ reads $R_5$ before $I_3$ writes to it).\n*   $I_4$ has a WAW dependency on $I_3$ for register $R_5$.\n*   $I_5$ has a RAW dependency on $I_4$ for register $R_5$.\n\n**Timeline:**\n*   **Cycle 1:** $I_1$ issues (Load FU occupied).\n*   **Cycle 2:** $I_1$ reads operands. $I_2$ issues (ALU1 occupied).\n*   **Cycle 3:** $I_1$ begins execution (cycle $1$ of $3$). $I_2$ stalls at RO (RAW hazard on $R_9$, which is not yet written by $I_1$). $I_3$ issues (ALU2 occupied).\n*   **Cycle 4:** $I_1$ executes (cycle $2$ of $3$). $I_2$ remains stalled (RAW on $R_9$). $I_3$ reads operands. $I_4$ attempts to issue. It is blocked because an active instruction ($I_3$) is also writing to $R_5$. This is a **WAW stall**. (WAW stall cycles = $1$).\n*   **Cycle 5:** $I_1$ executes (cycle $3$ of $3$), completing at the end of this cycle. $I_2$ remains stalled (RAW on $R_9$). $I_3$ begins execution (cycle $1$ of $2$). $I_4$ remains stalled on Issue due to the **WAW hazard** from $I_3$. (WAW stall cycles = $2$).\n*   **Cycle 6:** $I_1$ performs Write Result. $R_9$ will be available in cycle $7$. $I_2$ remains stalled (RAW on $R_9$). $I_3$ executes (cycle $2$ of $2$), completing at the end of this cycle. $I_4$ remains stalled on Issue due to the **WAW hazard** from $I_3$. (WAW stall cycles = $3$).\n*   **Cycle 7:**\n    *   $I_3$ is ready for Write Result. However, an earlier instruction, $I_2$, has not yet read its operands and uses $R_5$ (the destination of $I_3$) as a source. $I_3$ must stall. This is a **WAR stall**. (WAR stall cycles = $1$).\n    *   $I_2$ now reads its operands, as $R_9$ is available.\n    *   $I_4$ remains stalled on Issue due to the **WAW hazard** from $I_3$ (which is still active, as it has not completed WR). (WAW stall cycles = $4$).\n*   **Cycle 8:**\n    *   The WAR condition for $I_3$ is now clear because $I_2$ read its operands in the previous cycle. $I_3$ performs Write Result. The register reservation on $R_5$ by $I_3$ is released.\n    *   $I_2$ begins execution (cycle $1$ of $2$).\n    *   Following the WR of $I_3$ in this same cycle, the WAW hazard on $I_4$ is cleared. $I_4$ issues (Multiplier FU occupied).\n*   **Cycle 9:** $I_2$ executes (cycle $2$ of $2$), completing at the end of this cycle. $I_4$ reads operands. $I_5$ issues (ALU2 occupied).\n*   **Cycle 10:** $I_2$ performs Write Result. $I_4$ begins execution (cycle $1$ of $5$). $I_5$ stalls at RO (RAW hazard on $R_5$, which is being computed by $I_4$).\n*   **Cycles 11-14:** $I_4$ continues execution (cycles $2, 3, 4, 5$). $I_5$ remains stalled (RAW). At the end of cycle $14$, $I_4$ completes execution.\n*   **Cycle 15:** $I_4$ performs Write Result. There is no WAR stall because $I_5$, which reads $R_5$, is a later, not an earlier, instruction. $R_5$ will be available in cycle $16$. $I_5$ reads operands.\n*   **Cycles 16-17:** $I_5$ executes.\n*   **Cycle 18:** $I_5$ performs Write Result. All instructions are complete.\n\n### Step 3: Tallying the Stalls\n\nWe now sum the stall cycles that were explicitly identified as being caused by WAW or WAR hazards.\n\n*   **WAW Stalls:**\n    *   Instruction $I_4$ was ready to issue in cycle $4$ but was blocked by $I_3$ writing to the same destination register, $R_5$.\n    *   $I_4$ stalled during cycles $4, 5, 6,$ and $7$.\n    *   Total WAW stall cycles = $4$.\n\n*   **WAR Stalls:**\n    *   Instruction $I_3$ was ready to perform Write Result in cycle $7$ but was blocked because an earlier instruction, $I_2$, had not yet read its source operand $R_5$.\n    *   $I_3$ stalled during cycle $7$.\n    *   Total WAR stall cycles = $1$.\n\n*   **Total Stall Cycles (WAW + WAR):**\n    *   The total number of stall cycles attributed exclusively to WAW and WAR hazards is the sum of the individual counts.\n    *   Total = (WAW stalls) + (WAR stalls) = $4 + 1 = 5$.\n\nThe stall cycles experienced by $I_2$ and $I_5$ were due to RAW hazards and are not counted per the problem's instructions. No structural stalls on the write port occurred.", "answer": "$$\n\\boxed{5}\n$$", "id": "3638650"}, {"introduction": "While scoreboarding allows some instructions to execute out of program order, its ability to exploit instruction-level parallelism (ILP) can be severely limited by data dependencies. This problem [@problem_id:3638642] presents a sequence of instructions with a tight chain of dependencies. Your task is to analyze why, despite having multiple functional units, the scoreboard is forced to execute the instructions serially, revealing the performance impact of true (RAW) and anti-dependencies (WAR).", "problem": "Consider a classic scoreboard-based dynamically scheduled processor in the style of the CDC 6600. The scoreboard implements the following four-stage lifetime for each instruction: Issue, Read Operands, Execute, Write Result. The rules are:\n\n- Issue: The instruction may issue in program order only if a suitable functional unit is free and there is no write-after-write (WAW) hazard on its destination register.\n- Read Operands: The instruction may read its source registers when both are marked ready (no pending producer) and all RAW constraints are satisfied.\n- Execute: The instruction occupies its functional unit for a fixed latency specific to the operation.\n- Write Result: The instruction may write its destination when there is no write-after-read (WAR) hazard with any earlier instruction that has not yet read its operands.\n\nAssume the machine has two identical integer adders. Each add instruction uses one adder and has an execute latency of $3$ cycles. Each Issue stage takes $1$ cycle, each Read Operands stage takes $1$ cycle, and each Write Result stage takes $1$ cycle. Only one instruction can be issued per cycle. A functional unit is allocated at Issue and remains occupied until Write Result completes. At the end of a Write Result stage in cycle $t$, the functional unit becomes available to Issue in cycle $t+1$. All initial register values are available at cycle $0$.\n\nConsider the following three integer add instructions, in program order, with explicit dataflow:\n\n- Instruction $\\mathrm{I1}$: $R1 \\leftarrow R2 + R3$,\n- Instruction $\\mathrm{I2}$: $R2 \\leftarrow R1 + R4$,\n- Instruction $\\mathrm{I3}$: $R3 \\leftarrow R2 + R5$,\n\nwhere $R2$, $R3$, $R4$, and $R5$ are ready at cycle $0$ with valid initial values.\n\nStarting only from the scoreboard rules above and the semantics of read-after-write (RAW), write-after-read (WAR), and write-after-write (WAW) hazards, reason whether any parallelism in the Execute stages is possible for this sequence, and determine the minimal completion time (the cycle in which the final Write Result completes) for all three instructions under the given latencies and resource constraints. Express the final time in cycles. No rounding is required.", "solution": "The problem statement is validated as scientifically grounded, well-posed, objective, and internally consistent. It describes a classic scenario in computer architecture that can be analyzed formally using the provided rules. There are no ambiguities or contradictions.\n\nThe problem asks to determine if parallelism is possible in the Execute stages for a sequence of three instructions on a scoreboard-based processor and to find the minimal completion time. The analysis requires a step-by-step simulation of the processor's state, governed by the scoreboard rules and constrained by data dependencies and resource availability.\n\nFirst, we identify the data dependencies between the instructions:\n- Instruction $I1: R1 \\leftarrow R2 + R3$\n- Instruction $I2: R2 \\leftarrow R1 + R4$\n- Instruction $I3: R3 \\leftarrow R2 + R5$\n\n1.  **Read-After-Write (RAW) or True Data Dependencies**: An instruction must wait for its source operands to be produced by a prior instruction.\n    - $I2$ reads $R1$, which is written by $I1$. This creates a RAW dependency, denoted as $I1 \\xrightarrow{\\text{RAW}} I2$. $I2$ cannot read its operands until $I1$ has completed its Write Result stage.\n    - $I3$ reads $R2$, which is written by $I2$. This creates a RAW dependency, $I2 \\xrightarrow{\\text{RAW}} I3$. $I3$ cannot read its operands until $I2$ has completed its Write Result stage.\n    These dependencies form a chain: $I1 \\rightarrow I2 \\rightarrow I3$.\n\n2.  **Write-After-Read (WAR) or Anti-Dependencies**: An instruction must not write to its destination register before a prior instruction has read from that same register.\n    - $I2$ writes to $R2$, which is read by $I1$. This creates a WAR dependency, $I1 \\xrightarrow{\\text{WAR}} I2$. $I2$ cannot write its result until $I1$ has read its operands.\n    - $I3$ writes to $R3$, which is read by $I1$. This creates a WAR dependency, $I1 \\xrightarrow{\\text{WAR}} I3$. $I3$ cannot write its result until $I1$ has read its operands.\n    The scoreboard handles these hazards by delaying the Write Result stage of the writing instruction ($I2$, $I3$) until the reading instruction ($I1$) has completed its Read Operands stage.\n\n3.  **Write-After-Write (WAW) or Output Dependencies**: An instruction must not write to its destination register before a prior instruction has written to that same register.\n    - The instructions $I1$, $I2$, and $I3$ write to distinct registers ($R1$, $R2$, $R3$, respectively). Therefore, there are no WAW hazards among them. The Issue stage can proceed without WAW stalls relative to other instructions in this sequence.\n\nThe processor has two identical integer adders, which we will call $FU1$ and $FU2$. Each stage (Issue, Read Operands, Write Result) takes $1$ cycle. The Execute stage for an add operation takes $3$ cycles. A functional unit is occupied from the cycle it is issued until the cycle its Write Result stage completes.\n\nWe can construct a timing chart to track the progress of each instruction through the four pipeline stages: Issue ($I$), Read Operands ($RO$), Execute ($EX$), and Write Result ($WR$). The numbers in the table represent the cycle number in which each stage completes. The duration of the $EX$ stage is shown by the range of cycles it occupies.\n\n| Instruction    | Stage $I$ | Stage $RO$ | Stage $EX$     | Stage $WR$ | FU    | Comments |\n|----------------|-----------|------------|----------------|------------|-------|----------|\n| $I1: R1 \\leftarrow R2+R3$ | $1$         | $2$          | $3, 4, 5$      | $6$          | $FU1$ | Issues in cycle 1. $R2, R3$ are ready, so RO is in cycle 2. |\n| $I2: R2 \\leftarrow R1+R4$ | $2$         | $7$          | $8, 9, 10$     | $11$         | $FU2$ | Issues in cycle 2. Stalls for RAW on $R1$. $I1$ WR completes at cycle 6, so $I2$ RO begins in cycle 7. |\n| $I3: R3 \\leftarrow R2+R5$ | $7$         | $12$         | $13, 14, 15$   | $16$         | $FU1$ | Stalls for FU. $FU1$ is free in cycle 7. Stalls for RAW on $R2$. $I2$ WR completes at cycle 11, so $I3$ RO begins in cycle 12. |\n\n**Cycle-by-Cycle Analysis:**\n\n- **Cycle 1**: $I1$ issues, as $FU1$ is free and there are no WAW hazards. $FU1$ is allocated to $I1$.\n- **Cycle 2**: $I1$ proceeds to the Read Operands ($RO$) stage. Its source registers, $R2$ and $R3$, are ready at cycle $0$. $I1$ completes $RO$. In parallel, $I2$ issues, as $FU2$ is free. $FU2$ is allocated to $I2$. $I3$ cannot issue because only one instruction can be issued per cycle.\n- **Cycle 3**: $I1$ begins its $3$-cycle execution. It will occupy $FU1$ for cycles $3, 4, 5$. $I2$ attempts its $RO$ stage but stalls because its source register $R1$ is not yet available (it is being produced by $I1$). $I3$ cannot issue as both functional units are now allocated.\n- **Cycles 4, 5**: $I1$ continues execution. $I2$ continues to stall in $RO$. $I3$ continues to stall at Issue.\n- **Cycle 6**: $I1$ finishes execution and enters the Write Result ($WR$) stage. It writes to $R1$. The WAR hazard check ($I1 \\xrightarrow{\\text{WAR}} I2, I3$) has no effect as $I1$ is the first instruction. $R1$ becomes available at the end of this cycle. $I2$ is still waiting for $R1$. $I3$ is still waiting for a free FU.\n- **Cycle 7**: $I1$ is complete. $FU1$ becomes available for a new instruction (since $I1$'s $WR$ completed in cycle $t=6$, the FU is free in $t+1=7$). $I3$ now issues, taking $FU1$. In parallel, $I2$ detects that $R1$ is ready and proceeds with its $RO$ stage, which completes in this cycle.\n- **Cycle 8**: $I2$ begins its $3$-cycle execution in $FU2$ (cycles $8, 9, 10$). $I3$ attempts its $RO$ stage but stalls, waiting for $R2$ from $I2$.\n- **Cycles 9, 10**: $I2$ continues execution. $I3$ continues to stall in $RO$.\n- **Cycle 11**: $I2$ finishes execution and enters the $WR$ stage. It writes to $R2$. The WAR hazard check ($I1 \\xrightarrow{\\text{WAR}} I2$) is passed because $I1$ completed its $RO$ stage in cycle $2$. $R2$ becomes available at the end of this cycle.\n- **Cycle 12**: $I2$ is complete. $I3$ detects that $R2$ is ready and proceeds with its $RO$ stage.\n- **Cycles 13, 14, 15**: $I3$ is in the $EX$ stage, using $FU1$.\n- **Cycle 16**: $I3$ finishes execution and enters the $WR$ stage. The WAR hazard check ($I1 \\xrightarrow{\\text{WAR}} I3$) is passed as $I1$ completed its $RO$ stage in cycle $2$. It writes to $R3$ and completes.\n\n**Conclusion on Parallelism and Completion Time:**\n\nThe Execute stages for the three instructions occur during the following cycle intervals:\n- $I1_{EX}$: cycles $3-5$\n- $I2_{EX}$: cycles $8-10$\n- $I3_{EX}$: cycles $13-15$\n\nThese intervals are disjoint. Therefore, **no parallelism is achieved in the Execute stages**. The strong chain of RAW dependencies ($I1 \\xrightarrow{\\text{RAW}} I2 \\xrightarrow{\\text{RAW}} I3$) serializes the execution, forcing the instructions to proceed one after another despite the availability of two functional units.\n\nThe final instruction, $I3$, completes its Write Result stage at the end of cycle $16$. Thus, the minimal completion time for all three instructions is $16$ cycles.", "answer": "$$ \\boxed{16} $$", "id": "3638642"}, {"introduction": "The limitations of a classic scoreboard, particularly its handling of false dependencies (WAR and WAW), motivated the development of more advanced dynamic scheduling techniques. This final practice [@problem_id:3638623] explores the most important of these: register renaming. You will first analyze a loop to see how name dependencies constrain performance, then calculate the theoretical improvement when register renaming eliminates these hazards, leaving only the true flow of data to dictate the schedule.", "problem": "A central processing unit (CPU) implements a classic scoreboard with in-order issue, out-of-order read and write, and the following properties. An instruction goes through four conceptual stages: Issue, Read Operands, Execute, and Write Result. The scoreboard enforces hazards as follows: at Issue, it prevents write-after-write (WAW) hazards by disallowing multiple active writers to the same architectural register; at Read Operands, it prevents read-after-write (RAW) hazards by delaying operand reads until the most recent earlier producer of each source register has written its result; at Write Result, it prevents write-after-read (WAR) hazards by delaying a write until all earlier instructions that read that register have performed their reads. Functional unit availability is tracked; each instruction must acquire a functional unit at Issue. Assume fully pipelined functional units with fixed execution latencies and no structural conflicts on the register file or writeback ports beyond what the scoreboard already models.\n\nConsider the infinite-loop microbenchmark consisting of the iteration body of three instructions:\n- $I_1$: $R_1 \\leftarrow R_2 + R_3$ (uses the adder),\n- $I_2$: $R_2 \\leftarrow R_1 + R_4$ (uses the adder),\n- $I_3$: $R_3 \\leftarrow R_2 \\times R_5$ (uses the multiplier),\n\nwhere $R_4$ and $R_5$ are loop-invariant. The adder has an execution latency of $L_A$ cycles and the multiplier has an execution latency of $L_M$ cycles. An instruction’s result becomes available to dependent consumers in the cycle immediately following the completion of its execution latency. Assume that the loop is scheduled so that in each iteration the three instructions appear in the program order $I_1$, $I_2$, $I_3$, and that there are no other instructions in the loop.\n\nTasks:\n- Starting from the fundamental definitions of data dependences and hazards (RAW, WAR, WAW), construct the dependence relations within a single iteration and the loop-carried dependences across successive iterations. Explain why, under a scoreboard without register renaming (register renaming (RR) being the dynamic mapping of architectural registers to distinct physical registers to eliminate false dependences), these relations create a directed cycle that forces serial initiation of iterations, even though functional units are fully pipelined.\n- Then, assuming ideal register renaming that eliminates all anti-dependences (WAR) and output dependences (WAW) while preserving true data dependences (RAW), derive from first principles the minimum steady-state initiation interval, measured in cycles per iteration, that the loop can achieve as a function of $L_A$ and $L_M$.\n- Finally, evaluate your expression for $L_A = 2$ and $L_M = 4$ and report the steady-state initiation interval as a single number. Express your final answer as the number of cycles per iteration (no units). No rounding is required.", "solution": "The user-provided problem is a valid exercise in computer architecture, specifically concerning the performance analysis of a dynamic scheduling processor with a scoreboard. All provided information is self-contained, consistent, and scientifically grounded in established principles of processor design. We can therefore proceed with a full solution.\n\nThe analysis is divided into three parts as requested: first, an examination of the loop execution without register renaming; second, the derivation of the minimum initiation interval with ideal register renaming; and third, a numerical evaluation of the result.\n\n### Part 1: Analysis without Register Renaming\n\nA data dependence exists between two instructions when they access the same memory location or register, and at least one of the accesses is a write. There are three types of data dependences:\n1.  Read-After-Write (RAW), or true dependence: An instruction reads a location after a prior instruction writes to it. E.g., $I_i: R_x \\leftarrow \\dots; \\dots; I_j: \\dots \\leftarrow R_x + \\dots$.\n2.  Write-After-Read (WAR), or anti-dependence: An instruction writes to a location after a prior instruction reads from it. E.g., $I_i: \\dots \\leftarrow R_x + \\dots; \\dots; I_j: R_x \\leftarrow \\dots$.\n3.  Write-After-Write (WAW), or output dependence: An instruction writes to a location after a prior instruction also writes to it. E.g., $I_i: R_x \\leftarrow \\dots; \\dots; I_j: R_x \\leftarrow \\dots$.\n\nRAW dependences represent the true flow of data. WAR and WAW dependences are \"false\" or \"name\" dependences, as they arise from the re-use of a finite number of architectural register names, not from a need for data to flow between instructions.\n\nLet $I_j^k$ denote instruction $I_j$ in iteration $k$. The instructions are:\n- $I_1^k: R_1 \\leftarrow R_2 + R_3$\n- $I_2^k: R_2 \\leftarrow R_1 + R_4$\n- $I_3^k: R_3 \\leftarrow R_2 \\times R_5$\n\n**Dependences within a single iteration ($k$):**\n-   $I_1^k \\xrightarrow{\\text{RAW}, R_1} I_2^k$: $I_2^k$ reads $R_1$ after $I_1^k$ writes it.\n-   $I_2^k \\xrightarrow{\\text{RAW}, R_2} I_3^k$: $I_3^k$ reads $R_2$ after $I_2^k$ writes it.\n-   $I_1^k \\xrightarrow{\\text{WAR}, R_2} I_2^k$: $I_2^k$ writes $R_2$ after $I_1^k$ reads it.\n-   $I_1^k \\xrightarrow{\\text{WAR}, R_3} I_3^k$: $I_3^k$ writes $R_3$ after $I_1^k$ reads it.\n\n**Loop-carried dependences (from iteration $k$ to $k+1$):**\nThe values of registers $R_2$ and $R_3$ read by $I_1^{k+1}$ are those produced in iteration $k$.\n-   $I_2^k \\xrightarrow{\\text{RAW}, R_2} I_1^{k+1}$: $I_1^{k+1}$ reads the value of $R_2$ produced by $I_2^k$.\n-   $I_3^k \\xrightarrow{\\text{RAW}, R_3} I_1^{k+1}$: $I_1^{k+1}$ reads the value of $R_3$ produced by $I_3^k$.\n\nFalse dependences also exist across iterations due to the reuse of register names $R_1, R_2, R_3$.\n-   $I_j^k \\xrightarrow{\\text{WAW}, R_j} I_j^{k+1}$ for $j \\in \\{1, 2, 3\\}$. For example, both $I_2^k$ and $I_2^{k+1}$ write to $R_2$.\n-   $I_1^{k+1} \\xrightarrow{\\text{WAR}, R_2} I_2^{k+1}$: $I_2^{k+1}$ writes to $R_2$, which was read by the earlier instruction $I_1^{k+1}$.\n-   $I_1^{k+1} \\xrightarrow{\\text{WAR}, R_3} I_3^{k+1}$: $I_3^{k+1}$ writes to $R_3$, which was read by the earlier instruction $I_1^{k+1}$.\n\nThe classic scoreboard serializes iterations due to the interaction of these dependences. Let's focus on register $R_2$ as an example. A directed cycle of constraints is formed:\n1.  **RAW Hazard**: $I_2^k \\xrightarrow{\\text{RAW}, R_2} I_1^{k+1}$. The scoreboard will stall the Read Operands stage of $I_1^{k+1}$ until $I_2^k$ completes its Write Result stage. Let's denote stage `S` of instruction $I$ as $S(I)$. This means $RO(I_1^{k+1})$ must happen after $WB(I_2^k)$.\n2.  **WAR Hazard**: $I_1^{k+1} \\xrightarrow{\\text{WAR}, R_2} I_2^{k+1}$. The scoreboard will delay the Write Result stage of $I_2^{k+1}$ until the earlier instruction $I_1^{k+1}$ has completed its Read Operands stage. This means $WB(I_2^{k+1})$ must happen after $RO(I_1^{k+1})$.\n3.  **WAW Hazard**: $I_2^k \\xrightarrow{\\text{WAW}, R_2} I_2^{k+1}$. The scoreboard will stall the Issue stage of $I_2^{k+1}$ until $I_2^k$ is no longer an active writer, which means $I_2^k$ must complete its Write Result stage. This means $Issue(I_2^{k+1})$ must happen after $WB(I_2^k)$.\n\nCombining these constraints, we have a chain: $WB(I_2^k)$ enables $Issue(I_2^{k+1})$ to proceed, and it also enables $RO(I_1^{k+1})$. The completion of $RO(I_1^{k+1})$ in turn enables $WB(I_2^{k+1})$. The execution of $I_2^{k+1}$ is therefore tightly constrained by the completion of $I_2^k$ and the progress of $I_1^{k+1}$. A similar cycle exists for register $R_3$. The net effect of these inter-iteration RAW, WAR, and WAW hazards on the same register names is that iteration $k+1$ cannot substantially overlap with iteration $k$. The start of iteration $k+1$ is dependent on the completion of iteration $k$, forcing serial initiation of iterations.\n\n### Part 2: Analysis with Ideal Register Renaming\n\nIdeal register renaming eliminates all WAR and WAW hazards by dynamically mapping architectural registers to a large pool of physical registers. This leaves only the true data (RAW) dependences. The minimum steady-state initiation interval, $II$, is the time between the start of successive loop iterations. It is constrained by two factors: recurrences in the dataflow graph ($II_{rec}$) and hardware resource limitations ($II_{res}$). The achievable $II$ is the maximum of these two lower bounds: $II = \\max(II_{rec}, II_{res})$.\n\n**Recurrence-Constrained Minimum Initiation Interval ($II_{rec}$):**\nWe analyze the RAW dependences to find loops in the dependence graph that cross iteration boundaries. Let $S_j(k)$ be the start-of-execution time for instruction $I_j$ in iteration $k$. An instruction's result is available after its latency. The start time of a dependent instruction must be greater than or equal to the time the needed result is available.\nThe RAW dependences give the following inequalities:\n1.  $S_2(k) \\ge S_1(k) + L_A$\n2.  $S_3(k) \\ge S_2(k) + L_A$\n3.  $S_1(k+1) \\ge S_2(k) + L_A$\n4.  $S_1(k+1) \\ge S_3(k) + L_M$\n\nTo find the minimum $II$, we look for the tightest constraint. We can combine these inequalities to find the longest dependence path that forms a recurrence.\nFrom (4), we have the start of $I_1$ in iteration $k+1$ depending on the completion of $I_3$ in iteration $k$.\n$$ S_1(k+1) \\ge S_3(k) + L_M $$\nSubstitute (2) into this expression:\n$$ S_1(k+1) \\ge (S_2(k) + L_A) + L_M $$\nSubstitute (1) into this expression:\n$$ S_1(k+1) \\ge ( (S_1(k) + L_A) + L_A ) + L_M $$\n$$ S_1(k+1) \\ge S_1(k) + 2L_A + L_M $$\nThis inequality traces the critical recurrence path: $I_1^k \\xrightarrow{} I_2^k \\xrightarrow{} I_3^k \\xrightarrow{} I_1^{k+1}$.\nIn steady state, the time between the start of the same instruction in consecutive iterations is the initiation interval, $II$. Thus, $S_1(k+1) = S_1(k) + II$. Substituting this into the inequality gives:\n$$ S_1(k) + II \\ge S_1(k) + 2L_A + L_M $$\n$$ II \\ge 2L_A + L_M $$\nThis establishes the recurrence-constrained lower bound: $II_{rec} = 2L_A + L_M$.\n\n**Resource-Constrained Minimum Initiation Interval ($II_{res}$):**\nThis bound is determined by the demand for each type of functional unit. The functional units are fully pipelined, meaning they can accept a new operation on every clock cycle.\n-   **Adder:** Used by $I_1$ and $I_2$. This is $2$ uses per iteration. With $1$ adder unit, the minimum interval required to service these requests is $II_{res}(\\text{adder}) = \\frac{2 \\text{ uses}}{1 \\text{ unit}} = 2$ cycles per iteration.\n-   **Multiplier:** Used by $I_3$. This is $1$ use per iteration. With $1$ multiplier unit, the minimum interval is $II_{res}(\\text{multiplier}) = \\frac{1 \\text{ use}}{1 \\text{ unit}} = 1$ cycle per iteration.\n\nThe overall resource-constrained MII is the maximum over all resource types:\n$$ II_{res} = \\max(2, 1) = 2 $$\n\n**Minimum Initiation Interval ($II$):**\nThe achievable initiation interval is the maximum of the recurrence and resource constraints.\n$$ II = \\max(II_{rec}, II_{res}) = \\max(2L_A + L_M, 2) $$\nSince the execution latencies $L_A$ and $L_M$ are positive integers (at least $1$), the term $2L_A + L_M$ will be at least $2(1) + 1 = 3$. Therefore, the recurrence is always the limiting factor.\n$$ II = 2L_A + L_M $$\n\n### Part 3: Numerical Evaluation\n\nWe are given the latencies $L_A = 2$ cycles and $L_M = 4$ cycles. Substituting these values into our derived expression for the minimum initiation interval:\n$$ II = 2(2) + 4 $$\n$$ II = 4 + 4 $$\n$$ II = 8 $$\nThe minimum steady-state initiation interval is $8$ cycles per iteration.", "answer": "$$\\boxed{8}$$", "id": "3638623"}]}