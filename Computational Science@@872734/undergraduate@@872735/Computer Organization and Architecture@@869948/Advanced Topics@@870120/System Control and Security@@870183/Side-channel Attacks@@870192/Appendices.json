{"hands_on_practices": [{"introduction": "Side-channel attacks often depend on measuring incredibly small timing differences, such as the delay from a single extra cache miss. These time differences, often denoted by a variable like $\\delta$, can be much smaller than the resolution, $\\Delta$, of the timers available to an attacker. This practice [@problem_id:3676151] explores the fundamental technique of signal amplification, where an operation is repeated many times to make a minuscule timing effect accumulate until it becomes reliably measurable, thereby overcoming hardware limitations.", "problem": "An attacker is mounting a timing side-channel attack on a Central Processing Unit (CPU) by measuring the time of a code path that may include exactly one extra Last-Level Cache (LLC) miss. The one-miss penalty adds a small true-time increment of size $\\delta$ to the execution time relative to a miss-free baseline, with $\\delta \\ll \\Delta$. The available timer has finite resolution $\\Delta$: any true elapsed time $T$ is returned as the largest multiple of $\\Delta$ not exceeding $T$.\n\nThe attacker can amplify the timing difference by repeating the same measurement-sensitive operation back-to-back $R$ times and then reading the timer once, both for the baseline path and for the path that incurs one extra miss per operation. Assume all other noise sources are negligible compared to quantization due to the timer resolution, and that the true per-operation miss penalty $\\delta$ is constant and independent across repetitions.\n\nStarting only from the following fundamental bases:\n- If a single operation exhibits a true-time difference of $\\delta$ between two conditions, $R$ identical back-to-back repetitions exhibit a true-time difference of $R \\delta$ between those conditions.\n- The timer returns measured time $M(T) = \\Delta \\left\\lfloor \\frac{T}{\\Delta} \\right\\rfloor$ for a true time $T$, where $\\left\\lfloor \\cdot \\right\\rfloor$ is the floor function.\n\nDerive a condition on $R$ that guarantees the two measured times (baseline versus one-miss-per-operation) will be different for any possible alignment of the true time within a quantization bin. Then, determine the minimal integer $R$ that satisfies this condition. Express your final answer as a single closed-form analytical expression in terms of $\\Delta$ and $\\delta$.", "solution": "The problem requires the derivation of a condition on the number of repetitions, $R$, that guarantees a measurable timing difference, and from this, the minimal integer value of $R$. The analysis will proceed from the fundamental definitions provided.\n\nFirst, let us define the true execution times. Let $T_{0}$ be the true execution time of the baseline (miss-free) operation.\nThe true execution time for $R$ repetitions of the baseline path is:\n$$T_{base} = R T_{0}$$\n\nThe path with one extra miss per operation has a true execution time of $T_{0} + \\delta$ for a single operation. For $R$ back-to-back repetitions, the true execution time is:\n$$T_{miss} = R (T_{0} + \\delta) = R T_{0} + R \\delta$$\n\nThe timer has a finite resolution $\\Delta$. The measured time $M$ for a true time $T$ is given by the function:\n$$M(T) = \\Delta \\left\\lfloor \\frac{T}{\\Delta} \\right\\rfloor$$\nwhere $\\lfloor \\cdot \\rfloor$ is the floor function.\n\nApplying this to our two scenarios, the measured time for the baseline path is:\n$$M_{base} = M(T_{base}) = \\Delta \\left\\lfloor \\frac{R T_{0}}{\\Delta} \\right\\rfloor$$\n\nThe measured time for the path with misses is:\n$$M_{miss} = M(T_{miss}) = \\Delta \\left\\lfloor \\frac{R T_{0} + R \\delta}{\\Delta} \\right\\rfloor$$\n\nThe objective is to find a condition on $R$ that guarantees $M_{miss} \\neq M_{base}$ for any possible value of $T_{0}$. Since the miss penalty $\\delta$ is a positive time increment, $T_{miss} > T_{base}$. Consequently, the measured time cannot decrease, so $M_{miss} \\ge M_{base}$. The condition for the measured times to be different is therefore equivalent to requiring $M_{miss} > M_{base}$.\n\n$$ \\Delta \\left\\lfloor \\frac{R T_{0} + R \\delta}{\\Delta} \\right\\rfloor > \\Delta \\left\\lfloor \\frac{R T_{0}}{\\Delta} \\right\\rfloor $$\n\nDividing by $\\Delta$ (which is a positive time quantity) preserves the inequality:\n$$ \\left\\lfloor \\frac{R T_{0}}{\\Delta} + \\frac{R \\delta}{\\Delta} \\right\\rfloor > \\left\\lfloor \\frac{R T_{0}}{\\Delta} \\right\\rfloor $$\n\nLet us introduce the dimensionless variables $x = \\frac{R T_{0}}{\\Delta}$ and $y = \\frac{R \\delta}{\\Delta}$. The required condition becomes:\n$$ \\lfloor x + y \\rfloor > \\lfloor x \\rfloor $$\nThis inequality must hold for any value of $x \\ge 0$, because the baseline time $T_{0}$ is unknown and can result in any \"alignment of the true time within a quantization bin\". The variable $x$ represents this alignment, scaled by the number of repetitions $R$.\n\nThe inequality $\\lfloor x + y \\rfloor > \\lfloor x \\rfloor$ fails to hold if and only if there is no integer in the interval $(x, x+y]$. This situation, $\\lfloor x+y \\rfloor = \\lfloor x \\rfloor$, poses the greatest challenge to the attacker. We need to find a condition on $y$ (and thus on $R$) that prevents this equality from being possible for any $x$.\n\nThe worst-case scenario for distinguishing the times occurs when the baseline true time $T_{base}$ (and thus $x$) is positioned such that the addition of the amplified penalty $R\\delta$ (and thus $y$) is least likely to cross an integer boundary of the timer resolution. This happens when the baseline time $T_{base}$ is just slightly greater than a multiple of $\\Delta$.\n\nLet us formalize this. Let $k = \\lfloor x \\rfloor$ be an integer. The value of $x$ can be written as $x = k + \\epsilon$, where $0 \\le \\epsilon < 1$. The variable $\\epsilon$ represents the fractional part of $x$, corresponding to the alignment within a timer quantization interval. The problem states that this must hold for *any* possible alignment, so we must consider all possible values of $\\epsilon \\in [0, 1)$.\n\nThe inequality becomes:\n$$ \\lfloor k + \\epsilon + y \\rfloor > \\lfloor k + \\epsilon \\rfloor $$\nSince $k$ is an integer and $0 \\le \\epsilon < 1$, we have $\\lfloor k + \\epsilon \\rfloor = k$. The condition is:\n$$ \\lfloor k + \\epsilon + y \\rfloor > k $$\nThis is equivalent to requiring:\n$$ k + \\epsilon + y \\ge k+1 $$\n$$ \\epsilon + y \\ge 1 $$\n\nThis inequality, $y \\ge 1 - \\epsilon$, must be satisfied for all possible values of $\\epsilon \\in [0, 1)$. To guarantee this, we must satisfy the inequality for the \"worst-case\" value of $\\epsilon$, which is the value that makes the condition hardest to meet. The right-hand side, $1-\\epsilon$, is maximized when $\\epsilon$ is minimized. The lower bound of $\\epsilon$ is $0$. To ensure the condition holds for an arbitrarily small positive $\\epsilon$, we must consider the limit as $\\epsilon \\to 0^{+}$.\nIn this limit, the condition becomes:\n$$ y \\ge 1 $$\n\nSubstituting back $y = \\frac{R\\delta}{\\Delta}$:\n$$ \\frac{R\\delta}{\\Delta} \\ge 1 $$\n$$ R\\delta \\ge \\Delta $$\n\nThis is the general condition on $R$ that guarantees the measured times will be different, regardless of the initial timing alignment. The total amplified time difference, $R\\delta$, must be at least as large as a single timer resolution interval, $\\Delta$.\n\nThe final step is to determine the minimal *integer* $R$ that satisfies this condition. From the inequality $R\\delta \\ge \\Delta$, we can isolate $R$:\n$$ R \\ge \\frac{\\Delta}{\\delta} $$\nSince $R$ must be an integer, the smallest integer value of $R$ that satisfies this inequality is the ceiling of the ratio $\\frac{\\Delta}{\\delta}$. The ceiling function $\\lceil z \\rceil$ gives the smallest integer greater than or equal to $z$.\n\nTherefore, the minimal integer number of repetitions is:\n$$ R_{min} = \\left\\lceil \\frac{\\Delta}{\\delta} \\right\\rceil $$\nThis expression is the complete and final analytical solution for the minimal integer $R$. The initial condition $\\delta \\ll \\Delta$ from the problem statement implies that $\\frac{\\Delta}{\\delta} \\gg 1$, confirming that a significant number of repetitions is indeed necessary for the attack to succeed, which is consistent with the premise of amplifying a small signal.", "answer": "$$\\boxed{\\left\\lceil \\frac{\\Delta}{\\delta} \\right\\rceil}$$", "id": "3676151"}, {"introduction": "Now that we understand how to measure small timing variations, we can explore how these measurements can leak secret information from cryptographic components. A classic target is a lookup table, such as an S-box, where the memory access pattern is determined by a secret key. This exercise [@problem_id:3676164] connects the physical organization of computer architecture to the abstract realm of information theory by tasking you to analyze how the mapping of memory addresses to cache lines creates an observable signal, and then use Shannon entropy to precisely quantify how many bits of a secret key are leaked by this channel.", "problem": "A single-byte substitution box (S-box) with $256$ entries is stored contiguously in memory and aligned to a $64$-byte boundary. Each entry has size $e$ bytes, where $e$ is a power of two with $1 \\leq e \\leq 64$, and the table occupies exactly $256e$ bytes. The central processing unit (CPU) cache has a cache line size of $64$ bytes. Assume that each S-box lookup accesses exactly one cache line and that there are no hardware features (such as prefetching) that would fetch unrelated lines.\n\nA single secret key byte $k \\in \\{0,1,\\dots,255\\}$ is used to form the S-box index $i = p \\oplus k$, where $\\oplus$ denotes bitwise exclusive OR, and $p$ is a known plaintext byte provided by the attacker. The attacker can perform $m \\geq 1$ chosen-plaintext queries with plaintext bytes $p_{1},\\dots,p_{m}$ and, for each query, can observe only the cache line index $\\ell \\in \\{0,1,\\dots,L-1\\}$ accessed by the S-box lookup, where $L$ is the number of cache lines spanned by the table.\n\nStarting from first principles in computer organization relevant to caches and memory addressing, answer the following:\n\n1. Derive the set of S-box indices $i$ that map to a given cache line index $\\ell$. Express your derivation in terms of $e$, $64$, and $\\ell$ without using any shortcut formulas.\n\n2. Under a uniform prior for $k$ over $\\{0,\\dots,255\\}$ and assuming $m \\geq 1$ observations with known $p_{j}$, quantify the remaining uncertainty about $k$ after these observations by computing the Shannon entropy of the posterior in bits. Express your final result as a closed-form expression in terms of $e$. Do not round; express the result in bits.", "solution": "This problem is divided into two parts. First, we must derive the relationship between an S-box index and its corresponding cache line index. Second, we must use this relationship to quantify the information leaked about a secret key, using Shannon entropy.\n\n### Part 1: Derivation of S-box Indices per Cache Line\n\nWe are given an S-box table with $256$ entries, stored contiguously in memory. The table's starting address is aligned to a $64$-byte boundary. Let the base address of the S-box table be $A_{\\text{base}}$. The alignment condition means that $A_{\\text{base}}$ is a multiple of $64$. Mathematically, $A_{\\text{base}} \\pmod{64} = 0$.\n\nEach entry in the S-box has a size of $e$ bytes. The S-box is indexed by $i \\in \\{0, 1, \\dots, 255\\}$. The memory address of the first byte of the entry for index $i$ is given by:\n$$A_i = A_{\\text{base}} + i \\cdot e$$\nThe CPU cache has a line size of $C_S = 64$ bytes. A memory address $A$ is mapped to a physical cache line. The index of the cache line containing address $A$ is $\\lfloor A / C_S \\rfloor = \\lfloor A / 64 \\rfloor$.\n\nThe problem states that the attacker observes a relative cache line index $\\ell$. This is the index of the cache line relative to the start of the S-box table. The first cache line occupied by the table has the absolute index $\\lfloor A_{\\text{base}} / 64 \\rfloor$. Since $A_{\\text{base}}$ is a multiple of $64$, lets say $A_{\\text{base}} = 64 \\cdot N$ for some integer $N$, this index is simply $N$.\n\nThe absolute cache line index for the memory address $A_i$ is $\\lfloor A_i / 64 \\rfloor$. The relative index $\\ell$ is the difference between this and the base index:\n$$\\ell = \\lfloor \\frac{A_i}{64} \\rfloor - \\lfloor \\frac{A_{\\text{base}}}{64} \\rfloor$$\nSubstituting the expressions for $A_i$ and $A_{\\text{base}}$:\n$$\\ell = \\left\\lfloor \\frac{64 \\cdot N + i \\cdot e}{64} \\right\\rfloor - \\left\\lfloor \\frac{64 \\cdot N}{64} \\right\\rfloor$$\nUsing the property of the floor function $\\lfloor x+k \\rfloor = \\lfloor x \\rfloor + k$ for any integer $k$:\n$$\\ell = \\left\\lfloor \\frac{i \\cdot e}{64} + N \\right\\rfloor - N = \\left\\lfloor \\frac{i \\cdot e}{64} \\right\\rfloor + N - N = \\left\\lfloor \\frac{i \\cdot e}{64} \\right\\rfloor$$\nThis equation provides the mapping from an S-box index $i$ to the observed relative cache line index $\\ell$.\n\nTo find the set of S-box indices $i$ that map to a given cache line index $\\ell$, we must solve this equation for $i$. From the definition of the floor function, the equation $\\ell = \\lfloor x \\rfloor$ is equivalent to the inequality $\\ell \\le x < \\ell + 1$. Applying this to our equation:\n$$\\ell \\le \\frac{i \\cdot e}{64} < \\ell + 1$$\nTo isolate $i$, we multiply the inequality by $64/e$:\n$$\\frac{64\\ell}{e} \\le i < \\frac{64(\\ell+1)}{e}$$\nSince $i$ must be an integer and is restricted to the range $\\{0, 1, \\dots, 255\\}$, the set of S-box indices $S_\\ell$ that map to a specific cache line index $\\ell$ is:\n$$S_\\ell = \\left\\{ i \\in \\{0, 1, \\dots, 255\\} \\, \\middle| \\, \\frac{64\\ell}{e} \\le i < \\frac{64(\\ell+1)}{e} \\right\\}$$\nThe number of S-box indices per cache line is constant for all $\\ell$ and is equal to $\\frac{64(\\ell+1)}{e} - \\frac{64\\ell}{e} = \\frac{64}{e}$. Let us denote this quantity by $N_C = \\frac{64}{e}$. Since $e$ is a power of two and $1 \\le e \\le 64$, $N_C$ is also a power of two and $1 \\le N_C \\le 64$. The set of indices can thus be written as $\\{i \\mid \\ell N_C \\le i < (\\ell+1)N_C\\}$.\n\n### Part 2: Quantifying Remaining Uncertainty\n\nThe attacker performs a chosen-plaintext attack. For a chosen plaintext $p$, the S-box index is $i = p \\oplus k$, where $k$ is the secret key. The attacker observes the cache line index $\\ell = \\lfloor (p \\oplus k) \\cdot e / 64 \\rfloor$. This observation reveals which set $S_\\ell$ the value $p \\oplus k$ belongs to.\n\nThe condition $i \\in S_\\ell$ is equivalent to $\\lfloor i/N_C \\rfloor = \\ell$, where $N_C = 64/e$. As established, $N_C$ is a power of two. Let $N_C = 2^n$. The operation $i \\to \\lfloor i/2^n \\rfloor$ is equivalent to an arithmetic right shift of the $8$-bit integer $i$ by $n$ positions. This operation effectively extracts the most significant $8-n$ bits of $i$. The bottom $n$ bits of $i$ are discarded.\n\nTherefore, observing $\\ell$ for the index $i=p \\oplus k$ is equivalent to learning the most significant $8-n$ bits of the value $p \\oplus k$.\nThe bitwise XOR operation has no carries, meaning each bit of the result $p \\oplus k$ depends only on the corresponding bits of $p$ and $k$. Let $x_{MSB}$ and $x_{LSB}$ denote the most significant $8-n$ bits and least significant $n$ bits of an $8$-bit value $x$, respectively. Then:\n$$(p \\oplus k)_{MSB} = p_{MSB} \\oplus k_{MSB}$$\n$$(p \\oplus k)_{LSB} = p_{LSB} \\oplus k_{LSB}$$\nThe attacker observes $(p \\oplus k)_{MSB}$. Since the attacker chose $p$, they know $p_{MSB}$. Thus, they can compute the most significant $8-n$ bits of the secret key:\n$$k_{MSB} = (p \\oplus k)_{MSB} \\oplus p_{MSB}$$\nA single observation with any known $p$ is sufficient to determine $k_{MSB}$. Any further observations with other plaintexts $p_j$ will only reconfirm this same information about $k_{MSB}$.\n\nCritically, the observation provides no information whatsoever about the least significant $n$ bits of the key, $k_{LSB}$. The prior distribution for $k$ is uniform over all $256$ possibilities, which implies each of the $8$ bits of $k$ is an independent and uniformly random binary digit. After the attack, the top $8-n$ bits are known, but the bottom $n$ bits remain completely unknown and are still uniformly distributed.\n\nThe set of possible keys is reduced to those that share the determined $k_{MSB}$. Since there are $n$ unknown bits in $k_{LSB}$, there are $2^n$ possible keys remaining. The posterior probability distribution is uniform over this set of $2^n$ keys. The probability of each of these remaining keys is $P(k) = 1/2^n$.\n\nThe Shannon entropy of the posterior distribution of the key $K$ is given by $H(K) = -\\sum_{k} P(k) \\log_2 P(k)$. For our uniform distribution over $2^n$ outcomes:\n$$H(K) = - \\sum_{j=1}^{2^n} \\frac{1}{2^n} \\log_2\\left(\\frac{1}{2^n}\\right) = - 2^n \\cdot \\frac{1}{2^n} \\log_2(2^{-n}) = - (-n) = n$$\nThe remaining uncertainty is $n$ bits. We must express this in terms of the given parameter $e$. We have the relation $N_C = 2^n$, and $N_C=64/e$.\n$$2^n = \\frac{64}{e}$$\nTaking the base-$2$ logarithm of both sides:\n$$n = \\log_2\\left(\\frac{64}{e}\\right) = \\log_2(64) - \\log_2(e) = \\log_2(2^6) - \\log_2(e) = 6 - \\log_2(e)$$\nThus, the remaining uncertainty about the key $k$, quantified by the Shannon entropy of its posterior distribution, is $6 - \\log_2(e)$ bits.", "answer": "$$\n\\boxed{6 - \\log_{2}(e)}\n$$", "id": "3676164"}, {"introduction": "Understanding attacks is critical, but the ultimate goal is to build secure systems, which requires both designing defenses and verifying their effectiveness. This involves implementing \"constant-time\" code that avoids secret-dependent branches or memory accesses, and then rigorously testing that the implementation is free from subtle information leakage. In this final practice [@problem_id:3676135], you will compare a vulnerable table-based implementation with a protected bit-sliced one, reasoning about their microarchitectural leakage and considering how to empirically test for any residual leakage using statistical methods, a crucial skill in modern security engineering.", "problem": "An implementer is comparing two Advanced Encryption Standard (AES) SubBytes designs on a modern out-of-order superscalar core with private instruction and data caches, fixed frequency, and no simultaneous multithreading. Implementation $\\mathrm{I}_{\\mathrm{TBL}}$ uses a $256$-entry lookup table indexed by the secret byte, with straight-line code and no conditional branches. Implementation $\\mathrm{I}_{\\mathrm{BIT}}$ is a bit-sliced realization that computes the same mapping using only boolean operations on registers with no secret-dependent control flow and no secret-dependent memory addresses; round keys are loaded from fixed addresses. Before each run the caches are invalidated. An attacker can collect per-invocation traces consisting of wall-clock cycles, selected hardware performance counters (e.g., data-cache misses, branch mispredictions, and per-port micro-operation issue counts), and the input class label. The attacker cannot measure power or electromagnetic emanations directly. The goal is to reason, from first principles, which microarchitectural effects can still produce secret-dependent timing or counter variation in $\\mathrm{I}_{\\mathrm{BIT}}$ compared to $\\mathrm{I}_{\\mathrm{TBL}}$, and how to empirically estimate a residual leakage metric $\\ell$ from the collected traces.\n\nUse only core definitions of side-channel leakage and well-established facts about microarchitectural variability as the starting point: secret-dependent memory addresses can induce variable-latency cache behavior, mispredicted branches incur penalties, and execution ports schedule micro-operations based on the instruction mix. Reason about whether these effects can create secret-correlated observables in each implementation under the stated conditions.\n\nWhich of the following statements are correct?\n\nA. In $\\mathrm{I}_{\\mathrm{TBL}}$, data-cache behavior is secret-dependent because table indices are secret, so hits and misses (and thus total cycles) correlate with the secret even without branches. In $\\mathrm{I}_{\\mathrm{BIT}}$, eliminating secret-dependent memory addresses and branches removes cache- and branch-based timing leakage; execution-port contention does not leak secrets if the instruction mix is independent of the secret. To estimate $\\ell$, collect two populations of traces (fixed secret versus random secret) and apply a two-sample statistical test on features such as cycles and miss counts; a large absolute test statistic indicates leakage.\n\nB. In $\\mathrm{I}_{\\mathrm{BIT}}$, the instruction-cache still leaks the secret because instruction fetch addresses depend on secret-driven branch targets. Estimating $\\ell$ by comparing only the average cycles between fixed and random secrets is sufficient; no statistical test is needed.\n\nC. In $\\mathrm{I}_{\\mathrm{TBL}}$, caches do not leak because the table is small enough to reside in the data cache, so hits are guaranteed. In $\\mathrm{I}_{\\mathrm{BIT}}$, boolean operations have data-dependent latency that changes execution-port usage, creating a secret-dependent timing channel. The most direct way to estimate $\\ell$ is to count branch mispredictions.\n\nD. In $\\mathrm{I}_{\\mathrm{BIT}}$ under the stated conditions, the only remaining leakage sources are power or electromagnetic switching activity in the datapath, not cache, branch, or port timing; therefore $\\ell$ cannot be detected with timing or hardware counters and must be estimated from power traces.\n\nE. Under the stated single-thread, fixed-frequency conditions, $\\mathrm{I}_{\\mathrm{BIT}}$ removes secret-dependent cache and branch effects, and its execution-port usage is secret-invariant if the instruction sequence is fixed. An empirical way to estimate $\\ell$ from the available traces is to compute a mutual information estimate between a chosen secret feature (e.g., a bit of the secret byte) and the vector of timing and counter measurements; a nonzero estimate indicates measurable leakage.", "solution": "### Derivation from First Principles\n\nThe analysis will proceed by examining the microarchitectural behavior of each implementation based on the provided descriptions.\n\n**Analysis of Implementation $\\mathrm{I}_{\\mathrm{TBL}}$**\n\nThis implementation uses a lookup table indexed by a secret byte. Let the base address of the table be $A_{base}$ and the secret byte be $S$. A memory access will be made to an address $A_{mem} = A_{base} + S$.\n1.  **Data Cache Behavior:** The memory access address $A_{mem}$ is directly dependent on the secret value $S$. Although the problem states caches are invalidated before each run, this does not eliminate leakage. On the contrary, it makes the first access to any cache line a compulsory miss. The $256$-entry table will likely span multiple cache lines (e.g., for $1$-byte entries and $64$-byte cache lines, it occupies $256/64 = 4$ cache lines). The specific cache line fetched into the data cache upon a miss is determined by $S$. This has two consequences:\n    -   The cache set to which the address maps is secret-dependent, which can cause varying contention with other data accesses.\n    -   Subsequent accesses to the S-box within the same cryptographic operation might result in a hit or a miss depending on whether a previous secret byte in the same operation mapped to the same cache line.\n    Thus, the sequence of data cache hits and misses, and consequently the overall execution time, will be correlated with the secret data. This is a classic cache-timing side channel. The `data-cache misses` performance counter would also exhibit secret-dependent behavior.\n2.  **Control Flow:** The implementation is described as \"straight-line code and no conditional branches\". This means there are no secret-dependent branches, so leakage through branch prediction mechanisms is not present.\n\nIn summary, $\\mathrm{I}_{\\mathrm{TBL}}$ is vulnerable to data-cache side-channel attacks.\n\n**Analysis of Implementation $\\mathrm{I}_{\\mathrm{BIT}}$**\n\nThis implementation is designed to be \"constant-time\" by eliminating common sources of leakage.\n1.  **Data Cache Behavior:** It has \"no secret-dependent memory addresses\". This explicitly closes the data-cache timing channel described for $\\mathrm{I}_{\\mathrm{TBL}}$.\n2.  **Control Flow:** It has \"no secret-dependent control flow\". This explicitly closes any channel based on branch timing or branch prediction.\n3.  **Instruction Sequence & Execution Ports:** It uses \"only boolean operations on registers\". This implies a fixed sequence of instructions is executed regardless of the content of the secret data. On a superscalar, out-of-order processor, a fixed instruction sequence translates to a fixed stream of micro-operations ($\\mu$ops) being fed into the scheduler. Given that the instruction mix is constant, the demand for specific execution ports will be statistically invariant with respect to the secret. Therefore, major timing variations due to execution port contention are eliminated.\n4.  **Residual Leakage:** While the primary, high-bandwidth microarchitectural channels are closed, subtle leakages can remain. The actual data values being processed can influence the physical state of the processor. For example, the number of bits that flip on an internal data bus is secret-dependent. This causes variations in instantaneous current draw (power consumption). Such power fluctuations can couple into the chip's power delivery and clock networks, potentially causing minute variations in the propagation delay of signals. These tiny, data-dependent timing variations might be observable in high-precision measurements of the total wall-clock cycles, even if the instruction count and nominal latencies are constant. This is a form of microarchitectural leakage that is physically rooted in power consumption but manifests as timing jitter. The attacker is equipped to measure `wall-clock cycles`, which is the observable for this type of leakage.\n\n**Analysis of Leakage Estimation ($\\ell$)**\n\nThe goal is to empirically estimate a leakage metric $\\ell$ from the collected traces (cycles, counters).\n1.  **Two-Sample Statistical Tests:** A common method for leakage *detection* is Test Vector Leakage Assessment (TVLA). This involves collecting two sets of traces: one for a fixed, known secret and one for random secrets. A statistical test, such as Welch's t-test, is then applied to the two populations of traces. If the test yields a statistic that exceeds a certain confidence threshold (e.g., $|t| > 4.5$), it indicates a statistically significant difference between the two distributions, proving the existence of leakage. The magnitude of the test statistic itself can be used as a proxy for the leakage amount.\n2.  **Information-Theoretic Metrics:** A more formal way to *quantify* leakage is to use information theory. Mutual Information (MI), $I(S; O)$, measures the amount of information that a set of observations $O$ (e.g., timing and counter measurements) reveals about a secret $S$. An estimate of $I(S; O) > 0$ indicates leakage. This can be done by collecting traces for many known values of $S$ and using statistical estimators to compute the MI from the empirical distributions of $S$ and $O$. This is a very general method capable of detecting any statistical dependency, including subtle ones.\n\n### Option-by-Option Analysis\n\n**A. In $\\mathrm{I}_{\\mathrm{TBL}}$, data-cache behavior is secret-dependent because table indices are secret, so hits and misses (and thus total cycles) correlate with the secret even without branches. In $\\mathrm{I}_{\\mathrm{BIT}}$, eliminating secret-dependent memory addresses and branches removes cache- and branch-based timing leakage; execution-port contention does not leak secrets if the instruction mix is independent of the secret. To estimate $\\ell$, collect two populations of traces (fixed secret versus random secret) and apply a two-sample statistical test on features such as cycles and miss counts; a large absolute test statistic indicates leakage.**\n-   The analysis of $\\mathrm{I}_{\\mathrm{TBL}}$ is correct. Secret-dependent indices cause secret-dependent cache access patterns.\n-   The analysis of $\\mathrm{I}_{\\mathrm{BIT}}$ is correct. It correctly identifies that the major known channels (cache, branch) are closed and links the absence of port contention leakage to the secret-invariant instruction mix.\n-   The proposed estimation methodology is a correct description of the TVLA framework, a standard procedure for empirical leakage detection.\n-   **Verdict: Correct**\n\n**B. In $\\mathrm{I}_{\\mathrm{BIT}}$, the instruction-cache still leaks the secret because instruction fetch addresses depend on secret-driven branch targets. Estimating $\\ell$ by comparing only the average cycles between fixed and random secrets is sufficient; no statistical test is needed.**\n-   The first claim is factually incorrect. The problem states $\\mathrm{I}_{\\mathrm{BIT}}$ has \"no secret-dependent control flow,\" meaning instruction fetch addresses are independent of the secret.\n-   The second claim describes a methodologically flawed approach. Simply comparing mean values without a statistical test for significance is not a robust way to detect leakage, as any observed difference could be due to random noise.\n-   **Verdict: Incorrect**\n\n**C. In $\\mathrm{I}_{\\mathrm{TBL}}$, caches do not leak because the table is small enough to reside in the data cache, so hits are guaranteed. In $\\mathrm{I}_{\\mathrm{BIT}}$, boolean operations have data-dependent latency that changes execution-port usage, creating a secret-dependent timing channel. The most direct way to estimate $\\ell$ is to count branch mispredictions.**\n-   The claim about $\\mathrm{I}_{\\mathrm{TBL}}$ is incorrect. A small table size does not prevent leakage, especially since caches are invalidated pre-run, guaranteeing initial misses. The address-to-cache-set mapping is still secret-dependent.\n-   The claim about $\\mathrm{I}_{\\mathrm{BIT}}$ is speculative and generally untrue for simple boolean operations on modern CPUs, which have fixed latencies. Stating this as a definite cause of changing execution-port usage is a strong, likely false claim.\n-   The suggested estimation method (counting branch mispredictions) is irrelevant for $\\mathrm{I}_{\\mathrm{BIT}}$, which has no secret-dependent branches.\n-   **Verdict: Incorrect**\n\n**D. In $\\mathrm{I}_{\\mathrm{BIT}}$ under the stated conditions, the only remaining leakage sources are power or electromagnetic switching activity in the datapath, not cache, branch, or port timing; therefore $\\ell$ cannot be detected with timing or hardware counters and must be estimated from power traces.**\n-   The premise that the primary leakage source is physical (power/EM) is plausible. However, the conclusion that it \"cannot be detected with timing\" is a non-sequitur and incorrect. Data-dependent power variations can couple into the timing domain, creating measurable jitter in execution time (wall-clock cycles). The attacker has access to cycle counts, which is a timing measurement. The statement incorrectly decouples the physical cause from its potential microarchitectural manifestation.\n-   **Verdict: Incorrect**\n\n**E. Under the stated single-thread, fixed-frequency conditions, $\\mathrm{I}_{\\mathrm{BIT}}$ removes secret-dependent cache and branch effects, and its execution-port usage is secret-invariant if the instruction sequence is fixed. An empirical way to estimate $\\ell$ from the available traces is to compute a mutual information estimate between a chosen secret feature (e.g., a bit of the secret byte) and the vector of timing and counter measurements; a nonzero estimate indicates measurable leakage.**\n-   The analysis of $\\mathrm{I}_{\\mathrm{BIT}}$ is correct, summarizing its constant-time properties regarding cache, branch, and execution port usage based on the fixed instruction sequence.\n-   The proposed estimation methodology, using Mutual Information (MI), is a standard, powerful, and information-theoretically sound approach to quantify leakage. It correctly identifies the variables of interest (a secret feature and the measurement vector) and the condition for leakage (a nonzero MI estimate). This method is general enough to capture any form of statistical dependency, including subtle timing variations.\n-   **Verdict: Correct**\n\nBoth statements A and E are correct. They provide sound analyses and describe valid, standard methodologies for evaluating side-channel leakage.", "answer": "$$\\boxed{AE}$$", "id": "3676135"}]}