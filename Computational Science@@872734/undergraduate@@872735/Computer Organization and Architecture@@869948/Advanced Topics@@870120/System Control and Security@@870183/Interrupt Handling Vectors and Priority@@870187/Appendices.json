{"hands_on_practices": [{"introduction": "The efficiency of an interrupt-driven system is fundamentally limited by how quickly it can service each event. This practice breaks down the total time cost of an interrupt into its constituent parts—entry, workload, and exit—allowing you to quantify its impact on performance [@problem_id:3652721]. By analyzing different architectural optimization strategies, you will gain a concrete understanding of how features like tail-chaining or banked registers translate directly into higher event throughput.", "problem": "A Central Processing Unit (CPU) executes a single high-priority Interrupt Service Routine (ISR) in a saturated steady state, meaning interrupts from one device arrive back-to-back with no idle cycles between services. The CPU uses a vectored interrupt scheme through a Programmable Interrupt Controller (PIC) with fixed priorities. The system parameters and microarchitectural costs are as follows:\n\n- Clock frequency: $f_{clk} = 250 \\times 10^{6}\\,\\text{Hz}$.\n- Baseline interrupt entry sequence costs:\n  - PIC interrupt acknowledge handshake: $3$ cycles.\n  - Priority resolution: $3$ cycles.\n  - Vector fetch from off-chip memory: $1$ bus cycle plus $2$ wait states $\\Rightarrow 3$ cycles total.\n  - Pipeline flush: $5$ cycles.\n  - Save $12$ general-purpose registers, $2$ cycles each: $24$ cycles.\n  - Mode switch to interrupt state: $2$ cycles.\n- Baseline ISR body work for the hot device:\n  - Read status register: $3$ cycles.\n  - Read data register: $3$ cycles.\n  - Write device acknowledge: $3$ cycles.\n  - Arithmetic and logic operations: $4$ cycles.\n  - Conditional branch: $3$ cycles.\n- Baseline interrupt exit sequence costs:\n  - Write End-of-Interrupt (EOI) to PIC: $3$ cycles.\n  - Restore $12$ registers, $2$ cycles each: $24$ cycles.\n  - Return-from-interrupt instruction: $4$ cycles.\n  - Pipeline refill: $5$ cycles.\n\nYou may enable at most one of the following microarchitectural optimization strategies; they do not combine:\n\n- Strategy S1 (vector-cache and priority masking): Eliminate the PIC handshake and off-chip vector fetch; reduce priority resolution to $1$ cycle via masking to a single source; enable auto-EOI in the PIC so that explicit EOI on exit is unnecessary.\n- Strategy S2 (Fast Interrupt Request (FIRQ) with banked registers): Only $4$ registers are saved/restored at $2$ cycles each (banked registers cover the rest); relocate the vector table to on-chip scratchpad for a $1$-cycle vector fetch; other entry and exit activities are unchanged.\n- Strategy S3 (hardware tail-chaining for back-to-back interrupts from the same source): When a new interrupt is pending at exit, hardware bypasses the full exit and next full entry. The steady-state transition from one ISR instance to the next incurs a fixed chain-boundary overhead of $14$ cycles (including $1$ cycle for priority check, $1$ cycle to reuse the same vector, $8$ cycles for minimal pipeline adjustment, and $4$ cycles of housekeeping including EOI). In steady state, the per-event cost is the ISR work plus this chain-boundary overhead.\n\nAssume the system remains continuously saturated by the same high-priority device so that steady-state assumptions apply. Derive the steady-state event rate (events per second) for each strategy from first principles based on $f_{clk}$ and the cycle counts, and then determine the maximum achievable steady-state event rate among S1, S2, and S3. Express the final rate in events per second and round your final reported answer to four significant figures.", "solution": "The problem is valid as it is scientifically grounded in the principles of computer architecture, is well-posed with sufficient and consistent data, and is expressed objectively.\n\nThe objective is to determine the maximum achievable steady-state event rate for a single high-priority interrupt source under three different microarchitectural optimization strategies. The event rate, $R$, is the clock frequency, $f_{clk}$, divided by the total number of clock cycles per event, $T_{total}$.\n$$R = \\frac{f_{clk}}{T_{total}}$$\nThe clock frequency is given as $f_{clk} = 250 \\times 10^{6}\\,\\text{Hz}$. We must calculate $T_{total}$ for each strategy.\n\nFirst, we establish the baseline costs by summing the cycle counts for the three phases of interrupt handling: entry, ISR body work, and exit.\n\nThe total cycles for the ISR body work, $T_{work}$, is constant across all scenarios.\n$T_{work} = (\\text{read status}) + (\\text{read data}) + (\\text{write ack}) + (\\text{ALU ops}) + (\\text{branch})$\n$T_{work} = 3 + 3 + 3 + 4 + 3 = 16$ cycles.\n\nThe baseline entry cost, $T_{entry,base}$, is:\n$T_{entry,base} = (\\text{PIC ack}) + (\\text{prio res}) + (\\text{vector fetch}) + (\\text{pipe flush}) + (\\text{save regs}) + (\\text{mode switch})$\n$T_{entry,base} = 3 + 3 + 3 + 5 + (12 \\times 2) + 2 = 3 + 3 + 3 + 5 + 24 + 2 = 40$ cycles.\n\nThe baseline exit cost, $T_{exit,base}$, is:\n$T_{exit,base} = (\\text{write EOI}) + (\\text{restore regs}) + (\\text{reti}) + (\\text{pipe refill})$\n$T_{exit,base} = 3 + (12 \\times 2) + 4 + 5 = 3 + 24 + 4 + 5 = 36$ cycles.\n\nThe total baseline processing time would be $T_{total,base} = T_{entry,base} + T_{work} + T_{exit,base} = 40 + 16 + 36 = 92$ cycles.\n\nNow, we will analyze each strategy to find its total cycle count per event.\n\n**Strategy S1: Vector-cache and priority masking**\nThis strategy modifies the baseline entry and exit sequences as follows:\n- PIC interrupt acknowledge handshake ($3$ cycles) is eliminated.\n- Priority resolution is reduced from $3$ cycles to $1$ cycle.\n- Off-chip vector fetch ($3$ cycles) is eliminated.\n- Explicit EOI write on exit ($3$ cycles) is eliminated due to auto-EOI.\n\nThe new entry cost, $T_{entry,S1}$, is the baseline entry cost with these modifications.\n$T_{entry,S1} = T_{entry,base} - 3_{\\text{ack}} - (3-1)_{\\text{prio}} - 3_{\\text{vector}} = 40 - 3 - 2 - 3 = 32$ cycles.\nAlternatively, calculating from the remaining components:\n$T_{entry,S1} = 1_{\\text{prio}} + 5_{\\text{flush}} + 24_{\\text{save}} + 2_{\\text{mode}} = 32$ cycles.\n\nThe new exit cost, $T_{exit,S1}$, is the baseline exit cost without the EOI write.\n$T_{exit,S1} = T_{exit,base} - 3_{\\text{EOI}} = 36 - 3 = 33$ cycles.\nAlternatively, calculating from the remaining components:\n$T_{exit,S1} = 24_{\\text{restore}} + 4_{\\text{reti}} + 5_{\\text{refill}} = 33$ cycles.\n\nThe total cycle count for Strategy S1 is:\n$T_{total,S1} = T_{entry,S1} + T_{work} + T_{exit,S1} = 32 + 16 + 33 = 81$ cycles.\n\nThe event rate for Strategy S1 is:\n$R_{S1} = \\frac{f_{clk}}{T_{total,S1}} = \\frac{250 \\times 10^6}{81}$ events/s.\n\n**Strategy S2: Fast Interrupt Request (FIRQ) with banked registers**\nThis strategy modifies the baseline as follows:\n- Only $4$ registers are saved and restored, costing $4 \\times 2 = 8$ cycles each, instead of $12$ registers for $24$ cycles.\n- Vector fetch is from on-chip memory, costing $1$ cycle instead of $3$.\n\nThe new entry cost, $T_{entry,S2}$, is the baseline entry with these changes. The reduction in register save cost is $24 - (4 \\times 2) = 16$ cycles. The reduction in vector fetch cost is $3 - 1 = 2$ cycles.\n$T_{entry,S2} = T_{entry,base} - 16_{\\text{save}} - 2_{\\text{vector}} = 40 - 16 - 2 = 22$ cycles.\nAlternatively, calculating from the components:\n$T_{entry,S2} = 3_{\\text{ack}} + 3_{\\text{prio}} + 1_{\\text{vector}} + 5_{\\text{flush}} + (4 \\times 2)_{\\text{save}} + 2_{\\text{mode}} = 3+3+1+5+8+2 = 22$ cycles.\n\nThe new exit cost, $T_{exit,S2}$, is updated with the reduced register restore cost. The reduction is $24 - (4 \\times 2) = 16$ cycles.\n$T_{exit,S2} = T_{exit,base} - 16_{\\text{restore}} = 36 - 16 = 20$ cycles.\nAlternatively, calculating from the components:\n$T_{exit,S2} = 3_{\\text{EOI}} + (4 \\times 2)_{\\text{restore}} + 4_{\\text{reti}} + 5_{\\text{refill}} = 3+8+4+5 = 20$ cycles.\n\nThe total cycle count for Strategy S2 is:\n$T_{total,S2} = T_{entry,S2} + T_{work} + T_{exit,S2} = 22 + 16 + 20 = 58$ cycles.\n\nThe event rate for Strategy S2 is:\n$R_{S2} = \\frac{f_{clk}}{T_{total,S2}} = \\frac{250 \\times 10^6}{58}$ events/s.\n\n**Strategy S3: Hardware tail-chaining**\nThis strategy is fundamentally different. In a saturated steady state, the hardware bypasses the full exit and entry sequences between interrupts from the same source. The cost per event is the ISR work plus a fixed chain-boundary overhead.\n$T_{overhead,S3} = 14$ cycles.\nThe ISR work remains $T_{work} = 16$ cycles.\n\nThe total cycle count for Strategy S3 is:\n$T_{total,S3} = T_{work} + T_{overhead,S3} = 16 + 14 = 30$ cycles.\n\nThe event rate for Strategy S3 is:\n$R_{S3} = \\frac{f_{clk}}{T_{total,S3}} = \\frac{250 \\times 10^6}{30}$ events/s.\n\n**Comparison of Event Rates**\nNow we compare the three rates to find the maximum.\n$R_{S1} = \\frac{250 \\times 10^6}{81} \\approx 3.086 \\times 10^6$ events/s.\n$R_{S2} = \\frac{250 \\times 10^6}{58} \\approx 4.310 \\times 10^6$ events/s.\n$R_{S3} = \\frac{250 \\times 10^6}{30} = \\frac{25}{3} \\times 10^6 \\approx 8.333 \\times 10^6$ events/s.\n\nBy comparing the denominators ($30 < 58 < 81$), it is clear that $R_{S3}$ is the largest value.\n$R_{\\max} = R_{S3} = \\frac{250 \\times 10^6}{30} = 8333333.\\overline{3}$ events/s.\n\nThe problem requires the final answer to be rounded to four significant figures.\n$R_{\\max} \\approx 8.333 \\times 10^6$ events/s.", "answer": "$$\\boxed{8.333 \\times 10^6}$$", "id": "3652721"}, {"introduction": "Beyond speed, reliability is the cornerstone of any robust system. When interrupts can preempt each other in a deeply nested fashion, the stack becomes a critical resource whose limits must be respected to prevent catastrophic failure [@problem_id:3652658]. This exercise guides you through a worst-case analysis to determine the total stack space required, combining the demands of the application's call chain with the cumulative context saved by a series of nested interrupts.", "problem": "A microcontroller, denoted as architecture $\\mathcal{A}$, executes a single thread on a full-descending stack with $32$-bit words. The system employs a vectored interrupt controller with strictly preemptive priority: any pending interrupt with a numerically lower priority value than the currently running context is allowed to preempt immediately. Priority level $0$ is the highest; there is no non-maskable interrupt enabled in this scenario. The interrupt vector table assigns four maskable interrupts to vector entries corresponding to the following priorities: $\\mathrm{I_A}$ at priority $7$, $\\mathrm{I_B}$ at priority $5$, $\\mathrm{I_C}$ at priority $3$, and $\\mathrm{I_D}$ at priority $1$. Assume worst-case arrival times such that each higher-priority interrupt can arrive and preempt the currently executing interrupt before it completes, and that the controller and compiler introduce no artificial delays other than the architectural latencies described below.\n\nOn every exception entry (including interrupt entry), the hardware of $\\mathcal{A}$ automatically stacks a fixed core context consisting of the general-purpose registers $r0$ through $r3$, register $r12$, the link register $lr$, the program counter $pc$, and the program status register $\\mathrm{psr}$. Each of these is one word, and the core context therefore stacks a fixed number of words. The microcontroller includes a floating-point unit. The operating system configures the processor to always save the floating-point context on every interrupt entry. When the floating-point context is saved, the hardware additionally pushes registers $f0$ through $f15$ and the floating-point status and control register $\\mathrm{fpscr}$, and it inserts exactly one padding word to preserve $8$-byte stack alignment on entry. Assume interrupts are written to avoid additional stack use beyond the hardware-stacked context. Assume the stack alignment requirement is already satisfied by the described padding, so no further padding is needed.\n\nThe thread that is interrupted is executing a call chain of three functions $T \\rightarrow P \\rightarrow C$ at the moment the first interrupt is taken. The application uses a standard calling convention in which each function’s stack frame consists of its local storage, the saved callee-saved registers, and the link register $lr$. The three active frames have the following compositions:\n- In $T$: local storage of $124$ bytes; saved callee-saved registers $r4$ through $r11$ (eight registers); and $lr$.\n- In $P$: local storage of $44$ bytes; saved callee-saved registers $r4$ through $r9$ (six registers); and $lr$.\n- In $C$: local storage of $36$ bytes; saved callee-saved registers $r4$ through $r7$ (four registers); and $lr$.\n\nAssume each register is one word and each word is $4$ bytes. Each function’s frame size is rounded up to a multiple of $8$ bytes due to alignment constraints; the local storage sizes above are the unrounded amounts. All three functions have already executed their prologues, so their full frames are present on the stack at the moment of the first interrupt.\n\nUsing only first principles of preemptive priority interrupt handling and context stacking, determine the minimum stack allocation $S$ in bytes required to avoid overflow in the worst case where the four interrupts $\\mathrm{I_A}$, $\\mathrm{I_B}$, $\\mathrm{I_C}$, and $\\mathrm{I_D}$ nest to their maximum depth and each interrupt handler executes at least one floating-point instruction, thereby triggering the floating-point context save path on entry. Ignore any effects of tail-chaining on simultaneous residency of stacked frames.\n\nExpress your final answer as a single integer number of bytes. No rounding is required. Do not include units in your final boxed answer, but express the answer in bytes in your reasoning.", "solution": "The problem requires the calculation of the minimum stack allocation $S$ in bytes to prevent a stack overflow under a worst-case scenario of nested interrupts. The total stack usage is the sum of the stack space consumed by the interrupted application thread and the space consumed by the maximum possible number of nested interrupt service routines.\n\nThe word size is specified as $32$ bits, which is $4$ bytes.\n\nFirst, we calculate the stack space used by the application thread. The thread is executing a call chain $T \\rightarrow P \\rightarrow C$, and the stack frames for all three functions ($T$, $P$, and $C$) are present on the stack. The size of each function's frame must be calculated, including local storage, saved callee-saved registers, and the saved link register ($lr$), and then rounded up to a multiple of $8$ bytes for alignment.\n\nThe size of a single register is one word, which is $4$ bytes.\n\nFrame for function $C$:\n- Local storage: $36$ bytes.\n- Saved callee-saved registers ($r4$ through $r7$): $4$ registers $\\times 4$ bytes/register = $16$ bytes.\n- Saved link register ($lr$): $1$ register $\\times 4$ bytes/register = $4$ bytes.\n- Total unaligned size of frame $C$: $S_{C, \\text{unaligned}} = 36 + 16 + 4 = 56$ bytes.\nSince $56$ is a multiple of $8$, the aligned size is $S_C = 56$ bytes.\n\nFrame for function $P$:\n- Local storage: $44$ bytes.\n- Saved callee-saved registers ($r4$ through $r9$): $6$ registers $\\times 4$ bytes/register = $24$ bytes.\n- Saved link register ($lr$): $1$ register $\\times 4$ bytes/register = $4$ bytes.\n- Total unaligned size of frame $P$: $S_{P, \\text{unaligned}} = 44 + 24 + 4 = 72$ bytes.\nSince $72$ is a multiple of $8$, the aligned size is $S_P = 72$ bytes.\n\nFrame for function $T$:\n- Local storage: $124$ bytes.\n- Saved callee-saved registers ($r4$ through $r11$): $8$ registers $\\times 4$ bytes/register = $32$ bytes.\n- Saved link register ($lr$): $1$ register $\\times 4$ bytes/register = $4$ bytes.\n- Total unaligned size of frame $T$: $S_{T, \\text{unaligned}} = 124 + 32 + 4 = 160$ bytes.\nSince $160$ is a multiple of $8$, the aligned size is $S_T = 160$ bytes.\n\nThe total stack usage by the application thread, $S_{\\text{thread}}$, is the sum of the sizes of these three frames:\n$$S_{\\text{thread}} = S_C + S_P + S_T = 56 + 72 + 160 = 288 \\text{ bytes}$$\n\nNext, we calculate the stack space used by a single interrupt. The problem specifies that on every interrupt entry, both the core context and the floating-point context are saved.\n\nThe core context consists of registers $r0$ through $r3$ ($4$ registers), $r12$ ($1$ register), $lr$ ($1$ register), $pc$ ($1$ register), and $\\mathrm{psr}$ ($1$ register). This is a total of $4+1+1+1+1=8$ registers.\nThe size of the core context stack frame is:\n$$S_{\\text{core}} = 8 \\text{ registers} \\times 4 \\text{ bytes/register} = 32 \\text{ bytes}$$\n\nThe floating-point context save pushes registers $f0$ through $f15$ ($16$ registers), the $\\mathrm{fpscr}$ ($1$ register), and one padding word ($1$ word) to maintain $8$-byte alignment. This is a total of $16+1+1 = 18$ words.\nThe size of the floating-point context stack frame is:\n$$S_{\\text{fp}} = 18 \\text{ words} \\times 4 \\text{ bytes/word} = 72 \\text{ bytes}$$\n\nThe total stack space consumed by a single interrupt, $S_{\\text{interrupt}}$, is the sum of the core and floating-point context sizes:\n$$S_{\\text{interrupt}} = S_{\\text{core}} + S_{\\text{fp}} = 32 + 72 = 104 \\text{ bytes}$$\n\nThe worst-case scenario involves the maximum nesting of all four specified interrupts. The interrupts are $\\mathrm{I_A}$ (priority $7$), $\\mathrm{I_B}$ (priority $5$), $\\mathrm{I_C}$ (priority $3$), and $\\mathrm{I_D}$ (priority $1$). Since a lower priority value signifies a higher preemption priority, the deepest nesting occurs when the lowest-priority interrupt is preempted by the next higher, and so on. The sequence is: thread execution is preempted by $\\mathrm{I_A}$, which is preempted by $\\mathrm{I_B}$, which is preempted by $\\mathrm{I_C}$, which is finally preempted by $\\mathrm{I_D}$. This results in $4$ interrupt-handling contexts being pushed onto the stack.\n\nThe total stack usage for all nested interrupts is:\n$$S_{\\text{interrupts\\_total}} = 4 \\times S_{\\text{interrupt}} = 4 \\times 104 = 416 \\text{ bytes}$$\n\nFinally, the total minimum stack allocation $S$ required to avoid an overflow is the sum of the thread's stack usage and the total interrupt stack usage:\n$$S = S_{\\text{thread}} + S_{\\text{interrupts\\_total}} = 288 + 416 = 704 \\text{ bytes}$$", "answer": "$$\\boxed{704}$$", "id": "3652658"}, {"introduction": "The final piece of the puzzle is logical correctness, especially when dealing with the nuances of real hardware. This practice delves into the design of an Interrupt Service Routine (ISR) that must contend with shared, level-triggered interrupt lines and the possibility of spurious events from electrical noise [@problem_id:3652686]. You will learn the critical importance of the sequence of operations—such as raising processor priority, verifying the interrupt source, and correctly signaling completion—to prevent common but fatal bugs like system livelock.", "problem": "A Central Processing Unit (CPU) connected to a shared, level-triggered interrupt line is served by a Programmable Interrupt Controller (PIC) that performs fixed-priority resolution across multiple interrupt lines and delivers an interrupt vector $v$ to the CPU when any device asserts the line. A set of devices share this line and expose a memory-mapped status register $SR$ whose bit-field $\\{b_0, b_1, \\ldots, b_{m-1}\\}$ indicates pending interrupt sources; reading $SR$ is atomic and side-effect free, while each device’s interrupt cause is cleared by writing to the device’s cause-clear register after service. The PIC sets an in-service latch $IS$ for the line only when a valid request was accepted; in rare noise-induced cases, the CPU may receive a vector $v$ while $SR = 0$ and the PIC does not set $IS$ for that event. The End-of-Interrupt (EOI) command clears $IS$ for valid interrupts. The CPU can raise its Interrupt Priority Level (IPL) to mask further interrupts of the same or lower priority during an Interrupt Service Routine (ISR), where ISR stands for Interrupt Service Routine.\n\nYou must choose the ISR sequencing that both handles real interrupts correctly and safely accounts for spurious interrupts caused by electrical noise without entering livelock. The system-level requirements are:\n\n- Correctness under level-trigger semantics: if a device is the true source, the ISR must identify a pending source by reading $SR$, service the highest-priority pending source according to a software priority function $\\pi : \\{0,1,\\ldots,m-1\\} \\to \\mathbb{N}$, and clear its cause so that the shared line deasserts. Only after servicing a valid source should the ISR issue an EOI to the PIC.\n- Spurious robustness: if $SR = 0$ on entry, the ISR must detect that no source is pending, increment a counter $C_{\\text{spurious}}$, and return without livelock. No busy-waiting loops or repeated acknowledgments should be performed in this case.\n- Priority hygiene: while servicing, the ISR should prevent re-entrancy on the same vector and avoid allowing lower-priority interrupts to preempt before the current source is quiesced.\n\nWhich option best satisfies these requirements?\n\nA. On entry, raise IPL to mask the same vector. Read $SR$ once. If $SR = 0$, increment $C_{\\text{spurious}}$ and return without issuing EOI. If $SR \\neq 0$, select the highest-priority pending bit index $i^\\ast = \\arg\\min_{i \\in \\{0,\\ldots,m-1\\},\\, b_i=1} \\pi(i)$, service device $i^\\ast$, clear its cause, then issue EOI to the PIC, lower IPL, and return.\n\nB. On entry, raise IPL. Continuously poll $SR$ in a loop until $SR \\neq 0$. When a bit becomes set, select $i^\\ast$ by $\\pi(\\cdot)$, service and clear, then issue EOI and return. If $SR$ remains $0$, continue polling indefinitely.\n\nC. On entry, immediately issue EOI to the PIC to free lower-priority interrupts, then read $SR$. If $SR = 0$, increment $C_{\\text{spurious}}$ and return. If $SR \\neq 0$, select $i^\\ast$ by $\\pi(\\cdot)$, service and clear, lower IPL, and return.\n\nD. On entry, if $SR = 0$, mask the shared interrupt line in the PIC, busy-wait for a duration $T$ with $T > 0$ to see if any bit in $SR$ becomes set, and if none does, increment $C_{\\text{spurious}}$, unmask the line, and return. If $SR \\neq 0$, select $i^\\ast$ by $\\pi(\\cdot)$, service and clear, issue EOI, and return.", "solution": "The user has provided a detailed problem concerning the design of an Interrupt Service Routine (ISR) for a system with a shared, level-triggered interrupt line, a Programmable Interrupt Controller (PIC), and the possibility of spurious interrupts. The task is to select the correct sequence of operations within the ISR that satisfies three specific system-level requirements: correctness for level-triggered sources, robustness against spurious interrupts, and proper priority management.\n\nFirst, let us validate the problem statement.\n\n### Step 1: Extract Givens\n-   **Hardware Setup**: A Central Processing Unit (CPU) is connected to a shared, level-triggered interrupt line. A PIC manages interrupts from multiple devices on this line, performing fixed-priority resolution and delivering an interrupt vector $v$ to the CPU.\n-   **Device Interface**: Devices on the shared line use a memory-mapped status register, $SR$, with bit-field $\\{b_0, b_1, \\ldots, b_{m-1}\\}$ to indicate pending interrupt sources. Reading $SR$ is atomic and has no side effects. The cause of a device's interrupt is cleared by writing to a separate device-specific register.\n-   **PIC Behavior**: The PIC sets an in-service latch, $IS$, for the interrupt line when a valid request is accepted by the CPU. An End-of-Interrupt (EOI) command clears this latch.\n-   **Spurious Interrupts**: Spurious interrupts can occur due to noise. In these cases, the CPU receives the vector $v$, but the device status register is zero ($SR=0$), and the PIC's in-service latch $IS$ is not set.\n-   **CPU Capabilities**: The CPU can raise its Interrupt Priority Level (IPL) to mask interrupts of the same or lower priority.\n-   **Software Priority**: A function $\\pi : \\{0,1,\\ldots,m-1\\} \\to \\mathbb{N}$ defines the software-managed priority of the interrupt sources, where a lower value of $\\pi(i)$ corresponds to a higher priority.\n-   **Requirement 1 (Correctness)**: For a real interrupt, the ISR must read $SR$, identify and service the highest-priority source according to $\\pi$, clear the device's interrupt cause, and then issue an EOI to the PIC.\n-   **Requirement 2 (Spurious Robustness)**: If $SR=0$ on entry, the ISR must increment a counter $C_{\\text{spurious}}$ and return without causing a livelock. No busy-waiting is allowed.\n-   **Requirement 3 (Priority Hygiene)**: The ISR must prevent re-entrancy from the same interrupt vector and preemption by lower-priority interrupts while servicing a source.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is scientifically grounded, well-posed, and objective. It describes a standard, realistic scenario in computer architecture and embedded systems design. The concepts of level-triggered interrupts, shared interrupt lines, PICs (like the Intel $8259$ or ARM GIC), in-service registers, EOIs, spurious interrupts, and CPU priority levels are all fundamental and well-established. The requirements are clear, consistent, and do not contain contradictions. The problem is a valid and non-trivial test of understanding interrupt handling logic.\n\n### Step 3: Verdict and Action\nThe problem statement is valid. I will proceed with the derivation of the solution and evaluation of the options.\n\n### Derivation of the Correct ISR Sequence\n\nBased on first principles and the stated requirements, the ISR must perform its operations in a specific order to ensure correctness and stability.\n\n1.  **Priority Management (Requirement 3)**: Upon ISR entry, the first action must be to raise the CPU's Interrupt Priority Level (IPL). This prevents the current ISR from being preempted by another interrupt of the same or lower priority. This is essential for preventing race conditions and ensuring priority hygiene. It also prevents re-entrancy on the same interrupt vector, as the vector itself would be masked by the elevated IPL.\n\n2.  **Source Identification**: The ISR must determine if the interrupt is legitimate or spurious. The definitive source of truth for this is the shared device status register, $SR$. The ISR must read $SR$.\n\n3.  **Handling Spurious Interrupts (Requirement 2)**: If the read value of $SR$ is $0$, the interrupt is spurious. According to the problem, for such an event, the PIC did not set its in-service latch $IS$.\n    -   Therefore, no EOI should be sent. Sending an EOI is intended to clear the $IS$ latch for the current interrupt level. If no latch is set, sending an EOI is incorrect and could potentially interfere with the PIC's state machine (e.g., prematurely ending a different, legitimate interrupt that was in service).\n    -   The ISR should increment the counter $C_{\\text{spurious}}$.\n    -   The ISR must then return from the interrupt. Busy-waiting or polling is explicitly forbidden.\n\n4.  **Handling Valid Interrupts (Requirement 1)**: If the read value of $SR$ is non-zero ($SR \\neq 0$), at least one device is requesting service.\n    -   **Service**: The ISR must determine the highest-priority pending source by finding the index $i^\\ast$ corresponding to a set bit $b_{i^\\ast}=1$ that minimizes the priority function $\\pi(i^\\ast)$. It must then execute the service routine for device $i^\\ast$.\n    -   **Clear the Source**: After servicing, the ISR must clear the interrupt condition *at the device*, typically by writing to a device-specific register. This action is what causes the device to de-assert its signal on the level-triggered line. This is a critical step; failure to do so for a level-triggered interrupt would cause the interrupt to persist.\n    -   **Signal End-of-Interrupt (EOI)**: Only after the device has been serviced and its cause cleared should the ISR issue an EOI command to the PIC. This informs the PIC that the service for the current interrupt is complete, causing the PIC to clear its $IS$ latch. For a level-triggered system, if other lower-priority devices still hold the line high, the PIC can now generate a new interrupt if its priority logic allows. Issuing the EOI *before* clearing the source is a classic bug that causes an immediate re-triggering of the same interrupt, leading to livelock.\n    -   **Return**: Finally, the ISR should return. The return-from-interrupt instruction will typically restore the CPU's original IPL.\n\nThis derived sequence provides a robust framework for evaluating the given options.\n\n### Option-by-Option Analysis\n\n**A. On entry, raise IPL to mask the same vector. Read $SR$ once. If $SR = 0$, increment $C_{\\text{spurious}}$ and return without issuing EOI. If $SR \\neq 0$, select the highest-priority pending bit index $i^\\ast = \\arg\\min_{i \\in \\{0,\\ldots,m-1\\},\\, b_i=1} \\pi(i)$, service device $i^\\ast$, clear its cause, then issue EOI to the PIC, lower IPL, and return.**\n\n-   **Raise IPL**: Correctly implements Requirement 3.\n-   **Read $SR$**: Correctly identifies the state.\n-   **Spurious Case ($SR=0$)**: Correctly increments $C_{\\text{spurious}}$ and returns without an EOI, satisfying Requirement 2.\n-   **Valid Case ($SR \\neq 0$)**: Correctly identifies the highest-priority source, services it, clears the cause, and *then* issues the EOI. This is the correct order for level-triggered interrupts and satisfies Requirement 1. Lowering IPL before return is also correct.\n-   **Verdict**: **Correct**. This option follows the derived ideal sequence precisely.\n\n**B. On entry, raise IPL. Continuously poll $SR$ in a loop until $SR \\neq 0$. When a bit becomes set, select $i^\\ast$ by $\\pi(\\cdot)$, service and clear, then issue EOI and return. If $SR$ remains $0$, continue polling indefinitely.**\n\n-   This option handles the spurious case ($SR=0$) by entering an infinite polling loop. This constitutes a livelock (or more accurately, a deadlock for the CPU) and is an explicit violation of Requirement 2 (\"Return without livelock. No busy-waiting loops...\").\n-   **Verdict**: **Incorrect**.\n\n**C. On entry, immediately issue EOI to the PIC to free lower-priority interrupts, then read $SR$. If $SR = 0$, increment $C_{\\text{spurious}}$ and return. If $SR \\neq 0$, select $i^\\ast$ by $\\pi(\\cdot)$, service and clear, lower IPL, and return.**\n\n-   Issuing an EOI at the beginning of the ISR, before clearing the interrupt source at the device, is a critical flaw for level-triggered interrupts. The interrupt line remains asserted, so the PIC, upon receiving the EOI, will immediately re-signal the same interrupt, causing the ISR to re-enter itself, leading to stack overflow and system lockup. This violates Requirement 1, which states EOI should be issued *after* servicing. Furthermore, it omits raising IPL, violating Requirement 3.\n-   **Verdict**: **Incorrect**.\n\n**D. On entry, if $SR = 0$, mask the shared interrupt line in the PIC, busy-wait for a duration $T$ with $T > 0$ to see if any bit in $SR$ becomes set, and if none does, increment $C_{\\text{spurious}}$, unmask the line, and return. If $SR \\neq 0$, select $i^\\ast$ by $\\pi(\\cdot)$, service and clear, issue EOI, and return.**\n\n-   For the spurious case ($SR=0$), this option introduces a busy-wait for a duration $T$. This violates Requirement 2, which forbids busy-waiting.\n-   For the valid case ($SR \\neq 0$), this option fails to raise the CPU's IPL upon entry. This violates Requirement 3, as it fails to prevent re-entrancy and preemption by lower-priority interrupts.\n-   **Verdict**: **Incorrect**.\n\nConclusion: Option A is the only one that correctly sequences all required operations to meet the specified system-level requirements for correctness, robustness, and priority management.", "answer": "$$\\boxed{A}$$", "id": "3652686"}]}