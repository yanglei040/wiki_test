{"hands_on_practices": [{"introduction": "The design of a processor's datapath involves fundamental trade-offs between performance, area, and complexity. This exercise provides a concrete example of this principle by contrasting a fast but large parallel adder with a slower but smaller bit-serial implementation. By quantifying the latency and the simplification in control logic, you will gain a practical understanding of how architectural choices for the datapath directly influence both execution speed and the design of the control path [@problem_id:3632396].", "problem": "A processor datapath currently implements a $W$-bit addition using a $W$-bit ripple-carry adder built from $W$ identical $1$-bit full adder slices. The control path is microcoded and broadcasts $k$ function-select control lines to the Arithmetic Logic Unit (ALU), which in this design is slice-based with the $k$ lines fanned out identically to each of the $W$ bit-slices. You are asked to redesign the datapath to use a bit-serial adder and to quantify both the resulting latency and the control-path simplicity gain.\n\nIn the bit-serial design, the datapath consists of a single $1$-bit full adder, two $W$-bit shift registers $R_A$ and $R_B$ that hold the operands, one $W$-bit shift register $R_S$ that accumulates the sum, and a single carry flip-flop $C$. A simple Finite State Machine (FSM) controller sequences the operation as follows:\n- An initialization micro-operation that clears the carry flip-flop to $C \\leftarrow 0$ and prepares $R_S$ to accept result bits.\n- A loop of $W$ identical cycles. In each cycle, the least significant bit (LSB) of $R_A$ and the LSB of $R_B$ are presented to the full adder, the resulting sum bit is shifted into $R_S$, the carry-out updates $C$, and both $R_A$ and $R_B$ shift right by $1$ bit.\n- A final commit micro-operation that writes the content of $R_S$ to the architected destination register.\n\nAssume the initialization and commit each consume exactly $1$ clock cycle, and that each loop iteration consumes exactly $1$ clock cycle. Define the control-path simplicity gain as the ratio $G$ of the total number of ALU function-select control fanout endpoints in the original $W$-bit parallel design to that in the $1$-bit serial design. For this purpose, count only the $k$ ALU function-select lines and only their fanout endpoints into the ALU slices; do not include any other control or datapath signals.\n\nUsing only basic definitions of ripple-carry addition, sequential control, and control-signal fanout, derive:\n- The exact latency in cycles, $L_{\\text{serial}}$, for one $W$-bit addition on the bit-serial datapath including the initialization and commit.\n- The control-path simplicity gain $G$ as defined above.\n\nExpress your final answer as a single row vector using the LaTeX $\\texttt{pmatrix}$ environment with entries $L_{\\text{serial}}$ (in cycles) and $G$. No numerical evaluation or rounding is required; provide a closed-form analytic expression in terms of $W$ and $k$.", "solution": "The problem as stated is scientifically grounded, well-posed, and self-contained, presenting a valid scenario in computer organization and architecture. All necessary definitions and conditions are provided to derive the required quantities without ambiguity. We proceed with the solution.\n\nThe problem requires the derivation of two quantities for a bit-serial adder design: the latency $L_{\\text{serial}}$ in clock cycles and the control-path simplicity gain $G$.\n\nFirst, we derive the latency $L_{\\text{serial}}$. The problem describes the bit-serial addition as a sequence of three distinct micro-operations, with the duration of each specified in clock cycles. The total latency is the sum of the durations of these operations.\n1.  The initialization step, which includes clearing the carry flip-flop $C$ to $0$ ($C \\leftarrow 0$), is stated to consume exactly $1$ clock cycle.\n2.  The main processing loop, which performs the bit-by-bit addition, runs for $W$ identical cycles, where $W$ is the operand width. The problem states that each iteration of this loop consumes exactly $1$ clock cycle. Therefore, the total time for the loop phase is $W \\times 1 = W$ clock cycles.\n3.  The final commit step, which writes the result from the accumulator register $R_S$ to its final destination, is stated to consume exactly $1$ clock cycle.\n\nThe total latency, $L_{\\text{serial}}$, is the sum of the latencies of these three sequential phases:\n$$L_{\\text{serial}} = (\\text{latency of initialization}) + (\\text{latency of loop}) + (\\text{latency of commit})$$\nSubstituting the given values:\n$$L_{\\text{serial}} = 1 + W + 1$$\n$$L_{\\text{serial}} = W + 2$$\nThe latency of the $W$-bit serial addition is therefore $W+2$ clock cycles.\n\nNext, we derive the control-path simplicity gain, $G$. This is defined as the ratio of the total number of ALU function-select control fanout endpoints in the original parallel design to that in the new bit-serial design. We must count only the endpoints of the $k$ ALU function-select lines where they connect to the ALU slices.\n\nIn the original parallel design, the ALU is a $W$-bit ripple-carry adder constructed from $W$ identical $1$-bit full adder slices. There are $k$ function-select control lines from the microcoded control path. The problem states these $k$ lines are \"fanned out identically to each of the $W$ bit-slices\". This means that each of the $k$ control signals is an input to every one of the $W$ slices. The total number of fanout endpoints is the product of the number of control lines and the number of slices they connect to.\n$$\\text{Endpoints}_{\\text{original}} = (\\text{number of control lines}) \\times (\\text{number of slices})$$\n$$\\text{Endpoints}_{\\text{original}} = k \\times W$$\n\nIn the new bit-serial design, the ALU consists of a single $1$-bit full adder. The control path would still need to provide the $k$ function-select lines to this single slice to specify the operation (even if the only operation described is addition, a general ALU architecture is implied by the presence of function-select lines). Thus, the $k$ control lines connect to this one slice.\n$$\\text{Endpoints}_{\\text{serial}} = (\\text{number of control lines}) \\times (\\text{number of slices})$$\n$$\\text{Endpoints}_{\\text{serial}} = k \\times 1 = k$$\n\nThe control-path simplicity gain $G$ is the ratio of these two quantities:\n$$G = \\frac{\\text{Endpoints}_{\\text{original}}}{\\text{Endpoints}_{\\text{serial}}}$$\n$$G = \\frac{k W}{k}$$\nAssuming $k$ is a positive integer, as it represents a number of physical control lines ($k > 0$), we can cancel $k$ from the numerator and the denominator.\n$$G = W$$\n\nThe two derived quantities are $L_{\\text{serial}} = W + 2$ and $G = W$. The problem asks for the final answer to be expressed as a single row vector.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nW + 2 & W\n\\end{pmatrix}\n}\n$$", "id": "3632396"}, {"introduction": "In a pipelined processor, the control path must ensure that the correct next instruction address is selected, even as decisions about branches and exceptions are resolved in later pipeline stages. This practice moves beyond simple logic to address the critical real-world issue of combinational logic hazards, or glitches, which can cause catastrophic errors if not managed. You are challenged to design a robust, glitch-free control system for the Program Counter ($PC$) multiplexer, reinforcing the importance of registered control signals and priority logic in creating stable, high-performance synchronous systems [@problem_id:3632388].", "problem": "A $5$-stage Reduced Instruction Set Computer (RISC) pipeline consists of Instruction Fetch (IF), Instruction Decode (ID), Execute (EX), Memory (MEM), and Write-back (WB). The next Program Counter (PC) value, denoted $PC_{\\text{next}}$, is selected by a $4$-to-$1$ multiplexer from among four sources: the sequential increment $PC+4$, the computed branch target $PC_{\\text{br}}$, the jump target $PC_{\\text{jmp}}$, and the exception vector $PC_{\\text{exc}}$. The multiplexer is controlled by a one-hot vector $S$ of width $4$, where $S_0$ selects $PC+4$, $S_1$ selects $PC_{\\text{br}}$, $S_2$ selects $PC_{\\text{jmp}}$, and $S_3$ selects $PC_{\\text{exc}}$. The one-hot constraint requires $\\sum_{i=0}^{3} S_i = 1$ with exactly one $S_i$ equal to $1$.\n\nBranch resolution occurs in the EX stage. A combinational network in EX produces raw decisions $\\{d_{\\text{seq}}, d_{\\text{br}}, d_{\\text{jmp}}, d_{\\text{exc}}\\}$, where $d_{\\text{seq}}$ indicates the sequential fall-through, $d_{\\text{br}}$ indicates a taken branch, $d_{\\text{jmp}}$ indicates a jump, and $d_{\\text{exc}}$ indicates an exception. Due to operand arrival times and control signals (such as pipeline flush and stall), the raw decisions can exhibit dynamic hazards (transient glitches) during the cycle as inputs settle. The processor uses a single-phase synchronous clock of period $T$, and all pipeline registers capture on the rising edge. The $PC$ register is updated in the IF stage based on the multiplexer output that is active during the cycle preceding the sampling edge.\n\nDesign a glitch-free control path for the $PC$ multiplexer such that:\n- The select lines applied to the multiplexer remain one-hot and stable for the entire cycle in which $PC_{\\text{next}}$ is driven.\n- Mutually exclusive selection is guaranteed even in the presence of transient behavior in $\\{d_{\\text{seq}}, d_{\\text{br}}, d_{\\text{jmp}}, d_{\\text{exc}}\\}$.\n- The design respects the single-phase synchronous timing model and typical pipeline flow-control signals, including $valid$, $stall$, and $flush$.\n\nWhich of the following control strategies satisfies these requirements?\n\nA. Drive the $PC$ multiplexer directly from the raw EX combinational outputs by wiring $S_0 \\leftarrow d_{\\text{seq}}$, $S_1 \\leftarrow d_{\\text{br}}$, $S_2 \\leftarrow d_{\\text{jmp}}$, $S_3 \\leftarrow d_{\\text{exc}}$, and add a combinational fallback such that if all $d$ signals are $0$ then $S_0$ is forced to $1$; no registers are inserted between EX and IF.\n\nB. Construct disjoint one-hot decisions in EX by masking pairwise conflicts (e.g., exception preempts all, jump preempts branch, branch preempts sequential), qualify them with the EX-stage $valid$ and the absence of an incoming $flush$, then register the resulting one-hot vector at the EX/MEM boundary. Use the registered vector to drive the IF-stage $PC$ multiplexer in the following cycle, further masking with IF-stage $stall$ and downstream $flush$ so that exactly one of $\\{S_0,S_1,S_2,S_3\\}$ is asserted for the duration of the cycle that drives $PC_{\\text{next}}$.\n\nC. Encode the raw EX decisions into a binary select $\\{s_1, s_0\\}$ using a priority encoder (exceptions highest, then jump, then branch, then sequential), and feed $\\{s_1, s_0\\}$ combinationally to the IF-stage $PC$ multiplexer in the same cycle; rely on the priority encoder to suppress conflicts instead of one-hot enforcement.\n\nD. Combine $d_{\\text{br}}$ and $d_{\\text{jmp}}$ using a wired-OR to form a single \"non-sequential\" signal, gate it with the inverse of $d_{\\text{exc}}$, and derive $S_0$ as the inverse of this gated signal; use the remaining signals directly to form $S_1$, $S_2$, and $S_3$ without any registers, assuming mutually exclusive decode makes simultaneous assertions practically impossible.\n\nE. Replace the EX combinational network with cross-coupled set-reset latches that implement a one-hot arbiter among $\\{d_{\\text{seq}}, d_{\\text{br}}, d_{\\text{jmp}}, d_{\\text{exc}}\\}$ and feed the latch outputs directly to the IF-stage $PC$ multiplexer in the same cycle, assuming that asynchronous arbitration ensures mutual exclusion and glitch suppression without pipeline registers.", "solution": "## Problem Validation\n\n### Step 1: Extract Givens\n- **Pipeline Structure**: A $5$-stage Reduced Instruction Set Computer (RISC) pipeline: Instruction Fetch (IF), Instruction Decode (ID), Execute (EX), Memory (MEM), and Write-back (WB).\n- **Program Counter (PC) Update**: The next PC value, $PC_{\\text{next}}$, is selected by a $4$-to-$1$ multiplexer.\n- **Multiplexer Inputs**:\n    1.  Sequential increment: $PC+4$\n    2.  Computed branch target: $PC_{\\text{br}}$\n    3.  Jump target: $PC_{\\text{jmp}}$\n    4.  Exception vector: $PC_{\\text{exc}}$\n- **Multiplexer Control**: A one-hot vector $S$ of width $4$.\n    - $S_0$ selects $PC+4$.\n    - $S_1$ selects $PC_{\\text{br}}$.\n    - $S_2$ selects $PC_{\\text{jmp}}$.\n    - $S_3$ selects $PC_{\\text{exc}}$.\n- **One-Hot Constraint**: $\\sum_{i=0}^{3} S_i = 1$, with exactly one $S_i$ equal to $1$.\n- **Decision Logic**:\n    - Branch resolution occurs in the EX stage.\n    - A combinational network in EX produces raw decisions $\\{d_{\\text{seq}}, d_{\\text{br}}, d_{\\text{jmp}}, d_{\\text{exc}}\\}$.\n    - These raw decisions can exhibit dynamic hazards (transient glitches).\n- **Timing Model**:\n    - Single-phase synchronous clock of period $T$.\n    - All pipeline registers capture on the rising edge.\n    - The $PC$ register is updated in the IF stage based on the multiplexer output active during the cycle preceding the sampling edge.\n- **Design Objective**: Design a glitch-free control path for the $PC$ multiplexer.\n- **Design Constraints**:\n    1.  The select lines $S$ must be one-hot and stable for the entire cycle.\n    2.  Mutual exclusion among selections must be guaranteed, even with transient behavior in the raw decisions $\\{d_{\\text{seq}}, d_{\\text{br}}, d_{\\text{jmp}}, d_{\\text{exc}}\\}$.\n    3.  The design must respect standard pipeline flow-control signals, including $valid$, $stall$, and $flush$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is scientifically grounded, well-posed, and objective.\n- **Scientifically Grounded**: The problem describes a canonical and realistic challenge in the design of pipelined processors. The concepts of pipeline stages, PC control, branch hazards, exceptions, stalls, flushes, and the dangers of combinational logic glitches are all fundamental to computer architecture and digital logic design. No pseudoscience or factually incorrect premises are present.\n- **Well-Posed**: The problem provides a clear objective (design a glitch-free control path) and a set of explicit constraints that the solution must satisfy. The information given is sufficient to logically deduce the properties of a correct solution and evaluate the provided options. A unique class of valid solutions exists.\n- **Objective**: The problem is described using precise, unambiguous technical terminology (e.g., \"one-hot vector,\" \"dynamic hazards,\" \"single-phase synchronous clock\"). The requirements are quantitative and verifiable.\n\nThe problem does not exhibit any of the invalidity flaws. It is a well-formed engineering design problem.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. The solution process will now proceed.\n\n## Principle-Based Derivation\nThe core task is to generate a stable, one-hot select signal $S$ for the $PC$ multiplexer located in the IF stage, based on decisions $\\{d_{\\text{seq}}, d_{\\text{br}}, d_{\\text{jmp}}, d_{\\text{exc}}\\}$ computed in the EX stage.\n\n1.  **Addressing Glitches and Stability**: The problem states that the raw decision signals $\\{d\\}$ from the EX stage's combinational logic are subject to \"dynamic hazards (transient glitches)\". It also requires the final MUX select lines $S$ to be \"stable for the entire cycle\". Driving a multiplexer with glitchy select lines is unacceptable in a synchronous design, as it can cause the multiplexer's output to be momentarily incorrect. If this glitch occurs near the clock edge of the register capturing the output (the $PC$ register), it can lead to setup/hold time violations, metastability, or latching an erroneous value. The only way to convert a glitchy signal from combinational logic into a stable signal that lasts for an entire clock cycle is to pass it through a synchronous register (like a D flip-flop).\n\n2.  **Pipeline Timing and Control Path**: The decisions are made in the EX stage, but the control is needed in the IF stage. This implies a control signal must be routed from a later pipeline stage (EX) back to an earlier one (IF). A direct, purely combinational feedback path from the EX stage logic to the IF stage logic is highly undesirable. Such a path would be physically long, difficult to meet timing on, and, most importantly, would propagate the very glitches the design must eliminate. Therefore, the control information generated in EX must be registered before being used in IF. The natural place to register information from the EX stage is in the EX/MEM pipeline register at the end of the EX cycle. This makes the sanitized control information available and stable during the next clock cycle, when the corresponding instruction is in the MEM stage. This stable signal can then be safely fed back to the IF stage.\n\n3.  **Ensuring Mutual Exclusion (One-Hot Enforcement)**: The raw decisions $\\{d\\}$ may not be mutually exclusive during transients (e.g., $d_{\\text{seq}}$ might be $1$, and as the branch condition resolves, $d_{\\text{br}}$ might transition to $1$ before $d_{\\text{seq}}$ transitions to $0$, creating a brief interval where both are $1$). To satisfy the one-hot constraint, a priority system must be imposed. The standard priority order is: exceptions have the highest priority, followed by jumps, then taken branches, and finally the default sequential path. This can be implemented with combinational logic in the EX stage. For example:\n    - $c_{\\text{exc}} = d_{\\text{exc}}$\n    - $c_{\\text{jmp}} = d_{\\text{jmp}} \\land \\neg d_{\\text{exc}}$\n    - $c_{\\text{br}} = d_{\\text{br}} \\land \\neg d_{\\text{jmp}} \\land \\neg d_{\\text{exc}}$\n    - $c_{\\text{seq}} = \\neg (c_{\\text{exc}} \\lor c_{\\text{jmp}} \\lor c_{\\text{br}})$ (assuming the default is sequential if no other event occurs).\n    This logic creates a set of signals $\\{c\\}$ that are guaranteed to be mutually exclusive *statically*, but they are still combinational outputs and will have their own glitches. These sanitized signals are what should be registered.\n\n4.  **Handling Pipeline Flow Control**: The final MUX control in the IF stage must also account for pipeline stalls and flushes. A signal from the MEM stage indicating a branch misprediction (which includes the correct target PC) must override the default IF stage behavior. Similarly, if the IF stage is stalled (e.g., waiting for an I-cache miss), the PC should not advance. This is typically handled by gating the final select logic with a stall signal. For instance, if `IF_stall` is asserted, the logic could force $S_0 = 1$ (to select $PC+4$) but separately disable the PC register's write enable, effectively freezing the PC. The requirement that exactly one $S_i = 1$ must always hold means the stall/flush logic must be integrated to produce a valid one-hot vector under all conditions.\n\n**Conclusion of Derivation**: A correct design must:\na.  Use priority logic in the EX stage to create mutually exclusive control signals from the raw decisions.\nb.  Register these signals at a pipeline boundary (e.g., EX/MEM) to eliminate glitches and provide cycle-long stability.\nc.  Feed the stable, registered signals from the later pipeline stage (e.g., MEM) back to the IF stage.\nd.  In the IF stage, combine these feedback signals with local pipeline control signals ($stall$, $flush$) to generate the final, stable, one-hot MUX select vector $S$.\n\n## Option-by-Option Analysis\n\n**A. Drive the PC multiplexer directly from the raw EX combinational outputs by wiring $S_0 \\leftarrow d_{\\text{seq}}$, $S_1 \\leftarrow d_{\\text{br}}$, $S_2 \\leftarrow d_{\\text{jmp}}$, $S_3 \\leftarrow d_{\\text{exc}}$, and add a combinational fallback such that if all $d$ signals are $0$ then $S_0$ is forced to $1$; no registers are inserted between EX and IF.**\nThis strategy is fundamentally flawed. The key phrase \"no registers are inserted\" means it creates a long combinational path from EX to IF, which propagates the glitches from the raw $\\{d\\}$ signals directly to the $PC$ multiplexer's select lines. This violates the primary requirements of having stable and glitch-free select lines. Furthermore, the described logic does not properly enforce the one-hot constraint in the presence of glitches where multiple $d$ signals could be transiently asserted.\n**Verdict: Incorrect**\n\n**B. Construct disjoint one-hot decisions in EX by masking pairwise conflicts (e.g., exception preempts all, jump preempts branch, branch preempts sequential), qualify them with the EX-stage $valid$ and the absence of an incoming $flush$, then register the resulting one-hot vector at the EX/MEM boundary. Use the registered vector to drive the IF-stage PC multiplexer in the following cycle, further masking with IF-stage $stall$ and downstream $flush$ so that exactly one of $\\{S_0,S_1,S_2,S_3\\}$ is asserted for the duration of the cycle that drives $PC_{\\text{next}}$.**\nThis option follows the derived principles perfectly.\n1.  \"Construct disjoint one-hot decisions in EX by masking pairwise conflicts\" is the priority encoding step to ensure mutual exclusion.\n2.  \"register the resulting one-hot vector at the EX/MEM boundary\" is the critical step to eliminate glitches and create a stable signal.\n3.  \"Use the registered vector to drive the IF-stage PC multiplexer in the following cycle\" describes the correct, registered feedback path from a later stage (MEM) to an earlier one (IF).\n4.  \"further masking with IF-stage $stall$ and downstream $flush$\" correctly incorporates pipeline flow control.\nThis design ensures the select lines $S$ are stable, one-hot, and correct for all pipeline conditions.\n**Verdict: Correct**\n\n**C. Encode the raw EX decisions into a binary select $\\{s_1, s_0\\}$ using a priority encoder... and feed $\\{s_1, s_0\\}$ combinationally to the IF-stage $PC$ multiplexer in the same cycle...**\nThis option fails for the same primary reason as option A: it uses a purely combinational path (\"feed ... combinationally ... in the same cycle\") from EX to IF. While a priority encoder ensures its output corresponds to the highest-priority active input, the encoder's own output signals can glitch as the inputs settle. Propagating these glitches to the IF stage is unacceptable. Furthermore, it proposes a binary encoding, which contradicts the problem's stated use of a one-hot control vector $S$ (though this is a secondary issue to the fundamental timing flaw).\n**Verdict: Incorrect**\n\n**D. Combine $d_{\\text{br}}$ and $d_{\\text{jmp}}$ using a wired-OR... without any registers, assuming mutually exclusive decode makes simultaneous assertions practically impossible.**\nThis option also fails by specifying \"without any registers,\" leading to a glitchy combinational path. Its logic for creating mutual exclusion is incomplete and flawed. Most critically, it relies on an assumption (\"assuming mutually exclusive decode makes simultaneous assertions practically impossible\") that directly contradicts the problem's premise that the raw decisions $\\{d\\}$ *do* have dynamic hazards, which implies transient non-mutual-exclusivity. A robust design cannot be based on such a faulty assumption.\n**Verdict: Incorrect**\n\n**E. Replace the EX combinational network with cross-coupled set-reset latches that implement a one-hot arbiter... and feed the latch outputs directly to the IF-stage PC multiplexer in the same cycle...**\nThis option introduces an asynchronous circuit (arbiter) into a synchronous pipeline without a proper synchronization interface. The time an arbiter takes to resolve contention can be unpredictable and may lead to metastability. Feeding its output \"directly... in the same cycle\" to the IF stage is a severe violation of synchronous design principles. This creates an un-registered, asynchronously-generated signal path, which is even more dangerous than a simple combinational path due to the risk of metastability. This violates the requirement for a stable signal and is poor engineering practice in a synchronous system.\n**Verdict: Incorrect**", "answer": "$$\\boxed{B}$$", "id": "3632388"}, {"introduction": "Real-world digital systems are rarely governed by a single clock; they are complex integrations of components operating in different clock domains. This practice explores the dangerous phenomenon of metastability, which occurs when a signal crosses between asynchronous domains, potentially leading to system failure. By analyzing a common bug and evaluating standard solutions like two-flip-flop synchronizers, you will learn indispensable techniques for designing reliable systems and appreciate how physical realities fundamentally shape robust control path implementation [@problem_id:3632351].", "problem": "A pipelined processor has a write-back data path in which a $2:1$ multiplexer selects between the arithmetic logic unit output and a memory load value to drive the register file write-data port. The select signal $S$ for this multiplexer is generated in a separate clock domain with clock $C_s$ at frequency $125\\,\\mathrm{MHz}$ and is consumed in the destination clock domain with clock $C_d$ at frequency $500\\,\\mathrm{MHz}$. The register file write clock is $C_d$, and the write-enable is synchronous to $C_d$. A rare bug is observed: random incorrect register writes occur, correlated with transitions of $S$ arriving close to the rising edge of $C_d$. In the existing implementation, $S$ directly drives the multiplexer select in the $C_d$ domain without any synchronization.\n\nFrom first principles, recall that when a flip-flop input changes within the setup/hold aperture around its sampling edge, the flip-flop may enter a metastable state whose resolution time is an exponential random variable characterized by a device time constant $\\tau$, and that the probability of an unresolved metastability after a given available resolution time decays exponentially in that time. Also recall that sampling unrelated clock domain signals independently on multiple flip-flops can produce incoherent multi-bit values.\n\nAssume the following for quantitative consideration: the $C_d$ clock period is $2\\,\\mathrm{ns}$, and the synchronizer flip-flops have a metastability time constant $\\tau = 20\\,\\mathrm{ps}$. Neglect second-order timing effects such as clock-to-$Q$ and setup time when estimating available resolution time on the order of a clock period.\n\nWhich of the following design changes and statements are correct in order to eliminate the random writes and to apply two-flip-flop synchronizers appropriately? Select all that apply.\n\nA. Insert a $2$-flip-flop D-type synchronizer in the $C_d$ domain on the select $S$ before the multiplexer; if $S$ is a pulse in $C_s$, first convert it to a level that remains asserted for at least $2$ destination cycles to ensure it can be reliably captured.\n\nB. Independently apply a $2$-flip-flop synchronizer to each bit of the multi-bit write address and to each bit of the write-data bus crossing into $C_d$; this preserves coherency with only $1$ cycle of latency and eliminates random writes.\n\nC. Leave $S$ asynchronous, but add a $2$-flip-flop synchronizer to the write-enable in $C_d$; because the write-enable will be delayed, the multiplexer output will have time to settle, guaranteeing correct writes.\n\nD. When multiple related control fields must cross from $C_s$ to $C_d$, transfer the control bundle using a request/acknowledge handshake or an asynchronous first-in first-out (FIFO), capture them with registers in $C_d$, and only then drive the multiplexer select with the registered $S$.\n\nE. A single-flip-flop synchronizer on $S$ is sufficient at $500\\,\\mathrm{MHz}$ because the probability of metastability decreases approximately linearly with the additional resolution time provided by a synchronizer.\n\nF. With destination clock at $500\\,\\mathrm{MHz}$ and metastability time constant $\\tau = 20\\,\\mathrm{ps}$, adding one extra destination clock period of resolution time (by using a $2$-flip-flop synchronizer instead of a $1$-flip-flop) increases the Mean Time Between Failures (MTBF) by a factor on the order of $e^{100}$.\n\nG. Place the $2$-flip-flop synchronizer on the multiplexer data output instead of on its select $S$; this is preferable because it preserves the relative timing of control signals and eliminates the bug with lower latency.\n\nH. Two-flip-flop synchronizers are appropriate for single-bit level signals crossing clock domains; for one-cycle pulses from the source domain, use a toggle-based scheme or stretch the pulse before the $2$-flip-flop synchronizer; for multi-bit values, use Gray coding or a handshake rather than per-bit $2$-flip-flop synchronizers.", "solution": "The problem statement describes a classic clock domain crossing (CDC) issue in a digital system. A control signal, $S$, generated in a source clock domain ($C_s$) is used to control a multiplexer in a destination clock domain ($C_d$) without proper synchronization. When the signal $S$ transitions close to the active edge of the destination clock $C_d$, it can violate the setup or hold time requirements of the sequential elements in the $C_d$ domain that are affected by the multiplexer's output. In this case, the register file, which is clocked by $C_d$, samples the output of the multiplexer. An unstable multiplexer output can lead to the register file latching an incorrect or metastable value, explaining the \"random incorrect register writes.\" The fundamental goal is to ensure that the select signal $S$ is stable for the required setup and hold time around the rising edge of $C_d$.\n\nThe problem is scientifically grounded, well-posed, and objective. The provided physical parameters ($f_s = 125\\,\\mathrm{MHz}$, $f_d = 500\\,\\mathrm{MHz}$, $T_d = 2\\,\\mathrm{ns}$, $\\tau = 20\\,\\mathrm{ps}$) are consistent and realistic. The core issue is a standard topic in digital design and computer architecture. The problem is valid.\n\nWe will now evaluate each option based on first principles of digital design and CDC synchronization.\n\n**A. Insert a $2$-flip-flop D-type synchronizer in the $C_d$ domain on the select $S$ before the multiplexer; if $S$ is a pulse in $C_s$, first convert it to a level that remains asserted for at least $2$ destination cycles to ensure it can be reliably captured.**\n\nThis statement proposes the standard solution for synchronizing a single-bit control signal crossing a clock domain. A $2$-flip-flop (2-FF) synchronizer consists of two D-type flip-flops cascaded in series, both clocked by the destination clock $C_d$. The first flip-flop samples the asynchronous signal $S$. Its output may become metastable if $S$ changes within the setup/hold aperture of this flip-flop. The second flip-flop samples the output of the first one. The key is that the entire clock period of $C_d$ is available for the first flip-flop's output to resolve from a metastable state to a stable logic level ($0$ or $1$) before it is sampled by the second flip-flop. The output of the second flip-flop is a stable, synchronized version of $S$ that is safe to use in the $C_d$ domain.\n\nThe statement also correctly addresses the issue of synchronizing pulses. For a synchronizer to reliably capture a signal, the signal must be stable for at least one full cycle of the destination clock. The source clock period is $T_s = 1/(125\\,\\mathrm{MHz}) = 8\\,\\mathrm{ns}$. The destination clock period is $T_d = 2\\,\\mathrm{ns}$. A pulse lasting one $C_s$ cycle is $8\\,\\mathrm{ns}$ wide, which is $4$ times the $C_d$ period. This is sufficient for capture. The recommendation to ensure the signal is asserted for at least $2$ destination cycles is a robust design practice to prevent the pulse from being missed due to unfavorable clock phase alignment. This entire statement describes a correct and robust design change.\n\nVerdict: **Correct**.\n\n**B. Independently apply a $2$-flip-flop synchronizer to each bit of the multi-bit write address and to each bit of the write-data bus crossing into $C_{d}$; this preserves coherency with only $1$ cycle of latency and eliminates random writes.**\n\nThis option is flawed for several reasons. First, the problem is with the control signal $S$, not necessarily the write address or write-data bus. The problem states the write-enable is synchronous to $C_d$, which strongly implies the associated data and address busses are also valid in the $C_d$ domain.\nSecond, and more critically, it proposes synchronizing a multi-bit bus by applying an independent $2$-FF synchronizer to each bit. This is a fundamentally incorrect design practice. Due to the random nature of metastability resolution, different bits of the bus can be synchronized on different clock cycles. If the bus value changes from, say, $01111111_2$ to $10000000_2$, the synchronized value could temporarily become an invalid intermediate value like $00000000_2$ or $11111111_2$. This loss of coherency is unacceptable for data or address buses.\nThird, a $2$-FF synchronizer introduces a latency of $2$ to $3$ destination clock cycles, not $1$.\n\nVerdict: **Incorrect**.\n\n**C. Leave $S$ asynchronous, but add a $2$-flip-flop synchronizer to the write-enable in $C_{d}$; because the write-enable will be delayed, the multiplexer output will have time to settle, guaranteeing correct writes.**\n\nThis approach does not solve the root problem. The write-enable signal being active enables the write operation into the register file at the clock edge. The data input to the register file (the MUX output) must be stable during the setup/hold window around this clock edge. Leaving $S$ asynchronous means the MUX select line can still change at any time. If $S$ changes too close to the clock edge when the (delayed) write-enable is asserted, the MUX output will still be unstable, violating the register file's setup time. It could also change during the write operation, violating the hold time. Delaying the write-enable does not stabilize the data input.\n\nVerdict: **Incorrect**.\n\n**D. When multiple related control fields must cross from $C_{s}$ to $C_{d}$, transfer the control bundle using a request/acknowledge handshake or an asynchronous first-in first-out (FIFO), capture them with registers in $C_{d}$, and only then drive the multiplexer select with the registered $S$.**\n\nThis statement describes advanced, robust techniques for handling multi-bit CDC. While the problem focuses on a single signal $S$, in a real processor, $S$ would likely be part of a larger control word from the instruction decode/control unit. Transferring a bundle of related control signals requires ensuring their coherency. An asynchronous FIFO or a request/acknowledge handshake protocol are standard, correct methods to do this. These methods ensure that a stable, coherent multi-bit value is presented to the destination domain, which can then safely capture it into registers. Using the captured, registered value of $S$ to drive the multiplexer select would indeed solve the problem. This option describes a correct, general, and robust solution that is applicable to the context.\n\nVerdict: **Correct**.\n\n**E. A single-flip-flop synchronizer on $S$ is sufficient at $500\\,\\mathrm{MHz}$ because the probability of metastability decreases approximately linearly with the additional resolution time provided by a synchronizer.**\n\nThis statement is factually incorrect. A single-flip-flop synchronizer is not sufficient because its output can be metastable. If this metastable signal is fed into combinational logic (e.g., the MUX), it can cause glitches or invalid logic levels to propagate, defeating the purpose. The core principle of a $2$-FF synchronizer is that the second flip-flop allows a full clock period for the first flip-flop's potential metastability to resolve. Furthermore, the problem statement itself correctly recalls that the probability of unresolved metastability decays **exponentially** with the available resolution time, not linearly. The claim of linear decay is incorrect and significantly understates the benefit of adding resolution time.\n\nVerdict: **Incorrect**.\n\n**F. With destination clock at $500\\,\\mathrm{MHz}$ and metastability time constant $\\tau = 20\\,\\mathrm{ps}$, adding one extra destination clock period of resolution time (by using a $2$-flip-flop synchronizer instead of a $1$-flip-flop) increases the Mean Time Between Failures (MTBF) by a factor on the order of $e^{100}$.**\n\nThe Mean Time Between Failures (MTBF) due to metastability for a synchronizer is proportional to an exponential term involving the resolution time $t_r$ and the metastability time constant $\\tau$. Specifically, $MTBF \\propto e^{t_r/\\tau}$.\nA $2$-FF synchronizer provides one full destination clock period of additional resolution time ($t_r = T_d$) compared to a single stage where the output is used immediately.\nGiven:\nDestination clock frequency, $f_d = 500\\,\\mathrm{MHz}$.\nDestination clock period, $T_d = 1 / f_d = 1 / (500 \\times 10^6\\,\\mathrm{Hz}) = 2 \\times 10^{-9}\\,\\mathrm{s} = 2\\,\\mathrm{ns}$.\nMetastability time constant, $\\tau = 20\\,\\mathrm{ps} = 20 \\times 10^{-12}\\,\\mathrm{s}$.\nThe exponent for the MTBF improvement factor is $t_r/\\tau$:\n$$\n\\frac{t_r}{\\tau} = \\frac{T_d}{\\tau} = \\frac{2 \\times 10^{-9}\\,\\mathrm{s}}{20 \\times 10^{-12}\\,\\mathrm{s}} = \\frac{2000 \\times 10^{-12}\\,\\mathrm{s}}{20 \\times 10^{-12}\\,\\mathrm{s}} = 100\n$$\nTherefore, the MTBF is increased by a factor of $e^{100}$. The calculation is correct. This quantifies the dramatic improvement in reliability afforded by the second flip-flop in a synchronizer.\n\nVerdict: **Correct**.\n\n**G. Place the $2$-flip-flop synchronizer on the multiplexer data output instead of on its select $S$; this is preferable because it preserves the relative timing of control signals and eliminates the bug with lower latency.**\n\nThe MUX output is a multi-bit data bus (e.g., $32$ or $64$ bits). Placing a synchronizer here would mean applying independent $2$-FF synchronizers to each bit of this wide bus. As explained for option B, this is a dangerous design that leads to data incoherency. The correct and standard approach is to synchronize the single-bit control signal ($S$) *before* the MUX. This ensures the MUX selects the correct, stable data source, and the entire data word at the MUX output is correct and stable within the $C_d$ domain. The claim of lower latency is also unsubstantiated; both approaches add a latency of approximately $2$ destination clock cycles.\n\nVerdict: **Incorrect**.\n\n**H. Two-flip-flop synchronizers are appropriate for single-bit level signals crossing clock domains; for one-cycle pulses from the source domain, use a toggle-based scheme or stretch the pulse before the $2$-flip-flop synchronizer; for multi-bit values, use Gray coding or a handshake rather than per-bit $2$-flip-flop synchronizers.**\n\nThis statement provides an accurate and comprehensive summary of best practices for CDC design.\n1.  **Single-bit signals:** $2$-FF synchronizers are indeed the standard method for level-based single signals. This is correct.\n2.  **Pulses:** Short pulses can be missed by a synchronizer. Pulse stretching (making the pulse wider) or a toggle-based scheme (where an event is signaled by a change of level, 0->1 or 1->0) are standard, robust solutions for transferring pulse/event information across clock domains. This is correct.\n3.  **Multi-bit values:** It correctly warns against per-bit synchronizers for general multi-bit values. It suggests two valid techniques for maintaining coherency: Gray coding (for specific cases like counters where only one bit changes at a time) and handshakes (a general and robust method for any multi-bit data). This is also correct.\n\nThe entire statement is a correct enumeration of sound engineering principles for handling various CDC scenarios.\n\nVerdict: **Correct**.", "answer": "$$\\boxed{ADFH}$$", "id": "3632351"}]}