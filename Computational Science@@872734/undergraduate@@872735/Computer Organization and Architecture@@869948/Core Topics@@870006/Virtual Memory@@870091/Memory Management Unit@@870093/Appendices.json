{"hands_on_practices": [{"introduction": "Before diving into complex MMU behaviors, we must first understand the fundamental arithmetic that governs virtual memory systems. This exercise focuses on deriving the number of physical frames and page table entries from a system's core parameters: the widths of virtual and physical addresses ($v$ and $p_{a}$) and the page size ($p$). Mastering these basic calculations is the first step toward appreciating the scale of memory management structures and the design trade-offs they entail [@problem_id:3657823].", "problem": "A computer system uses a Memory Management Unit (MMU) implementing pure paging with fixed-size pages. The system has a Virtual Address (VA) width of $v$ bits and a Physical Address (PA) width of $p_{a}$ bits. Each page has size $p$ bytes. The MMU employs a single-level page table, and each Page Table Entry (PTE) maps one virtual page to one physical frame. Assume there is no segmentation, no superpages, no reserved regions, and that all addressable virtual space and physical memory are fully populated and usable. Also assume the page size is an exact power of two bytes so that the page offset field is well-defined.\n\nStarting from the core definitions of address decomposition in paging systems, derive the maximum number of distinct physical frames $F$ and the number of PTEs $N$ required for full coverage of the virtual address space, in terms of $v$, $p_{a}$, and $p$. Then, evaluate your derived expressions for the specific machine parameters $v = 36$, $p_{a} = 32$, and $p = 2^{12}$ bytes.\n\nPresent your final answer as a row matrix $\\left(F \\;\\; N\\right)$ with both entries as exact integers. No rounding is required, and no units should be included in the final answer.", "solution": "The user has asked for a critical validation and, if valid, a solution to a problem concerning a computer system's Memory Management Unit (MMU).\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- The system uses pure paging with fixed-size pages.\n- Virtual Address (VA) width is $v$ bits.\n- Physical Address (PA) width is $p_{a}$ bits.\n- Page size is $p$ bytes.\n- The page table is a single-level structure.\n- Each Page Table Entry (PTE) maps one virtual page to one physical frame.\n- It is assumed that there is no segmentation, no superpages, no reserved regions.\n- All addressable virtual space and physical memory are fully populated and usable.\n- The page size $p$ is an exact power of two.\n- Specific parameters for evaluation are $v = 36$, $p_{a} = 32$, and $p = 2^{12}$ bytes.\n- The objective is to derive expressions for the maximum number of distinct physical frames, $F$, and the number of PTEs, $N$, required for full coverage of the virtual address space, and then evaluate them for the given parameters.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem is firmly grounded in the fundamental principles of computer architecture and operating systems, specifically virtual memory management using paging. All terms and concepts are standard and well-defined.\n- **Well-Posed**: The problem is well-posed. It provides all necessary parameters ($v$, $p_a$, $p$) to uniquely determine the desired quantities ($F$, $N$). The simplifying assumptions (single-level page table, no segmentation) remove ambiguity and ensure a unique solution exists.\n- **Objective**: The problem statement is objective, using precise technical language without subjective or opinion-based claims.\n- **Completeness and Consistency**: The problem is self-contained and consistent. The given values ($v=36$, $p_a=32$, $p=2^{12}$) are plausible and do not contradict each other or the underlying principles. An architecture with a larger virtual address space than physical address space is a common design pattern.\n- **Other Flaws**: The problem is not scientifically unsound, non-formalizable, unrealistic, ill-posed, pseudo-profound, or outside scientific verifiability. It is a standard, solvable problem in computer organization.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\n### Solution Derivation\n\nThe analysis begins from the fundamental definitions of physical and virtual address spaces and their partitioning into frames and pages.\n\n**1. Derivation of the Number of Physical Frames ($F$)**\n\nThe physical address space is the set of all possible physical addresses. The size of this space is determined by the physical address width, $p_{a}$.\nTotal Physical Memory Size $= 2^{p_{a}}$ bytes.\n\nThis physical memory is partitioned into a set of fixed-size blocks called physical frames. The size of each frame is specified to be equal to the page size, $p$.\nFrame Size $= p$ bytes.\n\nThe maximum number of distinct physical frames, $F$, is the total size of physical memory divided by the size of a single frame.\n$$F = \\frac{\\text{Total Physical Memory Size}}{\\text{Frame Size}}$$\n$$F = \\frac{2^{p_{a}}}{p}$$\n\nThis expression gives the maximum number of physical frames that the hardware can support.\n\n**2. Derivation of the Number of Page Table Entries ($N$)**\n\nThe virtual address space is the set of all virtual addresses that a program can generate. The size of this space is determined by the virtual address width, $v$.\nTotal Virtual Address Space Size $= 2^{v}$ bytes.\n\nThis virtual address space is partitioned into fixed-size blocks called virtual pages. The size of a page is given as $p$.\nPage Size $= p$ bytes.\n\nThe problem states that the MMU must provide coverage for the entire virtual address space. In a single-level paging scheme, this requires one Page Table Entry (PTE) for each virtual page. Therefore, the total number of PTEs, $N$, must be equal to the total number of virtual pages.\n$$N = \\frac{\\text{Total Virtual Address Space Size}}{\\text{Page Size}}$$\n$$N = \\frac{2^{v}}{p}$$\n\n**3. Evaluation for Specific Machine Parameters**\n\nThe problem provides the following specific values:\n- Virtual address width, $v = 36$\n- Physical address width, $p_{a} = 32$\n- Page size, $p = 2^{12}$ bytes\n\nWe substitute these values into the derived expressions for $F$ and $N$.\n\nCalculation for $F$:\n$$F = \\frac{2^{p_{a}}}{p} = \\frac{2^{32}}{2^{12}}$$\nUsing the property of exponents $\\frac{a^m}{a^n} = a^{m-n}$:\n$$F = 2^{32 - 12} = 2^{20}$$\nTo find the integer value, we can use the fact that $2^{10} = 1024$:\n$$F = (2^{10})^2 = (1024)^2 = 1,048,576$$\nSo, the maximum number of distinct physical frames is $1,048,576$.\n\nCalculation for $N$:\n$$N = \\frac{2^{v}}{p} = \\frac{2^{36}}{2^{12}}$$\nUsing the same property of exponents:\n$$N = 2^{36 - 12} = 2^{24}$$\nTo find the integer value:\n$$N = 2^4 \\times 2^{20} = 16 \\times 1,048,576$$\nPerforming the multiplication:\n$$N = 16,777,216$$\nSo, the number of PTEs required for full coverage of the virtual address space is $16,777,216$.\n\nThe final answer is to be presented as a row matrix $(F \\;\\; N)$.", "answer": "$$\\boxed{\\begin{pmatrix} 1048576 & 16777216 \\end{pmatrix}}$$", "id": "3657823"}, {"introduction": "While address translation seems straightforward for accesses contained within a single page, real-world programs often perform memory operations that cross page boundaries. This practice explores how the MMU handles such an unaligned access, requiring multiple translations for a single instruction, and what happens when one of those translations fails. By analyzing this scenario, you will gain a deeper understanding of page faults and the principle of precise exceptions, which is critical for how hardware and operating systems cooperate to ensure memory accesses are both correct and secure [@problem_id:3657891].", "problem": "A process executes on a machine with page-based virtual memory and a byte-addressable architecture. The Memory Management Unit (MMU) translates each virtual page to a physical page using a page table, possibly cached in a Translation Lookaside Buffer (TLB). Pages are of size $P = 4096$ bytes. Consider a single instruction that performs a load of $w = 8$ bytes starting at virtual address $v = 0x0000000000000\\mathrm{FFB}$.\n\nAssume the following:\n- The first page that contains the starting address is valid and mapped.\n- The immediately following page is not mapped (no valid page table entry), and therefore any access to it would trigger an exception.\n\nFrom first principles, reason about how many page translations the MMU must perform to complete the load and the exception behavior if the second page is unmapped. Choose the option that best describes both the number of translations and the resulting fault semantics for this single $w$-byte access.\n\nA. The MMU performs $1$ translation because the instruction is a single memory operation; no fault occurs because caches retrieve data across page boundaries transparently.\n\nB. The MMU performs $2$ translations because the accessed byte range spans two pages; when translating the second page the MMU detects that it is unmapped and raises a page fault exception, the instruction aborts, and no partial data or side effects are architecturally visible.\n\nC. The MMU performs $2$ translations; the first $4$ bytes are returned from the mapped page, then a general protection fault is raised due to the unmapped second page, and the architectural state reflects the partial result of the load.\n\nD. The MMU performs $w = 8$ independent translations, one per byte accessed; an exception is deferred until all byte translations are attempted, guaranteeing that partial data from the mapped page becomes visible before the fault.", "solution": "The problem statement will be validated by breaking it down into its fundamental components and verifying their scientific and logical consistency.\n\n### Step 1: Extract Givens\n- **System Architecture**: Page-based virtual memory, byte-addressable.\n- **Translation Unit**: Memory Management Unit (MMU) handles virtual-to-physical address translation.\n- **Page Size**: $P = 4096$ bytes.\n- **Instruction**: A single load operation.\n- **Access Size**: $w = 8$ bytes.\n- **Starting Virtual Address**: $v = 0x0000000000000\\mathrm{FFB}$.\n- **Condition 1**: The virtual page containing the starting address $v$ is valid and mapped.\n- **Condition 2**: The virtual page immediately following the first one is not mapped. Any access to it will trigger an exception.\n\n### Step 2: Validate Using Extracted Givens\nThe problem describes a memory access that straddles a page boundary, a classic scenario in computer architecture.\n\n- **Scientific Groundedness**: The concepts of virtual memory, page tables, MMU, page faults, and byte-addressability are all fundamental and standard in computer organization and architecture. The page size of $4096$ bytes ($4$ KiB) is extremely common. An $8$-byte load is typical for a $64$-bit architecture (e.g., loading a `double` or `long long`). The scenario is scientifically and technically sound.\n- **Well-Posedness**: The problem provides all necessary information to determine the outcome. The starting address, access size, and page size allow for a precise calculation of the virtual addresses involved. The status of the relevant pages (mapped vs. unmapped) is explicitly stated. The question is specific and answerable.\n- **Objectivity**: The problem is stated in precise, objective, technical language, free from ambiguity or subjective claims.\n\nThe problem statement is valid. It is a well-posed, standard problem in computer architecture. We may proceed with the solution.\n\n### Derivation of Solution\nThe solution is derived from the first principles of virtual memory management.\n\n1.  **Determine the virtual address range of the memory access.**\n    The load operation is for $w=8$ bytes, starting at the virtual address $v = 0x0000000000000\\mathrm{FFB}$. The access spans the byte addresses from $v$ to $v + w - 1$.\n    - Start Address: $0x...0\\mathrm{FFB}$\n    - End Address: $0x...0\\mathrm{FFB} + 8 - 1 = 0x...0\\mathrm{FFB} + 7 = 0x...0\\mathrm{FFE} + 4 = 0x...0\\mathrm{FFF} + 3 = 0x...1002$.\n    The complete virtual address range for the load operation is $[0x0000000000000\\mathrm{FFB}, 0x0000000000001002]$.\n\n2.  **Identify the virtual pages spanned by this address range.**\n    The page size is $P = 4096$ bytes, which is $2^{12}$ bytes or $0x1000$ bytes in hexadecimal. A virtual address is partitioned into a virtual page number (VPN) and a page offset. The offset consists of the lower $12$ bits of the address.\n    - Page boundaries occur at multiples of $0x1000$. The first few pages are:\n        - Page 0: Addresses $[0x...0000, 0x...0\\mathrm{FFF}]$.\n        - Page 1: Addresses $[0x...1000, 0x...1\\mathrm{FFF}]$.\n        - and so on.\n    - The starting address of the access, $0x...0\\mathrm{FFB}$, falls within Page 0. Its VPN can be considered $0$ and its offset is $0\\mathrm{FFB}$.\n    - The ending address of the access, $0x...1002$, falls within Page 1. Its VPN is $1$ and its offset is $0x002$.\n    - Since the access starts in Page 0 and ends in Page 1, the single $8$-byte load operation spans two distinct virtual pages.\n\n3.  **Analyze the MMU's translation requirements.**\n    The MMU translates virtual page numbers (VPNs) into physical frame numbers (PFNs). Since the memory access touches two different virtual pages, the MMU must perform a translation for each of these pages to construct the full physical address range for the load.\n    - **Translation 1**: The MMU must translate the VPN for the first part of the access (the bytes from address $0x...0\\mathrm{FFB}$ to $0x...0\\mathrm{FFF}$). This corresponds to Page 0. The problem states that \"The first page that contains the starting address is valid and mapped.\" Therefore, this translation succeeds.\n    - **Translation 2**: The MMU must also translate the VPN for the second part of the access (the bytes from address $0x...1000$ to $0x...1002$). This corresponds to Page 1. The problem states that \"The immediately following page is not mapped.\" When the MMU attempts to look up the page table entry for Page 1, it will find that the entry is invalid (or not present). This event triggers a hardware exception.\n\n4.  **Analyze the exception semantics (atomicity of the instruction).**\n    The exception triggered by an access to an unmapped page is a **page fault**. Modern processors are designed with precise exception semantics. This means that when an instruction faults, the processor state is restored to the state that existed immediately before the faulting instruction began execution. No architectural state (such as the contents of the destination register for the load) is modified.\n    - This \"all-or-nothing\" behavior is crucial. It allows the operating system's page fault handler to resolve the fault (e.g., by loading the required page from disk into memory) and then restart the faulting instruction as if it had never been attempted.\n    - In this scenario, the MMU's attempt to translate the address for the second page ($0x...1000$) will fail. A page fault is immediately raised. The CPU will not proceed to load any data. It will discard any partial, speculative work done for the instruction, ensure no registers are updated, and transfer control to the OS. The program counter will be set to the address of the faulting load instruction.\n    - Therefore, the MMU attempts $2$ translations. The second one fails, raising a page fault. The instruction is aborted with no partial results made architecturally visible.\n\n### Option-by-Option Analysis\n\n- **A. The MMU performs $1$ translation because the instruction is a single memory operation; no fault occurs because caches retrieve data across page boundaries transparently.**\n  - The premise that the MMU performs only $1$ translation is incorrect. The number of translations is dictated by the number of distinct pages accessed, which is $2$.\n  - The claim that caches transparently bypass page-mapping faults is fundamentally incorrect. Caches work with the memory hierarchy, which includes the MMU. An unmapped page is an error condition that caching does not and cannot override.\n  - **Verdict**: Incorrect.\n\n- **B. The MMU performs $2$ translations because the accessed byte range spans two pages; when translating the second page the MMU detects that it is unmapped and raises a page fault exception, the instruction aborts, and no partial data or side effects are architecturally visible.**\n  - This statement correctly identifies that the access spans two pages, thus requiring $2$ translations.\n  - It correctly describes the consequence of accessing the unmapped second page: a page fault exception.\n  - It correctly describes the precise exception model of modern CPUs: the instruction is aborted, and no partial results or side effects become part of the architectural state. This aligns perfectly with our first-principles derivation.\n  - **Verdict**: Correct.\n\n- **C. The MMU performs $2$ translations; the first $4$ bytes are returned from the mapped page, then a general protection fault is raised due to the unmapped second page, and the architectural state reflects the partial result of the load.**\n  - The number of translations ($2$) is correct.\n  - The type of fault is typically a *page fault* for a non-present page, not a *general protection fault* (which is usually related to access rights on a present page).\n  - The claim that a partial result is made architecturally visible is incorrect, as it violates the principle of precise, restartable exceptions.\n  - **Verdict**: Incorrect.\n\n- **D. The MMU performs $w = 8$ independent translations, one per byte accessed; an exception is deferred until all byte translations are attempted, guaranteeing that partial data from the mapped page becomes visible before the fault.**\n  - The premise that the MMU performs a translation for each byte is incorrect. Translation is done on a per-page granularity. This would require $2$ translations, not $8$.\n  - The fault is not deferred. It is raised as soon as the invalid access is detected.\n  - The claim that partial data becomes visible is incorrect for the reasons already stated.\n  - **Verdict**: Incorrect.", "answer": "$$\\boxed{B}$$", "id": "3657891"}, {"introduction": "Address translation is essential but can be slow if every memory access requires consulting page tables in main memory. To accelerate this process, MMUs include a high-speed cache for recent translations called the Translation Lookaside Buffer (TLB). This exercise shifts our focus to performance by asking you to model the impact of TLB misses on a processor's overall Cycles Per Instruction ($CPI$). This hands-on analysis demonstrates the critical role of the TLB in making virtual memory practical and provides a quantitative framework for evaluating architectural design choices related to memory management [@problem_id:3657824].", "problem": "A processor implementing a Memory Management Unit (MMU) uses a software-managed Translation Lookaside Buffer (TLB), similar to Microprocessor without Interlocked Pipeline Stages (MIPS). On each memory reference, the MMU consults the TLB. When a translation is present in the TLB, the access proceeds without additional stall cycles beyond the baseline execution. When the translation is absent, a trap transfers control to the operating system, which runs a handler to resolve the miss and insert the appropriate TLB entry. Assume the following fundamental base of definitions and facts:\n\n- The expected cycles per instruction, called Cycles Per Instruction (CPI), can be decomposed into a baseline term and additional stall terms caused by events such as misses. This is an application of the definition of CPI and linearity of expectation.\n- The Translation Lookaside Buffer (TLB) miss rate is the fraction of memory references that result in a TLB miss.\n- For a software-managed TLB on Microprocessor without Interlocked Pipeline Stages (MIPS), a miss invokes a handler that saves the necessary state, locates the translation via a page table walk, writes the TLB entry using a privileged instruction, and restores state before returning. Suppose the handler resolves each miss in exactly $t_h$ cycles. Ignore page faults and data cache misses of handler code and page table entries, and assume that TLB hits overlap with the pipeline such that there is no extra stall cost on hits beyond the baseline CPI.\n\nGiven:\n- $C_{\\text{base}}$: the baseline Cycles Per Instruction absent any TLB misses.\n- $f_m$: the average number of memory references per instruction, treated as a nonnegative real number (for example, $f_m = 0.5$ means on average half a memory reference per instruction).\n- $m$: the TLB miss rate per memory reference, expressed as a decimal fraction (for example, $m = 0.01$ means one miss per one hundred references).\n- $t_h$: the cycles consumed by the TLB miss handler for each miss.\n\nUnder these assumptions, design a program that computes:\n1. The new Cycles Per Instruction $C_{\\text{new}}$ when TLB misses occur, based on $C_{\\text{base}}$, $f_m$, $m$, and $t_h$.\n2. The fractional overhead $o$ attributable solely to TLB misses, defined as the additional CPI due to TLB misses divided by the baseline CPI. Express $o$ as a decimal fraction.\n\nYour program must hard-code and evaluate the following test suite of parameter sets, chosen to cover a happy path and significant boundary conditions:\n- Test case $1$: $C_{\\text{base}} = 1.10$, $f_m = 0.35$, $m = 0.01$, $t_h = 120$.\n- Test case $2$ (boundary with zero miss rate): $C_{\\text{base}} = 1.00$, $f_m = 0.50$, $m = 0.00$, $t_h = 200$.\n- Test case $3$ (boundary with zero memory references): $C_{\\text{base}} = 1.30$, $f_m = 0.00$, $m = 0.05$, $t_h = 150$.\n- Test case $4$ (small miss rate with large handler cost): $C_{\\text{base}} = 0.90$, $f_m = 0.40$, $m = 0.0025$, $t_h = 200$.\n- Test case $5$ (efficient handler): $C_{\\text{base}} = 1.20$, $f_m = 0.30$, $m = 0.005$, $t_h = 60$.\n\nScientific realism conditions:\n- Treat $m$ as independent of instruction type and of $f_m$, and assume that $t_h$ fully stalls the pipeline for the duration of the handler.\n- Ignore secondary effects such as instruction cache pressure from the handler, pipeline refills, and speculative execution side-effects.\n\nOutput requirements:\n- For each test case, compute $C_{\\text{new}}$ and $o$.\n- Round each numeric result to $6$ decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list of two-element lists enclosed in square brackets, in the exact format $[[C_{\\text{new}},o],\\dots]$. For example, $[[1.234000,0.056000],[\\dots]]$.", "solution": "The problem statement is critically validated before proceeding to a solution.\n\n### Step 1: Extract Givens\n- **Baseline Cycles Per Instruction ($C_{\\text{base}}$)**: The CPI absent any TLB misses.\n- **Average memory references per instruction ($f_m$)**: A nonnegative real number.\n- **TLB miss rate per memory reference ($m$)**: A decimal fraction.\n- **TLB miss handler cost ($t_h$)**: The number of cycles consumed by the handler for each miss.\n- **New Cycles Per Instruction ($C_{\\text{new}}$)**: The CPI when TLB misses occur.\n- **Fractional overhead ($o$)**: The additional CPI due to TLB misses divided by the baseline CPI.\n- **Assumptions**:\n    - The CPI is decomposable: $C_{\\text{new}} = C_{\\text{base}} + \\text{CPI}_{\\text{stalls}}$.\n    - A TLB miss incurs a penalty of exactly $t_h$ cycles.\n    - TLB hits have zero additional stall cost.\n    - Page faults and cache misses for handler/page table data are ignored.\n- **Test Cases**:\n    1. $C_{\\text{base}} = 1.10$, $f_m = 0.35$, $m = 0.01$, $t_h = 120$.\n    2. $C_{\\text{base}} = 1.00$, $f_m = 0.50$, $m = 0.00$, $t_h = 200$.\n    3. $C_{\\text{base}} = 1.30$, $f_m = 0.00$, $m = 0.05$, $t_h = 150$.\n    4. $C_{\\text{base}} = 0.90$, $f_m = 0.40$, $m = 0.0025$, $t_h = 200$.\n    5. $C_{\\text{base}} = 1.20$, $f_m = 0.30$, $m = 0.005$, $t_h = 60$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the specified criteria:\n- **Scientifically Grounded**: The problem is firmly rooted in the principles of computer architecture. The CPI-based performance model ($C_{\\text{new}} = C_{\\text{base}} + \\text{stall\\_cycles\\_per\\_instruction}$) is a standard and fundamental method for analyzing processor performance. The role of the TLB, the concept of a software-managed miss handler, and the calculation of performance penalties are all core topics in this field. The stated assumptions are typical simplifications used to create a tractable, first-order model.\n- **Well-Posed**: The problem is well-posed. It requests the calculation of two specific metrics, $C_{\\text{new}}$ and $o$, and provides all necessary input variables ($C_{\\text{base}}$, $f_m$, $m$, $t_h$) and clear definitions to derive unique mathematical formulas for the outputs.\n- **Objective**: The problem is expressed in objective, quantitative language. The definitions are precise, and there are no subjective or ambiguous terms.\n- **Flaw Analysis**: The problem exhibits none of the specified flaws. It is not scientifically unsound, non-formalizable, incomplete, unrealistic (within its simplified model), ill-posed, or trivial. It represents a standard, formalizable exercise in quantitative processor performance analysis.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be provided.\n\n### Solution Derivation\nThe objective is to derive expressions for the new Cycles Per Instruction, $C_{\\text{new}}$, and the fractional overhead, $o$, based on the provided parameters.\n\nThe total CPI, $C_{\\text{new}}$, is the sum of the baseline CPI, $C_{\\text{base}}$, and the additional CPI component resulting from processor stalls. In this model, stalls are caused exclusively by TLB misses.\n$$\nC_{\\text{new}} = C_{\\text{base}} + C_{\\text{TLB\\_stall}}\n$$\nwhere $C_{\\text{TLB\\_stall}}$ represents the average number of stall cycles per instruction due to TLB misses.\n\nTo calculate $C_{\\text{TLB\\_stall}}$, we first determine the frequency of TLB misses per instruction.\n- The average number of memory references per instruction is given by $f_m$.\n- The probability of a TLB miss for any given memory reference is the miss rate, $m$.\n\nAssuming that TLB misses are independent events, the average number of TLB misses per instruction is the product of the number of memory references per instruction and the miss rate per reference.\n$$\n\\text{Misses per Instruction} = f_m \\cdot m\n$$\nEach TLB miss incurs a penalty of $t_h$ cycles. Therefore, the total stall cycles per instruction attributable to TLB misses is the number of misses per instruction multiplied by the cost per miss.\n$$\nC_{\\text{TLB\\_stall}} = (\\text{Misses per Instruction}) \\times (\\text{Cost per Miss}) = (f_m \\cdot m) \\cdot t_h\n$$\nSubstituting this back into the equation for $C_{\\text{new}}$, we obtain the final expression:\n$$\nC_{\\text{new}} = C_{\\text{base}} + f_m \\cdot m \\cdot t_h\n$$\nNext, we derive the expression for the fractional overhead, $o$. The problem defines $o$ as the additional CPI due to TLB misses divided by the baseline CPI.\nThe additional CPI due to TLB misses is precisely the $C_{\\text{TLB\\_stall}}$ term we just calculated.\n$$\no = \\frac{C_{\\text{TLB\\_stall}}}{C_{\\text{base}}}\n$$\nSubstituting the expression for $C_{\\text{TLB\\_stall}}$ gives:\n$$\no = \\frac{f_m \\cdot m \\cdot t_h}{C_{\\text{base}}}\n$$\nThese two derived formulas, for $C_{\\text{new}}$ and $o$, can be applied to each test case to compute the required results. For cases where $m=0$ or $f_m=0$, the product $f_m \\cdot m \\cdot t_h$ correctly evaluates to $0$, resulting in $C_{\\text{new}} = C_{\\text{base}}$ and $o = 0$, which is consistent with the physical scenario of no TLB miss stalls.", "answer": "[[1.520000,0.381818],[1.000000,0.000000],[1.300000,0.000000],[1.100000,0.222222],[1.290000,0.075000]]", "id": "3657824"}]}