{"hands_on_practices": [{"introduction": "This first practice problem provides a concrete look at how different ISA philosophies translate into real code. By hand-compiling a single arithmetic expression for stack, accumulator, register-memory, and load-store architectures, you will gain an intuitive understanding of a core trade-off in computer design: code density. This exercise will clarify how instruction formats and operand models directly impact the size of a program. [@problem_id:3653344]", "problem": "You are asked to evaluate code density across the four classical Instruction Set Architecture (ISA) classes for computing the expression $E = \\big((x+y)\\cdot(z-w)\\big)/(u+v)$, where the variables $x$, $y$, $z$, $w$, $u$, $v$ are stored in memory at distinct addresses, and the final result $E$ must be stored to a designated memory location $r$. Use only the minimal instruction sequences that correctly compute $E$ under each ISA’s operand model, and count the total code size in bits for each sequence using the instruction encodings specified below. Then, report a single value: the difference in bits between the largest and the smallest total code sizes among the four ISA classes.\n\nBase assumptions and encoding model, grounded in core definitions of Instruction Set Architecture (ISA) classes and instruction encoding fields:\n\n- Definitions:\n  - A stack machine uses zero-address arithmetic; operands are implicitly the top elements of a Last-In-First-Out stack.\n  - An accumulator machine has a single implicit accumulator register that participates in all arithmetic.\n  - A register-memory machine permits arithmetic between a general-purpose register and either another register or a memory operand.\n  - A load-store machine (reduced instruction set) only permits arithmetic between registers; all memory access is via explicit load and store.\n\n- Memory addresses:\n  - All memory operand addresses are absolute and encoded in 16-bit fields.\n  - There are no immediate literals; only memory and register operands are available.\n\n- Required arithmetic operations:\n  - Addition, subtraction, multiplication, and division are available in each ISA class with natural semantics. For subtraction and division, the order is left operand minus or divided by right operand as determined by the operand model of each ISA.\n\n- Instruction encodings:\n  1. Stack ISA:\n     - Zero-operand arithmetic instructions (ADD, SUB, MUL, DIV) are encoded in $8$ bits.\n     - PUSH and POP with a memory operand have $8$-bit opcode and one $16$-bit address operand, totaling $24$ bits each.\n     - Arithmetic semantics: ADD pops $S_{-1}$ and $S_{0}$ and pushes $S_{-1}+S_{0}$; SUB pushes $S_{-1}-S_{0}$; DIV pushes $S_{-1}/S_{0}$; MUL pushes $S_{-1}\\cdot S_{0}$.\n  2. Accumulator ISA:\n     - One-address instructions with the implicit accumulator $A$: LOAD $A,\\,[\\text{addr}]$, STORE $[\\text{addr}],\\,A$, and arithmetic A := A op $M[\\text{addr}]$ (ADD, SUB, MUL, DIV).\n     - All such instructions encode with an $8$-bit opcode plus one $16$-bit address, totaling $24$ bits each.\n  3. Register-memory ISA:\n     - There are $16$ general-purpose registers, each encoded in a 4-bit field.\n     - Register-register arithmetic (e.g., ADD $R_d,R_s$; SUB; MUL; DIV) are $16$ bits per instruction.\n     - Register-memory arithmetic and loads/stores of the form op $R,\\,[\\text{addr}]$ or STORE $[\\text{addr}],\\,R$ encode as $32$ bits per instruction (to accommodate an $8$-bit opcode, a $4$-bit register field, a $16$-bit address, and alignment/padding to a full number of bytes).\n  4. Load-store ISA:\n     - There are $16$ general-purpose registers, each encoded in a 4-bit field.\n     - All instructions are $32$ bits long.\n     - Arithmetic is register-register only (three-operand form where applicable), and memory is accessed only via explicit LOAD and STORE with absolute $16$-bit addresses.\n\n- Initial conditions:\n  - No register contains a useful initial value.\n  - The expression must be computed exactly as $E = \\big((x+y)\\cdot(z-w)\\big)/(u+v)$ and stored to memory location $r$.\n  - No micro-operations or implicit temporaries beyond those stated by the ISA model are allowed.\n\nTask:\n- For each ISA class, determine a shortest correct instruction sequence that computes $E$ and stores it to $r$, under the given models.\n- Using the encodings above, compute the total code size in bits for each sequence.\n- Let $S_{\\min}$ be the smallest of the four totals and $S_{\\max}$ be the largest. Compute $S_{\\max}-S_{\\min}$.\n- Express the final difference as a real number in bits. Do not include any units in your final boxed answer.", "solution": "The problem requires an analysis of code density for computing the expression $E = \\big((x+y)\\cdot(z-w)\\big)/(u+v)$ across four classical Instruction Set Architecture (ISA) classes: stack, accumulator, register-memory, and load-store. For each class, we must devise a minimal instruction sequence, calculate its total size in bits based on the provided encoding scheme, and finally determine the difference between the maximum and minimum code sizes obtained.\n\nFirst, the problem is validated and found to be well-posed and scientifically sound. It is a standard problem in computer architecture concerning ISA design trade-offs. The instruction encoding models are simplified but consistent representations of their respective classes. A minor ambiguity regarding the availability of temporary memory locations for the accumulator architecture is resolved by the standard and necessary assumption that such locations are available; without them, the expression cannot be computed, and the problem would be ill-posed. All other specifications are clear and sufficient to proceed.\n\nThe evaluation of the expression $E = \\frac{(x+y)(z-w)}{u+v}$ can be decomposed into the following steps:\n$1$. Compute $T_a = (x+y)$.\n$2$. Compute $T_b = (z-w)$.\n$3$. Compute $T_c = T_a \\cdot T_b$.\n$4$. Compute $T_d = (u+v)$.\n$5$. Compute $E = T_c / T_d$.\nThis requires a total of five arithmetic operations: two additions, one subtraction, one multiplication, and one division. All six variables ($x, y, z, w, u, v$) must be fetched from memory, and the final result $E$ must be stored back to memory location $r$.\n\nWe now analyze each ISA class in turn.\n\n**1. Stack ISA**\nA stack-based machine uses a last-in, first-out stack for operands. Arithmetic operations implicitly operate on the top elements of the stack. The expression evaluation naturally follows its Reverse Polish Notation (RPN) form: `x y + z w - * u v + /`.\n\nThe minimal instruction sequence is:\n1. `PUSH [x]`  ; Push value of $x$ onto the stack.\n2. `PUSH [y]`  ; Push value of $y$. Stack: $[(x), (y)]$.\n3. `ADD`        ; Pop $x, y$ and push $(x+y)$. Stack: $[(x+y)]$.\n4. `PUSH [z]`  ; Push value of $z$. Stack: $[(x+y), (z)]$.\n5. `PUSH [w]`  ; Push value of $w$. Stack: $[(x+y), (z), (w)]$.\n6. `SUB`        ; Pop $z, w$ and push $(z-w)$. Stack: $[(x+y), (z-w)]$.\n7. `MUL`        ; Pop $(x+y), (z-w)$ and push their product. Stack: $[(x+y)(z-w)]$.\n8. `PUSH [u]`  ; Push value of $u$. Stack: $[(x+y)(z-w), (u)]$.\n9. `PUSH [v]`  ; Push value of $v$. Stack: $[(x+y)(z-w), (u), (v)]$.\n10. `ADD`       ; Pop $u, v$ and push $(u+v)$. Stack: $[(x+y)(z-w), (u+v)]$.\n11. `DIV`       ; Pop product and sum, push quotient. Stack: $[E]$.\n12. `POP [r]`   ; Pop result and store into memory at address $r$.\n\nThe sequence requires $6$ `PUSH` operations, $1$ `POP` operation, and $5$ arithmetic operations.\n\nCalculation of code size:\n- PUSH and POP instructions are specified to be $24$ bits each ($8$-bit opcode + $16$-bit address). There are $7$ such instructions. Total size: $7 \\times 24 = 168$ bits.\n- Zero-operand arithmetic instructions are $8$ bits each. There are $5$ such instructions (two `ADD`, one `SUB`, one `MUL`, one `DIV`). Total size: $5 \\times 8 = 40$ bits.\n- Total code size for Stack ISA: $S_{stack} = 168 + 40 = 208$ bits.\n\n**2. Accumulator ISA**\nAn accumulator architecture uses a single implicit register, the accumulator ($A$), for all arithmetic operations. Operations typically take the form $A \\leftarrow A \\text{ op } M[\\text{addr}]$. Since there is only one register, intermediate results of sub-expressions must be stored in temporary memory locations (spilled). To compute $E = \\text{Numerator} / \\text{Denominator}$ where division is non-commutative ($A \\leftarrow A / M[\\text{addr}]$), an optimal strategy is to compute the denominator first and spill it to memory, then compute the numerator, leaving it in the accumulator for the final division. Let `temp1` and `temp2` be temporary memory locations.\n\nThe minimal instruction sequence is:\n1. `LOAD [u]`      ; $A \\leftarrow M[u]$\n2. `ADD [v]`       ; $A \\leftarrow A + M[v] = (u+v)$\n3. `STORE [temp1]` ; $M[\\text{temp1}] \\leftarrow (u+v)$ (Store the denominator)\n4. `LOAD [z]`      ; $A \\leftarrow M[z]$\n5. `SUB [w]`       ; $A \\leftarrow A - M[w] = (z-w)$\n6. `STORE [temp2]` ; $M[\\text{temp2}] \\leftarrow (z-w)$\n7. `LOAD [x]`      ; $A \\leftarrow M[x]$\n8. `ADD [y]`       ; $A \\leftarrow A + M[y] = (x+y)$\n9. `MUL [temp2]`    ; $A \\leftarrow A \\cdot M[\\text{temp2}] = (x+y)(z-w)$ (Numerator is now in A)\n10. `DIV [temp1]`   ; $A \\leftarrow A / M[\\text{temp1}] = E$\n11. `STORE [r]`     ; $M[r] \\leftarrow A$\n\nThis sequence with 11 instructions is minimal.\n\nCalculation of code size:\n- Each instruction has an $8$-bit opcode and a $16$-bit address, totaling $24$ bits.\n- There are $11$ instructions in the sequence.\n- Total code size for Accumulator ISA: $S_{acc} = 11 \\times 24 = 264$ bits.\n\n**3. Register-Memory ISA**\nThis ISA allows arithmetic between two registers or a register and a memory location. There are $16$ registers. It is more efficient to use registers for temporary values than memory.\n\nThe minimal instruction sequence is:\n1. `LOAD R1, [x]`   ; $R_1 \\leftarrow M[x]$\n2. `ADD R1, [y]`    ; $R_1 \\leftarrow R_1 + M[y] = (x+y)$\n3. `LOAD R2, [z]`   ; $R_2 \\leftarrow M[z]$\n4. `SUB R2, [w]`    ; $R_2 \\leftarrow R_2 - M[w] = (z-w)$\n5. `MUL R1, R2`     ; $R_1 \\leftarrow R_1 \\cdot R_2 = (x+y)(z-w)$\n6. `LOAD R3, [u]`   ; $R_3 \\leftarrow M[u]$\n7. `ADD R3, [v]`    ; $R_3 \\leftarrow R_3 + M[v] = (u+v)$\n8. `DIV R1, R3`     ; $R_1 \\leftarrow R_1 / R_3 = E$\n9. `STORE [r], R1`  ; $M[r] \\leftarrow R_1$\n\nThis sequence uses $3$ registers and is minimal.\n\nCalculation of code size:\n- Register-memory operations (LOAD, STORE, ADD/SUB with memory operand) are $32$ bits each. There are $7$ such instructions. Total size: $7 \\times 32 = 224$ bits.\n- Register-register arithmetic (MUL, DIV) are $16$ bits each. There are $2$ such instructions. Total size: $2 \\times 16 = 32$ bits.\n- Total code size for Register-Memory ISA: $S_{regmem} = 224 + 32 = 256$ bits.\n\n**4. Load-Store ISA**\nIn a load-store (or RISC-style) architecture, arithmetic operations can only be performed on operands residing in registers. Memory is accessed exclusively through `LOAD` and `STORE` instructions. We assume a three-operand format for arithmetic instructions (e.g., `ADD Rd, Rs1, Rs2`).\n\nThe minimal instruction sequence is:\n1. `LOAD R1, [x]`    ; Load all required operands from memory.\n2. `LOAD R2, [y]`\n3. `LOAD R3, [z]`\n4. `LOAD R4, [w]`\n5. `LOAD R5, [u]`\n6. `LOAD R6, [v]`\n7. `ADD R7, R1, R2`  ; $R_7 \\leftarrow (x+y)$\n8. `SUB R8, R3, R4`  ; $R_8 \\leftarrow (z-w)$\n9. `MUL R7, R7, R8`  ; $R_7 \\leftarrow R_7 \\cdot R_8 = (x+y)(z-w)$ (reusing R7)\n10. `ADD R8, R5, R6` ; $R_8 \\leftarrow (u+v)$ (reusing R8)\n11. `DIV R7, R7, R8` ; $R_7 \\leftarrow R_7 / R_8 = E$\n12. `STORE [r], R7` ; Store the final result.\n\nThis sequence requires $6$ `LOAD` instructions, $5$ arithmetic instructions, and $1$ `STORE` instruction, for a total of $12$ instructions.\n\nCalculation of code size:\n- All instructions are specified to be $32$ bits long.\n- There are $12$ instructions in the sequence.\n- Total code size for Load-Store ISA: $S_{loadstore} = 12 \\times 32 = 384$ bits.\n\n**Summary and Final Calculation**\nWe have computed the minimal code size for each ISA class:\n- $S_{stack} = 208$ bits\n- $S_{acc} = 264$ bits\n- $S_{regmem} = 256$ bits\n- $S_{loadstore} = 384$ bits\n\nThe smallest code size is $S_{\\min} = S_{stack} = 208$ bits.\nThe largest code size is $S_{\\max} = S_{loadstore} = 384$ bits.\n\nThe problem asks for the difference between the largest and the smallest total code sizes.\n$S_{\\max} - S_{\\min} = 384 - 208 = 176$ bits.", "answer": "$$\\boxed{176}$$", "id": "3653344"}, {"introduction": "Moving from a single expression to a general data structure, this exercise challenges you to analyze the performance of stack versus register-based ISAs as the problem scales. You will derive expressions for the number of operations required to evaluate a balanced binary tree, a common structure for representing computations. This analysis highlights the fundamental differences in how these architectures handle temporary values and reveals important scaling properties, such as the logarithmic register requirement for load-store machines. [@problem_id:3653331]", "problem": "A balanced binary expression tree is a finite acyclic graph in which every internal node has exactly two children (binary operators), every leaf holds a single operand, and the left and right subtrees of any node differ in height by at most one. Let the tree have $n$ leaves (operands). Consider evaluating this expression on a Stack Instruction Set Architecture (ISA), where an instruction either pushes an operand to the stack or applies a binary operator that pops two operands from the stack and then pushes the resulting value back onto the stack. Assume an evaluation order that leaves the final result on the top of the stack with no extra pushes or pops beyond those dictated by operand loads and operator execution, and assume there are no side effects and no common subexpression reuse.\n\nFor comparison, consider evaluation on a Load-Store Register ISA (Instruction Set Architecture) using only registers, aiming to minimize register spills. A register spill is any temporary value that must be saved to memory due to insufficient registers. The minimal number of registers required to evaluate an expression tree without any spills is equal to the Strahler number (also known as the Sethi–Ullman number) of the tree. A leaf requires one register; an internal node requires either the maximum of its children’s requirements or one more than that maximum when both children require the same number of registers.\n\nStarting from the definitions above and the general tree property that the number of edges equals the number of nodes minus one, derive closed-form expressions in terms of $n$ for:\n- the total number of pushes executed,\n- the total number of pops executed,\n- the minimal number of registers required to evaluate the balanced binary expression tree without spills.\n\nExpress your final answer as three closed-form expressions in terms of $n$. No rounding is required.", "solution": "Let the expression tree be a full binary tree (every internal node has exactly two children) with $n$ leaves. Denote the number of internal nodes by $m$.\n\nStep 1: Relate $m$ and $n$ using fundamental graph properties.\nA tree with $N$ total nodes has exactly $N-1$ edges. In a full binary tree, each internal node contributes exactly $2$ outgoing edges to its two children, so the total number of edges is $2m$. The total number of nodes is $m + n$ (internal nodes plus leaves). Equating the two expressions for the number of edges gives\n$$\n2m = (m + n) - 1 \\quad \\Rightarrow \\quad m = n - 1.\n$$\n\nStep 2: Count pushes on a Stack ISA.\nBy definition of the evaluation model:\n- Each leaf operand is pushed exactly once onto the stack, contributing $n$ pushes.\n- Each binary operator at an internal node consumes two operands via pops and then produces one result that is pushed back onto the stack. Therefore, each internal node contributes $1$ push.\nSince there are $m = n - 1$ internal nodes, operator-result pushes contribute $n - 1$ pushes.\nTherefore, the total number of pushes is\n$$\nn + (n - 1) = 2n - 1.\n$$\n\nStep 3: Count pops on a Stack ISA.\nEach internal node applies a binary operator that must pop two operands. No extra pops are assumed at the end, since the final result remains on the stack. Therefore, the total number of pops is\n$$\n2m = 2(n - 1) = 2n - 2.\n$$\n\nStep 4: Minimal registers for a balanced binary expression tree.\nWe use the Strahler number characterization derived from first principles of register needs:\n- A leaf requires $1$ register (to hold its value).\n- For an internal node whose left and right subtrees require $i$ and $j$ registers, respectively, the minimal register requirement at the node is\n  - $\\max(i, j)$ if $i \\neq j$, since one can evaluate the larger subtree first using $\\max(i, j)$ registers, keep its single result in $1$ register, and then evaluate the smaller subtree within the same budget without needing an extra register;\n  - $i + 1$ if $i = j$, since evaluating one subtree to a single result occupies $1$ register, and then evaluating the other subtree requires $i$ registers concurrently; thus one needs $i + 1$ registers to avoid spilling.\nThis recurrence is the Strahler/Sethi–Ullman labeling.\n\nFor a balanced binary tree with $n$ leaves, let $R(n)$ denote the minimal number of registers. We claim\n$$\nR(n) = \\left\\lfloor \\log_{2}(n) \\right\\rfloor + 1.\n$$\nWe justify this as follows.\n\nFirst, for a perfect balanced tree with $n = 2^{k}$ leaves, every level combines subtrees of equal register need, so the label increases by $1$ at each internal level. Leaves have label $1$, and there are $k$ internal levels, so the root requires $k + 1$ registers:\n$$\nR(2^{k}) = k + 1 = \\log_{2}(2^{k}) + 1.\n$$\n\nSecond, for balanced trees with $2^{k} < n < 2^{k+1}$, the largest complete balanced subtrees that can appear have at most $2^{k}$ leaves. Evaluating such a subtree requires $k + 1$ registers, and the other side requires at most $k + 1$ registers. If both sides are labeled $k + 1$, the root requires $(k + 1) + 1 = k + 2$ registers; however, balanced partitioning of $n$ leaves into $\\lfloor n/2 \\rfloor$ and $\\lceil n/2 \\rceil$ ensures that at least one side has fewer than $2^{k}$ leaves whenever $n < 2^{k+1}$. Therefore, at the root, one child has register label $k + 1$ and the other has at most $k$ (they differ by at most one), yielding a root label of $\\max(k+1, k) = k + 1$ by the recurrence. This shows that for $2^{k} \\leq n \\leq 2^{k+1} - 1$,\n$$\nR(n) = k + 1 = \\left\\lfloor \\log_{2}(n) \\right\\rfloor + 1.\n$$\n\nThus the minimal number of registers needed to evaluate a balanced binary expression tree with $n$ leaves without spilling is $\\left\\lfloor \\log_{2}(n) \\right\\rfloor + 1$.\n\nStep 5: Assemble the expressions.\n- Total pushes: $2n - 1$.\n- Total pops: $2n - 2$.\n- Minimal registers: $\\left\\lfloor \\log_{2}(n) \\right\\rfloor + 1$.\n\nThese are closed-form expressions in terms of $n$.", "answer": "$$\\boxed{\\begin{pmatrix}2n - 1 & 2n - 2 & \\left\\lfloor \\log_{2}(n) \\right\\rfloor + 1\\end{pmatrix}}$$", "id": "3653331"}, {"introduction": "This final practice transitions from analyzing existing designs to determining design requirements. Instead of evaluating a specific tree, you will determine the minimum number of registers a processor needs to guarantee that *any* binary expression tree of a given height can be evaluated without resorting to slow memory spills. Solving this problem requires applying the principles of optimal code generation to a worst-case scenario, a crucial skill for both compiler writers and hardware architects. [@problem_id:3653353]", "problem": "You are designing a code generator for a Load-Store Instruction Set Architecture (Instruction Set Architecture (ISA)) that enforces the following rules for evaluating arithmetic expressions:\n- All arithmetic and logical operations are binary and execute only on registers: each instruction takes exactly two source registers and produces a result in a destination register (three-operand form).\n- Memory access is permitted only via explicit load and store instructions; there are no implicit memory operands for arithmetic instructions.\n- Leaves of an expression tree denote memory-resident operands that must be loaded into a register before use.\n- No spilling is allowed: once evaluation begins, no intermediate result may be stored to memory except for a final store of the root result, which does not count toward the register requirement.\n\nA binary expression is modeled as a full binary tree where each internal node has exactly two children and corresponds to a binary operator, and each leaf corresponds to an operand. The height of a tree is defined to be the number of edges on the longest path from the root to any leaf. Let $h \\in \\mathbb{N}$ denote the height of the expression tree. You are free to choose the evaluation order of the left and right subtrees at each internal node as long as the semantics of the binary operation are preserved.\n\nUsing only the above fundamental constraints and definitions, derive, from first principles, the minimal number of general-purpose registers (General-Purpose Registers (GPRs)) that is sufficient and also necessary to guarantee that any binary expression tree of height $h$ can be evaluated without spills on this Load-Store ISA. Express your final answer as a closed-form analytic expression in $h$. Do not provide an inequality or an equation. No rounding is needed.", "solution": "The problem requires the derivation of the minimal number of general-purpose registers (GPRs) that is both sufficient and necessary to evaluate any binary expression tree of height $h$ on a specified Load-Store Instruction Set Architecture (ISA) without spilling intermediate results to memory.\n\nLet $R(T)$ be the minimum number of registers required to evaluate the expression represented by a tree $T$. The rules of the ISA dictate the process.\nThe base case for our recursive analysis is a leaf of the expression tree. A leaf represents a memory-resident operand. According to the rules, it must be loaded into a register before it can be used. This operation requires one register. Thus, for any leaf node $l$, the register requirement is:\n$$R(l) = 1$$\n\nNow, consider an internal node $N$ of the tree. This node represents a binary operation. The problem states this is a full binary tree, where each internal node has exactly two children. Let the left and right children of $N$ be the roots of subtrees $T_L$ and $T_R$, respectively. Let $r_L = R(T_L)$ and $r_R = R(T_R)$ be the register requirements for the left and right subtrees.\n\nTo evaluate the operation at $N$, we must first compute the values of the expressions for $T_L$ and $T_R$. The problem allows choosing the evaluation order of these subtrees. Let us first analyze the case where we evaluate $T_L$ and then $T_R$.\n1.  Evaluation of $T_L$: This sub-computation requires $r_L$ registers. Upon completion, the result of $T_L$ is held in one of these registers.\n2.  Evaluation of $T_R$: While evaluating $T_R$, the result from $T_L$ must be preserved in its register. Therefore, the evaluation of $T_R$, which requires $r_R$ registers, must proceed using a pool of registers that does not include the one holding $T_L$'s result. If we have a total of $k$ registers available, one is occupied, leaving $k-1$ for the computation of $T_R$. To avoid spilling, it must be that $k-1 \\ge r_R$, which implies $k \\ge r_R+1$.\n3.  Final Operation: After $T_R$ is evaluated, its result is in a register. We now have the result of $T_L$ in one register and the result of $T_R$ in another. The binary operation at node $N$ is then performed using a three-operand instruction on these two registers, storing the final result in a destination register.\n\nThe total number of registers $k$ needed during this entire process (evaluate $T_L$ then $T_R$) must be sufficient for all stages. During the first stage, $r_L$ registers are needed. During the second stage, $r_R$ registers are needed for the computation of $T_R$, plus one register to hold the result of $T_L$, for a total of $r_R+1$. Therefore, the total number of registers required for this evaluation order is $\\max(r_L, r_R+1)$.\n\nBy symmetry, if we choose to evaluate $T_R$ first, followed by $T_L$, the number of registers required is $\\max(r_R, r_L+1)$.\n\nSince we can choose the order that minimizes the resource cost, the register requirement for the tree rooted at $N$, $R(T_N)$, is:\n$$R(T_N) = \\min(\\max(r_L, r_R+1), \\max(r_R, r_L+1))$$\n\nLet's simplify this expression by considering the relationship between $r_L$ and $r_R$:\n- If $r_L = r_R$: The expression becomes $\\min(\\max(r_L, r_L+1), \\max(r_L, r_L+1)) = r_L+1$.\n- If $r_L > r_R$: The expression is $\\min(\\max(r_L, r_R+1), \\max(r_R, r_L+1))$. Since $r_L > r_R$, it follows that $r_L \\ge r_R+1$. Thus, $\\max(r_L, r_R+1) = r_L$. The second term is $\\max(r_R, r_L+1) = r_L+1$. The minimum of these is $\\min(r_L, r_L+1) = r_L$. In this case, the optimal strategy is to evaluate the more complex subtree ($T_L$) first.\n- If $r_R > r_L$: By symmetry, the requirement is $r_R$.\n\nWe can summarize the recurrence for the register requirement of a node $N$ as:\n$$R(T_N) = \\begin{cases} r_L + 1 & \\text{if } r_L = r_R \\\\ \\max(r_L, r_R) & \\text{if } r_L \\neq r_R \\end{cases}$$\n\nThe problem asks for a number of registers that is sufficient and necessary for *any* binary expression tree of height $h$. This is equivalent to finding the maximum possible register requirement among all trees of height $h$. Let this quantity be $K(h)$.\n$$K(h) = \\max \\{ R(T) \\mid \\text{height}(T) = h \\}$$\n\nFrom the recurrence relation for $R(T_N)$, we observe that the register requirement for a parent node increases (by $1$) only if its children have identical register requirements. If the children's requirements differ, the parent's requirement is simply the maximum of the children's, showing no growth. To construct a tree of height $h$ that maximizes the register count, we should maximize the number of nodes whose subtrees have equal register requirements. This is achieved by making the tree as balanced as possible in terms of register needs at each level. This structure corresponds to a perfect binary tree, where the subtrees of any node have the same height.\n\nLet us determine the register requirement for a perfect binary tree of height $h$.\nThe height $h$ is defined as the number of edges on the longest path. A binary expression tree must have at least one internal node, so $h \\ge 1$.\n- Base Case ($h=1$): A perfect binary tree of height $1$ consists of a root and two leaf children. For each leaf, the register requirement is $1$. So, $r_L=1$ and $r_R=1$. Since $r_L=r_R$, the total requirement is $r_L+1 = 1+1=2$. Thus, $K(1)=2$.\n- Recursive Step: A perfect binary tree of height $h$ has two subtrees that are both perfect binary trees of height $h-1$. The register requirement for each of these subtrees is $K(h-1)$. Since the requirements are equal, the total requirement for the tree of height $h$ is $K(h-1)+1$.\n\nThis gives the recurrence relation $K(h) = K(h-1)+1$ with the initial condition $K(1)=2$. This is a simple arithmetic progression, whose solution is:\n$$K(h) = K(1) + (h-1) = 2 + h - 1 = h+1$$\n\nThis construction of a perfect binary tree demonstrates that for any $h \\ge 1$, there exists a tree of height $h$ that requires $h+1$ registers. Therefore, $h+1$ is a *necessary* number of registers.\n\nNext, we must show that $h+1$ registers are also *sufficient* for any tree of height $h$. We prove by induction that for any tree $T$ of height $h$, $R(T) \\le h+1$.\n- Base Case ($h=1$): Any tree of height $1$ has two leaf children, so $r_L=1$ and $r_R=1$. The requirement is $R(T) = 1+1=2$. Our formula gives $1+1=2$. The inequality $R(T) \\le h+1$ holds as $2 \\le 1+1$.\n- Inductive Hypothesis: Assume that for any tree $T'$ of height $k < h$, the register requirement satisfies $R(T') \\le k+1$.\n- Inductive Step: Consider an arbitrary tree $T$ of height $h$. Its root has subtrees $T_L$ and $T_R$ with heights $h_L$ and $h_R$ respectively, where $\\max(h_L, h_R) = h-1$.\n  By the inductive hypothesis, $r_L = R(T_L) \\le h_L+1$ and $r_R = R(T_R) \\le h_R+1$.\n  The requirement for $T$ is $R(T) = \\min(\\max(r_L, r_R+1), \\max(r_R, r_L+1))$.\n  Let's find an upper bound for $R(T)$. Without loss of generality, assume we evaluate the subtree with the larger register requirement first. Let's say $r_L \\ge r_R$. Then the optimal evaluation order is $T_L$ then $T_R$, and the register requirement is $\\max(r_L, r_R+1)$.\n  Using the inductive hypothesis:\n  $r_L \\le h_L+1 \\le (h-1)+1 = h$.\n  $r_R+1 \\le (h_R+1)+1 = h_R+2$. Since $h_R \\le h-1$, we have $h_R+2 \\le (h-1)+2 = h+1$.\n  Therefore, $R(T) = \\max(r_L, r_R+1) \\le \\max(h, h+1) = h+1$.\n  If $r_R > r_L$, the argument is symmetric and also yields $R(T) \\le h+1$.\nThis completes the induction, proving that $h+1$ registers are *sufficient* to evaluate any binary expression tree of height $h$.\n\nSince $h+1$ is both necessary and sufficient, it is the minimal number of registers required. The final expression is a function of $h$.", "answer": "$$\n\\boxed{h+1}\n$$", "id": "3653353"}]}