{"hands_on_practices": [{"introduction": "Mastering computational engineering begins with a solid command of the fundamentals. This first exercise [@problem_id:13578] isolates the most essential operation in matrix algebra: multiplication. By focusing on calculating a single entry of a product matrix, you will practice the core 'row-by-column' dot product rule, which is the engine behind countless advanced applications.", "problem": "Consider a $3 \\times 3$ matrix $A$ defined by symbolic constants as its entries:\n$$\nA = \\begin{pmatrix}\n\\alpha & \\beta & \\gamma \\\\\n\\delta & \\epsilon & \\zeta \\\\\n\\eta & \\theta & \\iota\n\\end{pmatrix}\n$$\nThe square of this matrix is denoted as $A^2 = AA$. The product of two $3 \\times 3$ matrices, say $C = XY$, is defined such that each entry $c_{ij}$ is the dot product of the $i$-th row of $X$ and the $j$-th column of $Y$. Specifically, the formula for the entry in the $i$-th row and $j$-th column is:\n$$\nc_{ij} = \\sum_{k=1}^{3} x_{ik} y_{kj}\n$$\nYour task is to derive the expression for the entry in the first row and third column of the matrix $A^2$. Let this entry be denoted as $(A^2)_{13}$.", "solution": "Let the matrix product $A^2 = AA$ be denoted by the matrix $B$. Thus, $B = A^2$. We want to find the entry in the first row and third column of $B$, which is denoted as $b_{13}$.\n\nAccording to the definition of matrix multiplication, the entry $b_{ij}$ of the product matrix $B = AA$ is given by the formula:\n$$\nb_{ij} = \\sum_{k=1}^{3} a_{ik} a_{kj}\n$$\nWe are asked to find the specific entry $b_{13}$, which corresponds to setting $i=1$ and $j=3$:\n$$\nb_{13} = \\sum_{k=1}^{3} a_{1k} a_{k3}\n$$\nExpanding the summation gives us three terms:\n$$\nb_{13} = a_{11}a_{13} + a_{12}a_{23} + a_{13}a_{33}\n$$\nThis expression represents the dot product of the first row of $A$ with the third column of $A$.\n\nThe given matrix $A$ is:\n$$\nA = \\begin{pmatrix}\na_{11} & a_{12} & a_{13} \\\\\na_{21} & a_{22} & a_{23} \\\\\na_{31} & a_{32} & a_{33}\n\\end{pmatrix}\n= \\begin{pmatrix}\n\\alpha & \\beta & \\gamma \\\\\n\\delta & \\epsilon & \\zeta \\\\\n\\eta & \\theta & \\iota\n\\end{pmatrix}\n$$\nFrom this matrix, we can identify the specific entries needed for our calculation:\n- The elements of the first row are $a_{11} = \\alpha$, $a_{12} = \\beta$, and $a_{13} = \\gamma$.\n- The elements of the third column are $a_{13} = \\gamma$, $a_{23} = \\zeta$, and $a_{33} = \\iota$.\n\nNow, we substitute these symbolic values into the expanded formula for $b_{13}$:\n$$\nb_{13} = (\\alpha)(\\gamma) + (\\beta)(\\zeta) + (\\gamma)(\\iota)\n$$\nSimplifying the expression, we get:\n$$\nb_{13} = \\alpha\\gamma + \\beta\\zeta + \\gamma\\iota\n$$\nThis is the final expression for the entry in the first row and third column of $A^2$.", "answer": "$$\n\\boxed{\\alpha\\gamma + \\beta\\zeta + \\gamma\\iota}\n$$", "id": "13578"}, {"introduction": "Matrix algebra provides the language to describe and analyze physical systems. In this practice [@problem_id:2411736], we move from abstract rules to a tangible engineering model of a simple truss structure. You will learn to construct a system's stiffness matrix $K$, a cornerstone of computational mechanics, and then use its determinant, $\\det(K)$, to predict a critical physical behavior: structural stability. This exercise demonstrates the power of matrix properties to yield profound insights into real-world engineering problems.", "problem": "A planar pin-jointed truss consists of two straight bars connecting a free node to two fixed supports. Let node $1$ be fixed at global coordinates $(0,0)$, node $2$ be fixed at global coordinates $(b,0)$ with $b>0$, and node $3$ be free at global coordinates $(a,h)$, where $a$ and $h$ are real parameters. Bar $e_{1}$ connects node $1$ to node $3$, and bar $e_{2}$ connects node $2$ to node $3$. Each bar is linear elastic, massless, and carries only axial force, with constant axial rigidity $E A$ and undeformed lengths determined by the given coordinates. Small-displacement kinematics apply, all joints are ideal frictionless pins, and supports at nodes $1$ and $2$ prevent displacement in both global directions.\n\nAfter statically condensing the fixed degrees of freedom at nodes $1$ and $2$, the remaining condensed global stiffness matrix $K \\in \\mathbb{R}^{2 \\times 2}$ maps the displacement vector of node $3$, $u=\\begin{pmatrix}u_{3x}\\\\ u_{3y}\\end{pmatrix}$, to the equivalent nodal force vector $f=\\begin{pmatrix}f_{3x}\\\\ f_{3y}\\end{pmatrix}$ via $f=K u$ in the global basis.\n\nUsing only first principles of linearized truss behavior, form $K$ for this system and then compute the exact analytic expression of its determinant $\\det(K)$ as a function of $E$, $A$, $a$, $b$, and $h$. Report $\\det(K)$ as a single closed-form expression. No rounding is required. Additionally, based on your result, identify the geometric condition on $a$, $b$, and $h$ under which $K$ is singular, but do not include that condition in your final reported answer.", "solution": "The problem statement must first be subjected to rigorous validation before a solution is attempted.\n\n### Step 1: Extract Givens\n- **System**: A planar pin-jointed truss with two straight bars.\n- **Nodes**:\n    - Node $1$: Fixed support at global coordinates $(0,0)$.\n    - Node $2$: Fixed support at global coordinates $(b,0)$, where $b>0$.\n    - Node $3$: Free node at global coordinates $(a,h)$.\n- **Elements (Bars)**:\n    - Bar $e_1$: Connects node $1$ to node $3$.\n    - Bar $e_2$: Connects node $2$ to node $3$.\n- **Material and Geometric Properties**:\n    - Each bar is linear elastic, massless, and carries only axial force.\n    - Constant axial rigidity is $EA$.\n    - Undeformed lengths are determined by the initial node coordinates.\n- **Assumptions**:\n    - Small-displacement kinematics apply.\n    - All joints are ideal frictionless pins.\n    - Supports at nodes $1$ and $2$ are fixed (prevent displacement in both global directions).\n- **Mathematical Formulation**:\n    - The condensed global stiffness matrix $K \\in \\mathbb{R}^{2 \\times 2}$ relates the displacement vector of node $3$, $u=\\begin{pmatrix}u_{3x}\\\\ u_{3y}\\end{pmatrix}$, to the nodal force vector $f=\\begin{pmatrix}f_{3x}\\\\ f_{3y}\\end{pmatrix}$ via the equation $f=K u$.\n- **Task**:\n    1. Form the matrix $K$ using first principles.\n    2. Compute the exact analytic expression for its determinant, $\\det(K)$, as a function of $E$, $A$, $a$, $b$, and $h$.\n    3. Identify the geometric condition for which $K$ is singular.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the validation criteria:\n- **Scientifically Grounded**: The problem is a standard, fundamental exercise in the field of structural mechanics, specifically using the direct stiffness method for truss analysis. All principles involved (linear elasticity, small-displacement theory, matrix methods) are well-established in computational engineering.\n- **Well-Posed**: The problem is clearly defined. The geometry, material properties, and boundary conditions are specified, allowing for the construction of a unique condensed stiffness matrix. The task to compute its determinant is unambiguous.\n- **Objective**: The problem statement is expressed in precise, objective mathematical and engineering terminology, free of any subjective or speculative content.\n- **Completeness and Consistency**: The problem is self-contained and provides all necessary information. There are no contradictions. The condition $b>0$ ensures that nodes $1$ and $2$ are distinct.\n\n### Step 3: Verdict and Action\nThe problem is scientifically sound, well-posed, and objective. It is deemed **valid**. We may proceed with the solution.\n\nThe solution requires the application of the direct stiffness method. The condensed stiffness matrix $K$ for the free node $3$ is the sum of the contributions from each element connected to it. The contribution of an element $e$ to the stiffness matrix of its connected nodes is a $4 \\times 4$ matrix in global coordinates. Since nodes $1$ and $2$ are fixed, their displacements are zero. We are interested only in the $2 \\times 2$ sub-matrix that relates the forces at node $3$ to the displacements of node $3$. This sub-matrix for a single element connecting a fixed node to a free node is given by:\n$$\nK_e = \\frac{EA}{L}\n\\begin{pmatrix}\nc^2 & cs \\\\\ncs & s^2\n\\end{pmatrix}\n$$\nwhere $L$ is the length of the element, and $c$ and $s$ are the cosines and sines of the angle the element makes with the positive global $x$-axis, respectively. The total condensed stiffness matrix is the sum of the contributions from bar $e_1$ and bar $e_2$: $K = K_1 + K_2$.\n\n**Bar 1 (connecting node 1 at $(0,0)$ to node 3 at $(a,h)$):**\nThe length of bar $e_1$ is $L_1 = \\sqrt{(a-0)^2 + (h-0)^2} = \\sqrt{a^2+h^2}$.\nThe direction cosines are:\n$$\nc_1 = \\frac{a-0}{L_1} = \\frac{a}{\\sqrt{a^2+h^2}}\n$$\n$$\ns_1 = \\frac{h-0}{L_1} = \\frac{h}{\\sqrt{a^2+h^2}}\n$$\nThe stiffness contribution from bar $e_1$ is:\n$$\nK_1 = \\frac{EA}{L_1}\n\\begin{pmatrix}\nc_1^2 & c_1 s_1 \\\\\nc_1 s_1 & s_1^2\n\\end{pmatrix}\n= \\frac{EA}{\\sqrt{a^2+h^2}}\n\\begin{pmatrix}\n\\frac{a^2}{a^2+h^2} & \\frac{ah}{a^2+h^2} \\\\\n\\frac{ah}{a^2+h^2} & \\frac{h^2}{a^2+h^2}\n\\end{pmatrix}\n= \\frac{EA}{(a^2+h^2)^{3/2}}\n\\begin{pmatrix}\na^2 & ah \\\\\nah & h^2\n\\end{pmatrix}\n$$\n\n**Bar 2 (connecting node 2 at $(b,0)$ to node 3 at $(a,h)$):**\nThe length of bar $e_2$ is $L_2 = \\sqrt{(a-b)^2 + (h-0)^2} = \\sqrt{(a-b)^2+h^2}$.\nThe direction cosines are:\n$$\nc_2 = \\frac{a-b}{L_2} = \\frac{a-b}{\\sqrt{(a-b)^2+h^2}}\n$$\n$$\ns_2 = \\frac{h-0}{L_2} = \\frac{h}{\\sqrt{(a-b)^2+h^2}}\n$$\nThe stiffness contribution from bar $e_2$ is:\n$$\nK_2 = \\frac{EA}{L_2}\n\\begin{pmatrix}\nc_2^2 & c_2 s_2 \\\\\nc_2 s_2 & s_2^2\n\\end{pmatrix}\n= \\frac{EA}{\\sqrt{(a-b)^2+h^2}}\n\\begin{pmatrix}\n\\frac{(a-b)^2}{(a-b)^2+h^2} & \\frac{(a-b)h}{(a-b)^2+h^2} \\\\\n\\frac{(a-b)h}{(a-b)^2+h^2} & \\frac{h^2}{(a-b)^2+h^2}\n\\end{pmatrix}\n= \\frac{EA}{((a-b)^2+h^2)^{3/2}}\n\\begin{pmatrix}\n(a-b)^2 & (a-b)h \\\\\n(a-b)h & h^2\n\\end{pmatrix}\n$$\n\n**Total Condensed Stiffness Matrix $K$:**\nThe total stiffness matrix $K$ is the sum $K=K_1+K_2$.\n$$\nK = \\begin{pmatrix} K_{11} & K_{12} \\\\ K_{21} & K_{22} \\end{pmatrix} = K_1 + K_2\n$$\nThe components are:\n$$\nK_{11} = EA \\left( \\frac{a^2}{(a^2+h^2)^{3/2}} + \\frac{(a-b)^2}{((a-b)^2+h^2)^{3/2}} \\right)\n$$\n$$\nK_{12} = K_{21} = EA \\left( \\frac{ah}{(a^2+h^2)^{3/2}} + \\frac{(a-b)h}{((a-b)^2+h^2)^{3/2}} \\right)\n$$\n$$\nK_{22} = EA \\left( \\frac{h^2}{(a^2+h^2)^{3/2}} + \\frac{h^2}{((a-b)^2+h^2)^{3/2}} \\right)\n$$\n\n**Determinant of $K$:**\nWe must compute $\\det(K) = K_{11}K_{22} - K_{12}^2$. For simplicity in algebra, let us define two constants:\n$$\nC_1 = \\frac{1}{(a^2+h^2)^{3/2}} \\quad \\text{and} \\quad C_2 = \\frac{1}{((a-b)^2+h^2)^{3/2}}\n$$\nWith these, the components become:\n$K_{11} = EA(C_1 a^2 + C_2(a-b)^2)$\n$K_{12} = EA(C_1 ah + C_2(a-b)h)$\n$K_{22} = EA(C_1 h^2 + C_2 h^2) = EAh^2(C_1+C_2)$\n\nNow, we compute the determinant:\n$$\n\\det(K) = K_{11}K_{22} - K_{12}^2\n$$\n$$\n\\frac{\\det(K)}{(EA)^2} = (C_1 a^2 + C_2(a-b)^2) h^2(C_1+C_2) - (C_1 ah + C_2(a-b)h)^2\n$$\nFactoring out $h^2$ from the entire expression:\n$$\n\\frac{\\det(K)}{(EA)^2} = h^2 \\left[ (C_1 a^2 + C_2(a-b)^2)(C_1+C_2) - (C_1 a + C_2(a-b))^2 \\right]\n$$\nExpanding the terms inside the brackets:\n$$\n[ \\dots ] = (C_1^2 a^2 + C_1 C_2 a^2 + C_1 C_2 (a-b)^2 + C_2^2(a-b)^2) - (C_1^2 a^2 + 2C_1 C_2 a(a-b) + C_2^2(a-b)^2)\n$$\nThe terms $C_1^2 a^2$ and $C_2^2(a-b)^2$ cancel out. We are left with:\n$$\n[ \\dots ] = C_1 C_2 a^2 + C_1 C_2 (a-b)^2 - 2C_1 C_2 a(a-b)\n$$\nFactoring out $C_1 C_2$:\n$$\n[ \\dots ] = C_1 C_2 [a^2 + (a-b)^2 - 2a(a-b)]\n$$\n$$\n[ \\dots ] = C_1 C_2 [a^2 + (a^2 - 2ab + b^2) - (2a^2 - 2ab)]\n$$\n$$\n[ \\dots ] = C_1 C_2 [a^2 + a^2 - 2ab + b^2 - 2a^2 + 2ab] = C_1 C_2 b^2\n$$\nSubstituting this back into the expression for the determinant:\n$$\n\\frac{\\det(K)}{(EA)^2} = h^2 (C_1 C_2 b^2)\n$$\n$$\n\\det(K) = (EA)^2 b^2 h^2 C_1 C_2\n$$\nFinally, substituting the definitions of $C_1$ and $C_2$:\n$$\n\\det(K) = (EA)^2 b^2 h^2 \\left( \\frac{1}{(a^2+h^2)^{3/2}} \\right) \\left( \\frac{1}{((a-b)^2+h^2)^{3/2}} \\right)\n$$\nThis simplifies to the final closed-form expression:\n$$\n\\det(K) = \\frac{(EA)^2 b^2 h^2}{[(a^2+h^2)((a-b)^2+h^2)]^{3/2}}\n$$\n\n**Singularity Condition**:\nThe stiffness matrix $K$ is singular if and only if $\\det(K) = 0$. Given that $E, A, b$ are positive constants, the determinant is zero if and only if $h^2=0$, which implies $h=0$. The denominator is non-zero, assuming the free node does not coincide with a support. The geometric condition for singularity is $h=0$. This corresponds to the case where all three nodes are collinear, resulting in a mechanism that is unstable to forces applied transverse to the line of the bars. This is a basic result of structural stability.", "answer": "$$\n\\boxed{\\frac{(EA)^{2} b^{2} h^{2}}{[(a^{2}+h^{2})((a-b)^{2}+h^{2})]^{\\frac{3}{2}}}}\n$$", "id": "2411736"}, {"introduction": "Theoretical understanding must ultimately be translated into efficient computation. This final practice [@problem_id:2411766] bridges the gap between pen-and-paper mathematics and practical software implementation. You will tackle a problem central to large-scale computational engineering: performing matrix-vector multiplication $y = Ax$ efficiently by exploiting sparsity. By deriving and implementing an algorithm for this operation, you will gain hands-on experience with the data structures and logic that make modern simulations feasible.", "problem": "In computational engineering, large linear systems arising from discretized partial differential equations are frequently sparse, meaning most entries of the system matrix are zero. Let $A \\in \\mathbb{R}^{m \\times n}$ be a sparse matrix and $x \\in \\mathbb{R}^{n}$ a vector. The foundational definition of matrix-vector multiplication is $y = A x$ with components $y_{i} = \\sum_{j=0}^{n-1} A_{ij} x_{j}$ for each $i \\in \\{0,1,\\dots,m-1\\}$. Efficient computation requires a storage scheme that avoids storing and operating on explicit zeros. One widely used representation is Compressed Sparse Row (CSR), which stores all nonzero entries grouped by row using three one-dimensional arrays: $data \\in \\mathbb{R}^{\\mathrm{nnz}}$, $indices \\in \\mathbb{Z}^{\\mathrm{nnz}}$, and $indptr \\in \\mathbb{Z}^{m+1}$, where $\\mathrm{nnz}$ is the number of stored nonzeros. Conceptually, for a given row $i$, the contiguous slice $k \\in \\{ indptr[i], indptr[i+1]-1 \\}$ enumerates the nonzeros of row $i$, with column index $j = indices[k]$ and value $A_{ij} = data[k]$.\n\nTask: Starting from the fundamental definition $y_{i} = \\sum_{j=0}^{n-1} A_{ij} x_{j}$ and the CSR data semantics above, derive a correct algorithm to compute $y = A x$ that accesses exactly the stored nonzero values and no explicit zeros. Then implement a program that:\n- Takes a predefined test suite of sparse matrices specified in coordinate form as a list of triplets $(i,j,v)$ with $i \\in \\{0,\\dots,m-1\\}$, $j \\in \\{0,\\dots,n-1\\}$, and $v \\in \\mathbb{R}$, and a vector $x \\in \\mathbb{R}^{n}$.\n- Assembles each matrix into CSR by summing duplicate coordinates $(i,j)$ to a single entry, discarding any entries whose assembled value becomes exactly zero after summation, and sorting column indices in strictly ascending order within each row. Assume $0$-based indexing.\n- Computes $y = A x$ using only the CSR representation.\n- Produces a single line of output containing the list of results for all test cases, each result being the output vector $y$ for that case. The format must be a single Python-like list literal with no spaces: for example, $[[1,2],[3,4]]$. All floating-point outputs must be rounded to six decimal places; integers should be printed without a decimal point. If a rounded floating-point value is an integer, print it as an integer (for example, round $3.000000$ to $3$).\n\nUse only logic and definitions from matrix algebra; do not rely on any external sparse linear algebra libraries.\n\nTest suite (each case is given by $(m,n,\\mathcal{S},x)$, where $\\mathcal{S}$ is the multiset of coordinates $(i,j,v)$):\n- Case $1$ (happy path, square, unsorted, duplicates): $m = 5$, $n = 5$, \n  $\\mathcal{S} = \\{ (0,3,2), (0,0,10), (0,4,-1), (0,3,3), (1,2,-2), (1,1,7), (2,2,4), (2,4,8), (2,0,1), (3,3,6), (4,1,-3), (4,4,2), (4,2,5) \\}$,\n  $x = [1.5, -2.0, 0.5, -1.0, 3.0]$.\n- Case $2$ (rectangular, empty row, duplicates): $m = 3$, $n = 5$,\n  $\\mathcal{S} = \\{ (0,1,3), (0,4,-1), (0,0,2), (2,3,-2), (2,2,4), (2,2,1), (2,0,5) \\}$,\n  $x = [1, 0, -1, 2, -3]$.\n- Case $3$ (diagonal, mixed signs): $m = 4$, $n = 4$,\n  $\\mathcal{S} = \\{ (0,0,-1), (1,1,2), (2,2,-3), (3,3,4) \\}$,\n  $x = [0.5, -1.5, 2.0, -2.5]$.\n- Case $4$ (zero matrix): $m = 3$, $n = 3$, $\\mathcal{S} = \\varnothing$, $x = [7, -8, 9]$.\n- Case $5$ (smallest nontrivial, duplicates cancelling): $m = 1$, $n = 1$, $\\mathcal{S} = \\{ (0,0,2), (0,0,-5), (0,0,1) \\}$, $x = [4]$.\n\nAngle units are not applicable. There are no physical units.\n\nYour program should produce a single line of output containing the results as a comma-separated list of the output vectors for all cases, enclosed in square brackets, with no spaces. For example, the format is $[[y^{(1)}_0,\\dots],[y^{(2)}_0,\\dots],\\dots]$ where each $y^{(k)}$ is the vector for case $k$ printed as specified above.", "solution": "The task is to derive and implement a correct algorithm for sparse matrix-vector multiplication, $y = Ax$, where the matrix $A$ is represented in Compressed Sparse Row (CSR) format. The derivation must be based on fundamental principles of matrix algebra.\n\nThe foundational definition of the product of a matrix $A \\in \\mathbb{R}^{m \\times n}$ and a vector $x \\in \\mathbb{R}^{n}$ is a vector $y \\in \\mathbb{R}^{m}$ whose components $y_i$ are given by the dot product of the $i$-th row of $A$ with the vector $x$. For each row index $i \\in \\{0, 1, \\dots, m-1\\}$, the component $y_i$ is calculated as:\n$$ y_i = \\sum_{j=0}^{n-1} A_{ij} x_j $$\nFor a sparse matrix, most of the entries $A_{ij}$ are zero. A computationally efficient algorithm must avoid the trivial operations where $A_{ij}=0$, as these terms do not contribute to the sum. The CSR format is engineered for this purpose. It represents the matrix $A$ using three one-dimensional arrays:\n1.  $data \\in \\mathbb{R}^{\\mathrm{nnz}}$: A contiguous array of the non-zero values of $A$, ordered row by row. Here, $\\mathrm{nnz}$ is the number of stored non-zero entries.\n2.  $indices \\in \\mathbb{Z}^{\\mathrm{nnz}}$: An array of the same size, $\\mathrm{nnz}$, containing the column index $j$ for each corresponding value in the $data$ array.\n3.  $indptr \\in \\mathbb{Z}^{m+1}$: An array that stores pointers to the start of each row's data within the $data$ and $indices$ arrays. The non-zero entries for row $i$ are located in the slice from index $indptr[i]$ (inclusive) to $indptr[i+1]$ (exclusive).\n\nWe must formalize the relationship between the standard matrix notation $A_{ij}$ and the CSR representation. For a given row $i$, the loop for $k$ from $indptr[i]$ to $indptr[i+1]-1$ iterates through all stored entries of that row. For each such index $k$, the matrix element's value is $v = data[k]$ and its column is $j = indices[k]$. This means $A_{i, indices[k]} = data[k]$. All other entries $A_{ij}$ for row $i$ are zero by definition of the sparse storage.\n\nWe can now substitute this structural property into the fundamental definition of $y_i$. The summation over all column indices $j \\in \\{0, \\dots, n-1\\}$ can be replaced by a restricted summation over only those columns that correspond to stored non-zero entries. These are precisely the columns given by the $indices$ array for the slice corresponding to row $i$.\n\nThe summation for $y_i$ thus becomes:\n$$ y_i = \\sum_{k=indptr[i]}^{indptr[i+1]-1} A_{i, indices[k]} \\cdot x_{indices[k]} $$\nBy substituting the CSR value, $A_{i, indices[k]} = data[k]$, we arrive at the final, computationally efficient formula that operates solely on the stored non-zero values:\n$$ y_i = \\sum_{k=indptr[i]}^{indptr[i+1]-1} data[k] \\cdot x_{indices[k]} $$\nThis relation forms the basis of our algorithm. It requires initializing an output vector $y$ to zeros and then iterating through each row $i$ of the matrix. For each row, we compute the sum of products of the non-zero values with the corresponding elements of the vector $x$, as indexed by the $indices$ array, and store the result in $y_i$.\n\nThe implementation consists of two primary stages:\n1.  **CSR Assembly from Coordinates**: The input matrix, provided as a multiset of $(i, j, v)$ coordinate triplets, must be converted to the CSR format. This procedure involves:\n    a. Aggregating values for duplicate $(i, j)$ coordinates. A temporary data structure, such as a list of dictionaries where each dictionary maps column indices to values for a single row, is suitable for this aggregation.\n    b. Filtering out any entries where the aggregated value is exactly zero, as specified.\n    c. Sorting the non-zero entries within each row by their column index in strictly ascending order.\n    d. Constructing the final $data$, $indices$, and $indptr$ arrays from this processed, sorted, and filtered information. The $indptr$ array is built by computing the cumulative sum of the counts of non-zero elements in each row.\n\n2.  **Matrix-Vector Multiplication**: With the CSR representation $(data, indices, indptr)$ and the vector $x$ available, the product vector $y$ is computed by directly implementing the derived formula. An outer loop iterates over the rows $i \\in \\{0, \\dots, m-1\\}$. A nested loop iterates over the non-zero element index $k \\in \\{indptr[i], \\dots, indptr[i+1]-1\\}$, accumulating the products $data[k] \\cdot x_{indices[k]}$ into the corresponding component $y_i$.\n\nThis two-stage process guarantees correctness by strict adherence to the mathematical definitions and achieves computational efficiency by leveraging the sparse storage scheme to eliminate all operations involving zero-valued matrix entries.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the sparse matrix-vector multiplication problem for a suite of test cases.\n    \"\"\"\n    # Execution Environment:\n    # language: Python 3.12\n    # libraries:\n    #   - name: numpy, version: 1.23.5\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        {\"m\": 5, \"n\": 5,\n         \"S\": [(0, 3, 2), (0, 0, 10), (0, 4, -1), (0, 3, 3), (1, 2, -2), (1, 1, 7),\n               (2, 2, 4), (2, 4, 8), (2, 0, 1), (3, 3, 6), (4, 1, -3), (4, 4, 2), (4, 2, 5)],\n         \"x\": [1.5, -2.0, 0.5, -1.0, 3.0]},\n        # Case 2\n        {\"m\": 3, \"n\": 5,\n         \"S\": [(0, 1, 3), (0, 4, -1), (0, 0, 2), (2, 3, -2), (2, 2, 4), (2, 2, 1), (2, 0, 5)],\n         \"x\": [1, 0, -1, 2, -3]},\n        # Case 3\n        {\"m\": 4, \"n\": 4,\n         \"S\": [(0, 0, -1), (1, 1, 2), (2, 2, -3), (3, 3, 4)],\n         \"x\": [0.5, -1.5, 2.0, -2.5]},\n        # Case 4\n        {\"m\": 3, \"n\": 3, \"S\": [], \"x\": [7, -8, 9]},\n        # Case 5\n        {\"m\": 1, \"n\": 1, \"S\": [(0, 0, 2), (0, 0, -5), (0, 0, 1)], \"x\": [4]}\n    ]\n\n    def assemble_csr(m, n, S):\n        \"\"\"\n        Assembles a sparse matrix in CSR format from a list of coordinate (COO) triplets.\n        \"\"\"\n        # Step 1: Aggregate duplicate entries and store by row\n        rows = [{} for _ in range(m)]\n        for i, j, v in S:\n            if 0 <= i < m and 0 <= j < n:\n                rows[i][j] = rows[i].get(j, 0.0) + v\n\n        data = []\n        indices = []\n        indptr = np.zeros(m + 1, dtype=int)\n        \n        # Step 2: Build data, indices, and indptr arrays\n        nnz = 0\n        for i in range(m):\n            indptr[i] = nnz\n            # Sort column indices for the current row\n            sorted_cols = sorted(rows[i].keys())\n            for j in sorted_cols:\n                val = rows[i][j]\n                # Discard entries that sum to exactly zero\n                if val != 0.0:\n                    data.append(val)\n                    indices.append(j)\n                    nnz += 1\n        indptr[m] = nnz\n        \n        return np.array(data), np.array(indices, dtype=int), indptr\n\n    def matvec_csr(m, csr_data, x):\n        \"\"\"\n        Computes the matrix-vector product y = Ax using CSR representation.\n        \"\"\"\n        data, indices, indptr = csr_data\n        y = np.zeros(m, dtype=float)\n        \n        for i in range(m):\n            row_sum = 0.0\n            start_ptr = indptr[i]\n            end_ptr = indptr[i+1]\n            for k in range(start_ptr, end_ptr):\n                val = data[k]\n                col_idx = indices[k]\n                row_sum += val * x[col_idx]\n            y[i] = row_sum\n            \n        return y\n\n    def format_number(num):\n        \"\"\"\n        Formats a number according to the problem's output specification.\n        Rounds to 6 decimal places. Prints as integer if it rounds to an integer.\n        \"\"\"\n        rounded_num = round(num, 6)\n        if rounded_num == int(rounded_num):\n            return str(int(rounded_num))\n        else:\n            return f\"{rounded_num:.6f}\"\n\n    def format_vector(vec):\n        \"\"\"\n        Formats a vector into the required string representation '[v0,v1,...]'.\n        \"\"\"\n        formatted_components = [format_number(v) for v in vec]\n        return f\"[{','.join(formatted_components)}]\"\n\n    results = []\n    for case in test_cases:\n        m, n, S, x_list = case[\"m\"], case[\"n\"], case[\"S\"], case[\"x\"]\n        x_vec = np.array(x_list, dtype=float)\n        \n        csr_matrix_data = assemble_csr(m, n, S)\n        y_vec = matvec_csr(m, csr_matrix_data, x_vec)\n        \n        results.append(format_vector(y_vec))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2411766"}]}