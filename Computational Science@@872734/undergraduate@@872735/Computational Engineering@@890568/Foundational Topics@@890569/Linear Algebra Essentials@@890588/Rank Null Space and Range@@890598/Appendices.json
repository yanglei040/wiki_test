{"hands_on_practices": [{"introduction": "Rank-one matrices represent the simplest, non-trivial linear operators and serve as fundamental building blocks in many advanced methods, including model reduction and statistical analysis. This exercise explores the properties of a matrix formed by an outer product, $A = uv^T$, which is a canonical example of a rank-one matrix. By applying the core definitions of range and null space, you will gain a concrete understanding of how the structure of a matrix directly determines the geometric properties of the transformation it represents [@problem_id:2431359].", "problem": "In a reduced-order sensing model for a thermal system, a measurement operator is modeled as a rank-one map that takes a state vector in a low-dimensional subspace to a measured displacement along a fixed instrument direction. Specifically, let $u \\in \\mathbb{R}^{5}$ and $v \\in \\mathbb{R}^{3}$ be nonzero column vectors, and define the measurement matrix $A \\in \\mathbb{R}^{5 \\times 3}$ by the outer product $A = u v^{T}$. The map $A$ takes an input $x \\in \\mathbb{R}^{3}$ to the output $A x \\in \\mathbb{R}^{5}$. Starting from the fundamental definitions of range, null space, and rank for linear maps, first determine the structure of the range and the null space of $A$, and then determine the rank of $A$. Finally, compute the scalar quantity $S$ defined by\n$$\nS = \\dim(\\operatorname{range}(A)) + \\dim(\\operatorname{null}(A)).\n$$\nExpress your final answer as a single real number. No units are required. Do not round.", "solution": "The problem statement has been rigorously validated. The givens are:\n1. $u \\in \\mathbb{R}^{5}$ is a nonzero column vector.\n2. $v \\in \\mathbb{R}^{3}$ is a nonzero column vector.\n3. The matrix $A \\in \\mathbb{R}^{5 \\times 3}$ is defined by the outer product $A = u v^{T}$.\n4. The linear map is $x \\mapsto Ax$, where $x \\in \\mathbb{R}^{3}$.\n5. The quantity to compute is $S = \\dim(\\operatorname{range}(A)) + \\dim(\\operatorname{null}(A))$.\n\nThe problem is scientifically grounded in linear algebra, is well-posed with all necessary information provided and no contradictions, and is stated objectively. It is a valid problem. We proceed to the solution.\n\nThe problem requires an analysis based on the fundamental definitions of the range, null space, and rank of a linear transformation represented by the matrix $A$.\n\nThe range of $A$, denoted $\\operatorname{range}(A)$, is the set of all possible outputs $Ax$ for any vector $x$ in the domain $\\mathbb{R}^{3}$. This is also known as the column space of $A$.\n$$ \\operatorname{range}(A) = \\{ y \\in \\mathbb{R}^{5} \\mid y = Ax \\text{ for some } x \\in \\mathbb{R}^{3} \\} $$\nGiven the definition $A = u v^{T}$, any vector in the range can be written as:\n$$ y = Ax = (u v^{T}) x $$\nBy the associativity of matrix multiplication, this expression becomes:\n$$ y = u (v^{T} x) $$\nThe term $v^{T}x$ is the dot product of the vectors $v$ and $x$. Since $v \\in \\mathbb{R}^{3}$ and $x \\in \\mathbb{R}^{3}$, $v^{T}$ is a $1 \\times 3$ row vector and $x$ is a $3 \\times 1$ column vector. Their product $v^{T}x$ is a $1 \\times 1$ matrix, which is a scalar. Let us denote this scalar by $\\alpha = v^{T}x$.\nThus, any vector $y$ in the range of $A$ is of the form $y = \\alpha u$. This means that every vector in the range of $A$ is a scalar multiple of the fixed vector $u$. The set of all scalar multiples of a single vector is the span of that vector.\n$$ \\operatorname{range}(A) = \\operatorname{span}(u) $$\nWe are given that $u$ is a nonzero vector. A basis for the span of a single nonzero vector is the vector itself. The dimension of a vector space is the number of vectors in its basis. Therefore, the dimension of the range of $A$ is $1$.\n$$ \\dim(\\operatorname{range}(A)) = 1 $$\n\nThe rank of a matrix is defined as the dimension of its range.\n$$ \\operatorname{rank}(A) = \\dim(\\operatorname{range}(A)) $$\nFrom our analysis, we conclude that the rank of $A$ is $1$.\n$$ \\operatorname{rank}(A) = 1 $$\n\nThe null space of $A$, denoted $\\operatorname{null}(A)$, is the set of all vectors $x$ in the domain $\\mathbb{R}^{3}$ that are mapped to the zero vector in the codomain $\\mathbb{R}^{5}$.\n$$ \\operatorname{null}(A) = \\{ x \\in \\mathbb{R}^{3} \\mid Ax = 0 \\} $$\nWe substitute the expression for $Ax$:\n$$ u(v^{T}x) = 0 $$\nWe are given that $u$ is a nonzero vector. For the product of a nonzero vector $u$ and a scalar $\\alpha = v^{T}x$ to be the zero vector, the scalar must be zero.\n$$ v^{T}x = 0 $$\nThis equation defines the null space of $A$. It consists of all vectors $x \\in \\mathbb{R}^{3}$ that are orthogonal to the vector $v$. Geometrically, the set of all vectors in $\\mathbb{R}^{3}$ orthogonal to a single given nonzero vector $v$ forms a plane through the origin. A plane through the origin in $\\mathbb{R}^{3}$ is a two-dimensional subspace.\nTo be more formal, the set $\\{x \\in \\mathbb{R}^{3} \\mid v^T x = 0\\}$ is the orthogonal complement of the subspace spanned by $v$, denoted $(\\operatorname{span}(v))^{\\perp}$, within the space $\\mathbb{R}^3$. Since $v$ is a nonzero vector, $\\dim(\\operatorname{span}(v)) = 1$. For any subspace $W$ of a finite-dimensional inner product space $V$, we know that $\\dim(V) = \\dim(W) + \\dim(W^{\\perp})$. In our case, $V = \\mathbb{R}^{3}$ and $W = \\operatorname{span}(v)$.\n$$ \\dim(\\mathbb{R}^{3}) = \\dim(\\operatorname{span}(v)) + \\dim((\\operatorname{span}(v))^{\\perp}) $$\n$$ 3 = 1 + \\dim(\\operatorname{null}(A)) $$\nFrom this, it is clear that the dimension of the null space is $2$.\n$$ \\dim(\\operatorname{null}(A)) = 2 $$\n\nFinally, we are asked to compute the scalar quantity $S$:\n$$ S = \\dim(\\operatorname{range}(A)) + \\dim(\\operatorname{null}(A)) $$\nSubstituting the dimensions we have found:\n$$ S = 1 + 2 = 3 $$\nThis result is a direct verification of the rank-nullity theorem for the linear map $A: \\mathbb{R}^{3} \\to \\mathbb{R}^{5}$. The theorem states that the dimension of the domain of a linear map is equal to the sum of the dimension of its range (rank) and the dimension of its null space (nullity).\n$$ \\dim(\\text{domain of } A) = \\operatorname{rank}(A) + \\dim(\\operatorname{null}(A)) $$\nIn this problem, the domain is $\\mathbb{R}^{3}$, so its dimension is $3$. Our calculation confirms this fundamental theorem.\n$$ 3 = 1 + 2 $$\nThe value of $S$ is therefore $3$.", "answer": "$$\n\\boxed{3}\n$$", "id": "2431359"}, {"introduction": "In many computational engineering tasks, such as constrained optimization or data fitting, it is necessary to project vectors onto a specific subspace. This practice moves from analyzing a given matrix to constructing one that performs a desired function. You will build an orthogonal projection matrix that maps vectors onto a null space, a common procedure for enforcing linear constraints or finding the closest point in a subspace to a given data point [@problem_id:2431352].", "problem": "In computational engineering, feasibility under a linear equality constraint is often enforced by orthogonally projecting a candidate vector onto the constraint manifold. Consider the standard Euclidean inner product on $\\mathbb{R}^{3}$ and the linear constraint defined by the matrix $A \\in \\mathbb{R}^{1 \\times 3}$ given by\n$$\nA = \\begin{pmatrix} 1  2  3 \\end{pmatrix}.\n$$\nLet $\\mathcal{N}(A) \\subset \\mathbb{R}^{3}$ denote the null space of $A$. Construct the matrix $P \\in \\mathbb{R}^{3 \\times 3}$ that represents the orthogonal projection (with respect to the standard Euclidean inner product) of any vector in $\\mathbb{R}^{3}$ onto $\\mathcal{N}(A)$. Report the exact value of the $(1,2)$-entry of $P$, denoted $P_{12}$. Provide your answer as an exact value. No rounding is required.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- The vector space is $\\mathbb{R}^{3}$ with the standard Euclidean inner product.\n- A linear constraint is defined by the matrix $A = \\begin{pmatrix} 1  2  3 \\end{pmatrix}$, where $A \\in \\mathbb{R}^{1 \\times 3}$.\n- $\\mathcal{N}(A)$ is the null space of the matrix $A$.\n- The task is to find the matrix a $P \\in \\mathbb{R}^{3 \\times 3}$ that represents the orthogonal projection onto $\\mathcal{N}(A)$.\n- The specific value required is the $(1,2)$-entry of $P$, denoted as $P_{12}$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, well-posed, and objective. It is a standard problem in linear algebra concerning the construction of a projection matrix onto a subspace, a fundamental concept in computational engineering and other applied sciences. The subspace $\\mathcal{N}(A)$ is well-defined, and the orthogonal projection operator onto it is unique. All required information is provided and is self-consistent. The problem does not violate any principles of scientific or mathematical logic.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A solution will be furnished.\n\nThe null space of $A$, denoted $\\mathcal{N}(A)$, is the set of all vectors $x \\in \\mathbb{R}^{3}$ such that $Ax = 0$. This condition, $x_{1} + 2x_{2} + 3x_{3} = 0$, defines a plane through the origin in $\\mathbb{R}^{3}$. We are asked to find the matrix $P$ for the orthogonal projection onto this plane.\n\nIn any inner product space, the space can be decomposed into a direct sum of a subspace and its orthogonal complement. For the space $\\mathbb{R}^{3}$ and the subspace $\\mathcal{N}(A)$, we have the orthogonal decomposition $\\mathbb{R}^{3} = \\mathcal{N}(A) \\oplus \\mathcal{N}(A)^{\\perp}$. The orthogonal complement of the null space of a matrix $A$ is the range of its transpose, $A^{T}$. This is a fundamental result from linear algebra, often called the fundamental theorem of linear algebra. Thus, $\\mathcal{N}(A)^{\\perp} = \\mathcal{R}(A^{T})$.\n\nThe matrix $A$ is given as a row vector $A = \\begin{pmatrix} 1  2  3 \\end{pmatrix}$. Its transpose is the column vector $A^{T} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}$. Let us denote this vector as $a = \\begin{pmatrix} 1  2  3 \\end{pmatrix}^{T}$. The range of $A^{T}$, $\\mathcal{R}(A^{T})$, is the one-dimensional subspace spanned by the vector $a$. This is a line passing through the origin.\n\nAny vector $v \\in \\mathbb{R}^{3}$ can be uniquely written as $v = v_{\\mathcal{N}} + v_{\\mathcal{N}^{\\perp}}$, where $v_{\\mathcal{N}} \\in \\mathcal{N}(A)$ and $v_{\\mathcal{N}^{\\perp}} \\in \\mathcal{N}(A)^{\\perp} = \\mathcal{R}(A^{T})$. The projection of $v$ onto $\\mathcal{N}(A)$ is $v_{\\mathcal{N}} = P v$, and the projection of $v$ onto $\\mathcal{R}(A^{T})$ is $v_{\\mathcal{N}^{\\perp}} = P_{\\perp}v$. It follows that $v = P v + P_{\\perp}v = (P + P_{\\perp})v$. This must hold for all $v \\in \\mathbb{R}^3$, so we have the matrix relation $P + P_{\\perp} = I$, where $I$ is the $3 \\times 3$ identity matrix.\n\nIt is computationally simpler to first determine the projection matrix $P_{\\perp}$ onto the one-dimensional subspace $\\mathcal{R}(A^{T})$ and then find $P$ using the relation $P = I - P_{\\perp}$. The orthogonal projection of a vector onto the line spanned by a non-zero vector $a$ is given by the formula:\n$$\nP_{\\perp} = \\frac{a a^{T}}{a^{T} a}\n$$\nHere, $a = \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}$. We compute the components:\nThe denominator is the inner product of $a$ with itself, which is the squared Euclidean norm:\n$$\na^{T} a = \\begin{pmatrix} 1  2  3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix} = (1)(1) + (2)(2) + (3)(3) = 1 + 4 + 9 = 14\n$$\nThe numerator is the outer product of $a$ with itself:\n$$\na a^{T} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix} \\begin{pmatrix} 1  2  3 \\end{pmatrix} = \\begin{pmatrix}\n1 \\cdot 1  1 \\cdot 2  1 \\cdot 3 \\\\\n2 \\cdot 1  2 \\cdot 2  2 \\cdot 3 \\\\\n3 \\cdot 1  3 \\cdot 2  3 \\cdot 3\n\\end{pmatrix}\n= \\begin{pmatrix}\n1  2  3 \\\\\n2  4  6 \\\\\n3  6  9\n\\end{pmatrix}\n$$\nThus, the projection matrix onto $\\mathcal{R}(A^{T})$ is:\n$$\nP_{\\perp} = \\frac{1}{14} \\begin{pmatrix}\n1  2  3 \\\\\n2  4  6 \\\\\n3  6  9\n\\end{pmatrix}\n$$\nThe projection matrix $P$ onto the null space $\\mathcal{N}(A)$ is then:\n$$\nP = I - P_{\\perp} = \\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  0  1\n\\end{pmatrix} - \\frac{1}{14} \\begin{pmatrix}\n1  2  3 \\\\\n2  4  6 \\\\\n3  6  9\n\\end{pmatrix}\n$$\n$$\nP = \\frac{1}{14} \\left[ \\begin{pmatrix}\n14  0  0 \\\\\n0  14  0 \\\\\n0  0  14\n\\end{pmatrix} - \\begin{pmatrix}\n1  2  3 \\\\\n2  4  6 \\\\\n3  6  9\n\\end{pmatrix} \\right] = \\frac{1}{14} \\begin{pmatrix}\n13  -2  -3 \\\\\n-2  10  -6 \\\\\n-3  -6  5\n\\end{pmatrix}\n$$\nThe problem asks for the $(1,2)$-entry of this matrix $P$, which is $P_{12}$. From the resulting matrix, we identify this entry:\n$$\nP_{12} = \\frac{-2}{14} = -\\frac{1}{7}\n$$\nThis is the exact value required.", "answer": "$$\n\\boxed{-\\frac{1}{7}}\n$$", "id": "2431352"}, {"introduction": "While theoretical mathematics assumes perfect precision, computational engineering operates within the limits of floating-point arithmetic. This crucial distinction gives rise to the concept of numerical rank, which can differ significantly from the theoretical rank for ill-conditioned matrices. This coding exercise [@problem_id:2431404] uses the Hilbert matrix—a classic example of ill-conditioning—to demonstrate how a theoretically invertible matrix can behave as if it is rank-deficient in practice, a vital lesson for developing robust numerical software.", "problem": "Construct a program that analyzes the rank, null space, and range properties of the Hilbert matrix in exact and floating-point senses. For a positive integer $n$, define the $n \\times n$ Hilbert matrix $H_n$ over the real numbers by the rule\n$$\n(H_n)_{ij} = \\frac{1}{i + j - 1}, \\quad i,j \\in \\{1, \\dots, n\\}.\n$$\nFor each specified size $n$, your program must compute and return the following quantities:\n- The theoretical rank $r_{\\text{theory}}$ of $H_n$ over the field of real numbers in exact arithmetic.\n- The matrix two-norm condition number $\\kappa_2(H_n)$, defined by\n$$\n\\kappa_2(H_n) = \\frac{\\sigma_{\\max}(H_n)}{\\sigma_{\\min}(H_n)},\n$$\nwhere $\\sigma_{\\max}(H_n)$ and $\\sigma_{\\min}(H_n)$ denote, respectively, the largest and smallest singular values of $H_n$.\n- The relative numerical rank under the thresholds $\\tau_1 = 10^{-12}$ and $\\tau_2 = 10^{-8}$, defined as\n$$\nr_{\\text{num}}(H_n;\\tau) = \\#\\{ i \\in \\{1,\\dots,n\\} : \\sigma_i / \\sigma_{\\max}(H_n)  \\tau \\},\n$$\nwhere $\\{\\sigma_i\\}_{i=1}^n$ are the singular values of $H_n$ sorted in nonincreasing order. For each threshold, also return the corresponding numerical nullity\n$$\n\\nu_{\\text{num}}(H_n;\\tau) = n - r_{\\text{num}}(H_n;\\tau).\n$$\n\nTest suite and required coverage:\n- Use the following set of sizes to exercise general behavior, boundary, and ill-conditioning regimes: $n \\in \\{1, 3, 5, 8, 12, 15\\}$.\n- For each $n$ in the set above, compute and return the tuple\n$$\n[n,\\ r_{\\text{theory}},\\ \\kappa_2(H_n),\\ r_{\\text{num}}(H_n;10^{-12}),\\ \\nu_{\\text{num}}(H_n;10^{-12}),\\ r_{\\text{num}}(H_n;10^{-8}),\\ \\nu_{\\text{num}}(H_n;10^{-8})].\n$$\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each entry is itself a list in the order specified above. For example:\n\"[ [n1,r_theory,cond2,rank_tau1,nullity_tau1,rank_tau2,nullity_tau2], [n2,r_theory,cond2,rank_tau1,nullity_tau1,rank_tau2,nullity_tau2], ... ]\".\n- No physical units, angle units, or percentages are involved in this problem; all outputs are dimensionless real numbers or integers as defined above.", "solution": "The Hilbert matrix $H_n$ is defined by $(H_n)_{ij} = 1/(i + j - 1)$ for $i,j \\in \\{1,\\dots,n\\}$. The program must compute the theoretical rank, the matrix two-norm condition number, and the relative numerical rank under specified thresholds. The solution proceeds from fundamental definitions as follows.\n\nFirst, determine the theoretical rank $r_{\\text{theory}}$ over the real numbers. A fundamental identity that follows from the definition is the integral representation\n$$\n(H_n)_{ij} = \\int_0^1 x^{i + j - 2}\\,dx,\n$$\nwhich shows that $H_n$ is the Gram matrix of the functions $\\{x^{k}\\}_{k=0}^{n-1}$ with respect to the inner product $\\langle f, g\\rangle = \\int_0^1 f(x) g(x)\\,dx$. For any nonzero vector $c \\in \\mathbb{R}^n$, define the polynomial $p(x) = \\sum_{k=0}^{n-1} c_{k+1} x^k$. Then\n$$\nc^\\top H_n c = \\sum_{i=1}^n \\sum_{j=1}^n c_i c_j \\int_0^1 x^{i + j - 2}\\,dx = \\int_0^1 \\left(\\sum_{i=1}^n c_i x^{i-1}\\right)^2 dx = \\int_0^1 p(x)^2 dx.\n$$\nBecause $p$ is not the zero polynomial when $c \\neq 0$, the integral is strictly positive. Therefore, $H_n$ is symmetric positive definite. A symmetric positive definite matrix is nonsingular, and consequently has full rank. Hence,\n$$\nr_{\\text{theory}} = \\operatorname{rank}(H_n) = n.\n$$\n\nSecond, compute the matrix two-norm condition number $\\kappa_2(H_n)$. The matrix two-norm is the largest singular value of the matrix, and the reciprocal of the smallest singular value is the two-norm of the inverse when the matrix is nonsingular. By definition,\n$$\n\\kappa_2(H_n) = \\frac{\\sigma_{\\max}(H_n)}{\\sigma_{\\min}(H_n)},\n$$\nwhere the singular values $\\sigma_i$ are the nonnegative square roots of the eigenvalues of $H_n^\\top H_n$. These can be obtained from the Singular Value Decomposition (SVD), that is, a factorization $H_n = U \\Sigma V^\\top$ with $U$ and $V$ orthogonal and $\\Sigma$ diagonal with nonnegative entries $\\sigma_1 \\ge \\cdots \\ge \\sigma_n \\ge 0$. In exact arithmetic $H_n$ is nonsingular and $\\sigma_{\\min}(H_n)  0$, but in floating-point arithmetic the smallest singular value may approach the machine underflow regime as $n$ grows, reflecting ill-conditioning.\n\nThird, define and compute the relative numerical rank at thresholds $\\tau \\in \\{10^{-12}, 10^{-8}\\}$. The relative numerical rank measures how many singular values remain significant relative to the largest singular value under a fixed relative cutoff. Formally,\n$$\nr_{\\text{num}}(H_n;\\tau) = \\#\\{ i \\in \\{1,\\dots,n\\} : \\sigma_i / \\sigma_{\\max}(H_n)  \\tau \\}.\n$$\nThe associated numerical nullity is the dimension that is effectively lost under the threshold,\n$$\n\\nu_{\\text{num}}(H_n;\\tau) = n - r_{\\text{num}}(H_n;\\tau).\n$$\nThese quantities reflect the effective dimension of the range and null space under finite precision constraints set by $\\tau$.\n\nAlgorithmic procedure consistent with these principles:\n- For each $n$ in the test set $\\{1,3,5,8,12,15\\}$, construct $H_n$ by evaluating $(H_n)_{ij} = 1/(i+j-1)$ on the integer index grid.\n- Compute the singular values $\\{\\sigma_i\\}_{i=1}^n$ of $H_n$ in nonincreasing order using Singular Value Decomposition (SVD).\n- Evaluate $\\kappa_2(H_n) = \\sigma_1 / \\sigma_n$; if $\\sigma_n$ underflows to zero numerically, treat $\\kappa_2(H_n)$ as $+\\infty$ in floating-point arithmetic.\n- For the thresholds $\\tau_1 = 10^{-12}$ and $\\tau_2 = 10^{-8}$, compute $r_{\\text{num}}(H_n;\\tau)$ and $\\nu_{\\text{num}}(H_n;\\tau)$ using the definition based on the normalized singular values $\\sigma_i/\\sigma_1$.\n- The theoretical rank $r_{\\text{theory}}$ equals $n$ because $H_n$ is symmetric positive definite, as shown above.\n\nBehavior with increasing size:\n- The theoretical rank remains $n$ for every $n$, because $H_n$ is symmetric positive definite, hence of full rank.\n- The two-norm condition number $\\kappa_2(H_n)$ grows rapidly with $n$ due to the extreme disparity between the largest and smallest singular values of $H_n$; this growth is superlinear and in practice becomes extremely large for moderate $n$.\n- For fixed relative thresholds $\\tau_1$ and $\\tau_2$, the relative numerical rank $r_{\\text{num}}(H_n;\\tau)$ typically decreases as $n$ increases, reflecting that more singular values fall below the relative cutoff. Consequently, the numerical nullity $\\nu_{\\text{num}}(H_n;\\tau)$ increases with $n$ for fixed $\\tau$.\n\nOutput specification:\n- For each $n \\in \\{1,3,5,8,12,15\\}$, return the list $[n, r_{\\text{theory}}, \\kappa_2(H_n), r_{\\text{num}}(H_n;10^{-12}), \\nu_{\\text{num}}(H_n;10^{-12}), r_{\\text{num}}(H_n;10^{-8}), \\nu_{\\text{num}}(H_n;10^{-8})]$.\n- Aggregate these lists into a single top-level list and print it as a single line, with entries comma-separated and enclosed in square brackets, exactly as specified in the problem statement.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef hilbert_matrix(n: int) - np.ndarray:\n    \"\"\"Construct the n x n Hilbert matrix H where H[i,j] = 1/(i+j-1).\"\"\"\n    i = np.arange(1, n + 1, dtype=np.float64).reshape(-1, 1)\n    j = np.arange(1, n + 1, dtype=np.float64).reshape(1, -1)\n    return 1.0 / (i + j - 1.0)\n\ndef compute_metrics_for_n(n: int, tau_list):\n    \"\"\"\n    Compute:\n    - theoretical rank (n)\n    - 2-norm condition number kappa2 = sigma_max/sigma_min\n    - relative numerical ranks and nullities for thresholds in tau_list\n    Returns a list: [n, r_theory, kappa2, r_num_tau1, null_tau1, r_num_tau2, null_tau2, ...]\n    \"\"\"\n    H = hilbert_matrix(n)\n    # Singular values in descending order\n    s = np.linalg.svd(H, compute_uv=False)\n    sigma_max = float(s[0])\n    sigma_min = float(s[-1])\n    if sigma_min == 0.0:\n        kappa2 = float('inf')\n    else:\n        kappa2 = sigma_max / sigma_min\n\n    # Theoretical rank for Hilbert matrices over R is n (positive definite)\n    r_theory = n\n\n    results = [n, r_theory, kappa2]\n    # Relative numerical ranks per tau\n    ratios = s / sigma_max if sigma_max != 0.0 else np.zeros_like(s)\n    for tau in tau_list:\n        r_num = int(np.sum(ratios  tau))\n        null_num = n - r_num\n        results.extend([r_num, null_num])\n    return results\n\ndef format_number(x):\n    \"\"\"\n    Format numbers without spaces and with a stable representation.\n    Use repr for floats/ints to preserve precision and avoid locale issues.\n    \"\"\"\n    if isinstance(x, float):\n        return repr(x)\n    else:\n        return str(int(x))\n\ndef format_list_no_spaces(lst):\n    return \"[\" + \",\".join(format_number(x) if not isinstance(x, (list, tuple)) else format_list_no_spaces(x) for x in lst) + \"]\"\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Sizes n to test: {1, 3, 5, 8, 12, 15}\n    test_ns = [1, 3, 5, 8, 12, 15]\n    # Relative thresholds tau1 = 1e-12, tau2 = 1e-8\n    tau_list = [1e-12, 1e-8]\n\n    results = []\n    for n in test_ns:\n        metrics = compute_metrics_for_n(n, tau_list)\n        results.append(metrics)\n\n    # Final print statement in the exact required format: a single line with a list of lists.\n    print(format_list_no_spaces(results))\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2431404"}]}