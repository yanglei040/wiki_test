{"hands_on_practices": [{"introduction": "To effectively use predictor-corrector schemes, one must first master the fundamental mechanics. This first practice problem [@problem_id:2202828] provides a straightforward initial value problem, allowing you to focus on correctly applying the predictor (Euler) and corrector (trapezoidal) steps of Heun's method in sequence. Successfully solving it demonstrates procedural fluency with this foundational two-stage process.", "problem": "Consider the first-order ordinary differential equation (ODE) given by $y'(t) = \\sin(t) - \\frac{y(t)}{t+1}$, which describes a system with a time-varying input and a time-dependent decay rate. We are given the initial condition $y(0) = 2$. We wish to approximate the value of $y(0.1)$ using a single step of Heun's method. The argument of the sine function is in radians.\n\nHeun's method is a predictor-corrector algorithm for solving an initial value problem of the form $y' = f(t,y)$, with $y(t_0) = y_0$. For a given step size $h$, the approximation at the next time step, $y_1 \\approx y(t_0+h)$, is computed in two stages:\n\n1.  **Predictor Step**: An intermediate value, $\\tilde{y}_1$, is estimated using Euler's method:\n    $$ \\tilde{y}_1 = y_0 + h f(t_0, y_0) $$\n2.  **Corrector Step**: The final approximation, $y_1$, is calculated by averaging the slope at the initial point $(t_0, y_0)$ and the slope at the estimated point $(t_1, \\tilde{y}_1)$, where $t_1 = t_0 + h$:\n    $$ y_1 = y_0 + \\frac{h}{2} \\left[ f(t_0, y_0) + f(t_1, \\tilde{y}_1) \\right] $$\n\nUsing a single step, calculate the numerical approximation for $y(0.1)$. Round your final answer to four significant figures.", "solution": "We are given the ODE $y'(t)=\\sin(t)-\\dfrac{y(t)}{t+1}$ with $y(0)=2$ and seek $y(0.1)$ using one Heun step of size $h=0.1$. Define $f(t,y)=\\sin(t)-\\dfrac{y}{t+1}$.\n\nAt the initial point $(t_{0},y_{0})=(0,2)$, compute the slope:\n$$\nf(t_{0},y_{0})=f(0,2)=\\sin(0)-\\frac{2}{0+1}=0-2=-2.\n$$\n\nPredictor step (Euler):\n$$\n\\tilde{y}_{1}=y_{0}+h\\,f(t_{0},y_{0})=2+0.1\\cdot(-2)=1.8.\n$$\n\nEvaluate the slope at $(t_{1},\\tilde{y}_{1})$ with $t_{1}=t_{0}+h=0.1$:\n$$\nf(t_{1},\\tilde{y}_{1})=f(0.1,1.8)=\\sin(0.1)-\\frac{1.8}{1.1}.\n$$\nUsing radians, $\\sin(0.1)\\approx 0.0998334166468$ and $\\dfrac{1.8}{1.1}\\approx 1.63636363636$, so\n$$\nf(t_{1},\\tilde{y}_{1})\\approx 0.0998334166468-1.63636363636\\approx -1.5365302197168.\n$$\n\nCorrector step:\n$$\ny_{1}=y_{0}+\\frac{h}{2}\\Big(f(t_{0},y_{0})+f(t_{1},\\tilde{y}_{1})\\Big)\n=2+0.05\\left(-2-1.5365302197168\\right)\\approx 2-0.1768265109858\\approx 1.8231734890142.\n$$\n\nRounding to four significant figures gives $y(0.1)\\approx 1.823$.", "answer": "$$\\boxed{1.823}$$", "id": "2202828"}, {"introduction": "While higher-order methods like Heun's are often more accurate than simpler ones, they are not universally superior, especially when stability is a concern. This exercise [@problem_id:2428207] presents a cautionary tale using a stiff ordinary differential equation, where a large step size leads to numerical instability. You will discover the surprising result that the \"corrector\" step can actually amplify the error relative to the initial prediction, providing a crucial lesson on the limitations of explicit methods.", "problem": "Consider the initial value problem for the ordinary differential equation (ODE)\n$$\\frac{dy}{dt}=-10\\,y,\\qquad y(0)=1.$$\nAdvance the solution from $t=0$ to $t=0.5$ using a single two-stage explicit trapezoidal predictor-corrector step (Heunâ€™s method) with step size $h=0.5$. Let $y_{E}$ denote the forward Euler predictor obtained at $t=0.5$, and let $y_{H}$ denote the corrected value at $t=0.5$ after applying the trapezoidal corrector. Let $y^{\\ast}$ denote the exact solution at $t=0.5$. Compute the ratio\n$$r=\\frac{|y_{H}-y^{\\ast}|}{|y_{E}-y^{\\ast}|}.$$\nRound your final answer to four significant figures. Do not include units.", "solution": "The problem is validated as self-contained, scientifically grounded, and well-posed. We proceed with the solution.\n\nThe initial value problem is given by the ordinary differential equation (ODE)\n$$ \\frac{dy}{dt} = f(t, y) = -10y $$\nwith the initial condition $y(0) = 1$.\nWe are tasked to find the numerical solution at $t_1 = 0.5$ using one step of size $h = 0.5$, starting from $t_0 = 0$ and $y_0 = 1$. The final objective is to compute a ratio of errors.\n\nFirst, we must determine the exact solution, denoted by $y^{\\ast}(t)$. The ODE is a linear, first-order, separable equation.\n$$ \\frac{dy}{y} = -10 dt $$\nIntegrating both sides yields:\n$$ \\int \\frac{dy}{y} = \\int (-10) dt $$\n$$ \\ln|y| = -10t + C $$\nwhere $C$ is the constant of integration. Exponentiating both sides gives:\n$$ y(t) = A \\exp(-10t) $$\nwhere $A = \\exp(C)$. We use the initial condition $y(0) = 1$ to find $A$:\n$$ 1 = A \\exp(-10 \\cdot 0) \\implies A = 1 $$\nTherefore, the exact solution is:\n$$ y^{\\ast}(t) = \\exp(-10t) $$\nAt $t=0.5$, the exact value is:\n$$ y^{\\ast} = y^{\\ast}(0.5) = \\exp(-10 \\cdot 0.5) = \\exp(-5) $$\n\nNext, we compute the forward Euler predictor value, $y_{E}$, at $t_1 = 0.5$. The forward Euler method is given by the formula:\n$$ y_{n+1} = y_n + h f(t_n, y_n) $$\nFor our problem, $n=0$, $y_0=1$, $t_0=0$, and $h=0.5$. The function is $f(t_0, y_0) = -10y_0 = -10(1) = -10$.\nThus, the predicted value is:\n$$ y_{E} = y_0 + h f(t_0, y_0) = 1 + (0.5)(-10) = 1 - 5 = -4 $$\n\nNow, we compute the corrected value, $y_{H}$, using Heun's method (a two-stage explicit trapezoidal predictor-corrector method). The method is defined by:\n1. Predictor step: $\\tilde{y}_{n+1} = y_n + h f(t_n, y_n)$\n2. Corrector step: $y_{n+1} = y_n + \\frac{h}{2} \\left[ f(t_n, y_n) + f(t_{n+1}, \\tilde{y}_{n+1}) \\right]$\n\nThe predictor step is identical to the forward Euler step, so we have $\\tilde{y}_1 = y_E = -4$.\nFor the corrector step, we need to evaluate the function $f$ at the new time $t_1 = 0.5$ using the predicted value $\\tilde{y}_1 = -4$.\n- The slope at the beginning of the interval is $k_1 = f(t_0, y_0) = f(0, 1) = -10(1) = -10$.\n- The slope at the end of the interval, estimated using the predictor, is $k_2 = f(t_1, \\tilde{y}_1) = f(0.5, -4) = -10(-4) = 40$.\nThe corrected value $y_H$ is then:\n$$ y_{H} = y_0 + \\frac{h}{2} (k_1 + k_2) = 1 + \\frac{0.5}{2} (-10 + 40) = 1 + (0.25)(30) = 1 + 7.5 = 8.5 $$\n\nFinally, we compute the ratio $r$ of the absolute errors.\nThe error of the corrected value is $|y_{H} - y^{\\ast}|$.\n$$ |y_{H} - y^{\\ast}| = |8.5 - \\exp(-5)| $$\nThe error of the predictor (Euler) value is $|y_{E} - y^{\\ast}|$.\n$$ |y_{E} - y^{\\ast}| = |-4 - \\exp(-5)| = |- (4 + \\exp(-5))| = 4 + \\exp(-5) $$\nThe ratio $r$ is:\n$$ r = \\frac{|y_{H} - y^{\\ast}|}{|y_{E} - y^{\\ast}|} = \\frac{|8.5 - \\exp(-5)|}{4 + \\exp(-5)} $$\nTo obtain the numerical value, we use $\\exp(-5) \\approx 0.006737947$.\n$$ r = \\frac{8.5 - 0.006737947}{4 + 0.006737947} = \\frac{8.493262053}{4.006737947} \\approx 2.1197368 $$\nRounding the result to four significant figures, we get:\n$$ r \\approx 2.120 $$\nThis large ratio, greater than $1$, indicates that for this large step size, the corrector step does not improve the accuracy relative to the predictor but rather increases the error. This is a known consequence of using an explicit method with a step size outside the region of absolute stability for a stiff problem.", "answer": "$$\\boxed{2.120}$$", "id": "2428207"}, {"introduction": "After understanding the mechanics and limitations of a fixed numerical scheme, we can advance to the art of method design. This problem [@problem_id:2428224] challenges you to modify the standard Heun's method by introducing tunable weights. Your goal is to derive these weights to make the method exact for the canonical linear test equation, $y^{\\prime} = \\lambda y$, introducing the powerful concept of exponential fitting and tailoring methods for specific classes of problems.", "problem": "A linear autonomous initial value problem in computational engineering is given by the ordinary differential equation (ODE) $y^{\\prime}(t) = f(t,y(t))$ with initial condition $y(t_0) = y_0$. Consider a two-stage predictor-corrector scheme of Heun-type that uses a forward Euler predictor followed by a weighted average of slopes for the corrector. Specifically, for a step size $h > 0$, define\n- the predictor by $y^{(p)}_{i+1} = y_i + h f(t_i, y_i)$,\n- the corrector by $y_{i+1} = y_i + h\\left(\\alpha f(t_i,y_i) + \\beta f(t_{i+1}, y^{(p)}_{i+1})\\right)$,\nwhere $\\alpha$ and $\\beta$ are weights that may depend on the non-dimensional step parameter $z = h \\lambda$ for a constant $\\lambda \\in \\mathbb{C}$. Impose the consistency condition that the corrector uses a weighted average of the two slopes, namely $\\alpha + \\beta = 1$.\n\nDetermine the weight $\\beta(z)$ such that, when applied to the linear test equation $y^{\\prime} = \\lambda y$ with constant $\\lambda$, the one-step update reproduces the exact solution amplification, i.e., $y_{i+1} = \\exp(z) y_i$, for any $z \\in \\mathbb{C}$. Express your final answer as a closed-form analytic expression for $\\beta(z)$. No numerical rounding is required.", "solution": "The problem statement is critically analyzed and found to be valid. It is a well-posed problem in the field of numerical analysis for ordinary differential equations, grounded in established scientific principles. All necessary information is provided, and there are no inconsistencies or ambiguities. We may therefore proceed with the derivation of the solution.\n\nThe objective is to determine the weight $\\beta(z)$ for a two-stage predictor-corrector scheme such that it exactly reproduces the solution of the linear test equation $y^{\\prime} = \\lambda y$. The non-dimensional step parameter is $z = h\\lambda$, where $h$ is the step size and $\\lambda \\in \\mathbb{C}$ is a constant.\n\nThe given numerical scheme consists of a predictor and a corrector step:\n1.  Predictor: $y^{(p)}_{i+1} = y_i + h f(t_i, y_i)$\n2.  Corrector: $y_{i+1} = y_i + h\\left(\\alpha f(t_i,y_i) + \\beta f(t_{i+1}, y^{(p)}_{i+1})\\right)$\n\nWe apply this scheme to the linear test equation $y^{\\prime}(t) = \\lambda y(t)$. For this equation, the function $f(t,y)$ is given by $f(t,y) = \\lambda y$.\nThe function evaluations at the required points are:\n$f(t_i, y_i) = \\lambda y_i$\n$f(t_{i+1}, y^{(p)}_{i+1}) = \\lambda y^{(p)}_{i+1}$\n\nFirst, we substitute $f(t_i, y_i) = \\lambda y_i$ into the predictor equation:\n$$y^{(p)}_{i+1} = y_i + h (\\lambda y_i) = (1 + h\\lambda) y_i$$\n\nNext, we substitute the function evaluations into the corrector equation:\n$$y_{i+1} = y_i + h\\left(\\alpha (\\lambda y_i) + \\beta (\\lambda y^{(p)}_{i+1})\\right)$$\nWe can factor out $\\lambda$ from the term in the parentheses:\n$$y_{i+1} = y_i + h\\lambda\\left(\\alpha y_i + \\beta y^{(p)}_{i+1}\\right)$$\nNow, we replace the predicted value $y^{(p)}_{i+1}$ with the expression we found from the predictor step:\n$$y_{i+1} = y_i + h\\lambda\\left(\\alpha y_i + \\beta (1 + h\\lambda) y_i\\right)$$\nFactoring out $y_i$ from the right-hand side gives the one-step update rule in terms of an amplification factor:\n$$y_{i+1} = \\left[1 + h\\lambda\\left(\\alpha + \\beta(1 + h\\lambda)\\right)\\right] y_i$$\n\nThe problem states the consistency condition $\\alpha + \\beta = 1$, which implies $\\alpha = 1 - \\beta$. We substitute this into the expression for the amplification factor:\n$$y_{i+1} = \\left[1 + h\\lambda\\left((1 - \\beta) + \\beta(1 + h\\lambda)\\right)\\right] y_i$$\nLet us simplify the term within the square brackets:\n$$1 + h\\lambda\\left(1 - \\beta + \\beta + \\beta h\\lambda\\right) = 1 + h\\lambda\\left(1 + \\beta h\\lambda\\right) = 1 + h\\lambda + \\beta (h\\lambda)^2$$\nThe numerical update can thus be written as:\n$$y_{i+1} = \\left(1 + h\\lambda + \\beta (h\\lambda)^2\\right) y_i$$\n\nWe introduce the non-dimensional parameter $z = h\\lambda$. The equation becomes:\n$$y_{i+1} = \\left(1 + z + \\beta z^2\\right) y_i$$\nThe expression $R(z, \\beta) = 1 + z + \\beta z^2$ is the amplification factor of the numerical method.\n\nThe problem requires that the numerical scheme reproduces the exact solution amplification. The exact solution of the initial value problem $y^{\\prime} = \\lambda y$ with $y(t_i) = y_i$ is $y(t) = y_i \\exp(\\lambda(t - t_i))$. At time $t_{i+1} = t_i + h$, the exact solution is:\n$$y(t_{i+1}) = y_i \\exp(\\lambda h) = y_i \\exp(z)$$\nThe condition is that the numerical update must match this exact result, so $y_{i+1}$ must equal $y_i \\exp(z)$.\nEquating the numerical and exact amplification factors, we have:\n$$1 + z + \\beta z^2 = \\exp(z)$$\n\nWe must now solve this equation for $\\beta$, which is specified to be a function of $z$, denoted $\\beta(z)$.\n$$\\beta(z) z^2 = \\exp(z) - 1 - z$$\nFor $z \\neq 0$, we can divide by $z^2$ to obtain the expression for $\\beta(z)$:\n$$\\beta(z) = \\frac{\\exp(z) - 1 - z}{z^2}$$\nThis expression is a closed-form analytic function of $z$. For the case $z = 0$, the expression is an indeterminate form $0/0$. We can find the value of $\\beta(0)$ by taking the limit as $z \\to 0$. Using the Taylor series expansion of the exponential function around $z=0$:\n$$\\exp(z) = 1 + z + \\frac{z^2}{2!} + \\frac{z^3}{3!} + \\dots$$\nSubstituting this into the expression for $\\beta(z)$:\n$$\\beta(z) = \\frac{\\left(1 + z + \\frac{z^2}{2} + O(z^3)\\right) - 1 - z}{z^2} = \\frac{\\frac{z^2}{2} + O(z^3)}{z^2} = \\frac{1}{2} + O(z)$$\nThe limit as $z \\to 0$ is $\\frac{1}{2}$. Thus, the function $\\beta(z)$ is well-defined for all $z \\in \\mathbb{C}$, with $\\beta(0) = \\frac{1}{2}$. The derived expression is the required closed-form solution.", "answer": "$$\n\\boxed{\\frac{\\exp(z) - 1 - z}{z^2}}\n$$", "id": "2428224"}]}