{"hands_on_practices": [{"introduction": "To truly understand piecewise linear interpolation, it is helpful to contrast it with more complex methods. This first exercise provides a direct comparison with a natural cubic spline, a popular choice for generating smooth curves. By calculating the interpolated value from the same set of points using both methods, you will gain a hands-on appreciation for the difference between a simple, connected-line ($C^0$ continuity) approach and a smoother, curvature-minimizing ($C^2$ continuity) one.", "problem": "An engineer is modeling the shape of a thin, flexible rod that is constrained to pass through three points in a 2D Cartesian plane: $P_0=(-1, 1)$, $P_1=(0, 0)$, and $P_2=(1, 1)$. Two simple models are proposed to estimate the rod's vertical position, $y$, at other horizontal locations, $x$.\n\nModel A is a piecewise linear interpolant, which connects the specified points with straight line segments.\nModel B is a natural cubic spline, which ensures the curve is smooth by matching first and second derivatives at the interior points, and has zero second derivatives at the endpoints.\n\nCalculate the vertical position of the rod at $x=0.5$ as predicted by both Model A and Model B. Let these values be $y_A$ and $y_B$, respectively. Present your answer as a pair of exact fractions $(y_A, y_B)$.", "solution": "We label the nodes as $x_{0}=-1$, $x_{1}=0$, $x_{2}=1$ with corresponding values $y_{0}=1$, $y_{1}=0$, $y_{2}=1$.\n\nModel A (piecewise linear interpolant): For $x \\in [x_{1},x_{2}]$, the line through $(0,0)$ and $(1,1)$ has slope\n$$\nm=\\frac{y_{2}-y_{1}}{x_{2}-x_{1}}=\\frac{1-0}{1-0}=1,\n$$\nso the interpolant is\n$$\ny(x)=y_{1}+m(x-x_{1})=0+1\\cdot(x-0)=x.\n$$\nEvaluating at $x=\\frac{1}{2}$ gives\n$$\ny_{A}=y\\!\\left(\\frac{1}{2}\\right)=\\frac{1}{2}.\n$$\n\nModel B (natural cubic spline): Let $M_{i}=S''(x_{i})$. Natural end conditions give $M_{0}=0$ and $M_{2}=0$. With $h_{0}=x_{1}-x_{0}=1$ and $h_{1}=x_{2}-x_{1}=1$, the cubic spline system at the interior node $i=1$ is\n$$\nh_{0}M_{0}+2(h_{0}+h_{1})M_{1}+h_{1}M_{2}=6\\left(\\frac{y_{2}-y_{1}}{h_{1}}-\\frac{y_{1}-y_{0}}{h_{0}}\\right).\n$$\nSubstituting the values,\n$$\n1\\cdot 0+2(1+1)M_{1}+1\\cdot 0=6\\left(\\frac{1-0}{1}-\\frac{0-1}{1}\\right)=6(1-(-1))=12,\n$$\nso\n$$\n4M_{1}=12 \\quad \\Rightarrow \\quad M_{1}=3.\n$$\nOn the interval $[x_{1},x_{2}]=[0,1]$, the spline is\n$$\nS(x)=\\frac{M_{1}}{6h_{1}}(x_{2}-x)^{3}+\\frac{M_{2}}{6h_{1}}(x-x_{1})^{3}+\\left(y_{1}-\\frac{M_{1}h_{1}^{2}}{6}\\right)\\frac{x_{2}-x}{h_{1}}+\\left(y_{2}-\\frac{M_{2}h_{1}^{2}}{6}\\right)\\frac{x-x_{1}}{h_{1}}.\n$$\nWith $h_{1}=1$, $M_{1}=3$, $M_{2}=0$, $y_{1}=0$, and $y_{2}=1$, this simplifies to\n$$\nS(x)=\\frac{3}{6}(1-x)^{3}+0+\\left(0-\\frac{3}{6}\\right)(1-x)+\\left(1-0\\right)x\n=\\frac{1}{2}(1-x)^{3}-\\frac{1}{2}(1-x)+x.\n$$\nExpanding and combining like terms,\n$$\nS(x)=\\frac{1}{2}-\\frac{3}{2}x+\\frac{3}{2}x^{2}-\\frac{1}{2}x^{3}-\\frac{1}{2}+\\frac{1}{2}x+x\n=\\frac{3}{2}x^{2}-\\frac{1}{2}x^{3}.\n$$\nEvaluating at $x=\\frac{1}{2}$ gives\n$$\ny_{B}=S\\!\\left(\\frac{1}{2}\\right)=\\frac{3}{2}\\left(\\frac{1}{2}\\right)^{2}-\\frac{1}{2}\\left(\\frac{1}{2}\\right)^{3}\n=\\frac{3}{2}\\cdot\\frac{1}{4}-\\frac{1}{2}\\cdot\\frac{1}{8}\n=\\frac{3}{8}-\\frac{1}{16}\n=\\frac{5}{16}.\n$$\n\nThus, the required pair is $\\left(\\frac{1}{2},\\frac{5}{16}\\right)$.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{1}{2} & \\frac{5}{16}\\end{pmatrix}}$$", "id": "2164998"}, {"introduction": "Piecewise linear interpolation is not just for plotting; it is a powerful tool for analyzing data when the underlying function is unknown. A common task is to find the roots of a function, i.e., where it crosses the zero axis. This practice challenges you to write a program that finds all roots of a function defined only by a set of data points, forcing you to translate the geometric concept of a root into a robust algorithm that can handle multiple scenarios, including intervals where the function is entirely zero.", "problem": "You are given a finite set of grid points $\\{(x_i,f_i)\\}_{i=0}^n$ with strictly increasing abscissae $x_0 < x_1 < \\cdots < x_n$ and real ordinates $f_i$. Define the piecewise linear interpolant $\\widehat{f}(x)$ by linear interpolation between consecutive data points on each closed interval $[x_i,x_{i+1}]$ for $i \\in \\{0,\\ldots,n-1\\}$, and undefined outside $[x_0,x_n]$. The root set $\\mathcal{Z}$ is the subset of $[x_0,x_n]$ where $\\widehat{f}(x)=0$. The root set can contain isolated points and, if $\\widehat{f}(x)$ is identically zero on a nontrivial interval, closed intervals. An isolated root at an endpoint shared by two segments must be included only once. If multiple zero segments are contiguous or overlapping, they must be merged into a single closed interval. The domain endpoints $x_0$ and $x_n$ must be treated inclusively.\n\nWrite a program that, for each specified test case, returns the complete description of $\\mathcal{Z}$ as an ordered list consisting of:\n- real numbers for isolated roots, and\n- two-element lists $[a,b]$ (with $a<b$) to denote closed zero intervals where $\\widehat{f}(x)=0$ for all $x \\in [a,b]$.\n\nOrder the output left-to-right by increasing coordinate: intervals are ordered by their left endpoint $a$; isolated points are ordered by their value. If an isolated point lies within or at the boundary of any reported interval $[a,b]$, it must not be listed separately. Each real number in the output must be rounded to $10$ decimal places when printed. The program must produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets in the form $[\\text{case1},\\text{case2},\\ldots]$, where each $\\text{case}$ is formatted as described above.\n\nTest suite (each test case is given by its grid):\n- Test case $1$: $x=[-2.0,-1.0,0.5,2.0]$, $f=[1.0,-1.0,2.0,-2.0]$.\n- Test case $2$: $x=[0.0,1.0,2.0,3.0]$, $f=[3.0,0.0,-1.0,2.0]$.\n- Test case $3$: $x=[0.0,1.0,2.0,3.0]$, $f=[1.0,0.0,0.0,-1.0]$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[\\text{result1},\\text{result2},\\text{result3}]$). Each $\\text{result}$ must be either a list of real numbers and/or two-element lists as specified above, with all real numbers rounded to $10$ decimal places when printed.", "solution": "The problem statement has been subjected to validation and is determined to be valid. It is scientifically grounded in the principles of numerical analysis, specifically piecewise linear interpolation. The problem is well-posed, with all terms, conditions, and objectives defined with sufficient mathematical precision to permit a unique, verifiable solution. We may therefore proceed with the derivation of a solution.\n\nThe core of the problem is to find the root set $\\mathcal{Z} = \\{x \\in [x_0, x_n] \\mid \\widehat{f}(x) = 0\\}$ for a piecewise linear interpolant $\\widehat{f}(x)$. The function $\\widehat{f}(x)$ is defined over a set of grid points $\\{(x_i, f_i)\\}_{i=0}^n$ where $x_0 < x_1 < \\cdots < x_n$.\n\nOn any given closed interval $[x_i, x_{i+1}]$ for $i \\in \\{0, \\ldots, n-1\\}$, the interpolant $\\widehat{f}(x)$ is described by the linear function connecting the points $(x_i, f_i)$ and $(x_{i+1}, f_{i+1})$. The equation for $\\widehat{f}(x)$ on this segment is:\n$$ \\widehat{f}(x) = f_i + (f_{i+1} - f_i) \\frac{x - x_i}{x_{i+1} - x_i}, \\quad x \\in [x_i, x_{i+1}] $$\nTo find the roots, we must solve $\\widehat{f}(x) = 0$ across the entire domain $[x_0, x_n]$. This requires analyzing each segment $[x_i, x_{i+1}]$ for three possible types of contributions to the root set $\\mathcal{Z}$:\n\n1.  **Interior Root:** An isolated root exists within the open interval $(x_i, x_{i+1})$ if and only if the function values at the endpoints have opposite signs. By the Intermediate Value Theorem, a sign change, $f_i \\cdot f_{i+1} < 0$, guarantees a root. As the function is linear on the segment, this root is unique. We solve $\\widehat{f}(x) = 0$ for $x$:\n    $$ x_{\\text{root}} = x_i - f_i \\frac{x_{i+1} - x_i}{f_{i+1} - f_i} $$\n    This formula is valid since $f_i \\cdot f_{i+1} < 0$ implies $f_i \\neq f_{i+1}$.\n\n2.  **Interval of Roots:** The function $\\widehat{f}(x)$ is identically zero over the entire closed interval $[x_i, x_{i+1}]$ if and only if the function values at both endpoints are zero, i.e., $f_i = 0$ and $f_{i+1} = 0$. In this case, the entire interval $[x_i, x_{i+1}]$ is a subset of $\\mathcal{Z}$.\n\n3.  **Grid Point Root:** A grid point $x_k$ is a root if $f_k = 0$. Such points can be isolated roots or endpoints of a zero-interval.\n\nBased on this analysis, a systematic algorithm is constructed to identify and correctly format all elements of the root set $\\mathcal{Z}$.\n\n**Algorithm:**\n\n1.  **Initialization:** Two data structures are initialized: a set, `isolated_roots`, to store unique isolated root values, and a list, `zero_intervals`, to store intervals $[a, b]$ where $\\widehat{f}(x)$ is identically zero.\n\n2.  **Segment Analysis:** Iterate through each segment $[x_i, x_{i+1}]$ for $i$ from $0$ to $n-1$:\n    -   If $f_i \\cdot f_{i+1} < 0$, an interior root exists. Calculate its value using the formula above and add it to the `isolated_roots` set.\n    -   If $f_i = 0$ and $f_{i+1} = 0$, the segment $[x_i, x_{i+1}]$ is a zero-interval. Add this interval to the `zero_intervals` list.\n\n3.  **Grid Point Analysis:** Iterate through all grid points $(x_k, f_k)$ for $k$ from $0$ to $n$. If $f_k = 0$, add the value $x_k$ to the `isolated_roots` set. Using a set automatically handles the requirement that a root at a shared endpoint be included only once.\n\n4.  **Interval Merging:** The `zero_intervals` list may contain contiguous or overlapping intervals (e.g., $[x_i, x_{i+1}]$ and $[x_{i+1}, x_{i+2}]$). These must be merged.\n    -   Sort `zero_intervals` based on their starting points.\n    -   Iterate through the sorted list, merging any interval $[c,d]$ with the current merged interval $[a,b]$ if $c \\le b$. The merged interval becomes $[a, \\max(b,d)]$. This process yields a new list, `merged_intervals`, of disjoint closed intervals.\n\n5.  **Root Filtering:** The `isolated_roots` set may contain points that are part of the `merged_intervals` (e.g., endpoints). Such points must not be listed separately.\n    -   Create a new list, `final_isolated_roots`.\n    -   For each root $r$ in `isolated_roots`, check if it is contained within any interval $[a,b]$ in `merged_intervals` (i.e., if $a \\le r \\le b$).\n    -   If $r$ is not contained in any interval, add it to `final_isolated_roots`.\n\n6.  **Final Assembly:** The complete root set $\\mathcal{Z}$ is the union of `final_isolated_roots` and `merged_intervals`.\n    -   Combine these two collections into a single list.\n    -   Sort the final list in increasing order. For sorting purposes, an interval $[a,b]$ is ordered by its left endpoint $a$.\n    -   Format the resulting list according to the output specification, rounding all numerical values to $10$ decimal places.\n\nThis procedure rigorously constructs the complete root set, satisfying all constraints given in the problem statement.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\n            np.array([-2.0, -1.0, 0.5, 2.0]), \n            np.array([1.0, -1.0, 2.0, -2.0])\n        ),\n        (\n            np.array([0.0, 1.0, 2.0, 3.0]), \n            np.array([3.0, 0.0, -1.0, 2.0])\n        ),\n        (\n            np.array([0.0, 1.0, 2.0, 3.0]), \n            np.array([1.0, 0.0, 0.0, -1.0])\n        ),\n    ]\n\n    results = []\n    for x_coords, f_values in test_cases:\n        result = find_root_set(x_coords, f_values)\n        results.append(format_case_output(result))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\ndef find_root_set(x, f):\n    \"\"\"\n    Calculates the root set for a given piecewise linear function.\n\n    Args:\n        x (np.ndarray): Array of x-coordinates (abscissae), strictly increasing.\n        f (np.ndarray): Array of function values (ordinates).\n\n    Returns:\n        list: A sorted list of isolated roots (floats) and zero intervals ([a, b]).\n    \"\"\"\n    n = len(x)\n    isolated_roots = set()\n    zero_intervals = []\n\n    # Step 2: Segment Analysis for interior roots and zero intervals\n    for i in range(n - 1):\n        x_i, f_i = x[i], f[i]\n        x_i1, f_i1 = x[i+1], f[i+1]\n\n        if f_i * f_i1 < 0:\n            # Interior root\n            root = x_i - f_i * (x_i1 - x_i) / (f_i1 - f_i)\n            isolated_roots.add(root)\n        elif f_i == 0 and f_i1 == 0:\n            # Zero interval\n            zero_intervals.append([x_i, x_i1])\n\n    # Step 3: Grid Point Analysis\n    for i in range(n):\n        if f[i] == 0:\n            isolated_roots.add(x[i])\n            \n    # Step 4: Interval Merging\n    if not zero_intervals:\n        merged_intervals = []\n    else:\n        zero_intervals.sort(key=lambda interval: interval[0])\n        merged_intervals = [zero_intervals[0]]\n        for i in range(1, len(zero_intervals)):\n            current_interval = zero_intervals[i]\n            last_merged_interval = merged_intervals[-1]\n            \n            # Check for contiguity or overlap\n            if current_interval[0] <= last_merged_interval[1]:\n                last_merged_interval[1] = max(last_merged_interval[1], current_interval[1])\n            else:\n                merged_intervals.append(current_interval)\n\n    # Step 5: Root Filtering\n    final_isolated_roots = []\n    sorted_roots = sorted(list(isolated_roots))\n    \n    for root in sorted_roots:\n        is_covered = False\n        for interval in merged_intervals:\n            # Check if root is within or at the boundary of an interval\n            if interval[0] <= root <= interval[1]:\n                is_covered = True\n                break\n        if not is_covered:\n            final_isolated_roots.append(root)\n            \n    # Step 6: Final Assembly\n    final_result = final_isolated_roots + merged_intervals\n    \n    # Sort final list: intervals by their start point, points by their value\n    final_result.sort(key=lambda item: item if isinstance(item, (int, float)) else item[0])\n    \n    return final_result\n\ndef format_case_output(result_list):\n    \"\"\"\n    Formats the result of a single case into the required string representation.\n    \"\"\"\n    formatted_items = []\n    for item in result_list:\n        if isinstance(item, list):\n            # It's an interval [a, b]\n            formatted_items.append(f\"[{item[0]:.10f},{item[1]:.10f}]\")\n        else:\n            # It's an isolated root (float)\n            formatted_items.append(f\"{item:.10f}\")\n    return f\"[{','.join(formatted_items)}]\"\n\nsolve()\n```", "id": "2423755"}, {"introduction": "While simple, using a uniform grid for interpolation can be highly inefficient, wasting points in regions where the function is smooth and lacking them where it changes rapidly. This advanced practice introduces a powerful solution: adaptive grid refinement. You will design an algorithm that intelligently adds points to the grid based on a local estimate of the interpolation error, creating an efficient, non-uniform grid tailored to the function's specific features. This exercise is a step toward building sophisticated and efficient computational tools.", "problem": "You are given a family of scalar functions on a closed interval and asked to construct an adaptive grid generator for piecewise linear interpolation that refines where a computable estimate of the magnitude of the second derivative, written as $\\lvert f^{\\prime\\prime}(x)\\rvert$, is large. You must start from fundamental definitions and well-tested facts, and you must implement a fully deterministic algorithm that can be verified on a fixed test suite. All angles used in trigonometric functions are to be interpreted in radians. No physical units are involved in this problem.\n\nYour program must implement the following requirements.\n\n- Input and initialization:\n  - A function $f:[a,b]\\to\\mathbb{R}$, an interval $[a,b]$ with $a<b$, an initial number of grid points $m_{0}\\in\\mathbb{N}$ with $m_{0}\\geq 3$, a nonnegative tolerance $\\mathrm{tol}>0$, and a maximum permitted number of grid points $N_{\\max}\\in\\mathbb{N}$ with $N_{\\max}\\geq m_{0}$.\n  - Initialize a strictly increasing grid of nodes $a=x_{0}<x_{1}<\\dots<x_{m_{0}-1}=b$ as $m_{0}$ equally spaced points on $[a,b]$. For each node $x_{i}$, store $y_{i}=f(x_{i})$.\n\n- Local second-derivative estimator on a nonuniform grid:\n  - For each triple of consecutive nodes $(x_{k-1},x_{k},x_{k+1})$ with $k\\in\\{1,2,\\dots,n-2\\}$ when the current grid has $n$ nodes, define $D2_{k}$ to be the second derivative at $x_{k}$ of the unique quadratic polynomial that interpolates the three points $(x_{k-1},y_{k-1})$, $(x_{k},y_{k})$, $(x_{k+1},y_{k+1})$.\n  - For each interval $I_{i}=[x_{i},x_{i+1}]$ with length $h_{i}=x_{i+1}-x_{i}$, define a scalar curvature indicator $s_{i}$ by\n    - $s_{0}=\\lvert D2_{1}\\rvert$,\n    - $s_{i}=\\max\\{\\lvert D2_{i}\\rvert,\\lvert D2_{i+1}\\rvert\\}$ for $i\\in\\{1,2,\\dots,n-3\\}$,\n    - $s_{n-2}=\\lvert D2_{n-2}\\rvert$.\n  - Define the interval error indicator $e_{i}=s_{i}\\,h_{i}^{2}$.\n\n- Greedy refinement rule and stopping criteria:\n  - While the maximum interval indicator satisfies $\\max_{i} e_{i}>\\mathrm{tol}$ and the number of nodes $n<N_{\\max}$, refine a single interval per iteration as follows:\n    - Select $i^{\\star}$ to be the smallest index achieving the maximum value of $e_{i}$.\n    - Insert the midpoint $m=(x_{i^{\\star}}+x_{i^{\\star}+1})/2$ as a new node, evaluate $f(m)$, and maintain the grid in sorted order with the associated function values.\n  - Stop when either $\\max_{i} e_{i}\\leq \\mathrm{tol}$ or the grid has reached $N_{\\max}$ nodes.\n\n- Final quality assessment:\n  - Let $L(x)$ denote the piecewise linear interpolant through the final grid nodes. Approximate the supremum norm of the interpolation error on $[a,b]$ by sampling $L(x)$ and $f(x)$ at exactly $10001$ equally spaced points $\\{x^{\\mathrm{test}}_{j}\\}_{j=0}^{10000}$ on $[a,b]$, and computing $E=\\max_{0\\leq j\\leq 10000}\\lvert f(x^{\\mathrm{test}}_{j})-L(x^{\\mathrm{test}}_{j})\\rvert$.\n\nYour program must implement the algorithm above exactly and run on the following test suite. For each test case, output the final number of nodes and the measured maximum absolute error $E$.\n\n- Test suite (angles are in radians):\n  - Test $1$: $f(x)=\\sin(6x)$ on $[0,1]$, with $m_{0}=5$, $\\mathrm{tol}=0.02$, $N_{\\max}=200$.\n  - Test $2$: $f(x)=2x+3$ on $[0,1]$, with $m_{0}=3$, $\\mathrm{tol}=10^{-6}$, $N_{\\max}=50$.\n  - Test $3$: $f(x)=\\arctan\\!\\big(50(x-0.5)\\big)$ on $[0,1]$, with $m_{0}=5$, $\\mathrm{tol}=0.005$, $N_{\\max}=200$.\n  - Test $4$: $f(x)=\\exp(x)$ on $[0,5]$, with $m_{0}=5$, $\\mathrm{tol}=0.5$, $N_{\\max}=300$.\n  - Test $5$: $f(x)=\\sin(x)$ on $[0,0.01]$, with $m_{0}=3$, $\\mathrm{tol}=10^{-4}$, $N_{\\max}=50$.\n\nFinal output format:\n\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case result must itself be a two-element list of the form $[n,E]$, where $n$ is the final number of nodes (an integer) and $E$ is the maximum absolute error (a floating-point number). For example, the overall format must look like $[[n_{1},E_{1}],[n_{2},E_{2}],\\dots]$ with no extra spaces inserted.", "solution": "The problem statement is critically validated and found to be scientifically grounded, well-posed, objective, and complete. It describes a standard adaptive mesh refinement algorithm for piecewise linear interpolation. The problem is valid. A complete solution is provided below.\n\nThe fundamental principle behind adaptive grid generation is to distribute a finite number of grid points efficiently, placing them densely in regions where the function to be interpolated changes rapidly and sparsely where it is smooth. For piecewise linear interpolation, the interpolation error on an interval $[x_i, x_{i+1}]$ is controlled by the magnitude of the function's second derivative, $\\lvert f^{\\prime\\prime}(x)\\rvert$, and the interval length, $h_i = x_{i+1} - x_i$. The standard error bound is given by:\n$$ \\max_{x \\in [x_i, x_{i+1}]} \\lvert f(x) - L(x) \\rvert \\le \\frac{h_i^2}{8} \\max_{z \\in [x_i, x_{i+1}]} \\lvert f^{\\prime\\prime}(z) \\rvert $$\nwhere $L(x)$ is the linear interpolant on the interval. This motivates an error indicator for each interval $I_i = [x_i, x_{i+1}]$ of the form $e_i = s_i h_i^2$, where $s_i$ is an estimate of the magnitude of the second derivative over or near the interval.\n\nThe algorithm proceeds as follows:\n1.  Initialize a coarse, uniform grid of $m_0$ points on the interval $[a, b]$.\n2.  Iteratively refine the grid based on a local error indicator. In each step, the interval with the largest error indicator is bisected.\n3.  The process terminates when the largest error indicator falls below a specified tolerance $\\mathrm{tol}$, or when the total number of grid points reaches a maximum limit $N_{\\max}$.\n\nThe core of the algorithm is the computation of the error indicator $e_i$. This requires a numerical estimate of the second derivative, since $f^{\\prime\\prime}(x)$ is not assumed to be available analytically. The problem specifies a method based on local quadratic interpolation.\n\nFor each triple of consecutive nodes $(x_{k-1}, y_{k-1})$, $(x_k, y_k)$, $(x_{k+1}, y_{k+1})$, we construct a unique quadratic polynomial $P_k(x)$ that passes through these points. The second derivative of this polynomial, $P_k^{\\prime\\prime}(x)$, is a constant and serves as an approximation of $f^{\\prime\\prime}(x_k)$. This approximation is denoted by $D2_k$.\nThe formula for $D2_k$ can be derived from the Newton form of the interpolating polynomial. The second divided difference is given by:\n$$ f[x_{k-1}, x_k, x_{k+1}] = \\frac{f[x_k, x_{k+1}] - f[x_{k-1}, x_k]}{x_{k+1} - x_{k-1}} $$\nwhere $f[x_i, x_j] = (y_j - y_i) / (x_j - x_i)$. The second derivative of the interpolating quadratic is $P_k^{\\prime\\prime}(x) = 2 f[x_{k-1}, x_k, x_{k+1}]$. Let $h_{k-1} = x_k - x_{k-1}$ and $h_k = x_{k+1} - x_k$. The formula for $D2_k$ becomes:\n$$ D2_k = 2 \\frac{ \\frac{y_{k+1} - y_k}{h_k} - \\frac{y_k - y_{k-1}}{h_{k-1}} }{ x_{k+1} - x_{k-1} } = \\frac{2}{h_k + h_{k-1}} \\left( \\frac{y_{k+1} - y_k}{h_k} - \\frac{y_k - y_{k-1}}{h_{k-1}} \\right) $$\nThis formula is defined for each interior grid point $x_k$, where $k \\in \\{1, 2, \\dots, n-2\\}$ for a grid with $n$ points.\n\nWith the values of $D2_k$ computed, the problem defines a scalar curvature indicator $s_i$ for each interval $I_i=[x_i,x_{i+1}]$. This indicator aggregates the second derivative information at the interval's endpoints (or the nearest interior points for the boundary intervals). For a grid with $n$ nodes ($n-1$ intervals), the definitions are:\n-   For the first interval $I_0$: $s_0 = \\lvert D2_1 \\rvert$\n-   For interior intervals $I_i$, $i \\in \\{1, \\dots, n-3\\}$: $s_i = \\max\\{\\lvert D2_i \\rvert, \\lvert D2_{i+1} \\rvert\\}$\n-   For the last interval $I_{n-2}$: $s_{n-2} = \\lvert D2_{n-2} \\rvert$\n\nThe interval error indicator is then $e_i = s_i h_i^2$.\n\nThe refinement strategy is a greedy algorithm. In each iteration, we identify the interval $I_{i^{\\star}}$ with the maximum error indicator, $e_{i^{\\star}} = \\max_j e_j$. If multiple intervals share this maximum value, the one with the smallest index $i^{\\star}$ is chosen. This interval is bisected by inserting its midpoint $m = (x_{i^{\\star}} + x_{i^{\\star}+1})/2$ as a new node. The function value $f(m)$ is computed, and the grid data arrays are updated.\n\nThis iterative process continues until the stopping criterion is met: $\\max_i e_i \\le \\mathrm{tol}$ or the number of nodes $n = N_{\\max}$.\n\nFinally, to assess the quality of the resulting grid, the supremum norm of the interpolation error, $\\lVert f-L \\rVert_{\\infty}$, is approximated. This is done by sampling the true function $f(x)$ and the final piecewise linear interpolant $L(x)$ at a large number of test points, $\\{x^{\\mathrm{test}}_j\\}_{j=0}^{10000}$, uniformly distributed over $[a,b]$. The maximum absolute difference is computed as the error estimate $E$:\n$$ E = \\max_{0 \\le j \\le 10000} \\lvert f(x^{\\mathrm{test}}_j) - L(x^{\\mathrm{test}}_j) \\rvert $$\nThe final output for each test case consists of the final number of nodes $n$ and this estimated error $E$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_adaptive_interpolation(f, a, b, m0, tol, N_max):\n    \"\"\"\n    Constructs an adaptive grid for piecewise linear interpolation.\n\n    Args:\n        f (callable): The function to interpolate, f(x).\n        a (float): The start of the interval.\n        b (float): The end of the interval.\n        m0 (int): The initial number of grid points.\n        tol (float): The error tolerance for stopping.\n        N_max (int): The maximum number of grid points.\n\n    Returns:\n        list: A list containing the final number of nodes and the maximum error, [n, E].\n    \"\"\"\n    # 1. Initialization\n    # Using lists for efficient insertion of new nodes\n    x_nodes = np.linspace(a, b, m0).tolist()\n    y_nodes = [f(x) for x in x_nodes]\n\n    # 2. Refinement Loop\n    while len(x_nodes) < N_max:\n        n = len(x_nodes)\n        \n        # Guard against grids too small to compute second derivatives\n        if n < 3:\n            break\n\n        # Compute D2_k values for all interior nodes\n        D2_values = []\n        for k in range(1, n - 1):\n            x_km1, x_k, x_kp1 = x_nodes[k-1], x_nodes[k], x_nodes[k+1]\n            y_km1, y_k, y_kp1 = y_nodes[k-1], y_nodes[k], y_nodes[k+1]\n            \n            h_km1 = x_k - x_km1\n            h_k = x_kp1 - x_k\n            \n            # This should not happen with a strictly increasing grid\n            if h_km1 <= 0 or h_k <= 0 or (h_k + h_km1) == 0:\n                D2_k = 0.0\n            else:\n                term1 = (y_kp1 - y_k) / h_k\n                term2 = (y_k - y_km1) / h_km1\n                D2_k = 2.0 * (term1 - term2) / (h_k + h_km1)\n            D2_values.append(D2_k)\n\n        # Compute error indicators e_i for each interval\n        errors = []\n        num_intervals = n - 1\n        for i in range(num_intervals):\n            h_i = x_nodes[i+1] - x_nodes[i]\n            \n            # Compute curvature indicator s_i\n            if num_intervals <= 2: # Corresponds to n <= 3\n                # D2_values has 1 element, use it for all intervals\n                s_i = abs(D2_values[0])\n            elif i == 0: # First interval\n                s_i = abs(D2_values[0]) # |D2_1|\n            elif i == num_intervals - 1: # Last interval\n                s_i = abs(D2_values[-1]) # |D2_{n-2}|\n            else: # Interior intervals\n                # s_i = max(|D2_i|, |D2_{i+1}|)\n                # D2_values[k-1] corresponds to D2_k\n                # D2_values index is k-1. s_i needs D2_i, D2_{i+1}. Indices are i, i+1.\n                # So we need D2_values[i-1] and D2_values[i]\n                s_i = max(abs(D2_values[i]), abs(D2_values[i-1]))\n            \n            e_i = s_i * h_i**2\n            errors.append(e_i)\n        \n        # Check stopping criterion\n        max_error_indicator = max(errors)\n        if max_error_indicator <= tol:\n            break\n\n        # Refine grid: find smallest index i_star with max error and insert midpoint\n        i_star = errors.index(max_error_indicator)\n        \n        m = (x_nodes[i_star] + x_nodes[i_star+1]) / 2.0\n        fm = f(m)\n        \n        x_nodes.insert(i_star + 1, m)\n        y_nodes.insert(i_star + 1, fm)\n\n    # 3. Final Quality Assessment\n    n_final = len(x_nodes)\n    x_test = np.linspace(a, b, 10001)\n    y_true = np.array([f(x) for x in x_test])\n    \n    x_nodes_np = np.array(x_nodes)\n    y_nodes_np = np.array(y_nodes)\n    y_interp = np.interp(x_test, x_nodes_np, y_nodes_np)\n    \n    E = np.max(np.abs(y_true - y_interp))\n    \n    return [n_final, E]\n    \n\ndef solve():\n    \"\"\"\n    Runs the adaptive interpolation algorithm on a predefined test suite.\n    \"\"\"\n    # Define test functions\n    f1 = lambda x: np.sin(6 * x)\n    f2 = lambda x: 2 * x + 3\n    f3 = lambda x: np.arctan(50 * (x - 0.5))\n    f4 = lambda x: np.exp(x)\n    f5 = lambda x: np.sin(x)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (f1, 0.0, 1.0, 5, 0.02, 200),\n        (f2, 0.0, 1.0, 3, 1e-6, 50),\n        (f3, 0.0, 1.0, 5, 0.005, 200),\n        (f4, 0.0, 5.0, 5, 0.5, 300),\n        (f5, 0.0, 0.01, 3, 1e-4, 50)\n    ]\n\n    results = []\n    for case in test_cases:\n        # Unpack case parameters and call the solver\n        f, a, b, m0, tol, N_max = case\n        result = run_adaptive_interpolation(f, a, b, m0, tol, N_max)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'[{n},{E}]' for n, E in results])}]\")\n\nsolve()\n\n```", "id": "2423835"}]}