{"hands_on_practices": [{"introduction": "Before we can use the Newton polynomial, we must compute its coefficientsâ€”the divided differences. This exercise walks you through a memory-efficient, in-place algorithm for this very task, providing a concrete understanding of the computational backbone of Newton interpolation [@problem_id:2189914]. By tracing the algorithm step-by-step, you will see how the typically presented two-dimensional divided difference table can be condensed and calculated within a single array.", "problem": "In numerical analysis, Newton's form of the interpolating polynomial is a powerful tool for constructing a polynomial that passes through a given set of data points. The coefficients of this polynomial are the divided differences, denoted $f[x_0, \\dots, x_k]$. A common method for computing these coefficients involves constructing a large two-dimensional table.\n\nConsider a memory-efficient, in-place algorithm designed to compute these coefficients using only a single one-dimensional array of size $n+1$. This algorithm operates on a set of $n+1$ data points $(x_0, y_0), (x_1, y_1), \\dots, (x_n, y_n)$.\n\nThe algorithm proceeds as follows:\n1.  Initialize a one-dimensional array, let's call it $A$, of size $n+1$ with the dependent variable values. That is, $A_i$ is set to $y_i$ for $i = 0, 1, \\dots, n$.\n2.  Execute a nested loop. The outer loop iterates with an index $k$ from $1$ to $n$. The inner loop iterates with an index $j$ from $n$ down to $k$.\n3.  Inside the inner loop, update the array element $A_j$ using the formula:\n    $$A_j \\leftarrow \\frac{A_j - A_{j-1}}{x_j - x_{j-k}}$$\n\nAfter the algorithm terminates, the array $A$ will contain the required coefficients for the Newton polynomial, i.e., $A_k = f[x_0, \\dots, x_k]$ for $k=0, \\dots, n$.\n\nSuppose you are given the following four data points (so $n=3$):\n- $(x_0, y_0) = (-2, -5)$\n- $(x_1, y_1) = (-1, 1)$\n- $(x_2, y_2) = (1, 1)$\n- $(x_3, y_3) = (2, 7)$\n\nApply the memory-efficient algorithm described above to these data points. What are the final contents of the array $A$ after the algorithm completes its execution? Present your answer as a sequence of four numbers representing the elements $A_0, A_1, A_2, A_3$.", "solution": "We are given data points $(x_{0},y_{0})=(-2,-5)$, $(x_{1},y_{1})=(-1,1)$, $(x_{2},y_{2})=(1,1)$, $(x_{3},y_{3})=(2,7)$ and must run the in-place divided-differences algorithm:\n1) Initialize $A_{i}=y_{i}$ for $i=0,1,2,3$, so\n$$A_{0}=-5,\\quad A_{1}=1,\\quad A_{2}=1,\\quad A_{3}=7.$$\n\n2) For $k=1$ to $3$, for $j=3$ down to $k$, update\n$$A_{j}\\leftarrow \\frac{A_{j}-A_{j-1}}{x_{j}-x_{j-k}}.$$\n\nOuter loop $k=1$:\n- For $j=3$:\n$$A_{3}\\leftarrow \\frac{A_{3}-A_{2}}{x_{3}-x_{2}}=\\frac{7-1}{2-1}=6.$$\n- For $j=2$:\n$$A_{2}\\leftarrow \\frac{A_{2}-A_{1}}{x_{2}-x_{1}}=\\frac{1-1}{1-(-1)}=\\frac{0}{2}=0.$$\n- For $j=1$:\n$$A_{1}\\leftarrow \\frac{A_{1}-A_{0}}{x_{1}-x_{0}}=\\frac{1-(-5)}{-1-(-2)}=\\frac{6}{1}=6.$$\nArray after $k=1$:\n$$A=\\left(-5,\\ 6,\\ 0,\\ 6\\right).$$\n\nOuter loop $k=2$:\n- For $j=3$:\n$$A_{3}\\leftarrow \\frac{A_{3}-A_{2}}{x_{3}-x_{1}}=\\frac{6-0}{2-(-1)}=\\frac{6}{3}=2.$$\n- For $j=2$:\n$$A_{2}\\leftarrow \\frac{A_{2}-A_{1}}{x_{2}-x_{0}}=\\frac{0-6}{1-(-2)}=\\frac{-6}{3}=-2.$$\nArray after $k=2$:\n$$A=\\left(-5,\\ 6,\\ -2,\\ 2\\right).$$\n\nOuter loop $k=3$:\n- For $j=3$:\n$$A_{3}\\leftarrow \\frac{A_{3}-A_{2}}{x_{3}-x_{0}}=\\frac{2-(-2)}{2-(-2)}=\\frac{4}{4}=1.$$\nArray after $k=3$:\n$$A=\\left(-5,\\ 6,\\ -2,\\ 1\\right).$$\n\nThus the final contents are $A_{0}=-5$, $A_{1}=6$, $A_{2}=-2$, $A_{3}=1$.", "answer": "$$\\boxed{\\begin{pmatrix}-5  6  -2  1\\end{pmatrix}}$$", "id": "2189914"}, {"introduction": "The structure of the Newton form provides powerful insights into the relationship between the polynomial and the data points it interpolates. This practice reverses the typical problem; instead of building a polynomial from data, you will deduce the original data points from a given Newton-like polynomial [@problem_id:2189936]. This exercise sharpens your ability to interpret the polynomial's form and leverage its properties for analysis, as demonstrated in a hypothetical sensor modeling scenario.", "problem": "A research team is modeling the transient behavior of a newly developed sensor. The voltage output of the sensor, $V$, is measured as a function of time, $t$. Based on preliminary data, the team approximates the response with a quadratic polynomial, $V(t)$. The polynomial is constructed by interpolating three data points: $(t_A, V_A)$, $(t_B, V_B)$, and $(t_C, V_C)$.\n\nThe resulting polynomial is written in a specific Newton-like form as:\n$$V(t) = k_0 + k_1(t - t_A) + k_2(t - t_A)(t - t_C)$$\nwhere the constants are given as $k_0 = 5$, $k_1 = -2$, and $k_2 = 3$. The time coordinates for two of the data points are $t_A = 1 \\text{ s}$ and $t_C = 3 \\text{ s}$. The third data point, $(t_B, V_B)$, was measured at the time when the sensor's voltage reached its global minimum value on the interval $[t_A, t_C]$.\n\nDetermine the coordinates of the three data points $(t_A, V_A)$, $(t_B, V_B)$, and $(t_C, V_C)$. Express your answer as a single row matrix containing the six numerical values of the coordinates in the order $t_A, V_A, t_B, V_B, t_C, V_C$. Time values should be in seconds and voltage values in volts. Use exact fractions for any non-integer values.", "solution": "We are given the quadratic sensor response in a Newton-like form:\n$$V(t) = k_{0} + k_{1}(t - t_{A}) + k_{2}(t - t_{A})(t - t_{C}),$$\nwith $k_{0} = 5$, $k_{1} = -2$, $k_{2} = 3$, $t_{A} = 1$, and $t_{C} = 3$. The third point $(t_{B}, V_{B})$ corresponds to the global minimum of $V(t)$ on $[t_{A}, t_{C}]$.\n\nFirst, compute $V(t)$ explicitly by expanding:\n$$(t - t_{A})(t - t_{C}) = (t - 1)(t - 3) = t^{2} - 4t + 3.$$\nThus,\n$$V(t) = 5 - 2(t - 1) + 3(t^{2} - 4t + 3) = 5 - 2t + 2 + 3t^{2} - 12t + 9,$$\nwhich simplifies to\n$$V(t) = 3t^{2} - 14t + 16.$$\n\nEvaluate $V$ at $t_{A}$ and $t_{C}$ to get $V_{A}$ and $V_{C}$:\n- Using the given form, at $t = t_{A}$, $(t - t_{A}) = 0$, so\n$$V_{A} = V(t_{A}) = k_{0} = 5.$$\n- At $t = t_{C}$, $(t - t_{C}) = 0$, so\n$$V_{C} = V(t_{C}) = k_{0} + k_{1}(t_{C} - t_{A}) = 5 + (-2)(3 - 1) = 1.$$\n\nTo find the global minimum on $[1,3]$, differentiate $V(t)$:\n$$V'(t) = 6t - 14.$$\nSet $V'(t) = 0$ to locate the critical point:\n$$6t - 14 = 0 \\implies t = \\frac{14}{6} = \\frac{7}{3}.$$\nSince $V''(t) = 6 > 0$, $V$ is convex and this critical point is a global minimum. It lies in the interval $[1,3]$, so $t_{B} = \\frac{7}{3}$ and\n$$V_{B} = V\\!\\left(\\frac{7}{3}\\right) = 3\\left(\\frac{7}{3}\\right)^{2} - 14\\left(\\frac{7}{3}\\right) + 16 = \\frac{147}{9} - \\frac{98}{3} + 16 = \\frac{49}{3} - \\frac{98}{3} + \\frac{48}{3} = -\\frac{1}{3}.$$\n\nTherefore, the three data points are $(t_{A}, V_{A}) = (1, 5)$, $(t_{B}, V_{B}) = \\left(\\frac{7}{3}, -\\frac{1}{3}\\right)$, and $(t_{C}, V_{C}) = (3, 1)$. The requested row matrix is $1, 5, \\frac{7}{3}, -\\frac{1}{3}, 3, 1$.", "answer": "$$\\boxed{\\begin{pmatrix}1  5  \\frac{7}{3}  -\\frac{1}{3}  3  1\\end{pmatrix}}$$", "id": "2189936"}, {"introduction": "While polynomial interpolation is a powerful tool, high-degree interpolants can behave unexpectedly, especially with poorly chosen interpolation points. This advanced practice has you confront the famous Runge phenomenon, where interpolation with equally spaced nodes leads to wild oscillations near the interval's ends [@problem_id:2426405]. By implementing Newton interpolation for both equally spaced nodes and strategically chosen Chebyshev nodes, you will computationally verify this phenomenon and discover why node placement is critical for achieving accurate and stable approximations.", "problem": "You are to implement polynomial interpolation in Newton form for the Runge function using two node-generation strategies. Start from the fundamental definition that for $n+1$ distinct nodes $\\{x_0,\\dots,x_n\\}$ and function values $\\{f(x_0),\\dots,f(x_n)\\}$, there exists a unique polynomial $p_n(x)$ of degree at most $n$ that satisfies $p_n(x_i)=f(x_i)$ for all $i$. Use the recursive definition of divided differences and the Newton basis to derive a numerically stable evaluation algorithm. The target function is the Runge function $f(x)=\\dfrac{1}{1+25x^2}$ on $[-1,1]$. All angles must be in radians.\n\nYour tasks are:\n- Implement a function to compute the divided differences for nodes $\\{x_i\\}_{i=0}^n$ and values $\\{f(x_i)\\}_{i=0}^n$, producing the Newton-form coefficients $\\{c_0,\\dots,c_n\\}$ for $p_n(x)$.\n- Implement a function to evaluate the Newton-form interpolant at arbitrary $x$ using nested multiplication based on the Newton basis $\\{1,(x-x_0),(x-x_0)(x-x_1),\\dots\\}$ and the previously computed coefficients $\\{c_k\\}_{k=0}^n$.\n- Generate two sets of interpolation nodes on $[-1,1]$ for each degree $n$:\n  - Equally spaced nodes: $x_i=-1+\\dfrac{2i}{n}$ for $i=0,\\dots,n$.\n  - Chebyshev nodes of the first kind (extrema) on $[-1,1]$: $x_i=\\cos\\!\\left(\\dfrac{i\\pi}{n}\\right)$ for $i=0,\\dots,n$. Use radians.\n- For each interpolant, evaluate $p_n(x)$ on a dense grid of $M$ points uniformly spaced on $[-1,1]$ and compute the maximum absolute error $E_{\\max}=\\max_{x\\in\\mathcal{G}}|p_n(x)-f(x)|$, where $\\mathcal{G}$ is the evaluation grid.\n- Do all arithmetic in double precision.\n\nTest suite specification:\n- Use the Runge function $f(x)=\\dfrac{1}{1+25x^2}$ on $[-1,1]$.\n- Use an evaluation grid $\\mathcal{G}$ of $M=10001$ equally spaced points on $[-1,1]$.\n- Use the following degrees (with $n+1$ nodes each): $n\\in\\{0,1,5,10,20\\}$.\n- For each $n$ in the above set, compute two numbers: $E_{\\max}^{\\text{eq}}(n)$ for equally spaced nodes and $E_{\\max}^{\\text{ch}}(n)$ for Chebyshev nodes (with angles in radians).\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain real numbers in the following order:\n  - $\\big[E_{\\max}^{\\text{eq}}(0),E_{\\max}^{\\text{ch}}(0),E_{\\max}^{\\text{eq}}(1),E_{\\max}^{\\text{ch}}(1),E_{\\max}^{\\text{eq}}(5),E_{\\max}^{\\text{ch}}(5),E_{\\max}^{\\text{eq}}(10),E_{\\max}^{\\text{ch}}(10),E_{\\max}^{\\text{eq}}(20),E_{\\max}^{\\text{ch}}(20)\\big]$.\n- The output must be a single line and must not contain any additional text.", "solution": "The problem starts from the core definition of interpolation: given $n+1$ distinct nodes $\\{x_0,\\dots,x_n\\}$ and data values $\\{y_0,\\dots,y_n\\}$ with $y_i=f(x_i)$, there exists a unique polynomial $p_n(x)$ of degree at most $n$ such that $p_n(x_i)=y_i$ for $i=0,\\dots,n$. One constructive representation is the Newton form, which combines two fundamental pieces: divided differences and the Newton basis. The Newton basis is defined recursively as $N_0(x)=1$, $N_k(x)=(x-x_{k-1})N_{k-1}(x)$ for $k\\ge 1$, which yields $N_k(x)=\\prod_{j=0}^{k-1}(x-x_j)$. The interpolant can be expressed as $p_n(x)=\\sum_{k=0}^n c_k N_k(x)$, where the coefficients $c_k$ are the divided differences $c_k=f[x_0,\\dots,x_k]$. The divided differences are determined from the data via the recursion $f[x_i]=y_i$ and, for $k\\ge 1$, $f[x_i,\\dots,x_{i+k}]=\\dfrac{f[x_{i+1},\\dots,x_{i+k}]-f[x_i,\\dots,x_{i+k-1}]}{x_{i+k}-x_i}$. This construction directly encodes the data constraints $p_n(x_i)=y_i$ by induction on $i$, ensuring existence and uniqueness.\n\nAlgorithmic design proceeds as follows. First, compute the divided differences. We can implement the recursion in-place on an array $d$ initialized as $d_i^{(0)}=y_i$. For each order $k=1,\\dots,n$ and indices $i=0,\\dots,n-k$, update $d_i^{(k)}=\\dfrac{d_{i+1}^{(k-1)}-d_i^{(k-1)}}{x_{i+k}-x_i}$. After completing all orders, the Newton coefficients are $c_k=d_0^{(k)}$ for $k=0,\\dots,n$. This is an $O(n^2)$ operation and uses only the core recursion.\n\nSecond, evaluate the interpolant efficiently and stably by nested multiplication (a Horner-like scheme adapted to the Newton basis). Starting with $v=c_n$, accumulate $v \\leftarrow c_{k}+ (x-x_k)\\,v$ for $k=n-1,\\dots,0$. This follows from the basis identity $N_{k+1}(x)=(x-x_k)N_k(x)$ rearranged to express $p_n$ in nested form: $p_n(x)=c_0+(x-x_0)\\left(c_1+(x-x_1)\\left(\\dots+(x-x_{n-1})c_n\\right)\\right)$. This evaluation is $O(n)$ per point and numerically stable relative to a naive basis expansion.\n\nFor node placement, we compare two strategies on $[-1,1]$. Equally spaced nodes use $x_i=-1+\\dfrac{2i}{n}$ for $i=0,\\dots,n$. Chebyshev nodes of the first kind (extrema) are $x_i=\\cos\\!\\left(\\dfrac{i\\pi}{n}\\right)$ for $i=0,\\dots,n$, which cluster near the endpoints and are known to reduce the maximum interpolation error for analytic functions. All trigonometric computations use radians, as specified. The Runge function $f(x)=\\dfrac{1}{1+25x^2}$ is analytic on and around $[-1,1]$, yet it famously exhibits the Runge phenomenon when interpolated with equally spaced nodes: as $n$ increases, the maximum error $E_{\\max}$ may worsen due to oscillations near $x=\\pm 1$. Chebyshev nodes mitigate this by minimizing the Lebesgue constant growth and distributing node density where it is most needed.\n\nTo quantify the behavior, we evaluate on a dense grid $\\mathcal{G}$ of $M=10001$ equispaced points on $[-1,1]$. For each $n\\in\\{0,1,5,10,20\\}$ and each node strategy, we compute the interpolant $p_n(x)$ on $\\mathcal{G}$ and then the maximum absolute error $E_{\\max}=\\max_{x\\in\\mathcal{G}}|p_n(x)-f(x)|$. The program outputs the sequence $[E_{\\max}^{\\text{eq}}(0),E_{\\max}^{\\text{ch}}(0),E_{\\max}^{\\text{eq}}(1),E_{\\max}^{\\text{ch}}(1),E_{\\max}^{\\text{eq}}(5),E_{\\max}^{\\text{ch}}(5),E_{\\max}^{\\text{eq}}(10),E_{\\max}^{\\text{ch}}(10),E_{\\max}^{\\text{eq}}(20),E_{\\max}^{\\text{ch}}(20)]$ on a single line. We expect $E_{\\max}^{\\text{eq}}(n)$ to initially decrease and then increase with $n$ due to the Runge phenomenon, while $E_{\\max}^{\\text{ch}}(n)$ should decrease more steadily.\n\nImplementation details ensure numerical robustness:\n- Divided differences are computed in place using double-precision arrays to avoid unnecessary copies.\n- The evaluation uses vectorized nested multiplication over the grid for efficiency.\n- For the Chebyshev node generator, $n=0$ is handled explicitly, yielding the single node $x_0=\\cos(0)=1$. For $n\\ge 1$, nodes $\\cos\\!\\left(\\dfrac{i\\pi}{n}\\right)$ for $i=0,\\dots,n$ are generated and sorted to ascending order; sorting does not change the interpolating polynomial when coefficients are recomputed for the sorted order, and it yields consistent ordering across strategies.\n\nThis principled approach directly reflects the core definitions of interpolation and divided differences, employs the Newton basis to obtain an efficient algorithm, and computes the requested error metrics on a fixed grid for objective comparison across node sets and degrees.", "answer": "```python\nimport numpy as np\n\ndef runge_function(x: np.ndarray) - np.ndarray:\n    # f(x) = 1 / (1 + 25 x^2)\n    return 1.0 / (1.0 + 25.0 * x * x)\n\ndef divided_differences(x: np.ndarray, y: np.ndarray) - np.ndarray:\n    \"\"\"\n    Compute Newton divided differences coefficients.\n    x: nodes (n+1,)\n    y: values at nodes (n+1,)\n    Returns coefficients c such that p(x) = c0 + c1*(x-x0) + ... in Newton form.\n    \"\"\"\n    n = x.size - 1\n    dd = y.astype(float).copy()\n    # In-place computation: dd[i] overwritten by higher-order divided differences\n    for k in range(1, n + 1):\n        # Update dd[0..n-k]\n        denom = x[k:] - x[:-k]\n        # Avoid division by zero; nodes are distinct by construction\n        dd[: n - k + 1] = (dd[1: n - k + 2] - dd[: n - k + 1]) / denom\n    # Coefficients are dd[0] at each order; we need to reconstruct them\n    # We can recompute to capture dd[0] at each stage by re-running but more efficient:\n    # Build the table once and collect c's\n    # Rebuild more explicitly:\n    dd_table = y.astype(float).copy()\n    coeffs = [dd_table[0]]\n    for k in range(1, n + 1):\n        dd_table[: n - k + 1] = (dd_table[1: n - k + 2] - dd_table[: n - k + 1]) / (x[k:] - x[:-k])\n        coeffs.append(dd_table[0])\n    return np.array(coeffs, dtype=float)\n\ndef newton_evaluate(x_eval: np.ndarray, x_nodes: np.ndarray, coeffs: np.ndarray) - np.ndarray:\n    \"\"\"\n    Evaluate Newton-form polynomial with given nodes and coefficients at x_eval.\n    Uses nested multiplication (Horner-like) for Newton basis.\n    \"\"\"\n    # Start from highest-order coefficient\n    p = np.full_like(x_eval, fill_value=coeffs[-1], dtype=float)\n    # Iterate backwards over nodes\n    for k in range(len(coeffs) - 2, -1, -1):\n        p = coeffs[k] + (x_eval - x_nodes[k]) * p\n    return p\n\ndef equispaced_nodes(n: int) - np.ndarray:\n    # n+1 nodes from -1 to 1 inclusive\n    return np.linspace(-1.0, 1.0, n + 1, dtype=float)\n\ndef chebyshev_extrema_nodes(n: int) - np.ndarray:\n    # Chebyshev nodes of the first kind (extrema): x_i = cos(i*pi/n), i=0..n\n    if n == 0:\n        nodes = np.array([1.0], dtype=float)\n    else:\n        i = np.arange(0, n + 1, dtype=float)\n        nodes = np.cos(np.pi * i / float(n))\n    # Sort ascending for consistency\n    nodes.sort()\n    return nodes\n\ndef max_abs_error_on_grid(n: int, node_strategy: str, grid: np.ndarray) - float:\n    if node_strategy == \"equispaced\":\n        x_nodes = equispaced_nodes(n)\n    elif node_strategy == \"chebyshev\":\n        x_nodes = chebyshev_extrema_nodes(n)\n    else:\n        raise ValueError(\"Unknown node strategy\")\n\n    y_nodes = runge_function(x_nodes)\n    coeffs = divided_differences(x_nodes, y_nodes)\n    p_vals = newton_evaluate(grid, x_nodes, coeffs)\n    f_vals = runge_function(grid)\n    err = np.abs(p_vals - f_vals)\n    return float(np.max(err))\n\ndef solve():\n    # Define the test cases: degrees n\n    n_values = [0, 1, 5, 10, 20]\n    # Evaluation grid of M=10001 points on [-1,1]\n    M = 10001\n    grid = np.linspace(-1.0, 1.0, M, dtype=float)\n\n    results = []\n    for n in n_values:\n        e_eq = max_abs_error_on_grid(n, \"equispaced\", grid)\n        e_ch = max_abs_error_on_grid(n, \"chebyshev\", grid)\n        results.append(e_eq)\n        results.append(e_ch)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2426405"}]}