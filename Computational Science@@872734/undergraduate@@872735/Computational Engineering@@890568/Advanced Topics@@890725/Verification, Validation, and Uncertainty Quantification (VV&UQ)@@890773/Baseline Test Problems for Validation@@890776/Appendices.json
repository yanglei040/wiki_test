{"hands_on_practices": [{"introduction": "This practice focuses on one of the most fundamental stochastic processes: the random walk. You will implement a simulation of random walkers and verify a cornerstone result of statistical physics—that the mean squared displacement grows linearly with time. This exercise demonstrates how to validate a stochastic code by testing its output against a theoretical scaling law and highlights the concept of statistical convergence [@problem_id:2373658].", "problem": "Consider a one-dimensional discrete-time random walk defined as follows. There are $N$ independent walkers. For each walker $i \\in \\{1,\\dots,N\\}$ and each discrete time step $t \\in \\{1,\\dots,T\\}$, the position $x_i(t)$ evolves according to $x_i(t) = \\sum_{k=1}^{t} s_i(k)$, where the steps $s_i(k)$ are independent and identically distributed with zero mean. The empirical mean squared displacement (mean squared displacement (MSD)) at time $t$ over the ensemble of walkers is $\\widehat{M}(t) = \\frac{1}{N} \\sum_{i=1}^{N} x_i(t)^2$. For each test case, define the set of times as $\\{1,2,\\dots,T\\}$ and consider the best affine function $f(t) = \\alpha + \\beta t$ that minimizes the sum of squared residuals $\\sum_{t=1}^{T} \\left(\\widehat{M}(t) - f(t)\\right)^2$. Let $R^2$ denote the coefficient of determination $R^2 = 1 - \\frac{\\sum_{t=1}^{T} \\left(\\widehat{M}(t) - f(t)\\right)^2}{\\sum_{t=1}^{T} \\left(\\widehat{M}(t) - \\overline{\\widehat{M}}\\right)^2}$, where $\\overline{\\widehat{M}}$ is the average of $\\widehat{M}(t)$ over $t \\in \\{1,\\dots,T\\}$.\n\nYour task is to simulate the random walks under the specified step distributions and parameter values, compute $\\widehat{M}(t)$ for all $t \\in \\{1,\\dots,T\\}$, fit the affine function $f(t)$ in the least-squares sense to obtain $\\beta$, compute $R^2$, and, for each test case, return a boolean indicating whether both of the following validation conditions are simultaneously satisfied:\n- The absolute deviation $|\\beta - \\beta_{\\mathrm{expected}}|$ is less than or equal to a given absolute tolerance $\\varepsilon$.\n- The coefficient of determination $R^2$ is greater than or equal to a given threshold $R^2_{\\min}$.\n\nEach test case specifies the number of walkers $N$, the number of time steps $T$, the step distribution family and its parameters, the expected slope $\\beta_{\\mathrm{expected}}$, the absolute tolerance $\\varepsilon$, and the minimum acceptable coefficient of determination $R^2_{\\min}$. The discrete time step is $\\Delta t = 1$, and the time index $t$ is dimensionless; no physical units are involved.\n\nUse the following test suite, with the distributions defined purely by their parameters as indicated. In all cases, the steps $s_i(k)$ are independent across $i$ and $k$.\n- Case $1$ (happy path, symmetric Bernoulli): $N = 40000$, $T = 300$, distribution: symmetric Bernoulli with amplitude $a$, namely $s_i(k) \\in \\{-a,+a\\}$ with equal probability and $a = 1$. Expected slope $\\beta_{\\mathrm{expected}} = 1$. Absolute tolerance $\\varepsilon = 0.02$. Minimum $R^2_{\\min} = 0.999$.\n- Case $2$ (small-sample boundary, symmetric Bernoulli): $N = 300$, $T = 25$, distribution: symmetric Bernoulli with amplitude $a = 1$. Expected slope $\\beta_{\\mathrm{expected}} = 1$. Absolute tolerance $\\varepsilon = 0.35$. Minimum $R^2_{\\min} = 0.90$.\n- Case $3$ (Gaussian steps): $N = 40000$, $T = 300$, distribution: Gaussian with mean $0$ and standard deviation $\\sigma = 2$. Expected slope $\\beta_{\\mathrm{expected}} = 4$. Absolute tolerance $\\varepsilon = 0.08$. Minimum $R^2_{\\min} = 0.999$.\n- Case $4$ (uniform steps with matched variance): $N = 40000$, $T = 300$, distribution: uniform on $[-a,a]$ with $a = \\sqrt{3}$. Expected slope $\\beta_{\\mathrm{expected}} = 1$. Absolute tolerance $\\varepsilon = 0.025$. Minimum $R^2_{\\min} = 0.999$.\n- Case $5$ (sparse steps with matched variance): $N = 40000$, $T = 300$, distribution: with probability $p$ take $s_i(k) \\in \\{-b,+b\\}$ with equal probability, otherwise $s_i(k) = 0$, where $p = 0.1$ and $b = \\sqrt{10}$. Expected slope $\\beta_{\\mathrm{expected}} = 1$. Absolute tolerance $\\varepsilon = 0.03$. Minimum $R^2_{\\min} = 0.999$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the cases above, where each entry is a boolean indicating whether the test case passes both validation conditions (for example, \"[True,False,True,True,False]\"). No additional text should be printed.", "solution": "The problem statement is valid. It presents a well-defined computational experiment based on the standard model of a one-dimensional discrete-time random walk, a fundamental concept in statistical mechanics and stochastic processes. All parameters, definitions, and conditions are provided, and the underlying scientific principles are sound.\n\nThe core principle is the relationship between the microscopic dynamics of a random walker and its macroscopic diffusion behavior, quantified by the Mean Squared Displacement (MSD). For a single walker $i$, its position at a discrete time step $t$ is the sum of its previous steps, $x_i(t) = \\sum_{k=1}^{t} s_i(k)$. The steps $s_i(k)$ are independent and identically distributed random variables with zero mean, $\\mathbb{E}[s_i(k)] = 0$, and a finite variance, $\\text{Var}(s_i(k)) = \\sigma_s^2$.\n\nThe theoretical MSD, denoted $M(t)$, is the ensemble average of the squared displacement, defined as $M(t) = \\mathbb{E}[x_i(t)^2]$. We can derive its form as follows:\n$$M(t) = \\mathbb{E}\\left[ \\left( \\sum_{k=1}^{t} s_i(k) \\right)^2 \\right] = \\mathbb{E}\\left[ \\sum_{k=1}^{t} \\sum_{l=1}^{t} s_i(k) s_i(l) \\right]$$\nBy the linearity of the expectation operator, this becomes:\n$$M(t) = \\sum_{k=1}^{t} \\sum_{l=1}^{t} \\mathbb{E}[s_i(k) s_i(l)]$$\nSince the steps $s_i(k)$ are independent for different time indices, the expectation of their product separates, $\\mathbb{E}[s_i(k)s_i(l)] = \\mathbb{E}[s_i(k)]\\mathbb{E}[s_i(l)]$ for $k \\neq l$. As the mean of each step is zero, these cross-terms all vanish. The only non-zero contributions come from terms where $k=l$:\n$$\\mathbb{E}[s_i(k)s_i(k)] = \\mathbb{E}[s_i(k)^2] = \\text{Var}(s_i(k)) + (\\mathbb{E}[s_i(k)])^2 = \\sigma_s^2 + 0^2 = \\sigma_s^2$$\nThe sum thus simplifies to:\n$$M(t) = \\sum_{k=1}^{t} \\mathbb{E}[s_i(k)^2] = \\sum_{k=1}^{t} \\sigma_s^2 = \\sigma_s^2 t$$\nThis result shows that the theoretical MSD is a linear function of time, with a slope equal to the variance of the step distribution. This is a hallmark of normal diffusion.\n\nThe problem asks to compute the empirical MSD, $\\widehat{M}(t)$, by averaging over a finite ensemble of $N$ walkers:\n$$\\widehat{M}(t) = \\frac{1}{N} \\sum_{i=1}^{N} x_i(t)^2$$\nAccording to the law of large numbers, for a sufficiently large $N$, $\\widehat{M}(t)$ serves as a good approximation of the theoretical expectation $M(t)$. Therefore, we anticipate that the empirical data points $(t, \\widehat{M}(t))$ for $t \\in \\{1, \\dots, T\\}$ will lie close to a straight line passing through the origin.\n\nThe task is to fit these empirical data to an affine function $f(t) = \\alpha + \\beta t$ by minimizing the sum of squared residuals, $\\sum_{t=1}^{T} (\\widehat{M}(t) - f(t))^2$. This is a standard simple linear regression problem. The slope $\\beta$ of the best-fit line is an empirical estimate of the theoretical slope $\\sigma_s^2$. The problem provides expected values for the slope, $\\beta_{\\mathrm{expected}}$, which correspond to the theoretical variance $\\sigma_s^2$ for each specified step distribution. For example, for the symmetric Bernoulli distribution with steps $\\pm a$, the variance is $\\sigma_s^2 = (-a)^2(0.5) + (a)^2(0.5) = a^2$. For $a=1$, $\\sigma_s^2 = 1$, matching $\\beta_{\\mathrm{expected}}$. All other cases are similarly consistent.\n\nThe algorithmic procedure to solve the problem for each test case is as follows:\n1.  **Simulation of Steps**: For $N$ walkers and $T$ time steps, generate an $N \\times T$ matrix of random steps, where each element is drawn independently from the specified probability distribution (Bernoulli, Gaussian, uniform, or sparse).\n2.  **Calculation of Trajectories**: Compute the trajectory for each walker by taking the cumulative sum of its steps along the time axis. This yields an $N \\times T$ matrix of positions $x_i(t)$.\n3.  **Calculation of Empirical MSD**: For each time point $t$ from $1$ to $T$, square the positions of all walkers and compute the mean across the $N$ walkers. This results in a vector $\\widehat{M}(t)$ of length $T$.\n4.  **Linear Regression**: Perform a simple linear regression on the data points $(t, \\widehat{M}(t))$ for $t \\in \\{1, \\dots, T\\}$. This yields the best-fit slope $\\beta$.\n5.  **Coefficient of Determination**: Calculate the coefficient of determination $R^2 = 1 - \\frac{\\sum_{t=1}^{T} (\\widehat{M}(t) - f(t))^2}{\\sum_{t=1}^{T} (\\widehat{M}(t) - \\overline{\\widehat{M}})^2}$ to quantify the goodness of fit of the linear model.\n6.  **Validation**: Compare the computed $\\beta$ and $R^2$ against the provided thresholds. A case passes if and only if both $|\\beta - \\beta_{\\mathrm{expected}}| \\le \\varepsilon$ and $R^2 \\ge R^2_{\\min}$ are true.\n\nThis procedure is implemented using the `numpy` library for efficient vectorized computation and the `scipy.stats.linregress` function for a robust and direct calculation of the regression slope and coefficient of determination.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import linregress\n\ndef run_case(case_params):\n    \"\"\"\n    Runs a single simulation case for a random walk ensemble.\n\n    Args:\n        case_params (dict): A dictionary containing all parameters for the case.\n\n    Returns:\n        bool: True if both validation conditions are met, False otherwise.\n    \"\"\"\n    N = case_params['N']\n    T = case_params['T']\n    dist_info = case_params['distribution']\n    beta_expected = case_params['beta_expected']\n    epsilon = case_params['epsilon']\n    r_squared_min = case_params['r_squared_min']\n\n    # Step 1: Generate steps based on the specified distribution.\n    if dist_info['name'] == 'bernoulli':\n        a = dist_info['a']\n        steps = np.random.choice([-a, a], size=(N, T))\n    elif dist_info['name'] == 'gaussian':\n        sigma = dist_info['sigma']\n        steps = np.random.normal(loc=0.0, scale=sigma, size=(N, T))\n    elif dist_info['name'] == 'uniform':\n        a = dist_info['a']\n        steps = np.random.uniform(low=-a, high=a, size=(N, T))\n    elif dist_info['name'] == 'sparse':\n        p = dist_info['p']\n        b = dist_info['b']\n        # Efficiently generate sparse steps:\n        # First, generate choices from {-b, b} for all potential steps.\n        potential_steps = np.random.choice([-b, b], size=(N, T))\n        # Then, create a mask to determine which steps are non-zero.\n        is_step_taken = np.random.rand(N, T)  p\n        steps = potential_steps * is_step_taken\n    else:\n        # This should not be reached with the given problem statement.\n        raise ValueError(f\"Unknown distribution name: {dist_info['name']}\")\n\n    # Step 2: Compute trajectories by taking the cumulative sum of steps.\n    # The positions are the cumulative sum along the time axis (axis=1).\n    positions = np.cumsum(steps, axis=1)\n\n    # Step 3: Compute the empirical Mean Squared Displacement (MSD).\n    # For each time t, average the squared positions over all N walkers (axis=0).\n    msd_empirical = np.mean(np.square(positions), axis=0)\n\n    # Step 4: Perform linear regression on the MSD data.\n    # The time vector t runs from 1 to T.\n    t_values = np.arange(1, T + 1)\n    \n    # Use scipy.stats.linregress for a robust linear fit.\n    # It directly returns slope, intercept, r_value, p_value, and stderr.\n    regression_result = linregress(t_values, msd_empirical)\n    beta_fit = regression_result.slope\n    # The coefficient of determination R^2 is the square of the correlation coefficient r_value.\n    r_squared = regression_result.rvalue**2\n\n    # Step 5: Validate the results against the given conditions.\n    condition_beta = np.abs(beta_fit - beta_expected) = epsilon\n    condition_r2 = r_squared >= r_squared_min\n\n    return condition_beta and condition_r2\n\ndef solve():\n    \"\"\"\n    Defines and runs the suite of test cases, then prints the results.\n    \"\"\"\n    test_cases = [\n        # Case 1: Happy path, symmetric Bernoulli\n        {\n            'N': 40000, 'T': 300, \n            'distribution': {'name': 'bernoulli', 'a': 1.0},\n            'beta_expected': 1.0, 'epsilon': 0.02, 'r_squared_min': 0.999\n        },\n        # Case 2: Small-sample boundary, symmetric Bernoulli\n        {\n            'N': 300, 'T': 25,\n            'distribution': {'name': 'bernoulli', 'a': 1.0},\n            'beta_expected': 1.0, 'epsilon': 0.35, 'r_squared_min': 0.90\n        },\n        # Case 3: Gaussian steps\n        {\n            'N': 40000, 'T': 300,\n            'distribution': {'name': 'gaussian', 'sigma': 2.0},\n            'beta_expected': 4.0, 'epsilon': 0.08, 'r_squared_min': 0.999\n        },\n        # Case 4: Uniform steps with matched variance\n        {\n            'N': 40000, 'T': 300,\n            'distribution': {'name': 'uniform', 'a': np.sqrt(3)},\n            'beta_expected': 1.0, 'epsilon': 0.025, 'r_squared_min': 0.999\n        },\n        # Case 5: Sparse steps with matched variance\n        {\n            'N': 40000, 'T': 300,\n            'distribution': {'name': 'sparse', 'p': 0.1, 'b': np.sqrt(10)},\n            'beta_expected': 1.0, 'epsilon': 0.03, 'r_squared_min': 0.999\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_case(case)\n        results.append(result)\n\n    # Print the final result in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Execute the solver.\nsolve()\n```", "id": "2373658"}, {"introduction": "Here, we use the classic one-dimensional heat equation as a benchmark for validating a PDE solver or a data-driven surrogate model. By using a sinusoidal initial condition on a periodic domain, we can derive a simple, exact analytical solution. Your task is to compare a hypothetical model's prediction against this exact solution, providing a concrete example of how to quantify accuracy and diagnose different types of error in a continuous field simulation [@problem_id:2373647].", "problem": "You are validating a data-driven surrogate for a partial differential equation by benchmarking it against a canonical, exactly solvable case. Consider the One-Dimensional (1D) heat equation on a periodic domain,\n$$\n\\frac{\\partial u}{\\partial t}(x,t) = \\alpha \\,\\frac{\\partial^2 u}{\\partial x^2}(x,t), \\quad x \\in [0,L), \\quad t \\ge 0,\n$$\nwith periodic boundary condition on $[0,L)$ and the sinusoidal initial condition\n$$\nu(x,0) = A \\,\\sin\\!\\big(m\\,x + \\phi\\big).\n$$\nAll angles must be interpreted in radians. All quantities are dimensionless. The domain length is $L = 2\\pi$.\n\nYour task is to write a complete program that, for a set of provided test cases, computes the relative discrete $L^2$-error of a given predicted field with respect to the exact solution of the heat equation for the same parameters. Use a uniform grid of $N_x$ points,\n$$\nx_i = \\frac{i\\,L}{N_x}, \\quad i = 0,1,\\dots,N_x-1,\n$$\nand define the discrete $L^2$-norm of a grid function $v_i$ by\n$$\n\\|v\\|_2 = \\sqrt{\\sum_{i=0}^{N_x-1} v_i^2},\n$$\nand the relative error to be\n$$\nE = \\frac{\\|u_{\\mathrm{pred}} - u_{\\mathrm{exact}}\\|_2}{\\|u(\\cdot,0)\\|_2}.\n$$\nHere $u_{\\mathrm{pred}}$ denotes the provided predicted field for the test, $u_{\\mathrm{exact}}$ denotes the exact solution evaluated at the same grid points and time, and $u(\\cdot,0)$ denotes the initial condition evaluated at the same grid points. Angles must be in radians.\n\nTest suite. Evaluate the relative error $E$ for each of the following four test cases. In all cases, the domain length is $L = 2\\pi$ and the grid uses $N_x = 64$ points.\n\n- Test Case A (happy path):\n  - Parameters: $\\alpha = 0.3$, $A = 1.0$, $m = 3$, $\\phi = \\pi/6$, $t = 0.5$.\n  - Predicted field: $u_{\\mathrm{pred}}$ equals the exact solution for these parameters.\n\n- Test Case B (small structured perturbation):\n  - Parameters: $\\alpha = 0.3$, $A = 1.0$, $m = 3$, $\\phi = \\pi/6$, $t = 0.5$.\n  - Predicted field: $u_{\\mathrm{pred}}(x) = u_{\\mathrm{exact}}(x,t) + \\varepsilon\\,A\\,\\sin(r\\,x)$ with $\\varepsilon = 0.01$ and $r = 7$.\n\n- Test Case C (diffusivity mismatch):\n  - Parameters: $\\alpha = 0.3$, $A = 1.0$, $m = 3$, $\\phi = \\pi/6$, $t = 0.5$.\n  - Predicted field: $u_{\\mathrm{pred}}(x) = A\\,\\exp\\!\\big(-(1+\\delta)\\,\\alpha\\,m^2\\,t\\big)\\,\\sin(m\\,x + \\phi)$ with $\\delta = 0.2$.\n\n- Test Case D (phase error at initial time):\n  - Parameters: $\\alpha = 0.3$, $A = 1.0$, $m = 5$, $\\phi = \\pi/4$, $t = 0$.\n  - Predicted field: $u_{\\mathrm{pred}}(x) = A\\,\\sin\\!\\big(m\\,x + (\\phi + \\Delta\\phi)\\big)$ with $\\Delta\\phi = \\pi/12$.\n\nImplementation requirements:\n- Compute the exact solution $u_{\\mathrm{exact}}(x,t)$ implied by the heat equation, the periodic boundary condition, and the given initial condition, at the specified time $t$ and grid points $x_i$, for each test case.\n- For each test case, compute the relative error $E$ as defined above.\n- Final output format: Your program should produce a single line of output containing the four relative errors for Test Cases A, B, C, and D, in that order, rounded to $10$ decimal places, as a comma-separated list enclosed in square brackets, for example, \"[e_A,e_B,e_C,e_D]\".", "solution": "The problem statement has been analyzed and is determined to be valid. It is scientifically grounded, well-posed, objective, and contains all necessary information for a unique solution. We may proceed.\n\nThe task is to compute a benchmark for a surrogate model by calculating the relative discrete $L^2$-error against an exact analytical solution of the one-dimensional heat equation.\n\nFirst, we must find the exact solution to the governing partial differential equation,\n$$\n\\frac{\\partial u}{\\partial t}(x,t) = \\alpha \\,\\frac{\\partial^2 u}{\\partial x^2}(x,t)\n$$\non the domain $x \\in [0,L)$ with $L=2\\pi$, subject to periodic boundary conditions and the initial condition\n$$\nu(x,0) = A \\,\\sin(m\\,x + \\phi).\n$$\nThis is a linear partial differential equation. We can test for a solution of a form that preserves the sinusoidal spatial structure of the initial condition. Let us propose a solution of the form:\n$$\nu(x,t) = f(t) \\sin(m\\,x + \\phi).\n$$\nSubstituting this into the heat equation requires computing the partial derivatives:\n$$\n\\frac{\\partial u}{\\partial t} = f'(t) \\sin(m\\,x + \\phi)\n$$\n$$\n\\frac{\\partial u}{\\partial x} = f(t) \\cos(m\\,x + \\phi) \\cdot m\n$$\n$$\n\\frac{\\partial^2 u}{\\partial x^2} = -f(t) \\sin(m\\,x + \\phi) \\cdot m^2 = -m^2 u(x,t) / f(t)\n$$\nThe heat equation becomes:\n$$\nf'(t) \\sin(m\\,x + \\phi) = \\alpha \\, (-m^2 f(t) \\sin(m\\,x + \\phi))\n$$\n$$\nf'(t) = -\\alpha m^2 f(t)\n$$\nThis is a first-order ordinary differential equation for $f(t)$, whose solution is $f(t) = C e^{-\\alpha m^2 t}$ for some constant $C$. To find $C$, we apply the initial condition at $t=0$:\n$$\nu(x,0) = f(0) \\sin(m\\,x + \\phi) = C e^0 \\sin(m\\,x + \\phi) = C \\sin(m\\,x + \\phi).\n$$\nComparing this to the given initial condition, $u(x,0) = A \\sin(m\\,x + \\phi)$, we find that $C=A$.\n\nThus, the exact analytical solution is:\n$$\nu_{\\mathrm{exact}}(x,t) = A\\,e^{-\\alpha m^2 t} \\sin(m\\,x + \\phi).\n$$\nThis solution satisfies the periodic boundary conditions on $[0, 2\\pi)$ because the parameter $m$ is given as an integer for all test cases, ensuring $\\sin(m(x+2\\pi)+\\phi) = \\sin(mx+2\\pi m+\\phi) = \\sin(mx+\\phi)$.\n\nThe problem requires computation on a discrete grid of $N_x$ points:\n$$\nx_i = \\frac{i L}{N_x} = \\frac{i \\cdot 2\\pi}{N_x}, \\quad i = 0, 1, \\dots, N_x-1.\n$$\nThe discrete $L^2$-norm of a function $v$ evaluated on this grid, $v_i = v(x_i)$, is defined as:\n$$\n\\|v\\|_2 = \\sqrt{\\sum_{i=0}^{N_x-1} v_i^2}.\n$$\nThe relative error $E$ is defined as the ratio of the norm of the prediction error to the norm of the initial condition:\n$$\nE = \\frac{\\|u_{\\mathrm{pred}} - u_{\\mathrm{exact}}\\|_2}{\\|u(\\cdot,0)\\|_2}.\n$$\nFor all test cases, the domain length is $L=2\\pi$ and the grid size is $N_x = 64$. We will now evaluate the error $E$ for each of the four specified test cases.\n\n**Test Case A:**\nParameters: $\\alpha = 0.3$, $A = 1.0$, $m = 3$, $\\phi = \\pi/6$, $t = 0.5$.\nThe predicted field $u_{\\mathrm{pred}}$ is given to be equal to the exact solution $u_{\\mathrm{exact}}(x, t)$ for these parameters.\nThe numerator is $\\|u_{\\mathrm{exact}} - u_{\\mathrm{exact}}\\|_2 = \\|0\\|_2 = 0$.\nTherefore, the relative error is $E_A = 0$.\n\n**Test Case B:**\nParameters: $\\alpha = 0.3$, $A = 1.0$, $m = 3$, $\\phi = \\pi/6$, $t = 0.5$.\nThe exact solution is $u_{\\mathrm{exact}}(x,t) = A e^{-\\alpha m^2 t} \\sin(mx+\\phi)$.\nThe predicted field is $u_{\\mathrm{pred}}(x) = u_{\\mathrm{exact}}(x,t) + \\varepsilon A \\sin(rx)$, with $\\varepsilon = 0.01$ and $r = 7$.\nThe difference is $u_{\\mathrm{pred}} - u_{\\mathrm{exact}} = \\varepsilon A \\sin(rx)$.\nThe initial condition is $u(x,0) = A \\sin(mx+\\phi)$.\nThe relative error is:\n$$\nE_B = \\frac{\\|\\varepsilon A \\sin(rx)\\|_2}{\\|A \\sin(mx+\\phi)\\|_2} = \\varepsilon \\frac{\\|\\sin(rx)\\|_2}{\\|\\sin(mx+\\phi)\\|_2}.\n$$\nFor a uniform grid over a full period, the discrete $L^2$-norm of a sinusoid is independent of its phase and its integer wavenumber $k$ (provided $2k$ is not a multiple of $N_x$). For $r=7$ and $m=3$ with $N_x=64$, this holds. Thus, $\\|\\sin(rx)\\|_2 = \\|\\sin(mx+\\phi)\\|_2$.\nThe error simplifies to $E_B = \\varepsilon = 0.01$.\n\n**Test Case C:**\nParameters: $\\alpha = 0.3$, $A = 1.0$, $m = 3$, $\\phi = \\pi/6$, $t = 0.5$.\nThe exact solution is $u_{\\mathrm{exact}}(x,t) = A e^{-\\alpha m^2 t} \\sin(mx+\\phi)$.\nThe predicted field is $u_{\\mathrm{pred}}(x) = A e^{-(1+\\delta)\\alpha m^2 t} \\sin(mx+\\phi)$, with $\\delta = 0.2$.\nThe difference is $u_{\\mathrm{pred}} - u_{\\mathrm{exact}} = A \\left( e^{-(1+\\delta)\\alpha m^2 t} - e^{-\\alpha m^2 t} \\right) \\sin(mx+\\phi)$.\nThe initial condition is $u(x,0) = A \\sin(mx+\\phi)$.\nThe relative error is:\n$$\nE_C = \\frac{\\|A \\left( e^{-(1+\\delta)\\alpha m^2 t} - e^{-\\alpha m^2 t} \\right) \\sin(mx+\\phi)\\|_2}{\\|A \\sin(mx+\\phi)\\|_2}\n$$\n$$\nE_C = \\frac{|A \\left( e^{-(1+\\delta)\\alpha m^2 t} - e^{-\\alpha m^2 t} \\right)| \\cdot \\|\\sin(mx+\\phi)\\|_2}{|A| \\cdot \\|\\sin(mx+\\phi)\\|_2}\n$$\nThe norm terms cancel, yielding:\n$$\nE_C = |e^{-(1+\\delta)\\alpha m^2 t} - e^{-\\alpha m^2 t}| = e^{-\\alpha m^2 t} |e^{-\\delta\\alpha m^2 t} - 1|.\n$$\nSubstituting the values $\\alpha=0.3$, $m=3$, $t=0.5$, $\\delta=0.2$:\n$\\alpha m^2 t = 0.3 \\cdot 9 \\cdot 0.5 = 1.35$.\n$\\delta\\alpha m^2 t = 0.2 \\cdot 1.35 = 0.27$.\n$E_C = e^{-1.35} (1 - e^{-0.27})$.\n\n**Test Case D:**\nParameters: $\\alpha = 0.3$, $A = 1.0$, $m = 5$, $\\phi = \\pi/4$, $t = 0$.\nAt $t=0$, the exact solution is the initial condition itself: $u_{\\mathrm{exact}}(x,0) = u(x,0) = A \\sin(mx+\\phi)$.\nThe predicted field is $u_{\\mathrm{pred}}(x) = A \\sin(mx + \\phi + \\Delta\\phi)$, with $\\Delta\\phi = \\pi/12$.\nThe difference is $u_{\\mathrm{pred}} - u_{\\mathrm{exact}} = A (\\sin(mx+\\phi+\\Delta\\phi) - \\sin(mx+\\phi))$.\nThe relative error is:\n$$\nE_D = \\frac{\\|A (\\sin(mx+\\phi+\\Delta\\phi) - \\sin(mx+\\phi))\\|_2}{\\|A \\sin(mx+\\phi)\\|_2} = \\frac{\\|\\sin(mx+\\phi+\\Delta\\phi) - \\sin(mx+\\phi)\\|_2}{\\|\\sin(mx+\\phi)\\|_2}.\n$$\nUsing the trigonometric identity $\\sin(B) - \\sin(A) = 2 \\cos\\left(\\frac{A+B}{2}\\right) \\sin\\left(\\frac{B-A}{2}\\right)$, the numerator term becomes:\n$2 \\cos\\left(mx+\\phi+\\frac{\\Delta\\phi}{2}\\right) \\sin\\left(\\frac{\\Delta\\phi}{2}\\right)$.\nThe norm of the error is $|2 \\sin(\\frac{\\Delta\\phi}{2})| \\cdot \\|\\cos(mx+\\phi+\\frac{\\Delta\\phi}{2})\\|_2$.\nAs in case B, the norms of sine and cosine functions with the same wavenumber are equal on this grid.\n$$\nE_D = \\frac{|2 \\sin(\\frac{\\Delta\\phi}{2})| \\cdot \\|\\cos(mx+\\phi+\\frac{\\Delta\\phi}{2})\\|_2}{\\|\\sin(mx+\\phi)\\|_2} = |2 \\sin(\\frac{\\Delta\\phi}{2})|.\n$$\nWith $\\Delta\\phi = \\pi/12$, the error is $E_D = 2 \\sin(\\pi/24)$.\n\nThe program below will implement the direct numerical calculation of the error $E$ for each case based on its definition, which will confirm these analytical results.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the relative discrete L2-error for four test cases of the\n    1D heat equation against various predicted fields.\n    \"\"\"\n\n    # Domain and grid parameters common to all test cases\n    L = 2.0 * np.pi\n    Nx = 64\n\n    # Grid points\n    x = np.linspace(0, L, Nx, endpoint=False)\n\n    # Test case definitions\n    test_cases = [\n        {\n            'name': 'A',\n            'alpha': 0.3, 'A': 1.0, 'm': 3, 'phi': np.pi / 6, 't': 0.5,\n            'pred_type': 'exact'\n        },\n        {\n            'name': 'B',\n            'alpha': 0.3, 'A': 1.0, 'm': 3, 'phi': np.pi / 6, 't': 0.5,\n            'pred_type': 'structured_perturbation',\n            'eps': 0.01, 'r': 7\n        },\n        {\n            'name': 'C',\n            'alpha': 0.3, 'A': 1.0, 'm': 3, 'phi': np.pi / 6, 't': 0.5,\n            'pred_type': 'diffusivity_mismatch',\n            'delta': 0.2\n        },\n        {\n            'name': 'D',\n            'alpha': 0.3, 'A': 1.0, 'm': 5, 'phi': np.pi / 4, 't': 0.0,\n            'pred_type': 'phase_error',\n            'dphi': np.pi / 12\n        }\n    ]\n\n    results = []\n\n    def discrete_L2_norm(v):\n        \"\"\"Computes the discrete L2-norm of a vector.\"\"\"\n        return np.sqrt(np.sum(v**2))\n\n    def get_exact_solution(x_grid, t_val, A, alpha, m, phi):\n        \"\"\"Computes the analytical solution on the grid.\"\"\"\n        decay = np.exp(-alpha * m**2 * t_val)\n        spatial = A * np.sin(m * x_grid + phi)\n        return decay * spatial\n\n    for case in test_cases:\n        # Extract parameters for the current test case\n        alpha = case['alpha']\n        A = case['A']\n        m = case['m']\n        phi = case['phi']\n        t = case['t']\n\n        # 1. Calculate the exact solution at time t\n        u_exact = get_exact_solution(x, t, A, alpha, m, phi)\n\n        # 2. Calculate the initial condition at t=0\n        u_initial = get_exact_solution(x, 0, A, alpha, m, phi)\n        \n        # 3. Calculate the predicted field u_pred based on the test case\n        pred_type = case['pred_type']\n        if pred_type == 'exact':\n            u_pred = u_exact\n        elif pred_type == 'structured_perturbation':\n            eps = case['eps']\n            r = case['r']\n            perturbation = eps * A * np.sin(r * x)\n            u_pred = u_exact + perturbation\n        elif pred_type == 'diffusivity_mismatch':\n            delta = case['delta']\n            decay_pred = np.exp(-(1 + delta) * alpha * m**2 * t)\n            u_pred = A * decay_pred * np.sin(m * x + phi)\n        elif pred_type == 'phase_error':\n            dphi = case['dphi']\n            u_pred = A * np.sin(m * x + phi + dphi)\n        else:\n            raise ValueError(f\"Unknown prediction type: {pred_type}\")\n\n        # 4. Compute the relative L2 error\n        # Denominator is the norm of the initial condition\n        norm_initial = discrete_L2_norm(u_initial)\n        \n        # Numerator is the norm of the difference between predicted and exact\n        error_field = u_pred - u_exact\n        norm_error = discrete_L2_norm(error_field)\n        \n        if norm_initial == 0:\n            # Handle trivial case of zero initial condition\n            relative_error = 0.0 if norm_error == 0.0 else np.inf\n        else:\n            relative_error = norm_error / norm_initial\n        \n        # Round to 10 decimal places as required\n        results.append(round(relative_error, 10))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2373647"}, {"introduction": "This advanced exercise tackles the validation of a nonlinear Finite Element Method (FEM) solver for large-deformation solid mechanics. You will simulate the compression of a hyperelastic block and compare the solver's computed reaction force against a reference solution derived from the assumption of homogeneous deformation. This practice illustrates how to create a rigorous benchmark for a sophisticated computational tool by ensuring it correctly solves a fundamental, analytically tractable case [@problem_id:2373682].", "problem": "Design and implement a baseline validation for a non-linear Finite Element Method (FEM) solver for large-deformation compression of a simple elastomeric block. The objective is to verify the accuracy of the solver by comparing the computed reaction force–displacement curve to a reference curve derived from homogeneous deformation of a compressible hyperelastic material. All calculations are non-dimensional; no physical units are used.\n\nYou must base your derivation and algorithm strictly on fundamental principles: the principle of virtual work in quasi-static equilibrium, kinematics of finite deformation, and a hyperelastic constitutive model specified below. Do not use any pre-derived shortcut formulas beyond these foundations.\n\nAssumptions and model:\n- The block occupies an initial rectangular domain with initial length $L_0$ along the loading direction ($x$-axis), and initial width $W_0$ and height $H_0$ in the lateral directions. The initial cross-sectional area is $A_0 = W_0 H_0$.\n- Lateral faces are traction-free, and rigid platens compress the block along the $x$-axis by a prescribed end displacement.\n- The material is homogeneous and hyperelastic with the compressible Neo-Hookean strain-energy density\n$$\n\\psi(\\mathbf{F}) = \\frac{\\mu}{2}\\left(I_1 - 3\\right) - \\mu \\ln J + \\frac{\\kappa}{2} \\left(\\ln J\\right)^2,\n$$\nwhere $\\mathbf{F}$ is the deformation gradient, $I_1 = \\mathrm{tr}\\left(\\mathbf{C}\\right)$ with $\\mathbf{C} = \\mathbf{F}^\\top \\mathbf{F}$, $J = \\det \\mathbf{F}$, $\\mu$ is the shear modulus, and $\\kappa$ is the bulk modulus.\n\nTarget derivation and discretization requirements:\n- Starting from the principle of minimum potential energy and the definition $\\mathbf{P} = \\partial \\psi / \\partial \\mathbf{F}$, derive the nominal stress $\\mathbf{P}$.\n- Impose traction-free lateral faces by enforcing vanishing nominal traction in the lateral directions. For a homogeneous deformation with principal stretches $\\lambda_x$, $\\lambda_y$, $\\lambda_z$, this implies two scalar equations that determine the lateral stretch $\\lambda_t$ (assuming $\\lambda_y = \\lambda_z = \\lambda_t$) as a function of the axial stretch $\\lambda_x$.\n- Implement a one-dimensional Total Lagrangian two-node bar element mesh along the $x$-axis with $n$ linear elements (node count $n+1$). Use the axial nominal stress component $P_{xx}$ and assemble the global internal force vector and the consistent tangent stiffness matrix. The axial element stretch in element $e$ is $\\lambda_x = \\ell_e / L_e$, where $L_e$ is the initial element length and $\\ell_e$ is the current element length.\n- For the consistent algorithmic tangent, it is acceptable in this validation to compute $\\mathrm{d}P_{xx}/\\mathrm{d}\\lambda_x$ by numerical differentiation with a small relative perturbation.\n- Apply quasi-static loading in increments. Impose Dirichlet conditions $u(0) = 0$ and $u(L_0) = -\\Delta$, where $\\Delta$ increases monotonically from $0$ to a specified maximum fraction of $L_0$. Solve each load step by Newton–Raphson iteration on the free degrees of freedom.\n- Compute the reaction force at the loaded end as the support reaction that balances the internal nodal force at the corresponding Dirichlet degree of freedom. Define the positive reaction as compressive (that is, positive when balancing a compressive internal force).\n- Compute a reference reaction for each load level using the homogeneous deformation solution: for the specified axial stretch $\\lambda_x = (L_0-\\Delta)/L_0$, solve the lateral traction-free condition for $\\lambda_t$ and then evaluate the axial nominal stress $P_{xx}$; the reference reaction is $R_\\mathrm{ref} = -A_0 P_{xx}$.\n- For each test case, evaluate the maximum absolute relative error across all load steps,\n$$\n\\varepsilon_\\mathrm{max} = \\max_{\\text{steps}} \\frac{\\left|R_\\mathrm{FEM} - R_\\mathrm{ref}\\right|}{\\max\\left(\\left|R_\\mathrm{ref}\\right|, \\epsilon\\right)},\n$$\nwith a small $\\epsilon = 10^{-12}$ to avoid division by zero at vanishing loads.\n\nBoundary conditions:\n- Left end fixed: $u(0) = 0$.\n- Right end prescribed displacement: $u(L_0) = -\\Delta$, with $\\Delta$ ramped linearly over the specified number of steps.\n\nAngles are not used. All quantities are dimensionless.\n\nTest suite:\nImplement your program to run the following three test cases. For each case, the load is applied linearly over the specified number of steps to the specified final compression. Each test case is specified as a tuple $(\\mu,\\kappa,L_0,W_0,H_0,n,\\text{final\\_compression},\\text{n\\_steps})$:\n- Test case A (general case): $(\\mu,\\kappa,L_0,W_0,H_0,n,\\text{final\\_compression},\\text{n\\_steps}) = (1.2, 120.0, 1.0, 0.5, 0.5, 8, 0.30, 15)$.\n- Test case B (large compression edge case): $(\\mu,\\kappa,L_0,W_0,H_0,n,\\text{final\\_compression},\\text{n\\_steps}) = (0.8, 8.0, 1.0, 0.5, 0.5, 3, 0.60, 20)$.\n- Test case C (nearly incompressible): $(\\mu,\\kappa,L_0,W_0,H_0,n,\\text{final\\_compression},\\text{n\\_steps}) = (1.0, 1000.0, 1.0, 0.5, 0.5, 20, 0.20, 20)$.\n\nRequired final output:\n- Your program must output a single line containing the three results for the test cases in order A, B, C, as a comma-separated list enclosed in square brackets, for example $\\left[r_1,r_2,r_3\\right]$, where each $r_i$ is the maximum absolute relative error $\\varepsilon_\\mathrm{max}$ for that test case, rounded to eight decimal places.", "solution": "We develop a baseline validation for a non-linear large-deformation Finite Element Method (FEM) solver applied to an elastomeric block under uniaxial compression. The goal is to compare the computed reaction force–displacement curve against a reference derived from homogeneous deformation under a compressible Neo-Hookean model. All quantities are non-dimensional.\n\nFoundations:\n- Quasi-static equilibrium derives from the principle of virtual work: for admissible virtual displacements, the internal virtual work equals external virtual work. In the absence of body forces and with displacement control at the loaded boundary, the weak form reduces to the balance of internal forces and boundary reactions.\n- Kinematics of finite deformation: the deformation gradient is $\\mathbf{F} = \\partial \\mathbf{x} / \\partial \\mathbf{X}$, with $J = \\det \\mathbf{F}  0$. The right Cauchy–Green tensor is $\\mathbf{C} = \\mathbf{F}^\\top \\mathbf{F}$, with first invariant $I_1 = \\mathrm{tr}\\,\\mathbf{C}$.\n- Hyperelastic constitutive law: the strain-energy density is\n$$\n\\psi(\\mathbf{F}) = \\frac{\\mu}{2}\\left(I_1 - 3\\right) - \\mu \\ln J + \\frac{\\kappa}{2}\\left(\\ln J\\right)^2,\n$$\nwith shear modulus $\\mu$ and bulk modulus $\\kappa$. The nominal (first Piola–Kirchhoff) stress follows from the energy conjugacy,\n$$\n\\mathbf{P} = \\frac{\\partial \\psi}{\\partial \\mathbf{F}}.\n$$\n\nDerivation of the nominal stress:\nWe compute $\\partial \\psi / \\partial \\mathbf{F}$ by standard manipulations using $\\partial I_1 / \\partial \\mathbf{F} = 2\\mathbf{F}$ and $\\partial J / \\partial \\mathbf{F} = J \\mathbf{F}^{-\\top}$, and $\\partial \\ln J / \\partial \\mathbf{F} = \\mathbf{F}^{-\\top}$. The result is\n$$\n\\mathbf{P} = \\mu\\left(\\mathbf{F} - \\mathbf{F}^{-\\top}\\right) + \\kappa \\left(\\ln J\\right)\\mathbf{F}^{-\\top}.\n$$\nThis expression is widely used and follows from the given energy density.\n\nHomogeneous deformation and lateral traction-free conditions:\nFor a homogeneous uniaxial compression with principal stretches $\\lambda_x$, $\\lambda_y$, $\\lambda_z$, we exploit symmetry and set $\\lambda_y = \\lambda_z = \\lambda_t$ and $\\mathbf{F} = \\mathrm{diag}(\\lambda_x,\\lambda_t,\\lambda_t)$. The determinant is $J = \\lambda_x \\lambda_t^2$, and the nominal stress is diagonal with components\n$$\nP_{ii} = \\mu\\left(\\lambda_i - \\frac{1}{\\lambda_i}\\right) + \\kappa \\frac{\\ln J}{\\lambda_i}.\n$$\nThe traction-free lateral faces imply $P_{yy} = 0$ and $P_{zz} = 0$, which coincide by symmetry. The scalar lateral traction-free condition reads\n$$\ng(\\lambda_t;\\lambda_x) \\equiv \\mu\\left(\\lambda_t - \\frac{1}{\\lambda_t}\\right) + \\kappa \\frac{\\ln\\left(\\lambda_x \\lambda_t^2\\right)}{\\lambda_t} = 0.\n$$\nGiven $\\lambda_x$, one solves this scalar nonlinear equation for $\\lambda_t  0$. A robust initial guess is the incompressible limit $\\lambda_t^{(0)} = \\lambda_x^{-1/2}$. The axial nominal stress then is\n$$\nP_{xx}(\\lambda_x) = \\mu\\left(\\lambda_x - \\frac{1}{\\lambda_x}\\right) + \\kappa \\frac{\\ln\\left(\\lambda_x \\lambda_t^2(\\lambda_x)\\right)}{\\lambda_x}.\n$$\nThe reference reaction for a block with initial cross-section $A_0$ is $R_\\mathrm{ref} = -A_0 P_{xx}(\\lambda_x)$, with the sign convention that compression yields a positive reaction.\n\nOne-dimensional Total Lagrangian FEM discretization:\nWe discretize the bar along $x$ into $n$ linear two-node elements (nodes $i=0,\\dots,n$). The initial nodal positions are $X_i = i\\,L_0/n$, and the only degree of freedom at node $i$ is the axial displacement $u_i$. For element $e$ connecting nodes $a$ and $b$, the initial length is $L_e = L_0/n$, and the axial stretch is\n$$\n\\lambda_x^{(e)} = \\frac{\\ell_e}{L_e} = \\frac{(X_b + u_b) - (X_a + u_a)}{L_e} = 1 + \\frac{u_b - u_a}{L_e}.\n$$\nThe internal force vector for element $e$ in the Total Lagrangian form with constant $P_{xx}$ over the element is\n$$\n\\mathbf{f}_\\mathrm{int}^{(e)} = A_0 P_{xx}\\left(\\lambda_x^{(e)}\\right)\\begin{bmatrix}-1\\\\+1\\end{bmatrix}.\n$$\nThe consistent algorithmic tangent for element $e$ is obtained by differentiating with respect to the nodal displacements using the chain rule:\n$$ \\mathbf{K}^{(e)} = A_0 \\frac{\\mathrm{d}P_{xx}}{\\mathrm{d}\\lambda_x}\\Big|_{\\lambda_x^{(e)}} \\begin{bmatrix}\\frac{1}{L_e}  -\\frac{1}{L_e} \\\\ -\\frac{1}{L_e}  \\frac{1}{L_e}\\end{bmatrix}. $$\nIn this validation, we compute $\\mathrm{d}P_{xx}/\\mathrm{d}\\lambda_x$ numerically by a central finite difference with a small relative perturbation. Global assembly yields the internal force vector $\\mathbf{f}_\\mathrm{int}(\\mathbf{u})$ and tangent stiffness matrix $\\mathbf{K}(\\mathbf{u})$.\n\nBoundary conditions and solution procedure:\nWe impose $u_0 = 0$ and $u_n = -\\Delta$ at each load step, with $\\Delta$ ramped linearly from $0$ to the final compression. The free degrees of freedom are the interior nodes. At each load step, the Newton–Raphson iteration updates the free degrees via\n$$\n\\mathbf{K}_{ff}(\\mathbf{u})\\,\\Delta\\mathbf{u}_f = -\\mathbf{r}_f(\\mathbf{u}), \\quad \\mathbf{r} \\equiv \\mathbf{f}_\\mathrm{int},\n$$\nuntil convergence, where the subscript $f$ indicates the free degrees of freedom. Convergence is checked by either the residual norm or the displacement increment norm; a typical criterion is $\\|\\Delta \\mathbf{u}_f\\|_\\infty  10^{-12} L_0$. The reaction at the loaded end is computed as the support reaction that balances the internal force at the Dirichlet node, namely $R = -f_{\\mathrm{int},n}$, which is positive in compression for negative $P_{xx}$.\n\nReference solution and error metric:\nAt each load level with end-shortening $\\Delta$, the homogeneous axial stretch is $\\lambda_x = (L_0 - \\Delta)/L_0$. Solve $g(\\lambda_t;\\lambda_x) = 0$ for $\\lambda_t$ by a scalar Newton method. Then compute $P_{xx}(\\lambda_x)$ and the reference reaction $R_\\mathrm{ref} = -A_0 P_{xx}(\\lambda_x)$. The test metric is the maximum absolute relative error across steps,\n$$\n\\varepsilon_\\mathrm{max} = \\max_{\\text{steps}} \\frac{\\left|R_\\mathrm{FEM} - R_\\mathrm{ref}\\right|}{\\max\\left(\\left|R_\\mathrm{ref}\\right|, 10^{-12}\\right)}.\n$$\n\nAlgorithmic details for robustness:\n- The scalar Newton solve for $\\lambda_t$ uses the derivative\n$$\n\\frac{\\mathrm{d}g}{\\mathrm{d}\\lambda_t} = \\mu\\left(1 + \\frac{1}{\\lambda_t^2}\\right) + \\kappa \\frac{2 - \\ln\\left(\\lambda_x \\lambda_t^2\\right)}{\\lambda_t^2},\n$$\nwith backtracking if necessary to maintain $\\lambda_t  0$ and decrease $|g|$.\n- The numerical derivative $\\mathrm{d}P_{xx}/\\mathrm{d}\\lambda_x$ uses a central difference with a small relative perturbation of $\\lambda_x$ to ensure scale invariance and stability.\n\nTest suite and expected behavior:\nWe run three cases:\n- Test A: $(\\mu,\\kappa,L_0,W_0,H_0,n,\\text{final\\_compression},\\text{n\\_steps}) = (1.2, 120.0, 1.0, 0.5, 0.5, 8, 0.30, 15)$. This is a well-conditioned case with moderate compressibility.\n- Test B: $(\\mu,\\kappa,L_0,W_0,H_0,n,\\text{final\\_compression},\\text{n\\_steps}) = (0.8, 8.0, 1.0, 0.5, 0.5, 3, 0.60, 20)$. This probes large compressions with higher nonlinearity.\n- Test C: $(\\mu,\\kappa,L_0,W_0,H_0,n,\\text{final\\_compression},\\text{n\\_steps}) = (1.0, 1000.0, 1.0, 0.5, 0.5, 20, 0.20, 20)$. This probes near-incompressibility stiffness.\n\nBecause the bar discretization with the given constitutive update enforces the same axial stretch in each element at equilibrium under displacement control, the FEM reaction should match the homogeneous reference to within numerical tolerances. Therefore, the maximum relative errors $\\varepsilon_\\mathrm{max}$ should be small, typically near machine precision for Test A and Test C, and slightly larger but still very small for Test B due to stronger nonlinearity. The program reports these three errors rounded to eight decimal places as a single-line list $\\left[r_A,r_B,r_C\\right]$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve_lateral_stretch(lambda_x, mu, kappa, tol=1e-12, max_iter=100):\n    \"\"\"\n    Solve for lateral stretch lambda_t given axial stretch lambda_x\n    under traction-free lateral faces for compressible Neo-Hookean.\n    g(lambda_t) = mu*(lambda_t - 1/lambda_t) + kappa * ln(J)/lambda_t = 0\n    with J = lambda_x * lambda_t^2.\n    \"\"\"\n    # Robust initial guess: incompressible estimate\n    lam_t = max(lambda_x ** (-0.5), 1e-12)\n    for _ in range(max_iter):\n        J = lambda_x * lam_t * lam_t\n        if J = 0 or not np.isfinite(J):\n            # Recover with small positive perturbation\n            lam_t = max(lam_t, 1e-8)\n            J = lambda_x * lam_t * lam_t\n        g = mu * (lam_t - 1.0 / lam_t) + kappa * (np.log(J)) / lam_t\n        if abs(g)  tol:\n            return lam_t\n        # Derivative of g with respect to lambda_t\n        dg = mu * (1.0 + 1.0 / (lam_t * lam_t)) + kappa * (2.0 - np.log(J)) / (lam_t * lam_t)\n        # Newton step with backtracking if needed\n        delta = -g / dg\n        lam_new = lam_t + delta\n        if lam_new = 0 or not np.isfinite(lam_new):\n            # Backtracking line search on lambda_t to keep positivity and reduce |g|\n            alpha = 1.0\n            success = False\n            while alpha > 1e-8:\n                cand = lam_t + alpha * delta\n                if cand > 0 and np.isfinite(cand):\n                    Jc = lambda_x * cand * cand\n                    if Jc > 0 and np.isfinite(Jc):\n                        gc = mu * (cand - 1.0 / cand) + kappa * (np.log(Jc)) / cand\n                        if abs(gc)  abs(g):\n                            lam_new = cand\n                            success = True\n                            break\n                alpha *= 0.5\n            if not success:\n                # Fallback small positive update\n                lam_new = max(lam_t * 0.5, 1e-10)\n        lam_t = lam_new\n    # If not converged, return current estimate (still positive)\n    return max(lam_t, 1e-10)\n\ndef Pxx_given_lambda(lambda_x, mu, kappa):\n    \"\"\"\n    Compute axial nominal stress P_xx for compressible Neo-Hookean\n    under uniaxial stretch lambda_x with traction-free lateral faces.\n    \"\"\"\n    lam_t = solve_lateral_stretch(lambda_x, mu, kappa)\n    J = lambda_x * lam_t * lam_t\n    # P_xx = mu*(lambda_x - 1/lambda_x) + kappa * ln(J) / lambda_x\n    return mu * (lambda_x - 1.0 / lambda_x) + kappa * (np.log(J)) / lambda_x\n\ndef dPxx_dlambda_numeric(lambda_x, mu, kappa, rel_eps=1e-7):\n    \"\"\"\n    Numerical derivative dPxx/dlambda_x via central relative finite difference.\n    \"\"\"\n    h = rel_eps\n    lp = lambda_x * (1.0 + h)\n    lm = lambda_x * (1.0 - h)\n    # Ensure positivity\n    if lm = 0:\n        lm = lambda_x * (1.0 - 0.5 * h)\n        lp = lambda_x * (1.0 + 0.5 * h)\n        h = 0.5 * h\n    Pp = Pxx_given_lambda(lp, mu, kappa)\n    Pm = Pxx_given_lambda(lm, mu, kappa)\n    return (Pp - Pm) / (2.0 * h * lambda_x)\n\ndef assemble_internal_and_tangent(u, L0, A0, n_el, mu, kappa):\n    \"\"\"\n    Assemble global internal force vector and tangent stiffness matrix\n    for a 1D bar with n_el elements and n_el+1 nodes.\n    \"\"\"\n    n_nodes = n_el + 1\n    f_int = np.zeros(n_nodes)\n    K = np.zeros((n_nodes, n_nodes))\n    L_e0 = L0 / n_el\n\n    # Nodal positions in reference\n    # X_i = i * L_e0\n    for e in range(n_el):\n        a = e\n        b = e + 1\n        ua = u[a]\n        ub = u[b]\n        # Axial stretch in element e: lambda_x = 1 + (ub - ua)/L_e0\n        lambda_x = 1.0 + (ub - ua) / L_e0\n        # Compute stress and tangent\n        P = Pxx_given_lambda(lambda_x, mu, kappa)\n        dP = dPxx_dlambda_numeric(lambda_x, mu, kappa)\n\n        # Element internal force: A0 * P * [-1, +1]\n        fe = A0 * P * np.array([-1.0, +1.0])\n        f_int[a] += fe[0]\n        f_int[b] += fe[1]\n\n        # Element tangent: A0 * dP/dlambda * [[1/L_e0, -1/L_e0], [-1/L_e0, 1/L_e0]]\n        coef = A0 * dP / L_e0\n        Ke = coef * np.array([[1.0, -1.0], [-1.0, 1.0]])\n        K[a, a] += Ke[0, 0]\n        K[a, b] += Ke[0, 1]\n        K[b, a] += Ke[1, 0]\n        K[b, b] += Ke[1, 1]\n\n    return f_int, K\n\ndef solve_bar(mu, kappa, L0, W0, H0, n_el, final_compression, n_steps):\n    \"\"\"\n    Solve displacement-controlled compression and return the maximum absolute relative\n    error between FEM reaction and the homogeneous-reference reaction over all steps.\n    \"\"\"\n    A0 = W0 * H0\n    n_nodes = n_el + 1\n    # Initialize displacements\n    u = np.zeros(n_nodes)\n    left = 0\n    right = n_nodes - 1\n    free = np.arange(1, n_nodes - 1, dtype=int)\n    # Track maximum relative error\n    max_rel_err = 0.0\n    # Load path\n    for step in range(1, n_steps + 1):\n        frac = step / n_steps\n        Delta = final_compression * L0 * frac\n        # Apply boundary conditions\n        u[left] = 0.0\n        u[right] = -Delta\n        # Newton-Raphson on free DOFs\n        for it in range(60):\n            f_int, K = assemble_internal_and_tangent(u, L0, A0, n_el, mu, kappa)\n            # Residual on free DOFs: internal forces must vanish on free DOFs\n            r = f_int[free]\n            # Convergence check on displacement increment norm later\n            if free.size > 0:\n                Kff = K[np.ix_(free, free)]\n                # Solve for update\n                try:\n                    du = -np.linalg.solve(Kff, r)\n                except np.linalg.LinAlgError:\n                    # Regularize slightly if singular (should not occur with proper setup)\n                    Kff_reg = Kff + 1e-12 * np.eye(Kff.shape[0])\n                    du = -np.linalg.solve(Kff_reg, r)\n                u[free] += du\n                if np.linalg.norm(du, ord=np.inf)  1e-12 * L0:\n                    break\n            else:\n                # No free DOFs; skip\n                break\n        # Post-converged internal forces for reaction\n        f_int, _ = assemble_internal_and_tangent(u, L0, A0, n_el, mu, kappa)\n        R_fem = -f_int[right]  # reaction at right end, positive in compression\n        # Reference reaction from homogeneous solution\n        lambda_x = (L0 - Delta) / L0\n        P_ref = Pxx_given_lambda(lambda_x, mu, kappa)\n        R_ref = -A0 * P_ref\n        denom = max(abs(R_ref), 1e-12)\n        rel_err = abs(R_fem - R_ref) / denom\n        if rel_err > max_rel_err:\n            max_rel_err = rel_err\n    return max_rel_err\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each tuple: (mu, kappa, L0, W0, H0, n_el, final_compression, n_steps)\n    test_cases = [\n        (1.2, 120.0, 1.0, 0.5, 0.5, 8, 0.30, 15),   # Test A: general case\n        (0.8, 8.0, 1.0, 0.5, 0.5, 3, 0.60, 20),     # Test B: large compression\n        (1.0, 1000.0, 1.0, 0.5, 0.5, 20, 0.20, 20), # Test C: nearly incompressible\n    ]\n\n    results = []\n    for case in test_cases:\n        mu, kappa, L0, W0, H0, n_el, final_comp, n_steps = case\n        err = solve_bar(mu, kappa, L0, W0, H0, n_el, final_comp, n_steps)\n        results.append(round(float(err), 8))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2373682"}]}