{"hands_on_practices": [{"introduction": "To truly grasp sensitivity analysis, we must start with the fundamentals. This first practice invites you to analytically derive the Sobol' indices for a simple, additive model. By working through the calculus of expectations and variances, you will build a foundational understanding of how an input's contribution to output variance is quantified.", "problem": "Consider the model output defined by the function $f(x_1, x_2) = \\sin(x_1) + \\cos(x_2)$, where the input parameters $x_1$ and $x_2$ are independent random variables, each uniformly distributed on the interval $[0, 2\\pi]$ (angles measured in radians). Using the variance-based definitions of Sobol' sensitivity indices, determine the first-order indices $S_1$ and $S_2$, the second-order interaction index $S_{12}$, and the total-effect indices $S_{T1}$ and $S_{T2}$. Provide exact values.\n\nReport your final answer as a single row matrix in the order $(S_1, S_2, S_{12}, S_{T1}, S_{T2})$. No rounding is required, and no units are to be included in the final answer.", "solution": "The problem is valid. It is a well-posed, scientifically grounded problem in the field of sensitivity analysis. All necessary information is provided, and the objective is clearly stated. We proceed to the solution.\n\nThe problem requires the calculation of Sobol' sensitivity indices for the model output $Y = f(x_1, x_2) = \\sin(x_1) + \\cos(x_2)$, where the inputs $x_1$ and $x_2$ are independent random variables uniformly distributed on the interval $[0, 2\\pi]$. The probability density function (PDF) for both $x_1$ and $x_2$ is $p(x) = \\frac{1}{2\\pi}$ for $x \\in [0, 2\\pi]$.\n\nThe Sobol' first-order sensitivity index $S_i$ for an input $x_i$ is defined as the fraction of the total variance $\\operatorname{Var}(Y)$ contributed by the main effect of $x_i$:\n$$S_i = \\frac{\\operatorname{Var}(\\mathbb{E}[Y | x_i])}{\\operatorname{Var}(Y)}$$\nThe total-effect index $S_{Ti}$ is the sum of all effects involving $x_i$ (main effect and all interactions). It can be calculated as:\n$$S_{Ti} = \\frac{\\mathbb{E}[\\operatorname{Var}(Y | X_{\\sim i})]}{\\operatorname{Var}(Y)} = 1 - \\frac{\\operatorname{Var}(\\mathbb{E}[Y | X_{\\sim i}])}{\\operatorname{Var}(Y)}$$\nwhere $X_{\\sim i}$ denotes the set of all input variables except $x_i$. The interaction index $S_{ij}$ measures the variance from the interaction between $x_i$ and $x_j$ that is not accounted for in their first-order effects.\n\nFirst, we calculate the total variance of the output, $\\operatorname{Var}(Y)$.\n$$\\operatorname{Var}(Y) = \\operatorname{Var}[\\sin(x_1) + \\cos(x_2)]$$\nSince $x_1$ and $x_2$ are independent, the variance of the sum is the sum of the variances:\n$$\\operatorname{Var}(Y) = \\operatorname{Var}[\\sin(x_1)] + \\operatorname{Var}[\\cos(x_2)]$$\nTo compute these variances, we need the expectations $\\mathbb{E}[\\sin(x_1)]$, $\\mathbb{E}[\\sin^2(x_1)]$, $\\mathbb{E}[\\cos(x_2)]$, and $\\mathbb{E}[\\cos^2(x_2)]$.\n\nThe expectation of $\\sin(x_1)$ is:\n$$\\mathbb{E}[\\sin(x_1)] = \\int_0^{2\\pi} \\sin(x_1) p(x_1) dx_1 = \\frac{1}{2\\pi} \\int_0^{2\\pi} \\sin(x_1) dx_1 = \\frac{1}{2\\pi} [-\\cos(x_1)]_0^{2\\pi} = \\frac{1}{2\\pi} (-\\cos(2\\pi) + \\cos(0)) = \\frac{1}{2\\pi}(-1 + 1) = 0$$\nThe expectation of $\\sin^2(x_1)$ is:\n$$\\mathbb{E}[\\sin^2(x_1)] = \\frac{1}{2\\pi} \\int_0^{2\\pi} \\sin^2(x_1) dx_1 = \\frac{1}{2\\pi} \\int_0^{2\\pi} \\frac{1 - \\cos(2x_1)}{2} dx_1 = \\frac{1}{4\\pi} \\left[x_1 - \\frac{\\sin(2x_1)}{2}\\right]_0^{2\\pi} = \\frac{1}{4\\pi} (2\\pi) = \\frac{1}{2}$$\nThe variance of $\\sin(x_1)$ is therefore:\n$$\\operatorname{Var}[\\sin(x_1)] = \\mathbb{E}[\\sin^2(x_1)] - (\\mathbb{E}[\\sin(x_1)])^2 = \\frac{1}{2} - 0^2 = \\frac{1}{2}$$\nBy symmetry, for $\\cos(x_2)$:\n$$\\mathbb{E}[\\cos(x_2)] = \\frac{1}{2\\pi} \\int_0^{2\\pi} \\cos(x_2) dx_2 = \\frac{1}{2\\pi} [\\sin(x_2)]_0^{2\\pi} = 0$$\n$$\\mathbb{E}[\\cos^2(x_2)] = \\frac{1}{2\\pi} \\int_0^{2\\pi} \\cos^2(x_2) dx_2 = \\frac{1}{2\\pi} \\int_0^{2\\pi} \\frac{1 + \\cos(2x_2)}{2} dx_2 = \\frac{1}{4\\pi} \\left[x_2 + \\frac{\\sin(2x_2)}{2}\\right]_0^{2\\pi} = \\frac{1}{4\\pi}(2\\pi) = \\frac{1}{2}$$\nThe variance of $\\cos(x_2)$ is:\n$$\\operatorname{Var}[\\cos(x_2)] = \\mathbb{E}[\\cos^2(x_2)] - (\\mathbb{E}[\\cos(x_2)])^2 = \\frac{1}{2} - 0^2 = \\frac{1}{2}$$\nThe total variance of the output is:\n$$\\operatorname{Var}(Y) = \\operatorname{Var}[\\sin(x_1)] + \\operatorname{Var}[\\cos(x_2)] = \\frac{1}{2} + \\frac{1}{2} = 1$$\n\nNow, we compute the first-order indices, $S_1$ and $S_2$.\nFor $S_1$, we need $\\operatorname{Var}(\\mathbb{E}[Y | x_1])$. The conditional expectation is:\n$$\\mathbb{E}[Y | x_1] = \\mathbb{E}[\\sin(x_1) + \\cos(x_2) | x_1] = \\sin(x_1) + \\mathbb{E}[\\cos(x_2)] = \\sin(x_1) + 0 = \\sin(x_1)$$\nThe variance of this conditional expectation is:\n$$\\operatorname{Var}(\\mathbb{E}[Y | x_1]) = \\operatorname{Var}[\\sin(x_1)] = \\frac{1}{2}$$\nSo, the first-order index for $x_1$ is:\n$$S_1 = \\frac{\\operatorname{Var}(\\mathbb{E}[Y | x_1])}{\\operatorname{Var}(Y)} = \\frac{1/2}{1} = \\frac{1}{2}$$\nFor $S_2$, by symmetry:\n$$\\mathbb{E}[Y | x_2] = \\mathbb{E}[\\sin(x_1) + \\cos(x_2) | x_2] = \\mathbb{E}[\\sin(x_1)] + \\cos(x_2) = 0 + \\cos(x_2) = \\cos(x_2)$$\n$$\\operatorname{Var}(\\mathbb{E}[Y | x_2]) = \\operatorname{Var}[\\cos(x_2)] = \\frac{1}{2}$$\nThe first-order index for $x_2$ is:\n$$S_2 = \\frac{\\operatorname{Var}(\\mathbb{E}[Y | x_2])}{\\operatorname{Var}(Y)} = \\frac{1/2}{1} = \\frac{1}{2}$$\n\nNext, we determine the second-order interaction index $S_{12}$. The model function $f(x_1, x_2) = \\sin(x_1) + \\cos(x_2)$ is purely additive, meaning it is a sum of functions of single variables. For such models, there are no interaction effects between the variables. This can be seen from the Sobol' decomposition $f = f_0 + f_1 + f_2 + f_{12}$, where $f_0 = \\mathbb{E}[Y]=0$, $f_1(x_1) = \\mathbb{E}[Y|x_1]-f_0 = \\sin(x_1)$, and $f_2(x_2) = \\mathbb{E}[Y|x_2]-f_0 = \\cos(x_2)$. The interaction term $f_{12}$ is defined as $f_{12} = f - f_0 - f_1 - f_2 = (\\sin(x_1) + \\cos(x_2)) - 0 - \\sin(x_1) - \\cos(x_2) = 0$.\nThe variance of the interaction term, $\\operatorname{Var}(f_{12})$, is therefore $0$.\n$$S_{12} = \\frac{\\operatorname{Var}(f_{12})}{\\operatorname{Var}(Y)} = \\frac{0}{1} = 0$$\nWe can verify this from the variance decomposition: $\\operatorname{Var}(Y) = \\operatorname{Var}(f_1) + \\operatorname{Var}(f_2) + \\operatorname{Var}(f_{12})$. Dividing by $\\operatorname{Var}(Y)$ gives $1 = S_1 + S_2 + S_{12}$. Since $S_1 = \\frac{1}{2}$ and $S_2 = \\frac{1}{2}$, we confirm $1 = \\frac{1}{2} + \\frac{1}{2} + S_{12}$, which implies $S_{12} = 0$.\n\nFinally, we compute the total-effect indices, $S_{T1}$ and $S_{T2}$. The total-effect index $S_{Ti}$ is the sum of the main effect of $x_i$ and all interaction effects involving $x_i$.\nFor $x_1$:\n$$S_{T1} = S_1 + S_{12} = \\frac{1}{2} + 0 = \\frac{1}{2}$$\nFor $x_2$:\n$$S_{T2} = S_2 + S_{12} = \\frac{1}{2} + 0 = \\frac{1}{2}$$\nThis is a general property of additive models: the total-effect index for an input is equal to its first-order index, i.e., $S_{Ti} = S_i$, because there are no interactions.\n\nThe calculated Sobol' indices are:\n$S_1 = \\frac{1}{2}$\n$S_2 = \\frac{1}{2}$\n$S_{12} = 0$\n$S_{T1} = \\frac{1}{2}$\n$S_{T2} = \\frac{1}{2}$\n\nThe final answer is to be reported as a single row matrix in the order $(S_1, S_2, S_{12}, S_{T1}, S_{T2})$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{2}  \\frac{1}{2}  0  \\frac{1}{2}  \\frac{1}{2}\n\\end{pmatrix}\n}\n$$", "id": "2434889"}, {"introduction": "An input's influence is not always obvious from its individual effect alone. This exercise presents a classic case where an input has a first-order index of zero, suggesting it has no importance, yet it is critically involved in the model's behavior through interactions [@problem_id:2434812]. Solving this problem reveals why total-effect indices are indispensable for uncovering the complete picture of an input's influence.", "problem": "Consider a deterministic model with two independent real-valued inputs $X_1$ and $X_2$, each distributed as $\\mathrm{Uniform}(0,1)$. The scalar output is defined by\n$$\nY \\;=\\; \\bigl(X_1 - \\tfrac{1}{2}\\bigr)\\,\\bigl(X_2 - \\tfrac{1}{2}\\bigr).\n$$\nFor an input $X_i$, the first-order Sobol' index is defined as\n$$\nS_i \\;=\\; \\frac{\\mathrm{Var}\\!\\bigl(\\mathbb{E}[Y \\mid X_i]\\bigr)}{\\mathrm{Var}(Y)},\n$$\nand the total-order Sobol' index is defined as\n$$\nS_{Ti} \\;=\\; \\frac{\\mathbb{E}\\!\\bigl[\\mathrm{Var}(Y \\mid X_{\\sim i})\\bigr]}{\\mathrm{Var}(Y)},\n$$\nwhere $\\mathbb{E}[\\cdot]$ denotes expectation, $\\mathrm{Var}(\\cdot)$ denotes variance, and $X_{\\sim i}$ denotes the collection of all inputs except $X_i$.\n\nUsing only these definitions and the given distributions, determine the exact value of the total-order Sobol' index $S_{T1}$ for input $X_1$, and verify that the first-order index $S_1$ is equal to $0$. Provide the exact value (no rounding) of $S_{T1}$ as your final answer. The Sobol' indices are dimensionless; no units should be reported.", "solution": "The problem statement is subjected to validation.\n**Givens:**\n1.  Model: $Y = (X_1 - \\tfrac{1}{2})(X_2 - \\tfrac{1}{2})$.\n2.  Inputs: $X_1, X_2$ are independent real-valued inputs.\n3.  Distribution: $X_1 \\sim \\mathrm{Uniform}(0,1)$ and $X_2 \\sim \\mathrm{Uniform}(0,1)$.\n4.  First-order Sobol' index: $S_i = \\frac{\\mathrm{Var}(\\mathbb{E}[Y \\mid X_i])}{\\mathrm{Var}(Y)}$.\n5.  Total-order Sobol' index: $S_{Ti} = \\frac{\\mathbb{E}[\\mathrm{Var}(Y \\mid X_{\\sim i})]}{\\mathrm{Var}(Y)}$.\n6.  $X_{\\sim i}$ denotes all inputs except $X_i$.\n\n**Validation:**\nThe problem is scientifically grounded, being a standard exercise in Sobol' sensitivity analysis. It is well-posed, with all necessary mathematical objects and distributions clearly and unambiguously defined. The problem is objective and contains no factual unsoundness, incompleteness, or contradictions. The premises are mathematically and statistically sound. Therefore, the problem is deemed valid and a solution will be provided.\n\nThe solution proceeds by first computing the total variance of the output, $\\mathrm{Var}(Y)$, which serves as the denominator for both indices. Subsequently, we will compute the numerators for $S_1$ and $S_{T1}$ and verify the stated conditions.\n\nFirst, we establish the properties of the input random variables. For an input $X_i \\sim \\mathrm{Uniform}(0,1)$, the expectation is:\n$$\n\\mathbb{E}[X_i] = \\int_0^1 x \\, dx = \\frac{1}{2}\n$$\nThe variance is given by $\\mathrm{Var}(X_i) = \\mathbb{E}[X_i^2] - (\\mathbb{E}[X_i])^2$. We compute the second moment:\n$$\n\\mathbb{E}[X_i^2] = \\int_0^1 x^2 \\, dx = \\frac{1}{3}\n$$\nThus, the variance is:\n$$\n\\mathrm{Var}(X_i) = \\frac{1}{3} - \\left(\\frac{1}{2}\\right)^2 = \\frac{1}{3} - \\frac{1}{4} = \\frac{1}{12}\n$$\nIt is convenient to work with centered variables. Let $Z_i = X_i - \\frac{1}{2}$. The properties of $Z_i$ are:\n$$\n\\mathbb{E}[Z_i] = \\mathbb{E}\\left[X_i - \\frac{1}{2}\\right] = \\mathbb{E}[X_i] - \\frac{1}{2} = \\frac{1}{2} - \\frac{1}{2} = 0\n$$\n$$\n\\mathrm{Var}(Z_i) = \\mathrm{Var}\\left(X_i - \\frac{1}{2}\\right) = \\mathrm{Var}(X_i) = \\frac{1}{12}\n$$\nThe model can now be written as $Y = Z_1 Z_2$.\n\nNow, we compute the total variance $\\mathrm{Var}(Y)$.\nThe expectation of $Y$ is:\n$$\n\\mathbb{E}[Y] = \\mathbb{E}[Z_1 Z_2]\n$$\nSince $X_1$ and $X_2$ are independent, $Z_1$ and $Z_2$ are also independent. Therefore:\n$$\n\\mathbb{E}[Y] = \\mathbb{E}[Z_1]\\mathbb{E}[Z_2] = (0)(0) = 0\n$$\nThe variance of $Y$ is $\\mathrm{Var}(Y) = \\mathbb{E}[Y^2] - (\\mathbb{E}[Y])^2$. We compute $\\mathbb{E}[Y^2]$:\n$$\n\\mathbb{E}[Y^2] = \\mathbb{E}[(Z_1 Z_2)^2] = \\mathbb{E}[Z_1^2 Z_2^2]\n$$\nDue to independence, $\\mathbb{E}[Z_1^2 Z_2^2] = \\mathbb{E}[Z_1^2]\\mathbb{E}[Z_2^2]$.\nFrom the definition of variance, $\\mathrm{Var}(Z_i) = \\mathbb{E}[Z_i^2] - (\\mathbb{E}[Z_i])^2$. Since $\\mathbb{E}[Z_i] = 0$, we have $\\mathbb{E}[Z_i^2] = \\mathrm{Var}(Z_i) = \\frac{1}{12}$.\nSo,\n$$\n\\mathbb{E}[Y^2] = \\left(\\frac{1}{12}\\right)\\left(\\frac{1}{12}\\right) = \\frac{1}{144}\n$$\nThe total variance of the output is:\n$$\n\\mathrm{Var}(Y) = \\frac{1}{144} - (0)^2 = \\frac{1}{144}\n$$\nNext, we verify that the first-order index $S_1$ is $0$. The numerator is $\\mathrm{Var}(\\mathbb{E}[Y \\mid X_1])$. We compute the conditional expectation:\n$$\n\\mathbb{E}[Y \\mid X_1] = \\mathbb{E}\\left[\\left(X_1 - \\frac{1}{2}\\right)\\left(X_2 - \\frac{1}{2}\\right) \\mid X_1\\right]\n$$\nGiven $X_1$, the term $(X_1 - \\frac{1}{2})$ is a constant.\n$$\n\\mathbb{E}[Y \\mid X_1] = \\left(X_1 - \\frac{1}{2}\\right) \\mathbb{E}\\left[\\left(X_2 - \\frac{1}{2}\\right) \\mid X_1\\right]\n$$\nDue to the independence of $X_1$ and $X_2$, the conditioning on $X_1$ has no effect on the expectation of a function of $X_2$.\n$$\n\\mathbb{E}\\left[\\left(X_2 - \\frac{1}{2}\\right) \\mid X_1\\right] = \\mathbb{E}\\left[X_2 - \\frac{1}{2}\\right] = \\mathbb{E}[X_2] - \\frac{1}{2} = 0\n$$\nThus, the conditional expectation is:\n$$\n\\mathbb{E}[Y \\mid X_1] = \\left(X_1 - \\frac{1}{2}\\right) \\cdot 0 = 0\n$$\nThe variance of a constant is zero, so $\\mathrm{Var}(\\mathbb{E}[Y \\mid X_1]) = \\mathrm{Var}(0) = 0$.\nThe first-order index for $X_1$ is:\n$$\nS_1 = \\frac{\\mathrm{Var}(\\mathbb{E}[Y \\mid X_1])}{\\mathrm{Var}(Y)} = \\frac{0}{1/144} = 0\n$$\nThis verifies the given condition.\n\nFinally, we determine the total-order index $S_{T1}$. The numerator is $\\mathbb{E}[\\mathrm{Var}(Y \\mid X_{\\sim 1})]$. For this two-input model, $X_{\\sim 1}$ is simply the input $X_2$. We must compute $\\mathbb{E}[\\mathrm{Var}(Y \\mid X_2)]$. First, we find the conditional variance:\n$$\n\\mathrm{Var}(Y \\mid X_2) = \\mathrm{Var}\\left(\\left(X_1 - \\frac{1}{2}\\right)\\left(X_2 - \\frac{1}{2}\\right) \\mid X_2\\right)\n$$\nIn the context of conditioning on $X_2$, the term $(X_2 - \\frac{1}{2})$ is treated as a constant factor. Using the property $\\mathrm{Var}(aU) = a^2\\mathrm{Var}(U)$:\n$$\n\\mathrm{Var}(Y \\mid X_2) = \\left(X_2 - \\frac{1}{2}\\right)^2 \\mathrm{Var}\\left(\\left(X_1 - \\frac{1}{2}\\right) \\mid X_2\\right)\n$$\nDue to independence, $\\mathrm{Var}((X_1 - \\frac{1}{2}) \\mid X_2) = \\mathrm{Var}(X_1 - \\frac{1}{2}) = \\mathrm{Var}(X_1) = \\frac{1}{12}$.\nSo, the conditional variance is:\n$$\n\\mathrm{Var}(Y \\mid X_2) = \\frac{1}{12}\\left(X_2 - \\frac{1}{2}\\right)^2\n$$\nNow, we take the expectation of this quantity with respect to the distribution of $X_2$:\n$$\n\\mathbb{E}[\\mathrm{Var}(Y \\mid X_2)] = \\mathbb{E}\\left[\\frac{1}{12}\\left(X_2 - \\frac{1}{2}\\right)^2\\right] = \\frac{1}{12}\\mathbb{E}\\left[\\left(X_2 - \\frac{1}{2}\\right)^2\\right]\n$$\nThe term $\\mathbb{E}[(X_2 - \\frac{1}{2})^2]$ is, by definition, the second central moment of $X_2$, which is the variance of $X_2$, since $\\mathbb{E}[X_2] = \\frac{1}{2}$.\n$$\n\\mathbb{E}\\left[\\left(X_2 - \\frac{1}{2}\\right)^2\\right] = \\mathrm{Var}(X_2) = \\frac{1}{12}\n$$\nTherefore, the numerator for the total-order index is:\n$$\n\\mathbb{E}[\\mathrm{Var}(Y \\mid X_2)] = \\frac{1}{12} \\cdot \\frac{1}{12} = \\frac{1}{144}\n$$\nFinally, the total-order index $S_{T1}$ is:\n$$\nS_{T1} = \\frac{\\mathbb{E}[\\mathrm{Var}(Y \\mid X_{\\sim 1})]}{\\mathrm{Var}(Y)} = \\frac{1/144}{1/144} = 1\n$$\nThe result $S_{T1} = 1$ signifies that all the variance in the output $Y$ is attributable to the input $X_1$ through its direct effect (which is zero) and its interactions. In this particular model, the variance arises purely from the interaction between $X_1$ and $X_2$.", "answer": "$$\\boxed{1}$$", "id": "2434812"}, {"introduction": "Many real-world models are driven not by a few scalar parameters, but by entire functions, like a time-varying load on a structure. This computational practice challenges you to assess the sensitivity of a bridge's deflection to the time-history of an applied force [@problem_id:2434842]. By implementing the analysis, you will learn how to pinpoint the most critical moments in a functional input's history, a powerful skill in engineering design and analysis.", "problem": "Implement a complete program that computes first-order variance-based sensitivity indices for a linear time-invariant model output driven by a functional input that is discretized in time. The model represents a single mode approximation of a simply-supported bridge modeled as a Single Degree of Freedom (SDOF) oscillator. The model output at a final time $T$ is the deflection response written as a linear functional of the time-history of the load.\n\nModel definition:\n- Let the time interval be $[0,T]$, with $T0$.\n- Let $N\\ge 2$ be the number of equally spaced time samples, with time step $\\Delta t = T/(N-1)$, and nodes $t_i = i\\,\\Delta t$ for $i\\in\\{0,1,\\dots,N-1\\}$.\n- Let the random input vector be $U=(U_0,\\dots,U_{N-1})$, where the components are mutually independent, with $\\mathbb{E}[U_i]=0$ and $\\operatorname{Var}(U_i)=\\sigma_i^2$ given.\n- The model output is\n$$\nY \\;=\\; \\sum_{i=0}^{N-1} h\\!\\left(T-t_i\\right)\\,U_i\\,\\Delta t,\n$$\nwhere the weighting function $h$ is the SDOF unit impulse response\n$$\nh(\\tau) \\;=\\; \\frac{\\beta}{\\omega_d}\\, e^{-\\zeta\\,\\omega_n\\,\\tau}\\,\\sin\\!\\left(\\omega_d\\,\\tau\\right), \\quad \\tau\\ge 0,\n$$\nwith parameters $\\omega_n0$ (undamped natural frequency), $0\\le \\zeta1$ (damping ratio), $\\omega_d=\\omega_n\\sqrt{1-\\zeta^2}$ (damped natural frequency), and gain $\\beta0$. All angles used in the $\\sin(\\cdot)$ function are in radians.\n\nTask:\n- For each provided parameter set, compute the vector of first-order variance-based sensitivity indices $S=(S_0,\\dots,S_{N-1})$ of $Y$ with respect to the components $(U_0,\\dots,U_{N-1})$ under the assumption that the components of $U$ are mutually independent. The first-order index for component $i$ is defined by\n$$\nS_i \\;=\\; \\frac{\\operatorname{Var}\\!\\left(\\mathbb{E}[\\,Y \\mid U_i\\,]\\right)}{\\operatorname{Var}(Y)}.\n$$\n\nTest suite:\nYour program must compute $S$ for each of the following four parameter sets. In each item, the tuple lists $(T,N,\\omega_n,\\zeta,\\beta,\\{\\sigma_i^2\\}_{i=0}^{N-1})$.\n\n- Case $1$: $(T,N,\\omega_n,\\zeta,\\beta,\\{\\sigma_i^2\\}) = (\\,5.0,\\,5,\\,2.0,\\,0.1,\\,1.0,\\,[\\,1.0,\\,1.0,\\,1.0,\\,1.0,\\,1.0\\,]\\,)$.\n- Case $2$: $(T,N,\\omega_n,\\zeta,\\beta,\\{\\sigma_i^2\\}) = (\\,\\pi,\\,5,\\,1.0,\\,0.0,\\,1.0,\\,[\\,1.0,\\,1.0,\\,1.0,\\,1.0,\\,1.0\\,]\\,)$.\n- Case $3$: $(T,N,\\omega_n,\\zeta,\\beta,\\{\\sigma_i^2\\}) = (\\,4.0,\\,4,\\,1.5,\\,0.2,\\,1.0,\\,[\\,1.0,\\,0.0,\\,2.0,\\,0.0\\,]\\,)$.\n- Case $4$: $(T,N,\\omega_n,\\zeta,\\beta,\\{\\sigma_i^2\\}) = (\\,2.0,\\,6,\\,3.0,\\,0.05,\\,1.0,\\,[\\,0.5,\\,1.5,\\,0.2,\\,2.5,\\,1.0,\\,0.3\\,]\\,)$.\n\nAnswer specification:\n- For each case, return the list $[S_0,S_1,\\dots,S_{N-1}]$.\n- Your program should produce a single line of output containing the results as a comma-separated list of these lists, enclosed in square brackets, for example, $[\\,[\\cdot],\\,[\\cdot],\\,[\\cdot],\\,[\\cdot]\\,]$.\n- Each $S_i$ must be output as a real number (a float). No physical units are required in the output. Angles are in radians as specified above.", "solution": "The problem is subjected to validation.\n\nStep 1: Extracted Givens\n- Time Interval: $[0,T]$, with $T0$.\n- Time Discretization: $N\\ge 2$ samples, time step $\\Delta t = T/(N-1)$, nodes $t_i = i\\,\\Delta t$ for $i\\in\\{0,1,\\dots,N-1\\}$.\n- Random Input: $U=(U_0,\\dots,U_{N-1})$, where components $U_i$ are mutually independent, with $\\mathbb{E}[U_i]=0$ and $\\operatorname{Var}(U_i)=\\sigma_i^2$.\n- Model Output: $Y \\;=\\; \\sum_{i=0}^{N-1} h\\!\\left(T-t_i\\right)\\,U_i\\,\\Delta t$.\n- Weighting Function (Unit Impulse Response): $h(\\tau) \\;=\\; \\frac{\\beta}{\\omega_d}\\, e^{-\\zeta\\,\\omega_n\\,\\tau}\\,\\sin\\!\\left(\\omega_d\\,\\tau\\right)$ for $\\tau\\ge 0$.\n- Function Parameters: $\\omega_n0$, $0\\le \\zeta1$, $\\omega_d=\\omega_n\\sqrt{1-\\zeta^2}$, $\\beta0$.\n- Task: Compute the vector of first-order variance-based sensitivity indices $S=(S_0,\\dots,S_{N-1})$, where $S_i \\;=\\; \\frac{\\operatorname{Var}\\!\\left(\\mathbb{E}[\\,Y \\mid U_i\\,]\\right)}{\\operatorname{Var}(Y)}$.\n- Test Data: Four distinct parameter sets are provided.\n\nStep 2: Validation\n- The problem is scientifically grounded. It describes the sensitivity analysis of a standard linear single-degree-of-freedom (SDOF) oscillator, which is a fundamental model in physics and engineering. The method of variance-based sensitivity analysis (Sobol' indices) is a well-established and rigorous mathematical technique.\n- The problem is well-posed. All required parameters, functional forms, and statistical properties of the inputs are defined. The constraints on the parameters ($T0$, $N\\ge 2$, $\\omega_n0$, $0\\le \\zeta  1$) ensure that the physical model is well-defined and avoids singularities such as division by zero. A unique, stable solution for the sensitivity indices exists for each given parameter set.\n- The problem is objective and formal. It is stated using precise mathematical language without ambiguity or subjective elements.\n\nStep 3: Verdict\nThe problem is valid. A reasoned solution will be provided.\n\nThe model output $Y$ is a linear combination of the random input variables $U_i$. We can write it as:\n$$\nY = \\sum_{j=0}^{N-1} c_j U_j\n$$\nwhere the coefficients $c_j$ are deterministic and given by:\n$$\nc_j = h(T-t_j)\\,\\Delta t\n$$\nThe task is to compute the first-order sensitivity index $S_i$ for each input $U_i$, defined as:\n$$\nS_i = \\frac{\\operatorname{Var}(\\mathbb{E}[Y \\mid U_i])}{\\operatorname{Var}(Y)}\n$$\nWe must first compute the total variance of the output, $\\operatorname{Var}(Y)$, and the partial variances, $\\operatorname{Var}(\\mathbb{E}[Y \\mid U_i])$.\n\n1. Calculation of Total Variance $\\operatorname{Var}(Y)$:\nThe input variables $U_j$ are mutually independent. Consequently, the terms $c_j U_j$ in the sum for $Y$ are also mutually independent. The variance of a sum of independent random variables is the sum of their variances.\n$$\n\\operatorname{Var}(Y) = \\operatorname{Var}\\left(\\sum_{j=0}^{N-1} c_j U_j\\right) = \\sum_{j=0}^{N-1} \\operatorname{Var}(c_j U_j)\n$$\nUsing the property $\\operatorname{Var}(aX) = a^2\\operatorname{Var}(X)$ for a constant $a$ and random variable $X$, we have:\n$$\n\\operatorname{Var}(c_j U_j) = c_j^2 \\operatorname{Var}(U_j) = c_j^2 \\sigma_j^2\n$$\nTherefore, the total variance is:\n$$\n\\operatorname{Var}(Y) = \\sum_{j=0}^{N-1} c_j^2 \\sigma_j^2\n$$\n\n2. Calculation of Partial Variance $\\operatorname{Var}(\\mathbb{E}[Y \\mid U_i])$:\nFirst, we find the conditional expectation $\\mathbb{E}[Y \\mid U_i]$. By linearity of expectation:\n$$\n\\mathbb{E}[Y \\mid U_i] = \\mathbb{E}\\left[\\sum_{j=0}^{N-1} c_j U_j \\;\\Bigg|\\; U_i\\right] = \\sum_{j=0}^{N-1} \\mathbb{E}[c_j U_j \\mid U_i]\n$$\nWe split the sum for the index $j=i$ and for all indices $j \\neq i$:\n$$\n\\mathbb{E}[Y \\mid U_i] = \\mathbb{E}[c_i U_i \\mid U_i] + \\sum_{j \\neq i} \\mathbb{E}[c_j U_j \\mid U_i]\n$$\nFor the term $j=i$, $U_i$ is known, so $\\mathbb{E}[c_i U_i \\mid U_i] = c_i U_i$.\nFor any term $j \\neq i$, $U_j$ is independent of $U_i$. Thus, conditioning on $U_i$ does not affect the expectation of $U_j$.\n$$\n\\mathbb{E}[c_j U_j \\mid U_i] = c_j \\mathbb{E}[U_j]\n$$\nSince it is given that $\\mathbb{E}[U_j] = 0$ for all $j$, this term is zero.\nCombining these results, the conditional expectation simplifies to:\n$$\n\\mathbb{E}[Y \\mid U_i] = c_i U_i\n$$\nNow we compute the variance of this expression:\n$$\n\\operatorname{Var}(\\mathbb{E}[Y \\mid U_i]) = \\operatorname{Var}(c_i U_i) = c_i^2 \\operatorname{Var}(U_i) = c_i^2 \\sigma_i^2\n$$\n\n3. Formulation of the Sensitivity Index $S_i$:\nSubstituting the expressions for the total and partial variances into the definition of $S_i$:\n$$\nS_i = \\frac{c_i^2 \\sigma_i^2}{\\sum_{j=0}^{N-1} c_j^2 \\sigma_j^2}\n$$\nNow, we substitute $c_j = h(T-t_j)\\Delta t$:\n$$\nS_i = \\frac{\\left(h(T-t_i)\\Delta t\\right)^2 \\sigma_i^2}{\\sum_{j=0}^{N-1} \\left(h(T-t_j)\\Delta t\\right)^2 \\sigma_j^2}\n$$\nThe factor $(\\Delta t)^2$ appears in both the numerator and every term of the denominator's sum, thus it can be cancelled. This cancellation simplifies the expression for $S_i$ significantly, removing the dependency on $\\Delta t$:\n$$\nS_i = \\frac{h(T-t_i)^2 \\sigma_i^2}{\\sum_{j=0}^{N-1} h(T-t_j)^2 \\sigma_j^2}\n$$\nThis is the final formula used for computation. If the total variance in the denominator is zero (which implies the output $Y$ is a constant), all partial variances in the numerators must also be zero. In this special case, the output is insensitive to all inputs, and all $S_i$ are defined to be $0$.\n\nThe algorithm is as follows:\nFor each given parameter set $(T,N,\\omega_n,\\zeta,\\beta,\\{\\sigma_i^2\\})$:\n1.  Calculate the time points $t_i = i \\frac{T}{N-1}$ for $i=0,\\dots,N-1$.\n2.  Calculate the arguments for the impulse response function: $\\tau_i = T - t_i$.\n3.  Calculate the damped natural frequency $\\omega_d = \\omega_n\\sqrt{1-\\zeta^2}$.\n4.  Evaluate the impulse response function $h_i = h(\\tau_i)$ for each $\\tau_i$.\n5.  Calculate the numerator terms (proportional to partial variances), $D_i = h_i^2 \\sigma_i^2$.\n6.  Calculate the denominator (proportional to total variance), $D = \\sum_{j=0}^{N-1} D_j$.\n7.  If $D=0$, all $S_i$ are $0$. Otherwise, compute each sensitivity index as $S_i = D_i / D$.\n8.  Collect the resulting list $[S_0, \\dots, S_{N-1}]$ for the current case.\nThis procedure is repeated for all four test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes first-order variance-based sensitivity indices for a linear SDOF model.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (5.0, 5, 2.0, 0.1, 1.0, [1.0, 1.0, 1.0, 1.0, 1.0]),\n        (np.pi, 5, 1.0, 0.0, 1.0, [1.0, 1.0, 1.0, 1.0, 1.0]),\n        (4.0, 4, 1.5, 0.2, 1.0, [1.0, 0.0, 2.0, 0.0]),\n        (2.0, 6, 3.0, 0.05, 1.0, [0.5, 1.5, 0.2, 2.5, 1.0, 0.3]),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        T, N, wn, zeta, beta, sigma_sq_list = case\n        \n        # Convert list to numpy array for vectorized operations\n        sigma_sq = np.array(sigma_sq_list)\n\n        # 1. Calculate time points and arguments for h(tau)\n        # Time nodes t_i from 0 to T\n        t = np.linspace(0, T, N)\n        # Arguments for h are tau_i = T - t_i. This is equivalent to time-reversing\n        # the linspace from T to 0.\n        tau = np.linspace(T, 0, N)\n\n        # 2. Calculate derived physical parameters\n        # Damped natural frequency, wd\n        wd = wn * np.sqrt(1 - zeta**2)\n\n        # 3. Evaluate the impulse response function h(tau)\n        # h(tau) = (beta / wd) * exp(-zeta * wn * tau) * sin(wd * tau)\n        # The case wd = 0 corresponds to zeta = 1 (critical damping), which is\n        # excluded by problem constraints (zeta  1).\n        # However, for numerical stability, if wd is very small, sin(wd*tau)/wd approaches tau.\n        # Given the problem constraints, a direct computation is safe.\n        h_coeffs = (beta / wd) * np.exp(-zeta * wn * tau) * np.sin(wd * tau)\n\n        # 4. Calculate terms proportional to partial variances\n        # D_i = h(T-t_i)^2 * sigma_i^2\n        partial_vars = h_coeffs**2 * sigma_sq\n\n        # 5. Calculate term proportional to total variance\n        # D = sum(D_j)\n        total_var = np.sum(partial_vars)\n\n        # 6. Compute sensitivity indices S_i = D_i / D\n        if total_var == 0:\n            # If total variance is zero, output is constant, so it is insensitive to all inputs.\n            s_indices = np.zeros(N)\n        else:\n            s_indices = partial_vars / total_var\n\n        all_results.append(s_indices.tolist())\n\n    # Final print statement in the exact required format.\n    # The format is a string representation of a list of lists.\n    # map(str, ...) converts each inner list to its string form, e.g., '[0.1, 0.2]'.\n    # ','.join(...) joins these strings with commas.\n    # The outer f\"[{...}]\" wraps the result in brackets.\n    # e.g., \"[[0.1, 0.2],[0.3, 0.4]]\"\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "2434842"}]}