{"hands_on_practices": [{"introduction": "The master-worker paradigm is a cornerstone of parallel computing, ideal for problems that can be decomposed into independent tasks. In this practice, you will build a discrete-event simulation to model this pattern, focusing on the use of non-blocking sends for task distribution [@problem_id:2413700]. This exercise will develop your skills in performance modeling and help you understand how factors like network latency, bandwidth, and task computation time collectively determine the overall application runtime, or makespan.", "problem": "Implement a discrete-event simulation of a master/worker computation to study message passing and communication patterns. The master assigns independent tasks to a fixed pool of workers using non-blocking sends. Each task consists of a request message from the master to a worker, a computation on the worker, and a result message from the worker back to the master. The master does not block on sends; it can post multiple sends at the same simulation time instant. Workers process at most one task at a time and immediately become idle upon finishing computation; result messages do not delay a worker’s availability. Your goal is to compute the total completion time (makespan) for a set of given scenarios.\n\nFundamental base and assumptions:\n- Use the standard definitions from message passing systems such as Message Passing Interface (MPI). In particular, a non-blocking send returns control to the caller immediately without waiting for message transfer to complete. We model the network transfer time using a fixed latency and a bandwidth term.\n- Let $L$ be the one-way latency in seconds, $B$ be the bandwidth in bytes per second, and $s$ be the message size in bytes. The one-way transfer time is\n$$\nT(s) = L + \\frac{s}{B},\n$$\nwith the convention that if $B = \\infty$ then $\\frac{s}{B} = 0$.\n- For each task $i$ with worker compute time $c_i$ (in seconds), there is a request message of size $s_\\mathrm{req}$ sent from master to worker before computation, and a result message of size $s_\\mathrm{resp}$ sent from worker to master after computation. Thus, if a task is assigned to a worker at time $t$, it starts computing at time $t + T(s_\\mathrm{req})$ and finishes computing at time $t + T(s_\\mathrm{req}) + c_i$. Its result reaches the master at time $t + T(s_\\mathrm{req}) + c_i + T(s_\\mathrm{resp})$.\n- The master uses non-blocking sends. As soon as a worker is idle and there is a pending task, at that exact simulation time the master posts a send to that worker. The send does not block the master, and the assignment time is the moment the worker becomes idle. The worker’s availability is not delayed by sending its result because the worker’s send is assumed non-blocking.\n- Workers process at most one task at a time. The master begins by assigning up to $\\min(W, N)$ tasks at time $t=0$, where $W$ is the number of workers and $N$ is the number of tasks. There is no preemption.\n\nQuantities to compute:\n- For each scenario, compute the makespan $T_\\mathrm{end}$, defined as the time when the master has received the last result message. Formally,\n$$\nT_\\mathrm{end} = \\max_{i=1,\\dots,N} \\left( t_i^\\mathrm{assign} + T(s_\\mathrm{req}) + c_i + T(s_\\mathrm{resp}) \\right),\n$$\nwhere $t_i^\\mathrm{assign}$ is the time the master assigns task $i$ to some worker (determined by the event-driven schedule described above).\n\nAlgorithmic requirement:\n- Implement a discrete-event simulation based on the above definitions. A correct and efficient approach is to simulate worker availability using a priority queue keyed by each worker’s next compute-completion time, posting new assignments at the exact times workers become idle. You must not rely on any external libraries for message passing; this is a pure simulation.\n\nUnits and numerical specification:\n- All times must be expressed in seconds.\n- All message sizes must be expressed in bytes.\n- All bandwidths must be expressed in bytes per second.\n- Your program must output each makespan in seconds, rounded to six decimal places.\n\nTest suite:\nFor each test case, specify $(W, \\{c_i\\}, L, B, s_\\mathrm{req}, s_\\mathrm{resp})$ and compute $T_\\mathrm{end}$.\n\n- Test 1 (general case):\n  - $W = 3$\n  - $\\{c_i\\} = [2.0, 3.0, 7.0, 1.0, 4.0]$ (seconds)\n  - $L = 0.1$ (seconds)\n  - $B = 10^6$ (bytes/second)\n  - $s_\\mathrm{req} = 1000$ (bytes)\n  - $s_\\mathrm{resp} = 1000$ (bytes)\n- Test 2 (boundary with zero communication cost):\n  - $W = 1$\n  - $\\{c_i\\} = [1.0, 2.0, 3.0]$ (seconds)\n  - $L = 0.0$ (seconds)\n  - $B = \\infty$ (bytes/second)\n  - $s_\\mathrm{req} = 100$ (bytes)\n  - $s_\\mathrm{resp} = 100$ (bytes)\n- Test 3 (latency-dominated micro-tasks):\n  - $W = 2$\n  - $\\{c_i\\} = [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]$ (seconds)\n  - $L = 0.2$ (seconds)\n  - $B = 10^6$ (bytes/second)\n  - $s_\\mathrm{req} = 100$ (bytes)\n  - $s_\\mathrm{resp} = 100$ (bytes)\n- Test 4 (many workers, few tasks):\n  - $W = 10$\n  - $\\{c_i\\} = [5.0, 1.0, 2.0]$ (seconds)\n  - $L = 0.05$ (seconds)\n  - $B = 10^6$ (bytes/second)\n  - $s_\\mathrm{req} = 500$ (bytes)\n  - $s_\\mathrm{resp} = 500$ (bytes)\n- Test 5 (bandwidth-dominated messages):\n  - $W = 4$\n  - $\\{c_i\\} = [0.5, 1.5, 0.7, 2.0, 1.2, 0.3, 0.9]$ (seconds)\n  - $L = 0.02$ (seconds)\n  - $B = 2 \\times 10^3$ (bytes/second)\n  - $s_\\mathrm{req} = 4000$ (bytes)\n  - $s_\\mathrm{resp} = 8000$ (bytes)\n\nFinal output format:\n- Your program must produce a single line of output containing the five makespans corresponding to the five tests, as a comma-separated list enclosed in square brackets, for example, $[x_1, x_2, x_3, x_4, x_5]$, where each $x_k$ is the makespan in seconds rounded to six decimal places.\n- Your program must be self-contained, must not read any input, and must not access external files or networks.", "solution": "The problem presented is a valid and well-posed exercise in computational systems modeling. It is a standard formulation of a master-worker parallel computation pattern, grounded in the fundamental principles of discrete-event simulation and network performance modeling. The parameters are clearly defined, the objective function is specified unambiguously, and the scheduling policy is deterministic, which guarantees a unique solution. The problem provides a concrete set of test cases for verification. We will proceed with a solution based on these principles.\n\nThe system dynamics are governed by events, specifically the completion of a computation by a worker. This makes discrete-event simulation the natural and correct approach. We model the system state by tracking the availability of each worker and the queue of tasks yet to be scheduled. The most efficient method to manage worker availability is to use a priority queue, where the priority of each event is its timestamp.\n\nLet $W$ be the number of workers and $N$ be the number of tasks. The compute time for task $i$ is $c_i$. The network is characterized by a one-way latency $L$ and a bandwidth $B$. The size of a request message is $s_\\mathrm{req}$ and a response message is $s_\\mathrm{resp}$. The one-way transfer time for a message of size $s$ is given by the linear model $T(s) = L + s/B$. It is understood that if $B = \\infty$, the term $s/B$ is $0$.\n\nFrom this, we define the request transfer time $T_\\mathrm{req} = T(s_\\mathrm{req})$ and response transfer time $T_\\mathrm{resp} = T(s_\\mathrm{resp})$.\n\nA task assigned at time $t_\\mathrm{assign}$ will begin computation on the worker at time $t_\\mathrm{assign} + T_\\mathrm{req}$. The computation itself takes $c_i$ seconds. Thus, the worker completes the computation at time $t_\\mathrm{finish\\_compute} = t_\\mathrm{assign} + T_\\mathrm{req} + c_i$. Upon completion, the worker is immediately available to be assigned a new task. The result message is then sent, arriving at the master at time $t_\\mathrm{result\\_arrival} = t_\\mathrm{finish\\_compute} + T_\\mathrm{resp}$. The overall objective is to find the makespan, $T_\\mathrm{end}$, which is the time the last result message is received by the master:\n$$\nT_\\mathrm{end} = \\max_{i=1,\\dots,N} \\{t_\\mathrm{result\\_arrival}^{(i)}\\}\n$$\nwhere $t_\\mathrm{result\\_arrival}^{(i)}$ is the arrival time of the result for task $i$.\n\nThe core of our simulation is a priority queue, which we will call `worker_events`. This data structure will store events corresponding to workers finishing their computations. Each element in the queue will be a tuple $(t, w)$, representing that worker $w$ will finish its current computation at time $t$. The priority queue is ordered by time $t$, so we can always efficiently retrieve the next worker that becomes free.\n\nThe simulation proceeds as follows:\n\n1.  **Initialization**:\n    *   Initialize a variable `makespan` to $0$.\n    *   Initialize a queue of unassigned tasks, sequenced in the order they are given. Let `next_task_idx` be the index of the next task to assign.\n    *   At simulation time $t=0$, the master assigns the first $\\min(W, N)$ tasks. For each of these initial tasks $i \\in \\{0, 1, \\dots, \\min(W, N)-1\\}$, assigned to worker $i$:\n        *   The assignment time is $t_i^\\mathrm{assign} = 0$.\n        *   The computation finish time is $t_{i}^\\mathrm{finish\\_compute} = 0 + T_\\mathrm{req} + c_i$.\n        *   Push the event $(t_{i}^\\mathrm{finish\\_compute}, i)$ into the `worker_events` priority queue.\n        *   The result arrival time is $t_{i}^\\mathrm{result\\_arrival} = t_{i}^\\mathrm{finish\\_compute} + T_\\mathrm{resp}$.\n        *   Update `makespan` = $\\max(\\text{makespan}, t_{i}^\\mathrm{result\\_arrival})$.\n    *   Set `next_task_idx` to $\\min(W, N)$.\n\n2.  **Simulation Loop**:\n    *   This loop continues as long as there are tasks remaining to be assigned (i.e., `next_task_idx` < $N$).\n    *   Extract the event with the minimum time from `worker_events`. This gives $(t_\\mathrm{finish}, w_\\mathrm{free})$, the time when worker $w_\\mathrm{free}$ becomes idle.\n    *   The problem states that a new task is assigned to this worker at the exact moment it becomes idle. Therefore, the assignment time for the next task (let its index be $j = \\text{next\\_task\\_idx}$) is $t_j^\\mathrm{assign} = t_\\mathrm{finish}$.\n    *   Schedule this new task $j$ on worker $w_\\mathrm{free}$:\n        *   The new computation finish time for this worker is $t_{j}^\\mathrm{finish\\_compute} = t_j^\\mathrm{assign} + T_\\mathrm{req} + c_j$.\n        *   Push the new event $(t_{j}^\\mathrm{finish\\_compute}, w_\\mathrm{free})$ into the `worker_events` priority queue.\n        *   The result arrival time for task $j$ is $t_{j}^\\mathrm{result\\_arrival} = t_{j}^\\mathrm{finish\\_compute} + T_\\mathrm{resp}$.\n        *   Update `makespan` = $\\max(\\text{makespan}, t_{j}^\\mathrm{result\\_arrival})$.\n    *   Increment `next_task_idx`.\n\n3.  **Termination**:\n    *   The loop terminates when `next_task_idx` reaches $N$, meaning all tasks have been scheduled. The final value held by the `makespan` variable is the maximum of all result arrival times, which is precisely the definition of $T_\\mathrm{end}$.\n\nThis algorithm correctly models the specified system and will be implemented to solve for the given test cases. Python's `heapq` module provides a suitable implementation of a min-priority queue.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport heapq\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print results.\n    \"\"\"\n    # Test cases defined as tuples:\n    # (W, {c_i}, L, B, s_req, s_resp)\n    test_cases = [\n        # Test 1 (general case)\n        (3, [2.0, 3.0, 7.0, 1.0, 4.0], 0.1, 1e6, 1000, 1000),\n        # Test 2 (boundary with zero communication cost)\n        (1, [1.0, 2.0, 3.0], 0.0, np.inf, 100, 100),\n        # Test 3 (latency-dominated micro-tasks)\n        (2, [0.05] * 10, 0.2, 1e6, 100, 100),\n        # Test 4 (many workers, few tasks)\n        (10, [5.0, 1.0, 2.0], 0.05, 1e6, 500, 500),\n        # Test 5 (bandwidth-dominated messages)\n        (4, [0.5, 1.5, 0.7, 2.0, 1.2, 0.3, 0.9], 0.02, 2e3, 4000, 8000),\n    ]\n\n    results = []\n    for case in test_cases:\n        makespan = simulate_master_worker(*case)\n        results.append(f\"{makespan:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\ndef simulate_master_worker(W, c_tasks, L, B, s_req, s_resp):\n    \"\"\"\n    Implements a discrete-event simulation of a master/worker computation.\n\n    Args:\n        W (int): Number of workers.\n        c_tasks (list[float]): List of compute times for each task.\n        L (float): One-way network latency in seconds.\n        B (float): Network bandwidth in bytes per second.\n        s_req (float): Request message size in bytes.\n        s_resp (float): Response message size in bytes.\n\n    Returns:\n        float: The total completion time (makespan) in seconds.\n    \"\"\"\n    num_tasks = len(c_tasks)\n    if num_tasks == 0:\n        return 0.0\n\n    # Calculate one-way transfer times for request and response messages\n    if B == np.inf:\n        t_req = L\n        t_resp = L\n    else:\n        t_req = L + s_req / B\n        t_resp = L + s_resp / B\n\n    # Priority queue stores events of workers finishing computation.\n    # Each item is a tuple: (finish_compute_time, worker_id).\n    worker_events = []\n    \n    # Track the overall makespan (time last result is received by master).\n    makespan = 0.0\n    \n    # Index for the next task to be assigned from the c_tasks list.\n    next_task_idx = 0\n\n    # Initial phase: Assign tasks to all available workers at time t=0.\n    num_initial_tasks = min(W, num_tasks)\n    for i in range(num_initial_tasks):\n        c_i = c_tasks[i]\n        worker_id = i\n        \n        # Assignment time is 0 for the initial batch of tasks.\n        t_assign = 0.0\n        \n        # A worker finishes its computation at t_assign + network_delay + compute_time.\n        finish_compute_time = t_assign + t_req + c_i\n        \n        # The result for this task arrives at the master after the response message is sent.\n        result_arrival_time = finish_compute_time + t_resp\n        \n        # Update the makespan with the latest result arrival.\n        makespan = max(makespan, result_arrival_time)\n        \n        # Add a \"worker free\" event to the priority queue.\n        heapq.heappush(worker_events, (finish_compute_time, worker_id))\n        \n        next_task_idx += 1\n\n    # Main simulation loop: process events until all tasks are assigned.\n    while next_task_idx < num_tasks:\n        # Get the next worker to become free from the priority queue.\n        # This event defines the current simulation time for the new assignment.\n        finish_compute_time, worker_id = heapq.heappop(worker_events)\n        \n        # The worker becomes free at finish_compute_time. This is the assignment\n        # time for the next task scheduled on this worker.\n        t_assign = finish_compute_time\n        \n        # Get the compute time for the next task in the queue.\n        c_i = c_tasks[next_task_idx]\n        \n        # Schedule the new task on the now-free worker.\n        new_finish_compute_time = t_assign + t_req + c_i\n        new_result_arrival_time = new_finish_compute_time + t_resp\n        \n        # Update the overall makespan.\n        makespan = max(makespan, new_result_arrival_time)\n        \n        # Add the new event for this worker finishing its new task.\n        heapq.heappush(worker_events, (new_finish_compute_time, worker_id))\n        \n        next_task_idx += 1\n        \n    return makespan\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2413700"}, {"introduction": "While well-designed communication patterns enable parallelism, poorly designed ones can lead to critical errors like deadlock. This practice explores a classic deadlock scenario arising from resource contention in a ring communication pattern [@problem_id:2413727]. By simulating a system with limited message buffer space, you will not only reproduce a deadlock but also derive from first principles the minimal resources required to prevent it, gaining a deep intuition for a fundamental hazard in message passing.", "problem": "Consider a discrete, deterministic simulation of blocking message passing among $n$ sequential processes arranged in a unidirectional ring. Each process executes exactly two operations in a fixed order: (i) a blocking send of a single message of size $m$ bytes to its successor, and then (ii) a blocking receive of a single message of size $m$ bytes from its predecessor. The successor of process $i$ is $(i+1)\\bmod n$, and the predecessor is $(i-1)\\bmod n$. There is a single global system buffer pool of size $S$ bytes shared by all sends. A send operation succeeds if and only if at least $m$ bytes are currently available in the global pool; if it succeeds, it enqueues the message into the destination’s inbox and consumes exactly $m$ bytes from the pool. A receive operation succeeds if and only if the receiver’s inbox currently contains at least one message; upon success, it removes the message and returns $m$ bytes to the global pool. All channels are reliable and lossless. No process changes its operation order and no process performs any other actions.\n\nDefine deadlock as a state in which at least one process is not finished and no process can complete its next operation given the current global buffer usage and inbox contents. The simulation proceeds in deterministic round-robin sweeps over processes $0,1,\\dots,n-1,0,1,\\dots$ repeatedly. In each sweep, each process attempts to perform its current operation; if the operation’s condition is not satisfied, the process remains blocked on that operation for this attempt. The simulation terminates either when all processes have completed both operations or when an entire sweep results in no successful operation while at least one process is not finished (deadlock).\n\nTask: Write a complete program that simulates this system exactly as specified above. For each test case below, run the simulation twice:\n- First, with the provided tuple $(n,m,S)$, and record whether the simulation ends in deadlock (record `True` for deadlock, `False` otherwise).\n- Second, without changing the send/receive order or the round-robin schedule, replace $S$ by the minimal global buffer size $S_{\\text{fix}}$ (in bytes) that guarantees the absence of deadlock for this workload, and record whether the simulation ends in deadlock under this fixed configuration. You must determine $S_{\\text{fix}}$ from first principles.\n\nAll byte quantities are to be interpreted literally in bytes. There are no other units in this problem. Your program must produce a single line of output containing the results as a comma-separated list of booleans enclosed in square brackets, in the order specified below. For each test case, output the pair of booleans $[b_{\\text{orig}},b_{\\text{fix}}]$ flattened into a single list in the same order as the test cases are listed.\n\nTest suite (each tuple is $(n,m,S)$, with all quantities in bytes):\n- $(2,10,10)$\n- $(2,10,20)$\n- $(3,8,8)$\n- $(4,8,15)$\n- $(5,7,35)$\n\nTherefore, the required single-line output must contain $10$ booleans corresponding to these $5$ test cases, each contributing $2$ booleans in the stated order. The output format must be exactly a single line:\n\"[b1,b2,b3,b4,b5,b6,b7,b8,b9,b10]\"\nwhere each $b_i$ is either \"True\" or \"False\".", "solution": "The system described is a discrete-time simulation of communicating sequential processes. The critical aspect of this problem is the potential for deadlock, a circular dependency on shared resources. Here, the resources are the global buffer space and the messages themselves. We must first analyze the conditions that lead to deadlock to determine the minimal buffer size $S_{\\text{fix}}$ that guarantees its prevention. Then, we construct a simulation program to verify the behavior for the given test cases.\n\nLet us analyze the system dynamics. The state of each process $i$ can be one of three: `SEND`, `RECEIVE`, or `DONE`. Initially, all $n$ processes are in the `SEND` state, the buffer holds $S$ bytes, and all message inboxes are empty. The simulation proceeds in sweeps, with processes $0, 1, \\dots, n-1$ attempting their operations sequentially.\n\nA deadlock occurs if and only if the system reaches a state where no process can proceed, yet not all processes are `DONE`. A process is blocked on `SEND` if the buffer has fewer than $m$ bytes. A process is blocked on `RECEIVE` if its inbox is empty.\n\nConsider the initial sweeps. In the first sweep, all processes attempt to send. Let $k_{\\max}$ be the maximum number of processes that can sequentially send before the buffer is exhausted. A process `SEND` consumes $m$ bytes, so $k_{\\max}$ successful sends consume $k_{\\max} \\cdot m$ bytes. This is possible if $S \\ge k_{\\max} \\cdot m$. The $(k_{\\max}+1)$-th process would fail if $S - k_{\\max} \\cdot m < m$. Thus, $k_{\\max} = \\lfloor S/m \\rfloor$. For the problem to be non-trivial, we assume $S \\ge m$ and $n \\ge 2$. Therefore, $k_{\\max} \\ge 1$.\n\nAfter the first round of send attempts based on the round-robin schedule $0, 1, \\dots, n-1$:\n- Processes $0, 1, \\dots, k_{\\max}-1$ successfully send and transition to the `RECEIVE` state.\n- Processes $k_{\\max}, \\dots, n-1$ fail to send and remain blocked in the `SEND` state.\n- The buffer size is reduced to $S' = S - k_{\\max} \\cdot m$. By definition of $k_{\\max}$, we have $S' < m$.\n- The inbox of process $i$ contains one message for each $i \\in \\{1, \\dots, k_{\\max}\\}$. Other inboxes are empty.\n\nNow, consider the next sweep.\n- Any process $j \\in \\{k_{\\max}, \\dots, n-1\\}$ is blocked on `SEND` because the buffer size $S'$ is less than $m$.\n- A process $i \\in \\{0, \\dots, k_{\\max}-1\\}$ is blocked on `RECEIVE` if its inbox is empty. This means its predecessor, $(i-1) \\bmod n$, has not yet successfully sent a message.\n- Let's examine the `RECEIVE` processes:\n    - Process $0$ is waiting for a message from process $n-1$. If $k_{\\max} < n$, then process $n-1$ is blocked on `SEND`. Thus, process $0$ is blocked on `RECEIVE`.\n    - Process $i \\in \\{1, \\dots, k_{\\max}-1\\}$ is waiting for a message from process $i-1$. In the first sweep, process $i-1$ successfully sent a message. Therefore, the inbox of process $i$ is not empty. Process $i$ can successfully receive.\n\nA deadlock occurs if no process can make progress. The `SEND`-blocked processes cannot progress. The `RECEIVE`-blocked processes can progress only if at least one of them can receive. As analyzed, processes $1, \\dots, k_{\\max}-1$ are capable of receiving. A deadlock will occur if and only if this set of receivable processes is empty.\nThe set $\\{1, \\dots, k_{\\max}-1\\}$ is empty if $k_{\\max}-1 < 1$, which simplifies to $k_{\\max} < 2$. Since we assumed $S \\ge m$, $k_{\\max}$ must be at least $1$. Thus, a deadlock is guaranteed if $k_{\\max} = 1$.\n\nThe condition $k_{\\max} = 1$ is equivalent to $1 \\le S/m < 2$, or $m \\le S < 2m$. In this scenario, only process $0$ sends. It then blocks waiting for a message from process $n-1$. All other processes, $1, \\dots, n-1$, are blocked on `SEND` due to insufficient buffer. No process can proceed, and the system is in deadlock.\n\nTo guarantee the absence of deadlock, we must ensure that this condition is avoided. We must have $k_{\\max} \\ge 2$. This requires $S/m \\ge 2$, or $S \\ge 2m$. If $S \\ge 2m$, then at least processes $0$ and $1$ can send. In the next sweep, process $1$ can receive, which returns $m$ bytes to the buffer. This may allow process $2$ (if it was blocked) to send, and a chain reaction of unblocking events propagates through the system, eventually leading to completion for all processes.\n\nTherefore, for any number of processes $n \\ge 2$, the minimal global buffer size that guarantees the absence of deadlock is $S_{\\text{fix}} = 2m$.\n\nThe program will implement a direct simulation of the system. For each test case $(n, m, S)$, it will first run the simulation with the provided $S$ to find $b_{\\text{orig}}$. It will then calculate $S_{\\text{fix}} = 2m$ and run the simulation again with this value to find $b_{\\text{fix}}$. The simulation function will maintain the state of each process, the contents of each inbox, and the available buffer size, executing sweeps until a terminal state (all processes `DONE` or deadlock) is reached.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\n\ndef simulate(n, m, S):\n    \"\"\"\n    Simulates the message passing system as described.\n\n    Args:\n        n (int): Number of processes.\n        m (int): Message size in bytes.\n        S (int): Global buffer size in bytes.\n\n    Returns:\n        bool: True if deadlock occurs, False otherwise.\n    \"\"\"\n    # States: 0=SEND, 1=RECEIVE, 2=DONE\n    process_states = [0] * n\n    inboxes = [[] for _ in range(n)]\n    buffer_size = S\n    \n    # Handle the trivial case where no process can ever send.\n    if S < m:\n        return True\n\n    while True:\n        num_done = sum(1 for state in process_states if state == 2)\n        if num_done == n:\n            return False  # Success, all processes are done\n\n        progress_in_sweep = False\n        for i in range(n):\n            state = process_states[i]\n\n            if state == 0:  # SEND\n                if buffer_size >= m:\n                    buffer_size -= m\n                    successor = (i + 1) % n\n                    inboxes[successor].append(1)  # Message content is irrelevant\n                    process_states[i] = 1\n                    progress_in_sweep = True\n            \n            elif state == 1:  # RECEIVE\n                if len(inboxes[i]) > 0:\n                    inboxes[i].pop(0)\n                    buffer_size += m\n                    process_states[i] = 2\n                    progress_in_sweep = True\n        \n        if not progress_in_sweep:\n            # If no progress was made, check if we are done or deadlocked.\n            # The check for all_done is at the start of the loop.\n            # So if we are here with no progress, it must be a deadlock.\n            return True  # Deadlock\n\ndef solve():\n    \"\"\"\n    Runs the simulation for all test cases and prints the results.\n    \"\"\"\n    test_cases = [\n        # (n, m, S)\n        (2, 10, 10),\n        (2, 10, 20),\n        (3, 8, 8),\n        (4, 8, 15),\n        (5, 7, 35),\n    ]\n\n    results = []\n    for n, m, S in test_cases:\n        # Run original simulation\n        b_orig = simulate(n, m, S)\n        results.append(b_orig)\n\n        # Determine S_fix and run fixed simulation\n        # As derived, the minimal buffer size to avoid deadlock for n >= 2\n        # is 2*m, as this ensures at least two processes can send,\n        # allowing the second one to eventually receive and replenish the buffer.\n        S_fix = 2 * m\n        b_fix = simulate(n, m, S_fix)\n        results.append(b_fix)\n\n    # Format output as a single line: \"[True,False,True,...]\"\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2413727"}, {"introduction": "Efficiently communicating portions of large data structures, such as a sub-matrix, is a frequent challenge in scientific computing. This final practice moves into the realm of performance optimization, asking you to analyze the trade-offs between two common strategies for sending non-contiguous data [@problem_id:2413742]. Using a first-principles cost model, you will compare the performance of an MPI-style derived datatype against manual data packing, revealing how the optimal choice depends on the data layout and underlying hardware characteristics.", "problem": "You are studying the performance trade-offs between two communication strategies for sending a rectangular, non-contiguous slice of a row-major dense matrix from one process to another in the Message Passing Interface (MPI) paradigm, without actually invoking the Message Passing Interface (MPI) runtime. The two strategies are: (i) using a derived datatype that describes the non-contiguous memory layout, and (ii) manual packing into a contiguous buffer followed by a contiguous send and a contiguous unpack at the receiver. Model the total time using a first-principles cost model grounded in a latency–bandwidth description of message passing.\n\nLet the matrix have $M$ rows and $N$ columns, stored in row-major order. The slice to be sent is a rectangle covering rows $r_0$ through $r_0 + m - 1$ and columns $c_0$ through $c_0 + w - 1$, with $m \\ge 1$ and $w \\ge 1$. This selection consists of $m$ contiguous row-blocks of length $w$ elements each, separated in memory by a stride equal to $N - w$ elements. Each element occupies $b$ bytes.\n\nAssume the following timing model, in which each symbol denotes a nonnegative real constant with physical units as indicated:\n- Communication of a contiguous message of size $B$ bytes takes time $\\alpha + \\beta B$, where $\\alpha$ is the latency in seconds and $\\beta$ is the inverse bandwidth in seconds per byte.\n- When using a derived datatype to express the non-contiguous layout, the implementation incurs an additional per-noncontiguous-block overhead of $\\sigma$ seconds for each of the $m$ contiguous row-blocks. If the layout is contiguous, defined by the condition $w = N$, then treat the selection as a single contiguous block with no additional non-contiguity overhead.\n- When using manual packing and unpacking, each element copied during packing or unpacking costs $\\gamma$ seconds. If the layout is contiguous, defined by $w = N$, then no packing or unpacking is required and the packing and unpacking time is zero.\n\nUsing only these definitions, the quantities to be computed for each test case are:\n- The total number of selected elements $E = m \\cdot w$.\n- The total number of selected bytes $B = E \\cdot b$.\n- The total time for the derived-datatype strategy, and the total time for the manual packing strategy, each in seconds.\n- The ratio $S = T_{\\mathrm{pack}} / T_{\\mathrm{dtype}}$, which is dimensionless.\n\nConstants shared across all test cases:\n- Element size $b = 8$ bytes.\n- Latency $\\alpha = 2.0 \\times 10^{-6}$ seconds.\n- Inverse bandwidth $\\beta = 1.0 \\times 10^{-10}$ seconds per byte.\n- Per-noncontiguous-block overhead $\\sigma = 5.0 \\times 10^{-9}$ seconds.\n- Per-element packing or unpacking time $\\gamma = 5.0 \\times 10^{-10}$ seconds.\n\nTest suite of parameter values $(M, N, m, w)$ to be used, where $r_0$ and $c_0$ are arbitrary and may be ignored as they do not affect the time under this model:\n- Case A: $(M, N, m, w) = (4096, 4096, 512, 64)$.\n- Case B: $(M, N, m, w) = (4096, 4096, 256, 4096)$.\n- Case C: $(M, N, m, w) = (4096, 4096, 4096, 1)$.\n- Case D: $(M, N, m, w) = (1024, 1024, 4, 4)$.\n- Case E: $(M, N, m, w) = (8192, 2048, 1024, 128)$.\n\nYour task is to write a complete, runnable program that, for each case, computes $S = T_{\\mathrm{pack}} / T_{\\mathrm{dtype}}$ according to the model above and produces a single line of output containing the results as a comma-separated list enclosed in square brackets. Each ratio must be rounded to exactly $6$ decimal places. The output must therefore have the form\n- $\\left[\\text{caseA},\\text{caseB},\\text{caseC},\\text{caseD},\\text{caseE}\\right]$\nwhere each placeholder is the rounded value of $S$ for the corresponding case. No physical units are to be printed for these dimensionless ratios.", "solution": "The task is to model the total time for two different communication strategies and compute their ratio. We will first derive the expressions for the total time for each strategy, $T_{\\mathrm{dtype}}$ and $T_{\\mathrm{pack}}$, based on the provided first-principles model.\n\nThe total number of elements to be communicated is $E = m \\cdot w$.\nThe total number of bytes is $B = E \\cdot b = m \\cdot w \\cdot b$.\n\nWe must distinguish between two scenarios for the data layout:\n1.  **Contiguous data**: This occurs when the width of the slice, $w$, is equal to the full width of the matrix, $N$. The slice consists of $m$ full rows, which form a single contiguous block of memory in a row-major layout.\n2.  **Non-contiguous data**: This occurs when $w < N$. The slice consists of $m$ separate blocks of data, each of size $w \\cdot b$ bytes.\n\nLet us analyze each strategy.\n\n**Strategy 1: Derived Datatype ($T_{\\mathrm{dtype}}$)**\nThis strategy involves creating a description of the non-contiguous memory layout and passing it to the communication subsystem, which then gathers the data directly.\n\n- **Non-contiguous case ($w < N$)**: The communication consists of one logical message send. The base time for transferring $B$ bytes is $\\alpha + \\beta B$. The problem states an additional overhead of $\\sigma$ for each of the $m$ non-contiguous blocks. The total time is therefore the sum of the latency, bandwidth-dependent transfer time, and the non-contiguity overhead.\n$$T_{\\mathrm{dtype}} = \\alpha + \\beta B + m \\sigma = \\alpha + \\beta (mwb) + m\\sigma$$\n\n- **Contiguous case ($w = N$)**: The problem specifies that a contiguous layout is treated as a single block with no non-contiguity overhead. The time is simply the standard latency-bandwidth cost.\n$$T_{\\mathrm{dtype}} = \\alpha + \\beta B = \\alpha + \\beta (mNb)$$\n\n**Strategy 2: Manual Packing ($T_{\\mathrm{pack}}$)**\nThis strategy involves three distinct stages: first, the sending process manually copies the non-contiguous data blocks into a single contiguous buffer; second, this buffer is sent; third, the receiving process copies the data from the contiguous buffer into the final non-contiguous destination.\n\n- **Non-contiguous case ($w < N$)**:\n    1.  **Packing**: The sender copies $E = m \\cdot w$ elements. At a cost of $\\gamma$ per element, this takes $E \\cdot \\gamma$ seconds.\n    2.  **Communication**: The resulting contiguous buffer of size $B$ bytes is sent, taking $\\alpha + \\beta B$ seconds.\n    3.  **Unpacking**: The receiver copies $E$ elements from the buffer. This also takes $E \\cdot \\gamma$ seconds.\nThe total time is the sum of these three stages. The cost $\\gamma$ applies to each element copy, both for packing and unpacking.\n$$T_{\\mathrm{pack}} = (E\\gamma) + (\\alpha + \\beta B) + (E\\gamma) = \\alpha + \\beta B + 2E\\gamma = \\alpha + \\beta (mwb) + 2(mw)\\gamma$$\n\n- **Contiguous case ($w = N$)**: The data is already in a single contiguous block. No packing or unpacking is required. The cost for these steps is zero. The communication proceeds as a standard contiguous transfer.\n$$T_{\\mathrm{pack}} = \\alpha + \\beta B = \\alpha + \\beta (mNb)$$\n\n**Ratio Calculation ($S$)**\nThe ratio $S$ is defined as $T_{\\mathrm{pack}} / T_{\\mathrm{dtype}}$.\n\n- **Contiguous case ($w = N$)**:\nIn this case, $T_{\\mathrm{pack}} = T_{\\mathrm{dtype}} = \\alpha + \\beta (mNb)$.\n$$S = \\frac{\\alpha + \\beta (mNb)}{\\alpha + \\beta (mNb)} = 1$$\n\n- **Non-contiguous case ($w < N$)**:\n$$S = \\frac{T_{\\mathrm{pack}}}{T_{\\mathrm{dtype}}} = \\frac{\\alpha + \\beta (mwb) + 2(mw)\\gamma}{\\alpha + \\beta (mwb) + m\\sigma}$$\n\nThis ratio determines which strategy is superior. If $S < 1$, manual packing is faster. If $S > 1$, the derived datatype is faster. The trade-off is between the per-block overhead of the derived datatype ($m\\sigma$) and the per-element copy overhead of manual packing ($2(mw)\\gamma$).\n\nWe now apply these formulas to the given test cases using the provided constants:\n$b = 8$, $\\alpha = 2.0 \\times 10^{-6}$, $\\beta = 1.0 \\times 10^{-10}$, $\\sigma = 5.0 \\times 10^{-9}$, $\\gamma = 5.0 \\times 10^{-10}$.\n\n- **Case A: $(M, N, m, w) = (4096, 4096, 512, 64)$**. Here, $w < N$. Non-contiguous.\n  $m=512$, $w=64$.\n  $S = \\frac{2 \\cdot 10^{-6} + (10^{-10} \\cdot 512 \\cdot 64 \\cdot 8) + 2(512 \\cdot 64) \\cdot 5 \\cdot 10^{-10}}{2 \\cdot 10^{-6} + (10^{-10} \\cdot 512 \\cdot 64 \\cdot 8) + 512 \\cdot 5 \\cdot 10^{-9}} \\approx 1.981596$\n\n- **Case B: $(M, N, m, w) = (4096, 4096, 256, 4096)$**. Here, $w = N$. Contiguous.\n  $S = 1.000000$\n\n- **Case C: $(M, N, m, w) = (4096, 4096, 4096, 1)$**. Here, $w < N$. Non-contiguous.\n  $m=4096$, $w=1$.\n  $S = \\frac{2 \\cdot 10^{-6} + (10^{-10} \\cdot 4096 \\cdot 1 \\cdot 8) + 2(4096 \\cdot 1) \\cdot 5 \\cdot 10^{-10}}{2 \\cdot 10^{-6} + (10^{-10} \\cdot 4096 \\cdot 1 \\cdot 8) + 4096 \\cdot 5 \\cdot 10^{-9}} \\approx 0.363900$\n\n- **Case D: $(M, N, m, w) = (1024, 1024, 4, 4)$**. Here, $w < N$. Non-contiguous.\n  $m=4$, $w=4$.\n  $S = \\frac{2 \\cdot 10^{-6} + (10^{-10} \\cdot 4 \\cdot 4 \\cdot 8) + 2(4 \\cdot 4) \\cdot 5 \\cdot 10^{-10}}{2 \\cdot 10^{-6} + (10^{-10} \\cdot 4 \\cdot 4 \\cdot 8) + 4 \\cdot 5 \\cdot 10^{-9}} \\approx 0.998032$\n\n- **Case E: $(M, N, m, w) = (8192, 2048, 1024, 128)$**. Here, $w < N$. Non-contiguous.\n  $m=1024$, $w=128$.\n  $S = \\frac{2 \\cdot 10^{-6} + (10^{-10} \\cdot 1024 \\cdot 128 \\cdot 8) + 2(1024 \\cdot 128) \\cdot 5 \\cdot 10^{-10}}{2 \\cdot 10^{-6} + (10^{-10} \\cdot 1024 \\cdot 128 \\cdot 8) + 1024 \\cdot 5 \\cdot 10^{-9}} \\approx 2.124978$\n\nThese results will be computed and formatted by the program.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\n# No imports are needed for this problem.\n\ndef solve():\n    \"\"\"\n    Calculates the performance ratio of manual packing vs. derived datatypes\n    for non-contiguous data transfer based on a latency-bandwidth model.\n    \"\"\"\n    \n    # Define the physical and model constants.\n    b = 8.0              # Element size in bytes\n    alpha = 2.0e-6       # Latency in seconds\n    beta = 1.0e-10       # Inverse bandwidth in seconds per byte\n    sigma = 5.0e-9       # Per-noncontiguous-block overhead in seconds\n    gamma = 5.0e-10      # Per-element packing or unpacking time in seconds\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple (M, N, m, w).\n    test_cases = [\n        (4096, 4096, 512, 64),    # Case A\n        (4096, 4096, 256, 4096),  # Case B\n        (4096, 4096, 4096, 1),     # Case C\n        (1024, 1024, 4, 4),        # Case D\n        (8192, 2048, 1024, 128),   # Case E\n    ]\n\n    results = []\n    for case in test_cases:\n        # Unpack parameters for clarity. M is not used in the model.\n        _M, N, m, w = case\n\n        # Check for the contiguous case where the slice width equals the matrix width.\n        if w == N:\n            # For contiguous data, both strategies are identical: a single\n            # contiguous transfer with no overhead. The ratio is 1.\n            S = 1.0\n        else:\n            # This is the non-contiguous case.\n            \n            # Calculate total elements and bytes.\n            E = m * w  # Total number of elements\n            B = E * b  # Total number of bytes\n\n            # Calculate the communication time for the derived-datatype strategy.\n            # T_dtype = latency + bandwidth_term + per_block_overhead\n            T_dtype = alpha + beta * B + m * sigma\n\n            # Calculate the communication time for the manual packing strategy.\n            # T_pack = pack_time + (latency + bandwidth_term) + unpack_time\n            # Total copy overhead is for both packing and unpacking.\n            T_pack = alpha + beta * B + 2 * E * gamma\n\n            # Compute the ratio S.\n            S = T_pack / T_dtype\n        \n        # Append the formatted result to the list.\n        # The value must be rounded and formatted to exactly 6 decimal places.\n        results.append(f\"{S:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2413742"}]}