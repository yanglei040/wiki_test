{"hands_on_practices": [{"introduction": "The quest for the \"best\" approximation often leads to surprising and elegant results. This first exercise delves into the core of minimax theory by asking for the best quadratic approximation to a specific cubic polynomial. By working through this problem, you will see a direct and beautiful application of the Chebyshev Equioscillation Theorem and uncover the fundamental role that Chebyshev polynomials play in defining optimal approximations. [@problem_id:2425564]", "problem": "Let $f(x)=4x^{3}-3x$ on the interval $[-1,1]$. Let $\\mathcal{P}_{2}$ denote the set of all real polynomials of degree at most $2$. With the uniform norm $\\|g\\|_{\\infty,[-1,1]}=\\max_{x\\in[-1,1]}|g(x)|$, determine the unique minimax quadratic approximant $p^{\\star}\\in\\mathcal{P}_{2}$ that minimizes $\\|f-p\\|_{\\infty,[-1,1]}$ over all $p\\in\\mathcal{P}_{2}$. Provide $p^{\\star}(x)$ explicitly as a simplified exact expression. Your final answer must be a single analytic expression.", "solution": "The problem statement must first be validated for scientific soundness, completeness, and objectivity.\n\n**Step 1: Extract Givens**\n- The function to be approximated is $f(x)=4x^{3}-3x$.\n- The interval of approximation is $[-1,1]$.\n- The space of approximating polynomials is $\\mathcal{P}_{2}$, the set of all real polynomials of degree at most $2$.\n- The norm for measuring the error is the uniform norm, $\\|g\\|_{\\infty,[-1,1]}=\\max_{x\\in[-1,1]}|g(x)|$.\n- The objective is to determine the unique minimax quadratic approximant $p^{\\star}\\in\\mathcal{P}_{2}$ that minimizes $\\|f-p\\|_{\\infty,[-1,1]}$ over all $p\\in\\mathcal{P}_{2}$.\n- The required output is an explicit, simplified exact expression for $p^{\\star}(x)$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, being a standard problem in approximation theory, a subfield of numerical analysis and computational engineering. It is well-posed; the existence and uniqueness of such a polynomial approximant are guaranteed by fundamental theorems. The problem is stated in objective, precise mathematical language without ambiguity or missing information. There are no contradictions or scientifically unsound premises.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\nThe problem asks for the best approximation of the function $f(x) = 4x^{3}-3x$ on the interval $[-1,1]$ by a polynomial $p(x)$ of degree at most $2$, in the sense of minimizing the maximum absolute error $\\|f - p\\|_{\\infty,[-1,1]}$. This is a classic minimax approximation problem.\n\nThe cornerstone for solving this problem is the Chebyshev Equioscillation Theorem. This theorem states that a polynomial $p^{\\star} \\in \\mathcal{P}_{n}$ is the unique best uniform approximation to a continuous function $f(x)$ on an interval $[a,b]$ if and only if the error function $e(x) = f(x) - p^{\\star}(x)$ exhibits at least $n+2$ points of equioscillation. That is, there must exist at least $n+2$ points $x_0  x_1  \\dots  x_{n+1}$ in $[a,b]$ such that $|e(x_i)| = \\|e\\|_{\\infty, [a,b]}$, and the sign of the error alternates, i.e., $e(x_i) = -e(x_{i+1})$ for $i=0, 1, \\dots, n$.\n\nIn this specific problem, the space of approximating polynomials is $\\mathcal{P}_{2}$, so the degree is at most $n=2$. The interval is $[-1,1]$. Therefore, we must find a polynomial $p^{\\star}(x) \\in \\mathcal{P}_2$ such that the error function $e(x) = f(x) - p^{\\star}(x)$ has at least $n+2 = 4$ points of equioscillation on $[-1,1]$.\n\nThe crucial first step is to recognize the function $f(x)$. The given function is $f(x) = 4x^{3}-3x$. This is the definition of the Chebyshev polynomial of the first kind of degree $3$, denoted as $T_3(x)$. So, we are tasked with finding the best quadratic approximation to $T_3(x)$ on $[-1,1]$.\n\nLet us examine the properties of $T_3(x)$. By definition, $T_n(x) = \\cos(n \\arccos(x))$. For $x \\in [-1,1]$, the value of $T_n(x)$ is bounded by $[-1,1]$. The extrema of $T_n(x)$ on $[-1,1]$ occur at the points $x_k = \\cos\\left(\\frac{k\\pi}{n}\\right)$ for $k = 0, 1, \\dots, n$. At these points, $T_n(x_k) = \\cos(k\\pi) = (-1)^k$.\n\nFor our function $f(x) = T_3(x)$, we have $n=3$. The extrema occur at $3+1=4$ points:\n$x_k = \\cos\\left(\\frac{k\\pi}{3}\\right)$ for $k = 0, 1, 2, 3$.\nLet's list these points and the corresponding values of $f(x)$:\n- For $k=0$: $x_0 = \\cos(0) = 1$. The function value is $f(1) = T_3(1) = (-1)^0 = 1$.\n- For $k=1$: $x_1 = \\cos\\left(\\frac{\\pi}{3}\\right) = \\frac{1}{2}$. The function value is $f\\left(\\frac{1}{2}\\right) = T_3\\left(\\frac{1}{2}\\right) = (-1)^1 = -1$.\n- For $k=2$: $x_2 = \\cos\\left(\\frac{2\\pi}{3}\\right) = -\\frac{1}{2}$. The function value is $f\\left(-\\frac{1}{2}\\right) = T_3\\left(-\\frac{1}{2}\\right) = (-1)^2 = 1$.\n- For $k=3$: $x_3 = \\cos(\\pi) = -1$. The function value is $f(-1) = T_3(-1) = (-1)^3 = -1$.\n\nLet us propose a candidate for the best approximating polynomial $p^{\\star}(x)$. A simple but logical choice is the zero polynomial, $p^{\\star}(x) = 0$. This polynomial is clearly an element of $\\mathcal{P}_2$.\n\nNow, we must verify if this choice satisfies the conditions of the Equioscillation Theorem. The error function is:\n$e(x) = f(x) - p^{\\star}(x) = (4x^{3}-3x) - 0 = 4x^{3}-3x = T_3(x)$.\n\nThe uniform norm of the error is:\n$\\|e\\|_{\\infty, [-1,1]} = \\|T_3\\|_{\\infty, [-1,1]} = \\max_{x \\in [-1,1]} |T_3(x)| = 1$.\n\nWe have identified four points in the interval $[-1,1]$, namely $\\{-1, -1/2, 1/2, 1\\}$, where the error function $|e(x)|$ attains this maximum value of $1$. The number of these points is $4$, which satisfies the requirement of being at least $n+2 = 2+2=4$.\n\nLet us check the alternating sign condition at these points, ordered as $x_3  x_2  x_1  x_0$:\n- $e(-1) = T_3(-1) = -1$\n- $e\\left(-\\frac{1}{2}\\right) = T_3\\left(-\\frac{1}{2}\\right) = 1$\n- $e\\left(\\frac{1}{2}\\right) = T_3\\left(\\frac{1}{2}\\right) = -1$\n- $e(1) = T_3(1) = 1$\n\nThe values of the error at these four points are $-1, 1, -1, 1$. They are equal in magnitude to the maximum error and alternate in sign.\n\nAll conditions of the Chebyshev Equioscillation Theorem are satisfied for $p^{\\star}(x)=0$ and $n=2$. Therefore, $p^{\\star}(x)=0$ is the unique minimax polynomial approximation of degree at most $2$ to $f(x)=4x^3-3x$ on the interval $[-1,1]$.", "answer": "$$\\boxed{0}$$", "id": "2425564"}, {"introduction": "While polynomials are versatile tools for approximation, they have inherent limitations. A skilled engineer knows when to choose a different tool for the job. This exercise challenges you to consider approximating the function $f(x) = \\tan(x)$, which features singularities that polynomials cannot model. You will compare the performance of minimax polynomials against rational functions (Padé approximants), providing critical insight into how to handle functions with more complex behavior. [@problem_id:2425551]", "problem": "Consider the function $f(x)=\\tan(x)$ on the symmetric interval $[-a,a]$ with $0a\\pi/2$. For a fixed nonnegative integer $n$, let $p_n^\\star$ denote a polynomial of degree at most $n$ that minimizes the uniform (maximum) approximation error $\\|f-p\\|_{\\infty,[-a,a]}=\\max_{|x|\\le a}|f(x)-p(x)|$ over all polynomials $p$ of degree at most $n$; such a $p_n^\\star$ is called a minimax polynomial. A rational function $R(x)=P(x)/Q(x)$ is called a Padé approximant of type $[L/M]$ about $x=0$ for $f$ if $Q(0)=1$ and the Maclaurin series of $R(x)-f(x)$ has vanishing coefficients up to and including the term in $x^{L+M}$.\n\nSelect all statements that are correct about approximating $\\tan(x)$ on $[-a,a]$ and about the ability of rational versus polynomial approximants to capture poles.\n\nA. The Padé approximant of type $[1/2]$ to $\\tan(x)$ about $x=0$ can be written as $R_{[1/2]}(x)=\\dfrac{x}{1-\\frac{x^2}{3}}$, and its Maclaurin series matches that of $\\tan(x)$ through order $x^3$.\n\nB. The function $R_{[1/2]}(x)=\\dfrac{x}{1-\\frac{x^2}{3}}$ has a simple real pole at $x=\\sqrt{3}$, which lies outside $[-a,a]$ whenever $a\\pi/2$.\n\nC. The Padé approximant of type $[1/1]$ to $\\tan(x)$ about $x=0$ is $R_{[1/1]}(x)=x$, so it introduces no pole.\n\nD. For any $0a\\pi/2$ and any finite degree $n$, the minimax polynomial $p_n^\\star$ on $[-a,a]$ can reproduce the vertical asymptote of $\\tan(x)$ at $x=\\pm\\pi/2$ within the interval, yielding zero maximum error.\n\nE. If a rational approximant $R(x)$ has a pole inside the chosen interval of approximation, then $\\max_{|x|\\le a}|\\tan(x)-R(x)|$ is infinite.\n\nF. On $[-a,a]$ with $0a\\pi/2$, the minimax polynomial $p_n^\\star$ of degree $n$ coincides with the degree-$n$ Taylor polynomial of $\\tan(x)$ about $x=0$.", "solution": "The problem statement submitted for analysis is well-posed and scientifically sound. I will first confirm its validity before proceeding to a full solution.\n\n**Problem Validation**\n\n**Step 1: Extract Givens**\n- The function to be approximated is $f(x) = \\tan(x)$.\n- The approximation interval is a symmetric interval $[-a, a]$, where the constant $a$ satisfies $0  a  \\pi/2$.\n- The minimax polynomial, denoted $p_n^\\star$, is defined as a polynomial of degree at most $n$ that minimizes the uniform norm of the error, $\\|f-p\\|_{\\infty,[-a,a]} = \\max_{|x|\\le a}|f(x)-p(x)|$.\n- A Padé approximant of type $[L/M]$ for a function $f(x)$ about $x=0$ is a rational function $R(x) = P(x)/Q(x)$ such that the degree of $P(x)$ is at most $L$, the degree of $Q(x)$ is at most $M$, $Q(0)=1$, and the Maclaurin series of $f(x) - R(x)$ begins with a power of $x$ greater than or equal to $L+M+1$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem statement is evaluated against the established criteria:\n- **Scientific Grounding:** The concepts of minimax polynomial approximation (best uniform approximation), Padé approximants, and Taylor series are fundamental and well-established in the field of numerical analysis and approximation theory. The function $\\tan(x)$ is a standard analytic function. The problem is scientifically and mathematically sound.\n- **Well-Posedness:** The function $f(x)=\\tan(x)$ is continuous and infinitely differentiable on the specified interval $[-a,a]$, as $a  \\pi/2$ ensures the interval does not contain any of the function's poles. The existence and uniqueness of the minimax polynomial for a continuous function on a closed, bounded interval is guaranteed by Chebyshev's approximation theorem. Padé approximants are uniquely determined for a given type $[L/M]$ for functions with a known Taylor series expansion, such as $\\tan(x)$. The problem is well-posed.\n- **Objectivity:** The problem statement and its definitions are precise, objective, and free from any subjective or ambiguous language.\n\n**Step 3: Verdict and Action**\nThe problem statement is declared **valid**. A rigorous solution will be developed by analyzing each option.\n\n**Solution Derivation and Option Analysis**\n\nThe Maclaurin series for $f(x) = \\tan(x)$ is required for the analysis. Since $\\tan(x)$ is an odd function, its series contains only odd powers of $x$:\n$$\n\\tan(x) = x + \\frac{1}{3}x^3 + \\frac{2}{15}x^5 + O(x^7)\n$$\n\n**Analysis of Option A**\nThe statement claims that the Padé approximant of type $[1/2]$ is $R_{[1/2]}(x)=\\dfrac{x}{1-\\frac{x^2}{3}}$ and that its Maclaurin series matches that of $\\tan(x)$ through order $x^3$.\n\nTo find the Padé approximant $R_{[1/2]}(x) = \\frac{P_1(x)}{Q_2(x)} = \\frac{p_0 + p_1 x}{1 + q_1 x + q_2 x^2}$, we enforce the condition $\\tan(x) Q_2(x) - P_1(x) = O(x^{1+2+1}) = O(x^4)$.\n$$\n\\left(x + \\frac{1}{3}x^3 + \\dots\\right)(1 + q_1 x + q_2 x^2) - (p_0 + p_1 x) = O(x^4)\n$$\nExpanding the product and collecting terms by powers of $x$:\n$$\n-p_0 + (1-p_1)x + q_1 x^2 + \\left(\\frac{1}{3} + q_2\\right)x^3 + \\dots = O(x^4)\n$$\nEquating coefficients to zero up to the term $x^3$:\n- Coefficient of $x^0$: $-p_0 = 0 \\implies p_0 = 0$.\n- Coefficient of $x^1$: $1 - p_1 = 0 \\implies p_1 = 1$.\n- Coefficient of $x^2$: $q_1 = 0$.\n- Coefficient of $x^3$: $\\frac{1}{3} + q_2 = 0 \\implies q_2 = -\\frac{1}{3}$.\n\nThis yields $P_1(x) = x$ and $Q_2(x) = 1 - \\frac{1}{3}x^2$. The Padé approximant is indeed $R_{[1/2]}(x) = \\frac{x}{1 - x^2/3}$.\nThe definition of the Padé approximant of type $[L/M]$ guarantees that its Maclaurin series matches that of the function through order $L+M$. For $[1/2]$, this is order $1+2=3$. We can verify this:\n$$\nR_{[1/2]}(x) = x\\left(1 - \\frac{x^2}{3}\\right)^{-1} = x\\left(1 + \\frac{x^2}{3} + \\left(\\frac{x^2}{3}\\right)^2 + \\dots\\right) = x + \\frac{x^3}{3} + \\frac{x^5}{9} + \\dots\n$$\nThe Maclaurin series for $\\tan(x)$ is $x + \\frac{x^3}{3} + \\frac{2x^5}{15} + \\dots$. The series match up to and including the $x^3$ term.\n\nVerdict: **Correct**.\n\n**Analysis of Option B**\nThe statement asserts that $R_{[1/2]}(x)=\\dfrac{x}{1-\\frac{x^2}{3}}$ has a simple real pole at $x=\\sqrt{3}$ and this pole lies outside $[-a, a]$ for $a  \\pi/2$.\n\nThe poles of $R_{[1/2]}(x)$ are the roots of the denominator:\n$$\n1 - \\frac{x^2}{3} = 0 \\implies x^2 = 3 \\implies x = \\pm\\sqrt{3}\n$$\nThese are indeed simple real poles. The statement focuses on $x=\\sqrt{3}$.\nWe must verify if this pole is outside the interval $[-a,a]$ for all $a \\in (0, \\pi/2)$. This is equivalent to checking if $\\sqrt{3}  a$ for all such $a$. Since the maximum possible value for $a$ is approached as $a \\to \\pi/2$, it suffices to check if $\\sqrt{3}  \\pi/2$.\nWe compare the squares of these two positive numbers:\n- $(\\sqrt{3})^2 = 3$.\n- $(\\pi/2)^2 = \\pi^2/4$. Using the approximation $\\pi \\approx 3.14159$, we get $\\pi^2 \\approx 9.8696$. Thus, $(\\pi/2)^2 \\approx 9.8696 / 4 \\approx 2.4674$.\nSince $3  2.4674$, it follows that $\\sqrt{3}  \\pi/2$.\nGiven that $a  \\pi/2$, we have $a  \\pi/2  \\sqrt{3}$. Therefore, the pole at $x=\\sqrt{3}$ (and also at $x=-\\sqrt{3}$) lies strictly outside the interval of approximation $[-a,a]$. This illustrates a primary advantage of rational approximation: the ability to model nearby singular behavior by placing poles just outside the approximation interval.\n\nVerdict: **Correct**.\n\n**Analysis of Option C**\nThe statement proposes that the Padé approximant of type $[1/1]$ is $R_{[1/1]}(x)=x$ and thus has no pole.\n\nLet $R_{[1/1]}(x) = \\frac{p_0 + p_1 x}{1 + q_1 x}$. The defining equation is $\\tan(x)(1+q_1 x) - (p_0 + p_1 x) = O(x^{1+1+1}) = O(x^3)$.\n$$\n\\left(x + \\frac{1}{3}x^3 + \\dots\\right)(1 + q_1 x) - (p_0 + p_1 x) = O(x^3)\n$$\n$$\n-p_0 + (1-p_1)x + q_1 x^2 + O(x^3) = O(x^3)\n$$\nEquating coefficients to zero up to the term $x^2$:\n- Coefficient of $x^0$: $-p_0 = 0 \\implies p_0 = 0$.\n- Coefficient of $x^1$: $1 - p_1 = 0 \\implies p_1 = 1$.\n- Coefficient of $x^2$: $q_1 = 0$.\nThe approximant is $R_{[1/1]}(x) = \\frac{x}{1} = x$. This is a polynomial of degree $1$. A polynomial has no poles in the finite complex plane. The statement is accurate.\n\nVerdict: **Correct**.\n\n**Analysis of Option D**\nThe statement claims a finite-degree polynomial $p_n^\\star$ can reproduce a vertical asymptote of $\\tan(x)$ and achieve zero error.\n\nThis statement is fundamentally flawed. A polynomial of any finite degree $n$, $p_n(x) = \\sum_{k=0}^n c_k x^k$, is an entire function, meaning it is defined and finite for all finite real (and complex) numbers. It cannot have a vertical asymptote, which is a locus where the function's magnitude tends to infinity.\nFurthermore, the asymptotes of $\\tan(x)$ occur at $x = \\pm\\pi/2$, which are explicitly excluded from the interval of approximation $[-a,a]$ since $a\\pi/2$.\nFinally, achieving zero maximum error, $\\|f-p_n^\\star\\|_{\\infty,[-a,a]}=0$, would imply that $p_n^\\star(x) = \\tan(x)$ for all $x \\in [-a,a]$. This is impossible, as $\\tan(x)$ is a transcendental function (its Maclaurin series has infinitely many non-zero coefficients), while $p_n^\\star(x)$ is a polynomial. A transcendental function cannot be identical to a polynomial over any interval.\n\nVerdict: **Incorrect**.\n\n**Analysis of Option E**\nThe statement posits that if a rational approximant $R(x)$ has a pole inside the approximation interval, the maximum approximation error is infinite.\n\nLet the interval be $I = [-a, a]$ where $0  a  \\pi/2$. On this interval, $f(x) = \\tan(x)$ is continuous and therefore bounded. Let $M = \\sup_{x \\in I} |\\tan(x)| = \\tan(a)$, which is finite.\nLet $R(x)$ be a rational approximant with a pole at $x_0 \\in I$. By definition of a pole, $\\lim_{x \\to x_0} |R(x)| = \\infty$.\nThe error at a point $x$ is $|\\tan(x) - R(x)|$. Using the reverse triangle inequality, we have:\n$$\n|\\tan(x) - R(x)| \\ge ||R(x)| - |\\tan(x)||\n$$\nAs $x \\to x_0$, $|R(x)| \\to \\infty$ while $|\\tan(x)|$ approaches the finite value $|\\tan(x_0)|$. Thus, the difference $|R(x)| - |\\tan(x)|$ approaches infinity, and so does the error $|\\tan(x) - R(x)|$.\nThe maximum error is the supremum of the error function over the interval:\n$$\n\\max_{|x| \\le a} |\\tan(x) - R(x)| = \\sup_{x \\in [-a,a]} |\\tan(x) - R(x)|\n$$\nSince the error function is unbounded at $x_0 \\in [-a,a]$, its supremum over the interval is infinite.\n\nVerdict: **Correct**.\n\n**Analysis of Option F**\nThe statement asserts that the minimax polynomial $p_n^\\star$ is identical to the degree-$n$ Taylor polynomial of $\\tan(x)$ about $x=0$.\n\nThis is generally false. The Taylor polynomial $T_n(x)$ is constructed to be the best polynomial approximation in an infinitesimal neighborhood of a single point (here, $x=0$). Its error, $f(x) - T_n(x)$, is of the highest possible order at that point.\nThe minimax polynomial $p_n^\\star(x)$ is constructed to minimize the maximum error across the entire interval $[-a,a]$. By the Chebyshev equioscillation theorem, the error function $f(x) - p_n^\\star(x)$ must exhibit a characteristic oscillatory behavior, attaining its maximum absolute value at a minimum of $n+2$ points in the interval, with alternating signs.\nThe error of the Taylor polynomial for $\\tan(x)$, which is $E_T(x) = \\tan(x) - T_n(x)$, does not generally possess this equioscillation property. For example, for $n=1$, $T_1(x) = x$, and the error is $\\tan(x) - x$. The derivative is $\\sec^2(x) - 1 = \\tan^2(x) \\ge 0$, so the error is monotonically increasing on $[0,a]$. It does not oscillate at all.\nThe coincidence of the minimax polynomial and the Taylor polynomial occurs only in special cases, none of which apply to the function $\\tan(x)$ on a general interval $[-a,a]$.\n\nVerdict: **Incorrect**.", "answer": "$$\\boxed{ABCE}$$", "id": "2425551"}, {"introduction": "Theory finds its true purpose when applied to solve tangible engineering challenges. In this practice, we move from analytical exercises to a realistic computational problem: predicting the remaining useful life (RUL) of a turbine blade. You will construct a polynomial model from a set of simulated data, but with a crucial twist—you must find the coefficients that minimize the maximum possible error. This requires translating the minimax approximation principle into a practical linear programming formulation, a powerful technique in any computational engineer's toolkit. [@problem_id:2425556]", "problem": "You are given a deterministic degradation law for the remaining useful life (RUL) of a turbine blade as a function of operating hours and load cycles. Let $h$ denote operating hours (in hours) and $c$ denote the number of high-stress cycles (dimensionless count). The true, unknown RUL function is modeled for this exercise by a known map $R(h,c)$ defined by\n$$\nR(h,c) \\;=\\; \\max\\!\\Big(0,\\; L_0 \\;-\\; \\alpha\\,h \\;-\\; \\beta\\,c \\;-\\; \\gamma\\,\\sqrt{h+1} \\;-\\; \\delta\\,h\\,c \\Big),\n$$\nwith constants $L_0 = 5000$, $\\alpha = 0.8$, $\\beta = 0.2$, $\\gamma = 30$, and $\\delta = 8\\times 10^{-5}$. The output $R(h,c)$ is in hours. All numbers above represent fixed scalars.\n\nYou must construct, for each specified case, a bivariate polynomial model of total degree at most $d$ in the normalized, dimensionless variables\n$$\nx \\;=\\; \\frac{h - h_{\\min}}{h_{\\max}-h_{\\min}}, \\qquad\ny \\;=\\; \\frac{c - c_{\\min}}{c_{\\max}-c_{\\min}},\n$$\nover a rectangular domain $[h_{\\min},h_{\\max}]\\times [c_{\\min},c_{\\max}]$, where $h_{\\min}$, $h_{\\max}$, $c_{\\min}$, $c_{\\max}$ are the case-specific bounds given below. The polynomial has the form\n$$\np(x,y) \\;=\\; \\sum_{\\substack{i,j\\ge 0\\\\ i+j\\le d}} a_{ij}\\,x^{i}\\,y^{j},\n$$\nwith real coefficients $a_{ij}$. For each case, determine the coefficients $\\{a_{ij}\\}$ that minimize the maximum absolute modeling error on a finite training set,\n$$\n\\min_{\\{a_{ij}\\}} \\; \\max_{(h_k,c_k)\\in \\mathcal{T}} \\; \\big|\\,p(x_k,y_k) \\;-\\; R(h_k,c_k)\\,\\big| ,\n$$\nwhere $\\mathcal{T}$ is the uniformly spaced training grid of size $N_h\\times N_c$ over the domain (grid includes endpoints), and $(x_k,y_k)$ are the normalized coordinates of $(h_k,c_k)$.\n\nFor evaluation, compute the maximum absolute error over a separate uniformly spaced validation grid $\\mathcal{V}$ of size $N_h^{\\mathrm{val}}\\times N_c^{\\mathrm{val}}$ on the same domain,\n$$\nE_{\\max} \\;=\\; \\max_{(h,c)\\in \\mathcal{V}} \\; \\big|\\,p(x,y) \\;-\\; R(h,c)\\,\\big| .\n$$\nReport $E_{\\max}$ in hours for each case.\n\nTest suite specification (each case provides $(d,\\;[h_{\\min},h_{\\max}],\\;[c_{\\min},c_{\\max}],\\;N_h\\times N_c,\\;N_h^{\\mathrm{val}}\\times N_c^{\\mathrm{val}})$):\n- Case $1$: $d=2$, $[0,2000]$, $[0,4000]$, $21\\times 21$, $41\\times 41$.\n- Case $2$: $d=1$, $[0,200]$, $[0,200]$, $11\\times 11$, $41\\times 41$.\n- Case $3$: $d=3$, $[0,3500]$, $[0,7000]$, $25\\times 25$, $51\\times 51$.\n- Case $4$: $d=2$, $[3000,4500]$, $[6000,9000]$, $15\\times 15$, $41\\times 41$.\n\nYour program must, for each case, compute the coefficients $\\{a_{ij}\\}$ that minimize the maximum absolute error on the training grid and then evaluate $E_{\\max}$ on the validation grid. The final outputs are the four validation maximum absolute errors, each expressed in hours as floating-point numbers rounded to three decimals.\n\nFinal output format: Your program should produce a single line containing the results as a comma-separated list enclosed in square brackets, for example $[e_1,e_2,e_3,e_4]$, where each $e_k$ is the rounded maximum absolute error (in hours) for Case $k$.", "solution": "The problem is valid. It is a well-posed, scientifically grounded problem in computational engineering, specifically in the area of function approximation using minimax principles. All necessary data and definitions are provided, and there are no internal contradictions or logical flaws.\n\nThe core task is to determine the coefficients $\\{a_{ij}\\}$ of a bivariate polynomial $p(x,y)$ that best approximates a given function $R(h,c)$ on a finite training set $\\mathcal{T}$. The criterion for \"best\" is the minimization of the maximum absolute error, which is an application of Chebyshev or $L_{\\infty}$ approximation. This minimax problem can be rigorously transformed into a linear programming (LP) problem.\n\nLet the bivariate polynomial of total degree at most $d$ be\n$$\np(x,y) = \\sum_{\\substack{i,j\\ge 0\\\\ i+j\\le d}} a_{ij}\\,x^{i}\\,y^{j}.\n$$\nFor computational purposes, we flatten the coefficients $\\{a_{ij}\\}$ into a single vector $\\boldsymbol{\\alpha}$ of length $N_{coeffs} = (d+1)(d+2)/2$. The polynomial can then be expressed as\n$$\np(x,y) = \\sum_{k=1}^{N_{coeffs}} \\alpha_k \\phi_k(x,y),\n$$\nwhere $\\{\\phi_k(x,y) = x^{i_k}y^{j_k}\\}$ is an ordered basis for the polynomial space. The problem is to find the coefficient vector $\\boldsymbol{\\alpha}$ that solves the optimization problem:\n$$\n\\min_{\\boldsymbol{\\alpha}} \\max_{(h_m,c_m)\\in\\mathcal{T}} |p(x_m,y_m) - R(h_m,c_m)|,\n$$\nwhere the index $m$ runs over the $M = N_h \\times N_c$ points in the training set $\\mathcal{T}$, and $(x_m, y_m)$ are the normalized coordinates corresponding to $(h_m,c_m)$.\n\nThis minimax problem is equivalent to finding the minimum value $\\epsilon$ for which a set of coefficients $\\boldsymbol{\\alpha}$ exists that satisfies\n$$\n|p(x_m,y_m) - R(h_m,c_m)| \\le \\epsilon, \\quad \\forall (h_m,c_m) \\in \\mathcal{T}.\n$$\nThe problem is thus reformulated as:\n$$\n\\min_{\\boldsymbol{\\alpha}, \\epsilon} \\epsilon\n$$\nsubject to the $2M$ linear inequalities:\n$$\n- \\epsilon \\le p(x_m,y_m) - R(h_m,c_m) \\le \\epsilon, \\quad \\text{for } m=1, \\dots, M.\n$$\nSubstituting the polynomial expression, these inequalities become:\n$$\n\\sum_{k=1}^{N_{coeffs}} \\alpha_k \\phi_k(x_m,y_m) - \\epsilon \\le R(h_m,c_m)\n$$\n$$\n-\\sum_{k=1}^{N_{coeffs}} \\alpha_k \\phi_k(x_m,y_m) - \\epsilon \\le -R(h_m,c_m)\n$$\nThis is a linear program for the unknown variables $\\mathbf{u} = [\\alpha_1, \\dots, \\alpha_{N_{coeffs}}, \\epsilon]^T$. In the standard form $\\min \\mathbf{c}^T\\mathbf{u}$ subject to $A_{ub}\\mathbf{u} \\le \\mathbf{b}_{ub}$, the components are:\n1.  The vector of unknowns $\\mathbf{u}$ has dimension $N_{coeffs}+1$. The coefficients $\\alpha_k$ are unbounded, while the error $\\epsilon$ must be non-negative.\n2.  The objective vector is $\\mathbf{c} = [0, \\dots, 0, 1]^T$, of dimension $N_{coeffs}+1$, to minimize $\\epsilon$.\n3.  Let $V$ be the $M \\times N_{coeffs}$ generalized Vandermonde matrix where $V_{mk} = \\phi_k(x_m, y_m)$. Let $\\mathbf{r}$ be the $M \\times 1$ vector where $r_m = R(h_m, c_m)$. The constraint matrix $A_{ub}$ of size $(2M) \\times (N_{coeffs}+1)$ and the vector $\\mathbf{b}_{ub}$ of size $2M$ are constructed as:\n$$\nA_{ub} = \\begin{pmatrix} V  -\\mathbf{1} \\\\ -V  -\\mathbf{1} \\end{pmatrix}, \\quad \\mathbf{b}_{ub} = \\begin{pmatrix} \\mathbf{r} \\\\ -\\mathbf{r} \\end{pmatrix},\n$$\nwhere $\\mathbf{1}$ is an $M \\times 1$ column vector of ones.\n\nThe computational procedure for each test case is as follows:\n1.  Define the case parameters: degree $d$, domain bounds $[h_{\\min}, h_{\\max}]$ and $[c_{\\min}, c_{\\max}]$, and grid sizes $N_h \\times N_c$ and $N_h^{\\mathrm{val}} \\times N_c^{\\mathrm{val}}$.\n2.  Generate the $M = N_h \\times N_c$ training points, normalize their coordinates, and evaluate the true function $R(h,c)$ to form the vector $\\mathbf{r}$.\n3.  Construct the polynomial basis and the corresponding Vandermonde matrix $V$.\n4.  Set up and solve the LP problem using a numerical solver, specifying that the coefficient variables $\\alpha_k$ are unbounded and the error variable $\\epsilon$ is non-negative. This yields the optimal coefficient vector $\\boldsymbol{\\alpha}^*$.\n5.  Construct the optimal polynomial $p^*(x,y)$ using $\\boldsymbol{\\alpha}^*$.\n6.  Generate the validation grid $\\mathcal{V}$ and evaluate the model error at each validation point.\n7.  The final result for the case, $E_{\\max}$, is the maximum absolute error found on the validation grid:\n$$\nE_{\\max} = \\max_{(h,c) \\in \\mathcal{V}} |p^*(x,y) - R(h,c)|.\n$$\nThis procedure is applied to all four specified cases to obtain the required validation errors.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import linprog\n\ndef solve():\n    \"\"\"\n    Solves the polynomial minimax approximation problem for a set of test cases.\n    \"\"\"\n    # Define problem constants for the RUL function\n    L0 = 5000.0\n    alpha = 0.8\n    beta = 0.2\n    gamma = 30.0\n    delta = 8e-5\n\n    def R(h, c):\n        \"\"\"\n        Calculates the true Remaining Useful Life (RUL) based on the given degradation law.\n        The function is vectorized to handle numpy arrays for h and c.\n        \"\"\"\n        val = L0 - alpha * h - beta * c - gamma * np.sqrt(h + 1.0) - delta * h * c\n        return np.maximum(0, val)\n\n    # Test suite specification\n    # Each case: (d, [h_min, h_max], [c_min, c_max], (N_h, N_c), (N_h_val, N_c_val))\n    test_cases = [\n        (2, [0.0, 2000.0], [0.0, 4000.0], (21, 21), (41, 41)),\n        (1, [0.0, 200.0], [0.0, 200.0], (11, 11), (41, 41)),\n        (3, [0.0, 3500.0], [0.0, 7000.0], (25, 25), (51, 51)),\n        (2, [3000.0, 4500.0], [6000.0, 9000.0], (15, 15), (41, 41)),\n    ]\n\n    results = []\n\n    for case in test_cases:\n        d, h_bounds, c_bounds, train_grid_size, val_grid_size = case\n        h_min, h_max = h_bounds\n        c_min, c_max = c_bounds\n        N_h, N_c = train_grid_size\n        N_h_val, N_c_val = val_grid_size\n\n        # 1. Generate polynomial basis exponents (i, j) for total degree = d\n        exponents = []\n        for total_degree in range(d + 1):\n            for i in range(total_degree + 1):\n                j = total_degree - i\n                exponents.append((i, j))\n        num_coeffs = len(exponents)\n\n        # 2. Generate training grid and evaluate the RUL function\n        h_train_pts = np.linspace(h_min, h_max, N_h)\n        c_train_pts = np.linspace(c_min, c_max, N_c)\n        h_train_grid, c_train_grid = np.meshgrid(h_train_pts, c_train_pts)\n        \n        h_train_flat = h_train_grid.flatten()\n        c_train_flat = c_train_grid.flatten()\n        num_train_pts = len(h_train_flat)\n\n        x_train_flat = (h_train_flat - h_min) / (h_max - h_min)\n        y_train_flat = (c_train_flat - c_min) / (c_max - c_min)\n        R_train_flat = R(h_train_flat, c_train_flat)\n\n        # 3. Construct the Linear Programming problem\n        # Generalized Vandermonde matrix V for training points\n        V_train = np.zeros((num_train_pts, num_coeffs))\n        for i, (p, q) in enumerate(exponents):\n            V_train[:, i] = x_train_flat**p * y_train_flat**q\n        \n        # LP objective: minimize epsilon (the last variable)\n        c_lp = np.zeros(num_coeffs + 1)\n        c_lp[num_coeffs] = 1.0\n\n        # LP inequality constraints matrix A_ub\n        A_ub = np.zeros((2 * num_train_pts, num_coeffs + 1))\n        A_ub[:num_train_pts, :num_coeffs] = V_train\n        A_ub[num_train_pts:, :num_coeffs] = -V_train\n        A_ub[:, -1] = -1.0\n\n        # LP inequality constraints vector b_ub\n        b_ub = np.concatenate([R_train_flat, -R_train_flat])\n        \n        # Bounds for variables: coefficients are unbounded, epsilon = 0\n        bounds = [(None, None)] * num_coeffs + [(0, None)]\n\n        # 4. Solve the LP problem\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        \n        coeffs = res.x[:num_coeffs]\n\n        # 5. Evaluate the obtained polynomial on the validation grid\n        h_val_pts = np.linspace(h_min, h_max, N_h_val)\n        c_val_pts = np.linspace(c_min, c_max, N_c_val)\n        h_val_grid, c_val_grid = np.meshgrid(h_val_pts, c_val_pts)\n        \n        h_val_flat = h_val_grid.flatten()\n        c_val_flat = c_val_grid.flatten()\n\n        x_val_flat = (h_val_flat - h_min) / (h_max - h_min)\n        y_val_flat = (c_val_flat - c_min) / (c_max - c_min)\n        R_val_flat = R(h_val_flat, c_val_flat)\n\n        # Vandermonde matrix for validation points\n        V_val = np.zeros((len(x_val_flat), num_coeffs))\n        for i, (p, q) in enumerate(exponents):\n            V_val[:, i] = x_val_flat**p * y_val_flat**q\n\n        # Predictions from the fitted polynomial\n        p_val = V_val @ coeffs\n        \n        # Compute maximum absolute error on the validation set\n        E_max = np.max(np.abs(p_val - R_val_flat))\n        \n        results.append(round(E_max, 3))\n\n    # Print the final results in the required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2425556"}]}