{"hands_on_practices": [{"introduction": "To truly grasp how penalty methods transform a constrained problem into a sequence of unconstrained ones, there is no substitute for building a solver yourself. This practice guides you through implementing a sequential quadratic penalty method, focusing on a crucial practical technique known as 'warm-starting'. By comparing the performance of cold-starting versus warm-starting the subproblems, you will experimentally verify the significant computational savings that make sequential methods efficient in practice [@problem_id:2423453].", "problem": "You are asked to implement a sequential quadratic penalty method for constrained optimization and to experimentally quantify the benefit of warm-starting by reusing the previous subproblem’s solution as the initial guess for the next penalty parameter. Implement a gradient-based solver with a backtracking Armijo line search to minimize a sequence of unconstrained penalized subproblems. For a fixed sequence of penalty parameters $\\{\\rho_k\\}_{k=1}^K$ with $\\rho_1  \\rho_2  \\dots  \\rho_K$, compare two strategies for each test case: (i) cold-starting each subproblem from the same initial point, and (ii) warm-starting subproblem $k+1$ from the computed minimizer of subproblem $k$. Report the speedup factor defined as the ratio of the total number of gradient descent iterations taken by cold-starting to that taken by warm-starting across the full penalty sequence.\n\nFundamental base and definitions to use:\n- A constrained minimization problem has objective $f:\\mathbb{R}^n\\to\\mathbb{R}$, inequality constraints $g_i(x)\\le 0$ for $i\\in\\{1,\\dots,m\\}$, and equality constraints $h_j(x)=0$ for $j\\in\\{1,\\dots,p\\}$.\n- The classical quadratic penalty for inequalities is applied to the violation as $\\max\\{0, g_i(x)\\}^2$ and for equalities as $h_j(x)^2$.\n- The penalized subproblem for a given $\\rho0$ is to minimize \n$$\n\\Phi_\\rho(x)=f(x)+\\rho\\left(\\sum_{i=1}^m \\max\\{0,g_i(x)\\}^2+\\sum_{j=1}^p h_j(x)^2\\right).\n$$\n- Use gradient descent with a backtracking Armijo rule: given current $x$, gradient $\\nabla\\Phi_\\rho(x)$, initial step size $t_0$, shrinkage factor $\\beta\\in(0,1)$, and Armijo parameter $c\\in(0,1)$, choose the largest $t$ from the sequence $\\{t_0, \\beta t_0, \\beta^2 t_0,\\dots\\}$ satisfying\n$$\n\\Phi_\\rho(x - t \\nabla \\Phi_\\rho(x)) \\le \\Phi_\\rho(x) - c\\,t\\,\\|\\nabla \\Phi_\\rho(x)\\|_2^2.\n$$\n- Stop the inner solver when $\\|\\nabla \\Phi_\\rho(x)\\|_2\\le \\varepsilon$.\n\nImplementation requirements:\n- Implement the quadratic penalty method and gradient descent with backtracking Armijo line search exactly as defined above.\n- For inequality constraints, treat only the positive violation by using the $\\max\\{0,\\cdot\\}$ structure in both the penalty value and its gradient. For equality constraints, penalize the squared residual.\n- Use the penalty sequence $\\rho \\in \\{10, 100, 1000\\}$.\n- Use gradient tolerance $\\varepsilon=10^{-6}$, Armijo parameter $c=10^{-4}$, shrinkage factor $\\beta=\\frac{1}{2}$, and initial step size $t_0=1$ for all subproblems. Cap the maximum number of gradient iterations per subproblem at $N_{\\max}=10^4$.\n- Count the number of outer gradient descent iterations (each accepted step after line search) taken to converge a subproblem; do not count line search backtracking steps separately.\n\nTest suite:\nImplement and solve the following three two-dimensional test cases. In each case, return the speedup factor\n$$\nS=\\frac{N_{\\mathrm{cold}}}{N_{\\mathrm{warm}}},\n$$\nwhere $N_{\\mathrm{cold}}$ is the total number of gradient descent iterations summed over all penalty parameters when cold-starting each subproblem from the specified initial point, and $N_{\\mathrm{warm}}$ is the total when warm-starting each subproblem from the previous subproblem’s solution.\n\n- Case $\\mathbf{A}$ (convex quadratic with a binding linear inequality):\n  - Objective: $f(x,y)=(x-1)^2+2\\,(y+2)^2$.\n  - Inequality: $g_1(x,y)=1-x-y\\le 0$.\n  - No equalities.\n  - Initial point: $x_0=(0,0)$.\n\n- Case $\\mathbf{B}$ (convex quadratic with an equality):\n  - Objective: $f(x,y)=(x-3)^2+(y-1)^2$.\n  - Equality: $h_1(x,y)=x-y=0$.\n  - No inequalities.\n  - Initial point: $x_0=(0,0)$.\n\n- Case $\\mathbf{C}$ (convex quadratic with a curved inequality):\n  - Objective: $f(x,y)=(x+2)^2+y^2$.\n  - Inequality: $g_1(x,y)=x^2+y^2-1\\le 0$.\n  - No equalities.\n  - Initial point: $x_0=(0,0)$.\n\nOutput specification:\n- For each case, compute the speedup factor $S$ as defined above.\n- Your program should produce a single line of output containing the three speedup factors as a comma-separated list enclosed in square brackets, in the order $\\left[S_A,S_B,S_C\\right]$, where $S_A$ corresponds to Case $\\mathbf{A}$, $S_B$ to Case $\\mathbf{B}$, and $S_C$ to Case $\\mathbf{C}$. For example, output of the form $\\left[\\text{result}_1,\\text{result}_2,\\text{result}_3\\right]$ with numeric values.\n- Express each speedup factor as a floating-point number. You may round internally, but the printed values must be standard decimal floats.\n\nNo physical units are involved. Angles are not used. Percentages are not used.\n\nThe final program must be self-contained, require no input, and adhere to the specified runtime environment. The correctness will be assessed by verifying that the implementation follows the definitions and that warm-starting yields strictly fewer iterations or at least not more, producing meaningful speedup factors for the specified cases. The output must be exactly one line in the specified format.", "solution": "The problem requires the implementation of a sequential quadratic penalty method to solve constrained optimization problems. The core of the task is to compare the computational efficiency of two initialization strategies for the sequence of unconstrained subproblems: a cold-start strategy versus a warm-start strategy. The efficiency is to be quantified by a speedup factor, defined as the ratio of total gradient descent iterations.\n\nThe general form of the constrained optimization problem is to minimize an objective function $f(x)$ subject to a set of inequality constraints $g_i(x) \\le 0$ for $i \\in \\{1, \\dots, m\\}$ and equality constraints $h_j(x) = 0$ for $j \\in \\{1, \\dots, p\\}$, where $x \\in \\mathbb{R}^n$.\n\nThe quadratic penalty method approximates the solution to this problem by solving a sequence of unconstrained minimization problems. For a given penalty parameter $\\rho > 0$, the penalized objective function $\\Phi_\\rho(x)$ is constructed by adding terms to the original objective function that penalize violations of the constraints. The specific form of the penalized function is:\n$$\n\\Phi_\\rho(x) = f(x) + \\rho \\left( \\sum_{i=1}^m \\left(\\max\\{0, g_i(x)\\}\\right)^2 + \\sum_{j=1}^p \\left(h_j(x)\\right)^2 \\right)\n$$\nThis function, $\\Phi_\\rho(x)$, is then minimized with respect to $x$. By solving this unconstrained problem for a sequence of increasing penalty parameters, $\\rho_1  \\rho_2  \\dots  \\rho_K$, the sequence of minimizers $x^*(\\rho_k)$ converges to the solution of the original constrained problem.\n\nTo minimize each unconstrained subproblem $\\min_x \\Phi_\\rho(x)$, a gradient-based method is required. The gradient of the penalized objective function, $\\nabla \\Phi_\\rho(x)$, is derived using the chain rule. For an inequality constraint term $P_i(x) = \\rho (\\max\\{0, g_i(x)\\})^2$, the gradient is $\\nabla P_i(x) = 2 \\rho \\max\\{0, g_i(x)\\} \\nabla g_i(x)$. For an equality constraint term $Q_j(x) = \\rho (h_j(x))^2$, the gradient is $\\nabla Q_j(x) = 2 \\rho h_j(x) \\nabla h_j(x)$. Combining these with the gradient of the objective function, the full gradient is:\n$$\n\\nabla \\Phi_\\rho(x) = \\nabla f(x) + 2\\rho \\left( \\sum_{i=1}^m \\max\\{0, g_i(x)\\} \\nabla g_i(x) + \\sum_{j=1}^p h_j(x) \\nabla h_j(x) \\right)\n$$\nThe unconstrained minimization is performed using gradient descent. Starting from a point $x_k$, the next point $x_{k+1}$ is found by moving in the direction of the negative gradient:\n$$\nx_{k+1} = x_k - t \\nabla \\Phi_\\rho(x_k)\n$$\nThe step size $t > 0$ is determined by a backtracking line search employing the Armijo condition. For a given descent direction $d_k = -\\nabla \\Phi_\\rho(x_k)$, we seek the largest $t$ from the sequence $\\{t_0, \\beta t_0, \\beta^2 t_0, \\dots\\}$ that satisfies:\n$$\n\\Phi_\\rho(x_k + t d_k) \\le \\Phi_\\rho(x_k) + c \\, t \\, \\nabla \\Phi_\\rho(x_k)^T d_k\n$$\nwhich, using $d_k = -\\nabla \\Phi_\\rho(x_k)$, simplifies to the form given in the problem statement:\n$$\n\\Phi_\\rho(x_k - t \\nabla \\Phi_\\rho(x_k)) \\le \\Phi_\\rho(x_k) - c \\, t \\, \\|\\nabla \\Phi_\\rho(x_k)\\|_2^2\n$$\nThe algorithm iterates until the norm of the gradient is below a specified tolerance $\\varepsilon$, i.e., $\\|\\nabla \\Phi_\\rho(x)\\|_2 \\le \\varepsilon$. The parameters for this solver are fixed: initial step size $t_0=1$, Armijo parameter $c=10^{-4}$, shrinkage factor $\\beta=0.5$, and gradient norm tolerance $\\varepsilon=10^{-6}$. The maximum number of iterations per subproblem is capped at $N_{\\max}=10^4$.\n\nThe experiment compares two strategies over the penalty parameter sequence $\\rho \\in \\{10, 100, 1000\\}$:\n1.  **Cold-Start:** Each subproblem for $\\rho_k$ is initialized from the same starting point $x_0$. The total number of iterations, $N_{\\mathrm{cold}}$, is the sum of iterations required to solve each subproblem independently.\n2.  **Warm-Start:** The first subproblem (for $\\rho_1=10$) is initialized from $x_0$. The subproblem for each subsequent $\\rho_{k+1}$ is initialized using the solution obtained from the previous subproblem for $\\rho_k$. The total number of iterations, $N_{\\mathrm{warm}}$, is the sum of iterations across this sequence.\n\nThe rationale for warm-starting is that the solution $x^*(\\rho_k)$ is expected to be a good initial guess for the minimizer of $\\Phi_{\\rho_{k+1}}(x)$, especially when $\\rho_{k+1}$ is not drastically larger than $\\rho_k$. This should lead to faster convergence. The performance gain is measured by the speedup factor $S = N_{\\mathrm{cold}} / N_{\\mathrm{warm}}$.\n\nThe implementation will proceed by defining Python functions for each test case's objective and constraint functions and their respective gradients. A generalized solver function will execute the gradient descent with Armijo line search. A top-level function will manage the sequence of penalty parameters, apply both cold-start and warm-start strategies, count the total iterations for each, and compute the speedup. This process will be repeated for all three test cases provided.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the specified test cases and print the results.\n    \"\"\"\n    \n    # --- Solver Parameters ---\n    SOLVER_PARAMS = {\n        'epsilon': 1e-6,\n        'c_armijo': 1e-4,\n        'beta': 0.5,\n        't0': 1.0,\n        'n_max': 10000\n    }\n    PENALTY_PARAMS = [10.0, 100.0, 1000.0]\n\n    # --- Test Case Definitions ---\n    \n    # Case A: (x-1)^2 + 2(y+2)^2, s.t. 1-x-y = 0\n    case_A = {\n        'f': lambda x: (x[0] - 1.0)**2 + 2.0 * (x[1] + 2.0)**2,\n        'grad_f': lambda x: np.array([2.0 * (x[0] - 1.0), 4.0 * (x[1] + 2.0)]),\n        'g': [lambda x: 1.0 - x[0] - x[1]],\n        'grad_g': [lambda x: np.array([-1.0, -1.0])],\n        'h': [],\n        'grad_h': [],\n        'x0': np.array([0.0, 0.0])\n    }\n\n    # Case B: (x-3)^2 + (y-1)^2, s.t. x-y = 0\n    case_B = {\n        'f': lambda x: (x[0] - 3.0)**2 + (x[1] - 1.0)**2,\n        'grad_f': lambda x: np.array([2.0 * (x[0] - 3.0), 2.0 * (x[1] - 1.0)]),\n        'g': [],\n        'grad_g': [],\n        'h': [lambda x: x[0] - x[1]],\n        'grad_h': [lambda x: np.array([1.0, -1.0])],\n        'x0': np.array([0.0, 0.0])\n    }\n    \n    # Case C: (x+2)^2 + y^2, s.t. x^2+y^2-1 = 0\n    case_C = {\n        'f': lambda x: (x[0] + 2.0)**2 + x[1]**2,\n        'grad_f': lambda x: np.array([2.0 * (x[0] + 2.0), 2.0 * x[1]]),\n        'g': [lambda x: x[0]**2 + x[1]**2 - 1.0],\n        'grad_g': [lambda x: np.array([2.0 * x[0], 2.0 * x[1]])],\n        'h': [],\n        'grad_h': [],\n        'x0': np.array([0.0, 0.0])\n    }\n\n    test_cases = [case_A, case_B, case_C]\n    \n    def get_penalized_funcs(case, rho):\n        \"\"\"Creates the penalized function and its gradient for a given case and rho.\"\"\"\n        \n        def phi(x):\n            f_val = case['f'](x)\n            g_sum = sum(max(0, g_func(x))**2 for g_func in case['g'])\n            h_sum = sum(h_func(x)**2 for h_func in case['h'])\n            return f_val + rho * (g_sum + h_sum)\n\n        def grad_phi(x):\n            grad_f_val = case['grad_f'](x)\n            \n            grad_g_sum = np.zeros_like(x)\n            for g_func, grad_g_func in zip(case['g'], case['grad_g']):\n                g_val = g_func(x)\n                if g_val  0:\n                    grad_g_sum += 2.0 * g_val * grad_g_func(x)\n\n            grad_h_sum = np.zeros_like(x)\n            for h_func, grad_h_func in zip(case['h'], case['grad_h']):\n                h_val = h_func(x)\n                grad_h_sum += 2.0 * h_val * grad_h_func(x)\n                \n            return grad_f_val + rho * (grad_g_sum + grad_h_sum)\n        \n        return phi, grad_phi\n\n    def gradient_descent(phi, grad_phi, x_init, params):\n        \"\"\"\n        Performs gradient descent with backtracking Armijo line search.\n        \"\"\"\n        x = np.copy(x_init)\n        n_iters = 0\n        \n        for k in range(params['n_max']):\n            grad = grad_phi(x)\n            grad_norm_sq = np.dot(grad, grad)\n\n            if np.sqrt(grad_norm_sq) = params['epsilon']:\n                break\n            \n            # Backtracking line search\n            t = params['t0']\n            phi_x = phi(x)\n            \n            while True:\n                x_new = x - t * grad\n                phi_new = phi(x_new)\n                armijo_check = phi_x - params['c_armijo'] * t * grad_norm_sq\n                \n                if phi_new = armijo_check:\n                    break\n                t *= params['beta']\n            \n            x = x_new\n            n_iters += 1\n        \n        return x, n_iters\n\n    def run_penalty_method(case, solver_params, penalty_params):\n        \"\"\"\n        Runs the full sequential penalty method for a case,\n        calculating iterations for both cold and warm starts.\n        \"\"\"\n        # Cold start\n        total_iters_cold = 0\n        for rho in penalty_params:\n            phi, grad_phi = get_penalized_funcs(case, rho)\n            _, n_iters = gradient_descent(phi, grad_phi, case['x0'], solver_params)\n            total_iters_cold += n_iters\n            \n        # Warm start\n        total_iters_warm = 0\n        x_warm = np.copy(case['x0'])\n        for rho in penalty_params:\n            phi, grad_phi = get_penalized_funcs(case, rho)\n            x_sol, n_iters = gradient_descent(phi, grad_phi, x_warm, solver_params)\n            total_iters_warm += n_iters\n            x_warm = x_sol\n            \n        if total_iters_warm == 0:\n             # This case should not happen in this problem, but is a safeguard.\n             # If cold is also 0, speedup is 1. If cold  0, speedup is \"infinite\".\n            return 1.0 if total_iters_cold == 0 else float('inf')\n            \n        return float(total_iters_cold) / float(total_iters_warm)\n\n    results = []\n    for case in test_cases:\n        speedup = run_penalty_method(case, SOLVER_PARAMS, PENALTY_PARAMS)\n        results.append(speedup)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2423453"}, {"introduction": "In contrast to exterior penalty methods, barrier methods ensure that all iterates remain strictly inside the feasible region. This exercise moves from numerical implementation to analytical derivation, allowing you to see the inner workings of a logarithmic barrier function with full clarity. By deriving the exact minimizer $x(\\rho)$ for a simple one-dimensional problem, you will gain direct insight into how the barrier parameter $\\rho$ controls the solution's path along the central trajectory and determines when a constraint becomes 'active' [@problem_id:2423438].", "problem": "You are given a scalar constrained optimization problem designed to illustrate how a constraint can transition from inactive (strictly satisfied) to active (approximately binding) as a tunable parameter is sequentially increased within a barrier method framework. Consider the convex optimization problem of minimizing a smooth objective subject to a single inequality constraint. Let the objective be $f(x) = (x - 2)^2$ and the inequality constraint be $c(x) = x - 1 \\le 0$ (equivalently, $x \\le 1$). To enforce the constraint via a logarithmic barrier, consider the barrier-augmented objective\n$$\n\\psi_{\\rho}(x) = \\rho\\, f(x) - \\log(1 - x),\n$$\ndefined on the open domain $x  1$, where $\\rho  0$ is a tunable weighting parameter. The barrier term $-\\log(1 - x)$ encodes the constraint $x \\le 1$ and ensures iterates remain strictly feasible. As $\\rho$ is increased sequentially, the barrier influence diminishes relative to $f(x)$, and the minimizer of $\\psi_{\\rho}$ approaches the boundary where the constraint becomes active in the sense of approximate equality.\n\nStarting from fundamental principles (first-order optimality conditions for unconstrained minimization over the open domain $x  1$ and properties of convexity), derive the unique minimizer $x(\\rho)$ for $\\rho  0$ in closed form and use it to detect when the constraint is “active” in the approximate sense. Define the slack $s(\\rho) = 1 - x(\\rho)$. For a given tolerance $\\tau  0$, say that the constraint is active if $s(\\rho) \\le \\tau$ and inactive if $s(\\rho)  \\tau$.\n\nYour task is to write a complete, runnable program that:\n- Uses the derived closed-form $x(\\rho)$ to evaluate $s(\\rho)$ for each test value of $\\rho$ in the test suite.\n- Compares $s(\\rho)$ against a fixed tolerance $\\tau$ to produce an activity indicator: output $1$ if the constraint is active and $0$ otherwise.\n\nFundamental base you may use: first-order necessary and sufficient conditions for convex smooth minimization (vanishing gradient characterizes the minimizer on the open domain), the definition of the logarithmic barrier for an inequality constraint $x \\le 1$, and basic algebra to solve the resulting optimality equation.\n\nTest suite:\n- Barrier weights $\\rho \\in \\{0.1, 1, 10, 50, 100\\}$.\n- Tolerance $\\tau = 0.01$.\n\nFinal output format:\n- Your program should produce a single line of output containing the activity results for the test suite as a comma-separated list of integers enclosed in square brackets, in the same order as the given $\\rho$ values. For example, an output could look like $[0,1,1,1,1]$ but with the correct results for this problem.\n\nNo physical units are involved in this problem. Angles are not used. Percentages are not used; when comparing to the tolerance $\\tau$, all values are pure real numbers. The answer for each test case must be an integer in $\\{0,1\\}$, and the program must aggregate these into a single list as specified.", "solution": "The problem presented is a well-posed exercise in constrained optimization, specifically illustrating the mechanics of a logarithmic barrier method. Its components are mathematically precise, scientifically grounded in the principles of convex optimization, and constitute a complete and consistent setup. The problem is therefore deemed valid. We shall proceed with its formal solution.\n\nThe task is to find the unique minimizer of the barrier-augmented objective function $\\psi_{\\rho}(x)$ for a given parameter $\\rho > 0$, where\n$$\n\\psi_{\\rho}(x) = \\rho f(x) - \\log(1 - x)\n$$\nwith the objective $f(x) = (x - 2)^2$. The domain of definition is the open interval $(-\\infty, 1)$, which enforces strict satisfaction of the constraint $x - 1  0$.\n\nThe function $\\psi_{\\rho}(x)$ is the sum of two functions: $\\rho(x-2)^2$ and $-\\log(1-x)$. The first term, being a scaled quadratic with a positive leading coefficient since $\\rho > 0$, is a convex function. The second term, the logarithmic barrier, is also convex on its domain $x  1$. The sum of convex functions is convex. To demonstrate strict convexity, we examine the second derivative.\n\nThe first derivative of $\\psi_{\\rho}(x)$ with respect to $x$ is:\n$$\n\\frac{d\\psi_{\\rho}}{dx} = \\frac{d}{dx} \\left[ \\rho (x - 2)^2 - \\log(1 - x) \\right] = 2\\rho(x - 2) - \\frac{-1}{1 - x} = 2\\rho(x - 2) + \\frac{1}{1 - x}.\n$$\nThe second derivative is:\n$$\n\\frac{d^2\\psi_{\\rho}}{dx^2} = \\frac{d}{dx} \\left[ 2\\rho(x - 2) + (1 - x)^{-1} \\right] = 2\\rho + (-1)(1 - x)^{-2}(-1) = 2\\rho + \\frac{1}{(1 - x)^2}.\n$$\nFor any $\\rho > 0$ and any $x$ in the domain $x  1$, both terms $2\\rho$ and $\\frac{1}{(1 - x)^2}$ are strictly positive. Therefore, $\\frac{d^2\\psi_{\\rho}}{dx^2} > 0$ for all $x  1$, which confirms that $\\psi_{\\rho}(x)$ is a strictly convex function on its domain.\n\nFor a strictly convex and differentiable function on an open set, the first-order necessary condition for a minimum, that the gradient (in this scalar case, the derivative) vanishes, is also a sufficient condition. Thus, the unique minimizer $x(\\rho)$ is found by solving the equation $\\frac{d\\psi_{\\rho}}{dx} = 0$:\n$$\n2\\rho(x - 2) + \\frac{1}{1 - x} = 0.\n$$\nTo solve for $x$, we first clear the denominator by multiplying by $(1 - x)$, which is non-zero in the domain:\n$$\n2\\rho(x - 2)(1 - x) + 1 = 0\n$$\n$$\n2\\rho(x - x^2 - 2 + 2x) + 1 = 0\n$$\n$$\n2\\rho(-x^2 + 3x - 2) + 1 = 0\n$$\n$$\n-2\\rho x^2 + 6\\rho x - 4\\rho + 1 = 0.\n$$\nThis is a quadratic equation of the form $ax^2 + bx + c = 0$, with coefficients $a = 2\\rho$, $b = -6\\rho$, and $c = 4\\rho - 1$. We apply the quadratic formula to find the roots:\n$$\nx = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} = \\frac{6\\rho \\pm \\sqrt{(-6\\rho)^2 - 4(2\\rho)(4\\rho - 1)}}{2(2\\rho)}\n$$\n$$\nx = \\frac{6\\rho \\pm \\sqrt{36\\rho^2 - 8\\rho(4\\rho - 1)}}{4\\rho} = \\frac{6\\rho \\pm \\sqrt{36\\rho^2 - 32\\rho^2 + 8\\rho}}{4\\rho}\n$$\n$$\nx = \\frac{6\\rho \\pm \\sqrt{4\\rho^2 + 8\\rho}}{4\\rho} = \\frac{6\\rho \\pm 2\\sqrt{\\rho^2 + 2\\rho}}{4\\rho} = \\frac{3\\rho \\pm \\sqrt{\\rho^2 + 2\\rho}}{2\\rho}.\n$$\nThis gives two potential solutions. We must select the one that respects the domain constraint $x  1$.\nConsider the root with the plus sign:\n$x_1 = \\frac{3\\rho + \\sqrt{\\rho^2 + 2\\rho}}{2\\rho}$. Since $\\rho > 0$, we have $\\sqrt{\\rho^2 + 2\\rho} > \\sqrt{\\rho^2} = \\rho$. Thus, the numerator is greater than $3\\rho + \\rho = 4\\rho$, and $x_1 > \\frac{4\\rho}{2\\rho} = 2$. This root is invalid as it lies outside the domain $x  1$.\n\nConsider the root with the minus sign:\n$x_2 = \\frac{3\\rho - \\sqrt{\\rho^2 + 2\\rho}}{2\\rho}$. Since $\\rho  \\sqrt{\\rho^2 + 2\\rho}$, the numerator is $3\\rho - \\sqrt{\\rho^2 + 2\\rho}  3\\rho - \\rho = 2\\rho$. Therefore, $x_2  \\frac{2\\rho}{2\\rho} = 1$. This root is always within the feasible domain.\nThe unique minimizer is thus given by the closed-form expression:\n$$\nx(\\rho) = \\frac{3\\rho - \\sqrt{\\rho^2 + 2\\rho}}{2\\rho}.\n$$\nThe problem defines the slack variable as $s(\\rho) = 1 - x(\\rho)$. Substituting the expression for $x(\\rho)$:\n$$\ns(\\rho) = 1 - \\left( \\frac{3\\rho - \\sqrt{\\rho^2 + 2\\rho}}{2\\rho} \\right) = \\frac{2\\rho - (3\\rho - \\sqrt{\\rho^2 + 2\\rho})}{2\\rho} = \\frac{\\sqrt{\\rho^2 + 2\\rho} - \\rho}{2\\rho}.\n$$\nThe constraint is defined as \"active\" if $s(\\rho) \\le \\tau$ and \"inactive\" otherwise. With $\\tau = 0.01$, we must evaluate this condition for each given value of $\\rho$. The program will implement this logic.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the constrained optimization problem using a logarithmic barrier method\n    and determines constraint activity for a suite of test cases.\n    \"\"\"\n    # The test suite consists of a set of barrier weights `rho`\n    # and a fixed tolerance `tau`.\n    test_cases = {\n        \"rho_values\": [0.1, 1, 10, 50, 100],\n        \"tau\": 0.01\n    }\n\n    rho_values = test_cases[\"rho_values\"]\n    tau = test_cases[\"tau\"]\n\n    results = []\n\n    # For each barrier weight `rho`, calculate the slack and determine if the\n    # constraint is active.\n    for rho in rho_values:\n        # The minimizer x(rho) of the barrier-augmented objective is derived from\n        # the first-order optimality condition d/dx [rho*(x-2)^2 - log(1-x)] = 0.\n        # This leads to the quadratic equation 2*rho*x^2 - 6*rho*x + (4*rho - 1) = 0.\n        # The valid root (satisfying x  1) is x(rho) = (3*rho - sqrt(rho^2 + 2*rho)) / (2*rho).\n\n        # The slack is s(rho) = 1 - x(rho).\n        # A simpler expression for the slack is derived as:\n        # s(rho) = (sqrt(rho^2 + 2*rho) - rho) / (2*rho)\n        \n        # We must use floating-point numbers for the calculations.\n        rho_f = float(rho)\n        \n        # Calculate the slack s(rho).\n        numerator = np.sqrt(rho_f**2 + 2 * rho_f) - rho_f\n        denominator = 2 * rho_f\n        slack = numerator / denominator\n\n        # The constraint is \"active\" if the slack is less than or equal to the tolerance.\n        # Activity indicator is 1 for active, 0 for inactive.\n        if slack = tau:\n            activity_indicator = 1\n        else:\n            activity_indicator = 0\n        \n        results.append(activity_indicator)\n\n    # The final output must be a single line containing the activity results\n    # as a comma-separated list of integers enclosed in square brackets.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2423438"}, {"introduction": "The elegance of barrier methods comes with significant numerical challenges, particularly as iterates approach a constraint boundary. This practice provides a focused analysis of the local behavior of an interior-point algorithm in this critical regime, exploring how the Hessian matrix becomes ill-conditioned. Understanding the properties of the Newton step near the boundary, as you will do here, is fundamental to appreciating the design of modern, robust interior-point solvers that must navigate this behavior [@problem_id:2423460].", "problem": "Consider the unconstrained minimization of the barrier-augmented objective associated with a single inequality constraint in one spatial dimension. Let the original objective be the quadratic function $f(x) = (x - a)^2$, and let the inequality constraint be $g(x) = c - x \\le 0$, so the feasible region is $\\{x \\in \\mathbb{R} \\, | \\, x \\ge c\\}$ and the interior is $\\{x \\in \\mathbb{R} \\, | \\, x  c\\}$. For a barrier parameter $\\mu  0$, define the logarithmic barrier-augmented objective\n$$\n\\phi_{\\mu}(x) \\;=\\; f(x) \\;-\\; \\mu \\,\\log\\!\\big(-g(x)\\big) \\;=\\; (x - a)^2 \\;-\\; \\mu \\,\\log(x - c),\n$$\nwhich is well-defined for $x  c$. For an interior starting point $x_0 = c + \\delta$ with $\\delta  0$ and $g(x_0) = -\\delta$, analyze the local quadratic model of $\\phi_{\\mu}$ at $x_0$.\n\nUsing only the definitions of gradient and Hessian, let $\\nabla \\phi_{\\mu}(x_0)$ denote the first derivative of $\\phi_{\\mu}$ at $x_0$, and let $\\nabla^2 \\phi_{\\mu}(x_0)$ denote the second derivative of $\\phi_{\\mu}$ at $x_0$. Define the scalar $s$ to be the unique solution of the linear equation\n$$\n\\big(\\nabla^2 \\phi_{\\mu}(x_0)\\big)\\, s \\;=\\; -\\,\\nabla \\phi_{\\mu}(x_0).\n$$\nDefine the quadratic-model predicted change at $x_0$ in the direction $s$ as\n$$\n\\Delta \\;=\\; \\nabla \\phi_{\\mu}(x_0)\\, s \\;+\\; \\tfrac{1}{2}\\, s^2 \\, \\nabla^2 \\phi_{\\mu}(x_0).\n$$\nFinally, define the ratio\n$$\nr \\;=\\; \\frac{s}{x_0 - c} \\;=\\; \\frac{s}{\\delta}.\n$$\n\nFor each test case below, you must evaluate at $x_0 = c + \\delta$ and return a list of four quantities:\n- $|s|$,\n- $\\Delta$,\n- an indicator of positive curvature given by $1$ if $\\nabla^2 \\phi_{\\mu}(x_0)  0$ and $0$ otherwise,\n- the ratio $r$.\n\nAll computations must be carried out in standard double-precision floating point arithmetic. Do not round the results.\n\nTest Suite:\n- Case $1$: $a = 1$, $c = 0$, $\\mu = 10^{-1}$, $\\delta = 10^{-3}$.\n- Case $2$: $a = 1$, $c = 0$, $\\mu = 1$, $\\delta = 10^{-9}$.\n- Case $3$: $a = 1$, $c = 0$, $\\mu = 1$, $\\delta = 10^{-12}$.\n- Case $4$: $a = 10^{-8}$, $c = 0$, $\\mu = 1$, $\\delta = 10^{-12}$.\n- Case $5$: $a = 1$, $c = 0$, $\\mu = 10^{-6}$, $\\delta = 10^{-12}$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results for all five test cases as a comma-separated list enclosed in square brackets with no spaces. Each test case result must itself be a list in the same format, i.e., the overall output must look like\n$[[q_{11},q_{12},q_{13},q_{14}],[q_{21},q_{22},q_{23},q_{24}],[q_{31},q_{32},q_{33},q_{34}],[q_{41},q_{42},q_{43},q_{44}],[q_{51},q_{52},q_{53},q_{54}]]$,\nwhere $q_{ij}$ denotes the required quantities for case $i$ in the order listed above.", "solution": "The problem statement presented is a well-posed and scientifically sound exercise in the analysis of interior-point methods for constrained optimization. All definitions, parameters, and objectives are specified with sufficient precision. The problem is valid and admits a unique, verifiable solution. We shall proceed with the derivation and computation.\n\nThe task is to analyze the local quadratic model of a barrier-augmented objective function at a specified interior point. The original objective is $f(x) = (x - a)^2$ and the inequality constraint is $g(x) = c - x \\le 0$. The logarithmic barrier-augmented objective function is given by:\n$$\n\\phi_{\\mu}(x) = f(x) - \\mu \\log(-g(x)) = (x - a)^2 - \\mu \\log(x - c)\n$$\nThis function is defined for $x > c$, with a barrier parameter $\\mu > 0$. The analysis is to be performed at the point $x_0 = c + \\delta$, where $\\delta > 0$.\n\nFirst, we must compute the first and second derivatives of $\\phi_{\\mu}(x)$ with respect to $x$. These are referred to as the gradient $\\nabla \\phi_{\\mu}(x)$ and the Hessian $\\nabla^2 \\phi_{\\mu}(x)$ in the one-dimensional context.\n\nThe first derivative is:\n$$\n\\nabla \\phi_{\\mu}(x) = \\frac{d}{dx} \\phi_{\\mu}(x) = \\frac{d}{dx} \\left( (x - a)^2 - \\mu \\log(x - c) \\right) = 2(x - a) - \\frac{\\mu}{x - c}\n$$\nThe second derivative is:\n$$\n\\nabla^2 \\phi_{\\mu}(x) = \\frac{d^2}{dx^2} \\phi_{\\mu}(x) = \\frac{d}{dx} \\left( 2(x - a) - \\frac{\\mu}{x - c} \\right) = 2 + \\frac{\\mu}{(x - c)^2}\n$$\nNext, we evaluate these derivatives at the specified point $x_0 = c + \\delta$. At this point, the term $x_0 - c$ simplifies to $\\delta$.\n$$\n\\nabla \\phi_{\\mu}(x_0) = 2(x_0 - a) - \\frac{\\mu}{x_0 - c} = 2(c + \\delta - a) - \\frac{\\mu}{\\delta}\n$$\n$$\n\\nabla^2 \\phi_{\\mu}(x_0) = 2 + \\frac{\\mu}{(x_0 - c)^2} = 2 + \\frac{\\mu}{\\delta^2}\n$$\nThe quantity $s$ is defined as the solution to the linear system representing Newton's method for minimizing $\\phi_{\\mu}(x)$:\n$$\n\\big(\\nabla^2 \\phi_{\\mu}(x_0)\\big) s = -\\nabla \\phi_{\\mu}(x_0)\n$$\nSince $\\nabla^2 \\phi_{\\mu}(x_0)$ is a scalar, we can solve for $s$ by division:\n$$\ns = -\\frac{\\nabla \\phi_{\\mu}(x_0)}{\\nabla^2 \\phi_{\\mu}(x_0)} = -\\frac{2(c + \\delta - a) - \\frac{\\mu}{\\delta}}{2 + \\frac{\\mu}{\\delta^2}}\n$$\nThe first quantity to be returned is the absolute value of $s$, denoted $|s|$.\n\nThe second quantity is the predicted change $\\Delta$ from the quadratic model:\n$$\n\\Delta = \\nabla \\phi_{\\mu}(x_0) s + \\frac{1}{2} s^2 \\nabla^2 \\phi_{\\mu}(x_0)\n$$\nWe can substitute the relation $\\nabla \\phi_{\\mu}(x_0) = -s \\nabla^2 \\phi_{\\mu}(x_0)$ into this expression to simplify it:\n$$\n\\Delta = (-s \\nabla^2 \\phi_{\\mu}(x_0)) s + \\frac{1}{2} s^2 \\nabla^2 \\phi_{\\mu}(x_0) = -s^2 \\nabla^2 \\phi_{\\mu}(x_0) + \\frac{1}{2} s^2 \\nabla^2 \\phi_{\\mu}(x_0) = -\\frac{1}{2} s^2 \\nabla^2 \\phi_{\\mu}(x_0)\n$$\nThis simplified form is robust for numerical computation.\n\nThe third quantity is an indicator of positive curvature. We must check the sign of the Hessian $\\nabla^2 \\phi_{\\mu}(x_0)$.\n$$\n\\nabla^2 \\phi_{\\mu}(x_0) = 2 + \\frac{\\mu}{\\delta^2}\n$$\nGiven the problem constraints that $\\mu > 0$ and $\\delta > 0$, it is clear that $\\mu/\\delta^2 > 0$. Therefore, $\\nabla^2 \\phi_{\\mu}(x_0)$ is strictly greater than $2$. The Hessian is always positive, which implies that the barrier-augmented function $\\phi_{\\mu}(x)$ is strictly convex. The indicator for positive curvature, $1$ if $\\nabla^2 \\phi_{\\mu}(x_0) > 0$ and $0$ otherwise, is thus always $1$.\n\nThe fourth quantity is the ratio $r$:\n$$\nr = \\frac{s}{x_0 - c} = \\frac{s}{\\delta}\n$$\nThis can be calculated directly after finding $s$.\n\nThe computational procedure for each test case $(a, c, \\mu, \\delta)$ is as follows:\n$1$. Calculate $\\nabla \\phi_{\\mu}(x_0) = 2(c + \\delta - a) - \\mu / \\delta$.\n$2$. Calculate $\\nabla^2 \\phi_{\\mu}(x_0) = 2 + \\mu / \\delta^2$.\n$3$. Calculate $s = -\\nabla \\phi_{\\mu}(x_0) / \\nabla^2 \\phi_{\\mu}(x_0)$.\n$4$. Compute the four required values:\n    - $|s|$\n    - $\\Delta = -0.5 \\cdot s^2 \\cdot \\nabla^2 \\phi_{\\mu}(x_0)$\n    - Curvature indicator: $1.0$\n    - $r = s / \\delta$\n\nThese steps are implemented in the provided Python code to compute the results for all specified test cases using standard double-precision floating-point arithmetic.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test suite by analyzing the local\n    quadratic model of a barrier-augmented objective function.\n    \"\"\"\n\n    test_cases = [\n        # Case 1: a = 1, c = 0, mu = 1e-1, delta = 1e-3\n        (1.0, 0.0, 1e-1, 1e-3),\n        # Case 2: a = 1, c = 0, mu = 1, delta = 1e-9\n        (1.0, 0.0, 1.0, 1e-9),\n        # Case 3: a = 1, c = 0, mu = 1, delta = 1e-12\n        (1.0, 0.0, 1.0, 1e-12),\n        # Case 4: a = 1e-8, c = 0, mu = 1, delta = 1e-12\n        (10e-9, 0.0, 1.0, 1e-12),\n        # Case 5: a = 1, c = 0, mu = 1e-6, delta = 1e-12\n        (1.0, 0.0, 1e-6, 1e-12),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        a, c, mu, delta = case\n        \n        # Calculate the gradient (first derivative) at x_0 = c + delta\n        # grad_phi = 2 * (x_0 - a) - mu / (x_0 - c)\n        # x_0 - c = delta\n        # x_0 - a = c + delta - a\n        grad_phi = 2.0 * (c + delta - a) - mu / delta\n        \n        # Calculate the Hessian (second derivative) at x_0 = c + delta\n        # hess_phi = 2 + mu / (x_0 - c)^2\n        hess_phi = 2.0 + mu / (delta**2)\n        \n        # Calculate the Newton step s\n        # hess_phi * s = -grad_phi\n        s = -grad_phi / hess_phi\n        \n        # 1. |s|\n        abs_s = abs(s)\n        \n        # 2. Predicted change Delta\n        # Delta = -0.5 * s^2 * hess_phi\n        delta_change = -0.5 * s**2 * hess_phi\n        \n        # 3. Indicator of positive curvature\n        # hess_phi = 2 + mu/delta^2. Since mu  0, delta  0, hess_phi is always  0.\n        pos_curv_indicator = 1.0 if hess_phi  0 else 0.0\n        \n        # 4. Ratio r\n        # r = s / delta\n        r = s / delta\n        \n        results.append([abs_s, delta_change, pos_curv_indicator, r])\n\n    # Format the final output string as a list of lists with no spaces\n    # e.g., [[q11,q12,q13,q14],[q21,q22,q23,q24],...]\n    inner_results_str = [f\"[{','.join(map(str, res))}]\" for res in results]\n    final_output = f\"[{','.join(inner_results_str)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "2423460"}]}