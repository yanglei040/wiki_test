{"hands_on_practices": [{"introduction": "The Linear Speedup Theorem is more than a theoretical curiosity; it is a constructive proof that provides a recipe for building faster machines. This first practice places you in the role of a machine designer, tasked with making a concrete design choice to achieve a desired performance target. You will determine the necessary compression factor for a Turing Machine, bridging the gap between the theorem's abstract promise and a specific engineering parameter [@problem_id:1430465].", "problem": "A computer scientist is working with a language $L$ which is decided by a specific single-tape Turing Machine (TM), denoted as $M$. The worst-case time complexity of $M$ is known to be $T(n) = 2n^2 + 10n$, where $n$ is the length of the input string. According to the linear speedup theorem, it is possible to construct a new single-tape TM, let's call it $M'$, that also decides $L$ but runs significantly faster. The goal is to design $M'$ to have a time complexity of $T'(n) \\le n^2 + n + c$ for all sufficiently large $n$, where $c$ is a constant.\n\nThe construction of $M'$ involves tape compression, where each cell on $M'$'s tape represents a block of $k$ consecutive symbols from $M$'s tape. The simulation phase of $M'$ consists of macro-steps, where each macro-step of $M'$ simulates multiple steps of $M$ in a constant number of $M'$'s own steps. A thorough analysis shows that simulating what occurs across a local region of $M$'s tape (the current block and its two neighbors) to determine the outcome of $k$ steps of $M$ can be done in 8 steps by $M'$ (read, compute, write, and move to the next relevant block).\n\nWhich of the following choices correctly describes a necessary part of the design for $M'$, including the minimum integer compression factor $k$ that guarantees the target time complexity is met?\n\nA. Use a compression factor $k=8$. The state of $M'$ encodes the state of $M$ and the position of $M$'s head within the current $k$-symbol block. This is sufficient as $k1$, ensuring a speedup.\n\nB. Use a compression factor $k=16$. The state of $M'$ must encode the state of $M$, the head position within the current block, and the contents of the left and right adjacent blocks on its tape to allow for local simulation.\n\nC. Use a compression factor $k=17$. The state of $M'$ must encode the state of $M$, the head position within the current block, and the contents of the left and right adjacent blocks on its tape to allow for local simulation.\n\nD. Use a compression factor $k=17$. The state of $M'$ only needs to encode the state of $M$. To handle boundary crossings between blocks, $M'$ moves its head to the adjacent cell to read it, which takes one extra step per crossing.\n\nE. The speedup to $n^2 + n + c$ is impossible to guarantee for a single-tape TM. This level of speedup would require a multi-tape TM, which is a different machine model.", "solution": "We are given a single-tape TM $M$ with worst-case time $T(n)=2n^{2}+10n$. We construct a compressed single-tape simulator $M'$ using block compression by a factor $k$, where each cell on $M'$ encodes $k$ consecutive symbols of $M$. The macro-step simulation assumption states that $M'$ can simulate $k$ steps of $M$ in $8$ steps of $M'$, by reading the current block and its two neighbors, performing the local computation, writing the updated blocks, and moving to the next relevant block.\n\nLet $T'(n)$ denote the time of $M'$ on inputs of length $n$. The standard linear speedup analysis for single-tape TMs with block compression yields\n$$\nT'(n) \\le \\frac{8}{k}\\,T(n) + \\alpha n + \\beta,\n$$\nwhere the term $\\alpha n$ accounts for linear-time overheads such as initial packing of the input into blocks, and $\\beta$ is a constant. Substituting $T(n)=2n^{2}+10n$ gives\n$$\nT'(n) \\le \\frac{8}{k}\\left(2n^{2}+10n\\right) + \\alpha n + \\beta\n= \\left(\\frac{16}{k}\\right)n^{2} + \\left(\\frac{80}{k}+\\alpha\\right)n + \\beta.\n$$\n\nWe want $T'(n) \\le n^{2} + n + c$ for all sufficiently large $n$. Equivalently, for some constant $c$ and all sufficiently large $n$,\n$$\n\\left(1 - \\frac{16}{k}\\right)n^{2} + \\left(1 - \\frac{80}{k} - \\alpha\\right)n + (c - \\beta) \\ge 0.\n$$\nFor this inequality to hold for all sufficiently large $n$, the leading coefficient must be strictly positive:\n$$\n1 - \\frac{16}{k} > 0 \\quad \\Longleftrightarrow \\quad k > 16.\n$$\nIf $k=16$, then the quadratic term cancels and we would require $1 - \\frac{80}{16} - \\alpha \\ge 0$, i.e., $1 - 5 - \\alpha \\ge 0$, which is impossible since $\\alpha \\ge 0$. Therefore the minimum integer $k$ that guarantees the target asymptotic bound is $k=17$.\n\nNext, we identify the necessary finite-control information in $M'$. To perform each macro-step in constant time (here, $8$ steps) without incurring extra head motion, $M'$ must locally determine the effect of $k$ steps of $M$ across possible head movements within the current $k$-symbol block and across the boundaries into neighboring blocks. This requires that the finite control of $M'$ encode:\n- the current state of $M$,\n- the position of $M$â€™s head within the current $k$-symbol block (an integer in $\\{0,\\dots,k-1\\}$),\n- the contents of the current, left-adjacent, and right-adjacent blocks (so that $M'$ can compute the $k$-step outcome locally without extra scans).\n\nSince $k$ is a fixed constant, encoding these block contents in the control (via an enlarged but finite state space) is feasible. Without storing the adjacent blocks, $M'$ would need to move to read them during the macro-step, causing more than a constant overhead per macro-step and violating the assumed $8$-step simulation.\n\nTherefore, the correct design choice is to use $k=17$ and to encode in the control the state of $M$, the head position within the current block, and the contents of the adjacent blocks for constant-time local simulation. Among the options, this corresponds to choice C.", "answer": "$$\\boxed{C}$$", "id": "1430465"}, {"introduction": "While the speedup theorem guarantees a reduction in runtime, this gain comes at a cost in machine complexity. This exercise explores this trade-off by examining what happens when the speedup procedure is applied iteratively. By analyzing the exponential growth of the machine's alphabet and state set, you will quantify the steep price of speed, revealing a crucial limitation on the theorem's practical application [@problem_id:1430470].", "problem": "A team of theoretical computer scientists is analyzing the trade-offs involved in iteratively applying optimization techniques to computational models. They start with a single-tape Turing Machine (TM), denoted $M_0$, which has an initial set of states $Q_0$ and a tape alphabet $\\Gamma_0$. The initial number of states is $|Q_0| = s$ and the initial alphabet size is $|\\Gamma_0| = a$, where $a \\geq 2$ and $s \\geq 1$.\n\nThey generate a sequence of increasingly faster TMs, $M_1, M_2, \\ldots, M_N$, by repeatedly applying a specific procedure based on the linear speedup theorem. The transformation from machine $M_{k-1}$ to $M_k$ for $k \\in \\{1, 2, \\ldots, N\\}$ is governed by a constant symbol-compression factor, an integer $m  1$. This transformation follows two rules:\n\n1.  **Alphabet Expansion**: The tape alphabet $\\Gamma_k$ of machine $M_k$ is constructed by grouping symbols from $\\Gamma_{k-1}$ into non-overlapping blocks of length $m$. Thus, a single symbol of $M_k$ represents a sequence of $m$ symbols of $M_{k-1}$.\n2.  **State Complexity Growth**: In one computational step, machine $M_k$ simulates the behavior of machine $M_{k-1}$. To achieve this, the finite control of $M_k$ must store not only the current state of $M_{k-1}$ but also the local tape configuration of $M_{k-1}$. The construction protocol specifies that a state in $Q_k$ must encode the current state from $Q_{k-1}$ and the contents of a tape segment of $M_{k-1}$ of length $3m$ symbols (the $m$ symbols corresponding to the current position of $M_k$'s head, plus the $m$ symbols in the block to the immediate left and the $m$ symbols in the block to the immediate right).\n\nAfter $N$ complete iterations of this procedure, we have the final machine $M_N$ with state set $Q_N$ and alphabet $\\Gamma_N$.\n\nDetermine the value of the ratio $\\frac{\\ln(|Q_N|)}{\\ln(|\\Gamma_N|)}$, where $\\ln$ denotes the natural logarithm. Your answer should be a closed-form expression in terms of the initial parameters $s, a, m$, and the number of iterations $N$.", "solution": "Let $g_{k} = |\\Gamma_{k}|$ and $q_{k} = |Q_{k}|$. By the alphabet expansion rule, each symbol of $M_{k}$ encodes a block of $m$ symbols of $M_{k-1}$, so the alphabet sizes satisfy\n$$\ng_{k} = g_{k-1}^{m}, \\quad g_{0} = a.\n$$\nSolving this recursion by repeated substitution gives\n$$\ng_{k} = a^{m^{k}},\n$$\nand in particular\n$$\n|\\Gamma_{N}| = g_{N} = a^{m^{N}}.\n$$\nBy the state complexity rule, a state of $M_{k}$ must encode a state of $M_{k-1}$ together with the contents of a length-$3m$ segment over $\\Gamma_{k-1}$, hence\n$$\nq_{k} = q_{k-1}\\, g_{k-1}^{3m}, \\quad q_{0} = s.\n$$\nUsing $g_{k-1} = a^{m^{k-1}}$, this becomes\n$$\nq_{k} = q_{k-1}\\, a^{3m \\cdot m^{k-1}} = q_{k-1}\\, a^{3 m^{k}}.\n$$\nUnrolling the product yields\n$$\nq_{N} = s \\prod_{i=1}^{N} a^{3 m^{i}} = s\\, a^{3 \\sum_{i=1}^{N} m^{i}}.\n$$\nThe sum is a geometric series:\n$$\n\\sum_{i=1}^{N} m^{i} = \\frac{m(m^{N} - 1)}{m - 1}.\n$$\nTherefore,\n$$\n|Q_{N}| = q_{N} = s\\, a^{\\frac{3m(m^{N}-1)}{m-1}}.\n$$\nWe now compute the ratio of logarithms. Using $\\ln(xy) = \\ln x + \\ln y$ and $\\ln(a^{b}) = b \\ln a$,\n$$\n\\ln(|Q_{N}|) = \\ln(s) + \\frac{3m(m^{N}-1)}{m-1}\\, \\ln(a), \\qquad \\ln(|\\Gamma_{N}|) = m^{N} \\ln(a).\n$$\nHence,\n$$\n\\frac{\\ln(|Q_{N}|)}{\\ln(|\\Gamma_{N}|)} = \\frac{\\ln(s)}{m^{N}\\ln(a)} + \\frac{3m(m^{N}-1)}{(m-1)m^{N}}.\n$$\nThis simplifies to\n$$\n\\frac{\\ln(|Q_{N}|)}{\\ln(|\\Gamma_{N}|)} = \\frac{\\ln(s)}{m^{N}\\ln(a)} + \\frac{3\\bigl(m - m^{1-N}\\bigr)}{m - 1}.\n$$\nThis is the desired closed-form expression in terms of $s, a, m$, and $N$.", "answer": "$$\\boxed{\\frac{\\ln(s)}{m^{N}\\ln(a)}+\\frac{3\\left(m-m^{1-N}\\right)}{m-1}}$$", "id": "1430470"}, {"introduction": "The fundamental ideas of computation often transcend specific machine models, and the concept of linear speedup is no exception. This final practice challenges you to generalize the technique from a standard one-dimensional tape to a two-dimensional grid. You will adapt the symbol-packing strategy to a new geometry, reinforcing the core principles of the theorem by applying them in an unfamiliar context [@problem_id:1430455].", "problem": "Consider a Turing Machine (TM) with a two-dimensional tape, infinite in all four directions (North, South, East, West). Let this machine be $M$. The time complexity of $M$ for an input provided as an initial non-blank configuration on an $n \\times n$ square of tape cells is given by the function $T(n) = \\alpha n^{3} + \\beta n^{2}$, where $\\alpha$ and $\\beta$ are known positive constants.\n\nWe wish to construct a new 2D-tape TM, let's call it $M'$, that solves the same problem but faster. The strategy is to use tape compression. Each cell of $M'$'s tape stores a single \"macro-symbol\" that represents an entire $m \\times m$ block of cells from $M$'s tape, where $m$ is a positive integer called the compression factor.\n\nThe operation of $M'$ consists of two phases: an initial compression phase and a simulation phase.\n1.  **Compression Phase**: $M'$ reads the entire $n \\times n$ input from $M$'s tape and writes the corresponding compressed $(\\lceil n/m \\rceil \\times \\lceil n/m \\rceil)$ configuration onto its own tape. This phase takes a total of $\\gamma n^{2}$ steps, where $\\gamma$ is a known positive constant.\n2.  **Simulation Phase**: $M'$ simulates the execution of $M$. To simulate a block of $m$ consecutive steps of $M$, $M'$ performs a fixed routine that takes a constant number of its own steps. This routine involves:\n    a. A sequence of $K$ moves to read the macro-symbols in its current cell and the 8 adjacent cells (a $3 \\times 3$ neighborhood). $K$ is a given positive integer constant.\n    b. An internal computation within its finite control (which takes zero moves on the tape).\n    c. A single write operation to update the macro-symbol in its current cell.\n    d. A single move to the adjacent macro-cell that now contains the simulated head of $M$. (It is guaranteed that after $m$ steps, the head of $M$ will have moved to a position contained within the $3 \\times 3$ neighborhood of macro-cells).\n\nThe total time for $M'$, $T'(n)$, is the sum of the time for these two phases. The goal is to achieve a linear speedup, defined by the condition $T'(n) \\le \\frac{1}{c} T(n)$ for a desired speedup factor $c1$ and for all sufficiently large integers $n$.\n\nDetermine the minimum positive integer value for the compression factor $m$ that guarantees this speedup is achieved. Your answer should be a closed-form analytic expression in terms of the constants $c$ and $K$.", "solution": "We model the running time of the compressed simulator $M'$ by counting its steps in the two phases.\n\nCompression phase: By assumption, compressing the $n \\times n$ input into macro-cells takes $\\gamma n^{2}$ steps.\n\nSimulation phase: Let one macro-step be the routine that simulates exactly $m$ steps of $M$ using the fixed sequence: $K$ moves to collect the $3 \\times 3$ neighborhood of macro-cells, $0$ moves for internal computation, $1$ write, and $1$ move to the next macro-cell. Hence each macro-step costs $K+2$ moves of $M'$. To simulate $T(n)$ steps of $M$, $M'$ needs at most $\\lceil T(n)/m \\rceil$ macro-steps. Therefore\n$$\nT'(n) \\le \\gamma n^{2} + (K+2)\\left\\lceil \\frac{T(n)}{m} \\right\\rceil \\le \\gamma n^{2} + \\frac{K+2}{m}T(n) + (K+2).\n$$\nUsing $T(n)=\\alpha n^{3}+\\beta n^{2}$, this yields\n$$\nT'(n) \\le \\gamma n^{2} + \\frac{K+2}{m}\\left(\\alpha n^{3}+\\beta n^{2}\\right) + (K+2).\n$$\n\nTo achieve a linear speedup by a factor $c1$ for all sufficiently large $n$, we require\n$$\nT'(n) \\le \\frac{1}{c}T(n) = \\frac{1}{c}\\left(\\alpha n^{3}+\\beta n^{2}\\right)\n$$\neventually in $n$. Ignoring the additive constant $(K+2)$, which is dominated for large $n$, this inequality is implied for sufficiently large $n$ if and only if the leading $n^{3}$-term on the left is strictly smaller than the leading $n^{3}$-term on the right. Writing the inequality explicitly and collecting powers of $n$ gives\n$$\n\\left(\\frac{K+2}{m}-\\frac{1}{c}\\right)\\alpha n^{3}+\\left(\\gamma+\\frac{K+2}{m}\\beta-\\frac{1}{c}\\beta\\right)n^{2} \\le 0.\n$$\nSince $\\alpha,\\beta,\\gamma0$, the $n^{3}$ term must have a strictly negative coefficient to guarantee the inequality for all sufficiently large $n$; equality would leave a positive $n^{2}$ term due to $\\gamma0$ and thus violate the bound. Therefore we must have\n$$\n\\frac{K+2}{m} - \\frac{1}{c}  0 \\quad \\Longleftrightarrow \\quad m  c\\,(K+2).\n$$\nBecause $m$ must be a positive integer, the smallest such $m$ is the least integer strictly greater than $c\\,(K+2)$, namely\n$$\nm_{\\min}=\\left\\lfloor c\\,(K+2)\\right\\rfloor + 1.\n$$\nThis condition guarantees that the $n^{3}$ coefficient on the left is strictly smaller than that on the right, so the negative $n^{3}$ gap eventually dominates the positive $n^{2}$ terms (including the compression cost), ensuring $T'(n)\\le \\frac{1}{c}T(n)$ for all sufficiently large $n$.", "answer": "$$\\boxed{\\left\\lfloor c\\,(K+2)\\right\\rfloor + 1}$$", "id": "1430455"}]}