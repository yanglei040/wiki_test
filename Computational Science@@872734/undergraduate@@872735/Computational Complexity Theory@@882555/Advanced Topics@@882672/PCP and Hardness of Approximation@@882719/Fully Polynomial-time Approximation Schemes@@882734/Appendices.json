{"hands_on_practices": [{"introduction": "The core promise of a Fully Polynomial-Time Approximation Scheme (FPTAS) is its provable performance guarantee. For a maximization problem, this means the algorithm's output is guaranteed to be within a specific fraction of the true, but often computationally infeasible, optimal solution. This first exercise [@problem_id:1424984] provides a concrete scenario to make this abstract guarantee tangible, asking you to calculate the worst-case performance of an FPTAS given its error parameter $\\epsilon$.", "problem": "A cloud infrastructure company needs to select a subset of pending high-performance computing jobs to run on a supercomputer with a limited processing capacity for the next 24-hour cycle. Each job has a specific computational cost and generates a certain amount of revenue. The total computational cost of selected jobs cannot exceed the supercomputer's capacity. This resource allocation task is equivalent to the 0/1 knapsack problem, which is known to be NP-hard.\n\nTo find a nearly optimal solution in a practical amount of time, the company employs a Fully Polynomial-Time Approximation Scheme (FPTAS). An external consultant, using an exact but slow exponential-time algorithm, has determined that the maximum possible revenue (the optimal solution value, $V_{opt}$) for one particular day's set of pending jobs is exactly $\\$1,254,300$. The company's FPTAS implementation is configured with an error parameter $\\epsilon = 0.085$.\n\nBased on the performance guarantee provided by the FPTAS framework for a maximization problem, what is the minimum revenue the company is guaranteed to generate from the jobs selected by this approximation algorithm? Express your answer in dollars, rounded to three significant figures.", "solution": "The problem asks for the minimum guaranteed revenue from a selection of jobs made by a Fully Polynomial-Time Approximation Scheme (FPTAS). We are given the value of the optimal solution and the error parameter of the FPTAS.\n\nFirst, let's recall the definition of an FPTAS for a maximization problem. An algorithm is an FPTAS if, for any instance of the problem and any error parameter $\\epsilon  0$, it produces a solution with a value $V_{approx}$ that is guaranteed to be within a certain factor of the optimal solution's value, $V_{opt}$. The specific guarantee for a maximization problem is given by the inequality:\n$$V_{approx} \\geq (1 - \\epsilon)V_{opt}$$\nThe algorithm must also run in time that is polynomial in both the input size and $1/\\epsilon$.\n\nIn this problem, we are asked for the minimum guaranteed revenue. This corresponds to the lower bound on $V_{approx}$ as defined by the FPTAS guarantee. We are given the following values:\nThe optimal solution value, $V_{opt} = \\$1,254,300$.\nThe error parameter, $\\epsilon = 0.085$.\n\nWe need to calculate the minimum guaranteed value, which we'll call $V_{min\\_guaranteed}$.\n$$V_{min\\_guaranteed} = (1 - \\epsilon)V_{opt}$$\n\nNow, we substitute the given numerical values into this formula.\n$$V_{min\\_guaranteed} = (1 - 0.085) \\times 1,254,300$$\n\nFirst, calculate the term in the parenthesis:\n$$1 - 0.085 = 0.915$$\n\nNext, multiply this factor by the optimal value:\n$$V_{min\\_guaranteed} = 0.915 \\times 1,254,300$$\n$$V_{min\\_guaranteed} = 1,148,184.5$$\n\nThe problem requires the answer to be rounded to three significant figures. The calculated value is $1,148,184.5$.\nThe first three significant figures are 1, 1, and 4. The fourth significant figure is 8. Since 8 is 5 or greater, we must round up the third significant figure. So, the '4' becomes a '5'. The digits following the third significant figure are replaced by zeros to maintain the magnitude of the number.\nThe rounded value is $1,150,000$.\n\nTo express this unambiguously with three significant figures, we use scientific notation.\n$$1,150,000 = 1.15 \\times 10^6$$\n\nThus, the minimum revenue the company is guaranteed to generate is $\\$1,150,000$.", "answer": "$$\\boxed{1.15 \\times 10^{6}}$$", "id": "1424984"}, {"introduction": "While an FPTAS allows us to get arbitrarily close to the optimal solution, this precision comes at a computational cost. The \"fully polynomial\" nature of the scheme means the runtime is polynomial in both the input size $n$ and, crucially, in $1/\\epsilon$. This practice [@problem_id:1425231] explores the practical implications of this trade-off, demonstrating how much slower an algorithm becomes when you demand a higher-quality solution.", "problem": "A technology company has developed an algorithm for optimizing the scheduling of $n$ computational jobs in a data center to maximize the total value of completed work. Since finding the perfectly optimal schedule is an NP-hard problem, the company employs an approximation algorithm. Their algorithm is a Fully Polynomial-Time Approximation Scheme (FPTAS).\n\nFor a maximization problem, an FPTAS is an algorithm that, for any given input of size $n$ and any error parameter $\\epsilon  0$, runs in time that is polynomial in both $n$ and $1/\\epsilon$. The algorithm is guaranteed to produce a solution with a value that is at least $(1-\\epsilon)$ times the value of the optimal solution.\n\nThe specific FPTAS developed by the company has a time complexity of $T(n, \\epsilon) = O\\left(\\frac{n^2 \\log n}{\\epsilon^3}\\right)$.\n\nCurrently, the operations team runs the algorithm with a parameter setting that guarantees the solution's value is at least 95% of the optimal value. To meet the demands for a critical end-of-year analysis, the management board has requested a higher quality guarantee, requiring the solution's value to be at least 99.5% of the optimal value.\n\nAssuming the number of jobs $n$ remains constant for both runs, calculate the factor by which the algorithm's runtime will increase to meet this new, more stringent quality requirement.", "solution": "We are given an FPTAS for a maximization problem with runtime complexity\n$$\nT(n,\\epsilon)=O\\left(\\frac{n^{2}\\log n}{\\epsilon^{3}}\\right).\n$$\nFor a maximization FPTAS, a guarantee that the solution value is at least a fraction $q$ of the optimal value corresponds to choosing $\\epsilon=1-q$.\n\nThe current run guarantees at least $0.95$ of optimal, so\n$$\n\\epsilon_{1}=1-0.95=0.05.\n$$\nThe desired run guarantees at least $0.995$ of optimal, so\n$$\n\\epsilon_{2}=1-0.995=0.005.\n$$\n\nFor fixed $n$, the runtime scales as $T(n,\\epsilon)\\propto \\epsilon^{-3}$. Therefore, the factor increase in runtime to move from $\\epsilon_{1}$ to $\\epsilon_{2}$ is\n$$\n\\frac{T(n,\\epsilon_{2})}{T(n,\\epsilon_{1})}=\\left(\\frac{\\epsilon_{1}}{\\epsilon_{2}}\\right)^{3}=\\left(\\frac{0.05}{0.005}\\right)^{3}=10^{3}=1000.\n$$\nThus, the runtime increases by a factor of $1000$.", "answer": "$$\\boxed{1000}$$", "id": "1425231"}, {"introduction": "We've seen what an FPTAS guarantees and the computational price of that guarantee, but how is it achieved? This final practice [@problem_id:1425257] pulls back the curtain on the elegant technique of scaling and rounding, which is central to many FPTAS designs, including the classic one for the knapsack problem. By analyzing how item values are transformed, you'll uncover the link between the error parameter $\\epsilon$ and the reduction in the problem's state space, which is what makes an efficient, approximate solution possible.", "problem": "A computer scientist is designing an algorithm for a resource selection problem, which can be modeled as a variation of the 0/1 Knapsack problem. The objective is to select a subset from a collection of $n$ available items. For each item $i \\in \\{1, \\dots, n\\}$, there is an associated integer value $p_i  0$ and an integer cost $c_i  0$. The goal is to choose a subset of items that maximizes the total value $\\sum p_i$, under the constraint that the total cost $\\sum c_i$ does not exceed a budget $C$.\n\nBecause this problem is NP-hard, the scientist implements a Fully Polynomial-Time Approximation Scheme (FPTAS). This scheme guarantees a solution whose value is at least $(1-\\epsilon)$ times the optimal value, where $\\epsilon \\in (0, 1)$ is a user-specified error tolerance. The FPTAS operates as follows:\n\n1.  A 2-approximation algorithm is first run to find an approximate solution value, denoted $P_{approx}$. This value is guaranteed to satisfy $OPT/2 \\le P_{approx} \\le OPT$, where $OPT$ is the value of the true optimal solution.\n2.  A scaling factor $K$ is computed using the formula $K = \\frac{\\epsilon P_{approx}}{n}$.\n3.  For each item $i$, its value $p_i$ is converted to a new scaled integer value, $p'_i = \\left\\lfloor \\frac{p_i}{K} \\right\\rfloor$.\n4.  The problem is then solved exactly using these new scaled values $p'_i$ and original costs $c_i$. This is accomplished with a dynamic programming algorithm that finds the subset of items maximizing the total scaled value $\\sum p'_i$ while respecting the budget $C$.\n5.  The space complexity of the dynamic programming stage is dominated by the range of achievable scaled values. Specifically, the algorithm stores a mapping from each possible total scaled value to the minimum cost to achieve it.\n\nYour task is to determine an upper bound for the maximum possible total scaled value, $\\sum p'_i$, for any subset of items that respects the cost constraint $C$. Express your answer as an analytical expression in terms of $n$ and $\\epsilon$.", "solution": "Let $S$ be any subset of items with total cost at most $C$. Define the unscaled value $V(S)=\\sum_{i\\in S}p_{i}$ and the scaled value $V'(S)=\\sum_{i\\in S}p'_{i}$.\n\nBy definition of the scaling, for each item $i$,\n$$\np'_{i}=\\left\\lfloor \\frac{p_{i}}{K}\\right\\rfloor \\le \\frac{p_{i}}{K}.\n$$\nSumming over any feasible subset $S$,\n$$\nV'(S)=\\sum_{i\\in S}p'_{i}\\le \\sum_{i\\in S}\\frac{p_{i}}{K}=\\frac{V(S)}{K}.\n$$\nLet $OPT$ denote the optimal unscaled value over all feasible subsets. Then $V(S)\\le OPT$ for any feasible $S$, hence\n$$\nV'(S)\\le \\frac{OPT}{K}.\n$$\nUsing the chosen scaling $K=\\frac{\\epsilon P_{approx}}{n}$,\n$$\n\\frac{OPT}{K}=\\frac{OPT}{\\epsilon P_{approx}/n}=\\frac{n}{\\epsilon}\\cdot\\frac{OPT}{P_{approx}}.\n$$\nFrom the $2$-approximation guarantee $OPT/2\\le P_{approx}\\le OPT$, we obtain\n$$\n\\frac{OPT}{P_{approx}}\\le 2.\n$$\nTherefore, for any feasible $S$,\n$$\nV'(S)\\le \\frac{n}{\\epsilon}\\cdot\\frac{OPT}{P_{approx}}\\le \\frac{2n}{\\epsilon}.\n$$\nConsequently, the maximum possible total scaled value over all feasible subsets is upper bounded by $\\frac{2n}{\\epsilon}$.", "answer": "$$\\boxed{\\frac{2n}{\\epsilon}}$$", "id": "1425257"}]}