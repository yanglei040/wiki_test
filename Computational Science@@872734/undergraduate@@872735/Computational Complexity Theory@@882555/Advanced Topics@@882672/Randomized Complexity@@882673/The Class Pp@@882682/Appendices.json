{"hands_on_practices": [{"introduction": "To truly understand the complexity class PP, we must move from definition to application. This first exercise guides you through constructing a probabilistic Turing machine for the Boolean Satisfiability Problem (SAT), a cornerstone of computational complexity. By designing a machine that uses randomness to place SAT within PP [@problem_id:1454712], you will gain hands-on experience with the class's mechanics and appreciate its computational power, which notably includes the entire class NP.", "problem": "In computational complexity theory, the class PP (Probabilistic Polynomial Time) consists of decision problems solvable by a Probabilistic Turing Machine in polynomial time with an error probability of less than $1/2$. A Probabilistic Turing Machine (PTM) is a type of non-deterministic Turing machine where each transitional choice is augmented with a probability, typically a fair coin flip.\n\nLet's consider the Boolean Satisfiability Problem (SAT), which asks whether there exists a satisfying assignment for a given Boolean formula. Suppose we have a Boolean formula $\\phi$ with $n$ distinct variables. Let $S$ be the total number of unique assignments of truth values to these variables that make the formula $\\phi$ true.\n\nA PTM is constructed to work on the input $\\phi$. The PTM executes the following algorithm:\n1. It generates a variable assignment, denoted by $y$, by choosing a truth value (true or false) for each of the $n$ variables. Each of these $n$ choices is made uniformly and independently at random.\n2. It generates an additional random bit $b \\in \\{0, 1\\}$, where the probability of choosing $b=0$ is equal to the probability of choosing $b=1$. This choice is independent of the variable assignment.\n3. The PTM halts and accepts if the assignment $y$ satisfies the formula $\\phi$, OR if the random bit is $b=1$. If neither of these conditions is met, the PTM halts and rejects.\n\nYour task is to determine the exact probability that this PTM will accept. Express your answer as a single closed-form analytic expression in terms of $n$ and $S$.", "solution": "Let $A$ be the event that the random assignment $y$ satisfies $\\phi$, and let $B$ be the event that the random bit equals $1$. The PTM accepts if and only if $A \\cup B$ occurs.\n\nThere are $2^{n}$ possible assignments and exactly $S$ satisfying assignments, so\n$$\n\\Pr(A)=\\frac{S}{2^{n}}.\n$$\nThe bit is fair, so\n$$\n\\Pr(B)=\\frac{1}{2}.\n$$\nThe assignment and the bit are generated independently, hence\n$$\n\\Pr(A \\cap B)=\\Pr(A)\\Pr(B)=\\frac{S}{2^{n}} \\cdot \\frac{1}{2}=\\frac{S}{2^{n+1}}.\n$$\nBy the inclusion-exclusion principle,\n$$\n\\Pr(A \\cup B)=\\Pr(A)+\\Pr(B)-\\Pr(A \\cap B)=\\frac{S}{2^{n}}+\\frac{1}{2}-\\frac{S}{2^{n+1}}.\n$$\nCombine terms to obtain\n$$\n\\Pr(\\text{accept})=\\frac{1}{2}+\\frac{S}{2^{n+1}}=\\frac{2^{n}+S}{2^{n+1}}.\n$$", "answer": "$$\\boxed{\\frac{2^{n}+S}{2^{n+1}}}$$", "id": "1454712"}, {"introduction": "The landscape of probabilistic computation includes both PP and the closely related class BPP (Bounded-error Probabilistic Polynomial time). This practice challenges you to clarify the crucial distinction between them through a thought experiment involving a hypothetical class, `StrongPP` [@problem_id:1454728]. By analyzing `StrongPP`, you will discover that the defining feature of BPP is its constant probability gap, which allows for error reduction—a property not guaranteed for PP, where the gap can be exponentially small.", "problem": "In computational complexity theory, we study classes of problems based on the resources required to solve them. Consider a new complexity class we will call `StrongPP`. A language, which is a set of strings representing a decision problem, $L$ belongs to `StrongPP` if there exists a Probabilistic Polynomial-time Turing Machine (PPTM) $M$ that runs in time bounded by a polynomial in the input length, such that for any input string $x$:\n- If $x$ is in the language $L$ (i.e., $x \\in L$), the probability that $M$ accepts $x$ is at least $3/4$.\n- If $x$ is not in the language $L$ (i.e., $x \\notin L$), the probability that $M$ accepts $x$ is at most $1/4$.\n\nLet P, BPP (Bounded-error Probabilistic Polynomial time), and PP (Probabilistic Polynomial time) be the standard complexity classes. Which of the following statements accurately describes the relationship between `StrongPP` and these classes?\n\nA. `StrongPP` = P\n\nB. `StrongPP` = PP\n\nC. `StrongPP` = BPP\n\nD. $P \\subset \\text{StrongPP} \\subset \\text{BPP}$\n\nE. $\\text{BPP} \\subset \\text{StrongPP} \\subset \\text{PP}$", "solution": "We compare the class defined as follows: a language $L$ is in StrongPP if there exists a probabilistic polynomial-time Turing machine $M$ such that for all inputs $x$, if $x \\in L$ then $\\Pr[M(x)\\text{ accepts}] \\geq \\frac{3}{4}$, and if $x \\notin L$ then $\\Pr[M(x)\\text{ accepts}] \\leq \\frac{1}{4}$.\n\nFirst, recall the standard definition of BPP: a language $L$ is in BPP if there exists a probabilistic polynomial-time Turing machine $M$ such that for all inputs $x$, if $x \\in L$ then $\\Pr[M(x)\\text{ accepts}] \\geq \\frac{2}{3}$, and if $x \\notin L$ then $\\Pr[M(x)\\text{ accepts}] \\leq \\frac{1}{3}$. It is standard that BPP is insensitive to the particular constant gap: any fixed constants $a,b$ with $a-b \\geq \\delta$ for some constant $\\delta0$ and $a\\frac{1}{2}b$ yield the same class via error reduction by independent repetition and majority vote.\n\nInclusion StrongPP $\\subseteq$ BPP: The StrongPP thresholds already satisfy stronger bounds than the canonical BPP thresholds in the sense that $\\frac{3}{4} \\geq \\frac{2}{3}$ and $\\frac{1}{4} \\leq \\frac{1}{3}$. Therefore any language with a StrongPP witness machine also meets the BPP criterion directly, so StrongPP $\\subseteq$ BPP.\n\nInclusion BPP $\\subseteq$ StrongPP: Let $L \\in \\text{BPP}$. Then there exists a probabilistic polynomial-time machine $M$ such that\n$$\nx \\in L \\implies \\Pr[M(x)\\text{ accepts}] \\geq \\frac{2}{3}, \\quad x \\notin L \\implies \\Pr[M(x)\\text{ accepts}] \\leq \\frac{1}{3}.\n$$\nConstruct $M^{\\prime}$ that on input $x$ runs $M$ independently $k$ times and accepts iff strictly more than $\\frac{k}{2}$ runs accept (majority vote). Let $X_{1},\\dots,X_{k}$ be i.i.d. indicator variables for acceptance of each run, and $S=\\sum_{i=1}^{k} X_{i}$.\n\nFor $x \\in L$, we have $\\mathbb{E}[S] \\geq \\frac{2}{3}k$. The error event is $S \\leq \\frac{k}{2}$. By Hoeffding’s inequality for bounded independent variables in $[0,1]$,\n$$\n\\Pr\\left[S - \\mathbb{E}[S] \\leq -t\\right] \\leq \\exp\\left(-\\frac{2 t^{2}}{k}\\right).\n$$\nTaking $t = \\mathbb{E}[S] - \\frac{k}{2} \\geq \\frac{2}{3}k - \\frac{k}{2} = \\frac{k}{6}$, we get\n$$\n\\Pr\\left[S \\leq \\frac{k}{2}\\right] \\leq \\exp\\left(-\\frac{2 (\\frac{k}{6})^{2}}{k}\\right) = \\exp\\left(-\\frac{k}{18}\\right).\n$$\nThus for $x \\in L$, $\\Pr[M^{\\prime}(x)\\text{ accepts}] \\geq 1 - \\exp\\left(-\\frac{k}{18}\\right)$. Similarly, for $x \\notin L$, with $\\mathbb{E}[S] \\leq \\frac{1}{3}k$, the acceptance event $S \\geq \\frac{k}{2}$ is an upward deviation of at least $\\frac{k}{6}$, yielding\n$$\n\\Pr\\left[M^{\\prime}(x)\\text{ accepts}\\right] = \\Pr\\left[S \\geq \\frac{k}{2}\\right] \\leq \\exp\\left(-\\frac{k}{18}\\right).\n$$\nChoose any fixed integer $k$ satisfying\n$$\n\\exp\\left(-\\frac{k}{18}\\right) \\leq \\frac{1}{4} \\quad \\Longleftrightarrow \\quad k \\geq 18 \\ln 4.\n$$\nThis $k$ is a constant, so $M^{\\prime}$ runs in probabilistic polynomial time and achieves\n$$\nx \\in L \\implies \\Pr[M^{\\prime}(x)\\text{ accepts}] \\geq \\frac{3}{4}, \\quad x \\notin L \\implies \\Pr[M^{\\prime}(x)\\text{ accepts}] \\leq \\frac{1}{4}.\n$$\nHence $L \\in \\text{StrongPP}$, establishing BPP $\\subseteq$ StrongPP.\n\nCombining both inclusions gives StrongPP $=$ BPP. Therefore the correct choice among the options is C.\n\nFinally, observe why other options are incorrect or unsubstantiated: A would imply BPP $=$ P, which is open; B would imply BPP $=$ PP, which is not known and widely believed false; D and E assert proper containments that are not justified since we have equality StrongPP $=$ BPP.", "answer": "$$\\boxed{C}$$", "id": "1454728"}, {"introduction": "A fundamental way to characterize a complexity class is by studying its closure properties, such as whether the union of two languages in the class also belongs to the class. This problem invites you to investigate if PP is closed under the union operation using a straightforward, intuitive construction [@problem_id:1454737]. This exercise is a critical test of your understanding of the fine details of the PP definition, particularly the strict inequality, and it demonstrates why seemingly simple approaches can sometimes fail in complexity theory.", "problem": "In computational complexity theory, the class PP (Probabilistic Polynomial time) captures decision problems solvable by a probabilistic algorithm in polynomial time, with an error probability of less than 1/2. Formally, a language $L$ is in PP if there exists a polynomial-time Probabilistic Turing Machine (PTM), let's call it $M$, such that for any input string $x$:\n- If $x \\in L$, the probability that $M$ accepts $x$ is strictly greater than 1/2.\n- If $x \\notin L$, the probability that $M$ accepts $x$ is less than or equal to 1/2.\n\nSuppose two research teams have developed PP algorithms for two different languages, $L_1$ and $L_2$. Let $M_1$ and $M_2$ be the PTMs that decide $L_1$ and $L_2$ respectively, according to the definition of PP. A new team wants to build a PTM, $M_{new}$, to decide the union of these two languages, $L_{union} = L_1 \\cup L_2$.\n\nThey propose the following algorithm for $M_{new}$ on an input $x$:\n1. Flip a single, fair, independent random coin.\n2. If the coin comes up heads, run the machine $M_1$ on input $x$ and output whatever $M_1$ outputs.\n3. If the coin comes up tails, run the machine $M_2$ on input $x$ and output whatever $M_2$ outputs.\n\nThe random choices made by $M_1$ and $M_2$ are independent of each other and of the initial coin flip. Let $p_1(x)$ be the acceptance probability of $M_1$ on input $x$, and $p_2(x)$ be the acceptance probability of $M_2$ on input $x$. Let $p_{new}(x)$ be the acceptance probability of the constructed machine $M_{new}$ on input $x$.\n\nWhich of the following statements provides the most accurate analysis of the proposed machine $M_{new}$?\n\nA. The machine $M_{new}$ is a valid PP machine for $L_1 \\cup L_2$ because for any $x \\in L_1 \\cup L_2$, at least one of $p_1(x)$ or $p_2(x)$ must be greater than 1/2, which guarantees that $p_{new}(x)  1/2$.\n\nB. The machine $M_{new}$ fails because for an input $x \\notin L_1 \\cup L_2$, the acceptance probability $p_{new}(x)$ could be greater than 1/2.\n\nC. The machine $M_{new}$ is a valid PP machine for $L_1 \\cup L_2$ because it correctly handles both the case where $x \\in L_1 \\cup L_2$ and the case where $x \\notin L_1 \\cup L_2$ according to the PP definition.\n\nD. The machine $M_{new}$ is not a valid PP machine for $L_1 \\cup L_2$ because there can exist an input $x \\in L_1 \\cup L_2$ for which the acceptance probability $p_{new}(x)$ is exactly 1/2.\n\nE. The machine $M_{new}$ is not a valid PP machine for $L_1 \\cup L_2$ because its runtime is not guaranteed to be polynomial.", "solution": "Let's analyze the proposed PTM $M_{new}$ and determine if it correctly decides the language $L_{union} = L_1 \\cup L_2$ in the complexity class PP.\n\nFirst, we determine the acceptance probability $p_{new}(x)$ of $M_{new}$ on an input $x$. The algorithm for $M_{new}$ involves an initial coin flip.\n- With probability 1/2 (heads), the machine runs $M_1$, which accepts with probability $p_1(x)$.\n- With probability 1/2 (tails), the machine runs $M_2$, which accepts with probability $p_2(x)$.\nBy the law of total probability, the overall acceptance probability $p_{new}(x)$ is the weighted average of the conditional probabilities:\n$$p_{new}(x) = \\frac{1}{2} \\cdot p_1(x) + \\frac{1}{2} \\cdot p_2(x) = \\frac{p_1(x) + p_2(x)}{2}$$\n\nNow, we must check if this acceptance probability satisfies the conditions for PP for the language $L_{union} = L_1 \\cup L_2$. The conditions are:\n1. If $x \\in L_{union}$, then $p_{new}(x)  1/2$.\n2. If $x \\notin L_{union}$, then $p_{new}(x) \\le 1/2$.\n\nLet's analyze the second condition first (the \"no\" case).\nIf $x \\notin L_1 \\cup L_2$, it means that $x \\notin L_1$ AND $x \\notin L_2$.\nAccording to the PP definition for $M_1$ and $M_2$:\n- $x \\notin L_1 \\implies p_1(x) \\le 1/2$.\n- $x \\notin L_2 \\implies p_2(x) \\le 1/2$.\nSubstituting these into the expression for $p_{new}(x)$:\n$$p_{new}(x) = \\frac{p_1(x) + p_2(x)}{2} \\le \\frac{1/2 + 1/2}{2} = \\frac{1}{2}$$\nSo, for any $x \\notin L_1 \\cup L_2$, we have $p_{new}(x) \\le 1/2$. This condition is satisfied. This eliminates option B.\n\nNow let's analyze the first condition (the \"yes\" case).\nIf $x \\in L_1 \\cup L_2$, it means that $x \\in L_1$ OR $x \\in L_2$ (or both). We need to verify if $p_{new}(x)  1/2$ is always true in this case.\nLet's consider the sub-cases:\n- Sub-case 1: $x \\in L_1$ and $x \\in L_2$.\n  Then $p_1(x)1/2$ and $p_2(x)1/2$.\n  $p_{new}(x) = \\frac{p_1(x) + p_2(x)}{2}  \\frac{1/2 + 1/2}{2} = 1/2$. This works.\n- Sub-case 2: $x \\in L_1$ and $x \\notin L_2$.\n  Then $p_1(x)  1/2$ and $p_2(x) \\le 1/2$.\n  $p_{new}(x) = \\frac{p_1(x) + p_2(x)}{2}$.\n  Here, we need to check if this expression is always strictly greater than 1/2. Let's try to construct a counterexample. The definition of PP allows the probabilities to be any value satisfying the inequalities.\n  Suppose for a specific input $x_0 \\in L_1$, the machine $M_1$ has an acceptance probability of $p_1(x_0) = 3/4$. This satisfies $p_1(x_0)  1/2$.\n  Suppose for the same input $x_0$, $x_0 \\notin L_2$, and the machine $M_2$ has an acceptance probability of $p_2(x_0) = 1/4$. This satisfies $p_2(x_0) \\le 1/2$.\n  In this scenario, $x_0 \\in L_1 \\cup L_2$. Let's calculate $p_{new}(x_0)$:\n  $$p_{new}(x_0) = \\frac{p_1(x_0) + p_2(x_0)}{2} = \\frac{3/4 + 1/4}{2} = \\frac{1}{2}$$\n  The result is exactly 1/2. However, for an input in the language ($x_0 \\in L_1 \\cup L_2$), a PP machine must accept with a probability *strictly* greater than 1/2. Since $p_{new}(x_0) = 1/2$, the machine $M_{new}$ fails to satisfy the PP condition for this input.\n  Therefore, the proposed construction is not a valid PP machine for $L_1 \\cup L_2$.\n\nThis analysis confirms that the construction can fail for \"yes\" instances, specifically when the probabilities sum to exactly 1. So, statement D is the correct one.\nStatement A is incorrect because, as shown by the counterexample, the condition is not guaranteed.\nStatement C is incorrect because the machine fails for certain \"yes\" instances.\nStatement E is incorrect because $M_1$ and $M_2$ run in polynomial time, and $M_{new}$ simply runs one of them, so its runtime is also polynomial.", "answer": "$$\\boxed{D}$$", "id": "1454737"}]}