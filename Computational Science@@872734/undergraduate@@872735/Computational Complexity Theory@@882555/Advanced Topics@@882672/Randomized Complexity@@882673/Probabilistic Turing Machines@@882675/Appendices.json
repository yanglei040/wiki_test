{"hands_on_practices": [{"introduction": "Probabilistic algorithms in the class $\\mathrm{BPP}$ offer efficient solutions but come with a small chance of error. A key strength of this model is our ability to reduce this error significantly through a process called probability amplification. This exercise [@problem_id:1436863] provides a hands-on calculation to demonstrate how running an algorithm multiple times and taking a majority vote can drastically improve its reliability.", "problem": "In the field of computational complexity theory, a decision problem is said to be solvable by a bounded-error probabilistic polynomial-time algorithm if there exists an algorithm that, for any given input, correctly decides whether the input belongs to the language with a probability of at least $\\frac{2}{3}$. This implies the probability of an incorrect answer on any single run is at most $\\frac{1}{3}$.\n\nConsider such an algorithm, let's call it `ALG`, which is being used to validate the integrity of data records. For any given data record, `ALG` provides the correct validation result with a probability of exactly $\\frac{2}{3}$, meaning its error probability is exactly $\\frac{1}{3}$. To improve reliability, an engineer implements an amplification strategy: the algorithm `ALG` is run three independent times on the same input data record, and the final answer is determined by taking the majority vote of the three outcomes.\n\nWhat is the probability that this majority-vote procedure yields an incorrect answer? Express your final answer as a fraction in its simplest form.", "solution": "Let $p$ be the probability that a single run of the algorithm `ALG` produces an incorrect answer. According to the problem statement, we have $p = \\frac{1}{3}$.\nConsequently, the probability that a single run produces the correct answer is $1 - p = 1 - \\frac{1}{3} = \\frac{2}{3}$.\n\nThe amplification strategy involves running the algorithm three independent times and taking the majority vote. The final result from this procedure will be incorrect if and only if the majority of the runs produce an incorrect answer. For three runs, this means that either two out of three runs are incorrect, or all three runs are incorrect.\n\nLet's analyze these two mutually exclusive cases. The runs are independent, so we can model the number of incorrect outcomes using the binomial distribution. Let $n=3$ be the number of trials (runs).\n\nCase 1: Exactly two runs are incorrect.\nThe number of ways to choose which two of the three runs are incorrect is given by the binomial coefficient $\\binom{3}{2}$. The probability of any specific sequence of two incorrect runs and one correct run (e.g., Incorrect-Incorrect-Correct) is $p \\cdot p \\cdot (1-p) = p^2 (1-p)$.\nSo, the total probability of having exactly two incorrect runs is:\n$$P(\\text{2 incorrect}) = \\binom{3}{2} p^2 (1-p)$$\nWe know $\\binom{3}{2} = \\frac{3!}{2!(3-2)!} = \\frac{3 \\cdot 2 \\cdot 1}{(2 \\cdot 1)(1)} = 3$.\nSubstituting the values of $p$ and $1-p$:\n$$P(\\text{2 incorrect}) = 3 \\left(\\frac{1}{3}\\right)^2 \\left(\\frac{2}{3}\\right) = 3 \\cdot \\frac{1}{9} \\cdot \\frac{2}{3} = \\frac{6}{27}$$\n\nCase 2: All three runs are incorrect.\nThe number of ways for this to happen is $\\binom{3}{3} = 1$. The probability of this specific sequence (Incorrect-Incorrect-Incorrect) is $p \\cdot p \\cdot p = p^3$.\nSo, the total probability of having three incorrect runs is:\n$$P(\\text{3 incorrect}) = \\binom{3}{3} p^3 (1-p)^0 = 1 \\cdot p^3$$\nSubstituting the value of $p$:\n$$P(\\text{3 incorrect}) = \\left(\\frac{1}{3}\\right)^3 = \\frac{1}{27}$$\n\nThe total probability of the majority-vote procedure being incorrect is the sum of the probabilities of these two cases:\n$$P(\\text{failure}) = P(\\text{2 incorrect}) + P(\\text{3 incorrect})$$\n$$P(\\text{failure}) = \\frac{6}{27} + \\frac{1}{27} = \\frac{7}{27}$$\n\nThe final probability is $\\frac{7}{27}$. This fraction is already in its simplest form since 7 and 27 are coprime.", "answer": "$$\\boxed{\\frac{7}{27}}$$", "id": "1436863"}, {"introduction": "Algorithms with one-sided error, which define classes like $\\mathrm{RP}$ and $\\mathrm{co-RP}$, offer a different model of probabilistic computation where one type of answer is always definitive. This property allows for a powerful error reduction strategy, as a single correct run can reveal the true answer. In this practice [@problem_id:1436854], you will calculate the minimum number of trials needed to guarantee a high level of confidence, a fundamental task in the practical application of randomized algorithms.", "problem": "A computer scientist is designing an algorithm for a decision problem concerning a language $L$. The algorithm uses a Probabilistic Turing Machine (PTM), which is a variant of a standard Turing machine that can make random choices at each step. This PTM is intended to be an example of an algorithm for a language in the complexity class known as **RP** (Randomized Polynomial time).\n\nThe behavior of this specific PTM, denoted as $M$, is characterized as follows for any given input string $x$:\n- If the string $x$ belongs to the language $L$ (i.e., $x \\in L$), the machine $M$ will halt and correctly output 'accept' with a probability of $3/4$. It will erroneously halt and output 'reject' with a probability of $1/4$.\n- If the string $x$ does not belong to the language $L$ (i.e., $x \\notin L$), the machine $M$ is guaranteed to halt and output 'reject'.\n\nTo improve the reliability of the result, the scientist proposes an amplified algorithm, denoted $M_k$. This new algorithm executes the original PTM, $M$, for $k$ independent trials on the same input string $x$. The decision rule for $M_k$ is defined as follows: it will output 'accept' for the input $x$ if at least one of the $k$ trials results in an 'accept'; otherwise, if all $k$ trials result in 'reject', $M_k$ will output 'reject'.\n\nWhat is the minimum integer number of trials, $k$, that must be performed to ensure that the probability of the amplified algorithm $M_k$ erroneously rejecting an input that is in the language $L$ is strictly less than $1\\%$?", "solution": "For one independent run of $M$ on an input $x \\in L$, the error event “reject” occurs with probability $\\frac{1}{4}$. The amplified algorithm $M_{k}$ rejects only if all $k$ independent runs reject. By independence, the probability that all $k$ runs reject when $x \\in L$ is\n$$\n\\left(\\frac{1}{4}\\right)^{k}.\n$$\nWe require this error probability to be strictly less than $\\frac{1}{100}$:\n$$\n\\left(\\frac{1}{4}\\right)^{k} < \\frac{1}{100}.\n$$\nEquivalently,\n$$\n4^{k} > 100.\n$$\nTaking natural logarithms,\n$$\nk \\ln 4 > \\ln 100 = 2 \\ln 10,\n$$\nso\n$$\nk > \\frac{2 \\ln 10}{\\ln 4}.\n$$\nTo find the smallest integer $k$ satisfying this strict inequality, we can test small integer values for $k$.\nFor $k=3$, $4^{3} = 64$, which is not greater than $100$.\nFor $k=4$, $4^{4} = 256$, which is greater than $100$.\nSo $k=4$ suffices, while $k=3$ does not. Hence the minimum integer is $k=4$. The corresponding error probability is $\\left(\\frac{1}{4}\\right)^{4} = \\frac{1}{256}$, which is less than $\\frac{1}{100}$.", "answer": "$$\\boxed{4}$$", "id": "1436854"}, {"introduction": "The precise definitions of complexity classes are crucial to their power and relationships. This final practice moves from calculation to a conceptual deep dive, asking you to consider the consequences of relaxing the definition of $\\mathrm{RP}$ [@problem_id:1436826]. By investigating a hypothetical class $\\mathrm{RP_{weak}}$, you will uncover a surprising and profound equivalence with the class $\\mathrm{NP}$, revealing a deep connection between randomness and nondeterminism.", "problem": "In computational complexity theory, a probabilistic Turing machine is a variant of a standard Turing machine that can employ randomness. A language $L$ is said to be in the complexity class **RP** (Randomized Polynomial Time) if there exists a polynomial-time probabilistic Turing machine $M$ with the following properties for any input string $x$:\n1.  If $x$ is in the language $L$ (a \"yes-instance\"), the probability that $M$ outputs \"accept\" is at least $1/2$. Formally, $x \\in L \\implies \\Pr[M(x) \\text{ accepts}] \\geq 1/2$.\n2.  If $x$ is not in the language $L$ (a \"no-instance\"), the probability that $M$ outputs \"accept\" is exactly $0$. Formally, $x \\notin L \\implies \\Pr[M(x) \\text{ accepts}] = 0$.\n\nA computer science student proposes a \"weaker\" version of this class, which they call `RP_weak`. The definition is identical to **RP** except for the condition on \"yes-instances,\" which is relaxed. Specifically, a language $L$ is in `RP_weak` if there exists a polynomial-time probabilistic Turing machine $M'$ such that for any input string $x$:\n1.  If $x \\in L$, the probability that $M'$ outputs \"accept\" is strictly greater than $0$. Formally, $x \\in L \\implies \\Pr[M'(x) \\text{ accepts}] > 0$.\n2.  If $x \\notin L$, the probability that $M'$ outputs \"accept\" is exactly $0$. Formally, $x \\notin L \\implies \\Pr[M'(x) \\text{ accepts}] = 0$.\n\nThis new definition seems to allow for algorithms that have an astronomically small, but non-zero, chance of success on yes-instances. The question is whether this change significantly alters the computational power of the class. Which of the following well-known complexity classes is provably equivalent to `RP_weak`?\n\nRecall the definition of **NP** (Nondeterministic Polynomial Time): A language $L$ is in **NP** if for every $x \\in L$, there exists a 'certificate' or 'witness' string $y$ of length polynomial in the length of $x$, such that a deterministic polynomial-time Turing machine (the 'verifier') can check that $y$ proves $x \\in L$. For $x \\notin L$, no such certificate exists.\n\nA. `P` (Polynomial Time)\nB. `RP` (Randomized Polynomial Time)\nC. `BPP` (Bounded-error Probabilistic Polynomial Time)\nD. `NP` (Nondeterministic Polynomial Time)\nE. `PSPACE` (Polynomial Space)", "solution": "Let $L$ be in $\\text{RP\\_weak}$, witnessed by a probabilistic Turing machine $M'$ that runs in polynomial time. By the time bound, there exists a polynomial $p$ such that on inputs of length $n$, $M'$ uses at most $p(n)$ random bits. For any fixed input $x$, each execution of $M'$ corresponds to fixing a random string $r \\in \\{0,1\\}^{p(|x|)}$ and running the deterministic computation of $M'$ with randomness set to $r$.\n\nFirst inclusion $\\text{RP\\_weak} \\subseteq \\text{NP}$: Suppose $x \\in L$. By definition, $\\Pr[M'(x) \\text{ accepts}] > 0$. Since the sample space is finite, this implies that there exists at least one random string $r \\in \\{0,1\\}^{p(|x|)}$ such that the deterministic computation $M'(x;r)$ accepts. Consider the nondeterministic verifier $V$ that on input $(x,r)$ simulates $M'$ on $x$ with random tape set to $r$ and accepts if and only if $M'$ accepts. The simulation is deterministic and runs in time polynomial in $|x|$ because $M'$ does and $|r| \\leq p(|x|)$. If $x \\notin L$, then by definition $\\Pr[M'(x) \\text{ accepts}] = 0$, which implies that for all $r$, $M'(x;r)$ rejects. Hence there is no accepting witness. Therefore $L \\in \\text{NP}$.\n\nSecond inclusion $\\text{NP} \\subseteq \\text{RP\\_weak}$: Let $L \\in \\text{NP}$ with verifier $V$ running in time polynomial in $|x|$. There exists a polynomial $p$ such that for every $x \\in L$, there is a witness $y \\in \\{0,1\\}^{p(|x|)}$ with $V(x,y)$ accepting, and for $x \\notin L$ no such $y$ exists. Define a probabilistic machine $M'$ as follows on input $x$: sample a uniformly random string $y \\in \\{0,1\\}^{p(|x|)}$, run $V(x,y)$ deterministically, and accept if and only if $V$ accepts. This $M'$ runs in polynomial time. If $x \\in L$, then there exists $y^{\\ast}$ with $V(x,y^{\\ast})$ accepting, so\n$$\n\\Pr[M'(x) \\text{ accepts}] \\geq \\Pr[y = y^{\\ast}] = 2^{-p(|x|)} > 0.\n$$\nIf $x \\notin L$, then for all $y$, $V(x,y)$ rejects, so\n$$\n\\Pr[M'(x) \\text{ accepts}] = 0.\n$$\nThus $L \\in \\text{RP\\_weak}$.\n\nCombining both inclusions gives $\\text{RP\\_weak} = \\text{NP}$. Therefore the class provably equivalent to $\\text{RP\\_weak}$ is $\\text{NP}$, which corresponds to option D.", "answer": "$$\\boxed{D}$$", "id": "1436826"}]}