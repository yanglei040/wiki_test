{"hands_on_practices": [{"introduction": "We begin our exploration of the NC hierarchy with the most foundational class, $NC^0$. This class captures problems that are \"embarrassingly parallel,\" where each piece of the output can be computed independently and with minimal information from the input. The following problem on Gray code conversion is a perfect illustration of this principle, challenging you to analyze the direct relationship between input and output bits to determine if the problem can be solved by a circuit of constant depth [@problem_id:1459534].", "problem": "In the field of computational complexity theory, the NC hierarchy (Nick's Class) is used to classify problems that are considered \"efficiently parallelizable.\" A problem is said to be in the class $NC^k$ if it can be solved by a uniform family of Boolean circuits with a size that is polynomial in the input size $n$ and a depth that is polylogarithmic, specifically $O(\\log^k n)$. The class $NC^0$ corresponds to problems solvable with constant-depth, polynomial-size circuits, where each output bit can only depend on a constant number of input bits.\n\nConsider the problem of converting an $n$-bit binary integer into its corresponding $n$-bit reflected binary code, also known as the Gray code. Let the input binary representation be $B = b_{n-1}b_{n-2}...b_1b_0$ and the output Gray code be $G = g_{n-1}g_{n-2}...g_1g_0$. The conversion is defined by the following rules:\n- The most significant bit remains the same: $g_{n-1} = b_{n-1}$.\n- For all other bits (where $0 \\le i  n-1$), the Gray code bit is the exclusive OR (XOR) of the corresponding binary bit and the next more significant binary bit: $g_i = b_i \\oplus b_{i+1}$.\n\nBased on the provided definitions, determine the most precise classification for this conversion problem within the NC hierarchy.\n\nA. The problem is in $NC^0$.\n\nB. The problem is in $NC^1$, but not in $NC^0$.\n\nC. The problem is in $NC^2$, but not in $NC^1$.\n\nD. The problem is P-complete and is therefore believed not to be in any $NC^k$ class.\n\nE. The classification depends on whether $n$ is a power of two.", "solution": "We are asked to classify, within the NC hierarchy, the mapping from an $n$-bit binary number $B = b_{n-1}b_{n-2}\\dots b_{1}b_{0}$ to its $n$-bit Gray code $G = g_{n-1}g_{n-2}\\dots g_{1}g_{0}$ defined by\n$$\ng_{n-1} = b_{n-1}, \\quad g_{i} = b_{i} \\oplus b_{i+1} \\quad \\text{for } 0 \\leq i  n-1.\n$$\nBy definition, a language (or function) is in $NC^{k}$ if there exists a uniform family of Boolean circuits of polynomial size and depth $O\\!\\left((\\log n)^{k}\\right)$ computing it, with bounded fan-in. The class $NC^{0}$ consists of functions computable by uniform families of constant-depth, polynomial-size circuits with bounded fan-in, equivalently where each output bit depends on only $O(1)$ input bits.\n\nFor each $i$ with $0 \\leq i  n-1$, the output bit $g_{i}$ depends only on the two input bits $b_{i}$ and $b_{i+1}$, and for $i = n-1$ we have $g_{n-1}$ depending only on $b_{n-1}$. Thus each output bit depends on a constant number of inputs, independent of $n$. Moreover, each $g_{i}$ can be computed by a constant-depth bounded fan-in circuit over $\\{\\land,\\lor,\\neg\\}$, since the exclusive-or of two bits has the standard Boolean expression\n$$\nb_{i} \\oplus b_{i+1} \\;=\\; (b_{i} \\land \\neg b_{i+1}) \\;\\lor\\; (\\neg b_{i} \\land b_{i+1}).\n$$\nThis realization uses at most one layer of negations feeding a layer of binary $\\land$ gates, feeding a single binary $\\lor$ gate, giving constant depth (for example, depth $3$ with bounded fan-in $2$). The most significant bit $g_{n-1} = b_{n-1}$ is implemented by a wire. Therefore, computing all $n$ output bits in parallel yields a circuit of depth that is a fixed constant, independent of $n$, and of size $O(n)$, which is polynomial in $n$.\n\nRegarding uniformity, the wiring pattern is completely regular: for each $i$, the gates for $g_{i}$ connect only to $b_{i}$ and $b_{i+1}$ (or to $b_{n-1}$ alone when $i = n-1$). Hence a standard uniformity condition (such as DLOGTIME-uniformity) is satisfied, because a deterministic Turing machine can, given $n$ and gate indices encoded in binary, compute the connections in time $O(\\log n)$.\n\nThus the conversion mapping is computable by a uniform family of constant-depth, polynomial-size, bounded-fan-in Boolean circuits in which each output bit depends on $O(1)$ input bits. Therefore the problem is in $NC^{0}$. Since $NC^{0} \\subseteq NC^{1} \\subseteq NC^{2} \\subseteq \\dots$, the most precise classification among the given options is that it is in $NC^{0}$.", "answer": "$$\\boxed{A}$$", "id": "1459534"}, {"introduction": "Many computational tasks are not as localized as those in $NC^0$ and require combining information from across the entire input. The class $NC^1$ characterizes problems solvable in logarithmic time, often using powerful parallel algorithmic techniques like prefix scans. The \"First-One\" problem is a classic example that appears sequential at first glance but can be solved with remarkable efficiency in parallel, demonstrating the power of $O(\\log n)$ depth circuits [@problem_id:1459518].", "problem": "In the field of parallel computing, understanding the inherent parallelism of a problem is crucial for designing efficient algorithms. The complexity class known as Nick's Class (NC) provides a framework for this analysis. A computational problem is said to belong to NC if it can be solved on a parallel computer in polylogarithmic time (i.e., time proportional to $O(\\log^k n)$ for some constant $k$, where $n$ is the input size) using a number of processors that is polynomial in $n$. More specifically, a problem is in $NC^k$ if its parallel time complexity is $O(\\log^k n)$.\n\nConsider the fundamental \"First-One\" problem, which is a common subroutine in parallel data processing. The problem is defined as follows: Given a binary string $S$ of length $n$, represented as an array of bits $S[1..n]$, find the smallest index $i$ such that $S[i]=1$. If the string contains no '1's, the output should be 0.\n\nBased on these definitions, determine the most precise classification for the \"First-One\" problem within the NC hierarchy.\n\nA. The problem is in $NC^1$.\n\nB. The problem is P-complete, which implies it is unlikely to be in NC.\n\nC. The problem requires $\\Omega(n)$ time to solve, even on a parallel machine, and thus is not in NC.\n\nD. The problem is in $NC^2$ but is not in $NC^1$.", "solution": "We recall the NC definition: a problem is in NC if it can be solved in time $O(\\log^{k} n)$ for some fixed $k \\in \\mathbb{N}$ using a number of processors polynomial in $n$. The class NC$^{1}$ consists of problems solvable with depth $O(\\log n)$ using polynomially many processors and bounded fan-in.\n\nWe construct an $O(\\log n)$-depth parallel algorithm for the First-One function. Let the input be $S[1],\\dots,S[n] \\in \\{0,1\\}$. Define the prefix-OR array $Q[1],\\dots,Q[n]$ by\n$$\nQ[i] \\equiv \\bigvee_{j=1}^{i} S[j].\n$$\nThe Boolean OR operation is associative, so we can compute all $Q[i]$ with a standard parallel prefix method in $O(\\log n)$ depth and polynomial work. One explicit method is recursive doubling: define $R^{(0)}[i] = S[i]$ for all $i$, and for $t=1,2,\\dots,\\lceil \\log_{2} n \\rceil$ set\n$$\nR^{(t)}[i] = \\begin{cases}\nR^{(t-1)}[i] \\lor R^{(t-1)}[i-2^{t-1}],  \\text{if } i2^{t-1},\\\\\nR^{(t-1)}[i],  \\text{otherwise}.\n\\end{cases}\n$$\nEach stage uses only fan-in-$2$ OR gates, so has constant depth, and there are $\\lceil \\log_{2} n \\rceil$ stages. At the end, $Q[i] = R^{(\\lceil \\log_{2} n \\rceil)}[i]$ for all $i$, and the total depth is $O(\\log n)$ with $O(n)$ processors per stage, hence polynomially many processors overall.\n\nIntroduce $Q[0] \\equiv 0$ and define the marker array $M[1],\\dots,M[n]$ by\n$$\nM[i] \\equiv S[i] \\land \\lnot Q[i-1] = Q[i] \\land \\lnot Q[i-1].\n$$\nBy construction, $M[i]=1$ if and only if $i$ is the smallest index with $S[i]=1$; otherwise $M[i]=0$. If the string has no ones, then $Q[n]=0$ and thus $M[i]=0$ for all $i$.\n\nWe now encode the index as a binary number in the range $\\{0,1,\\dots,n\\}$. Let $L \\equiv \\lceil \\log_{2}(n+1) \\rceil$. For each bit position $b \\in \\{0,1,\\dots,L-1\\}$, define the $b$-th output bit $B[b]$ by\n$$\nB[b] \\equiv \\bigvee_{i=1}^{n} \\left( M[i] \\land \\mathrm{bit}_{b}(i) \\right),\n$$\nwhere $\\mathrm{bit}_{b}(i) \\in \\{0,1\\}$ is the $b$-th binary digit of $i$. Since at most one $M[i]$ equals $1$, these OR-reductions simply select the bits of that unique index; if all $M[i]=0$, then all $B[b]=0$, representing $0$. Each $B[b]$ is an OR over $n$ terms of fan-in $2$ OR gates arranged in a balanced binary tree, giving depth $O(\\log n)$. All $L$ bits are computed in parallel, so the depth for this stage remains $O(\\log n)$, and the number of processors is $O(n L)$, which is polynomial in $n$.\n\nCombining the stages, the total parallel time (circuit depth) is\n$$\nO(\\log n) + O(1) + O(\\log n) = O(\\log n),\n$$\nwith a number of processors polynomial in $n$ and bounded fan-in gates. Therefore, the First-One problem is in NC$^{1}$.\n\nThis shows option A is correct. Option B is false because the problem is not P-complete; it admits an NC$^{1}$ algorithm. Option C is false because the above algorithm runs in $O(\\log n)$ time on a parallel machine. Option D is false because we have exhibited an NC$^{1}$ algorithm; moreover, known separations do not place it outside NC$^{1}$.", "answer": "$$\\boxed{A}$$", "id": "1459518"}, {"introduction": "After classifying individual problems, it is crucial to understand how these classifications behave when we combine algorithms. This practice explores the closure properties of NC classes, a key concept for building complex parallel software from smaller, efficient modules. By analyzing the composition of two $NC^1$ functions, you will discover a fundamental structural property of the NC hierarchy and appreciate why these classes provide a robust framework for parallel computation [@problem_id:1459527].", "problem": "In the theory of parallel computation, the complexity class known as Nick's Class (NC) provides a framework for identifying problems that can be solved efficiently on parallel computers. A problem is considered to be in the class $NC^k$ for some integer $k \\ge 0$ if it can be solved by a uniform family of Boolean circuits that satisfy two key properties. For an input of size $n$, the circuit must have:\n1.  A size (number of gates) that is polynomial in $n$, i.e., $n^{O(1)}$.\n2.  A depth (longest path from an input to an output) that is polylogarithmic in $n$, specifically $O(\\log^k n)$.\nThe gates in these circuits are assumed to have a constant fan-in (number of inputs, typically 2).\n\nConsider two functions, $f$ and $g$, which map bit strings to bit strings. Both functions are known to be computable by algorithms belonging to the complexity class $NC^1$. A new, composite function $h$ is created by chaining these two functions together, such that for any input bit string $x$, the output is $h(x) = g(f(x))$.\n\nBased on the properties of circuit composition, what is the tightest and most accurate classification for the composite function $h$?\n\nA. $NC^0$\n\nB. $NC^1$\n\nC. $NC^2$\n\nD. **P**\n\nE. Not necessarily in any **NC** class.", "solution": "Let $f:\\{0,1\\}^{n} \\to \\{0,1\\}^{m(n)}$ and $g:\\{0,1\\}^{m} \\to \\{0,1\\}^{\\ell(m)}$ be computable by uniform $NC^{1}$ circuit families. By definition, there exist circuit families $\\{C_{f,n}\\}$ and $\\{C_{g,m}\\}$ with the following properties:\n- Size bounds: $\\mathrm{size}(C_{f,n}) = n^{O(1)}$ and $\\mathrm{size}(C_{g,m}) = m^{O(1)}$.\n- Depth bounds: $\\mathrm{depth}(C_{f,n}) = O(\\log n)$ and $\\mathrm{depth}(C_{g,m}) = O(\\log m)$.\n- Constant fan-in for all gates.\n\nSince $C_{f,n}$ has polynomial size in $n$, the number of output bits $m(n)$ satisfies $m(n) \\le n^{O(1)}$; otherwise, the circuit could not even present that many outputs within polynomial description size.\n\nDefine the composite function $h(x) = g(f(x))$. To compute $h$ on inputs of length $n$, construct the circuit $C_{h,n}$ by feeding the $m(n)$ outputs of $C_{f,n}$ as the $m(n)$ inputs to $C_{g,m(n)}$. Then:\n- The size satisfies\n$$\n\\mathrm{size}(C_{h,n}) \\le \\mathrm{size}(C_{f,n}) + \\mathrm{size}(C_{g,m(n)}) = n^{O(1)} + \\left(m(n)\\right)^{O(1)} = n^{O(1)},\n$$\nbecause $m(n) \\le n^{O(1)}$ implies $\\left(m(n)\\right)^{O(1)} = n^{O(1)}$.\n- The depth satisfies\n$$\n\\mathrm{depth}(C_{h,n}) \\le \\mathrm{depth}(C_{f,n}) + \\mathrm{depth}(C_{g,m(n)}) = O(\\log n) + O\\!\\left(\\log m(n)\\right).\n$$\nUsing $m(n) \\le n^{c}$ for some constant $c  0$, we have\n$$\n\\log m(n) \\le \\log\\!\\left(n^{c}\\right) = c \\log n,\n$$\nso\n$$\n\\mathrm{depth}(C_{h,n}) = O(\\log n).\n$$\nThe composed circuit retains constant fan-in and uniformity (standard uniformity notions such as logspace uniformity are closed under composition). Therefore, $h$ is computable by a uniform family of polynomial-size, $O(\\log n)$-depth, constant fan-in circuits, i.e., $h \\in NC^{1}$.\n\nThis is tight: in general, composing two nontrivial $NC^{1}$ functions does not drop the depth to $O(1)$, so $NC^{0}$ is too small; while $NC^{2}$ and $P$ are valid supersets, they are not the tightest classification.\n\nHence, the tightest and most accurate classification is $NC^{1}$.", "answer": "$$\\boxed{B}$$", "id": "1459527"}]}