{"hands_on_practices": [{"introduction": "The heart of Smoothed-Particle Hydrodynamics (SPH) is the smoothing kernel, a weighting function that distributes the properties of a single particle over a small, finite region of space. For the SPH method to accurately conserve fundamental quantities like mass, this kernel must be normalized, meaning its integral over all space must equal one. This foundational exercise [@problem_id:3194379] guides you through numerically verifying this \"unity property\" for the widely used cubic spline kernel, reinforcing your understanding of the kernel's mathematical structure and the role of its normalization constants across different dimensions.", "problem": "You are given the task to design and implement a numerical experiment that verifies kernel normalization in Smoothed-Particle Hydrodynamics (SPH). The objective is to numerically approximate the spatial integral of a chosen SPH kernel $W(\\mathbf{r}, h)$ and test whether it is close to $1$ for a range of smoothing lengths $h$. The experiment should be formulated in purely mathematical and algorithmic terms and executed by a single, complete program.\n\nFundamental base: Use the standard, widely adopted cubic spline kernel definition from Smoothed-Particle Hydrodynamics (SPH). The kernel is radially symmetric, so $W(\\mathbf{r}, h) = W(r, h)$ with $r = \\lVert \\mathbf{r} \\rVert$. The cubic spline kernel is defined by the piecewise function\n$$\nW(r,h) = \\frac{\\sigma_d}{h^d}\n\\begin{cases}\n1 - \\frac{3}{2} q^2 + \\frac{3}{4} q^3,  0 \\le q \\le 1, \\\\\n\\frac{1}{4} (2 - q)^3,  1  q \\le 2, \\\\\n0,  q > 2,\n\\end{cases}\n$$\nwhere $q = \\frac{r}{h}$, $d \\in \\{1, 2, 3\\}$ is the spatial dimension, and $\\sigma_d$ is the dimension-dependent normalization constant:\n- For $d = 1$, $\\sigma_1 = \\frac{2}{3}$.\n- For $d = 2$, $\\sigma_2 = \\frac{10}{7\\pi}$.\n- For $d = 3$, $\\sigma_3 = \\frac{1}{\\pi}$.\n\nExperiment design requirements:\n- Numerically approximate the spatial integral $\\int_{\\mathbb{R}^d} W(\\mathbf{r}, h)\\, dV$ using a radial reduction. Since $W$ depends only on $r$, you must express the volume element $dV$ in terms of $r$:\n    - For $d = 1$, $dV = 2\\, dr$ over $r \\in [0, 2h]$.\n    - For $d = 2$, $dV = 2\\pi r\\, dr$ over $r \\in [0, 2h]$.\n    - For $d = 3$, $dV = 4\\pi r^2\\, dr$ over $r \\in [0, 2h]$.\n- Perform a numerical integration on the interval $r \\in [0, 2h]$ using a uniform partition of $N$ sample points and the composite trapezoid rule.\n- For each test case, compute the numerical approximation\n$$\nI(d,h,N) \\approx \\int_0^{2h} W(r,h)\\, S_d(r)\\, dr,\n$$\nwhere $S_d(r)$ is the corresponding radial surface measure factor, specifically $S_1(r) = 2$, $S_2(r) = 2\\pi r$, and $S_3(r) = 4\\pi r^2$.\n\nOutput specification:\n- For each test case, return a boolean indicating whether the numerical approximation $I(d,h,N)$ is within a tolerance of $10^{-5}$ of $1$, i.e., whether $\\lvert I(d,h,N) - 1 \\rvert \\le 10^{-5}$.\n- The final program output must be a single line containing the results for all test cases as a comma-separated list enclosed in square brackets (for example, $[true,false,true]$ with Python booleans written as $True$ or $False$).\n\nUnit specification:\n- The integral $\\int W\\, dV$ is dimensionless. All reported booleans are unitless.\n\nTest suite:\nEvaluate the following test cases, each given by the tuple $(d,h,N)$:\n1. $(1, 0.05, 100)$: Happy path in one dimension with small $h$ and moderate resolution $N$.\n2. $(2, 0.05, 100)$: Happy path in two dimensions with small $h$ and moderate resolution $N$.\n3. $(3, 0.05, 100)$: Happy path in three dimensions with small $h$ and moderate resolution $N$.\n4. $(3, 1.0, 1000)$: Larger $h$ in three dimensions with high resolution $N$.\n5. $(2, 0.5, 600)$: Moderate $h$ in two dimensions with high resolution $N$.\n6. $(1, 2.0, 1200)$: Large $h$ in one dimension with high resolution $N$.\n\nYour program must implement the above and produce a single line of output containing the six booleans in order as a comma-separated list enclosed in square brackets.", "solution": "The user-provided problem is valid. It is a well-posed, scientifically grounded task from the field of computational science, specifically concerning the verification of a fundamental property of Smoothed-Particle Hydrodynamics (SPH) kernels. All necessary information is provided, and the task is to implement a numerical experiment based on standard mathematical and algorithmic principles.\n\nThe solution is designed based on the following principles and their translation into an algorithm.\n\n### 1. The Principle of Kernel Normalization\n\nIn SPH, physical quantities are approximated by summing contributions from neighboring particles, weighted by a kernel function $W$. For the method to be accurate and conserve quantities like mass, the kernel must be normalized. This means its integral over all space must be equal to one:\n$$\n\\int_{\\mathbb{R}^d} W(\\mathbf{r}, h) \\, dV = 1\n$$\nHere, $d$ is the number of spatial dimensions, $h$ is the smoothing length which defines the kernel's support size, and $dV$ is the volume element. The problem asks to numerically verify this property for the cubic spline kernel.\n\n### 2. The Cubic Spline Kernel\n\nThe problem provides the definition of the standard cubic spline kernel, which is a piecewise polynomial function with compact support (it is non-zero only for $r \\le 2h$). Its formula is:\n$$\nW(r,h) = \\frac{\\sigma_d}{h^d}\n\\begin{cases}\n1 - \\frac{3}{2} q^2 + \\frac{3}{4} q^3,  0 \\le q \\le 1, \\\\\n\\frac{1}{4} (2 - q)^3,  1  q \\le 2, \\\\\n0,  q > 2,\n\\end{cases}\n$$\nwhere $r = \\lVert \\mathbf{r} \\rVert$ is the radial distance, $q = r/h$ is the normalized radius, and $\\sigma_d$ is a dimension-dependent constant ($\\sigma_1 = 2/3$, $\\sigma_2 = 10/(7\\pi)$, $\\sigma_3 = 1/\\pi$) specifically chosen to ensure the normalization property holds analytically.\n\nThe algorithmic implementation of this kernel involves creating a function that takes $r$, $h$, and $d$ as inputs. Inside this function, the value of $q$ is computed. Conditional logic is required to select the correct polynomial segment based on the value of $q$. For efficient computation on an array of $r$ values, NumPy's boolean array masking is an ideal choice to apply the piecewise formulas in a vectorized manner.\n\n### 3. Radial Reduction of the Integral\n\nThe kernel $W(r,h)$ is radially symmetric, meaning its value depends only on the distance $r$ from the origin, not on the direction. This symmetry allows for a significant simplification of the $d$-dimensional integral. We can transform the integral from Cartesian coordinates to generalized spherical coordinates. The volume element $dV$ becomes a function of $r$ and angular variables. Integrating over the angular variables first yields a factor that is the surface area of a hypersphere of radius $r$. This reduces the multi-dimensional integral to a one-dimensional integral over the radial coordinate $r$.\n$$\n\\int_{\\mathbb{R}^d} W(\\mathbf{r}, h) \\, dV = \\int_0^\\infty W(r,h) \\, S_d(r) \\, dr\n$$\nwhere $S_d(r)$ is the \"surface measure factor\" provided in the problem statement:\n- For $d=1$: The \"volume\" element is $dx$. The integral is $\\int_{-2h}^{2h} W(x,h) dx$. Due to even symmetry ($W$ depends on $r=|x|$), this is $2 \\int_0^{2h} W(r,h) dr$. Thus, $S_1(r) = 2$.\n- For $d=2$: The volume element is $dV = r \\, dr \\, d\\theta$. Integrating over $\\theta$ from $0$ to $2\\pi$ gives a factor of $2\\pi$. Thus, $S_2(r) = 2\\pi r$.\n- For $d=3$: The volume element is $dV = r^2 \\sin\\theta \\, dr \\, d\\theta \\, d\\phi$. Integrating over the solid angle ($\\int_0^{2\\pi} \\int_0^\\pi \\sin\\theta \\, d\\theta \\, d\\phi$) gives $4\\pi$. Thus, $S_3(r) = 4\\pi r^2$.\n\nSince the kernel has compact support up to $r=2h$ (i.e., $W(r,h) = 0$ for $r > 2h$), the upper limit of integration becomes $2h$. The final integral to be computed numerically is:\n$$\nI(d,h) = \\int_0^{2h} W(r,h) \\, S_d(r) \\, dr\n$$\nThe integrand is $f(r) = W(r,h) S_d(r)$. The algorithm will construct this integrand by first calculating the kernel values $W(r,h)$ and then multiplying by the appropriate factor $S_d(r)$, which is selected based on the dimension $d$.\n\n### 4. Numerical Integration via Composite Trapezoid Rule\n\nTo approximate the definite integral $I(d,h)$, the problem specifies the composite trapezoid rule. This method approximates the area under the integrand by dividing the integration interval $[0, 2h]$ into a number of subintervals and summing the areas of the trapezoids formed by connecting the function values at the endpoints of each subinterval.\n\nFor an interval $[a,b]$ partitioned into $N-1$ subintervals by $N$ equally spaced points $\\{r_0, \\dots, r_{N-1}\\}$ with step size $\\Delta r = (b-a)/(N-1)$, the formula is:\n$$\n\\int_a^b f(r) dr \\approx \\frac{\\Delta r}{2} \\sum_{i=0}^{N-2} (f(r_i) + f(r_{i+1}))\n$$\nThis method is straightforward to implement and is well-suited for continuous integrands like the one in this problem. The error of the composite trapezoid rule decreases as the number of points $N$ increases.\n\nThe algorithmic implementation uses `numpy.linspace(0, 2*h, N)` to generate the array of $N$ sample points `r_vals`. The corresponding integrand values `f_vals` are then calculated. The `numpy.trapz(f_vals, r_vals)` function provides a direct, efficient, and numerically stable implementation of the composite trapezoid rule, which calculates the definite integral approximation.\n\n### 5. Algorithmic Synthesis\n\nThe complete algorithm is structured as follows:\n1.  A main `solve` function iterates through the list of test cases $(d,h,N)$.\n2.  For each test case, a helper function, say `calculate_integral_and_check_norm`, is called.\n3.  This helper function first generates an array of $N$ radial points $r_i$ uniformly spaced from $0$ to $2h$.\n4.  It then calls a dedicated kernel function, `cubic_spline_kernel(r, h, d)`, which computes the kernel values $W(r_i,h)$ for all points in a vectorized operation.\n5.  The helper function then computes the full integrand values $f(r_i) = W(r_i, h) S_d(r_i)$, selecting the correct $S_d(r_i)$ based on dimension $d$.\n6.  The numerical integral $I(d,h,N)$ is computed using `numpy.trapz`.\n7.  The absolute difference $|I(d,h,N) - 1|$ is compared against the specified tolerance of $10^{-5}$.\n8.  A boolean result (`True` or `False`) is returned and appended to a list of results.\n9.  Finally, the `solve` function formats this list of booleans into the required output string `\"[True,False,...]\"` and prints it.\n\nThis design directly translates the mathematical principles into a modular and verifiable program.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef cubic_spline_kernel(r: np.ndarray, h: float, d: int) - np.ndarray:\n    \"\"\"\n    Computes the SPH cubic spline kernel W(r, h) for a given dimension d.\n    The input r is expected to be a NumPy array.\n    \"\"\"\n    # 1. Determine the dimension-dependent normalization constant sigma_d.\n    if d == 1:\n        sigma_d = 2.0 / 3.0\n    elif d == 2:\n        sigma_d = 10.0 / (7.0 * np.pi)\n    elif d == 3:\n        sigma_d = 1.0 / np.pi\n    else:\n        # This case should not be reached with the given test suite.\n        raise ValueError(\"Dimension d must be 1, 2, or 3.\")\n\n    # 2. Calculate the normalized radius q = r/h.\n    # A small epsilon is added to h to avoid division by zero if h is ever 0.\n    q = r / (h + 1e-12)\n\n    # 3. Apply the piecewise function definition using boolean masking for vectorization.\n    # Initialize an array of zeros with the same shape as q.\n    kernel_values_unscaled = np.zeros_like(q, dtype=float)\n\n    # Condition for 0 = q  1\n    mask1 = q  1.0\n    q1 = q[mask1]\n    kernel_values_unscaled[mask1] = 1.0 - 1.5 * q1**2 + 0.75 * q1**3\n\n    # Condition for 1 = q  2\n    mask2 = (q = 1.0)  (q  2.0)\n    q2 = q[mask2]\n    kernel_values_unscaled[mask2] = 0.25 * (2.0 - q2)**3\n\n    # For q = 2, the values remain 0 as initialized.\n\n    # 4. Scale by the main normalization factor.\n    normalization_factor = sigma_d / (h**d)\n    return normalization_factor * kernel_values_unscaled\n\ndef calculate_integral_and_check_norm(d: int, h: float, N: int) - bool:\n    \"\"\"\n    Numerically integrates the kernel for a given test case and checks if it's normalized.\n    It returns True if |integral - 1| = 1e-5, and False otherwise.\n    \"\"\"\n    # Tolerance for checking the normalization.\n    tolerance = 1e-5\n\n    # 1. Set up the integration domain [0, 2h] and N sample points.\n    r_vals = np.linspace(0.0, 2.0 * h, N)\n\n    # 2. Calculate the kernel values at the sample points.\n    W_vals = cubic_spline_kernel(r_vals, h, d)\n\n    # 3. Calculate the full integrand, W(r,h) * S_d(r), where S_d is the surface measure.\n    if d == 1:\n        # S_1(r) = 2\n        integrand = 2.0 * W_vals\n    elif d == 2:\n        # S_2(r) = 2 * pi * r\n        integrand = 2.0 * np.pi * r_vals * W_vals\n    else:  # d == 3\n        # S_3(r) = 4 * pi * r^2\n        integrand = 4.0 * np.pi * r_vals**2 * W_vals\n    \n    # 4. Perform numerical integration using the composite trapezoid rule.\n    # np.trapz implements this rule efficiently.\n    integral_value = np.trapz(integrand, r_vals)\n\n    # 5. Check if the result is within the specified tolerance of 1.\n    is_normalized = abs(integral_value - 1.0) = tolerance\n    return is_normalized\n\ndef solve():\n    \"\"\"\n    Main function to run the numerical experiment for all test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple is (d, h, N).\n    test_cases = [\n        (1, 0.05, 100),\n        (2, 0.05, 100),\n        (3, 0.05, 100),\n        (3, 1.0, 1000),\n        (2, 0.5, 600),\n        (1, 2.0, 1200),\n    ]\n\n    results = []\n    for case in test_cases:\n        d, h, N = case\n        # For each case, calculate the integral and check the normalization condition.\n        result = calculate_integral_and_check_norm(d, h, N)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # str(True) is 'True', str(False) is 'False', matching problem requirements.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3194379"}, {"introduction": "Building on the properties of a single kernel, we now explore how kernels are used in practice to estimate physical fields. The most fundamental SPH calculation is the density summation, where contributions from all neighboring particles are added up. The accuracy of this summation is surprisingly sensitive to how particles are arranged. This practice investigates the difference in accuracy between a highly ordered lattice and a more uniform, \"glass-like\" disordered configuration for a fluid with constant density.", "problem": "You are asked to quantitatively assess how particle disorder affects the accuracy of the Smoothed Particle Hydrodynamics (SPH) density estimate for a uniform, compressible fluid in two spatial dimensions. Consider a fluid occupying a periodic unit square domain with side length $L=1$ and area $A=L^2=1$. The fluid has constant surface density $\\rho_0=1$ expressed in dimensionless units. The domain is populated by $N$ equal-mass particles at positions $\\{\\mathbf{r}_i\\}_{i=1}^N$ with total mass $M=\\rho_0 A=1$, so each particle has mass $m=M/N=1/N$.\n\nFor any particle $i$, the SPH density estimate is defined by\n$$\n\\rho_i \\equiv \\sum_{j=1}^N m\\, W\\!\\left(\\left\\|\\mathbf{r}_i - \\mathbf{r}_j\\right\\|_\\mathrm{per},\\, h\\right),\n$$\nwhere $\\|\\cdot\\|_\\mathrm{per}$ denotes the minimum-image periodic distance on the unit torus and $W(r,h)$ is the standard cubic spline SPH kernel in two spatial dimensions with compact support $2h$ and smoothing length $h$. The smoothing length must be chosen as\n$$\nh = \\eta \\,\\Delta, \\quad \\text{with} \\quad \\Delta = \\sqrt{\\frac{A}{N}} = \\frac{1}{\\sqrt{N}},\n$$\nfor a fixed constant $\\eta=1.2$.\n\nTwo distinct particle arrangements must be considered for each specified value of $N$:\n\n- Lattice arrangement: particles placed on a regular square lattice of size $\\sqrt{N}\\times\\sqrt{N}$ within the unit square with periodic boundaries.\n- Glass-like arrangement: particles placed at the first $N$ points of the two-dimensional Halton sequence with bases $2$ and $3$, i.e., for $k=1,2,\\ldots,N$, the position is $\\mathbf{r}_k=\\big(\\phi_2(k),\\,\\phi_3(k)\\big)$ where $\\phi_b(k)$ is the radical-inverse function in base $b$.\n\nFor each arrangement and for each $N$, compute the following dimensionless error metrics comparing the SPH density estimate $\\{\\rho_i\\}$ to the exact uniform density $\\rho_0$:\n- The mean absolute relative error,\n$$\nE_1 = \\frac{1}{N}\\sum_{i=1}^N \\frac{\\left|\\rho_i-\\rho_0\\right|}{\\rho_0}.\n$$\n- The root-mean-square relative error,\n$$\nE_2 = \\frac{1}{\\sqrt{N}}\\left(\\sum_{i=1}^N \\left(\\frac{\\rho_i-\\rho_0}{\\rho_0}\\right)^2\\right)^{1/2}.\n$$\n- The maximum relative error,\n$$\nE_\\infty = \\max_{1\\le i\\le N} \\frac{\\left|\\rho_i-\\rho_0\\right|}{\\rho_0}.\n$$\n\nUse strictly dimensionless units throughout, and express all error values as decimal numbers (not as percentages). For each error metric, round the result to six decimal places.\n\nTest Suite:\nEvaluate the triplet $\\big[E_1,E_2,E_\\infty\\big]$ for the following ordered list of test cases, where each case specifies a pair $(N,\\text{arrangement})$:\n- $(N=\\;100,\\;\\text{lattice})$\n- $(N=\\;100,\\;\\text{glass})$\n- $(N=\\;256,\\;\\text{lattice})$\n- $(N=\\;256,\\;\\text{glass})$\n- $(N=\\;441,\\;\\text{lattice})$\n- $(N=\\;441,\\;\\text{glass})$\n\nAdopt the minimum-image periodic distance on the unit square torus for all pairwise separations in the kernel evaluations. For each $N$ in the lattice arrangement, assume $N$ is a perfect square so that the lattice is $\\sqrt{N}\\times\\sqrt{N}$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list of lists, each inner list corresponding to one test case in the specified order and containing the three rounded error values in the order $\\big[E_1,E_2,E_\\infty\\big]$. For example:\n\"[ [e11,e12,e13],[e21,e22,e23],... ]\"\nEnsure the numerical values are rounded to six decimal places and there is no additional text beyond this single line. Use dimensionless units for all computations and outputs.", "solution": "The problem statement has been validated and is determined to be scientifically sound, well-posed, and complete. It constitutes a standard numerical experiment in the field of computational physics to assess the accuracy of the Smoothed Particle Hydrodynamics (SPH) method. The task is to compute density errors for two-dimensional particle distributions. A direct computational approach will be employed as follows.\n\nThe core of the SPH methodology is the representation of a continuous field $A(\\mathbf{r})$ by a summation over a set of discrete particles. For the density field $\\rho$, this is expressed as:\n$$\n\\rho(\\mathbf{r}) = \\sum_{j} m_j W\\left(\\left\\|\\mathbf{r} - \\mathbf{r}_j\\right\\|,\\, h\\right)\n$$\nwhere $m_j$ and $\\mathbf{r}_j$ are the mass and position of particle $j$, and $W$ is a smoothing kernel with characteristic width $h$, the smoothing length. The problem specifies the SPH density estimate for a particle $i$ at position $\\mathbf{r}_i$ as:\n$$\n\\rho_i = \\sum_{j=1}^N m\\, W\\!\\left(\\left\\|\\mathbf{r}_i - \\mathbf{r}_j\\right\\|_\\mathrm{per},\\, h\\right)\n$$\nThe domain is a two-dimensional unit square with periodic boundary conditions, area $A=1$, and total mass $M=1$. The fluid has a constant reference surface density $\\rho_0=1$. For $N$ particles, each thus has mass $m = M/N = 1/N$. The distance $\\|\\mathbf{r}_i - \\mathbf{r}_j\\|_\\mathrm{per}$ is the minimum-image distance on the unit torus, calculated for a displacement vector $\\Delta\\mathbf{r} = (\\Delta x, \\Delta y)$ as $\\sqrt{(\\Delta x - \\text{round}(\\Delta x))^2 + (\\Delta y - \\text{round}(\\Delta y))^2}$.\n\nThe smoothing length $h$ is coupled to the mean particle separation $\\Delta$. For a two dimensional domain of area $A=1$ with $N$ particles, the mean separation is $\\Delta = \\sqrt{A/N} = 1/\\sqrt{N}$. The smoothing length is set to $h = \\eta \\Delta$, with the constant $\\eta = 1.2$.\n\nThe kernel $W(r, h)$ is the standard cubic spline for two dimensions, which is non-zero only for $r \\le 2h$. Its analytical form is:\n$$\nW(r,h) = \\frac{10}{7\\pi h^2} \\times \\begin{cases} 1 - \\frac{3}{2}q^2 + \\frac{3}{4}q^3  0 \\le q \\le 1 \\\\ \\frac{1}{4}(2-q)^3  1  q \\le 2 \\\\ 0  q > 2 \\end{cases}\n$$\nwhere $q = r/h$ is the normalized distance.\n\nThe analysis requires two particle configurations:\n1.  **Lattice arrangement**: Particles are positioned on a uniform $\\sqrt{N} \\times \\sqrt{N}$ grid. The coordinates for a particle $(i,j)$ are taken as $(\\frac{i+0.5}{\\sqrt{N}}, \\frac{j+0.5}{\\sqrt{N}})$ for $i,j \\in \\{0, 1, \\dots, \\sqrt{N}-1\\}$. This ensures the lattice is centered within the unit domain.\n2.  **Glass-like arrangement**: Particles are placed at the first $N$ points of the two-dimensional Halton sequence with bases $2$ and $3$. The position of the $k$-th particle ($k=1, \\dots, N$) is $\\mathbf{r}_k = (\\phi_2(k), \\phi_3(k))$, where $\\phi_b(k)$ is the radical-inverse function in base $b$.\n\nFor each configuration and specified value of $N$, the SPH-estimated densities $\\{\\rho_i\\}_{i=1}^N$ are compared against the exact density $\\rho_0=1$ using three error metrics:\n-   Mean absolute relative error: $E_1 = \\frac{1}{N}\\sum_{i=1}^N |\\rho_i-1|$\n-   Root-mean-square relative error: $E_2 = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N (\\rho_i-1)^2}$\n-   Maximum relative error: $E_\\infty = \\max_{1\\le i\\le N} |\\rho_i-1|$\n\nThe computational procedure is as follows:\n1.  For each test case, specified by $(N, \\text{arrangement})$, the particle positions $\\{\\mathbf{r}_i\\}$ are generated.\n2.  A matrix of pairwise periodic distances, $d_{ij} = \\|\\mathbf{r}_i - \\mathbf{r}_j\\|_\\mathrm{per}$, is computed for all $i,j \\in \\{1, \\dots, N\\}$. This calculation is vectorized for efficiency.\n3.  The kernel function $W(d_{ij}, h)$ is evaluated for all pairs, creating a matrix of kernel values.\n4.  The density for each particle $\\rho_i$ is computed by summing the $i$-th row of the kernel matrix and multiplying by the particle mass $m=1/N$.\n5.  The error metrics $E_1, E_2, E_\\infty$ are calculated from the vector of computed densities.\n6.  The final error values are rounded to six decimal places as required.\n\nThis entire procedure is implemented in Python using the `numpy` library to handle array operations efficiently.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the SPH density error problem.\n    \"\"\"\n    \n    # Define the problem constants and test cases.\n    RHO_0 = 1.0\n    ETA = 1.2\n    \n    test_cases = [\n        (100, 'lattice'),\n        (100, 'glass'),\n        (256, 'lattice'),\n        (256, 'glass'),\n        (441, 'lattice'),\n        (441, 'glass'),\n    ]\n\n    # --- Helper functions ---\n\n    def radical_inverse(k, base):\n        \"\"\"Computes the radical inverse of k in a given base.\"\"\"\n        inv = 0.0\n        f = 1.0 / base\n        while k  0:\n            inv += (k % base) * f\n            k //= base\n            f /= base\n        return inv\n\n    def generate_lattice(n_particles):\n        \"\"\"Generates particle positions on a regular square lattice.\"\"\"\n        n_side = int(np.sqrt(n_particles))\n        if n_side**2 != n_particles:\n            raise ValueError(\"N must be a perfect square for lattice arrangement\")\n        \n        points = np.zeros((n_particles, 2))\n        dx = 1.0 / n_side\n        \n        idx = 0\n        for i in range(n_side):\n            for j in range(n_side):\n                points[idx, 0] = (i + 0.5) * dx\n                points[idx, 1] = (j + 0.5) * dx\n                idx += 1\n        return points\n\n    def generate_glass(n_particles):\n        \"\"\"Generates particle positions from a Halton sequence.\"\"\"\n        points = np.zeros((n_particles, 2))\n        for k in range(1, n_particles + 1):\n            points[k-1, 0] = radical_inverse(k, 2)\n            points[k-1, 1] = radical_inverse(k, 3)\n        return points\n\n    def W_cubic_spline_vectorized(r, h):\n        \"\"\"Vectorized 2D cubic spline SPH kernel.\"\"\"\n        alpha_d = 10.0 / (7.0 * np.pi * h**2)\n        q = r / h\n        \n        res = np.zeros_like(q)\n        \n        # Condition: 1  q = 2\n        mask1 = (q  1.0)  (q = 2.0)\n        q1 = q[mask1]\n        res[mask1] = alpha_d * 0.25 * (2.0 - q1)**3\n        \n        # Condition: 0 = q = 1\n        mask2 = q = 1.0\n        q2 = q[mask2]\n        res[mask2] = alpha_d * (1.0 - 1.5 * q2**2 + 0.75 * q2**3)\n        \n        return res\n\n    def compute_errors(n_particles, arrangement_type):\n        \"\"\"\n        Computes the SPH density and error metrics for a given configuration.\n        \"\"\"\n        # 1. Set parameters\n        m = 1.0 / n_particles\n        delta = 1.0 / np.sqrt(n_particles)\n        h = ETA * delta\n\n        # 2. Generate particle positions\n        if arrangement_type == 'lattice':\n            positions = generate_lattice(n_particles)\n        elif arrangement_type == 'glass':\n            positions = generate_glass(n_particles)\n        else:\n            raise ValueError(f\"Unknown arrangement type: {arrangement_type}\")\n            \n        # 3. Compute pairwise periodic distances (vectorized)\n        delta_r = positions[:, np.newaxis, :] - positions[np.newaxis, :, :]\n        delta_r -= np.round(delta_r)  # Minimum image convention for unit domain\n        distances = np.linalg.norm(delta_r, axis=2)\n\n        # 4. Evaluate kernel for all pairs\n        kernel_values = W_cubic_spline_vectorized(distances, h)\n\n        # 5. Sum contributions to get densities\n        densities = m * np.sum(kernel_values, axis=1)\n\n        # 6. Compute error metrics\n        relative_errors = (densities - RHO_0) / RHO_0\n        \n        e1 = np.mean(np.abs(relative_errors))\n        e2 = np.sqrt(np.mean(relative_errors**2))\n        e_inf = np.max(np.abs(relative_errors))\n        \n        return [round(e1, 6), round(e2, 6), round(e_inf, 6)]\n\n    # --- Main execution loop ---\n    \n    all_results = []\n    for n, arr_type in test_cases:\n        errors = compute_errors(n, arr_type)\n        all_results.append(errors)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "2439536"}, {"introduction": "After mastering the spatial discretization in SPH, the next challenge is advancing the simulation in time. Explicit integration schemes, which are common in SPH, are only stable if the time step, $\\Delta t$, is sufficiently small. This practice [@problem_id:2439517] introduces the three most common criteria for choosing an adaptive time step: the Courant–Friedrichs–Lewy (CFL) condition, a force-based limit, and a viscous diffusion limit. You will implement a controller that selects the most restrictive (smallest) time step at each moment, gaining a hands-on understanding of the stability constraints that govern dynamic simulations.", "problem": "You are tasked with implementing a variable time-step controller for an explicit Smoothed Particle Hydrodynamics (SPH) time integrator using three fundamental stability and accuracy considerations: a Courant–Friedrichs–Lewy (CFL) condition, a force (acceleration) condition, and a viscous diffusion condition. Your solution must start from first principles consistent with explicit methods for hyperbolic and parabolic problems and classical kinematics, and derive the exact expressions you will implement for the time-step at each iteration. The scenario is one-dimensional with uniform smoothing length, and the program should integrate only the time variable while sampling prescribed maximum field magnitudes over time. All physical quantities must be treated in the International System of Units (SI), and time should always be computed and reported in seconds.\n\nStarting point for derivation: Use only the following base principles as your fundamental starting point.\n- Characteristic signal propagation in hyperbolic systems: the information travels at a characteristic speed, so a stable explicit step must be limited by a ratio of spatial resolution to maximum signal speed.\n- Kinematics under constant acceleration over a time step: the displacement under uniform acceleration must remain small relative to the spatial resolution to preserve accuracy.\n- Stability limit for explicit schemes applied to parabolic diffusion: the time-step must be bounded proportionally to the square of the spatial resolution and inversely to the kinematic viscosity.\n\nAssume the following modeling setup:\n- Smoothing length $h$ is constant and uniform.\n- The maximum signal speed is modeled as the sum of the speed of sound and a convective speed, so the instantaneous maximum signal speed is $s(t) = c + \\lvert v_{\\max}(t)\\rvert$, where $c$ is the (constant) speed of sound and $v_{\\max}(t)$ is the time-varying maximum particle speed magnitude.\n- The maximum acceleration magnitude $a_{\\max}(t)$ is time-dependent.\n- The kinematic viscosity $\\nu$ is constant and uniform.\n- Each time-step uses a safety coefficient $C_{\\mathrm{CFL}}$, $C_{\\mathrm{force}}$, and $C_{\\mathrm{visc}}$ for the three limits, respectively, each strictly between $0$ and $1$.\n\nDerive, from the above principles, explicit formulas for the three candidate time-steps at time $t$: a hyperbolic (CFL) bound in terms of $h$ and $s(t)$, a force-based bound in terms of $h$ and $a_{\\max}(t)$, and a viscous-diffusion bound in terms of $h$ and $\\nu$. Then implement an explicit time-advancement controller that, starting at $t=0$, repeatedly:\n- Evaluates the three candidate bounds at the current time $t$;\n- Chooses the minimum of the three as the next time increment $\\Delta t$ (breaking ties by selecting the first in the order CFL, then force, then viscous);\n- Records which bound is limiting at that step using the integer codes: $0$ for CFL, $1$ for force, and $2$ for viscous;\n- Advances time by $\\Delta t$;\n- Stops when $t$ reaches a specified final time $T_{\\mathrm{end}}$ (you must ensure $t$ does not exceed $T_{\\mathrm{end}}$; if necessary, truncate the last step to end exactly at $T_{\\mathrm{end}}$ but classify the limiter using the untruncated candidate bounds).\n\nHandle edge cases robustly: if $a_{\\max}(t)=0$ at any time, the force-based bound should be treated as $+\\infty$; if $\\nu=0$, the viscous bound should be treated as $+\\infty$. You may assume $cgt;0$ so the CFL bound is always finite. The evaluation of $v_{\\max}(t)$ and $a_{\\max}(t)$ is defined by smooth functions of time given below. Angles do not appear in this problem. There are no percentage quantities.\n\nFor testing and reproducibility, use the following test suite of three cases. In each case, the maximum velocity and acceleration are prescribed by\n- $v_{\\max}(t) = v_{0} + A_{v}\\left(1 - e^{-t/\\tau_{v}}\\right)$,\n- $a_{\\max}(t) = a_{0} + A_{a} e^{-t/\\tau_{a}}$,\nwith all parameters given below. Use seconds for time, meters for length, meters per second for velocity, meters per second squared for acceleration, and meters squared per second for kinematic viscosity. Safety coefficients are dimensionless.\n\nTest case 1 (general mixed regime):\n- $h = 0.01$ m, $c = 5.0$ m/s, $\\nu = 1.0\\times 10^{-6}$ m$^{2}$/s,\n- $C_{\\mathrm{CFL}} = 0.25$, $C_{\\mathrm{force}} = 0.25$, $C_{\\mathrm{visc}} = 0.125$,\n- $T_{\\mathrm{end}} = 0.10$ s,\n- $v_{0} = 0.0$ m/s, $A_{v} = 3.0$ m/s, $\\tau_{v} = 0.02$ s,\n- $a_{0} = 0.0$ m/s$^{2}$, $A_{a} = 4000.0$ m/s$^{2}$, $\\tau_{a} = 0.015$ s.\n\nTest case 2 (viscous-limited with zero acceleration):\n- $h = 0.01$ m, $c = 5.0$ m/s, $\\nu = 0.5$ m$^{2}$/s,\n- $C_{\\mathrm{CFL}} = 0.25$, $C_{\\mathrm{force}} = 0.25$, $C_{\\mathrm{visc}} = 0.125$,\n- $T_{\\mathrm{end}} = 0.05$ s,\n- $v_{0} = 0.0$ m/s, $A_{v} = 3.0$ m/s, $\\tau_{v} = 0.02$ s,\n- $a_{0} = 0.0$ m/s$^{2}$, $A_{a} = 0.0$ m/s$^{2}$, $\\tau_{a} = 0.01$ s.\n\nTest case 3 (CFL-limited with zero viscosity):\n- $h = 0.005$ m, $c = 30.0$ m/s, $\\nu = 0.0$ m$^{2}$/s,\n- $C_{\\mathrm{CFL}} = 0.30$, $C_{\\mathrm{force}} = 0.30$, $C_{\\mathrm{visc}} = 0.30$,\n- $T_{\\mathrm{end}} = 0.010$ s,\n- $v_{0} = 0.0$ m/s, $A_{v} = 1.5$ m/s, $\\tau_{v} = 0.01$ s,\n- $a_{0} = 0.0$ m/s$^{2}$, $A_{a} = 5000.0$ m/s$^{2}$, $\\tau_{a} = 0.005$ s.\n\nProgram requirements:\n- Implement the variable time-step controller exactly as described.\n- For each test case, generate the list of integer codes indicating which bound limited the time-step at each iteration from $t=0$ until $t=T_{\\mathrm{end}}$.\n- Your program should produce a single line of output containing the results for all three test cases as a comma-separated list of lists in Python literal form, for example, $\\left[\\left[\\dots\\right],\\left[\\dots\\right],\\left[\\dots\\right]\\right]$.\n\nFinal output format:\n- Your program should produce a single line of output containing the three lists of limiter codes, enclosed in a single pair of square brackets and separated by commas, e.g., $\\left[\\left[\\ell_{1,1}, \\ell_{1,2}, \\dots\\right], \\left[\\ell_{2,1}, \\ell_{2,2}, \\dots\\right], \\left[\\ell_{3,1}, \\ell_{3,2}, \\dots\\right]\\right]$, where each $\\ell_{i,j}$ is an integer in $\\left\\{0,1,2\\right\\}$.", "solution": "The problem proposed is valid. It is scientifically grounded in the principles of numerical methods for partial differential equations, specifically for smoothed particle hydrodynamics (SPH). The problem is well-posed, objective, and provides a complete and consistent set of data and instructions for implementing a deterministic time-stepping algorithm. We shall now proceed with the derivation and solution.\n\nThe objective is to construct a variable time-step controller for an explicit SPH simulation. The time increment, $\\Delta t$, at each step is chosen as the minimum of three candidate values derived from stability and accuracy considerations: the Courant–Friedrichs–Lewy (CFL) condition, a force-based acceleration limit, and a viscous diffusion limit.\n\nLet us derive the expressions for these three time-step bounds from the provided first principles. The characteristic spatial resolution of the SPH method is given by the smoothing length, $h$.\n\n1.  **CFL (Hyperbolic) Time-Step, $\\Delta t_{\\mathrm{CFL}}$**\nThe first principle is based on the stability of explicit methods for hyperbolic systems. Information, or a physical signal, propagates at a characteristic speed. For stability, the numerical domain of dependence must contain the physical domain of dependence. In an SPH context, this means that in a single time-step $\\Delta t$, information should not propagate further than the local interaction distance, which is on the order of the smoothing length $h$. The maximum speed of signal propagation, $s(t)$, is given as the sum of the speed of sound $c$ and the magnitude of the maximum particle velocity $|v_{\\max}(t)|$.\nThe condition is expressed as:\n$$ \\Delta t \\le C_{\\mathrm{CFL}} \\frac{h}{s(t)} $$\nwhere $C_{\\mathrm{CFL}}$ is a safety coefficient, typically less than $1$. Substituting the given expression for $s(t) = c + |v_{\\max}(t)|$, we obtain the candidate time-step from the CFL condition:\n$$ \\Delta t_{\\mathrm{CFL}}(t) = C_{\\mathrm{CFL}} \\frac{h}{c + |v_{\\max}(t)|} $$\n\n2.  **Force-Based (Kinematic) Time-Step, $\\Delta t_{\\mathrm{force}}$**\nThe second principle ensures accuracy by limiting the displacement of a particle due to acceleration within a single time-step. The principle states that this displacement should be small relative to the spatial resolution $h$. The displacement of a particle under a constant acceleration $a$ over a time $\\Delta t$ is $\\frac{1}{2}a(\\Delta t)^2$. The standard SPH criterion formalizing this principle limits the time-step such that:\n$$ \\frac{1}{2} a_{\\max}(t) (\\Delta t)^2 \\le \\alpha h $$\nwhere $a_{\\max}(t)$ is the maximum magnitude of acceleration in the system and $\\alpha$ is a small dimensionless constant. Rearranging for $\\Delta t$ yields $\\Delta t \\le \\sqrt{2\\alpha h / a_{\\max}(t)}$. This is commonly written in the form:\n$$ \\Delta t \\le C_{\\mathrm{force}} \\sqrt{\\frac{h}{a_{\\max}(t)}} $$\nwhere $C_{\\mathrm{force}}$ is a user-defined safety coefficient. We will adopt this standard form as the direct implementation of the stated principle. Thus, the force-based time-step is:\n$$ \\Delta t_{\\mathrm{force}}(t) = C_{\\mathrm{force}} \\sqrt{\\frac{h}{a_{\\max}(t)}} $$\nThis expression is valid only for $a_{\\max}(t)  0$. If $a_{\\max}(t) = 0$, there is no acceleration to limit, so this condition imposes no upper bound on the time-step. In this case, we treat $\\Delta t_{\\mathrm{force}}$ as being infinitely large.\n\n3.  **Viscous Diffusion Time-Step, $\\Delta t_{\\mathrm{visc}}$**\nThe third principle comes from the stability analysis of explicit numerical schemes for parabolic diffusion equations of the form $\\partial u/\\partial t = \\nu \\nabla^2 u$, where $\\nu$ is the kinematic viscosity. For a simple forward-time, centered-space (FTCS) discretization, the stability condition is $\\Delta t \\le (\\Delta x)^2/(2\\nu)$. In SPH, the spatial resolution $\\Delta x$ is replaced by the smoothing length $h$. The generic form of this stability constraint is:\n$$ \\Delta t \\le C_{\\mathrm{visc}} \\frac{h^2}{\\nu} $$\nwhere $C_{\\mathrm{visc}}$ is a safety coefficient that accounts for the constant prefactors (like $1/2$) and other details of the specific SPH discretization of the viscous term. The problem provides this coefficient directly. Therefore, the viscous time-step is:\n$$ \\Delta t_{\\mathrm{visc}} = C_{\\mathrm{visc}} \\frac{h^2}{\\nu} $$\nNote that this time-step is constant if $\\nu$ and $h$ are constant. If $\\nu = 0$, viscosity is absent, and this constraint does not apply. We thus treat $\\Delta t_{\\mathrm{visc}}$ as being infinitely large in this case.\n\n**Time Integration Algorithm**\nThe simulation proceeds from an initial time $t=0$ to a final time $T_{\\mathrm{end}}$. At each step, starting at time $t$, the algorithm is as follows:\n1.  Evaluate the time-dependent maximum velocity and acceleration, $v_{\\max}(t)$ and $a_{\\max}(t)$, using the prescribed functions:\n    $$ v_{\\max}(t) = v_{0} + A_{v}\\left(1 - e^{-t/\\tau_{v}}\\right) $$\n    $$ a_{\\max}(t) = a_{0} + A_{a} e^{-t/\\tau_{a}} $$\n2.  Calculate the three candidate time-steps: $\\Delta t_{\\mathrm{CFL}}(t)$, $\\Delta t_{\\mathrm{force}}(t)$, and $\\Delta t_{\\mathrm{visc}}$.\n3.  Determine the limiting time-step for the current iteration:\n    $$ \\Delta t_{\\mathrm{chosen}} = \\min(\\Delta t_{\\mathrm{CFL}}, \\Delta t_{\\mathrm{force}}, \\Delta t_{\\mathrm{visc}}) $$\n4.  Identify which condition is the limiting one. We use integer codes: $0$ for CFL, $1$ for force, and $2$ for viscous. The tie-breaking rule is to select the first one in this specified order. This code is recorded for the current step.\n5.  Advance the simulation time. The time increment $\\Delta t_{\\mathrm{step}}$ is set to $\\Delta t_{\\mathrm{chosen}}$. However, to ensure the simulation ends exactly at $T_{\\mathrm{end}}$, the last step is truncated if necessary. That is, if $t + \\Delta t_{\\mathrm{chosen}} \\ge T_{\\mathrm{end}}$, the current step is the final one, and the time is advanced to $T_{\\mathrm{end}}$. Otherwise, the time is advanced by $\\Delta t_{\\mathrm{chosen}}$: $t \\leftarrow t + \\Delta t_{\\mathrm{chosen}}$. The loop continues as long as $t  T_{\\mathrm{end}}$. The limiter code for the final step is determined from the untruncated $\\Delta t_{\\mathrm{chosen}}$.\n\nThis procedure is implemented for each test case to generate a sequence of limiter codes.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and implements a variable time-step controller for an explicit SPH simulation.\n    The controller uses CFL, force, and viscous stability criteria.\n    \"\"\"\n\n    def run_simulation(h, c, nu, C_cfl, C_force, C_visc, T_end, v0, Av, tau_v, a0, Aa, tau_a):\n        \"\"\"\n        Runs a single SPH time-stepping simulation for a given set of parameters.\n        \n        Returns a list of integer codes indicating the limiter at each step.\n        \"\"\"\n\n        # Define the time-dependent functions for maximum velocity and acceleration\n        def v_max_func(t):\n            # The problem statement defines v_max(t) which may not be a magnitude, but\n            # all test cases result in v_max(t) = 0. The CFL condition uses |v_max(t)|.\n            if tau_v  0:\n                return v0 + Av * (1.0 - np.exp(-t / tau_v))\n            return v0 + Av # Case for tau_v - 0 or t - inf\n\n        def a_max_func(t):\n            if tau_a  0:\n                return a0 + Aa * np.exp(-t / tau_a)\n            return a0 # Case for tau_a - 0 or t - inf\n\n        t = 0.0\n        limiters = []\n\n        # The loop must continue as long as the current time is less than the end time.\n        while t  T_end:\n            # 1. Evaluate maximum velocity and acceleration at the current time t\n            current_v_max = v_max_func(t)\n            current_a_max = a_max_func(t)\n\n            # 2. Calculate the three candidate time steps\n            \n            # CFL (Hyperbolic) Condition\n            # s(t) = c + |v_max(t)|\n            # c  0 is assumed, so s_t is always positive.\n            s_t = c + abs(current_v_max)\n            dt_cfl = C_cfl * h / s_t\n\n            # Force (Kinematic) Condition\n            if current_a_max  0.0:\n                dt_force = C_force * np.sqrt(h / current_a_max)\n            else:\n                dt_force = np.inf\n\n            # Viscous Diffusion Condition\n            if nu  0.0:\n                dt_visc = C_visc * h**2 / nu\n            else:\n                dt_visc = np.inf\n\n            # 3. Determine the limiting time step and its corresponding code\n            dt_candidates = [dt_cfl, dt_force, dt_visc]\n            \n            # np.argmin implements the required tie-breaking rule (first minimum is chosen)\n            limiter_code = int(np.argmin(dt_candidates))\n            dt_chosen = dt_candidates[limiter_code]\n            \n            # 4. Record the limiter code for the current step\n            limiters.append(limiter_code)\n\n            # 5. Advance the simulation time.\n            # Truncate the last step to ensure t does not exceed T_end.\n            if t + dt_chosen = T_end:\n                t = T_end\n            else:\n                t += dt_chosen\n        \n        return limiters\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (general mixed regime)\n        {'h': 0.01, 'c': 5.0, 'nu': 1.0e-6, 'C_cfl': 0.25, 'C_force': 0.25, 'C_visc': 0.125, 'T_end': 0.10, 'v0': 0.0, 'Av': 3.0, 'tau_v': 0.02, 'a0': 0.0, 'Aa': 4000.0, 'tau_a': 0.015},\n        # Case 2 (viscous-limited with zero acceleration)\n        {'h': 0.01, 'c': 5.0, 'nu': 0.5, 'C_cfl': 0.25, 'C_force': 0.25, 'C_visc': 0.125, 'T_end': 0.05, 'v0': 0.0, 'Av': 3.0, 'tau_v': 0.02, 'a0': 0.0, 'Aa': 0.0, 'tau_a': 0.01},\n        # Case 3 (CFL-limited with zero viscosity)\n        {'h': 0.005, 'c': 30.0, 'nu': 0.0, 'C_cfl': 0.30, 'C_force': 0.30, 'C_visc': 0.30, 'T_end': 0.010, 'v0': 0.0, 'Av': 1.5, 'tau_v': 0.01, 'a0': 0.0, 'Aa': 5000.0, 'tau_a': 0.005},\n    ]\n\n    results = []\n    for case in test_cases:\n        limiters = run_simulation(**case)\n        results.append(limiters)\n\n    # Format the output as a compact Python literal string for a list of lists.\n    # e.g., [[1,2,3],[4],[5,6]]\n    # This construction ensures no spaces are included, matching the example format style.\n    inner_lists_str = [f\"[{','.join(map(str, r))}]\" for r in results]\n    final_output = f\"[{','.join(inner_lists_str)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "2439517"}]}