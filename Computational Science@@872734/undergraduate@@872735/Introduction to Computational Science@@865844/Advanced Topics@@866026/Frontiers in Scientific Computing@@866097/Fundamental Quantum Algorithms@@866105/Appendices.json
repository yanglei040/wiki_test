{"hands_on_practices": [{"introduction": "The promise of quantum speedup is not universal; it critically depends on the structure of the search problem. This exercise challenges you to compare the query complexity of searching an unstructured list versus a sorted one, revealing why the nature of the available information—simple membership versus relational order—dictates whether a quantum advantage is possible. By analyzing these two scenarios [@problem_id:3242170], you will gain a deeper intuition for the boundaries of Grover's algorithm.", "problem": "Consider two search tasks over a set of $n$ distinct keys in the Quantum Query Model (QQM), where a query is the application of a unitary oracle on a quantum register and the cost measure is the number of oracle applications.\n\nTask 1 (Uniform Unsorted Array with a Single Marked Item): The keys are stored in an array in arbitrary order, and there is exactly one marked index $i^\\star \\in \\{0,1,\\dots,n-1\\}$ such that a Boolean predicate $f(i^\\star) = 1$ and $f(i) = 0$ for all $i \\neq i^\\star$. Access is via the standard membership oracle $O_f$ that acts as $O_f\\colon \\lvert i\\rangle \\lvert b\\rangle \\mapsto \\lvert i\\rangle \\lvert b \\oplus f(i)\\rangle$, with unit cost per query.\n\nTask 2 (Ordered Search via a Balanced Binary Search Tree): The keys are maintained in a Balanced Binary Search Tree (BST), which is a binary tree whose in-order traversal yields the keys in strictly increasing order and whose height is $\\Theta(\\log n)$ in the worst case. The unknown target key $x^\\star$ is known to be one of the stored keys. Access is via a comparison oracle $O_{\\leq}$ that implements $O_{\\leq}\\colon \\lvert y\\rangle \\lvert b\\rangle \\mapsto \\lvert y\\rangle \\lvert b \\oplus \\mathbf{1}[x^\\star \\leq y]\\rangle$, where $\\mathbf{1}[\\cdot]$ is the indicator function, with unit cost per query.\n\nStarting from fundamental definitions and well-tested facts:\n- A Balanced Binary Search Tree (BST) supports comparisons that deterministically partition the set of possible ranks of $x^\\star$ into two halves per comparison, and classical binary search isolates $x^\\star$ by halving the candidate set at each step.\n- Grover’s algorithm is the canonical amplitude-amplification procedure for searching a single marked item in an unstructured domain using a membership oracle.\n\nSelect all statements that are correct about the optimal quantum query complexities in these two tasks and about how order information constrains potential quantum speedups.\n\nA. In Task $1$, with a single marked index and access only to $O_f$, the optimal quantum query complexity is $\\Theta(\\sqrt{n})$, achieved by Grover’s algorithm, whereas any classical algorithm requires $\\Theta(n)$ queries in the worst case.\n\nB. In Task $2$, by leveraging superposition over comparisons in the BST, a quantum algorithm can locate $x^\\star$ using only $\\Theta(\\sqrt{\\log n})$ comparison queries.\n\nC. In Task $2$, the presence of total order information induces an $\\Omega(\\log n)$ quantum query lower bound for ordered search, so the best quantum algorithms still use $\\Theta(\\log n)$ queries up to constant factors, rather than $\\Theta(\\sqrt{n})$.\n\nD. If the keys are sorted but the oracle access is restricted to equality testing $O_{=}\\colon \\lvert y\\rangle \\lvert b\\rangle \\mapsto \\lvert y\\rangle \\lvert b \\oplus \\mathbf{1}[y = x^\\star]$, without exposing order information, the optimal quantum query complexity to find $x^\\star$ remains $\\Theta(\\sqrt{n})$, matching the unstructured case.", "solution": "We analyze the query complexity of each task based on fundamental principles of classical and quantum algorithms.\n\n**Analysis of Task 1: Unstructured Search**\nThe task is to find a single marked index $i^\\star$ in a set of size $n$ using the oracle $O_f: \\lvert i\\rangle \\lvert b\\rangle \\mapsto \\lvert i\\rangle \\lvert b \\oplus f(i)\\rangle$, where $f(i) = \\delta_{i, i^\\star}$. The domain is \"unstructured\" because the oracle only provides information about whether $f(i)=1$ or $f(i)=0$.\n\n- **Classically**, to be certain of finding $i^\\star$, an algorithm must query indices sequentially. In the worst-case scenario, the marked item is the last one checked. This requires $n$ queries (or $n-1$ if it's known one item is marked). Thus, the classical worst-case query complexity is $\\Theta(n)$.\n\n- **Quantumly**, this problem is the canonical search problem solved by Grover's algorithm. Grover's algorithm can identify $i^\\star$ using a number of queries proportional to the square root of the search space size. The number of oracle calls is $O(\\sqrt{n})$. It is a well-established result by Bennett, Bernstein, Brassard, and Vazirani (BBBV) that any quantum algorithm for this problem must make at least $\\Omega(\\sqrt{n})$ queries. Therefore, the optimal quantum query complexity for unstructured search is $\\Theta(\\sqrt{n})$.\n\n**Analysis of Task 2: Ordered Search**\nThe task is to find a target key $x^\\star$ in a sorted set of $n$ keys using the comparison oracle $O_{\\leq}: \\lvert y\\rangle \\lvert b\\rangle \\mapsto \\lvert y\\rangle \\lvert b \\oplus \\mathbf{1}[x^\\star \\leq y]\\rangle$. The information that the keys are sorted is crucial.\n\n- **Classically**, the problem is solved by binary search. One queries a key at the median of the current search interval. The oracle's response, $x^\\star \\leq y$ or $x^\\star > y$, allows the algorithm to discard half of the interval. To reduce the search space from $n$ items to 1, $\\lceil\\log_2 n\\rceil$ comparisons are needed. The classical query complexity is therefore $\\Theta(\\log n)$.\n\n- **Quantumly**, a common misconception is to apply Grover's algorithm to the $\\log n$ steps of binary search, suggesting a $\\Theta(\\sqrt{\\log n})$ complexity. This is incorrect. The issue is that the outcome of each query in binary search determines the subsequent query, creating a dependency that prevents a simple Grover-like speedup. The problem of searching a sorted list has a specific quantum lower bound. Using the quantum adversary method, it can be proven that any quantum algorithm that finds an item in a sorted list of size $n$ using comparison queries requires $\\Omega(\\log n)$ queries. Since a quantum computer can execute the classical binary search algorithm using $\\Theta(\\log n)$ queries, this provides an upper bound. The lower and upper bounds match, so the optimal quantum query complexity for ordered search is $\\Theta(\\log n)$.\n\n**Option-by-Option Evaluation**\n\nA. **In Task $1$, with a single marked index and access only to $O_f$, the optimal quantum query complexity is $\\Theta(\\sqrt{n})$, achieved by Grover’s algorithm, whereas any classical algorithm requires $\\Theta(n)$ queries in the worst case.**\nThis statement is a precise summary of the complexity of unstructured search. As derived above, the classical worst-case complexity is $\\Theta(n)$. The optimal quantum query complexity is $\\Theta(\\sqrt{n})$.\nVerdict: **Correct**.\n\nB. **In Task $2$, by leveraging superposition over comparisons in the BST, a quantum algorithm can locate $x^\\star$ using only $\\Theta(\\sqrt{\\log n})$ comparison queries.**\nThis statement reflects a misunderstanding of how quantum search applies to structured problems. As explained above, the quantum query complexity for ordered search is lower-bounded by $\\Omega(\\log n)$. A $\\Theta(\\sqrt{\\log n})$ complexity is not achievable.\nVerdict: **Incorrect**.\n\nC. **In Task $2$, the presence of total order information induces an $\\Omega(\\log n)$ quantum query lower bound for ordered search, so the best quantum algorithms still use $\\Theta(\\log n)$ queries up to constant factors, rather than $\\Theta(\\sqrt{n})$.**\nThis statement accurately describes the situation for ordered search. The $\\Omega(\\log n)$ lower bound is a standard result in quantum query complexity. Since the classical algorithm already achieves a $\\Theta(\\log n)$ query count, quantum algorithms offer no asymptotic speedup in terms of query complexity for this specific problem.\nVerdict: **Correct**.\n\nD. **If the keys are sorted but the oracle access is restricted to equality testing $O_{=}\\colon \\lvert y\\rangle \\lvert b\\rangle \\mapsto \\lvert y\\rangle \\lvert b \\oplus \\mathbf{1}[y = x^\\star]$, without exposing order information, the optimal quantum query complexity to find $x^\\star$ remains $\\Theta(\\sqrt{n})$, matching the unstructured case.**\nThis statement describes a scenario where the data has a structure (it's sorted), but the oracle does not provide access to that structure. The oracle $O_=$ only allows checking for equality. Without directional information ($y < x^\\star$ or $y > x^\\star$), an algorithm cannot perform binary search. The problem is therefore identical to a search on an unstructured database of $n$ items, as in Task 1. The optimal quantum query complexity is thus $\\Theta(\\sqrt{n})$.\nVerdict: **Correct**.", "answer": "$$\\boxed{ACD}$$", "id": "3242170"}, {"introduction": "Theoretical speedups must be weighed against the practicalities of classical computing, such as pre-computation and memory usage. This practice [@problem_id:3133889] moves beyond single-query analysis to compare Grover's search against classical hashing over a batch of queries. You will explore the important trade-offs between one-time processing costs and per-query efficiency, determining the threshold at which a clever classical approach can outperform a quantum one.", "problem": "You are given a static set of $N$ distinct keys drawn from a large universe, stored in arbitrary order in classical memory. You will receive a batch of $Q$ membership queries, each query asking whether a presented key is in the set. Assume the following computational models.\n\n- Classical, unstructured search with no precomputation uses only $O(1)$ extra memory and may sequentially inspect the stored keys.\n- Classical hashing with precomputation may preprocess the keys into a hash table using $O(N)$ extra memory and $O(N)$ preprocessing time; lookups in the resulting table have expected time $O(1)$ under standard hashing assumptions.\n- Grover’s algorithm for unstructured search runs in $O(\\sqrt{N})$ oracle queries per successful search using only $O(1)$ extra memory, and there is no assumed quantum random-access memory structure.\n\nYou should compare total time across the $Q$ queries and account for the one-time classical preprocessing cost when applicable. In addition, consider the effect of a memory budget $M$ when $M < N$ for classical hashing if relevant. Ignore constant factors and lower-order terms, and suppose that the hashing model uses separate chaining with table size proportional to the allocated memory so that load factor is $\\alpha = N/M$.\n\nWhich of the following statements are true?\n\nA. With no precomputation beyond $O(1)$ extra memory, Grover’s algorithm answers a single successful membership query in expected $O(\\sqrt{N})$ time, whereas the best classical method requires expected $O(N)$ time; thus Grover provides a quadratic advantage in $N$ in this regime.\n\nB. If a classical algorithm is allowed to build a hash table in $O(N)$ time using $O(N)$ memory, then for a batch of $Q$ queries the classical total time is $O(N + Q)$ while a straightforward application of Grover’s algorithm uses $O(Q\\sqrt{N})$ time. Consequently, there is a threshold $Q = \\Theta(\\sqrt{N})$ beyond which the classical approach is asymptotically faster in total time.\n\nC. With $O(N)$ precomputation memory, a quantum algorithm can combine Grover’s algorithm with hashing to achieve worst-case $O(1)$ query time while using only $O(\\sqrt{N})$ preprocessing time.\n\nD. Even when restricted to a precomputation memory budget $M = o(N)$, a classical algorithm can guarantee expected $O(1)$ lookup time for arbitrary adversarial queries by using a carefully chosen hash function.\n\nE. Under separate chaining with a table of $M$ slots built in $O(N)$ time, the classical expected lookup time per query is $O(1 + N/M)$; hence a simple time–memory tradeoff is that expected per-query time scales as $O(N/M)$ when $M \\ll N$.", "solution": "We are asked to compare the total time complexity of classical and quantum search algorithms under different scenarios, including single queries, batch queries, and memory constraints.\n\n**A. With no precomputation beyond $O(1)$ extra memory, Grover’s algorithm answers a single successful membership query in expected $O(\\sqrt{N})$ time, whereas the best classical method requires expected $O(N)$ time; thus Grover provides a quadratic advantage in $N$ in this regime.**\n*   **Classical Method:** With no precomputation and $O(1)$ memory, the only option is a linear scan through the $N$ keys. The expected time for a successful search is $O(N)$.\n*   **Grover's Algorithm:** The problem states Grover's algorithm uses $O(\\sqrt{N})$ oracle queries. Assuming each query takes constant time, the total time is $O(\\sqrt{N})$.\n*   **Advantage:** Comparing classical time $T_{cl} = O(N)$ to quantum time $T_q = O(\\sqrt{N})$, we see that $T_{cl} = O((T_q)^2)$. This signifies a quadratic speedup.\n*   **Verdict:** Correct.\n\n**B. If a classical algorithm is allowed to build a hash table in $O(N)$ time using $O(N)$ memory, then for a batch of $Q$ queries the classical total time is $O(N + Q)$ while a straightforward application of Grover’s algorithm uses $O(Q\\sqrt{N})$ time. Consequently, there is a threshold $Q = \\Theta(\\sqrt{N})$ beyond which the classical approach is asymptotically faster in total time.**\n*   **Classical Total Time:** This involves a one-time preprocessing cost of $O(N)$ to build the hash table, plus the time for $Q$ queries. With $O(N)$ memory, lookups are expected $O(1)$ each. Total time: $T_{cl} = O(N) + Q \\cdot O(1) = O(N+Q)$.\n*   **Quantum Total Time:** Running Grover's algorithm independently for each of the $Q$ queries takes $T_q = Q \\cdot O(\\sqrt{N}) = O(Q\\sqrt{N})$.\n*   **Threshold:** We find the crossover point by setting the complexities equal: $N+Q \\approx Q\\sqrt{N}$, which simplifies to $N \\approx Q(\\sqrt{N}-1)$. For large $N$, this gives $Q \\approx \\frac{N}{\\sqrt{N}} = \\sqrt{N}$. Thus, the threshold is $Q = \\Theta(\\sqrt{N})$. If $Q$ is asymptotically larger than $\\sqrt{N}$, the classical hashing approach becomes more efficient.\n*   **Verdict:** Correct.\n\n**C. With $O(N)$ precomputation memory, a quantum algorithm can combine Grover’s algorithm with hashing to achieve worst-case $O(1)$ query time while using only $O(\\sqrt{N})$ preprocessing time.**\n*   The claim of \"$O(\\sqrt{N})$ preprocessing time\" is incorrect. To build a data structure (like a hash table) for $N$ items, any algorithm must at least read all $N$ items, which requires $\\Omega(N)$ time. A sub-linear time preprocessing is not possible for this task.\n*   **Verdict:** Incorrect.\n\n**D. Even when restricted to a precomputation memory budget $M = o(N)$, a classical algorithm can guarantee expected $O(1)$ lookup time for arbitrary adversarial queries by using a carefully chosen hash function.**\n*   A memory budget of $M = o(N)$ means the table size $M$ is asymptotically smaller than the number of items $N$.\n*   The load factor is $\\alpha = N/M$. If $M = o(N)$, then $\\alpha = \\omega(1)$, meaning the load factor grows without bound.\n*   For any standard hashing scheme, the expected lookup time depends on the load factor $\\alpha$. For example, with separate chaining, it's $O(1+\\alpha)$. Since $\\alpha$ is not a constant, the expected lookup time cannot be $O(1)$.\n*   **Verdict:** Incorrect.\n\n**E. Under separate chaining with a table of $M$ slots built in $O(N)$ time, the classical expected lookup time per query is $O(1 + N/M)$; hence a simple time–memory tradeoff is that expected per-query time scales as $O(N/M)$ when $M \\ll N$.**\n*   **Expected Lookup Time:** For separate chaining with $N$ items and $M$ slots, the load factor is $\\alpha = N/M$. The expected time for a lookup (successful or unsuccessful) is $O(1+\\alpha)$, which is $O(1+N/M)$. This is a standard result from the analysis of hashing.\n*   **Time-Memory Tradeoff:** In the regime where $M \\ll N$, the term $N/M$ dominates the constant $1$. Therefore, the complexity $O(1 + N/M)$ simplifies to $O(N/M)$. This correctly describes the tradeoff: as memory $M$ decreases, the expected query time increases proportionally.\n*   **Verdict:** Correct.", "answer": "$$\\boxed{ABE}$$", "id": "3133889"}, {"introduction": "The concept of an \"oracle\" is an abstraction; in reality, it must be compiled into a physical quantum circuit with a tangible cost. This problem [@problem_id:3133929] guides you from the high-level model of query complexity to the practical world of fault-tolerant resource estimation. By estimating the $T$-count for a $3$-SAT oracle, you will learn how to quantify the implementation cost of a key component of a quantum algorithm.", "problem": "Consider building a Grover oracle for a Boolean formula in Conjunctive Normal Form (CNF) with $n$ input bits and $m$ clauses, where each clause is the disjunction of exactly three literals (three-satisfiability, also called $3$-SAT). The oracle should flip the phase of computational basis states $|x\\rangle$ that satisfy all clauses. Assume the standard reversible compute–phase–uncompute pattern, and that the circuit is compiled into the Clifford plus $T$ (Clifford+$T$) gate set. Use the following modeling assumptions that are common in fault-tolerant resource estimation:\n\n- Each literal is either a variable $x_{j}$ or its negation $\\neg x_{j}$, and negations are implemented by Pauli-$X$ gates, which are Clifford gates.\n- A two-input disjunction $a \\lor b$ is implemented reversibly via De Morgan’s law as $a \\lor b = \\neg(\\neg a \\land \\neg b)$, so its non-Clifford cost is that of one two-input conjunction.\n- A two-input conjunction is implemented by a controlled-controlled-NOT (Toffoli) using clean ancillae. Take the non-Clifford cost of one Toffoli to be exactly $7$ $T$ gates.\n- A three-input disjunction $a \\lor b \\lor c$ is built by composing two two-input disjunctions.\n- The global conjunction of the $m$ clause outputs is formed as a binary tree of two-input conjunctions with clean ancillae.\n- The phase flip conditioned on the final conjunction is implemented by a Clifford gate (for example, a controlled-$Z$), contributing no $T$ gates.\n- All intermediate values are uncomputed after the phase flip to restore all ancillae to $|0\\rangle$.\n\nUnder these assumptions, derive a closed-form symbolic expression for the total $T$-count of a single application of the Grover oracle as a function of $n$ and $m$. Express your final answer as a single analytic expression. No rounding is required, and no units are involved.", "solution": "The problem requires deriving the total $T$-count for a Grover oracle for a $3$-SAT instance with $m$ clauses. The oracle operates using the compute-phase-uncompute pattern. The total $T$-count, $T_{\\text{total}}$, is the sum of the $T$-counts for these three stages.\n\n1.  **Decomposition of the Oracle Cost**\n    The total $T$-count is $T_{\\text{total}} = T_{\\text{compute}} + T_{\\text{phase}} + T_{\\text{uncompute}}$.\n    -   **Phase Stage ($T_{\\text{phase}}$):** Assumption 6 states the conditional phase flip is a Clifford gate. Clifford gates have a $T$-count of 0. Thus, $T_{\\text{phase}} = 0$.\n    -   **Uncomputation Stage ($T_{\\text{uncompute}}$):** Assumption 7 states that the circuit is run in reverse to uncompute intermediate results. The inverse of a Clifford+$T$ circuit has the same $T$-count as the original circuit. Therefore, $T_{\\text{uncompute}} = T_{\\text{compute}}$.\n    -   This simplifies the total cost to: $T_{\\text{total}} = T_{\\text{compute}} + 0 + T_{\\text{compute}} = 2 \\times T_{\\text{compute}}$.\n    Our main task is to calculate $T_{\\text{compute}}$.\n\n2.  **Calculating the Computation Cost ($T_{\\text{compute}}$)**\n    The computation stage evaluates the entire $3$-SAT formula. This involves two steps: (A) evaluating all $m$ clauses individually, and (B) combining the results of these clauses.\n    $T_{\\text{compute}} = T_{\\text{clauses}} + T_{\\text{global\\_AND}}$.\n\n    **A. Cost of Evaluating $m$ Clauses ($T_{\\text{clauses}}$)**\n    -   Each clause is a 3-input disjunction ($a \\lor b \\lor c$).\n    -   Per assumption 4, this is built from two 2-input disjunctions (e.g., $(a \\lor b) \\lor c$).\n    -   Per assumption 2, the non-Clifford cost of a 2-input disjunction is the same as a 2-input conjunction.\n    -   Per assumption 3, a 2-input conjunction is a Toffoli gate, which costs $7$ $T$ gates.\n    -   Therefore, the cost of one 3-input clause is the cost of two Toffoli gates: $T_{\\text{clause}} = 2 \\times 7 = 14$ $T$ gates.\n    -   Since there are $m$ independent clauses, the total cost for this part is:\n        $$T_{\\text{clauses}} = m \\times T_{\\text{clause}} = 14m$$\n\n    **B. Cost of the Global Conjunction ($T_{\\text{global\\_AND}}$)**\n    -   This step computes the logical AND of the $m$ outputs from the clause evaluations.\n    -   Per assumption 5, this is done using a binary tree of 2-input conjunctions.\n    -   To compute the AND of $m$ bits, $m-1$ 2-input AND operations are needed.\n    -   Each 2-input AND is a Toffoli gate, costing $7$ $T$ gates.\n    -   The total cost for this part is:\n        $$T_{\\text{global\\_AND}} = (m-1) \\times 7 = 7m - 7$$\n\n    **Total Computation Cost**\n    Summing the costs from parts A and B:\n    $$T_{\\text{compute}} = T_{\\text{clauses}} + T_{\\text{global\\_AND}} = 14m + (7m - 7) = 21m - 7$$\n\n3.  **Final Calculation for the Oracle**\n    Finally, we substitute $T_{\\text{compute}}$ back into our expression for the total oracle cost:\n    $$T_{\\text{total}} = 2 \\times T_{\\text{compute}} = 2 \\times (21m - 7)$$\n    $$T_{\\text{total}} = 42m - 14$$\n\nThe number of variables, $n$, does not affect the $T$-count under these specific modeling assumptions, as all operations involving variables (negations) are Clifford gates. The cost depends only on the number of clauses, $m$.", "answer": "$$\\boxed{42m - 14}$$", "id": "3133929"}]}