{"hands_on_practices": [{"introduction": "To truly appreciate the difference between local and global minima, we must first experience how easily an algorithm can be misled. This practice challenges you to implement the workhorse of optimization, gradient descent, on a function specifically designed with a narrow valley and numerous local minima [@problem_id:3156569]. By experimenting with both constant and adaptive step sizes, you will gain first-hand insight into why sophisticated step-size control is not just a theoretical refinement but a practical necessity for navigating complex computational landscapes.", "problem": "Consider the function $f:\\mathbb{R}^2\\rightarrow\\mathbb{R}$ defined by $f(x,y)=x^2+100\\,y^2+\\sin(10\\,x)\\,\\sin(10\\,y)$, where all angles are measured in radians. This function combines a strongly anisotropic quadratic bowl with high-frequency oscillations, which induce many local minima. In introduction to computational science, distinguishing local minima from a global minimum and designing a step-size schedule that can traverse narrow valleys without getting trapped is essential.\n\nStarting from the core definitions:\n- A point $(x^\\star,y^\\star)$ is a local minimum if there exists a neighborhood $\\mathcal{N}$ of $(x^\\star,y^\\star)$ such that $f(x^\\star,y^\\star)\\le f(x,y)$ for all $(x,y)\\in\\mathcal{N}$.\n- A global minimum satisfies $f(x^\\star,y^\\star)\\le f(x,y)$ for all $(x,y)\\in\\mathbb{R}^2$.\n- Gradient-based methods update $(x,y)$ by moving in the direction of steepest descent, $-\\nabla f(x,y)$, with a chosen step size.\n\nYour task is to implement two optimization schemes on $f$ over the bounded domain $[-1,1]\\times[-1,1]$, projecting back to this domain after each update to avoid unbounded growth outside the plausible search region:\n1. Constant-step gradient descent: $(x_{k+1},y_{k+1})=(x_k,y_k)-\\alpha\\,\\nabla f(x_k,y_k)$ with fixed $\\alpha$, followed by projection of $(x_{k+1},y_{k+1})$ onto $[-1,1]\\times[-1,1]$.\n2. Adaptive-step gradient descent using backtracking line search with the sufficient decrease (Armijo) condition: starting from an initial step size $\\alpha_0$, repeatedly shrink by a factor $\\rho$ until $f((x,y)-\\alpha\\,\\nabla f(x,y))\\le f(x,y)-c\\,\\alpha\\,\\|\\nabla f(x,y)\\|_2^2$, then take the step and project onto $[-1,1]\\times[-1,1]$.\n\nYou must compute the gradient $\\nabla f(x,y)$ analytically and implement the algorithms strictly from these definitions. Angles in the $\\sin(\\cdot)$ and $\\cos(\\cdot)$ functions must be treated in radians.\n\nImplement both methods and compare their behavior on a set of initial conditions and step-size parameters chosen to reveal the narrow-valley effect and the distinction between local and global minima. Use the following test suite, which specifies method type, step-size parameters, initial point $(x_0,y_0)$, and maximum iterations $K$:\n- Test $1$: Constant-step descent with $\\alpha=0.02$, $(x_0,y_0)=(0.6,0.15)$, $K=1000$.\n- Test $2$: Constant-step descent with $\\alpha=0.05$, $(x_0,y_0)=(0.6,0.15)$, $K=1000$.\n- Test $3$: Constant-step descent with $\\alpha=0.0005$, $(x_0,y_0)=(0.6,0.15)$, $K=1000$.\n- Test $4$: Adaptive-step descent with $\\alpha_0=0.1$, $\\rho=0.5$, $c=10^{-4}$, $(x_0,y_0)=(0.6,0.15)$, $K=1000$.\n- Test $5$: Adaptive-step descent with $\\alpha_0=0.1$, $\\rho=0.5$, $c=10^{-4}$, $(x_0,y_0)=(0.0,0.9)$, $K=1000$.\n\nFor each test, run the algorithm until either the maximum iteration count $K$ is reached or the gradient norm $\\|\\nabla f(x,y)\\|_2$ falls below $10^{-8}$. After the run, report the final objective value $f(x_K,y_K)$ rounded to six decimal places. No physical units are involved; angles are in radians.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3,r_4,r_5]$), where each $r_i$ is the six-decimal rounded final objective value for Test $i$ in the order listed above.", "solution": "The user has provided a valid, well-posed problem in computational science. The task is to implement and compare two gradient descent-based optimization algorithms on a specified function, subject to domain constraints.\n\n### Problem Formulation\n\nThe objective is to find local minima of the function $f: \\mathbb{R}^2 \\rightarrow \\mathbb{R}$ defined as:\n$$f(x,y) = x^2 + 100\\,y^2 + \\sin(10\\,x)\\,\\sin(10\\,y)$$\nThe optimization is performed over the bounded domain $\\mathcal{D} = [-1, 1] \\times [-1, 1]$. The function $f(x,y)$ consists of two parts: a quadratic bowl $x^2 + 100y^2$ and an oscillatory term $\\sin(10x)\\sin(10y)$. The quadratic term creates a long, narrow valley aligned with the $x$-axis, as evidenced by the Hessian matrix of this term, $\\begin{pmatrix} 2  0 \\\\ 0  200 \\end{pmatrix}$, which has a large condition number of $100$. The oscillatory term superimposes many local minima onto this underlying structure, making it challenging for simple optimization algorithms to find a global minimum.\n\n### Gradient Calculation\n\nGradient-based methods require the analytical gradient of the objective function, $\\nabla f$. The partial derivatives with respect to $x$ and $y$ are calculated as follows:\n$$ \\frac{\\partial f}{\\partial x} = \\frac{\\partial}{\\partial x} (x^2 + 100\\,y^2 + \\sin(10\\,x)\\,\\sin(10\\,y)) = 2x + 10\\cos(10\\,x)\\sin(10\\,y) $$\n$$ \\frac{\\partial f}{\\partial y} = \\frac{\\partial}{\\partial y} (x^2 + 100\\,y^2 + \\sin(10\\,x)\\,\\sin(10\\,y)) = 200y + 10\\sin(10\\,x)\\cos(10\\,y) $$\nThus, the gradient vector is:\n$$ \\nabla f(x,y) = \\begin{pmatrix} 2x + 10\\cos(10\\,x)\\sin(10\\,y) \\\\ 200y + 10\\sin(10\\,x)\\cos(10\\,y) \\end{pmatrix} $$\nAll trigonometric functions operate on angles in radians.\n\n### Optimization Algorithms\n\nThe core algorithm is Projected Gradient Descent. At each iteration $k$, a candidate point is found by moving from the current point $(x_k, y_k)$ in the direction of the negative gradient (steepest descent). This new point is then projected back onto the feasible domain $\\mathcal{D}$. The iterative update is:\n$$ (\\tilde{x}_{k+1}, \\tilde{y}_{k+1}) = (x_k, y_k) - \\alpha_k \\nabla f(x_k, y_k) $$\n$$ (x_{k+1}, y_{k+1}) = \\text{Proj}_{\\mathcal{D}}(\\tilde{x}_{k+1}, \\tilde{y}_{k+1}) $$\nwhere $\\alpha_k$ is the step size at iteration $k$, and $\\text{Proj}_{\\mathcal{D}}$ is the projection operator onto the box $[-1, 1] \\times [-1, 1]$, defined as $(\\text{clip}(x, -1, 1), \\text{clip}(y, -1, 1))$.\n\nTwo strategies for choosing the step size $\\alpha_k$ are implemented:\n\n1.  **Constant-Step Gradient Descent**: A fixed step size $\\alpha_k = \\alpha$ is used for all iterations. The choice of $\\alpha$ is critical: if it is too large, the algorithm may become unstable and diverge; if it is too small, convergence will be impractically slow. This method is sensitive to the local curvature of the function, which varies significantly in this problem.\n\n2.  **Adaptive-Step Gradient Descent with Backtracking Line Search**: The step size $\\alpha_k$ is determined dynamically at each iteration. Starting with an initial guess $\\alpha_0$, the step size is repeatedly reduced by a factor $\\rho \\in (0,1)$ until it satisfies the Armijo (or sufficient decrease) condition:\n    $$ f((x_k,y_k) - \\alpha \\nabla f(x_k,y_k)) \\le f(x_k,y_k) - c \\alpha \\|\\nabla f(x_k,y_k)\\|_2^2 $$\n    for a small constant $c$ (e.g., $10^{-4}$). This ensures that each step makes sufficient progress in decreasing the objective function value, making the algorithm more robust and generally more efficient than the constant-step method. The Armijo condition is checked on the unconstrained step, before the projection is applied, as specified.\n\n### Implementation and Execution\n\nThe algorithms are implemented in Python using the `numpy` library. For each of the five specified test cases, the corresponding algorithm is initialized with the given starting point $(x_0, y_0)$ and parameters. The iterative process continues until either the maximum number of iterations, $K$, is reached, or the L2-norm of the gradient, $\\|\\nabla f(x,y)\\|_2$, falls below a tolerance of $10^{-8}$. The final objective function value $f(x,y)$ at the terminal point is then calculated and reported. This process is repeated for each test case to compare the effectiveness of the different parameterizations and methods.\n\nThe expected behavior is that the constant-step methods with poorly chosen step sizes (Tests $1$ and $2$) will perform poorly, either oscillating or getting stuck at the domain boundary with a high objective value. The very small step size (Test $3$) will make slow progress. The adaptive-step method (Tests $4$ and $5$) is expected to be robust, finding suitable step sizes automatically and converging to a low-value local minimum, demonstrating its superiority for complex optimization landscapes. The different starting points in Tests $4$ and $5$ will likely lead to convergence to different local minima, highlighting the path-dependent nature of local optimization.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and compares constant-step and adaptive-step projected gradient\n    descent algorithms for a given function and test suite.\n    \"\"\"\n\n    # Define the objective function f(p), its gradient grad_f(p), and the\n    # projection operator. p is a numpy array [x, y].\n    def f(p):\n        x, y = p\n        return x**2 + 100*y**2 + np.sin(10*x) * np.sin(10*y)\n\n    def grad_f(p):\n        x, y = p\n        df_dx = 2*x + 10*np.cos(10*x)*np.sin(10*y)\n        df_dy = 200*y + 10*np.sin(10*x)*np.cos(10*y)\n        return np.array([df_dx, df_dy])\n\n    def project(p):\n        return np.clip(p, -1, 1)\n\n    # Algorithm 1: Constant-step projected gradient descent\n    def constant_step_descent(alpha, p0, K, tol):\n        p = np.array(p0, dtype=float)\n        for _ in range(K):\n            grad = grad_f(p)\n            if np.linalg.norm(grad)  tol:\n                break\n            p_next_unprojected = p - alpha * grad\n            p = project(p_next_unprojected)\n        return f(p)\n\n    # Algorithm 2: Adaptive-step projected gradient descent with backtracking\n    def adaptive_step_descent(alpha0, rho, c, p0, K, tol):\n        p = np.array(p0, dtype=float)\n        for _ in range(K):\n            grad = grad_f(p)\n            grad_norm = np.linalg.norm(grad)\n            if grad_norm  tol:\n                break\n            \n            # Backtracking line search to satisfy the Armijo condition\n            alpha = alpha0\n            current_f_val = f(p)\n            grad_norm_sq = grad_norm**2\n            \n            while True:\n                p_candidate = p - alpha * grad\n                \n                # Check Armijo condition on the unprojected candidate point\n                if f(p_candidate) = current_f_val - c * alpha * grad_norm_sq:\n                    break\n                \n                alpha *= rho\n                \n                # Failsafe for pathologically small step sizes\n                if alpha  1e-16:\n                    break\n\n            p_next_unprojected = p - alpha * grad\n            p = project(p_next_unprojected)\n        return f(p)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test 1: Constant-step, alpha=0.02\n        {'method': 'constant', 'params': {'alpha': 0.02, 'p0': (0.6, 0.15), 'K': 1000}},\n        # Test 2: Constant-step, alpha=0.05\n        {'method': 'constant', 'params': {'alpha': 0.05, 'p0': (0.6, 0.15), 'K': 1000}},\n        # Test 3: Constant-step, alpha=0.0005\n        {'method': 'constant', 'params': {'alpha': 0.0005, 'p0': (0.6, 0.15), 'K': 1000}},\n        # Test 4: Adaptive-step\n        {'method': 'adaptive', 'params': {'alpha0': 0.1, 'rho': 0.5, 'c': 1e-4, 'p0': (0.6, 0.15), 'K': 1000}},\n        # Test 5: Adaptive-step, different initial point\n        {'method': 'adaptive', 'params': {'alpha0': 0.1, 'rho': 0.5, 'c': 1e-4, 'p0': (0.0, 0.9), 'K': 1000}},\n    ]\n\n    results = []\n    TOLERANCE = 1e-8\n    \n    for case in test_cases:\n        params = case['params']\n        if case['method'] == 'constant':\n            res = constant_step_descent(\n                alpha=params['alpha'],\n                p0=params['p0'],\n                K=params['K'],\n                tol=TOLERANCE\n            )\n        else: # 'adaptive'\n            res = adaptive_step_descent(\n                alpha0=params['alpha0'],\n                rho=params['rho'],\n                c=params['c'],\n                p0=params['p0'],\n                K=params['K'],\n                tol=TOLERANCE\n            )\n        results.append(res)\n    \n    # Final print statement in the exact required format.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3156569"}, {"introduction": "While numerical methods explore a function's landscape, analytical techniques provide rigorous proofs about the location of extrema within a defined region. This exercise transitions from numerical searching to the formal logic of constrained optimization, using the method of Lagrange multipliers to find the minimum of a function on a closed disk [@problem_id:3156548]. This practice is crucial for understanding how to methodically identify all candidate points—both in the interior and on the boundary—to definitively locate a global minimum.", "problem": "In computational modeling and numerical optimization, distinguishing between local and global minima is crucial for interpreting algorithmic outputs. Consider the nonconvex objective function defined on the closed unit disk in the plane, $$f(x,y) = \\sin(x) + \\sin(y),$$ with the inequality constraint $$x^{2} + y^{2} \\leq 1.$$ Using only core definitions of constrained local and global minima, and well-tested calculus facts about differentiability and necessary optimality conditions for smooth equality constraints (Karush–Kuhn–Tucker (KKT) conditions specialized to equality via the method of Lagrange multipliers), determine the constrained local minima that lie on the boundary $$x^{2} + y^{2} = 1,$$ and then identify the constrained global minimum over the entire closed disk. Your final numerical result must be the exact analytic expression for the minimal objective value $$\\min\\{\\,f(x,y) : x^{2} + y^{2} \\leq 1\\,\\}.$$ No rounding is required.", "solution": "The problem is to find the global minimum of the objective function $f(x,y) = \\sin(x) + \\sin(y)$ on the domain defined by the closed unit disk $D = \\{(x,y) \\in \\mathbb{R}^2 : x^2 + y^2 \\leq 1 \\}$.\n\nAccording to the Extreme Value Theorem, a continuous function on a compact set attains a global minimum and maximum. The function $f(x,y)$ is continuous everywhere, and the domain $D$ is a closed and bounded set (compact) in $\\mathbb{R}^2$. Therefore, a global minimum exists.\n\nThe search for the global minimum is conducted in two parts: analyzing the interior of the disk and analyzing its boundary.\n\n**1. Analysis of the Interior**\nThe interior of the disk is the open set $I = \\{(x,y) : x^2 + y^2  1 \\}$. Any local extremum in the interior must be a critical point, where the gradient of $f$ is zero. The gradient of $f$ is:\n$$ \\nabla f(x,y) = \\left( \\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y} \\right) = (\\cos(x), \\cos(y)) $$\nFor a point to be a critical point, we must have $\\nabla f(x,y) = (0,0)$, which implies the system of equations:\n$$ \\cos(x) = 0 $$\n$$ \\cos(y) = 0 $$\nThe solutions to $\\cos(t) = 0$ are $t = \\frac{\\pi}{2} + k\\pi$ for any integer $k$. Thus, any critical point must be of the form $(x,y) = (\\frac{\\pi}{2} + m\\pi, \\frac{\\pi}{2} + n\\pi)$ for integers $m, n$.\n\nWe must check if any such point lies within the interior of the unit disk, $x^2 + y^2  1$. The smallest possible non-zero magnitude for $x$ and $y$ satisfying these conditions is $|x| = \\frac{\\pi}{2}$ and $|y| = \\frac{\\pi}{2}$.\nSince $\\pi \\approx 3.14159$, we have $\\frac{\\pi}{2} \\approx 1.5708  1$.\nFor any critical point $(x,y)$, we have $|x| \\ge \\frac{\\pi}{2}$ and $|y| \\ge \\frac{\\pi}{2}$. Therefore,\n$$ x^2 + y^2 \\ge \\left(\\frac{\\pi}{2}\\right)^2 + \\left(\\frac{\\pi}{2}\\right)^2 = 2 \\frac{\\pi^2}{4} = \\frac{\\pi^2}{2} \\approx 4.93  1 $$\nThis contradicts the condition $x^2 + y^2  1$. Thus, there are no critical points of $f(x,y)$ in the interior of the unit disk. This implies that the global minimum must lie on the boundary of the disk.\n\n**2. Analysis of the Boundary**\nThe boundary is the circle defined by the equality constraint $g(x,y) = x^2 + y^2 - 1 = 0$. We use the method of Lagrange multipliers to find candidate points for local extrema on this boundary. The Lagrangian function is:\n$$ L(x, y, \\lambda) = f(x, y) - \\lambda g(x, y) = \\sin(x) + \\sin(y) - \\lambda(x^2 + y^2 - 1) $$\nTo find the critical points of the constrained system, we set the gradient of the Lagrangian to zero:\n$$ \\nabla L(x, y, \\lambda) = 0 $$\nThis yields the following system of equations:\n1. $\\frac{\\partial L}{\\partial x} = \\cos(x) - 2\\lambda x = 0 \\implies \\cos(x) = 2\\lambda x$\n2. $\\frac{\\partial L}{\\partial y} = \\cos(y) - 2\\lambda y = 0 \\implies \\cos(y) = 2\\lambda y$\n3. $\\frac{\\partial L}{\\partial \\lambda} = -(x^2 + y^2 - 1) = 0 \\implies x^2 + y^2 = 1$\n\nFirst, we analyze edge cases for equations $1$ and $2$.\n- If $\\lambda = 0$, then $\\cos(x)=0$ and $\\cos(y)=0$. As shown previously, this implies $x^2+y^2  1$, which contradicts equation $3$. So, $\\lambda \\neq 0$.\n- If $x=0$, equation $3$ gives $y = \\pm 1$. Equation $1$ becomes $\\cos(0) = 1 = 0$, a contradiction. So, $x \\neq 0$. By symmetry, $y \\neq 0$.\n\nSince $x, y, \\lambda$ are all non-zero, we can rewrite equations $1$ and $2$ as:\n$$ 2\\lambda = \\frac{\\cos(x)}{x} \\quad \\text{and} \\quad 2\\lambda = \\frac{\\cos(y)}{y} $$\nThis implies:\n$$ \\frac{\\cos(x)}{x} = \\frac{\\cos(y)}{y} $$\nLet's analyze the function $h(t) = \\frac{\\cos(t)}{t}$ for $t \\in [-1, 1] \\setminus \\{0\\}$, since any $(x,y)$ on the unit circle must satisfy $|x|\\le 1$ and $|y|\\le 1$.\nThe derivative of $h(t)$ is:\n$$ h'(t) = \\frac{-t\\sin(t) - \\cos(t)(1)}{t^2} = -\\frac{t\\sin(t) + \\cos(t)}{t^2} $$\nFor $t \\in (0, 1]$, we have $t > 0$, $\\sin(t) > 0$, and $\\cos(t) > 0$ (since $1  \\frac{\\pi}{2}$). Thus, the numerator $t\\sin(t) + \\cos(t)$ is strictly positive, and $h'(t)  0$. So $h(t)$ is strictly decreasing on $(0, 1]$. Since $h'(t)$ is an even function, $h'(t)$ is also negative on $[-1, 0)$. The function $h(t)$ is therefore strictly decreasing on $(0, 1]$ and on $[-1, 0)$ separately. The range of $h$ on $(0, 1]$ is positive, while on $[-1, 0)$ it is negative. Thus, for $h(x) = h(y)$ to hold, $x$ and $y$ must have the same sign. Since $h$ is injective on each interval, this implies $x=y$.\n\nSubstituting $x=y$ into the constraint equation $x^2+y^2=1$:\n$$ x^2 + x^2 = 1 \\implies 2x^2 = 1 \\implies x^2 = \\frac{1}{2} $$\nThis gives two solutions for $x$: $x = \\frac{1}{\\sqrt{2}}$ and $x = -\\frac{1}{\\sqrt{2}}$.\nSince $y=x$, we have two candidate points:\n- $P_1 = (\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}})$\n- $P_2 = (-\\frac{1}{\\sqrt{2}}, -\\frac{1}{\\sqrt{2}})$\n\n**3. Identification of Local and Global Minima**\nThe problem specifies using Karush-Kuhn-Tucker (KKT) conditions to identify local minima. For a minimization problem with constraint $g(x,y) \\le 0$, the KKT conditions for a point on the boundary require $\\nabla f(x,y) + \\mu \\nabla g(x,y) = 0$ with a multiplier $\\mu \\ge 0$.\nIn our Lagrange setup, $\\nabla f - \\lambda \\nabla g = 0$, so we have $\\mu = -\\lambda$. The condition for a local minimum is thus $\\lambda \\le 0$.\n\nLet's find the value of $\\lambda$ for each point:\n- At $P_1 = (\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}})$:\nFrom $\\cos(x) = 2\\lambda x$, we get $\\cos(\\frac{1}{\\sqrt{2}}) = 2\\lambda (\\frac{1}{\\sqrt{2}})$, so $\\lambda = \\frac{1}{\\sqrt{2}}\\cos(\\frac{1}{\\sqrt{2}})$. Since $0  \\frac{1}{\\sqrt{2}}  \\frac{\\pi}{2}$, $\\cos(\\frac{1}{\\sqrt{2}})  0$, so $\\lambda  0$. This point does not satisfy the necessary KKT condition for a local minimum; it is a candidate for a local maximum. The value is $f(P_1) = 2\\sin(\\frac{1}{\\sqrt{2}})$.\n\n- At $P_2 = (-\\frac{1}{\\sqrt{2}}, -\\frac{1}{\\sqrt{2}})$:\nFrom $\\cos(x) = 2\\lambda x$, we get $\\cos(-\\frac{1}{\\sqrt{2}}) = 2\\lambda (-\\frac{1}{\\sqrt{2}})$, which simplifies to $\\cos(\\frac{1}{\\sqrt{2}}) = -\\sqrt{2}\\lambda$. This gives $\\lambda = -\\frac{1}{\\sqrt{2}}\\cos(\\frac{1}{\\sqrt{2}})$. Since $\\cos(\\frac{1}{\\sqrt{2}})  0$, we have $\\lambda  0$. This point satisfies the necessary KKT condition for a local minimum. Thus, $P_2$ is a constrained local minimum. The value is $f(P_2) = \\sin(-\\frac{1}{\\sqrt{2}}) + \\sin(-\\frac{1}{\\sqrt{2}}) = -2\\sin(\\frac{1}{\\sqrt{2}})$.\n\nHaving analyzed both the interior and the boundary, the full set of candidate points for the global minimum consists only of the local minimum found on the boundary, $P_2$. As a global minimum is guaranteed to exist by the Extreme Value Theorem, this single candidate must be the global minimum.\n\nThe minimal value of the objective function on the closed unit disk is therefore the value at point $P_2$.\n$$ \\min_{x^2+y^2 \\le 1} f(x,y) = f\\left(-\\frac{1}{\\sqrt{2}}, -\\frac{1}{\\sqrt{2}}\\right) = -2\\sin\\left(\\frac{1}{\\sqrt{2}}\\right) $$", "answer": "$$\\boxed{-2\\sin\\left(\\frac{1}{\\sqrt{2}}\\right)}$$", "id": "3156548"}, {"introduction": "What if a landscape is so vast and littered with local minima that a simple search from one starting point is bound to fail? This hands-on practice introduces a powerful global optimization strategy called basin hopping, a metaheuristic designed to systematically escape these local traps [@problem_id:3156501]. By implementing an algorithm that combines deterministic local searches with stochastic jumps, you will explore how to balance local refinement (exploitation) with broad exploration to significantly increase the chances of discovering the true global minimum.", "problem": "You are to write a complete and runnable program that implements a basin hopping metaheuristic to study local versus global minima on a two-dimensional landscape. The objective function is $f(x,y) = \\sin(x) + \\sin(y) + 0.2(x^2 + y^2)$, where all angular arguments for the sine function must be treated in radians. The computational task is to examine how the stochastic jump radius influences the ability to discover the global minimum, through repeated local minimizations initiated from random points and interleaved with randomized jumps.\n\nThe foundational base for this problem is the following well-tested definitions and facts:\n- A point $(x^\\star,y^\\star)$ is a local minimum of a differentiable function $f$ if there exists a neighborhood $U$ of $(x^\\star,y^\\star)$ such that $f(x^\\star,y^\\star) \\le f(x,y)$ for all $(x,y) \\in U$. A point $(x^\\star,y^\\star)$ is a global minimum if $f(x^\\star,y^\\star) \\le f(x,y)$ for all $(x,y)$ in the domain.\n- For differentiable functions, local minimizers must satisfy the first-order stationarity condition $\\nabla f(x^\\star,y^\\star) = \\mathbf{0}$, and the second derivative (Hessian) provides local curvature information that influences local optimality.\n- Basin hopping is a metaheuristic that alternates deterministic local minimization with stochastic jumps in the search space to escape basins of attraction and improve the chance of finding global minima.\n\nYour program must implement the following in purely mathematical and logical terms:\n1. Define the function $f(x,y) = \\sin(x) + \\sin(y) + 0.2(x^2 + y^2)$ over the bounded domain $[-6,6] \\times [-6,6]$.\n2. Implement local minimization for $f$ using a gradient-based routine that respects the given bounds. The derivative of the sine function must be computed with angles in radians.\n3. Implement basin hopping with greedy acceptance: start from a random initial point $(x_0,y_0)$, perform a local minimization to obtain a local minimum $(x_\\mathrm{loc},y_\\mathrm{loc})$, propose a random jump of radius $r$ uniformly distributed over the disk of radius $r$ centered at $(x_\\mathrm{loc},y_\\mathrm{loc})$, clip the jumped point to the domain $[-6,6] \\times [-6,6]$, then locally minimize from the clipped point. Accept the new local minimum only if it strictly improves the objective value relative to the current local minimum; otherwise, retain the current one. Repeat this process for a fixed number of steps.\n4. Use a multi-start local minimization in one dimension to compute an accurate approximation of the global minimum of $g(t) = \\sin(t) + 0.2 t^2$ on $[-6,6]$, and infer the global minimum of $f$ using separability. Specifically, compute $t^\\star \\in [-6,6]$ that minimizes $g$, then the global minimum of $f$ occurs at $(t^\\star,t^\\star)$ with value $f^\\star = 2 g(t^\\star)$.\n5. Use a Pseudo-Random Number Generator (PRNG) with deterministic seeding to ensure reproducibility. Each test case must use a seed derived deterministically from its parameters. All random angles and uniform variables used in your program must be in radians and dimensionless, respectively.\n6. For each test case, count how many independent basin hopping runs end at the global minimum (within a prescribed tolerance), and report this count as an integer.\n\nAngle unit specification:\n- All trigonometric evaluations and angular samples must be in radians.\n\nThe test suite consists of five test cases that vary the jump radius $r$ to test different facets of the algorithm:\n- Case $1$ (boundary case): $r = 0.0$ (equivalent to pure local minimization without jumps).\n- Case $2$ (small jumps): $r = 0.5$.\n- Case $3$ (moderate jumps): $r = 1.5$.\n- Case $4$ (large jumps): $r = 3.0$.\n- Case $5$ (very large jumps): $r = 5.0$.\n\nCommon parameters for all test cases:\n- Domain bounds: $[-6,6] \\times [-6,6]$.\n- Number of basin hopping steps per run: $N = 60$.\n- Number of independent runs per test case: $R = 30$.\n- Global optimality tolerance: declare success if the final objective value is within $\\varepsilon = 10^{-6}$ of the computed global minimum $f^\\star$.\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The result for each test case is the integer count of successful runs out of $R$, in the order of the test cases above. For example, the output format is $[s_1,s_2,s_3,s_4,s_5]$, where each $s_i$ is an integer.\n\nScientific realism and constraints:\n- The basin hopping jump must be sampled uniformly in area over a disk of radius $r$. To achieve uniformity, sample the radius as $r \\sqrt{u}$ where $u$ is uniform in $[0,1]$, and the angle uniformly in $[0,2\\pi]$ in radians.\n- Local minimization must use gradient information and enforce the domain bounds through a bounded method.\n- All computations must be deterministic given the fixed seeds per test case.\n\nYour program must be self-contained, require no external input, and adhere strictly to the specified final output format.", "solution": "The problem requires the implementation of a basin hopping metaheuristic to explore the energy landscape of a two-dimensional function and assess how the algorithm's ability to find the global minimum is affected by the size of its stochastic jumps. The solution is constructed methodically, beginning with an analysis of the objective function to determine the true global minimum, followed by the implementation of the specified basin hopping algorithm.\n\nThe objective function is given by $f(x,y) = \\sin(x) + \\sin(y) + 0.2(x^2 + y^2)$ over the domain $(x,y) \\in [-6,6] \\times [-6,6]$. A key property of this function is its separability, meaning it can be expressed as a sum of two independent one-dimensional functions: $f(x,y) = g(x) + g(y)$, where $g(t) = \\sin(t) + 0.2t^2$. This property implies that the global minimum of $f(x,y)$ occurs at a point $(t^\\star, t^\\star)$, where $t^\\star$ is the value of $t$ that globally minimizes $g(t)$ on the interval $[-6,6]$.\n\nFirst, we must accurately determine this global minimum, which serves as the benchmark for success. The minimizers of $g(t)$ are either stationary points where the derivative $g'(t) = \\cos(t) + 0.4t$ is zero, or the boundary points $t = -6$ and $t = 6$. A numerical investigation reveals that $g(t)$ has two local minima within the interval $[-6,6]$. As stipulated, a multi-start local minimization approach is used to find the global minimum of $g(t)$. We perform bounded one-dimensional minimization on sub-intervals that contain these local minima (e.g., $[-6,0]$ and $[0,6]$) and compare the resulting values with the function values at the domain boundaries $g(-6)$ and $g(6)$. This procedure robustly identifies the global minimum of $g(t)$ at $t^\\star \\approx -1.30644$, with a value of $g(t^\\star) \\approx -0.62638$. Consequently, the global minimum of the two-dimensional function $f(x,y)$ is $f^\\star = f(t^\\star, t^\\star) = 2g(t^\\star) \\approx -1.252767$. This value will be the target for our optimization runs.\n\nThe core of the problem is the basin hopping algorithm. This is a stochastic global optimization technique designed to overcome the primary weakness of local search methods: getting trapped in local minima. The algorithm operates by iteratively applying two phases: a deterministic local minimization and a stochastic \"hop\" or perturbation to a new starting point.\n\nThe implementation proceeds as follows for each test case, which is defined by a specific jump radius $r$:\n$1$. A set of $R=30$ independent runs is performed to ensure statistically meaningful results. Each run is initialized with a deterministic seed derived from the test case and run index to guarantee reproducibility.\n$2$. Each run begins by selecting a random starting point $(x_0, y_0)$ uniformly from the domain $[-6,6] \\times [-6,6]$. From this point, a local minimization is performed to find the first local minimum, which becomes the initial \"best\" solution found, $(x_{\\text{best}}, y_{\\text{best}})$.\n$3$. The local minimization is carried out using a gradient-based quasi-Newton method, specifically the Limited-memory Broyden–Fletcher–Goldfarb–Shanno algorithm with box constraints (`L-BFGS-B`). This method is efficient and respects the domain boundaries, as required. It uses the analytical gradient (Jacobian) of $f(x,y)$, which is $\\nabla f(x,y) = (\\cos(x)+0.4x, \\cos(y)+0.4y)$, for faster convergence.\n$4$. The main basin hopping loop then executes for $N=60$ steps. In each step:\n    a. A new candidate point is generated by taking a stochastic jump from the current best minimum, $x_{\\text{best}}$. The jump is sampled uniformly from a disk of radius $r$. To achieve this, a jump magnitude $\\rho$ is sampled as $\\rho = r \\sqrt{u}$ where $u \\sim U(0,1)$, and a jump angle $\\theta$ is sampled from $\\theta \\sim U(0, 2\\pi)$. The new point is $x_{\\text{prop}} = x_{\\text{best}} + (\\rho\\cos\\theta, \\rho\\sin\\theta)$.\n    b. The proposed point $x_{\\text{prop}}$ is clipped to ensure it remains within the domain $[-6,6] \\times [-6,6]$.\n    c. A new local minimization is initiated from this clipped point, yielding a new local minimum, $x_{\\text{new}}$, with function value $f_{\\text{new}}$.\n    d. A greedy acceptance criterion is applied: if $f_{\\text{new}}  f_{\\text{best}}$, the new minimum is accepted as the current best solution. Otherwise, the algorithm remains at the previous best minimum. This ensures that the search trajectory on the landscape of local minima is monotonically decreasing in energy.\n$5$. After $N=60$ steps, the final function value $f_{\\text{best}}$ is compared against the pre-computed global minimum $f^\\star$. If $|f_{\\text{best}} - f^\\star|  \\varepsilon$ where the tolerance $\\varepsilon=10^{-6}$, the run is counted as a success.\n$6$. The total count of successful runs out of $R=30$ is recorded for the given jump radius $r$.\n\nThis entire process is repeated for each of the five specified radii ($r=0.0, 0.5, 1.5, 3.0, 5.0$), and the resulting success counts are aggregated into a final list. The case $r=0.0$ serves as a control, corresponding to a multi-start local search without any jumps. The varying radii are designed to probe the trade-off between exploration (large jumps) and exploitation (small jumps) in finding the global minimum.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize, minimize_scalar\n\ndef solve():\n    \"\"\"\n    Implements a basin hopping metaheuristic to find the global minimum of a 2D function.\n    The program evaluates the success rate for different jump radii.\n    \"\"\"\n    # Common parameters for all test cases\n    N_STEPS = 60\n    N_RUNS = 30\n    DOMAIN_BOUNDS_1D = (-6, 6)\n    DOMAIN_BOUNDS_2D = [(-6, 6), (-6, 6)]\n    GLOBAL_TOLERANCE = 1e-6\n    TEST_CASES_R = [0.0, 0.5, 1.5, 3.0, 5.0]\n\n    # --- Step 1: Define objective function and its gradient ---\n    def f(p):\n        \"\"\"The 2D objective function f(x, y).\"\"\"\n        x, y = p\n        return np.sin(x) + np.sin(y) + 0.2 * (x**2 + y**2)\n\n    def jac_f(p):\n        \"\"\"The Jacobian (gradient) of the objective function.\"\"\"\n        x, y = p\n        return np.array([np.cos(x) + 0.4 * x, np.cos(y) + 0.4 * y])\n\n    # --- Step 2: Compute the true global minimum value ---\n    def g(t):\n        \"\"\"The 1D component of the separable function f(x, y).\"\"\"\n        return np.sin(t) + 0.2 * t**2\n\n    # Use multi-start local minimization for the 1D function g(t)\n    # Search for minima in sub-intervals based on analysis of g'(t).\n    res1 = minimize_scalar(g, bounds=(-3, 0), method='bounded')\n    res2 = minimize_scalar(g, bounds=(2, 5), method='bounded')\n    \n    # Consider the domain endpoints as potential minima\n    g_at_endpoints = [g(DOMAIN_BOUNDS_1D[0]), g(DOMAIN_BOUNDS_1D[1])]\n\n    # The global minimum of g(t) is the minimum of all found local minima and endpoint values.\n    global_min_g = min(res1.fun, res2.fun, *g_at_endpoints)\n    \n    # The global minimum of f(x,y) is twice the global minimum of g(t).\n    f_star = 2 * global_min_g\n\n    # --- Step 3: Run basin hopping for each test case ---\n    results = []\n    for i, r in enumerate(TEST_CASES_R):\n        success_count = 0\n        for j in range(N_RUNS):\n            # Use a deterministic seed for reproducibility, unique for each run.\n            seed = i * N_RUNS + j\n            rng = np.random.default_rng(seed)\n\n            # Start from a random initial point within the domain.\n            x0 = rng.uniform(DOMAIN_BOUNDS_1D[0], DOMAIN_BOUNDS_1D[1], size=2)\n\n            # Perform an initial local minimization.\n            res = minimize(f, x0, jac=jac_f, method='L-BFGS-B', bounds=DOMAIN_BOUNDS_2D)\n            x_best = res.x\n            f_best = res.fun\n\n            # Perform N basin hopping steps.\n            for _ in range(N_STEPS):\n                # Propose a random jump, sampled uniformly from a disk of radius r.\n                jump_magnitude = r * np.sqrt(rng.uniform(0, 1))\n                jump_angle = rng.uniform(0, 2 * np.pi)\n                \n                jump_vector = np.array([jump_magnitude * np.cos(jump_angle), \n                                        jump_magnitude * np.sin(jump_angle)])\n                \n                x_proposed = x_best + jump_vector\n                \n                # Clip the new point to stay within the domain.\n                x_proposed_clipped = np.clip(x_proposed, DOMAIN_BOUNDS_1D[0], DOMAIN_BOUNDS_1D[1])\n\n                # Perform a local minimization from the new point.\n                res_new = minimize(f, x_proposed_clipped, jac=jac_f, method='L-BFGS-B', bounds=DOMAIN_BOUNDS_2D)\n                \n                # Greedy acceptance criterion: accept only if strictly better.\n                if res_new.fun  f_best:\n                    x_best = res_new.x\n                    f_best = res_new.fun\n\n            # After all steps, check if the found minimum is the global minimum.\n            if abs(f_best - f_star)  GLOBAL_TOLERANCE:\n                success_count += 1\n                \n        results.append(success_count)\n\n    # --- Step 4: Final Output ---\n    # Print the success counts for each test case in the specified format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3156501"}]}