{"hands_on_practices": [{"introduction": "In computational science, performance is often limited by more than just raw processing power. This exercise explores a common scenario where both CPU speed and data access (I/O) bandwidth are constraints. You will step into the role of a systems designer to develop a mathematical model that optimally balances these competing resources. By deriving the solution from first principles, you will uncover an elegant principle: to achieve the fastest completion time, both the workload and the shared I/O bandwidth must be allocated in proportion to the computational power of each worker [@problem_id:3155775]. This practice provides a sharp, analytical foundation for understanding multi-resource load balancing.", "problem": "You are designing a batch compressor that splits a total data size $S$ (in megabytes) across $W$ parallel workers. Worker $j$ has a Central Processing Unit (CPU) compression rate $c_j$ (in megabytes per second). All workers read their data from a single shared storage system with total Input/Output (I/O) bandwidth $B$ (in megabytes per second) that can be arbitrarily split among workers as instantaneous bandwidth shares $u_j$ (in megabytes per second), subject to the constraint that the sum of the shares does not exceed the total bandwidth.\n\nStart from the following fundamental base:\n- For any serial stages of work, total time is additive. If a worker must read and then compute, the time is the sum of the read time and the compute time.\n- Time equals work divided by rate. If a worker processes a data amount $x$ at rate $r$, the time spent is $x/r$.\n\nModel each worker $j$ as processing a chunk of size $x_j$ (in megabytes). The worker reads at bandwidth share $u_j$ (in megabytes per second) and computes at CPU rate $c_j$ (in megabytes per second). There is no overlap between I/O and CPU; the stages are serial. Therefore, the completion time for worker $j$ is\n$$\nt_j = \\frac{x_j}{u_j} + \\frac{x_j}{c_j}.\n$$\nThe shared I/O bandwidth must satisfy\n$$\n\\sum_{j=1}^{W} u_j \\le B,\n$$\nand the total data constraint is\n$$\n\\sum_{j=1}^{W} x_j = S,\n$$\nwith $x_j \\ge 0$ and $u_j \\ge 0$ for all $j$.\n\nYour tasks are:\n- Derive, from the stated base and constraints only, the optimal assignments $\\{x_j\\}_{j=1}^W$ and $\\{u_j\\}_{j=1}^W$ that minimize the makespan, defined as the common completion time $t$ under the equalization constraint $t_j = t$ for all $j$ with $x_j > 0$.\n- Express the common completion time $t$ (in seconds) as a function of $S$, $B$, and $\\{c_j\\}$.\n- Provide explicit formulas for the optimal chunk sizes $x_j$ (in megabytes) and bandwidth shares $u_j$ (in megabytes per second) in terms of $S$, $B$, and $\\{c_j\\}$.\n\nImplement a program that computes, for each provided test case, a single list containing:\n- First, the common completion time $t$ in seconds.\n- Next, the chunk sizes $x_1, x_2, \\ldots, x_W$ in megabytes.\n- Finally, the bandwidth shares $u_1, u_2, \\ldots, u_W$ in megabytes per second.\n\nAll numeric outputs must be expressed in the units specified above and rounded to exactly $6$ decimal places. The program must aggregate the results for all test cases into a single line: a comma-separated list of per-test-case lists, each enclosed in square brackets, and the entire aggregate enclosed in square brackets. For example, the final output should look like\n$[$ $[\\,\\text{case1\\_values}\\,]$ $,$ $[\\,\\text{case2\\_values}\\,]$ $,$ $\\ldots$ $]$.\n\nTest suite:\n- Case $1$: $S = 1000$, $B = 400$, $\\{c_j\\} = [50, 100, 150]$.\n- Case $2$: $S = 800$, $B = 100000$, $\\{c_j\\} = [80, 40, 80]$.\n- Case $3$: $S = 600$, $B = 60$, $\\{c_j\\} = [500, 200, 100]$.\n- Case $4$: $S = 123$, $B = 500$, $\\{c_j\\} = [200]$.\n- Case $5$: $S = 100$, $B = 100$, $\\{c_j\\} = [1, 9]$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case is represented by a bracketed list in the order $[t, x_1, \\ldots, x_W, u_1, \\ldots, u_W]$, with all numbers rounded to exactly $6$ decimal places and no unit symbols included in the printed output.", "solution": "The problem is subjected to validation against the established criteria.\n\n### Step 1: Extract Givens\n- Total data size: $S$ (megabytes)\n- Number of parallel workers: $W$\n- CPU compression rate for worker $j$: $c_j$ (megabytes per second)\n- Total shared I/O bandwidth: $B$ (megabytes per second)\n- Bandwidth share for worker $j$: $u_j$ (megabytes per second)\n- Data chunk size for worker $j$: $x_j$ (megabytes)\n- Completion time for worker $j$: $t_j = \\frac{x_j}{u_j} + \\frac{x_j}{c_j}$\n- Bandwidth constraint: $\\sum_{j=1}^{W} u_j \\le B$\n- Total data constraint: $\\sum_{j=1}^{W} x_j = S$\n- Non-negativity constraints: $x_j \\ge 0$, $u_j \\ge 0$ for all $j=1, \\ldots, W$.\n- Optimization objective: Minimize the makespan, $t$.\n- Equalization constraint: $t_j = t$ for all workers $j$ with $x_j > 0$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed as **valid**.\n- **Scientifically Grounded**: The model is based on fundamental principles of performance modeling in computational science, specifically relating work, rate, and time, and considering constraints on shared resources.\n- **Well-Posed**: The problem is a well-defined constrained optimization problem to minimize the makespan under an equalization constraint, which typically admits a unique and meaningful solution.\n- **Objective**: The problem is stated using precise, unambiguous mathematical and physical terms.\n- **Completeness and Consistency**: The problem provides all necessary data and constraints for a unique solution to be derived. The constraints are consistent with one another. To minimize time, it is implicit that the full bandwidth capacity will be utilized, thus $\\sum u_j = B$.\n- **Realism**: The physical quantities and their relationships are realistic simplifications used in performance analysis.\n\n### Step 3: Verdict and Action\nThe problem is valid. The derivation of the solution follows.\n\n### Derivation of Optimal Assignments and Completion Time\n\nThe objective is to minimize the common completion time, or makespan, $t$. The problem is formulated as finding the values of $\\{x_j\\}_{j=1}^W$ and $\\{u_j\\}_{j=1}^W$ that achieve this minimum $t$, subject to the given constraints.\n\nFor any worker $j$ assigned a non-zero chunk of data ($x_j > 0$), its completion time is given by:\n$$t_j = \\frac{x_j}{u_j} + \\frac{x_j}{c_j}$$\nThe equalization constraint requires that $t_j = t$ for all such workers.\n$$t = x_j \\left(\\frac{1}{u_j} + \\frac{1}{c_j}\\right)$$\nThis equation implies that for a given makespan $t$, the amount of data $x_j$ a worker can process depends on its assigned I/O bandwidth $u_j$ and its intrinsic CPU rate $c_j$.\n\nTo minimize $t$ for a fixed total amount of work $S$, the system must operate at its maximum possible aggregate throughput. The aggregate throughput is $\\frac{S}{t}$. Maximizing this throughput is equivalent to minimizing $t$.\n\nLet us express the total work $S$ in terms of $t$ and the individual assignments. First, we rearrange the time equation to solve for $x_j$:\n$$x_j = \\frac{t}{\\frac{1}{u_j} + \\frac{1}{c_j}} = t \\frac{u_j c_j}{u_j + c_j}$$\nSumming over all workers, we use the total data constraint $\\sum x_j = S$:\n$$S = \\sum_{j=1}^{W} x_j = \\sum_{j=1}^{W} t \\frac{u_j c_j}{u_j + c_j} = t \\sum_{j=1}^{W} \\frac{u_j c_j}{u_j + c_j}$$\nFrom this, the aggregate throughput is:\n$$\\frac{S}{t} = \\sum_{j=1}^{W} \\frac{u_j c_j}{u_j + c_j}$$\nOur optimization problem is to maximize this aggregate throughput by choosing the bandwidth shares $\\{u_j\\}$ subject to the constraints $\\sum_{j=1}^{W} u_j \\le B$ and $u_j \\ge 0$. To maximize throughput, the system should not be artificially bottlenecked by underutilizing the I/O resource. Therefore, the optimal solution must lie on the boundary of the constraint, where $\\sum_{j=1}^{W} u_j = B$.\n\nWe formulate this as a constrained optimization problem using the method of Lagrange multipliers. The Lagrangian function $\\mathcal{L}$ is:\n$$\\mathcal{L}(\\{u_j\\}, \\lambda) = \\sum_{j=1}^{W} \\frac{u_j c_j}{u_j + c_j} - \\lambda \\left(\\sum_{j=1}^{W} u_j - B\\right)$$\nTo find the optimal $\\{u_j\\}$, we set the partial derivative of $\\mathcal{L}$ with respect to each $u_k$ to zero:\n$$\\frac{\\partial \\mathcal{L}}{\\partial u_k} = \\frac{\\partial}{\\partial u_k}\\left(\\frac{u_k c_k}{u_k + c_k}\\right) - \\lambda = 0$$\nUsing the quotient rule for differentiation, we find:\n$$\\frac{\\partial}{\\partial u_k}\\left(\\frac{u_k c_k}{u_k + c_k}\\right) = \\frac{c_k(u_k + c_k) - u_k c_k(1)}{(u_k + c_k)^2} = \\frac{c_k^2}{(u_k + c_k)^2}$$\nThus, for each worker $k$, we have:\n$$\\frac{c_k^2}{(u_k + c_k)^2} = \\lambda \\implies \\frac{c_k}{u_k + c_k} = \\sqrt{\\lambda}$$\nWe solve for $u_k$:\n$$u_k + c_k = \\frac{c_k}{\\sqrt{\\lambda}} \\implies u_k = c_k \\left(\\frac{1}{\\sqrt{\\lambda}} - 1\\right)$$\nThis shows that $u_k$ is proportional to $c_k$. We determine the constant of proportionality (related to $\\lambda$) by applying the bandwidth constraint $\\sum u_k = B$:\n$$B = \\sum_{k=1}^{W} u_k = \\sum_{k=1}^{W} c_k \\left(\\frac{1}{\\sqrt{\\lambda}} - 1\\right) = \\left(\\frac{1}{\\sqrt{\\lambda}} - 1\\right) \\sum_{k=1}^{W} c_k$$\nLet $C_{\\text{total}} = \\sum_{k=1}^{W} c_k$. Then:\n$$B = \\left(\\frac{1}{\\sqrt{\\lambda}} - 1\\right) C_{\\text{total}} \\implies \\frac{1}{\\sqrt{\\lambda}} - 1 = \\frac{B}{C_{\\text{total}}}$$\nSubstituting this back into the expression for $u_k$:\n$$u_k = c_k \\left(\\frac{B}{C_{\\text{total}}}\\right) = B \\frac{c_k}{\\sum_{j=1}^W c_j}$$\nThis is the explicit formula for the optimal bandwidth shares $u_k$. It dictates that the total bandwidth $B$ should be allocated to workers in proportion to their CPU rates $c_k$.\n\nWith the optimal $u_j$ found, we can determine the minimal makespan $t$. First, we compute the term $\\frac{u_j c_j}{u_j + c_j}$:\n$$u_j + c_j = B \\frac{c_j}{C_{\\text{total}}} + c_j = c_j \\left(\\frac{B}{C_{\\text{total}}} + 1\\right) = c_j \\frac{B + C_{\\text{total}}}{C_{\\text{total}}}$$\n$$\\frac{u_j c_j}{u_j + c_j} = \\frac{\\left(B \\frac{c_j}{C_{\\text{total}}}\\right)c_j}{c_j \\frac{B + C_{\\text{total}}}{C_{\\text{total}}}} = \\frac{B c_j}{B + C_{\\text{total}}}$$\nThe aggregate throughput is the sum of these terms:\n$$\\frac{S}{t} = \\sum_{j=1}^{W} \\frac{B c_j}{B + C_{\\text{total}}} = \\frac{B}{B + C_{\\text{total}}} \\sum_{j=1}^{W} c_j = \\frac{B \\, C_{\\text{total}}}{B + C_{\\text{total}}}$$\nSolving for $t$, we obtain the formula for the minimal makespan:\n$$t = S \\frac{B + C_{\\text{total}}}{B \\, C_{\\text{total}}} = S \\left(\\frac{1}{B} + \\frac{1}{C_{\\text{total}}}\\right)$$\nThis elegant result shows the total time is determined by the total work $S$ divided by an effective system rate, which is the harmonic sum of the total I/O bandwidth $B$ and the total CPU rate $C_{\\text{total}}$.\n\nFinally, we find the optimal data chunk sizes $x_j$. Using the expression for $x_j$ derived earlier:\n$$x_j = t \\frac{u_j c_j}{u_j + c_j} = t \\left(\\frac{B c_j}{B + C_{\\text{total}}}\\right)$$\nSubstituting the formula for $t$:\n$$x_j = S \\left(\\frac{B + C_{\\text{total}}}{B \\, C_{\\text{total}}}\\right) \\left(\\frac{B c_j}{B + C_{\\text{total}}}\\right) = S \\frac{c_j}{C_{\\text{total}}} = S \\frac{c_j}{\\sum_{k=1}^W c_k}$$\nThis demonstrates that the total data $S$ should also be partitioned among workers in proportion to their CPU rates $c_j$.\n\n### Summary of Formulas\n1.  **Total CPU rate**: $C_{\\text{total}} = \\sum_{j=1}^{W} c_j$\n2.  **Optimal common completion time**: $t = S \\left(\\frac{1}{B} + \\frac{1}{C_{\\text{total}}}\\right)$\n3.  **Optimal chunk sizes**: $x_j = S \\frac{c_j}{C_{\\text{total}}}$\n4.  **Optimal bandwidth shares**: $u_j = B \\frac{c_j}{C_{\\text{total}}}$\n\nThese formulas will be implemented to solve the given test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the optimal completion time, chunk sizes, and bandwidth shares\n    for a parallel processing problem.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1000, 400, [50, 100, 150]),     # Case 1\n        (800, 100000, [80, 40, 80]),    # Case 2\n        (600, 60, [500, 200, 100]),     # Case 3\n        (123, 500, [200]),              # Case 4\n        (100, 100, [1, 9]),             # Case 5\n    ]\n\n    all_results_str = []\n    \n    for S, B, c_j_list in test_cases:\n        # Convert inputs to numpy array for vectorized operations\n        c_j = np.array(c_j_list, dtype=float)\n        \n        # Calculate the total CPU rate\n        C_total = np.sum(c_j)\n\n        # Handle potential division by zero, though not expected from problem constraints.\n        if B == 0 or C_total == 0:\n            # This scenario corresponds to an infinite completion time.\n            # As the problem implies positive inputs, we proceed with calculation.\n            # A robust implementation might raise an error here.\n            continue\n\n        # Derived formula for the common completion time t\n        t = S * (1.0 / B + 1.0 / C_total)\n\n        # Derived formula for optimal chunk sizes x_j\n        x_j = S * (c_j / C_total)\n\n        # Derived formula for optimal bandwidth shares u_j\n        u_j = B * (c_j / C_total)\n\n        # Assemble the results for the current case in the specified order\n        case_result = [t] + x_j.tolist() + u_j.tolist()\n        \n        # Format each number to 6 decimal places and create the bracketed string\n        case_result_str = f\"[{','.join([f'{val:.6f}' for val in case_result])}]\"\n        all_results_str.append(case_result_str)\n\n    # Final print statement in the exact required format: a list of lists.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```", "id": "3155775"}, {"introduction": "When designing a parallel application, a fundamental choice is how to distribute tasks among workers. Should you divide the work statically ahead of time, or should you implement a dynamic \"work-stealing\" model where idle workers grab new tasks from a shared queue? This hands-on simulation [@problem_id:3155817] allows you to conduct a computational experiment to answer this very question. By modeling both a distributed-memory system with static partitioning and a shared-memory system with dynamic scheduling, you will gain tangible insights into the trade-offs between them, particularly how task time variability and communication overhead influence which strategy wins.", "problem": "You must write a complete, runnable program that simulates and compares two load balancing strategies for parallel task execution while controlling the number of worker entities, the number of independent tasks, and the variance of task durations. The comparison is between a distributed memory system using static partitioning and a shared memory system using dynamic scheduling. The program must be self-contained, require no user input, and produce the specified output format in a single line.\n\nFundamental base and definitions to be used:\n- A distributed memory system assigns tasks to processors that do not share a centralized state; in static partitioning, each processor receives a predetermined subset of tasks. A shared memory system provides a global state accessible by all threads; in dynamic scheduling, a centralized queue provides one task at a time to the next available worker.\n- The total work is the sum of all task durations, written as $W = \\sum_{i=1}^{n} t_i$, where $n$ is the number of tasks and $t_i$ is the duration of task $i$. The makespan is the parallel completion time, written as $T = \\max_{j \\in \\{1,\\dots,p\\}} L_j$, where $p$ is the number of processors or threads and $L_j$ is the total load processed by worker $j$ including any overhead. Load balancing aims to minimize the variance of $L_j$ so that $T$ is near $W/p$.\n- Each task duration $t_i$ must be strictly nonnegative and measured in seconds. Any overhead for scheduling or communication must also be measured in seconds. Answer anything that involves physical time in seconds.\n\nSimulation specifications:\n- Tasks are independent and have durations $t_i$ drawn from a normal distribution with mean $\\mu$ seconds and standard deviation $\\sigma$ seconds, truncated at $0$ to enforce nonnegativity. Use a Random Number Generator (RNG) with a fixed seed per test case for reproducibility.\n- Distributed memory static partitioning: partition $n$ tasks into $p$ blocks using contiguous assignment. The first $r = n \\bmod p$ processors receive $b+1$ tasks, and the remaining $p-r$ processors receive $b$ tasks, where $b = \\left\\lfloor \\frac{n}{p} \\right\\rfloor$. The load on processor $j$ is $L^{\\text{dist}}_j = \\sum t_i + o_{\\text{dist}} \\cdot m_j$, where $m_j$ is the number of tasks assigned to processor $j$ and $o_{\\text{dist}}$ is the per-task overhead in seconds for distributed memory (e.g., communication or dispatch cost).\n- Shared memory dynamic scheduling: maintain a centralized queue of $n$ tasks. Each of $p$ workers repeatedly pulls the next available task when it becomes idle. The completion time of a worker increases by $t_i + o_{\\text{sh}}$ for each task it processes, where $o_{\\text{sh}}$ is the per-task overhead in seconds for shared memory (e.g., contention or scheduler cost). The makespan is the maximum completion time among all workers.\n\nYour program must implement both strategies and compute their makespans:\n- $T_{\\text{dist}} = \\max_j L^{\\text{dist}}_j$ for distributed static partitioning.\n- $T_{\\text{sh}}$ for shared dynamic scheduling from the event-driven assignment described above.\n\nRequired output:\n- For each test case, compute the ratio $R = \\frac{T_{\\text{dist}}}{T_{\\text{sh}}}$. This ratio is dimensionless (unitless). Larger $R$ indicates that shared memory dynamic scheduling is faster relative to distributed static partitioning for that case.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3]$), where each $r_k$ is the floating-point ratio for the $k$-th test case.\n\nTest suite:\nUse the following parameter sets. All time-related quantities must be handled in seconds. The RNG seed must be applied exactly as specified to make the results deterministic.\n- Case $1$ (happy path, low variance): $p=4$, $n=100$, $\\mu=1.0$ seconds, $\\sigma=0.1$ seconds, $o_{\\text{sh}}=0.0005$ seconds, $o_{\\text{dist}}=0.005$ seconds, seed $=42$.\n- Case $2$ (high variance): $p=8$, $n=1000$, $\\mu=0.5$ seconds, $\\sigma=0.6$ seconds, $o_{\\text{sh}}=0.0002$ seconds, $o_{\\text{dist}}=0.01$ seconds, seed $=123$.\n- Case $3$ (boundary: $p \\gg n$): $p=32$, $n=40$, $\\mu=1.0$ seconds, $\\sigma=0.5$ seconds, $o_{\\text{sh}}=0.0002$ seconds, $o_{\\text{dist}}=0.005$ seconds, seed $=98765$.\n- Case $4$ (moderate variance, different overheads): $p=16$, $n=1000$, $\\mu=0.2$ seconds, $\\sigma=0.2$ seconds, $o_{\\text{sh}}=0.0001$ seconds, $o_{\\text{dist}}=0.002$ seconds, seed $=2023$.\n- Case $5$ (edge: zero variance): $p=10$, $n=100$, $\\mu=1.0$ seconds, $\\sigma=0.0$ seconds, $o_{\\text{sh}}=0.0003$ seconds, $o_{\\text{dist}}=0.0003$ seconds, seed $=7$.\n\nProgram constraints:\n- Implement the simulation using any modern programming language logic, but the final submission must be Python code as specified in the final answer section.\n- Do not read input. Hard-code the test cases as listed.\n- Use the exact output format described: a single line with a list of floating-point ratios for the five cases, in order, enclosed in square brackets with comma separation.", "solution": "The problem requires a comparative analysis of two fundamental load balancing strategies in parallel computing: static partitioning for distributed memory systems and dynamic scheduling for shared memory systems. The objective is to simulate both strategies under various conditions and quantify their relative performance using the ratio of their makespans. A makespan is the total time elapsed from the start of a computation to the moment the last task is completed.\n\nThe foundation of this simulation is the generation of a workload, which consists of a set of $n$ independent tasks. The duration, $t_i$, of each task $i \\in \\{1, \\dots, n\\}$ is a random variable. As specified, task durations are drawn from a normal distribution with a given mean $\\mu$ and standard deviation $\\sigma$. Since time cannot be negative, any sampled value less than $0$ is truncated to $0$. This is mathematically expressed as $t_i = \\max(0, X_i)$, where each $X_i$ is an independent sample from the distribution $N(\\mu, \\sigma^2)$. To ensure the simulation is reproducible, the random number generator is initialized with a fixed seed for each test case.\n\nThe first strategy is static partitioning, characteristic of a distributed memory environment where inter-processor communication is costly, favoring a pre-computation allocation of work. The $n$ tasks are divided among $p$ processors using a contiguous block assignment. The number of tasks per processor is determined to be as balanced as possible: let $b = \\lfloor n/p \\rfloor$ be the base number of tasks and $r = n \\bmod p$ be the remainder. The first $r$ processors are assigned $m_j = b+1$ tasks each, and the subsequent $p-r$ processors are assigned $m_j = b$ tasks each. The total load on a processor $j$, denoted $L^{\\text{dist}}_j$, is the sum of the durations of its assigned tasks plus a total overhead cost. The overhead is modeled as a constant cost $o_{\\text{dist}}$ for each task assigned to the processor. Therefore, the load is calculated as $L^{\\text{dist}}_j = \\left(\\sum_{i \\in \\text{Tasks}_j} t_i\\right) + m_j \\cdot o_{\\text{dist}}$. Since all processors start simultaneously in this model, the overall makespan, $T_{\\text{dist}}$, is determined by the processor that takes the longest to finish its work: $T_{\\text{dist}} = \\max_{j \\in \\{1, \\dots, p\\}} L^{\\text{dist}}_j$.\n\nThe second strategy is dynamic scheduling via a central queue, typical of a shared memory environment where threads can efficiently access a common pool of work. This process is modeled as an event-driven simulation. We have $p$ workers, all initially idle at time $t=0$. The $n$ tasks are placed in a conceptual queue. Whenever a worker becomes free, it takes the next available task from the front of the queue. To implement this, we can maintain the finish time of each of the $p$ workers. A min-priority queue is an efficient data structure for this purpose, as it allows for quick retrieval of the worker that will become available earliest.\nThe simulation proceeds as follows:\n$1$. Initialize a min-priority queue with $p$ entries, each with value $0$, representing the initial availability time of each worker.\n$2$. For each of the $n$ tasks with duration $t_i$:\n    a. Extract the minimum time $t_{\\text{free}}$ from the priority queue. This represents the earliest time any worker becomes free.\n    b. Assign the task $t_i$ to this worker. The worker will now be occupied until a new finish time, calculated as $t_{\\text{new}} = t_{\\text{free}} + t_i + o_{\\text{sh}}$, where $o_{\\text{sh}}$ is the per-task overhead for accessing the shared queue.\n    c. Insert this new finish time $t_{\\text{new}}$ back into the priority queue.\n$3$. After all $n$ tasks have been assigned through this process, the values in the priority queue represent the final completion times of all tasks handled by each worker. The makespan for the dynamic scheduling strategy, $T_{\\text{sh}}$, is the maximum value in the priority queue, as this corresponds to the time the last task in the entire set is completed: $T_{\\text{sh}} = \\max(\\text{final worker finish times})$.\n\nFinally, to compare the effectiveness of the two strategies, we compute the dimensionless ratio $R = \\frac{T_{\\text{dist}}}{T_{\\text{sh}}}$. A ratio $R > 1$ signifies that dynamic scheduling was faster (i.e., had a smaller makespan) than static partitioning, indicating that its ability to adapt to variations in task durations outweighed its overhead. Conversely, a ratio $R < 1$ would suggest static partitioning was more efficient, which might occur if task durations are uniform and the distributed overhead $o_{\\text{dist}}$ is smaller than the shared overhead $o_{\\text{sh}}$. A ratio $R \\approx 1$ implies comparable performance. This ratio serves as the final output for each test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport heapq\n\ndef solve():\n    \"\"\"\n    Simulates and compares distributed static partitioning and shared dynamic scheduling\n    for parallel task execution across a suite of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple is (p, n, mu, sigma, o_sh, o_dist, seed)\n    test_cases = [\n        (4, 100, 1.0, 0.1, 0.0005, 0.005, 42),\n        (8, 1000, 0.5, 0.6, 0.0002, 0.01, 123),\n        (32, 40, 1.0, 0.5, 0.0002, 0.005, 98765),\n        (16, 1000, 0.2, 0.2, 0.0001, 0.002, 2023),\n        (10, 100, 1.0, 0.0, 0.0003, 0.0003, 7)\n    ]\n\n    results = []\n    for p, n, mu, sigma, o_sh, o_dist, seed in test_cases:\n        # Step 1: Generate task durations using a seeded RNG\n        # for reproducibility.\n        rng = np.random.default_rng(seed)\n        tasks = rng.normal(loc=mu, scale=sigma, size=n)\n        # Enforce non-negativity by truncating at 0.\n        tasks = np.maximum(0, tasks)\n\n        # Step 2: Simulate distributed memory static partitioning.\n        T_dist = 0.0\n        if p > 0 and n > 0:\n            b = n // p  # Base number of tasks per processor\n            r = n % p   # Remainder, for processors getting an extra task\n            \n            processor_loads_dist = np.zeros(p)\n            task_idx = 0\n            for j in range(p):\n                num_tasks_for_proc = b + 1 if j < r else b\n                if num_tasks_for_proc > 0:\n                    end_idx = task_idx + num_tasks_for_proc\n                    assigned_tasks = tasks[task_idx:end_idx]\n                    work_duration = np.sum(assigned_tasks)\n                    overhead = num_tasks_for_proc * o_dist\n                    processor_loads_dist[j] = work_duration + overhead\n                    task_idx = end_idx\n            \n            T_dist = np.max(processor_loads_dist)\n\n        # Step 3: Simulate shared memory dynamic scheduling.\n        T_sh = 0.0\n        if p > 0 and n > 0:\n            # A min-heap tracks the time each worker becomes free.\n            worker_finish_times = [0.0] * p\n            heapq.heapify(worker_finish_times)\n            \n            for task_duration in tasks:\n                # Get the worker that finishes earliest.\n                earliest_finish_time = heapq.heappop(worker_finish_times)\n                \n                # Assign the current task to this worker and update its finish time.\n                new_finish_time = earliest_finish_time + task_duration + o_sh\n                heapq.heappush(worker_finish_times, new_finish_time)\n            \n            # The makespan is the time the last worker finishes.\n            T_sh = max(worker_finish_times)\n\n        # Step 4: Compute the ratio.\n        ratio = 0.0\n        if T_sh > 0:\n            ratio = T_dist / T_sh\n        elif T_dist > 0:\n            # This case (T_sh=0, T_dist>0) is unlikely but handle for robustness.\n            ratio = float('inf')\n        else:\n            # If both are 0 (e.g., n=0), their performance is identical.\n            ratio = 1.0\n\n        results.append(ratio)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3155817"}, {"introduction": "Much like a factory assembly line, many scientific computations are structured as a pipeline of sequential stages. The overall throughput of such a system is dictated by its slowest stageâ€”the bottleneck. In this advanced practice, you will act as a performance engineer tasked with optimizing a digital image processing pipeline [@problem_id:3155812]. Your challenge is to analyze the baseline performance, then strategically re-engineer the pipeline by fusing stages and re-allocating workers to smash the bottleneck. This exercise beautifully integrates theoretical prediction, based on bottleneck analysis, with empirical verification through simulation, providing a comprehensive experience in real-world performance tuning.", "problem": "An image processing pipeline consists of a sequence of $J$ stages. Each stage $j \\in \\{1,\\dots,J\\}$ has a deterministic processing cost $s_j$ measured in seconds per image. A stage may have $w_j$ identical workers (for example, processor threads), each processing one image at a time. Images flow through the pipeline in order, and an image must complete stage $1$ before entering stage $2$, and so on. The system is closed: there are no external arrivals, and a fixed batch of $M$ images is processed. You are allowed two types of modifications to the pipeline: reordering stages, and fusing adjacent stages into composite stages. Fusing creates a composite stage whose processing cost is the sum of the fused stage costs, and whose workers are the sum of the workers allocated to the fused stages. The total number of workers available across all stages is a fixed integer $N_{\\text{total}}$. The baseline policy assigns exactly one worker to each stage and does not use any surplus workers beyond $J$ (that is, if $N_{\\text{total}} > J$, the extra $N_{\\text{total}} - J$ workers are unused in the baseline).\n\nStarting from foundational definitions of rate, flow conservation, and bottlenecks in serial systems, derive a principle-based method to:\n- Predict the steady-state throughput in images per second of the baseline pipeline configuration as a function of $\\{s_j\\}$ and $\\{w_j\\}$ under the baseline policy.\n- Construct an optimized pipeline using any reordering and fusing you choose, subject to using exactly $K$ composite stages after fusing, and allocate the $N_{\\text{total}}$ workers across the $K$ composite stages to most nearly equalize the stage service rates under integer worker constraints. Your optimization must be explainable from first principles and must not assume any formula that has not been derived from the stated base.\n- Predict the steady-state throughput in images per second of the optimized pipeline.\n- Verify both predictions empirically by simulating the passage of $M$ images through the pipeline with deterministic service times and finite worker pools per stage, measuring the empirical throughput as $M$ divided by the total completion time of the batch (expressed in images per second). Use seconds for time and images per second for throughput.\n\nDesign your program to implement the following concrete test suite. In each case, the optimization must produce exactly $K$ composite stages and allocate all $N_{\\text{total}}$ workers across these $K$ composite stages. For empirical verification, simulate exactly $M$ images:\n- Test $1$: $J=4$, $s=[1.0,1.0,1.0,1.0]$ seconds, $N_{\\text{total}}=4$, $K=2$, $M=400$.\n- Test $2$: $J=4$, $s=[5.0,1.0,1.0,1.0]$ seconds, $N_{\\text{total}}=4$, $K=2$, $M=400$.\n- Test $3$: $J=1$, $s=[5.0]$ seconds, $N_{\\text{total}}=3$, $K=1$, $M=600$.\n- Test $4$: $J=5$, $s=[8.0,2.0,2.0,2.0,2.0]$ seconds, $N_{\\text{total}}=6$, $K=3$, $M=600$.\n\nYour program must:\n- For each test case, compute the predicted baseline throughput (images per second), the predicted optimized throughput (images per second), the empirically measured baseline throughput (images per second), the empirically measured optimized throughput (images per second), the predicted improvement factor defined as the optimized predicted throughput divided by the baseline predicted throughput (dimensionless), and the empirically measured improvement factor defined as the optimized empirical throughput divided by the baseline empirical throughput (dimensionless).\n- Express all throughputs in images per second and all improvement factors as decimals (no percentage signs), rounding each reported value to exactly $6$ decimal places.\n\nFinal output format requirement:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain, in order for tests $1$ through $4$, the $6$ values per test: baseline predicted throughput, optimized predicted throughput, baseline empirical throughput, optimized empirical throughput, predicted improvement factor, empirical improvement factor. Concretely, the output should be of the form $\\left[\\text{T}_{1,\\text{base,pred}},\\text{T}_{1,\\text{opt,pred}},\\text{T}_{1,\\text{base,emp}},\\text{T}_{1,\\text{opt,emp}},\\text{I}_{1,\\text{pred}},\\text{I}_{1,\\text{emp}},\\dots,\\text{T}_{4,\\text{base,pred}},\\text{T}_{4,\\text{opt,pred}},\\text{T}_{4,\\text{base,emp}},\\text{T}_{4,\\text{opt,emp}},\\text{I}_{4,\\text{pred}},\\text{I}_{4,\\text{emp}}\\right]$, with each value rounded to $6$ decimal places.", "solution": "The problem requires the analysis and optimization of a serial image processing pipeline. The solution will proceed by first establishing the fundamental principles governing the throughput of such a system. Based on these principles, we will derive methods to predict the performance of both a baseline and an optimized pipeline configuration. Finally, we will describe an empirical simulation method to verify these predictions.\n\n**1. Foundational Principles and Throughput Prediction**\n\nA processing pipeline is a system of sequential stages. The overall performance of such a system is governed by the rate at which each stage can process its tasks.\n\nLet stage $j \\in \\{1, \\dots, J\\}$ have a deterministic processing cost of $s_j$ seconds per image. This represents the service time for a single image at that stage. The intrinsic rate of a single worker at stage $j$ is therefore $1/s_j$ images per second. If stage $j$ is allocated $w_j$ identical parallel workers, its total service capacity, or service rate $\\mu_j$, is the sum of the individual worker rates, assuming images are always available to be processed.\n$$\n\\mu_j = \\frac{w_j}{s_j} \\quad \\text{(images/second)}\n$$\nIn a serial pipeline operating in a steady state, the principle of flow conservation dictates that the long-term average throughput, let's call it $T$, must be the same through every stage. Furthermore, the throughput of any given stage cannot exceed its service rate, so $T \\leq \\mu_j$ for all $j \\in \\{1, \\dots, J\\}$.\n\nThis implies that the overall system throughput is constrained by the stage with the lowest service rate. This stage is known as the bottleneck. The steady-state throughput of the entire pipeline is therefore the minimum of the service rates of all its constituent stages:\n$$\nT = \\min_{j \\in \\{1, \\dots, J\\}} \\{\\mu_j\\} = \\min_{j \\in \\{1, \\dots, J\\}} \\left\\{ \\frac{w_j}{s_j} \\right\\}\n$$\n\n**2. Baseline Pipeline Analysis**\n\nThe problem defines a baseline policy where each of the $J$ stages is assigned exactly one worker, i.e., $w_j = 1$ for all $j$. Any surplus workers from the total pool of $N_{\\text{total}}$ are unused.\n\nApplying the derived throughput formula to the baseline case, we have:\n$$\nT_{\\text{base,pred}} = \\min_{j \\in \\{1, \\dots, J\\}} \\left\\{ \\frac{1}{s_j} \\right\\}\n$$\nThis can be rewritten as:\n$$\nT_{\\text{base,pred}} = \\frac{1}{\\max_{j \\in \\{1, \\dots, J\\}} \\{s_j\\}}\n$$\nThis result is intuitive: the throughput of a pipeline with single workers is limited by the reciprocal of the longest processing time of any individual stage.\n\n**3. Optimized Pipeline Design and Analysis**\n\nThe optimization task involves reordering the original stages and fusing them into exactly $K$ composite stages, then allocating the $N_{\\text{total}}$ workers to these new stages to maximize throughput.\n\nLet the $K$ composite stages be indexed by $k \\in \\{1, \\dots, K\\}$. Let $S_k$ be the sum of the processing costs of the original stages that are fused to form composite stage $k$, and let $W_k$ be the integer number of workers allocated to it. The total number of workers is conserved: $\\sum_{k=1}^K W_k = N_{\\text{total}}$. The throughput of the optimized pipeline is $T_{\\text{opt}} = \\min_k \\{W_k / S_k\\}$.\n\nTo maximize this throughput, we must solve the maximin problem: $\\max \\left( \\min_k \\{W_k / S_k\\} \\right)$. This objective is maximized when the service rates of all composite stages are equal, i.e., $W_1/S_1 = W_2/S_2 = \\dots = W_K/S_K$.\n\nThis represents a complex joint optimization problem over the partitioning of stages and the integer allocation of workers. A robust heuristic approach involves two sequential steps:\n\n**Step 3.1: Stage Fusing (Partitioning)**\nFirst, we partition the set of original stage costs $\\{s_j\\}_{j=1}^J$ into $K$ subsets. The goal of this step is to create composite stages with total costs $\\{S_k\\}_{k=1}^K$ that are as balanced as possible. This provides a good foundation for the subsequent worker allocation. A greedy algorithm is effective for this: sort the original costs $s_j$ in descending order. Then, iteratively, add the next cost from the sorted list to the partition that currently has the smallest sum. This heuristic tends to produce well-balanced partitions. The problem statement allows reordering, so this corresponds to forming arbitrary, not just adjacent, fusions.\n\n**Step 3.2: Worker Allocation**\nGiven the composite costs $S_k$, we must find an integer allocation $\\{W_k\\}$ summing to $N_{\\text{total}}$ that maximizes $\\min_k \\{W_k / S_k\\}$. The ideal, non-integer allocation would be $W_k^{\\text{ideal}} \\propto S_k$. To find the best integer solution, we use a greedy iterative algorithm that directly targets the bottleneck:\n1. Initialize each of the $K$ composite stages with one worker, so $W_k=1$ for all $k$. This uses $K$ workers.\n2. The remaining $N_{\\text{rem}} = N_{\\text{total}} - K$ workers are distributed one by one.\n3. In each of the $N_{\\text{rem}}$ iterations, identify the current bottleneck stage $k^*$, which is the stage with the minimum rate $W_k/S_k$. In case of ties, the stage with the larger cost $S_k$ is chosen as the bottleneck.\n4. Add one worker to this bottleneck stage: $W_{k^*} \\leftarrow W_{k^*} + 1$.\n5. Repeat until all workers are allocated.\n\nThis procedure incrementally improves the lowest stage rate, directly addressing the maximin objective. The predicted throughput of the resulting optimized pipeline is:\n$$\nT_{\\text{opt,pred}} = \\min_{k \\in \\{1, \\dots, K\\}} \\left\\{ \\frac{W_k}{S_k} \\right\\}\n$$\nwhere $\\{S_k\\}$ and $\\{W_k\\}$ are the outcomes of the optimization procedure.\n\n**4. Empirical Verification via Simulation**\n\nThe theoretical predictions for steady-state throughput neglect transient start-up and wind-down effects of processing a finite batch of $M$ images. To obtain an empirical measure, we simulate the pipeline's operation.\n\nThe simulation can be modeled efficiently using a recurrence relation derived from queueing theory. Let $C_{i,j}$ be the completion time of image $i$ ($i \\in \\{0, \\dots, M-1\\}$) at stage $j$ ($j \\in \\{0, \\dots, J-1\\}$). An image can only start processing at stage $j$ after two conditions are met:\n1. The image itself has arrived at stage $j$, which occurs when it completes stage $j-1$. This time is $C_{i, j-1}$.\n2. A worker at stage $j$ is available. With $w_j$ workers and images processed in order, the worker for image $i$ will be free no earlier than when image $i-w_j$ completed stage $j$. This time is $C_{i-w_j, j}$.\n\nThe start time for image $i$ at stage $j$ is the maximum of these two times. The completion time is the start time plus the service time $s_j$. This gives the recurrence:\n$$\nC_{i,j} = \\max(C_{i, j-1}, C_{i-w_j, j}) + s_j\n$$\nThe boundary conditions are $C_{i, -1} = 0$ (images are available for the first stage at time $0$) and $C_{k, j} = 0$ for $k < 0$. The simulation proceeds by computing the matrix $C_{i,j}$ for all images and stages.\n\nThe total time to process the batch of $M$ images is the time the last image completes the last stage, which is $C_{M-1, J-1}$ (using $0$-based indexing). The empirical throughput is then:\n$$\nT_{\\text{emp}} = \\frac{M}{C_{M-1, J-1}}\n$$\nThis simulation is performed for both the baseline and the optimized pipeline configurations.\n\n**5. Improvement Factor**\n\nThe improvement due to optimization is quantified by the ratio of the optimized throughput to the baseline throughput.\n- Predicted Improvement Factor: $I_{\\text{pred}} = T_{\\text{opt,pred}} / T_{\\text{base,pred}}$\n- Empirical Improvement Factor: $I_{\\text{emp}} = T_{\\text{opt,emp}} / T_{\\text{base,emp}}$\nThese factors are dimensionless.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef get_predicted_throughput(s_list: list[float], w_list: list[int]) -> float:\n    \"\"\"Calculates the predicted steady-state throughput of a pipeline.\"\"\"\n    if not s_list:\n        return np.inf\n    \n    min_rate = np.inf\n    for s, w in zip(s_list, w_list):\n        if s > 0:\n            rate = w / s\n            if rate < min_rate:\n                min_rate = rate\n        else: # A stage with zero cost has infinite throughput\n            pass\n    return min_rate\n\ndef run_simulation(s_list: list[float], w_list: list[int], M: int) -> float:\n    \"\"\"Simulates the pipeline to find the empirical throughput for M images.\"\"\"\n    num_stages = len(s_list)\n    if num_stages == 0:\n        return np.inf\n    if M == 0:\n        return 0.0\n\n    # completion_times[i, j] is the time image i completes stage j\n    completion_times = np.zeros((M, num_stages))\n\n    for j in range(num_stages):\n        s = s_list[j]\n        w = w_list[j]\n        if w == 0: # If a stage has no workers, no image can pass\n            return 0.0\n        for i in range(M):\n            # Time image i is available for stage j (finished previous stage)\n            arrival_time_at_stage_j = completion_times[i, j - 1] if j > 0 else 0.0\n            \n            # Time a worker for image i becomes available.\n            # This is determined by when the (i-w)-th image finished *this* stage.\n            contention_finish_time = completion_times[i - w, j] if i >= w else 0.0\n            \n            start_time = max(arrival_time_at_stage_j, contention_finish_time)\n            completion_times[i, j] = start_time + s\n            \n    total_time = completion_times[M - 1, num_stages - 1]\n    \n    if total_time == 0:\n        return np.inf\n        \n    return M / total_time\n\ndef optimize_pipeline(s: list[float], N_total: int, K: int) -> tuple[list[float], list[int]]:\n    \"\"\"\n    Constructs an optimized pipeline by partitioning stages and allocating workers.\n    Returns the composite stage costs (S_opt) and worker allocations (W_opt).\n    \"\"\"\n    # 1. Partition original stages into K composite stages using a greedy algorithm\n    # to make partition sums as equal as possible.\n    if K == 0:\n        return [], []\n    \n    s_sorted_indices = np.argsort(s)[::-1]\n    s_sorted = [s[i] for i in s_sorted_indices]\n    \n    partition_sums = [0.0] * K\n    \n    for cost in s_sorted:\n        min_sum_idx = np.argmin(partition_sums)\n        partition_sums[min_sum_idx] += cost\n        \n    S_opt = partition_sums\n    \n    # 2. Allocate N_total workers to the K composite stages using a greedy iterative\n    # approach that adds workers to the current bottleneck.\n    if K > N_total:\n        # Fallback for an unlikely scenario: not enough workers for 1 per stage.\n        W_opt = [0] * K\n        for i in range(N_total):\n            W_opt[i] += 1\n        return S_opt, W_opt\n\n    W_opt = [1] * K\n    workers_to_distribute = N_total - K\n    \n    for _ in range(workers_to_distribute):\n        current_rates = [(w / s if s > 0 else np.inf) for w, s in zip(W_opt, S_opt)]\n        \n        # Find the bottleneck stage (minimum rate), with tie-breaking.\n        min_rate = np.inf\n        bottleneck_idx = -1\n        \n        potential_bottlenecks = []\n        for i in range(K):\n            if current_rates[i] < min_rate:\n                min_rate = current_rates[i]\n                potential_bottlenecks = [i]\n            elif current_rates[i] == min_rate:\n                potential_bottlenecks.append(i)\n\n        if len(potential_bottlenecks) == 1:\n            bottleneck_idx = potential_bottlenecks[0]\n        else:\n            # Tie-break by choosing the stage with the largest cost S_k\n            max_s_val = -1.0\n            for idx in potential_bottlenecks:\n                if S_opt[idx] > max_s_val:\n                    max_s_val = S_opt[idx]\n                    bottleneck_idx = idx\n\n        if bottleneck_idx != -1:\n            W_opt[bottleneck_idx] += 1\n        else: # Should not happen if K > 0\n            W_opt[0] += 1\n            \n    return S_opt, W_opt\n\ndef run_analysis(J, s, N_total, K, M):\n    \"\"\"Performs the full analysis for a single test case.\"\"\"\n    # Baseline calculations\n    s_base = list(s)\n    w_base = [1] * J\n    T_base_pred = get_predicted_throughput(s_base, w_base)\n    T_base_emp = run_simulation(s_base, w_base, M)\n\n    # Optimized calculations\n    S_opt, W_opt = optimize_pipeline(s, N_total, K)\n    T_opt_pred = get_predicted_throughput(S_opt, W_opt)\n    T_opt_emp = run_simulation(S_opt, W_opt, M)\n    \n    # Improvement factors\n    I_pred = T_opt_pred / T_base_pred if T_base_pred > 0 else 0.0\n    I_emp = T_opt_emp / T_base_emp if T_base_emp > 0 else 0.0\n    \n    return [T_base_pred, T_opt_pred, T_base_emp, T_opt_emp, I_pred, I_emp]\n\ndef solve():\n    \"\"\"Defines test cases and prints the final formatted result string.\"\"\"\n    test_cases = [\n        # J, s, N_total, K, M\n        (4, [1.0, 1.0, 1.0, 1.0], 4, 2, 400),\n        (4, [5.0, 1.0, 1.0, 1.0], 4, 2, 400),\n        (1, [5.0], 3, 1, 600),\n        (5, [8.0, 2.0, 2.0, 2.0, 2.0], 6, 3, 600)\n    ]\n\n    all_results = []\n    for J, s, N_total, K, M in test_cases:\n        case_results = run_analysis(J, s, N_total, K, M)\n        all_results.extend(case_results)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{val:.6f}' for val in all_results])}]\")\n\nsolve()\n```", "id": "3155812"}]}