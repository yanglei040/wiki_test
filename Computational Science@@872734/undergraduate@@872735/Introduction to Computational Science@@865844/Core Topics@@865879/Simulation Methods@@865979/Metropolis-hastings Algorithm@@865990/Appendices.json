{"hands_on_practices": [{"introduction": "This first exercise demystifies the Metropolis-Hastings algorithm by examining its simplest variant, the original Metropolis algorithm. By using a symmetric proposal distribution, where the probability of proposing a move from state $i$ to $j$ is the same as from $j$ to $i$, the acceptance calculation simplifies. This allows us to focus on the core principle: accepting or rejecting new states based on the ratio of their target probabilities, which ensures the simulation eventually explores the desired distribution.", "problem": "A simulation generates states from the set of non-negative integers $\\{0, 1, 2, \\dots \\}$. The objective is to sample from a target probability distribution where the probability of being in state $k$, denoted $\\pi(k)$, is proportional to $(1/2)^k$.\n\nThe simulation uses a Markov chain which transitions between states. At any given state $i > 0$, a proposal for the next state, $j$, is made by choosing either $j=i-1$ or $j=i+1$ with equal probability of $1/2$. If the current state is $i=0$, the proposal is always to state $j=1$. The transition probability from state $i$ to a proposed state $j$ is denoted $Q(j|i)$.\n\nThe decision to accept the proposed move is determined by the Metropolis-Hastings acceptance probability.\n\nSuppose the chain is currently at state $X_t=3$, and a move to the candidate state $y=4$ is proposed. Calculate the probability that this move is accepted. Express your answer as an exact value.", "solution": "We are given a target distribution on non-negative integers with probabilities proportional to $(1/2)^{k}$. Write the target as\n$$\n\\pi(k)=C\\left(\\frac{1}{2}\\right)^{k},\n$$\nwhere $C$ is the normalizing constant (which will cancel in the Metropolis-Hastings ratio).\n\nThe proposal kernel $Q(j\\mid i)$ is defined by:\n- If $i>0$, then $Q(i-1\\mid i)=\\frac{1}{2}$ and $Q(i+1\\mid i)=\\frac{1}{2}$.\n- If $i=0$, then $Q(1\\mid 0)=1$.\n\nThe Metropolis-Hastings acceptance probability for a move from current state $i$ to proposed state $y$ is\n$$\n\\alpha(i\\to y)=\\min\\left\\{1,\\ \\frac{\\pi(y)\\,Q(i\\mid y)}{\\pi(i)\\,Q(y\\mid i)}\\right\\}.\n$$\n\nHere, the current state is $i=3$ and the proposal is $y=4$. Since both $i=3$ and $y=4$ are greater than $0$, we have\n$$\nQ(4\\mid 3)=\\frac{1}{2},\\qquad Q(3\\mid 4)=\\frac{1}{2}.\n$$\nTherefore,\n$$\n\\frac{\\pi(4)\\,Q(3\\mid 4)}{\\pi(3)\\,Q(4\\mid 3)}\n=\\frac{C\\left(\\frac{1}{2}\\right)^{4}\\cdot \\frac{1}{2}}{C\\left(\\frac{1}{2}\\right)^{3}\\cdot \\frac{1}{2}}\n=\\frac{\\left(\\frac{1}{2}\\right)^{4}}{\\left(\\frac{1}{2}\\right)^{3}}\n=\\frac{1}{2}.\n$$\nThus, the acceptance probability is\n$$\n\\alpha(3\\to 4)=\\min\\left\\{1,\\ \\frac{1}{2}\\right\\}=\\frac{1}{2}.\n$$", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "1343441"}, {"introduction": "Building upon the basics, this problem introduces an asymmetric proposal distribution, a common scenario in more sophisticated applications. This requires us to use the full Metropolis-Hastings acceptance formula, which includes the crucial \"Hastings correction\" factor. This practice is key to understanding how the algorithm maintains its theoretical guarantees of converging to the target distribution, even when the proposal mechanism is not balanced.", "problem": "A computational simulation uses the Metropolis-Hastings algorithm to explore the conformational states of a protein. The model simplifies the protein's structure into three possible discrete states: State 1, State 2, and State 3. The goal of the simulation is to generate samples from a target stationary distribution, $\\pi$, which represents the equilibrium probability of finding the protein in each state. This target distribution is given by:\n$\\pi(\\text{State 1}) = 0.1$\n$\\pi(\\text{State 2}) = 0.3$\n$\\pi(\\text{State 3}) = 0.6$\n\nThe algorithm proceeds by proposing moves from a current state $i$ to a new state $j$ according to a proposal distribution $q(j|i)$. The proposal mechanism is defined as follows:\n- From State 1, a move to State 2 is proposed with probability $0.2$, and a move to State 3 is proposed with probability $0.8$.\n- From State 2, a move to State 1 is proposed with probability $0.5$, and a move to State 3 is proposed with probability $0.5$.\n- From State 3, a move to State 1 is proposed with probability $0.1$, and a move to State 2 is proposed with probability $0.9$.\n\nSuppose the simulation is currently in State 1 and a move to State 3 is proposed. Calculate the acceptance probability for this specific transition. Express your final answer as a simplified fraction.", "solution": "In the Metropolis-Hastings algorithm, the acceptance probability for a proposed move from a current state $i$ to a new state $j$ is\n$$\n\\alpha_{i \\to j} = \\min\\left(1, \\frac{\\pi(j)\\,q(i \\mid j)}{\\pi(i)\\,q(j \\mid i)}\\right).\n$$\nFor the proposed transition from State 1 to State 3, use the given target probabilities and proposal probabilities. Converting the given decimals to exact fractions,\n$$\n\\pi(\\text{State 3}) = \\frac{3}{5}, \\quad \\pi(\\text{State 1}) = \\frac{1}{10}, \\quad q(3 \\mid 1) = \\frac{4}{5}, \\quad q(1 \\mid 3) = \\frac{1}{10}.\n$$\nSubstitute into the acceptance ratio:\n$$\n\\frac{\\pi(3)\\,q(1 \\mid 3)}{\\pi(1)\\,q(3 \\mid 1)} = \\frac{\\left(\\frac{3}{5}\\right)\\left(\\frac{1}{10}\\right)}{\\left(\\frac{1}{10}\\right)\\left(\\frac{4}{5}\\right)} = \\frac{\\frac{3}{50}}{\\frac{4}{50}} = \\frac{3}{4}.\n$$\nTherefore,\n$$\n\\alpha_{1 \\to 3} = \\min\\left(1, \\frac{3}{4}\\right) = \\frac{3}{4}.\n$$", "answer": "$$\\boxed{\\frac{3}{4}}$$", "id": "1962671"}, {"introduction": "Beyond calculating acceptance probabilities, a practitioner must understand how the algorithm behaves in practice. This thought experiment delves into a critical issue: the choice of proposal step size and its impact on the sampler's ability to explore the entire parameter space. By considering a challenging bimodal target distribution, we develop intuition for diagnosing common problems like poor mixing and getting trapped in a local mode, which are essential skills for any real-world application of MCMC.", "problem": "A data scientist is analyzing the posterior probability distribution for a parameter $\\theta$ of a complex climate model. The analysis reveals that the posterior distribution, denoted as $p(\\theta)$, is bimodal, with two distinct peaks of high probability located at $\\theta_A$ and $\\theta_B$, separated by a wide region of very low probability. To explore this distribution and estimate properties like the posterior mean, the scientist employs the Metropolis-Hastings (M-H) algorithm.\n\nThe M-H sampler is initialized with a starting value $\\theta_0$ located within the high-probability region around the first peak, $\\theta_A$. A symmetric proposal distribution $q(\\theta' | \\theta) = \\mathcal{N}(\\theta' | \\theta, \\sigma^2)$ is used, where $\\mathcal{N}$ is a normal distribution centered at the current state $\\theta$ with a standard deviation $\\sigma$, which represents the proposal step size. The scientist, aiming for a high acceptance rate, chooses a very small value for $\\sigma$ relative to the distance between the two modes, $|\\theta_A - \\theta_B|$.\n\nAfter running the M-H sampler for a very large number of iterations, which of the following descriptions most accurately characterizes the expected outcome of this simulation?\n\nA. The sampler will efficiently find the global maximum of the posterior distribution $p(\\theta)$ and remain there, thus providing an excellent point estimate for the parameter.\n\nB. The acceptance rate for proposed states will be very low, causing the chain to remain near the initial state $\\theta_0$ and explore very little of the parameter space.\n\nC. The generated chain of samples will be highly autocorrelated, and its histogram will largely represent the shape of the mode around $\\theta_A$, while failing to discover the mode around $\\theta_B$.\n\nD. The samples will alternate between the two modes in a systematic fashion, jumping from the region of $\\theta_A$ to the region of $\\theta_B$ and back again with regular frequency.\n\nE. The states of the chain will be nearly independent of one another, indicating that the sampler has successfully converged to the true bimodal posterior distribution.", "solution": "We analyze the Metropolis-Hastings (M-H) sampler with a symmetric proposal and very small proposal scale relative to the distance between two separated modes of the posterior $p(\\theta)$ at $\\theta_{A}$ and $\\theta_{B}$.\n\nFor a symmetric proposal $q(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta' \\mid \\theta, \\sigma^{2})$, the Metropolis-Hastings acceptance probability is\n$$\na(\\theta \\rightarrow \\theta') = \\min\\left\\{1, \\frac{p(\\theta')}{p(\\theta)}\\right\\}.\n$$\nThe chain is initialized at $\\theta_{0}$ in the high-probability region around $\\theta_{A}$. Because $\\sigma$ is chosen to be very small compared to the separation $|\\theta_{A} - \\theta_{B}|$, proposed moves satisfy $|\\theta' - \\theta| = O(\\sigma)$ and thus remain very close to the current state. In a high-probability region near a mode, $p(\\theta')$ is close to $p(\\theta)$ for small steps, so\n$$\n\\frac{p(\\theta')}{p(\\theta)} \\approx 1,\n$$\nimplying that $a(\\theta \\rightarrow \\theta') \\approx 1$ and the local acceptance rate is high. Hence, option B (very low acceptance rate) is contradicted by the small-step, within-mode behavior.\n\nNext, consider transitions between the modes. The probability to directly propose a state near $\\theta_{B}$ from a current state near $\\theta_{A}$ under the Gaussian proposal is\n$$\nq(\\theta_{B} \\mid \\theta) \\propto \\exp\\left(-\\frac{|\\theta_{B} - \\theta|^{2}}{2 \\sigma^{2}}\\right).\n$$\nSince $\\sigma \\ll |\\theta_{A} - \\theta_{B}|$, this proposal probability is exponentially small in $|\\theta_{A} - \\theta_{B}|^{2} / \\sigma^{2}$. Therefore, direct jumps across the low-probability valley are essentially never proposed on practical time scales. Alternatively, crossing the valley via many small steps requires repeatedly proposing moves into regions where $p(\\theta') \\ll p(\\theta)$, for which\n$$\na(\\theta \\rightarrow \\theta') = \\min\\left\\{1, \\frac{p(\\theta')}{p(\\theta)}\\right\\} \\ll 1,\n$$\nso such steps are overwhelmingly rejected. Consequently, the chain becomes effectively trapped near $\\theta_{A}$ for a very long time, failing to discover $\\theta_{B}$ in practice.\n\nBecause moves are very local and the chain stays within the same mode, successive samples are highly autocorrelated. The empirical histogram thus reflects the local shape around $\\theta_{A}$ but does not capture the separated mode near $\\theta_{B}$. This rules out option E (independence and successful convergence) and option D (regular alternation between modes). Option A is incorrect because M-H is a sampler targeting $p(\\theta)$, not an optimizer; moreover, with small steps and bimodality, it neither efficiently finds nor remains at a global maximum.\n\nTherefore, the most accurate description is that the chain exhibits high autocorrelation, predominantly samples the neighborhood of $\\theta_{A}$, and fails to discover the second mode $\\theta_{B}$.\n\nThe correct choice is C.", "answer": "$$\\boxed{C}$$", "id": "1962668"}]}