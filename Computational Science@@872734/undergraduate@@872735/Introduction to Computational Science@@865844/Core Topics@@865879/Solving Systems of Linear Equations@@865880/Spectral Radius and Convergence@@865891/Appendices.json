{"hands_on_practices": [{"introduction": "Calculating eigenvalues directly can be computationally expensive, making it difficult to quickly assess if an iterative method will converge. This practice explores a powerful alternative: using the Gershgorin Circle Theorem to estimate the location of eigenvalues in the complex plane. By constructing these discs, you can derive a sufficient condition for convergence without finding the exact spectral radius, providing a practical tool for analysis and design [@problem_id:3196449].", "problem": "Consider the linear fixed-point iteration $x_{k+1} = T x_k + c$ for a square matrix $T \\in \\mathbb{R}^{3 \\times 3}$ and a constant vector $c \\in \\mathbb{R}^{3}$. The spectral radius $\\rho(T)$ is defined as the maximum of the absolute values of the eigenvalues of $T$. The Gershgorin Circle Theorem states that every eigenvalue of a matrix lies within at least one of its Gershgorin discs, which are constructed from the matrix rows. Assume $T(\\alpha)$ is the tridiagonal matrix\n$$\nT(\\alpha) = \\begin{pmatrix}\n\\frac{3}{5}  \\alpha  0 \\\\\n\\alpha  \\frac{3}{5}  \\alpha \\\\\n0  \\alpha  \\frac{3}{5}\n\\end{pmatrix},\n$$\nwhere $\\alpha \\geq 0$ is a parameter.\n\nUsing only foundational definitions and the Gershgorin Circle Theorem, derive a bound on the eigenvalue locations of $T(\\alpha)$ in the complex plane, obtain from this bound a sufficient condition for convergence of the iteration $x_{k+1} = T x_k + c$ for all initial vectors, and identify the borderline value of $\\alpha$ at which the Gershgorin discs are tangent to the unit circle $|z|=1$. Provide reasoning that connects the spectral radius bound to convergence and explain the status of convergence at the borderline value of $\\alpha$ based on Gershgorin discs.\n\nReport the critical value of $\\alpha$ at which the Gershgorin discs just touch the unit circle as your final answer. No rounding is required.", "solution": "The problem is subjected to validation before a solution is attempted.\n\n### Step 1: Extract Givens\n- The linear fixed-point iteration is $x_{k+1} = T x_k + c$.\n- The iteration matrix is $T \\in \\mathbb{R}^{3 \\times 3}$, and the constant vector is $c \\in \\mathbb{R}^{3}$.\n- The spectral radius is defined as $\\rho(T) = \\max_i |\\lambda_i|$, where $\\lambda_i$ are the eigenvalues of $T$.\n- The Gershgorin Circle Theorem is stated to be a tool for analysis.\n- The specific matrix under consideration is a function of a parameter $\\alpha$:\n$$\nT(\\alpha) = \\begin{pmatrix}\n\\frac{3}{5}  \\alpha  0 \\\\\n\\alpha  \\frac{3}{5}  \\alpha \\\\\n0  \\alpha  \\frac{3}{5}\n\\end{pmatrix}\n$$\n- A constraint on the parameter is given: $\\alpha \\geq 0$.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded:** The problem is firmly located within numerical linear algebra, a core area of computational science. The concepts of fixed-point iteration, spectral radius, convergence criteria, and the Gershgorin Circle Theorem are standard, well-established mathematical principles.\n2.  **Well-Posed:** The problem is structured to have a unique solution. It asks for a sufficient condition and a specific \"borderline\" value of a parameter based on a clear geometric interpretation of the Gershgorin discs.\n3.  **Objective:** The problem is stated using precise mathematical language, free of ambiguity or subjective claims.\n4.  **Completeness:** The problem is self-contained. All necessary information is provided. It implicitly relies on the standard theorem connecting the spectral radius to the convergence of linear iterations, which it asks to be explained.\n5.  **Not Ill-Posed or Poorly Structured:** The problem is clear, and a path to a solution using the specified theorem exists.\n6.  **Not Trivial or Pseudo-Profound:** The problem requires a correct application and interpretation of the Gershgorin Circle Theorem and its implications for matrix norms and spectral radius, which is a standard but non-trivial exercise.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A full solution will be provided.\n\n***\n\nThe convergence of the linear fixed-point iteration $x_{k+1} = T x_k + c$ for any initial vector $x_0$ is guaranteed if and only if the spectral radius of the iteration matrix $T$ is strictly less than one, i.e., $\\rho(T)  1$. We will use the Gershgorin Circle Theorem to find an upper bound for the spectral radius of the matrix $T(\\alpha)$ and thereby establish a sufficient condition for convergence.\n\nThe Gershgorin Circle Theorem states that every eigenvalue of a square matrix $A = (a_{ij})$ lies within at least one of the Gershgorin discs $D_i$ in the complex plane, where for each row $i$, the disc $D_i$ is centered at the diagonal element $a_{ii}$ and has a radius $R_i$ equal to the sum of the absolute values of the off-diagonal elements in that row:\n$$ D_i = \\{z \\in \\mathbb{C} : |z - a_{ii}| \\leq R_i\\}, \\quad \\text{where} \\quad R_i = \\sum_{j \\neq i} |a_{ij}| $$\nThe set of all eigenvalues, the spectrum $\\sigma(A)$, is contained in the union of these discs: $\\sigma(A) \\subseteq \\bigcup_i D_i$.\n\nFor the given matrix $T(\\alpha)$:\n$$\nT(\\alpha) = \\begin{pmatrix}\n\\frac{3}{5}  \\alpha  0 \\\\\n\\alpha  \\frac{3}{5}  \\alpha \\\\\n0  \\alpha  \\frac{3}{5}\n\\end{pmatrix}\n$$\nwith $\\alpha \\geq 0$, we define the Gershgorin discs:\n\n1.  For the first row ($i=1$): The center is $a_{11} = \\frac{3}{5}$. The radius is $R_1 = |a_{12}| + |a_{13}| = |\\alpha| + |0| = \\alpha$, since $\\alpha \\geq 0$. The disc is $D_1 = \\{z \\in \\mathbb{C} : |z - \\frac{3}{5}| \\leq \\alpha\\}$.\n\n2.  For the second row ($i=2$): The center is $a_{22} = \\frac{3}{5}$. The radius is $R_2 = |a_{21}| + |a_{23}| = |\\alpha| + |\\alpha| = 2\\alpha$. The disc is $D_2 = \\{z \\in \\mathbb{C} : |z - \\frac{3}{5}| \\leq 2\\alpha\\}$.\n\n3.  For the third row ($i=3$): The center is $a_{33} = \\frac{3}{5}$. The radius is $R_3 = |a_{31}| + |a_{32}| = |0| + |\\alpha| = \\alpha$. The disc is $D_3 = \\{z \\in \\mathbb{C} : |z - \\frac{3}{5}| \\leq \\alpha\\}$.\n\nThe discs $D_1$ and $D_3$ are identical. Since $\\alpha \\geq 0$, we have $2\\alpha \\geq \\alpha$, which implies that the radius of $D_2$ is greater than or equal to the radius of $D_1$ and $D_3$. As all three discs share the same center, $D_1 \\subseteq D_2$ and $D_3 \\subseteq D_2$. Therefore, the union of the three discs is simply the largest disc, $D_2$:\n$$ \\bigcup_{i=1}^3 D_i = D_2 = \\{z \\in \\mathbb{C} : |z - \\frac{3}{5}| \\leq 2\\alpha \\} $$\nThis implies that all eigenvalues $\\lambda$ of $T(\\alpha)$ must lie within this disc. This provides the requested bound on the eigenvalue locations.\n\nThe spectral radius $\\rho(T(\\alpha))$ is the maximum modulus of its eigenvalues. Since all eigenvalues lie in $D_2$, the spectral radius is bounded by the maximum possible modulus of any point $z$ in $D_2$:\n$$ \\rho(T(\\alpha)) = \\max_{\\lambda \\in \\sigma(T(\\alpha))} |\\lambda| \\leq \\max_{z \\in D_2} |z| $$\nThe disc $D_2$ is centered at the real number $\\frac{3}{5}$ with radius $2\\alpha$. The point in this disc with the maximum modulus lies on its boundary along the positive real axis. This point is $z_{max} = \\frac{3}{5} + 2\\alpha$. Thus, we have an upper bound for the spectral radius:\n$$ \\rho(T(\\alpha)) \\leq \\frac{3}{5} + 2\\alpha $$\nA sufficient condition for the convergence of the iteration is $\\rho(T(\\alpha))  1$. Using our bound, a sufficient condition is:\n$$ \\frac{3}{5} + 2\\alpha  1 $$\n$$ 2\\alpha  1 - \\frac{3}{5} $$\n$$ 2\\alpha  \\frac{2}{5} $$\n$$ \\alpha  \\frac{1}{5} $$\nCombined with the given constraint $\\alpha \\geq 0$, a sufficient condition for convergence is $0 \\leq \\alpha  \\frac{1}{5}$.\n\nThe borderline value of $\\alpha$ is where the Gershgorin discs are tangent to the unit circle $|z|=1$. Since the union of the discs is $D_2$, this corresponds to the point in $D_2$ farthest from the origin having a modulus of $1$. This occurs when the upper bound for the spectral radius equals $1$:\n$$ \\frac{3}{5} + 2\\alpha = 1 $$\nSolving for $\\alpha$ gives the critical value:\n$$ 2\\alpha = \\frac{2}{5} \\implies \\alpha = \\frac{1}{5} $$\nAt this borderline value, $\\alpha = \\frac{1}{5}$, the bound on the spectral radius derived from the Gershgorin theorem is $\\rho(T(\\frac{1}{5})) \\leq 1$. The theorem only provides an inclusion region for the eigenvalues. It does not guarantee that an eigenvalue actually lies on the boundary of this region. The strict condition for convergence is $\\rho(T)  1$. The condition $\\rho(T) \\leq 1$ is not sufficient to guarantee convergence. An eigenvalue with modulus $1$ might exist, which could lead to divergence or non-convergent oscillation. Therefore, based on the information provided by the Gershgorin discs alone, convergence at the borderline value $\\alpha = \\frac{1}{5}$ is not guaranteed; the status is inconclusive.\n\nThe question asks for the critical value of $\\alpha$ at which the Gershgorin discs touch the unit circle. This is the value we have calculated.", "answer": "$$\n\\boxed{\\frac{1}{5}}\n$$", "id": "3196449"}, {"introduction": "In numerical analysis, it is vital to distinguish between sufficient and necessary conditions for convergence. Strict Diagonal Dominance (SDD) is a famous sufficient condition guaranteeing that the Jacobi method converges, but is it necessary? This exercise challenges that assumption by having you analyze a counterexample, reinforcing the fundamental principle that the spectral radius criterion, $\\rho(T) \\lt 1$, is the one true arbiter of convergence [@problem_id:3219053].", "problem": "Consider the question of whether Strict Diagonal Dominance (SDD) by rows is necessary for the convergence of the Jacobi iterative method. Starting only from the core definitions of the Jacobi method and spectral radius, analyze the following concrete matrix as a potential counterexample:\n$$\nA \\;=\\; \\begin{pmatrix}\n1  -2  0 \\\\\n0  1  -2 \\\\\n0  0  1\n\\end{pmatrix}.\n$$\nTasks:\n- First, verify that $A$ is not strictly diagonally dominant by rows (SDD).\n- Using only the fundamental definition of the Jacobi iteration based on the diagonal and off-diagonal splitting of $A$, derive the Jacobi iteration matrix and determine its spectral radius. Explain how this implies convergence or divergence of the Jacobi method for this $A$.\n- Conclude whether SDD is a necessary condition for Jacobi convergence and justify your conclusion by reference to this matrix.\n\nReport as your final answer the exact value of the spectral radius of the Jacobi iteration matrix for $A$. No rounding is required. The final answer must be a single real number.", "solution": "The problem requires an analysis of the necessity of Strict Diagonal Dominance (SDD) for the convergence of the Jacobi iterative method, using a specific matrix as a potential counterexample. The analysis will proceed in three steps as requested: verification of the matrix's non-SDD property, derivation of the Jacobi iteration matrix and its spectral radius to assess convergence, and a final conclusion on the necessity of the SDD condition.\n\nFirst, we validate that the given matrix $A$ is not strictly diagonally dominant by rows. The matrix is:\n$$\nA = \\begin{pmatrix}\n1  -2  0 \\\\\n0  1  -2 \\\\\n0  0  1\n\\end{pmatrix}\n$$\nA matrix $M$ with entries $m_{ij}$ is strictly diagonally dominant by rows if the absolute value of each diagonal element is greater than the sum of the absolute values of the off-diagonal elements in its row. That is, for all rows $i$, the condition $|m_{ii}|  \\sum_{j \\neq i} |m_{ij}|$ must hold. Let's examine this condition for matrix $A$.\n\nFor row $i=1$: The diagonal element is $a_{11} = 1$. The sum of the absolute values of the off-diagonal elements is $|a_{12}| + |a_{13}| = |-2| + |0| = 2$. The condition is $|1|  2$, which simplifies to $1  2$. This is false.\n\nFor row $i=2$: The diagonal element is $a_{22} = 1$. The sum of the absolute values of the off-diagonal elements is $|a_{21}| + |a_{23}| = |0| + |-2| = 2$. The condition is $|1|  2$, which is $1  2$. This is also false.\n\nFor row $i=3$: The diagonal element is $a_{33} = 1$. The sum of the absolute values of the off-diagonal elements is $|a_{31}| + |a_{32}| = |0| + |0| = 0$. The condition is $|1|  0$, which is $1  0$. This is true.\n\nSince the condition for strict diagonal dominance fails for rows $1$ and $2$, the matrix $A$ is not strictly diagonally dominant by rows.\n\nSecond, we derive the Jacobi iteration matrix $T_J$ and its spectral radius $\\rho(T_J)$. The Jacobi method for solving a linear system $Ax=b$ is based on the splitting of the matrix $A$ into its diagonal ($D$), strictly lower triangular ($L$), and strictly upper triangular ($U$) components, such that $A = D + L + U$. The iterative scheme is given by $Dx_{k+1} = -(L+U)x_k + b$. This can be rewritten as $x_{k+1} = -D^{-1}(L+U)x_k + D^{-1}b$. The Jacobi iteration matrix is thus defined as $T_J = -D^{-1}(L+U)$.\n\nFor our matrix $A$:\nThe diagonal component is $D = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{pmatrix} = I$, the identity matrix.\nThe strictly lower triangular component is $L = \\begin{pmatrix} 0  0  0 \\\\ 0  0  0 \\\\ 0  0  0 \\end{pmatrix}$, the zero matrix.\nThe strictly upper triangular component is $U = \\begin{pmatrix} 0  -2  0 \\\\ 0  0  -2 \\\\ 0  0  0 \\end{pmatrix}$.\n\nThe inverse of the diagonal matrix $D$ is $D^{-1} = I^{-1} = I$.\nNow we can construct the Jacobi iteration matrix $T_J$:\n$$\nT_J = -D^{-1}(L+U) = -I\\left(\\begin{pmatrix} 0  0  0 \\\\ 0  0  0 \\\\ 0  0  0 \\end{pmatrix} + \\begin{pmatrix} 0  -2  0 \\\\ 0  0  -2 \\\\ 0  0  0 \\end{pmatrix}\\right) = -\\begin{pmatrix} 0  -2  0 \\\\ 0  0  -2 \\\\ 0  0  0 \\end{pmatrix} = \\begin{pmatrix} 0  2  0 \\\\ 0  0  2 \\\\ 0  0  0 \\end{pmatrix}\n$$\nThe convergence of the Jacobi method is determined by the spectral radius of $T_J$, denoted $\\rho(T_J)$, which is the maximum absolute value of its eigenvalues. The eigenvalues $\\lambda$ are the roots of the characteristic equation $\\det(T_J - \\lambda I) = 0$.\n$$\nT_J - \\lambda I = \\begin{pmatrix} 0-\\lambda  2  0 \\\\ 0  0-\\lambda  2 \\\\ 0  0  0-\\lambda \\end{pmatrix} = \\begin{pmatrix} -\\lambda  2  0 \\\\ 0  -\\lambda  2 \\\\ 0  0  -\\lambda \\end{pmatrix}\n$$\nThe determinant of this upper triangular matrix is the product of its diagonal entries:\n$$\n\\det(T_J - \\lambda I) = (-\\lambda)(-\\lambda)(-\\lambda) = -\\lambda^3\n$$\nSetting the characteristic polynomial to zero, we get $-\\lambda^3 = 0$, which yields a single eigenvalue $\\lambda = 0$ with an algebraic multiplicity of $3$. The set of eigenvalues is $\\{\\lambda_1, \\lambda_2, \\lambda_3\\} = \\{0, 0, 0\\}$.\n\nThe spectral radius is the maximum of the absolute values of the eigenvalues:\n$$\n\\rho(T_J) = \\max\\{|0|, |0|, |0|\\} = 0\n$$\nA necessary and sufficient condition for the convergence of an iterative method for any initial guess is that the spectral radius of its iteration matrix must be strictly less than $1$. Here, we have $\\rho(T_J) = 0$, and since $0  1$, the Jacobi method for a system with coefficient matrix $A$ is guaranteed to converge.\n\nFinally, we conclude whether SDD is a necessary condition for Jacobi convergence. A condition is necessary if its absence implies the absence of the outcome. In this context, if SDD were necessary for Jacobi convergence, then any matrix for which Jacobi converges must be SDD. Our analysis provides a direct counterexample to this statement. We have demonstrated that:\n1. The matrix $A$ is not strictly diagonally dominant.\n2. The Jacobi method for matrix $A$ converges, as its spectral radius is $0$.\n\nBecause the Jacobi method converges for a matrix that is not strictly diagonally dominant, we conclude that strict diagonal dominance is not a necessary condition for the convergence of the Jacobi method. It is, however, a well-known sufficient condition.", "answer": "$$\\boxed{0}$$", "id": "3219053"}, {"introduction": "While the Jacobi and Gauss-Seidel methods are closely related iterative solvers for linear systems, their convergence behaviors can be surprisingly different for the same problem. This practice guides you through constructing a matrix where one method converges rapidly while the other diverges. This striking result emphasizes that convergence depends critically on the structure of the specific iteration matrix, such as $B_{\\mathrm{J}}$ versus $B_{\\mathrm{GS}}$, and not just on the properties of the original system matrix $A$ [@problem_id:3219042].", "problem": "Let $A \\in \\mathbb{R}^{3 \\times 3}$ be split into $A = D + L + U$ where $D$ is the diagonal part, $L$ is the strictly lower triangular part, and $U$ is the strictly upper triangular part. Consider the stationary iterations for solving $A x = b$: the Jacobi iteration and the Gauss–Seidel iteration. Construct a concrete $3 \\times 3$ real matrix $A$ with integer entries such that $A$ is not strictly diagonally dominant by rows, the Jacobi iteration converges (as characterized by the spectral radius of its iteration matrix), while the Gauss–Seidel iteration diverges (as characterized by the spectral radius of its iteration matrix). For your constructed matrix, explicitly derive the Jacobi and Gauss–Seidel iteration matrices from $D$, $L$, and $U$, compute their spectral radii, and report the value of $\\rho(B_{\\mathrm{GS}}) - \\rho(B_{\\mathrm{J}})$. Express your final answer as an exact real number; no rounding is needed.", "solution": "The problem has been validated and is a well-posed problem in numerical linear algebra. It asks for the construction of a specific $3 \\times 3$ real matrix with integer entries that demonstrates that the convergence of the Jacobi iterative method does not imply the convergence of the Gauss-Seidel method. I will construct such a matrix, verify it meets all conditions, and then perform the required calculations.\n\nLet us construct the matrix $A \\in \\mathbb{R}^{3 \\times 3}$ as follows:\n$$\nA = \\begin{pmatrix} 1  2  -2 \\\\ 1  1  1 \\\\ 2  2  1 \\end{pmatrix}\n$$\nThis matrix has integer entries as required.\n\nFirst, we verify that $A$ is not strictly diagonally dominant by rows. The condition for strict diagonal dominance for a row $i$ is $|a_{ii}|  \\sum_{j \\neq i} |a_{ij}|$.\nFor row $1$: $|a_{11}| = |1| = 1$. The sum of the absolute values of the off-diagonal elements is $|a_{12}| + |a_{13}| = |2| + |-2| = 4$. Since $1 \\not 4$, the condition is not met for the first row.\nFor row $2$: $|a_{22}| = |1| = 1$. The sum of the absolute values of the off-diagonal elements is $|a_{21}| + |a_{23}| = |1| + |1| = 2$. Since $1 \\not 2$, the condition is not met for the second row.\nFor row $3$: $|a_{33}| = |1| = 1$. The sum of the absolute values of the off-diagonal elements is $|a_{31}| + |a_{32}| = |2| + |2| = 4$. Since $1 \\not 4$, the condition is not met for the third row.\nSince the condition fails for all three rows, the matrix $A$ is not strictly diagonally dominant by rows.\n\nNext, we analyze the convergence of the Jacobi and Gauss-Seidel iterations. The matrix $A$ is split into its diagonal ($D$), strictly lower triangular ($L$), and strictly upper triangular ($U$) parts:\n$$\nD = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{pmatrix}, \\quad L = \\begin{pmatrix} 0  0  0 \\\\ 1  0  0 \\\\ 2  2  0 \\end{pmatrix}, \\quad U = \\begin{pmatrix} 0  2  -2 \\\\ 0  0  1 \\\\ 0  0  0 \\end{pmatrix}\n$$\nNote that $D$ is the identity matrix, $I$.\n\nThe Jacobi iteration matrix is given by $B_{\\mathrm{J}} = -D^{-1}(L+U)$. Since $D=I$, this simplifies to $B_{\\mathrm{J}} = -(L+U)$.\n$$\nB_{\\mathrm{J}} = - \\left( \\begin{pmatrix} 0  0  0 \\\\ 1  0  0 \\\\ 2  2  0 \\end{pmatrix} + \\begin{pmatrix} 0  2  -2 \\\\ 0  0  1 \\\\ 0  0  0 \\end{pmatrix} \\right) = - \\begin{pmatrix} 0  2  -2 \\\\ 1  0  1 \\\\ 2  2  0 \\end{pmatrix} = \\begin{pmatrix} 0  -2  2 \\\\ -1  0  -1 \\\\ -2  -2  0 \\end{pmatrix}\n$$\nTo find the spectral radius $\\rho(B_{\\mathrm{J}})$, we compute the eigenvalues $\\lambda$ from the characteristic equation $\\det(B_{\\mathrm{J}} - \\lambda I) = 0$:\n$$\n\\det \\begin{pmatrix} -\\lambda  -2  2 \\\\ -1  -\\lambda  -1 \\\\ -2  -2  -\\lambda \\end{pmatrix} = -\\lambda(\\lambda^2 - 2) - (-2)(\\lambda - 2) + 2(2 - 2\\lambda) = -\\lambda^3 + 2\\lambda + 2\\lambda - 4 + 4 - 4\\lambda = -\\lambda^3\n$$\nThe characteristic equation is $-\\lambda^3 = 0$, which has a triple root $\\lambda = 0$. The eigenvalues are $\\lambda_1 = \\lambda_2 = \\lambda_3 = 0$.\nThe spectral radius of the Jacobi matrix is $\\rho(B_{\\mathrm{J}}) = \\max\\{|0|\\} = 0$.\nSince $\\rho(B_{\\mathrm{J}})  1$, the Jacobi iteration converges.\n\nThe Gauss-Seidel iteration matrix is given by $B_{\\mathrm{GS}} = -(D+L)^{-1}U$.\nFirst, we find the inverse of $(D+L)$:\n$$\nD+L = \\begin{pmatrix} 1  0  0 \\\\ 1  1  0 \\\\ 2  2  1 \\end{pmatrix}\n$$\nUsing forward substitution to solve $(D+L)Y=I$, we find the inverse:\n$$\n(D+L)^{-1} = \\begin{pmatrix} 1  0  0 \\\\ -1  1  0 \\\\ 0  -2  1 \\end{pmatrix}\n$$\nNow, we compute $B_{\\mathrm{GS}}$:\n$$\nB_{\\mathrm{GS}} = -(D+L)^{-1}U = - \\begin{pmatrix} 1  0  0 \\\\ -1  1  0 \\\\ 0  -2  1 \\end{pmatrix} \\begin{pmatrix} 0  2  -2 \\\\ 0  0  1 \\\\ 0  0  0 \\end{pmatrix} = - \\begin{pmatrix} 0  2  -2 \\\\ 0  -2  3 \\\\ 0  0  -2 \\end{pmatrix} = \\begin{pmatrix} 0  -2  2 \\\\ 0  2  -3 \\\\ 0  0  2 \\end{pmatrix}\n$$\nSince $B_{\\mathrm{GS}}$ is an upper triangular matrix, its eigenvalues are its diagonal entries: $\\lambda_1 = 0$, $\\lambda_2 = 2$, and $\\lambda_3 = 2$.\nThe spectral radius of the Gauss-Seidel matrix is $\\rho(B_{\\mathrm{GS}}) = \\max\\{|0|, |2|, |2|\\} = 2$.\nSince $\\rho(B_{\\mathrm{GS}}) = 2 \\ge 1$, the Gauss-Seidel iteration diverges.\n\nThe constructed matrix $A$ fulfills all the given conditions.\nThe final step is to compute the value of $\\rho(B_{\\mathrm{GS}}) - \\rho(B_{\\mathrm{J}})$.\n$$\n\\rho(B_{\\mathrm{GS}}) - \\rho(B_{\\mathrm{J}}) = 2 - 0 = 2\n$$", "answer": "$$\n\\boxed{2}\n$$", "id": "3219042"}]}