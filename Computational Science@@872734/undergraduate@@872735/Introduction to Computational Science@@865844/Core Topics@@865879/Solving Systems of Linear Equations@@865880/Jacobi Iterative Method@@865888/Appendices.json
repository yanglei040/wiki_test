{"hands_on_practices": [{"introduction": "The Jacobi method provides a way to solve a system of linear equations by starting with a guess and iteratively refining it. But how do we know if this refinement process will actually lead us to the correct answer? This practice gets to the heart of the matter by having you calculate the spectral radius of the Jacobi iteration matrix, a key value that provides the definitive test for convergence [@problem_id:2207653].", "problem": "In a simplified economic model, the equilibrium prices, $p_1$ and $p_2$, of two competing but interdependent software products are determined by a system of linear equations. To find these prices, one might use an iterative numerical method. Consider the following system that models the price relationship:\n\n$$\n\\begin{align*}\n4p_1 - 2p_2 = 10 \\\\\np_1 + 5p_2 = 17\n\\end{align*}\n$$\n\nThis system can be written in the matrix form $A\\mathbf{p} = \\mathbf{b}$. The Jacobi method is an iterative algorithm for solving such a system. The convergence of the Jacobi method is determined by the spectral radius, $\\rho(T_J)$, of its iteration matrix $T_J$.\n\nCalculate the spectral radius of the Jacobi iteration matrix $T_J$ for the given system of equations. Express your final answer as a closed-form analytic expression.", "solution": "The linear system is written as $A\\mathbf{p}=\\mathbf{b}$ with\n$$\nA=\\begin{pmatrix}4  -2 \\\\ 1  5\\end{pmatrix},\\quad \\mathbf{p}=\\begin{pmatrix}p_{1} \\\\ p_{2}\\end{pmatrix},\\quad \\mathbf{b}=\\begin{pmatrix}10 \\\\ 17\\end{pmatrix}.\n$$\nFor the Jacobi method, we decompose $A$ into its diagonal part $D$ and its off-diagonal part. The Jacobi iteration matrix is defined as $T_J = -D^{-1}(A-D)$. The diagonal matrix $D$ and its inverse $D^{-1}$ are:\n$$\nD=\\begin{pmatrix}4  0 \\\\ 0  5\\end{pmatrix},\\quad D^{-1}=\\begin{pmatrix}\\frac{1}{4}  0 \\\\ 0  \\frac{1}{5}\\end{pmatrix}.\n$$\nThe off-diagonal part is $A-D = \\begin{pmatrix}0  -2 \\\\ 1  0\\end{pmatrix}$.\nHence, the iteration matrix is:\n$$\nT_{J}=-D^{-1}(A-D)=-\\begin{pmatrix}\\frac{1}{4}  0 \\\\ 0  \\frac{1}{5}\\end{pmatrix}\\begin{pmatrix}0  -2 \\\\ 1  0\\end{pmatrix} = -\\begin{pmatrix}0  -\\frac{1}{2} \\\\ \\frac{1}{5}  0\\end{pmatrix} = \\begin{pmatrix}0  \\frac{1}{2} \\\\ -\\frac{1}{5}  0\\end{pmatrix}.\n$$\nTo find the spectral radius, we compute the eigenvalues of $T_{J}$. For a matrix of the form $\\begin{pmatrix}0  a \\\\ b  0\\end{pmatrix}$, the characteristic polynomial is $\\lambda^{2}-ab=0$, so the eigenvalues are $\\lambda=\\pm\\sqrt{ab}$. Here $a=\\frac{1}{2}$ and $b=-\\frac{1}{5}$, giving\n$$\n\\lambda^{2}-\\left(\\frac{1}{2}\\right)\\left(-\\frac{1}{5}\\right)=\\lambda^{2}+\\frac{1}{10}=0,\n$$\nso\n$$\n\\lambda=\\pm i\\sqrt{\\frac{1}{10}}.\n$$\nThe spectral radius is the maximum modulus of the eigenvalues:\n$$\n\\rho(T_{J})=\\sqrt{\\frac{1}{10}}=\\frac{1}{\\sqrt{10}}.\n$$", "answer": "$$\\boxed{\\frac{1}{\\sqrt{10}}}$$", "id": "2207653"}, {"introduction": "While the spectral radius is the ultimate arbiter of convergence, calculating it isn't always easy, leading us to use simpler, sufficient conditions like strict diagonal dominance to quickly guarantee convergence. This thought-provoking exercise challenges you to explore the interesting region where this simple check fails, yet the method still works. This will sharpen your understanding of the crucial difference between sufficient and necessary conditions in numerical analysis [@problem_id:2442152].", "problem": "Let $A(\\alpha)$ be the $3 \\times 3$ real matrix\n$$\nA(\\alpha)=\\begin{pmatrix}\n1  -\\alpha  0 \\\\\n-\\alpha  1  -\\alpha \\\\\n0  -\\alpha  1\n\\end{pmatrix},\n$$\nwhere $\\alpha \\in \\mathbb{R}$. A matrix is said to be strictly diagonally dominant if for every row index $i$ one has $|a_{ii}|  \\sum_{j \\neq i} |a_{ij}|$. Consider the Jacobi stationary iteration for solving the linear system $A(\\alpha)\\,x=b$, which is defined via the diagonal-offdiagonal splitting of $A(\\alpha)$. Say that the Jacobi method converges if, for this $A(\\alpha)$, the iteration converges for all right-hand sides $b \\in \\mathbb{R}^{3}$ and for any initial guess.\n\nDetermine the exact value of\n$$\nc=\\sup\\left\\{\\,|\\alpha| \\,:\\, A(\\alpha)\\ \\text{is not strictly diagonally dominant and the Jacobi iteration converges}\\,\\right\\}.\n$$\nGive your answer as a single closed-form expression. No rounding is required.", "solution": "The problem is first subjected to validation.\n\n**Step 1: Extract Givens**\n-   The matrix is given as $A(\\alpha) = \\begin{pmatrix} 1  -\\alpha  0 \\\\ -\\alpha  1  -\\alpha \\\\ 0  -\\alpha  1 \\end{pmatrix}$, where $\\alpha \\in \\mathbb{R}$.\n-   The definition of a strictly diagonally dominant (SDD) matrix is provided: for every row index $i$, $|a_{ii}|  \\sum_{j \\neq i} |a_{ij}|$.\n-   The Jacobi stationary iteration for $A(\\alpha)x=b$ is considered.\n-   The definition of convergence for the Jacobi method is given: the iteration converges for all right-hand sides $b \\in \\mathbb{R}^{3}$ and for any initial guess.\n-   The quantity to be determined is $c=\\sup\\left\\{\\,|\\alpha| \\,:\\, A(\\alpha)\\ \\text{is not strictly diagonally dominant and the Jacobi iteration converges}\\,\\right\\}$.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientific Grounding**: The problem is situated in the domain of numerical linear algebra, a core topic in computational science. The concepts of strict diagonal dominance, Jacobi iteration, and convergence based on spectral radius are standard and well-established mathematical principles. The problem is scientifically sound.\n-   **Well-Posedness**: The problem defines a set of real numbers $|\\alpha|$ based on two clear, formalizable conditions. It then asks for the supremum of this set. This is a well-defined mathematical objective. The problem is not underspecified, overconstrained, or ambiguous.\n-   **Objectivity**: The problem is stated using precise mathematical language and definitions. It is free from subjective claims or opinions.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is a standard exercise in analyzing the convergence of an iterative method. A solution will be provided.\n\n**Solution Derivation**\n\nThe problem requires us to find the supremum of a set of values $|\\alpha|$ that satisfy two conditions simultaneously:\n1.  The matrix $A(\\alpha)$ is **not** strictly diagonally dominant.\n2.  The Jacobi iteration for the system $A(\\alpha)x=b$ converges.\n\nWe will analyze each condition separately to determine the constraints on $|\\alpha|$.\n\n**Condition 1: Strict Diagonal Dominance**\n\nA matrix is strictly diagonally dominant if for each row $i$, the absolute value of the diagonal element is greater than the sum of the absolute values of the off-diagonal elements in that row. For the given matrix $A(\\alpha)$:\n$$\nA(\\alpha)=\\begin{pmatrix}\n1  -\\alpha  0 \\\\\n-\\alpha  1  -\\alpha \\\\\n0  -\\alpha  1\n\\end{pmatrix}\n$$\nThe conditions for strict diagonal dominance are:\n-   Row 1: $|a_{11}|  |a_{12}| + |a_{13}| \\implies |1|  |-\\alpha| + |0| \\implies 1  |\\alpha|$.\n-   Row 2: $|a_{22}|  |a_{21}| + |a_{23}| \\implies |1|  |-\\alpha| + |-\\alpha| \\implies 1  2|\\alpha| \\implies |\\alpha|  \\frac{1}{2}$.\n-   Row 3: $|a_{33}|  |a_{31}| + |a_{32}| \\implies |1|  |0| + |-\\alpha| \\implies 1  |\\alpha|$.\n\nFor $A(\\alpha)$ to be strictly diagonally dominant, all three inequalities must be satisfied. The most restrictive condition is $|\\alpha|  \\frac{1}{2}$. Therefore, $A(\\alpha)$ is strictly diagonally dominant if and only if $|\\alpha|  \\frac{1}{2}$.\n\nThe problem specifies that $A(\\alpha)$ is **not** strictly diagonally dominant. This is the negation of the condition just derived. Thus, the first condition on $\\alpha$ is:\n$$ |\\alpha| \\ge \\frac{1}{2} $$\n\n**Condition 2: Convergence of the Jacobi Method**\n\nThe Jacobi iteration for a linear system $Ax=b$ is defined by splitting the matrix $A$ into its diagonal ($D$) and off-diagonal parts. The iteration matrix is $T_J = -D^{-1}(A-D)$. The method converges for any initial guess if and only if the spectral radius of the iteration matrix, $\\rho(T_J)$, is strictly less than $1$.\n\nFor our matrix $A(\\alpha)$, the diagonal part is $D = I$.\nThe Jacobi iteration matrix is therefore:\n$$ T_J = -I^{-1}(A(\\alpha)-I) = -(A(\\alpha)-I) = \\begin{pmatrix} 0  \\alpha  0 \\\\ \\alpha  0  \\alpha \\\\ 0  \\alpha  0 \\end{pmatrix} $$\nTo find the spectral radius $\\rho(T_J)$, we must find the eigenvalues of $T_J$ by solving the characteristic equation $\\det(T_J - \\lambda I) = 0$.\n$$\n\\det\\begin{pmatrix}\n-\\lambda  \\alpha  0 \\\\\n\\alpha  -\\lambda  \\alpha \\\\\n0  \\alpha  -\\lambda\n\\end{pmatrix} = 0\n$$\nExpanding the determinant along the first row:\n$$\n-\\lambda \\det\\begin{pmatrix} -\\lambda  \\alpha \\\\ \\alpha  -\\lambda \\end{pmatrix} - \\alpha \\det\\begin{pmatrix} \\alpha  \\alpha \\\\ 0  -\\lambda \\end{pmatrix} = 0\n$$\n$$\n-\\lambda (\\lambda^2 - \\alpha^2) - \\alpha(-\\alpha\\lambda - 0) = 0\n$$\n$$\n-\\lambda^3 + \\alpha^2\\lambda + \\alpha^2\\lambda = 0\n$$\n$$\n-\\lambda^3 + 2\\alpha^2\\lambda = 0\n$$\n$$\n\\lambda(-\\lambda^2 + 2\\alpha^2) = 0\n$$\nThe eigenvalues $\\lambda$ are the roots of this equation: $\\lambda_1 = 0$ and $\\lambda^2 = 2\\alpha^2$, which gives $\\lambda_{2,3} = \\pm\\sqrt{2\\alpha^2} = \\pm\\sqrt{2}|\\alpha|$.\nThe eigenvalues of $T_J$ are $\\{0, \\sqrt{2}|\\alpha|, -\\sqrt{2}|\\alpha|\\}$.\n\nThe spectral radius $\\rho(T_J)$ is the maximum of the absolute values of the eigenvalues:\n$$\n\\rho(T_J) = \\max\\left\\{|0|, |\\sqrt{2}|\\alpha||, |-\\sqrt{2}|\\alpha||\\right\\} = \\sqrt{2}|\\alpha|\n$$\nThe Jacobi method converges if and only if $\\rho(T_J)  1$. This provides our second condition on $\\alpha$:\n$$\n\\sqrt{2}|\\alpha|  1 \\implies |\\alpha|  \\frac{1}{\\sqrt{2}}\n$$\n\n**Combining Conditions to Find c**\n\nWe are asked to find $c = \\sup(S)$, where $S$ is the set of values of $|\\alpha|$ that satisfy both derived conditions:\n1.  $|\\alpha| \\ge \\frac{1}{2}$\n2.  $|\\alpha|  \\frac{1}{\\sqrt{2}}$\n\nCombining these inequalities, we define the interval for $|\\alpha|$:\n$$\n\\frac{1}{2} \\le |\\alpha|  \\frac{1}{\\sqrt{2}}\n$$\nThe set of possible values for $|\\alpha|$ is the interval $\\left[\\frac{1}{2}, \\frac{1}{\\sqrt{2}}\\right)$. The supremum of this set is the least upper bound, which is the right endpoint of the interval.\n\nTherefore, the exact value of $c$ is:\n$$\nc = \\sup\\left[\\frac{1}{2}, \\frac{1}{\\sqrt{2}}\\right) = \\frac{1}{\\sqrt{2}}\n$$\nThis value can also be written as $\\frac{\\sqrt{2}}{2}$. We will provide the former.", "answer": "$$\n\\boxed{\\frac{1}{\\sqrt{2}}}\n$$", "id": "2442152"}, {"introduction": "When an iterative method converges, we might intuitively expect each step to bring us progressively closer to the solution. This practice explores a fascinating and practical nuance: even for a guaranteed convergent system, the residual—a measure of the error at each step—does not necessarily decrease monotonically. By working through this example [@problem_id:3218944], you will gain a more realistic understanding of the dynamic behavior of iterative solvers.", "problem": "Let $A \\in \\mathbb{R}^{2 \\times 2}$ and $b \\in \\mathbb{R}^{2}$ be defined by\n$$\nA = \\begin{pmatrix} 5  -4 \\\\ \\frac{1}{10}  \\frac{6}{5} \\end{pmatrix}, \\qquad b = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}.\n$$\nConsider solving $A x = b$ using the Jacobi iteration starting from the initial guess $x_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$, and use the standard Euclidean vector norm for all norms. Starting from fundamental definitions of the Jacobi method and the spectral radius, do the following:\n1. Establish that $A$ is strictly diagonally dominant.\n2. Using the definition of Jacobi iteration from a diagonal-off-diagonal splitting of $A$, derive the iteration mapping and justify that the Jacobi iteration converges for this $A$ by analytically determining the spectral radius of the corresponding iteration matrix.\n3. Compute the first iterate $x_{1}$ and the residuals $r_{0} = b - A x_{0}$ and $r_{1} = b - A x_{1}$, and determine whether $\\|r_{1}\\|$ is greater than, equal to, or less than $\\|r_{0}\\|$.\n4. Provide the exact value of the spectral radius of the Jacobi iteration matrix for this $A$ as your final answer. No rounding is required; write your answer in a simplified exact radical form.", "solution": "The problem is valid as it is a well-posed question in numerical linear algebra with all necessary information provided. We proceed with the solution by addressing each part of the problem statement.\n\nThe given matrix $A$ and vector $b$ are:\n$$\nA = \\begin{pmatrix} 5  -4 \\\\ \\frac{1}{10}  \\frac{6}{5} \\end{pmatrix}, \\qquad b = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\nThe problem is to analyze the Jacobi iteration for solving the linear system $A x = b$.\n\n1.  **Strict Diagonal Dominance**\n\nA square matrix $A = (a_{ij})$ is strictly diagonally dominant if, for each row $i$, the magnitude of the diagonal element is strictly greater than the sum of the magnitudes of all other elements in that row. Mathematically, this is expressed as:\n$$\n|a_{ii}|  \\sum_{j \\neq i} |a_{ij}| \\quad \\text{for all } i\n$$\nWe check this condition for the given matrix $A$:\n\nFor the first row ($i=1$):\nThe diagonal element is $a_{11} = 5$. The off-diagonal element is $a_{12} = -4$.\nWe check if $|a_{11}|  |a_{12}|$.\n$|5| = 5$.\n$|-4| = 4$.\nSince $5  4$, the condition holds for the first row.\n\nFor the second row ($i=2$):\nThe diagonal element is $a_{22} = \\frac{6}{5}$. The off-diagonal element is $a_{21} = \\frac{1}{10}$.\nWe check if $|a_{22}|  |a_{21}|$.\n$|\\frac{6}{5}| = \\frac{6}{5} = 1.2$.\n$|\\frac{1}{10}| = \\frac{1}{10} = 0.1$.\nSince $\\frac{6}{5}  \\frac{1}{10}$ (or $1.2  0.1$), the condition holds for the second row.\n\nSince the condition for strict diagonal dominance is satisfied for all rows, the matrix $A$ is strictly diagonally dominant.\n\n2.  **Jacobi Iteration and Convergence**\n\nThe Jacobi method is based on splitting the matrix $A$ into its diagonal part $D$ and its off-diagonal part. For the decomposition $A = D - L - U$ where $-L$ is the strictly lower triangular part and $-U$ is the strictly upper triangular part:\n$$\nD = \\begin{pmatrix} 5  0 \\\\ 0  \\frac{6}{5} \\end{pmatrix}, \\quad L = \\begin{pmatrix} 0  0 \\\\ -\\frac{1}{10}  0 \\end{pmatrix}, \\quad U = \\begin{pmatrix} 0  4 \\\\ 0  0 \\end{pmatrix}\n$$\nThe Jacobi iteration is defined by $D x_{k+1} = (L+U) x_k + b$, and the iteration matrix is $T_J = D^{-1}(L+U)$.\n\nFirst, we find the inverse of $D$:\n$$\nD^{-1} = \\begin{pmatrix} 5^{-1}  0 \\\\ 0  (\\frac{6}{5})^{-1} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{5}  0 \\\\ 0  \\frac{5}{6} \\end{pmatrix}\n$$\nNext, we compute $L+U$:\n$$\nL+U = \\begin{pmatrix} 0  4 \\\\ -\\frac{1}{10}  0 \\end{pmatrix}\n$$\nNow, we can derive the iteration matrix $T_J$:\n$$\nT_J = D^{-1}(L+U) = \\begin{pmatrix} \\frac{1}{5}  0 \\\\ 0  \\frac{5}{6} \\end{pmatrix} \\begin{pmatrix} 0  4 \\\\ -\\frac{1}{10}  0 \\end{pmatrix} = \\begin{pmatrix} 0  \\frac{4}{5} \\\\ -\\frac{5}{60}  0 \\end{pmatrix} = \\begin{pmatrix} 0  \\frac{4}{5} \\\\ -\\frac{1}{12}  0 \\end{pmatrix}\n$$\nThe Jacobi iteration converges for any initial guess if and only if the spectral radius of the iteration matrix, $\\rho(T_J)$, is strictly less than $1$. The spectral radius is the maximum absolute value of the eigenvalues of $T_J$.\nWe find the eigenvalues $\\lambda$ by solving the characteristic equation $\\det(T_J - \\lambda I) = 0$:\n$$\n\\det\\left( \\begin{pmatrix} 0  \\frac{4}{5} \\\\ -\\frac{1}{12}  0 \\end{pmatrix} - \\lambda \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} \\right) = \\det\\begin{pmatrix} -\\lambda  \\frac{4}{5} \\\\ -\\frac{1}{12}  -\\lambda \\end{pmatrix} = 0\n$$\n$$\n(-\\lambda)(-\\lambda) - \\left(\\frac{4}{5}\\right)\\left(-\\frac{1}{12}\\right) = \\lambda^2 + \\frac{4}{60} = \\lambda^2 + \\frac{1}{15} = 0\n$$\nThis gives $\\lambda^2 = -\\frac{1}{15}$, so the eigenvalues are $\\lambda_{1,2} = \\pm i \\sqrt{\\frac{1}{15}} = \\pm \\frac{i}{\\sqrt{15}}$.\n\nThe absolute value of these complex eigenvalues is:\n$$\n|\\lambda_{1,2}| = \\left|\\pm \\frac{i}{\\sqrt{15}}\\right| = \\sqrt{0^2 + \\left(\\pm \\frac{1}{\\sqrt{15}}\\right)^2} = \\sqrt{\\frac{1}{15}} = \\frac{1}{\\sqrt{15}}\n$$\nThe spectral radius is the maximum of these absolute values:\n$$\n\\rho(T_J) = \\max \\left( \\frac{1}{\\sqrt{15}}, \\frac{1}{\\sqrt{15}} \\right) = \\frac{1}{\\sqrt{15}}\n$$\nSince $\\sqrt{15}  \\sqrt{1} = 1$, we have $0  \\frac{1}{\\sqrt{15}}  1$. Because $\\rho(T_J)  1$, the Jacobi iteration is guaranteed to converge for this matrix $A$.\n\n3.  **First Iterate and Residuals**\n\nWe are given the initial guess $x_0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$. The first iterate $x_1$ is computed using the Jacobi iteration formula:\n$$\nx_1 = T_J x_0 + D^{-1}b = \\begin{pmatrix} 0  \\frac{4}{5} \\\\ -\\frac{1}{12}  0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} \\frac{1}{5}  0 \\\\ 0  \\frac{5}{6} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\n$$\nx_1 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ \\frac{5}{6} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\frac{5}{6} \\end{pmatrix}\n$$\nThe residual vector is defined as $r_k = b - Ax_k$.\n\nThe initial residual $r_0$ is:\n$$\nr_0 = b - A x_0 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} - A \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\nThe Euclidean norm of the initial residual is:\n$$\n\\|r_0\\| = \\left\\| \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\right\\|_2 = \\sqrt{0^2 + 1^2} = 1\n$$\nThe residual after the first iteration, $r_1$, is:\n$$\nr_1 = b - A x_1 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} - \\begin{pmatrix} 5  -4 \\\\ \\frac{1}{10}  \\frac{6}{5} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ \\frac{5}{6} \\end{pmatrix}\n$$\nFirst, we compute the product $A x_1$:\n$$\nA x_1 = \\begin{pmatrix} 5(0) - 4(\\frac{5}{6}) \\\\ \\frac{1}{10}(0) + \\frac{6}{5}(\\frac{5}{6}) \\end{pmatrix} = \\begin{pmatrix} -\\frac{20}{6} \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} -\\frac{10}{3} \\\\ 1 \\end{pmatrix}\n$$\nNow we compute $r_1$:\n$$\nr_1 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} - \\begin{pmatrix} -\\frac{10}{3} \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} \\frac{10}{3} \\\\ 0 \\end{pmatrix}\n$$\nThe Euclidean norm of this residual is:\n$$\n\\|r_1\\| = \\left\\| \\begin{pmatrix} \\frac{10}{3} \\\\ 0 \\end{pmatrix} \\right\\|_2 = \\sqrt{\\left(\\frac{10}{3}\\right)^2 + 0^2} = \\frac{10}{3}\n$$\nComparing the norms of the residuals:\n$$\n\\|r_0\\| = 1, \\qquad \\|r_1\\| = \\frac{10}{3} \\approx 3.33...\n$$\nSince $\\frac{10}{3}  1$, we find that $\\|r_1\\|  \\|r_0\\|$. This demonstrates that even for a convergent iterative method, the norm of the residual is not guaranteed to decrease monotonically at every step.\n\n4.  **Final Answer Formulation**\n\nThe exact value of the spectral radius of the Jacobi iteration matrix for this $A$ was computed in part 2.\n$$\n\\rho(T_J) = \\frac{1}{\\sqrt{15}}\n$$\nTo rationalize the denominator, we multiply the numerator and denominator by $\\sqrt{15}$:\n$$\n\\rho(T_J) = \\frac{1}{\\sqrt{15}} \\cdot \\frac{\\sqrt{15}}{\\sqrt{15}} = \\frac{\\sqrt{15}}{15}\n$$\nThis is a simplified exact radical form.", "answer": "$$\n\\boxed{\\frac{\\sqrt{15}}{15}}\n$$", "id": "3218944"}]}