{"hands_on_practices": [{"introduction": "While many Fourier transforms can be found by direct integration or looking up standard pairs, a deeper understanding comes from leveraging the transform's rich set of properties. This practice challenges you to find the inverse transform of a function, $X(\\omega) = \\arctan(a\\omega)$, where a direct approach is cumbersome. By applying the frequency differentiation property, which connects differentiation in the frequency domain to multiplication by time in the time domain, you can convert the problem into a much simpler one. [@problem_id:1762463]", "problem": "Let $x(t)$ be a continuous-time signal whose Continuous-Time Fourier Transform (CTFT), defined by $X(\\omega) = \\int_{-\\infty}^{\\infty} x(t) e^{-j\\omega t} dt$, is given by:\n$$X(\\omega) = \\arctan(a\\omega)$$\nwhere $a$ is a known positive real constant and $j$ is the imaginary unit.\n\nDetermine the signal $x(t)$. Express your final answer as an analytic function of $t$ and $a$.", "solution": "We are given the continuous-time Fourier transform (CTFT) convention\n$$\nX(\\omega)=\\int_{-\\infty}^{\\infty} x(t)\\exp(-j\\omega t)\\,dt,\n$$\nand we need to find $x(t)$ such that $X(\\omega)=\\arctan(a\\omega)$, where $a0$.\n\nUse the frequency-derivative property of the Fourier transform. For a transform pair $x(t)\\leftrightarrow X(\\omega)$ under the stated convention, the following holds:\n$$\n\\frac{dX(\\omega)}{d\\omega}=\\int_{-\\infty}^{\\infty}x(t)\\frac{d}{d\\omega}\\bigl(\\exp(-j\\omega t)\\bigr)\\,dt\n=\\int_{-\\infty}^{\\infty}x(t)\\bigl(-jt\\bigr)\\exp(-j\\omega t)\\,dt\n=-j\\,\\mathcal{F}\\{t\\,x(t)\\}(\\omega),\n$$\nequivalently,\n$$\n\\mathcal{F}\\{t\\,x(t)\\}(\\omega)=j\\,\\frac{dX(\\omega)}{d\\omega}.\n$$\n\nDifferentiate $X(\\omega)=\\arctan(a\\omega)$:\n$$\n\\frac{dX(\\omega)}{d\\omega}=\\frac{a}{1+a^{2}\\omega^{2}}.\n$$\nTherefore,\n$$\n\\mathcal{F}\\{t\\,x(t)\\}(\\omega)=j\\,\\frac{a}{1+a^{2}\\omega^{2}}.\n$$\n\nWe now compute the inverse transform of $\\frac{1}{1+a^{2}\\omega^{2}}$. Using the standard pair\n$$\n\\int_{-\\infty}^{\\infty}\\exp(-\\alpha|t|)\\exp(-j\\omega t)\\,dt=\\frac{2\\alpha}{\\alpha^{2}+\\omega^{2}},\\quad \\alpha0,\n$$\nwe set $\\alpha=\\frac{1}{a}$ to obtain\n$$\n\\mathcal{F}\\left\\{\\frac{1}{2a}\\exp\\!\\left(-\\frac{|t|}{a}\\right)\\right\\}(\\omega)=\\frac{1}{1+a^{2}\\omega^{2}}.\n$$\nHence, by linearity,\n$$\nt\\,x(t)=\\mathcal{F}^{-1}\\left\\{j\\,\\frac{a}{1+a^{2}\\omega^{2}}\\right\\}(t)\n=j\\,a\\,\\mathcal{F}^{-1}\\left\\{\\frac{1}{1+a^{2}\\omega^{2}}\\right\\}(t)\n=j\\,a\\left(\\frac{1}{2a}\\exp\\!\\left(-\\frac{|t|}{a}\\right)\\right)\n=\\frac{j}{2}\\exp\\!\\left(-\\frac{|t|}{a}\\right).\n$$\nTherefore,\n$$\nx(t)=\\frac{j}{2}\\,\\frac{\\exp\\!\\left(-\\frac{|t|}{a}\\right)}{t},\n$$\ninterpreted in the distributional sense with a Cauchy principal value at $t=0$. To confirm the integration constant is zero, use the relation $j\\,\\frac{dX}{d\\omega}=\\mathcal{F}\\{t x(t)\\}$; integrating $\\frac{dX}{d\\omega}=\\frac{a}{1+a^{2}\\omega^{2}}$ yields $X(\\omega)=\\arctan(a\\omega)+C$. Since $X(0)=0$ and the principal-value integral $\\int_{-\\infty}^{\\infty}x(t)\\,dt=0$ for the odd integrand confirms $C=0$, the obtained $x(t)$ indeed inverts to $X(\\omega)=\\arctan(a\\omega)$.", "answer": "$$\\boxed{\\frac{j}{2}\\frac{\\exp(-|t|/a)}{t}}$$", "id": "1762463"}, {"introduction": "The Continuous Fourier Transform is defined by an integral, but in practice, we compute it using discrete data and algorithms like the Fast Fourier Transform (FFT). This transition from the continuous to the discrete world is not without its challenges, a primary one being spectral leakage, especially for signals with sharp jumps or discontinuities. This hands-on coding exercise guides you through approximating a CTFT, quantifying the resulting spectral leakage, and implementing windowing—a fundamental technique to mitigate such artifacts. [@problem_id:3112450]", "problem": "You are to implement a complete computational pipeline, grounded in first principles, to approximate the continuous-time Fourier transform of a piecewise-defined function with jump discontinuities, diagnose spectral leakage, and mitigate it with boundary smoothing. Use the fundamental definition of the Continuous-Time Fourier Transform (CTFT) and construct the algorithmic steps from this base. Whenever angles are used, they must be in radians. No physical units are involved.\n\nStart from the core definition of the Continuous-Time Fourier Transform (CTFT): given a real-valued function $f(x)$ with finite support on $[0,1]$, its CTFT is the map $\\omega \\mapsto F(\\omega)$ where $F(\\omega)$ is defined via an integral against the complex exponential. You must approximate $F(\\omega)$ by a Riemann sum constructed on a uniform grid over the domain of $f$, and you must diagnose spectral leakage via a quantitative tail-energy metric. Then, propose and implement a boundary smoothing approach that enforces continuity at the domain edges and empirically reduces spectral leakage.\n\nYour program must perform the following tasks using purely mathematical and algorithmic logic:\n\n- Construct a uniform grid on $[0,1]$ of $N$ points, with $N = 4096$. Denote the grid by $x_n = n \\Delta x$ for $n \\in \\{0,1,\\ldots,N-1\\}$, where $\\Delta x = 1/N$.\n- For each test case function $f$ defined on $[0,1]$ by piecewise-constant segments with jump discontinuities, sample $f$ on the grid.\n- Approximate the CTFT at discrete angular frequencies $\\omega_k = \\frac{2\\pi k}{T}$ for $k \\in \\{-\\lfloor N/2 \\rfloor, \\ldots, \\lfloor N/2 \\rfloor - 1\\}$ with $T = 1$, by a Riemann sum that is equivalent to a Discrete Fourier Transform (DFT) scaled by $\\Delta x$. Define Discrete Fourier Transform (DFT) on the uniformly sampled sequence and use it to compute approximations $\\hat{F}(\\omega_k)$ both without smoothing and with boundary smoothing.\n- Define spectral leakage for an approximation $\\hat{F}$ by the tail-energy fraction outside a specified angular frequency threshold. Let the tail threshold be $\\omega_{\\text{tail}} = 200\\pi$. The leakage metric is the ratio of energy beyond $|\\omega|  \\omega_{\\text{tail}}$ to the total energy across all sampled frequencies. Energies are computed from the squared magnitudes $|\\hat{F}(\\omega_k)|^2$; any uniform frequency-weight factor cancels in the fraction.\n- Implement a boundary smoothing that forces continuity at $x=0$ and $x=1$ by multiplying the sampled $f$ by a smooth taper function that is zero at the endpoints and strictly positive in the interior. Use a Hann taper window $w(n)$ on the discrete grid, defined so that $w(0) = 0$ and $w(N-1) = 0$, and $w(n)$ is continuous in $n$ when viewed as a function of $x_n$. Compute the CTFT approximation for both the unsmoothed case (rectangular window equal to $1$ on the entire grid) and the smoothed case (Hann taper), then compute their respective leakage fractions.\n- Report the improvement due to boundary smoothing for each test case as the ratio of the unsmoothed leakage fraction to the smoothed leakage fraction. A ratio greater than $1$ indicates that smoothing reduced leakage.\n\nTest suite specification:\n\nLet $T = 1$ and $N = 4096$. Define three piecewise-constant test functions on $[0,1]$ using the following segment lists, where each segment is $[a,b)$ except the last which is $[a,b]$, and on each segment the function equals the given constant value.\n\n- Case $1$ (boundary discontinuity present): $f(x) = 2$ on $[0,0.4)$, $f(x) = -1$ on $[0.4,0.7)$, and $f(x) = 0$ on $[0.7,1]$.\n- Case $2$ (boundary continuity at endpoints): $f(x) = 0$ on $[0,0.3)$, $f(x) = 3$ on $[0.3,0.6)$, and $f(x) = 0$ on $[0.6,1]$.\n- Case $3$ (narrow interior jump, endpoints are zero): $f(x) = 0$ on $[0,0.49)$, $f(x) = 5$ on $[0.49,0.51)$, and $f(x) = 0$ on $[0.51,1]$.\n\nFor each case, compute:\n\n- The leakage fraction for the unsmoothed rectangular window approximation, denoted $\\lambda_{\\text{rect}}$.\n- The leakage fraction for the Hann-tapered approximation, denoted $\\lambda_{\\text{hann}}$.\n- The leakage reduction ratio $r = \\lambda_{\\text{rect}} / \\lambda_{\\text{hann}}$.\n\nFinal output format requirement:\n\nYour program should produce a single line of output containing the leakage reduction ratios for the three test cases as a comma-separated list enclosed in square brackets, with each float rounded to $6$ decimal places, for example $[r_1,r_2,r_3]$. Angles must be in radians and the angular frequency threshold is $\\omega_{\\text{tail}} = 200\\pi$.", "solution": "We begin from the fundamental definition of the Continuous-Time Fourier Transform (CTFT). For a real-valued function $f(x)$ supported on $[0,1]$, the CTFT is the function $F(\\omega)$ defined by the integral\n$$\nF(\\omega) = \\int_{-\\infty}^{\\infty} f(x) e^{-i \\omega x} \\, dx,\n$$\nwhich reduces to\n$$\nF(\\omega) = \\int_{0}^{1} f(x) e^{-i \\omega x} \\, dx\n$$\nwhen $f(x)$ is zero outside $[0,1]$. This is the fundamental base: the CTFT is defined by integration against the complex exponential kernel $e^{-i \\omega x}$, a well-tested and widely accepted definition.\n\nTo implement a computational pipeline that is principled and aligned with this definition, we follow a Riemann-sum approximation. Let the domain be sampled on a uniform grid $x_n = n \\Delta x$, $n \\in \\{0,1,\\ldots,N-1\\}$, where $\\Delta x = 1/N$. For a discrete set of angular frequencies $\\omega_k = \\frac{2\\pi k}{T}$ with $T = 1$ and $k \\in \\{-\\lfloor N/2 \\rfloor, \\ldots, \\lfloor N/2 \\rfloor - 1\\}$, a Riemann-sum approximation of the CTFT is given by\n$$\n\\hat{F}(\\omega_k) \\approx \\Delta x \\sum_{n=0}^{N-1} f(x_n) e^{-i \\omega_k x_n}.\n$$\nThis sum is exactly a Discrete Fourier Transform (DFT) of the sampled sequence $f(x_n)$ at the frequencies $\\omega_k$ when scaled by $\\Delta x$, because the exponential $e^{-i \\omega_k x_n}$ becomes $e^{-i 2\\pi k n / N}$ for $T=1$ and $x_n = n/N$. Therefore, we can compute $\\hat{F}(\\omega_k)$ via a DFT (fast implementation via the Fast Fourier Transform) multiplied by $\\Delta x$.\n\nSpectral leakage is diagnosed by measuring how energy in the spectral estimate $\\hat{F}(\\omega)$ spreads outside a chosen frequency band. While perfect band-limiting is rare for piecewise-constant functions with jumps (which are known to have high-frequency content decaying like $1/\\omega$), a consistent quantitative metric can be defined via tail energy. For any approximation $\\hat{F}$, define the leakage fraction\n$$\n\\lambda = \\frac{\\sum_{k : |\\omega_k|  \\omega_{\\text{tail}}} |\\hat{F}(\\omega_k)|^2}{\\sum_{k} |\\hat{F}(\\omega_k)|^2},\n$$\nwhere $\\omega_{\\text{tail}}$ is a fixed angular frequency threshold and all sums are taken over the discrete frequency grid. Both numerator and denominator share any uniform bin width factor, so the fraction is invariant under such scaling. This metric quantifies the proportion of energy in high-frequency tails.\n\nBoundary discontinuities are a known source of spectral leakage in DFT-based approximations: the implicit periodic extension of the sampled function can induce a jump at $x=0$ and $x=1$ when the endpoint values differ, exciting high-frequency components. A principled mitigation is boundary smoothing by tapering, which enforces continuity (and, for sufficiently smooth tapers, differentiability) at the boundaries. A Hann taper is defined on the discrete grid by\n$$\nw(n) = \\tfrac{1}{2} \\left( 1 - \\cos\\left(\\frac{2\\pi n}{N-1}\\right) \\right),\n$$\nwhich satisfies $w(0) = 0$ and $w(N-1) = 0$, and smoothly attains $1$ near the center. Applying this taper to $f$ yields $f_{\\text{hann}}(x_n) = f(x_n) w(n)$, whose implicit periodic extension is continuous at the endpoints and thus reduces leakage. In frequency, multiplication by the taper corresponds to a convolution $F * W$ of the original CTFT with the taper’s CTFT, smoothing sharp spectral features and redistributing energy away from the endpoints of the frequency grid in a controlled manner.\n\nAlgorithmic steps:\n\n1. Construct the grid: set $N = 4096$ and $\\Delta x = 1/N$, with $x_n = n \\Delta x$.\n2. For each piecewise-defined test case, sample $f(x_n)$ by selecting the constant value for each segment according to whether $x_n \\in [a,b)$, with the last segment defined as $[a,b]$ to include $x=1$.\n3. Define two window functions: the rectangular window $w_{\\text{rect}}(n) = 1$ and the Hann window $w_{\\text{hann}}(n)$ given as above.\n4. Form two sequences for each case: $f_{\\text{rect}}(x_n) = f(x_n) w_{\\text{rect}}(n)$ and $f_{\\text{hann}}(x_n) = f(x_n) w_{\\text{hann}}(n)$.\n5. Compute their DFTs $\\mathcal{F}_{\\text{rect}}[k]$ and $\\mathcal{F}_{\\text{hann}}[k]$ and scale by $\\Delta x$ to obtain CTFT approximations $\\hat{F}_{\\text{rect}}(\\omega_k)$ and $\\hat{F}_{\\text{hann}}(\\omega_k)$; the discrete angular frequencies are $\\omega_k = \\frac{2\\pi k}{T}$ with $T=1$ and $k$ determined by the DFT frequency layout.\n6. Compute leakage fractions $\\lambda_{\\text{rect}}$ and $\\lambda_{\\text{hann}}$ by summing $|\\hat{F}(\\omega_k)|^2$ beyond $\\omega_{\\text{tail}} = 200\\pi$ and dividing by the total energy sum across all $k$.\n7. Compute the leakage reduction ratio $r = \\lambda_{\\text{rect}} / \\lambda_{\\text{hann}}$ for each case; $r  1$ indicates that boundary smoothing reduced spectral leakage.\n\nTest suite cases are:\n- Case $1$: $f(x) = 2$ on $[0,0.4)$, $f(x) = -1$ on $[0.4,0.7)$, $f(x) = 0$ on $[0.7,1]$; this has a boundary discontinuity at $x=0$ to $x=1$.\n- Case $2$: $f(x) = 0$ on $[0,0.3)$, $f(x) = 3$ on $[0.3,0.6)$, $f(x) = 0$ on $[0.6,1]$; this is continuous at the endpoints.\n- Case $3$: $f(x) = 0$ on $[0,0.49)$, $f(x) = 5$ on $[0.49,0.51)$, $f(x) = 0$ on $[0.51,1]$; this has narrow interior jumps but zero endpoints.\n\nInterpretation:\n- In Case $1$, endpoint discontinuities are expected to contribute strongly to leakage; Hann taper should significantly reduce $\\lambda$ yielding $r \\gg 1$.\n- In Case $2$, endpoints are continuous; leakage arises mainly from interior jumps; Hann taper reduces leakage less, so $r$ may be closer to $1$ than Case $1$.\n- In Case $3$, the narrow pulse produces broad frequency content mainly due to interior jumps; boundary smoothing primarily addresses endpoints, so $r$ may show modest improvement.\n\nFinally, the program must print the leakage reduction ratios $[r_1,r_2,r_3]$ on a single line, with each ratio rounded to $6$ decimal places, and angles treated in radians throughout, with $\\omega_{\\text{tail}} = 200\\pi$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef hann_window(N: int) - np.ndarray:\n    \"\"\"Generate a Hann window of length N that is zero at endpoints.\"\"\"\n    n = np.arange(N, dtype=float)\n    return 0.5 * (1.0 - np.cos(2.0 * np.pi * n / (N - 1)))\n\ndef sample_piecewise_function(N: int, segments: list) - np.ndarray:\n    \"\"\"\n    Sample a piecewise-constant function on [0,1] with N samples.\n    segments: list of tuples (a, b, value), with [a,b) except last is [a,b].\n    Assumes segments cover [0,1] without gaps and with non-overlapping intervals.\n    \"\"\"\n    x = np.linspace(0.0, 1.0, N, endpoint=False)  # x_n = n/N, n=0..N-1\n    f = np.zeros_like(x)\n    for i, (a, b, val) in enumerate(segments):\n        if i  len(segments) - 1:\n            mask = (x = a)  (x  b)\n        else:\n            # last segment includes the endpoint 1, but our grid excludes 1 (endpoint=False),\n            # so this mask is equivalent to [a,b) here.\n            mask = (x = a)  (x  b)\n        f[mask] = val\n    return f\n\ndef ctft_approx_via_fft(samples: np.ndarray, T: float) - tuple:\n    \"\"\"\n    Approximate CTFT using FFT of samples scaled by Delta x.\n    Returns (omega, F_hat), where omega are angular frequencies in radians per unit x.\n    \"\"\"\n    N = samples.size\n    dx = T / N\n    # FFT and frequencies:\n    F = np.fft.fft(samples) * dx\n    # Frequencies in cycles per unit x, convert to angular frequency by 2*pi:\n    freqs = np.fft.fftfreq(N, d=dx)  # cycles per unit\n    omega = 2.0 * np.pi * freqs      # radians per unit\n    return omega, F\n\ndef leakage_fraction(omega: np.ndarray, F_hat: np.ndarray, omega_tail: float) - float:\n    \"\"\"\n    Compute leakage fraction: energy beyond |omega|  omega_tail divided by total energy.\n    \"\"\"\n    power = np.abs(F_hat)**2\n    mask_tail = np.abs(omega)  omega_tail\n    tail_energy = power[mask_tail].sum()\n    total_energy = power.sum()\n    # Handle potential numerical edge case:\n    if total_energy == 0.0:\n        return 0.0\n    return float(tail_energy / total_energy)\n\ndef solve():\n    # Parameters\n    T = 1.0\n    N = 4096\n    omega_tail = 200.0 * np.pi  # radians per unit x\n\n    # Define test cases: list of segments (a, b, value)\n    test_cases = [\n        # Case 1: boundary discontinuity present\n        [(0.0, 0.4, 2.0), (0.4, 0.7, -1.0), (0.7, 1.0, 0.0)],\n        # Case 2: boundary continuity at endpoints (zeros at ends)\n        [(0.0, 0.3, 0.0), (0.3, 0.6, 3.0), (0.6, 1.0, 0.0)],\n        # Case 3: narrow interior jump, endpoints are zero\n        [(0.0, 0.49, 0.0), (0.49, 0.51, 5.0), (0.51, 1.0, 0.0)],\n    ]\n\n    # Windows\n    rect = np.ones(N, dtype=float)\n    hann = hann_window(N)\n\n    results = []\n    for segments in test_cases:\n        # Sample f\n        f = sample_piecewise_function(N, segments)\n\n        # Unsmooth: rectangular window\n        f_rect = f * rect\n        omega_rect, F_rect = ctft_approx_via_fft(f_rect, T)\n        lambda_rect = leakage_fraction(omega_rect, F_rect, omega_tail)\n\n        # Smooth: Hann window\n        f_hann = f * hann\n        omega_hann, F_hann = ctft_approx_via_fft(f_hann, T)\n        lambda_hann = leakage_fraction(omega_hann, F_hann, omega_tail)\n\n        # Leakage reduction ratio\n        if lambda_hann == 0.0:\n            ratio = float('inf') if lambda_rect  0.0 else 1.0\n        else:\n            ratio = lambda_rect / lambda_hann\n        results.append(ratio)\n\n    # Round to 6 decimal places and format output\n    formatted = [f\"{r:.6f}\" if np.isfinite(r) else \"inf\" for r in results]\n    print(f\"[{','.join(formatted)}]\")\n\nsolve()\n```", "id": "3112450"}, {"introduction": "Reconstructing a signal from its spectrum—the inverse Fourier transform—is as important as the forward transform. The accuracy of this reconstruction hinges critically on how the frequency domain is sampled. This computational practice explores how moving beyond a simple uniform grid to a 'smarter' non-uniform grid, which concentrates points where the spectrum has more information, can dramatically improve results. You will implement and compare different numerical integration schemes to see firsthand how thoughtful grid design is a cornerstone of efficient and accurate computational science. [@problem_id:3112393]", "problem": "Consider the Continuous Fourier Transform (CFT) and its inverse, defined for a square-integrable function $f(t)$ by\n$$\nF(\\omega) = \\int_{-\\infty}^{\\infty} f(t)\\,e^{-i\\omega t}\\,dt,\\quad\nf(t) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} F(\\omega)\\,e^{i\\omega t}\\,d\\omega,\n$$\nwhere $i$ denotes the imaginary unit and all angular frequencies $\\omega$ and arguments of trigonometric/exponential functions are in radians. In computational practice, the inverse transform integral is approximated by a finite interval and a discrete sum. The accuracy depends strongly on the sampling of $F(\\omega)$ in the frequency domain and on the chosen quadrature scheme.\n\nYour task is to implement a program that reconstructs a known time-domain signal from its analytically known frequency-domain representation, using both uniform and nonuniform sampling schemes for $\\omega$. You must design and compare two inverse transform schemes tailored to nonuniform $\\omega$ grids, and benchmark them against a uniform-grid trapezoidal-rule baseline.\n\nUse the test signal\n$$\nf(t) = \\exp\\!\\left(-\\frac{t^2}{2\\sigma^2}\\right),\\quad F(\\omega) = \\int_{-\\infty}^{\\infty} \\exp\\!\\left(-\\frac{t^2}{2\\sigma^2}\\right) e^{-i\\omega t}\\,dt = \\sqrt{2\\pi}\\,\\sigma\\,\\exp\\!\\left(-\\frac{\\sigma^2\\omega^2}{2}\\right),\n$$\nwhich exactly satisfies the above CFT pair for the stated normalization. Fix the parameter $\\sigma = 0.75$. To approximate the inverse integral, truncate to the interval $\\omega\\in[-\\Omega,\\Omega]$ and discretize $\\omega$ using either a uniform or a specified nonuniform sampling rule.\n\nImplement the following inverse schemes.\n- Uniform-grid baseline: Use a uniform grid with $N$ points on $[-\\Omega,\\Omega]$, apply the composite trapezoidal rule to approximate\n$$\n\\hat{f}(t) \\approx \\frac{1}{2\\pi}\\sum_{k=0}^{N-1} F(\\omega_k)\\,e^{i\\omega_k t}\\,w_k,\n$$\nwith uniform spacing and trapezoidal weights $w_k$.\n- Nonuniform scheme A (composite trapezoidal on nonuniform nodes): Given a sorted, nonuniform $\\{\\omega_k\\}_{k=0}^{N-1}$ on $[-\\Omega,\\Omega]$, approximate the integral using the composite trapezoidal rule derived from linear interpolation of $F(\\omega)e^{i\\omega t}$ between adjacent nodes. Use nonuniform trapezoidal weights determined by neighboring node spacings.\n- Nonuniform scheme B (cubic-spline interpolation plus Gauss–Legendre (GL) quadrature): Build a natural cubic spline $S(\\omega)$ approximating $F(\\omega)$ on the given nonuniform nodes. On each interval $[\\omega_k,\\omega_{k+1}]$, approximate\n$$\n\\int_{\\omega_k}^{\\omega_{k+1}} S(\\omega)\\,e^{i\\omega t}\\,d\\omega\n$$\nby mapping to the standard GL nodes and weights on $[-1,1]$ (use $4$-point Gauss–Legendre), evaluating $S(\\omega)$ at the mapped nodes, and summing contributions over all intervals. Combine interval integrals and scale by $\\frac{1}{2\\pi}$ to obtain $\\hat{f}(t)$.\n\nFor all schemes, evaluate the reconstruction on a uniform time grid $t\\in[-6,6]$ with $M=201$ points. Compute the maximum absolute error\n$$\nE = \\max_{t\\in[-6,6]} \\left|\\hat{f}(t) - f(t)\\right|.\n$$\n\nDesign the following test suite of parameter sets to explore the effect of nonuniform $\\omega$ sampling on inverse-transform accuracy. In every case, compute and report three errors: the uniform-grid baseline error (using a uniform grid with the same $N$ and $\\Omega$), the nonuniform composite trapezoid error, and the nonuniform spline–GL error.\n- Case $1$ (happy path, uniform sampling): $N=513$, $\\Omega=14.0$, uniform $\\omega$ grid on $[-\\Omega,\\Omega]$.\n- Case $2$ (nonuniform clustered near $\\omega=0$): $N=513$, $\\Omega=14.0$, nonuniform nodes defined by $\\omega(u)=\\Omega\\,\\tanh(a u)/\\tanh(a)$ with $a=2.0$ and $u$ uniformly spaced in $[-1,1]$; sort nodes ascending.\n- Case $3$ (nonuniform skewed toward positive $\\omega$): $N=513$, $\\Omega=14.0$, nonuniform nodes defined by $\\omega(x)=\\Omega\\,(2x^p-1)$ with $p=3.0$ and $x$ uniformly spaced in $[0,1]$; sort nodes ascending.\n- Case $4$ (boundary, sparse nonuniform sampling): $N=65$, $\\Omega=14.0$, nonuniform clustered near $\\omega=0$ with the same $\\tanh$ mapping as Case $2$ ($a=2.0$); sort nodes ascending.\n\nAngle unit specification: all angular frequencies $\\omega$ and the exponent $i\\omega t$ are in radians.\n\nYour program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Aggregate the $3$ errors from each case in order, producing $12$ numbers total in the order\n$$\n[\\text{Case 1 uniform},\\ \\text{Case 1 nonuniform A},\\ \\text{Case 1 nonuniform B},\\ \\text{Case 2 uniform},\\ \\text{Case 2 nonuniform A},\\ \\text{Case 2 nonuniform B},\\ \\text{Case 3 uniform},\\ \\text{Case 3 nonuniform A},\\ \\text{Case 3 nonuniform B},\\ \\text{Case 4 uniform},\\ \\text{Case 4 nonuniform A},\\ \\text{Case 4 nonuniform B}],\n$$\nwith each number rounded to six decimal places. No other text should be printed.\n\nAll computations must be performed in pure mathematics without physical units. Ensure scientific realism by choosing truncation $\\Omega$ sufficiently large that $F(\\omega)$ is numerically negligible outside $[-\\Omega,\\Omega]$ for the stated $\\sigma$. The program must be self-contained, require no input, and be runnable in any modern programming language; however, the final answer must be a complete, runnable program as specified in the answer section.", "solution": "The problem statement is scientifically sound, well-posed, objective, and contains all necessary information for a unique solution. The definitions of the Continuous Fourier Transform (CFT), the test signal, and the numerical schemes are standard and consistent with the principles of computational science and numerical analysis. The parameters provided are realistic and suitable for the proposed numerical experiment. Therefore, the problem is valid, and a solution will be provided.\n\nThe objective is to reconstruct a time-domain signal, a Gaussian function, from its analytical Fourier transform using three different numerical schemes for the inverse transform integral. The accuracy of these schemes is evaluated by comparing the reconstructed signal $\\hat{f}(t)$ to the exact signal $f(t)$ across a specified time interval. The test signal and its transform are given by:\n$$f(t) = \\exp\\left(-\\frac{t^2}{2\\sigma^2}\\right)$$\n$$F(\\omega) = \\sqrt{2\\pi}\\,\\sigma\\,\\exp\\left(-\\frac{\\sigma^2\\omega^2}{2}\\right)$$\nwith the parameter $\\sigma = 0.75$. The inverse transform integral is approximated over a finite frequency domain $\\omega \\in [-\\Omega, \\Omega]$:\n$$\\hat{f}(t) = \\frac{1}{2\\pi}\\int_{-\\Omega}^{\\Omega} F(\\omega)\\,e^{i\\omega t}\\,d\\omega$$\nThis integral is calculated for a set of discrete time points $t_j$ on the interval $[-6, 6]$ using $M=201$ uniformly spaced points.\n\nThe core of the problem lies in the design and comparison of three numerical quadrature methods to approximate the integral.\n\n1.  **Uniform-Grid Baseline (Composite Trapezoidal Rule)**\n    This method serves as a standard reference. The frequency interval $[-\\Omega, \\Omega]$ is discretized into a uniform grid of $N$ points, $\\{\\omega_k\\}_{k=0}^{N-1}$, with constant spacing $\\Delta\\omega = \\frac{2\\Omega}{N-1}$. The integral is approximated using the composite trapezoidal rule. The approximation for $\\hat{f}(t)$ is given by a weighted sum:\n    $$\\hat{f}(t) \\approx \\frac{1}{2\\pi}\\sum_{k=0}^{N-1} F(\\omega_k)\\,e^{i\\omega_k t}\\,w_k$$\n    Here, the weights $w_k$ for the trapezoidal rule are:\n    $$w_k = \\begin{cases} \\Delta\\omega/2  \\text{if } k=0 \\text{ or } k=N-1 \\\\ \\Delta\\omega  \\text{if } 1 \\le k \\le N-2 \\end{cases}$$\n    This scheme is straightforward but can be inefficient if the integrand varies rapidly in some regions and slowly in others.\n\n2.  **Nonuniform Scheme A (Composite Trapezoidal on Nonuniform Nodes)**\n    This scheme generalizes the trapezoidal rule to a sorted, nonuniform grid $\\{\\omega_k\\}_{k=0}^{N-1}$. The integral is decomposed into a sum of integrals over the subintervals $[\\omega_k, \\omega_{k+1}]$. Each sub-integral is approximated using the area of a trapezoid:\n    $$\\int_{\\omega_k}^{\\omega_{k+1}} g(\\omega) \\, d\\omega \\approx \\frac{g(\\omega_k) + g(\\omega_{k+1})}{2} (\\omega_{k+1} - \\omega_k)$$\n    where $g(\\omega) = F(\\omega)e^{i\\omega t}$. Summing over all subintervals from $k=0$ to $N-2$ gives the full integral approximation. This can be expressed in the same weighted sum form as the uniform case, but with node-dependent weights:\n    $$\\hat{f}(t) = \\frac{1}{2\\pi}\\sum_{k=0}^{N-1} F(\\omega_k)\\,e^{i\\omega t}\\,w_k$$\n    The weights for the nonuniform grid are:\n    $$w_k = \\begin{cases} \\frac{1}{2}(\\omega_1 - \\omega_0)  \\text{if } k=0 \\\\ \\frac{1}{2}(\\omega_{k+1} - \\omega_{k-1})  \\text{if } 1 \\le k \\le N-2 \\\\ \\frac{1}{2}(\\omega_{N-1} - \\omega_{N-2})  \\text{if } k=N-1 \\end{cases}$$\n    This method adapts to the local density of nodes, providing a more flexible quadrature.\n\n3.  **Nonuniform Scheme B (Cubic Spline Interpolation + Gauss–Legendre Quadrature)**\n    This is a more sophisticated, higher-order scheme. First, the known values of the real-valued function $F(\\omega)$ at the nonuniform nodes $\\{\\omega_k\\}$ are used to construct a natural cubic spline, $S(\\omega)$. A natural spline is one where the second derivatives at the endpoints are set to zero, which is a reasonable choice in the absence of other boundary information. This spline provides a smooth, piecewise-cubic approximation of $F(\\omega)$ across the entire interval $[-\\Omega, \\Omega]$.\n    The integral is then computed as:\n    $$\\hat{f}(t) = \\frac{1}{2\\pi}\\sum_{k=0}^{N-2} \\int_{\\omega_k}^{\\omega_{k+1}} S(\\omega)\\,e^{i\\omega t}\\,d\\omega$$\n    Each sub-integral over $[\\omega_k, \\omega_{k+1}]$ is evaluated using $4$-point Gauss–Legendre (GL) quadrature, a high-precision method. We transform the interval $[\\omega_k, \\omega_{k+1}]$ to the standard GL interval $[-1, 1]$ via the linear mapping:\n    $$\\omega(u) = \\frac{\\omega_{k+1} - \\omega_k}{2}u + \\frac{\\omega_{k+1} + \\omega_k}{2}$$\n    The integral over the subinterval becomes:\n    $$\\int_{\\omega_k}^{\\omega_{k+1}} S(\\omega)e^{i\\omega t}d\\omega = \\frac{\\omega_{k+1} - \\omega_k}{2} \\int_{-1}^{1} S(\\omega(u))e^{i\\omega(u)t}du$$\n    This is then approximated using the $4$-point GL formula:\n    $$\\approx \\frac{\\omega_{k+1} - \\omega_k}{2} \\sum_{j=1}^{4} c_j S(\\omega(u_j))e^{i\\omega(u_j)t}$$\n    where $\\{u_j\\}$ and $\\{c_j\\}$ are the standard $4$-point GL nodes and weights on $[-1, 1]$. The total integral is the sum of these contributions over all $N-1$ subintervals. This method is expected to yield high accuracy, particularly if the nonuniform grid is well-chosen for the function $F(\\omega)$.\n\nThe four test cases specified in the problem statement are designed to systematically evaluate these schemes.\n- **Case 1** tests the behavior of all three methods on a simple uniform grid. For Schemes A and B, this serves as a consistency check.\n- **Case 2** uses a `tanh` mapping to cluster frequency nodes near $\\omega=0$. Since the Gaussian $F(\\omega)$ has most of its energy concentrated around the origin, this grid is expected to be highly efficient, leading to low errors for the nonuniform schemes.\n- **Case 3** uses a power-law mapping that skews the grid towards positive $\\omega$. For an even function like our $F(\\omega)$, this asymmetric sampling is suboptimal and is expected to increase the approximation error.\n- **Case 4** repeats the efficient `tanh` mapping but with a much smaller number of points ($N=65$ vs. $N=513$), testing the robustness and convergence properties of the schemes under sparse sampling conditions.\n\nFor each case, we compute the maximum absolute error $E = \\max_{t} |\\hat{f}(t) - f(t)|$ for the uniform baseline, Scheme A, and Scheme B. The implementation will be vectorized for computational efficiency.", "answer": "```python\nimport numpy as np\nfrom scipy.interpolate import CubicSpline\nfrom scipy.special import roots_legendre\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for inverse Fourier transform schemes.\n    \"\"\"\n    # Define problem constants and evaluation grid\n    SIGMA = 0.75\n    T_MIN, T_MAX, M = -6.0, 6.0, 201\n    T_GRID = np.linspace(T_MIN, T_MAX, M)\n\n    # 4-point Gauss-Legendre nodes and weights on [-1, 1]\n    GL_NODES, GL_WEIGHTS = roots_legendre(4)\n\n    # Analytical functions for the signal and its transform\n    def f_true(t, sigma):\n        return np.exp(-t**2 / (2 * sigma**2))\n\n    def F_freq(omega, sigma):\n        return np.sqrt(2 * np.pi) * sigma * np.exp(-(sigma**2 * omega**2) / 2)\n\n    # Grid generation functions\n    def generate_uniform_grid(N, Omega):\n        return np.linspace(-Omega, Omega, N)\n\n    def generate_tanh_grid(N, Omega, a):\n        u = np.linspace(-1.0, 1.0, N)\n        omega = Omega * np.tanh(a * u) / np.tanh(a)\n        # Ensure endpoints are exactly -Omega and Omega\n        omega[0], omega[-1] = -Omega, Omega\n        return np.sort(omega)\n\n    def generate_power_law_grid(N, Omega, p):\n        x = np.linspace(0.0, 1.0, N)\n        omega = Omega * (2 * x**p - 1)\n        # Ensure endpoints are exactly -Omega and Omega\n        omega[0], omega[-1] = -Omega, Omega\n        return np.sort(omega)\n\n    # Inverse transform implementations\n    def inverse_transform_uniform_trapz(omega_grid, t_grid, sigma):\n        N = len(omega_grid)\n        Omega = omega_grid[-1]\n        delta_omega = 2 * Omega / (N - 1)\n        \n        weights = np.full(N, delta_omega)\n        weights[0] = weights[-1] = 0.5 * delta_omega\n        \n        F_vals = F_freq(omega_grid, sigma)\n        integrand_base = F_vals * weights\n        \n        exp_matrix = np.exp(1j * np.outer(t_grid, omega_grid))\n        f_hat = (1 / (2 * np.pi)) * (exp_matrix @ integrand_base)\n        return f_hat\n\n    def inverse_transform_nonuniform_trapz(omega_grid, t_grid, sigma):\n        N = len(omega_grid)\n        \n        weights = np.zeros(N)\n        weights[0] = 0.5 * (omega_grid[1] - omega_grid[0])\n        weights[1:-1] = 0.5 * (omega_grid[2:] - omega_grid[:-2])\n        weights[-1] = 0.5 * (omega_grid[-1] - omega_grid[-2])\n        \n        F_vals = F_freq(omega_grid, sigma)\n        integrand_base = F_vals * weights\n        \n        exp_matrix = np.exp(1j * np.outer(t_grid, omega_grid))\n        f_hat = (1 / (2 * np.pi)) * (exp_matrix @ integrand_base)\n        return f_hat\n\n    def inverse_transform_spline_gl(omega_grid, t_grid, sigma, gl_nodes, gl_weights):\n        N = len(omega_grid)\n        \n        # Build natural cubic spline for F(omega)\n        F_vals = F_freq(omega_grid, sigma)\n        spline = CubicSpline(omega_grid, F_vals, bc_type='natural')\n        \n        # Vectorized calculation\n        num_intervals = N - 1\n        num_gl_points = len(gl_nodes)\n        \n        # Interval properties\n        w_k = omega_grid[:-1]\n        w_kp1 = omega_grid[1:]\n        h = w_kp1 - w_k\n        jac = h / 2.0\n        \n        # Map GL nodes to each interval\n        # Shape: (num_intervals, num_gl_points)\n        omega_gl_mapped = jac[:, np.newaxis] * gl_nodes[np.newaxis, :] + (w_kp1 + w_k)[:, np.newaxis] / 2.0\n        \n        # Evaluate spline at all mapped GL nodes\n        S_at_gl = spline(omega_gl_mapped)\n        \n        # Precompute effective weights for the final sum\n        # Shape: (num_intervals, num_gl_points)\n        W_eff_matrix = jac[:, np.newaxis] * gl_weights[np.newaxis, :] * S_at_gl\n        \n        # Flatten the mapped omega and effective weights\n        omega_eff = omega_gl_mapped.flatten() # Shape: (num_intervals * num_gl_points,)\n        W_eff = W_eff_matrix.flatten()       # Shape: (num_intervals * num_gl_points,)\n        \n        # Perform the final matrix-vector product\n        exp_matrix = np.exp(1j * np.outer(t_grid, omega_eff)) # Shape: (M, num_intervals * num_gl_points)\n        f_hat = (1 / (2 * np.pi)) * (exp_matrix @ W_eff)\n        return f_hat\n\n    # Test suite definition\n    test_cases = [\n        {'N': 513, 'Omega': 14.0, 'grid_type': 'uniform', 'params': {}},\n        {'N': 513, 'Omega': 14.0, 'grid_type': 'tanh', 'params': {'a': 2.0}},\n        {'N': 513, 'Omega': 14.0, 'grid_type': 'power', 'params': {'p': 3.0}},\n        {'N': 65, 'Omega': 14.0, 'grid_type': 'tanh', 'params': {'a': 2.0}},\n    ]\n\n    results = []\n    \n    # Calculate true signal on the evaluation grid\n    f_vals_true = f_true(T_GRID, SIGMA)\n\n    for case in test_cases:\n        N, Omega = case['N'], case['Omega']\n        \n        # 1. Generate grids\n        if case['grid_type'] == 'uniform':\n            nonuniform_grid = generate_uniform_grid(N, Omega)\n        elif case['grid_type'] == 'tanh':\n            nonuniform_grid = generate_tanh_grid(N, Omega, **case['params'])\n        elif case['grid_type'] == 'power':\n            nonuniform_grid = generate_power_law_grid(N, Omega, **case['params'])\n        \n        uniform_grid = generate_uniform_grid(N, Omega)\n\n        # 2. Compute baseline error (uniform grid, uniform rule)\n        f_hat_uni = inverse_transform_uniform_trapz(uniform_grid, T_GRID, SIGMA)\n        err_uniform = np.max(np.abs(f_hat_uni - f_vals_true))\n        \n        # 3. Compute error for Scheme A (nonuniform grid, nonuniform trapz)\n        f_hat_nuni_A = inverse_transform_nonuniform_trapz(nonuniform_grid, T_GRID, SIGMA)\n        err_nonuniform_A = np.max(np.abs(f_hat_nuni_A - f_vals_true))\n        \n        # 4. Compute error for Scheme B (nonuniform grid, spline+GL)\n        f_hat_nuni_B = inverse_transform_spline_gl(nonuniform_grid, T_GRID, SIGMA, GL_NODES, GL_WEIGHTS)\n        err_nonuniform_B = np.max(np.abs(f_hat_nuni_B - f_vals_true))\n        \n        results.extend([err_uniform, err_nonuniform_A, err_nonuniform_B])\n        \n    # Print results in the required format\n    print(f\"[{','.join(f'{x:.6f}' for x in results)}]\")\n\nsolve()\n```", "id": "3112393"}]}