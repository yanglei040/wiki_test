{"hands_on_practices": [{"introduction": "To truly grasp an iterative algorithm like the power method, there is no substitute for performing the calculations by hand. This first exercise guides you through the fundamental steps of the normalized power method. By executing two full iterations, you will develop a concrete intuition for how the vector sequence converges toward the dominant eigenvector and how the corresponding eigenvalue estimate is refined at each step [@problem_id:1396807].", "problem": "Consider the matrix $A$ and the initial vector $v_0$ given by:\n$$\nA = \\begin{pmatrix} 2  3 \\\\ 1  4 \\end{pmatrix}, \\quad v_0 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\nThe normalized power method is an iterative algorithm used to find the dominant eigenvalue and its corresponding eigenvector of a matrix. At each step $k \\ge 0$, given an eigenvector approximation $v_k$, the successive approximations are computed as follows:\n1.  Compute the next unscaled vector: $w_{k+1} = A v_k$.\n2.  Determine the eigenvalue approximation, $\\lambda_{k+1}$, which is defined as the entry of $w_{k+1}$ with the largest absolute value (i.e., the infinity norm of $w_{k+1}$).\n3.  Compute the next eigenvector approximation: $v_{k+1} = \\frac{1}{\\lambda_{k+1}} w_{k+1}$.\n\nStarting with the initial vector $v_0$, perform two full iterations of this method to find the approximations $\\lambda_2$ and $v_2$.\n\nProvide your answer as a row matrix containing the components of the final eigenvector approximation $v_2 = \\begin{pmatrix} x_2 \\\\ y_2 \\end{pmatrix}$ followed by the final eigenvalue approximation $\\lambda_2$, in the order $(x_2, y_2, \\lambda_2)$. Express all values as exact fractions.", "solution": "We apply the normalized power method as specified. Start with $v_{0} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$. Compute\n$$\nw_{1} = A v_{0} = \\begin{pmatrix} 2  3 \\\\ 1  4 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2 \\cdot 1 + 3 \\cdot 0 \\\\ 1 \\cdot 1 + 4 \\cdot 0 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}.\n$$\nThe eigenvalue approximation is the infinity norm,\n$$\n\\lambda_{1} = \\|w_{1}\\|_{\\infty} = \\max\\{ |2|, |1| \\} = 2,\n$$\nand the normalized vector is\n$$\nv_{1} = \\frac{1}{\\lambda_{1}} w_{1} = \\frac{1}{2} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ \\frac{1}{2} \\end{pmatrix}.\n$$\nSecond iteration:\n$$\nw_{2} = A v_{1} = \\begin{pmatrix} 2  3 \\\\ 1  4 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ \\frac{1}{2} \\end{pmatrix} = \\begin{pmatrix} 2 \\cdot 1 + 3 \\cdot \\frac{1}{2} \\\\ 1 \\cdot 1 + 4 \\cdot \\frac{1}{2} \\end{pmatrix} = \\begin{pmatrix} 2 + \\frac{3}{2} \\\\ 1 + 2 \\end{pmatrix} = \\begin{pmatrix} \\frac{7}{2} \\\\ 3 \\end{pmatrix}.\n$$\nThen\n$$\n\\lambda_{2} = \\|w_{2}\\|_{\\infty} = \\max\\left\\{ \\left| \\frac{7}{2} \\right|, |3| \\right\\} = \\frac{7}{2},\n$$\nand\n$$\nv_{2} = \\frac{1}{\\lambda_{2}} w_{2} = \\frac{2}{7} \\begin{pmatrix} \\frac{7}{2} \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ \\frac{6}{7} \\end{pmatrix}.\n$$\nThus $v_{2} = \\begin{pmatrix} 1 \\\\ \\frac{6}{7} \\end{pmatrix}$ and $\\lambda_{2} = \\frac{7}{2}$, so the requested row matrix is $\\begin{pmatrix} 1  \\frac{6}{7}  \\frac{7}{2} \\end{pmatrix}$.", "answer": "$$\\boxed{\\begin{pmatrix}1  \\frac{6}{7}  \\frac{7}{2}\\end{pmatrix}}$$", "id": "1396807"}, {"introduction": "While the power method is remarkably effective, its success is not guaranteed for every starting vector. This practice delves into the theoretical conditions that govern its convergence, exploring a scenario where the method fails to find the dominant eigenvector. By examining the initial vector's components along the matrix's eigenspaces, you will uncover the critical requirement for convergence and gain a deeper appreciation for the algorithm's underlying principles [@problem_id:1396827].", "problem": "The power method is an iterative algorithm used to find the dominant eigenvalue and a corresponding eigenvector of a matrix. For a given matrix $A$ and a non-zero initial vector $v_0$, the method generates a sequence of vectors defined by $v_{k+1} = A v_k$. In practice, to prevent the magnitude of the vectors from growing or shrinking uncontrollably, a normalization step is included in each iteration, typically defining the sequence as $v_{k+1} = \\frac{A v_k}{\\|A v_k\\|}$.\n\nConsider the real symmetric matrix $A = \\begin{pmatrix} 6  -2 \\\\ -2  9 \\end{pmatrix}$. The eigenvalues of this matrix are $\\lambda_1 = 10$ and $\\lambda_2 = 5$. The corresponding eigenvectors are $u_1 = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}$ for $\\lambda_1$, and $u_2 = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$ for $\\lambda_2$.\n\nUnder normal circumstances, for a randomly chosen initial vector $v_0$, the sequence of vectors $\\{v_k\\}$ produced by the normalized power method converges to a unit vector parallel to the dominant eigenvector $u_1$. However, this convergence is not guaranteed for all non-zero initial vectors.\n\nFrom the choices below, select the initial vector $v_0$ for which the normalized power method will **fail** to converge to a vector parallel to the dominant eigenvector $u_1$.\n\nA. $v_0 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$\n\nB. $v_0 = \\begin{pmatrix} 3 \\\\ -1 \\end{pmatrix}$\n\nC. $v_0 = \\begin{pmatrix} -4 \\\\ -2 \\end{pmatrix}$\n\nD. $v_0 = \\begin{pmatrix} 1 \\\\ -2.1 \\end{pmatrix}$\n\nE. $v_0 = \\begin{pmatrix} 3 \\\\ -6 \\end{pmatrix}$", "solution": "Let $A$ be diagonalizable with eigenpairs $(\\lambda_{1},u_{1})$ and $(\\lambda_{2},u_{2})$, where $\\lambda_{1}  \\lambda_{2}$. For any nonzero initial vector $v_{0}$, write the spectral decomposition\n$$\nv_{0} = c_{1} u_{1} + c_{2} u_{2}.\n$$\nAfter $k$ iterations without normalization,\n$$\nv_{k} = A^{k} v_{0} = c_{1} \\lambda_{1}^{k} u_{1} + c_{2} \\lambda_{2}^{k} u_{2}.\n$$\nIn the normalized power method, the direction of $v_{k}$ is that of $v_{k}/\\|v_{k}\\|$. If $c_{1} \\neq 0$, then since $\\left|\\frac{\\lambda_{2}}{\\lambda_{1}}\\right|  1$, the term $c_{1}\\lambda_{1}^{k}u_{1}$ dominates, and the sequence converges to a unit vector parallel to $u_{1}$. If $c_{1} = 0$, then $v_{0}$ lies entirely in the eigenspace of $\\lambda_{2}$, so $A^{k} v_{0} \\parallel u_{2}$ for all $k$, and the normalized sequence does not converge to a vector parallel to $u_{1}$.\n\nFor the given symmetric $A$, the eigenvectors $u_{1} = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}$ and $u_{2} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$ are orthogonal. Thus $c_{1} = 0$ if and only if $v_{0} \\cdot u_{1} = 0$, equivalently $v_{0}$ is a scalar multiple of $u_{2}$.\n\nCheck each option by computing $v_{0} \\cdot u_{1}$:\n- $A$: $\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\cdot \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} = 1 - 2 = -1 \\neq 0$.\n- $B$: $\\begin{pmatrix} 3 \\\\ -1 \\end{pmatrix} \\cdot \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} = 3 + 2 = 5 \\neq 0$.\n- $C$: $\\begin{pmatrix} -4 \\\\ -2 \\end{pmatrix} \\cdot \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} = -4 + 4 = 0$, and indeed $\\begin{pmatrix} -4 \\\\ -2 \\end{pmatrix} = -2 \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$ is a multiple of $u_{2}$.\n- $D$: $\\begin{pmatrix} 1 \\\\ -2.1 \\end{pmatrix} \\cdot \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} = 1 + 4.2 = 5.2 \\neq 0$.\n- $E$: $\\begin{pmatrix} 3 \\\\ -6 \\end{pmatrix} \\cdot \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} = 3 + 12 = 15 \\neq 0$, and it is parallel to $u_{1}$.\n\nTherefore, the normalized power method fails to converge to a vector parallel to $u_{1}$ only for option $C$.", "answer": "$$\\boxed{C}$$", "id": "1396827"}, {"introduction": "The standard power method is designed to find only one eigenvalue: the one with the largest absolute value. This exercise introduces a powerful extension, the shifted power method, which allows us to find other eigenvalues of a matrix. You will determine the appropriate spectral shift, $\\sigma$, to apply to a matrix $A$ to form a new matrix $B = A - \\sigma I$, such that a desired eigenvalue of $A$ becomes the dominant eigenvalue of $B$, making it accessible to the power method [@problem_id:1396815].", "problem": "The power iteration method is an algorithm used to find the dominant eigenvalue and its corresponding eigenvector of a matrix. For a matrix $M$ with a unique real eigenvalue $\\lambda_{\\text{dom}}$ such that $|\\lambda_{\\text{dom}}|  |\\lambda_i|$ for all other eigenvalues $\\lambda_i$, the sequence of vectors generated by $\\mathbf{x}_{k+1} = \\frac{M\\mathbf{x}_k}{\\|M\\mathbf{x}_k\\|}$ (starting from a suitable initial vector $\\mathbf{x}_0$) will converge to an eigenvector associated with $\\lambda_{\\text{dom}}$.\n\nConsider a $3 \\times 3$ real matrix $A$ which is diagonalizable and has eigenvalues $\\{-5, 1, 4\\}$. We define a new matrix $B$ by applying a real-valued shift $\\sigma$ to $A$, such that $B = A - \\sigma I$, where $I$ is the $3 \\times 3$ identity matrix.\n\nWe wish to use the power iteration method on the matrix $B$ to determine the eigenvector of $A$ that corresponds to the eigenvalue $-5$. This requires that the new eigenvalue of $B$ related to the eigenvalue $-5$ of $A$ becomes the unique dominant eigenvalue of $B$.\n\nWhich of the following options correctly describes the set of all possible values for the shift $\\sigma$ that guarantees this convergence?\n\nA. $\\sigma \\in (-2, \\infty)$\n\nB. $\\sigma \\in (-\\infty, -2)$\n\nC. $\\sigma \\in (-2, -0.5)$\n\nD. $\\sigma \\in (-\\infty, -0.5)$\n\nE. $\\sigma \\in (-0.5, \\infty)$", "solution": "Let the eigenvalues of $A$ be $\\{-5, 1, 4\\}$. For $B = A - \\sigma I$, the eigenvalues are\n$$\n\\mu_{1} = -5 - \\sigma,\\quad \\mu_{2} = 1 - \\sigma,\\quad \\mu_{3} = 4 - \\sigma.\n$$\nTo make the eigenvector of $A$ corresponding to $-5$ the limit of the power iteration on $B$, the associated eigenvalue $\\mu_{1}$ must be the unique dominant eigenvalue in magnitude:\n$$\n|\\mu_{1}|  |\\mu_{2}| \\quad \\text{and} \\quad |\\mu_{1}|  |\\mu_{3}|.\n$$\nEquivalently,\n$$\n|-5 - \\sigma|  |1 - \\sigma| \\quad \\text{and} \\quad |-5 - \\sigma|  |4 - \\sigma|.\n$$\nRewrite as distances from $\\sigma$:\n$$\n|\\sigma + 5|  |\\sigma - 1|, \\quad |\\sigma + 5|  |\\sigma - 4|.\n$$\nSolve each inequality by squaring both sides (which preserves strict inequality for nonnegative quantities):\n$$\n(\\sigma + 5)^{2}  (\\sigma - 1)^{2} \\;\\Longrightarrow\\; \\sigma^{2} + 10\\sigma + 25  \\sigma^{2} - 2\\sigma + 1 \\;\\Longrightarrow\\; 12\\sigma  -24 \\;\\Longrightarrow\\; \\sigma  -2,\n$$\n$$\n(\\sigma + 5)^{2}  (\\sigma - 4)^{2} \\;\\Longrightarrow\\; \\sigma^{2} + 10\\sigma + 25  \\sigma^{2} - 8\\sigma + 16 \\;\\Longrightarrow\\; 18\\sigma  -9 \\;\\Longrightarrow\\; \\sigma  -\\frac{1}{2}.\n$$\nBoth conditions must hold simultaneously, so\n$$\n\\sigma  -\\frac{1}{2}.\n$$\nStrict inequalities ensure uniqueness of the dominant magnitude (excluding the tie points $\\sigma = -2$ and $\\sigma = -\\frac{1}{2}$). Therefore, the set of all shifts guaranteeing convergence to the eigenvector of $A$ for eigenvalue $-5$ is $\\sigma \\in \\left(-\\frac{1}{2}, \\infty\\right)$, which corresponds to option E.", "answer": "$$\\boxed{E}$$", "id": "1396815"}]}