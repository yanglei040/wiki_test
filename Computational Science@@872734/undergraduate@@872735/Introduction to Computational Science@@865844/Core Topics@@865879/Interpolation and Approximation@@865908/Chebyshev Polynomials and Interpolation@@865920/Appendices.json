{"hands_on_practices": [{"introduction": "To apply Chebyshev interpolation, we must first identify the optimal points at which to sample a function. This practice guides you through the fundamental process of calculating these Chebyshev nodes, which are the roots of Chebyshev polynomials. By mastering this calculation [@problem_id:2187308], you build a concrete understanding of why these points are special and how they are derived directly from the polynomial's definition.", "problem": "In the field of numerical approximation, choosing the points at which to evaluate a function for polynomial interpolation is crucial for minimizing error. For a function defined on the interval $[-1, 1]$, the set of points that minimizes the maximum possible interpolation error are known as the Chebyshev nodes. For interpolation using a polynomial of degree at most $n$, the $n+1$ Chebyshev nodes are the roots of the Chebyshev polynomial of the first kind of degree $n+1$, denoted $T_{n+1}(x)$.\n\nThe Chebyshev polynomials are defined by the relation $T_k(x) = \\cos(k \\arccos(x))$ for an integer $k \\ge 0$.\n\nDetermine the set of nodes required for an optimal polynomial interpolation of degree at most $3$. This corresponds to finding the roots of $T_4(x)$. Find the exact values of these four nodes. List the nodes in ascending order.", "solution": "We seek the optimal interpolation nodes on $[-1,1]$ for a polynomial of degree at most $3$. By the Chebyshev criterion, these are the $4$ roots of $T_{4}(x)$, where $T_{k}(x)$ is defined by $T_{k}(x)=\\cos(k\\arccos(x))$.\n\nLet $x=\\cos\\theta$ with $\\theta=\\arccos(x)$. Then\n$$\nT_{4}(x)=\\cos(4\\theta).\n$$\nThe roots of $T_{4}(x)$ occur when\n$$\n\\cos(4\\theta)=0.\n$$\nThe general solutions in $\\theta\\in[0,\\pi]$ are\n$$\n4\\theta=\\frac{(2m-1)\\pi}{2},\\quad m=1,2,3,4,\n$$\nso\n$$\n\\theta_{m}=\\frac{(2m-1)\\pi}{8},\\quad m=1,2,3,4.\n$$\nTherefore the nodes are\n$$\nx_{m}=\\cos\\left(\\frac{(2m-1)\\pi}{8}\\right),\\quad m=1,2,3,4,\n$$\nnamely\n$$\n\\cos\\left(\\frac{\\pi}{8}\\right),\\ \\cos\\left(\\frac{3\\pi}{8}\\right),\\ \\cos\\left(\\frac{5\\pi}{8}\\right),\\ \\cos\\left(\\frac{7\\pi}{8}\\right).\n$$\nUsing the identities $\\cos\\left(\\frac{5\\pi}{8}\\right)=-\\cos\\left(\\frac{3\\pi}{8}\\right)$ and $\\cos\\left(\\frac{7\\pi}{8}\\right)=-\\cos\\left(\\frac{\\pi}{8}\\right)$, and the half-angle values\n$$\n\\cos\\left(\\frac{\\pi}{8}\\right)=\\frac{1}{2}\\sqrt{2+\\sqrt{2}},\\quad \\cos\\left(\\frac{3\\pi}{8}\\right)=\\frac{1}{2}\\sqrt{2-\\sqrt{2}},\n$$\nthe four nodes in ascending order are\n$$\n-\\frac{1}{2}\\sqrt{2+\\sqrt{2}},\\ -\\frac{1}{2}\\sqrt{2-\\sqrt{2}},\\ \\frac{1}{2}\\sqrt{2-\\sqrt{2}},\\ \\frac{1}{2}\\sqrt{2+\\sqrt{2}}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}-\\frac{1}{2}\\sqrt{2+\\sqrt{2}}  -\\frac{1}{2}\\sqrt{2-\\sqrt{2}}  \\frac{1}{2}\\sqrt{2-\\sqrt{2}}  \\frac{1}{2}\\sqrt{2+\\sqrt{2}}\\end{pmatrix}}$$", "id": "2187308"}, {"introduction": "With the ability to find Chebyshev nodes, the next step is to use them for their intended purpose: function approximation. This exercise provides a hands-on example of interpolating a simple function, $f(x) = x^3$, using a lower-degree polynomial [@problem_id:2187288]. This will demonstrate the power and precision of Chebyshev interpolation and serve as a bridge from node calculation to practical application.", "problem": "In numerical analysis, interpolation using Chebyshev nodes is a superior alternative to using equally spaced points, especially for avoiding Runge's phenomenon. This method chooses interpolation points that are the roots of Chebyshev polynomials, which are clustered near the endpoints of the interval.\n\nConsider the function $f(x) = x^3$ over the interval $[-1, 1]$. Your task is to find the unique polynomial of degree at most 2, let's call it $P_2(x)$, that interpolates $f(x)$ at the three Chebyshev nodes on this interval. These nodes are defined as the roots of the degree-3 Chebyshev polynomial of the first kind, $T_3(x)$.\n\nExpress your answer for $P_2(x)$ as a simplified polynomial in terms of $x$.", "solution": "We are given $f(x)=x^{3}$ on $[-1,1]$ and must find the unique polynomial $P_{2}(x)$ of degree at most $2$ that interpolates $f(x)$ at the three Chebyshev nodes on this interval, defined as the roots of $T_{3}(x)$, the degree-$3$ Chebyshev polynomial of the first kind.\n\nUse the identity $T_{3}(x)=\\cos(3\\arccos x)=4x^{3}-3x$. The roots of $T_{3}(x)$ are the three Chebyshev nodes:\n$$\nT_{3}(x)=4x^{3}-3x=x(4x^{2}-3)=0\n\\quad\\Longrightarrow\\quad\nx\\in\\left\\{0,\\;\\pm\\frac{\\sqrt{3}}{2}\\right\\}.\n$$\nLet $P_{2}(x)=A x^{2}+B x+C$. The interpolation conditions are $P_{2}(\\xi)=\\xi^{3}$ at each node $\\xi\\in\\left\\{0,\\pm\\frac{\\sqrt{3}}{2}\\right\\}$.\n\n1) At $x=0$:\n$$\nP_{2}(0)=C=0 \\quad\\Longrightarrow\\quad C=0.\n$$\n\n2) Let $a=\\frac{\\sqrt{3}}{2}$. At $x=a$ and $x=-a$:\n$$\nP_{2}(a)=A a^{2}+B a=a^{3},\\qquad P_{2}(-a)=A a^{2}-B a=-a^{3}.\n$$\nAdding these two equations eliminates $B$:\n$$\n(A a^{2}+B a)+(A a^{2}-B a)=a^{3}+(-a^{3})\n\\;\\Longrightarrow\\;\n2A a^{2}=0\n\\;\\Longrightarrow\\;\nA=0\n\\quad(\\text{since }a\\neq 0).\n$$\nSubstitute $A=0$ into $A a^{2}+B a=a^{3}$ to solve for $B$:\n$$\nB a=a^{3}\\;\\Longrightarrow\\;B=a^{2}.\n$$\nWith $a=\\frac{\\sqrt{3}}{2}$, we have\n$$\na^{2}=\\left(\\frac{\\sqrt{3}}{2}\\right)^{2}=\\frac{3}{4}.\n$$\nTherefore,\n$$\nP_{2}(x)=B x=\\frac{3}{4}\\,x.\n$$\nA quick check: $P_{2}(0)=0=f(0)$, and $P_{2}(\\pm a)=\\frac{3}{4}(\\pm a)=\\pm a\\cdot\\frac{3}{4}=\\pm a^{3}=f(\\pm a)$, so the interpolation conditions are satisfied at all three Chebyshev nodes.\n\nHence, the unique interpolating polynomial of degree at most $2$ is $P_{2}(x)=\\frac{3}{4}x$.", "answer": "$$\\boxed{\\frac{3}{4}x}$$", "id": "2187288"}, {"introduction": "In many real-world scenarios, functions are represented not by a single interpolant but as a longer Chebyshev series, which can be thought of as a 'Chebyshev-Fourier' series. This advanced practice challenges you to implement and analyze Clenshaw's algorithm, the standard, highly efficient method for evaluating such series [@problem_id:3105806]. Completing this exercise will equip you with a core computational technique used widely in numerical libraries and scientific computing.", "problem": "You are asked to construct a complete, runnable program that evaluates Chebyshev series accurately and efficiently, and then analyzes theoretical performance characteristics. Work entirely in purely mathematical terms. All angles must be in radians. Your program must implement a vectorized evaluator based on a stable backward recurrence derived from the defining recurrence for Chebyshev polynomials, and also a naive evaluator that uses the cosine identity. You must quantify correctness against a trusted reference and compute theoretical operation and call counts, along with idealized Single Instruction Multiple Data (SIMD) speedups under a simple model. Your final output must be a single line containing the aggregated results of all test cases, printed as a single bracketed list with no spaces.\n\nBackground and base definitions\n- The Chebyshev polynomials of the first kind, denoted by $T_k(x)$, are defined by the recurrence\n  $$\n  T_0(x) = 1,\\quad T_1(x) = x,\\quad T_{k+1}(x) = 2x\\,T_k(x) - T_{k-1}(x)\\quad\\text{for } k \\ge 1.\n  $$\n- Equivalently, for $x \\in [-1,1]$ and $\\theta = \\arccos(x)$ (in radians), they satisfy the identity\n  $$\n  T_k(x) = \\cos(k\\,\\theta).\n  $$\n- A Chebyshev series of degree $n$ is\n  $$\n  S(x) = \\sum_{k=0}^{n} c_k\\,T_k(x).\n  $$\n\nTasks\n1) Starting only from the recurrence for $T_k(x)$ and the series definition, derive a stable backward recurrence to evaluate $S(x)$ at many points $x$ concurrently and implement it in a vectorized way that operates on entire arrays without looping over the evaluation points in Python. The vectorized algorithm must be based on a backward recurrence that accumulates two previous states, and must not perform any explicit Python-level loops over the evaluation points.\n\n2) Implement a naive evaluator using the cosine identity $T_k(x) = \\cos(k\\,\\arccos(x))$ in radians. This method should directly construct $S(x)$ by summing $c_k \\cos(k\\,\\arccos(x))$ for $k = 0,\\dots,n$.\n\n3) For each test case below, compute both evaluators and also a trusted reference using a robust Chebyshev series evaluator. Report the maximum absolute error between each method and the reference.\n\n4) For each test case, compute the following theoretical complexity and performance quantities:\n   - The number of inverse cosine evaluations in the naive method, equal to the number of evaluation points $m$.\n   - The number of cosine evaluations in the naive method, equal to $(n+1)\\,m$.\n   - The floating-point operation count (treating each addition and multiplication as one floating-point operation) for the vectorized backward-recurrence method, under the following model:\n     - Precompute $\\alpha = 2x$ once at cost $m$ multiplications.\n     - For each $k$ from $n$ down to $1$, compute $b_k = \\alpha\\,b_{k+1} - b_{k+2} + c_k$ with $m$ multiplications and $2m$ additions.\n     - Combine the result as $S(x) = c_0 + x\\,b_1 - b_2$ with $m$ multiplications and $2m$ additions.\n     - The total thus equals $(3n+3)\\,m$ floating-point operations.\n   - The idealized SIMD (Single Instruction Multiple Data) speedups for widths $W=4$ and $W=8$, defined as the ideal throughput multiple $\\min\\{m, W\\}$ relative to a scalar lane under perfect vectorization and no stalls.\n\n5) Output specification: For each test case, output a list with the following seven entries in this exact order:\n   - Maximum absolute error of the vectorized backward-recurrence method relative to the reference, as a float rounded to twelve significant digits.\n   - Maximum absolute error of the naive cosine method relative to the reference, as a float rounded to twelve significant digits.\n   - The number of $\\arccos$ calls in the naive method, as an integer.\n   - The number of $\\cos$ calls in the naive method, as an integer.\n   - The total floating-point operation count for the vectorized backward-recurrence method, as an integer.\n   - The idealized SIMD speedup for $W=4$, as an integer.\n   - The idealized SIMD speedup for $W=8$, as an integer.\n   Aggregate the three test-case lists into a single list, and print exactly one line containing this aggregate, formatted as a single bracketed list with no spaces, for example: `[[...],[...],[...]]`.\n\nTest suite\nUse the following three independent test cases. All angles are in radians. All $x$ lie in $[-1,1]$.\n\n- Test case $1$ (boundary, constant series):\n  - Degree $n = 0$.\n  - Coefficients $c = [2.5]$.\n  - Evaluation points $x = [-1.0,\\,-0.5,\\,0.0,\\,0.5,\\,1.0]$.\n- Test case $2$ (moderate degree and grid):\n  - Degree $n = 5$.\n  - Coefficients $c = [0.5,\\,-1.0,\\,0.75,\\,-0.25,\\,0.125,\\,-0.0625]$.\n  - Evaluation points $x = [-1.0,\\,-0.75,\\,-0.5,\\,-0.25,\\,0.0,\\,0.25,\\,0.5,\\,0.75,\\,1.0]$.\n- Test case $3$ (stress, high degree and dense grid):\n  - Degree $n = 200$.\n  - Coefficients defined by $c_k = \\dfrac{(-1)^k}{(k+1)^2}$ for $k = 0,\\dots,200$.\n  - Evaluation points are $m = 2001$ equispaced points in $[-1,1]$, inclusive.\n\nFinal output format and type requirements\n- Your program must produce a single line of output containing the results as a comma-separated list of the three per-test-case lists, enclosed in a single pair of square brackets, with no spaces.\n- The entries must be of types float or integer exactly as specified above.\n- Each float must be rounded to twelve significant digits before printing.", "solution": "### 1. Derivation of the Vectorized Backward Recurrence (Clenshaw's Algorithm Variant)\n\nThe objective is to evaluate the Chebyshev series $S(x) = \\sum_{k=0}^{n} c_k T_k(x)$ efficiently. The evaluation is split into the constant term $c_0 T_0(x) = c_0$ and the sum over higher-order terms. Let $S_{1..n}(x) = \\sum_{k=1}^{n} c_k T_k(x)$, so that $S(x) = c_0 + S_{1..n}(x)$.\n\nWe use a backward recurrence relation, a technique known as Clenshaw's algorithm. Let us define an auxiliary sequence $b_k$ for $k=n, n-1, \\dots, 1$, governed by the recurrence:\n$$\nb_k = c_k + 2x\\,b_{k+1} - b_{k+2}\n$$\nwith the initial conditions $b_{n+1} = 0$ and $b_{n+2} = 0$. This can be rearranged to express the coefficients $c_k$ as:\n$$\nc_k = b_k - 2x\\,b_{k+1} + b_{k+2}\n$$\nSubstituting this expression for $c_k$ into the sum $S_{1..n}(x)$:\n$$\nS_{1..n}(x) = \\sum_{k=1}^{n} \\left(b_k - 2x\\,b_{k+1} + b_{k+2}\\right) T_k(x)\n$$\nWe can split this into three separate sums:\n$$\nS_{1..n}(x) = \\sum_{k=1}^{n} b_k T_k(x) - \\sum_{k=1}^{n} 2x\\,b_{k+1} T_k(x) + \\sum_{k=1}^{n} b_{k+2} T_k(x)\n$$\nUsing the identity $T_{j}(x) = 2x\\,T_{j-1}(x) - T_{j-2}(x)$, we find that the coefficient multiplying each $b_j$ for $j \\in \\{3, \\dots, n\\}$ is $T_j(x) - 2x\\,T_{j-1}(x) + T_{j-2}(x) = 0$. The sum therefore telescopes, leaving only the boundary terms.\n\nThe non-canceling terms are those involving $b_1, b_2, b_{n+1}, b_{n+2}$. Given the initial conditions $b_{n+1} = 0$ and $b_{n+2} = 0$, all terms involving these two coefficients vanish. The sum simplifies to the terms involving $b_1$ and $b_2$:\n$$\nS_{1..n}(x) = b_1 T_1(x) + (b_2 T_2(x) - 2x\\,b_2 T_1(x))\n$$\nUsing $T_1(x) = x$ and $T_2(x) = 2x^2 - 1$:\n$$\nS_{1..n}(x) = b_1 x + b_2 (2x^2 - 1) - 2x\\,b_2 x = b_1 x + 2x^2 b_2 - b_2 - 2x^2 b_2 = x\\,b_1 - b_2\n$$\nFinally, the full series sum is:\n$$\nS(x) = c_0 + S_{1..n}(x) = c_0 + x\\,b_1 - b_2\n$$\nThis confirms the algorithm specified in the problem statement. For vectorization, the evaluation points $x$ are treated as an array. The auxiliary states $b_k$ are also arrays of the same size, and the recurrence is applied using element-wise array operations in NumPy.\n\n### 2. Implementation and Analysis\n\nThe problem is solved using a Python program that implements the derived recurrence, the naive cosine-based method, and the specified complexity analysis.\n\n```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Chebyshev series evaluation problem by implementing and\n    analyzing two methods: a vectorized backward recurrence and a naive\n    cosine identity sum.\n    \"\"\"\n\n    def process_case(c, x):\n        \"\"\"\n        Processes a single test case: evaluates the series, calculates errors,\n        and computes theoretical complexity metrics.\n        \"\"\"\n        n = len(c) - 1 if len(c)  0 else -1\n        m = len(x)\n\n        if m == 0:\n            return [0.0, 0.0, 0, 0, 0, 0, 0]\n\n        # 1. Vectorized backward recurrence method\n        if n  0:\n            y_recurrence = np.zeros_like(x)\n        elif n == 0:\n            y_recurrence = np.full_like(x, c[0])\n        else:\n            alpha = 2.0 * x\n            b1 = np.zeros_like(x)\n            b2 = np.zeros_like(x)\n            for k in range(n, 0, -1):\n                b0 = c[k] + alpha * b1 - b2\n                b2 = b1\n                b1 = b0\n            y_recurrence = c[0] + x * b1 - b2\n\n        # 2. Naive evaluator using cosine identity\n        if n  0:\n            y_naive = np.zeros_like(x)\n        else:\n            with np.errstate(invalid='ignore'): # arccos(-1) or arccos(1) can be inexact\n                theta = np.arccos(x)\n            k_vals = np.arange(n + 1).reshape(-1, 1)\n            c_col = c.reshape(-1, 1)\n            T_matrix = np.cos(k_vals * theta)\n            y_naive = np.sum(c_col * T_matrix, axis=0)\n\n        # 3. Reference solution and error calculation\n        y_ref = np.polynomial.chebyshev.chebval(x, c)\n        err_recurrence = np.max(np.abs(y_recurrence - y_ref))\n        err_naive = np.max(np.abs(y_naive - y_ref))\n\n        # 4. Theoretical complexity and performance quantities\n        arccos_calls = m\n        if n  0:\n            cos_calls = 0\n            flops_recurrence = 0\n        else:\n            cos_calls = (n + 1) * m\n            flops_recurrence = (3 * n + 3) * m\n\n        simd_4 = min(m, 4)\n        simd_8 = min(m, 8)\n\n        # 5. Assemble results list\n        return [\n            err_recurrence,\n            err_naive,\n            int(arccos_calls),\n            int(cos_calls),\n            int(flops_recurrence),\n            int(simd_4),\n            int(simd_8)\n        ]\n\n    # --- Test Cases ---\n    c1 = np.array([2.5])\n    x1 = np.array([-1.0, -0.5, 0.0, 0.5, 1.0])\n    res1 = process_case(c1, x1)\n\n    c2 = np.array([0.5, -1.0, 0.75, -0.25, 0.125, -0.0625])\n    x2 = np.array([-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0])\n    res2 = process_case(c2, x2)\n\n    n3 = 200\n    k3 = np.arange(n3 + 1)\n    c3 = ((-1.0)**k3) / ((k3 + 1.0)**2)\n    m3 = 2001\n    x3 = np.linspace(-1.0, 1.0, m3)\n    res3 = process_case(c3, x3)\n\n    all_results = [res1, res2, res3]\n\n    def format_list_item(item):\n        if isinstance(item, float):\n            return f\"{item:.12g}\"\n        return str(item)\n\n    result_strings = []\n    for res_list in all_results:\n        formatted_items = [format_list_item(item) for item in res_list]\n        result_strings.append(f\"[{','.join(formatted_items)}]\")\n\n    print(f\"[{','.join(result_strings)}]\")\n\n# solve() # This function would be called in the execution environment\n```\nThe above code implements the required evaluators and analysis. Executing this program with the specified test cases produces the final aggregated list of results.", "answer": "$$\\boxed{[[0.0,0.0,5,5,15,4,5],[2.22044604925e-16,4.99600361081e-16,9,54,162,4,8],[1.33226762955e-15,1.75838501009e-12,2001,402201,1206603,4,8]]}$$", "id": "3105806"}]}