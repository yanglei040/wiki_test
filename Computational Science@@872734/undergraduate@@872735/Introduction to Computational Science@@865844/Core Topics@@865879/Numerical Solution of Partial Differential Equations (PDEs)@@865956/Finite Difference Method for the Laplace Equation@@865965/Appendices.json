{"hands_on_practices": [{"introduction": "This first practice is designed to give you a concrete feel for the iterative nature of solving the discretized Laplace equation. You will apply the Jacobi method, one of the simplest iterative techniques, for a single step. By manually calculating the updated potential values, you'll see firsthand how the \"averaging\" property of the Laplace equation works at the discrete level, where each point's new value is determined by its neighbors from the previous iteration. [@problem_id:2172039]", "problem": "Consider the problem of determining the electrostatic potential $u(x,y)$ inside a square, charge-free region. The potential satisfies the two-dimensional Laplace equation:\n$$\n\\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} = 0\n$$\nThe domain is discretized into a uniform grid of points $(x_i, y_j)$, where $x_i = i \\cdot h$ and $y_j = j \\cdot h$ for $i,j \\in \\{0, 1, 2, 3\\}$. The grid spacing $h$ is constant. This grid results in four interior points: $(x_1, y_1)$, $(x_1, y_2)$, $(x_2, y_1)$, and $(x_2, y_2)$. Let the potential at these grid points be denoted by $u_{ij} = u(x_i, y_j)$.\n\nThe potential on the boundary is fixed. The values at the boundary points adjacent to the interior grid points are given as follows:\n- On the left boundary: $u_{0,1} = 21.0$ V and $u_{0,2} = 21.0$ V.\n- On the right boundary: $u_{3,1} = 41.0$ V and $u_{3,2} = 41.0$ V.\n- On the bottom boundary: $u_{1,0} = 9.0$ V and $u_{2,0} = 9.0$ V.\n- On the top boundary: $u_{1,3} = 81.0$ V and $u_{2,3} = 81.0$ V.\n\nThe Laplace equation is approximated using the standard five-point stencil finite difference formula, which relates the potential at an interior point to its four nearest neighbors. The Jacobi method is used to solve the resulting system of linear equations.\n\nStarting with an initial guess of $u_{ij}^{(0)} = 0$ V for all four interior points (where $i,j \\in \\{1,2\\}$), calculate the numerical values of the potential at these points after one complete iteration of the Jacobi method.\n\nProvide the updated potential values for $u_{11}, u_{12}, u_{21}, u_{22}$ in this specific order. The final answer should be a set of four numbers. Do not include units in your final answer.", "solution": "The two-dimensional Laplace equation discretized with the standard five-point stencil on a uniform grid gives, for an interior node $(i,j)$,\n$$\n\\frac{u_{i+1,j}-2u_{i,j}+u_{i-1,j}}{h^{2}}+\\frac{u_{i,j+1}-2u_{i,j}+u_{i,j-1}}{h^{2}}=0,\n$$\nwhich simplifies to the averaging relation\n$$\nu_{i,j}=\\frac{1}{4}\\left(u_{i+1,j}+u_{i-1,j}+u_{i,j+1}+u_{i,j-1}\\right).\n$$\nThe Jacobi iteration updates each interior point using neighbors from the previous iterate:\n$$\nu_{i,j}^{(k+1)}=\\frac{1}{4}\\left(u_{i+1,j}^{(k)}+u_{i-1,j}^{(k)}+u_{i,j+1}^{(k)}+u_{i,j-1}^{(k)}\\right),\n$$\nwith boundary values held fixed. With the initial guess $u_{ij}^{(0)}=0$ for $i,j\\in\\{1,2\\}$ and the given boundary data, the first-iteration updates are:\n\nFor $u_{11}$:\n$$\nu_{11}^{(1)}=\\frac{1}{4}\\left(u_{21}^{(0)}+u_{01}+u_{12}^{(0)}+u_{10}\\right)=\\frac{1}{4}\\left(0+21+0+9\\right)=7.5.\n$$\n\nFor $u_{12}$:\n$$\nu_{12}^{(1)}=\\frac{1}{4}\\left(u_{22}^{(0)}+u_{02}+u_{13}+u_{11}^{(0)}\\right)=\\frac{1}{4}\\left(0+21+81+0\\right)=25.5.\n$$\n\nFor $u_{21}$:\n$$\nu_{21}^{(1)}=\\frac{1}{4}\\left(u_{31}+u_{11}^{(0)}+u_{22}^{(0)}+u_{20}\\right)=\\frac{1}{4}\\left(41+0+0+9\\right)=12.5.\n$$\n\nFor $u_{22}$:\n$$\nu_{22}^{(1)}=\\frac{1}{4}\\left(u_{32}+u_{12}^{(0)}+u_{23}+u_{21}^{(0)}\\right)=\\frac{1}{4}\\left(41+0+81+0\\right)=30.5.\n$$\n\nThus, after one Jacobi iteration starting from zero, the updated potentials in the order $(u_{11},u_{12},u_{21},u_{22})$ are $(7.5,25.5,12.5,30.5)$.", "answer": "$$\\boxed{\\begin{pmatrix} 7.5  25.5  12.5  30.5 \\end{pmatrix}}$$", "id": "2172039"}, {"introduction": "Moving beyond the basic setup, this exercise challenges you to diagnose a common failure in numerical simulations. While Dirichlet boundary conditions uniquely determine a solution, imposing Neumann (derivative) conditions on all boundaries introduces profound issues of solution uniqueness and existence. This problem simulates a realistic scenario where a solver fails, requiring you to apply theoretical principles to identify the missing compatibility condition and propose valid remedies. [@problem_id:3128839]", "problem": "A team is implementing the Finite Difference Method (FDM) for the Laplace equation on the square domain $\\Omega = [0,1]\\times[0,1]$. They discretize $\\nabla^2 u = 0$ on a uniform Cartesian grid with spacing $h$ using the standard $5$-point stencil in the interior and enforce Neumann boundary conditions $\\frac{\\partial u}{\\partial n} = g$ on all sides by second-order accurate one-sided differences with ghost points. The resulting linear system has the form $A u = b$, where $A$ is assembled from the discrete Laplacian and $b$ encodes the boundary flux data $g$ via the Neumann enforcement.\n\nWhen they run their iterative solver on a case with nontrivial boundary flux $g$ prescribed on $\\partial\\Omega$, the solver reports that the coefficient matrix is singular or the residual stagnates without converging. The task is to diagnose why the solver fails under all-Neumann boundary conditions and to identify missing compatibility requirements and propose minimal fixes that preserve the original governing equation and physical model.\n\nWhich of the following statements correctly diagnose the failure and propose acceptable remedies? Select all that apply.\n\nA. The linear system constructed from the $5$-point Laplacian with pure Neumann boundary conditions is singular because constant vectors lie in its nullspace; uniqueness requires fixing the additive constant.\n\nB. The failure is due to the grid spacing $h$ being too large; simply refining the mesh will remove the singularity and guarantee convergence.\n\nC. A necessary compatibility condition for solvability is that the net prescribed normal flux across $\\partial\\Omega$ integrates to zero; if the boundary data violate this, no solution exists.\n\nD. A minimal fix that preserves the governing equation is to enforce a single linear constraint, such as $\\int_{\\Omega} u \\,\\mathrm{d}\\Omega = 0$ or by pinning one node value, thereby rendering $A$ nonsingular.\n\nE. Adding a small reaction term and solving $\\nabla^2 u - \\varepsilon u = 0$ with $\\varepsilon  0$ will both ensure uniqueness and maintain the original physical model unchanged; this is an acceptable fix.\n\nF. If boundary data violate solvability, one can project them onto the compatible subspace by subtracting their mean flux so that the discrete net flux is zero; this yields a solvable problem for the original Laplace equation.", "solution": "The problem statement is evaluated for validity.\n\n**Step 1: Extract Givens**\n- Governing Equation: Laplace equation, $\\nabla^2 u = 0$.\n- Domain: Square domain, $\\Omega = [0,1]\\times[0,1]$.\n- Discretization: Finite Difference Method (FDM) on a uniform Cartesian grid with spacing $h$.\n- Interior Stencil: Standard $5$-point stencil.\n- Boundary Conditions: Neumann boundary conditions, $\\frac{\\partial u}{\\partial n} = g$, on all sides $\\partial\\Omega$.\n- Boundary Implementation: Second-order accurate one-sided differences with ghost points.\n- Linear System: $A u = b$, where $A$ is from the discrete Laplacian and $b$ from the boundary flux $g$.\n- Observation: Iterative solver fails (singular matrix or residual stagnation) for nontrivial flux $g$.\n- Objective: Diagnose the failure, identify compatibility requirements, and propose minimal fixes that preserve the original governing equation and physical model.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is a standard one in the numerical analysis of partial differential equations. The Laplace equation with pure Neumann boundary conditions is a classic elliptic problem, and the issues of solvability and uniqueness are fundamental to its theory. All concepts are well-established in mathematics and computational science.\n- **Well-Posed:** The problem statement is well-posed. It clearly describes a physical and numerical setup and the resulting failure, asking for a correct diagnosis based on established theory.\n- **Objective:** The language is formal, technical, and free of any subjective or ambiguous terms.\n- **Completeness and Consistency:** The information provided is sufficient and consistent. The description of a pure Neumann problem for the Laplacian leading to a singular matrix is a well-known and expected outcome.\n\n**Step 3: Verdict and Action**\nThe problem statement is internally consistent, scientifically sound, and well-posed. It is a valid problem for analysis.\n\n**Derivation of Governing Principles**\n\nThe problem concerns the solution of the Laplace equation $\\nabla^2 u = 0$ on a domain $\\Omega$ with pure Neumann boundary conditions, $\\frac{\\partial u}{\\partial n} = g$ on the boundary $\\partial\\Omega$.\n\nThere are two fundamental issues with this continuous problem formulation that are inherited by its discrete counterpart.\n\n1.  **Non-uniqueness of the Solution:** If $u(x,y)$ is a solution, then for any arbitrary constant $C$, the function $v(x,y) = u(x,y) + C$ is also a solution. This is because the Laplacian operator annihilates constants, $\\nabla^2(u+C) = \\nabla^2 u + \\nabla^2 C = 0 + 0 = 0$, and the normal derivative is also unaffected, $\\frac{\\partial(u+C)}{\\partial n} = \\frac{\\partial u}{\\partial n} = g$. Therefore, a solution to the pure Neumann problem is only unique up to an additive constant.\n\n2.  **Solvability Condition:** There is a constraint on the boundary data $g$ for a solution to exist at all. By applying the Divergence Theorem (or Green's first identity) to the governing equation, we have:\n    $$ \\int_\\Omega \\nabla^2 u \\, d\\Omega = \\int_{\\partial\\Omega} \\nabla u \\cdot \\mathbf{n} \\, dS = \\int_{\\partial\\Omega} \\frac{\\partial u}{\\partial n} \\, dS $$\n    Since $\\nabla^2 u = 0$ everywhere in $\\Omega$, the left-hand side is zero. Substituting the boundary condition, we obtain a necessary compatibility condition:\n    $$ \\int_{\\partial\\Omega} g \\, dS = 0 $$\n    This means the total net flux across the boundary must be zero. If this condition is not met, no solution to the PDE exists.\n\nWhen the problem is discretized using the Finite Difference Method, these two issues manifest in the resulting linear system $A u = b$.\n\n1.  **Singularity of Matrix $A$:** The discrete Laplacian operator, constructed from the $5$-point stencil and the specified Neumann boundary conditions, has the property that the sum of the coefficients in each row of the matrix $A$ is zero. This means that if $\\mathbf{1}$ is a vector where every entry is $1$, then $A\\mathbf{1} = \\mathbf{0}$. This indicates that the constant vector $\\mathbf{1}$ lies in the nullspace of $A$, so $\\det(A) = 0$ and the matrix $A$ is singular. This corresponds directly to the non-uniqueness of the continuous solution.\n\n2.  **Consistency of the Linear System:** A linear system $A u = b$ has a solution if and only if the vector $b$ is in the column space (range) of $A$. For a symmetric matrix like $A$, this is equivalent to $b$ being orthogonal to the nullspace of $A$. Since the nullspace contains the vector $\\mathbf{1}$, the solvability condition becomes $\\mathbf{1}^T b = 0$, or $\\sum_i b_i = 0$. The vector $b$ is constructed from the boundary flux data $g$. This discrete sum is the numerical analogue of the continuous integral condition $\\int_{\\partial\\Omega} g \\, dS = 0$. If $\\mathbf{1}^T b \\neq 0$, the system is inconsistent, and an iterative solver will typically show a non-converging or stagnating residual.\n\n**Evaluation of Options**\n\n**A. The linear system constructed from the $5$-point Laplacian with pure Neumann boundary conditions is singular because constant vectors lie in its nullspace; uniqueness requires fixing the additive constant.**\nThis statement is a precise and correct diagnosis of the uniqueness issue. As derived above, the discrete operator annihilates constant vectors, meaning the matrix $A$ has a non-trivial nullspace containing the vector of all ones. A matrix with a non-trivial nullspace is singular. This singularity reflects the fact that the solution is only defined up to an additive constant, which must be fixed to ensure uniqueness.\n**Verdict: Correct**\n\n**B. The failure is due to the grid spacing $h$ being too large; simply refining the mesh will remove the singularity and guarantee convergence.**\nThis statement is incorrect. The singularity of the matrix $A$ is an intrinsic algebraic property of the discrete Laplacian operator under pure Neumann conditions. The property that $A\\mathbf{1} = \\mathbf{0}$ holds true regardless of the value of the grid spacing $h$. Refining the mesh will increase the size of the matrix $A$, but the new, larger matrix will also be singular for the same fundamental reason. Mesh refinement does not alter the nullspace structure.\n**Verdict: Incorrect**\n\n**C. A necessary compatibility condition for solvability is that the net prescribed normal flux across $\\partial\\Omega$ integrates to zero; if the boundary data violate this, no solution exists.**\nThis statement correctly identifies the solvability condition as derived from the Divergence Theorem. The condition $\\int_{\\partial\\Omega} g \\, dS = 0$ is a fundamental constraint on the data $g$. If this physical conservation law is violated, the mathematical problem is ill-posed, and no solution exists. The stagnation of the solver's residual is the numerical symptom of attempting to solve such an inconsistent system.\n**Verdict: Correct**\n\n**D. A minimal fix that preserves the governing equation is to enforce a single linear constraint, such as $\\int_{\\Omega} u \\,\\mathrm{d}\\Omega = 0$ or by pinning one node value, thereby rendering $A$ nonsingular.**\nThis statement proposes standard and valid remedies for the non-uniqueness issue. Both pinning a single node's value (e.g., $u_{i_0, j_0} = C$) and enforcing a zero-mean condition on the solution (the discrete version of $\\int_{\\Omega} u \\,d\\Omega = 0$) are single linear constraints that remove the constant from the solution space. This effectively removes the constant vector from the nullspace of the modified system's matrix, making it nonsingular and the solution unique. Crucially, these fixes do not alter the original governing equation $\\nabla^2 u = 0$.\n**Verdict: Correct**\n\n**E. Adding a small reaction term and solving $\\nabla^2 u - \\varepsilon u = 0$ with $\\varepsilon  0$ will both ensure uniqueness and maintain the original physical model unchanged; this is an acceptable fix.**\nThis statement is partially correct but ultimately flawed in its conclusion. Solving the modified Helmholtz equation $\\nabla^2 u - \\varepsilon u = 0$ does lead to a unique solution, as the operator $(\\nabla^2 - \\varepsilon I)$ for $\\varepsilon  0$ yields an invertible (negative definite) discrete matrix. However, the claim that this `maintain[s] the original physical model unchanged` is false. The governing equation has been fundamentally altered from the Laplace equation to the Helmholtz equation. This represents a different physical model (e.g., steady-state diffusion with a reaction or bulk sink). The problem specifies that fixes should preserve the original governing equation, which this method fails to do.\n**Verdict: Incorrect**\n\n**F. If boundary data violate solvability, one can project them onto the compatible subspace by subtracting their mean flux so that the discrete net flux is zero; this yields a solvable problem for the original Laplace equation.**\nThis statement accurately describes the standard procedure for handling inconsistent boundary data that violate the compatibility condition. If the discrete net flux is non-zero ($\\mathbf{1}^T b \\neq 0$), the original system is unsolvable. By modifying the boundary data (and thus the vector $b$) such that the new data satisfy the condition (e.g., $g' = g - \\text{mean}(g)$), one obtains a new, solvable problem. This projection modifies the boundary condition but leaves the governing PDE, $\\nabla^2 u = 0$, intact. This is a correct and practical approach to obtaining a physically meaningful solution for the original PDE operator.\n**Verdict: Correct**", "answer": "$$\\boxed{ACDF}$$", "id": "3128839"}, {"introduction": "In computational science, finding a solution is only half the battle; finding it efficiently is equally important. This final practice shifts focus from correctness to performance, exploring how the choice of a linear solver impacts the time-to-solution as problem sizes grow. You will compare the computational complexity of a direct solver with that of an advanced iterative method, learning to analyze algorithmic scaling and predict practical limits on achievable problem sizes. [@problem_id:3128786]", "problem": "Consider the two-dimensional Laplace equation on the unit square domain with Dirichlet boundary conditions, specified by $\\nabla^2 u = 0$ on $[0,1]\\times[0,1]$ with $u=0$ on the boundary. Using a standard five-point finite difference stencil on a uniform grid, let there be $N$ interior grid points along each axis, producing $M=N^2$ unknowns. The discrete linear system is of the form $A \\mathbf{u} = \\mathbf{b}$, where $A$ is sparse, symmetric positive definite (SPD).\n\nTwo solver families commonly used in computational science laboratories are considered:\n\n- A direct solver based on nested dissection and Cholesky factorization tailored to structured two-dimensional grids.\n- A multigrid V-cycle iterative solver with smoothing operations on each level.\n\nYour task is to reason from first principles about how the number of floating-point operations scales with the grid parameter $N$ for each solver family, and then use these scalings to produce time-to-solution predictions and practical limits. Assume the following modeling constants capturing implementation overheads and per-operation costs:\n- Proportionality constant $\\alpha = 40$ for the direct solver.\n- Proportionality constant $\\beta = 10$ for the multigrid solver.\nBoth constants are dimensionless multipliers on the leading-order scaling you derive.\n\nDefine the sustained floating-point execution rate of the hardware as $r$ (in floating-point operations per second), and define an allowable maximum wall-clock time per solve as $T_{\\max}$ (in seconds). The time to solution $t$ for a given solver model is computed by dividing the total operation count by $r$, and must be expressed in seconds.\n\nFor each test case, your program must:\n1. Compute the predicted time-to-solution for the direct solver, $t_{\\mathrm{direct}}$, in $\\mathrm{s}$.\n2. Compute the predicted time-to-solution for the multigrid solver, $t_{\\mathrm{mg}}$, in $\\mathrm{s}$.\n3. Compute the largest integer $N_{\\max,\\mathrm{direct}}$ such that the predicted time for the direct solver does not exceed $T_{\\max}$.\n4. Compute the largest integer $N_{\\max,\\mathrm{mg}}$ such that the predicted time for the multigrid solver does not exceed $T_{\\max}$.\n\nYou must express all times in seconds, rounded to six decimal places. The output must not include any unit symbols, only numeric values. Angles are not involved, so no angle unit is required.\n\nUse the following test suite, each case given as a triple $(N,r,T_{\\max})$:\n- Case A: $(N = 8,\\ r = 2\\times 10^{10},\\ T_{\\max} = 2)$.\n- Case B: $(N = 64,\\ r = 2\\times 10^{10},\\ T_{\\max} = 2)$.\n- Case C: $(N = 256,\\ r = 2\\times 10^{10},\\ T_{\\max} = 2)$.\n- Case D: $(N = 512,\\ r = 1\\times 10^{11},\\ T_{\\max} = 1)$.\n- Case E (edge case): $(N = 1,\\ r = 1\\times 10^{9},\\ T_{\\max} = 0.1)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case result is itself a four-element list in the order $[t_{\\mathrm{direct}},t_{\\mathrm{mg}},N_{\\max,\\mathrm{direct}},N_{\\max,\\mathrm{mg}}]$. For example, the overall output format must be\n$[[t_{\\mathrm{direct},A},t_{\\mathrm{mg},A},N_{\\max,\\mathrm{direct},A},N_{\\max,\\mathrm{mg},A}],[t_{\\mathrm{direct},B},t_{\\mathrm{mg},B},N_{\\max,\\mathrm{direct},B},N_{\\max,\\mathrm{mg},B}],\\dots]$,\nwith all numeric entries shown, times rounded to six decimal places, and no extra spaces.\n\nDesign your algorithm and compute the answers by starting from foundational properties of the finite difference method and solver structures, without using shortcut formulas provided to you. All numerical outputs must be either integers or floating-point numbers as specified.", "solution": "The problem statement has been critically examined and is determined to be valid. It is scientifically grounded in established principles of computational science, specifically the numerical solution of partial differential equations. The problem is well-posed, with all necessary data and definitions provided to derive a unique, meaningful solution. The language is objective and the constraints are consistent and physically plausible.\n\nThe task is to analyze the computational complexity of two different solver algorithms for the linear system arising from a finite difference discretization of the two-dimensional Laplace equation, $\\nabla^2 u = 0$. The domain is the unit square $[0,1]\\times[0,1]$ with homogeneous Dirichlet boundary conditions ($u=0$ on the boundary). The discretization uses a standard five-point stencil on a uniform grid with $N$ interior points along each axis, resulting in a system of $M = N^2$ linear equations $A \\mathbf{u} = \\mathbf{b}$. The matrix $A$ is known to be sparse and symmetric positive definite (SPD).\n\nWe first derive the scaling of the number of floating-point operations (FLOPS) with respect to the grid parameter $N$ for each solver family.\n\n**1. Direct Solver: Nested Dissection with Cholesky Factorization**\n\nA direct solver finds the exact solution (up to machine precision) by factoring the matrix $A$. For an SPD matrix, Cholesky factorization ($A=LL^T$) is the method of choice. The computational cost of Cholesky factorization is highly dependent on the ordering of the unknowns, which affects the amount of \"fill-in\"â€”zero entries in $A$ that become non-zero in the factor $L$.\n\nA simple lexicographical ordering of the grid points results in a matrix $A$ with a bandwidth of approximately $N$. The FLOPS for a banded Cholesky factorization scale as $O(M \\cdot (\\text{bandwidth})^2) = O(N^2 \\cdot N^2) = O(N^4)$.\n\nHowever, the problem specifies the use of **nested dissection**. This is a far more efficient ordering strategy for matrices arising from grid-based problems. The method recursively partitions the grid. For a two-dimensional grid, a \"separator\" of grid points is chosen to divide the grid into two subdomains. The unknowns associated with the separator are ordered last. This process is applied recursively to the subdomains. The resulting matrix structure minimizes fill-in.\n\nFor a 2D problem with $M=N^2$ unknowns, the seminal work by George and Liu showed that the number of operations for Cholesky factorization using nested dissection scales as $O(M^{3/2})$. Expressing this in terms of $N$:\n$$\n\\text{FLOPS}_{\\mathrm{direct}} \\propto M^{3/2} = (N^2)^{3/2} = N^3\n$$\nThe problem provides a dimensionless proportionality constant $\\alpha = 40$ to model implementation-specific overheads. The total operation count, $C_{\\mathrm{direct}}$, is therefore:\n$$\nC_{\\mathrm{direct}}(N) = \\alpha N^3 = 40 N^3\n$$\n\n**2. Iterative Solver: Multigrid V-Cycle**\n\nMultigrid is an advanced iterative method renowned for its optimal efficiency. The fundamental principle is that simple relaxation smoothers (like Jacobi or Gauss-Seidel) are effective at reducing high-frequency components of the error but are very slow to damp low-frequency (smooth) error components. Multigrid methods overcome this by representing the smooth error on coarser grids, where it becomes relatively high-frequency and can be efficiently eliminated.\n\nA single multigrid V-cycle involves:\n- A few pre-smoothing steps on the fine grid.\n- Restricting the residual error to a coarser grid.\n- Recursively calling the solver on the coarse grid problem. This continues until a very coarse grid is reached, where the problem can be solved directly at negligible cost.\n- Prolongating (interpolating) the coarse-grid correction back to the fine grid.\n- A few post-smoothing steps on the fine grid.\n\nThe cost of smoothing, restriction, and prolongation on a grid with $M$ points is proportional to $M$. If the grid size is reduced by a constant factor at each level (typically a factor of $4$ for 2D grids), the total work for one V-cycle, $W(M)$, follows the recurrence $W(M) \\approx cM + W(M/4)$. The solution is a geometric series:\n$$\nW(M) \\approx cM + \\frac{cM}{4} + \\frac{cM}{16} + \\dots = cM \\sum_{k=0}^{\\infty} \\left(\\frac{1}{4}\\right)^k = cM \\frac{1}{1 - 1/4} = \\frac{4}{3}cM\n$$\nThus, the work per V-cycle is $O(M)$. A key theoretical result for multigrid is that for elliptic problems like the Laplace equation, the convergence rate per V-cycle is a constant independent of the grid size $M$. This means a fixed, small number of V-cycles is sufficient to solve the problem to a given accuracy.\n\nTherefore, the total number of operations for a multigrid solver is proportional to the number of unknowns, $M$.\n$$\n\\text{FLOPS}_{\\mathrm{mg}} \\propto M = N^2\n$$\nUsing the provided proportionality constant $\\beta = 10$, the total operation count, $C_{\\mathrm{mg}}$, is:\n$$\nC_{\\mathrm{mg}}(N) = \\beta N^2 = 10 N^2\n$$\n\n**3. Time-to-Solution and Maximum Problem Size**\n\nGiven the hardware's sustained floating-point execution rate, $r$, the time-to-solution, $t$, is the total operation count divided by $r$.\n\nFor the direct solver:\n$$\nt_{\\mathrm{direct}}(N, r) = \\frac{C_{\\mathrm{direct}}(N)}{r} = \\frac{40 N^3}{r}\n$$\nFor the multigrid solver:\n$$\nt_{\\mathrm{mg}}(N, r) = \\frac{C_{\\mathrm{mg}}(N)}{r} = \\frac{10 N^2}{r}\n$$\n\nThe largest integer grid size, $N_{\\max}$, solvable within a maximum wall-clock time $T_{\\max}$ is found by setting $t \\le T_{\\max}$ and solving for $N$.\n\nFor the direct solver, we solve for $N$ in $\\frac{40 N^3}{r} \\le T_{\\max}$:\n$$\nN^3 \\le \\frac{r T_{\\max}}{40} \\implies N \\le \\left( \\frac{r T_{\\max}}{40} \\right)^{1/3}\n$$\nSince $N$ must be an integer, we take the floor of the result:\n$$\nN_{\\max,\\mathrm{direct}} = \\left\\lfloor \\left( \\frac{r T_{\\max}}{40} \\right)^{1/3} \\right\\rfloor\n$$\n\nFor the multigrid solver, we solve for $N$ in $\\frac{10 N^2}{r} \\le T_{\\max}$:\n$$\nN^2 \\le \\frac{r T_{\\max}}{10} \\implies N \\le \\sqrt{\\frac{r T_{\\max}}{10}}\n$$\nAs an integer, $N$ is the floor of the result:\n$$\nN_{\\max,\\mathrm{mg}} = \\left\\lfloor \\sqrt{\\frac{r T_{\\max}}{10}} \\right\\rfloor\n$$\n\nThese formulas are now applied to each test case to compute the required numerical results.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes time-to-solution predictions and practical limits for direct\n    and multigrid solvers for the 2D Laplace equation.\n    \"\"\"\n    # Define the test cases from the problem statement as tuples of (N, r, T_max).\n    test_cases = [\n        # Case A\n        (8, 2e10, 2),\n        # Case B\n        (64, 2e10, 2),\n        # Case C\n        (256, 2e10, 2),\n        # Case D\n        (512, 1e11, 1),\n        # Case E\n        (1, 1e9, 0.1),\n    ]\n\n    # Proportionality constants from the problem.\n    # alpha for the direct solver (scaling with N^3).\n    alpha = 40.0\n    # beta for the multigrid solver (scaling with N^2).\n    beta = 10.0\n\n    all_results = []\n    for case in test_cases:\n        N, r, T_max = case\n\n        # 1. Compute predicted time-to-solution for the direct solver.\n        # Operation count C_direct = alpha * N^3.\n        # Time t_direct = C_direct / r.\n        t_direct = (alpha * N**3) / r\n\n        # 2. Compute predicted time-to-solution for the multigrid solver.\n        # Operation count C_mg = beta * N^2.\n        # Time t_mg = C_mg / r.\n        t_mg = (beta * N**2) / r\n\n        # 3. Compute the largest integer N_max,direct.\n        # We need t_direct = T_max, which is (alpha * N^3) / r = T_max.\n        # This simplifies to N = (r * T_max / alpha)^(1/3).\n        # Since N must be an integer, we take the floor.\n        N_max_direct = int(((r * T_max) / alpha)**(1/3))\n\n        # 4. Compute the largest integer N_max,mg.\n        # We need t_mg = T_max, which is (beta * N^2) / r = T_max.\n        # This simplifies to N = sqrt(r * T_max / beta).\n        # Since N must be an integer, we take the floor.\n        N_max_mg = int(((r * T_max) / beta)**(0.5))\n\n        # Format the case result as a string to exactly match the required output format,\n        # avoiding spaces that str(list) would introduce.\n        # Times are formatted to six decimal places.\n        case_result_str = f\"[{t_direct:.6f},{t_mg:.6f},{N_max_direct},{N_max_mg}]\"\n        all_results.append(case_result_str)\n\n    # Final print statement in the exact required format.\n    # The output is a single line: a list of lists, represented as a string.\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "3128786"}]}