{"hands_on_practices": [{"introduction": "The computational power of the Fast Multipole Method stems from its ability to efficiently manipulate condensed mathematical descriptions of source distributions. In two dimensions, the algebra of complex numbers provides a particularly elegant framework for handling the rotation and translation of these multipole expansions. This practice [@problem_id:2392057] challenges you to verify the correctness of these fundamental transformation operators, which form the mathematical engine of the FMM, by comparing their analytical predictions against a direct re-computation from transformed source particles.", "problem": "You are given a system of point sources in two spatial dimensions that generate a scalar potential governed by the Laplace equation. The fundamental solution in two dimensions is the logarithmic kernel, with potential generated by a set of sources located at positions $\\{(x_j,y_j)\\}_{j=1}^{N}$ with strengths $\\{q_j\\}_{j=1}^{N}$ defined by\n$$\n\\phi(\\mathbf{r}) \\;=\\; -\\frac{1}{2\\pi}\\sum_{j=1}^{N} q_j \\,\\log\\left(\\|\\mathbf{r}-\\mathbf{r}_j\\|\\right),\n$$\nwhere $\\mathbf{r}=(x,y)$ and $\\mathbf{r}_j=(x_j,y_j)$. Consider the complex representation $z=x+\\mathrm{i}y$ and the multipole moments of order $n$ about a center $c=c_x+\\mathrm{i}c_y$ defined by\n$$\nM_0 \\;=\\; \\sum_{j=1}^{N} q_j,\\qquad M_n \\;=\\; \\sum_{j=1}^{N} q_j\\,(z_j-c)^n\\quad\\text{for } n\\ge 1,\n$$\nwhere $z_j=x_j+\\mathrm{i}y_j$.\n\nA rigid rotation of all source positions about the center $c$ by an angle $\\theta$ (in radians) in the counterclockwise sense transforms the moments according to\n$$\nM_n^{(\\mathrm{rot})} \\;=\\; \\sum_{j=1}^{N} q_j\\,(z_j'-c)^n,\\quad \\text{where } z_j'-c \\;=\\; e^{\\mathrm{i}\\theta}\\,(z_j-c).\n$$\nA translation of the expansion center from $c$ to $c' = c + d$ with $d=d_x+\\mathrm{i}d_y$ relates the moments by the binomial identity\n$$\nM_n^{(\\mathrm{trans})}(c') \\;=\\; \\sum_{k=0}^{n} \\binom{n}{k}\\,(-d)^{\\,n-k}\\,M_k(c).\n$$\n\nNow consider representing planar vectors as pure quaternions for the purpose of rotation. A planar vector $\\mathbf{v}=(x,y)$ is embedded as the pure quaternion $v = 0 + x\\,\\mathbf{i} + y\\,\\mathbf{j} + 0\\,\\mathbf{k}$. A counterclockwise rotation by an angle $\\theta$ about the $\\mathbf{k}$-axis is given by the unit quaternion\n$$\nu(\\theta) \\;=\\; \\cos\\!\\left(\\frac{\\theta}{2}\\right) \\;+\\; \\sin\\!\\left(\\frac{\\theta}{2}\\right)\\,\\mathbf{k},\n$$\nacting on $v$ via conjugation $v' \\,=\\, u(\\theta)\\,v\\,u(\\theta)^{-1}$, which yields the rotated planar vector.\n\nTask. Implement a program that, for each test case below and for a specified nonnegative integer order $p$, computes the following two maximum absolute discrepancies:\n1. Rotation discrepancy: The maximum absolute difference over $n=0,1,\\dots,p$ between the moments recomputed from the sources rotated about $c$ by the quaternion conjugation formula and the moments predicted by the complex-phase rule $M_n \\mapsto e^{\\mathrm{i}n\\theta}M_n$.\n2. Translation discrepancy: The maximum absolute difference over $n=0,1,\\dots,p$ between the moments recomputed at the translated center $c' = c + d$ and the moments predicted by the binomial translation formula given above.\n\nAll angles must be in radians. The final outputs for each test case are real numbers (floating-point) representing these two maximum absolute discrepancies. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a two-element list $[E_{\\mathrm{rot}},E_{\\mathrm{trans}}]$ in that order. For example, the output format must be of the form\n$$\n\\big[\\,[E_{\\mathrm{rot}}^{(1)},E_{\\mathrm{trans}}^{(1)}],\\,[E_{\\mathrm{rot}}^{(2)},E_{\\mathrm{trans}}^{(2)}],\\,\\dots\\,\\big].\n$$\n\nTest suite. For each case below, use the specified sources $\\{(x_j,y_j),q_j\\}$, center $c=(c_x,c_y)$, order $p$, rotation angle $\\theta$, and translation increment $d=(d_x,d_y)$.\n\n- Case A (general configuration):\n  - $p=6$,\n  - $\\{(x_j,y_j)\\}_{j=1}^{4} = \\{(0.3,-0.1),\\,(1.1,0.7),\\,(-0.8,0.5),\\,(0.0,0.0)\\}$,\n  - $\\{q_j\\}_{j=1}^{4} = \\{1.0,\\,-2.0,\\,0.5,\\,-0.3\\}$,\n  - $c=(0.2,-0.1)$,\n  - $\\theta=\\pi/3$,\n  - $d=(0.1,-0.2)$.\n\n- Case B (zero-strength edge case):\n  - $p=5$,\n  - $\\{(x_j,y_j)\\}_{j=1}^{3} = \\{(-0.4,0.9),\\,(0.9,-0.2),\\,(0.3,-0.7)\\}$,\n  - $\\{q_j\\}_{j=1}^{3} = \\{0.0,\\,0.0,\\,0.0\\}$,\n  - $c=(0.0,0.0)$,\n  - $\\theta=\\pi/2$,\n  - $d=(0.5,0.5)$.\n\n- Case C (single-source, coincident center; zero rotation/translation):\n  - $p=7$,\n  - $\\{(x_j,y_j)\\}_{j=1}^{1} = \\{(0.7,-1.2)\\}$,\n  - $\\{q_j\\}_{j=1}^{1} = \\{2.5\\}$,\n  - $c=(0.7,-1.2)$,\n  - $\\theta=0.0$,\n  - $d=(0.0,0.0)$.\n\n- Case D (symmetric configuration, nontrivial translation and half-turn rotation):\n  - $p=8$,\n  - $\\{(x_j,y_j)\\}_{j=1}^{4} = \\{(0.6,0.0),\\,(-0.6,0.0),\\,(0.0,0.9),\\,(0.0,-0.9)\\}$,\n  - $\\{q_j\\}_{j=1}^{4} = \\{1.0,\\,1.0,\\,-1.0,\\,-1.0\\}$,\n  - $c=(0.0,0.0)$,\n  - $\\theta=\\pi$,\n  - $d=(-0.2,0.3)$.\n\nYour program should compute, for each case, the pair of floating-point numbers $[E_{\\mathrm{rot}},E_{\\mathrm{trans}}]$ and output them as a single line in the exact format described above. No external input is provided, and no physical units are involved beyond the dimensionless quantities specified. Angles are in radians. All numerical results must be given as raw decimal numbers in the program’s single-line output, without additional text.", "solution": "The problem is valid. It is a well-defined computational task based on established principles of potential theory and the Fast Multipole Method (FMM) in computational physics. The problem asks for the numerical verification of two fundamental transformation identities for multipole moments in a two-dimensional system governed by the Laplace equation.\n\nThe solution proceeds by implementing a direct computational process for each test case. The core of the task is to calculate two maximum absolute discrepancies, $E_{\\mathrm{rot}}$ and $E_{\\mathrm{trans}}$, up to a specified multipole order $p$. These discrepancies quantify the numerical difference between two equivalent methods of calculating transformed multipole moments. The mathematical equivalence implies that any non-zero result is attributable to a difference in floating-point error accumulation between the two computational pathways.\n\nWe begin by defining the multipole moments of a system of $N$ point sources with strengths $\\{q_j\\}_{j=1}^{N}$ at complex positions $\\{z_j\\}_{j=1}^{N}$ with respect to an expansion center $c$. The moment of order $n$ is given by\n$$\nM_n(c) = \\sum_{j=1}^{N} q_j (z_j - c)^n, \\quad n=0, 1, \\dots, p.\n$$\nThese moments are computed once and stored as an array of $p+1$ complex numbers, forming the basis for subsequent transformations.\n\n**1. Rotation Discrepancy ($E_{\\mathrm{rot}}$)**\n\nThe first task is to verify the consistency of the moment rotation formula. A counterclockwise rotation of all source positions about the center $c$ by an angle $\\theta$ transforms the relative position vectors $z_j - c$ to $(z_j - c)e^{\\mathrm{i}\\theta}$. The problem states that this rotation can be represented by quaternion conjugation, which for a planar vector is equivalent to multiplication by the complex phase factor $e^{\\mathrm{i}\\theta}$.\n\nWe compute the rotated moments in two ways:\n\na) **Re-computation from Rotated Sources**: The new source positions $z_j'$ after rotation about $c$ are given by $z_j' = c + (z_j - c)e^{\\mathrm{i}\\theta}$. We use these new positions to re-calculate the moments with respect to the original center $c$. Let us call these the recomputed moments, $M_n^{(\\mathrm{comp\\_rot})}(c)$.\n$$\nM_n^{(\\mathrm{comp\\_rot})}(c) = \\sum_{j=1}^{N} q_j (z_j' - c)^n = \\sum_{j=1}^{N} q_j \\left( (z_j - c)e^{\\mathrm{i}\\theta} \\right)^n.\n$$\n\nb) **Prediction via Transformation Rule**: The transformation rule for moments can be derived from the definition above:\n$$\nM_n^{(\\mathrm{comp\\_rot})}(c) = \\left(e^{\\mathrm{i}\\theta}\\right)^n \\sum_{j=1}^{N} q_j (z_j - c)^n = e^{\\mathrm{i}n\\theta} M_n(c).\n$$\nThis gives a direct formula for the predicted rotated moments, $M_n^{(\\mathrm{pred\\_rot})}(c)$, based on the original moments $M_n(c)$.\n$$\nM_n^{(\\mathrm{pred\\_rot})}(c) = e^{\\mathrm{i}n\\theta} M_n(c).\n$$\n\nThe rotation discrepancy, $E_{\\mathrm{rot}}$, is the maximum absolute difference between these two sets of moments over all orders $n=0, 1, \\dots, p$.\n$$\nE_{\\mathrm{rot}} = \\max_{0 \\le n \\le p} \\left| M_n^{(\\mathrm{comp\\_rot})}(c) - M_n^{(\\mathrm{pred\\_rot})}(c) \\right|.\n$$\n\n**2. Translation Discrepancy ($E_{\\mathrm{trans}}$)**\n\nThe second task is to verify the moment translation formula, also known as an M-to-M (multipole-to-multipole) translation. When the expansion center is shifted from $c$ to a new center $c' = c + d$, the moments change accordingly.\n\nWe compute the moments at the new center $c'$ in two ways:\n\na) **Re-computation at New Center**: The moments are calculated directly from the definition using the new center $c'$. Let these be the recomputed translated moments, $M_n^{(\\mathrm{comp\\_trans})}(c')$.\n$$\nM_n^{(\\mathrm{comp\\_trans})}(c') = \\sum_{j=1}^{N} q_j (z_j - c')^n = \\sum_{j=1}^{N} q_j (z_j - (c+d))^n.\n$$\n\nb) **Prediction via Transformation Rule**: The moments at the new center $c'$ can be expressed in terms of the moments at the old center $c$ using the binomial identity provided in the problem statement.\n$$\n(z_j - c')^n = ((z_j - c) - d)^n = \\sum_{k=0}^{n} \\binom{n}{k} (z_j-c)^k (-d)^{n-k}.\n$$\nSubstituting this into the moment definition and swapping summations yields the M-to-M translation formula, which we use for prediction:\n$$\nM_n^{(\\mathrm{pred\\_trans})}(c') = \\sum_{k=0}^{n} \\binom{n}{k} M_k(c) (-d)^{n-k}.\n$$\n\nThe translation discrepancy, $E_{\\mathrm{trans}}$, is the maximum absolute difference between these two sets of moments over all orders $n=0, 1, \\dots, p$.\n$$\nE_{\\mathrm{trans}} = \\max_{0 \\le n \\le p} \\left| M_n^{(\\mathrm{comp\\_trans})}(c') - M_n^{(\\mathrm{pred\\_trans})}(c') \\right|.\n$$\n\nFor each test case, the program implements these computations using complex arithmetic and calculates the two required discrepancy values, $[E_{\\mathrm{rot}}, E_{\\mathrm{trans}}]$. The final output aggregates these pairs into a single list.", "answer": "```python\nimport numpy as np\nfrom scipy.special import comb\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases and prints the formatted result.\n    \"\"\"\n\n    test_cases = [\n        {\n            'p': 6,\n            'sources': [(0.3, -0.1), (1.1, 0.7), (-0.8, 0.5), (0.0, 0.0)],\n            'strengths': [1.0, -2.0, 0.5, -0.3],\n            'center': (0.2, -0.1),\n            'theta': np.pi / 3,\n            'd_vec': (0.1, -0.2),\n        },\n        {\n            'p': 5,\n            'sources': [(-0.4, 0.9), (0.9, -0.2), (0.3, -0.7)],\n            'strengths': [0.0, 0.0, 0.0],\n            'center': (0.0, 0.0),\n            'theta': np.pi / 2,\n            'd_vec': (0.5, 0.5),\n        },\n        {\n            'p': 7,\n            'sources': [(0.7, -1.2)],\n            'strengths': [2.5],\n            'center': (0.7, -1.2),\n            'theta': 0.0,\n            'd_vec': (0.0, 0.0),\n        },\n        {\n            'p': 8,\n            'sources': [(0.6, 0.0), (-0.6, 0.0), (0.0, 0.9), (0.0, -0.9)],\n            'strengths': [1.0, 1.0, -1.0, -1.0],\n            'center': (0.0, 0.0),\n            'theta': np.pi,\n            'd_vec': (-0.2, 0.3),\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        solver = FMMDiscrepancyCalculator(\n            p=case['p'],\n            sources=case['sources'],\n            strengths=case['strengths'],\n            center=case['center'],\n            theta=case['theta'],\n            d_vec=case['d_vec']\n        )\n        result_pair = solver.calculate_all_discrepancies()\n        all_results.append(result_pair)\n\n    # Format the final output string as specified in the problem statement.\n    output_str = f\"[{','.join([f'[{r[0]},{r[1]}]' for r in all_results])}]\"\n    print(output_str)\n\nclass FMMDiscrepancyCalculator:\n    \"\"\"\n    A class to compute multipole moment transformation discrepancies.\n    \"\"\"\n\n    def __init__(self, p, sources, strengths, center, theta, d_vec):\n        self.p = p\n        self.sources = np.array([complex(x, y) for x, y in sources], dtype=np.complex128)\n        self.strengths = np.array(strengths, dtype=np.float64)\n        self.c = complex(center[0], center[1])\n        self.theta = theta\n        self.d = complex(d_vec[0], d_vec[1])\n        self.orders = np.arange(self.p + 1)\n\n        # property to cache original moments calculation\n        self._original_moments = None\n\n    @property\n    def original_moments(self):\n        if self._original_moments is None:\n            self._original_moments = self._compute_moments(self.sources, self.c)\n        return self._original_moments\n\n    def _compute_moments(self, source_positions, center):\n        \"\"\"Computes moments from source positions relative to a center.\"\"\"\n        moments = np.zeros(self.p + 1, dtype=np.complex128)\n        relative_pos = source_positions - center\n        for n in self.orders:\n            # numpy.power correctly handles z^0 = 1, including 0^0 = 1.\n            moments[n] = np.sum(self.strengths * np.power(relative_pos, n))\n        return moments\n\n    def calculate_rotation_discrepancy(self):\n        \"\"\"\n        Computes the maximum discrepancy for moment rotation.\n        \"\"\"\n        # Predicted moments using M_n' = e^(i*n*theta) * M_n\n        rot_factors = np.exp(1j * self.orders * self.theta)\n        predicted_moments = self.original_moments * rot_factors\n\n        # Recomputed moments from explicitly rotated sources.\n        # The quaternion rotation on the ij-plane is equivalent to multiplication by e^(i*theta).\n        relative_pos = self.sources - self.c\n        rotator = np.exp(1j * self.theta)\n        rotated_sources = self.c + relative_pos * rotator\n        recomputed_moments = self._compute_moments(rotated_sources, self.c)\n        \n        # Calculate maximum absolute difference\n        discrepancy = np.abs(recomputed_moments - predicted_moments)\n        return np.max(discrepancy)\n\n    def calculate_translation_discrepancy(self):\n        \"\"\"\n        Computes the maximum discrepancy for moment translation.\n        \"\"\"\n        # Predicted moments using the binomial M-to-M formula\n        predicted_moments = np.zeros(self.p + 1, dtype=np.complex128)\n        for n in self.orders:\n            for k in range(n + 1):\n                # Use exact=True to avoid float conversion of binomial coefficient\n                binomial_coeff = comb(n, k, exact=True)\n                term = binomial_coeff * ((-self.d) ** (n - k)) * self.original_moments[k]\n                predicted_moments[n] += term\n\n        # Recomputed moments at the new, translated center\n        new_center = self.c + self.d\n        recomputed_moments = self._compute_moments(self.sources, new_center)\n        \n        # Calculate maximum absolute difference\n        discrepancy = np.abs(recomputed_moments - predicted_moments)\n        return np.max(discrepancy)\n        \n    def calculate_all_discrepancies(self):\n        \"\"\"Calculates both discrepancies and returns them as a pair.\"\"\"\n        e_rot = self.calculate_rotation_discrepancy()\n        e_trans = self.calculate_translation_discrepancy()\n        return [e_rot, e_trans]\n\nsolve()\n```", "id": "2392057"}, {"introduction": "The efficiency of the Fast Multipole Method is built upon a hierarchical spatial decomposition, typically an octree in three dimensions, which organizes particles and their corresponding multipole expansions. Understanding the memory footprint of this data structure is crucial for any practical implementation, as it reveals how resource requirements scale. This exercise [@problem_id:2392064] guides you through modeling the memory usage from the ground up, linking the number of particles $N$ and the expansion order $p$ to the total storage cost, thereby providing a concrete grasp of the algorithm's scalability.", "problem": "You are asked to model and compute the memory footprint of a three-dimensional Fast Multipole Method (FMM) implementation for the Laplace kernel as a function of the number of particles and the expansion order. Your task is to derive a principled memory model from first principles of the algorithm's data structures and then implement a program that evaluates the model on a given test suite.\n\nAssume the following standard and explicitly defined setup:\n\n- The Fast Multipole Method (FMM) for the three-dimensional Laplace potential uses real spherical harmonic expansions up to order $p$.\n- The computational domain is a cube partitioned into a complete, level-uniform octree of depth $h$, such that every leaf node at depth $h$ contains at most $n_{\\text{leaf}}$ particles. A complete octree of depth $h$ has exactly $8^h$ leaves and $(8^{h+1} - 1)/7$ total nodes (including internal and leaf nodes). The minimal such depth $h$ is chosen so that $8^h \\ge \\lceil N / n_{\\text{leaf}} \\rceil$, where $N$ is the number of particles.\n- The number of coefficients in a real spherical harmonic multipole expansion of order $p$ for the Laplace kernel in three dimensions equals the number of spherical harmonics up to degree $p$, which is $\\sum_{\\ell=0}^{p} (2\\ell + 1) = (p+1)^2$. A local expansion has the same number of coefficients.\n- All floating-point values are stored in IEEE $754$ double precision (that is, $8$ bytes per floating-point value), and all integer indices are stored as $64$-bit signed integers (that is, $8$ bytes per integer).\n\nYou must adopt the following precise memory model:\n\n- Per particle:\n  - Store position $(x,y,z)$ as three doubles: $3 \\times 8$ bytes.\n  - Store the particle’s scalar source strength $q$ as one double: $1 \\times 8$ bytes.\n  - Store the index of the leaf that contains the particle as one $64$-bit integer: $1 \\times 8$ bytes.\n  - Store a permutation index for Morton ordering as one $64$-bit integer: $1 \\times 8$ bytes.\n  - Therefore, per particle memory is $4 \\times 8 + 2 \\times 8 = 48$ bytes and the total particle storage is $M_{\\text{particles}}(N) = 48 N$ bytes.\n- Per tree node (both internal and leaf nodes), store node metadata:\n  - Node center $(c_x,c_y,c_z)$ as three doubles: $3 \\times 8$ bytes.\n  - Node half-size $h_{\\text{size}}$ as one double: $1 \\times 8$ bytes.\n  - Particle index range $(i_{\\text{start}}, i_{\\text{end}})$ in Morton-sorted order as two $64$-bit integers: $2 \\times 8$ bytes.\n  - Therefore, per node metadata is $48$ bytes, and the total metadata storage is $M_{\\text{node-meta}}(\\text{total\\_nodes}) = 48 \\times \\text{total\\_nodes}$ bytes.\n- Per tree node, store both a multipole expansion and a local expansion (both in doubles), each with $(p+1)^2$ coefficients:\n  - Per node expansion storage is $2 \\times (p+1)^2 \\times 8$ bytes.\n  - Therefore, total expansion storage is $M_{\\text{exp}}(\\text{total\\_nodes}, p) = 16 \\times (p+1)^2 \\times \\text{total\\_nodes}$ bytes.\n- Per leaf node, store a fixed-size near-neighbor list with up to $26$ neighbor leaf indices (axis-aligned adjacent neighbors) as $64$-bit integers:\n  - Per leaf neighbor list storage is $26 \\times 8$ bytes.\n  - Therefore, total neighbor list storage is $M_{\\text{near}}(\\text{leaves}) = 26 \\times 8 \\times \\text{leaves} = 208 \\times \\text{leaves}$ bytes.\n\nDefinitions and required derivations from core principles:\n\n- From the definition of spherical harmonics, the number of modes up to degree $p$ is $\\sum_{\\ell=0}^{p} (2\\ell + 1) = (p+1)^2$.\n- For a complete octree of depth $h$, the total number of nodes is $\\sum_{k=0}^{h} 8^k = (8^{h+1} - 1)/7$ and the number of leaves is $8^h$.\n- The minimal depth $h$ is chosen to satisfy $8^h \\ge \\lceil N / n_{\\text{leaf}} \\rceil$.\n\nLet $N$ denote the number of particles, $p$ denote the expansion order, and $n_{\\text{leaf}}$ denote the leaf capacity. Define:\n- $L_{\\text{req}} = \\lceil N / n_{\\text{leaf}} \\rceil$,\n- $h = \\min \\{ h' \\in \\mathbb{N}_0 : 8^{h'} \\ge L_{\\text{req}} \\}$,\n- $\\text{leaves} = 8^h$,\n- $\\text{total\\_nodes} = (8^{h+1} - 1)/7$.\n\nThen the total memory in bytes is:\n$$\nM_{\\text{total}}(N,p,n_{\\text{leaf}}) = M_{\\text{particles}}(N) + M_{\\text{node-meta}}(\\text{total\\_nodes}) + M_{\\text{exp}}(\\text{total\\_nodes}, p) + M_{\\text{near}}(\\text{leaves}).\n$$\n\nYour program must:\n\n- Implement a function that, given $(N,p,n_{\\text{leaf}})$, computes $M_{\\text{total}}$ in bytes using the above model.\n- Convert the result to mebibytes (MiB), where $1$ MiB $= 2^{20}$ bytes, and report the result as a floating-point number rounded to exactly $6$ decimal places.\n\nTest suite:\n\nEvaluate the model for the following parameter sets $(N, p, n_{\\text{leaf}})$:\n\n- $(100000, 6, 200)$: a typical moderate case.\n- $(50, 0, 200)$: very small $N$, minimal expansion order.\n- $(10000, 12, 128)$: moderate $N$, high expansion order.\n- $(1000000, 4, 256)$: large $N$, moderate expansion order.\n- $(400, 1, 200)$: exactly two leaves in the occupancy bound, small expansion order.\n\nFinal output format:\n\n- Your program should produce a single line of output containing the results for the test suite in order, as a comma-separated list enclosed in square brackets, with each number in MiB rounded to exactly $6$ decimal places. For example, an output with two results should look like: $[12.345000,67.890000]$. Ensure there are no spaces after commas.", "solution": "The problem statement has been subjected to rigorous validation against the established criteria of scientific grounding, well-posedness, and objectivity.\n\nThe givens are as follows:\n- A model for the memory footprint of a three-dimensional Fast Multipole Method (FMM) for the Laplace kernel.\n- The use of real spherical harmonic expansions of order $p$, with $(p+1)^2$ coefficients per expansion.\n- A complete, level-uniform octree of depth $h$, where $h$ is the minimum integer satisfying $8^h \\ge \\lceil N / n_{\\text{leaf}} \\rceil$. The total nodes are $(8^{h+1}-1)/7$, and leaves are $8^h$.\n- Data type sizes: $8$ bytes for double-precision floats and $8$ bytes for $64$-bit integers.\n- A specific memory model is defined with four components:\n  1. Particle storage: $M_{\\text{particles}}(N) = 48N$ bytes.\n  2. Node metadata storage: $M_{\\text{node-meta}}(\\text{total\\_nodes}) = 48 \\times \\text{total\\_nodes}$ bytes.\n  3. Expansion coefficient storage: $M_{\\text{exp}}(\\text{total\\_nodes}, p) = 16(p+1)^2 \\times \\text{total\\_nodes}$ bytes.\n  4. Leaf neighbor list storage: $M_{\\text{near}}(\\text{leaves}) = 208 \\times \\text{leaves}$ bytes.\n- The total memory is the sum: $M_{\\text{total}} = M_{\\text{particles}} + M_{\\text{node-meta}} + M_{\\text{exp}} + M_{\\text{near}}$.\n- The final result must be reported in mebibytes (MiB), where $1 \\text{ MiB} = 2^{20}$ bytes, rounded to $6$ decimal places.\n\nThe validation concludes that the problem is valid. It is scientifically sound, as it is based on established principles of the FMM algorithm and its common data structures. All terms are defined unambiguously, and all necessary parameters and formulas are provided. The problem is well-posed, leading to a unique, verifiable solution for each set of input parameters.\n\nWe now proceed with the formal derivation and computation. The total memory, $M_{\\text{total}}$, is a function of the number of particles $N$, the expansion order $p$, and the leaf node capacity $n_{\\text{leaf}}$. The calculation for a given triplet $(N, p, n_{\\text{leaf}})$ is performed in the following steps.\n\nFirst, we determine the structural parameters of the octree.\nThe minimum number of leaf nodes required to contain $N$ particles with a capacity of $n_{\\text{leaf}}$ per leaf is:\n$$ L_{\\text{req}} = \\left\\lceil \\frac{N}{n_{\\text{leaf}}} \\right\\rceil $$\nThe problem specifies a complete, level-uniform octree. The depth $h$ of this tree must be the smallest non-negative integer such that the number of leaves, $8^h$, is at least $L_{\\text{req}}$. This is expressed as:\n$$ h = \\min \\{ h' \\in \\mathbb{N}_0 : 8^{h'} \\ge L_{\\text{req}} \\} $$\nThis can be computed by finding the smallest integer $h$ that satisfies $h \\ge \\log_8(L_{\\text{req}})$, which is $h = \\lceil\\log_8(L_{\\text{req}})\\rceil$ for $L_{\\text{req}} \\ge 1$. For the edge case where $N=0$ or no particles land in any box (which is not in the test suite), $L_{\\text{req}}$ could be $0$, in which case $h=0$ is the correct choice.\nOnce the depth $h$ is determined, the number of leaf nodes in the complete tree model is:\n$$ \\text{leaves} = 8^h $$\nThe total number of nodes in a complete octree of depth $h$ is the sum of a geometric series:\n$$ \\text{total\\_nodes} = \\sum_{k=0}^{h} 8^k = \\frac{8^{h+1} - 1}{8 - 1} = \\frac{8^{h+1} - 1}{7} $$\n\nSecond, we calculate the memory usage for each component of the model using these structural parameters.\nThe storage for $N$ particles is given directly:\n$$ M_{\\text{particles}} = 48N $$\nThe metadata for all tree nodes (both internal and leaf) is:\n$$ M_{\\text{node-meta}} = 48 \\times \\text{total\\_nodes} $$\nThe storage for multipole and local expansions, each with $(p+1)^2$ coefficients of size $8$ bytes, across all nodes is:\n$$ M_{\\text{exp}} = 2 \\times (p+1)^2 \\times 8 \\times \\text{total\\_nodes} = 16(p+1)^2 \\times \\text{total\\_nodes} $$\nThe storage for the fixed-size neighbor lists for all leaf nodes is:\n$$ M_{\\text{near}} = 26 \\times 8 \\times \\text{leaves} = 208 \\times \\text{leaves} $$\n\nThird, we sum these components to find the total memory in bytes:\n$$ M_{\\text{total}}(N, p, n_{\\text{leaf}}) = M_{\\text{particles}} + M_{\\text{node-meta}} + M_{\\text{exp}} + M_{\\text{near}} $$\nSubstituting the expressions for each component gives the full model:\n$$ M_{\\text{total}} = 48N + 48 \\left(\\frac{8^{h+1} - 1}{7}\\right) + 16(p+1)^2 \\left(\\frac{8^{h+1} - 1}{7}\\right) + 208(8^h) $$\nThis can be simplified by factoring out the `total_nodes` term:\n$$ M_{\\text{total}} = 48N + \\left(48 + 16(p+1)^2\\right) \\left(\\frac{8^{h+1} - 1}{7}\\right) + 208(8^h) $$\n\nFinally, the result in bytes is converted to mebibytes (MiB) and rounded to the specified precision:\n$$ M_{\\text{MiB}} = \\frac{M_{\\text{total}}}{2^{20}} $$\nThis procedure is applied to each of the specified test cases to generate the final output. For instance, for the case $(N, p, n_{\\text{leaf}}) = (100000, 6, 200)$, we have:\n- $L_{\\text{req}} = \\lceil 100000 / 200 \\rceil = 500$.\n- $h = \\min \\{h' : 8^{h'} \\ge 500\\} = 3$, since $8^2 = 64$ and $8^3 = 512$.\n- $\\text{leaves} = 8^3 = 512$.\n- $\\text{total\\_nodes} = (8^4 - 1)/7 = 4095/7 = 585$.\n- $M_{\\text{particles}} = 48 \\times 100000 = 4,800,000$ bytes.\n- $M_{\\text{node-meta}} = 48 \\times 585 = 28,080$ bytes.\n- $M_{\\text{exp}} = 16 \\times (6+1)^2 \\times 585 = 16 \\times 49 \\times 585 = 458,640$ bytes.\n- $M_{\\text{near}} = 208 \\times 512 = 106,496$ bytes.\n- $M_{\\text{total}} = 4800000 + 28080 + 458640 + 106496 = 5,393,216$ bytes.\n- $M_{\\text{MiB}} = 5393216 / 2^{20} \\approx 5.1434326... \\rightarrow 5.143433$ MiB.\nThe implementation will mechanize this exact procedure.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\n# from scipy import ...\n\ndef calculate_memory_mib(N, p, n_leaf):\n    \"\"\"\n    Calculates the total memory footprint of an FMM implementation in Mebibytes (MiB).\n\n    Args:\n        N (int): The total number of particles.\n        p (int): The expansion order for spherical harmonics.\n        n_leaf (int): The maximum number of particles per leaf node.\n\n    Returns:\n        float: The total memory usage in MiB.\n    \"\"\"\n    # Step 1: Determine tree structure parameters\n    if N == 0:\n        L_req = 0\n    else:\n        # L_req = ceil(N / n_leaf)\n        L_req = math.ceil(N / n_leaf)\n\n    if L_req <= 1:\n        h = 0\n    else:\n        # h = min { h' in N_0 : 8^h' >= L_req }\n        # This is equivalent to ceil(log8(L_req))\n        h = math.ceil(math.log(L_req, 8))\n\n    # Number of leaves in a complete octree of depth h\n    leaves = 8**h\n    # Total nodes in a complete octree of depth h\n    total_nodes = (8**(h + 1) - 1) // 7\n\n    # Step 2: Calculate memory for each component in bytes\n    # Per-particle storage\n    m_particles = 48 * N\n    \n    # Per-node metadata storage\n    m_node_meta = 48 * total_nodes\n    \n    # Per-node expansion storage\n    num_coeffs = (p + 1)**2\n    # 2 expansions (multipole, local) * num_coeffs * 8 bytes/coeff\n    m_exp = 16 * num_coeffs * total_nodes\n    \n    # Per-leaf near-neighbor list storage\n    # 26 neighbors * 8 bytes/index\n    m_near = 208 * leaves\n\n    # Step 3: Sum components and convert to MiB\n    m_total_bytes = m_particles + m_node_meta + m_exp + m_near\n    \n    # 1 MiB = 2^20 bytes\n    mebibytes = m_total_bytes / (2**20)\n    \n    return mebibytes\n\ndef solve():\n    \"\"\"\n    Solves the problem by evaluating the memory model for all test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple (N, p, n_leaf)\n    test_cases = [\n        (100000, 6, 200),  # a typical moderate case\n        (50, 0, 200),      # very small N, minimal expansion order\n        (10000, 12, 128),  # moderate N, high expansion order\n        (1000000, 4, 256), # large N, moderate expansion order\n        (400, 1, 200),     # exactly two leaves in occupancy bound\n    ]\n\n    results = []\n    for case in test_cases:\n        N, p, n_leaf = case\n        result_mib = calculate_memory_mib(N, p, n_leaf)\n        # Format the result to exactly 6 decimal places\n        results.append(f\"{result_mib:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2392064"}, {"introduction": "The elegance of the FMM lies in its adaptive approximation strategy, which hinges on the crucial decision of whether to use a compact multipole expansion or perform a direct calculation for a given group of particles. This decision is governed by a geometric rule known as the multipole-acceptance criterion (MAC), which partitions the computational work into far-field and near-field interactions. In this exercise [@problem_id:2392072], you will probe the behavior of this criterion by constructing several 'pathological' particle distributions, allowing you to analyze how the structure of the interaction lists and the balance of work change with the system's geometry.", "problem": "You are given the task of constructing particle configurations that are pathological for hierarchical long-range interaction schemes, and of quantifying, for each configuration, how a cell-based grouping test partitions interactions into well-separated versus near-field categories. Consider an axis-aligned cubic computational domain centered at the origin with half-size $H$, containing $N$ point particles at positions $\\{\\mathbf{x}_i\\}_{i=1}^N \\subset \\mathbb{R}^3$. Partition the domain into an octree: recursively subdivide any cube containing more than $C$ particles into $8$ equal child cubes until either the particle count in a cube is at most $C$ or a maximum depth $D$ is reached. A leaf cell is any non-empty cube not subdivided further by this rule. Let $\\mathcal{L}$ denote the set of all such leaf cells with at least one particle.\n\nFor each target leaf cell $T \\in \\mathcal{L}$ with center $\\mathbf{c}_T$ and half-size $h_T$, define its interaction list $\\mathcal{I}(T)$ as a set of source cells $S$ selected by the following geometric rule. For any source cell $S$ with center $\\mathbf{c}_S$ and half-size $h_S$, define the Euclidean distance $r_{ST} = \\|\\mathbf{c}_S - \\mathbf{c}_T\\|_2$ and the disjointness predicate that $S$ and $T$ are disjoint if and only if there exists at least one coordinate axis $a \\in \\{x,y,z\\}$ such that $|\\mathbf{c}_{S,a} - \\mathbf{c}_{T,a}| > h_S + h_T$. Define the multipole-acceptance test with parameter $\\theta \\in (0,1)$ as follows: a source cell $S$ is accepted for $T$ if and only if $S$ and $T$ are disjoint and $h_S / r_{ST} \\le \\theta$. Classify source cells for each target leaf as follows. Starting from the source root cell and a fixed target leaf $T$, if a source cell $S$ satisfies the acceptance test, then include $S$ in $\\mathcal{I}(T)$. If $S$ does not satisfy the acceptance test and $S$ is not a leaf, then classify its children in the same manner. If $S$ does not satisfy the acceptance test and $S$ is a leaf, or if $S$ and $T$ are not disjoint and $S$ is a leaf, then the pair $(S,T)$ is a near-field leaf-pair that must be computed directly. In addition, if $r_{ST} = 0$, then this pair cannot be accepted and must be refined unless $S$ is a leaf, in which case it is a near-field leaf-pair. For each target leaf $T$, this process yields a finite set $\\mathcal{I}(T)$ and a corresponding multiset of near-field leaf-pairs involving $T$.\n\nFor each configuration specified below, build the octree with the given parameters and compute the following four quantities:\n- The maximum interaction-list size across targets, $\\max_{T \\in \\mathcal{L}} |\\mathcal{I}(T)|$.\n- The arithmetic mean interaction-list size across targets, $\\frac{1}{|\\mathcal{L}|} \\sum_{T \\in \\mathcal{L}} |\\mathcal{I}(T)|$, rounded to three digits after the decimal point.\n- The total count of near-field leaf-pairs encountered over all targets, $\\sum_{T \\in \\mathcal{L}} \\#\\{\\text{near-field leaf-pairs involving }T\\}$.\n- The number of target leaves, $|\\mathcal{L}|$.\n\nAngles must be interpreted in radians.\n\nConstruct the following five pathological configurations, each inside the cube of half-size $H = 1.25$, with octree capacity $C = 32$, maximum depth $D = 20$, and multipole-acceptance parameter $\\theta = 0.5$. All distances are unitless. In all cases, take particle radius parameter $R = 1$ unless otherwise stated.\n\nTest Suite (each line is one test case specifying geometry and parameters):\n1. Hollow spherical shell: $N = 4096$ points quasi-uniformly distributed on the sphere of radius $R$. Use the deterministic Fibonacci construction: let $\\varphi = \\frac{1+\\sqrt{5}}{2}$ and $\\alpha = 2\\pi\\left(1 - \\frac{1}{\\varphi}\\right)$. For $k \\in \\{0,1,\\dots,N-1\\}$, define $z_k = 1 - \\frac{2(k+0.5)}{N}$, $r_k = \\sqrt{1 - z_k^2}$, $\\theta_k = \\alpha k$, and set $\\mathbf{x}_k = \\left(R r_k \\cos \\theta_k, R r_k \\sin \\theta_k, R z_k\\right)$.\n2. Great-circle ring: $N = 4096$ points on the circle of radius $R$ in the plane $z=0$. For $k \\in \\{0,1,\\dots,N-1\\}$, set $\\mathbf{x}_k = \\left(R \\cos \\frac{2\\pi k}{N}, R \\sin \\frac{2\\pi k}{N}, 0\\right)$.\n3. Eight-corner clusters: $N = 4096$ points arranged as $8$ identical $8\\times 8 \\times 8$ grids of points, one grid packed inside a small cube of side $0.02$ centered near each corner of the cube of side $2R$, offset inward by $0.05$. Let the inward offset be $\\delta = 0.05$ and the micro-grid span be $\\varepsilon = 0.02$. For each corner sign triple $\\mathbf{s} \\in \\{-1,1\\}^3$, define the cluster center $\\mathbf{c}_{\\mathbf{s}} = \\mathbf{s}\\,(R - \\delta)$. For grid indices $(p,q,r) \\in \\{0,1,\\dots,7\\}^3$, define the local offset $\\mathbf{o}_{pqr} = \\varepsilon \\left(\\frac{p}{7} - \\frac{1}{2}, \\frac{q}{7} - \\frac{1}{2}, \\frac{r}{7} - \\frac{1}{2}\\right)$ and place one particle at $\\mathbf{x} = \\mathbf{c}_{\\mathbf{s}} + \\mathbf{o}_{pqr}$ for each $(\\mathbf{s},p,q,r)$.\n4. Single particle: $N = 1$ particle at the origin, $\\mathbf{x}_1 = (0,0,0)$.\n5. Collinear line: $N = 4096$ particles on the $x$-axis from $-R$ to $R$ inclusive with equal spacing. For $k \\in \\{0,1,\\dots,N-1\\}$, set $\\mathbf{x}_k = \\left(-R + \\frac{2R}{N-1} k, 0, 0\\right)$.\n\nFor all test cases, use the same domain half-size $H$, octree capacity $C$, maximum depth $D$, and multipole parameter $\\theta$ as specified above. Your program must construct the particles, build the octree, perform the classification for each target leaf as defined, and compute the four requested quantities. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a list of four numbers in the order given. For example, the output should be formatted as a single line like $[\\,[a_1,b_1,c_1,d_1],\\,[a_2,b_2,c_2,d_2],\\,\\dots\\,]$, where $a_i$, $b_i$, $c_i$, and $d_i$ are the four numbers for test case $i$ and $b_i$ is rounded to three digits after the decimal point.", "solution": "The problem presented is a well-defined exercise in computational physics, specifically concerning the analysis of a core component of the Fast Multipole Method (FMM). The task requires the implementation of an octree data structure to partition a three-dimensional space containing particles, and subsequently, for each leaf of this tree, to classify all other cells as either far-field (part of an interaction list) or near-field, based on a geometric multipole-acceptance criterion. This analysis must be performed for five specific particle configurations designed to test the algorithm's behavior under pathological conditions. The problem is scientifically sound, mathematically precise, and algorithmically explicit. Therefore, it is deemed a valid problem.\n\nThe solution proceeds by implementing the specified algorithms and applying them to each test case. The main components of the solution are: particle generation, octree construction, and interaction classification.\n\n**1. Particle Generation**\n\nFor each of the five test cases, $N$ particles are generated within a domain defined by a cube of half-size $H = 1.25$ centered at the origin. The coordinates $\\{\\mathbf{x}_i\\}_{i=1}^N$ are determined by the following rules, with radius parameter $R=1$:\n\n- **Case 1: Hollow Spherical Shell ($N=4096$)**\n  Particles are distributed on the surface of a sphere of radius $R=1$ using the Fibonacci lattice construction. For $k \\in \\{0, 1, \\dots, N-1\\}$, with $\\varphi = \\frac{1+\\sqrt{5}}{2}$ and $\\alpha = 2\\pi(1 - 1/\\varphi)$, the coordinates $\\mathbf{x}_k = (x_k, y_k, z_k)$ are:\n  $$ z_k = 1 - \\frac{2(k+0.5)}{N} $$\n  $$ r_k = \\sqrt{1 - z_k^2} $$\n  $$ \\theta_k = \\alpha k $$\n  $$ \\mathbf{x}_k = (R r_k \\cos \\theta_k, R r_k \\sin \\theta_k, R z_k) $$\n\n- **Case 2: Great-circle Ring ($N=4096$)**\n  Particles are uniformly distributed on a circle of radius $R=1$ in the $z=0$ plane. For $k \\in \\{0, 1, \\dots, N-1\\}$:\n  $$ \\mathbf{x}_k = \\left(R \\cos \\frac{2\\pi k}{N}, R \\sin \\frac{2\\pi k}{N}, 0\\right) $$\n\n- **Case 3: Eight-corner Clusters ($N=4096$)**\n  $N/8 = 512$ particles are placed in a small cubic grid near each of the $8$ corners of a cube of side $2R$. Parameters are $\\delta=0.05$ and $\\varepsilon=0.02$. For each corner sign triple $\\mathbf{s} \\in \\{-1,1\\}^3$ and grid indices $(p,q,r) \\in \\{0,1,\\dots,7\\}^3$:\n  $$ \\mathbf{c}_{\\mathbf{s}} = \\mathbf{s}\\,(R - \\delta) $$\n  $$ \\mathbf{o}_{pqr} = \\varepsilon \\left(\\frac{p}{7} - \\frac{1}{2}, \\frac{q}{7} - \\frac{1}{2}, \\frac{r}{7} - \\frac{1}{2}\\right) $$\n  A particle is placed at $\\mathbf{x} = \\mathbf{c}_{\\mathbf{s}} + \\mathbf{o}_{pqr}$.\n\n- **Case 4: Single Particle ($N=1$)**\n  A single particle is placed at the origin:\n  $$ \\mathbf{x}_1 = (0, 0, 0) $$\n\n- **Case 5: Collinear Line ($N=4096$)**\n  Particles are placed with equal spacing on the $x$-axis from $-R$ to $R$. For $k \\in \\{0, 1, \\dots, N-1\\}$:\n  $$ \\mathbf{x}_k = \\left(-R + \\frac{2R}{N-1} k, 0, 0\\right) $$\n\n**2. Octree Construction**\n\nAn octree is constructed to spatially partition the particles. The process starts with a root cell, a cube centered at $(0,0,0)$ with half-size $H=1.25$. This cell contains all $N$ particles. A recursive subdivision procedure is applied: any cell containing more than $C=32$ particles is subdivided into $8$ equal cubic children, unless the cell is already at the maximum depth $D=20$. The particles within the parent cell are then distributed among its children. This process continues until all cells either contain $C$ or fewer particles or are at depth $D$. A non-empty cell that is not subdivided is a leaf cell. The set of all such leaf cells is denoted by $\\mathcal{L}$.\n\n**3. Interaction Classification**\n\nFor each target leaf cell $T \\in \\mathcal{L}$, a traversal of the entire octree (starting from the root as the initial source cell $S$) is performed to build its interaction list $\\mathcal{I}(T)$ and to count near-field leaf-pairs. The classification rule for a source cell $S$ relative to a target leaf $T$ is as follows:\n\n- Let $\\mathbf{c}_S, h_S$ and $\\mathbf{c}_T, h_T$ be the centers and half-sizes of $S$ and $T$, respectively.\n- The cells are disjoint if $|\\mathbf{c}_{S,a} - \\mathbf{c}_{T,a}| > h_S + h_T$ for at least one axis $a \\in \\{x,y,z\\}$.\n- The multipole-acceptance criterion (MAC) is satisfied if $S$ and $T$ are disjoint and the condition $h_S / r_{ST} \\le \\theta$ holds, where $r_{ST} = \\|\\mathbf{c}_S - \\mathbf{c}_T\\|_2$ and $\\theta=0.5$. If $r_{ST}=0$, the test fails.\n\nThe recursive classification proceeds for a given target $T$ and a source cell $S$:\n1. If the MAC is satisfied, $S$ is added to $\\mathcal{I}(T)$, and the traversal of this branch of the source tree terminates.\n2. If the MAC is not satisfied:\n   a. If $S$ is a non-leaf cell, the procedure is recursively applied to each of its children.\n   b. If $S$ is a leaf cell, the pair $(S,T)$ is classified as a near-field leaf-pair.\n\nThis process is repeated for every target leaf $T \\in \\mathcal{L}$.\n\n**4. Computation of Statistics**\n\nAfter classifying interactions for all target leaves, the following four quantities are computed for each test case:\n- The maximum size of any interaction list: $\\max_{T \\in \\mathcal{L}} |\\mathcal{I}(T)|$.\n- The arithmetic mean of interaction list sizes, rounded to three decimal places: $\\frac{1}{|\\mathcal{L}|} \\sum_{T \\in \\mathcal{L}} |\\mathcal{I}(T)|$.\n- The total count of near-field leaf-pairs: $\\sum_{T \\in \\mathcal{L}} \\#\\{S \\in \\mathcal{L} \\mid (S,T) \\text{ is a near-field pair}\\}$.\n- The total number of non-empty leaf cells: $|\\mathcal{L}|$.\n\nThe implementation systematically executes these steps, collecting the four statistics for each of the five particle configurations.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport collections\n\n# from scipy import ... # Scipy is not required for this implementation.\n\nclass Cell:\n    \"\"\"Represents a cell in the octree.\"\"\"\n    def __init__(self, center, half_size, depth, parent=None):\n        self.center = center\n        self.half_size = half_size\n        self.depth = depth\n        self.parent = parent\n        self.children = []\n        self.particle_indices = []\n        self.is_leaf = False\n\ndef generate_particles(config, N, R):\n    \"\"\"Generates particle coordinates for a given configuration.\"\"\"\n    if config == \"sphere\":\n        particles = np.zeros((N, 3))\n        phi = (1.0 + np.sqrt(5.0)) / 2.0\n        alpha = 2.0 * np.pi * (1.0 - 1.0 / phi)\n        for k in range(N):\n            z_k = 1.0 - (2.0 * (k + 0.5)) / N\n            r_k = np.sqrt(1.0 - z_k**2)\n            theta_k = alpha * k\n            particles[k] = [R * r_k * np.cos(theta_k), R * r_k * np.sin(theta_k), R * z_k]\n        return particles\n    elif config == \"ring\":\n        particles = np.zeros((N, 3))\n        for k in range(N):\n            angle = 2.0 * np.pi * k / N\n            particles[k] = [R * np.cos(angle), R * np.sin(angle), 0.0]\n        return particles\n    elif config == \"clusters\":\n        particles = np.zeros((N, 3))\n        delta = 0.05\n        epsilon = 0.02\n        pidx = 0\n        signs = [-1.0, 1.0]\n        for sx in signs:\n            for sy in signs:\n                for sz in signs:\n                    s_vec = np.array([sx, sy, sz])\n                    cluster_center = s_vec * (R - delta)\n                    for p in range(8):\n                        for q in range(8):\n                            for r in range(8):\n                                o_pqr = epsilon * (np.array([p / 7.0, q / 7.0, r / 7.0]) - 0.5)\n                                particles[pidx] = cluster_center + o_pqr\n                                pidx += 1\n        return particles\n    elif config == \"single\":\n        return np.array([[0.0, 0.0, 0.0]])\n    elif config == \"line\":\n        return np.linspace([-R, 0, 0], [R, 0, 0], N)\n    return np.array([])\n\ndef build_octree_recursive(cell, particles, C, D):\n    \"\"\"Recursively builds the octree.\"\"\"\n    if len(cell.particle_indices) <= C or cell.depth >= D:\n        cell.is_leaf = len(cell.particle_indices) > 0\n        return\n\n    child_half_size = cell.half_size / 2.0\n    offsets = np.array([\n        [-1, -1, -1], [ 1, -1, -1], [-1,  1, -1], [ 1,  1, -1],\n        [-1, -1,  1], [ 1, -1,  1], [-1,  1,  1], [ 1,  1,  1]\n    ]) * child_half_size\n\n    child_centers = cell.center + offsets\n    \n    # Partition particles\n    particle_coords = particles[cell.particle_indices]\n    relative_coords = particle_coords - cell.center\n    \n    child_indices_map = collections.defaultdict(list)\n    for i, p_idx in enumerate(cell.particle_indices):\n        pos = relative_coords[i]\n        child_num = ( (1 if pos[0] >= 0 else 0) +\n                      (2 if pos[1] >= 0 else 0) +\n                      (4 if pos[2] >= 0 else 0) )\n        child_indices_map[child_num].append(p_idx)\n\n    for i in range(8):\n        child_center = child_centers[i]\n        child = Cell(child_center, child_half_size, cell.depth + 1, parent=cell)\n        if i in child_indices_map:\n            child.particle_indices = child_indices_map[i]\n            build_octree_recursive(child, particles, C, D)\n        else:\n            # Empty cell, mark as leaf but it won't be collected\n            child.is_leaf = True\n        cell.children.append(child)\n\ndef get_leaf_cells(cell):\n    \"\"\"Collects all non-empty leaf cells from the tree.\"\"\"\n    if not cell:\n        return []\n    if cell.is_leaf:\n        return [cell] if len(cell.particle_indices) > 0 else []\n    \n    leaves = []\n    for child in cell.children:\n        leaves.extend(get_leaf_cells(child))\n    return leaves\n\ndef find_interactions(target_leaf, source_cell, theta, results):\n    \"\"\"Recursively finds interactions for a target leaf.\"\"\"\n    if not source_cell or (source_cell.is_leaf and not source_cell.particle_indices):\n        return\n\n    r_st_vec = source_cell.center - target_leaf.center\n    r_st = np.linalg.norm(r_st_vec)\n\n    # Disjointness check\n    is_disjoint = np.any(np.abs(r_st_vec) > (source_cell.half_size + target_leaf.half_size))\n    \n    # MAC test\n    mac_satisfied = False\n    if is_disjoint:\n        # Avoid division by zero, although r_st > 0 if disjoint\n        if r_st > 0 and (source_cell.half_size / r_st) <= theta:\n            mac_satisfied = True\n\n    if mac_satisfied:\n        results['ilist'].append(source_cell)\n    else:\n        if source_cell.is_leaf:\n            if source_cell != target_leaf:\n                 results['near_field_pairs'] +=1\n            else: # Self interaction S=T fails MAC and is leaf\n                 results['near_field_pairs'] +=1\n        else:\n            for child in source_cell.children:\n                find_interactions(target_leaf, child, theta, results)\n\ndef solve():\n    \"\"\"Main function to run all test cases and print results.\"\"\"\n    test_cases = [\n        (\"sphere\", 4096, 1.0),\n        (\"ring\", 4096, 1.0),\n        (\"clusters\", 4096, 1.0),\n        (\"single\", 1, 1.0),\n        (\"line\", 4096, 1.0),\n    ]\n\n    H = 1.25\n    C = 32\n    D = 20\n    THETA = 0.5\n\n    all_results = []\n\n    for config, N, R in test_cases:\n        particles = generate_particles(config, N, R)\n        \n        root = Cell(center=np.array([0.0, 0.0, 0.0]), half_size=H, depth=0)\n        root.particle_indices = list(range(N))\n        \n        build_octree_recursive(root, particles, C, D)\n        \n        leaf_cells = get_leaf_cells(root)\n        num_leaves = len(leaf_cells)\n\n        if num_leaves == 0:\n            all_results.append([0, 0.0, 0, 0])\n            continue\n\n        interaction_list_sizes = []\n        total_near_field_pairs = 0\n\n        for target_leaf in leaf_cells:\n            # Re-initialize results for each target leaf\n            current_target_results = {'ilist': [], 'near_field_pairs': 0}\n            find_interactions_wrapper(target_leaf, root, THETA, current_target_results)\n\n            interaction_list_sizes.append(len(current_target_results['ilist']))\n            total_near_field_pairs += current_target_results['near_field_pairs']\n\n        max_ilist_size = max(interaction_list_sizes) if interaction_list_sizes else 0\n        mean_ilist_size = np.mean(interaction_list_sizes) if interaction_list_sizes else 0.0\n\n        all_results.append([\n            max_ilist_size,\n            round(mean_ilist_size, 3),\n            total_near_field_pairs,\n            num_leaves\n        ])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\ndef find_interactions_wrapper(target_leaf, root, theta, results):\n    \"\"\"\n    Wrapper for recursive interaction finding for a single target leaf.\n    This starts the traversal from the root for a given target.\n    \"\"\"\n    to_visit = [root]\n    while to_visit:\n        source_cell = to_visit.pop(0)\n\n        if not source_cell or (source_cell.is_leaf and not source_cell.particle_indices):\n            continue\n\n        r_st_vec = source_cell.center - target_leaf.center\n        \n        is_disjoint = np.any(np.abs(r_st_vec) > (source_cell.half_size + target_leaf.half_size))\n        \n        mac_satisfied = False\n        if is_disjoint:\n            r_st = np.linalg.norm(r_st_vec)\n            if r_st > 1e-12 and (source_cell.half_size / r_st) <= theta: # Added tolerance for r_st\n                mac_satisfied = True\n\n        if mac_satisfied:\n            results['ilist'].append(source_cell)\n        else:\n            if source_cell.is_leaf:\n                results['near_field_pairs'] += 1\n            else:\n                for child in source_cell.children:\n                    to_visit.append(child)\n\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2392072"}]}