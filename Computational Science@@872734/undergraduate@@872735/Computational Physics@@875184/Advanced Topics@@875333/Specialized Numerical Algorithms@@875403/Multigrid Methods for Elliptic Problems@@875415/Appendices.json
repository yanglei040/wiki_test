{"hands_on_practices": [{"introduction": "To truly grasp the power and elegance of multigrid methods, there is no substitute for building one yourself. This first practice [@problem_id:2415837] guides you through the implementation of a complete geometric multigrid V-cycle solver for the classic two-dimensional Poisson equation. You will construct the essential components—a smoother, grid transfer operators, and the recursive V-cycle logic—providing a deep, practical understanding of how these pieces work in concert to efficiently eliminate errors across all frequency scales.", "problem": "Consider the two-dimensional elliptic Partial Differential Equation (PDE) on the unit square with homogeneous Dirichlet boundary condition (DBC):\n$$\n-\\Delta u(x,y) = f(x,y) \\quad \\text{for } (x,y)\\in (0,1)\\times(0,1), \\qquad u(x,y)=0 \\quad \\text{on } \\partial([0,1]\\times[0,1]).\n$$\nDiscretize the interior using a uniform Cartesian grid with $N\\times N$ unknowns, grid spacing $h=1/(N+1)$, and the standard $5$-point finite difference stencil for the discrete negative Laplacian. Let the right-hand-side $f$ be a point source modeled as a Dirac delta function at a point that coincides with a grid node. On the grid, represent this point source by a discrete Kronecker delta scaled to preserve unit integral in the continuum limit, i.e., set $f_{i_{0},j_{0}}=1/h^{2}$ at the chosen grid node $(i_{0},j_{0})$ and $f_{i,j}=0$ elsewhere. In all cases below, indices $(i,j)$ refer to interior grid indices with $i,j\\in\\{0,1,\\dots,N-1\\}$ corresponding to the physical location $(x_{i},y_{j})=((i+1)h,(j+1)h)$.\n\nYour task is to implement a geometric multigrid V-cycle solver for the linear system arising from this discretization. Start from the following fundamental base:\n- The discrete operator corresponding to $-\\Delta$ under $5$-point finite differences on the interior is given by\n$$\n(Au)_{i,j}=\\frac{4u_{i,j}-u_{i+1,j}-u_{i-1,j}-u_{i,j+1}-u_{i,j-1}}{h^{2}},\n$$\nwith homogeneous DBC enforced by treating values outside the interior as zero.\n- The Kronecker-delta representation of a point source at $(i_{0},j_{0})$ with unit integral requires $f_{i_{0},j_{0}}=1/h^{2}$ so that $\\sum_{i,j} f_{i,j} h^{2}=1$.\n\nDesign a V-cycle that, on each level:\n- Uses weighted Jacobi smoothing with weight $\\omega=2/3$ for $\\nu_{1}$ pre-smoothing steps and $\\nu_{2}$ post-smoothing steps. Use $\\nu_{1}=\\nu_{2}=3$. Weighted Jacobi updates are\n$$\nu \\leftarrow u + \\omega D^{-1}(f-Au),\n$$\nwhere $D$ is the diagonal of $A$, i.e., $D_{i,j}=4/h^{2}$ so that $D^{-1}=(h^{2}/4)I$.\n- Employs full-weighting restriction to transfer the fine-grid residual to the coarse grid.\n- Employs bilinear interpolation for prolongation of the coarse-grid error correction.\n- Recurses by standard coarsening with interior sizes $N\\mapsto(N-1)/2$, assuming $N$ is of the form $2^{\\ell}-1$. On the coarsest level with $N\\le 3$, solve the linear system exactly by a direct dense solve for the discrete operator.\n\nQuantify robustness using the relative residual after each full V-cycle:\n$$\n\\rho = \\frac{\\lVert r \\rVert_{2}}{\\lVert f \\rVert_{2}}, \\quad r=f-Au,\n$$\nwhere $\\lVert\\cdot\\rVert_{2}$ is the Euclidean norm. Iterate V-cycles starting from the zero initial guess until either $\\rho \\le \\epsilon$ or a maximum of $K$ cycles has been performed. Report the final $\\rho$ that is achieved for each test case.\n\nTest suite. Implement and run your solver for the following parameter sets, which together probe a happy path, near-boundary behavior, superposition of multiple point sources, and a smaller grid edge case:\n- Case $1$: $N=63$, one point source at $(i_{0},j_{0})=(31,31)$, tolerance $\\epsilon=10^{-8}$, maximum cycles $K=20$.\n- Case $2$: $N=63$, one point source at $(i_{0},j_{0})=(1,1)$, tolerance $\\epsilon=10^{-8}$, maximum cycles $K=20$.\n- Case $3$: $N=31$, two point sources at $(i_{0},j_{0})\\in\\{(7,7),(23,23)\\}$ with both entries set to $1/h^{2}$, tolerance $\\epsilon=10^{-8}$, maximum cycles $K=20$.\n- Case $4$: $N=31$, one point source at $(i_{0},j_{0})=(0,0)$, tolerance $\\epsilon=10^{-8}$, maximum cycles $K=20$.\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list of floats enclosed in square brackets, where each float is the final relative residual $\\rho$ for the corresponding case, rounded to $6$ significant figures (for example, $[3.2e-07,1.1e-09, \\dots]$). No other text should be printed.", "solution": "The problem presented is a valid and well-posed task in computational physics. It asks for the implementation of a geometric multigrid V-cycle solver for the linear system $Au = f$ arising from the finite difference discretization of the two-dimensional Poisson equation, $-\\Delta u = f$, on a unit square with homogeneous Dirichlet boundary conditions. The problem is scientifically grounded, self-contained, and all parameters and algorithms are specified with sufficient precision for a unique implementation.\n\nThe core principle of a multigrid method is to accelerate the convergence of a basic iterative solver (the \"smoother\") by solving for the error on a hierarchy of coarser grids. High-frequency components of the error are efficiently damped by the smoother on a fine grid, while low-frequency components are resolved on coarser grids where they appear as high-frequency and can be damped effectively. A V-cycle is a specific recursive algorithm that traverses this grid hierarchy.\n\nThe solution is structured as follows: First, we define the components of the multigrid algorithm—the discrete operator, the smoother, and the grid transfer operators (restriction and prolongation). Then, we combine these into the recursive V-cycle procedure.\n\n**1. Discretization and Operators**\n\nThe continuous problem is discretized on a uniform grid with $N \\times N$ interior points and mesh size $h = 1/(N+1)$. The solution $u$ and right-hand side $f$ are represented as $N \\times N$ arrays. The discrete negative Laplacian operator, $A$, is given by the $5$-point stencil:\n$$\n(Au)_{i,j} = \\frac{4u_{i,j} - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1}}{h^2}\n$$\nfor interior indices $i,j \\in \\{0, 1, \\dots, N-1\\}$. Homogeneous Dirichlet boundary conditions are enforced by setting $u_{i,j} = 0$ for any index pair $(i,j)$ outside this interior range.\n\n**2. Weighted Jacobi Smoother**\n\nThe smoother's role is to reduce high-frequency error. We use the weighted Jacobi method. The update for a single smoothing step is:\n$$\nu \\leftarrow u + \\omega D^{-1}(f - Au)\n$$\nHere, $r = f - Au$ is the residual. The matrix $D$ is the diagonal of $A$, which has a constant value $D_{i,j} = 4/h^2$ for all interior points. Thus, its inverse is a scalar multiplication: $D^{-1} = (h^2/4)I$. The weight $\\omega = 2/3$ is chosen for good smoothing properties for this specific operator. We perform $\\nu_1 = 3$ pre-smoothing steps before coarsening and $\\nu_2 = 3$ post-smoothing steps after correction from the coarse grid.\n\n**3. Grid Transfer Operators**\n\nGrid transfer operators move data between fine and coarse grids. The grid hierarchy is defined by the standard coarsening rule for grids of size $N = 2^\\ell - 1$, where a fine grid of size $N_{\\text{fine}}$ is mapped to a coarse grid of size $N_{\\text{coarse}} = (N_{\\text{fine}} - 1)/2$.\n\n**Restriction ($R$):** The fine-grid residual $r^{\\text{fine}}$ is transferred to the coarse grid to form the right-hand side of the coarse-grid error equation, $r^{\\text{coarse}} = R r^{\\text{fine}}$. We use full-weighting restriction, where a coarse-grid value is a weighted average of $9$ corresponding fine-grid values. The stencil for the coarse-grid point $(I,J)$ centered at fine-grid point $(2I+1, 2J+1)$ is:\n$$\nr^{\\text{coarse}}_{I,J} = \\frac{1}{16} \\sum_{i,j \\in \\{-1,0,1\\}} w_{i,j} r^{\\text{fine}}_{2I+1+i, 2J+1+j}, \\quad \\text{with weights } W = \\begin{pmatrix} 1 & 2 & 1 \\\\ 2 & 4 & 2 \\\\ 1 & 2 & 1 \\end{pmatrix}\n$$\n\n**Prolongation ($P$):** After solving the error equation on the coarse grid, the resulting error correction $e^{\\text{coarse}}$ must be interpolated back to the fine grid: $e^{\\text{fine}} = P e^{\\text{coarse}}$. We use bilinear interpolation. A coarse-grid value $e^{\\text{coarse}}_{I,J}$ is used to determine values at a $2 \\times 2$ block of fine-grid points.\n- Fine-grid points coinciding with coarse-grid points are copied directly: $e^{\\text{fine}}_{2I+1, 2J+1} = e^{\\text{coarse}}_{I,J}$.\n- Fine-grid points along horizontal edges are averages of two coarse-grid neighbors: $e^{\\text{fine}}_{2I+1, 2J} = \\frac{1}{2}(e^{\\text{coarse}}_{I,J} + e^{\\text{coarse}}_{I,J-1})$.\n- Fine-grid points along vertical edges are averages of two coarse-grid neighbors: $e^{\\text{fine}}_{2I, 2J+1} = \\frac{1}{2}(e^{\\text{coarse}}_{I,J} + e^{\\text{coarse}}_{I-1,J})$.\n- Fine-grid points at nexus locations are averages of four coarse-grid neighbors: $e^{\\text{fine}}_{2I, 2J} = \\frac{1}{4}(e^{\\text{coarse}}_{I,J} + e^{\\text{coarse}}_{I-1,J} + e^{\\text{coarse}}_{I,J-1} + e^{\\text{coarse}}_{I-1,J-1})$.\nBoundary conditions are handled by assuming values outside the coarse grid are zero.\n\n**4. The V-Cycle Algorithm**\n\nA single V-cycle for solving $A^k u^k = f^k$ on grid level $k$ is defined recursively:\n\n1.  **Base Case:** If the grid is the coarsest (here, $N_k \\le 3$), solve the system $A^k u^k = f^k$ directly. This involves constructing the small, dense matrix $A^k$ and using a standard linear solver like LU decomposition.\n2.  **Recursive Step (for finer grids):**\n    a. **Pre-smoothing:** Apply $\\nu_1 = 3$ steps of the weighted Jacobi smoother to the current approximation of $u^k$.\n    $$\n    u^k \\leftarrow \\text{Smooth}^{\\nu_1}(A^k, f^k, u^k)\n    $$\n    b. **Compute Residual:** Calculate the residual on the fine grid: $r^k = f^k - A^k u^k$.\n    c. **Restriction:** Transfer the residual to the next coarser level, $k+1$.\n    $$\n    r^{k+1} = R r^k\n    $$\n    d. **Coarse-Grid Solve:** Solve the residual equation on the coarse grid, $A^{k+1} e^{k+1} = r^{k+1}$, for the error correction $e^{k+1}$. This is done by a recursive call to the V-cycle algorithm, starting with a zero initial guess for the error.\n    $$\n    e^{k+1} = \\text{V-cycle}(A^{k+1}, r^{k+1}, \\text{initial guess } \\mathbf{0})\n    $$\n    e. **Prolongation:** Interpolate the computed error correction back to the fine grid.\n    $$\n    e^k = P e^{k+1}\n    $$\n    f. **Correction:** Update the fine-grid solution.\n    $$\n    u^k \\leftarrow u^k + e^k\n    $$\n    g. **Post-smoothing:** Apply $\\nu_2 = 3$ steps of the weighted Jacobi smoother to the corrected solution.\n    $$\n    u^k \\leftarrow \\text{Smooth}^{\\nu_2}(A^k, f^k, u^k)\n    $$\nThe V-cycle process is initiated with a zero initial guess, $\\mathbf{u}=\\mathbf{0}$, and is iterated until the relative residual $\\rho = \\lVert f-Au \\rVert_2 / \\lVert f \\rVert_2$ falls below a tolerance $\\epsilon = 10^{-8}$ or a maximum of $K=20$ cycles is reached. The final achieved $\\rho$ is reported.", "answer": "```python\nimport numpy as np\n\nclass VCycleSolver:\n    \"\"\"\n    A geometric multigrid V-cycle solver for the 2D Poisson equation.\n    \"\"\"\n    def __init__(self, omega=2/3, nu1=3, nu2=3, coarsest_n=3):\n        self.omega = omega\n        self.nu1 = nu1\n        self.nu2 = nu2\n        self.coarsest_n = coarsest_n\n        self._coarsest_matrices = {}\n\n    def _apply_A(self, u, h):\n        \"\"\"Applies the 5-point stencil discrete Laplacian operator.\"\"\"\n        u_padded = np.pad(u, 1, mode='constant', constant_values=0)\n        # 4*u_ij - u_{i+1,j} - u_{i-1,j} - u_{i,j+1} - u_{i,j-1}\n        laplacian = (4 * u -\n                     (u_padded[1:-1, 2:] + u_padded[1:-1, :-2] +\n                      u_padded[2:, 1:-1] + u_padded[:-2, 1:-1]))\n        return laplacian / (h**2)\n\n    def _weighted_jacobi(self, u, f, h, nu):\n        \"\"\"Performs `nu` steps of weighted Jacobi smoothing.\"\"\"\n        D_inv = h**2 / 4.0\n        for _ in range(nu):\n            r = f - self._apply_A(u, h)\n            u += self.omega * D_inv * r\n        return u\n\n    def _restrict(self, r_fine):\n        \"\"\"Performs full-weighting restriction.\"\"\"\n        # Stencil: 1/16 * [[1, 2, 1], [2, 4, 2], [1, 2, 1]]\n        r_coarse = (\n            4 * r_fine[1::2, 1::2] +\n            2 * (r_fine[1::2, 0:-1:2] + r_fine[1::2, 2::2] +\n                 r_fine[0:-1:2, 1::2] + r_fine[2::2, 1::2]) +\n            1 * (r_fine[0:-1:2, 0:-1:2] + r_fine[0:-1:2, 2::2] +\n                 r_fine[2::2, 0:-1:2] + r_fine[2::2, 2::2])\n        ) / 16.0\n        return r_coarse\n\n    def _prolongate(self, e_coarse):\n        \"\"\"Performs bilinear interpolation for prolongation.\"\"\"\n        Nc = e_coarse.shape[0]\n        Nf = 2 * Nc + 1\n        e_fine = np.zeros((Nf, Nf))\n\n        # Direct injection\n        e_fine[1::2, 1::2] = e_coarse\n\n        # Pad for easier interpolation\n        e_coarse_padded = np.pad(e_coarse, 1, mode='constant', constant_values=0)\n\n        # Interpolate vertical edges (average of horizontal neighbors)\n        e_fine[1::2, 0::2] = 0.5 * (e_coarse_padded[1:-1, :-1] + e_coarse_padded[1:-1, 1:])\n\n        # Interpolate horizontal edges (average of vertical neighbors)\n        e_fine[0::2, 1::2] = 0.5 * (e_coarse_padded[:-1, 1:-1] + e_coarse_padded[1:, 1:-1])\n\n        # Interpolate center points (average of 4 diagonal neighbors)\n        e_fine[0::2, 0::2] = 0.25 * (e_coarse_padded[:-1, :-1] + e_coarse_padded[:-1, 1:] +\n                                     e_coarse_padded[1:, :-1] + e_coarse_padded[1:, 1:])\n        return e_fine\n\n    def _get_coarsest_A(self, N, h):\n        \"\"\"Builds and caches the matrix for the coarsest grid.\"\"\"\n        if N in self._coarsest_matrices:\n            return self._coarsest_matrices[N]\n\n        size = N * N\n        if size == 0:\n            return np.zeros((0, 0))\n            \n        T_n = np.diag(np.full(N, 4.0)) - np.diag(np.ones(N - 1), 1) - np.diag(np.ones(N - 1), -1)\n        A = (np.kron(np.eye(N), T_n) +\n             np.kron(np.diag(np.ones(N - 1), 1), -np.eye(N)) +\n             np.kron(np.diag(np.ones(N - 1), -1), -np.eye(N)))\n        A /= h**2\n        self._coarsest_matrices[N] = A\n        return A\n\n    def _solve_coarsest(self, f, N, h):\n        \"\"\"Directly solves the system on the coarsest grid.\"\"\"\n        if N == 0:\n            return np.zeros((0,0))\n        A = self._get_coarsest_A(N, h)\n        u_vec = np.linalg.solve(A, f.flatten())\n        return u_vec.reshape((N, N))\n\n    def run_v_cycle(self, u, f, N):\n        \"\"\"Executes one recursive V-cycle.\"\"\"\n        h = 1.0 / (N + 1)\n\n        # 1. Base case: solve directly on coarsest grid\n        if N = self.coarsest_n:\n            return self._solve_coarsest(f, N, h)\n\n        # 2. Pre-smoothing\n        u = self._weighted_jacobi(u, f, h, self.nu1)\n\n        # 3. Compute residual\n        r = f - self._apply_A(u, h)\n\n        # 4. Restrict residual\n        r_coarse = self._restrict(r)\n\n        # 5. Solve coarse-grid error equation recursively\n        Nc = (N - 1) // 2\n        e_coarse_initial = np.zeros((Nc, Nc))\n        e_coarse = self.run_v_cycle(e_coarse_initial, r_coarse, Nc)\n\n        # 6. Prolongate error correction\n        e_fine = self._prolongate(e_coarse)\n\n        # 7. Correct fine-grid solution\n        u += e_fine\n\n        # 8. Post-smoothing\n        u = self._weighted_jacobi(u, f, h, self.nu2)\n\n        return u\n\n    def solve_system(self, N, f, tol, max_cycles):\n        \"\"\"Iteratively solves the system using V-cycles.\"\"\"\n        u = np.zeros((N, N))\n        h = 1.0 / (N + 1)\n        \n        norm_f = np.linalg.norm(f.flatten())\n        if norm_f == 0:\n            return 0.0\n\n        r = f - self._apply_A(u, h)\n        rel_res = np.linalg.norm(r.flatten()) / norm_f\n\n        for _ in range(max_cycles):\n            if rel_res = tol:\n                break\n            u = self.run_v_cycle(u, f, N)\n            r = f - self._apply_A(u, h)\n            rel_res = np.linalg.norm(r.flatten()) / norm_f\n        \n        return rel_res\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        {'N': 63, 'sources': [(31, 31)]},\n        {'N': 63, 'sources': [(1, 1)]},\n        {'N': 31, 'sources': [(7, 7), (23, 23)]},\n        {'N': 31, 'sources': [(0, 0)]},\n    ]\n    epsilon = 1e-8\n    K = 20\n\n    solver = VCycleSolver(omega=2/3, nu1=3, nu2=3)\n    results = []\n\n    for case in test_cases:\n        N = case['N']\n        sources = case['sources']\n        \n        h = 1.0 / (N + 1)\n        f = np.zeros((N, N))\n        for i0, j0 in sources:\n            f[i0, j0] = 1.0 / h**2\n        \n        final_rho = solver.solve_system(N, f, epsilon, K)\n        results.append(f\"{final_rho:.6g}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2415837"}, {"introduction": "After implementing a solver, a computational scientist's next question is \"How fast is it, and how well does it scale?\". This exercise [@problem_id:2415818] shifts our focus from implementation to performance analysis, using a detailed analytical model to investigate the parallel performance of a red-black Gauss-Seidel smoother. By dissecting the total runtime into computation, memory access, and parallel overheads, you will develop a crucial understanding of the real-world factors that govern the efficiency of high-performance algorithms.", "problem": "Consider the two-dimensional Poisson equation with Dirichlet boundary conditions discretized on a square grid using the standard five-point finite-difference stencil. Within a multigrid V-cycle, a red-black Gauss–Seidel smoother is applied on each grid level. Let the finest-level interior grid have $n_0 \\times n_0$ points, with coarsening by a factor of $2$ in each spatial direction so that level $\\ell$ has $n_\\ell = \\max\\!\\left(2, \\left\\lfloor \\dfrac{n_0}{2^\\ell} \\right\\rfloor \\right)$ interior points per dimension and $N_\\ell = n_\\ell^2$ interior points in total. Assume that smoothing is performed on each level with a total of $n_{\\mathrm{sweeps}} = \\nu_1 + \\nu_2$ sweeps per V-cycle.\n\nThe red-black Gauss–Seidel method updates half the points (the red set) followed by the other half (the black set) in each sweep. Assume that one point update costs $w_f$ floating-point operations and transfers $w_m$ bytes to or from main memory. The computation runs on a multi-core central processing unit (CPU) with $p$ identical cores, each capable of a sustained floating-point rate $f_{\\mathrm{core}}$ (in floating-point operations per second), and a shared sustained memory bandwidth $B$ (in bytes per second). A global barrier synchronization has latency $\\tau_b$ (in seconds), and the scheduling/launch overhead per color phase has latency $\\tau_\\ell$ (in seconds). Angles do not appear; no specific angle unit is required. All time parameters are in seconds.\n\nFor a given level $\\ell$ and core count $p$, define the effective per-color concurrency as\n$$\nc_\\ell(p) = \\min\\!\\left(p, \\frac{N_\\ell}{2}\\right).\n$$\nThe compute-limited time for one smoothing sweep on level $\\ell$ is\n$$\nT^{(\\mathrm{comp})}_\\ell(p) = \\frac{N_\\ell \\, w_f}{f_{\\mathrm{core}} \\, c_\\ell(p)}.\n$$\nThe memory-limited time for one smoothing sweep on level $\\ell$ is\n$$\nT^{(\\mathrm{mem})}_\\ell = \\frac{N_\\ell \\, w_m}{B}.\n$$\nThe base time for one sweep on level $\\ell$ is\n$$\nT^{(\\mathrm{base})}_\\ell(p) = \\max\\!\\left( T^{(\\mathrm{comp})}_\\ell(p), \\, T^{(\\mathrm{mem})}_\\ell \\right).\n$$\nEach sweep has two color phases and thus incurs overheads\n$$\nT^{(\\mathrm{bar})}(p) = \\mathbf{1}_{\\{p1\\}} \\cdot 2 \\, \\tau_b, \\qquad\nT^{(\\mathrm{sched})}(p) = \\mathbf{1}_{\\{p1\\}} \\cdot 2 \\, \\tau_\\ell,\n$$\nwhere $\\mathbf{1}_{\\{p1\\}}$ is $1$ if $p1$ and $0$ otherwise. The total smoothing time for one sweep on level $\\ell$ is\n$$\nT_\\ell(p) = T^{(\\mathrm{base})}_\\ell(p) + T^{(\\mathrm{bar})}(p) + T^{(\\mathrm{sched})}(p).\n$$\nLet the total smoother time over one V-cycle be\n$$\nT_{\\mathrm{total}}(p) = \\sum_{\\ell} n_{\\mathrm{sweeps}} \\, T_\\ell(p).\n$$\nDefine the parallel speedup and efficiency as\n$$\nS = \\frac{T_{\\mathrm{total}}(1)}{T_{\\mathrm{total}}(p)}, \\qquad E = \\frac{S}{p}.\n$$\nTo identify overhead sources, report the following fractions with respect to $T_{\\mathrm{total}}(p)$:\n- Barrier fraction:\n$$\nF_{\\mathrm{bar}} = \\frac{\\sum_{\\ell} n_{\\mathrm{sweeps}} \\, T^{(\\mathrm{bar})}(p)}{T_{\\mathrm{total}}(p)}.\n$$\n- Scheduling fraction:\n$$\nF_{\\mathrm{sched}} = \\frac{\\sum_{\\ell} n_{\\mathrm{sweeps}} \\, T^{(\\mathrm{sched})}(p)}{T_{\\mathrm{total}}(p)}.\n$$\n- Parallelism-limit fraction (loss due to insufficient concurrency $c_\\ell(p)  p$ in the compute-limited regime):\nFor each level $\\ell$, define the ideal compute-limited sweep time if full concurrency $p$ were usable as\n$$\nT^{(\\mathrm{comp,ideal})}_\\ell(p) = \\frac{N_\\ell \\, w_f}{f_{\\mathrm{core}} \\, p}.\n$$\nThen the per-level loss is\n$$\nL_\\ell(p) = \n\\begin{cases}\nT^{(\\mathrm{comp})}_\\ell(p) - T^{(\\mathrm{comp,ideal})}_\\ell(p),  \\text{if } T^{(\\mathrm{comp})}_\\ell(p) \\ge T^{(\\mathrm{mem})}_\\ell, \\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\nand the total fraction is\n$$\nF_{\\mathrm{plim}} = \\frac{\\sum_{\\ell} n_{\\mathrm{sweeps}} \\, L_\\ell(p)}{T_{\\mathrm{total}}(p)}.\n$$\n\nYour task is to write a complete, runnable program that, for the specified test suite below, computes for each test case the list $[S, E, F_{\\mathrm{bar}}, F_{\\mathrm{sched}}, F_{\\mathrm{plim}}]$ and prints a single line containing all test-case results as a comma-separated list of these lists enclosed in a single pair of square brackets, for example $[[a_1,a_2,a_3,a_4,a_5],[b_1,b_2,b_3,b_4,b_5]]$. All reported values must be floating-point numbers rounded to exactly $6$ digits after the decimal point. No other text should be printed.\n\nUse the following parameter values for all test cases unless explicitly overridden:\n- Per-update costs: $w_f = 10$ floating-point operations, $w_m = 48$ bytes.\n- Smoother sweep counts: $\\nu_1 = 2$, $\\nu_2 = 1$ so that $n_{\\mathrm{sweeps}} = 3$.\n- Machine parameters: $f_{\\mathrm{core}} = 2 \\times 10^{9}$ floating-point operations per second, $B = 4 \\times 10^{10}$ bytes per second, $\\tau_b = 2 \\times 10^{-6}$ seconds, $\\tau_\\ell = 5 \\times 10^{-6}$ seconds.\n\nTest suite (each case specified by $(n_0, p)$):\n- Case $1$: $(n_0, p) = (512, 1)$.\n- Case $2$: $(n_0, p) = (512, 4)$.\n- Case $3$: $(n_0, p) = (512, 16)$.\n- Case $4$: $(n_0, p) = (128, 16)$.\n- Case $5$: $(n_0, p) = (32, 64)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases above, where each element is itself a list of the five floating-point values $[S, E, F_{\\mathrm{bar}}, F_{\\mathrm{sched}}, F_{\\mathrm{plim}}]$ rounded to $6$ decimal places.", "solution": "The problem statement has been rigorously validated and is determined to be valid. It presents a well-posed computational task based on a clear, explicit, and scientifically sound performance model for a multigrid smoother, a standard algorithm in computational physics. All necessary parameters and definitions are provided, and no contradictions or ambiguities are present. We may therefore proceed with the solution.\n\nThe objective is to compute a set of parallel performance metrics for a multigrid V-cycle smoother using a given analytical performance model. The metrics include parallel speedup ($S$), efficiency ($E$), and fractions of total time attributed to barrier synchronization ($F_{\\mathrm{bar}}$), scheduling overhead ($F_{\\mathrm{sched}}$), and insufficient parallelism ($F_{\\mathrm{plim}}$). The calculation will be performed for several test cases, each defined by a finest grid size $n_0$ and a number of processor cores $p$.\n\nThe computational procedure is built by directly implementing the provided formulae. The overall structure of the calculation for a single test case $(n_0, p)$ is as follows:\n\nFirst, we must determine the grid hierarchy. The V-cycle operates on a sequence of grids, starting from the finest level $\\ell=0$ with $n_0 \\times n_0$ interior points. Each subsequent level $\\ell+1$ is obtained by coarsening the grid on level $\\ell$ by a factor of $2$. The number of interior points per dimension on level $\\ell$ is given by $n_\\ell = \\max\\!\\left(2, \\left\\lfloor \\dfrac{n_0}{2^\\ell} \\right\\rfloor \\right)$. The V-cycle proceeds until the grid size no longer decreases, which occurs when $n_\\ell=2$. We generate the sequence of grid sizes $\\{n_\\ell\\}$ for $\\ell = 0, 1, 2, \\dots$ until this condition is met.\n\nSecond, for each level $\\ell$ in the hierarchy and a given number of cores $p$, we calculate the total time for one smoothing sweep, $T_\\ell(p)$. This involves several steps:\n1.  Calculate the total number of interior points: $N_\\ell = n_\\ell^2$.\n2.  Determine the effective per-color concurrency: $c_\\ell(p) = \\min\\!\\left(p, \\frac{N_\\ell}{2}\\right)$. This reflects that a red-black smoother processes $\\frac{N_\\ell}{2}$ points in parallel during each of its two phases.\n3.  Calculate the compute-limited time for one sweep: $T^{(\\mathrm{comp})}_\\ell(p) = \\frac{N_\\ell \\, w_f}{f_{\\mathrm{core}} \\, c_\\ell(p)}$. This models the time assuming performance is limited by the floating-point capability of the available cores.\n4.  Calculate the memory-limited time for one sweep: $T^{(\\mathrm{mem})}_\\ell = \\frac{N_\\ell \\, w_m}{B}$. This models the time assuming performance is limited by memory bandwidth.\n5.  The base time for one sweep is the maximum of these two: $T^{(\\mathrm{base})}_\\ell(p) = \\max\\!\\left( T^{(\\mathrm{comp})}_\\ell(p), \\, T^{(\\mathrm{mem})}_\\ell \\right)$. This is a standard roofline model assumption.\n6.  Calculate the parallel overheads for one sweep. Since each sweep consists of two phases (red and black), a barrier and scheduling event may occur for each. The total overheads are $T^{(\\mathrm{bar})}(p) = \\mathbf{1}_{\\{p1\\}} \\cdot 2 \\, \\tau_b$ and $T^{(\\mathrm{sched})}(p) = \\mathbf{1}_{\\{p1\\}} \\cdot 2 \\, \\tau_\\ell$, where $\\mathbf{1}_{\\{p1\\}}$ is the indicator function, equal to $1$ if $p1$ and $0$ if $p=1$.\n7.  The total time for one sweep on level $\\ell$ is the sum of the base time and overheads: $T_\\ell(p) = T^{(\\mathrm{base})}_\\ell(p) + T^{(\\mathrm{bar})}(p) + T^{(\\mathrm{sched})}(p)$.\n\nThird, we calculate the total smoother time over one complete V-cycle, $T_{\\mathrm{total}}(p)$. This is the sum of the sweep times over all levels, multiplied by the number of sweeps per level, $n_{\\mathrm{sweeps}}$:\n$$\nT_{\\mathrm{total}}(p) = n_{\\mathrm{sweeps}} \\sum_{\\ell} T_\\ell(p)\n$$\n\nFourth, we calculate the total time lost due to insufficient parallelism. For each level $\\ell$, this loss, $L_\\ell(p)$, occurs only if the sweep is compute-limited ($T^{(\\mathrm{comp})}_\\ell(p) \\ge T^{(\\mathrm{mem})}_\\ell$) and there are fewer independent tasks than cores ($c_\\ell(p)  p$). The loss is the difference between the actual compute time and the ideal time if all $p$ cores could have been used:\n$$\nL_\\ell(p) = \n\\begin{cases}\nT^{(\\mathrm{comp})}_\\ell(p) - \\frac{N_\\ell \\, w_f}{f_{\\mathrm{core}} \\, p},  \\text{if } T^{(\\mathrm{comp})}_\\ell(p) \\ge T^{(\\mathrm{mem})}_\\ell, \\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\nThe total parallelism-limit loss over the V-cycle is $L_{\\mathrm{total}}(p) = n_{\\mathrm{sweeps}} \\sum_{\\ell} L_\\ell(p)$.\n\nFinally, we compute the required performance metrics.\n1.  To find the speedup $S$, we need the serial execution time $T_{\\mathrm{total}}(1)$. This is calculated by applying the entire procedure above with $p=1$. The speedup is then $S = \\frac{T_{\\mathrm{total}}(1)}{T_{\\mathrm{total}}(p)}$.\n2.  The efficiency is $E = \\frac{S}{p}$.\n3.  The overhead fractions are calculated by summing the respective overhead components across all levels, multiplying by $n_{\\mathrm{sweeps}}$, and normalizing by the total time $T_{\\mathrm{total}}(p)$:\n    $F_{\\mathrm{bar}} = \\frac{n_{\\mathrm{sweeps}} \\sum_{\\ell} T^{(\\mathrm{bar})}(p)}{T_{\\mathrm{total}}(p)}$\n    $F_{\\mathrm{sched}} = \\frac{n_{\\mathrm{sweeps}} \\sum_{\\ell} T^{(\\mathrm{sched})}(p)}{T_{\\mathrm{total}}(p)}$\n    $F_{\\mathrm{plim}} = \\frac{L_{\\mathrm{total}}(p)}{T_{\\mathrm{total}}(p)}$\n\nFor the special case of $p=1$, the overheads $T^{(\\mathrm{bar})}(1)$, $T^{(\\mathrm{sched})}(1)$, and $L_\\ell(1)$ are all zero. Consequently, $S=1$, $E=1$, and all overhead fractions are $0$.\n\nThis complete procedure will be implemented and applied to each test case specified in the problem statement.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes parallel performance metrics for a multigrid V-cycle smoother\n    based on a provided analytical performance model.\n    \"\"\"\n\n    # --- Fixed Parameters ---\n    W_F = 10.0  # FLOPs per point update\n    W_M = 48.0  # Bytes per point update\n    N_SWEEPS = 3.0  # n_sweeps = nu_1 + nu_2 = 2 + 1\n    F_CORE = 2.0e9  # FLOPS per core per second\n    B = 4.0e10  # Bytes per second (memory bandwidth)\n    TAU_B = 2.0e-6  # seconds (barrier latency)\n    TAU_L = 5.0e-6  # seconds (scheduling latency)\n\n    # --- Test Suite ---\n    test_cases = [\n        (512, 1),\n        (512, 4),\n        (512, 16),\n        (128, 16),\n        (32, 64),\n    ]\n\n    def calculate_performance_components(n0, p):\n        \"\"\"\n        Calculates total time and overhead components for a given n0 and p.\n        \"\"\"\n        # Generate grid hierarchy\n        n_levels = []\n        n_current = n0\n        if n_current > 0:\n            n_levels.append(n_current)\n        while n_current > 2:\n            n_next = max(2, n_current // 2)\n            if n_next  n_current:\n                n_levels.append(n_next)\n                n_current = n_next\n            else:\n                break\n        \n        num_levels = len(n_levels)\n        total_time = 0.0\n        total_loss_plim = 0.0\n        \n        # Overheads are independent of level, calculated once\n        t_bar_p = 2.0 * TAU_B if p > 1 else 0.0\n        t_sched_p = 2.0 * TAU_L if p > 1 else 0.0\n\n        for n_l in n_levels:\n            N_l = float(n_l**2)\n            \n            # Concurrency\n            c_l_p = min(p, N_l / 2.0)\n            \n            # Compute-limited time\n            # Handle c_l_p = 0 case for very small grids (Nl=1, not possible here as min n_l is 2)\n            t_comp_l_p = (N_l * W_F) / (F_CORE * c_l_p) if c_l_p > 0 else float('inf')\n            \n            # Memory-limited time\n            t_mem_l = (N_l * W_M) / B\n            \n            # Base sweep time\n            t_base_l_p = max(t_comp_l_p, t_mem_l)\n            \n            # Total sweep time per level\n            t_l_p = t_base_l_p + t_bar_p + t_sched_p\n            total_time += t_l_p\n            \n            # Parallelism-limit loss\n            if t_comp_l_p >= t_mem_l:\n                t_comp_ideal_l_p = (N_l * W_F) / (F_CORE * p) if p > 0 else float('inf')\n                loss_l_p = t_comp_l_p - t_comp_ideal_l_p\n                total_loss_plim += loss_l_p\n\n        total_time *= N_SWEEPS\n        total_loss_plim *= N_SWEEPS\n        \n        total_barrier_time = N_SWEEPS * num_levels * t_bar_p\n        total_sched_time = N_SWEEPS * num_levels * t_sched_p\n\n        return total_time, total_barrier_time, total_sched_time, total_loss_plim\n\n    results = []\n    for n0, p in test_cases:\n        if p == 1:\n            # For p=1, S=1, E=1, and all overhead fractions are 0 by definition\n            results.append([1.0, 1.0, 0.0, 0.0, 0.0])\n            continue\n            \n        # Calculate for p=1 (serial baseline)\n        T_total_1, _, _, _ = calculate_performance_components(n0, 1)\n\n        # Calculate for given p\n        T_total_p, T_bar_total, T_sched_total, L_plim_total = calculate_performance_components(n0, p)\n        \n        if T_total_p == 0: # Avoid division by zero\n            S = 0.0\n            E = 0.0\n            F_bar = 0.0\n            F_sched = 0.0\n            F_plim = 0.0\n        else:\n            S = T_total_1 / T_total_p\n            E = S / p\n            F_bar = T_bar_total / T_total_p\n            F_sched = T_sched_total / T_total_p\n            F_plim = L_plim_total / T_total_p\n            \n        results.append([S, E, F_bar, F_sched, F_plim])\n\n    # Format output as specified\n    formatted_results = []\n    for res_list in results:\n        formatted_numbers = [f\"{v:.6f}\" for v in res_list]\n        formatted_results.append(f\"[{','.join(formatted_numbers)}]\")\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\n\nsolve()\n```", "id": "2415818"}, {"introduction": "The principles of multigrid are not confined to structured, geometric grids. This final practice [@problem_id:2415820] explores how similar mathematical structures arise in entirely different domains, such as force-directed graph drawing. By setting up the energy minimization problem, you will derive a linear system involving a graph Laplacian, an operator analogous to the familiar grid-based Laplacian. This exercise highlights the broad applicability of multigrid concepts and serves as an introduction to the world of Algebraic Multigrid (AMG), which extends these powerful solution techniques to unstructured problems.", "problem": "You are given an undirected simple graph with vertex set $V=\\{0,1,\\dots,N-1\\}$ and edge set $E \\subseteq V \\times V$, a subset of anchored vertices $A \\subset V$ with fixed two-dimensional positions $\\{\\mathbf{g}_i \\in \\mathbb{R}^2 : i \\in A\\}$, and a subset of free vertices $U = V \\setminus A$ whose positions are unknown. Consider the quadratic energy\n$$\n\\mathcal{E}(\\{\\mathbf{p}_i\\}_{i \\in V}) \\;=\\; \\frac{k_a}{2} \\sum_{(i,j)\\in E} \\|\\mathbf{p}_i - \\mathbf{p}_j\\|_2^2 \\;+\\; \\frac{k_r}{2}\\sum_{i\\in V} \\|\\mathbf{p}_i - \\bar{\\mathbf{p}}\\|_2^2,\n$$\nwhere $k_a \\ge 0$ and $k_r \\ge 0$ are given real parameters, and $\\bar{\\mathbf{p}} = \\frac{1}{N}\\sum_{i\\in V}\\mathbf{p}_i$ is the centroid. The positions $\\{\\mathbf{p}_i\\}$ are constrained by $\\mathbf{p}_i = \\mathbf{g}_i$ for all $i \\in A$. Let $\\mathbf{L}\\in\\mathbb{R}^{N\\times N}$ be the unnormalized graph Laplacian with entries $L_{ii}=\\deg(i)$ and $L_{ij}=-1$ if $(i,j)\\in E$, and $L_{ij}=0$ otherwise, and let $\\mathbf{J}\\in\\mathbb{R}^{N\\times N}$ be the all-ones matrix. Show that the stationary conditions for the free vertices yield a linear system of the form\n$$\n\\Big(k_a\\,\\mathbf{L} + k_r\\big(\\mathbf{I} - \\tfrac{1}{N}\\mathbf{J}\\big)\\Big)_{UU}\\,\\mathbf{p}_U \\;=\\; -\\Big(k_a\\,\\mathbf{L} + k_r\\big(\\mathbf{I} - \\tfrac{1}{N}\\mathbf{J}\\big)\\Big)_{UA}\\,\\mathbf{p}_A,\n$$\nwhere $\\mathbf{p}_U$ and $\\mathbf{p}_A$ stack the unknown and anchored positions, respectively. The two spatial components are independent and satisfy identical scalar linear systems.\n\nYour task is to, for each specified test case, compute the unique minimizer consistent with the anchors and evaluate the total energy $\\mathcal{E}$ at that minimizer. Report the result for each test case as a real number. All computations are non-dimensional and require no physical units.\n\nTest suite:\n- Test case $1$ (one-dimensional path graph with both end anchors and weak centroid repulsion):\n  - Graph: path on $N=5$ vertices with edges $(0,1),(1,2),(2,3),(3,4)$.\n  - Anchors: $A=\\{0,4\\}$ with $\\mathbf{g}_0=(0,0)$ and $\\mathbf{g}_4=(1,0)$.\n  - Parameters: $k_a=1$ and $k_r=0.1$.\n- Test case $2$ (two-dimensional rectangular grid graph with full boundary anchors and no centroid repulsion):\n  - Graph: $5\\times 5$ grid with $N=25$ vertices labeled by $(i,j)$ with $i,j\\in\\{0,1,2,3,4\\}$ and edges between axis-aligned neighbors at unit spacing.\n  - Anchors: all boundary vertices $\\{(i,j): i\\in\\{0,4\\}\\ \\text{or}\\ j\\in\\{0,4\\}\\}$ are fixed to their normalized coordinates in the unit square, i.e., $\\mathbf{g}_{(i,j)}=\\big(i/4,\\; j/4\\big)$. The interior vertices $\\{(i,j): i,j\\in\\{1,2,3\\}\\}$ are free.\n  - Parameters: $k_a=1$ and $k_r=0$.\n- Test case $3$ (one-dimensional path graph with both end anchors and strong centroid repulsion):\n  - Graph: path on $N=3$ vertices with edges $(0,1),(1,2)$.\n  - Anchors: $A=\\{0,2\\}$ with $\\mathbf{g}_0=(0,0)$ and $\\mathbf{g}_2=(1,0)$.\n  - Parameters: $k_a=1$ and $k_r=1$.\n- Test case $4$ (one-dimensional path graph with a single anchor and no centroid repulsion):\n  - Graph: path on $N=2$ vertices with edge $(0,1)$.\n  - Anchors: $A=\\{0\\}$ with $\\mathbf{g}_0=(0,0)$. Vertex $1$ is free.\n  - Parameters: $k_a=1$ and $k_r=0$.\n\nRequired output:\n- For each test case, compute the minimizing configuration $\\{\\mathbf{p}_i\\}$ and evaluate the total energy $\\mathcal{E}$ at that configuration as a real number.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[$\\text{result}_1$,$\\text{result}_2$,$\\text{result}_3$,$\\text{result}_4$]\").\n- Each result must be rounded to exactly $6$ digits after the decimal point. The numeric values in the output must be in decimal form (not scientific notation).\n\nNo methodological assumptions are to be stated or used in the problem statement; the problem is stated purely in terms of minimizing a quadratic energy under linear constraints and reporting the resulting energy values. The final answers for the test cases must be real numbers as specified.", "solution": "The problem as stated is valid. It is a well-posed problem in mathematical optimization, grounded in the physical principle of minimizing a potential energy functional. It is self-contained, objective, and all its components are rigorously defined. I will proceed with the solution.\n\nThe core of the problem is to find the set of positions $\\{\\mathbf{p}_i \\in \\mathbb{R}^2\\}_{i \\in V}$ that minimizes the quadratic energy functional\n$$\n\\mathcal{E}(\\{\\mathbf{p}_i\\}) \\;=\\; \\frac{k_a}{2} \\sum_{(i,j)\\in E} \\|\\mathbf{p}_i - \\mathbf{p}_j\\|_2^2 \\;+\\; \\frac{k_r}{2}\\sum_{i\\in V} \\|\\mathbf{p}_i - \\bar{\\mathbf{p}}\\|_2^2\n$$\nsubject to the constraints $\\mathbf{p}_i = \\mathbf{g}_i$ for all anchored vertices $i \\in A$. The set of free vertices is denoted $U = V \\setminus A$. The positions $\\{\\mathbf{p}_i\\}_{i \\in U}$ are the variables to be optimized.\n\nThe spatial components of the problem are decoupled. The energy functional can be additively separated for the $x$ and $y$ coordinates. Let $\\mathbf{x} \\in \\mathbb{R}^N$ and $\\mathbf{y} \\in \\mathbb{R}^N$ be the vectors of all $x$ and $y$ coordinates, respectively. The total energy is $\\mathcal{E} = \\mathcal{E}_x(\\mathbf{x}) + \\mathcal{E}_y(\\mathbf{y})$, where the form of $\\mathcal{E}_x$ and $\\mathcal{E}_y$ is identical. We will derive the system for the $x$-coordinates; the $y$-coordinates follow analogously.\n$$\n\\mathcal{E}_x(\\mathbf{x}) = \\frac{k_a}{2} \\sum_{(i,j)\\in E} (x_i - x_j)^2 + \\frac{k_r}{2}\\sum_{i\\in V} (x_i - \\bar{x})^2\n$$\nThe first term is a quadratic form involving the graph Laplacian $\\mathbf{L}$. It can be written as $\\frac{k_a}{2} \\mathbf{x}^T \\mathbf{L} \\mathbf{x}$. The second term involves the centroid $\\bar{x} = \\frac{1}{N} \\sum_{j=1}^N x_j = \\frac{1}{N} \\mathbf{1}^T \\mathbf{x}$. This term can be written as $\\frac{k_r}{2} \\|\\mathbf{x} - \\bar{x}\\mathbf{1}\\|_2^2 = \\frac{k_r}{2} \\|\\mathbf{x} - \\frac{1}{N}\\mathbf{J}\\mathbf{x}\\|_2^2$, where $\\mathbf{J}$ is the all-ones matrix. Let $\\mathbf{P} = \\mathbf{I} - \\frac{1}{N}\\mathbf{J}$ be the projection matrix onto the subspace orthogonal to the vector $\\mathbf{1}$. Since $\\mathbf{P}$ is a projection, $\\mathbf{P}^T\\mathbf{P} = \\mathbf{P}$. The second term is thus $\\frac{k_r}{2} \\mathbf{x}^T \\mathbf{P} \\mathbf{x}$.\n\nThe total energy for the $x$-coordinates is therefore\n$$\n\\mathcal{E}_x(\\mathbf{x}) = \\frac{1}{2} \\mathbf{x}^T \\Big(k_a\\mathbf{L} + k_r\\big(\\mathbf{I} - \\tfrac{1}{N}\\mathbf{J}\\big)\\Big) \\mathbf{x} = \\frac{1}{2}\\mathbf{x}^T \\mathbf{M} \\mathbf{x},\n$$\nwhere $\\mathbf{M} = k_a\\mathbf{L} + k_r\\big(\\mathbf{I} - \\tfrac{1}{N}\\mathbf{J}\\big)$.\n\nTo find the minimum, we must solve for the unknown coordinates $\\mathbf{x}_U$ corresponding to the free vertices $U$. Let us partition the vector $\\mathbf{x}$ and matrix $\\mathbf{M}$ according to the sets $U$ and $A$. Let $\\mathbf{x}_U$ be the vector of coordinates for vertices in $U$, and $\\mathbf{x}_A$ be the vector of known coordinates for vertices in $A$.\n$$\n\\mathcal{E}_x(\\mathbf{x}_U) = \\frac{1}{2} \\begin{pmatrix} \\mathbf{x}_U^T  \\mathbf{x}_A^T \\end{pmatrix} \\begin{pmatrix} \\mathbf{M}_{UU}  \\mathbf{M}_{UA} \\\\ \\mathbf{M}_{AU}  \\mathbf{M}_{AA} \\end{pmatrix} \\begin{pmatrix} \\mathbf{x}_U \\\\ \\mathbf{x}_A \\end{pmatrix}\n$$\nExpanding this expression gives\n$$\n\\mathcal{E}_x(\\mathbf{x}_U) = \\frac{1}{2} (\\mathbf{x}_U^T \\mathbf{M}_{UU} \\mathbf{x}_U + 2 \\mathbf{x}_U^T \\mathbf{M}_{UA} \\mathbf{x}_A + \\mathbf{x}_A^T \\mathbf{M}_{AA} \\mathbf{x}_A),\n$$\nwhere we used the symmetry $\\mathbf{M}_{AU} = \\mathbf{M}_{UA}^T$. To find the stationary point, we compute the gradient of $\\mathcal{E}_x$ with respect to $\\mathbf{x}_U$ and set it to zero:\n$$\n\\nabla_{\\mathbf{x}_U} \\mathcal{E}_x = \\mathbf{M}_{UU} \\mathbf{x}_U + \\mathbf{M}_{UA} \\mathbf{x}_A = \\mathbf{0}.\n$$\nThis yields the linear system for the unknown coordinates:\n$$\n\\mathbf{M}_{UU} \\mathbf{x}_U = -\\mathbf{M}_{UA} \\mathbf{x}_A.\n$$\nSince this holds for both $x$ and $y$ coordinates, we can write it in terms of the position vectors, where $\\mathbf{p}_U$ is a $|U|\\times 2$ matrix of unknown positions and $\\mathbf{p}_A$ is a $|A|\\times 2$ matrix of anchored positions:\n$$\n\\mathbf{M}_{UU} \\mathbf{p}_U = -\\mathbf{M}_{UA} \\mathbf{p}_A.\n$$\nThis confirms the form given in the problem statement. The matrix $\\mathbf{M}_{UU}$ is symmetric and positive definite for a connected graph with at least one anchor, guaranteeing a unique solution.\n\nThe algorithm to solve each test case is as follows:\n1. Construct the graph Laplacian $\\mathbf{L}$ from the edge set $E$.\n2. Construct the system matrix $\\mathbf{M} = k_a\\mathbf{L} + k_r(\\mathbf{I} - \\frac{1}{N}\\mathbf{J})$.\n3. Identify the sets of free ($U$) and anchored ($A$) vertices and their corresponding indices.\n4. Extract the submatrices $\\mathbf{M}_{UU}$ and $\\mathbf{M}_{UA}$ and the matrix of anchor positions $\\mathbf{p}_A$.\n5. Solve the linear system $\\mathbf{M}_{UU}\\mathbf{p}_U = -\\mathbf{M}_{UA}\\mathbf{p}_A$ for the unknown positions $\\mathbf{p}_U$.\n6. Reconstruct the full matrix of positions $\\mathbf{p}$ with both free and anchored vertices.\n7. Compute the total energy $\\mathcal{E}$ using the complete set of positions $\\{\\mathbf{p}_i\\}$. This can be efficiently computed as $\\mathcal{E} = \\frac{1}{2} \\mathrm{Tr}(\\mathbf{p}^T \\mathbf{M} \\mathbf{p})$.\n\nThis procedure is applied to each test case.\nFor Test Case 1, a path graph on $N=5$ vertices, the system is solved numerically.\nFor Test Case 2, a $5\\times 5$ grid with boundary anchors and $k_r=0$, the solution can be found by inspection. The minimizer corresponds to a discrete harmonic function, which results in linear interpolation of the boundary positions, i.e., $\\mathbf{p}_{(i,j)}=(i/4, j/4)$. The energy is $\\mathcal{E} = 1.25$.\nFor Test Case 3, a path graph on $N=3$ vertices, the problem has a simple analytical solution $\\mathbf{p}_1 = (1/2, 0)$, yielding an energy of $\\mathcal{E}=0.5$.\nFor Test Case 4, a path graph on $N=2$ vertices with one anchor, the free vertex is pulled to the same position as the anchor, resulting in zero energy, $\\mathcal{E}=0$.\n\nThe numerical results are computed according to the described algorithm.", "answer": "```python\nimport numpy as np\n\ndef compute_energy_for_case(N, edges, anchors, k_a, k_r):\n    \"\"\"\n    Computes the minimum energy for a given graph layout problem.\n\n    Args:\n        N (int): Number of vertices.\n        edges (list of tuples): List of edges in the graph.\n        anchors (dict): Dictionary mapping anchored vertex indices to their (x, y) positions.\n        k_a (float): Spring constant for the attractive term.\n        k_r (float): Repulsion constant for the centroid term.\n\n    Returns:\n        float: The total energy at the minimizing configuration.\n    \"\"\"\n    # 1. Setup indices\n    all_indices = set(range(N))\n    anchor_indices = sorted(list(anchors.keys()))\n    free_indices = sorted(list(all_indices - set(anchor_indices)))\n\n    # 2. Build matrices L and M\n    L = np.zeros((N, N))\n    for i, j in edges:\n        L[i, j] = -1\n        L[j, i] = -1\n        L[i, i] += 1\n        L[j, j] += 1\n    \n    M = k_a * L\n    if k_r > 0:\n        J = np.ones((N, N))\n        M += k_r * (np.identity(N) - J / N)\n    \n    # 3. Partition M and setup linear system\n    num_free = len(free_indices)\n    num_anchors = len(anchor_indices)\n\n    if num_free == 0:\n        p_full = np.zeros((N, 2))\n        p_A = np.array([anchors[i] for i in anchor_indices])\n        p_full[anchor_indices, :] = p_A\n        energy = 0.5 * np.trace(p_full.T @ M @ p_full)\n        return energy\n\n    M_UU = M[np.ix_(free_indices, free_indices)]\n    M_UA = M[np.ix_(free_indices, anchor_indices)]\n    \n    p_A = np.array([anchors[i] for i in anchor_indices])\n    \n    # 4. Solve for free vertex positions\n    if num_anchors > 0:\n        RHS = -M_UA @ p_A\n    else:\n        RHS = np.zeros((num_free, 2))\n        \n    p_U = np.linalg.solve(M_UU, RHS)\n    \n    # 5. Assemble full position matrix\n    p_full = np.zeros((N, 2))\n    p_full[free_indices, :] = p_U\n    p_full[anchor_indices, :] = p_A\n\n    # 6. Calculate total energy\n    energy = 0.5 * np.trace(p_full.T @ M @ p_full)\n    \n    return energy\n\ndef solve():\n    \"\"\"\n    Defines test cases and computes the energy for each, printing the results.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        {\n            \"N\": 5,\n            \"edges\": [(0, 1), (1, 2), (2, 3), (3, 4)],\n            \"anchors\": {0: (0.0, 0.0), 4: (1.0, 0.0)},\n            \"k_a\": 1.0,\n            \"k_r\": 0.1\n        },\n        # Test case 2\n        {\n            \"N\": 25,\n            \"edges\": [\n                (i * 5 + j, i * 5 + j + 1) for i in range(5) for j in range(4)\n            ] + [\n                (i * 5 + j, (i + 1) * 5 + j) for i in range(4) for j in range(5)\n            ],\n            \"anchors\": {\n                i * 5 + j: (i / 4.0, j / 4.0)\n                for i in range(5) for j in range(5)\n                if i in {0, 4} or j in {0, 4}\n            },\n            \"k_a\": 1.0,\n            \"k_r\": 0.0\n        },\n        # Test case 3\n        {\n            \"N\": 3,\n            \"edges\": [(0, 1), (1, 2)],\n            \"anchors\": {0: (0.0, 0.0), 2: (1.0, 0.0)},\n            \"k_a\": 1.0,\n            \"k_r\": 1.0\n        },\n        # Test case 4\n        {\n            \"N\": 2,\n            \"edges\": [(0, 1)],\n            \"anchors\": {0: (0.0, 0.0)},\n            \"k_a\": 1.0,\n            \"k_r\": 0.0\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        energy = compute_energy_for_case(\n            case[\"N\"], case[\"edges\"], case[\"anchors\"], case[\"k_a\"], case[\"k_r\"]\n        )\n        results.append(energy)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```", "id": "2415820"}]}