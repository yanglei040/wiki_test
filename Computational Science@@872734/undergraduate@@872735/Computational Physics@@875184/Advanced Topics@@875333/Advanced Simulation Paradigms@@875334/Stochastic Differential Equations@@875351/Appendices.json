{"hands_on_practices": [{"introduction": "While individual trajectories of a stochastic process are random, their average behavior is often predictable and governed by the drift term of the governing Stochastic Differential Equation (SDE). This exercise serves as a fundamental first step in analyzing SDEs by isolating this deterministic trend. By leveraging the key property that the expectation of an Itô integral is zero, you will calculate the expected future value of a process, learning to separate the predictable evolution from the random fluctuations [@problem_id:1311631].", "problem": "A simplified model for the price, $X_t$, of a certain non-dividend-paying commodity is described by a Stochastic Differential Equation (SDE). The model assumes a baseline drift rate, $a$, and a volatility, $b$. Additionally, a predictable, strengthening market trend causes the drift rate itself to increase linearly with time, at a rate $c$. The dynamics of the commodity price are therefore modeled by the SDE:\n$$dX_t = (a + ct) dt + b dW_t$$\nwhere $t \\ge 0$ is time, $a$, $b$, and $c$ are positive real constants, and $W_t$ is a standard Wiener process representing random market fluctuations. The initial price of the commodity at time $t=0$ is known to be $X_0 = x_0$.\n\nDetermine the expected price of the commodity at a future time $t > 0$, denoted by $\\mathbb{E}[X_t]$, as a function of the parameters $x_0, a, c,$ and $t$.", "solution": "We are given the SDE $dX_{t} = (a + c t)\\,dt + b\\,dW_{t}$ with initial condition $X_{0} = x_{0}$, where $a$, $b$, and $c$ are positive constants and $W_{t}$ is a standard Wiener process with $W_{0} = 0$.\n\nIntegrate both sides from $0$ to $t$:\n$$\nX_{t} - X_{0} = \\int_{0}^{t} (a + c s)\\,ds + b \\int_{0}^{t} dW_{s}.\n$$\nUsing $X_{0} = x_{0}$ and $\\int_{0}^{t} dW_{s} = W_{t}$, this gives\n$$\nX_{t} = x_{0} + \\int_{0}^{t} (a + c s)\\,ds + b W_{t}.\n$$\n\nTake expectations on both sides and use linearity of expectation together with the property that for an adapted square-integrable integrand, the Itô integral has zero mean, specifically $\\mathbb{E}\\!\\left[\\int_{0}^{t} b\\,dW_{s}\\right] = 0$ (equivalently $\\mathbb{E}[W_{t}] = 0$):\n$$\n\\mathbb{E}[X_{t}] = x_{0} + \\int_{0}^{t} (a + c s)\\,ds.\n$$\n\nEvaluate the deterministic integral:\n$$\n\\int_{0}^{t} (a + c s)\\,ds = \\int_{0}^{t} a\\,ds + \\int_{0}^{t} c s\\,ds = a t + \\frac{1}{2} c t^{2}.\n$$\n\nTherefore,\n$$\n\\mathbb{E}[X_{t}] = x_{0} + a t + \\frac{1}{2} c t^{2}.\n$$", "answer": "$$\\boxed{x_{0} + a t + \\frac{1}{2} c t^{2}}$$", "id": "1311631"}, {"introduction": "In many physical systems, we are interested in a quantity that is a function of another variable undergoing random motion, such as deriving the kinetic energy from a particle's stochastic velocity. This requires a special tool, Itô's Lemma, which serves as the chain rule for stochastic calculus and introduces a correction term that has no counterpart in deterministic calculus. This hands-on practice provides essential experience in applying Itô's Lemma to the famous Langevin equation, a cornerstone of statistical physics, to see how random fluctuations systematically affect the dynamics of related physical quantities [@problem_id:1311625].", "problem": "The one-dimensional motion of a nanoparticle suspended in a fluid at thermal equilibrium can be modeled using the Langevin equation. The velocity of the particle, $V_t$, is described by a stochastic process that accounts for both viscous drag from the fluid and random thermal kicks from surrounding molecules. This process is governed by the following Stochastic Differential Equation (SDE):\n$$dV_t = -\\gamma V_t dt + \\sigma dW_t$$\nHere, $V_t$ is the particle's velocity at time $t$, $\\gamma$ is a positive constant representing the drag coefficient, $\\sigma$ is a positive constant representing the magnitude of the random thermal forces, and $W_t$ is a standard Wiener process (Brownian motion).\n\nThe specific kinetic energy of the particle (kinetic energy per unit mass) is given by $K_t = \\frac{1}{2}V_t^2$. The evolution of this specific kinetic energy over time can also be described by an SDE of the form:\n$$dK_t = \\mu(V_t) dt + \\eta(V_t) dW_t$$\nwhere $\\mu(V_t)$ is the drift coefficient and $\\eta(V_t)$ is the diffusion coefficient, both of which may depend on the velocity $V_t$.\n\nYour task is to find the expressions for the drift coefficient $\\mu(V_t)$ and the diffusion coefficient $\\eta(V_t)$ for the specific kinetic energy process $K_t$. Present your answer as a pair of expressions $(\\mu(V_t), \\eta(V_t))$.", "solution": "We start from the given SDE for the velocity:\n$$dV_{t} = -\\gamma V_{t}\\,dt + \\sigma\\,dW_{t}.$$\nDefine the specific kinetic energy as\n$$K_{t} = \\frac{1}{2}V_{t}^{2}.$$\nApply Itô's lemma to the function $f(v) = \\frac{1}{2}v^{2}$. Its first and second derivatives are\n$$f'(v) = v, \\qquad f''(v) = 1.$$\nFor a one-dimensional Itô process $dV_{t} = a(V_{t},t)\\,dt + b(V_{t},t)\\,dW_{t}$, Itô's lemma gives\n$$df(V_{t}) = f'(V_{t})\\,dV_{t} + \\frac{1}{2}f''(V_{t})\\,(dV_{t})^{2},$$\nusing the Itô rules $(dW_{t})^{2} = dt$, $dt\\,dW_{t} = 0$, and $(dt)^{2} = 0$. Here, $a(V_{t},t) = -\\gamma V_{t}$ and $b(V_{t},t) = \\sigma$, so\n$$(dV_{t})^{2} = \\sigma^{2}\\,dt.$$\nTherefore,\n$$dK_{t} = f'(V_{t})\\,dV_{t} + \\frac{1}{2}f''(V_{t})\\,(dV_{t})^{2} = V_{t}\\left(-\\gamma V_{t}\\,dt + \\sigma\\,dW_{t}\\right) + \\frac{1}{2}\\cdot 1 \\cdot \\sigma^{2}\\,dt.$$\nCollecting terms yields\n$$dK_{t} = \\left(-\\gamma V_{t}^{2} + \\frac{1}{2}\\sigma^{2}\\right)dt + \\sigma V_{t}\\,dW_{t}.$$\nBy identification with $dK_{t} = \\mu(V_{t})\\,dt + \\eta(V_{t})\\,dW_{t}$, we obtain\n$$\\mu(V_{t}) = -\\gamma V_{t}^{2} + \\frac{1}{2}\\sigma^{2}, \\qquad \\eta(V_{t}) = \\sigma V_{t}.$$", "answer": "$$\\boxed{\\begin{pmatrix}-\\gamma V_{t}^{2} + \\frac{1}{2}\\sigma^{2} & \\sigma V_{t}\\end{pmatrix}}$$", "id": "1311625"}, {"introduction": "Most real-world SDEs cannot be solved with pen and paper, making numerical simulation an essential tool for the computational scientist. The Euler-Maruyama method is the most straightforward numerical scheme, but its application is not without subtleties, as the presence of stochastic noise introduces unique stability challenges. This exercise bridges the gap between theory and computation by asking you to analyze the mean-square stability of this method, revealing how the interplay between the drift and diffusion terms imposes critical constraints on the simulation time step, $\\Delta t$, for the numerical solution to remain meaningful [@problem_id:1710321].", "problem": "A stochastic model for a certain quantity $X_t$ is described by the scalar linear Stochastic Differential Equation (SDE):\n$$\ndX_t = \\lambda X_t dt + \\mu X_t dW_t\n$$\nwhere $t$ is time, $X_0$ is the non-zero initial value, $W_t$ is a standard Wiener process, and $\\lambda$ and $\\mu$ are real constants with $\\lambda \\neq 0$. The parameters $\\lambda$ and $\\mu$ are such that the exact solution $X_t$ is mean-square stable, meaning $\\lim_{t \\to \\infty} \\mathbb{E}[X_t^2] = 0$.\n\nTo approximate the solution numerically, the explicit Euler-Maruyama (EM) method is applied with a constant time step $\\Delta t > 0$, generating a sequence of approximations $\\{X_n\\}_{n \\geq 0}$ where $X_n \\approx X(n\\Delta t)$. The EM method is said to be mean-square stable if the sequence of second moments of the numerical solution, $\\mathbb{E}[X_n^2]$, converges to zero as $n \\to \\infty$.\n\nDetermine the maximum allowable time step, $\\Delta t_{max}$, for which the EM scheme is guaranteed to be mean-square stable. Express your answer as a single analytic expression in terms of $\\lambda$ and $\\mu$.", "solution": "The given Stochastic Differential Equation (SDE) is $dX_t = \\lambda X_t dt + \\mu X_t dW_t$.\nThe explicit Euler-Maruyama (EM) scheme for a general SDE $dY_t = a(t, Y_t) dt + b(t, Y_t) dW_t$ is given by $Y_{n+1} = Y_n + a(t_n, Y_n) \\Delta t + b(t_n, Y_n) \\Delta W_n$, where $\\Delta t = t_{n+1} - t_n$ and $\\Delta W_n = W_{t_{n+1}} - W_{t_n}$. The increments of the Wiener process $\\Delta W_n$ are independent and identically distributed normal random variables with mean $\\mathbb{E}[\\Delta W_n] = 0$ and variance $\\mathbb{E}[(\\Delta W_n)^2] = \\Delta t$.\n\nApplying the EM scheme to the specific SDE in the problem, we get the discrete-time update rule:\n$$\nX_{n+1} = X_n + \\lambda X_n \\Delta t + \\mu X_n \\Delta W_n\n$$\nWe can factor out $X_n$ to write this as:\n$$\nX_{n+1} = X_n (1 + \\lambda \\Delta t + \\mu \\Delta W_n)\n$$\nTo analyze the mean-square stability, we need to examine the evolution of the second moment, $\\mathbb{E}[X_n^2]$. We start by squaring the expression for $X_{n+1}$:\n$$\nX_{n+1}^2 = X_n^2 (1 + \\lambda \\Delta t + \\mu \\Delta W_n)^2\n$$\nExpanding the squared term gives:\n$$\nX_{n+1}^2 = X_n^2 (1 + \\lambda^2 (\\Delta t)^2 + \\mu^2 (\\Delta W_n)^2 + 2\\lambda \\Delta t + 2\\mu \\Delta W_n + 2\\lambda\\mu \\Delta t \\Delta W_n)\n$$\nNow, we take the expectation of both sides. It is most rigorous to first take the conditional expectation with respect to the filtration $\\mathcal{F}_{t_n}$ (the information available up to time $t_n$). Since $X_n$ and $\\Delta t$ are known at time $t_n$, they can be treated as constants inside the conditional expectation. The increment $\\Delta W_n$ is independent of $\\mathcal{F}_{t_n}$.\n$$\n\\mathbb{E}[X_{n+1}^2 | \\mathcal{F}_{t_n}] = X_n^2 \\mathbb{E}[(1 + \\lambda^2 (\\Delta t)^2 + \\mu^2 (\\Delta W_n)^2 + 2\\lambda \\Delta t + 2\\mu \\Delta W_n + 2\\lambda\\mu \\Delta t \\Delta W_n) | \\mathcal{F}_{t_n}]\n$$\nUsing the linearity of expectation and the properties $\\mathbb{E}[\\Delta W_n | \\mathcal{F}_{t_n}] = \\mathbb{E}[\\Delta W_n] = 0$ and $\\mathbb{E}[(\\Delta W_n)^2 | \\mathcal{F}_{t_n}] = \\mathbb{E}[(\\Delta W_n)^2] = \\Delta t$, we get:\n$$\n\\mathbb{E}[X_{n+1}^2 | \\mathcal{F}_{t_n}] = X_n^2 (1 + \\lambda^2 (\\Delta t)^2 + \\mu^2 \\Delta t + 2\\lambda \\Delta t + 0 + 0)\n$$\n$$\n\\mathbb{E}[X_{n+1}^2 | \\mathcal{F}_{t_n}] = X_n^2 (1 + 2\\lambda \\Delta t + \\lambda^2 (\\Delta t)^2 + \\mu^2 \\Delta t)\n$$\nUsing the law of total expectation, $\\mathbb{E}[Y] = \\mathbb{E}[\\mathbb{E}[Y | \\mathcal{G}]]$, we have:\n$$\n\\mathbb{E}[X_{n+1}^2] = \\mathbb{E}[\\mathbb{E}[X_{n+1}^2 | \\mathcal{F}_{t_n}]] = \\mathbb{E}[X_n^2 (1 + 2\\lambda \\Delta t + \\lambda^2 (\\Delta t)^2 + \\mu^2 \\Delta t)]\n$$\nSince the term in the parentheses is constant, we can pull it out of the outer expectation:\n$$\n\\mathbb{E}[X_{n+1}^2] = (1 + 2\\lambda \\Delta t + \\lambda^2 (\\Delta t)^2 + \\mu^2 \\Delta t) \\mathbb{E}[X_n^2]\n$$\nThis is a geometric recurrence relation for the sequence of second moments. Let the amplification factor be $R(\\Delta t) = 1 + 2\\lambda \\Delta t + \\lambda^2 (\\Delta t)^2 + \\mu^2 \\Delta t$.\nFor the numerical scheme to be mean-square stable, we require $\\lim_{n \\to \\infty} \\mathbb{E}[X_n^2] = 0$. This holds if and only if the magnitude of the amplification factor is less than one, i.e., $|R(\\Delta t)| < 1$.\n\nWe can rewrite $R(\\Delta t)$ as:\n$$\nR(\\Delta t) = (1 + \\lambda \\Delta t)^2 + \\mu^2 \\Delta t\n$$\nSince $(\\Delta t) > 0$ and $\\mu^2 \\geq 0$, the term $\\mu^2 \\Delta t$ is non-negative. Also, $(1 + \\lambda \\Delta t)^2$ is non-negative. Therefore, $R(\\Delta t) \\geq 0$. The stability condition $|R(\\Delta t)| < 1$ simplifies to $R(\\Delta t) < 1$.\n$$\n1 + 2\\lambda \\Delta t + \\lambda^2 (\\Delta t)^2 + \\mu^2 \\Delta t < 1\n$$\nSubtracting 1 from both sides gives:\n$$\n2\\lambda \\Delta t + \\lambda^2 (\\Delta t)^2 + \\mu^2 \\Delta t < 0\n$$\nSince $\\Delta t > 0$, we can divide by $\\Delta t$ without changing the inequality's direction:\n$$\n2\\lambda + \\lambda^2 \\Delta t + \\mu^2 < 0\n$$\nNow, we solve for $\\Delta t$. Rearranging the terms, we get:\n$$\n\\lambda^2 \\Delta t < -2\\lambda - \\mu^2\n$$\nFor this inequality to have any solution for $\\Delta t > 0$, the right-hand side must be positive, which means $-2\\lambda - \\mu^2 > 0$, or $2\\lambda + \\mu^2 < 0$. This is precisely the condition for the exact SDE to be mean-square stable, which was given in the problem statement.\nSince the problem states that $\\lambda \\neq 0$, we have $\\lambda^2 > 0$. We can divide by $\\lambda^2$ to isolate $\\Delta t$:\n$$\n\\Delta t < \\frac{-2\\lambda - \\mu^2}{\\lambda^2}\n$$\nThe right-hand side of this inequality represents the upper bound on the time step for mean-square stability. Therefore, the maximum allowable time step is:\n$$\n\\Delta t_{max} = \\frac{-2\\lambda - \\mu^2}{\\lambda^2}\n$$", "answer": "$$\\boxed{\\frac{-2\\lambda - \\mu^{2}}{\\lambda^{2}}}$$", "id": "1710321"}]}