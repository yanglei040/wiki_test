{"hands_on_practices": [{"introduction": "To truly appreciate why pivoting is not just an optional extra but a cornerstone of numerical stability, we must first confront the pitfalls of finite-precision arithmetic. This first exercise [@problem_id:2193047] simulates a scenario using simplified \"chopping\" arithmetic to demonstrate how a seemingly innocuous system can yield wildly inaccurate results without pivoting. By working through this problem, you will witness firsthand the dramatic improvement in accuracy when a proper pivot strategy is employed.", "problem": "Consider the following system of linear equations:\n$$\n\\begin{align*}\n(2.00 \\times 10^{-4}) x_1 + 2.00 x_2 &= 4.00 \\\\\n1.00 x_1 + 3.00 x_2 &= 5.00\n\\end{align*}\n$$\nYou are to solve this system using Gaussian elimination, but all calculations must be performed using a simplified floating-point representation known as **three-digit chopping arithmetic**. In this arithmetic system, numbers are first written in normalized decimal form, $\\pm 0.d_1d_2d_3d_4... \\times 10^n$, where $d_1 \\in \\{1, 2, \\dots, 9\\}$. The number is then stored by \"chopping off\" all digits after the third, resulting in the form $\\pm 0.d_1d_2d_3 \\times 10^n$. This chopping occurs after every individual arithmetic operation (addition, subtraction, multiplication, division).\n\nCalculate the solution vector $\\mathbf{x} = [x_1, x_2]^T$ using Gaussian elimination **with partial pivoting**. Express your final answer as the two components of the solution vector.", "solution": "We apply Gaussian elimination with partial pivoting under three-digit chopping arithmetic (store numbers in normalized form with three significant digits after each operation).\n\nStart with the augmented matrix\n$$\n\\left[\\begin{array}{cc|c}\n2.00\\times 10^{-4} & 2.00 & 4.00\\\\\n1.00 & 3.00 & 5.00\n\\end{array}\\right].\n$$\nPartial pivoting on column 1 compares $|2.00\\times 10^{-4}|$ and $|1.00|$, so we swap the two rows:\n$$\n\\left[\\begin{array}{cc|c}\n1.00 & 3.00 & 5.00\\\\\n2.00\\times 10^{-4} & 2.00 & 4.00\n\\end{array}\\right].\n$$\nElimination multiplier\n$$\n\\ell_{21}=\\text{chop}_{3}\\left(\\frac{2.00\\times 10^{-4}}{1.00}\\right)=2.00\\times 10^{-4}.\n$$\nUpdate row 2 entries with chopping after each operation:\n- New $a_{21}$:\n$$\n\\text{chop}_{3}\\left(2.00\\times 10^{-4}-\\ell_{21}\\cdot 1.00\\right)=\\text{chop}_{3}\\left(2.00\\times 10^{-4}-2.00\\times 10^{-4}\\right)=0.\n$$\n- New $a_{22}$:\n$$\n\\ell_{21}\\cdot a_{12}=\\text{chop}_{3}\\left((2.00\\times 10^{-4})\\cdot 3.00\\right)=6.00\\times 10^{-4},\n$$\n$$\na_{22}^{(new)}=\\text{chop}_{3}\\left(2.00-6.00\\times 10^{-4}\\right)=\\text{chop}_{3}(1.9994)=1.99.\n$$\n- New $b_{2}$:\n$$\n\\ell_{21}\\cdot b_{1}=\\text{chop}_{3}\\left((2.00\\times 10^{-4})\\cdot 5.00\\right)=1.00\\times 10^{-3},\n$$\n$$\nb_{2}^{(new)}=\\text{chop}_{3}\\left(4.00-1.00\\times 10^{-3}\\right)=\\text{chop}_{3}(3.999)=3.99.\n$$\nThe upper triangular system is thus\n$$\n\\begin{cases}\n1.00\\,x_{1}+3.00\\,x_{2}=5.00,\\\\\n1.99\\,x_{2}=3.99.\n\\end{cases}\n$$\nBack substitution with chopping after each operation:\n$$\nx_{2}=\\text{chop}_{3}\\left(\\frac{3.99}{1.99}\\right)=\\text{chop}_{3}(2.005025\\ldots)=2.00.\n$$\nThen\n$$\na_{12}\\,x_{2}=\\text{chop}_{3}(3.00\\cdot 2.00)=6.00,\\quad\nb_{1}-a_{12}x_{2}=\\text{chop}_{3}(5.00-6.00)=-1.00,\n$$\n$$\nx_{1}=\\text{chop}_{3}\\left(\\frac{-1.00}{1.00}\\right)=-1.00.\n$$\nTherefore, under three-digit chopping arithmetic with partial pivoting, the solution vector is $x_{1}=-1.00$ and $x_{2}=2.00$.", "answer": "$$\\boxed{\\begin{pmatrix} -1.00 \\\\ 2.00 \\end{pmatrix}}$$", "id": "2193047"}, {"introduction": "Having seen the dangers of finite-precision arithmetic, we now shift our focus to the pure algebraic structure of Gaussian elimination. In this exercise [@problem_id:2397350], you will implement the algorithm from scratch using exact rational arithmetic, completely removing round-off error. This will allow you to solve notoriously ill-conditioned systems like the Hilbert matrix perfectly and build a deep, mechanical understanding of how partial pivoting works in an idealized, error-free setting.", "problem": "You are to design and implement a robust solver for square linear systems using Gaussian elimination (GE) with partial pivoting (PP) carried out in exact rational arithmetic. The goal is to eliminate roundoff error altogether by representing every entry as a rational number and to use pivoting to ensure correct row selection and reliable singularity detection for ill-conditioned systems. You must start from the fundamental definition of a linear system and the invariance of the solution set under elementary row operations. Do not introduce any floating-point approximations in the elimination or back-substitution phases; all computations must be performed exactly using rational numbers.\n\nFundamental base and setting: A square linear system is given by $A \\, x = b$, where $A \\in \\mathbb{Q}^{n \\times n}$ and $b \\in \\mathbb{Q}^{n}$. Two systems related by elementary row operations have the same solution set. Gaussian elimination applies a finite sequence of row permutations, row scalings, and row additions to reduce the system to an upper triangular form, after which back substitution recovers a solution if the system is nonsingular. Partial pivoting selects, at each column $k$, a row from indices $i \\in \\{k, k+1, \\dots, n-1\\}$ with a pivot entry of maximal absolute value in that column and swaps it into position $k$ before elimination, which avoids division by zero and mitigates the effect of small pivots. In exact rational arithmetic, pivoting also provides a principled way to detect singularity by counting the number of nonzero pivots.\n\nYour implementation requirements:\n- Implement Gaussian elimination with partial pivoting using exact rational arithmetic for all matrix and vector entries. Represent all numbers as rationals, and ensure that every division is exact in the field $\\mathbb{Q}$.\n- At each step $k$, choose a pivot row with maximal $|A_{ik}|$ for $i \\ge k$. If the maximal value is $0$, declare the column $k$ as having no pivot and continue with the next column to enable rank computation. Track the number of nonzero pivots to obtain the rank.\n- If the system is of full rank $n$, perform exact back substitution to compute the unique solution $x \\in \\mathbb{Q}^{n}$. If the system is rank-deficient, report the computed rank $r < n$ and do not attempt to produce one particular solution.\n\nTest suite:\nImplement your solver and run it on the following four test cases. All matrices $A$ and vectors $b$ must be constructed exactly over $\\mathbb{Q}$, and all right-hand sides $b$ are to be formed exactly as specified.\n\n- Test case $1$ (happy path, ill-conditioned but nonsingular): Let $n = 5$, let $A$ be the Hilbert matrix with entries $A_{ij} = 1/(i+j-1)$ for $i,j \\in \\{1,2,3,4,5\\}$, and let the exact solution be $x^{\\star} = [1,1,1,1,1]^{\\top}$. Construct $b = A \\, x^{\\star}$ exactly in $\\mathbb{Q}^{n}$.\n- Test case $2$ (harder ill-conditioned, nonsingular): Let $n = 7$, let $A$ be the Hilbert matrix with entries $A_{ij} = 1/(i+j-1)$ for $i,j \\in \\{1,2,3,4,5,6,7\\}$, and let the exact solution be $x^{\\star} = [1,-1,1,-1,1,-1,1]^{\\top}$. Construct $b = A \\, x^{\\star}$ exactly.\n- Test case $3$ (singular but consistent): Let $A$ be the $3 \\times 3$ matrix with rows $[1,2,3]$, $[2,4,6]$, $[1,2,3]$, and let $b = [6,12,6]^{\\top}$. This system has infinitely many solutions; your solver must detect singularity and report the rank.\n- Test case $4$ (boundary singular case): Let $A$ be the $1 \\times 1$ matrix $[0]$ and let $b = [0]$. This system is consistent with infinitely many solutions; your solver must report the rank.\n\nRequired outputs for each test case:\n- For test cases $1$ and $2$: Produce a list of three items $[\\text{ok}, r_{\\infty}, e_{\\infty}]$, where $\\text{ok}$ is a boolean that is true if and only if the computed exact solution $x$ matches $x^{\\star}$ entrywise in $\\mathbb{Q}$ without any discrepancy, $r_{\\infty} = \\max_{i} |(A x - b)_{i}|$ is the maximum absolute residual reported as a floating-point number, and $e_{\\infty} = \\max_{i} |(x - x^{\\star})_{i}|$ is the maximum absolute error reported as a floating-point number.\n- For test cases $3$ and $4$: Produce the integer rank $r$ of the matrix $A$ computed by counting nonzero pivots during elimination with partial pivoting.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The line must contain four entries in order, corresponding to test cases $1$ through $4$. The first two entries must each be a list as specified above, and the last two entries must be integers. For example, an admissible format is $[[\\text{True}, 0.0, 0.0],[\\text{True}, 0.0, 0.0],1,0]$. No physical units are involved in this problem, and no angles are used.\n\nConstraints:\n- You must not use floating-point arithmetic anywhere in the elimination or back-substitution logic. All arithmetic in the solver must be done over $\\mathbb{Q}$.\n- You must implement partial pivoting and rank detection as described. You must not rely on external linear algebra solvers or symbolic algebra systems.", "solution": "The problem requires the design and implementation of a solver for square linear systems $A x = b$, where the matrix $A \\in \\mathbb{Q}^{n \\times n}$ and the vector $b \\in \\mathbb{Q}^{n}$ are defined over the field of rational numbers. The solution must employ Gaussian elimination with partial pivoting (GE-PP), with all arithmetic performed exactly in $\\mathbb{Q}$ to preclude any roundoff error.\n\nThe fundamental principle is that the solution set of a linear system is invariant under elementary row operations. Gaussian elimination systematically applies these operations—row swapping, row scaling, and adding a multiple of one row to another—to transform the original system into an equivalent, but more easily solved, upper triangular form.\n\nOur methodology is as follows:\n\nFirst, we represent all numerical values as rational numbers. Python's `fractions.Fraction` class is suitable for this, as it performs exact arithmetic on objects representing fractions $\\frac{p}{q}$ where $p$ and $q$ are integers. This approach completely circumvents the precision and stability issues inherent in floating-point arithmetic, which is particularly critical for the ill-conditioned Hilbert matrices in the test suite.\n\nThe algorithm operates on the augmented matrix $[A|b]$. It proceeds via two main phases: forward elimination and back substitution.\n\nThe forward elimination phase aims to reduce the matrix $A$ to row echelon form. The process iterates through the columns $k$ from $0$ to $n-1$. At each step, we determine the rank of the matrix processed so far, denoted by a variable `rank`.\n$1$. **Pivoting**: For the current column $k$, we search for the entry with the maximum absolute value in rows $i \\ge \\text{rank}$. Let this pivot entry be $A_{p,k}$. We then swap the entire row $p$ with row `rank`. This is partial pivoting. Its purpose in exact arithmetic is to handle zero pivots systematically and provide a consistent method for rank determination.\n$2$. **Rank Determination**: If the selected pivot element is zero, it implies that column $k$ is linearly dependent on the preceding pivot columns. In this case, no elimination is performed for this column, the rank is not incremented, and the algorithm proceeds to the next column $k+1$.\n$3$. **Elimination**: If the pivot $A_{\\text{rank},k}$ is non-zero, we use it to eliminate all entries below it in the same column. For each row $i > \\text{rank}$, we compute a multiplier $m_{i,k} = A_{i,k} / A_{\\text{rank},k}$. This division is exact. We then update the row via the operation $R_i \\leftarrow R_i - m_{i,k} R_{\\text{rank}}$. This operation is applied to the entire augmented row, from column $k$ to the end. After elimination for column $k$ is complete, we increment the rank, `rank` $\\leftarrow$ `rank` $+ 1$.\n\nAfter the forward elimination process finishes, the variable `rank` holds the rank of the matrix $A$.\n\nThe solution phase depends on the computed rank.\n- **Singular Case**: If $\\text{rank} < n$, the matrix $A$ is singular. The system may have no solution or infinitely many solutions. As per the problem specification, we do not attempt to find a solution but instead report the computed rank $r = \\text{rank}$. This is the outcome for Test Cases $3$ and $4$.\n- **Nonsingular Case**: If $\\text{rank} = n$, the matrix is of full rank. The forward elimination has produced an equivalent system where the matrix is upper triangular with a non-zero diagonal. A unique solution $x \\in \\mathbb{Q}^{n}$ exists and is found using back substitution. Starting from the last variable, $x_{n-1}$, we solve for each $x_i$ iteratively:\n$$x_{n-1} = \\frac{b_{n-1}}{A_{n-1,n-1}}$$\n$$x_i = \\frac{1}{A_{ii}} \\left( b_i - \\sum_{j=i+1}^{n-1} A_{ij} x_j \\right) \\quad \\text{for } i = n-2, n-3, \\dots, 0$$\nAll calculations in this phase are also exact. This path is followed for Test Cases $1$ and $2$.\n\nFor the nonsingular test cases, we must verify the computed solution. The problem provides the exact solution $x^{\\star}$. We verify our computed solution $x$ by checking if $x = x^{\\star}$ entrywise. Since all arithmetic is exact, the two must be identical. We then compute two metrics: the maximum absolute residual $r_{\\infty} = \\max_{i} |(A x - b)_{i}|$ and the maximum absolute error $e_{\\infty} = \\max_{i} |(x - x^{\\star})_{i}|$. These quantities are calculated exactly as rational numbers and then converted to floating-point numbers for the final report. Given the exactness of the solver, we expect both $r_{\\infty}$ and $e_{\\infty}$ to be $0.0$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom fractions import Fraction\nimport copy\n\ndef GEPP_rational(A_in, b_in):\n    \"\"\"\n    Solves a linear system Ax=b using Gaussian elimination with partial pivoting\n    in exact rational arithmetic.\n\n    Args:\n        A_in (list of lists): The matrix A.\n        b_in (list): The vector b.\n\n    Returns:\n        tuple: A tuple containing a status string ('nonsingular' or 'singular')\n               and a payload (the solution vector x or the rank).\n    \"\"\"\n    n = len(A_in)\n    # Create an augmented matrix with Fraction objects.\n    # A deep copy is used to avoid modifying inputs.\n    Ab = []\n    for i in range(n):\n        row = [Fraction(x) for x in A_in[i]] + [Fraction(b_in[i])]\n        Ab.append(row)\n\n    rank = 0\n    # Forward elimination phase\n    for k in range(n):  # Iterate through columns\n        if rank == n:\n            break\n\n        # Find pivot in column k, from row 'rank' downwards\n        i_max = rank\n        v_max = abs(Ab[rank][k])\n        for i in range(rank + 1, n):\n            if abs(Ab[i][k]) > v_max:\n                v_max = abs(Ab[i][k])\n                i_max = i\n\n        # If maximal pivot in this column (in the active submatrix) is zero,\n        # the column is linearly dependent. We move to the next column.\n        if Ab[i_max][k] == 0:\n            continue\n\n        # Swap the found pivot row with the current rank row\n        Ab[rank], Ab[i_max] = Ab[i_max], Ab[rank]\n        \n        pivot_val = Ab[rank][k]\n\n        # Eliminate entries below the pivot\n        for i in range(rank + 1, n):\n            factor = Ab[i][k] / pivot_val\n            # Apply row operation to the rest of the row\n            for j in range(k, n + 1):\n                Ab[i][j] -= factor * Ab[rank][j]\n        \n        rank += 1\n    \n    # Solution phase\n    if rank  n:\n        return (\"singular\", rank)\n\n    # Nonsingular case: perform back substitution\n    x = [Fraction(0)] * n\n    for i in range(n - 1, -1, -1):\n        # We know pivots are on the diagonal because rank == n for a square matrix\n        sum_ax = sum(Ab[i][j] * x[j] for j in range(i + 1, n))\n        x[i] = (Ab[i][n] - sum_ax) / Ab[i][i]\n    \n    return (\"nonsingular\", x)\n\ndef mat_vec_mul(A, x):\n    \"\"\"Matrix-vector multiplication with Fraction objects.\"\"\"\n    n = len(A)\n    b = [Fraction(0)] * n\n    for i in range(n):\n        for j in range(n):\n            b[i] += A[i][j] * x[j]\n    return b\n\ndef solve():\n    \"\"\"\n    Defines, runs, and formats the results for the four test cases.\n    \"\"\"\n    # Test Case 1: Hilbert matrix n=5\n    n1 = 5\n    A1 = [[Fraction(1, i + j + 1) for j in range(n1)] for i in range(n1)]\n    x1_star = [Fraction(1)] * n1\n    b1 = mat_vec_mul(A1, x1_star)\n\n    # Test Case 2: Hilbert matrix n=7\n    n2 = 7\n    A2 = [[Fraction(1, i + j + 1) for j in range(n2)] for i in range(n2)]\n    x2_star = [Fraction(-1) if i % 2 else Fraction(1) for i in range(n2)]\n    b2 = mat_vec_mul(A2, x2_star)\n\n    # Test Case 3: Singular consistent system\n    A3 = [[1, 2, 3], [2, 4, 6], [1, 2, 3]]\n    b3 = [6, 12, 6]\n\n    # Test Case 4: Boundary singular case\n    A4 = [[0]]\n    b4 = [0]\n\n    test_cases = [\n        {'A': A1, 'b': b1, 'x_star': x1_star},\n        {'A': A2, 'b': b2, 'x_star': x2_star},\n        {'A': A3, 'b': b3, 'x_star': None},\n        {'A': A4, 'b': b4, 'x_star': None},\n    ]\n\n    all_results = []\n    for case in test_cases:\n        A, b, x_star = case['A'], case['b'], case['x_star']\n        status, payload = GEPP_rational(A, b)\n        \n        if status == \"singular\":\n            all_results.append(payload) # Payload is the rank\n        else: # \"nonsingular\"\n            x_computed = payload\n            n = len(A)\n            \n            # Verify solution correctness\n            ok = all(x_computed[i] == x_star[i] for i in range(n))\n\n            # Compute residual r = Ax - b\n            Ax = mat_vec_mul(A, x_computed)\n            # The input b may not be Fraction objects, so convert\n            b_frac = [Fraction(val) for val in b]\n            residual = [Ax[i] - b_frac[i] for i in range(n)]\n            r_inf = float(max(abs(v) for v in residual))\n\n            # Compute error e = x - x_star\n            error = [x_computed[i] - x_star[i] for i in range(n)]\n            e_inf = float(max(abs(v) for v in error))\n\n            all_results.append([ok, r_inf, e_inf])\n    \n    # Custom string formatting to avoid spaces after comma in lists\n    formatted_results = []\n    for res in all_results:\n        if isinstance(res, list):\n            # Format list as [True,0.0,0.0] without spaces\n            list_str = f\"[{str(res[0])},{str(res[1])},{str(res[2])}]\"\n            formatted_results.append(list_str)\n        else:\n            formatted_results.append(str(res))\n    \n    # Final print statement must match the exact specified format.\n    # The default str() for a list has spaces, which might be undesirable.\n    # The example format `[[True, 0.0, 0.0],[True, 0.0, 0.0],1,0]` has spaces\n    # inside the sublists but not between elements of the main list.\n    # `str(list)` gives spaces. `','.join(map(str, list))` also gives spaces\n    # when an element is a list itself. Let's build the string manually for precision.\n    result_str = f\"[{','.join(str(r) for r in all_results)}]\"\n    # Python's str([True, 0.0, 0.0]) is '[True, 0.0, 0.0]', which has spaces.\n    # The prompt's example format is `[[True, 0.0, 0.0],[True, 0.0, 0.0],1,0]`\n    # This implies str(list) is acceptable for sublists. Let's use the simplest\n    # correct method.\n    \n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "2397350"}, {"introduction": "Our final practice moves from the correctness of the algorithm to its practical performance in the context of large-scale computational physics. This problem [@problem_id:2397353] explores the \"fill-in\" phenomenon in sparse matrices, which arise frequently from discretizing differential equations. By analyzing the LU factorization of a discrete Laplacian matrix, you will discover how Gaussian elimination can introduce new non-zero elements, a critical consideration for memory and efficiency in real-world simulations.", "problem": "You are given a family of linear systems arising from a two-dimensional discrete Laplacian on a square lattice with Dirichlet boundary conditions. For a given integer grid size $n \\ge 1$, define $N = n^2$ and the coefficient matrix $A \\in \\mathbb{R}^{N \\times N}$ in natural lexicographic ordering as follows. For each lattice node with coordinates $(i,j)$ where $i \\in \\{0,\\dots,n-1\\}$ and $j \\in \\{0,\\dots,n-1\\}$, let the corresponding linear index be $k = i n + j$. Then the entries of $A$ are given by $A_{k,k} = 4$, and $A_{k,k'} = -1$ if and only if $(i',j')$ is a nearest neighbor of $(i,j)$ on the grid, where $k' = i' n + j'$ and the nearest neighbors are $(i \\pm 1, j)$ and $(i, j \\pm 1)$ provided they lie within the grid; all other entries are zero. This $A$ is the canonical five-point stencil matrix for the discrete Poisson equation on a uniform square grid.\n\nConsider the factorization with row permutations $P A = L U$, where $P \\in \\mathbb{R}^{N \\times N}$ is a permutation matrix produced by a pivoting strategy, $L \\in \\mathbb{R}^{N \\times N}$ is unit lower triangular, and $U \\in \\mathbb{R}^{N \\times N}$ is upper triangular. The factorization may introduce new nonzero entries that are zero in the permuted coefficient matrix $P A$. Let the numerical zero threshold be $\\tau = 10^{-12}$; an entry $x \\in \\mathbb{R}$ is treated as zero if $|x| \\le \\tau$ and nonzero if $|x|  \\tau$.\n\nDefine the following quantities computed with respect to the permuted matrix $A_{\\mathrm{perm}} = P A$:\n- The nonzero count of $A_{\\mathrm{perm}}$ is $\\mathrm{nnz}(A_{\\mathrm{perm}}) = \\left|\\{(i,j) : |(A_{\\mathrm{perm}})_{ij}|  \\tau\\}\\right|$.\n- The structural union of the strictly lower part of $L$ and all of $U$ is the set $$\\mathcal{S}_{LU} = \\{(i,j) : i  j \\text{ and } |L_{ij}|  \\tau\\} \\cup \\{(i,j) : |U_{ij}|  \\tau\\}.$$\n- The union nonzero count is $\\mathrm{nnz}_{LU} = |\\mathcal{S}_{LU}|$.\n- The fill-in count is $$F = \\left|\\{(i,j) : |(A_{\\mathrm{perm}})_{ij}| \\le \\tau \\text{ and } \\big((i,j) \\in \\mathcal{S}_{LU}\\big)\\}\\right|.$$\n- The fill-in fraction is $f = F / \\mathrm{nnz}(A_{\\mathrm{perm}})$, expressed as a decimal number.\n\nYour task is to write a program that, for each given grid size $n$, constructs $A$, performs a factorization into $P$, $L$, and $U$ compatible with the above, computes $A_{\\mathrm{perm}}$, and then evaluates $\\mathrm{nnz}(A_{\\mathrm{perm}})$, $\\mathrm{nnz}_{LU}$, $F$, and $f$ using the threshold $\\tau$ as defined.\n\nTest suite:\n- Case $1$: $n = 1$ (boundary case with minimal dimension).\n- Case $2$: $n = 2$ (small grid).\n- Case $3$: $n = 3$ (moderate grid).\n- Case $4$: $n = 5$ (larger grid within modest computational effort).\n\nFor each test case, the program must produce the list $[\\mathrm{nnz}(A_{\\mathrm{perm}}), \\mathrm{nnz}_{LU}, F, f]$, with $f$ numerically rounded to $6$ decimal places. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes one inner list in the same order as above and the inner lists contain comma-separated values with no spaces. For example, the final output format must be\n\"[[a_{1},b_{1},c_{1},d_{1}],[a_{2},b_{2},c_{2},d_{2}],[a_{3},b_{3},c_{3},d_{3}],[a_{4},b_{4},c_{4},d_{4}]]\"\nwith $a_{k}$, $b_{k}$, and $c_{k}$ integers and $d_{k}$ a decimal number rounded to $6$ places. No physical units are involved, and no angles or percentages appear in the output.", "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the field of numerical linear algebra and its application to computational physics, specifically the solution of partial differential equations on a grid. The problem is well-posed, objective, and self-contained, providing all necessary definitions, data, and constraints for a unique and verifiable solution. The computational tasks are feasible for the given test cases.\n\nThe task is to analyze the fill-in phenomenon that occurs during the $PA=LU$ factorization of a sparse matrix $A$ derived from a two-dimensional discrete Laplacian. For a given grid size $n$, we must construct the $N \\times N$ matrix $A$ where $N=n^2$, perform the factorization, and compute several quantities related to the sparsity patterns of the original and factored matrices.\n\nThe process is implemented as a sequence of steps for each given integer $n$.\n\n1.  **Construction of the Coefficient Matrix $A$**\n    The matrix $A \\in \\mathbb{R}^{N \\times N}$ represents the five-point stencil for the discrete Laplacian on an $n \\times n$ grid. The nodes of the grid are indexed lexicographically. A node at grid coordinates $(i,j)$, where $i, j \\in \\{0, \\dots, n-1\\}$, is mapped to a single linear index $k = i \\cdot n + j$. The matrix $A$ is constructed as follows:\n    - For each index $k \\in \\{0, \\dots, N-1\\}$, the diagonal entry is set to $A_{k,k} = 4$.\n    - For an off-diagonal entry $A_{k,k'}$, it is set to $-1$ if and only if the node $k'$ is a nearest-neighbor to node $k$ on the grid. For a node $(i,j)$ with index $k$, its neighbors are $(i \\pm 1, j)$ and $(i, j \\pm 1)$, provided they lie within the grid boundaries.\n    - All other entries of $A$ are $0$.\n    This results in a sparse, symmetric, positive-definite, and diagonally dominant matrix.\n\n2.  **$PA=LU$ Factorization**\n    The problem requires a factorization of the form $P A = L U$, where $P$ is a permutation matrix resulting from a pivoting strategy, $L$ is a unit lower triangular matrix, and $U$ is an upper triangular matrix. We will employ a standard numerical library function, `scipy.linalg.lu`, to perform this factorization. This function computes a decomposition $A = P_{\\text{SciPy}} L_{\\text{SciPy}} U_{\\text{SciPy}}$. To match the required form, we can left-multiply by $P_{\\text{SciPy}}^{-1} = P_{\\text{SciPy}}^T$, which yields $P_{\\text{SciPy}}^T A = L_{\\text{SciPy}} U_{\\text{SciPy}}$.\n    Therefore, we can identify the matrices from the problem statement as:\n    - $P = P_{\\text{SciPy}}^T$\n    - $L = L_{\\text{SciPy}}$\n    - $U = U_{\\text{SciPy}}$\n    The matrix $A$ being symmetric and positive-definite implies that pivoting may not be strictly necessary for numerical stability, and for small $n$, $P$ may be the identity matrix, $I$. However, relying on a general-purpose library function that incorporates a pivoting strategy is a robust approach.\n\n3.  **Calculation of Sparsity Metrics**\n    With $A$, $P$, $L$, and $U$ determined, we compute the required quantities using the numerical zero threshold $\\tau = 10^{-12}$.\n\n    - **Permuted Matrix $A_{\\mathrm{perm}}$**: This is computed as $A_{\\mathrm{perm}} = P A$.\n\n    - **Nonzero count of $A_{\\mathrm{perm}}$**: $\\mathrm{nnz}(A_{\\mathrm{perm}})$ is the number of elements $(A_{\\mathrm{perm}})_{ij}$ such that $|(A_{\\mathrm{perm}})_{ij}| > \\tau$. This is computed by applying the condition to the entire matrix and summing the resulting boolean values.\n      $$ \\mathrm{nnz}(A_{\\mathrm{perm}}) = \\sum_{i=0}^{N-1} \\sum_{j=0}^{N-1} \\mathbb{I}(|(A_{\\mathrm{perm}})_{ij}| > \\tau) $$\n      where $\\mathbb{I}(\\cdot)$ is the indicator function.\n\n    - **Union Nonzero Count $\\mathrm{nnz}_{LU}$**: First, we define the set of nonzero positions in the factors, $\\mathcal{S}_{LU} = \\{(i,j) : i > j \\text{ and } |L_{ij}| > \\tau\\} \\cup \\{(i,j) : |U_{ij}| > \\tau\\}$. The count $\\mathrm{nnz}_{LU}$ is the cardinality of this set, $|\\mathcal{S}_{LU}|$. Since the first set of indices corresponds to the strictly lower triangle and the second to the upper triangle (including the diagonal), the sets are disjoint. Thus, the total count is the sum of the counts from each part.\n\n    - **Fill-in Count $F$**: Fill-in refers to positions that are zero in the original (permuted) matrix but become nonzero in the LU factors. The count $F$ is defined as the number of index pairs $(i,j)$ such that $(A_{\\mathrm{perm}})_{ij}$ is zero (i.e., $|(A_{\\mathrm{perm}})_{ij}| \\le \\tau$) but $(i,j)$ is in the structural union $\\mathcal{S}_{LU}$.\n      $$ F = \\left| \\left\\{ (i,j) \\in \\mathcal{S}_{LU} \\mid |(A_{\\mathrm{perm}})_{ij}| \\le \\tau \\right\\} \\right| $$\n      This is calculated by creating boolean masks for the zero positions in $A_{\\mathrm{perm}}$ and the nonzero positions in $\\mathcal{S}_{LU}$, and then finding the size of their intersection.\n\n    - **Fill-in Fraction $f$**: This is the ratio of the fill-in count to the number of nonzeros in the permuted matrix.\n      $$ f = \\frac{F}{\\mathrm{nnz}(A_{\\mathrm{perm}})} $$\n      The result is rounded to $6$ decimal places as required. For the trivial case where $\\mathrm{nnz}(A_{\\mathrm{perm}}) = 0$, $f$ would be $0$.\n\nThis procedure is systematically applied to each value of $n$ in the test suite to generate the final results.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport scipy.linalg\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n\n    def construct_A(n: int) -> np.ndarray:\n        \"\"\"\n        Constructs the coefficient matrix A for a given grid size n.\n\n        The matrix corresponds to a 2D discrete Laplacian on an n x n grid\n        with Dirichlet boundary conditions, using natural lexicographic ordering.\n        \"\"\"\n        N = n * n\n        if N == 0:\n            return np.array([[]])\n        \n        A = np.zeros((N, N), dtype=float)\n\n        for i in range(n):\n            for j in range(n):\n                k = i * n + j\n                A[k, k] = 4\n                \n                # Neighbor above\n                if i > 0:\n                    k_neighbor = (i - 1) * n + j\n                    A[k, k_neighbor] = -1\n                \n                # Neighbor below\n                if i  n - 1:\n                    k_neighbor = (i + 1) * n + j\n                    A[k, k_neighbor] = -1\n                    \n                # Neighbor left\n                if j > 0:\n                    k_neighbor = i * n + (j - 1)\n                    A[k, k_neighbor] = -1\n                \n                # Neighbor right\n                if j  n - 1:\n                    k_neighbor = i * n + (j + 1)\n                    A[k, k_neighbor] = -1\n        \n        return A\n\n    def analyze_factorization(n: int) -> list:\n        \"\"\"\n        For a given grid size n, constructs matrix A, performs PA=LU\n        factorization, and computes the required sparsity metrics.\n        \"\"\"\n        A = construct_A(n)\n        \n        # The problem asks for a factorization P A = L U.\n        # scipy.linalg.lu returns P_scipy, L, U such that A = P_scipy @ L @ U.\n        # So, we can left-multiply by P_scipy.T (since P is a permutation matrix)\n        # to get P_scipy.T @ A = L @ U.\n        # Thus, the P in the problem statement is P_scipy.T.\n        P_scipy, L, U = scipy.linalg.lu(A)\n        P = P_scipy.T\n        \n        A_perm = P @ A\n        \n        tau = 1e-12\n\n        # 1. Nonzero count of A_perm\n        nnz_A_perm = np.sum(np.abs(A_perm) > tau)\n\n        # 2. Structural union S_LU and its nonzero count nnz_LU\n        # S_LU = {(i,j) : i > j and |L_ij| > tau} U {(i,j) : |U_ij| > tau}\n        mask_L_strict_lower = np.abs(np.tril(L, -1)) > tau\n        mask_U = np.abs(U) > tau\n        mask_LU_union = mask_L_strict_lower | mask_U\n        nnz_LU = np.sum(mask_LU_union)\n\n        # 3. Fill-in count F\n        # F = |{(i,j) : |(A_perm)_ij| = tau and (i,j) in S_LU}|\n        mask_A_perm_zero = np.abs(A_perm) = tau\n        F = np.sum(mask_A_perm_zero  mask_LU_union)\n\n        # 4. Fill-in fraction f\n        if nnz_A_perm == 0:\n            f = 0.0\n        else:\n            f = F / nnz_A_perm\n        \n        return [int(nnz_A_perm), int(nnz_LU), int(F), round(f, 6)]\n\n    # Define the test cases from the problem statement.\n    test_cases = [1, 2, 3, 5]\n\n    results = []\n    for n in test_cases:\n        result = analyze_factorization(n)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # e.g., \"[[a1,b1,c1,d1],[a2,b2,c2,d2]]\"\n    result_str = ','.join([f\"[{','.join(map(str, res))}]\" for res in results])\n    print(f\"[{result_str}]\")\n\nsolve()\n```", "id": "2397353"}]}