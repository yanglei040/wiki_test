{"hands_on_practices": [{"introduction": "Before diving into complex numerical algorithms, it is crucial to first develop physical intuition. This initial practice problem [@problem_id:2406731] presents what appears to be a standard two-dimensional heat transfer scenario, but it holds a valuable lesson in problem-solving. By carefully analyzing the boundary conditions, you will discover how the physics of the situation dramatically simplifies the mathematics, leading to an elegant analytical solution without a complex grid-based solver. This exercise underscores the principle that a computational physicist's most powerful tool is often analytical thinking before computation.", "problem": "Consider a homogeneous, isotropic rectangular plate occupying the domain $\\{(x,y)\\,|\\,0 \\le x \\le L_x,\\;0 \\le y \\le L_y\\}$ with no internal heat sources. The steady-state temperature field $T(x,y)$ satisfies the two-dimensional Laplace equation\n$$\n\\frac{\\partial^2 T}{\\partial x^2} + \\frac{\\partial^2 T}{\\partial y^2} = 0\n$$\non the open rectangle. The boundary conditions are as follows: the bottom edge is held at a uniform temperature $T(x,0) = T_{\\mathrm{hot}}$ in $\\mathrm{K}$, the top edge is held at a uniform temperature $T(x,L_y) = T_{\\mathrm{cold}}$ in $\\mathrm{K}$, and the left and right edges are thermally insulated, that is $\\frac{\\partial T}{\\partial x}(0,y) = 0$ and $\\frac{\\partial T}{\\partial x}(L_x,y) = 0$ for all $y \\in [0,L_y]$. All lengths must be treated in $\\mathrm{m}$ and all temperatures must be treated in $\\mathrm{K}$. Angles are not involved. Your task is to compute, for each specified parameter set, the steady-state temperature at the geometric center $(x,y) = (L_x/2,L_y/2)$ and report it in $\\mathrm{K}$, rounded to $3$ decimal places.\n\nTest suite (each case specifies $(L_x,\\;L_y,\\;T_{\\mathrm{hot}},\\;T_{\\mathrm{cold}})$ in $(\\mathrm{m},\\;\\mathrm{m},\\;\\mathrm{K},\\;\\mathrm{K})$):\n- Case A: $L_x = 1.0\\,\\mathrm{m}$, $L_y = 1.0\\,\\mathrm{m}$, $T_{\\mathrm{hot}} = 400.0\\,\\mathrm{K}$, $T_{\\mathrm{cold}} = 300.0\\,\\mathrm{K}$.\n- Case B: $L_x = 2.5\\,\\mathrm{m}$, $L_y = 0.8\\,\\mathrm{m}$, $T_{\\mathrm{hot}} = 310.0\\,\\mathrm{K}$, $T_{\\mathrm{cold}} = 330.0\\,\\mathrm{K}$.\n- Case C: $L_x = 0.7\\,\\mathrm{m}$, $L_y = 3.0\\,\\mathrm{m}$, $T_{\\mathrm{hot}} = 273.15\\,\\mathrm{K}$, $T_{\\mathrm{cold}} = 373.15\\,\\mathrm{K}$.\n- Case D: $L_x = 1.2\\,\\mathrm{m}$, $L_y = 2.0\\,\\mathrm{m}$, $T_{\\mathrm{hot}} = 300.0\\,\\mathrm{K}$, $T_{\\mathrm{cold}} = 300.0\\,\\mathrm{K}$.\n\nFor each case, compute the steady-state temperature $T$ at $(L_x/2,L_y/2)$ in $\\mathrm{K}$ and round to $3$ decimal places. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[resultA,resultB,resultC,resultD]\") with no spaces, where each entry is the rounded number in $\\mathrm{K}$ expressed as a decimal number.", "solution": "The problem statement is coherent, scientifically grounded, and mathematically well-posed. It describes a standard boundary value problem for the two-dimensional Laplace equation on a rectangular domain with a combination of Dirichlet and Neumann boundary conditions. Such a problem is known from the theory of partial differential equations to possess a unique and stable solution. We shall therefore proceed directly to the derivation of this solution.\n\nThe physical system is described by the steady-state heat equation, which is the Laplace equation for the temperature field $T(x,y)$:\n$$\n\\frac{\\partial^2 T}{\\partial x^2} + \\frac{\\partial^2 T}{\\partial y^2} = 0\n$$\nThe domain is the rectangle defined by $0 \\le x \\le L_x$ and $0 \\le y \\le L_y$. The boundary conditions are:\n$1$. $T(x,0) = T_{\\mathrm{hot}}$ (Dirichlet)\n$2$. $T(x,L_y) = T_{\\mathrm{cold}}$ (Dirichlet)\n$3$. $\\frac{\\partial T}{\\partial x}(0,y) = 0$ (Neumann)\n$4$. $\\frac{\\partial T}{\\partial x}(L_x,y) = 0$ (Neumann)\n\nWe employ the method of separation of variables, assuming a solution of the form $T(x,y) = X(x)Y(y)$. Substituting this into the Laplace equation and separating the variables yields:\n$$\n\\frac{X''(x)}{X(x)} = -\\frac{Y''(y)}{Y(y)} = -\\lambda\n$$\nwhere $\\lambda$ is the separation constant. This gives two ordinary differential equations:\n$$\nX''(x) + \\lambda X(x) = 0\n$$\n$$\nY''(y) - \\lambda Y(y) = 0\n$$\nWe first solve the equation for $X(x)$ using the homogeneous Neumann boundary conditions. The conditions $\\frac{\\partial T}{\\partial x}(0,y) = X'(0)Y(y) = 0$ and $\\frac{\\partial T}{\\partial x}(L_x,y) = X'(L_x)Y(y) = 0$ require that $X'(0) = 0$ and $X'(L_x) = 0$ for any non-trivial solution $Y(y)$.\n\nCase $1$: $\\lambda > 0$. Let $\\lambda = k^2$ with $k > 0$. The solution is $X(x) = A\\cos(kx) + B\\sin(kx)$. The derivative is $X'(x) = -Ak\\sin(kx) + Bk\\cos(kx)$.\nApplying $X'(0)=0$ gives $B_k=0$, so $B=0$. The solution form is $X(x) = A\\cos(kx)$.\nApplying $X'(L_x)=0$ gives $-Ak\\sin(kL_x) = 0$. For a non-trivial solution ($A \\neq 0$), we must have $\\sin(kL_x) = 0$, which implies $kL_x = n\\pi$ for $n=1, 2, 3, \\ldots$.\nThe eigenvalues are $\\lambda_n = k_n^2 = \\left(\\frac{n\\pi}{L_x}\\right)^2$ for $n \\ge 1$. The corresponding eigenfunctions are $X_n(x) = A_n \\cos\\left(\\frac{n\\pi x}{L_x}\\right)$.\n\nCase $2$: $\\lambda = 0$. The equation becomes $X''(x) = 0$, with solution $X(x) = C_1x + C_2$. The derivative is $X'(x) = C_1$.\nThe conditions $X'(0)=0$ and $X'(L_x)=0$ both give $C_1=0$. Thus, $X_0(x) = C_2$ (a constant) is also a valid eigenfunction, corresponding to the eigenvalue $\\lambda_0 = 0$.\n\nCase $3$: $\\lambda < 0$. Let $\\lambda = -k^2$ with $k > 0$. The equation $X''(x) - k^2X(x) = 0$ has solution $X(x) = A\\cosh(kx) + B\\sinh(kx)$. Applying the boundary conditions leads to $A=B=0$, yielding only the trivial solution. Thus, there are no negative eigenvalues.\n\nNow we solve for $Y(y)$.\nFor $\\lambda_n = k_n^2 = \\left(\\frac{n\\pi}{L_x}\\right)^2$ with $n \\ge 1$, the equation is $Y_n''(y) - k_n^2 Y_n(y) = 0$. Its solution is $Y_n(y) = C_n\\cosh(k_n y) + D_n\\sinh(k_n y)$.\nFor $\\lambda_0 = 0$, the equation is $Y_0''(y) = 0$. Its solution is $Y_0(y) = C_0 y + D_0$.\n\nThe general solution is a superposition of all possible product solutions:\n$$\nT(x,y) = X_0(x)Y_0(y) + \\sum_{n=1}^{\\infty} X_n(x)Y_n(y)\n$$\nAbsorbing constants, this becomes:\n$$\nT(x,y) = C_0 y + D_0 + \\sum_{n=1}^{\\infty} \\cos\\left(\\frac{n\\pi x}{L_x}\\right) \\left[ E_n \\cosh\\left(\\frac{n\\pi y}{L_x}\\right) + F_n \\sinh\\left(\\frac{n\\pi y}{L_x}\\right) \\right]\n$$\nWe now apply the remaining non-homogeneous Dirichlet boundary conditions.\nAt $y=0$: $T(x,0) = T_{\\mathrm{hot}}$.\n$$\nT_{\\mathrm{hot}} = D_0 + \\sum_{n=1}^{\\infty} E_n \\cos\\left(\\frac{n\\pi x}{L_x}\\right)\n$$\nThis is a Fourier cosine series representation of the constant function $T_{\\mathrm{hot}}$. By inspection, or by calculating the Fourier coefficients, the constant term must be $D_0 = T_{\\mathrm{hot}}$, and all other coefficients for $n \\ge 1$ must be zero, so $E_n = 0$ for all $n \\ge 1$.\n\nThe solution simplifies to:\n$$\nT(x,y) = C_0 y + T_{\\mathrm{hot}} + \\sum_{n=1}^{\\infty} F_n \\cos\\left(\\frac{n\\pi x}{L_x}\\right) \\sinh\\left(\\frac{n\\pi y}{L_x}\\right)\n$$\nAt $y=L_y$: $T(x,L_y) = T_{\\mathrm{cold}}$.\n$$\nT_{\\mathrm{cold}} = C_0 L_y + T_{\\mathrm{hot}} + \\sum_{n=1}^{\\infty} F_n \\sinh\\left(\\frac{n\\pi L_y}{L_x}\\right) \\cos\\left(\\frac{n\\pi x}{L_x}\\right)\n$$\nThis is a Fourier cosine series for the constant function $T_{\\mathrm{cold}}$. Again, by comparing coefficients:\nThe constant term must match: $T_{\\mathrm{cold}} = C_0 L_y + T_{\\mathrm{hot}} \\implies C_0 = \\frac{T_{\\mathrm{cold}} - T_{\\mathrm{hot}}}{L_y}$.\nThe coefficients of the cosine terms for $n \\ge 1$ must be zero: $F_n \\sinh\\left(\\frac{n\\pi L_y}{L_x}\\right) = 0$.\nSince $\\frac{n\\pi L_y}{L_x} > 0$ for $n \\ge 1$, we have $\\sinh\\left(\\frac{n\\pi L_y}{L_x}\\right) \\neq 0$. Therefore, we must have $F_n = 0$ for all $n \\ge 1$.\n\nAll terms in the summation vanish. The unique solution is remarkably simple, depending only on the $y$-coordinate:\n$$\nT(x,y) = \\left(\\frac{T_{\\mathrm{cold}} - T_{\\mathrm{hot}}}{L_y}\\right) y + T_{\\mathrm{hot}}\n$$\nThis linear profile represents a uniform vertical temperature gradient, consistent with one-dimensional heat flow between two parallel plates, as dictated by the insulated side boundaries. We are asked to find the temperature at the geometric center of the plate, $(x,y) = (L_x/2, L_y/2)$. The temperature is independent of $x$. Substituting $y = L_y/2$ gives:\n$$\nT(L_x/2, L_y/2) = \\left(\\frac{T_{\\mathrm{cold}} - T_{\\mathrm{hot}}}{L_y}\\right) \\frac{L_y}{2} + T_{\\mathrm{hot}} = \\frac{T_{\\mathrm{cold}} - T_{\\mathrm{hot}}}{2} + T_{\\mathrm{hot}} = \\frac{T_{\\mathrm{cold}} + T_{\\mathrm{hot}}}{2}\n$$\nThe temperature at the vertical midpoint is simply the arithmetic mean of the top and bottom boundary temperatures. This result is independent of the plate dimensions $L_x$ and $L_y$. Each test case is solved by applying this formula.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the steady-state temperature at the center of a rectangular plate\n    with specified boundary conditions.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each tuple contains (Lx, Ly, Thot, Tcold) in units of (m, m, K, K).\n    test_cases = [\n        (1.0, 1.0, 400.0, 300.0),\n        (2.5, 0.8, 310.0, 330.0),\n        (0.7, 3.0, 273.15, 373.15),\n        (1.2, 2.0, 300.0, 300.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        # Unpack the parameters for the current case.\n        # Lx and Ly are not needed for the final calculation but are kept for clarity.\n        Lx, Ly, Thot, Tcold = case\n\n        # The analytical solution for the temperature T(x,y) is:\n        # T(x,y) = ((Tcold - Thot) / Ly) * y + Thot\n        # This is because the side walls are insulated, making the heat flow\n        # purely one-dimensional in the y-direction.\n        # We need to find the temperature at the geometric center (Lx/2, Ly/2).\n        # T(Lx/2, Ly/2) = ((Tcold - Thot) / Ly) * (Ly/2) + Thot\n        # T_center = (Tcold - Thot) / 2 + Thot\n        # T_center = (Tcold + Thot) / 2\n        \n        temp_center = (Thot + Tcold) / 2.0\n        \n        # Format the result to 3 decimal places as required.\n        results.append(f\"{temp_center:.3f}\")\n\n    # Final print statement in the exact required format: [resultA,resultB,...]\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2406731"}, {"introduction": "When an analytical solution is not feasible, we must turn to numerical methods to approximate the solution. This practice [@problem_id:2406696] guides you through the fundamental process of building a finite difference solver from first principles. You will learn to discretize the domain, approximate derivatives to form the core five-point stencil, and, crucially, implement the more challenging Neumann (derivative) boundary conditions that are ubiquitous in physics and engineering models.", "problem": "Consider the two-dimensional Laplace equation, which is the prototype elliptic partial differential equation (PDE) for steady-state, source-free fields. The governing equation in a rectangular domain is\n$$\n\\nabla^2 u(x,y) \\equiv \\frac{\\partial^2 u}{\\partial x^2}(x,y) + \\frac{\\partial^2 u}{\\partial y^2}(x,y) = 0 \\quad \\text{for} \\quad (x,y)\\in \\Omega,\n$$\nwith $\\Omega = [0,1]\\times[0,1]$. Boundary conditions are prescribed on the boundary $\\partial\\Omega$, and may be of Dirichlet type $u = d(x,y)$ or Neumann type $\\frac{\\partial u}{\\partial n} = g(x,y)$, where $\\frac{\\partial}{\\partial n}$ denotes the outward normal derivative. The aim is to construct a computational solver that can handle a mix of Dirichlet and Neumann conditions on different, possibly piecewise, segments of the boundary.\n\nYour task is to write a complete, runnable program that:\n- Discretizes the domain $\\Omega$ with a uniform Cartesian grid of $N\\times N$ nodes, where $N$ is specified per test case.\n- Derives from first principles a second-order accurate finite difference method for the interior discretization of $\\nabla^2 u = 0$ based on Taylor expansions, and a second-order accurate treatment of Neumann boundary conditions along the inward normal direction (do not assume any formula without derivation; use the definitions of derivatives and Taylor series to construct second-order approximations).\n- Assembles and solves the resulting linear system for $u$ at all grid nodes.\n- Supports boundary conditions specified piecewise along each side of the square. For each side, segments are given in terms of a parameter $s\\in[0,1]$ that traverses the side: for the left and right sides $s=y$, and for the bottom and top sides $s=x$. At each grid boundary node, select the appropriate boundary condition type and value by locating $s$ within the prescribed segment intervals. At the four corner nodes, impose Dirichlet values taken from the exact solution specified for the test case to remove any ambiguity.\n- For Neumann data, the outward normal derivative must be used. The outward unit normal is $(-\\hat{\\boldsymbol{i}})$ on the left, $(+\\hat{\\boldsymbol{i}})$ on the right, $(-\\hat{\\boldsymbol{j}})$ on the bottom, and $(+\\hat{\\boldsymbol{j}})$ on the top sides.\n\nUse the following test suite. In each case, an exact harmonic function $u^\\star(x,y)$ is provided. You must construct boundary condition data consistent with $u^\\star(x,y)$ so that the exact solution satisfies both the PDE and the boundary conditions. For Neumann data, compute $g(x,y)=\\frac{\\partial u^\\star}{\\partial n}(x,y)$ using the outward normal definition above.\n\n- Test case A (general mixed, smooth polynomial):\n  - Domain: $\\Omega=[0,1]\\times[0,1]$.\n  - Grid: $N=51$ (so the grid spacing is $h=\\frac{1}{N-1}$).\n  - Exact solution: $u^\\star(x,y)=x^2 - y^2$.\n  - Boundary segmentation:\n    - Left side ($x=0$): Dirichlet on $s\\in[0,1]$ with $u = u^\\star(0,y)$.\n    - Right side ($x=1$): Dirichlet on $s\\in[0,1]$ with $u = u^\\star(1,y)$.\n    - Bottom side ($y=0$): Neumann on $s\\in[0,1]$ with $\\frac{\\partial u}{\\partial n} = -\\frac{\\partial u^\\star}{\\partial y}(x,0)$.\n    - Top side ($y=1$): Neumann on $s\\in[0,1]$ with $\\frac{\\partial u}{\\partial n} = +\\frac{\\partial u^\\star}{\\partial y}(x,1)$.\n    - Corners: Dirichlet set to $u^\\star$.\n- Test case B (piecewise mix on a side):\n  - Domain: $\\Omega=[0,1]\\times[0,1]$.\n  - Grid: $N=51$.\n  - Exact solution: $u^\\star(x,y)=x$.\n  - Boundary segmentation:\n    - Left side ($x=0$): Dirichlet on $s\\in[0,1]$ with $u = u^\\star(0,y)$.\n    - Right side ($x=1$): Neumann on $s\\in[0,1]$ with $\\frac{\\partial u}{\\partial n} = +\\frac{\\partial u^\\star}{\\partial x}(1,y)$.\n    - Bottom side ($y=0$): Dirichlet on $s\\in[0,1]$ with $u = u^\\star(x,0)$.\n    - Top side ($y=1$): Piecewise along $s=x$:\n      - Neumann on $s\\in[0,0.4]$ with $\\frac{\\partial u}{\\partial n} = +\\frac{\\partial u^\\star}{\\partial y}(x,1)$,\n      - Dirichlet on $s\\in(0.4,1]$ with $u = u^\\star(x,1)$.\n    - Corners: Dirichlet set to $u^\\star$.\n- Test case C (edge case with small grid and homogeneous Neumann on two sides):\n  - Domain: $\\Omega=[0,1]\\times[0,1]$.\n  - Grid: $N=9$.\n  - Exact solution: $u^\\star(x,y)=y$.\n  - Boundary segmentation:\n    - Left side ($x=0$): Neumann on $s\\in[0,1]$ with $\\frac{\\partial u}{\\partial n} = -\\frac{\\partial u^\\star}{\\partial x}(0,y)$.\n    - Right side ($x=1$): Neumann on $s\\in[0,1]$ with $\\frac{\\partial u}{\\partial n} = +\\frac{\\partial u^\\star}{\\partial x}(1,y)$.\n    - Bottom side ($y=0$): Dirichlet on $s\\in[0,1]$ with $u = u^\\star(x,0)$.\n    - Top side ($y=1$): Dirichlet on $s\\in[0,1]$ with $u = u^\\star(x,1)$.\n    - Corners: Dirichlet set to $u^\\star$.\n\nRequired numerical design:\n- Interior discretization: Derive a second-order accurate five-point finite difference approximation to $\\nabla^2 u = 0$ on interior nodes using Taylor expansions about a grid node and the definition of second derivatives as limits of symmetric difference quotients.\n- Neumann boundary discretization: Derive a second-order accurate one-sided finite difference approximation for the outward normal derivative at boundary nodes along the inward normal direction. Construct a linear relation between the boundary node and the first two interior nodes along the inward normal direction and the Neumann data $g$ that is consistent to second order in $h$.\n- Dirichlet boundary discretization: Enforce the prescribed value of $u$ at boundary nodes exactly.\n\nFor each test case, compute the maximum absolute error\n$$\nE_\\infty = \\max_{0\\le i,j \\le N-1} \\left| u_{i,j}^{\\text{num}} - u^\\star(x_i,y_j) \\right|\n$$\nover all grid nodes, where $x_i = i\\,h$, $y_j = j\\,h$, and $h=\\frac{1}{N-1}$.\n\nFinal output format:\n- Your program must produce a single line of output containing a list with the three error values for Test cases A, B, and C, in this order, rounded to eight decimal places. The format must be exactly\n- A single line: \"[eA,eB,eC]\" where each entry is a decimal numeral (e.g., \"[0.00000000,0.00000000,0.00000000]\").\n\nNo physical units are involved in this problem. No angles are used. No percentages are required. The program must be fully self-contained and must not read any input. It must run \"as is\" and produce the required line of output. Ensure scientific realism and internal consistency in all choices and derivations. Your algorithm must start from the fundamental definitions of derivatives and Taylor expansions; no shortcut formulas may be assumed without derivation in your implementation design. The solver must be general enough to handle the piecewise boundary specifications given above.", "solution": "The user requests a computational solution to the two-dimensional Laplace equation on a unit square, $\\nabla^2 u = 0$, utilizing a second-order finite difference method for both interior nodes and Neumann boundary conditions. The problem is well-defined, scientifically sound, and all necessary parameters for the test cases are provided. The problem validity check is passed. We shall proceed with the derivation and construction of the solver.\n\nThe governing partial differential equation (PDE) is the Laplace equation in a domain $\\Omega = [0,1]\\times[0,1]$:\n$$\n\\frac{\\partial^2 u}{\\partial x^2}(x,y) + \\frac{\\partial^2 u}{\\partial y^2}(x,y) = 0\n$$\n\nWe discretize the domain $\\Omega$ using a uniform Cartesian grid with $N \\times N$ nodes. The grid points are denoted by $(x_i, y_j) = (i h, j h)$ for $i, j \\in \\{0, 1, \\dots, N-1\\}$, where the grid spacing is $h = \\frac{1}{N-1}$. The value of the function $u$ at a grid point $(x_i, y_j)$ is denoted by $u_{i,j}$.\n\nDerivation of the Finite Difference Stencils\n\nThe core of the method is the approximation of partial derivatives using Taylor series expansions.\n\n1. Interior Node Discretization\n\nFor an interior node $(i,j)$, where $0 < i < N-1$ and $0 < j < N-1$, we approximate the second partial derivatives. The Taylor series expansions of $u$ around $(x_i, y_j)$ in the $x$-direction are:\n$$\nu(x_i+h, y_j) = u_{i,j} + h \\left(\\frac{\\partial u}{\\partial x}\\right)_{i,j} + \\frac{h^2}{2} \\left(\\frac{\\partial^2 u}{\\partial x^2}\\right)_{i,j} + \\frac{h^3}{6} \\left(\\frac{\\partial^3 u}{\\partial x^3}\\right)_{i,j} + O(h^4)\n$$\n$$\nu(x_i-h, y_j) = u_{i,j} - h \\left(\\frac{\\partial u}{\\partial x}\\right)_{i,j} + \\frac{h^2}{2} \\left(\\frac{\\partial^2 u}{\\partial x^2}\\right)_{i,j} - \\frac{h^3}{6} \\left(\\frac{\\partial^3 u}{\\partial x^3}\\right)_{i,j} + O(h^4)\n$$\nAdding these two expansions eliminates the odd-order derivative terms:\n$$\nu_{i+1,j} + u_{i-1,j} = 2u_{i,j} + h^2 \\left(\\frac{\\partial^2 u}{\\partial x^2}\\right)_{i,j} + O(h^4)\n$$\nSolving for the second derivative, we obtain the second-order accurate central difference approximation:\n$$\n\\left(\\frac{\\partial^2 u}{\\partial x^2}\\right)_{i,j} = \\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} + O(h^2)\n$$\nBy analogy, the approximation for the second derivative in the $y$-direction is:\n$$\n\\left(\\frac{\\partial^2 u}{\\partial y^2}\\right)_{i,j} = \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} + O(h^2)\n$$\nSubstituting these into the Laplace equation $\\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} = 0$ gives the discrete equation for an interior node:\n$$\n\\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} + \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} = 0\n$$\nMultiplying by $h^2$, we arrive at the well-known five-point stencil for the discrete Laplacian:\n$$\nu_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j} = 0\n$$\n\n2. Neumann Boundary Condition Discretization\n\nThe problem requires a second-order accurate one-sided approximation for the normal derivative $\\frac{\\partial u}{\\partial n} = g(x,y)$. Let us derive this for the right boundary at $x=1$ (i.e., for nodes $(N-1, j)$), where the outward normal is in the $+x$ direction, so $\\frac{\\partial u}{\\partial n} = \\frac{\\partial u}{\\partial x}$. We must construct a linear relation involving the boundary node $u_{N-1,j}$ and the two adjacent interior nodes along the inward normal, $u_{N-2,j}$ and $u_{N-3,j}$.\n\nWe write the Taylor expansions for $u_{N-2,j}$ and $u_{N-3,j}$ around the boundary node $(x_{N-1}, y_j)$:\n$$\nu_{N-2,j} = u(x_{N-1}-h, y_j) = u_{N-1,j} - h \\left(\\frac{\\partial u}{\\partial x}\\right)_{N-1,j} + \\frac{h^2}{2!} \\left(\\frac{\\partial^2 u}{\\partial x^2}\\right)_{N-1,j} + O(h^3)\n$$\n$$\nu_{N-3,j} = u(x_{N-1}-2h, y_j) = u_{N-1,j} - 2h \\left(\\frac{\\partial u}{\\partial x}\\right)_{N-1,j} + \\frac{(2h)^2}{2!} \\left(\\frac{\\partial^2 u}{\\partial x^2}\\right)_{N-1,j} + O(h^3)\n$$\nWe form a linear combination $A u_{N-2,j} + B u_{N-3,j}$ to eliminate the second derivative term $\\frac{\\partial^2 u}{\\partial x^2}$. We need $A \\frac{h^2}{2} + B \\frac{4h^2}{2} = 0$, which implies $A + 4B = 0$. Choosing $A=4$ and $B=-1$ yields:\n$$\n4 u_{N-2,j} - u_{N-3,j} = (4-1) u_{N-1,j} + (-4h+2h) \\left(\\frac{\\partial u}{\\partial x}\\right)_{N-1,j} + O(h^3)\n$$\n$$\n4 u_{N-2,j} - u_{N-3,j} = 3 u_{N-1,j} - 2h \\left(\\frac{\\partial u}{\\partial x}\\right)_{N-1,j} + O(h^3)\n$$\nSolving for the first derivative gives the second-order accurate one-sided finite difference formula:\n$$\n\\left(\\frac{\\partial u}{\\partial x}\\right)_{N-1,j} = \\frac{3u_{N-1,j} - 4u_{N-2,j} + u_{N-3,j}}{2h} + O(h^2)\n$$\nGiven the Neumann condition $\\frac{\\partial u}{\\partial x}|_{N-1,j} = g_{N-1,j}$, the discrete equation for this boundary node becomes:\n$$\n3u_{N-1,j} - 4u_{N-2,j} + u_{N-3,j} = 2h g_{N-1,j}\n$$\nAnalogous formulas are derived for the other three boundaries, taking into account the direction of the outward normal:\n- Left boundary ($i=0, \\frac{\\partial u}{\\partial n} = -\\frac{\\partial u}{\\partial x} = g$): $3u_{0,j} - 4u_{1,j} + u_{2,j} = 2h g_{0,j}$\n- Bottom boundary ($j=0, \\frac{\\partial u}{\\partial n} = -\\frac{\\partial u}{\\partial y} = g$): $3u_{i,0} - 4u_{i,1} + u_{i,2} = 2h g_{i,0}$\n- Top boundary ($j=N-1, \\frac{\\partial u}{\\partial n} = \\frac{\\partial u}{\\partial y} = g$): $3u_{i,N-1} - 4u_{i,N-2} + u_{i,N-3} = 2h g_{i,N-1}$\n\nSystem Assembly and Solution\n\nThe discrete equations for all $N^2$ nodes form a large linear system $A\\mathbf{u} = \\mathbf{b}$, where $\\mathbf{u}$ is a vector containing all unknown values $u_{i,j}$. We map the 2D grid index $(i,j)$ to a 1D vector index $k = j \\times N + i$. The matrix $A$ and vector $\\mathbf{b}$ are constructed row by row, with one row for each grid node $k$:\n\n1.  **Interior Node $(i,j)$**: The equation is $u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j} = 0$. The corresponding matrix row $k$ will have a coefficient of $-4$ on the main diagonal ($A_{k,k}$), and coefficients of $1$ at columns corresponding to its four neighbors. The right-hand side entry $b_k$ is $0$.\n\n2.  **Dirichlet Boundary Node $(i,j)$**: The condition is $u_{i,j} = d_{i,j}$. This is enforced directly. The matrix row $k$ becomes an identity row: $A_{k,k} = 1$, all other $A_{k,m}=0$, and $b_k = d_{i,j}$.\n\n3.  **Neumann Boundary Node $(i,j)$**: The equation is one of the one-sided stencils derived above. For a node on the right boundary, the equation $3u_{N-1,j} - 4u_{N-2,j} + u_{N-3,j} = 2h g_{N-1,j}$ is used. The matrix row $k$ corresponding to $(N-1, j)$ will have coefficients $3, -4, 1$ at columns mapping to $(N-1,j), (N-2,j), (N-3,j)$, respectively. The right-hand side is $b_k = 2h g_{N-1,j}$.\n\n4.  **Corner Nodes**: The problem specifies that corner nodes are always assigned Dirichlet values from the exact solution $u^\\star$. This is a special case of a Dirichlet boundary condition and is crucial for removing ambiguity, especially if two Neumann boundaries meet at a corner.\n\nThe resulting linear system is large and sparse. It is constructed using a sparse matrix format (e.g., `scipy.sparse.lil_matrix`) for efficiency and solved using a direct sparse solver (`scipy.sparse.linalg.spsolve`). After solving for the vector $\\mathbf{u}$, it is reshaped back into an $N \\times N$ grid representing the numerical solution $u_{i,j}^{\\text{num}}$. This solution is then compared to the exact solution $u^\\star(x_i, y_j)$ on the grid to compute the maximum absolute error $E_\\infty = \\max_{i,j} |u_{i,j}^{\\text{num}} - u^\\star(x_i, y_j)|$.", "answer": "```python\nimport numpy as np\nfrom scipy.sparse import lil_matrix\nfrom scipy.sparse.linalg import spsolve\n\ndef solve_laplace_2d(N, u_star, bc_config):\n    \"\"\"\n    Solves the 2D Laplace equation on a unit square using a second-order\n    finite difference method with mixed Dirichlet/Neumann boundary conditions.\n    \"\"\"\n    h = 1.0 / (N - 1)\n    num_unknowns = N * N\n    \n    # Initialize sparse matrix A and vector b\n    A = lil_matrix((num_unknowns, num_unknowns))\n    b = np.zeros(num_unknowns)\n    \n    # Create coordinate grids\n    x_coords = np.linspace(0, 1, N)\n    y_coords = np.linspace(0, 1, N)\n    \n    for j in range(N):\n        for i in range(N):\n            k = j * N + i  # Row-major mapping from (i, j) to k\n            x, y = x_coords[i], y_coords[j]\n            \n            # 1. Corner nodes (always Dirichlet from exact solution)\n            is_corner = (i == 0 or i == N - 1) and (j == 0 or j == N - 1)\n            if is_corner:\n                A[k, k] = 1.0\n                b[k] = u_star(x, y)\n                continue\n\n            # 2. Boundary nodes (not corners)\n            side_name = None\n            s_coord = -1.0\n            if i == 0:\n                side_name, s_coord = 'left', y\n            elif i == N - 1:\n                side_name, s_coord = 'right', y\n            elif j == 0:\n                side_name, s_coord = 'bottom', x\n            elif j == N - 1:\n                side_name, s_coord = 'top', x\n\n            if side_name:\n                segments = bc_config[side_name]\n                bc_type, bc_value_func = None, None\n                \n                # Find the correct piecewise segment for this node\n                for seg_s_max, seg_type, seg_func in segments:\n                    # The condition `s_coord <= seg_s_max` correctly handles\n                    # intervals like [0, 0.4] and (0.4, 1.0]. A small\n                    # tolerance is added for floating point comparison.\n                    if s_coord <= seg_s_max + 1e-9:\n                        bc_type = seg_type\n                        bc_value_func = seg_func\n                        break\n                \n                if bc_type == 'D': # Dirichlet condition\n                    A[k, k] = 1.0\n                    b[k] = bc_value_func(x, y)\n                elif bc_type == 'N': # Neumann condition\n                    g_val = bc_value_func(x, y)\n                    if side_name == 'left': # d/dn = -d/dx = g -> 3u_0 - 4u_1 + u_2 = -2hg -> No, d/dn = -d/dx = g implies - (3u_0 - 4u_1 + u_2)/(2h) = g -> 3u_0 - 4u_1 + u_2 = -2hg. Wait, my derivation: (∂u/∂x) = (3u_0-4u_1+u_2)/(2h) is incorrect for left side. It should be (-3u_0+4u_1-u_2)/(2h). Let's rederive. u_1 = u_0 + h u'_0 + h^2/2 u''_0; u_2 = u_0 + 2h u'_0 + (2h)^2/2 u''_0. 4u_1 - u_2 = 3u_0 + 2h u'_0 + O(h^3). So u'_0 = (4u_1 - u_2 - 3u_0)/(-2h) = (-3u_0 + 4u_1 - u_2)/(2h). OK. So for left: d/dn = -d/dx = g -> -(-3u_0+4u_1-u_2)/(2h)=g -> -3u_0+4u_1-u_2 = -2hg.\n                        A[k, j * N + 0] = -3.0\n                        A[k, j * N + 1] = 4.0\n                        A[k, j * N + 2] = -1.0\n                        b[k] = -2.0 * h * g_val\n                    elif side_name == 'right': # d/dn = d/dx = g -> 3u_{N-1} - 4u_{N-2} + u_{N-3} = 2hg\n                        A[k, j * N + (N - 1)] = 3.0\n                        A[k, j * N + (N - 2)] = -4.0\n                        A[k, j * N + (N - 3)] = 1.0\n                        b[k] = 2.0 * h * g_val\n                    elif side_name == 'bottom': # d/dn = -d/dy = g\n                        A[k, (0 * N) + i] = -3.0\n                        A[k, (1 * N) + i] = 4.0\n                        A[k, (2 * N) + i] = -1.0\n                        b[k] = -2.0 * h * g_val\n                    elif side_name == 'top': # d/dn = d/dy = g\n                        A[k, ((N - 1) * N) + i] = 3.0\n                        A[k, ((N - 2) * N) + i] = -4.0\n                        A[k, ((N - 3) * N) + i] = 1.0\n                        b[k] = 2.0 * h * g_val\n                continue\n\n            # 3. Interior nodes\n            A[k, k] = -4.0\n            A[k, k - 1] = 1.0  # u_{i-1, j}\n            A[k, k + 1] = 1.0  # u_{i+1, j}\n            A[k, k - N] = 1.0  # u_{i, j-1}\n            A[k, k + N] = 1.0  # u_{i, j+1}\n            b[k] = 0.0\n\n    # Solve the linear system\n    A_csc = A.tocsc()\n    u_vec = spsolve(A_csc, b)\n    u_numerical = u_vec.reshape((N, N))\n\n    # Calculate exact solution and error\n    u_exact_grid = np.zeros((N, N))\n    for j in range(N):\n        for i in range(N):\n            u_exact_grid[j, i] = u_star(x_coords[i], y_coords[j])\n            \n    max_error = np.max(np.abs(u_numerical - u_exact_grid))\n    return max_error\n\n\ndef solve():\n    # Test case A (general mixed, smooth polynomial)\n    N_A = 51\n    u_star_A = lambda x, y: x**2 - y**2\n    u_dy_A = lambda x, y: -2*y\n    bc_A = {\n        'left':   [(1.0, 'D', lambda x, y: u_star_A(0, y))],\n        'right':  [(1.0, 'D', lambda x, y: u_star_A(1, y))],\n        'bottom': [(1.0, 'N', lambda x, y: -u_dy_A(x, 0))],\n        'top':    [(1.0, 'N', lambda x, y: u_dy_A(x, 1))]\n    }\n    case_A = (N_A, u_star_A, bc_A)\n\n    # Test case B (piecewise mix on a side)\n    N_B = 51\n    u_star_B = lambda x, y: x\n    u_dx_B = lambda x, y: 1.0\n    u_dy_B = lambda x, y: 0.0\n    bc_B = {\n        'left':   [(1.0, 'D', lambda x, y: u_star_B(0, y))],\n        'right':  [(1.0, 'N', lambda x, y: u_dx_B(1, y))],\n        'bottom': [(1.0, 'D', lambda x, y: u_star_B(x, 0))],\n        'top':    [(0.4, 'N', lambda x, y: u_dy_B(x, 1)),\n                   (1.0, 'D', lambda x, y: u_star_B(x, 1))]\n    }\n    case_B = (N_B, u_star_B, bc_B)\n\n    # Test case C (edge case with small grid and homogeneous Neumann)\n    N_C = 9\n    u_star_C = lambda x, y: y\n    u_dx_C = lambda x, y: 0.0\n    u_dy_C = lambda x, y: 1.0\n    bc_C = {\n        'left':   [(1.0, 'N', lambda x, y: -u_dx_C(0, y))],\n        'right':  [(1.0, 'N', lambda x, y: u_dx_C(1, y))],\n        'bottom': [(1.0, 'D', lambda x, y: u_star_C(x, 0))],\n        'top':    [(1.0, 'D', lambda x, y: u_star_C(x, 1))]\n    }\n    case_C = (N_C, u_star_C, bc_C)\n    \n    test_cases = [case_A, case_B, case_C]\n    \n    results = []\n    for case in test_cases:\n        error = solve_laplace_2d(*case)\n        results.append(f\"{error:.8f}\")\n        \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2406696"}, {"introduction": "Discretizing the Laplace equation transforms a single partial differential equation into a large system of coupled linear algebraic equations. Solving this system efficiently is a critical challenge, especially for fine grids where direct matrix inversion is computationally prohibitive. This final practice [@problem_id:2406769] explores this challenge by comparing the convergence rates of three classic iterative solvers: Jacobi, Gauss-Seidel, and Successive Over-Relaxation (SOR). By implementing these methods, you will gain hands-on experience with their performance and understand the practical trade-offs involved in choosing a numerical solver.", "problem": "Consider the two-dimensional Laplace equation $\\nabla^2 u = 0$ on the square domain $\\Omega = (0,1)\\times(0,1)$ with Dirichlet boundary conditions. Let the boundary data be $u(x,0) = \\sin(\\pi x)$, $u(x,1) = 0$, $u(0,y)=0$, and $u(1,y)=0$, where angles are in radians. Discretize the domain using a uniform grid with $N$ interior points in each spatial direction (so that the grid spacing is $h = \\frac{1}{N+1}$ and there are $(N+2)\\times(N+2)$ total grid points including the boundary). Use the standard second-order centered finite-difference approximation for the Laplacian to obtain a linear system for the interior unknowns. Starting from the discrete Laplace operator definition derived from the continuous equation and central differences, implement three stationary iterative methods to solve the discrete equations: the Jacobi method, the Gauss–Seidel method, and the Successive Over-Relaxation (SOR) method with relaxation parameter $\\omega$ satisfying $0 < \\omega < 2$. For each method, use the following fundamental base and definitions:\n\n- The discrete Laplace equation at an interior grid point $(i,j)$ is obtained from the central-difference approximation to $\\nabla^2 u = 0$:\n$$\\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} + \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} = 0,$$\nwhich is algebraically equivalent to the stencil equation\n$$-u_{i+1,j} - u_{i-1,j} - u_{i,j+1} - u_{i,j-1} + 4 u_{i,j} = 0.$$\n- From this, define the discrete residual on the interior as\n$$r_{i,j} = 4u_{i,j} - \\left(u_{i+1,j}+u_{i-1,j}+u_{i,j+1}+u_{i,j-1}\\right),$$\nand its infinity norm as $\\|r\\|_{\\infty} = \\max_{i,j} |r_{i,j}|$.\n- Use the stopping rule $\\|r^{(k)}\\|_{\\infty} \\le \\text{tol}\\cdot \\|r^{(0)}\\|_{\\infty}$, where $\\text{tol}$ is a given tolerance and $k$ is the iteration index, with the initial guess $u^{(0)}$ equal to zero on all interior points and fixed boundary values on the boundary points.\n\nYour program must:\n- Implement the Jacobi iteration that updates all interior values using only the previous iteration’s values.\n- Implement the Gauss–Seidel iteration in a way that uses the most recently available neighbor values (you may use a red–black ordering to achieve this).\n- Implement the SOR iteration using red–black ordering with relaxation parameter $\\omega$ via\n$$u^{(k+1)}_{i,j} = u^{(k)}_{i,j} + \\omega\\left(\\frac{1}{4}\\left(u^{(*)}_{i+1,j}+u^{(*)}_{i-1,j}+u^{(*)}_{i,j+1}+u^{(*)}_{i,j-1}\\right) - u^{(k)}_{i,j}\\right),$$\nwhere $u^{(*)}$ denotes the most up-to-date values consistent with Gauss–Seidel ordering on each color. Take $\\omega = 1$ to recover Gauss–Seidel.\n\nYour task is to compare the convergence rates of the three methods quantitatively by reporting, for each test case, the number of iterations required by each method to satisfy the stopping rule. Use the same discretization, boundary conditions, and stopping criterion for all methods, and report iteration counts as integers.\n\nTest suite. Run your program on the following parameter sets, where each test case is a triple $(N, \\text{tol}, \\omega)$:\n- Test $1$: $(20, 10^{-5}, 1.5)$.\n- Test $2$: $(20, 10^{-5}, 1.0)$.\n- Test $3$: $(10, 10^{-8}, 1.8)$.\n- Test $4$: $(40, 10^{-4}, 1.9)$.\n\nFor each test case, your program must produce a list $[n_J, n_{GS}, n_{SOR}]$ containing the iteration counts required by the Jacobi, Gauss–Seidel, and SOR methods, respectively, to meet the stopping rule. Aggregate the results of all tests into a single line as a comma-separated list of these lists, with no spaces, enclosed in square brackets. For example, your output must look exactly like\n$[[n_J^{(1)},n_{GS}^{(1)},n_{SOR}^{(1)}],[n_J^{(2)},n_{GS}^{(2)},n_{SOR}^{(2)}],[n_J^{(3)},n_{GS}^{(3)},n_{SOR}^{(3)}],[n_J^{(4)},n_{GS}^{(4)},n_{SOR}^{(4)}]]$,\nprinted as a single line. No physical units are involved. Angles in the sine function must be interpreted in radians.", "solution": "The problem as stated is a standard, well-posed exercise in the numerical solution of elliptic partial differential equations. It is scientifically sound, self-contained, and algorithmically specified. There are no contradictions, ambiguities, or factual errors. Therefore, we proceed directly to the solution.\n\nThe problem requires solving the two-dimensional Laplace equation $\\nabla^2 u = \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} = 0$ on a unit square domain $\\Omega = (0,1)\\times(0,1)$. The potential $u(x,y)$ is subject to Dirichlet boundary conditions: $u(x,0) = \\sin(\\pi x)$, and $u=0$ on the other three boundaries.\n\nThe first step is to discretize the continuous problem. The domain is covered by a uniform grid with $(N+2) \\times (N+2)$ points, where $N$ is the number of interior points in each direction. The grid spacing is $h = \\frac{1}{N+1}$. A grid point is denoted by $(x_i, y_j) = (ih, jh)$ for indices $i,j \\in \\{0, 1, \\dots, N+1\\}$. The value of the potential at this point is $u_{i,j} \\approx u(x_i, y_j)$.\n\nThe Laplacian operator $\\nabla^2$ is approximated at each interior grid point $(i,j)$ using the second-order central difference formula:\n$$ \\nabla^2 u \\bigg|_{(x_i, y_j)} \\approx \\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} + \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} $$\nSetting this approximation to $0$ gives the discrete Laplace equation for the interior points ($1 \\le i,j \\le N$):\n$$ u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j} = 0 $$\nThis five-point stencil equation can be rearranged to express $u_{i,j}$ as the average of its four neighbors:\n$$ u_{i,j} = \\frac{1}{4} \\left( u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} \\right) $$\nThis set of $N^2$ linear equations for the $N^2$ interior unknown values forms a large, sparse linear system of the form $A\\mathbf{u} = \\mathbf{b}$, where $\\mathbf{u}$ is a vector of the unknowns $u_{i,j}$ and the matrix $A$ represents the discrete Laplacian operator. The right-hand side vector $\\mathbf{b}$ incorporates the fixed boundary values. Such systems are well-suited for solution by iterative methods.\n\nWe are tasked to implement three classical stationary iterative methods: Jacobi, Gauss-Seidel, and Successive Over-Relaxation (SOR). These methods start with an initial guess $u^{(0)}$ and generate a sequence of approximations $u^{(k)}$ that converges to the true solution.\n\nThe Jacobi method is the simplest iterative scheme. For each point $(i,j)$, the new value $u_{i,j}^{(k+1)}$ is computed using only the values from the previous iteration, $u^{(k)}$. The update rule is a direct application of the averaging formula:\n$$ u_{i,j}^{(k+1)} = \\frac{1}{4} \\left( u_{i+1,j}^{(k)} + u_{i-1,j}^{(k)} + u_{i,j+1}^{(k)} + u_{i,j-1}^{(k)} \\right) $$\nThis update can be performed for all interior points simultaneously (or in any order), as the calculation for each point is independent of the others within the same iteration. In a vectorized implementation, a full copy of the grid from iteration $k$ is required to compute the grid for iteration $k+1$.\n\nThe Gauss-Seidel method improves upon Jacobi by using the most recently computed values within the current iteration. The update rule is:\n$$ u_{i,j}^{(k+1)} = \\frac{1}{4} \\left( u_{i+1,j}^{(*)} + u_{i-1,j}^{(*)} + u_{i,j+1}^{(*)} + u_{i,j-1}^{(*)} \\right) $$\nwhere $u^{(*)}$ denotes the most up-to-date value available. For example, in a lexicographical ordering (row by row, column by column), the calculation for $u_{i,j}^{(k+1)}$ would use $u_{i-1,j}^{(k+1)}$ and $u_{i,j-1}^{(k+1)}$ from the current iteration $k+1$, and $u_{i+1,j}^{(k)}$ and $u_{i,j+1}^{(k)}$ from the previous iteration $k$. This dependency on the update order makes parallelization complex. The red-black ordering scheme circumvents this. The grid points are colored like a checkerboard. All \"red\" points are updated first, using values from their \"black\" neighbors (from the previous iteration). Then, all \"black\" points are updated, using the newly computed values from their \"red\" neighbors. Each of the two stages (red update, black update) can be fully vectorized.\n\nThe Successive Over-Relaxation (SOR) method is an extrapolation of the Gauss-Seidel method, designed to accelerate convergence. It computes the Gauss-Seidel update, and then pushes the solution further in that direction, controlled by a relaxation parameter $\\omega$. The update formula is:\n$$ u_{i,j}^{(k+1)} = u_{i,j}^{(k)} + \\omega \\left( u_{i,j}^{\\text{GS}} - u_{i,j}^{(k)} \\right) = (1-\\omega)u_{i,j}^{(k)} + \\omega u_{i,j}^{\\text{GS}} $$\nwhere $u_{i,j}^{\\text{GS}}$ is the value that would be computed by the Gauss-Seidel step at that point. Like Gauss-Seidel, SOR is implemented using the red-black ordering to efficiently use the most recent values. When $\\omega=1$, the SOR method reduces exactly to the Gauss-Seidel method. For Laplacetype problems, choosing an optimal $\\omega$ in the range $1 < \\omega < 2$ (over-relaxation) typically leads to a significant speedup in convergence.\n\nThe stopping criterion is based on the infinity norm of the discrete residual, defined as $\\|r^{(k)}\\|_{\\infty} = \\max_{i,j} |r_{i,j}^{(k)}|$, where $r_{i,j}^{(k)} = 4u_{i,j}^{(k)} - (u_{i+1,j}^{(k)} + u_{i-1,j}^{(k)} + u_{i,j+1}^{(k)} + u_{i,j-1}^{(k)})$. The iteration stops when $\\|r^{(k)}\\|_{\\infty} \\le \\text{tol} \\cdot \\|r^{(0)}\\|_{\\infty}$, where $\\text{tol}$ is a given tolerance and $\\|r^{(0)}\\|_{\\infty}$ is the residual norm of the initial guess ($u^{(0)}=0$ on the interior). This relative criterion ensures a fair comparison between different problem setups.\n\nThe implementation consists of three main functions. One function sets up the $(N+2) \\times (N+2)$ grid, initializing the interior to $0$ and setting the boundary conditions. A second function implements the Jacobi iteration. A third function implements the SOR iteration with red-black ordering, which is also used for the Gauss-Seidel method by setting $\\omega=1$. A helper function calculates the residual norm at each step. The main program iterates through the test cases, calls the appropriate solver functions, and records the number of iterations required for convergence.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef setup_initial_state(N):\n    \"\"\"\n    Initializes the grid with boundary conditions and zero interior.\n\n    Args:\n        N (int): Number of interior points in each direction.\n\n    Returns:\n        tuple: A tuple containing:\n            - np.ndarray: The (N+2)x(N+2) grid `u`.\n            - float: The grid spacing `h`.\n    \"\"\"\n    h = 1.0 / (N + 1)\n    u = np.zeros((N + 2, N + 2))\n    \n    # Set boundary condition u(x,0) = sin(pi*x)\n    # The j=0 row corresponds to y=0.\n    x_coords = np.linspace(0, 1, N + 2)\n    u[0, :] = np.sin(np.pi * x_coords)\n    \n    # Other boundaries u(x,1)=0, u(0,y)=0, u(1,y)=0 are already zero.\n    return u, h\n\ndef calculate_residual_norm(u, N):\n    \"\"\"\n    Calculates the infinity norm of the residual on the interior grid.\n\n    Args:\n        u (np.ndarray): The full (N+2)x(N+2) grid.\n        N (int): Number of interior grid points.\n\n    Returns:\n        float: The infinity norm of the residual.\n    \"\"\"\n    interior = u[1:N + 1, 1:N + 1]\n    neighbors_sum = (u[1:N + 1, 2:N + 2] + u[1:N + 1, 0:N] +\n                     u[2:N + 2, 1:N + 1] + u[0:N, 1:N + 1])\n    residual = 4 * interior - neighbors_sum\n    return np.max(np.abs(residual))\n\ndef solve_jacobi(N, tol):\n    \"\"\"\n    Solves the Laplace equation using the Jacobi method.\n\n    Args:\n        N (int): Number of interior grid points.\n        tol (float): Convergence tolerance.\n\n    Returns:\n        int: Number of iterations to converge.\n    \"\"\"\n    u, h = setup_initial_state(N)\n    \n    r0_norm = calculate_residual_norm(u, N)\n    if r0_norm == 0:\n        return 0\n    \n    threshold = tol * r0_norm\n    \n    k = 0\n    while True:\n        k += 1\n        \n        u_old = u.copy()\n        \n        neighbors_sum = (u_old[1:N + 1, 2:N + 2] + u_old[1:N + 1, 0:N] +\n                         u_old[2:N + 2, 1:N + 1] + u_old[0:N, 1:N + 1])\n        u[1:N + 1, 1:N + 1] = 0.25 * neighbors_sum\n        \n        r_norm = calculate_residual_norm(u, N)\n        if r_norm <= threshold:\n            return k\n\ndef solve_sor(N, tol, omega):\n    \"\"\"\n    Solves the Laplace equation using SOR with red-black ordering.\n    Recovers Gauss-Seidel for omega=1.0.\n\n    Args:\n        N (int): Number of interior grid points.\n        tol (float): Convergence tolerance.\n        omega (float): Relaxation parameter.\n\n    Returns:\n        int: Number of iterations to converge.\n    \"\"\"\n    u, h = setup_initial_state(N)\n    \n    r0_norm = calculate_residual_norm(u, N)\n    if r0_norm == 0:\n        return 0\n        \n    threshold = tol * r0_norm\n    \n    # Create red-black masks for the interior (N x N) grid.\n    # (j, i) indices for the interior part start from 0.\n    # Grid point (j_grid, i_grid) where j_grid, i_grid in [1,N]\n    # corresponds to mask point (j_grid-1, i_grid-1).\n    # Color depends on (j_grid + i_grid). (j_grid-1) + (i_grid-1) has same parity.\n    I, J = np.meshgrid(np.arange(N), np.arange(N))\n    red_mask = (I + J) % 2 == 0\n    black_mask = ~red_mask\n    \n    k = 0\n    while True:\n        k += 1\n        \n        # Keep a copy of the interior from the start of the iteration\n        # for the (1-omega) term.\n        u_old_interior = u[1:N + 1, 1:N + 1].copy()\n\n        # Update red points. Neighbors are black, use values from start of iteration.\n        neighbors_sum = (u[1:N + 1, 2:N + 2] + u[1:N + 1, 0:N] +\n                         u[2:N + 2, 1:N + 1] + u[0:N, 1:N + 1])\n        gs_update = 0.25 * neighbors_sum\n        u[1:N + 1, 1:N + 1][red_mask] = (1 - omega) * u_old_interior[red_mask] + \\\n                                      omega * gs_update[red_mask]\n\n        # Update black points. Neighbors are red, use newly updated values.\n        neighbors_sum = (u[1:N + 1, 2:N + 2] + u[1:N + 1, 0:N] +\n                         u[2:N + 2, 1:N + 1] + u[0:N, 1:N + 1])\n        gs_update = 0.25 * neighbors_sum\n        u[1:N + 1, 1:N + 1][black_mask] = (1 - omega) * u_old_interior[black_mask] + \\\n                                        omega * gs_update[black_mask]\n        \n        r_norm = calculate_residual_norm(u, N)\n        if r_norm <= threshold:\n            return k\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        (20, 1e-5, 1.5),\n        (20, 1e-5, 1.0),\n        (10, 1e-8, 1.8),\n        (40, 1e-4, 1.9),\n    ]\n\n    results = []\n    for N, tol, omega_sor in test_cases:\n        # Calculate iterations for Jacobi\n        n_J = solve_jacobi(N, tol)\n        \n        # Calculate iterations for Gauss-Seidel (SOR with omega=1.0)\n        n_GS = solve_sor(N, tol, 1.0)\n        \n        # Calculate iterations for SOR with the specified omega\n        n_SOR = solve_sor(N, tol, omega_sor)\n        \n        results.append([n_J, n_GS, n_SOR])\n\n    # Format the output string as specified: [[r1,r2,r3],[...],...]\n    formatted_results = [f'[{\",\".join(map(str, r))}]' for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2406769"}]}