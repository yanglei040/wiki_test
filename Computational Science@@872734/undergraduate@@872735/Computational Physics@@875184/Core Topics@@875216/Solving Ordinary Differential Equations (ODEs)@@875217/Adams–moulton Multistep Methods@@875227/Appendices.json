{"hands_on_practices": [{"introduction": "The implicit nature of Adams–Moulton methods is their defining characteristic, offering superior stability at the cost of increased computational effort per step. When applied to a nonlinear ordinary differential equation, this implicitness manifests as a nonlinear algebraic equation that must be solved for the solution at the next time step. This foundational exercise [@problem_id:2187830] guides you through the process of deriving this algebraic equation for the logistic model of population growth, translating the abstract concept of an implicit method into a concrete quadratic equation.", "problem": "The logistic differential equation is a fundamental model for population growth under limiting constraints. It is given by\n$$\ny'(t) = r y(t) \\left(1 - \\frac{y(t)}{K}\\right)\n$$\nwhere $y(t)$ is the population at time $t$, $r$ is the intrinsic growth rate, and $K$ is the carrying capacity. Both $r$ and $K$ are positive constants.\n\nTo solve this equation numerically, one can use a variety of methods. The two-step Adams–Moulton method is an implicit multistep method defined by the formula:\n$$\ny_{n+1} = y_n + \\frac{h}{12}(5f_{n+1} + 8f_n - f_{n-1})\n$$\nHere, $h$ is the constant step size, $y_k$ is the numerical approximation of $y(t_k)$ at time $t_k = t_0 + kh$, and $f_k$ is the shorthand for $f(t_k, y_k)$, where $f(t, y) = y'(t)$.\n\nBecause the term $f_{n+1}$ depends on the unknown value $y_{n+1}$, applying this method to a nonlinear differential equation results in a nonlinear algebraic equation that must be solved for $y_{n+1}$ at each step. For the logistic equation, this algebraic equation is quadratic in $y_{n+1}$ and can be written in the standard form:\n$$\nA y_{n+1}^2 + B y_{n+1} + C = 0\n$$\nYour task is to determine the expressions for the coefficients $A$, $B$, and $C$. Your final answer should be the expressions for $A$, $B$, and $C$ in terms of the step size $h$, the logistic model parameters $r$ and $K$, and the known values from previous steps, $y_n$, $f_n$, and $f_{n-1}$.", "solution": "We start from the logistic differential equation with $f(t,y)=r y\\left(1-\\frac{y}{K}\\right)=r y-\\frac{r}{K}y^{2}$ and the two-step Adams–Moulton method\n$$\ny_{n+1}=y_{n}+\\frac{h}{12}\\left(5 f_{n+1}+8 f_{n}-f_{n-1}\\right).\n$$\nSubstituting $f_{n+1}=f(t_{n+1},y_{n+1})=r y_{n+1}-\\frac{r}{K}y_{n+1}^{2}$ gives\n$$\ny_{n+1}=y_{n}+\\frac{h}{12}\\left(5\\left(r y_{n+1}-\\frac{r}{K}y_{n+1}^{2}\\right)+8 f_{n}-f_{n-1}\\right).\n$$\nBring all terms to the left-hand side to write a quadratic equation in $y_{n+1}$:\n$$\ny_{n+1}-y_{n}-\\frac{h}{12}\\left(5 r y_{n+1}-5\\frac{r}{K}y_{n+1}^{2}+8 f_{n}-f_{n-1}\\right)=0.\n$$\nCollecting like terms yields\n$$\n\\frac{5 h r}{12 K}y_{n+1}^{2}+\\left(1-\\frac{5 h r}{12}\\right)y_{n+1}-y_{n}-\\frac{h}{12}\\left(8 f_{n}-f_{n-1}\\right)=0.\n$$\nMatching this with $A y_{n+1}^{2}+B y_{n+1}+C=0$, we identify\n$$\nA=\\frac{5 h r}{12 K},\\quad B=1-\\frac{5 h r}{12},\\quad C=-y_{n}-\\frac{h}{12}\\left(8 f_{n}-f_{n-1}\\right).\n$$\nThese are expressed in terms of $h$, $r$, $K$, and the known quantities $y_{n}$, $f_{n}$, and $f_{n-1}$.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{5 h r}{12 K}  1-\\frac{5 h r}{12}  -y_{n}-\\frac{h}{12}\\left(8 f_{n}-f_{n-1}\\right)\\end{pmatrix}}$$", "id": "2187830"}, {"introduction": "Beyond local accuracy, a crucial test of a numerical method in physics is its ability to preserve fundamental invariants, like total energy, over long simulations. Standard methods like Adams–Moulton, when applied naively to conservative systems, are generally not \"symplectic\" and can introduce a systematic, non-physical drift in the computed energy. This advanced practice [@problem_id:2410042] challenges you to numerically demonstrate this energy drift, gaining a deeper appreciation for why specialized \"geometric integrators\" are essential for problems in mechanics and dynamics.", "problem": "You are asked to investigate, from first principles, whether a standard Adams–Bashforth/Adams–Moulton linear multistep method preserves the symplectic structure when applied to second-order conservative systems of the form $y''=f(y)$. In exact dynamics for such systems, total energy is conserved, and a symplectic numerical integrator preserves the symplectic $2$-form, typically exhibiting bounded, oscillatory energy error without long-term drift. Your task is to show numerically that a standard predictor–corrector pairing of a second-order Adams–Bashforth method with a second-order Adams–Moulton method (often denoted AB$2$/AM$2$), applied in the naïve way to the first-order reformulation of $y''=f(y)$, fails to conserve the symplectic structure and exhibits secular energy drift.\n\nStart from the following fundamental base:\n- Represent the second-order ordinary differential equation $y''=f(y)$ as a first-order system by introducing $x=y$ and $v=y'$, so that $x'=v$ and $v'=f(x)$. This system has the Hamiltonian (total energy) $H(x,v)$ that is conserved by the exact flow for conservative forces $f(x)=-\\partial U/\\partial x$ with potential $U(x)$.\n- Define the total energy as $H(x,v)=\\tfrac{1}{2}v^{2}+U(x)$, with $U(x)$ determined by $f(x)=-U'(x)$.\n- A linear multistep Adams method is constructed by integrating an interpolating polynomial approximation of the right-hand side over one step, using equally spaced past nodes.\n\nDerive from these bases:\n- The second-order Adams–Bashforth predictor for advancing one step using past evaluations of the right-hand side.\n- The second-order Adams–Moulton corrector for the same step, and the standard one-step predictor–evaluate–correct–evaluate (PECE) protocol applied componentwise to the first-order system $(x',v')=(v,f(x))$.\n- A one-step self-starting method to obtain the first additional state from the initial condition, before the multistep iteration begins.\n\nImplement the resulting AB$2$/AM$2$ PECE algorithm for the first-order system and use it to integrate over a long time interval. Quantify the presence or absence of energy drift by fitting a straight line $H(t)\\approx \\alpha t+\\beta$ to the numerically computed energy sequence via least squares and reporting the estimated slope $\\alpha$.\n\nUse the following test suite of cases, all with initial conditions $x(0)=y(0)=1$ and $v(0)=y'(0)=0$:\n- Case A (simple harmonic oscillator): $f(y)=-y$, potential $U(x)=\\tfrac{1}{2}x^{2}$, time step $h=0.1$ (dimensionless), total simulated time $T=1000$ (dimensionless).\n- Case B (simple harmonic oscillator): $f(y)=-y$, potential $U(x)=\\tfrac{1}{2}x^{2}$, time step $h=0.05$ (dimensionless), total simulated time $T=1000$ (dimensionless).\n- Case C (mathematical pendulum): $f(y)=-\\sin(y)$, potential $U(x)=1-\\cos(x)$, time step $h=0.05$ (dimensionless), total simulated time $T=1000$ (dimensionless), with angle $x$ measured in radians.\n\nImplementation requirements:\n- Reformulate $y''=f(y)$ as the first-order system $(x',v')=(v,f(x))$ and apply your AB$2$/AM$2$ PECE method componentwise.\n- Use a single-step, explicit, self-starting method of your choice to produce the first additional value needed by the multistep method; for example, a classical fourth-order Runge–Kutta step is acceptable.\n- Compute the discrete energy $H_{n}=H(x_{n},v_{n})$ at each time $t_{n}$, and estimate the drift slope $\\alpha$ by least squares fit of $H_{n}$ versus $t_{n}$ over the entire simulation window.\n- For each case, report the scalar slope $\\alpha$ as a floating-point number rounded to $6$ significant digits. No physical units are required for this problem.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order [Case A, Case B, Case C]. For example, your program must print a line formatted as $[a,b,c]$ where $a$, $b$, and $c$ are the requested slopes for the three cases, each rounded to $6$ significant digits.\n\nTest suite summary to implement exactly:\n- Case A: $(f(y)=-y,\\,h=0.1,\\,T=1000)$.\n- Case B: $(f(y)=-y,\\,h=0.05,\\,T=1000)$.\n- Case C: $(f(y)=-\\sin(y),\\,h=0.05,\\,T=1000)$, angle in radians.\n\nYour program must be self-contained, require no input, and follow the specified output format precisely.", "solution": "We begin by reformulating the second-order ordinary differential equation $y''=f(y)$ as a first-order system by introducing $x=y$ and $v=y'$. This yields the system\n$$\nx'=v,\\qquad v'=f(x).\n$$\nFor a conservative force $f(x)=-U'(x)$, the Hamiltonian (total energy) is $H(x,v)=\\tfrac{1}{2}v^{2}+U(x)$, which is conserved by the exact solution. Symplectic integrators preserve the canonical symplectic $2$-form, and although they do not generally conserve $H$ exactly at each step, they typically produce bounded, oscillatory energy error over long times without secular drift. In contrast, non-symplectic methods often exhibit secular growth or decay in a fitted energy trend.\n\nThe Adams family of linear multistep methods is derived by integrating over a step the right-hand side replaced by a polynomial interpolant through past (explicit Adams–Bashforth) or including the new point (implicit Adams–Moulton) data. For a uniform step size $h$, let $t_{n+1}=t_{n}+h$ and $y_{n}\\approx y(t_{n})$. The second-order Adams–Bashforth method is obtained by integrating the degree-$1$ Lagrange interpolant through $(t_{n},f_{n})$ and $(t_{n-1},f_{n-1})$, leading to\n$$\ny_{n+1}=y_{n}+h\\left(\\tfrac{3}{2}f_{n}-\\tfrac{1}{2}f_{n-1}\\right).\n$$\nThe second-order Adams–Moulton method (the trapezoidal rule) integrates the degree-$1$ interpolant through $(t_{n},f_{n})$ and $(t_{n+1},f_{n+1})$ to give\n$$\ny_{n+1}=y_{n}+h\\left(\\tfrac{1}{2}f_{n+1}+\\tfrac{1}{2}f_{n}\\right).\n$$\nApplied to the vector first-order system $z' = G(z)$ with $z=[x,v]^{\\top}$ and $G(z)=[v,\\,f(x)]^{\\top}$, these formulas hold componentwise with $f_{n}$ replaced by $G(z_{n})$.\n\nA standard predictor–evaluate–correct–evaluate (PECE) protocol that pairs AB$2$ (predictor) and AM$2$ (corrector) performs:\n- Predictor (AB$2$):\n$$\nz_{n+1}^{\\mathrm{p}}=z_{n}+h\\left(\\tfrac{3}{2}G(z_{n})-\\tfrac{1}{2}G(z_{n-1})\\right).\n$$\n- Evaluate at the predictor: compute $G(z_{n+1}^{\\mathrm{p}})$.\n- Corrector (AM$2$ with one evaluation at the predictor):\n$$\nz_{n+1}=z_{n}+h\\left(\\tfrac{1}{2}G(z_{n+1}^{\\mathrm{p}})+\\tfrac{1}{2}G(z_{n})\\right).\n$$\nThis is a common practical realization of the AB/AM pair that avoids solving a fully implicit system. However, this PECE variant is not symplectic for general Hamiltonian systems.\n\nBecause a linear multistep method requires starting values beyond the initial condition, we employ a single-step explicit method to compute $z_{1}$ from $z_{0}$. A classical fourth-order Runge–Kutta (RK$4$) step with step size $h$ suffices:\n$$\n\\begin{aligned}\nk_{1}=G(z_{0}),\\\\\nk_{2}=G\\!\\left(z_{0}+\\tfrac{h}{2}k_{1}\\right),\\\\\nk_{3}=G\\!\\left(z_{0}+\\tfrac{h}{2}k_{2}\\right),\\\\\nk_{4}=G\\!\\left(z_{0}+h\\,k_{3}\\right),\\\\\nz_{1}=z_{0}+\\tfrac{h}{6}\\left(k_{1}+2k_{2}+2k_{3}+k_{4}\\right).\n\\end{aligned}\n$$\n\nTo diagnose energy drift, we compute the energy sequence $H_{n}=H(x_{n},v_{n})$ for $n=0,1,\\dots,N$ at times $t_{n}=n\\,h$ over the interval $[0,T]$ with $N=T/h$. We fit a line $H_{n}\\approx \\alpha t_{n}+\\beta$ by least squares. The least squares slope is\n$$\n\\alpha=\\frac{\\sum_{n=0}^{N}(t_{n}-\\bar{t})(H_{n}-\\bar{H})}{\\sum_{n=0}^{N}(t_{n}-\\bar{t})^{2}},\n$$\nwhere $\\bar{t}$ and $\\bar{H}$ are the sample means of $\\{t_{n}\\}$ and $\\{H_{n}\\}$. A nonzero $\\alpha$ over a long interval indicates secular energy drift, which is incompatible with exact symplectic structure preservation.\n\nWe define the test systems and their energies:\n- Simple harmonic oscillator with $f(y)=-y$ has $U(x)=\\tfrac{1}{2}x^{2}$, so\n$$\nH(x,v)=\\tfrac{1}{2}v^{2}+\\tfrac{1}{2}x^{2}.\n$$\n- Mathematical pendulum with $f(y)=-\\sin(y)$ has $U(x)=1-\\cos(x)$, so\n$$\nH(x,v)=\\tfrac{1}{2}v^{2}+1-\\cos(x),\n$$\nwith $x$ in radians.\n\nAlgorithm summary for each case:\n- Set $z_{0}=[x_{0},v_{0}]^{\\top}$ with $x_{0}=1$ and $v_{0}=0$.\n- Compute $z_{1}$ using RK$4$ with step size $h$.\n- For $n=1,2,\\dots,N-1$, iterate the AB$2$/AM$2$ PECE update to obtain $z_{n+1}$.\n- Compute $H_{n}$ at each step and then estimate $\\alpha$ by least squares.\n- Report $\\alpha$ rounded to $6$ significant digits.\n\nExpected qualitative outcome:\n- For the simple harmonic oscillator, a symplectic method such as the Störmer–Verlet scheme would produce $\\alpha$ very close to $0$ with bounded oscillations in $H_{n}$. The AB$2$/AM$2$ PECE method, being non-symplectic in this application, yields a nonzero $\\alpha$ whose magnitude grows with $h$.\n- For the pendulum, the same phenomenon occurs; the fitted slope $\\alpha$ is nonzero, indicating drift.\n\nThe program implements the above and prints the three slopes in the required order and format $[a,b,c]$, each to $6$ significant digits.", "answer": "```python\nimport numpy as np\n\ndef rk4_step(G, z, h):\n    k1 = G(z)\n    k2 = G(z + 0.5 * h * k1)\n    k3 = G(z + 0.5 * h * k2)\n    k4 = G(z + h * k3)\n    return z + (h / 6.0) * (k1 + 2*k2 + 2*k3 + k4)\n\ndef ab2_am2_pece(G, z0, h, T):\n    N = int(round(T / h))\n    t = np.linspace(0.0, N * h, N + 1)\n    z = np.zeros((N + 1, 2), dtype=float)\n    z[0] = z0\n    # Self-start with RK4 to obtain z[1]\n    z[1] = rk4_step(G, z[0], h)\n    # Precompute G at steps 0 and 1\n    G_prev = G(z[0])\n    G_curr = G(z[1])\n    for n in range(1, N):\n        # Predictor: AB2\n        z_pred = z[n] + h * (1.5 * G_curr - 0.5 * G_prev)\n        G_pred = G(z_pred)\n        # Corrector: AM2 with one evaluation (PECE)\n        z_next = z[n] + 0.5 * h * (G_pred + G_curr)\n        # Shift for next iteration\n        z[n + 1] = z_next\n        G_prev, G_curr = G_curr, G(z_next)\n    return t, z\n\ndef make_system(system_name):\n    if system_name == \"sho\":\n        # f(x) = -x\n        def G(z):\n            x, v = z\n            return np.array([v, -x], dtype=float)\n        def energy(z):\n            x, v = z\n            return 0.5 * v * v + 0.5 * x * x\n        return G, energy\n    elif system_name == \"pendulum\":\n        # f(x) = -sin(x), x in radians\n        def G(z):\n            x, v = z\n            return np.array([v, -np.sin(x)], dtype=float)\n        def energy(z):\n            x, v = z\n            return 0.5 * v * v + (1.0 - np.cos(x))\n        return G, energy\n    else:\n        raise ValueError(\"Unknown system\")\n\ndef energy_drift_slope(t, H):\n    # Least-squares slope of H versus t\n    t_mean = np.mean(t)\n    H_mean = np.mean(H)\n    num = np.sum((t - t_mean) * (H - H_mean))\n    den = np.sum((t - t_mean) ** 2)\n    return num / den if den != 0.0 else 0.0\n\ndef run_case(system_name, h, T):\n    G, energy = make_system(system_name)\n    z0 = np.array([1.0, 0.0], dtype=float)\n    t, z = ab2_am2_pece(G, z0, h, T)\n    H = np.array([energy(zi) for zi in z])\n    slope = energy_drift_slope(t, H)\n    return slope\n\ndef solve():\n    # Define the test cases as per the problem statement:\n    # Case A: (sho, h=0.1, T=1000)\n    # Case B: (sho, h=0.05, T=1000)\n    # Case C: (pendulum, h=0.05, T=1000), angle in radians\n    test_cases = [\n        (\"sho\", 0.1, 1000.0),\n        (\"sho\", 0.05, 1000.0),\n        (\"pendulum\", 0.05, 1000.0),\n    ]\n\n    results = []\n    for system_name, h, T in test_cases:\n        slope = run_case(system_name, h, T)\n        results.append(slope)\n\n    # Format each result to 6 significant digits\n    formatted = [f\"{v:.6g}\" for v in results]\n    print(f\"[{','.join(formatted)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2410042"}, {"introduction": "In practice, a fixed step size is inefficient, as it must be chosen small enough for the most challenging part of the integration interval. This exercise [@problem_id:2371573] transitions from textbook methods to practical scientific computing by tasking you with building an adaptive solver. You will implement a step-size control algorithm that uses the difference between a predictor and corrector step to estimate the local error, automatically adjusting the step size $h$ to meet a desired accuracy tolerance, a core technique in professional-grade software.", "problem": "You are to design and implement an adaptive step-size controller for a predictor–corrector Adams–Moulton method that aims to keep the local error per unit step below a user-specified tolerance. Consider an initial-value problem defined by the ordinary differential equation (ODE) $y'(t)=f(t,y)$ with initial condition $y(t_0)=y_0$. You will use the second-order implicit trapezoidal rule (an Adams–Moulton method) as the corrector, coupled with a forward Euler predictor. The local error per unit step is to be estimated by the norm of the predictor–corrector difference divided by the current step size.\n\nStarting point (fundamental base): the ODE satisfies the integral relation\n$$\ny(t_{n+1}) = y(t_n) + \\int_{t_n}^{t_{n+1}} f(s, y(s))\\, ds,\n$$\nwith time nodes $t_{n+1}=t_n+h_n$, where $h_n$ is the step size for the $n$-th step. The implicit trapezoidal rule approximates the integral by a linear interpolant of $f$, leading to a corrector that utilizes $f(t_n,y_n)$ and $f(t_{n+1},y_{n+1})$. To avoid solving a fully implicit nonlinear equation, use a predictor–corrector approach: predict $y_{n+1}^p$ explicitly, then correct to $y_{n+1}^c$ by applying the trapezoidal rule with $f(t_{n+1},y_{n+1}^p)$ in place of the unknown $f(t_{n+1},y_{n+1}^c)$.\n\nDefine the per-step error indicator by\n$$\ne_n \\equiv \\frac{\\|y_{n+1}^p - y_{n+1}^c\\|}{h_n},\n$$\nwhere $\\|\\cdot\\|$ is the Euclidean norm. The adaptive controller must:\n- accept a step if $e_n \\le \\text{tol}$, where $\\text{tol} > 0$ is a user-specified tolerance,\n- otherwise reject the step and retry with a smaller $h_n$,\n- adjust $h_n$ for the next attempted step using a scale factor informed by how $e_n$ compares to $\\text{tol}$, together with a safety factor strictly between $0$ and $1$, and lower and upper bounds $h_{\\min}$ and $h_{\\max}$,\n- handle the final step so that $t$ lands exactly on the final time $T$ by shortening the step as needed,\n- use the Euclidean norm for vectors and the absolute value for scalars,\n- if $e_n=0$, increase the step cautiously within bounds,\n- if $h_n$ reaches $h_{\\min}$ and $e_n$ still exceeds tolerance, proceed by accepting the step to avoid deadlock, while still attempting to reduce $e_n$ on subsequent steps.\n\nImplement this algorithm in a single, complete, runnable program. The program must include a function that integrates any provided right-hand side $f(t,y)$ on an interval $[t_0,T]$ with initial condition $y_0$, using the described adaptive Adams–Moulton predictor–corrector scheme. Use the Euclidean norm for $\\|\\cdot\\|$. All variables are dimensionless; no physical units are required.\n\nTest suite. Run your solver on the following four test cases:\n\n- Case A (scalar exponential decay):\n  - $f(t,y) = -2\\,y$,\n  - $t_0 = 0$, $T = 5$,\n  - $y_0 = 1$,\n  - $\\text{tol} = 10^{-5}$,\n  - $h_0 = 0.1$, $h_{\\min} = 10^{-6}$, $h_{\\max} = 1$.\n  - Output for this case: the final value $y(T)$ as a float.\n\n- Case B (two-dimensional harmonic oscillator with angular frequency $\\omega$):\n  - State $y = [q,p]^\\top$ obeys $q' = p$, $p' = -\\omega^2 q$ with $\\omega = 5$,\n  - $t_0 = 0$, $T = 2\\pi/\\omega$,\n  - $y_0 = [1,0]^\\top$,\n  - $\\text{tol} = 10^{-6}$,\n  - $h_0 = 0.05$, $h_{\\min} = 10^{-6}$, $h_{\\max} = 0.2$.\n  - Output for this case: the final values $q(T)$ and $p(T)$ as two floats, in that order.\n\n- Case C (scalar logistic growth):\n  - $f(t,y) = r\\,y\\,(1 - y/K)$ with parameters $r = 3$, $K=1$,\n  - $t_0 = 0$, $T = 5$,\n  - $y_0 = 0.2$,\n  - $\\text{tol} = 10^{-5}$,\n  - $h_0 = 0.1$, $h_{\\min} = 10^{-6}$, $h_{\\max} = 0.5$.\n  - Output for this case: the final value $y(T)$ as a float.\n\n- Case D (edge case: very tight tolerance and small final time):\n  - $f(t,y) = y$,\n  - $t_0 = 0$, $T = 10^{-3}$,\n  - $y_0 = 1$,\n  - $\\text{tol} = 10^{-10}$,\n  - $h_0 = 10^{-4}$, $h_{\\min} = 10^{-8}$, $h_{\\max} = 10^{-2}$.\n  - Output for this case: the total number of accepted steps as an integer.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order\n$$\n[\\;y_A(T),\\; q_B(T),\\; p_B(T),\\; y_C(T),\\; N_D\\;],\n$$\nwhere $y_A(T)$ is the Case A final value, $q_B(T)$ and $p_B(T)$ are the Case B final position and momentum, $y_C(T)$ is the Case C final value, and $N_D$ is the Case D number of accepted steps. For example, a valid printed line looks like\n$$\n[\\;0.123456,\\;0.99999,\\;-0.00001,\\;0.98765,\\;42\\;].\n$$", "solution": "The problem is to construct and implement a numerical solver for an initial value problem (IVP) of a first-order ordinary differential equation (ODE). The IVP is defined as\n$$\n\\frac{dy}{dt} = f(t,y), \\quad y(t_0) = y_0.\n$$\nThe solver must employ an adaptive step-size strategy based on a predictor-corrector scheme. The scheme specified is a forward Euler predictor coupled with a second-order Adams–Moulton corrector, which is the implicit trapezoidal rule.\n\nThe fundamental principle is the integral form of the ODE, which relates the solution at time $t_n$ to the solution at $t_{n+1} = t_n + h_n$:\n$$\ny(t_{n+1}) = y(t_n) + \\int_{t_n}^{t_{n+1}} f(s, y(s)) \\, ds.\n$$\n\nThe specified predictor-corrector algorithm proceeds in two stages for each step from $t_n$ to $t_{n+1}$:\n\n1.  **Predictor Step**: An explicit forward Euler method is used to generate a first estimate of the solution at $t_{n+1}$, denoted $y_{n+1}^p$. This method approximates the integral by assuming the integrand $f(s, y(s))$ is constant over the interval $[t_n, t_{n+1}]$ and equal to its value at the start of the interval, $f(t_n, y_n)$.\n    $$\n    y_{n+1}^p = y_n + h_n f(t_n, y_n).\n    $$\n    This is a first-order accurate prediction.\n\n2.  **Corrector Step**: The trapezoidal rule is used to obtain a more accurate, corrected value, $y_{n+1}^c$. This rule approximates the integral by the area of a trapezoid formed by a linear interpolant between $f(t_n, y_n)$ and $f(t_{n+1}, y_{n+1})$. To avoid solving a nonlinear implicit equation for $y_{n+1}$, the predicted value $y_{n+1}^p$ is used to evaluate the function at the end of the interval, $f(t_{n+1}, y_{n+1}^p)$.\n    $$\n    y_{n+1}^c = y_n + \\frac{h_n}{2} \\left[ f(t_n, y_n) + f(t_{n+1}, y_{n+1}^p) \\right].\n    $$\n    This is a second-order accurate correction. The value $y_{n+1}^c$ is accepted as the final approximation for the step, $y_{n+1} = y_{n+1}^c$, provided the error criterion is met.\n\nThe core of the adaptive algorithm is the step-size controller, which relies on an estimate of the local error. The problem defines a specific error indicator, $e_n$, for the step from $t_n$ to $t_{n+1}$:\n$$\ne_n = \\frac{\\|y_{n+1}^p - y_{n+1}^c\\|}{h_n},\n$$\nwhere $\\|\\cdot\\|$ denotes the Euclidean norm for vectors or the absolute value for scalars. This indicator must be controlled to remain below a specified tolerance, $\\text{tol}$.\n\nThe local truncation error of the first-order predictor is $O(h_n^2)$, while the local truncation error of the second-order corrector is $O(h_n^3)$. The difference between the predictor and corrector values, $y_{n+1}^c - y_{n+1}^p$, is an estimate of the error in the predictor step and is of order $O(h_n^2)$.\n$$\n\\|y_{n+1}^p - y_{n+1}^c\\| = \\left\\| h_n f_n - \\frac{h_n}{2}(f_n + f(t_n+h_n, y_n+h_n f_n)) \\right\\| \\approx \\left\\| \\frac{h_n^2}{2} y''(t_n) \\right\\|.\n$$\nTherefore, the error indicator $e_n$ is of order $O(h_n)$:\n$$\ne_n \\approx \\frac{1}{h_n} \\left\\| \\frac{h_n^2}{2} y''(t_n) \\right\\| = \\frac{h_n}{2} \\|y''(t_n)\\|.\n$$\nSince $e_n \\propto h_n$, to adjust the step size from $h_{old}$ to $h_{new}$ such that the new error $e_{new}$ approximates the tolerance $\\text{tol}$, we use the relation $e_{new}/e_{old} \\approx h_{new}/h_{old}$. This gives $h_{new} \\approx h_{old} (\\text{tol}/e_{old})$.\n\nThe complete adaptive step-size control logic is as follows:\n\n1.  For a step from $t_n$ to $t_{n+1}$ with a proposed step size $h$, first ensure that the integration does not proceed past the final time $T$. The actual step size used is $h_{step} = \\min(h, T - t_n)$.\n\n2.  Calculate $y_{n+1}^p$ and $y_{n+1}^c$ using $h_{step}$.\n\n3.  Compute the error indicator $e_n = \\|y_{n+1}^p - y_{n+1}^c\\|/h_{step}$.\n\n4.  **Step Acceptance/Rejection**:\n    -   If $e_n \\le \\text{tol}$, the step is accepted. The new state is $(t_{n+1}, y_{n+1}) = (t_n + h_{step}, y_{n+1}^c)$.\n    -   If $e_n  \\text{tol}$, the step is rejected. The state remains $(t_n, y_n)$, and a new, smaller step size $h$ must be computed to retry the step.\n\n5.  **Step Size Update**: The calculation of the next step size, $h_{next}$, is based on the current step's outcome.\n    -   A safety factor $S$ (e.g., $S=0.9$) is used to provide a conservative estimate.\n    -   The update formula is $h_{new} = h_{step} \\times S \\times (\\frac{\\text{tol}}{e_n})$.\n    -   If $e_n=0$, the step size should be increased cautiously. A reasonable choice is to set the scaling factor $\\text{tol}/e_n$ to a maximum growth factor, for instance $5$.\n    -   To ensure stability, the change in step size is typically bounded. We enforce $h_{new}/h_{step} \\in [0.2, 5.0]$.\n    -   The new step size is clamped to the interval $[h_{min}, h_{max}]$.\n\n6.  **Algorithm Flow**:\n    -   If a step is accepted, $h_{next}$ is calculated using the update rule and used as the initial guess for the subsequent step.\n    -   If a step is rejected, $h_{next}$ is calculated and used to *retry* the current step. This loop continues until a step is accepted.\n\n7.  **Deadlock Prevention**: If a step is rejected and the required new step size $h_{next}$ is smaller than $h_{min}$, or if the current step size $h_{step}$ is already at $h_{min}$, the algorithm is stuck. To prevent deadlock, the step is accepted with the current result $y_{n+1}^c$ computed using $h_{step}=h_{min}$. The next step will also start with $h_{min}$. This is a pragmatic choice to ensure forward progress, even if the error tolerance is momentarily violated.\n\nThe integration proceeds from $t_0$ to $T$ by iteratively applying this adaptive step-taking logic until $t_n=T$. The final implementation aggregates results from the four specified test cases into a single output.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef adaptive_am2_solver(f, t0, T, y0, tol, h0, h_min, h_max):\n    \"\"\"\n    Integrates an ODE y'(t) = f(t,y) from t0 to T with initial condition y0\n    using an adaptive 2nd-order Adams-Moulton (Trapezoidal) method.\n\n    The predictor is the Forward Euler method. The step size is adapted to keep\n    the local error per unit step below a tolerance.\n    \"\"\"\n    t = t0\n    y = np.asarray(y0, dtype=float)\n    h = h0\n\n    accepted_steps = 0\n    rejected_steps = 0\n\n    # Safety factor for step size update\n    safety_factor = 0.9\n    # Step size change limiters\n    max_growth = 5.0\n    min_shrink = 0.2\n\n    while t  T:\n        # Ensure the last step lands exactly on T\n        if t + h  T:\n            h = T - t\n\n        # Rejection loop for the current step\n        while True:\n            # Check for infinitesimal step size\n            if t + h = t:\n                # Cannot make progress, break from all loops\n                # This can happen if h becomes smaller than machine epsilon relative to t.\n                t = T \n                break\n\n            # Predictor step (Forward Euler)\n            f_current = f(t, y)\n            y_p = y + h * f_current\n\n            # Corrector step (Trapezoidal Rule)\n            y_c = y + (h / 2.0) * (f_current + f(t + h, y_p))\n            \n            # Estimate error\n            if y.ndim == 0: # Scalar case\n                error_norm = np.abs(y_p - y_c)\n            else: # Vector case\n                error_norm = np.linalg.norm(y_p - y_c)\n            \n            # Error per unit step as defined in the problem\n            e_n = error_norm / h if h  0 else np.inf\n            \n            # Determine if the step is accepted or rejected\n            if e_n = tol:\n                # Step accepted\n                t += h\n                y = y_c\n                accepted_steps += 1\n                \n                # Calculate step size for the next step\n                if e_n == 0:\n                    growth_ratio = max_growth\n                else:\n                    growth_ratio = safety_factor * (tol / e_n)**1.0\n                \n                h = h * min(max_growth, max(min_shrink, growth_ratio))\n                h = min(h_max, max(h_min, h))\n                \n                break # Exit rejection loop\n            else:\n                # Step rejected\n                rejected_steps += 1\n                \n                # Propose a smaller step size for retry\n                shrink_ratio = safety_factor * (tol / e_n)**1.0\n                h_new = h * min(max_growth, max(min_shrink, shrink_ratio))\n                \n                # Deadlock prevention\n                if h = h_min:\n                    # Current step size is at minimum, but error is too high.\n                    # Accept the step to move on.\n                    t += h\n                    y = y_c\n                    accepted_steps += 1\n                    h = h_min # Continue with h_min\n                    break # Exit rejection loop\n\n                h = max(h_min, h_new)\n\n\n    result = {\n        'y_final': y.item() if y.ndim == 0 else y,\n        'accepted_steps': accepted_steps,\n        'rejected_steps': rejected_steps,\n        'final_time': t\n    }\n    return result\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: scalar exponential decay\n        {\n            'name': 'A',\n            'f': lambda t, y: -2.0 * y,\n            't0': 0.0, 'T': 5.0,\n            'y0': 1.0,\n            'tol': 1e-5,\n            'h0': 0.1, 'h_min': 1e-6, 'h_max': 1.0,\n            'output': 'y_final'\n        },\n        # Case B: two-dimensional harmonic oscillator\n        {\n            'name': 'B',\n            'f': lambda t, y: np.array([y[1], -25.0 * y[0]]),\n            't0': 0.0, 'T': 2.0 * np.pi / 5.0,\n            'y0': np.array([1.0, 0.0]),\n            'tol': 1e-6,\n            'h0': 0.05, 'h_min': 1e-6, 'h_max': 0.2,\n            'output': 'y_final'\n        },\n        # Case C: scalar logistic growth\n        {\n            'name': 'C',\n            'f': lambda t, y: 3.0 * y * (1.0 - y / 1.0),\n            't0': 0.0, 'T': 5.0,\n            'y0': 0.2,\n            'tol': 1e-5,\n            'h0': 0.1, 'h_min': 1e-6, 'h_max': 0.5,\n            'output': 'y_final'\n        },\n        # Case D: edge case\n        {\n            'name': 'D',\n            'f': lambda t, y: y,\n            't0': 0.0, 'T': 1e-3,\n            'y0': 1.0,\n            'tol': 1e-10,\n            'h0': 1e-4, 'h_min': 1e-8, 'h_max': 1e-2,\n            'output': 'accepted_steps'\n        }\n    ]\n\n    results_list = []\n    for case in test_cases:\n        res = adaptive_am2_solver(\n            case['f'], case['t0'], case['T'], case['y0'],\n            case['tol'], case['h0'], case['h_min'], case['h_max']\n        )\n        output_val = res[case['output']]\n        \n        if isinstance(output_val, np.ndarray):\n            results_list.extend(output_val.tolist())\n        else:\n            results_list.append(output_val)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results_list))}]\")\n\nsolve()\n```", "id": "2371573"}]}