{"hands_on_practices": [{"introduction": "The fluctuation-dissipation theorem is a cornerstone of statistical mechanics, providing a profound link between the microscopic fluctuations of a system in thermal equilibrium and its macroscopic response to external perturbations. This exercise provides a direct, hands-on verification of this theorem for a non-interacting paramagnet [@problem_id:2400547]. By comparing the heat capacity and magnetic susceptibility calculated from energy and magnetization fluctuations with those obtained from numerical derivatives, you will build confidence in both the physical theory and the computational techniques.", "problem": "A non-interacting $spin-\\frac{1}{2}$ paramagnet consists of $N$ identical, independent magnetic moments, each of magnitude $\\mu$, in a uniform magnetic field $B$. Each spin $s_i \\in \\{+1,-1\\}$ contributes an energy $-\\mu B s_i$, so the total energy is $E=-\\mu B \\sum_{i=1}^{N} s_i$ and the total magnetic moment is $M=\\mu \\sum_{i=1}^{N} s_i$. The system is in thermal equilibrium with a heat bath at absolute temperature $T$ and is described by the canonical ensemble with inverse temperature $\\beta = 1/(k_B T)$, where $k_B$ is the Boltzmann constant.\n\nYour task is to compute, for each parameter set in the test suite below, the following four quantities using first principles of equilibrium statistical mechanics:\n1) The heat capacity at constant volume $C_V$ from energy fluctuations, defined by $C_V = \\langle(\\Delta E)^2\\rangle/(k_B T^2)$, where $\\langle(\\Delta E)^2\\rangle = \\langle E^2 \\rangle - \\langle E \\rangle^2$ is the energy variance in the canonical ensemble at the specified $T$ and $B$.\n2) The heat capacity $C_V$ by numerically differentiating the average energy with respect to $T$ at fixed $B$, i.e., $C_V = \\mathrm{d}\\langle E \\rangle/\\mathrm{d}T$.\n3) The magnetic susceptibility $\\chi$ from magnetization fluctuations, defined by $\\chi = \\beta \\langle(\\Delta M)^2\\rangle$, where $\\langle(\\Delta M)^2\\rangle = \\langle M^2 \\rangle - \\langle M \\rangle^2$ is the magnetization variance in the canonical ensemble at the specified $T$ and $B$.\n4) The magnetic susceptibility $\\chi$ by numerically differentiating the average magnetization with respect to $B$ at fixed $T$, i.e., $\\chi = \\mathrm{d}\\langle M \\rangle/\\mathrm{d}B$.\n\nUse the canonical-ensemble definitions of averages $\\langle \\cdot \\rangle$ derived from the Boltzmann weights of the microstates of the specified model. All computations must be expressed in the International System of Units (SI): use $k_B = 1.380649\\times 10^{-23}\\,\\text{J/K}$ and $\\mu = \\mu_B = 9.2740100783\\times 10^{-24}\\,\\text{J/T}$. Report $C_V$ in $\\text{J/K}$ and $\\chi$ in $\\text{A}\\cdot\\text{m}^2/\\text{T}$. Angles do not appear in this problem. Do not use percentages.\n\nFor each parameter set, produce two diagnostic outputs:\n- The absolute difference between the two estimates of $C_V$, i.e., $|C_V^{\\mathrm{fluct}} - C_V^{\\mathrm{num}}|$ in $\\text{J/K}$.\n- The absolute difference between the two estimates of $\\chi$, i.e., $|\\chi^{\\mathrm{fluct}} - \\chi^{\\mathrm{num}}|$ in $\\text{A}\\cdot\\text{m}^2/\\text{T}$.\n\nTest suite (each case lists ($N, \\mu, B, T$)):\n- Case A: ($N=50$, $\\mu=9.2740100783\\times 10^{-24}\\,\\text{J/T}$, $B=0.1\\,\\text{T}$, $T=5.0\\,\\text{K}$)\n- Case B: ($N=50$, $\\mu=9.2740100783\\times 10^{-24}\\,\\text{J/T}$, $B=0.0\\,\\text{T}$, $T=10.0\\,\\text{K}$)\n- Case C: ($N=200$, $\\mu=9.2740100783\\times 10^{-24}\\,\\text{J/T}$, $B=2.0\\,\\text{T}$, $T=0.5\\,\\text{K}$)\n- Case D: ($N=1$, $\\mu=9.2740100783\\times 10^{-24}\\,\\text{J/T}$, $B=0.5\\,\\text{T}$, $T=1000.0\\,\\text{K}$)\n\nYour program should produce a single line of output containing the results for all cases as a comma-separated list enclosed in square brackets. For each case, list first the absolute difference for $C_V$ in $\\text{J/K}$ and then the absolute difference for $\\chi$ in $\\text{A}\\cdot\\text{m}^2/\\text{T}$. All numbers must be printed in scientific notation with exactly six digits after the decimal point. For the four cases above, the output must thus contain $8$ numbers in the order $[\\;|C_V^{\\mathrm{fluct}}-C_V^{\\mathrm{num}}|_{\\mathrm{A}},\\;|\\chi^{\\mathrm{fluct}}-\\chi^{\\mathrm{num}}|_{\\mathrm{A}},\\;|C_V^{\\mathrm{fluct}}-C_V^{\\mathrm{num}}|_{\\mathrm{B}},\\;|\\chi^{\\mathrm{fluct}}-\\chi^{\\mathrm{num}}|_{\\mathrm{B}},\\;|C_V^{\\mathrm{fluct}}-C_V^{\\mathrm{num}}|_{\\mathrm{C}},\\;|\\chi^{\\mathrm{fluct}}-\\chi^{\\mathrm{num}}|_{\\mathrm{C}},\\;|C_V^{\\mathrm{fluct}}-C_V^{\\mathrm{num}}|_{\\mathrm{D}},\\;|\\chi^{\\mathrm{fluct}}-\\chi^{\\mathrm{num}}|_{\\mathrm{D}}\\;]$.", "solution": "The posed problem is a standard, fundamental exercise in equilibrium statistical mechanics. It is scientifically grounded, well-posed, and objective. We shall therefore proceed with its solution.\n\nThe system consists of $N$ identical, non-interacting magnetic moments (spins), each of magnitude $\\mu$. In a magnetic field $B$, a single spin $s_i \\in \\{+1, -1\\}$ has energy states $E_{\\pm} = \\mp \\mu B$. The system is in thermal equilibrium at temperature $T$. The inverse temperature is $\\beta = 1/(k_B T)$, where $k_B$ is the Boltzmann constant.\n\nFirst, we must derive the canonical partition function, from which all thermodynamic quantities can be obtained. For a single spin, the partition function $z$ is the sum of Boltzmann factors over its two states:\n$$z = e^{-\\beta E_{+1}} + e^{-\\beta E_{-1}} = e^{-\\beta(-\\mu B)} + e^{-\\beta(+\\mu B)} = e^{\\beta \\mu B} + e^{-\\beta \\mu B} = 2 \\cosh(\\beta \\mu B)$$\nSince the $N$ spins are independent, the total partition function $Z$ for the system is the product of the single-spin partition functions:\n$$Z = z^N = \\left[ 2 \\cosh(\\beta \\mu B) \\right]^N$$\nThe logarithm of the partition function is $\\ln Z = N \\ln\\left[2 \\cosh(\\beta \\mu B)\\right]$. For convenience, we define the dimensionless variable $x = \\beta \\mu B = \\frac{\\mu B}{k_B T}$. Thus, $\\ln Z = N \\ln\\left[2 \\cosh(x)\\right]$.\n\nThe average energy $\\langle E \\rangle$ and average total magnetic moment $\\langle M \\rangle$ are derived from $\\ln Z$:\n$$\\langle E \\rangle = -\\frac{\\partial (\\ln Z)}{\\partial \\beta} = -\\frac{\\partial}{\\partial \\beta} \\left[ N \\ln\\left(2 \\cosh(\\beta \\mu B)\\right) \\right] = -N \\frac{1}{2\\cosh(\\beta \\mu B)} \\cdot 2\\sinh(\\beta \\mu B) \\cdot \\mu B$$\n$$\\langle E \\rangle = -N \\mu B \\tanh(\\beta \\mu B) = -N \\mu B \\tanh(x)$$\nThe total energy is $E = -MB$, so $\\langle E \\rangle = -\\langle M \\rangle B$. This implies:\n$$\\langle M \\rangle = N \\mu \\tanh(\\beta \\mu B) = N \\mu \\tanh(x)$$\n\nThe problem requires the calculation of heat capacity $C_V$ and magnetic susceptibility $\\chi$ by two distinct methods prescribed by statistical mechanics.\n\n**Method 1: Calculation from Fluctuations**\n\nThe first method utilizes the fluctuation-dissipation theorem, which relates response functions ($C_V$, $\\chi$) to the variance of thermodynamic quantities ($E$, $M$).\n\nThe heat capacity at constant volume is given by $C_V = \\langle (\\Delta E)^2 \\rangle / (k_B T^2)$, where the energy variance is $\\langle (\\Delta E)^2 \\rangle = \\langle E^2 \\rangle - \\langle E \\rangle^2 = -\\frac{\\partial \\langle E \\rangle}{\\partial \\beta}$.\n$$\\langle (\\Delta E)^2 \\rangle = -\\frac{\\partial}{\\partial \\beta} [-N \\mu B \\tanh(\\beta \\mu B)] = N \\mu B \\cdot \\text{sech}^2(\\beta \\mu B) \\cdot \\mu B = N(\\mu B)^2 \\text{sech}^2(x)$$\nTherefore, the heat capacity from fluctuations, $C_V^{\\mathrm{fluct}}$, is:\n$$C_V^{\\mathrm{fluct}} = \\frac{N(\\mu B)^2 \\text{sech}^2(x)}{k_B T^2} = \\frac{N(k_B T x)^2 \\text{sech}^2(x)}{k_B T^2} = N k_B x^2 \\text{sech}^2(x)$$\n\nThe magnetic susceptibility is given by $\\chi = \\beta \\langle (\\Delta M)^2 \\rangle$, where the magnetization variance is $\\langle (\\Delta M)^2 \\rangle = \\langle M^2 \\rangle - \\langle M \\rangle^2 = \\frac{1}{\\beta}\\frac{\\partial \\langle M \\rangle}{\\partial B}$.\n$$\\langle (\\Delta M)^2 \\rangle = \\frac{1}{\\beta} \\frac{\\partial}{\\partial B} [N\\mu \\tanh(\\beta \\mu B)] = \\frac{1}{\\beta} \\left[ N\\mu \\cdot \\text{sech}^2(\\beta \\mu B) \\cdot \\beta \\mu \\right] = N \\mu^2 \\text{sech}^2(x)$$\nTherefore, the magnetic susceptibility from fluctuations, $\\chi^{\\mathrm{fluct}}$, is:\n$$\\chi^{\\mathrm{fluct}} = \\beta (N \\mu^2 \\text{sech}^2(x)) = \\frac{N \\mu^2}{k_B T} \\text{sech}^2(x)$$\n\n**Method 2: Calculation from Numerical Differentiation**\n\nThe second method uses the thermodynamic definitions of $C_V$ and $\\chi$ as derivatives of average quantities. These must be computed numerically.\n\nThe heat capacity is the derivative of average energy with respect to temperature: $C_V = (\\frac{\\partial \\langle E \\rangle}{\\partial T})_B$. We approximate this derivative using a central finite difference formula with a small step size $h_T$:\n$$C_V^{\\mathrm{num}} = \\frac{\\langle E \\rangle(T+h_T, B) - \\langle E \\rangle(T-h_T, B)}{2h_T}$$\nwhere $\\langle E \\rangle(T, B) = -N\\mu B \\tanh(\\frac{\\mu B}{k_B T})$. We choose a relative step size $h_T = \\delta_T \\cdot T$ with $\\delta_T = 10^{-6}$ for numerical stability.\n\nThe magnetic susceptibility is the derivative of average magnetization with respect to the magnetic field: $\\chi = (\\frac{\\partial \\langle M \\rangle}{\\partial B})_T$. We again use a central finite difference formula with step size $h_B$:\n$$\\chi^{\\mathrm{num}} = \\frac{\\langle M \\rangle(T, B+h_B) - \\langle M \\rangle(T, B-h_B)}{2h_B}$$\nwhere $\\langle M \\rangle(T, B) = N\\mu \\tanh(\\frac{\\mu B}{k_B T})$. The choice of step size $h_B$ requires care. If $B \\neq 0$, a relative step $h_B = \\delta_B \\cdot B$ with $\\delta_B = 10^{-6}$ is appropriate. However, for the case $B=0$, this would yield a zero step. In this special case, we must use a small absolute step, $h_B = h_{abs}$ (e.g., $10^{-8}\\,\\mathrm{T}$), to evaluate the derivative at the origin.\n\n**Final Computation**\n\nFor each parameter set $(N, \\mu, B, T)$ given in the test suite, we will compute:\n1.  $C_V^{\\mathrm{fluct}} = N k_B (\\frac{\\mu B}{k_B T})^2 \\text{sech}^2(\\frac{\\mu B}{k_B T})$\n2.  $C_V^{\\mathrm{num}}$ via numerical differentiation of $\\langle E \\rangle(T)$\n3.  $\\chi^{\\mathrm{fluct}} = \\frac{N \\mu^2}{k_B T} \\text{sech}^2(\\frac{\\mu B}{k_B T})$\n4.  $\\chi^{\\mathrm{num}}$ via numerical differentiation of $\\langle M \\rangle(B)$\n\nFinally, we will calculate the absolute differences $|C_V^{\\mathrm{fluct}} - C_V^{\\mathrm{num}}|$ and $|\\chi^{\\mathrm{fluct}} - \\chi^{\\mathrm{num}}|$. These differences are expected to be very small, arising solely from the truncation error of the finite difference approximation, which is of order $O(h^2)$. The problem thereby serves to numerically verify the fluctuation-dissipation theorem for this system. All calculations will be performed in SI units as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the paramagnet problem by calculating heat capacity and magnetic\n    susceptibility using two different methods (fluctuations and numerical\n    differentiation) and reports the absolute difference between them.\n    \"\"\"\n    # Physical constants in SI units\n    k_B = 1.380649e-23  # Boltzmann constant in J/K\n    \n    # Test suite from the problem statement\n    test_cases = [\n        # (N, mu, B, T)\n        (50, 9.2740100783e-24, 0.1, 5.0),\n        (50, 9.2740100783e-24, 0.0, 10.0),\n        (200, 9.2740100783e-24, 2.0, 0.5),\n        (1, 9.2740100783e-24, 0.5, 1000.0)\n    ]\n\n    results = []\n\n    def avg_E(N, mu, B, T, k_B_val):\n        \"\"\"Calculates the average energy <E>.\"\"\"\n        if T <= 0:\n            return np.nan\n        if B == 0.0:\n            return 0.0\n        x = mu * B / (k_B_val * T)\n        return -N * mu * B * np.tanh(x)\n\n    def avg_M(N, mu, B, T, k_B_val):\n        \"\"\"Calculates the average magnetization <M>.\"\"\"\n        if T <= 0:\n            return np.nan\n        # tanh(x) is an odd function, so we can handle B=0 without an explicit check\n        # as tanh(0) = 0.\n        x = mu * B / (k_B_val * T)\n        return N * mu * np.tanh(x)\n\n    for N, mu, B, T in test_cases:\n        # --- Method 1: Calculation from Fluctuations (Analytical) ---\n\n        # The dimensionless argument for hyperbolic functions\n        # T is guaranteed to be > 0 in all test cases.\n        x = mu * B / (k_B * T)\n        \n        # sech(x) = 1/cosh(x)\n        sech_x = 1.0 / np.cosh(x)\n\n        # C_v from energy fluctuations\n        # For B=0, x=0, and Cv_fluct becomes 0.\n        Cv_fluct = N * k_B * x**2 * sech_x**2\n\n        # chi from magnetization fluctuations\n        chi_fluct = (N * mu**2 / (k_B * T)) * sech_x**2\n\n        # --- Method 2: Calculation from Numerical Differentiation ---\n\n        # C_v = d<E>/dT\n        h_T_rel = 1e-7 # Relative step for temperature derivative\n        h_T = h_T_rel * T\n        # Central difference formula\n        E_plus = avg_E(N, mu, B, T + h_T, k_B)\n        E_minus = avg_E(N, mu, B, T - h_T, k_B)\n        Cv_num = (E_plus - E_minus) / (2 * h_T)\n        \n        # chi = d<M>/dB\n        h_B_rel = 1e-7 # Relative step for magnetic field derivative\n        h_B_abs = 1e-9 # Absolute step for B=0 case\n        \n        if B == 0.0:\n            h_B = h_B_abs\n        else:\n            h_B = h_B_rel * B\n        \n        # Central difference formula\n        M_plus = avg_M(N, mu, B + h_B, T, k_B)\n        M_minus = avg_M(N, mu, B - h_B, T, k_B)\n        chi_num = (M_plus - M_minus) / (2 * h_B)\n        \n        # --- Diagnostic Outputs: Absolute Differences ---\n\n        diff_Cv = abs(Cv_fluct - Cv_num)\n        diff_chi = abs(chi_fluct - chi_num)\n\n        results.append(f\"{diff_Cv:.6e}\")\n        results.append(f\"{diff_chi:.6e}\")\n        \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2400547"}, {"introduction": "Having verified the fluctuation-dissipation theorem for a simple non-interacting system, we now introduce interactions with the one-dimensional Ising model. This model, while simple, captures the essence of cooperative phenomena and is solvable using the powerful transfer matrix method [@problem_id:2400552]. This practice challenges you to implement this method to numerically demonstrate a famous result: the absence of a finite-temperature phase transition in one dimension, which you will observe by seeing how the heat capacity peak behaves as the system size grows.", "problem": "You are tasked with writing a complete, runnable program that numerically analyzes the 1-dimensional Ising model to estimate heat capacity and magnetic susceptibility, and to test whether the peak in the heat capacity diverges with system size. Use reduced units where the coupling constant $J$ and the Boltzmann constant $k_B$ are set to $1$, so that temperature $T$ is dimensionless, the heat capacity per spin is dimensionless, and the magnetic field $h$ has the same units as $J$. In these reduced units, the static magnetic susceptibility per spin has units of $1/J$, which equals $1$, so it can be reported as a dimensionless number.\n\nModel: Consider the 1-dimensional Ising model with $N$ spins $s_i \\in \\{-1,+1\\}$ with periodic boundary conditions, Hamiltonian\n$$\nH(\\{s_i\\}) \\;=\\; -J \\sum_{i=1}^{N} s_i s_{i+1} \\;-\\; h \\sum_{i=1}^{N} s_i,\n$$\nwith $s_{N+1} \\equiv s_1$, and use $J=1$. In the canonical ensemble at temperature $T$ (with $\\beta \\equiv 1/T$), the partition function is\n$$\nZ_N(\\beta,h) \\;=\\; \\sum_{\\{s_i\\}} e^{-\\beta H(\\{s_i\\})}.\n$$\nThe free energy is $F = -\\beta^{-1} \\ln Z_N$, the internal energy satisfies $\\langle E \\rangle = -\\partial_{\\beta} \\ln Z_N$, and the heat capacity per spin is\n$$\nc_N(T) \\;=\\; \\frac{\\beta^2}{N}\\,\\frac{\\partial^2 \\ln Z_N}{\\partial \\beta^2}.\n$$\nThe static magnetic susceptibility per spin at zero field is defined by the fluctuation-dissipation theorem as\n$$\n\\chi_N(T) \\;=\\; \\frac{1}{\\beta N}\\,\\left.\\frac{\\partial^2 \\ln Z_N(\\beta,h)}{\\partial h^2}\\right|_{h=0}.\n$$\nCompute these quantities numerically by evaluating $\\ln Z_N$ via the $2\\times 2$ transfer matrix and taking second derivatives with respect to $\\beta$ and $h$ using centered finite differences. To ensure numerical stability of $\\ln Z_N$ for large $N$, use an expression that avoids overflow by factoring out the largest eigenvalue of the transfer matrix.\n\nNumerical method requirements:\n- Construct the $2\\times 2$ transfer matrix $T(\\beta,h)$ with elements $T_{s,s'} = \\exp\\left(\\beta J s s' + \\tfrac{1}{2}\\beta h (s+s')\\right)$ for $s,s' \\in \\{-1,+1\\}$ and $J=1$, and compute its two positive eigenvalues $\\lambda_1(\\beta,h)$ and $\\lambda_2(\\beta,h)$.\n- Compute $\\ln Z_N(\\beta,h)$ stably as\n$$\n\\ln Z_N(\\beta,h) \\;=\\; N \\ln \\lambda_{\\max}(\\beta,h) \\;+\\; \\ln\\left(1 + \\left[\\frac{\\lambda_{\\min}(\\beta,h)}{\\lambda_{\\max}(\\beta,h)}\\right]^N\\right),\n$$\nwhere $\\lambda_{\\max}$ and $\\lambda_{\\min}$ are the larger and smaller eigenvalues, respectively.\n- Evaluate second derivatives using centered finite differences with a small step:\n  - For the $\\beta$-derivative, use a step $\\delta_\\beta = 10^{-5}$:\n  $$\n  \\frac{\\partial^2 \\ln Z_N}{\\partial \\beta^2}(\\beta,0) \\;\\approx\\; \\frac{\\ln Z_N(\\beta+\\delta_\\beta,0) - 2\\ln Z_N(\\beta,0) + \\ln Z_N(\\beta-\\delta_\\beta,0)}{\\delta_\\beta^2}.\n  $$\n  - For the $h$-derivative, use a step $\\delta_h = 10^{-4}$:\n  $$\n  \\left.\\frac{\\partial^2 \\ln Z_N}{\\partial h^2}\\right|_{h=0} \\;\\approx\\; \\frac{\\ln Z_N(\\beta,\\delta_h) - 2\\ln Z_N(\\beta,0) + \\ln Z_N(\\beta,-\\delta_h)}{\\delta_h^2}.\n  $$\n\nYour program must:\n- Compute the heat capacity per spin $c_N(T)$ on a temperature grid $T \\in [0.2,5.0]$ with uniform spacing $\\Delta T = 0.002$ for each system size $N \\in \\{16,64,256\\}$, and report the maximum value $c_N^{\\max}$ over this grid for each $N$.\n- Quantify the non-divergence of the peak by reporting the differences $\\Delta_{64,16} = c_{64}^{\\max} - c_{16}^{\\max}$ and $\\Delta_{256,64} = c_{256}^{\\max} - c_{64}^{\\max}$, and an indicator $I$ defined to be $1$ if $\\Delta_{256,64} < \\Delta_{64,16}$ and $\\max(\\Delta_{64,16},\\Delta_{256,64}) < 0.05$, and $0$ otherwise.\n- Compute the static magnetic susceptibility per spin $\\chi_N(T)$ at $T=1.0$ and $h=0$ for $N \\in \\{16,64,256\\}$ using the second derivative with respect to $h$ as above.\n\nTest suite (parameter sets to evaluate):\n- Heat capacity peak computation on the grid $T \\in [0.2,5.0]$ with $\\Delta T = 0.002$ for $N=16$.\n- Heat capacity peak computation on the same grid for $N=64$.\n- Heat capacity peak computation on the same grid for $N=256$.\n- Susceptibility at $T=1.0$ and $h=0$ for $N\\in\\{16,64,256\\}$.\n\nQuantitative outputs and units:\n- Report $c_{16}^{\\max}$, $c_{64}^{\\max}$, $c_{256}^{\\max}$ as dimensionless numbers (reduced units).\n- Report $\\Delta_{64,16}$ and $\\Delta_{256,64}$ as dimensionless numbers.\n- Report $I$ as an integer in $\\{0,1\\}$.\n- Report $\\chi_{16}(T{=}1.0)$, $\\chi_{64}(T{=}1.0)$, $\\chi_{256}(T{=}1.0)$ as numbers in units of $1/J$; with $J=1$, these are numerically dimensionless.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the following order:\n$$\n[c_{16}^{\\max},\\, c_{64}^{\\max},\\, c_{256}^{\\max},\\, \\Delta_{64,16},\\, \\Delta_{256,64},\\, I,\\, \\chi_{16}(T{=}1.0),\\, \\chi_{64}(T{=}1.0),\\, \\chi_{256}(T{=}1.0)].\n$$\n- Each floating-point number must be rounded to exactly $6$ decimal places. The indicator $I$ must be an integer $0$ or $1$.", "solution": "The problem is subjected to validation and is found to be scientifically grounded, well-posed, and objective. It presents a standard computational physics task: the analysis of the one-dimensional Ising model using the transfer matrix method. All required physical quantities, parameters, and numerical procedures are unambiguously defined. Therefore, a solution is warranted.\n\nThe core of the problem lies in analyzing the one-dimensional Ising model. The Hamiltonian for a chain of $N$ spins $s_i \\in \\{-1, +1\\}$ with coupling constant $J$ and external magnetic field $h$ is given by\n$$\nH(\\{s_i\\}) = -J \\sum_{i=1}^{N} s_i s_{i+1} - h \\sum_{i=1}^{N} s_i\n$$\nThe problem specifies periodic boundary conditions, $s_{N+1} \\equiv s_1$, and reduced units where $J=1$ and the Boltzmann constant $k_B=1$. The temperature $T$ is thus dimensionless, and $\\beta = 1/T$.\n\nThe partition function $Z_N$ is the sum over all possible spin configurations:\n$$\nZ_N(\\beta,h) = \\sum_{\\{s_i\\}} e^{-\\beta H(\\{s_i\\})}\n$$\nThis sum can be efficiently calculated using the transfer matrix method. We can rewrite the Hamiltonian as a sum over nearest-neighbor interactions:\n$$\nH = \\sum_{i=1}^{N} \\left( -J s_i s_{i+1} - \\frac{h}{2} (s_i + s_{i+1}) \\right)\n$$\nThis allows us to express the partition function as the trace of the $N$-th power of a $2 \\times 2$ transfer matrix $T$:\n$$\nZ_N = \\sum_{s_1 \\dots s_N} \\prod_{i=1}^N e^{\\beta J s_i s_{i+1} + \\frac{\\beta h}{2}(s_i+s_{i+1})} = \\sum_{s_1} \\left( T^N \\right)_{s_1,s_1} = \\text{Tr}(T^N)\n$$\nThe elements of the transfer matrix $T$, indexed by spin values $s, s' \\in \\{+1, -1\\}$, are given by:\n$$\nT_{s,s'} = \\exp\\left(\\beta J s s' + \\frac{\\beta h}{2}(s+s')\\right)\n$$\nWith $J=1$, the matrix is:\n$$\nT(\\beta,h) = \\begin{pmatrix} T_{1,1} & T_{1,-1} \\\\ T_{-1,1} & T_{-1,-1} \\end{pmatrix} = \\begin{pmatrix} e^{\\beta(1+h)} & e^{-\\beta} \\\\ e^{-\\beta} & e^{\\beta(1-h)} \\end{pmatrix}\n$$\nThe partition function is the sum of the $N$-th powers of the eigenvalues of $T$, $Z_N = \\lambda_1^N + \\lambda_2^N$. The eigenvalues $\\lambda$ are found by solving the characteristic equation $\\det(T - \\lambda I) = 0$. The analytical solution for the eigenvalues is:\n$$\n\\lambda(\\beta,h) = e^{\\beta} \\cosh(\\beta h) \\pm \\sqrt{e^{2\\beta} \\sinh^2(\\beta h) + e^{-2\\beta}}\n$$\nLet $\\lambda_{\\max}$ be the larger eigenvalue and $\\lambda_{\\min}$ be the smaller one. For large $N$, direct computation of $\\lambda_{\\max}^N$ can lead to numerical overflow. A stable expression for the logarithm of the partition function is required:\n$$\n\\ln Z_N(\\beta,h) = \\ln(\\lambda_{\\max}^N + \\lambda_{\\min}^N) = \\ln\\left(\\lambda_{\\max}^N \\left(1 + \\left(\\frac{\\lambda_{\\min}}{\\lambda_{\\max}}\\right)^N\\right)\\right) = N \\ln \\lambda_{\\max} + \\ln\\left(1 + \\left(\\frac{\\lambda_{\\min}}{\\lambda_{\\max}}\\right)^N\\right)\n$$\nThis expression avoids overflow and is used for all subsequent calculations.\n\nThe thermodynamic quantities are derived from $\\ln Z_N$. The heat capacity per spin, $c_N(T)$, is given by:\n$$\nc_N(T) = \\frac{1}{N} \\frac{\\partial \\langle E \\rangle}{\\partial T} = \\frac{1}{N} \\frac{\\partial}{\\partial T} \\left(-\\frac{\\partial \\ln Z_N}{\\partial \\beta}\\right) = \\frac{1}{N} \\frac{\\partial\\beta}{\\partial T} \\frac{\\partial}{\\partial\\beta} \\left(-\\frac{\\partial \\ln Z_N}{\\partial \\beta}\\right) = \\frac{\\beta^2}{N} \\frac{\\partial^2 \\ln Z_N}{\\partial \\beta^2}\n$$\nThe static magnetic susceptibility per spin, $\\chi_N(T)$, at zero field is obtained from the fluctuation-dissipation theorem:\n$$\n\\chi_N(T) = \\frac{\\beta}{N} \\langle (M - \\langle M \\rangle)^2 \\rangle = \\frac{1}{\\beta N} \\left. \\frac{\\partial^2 \\ln Z_N(\\beta,h)}{\\partial h^2} \\right|_{h=0}\n$$\nBoth second derivatives are computed numerically using the centered finite-difference approximation. For a function $f(x)$, the second derivative is approximated as:\n$$\nf''(x) \\approx \\frac{f(x+\\delta) - 2f(x) + f(x-\\delta)}{\\delta^2}\n$$\nFor the heat capacity, we compute the derivative of $\\ln Z_N$ with respect to $\\beta$ at $h=0$ using a step $\\delta_\\beta = 10^{-5}$.\nFor the susceptibility, we compute the derivative of $\\ln Z_N$ with respect to $h$ at $h=0$ using a step $\\delta_h = 10^{-4}$.\n\nThe computational procedure is as follows:\n1.  A function is implemented to calculate the two eigenvalues, $\\lambda_{\\max}$ and $\\lambda_{\\min}$, for given $\\beta$ and $h$ using the analytical formula.\n2.  A function for $\\ln Z_N(\\beta,h)$ is implemented using the numerically stable expression.\n3.  The heat capacity $c_N(T)$ is computed for system sizes $N \\in \\{16, 64, 256\\}$ over a temperature grid $T \\in [0.2, 5.0]$ with spacing $\\Delta T = 0.002$. For each $N$, the maximum value on this grid, $c_N^{\\max}$, is found.\n4.  The differences in peak heights, $\\Delta_{64,16} = c_{64}^{\\max} - c_{16}^{\\max}$ and $\\Delta_{256,64} = c_{256}^{\\max} - c_{64}^{\\max}$, are calculated.\n5.  An indicator $I$ is determined: $I=1$ if both $\\Delta_{256,64} < \\Delta_{64,16}$ and $\\max(\\Delta_{64,16}, \\Delta_{256,64}) < 0.05$ are true, otherwise $I=0$. This tests for the non-divergence of the heat capacity peak, which is a known feature of the\n1D Ising model.\n6.  The magnetic susceptibility $\\chi_N(T)$ is computed at $T=1.0$ for $N \\in \\{16, 64, 256\\}$.\n7.  All computed values are collected and formatted into a single output line as specified, with floating-point numbers rounded to $6$ decimal places.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ... # Scipy is available but not required for this solution.\n\ndef solve():\n    \"\"\"\n    Numerically analyzes the 1D Ising model using the transfer matrix method\n    to estimate heat capacity and magnetic susceptibility.\n    \"\"\"\n\n    # --- Numerical Parameters ---\n    DELTA_BETA = 1e-5\n    DELTA_H = 1e-4\n    N_VALS = [16, 64, 256]\n    T_START, T_END, T_STEP = 0.2, 5.0, 0.002\n    \n    # --- Helper Functions ---\n\n    def get_eigenvalues(beta, h):\n        \"\"\"\n        Calculates the eigenvalues of the 2x2 transfer matrix for given beta and h.\n        J=1 is assumed.\n        \"\"\"\n        # Using the analytical solution for the eigenvalues:\n        # lambda = exp(beta) * cosh(beta*h) +/- sqrt(exp(2*beta)*sinh^2(beta*h) + exp(-2*beta))\n        term1 = np.exp(beta) * np.cosh(beta * h)\n        \n        # Use np.exp2 instead of np.exp to potentially avoid intermediate overflow\n        # on very large beta, though numpy handles large numbers well.\n        # exp(2*beta) = exp(beta)^2\n        exp_beta = np.exp(beta)\n        discriminant_term1 = (exp_beta * np.sinh(beta * h))**2\n        discriminant_term2 = np.exp(-2.0 * beta)\n        \n        sqrt_term = np.sqrt(discriminant_term1 + discriminant_term2)\n        \n        lambda_max = term1 + sqrt_term\n        lambda_min = term1 - sqrt_term\n        \n        return lambda_max, lambda_min\n\n    def log_Z_N(N, beta, h):\n        \"\"\"\n        Calculates the natural logarithm of the partition function Z_N using a\n        numerically stable formula to avoid overflow.\n        \"\"\"\n        if beta <= 0:\n            # Physical temperatures are positive, T > 0, so beta > 0.\n            # Handle beta=0 (T=inf) case to avoid division by zero in T=1/beta.\n            # At T=inf, all states are equally likely. Z = 2^N.\n            if beta == 0:\n                return N * np.log(2.0)\n            return np.nan\n\n        lambda_max, lambda_min = get_eigenvalues(beta, h)\n        \n        # The ratio lambda_min/lambda_max can be negative if h is complex, \n        # but for real h, both eigenvalues are positive.\n        ratio = lambda_min / lambda_max\n\n        # The term (ratio)^N can underflow to 0 for large N, which is fine.\n        # np.log1p(x) calculates log(1+x) accurately for small x.\n        log_Z = N * np.log(lambda_max) + np.log1p(ratio**N)\n        \n        return log_Z\n\n    # --- Main Calculation Logic ---\n\n    # Part 1: Heat Capacity\n    c_max_values = []\n    T_grid = np.arange(T_START, T_END + T_STEP / 2, T_STEP) # Ensure endpoint inclusion\n    \n    for N in N_VALS:\n        c_N_values = []\n        for T in T_grid:\n            beta = 1.0 / T\n            \n            # Finite difference for second derivative w.r.t. beta\n            lnZ_plus = log_Z_N(N, beta + DELTA_BETA, 0)\n            lnZ_mid = log_Z_N(N, beta, 0)\n            lnZ_minus = log_Z_N(N, beta - DELTA_BETA, 0)\n            \n            d2_lnZ_dbeta2 = (lnZ_plus - 2 * lnZ_mid + lnZ_minus) / (DELTA_BETA**2)\n            \n            # Heat capacity per spin\n            c_N = (beta**2 / N) * d2_lnZ_dbeta2\n            c_N_values.append(c_N)\n        \n        c_max_values.append(np.max(c_N_values))\n\n    c16_max, c64_max, c256_max = c_max_values[0], c_max_values[1], c_max_values[2]\n\n    # Part 2: Peak Divergence Analysis\n    delta_64_16 = c64_max - c16_max\n    delta_256_64 = c256_max - c64_max\n\n    is_slowing_down = delta_256_64 < delta_64_16\n    is_small_increase = max(delta_64_16, delta_256_64) < 0.05\n    indicator_I = 1 if is_slowing_down and is_small_increase else 0\n\n    # Part 3: Magnetic Susceptibility\n    chi_values = []\n    T_chi = 1.0\n    beta_chi = 1.0 / T_chi\n\n    for N in N_VALS:\n        # Finite difference for second derivative w.r.t. h\n        # Note: Z(h) = Z(-h), so lnZ(h) = lnZ(-h).\n        # We compute explicitly as per problem statement for robustness.\n        lnZ_plus = log_Z_N(N, beta_chi, DELTA_H)\n        lnZ_mid = log_Z_N(N, beta_chi, 0)\n        lnZ_minus = log_Z_N(N, beta_chi, -DELTA_H)\n        \n        d2_lnZ_dh2 = (lnZ_plus - 2 * lnZ_mid + lnZ_minus) / (DELTA_H**2)\n        \n        # Susceptibility per spin\n        chi_N = (1.0 / (beta_chi * N)) * d2_lnZ_dh2\n        chi_values.append(chi_N)\n\n    chi16, chi64, chi256 = chi_values[0], chi_values[1], chi_values[2]\n\n    # --- Final Output Formatting ---\n    \n    results = [\n        c16_max, c64_max, c256_max,\n        delta_64_16, delta_256_64,\n        indicator_I,\n        chi16, chi64, chi256\n    ]\n\n    formatted_results = [\n        f\"{results[0]:.6f}\", f\"{results[1]:.6f}\", f\"{results[2]:.6f}\",\n        f\"{results[3]:.6f}\", f\"{results[4]:.6f}\",\n        f\"{results[5]}\",\n        f\"{results[6]:.6f}\", f\"{results[7]:.6f}\", f\"{results[8]:.6f}\"\n    ]\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2400552"}, {"introduction": "In contrast to one-dimensional systems, models in higher dimensions can exhibit true phase transitions, characterized by the divergence of quantities like susceptibility and the emergence of universal scaling laws. Finite-size scaling is the essential theoretical and computational tool for studying these critical phenomena using simulations on finite systems [@problem_id:2400586]. This final practice shifts the focus from simulation to data analysis, guiding you to extract the universal critical exponent $\\gamma$ from mock simulation data and revealing how macroscopic laws emerge from scaling behavior near a critical point.", "problem": "You are given a set of independent, dimensionless numerical experiments on lattice spin systems of linear extent $L$ in spatial dimension $d$, each reporting the peak value of the zero-field magnetic susceptibility, denoted $\\chi_{\\max}(L)$, measured near the systemâ€™s pseudo-critical temperature for that finite size. Your goal is to estimate the critical exponent $\\gamma$ for each experiment using finite-size scaling, starting from a fundamental scaling hypothesis and proceeding to an algorithmic estimator.\n\nStart from the finite-size scaling ansatz for the singular part of the reduced free-energy density,\n$$\nf_{\\mathrm{s}}(t,h,L) = L^{-d}\\,\\mathcal{F}\\!\\left(t\\,L^{1/\\nu},\\,h\\,L^{y_h}\\right),\n$$\nwhere $t$ is the reduced temperature, $h$ is the external magnetic field, $\\nu$ is the correlation-length exponent, $y_h$ is the renormalization-group field exponent conjugate to $h$, and $\\mathcal{F}$ is a scaling function. Use standard thermodynamic definitions to express the zero-field susceptibility per site as the second field derivative of the free-energy density, and infer the finite-size scaling form of $\\chi(t,L)$ at $h=0$. Argue that the peak value $\\chi_{\\max}(L)$, obtained at the pseudo-critical reduced temperature $t^\\star(L)$ where $\\chi$ attains its maximum for that $L$, scales as a power of $L$ with an exponent that can be expressed using $\\nu$ and $\\gamma$. Derive a regression-ready relation by taking logarithms, and explain how to extract $\\gamma$ from a linear fit, given an independently specified value of $\\nu$.\n\nThen implement an algorithm that, for each experiment, performs the following steps:\n- Given a list of system sizes $L_i$ and corresponding measured $\\chi_{\\max}(L_i)$, compute the natural logarithms of both quantities and perform an unweighted linear least-squares fit of $\\ln \\chi_{\\max}$ versus $\\ln L$ to estimate the scaling slope.\n- Using the provided value of $\\nu$ for that experiment, convert the fitted slope into an estimate of $\\gamma$.\n- Return the estimates of $\\gamma$ for all experiments.\n\nAll quantities are dimensionless in this problem, so no physical units are required.\n\nYour program must apply the above procedure to the following test suite. Each experiment $k$ provides the tuple $\\left(\\{L_i\\},\\{\\chi_{\\max}(L_i)\\},\\nu\\right)$:\n\n- Experiment $1$ (two-dimensional Ising-like data with small finite-size noise):\n  - Sizes $L$: $[8,16,32,64,128]$\n  - Measured $\\chi_{\\max}$: $[19.21727,63.04,216.3451,718.995,2435.985]$\n  - Correlation-length exponent $\\nu$: $1.0$\n- Experiment $2$ (three-dimensional Ising-like synthetic data with modest noise):\n  - Sizes $L$: $[8,12,16,24,32,48]$\n  - Measured $\\chi_{\\max}$: $[24.243,51.967,92.64,207.868,353.192,798.372]$\n  - Correlation-length exponent $\\nu$: $0.630$\n- Experiment $3$ (two-dimensional data with mild analytic corrections to scaling):\n  - Sizes $L$: $[16,24,32]$\n  - Measured $\\chi_{\\max}$: $[40.8,81.3625,133.183]$\n  - Correlation-length exponent $\\nu$: $1.0$\n- Experiment $4$ (mean-field-like synthetic data in high effective dimension with small noise):\n  - Sizes $L$: $[16,32,64,128,256]$\n  - Measured $\\chi_{\\max}$: $[51.2,206.848,802.816,3276.8,13302.808]$\n  - Correlation-length exponent $\\nu$: $0.5$\n\nYour program should estimate $\\gamma$ for each experiment as described above. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the experiments, with each value rounded to $3$ decimal places. For example, the format must be exactly like $[g_1,g_2,g_3,g_4]$ where each $g_k$ is a floating-point number rounded to $3$ decimals.", "solution": "The problem statement is subjected to validation and is found to be scientifically valid, well-posed, and self-contained. It describes a standard procedure in computational statistical physics for determining a critical exponent from finite-size data, based on the established theory of finite-size scaling. All required data and theoretical premises are provided, and there are no contradictions or ambiguities. We may proceed with the solution.\n\nThe objective is to derive an estimator for the critical exponent $\\gamma$ from the provided finite-size scaling ansatz for the singular part of the free-energy density, $f_{\\mathrm{s}}$, and then apply it to the given experimental data.\n\nThe starting point is the finite-size scaling form of the singular part of the reduced free-energy density per site:\n$$\nf_{\\mathrm{s}}(t,h,L) = L^{-d}\\,\\mathcal{F}\\!\\left(t\\,L^{1/\\nu},\\,h\\,L^{y_h}\\right)\n$$\nHere, $t$ is the reduced temperature $t = (T-T_c)/T_c$, $h$ is the external magnetic field, $L$ is the linear system size, $d$ is the spatial dimension, $\\nu$ is the correlation-length critical exponent, and $y_h$ is the magnetic scaling exponent. The function $\\mathcal{F}$ is a universal scaling function.\n\nThe zero-field magnetic susceptibility per site, $\\chi$, is defined as the second derivative of the free-energy density with respect to the magnetic field, evaluated at $h=0$:\n$$\n\\chi(t,h) = -\\frac{\\partial^2 f(t,h)}{\\partial h^2}\n$$\nThe total free energy $f$ is the sum of a regular part $f_{\\mathrm{reg}}$ and the singular part $f_{\\mathrm{s}}$. Near the critical point, the singular behavior is dominated by $f_{\\mathrm{s}}$, so we focus on the scaling of the singular part of the susceptibility, $\\chi_{\\mathrm{s}}$. Differentiating $f_{\\mathrm{s}}$ with respect to $h$, we apply the chain rule. Let $x_t = tL^{1/\\nu}$ and $x_h = hL^{y_h}$ be the arguments of $\\mathcal{F}$.\n$$\n\\frac{\\partial f_{\\mathrm{s}}}{\\partial h} = L^{-d} \\frac{\\partial \\mathcal{F}(x_t, x_h)}{\\partial x_h} \\frac{\\partial x_h}{\\partial h} = L^{-d} \\mathcal{F}^{(0,1)}(x_t, x_h) L^{y_h}\n$$\nwhere $\\mathcal{F}^{(i,j)}$ denotes the $i$-th partial derivative with respect to the first argument and the $j$-th with respect to the second. The second derivative is:\n$$\n\\frac{\\partial^2 f_{\\mathrm{s}}}{\\partial h^2} = L^{-d} L^{y_h} \\frac{\\partial}{\\partial h} \\left(\\mathcal{F}^{(0,1)}(x_t, x_h)\\right) = L^{-d} L^{y_h} \\left( \\mathcal{F}^{(0,2)}(x_t, x_h) \\frac{\\partial x_h}{\\partial h} \\right) = L^{-d} (L^{y_h})^2 \\mathcal{F}^{(0,2)}(x_t, x_h)\n$$\nThus, the singular part of the susceptibility is:\n$$\n\\chi_{\\mathrm{s}}(t,h,L) = -L^{2y_h-d} \\mathcal{F}^{(0,2)}(tL^{1/\\nu}, hL^{y_h})\n$$\nWe are interested in the zero-field susceptibility, so we set $h=0$:\n$$\n\\chi_{\\mathrm{s}}(t,0,L) = L^{2y_h-d} \\left[-\\mathcal{F}^{(0,2)}(tL^{1/\\nu}, 0)\\right]\n$$\nLet us define a new scaling function $\\mathcal{G}(x) = -\\mathcal{F}^{(0,2)}(x, 0)$. The expression then simplifies to:\n$$\n\\chi_{\\mathrm{s}}(t,0,L) = L^{2y_h-d} \\mathcal{G}(tL^{1/\\nu})\n$$\nThe problem specifies that $\\chi_{\\max}(L)$ is the peak value of the susceptibility, which for a finite system occurs at a pseudo-critical temperature $t^\\star(L)$. This corresponds to the argument of $\\mathcal{G}$ having a value $x^\\star = t^\\star(L)L^{1/\\nu}$ that maximizes the function $\\mathcal{G}(x)$. Since $x^\\star$ and $\\mathcal{G}(x^\\star)$ are constants for large $L$, the scaling of the peak susceptibility is determined entirely by the prefactor involving $L$:\n$$\n\\chi_{\\max}(L) \\equiv \\chi(t^\\star(L), 0, L) \\propto L^{2y_h-d}\n$$\nTo connect this to the conventional critical exponent $\\gamma$, we use standard scaling relations. The scaling exponent of the magnetic field, $y_h$, is related to the anomalous dimension exponent $\\eta$ by $2y_h = d+2-\\eta$. Substituting this gives the exponent of $L$ as:\n$$\n2y_h-d = (d+2-\\eta) - d = 2-\\eta\n$$\nFurthermore, the hyperscaling relation $\\gamma = \\nu(2-\\eta)$ connects $\\gamma$, $\\nu$, and $\\eta$. From this, we have $2-\\eta = \\gamma/\\nu$. Therefore, the scaling of the peak susceptibility is given by:\n$$\n\\chi_{\\max}(L) \\propto L^{\\gamma/\\nu}\n$$\nThis is the fundamental power-law relation we must use. To extract the exponent $\\gamma/\\nu$ from the provided data, we linearize this relationship by taking the natural logarithm of both sides:\n$$\n\\ln \\chi_{\\max}(L) = \\ln(C) + \\left(\\frac{\\gamma}{\\nu}\\right) \\ln L\n$$\nwhere $C$ is the constant of proportionality. This equation is in the form of a straight line, $y = m x + c$, with:\n- Dependent variable $y = \\ln \\chi_{\\max}(L)$.\n- Independent variable $x = \\ln L$.\n- Slope $m = \\gamma/\\nu$.\n- Intercept $c = \\ln(C)$.\n\nThe prescribed algorithm is to perform a linear least-squares regression on the data points $(\\ln L_i, \\ln \\chi_{\\max}(L_i))$ for each experiment. This fit yields an estimate for the slope, $\\hat{m}$. Given the known value of $\\nu$ for the experiment, the estimate for the critical exponent $\\gamma$ is then calculated as:\n$$\n\\hat{\\gamma} = \\hat{m} \\cdot \\nu\n$$\nThe implementation will follow this procedure for each of the four experimental datasets. A linear regression will be performed on the logarithmically transformed data to find the slope, from which $\\gamma$ will be computed.\nThe final results for each experiment will be collected and formatted as requested. For the unweighted linear least-squares fit, the `numpy.polyfit` function is a suitable and efficient tool.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the critical exponent gamma for multiple experiments\n    using finite-size scaling analysis.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (list of L, list of chi_max, nu)\n    test_cases = [\n        # Experiment 1\n        (\n            [8, 16, 32, 64, 128],\n            [19.21727, 63.04, 216.3451, 718.995, 2435.985],\n            1.0\n        ),\n        # Experiment 2\n        (\n            [8, 12, 16, 24, 32, 48],\n            [24.243, 51.967, 92.64, 207.868, 353.192, 798.372],\n            0.630\n        ),\n        # Experiment 3\n        (\n            [16, 24, 32],\n            [40.8, 81.3625, 133.183],\n            1.0\n        ),\n        # Experiment 4\n        (\n            [16, 32, 64, 128, 256],\n            [51.2, 206.848, 802.816, 3276.8, 13302.808],\n            0.5\n        )\n    ]\n\n    results = []\n    for L_values, chi_max_values, nu in test_cases:\n        # Convert lists to NumPy arrays for vectorized operations.\n        L = np.array(L_values)\n        chi_max = np.array(chi_max_values)\n\n        # Compute the natural logarithms of L and chi_max.\n        # This transforms the power-law relation into a linear one.\n        # ln(chi_max) = (gamma/nu) * ln(L) + const\n        log_L = np.log(L)\n        log_chi_max = np.log(chi_max)\n\n        # Perform unweighted linear least-squares regression.\n        # np.polyfit with deg=1 fits a polynomial of degree 1 (a line).\n        # It returns the coefficients [slope, intercept].\n        slope, intercept = np.polyfit(log_L, log_chi_max, 1)\n\n        # The slope of the fit is an estimate for the ratio gamma/nu.\n        m_hat = slope\n\n        # Calculate the estimate for gamma using the given value of nu.\n        # gamma = (gamma/nu) * nu\n        gamma_hat = m_hat * nu\n        \n        results.append(gamma_hat)\n\n    # Format the results into a string with each value rounded to 3 decimal places.\n    # The f-string format specifier '{value:.3f}' ensures three decimal places,\n    # including trailing zeros.\n    formatted_results = [f\"{g:.3f}\" for g in results]\n    output_string = f\"[{','.join(formatted_results)}]\"\n\n    # Final print statement in the exact required format.\n    print(output_string)\n\nsolve()\n```", "id": "2400586"}]}