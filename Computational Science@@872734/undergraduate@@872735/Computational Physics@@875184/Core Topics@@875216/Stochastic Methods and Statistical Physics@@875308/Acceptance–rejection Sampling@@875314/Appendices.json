{"hands_on_practices": [{"introduction": "To apply Acceptance-Rejection Sampling effectively, our goal is to maximize the acceptance rate, which is equivalent to minimizing the envelope constant $M$. This first practice explores the simplest case of this optimization: using a Gaussian proposal distribution to sample from a Gaussian target [@problem_id:2370869]. By analytically determining the optimal parameter for the proposal, you will build a foundational intuition about the relationship between proposal choice, the envelope constant, and overall sampling efficiency.", "problem": "A one-dimensional target probability density function $p(x)$ is Gaussian with mean $0$ and standard deviation $\\sigma_p$, that is, $p(x) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma_p}\\exp\\!\\left(-\\frac{x^{2}}{2\\sigma_p^{2}}\\right)$. You wish to use acceptance–rejection sampling with a Gaussian proposal density $g(x)$ having mean $0$ and standard deviation $\\sigma_g$, i.e., $g(x) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma_g}\\exp\\!\\left(-\\frac{x^{2}}{2\\sigma_g^{2}}\\right)$. In acceptance–rejection sampling, an envelope constant $M$ must satisfy $p(x) \\leq M\\,g(x)$ for all $x \\in \\mathbb{R}$, and the algorithm is well-defined only if the smallest such admissible $M$ is finite. Determine the value of $\\sigma_g$ that minimizes this smallest admissible envelope constant $M$ among all choices of $\\sigma_g$ for which a finite $M$ exists. Provide your final answer as a closed-form expression for the optimal $\\sigma_g$ in terms of $\\sigma_p$. No numerical approximation is required, and no units are needed.", "solution": "The problem statement is critically examined for validity.\n\nStep 1: Extract Givens\n- Target probability density function (PDF): $p(x) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma_p}\\exp\\!\\left(-\\frac{x^{2}}{2\\sigma_p^{2}}\\right)$, which is a Gaussian distribution with mean $0$ and standard deviation $\\sigma_p$.\n- Proposal probability density function (PDF): $g(x) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma_g}\\exp\\!\\left(-\\frac{x^{2}}{2\\sigma_g^{2}}\\right)$, which is a Gaussian distribution with mean $0$ and standard deviation $\\sigma_g$.\n- Acceptance-rejection condition: $p(x) \\leq M\\,g(x)$ for all $x \\in \\mathbb{R}$.\n- Objective: Find the value of $\\sigma_g$ that minimizes the smallest admissible envelope constant $M$.\n- Constraint: The search for the optimal $\\sigma_g$ is restricted to those values for which a finite $M$ exists.\n\nStep 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, as it deals with the standard and well-established acceptance-rejection sampling algorithm, a fundamental technique in computational physics and statistics. The functions involved, Gaussian distributions, are ubiquitous in these fields. The problem is well-posed, asking for the minimization of a well-defined quantity ($M$) with respect to a parameter ($\\sigma_g$) under clear constraints. The language is objective and mathematically precise. The problem is self-contained and free from logical contradictions, factual errors, or ambiguities.\n\nStep 3: Verdict and Action\nThe problem is deemed valid. A rigorous solution will be provided.\n\nThe core of the acceptance-rejection method lies in the condition $p(x) \\leq M g(x)$ for all $x$. To ensure the highest efficiency for the algorithm, we must find the smallest possible value of the constant $M$ that satisfies this inequality for a given pair of distributions $p(x)$ and $g(x)$. This smallest $M$ is given by the supremum of the ratio $\\frac{p(x)}{g(x)}$ over the entire domain of $x$. Let this ratio be denoted by $f(x)$.\n\n$$\nM = \\sup_{x \\in \\mathbb{R}} f(x) = \\sup_{x \\in \\mathbb{R}} \\frac{p(x)}{g(x)}\n$$\n\nWe substitute the given expressions for $p(x)$ and $g(x)$:\n\n$$\nf(x) = \\frac{\\frac{1}{\\sqrt{2\\pi}\\,\\sigma_p}\\exp\\left(-\\frac{x^{2}}{2\\sigma_p^{2}}\\right)}{\\frac{1}{\\sqrt{2\\pi}\\,\\sigma_g}\\exp\\left(-\\frac{x^{2}}{2\\sigma_g^{2}}\\right)}\n$$\n\nSimplifying the expression, the constant term $\\frac{1}{\\sqrt{2\\pi}}$ cancels out:\n\n$$\nf(x) = \\frac{\\sigma_g}{\\sigma_p} \\exp\\left(-\\frac{x^{2}}{2\\sigma_p^{2}} + \\frac{x^{2}}{2\\sigma_g^{2}}\\right)\n$$\n\nCombining the terms in the exponent:\n\n$$\nf(x) = \\frac{\\sigma_g}{\\sigma_p} \\exp\\left(\\frac{x^{2}}{2}\\left(\\frac{1}{\\sigma_g^{2}} - \\frac{1}{\\sigma_p^{2}}\\right)\\right)\n$$\n\nThe algorithm is well-defined only if $M$ is finite. For $M = \\sup_{x \\in \\mathbb{R}} f(x)$ to be finite, the function $f(x)$ must be bounded as $x \\to \\pm\\infty$. The behavior of $f(x)$ at large $|x|$ is dominated by the exponential term. If the coefficient of $x^{2}$ in the exponent is positive, $f(x)$ will grow without bound as $|x| \\to \\infty$. Therefore, for a finite $M$ to exist, this coefficient must be non-positive. This establishes the condition on $\\sigma_g$:\n\n$$\n\\frac{1}{\\sigma_g^{2}} - \\frac{1}{\\sigma_p^{2}} \\leq 0\n$$\n\n$$\n\\frac{1}{\\sigma_g^{2}} \\leq \\frac{1}{\\sigma_p^{2}}\n$$\n\nSince both $\\sigma_g$ and $\\sigma_p$ are standard deviations, they are strictly positive. Thus, we can take the reciprocal of both sides and reverse the inequality sign, and then take the square root:\n\n$$\n\\sigma_g^{2} \\geq \\sigma_p^{2} \\implies \\sigma_g \\geq \\sigma_p\n$$\n\nThis is the set of all choices of $\\sigma_g$ for which a finite $M$ exists, as mentioned in the problem statement. The physical interpretation is that the proposal distribution $g(x)$ must have tails that are at least as \"heavy\" as the target distribution $p(x)$ to envelop it everywhere.\n\nNow, for any $\\sigma_g$ satisfying $\\sigma_g \\geq \\sigma_p$, the coefficient $\\left(\\frac{1}{\\sigma_g^{2}} - \\frac{1}{\\sigma_p^{2}}\\right)$ is non-positive. Consequently, the term $\\exp\\left(\\frac{x^{2}}{2}\\left(\\frac{1}{\\sigma_g^{2}} - \\frac{1}{\\sigma_p^{2}}\\right)\\right)$ has its maximum value when $x^2$ is minimized, which occurs at $x=0$. At this point, the exponential term is $\\exp(0) = 1$.\n\nTherefore, the smallest admissible envelope constant $M$ for a given valid $\\sigma_g$ is:\n\n$$\nM(\\sigma_g) = f(0) = \\frac{\\sigma_g}{\\sigma_p} \\exp(0) = \\frac{\\sigma_g}{\\sigma_p}\n$$\n\nThe problem requires us to find the value of $\\sigma_g$ that minimizes this function $M(\\sigma_g)$, subject to the constraint $\\sigma_g \\geq \\sigma_p$. The function to be minimized is $M(\\sigma_g) = \\frac{\\sigma_g}{\\sigma_p}$. Since $\\sigma_p$ is a positive constant, $M(\\sigma_g)$ is a linearly increasing function of $\\sigma_g$. To minimize a linearly increasing function on an interval, one must choose the smallest possible value in the domain of the function. The domain for $\\sigma_g$ is $[\\sigma_p, \\infty)$.\n\nThe minimum value of $M(\\sigma_g)$ is therefore attained at the lower boundary of this domain, which is:\n\n$$\n\\sigma_g = \\sigma_p\n$$\n\nAt this optimal value, the constant $M$ becomes $M = \\frac{\\sigma_p}{\\sigma_p} = 1$, which corresponds to an acceptance rate of $1/M = 1$. This is the most efficient scenario possible, occurring when the proposal distribution is identical to the target distribution.", "answer": "$$\n\\boxed{\\sigma_p}\n$$", "id": "2370869"}, {"introduction": "Building on the first practice, we now tackle a more realistic scenario where a perfect proposal is not available. Here we use a common Gaussian proposal to sample from a more complex distribution derived from a quartic potential [@problem_id:2370842]. This problem moves beyond the ideal case and develops a crucial practical skill: analytically tuning a proposal's parameters to achieve the best possible efficiency when the proposal and target have different functional forms.", "problem": "A one-dimensional particle in a dimensionless quartic confining potential has an unnormalized Boltzmann weight given by the target function $\\varphi(x) = \\exp\\!\\big(-x^{4}/2\\big)$ for all $x \\in \\mathbb{R}$. To draw samples from the corresponding normalized distribution using acceptance–rejection sampling, consider the family of normalized Gaussian proposal densities $q_{\\alpha}(x) = \\dfrac{1}{\\sqrt{2\\pi}\\,\\alpha}\\,\\exp\\!\\big(-x^{2}/(2\\alpha^{2})\\big)$ with a controllable scale parameter $\\alpha  0$. Define the envelope constant $M(\\alpha)$ as the smallest real number such that $\\varphi(x) \\leq M(\\alpha)\\,q_{\\alpha}(x)$ for all $x \\in \\mathbb{R}$.\n\nDetermine, in closed form, the value of $\\alpha$ that minimizes $M(\\alpha)$. Provide your answer as an exact analytical expression for the optimizing $\\alpha$, with no numerical approximation and no units.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- Target function: $\\varphi(x) = \\exp(-x^{4}/2)$, for $x \\in \\mathbb{R}$.\n- Proposal density family: $q_{\\alpha}(x) = \\dfrac{1}{\\sqrt{2\\pi}\\,\\alpha}\\,\\exp(-x^{2}/(2\\alpha^{2}))$, for $\\alpha  0$.\n- Envelope constant definition: $M(\\alpha)$ is the smallest real number such that $\\varphi(x) \\leq M(\\alpha)\\,q_{\\alpha}(x)$ for all $x \\in \\mathbb{R}$.\n- Objective: Find the value of $\\alpha$ that minimizes $M(\\alpha)$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific or Factual Soundness**: The problem is a standard exercise in computational physics and statistics, concerning the optimization of the acceptance-rejection sampling method. The functions and concepts (Boltzmann weight, Gaussian density) are standard and correct. The problem is scientifically sound.\n- **Well-Posed**: The problem is a well-defined optimization task. It asks for the minimizer of a function $M(\\alpha)$ that is derived from the given functions $\\varphi(x)$ and $q_{\\alpha}(x)$. The existence and uniqueness of a solution can be reasonably expected.\n- **Objective**: The problem is stated using precise mathematical language, with no subjective or ambiguous terms.\n- **Completeness and Consistency**: The problem provides all necessary definitions and constraints. No information is missing or contradictory.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\nThe core of the acceptance-rejection method requires finding an envelope constant $M(\\alpha)$ such that $\\varphi(x) \\le M(\\alpha) q_{\\alpha}(x)$ for all $x$. To maximize the efficiency of the sampling algorithm, one must find the minimum possible value of this constant. This minimum value for a given $\\alpha$ is given by the maximum of the ratio of the two functions.\n$$M(\\alpha) = \\sup_{x \\in \\mathbb{R}} \\frac{\\varphi(x)}{q_{\\alpha}(x)}$$\nLet us define the ratio function $R(x, \\alpha)$:\n$$R(x, \\alpha) = \\frac{\\varphi(x)}{q_{\\alpha}(x)} = \\frac{\\exp(-x^{4}/2)}{\\frac{1}{\\sqrt{2\\pi}\\,\\alpha}\\,\\exp(-x^{2}/(2\\alpha^{2}))} = \\sqrt{2\\pi}\\,\\alpha \\exp\\left(-\\frac{x^{4}}{2} + \\frac{x^{2}}{2\\alpha^{2}}\\right)$$\nTo find the maximum of $R(x, \\alpha)$ with respect to $x$ for a fixed $\\alpha  0$, it is simpler to find the maximum of its natural logarithm, since $\\ln$ is a strictly increasing function. Let $g(x, \\alpha) = \\ln(R(x, \\alpha))$.\n$$g(x, \\alpha) = \\ln(\\sqrt{2\\pi}\\,\\alpha) - \\frac{x^{4}}{2} + \\frac{x^{2}}{2\\alpha^{2}}$$\nTo find the maximum, we compute the partial derivative with respect to $x$ and set it to zero:\n$$\\frac{\\partial g}{\\partial x} = -2x^{3} + \\frac{x}{\\alpha^{2}} = x\\left(\\frac{1}{\\alpha^{2}} - 2x^{2}\\right)$$\nSetting $\\frac{\\partial g}{\\partial x} = 0$ yields the critical points $x=0$ and $x^{2} = \\frac{1}{2\\alpha^{2}}$. To determine the nature of these critical points, we examine the second partial derivative:\n$$\\frac{\\partial^{2} g}{\\partial x^{2}} = -6x^{2} + \\frac{1}{\\alpha^{2}}$$\nAt $x=0$, $\\frac{\\partial^{2} g}{\\partial x^{2}}|_{x=0} = \\frac{1}{\\alpha^{2}}  0$, which corresponds to a local minimum.\nAt $x^{2} = \\frac{1}{2\\alpha^{2}}$, $\\frac{\\partial^{2} g}{\\partial x^{2}}|_{x^{2}=1/(2\\alpha^{2})} = -6\\left(\\frac{1}{2\\alpha^{2}}\\right) + \\frac{1}{\\alpha^{2}} = -\\frac{3}{\\alpha^{2}} + \\frac{1}{\\alpha^{2}} = -\\frac{2}{\\alpha^{2}}  0$. This indicates a local maximum. Thus, the supremum of $g(x, \\alpha)$ occurs at $x^{2} = \\frac{1}{2\\alpha^{2}}$.\n\nSubstituting this value of $x^2$ back into the expression for $g(x, \\alpha)$ gives the maximum value, which we denote $g_{\\max}(\\alpha)$:\n$$g_{\\max}(\\alpha) = \\ln(\\sqrt{2\\pi}\\,\\alpha) - \\frac{1}{2}\\left(\\frac{1}{2\\alpha^{2}}\\right)^{2} + \\frac{1}{2\\alpha^{2}}\\left(\\frac{1}{2\\alpha^{2}}\\right)$$\n$$g_{\\max}(\\alpha) = \\ln(\\sqrt{2\\pi}\\,\\alpha) - \\frac{1}{8\\alpha^{4}} + \\frac{1}{4\\alpha^{4}} = \\ln(\\sqrt{2\\pi}\\,\\alpha) + \\frac{1}{8\\alpha^{4}}$$\nThe envelope constant $M(\\alpha)$ is the exponential of this value:\n$$M(\\alpha) = \\exp(g_{\\max}(\\alpha)) = \\exp\\left(\\ln(\\sqrt{2\\pi}\\,\\alpha) + \\frac{1}{8\\alpha^{4}}\\right) = \\sqrt{2\\pi}\\,\\alpha \\exp\\left(\\frac{1}{8\\alpha^{4}}\\right)$$\nThe objective is to find the value of $\\alpha$ that minimizes $M(\\alpha)$. We can achieve this by minimizing $\\ln(M(\\alpha))$, which we will call $h(\\alpha)$.\n$$h(\\alpha) = \\ln(M(\\alpha)) = \\ln(\\sqrt{2\\pi}) + \\ln(\\alpha) + \\frac{1}{8\\alpha^{4}} = \\ln(\\sqrt{2\\pi}) + \\ln(\\alpha) + \\frac{1}{8}\\alpha^{-4}$$\nWe differentiate $h(\\alpha)$ with respect to $\\alpha$ and set the derivative to zero:\n$$\\frac{dh}{d\\alpha} = \\frac{1}{\\alpha} + \\frac{1}{8}(-4)\\alpha^{-5} = \\frac{1}{\\alpha} - \\frac{1}{2\\alpha^{5}}$$\nSetting $\\frac{dh}{d\\alpha} = 0$:\n$$\\frac{1}{\\alpha} - \\frac{1}{2\\alpha^{5}} = 0$$\nSince $\\alpha  0$, we can multiply by $2\\alpha^{5}$ to obtain:\n$$2\\alpha^{4} - 1 = 0 \\implies \\alpha^{4} = \\frac{1}{2}$$\nThe only real positive solution is:\n$$\\alpha = \\left(\\frac{1}{2}\\right)^{1/4}$$\nTo confirm this is a minimum, we examine the second derivative of $h(\\alpha)$:\n$$\\frac{d^{2}h}{d\\alpha^{2}} = \\frac{d}{d\\alpha}\\left(\\alpha^{-1} - \\frac{1}{2}\\alpha^{-5}\\right) = -\\alpha^{-2} - \\frac{1}{2}(-5)\\alpha^{-6} = -\\frac{1}{\\alpha^{2}} + \\frac{5}{2\\alpha^{6}}$$\nSubstituting the value of $\\alpha^4 = 1/2$ into the second derivative:\n$$\\frac{d^{2}h}{d\\alpha^{2}} = \\frac{1}{\\alpha^{6}}\\left(\\frac{5}{2} - \\alpha^{4}\\right) = \\frac{1}{\\alpha^{6}}\\left(\\frac{5}{2} - \\frac{1}{2}\\right) = \\frac{2}{\\alpha^{6}}$$\nSince $\\alpha  0$, $\\alpha^{6}$ is positive, so $\\frac{d^{2}h}{d\\alpha^{2}}  0$. This confirms that the value of $\\alpha$ we found corresponds to a local minimum of $M(\\alpha)$.\nThe value of $\\alpha$ that minimizes the envelope constant $M(\\alpha)$ is therefore $\\left(\\frac{1}{2}\\right)^{1/4}$.", "answer": "$$\\boxed{\\left(\\frac{1}{2}\\right)^{1/4}}$$", "id": "2370842"}, {"introduction": "Real-world scientific problems often involve complex, multi-modal distributions where a simple proposal is inefficient. This final practice moves from analytical optimization to computational strategy by addressing the challenge of sampling from a bimodal distribution [@problem_id:2370829]. You will computationally compare the efficiency of a naive, single-mode proposal against a more sophisticated mixture proposal, demonstrating the powerful gains achieved by tailoring the proposal's structure to match the target.", "problem": "You will compare the efficiency of acceptance–rejection sampling (ARS) for drawing samples from a one-dimensional bimodal target probability density function using two distinct proposal strategies. The efficiency metric is the acceptance rate, which for a valid ARS setup equals the reciprocal of the enveloping constant.\n\nFundamental base and definitions:\n- A probability density function $f(x)$ is a nonnegative function with $\\int_{-\\infty}^{\\infty} f(x)\\,dx = 1$.\n- In acceptance–rejection sampling (ARS), one selects a proposal density $g(x)$ with $\\int g(x)\\,dx = 1$ and a constant $M \\ge 1$ such that $M\\,g(x) \\ge f(x)$ for all $x \\in \\mathbb{R}$. The ARS procedure draws $X \\sim g$ and $U \\sim \\text{Uniform}(0,1)$ and accepts $X$ if $U \\le \\frac{f(X)}{M g(X)}$. This guarantees that accepted $X$ values are distributed according to $f$.\n- The acceptance rate is the expected value $\\mathbb{E}\\left[\\frac{f(X)}{M g(X)}\\right]$ with $X \\sim g$. Under the ARS conditions and $f$ normalized to integrate to $1$, the acceptance rate equals $\\frac{1}{M}$.\n\nTarget and proposals to be studied:\n- Target density $f(x)$: a mixture of two normal components with common standard deviation $\\sigma_t  0$, means $\\mu_1$ and $\\mu_2$, and mixing weight $w \\in (0,1)$ on the first mode,\n$$\nf(x) \\;=\\; w\\,\\phi(x;\\mu_1,\\sigma_t) \\;+\\; (1-w)\\,\\phi(x;\\mu_2,\\sigma_t),\n$$\nwhere $\\phi(x;\\mu,\\sigma)$ is the normal density\n$$\n\\phi(x;\\mu,\\sigma) \\;=\\; \\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\,\\exp\\!\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right).\n$$\n- Proposal A (single unimodal proposal) $g_s(x)$: a single normal density with mean chosen as the mixture mean $\\mu_p = w\\,\\mu_1 + (1-w)\\,\\mu_2$ and standard deviation chosen as the square root of the mixture variance,\n$$\n\\sigma_p \\;=\\; \\sqrt{\\sigma_t^2 + w(1-w)(\\mu_2-\\mu_1)^2}, \\qquad g_s(x) = \\phi(x;\\mu_p,\\sigma_p).\n$$\n- Proposal B (mixture of two strategically placed unimodal proposals) $g_m(x)$: a mixture of two normal components centered at the two modes with the same standard deviation as the target and the same weights,\n$$\ng_m(x) \\;=\\; w\\,\\phi(x;\\mu_1,\\sigma_t) \\;+\\; (1-w)\\,\\phi(x;\\mu_2,\\sigma_t).\n$$\n\nComputational task:\n- For each test case in the suite below, compute a valid enveloping constant for each proposal,\n$$\nM_s \\;\\ge\\; \\sup_{x \\in \\mathbb{R}} \\frac{f(x)}{g_s(x)}, \\qquad\nM_m \\;\\ge\\; \\sup_{x \\in \\mathbb{R}} \\frac{f(x)}{g_m(x)}.\n$$\n- Because the exact supremum may not be obtainable in closed form, compute a numerically valid upper bound by evaluating the ratio on a sufficiently wide and dense grid and then multiplying the maximum observed ratio by a small safety factor to guarantee validity. Use the domain\n$$\n[x_{\\min}, x_{\\max}] \\;=\\; \\big[\\min(\\mu_1,\\mu_2) - L,\\; \\max(\\mu_1,\\mu_2) + L\\big], \\quad L \\;=\\; 8\\,\\sigma_t + |\\mu_2-\\mu_1|,\n$$\nand a uniform grid of $N_{\\text{grid}} = 200001$ points on this interval. Let $\\widehat{M}$ denote the observed maximum ratio on the grid. Define the certified constants\n$$\nM \\;=\\; \\gamma\\,\\widehat{M}, \\quad \\text{with safety factor } \\gamma \\;=\\; 1.0005.\n$$\n- Compute the acceptance rates $a_s = 1/M_s$ and $a_m = 1/M_m$ for proposals $g_s$ and $g_m$, respectively.\n- For each test case, report the improvement factor $I = a_m/a_s$ as a decimal number.\n\nTest suite:\n- Case 1 (balanced, well-separated modes): $\\mu_1 = -3$, $\\mu_2 = 3$, $\\sigma_t = 1$, $w = 0.5$.\n- Case 2 (balanced, moderately overlapping modes): $\\mu_1 = -1$, $\\mu_2 = 1$, $\\sigma_t = 1$, $w = 0.5$.\n- Case 3 (unequal weights, separated modes): $\\mu_1 = 0$, $\\mu_2 = 8$, $\\sigma_t = 1$, $w = 0.9$.\n- Case 4 (balanced, extremely separated modes): $\\mu_1 = -6$, $\\mu_2 = 6$, $\\sigma_t = 1$, $w = 0.5$.\n\nAnswer specification:\n- For each test case, the answer is a single float $I$ representing the improvement factor $a_m/a_s$.\n- Your program must produce a single line of output containing the results as a comma-separated list of the improvement factors for the test suite, in the same order as above, enclosed in square brackets. Each float must be rounded to six decimal places (use decimal form, not a percentage). For example, a valid output format is $[1.234000,2.000000, \\dots]$.", "solution": "The problem requires a comparative analysis of the efficiency of two different proposal strategies for acceptance-rejection sampling (ARS) from a bimodal target probability density function. The efficiency is quantified by the acceptance rate, which is the reciprocal of the enveloping constant $M$. The improvement factor is defined as the ratio of the acceptance rates of the two proposals.\n\nThe target probability density function, $f(x)$, is a mixture of two normal distributions:\n$$\nf(x) = w\\,\\phi(x;\\mu_1,\\sigma_t) + (1-w)\\,\\phi(x;\\mu_2,\\sigma_t)\n$$\nwhere $\\phi(x;\\mu,\\sigma)$ is the normal probability density function:\n$$\n\\phi(x;\\mu,\\sigma) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\,\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\n$$\nThe parameters are the means $\\mu_1$ and $\\mu_2$, a common standard deviation $\\sigma_t  0$, and a mixing weight $w \\in (0,1)$.\n\nTwo proposal densities are specified for analysis.\n\nProposal A, a single unimodal proposal $g_s(x)$, is a normal density whose mean and variance are matched to the mean and variance of the target mixture distribution $f(x)$. The mean of the mixture is $\\mu_p = w\\,\\mu_1 + (1-w)\\,\\mu_2$, and the variance is $\\sigma_p^2 = \\sigma_t^2 + w(1-w)(\\mu_2-\\mu_1)^2$. Thus, the proposal is:\n$$\ng_s(x) = \\phi(x; \\mu_p, \\sigma_p) \\quad \\text{with} \\quad \\mu_p = w\\,\\mu_1 + (1-w)\\,\\mu_2, \\quad \\sigma_p = \\sqrt{\\sigma_t^2 + w(1-w)(\\mu_2-\\mu_1)^2}\n$$\nThis strategy attempts to approximate the bimodal target with a single, broader normal distribution.\n\nProposal B, a mixture proposal $g_m(x)$, is constructed to be identical to the target density:\n$$\ng_m(x) = w\\,\\phi(x;\\mu_1,\\sigma_t) + (1-w)\\,\\phi(x;\\mu_2,\\sigma_t)\n$$\nThis represents a 'perfect' proposal, as it has the same form as the target distribution.\n\nThe core of acceptance-rejection sampling relies on an enveloping constant $M$ such that $f(x) \\le M\\,g(x)$ for all $x$. The minimal such constant is $M = \\sup_{x \\in \\mathbb{R}} \\frac{f(x)}{g(x)}$. The acceptance probability, or efficiency, is given by $a = 1/M$. We must compute the enveloping constants $M_s$ and $M_m$ for proposals $g_s(x)$ and $g_m(x)$, respectively.\n\nFor Proposal B, since $g_m(x) = f(x)$, the ratio is identically one:\n$$\n\\frac{f(x)}{g_m(x)} = 1, \\quad \\forall x \\in \\mathbb{R}\n$$\nTherefore, the theoretical supremum is $\\sup_{x} \\frac{f(x)}{g_m(x)} = 1$. The numerically observed maximum on any grid, $\\widehat{M}_m$, will be $1$ (up to floating-point precision). According to the problem specification, the certified constant is $M_m = \\gamma\\,\\widehat{M}_m = \\gamma \\cdot 1 = \\gamma$, where $\\gamma = 1.0005$ is the safety factor. The corresponding acceptance rate is $a_m = 1/M_m = 1/\\gamma$.\n\nFor Proposal A, the ratio $r_s(x) = f(x)/g_s(x)$ is not constant. An analytical determination of its supremum is non-trivial. The problem mandates a numerical approach: we find the maximum value of this ratio on a specified dense grid, $\\widehat{M}_s = \\max_{x \\in \\text{grid}} r_s(x)$. The certified constant is then $M_s = \\gamma\\,\\widehat{M}_s$. The acceptance rate for this proposal is $a_s = 1/M_s$.\n\nThe objective is to compute the improvement factor $I$, defined as the ratio of the acceptance rates:\n$$\nI = \\frac{a_m}{a_s}\n$$\nSubstituting the expressions for the acceptance rates in terms of the certified constants, we obtain:\n$$\nI = \\frac{1/M_m}{1/M_s} = \\frac{M_s}{M_m}\n$$\nUsing the definitions $M_s = \\gamma\\,\\widehat{M}_s$ and $M_m = \\gamma$, the expression for the improvement factor simplifies:\n$$\nI = \\frac{\\gamma\\,\\widehat{M}_s}{\\gamma} = \\widehat{M}_s\n$$\nThus, the required improvement factor is precisely the maximum value of the ratio $f(x)/g_s(x)$ observed on the numerical grid, before the application of the safety factor. This is the quantity we must compute for each test case.\n\nThe computational procedure for each test case is as follows:\n1.  Given the parameters $\\mu_1$, $\\mu_2$, $\\sigma_t$, and $w$.\n2.  Define the target density function $f(x) = w\\,\\phi(x;\\mu_1,\\sigma_t) + (1-w)\\,\\phi(x;\\mu_2,\\sigma_t)$.\n3.  Calculate the parameters for the single proposal $g_s(x)$:\n    -   Mean: $\\mu_p = w\\,\\mu_1 + (1-w)\\,\\mu_2$\n    -   Standard deviation: $\\sigma_p = \\sqrt{\\sigma_t^2 + w(1-w)(\\mu_2-\\mu_1)^2}$\n4.  Construct the numerical grid. The domain is $[x_{\\min}, x_{\\max}]$, where:\n    -   $L = 8\\,\\sigma_t + |\\mu_2-\\mu_1|$\n    -   $x_{\\min} = \\min(\\mu_1,\\mu_2) - L$\n    -   $x_{\\max} = \\max(\\mu_1,\\mu_2) + L$\n    -   The grid consists of $N_{\\text{grid}} = 200001$ uniformly spaced points on this domain.\n5.  Evaluate the functions $f(x)$ and $g_s(x)$ at each point on the grid.\n6.  Compute the ratio $r_s(x) = f(x)/g_s(x)$ for all grid points. Special care must be taken if $g_s(x)$ approaches zero, but given the wide grid and the nature of normal distributions, both numerator and denominator will tend to zero in the tails, and their ratio will be well-behaved.\n7.  The improvement factor $I$ is the maximum value found in the array of ratios: $I = \\max(r_s(x))$.\n8.  This process is repeated for all four test cases provided in the suite.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Computes the improvement factor of a mixture proposal over a single \n    unimodal proposal for acceptance-rejection sampling.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (balanced, well-separated modes)\n        {'mu1': -3.0, 'mu2': 3.0, 'sigma_t': 1.0, 'w': 0.5},\n        # Case 2 (balanced, moderately overlapping modes)\n        {'mu1': -1.0, 'mu2': 1.0, 'sigma_t': 1.0, 'w': 0.5},\n        # Case 3 (unequal weights, separated modes)\n        {'mu1': 0.0, 'mu2': 8.0, 'sigma_t': 1.0, 'w': 0.9},\n        # Case 4 (balanced, extremely separated modes)\n        {'mu1': -6.0, 'mu2': 6.0, 'sigma_t': 1.0, 'w': 0.5},\n    ]\n\n    # Constants from the problem statement\n    N_grid = 200001\n    \n    results = []\n\n    for case in test_cases:\n        mu1 = case['mu1']\n        mu2 = case['mu2']\n        sigma_t = case['sigma_t']\n        w = case['w']\n\n        # 1. Define the target density function f(x)\n        def f(x_vals):\n            term1 = w * norm.pdf(x_vals, loc=mu1, scale=sigma_t)\n            term2 = (1.0 - w) * norm.pdf(x_vals, loc=mu2, scale=sigma_t)\n            return term1 + term2\n\n        # 2. Calculate parameters for the single proposal g_s(x)\n        mu_p = w * mu1 + (1.0 - w) * mu2\n        var_p = sigma_t**2 + w * (1.0 - w) * (mu2 - mu1)**2\n        sigma_p = np.sqrt(var_p)\n\n        # 3. Define the single proposal density g_s(x)\n        def g_s(x_vals):\n            return norm.pdf(x_vals, loc=mu_p, scale=sigma_p)\n\n        # 4. Construct the numerical grid\n        L = 8.0 * sigma_t + np.abs(mu2 - mu1)\n        x_min = min(mu1, mu2) - L\n        x_max = max(mu1, mu2) + L\n        x_grid = np.linspace(x_min, x_max, N_grid)\n\n        # 5. Evaluate f(x) and g_s(x) on the grid\n        f_vals = f(x_grid)\n        g_s_vals = g_s(x_grid)\n\n        # 6. Compute the ratio r_s(x) = f(x) / g_s(x)\n        # To avoid division by zero or NaN, we handle cases where g_s is very small.\n        # If g_s(x) is near zero, f(x) must also be near zero for the ratio to be finite.\n        # In the extreme tails, both are effectively zero, and the ratio tends to zero.\n        # We can safely replace g_s_vals=0 with a very small number, or filter them.\n        # Here, we only divide where g_s_vals is non-zero.\n        # The result of f(x)/g(x) approaches 0 where g(x) goes to 0 faster than f(x),\n        # which is the case in the tails.\n        ratio_s = np.zeros_like(f_vals)\n        non_zero_mask = g_s_vals > 0\n        ratio_s[non_zero_mask] = f_vals[non_zero_mask] / g_s_vals[non_zero_mask]\n\n        # 7. The improvement factor I is the max of the ratio\n        # I = M_s / M_m = (gamma * M_hat_s) / (gamma * M_hat_m)\n        # M_hat_m = 1 because g_m(x) = f(x). So, I = M_hat_s.\n        improvement_factor = np.max(ratio_s)\n        results.append(improvement_factor)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2370829"}]}