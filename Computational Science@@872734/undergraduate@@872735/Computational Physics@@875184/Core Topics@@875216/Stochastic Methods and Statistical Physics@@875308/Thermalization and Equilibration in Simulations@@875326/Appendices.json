{"hands_on_practices": [{"introduction": "We begin our journey into equilibration with a visually intuitive and fundamental process: diffusion. Imagine a drop of dye placed in the center of a container of water; over time, the dye molecules spread out until they are uniformly distributed. This practice [@problem_id:2446022] challenges you to build a simulation of this process from scratch, modeling the dye particles' movement as a random walk. By tracking how the spatial variance of the particle ensemble evolves, you will directly observe and quantify the system's approach to its predictable equilibrium state.", "problem": "You are to write a complete, runnable program that simulates the diffusion of dye particles in a fluid confined to a finite hypercubic box with reflecting boundaries, and uses the variance of the particle positions, denoted by $\\sigma^2(t)$, as a measure of equilibration progression. The simulation must be formulated in discrete time with a fixed time step and proceed by evolving an ensemble of independent particles. Your program must implement the following scientifically grounded specifications.\n\n1) Fundamental model and update rule. Consider $N$ independent dye particles moving in $d$ dimensions within a hypercube of side length $L$ centered at the origin, i.e., positions $\\mathbf{x}\\in[-L/2,L/2]^d$. The motion is modeled as overdamped Brownian motion (a Wiener process) in discrete time. Over one time step of duration $\\Delta t$, each particle’s displacement in each coordinate is an independent Gaussian random variable with mean $0$ and variance $2 D \\Delta t$, where $D$ is the diffusion coefficient. That is, for each coordinate $\\alpha\\in\\{1,\\dots,d\\}$, the increment is $\\Delta x_{\\alpha}\\sim\\mathcal{N}(0,2 D \\Delta t)$. After the free-space update, reflecting boundaries must be enforced exactly for each coordinate by a reflection mapping that takes any coordinate $x$ to the interval $[-L/2,L/2]$ by repeated reflections. You must implement the following coordinate-wise reflection formula that handles arbitrarily large excursions in one step:\n$$\nu \\equiv \\operatorname{mod}\\!\\left(x+\\frac{L}{2},\\,2L\\right)\\in[0,2L),\\qquad\nx_{\\mathrm{ref}} \\equiv \\begin{cases}\nu-\\dfrac{L}{2}, & \\text{if } u\\le L, \\\\\n\\dfrac{3L}{2}-u, & \\text{if } u> L.\n\\end{cases}\n$$\nAll particles start at the box center at time $t=0$, i.e., $\\mathbf{x}_i(0)=\\mathbf{0}$ for $i\\in\\{1,\\dots,N\\}$.\n\n2) Variance and observables. At each discrete time $t_k=k\\,\\Delta t$ for $k\\in\\{0,1,\\dots,K\\}$, compute the ensemble variance of positions\n$$\n\\sigma^2(t_k)=\\frac{1}{N}\\sum_{i=1}^{N}\\left\\|\\mathbf{x}_i(t_k)-\\bar{\\mathbf{x}}(t_k)\\right\\|^2,\\qquad\n\\bar{\\mathbf{x}}(t_k)=\\frac{1}{N}\\sum_{i=1}^{N}\\mathbf{x}_i(t_k),\n$$\nwhere $\\|\\cdot\\|$ is the Euclidean norm. This scalar variance is the sum of coordinate-wise variances.\n\n3) Equilibrium target and equilibration metric. In the long-time limit under reflecting boundaries, the equilibrium distribution of positions is uniform in $[-L/2,L/2]^d$. You must analytically determine (and use in your code) the equilibrium total variance $\\sigma^2_{\\mathrm{eq}}$ for this uniform distribution. Define a target fraction $f\\in(0,1)$ and the corresponding threshold $\\sigma^2_{\\mathrm{thr}}=f\\,\\sigma^2_{\\mathrm{eq}}$. Define the equilibration time $\\tau_f$ to be the smallest $t_k$ for which $\\sigma^2(t_k)\\ge \\sigma^2_{\\mathrm{thr}}$. If $\\sigma^2(t)$ never reaches $\\sigma^2_{\\mathrm{thr}}$ within the simulated time window $[0,K\\,\\Delta t]$, report $\\tau_f=-1.0$.\n\n4) Early-time linear growth rate of variance. At sufficiently early times before the boundaries are significantly felt, the variance is expected to grow approximately linearly with $t$. To quantify this initial equilibration progression, estimate the initial linear growth rate $m$ of $\\sigma^2(t)$ by a least-squares fit of $\\sigma^2(t)\\approx m\\,t$ constrained to pass through the origin, using only time points with $\\sigma^2(t)\\le g\\,\\sigma^2_{\\mathrm{eq}}$ for a fixed gate fraction $g\\in(0,1)$. Use $g=0.2$. If fewer than a minimum number of points are available under this gate, use the first $M_{\\min}$ positive-time points instead, with $M_{\\min}=50$ or all available if fewer than $50$. The least-squares estimator constrained through the origin must be implemented as\n$$\nm=\\frac{\\sum_{j} t_j\\,\\sigma^2(t_j)}{\\sum_{j} t_j^2},\n$$\nwhere the sum is over the selected time indices $j$.\n\n5) Units. Use micrometers for length and seconds for time. The diffusion coefficient $D$ is in square micrometers per second. Report $m$ in square micrometers per second, and report $\\tau_f$ in seconds. All numeric outputs must be decimal numbers.\n\n6) Pseudo-randomness. Use a pseudo-random number generator with a fixed seed $s$ provided per test case to ensure reproducible results.\n\n7) Test suite. Your program must run the simulation for the following parameter sets, in order, and produce the required outputs for each. For each case, you are given the dimension $d$, side length $L$ in micrometers, diffusion coefficient $D$ in square micrometers per second, number of particles $N$, time step $\\Delta t$ in seconds, number of steps $K$, target fraction $f$, and random seed $s$:\n- Case A: $d=1$, $L=2.0\\,\\mu\\mathrm{m}$, $D=0.5\\,\\mu\\mathrm{m}^2/\\mathrm{s}$, $N=2000$, $\\Delta t=0.002\\,\\mathrm{s}$, $K=5000$, $f=0.9$, $s=12345$.\n- Case B: $d=2$, $L=5.0\\,\\mu\\mathrm{m}$, $D=1.5\\,\\mu\\mathrm{m}^2/\\mathrm{s}$, $N=3000$, $\\Delta t=0.002\\,\\mathrm{s}$, $K=3500$, $f=0.9$, $s=2024$.\n- Case C: $d=3$, $L=3.0\\,\\mu\\mathrm{m}$, $D=3.0\\,\\mu\\mathrm{m}^2/\\mathrm{s}$, $N=2500$, $\\Delta t=0.0015\\,\\mathrm{s}$, $K=3000$, $f=0.9$, $s=777$.\n- Case D: $d=1$, $L=10.0\\,\\mu\\mathrm{m}$, $D=2.0\\,\\mu\\mathrm{m}^2/\\mathrm{s}$, $N=1500$, $\\Delta t=0.001\\,\\mathrm{s}$, $K=2000$, $f=0.9$, $s=4242$.\n\n8) Required outputs. For each case, compute and return a two-element list $[m,\\tau_f]$, where $m$ is the initial linear growth rate in $\\mu\\mathrm{m}^2/\\mathrm{s}$ and $\\tau_f$ is the equilibration time in $\\mathrm{s}$ as defined above (use $\\tau_f=-1.0$ if the threshold is not reached). Aggregate the results for all four cases into a single list in the same order as the cases.\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a two-element list in the order $[m,\\tau_f]$, for example, $[[m_1,\\tau_{f,1}],[m_2,\\tau_{f,2}],[m_3,\\tau_{f,3}],[m_4,\\tau_{f,4}]]$.", "solution": "The problem statement has been subjected to rigorous validation and is determined to be valid. It is scientifically grounded, well-posed, and provides a complete and consistent set of specifications for a standard computational physics simulation. We will now proceed with the solution.\n\nThe problem requires the simulation of overdamped Brownian motion in a confined volume and the analysis of its equilibration dynamics. The solution is structured upon fundamental principles of statistical mechanics and stochastic processes, which are then implemented algorithmically.\n\nFirst, we establish the necessary theoretical groundwork.\n\n**1. Equilibrium State and Variance**\n\nIn the long-time limit ($t \\to \\infty$), the ensemble of particles diffusing within a box with reflecting boundaries will reach a state of thermal equilibrium. In this state, the probability density function for a particle's position is uniform over the volume of the box. For a $d$-dimensional hypercube of side length $L$ centered at the origin, each coordinate $x_{\\alpha}$ for $\\alpha \\in \\{1, \\dots, d\\}$ is an independent random variable uniformly distributed on the interval $[-L/2, L/2]$.\n\nThe variance of a continuous uniform random variable on $[a, b]$ is $(b-a)^2/12$. For a single coordinate $x_{\\alpha}$, this gives:\n$$\n\\mathrm{Var}(x_{\\alpha}) = \\frac{(L/2 - (-L/2))^2}{12} = \\frac{L^2}{12}\n$$\nThe problem defines the total variance as $\\sigma^2(t) = \\frac{1}{N}\\sum_{i=1}^{N}\\left\\|\\mathbf{x}_i(t)-\\bar{\\mathbf{x}}(t)\\right\\|^2$. For a large ensemble ($N \\to \\infty$), the sample mean $\\bar{\\mathbf{x}}(t)$ converges to the true mean of the distribution, which is $\\mathbf{0}$ by symmetry. So, the equilibrium variance $\\sigma^2_{\\mathrm{eq}}$ is the expectation value of the squared norm of the position vector, $E[\\|\\mathbf{X}\\|^2]$.\n$$\n\\sigma^2_{\\mathrm{eq}} = E\\left[\\sum_{\\alpha=1}^{d} x_{\\alpha}^2\\right] = \\sum_{\\alpha=1}^{d} E[x_{\\alpha}^2]\n$$\nSince the mean of each coordinate is $E[x_{\\alpha}] = 0$, we have $E[x_{\\alpha}^2] = \\mathrm{Var}(x_{\\alpha})$. Therefore, the theoretical equilibrium variance is:\n$$\n\\sigma^2_{\\mathrm{eq}} = \\sum_{\\alpha=1}^{d} \\frac{L^2}{12} = \\frac{d L^2}{12}\n$$\nThis analytical result is essential for defining the equilibration threshold $\\sigma^2_{\\mathrm{thr}} = f \\sigma^2_{\\mathrm{eq}}$.\n\n**2. Early-Time Dynamics and Growth Rate**\n\nAt very early times, before particles have had a chance to interact significantly with the boundaries, their motion is approximately that of free diffusion in an infinite space. For a particle starting at the origin, the mean-squared displacement (MSD) at time $t$ is given by the Einstein relation:\n$$\n\\langle \\|\\mathbf{x}(t)\\|^2 \\rangle = 2dDt\n$$\nHere, $D$ is the diffusion coefficient and $d$ is the dimensionality. The ensemble variance $\\sigma^2(t)$ is closely related to the MSD. For large $N$, $\\sigma^2(t) \\approx \\langle \\|\\mathbf{x}(t)\\|^2 \\rangle$. Thus, we expect a linear growth regime:\n$$\n\\sigma^2(t) \\approx (2dD)t\n$$\nThis implies that the initial linear growth rate $m$ should be theoretically close to $m_{\\mathrm{theory}} = 2dD$. The numerical estimation of $m$ from the simulation data serves as a verification of the simulation's correctness.\n\n**3. Algorithmic Implementation**\n\nThe simulation will be implemented based on the following algorithmic design.\n\n**Simulation Core:**\nA main loop iterates over discrete time steps $k = 0, 1, \\dots, K$. The state of the system is represented by a NumPy array `positions` of shape $(N, d)$, where $N$ is the number of particles and $d$ is the dimension. This array is initialized to zeros, as all particles start at the origin. At each step, observables are calculated, and then particle positions are updated.\n\n**Stochastic Update:**\nThe motion of each particle is governed by a discrete-time Wiener process. The displacement in each coordinate over a time step $\\Delta t$ is drawn from a normal distribution. For efficiency, we generate an $(N, d)$ array of random numbers at once. The standard deviation of the Gaussian distribution for each displacement component is $\\sigma_{\\Delta x} = \\sqrt{2D\\Delta t}$. The update rule is:\n$$\n\\mathbf{x}_i(t_{k+1}) = \\mathbf{x}_i(t_k) + \\Delta \\mathbf{x}_i\n$$\nwhere each component of $\\Delta \\mathbf{x}_i$ is drawn from $\\mathcal{N}(0, 2D\\Delta t)$.\n\n**Boundary Conditions:**\nAfter the free-space displacement, reflecting boundaries must be enforced. The provided formula is implemented in a vectorized fashion for all particles and coordinates simultaneously. The coordinate $x$ is first mapped to a value $u$ in the double-width interval $[0, 2L)$ using the modulo operator.\n$$\nu = \\operatorname{mod}(x + L/2, 2L)\n$$\nThen, a conditional mapping folds the position back into the primary interval $[-L/2, L/2]$. This is efficiently achieved using `numpy.where`, which applies a different formula based on whether $u > L$.\n\n**Observable Calculation:**\nAt each time step $t_k$, the ensemble variance $\\sigma^2(t_k)$ is computed. The most direct translation of the formula $\\frac{1}{N}\\sum_{i=1}^{N}\\left\\|\\mathbf{x}_i(t_k)-\\bar{\\mathbf{x}}(t_k)\\right\\|^2$ is prone to floating-point errors and is less efficient than using built-in NumPy functions. A numerically stable and efficient method is to compute the variance of each coordinate separately and sum the results. This is achieved with `numpy.var(positions, axis=0)`, which computes the variance along the particle axis, followed by a sum over the resulting dimensional variances.\n\n**Post-Simulation Analysis:**\nAfter completing the simulation loop and populating arrays of times $t_k$ and variances $\\sigma^2(t_k)$, we calculate the two required metrics.\n\n*   **Equilibration Time ($\\tau_f$):** We search for the first index $k$ where $\\sigma^2(t_k) \\ge \\sigma^2_{\\mathrm{thr}}$. The corresponding time $t_k$ is the result $\\tau_f$. If no such index exists, $\\tau_f$ is set to $-1.0$, as specified. This is accomplished by finding all indices satisfying the condition and taking the first one if the set is not empty.\n\n*   **Initial Slope ($m$):** The data points $(t_k, \\sigma^2(t_k))$ for the linear fit $y = mx$ are selected based on a two-stage logic to ensure a robust estimate of the initial rate.\n    1.  First, we identify all positive-time points where the variance is below a gate: $\\sigma^2(t_k) \\le g\\sigma^2_{\\mathrm{eq}}$, with $g=0.2$.\n    2.  If the number of these points is greater than or equal to a minimum threshold $M_{\\min}=50$, these points are used for the fit.\n    3.  Otherwise, as a fallback, we use the first $M_{\\min}$ positive-time points (or all available positive-time points if the total number of steps $K$ is less than $M_{\\min}$).\n    The slope $m$ is then calculated using the provided least-squares formula, $m = (\\sum_j t_j \\sigma^2_j) / (\\sum_j t_j^2)$, where the sums are over the selected indices $j$. This calculation is performed using vectorized NumPy operations.\n\nThis completes the design. The accompanying code implements this logic for the specified test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_simulation(d, L, D, N, dt, K, f, s):\n    \n    # Constants for analysis\n    G_GATE_FRACTION = 0.2\n    M_MIN_POINTS = 50\n\n    # 1. Initialization\n    # Use the modern, preferred method for reproducible RNG\n    rng = np.random.default_rng(s)\n\n    # All particles start at the origin (d-dimensional vector 0)\n    positions = np.zeros((N, d), dtype=np.float64)\n\n    # Theoretical equilibrium variance: sigma_eq^2 = d * L^2 / 12\n    sigma_sq_eq = d * (L**2) / 12.0\n    # Threshold for equilibration time\n    sigma_sq_thr = f * sigma_sq_eq\n    \n    # Standard deviation of the displacement in one step for one coordinate\n    step_std = np.sqrt(2.0 * D * dt)\n\n    # Arrays to store the time evolution of observables\n    times = np.linspace(0, K * dt, K + 1)\n    variances = np.zeros(K + 1, dtype=np.float64)\n\n    # 2. Simulation Loop\n    for k in range(K + 1):\n        # a. Calculate and store observables for the current state\n        # The total variance is the sum of variances of each coordinate.\n        # np.var(a, axis=0) computes variance over the N-particle ensemble for each dimension.\n        # The default ddof=0 means variance is computed as (1/N)*sum(...), matching the problem.\n        current_variance = np.sum(np.var(positions, axis=0))\n        variances[k] = current_variance\n\n        # b. Evolve the system for the next step (if not the last step)\n        if k < K:\n            # Generate random displacements for all particles and dimensions at once\n            displacements = rng.normal(loc=0.0, scale=step_std, size=(N, d))\n            \n            # Update positions with a free-space step\n            positions += displacements\n\n            # c. Apply reflecting boundary conditions\n            # This is a vectorized implementation of the given formula.\n            # It maps any position back to the hypercube [-L/2, L/2]^d.\n            u = np.mod(positions + L / 2.0, 2.0 * L)\n            positions = np.where(u > L, 1.5 * L - u, u - 0.5 * L)\n\n    # 3. Post-Simulation Analysis\n    \n    # a. Calculate equilibration time tau_f\n    # Find all time indices where the variance is at or above the threshold\n    reached_indices = np.where(variances >= sigma_sq_thr)[0]\n    \n    tau_f = -1.0\n    if reached_indices.size > 0:\n        # The first time this occurs is at the minimum of these indices\n        first_reach_index = reached_indices[0]\n        tau_f = times[first_reach_index]\n\n    # b. Calculate initial growth rate m\n    # We fit sigma^2(t) = m*t using points from the early, linear regime.\n    # We only consider positive-time points for the fit.\n    \n    # Primary method: Use points under the gate value\n    gate_value = G_GATE_FRACTION * sigma_sq_eq\n    \n    # Note: variances[0] = 0. We exclude it from rate calculation.\n    # Indices of positive-time points that are under the gate\n    fit_indices_gate = np.where((variances[1:] > 0) & (variances[1:] <= gate_value))[0] + 1\n\n    if fit_indices_gate.size >= M_MIN_POINTS:\n        fit_indices = fit_indices_gate\n    else:\n        # Fallback method: Use the first M_min positive-time points\n        num_pts_to_take = min(M_MIN_POINTS, K)\n        fit_indices = np.arange(1, num_pts_to_take + 1)\n\n    t_fit = times[fit_indices]\n    var_fit = variances[fit_indices]\n    \n    # Least-squares estimator for y = m*x is m = sum(x*y) / sum(x^2)\n    numerator = np.sum(t_fit * var_fit)\n    denominator = np.sum(t_fit**2)\n    \n    # Avoid division by zero if no points are selected (highly unlikely)\n    m = numerator / denominator if denominator > 0 else 0.0\n\n    return [m, tau_f]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    # Test cases as provided in the problem statement.\n    # (d, L, D, N, dt, K, f, s)\n    test_cases = [\n        (1, 2.0,  0.5, 2000, 0.002,  5000, 0.9, 12345),\n        (2, 5.0,  1.5, 3000, 0.002,  3500, 0.9, 2024),\n        (3, 3.0,  3.0, 2500, 0.0015, 3000, 0.9, 777),\n        (1, 10.0, 2.0, 1500, 0.001,  2000, 0.9, 4242),\n    ]\n\n    results = []\n    for case_params in test_cases:\n        m, tau_f = run_simulation(*case_params)\n        results.append([m, tau_f])\n\n    # Format the final output string exactly as required,\n    # creating a list of lists representation in a string without spaces.\n    string_parts = [f\"[{res[0]},{res[1]}]\" for res in results]\n    final_output = f\"[{','.join(string_parts)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "2446022"}, {"introduction": "Having seen a stochastic system equilibrate, we now turn to a deeper question: can a purely deterministic, reversible mechanical system exhibit thermalization? This practice tackles the famous Fermi-Pasta-Ulam-Tsingou (FPUT) problem [@problem_id:2445969], a cornerstone in the study of chaos and statistical mechanics. You will simulate a chain of coupled oscillators and monitor how energy, initially concentrated in a single vibrational mode, spreads among all the system's modes, probing the very foundations of the equipartition theorem.", "problem": "Consider a one-dimensional Fermi–Pasta–Ulam–Tsingou (FPUT) $\\alpha$ chain with $N$ identical point masses and periodic boundary conditions. Let $u_j(t)$ denote the displacement of the $j$-th mass from its equilibrium position at time $t$, with $j \\in \\{0,1,\\dots,N-1\\}$. The equations of motion in dimensionless units are\n$$\n\\ddot{u}_j(t) = \\left(u_{j+1}(t) - 2 u_j(t) + u_{j-1}(t)\\right) + \\alpha \\left[\\left(u_{j+1}(t) - u_j(t)\\right)^2 - \\left(u_j(t) - u_{j-1}(t)\\right)^2\\right],\n$$\nwith periodic indexing $u_{j+N} \\equiv u_j$. Assume unit mass and unit linear spring constant. The initial condition is a single-mode displacement with zero initial velocity:\n$$\nu_j(0) = A \\cos\\left(\\frac{2\\pi j}{N}\\right), \\quad \\dot{u}_j(0) = 0 \\quad \\text{for all } j.\n$$\n\nDefine the discrete Fourier transform (unitary normalization) of the displacement and velocity fields as\n$$\nQ_k(t) = \\frac{1}{\\sqrt{N}} \\sum_{j=0}^{N-1} u_j(t) \\, e^{- i \\frac{2\\pi}{N} k j},\\quad\nP_k(t) = \\frac{1}{\\sqrt{N}} \\sum_{j=0}^{N-1} \\dot{u}_j(t) \\, e^{- i \\frac{2\\pi}{N} k j},\n$$\nfor $k \\in \\{0,1,\\dots,N-1\\}$. For the corresponding harmonic chain, the normal mode angular frequencies are\n$$\n\\omega_k = 2 \\sin\\left(\\frac{\\pi k}{N}\\right).\n$$\nUsing these, define the instantaneous harmonic-mode energy proxy for each mode $k$ by\n$$\nE_k(t) = \\frac{1}{2}\\left(\\left|P_k(t)\\right|^2 + \\omega_k^2 \\left|Q_k(t)\\right|^2\\right).\n$$\nExclude the zero-frequency mode $k=0$ and form the normalized modal energy distribution over the nonzero modes:\n$$\n\\mathbf{e}(t) = \\left( \\frac{E_1(t)}{\\sum_{m=1}^{N-1} E_m(t)}, \\frac{E_2(t)}{\\sum_{m=1}^{N-1} E_m(t)}, \\dots, \\frac{E_{N-1}(t)}{\\sum_{m=1}^{N-1} E_m(t)} \\right).\n$$\nLet the target equipartition distribution be the uniform vector of length $N-1$,\n$$\n\\mathbf{u} = \\left(\\frac{1}{N-1}, \\frac{1}{N-1}, \\dots, \\frac{1}{N-1}\\right).\n$$\nDefine the instantaneous deviation from equipartition as the Euclidean norm\n$$\nD(t_n) = \\left\\| \\mathbf{e}(t_n) - \\mathbf{u} \\right\\|_2,\n$$\nevaluated on a uniform time grid $t_n = n \\,\\Delta t$ for $n = 0,1,2,\\dots, \\lfloor T_{\\text{end}}/\\Delta t \\rfloor$ with time step $\\Delta t$ and final time $T_{\\text{end}}$. Define the sliding-window average over a window of duration $W$ as\n$$\n\\overline{D}(t_n) = \\frac{1}{M_n} \\sum_{m=\\max(0, n-M+1)}^{n} D(t_m),\n$$\nwhere $M = \\left\\lceil \\frac{W}{\\Delta t} \\right\\rceil$ and $M_n = n - \\max(0, n-M+1) + 1$ is the number of available samples in the current window (for early times when fewer than $M$ samples exist, use all available samples to form the average). The equilibration time $\\tau$ is defined as the smallest $t_n$ such that $\\overline{D}(t_n) \\leq \\delta$. If no such $t_n$ exists in $[0, T_{\\text{end}}]$, report $\\tau = -1$.\n\nYour task is to write a complete and runnable program that, for each test case below, integrates the equations of motion using either the Velocity–Verlet scheme or the classical fourth-order Runge–Kutta scheme (as specified per test case), computes $\\tau$ as defined above, and outputs the results. All quantities are dimensionless, so no physical units are required. Angles, if any, are in radians. The final answers for each test case must be floats. If equilibration is not achieved within the simulated time interval, output the float $-1.0$ for that case.\n\nGlobal parameters for all test cases:\n- Sliding-window duration $W = 50$.\n- Equipartition tolerance $\\delta = 0.12$.\n\nTest suite (each tuple is $(N, \\alpha, A, \\Delta t, T_{\\text{end}}, \\text{integrator})$):\n- Case $1$: $(8, 0.25, 0.20, 0.05, 1000.0, \\text{\"verlet\"})$.\n- Case $2$: $(8, 0.25, 0.20, 0.05, 1000.0, \\text{\"rk4\"})$.\n- Case $3$: $(8, 0.02, 0.20, 0.05, 1000.0, \\text{\"verlet\"})$.\n- Case $4$: $(8, 0.25, 0.20, 0.12, 1000.0, \\text{\"rk4\"})$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the cases listed above. Each float must be rounded to three decimal places. For example, an output with four results should look like\n$$\n[\\tau_1,\\tau_2,\\tau_3,\\tau_4],\n$$\nwhere each $\\tau_i$ is printed with exactly three digits after the decimal point.", "solution": "The problem statement is reviewed and found to be valid. It presents a well-posed, scientifically-grounded numerical experiment based on the Fermi–Pasta–Ulam–Tsingou (FPUT) model, a canonical system in computational physics for studying thermalization and the ergodic hypothesis. All definitions, parameters, and objectives are specified with sufficient precision and are free from contradiction or ambiguity.\n\nThe task is to compute the equilibration time $\\tau$ for a system of $N$ oscillators. This requires a direct numerical simulation of the system's dynamics. The procedure is as follows:\n\n1.  **System Initialization**: The system state is defined by the displacements $\\mathbf{u}(t) = \\{u_j(t)\\}_{j=0}^{N-1}$ and velocities $\\dot{\\mathbf{u}}(t) = \\{\\dot{u}_j(t)\\}_{j=0}^{N-1}$. At time $t=0$, these are initialized according to the problem statement:\n    $$\n    u_j(0) = A \\cos\\left(\\frac{2\\pi j}{N}\\right), \\quad \\dot{u}_j(0) = 0\n    $$\n\n2.  **Numerical Integration**: The equations of motion are integrated forward in time from $t=0$ to $t=T_{\\text{end}}$ with a time step $\\Delta t$. The acceleration of the $j$-th mass, $\\ddot{u}_j$, is a function of the instantaneous positions of its neighbors:\n    $$\n    \\ddot{u}_j(t) = a_j(\\mathbf{u}(t)) = \\left(u_{j+1} - 2 u_j + u_{j-1}\\right) + \\alpha \\left[\\left(u_{j+1} - u_j\\right)^2 - \\left(u_j - u_{j-1}\\right)^2\\right]\n    $$\n    The periodic boundary conditions $u_{j+N} \\equiv u_j$ are handled by using cyclic indexing on the array of displacements. Two integration methods are required:\n\n    a.  **Velocity-Verlet**: This is a second-order symplectic integrator, well-suited for energy-conserving Hamiltonian systems. Given the state $(\\mathbf{u}(t_n), \\dot{\\mathbf{u}}(t_n))$ and acceleration $\\mathbf{a}(t_n) = \\mathbf{a}(\\mathbf{u}(t_n))$, the state at the next time step $t_{n+1} = t_n + \\Delta t$ is computed via:\n        $$\n        \\mathbf{u}(t_{n+1}) = \\mathbf{u}(t_n) + \\dot{\\mathbf{u}}(t_n)\\Delta t + \\frac{1}{2}\\mathbf{a}(t_n)(\\Delta t)^2\n        $$\n        $$\n        \\mathbf{a}(t_{n+1}) = \\mathbf{a}(\\mathbf{u}(t_{n+1}))\n        $$\n        $$\n        \\dot{\\mathbf{u}}(t_{n+1}) = \\dot{\\mathbf{u}}(t_n) + \\frac{1}{2}\\left(\\mathbf{a}(t_n) + \\mathbf{a}(t_{n+1})\\right)\\Delta t\n        $$\n\n    b.  **Fourth-Order Runge-Kutta (RK4)**: This is a general-purpose, higher-accuracy explicit integrator. The system is written in first-order form by defining a state vector $\\mathbf{y} = (\\mathbf{u}, \\dot{\\mathbf{u}})$. The time derivative is $\\frac{d\\mathbf{y}}{dt} = f(\\mathbf{y}) = (\\dot{\\mathbf{u}}, \\mathbf{a}(\\mathbf{u}))$. The update rule is:\n        $$\n        \\mathbf{k}_1 = \\Delta t \\cdot f(\\mathbf{y}_n)\n        $$\n        $$\n        \\mathbf{k}_2 = \\Delta t \\cdot f(\\mathbf{y}_n + \\mathbf{k}_1/2)\n        $$\n        $$\n        \\mathbf{k}_3 = \\Delta t \\cdot f(\\mathbf{y}_n + \\mathbf{k}_2/2)\n        $$\n        $$\n        \\mathbf{k}_4 = \\Delta t \\cdot f(\\mathbf{y}_n + \\mathbf{k}_3)\n        $$\n        $$\n        \\mathbf{y}_{n+1} = \\mathbf{y}_n + \\frac{1}{6}(\\mathbf{k}_1 + 2\\mathbf{k}_2 + 2\\mathbf{k}_3 + \\mathbf{k}_4)\n        $$\n\n3.  **Equipartition Analysis**: At each time step $t_n$, the following quantities are computed to assess the degree of thermalization:\n\n    a.  **Normal Mode Coordinates**: The displacement and velocity fields are transformed into normal mode (Fourier) space using the discrete Fourier transform with unitary normalization:\n        $$\n        Q_k(t_n) = \\frac{1}{\\sqrt{N}} \\sum_{j=0}^{N-1} u_j(t_n) \\, e^{-i \\frac{2\\pi kj}{N}}, \\quad P_k(t_n) = \\frac{1}{\\sqrt{N}} \\sum_{j=0}^{N-1} \\dot{u}_j(t_n) \\, e^{-i \\frac{2\\pi kj}{N}}\n        $$\n        This is implemented efficiently using the Fast Fourier Transform (FFT) algorithm.\n\n    b.  **Modal Energies**: The energy proxy for each mode $k \\in \\{1, \\dots, N-1\\}$ is calculated:\n        $$\n        E_k(t_n) = \\frac{1}{2}\\left(\\left|P_k(t_n)\\right|^2 + \\omega_k^2 \\left|Q_k(t_n)\\right|^2\\right)\n        $$\n        where $\\omega_k = 2 \\sin(\\pi k/N)$ are the harmonic frequencies. The $k=0$ mode is excluded as it corresponds to the conserved total momentum, which is zero for the given initial conditions.\n\n    c.  **Deviation from Equipartition**: The normalized energy distribution $\\mathbf{e}(t_n)$ and its Euclidean distance $D(t_n)$ from the uniform equipartition distribution $\\mathbf{u}$ are computed:\n        $$\n        \\mathbf{e}(t_n) = \\frac{1}{\\sum_{m=1}^{N-1} E_m(t_n)} (E_1, E_2, \\dots, E_{N-1}), \\quad D(t_n) = \\|\\mathbf{e}(t_n) - \\mathbf{u}\\|_2\n        $$\n\n4.  **Equilibration Time Determination**: The equilibration time $\\tau$ is found by monitoring a sliding-window average of the deviation, $\\overline{D}(t_n)$.\n    $$\n    \\overline{D}(t_n) = \\frac{1}{M_n} \\sum_{m=\\max(0, n-M+1)}^{n} D(t_m)\n    $$\n    The window size in steps is $M = \\lceil W/\\Delta t \\rceil$. The first time $t_n$ at which $\\overline{D}(t_n) \\leq \\delta$ is identified as the equilibration time $\\tau$. If this condition is not met by $t = T_{\\text{end}}$, the result is reported as $\\tau = -1$.\n\nThe final program implements this entire procedure, iterating through each test case defined in the problem, and formats the output as specified.", "answer": "```python\n# language: Python\n# version: 3.12\n# libraries:\n#   - name: numpy\n#     version: 1.23.5\n#   - name: scipy\n#     version: 1.11.4\n\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Solves the FPUT equilibration problem for the given test cases.\n    \"\"\"\n\n    def _acceleration(u, alpha, N):\n        \"\"\"\n        Computes the acceleration for all masses in the FPUT chain.\n        \"\"\"\n        u_jp1 = np.roll(u, -1)\n        u_jm1 = np.roll(u, 1)\n        \n        linear_force = u_jp1 - 2.0 * u + u_jm1\n        nonlinear_force = alpha * ((u_jp1 - u)**2.0 - (u - u_jm1)**2.0)\n        \n        return linear_force + nonlinear_force\n\n    def _run_simulation(params):\n        \"\"\"\n        Runs a single FPUT simulation and returns the equilibration time.\n        \"\"\"\n        N, alpha, A, dt, T_end, integrator = params\n        W = 50.0\n        delta = 0.12\n\n        # Setup initial conditions\n        j = np.arange(N)\n        u = A * np.cos(2.0 * np.pi * j / N)\n        v = np.zeros(N, dtype=float)\n        \n        # Pre-calculate constants\n        k_vals = np.arange(N)\n        omega_sq = (2.0 * np.sin(np.pi * k_vals / N))**2.0\n        uniform_dist = np.full(N - 1, 1.0 / (N - 1))\n        \n        M = math.ceil(W / dt)\n        D_values = []\n        \n        num_steps = int(T_end / dt)\n        \n        accel = _acceleration(u, alpha, N)\n        \n        for n in range(num_steps + 1):\n            t_n = n * dt\n            \n            # 1. Calculate deviation D(t_n)\n            Q = np.fft.fft(u, norm=\"ortho\")\n            P = np.fft.fft(v, norm=\"ortho\")\n            \n            Q_nonzero = Q[1:]\n            P_nonzero = P[1:]\n            omega_sq_nonzero = omega_sq[1:]\n            \n            E_k = 0.5 * (np.abs(P_nonzero)**2.0 + omega_sq_nonzero * np.abs(Q_nonzero)**2.0)\n            \n            E_tot = np.sum(E_k)\n            \n            if E_tot > 1e-15:\n                e_n = E_k / E_tot\n            else:\n                e_n = np.zeros(N - 1)\n                \n            D_n = np.linalg.norm(e_n - uniform_dist)\n            D_values.append(D_n)\n            \n            # 2. Calculate sliding window average\n            window_start_idx = max(0, n - M + 1)\n            current_window_D = D_values[window_start_idx:]\n            D_bar = np.mean(current_window_D)\n            \n            # 3. Check for equilibration\n            if D_bar <= delta:\n                return t_n\n                \n            # 4. Update state using the selected integrator\n            if integrator == \"verlet\":\n                u_new = u + v * dt + 0.5 * accel * dt**2.0\n                new_accel = _acceleration(u_new, alpha, N)\n                v_new = v + 0.5 * (accel + new_accel) * dt\n                u, v, accel = u_new, v_new, new_accel\n            elif integrator == \"rk4\":\n                def derivs(state_vec, N_val, alpha_val):\n                    u_comp = state_vec[:N_val]\n                    v_comp = state_vec[N_val:]\n                    a_comp = _acceleration(u_comp, alpha_val, N_val)\n                    return np.concatenate((v_comp, a_comp))\n                \n                y = np.concatenate((u, v))\n                \n                k1 = dt * derivs(y, N, alpha)\n                k2 = dt * derivs(y + 0.5 * k1, N, alpha)\n                k3 = dt * derivs(y + 0.5 * k2, N, alpha)\n                k4 = dt * derivs(y + k3, N, alpha)\n                \n                y_next = y + (k1 + 2.0 * k2 + 2.0 * k3 + k4) / 6.0\n                \n                u = y_next[:N]\n                v = y_next[N:]\n\n        return -1.0\n\n    test_cases = [\n        (8, 0.25, 0.20, 0.05, 1000.0, \"verlet\"),\n        (8, 0.25, 0.20, 0.05, 1000.0, \"rk4\"),\n        (8, 0.02, 0.20, 0.05, 1000.0, \"verlet\"),\n        (8, 0.25, 0.20, 0.12, 1000.0, \"rk4\"),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = _run_simulation(case)\n        results.append(result)\n\n    formatted_results = [f\"{res:.3f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2445969"}, {"introduction": "Our final practice is a crucial cautionary tale about the tools of computational physics. When we use stochastic methods like Monte Carlo to simulate a system in a thermal bath, we rely on pseudo-random number generators (RNGs) to mimic thermal fluctuations. This exercise [@problem_id:2445950] starkly reveals what happens when this 'digital heat bath' is flawed. By comparing a simulation of the Ising model using a high-quality RNG with one using a biased, low-quality generator, you will discover how seemingly subtle computational artifacts can completely prevent a system from reaching its correct thermal equilibrium.", "problem": "Consider a one-dimensional Ising chain of $N$ spins with periodic boundary conditions, where each spin $s_i \\in \\{+1,-1\\}$ and the Hamiltonian is $H(\\{s\\}) = -J \\sum_{i=1}^{N} s_i s_{i+1}$ with $s_{N+1} \\equiv s_1$. Assume $J=1$ and Boltzmann constant $k_\\mathrm{B}=1$, so that the inverse temperature is $\\beta = 1/T$. The system is coupled to a canonical heat bath at temperature $T$ and evolves according to a Metropolis Markov Chain Monte Carlo (MCMC) dynamics defined as follows: at each attempted update, a site index $i \\in \\{1,\\dots,N\\}$ is chosen uniformly at random, a proposal $s_i \\to -s_i$ is made, and the move is accepted with probability $\\min\\{1,\\exp(-\\beta \\Delta E)\\}$ where $\\Delta E$ is the energy change of the proposed flip. One sweep consists of $N$ such attempted updates. The initial configuration is the fully ordered state $s_i=+1$ for all $i$.\n\nThe exact equilibrium energy per spin in the thermodynamic limit for the one-dimensional Ising model at inverse temperature $\\beta$ and $J=1$ is $u^*(\\beta) = -\\tanh(\\beta)$. Define the equilibration time $\\tau_\\mathrm{eq}$ (in sweeps) for a given simulation and parameter set as the smallest sweep index $t \\ge W$ such that the absolute difference between the moving average of the measured energy per spin over the most recent $W$ sweeps and $u^*(\\beta)$ is less than or equal to a prescribed tolerance $\\delta$. If no such $t$ exists up to a maximum number of sweeps $S_\\max$, define $\\tau_\\mathrm{eq} = S_\\max + 1$.\n\nTwo distinct sources of uniformly distributed numbers in $[0,1)$ are used to drive the stochastic choices in the MCMC dynamics (both for site selection and for acceptance decisions):\n\n- Generator $\\mathcal{H}$ (high quality): an idealized source of independent draws from the continuous uniform distribution on $[0,1)$.\n- Generator $\\mathcal{L}$ (low quality): a biased pseudo-random number generator constructed from the linear congruential recurrence $x_{n+1} = (a x_n + c) \\bmod m$ with parameters $m=2^{31}$, $a=1103515245$, and $c=12345$, seeded by an integer $x_0$. The output variate is defined as $u_n = \\tfrac{1}{2} + \\frac{(x_n \\bmod (m/2))}{m}$, which yields values in the half-interval $[1/2,1)$ only.\n\nFor each test case listed below, simulate the dynamics as defined above using generator $\\mathcal{H}$ to compute $\\tau_\\mathrm{eq}^{(\\mathcal{H})}$ and using generator $\\mathcal{L}$ to compute $\\tau_\\mathrm{eq}^{(\\mathcal{L})}$, with the same physical parameters but possibly different seeds as specified. Report, for each case, the ratio $R = \\tau_\\mathrm{eq}^{(\\mathcal{L})}/\\tau_\\mathrm{eq}^{(\\mathcal{H})}$ rounded to three decimal places (dimensionless). Use $J=1$ throughout. Angles do not appear and no physical unit conversion is required; all quantities are dimensionless.\n\nTest suite (each tuple is $(N,\\ \\beta,\\ s_{\\mathcal{L}},\\ s_{\\mathcal{H}},\\ W,\\ \\delta,\\ S_\\max)$):\n\n- Case $1$: $(128,\\ 0.5,\\ 12345,\\ 2024,\\ 200,\\ 0.02,\\ 5000)$\n- Case $2$: $(64,\\ 1.0,\\ 54321,\\ 7,\\ 200,\\ 0.02,\\ 5000)$\n- Case $3$: $(64,\\ 0.1,\\ 999,\\ 42,\\ 200,\\ 0.02,\\ 5000)$\n- Case $4$: $(32,\\ 2.0,\\ 2023,\\ 31415,\\ 200,\\ 0.02,\\ 5000)$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the cases above, with each entry equal to $R$ rounded to three decimal places (for example, $[1.234,2.000,3.142,0.875]$).", "solution": "The problem requires the simulation of a one-dimensional Ising model using a Metropolis Monte Carlo algorithm to determine the equilibration time, $\\tau_\\mathrm{eq}$. This process is to be performed for two different pseudo-random number generators (RNGs), one of high quality ($\\mathcal{H}$) and one of low quality ($\\mathcal{L}$), to analyze the effect of RNG bias on simulation dynamics.\n\nThe system is an Ising chain of $N$ spins $s_i \\in \\{+1, -1\\}$ with periodic boundary conditions. The Hamiltonian is given by $H = -J \\sum_{i=1}^{N} s_i s_{i+1}$, with $J=1$. The system evolves via single-spin-flip Metropolis dynamics. At each step, a site $i$ is chosen randomly, and a flip $s_i \\to -s_i$ is proposed. The change in energy, $\\Delta E$, for such a flip is localized to the spin's neighbors:\n$$ \\Delta E = 2J s_i (s_{i-1} + s_{i+1}) $$\nWith $J=1$ and $s_i, s_{i-1}, s_{i+1} \\in \\{+1, -1\\}$, the possible non-zero values for $\\Delta E$ are $\\pm 4$. A move is accepted with probability $p = \\min\\{1, \\exp(-\\beta \\Delta E)\\}$, where $\\beta=1/T$ is the inverse temperature ($k_B=1$). The initial state is fully ordered, $s_i = +1$ for all $i$, corresponding to the ground state energy $E = -N$.\n\nThe equilibration time $\\tau_\\mathrm{eq}$ is defined as the first sweep $t \\ge W$ where the moving average of the energy per spin, $u_t = E_t/N$, over the last $W$ sweeps is within a tolerance $\\delta$ of the exact equilibrium energy per spin in the thermodynamic limit, $u^*(\\beta) = -\\tanh(\\beta)$. That is, $|\\text{MA}_W(u,t) - u^*(\\beta)| \\le \\delta$.\n\nThe two RNGs are:\n1.  Generator $\\mathcal{H}$: An ideal uniform RNG on $[0,1)$, implemented using `numpy.random.default_rng`.\n2.  Generator $\\mathcal{L}$: A biased Linear Congruential Generator (LCG) with recurrence $x_{n+1} = (a x_n + c) \\bmod m$ for $a=1103515245$, $c=12345$, $m=2^{31}$. The output is constructed as $u_n = \\frac{1}{2} + \\frac{(x_n \\bmod (m/2))}{m}$, which generates variates exclusively in the interval $[0.5, 1)$.\n\nThe bias of generator $\\mathcal{L}$ has profound consequences for the Metropolis algorithm.\nFirst, consider the acceptance step. An energetically unfavorable move ($\\Delta E > 0$) is accepted if a random number $r$ satisfies $r < \\exp(-\\beta \\Delta E)$. Since generator $\\mathcal{L}$ produces $r \\ge 0.5$, any move for which the acceptance probability $\\exp(-\\beta \\Delta E)$ is less than $0.5$ will be systematically rejected. The only move that increases energy has $\\Delta E = 4$. The condition for this move to be *ever* accepted is $\\exp(-4\\beta) \\ge 0.5$, which simplifies to $\\beta \\le \\frac{\\ln(2)}{4} \\approx 0.173$. For any $\\beta > \\frac{\\ln(2)}{4}$, the simulation driven by $\\mathcal{L}$ cannot accept any energy-increasing moves. Since the system starts in the ground state (all spins up), it will remain trapped in this state, as any spin flip increases the energy. For test cases $1$ ($\\beta=0.5$), $2$ ($\\beta=1.0$), and $4$ ($\\beta=2.0$), this condition holds. The energy per spin for these simulations will remain constant at $u=-1$. The equilibration condition $|-1 - (-\\tanh(\\beta))| \\le 0.02$ is not met for any of these cases, so $\\tau_\\mathrm{eq}^{(\\mathcal{L})}$ is assigned the failure value $S_\\max + 1$.\n\nSecond, consider the site selection. To select a site index from $\\{0, 1, \\dots, N-1\\}$, one typically computes $\\lfloor N \\times r \\rfloor$. With $r \\in [0.5, 1)$ from generator $\\mathcal{L}$, the selected site index will always be in the range $\\{\\lfloor N/2 \\rfloor, \\dots, N-1\\}$. This means only the second half of the spin chain is ever directly updated. This spatial bias further hinders equilibration, as thermal fluctuations must propagate from one half of the system to the other via boundary interactions only.\n\nFor case $3$ ($\\beta=0.1$), we have $\\beta < 0.173$, so energy-increasing moves are possible with generator $\\mathcal{L}$. However, their acceptance probability is severely reduced compared to an ideal generator, and the site selection remains biased. We expect this to significantly slow down equilibration, leading to $\\tau_\\mathrm{eq}^{(\\mathcal{L})} > \\tau_\\mathrm{eq}^{(\\mathcal{H})}$.\n\nThe solution involves implementing the simulation for both generators for each test case. For generator $\\mathcal{H}$, a full simulation is always run. For generator $\\mathcal{L}$, we exploit the trapping phenomenon for cases $1, 2,$ and $4$ to assign $\\tau_\\mathrm{eq}^{(\\mathcal{L})}$ directly. For case $3$, a full simulation is required for $\\mathcal{L}$ as well. Finally, the ratio $R = \\tau_\\mathrm{eq}^{(\\mathcal{L})} / \\tau_\\mathrm{eq}^{(\\mathcal{H})}$ is computed for each case.\n\nThe implementation will consist of:\n1.  A class for the biased LCG, `LCG`, and a wrapper for the numpy RNG to provide a consistent interface.\n2.  A function `run_simulation(N, beta, S_max, rng)` that performs the Metropolis MCMC simulation and returns the history of energy per spin.\n3.  A function `calculate_tau_eq(energy_history, beta, W, delta, S_max)` that processes the energy history to find the equilibration time.\n4.  A main loop to iterate over the test cases, execute the simulations, compute the ratios, and format the output.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the 1D Ising model equilibration problem for the specified test cases.\n    \"\"\"\n\n    class LCG:\n        \"\"\"\n        Implementation of the biased low-quality Linear Congruential Generator.\n        Produces random numbers in the interval [0.5, 1.0).\n        \"\"\"\n        def __init__(self, seed):\n            self.m = 2**31\n            self.a = 1103515245\n            self.c = 12345\n            self.x = int(seed)\n            self.m_half = self.m // 2\n\n        def _step(self):\n            self.x = (self.a * self.x + self.c) % self.m\n\n        def random(self):\n            \"\"\"Generates a float in [0.5, 1.0).\"\"\"\n            self._step()\n            return 0.5 + (self.x % self.m_half) / self.m\n\n        def integers(self, low, high):\n            \"\"\"Generates an integer in [low, high).\"\"\"\n            return low + int(self.random() * (high - low))\n\n    class NumpyRNG:\n        \"\"\"\n        Wrapper for NumPy's high-quality random number generator to provide a\n        consistent interface with the custom LCG.\n        \"\"\"\n        def __init__(self, seed):\n            self.rng = np.random.default_rng(seed)\n\n        def random(self):\n            \"\"\"Generates a float in [0.0, 1.0).\"\"\"\n            return self.rng.random()\n\n        def integers(self, low, high):\n            \"\"\"Generates an integer in [low, high).\"\"\"\n            return self.rng.integers(low, high)\n\n    def run_simulation(N, beta, S_max, rng):\n        \"\"\"\n        Performs a Metropolis MCMC simulation for the 1D Ising model.\n\n        Args:\n            N (int): Number of spins.\n            beta (float): Inverse temperature.\n            S_max (int): Maximum number of sweeps.\n            rng (object): An RNG object with .random() and .integers() methods.\n\n        Returns:\n            list: A list of energy per spin after each sweep.\n        \"\"\"\n        spins = np.ones(N, dtype=np.int8)\n        current_energy = -float(N)  # J=1, all spins aligned\n        energy_history = []\n\n        for _ in range(S_max):\n            for _ in range(N):  # One sweep consists of N attempted flips\n                # 1. Select a site uniformly at random\n                i = rng.integers(0, N)\n\n                # 2. Calculate energy change for a proposed flip\n                s_i = spins[i]\n                s_left = spins[(i - 1 + N) % N]\n                s_right = spins[(i + 1) % N]\n                \n                # J=1 is assumed\n                delta_E = 2.0 * s_i * (s_left + s_right)\n\n                # 3. Metropolis acceptance rule\n                accept = False\n                if delta_E <= 0:\n                    accept = True\n                else:\n                    p_accept = np.exp(-beta * delta_E)\n                    if rng.random() < p_accept:\n                        accept = True\n                \n                if accept:\n                    spins[i] *= -1\n                    current_energy += delta_E\n            \n            energy_history.append(current_energy / N)\n\n        return energy_history\n\n    def calculate_tau_eq(energy_history, beta, W, delta, S_max):\n        \"\"\"\n        Calculates the equilibration time from an energy history.\n\n        Args:\n            energy_history (list): List of energy per spin values.\n            beta (float): Inverse temperature.\n            W (int): Moving average window size.\n            delta (float): Tolerance for equilibration.\n            S_max (int): Maximum number of sweeps.\n\n        Returns:\n            int: The equilibration time in sweeps.\n        \"\"\"\n        u_star = -np.tanh(beta)\n        \n        if len(energy_history) < W:\n            return S_max + 1\n\n        energies_np = np.array(energy_history, dtype=float)\n        \n        # Calculate initial sum for the moving window\n        current_sum = np.sum(energies_np[0:W])\n        \n        # Check starting from the first possible full window\n        for t in range(W, S_max + 1):\n            # t is the sweep index (1-based)\n            # MA for sweeps t-W+1 to t corresponds to indices from t-W to t-1\n            end_idx = t - 1\n            start_idx = end_idx - W\n\n            if start_idx > 0:\n                current_sum = current_sum - energies_np[start_idx] + energies_np[end_idx]\n            \n            ma = current_sum / W\n\n            if np.abs(ma - u_star) <= delta:\n                return t\n        \n        return S_max + 1\n\n    test_cases = [\n        (128, 0.5, 12345, 2024, 200, 0.02, 5000),\n        (64, 1.0, 54321, 7, 200, 0.02, 5000),\n        (64, 0.1, 999, 42, 200, 0.02, 5000),\n        (32, 2.0, 2023, 31415, 200, 0.02, 5000),\n    ]\n\n    results = []\n    \n    # Critical value of beta for the biased LCG\n    beta_crit = np.log(2.0) / 4.0\n\n    for N, beta, s_L, s_H, W, delta, S_max in test_cases:\n        # Run simulation with high-quality generator H\n        rng_H = NumpyRNG(seed=s_H)\n        energy_hist_H = run_simulation(N, beta, S_max, rng_H)\n        tau_H = calculate_tau_eq(energy_hist_H, beta, W, delta, S_max)\n\n        # Run or analyze simulation with low-quality generator L\n        tau_L = 0\n        if beta > beta_crit:\n            # System is trapped in the ground state. Check if equilibration is ever met.\n            u_star = -np.tanh(beta)\n            if np.abs(-1.0 - u_star) <= delta:\n                # Should not happen for given test cases, but for completeness\n                tau_L = W \n            else:\n                tau_L = S_max + 1\n        else:\n            # For small beta, must run the full simulation\n            rng_L = LCG(seed=s_L)\n            energy_hist_L = run_simulation(N, beta, S_max, rng_L)\n            tau_L = calculate_tau_eq(energy_hist_L, beta, W, delta, S_max)\n\n        ratio = tau_L / tau_H\n        results.append(f\"{ratio:.3f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2445950"}]}