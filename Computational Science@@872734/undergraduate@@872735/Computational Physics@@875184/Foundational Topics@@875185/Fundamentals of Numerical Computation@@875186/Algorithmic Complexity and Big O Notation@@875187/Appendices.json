{"hands_on_practices": [{"introduction": "Understanding algorithmic complexity often begins with analyzing the core routines that form the building blocks of larger programs. This first exercise focuses on the power method, a fundamental iterative algorithm used to find the dominant eigenvalue of a matrix. By breaking down the algorithm into its constituent parts—matrix-vector multiplication and vector normalization—you will practice identifying the computationally dominant operation and determining how the total cost scales with the size of the problem, $n$. [@problem_id:2156935]", "problem": "An engineer is analyzing the performance of an algorithm to find the dominant eigenvalue of a large, dense, real-valued square matrix. The algorithm used is the power method. The process is defined as follows:\n\nLet $A$ be a dense $n \\times n$ matrix and $v_0$ be an initial non-zero vector of size $n \\times 1$. The algorithm proceeds iteratively for $k$ steps. For each iteration $i$ (from $1$ to $k$), it performs two main operations:\n\n1.  **Matrix-Vector Product:** A new vector $w_i$ is computed by multiplying the matrix $A$ with the vector from the previous iteration, $v_{i-1}$. That is, $w_i = A v_{i-1}$.\n2.  **Vector Normalization:** The vector $w_i$ is normalized using the Euclidean norm (L2 norm) to produce the vector for the next iteration, $v_i$. That is, $v_i = \\frac{w_i}{\\|w_i\\|_2}$, where $\\|w_i\\|_2 = \\sqrt{\\sum_{j=1}^{n} (w_i)_j^2}$.\n\nWhat is the total computational complexity of performing $k$ iterations of this algorithm, expressed using Big O notation?\n\nA) $O(kn)$\nB) $O(kn \\log n)$\nC) $O(kn^2)$\nD) $O(kn^3)$\nE) $O(n^2)$", "solution": "We analyze the cost per iteration and then multiply by the number of iterations.\n\nAt iteration $i$, the matrix-vector product $w_{i} = A v_{i-1}$, with $A \\in \\mathbb{R}^{n \\times n}$ dense and $v_{i-1} \\in \\mathbb{R}^{n}$, requires forming $n$ dot products, each of length $n$. Each dot product uses $n$ multiplications and $n-1$ additions, so the total arithmetic operations scale as a constant multiple of $n^{2}$. Hence the matrix-vector product has complexity\n$$\nO(n^{2}).\n$$\n\nNext, compute the Euclidean norm $\\|w_{i}\\|_{2} = \\left( \\sum_{j=1}^{n} (w_{i})_{j}^{2} \\right)^{1/2}$. Forming the sum of squares requires $n$ multiplications and $n-1$ additions, which is\n$$\nO(n).\n$$\nTaking the square root contributes a constant-time operation with respect to $n$, so it is $O(1)$ and does not change the order. Normalizing $v_{i} = \\frac{w_{i}}{\\|w_{i}\\|_{2}}$ requires $n$ divisions, which is\n$$\nO(n).\n$$\n\nTherefore, the total cost per iteration is\n$$\nO(n^{2}) + O(n) + O(n) = O(n^{2}),\n$$\nsince $O(n^{2})$ dominates $O(n)$. Over $k$ iterations, the total cost sums to\n$$\n\\sum_{i=1}^{k} O(n^{2}) = O(k n^{2}).\n$$\n\nThus, the overall computational complexity is $O(k n^{2})$, corresponding to option C.", "answer": "$$\\boxed{C}$$", "id": "2156935"}, {"introduction": "We now move from a general numerical algorithm to a specific and crucial application in computational physics: the N-body simulation. This practice asks you to analyze the time and space complexity of a standard leapfrog integrator used to simulate the motion of $N$ interacting particles. This exercise is vital for understanding why direct, brute-force simulations become computationally prohibitive for large systems and motivates the need for more advanced, optimized algorithms. [@problem_id:2372962]", "problem": "A molecular dynamics code advances a system of $N$ identical particles of mass $m$ in three spatial dimensions using a leapfrog integrator with pairwise central forces. One full time step of size $\\Delta t$ is implemented as follows, where bold symbols denote vectors in $\\mathbb{R}^{3}$ and indices run over particles:\n\n- Half-kick: For $i = 1,\\dots,N$, update velocities by\n$$\\mathbf{v}_{i} \\leftarrow \\mathbf{v}_{i} + \\frac{\\Delta t}{2}\\,\\mathbf{a}_{i}.$$\n\n- Drift: For $i = 1,\\dots,N$, update positions by\n$$\\mathbf{x}_{i} \\leftarrow \\mathbf{x}_{i} + \\Delta t\\,\\mathbf{v}_{i}.$$\n\n- Recompute accelerations:\n  - Reset: For $i = 1,\\dots,N$, set\n  $$\\mathbf{a}_{i} \\leftarrow \\mathbf{0}.$$\n  - Pairwise accumulation: For $i = 1,\\dots,N-1$, and for $j = i+1,\\dots,N$, compute the relative displacement\n  $$\\mathbf{r}_{ij} = \\mathbf{x}_{i} - \\mathbf{x}_{j},$$\n  evaluate a central pairwise force of the form\n  $$\\mathbf{f}_{ij} = \\varphi\\!\\left(|\\mathbf{r}_{ij}|\\right)\\,\\mathbf{r}_{ij},$$\n  where $\\varphi$ is a fixed function independent of $N$, and accumulate\n  $$\\mathbf{a}_{i} \\leftarrow \\mathbf{a}_{i} + \\frac{\\mathbf{f}_{ij}}{m}, \\qquad \\mathbf{a}_{j} \\leftarrow \\mathbf{a}_{j} - \\frac{\\mathbf{f}_{ij}}{m}.$$\n\n- Half-kick: For $i = 1,\\dots,N$, update velocities by\n$$\\mathbf{v}_{i} \\leftarrow \\mathbf{v}_{i} + \\frac{\\Delta t}{2}\\,\\mathbf{a}_{i}.$$\n\nAssumptions:\n- The spatial dimension $d=3$ is fixed and does not scale with $N$.\n- Evaluating $\\varphi\\!\\left(|\\mathbf{r}_{ij}|\\right)$, forming $\\mathbf{f}_{ij}$, and applying the two acceleration updates for a single pair $(i,j)$ takes a constant number of arithmetic operations independent of $N$, and uses a constant amount of additional memory.\n- There are no neighbor lists, cutoffs, domain decompositions, or other data structures that alter the asymptotic pair count.\n- All arithmetic operations run in constant time, and loop overheads are linear in the number of iterations.\n- The integrator stores the arrays $\\{\\mathbf{x}_{i}\\}_{i=1}^{N}$, $\\{\\mathbf{v}_{i}\\}_{i=1}^{N}$, and $\\{\\mathbf{a}_{i}\\}_{i=1}^{N}$; do not count any other data beyond constant-size parameters and loop indices.\n\nUsing the definition of algorithmic time complexity and space complexity, determine, as functions of $N$ and in Big-O notation, the total time complexity per single time step and the total space complexity of the integrator state described above. Provide your final answer as a row matrix with two entries, the first being the time complexity and the second being the space complexity, each expressed as a single Big-O expression.", "solution": "The problem statement is first validated for correctness and solvability.\n\n**Step 1: Extraction of Givens**\n- System: $N$ identical particles of mass $m$ in $3$ spatial dimensions.\n- Algorithm: A single time step of a leapfrog integrator of size $\\Delta t$.\n  - Step 1: Half-kick velocity update: $\\mathbf{v}_{i} \\leftarrow \\mathbf{v}_{i} + \\frac{\\Delta t}{2}\\,\\mathbf{a}_{i}$ for $i = 1,\\dots,N$.\n  - Step 2: Drift position update: $\\mathbf{x}_{i} \\leftarrow \\mathbf{x}_{i} + \\Delta t\\,\\mathbf{v}_{i}$ for $i = 1,\\dots,N$.\n  - Step 3: Recompute accelerations $\\mathbf{a}_i$. This involves resetting all $\\mathbf{a}_i$ to $\\mathbf{0}$ and then performing a pairwise force accumulation over all unique pairs $(i,j)$ with $i<j$. The force is $\\mathbf{f}_{ij} = \\varphi(|\\mathbf{r}_{ij}|)\\,\\mathbf{r}_{ij}$, and updates are $\\mathbf{a}_{i} \\leftarrow \\mathbf{a}_{i} + \\frac{\\mathbf{f}_{ij}}{m}$ and $\\mathbf{a}_{j} \\leftarrow \\mathbf{a}_{j} - \\frac{\\mathbf{f}_{ij}}{m}$.\n  - Step 4: Second half-kick velocity update, identical to Step $1$.\n- Assumptions:\n  - Spatial dimension $d=3$ is a fixed constant.\n  - The computational work for a single pair force calculation and accumulation is $O(1)$ (constant time).\n  - No algorithmic optimizations like neighbor lists are used; all pairs are checked.\n  - Arithmetic operations are $O(1)$; loop overheads are linear in the number of iterations.\n- Data Storage for Space Complexity: The arrays for position $\\{\\mathbf{x}_{i}\\}_{i=1}^{N}$, velocity $\\{\\mathbf{v}_{i}\\}_{i=1}^{N}$, and acceleration $\\{\\mathbf{a}_{i}\\}_{i=1}^{N}$.\n\n**Step 2: Validation**\nThe problem describes a standard brute-force N-body simulation using the Velocity Verlet algorithm, a common variant of the leapfrog integrator. The scenario is scientifically grounded in classical mechanics and computational physics. The problem is well-posed, providing a clear algorithm and sufficient assumptions to perform an unambiguous complexity analysis. All terms are defined, and the premises are consistent. There are no elements of pseudoscience, subjectivity, or logical contradiction.\n\n**Step 3: Verdict**\nThe problem is deemed valid. A solution will be constructed.\n\n**Analysis of Time Complexity**\n\nThe total time complexity for one full time step is the sum of the complexities of its constituent parts. We analyze each part as a function of the number of particles, $N$.\n\n1.  **First Half-kick**: This step involves a loop that iterates from $i=1$ to $N$. Inside the loop, the velocity vector $\\mathbf{v}_{i}$ is updated. Since the spatial dimension is fixed at $3$, this vector operation involves a constant number of floating-point operations (one scalar-vector multiplication and one vector addition). Therefore, the work inside the loop is $O(1)$. The total time complexity for this step is the number of iterations multiplied by the work per iteration, which is $N \\times O(1) = O(N)$.\n\n2.  **Drift**: This step is structurally identical to the first. A loop runs from $i=1$ to $N$, and inside, a position vector $\\mathbf{x}_{i}$ is updated. This is also a constant-time operation for a fixed-dimension vector. The total time complexity is thus $N \\times O(1) = O(N)$.\n\n3.  **Recompute Accelerations**: This part consists of two sub-steps.\n    -   **Reset**: The accelerations for all $N$ particles are set to the zero vector, $\\mathbf{a}_{i} \\leftarrow \\mathbf{0}$. This is done in a loop from $i=1$ to $N$. The operation is constant time for each particle. The complexity of this sub-step is $O(N)$.\n    -   **Pairwise Accumulation**: This is the computationally dominant part. The algorithm specifies a double loop: `for i = 1,...,N-1` and `for j = i+1,...,N`. This structure iterates over all unique pairs of particles $(i,j)$. The total number of such pairs is given by the sum:\n    $$ \\sum_{i=1}^{N-1} \\sum_{j=i+1}^{N} 1 = \\sum_{i=1}^{N-1} (N - i) = (N-1) + (N-2) + \\dots + 1 = \\frac{(N-1)N}{2} $$\n    The number of pairs is $\\frac{1}{2}N^2 - \\frac{1}{2}N$. For each pair, the algorithm computes the relative displacement $\\mathbf{r}_{ij}$, evaluates the force $\\mathbf{f}_{ij}$, and updates two acceleration vectors, $\\mathbf{a}_i$ and $\\mathbf{a}_j$. According to the problem's assumptions, all these operations for a single pair take a constant amount of time, $O(1)$. Therefore, the total time complexity for this sub-step is the number of pairs multiplied by the constant work per pair: $(\\frac{1}{2}N^2 - \\frac{1}{2}N) \\times O(1) = O(N^2)$.\n    The total complexity for recomputing accelerations is the sum of its sub-steps: $O(N) + O(N^2) = O(N^2)$.\n\n4.  **Second Half-kick**: This step is identical to the first half-kick, involving a loop over $N$ particles with $O(1)$ work inside. Its complexity is $O(N)$.\n\n**Total Time Complexity**: The total time complexity per time step, $T(N)$, is the sum of the complexities of all four steps:\n$$ T(N) = O(N) + O(N) + O(N^2) + O(N) $$\nIn Big-O notation, we retain only the highest-order term. Thus, the total time complexity is $O(N^2)$.\n\n**Analysis of Space Complexity**\n\nThe space complexity is determined by the amount of memory required to store the state of the system, as specified in the problem.\n\n-   **Position data**: The array $\\{\\mathbf{x}_{i}\\}_{i=1}^{N}$ stores the positions of $N$ particles. Each position $\\mathbf{x}_i$ is a vector in $\\mathbb{R}^3$, requiring storage for $3$ numbers (e.g., doubles). The memory required for one particle's position is constant. Thus, the total memory for all positions is proportional to $N$, which is $O(N)$.\n\n-   **Velocity data**: Similarly, the array $\\{\\mathbf{v}_{i}\\}_{i=1}^{N}$ stores the velocities of $N$ particles. Each velocity $\\mathbf{v}_i$ is also a $3$-dimensional vector, so the total storage required is $O(N)$.\n\n-   **Acceleration data**: The array $\\{\\mathbf{a}_{i}\\}_{i=1}^{N}$ stores the accelerations of $N$ particles. Each acceleration $\\mathbf{a}_i$ is a $3$-dimensional vector, so the storage required is also $O(N)$.\n\n**Total Space Complexity**: The total space complexity, $S(N)$, is the sum of the memory requirements for these three arrays. The problem specifies to not count other data like constant-size parameters.\n$$ S(N) = O(N) + O(N) + O(N) = O(N) $$\nThus, the total space complexity of the integrator state is $O(N)$.\n\nIn summary, the time complexity is dominated by the pairwise force calculation, scaling quadratically with the number of particles, while the space complexity scales linearly as we must store state information for each particle.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nO(N^2) & O(N)\n\\end{pmatrix}\n}\n$$", "id": "2372962"}, {"introduction": "Our final practice explores a more subtle aspect of computational complexity that arises in solving time-dependent partial differential equations, such as the heat equation. The challenge here is to determine the total computational cost not just by analyzing the operations within a single time step, but by also considering how the number of required time steps is constrained by the numerical stability of the explicit method. This problem demonstrates the critical interplay between spatial resolution, temporal resolution, and algorithmic stability in determining the overall feasibility of a simulation. [@problem_id:2373011]", "problem": "Consider the explicit finite-difference time integration of the two-dimensional ($2$-dimensional) heat equation on a square domain $[0,L]\\times[0,L]$ up to a fixed final time $T$. The domain is discretized on a uniform Cartesian grid with $M$ interior points along each spatial direction, so that the mesh spacing is $\\Delta x = L/(M+1)$. Let $N = M^{2}$ denote the total number of interior unknowns. Assume that in each time step the algorithm updates all interior grid points, and that each grid point update requires a constant number $c_{\\mathrm{op}}$ of floating-point operations (FLOP), independent of $M$. The explicit scheme uses a time step constrained by stability to be $\\Delta t = \\kappa (\\Delta x)^{2}$, where $\\kappa>0$ is a constant that does not depend on $M$, $N$, $L$, or $T$.\n\nUsing only these assumptions, determine the asymptotic total number of FLOP required to reach time $T$ as $M\\to\\infty$, and express your final result as a single Big-$\\mathcal{O}$ expression in terms of $N$ only. Provide the final answer as a single analytic expression with no units.", "solution": "The problem statement requires the determination of the asymptotic total computational cost, measured in floating-point operations (FLOP), for integrating the $2$-dimensional heat equation up to a fixed time $T$. The analysis must be based on the provided assumptions for an explicit finite-difference scheme.\n\nFirst, let us formalize the total number of FLOP, which we shall denote by $F_{\\text{total}}$. This total cost is the product of the computational cost per time step, $F_{\\text{step}}$, and the total number of time steps, $K_{\\text{steps}}$, required to reach the final time $T$.\n$$F_{\\text{total}} = F_{\\text{step}} \\times K_{\\text{steps}}$$\n\nThe problem states that at each time step, the algorithm updates all interior grid points. The total number of interior grid points is given as $N$. The cost to update a single grid point is a constant, $c_{\\text{op}}$, which does not depend on the mesh size. Therefore, the cost per time step is directly proportional to the number of points being updated:\n$$F_{\\text{step}} = c_{\\text{op}} N$$\nThis implies that the cost per step is of order $\\mathcal{O}(N)$.\n\nNext, we must determine the number of time steps, $K_{\\text{steps}}$. The simulation runs for a total duration of $T$, with each step advancing time by $\\Delta t$. Thus,\n$$K_{\\text{steps}} = \\frac{T}{\\Delta t}$$\n\nThe crucial part of the analysis lies in understanding the scaling of the time step $\\Delta t$. The problem specifies that for this explicit scheme, the time step is constrained by a stability condition:\n$$\\Delta t = \\kappa (\\Delta x)^2$$\nwhere $\\kappa > 0$ is a constant independent of the discretization parameters, and $\\Delta x$ is the mesh spacing.\n\nThe domain is a square of side length $L$, discretized with $M$ interior points along each dimension. This gives a mesh spacing of:\n$$\\Delta x = \\frac{L}{M+1}$$\nThe total number of interior unknowns, $N$, is related to $M$ by $N = M^2$. From this, we can express $M$ in terms of $N$ as $M = \\sqrt{N}$ for $M \\ge 0$. Substituting this into the expression for $\\Delta x$:\n$$\\Delta x = \\frac{L}{\\sqrt{N}+1}$$\n\nNow, we can express the time step $\\Delta t$ as a function of $N$:\n$$\\Delta t = \\kappa \\left( \\frac{L}{\\sqrt{N}+1} \\right)^2 = \\frac{\\kappa L^2}{(\\sqrt{N}+1)^2}$$\n\nWith this expression for $\\Delta t$, the total number of time steps becomes:\n$$K_{\\text{steps}} = \\frac{T}{\\Delta t} = \\frac{T (\\sqrt{N}+1)^2}{\\kappa L^2}$$\n\nWe are interested in the asymptotic behavior as $M \\to \\infty$, which corresponds to $N \\to \\infty$. For large $N$, the term $(\\sqrt{N}+1)^2$ behaves as $N$. More formally:\n$$(\\sqrt{N}+1)^2 = N + 2\\sqrt{N} + 1$$\nAs $N \\to \\infty$, the dominant term is $N$. Therefore, $K_{\\text{steps}}$ is asymptotically proportional to $N$:\n$$K_{\\text{steps}} = \\frac{T}{\\kappa L^2} (N + 2\\sqrt{N} + 1) = \\mathcal{O}(N)$$\n\nFinally, we can combine our results for $F_{\\text{step}}$ and $K_{\\text{steps}}$ to find the total computational cost, $F_{\\text{total}}$:\n$$F_{\\text{total}} = F_{\\text{step}} \\times K_{\\text{steps}} = (c_{\\text{op}} N) \\times \\left( \\frac{T (\\sqrt{N}+1)^2}{\\kappa L^2} \\right)$$\nLet us collect all constants that are independent of $N$ into a single term, $C = \\frac{c_{\\text{op}} T}{\\kappa L^2}$.\n$$F_{\\text{total}} = C \\cdot N \\cdot (\\sqrt{N}+1)^2 = C \\cdot N (N + 2\\sqrt{N} + 1) = C (N^2 + 2N^{3/2} + N)$$\nFor the purpose of Big-$\\mathcal{O}$ notation, we identify the highest power of $N$ in the expression for $F_{\\text{total}}$ as $N \\to \\infty$. The dominant term in the polynomial $N^2 + 2N^{3/2} + N$ is $N^2$.\nTherefore, the asymptotic total number of FLOP is given by:\n$$F_{\\text{total}} = \\mathcal{O}(N^2)$$\nThis result shows that the computational complexity of the explicit method for the $2$-dimensional heat equation scales quadratically with the number of unknowns. This is a consequence of the severe time step restriction imposed by the stability criterion, which is characteristic of explicit methods for parabolic problems.", "answer": "$$\n\\boxed{\\mathcal{O}(N^{2})}\n$$", "id": "2373011"}]}