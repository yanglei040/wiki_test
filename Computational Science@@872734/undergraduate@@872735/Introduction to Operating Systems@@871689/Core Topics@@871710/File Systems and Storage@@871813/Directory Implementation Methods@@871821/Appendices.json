{"hands_on_practices": [{"introduction": "While asymptotic analysis gives us a high-level understanding of performance, real-world behavior is determined by concrete operational costs. This first practice exercise allows you to move from abstract theory to quantitative analysis by building a detailed performance model from the ground up [@problem_id:3634443]. You will quantify the substantial performance difference between a linear list and a hash table for a very common scenario in file systems: looking up a file that does not exist. This illustrates how data structure choice is critical for optimizing frequent operations.", "problem": "A directory is a mapping from filenames to metadata records. Consider two directory implementation methods used by an operating system: a linear list and a hash table with separate chaining. For failed metadata queries such as the Portable Operating System Interface (POSIX) system call `stat`, the cost arises entirely from searching the directory data structure in memory; assume all other overheads are identical across implementations and therefore cancel when comparing the two methods.\n\nUse the following fundamental base:\n- In a linear list implementation, to conclude a filename is absent, the system must compare the queried name against each of the $n$ directory entries, incurring a per-entry comparison cost and loop-step overhead. There is also a final end-of-list check cost.\n- In a hash table with separate chaining and $B$ buckets under the uniform hashing assumption, the expected number of elements examined in an unsuccessful search equals the load factor $\\alpha = \\frac{n}{B}$. The cost includes computing the hash over the filename, accessing the relevant bucket, traversing the expected number of chain elements (each incurring a comparison and a link-traversal overhead), and performing a chain termination check.\n\nSuppose a directory contains $n = 8192$ entries. Assume a workload of $M = 5 \\times 10^{4}$ unsuccessful `stat` calls on filenames that do not exist in the directory; names are independent of the stored entries and uniformly distributed with respect to hashing. The average filename length examined by the hash function is $L = 24$ characters. The following microarchitectural costs apply, all measured in microseconds:\n- Per-entry average string comparison time in the directory: $t_{\\mathrm{cmp}} = 0.04$.\n- Per-iteration loop-step overhead in the linear list: $t_{\\ell} = 0.01$.\n- End-of-list check in the linear list: $t_{\\mathrm{end}} = 0.01$.\n- Number of hash buckets: $B = 4096$, so the load factor is $\\alpha = \\frac{n}{B}$.\n- Per-character hash computation time: $t_{\\mathrm{char}} = 0.01$.\n- Bucket access overhead in the hash table: $t_{\\mathrm{bucket}} = 0.02$.\n- Per-chain-element link-traversal overhead in the hash table: $t_{\\mathrm{link}} = 0.005$.\n- Chain termination check in the hash table: $t_{\\mathrm{chain}} = 0.01$.\n\nDerive from first principles an expression for the time to determine absence in each implementation and compute the average time saved per failed lookup when using the hash table instead of the linear list over the $M$ unsuccessful operations. Express your final answer in microseconds and round your answer to four significant figures.", "solution": "The objective is to compute the average time saved per unsuccessful lookup when using a hash table instead of a linear list. This quantity, denoted as $\\Delta T$, is the difference between the time taken for an unsuccessful search in a linear list, $T_{\\mathrm{linear}}$, and the time taken for an unsuccessful search in a hash table, $T_{\\mathrm{hash}}$.\n$$ \\Delta T = T_{\\mathrm{linear}} - T_{\\mathrm{hash}} $$\nWe will derive expressions for $T_{\\mathrm{linear}}$ and $T_{\\mathrm{hash}}$ from first principles based on the provided cost model.\n\nFirst, let us analyze the cost of an unsuccessful search in a linear list implementation. To conclude that a filename is absent, the system must search the entire list. For a directory with $n$ entries, this involves iterating through all $n$ entries. For each entry, a string comparison is performed (cost $t_{\\mathrm{cmp}}$) and a loop-step overhead is incurred (cost $t_{\\ell}$). After iterating through all $n$ entries, a final end-of-list check is performed (cost $t_{\\mathrm{end}}$). The total time for one unsuccessful lookup is the sum of these costs:\n$$ T_{\\mathrm{linear}} = n \\cdot (t_{\\mathrm{cmp}} + t_{\\ell}) + t_{\\mathrm{end}} $$\n\nNext, we analyze the cost of an unsuccessful search in a hash table with separate chaining. The process involves several steps:\n1.  Compute the hash of the queried filename. The average filename length is $L$ characters, and the per-character hashing cost is $t_{\\mathrm{char}}$. The total hash computation cost is $L \\cdot t_{\\mathrm{char}}$.\n2.  Access the appropriate bucket in the hash table, which has an overhead of $t_{\\mathrm{bucket}}$.\n3.  Traverse the linked list (chain) associated with that bucket. Under the uniform hashing assumption, the expected length of a chain for an unsuccessful search is the load factor, $\\alpha = \\frac{n}{B}$, where $n$ is the number of entries and $B$ is the number of buckets. For each of the $\\alpha$ elements in the chain, a string comparison (cost $t_{\\mathrm{cmp}}$) and a link traversal (cost $t_{\\mathrm{link}}$) are performed. The total cost for traversing the chain is $\\alpha \\cdot (t_{\\mathrm{cmp}} + t_{\\mathrm{link}})$.\n4.  After traversing the expected number of elements, a final check for the end of the chain (e.g., a null pointer) confirms the absence of the filename. This has a cost of $t_{\\mathrm{chain}}$.\n\nThe total expected time for one unsuccessful lookup in the hash table is the sum of these costs:\n$$ T_{\\mathrm{hash}} = (L \\cdot t_{\\mathrm{char}}) + t_{\\mathrm{bucket}} + \\alpha \\cdot (t_{\\mathrm{cmp}} + t_{\\mathrm{link}}) + t_{\\mathrm{chain}} $$\nSubstituting the definition of $\\alpha$:\n$$ T_{\\mathrm{hash}} = L \\cdot t_{\\mathrm{char}} + t_{\\mathrm{bucket}} + \\frac{n}{B} \\cdot (t_{\\mathrm{cmp}} + t_{\\mathrm{link}}) + t_{\\mathrm{chain}} $$\n\nThe average time saved per lookup, $\\Delta T$, is therefore:\n$$ \\Delta T = \\left[ n \\cdot (t_{\\mathrm{cmp}} + t_{\\ell}) + t_{\\mathrm{end}} \\right] - \\left[ L \\cdot t_{\\mathrm{char}} + t_{\\mathrm{bucket}} + \\frac{n}{B} \\cdot (t_{\\mathrm{cmp}} + t_{\\mathrm{link}}) + t_{\\mathrm{chain}} \\right] $$\nThe total number of unsuccessful operations, $M = 5 \\times 10^{4}$, is extraneous information as the problem asks for the *average time saved per lookup*, not the total time saved over the entire workload.\n\nWe are given the following values, all in microseconds:\n-   $n = 8192$\n-   $t_{\\mathrm{cmp}} = 0.04$\n-   $t_{\\ell} = 0.01$\n-   $t_{\\mathrm{end}} = 0.01$\n-   $L = 24$\n-   $t_{\\mathrm{char}} = 0.01$\n-   $B = 4096$\n-   $t_{\\mathrm{bucket}} = 0.02$\n-   $t_{\\mathrm{link}} = 0.005$\n-   $t_{\\mathrm{chain}} = 0.01$\n\nFirst, we substitute these values into the expression for $T_{\\mathrm{linear}}$:\n$$ T_{\\mathrm{linear}} = 8192 \\cdot (0.04 + 0.01) + 0.01 $$\n$$ T_{\\mathrm{linear}} = 8192 \\cdot (0.05) + 0.01 $$\n$$ T_{\\mathrm{linear}} = 409.6 + 0.01 = 409.61 \\text{ microseconds} $$\n\nNext, we calculate the load factor $\\alpha$:\n$$ \\alpha = \\frac{n}{B} = \\frac{8192}{4096} = 2 $$\nNow we substitute the values into the expression for $T_{\\mathrm{hash}}$:\n$$ T_{\\mathrm{hash}} = (24 \\cdot 0.01) + 0.02 + 2 \\cdot (0.04 + 0.005) + 0.01 $$\n$$ T_{\\mathrm{hash}} = 0.24 + 0.02 + 2 \\cdot (0.045) + 0.01 $$\n$$ T_{\\mathrm{hash}} = 0.24 + 0.02 + 0.09 + 0.01 $$\n$$ T_{\\mathrm{hash}} = 0.36 \\text{ microseconds} $$\n\nFinally, we compute the average time saved per lookup, $\\Delta T$:\n$$ \\Delta T = T_{\\mathrm{linear}} - T_{\\mathrm{hash}} = 409.61 - 0.36 = 409.25 \\text{ microseconds} $$\n\nThe problem requires the final answer to be rounded to four significant figures. The number $409.25$ has five significant figures. The first four are $4$, $0$, $9$, and $2$. The fifth digit is $5$, so we round up the fourth digit.\n$$ \\Delta T \\approx 409.3 \\text{ microseconds} $$", "answer": "$$\\boxed{409.3}$$", "id": "3634443"}, {"introduction": "The performance of a directory is not solely defined by lookup speed; its entire lifecycle, including deletions, must be considered. This exercise explores the practical trade-offs that arise from frequent deletions, comparing the use of \"tombstones\" in a hash table with periodic \"compaction\" in a linear list [@problem_id:3634353]. By modeling memory fragmentation and amortized maintenance costs, you will learn to evaluate data structures using a composite metric that mirrors the multi-objective decision-making process in real-world systems engineering.", "problem": "A directory stores file entries and supports lookups, insertions, and deletions. Consider two implementation strategies under frequent deletions, with the following assumptions and policies:\n\n- The directory size is fixed at $m = 8192$ slots. The steady-state number of live entries is $n = 4096$.\n- Each operation is independently a deletion with probability $p_{d} = 0.25$; other operations do not affect the fragmentation metrics considered here.\n- Strategy H (open-addressing hash table with linear probing and conservative deletion policy): a deletion marks the slot with a tombstone, and insertions do not reuse tombstones. A full cleanup (rehash) is triggered when the tombstone count reaches a threshold fraction $\\tau = 0.1$ of the table, at which point the table is rebuilt and tombstones are eliminated. The rebuild cost is proportional to the table size, with cost coefficient $c_{h} = 2$ per slot scanned. The average fragmentation at any time is defined as the long-run expected fraction of slots that are tombstones.\n- Strategy L (linear list stored in an array): a deletion marks a hole, and periodic compaction removes all holes after $D = 2048$ deletes since the last compaction. The compaction cost is proportional to the live entries, with cost coefficient $c_{l} = 1$ per live entry moved. The average fragmentation at any time is defined as the long-run expected fraction of slots that are holes.\n- To combine fragmentation and maintenance effects into a single per-operation metric, define the weighted per-operation cost as\n$$\nJ \\;=\\; \\gamma \\cdot \\text{(average fragmentation fraction)} \\;+\\; \\text{(amortized maintenance cost per operation)},\n$$\nwhere $\\gamma = 150$ is a fixed weighting factor (in units of primitive operations per unit fragmentation) multiplying the average fragmentation fraction.\n\nUsing only the policies and parameters stated, derive a self-contained expression for $J_{H}$ under Strategy H and $J_{L}$ under Strategy L from first principles, and compute the signed difference\n$$\n\\Delta \\;=\\; J_{H} \\;-\\; J_{L}.\n$$\nExpress the final answer as a single real number. No rounding is required.", "solution": "The objective is to compute the weighted per-operation cost $J$ for each strategy and then find their difference, $\\Delta = J_{H} - J_{L}$. The cost function is defined as $J = \\gamma \\cdot \\bar{f} + A$, where $\\bar{f}$ is the average fragmentation fraction and $A$ is the amortized maintenance cost per operation.\n\n**Analysis of Strategy H (Hash Table)**\n\nFirst, we determine the amortized maintenance cost, $A_H$. The maintenance operation is a full rehash of the table.\n- A rehash is triggered when the number of tombstones, $T$, reaches the threshold $T_{max} = \\tau m$.\n- The cost of one rehash is $C_H = c_h m$.\n- A rehash cycle begins with $T=0$ tombstones and ends when $T=T_{max}$. Since each deletion creates one tombstone and insertions do not reuse them, a total of $T_{max} = \\tau m$ deletions must occur to trigger the rehash.\n- The probability of an operation being a deletion is $p_d$. The expected number of total operations required to accumulate $T_{max}$ deletions is $N_{ops, H} = \\frac{T_{max}}{p_d} = \\frac{\\tau m}{p_d}$.\n- The amortized cost per operation is the total cost of one rehash distributed over the number of operations in the cycle:\n$$ A_H = \\frac{C_H}{N_{ops, H}} = \\frac{c_h m}{\\frac{\\tau m}{p_d}} = \\frac{c_h p_d}{\\tau} $$\n\nNext, we find the average fragmentation fraction, $\\bar{f}_H$.\n- The number of tombstones $T$ grows linearly (on average) with the number of operations from $0$ to $T_{max} = \\tau m$ during one cycle.\n- The average number of tombstones over the cycle is the time-average of this linear growth, which is $\\bar{T} = \\frac{0 + T_{max}}{2} = \\frac{\\tau m}{2}$.\n- The average fragmentation fraction is the average number of tombstones divided by the total table size $m$:\n$$ \\bar{f}_H = \\frac{\\bar{T}}{m} = \\frac{\\frac{\\tau m}{2}}{m} = \\frac{\\tau}{2} $$\n\nNow, we can compute the weighted cost $J_H$:\n$$ J_H = \\gamma \\bar{f}_H + A_H = \\gamma \\frac{\\tau}{2} + \\frac{c_h p_d}{\\tau} $$\nSubstituting the given values: $\\gamma = 150$, $\\tau = 0.1$, $c_h = 2$, and $p_d = 0.25$.\n$$ J_H = 150 \\cdot \\frac{0.1}{2} + \\frac{2 \\cdot 0.25}{0.1} = 150 \\cdot 0.05 + \\frac{0.5}{0.1} = 7.5 + 5 = 12.5 $$\n\n**Analysis of Strategy L (Linear List)**\n\nFirst, we determine the amortized maintenance cost, $A_L$. The maintenance operation is compaction.\n- Compaction is triggered after $D$ deletions have occurred.\n- The cost of one compaction is proportional to the number of live entries, $C_L = c_l n$.\n- A compaction cycle corresponds to the accumulation of $D$ deletions.\n- The expected number of total operations required to accumulate $D$ deletions is $N_{ops, L} = \\frac{D}{p_d}$.\n- The amortized cost per operation is the total cost of one compaction distributed over the number of operations in the cycle:\n$$ A_L = \\frac{C_L}{N_{ops, L}} = \\frac{c_l n}{\\frac{D}{p_d}} = \\frac{c_l n p_d}{D} $$\n\nNext, we find the average fragmentation fraction, $\\bar{f}_L$.\n- The fragmentation is due to holes left by deletions. The number of holes, $H$, grows linearly from $0$ to $D$ during one cycle.\n- The average number of holes over the cycle is $\\bar{H} = \\frac{0 + D}{2} = \\frac{D}{2}$.\n- The average fragmentation fraction is the average number of holes divided by the total directory size $m$:\n$$ \\bar{f}_L = \\frac{\\bar{H}}{m} = \\frac{D}{2m} $$\n\nNow, we can compute the weighted cost $J_L$:\n$$ J_L = \\gamma \\bar{f}_L + A_L = \\gamma \\frac{D}{2m} + \\frac{c_l n p_d}{D} $$\nSubstituting the given values: $\\gamma = 150$, $D = 2048$, $m = 8192$, $c_l = 1$, $n = 4096$, and $p_d = 0.25$.\n$$ J_L = 150 \\cdot \\frac{2048}{2 \\cdot 8192} + \\frac{1 \\cdot 4096 \\cdot 0.25}{2048} $$\n$$ J_L = 150 \\cdot \\frac{2048}{16384} + \\frac{1024}{2048} $$\nNoting that $2048/16384 = 1/8$ and $1024/2048=1/2$:\n$$ J_L = 150 \\cdot \\frac{1}{8} + \\frac{1}{2} = 18.75 + 0.5 = 19.25 $$\n\n**Final Calculation**\n\nThe final step is to compute the signed difference $\\Delta = J_H - J_L$.\n$$ \\Delta = 12.5 - 19.25 = -6.75 $$", "answer": "$$\n\\boxed{-6.75}\n$$", "id": "3634353"}, {"introduction": "Moving from a single-threaded context to the concurrent environment of modern operating systems introduces new and complex challenges, where correctness is paramount. This final practice shifts the focus from raw performance to ensuring data integrity in the face of simultaneous access by multiple threads [@problem_id:3634439]. You will tackle the subtle but dangerous Time-of-Check-to-Time-of-Use (TOCTOU) race condition by designing a mitigation strategy using sequence counters, a sophisticated lock-free technique. This conceptual challenge highlights how the choice of data structure profoundly influences the design of effective and efficient concurrency control mechanisms.", "problem": "An operating system directory can be implemented either as a linear list of directory entries or as a hash table with $B$ buckets. Consider concurrent threads performing lookups and modifications (insertions, deletions, renames). A correctness risk in concurrent lookup is Time-of-Check-to-Time-of-Use (TOCTOU): a reader checks a property of a directory entry and then uses the entry, but the directory may have changed in between, invalidating the checked property. A sequence counter is a shared integer that is incremented by a writer at the start and end of a modification; when incremented it transitions from an even value to an odd value and back to an even value. A reader observes the counter before reading, does its read, and rechecks the counter after reading; if the counter changed or is odd at either observation, the reader retries. Writers do not wait for readers and increment the appropriate sequence counter twice per modification. Assume modifications are applied atomically to directory data structures such that the sequence counter increments bracket the logical effect.\n\nSuppose you must design a TOCTOU mitigation strategy using sequence counters for both implementations:\n\n- Linear list: A reader performs a sequential scan, following $next$ pointers between nodes. Under contention, a long scan may interleave with multiple modifications. You may choose to revalidate at different granularities (per full scan, per step).\n- Hash table: A reader computes a hash and examines the corresponding bucket. You may choose global or bucket-level versioning. Assume that bucket membership does not change without a structural bucket operation (e.g., rehashing or a per-bucket chain link update).\n\nAssume the following model for performance under contention to ground your reasoning: modifications to bucket $i$ arrive as a Poisson process with rate $\\lambda_i$ events per unit time, and modifications anywhere in the directory arrive with rate $\\lambda = \\sum_{i=1}^{B} \\lambda_i$. A reader’s time scanning a single bucket is $T_{\\text{bucket}}$, and the time to traverse one node in the linear list is $T_{\\text{step}}$. Assume read-mostly workloads with $\\lambda_i \\ll \\lambda$ for most $i$, and that writers must not be blocked by readers.\n\nWhich option identifies a correct mitigation design using sequence counters that eliminates TOCTOU for both implementations and minimizes unnecessary reader retries under the stated workload assumptions?\n\nA. For the hash table, use per-bucket sequence counters: a reader sampling bucket $j$ reads the bucket’s counter $c_j$ before traversal and checks $c_j$ again after traversal; the reader accepts the result only if both observations are equal and even. Writers that modify bucket $j$ increment $c_j$ once at the start and once at the end of the change. For the linear list, revalidate against a single directory-wide sequence counter $s$ at each step: read $s$, read the current node and move to $next$, then recheck $s$; if $s$ changed or is odd at either observation, restart from the head. Writers increment $s$ at the start and end of any structural list change. This design detects any concurrent change affecting the reader’s path while minimizing retries by localizing validation for hash buckets.\n\nB. Use one directory-wide sequence counter $s$ for all structures: readers of both the hash table and linear list sample $s$ once before any traversal and once after finishing; if $s$ changed or is odd at either observation, the reader restarts its entire traversal. Writers increment $s$ once at the start and once at the end of any modification.\n\nC. For both implementations, add per-entry sequence counters that writers increment when changing that specific entry, and have readers verify counters only on the entries they touch; do not validate at the bucket or list level. Writers do not increment any bucket-level or global counter.\n\nD. For the hash table, use per-bucket counters, but have readers validate only after traversal (post-read), accepting as long as the final counter observation is even; for the linear list, validate only once per full scan with a global counter sampled before and after the scan, ignoring intermediate steps. Writers increment counters once at the end of modifications.", "solution": "The problem requires designing a Time-of-Check-to-Time-of-Use (TOCTOU) mitigation strategy using sequence counters for two different directory implementations: a linear list and a hash table. The design must be correct (eliminate TOCTOU) and efficient (minimize unnecessary reader retries) under a read-mostly workload where modifications are distributed across the structure.\n\nFirst, let us re-state the mechanics of a sequence counter as described in the problem. A writer increments a shared counter before a modification (making it odd) and after the modification (making it even again). A reader records the counter value before reading data. After reading, it checks the counter again. If the counter has changed, or if it was odd at the start, the data is potentially inconsistent, and the reader must retry its operation. This ensures that the reader's operation does not overlap with a writer's critical section.\n\nWe will now analyze the optimal strategy for each data structure.\n\n**1. Hash Table Analysis**\n\nA hash table consists of $B$ buckets. A lookup operation involves hashing a key to identify a specific bucket, say bucket $j$, and then searching only within that bucket. The key insight is that a modification to an entry in bucket $k$ (where $k \\ne j$) has no effect on the data or structure of bucket $j$. The operations on different buckets are independent, assuming no global table-wide operations like a resize/rehash.\n\nThe problem presents two choices for versioning: global or per-bucket.\n\n-   **Global Sequence Counter:** A single counter $s$ for the entire hash table. Any modification, regardless of which bucket it affects, increments $s$. A reader accessing bucket $j$ would read $s$, traverse the bucket (taking time $T_{\\text{bucket}}$), and then re-read $s$. The total rate of modifications across the entire table is $\\lambda = \\sum_{i=1}^{B} \\lambda_i$. A reader's operation will be invalidated if any modification occurs anywhere in the table during its read. The probability of a retry is proportional to $\\lambda T_{\\text{bucket}}$.\n\n-   **Per-Bucket Sequence Counters:** Each bucket $j$ has its own counter $c_j$. A writer modifying an entry in bucket $j$ only increments $c_j$. A reader accessing bucket $j$ would read $c_j$, traverse the bucket, and re-read $c_j$. The rate of modifications relevant to this reader is only $\\lambda_j$. The probability of a retry is proportional to $\\lambda_j T_{\\text{bucket}}$.\n\nThe problem states that the workload is such that $\\lambda_i \\ll \\lambda$ for most $i$. This means that the modification rate for a single bucket is much smaller than the total modification rate for the entire directory. Therefore, $\\lambda_j T_{\\text{bucket}} \\ll \\lambda T_{\\text{bucket}}$. Using per-bucket counters significantly reduces the number of unnecessary retries, as a reader is not affected by concurrent, unrelated modifications in other buckets. This directly addresses the goal of minimizing retries.\n\nThus, for the hash table, the optimal strategy is to use **per-bucket sequence counters**.\n\n**2. Linear List Analysis**\n\nA linear list is a single, monolithic data structure. A reader must traverse it sequentially from the head by following `next` pointers. A structural modification (insertion or deletion) at any point in the list can affect the validity of the rest of the list from the reader's perspective. For example, if a reader is at node $N_i$ and about to traverse to $N_{i+1}$, a concurrent writer could delete $N_{i+1}$. If the reader then uses its now-stale pointer to $N_{i+1}$, it results in a use-after-free error, which is a severe correctness violation far worse than stale data.\n\nThe problem presents two choices for validation granularity: per-full-scan or per-step.\n\n-   **Validate Per Full Scan:** A reader would read a single, directory-wide counter $s$ at the beginning of the scan and re-read it at the end. The time window for this check is the entire scan time, which can be long. This approach is fundamentally flawed and unsafe. It does not prevent the use-after-free scenario described above. A modification could occur mid-scan, breaking the list traversal, and the check at the end would be too late to prevent the error, even though it would correctly trigger a retry. Therefore, this strategy fails the primary requirement of correctness.\n\n-   **Validate Per Step:** A reader must re-validate the integrity of the list at each step of the traversal. A single, directory-wide counter $s$ must be used, because any modification anywhere in the list can invalidate the traversal path. The correct reader algorithm is:\n    1.  Start at the head of the list.\n    2.  In a loop:\n        a. Read $s$. Ensure it is even.\n        b. Read the current node's data and its `next` pointer.\n        c. Re-read $s$.\n        d. If the new value of $s$ is different from the old one, or if the initial value was odd, a concurrent modification has occurred. The traversal is potentially invalid, so the reader must abort and restart the entire scan from the head.\n        e. Otherwise, the step was safe. Move to the `next` node and continue.\n\nThis per-step validation ensures that the `next` pointer used to advance is always valid at the moment of traversal. The validation window for each step is very short ($T_{\\text{step}}$), making the probability of a conflict per step low. While a long scan still has a significant cumulative probability of being interrupted, this fine-grained checking is the only way to guarantee correctness and prevent catastrophic traversal errors.\n\nThus, for the linear list, the correct and necessary strategy is to use a **single, directory-wide sequence counter validated at each step**.\n\n**Conclusion of Derivation**\n\nThe optimal design that is both correct and minimizes retries is:\n-   **Hash Table:** Use per-bucket sequence counters, validated before and after traversing a bucket.\n-   **Linear List:** Use a single, directory-wide sequence counter, validated at each step of the traversal.\n\nWe will now evaluate the given options against this derived solution.\n\n**Option-by-Option Analysis**\n\n**A. For the hash table, use per-bucket sequence counters... For the linear list, revalidate against a single directory-wide sequence counter s at each step... This design detects any concurrent change affecting the reader’s path while minimizing retries by localizing validation for hash buckets.**\n\n-   **Hash Table Strategy:** This matches our derived optimal strategy (per-bucket counters) which minimizes unnecessary retries.\n-   **Linear List Strategy:** This matches our derived correct strategy (global counter, per-step validation) which is necessary to prevent traversal errors like use-after-free.\n-   **Rationale:** The provided rationale accurately summarizes why this combination is optimal: it localizes validation for the hash table to reduce spurious retries and ensures traversal safety for the linear list.\n-   **Verdict:** **Correct**.\n\n**B. Use one directory-wide sequence counter s for all structures: readers of both the hash table and linear list sample s once before any traversal and once after finishing...**\n\n-   **Hash Table Strategy:** This forces readers of one bucket to retry due to unrelated modifications in other buckets. This is suboptimal and violates the goal of minimizing unnecessary retries.\n-   **Linear List Strategy:** As analyzed, validating only once per full scan is unsafe. It does not prevent a reader from following a stale pointer from a deleted node mid-traversal.\n-   **Verdict:** **Incorrect**. This solution is suboptimal for the hash table and, more critically, incorrect/unsafe for the linear list.\n\n**C. For both implementations, add per-entry sequence counters that writers increment when changing that specific entry, and have readers verify counters only on the entries they touch...**\n\n-   **Analysis:** This strategy only protects against changes to the *data within an entry*. It offers no protection against *structural* changes to the directory, such as the insertion or deletion of an entry. For a linear list, a reader would not know if the `next` pointer it is about to follow is stale. For a hash table, a reader would not know if the entry it is examining has been unlinked from the bucket's chain. This approach fails to solve the core problem of ensuring a valid traversal path.\n-   **Verdict:** **Incorrect**.\n\n**D. For the hash table, use per-bucket counters, but have readers validate only after traversal (post-read)... for the linear list, validate only once per full scan... Writers increment counters once at the end of modifications.**\n\n-   **Analysis:** This option contains multiple fundamental errors regarding the sequence counter protocol.\n    1.  **Reader validation:** The protocol requires the reader to check the counter *before* and *after* the read. Checking only after a read is insufficient. A reader could begin while the counter is odd (writer is active), read inconsistent data, and see an even counter value at the end if the writer has finished. The read would be incorrectly accepted.\n    2.  **Writer increments:** The protocol requires the writer to increment the counter *at the start* (even $\\to$ odd) and *at the end* (odd $\\to$ even) of the modification. Incrementing only once at the end breaks the protocol; the crucial \"writer is active\" odd state is never signaled. This contradicts the problem's own definition of a sequence counter.\n    3.  **Linear list validation:** As established for option B, validating once per full scan is unsafe.\n-   **Verdict:** **Incorrect**. This option describes a broken and unsafe implementation of the sequence counter mechanism.", "answer": "$$\\boxed{A}$$", "id": "3634439"}]}