{"hands_on_practices": [{"introduction": "Correctly using a mutex lock seems simple: lock before the critical section, and unlock after. However, modern software is complex, and control flow can be unexpectedly altered by exceptions or early returns. This exercise explores a common and critical bug—a failure to release a mutex on an error path—and challenges you to identify robust programming patterns that guarantee resource cleanup, ensuring your program remains live and responsive even when errors occur. [@problem_id:3661749]", "problem": "A server program maintains a shared bounded queue protected by a mutex $M$ across $N$ worker threads $\\{T_1,\\dots,T_N\\}$. Each worker executes a critical section that performs the following conceptual steps: acquire $M$, manipulate the queue, and then release $M$. The manipulation stage invokes a helper function $f$ that may raise an exception event $E$ before the explicit release is reached. In a recent bug report, after $E$ occurs, other workers that attempt to acquire $M$ block indefinitely. You are asked to determine the root cause in terms of operating systems concurrency fundamentals, and to select pattern(s) that robustly eliminate the bug while preserving correct mutual exclusion.\n\nAssume the following foundational facts:\n- A mutex enforces mutual exclusion: at most $1$ thread holds $M$ at any time, so that the critical section’s state transitions appear atomic to other threads.\n- Progress requires that a thread holding $M$ eventually releases $M$; otherwise, other threads can block forever, violating liveness.\n- An exception alters control flow by unwinding the call stack, skipping subsequent statements in the current scope unless a language mechanism guarantees execution of cleanup code on scope exit.\n\nWhich of the following changes simultaneously satisfy both requirements: (i) guarantee that $M$ is released along all control-flow paths, including exceptions and early returns, and (ii) preserve mutual exclusion without any window where $M$ is released before the critical section is complete? Select all that apply.\n\nA. Create a scoped guard object immediately after successfully acquiring $M$ such that the guard’s destructor deterministically calls the release of $M$ on scope exit, and eliminate all manual releases. This is the Resource Acquisition Is Initialization (RAII) pattern.\n\nB. Surround the critical section with a try-catch construct that catches the specific exception type raised by $f$ and calls the release of $M$ only inside the catch handler, leaving regular return paths to continue using the existing manual release.\n\nC. Replace $M$ with a recursive (reentrant) mutex, allowing the same thread to acquire the lock multiple times, under the assumption that reentrancy prevents deadlocks caused by exceptions.\n\nD. Introduce a condition variable paired with $M$ and have threads signal on the condition variable from within the exception handler to notify other threads that they should proceed without blocking on $M$.\n\nE. Use a language feature that guarantees finalization on scope exit (for example, a finally block or a defer statement) to place the release of $M$ in that finalization construct, ensuring the release runs regardless of how control leaves the scope, including exceptions and early returns.", "solution": "The problem statement will first be validated for scientific soundness, self-consistency, and clarity.\n\n### Step 1: Extract Givens\n\nThe verbatim givens are as follows:\n- A server program with a shared bounded queue.\n- The queue is protected by a mutex, denoted as $M$.\n- There are $N$ worker threads, denoted as $\\{T_1,\\dots,T_N\\}$.\n- Each worker executes a critical section with a conceptual structure:\n    1.  Acquire $M$.\n    2.  Manipulate the queue.\n    3.  Release $M$.\n- The manipulation step involves a helper function $f$.\n- The function $f$ may raise an exception event $E$.\n- The exception $E$ occurs before the explicit release of $M$ is reached.\n- A bug is reported: after $E$ occurs, other workers attempting to acquire $M$ block indefinitely.\n- The task is to identify the root cause and select patterns that robustly fix the bug while preserving mutual exclusion.\n- A correct solution must satisfy two requirements:\n    (i) Guarantee that $M$ is released along all control-flow paths, including exceptions and early returns.\n    (ii) Preserve mutual exclusion without any window where $M$ is released before the critical section is complete.\n- Foundational Facts:\n    1.  A mutex enforces mutual exclusion, allowing at most $1$ thread to hold it at any time.\n    2.  Progress (liveness) requires a thread holding $M$ to eventually release it.\n    3.  An exception alters control flow by unwinding the call stack, skipping subsequent statements unless a language mechanism guarantees execution of cleanup code.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem statement is subjected to validation against the established criteria.\n\n- **Scientifically Grounded:** The problem is firmly rooted in the fundamental principles of concurrent programming and operating systems. The concepts of mutexes, critical sections, race conditions, deadlocks (a form of indefinite blocking), and exception safety are canonical topics in computer science. The described scenario is a classic and realistic programming error.\n- **Well-Posed:** The problem is well-posed. It describes a specific, reproducible bug (indefinite blocking), provides its direct cause (an unreleased mutex due to an exception), and asks for a solution in the form of programming patterns that satisfy two explicit and well-defined correctness criteria (guaranteed release and preservation of mutual exclusion).\n- **Objective:** The language is technical, precise, and free of ambiguity or subjectivity. The terms `mutex`, `critical section`, `exception`, `control flow`, and `mutual exclusion` have standard, formal definitions in the field.\n\nThe problem exhibits none of the invalidity flags:\n1.  **Scientific or Factual Unsoundness:** The premises are entirely sound and reflect real-world behavior in multithreaded systems.\n2.  **Non-Formalizable or Irrelevant:** The problem is formal and directly relevant to the topic of concurrency control.\n3.  **Incomplete or Contradictory Setup:** The information provided is sufficient and self-consistent. The cause-and-effect relationship between the exception and the indefinite blocking is clearly articulated.\n4.  **Unrealistic or Infeasible:** The scenario is not only realistic but is a frequent source of bugs in production software.\n5.  **Ill-Posed or Poorly Structured:** The problem is clearly structured and asks for a solution that can be uniquely evaluated against the given constraints.\n6.  **Pseudo-Profound, Trivial, or Tautological:** While a standard problem, it is not trivial. It tests a crucial understanding of the interaction between resource management and non-linear control flow, which is a core challenge in robust software design.\n7.  **Outside Scientific Verifiability:** The solutions are programming patterns that can be implemented, tested, and verified.\n\n### Step 3: Verdict and Action\n\nThe problem statement is **valid**. A solution will be derived.\n\n### Derivation of Solution\n\nThe root cause of the bug is a resource leak, specifically, the failure to release the mutex $M$. A thread acquires $M$, and during the execution of its critical section, an exception $E$ is thrown. Standard exception handling unwinds the call stack, causing control to jump to an exception handler or to terminate the thread. The code to release $M$, being located after the point where the exception was thrown, is never executed. Consequently, $M$ remains locked. Any other thread that subsequently attempts to acquire $M$ will be blocked, waiting for a release that will never happen. This violates the liveness property of the system.\n\nA robust solution must ensure that the release of $M$ is deterministically coupled with its acquisition, guaranteeing its execution regardless of how the critical section's scope is exited. This must be done without compromising the integrity of the critical section itself.\n\n### Evaluation of Options\n\nLet's evaluate each option against the two requirements: (i) guaranteed release and (ii) preserved mutual exclusion.\n\n**A. Create a scoped guard object immediately after successfully acquiring $M$ such that the guard’s destructor deterministically calls the release of $M$ on scope exit, and eliminate all manual releases. This is the Resource Acquisition Is Initialization (RAII) pattern.**\n\n- **Analysis:** This pattern automates resource management. A local (\"stack\") object is created immediately after the resource (the mutex $M$) is acquired. The language guarantees that the destructor of this local object is called when its scope is exited. This exit can be due to normal completion, an early `return` statement, or stack unwinding from an exception. By placing the `release(M)` call in the destructor, its execution is guaranteed.\n- **Requirement (i) - Guaranteed Release:** This is satisfied. The destructor is automatically invoked by the language runtime on all control-flow paths that exit the scope.\n- **Requirement (ii) - Preserved Mutual Exclusion:** This is satisfied. The guard object exists from the moment the lock is acquired until the critical section scope is exited. The lock is held for the entire duration of the critical section and is released precisely at the end.\n- **Verdict:** **Correct**.\n\n**B. Surround the critical section with a try-catch construct that catches the specific exception type raised by $f$ and calls the release of $M$ only inside the catch handler, leaving regular return paths to continue using the existing manual release.**\n\n- **Analysis:** This approach attempts to handle the exception path manually. The pseudo-code would look like: `acquire(M); try { ...; if (some_condition) return; ... } catch (E) { release(M); } release(M);`. The problem statement is explicit that this pattern relies on the existing manual release for the \"regular return path\". The critical flaw, as highlighted in the problem's requirements, is a failure to handle *all* control-flow paths. If the code within the `try` block contains an early `return` statement, control exits the function immediately. The `catch` block is not executed, and the final `release(M)` statement is skipped. The mutex is not released.\n- **Requirement (i) - Guaranteed Release:** This is **not** satisfied. The pattern is brittle and fails to handle early returns from within the `try` block.\n- **Requirement (ii) - Preserved Mutual Exclusion:** This is satisfied in the paths that are handled, but a failure to release is a more severe bug.\n- **Verdict:** **Incorrect**.\n\n**C. Replace $M$ with a recursive (reentrant) mutex, allowing the same thread to acquire the lock multiple times, under the assumption that reentrancy prevents deadlocks caused by exceptions.**\n\n- **Analysis:** A recursive mutex solves the problem of a thread deadlocking with itself, which occurs if a function that has acquired a non-recursive mutex calls another function that attempts to acquire the *same* mutex. It does not solve the problem of failing to release a mutex. If an exception prevents the release call(s), the recursive mutex will remain locked (with a lock count greater than $0$) by the exiting thread. Other threads will still block indefinitely. The premise that reentrancy prevents deadlocks *caused by exceptions* is false.\n- **Requirement (i) - Guaranteed Release:** This is **not** satisfied. The type of mutex is irrelevant to the problem of a release statement being skipped.\n- **Requirement (ii) - Preserved Mutual Exclusion:** This is satisfied, but it is irrelevant to solving the bug.\n- **Verdict:** **Incorrect**.\n\n**D. Introduce a condition variable paired with $M$ and have threads signal on the condition variable from within the exception handler to notify other threads that they should proceed without blocking on $M$.**\n\n- **Analysis:** This demonstrates a misunderstanding of condition variables. Condition variables are used for threads to wait for a specific condition to become true *while a mutex is released*. A thread waiting to acquire $M$ is blocked on the mutex primitive itself, not on a condition variable. Signaling a condition variable will wake up threads waiting *on that variable*, but it has no effect on threads blocked trying to acquire $M$. Furthermore, this does not release $M$, which is the core of the problem.\n- **Requirement (i) - Guaranteed Release:** This is **not** satisfied. It does not release the mutex.\n- **Requirement (ii) - Preserved Mutual Exclusion:** This is violated. The suggestion is to have other threads \"proceed without blocking on $M$,\" which would break mutual exclusion and lead to race conditions.\n- **Verdict:** **Incorrect**.\n\n**E. Use a language feature that guarantees finalization on scope exit (for example, a finally block or a defer statement) to place the release of $M$ in that finalization construct, ensuring the release runs regardless of how control leaves the scope, including exceptions and early returns.**\n\n- **Analysis:** This pattern is the procedural or block-structured equivalent of RAII (Option A). Languages like Java, C#, and Python provide `try...finally` blocks, and Go provides a `defer` statement. The `finally` block or deferred function is guaranteed to execute when control leaves the associated scope, regardless of the reason. The canonical pattern is `acquire(M); try { /* critical section */ } finally { release(M); }`.\n- **Requirement (i) - Guaranteed Release:** This is satisfied. The `finally` or `defer` construct is designed by a language specifically for this purpose.\n- **Requirement (ii) - Preserved Mutual Exclusion:** This is satisfied. The `try` block delineates the critical section. The lock is held for the duration of this block and released only upon its exit.\n- **Verdict:** **Correct**.", "answer": "$$\\boxed{AE}$$", "id": "3661749"}, {"introduction": "Even with perfectly crafted critical sections, the interaction between multiple threads and multiple locks can lead to a total system freeze known as deadlock. When a service hangs, how do you diagnose the problem? This practice places you in the role of a troubleshooter, providing you with a snapshot of a hung system—stack traces and lock ownership data—and asks you to apply fundamental deadlock theory to pinpoint the exact cycle of dependencies causing the failure. [@problem_id:3661769]", "problem": "A multithreaded service running on a Portable Operating System Interface (POSIX) compliant Operating System (OS) uses mutex locks to protect shared state across modules. Three mutexes, labeled $M_x$, $M_y$, and $M_z$, are created with default attributes. Four threads, labeled $T_1$, $T_2$, $T_3$, and $T_4$, execute worker functions that sometimes acquire more than one mutex. At wall-clock time $t = 17{:}23{:}54$, the service appears hung. You trigger a diagnostic capture that stops all threads and records their stack traces and an instrumented owner/waiter snapshot of each mutex. The capture yields the following:\n\n- Thread $T_1$ stack (top frames shown): \n  - $pthread\\_mutex\\_lock(M_y)$ blocking\n  - Below: $process\\_B$ called after holding $M_x$\n  - Instrumentation shows $T_1$ currently holds $M_x$ and is attempting to lock $M_y$\n\n- Thread $T_2$ stack (top frames shown):\n  - $pthread\\_mutex\\_lock(M_x)$ blocking\n  - Below: $process\\_A$ called after holding $M_y$\n  - Instrumentation shows $T_2$ currently holds $M_y$ and is attempting to lock $M_x$\n\n- Thread $T_3$ stack (top frames shown):\n  - $pthread\\_mutex\\_lock(M_z)$ blocking\n  - Below: $aux\\_work$ called without holding other mutexes\n  - Instrumentation shows $T_3$ is attempting to lock $M_z$\n\n- Thread $T_4$ stack (top frames shown):\n  - $do\\_maintenance$ running\n  - Instrumentation shows $T_4$ currently holds $M_z$ and is not attempting to lock any other mutex\n\n- Mutex owner/waiter snapshot (from instrumentation at the same instant):\n  - $M_x$: owner $T_1$; waiters $\\{T_2\\}$\n  - $M_y$: owner $T_2$; waiters $\\{T_1\\}$\n  - $M_z$: owner $T_4$; waiters $\\{T_3\\}$\n\nAssume standard mutex semantics: a call to $pthread\\_mutex\\_lock$ on a contended mutex transitions the calling thread into a blocked state and the mutex cannot be preempted or forcefully taken from its owner. A deadlock requires the four Coffman conditions: mutual exclusion, hold-and-wait, no preemption, and circular wait.\n\nUsing only these fundamental definitions and the captured data, you want to both diagnose the hang and choose the most robust, minimally invasive change to prevent recurrence. Which option correctly describes a principle-based debugging approach using the stack traces to identify who holds which mutex and who waits on which mutex, and then proposes a fix that breaks the underlying necessary condition for deadlock across all code paths?\n\nA. Construct a wait-for graph by mapping each blocked $pthread\\_mutex\\_lock$ frame to its target mutex and cross-referencing the owner from instrumentation: detect edges $T_1 \\rightarrow M_y \\rightarrow T_2$ and $T_2 \\rightarrow M_x \\rightarrow T_1$, which form a cycle, while $T_3 \\rightarrow M_z \\rightarrow T_4$ is not part of a cycle. Conclude $T_1$ and $T_2$ are deadlocked on $M_x$ and $M_y$ due to opposite lock acquisition orders in different paths. Break the circular wait system-wide by enforcing a strict global lock ordering $M_x \\rightarrow M_y \\rightarrow M_z$ in all modules, verified with assertions.\n\nB. Conclude $T_3$ and $T_4$ are deadlocked on $M_z$ because $T_3$ is blocked and $T_4$ holds $M_z$. Resolve by adding timeouts to all $pthread\\_mutex\\_lock$ calls, so blocked threads eventually abort their lock attempt and proceed.\n\nC. Diagnose starvation rather than deadlock: $T_1$ is blocked because $T_2$ has higher priority and keeps running. Fix by raising $T_1$’s scheduler priority above $T_2$ to ensure it can acquire $M_y$ sooner.\n\nD. Avoid cycles by inserting unlock-before-lock around $M_y$ in $process\\_B$: temporarily release $M_x$ whenever attempting to acquire $M_y$, then reacquire $M_x$ afterwards. This local change is sufficient to prevent deadlocks without a global policy.", "solution": "Begin with fundamental definitions. A mutex lock ensures mutual exclusion: at most one thread can own a mutex at any time. Under POSIX semantics, a call to $pthread\\_mutex\\_lock$ on a locked mutex blocks the caller until the mutex becomes available. The Coffman conditions state that a deadlock arises when four conditions simultaneously hold: mutual exclusion, hold-and-wait (each process holds at least one resource while waiting for others), no preemption (resources cannot be forcibly taken), and circular wait (there exists a cycle in the resource allocation graph such that each process waits for a resource held by the next process).\n\nFrom first principles, diagnosing deadlock involves constructing a wait-for/resource-allocation graph. Nodes can be threads ($T_i$) and mutexes ($M_j$). A directed edge $T_i \\rightarrow M_j$ indicates that thread $T_i$ is currently blocked waiting to acquire mutex $M_j$. A directed edge $M_j \\rightarrow T_i$ indicates that mutex $M_j$ is currently owned by thread $T_i$. A cycle alternating between threads and mutexes indicates circular wait, satisfying the fourth Coffman condition. If mutual exclusion, hold-and-wait, and no preemption also hold (which they do for standard mutex locks), then the system is in deadlock.\n\nUse the captured stack traces and instrumentation:\n\n- For $T_1$: Top frame shows $pthread\\_mutex\\_lock(M_y)$ blocking, and instrumentation states $T_1$ holds $M_x$. Therefore, add edges $T_1 \\rightarrow M_y$ and $M_x \\rightarrow T_1$.\n\n- For $T_2$: Top frame shows $pthread\\_mutex\\_lock(M_x)$ blocking, and instrumentation states $T_2$ holds $M_y$. Therefore, add edges $T_2 \\rightarrow M_x$ and $M_y \\rightarrow T_2$.\n\n- For $T_3$: Top frame shows $pthread\\_mutex\\_lock(M_z)$ blocking. Instrumentation does not show $T_3$ holding any other mutex, so add edge $T_3 \\rightarrow M_z$.\n\n- For $T_4$: Instrumentation shows $T_4$ holds $M_z$ and is not attempting to lock anything else, so add edge $M_z \\rightarrow T_4$.\n\nNow analyze the graph:\n\n- The subgraph involving $T_1$, $T_2$, $M_x$, and $M_y$ contains $T_1 \\rightarrow M_y \\rightarrow T_2 \\rightarrow M_x \\rightarrow T_1$. This is a cycle. Mutual exclusion holds because $M_x$ and $M_y$ are mutexes. Hold-and-wait holds because $T_1$ holds $M_x$ while waiting for $M_y$, and $T_2$ holds $M_y$ while waiting for $M_x$. No preemption holds for standard mutex locks. Therefore, all four Coffman conditions are satisfied, and $T_1$ and $T_2$ are deadlocked.\n\n- The subgraph involving $T_3$, $T_4$, and $M_z$ contains $T_3 \\rightarrow M_z \\rightarrow T_4$. There is no edge from $T_4$ to another mutex. Therefore, there is no cycle, and this is not a deadlock. It is a simple contention where $T_3$ waits until $T_4$ releases $M_z$.\n\nTo prevent recurrence, seek a minimally invasive change that breaks one of the Coffman conditions globally. The most standard and robust approach for mutex deadlocks in code bases that require multiple locks is to enforce a strict global lock ordering. If all code paths acquire $M_x$, then $M_y$, then $M_z$ (or any consistent total order), circular wait cannot arise: there cannot be a cycle because edges representing \"waits for\" always go from a lower-order lock to a higher-order lock, producing an acyclic partial order. This breaks the circular wait condition without changing mutual exclusion semantics or requiring preemption. Assertions can be used to verify that functions do not violate the order at runtime in debug builds.\n\nEvaluate each option:\n\nA. This option proposes the principled diagnostic method: construct the wait-for graph from the stack traces and owner data. It correctly identifies the cycle $T_1 \\rightarrow M_y \\rightarrow T_2 \\rightarrow M_x \\rightarrow T_1$ and correctly excludes $T_3$ and $T_4$ from a deadlock. It then proposes enforcing a global lock ordering $M_x \\rightarrow M_y \\rightarrow M_z$ across all modules, which breaks the circular wait condition by design. This is consistent with the fundamental definitions and is minimally invasive: it requires code changes only to re-order acquisitions and add checks, without altering the mutex abstraction. Verdict: Correct.\n\nB. This option incorrectly diagnoses a deadlock between $T_3$ and $T_4$. The graph shows no cycle; $T_3$ waits on $M_z$ held by $T_4$, but $T_4$ is not waiting. Therefore, this is not a deadlock. Furthermore, adding timeouts to $pthread\\_mutex\\_lock$ is not a standard POSIX feature and, even if implemented via nonblocking attempts and retries, may introduce livelock or violate critical sections’ atomicity guarantees. It does not address the actual cycle between $T_1$ and $T_2$. Verdict: Incorrect.\n\nC. This option claims starvation due to scheduler priority. The captured data explicitly shows blocking on mutex acquisition, not preemption issues. A priority change does not resolve a cycle where $T_1$ waits on $M_y$ held by $T_2$ while $T_2$ waits on $M_x$ held by $T_1$. Scheduler changes cannot break mutual exclusion dependencies. Verdict: Incorrect.\n\nD. This option suggests locally unlocking $M_x$ before attempting to acquire $M_y$ and then reacquiring $M_x$. While superficially it may avoid one instance of circular wait, it introduces a window where the critical section protected by $M_x$ is unprotected, potentially causing races and invariants violations. Moreover, without a consistent global policy, other paths can still acquire in opposite orders and deadlock. It is not a robust, system-wide fix and can degrade correctness. Verdict: Incorrect.\n\nTherefore, the best choice is option A, which correctly uses stack traces to build the wait-for graph, identifies the deadlock, and proposes a proper global lock ordering to break the circular wait condition.", "answer": "$$\\boxed{A}$$", "id": "3661769"}, {"introduction": "The best way to fix a deadlock is to prevent it from ever happening. Moving from reactive debugging to proactive design, this exercise challenges you to implement a solution to the classic 'Dining Philosophers' problem, a metaphor for resource contention in concurrent systems. By implementing a resource hierarchy—a strict ordering for lock acquisition—you will learn a powerful and widely-used strategy to break the circular wait condition and build a provably deadlock-free system. [@problem_id:3661790]", "problem": "You are asked to design, implement, and verify a concurrent simulation of the Dining Philosophers problem using mutex locks, with a deadlock-avoidance strategy based on resource hierarchy. Begin from the following fundamental base: the Coffman deadlock conditions state that a system can deadlock only if all of the following four conditions hold simultaneously: mutual exclusion, hold-and-wait, no preemption, and circular wait. In classical Dining Philosophers with forks modeled as mutually exclusive resources, mutual exclusion, hold-and-wait, and no preemption typically hold by design. Therefore, preventing circular wait is sufficient to ensure deadlock freedom. A well-tested method to prevent circular wait is to impose a strict total order on resources and require that threads acquire resources only in ascending order with respect to this order.\n\nDesign a program that creates $n$ philosopher threads arranged on a ring, indexed $0$ to $n-1$, where philosopher $i$ needs fork $i$ and fork $(i+1) \\bmod n$ to eat. Model each fork as a mutex lock. Implement resource hierarchy by imposing a strict total order on forks according to their indices, and require that each philosopher acquires the fork with the lower index first, followed by the fork with the higher index. In the boundary case where both forks coincide (which happens when $n=1$ because $(0+1) \\bmod 1 = 0$), the philosopher must acquire the single fork exactly once before eating.\n\nEach philosopher must perform exactly $k$ eat cycles. In one eat cycle, the philosopher must:\n- Acquire the required forks respecting the resource hierarchy,\n- Perform a constant-time critical section representing eating,\n- Release any held forks.\n\nAfter all philosopher threads terminate, verify that every philosopher completed exactly $k$ eat cycles. The program must produce a boolean for each test case: output $1$ if every philosopher ate exactly $k$ times and the program terminated, and $0$ otherwise.\n\nTest Suite:\nRun the simulation for the following parameter sets $(n, k)$ to cover a typical case, boundary conditions, and a larger stress case:\n- $(n, k) = (5, 100)$,\n- $(n, k) = (1, 100)$,\n- $(n, k) = (2, 100)$,\n- $(n, k) = (13, 50)$,\n- $(n, k) = (7, 0)$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,\\dots,result_m]$). For the above test suite, print $[b_1,b_2,b_3,b_4,b_5]$ where each $b_i$ is $1$ or $0$ as defined earlier. No units are required for the output since the values are dimensionless booleans represented as integers.", "solution": "The present problem requires the design and implementation of a concurrent simulation for the Dining Philosophers problem. The solution must prevent deadlock by employing a resource hierarchy strategy, as specified. The system consists of `$n$` philosophers and `$n$` forks, modeled as threads and mutex locks, respectively. Each philosopher must complete `$k$` cycles of thinking, acquiring forks, eating, and releasing forks.\n\n### Principle-Based Design\n\nThe solution is grounded in the principles of concurrent programming and deadlock theory. The Coffman conditions stipulate that deadlock can only occur if mutual exclusion, hold-and-wait, no preemption, and circular wait are all present. Our design inherently includes the first three:\n1.  **Mutual Exclusion**: Each fork is a mutex (`mtx_t`), which by definition can only be held by one thread at a time.\n2.  **Hold-and-Wait**: A philosopher acquires one fork and then holds it while waiting to acquire the second.\n3.  **No Preemption**: A philosopher cannot be forced to release a fork; they release it voluntarily after eating.\n\nTherefore, to prevent deadlock, we must eliminate the fourth condition: **Circular Wait**.\n\n### Deadlock Avoidance via Resource Hierarchy\n\nThe specified deadlock avoidance strategy is a resource hierarchy. This is a standard technique that imposes a global total ordering on all resources. Threads are then required to acquire resources in a sequence consistent with this ordering.\n\n1.  **Resource Modeling**: The `$n$` forks are indexed from `$0$` to `$n-1$`. This index serves as the basis for our total order. A fork with a lower index must be acquired before a fork with a higher index.\n\n2.  **Acquisition Logic**:\n    -   Each philosopher `$i$` (for `$i \\in \\{0, 1, ..., n-1\\}$`) is situated between fork `$i$` and fork `$(i+1) \\bmod n$`.\n    -   Let the two required forks for philosopher `$i$` be `$f_a = i$` and `$f_b = (i+1) \\bmod n$`.\n    -   The acquisition protocol is as follows:\n        -   Identify the fork with the lower index, `first_fork = min(f_a, f_b)`.\n        -   Identify the fork with the higher index, `second_fork = max(f_a, f_b)`.\n        -   The philosopher must first lock the mutex corresponding to `first_fork`.\n        -   Only then may the philosopher attempt to lock the mutex for `second_fork`.\n\n3.  **Breaking the Cycle**: This protocol breaks the circular wait condition. A classic deadlock scenario involves every philosopher picking up their left fork and waiting for their right fork, forming a circular dependency chain. With resource hierarchy, this chain is broken at philosopher `$n-1$`, who needs forks `$n-1$` and `$0$`. Instead of acquiring fork `$n-1$` and waiting for fork `$0$`, the protocol forces philosopher `$n-1$` to acquire fork `$0$` first. Since philosopher `$0$` also acquires fork `$0$` as their first fork, these two philosophers will contend for fork `$0$`, serializing their execution and preventing the deadlock cycle.\n\n### Implementation Details\n\nThe implementation is a C program utilizing the `threads.h` library.\n\n1.  **Main Loop**: The `main` function iterates through the specified test suite of `$(n, k)$` parameters. For each test case, it orchestrates the simulation.\n\n2.  **Simulation Setup**: For each simulation run with parameters `$n$` and `$k$`:\n    -   An array of `$n$` mutexes (`mtx_t`) is allocated and initialized to represent the forks.\n    -   An array of `$n$` counters (`int`) is allocated to track the number of times each philosopher has eaten.\n    -   `$n$` philosopher threads (`thrd_t`) are created. Each thread is passed its unique ID (`$0$` to `$n-1$`), the total number of philosophers `$n$`, the target number of eat cycles `$k$`, a pointer to its personal eat counter, and a pointer to the array of fork mutexes.\n\n3.  **Philosopher Thread Logic (`philosopher_routine`)**:\n    -   The core logic resides in this thread function. It executes a loop `$k$` times.\n    -   In each iteration, it implements the fork acquisition, eating, and release cycle.\n    -   The fork indices are calculated, and the `min`/`max` logic is applied to determine the acquisition order.\n    -   A special check, `if (first_fork_idx != second_fork_idx)`, is crucial. It correctly handles the boundary case `$n=1$`, where both required forks are the same (fork `$0$`). This prevents the undefined behavior of attempting to lock an already-held non-recursive mutex.\n    -   After successfully acquiring the necessary forks, the \"eating\" phase is a conceptual critical section. The thread then releases the forks in the reverse order of acquisition.\n    -   Once the loop of `$k$` cycles completes, the thread records its completion by setting its eat counter to `$k$`.\n\n4.  **Verification**: After creating all threads, the main thread waits for all of them to complete using `thrd_join`. Once all philosophers have finished, the main thread verifies the outcome. It iterates through the eat counters. If every counter equals `$k$`, the simulation for that test case is successful, and the result is `$1$`. Otherwise, it is `$0$`.\n\n5.  **Cleanup**: All mutexes are destroyed, and all dynamically allocated memory is freed to prevent resource leaks.\n\nThe final program collates the boolean results from each test case and prints them in the specified format `[b_1,b_2,...,b_m]`. The solution is robust and correctly implements the prescribed deadlock-avoidance mechanism for all given test cases, including boundary conditions such as `$n=1$` and `$k=0$`.", "answer": "```c\n// The complete and compilable C program goes here.\n// Headers must adhere to the specified restrictions.\n#include stdio.h\n#include stdlib.h\n#include string.h\n#include math.h\n#include complex.h\n#include threads.h\n#include stdatomic.h\n\n// A struct to hold the parameters for a single test case.\ntypedef struct {\n    int n; // Number of philosophers\n    int k; // Number of eat cycles\n} TestCase;\n\n// Data passed to each philosopher thread.\ntypedef struct {\n    int id;\n    int num_philosophers;\n    int eat_cycles_k;\n    int* eat_count;\n    mtx_t* forks;\n} PhilosopherArgs;\n\n// The function executed by each philosopher thread.\nint philosopher_routine(void* arg) {\n    PhilosopherArgs* data = (PhilosopherArgs*)arg;\n    int id = data-id;\n    int n = data-num_philosophers;\n    int k = data-eat_cycles_k;\n    mtx_t* forks = data-forks;\n\n    if (k == 0) {\n        *(data-eat_count) = 0;\n        return thrd_success;\n    }\n\n    // Determine fork indices\n    int left_fork = id;\n    int right_fork = (id + 1) % n;\n\n    // Apply resource hierarchy: always acquire lower-indexed fork first\n    int first_fork_idx, second_fork_idx;\n    if (left_fork  right_fork) {\n        first_fork_idx = left_fork;\n        second_fork_idx = right_fork;\n    } else {\n        first_fork_idx = right_fork;\n        second_fork_idx = left_fork;\n    }\n\n    for (int i = 0; i  k; ++i) {\n        // Acquire forks\n        mtx_lock(forks[first_fork_idx]);\n        // Handle n=1 case where right_fork == left_fork.\n        // Don't try to lock the same mutex twice.\n        if (first_fork_idx != second_fork_idx) {\n            mtx_lock(forks[second_fork_idx]);\n        }\n\n        // --- Critical Section: \"Eating\" ---\n        // This block represents the philosopher eating.\n        // No actual work/delay is needed for this simulation.\n\n        // Release forks in reverse order\n        if (first_fork_idx != second_fork_idx) {\n            mtx_unlock(forks[second_fork_idx]);\n        }\n        mtx_unlock(forks[first_fork_idx]);\n    }\n\n    *(data-eat_count) = k;\n    return thrd_success;\n}\n\n// Runs one full simulation for a given (n, k) and returns 1 on success, 0 on failure.\nint run_simulation(int n, int k) {\n    if (n = 0) {\n        return (n == 0) ? 1 : 0; // Vacuously true for n=0, false for n0.\n    }\n\n    mtx_t* forks = malloc((size_t)n * sizeof(mtx_t));\n    thrd_t* threads = malloc((size_t)n * sizeof(thrd_t));\n    int* eat_counts = calloc((size_t)n, sizeof(int));\n    PhilosopherArgs* p_args = malloc((size_t)n * sizeof(PhilosopherArgs));\n\n    if (!forks || !threads || !eat_counts || !p_args) {\n        free(forks);\n        free(threads);\n        free(eat_counts);\n        free(p_args);\n        return 0; // Memory allocation failure\n    }\n\n    for (int i = 0; i  n; ++i) {\n        if (mtx_init(forks[i], mtx_plain) != thrd_success) {\n            for (int j = 0; j  i; ++j) mtx_destroy(forks[j]);\n            free(forks);\n            free(threads);\n            free(eat_counts);\n            free(p_args);\n            return 0; // Mutex initialization failure\n        }\n    }\n\n    for (int i = 0; i  n; ++i) {\n        p_args[i] = (PhilosopherArgs){.id = i,\n                                      .num_philosophers = n,\n                                      .eat_cycles_k = k,\n                                      .eat_count = eat_counts[i],\n                                      .forks = forks};\n        if (thrd_create(threads[i], philosopher_routine, p_args[i]) != thrd_success) {\n            // In a real-world scenario, would need to gracefully stop already\n            // created threads. For this problem, we treat it as a fatal error.\n            // In practice, this failure is highly unlikely here.\n            for (int j = 0; j  n; ++j) mtx_destroy(forks[j]);\n            free(forks);\n            free(threads);\n            free(eat_counts);\n            free(p_args);\n            return 0;\n        }\n    }\n\n    for (int i = 0; i  n; ++i) {\n        thrd_join(threads[i], NULL);\n    }\n\n    // Verification\n    int success = 1;\n    for (int i = 0; i  n; ++i) {\n        if (eat_counts[i] != k) {\n            success = 0;\n            break;\n        }\n    }\n\n    // Cleanup\n    for (int i = 0; i  n; ++i) {\n        mtx_destroy(forks[i]);\n    }\n    free(forks);\n    free(threads);\n    free(eat_counts);\n    free(p_args);\n\n    return success;\n}\n\nint main(void) {\n    // Define the test cases from the problem statement.\n    TestCase test_cases[] = {\n        {5, 100}, {1, 100}, {2, 100}, {13, 50}, {7, 0}};\n\n    // Calculate the number of test cases.\n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    int results[num_cases];\n\n    // Calculate the result for each test case.\n    for (int i = 0; i  num_cases; ++i) {\n        results[i] = run_simulation(test_cases[i].n, test_cases[i].k);\n    }\n\n    // Print the results in the EXACT REQUIRED format before the final return statement.\n    printf(\"[\");\n    for (int i = 0; i  num_cases; ++i) {\n        printf(\"%d\", results[i]);\n        if (i  num_cases - 1) {\n            printf(\",\");\n        }\n    }\n    printf(\"]\\n\");\n\n    return EXIT_SUCCESS;\n}\n```", "id": "3661790"}]}