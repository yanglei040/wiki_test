{"hands_on_practices": [{"introduction": "The primary drawback of a spinlock is the busy-waiting, which consumes CPU cycles. However, the cost goes beyond wasted time; on modern multicore systems, the constant polling by spinning threads generates cache-coherence traffic that can actively slow down the thread currently holding the lock. This exercise provides a quantitative model to analyze this effect, allowing you to calculate how system throughput degrades as an increasing number of threads contend for a single lock. [@problem_id:3684320]", "problem": "Consider a symmetric, steady-state workload on a multicore machine in which $n$ identical threads contend for a single mutual-exclusion spinlock protecting a critical section. Each thread repeatedly attempts to acquire the lock, executes the critical section once, and releases the lock; there is no noncritical work. Assume First-Come, First-Served (FCFS) fairness among contenders and that the system has reached steady state.\n\nSuppose the mean lock hold time without contention is $H_{0}$, and that cache-coherence traffic generated by busy-waiting adds an incremental delay of $\\delta$ to the current holder’s critical-section time per spinning contender. Under this model, when there are $n$ threads contending, the mean lock hold time becomes $H(n) = H_{0} + \\delta\\,(n-1)$. For a tagged thread, its mean time in the system (from the instant it starts contending until it releases the lock) is the sum of its mean wait time and its mean hold time. In steady state, the long-run average number of contending threads equals the arrival rate times the mean time in the system, by the queueing conservation principle commonly known as Little’s Law.\n\nStarting from these premises and no others, derive the steady-state throughput $X(n)$ as a function of $n$, $H_{0}$, and $\\delta$, and then evaluate the throughput for $n = 16$, $H_{0} = 2.5\\,\\mu\\text{s}$, and $\\delta = 0.15\\,\\mu\\text{s}$. Express the final throughput in operations per millisecond, and round your answer to four significant figures.", "solution": "The problem asks for the derivation of the steady-state throughput of a multicore system with $n$ threads contending for a single spinlock, and for the evaluation of this throughput for a specific set of parameters.\n\nFirst, we validate the problem statement.\nThe givens are:\n- A closed system with $n$ identical threads.\n- Each thread's cycle consists only of acquiring a lock, executing a critical section, and releasing the lock.\n- Fairness is First-Come, First-Served (FCFS).\n- The mean lock hold time without contention is $H_{0}$.\n- An incremental delay of $\\delta$ is added to the hold time for each spinning contender.\n- The mean lock hold time with $n$ contenders is $H(n) = H_{0} + \\delta(n-1)$.\n- Little's Law: Average number of contenders = Arrival rate $\\times$ Mean time in system.\n\nThe problem is scientifically grounded in queueing theory and computer systems performance analysis. It is well-posed, objective, and provides a complete and consistent set of premises. The model and its parameters are standard in the analysis of lock contention. Therefore, the problem is deemed valid.\n\nWe proceed to the solution. Let $X(n)$ be the system throughput in operations per unit time. An \"operation\" is one execution of the critical section. Let $H(n)$ be the mean service time, which is the mean lock hold time. The problem states that there is no noncritical work, meaning all $n$ threads are always either holding the lock or waiting for it. For any $n \\ge 1$, the lock is therefore always held by some thread, meaning the server (the lock) is $100\\%$ utilized.\n\nThe throughput of a server is defined as its utilization divided by its mean service time. In this case, utilization is $1$ and the mean service time is $H(n)$. Thus, the throughput $X(n)$ is:\n$$X(n) = \\frac{1}{H(n)}$$\nThe problem specifies the model for $H(n)$:\n$$H(n) = H_{0} + \\delta(n-1)$$\nThis equation reflects that when one thread holds the lock, the other $n-1$ threads are spinning, each contributing an overhead of $\\delta$ to the holder's execution time.\nSubstituting this into the throughput equation gives the desired general expression for the steady-state throughput:\n$$X(n) = \\frac{1}{H_{0} + \\delta(n-1)}$$\n\nTo verify this result using the suggested application of Little's Law, $N = \\lambda T$, we define the terms for this system:\n- $N$: The average number of threads in the system (waiting and being served). As all $n$ threads are always contending, $N = n$.\n- $\\lambda$: The arrival rate of threads to the system. This is equivalent to the system throughput, $\\lambda = X(n)$.\n- $T$: The mean time a thread spends in the system per cycle, which we denote as $T(n)$.\n\nLittle's Law for this system is therefore:\n$$n = X(n) T(n)$$\nThe mean time in the system, $T(n)$, is the sum of the mean wait time, $W(n)$, and the mean hold time, $H(n)$:\n$$T(n) = W(n) + H(n)$$\nGiven the FCFS discipline in this closed system, a thread that has just finished its critical section and re-enters the queue must wait for all other $n-1$ threads to be served before its next turn. The service time for each of these threads is $H(n)$, because during any service, there are always $n-1$ other threads spinning. Thus, the mean wait time is:\n$$W(n) = (n-1)H(n)$$\nThe total cycle time for a thread is then:\n$$T(n) = (n-1)H(n) + H(n) = nH(n)$$\nSubstituting this into Little's Law:\n$$n = X(n) \\left( nH(n) \\right)$$\nSolving for $X(n)$ gives:\n$$X(n) = \\frac{n}{nH(n)} = \\frac{1}{H(n)} = \\frac{1}{H_{0} + \\delta(n-1)}$$\nThis confirms our initial derivation.\n\nNext, we evaluate the throughput for the given values:\n- $n = 16$\n- $H_{0} = 2.5\\,\\mu\\text{s} = 2.5 \\times 10^{-6}\\,\\text{s}$\n- $\\delta = 0.15\\,\\mu\\text{s} = 0.15 \\times 10^{-6}\\,\\text{s}$\n\nFirst, we calculate the mean hold time $H(16)$:\n$$H(16) = H_{0} + \\delta(16 - 1) = 2.5 \\times 10^{-6}\\,\\text{s} + 15 \\times (0.15 \\times 10^{-6}\\,\\text{s})$$\n$$H(16) = (2.5 + 2.25) \\times 10^{-6}\\,\\text{s}$$\n$$H(16) = 4.75 \\times 10^{-6}\\,\\text{s}$$\nThe throughput $X(16)$ is the reciprocal of this value:\n$$X(16) = \\frac{1}{4.75 \\times 10^{-6}\\,\\text{s}} = \\frac{1}{4.75} \\times 10^{6}\\,\\text{operations/s}$$\nThe problem requires the answer in operations per millisecond. We use the conversion $1\\,\\text{s} = 10^3\\,\\text{ms}$:\n$$X(16) = \\left( \\frac{1}{4.75} \\times 10^{6} \\frac{\\text{ops}}{\\text{s}} \\right) \\times \\left( \\frac{1\\,\\text{s}}{10^3\\,\\text{ms}} \\right) = \\frac{1000}{4.75}\\,\\text{ops/ms}$$\nNow, we perform the division:\n$$X(16) = \\frac{1000}{4.75} = \\frac{1000}{19/4} = \\frac{4000}{19} \\approx 210.526315... \\,\\text{ops/ms}$$\nFinally, we round the result to four significant figures. The first four significant digits are $2$, $1$, $0$, and $5$. The fifth digit is $2$, so we round down.\n$$X(16) \\approx 210.5\\,\\text{ops/ms}$$", "answer": "$$\\boxed{210.5}$$", "id": "3684320"}, {"introduction": "While the previous exercise modeled a system entirely bottlenecked by a lock, most real-world applications have both parallel and serial components. This practice extends our analysis to such a system, exploring the crucial interplay between parallel speedup and serialization slowdown exacerbated by contention. You will discover the counter-intuitive but critical principle that beyond a certain point, adding more processors can actually decrease overall performance, and you will calculate the exact threshold where this happens. [@problem_id:3684316]", "problem": "A workload executes on a symmetric multiprocessor with $n$ identical Central Processing Unit (CPU) cores. Each request consists of a non-critical computation of duration $u$ and a critical section protected by a single spinlock of duration $c$ when the lock holder runs without disturbance. All cores continuously have work; the lock is hot (every request acquires it once). Under busy waiting, each of the $n-1$ spinning cores repeatedly polls the lock variable, generating cache coherence traffic that interferes with the lock holder. Empirically, assume this interference adds an extra delay of $\\alpha(n-1)$ to each critical section execution on the lock holder. Ignore all other overheads and context switches, and assume a long run so that initial transients are negligible.\n\nStarting from first principles and definitions, model the total completion time for $m$ requests executed on $n$ cores and derive the steady-state throughput $X(n)$, measured in requests per second, as a function of $n$, $u$, $c$, and $\\alpha$. Then, compute $\\frac{dX}{dn}$ and determine the threshold number of cores $n^{\\star}$ at which $\\frac{dX}{dn} = 0$, so that for $n  n^{\\star}$ additional cores strictly decrease throughput due to spinlock contention.\n\nUse the parameter values $u = 8\\,\\text{ms}$, $c = 0.5\\,\\text{ms}$, and $\\alpha = 0.1\\,\\text{ms}$. Provide the numerical value of $n^{\\star}$, rounded to four significant figures. Express the final answer as a pure number with no units.", "solution": "The user wants me to first validate the problem statement and then, if it is valid, provide a reasoned solution.\n\n### Step 1: Extract Givens\n-   Number of CPU cores: $n$\n-   Duration of non-critical computation per request: $u$\n-   Duration of critical section per request (undisturbed): $c$\n-   Interference delay factor per spinning core: $\\alpha$\n-   Total number of requests: $m$\n-   System specifics: Symmetric multiprocessor, single spinlock, hot lock (all cores continuously have work), busy waiting.\n-   Interference model: The delay added to the critical section is $\\alpha(n-1)$.\n-   Assumptions: Ignore other overheads and context switches; analysis is for steady-state (long run).\n-   Goals:\n    1.  Model the total completion time for $m$ requests.\n    2.  Derive the steady-state throughput $X(n)$.\n    3.  Compute the derivative $\\frac{dX}{dn}$.\n    4.  Find the threshold number of cores $n^{\\star}$ where $\\frac{dX}{dn} = 0$.\n-   Parameter values for numerical calculation: $u = 8\\,\\text{ms}$, $c = 0.5\\,\\text{ms}$, $\\alpha = 0.1\\,\\text{ms}$.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded:** The problem describes a standard performance modeling scenario for lock contention in parallel systems. The model of spinner interference causing a slowdown for the lock holder is a well-established concept in computer architecture related to cache coherence protocols. The linear model for this overhead is a common and valid simplification. The problem is scientifically sound.\n2.  **Well-Posed:** The problem provides all necessary parameters and a clear objective. The goal is to build a model, analyze it using calculus, and find an optimal value, which is a well-defined mathematical task. A unique solution is expected.\n3.  **Objective:** The problem is stated in precise, technical language (\"critical section,\" \"spinlock,\" \"throughput\"). There is no subjective or ambiguous terminology.\n4.  **Flaw Check:** The problem does not violate any scientific principles, is not metaphorical, is self-contained, is not physically infeasible (the parameters are reasonable), and is not ill-posed or trivial.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be provided.\n\n### Solution Derivation\nThe problem requires modeling the performance of a multiprocessor system limited by a single spinlock. We will first model the total time required to complete $m$ requests and then derive the throughput $X(n)$.\n\nLet $T_m(n)$ be the total time to complete $m$ requests on $n$ cores. The execution of these requests involves two types of work: non-critical computation of duration $u$ and critical section execution of base duration $c$.\n\nThe total amount of non-critical work for $m$ requests is $m \\times u$. This work is parallelizable. With $n$ cores, and assuming perfect parallelization, the time spent on this portion of the workload is $\\frac{m u}{n}$.\n\nThe critical sections must be executed serially, as only one core can hold the lock at a time. There are $m$ such critical sections. The problem states that due to contention from the $n-1$ spinning cores, the execution time of a single critical section is increased. The effective duration of one critical section, $c_{eff}$, is the base time $c$ plus the interference delay:\n$$c_{eff}(n) = c + \\alpha(n-1)$$\nSince the $m$ critical sections are serialized, the total time spent executing them is the sum of their individual durations. Assuming the system is in a steady state where the lock is passed from one core to another without idle time (a \"hot lock\"), this total time is:\n$$T_{serial} = m \\times c_{eff}(n) = m(c + \\alpha(n-1))$$\nA common and effective model for the total completion time $T_m(n)$ combines the time for the parallelized portion and the serialized portion:\n$$T_m(n) = \\frac{m u}{n} + m(c + \\alpha(n-1))$$\nThis model represents the workload as having a perfectly parallel part and a strictly serial part, which is a good approximation for this type of system.\n\nThe steady-state throughput, $X(n)$, is defined as the number of requests completed per unit time. Therefore:\n$$X(n) = \\frac{m}{T_m(n)} = \\frac{m}{\\frac{m u}{n} + m(c + \\alpha(n-1))}$$\nWe can cancel the factor $m$:\n$$X(n) = \\frac{1}{\\frac{u}{n} + c + \\alpha(n-1)}$$\nTo find the number of cores $n^{\\star}$ that maximizes the throughput, we need to find the value of $n$ for which the derivative of $X(n)$ with respect to $n$ is zero. Let's treat $n$ as a continuous variable for this optimization.\nWe can write $X(n)$ as:\n$$X(n) = \\left( u n^{-1} + c + \\alpha n - \\alpha \\right)^{-1}$$\nLet the denominator be $D(n) = u n^{-1} + (c-\\alpha) + \\alpha n$. Then $X(n) = [D(n)]^{-1}$. Using the chain rule for differentiation:\n$$\\frac{dX}{dn} = -[D(n)]^{-2} \\cdot \\frac{dD}{dn}$$\nFirst, we find the derivative of the denominator, $D(n)$:\n$$\\frac{dD}{dn} = \\frac{d}{dn} \\left( u n^{-1} + c - \\alpha + \\alpha n \\right) = -u n^{-2} + \\alpha$$\nSubstituting this back into the expression for $\\frac{dX}{dn}$:\n$$\\frac{dX}{dn} = - \\frac{-u n^{-2} + \\alpha}{\\left( \\frac{u}{n} + c + \\alpha(n-1) \\right)^2} = \\frac{u n^{-2} - \\alpha}{\\left( \\frac{u}{n} + c + \\alpha(n-1) \\right)^2}$$\nTo find the threshold $n^{\\star}$, we set $\\frac{dX}{dn} = 0$. Since the denominator is a squared term and represents a sum of durations, it is strictly positive for $n \\ge 1$. Thus, we only need to set the numerator to zero:\n$$u (n^{\\star})^{-2} - \\alpha = 0$$\n$$\\frac{u}{(n^{\\star})^2} = \\alpha$$\n$$(n^{\\star})^2 = \\frac{u}{\\alpha}$$\nSince $n$ must be positive, we take the positive square root:\n$$n^{\\star} = \\sqrt{\\frac{u}{\\alpha}}$$\nThis value of $n^{\\star}$ represents the point of maximum throughput. For $n  n^{\\star}$, the numerator $u n^{-2} - \\alpha$ is positive, so $\\frac{dX}{dn}  0$ and throughput increases with $n$. For $n  n^{\\star}$, the numerator is negative, so $\\frac{dX}{dn}  0$ and adding more cores strictly decreases throughput due to overwhelming contention.\n\nNow, we substitute the given numerical values: $u = 8\\,\\text{ms}$ and $\\alpha = 0.1\\,\\text{ms}$.\n$$n^{\\star} = \\sqrt{\\frac{8}{0.1}} = \\sqrt{80}$$\nTo obtain the numerical answer, we calculate the value of $\\sqrt{80}$:\n$$n^{\\star} = \\sqrt{16 \\times 5} = 4\\sqrt{5} \\approx 4 \\times 2.2360679... \\approx 8.9442719...$$\nThe problem asks for the value rounded to four significant figures.\n$$n^{\\star} \\approx 8.944$$", "answer": "$$\\boxed{8.944}$$", "id": "3684316"}, {"introduction": "Performance and scalability are meaningless if a lock is not logically correct. This exercise shifts our focus from performance to correctness, examining the state machine that underpins a proper lock implementation. By diagnosing a subtle but catastrophic \"double-release\" bug, you will learn the importance of tracking lock ownership and enforcing invariants to build robust and reliable concurrent systems. [@problem_id:3684301]", "problem": "A non-recursive spinlock is implemented using atomic Compare-And-Swap (CAS) semantics: on acquire, a thread repeatedly performs an atomic operation that attempts to change a shared lock word from $\\text{Unlocked}$ to $\\text{Locked}$, spinning (busy waiting) while the operation fails, and on release, it writes back $\\text{Unlocked}$ with appropriate ordering so that critical-section stores become visible before the unlock. Consider a system with $n \\geq 2$ threads running on $m \\geq 1$ Central Processing Units (CPUs), where the lock protects a shared data structure. The core correctness requirement for any mutual exclusion mechanism is the safety property: at most one thread is in the critical section at any time. A fundamental additional requirement for a non-recursive spinlock is that only the thread that successfully acquired the lock may release it.\n\nDefine a minimal lock-state machine with states $S = \\{\\text{Unlocked}, \\text{Locked}\\}$. The allowed transitions are:\n- $\\text{Unlocked} \\rightarrow \\text{Locked}$ by a unique acquiring thread $T_i$,\n- $\\text{Locked} \\rightarrow \\text{Unlocked}$ by the same thread $T_i$.\n\nAn illegal transition occurs if either the precondition for the transition is not met (for example, attempting $\\text{Locked} \\rightarrow \\text{Unlocked}$ when the current state is $\\text{Unlocked}$), or the identity constraint is violated (for example, a thread $T_j \\neq T_i$ attempts to unlock when $T_i$ is the owner).\n\nSuppose there is a subtle bug in client code: a thread $T_1$ calls unlock twice in a row without an intervening lock, i.e., its intended sequence is $\\text{lock}(T_1)$, critical section, $\\text{unlock}(T_1)$, but due to a bug it executes $\\text{unlock}(T_1)$ again. Because of concurrency, it is possible that between the first and second unlock calls, some other thread $T_2$ acquires the lock, so that at the time of the second unlock by $T_1$, the state may be $\\text{Locked}$ and the owner may be $T_2$.\n\nYou are tasked with instrumenting the spinlock with invariants and assertions that will detect any illegal transition, including this double release scenario, as early as possible and without flagging valid interleavings. You may augment the lock with the following metadata, updated atomically where appropriate:\n- an owner identifier $o \\in \\{\\text{null}\\} \\cup \\{\\text{thread identifiers}\\}$,\n- a per-thread hold count $h_i \\in \\{0,1\\}$ (because the lock is non-recursive),\n- per-thread acquisition and release counters $a_i$ and $r_i$.\n\nWhich option specifies a set of invariants and assertions that will necessarily detect the second (buggy) unlock by $T_1$ under all interleavings, while not firing during any legal acquire or release?\n\nA. Assert only the state precondition on unlock: before any unlock, check $s = \\text{Locked}$. On acquire, assert $s = \\text{Unlocked}$ before attempting CAS. Do not track ownership or per-thread counts.\n\nB. Maintain and check the following invariants and assertions:\n- Precondition for acquire by $T_i$: assert $s = \\text{Unlocked}$; on successful CAS, set $s := \\text{Locked}$, $o := T_i$, increment $a_i$, and set $h_i := 1$.\n- Precondition for unlock by $T_i$: assert $s = \\text{Locked}$, $o = T_i$, and $h_i = 1$; then set $s := \\text{Unlocked}$, $o := \\text{null}$, $h_i := 0$, and increment $r_i$.\n- Global consistency: for all threads $i$, assert $r_i \\leq a_i$, and assert $\\sum_i h_i \\in \\{0,1\\}$.\nThese conditions reject any unlock when the current thread is not the owner or when the lock is not held, and prevent double release by the same thread.\n\nC. Maintain only global counters and a state-consistency check: define $A := \\sum_i a_i$ and $R := \\sum_i r_i$, assert $R \\leq A$ at all times, and assert that transitions alternate between $\\text{Unlocked}$ and $\\text{Locked}$ in the global timeline. Do not track $o$ or $h_i$.\n\nD. On unlock, assert that a store-load ordering barrier executes before writing $s := \\text{Unlocked}$, and on acquire, assert that a load-store ordering barrier executes after observing $s = \\text{Locked}$. Do not track $o$, $h_i$, or $(a_i, r_i)$, and do not assert state preconditions.\n\nSelect the best option.", "solution": "## Problem Validation\n\n### Step 1: Extract Givens\n\n- **Lock Implementation**: A non-recursive spinlock is implemented using atomic Compare-And-Swap (CAS).\n- **Acquire Operation**: A thread repeatedly performs an atomic operation attempting to change a shared lock word from $\\text{Unlocked}$ to $\\text{Locked}$, spinning while the operation fails.\n- **Release Operation**: The lock owner writes back $\\text{Unlocked}$ with appropriate memory ordering.\n- **System Parameters**: $n \\geq 2$ threads, $m \\geq 1$ CPUs.\n- **Correctness Requirements**:\n    1.  **Mutual Exclusion (Safety)**: At most one thread is in the critical section at any time.\n    2.  **Ownership on Release**: Only the thread that successfully acquired the lock may release it.\n- **Lock State Machine**:\n    - States $S = \\{\\text{Unlocked}, \\text{Locked}\\}$.\n    - Allowed transition $\\text{Unlocked} \\rightarrow \\text{Locked}$ by an acquiring thread $T_i$.\n    - Allowed transition $\\text{Locked} \\rightarrow \\text{Unlocked}$ by the same thread $T_i$.\n- **Bug Scenario**: A thread $T_1$ executes `unlock` twice in a row. Between the two `unlock` calls by $T_1$, another thread $T_2$ may acquire the lock. The specific interleaving to consider is: `lock(T_1)`, first `unlock(T_1)`, `lock(T_2)`, second (buggy) `unlock(T_1)`.\n- **Task**: Instrument the spinlock to detect any illegal transition, specifically the double release, under all interleavings, without flagging valid operations.\n- **Instrumentation Metadata Available**:\n    - Owner identifier $o \\in \\{\\text{null}\\} \\cup \\{\\text{thread identifiers}\\}$.\n    - Per-thread hold count $h_i \\in \\{0, 1\\}$ (for a non-recursive lock).\n    - Per-thread acquisition and release counters $a_i$ and $r_i$.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem statement is evaluated against the validation criteria:\n\n1.  **Scientifically Grounded**: The problem is rooted in fundamental concepts of concurrent programming and operating systems, including spinlocks, atomic operations (CAS), mutual exclusion, and race conditions. The described bug (double-release) and the instrumentation techniques (tracking ownership, counters) are standard and realistic topics in this field.\n2.  **Well-Posed**: The problem asks for a specific set of invariants and assertions to detect a well-defined erroneous behavior (a double-unlock) under concurrent execution. The goal is clear and formally specifiable.\n3.  **Objective**: The language used is technical, precise, and free of subjective or ambiguous terminology. The scenario and requirements are stated objectively.\n4.  **Incomplete or Contradictory Setup**: The problem is self-contained. It provides the lock's behavior, the exact bug to detect, the possible interleaving, and the tools available for instrumentation. There are no contradictions.\n5.  **Unrealistic or Infeasible**: The scenario is a common and plausible programming error in low-level concurrency. The system model ($n$ threads, $m$ CPUs) is standard.\n6.  **Ill-Posed or Poorly Structured**: The problem is well-structured, building from general principles to a specific scenario and a clear question. It admits a unique, best solution among the options.\n7.  **Pseudo-Profound, Trivial, or Tautological**: The problem is not trivial. It requires a careful analysis of state changes under concurrency and understanding which information is necessary to maintain and check to ensure logical correctness, distinguishing it from other aspects like memory visibility.\n8.  **Outside Scientific Verifiability**: The proposed solutions (the options) are all verifiable through logical analysis of the state transitions.\n\n### Step 3: Verdict and Action\n\nThe problem statement is **valid**. It is a well-defined, scientifically sound problem in computer science. The solution process will now proceed.\n\n## Solution Derivation\n\nThe core task is to devise a set of checks that can detect a specific illegal operation: a thread $T_1$ attempting to release a lock that it does not currently own. This situation arises in the given scenario:\n1.  Thread $T_1$ acquires the lock. The lock state is now $(\\text{state}=\\text{Locked}, \\text{owner}=T_1)$.\n2.  $T_1$ correctly releases the lock. The lock state becomes $(\\text{state}=\\text{Unlocked}, \\text{owner}=\\text{null})$.\n3.  Thread $T_2$ acquires the lock. The state becomes $(\\text{state}=\\text{Locked}, \\text{owner}=T_2)$.\n4.  $T_1$ erroneously attempts to release the lock again. At this point, the lock is in state $\\text{Locked}$, but its owner is $T_2$.\n\nAn illegal release by $T_1$ would violate mutual exclusion by prematurely unlocking the lock while $T_2$ is in its critical section. The instrumentation must therefore catch this attempt at step 4. A successful detection mechanism must, at the point of an `unlock` call by a thread $T_i$, be able to verify that $T_i$ is indeed the current, legitimate owner of the lock. This requires tracking lock ownership.\n\n### Option-by-Option Analysis\n\n**A. Assert only the state precondition on unlock: before any unlock, check $s = \\text{Locked}$. On acquire, assert $s = \\text{Unlocked}$ before attempting CAS. Do not track ownership or per-thread counts.**\n\nLet's trace the buggy scenario with these assertions:\n1.  `lock(T_1)`: $T_1$ finds $s=\\text{Unlocked}$ and its CAS succeeds, setting $s:=\\text{Locked}$.\n2.  `unlock(T_1)`: $T_1$ asserts $s=\\text{Locked}$. This is true. The assertion passes. $T_1$ sets $s:=\\text{Unlocked}$.\n3.  `lock(T_2)`: $T_2$ finds $s=\\text{Unlocked}$ and its CAS succeeds, setting $s:=\\text{Locked}$.\n4.  `unlock(T_1)` (buggy call): $T_1$ asserts $s=\\text{Locked}$. The lock state is indeed $\\text{Locked}$ (because $T_2$ holds it). The assertion **passes**, and $T_1$ proceeds to incorrectly set $s:=\\text{Unlocked}$, breaking the lock.\n\nThis set of assertions fails to detect the bug. The fundamental flaw is the lack of ownership tracking. Knowing the lock is `Locked` is insufficient; one must know *who* locked it.\n\n**Verdict for A: Incorrect.**\n\n**B. Maintain and check the following invariants and assertions: ...**\nThis option proposes a comprehensive set of metadata: state $s$, owner $o$, per-thread hold count $h_i$, and acquisition/release counters $a_i, r_i$. The key assertions are on the `unlock` path.\n\nLet's re-trace the scenario with these checks for `unlock` by thread $T_i$: `assert s = Locked, o = T_i, and h_i = 1`.\n\n1.  `lock(T_1)`: After successful CAS, the state is updated: $s:=\\text{Locked}$, $o:=T_1$, $a_1$ increments, $h_1:=1$.\n2.  `unlock(T_1)`: $T_1$ checks the preconditions.\n    - `assert s = Locked`: True.\n    - `assert o = T_1`: True.\n    - `assert h_1 = 1`: True.\n    All assertions pass. The state is updated: $s:=\\text{Unlocked}$, $o:=\\text{null}$, $h_1:=0$, $r_1$ increments.\n3.  `lock(T_2)`: After successful CAS, the state is updated: $s:=\\text{Locked}$, $o:=T_2$, $a_2$ increments, $h_2:=1$. Note that $h_1$ remains $0$.\n4.  `unlock(T_1)` (buggy call): $T_1$ checks the preconditions.\n    - `assert s = Locked`: True. The lock is held by $T_2$.\n    - `assert o = T_1`: **False.** The current owner $o$ is $T_2$. The assertion fails.\n    - `assert h_1 = 1`: **False.** The hold count for $T_1$, $h_1$, was set to $0$ during its valid unlock in step 2. The assertion fails.\n\nSince at least one assertion necessarily fails, the illegal unlock attempt is detected, preventing the violation of mutual exclusion. The set of checks is sufficient to catch the bug under all interleavings. The global consistency checks ($r_i \\leq a_i$ and $\\sum_i h_i \\in \\{0, 1\\}$) provide additional correctness guarantees, though the per-operation preconditions are sufficient for this specific bug.\n\n**Verdict for B: Correct.**\n\n**C. Maintain only global counters and a state-consistency check: define $A := \\sum_i a_i$ and $R := \\sum_i r_i$, assert $R \\leq A$ at all times, and assert that transitions alternate between $\\text{Unlocked}$ and $\\text{Locked}$ in the global timeline. Do not track $o$ or $h_i$.**\n\nThis approach uses aggregate counters, discarding per-thread information. Let's trace the scenario:\n1.  `lock(T_1)`: $a_1$ becomes $1$. $A=1, R=0$. $s: \\text{Unlocked} \\rightarrow \\text{Locked}$.\n2.  `unlock(T_1)`: $r_1$ becomes $1$. $A=1, R=1$. Check $R \\leq A$ passes. $s: \\text{Locked} \\rightarrow \\text{Unlocked}$.\n3.  `lock(T_2)`: $a_2$ becomes $1$. $A=2, R=1$. Check $R \\leq A$ passes. $s: \\text{Unlocked} \\rightarrow \\text{Locked}$.\n4.  `unlock(T_1)` (buggy): $r_1$ becomes $2$. $A=2, R=2$. Check $R \\leq A$ passes. $s: \\text{Locked} \\rightarrow \\text{Unlocked}$.\n\nThe invariant $R \\leq A$ is not violated. The global sequence of states is $\\text{Unlocked} \\rightarrow \\text{Locked} \\rightarrow \\text{Unlocked} \\rightarrow \\text{Locked} \\rightarrow \\text{Unlocked}$, which is a valid alternating sequence. This method is too coarse-grained to detect that the wrong thread is performing the unlock. It can detect if more unlocks than locks happen globally, but not an ownership violation.\n\n**Verdict for C: Incorrect.**\n\n**D. On unlock, assert that a store-load ordering barrier executes before writing $s := \\text{Unlocked}$, and on acquire, assert that a load-store ordering barrier executes after observing $s = \\text{Locked}$. Do not track $o$, $h_i$, or $(a_i, r_i)$, and do not assert state preconditions.**\n\nThis option focuses on memory ordering, which is a different aspect of lock implementation correctness. Memory barriers ensure that memory operations (reads and writes) performed by different threads on different CPUs appear in a consistent order. Specifically, the unlock barrier ensures that all writes from within the critical section are visible to other threads before the lock is released. The acquire barrier ensures that no reads or writes from the new critical section are reordered to occur before the lock is acquired.\n\nThese barriers are crucial for the correctness of the code *protected by* the lock, but they do not validate the logical sequence of lock/unlock operations themselves. The bug in question is a logical error (a protocol violation), not a memory visibility error. Asserting the presence of barriers does nothing to prevent a thread from calling `unlock` when it is not the owner. An implementation with the buggy client code would have these barriers, and thus the assertions would pass, while the logical flaw remains undetected.\n\n**Verdict for D: Incorrect.**", "answer": "$$\\boxed{B}$$", "id": "3684301"}]}