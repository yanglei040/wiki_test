{"hands_on_practices": [{"introduction": "The performance of an inverted page table (IPT) implemented with hashing depends on how evenly entries are distributed. This first exercise guides you through a foundational analysis, modeling the IPT as a classic \"balls and bins\" problem. By deriving the expected number of empty buckets from first principles, you will develop a quantitative understanding of the relationship between table size, memory usage, and load factor, which is essential for performance tuning.", "problem": "An operating system (OS) uses an Inverted Page Table (IPT) that is organized as a hash table with chaining. The table has $m$ buckets, and there are $n$ active page table entries. Each entry is hashed uniformly and independently into one of the $m$ buckets. The time to locate an entry in a bucket is proportional to the number of entries in that bucket, so bucket occupancy directly affects lookup performance.\n\nStarting from the definitions of probability, indicator random variables, and linearity of expectation, derive the exact expected fraction of buckets that are empty as a function of $m$ and $n$. Then, using a large-system approximation in which $m$ and $n$ are large while the load factor $\\alpha = n/m$ is held constant, derive the asymptotic form of the expected fraction of empty buckets. Finally, suppose the system aims to tune $m$ so that the expected fraction of empty buckets equals a target value $\\theta$ with $0 < \\theta < 1$. Using the asymptotic form, derive a closed-form expression for $m$ in terms of $n$ and $\\theta$.\n\nProvide your final answer as a row matrix with two entries: the first entry is the exact expected fraction of empty buckets as a function of $m$ and $n$, and the second entry is the asymptotic expression for $m$ in terms of $n$ and $\\theta$. No numerical approximation or rounding is required.", "solution": "The problem asks for three related derivations concerning the distribution of entries in an inverted page table, which is modeled as a hash table with chaining. We will address each part in sequence, starting from first principles as requested.\n\nThe setup is a classic \"balls and bins\" problem in probability theory, where $n$ balls (page table entries) are thrown independently and uniformly at random into $m$ bins (buckets).\n\nFirst, we derive the exact expected fraction of empty buckets. Let $X$ be the random variable representing the total number of empty buckets. We want to find the expected fraction, which is $\\frac{E[X]}{m}$. To calculate $E[X]$, we use the method of indicator random variables.\n\nLet $X_i$ be an indicator random variable for the event that bucket $i$ is empty, for $i \\in \\{1, 2, \\dots, m\\}$. By definition:\n$$\nX_i =\n\\begin{cases}\n1 & \\text{if bucket } i \\text{ is empty} \\\\\n0 & \\text{if bucket } i \\text{ is not empty}\n\\end{cases}\n$$\nThe total number of empty buckets is the sum of these indicator variables:\n$$X = \\sum_{i=1}^{m} X_i$$\nBy the linearity of expectation, the expected number of empty buckets is the sum of the expected values of the indicator variables:\n$$E[X] = E\\left[\\sum_{i=1}^{m} X_i\\right] = \\sum_{i=1}^{m} E[X_i]$$\nThe expectation of an indicator random variable is equal to the probability of the event it indicates. Therefore, $E[X_i] = P(\\text{bucket } i \\text{ is empty})$.\n\nLet's calculate this probability. Consider a single page table entry. Since hashing is uniform, the probability that this entry is hashed to any specific bucket $i$ is $\\frac{1}{m}$. Consequently, the probability that this entry is *not* hashed to bucket $i$ is $1 - \\frac{1}{m} = \\frac{m-1}{m}$.\n\nThere are $n$ entries in total, and their hash locations are independent. The event \"bucket $i$ is empty\" occurs if and only if none of the $n$ entries are hashed to bucket $i$. The probability of this compound event is the product of the individual probabilities for each entry:\n$$P(\\text{bucket } i \\text{ is empty}) = \\left(\\frac{m-1}{m}\\right) \\times \\left(\\frac{m-1}{m}\\right) \\times \\dots \\times \\left(\\frac{m-1}{m}\\right) \\quad (n \\text{ times})$$\n$$P(\\text{bucket } i \\text{ is empty}) = \\left(\\frac{m-1}{m}\\right)^n = \\left(1 - \\frac{1}{m}\\right)^n$$\nSo, for any bucket $i$, we have $E[X_i] = \\left(1 - \\frac{1}{m}\\right)^n$.\n\nNow, we can find the expected total number of empty buckets:\n$$E[X] = \\sum_{i=1}^{m} \\left(1 - \\frac{1}{m}\\right)^n = m \\left(1 - \\frac{1}{m}\\right)^n$$\nThe expected fraction of empty buckets is $\\frac{E[X]}{m}$:\n$$\\text{Expected Fraction} = \\frac{m \\left(1 - \\frac{1}{m}\\right)^n}{m} = \\left(1 - \\frac{1}{m}\\right)^n$$\nThis is the first required result.\n\nSecond, we derive the asymptotic form of this fraction in a large-system limit where $m \\to \\infty$ and $n \\to \\infty$ such that the load factor $\\alpha = \\frac{n}{m}$ remains constant. We substitute $n = \\alpha m$ into the expression for the fraction:\n$$\\left(1 - \\frac{1}{m}\\right)^n = \\left(1 - \\frac{1}{m}\\right)^{\\alpha m}$$\nWe evaluate the limit as $m \\to \\infty$:\n$$\\lim_{m \\to \\infty} \\left(1 - \\frac{1}{m}\\right)^{\\alpha m} = \\lim_{m \\to \\infty} \\left[ \\left(1 + \\frac{-1}{m}\\right)^m \\right]^{\\alpha}$$\nWe use the fundamental limit definition of the exponential function, $\\lim_{x \\to \\infty} \\left(1 + \\frac{k}{x}\\right)^x = \\exp(k)$. Here, $x=m$ and $k=-1$.\n$$\\lim_{m \\to \\infty} \\left(1 + \\frac{-1}{m}\\right)^m = \\exp(-1)$$\nTherefore, the asymptotic limit of the fraction is:\n$$\\left[\\exp(-1)\\right]^{\\alpha} = \\exp(-\\alpha) = \\exp\\left(-\\frac{n}{m}\\right)$$\nThe asymptotic form of the expected fraction of empty buckets is $\\exp\\left(-\\frac{n}{m}\\right)$.\n\nThird, we use this asymptotic form to derive an expression for $m$ in terms of $n$ and a target expected fraction of empty buckets, $\\theta$, where $0 < \\theta < 1$. We set the asymptotic fraction equal to $\\theta$:\n$$\\exp\\left(-\\frac{n}{m}\\right) = \\theta$$\nTo solve for $m$, we take the natural logarithm of both sides:\n$$\\ln\\left(\\exp\\left(-\\frac{n}{m}\\right)\\right) = \\ln(\\theta)$$\n$$-\\frac{n}{m} = \\ln(\\theta)$$\nSince $0 < \\theta < 1$, its logarithm $\\ln(\\theta)$ is a non-zero negative number. We can now solve for $m$:\n$$m = -\\frac{n}{\\ln(\\theta)}$$\nThis can also be written as $m = \\frac{n}{\\ln(1/\\theta)}$. The expression is well-defined and positive, as required for a number of buckets. This is the second required result.\n\nThe final answer will be a row matrix containing the exact expected fraction and the derived expression for $m$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\left(1 - \\frac{1}{m}\\right)^n & -\\frac{n}{\\ln(\\theta)}\n\\end{pmatrix}\n}\n$$", "id": "3651017"}, {"introduction": "While the previous problem assumed uniform hashing, real-world performance hinges on the quality of the hash function. This exercise explores a worst-case scenario where a poorly chosen hash function causes all entries to collide into a single bucket, completely undermining the efficiency of the IPT. Analyzing this degenerate case [@problem_id:3651073] highlights the critical importance of hash function design in preventing catastrophic performance degradation.", "problem": "A system implements an inverted page table (IPT) that stores exactly one entry per physical frame. A lookup for a virtual address uses a hash-based index into a table of $B$ buckets and resolves collisions by separate chaining. The key for hashing is the ordered pair $(\\text{PID}, \\text{VPN})$, where $PID$ is the Process Identifier (PID) and $VPN$ is the Virtual Page Number (VPN). The system designer mistakenly deploys the poor hash function $h(\\text{PID}, \\text{VPN}) = \\text{PID} \\bmod B$. Let there be $n$ occupied IPT entries at some instant, where $n \\leq B$ is not guaranteed and a single process may occupy multiple frames. Assume no auxiliary acceleration structures such as a Translation Lookaside Buffer (TLB); lookups traverse the chain in a bucket by comparing both `PID` and `VPN` fields for equality at each node.\n\nStarting only from the definitions of the inverted page table, hashing with separate chaining, and equality-based key comparison, do the following:\n\n- Derive a necessary and sufficient condition on the set of occupied entries $\\left\\{\\left(PID_{j}, VPN_{j}\\right)\\right\\}_{j=1}^{n}$ and the bucket count $B$ under which all $n$ entries collide into a single bucket when using $h(\\text{PID}, \\text{VPN}) = \\text{PID} \\bmod B$. Your derivation must identify the precise predicate that characterizes this degeneracy.\n- Under that degeneracy, determine the worst-case number of key comparisons performed by a single lookup (whether successful or unsuccessful) as a function of $n$.\n\nProvide only the expression for the worst-case number of comparisons as your final answer, in closed form with no units. If you choose to simplify, do so exactly; no rounding is required.", "solution": "The user wants me to solve the problem described in the prompt.\n\n### Step 1: Problem Validation\n\nFirst, I will validate the problem statement according to the specified criteria.\n\n#### Step 1.1: Extract Givens\n\n*   **System Architecture**: An inverted page table (IPT) with one entry per physical frame.\n*   **Lookup Mechanism**: Hash-based index into a table of $B$ buckets.\n*   **Collision Resolution**: Separate chaining.\n*   **Hash Key**: An ordered pair $(\\text{PID}, \\text{VPN})$, where $PID$ is the Process Identifier and $VPN$ is the Virtual Page Number.\n*   **Hash Function**: $h(\\text{PID}, \\text{VPN}) = \\text{PID} \\bmod B$.\n*   **System State**: There are $n$ occupied IPT entries.\n*   **Set of Entries**: The set of occupied entries is denoted as $\\{(PID_j, VPN_j)\\}_{j=1}^{n}$.\n*   **Constraints**: The condition $n \\leq B$ is not guaranteed. A single process may occupy multiple frames.\n*   **Assumptions**: No auxiliary acceleration structures like a Translation Lookaside Buffer (TLB). Lookups traverse the chain by comparing both `PID` and `VPN` fields for equality.\n*   **Objectives**:\n    1.  Derive a necessary and sufficient condition for all $n$ entries to collide into a single bucket.\n    2.  Under this condition, determine the worst-case number of key comparisons for a single lookup as a function of $n$.\n\n#### Step 1.2: Validate Using Extracted Givens\n\n*   **Scientific Grounding**: The problem is grounded in fundamental concepts of operating systems and data structures, specifically virtual memory management (inverted page tables) and hashing (hash tables with separate chaining). The scenario of a poorly designed hash function is a standard pedagogical example used to illustrate the importance of hash function quality. The concepts are scientifically and computationally sound.\n*   **Well-Posedness**: The problem is well-posed. It clearly defines the system, the hash function, and the data. It asks for two distinct, derivable results: a logical condition and a worst-case complexity analysis. The required information is provided, and a unique, meaningful answer can be determined.\n*   **Objectivity**: The problem is stated in precise, objective language, free of ambiguity or subjective claims. Terms like \"inverted page table,\" \"separate chaining,\" and \"key comparison\" have standard, unambiguous meanings in computer science.\n\nThe problem statement does not violate any of the invalidity criteria. It is a scientifically sound, well-posed, and objective problem from the field of computer science.\n\n#### Step 1.3: Verdict and Action\n\nThe problem is **valid**. I will proceed with the solution.\n\n### Step 2: Solution Derivation\n\nThe problem has two parts. First, we must derive the condition for maximum collision, and second, we must analyze the worst-case performance under that condition.\n\n#### Part 1: Necessary and Sufficient Condition for Degeneracy\n\nThe hash table has $B$ buckets, indexed from $0$ to $B-1$. The bucket for an entry with key $(\\text{PID}, \\text{VPN})$ is determined by the value of the hash function $h(\\text{PID}, \\text{VPN})$. The given hash function is $h(\\text{PID}, \\text{VPN}) = \\text{PID} \\bmod B$. Notably, the hash value depends only on the $PID$ and is independent of the $VPN$.\n\nAll $n$ occupied entries, represented by the set $\\{(PID_j, VPN_j)\\}_{j=1}^{n}$, collide into a single bucket if and only if they all hash to the same bucket index. Let this common bucket index be denoted by an integer $k$, where $0 \\leq k < B$.\n\nThis condition can be expressed mathematically as:\n$$h(\\text{PID}_j, \\text{VPN}_j) = k \\quad \\text{for all } j \\in \\{1, 2, \\dots, n\\}$$\n\nSubstituting the definition of the hash function, we get:\n$$\\text{PID}_j \\bmod B = k \\quad \\text{for all } j \\in \\{1, 2, \\dots, n\\}$$\n\nThis statement means that every Process Identifier $PID_j$ from the set of occupied entries must have the same remainder $k$ when divided by $B$. This is the definition of congruence modulo $B$. Therefore, for any two PIDs in the set, say $PID_i$ and $PID_j$, it must be that $PID_i \\bmod B = PID_j \\bmod B$. This is equivalent to stating that all PIDs belong to the same congruence class modulo $B$.\n\nThus, the necessary and sufficient condition is:\nThere exists an integer $k \\in \\{0, 1, \\dots, B-1\\}$ such that for all occupied entries $(PID_j, VPN_j)$ with $j \\in \\{1, \\dots, n\\}$, the process identifier $PID_j$ satisfies the congruence relation $\\text{PID}_j \\equiv k \\pmod{B}$.\n\n#### Part 2: Worst-Case Number of Key Comparisons\n\nUnder the degeneracy condition derived above, all $n$ occupied entries are stored in a single linked list (a chain) associated with one bucket, say bucket $k$. The length of this chain is $n$.\n\nA lookup for a target key $(\\text{PID}_{\\text{target}}, \\text{VPN}_{\\text{target}})$ proceeds as follows:\n1.  The bucket index is computed: $i = h(\\text{PID}_{\\text{target}}, \\text{VPN}_{\\text{target}}) = \\text{PID}_{\\text{target}} \\bmod B$.\n2.  The linked list at bucket $i$ is traversed. At each node in the list, the stored key $(\\text{PID}_{\\text{stored}}, \\text{VPN}_{\\text{stored}})$ is compared against the target key $(\\text{PID}_{\\text{target}}, \\text{VPN}_{\\text{target}})$. A single \"key comparison\" involves checking for equality of both fields: $( \\text{PID}_{\\text{stored}} = \\text{PID}_{\\text{target}} ) \\land ( \\text{VPN}_{\\text{stored}} = \\text{VPN}_{\\text{target}} )$.\n\nWe need to find the worst-case number of such comparisons. The worst case can occur in either a successful or an unsuccessful lookup. We must consider both.\n\n**Case A: Successful Lookup**\nA successful lookup occurs when the target key $(\\text{PID}_{\\text{target}}, \\text{VPN}_{\\text{target}})$ is one of the $n$ entries in the chain. The worst case for a search in a linked list happens when the target element is the last one in the list. To find it, the algorithm must traverse all preceding $n-1$ nodes, performing a failed comparison at each, and then perform a final, successful comparison at the $n$-th node. Therefore, the total number of key comparisons is $n$.\n\n**Case B: Unsuccessful Lookup**\nAn unsuccessful lookup occurs when the target key $(\\text{PID}_{\\text{target}}, \\text{VPN}_{\\text{target}})$ is not in the IPT. The worst case for an unsuccessful lookup happens when the search is directed to the most populated bucket. For the lookup to be directed to the chain of length $n$, the target PID must satisfy $\\text{PID}_{\\text{target}} \\bmod B = k$. The algorithm will then traverse the entire linked list of length $n$, performing a key comparison at each of the $n$ nodes. Since the key is not present, all $n$ comparisons will fail. After checking all $n$ entries and reaching the end of the list, the search terminates. The total number of key comparisons performed is $n$.\n\n**Conclusion**\nThe worst-case number of comparisons for a successful lookup is $n$. The worst-case number of comparisons for an unsuccessful lookup is also $n$. Therefore, the overall worst-case number of key comparisons for any single lookup (successful or unsuccessful) under the given degeneracy condition is the maximum of these two values, which is $n$.", "answer": "$$\\boxed{n}$$", "id": "3651073"}, {"introduction": "Modern system design must also account for malicious adversaries who actively try to create worst-case conditions. This practice problem elevates our analysis from accidental worst-cases to deliberate, targeted attacks on the IPT's hash table. By comparing an unsalted system to one defended by cryptographic salting [@problem_id:3651027], you will learn about the practical security measures needed to protect core OS data structures from denial-of-service threats.", "problem": "A system implements an inverted page table (IPT), which stores exactly one entry per physical frame. For address translation, the Operating System (OS) computes a bucket index in a hash table of size $M$ using a hash of the Process Identifier (PID) and the Virtual Page Number (VPN). Collisions are resolved by separate chaining, so the per-lookup cost is proportional to the corresponding bucketâ€™s chain length plus constant overhead. Assume the Translation Lookaside Buffer (TLB) covers only a subset of working-set translations and that misses must consult the IPT.\n\nFundamental base assumptions:\n- An inverted page table stores one record per physical frame: $\\langle \\text{PID}, \\text{VPN}, \\text{frame metadata} \\rangle$. \n- Under uniform hashing with separate chaining and $K$ keys distributed over $M$ buckets, the load factor is $\\alpha = K/M$ and the expected chain length in a bucket is $\\alpha$. Expected-time lookup is $O(1 + \\alpha)$.\n- A deterministic, public, unsalted hash $h(\\text{PID}, \\text{VPN})$ allows an input-selecting adversary to choose inputs to target specific buckets if preimages can be found cheaply. Introducing a secret per-boot salt $s$ to obtain $h(\\text{PID}, \\text{VPN}, s)$ from a $2$-universal family makes bucket assignment of attacker-chosen inputs indistinguishable from random to an adversary that does not know $s$.\n\nConsider the following concrete scenario. The hash table has $M = 2^{20}$ buckets, and collisions are resolved with singly linked lists. The OS caps any single process to at most $K_{\\max} = 2^{18}$ resident pages. A malicious process aims to degrade translation latency by forcing many of its mappings to collide into the same bucket.\n\nTwo configurations are considered:\n\n- Unsalted: the system uses a fixed, public, deterministic function $h(\\text{PID}, \\text{VPN})$.\n- Salted: at each boot, the OS draws a secret $k$-bit salt $s$ uniformly at random (with $k = 64$) and uses $h(\\text{PID}, \\text{VPN}, s)$ from a $2$-universal family. The attacker does not know $s$ and cannot directly observe bucket indices; it can only measure its own access latencies.\n\nSelect all statements that are true about the attack feasibility and defenses in this setting:\n\nA. If the system uses the unsalted $h(\\text{PID}, \\text{VPN})$ and it is publicly known and efficiently computable, then for a given $PID$ the adversary can select $K \\le K_{\\max}$ distinct $VPN$ values that map to the same bucket, forcing a chain of length $\\Theta(K)$ and making its own TLB-miss translation cost grow on the order of $K$.\n\nB. With a secret per-boot salt $s$ of $k = 64$ bits and a $2$-universal hash family, an adversary that does not know $s$ cannot bias bucket occupancy beyond random; for its $K \\le K_{\\max}$ pages, the expected chain length it contributes to any bucket is approximately $\\alpha = K/M$, so its expected lookup time remains $O(1)$.\n\nC. Even with a secret salt, the adversary can, by adaptively timing its own accesses, reconstruct the exact salt $s$ in $O(\\log M)$ probes and thereby deterministically create long single-bucket chains within a single boot.\n\nD. Even with salting that enforces uniform hashing, residual risk persists: as the system-wide load factor $\\alpha_{\\text{sys}}$ approaches $1$ or higher due to overall memory pressure, the tail of the chain-length distribution grows and increases worst-case and tail latencies; countermeasures such as limiting per-bucket chain length with an overflow area or a secondary table, or applying move-to-front heuristics, can reduce these tails.\n\nE. Switching to open addressing with probing eliminates the need for any salt because an attacker cannot induce primary clustering without knowing $s$, so the worst-case lookup time becomes a small constant independent of the load factor $\\alpha$.\n\nAssume realistic constant-factor effects from cache behavior, pointer chasing, and TLB behavior, but base your answer on the formal properties above. Provide no extraneous assumptions beyond those stated.", "solution": "The user has requested a meticulous validation and solution of a problem concerning inverted page tables and hash-based collision attacks in operating systems.\n\n### Problem Validation\n\nFirst, the problem statement must be validated for scientific soundness, clarity, and completeness.\n\n**Step 1: Extract Givens**\n\nThe problem provides the following information:\n- The system uses an inverted page table (IPT) with one entry per physical frame.\n- An entry is of the form $\\langle \\text{PID}, \\text{VPN}, \\text{frame metadata} \\rangle$.\n- Address translation uses a hash table of size $M$ to look up IPT entries.\n- The hash input is a pair of (Process Identifier, Virtual Page Number), i.e., $(\\text{PID}, \\text{VPN})$.\n- Collisions are resolved using separate chaining (singly linked lists).\n- TLB-miss lookup cost is proportional to the chain length plus a constant.\n- The hash table size is $M = 2^{20}$ buckets.\n- A single process is capped at a maximum of $K_{\\max} = 2^{18}$ resident pages.\n- Fundamental assumptions on hashing are provided:\n    - For uniform hashing with $K$ keys and $M$ buckets, the load factor is $\\alpha = K/M$, and the expected chain length is $\\alpha$. Expected-time lookup is $O(1 + \\alpha)$.\n    - An unsalted, public hash $h(\\text{PID}, \\text{VPN})$ is vulnerable to pre-image finding attacks by an adversary.\n    - A salted hash $h(\\text{PID}, \\text{VPN}, s)$ from a $2$-universal family with a secret salt $s$ makes bucket assignment indistinguishable from random for an adversary who does not know $s$.\n- Two configurations are considered:\n    1.  **Unsalted**: A fixed, public, deterministic hash function $h(\\text{PID}, \\text{VPN})$.\n    2.  **Salted**: A secret $k=64$ bit salt $s$ is chosen uniformly at random at boot, and the hash function $h(\\text{PID}, \\text{VPN}, s)$ is from a $2$-universal family. The attacker cannot observe $s$ or bucket indices, only measure its own access latencies.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientifically Grounded**: The problem is well-grounded in established computer science principles. Inverted page tables, hash tables, separate chaining, collision attacks (hash flooding), and cryptographic defenses like salted universal hashing are all standard concepts in operating systems and algorithms.\n- **Well-Posed**: The problem is well-posed. It defines a clear scenario with specific parameters ($M=2^{20}$, $K_{\\max}=2^{18}$, $k=64$) and two distinct system configurations. The question asks to evaluate the truthfulness of five specific statements, which is a well-defined task.\n- **Objective**: The problem is stated using precise, objective technical language. There are no subjective or ambiguous terms.\n- **Completeness and Consistency**: The provided information is sufficient and self-consistent. The assumptions about hashing properties, attacker capabilities, and system parameters are clearly laid out, enabling a rigorous analysis of each option. No contradictions are apparent.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is valid. It is scientifically sound, well-posed, objective, and self-contained. The analysis can proceed.\n\n### Solution Derivation and Option Analysis\n\nThe core of the problem is to assess the security and performance implications of using an unsalted versus a salted hash function for an inverted page table, particularly in the face of a malicious adversary.\n\n**Analysis of Option A**\n\nThe statement is: \"If the system uses the unsalted $h(\\text{PID}, \\text{VPN})$ and it is publicly known and efficiently computable, then for a given $PID$ the adversary can select $K \\le K_{\\max}$ distinct $VPN$ values that map to the same bucket, forcing a chain of length $\\Theta(K)$ and making its own TLB-miss translation cost grow on the order of $K$.\"\n\n- **Reasoning**: In the unsalted configuration, the hash function $h(\\text{PID}, \\text{VPN})$ is deterministic and public. An adversary, knowing its own $PID$, can compute $h(\\text{PID}, \\text{VPN})$ for any $VPN$. To mount a collision attack, the adversary picks an arbitrary target bucket index, say $b_0$. It then needs to find $K$ distinct virtual page numbers ($VPN_1, VPN_2, \\dots, VPN_K$) such that $h(\\text{PID}, VPN_i) = b_0$ for all $i \\in \\{1, \\dots, K\\}$. The problem states that the adversary can do this (\"if preimages can be found cheaply\"). Since typical non-cryptographic hash functions are not pre-image resistant, an attacker can generally find such inputs by iterating through $VPN$s and checking the hash output until $K$ matches are found. By mapping pages to these $K$ specific $VPN$s, the adversary forces the operating system to create $K$ entries in the IPT that all hash to the same bucket $b_0$. These entries will form a linked list (chain) of length $K$. According to the problem, a TLB miss for any of these pages will require traversing this chain. The lookup cost is proportional to the chain length, so the cost will be $O(K)$. For a specific chain created by the attacker of length $K$, the cost is more precisely $\\Theta(K)$.\n\n- **Verdict**: **Correct**. This statement accurately describes a classic denial-of-service attack via hash table collisions, which is entirely feasible with a public, unsalted hash function.\n\n**Analysis of Option B**\n\nThe statement is: \"With a secret per-boot salt $s$ of $k = 64$ bits and a $2$-universal hash family, an adversary that does not know $s$ cannot bias bucket occupancy beyond random; for its $K \\le K_{\\max}$ pages, the expected chain length it contributes to any bucket is approximately $\\alpha = K/M$, so its expected lookup time remains $O(1)$.\"\n\n- **Reasoning**: The use of a randomly chosen hash function from a $2$-universal family (instantiated by the secret salt $s$) is the standard defense against collision attacks. The key property of a $2$-universal family is that for any two distinct inputs $x_1, x_2$, the probability of collision $P[h_s(x_1) = h_s(x_2)]$ is at most $1/M$, where the probability is over the random choice of $s$. Since the adversary does not know $s$, it cannot predict which bucket a chosen $(\\text{PID}, \\text{VPN})$ pair will map to. From its perspective, each of its $K$ pages is mapped to a bucket chosen uniformly at random from the $M$ available buckets. Therefore, the adversary cannot force collisions into a single bucket. The $K$ pages it maps will be distributed across the $M$ buckets. The expected number of the adversary's pages in any single bucket is $K/M$. This is the load factor $\\alpha$ contributed by the adversary. Given $K \\le K_{\\max} = 2^{18}$ and $M = 2^{20}$, the adversary's load factor is at most $\\alpha_{\\text{adv}} = 2^{18} / 2^{20} = 1/4 = 0.25$. The total expected chain length is determined by the system-wide load factor $\\alpha_{\\text{sys}}$. As long as the system is not pathologically overloaded (i.e., $\\alpha_{\\text{sys}}$ is bounded by a constant), the expected lookup time remains $O(1 + \\alpha_{\\text{sys}}) = O(1)$. The salt effectively neutralizes the adversary's ability to create worst-case behavior.\n\n- **Verdict**: **Correct**. This statement correctly describes the cryptographic guarantee provided by a salted, universal hash function.\n\n**Analysis of Option C**\n\nThe statement is: \"Even with a secret salt, the adversary can, by adaptively timing its own accesses, reconstruct the exact salt $s$ in $O(\\log M)$ probes and thereby deterministically create long single-bucket chains within a single boot.\"\n\n- **Reasoning**: This describes a timing side-channel attack to recover the secret salt $s$. An access that misses the TLB will have a latency proportional to the length of the hash chain it traverses. By mapping pages and measuring access times, an attacker can learn information about collisions. For example, if mapping a new page $VPN_j$ increases the access time for a previously mapped page $VPN_i$, the attacker can infer a collision: $h(\\text{PID}, \\text{VPN}_i, s) = h(\\text{PID}, \\text{VPN}_j, s)$. However, the claim that the entire $k=64$-bit salt $s$ can be recovered in $O(\\log M)$ probes is extraordinarily strong and implausible. Here, $M=2^{20}$, so $\\log M \\approx 20$. Recovering a $64$-bit key with about $20$ probes is generally impossible from an information-theoretic standpoint, unless the hash function family has severe structural weaknesses that are not mentioned. Each probe (a timing measurement) provides a noisy, low-information signal (chain length), not a clean bucket index. Even if each probe revealed the exact $20$-bit bucket index, it would require at least $\\lceil 64/20 \\rceil = 4$ such perfect probes to recover $64$ bits of information about $s$, and this assumes the relationship between $s$ and the hash output is trivial, which it is not in a well-designed universal hash family. Recovering a cryptographic key via such a side channel is a complex cryptanalytic task that would typically require a vastly larger number of observations. The $O(\\log M)$ estimate is unrealistic.\n\n- **Verdict**: **Incorrect**. The complexity of recovering the salt is grossly underestimated.\n\n**Analysis of Option D**\n\nThe statement is: \"Even with salting that enforces uniform hashing, residual risk persists: as the system-wide load factor $\\alpha_{\\text{sys}}$ approaches $1$ or higher due to overall memory pressure, the tail of the chain-length distribution grows and increases worst-case and tail latencies; countermeasures such as limiting per-bucket chain length with an overflow area or a secondary table, or applying move-to-front heuristics, can reduce these tails.\"\n\n- **Reasoning**: Salting prevents *adversarial* worst-cases, but not *stochastic* ones. With uniform hashing, the distribution of keys into buckets can be modeled by a Poisson distribution with mean $\\lambda = \\alpha_{\\text{sys}} = N_{\\text{total}}/M$. As the system-wide load factor $\\alpha_{\\text{sys}}$ increases, the mean chain length increases. More importantly, the variance also increases, and the probability of observing very long chains (the tail of the distribution) becomes non-negligible. This leads to high tail latency for TLB misses, impacting real-time guarantees and quality of service. This is an inherent property of hash tables under high load. The second part of the statement lists standard techniques to mitigate this problem. Limiting bucket chain length and using an overflow area is a classic method. Using a secondary table is characteristic of schemes like 2-choice hashing. A \"move-to-front\" heuristic, where an accessed item is moved to the head of its chain, is a well-known technique to improve performance for non-uniform access patterns, as it reduces the average search time for frequently used items, thus shortening the experienced latency for the working set. All parts of this statement are correct descriptions of hash table behavior and management techniques.\n\n- **Verdict**: **Correct**. The statement correctly identifies the performance degradation of hash tables at high load factors, even with uniform hashing, and lists appropriate countermeasures.\n\n**Analysis of Option E**\n\nThe statement is: \"Switching to open addressing with probing eliminates the need for any salt because an attacker cannot induce primary clustering without knowing $s$, so the worst-case lookup time becomes a small constant independent of the load factor $\\alpha$.\"\n\n- **Reasoning**: This statement contains two significant errors.\n1.  **Need for salt**: Open addressing determines the initial probe slot using a hash function. If this function is an unsalted, public $h(k)$, an attacker can still choose multiple keys $k_1, k_2, \\dots$ that all hash to the same initial slot. This phenomenon is called primary clustering and leads to long probe sequences, a form of denial-of-service attack analogous to long chains in separate chaining. Therefore, salting is still required to prevent an adversary from choosing inputs that cause this clustering. The premise \"an attacker cannot induce primary clustering without knowing $s$\" is backward; it is precisely *because* an attacker *can* induce clustering *without* a salt that a salt is needed.\n2.  **Performance**: The performance of open addressing is highly dependent on the load factor $\\alpha$. For any standard probing scheme (linear, quadratic, double hashing), as $\\alpha$ approaches $1$, the expected number of probes for a lookup diverges. For example, for linear probing, the expected cost is $O((1-\\alpha)^{-2})$, and for double hashing, it is $O((1-\\alpha)^{-1})$. This is not a \"small constant independent of the load factor\". Performance degrades dramatically under high load. While some advanced hashing schemes can achieve constant-time lookups, \"open addressing with probing\" in general does not have this property.\n\n- **Verdict**: **Incorrect**. The statement is flawed in its understanding of both the security requirements and performance characteristics of open addressing.", "answer": "$$\\boxed{ABD}$$", "id": "3651027"}]}