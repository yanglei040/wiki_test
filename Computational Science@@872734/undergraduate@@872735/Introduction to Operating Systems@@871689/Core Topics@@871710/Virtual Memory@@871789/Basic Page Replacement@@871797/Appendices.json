{"hands_on_practices": [{"introduction": "The First-In-First-Out (FIFO) algorithm is appealing for its simplicity, but it can exhibit surprising behaviors. It is natural to assume that allocating more memory frames to a process will always decrease, or at least not increase, the number of page faults. This exercise [@problem_id:3623347] guides you through a classic counterexample, allowing you to directly observe and analyze Belady's anomaly, a phenomenon that violates this basic intuition.", "problem": "A demand-paged virtual memory system maintains a fixed-size set of physical frames and replaces pages on a fault using the First-In First-Out (FIFO) policy, where the page that has resided in memory the longest (i.e., the first that arrived) is evicted. A page fault occurs whenever a referenced page is not currently resident in any frame. Assume that all frames are initially empty and that a reference loads the page into a free frame if one exists; otherwise, the FIFO policy evicts the oldest resident page before loading the new one. Let $f_{\\text{FIFO}}(k)$ denote the total number of page faults when using $k$ frames under FIFO for a given reference string.\n\nGiven the classical reference sequence $S = (1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5)$, compute $f_{\\text{FIFO}}(3)$ and $f_{\\text{FIFO}}(4)$, and, starting from the above definitions, explain why the resulting values exemplify Belady's anomaly, wherein increasing the number of frames can increase the number of page faults under the FIFO policy.\n\nExpress your final answer as a two-entry row matrix $\\begin{pmatrix} f_{\\text{FIFO}}(3) & f_{\\text{FIFO}}(4) \\end{pmatrix}$ with exact integer values. No rounding is required.", "solution": "The problem statement is entirely self-contained, scientifically grounded in the principles of operating system memory management, and well-posed. All terms are standard and clearly defined, providing a basis for a unique and verifiable solution. Thus, the problem is deemed valid.\n\nThe task is to compute the number of page faults for a given reference string $S = (1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5)$ using a First-In First-Out (FIFO) page replacement policy with $k=3$ and $k=4$ frames, denoted by $f_{\\text{FIFO}}(3)$ and $f_{\\text{FIFO}}(4)$ respectively. Subsequently, we must explain why the result demonstrates Belady's anomaly.\n\nThe FIFO policy operates like a queue. When a page must be evicted, the one that has been in memory for the longest time is chosen. We will trace the state of the memory frames for each case. A page fault is indicated by 'F' and a hit by 'H'. The frames' contents represent the set of pages currently in memory. The \"Arrival Order\" queue shows the pages from oldest to newest.\n\n**Case 1: $k=3$ frames**\n\nWe simulate the process step-by-step for $f_{\\text{FIFO}}(3)$.\n\n| Reference | Page | Frames (Set)  | Fault/Hit | Arrival Order (Oldest $\\rightarrow$ Newest) | Action                               |\n|-----------|------|---------------|-----------|---------------------------------------------|--------------------------------------|\n| 1         | $1$  | $\\{1\\}$       | F         | $[1]$                                       | Load $1$ into an empty frame.          |\n| 2         | $2$  | $\\{1, 2\\}$    | F         | $[1, 2]$                                    | Load $2$ into an empty frame.          |\n| 3         | $3$  | $\\{1, 2, 3\\}$ | F         | $[1, 2, 3]$                                 | Load $3$ into an empty frame.          |\n| 4         | $4$  | $\\{2, 3, 4\\}$ | F         | $[2, 3, 4]$                                 | Evict $1$ (oldest), load $4$.          |\n| 5         | $1$  | $\\{3, 4, 1\\}$ | F         | $[3, 4, 1]$                                 | Evict $2$ (oldest), load $1$.          |\n| 6         | $2$  | $\\{4, 1, 2\\}$ | F         | $[4, 1, 2]$                                 | Evict $3$ (oldest), load $2$.          |\n| 7         | $5$  | $\\{1, 2, 5\\}$ | F         | $[1, 2, 5]$                                 | Evict $4$ (oldest), load $5$.          |\n| 8         | $1$  | $\\{1, 2, 5\\}$ | H         | $[1, 2, 5]$                                 | Page $1$ is in memory.               |\n| 9         | $2$  | $\\{1, 2, 5\\}$ | H         | $[1, 2, 5]$                                 | Page $2$ is in memory.               |\n| 10        | $3$  | $\\{2, 5, 3\\}$ | F         | $[2, 5, 3]$                                 | Evict $1$ (oldest), load $3$.          |\n| 11        | $4$  | $\\{5, 3, 4\\}$ | F         | $[5, 3, 4]$                                 | Evict $2$ (oldest), load $4$.          |\n| 12        | $5$  | $\\{5, 3, 4\\}$ | H         | $[5, 3, 4]$                                 | Page $5$ is in memory.               |\n\nCounting the number of faults (F), we find there are $9$ page faults.\nTherefore, $f_{\\text{FIFO}}(3) = 9$.\n\n**Case 2: $k=4$ frames**\n\nNext, we simulate the process for $f_{\\text{FIFO}}(4)$.\n\n| Reference | Page | Frames (Set)    | Fault/Hit | Arrival Order (Oldest $\\rightarrow$ Newest) | Action                               |\n|-----------|------|-----------------|-----------|---------------------------------------------|--------------------------------------|\n| 1         | $1$  | $\\{1\\}$         | F         | $[1]$                                       | Load $1$ into an empty frame.          |\n| 2         | $2$  | $\\{1, 2\\}$      | F         | $[1, 2]$                                    | Load $2$ into an empty frame.          |\n| 3         | $3$  | $\\{1, 2, 3\\}$   | F         | $[1, 2, 3]$                                 | Load $3$ into an empty frame.          |\n| 4         | $4$  | $\\{1, 2, 3, 4\\}$| F         | $[1, 2, 3, 4]$                              | Load $4$ into an empty frame.          |\n| 5         | $1$  | $\\{1, 2, 3, 4\\}$| H         | $[1, 2, 3, 4]$                              | Page $1$ is in memory.               |\n| 6         | $2$  | $\\{1, 2, 3, 4\\}$| H         | $[1, 2, 3, 4]$                              | Page $2$ is in memory.               |\n| 7         | $5$  | $\\{2, 3, 4, 5\\}$| F         | $[2, 3, 4, 5]$                              | Evict $1$ (oldest), load $5$.          |\n| 8         | $1$  | $\\{3, 4, 5, 1\\}$| F         | $[3, 4, 5, 1]$                              | Evict $2$ (oldest), load $1$.          |\n| 9         | $2$  | $\\{4, 5, 1, 2\\}$| F         | $[4, 5, 1, 2]$                              | Evict $3$ (oldest), load $2$.          |\n| 10        | $3$  | $\\{5, 1, 2, 3\\}$| F         | $[5, 1, 2, 3]$                              | Evict $4$ (oldest), load $3$.          |\n| 11        | $4$  | $\\{1, 2, 3, 4\\}$| F         | $[1, 2, 3, 4]$                              | Evict $5$ (oldest), load $4$.          |\n| 12        | $5$  | $\\{2, 3, 4, 5\\}$| F         | $[2, 3, 4, 5]$                              | Evict $1$ (oldest), load $5$.          |\n\nCounting the number of faults (F), we find there are $10$ page faults.\nTherefore, $f_{\\text{FIFO}}(4) = 10$.\n\n**Explanation of Belady's Anomaly**\n\nThe computed values are $f_{\\text{FIFO}}(3) = 9$ and $f_{\\text{FIFO}}(4) = 10$. We observe that $f_{\\text{FIFO}}(4) > f_{\\text{FIFO}}(3)$. This phenomenon, where increasing the number of allocated memory frames leads to an increase in the number of page faults, is known as Belady's anomaly. It is a counterintuitive result because one would generally expect more resources (i.e., more frames) to improve performance (i.e., cause fewer faults).\n\nThe anomaly occurs because the FIFO replacement algorithm does not consider the usage history or future likelihood of a page being referenced; it only considers the arrival time. The specific reason for the anomaly in this example can be pinpointed by comparing the frame states.\n\nAt reference 7, the string requests page 5.\n- In the $k=3$ case, just before reference 7, the trace shows the frames contain $\\{4, 1, 2\\}$ with arrival order $[4, 1, 2]$. The oldest page, $4$, is evicted to load page $5$. The new state is $\\{1, 2, 5\\}$. Crucially, pages $1$ and $2$ remain in memory, and the subsequent references to them are hits.\n- In the $k=4$ case, the frames contain $\\{1, 2, 3, 4\\}$ with arrival order $[1, 2, 3, 4]$. The oldest page is $1$. To load page $5$, page $1$ is evicted. The new state is $\\{2, 3, 4, 5\\}$. This eviction is detrimental because page $1$ is requested on the very next step (reference 8), causing an immediate page fault.\n\nThe larger frame set ($k = 4$) allowed the \"wrong\" page (page $1$, which was needed again soon) to become the oldest resident and thus the victim for replacement. In contrast, the smaller frame set ($k = 3$) had already been forced to evict pages that were not immediately needed, leading to a frame composition that fortuitously performed better on the subsequent references.\n\nBelady's anomaly is characteristic of page replacement algorithms that are not \"stack algorithms.\" A stack algorithm has the property that the set of pages in memory with $k$ frames is always a subset of the pages in memory with $k+1$ frames at any point in the reference string. FIFO does not satisfy this property, as demonstrated here: after reference $7$, the frame set for $k=3$ is $\\{1, 2, 5\\}$, while for $k=4$ it is $\\{2, 3, 4, 5\\}$. The former is not a subset of the latter.\n\nThe final computed values are presented as a two-entry row matrix.", "answer": "$$\n\\boxed{\\begin{pmatrix} 9 & 10 \\end{pmatrix}}\n$$", "id": "3623347"}, {"introduction": "The Least Recently Used (LRU) algorithm improves upon FIFO by using the principle of locality, evicting pages that have not been accessed for the longest time. While generally effective, LRU is not immune to pathological access patterns that cause \"thrashing.\" This problem [@problem_id:3623298] challenges you to analyze such a scenario, where the working set of pages is cyclically accessed and is just larger than the cache size, revealing the worst-case performance of LRU and leading to a steady-state miss rate of one.", "problem": "Consider a demand-paged system using the Least Recently Used (LRU) page replacement policy. The LRU policy maintains a recency stack and, at each time step, the set of pages resident in the cache of capacity $k$ frames is exactly the $k$ most recently referenced distinct pages. Let $k \\in \\mathbb{N}$ be the cache capacity and fix integers $k_{1}, k_{2} \\in \\mathbb{N}$ such that $k_{1} + k_{2} = k$ and $k_{1} \\geq 1$, $k_{2} \\geq 1$. Construct two disjoint sets of virtual pages $A$ and $B$ with $|A| = k_{1} + 1$ and $|B| = k_{2} + 1$. Define the infinite reference string $S$ by cyclic interleaving of these two sets as follows: in each cycle, reference every page of $A$ exactly once in any fixed order without repetition, then reference every page of $B$ exactly once in any fixed order without repetition, and repeat this two-block pattern forever. Using only the core definitions of the LRU policy and the recency stack characterization stated above, derive the exact steady-state miss rate of LRU on the infinite sequence $S$. Express your final answer as a single real number; no rounding is required.", "solution": "The problem asks for the steady-state miss rate of the Least Recently Used (LRU) page replacement policy for a specific type of infinite reference string. I will first validate the problem statement and then proceed to a formal derivation if the problem is valid.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- **Policy:** Least Recently Used (LRU) page replacement.\n- **LRU Definition:** At any time, the set of pages in the cache is \"exactly the $k$ most recently referenced distinct pages.\"\n- **Cache Capacity:** $k \\in \\mathbb{N}$.\n- **Integer Partition:** $k_1, k_2 \\in \\mathbb{N}$ such that $k_1 + k_2 = k$, $k_1 \\geq 1$, and $k_2 \\geq 1$.\n- **Page Sets:** Two disjoint sets of virtual pages, $A$ and $B$.\n- **Set Sizes:** $|A| = k_1 + 1$ and $|B| = k_2 + 1$.\n- **Reference String:** An infinite string $S$ is formed by cyclically referencing all pages in $A$ (in a fixed order), followed by all pages in $B$ (in a fixed order). This pattern $(A\\text{-block}, B\\text{-block})$ repeats indefinitely.\n- **Task:** Derive the exact steady-state miss rate.\n- **Answer Format:** A single real number.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding:** The problem is set within the standard theoretical framework of algorithm analysis in operating systems. The LRU policy and demand paging are core concepts. The problem is scientifically and mathematically sound.\n- **Well-Posedness:** The problem provides a precise definition of the LRU policy, the cache size, the page sets, and the reference string. It asks for a specific, computable quantity (steady-state miss rate). The parameters $k, k_1, k_2$ are defined as fixed but arbitrary natural numbers. The request for a \"single real number\" implies the result must be independent of these parameters. My analysis will determine if this is the case.\n- **Objectivity:** The problem is stated in formal, objective language without ambiguity or subjective claims.\n\nThe problem does not violate any of the invalidity criteria. It is a well-defined theoretical computer science problem. The construction involving $k_1$ and $k_2$ may be intricate, but it is not contradictory or incomplete.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. I will proceed with the solution.\n\n### Derivation of the Steady-State Miss Rate\n\nLet the total set of distinct pages be $P = A \\cup B$. Since $A$ and $B$ are disjoint, the total number of distinct pages is:\n$$N = |P| = |A| + |B| = (k_1 + 1) + (k_2 + 1) = k_1 + k_2 + 2$$\nGiven that $k = k_1 + k_2$, the total number of distinct pages is $N = k + 2$.\n\nThe reference string $S$ is generated by repeatedly cycling through all $N = k+2$ pages of $P$. A full cycle of references consists of $|A| + |B| = k+2$ individual page references.\n\nWe are interested in the steady-state miss rate. In the steady state, the cache's behavior follows a repeating pattern determined by the cyclic nature of the reference string. A page fault (miss) for a referenced page $p$ occurs if, at the time of reference, $p$ is not present in the cache.\n\nAccording to the problem's definition, the cache contains the $k$ most recently referenced distinct pages. Therefore, a miss on page $p$ occurs if and only if $p$ is not a member of the set of the $k$ most recently referenced distinct pages.\n\nLet us consider any arbitrary page $p \\in P$. We will analyze two consecutive references to this page $p$ in the steady state. Let the reference string be denoted by $(r_1, r_2, r_3, \\dots)$.\nSuppose a reference to page $p$ occurs at time $t_i$, so $r_{t_i} = p$.\nThe next reference to the same page $p$ will occur at time $t_{i+1}$. Since the reference string is a cycle of all $N = k+2$ distinct pages, exactly $N-1$ other distinct pages are referenced between these two consecutive accesses to $p$.\nTherefore, the time elapsed between the two references is $t_{i+1} - t_i = N = k+2$ steps.\n\nLet's examine the state of the system immediately before the reference to $p$ at time $t_{i+1}$. The sequence of references between time $t_i$ and $t_{i+1}$ is $(r_{t_i+1}, r_{t_i+2}, \\dots, r_{t_i+N-1})$. This sequence consists of the $N-1 = (k+2)-1 = k+1$ distinct pages in $P \\setminus \\{p\\}$.\n\nAt time $t_{i+1}-1$, the most recent reference was $r_{t_{i+1}-1}$. The history of references ending at this point is $(\\dots, r_{t_i}, r_{t_i+1}, \\dots, r_{t_{i+1}-1})$.\nThe set of distinct pages referenced from time $t_i+1$ to $t_{i+1}-1$ is precisely $P \\setminus \\{p\\}$, and its size is $k+1$. These are, by definition, the $k+1$ most recently referenced distinct pages just before time $t_{i+1}$.\n\nThe LRU cache, by definition, contains the $k$ most recently referenced distinct pages. At the moment just before referencing $p$ at time $t_{i+1}$, this set of $k$ pages must be a subset of the $k+1$ pages in $P \\setminus \\{p\\}$.\nSince $p \\notin (P \\setminus \\{p\\})$, it cannot be in any subset of $P \\setminus \\{p\\}$. Thus, $p$ is not in the cache at this time.\n\nConsequently, the reference to page $p$ at time $t_{i+1}$ results in a page fault.\n\nThis reasoning is valid for any page $p \\in P$. Therefore, in the steady state, every reference to any page results in a miss.\n\nThe total number of references in one full cycle of the string $S$ is $|A| + |B| = k+2$.\nThe number of misses in one full cycle, as demonstrated, is also $k+2$.\n\nThe steady-state miss rate is defined as the ratio of misses to references over a cycle:\n$$\\text{Miss Rate} = \\frac{\\text{Number of Misses in a Cycle}}{\\text{Number of References in a Cycle}} = \\frac{k+2}{k+2} = 1$$\n\nThe specific construction involving the sets $A$ and $B$ and the parameters $k_1$ and $k_2$ serves to define a reference string that is a cyclic permutation of $k+2$ distinct pages. The derived miss rate of $1$ is a general result for any such access pattern on an LRU cache of size $k$ and is independent of the specific values of $k, k_1,$ and $k_2$ (provided the conditions $k_1 \\ge 1, k_2 \\ge 1$ hold). The result is a single real number, as requested.", "answer": "$$\\boxed{1}$$", "id": "3623298"}, {"introduction": "The Optimal (OPT) algorithm provides the theoretical benchmark for page replacement, guaranteeing the minimum possible number of page faults. While it is impossible to implement for a real-time system because it requires knowledge of the future, we can implement it as an offline algorithm to evaluate the performance of practical policies. This hands-on coding challenge [@problem_id:3665680] asks you to design and implement an efficient version of OPT using appropriate data structures, bridging the gap between theoretical concepts and practical algorithm engineering.", "problem": "You are given a page reference string of length $n$ and a physical memory that can hold $F$ frames. The Optimal page replacement (OPT) algorithm, also known as the Minimum page replacement (MIN) algorithm, evicts the resident page whose next reference is farthest in the future (or never occurs again). Starting from this fundamental definition of page replacement and page faults in operating systems, design and implement a program that computes the exact number of page faults incurred by the OPT algorithm for multiple test cases. Your design must achieve $O(n \\log n)$ time complexity by tracking the next occurrences of pages and supporting efficient selection of the eviction candidate.\n\nYour program must adhere to the following requirements:\n\n- Derive a data structure from the definition of OPT that maintains, at each access time $t$, the mapping from resident pages to their next-use indices. You must:\n  1. Precompute, for each index $i$ in the reference string, the index of the next occurrence of the referenced page strictly after $i$, or a special \"no next use\" marker.\n  2. Maintain a max-priority queue keyed by next-use indices of resident pages, allowing extraction of the page with the largest next-use index (treat \"no next use\" as $+\\infty$).\n  3. Maintain a constant-time map from page identifiers to their positions within the priority queue to allow key updates when a page that is already resident is accessed.\n  4. For each reference at time $i$, update the key of the referenced page if it is resident; otherwise, insert it and evict the page with the maximum key when needed.\n\n- Use only basic integer page identifiers.\n\n- The final output for all test cases must be a single line containing a comma-separated list of integers enclosed in square brackets, with no spaces, where each integer is the number of OPT page faults for the corresponding test case.\n\nTest Suite:\n\nCompute the number of OPT page faults for the following parameter sets:\n\n1. Reference string $[1,2,3,4,1,2,5,1,2,3,4,5,6,1,7,2,3,7]$ with $F=3$.\n2. Reference string $[9,9,9,9,9]$ with $F=2$.\n3. Reference string $[1,2,1,2,1,2]$ with $F=1$.\n4. Reference string $[10,20,10,20,30,10,20,30,40,30,40]$ with $F=4$.\n5. Reference string $[3,4,5,3,6,7,3,8,3]$ with $F=2$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result1,result2,result3,result4,result5]$).", "solution": "The problem requires the implementation of the Optimal (OPT) page replacement algorithm, also known as the Minimum (MIN) algorithm, to calculate the number of page faults for several test cases. The OPT algorithm is defined by the policy of evicting the page that will be used furthest in the future. A direct implementation of this would require, at each page fault, searching the entire future reference string for all resident pages, which is computationally expensive. The problem mandates a more efficient approach with a time complexity of $O(n \\log n)$, where $n$ is the length of the reference string. This can be achieved by following the specified design involving precomputation and the use of a priority queue.\n\nThe core of the efficient algorithm rests on two main phases: a precomputation phase and a simulation phase.\n\n**1. Precomputation of Next-Use Information**\n\nTo make the \"furthest in the future\" decision quickly, we first pre-process the entire reference string. For each access at an index $i$ to a page $p$, we want to know the index of the next time page $p$ is accessed. We can compute an array, let's call it $next\\_use$, of the same length as the reference string. For each index $i$ from $0$ to $n-1$, $next\\_use[i]$ will store the smallest index $j > i$ such that $ref\\_str[j] = ref\\_str[i]$. If no such $j$ exists (i.e., this is the last occurrence of the page), we store a special marker representing infinity. A value larger than any possible index, such as $n+1$, serves as a practical representation for infinity.\n\nThis precomputation can be done efficiently in $O(n + V)$ time, where $V$ is the number of unique page identifiers, by iterating backward from the end of the reference string. An auxiliary array, $last\\_seen$, of size $V+1$ stores the most recently seen index of each page. When processing index $i$, $next\\_use[i]$ is set to the value currently in $last\\_seen[ref\\_str[i]]$, after which $last\\_seen[ref\\_str[i]]$ is updated to $i$.\n\n**2. Simulation with Efficient Data Structures**\n\nWith the $next\\_use$ array, we can simulate the page replacement process by iterating through the reference string from time $t=0$ to $n-1$. At each step, we process the reference to page $p = ref\\_str[t]$. We need to maintain the set of pages currently in the $F$ available frames. To efficiently choose a victim page according to the OPT rule, we use a combination of data structures as specified:\n\n- **A set of resident pages**: To check in $O(1)$ time if a page is currently in memory (a \"hit\" or a \"miss\"). This can be implemented as a boolean array or a hash set. Given integer page identifiers, a simple array `is_resident[page_id]` is most effective.\n\n- **A max-priority queue**: This data structure will store the resident pages, keyed by their next-use index. The page at the root of the max-priority queue is always the one with the largest next-use index, which is precisely the page that should be evicted according to the OPT algorithm. The size of this priority queue is at most $F$. Standard heap operations (insertion, extraction of maximum) take $O(\\log F)$ time.\n\n- **A map from page identifiers to their positions in the priority queue**: When a page that is already resident is accessed (a \"hit\"), its next-use time changes. We must update its key in the priority queue. A standard priority queue does not support an efficient `update-key` operation without first finding the element, which could take $O(F)$ time. To achieve the required logarithmic time complexity, we maintain a separate map (e.g., an array `page_to_heap_idx[page_id]`) that gives us the index of any resident page within the priority queue's underlying array in $O(1)$ time. This allows us to locate the page and update its key in $O(\\log F)$ time by Sifting it up or down to restore the heap property.\n\n**Simulation Steps:**\n\nFor each time step $t$ from $0$ to $n-1$, let $p = ref\\_str[t]$ be the referenced page and $k = next\\_use[t]$ be its next-use index.\n\n1.  **Page Hit**: If page $p$ is in the resident set, it's a hit. No page fault occurs. We must update its priority in the queue to reflect its new next-use time. We find its position in the heap using our $O(1)$ map, update its key to $k$, and restore the heap property. Since we are moving forward in time, the new next-use index is guaranteed to be greater than or equal to the old one's index, so this update corresponds to an increase-key operation, which is implemented with a `sift-up` in a max-heap.\n\n2.  **Page Miss**: If page $p$ is not resident, a page fault occurs. We increment the fault counter.\n    a.  **Frames Available**: If the number of resident pages is less than $F$, we simply add page $p$ to the resident set and insert it into the priority queue with key $k$.\n    b.  **Frames Full**: If all $F$ frames are occupied, we must evict a page. We extract the maximum element from the priority queueâ€”this is our victim page. We remove it from the resident set and then add the new page $p$ to the resident set and insert it into the priority queue with key $k$.\n\nThe total time complexity is the sum of the precomputation time and the simulation time. The precomputation is $O(n+V)$. The simulation involves $n$ steps, each taking at most $O(\\log F)$ for a priority queue operation. Thus, the simulation time is $O(n \\log F)$. Since the number of frames $F$ is at most the length of the string $n$, $\\log F \\le \\log n$. The total complexity is therefore bounded by $O(n \\log n)$, satisfying the problem's requirement.\n\nThe final implementation in C will construct these data structures from scratch, including a binary max-heap implementation that supports the necessary operations coupled with the index map for efficient key updates.", "answer": "```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\n// A node in the max-priority queue (max-heap)\ntypedef struct {\n    int next_use;\n    int page_id;\n} HeapNode;\n\n// Context for the priority queue and its associated mappings\ntypedef struct {\n    HeapNode* heap;\n    int* page_to_heap_idx;\n    int heap_size;\n    int capacity;\n} PQCtx;\n\n// Utility functions for the max-heap\nstatic void swap_nodes(PQCtx* ctx, int i, int j) {\n    HeapNode temp = ctx->heap[i];\n    ctx->heap[i] = ctx->heap[j];\n    ctx->heap[j] = temp;\n    ctx->page_to_heap_idx[ctx->heap[i].page_id] = i;\n    ctx->page_to_heap_idx[ctx->heap[j].page_id] = j;\n}\n\nstatic void sift_up(PQCtx* ctx, int i) {\n    while (i > 0 && ctx->heap[(i - 1) / 2].next_use < ctx->heap[i].next_use) {\n        swap_nodes(ctx, i, (i - 1) / 2);\n        i = (i - 1) / 2;\n    }\n}\n\nstatic void sift_down(PQCtx* ctx, int i) {\n    int max_index = i;\n    int left = 2 * i + 1;\n    if (left < ctx->heap_size && ctx->heap[left].next_use > ctx->heap[max_index].next_use) {\n        max_index = left;\n    }\n    int right = 2 * i + 2;\n    if (right < ctx->heap_size && ctx->heap[right].next_use > ctx->heap[max_index].next_use) {\n        max_index = right;\n    }\n    if (i != max_index) {\n        swap_nodes(ctx, i, max_index);\n        sift_down(ctx, max_index);\n    }\n}\n\nstatic void insert_heap(PQCtx* ctx, HeapNode node) {\n    if (ctx->heap_size >= ctx->capacity) return;\n    ctx->heap_size++;\n    int i = ctx->heap_size - 1;\n    ctx->heap[i] = node;\n    ctx->page_to_heap_idx[node.page_id] = i;\n    sift_up(ctx, i);\n}\n\nstatic HeapNode extract_max(PQCtx* ctx) {\n    HeapNode result = ctx->heap[0];\n    swap_nodes(ctx, 0, ctx->heap_size - 1);\n    ctx->heap_size--;\n    if (ctx->heap_size > 0) {\n        sift_down(ctx, 0);\n    }\n    return result;\n}\n\n/**\n * @brief Calculates the number of page faults for the OPT algorithm.\n * @param ref_str The page reference string.\n * @param n The length of the reference string.\n * @param F The number of available frames.\n * @return The total number of page faults.\n */\nstatic int calculate_opt_faults(const int* ref_str, int n, int F) {\n    if (F <= 0) return n;\n    if (n == 0) return 0;\n\n    // --- Step 1: Precompute next_use array ---\n    int* next_use_arr = malloc(n * sizeof(int));\n    if (!next_use_arr) return -1;\n\n    int max_pid = 0;\n    for (int i = 0; i < n; i++) {\n        if (ref_str[i] > max_pid) {\n            max_pid = ref_str[i];\n        }\n    }\n\n    int* last_seen = malloc((max_pid + 1) * sizeof(int));\n    if (!last_seen) { free(next_use_arr); return -1; }\n    for (int i = 0; i <= max_pid; i++) {\n        last_seen[i] = -1;\n    }\n\n    const int infinity = n + 1;\n    for (int i = n - 1; i >= 0; i--) {\n        int page = ref_str[i];\n        if (last_seen[page] == -1) {\n            next_use_arr[i] = infinity;\n        } else {\n            next_use_arr[i] = last_seen[page];\n        }\n        last_seen[page] = i;\n    }\n    free(last_seen);\n\n    // --- Step 2: Simulate page replacement ---\n    int page_faults = 0;\n    int* is_resident = calloc(max_pid + 1, sizeof(int));\n\n    PQCtx ctx;\n    ctx.heap = malloc(F * sizeof(HeapNode));\n    ctx.page_to_heap_idx = malloc((max_pid + 1) * sizeof(int));\n    \n    if (!is_resident || !ctx.heap || !ctx.page_to_heap_idx) {\n        free(next_use_arr); free(is_resident); free(ctx.heap); free(ctx.page_to_heap_idx);\n        return -1;\n    }\n\n    for (int i = 0; i <= max_pid; i++) {\n        ctx.page_to_heap_idx[i] = -1;\n    }\n    ctx.heap_size = 0;\n    ctx.capacity = F;\n\n    for (int i = 0; i < n; i++) {\n        int page = ref_str[i];\n        \n        if (is_resident[page]) {\n            // Hit: update page's next_use in the heap\n            int heap_idx = ctx.page_to_heap_idx[page];\n            ctx.heap[heap_idx].next_use = next_use_arr[i];\n            sift_up(&ctx, heap_idx);\n        } else {\n            // Miss\n            page_faults++;\n            HeapNode new_node = { .next_use = next_use_arr[i], .page_id = page };\n            if (ctx.heap_size < ctx.capacity) {\n                is_resident[page] = 1;\n                insert_heap(&ctx, new_node);\n            } else {\n                HeapNode victim = extract_max(&ctx);\n                is_resident[victim.page_id] = 0;\n                ctx.page_to_heap_idx[victim.page_id] = -1;\n                \n                is_resident[page] = 1;\n                insert_heap(&ctx, new_node);\n            }\n        }\n    }\n    \n    free(next_use_arr);\n    free(is_resident);\n    free(ctx.heap);\n    free(ctx.page_to_heap_idx);\n    \n    return page_faults;\n}\n\n// A struct to hold the parameters for a single test case.\ntypedef struct {\n    const int* ref_str;\n    int n;\n    int F;\n} TestCase;\n\nint main(void) {\n    const int ts1[] = {1,2,3,4,1,2,5,1,2,3,4,5,6,1,7,2,3,7};\n    const int ts2[] = {9,9,9,9,9};\n    const int ts3[] = {1,2,1,2,1,2};\n    const int ts4[] = {10,20,10,20,30,10,20,30,40,30,40};\n    const int ts5[] = {3,4,5,3,6,7,3,8,3};\n    \n    TestCase test_cases[] = {\n        { ts1, sizeof(ts1)/sizeof(ts1[0]), 3 },\n        { ts2, sizeof(ts2)/sizeof(ts2[0]), 2 },\n        { ts3, sizeof(ts3)/sizeof(ts3[0]), 1 },\n        { ts4, sizeof(ts4)/sizeof(ts4[0]), 4 },\n        { ts5, sizeof(ts5)/sizeof(ts5[0]), 2 },\n    };\n\n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    int* results = malloc(num_cases * sizeof(int));\n    if (!results) return EXIT_FAILURE;\n\n    for (int i = 0; i < num_cases; ++i) {\n        results[i] = calculate_opt_faults(test_cases[i].ref_str, test_cases[i].n, test_cases[i].F);\n    }\n\n    printf(\"[\");\n    for (int i = 0; i < num_cases; ++i) {\n        printf(\"%d\", results[i]);\n        if (i < num_cases - 1) {\n            printf(\",\");\n        }\n    }\n    printf(\"]\");\n\n    free(results);\n    return EXIT_SUCCESS;\n}\n```", "id": "3665680"}]}