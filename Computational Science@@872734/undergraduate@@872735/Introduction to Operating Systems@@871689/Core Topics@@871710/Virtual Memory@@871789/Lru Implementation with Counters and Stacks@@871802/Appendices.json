{"hands_on_practices": [{"introduction": "While the Least Recently Used (LRU) policy focuses on recency, other policies like Least Frequently Used (LFU) focus on overall popularity. This exercise pits the two against each other with a workload that undergoes a \"phase change,\" where the program's focus shifts dramatically. By tracing the behavior of both algorithms, you will discover why LRU's ability to adapt to new patterns of temporal locality is one of its greatest strengths [@problem_id:3655493].", "problem": "Consider a demand-paged system with a fixed working set of memory frames of size $M = 3$, using page replacement when a referenced page is not currently resident. A page fault occurs on any reference to a page not resident. Two classic replacement strategies are often implemented with counters: Least Recently Used (LRU) and Least Frequently Used (LFU). Least Recently Used (LRU) selects for eviction the page whose last access time is furthest in the past; one implementation maintains a stack (most-recently-used at the top, least-recently-used at the bottom) and on each reference moves the page to the top, evicting from the bottom when needed. Least Frequently Used (LFU) selects for eviction the page with the smallest reference count; one implementation maintains per-page frequency counters that increment on each reference, with ties broken by Least Recently Used to make a deterministic choice. Frequency counters are assumed to be persistent across evictions (they do not reset when a page leaves memory).\n\nSome students conflate frequency counters with recency counters and assume they behave similarly. Your task is to reason from the core definitions above and show a workload where LFU counters make strictly worse decisions than LRU recency. Consider the following reference string comprising two phases that model a phase change in the program’s locality:\n\n- Phase $1$: the sequence $\\left(A,B,C\\right)$ repeated $5$ times, for a total of $15$ references.\n- Phase $2$: the sequence $\\left(D,E,F\\right)$ repeated $4$ times, for a total of $12$ references.\n\nAssume the memory starts empty and that all pages $A,B,C,D,E,F$ are distinct. Using only the operational definitions of LRU and LFU given above, determine which statement best captures the page fault counts and the underlying reason for the difference between the two strategies on this workload.\n\nA. LRU incurs $6$ faults while LFU incurs $15$ faults, because LFU’s persistent frequency counters keep the high-frequency but cold pages $A,B,C$ resident throughout Phase $2$, thrashing among $D,E,F$ until their counts can catch up; LRU’s stack property immediately adapts to the phase change by evicting the least-recently-used pages.\n\nB. LRU and LFU both incur $6$ faults on this workload, because recency and frequency coincide when the working set fits in $3$ frames, so counters of either type behave the same.\n\nC. LFU incurs fewer faults ($9$) than LRU ($12$) on this workload, because frequency counters prioritize globally popular pages, whereas recency evicts useful pages too aggressively at phase boundaries.\n\nD. LRU and LFU have identical fault counts on all workloads with distinct pages when ties are broken by Least Recently Used, so any observed difference must be due to implementation overhead rather than policy.", "solution": "To determine the fault counts for each algorithm, we trace the state of the memory (of size $M=3$) for the entire reference string.\n\n**LRU Algorithm Trace**\n\nThe LRU algorithm evicts the page that has been unused for the longest time.\n\n*   **Phase 1: `(A,B,C)` repeated 5 times**\n    1.  `A`: Fault (1). Memory: `[A]`\n    2.  `B`: Fault (2). Memory: `[B, A]`\n    3.  `C`: Fault (3). Memory: `[C, B, A]` (LRU stack: C at top, A at bottom)\n    4.  The following 12 references in Phase 1 (`A, B, C, A, ...`) are all to pages already in memory. Each reference moves the page to the top of the LRU stack, but no new faults occur.\n    *   **Faults in Phase 1 (LRU): 3**\n\n*   **Phase 2: `(D,E,F)` repeated 4 times**\n    1.  At the start of Phase 2, the memory contains `{A, B, C}`. Because the last references were `A,B,C`, the LRU page is `A`.\n    2.  `D`: Fault (4). Evicts `A`. Memory: `{D, C, B}`.\n    3.  `E`: Fault (5). Evicts `B`. Memory: `{E, D, C}`.\n    4.  `F`: Fault (6). Evicts `C`. Memory: `{F, E, D}`.\n    5.  Now the memory contains the new working set `{D, E, F}`. The following 9 references in Phase 2 (`D, E, F, ...`) are all hits.\n    *   **Faults in Phase 2 (LRU): 3**\n\n*   **Total Faults (LRU):** $3 (\\text{Phase 1}) + 3 (\\text{Phase 2}) = 6$ faults.\n\n**LFU Algorithm Trace**\n\nThe LFU algorithm evicts the page with the lowest reference count. Ties are broken by LRU. Counters are persistent.\n\n*   **Phase 1: `(A,B,C)` repeated 5 times**\n    1.  `A`: Fault (1). Mem: `{A}`. Counts: `{A:1}`.\n    2.  `B`: Fault (2). Mem: `{A, B}`. Counts: `{A:1, B:1}`.\n    3.  `C`: Fault (3). Mem: `{A, B, C}`. Counts: `{A:1, B:1, C:1}`.\n    4.  The following 12 references are hits. Each hit increments the corresponding page's counter.\n    *   **End of Phase 1 State:** Memory contains `{A, B, C}`. Counts are `{A:5, B:5, C:5}`.\n    *   **Faults in Phase 1 (LFU): 3**\n\n*   **Phase 2: `(D,E,F)` repeated 4 times**\n    1.  `D`: Fault (4). Eviction needed. All resident pages (`A,B,C`) have a count of 5. LFU tie-breaks with LRU. `A` is the LRU page, so it's evicted. Mem: `{B, C, D}`. Counts: `{A:5, B:5, C:5, D:1}`.\n    2.  `E`: Fault (5). Eviction needed. Resident pages are `B` (count 5), `C` (count 5), and `D` (count 1). LFU evicts `D` (lowest count). Mem: `{B, C, E}`. Counts: `{...D:1, E:1}`.\n    3.  `F`: Fault (6). Eviction needed. Resident pages are `B` (count 5), `C` (count 5), and `E` (count 1). LFU evicts `E`. Mem: `{B, C, F}`. Counts: `{...E:1, F:1}`.\n    4.  `D`: Fault (7). Eviction needed. Resident pages are `B` (count 5), `C` (count 5), and `F` (count 1). LFU evicts `F`. Mem: `{B, C, D}`. Counts: `{...D:2, F:1}`.\n\n    A pattern of thrashing emerges. The pages `B` and `C` are never evicted because their reference count of 5 is never surpassed by the pages `D`, `E`, or `F` (whose maximum count will be 4). This leaves only one memory frame available for the new working set of size 3 (`{D, E, F}`). As a result, every single reference to a page in the new working set that is not the one currently in the single available frame will cause a fault. Since the access pattern is `D,E,F,D,E,F,...`, every access is a fault.\n    *   **Faults in Phase 2 (LFU): 12** (one for each of the 12 references).\n\n*   **Total Faults (LFU):** $3 (\\text{Phase 1}) + 12 (\\text{Phase 2}) = 15$ faults.\n\n**Conclusion**\n\nLRU adapts quickly to the phase change, incurring only 3 faults to load the new working set. LFU, due to its \"memory\" of past frequencies, fails to adapt. It holds on to the \"cold\" but high-frequency pages `B` and `C`, causing severe thrashing throughout Phase 2. The final fault counts are 6 for LRU and 15 for LFU. This matches option A.", "answer": "$$\n\\boxed{A}\n$$", "id": "3655493"}, {"introduction": "A perfect LRU implementation, such as maintaining a full stack of all memory pages, can be prohibitively expensive in terms of hardware resources. This practice problem explores a common engineering trade-off: approximating LRU using resource-efficient, coarse-grained counters that group pages into \"recency buckets.\" Your task is to analyze this approximation scheme and quantify its performance penalty, calculating the probability that it will fail to evict the true least recently used page [@problem_id:3655422].", "problem": "A system designer wishes to replace a full Least Recently Used (LRU) stack with a minimal per-page counter to approximate LRU for eviction decisions. Least Recently Used (LRU) maintains a total order of pages by recency: each resident page has a unique stack position, with position $1$ being most recently referenced and position $N$ being least recently referenced, where $N$ is the number of resident frames. To conserve memory, the designer proposes a counter-based approximation with $b=4$ bits per page that stores only a coarse-grained rank rather than the exact stack position.\n\nThe minimal counter-LRU is constructed as follows. Let $N$ be the number of resident frames, and define a bucket width\n$$\nq \\equiv \\frac{N}{2^{b}}.\n$$\nPartition the LRU stack positions $\\{1,2,\\dots,N\\}$ into $2^{b}$ contiguous buckets of width $q$ each. For a page with true stack position $s \\in \\{1,\\dots,N\\}$, define its stored counter value\n$$\nc(s) \\equiv \\min\\!\\left(\\left\\lfloor \\frac{s-1}{q}\\right\\rfloor,\\,2^{b}-1\\right),\n$$\nwhich maps $s$ into a bucket index $c \\in \\{0,1,\\dots,2^{b}-1\\}$. On eviction, the algorithm selects uniformly at random among pages whose counter equals $2^{b}-1$ (the last bucket), without consulting the exact stack order or timestamps. Assume $N$ is a positive integer multiple of $2^{b}$ so that $q$ is an integer and every bucket contains exactly $q$ pages.\n\nUsing only the fundamental properties of LRU (unique stack order of resident pages) and the symmetry of uniformly random stack orderings under steady-state random references within the resident set, perform the following:\n\n1. Construct the counter mapping $c(s)$ and explain why bucket sizes are equal and why ranking collisions (distinct pages sharing the same counter) necessarily occur.\n2. Derive, from first principles, the probability that two distinct randomly chosen resident pages have the same counter value under the uniform random distribution of stack positions.\n3. Derive the expected mis-eviction rate of the counter-LRU described above, defined as the probability that the algorithm evicts a page that is not the true least recently used page at the time of eviction.\n\nAssume $N=64$ frames and $b=4$ bits. Provide the final results for the collision probability and the mis-eviction rate as decimals. Round your answers to four significant figures. No units are required.", "solution": "The problem asks for an analysis of a counter-based LRU approximation.\n\nFirst, let's compute the system parameters based on the given values $N=64$ and $b=4$.\nThe number of possible counter values (and thus, buckets) is $2^{b} = 2^{4} = 16$.\nThe bucket width is $q \\equiv \\frac{N}{2^{b}} = \\frac{64}{16} = 4$.\n\n**1. Counter Mapping and Collisions**\n\nThe counter value for a page at true stack position $s \\in \\{1, 2, \\dots, N\\}$ is given by $c(s) \\equiv \\min\\!\\left(\\left\\lfloor \\frac{s-1}{q}\\right\\rfloor,\\,2^{b}-1\\right)$.\nWith $N=64$ and $q=4$, the argument of the floor function, $\\frac{s-1}{q}$, ranges from $\\frac{1-1}{4}=0$ for $s=1$ to $\\frac{64-1}{4} = \\frac{63}{4} = 15.75$ for $s=64$.\nThe floor of this argument, $\\left\\lfloor \\frac{s-1}{q}\\right\\rfloor$, therefore ranges from $\\lfloor 0 \\rfloor = 0$ to $\\lfloor 15.75 \\rfloor = 15$.\nThe maximum possible value is $15$, which is equal to $2^{b}-1 = 16-1$. So, the argument of the floor function never produces a value greater than or equal to $2^b$. Consequently, the $\\min$ operator is redundant for the given parameters, and the mapping simplifies to:\n$$\nc(s) = \\left\\lfloor \\frac{s-1}{q}\\right\\rfloor\n$$\nThis function maps the $N$ stack positions to the $2^b$ counter values $\\{0, 1, \\dots, 2^{b}-1\\}$.\n\nTo determine the size of each bucket, we find the set of stack positions $s$ that map to a given counter value $k \\in \\{0, 1, \\dots, 2^{b}-1\\}$.\n$$\nc(s) = k \\implies k = \\left\\lfloor \\frac{s-1}{q}\\right\\rfloor\n$$\nBy the definition of the floor function, this is equivalent to:\n$$\nk \\le \\frac{s-1}{q} < k+1\n$$\nMultiplying by $q$ yields:\n$$\nkq \\le s-1 < (k+1)q\n$$\nAdding $1$ to all parts gives the range of stack positions for bucket $k$:\n$$\nkq+1 \\le s \\le (k+1)q\n$$\nThe number of integer positions in this range is $((k+1)q) - (kq+1) + 1 = kq + q - kq - 1 + 1 = q$.\nThus, each counter value $k$ corresponds to a contiguous block of exactly $q$ stack positions. This confirms that all bucket sizes are equal, as stated in the problem's assumptions. For our parameters, each of the $16$ buckets contains $q=4$ stack positions.\n\nRanking collisions are instances where two or more distinct pages are assigned the same counter value. In this system, there are $N=64$ resident pages, each occupying a unique stack position. The number of available distinct counter values is $2^b=16$. According to the Pigeonhole Principle, if $N$ items (pages) are put into $2^b$ containers (counter values), and $N > 2^b$, then at least one container must hold more than one item. Here, $64 > 16$, so collisions are guaranteed. More specifically, since we have established that each counter value corresponds to $q=4$ stack positions, and each stack position is occupied by a unique page, exactly $q=4$ distinct pages will share any given counter value.\n\n**2. Collision Probability**\n\nWe wish to find the probability that two distinct, randomly chosen resident pages have the same counter value. We assume a uniform random distribution of stack positions, which implies that any permutation of the $N$ pages is equally likely.\n\nLet's select two distinct pages, $P_1$ and $P_2$. Let their stack positions be $s_1$ and $s_2$, respectively. Since the pages are distinct, $s_1 \\neq s_2$. We want to find the probability $P(c(s_1) = c(s_2))$.\n\nConsider page $P_1$. Its stack position $s_1$ falls into one of the $2^b$ buckets. Regardless of which bucket it is, that bucket contains a total of $q$ stack positions. Now, consider page $P_2$. There are $N-1$ remaining stack positions available for it. For $P_2$ to have the same counter as $P_1$, its stack position $s_2$ must be one of the other positions in the same bucket as $s_1$. Since the bucket containing $s_1$ has $q$ positions in total, and one is occupied by $P_1$, there are $q-1$ remaining positions in that bucket.\n\nThe probability that $s_2$ lands in one of these $q-1$ favorable positions, out of the $N-1$ total available positions, is:\n$$\nP(\\text{collision}) = \\frac{q-1}{N-1}\n$$\nUsing the given values $N=64$ and $q=4$:\n$$\nP(\\text{collision}) = \\frac{4-1}{64-1} = \\frac{3}{63} = \\frac{1}{21}\n$$\nAs a decimal, this is $1 \\div 21 \\approx 0.0476190...$. Rounded to four significant figures, the probability is $0.04762$.\n\n**3. Mis-eviction Rate**\n\nA mis-eviction occurs if the algorithm evicts a page that is not the true least recently used (LRU) page. The true LRU page is the one at stack position $s=N$.\n\nThe eviction algorithm identifies all pages with the maximum counter value, $c_{max} = 2^b - 1$, and selects one uniformly at random for eviction. The set of pages eligible for eviction are those whose stack positions $s$ map to this counter value.\nFrom Part 1, the stack positions corresponding to counter $k$ are $s \\in [kq+1, (k+1)q]$. For the last bucket, $k = 2^b - 1$:\n$$\ns \\in [(2^b-1)q+1, (2^b-1+1)q] = [(2^b-1)q+1, 2^b q]\n$$\nSubstituting $N = 2^b q$:\n$$\ns \\in [N-q+1, N]\n$$\nWith $N=64$ and $q=4$, the eviction candidates are the pages at stack positions $\\{61, 62, 63, 64\\}$. This set consists of $q=4$ pages.\nThe true LRU page is at position $s=64$, which is a member of this candidate set.\nThe algorithm selects one page from this set of $q$ pages with uniform probability. A mis-eviction occurs if the selected page is not the one at $s=N$.\n\nThe set of eviction candidates contains one true LRU page and $q-1$ other pages. The probability of selecting any specific page from this set is $\\frac{1}{q}$.\nThe probability of selecting the true LRU page is $\\frac{1}{q}$.\nThe probability of a mis-eviction is the probability of selecting any of the other $q-1$ pages:\n$$\nP(\\text{mis-eviction}) = \\frac{q-1}{q}\n$$\nUsing the value $q=4$:\n$$\nP(\\text{mis-eviction}) = \\frac{4-1}{4} = \\frac{3}{4} = 0.75\n$$\nRounding to four significant figures gives $0.7500$.\n\nThe final results are:\n- Collision Probability: $\\frac{1}{21} \\approx 0.04762$\n- Mis-eviction Rate: $\\frac{3}{4} = 0.7500$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.04762 & 0.7500\n\\end{pmatrix}\n}\n$$", "id": "3655422"}, {"introduction": "Counter-based implementations of LRU seem straightforward, but seemingly minor details can lead to major failures. This problem presents a cautionary tale about a naive counter implementation that uses a finite-bit global timestamp that can wrap around. You will construct an adversarial access pattern that exploits this wrap-around, causing the eviction policy to make catastrophically wrong decisions and leading to a dramatic increase in page faults compared to true LRU [@problem_id:3655499].", "problem": "Consider a demand-paged memory system with cache capacity of $C$ page frames. True Least Recently Used (LRU) is defined as the policy that, on a miss, evicts the page that has not been used for the longest time, which induces the LRU stack property: when comparing two capacities $C_{1}$ and $C_{2}$ with $C_{1} < C_{2}$ under the same reference string, the set of pages held by capacity $C_{1}$ is always a subset of those held by capacity $C_{2}$ at the same time. Now consider an implementation that attempts to realize LRU with per-page counters (call it counter-LRU): it maintains a global $b$-bit counter $t \\in \\{0,1,\\ldots,2^{b}-1\\}$ that increments by $1$ at every reference and wraps modulo $M = 2^{b}$. On each access to page $p$, the page’s stored timestamp $p.\\mathrm{ts}$ is set to the current value of $t$. On a miss, the victim is chosen as the resident page with the numerically smallest $p.\\mathrm{ts}$ (ties are broken by the smallest page identifier). This implementation compares timestamp values as ordinary integers and is unaware of wrap-around, so it does not preserve the true recency order at counter wrap.\n\nYou will construct an adversarial access pattern with cyclic working sets that causes counter-LRU to misorder recency at each phase boundary and thereby fault substantially more than true LRU. Use the following fixed parameters and conventions:\n\n- Let the cache capacity be $C = W$, for some integer $W \\ge 2$.\n- Let there be $2$ disjoint working sets $A = \\{a_{1},\\ldots,a_{W}\\}$ and $B = \\{b_{1},\\ldots,b_{W}\\}$, so that at any time the active working set has size $W$.\n- A phase on working set $X \\in \\{A,B\\}$ consists of $K$ complete rounds over $X$ in a fixed cyclic order without immediate self-repeats (for example, $x_{1},x_{2},\\ldots,x_{W},x_{1},x_{2},\\ldots$ for $K$ rounds), followed by a padding sequence that repeatedly references the final item of $X$ until just before the phase switch the global counter satisfies $t \\equiv M - 1 \\pmod{M}$. Assume $K W \\le M - 1$ so that $t$ does not wrap during a phase.\n- The trace alternates phases $A$ and $B$ forever. The initial cache is empty and the initial counter is $t = 0$.\n\nStarting only from the core definitions above, do the following:\n\n- Construct the explicit adversarial access pattern implied by the description that, at each switch between phases, ensures that the numerical timestamps of the pages in the incoming working set are strictly smaller than those of the outgoing set.\n- Explain why, under counter-LRU, this causes the incoming set to evict itself rather than the outgoing set throughout the phase, and count the steady-state number of faults per phase under counter-LRU.\n- Explain why, under true LRU, once the incoming set is loaded at the start of a phase, all subsequent references within the phase are hits (ignore the initial cold-start of the entire trace and count steady-state faults per phase).\n- Define the blow-up factor $\\rho$ as the ratio of the steady-state number of faults per phase under counter-LRU to that under true LRU for this adversarial trace, and derive a closed-form expression for $\\rho$ in terms of $K$, $W$, and $b$ subject to $K W \\le M - 1$ with $M = 2^{b}$.\n\nYour final answer must be a single closed-form symbolic expression for $\\rho$. No rounding is necessary, and no units are required.", "solution": "The problem requires the construction and analysis of an adversarial access pattern for a counter-based LRU approximation, comparing its performance to true LRU. The goal is to derive the performance blow-up factor $\\rho$.\n\nThe analysis will proceed in four parts:\n1.  Construction of the explicit adversarial access pattern.\n2.  Calculation of the steady-state number of faults per phase for a true LRU cache.\n3.  Calculation of the steady-state number of faults per phase for the counter-LRU implementation.\n4.  Derivation of the blow-up factor $\\rho$.\n\nLet's establish the context based on the provided definitions. The system has a cache of capacity $C=W$ frames. There are two disjoint working sets, $A = \\{a_{1}, \\ldots, a_{W}\\}$ and $B = \\{b_{1}, \\ldots, b_{W}\\}$. The global counter $t$ is a $b$-bit integer, operating modulo $M=2^b$.\n\n**1. Construction of the Adversarial Access Pattern**\n\nThe trace consists of alternating phases on working sets $A$ and $B$. A phase on a working set $X \\in \\{A, B\\}$ with pages $\\{x_1, \\ldots, x_W\\}$ is defined as:\n- A main part, consisting of $K$ full rounds of cyclic access to the pages of $X$: the sequence $(x_1, x_2, \\ldots, x_W)$ is repeated $K$ times. This constitutes $K \\times W$ memory accesses.\n- A padding part, consisting of repeated accesses to the last page, $x_W$, until the global counter $t$ reaches the value $M-1$.\n\nLet's consider the system in steady state, transitioning from a phase on set $A$ to a phase on set $B$. We can analyze the counter values by assuming the phase on set $A$ begins just after a counter wrap-around, so its first access occurs at $t=0$.\n- **Phase A (main part):** The trace is $K$ repetitions of $(a_1, \\ldots, a_W)$. This involves $KW$ accesses. The counter $t$ advances from $0$ to $KW-1$. The last access to page $a_i$ in the final round occurs at time $t = (K-1)W + i - 1$.\n- **Phase A (padding part):** The trace consists of repeated accesses to $a_W$. The counter increments from $KW$ up to $M-1$.\n- **State at the end of Phase A:** The cache contains the set of pages $A = \\{a_1, \\ldots, a_W\\}$. Their timestamps, $p.\\mathrm{ts}$, are the values of the counter $t$ at their last access.\n    - For $i \\in \\{1, \\ldots, W-1\\}$, page $a_i$ was last accessed during the final round of the main part. Thus, $a_i.\\mathrm{ts} = (K-1)W + i - 1$.\n    - Page $a_W$ was accessed last during the padding sequence, at the very end of the phase. Thus, $a_W.\\mathrm{ts} = M-1$.\n- **Start of Phase B:** The next access initiates Phase B. The counter $t$ increments from $M-1$ to $M$, which wraps around to $t=0$.\n    - The first access of Phase B, to page $b_1$, sets $b_1.\\mathrm{ts} = 0$.\n    - The second access, to $b_2$, sets $b_2.\\mathrm{ts} = 1$.\n    - In general, the accesses in the main part of Phase B will assign timestamps from $0$ to $KW-1$ to the pages in set $B$.\n\nThis construction achieves the adversarial condition: at the phase boundary, the resident pages from set $A$ have numerically large timestamps, while the incoming pages from set $B$ receive numerically small timestamps.\n\n**2. Analysis of True LRU**\n\nTrue LRU evicts the page that has not been used for the longest duration. We analyze the number of faults in a single steady-state phase (e.g., Phase B).\n- **Initial state for Phase B:** The cache is full and contains the pages of working set $A$, i.e., $\\{a_1, \\ldots, a_W\\}$. These pages were accessed during the previous phase.\n- **First $W$ accesses of Phase B:** The access sequence is $b_1, b_2, \\ldots, b_W$. Since these pages are not in the cache, each access results in a fault.\n    - Access to $b_1$: Miss. The least recently used page in the cache is $a_1$ (it was accessed earliest among all pages in $A$ during the last round of Phase A). $a_1$ is evicted. $b_1$ is loaded.\n    - Access to $b_2$: Miss. The least recently used page is now $a_2$. $a_2$ is evicted. $b_2$ is loaded.\n    - ...\n    - Access to $b_W$: Miss. The least recently used page is $a_W$. $a_W$ is evicted. $b_W$ is loaded.\n- **State after $W$ accesses:** After these initial $W$ faults, the cache contains exactly the working set $B$, i.e., $\\{b_1, \\ldots, b_W\\}$.\n- **Subsequent accesses in Phase B:** The remaining $(K-1)W$ accesses in the main part, and all accesses in the padding part, are to pages in set $B$. Since the entire working set $B$ is now resident in the cache of capacity $C=W$, all these subsequent accesses are hits.\n- **Fault Count:** The total number of faults per phase for true LRU is the number of compulsory misses required to load the new working set.\n$$\nN_{\\mathrm{LRU}} = W\n$$\n\n**3. Analysis of Counter-LRU**\n\nCounter-LRU evicts the resident page with the numerically smallest timestamp. We analyze its performance on the same steady-state Phase B.\n- **Initial state for Phase B:** The cache contains pages $\\{a_1, \\ldots, a_W\\}$. Their timestamps are $\\{(K-1)W, (K-1)W+1, \\ldots, KW-2, M-1\\}$.\n- **Core Argument:** We demonstrate that at least one page from set $A$ remains in the cache throughout the main part of Phase B.\n    - The page $a_W$ has timestamp $a_W.\\mathrm{ts} = M-1$.\n    - During the main part of Phase B, the global counter $t$ ranges from $0$ to $KW-1$. Any timestamp $p.\\mathrm{ts}$ assigned to a page in set $B$ during this part is therefore less than or equal to $KW-1$.\n    - The problem states the constraint $KW \\le M-1$, which implies $KW-1  M-1$.\n    - Therefore, for any page $b_j$ accessed during the main part of Phase B, its timestamp $b_j.\\mathrm{ts}$ will be strictly smaller than $a_W.\\mathrm{ts}$.\n    - Since counter-LRU evicts the page with the minimum timestamp, and $a_W$'s timestamp is always larger than any timestamp of a page in set $B$ (during the main phase), $a_W$ will never be a candidate for eviction during the main part of Phase B.\n- **Consequence:** Throughout the $KW$ accesses of the main part of Phase B, at least one frame is occupied by an A-page ($a_W$). This means the effective cache size available for the working set $B$ is at most $W-1$ frames.\n- The access pattern for set $B$ is a cyclic sequence over $W$ distinct pages. It is a classic result in caching theory that a cyclic access pattern on a working set of size $W$ in a cache of size less than $W$ results in a fault on every access.\n- Since the $W$ pages of set $B$ are competing for at most $W-1$ frames, every one of the $KW$ accesses $(b_1, \\ldots, b_W, \\ldots)$ during the main part of the phase will result in a miss.\n- The padding accesses to $b_W$ will be hits, as the very last access of the main part is to $b_W$, which loads it into the cache.\n- **Fault Count:** The total number of faults per phase for counter-LRU is equal to the number of accesses in the main part of the phase.\n$$\nN_{\\mathrm{C-LRU}} = K W\n$$\n\n**4. Derivation of the Blow-up Factor $\\rho$**\n\nThe blow-up factor $\\rho$ is defined as the ratio of the steady-state number of faults per phase under counter-LRU to that under true LRU.\n$$\n\\rho = \\frac{N_{\\mathrm{C-LRU}}}{N_{\\mathrm{LRU}}}\n$$\nSubstituting the derived fault counts:\n$$\n\\rho = \\frac{KW}{W}\n$$\nThe factor $W$ cancels out.\n$$\n\\rho = K\n$$\nThe expression for the blow-up factor $\\rho$ is simply $K$. This result depends on the parameter $K$, which sets the number of rounds per phase. The parameters $W$ and $b$ are embedded in the problem's premise ($C=W$, $M=2^b$, $KW \\le M-1$) that makes the adversarial pattern effective, but they do not appear in the final expression for the ratio of faults.", "answer": "$$\\boxed{K}$$", "id": "3655499"}]}