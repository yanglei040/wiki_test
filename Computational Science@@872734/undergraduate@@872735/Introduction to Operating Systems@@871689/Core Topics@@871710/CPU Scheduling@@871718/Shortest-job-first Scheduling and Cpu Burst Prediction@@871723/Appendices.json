{"hands_on_practices": [{"introduction": "To truly grasp the power of the Shortest-Job-First (SJF) scheduling algorithm, we begin by analyzing its performance in an ideal, simplified world. This first exercise challenges you to derive the worst-case waiting time for a set of jobs under non-preemptive SJF, assuming the scheduler has perfect knowledge of future CPU bursts [@problem_id:3682864]. By working through this theoretical scenario, you will establish a crucial performance benchmark and build a foundational understanding of why SJF is considered optimal under these conditions.", "problem": "Consider $n$ independent jobs $J_1, J_2, \\dots, J_n$ that arrive simultaneously at time $0$ and each consists of a single Central Processing Unit (CPU) burst. Let the true CPU burst lengths be $b_1, b_2, \\dots, b_n$ with $b_1 < b_2 < \\dots < b_n$. A non-preemptive Shortest-Job-First (SJF) scheduler is used, and the scheduler’s CPU burst predictions are perfect, meaning the predicted burst for each $J_i$ equals its true burst $b_i$. Assume there is no context-switch overhead and no input/output blocking; once a job begins its CPU burst, it runs to completion.\n\nStarting only from the core definitions of waiting time and the non-preemptive SJF selection rule, derive a closed-form analytic expression for the maximum waiting time experienced by any job among $J_1, \\dots, J_n$ in this scenario. The waiting time $W_i$ for job $J_i$ is defined as the time elapsed from its arrival until the instant it first begins execution on the CPU. Express your final answer symbolically in terms of $b_1, \\dots, b_n$ using sigma notation where appropriate, and do not include units in your expression.", "solution": "The problem will first be validated for scientific soundness, self-consistency, and clarity before a solution is attempted.\n\n### Step 1: Extract Givens\nThe problem statement provides the following information:\n- A set of $n$ independent jobs, $J_1, J_2, \\dots, J_n$.\n- All jobs arrive simultaneously at time $0$.\n- Each job consists of a single CPU burst.\n- The true CPU burst lengths are $b_1, b_2, \\dots, b_n$.\n- The burst lengths are strictly ordered: $b_1 < b_2 < \\dots < b_n$.\n- The scheduling algorithm is non-preemptive Shortest-Job-First (SJF).\n- The scheduler's predictions are perfect, meaning the predicted burst for job $J_i$ is its true burst, $b_i$.\n- There is no context-switch overhead.\n- There is no input/output blocking.\n- The waiting time $W_i$ for job $J_i$ is defined as the time from its arrival until it begins execution.\n- The objective is to derive a closed-form analytic expression for the maximum waiting time among all jobs.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the established criteria:\n- **Scientifically Grounded**: The problem is a classic theoretical exercise in the study of CPU scheduling algorithms within the field of operating systems. Shortest-Job-First scheduling, waiting time, and CPU bursts are all fundamental, well-established concepts. The simplifying assumptions (simultaneous arrival, no overhead) are standard for isolating and analyzing the core behavior of the algorithm.\n- **Well-Posed**: The problem is clearly defined. The strict inequality $b_1 < b_2 < \\dots < b_n$ eliminates any ambiguity in job selection, as there are no ties in burst length. The non-preemptive nature and perfect prediction ensure a deterministic and unique execution sequence. Therefore, a unique, stable, and meaningful solution exists.\n- **Objective**: The problem is stated using precise, unambiguous terminology standard to computer science. All parameters and definitions are objective.\n\nThe problem does not exhibit any of the flaws listed in the validation criteria (e.g., scientific unsoundness, incompleteness, ambiguity). It is a well-structured question rooted in established computer science theory.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be derived.\n\n### Derivation of the Solution\nThe objective is to find the maximum waiting time, $\\max\\{W_1, W_2, \\dots, W_n\\}$. We begin by analyzing the execution order of the jobs under the non-preemptive Shortest-Job-First (SJF) scheduling policy.\n\n1.  **Execution Order**:\n    - At time $t=0$, all $n$ jobs ($J_1, \\dots, J_n$) are in the ready queue.\n    - The SJF scheduler selects the job with the shortest predicted CPU burst. Since predictions are perfect, it selects the job with the smallest true burst length, $b_i$.\n    - From the given condition $b_1 < b_2 < \\dots < b_n$, the job with the absolute shortest burst length is $J_1$.\n    - Therefore, at time $t=0$, job $J_1$ is selected for execution.\n    - Because the scheduling is non-preemptive, $J_1$ runs to completion. It starts at time $0$ and finishes at time $b_1$.\n    - At time $t=b_1$, job $J_1$ is complete. The remaining jobs are $J_2, J_3, \\dots, J_n$.\n    - The scheduler again applies the SJF rule. Among the remaining jobs, $J_2$ has the shortest burst length, $b_2$.\n    - Therefore, job $J_2$ is selected next. It starts at time $b_1$ and runs to completion, finishing at time $b_1 + b_2$.\n    - This process continues sequentially. After jobs $J_1, \\dots, J_{k-1}$ have completed, the scheduler will select job $J_k$ as it has the shortest burst length among the remaining jobs.\n    - The resulting execution order is deterministically $J_1, J_2, J_3, \\dots, J_n$.\n\n2.  **Waiting Time for an Arbitrary Job $J_k$**:\n    - The waiting time for job $J_k$, denoted $W_k$, is the time elapsed from its arrival until its execution begins.\n    - All jobs arrive at time $0$. The waiting time is therefore equal to the job's start time.\n    - Job $J_1$ starts at time $0$. Its waiting time is $W_1 = 0$.\n    - Job $J_2$ starts after $J_1$ completes. Its start time is $b_1$. Its waiting time is $W_2 = b_1$.\n    - Job $J_3$ starts after $J_1$ and $J_2$ complete. Its start time is $b_1 + b_2$. Its waiting time is $W_3 = b_1 + b_2$.\n    - Generalizing, job $J_k$ starts after jobs $J_1, J_2, \\dots, J_{k-1}$ have all completed. The start time of $J_k$ is the sum of the burst times of these preceding jobs.\n    - The waiting time for job $J_k$ is given by:\n    $$W_k = \\sum_{i=1}^{k-1} b_i$$\n    This formula is valid for $k \\ge 2$. For $k=1$, the sum is over an empty set, which is correctly defined as $0$, so $W_1 = 0$.\n\n3.  **Maximum Waiting Time**:\n    - We need to find the maximum value in the set of waiting times $\\{W_1, W_2, \\dots, W_n\\}$.\n    - The waiting times form a sequence:\n        - $W_1 = 0$\n        - $W_2 = b_1$\n        - $W_3 = b_1 + b_2$\n        - ...\n        - $W_n = b_1 + b_2 + \\dots + b_{n-1}$\n    - A CPU burst length $b_i$ represents a duration of time and must be positive, so $b_i > 0$ for all $i \\in \\{1, \\dots, n\\}$.\n    - Consider the difference between consecutive waiting times, for $k \\ge 2$:\n    $$W_k - W_{k-1} = \\left(\\sum_{i=1}^{k-1} b_i\\right) - \\left(\\sum_{i=1}^{k-2} b_i\\right) = b_{k-1}$$\n    - Since $b_{k-1} > 0$, it follows that $W_k > W_{k-1}$ for all $k \\ge 2$.\n    - This proves that the sequence of waiting times is strictly increasing: $W_1 < W_2 < \\dots < W_n$.\n    - The maximum value in a strictly increasing sequence is its last element.\n    - Therefore, the maximum waiting time is $W_n$.\n\n4.  **Final Expression**:\n    - The maximum waiting time is $W_n$, which is the sum of the burst lengths of all jobs that executed before $J_n$. These are jobs $J_1, \\dots, J_{n-1}$.\n    - The final closed-form expression for the maximum waiting time is:\n    $$\\max_{k \\in \\{1,\\dots,n\\}} W_k = W_n = \\sum_{i=1}^{n-1} b_i$$", "answer": "$$\\boxed{\\sum_{i=1}^{n-1} b_i}$$", "id": "3682864"}, {"introduction": "Of course, real-world schedulers cannot see the future; they must rely on predictions. This practice transitions from the ideal world of perfect knowledge to the practical challenge of implementation [@problem_id:3682812]. You will build a scheduler that uses a sophisticated, adaptive learning algorithm to predict CPU bursts and then empirically evaluate its performance. By comparing the results of your predictive scheduler to both the ideal SJF and a simple First-Come-First-Served (FCFS) baseline, you will gain a concrete appreciation for how prediction quality directly impacts system efficiency and fairness.", "problem": "Consider a single-processor, non-preemptive Shortest-Job-First (SJF) scheduler that orders ready jobs by their predicted next Central Processing Unit (CPU) burst. Each job exhibits a sequence of observed CPU bursts, modeled as an independent and identically distributed (i.i.d.) stochastic process with finite expectation $E[b]$ and finite variance. Let the predictor be updated by a stochastic approximation of the form\n$$\n\\tau_{k+1}=\\tau_k+\\alpha_k\\left(b_k-\\tau_k\\right),\n$$\nwhere $\\tau_k$ is the prediction after $k$ observations and $b_k$ is the $k$-th observed CPU burst. The step sizes $\\alpha_k$ must be positive and monotonically non-increasing, and they should satisfy the canonical stochastic-approximation convergence constraints\n$$\n\\sum_{k=0}^{\\infty}\\alpha_k=\\infty\\quad\\text{and}\\quad\\sum_{k=0}^{\\infty}\\alpha_k^2<\\infty.\n$$\nStarting from these constraints and the definition of SJF scheduling, derive a rationally-parameterized, decreasing step-size schedule that depends only on two positive constants, denoted $\\,\\alpha_0\\,$ and $\\,\\beta\\,$, and justify mathematically that it satisfies the above series conditions when $\\,\\beta>0\\,$. Then, implement a program that uses this schedule to predict each job’s next CPU burst from its history and evaluates practical scheduling outcomes.\n\nAssume the following for implementation:\n- The initial prediction is set to the known expectation $\\,\\tau_0=E[b]\\,$ for each job.\n- All jobs are ready at time $\\,t=0\\,$.\n- Scheduling is non-preemptive.\n- Waiting and turnaround times must be computed in milliseconds (ms), and all outputs must be expressed in ms as real numbers.\n\nYour program must, for each test case below:\n- Compute each job’s predicted next burst $\\,\\tau_{\\text{pred}}\\,$ from its history using your derived step-size schedule.\n- Schedule the jobs by their predicted next bursts in ascending order (predicted SJF), compute the average waiting time and the average turnaround time (both in ms).\n- For comparison, compute the same metrics for the ideal SJF that uses the actual next bursts $\\,b_{\\text{next}}\\,$ and for First-Come-First-Served (FCFS), which uses the original job index order.\n- Compute the mean absolute error (MAE) between $\\,\\tau_{\\text{pred}}\\,$ and $\\,b_{\\text{next}}\\,$ (in ms).\n- Compute the average absolute deviation of $\\,\\tau_{\\text{pred}}\\,$ from $\\,E[b]\\,$ (in ms).\n\nTest suite (all burst lengths are in milliseconds):\n- Test case $\\,1\\,$ (happy path): $\\,\\alpha_0=1.0\\,$, $\\,\\beta=0.1\\,$, $\\,E[b]=10.0\\,$, $\\,5\\,$ jobs with histories and actual next bursts\n  - Job $\\,0\\,$: history $\\,\\{9.5,10.2,11.0\\}\\,$, $\\,b_{\\text{next}}=10.8\\,$.\n  - Job $\\,1\\,$: history $\\,\\{13.0,12.0,11.5,10.5\\}\\,$, $\\,b_{\\text{next}}=9.0\\,$.\n  - Job $\\,2\\,$: history $\\,\\{8.0,9.2\\}\\,$, $\\,b_{\\text{next}}=7.8\\,$.\n  - Job $\\,3\\,$: history $\\,\\{10.0,9.8,10.2,9.7,10.1\\}\\,$, $\\,b_{\\text{next}}=9.9\\,$.\n  - Job $\\,4\\,$: history $\\,\\{14.0\\}\\,$, $\\,b_{\\text{next}}=12.0\\,$.\n- Test case $\\,2\\,$ (boundary, nearly constant step size): $\\,\\alpha_0=0.9\\,$, $\\,\\beta=0.0\\,$, $\\,E[b]=20.0\\,$, $\\,4\\,$ jobs\n  - Job $\\,0\\,$: history $\\,\\{18.0,22.0\\}\\,$, $\\,b_{\\text{next}}=21.0\\,$.\n  - Job $\\,1\\,$: history $\\,\\{30.0,28.0,26.0\\}\\,$, $\\,b_{\\text{next}}=25.0\\,$.\n  - Job $\\,2\\,$: history $\\,\\{10.0,12.0,9.0,11.0\\}\\,$, $\\,b_{\\text{next}}=13.0\\,$.\n  - Job $\\,3\\,$: history $\\,\\{20.0\\}\\,$, $\\,b_{\\text{next}}=20.0\\,$.\n- Test case $\\,3\\,$ (edge, fast decay): $\\,\\alpha_0=1.0\\,$, $\\,\\beta=1.0\\,$, $\\,E[b]=5.0\\,$, $\\,6\\,$ jobs\n  - Job $\\,0\\,$: history $\\,\\{4.0,6.0,5.0,5.0,4.0,5.0\\}\\,$, $\\,b_{\\text{next}}=5.0\\,$.\n  - Job $\\,1\\,$: history $\\,\\{9.0,7.0,8.0\\}\\,$, $\\,b_{\\text{next}}=6.0\\,$.\n  - Job $\\,2\\,$: history $\\,\\{3.5,3.0\\}\\,$, $\\,b_{\\text{next}}=3.0\\,$.\n  - Job $\\,3\\,$: history $\\,\\{5.1\\}\\,$, $\\,b_{\\text{next}}=5.5\\,$.\n  - Job $\\,4\\,$: history $\\,\\{6.0,5.5,4.8,5.2,5.0,4.9,5.1,5.0\\}\\,$, $\\,b_{\\text{next}}=5.0\\,$.\n  - Job $\\,5\\,$: history $\\,\\{2.0,2.5,3.0\\}\\,$, $\\,b_{\\text{next}}=2.2\\,$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets.\n- For each test case, output eight real numbers in this order:\n  $[\\text{MAE},\\text{AvgWait}_{\\text{predSJF}},\\text{AvgTurn}_{\\text{predSJF}},\\text{AvgWait}_{\\text{trueSJF}},\\text{AvgTurn}_{\\text{trueSJF}},\\text{AvgWait}_{\\text{FCFS}},\\text{AvgTurn}_{\\text{FCFS}},\\text{AvgAbsDevTo}\\ E[b]]$.\n- Aggregate all test cases sequentially into a single flat list on one line, for example\n$[\\text{tc1\\_metric1},\\dots,\\text{tc1\\_metric8},\\text{tc2\\_metric1},\\dots,\\text{tc3\\_metric8}]$.", "solution": "The problem statement has been meticulously reviewed and is determined to be valid. It is scientifically grounded in the principles of operating system scheduling and stochastic approximation theory, is well-posed, and provides a complete and consistent set of requirements and data for a solvable problem. The inclusion of a test case with a parameter $\\,\\beta=0\\,$ falls outside the conditions for which theoretical convergence is to be proven ($\\,\\beta>0\\,$) but does not create a logical contradiction; rather, it represents a valid boundary case for which the derived update rule remains computationally well-defined.\n\nThe solution proceeds in two parts: first, the derivation and justification of the step-size schedule, and second, the detailed methodology for computing the required performance metrics.\n\n### Step 1: Derivation and Justification of the Step-Size Schedule\n\nThe problem requires the derivation of a rationally-parameterized, decreasing step-size schedule, denoted $\\,\\alpha_k\\,$, that depends on two positive constants, $\\,\\alpha_0\\,$ and $\\,\\beta\\,$. A suitable and common choice for such a schedule in stochastic approximation is:\n$$\n\\alpha_k = \\frac{\\alpha_0}{1 + \\beta k}\n$$\nThis schedule satisfies the stated requirements for $\\,\\alpha_0 > 0\\,$ and $\\,\\beta > 0\\,$:\n1.  It is a rational function of the step index $\\,k\\,$.\n2.  It depends only on the parameters $\\,\\alpha_0\\,$ and $\\,\\beta\\,$. For $\\,k=0\\,$, $\\,\\alpha_0 = \\frac{\\alpha_0}{1+0}\\,$ is consistent.\n3.  Given $\\,\\beta > 0\\,$, the denominator $\\,1 + \\beta k\\,$ is a strictly increasing function of $\\,k\\,$, thus $\\,\\alpha_k\\,$ is positive and monotonically non-increasing.\n\nWe must now demonstrate that this schedule satisfies the canonical Robbins-Monro convergence constraints for $\\,\\beta > 0\\,$.\n\n**Constraint 1: $\\,\\sum_{k=0}^{\\infty} \\alpha_k = \\infty\\,$ (Divergence of the series)**\n\nWe need to prove that the series $\\,\\sum_{k=0}^{\\infty} \\frac{\\alpha_0}{1 + \\beta k}\\,$ diverges. We can use the Limit Comparison Test. Let our series term be $\\,a_k = \\frac{\\alpha_0}{1 + \\beta k}\\,$. We compare it to the term of the harmonic series, $\\,c_k = \\frac{1}{k}\\,$, which is known to diverge.\n\nWe evaluate the limit of the ratio:\n$$\n\\lim_{k \\to \\infty} \\frac{a_k}{c_k} = \\lim_{k \\to \\infty} \\frac{\\frac{\\alpha_0}{1 + \\beta k}}{\\frac{1}{k}} = \\lim_{k \\to \\infty} \\frac{\\alpha_0 k}{1 + \\beta k}\n$$\nDividing the numerator and denominator by $\\,k\\,$ gives:\n$$\n\\lim_{k \\to \\infty} \\frac{\\alpha_0}{\\frac{1}{k} + \\beta} = \\frac{\\alpha_0}{\\beta}\n$$\nSince $\\,\\alpha_0 > 0\\,$ and $\\,\\beta > 0\\,$, the limit $\\,\\frac{\\alpha_0}{\\beta}\\,$ is a finite positive constant. By the Limit Comparison Test, since the harmonic series $\\,\\sum_{k=1}^{\\infty} \\frac{1}{k}\\,$ diverges, the series $\\,\\sum_{k=0}^{\\infty} \\alpha_k\\,$ must also diverge. The first constraint is satisfied.\n\n**Constraint 2: $\\,\\sum_{k=0}^{\\infty} \\alpha_k^2 < \\infty\\,$ (Convergence of the series of squares)**\n\nWe need to prove that the series $\\,\\sum_{k=0}^{\\infty} \\alpha_k^2 = \\sum_{k=0}^{\\infty} \\frac{\\alpha_0^2}{(1 + \\beta k)^2}\\,$ converges. We again use the Limit Comparison Test, this time comparing with the term of a convergent p-series, $\\,d_k = \\frac{1}{k^2}\\,$ (where $\\,p=2>1\\,$). Let our series term be $\\,b_k = \\frac{\\alpha_0^2}{(1 + \\beta k)^2}\\,$.\n\nWe evaluate the limit of the ratio:\n$$\n\\lim_{k \\to \\infty} \\frac{b_k}{d_k} = \\lim_{k \\to \\infty} \\frac{\\frac{\\alpha_0^2}{(1 + \\beta k)^2}}{\\frac{1}{k^2}} = \\lim_{k \\to \\infty} \\frac{\\alpha_0^2 k^2}{(1 + \\beta k)^2} = \\lim_{k \\to \\infty} \\frac{\\alpha_0^2 k^2}{1 + 2\\beta k + \\beta^2 k^2}\n$$\nDividing the numerator and denominator by $\\,k^2\\,$ gives:\n$$\n\\lim_{k \\to \\infty} \\frac{\\alpha_0^2}{\\frac{1}{k^2} + \\frac{2\\beta}{k} + \\beta^2} = \\frac{\\alpha_0^2}{\\beta^2}\n$$\nThis limit is a finite positive constant. Since the p-series $\\,\\sum_{k=1}^{\\infty} \\frac{1}{k^2}\\,$ converges, the series $\\,\\sum_{k=0}^{\\infty} \\alpha_k^2\\,$ must also converge. The second constraint is satisfied.\n\nThus, the schedule $\\,\\alpha_k = \\frac{\\alpha_0}{1 + \\beta k}\\,$ is a valid choice.\n\n### Step 2: Methodology for Prediction and Performance Evaluation\n\n**A. CPU Burst Prediction**\nFor each job, its next CPU burst is predicted based on its historical burst lengths. Let a job's history be a sequence of $\\,N\\,$ observed bursts $\\,\\{b_0, b_1, \\ldots, b_{N-1}\\}\\,$. The prediction process starts with an initial estimate $\\,\\tau_0 = E[b]\\,$, as specified. The estimate is iteratively updated using the derived schedule:\n$$\n\\tau_{k+1} = \\tau_k + \\alpha_k(b_k - \\tau_k) \\quad \\text{for } k = 0, 1, \\ldots, N-1\n$$\nwhere $\\,\\alpha_k = \\frac{\\alpha_0}{1 + \\beta k}\\,$. After iterating through all $\\,N\\,$ historical bursts, the final estimate $\\,\\tau_N\\,$ is taken as the predicted next burst, $\\,\\tau_{\\text{pred}} = \\tau_N\\,$.\n\n**B. Scheduling Metrics**\nSince all jobs arrive at time $\\,t=0\\,$ and scheduling is non-preemptive, the calculation of waiting and turnaround times for a sequence of jobs is straightforward. Let the jobs in a scheduled sequence of length $\\,J\\,$ be indexed $\\,p_0, p_1, \\ldots, p_{J-1}\\,$, where $\\,p_i\\,$ is the original identifier of the $\\,i\\,$-th job to be executed. The burst time for job $\\,j\\,$ is its actual next burst, $\\,b_{\\text{next}, j}\\,$.\n\nThe completion time $\\,C_{p_i}\\,$ of job $\\,p_i\\,$ is the sum of the actual burst times of all preceding jobs in the sequence, plus its own burst time:\n$$\nC_{p_i} = \\sum_{j=0}^{i} b_{\\text{next}, p_j}\n$$\nThe turnaround time for job $\\,p_i\\,$ is $\\,T_{p_i} = C_{p_i} - A_{p_i} = C_{p_i}\\,$, since arrival time $\\,A_{p_i} = 0\\,$.\nThe waiting time for job $\\,p_i\\,$ is $\\,W_{p_i} = T_{p_i} - b_{\\text{next}, p_i} = C_{p_{i-1}}\\,$ (with $\\,C_{p_{-1}}=0\\,$).\n$$\nW_{p_i} = \\sum_{j=0}^{i-1} b_{\\text{next}, p_j}\n$$\nThe average waiting time and average turnaround time are then computed over all $\\,J\\,$ jobs.\n\n**C. Evaluation Scenarios**\nThe problem requires an evaluation under three different scheduling disciplines:\n1.  **Predicted SJF**: Jobs are sorted in ascending order of their predicted bursts $\\,\\tau_{\\text{pred}}\\,$ (with original job index as a tie-breaker). The scheduling metrics are then computed using this order and the jobs' *actual* next bursts $\\,b_{\\text{next}}\\,$.\n2.  **True SJF**: Jobs are sorted in ascending order of their *actual* next bursts $\\,b_{\\text{next}}\\,$ (with original job index as a tie-breaker). This represents the ideal, optimal SJF scheduling.\n3.  **First-Come-First-Served (FCFS)**: Jobs are processed in their original order (index $\\,0, 1, 2, \\ldots\\,$).\n\n**D. Error Metrics**\nTwo error metrics are computed:\n1.  **Mean Absolute Error (MAE)**: Measures the average prediction accuracy.\n    $$\n    \\text{MAE} = \\frac{1}{J} \\sum_{j=0}^{J-1} |\\tau_{\\text{pred}, j} - b_{\\text{next}, j}|\n    $$\n2.  **Average Absolute Deviation from $\\,E[b]\\,$**: Measures the average deviation of predictions from the long-term process mean.\n    $$\n    \\text{AvgAbsDev} = \\frac{1}{J} \\sum_{j=0}^{J-1} |\\tau_{\\text{pred}, j} - E[b]|\n    $$\n\nThe implementation will systematically apply these steps to each test case, calculating the eight specified metrics and aggregating them into a single-line output.", "answer": "```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n\n// Data structure for a single job's input data\ntypedef struct {\n    int id;\n    const double* history;\n    int history_len;\n    double b_next;\n} JobData;\n\n// Data structure for a complete test case\ntypedef struct {\n    double alpha0;\n    double beta;\n    double E_b;\n    const JobData* jobs;\n    int num_jobs;\n} TestCase;\n\n// Data structure to hold calculated metrics for a job, used for sorting\ntypedef struct {\n    int original_id;\n    double predicted_burst;\n    double actual_burst;\n} JobMetrics;\n\n// Data structure to hold scheduling results\ntypedef struct {\n    double avg_wait_time;\n    double avg_turnaround_time;\n} SchedulingResult;\n\n// Comparison function for qsort, sorting by predicted burst time\nint compare_jobs_predicted(const void* a, const void* b) {\n    const JobMetrics* job_a = (const JobMetrics*)a;\n    const JobMetrics* job_b = (const JobMetrics*)b;\n    if (job_a->predicted_burst < job_b->predicted_burst) return -1;\n    if (job_a->predicted_burst > job_b->predicted_burst) return 1;\n    // Tie-break with original ID for stable sort\n    if (job_a->original_id < job_b->original_id) return -1;\n    if (job_a->original_id > job_b->original_id) return 1;\n    return 0;\n}\n\n// Comparison function for qsort, sorting by actual burst time\nint compare_jobs_actual(const void* a, const void* b) {\n    const JobMetrics* job_a = (const JobMetrics*)a;\n    const JobMetrics* job_b = (const JobMetrics*)b;\n    if (job_a->actual_burst < job_b->actual_burst) return -1;\n    if (job_a->actual_burst > job_b->actual_burst) return 1;\n    // Tie-break with original ID for stable sort\n    if (job_a->original_id < job_b->original_id) return -1;\n    if (job_a->original_id > job_b->original_id) return 1;\n    return 0;\n}\n\n// Calculates average waiting and turnaround times for a given job order\nSchedulingResult calculate_scheduling_metrics(const JobMetrics jobs[], int num_jobs) {\n    double total_wait_time = 0.0;\n    double total_turnaround_time = 0.0;\n    double current_time = 0.0;\n\n    for (int i = 0; i < num_jobs; ++i) {\n        // Waiting time for job i is the completion time of job i-1\n        total_wait_time += current_time;\n        \n        // Update current time with the burst of the current job\n        current_time += jobs[i].actual_burst;\n        \n        // Turnaround time for job i is its completion time\n        total_turnaround_time += current_time;\n    }\n\n    SchedulingResult result;\n    result.avg_wait_time = total_wait_time / num_jobs;\n    result.avg_turnaround_time = total_turnaround_time / num_jobs;\n    return result;\n}\n\nint main(void) {\n    // --- Test Case 1 Data ---\n    const double hist1_0[] = {9.5, 10.2, 11.0};\n    const double hist1_1[] = {13.0, 12.0, 11.5, 10.5};\n    const double hist1_2[] = {8.0, 9.2};\n    const double hist1_3[] = {10.0, 9.8, 10.2, 9.7, 10.1};\n    const double hist1_4[] = {14.0};\n    const JobData jobs1[] = {\n        {0, hist1_0, sizeof(hist1_0)/sizeof(double), 10.8},\n        {1, hist1_1, sizeof(hist1_1)/sizeof(double), 9.0},\n        {2, hist1_2, sizeof(hist1_2)/sizeof(double), 7.8},\n        {3, hist1_3, sizeof(hist1_3)/sizeof(double), 9.9},\n        {4, hist1_4, sizeof(hist1_4)/sizeof(double), 12.0}\n    };\n\n    // --- Test Case 2 Data ---\n    const double hist2_0[] = {18.0, 22.0};\n    const double hist2_1[] = {30.0, 28.0, 26.0};\n    const double hist2_2[] = {10.0, 12.0, 9.0, 11.0};\n    const double hist2_3[] = {20.0};\n    const JobData jobs2[] = {\n        {0, hist2_0, sizeof(hist2_0)/sizeof(double), 21.0},\n        {1, hist2_1, sizeof(hist2_1)/sizeof(double), 25.0},\n        {2, hist2_2, sizeof(hist2_2)/sizeof(double), 13.0},\n        {3, hist2_3, sizeof(hist2_3)/sizeof(double), 20.0}\n    };\n\n    // --- Test Case 3 Data ---\n    const double hist3_0[] = {4.0, 6.0, 5.0, 5.0, 4.0, 5.0};\n    const double hist3_1[] = {9.0, 7.0, 8.0};\n    const double hist3_2[] = {3.5, 3.0};\n    const double hist3_3[] = {5.1};\n    const double hist3_4[] = {6.0, 5.5, 4.8, 5.2, 5.0, 4.9, 5.1, 5.0};\n    const double hist3_5[] = {2.0, 2.5, 3.0};\n    const JobData jobs3[] = {\n        {0, hist3_0, sizeof(hist3_0)/sizeof(double), 5.0},\n        {1, hist3_1, sizeof(hist3_1)/sizeof(double), 6.0},\n        {2, hist3_2, sizeof(hist3_2)/sizeof(double), 3.0},\n        {3, hist3_3, sizeof(hist3_3)/sizeof(double), 5.5},\n        {4, hist3_4, sizeof(hist3_4)/sizeof(double), 5.0},\n        {5, hist3_5, sizeof(hist3_5)/sizeof(double), 2.2}\n    };\n\n    // --- Test Suite Definition ---\n    const TestCase test_cases[] = {\n        {1.0, 0.1, 10.0, jobs1, sizeof(jobs1)/sizeof(JobData)},\n        {0.9, 0.0, 20.0, jobs2, sizeof(jobs2)/sizeof(JobData)},\n        {1.0, 1.0, 5.0,  jobs3, sizeof(jobs3)/sizeof(JobData)}\n    };\n\n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    double results[num_cases * 8];\n    int result_idx = 0;\n\n    for (int i = 0; i < num_cases; ++i) {\n        const TestCase* tc = &test_cases[i];\n        JobMetrics* job_metrics = (JobMetrics*)malloc(tc->num_jobs * sizeof(JobMetrics));\n        if (!job_metrics) return EXIT_FAILURE;\n\n        double total_abs_err = 0.0;\n        double total_abs_dev_from_E = 0.0;\n\n        // --- 1. Predict next CPU burst for each job ---\n        for (int j = 0; j < tc->num_jobs; ++j) {\n            double tau = tc->E_b; // tau_0 = E[b]\n            for (int k = 0; k < tc->jobs[j].history_len; ++k) {\n                double alpha_k = tc->alpha0 / (1.0 + tc->beta * k);\n                tau = tau + alpha_k * (tc->jobs[j].history[k] - tau);\n            }\n            job_metrics[j].original_id = tc->jobs[j].id;\n            job_metrics[j].predicted_burst = tau;\n            job_metrics[j].actual_burst = tc->jobs[j].b_next;\n            \n            total_abs_err += fabs(tau - tc->jobs[j].b_next);\n            total_abs_dev_from_E += fabs(tau - tc->E_b);\n        }\n        \n        results[result_idx++] = total_abs_err / tc->num_jobs; // MAE\n\n        // --- 2. Evaluate Predicted SJF ---\n        JobMetrics* temp_jobs_pred = (JobMetrics*)malloc(tc->num_jobs * sizeof(JobMetrics));\n        if (!temp_jobs_pred) { free(job_metrics); return EXIT_FAILURE; }\n        memcpy(temp_jobs_pred, job_metrics, tc->num_jobs * sizeof(JobMetrics));\n        qsort(temp_jobs_pred, tc->num_jobs, sizeof(JobMetrics), compare_jobs_predicted);\n        SchedulingResult res_pred_sjf = calculate_scheduling_metrics(temp_jobs_pred, tc->num_jobs);\n        results[result_idx++] = res_pred_sjf.avg_wait_time;\n        results[result_idx++] = res_pred_sjf.avg_turnaround_time;\n        free(temp_jobs_pred);\n\n        // --- 3. Evaluate True SJF ---\n        JobMetrics* temp_jobs_true = (JobMetrics*)malloc(tc->num_jobs * sizeof(JobMetrics));\n        if (!temp_jobs_true) { free(job_metrics); return EXIT_FAILURE; }\n        memcpy(temp_jobs_true, job_metrics, tc->num_jobs * sizeof(JobMetrics));\n        qsort(temp_jobs_true, tc->num_jobs, sizeof(JobMetrics), compare_jobs_actual);\n        SchedulingResult res_true_sjf = calculate_scheduling_metrics(temp_jobs_true, tc->num_jobs);\n        results[result_idx++] = res_true_sjf.avg_wait_time;\n        results[result_idx++] = res_true_sjf.avg_turnaround_time;\n        free(temp_jobs_true);\n        \n        // --- 4. Evaluate FCFS ---\n        SchedulingResult res_fcfs = calculate_scheduling_metrics(job_metrics, tc->num_jobs);\n        results[result_idx++] = res_fcfs.avg_wait_time;\n        results[result_idx++] = res_fcfs.avg_turnaround_time;\n\n        // --- 5. Record Avg Abs Dev from E[b]\n        results[result_idx++] = total_abs_dev_from_E / tc->num_jobs;\n\n        free(job_metrics);\n    }\n\n    // Print the final aggregated results\n    printf(\"[\");\n    for (int i = 0; i < num_cases * 8; ++i) {\n        printf(\"%.6f%s\", results[i], (i == num_cases * 8 - 1) ? \"\" : \",\");\n    }\n    printf(\"]\");\n\n    return EXIT_SUCCESS;\n}\n\n```", "id": "3682812"}, {"introduction": "Our final practice takes a step back from implementation details to consider the broader system design and the human element. What happens if the processes themselves are responsible for reporting their predicted burst times? This exercise introduces concepts from game theory to explore how rational, self-interested processes might be tempted to manipulate the scheduler for their own benefit [@problem_id:3682845]. Your task is to think like a system architect and evaluate different penalty mechanisms designed to incentivize truthful reporting, revealing the deep connection between algorithm design and economic principles.", "problem": "A batch operating system uses non-preemptive Shortest Job First (SJF) scheduling, where the scheduler orders processes by the ascending values they report as their own predicted Central Processing Unit (CPU) burst time. There are $n$ processes in the batch, indexed by $i \\in \\{1,\\dots,n\\}$. Each process $i$ has a true burst time $b_i > 0$ that is known to the process but not to the scheduler. The system requires that all reported values $\\hat{b}_i$ lie in the set $\\{k \\Delta : k \\in \\mathbb{N}\\}$ for a fixed reporting quantum $\\Delta > 0$. Assume the true bursts satisfy $b_i \\in \\{k \\Delta : k \\in \\mathbb{N}\\}$ as well. Ties are broken by increasing process identifier.\n\nEach process $i$ experiences a waiting time equal to the sum of actual bursts of all jobs scheduled strictly before it, and it incurs a penalty $p(\\hat{b}_i, b_i)$ chosen by the system designer. The total disutility for process $i$ is its waiting time plus the penalty it pays. All processes are rational and choose their reports to minimize their own disutility.\n\nAssume the system designer knows fixed bounds: there are exactly $n$ jobs in the batch and each true burst satisfies $0 < b_j \\le \\bar{B}$ for a known $\\bar{B} > 0$. The designer wants to pick a penalty function $p(\\hat{b}, b)$ so that truthful reporting, $\\hat{b}_i = b_i$, is a weakly dominant strategy for every process $i$, regardless of the other reports.\n\nSelect all penalty functions below that achieve this property for all instances consistent with the bounds. You may assume parameters such as $\\lambda$ are system-chosen constants known to all processes.\n\nA. $p(\\hat{b}, b) = 0$ for all $\\hat{b}, b$.\n\nB. $p(\\hat{b}, b) = \\lambda \\, |\\hat{b} - b|$ with $\\lambda \\ge \\dfrac{(n-1)\\,\\bar{B}}{\\Delta}$.\n\nC. $p(\\hat{b}, b) = \\lambda \\, (\\hat{b} - b)^2$ for any fixed $\\lambda > 0$.\n\nD. $p(\\hat{b}, b) = \\lambda \\, \\max\\{0,\\, b - \\hat{b}\\}$ with $\\lambda \\ge \\dfrac{(n-1)\\,\\bar{B}}{\\Delta}$.\n\nE. $p(\\hat{b}, b) = \\lambda \\, \\mathbf{1}\\{\\hat{b} \\ne b\\}$ with $\\lambda > (n-1)\\,\\bar{B}$, where $\\mathbf{1}\\{\\cdot\\}$ is the indicator function.\n\nYour answer should be the set of all correct options.", "solution": "The problem asks us to identify which of the given penalty functions, $p(\\hat{b}, b)$, make truthful reporting, $\\hat{b}_i = b_i$, a weakly dominant strategy for every process $i$. The system uses non-preemptive Shortest Job First (SJF) scheduling based on reported burst times $\\hat{b}_i$.\n\nFirst, let us formalize the condition for a weakly dominant strategy in this context. A strategy for process $i$ is its choice of report, $\\hat{b}_i \\in \\{k \\Delta : k \\in \\mathbb{N}\\}$. The strategy $\\hat{b}_i^* = b_i$ is weakly dominant if, for any process $i$ with true burst time $b_i$, for any alternative report $\\hat{b}_i' \\neq b_i$, and for any set of reports from other processes $\\hat{\\mathbf{b}}_{-i} = (\\hat{b}_1, \\dots, \\hat{b}_{i-1}, \\hat{b}_{i+1}, \\dots, \\hat{b}_n)$, the total disutility for process $i$ is not improved by deviating from the truth. That is:\n$$U_i(b_i, \\hat{\\mathbf{b}}_{-i}) \\le U_i(\\hat{b}_i', \\hat{\\mathbf{b}}_{-i})$$\nThis must hold for all possible true burst times $b_j \\in (0, \\bar{B}]$ for $j \\neq i$. Furthermore, for any $\\hat{b}_i' \\neq b_i$, there must exist at least one profile of other players' reports $\\hat{\\mathbf{b}}_{-i}$ for which the inequality is strict:\n$$U_i(b_i, \\hat{\\mathbf{b}}_{-i}) < U_i(\\hat{b}_i', \\hat{\\mathbf{b}}_{-i})$$\n\nThe disutility for process $i$ is given by $U_i(\\hat{b}_i, \\hat{\\mathbf{b}}_{-i}) = W_i(\\hat{b}_i, \\hat{\\mathbf{b}}_{-i}) + p(\\hat{b}_i, b_i)$, where $W_i$ is the waiting time. The waiting time is the sum of the true burst times of all processes scheduled before $i$. The schedule is determined by sorting the pairs $(\\hat{b}_j, j)$ in ascending lexicographical order.\n\nLet's analyze the change in disutility, $\\Delta U_i$, when process $i$ changes its report from its true value $b_i$ to some other value $\\hat{b}_i'$:\n$$\\Delta U_i = U_i(\\hat{b}_i', \\hat{\\mathbf{b}}_{-i}) - U_i(b_i, \\hat{\\mathbf{b}}_{-i}) = [W_i(\\hat{b}_i', \\hat{\\mathbf{b}}_{-i}) - W_i(b_i, \\hat{\\mathbf{b}}_{-i})] + [p(\\hat{b}_i', b_i) - p(b_i, b_i)]$$\nLet $\\Delta W_i = W_i(\\hat{b}_i', \\hat{\\mathbf{b}}_{-i}) - W_i(b_i, \\hat{\\mathbf{b}}_{-i})$. For truth-telling to be weakly dominant, we need $\\Delta W_i + p(\\hat{b}_i', b_i) - p(b_i, b_i) \\ge 0$ for all $\\hat{b}_i' \\neq b_i$ and for all $\\hat{\\mathbf{b}}_{-i}$. All proposed penalty functions satisfy $p(b, b) = 0$. So the condition simplifies to:\n$$p(\\hat{b}_i', b_i) \\ge -\\Delta W_i$$\nThis must hold for all $\\hat{\\mathbf{b}}_{-i}$ and all valid true bursts $\\mathbf{b}_{-i}$. Therefore, the penalty must be greater than or equal to the maximum possible gain from misreporting:\n$$p(\\hat{b}_i', b_i) \\ge \\max_{\\hat{\\mathbf{b}}_{-i}, \\mathbf{b}_{-i}} \\{-\\Delta W_i\\}$$\n\nWe consider two cases for the deviation $\\hat{b}_i'$:\n\n1.  **Over-reporting ($\\hat{b}_i' > b_i$)**: By reporting a larger burst time, process $i$ can only move to a later position in the schedule or stay in the same position. Its waiting time can thus only increase or remain the same. Therefore, $\\Delta W_i \\ge 0$. The gain, $-\\Delta W_i$, is non-positive. For any penalty function where $p(\\hat{b}_i', b_i) \\ge 0$ for $\\hat{b}_i' > b_i$, the condition $p(\\hat{b}_i', b_i) \\ge -\\Delta W_i$ is satisfied. All proposed penalty functions A-E meet this requirement. So, over-reporting is never beneficial.\n\n2.  **Under-reporting ($\\hat{b}_i' < b_i$)**: By reporting a smaller burst time, process $i$ may move to an earlier position in the schedule, thereby decreasing its waiting time. Therefore, $\\Delta W_i \\le 0$, and the gain $-\\Delta W_i$ is non-negative. The penalty function must be designed to counteract this potential gain.\n\nTo find the required magnitude of the penalty, we must find the maximum possible gain. The gain $-\\Delta W_i$ is the sum of the true burst times of the processes that $i$ \"jumps ahead of\". To maximize this gain, we must construct a worst-case scenario. This involves process $i$ jumping ahead of the maximum number of processes, and those processes having the maximum possible true burst times.\n\nConsider process $i$. Let it contemplate changing its report from $b_i$ to $\\hat{b}_i' = b_i - k\\Delta$ for some integer $k \\ge 1$. The smallest possible under-report is $\\hat{b}_i' = b_i-\\Delta$.\nTo maximize the gain, let us configure the other $n-1$ processes (indexed by $j$) to have reports $\\hat{b}_j$ such that $i$ jumps them. Let all $n-1$ processes $j \\neq i$ report $\\hat{b}_j = b_i - \\Delta$. Furthermore, to maximize the set of processes that $i$ jumps, assume process $i$ has the smallest process ID, i.e., $i=1$.\n- If process $1$ reports truthfully $b_1$, its scheduling key is $(b_1, 1)$. All other processes $j \\in \\{2, \\dots, n\\}$ have keys $(\\hat{b}_j, j) = (b_1 - \\Delta, j)$. Thus, all other $n-1$ processes are scheduled before process $1$. Its waiting time is $W_1 = \\sum_{j=2}^n b_j$.\n- If process $1$ under-reports $\\hat{b}_1' = b_1 - \\Delta$, its key is $(b_1 - \\Delta, 1)$. Since $1 < j$ for all $j \\neq 1$, process $1$ is now scheduled first. Its waiting time becomes $W_1' = 0$.\n\nThe gain in waiting time is $-\\Delta W_1 = W_1 - W_1' = \\sum_{j=2}^n b_j$. To maximize this gain, each $b_j$ must be at its maximum allowed value, $\\bar{B}$. The maximum possible gain is thus $(n-1)\\bar{B}$.\nAny effective penalty function must impose a cost of at least this amount for any under-report. So, for any $\\hat{b}_i' < b_i$, we need:\n$$p(\\hat{b}_i', b_i) \\ge (n-1)\\bar{B}$$\n\nNow we evaluate each option.\n\n**A. $p(\\hat{b}, b) = 0$ for all $\\hat{b}, b$.**\nWith zero penalty, the disutility is just the waiting time, $U_i = W_i$. To minimize its waiting time, a rational process will always report the smallest possible value, $\\hat{b}_i = \\Delta$, to get scheduled as early as possible. This is clearly not truthful reporting.\n**Verdict: Incorrect.**\n\n**B. $p(\\hat{b}, b) = \\lambda \\, |\\hat{b} - b|$ with $\\lambda \\ge \\dfrac{(n-1)\\,\\bar{B}}{\\Delta}$.**\nFor under-reporting ($\\hat{b}_i' < b_i$), the report must be at least $\\Delta$ smaller than $b_i$: $b_i - \\hat{b}_i' \\ge \\Delta$.\nThe penalty is $p(\\hat{b}_i', b_i) = \\lambda (b_i - \\hat{b}_i')$.\nThe minimum penalty for any under-report is incurred for the smallest deviation, i.e., $b_i - \\hat{b}_i' = \\Delta$. This minimum penalty is $\\lambda\\Delta$.\nThe condition on $\\lambda$ is $\\lambda \\ge \\frac{(n-1)\\bar{B}}{\\Delta}$, which implies $\\lambda\\Delta \\ge (n-1)\\bar{B}$.\nSo, the minimum penalty for any under-report, $\\lambda\\Delta$, is at least the maximum possible gain, $(n-1)\\bar{B}$. Since the penalty $\\lambda(b_i - \\hat{b}_i')$ increases with the size of the under-report, the penalty is always sufficient.\nFor over-reporting, $\\Delta W_i \\ge 0$ and $p(\\hat{b}_i', b_i) > 0$, so there is no benefit. The weak dominance condition holds.\nWe must also check that for any $\\hat{b}_i' \\ne b_i$, there exists a $\\hat{\\mathbf{b}}_{-i}$ leading to a strict inequality. If we choose $\\hat{\\mathbf{b}}_{-i}$ such that $i$'s schedule position is unchanged (e.g., all other $\\hat{b}_j$ are very large), then $\\Delta W_i=0$. The change in disutility is $\\Delta U_i = p(\\hat{b}_i', b_i) = \\lambda|\\hat{b}_i' - b_i| > 0$. The strict inequality holds.\n**Verdict: Correct.**\n\n**C. $p(\\hat{b}, b) = \\lambda \\, (\\hat{b} - b)^2$ for any fixed $\\lambda > 0$.**\nThe penalty for an under-report of $\\hat{b}_i' = b_i - k\\Delta$ is $\\lambda(k\\Delta)^2$. The minimum penalty is $\\lambda\\Delta^2$ (for $k=1$).\nThis must be at least the maximum gain: $\\lambda\\Delta^2 \\ge (n-1)\\bar{B}$. This must hold for the choice of $\\lambda$.\nThe option states this works for *any* fixed $\\lambda > 0$. However, if $n, \\bar{B}, \\Delta$ are such that $(n-1)\\bar{B} > 0$, we can choose a $\\lambda$ small enough, e.g., $\\lambda = \\frac{(n-1)\\bar{B}}{2\\Delta^2}$, for which the condition $\\lambda\\Delta^2 \\ge (n-1)\\bar{B}$ fails. In such a situation, a process could benefit from under-reporting. Thus, the claim that this works for *any* $\\lambda > 0$ is false.\n**Verdict: Incorrect.**\n\n**D. $p(\\hat{b}, b) = \\lambda \\, \\max\\{0,\\, b - \\hat{b}\\}$ with $\\lambda \\ge \\dfrac{(n-1)\\,\\bar{B}}{\\Delta}$.**\nThis function only penalizes under-reporting.\nFor over-reporting ($\\hat{b}_i' > b_i$), $b_i - \\hat{b}_i' < 0$, so the penalty is $p(\\hat{b}_i', b_i) = 0$. The change in disutility is $\\Delta U_i = \\Delta W_i + 0$. Since $\\Delta W_i \\ge 0$, the disutility does not decrease. Weak dominance holds.\nFor under-reporting ($\\hat{b}_i' < b_i$), the penalty is $p(\\hat{b}_i', b_i) = \\lambda (b_i - \\hat{b}_i')$. This is identical to the penalty in option B for the case of under-reporting. The same analysis applies: the minimum penalty is $\\lambda\\Delta$, and the condition on $\\lambda$ ensures this is $\\ge (n-1)\\bar{B}$, the maximum possible gain.\nThe strict inequality condition for weak dominance also holds (e.g., in a scenario where $\\Delta W_i=0$, under-reporting by $\\Delta$ gives $\\Delta U_i = \\lambda \\Delta > 0$).\n**Verdict: Correct.**\n\n**E. $p(\\hat{b}, b) = \\lambda \\, \\mathbf{1}\\{\\hat{b} \\ne b\\}$ with $\\lambda > (n-1)\\,\\bar{B}$, where $\\mathbf{1}\\{\\cdot\\}$ is the indicator function.**\nThis function applies a fixed penalty $\\lambda$ for any misreport, regardless of its magnitude or direction.\nFor any misreport $\\hat{b}_i' \\ne b_i$, the penalty is $\\lambda$.\nWe must ensure the penalty is large enough to deter under-reporting. We need $\\lambda \\ge \\max(-\\Delta W_i) = (n-1)\\bar{B}$.\nThe condition given is $\\lambda > (n-1)\\bar{B}$, which is a sufficient (and slightly stronger) condition. With this penalty, the change in disutility is $\\Delta U_i = \\Delta W_i + \\lambda$.\nFor over-reporting, $\\Delta W_i \\ge 0$, so $\\Delta U_i = \\Delta W_i + \\lambda > 0$.\nFor under-reporting, $\\Delta W_i \\ge -(n-1)\\bar{B}$. So $\\Delta U_i \\ge -(n-1)\\bar{B} + \\lambda$. Since $\\lambda > (n-1)\\bar{B}$, we have $\\Delta U_i > 0$.\nIn all cases of misreporting, the disutility strictly increases for any $\\hat{\\mathbf{b}}_{-i}$. This means that truthful reporting is a strictly dominant strategy. A strictly dominant strategy is also a weakly dominant strategy.\n**Verdict: Correct.**", "answer": "$$\\boxed{BDE}$$", "id": "3682845"}]}