{"hands_on_practices": [{"introduction": "Understanding system performance begins with the fundamental unit of work: the process. This first exercise models a single process alternating between computation and I/O, allowing us to derive the core metrics of resource utilization. By analyzing this simple case, we can precisely define what it means for a system to be CPU-bound or I/O-bound, a concept that underpins all further performance analysis [@problem_id:3671863].", "problem": "Consider a single long-running process that repeatedly alternates between a central processing unit (CPU) burst and a disk input/output (I/O) burst. Let the CPU burst durations be independent and identically distributed as exponential random variables with rate parameter $\\lambda$, denoted $C_{i} \\sim \\text{Exp}(\\lambda)$, and let the disk I/O burst durations be independent and identically distributed as exponential random variables with rate parameter $\\mu$, denoted $D_{i} \\sim \\text{Exp}(\\mu)$. The process never terminates and has no think time between bursts; it immediately requests a disk I/O after each CPU burst and immediately becomes ready for the CPU after each disk I/O completion. The system contains a single CPU and a single disk device, and both are scheduled with non-preemptive First-Come, First-Served (FCFS). For the purpose of comparison, also consider a hypothetical change in which both devices use non-preemptive Shortest Job First (SJF) with perfect knowledge of the next burst lengths.\n\nUsing only the fundamental definition of utilization as the long-run fraction of time a resource is busy, and the stationarity of the alternating burst process, derive the steady-state CPU utilization and disk utilization in terms of $\\lambda$ and $\\mu$. State whether the utilizations are affected by the choice between FCFS and SJF in this single-process setting, and explain under what condition the CPU is the bottleneck versus when the disk is the bottleneck, where “bottleneck” means the resource with the larger long-run utilization. No numerical rounding is required. Express your final answer as a single row matrix containing the CPU utilization and the disk utilization as simplified symbolic expressions in $\\lambda$ and $\\mu$.", "solution": "The problem statement has been validated and is deemed valid. It is a self-contained, scientifically grounded, and well-posed problem in the domain of operating systems performance analysis. It relies on standard stochastic models and fundamental definitions.\n\nThe core of the problem is to determine the long-run utilization of the central processing unit (CPU) and the disk device for a single, non-terminating process that alternates between CPU and I/O bursts.\n\nLet $C_i$ be the duration of the $i$-th CPU burst, for $i=1, 2, \\dots$. The problem states that $C_i$ are independent and identically distributed (i.i.d.) random variables following an exponential distribution with rate parameter $\\lambda$. The probability density function is $f_C(t) = \\lambda \\exp(-\\lambda t)$ for $t \\ge 0$. The expected value, or mean duration, of a CPU burst is given by:\n$$E[C_i] = \\frac{1}{\\lambda}$$\n\nSimilarly, let $D_i$ be the duration of the $i$-th disk I/O burst. These are i.i.d. random variables following an exponential distribution with rate parameter $\\mu$. The probability density function is $f_D(t) = \\mu \\exp(-\\mu t)$ for $t \\ge 0$. The expected value of an I/O burst duration is:\n$$E[D_i] = \\frac{1}{\\mu}$$\n\nThe process executes a continuous sequence of cycles, where each cycle consists of one CPU burst followed by one I/O burst. Let $T_{cycle, i}$ be the duration of the $i$-th cycle. Then $T_{cycle, i} = C_i + D_i$. Since the process is stationary, we can analyze the behavior over an average cycle. The expected duration of a single, complete cycle is:\n$$E[T_{cycle}] = E[C_i + D_i] = E[C_i] + E[D_i] = \\frac{1}{\\lambda} + \\frac{1}{\\mu}$$\nThis can be simplified by finding a common denominator:\n$$E[T_{cycle}] = \\frac{\\mu + \\lambda}{\\lambda\\mu}$$\n\nUtilization is defined as the long-run fraction of time a resource is busy. For a stationary ergodic process like this one, the long-run time-average utilization is equal to the ratio of the expected busy time per cycle to the expected total time per cycle.\n\nFor the CPU, it is busy for a duration $C_i$ during each cycle $T_{cycle, i}$. The CPU utilization, $U_{CPU}$, is therefore:\n$$U_{CPU} = \\frac{E[C_i]}{E[T_{cycle}]} = \\frac{E[C_i]}{E[C_i] + E[D_i]}$$\nSubstituting the expected values:\n$$U_{CPU} = \\frac{\\frac{1}{\\lambda}}{\\frac{1}{\\lambda} + \\frac{1}{\\mu}} = \\frac{\\frac{1}{\\lambda}}{\\frac{\\mu + \\lambda}{\\lambda\\mu}} = \\frac{1}{\\lambda} \\cdot \\frac{\\lambda\\mu}{\\lambda + \\mu} = \\frac{\\mu}{\\lambda + \\mu}$$\n\nFor the disk device, it is busy for a duration $D_i$ during each cycle. Because this is a single process, the CPU and disk are never busy simultaneously. While the CPU is active, the disk is idle, and vice versa. The disk utilization, $U_{DISK}$, is:\n$$U_{DISK} = \\frac{E[D_i]}{E[T_{cycle}]} = \\frac{E[D_i]}{E[C_i] + E[D_i]}$$\nSubstituting the expected values:\n$$U_{DISK} = \\frac{\\frac{1}{\\mu}}{\\frac{1}{\\lambda} + \\frac{1}{\\mu}} = \\frac{\\frac{1}{\\mu}}{\\frac{\\mu + \\lambda}{\\lambda\\mu}} = \\frac{1}{\\mu} \\cdot \\frac{\\lambda\\mu}{\\lambda + \\mu} = \\frac{\\lambda}{\\lambda + \\mu}$$\nAs a consistency check, note that $U_{CPU} + U_{DISK} = \\frac{\\mu}{\\lambda + \\mu} + \\frac{\\lambda}{\\lambda + \\mu} = \\frac{\\lambda + \\mu}{\\lambda + \\mu} = 1$. This is expected, as the process is always using either the CPU or the disk, with no idle or think time.\n\nNext, we must consider the effect of the scheduling policy (non-preemptive First-Come, First-Served vs. non-preemptive Shortest Job First). Scheduling policies are algorithms designed to resolve contention when multiple processes or jobs compete for a single resource. In this problem, there is only a single process. When this process requires the CPU, it is the only process in the ready queue. When it requires the disk, it is the only process in the disk queue. Consequently, there is never more than one job to choose from. Any work-conserving scheduling policy, including both FCFS and SJF, will make the same decision: schedule the one and only available job. Therefore, the choice of scheduling discipline has no impact on the system's behavior or the resulting utilizations in this single-process scenario.\n\nFinally, we determine the bottleneck condition. The bottleneck is defined as the resource with the larger long-run utilization.\nThe CPU is the bottleneck if $U_{CPU}  U_{DISK}$:\n$$\\frac{\\mu}{\\lambda + \\mu}  \\frac{\\lambda}{\\lambda + \\mu}$$\nSince $\\lambda  0$ and $\\mu  0$, the denominator $\\lambda + \\mu$ is positive, so we can multiply both sides by it without changing the inequality:\n$$\\mu  \\lambda$$\nRecalling that $E[C_i] = 1/\\lambda$ and $E[D_i] = 1/\\mu$, the condition $\\mu  \\lambda$ is equivalent to $1/\\lambda  1/\\mu$, which means $E[C_i]  E[D_i]$. Thus, the CPU is the bottleneck if its average service time (burst duration) is greater than the disk's average service time.\n\nConversely, the disk is the bottleneck if $U_{DISK}  U_{CPU}$, which by symmetric reasoning, occurs when $\\lambda  \\mu$, or $E[D_i]  E[C_i]$. The disk is the bottleneck if its average service time is greater than the CPU's. If $\\lambda = \\mu$, the utilizations are equal, and the system is balanced.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{\\mu}{\\lambda + \\mu}  \\frac{\\lambda}{\\lambda + \\mu} \\end{pmatrix}}$$", "id": "3671863"}, {"introduction": "Once we understand the performance of a basic process cycle, the next logical step is to improve it. This practice explores a powerful optimization technique called *batching*, which is used to reduce the impact of fixed overheads like disk latency. By modeling a realistic disk service time, you will derive the conditions under which grouping I/O requests enhances system throughput, providing a quantitative justification for this widely-used strategy [@problem_id:3671917].", "problem": "Consider an operating system process with alternating Central Processing Unit (CPU) and Input/Output (I/O) bursts. The process repeatedly executes a CPU burst that takes $C$ milliseconds to compute with data already in memory, and then issues a blocking read to fetch the next $S$ bytes from a disk before the next CPU burst can begin. The disk’s service time for a contiguous read of size $x$ bytes is modeled as the sum of a fixed seek-plus-rotation latency $L$ milliseconds and a transfer time $x/B$ milliseconds, where $B$ is the average sequential throughput in bytes per millisecond. Assume that the process blocks during each read and that memory is sufficient to hold any prefetched data without additional overhead. Define the application’s long-run throughput as the asymptotic average number of bytes of useful data processed per millisecond, and assume physically realistic storage with $L0$.\n\nNow suppose the process adopts batching: instead of issuing one read of $S$ bytes after each CPU burst, it performs $k$ consecutive CPU bursts (consuming previously fetched data) and then issues a single blocking read of size $kS$ bytes before the next group of $k$ CPU bursts. Batching thereby reduces the I/O burst count by amortizing the fixed latency over a larger transfer.\n\nStarting only from the core definitions of CPU and I/O bursts and the standard disk service-time model described above, derive the minimal integer batch size $k_{\\min}$ such that batching yields a strictly higher long-run throughput than the non-batched policy. Express your final answer as an integer with no units.", "solution": "The problem is first subjected to a rigorous validation.\n\n**Step 1: Extract Givens**\n-   CPU burst time: $C$ milliseconds.\n-   Data size per CPU burst: $S$ bytes.\n-   Disk seek-plus-rotation latency: $L$ milliseconds.\n-   Disk sequential throughput: $B$ bytes per millisecond.\n-   Disk service time for a read of size $x$ bytes: $L + \\frac{x}{B}$ milliseconds.\n-   Batching policy: $k$ consecutive CPU bursts followed by a single read of size $kS$. The non-batched policy corresponds to $k=1$.\n-   Constraint: Storage is physically realistic, so $L0$.\n-   Objective: Find the minimal integer batch size, $k_{\\min}$, such that batching yields a strictly higher long-run throughput than the non-batched policy.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientific Grounding**: The problem is built upon standard, canonical models used in the study of operating systems. The concept of alternating CPU and I/O bursts is a fundamental abstraction for process behavior. The disk service time model, comprising a fixed latency and a variable transfer time, is a well-established first-order approximation for storage device performance. The principle of batching to amortize fixed overhead is a core optimization technique in computer science. The problem is scientifically sound.\n-   **Well-Posed**: All variables ($C$, $S$, $L$, $B$, $k$) are defined. The performance metric (long-run throughput) is unambiguously specified. The goal is to find a minimal integer $k_{\\min}$ satisfying a strict inequality, which points to a well-defined mathematical problem. The inclusion of the constraint $L0$ is crucial, preventing a degenerate case and ensuring a meaningful solution.\n-   **Objective**: The problem is stated in precise, quantitative, and unbiased language.\n-   **Completeness and Consistency**: The problem is self-contained, providing all necessary information for derivation. There are no internal contradictions.\n\n**Verdict:** The problem is deemed **valid**. It is a well-posed, scientifically grounded problem that tests fundamental concepts in system performance analysis.\n\n**Solution Derivation**\n\nThe long-run throughput, denoted as $\\eta$, is defined as the asymptotic average number of bytes of useful data processed per millisecond. We can calculate this by analyzing one complete operational cycle:\n$$ \\eta = \\frac{\\text{Total data processed in a cycle}}{\\text{Total time for the cycle}} $$\n\nFirst, we analyze the non-batched policy, which corresponds to a batch size of $k=1$. In a single cycle, the process performs one CPU burst and one I/O burst.\n-   The time for the CPU burst is $C$.\n-   The I/O is a read of size $S$. The time for this I/O burst is given by the disk service time model as $L + \\frac{S}{B}$.\n-   The total time for one cycle, $T_1$, is the sum of the CPU and I/O burst times:\n    $$ T_1 = C + L + \\frac{S}{B} $$\n-   The amount of data processed in this cycle is $S$.\n-   The throughput for the non-batched policy, $\\eta_1$, is therefore:\n    $$ \\eta_1 = \\frac{S}{T_1} = \\frac{S}{C + L + \\frac{S}{B}} $$\n\nNext, we analyze the batched policy for an integer batch size $k$. One macro-cycle of this policy consists of $k$ CPU bursts followed by a single, larger I/O burst.\n-   The total time for the $k$ consecutive CPU bursts is $kC$.\n-   The single I/O is a read of total size $kS$. The time for this I/O burst is $L + \\frac{kS}{B}$.\n-   The total time for one macro-cycle, $T_k$, is the sum of the total CPU time and the single I/O time:\n    $$ T_k = kC + L + \\frac{kS}{B} $$\n-   The total amount of data processed in this macro-cycle is $kS$.\n-   The throughput for the batched policy, $\\eta_k$, is therefore:\n    $$ \\eta_k = \\frac{kS}{T_k} = \\frac{kS}{kC + L + \\frac{kS}{B}} $$\n\nThe problem requires finding the minimal integer batch size $k_{\\min}$ for which the batched throughput is strictly greater than the non-batched throughput. We must find the smallest integer $k$ that satisfies the inequality $\\eta_k  \\eta_1$. The non-batched case is $k=1$, so we are looking for a solution where $k \\ge 2$.\n\nWe establish the inequality:\n$$ \\frac{kS}{kC + L + \\frac{kS}{B}}  \\frac{S}{C + L + \\frac{S}{B}} $$\nGiven that $S$ is a size in bytes, it must be positive ($S0$). We can safely divide both sides of the inequality by $S$:\n$$ \\frac{k}{kC + L + \\frac{kS}{B}}  \\frac{1}{C + L + \\frac{S}{B}} $$\nAll parameters ($C$, $L$, $S$, $B$) and the batch size $k$ are positive quantities. Therefore, the denominators on both sides of the inequality are strictly positive. We can cross-multiply without reversing the inequality sign:\n$$ k \\left( C + L + \\frac{S}{B} \\right)  1 \\left( kC + L + \\frac{kS}{B} \\right) $$\nDistributing $k$ on the left-hand side:\n$$ kC + kL + \\frac{kS}{B}  kC + L + \\frac{kS}{B} $$\nThe terms $kC$ and $\\frac{kS}{B}$ appear on both sides and can be cancelled by subtraction:\n$$ kL  L $$\nThe problem explicitly states that $L  0$, modeling a physically realistic disk with non-zero latency. Since $L$ is a positive constant, we can divide both sides by $L$ without altering the inequality:\n$$ k  1 $$\nThis result demonstrates that any batch size $k$ strictly greater than $1$ will yield a higher throughput than the non-batched policy. The problem asks for the minimal *integer* batch size, $k_{\\min}$, that satisfies this condition. The set of integers satisfying $k  1$ is $\\{2, 3, 4, \\dots\\}$. The smallest integer in this set is $2$.\nThus, the minimal integer batch size that strictly improves throughput is $2$.", "answer": "$$\\boxed{2}$$", "id": "3671917"}, {"introduction": "Real systems rarely run just one process; they manage many that compete for resources, leading to queues and waiting. This final exercise elevates our analysis from a single process to a multiprogrammed system, using queueing theory to connect the microscopic behavior of CPU-I/O bursts to macroscopic system-level goals. You will determine the optimal number of concurrent processes to satisfy a performance guarantee, demonstrating how to engineer a system's capacity based on the fundamental properties of its workload [@problem_id:3671871].", "problem": "A computer system runs a closed workload of $N$ identical processes that alternate between a Central Processing Unit (CPU) burst and a single disk Input/Output (I/O) operation. The CPU and the disk each serve one request at a time using First-Come First-Served (FCFS) scheduling, with independent and identically distributed service times that are exponential. The mean CPU burst time is $4 \\, \\mathrm{ms}$ and the mean disk service time is $6 \\, \\mathrm{ms}$. Context switching overheads and think times are negligible. Each process repeatedly visits the CPU exactly once and then the disk exactly once per cycle.\n\nLet $I$ denote the steady-state response time (waiting plus service) of a disk I/O request. You are tasked with choosing the multiprogramming level $N$ (i.e., the maximum number of resident processes) so that the probability that a disk I/O response exceeds a given threshold $T$ satisfies\n$\n\\Pr(I  T) \\le \\epsilon.\n$\nTake $T = 0.20 \\, \\mathrm{s}$ and $\\epsilon = 0.10$.\n\nStarting only from core definitions and well-tested results of queueing theory for exponential service queues and closed product-form networks, derive the constraint this imposes on the disk’s effective arrival rate in steady state, connect that rate to the system throughput as a function of $N$, and determine the largest integer value of $N$ for which the inequality holds. In your derivation, explicitly relate your sizing choice to the CPU idle probability at the chosen $N$ by expressing it in terms of the system throughput and the CPU service parameters, and evaluate its numeric value at that $N$ (reporting only $N$ as your final answer).\n\nExpress your final answer as the single integer $N_{\\max}$ that satisfies the requirement. No rounding is needed beyond exact integer selection. Times must be treated in seconds, but the final answer is dimensionless.", "solution": "The problem describes a closed queueing network with a fixed population of $N$ processes circulating between two service centers: a CPU and a disk. Both centers are single-server queues ($m=1$) with a First-Come First-Served (FCFS) discipline and exponentially distributed service times. This system is a classic example of a Gordon-Newell or closed Jackson queueing network.\n\nThe given parameters are:\nMean CPU service time, $S_{CPU} = 4 \\, \\mathrm{ms} = 0.004 \\, \\mathrm{s}$.\nMean disk service time, $S_{disk} = 6 \\, \\mathrm{ms} = 0.006 \\, \\mathrm{s}$.\nThe service rates are the reciprocals of the mean service times:\nCPU service rate, $\\mu_{CPU} = 1/S_{CPU} = 1/0.004 \\, \\mathrm{s}^{-1} = 250 \\, \\mathrm{s}^{-1}$.\nDisk service rate, $\\mu_{disk} = 1/S_{disk} = 1/0.006 \\, \\mathrm{s}^{-1} = \\frac{500}{3} \\, \\mathrm{s}^{-1} \\approx 166.67 \\, \\mathrm{s}^{-1}$.\n\nThe objective is to find the largest integer multiprogramming level, $N$, such that the probability of the disk I/O response time, $I$, exceeding a threshold $T = 0.20 \\, \\mathrm{s}$ is no more than $\\epsilon = 0.10$. That is, $\\Pr(I > T) \\le \\epsilon$.\n\nFirst, we analyze the disk I/O subsystem. For a node within a product-form closed queueing network, such as the disk in this system, the steady-state response time distribution is equivalent to that of an M/M/1 queue. The arrival rate to this equivalent queue, $\\lambda$, is the steady-state throughput of the system, which we denote by $X(N)$, and the service rate is $\\mu_{disk}$. The response time $I$ for an M/M/1 queue is exponentially distributed with parameter $\\mu_{disk} - X(N)$. The probability density function is $f(t) = (\\mu_{disk}-X(N))\\exp(-(\\mu_{disk}-X(N))t)$ for $t \\ge 0$.\n\nThe cumulative distribution function is $\\Pr(I \\le t) = 1 - \\exp(-(\\mu_{disk}-X(N))t)$, so the complementary cumulative distribution function (the survival function) is:\n$$\n\\Pr(I > t) = \\exp(-(\\mu_{disk} - X(N))t)\n$$\nThis result is valid for a stable queue, which requires that the arrival rate is less than the service rate, i.e., $X(N)  \\mu_{disk}$.\n\nThe problem imposes the constraint $\\Pr(I > T) \\le \\epsilon$. Substituting the expression for the survival function and the given values for $T$ and $\\epsilon$:\n$$\n\\exp(-(\\mu_{disk} - X(N))T) \\le \\epsilon\n$$\nTo find the constraint on the system throughput $X(N)$, we solve this inequality. Taking the natural logarithm of both sides (which is a monotonically increasing function and thus preserves the inequality):\n$$\n-(\\mu_{disk} - X(N))T \\le \\ln(\\epsilon)\n$$\nDividing by $-T$ (a negative quantity) reverses the direction of the inequality:\n$$\n\\mu_{disk} - X(N) \\ge -\\frac{\\ln(\\epsilon)}{T}\n$$\nRearranging to isolate $X(N)$, we find the upper bound on the system throughput, which is also the effective arrival rate at the disk:\n$$\nX(N) \\le \\mu_{disk} + \\frac{\\ln(\\epsilon)}{T}\n$$\nThis is the derived constraint on the disk's effective arrival rate. Let us compute this maximum allowable throughput, $X_{max}$.\n$$\nX_{max} = \\frac{1}{S_{disk}} + \\frac{\\ln(\\epsilon)}{T} = \\frac{1}{0.006 \\, \\mathrm{s}} + \\frac{\\ln(0.10)}{0.20 \\, \\mathrm{s}}\n$$\n$$\nX_{max} \\approx 166.667 \\, \\mathrm{s}^{-1} + \\frac{-2.302585}{0.20} \\, \\mathrm{s}^{-1} \\approx 166.667 \\, \\mathrm{s}^{-1} - 11.513 \\, \\mathrm{s}^{-1} \\approx 155.154 \\, \\mathrm{s}^{-1}\n$$\nSo, we must find the largest integer $N$ for which $X(N) \\le 155.154 \\, \\mathrm{s}^{-1}$.\n\nNext, we establish the relationship between the multiprogramming level $N$ and the system throughput $X(N)$. We use the Mean Value Analysis (MVA) algorithm, an iterative method for solving closed queueing networks. The MVA algorithm is based on the Arrival Theorem and Little's Law. It computes performance metrics for a system with population $n$ based on the metrics of a system with population $n-1$.\n\nThe MVA recurrence relations for this two-node system are:\n1. Mean response time at each node $i \\in \\{\\text{CPU, disk}\\}$: $R_i(n) = S_i (1 + Q_i(n-1))$\n2. System throughput: $X(n) = \\frac{n}{R_{CPU}(n) + R_{disk}(n)}$\n3. Mean queue length at each node $i$: $Q_i(n) = X(n) R_i(n)$\n\nThe iteration starts with the initial condition $Q_{CPU}(0) = 0$ and $Q_{disk}(0) = 0$. We compute $X(n)$ for $n=1, 2, 3, \\ldots$ and stop when $X(n)$ exceeds $X_{max}$.\n\nFor $n=1$:\n$R_{CPU}(1) = S_{CPU}(1+Q_{CPU}(0)) = 0.004(1+0) = 0.004 \\, \\mathrm{s}$\n$R_{disk}(1) = S_{disk}(1+Q_{disk}(0)) = 0.006(1+0) = 0.006 \\, \\mathrm{s}$\n$X(1) = \\frac{1}{R_{CPU}(1) + R_ {disk}(1)} = \\frac{1}{0.004 + 0.006} = \\frac{1}{0.01} = 100 \\, \\mathrm{s}^{-1}$.\n$X(1) = 100 \\le 155.154$, so $N \\ge 1$.\n$Q_{CPU}(1) = X(1)R_{CPU}(1) = 100 \\times 0.004 = 0.4$\n$Q_{disk}(1) = X(1)R_{disk}(1) = 100 \\times 0.006 = 0.6$\n\nFor $n=2$:\n$R_{CPU}(2) = S_{CPU}(1+Q_{CPU}(1)) = 0.004(1+0.4) = 0.0056 \\, \\mathrm{s}$\n$R_{disk}(2) = S_{disk}(1+Q_{disk}(1)) = 0.006(1+0.6) = 0.0096 \\, \\mathrm{s}$\n$X(2) = \\frac{2}{0.0056 + 0.0096} = \\frac{2}{0.0152} \\approx 131.579 \\, \\mathrm{s}^{-1}$.\n$X(2) \\approx 131.579 \\le 155.154$, so $N \\ge 2$.\n$Q_{CPU}(2) = X(2)R_{CPU}(2) \\approx 131.579 \\times 0.0056 \\approx 0.7368$\n$Q_{disk}(2) = X(2)R_{disk}(2) \\approx 131.579 \\times 0.0096 \\approx 1.2632$\n\nFor $n=3$:\n$R_{CPU}(3) = S_{CPU}(1+Q_{CPU}(2)) = 0.004(1+0.7368) = 0.0069472 \\, \\mathrm{s}$\n$R_{disk}(3) = S_{disk}(1+Q_{disk}(2)) = 0.006(1+1.2632) = 0.0135792 \\, \\mathrm{s}$\n$X(3) = \\frac{3}{0.0069472 + 0.0135792} = \\frac{3}{0.0205264} \\approx 146.154 \\, \\mathrm{s}^{-1}$.\n$X(3) \\approx 146.154 \\le 155.154$, so $N \\ge 3$.\n$Q_{CPU}(3) = X(3)R_{CPU}(3) \\approx 146.154 \\times 0.0069472 \\approx 1.0154$\n$Q_{disk}(3) = X(3)R_{disk}(3) \\approx 146.154 \\times 0.0135792 \\approx 1.9846$\n\nFor $n=4$:\n$R_{CPU}(4) = S_{CPU}(1+Q_{CPU}(3)) = 0.004(1+1.0154) = 0.0080616 \\, \\mathrm{s}$\n$R_{disk}(4) = S_{disk}(1+Q_{disk}(3)) = 0.006(1+1.9846) = 0.0179076 \\, \\mathrm{s}$\n$X(4) = \\frac{4}{0.0080616 + 0.0179076} = \\frac{4}{0.0259692} \\approx 154.028 \\, \\mathrm{s}^{-1}$.\n$X(4) \\approx 154.028 \\le 155.154$, so $N \\ge 4$.\n$Q_{CPU}(4) = X(4)R_{CPU}(4) \\approx 154.028 \\times 0.0080616 \\approx 1.2416$\n$Q_{disk}(4) = X(4)R_{disk}(4) \\approx 154.028 \\times 0.0179076 \\approx 2.7584$\n\nFor $n=5$:\n$R_{CPU}(5) = S_{CPU}(1+Q_{CPU}(4)) = 0.004(1+1.2416) = 0.0089664 \\, \\mathrm{s}$\n$R_{disk}(5) = S_{disk}(1+Q_{disk}(4)) = 0.006(1+2.7584) = 0.0225504 \\, \\mathrm{s}$\n$X(5) = \\frac{5}{0.0089664 + 0.0225504} = \\frac{5}{0.0315168} \\approx 158.644 \\, \\mathrm{s}^{-1}$.\n$X(5) \\approx 158.644 > 155.154$.\nThe condition is violated for $N=5$. Therefore, the largest integer value of $N$ that satisfies the inequality is $4$.\n\nFinally, as requested, we relate this choice of $N=4$ to the CPU idle probability. The utilization of the CPU, $U_{CPU}(N)$, is the fraction of time it is busy. By the Utilization Law, it is the product of the system throughput and the mean service time:\n$$\nU_{CPU}(N) = X(N) \\cdot S_{CPU}\n$$\nThe CPU idle probability, $P_{idle, CPU}(N)$, is the complement of its utilization:\n$$\nP_{idle, CPU}(N) = 1 - U_{CPU}(N) = 1 - X(N)S_{CPU}\n$$\nThis expression relates the CPU idle probability to the system throughput and service parameters. For our chosen value of $N=4$, we evaluate this probability:\n$$\nP_{idle, CPU}(4) = 1 - X(4)S_{CPU} \\approx 1 - (154.028 \\, \\mathrm{s}^{-1})(0.004 \\, \\mathrm{s}) \\approx 1 - 0.6161 = 0.3839\n$$\nThis confirms that at the maximum allowed multiprogramming level, the CPU is idle approximately $38.4\\%$ of the time. The bottleneck device is the disk, as its service time is longer. The disk utilization at $N=4$ is $U_{disk}(4) = X(4)S_{disk} \\approx 154.028 \\times 0.006 = 0.9242$, which is much higher.\n\nThe final answer is the largest integer $N$ that fulfills the requirement.", "answer": "$$\n\\boxed{4}\n$$", "id": "3671871"}]}