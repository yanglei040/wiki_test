{"hands_on_practices": [{"introduction": "Understanding the theoretical point at which a system begins to thrash is a foundational skill in operating systems. This practice challenges you to apply the working set model to a high-performance computing scenario, calculating the maximum number of jobs a system can support before its performance collapses due to excessive swapping [@problem_id:3685321]. By formalizing the relationship between available memory and aggregate workload demand, you will gain a quantitative understanding of memory pressure.", "problem": "A single High-Performance Computing (HPC) node runs an operating system that supports swapping and batch scheduling. The node has total physical Random Access Memory (RAM) of $M = 256$ GiB. A batch queue dispatches $n$ identical jobs. Each job has a steady-state memory working set of $W = 9$ GiB, measured over a fixed window $\\Delta t$ appropriate for the working set model. The operating system’s memory pressure controller maintains a reclaim headroom and begins sustained page reclamation when the aggregate resident demand exceeds a fraction $\\beta$ of the total physical memory, where $\\beta = 0.82$ and $0<\\beta<1$.\n\nUsing the canonical definition of the working set and thrashing, where thrashing is the regime in which sustained page reclamation forces working set pages to be repeatedly evicted and refetched, formalize the condition for the onset of thrashing for this workload from first principles and derive the largest integer $n_{\\max}$ such that thrashing does not occur. Then evaluate $n_{\\max}$ numerically for the given $M$, $W$, and $\\beta$. Express your final answer as an integer count (unitless). No rounding beyond the integer maximum is required.", "solution": "The problem is first subjected to a validation process to ensure its scientific soundness, consistency, and well-posed nature.\n\n### Step 1: Extract Givens\n- Total physical Random Access Memory (RAM): $M = 256$ GiB.\n- Number of identical jobs: $n$.\n- Steady-state memory working set per job: $W = 9$ GiB.\n- Working set measurement window: $\\Delta t$.\n- Memory pressure threshold fraction: $\\beta = 0.82$.\n- Constraint on the threshold: $0 < \\beta < 1$.\n- Definition of thrashing: The regime in which sustained page reclamation forces working set pages to be repeatedly evicted and refetched.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in the principles of operating system memory management, specifically the working set model proposed by Peter Denning. Thrashing is a well-defined phenomenon that occurs when the combined memory demands of active processes exceed the available physical memory, leading to excessive paging activity and a collapse in system throughput. The problem statement uses standard terminology and provides a clear, quantitative setup. The given values for memory size ($M = 256$ GiB), working set size ($W = 9$ GiB), and memory pressure threshold ($\\beta = 0.82$) are realistic for a High-Performance Computing (HPC) environment. The problem is self-contained, as the time window $\\Delta t$ is part of the definition of the given working set size $W$, but its specific value is not required for the calculation. The objective is to derive a maximum number of jobs $n_{\\max}$ based on these parameters, which is a well-posed question. The problem contains no scientific or factual unsoundness, no contradictions, and no ambiguities.\n\n### Step 3: Verdict and Action\nThe problem is deemed valid. A solution will be derived from first principles.\n\n### Derivation of the Thrashing Condition and Solution\n\nThe fundamental principle to prevent thrashing is to ensure that the aggregate working set of all concurrently running processes can be accommodated within the available physical memory. The working set of a process is the set of pages it has accessed over a recent time window $\\Delta t$. For a process to execute efficiently, its entire working set must remain resident in physical memory. If pages from the working set are evicted (swapped out), they will likely be needed again soon, leading to a page fault and subsequent I/O to fetch the page back from secondary storage. When this happens at a high rate for a significant number of processes, the system is said to be thrashing.\n\nThe problem states that there are $n$ identical jobs, each with a working set of size $W$. The total memory demand required to hold the working sets of all $n$ jobs in memory simultaneously is the aggregate working set size, which is given by:\n$$\n\\text{Total Working Set Demand} = n \\cdot W\n$$\n\nThe operating system monitors memory pressure and begins sustained page reclamation when the total resident memory demand exceeds a fraction $\\beta$ of the total physical memory $M$. This threshold, $\\beta \\cdot M$, represents the maximum amount of physical memory that the OS allows to be occupied by user processes before it takes aggressive measures (like swapping out pages that might be in active use) to free up memory. The remaining fraction, $(1-\\beta)M$, constitutes the \"reclaim headroom,\" reserved for the operating system kernel, file system caches, and to provide a buffer against sudden memory allocation spikes.\n\nTo avoid thrashing, the aggregate working set demand of all jobs must not exceed this operational memory capacity. If the total working set demand is greater than $\\beta \\cdot M$, the OS will be forced to reclaim pages that are part of one or more jobs' working sets. This action directly satisfies the problem's definition of thrashing: \"sustained page reclamation forces working set pages to be repeatedly evicted and refetched.\"\n\nTherefore, the condition to operate without thrashing is:\n$$\nn \\cdot W \\le \\beta \\cdot M\n$$\n\nThe problem asks for the largest integer $n_{\\max}$ for which this condition holds. We can solve for $n$ by rearranging the inequality:\n$$\nn \\le \\frac{\\beta \\cdot M}{W}\n$$\n\nSince $n$ must be an integer representing the number of jobs, the maximum value $n_{\\max}$ is the largest integer that satisfies this inequality. This is equivalent to taking the floor of the expression on the right-hand side:\n$$\nn_{\\max} = \\left\\lfloor \\frac{\\beta \\cdot M}{W} \\right\\rfloor\n$$\n\nNow, we substitute the numerical values provided in the problem statement to evaluate $n_{\\max}$:\n- $M = 256$ GiB\n- $W = 9$ GiB\n- $\\beta = 0.82$\n\nPlugging these values into the expression for $n_{\\max}$:\n$$\nn_{\\max} = \\left\\lfloor \\frac{0.82 \\cdot 256 \\text{ GiB}}{9 \\text{ GiB}} \\right\\rfloor\n$$\n\nThe units of GiB cancel, yielding a dimensionless quantity as expected for a count of jobs. We perform the calculation:\n$$\nn_{\\max} = \\left\\lfloor \\frac{209.92}{9} \\right\\rfloor\n$$\n$$\nn_{\\max} = \\left\\lfloor 23.32444... \\right\\rfloor\n$$\n\nThe floor of this value is $23$. Therefore, the largest integer number of jobs that can run concurrently without inducing thrashing is $23$. If $24$ jobs were to run, their aggregate working set demand ($24 \\cdot 9$ GiB $= 216$ GiB) would exceed the allowed memory threshold ($0.82 \\cdot 256$ GiB $\\approx 209.92$ GiB), triggering sustained page reclamation and, consequently, thrashing.", "answer": "$$\n\\boxed{23}\n$$", "id": "3685321"}, {"introduction": "While calculating static thresholds is useful, real systems are dynamic, with memory being allocated and freed continuously. This hands-on simulation task asks you to model a memory system and implement a back-pressure mechanism—a feedback loop where high swapping activity throttles new memory requests [@problem_id:3685318]. By translating a formal model into code and testing its stability, you will see firsthand how control theory principles are applied to maintain system health under memory pressure.", "problem": "You are to design and implement a discrete-time simulation of a memory allocator under swapping with back-pressure. The scenario concerns the effect of a thresholded control signal that slows allocations when swapping activity is high. The aim is to measure system stability in terms of bounded memory usage and controlled swapping intensity.\n\nFundamental bases and core definitions:\n- Conservation over discrete time: for any state variable $x$ updated at integer steps $t \\in \\{0,1,2,\\dots\\}$, the next value satisfies a balance of inflow minus outflow, written as $x_{t+1} = x_t + \\text{inflow}_t - \\text{outflow}_t$. This is a general conservation principle applicable to resource accumulation subject to arrivals and departures.\n- Swapping in operating systems: swapping is a mechanism by which memory pages are moved between physical memory and secondary storage when physical memory is overcommitted. Physical memory capacity is a fixed amount measured in pages; allocation inflow increases resident memory pages, and deallocation outflow reduces them. Swapping intensity increases with the degree of overcommit.\n\nModel definitions:\n- Let $P$ be the physical memory capacity in pages.\n- Let $M_t$ be the resident memory pages allocated at time step $t$.\n- Let $r$ be the base allocation request rate in pages per step (desired inflow if unconstrained).\n- Let $\\mu$ be the deallocation fraction per step, so the deallocation outflow at time $t$ is $\\mu M_t$.\n- Let $\\alpha$ be a proportionality constant mapping overcommit to swapping intensity.\n- Let $\\tau$ be the swapping threshold for back-pressure activation.\n- Let $k$ be the throttle strength in the allocator response.\n- Let $f_t$ be the swapping intensity at step $t$, modeled as a fraction proportional to the degree of overcommit:\n$$\nf_t = \\alpha \\cdot \\max\\left(0, \\frac{M_t - P}{P}\\right).\n$$\n- The allocator applies back-pressure when $f_t > \\tau$ by scaling the inflow. Define the scaling function $s(f_t, \\tau, k)$ as:\n$$\ns(f_t, \\tau, k) = \n\\begin{cases}\n1, & f_t \\le \\tau, \\\\\n\\frac{1}{1 + k \\cdot (f_t - \\tau)}, & f_t > \\tau.\n\\end{cases}\n$$\n- The closed-loop memory evolution is defined by the conservation update:\n$$\nM_{t+1} = \\max\\left(0, M_t + r \\cdot s(f_t, \\tau, k) - \\mu M_t \\right).\n$$\nThe $\\max$ maintains non-negativity of memory pages.\n\nStability measurement:\n- Let $f_{\\mathrm{crit}}$ be a critical swapping intensity threshold.\n- Define a window length $W$ and total simulation length $N$ steps. Over the last $W$ steps of the simulation, compute:\n    1. The maximum memory ratio:\n    $$\n    \\max\\limits_{t \\in \\{N-W,\\dots,N\\}} \\frac{M_t}{P}.\n    $$\n    2. The maximum swapping intensity:\n    $$\n    \\max\\limits_{t \\in \\{N-W,\\dots,N-1\\}} f_t.\n    $$\n    3. The mean absolute change in memory:\n    $$\n    \\frac{1}{W} \\sum_{t=N-W+1}^{N} \\left| M_t - M_{t-1} \\right|.\n    $$\n- With fixed tolerances $\\delta = 0.05$ (allowing up to $5$ percent overcapacity) and $\\epsilon = 1$ page, declare the system stable if and only if all of the following hold:\n    - $\\max\\limits_{t \\in \\{N-W,\\dots,N\\}} \\frac{M_t}{P} \\le 1 + \\delta$,\n    - $\\max\\limits_{t \\in \\{N-W,\\dots,N-1\\}} f_t \\le f_{\\mathrm{crit}}$,\n    - $\\frac{1}{W} \\sum_{t=N-W+1}^{N} \\left| M_t - M_{t-1} \\right| \\le \\epsilon$.\n\nImplementation requirements:\n- Write a complete program that, without user input, simulates multiple test cases and outputs a single line containing stability results as integers, one per test case, where $1$ denotes stable and $0$ denotes unstable.\n- Units: memory is in pages, time is in discrete steps, and swapping intensity is a dimensionless fraction per step.\n- For each test case, initialize $M_0$ as given in pages and iterate the update for $t = 0, 1, \\dots, N-1$. Use the last $W$ steps for stability measurements; if $W > N$, use the last $\\min(W, N)$ steps.\n\nTest suite:\nProvide the following $5$ test cases covering different scenarios, including a typical case, boundary conditions, and edge cases. Each test case is defined by $(P, r, \\mu, \\alpha, \\tau, k, f_{\\mathrm{crit}}, N, W, M_0)$.\n\n- Case $1$ (typical balanced workload): $P = 1000$, $r = 80$, $\\mu = 0.08$, $\\alpha = 0.8$, $\\tau = 0.2$, $k = 5$, $f_{\\mathrm{crit}} = 0.4$, $N = 300$, $W = 50$, $M_0 = 600$.\n- Case $2$ (early throttling boundary: $\\tau = 0$): $P = 1000$, $r = 120$, $\\mu = 0.08$, $\\alpha = 1.0$, $\\tau = 0.0$, $k = 8$, $f_{\\mathrm{crit}} = 0.35$, $N = 300$, $W = 50$, $M_0 = 600$.\n- Case $3$ (high demand, weak throttle): $P = 1000$, $r = 150$, $\\mu = 0.02$, $\\alpha = 1.2$, $\\tau = 0.5$, $k = 4$, $f_{\\mathrm{crit}} = 0.4$, $N = 400$, $W = 80$, $M_0 = 900$.\n- Case $4$ (no back-pressure: $k = 0$): $P = 1000$, $r = 100$, $\\mu = 0.05$, $\\alpha = 1.0$, $\\tau = 0.3$, $k = 0$, $f_{\\mathrm{crit}} = 0.3$, $N = 300$, $W = 50$, $M_0 = 500$.\n- Case $5$ (strong throttle, lower capacity): $P = 800$, $r = 100$, $\\mu = 0.10$, $\\alpha = 1.0$, $\\tau = 0.1$, $k = 12$, $f_{\\mathrm{crit}} = 0.5$, $N = 300$, $W = 60$, $M_0 = 400$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[1,0,1,1,0]$). Each entry corresponds to one test case in the order listed above. No other output is permitted.", "solution": "The problem presents a well-posed, scientifically grounded model of a computer memory allocation system featuring swapping and back-pressure. All variables, parameters, and evolution equations are explicitly defined, forming a deterministic discrete-time dynamical system. The criteria for system stability are precisely stated, allowing for an unambiguous computational solution. The problem is therefore valid.\n\nThe solution involves simulating the state of memory over time and then analyzing the trajectory to determine stability. The core of the model is the conservation principle for the number of allocated memory pages, $M_t$, at each discrete time step $t \\in \\{0, 1, 2, \\dots, N\\}$. The state update equation is given by:\n$$\nM_{t+1} = \\max\\left(0, M_t + \\text{inflow}_t - \\text{outflow}_t \\right)\n$$\nwhere `max` ensures that the number of pages does not become negative.\n\nThe outflow is modeled as a constant fraction $\\mu$ of the currently allocated pages:\n$$\n\\text{outflow}_t = \\mu M_t\n$$\nThe inflow is a base allocation request rate $r$ that is throttled by a scaling factor $s(f_t, \\tau, k)$ when swapping activity becomes high.\n$$\n\\text{inflow}_t = r \\cdot s(f_t, \\tau, k)\n$$\nThe scaling factor $s(f_t, \\tau, k)$ depends on the swapping intensity $f_t$. Swapping intensity is modeled as being proportional to the degree of memory overcommitment relative to the physical capacity $P$:\n$$\nf_t = \\alpha \\cdot \\max\\left(0, \\frac{M_t - P}{P}\\right)\n$$\nwhere $\\alpha$ is a proportionality constant. The system applies back-pressure via the scaling function $s(f_t, \\tau, k)$ when the swapping intensity $f_t$ exceeds a threshold $\\tau$. The function is defined as:\n$$\ns(f_t, \\tau, k) = \n\\begin{cases}\n1, & f_t \\le \\tau \\\\\n\\frac{1}{1 + k \\cdot (f_t - \\tau)}, & f_t > \\tau\n\\end{cases}\n$$\nThis function reduces the inflow rate as swapping intensity $f_t$ increases beyond the threshold $\\tau$, with $k$ controlling the strength of this feedback.\n\nCombining these components yields the complete evolution equation for memory pages:\n$$\nM_{t+1} = \\max\\left(0, M_t + r \\cdot s(f_t, \\tau, k) - \\mu M_t \\right)\n$$\nThe simulation proceeds by iteratively applying this equation starting from an initial state $M_0$ for $t = 0, 1, \\dots, N-1$. The history of memory states, $M_0, M_1, \\dots, M_N$, is stored for analysis.\n\nAfter the simulation completes, system stability is evaluated over a trailing window of $W$ steps. The effective window size is $W_{\\text{eff}} = \\min(W, N)$. Three metrics are computed:\n\n1.  Maximum memory ratio: The peak memory usage relative to capacity, computed over the state history from $M_{N-W_{\\text{eff}}}$ to $M_N$.\n    $$\n    \\max\\_ratio = \\max\\limits_{t \\in \\{N-W_{\\text{eff}},\\dots,N\\}} \\frac{M_t}{P}\n    $$\n2.  Maximum swapping intensity: The peak swapping activity, computed over the states from $M_{N-W_{\\text{eff}}}$ to $M_{N-1}$.\n    $$\n    \\max\\_f = \\max\\limits_{t \\in \\{N-W_{\\text{eff}},\\dots,N-1\\}} f_t\n    $$\n3.  Mean absolute change in memory: The average magnitude of memory fluctuation per time step, computed over the effective window.\n    $$\n    \\text{mean\\_abs\\_change} = \\frac{1}{W_{\\text{eff}}} \\sum_{t=N-W_{\\text{eff}}+1}^{N} \\left| M_t - M_{t-1} \\right|\n    $$\n\nThe system is declared stable if and only if all three of the following conditions are met, with given tolerances $\\delta = 0.05$ and $\\epsilon = 1.0$:\n- $\\max\\_ratio \\le 1 + \\delta$\n- $\\max\\_f \\le f_{\\mathrm{crit}}$\n- $\\text{mean\\_abs\\_change} \\le \\epsilon$\n\nThe C implementation will systematically process each test case. For each case, it will allocate an array to store the sequence $M_t$, run the simulation loop, compute the three stability metrics according to their definitions, and finally apply the stability conditions to yield a binary result ($1$ for stable, $0$ for unstable). The results for all test cases are then formatted into a single output line as specified.", "answer": "```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n\n// A custom max function for doubles.\nstatic inline double double_max(double a, double b) {\n    return a > b ? a : b;\n}\n\n// A struct to hold the parameters for a single test case.\ntypedef struct {\n    double P;\n    double r;\n    double mu;\n    double alpha;\n    double tau;\n    double k;\n    double f_crit;\n    int N;\n    int W;\n    double M0;\n} TestCase;\n\nint main(void) {\n    // Define the test cases from the problem statement.\n    TestCase test_cases[] = {\n        {1000.0, 80.0, 0.08, 0.8, 0.2, 5.0, 0.4, 300, 50, 600.0},\n        {1000.0, 120.0, 0.08, 1.0, 0.0, 8.0, 0.35, 300, 50, 600.0},\n        {1000.0, 150.0, 0.02, 1.2, 0.5, 4.0, 0.4, 400, 80, 900.0},\n        {1000.0, 100.0, 0.05, 1.0, 0.3, 0.0, 0.3, 300, 50, 500.0},\n        {800.0, 100.0, 0.10, 1.0, 0.1, 12.0, 0.5, 300, 60, 400.0}\n    };\n\n    // Calculate the number of test cases.\n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    int results[num_cases];\n    \n    // Stability condition constants\n    const double delta = 0.05;\n    const double epsilon = 1.0;\n\n    // Calculate the result for each test case.\n    for (int i = 0; i < num_cases; ++i) {\n        TestCase tc = test_cases[i];\n\n        // Allocate memory for the history of M_t values.\n        double* M_history = malloc((size_t)(tc.N + 1) * sizeof(double));\n        if (M_history == NULL) {\n            perror(\"Failed to allocate memory for simulation history\");\n            return EXIT_FAILURE;\n        }\n\n        M_history[0] = tc.M0;\n\n        // Run the discrete-time simulation.\n        for (int t = 0; t < tc.N; ++t) {\n            double M_t = M_history[t];\n\n            // Calculate swapping intensity f_t\n            double f_t = tc.alpha * double_max(0.0, (M_t - tc.P) / tc.P);\n\n            // Calculate scaling function s(f_t, tau, k)\n            double s_t;\n            if (f_t <= tc.tau) {\n                s_t = 1.0;\n            } else {\n                s_t = 1.0 / (1.0 + tc.k * (f_t - tc.tau));\n            }\n\n            // Calculate M_{t+1} using the conservation update equation.\n            double M_t_plus_1 = double_max(0.0, M_t + tc.r * s_t - tc.mu * M_t);\n            M_history[t + 1] = M_t_plus_1;\n        }\n\n        // --- Stability Measurement Phase ---\n        \n        // Adjust window size W if it's larger than the simulation length N.\n        int effective_W = (tc.W > tc.N) ? tc.N : tc.W;\n\n        // Metric 1: Maximum memory ratio\n        double max_mem_ratio = 0.0;\n        for (int t = tc.N - effective_W; t <= tc.N; ++t) {\n            max_mem_ratio = double_max(max_mem_ratio, M_history[t] / tc.P);\n        }\n\n        // Metric 2: Maximum swapping intensity\n        double max_f = 0.0;\n        for (int t = tc.N - effective_W; t < tc.N; ++t) {\n            double current_f = tc.alpha * double_max(0.0, (M_history[t] - tc.P) / tc.P);\n            max_f = double_max(max_f, current_f);\n        }\n\n        // Metric 3: Mean absolute change in memory\n        double sum_abs_change = 0.0;\n        for (int t = tc.N - effective_W + 1; t <= tc.N; ++t) {\n            sum_abs_change += fabs(M_history[t] - M_history[t - 1]);\n        }\n        double mean_abs_change = (effective_W > 0) ? sum_abs_change / effective_W : 0.0;\n\n        // Final Verdict: Check if all stability conditions are met.\n        int is_stable = (max_mem_ratio <= 1.0 + delta) &&\n                        (max_f <= tc.f_crit) &&\n                        (mean_abs_change <= epsilon);\n        \n        results[i] = is_stable;\n\n        free(M_history);\n    }\n\n    // Print the results in the EXACT REQUIRED format.\n    printf(\"[\");\n    for (int i = 0; i < num_cases; ++i) {\n        printf(\"%d%s\", results[i], (i == num_cases - 1) ? \"\" : \",\");\n    }\n    printf(\"]\\n\");\n\n    return EXIT_SUCCESS;\n}\n```", "id": "3685318"}, {"introduction": "Real-world operating systems are full of interacting features whose effects can be complex. This final practice explores a common conflict: the interaction between swapping and Transparent Huge Pages (THP). You will act as a systems engineer, analyzing performance data to design a robust policy that intelligently disables THP only when it's actively harming performance, using techniques like smoothing and hysteresis to avoid unstable, \"flapping\" behavior [@problem_id:3685380].", "problem": "A system running Transparent Huge Pages (THP) experiences intermittent latency spikes under memory pressure. Consider the following fundamentals. A major page fault occurs when a page is not in main memory and must be fetched from secondary storage, potentially causing swapping. Swap thrashing is the state where the working set of active processes exceeds the available physical memory such that the system spends a substantial fraction of time paging rather than executing useful work. Let page faults per second (pf/s) be the rate defined by $\\text{pf/s} = \\Delta F / \\Delta t$, where $\\Delta F$ is the change in the cumulative count of major page faults over interval $\\Delta t$. Let the THP allocation failure rate be $r_{\\text{fail}} = \\Delta N_{\\text{fail}} / \\Delta N_{\\text{attempt}}$, where $\\Delta N_{\\text{attempt}}$ is the number of THP allocation attempts and $\\Delta N_{\\text{fail}}$ is the number of those attempts that failed. Under memory fragmentation and pressure, THP allocation failures can induce kernel memory compaction and page splitting, which may exacerbate swap activity. You are tasked with deciding when to disable THP to mitigate swap thrashing while avoiding oscillations.\n\nAfter enabling THP at time $t = 0$, the system is observed over $3$ consecutive intervals of length $\\Delta t = 10 \\text{ s}$. The counters are as follows:\n\n- Interval $1$: $\\Delta F = 3100$, $\\Delta N_{\\text{attempt}} = 400$, $\\Delta N_{\\text{fail}} = 160$.\n- Interval $2$: $\\Delta F = 2600$, $\\Delta N_{\\text{attempt}} = 500$, $\\Delta N_{\\text{fail}} = 200$.\n- Interval $3$: $\\Delta F = 1700$, $\\Delta N_{\\text{attempt}} = 300$, $\\Delta N_{\\text{fail}} = 60$.\n\nAssume a baseline smoothed page fault rate just before enabling THP of $m_0 = 50$ pf/s. A proposed policy aims to disable THP only when it is likely contributing to swap thrashing, using the conjunction of high page fault pressure and signs of THP-related memory management overhead. Let the thresholds be $\\theta = 200$ pf/s and $\\eta = 0.3$. Suppose smoothing is desired to reduce sensitivity to transient spikes, and hysteresis is desired to avoid flapping when conditions sit near thresholds.\n\nWhich option most appropriately specifies a robust disable-and-reenable heuristic based on these observations and thresholds, and correctly concludes what action should be taken by the end of Interval $3$?\n\nA. Disable THP if the instantaneous $\\text{pf/s}$ in any single interval exceeds $\\theta$ or the THP allocation failure rate exceeds $\\eta$; re-enable as soon as either instantaneous metric falls below its threshold. Under the given data, disable at the end of Interval $1$ and re-enable at the end of Interval $3$.\n\nB. Disable THP when a smoothed $\\text{pf/s}$, computed as an exponentially weighted moving average with weight $\\alpha = 0.7$, exceeds $\\theta$ for at least $2$ consecutive intervals and the THP allocation failure rate also exceeds $\\eta$ for at least $2$ consecutive intervals; re-enable only after both metrics remain below lower hysteresis thresholds $\\theta_{\\text{low}} = 0.6 \\theta$ and $\\eta_{\\text{low}} = 0.5 \\eta$ for $3$ consecutive intervals. Under the given data, disable at the end of Interval $2$ and keep THP disabled through Interval $3$.\n\nC. Disable THP if the minor page fault rate exceeds $\\theta$, regardless of THP allocation failures; re-enable when the THP allocation failure rate drops below $\\eta$. Under the given data, disable at the end of Interval $1$ and re-enable at the end of Interval $2$.\n\nD. Disable THP only if the THP allocation failure rate exceeds $\\eta$ for $3$ consecutive intervals, ignoring $\\text{pf/s}$ as too noisy; re-enable when allocation failures fall below $\\eta$. Under the given data, never disable THP.", "solution": "The problem statement is evaluated for validity before proceeding to a solution.\n\n### Step 1: Extract Givens\n- A system is running Transparent Huge Pages (THP).\n- Major page fault definition is provided.\n- Swap thrashing definition is provided.\n- Page fault rate is defined as $\\text{pf/s} = \\Delta F / \\Delta t$.\n- THP allocation failure rate is defined as $r_{\\text{fail}} = \\Delta N_{\\text{fail}} / \\Delta N_{\\text{attempt}}$.\n- The problem context states that THP allocation failures can exacerbate swap activity.\n- The task is to specify a robust disable-and-reenable heuristic for THP to mitigate swap thrashing while avoiding oscillations.\n- Observation period consists of $3$ consecutive intervals, each with duration $\\Delta t = 10 \\text{ s}$.\n- Data for Interval $1$: $\\Delta F = 3100$, $\\Delta N_{\\text{attempt}} = 400$, $\\Delta N_{\\text{fail}} = 160$.\n- Data for Interval $2$: $\\Delta F = 2600$, $\\Delta N_{\\text{attempt}} = 500$, $\\Delta N_{\\text{fail}} = 200$.\n- Data for Interval $3$: $\\Delta F = 1700$, $\\Delta N_{\\text{attempt}} = 300$, $\\Delta N_{\\text{fail}} = 60$.\n- Baseline smoothed page fault rate before enabling THP: $m_0 = 50$ pf/s.\n- Proposed policy thresholds: $\\theta = 200$ pf/s and $\\eta = 0.3$.\n- Desired policy characteristics: smoothing and hysteresis.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in the domain of operating systems, specifically memory management. The concepts of Transparent Huge Pages (THP), page faults, swap thrashing, memory compaction, and the potential negative interactions between them are well-established. The use of control-theoretic principles like smoothing (e.g., EWMA) and hysteresis to create stable system policies is a standard and robust engineering practice. The problem is well-posed, providing all necessary definitions and data to evaluate the proposed heuristics in the options. The language is objective and precise. The numerical values are plausible for a system under heavy load. The problem does not violate any of the specified invalidity criteria.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. A solution will be derived.\n\n### Derivation and Option Analysis\n\nFirst, we calculate the instantaneous metrics for each of the $3$ intervals based on the provided data and definitions. Let $p_i$ be the page fault rate and $r_i$ be the THP allocation failure rate for interval $i$. The interval duration is given as $\\Delta t = 10 \\text{ s}$.\n\n**Interval 1:**\n- Page fault rate: $p_1 = \\frac{\\Delta F_1}{\\Delta t} = \\frac{3100}{10 \\text{ s}} = 310 \\text{ pf/s}$.\n- THP allocation failure rate: $r_1 = \\frac{\\Delta N_{\\text{fail,1}}}{\\Delta N_{\\text{attempt,1}}} = \\frac{160}{400} = 0.4$.\n\n**Interval 2:**\n- Page fault rate: $p_2 = \\frac{\\Delta F_2}{\\Delta t} = \\frac{2600}{10 \\text{ s}} = 260 \\text{ pf/s}$.\n- THP allocation failure rate: $r_2 = \\frac{\\Delta N_{\\text{fail,2}}}{\\Delta N_{\\text{attempt,2}}} = \\frac{200}{500} = 0.4$.\n\n**Interval 3:**\n- Page fault rate: $p_3 = \\frac{\\Delta F_3}{\\Delta t} = \\frac{1700}{10 \\text{ s}} = 170 \\text{ pf/s}$.\n- THP allocation failure rate: $r_3 = \\frac{\\Delta N_{\\text{fail,3}}}{\\Delta N_{\\text{attempt,3}}} = \\frac{60}{300} = 0.2$.\n\nThe thresholds are $\\theta = 200 \\text{ pf/s}$ and $\\eta = 0.3$.\nWe can summarize the comparison of the metrics to their respective thresholds:\n- Interval $1$: $p_1 = 310 > \\theta$ and $r_1 = 0.4 > \\eta$.\n- Interval $2$: $p_2 = 260 > \\theta$ and $r_2 = 0.4 > \\eta$.\n- Interval $3$: $p_3 = 170 < \\theta$ and $r_3 = 0.2 < \\eta$.\n\nThe problem asks for a \"robust disable-and-reenable heuristic\" that avoids oscillations, explicitly mentioning smoothing and hysteresis as desirable features. We now evaluate each option against this requirement and the calculated data.\n\n**A. Disable THP if the instantaneous $\\text{pf/s}$ in any single interval exceeds $\\theta$ or the THP allocation failure rate exceeds $\\eta$; re-enable as soon as either instantaneous metric falls below its threshold. Under the given data, disable at the end of Interval $1$ and re-enable at the end of Interval $3$.**\n\nThis heuristic is based on instantaneous values and lacks any form of smoothing or hysteresis. A policy that triggers on single-interval threshold crossings is highly susceptible to \"flapping\" or oscillations, where the system rapidly toggles THP on and off. The problem statement explicitly calls for a robust policy that avoids this behavior. Therefore, the proposed heuristic is poorly designed. Applying its logic: at the end of Interval $1$, $p_1 > \\theta$, so THP would be disabled. At the end of interval $3$, both $p_3 < \\theta$ and $r_3 < \\eta$, so THP would be re-enabled. While the conclusion about the actions is arithmetically sound based on the flawed policy, the policy itself is not robust and contradicts the design goals.\n\n**Verdict: Incorrect.**\n\n**B. Disable THP when a smoothed $\\text{pf/s}$, computed as an exponentially weighted moving average with weight $\\alpha = 0.7$, exceeds $\\theta$ for at least $2$ consecutive intervals and the THP allocation failure rate also exceeds $\\eta$ for at least $2$ consecutive intervals; re-enable only after both metrics remain below lower hysteresis thresholds $\\theta_{\\text{low}} = 0.6 \\theta$ and $\\eta_{\\text{low}} = 0.5 \\eta$ for $3$ consecutive intervals. Under the given data, disable at the end of Interval $2$ and keep THP disabled through Interval $3$.**\n\nThis heuristic incorporates all the desired features of a robust control policy:\n1.  **Smoothing**: It uses an exponentially weighted moving average (EWMA) for the page fault rate, $m_i = \\alpha p_i + (1-\\alpha) m_{i-1}$, to dampen transient spikes.\n2.  **Persistence**: It requires a condition to be met for $2$ consecutive intervals before disabling and $3$ intervals before re-enabling, preventing reactions to brief fluctuations.\n3.  **Hysteresis**: It uses separate, lower thresholds for re-enabling ($\\theta_{\\text{low}}$, $\\eta_{\\text{low}}$) to create a dead-band that prevents flapping around the primary thresholds.\n4.  **Conjunction**: It requires both high page fault pressure and high THP allocation failures, correctly diagnosing the specific problem scenario described.\n\nLet's apply this policy to the data. The smoothing parameter is $\\alpha = 0.7$, and the initial smoothed value is $m_0 = 50 \\text{ pf/s}$. The thresholds are $\\theta = 200 \\text{ pf/s}$ and $\\eta = 0.3$.\n- **Interval 1:**\n  - Smoothed pf/s: $m_1 = \\alpha p_1 + (1-\\alpha)m_0 = (0.7)(310) + (0.3)(50) = 217 + 15 = 232 \\text{ pf/s}$.\n  - Conditions: $m_1 = 232 > \\theta$ and $r_1 = 0.4 > \\eta$. This is the first interval meeting the disable criteria. No action is taken yet.\n- **Interval 2:**\n  - Smoothed pf/s: $m_2 = \\alpha p_2 + (1-\\alpha)m_1 = (0.7)(260) + (0.3)(232) = 182 + 69.6 = 251.6 \\text{ pf/s}$.\n  - Conditions: $m_2 = 251.6 > \\theta$ and $r_2 = 0.4 > \\eta$. This is the second consecutive interval meeting the disable criteria.\n  - **Action**: At the end of Interval $2$, the policy triggers, and THP is disabled.\n- **Interval 3:**\n  - The policy keeps THP disabled. The re-enable condition requires $3$ consecutive intervals where metrics are below $\\theta_{\\text{low}} = 0.6 \\theta = 120 \\text{ pf/s}$ and $\\eta_{\\text{low}} = 0.5 \\eta = 0.15$. In Interval $3$, $p_3=170 > \\theta_{\\text{low}}$ and $r_3 = 0.2 > \\eta_{\\text{low}}$. The re-enable condition is not met.\n\nThe heuristic is robustly designed, and its application to the data leads to the conclusion stated in the option: disable at the end of Interval $2$ and keep it disabled.\n\n**Verdict: Correct.**\n\n**C. Disable THP if the minor page fault rate exceeds $\\theta$, regardless of THP allocation failures; re-enable when the THP allocation failure rate drops below $\\eta$. Under the given data, disable at the end of Interval $1$ and re-enable at the end of Interval $2$.**\n\nThis option is fundamentally flawed. The policy rule is based on the **minor** page fault rate. The problem provides data exclusively for **major** page faults, as defined by $\\Delta F$. One cannot substitute a metric for another. Minor and major page faults represent different system events. Furthermore, the disabling condition ignores the THP failure rate, which is a key indicator. The re-enabling logic is asymmetric to the disabling logic and lacks hysteresis, making it a poor design. Since the policy cannot be evaluated with the given data, this option is invalid.\n\n**Verdict: Incorrect.**\n\n**D. Disable THP only if the THP allocation failure rate exceeds $\\eta$ for $3$ consecutive intervals, ignoring $\\text{pf/s}$ as too noisy; re-enable when allocation failures fall below $\\eta$. Under the given data, never disable THP.**\n\nThis heuristic is poorly conceived because it completely ignores the primary symptom of the problem it aims to solve. Swap thrashing is defined by excessive paging activity, so any policy to mitigate it must consider the page fault rate ($\\text{pf/s}$). While the failure rate $r_{\\text{fail}}$ is an indicator of THP-induced pressure, it is not a direct measure of thrashing. The re-enable condition lacks persistence and hysteresis, making it prone to flapping. Applying the flawed logic:\n- Condition: $r_i > \\eta = 0.3$ for $3$ consecutive intervals.\n- Interval $1$: $r_1 = 0.4 > 0.3$. (Met for $1$ interval)\n- Interval $2$: $r_2 = 0.4 > 0.3$. (Met for $2$ intervals)\n- Interval $3$: $r_3 = 0.2 < 0.3$. (Not met)\nThe condition is not met for $3$ consecutive intervals, so THP is never disabled. The conclusion drawn in the option is a correct application of its own deficient rule, but the rule itself is not appropriate.\n\n**Verdict: Incorrect.**\n\nIn summary, Option B is the only one that proposes a heuristic that is consistent with established principles of robust control systems engineering (smoothing, hysteresis, persistence) and correctly addresses the problem as stated (using a conjunction of relevant metrics). The calculations supporting its conclusion are also correct.", "answer": "$$\\boxed{B}$$", "id": "3685380"}]}