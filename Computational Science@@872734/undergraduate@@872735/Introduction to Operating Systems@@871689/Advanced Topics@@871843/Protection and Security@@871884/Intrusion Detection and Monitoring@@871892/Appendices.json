{"hands_on_practices": [{"introduction": "A fundamental technique in intrusion detection is to establish a baseline of known-good system configurations and alert on any deviations. This exercise formalizes that idea by representing complex `systemd` unit files as simple binary feature vectors. You will practice using a quantitative measure, the Hamming distance, to calculate the 'distance' of a new unit from a set of approved templates, providing a clear metric for identifying potentially unauthorized changes [@problem_id:3650781].", "problem": "An operating system configuration monitoring pipeline for an Intrusion Detection System (IDS) uses a whitelist baseline to detect stealthy persistence in Linux System Manager (systemd) unit files. Each unit is mapped to a binary feature vector of length $12$, where position $i$ indicates the presence ($1$) or absence ($0$) of a specific directive condition. The monitored features are fixed and applied uniformly to all units:\n- $f_{1}$: The $ExecStart$ command invokes a shell interpreter.\n- $f_{2}$: The $ExecStartPre$ directive is present.\n- $f_{3}$: The $ExecStartPost$ directive is present.\n- $f_{4}$: The $Type$ directive is set to $simple$.\n- $f_{5}$: The $Restart$ directive is set to $always$.\n- $f_{6}$: The $RestartSec$ directive is specified.\n- $f_{7}$: The $RemainAfterExit$ directive is specified.\n- $f_{8}$: The $WantedBy$ directive includes $multi-user.target$.\n- $f_{9}$: The $StandardOutput$ directive is set to $null$.\n- $f_{10}$: At least one $Environment$ key-value is defined.\n- $f_{11}$: A $ConditionPathExists$ directive is present.\n- $f_{12}$: The $User$ directive is specified and is non-root.\n\nThe whitelist contains three approved templates, each represented as a binary vector in the fixed feature order $\\left(f_{1}, f_{2}, \\dots, f_{12}\\right)$:\n$$\\mathbf{t}_{1} = (0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1)$$\n$$\\mathbf{t}_{2} = (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1)$$\n$$\\mathbf{t}_{3} = (0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0)$$\n\nA newly observed unit is mapped to the feature vector:\n$$\\mathbf{x} = (1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0).$$\n\nTreat the distance between two units as the count of positions at which their corresponding binary feature entries differ. Compute the minimal distance between $\\mathbf{x}$ and the whitelist set $\\{\\mathbf{t}_{1}, \\mathbf{t}_{2}, \\mathbf{t}_{3}\\}$. Provide your final answer as a single number. No rounding is required.", "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the context of computer science and operating systems security, using standard mathematical formalisms (binary vectors, distance metrics). The problem is well-posed, self-contained, and provides all necessary data and definitions for a unique solution.\n\nThe problem requires computing the minimal distance between a given feature vector $\\mathbf{x}$ and a set of whitelist template vectors $\\{\\mathbf{t}_{1}, \\mathbf{t}_{2}, \\mathbf{t}_{3}\\}$. All vectors are elements of the vector space $\\{0, 1\\}^{12}$. The distance metric is defined as \"the count of positions at which their corresponding binary feature entries differ.\" This is formally known as the Hamming distance.\n\nFor two binary vectors $\\mathbf{a} = (a_{1}, a_{2}, \\dots, a_{n})$ and $\\mathbf{b} = (b_{1}, b_{2}, \\dots, b_{n})$ of length $n$, the Hamming distance $d_{H}(\\mathbf{a}, \\mathbf{b})$ is given by the sum of the element-wise differences (which, for binary digits, is equivalent to the number of non-zero elements in the vector resulting from the bitwise XOR operation):\n$$d_{H}(\\mathbf{a}, \\mathbf{b}) = \\sum_{i=1}^{n} |a_{i} - b_{i}|$$\nIn this problem, the length of the vectors is $n=12$.\n\nThe given vectors are:\nThe observed unit vector:\n$$\\mathbf{x} = (1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0)$$\nThe whitelist template vectors:\n$$\\mathbf{t}_{1} = (0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1)$$\n$$\\mathbf{t}_{2} = (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1)$$\n$$\\mathbf{t}_{3} = (0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0)$$\n\nWe must compute the Hamming distance from $\\mathbf{x}$ to each template vector $\\mathbf{t}_{i}$ and then find the minimum of these distances.\n\n1.  **Compute the distance between $\\mathbf{x}$ and $\\mathbf{t}_{1}$:**\n    $d_{H}(\\mathbf{x}, \\mathbf{t}_{1}) = \\sum_{i=1}^{12} |x_{i} - t_{1,i}|$\n    The differing positions are $i=1, 3, 5, 7, 9, 11, 12$.\n    $d_{H}(\\mathbf{x}, \\mathbf{t}_{1}) = |1-0| + |0-0| + |1-0| + |1-1| + |1-0| + |1-1| + |1-0| + |1-1| + |1-0| + |1-1| + |1-0| + |0-1|$\n    $d_{H}(\\mathbf{x}, \\mathbf{t}_{1}) = 1 + 0 + 1 + 0 + 1 + 0 + 1 + 0 + 1 + 0 + 1 + 1 = 7$\n\n2.  **Compute the distance between $\\mathbf{x}$ and $\\mathbf{t}_{2}$:**\n    $d_{H}(\\mathbf{x}, \\mathbf{t}_{2}) = \\sum_{i=1}^{12} |x_{i} - t_{2,i}|$\n    The differing positions are $i=1, 3, 4, 5, 6, 8, 9, 10, 12$.\n    $d_{H}(\\mathbf{x}, \\mathbf{t}_{2}) = |1-0| + |0-0| + |1-0| + |1-0| + |1-0| + |1-0| + |1-1| + |1-0| + |1-0| + |1-0| + |1-1| + |0-1|$\n    $d_{H}(\\mathbf{x}, \\mathbf{t}_{2}) = 1 + 0 + 1 + 1 + 1 + 1 + 0 + 1 + 1 + 1 + 0 + 1 = 9$\n\n3.  **Compute the distance between $\\mathbf{x}$ and $\\mathbf{t}_{3}$:**\n    $d_{H}(\\mathbf{x}, \\mathbf{t}_{3}) = \\sum_{i=1}^{12} |x_{i} - t_{3,i}|$\n    The differing positions are $i=1, 2, 4, 7, 9, 11$.\n    $d_{H}(\\mathbf{x}, \\mathbf{t}_{3}) = |1-0| + |0-1| + |1-1| + |1-0| + |1-1| + |1-1| + |1-0| + |1-1| + |1-0| + |1-1| + |1-0| + |0-0|$\n    $d_{H}(\\mathbf{x}, \\mathbf{t}_{3}) = 1 + 1 + 0 + 1 + 0 + 0 + 1 + 0 + 1 + 0 + 1 + 0 = 6$\n\nThe set of computed distances is $\\{7, 9, 6\\}$. The minimal distance is the minimum value in this set.\nMinimal distance $= \\min\\{d_{H}(\\mathbf{x}, \\mathbf{t}_{1}), d_{H}(\\mathbf{x}, \\mathbf{t}_{2}), d_{H}(\\mathbf{x}, \\mathbf{t}_{3})\\}$\nMinimal distance $= \\min\\{7, 9, 6\\} = 6$\n\nThis minimal distance of $6$ indicates that the observed unit $\\mathbf{x}$ is \"closest\" to the whitelist template $\\mathbf{t}_{3}$, differing in $6$ feature conditions. In the context of an IDS, this distance would be compared against a threshold to determine if an alert should be generated.", "answer": "$$\\boxed{6}$$", "id": "3650781"}, {"introduction": "Beyond static files, an effective IDS must analyze dynamic system events in real-time. This practice challenges you to design a precise detection rule that identifies a common attack pattern—an unexpected interpreter launched by a service—while correctly ignoring legitimate administrative tasks that look similar [@problem_id:3650735]. Developing this kind of contextual logic is key to building a high-fidelity monitoring system that minimizes the noise of false positives.", "problem": "An operating system monitoring agent instruments the system call (syscall) $execve$ and emits structured events. Each event is modeled as a tuple $E = \\langle \\text{pid}, \\text{ppid}, \\text{name}, \\text{argv}, \\text{env}, \\text{tty}, \\text{cgroup}, \\text{path}, \\text{unit}, t \\rangle$, where $t$ is the event time, $\\text{name}$ is the basename of the executed program, $\\text{tty}$ denotes the controlling terminal (or $\\emptyset$ if none), $\\text{cgroup}$ is the control group path, and $\\text{unit}$ is the associated service unit name when known. You aim to build a runtime policy that raises an alert when a non-interactive service unexpectedly executes an interpreter via $execve$ (for example, launching $bash$ or $python$), while minimizing false positives from legitimate initialization scripts.\n\nStart from the following core definitions and facts rooted in operating systems and detection theory:\n\n- A process without a controlling terminal is non-interactive if and only if $\\text{tty} = \\emptyset$.\n- In systems using system and service manager units, long-running services commonly reside under control groups matching a pattern such as $\\text{cgroup} \\in \\mathcal{C}$, where $\\mathcal{C}$ includes entries like $\\text{system.slice}$ and unit-scoped subpaths; one-shot initialization tasks (init scripts) are associated with units of type oneshot or phases labeled pre/post (for example, $\\text{ExecStartPre}$, $\\text{ExecStartPost}$).\n- The syscall $execve$ replaces the current process image; invoking an interpreter introduces increased attack surface when the interpreter runs with the service’s privileges, especially post-boot.\n- Interpreters form a set $\\mathcal{I}$, e.g., $\\mathcal{I} = \\{\\text{bash}, \\text{sh}, \\text{zsh}, \\text{python}, \\text{perl}, \\text{ruby}, \\text{node}\\}$.\n- False positives occur when an alert is raised for expected, legitimate behavior. Initialization scripts are legitimately allowed to run interpreters during early boot and unit pre/post phases.\n- Let $T_{\\text{boot}}$ be the last system boot time. Define an early-boot window $\\Delta$ seconds, with $\\Delta$ chosen to cover typical initialization activity. For this problem, assume $\\Delta = 300$.\n\nYou are given that adversarial activity of concern involves a long-running service (for example, a database or web server process) that, well after boot, $execve$s an interpreter due to exploitation, while legitimate init scripts commonly run within $t \\in [T_{\\text{boot}}, T_{\\text{boot}} + \\Delta]$ and/or as oneshot or pre/post phases. You must choose a single policy predicate $D(E)$ that raises an alert for an event $E$ if and only if $D(E)$ evaluates to true.\n\nWhich policy below most effectively detects unexpected $execve$ of interpreters by non-interactive services while minimizing false positives from legitimate init scripts? Select the best option.\n\nA. Raise an alert if $\\text{tty} = \\emptyset$, $\\text{cgroup} \\in \\mathcal{C}$, and $\\text{name} \\in \\mathcal{I}$.\n\nB. Raise an alert if $\\text{tty} = \\emptyset$, $\\text{cgroup} \\in \\mathcal{C}$, and $\\text{name} \\in \\mathcal{I}$, but suppress alerts when $t - T_{\\text{boot}} \\le \\Delta$ or when $\\text{unit}$ is of type oneshot or the phase is pre/post; additionally, suppress when $\\text{ppid}$ maps to known init wrappers in a whitelist $\\mathcal{W}$ (for example, paths under $\\text{/etc/init.d}$ and $\\text{/lib/systemd}$).\n\nC. Raise an alert only if $\\text{tty} = \\emptyset$, $\\text{name} \\in \\mathcal{I}$, and the process opens a Transmission Control Protocol (TCP) socket within $2$ seconds of $execve$ as observed by the monitoring agent.\n\nD. Raise an alert if the count of $execve$ events with $\\text{name} \\in \\mathcal{I}$ seen from any non-interactive process exceeds $10$ in a $60$-minute window, regardless of service unit, boot time, or phase.\n\nAnswer the question by selecting the single best option. Justify your reasoning using the given definitions and facts, carefully considering how to reduce false positives from init scripts without missing the described adversarial behavior. Do not assume any unstated capabilities or data beyond the event fields provided and the stated facts.", "solution": "The objective is to create a high-fidelity detection policy that identifies unauthorized interpreter executions by services while minimizing false positives from legitimate system initialization and maintenance tasks. A systematic evaluation of each option against this goal reveals the optimal choice.\n\n*   **Option A** is too broad. While it correctly identifies the core suspicious pattern (a non-interactive service running an interpreter), it lacks any context to differentiate between a malicious act and a legitimate one. System services frequently use interpreters in initialization scripts (e.g., `ExecStartPre`) or for maintenance tasks, all of which would match this rule and generate a high volume of false positives.\n*   **Option C** is overly specific and prone to false negatives. It makes detection contingent on a subsequent network action (opening a TCP socket). An attacker could use the compromised interpreter for many other malicious purposes, such as local data manipulation, privilege escalation, or reconnaissance, none of which this rule would detect. It focuses on one possible *consequence* of the intrusion rather than the intrusion itself.\n*   **Option D** is a crude statistical rule that is poorly suited for detecting targeted attacks. It would fail to detect a single, deliberate execution of an interpreter (a false negative), which is a common and critical attack pattern. Conversely, a legitimate, complex script running as a background job could easily exceed the threshold, generating a false positive. This policy ignores the rich contextual data available in the event.\n*   **Option B** is the most effective and well-designed policy. It starts with the same strong core pattern as Option A but then systematically applies suppression logic based on contextual evidence of legitimate behavior.\n    1.  **Temporal Context:** It suppresses alerts during the initial boot phase ($t - T_{\\text{boot}} \\le \\Delta$), which is a common time for initialization scripts to run.\n    2.  **Semantic Context:** It suppresses alerts for units explicitly defined as one-shot tasks or as part of a pre/post execution phase, correctly identifying them as setup or teardown operations rather than the main service loop.\n    3.  **Process Context:** It uses parent process information (`ppid`) to whitelist executions spawned by known, trusted system wrappers.\n\nThis layered, context-aware approach allows the policy to precisely distinguish between the targeted malicious activity (an unexpected interpreter launched by a long-running service outside of a setup phase) and the legitimate system noise. It achieves the best balance between maximizing true positives and minimizing false positives.\n\nTherefore, Option B represents the most scientifically sound and practical approach to solving the stated detection problem.", "answer": "$$\\boxed{B}$$", "id": "3650735"}, {"introduction": "Effective security is not just about detecting intrusions, but also about understanding and prioritizing risks. This problem guides you through building a probabilistic model to quantify the expected monetary loss from a temporary security weakness—the removal of protective filesystem mount flags [@problem_id:3650719]. By applying concepts such as Poisson processes for attack arrivals and exponential distributions for detection times, you will translate an abstract security gap into a concrete financial risk assessment.", "problem": "A Linux operating system uses mount flags to mitigate classes of attacks at the filesystem boundary. The flags $noexec$, $nodev$, and $nosuid$ respectively prevent execution of binaries from a mount, creation or use of device files on a mount, and honoring set-user-identifier bits on a mount. An Intrusion Detection System (IDS) monitors the kernel’s mount events; if an attacker removes these flags on a monitored mount, the IDS eventually detects and reverts the mount configuration. Assume the following model grounded in core definitions from probability and operating systems:\n\n- For each of the three attack vectors corresponding to the three flags, attacker attempts arrive as a Poisson process with constant rate $\\lambda_i$ attempts per hour when the mount is in a compromised state (flags removed).\n- Conditioned on an attempt, the probability of a successful compromise depends on whether the protective flag is present. With the flag present, the success probability is $\\alpha_i$. With the flag removed, the success probability is $\\beta_i$, where $\\beta_i > \\alpha_i$.\n- Each successful compromise on vector $i$ produces an expected monetary loss of $L_i$ dollars, independent across attempts and vectors.\n- The IDS detection-and-revert time $T$ after the flag-removal event is exponentially distributed with parameter $\\mu$ per hour due to memoryless polling and independent alerting delays.\n\nAssume the three vectors are independent, arrivals are independent of detection, and stationarity holds during the short detection window.\n\nA single mount event removes all three flags simultaneously on a critical mount, and remains in that state until the IDS reverts it. Quantify the expected additional monetary loss incurred during this window due to the flag removal, compared to the counterfactual where the flags had remained in place for the same duration. Use the following parameters:\n\n- For the $noexec$-related vector: $\\lambda_1 = 0.03$ per hour, $\\alpha_1 = 0.05$, $\\beta_1 = 0.60$, $L_1 = 3000$ dollars.\n- For the $nodev$-related vector: $\\lambda_2 = 0.004$ per hour, $\\alpha_2 = 0.02$, $\\beta_2 = 0.40$, $L_2 = 12000$ dollars.\n- For the $nosuid$-related vector: $\\lambda_3 = 0.015$ per hour, $\\alpha_3 = 0.01$, $\\beta_3 = 0.50$, $L_3 = 8000$ dollars.\n- IDS detection parameter: $\\mu = 0.5$ per hour.\n\nExpress the final result in dollars, and round your answer to $4$ significant figures.", "solution": "The problem asks for the expected additional monetary loss incurred during a window of vulnerability. This window begins when protective mount flags are removed and ends when an Intrusion Detection System (IDS) detects the change and reverts it. The duration of this window, $T$, is a random variable following an exponential distribution with rate parameter $\\mu$.\n\nLet $\\Delta L_{\\text{total}}$ be the total additional monetary loss. The problem states there are three independent attack vectors, indexed by $i \\in \\{1, 2, 3\\}$. By the linearity of expectation, the total expected additional loss is the sum of the expected additional losses for each vector:\n$$E[\\Delta L_{\\text{total}}] = \\sum_{i=1}^{3} E[\\Delta L_i]$$\nwhere $E[\\Delta L_i]$ is the expected additional loss for attack vector $i$.\n\nLet us analyze a single attack vector $i$.\nThe arrival of attack attempts is modeled as a Poisson process with rate $\\lambda_i$. A key property of a Poisson process is that if events are selected independently with a constant probability $p$, the resulting process of selected events is also a Poisson process with a rate of $\\lambda_i p$. This is known as Poisson thinning.\n\nIn our case, the events are successful compromises.\nWhen the protective flag is present, the probability of success is $\\alpha_i$. The rate of successful compromises is $\\lambda_i^{\\alpha} = \\lambda_i \\alpha_i$.\nWhen the protective flag is removed, the probability of success is $\\beta_i$. The rate of successful compromises is $\\lambda_i^{\\beta} = \\lambda_i \\beta_i$.\n\nThe loss is incurred over a random time interval $[0, T]$, where the probability density function of $T$ is $f_T(t) = \\mu \\exp(-\\mu t)$ for $t \\ge 0$. The expected duration of this interval is $E[T] = \\frac{1}{\\mu}$.\n\nThe additional loss for vector $i$, $\\Delta L_i$, is the difference between the loss that occurs with flags removed and the loss that would have occurred with flags present, over the same random duration $T$. Let $N_i^{\\beta}(t)$ and $N_i^{\\alpha}(t)$ be the number of successful compromises over a time interval $t$ with flags removed and present, respectively. These are random variables following Poisson distributions with parameters $\\lambda_i \\beta_i t$ and $\\lambda_i \\alpha_i t$. The associated losses are $L_i N_i^{\\beta}(T)$ and $L_i N_i^{\\alpha}(T)$.\n\nThe expected additional loss is:\n$$E[\\Delta L_i] = E[L_i N_i^{\\beta}(T) - L_i N_i^{\\alpha}(T)] = L_i \\left( E[N_i^{\\beta}(T)] - E[N_i^{\\alpha}(T)] \\right)$$\nTo find the expectation of $N(T)$, where $N(t)$ is a Poisson process with rate $\\lambda'$ and $T$ is an independent random variable, we use the Law of Total Expectation (also known as the tower property), $E[X] = E_Y[E[X|Y]]$.\n$$E[N(T)] = E_T[E[N(T)|T=t]]$$\nFor a fixed duration $t$, the expected number of events for a Poisson process with rate $\\lambda'$ is $E[N(t)] = \\lambda' t$.\n$$E[N(T)] = E_T[\\lambda' T] = \\lambda' E[T]$$\nSince $T$ is exponentially distributed with parameter $\\mu$, its expectation is $E[T] = \\frac{1}{\\mu}$.\nTherefore, the expected number of events over the random interval is:\n$$E[N(T)] = \\frac{\\lambda'}{\\mu}$$\nApplying this result to our two scenarios:\n$$E[N_i^{\\beta}(T)] = \\frac{\\lambda_i \\beta_i}{\\mu}$$\n$$E[N_i^{\\alpha}(T)] = \\frac{\\lambda_i \\alpha_i}{\\mu}$$\nSubstituting these back into the expression for the expected additional loss for vector $i$:\n$$E[\\Delta L_i] = L_i \\left( \\frac{\\lambda_i \\beta_i}{\\mu} - \\frac{\\lambda_i \\alpha_i}{\\mu} \\right) = \\frac{L_i \\lambda_i (\\beta_i - \\alpha_i)}{\\mu}$$\nThe total expected additional loss is the sum over all three vectors:\n$$E[\\Delta L_{\\text{total}}] = \\sum_{i=1}^{3} \\frac{L_i \\lambda_i (\\beta_i - \\alpha_i)}{\\mu} = \\frac{1}{\\mu} \\sum_{i=1}^{3} L_i \\lambda_i (\\beta_i - \\alpha_i)$$\nNow, we substitute the given parameters.\nThe IDS detection parameter is $\\mu = 0.5$ per hour.\n\nFor vector $i=1$ ($noexec$):\n$\\lambda_1 = 0.03$ per hour, $\\alpha_1 = 0.05$, $\\beta_1 = 0.60$, $L_1 = 3000$ dollars.\nTerm $1$: $L_1 \\lambda_1 (\\beta_1 - \\alpha_1) = 3000 \\times 0.03 \\times (0.60 - 0.05) = 3000 \\times 0.03 \\times 0.55 = 49.5$.\n\nFor vector $i=2$ ($nodev$):\n$\\lambda_2 = 0.004$ per hour, $\\alpha_2 = 0.02$, $\\beta_2 = 0.40$, $L_2 = 12000$ dollars.\nTerm $2$: $L_2 \\lambda_2 (\\beta_2 - \\alpha_2) = 12000 \\times 0.004 \\times (0.40 - 0.02) = 12000 \\times 0.004 \\times 0.38 = 18.24$.\n\nFor vector $i=3$ ($nosuid$):\n$\\lambda_3 = 0.015$ per hour, $\\alpha_3 = 0.01$, $\\beta_3 = 0.50$, $L_3 = 8000$ dollars.\nTerm $3$: $L_3 \\lambda_3 (\\beta_3 - \\alpha_3) = 8000 \\times 0.015 \\times (0.50 - 0.01) = 8000 \\times 0.015 \\times 0.49 = 58.8$.\n\nThe sum of these terms is:\n$$\\sum_{i=1}^{3} L_i \\lambda_i (\\beta_i - \\alpha_i) = 49.5 + 18.24 + 58.8 = 126.54$$\nFinally, we compute the total expected additional loss:\n$$E[\\Delta L_{\\text{total}}] = \\frac{1}{0.5} \\times 126.54 = 2 \\times 126.54 = 253.08$$\nThe problem requires the answer to be rounded to $4$ significant figures. The number $253.08$ rounded to four significant figures is $253.1$.\nThe expected additional loss, in dollars, is $253.1$.", "answer": "$$\\boxed{253.1}$$", "id": "3650719"}]}