{"hands_on_practices": [{"introduction": "One of the operating system's most fundamental roles is to manage shared resources securely, preventing one user's actions from harming another's. This exercise explores a core POSIX filesystem feature—the sticky bit—that provides a crucial layer of protection in world-writable directories like `/tmp`. By working through this hypothetical scenario [@problem_id:3673293], you will clarify the often-misunderstood distinction between permissions for modifying a directory's contents and permissions for accessing a file's data, a key concept in preventing unauthorized file tampering.", "problem": "An Operating System (OS) conforming to the Portable Operating System Interface (POSIX) runs a multi-user server where students share project folders. Consider two directories on the same filesystem: a shared workspace directory $D_s = \\text{/shared}$ with mode $1777$ (that is, world-writable and with the sticky bit set), owned by user $u_0$ (the administrator), and an open scratch directory $D_o = \\text{/scratch}$ with mode $0777$ (world-writable, no sticky bit), also owned by user $u_0$. Two users, $u_A$ and $u_B$, collaborate on projects. In $D_s$, user $u_A$ creates a regular file $f_A = \\text{/shared/report.txt}$ with mode $0644$ (owner read-write, group read, others read). User $u_B$ runs a malware sample $M_B$ without elevated privileges and attempts typical malicious actions in both $D_s$ and $D_o$: bulk deletion of other users' files, replacement via rename, content modification, symbolic-link redirection, and directory entry manipulation.\n\nBased on the foundational semantics of POSIX directories and the sticky bit, which of the following statements correctly identify how $D_s$ and $D_o$ mitigate or permit $M_B$'s behaviors? Select all that apply.\n\nA. In $D_s$ with mode $1777$, a process of $u_B$ cannot unlink or rename $f_A$ unless $u_B$ owns $f_A$, owns $D_s$, or has superuser privileges; therefore, mass-deletion of other users' files is directly mitigated by the sticky bit.\n\nB. The sticky bit on $D_s$ does not constrain read or write operations on the contents of $f_A$; thus, if $f_A$ were writable by $u_B$, content modification by $M_B$ would still be possible despite the sticky bit.\n\nC. In $D_o$ with mode $0777$, unlink of $f_A$ by $u_B$ is permitted provided $u_B$ has write and execute permissions on $D_o$, irrespective of $f_A$'s own mode bits; therefore, deletion protection based solely on $f_A$'s permissions is ineffective in $D_o$.\n\nD. The sticky bit on $D_s$ prevents $u_B$ from creating symbolic links in $D_s$ that point to sensitive paths elsewhere; therefore, symbolic-link redirection attacks are blocked by the sticky bit.\n\nE. The permission check for unlinking $f_A$ is performed against $f_A$'s mode bits; consequently, if $f_A$ is not writable by $u_B$, $u_B$ cannot unlink it even in a world-writable directory.", "solution": "The problem asks to evaluate several statements concerning file system permissions in a POSIX-compliant Operating System, specifically contrasting a world-writable directory with the sticky bit set ($D_s$) against one without it ($D_o$). To validate the statements, we must first establish the fundamental principles governing file and directory operations in POSIX.\n\n**First Principles:**\n1.  **Accessing File Contents (read/write):** Permission to read from or write to a file's data is governed by the file's own mode bits, in conjunction with the user's ID and group memberships. To perform these actions, one must also have execute (`x`) permission on the containing directory and all its parent directories to be able to traverse the path to the file's inode.\n2.  **Modifying Directory Contents (create/delete/rename):** The ability to create, delete (`unlink`), or rename a file within a directory is governed by the permissions of the **directory itself**. Specifically, a user must have both write (`w`) and execute (`x`) permissions on the directory to modify its contents. The permissions of the file being deleted or renamed are not checked for this operation.\n3.  **The Sticky Bit on Directories (mode `t`):** When the sticky bit is set on a world-writable directory (e.g., mode $1777$), it adds a crucial restriction to the rule for deletion and renaming. A process can only unlink or rename a file in that directory if the effective user ID of the process is one of the following:\n    *   The owner of the file.\n    *   The owner of the directory.\n    *   The superuser (root).\n    This rule applies *in addition to* the standard requirement of write and execute permissions on the directory. The sticky bit does not affect file creation or operations on file contents.\n\n**Problem Setup Analysis:**\n*   Directory $D_s$: Path `/shared`, mode $1777$. This is a world-writable, world-executable directory with the sticky bit set. It is owned by $u_0$.\n*   Directory $D_o$: Path `/scratch`, mode $0777$. This is a world-writable, world-executable directory without the sticky bit. It is also owned by $u_0$.\n*   File $f_A$: Path `/shared/report.txt`, owned by user $u_A$, mode $0644$. This means owner $u_A$ has read/write, while group and others (including user $u_B$) have read-only access.\n*   User $u_B$: A non-privileged user who is not $u_A$ and not $u_0$. $u_B$ attempts actions via malware $M_B$.\n\nWe will now evaluate each statement based on these principles.\n\n**A. In $D_s$ with mode $1777$, a process of $u_B$ cannot unlink or rename $f_A$ unless $u_B$ owns $f_A$, owns $D_s$, or has superuser privileges; therefore, mass-deletion of other users' files is directly mitigated by the sticky bit.**\nThis statement directly applies the rule of the sticky bit. User $u_B$ attempts to unlink or rename the file $f_A$, which is owned by $u_A$.\n1.  Does $u_B$ have write and execute permission on $D_s$? Yes, the mode is $1777$.\n2.  Is the sticky bit set on $D_s$? Yes.\n3.  Therefore, the additional checks apply. Does $u_B$ own the file $f_A$? No, $u_A$ does. Does $u_B$ own the directory $D_s$? No, $u_0$ does. Is $u_B$ the superuser? No, the problem states no elevated privileges.\nSince none of the conditions for overriding the sticky bit's protection are met, $u_B$ cannot unlink or rename $f_A$. The \"therefore\" clause correctly concludes that this mechanism prevents a user from deleting other users' files in a shared directory, thus mitigating mass-deletion attacks. The statement is a correct and precise description of the sticky bit's purpose and effect.\n**Verdict: Correct.**\n\n**B. The sticky bit on $D_s$ does not constrain read or write operations on the contents of $f_A$; thus, if $f_A$ were writable by $u_B$, content modification by $M_B$ would still be possible despite the sticky bit.**\nThe sticky bit is a property of the directory that governs directory entry manipulation (`unlink`, `rename`). It has no effect on the permissions related to the file's content. The ability to read or write a file's content is governed by the file's own mode bits. The statement correctly asserts this separation of concerns. If $f_A$ had a mode like $0666$, granting write permission to \"others\", then $u_B$ would be able to modify its contents, as the sticky bit on the parent directory $D_s$ would not be checked for a `write()` system call. The statement correctly identifies the scope and limitation of the sticky bit's protection.\n**Verdict: Correct.**\n\n**C. In $D_o$ with mode $0777$, unlink of $f_A$ by $u_B$ is permitted provided $u_B$ has write and execute permissions on $D_o$, irrespective of $f_A$'s own mode bits; therefore, deletion protection based solely on $f_A$'s permissions is ineffective in $D_o$.**\nThis statement analyzes the behavior in directory $D_o$, which has mode $0777$ (world-writable, no sticky bit). To unlink a file, the kernel checks only if the user has write and execute permissions on the containing directory.\n1.  Does $u_B$ have write and execute permissions on $D_o$? Yes, from mode $0777$.\n2.  Is the sticky bit set? No.\nTherefore, no further checks are made. $u_B$ can unlink any file within $D_o$, regardless of who owns that file or what the file's own permissions are. The statement that the `unlink` is permitted \"irrespective of $f_A$'s own mode bits\" is a fundamental tenet of POSIX permissions. The conclusion that file permissions alone are ineffective for deletion protection in a world-writable directory (without a sticky bit) is accurate. This is precisely the vulnerability that the sticky bit was designed to fix.\n**Verdict: Correct.**\n\n**D. The sticky bit on $D_s$ prevents $u_B$ from creating symbolic links in $D_s$ that point to sensitive paths elsewhere; therefore, symbolic-link redirection attacks are blocked by the sticky bit.**\nThis statement is incorrect. The creation of any file type (including regular files, directories, and symbolic links) in a directory requires only write and execute permissions on that directory. The sticky bit only restricts deletion and renaming of existing entries not owned by the user. Since $D_s$ has mode $1777$, user $u_B$ has the necessary `w` and `x` permissions to create new entries. The sticky bit places no constraints on this creative action. Therefore, $u_B$ is free to create a symbolic link in $D_s$, and the sticky bit does not block this form of attack.\n**Verdict: Incorrect.**\n\n**E. The permission check for unlinking $f_A$ is performed against $f_A$'s mode bits; consequently, if $f_A$ is not writable by $u_B$, $u_B$ cannot unlink it even in a world-writable directory.**\nThis statement describes a common but incorrect understanding of POSIX permissions. The `unlink` system call removes a name-to-inode link from a directory; it is an operation on the directory, not on the file's content or metadata. As such, the permission check for `unlink` is performed on the directory's permissions (requiring `w` and `x`), not the file's. The file's own permissions are irrelevant. The entire purpose of the sticky bit is to compensate for this fact in shared directories. Without the sticky bit, as in $D_o$, $u_B$ can indeed unlink $f_A$ (if it were in $D_o$) even though $f_A$ itself is not writable by $u_B$.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{ABC}$$", "id": "3673293"}, {"introduction": "Modern security often relies on detecting the byproducts of malicious activity, and ransomware provides a clear example by generating encrypted files that appear highly random. This practice introduces a quantitative detection method using Shannon entropy, a concept from information theory, to measure this randomness. This problem [@problem_id:3673396] challenges you to think like a security engineer, using hypothetical statistical models to design a detector and balance the critical trade-off between maximizing the true detection rate and minimizing disruptive false positives.", "problem": "An operating system file-monitoring subsystem computes per-file Shannon entropy $H$ (in bits per byte) immediately after any write operation, using the definition\n$$\nH \\;=\\; -\\sum_{b=0}^{255} p(b)\\,\\log_2 p(b),\n$$\nwhere $p(b)$ is the empirical probability that byte value $b$ appears in the file. A security team proposes an entropy-threshold detector: flag a file as suspicious if $H \\ge \\tau$. They aim to detect ransomware, which encrypts user files and typically produces byte distributions close to uniform (i.e., $H$ near $8$). However, they know that benign compressed archives also exhibit high entropy and can cause false positives.\n\nAssume the following empirically observed distributions of $H$ for newly modified files, modeled as independent normal random variables:\n- Benign uncompressed text/source files: $H \\sim \\mathcal{N}(\\mu_b, \\sigma_b^2)$ with $\\mu_b = 5.2$ and $\\sigma_b = 0.4$.\n- Benign compressed archives (e.g., zip, gzip): $H \\sim \\mathcal{N}(\\mu_c, \\sigma_c^2)$ with $\\mu_c = 7.6$ and $\\sigma_c = 0.2$.\n- Ransomware-encrypted outputs: $H \\sim \\mathcal{N}(\\mu_r, \\sigma_r^2)$ with $\\mu_r = 7.95$ and $\\sigma_r = 0.05$.\n\nThe design requirements are:\n- The false positive rate on benign uncompressed files must satisfy $\\Pr[H \\ge \\tau \\mid \\text{uncompressed}] \\le 10^{-3}$.\n- The detection rate on ransomware outputs must satisfy $\\Pr[H \\ge \\tau \\mid \\text{ransomware}] \\ge 0.95$.\n- Among thresholds $\\tau$ that satisfy both constraints, prefer the choice that minimizes expected false positives on compressed archives, i.e., minimizes $\\Pr[H \\ge \\tau \\mid \\text{compressed}]$.\n\nBased on these requirements and the normal-model assumptions above, which option most appropriately chooses $\\tau$, correctly characterizes the false positives on compressed archives, and proposes realistic operating system countermeasures that complement entropy-based detection without relying solely on it?\n\nA. Choose $\\tau = 7.90$ because it is close to $8$, claim $\\Pr[H \\ge \\tau \\mid \\text{ransomware}] \\ge 0.95$ and $\\Pr[H \\ge \\tau \\mid \\text{compressed}] \\approx 0$, and mitigate residual risk by disabling the compression subsystem entirely to eliminate false positives.\n\nB. Choose $\\tau \\approx 7.87$ to satisfy both $\\Pr[H \\ge \\tau \\mid \\text{uncompressed}] \\le 10^{-3}$ and $\\Pr[H \\ge \\tau \\mid \\text{ransomware}] \\ge 0.95$ while minimizing $\\Pr[H \\ge \\tau \\mid \\text{compressed}]$ among feasible $\\tau$. Acknowledge that $\\Pr[H \\ge \\tau \\mid \\text{compressed}]$ is nontrivial (on the order of a few $\\times 10^{-2}$ to $10^{-1}$), and propose complementary operating system measures such as copy-on-write (COW) snapshots via Volume Shadow Copy Service (VSS) to allow rapid rollback, per-process write-burst anomaly detection with I/O rate limiting, and extension/path-based whitelisting to reduce flags for known archive outputs.\n\nC. Choose $\\tau \\approx 6.44$ by meeting only the uncompressed false positive constraint, assert that ransomware detection will be near perfect and compressed false positives negligible, and mitigate harm by increasing the central processing unit (CPU) scheduling priority of any process that triggers the detector so it completes quickly, reducing user disruption.\n\nD. Choose $\\tau = 7.60$ to align with the compressed mean, claim this balances detection and false positives, and propose immediately terminating any process writing files with $H \\ge \\tau$ without logging or snapshotting to maximize prevention.\n\nE. Choose $\\tau = 7.75$ to exceed typical compressed entropy, claim that both constraints hold with minimal compressed false positives, and suggest relying exclusively on entropy thresholding without additional operating system mechanisms because high entropy uniquely identifies ransomware.", "solution": "The problem is to find an optimal threshold $\\tau$ for an entropy-based ransomware detector. We must satisfy two constraints and then optimize a third criterion. The given distributions are:\n-   Benign uncompressed: $H_b \\sim \\mathcal{N}(5.2, 0.4^2)$\n-   Benign compressed: $H_c \\sim \\mathcal{N}(7.6, 0.2^2)$\n-   Ransomware: $H_r \\sim \\mathcal{N}(7.95, 0.05^2)$\n\n**1. Analyze the Constraints to Find the Feasible Range for $\\tau$**\n\nLet $Z$ be a standard normal random variable, $Z \\sim \\mathcal{N}(0, 1)$. We use its cumulative distribution function $\\Phi(z)$ and its inverse $\\Phi^{-1}(p)$.\n\n*   **Constraint 1: False positive rate on uncompressed files.**\n    The false positive rate on uncompressed files must be at most $10^{-3}$.\n    $\\Pr[H_b \\ge \\tau] \\le 10^{-3}$\n    Standardizing the variable: $\\Pr\\left[Z \\ge \\frac{\\tau - 5.2}{0.4}\\right] \\le 10^{-3}$.\n    The standard normal quantile for a tail probability of $10^{-3}$ is $z_{0.001} = \\Phi^{-1}(0.999) \\approx 3.0902$.\n    The constraint becomes: $\\frac{\\tau - 5.2}{0.4} \\ge 3.0902 \\implies \\tau \\ge 5.2 + (0.4 \\times 3.0902) \\implies \\tau \\ge 6.436$.\n\n*   **Constraint 2: Detection rate on ransomware.**\n    The detection rate for ransomware must be at least $0.95$.\n    $\\Pr[H_r \\ge \\tau] \\ge 0.95$\n    Standardizing: $\\Pr\\left[Z \\ge \\frac{\\tau - 7.95}{0.05}\\right] \\ge 0.95$.\n    This means the standardized value must be less than or equal to the quantile for a cumulative probability of $1-0.95 = 0.05$. This quantile is $z_{0.95} = \\Phi^{-1}(0.05) \\approx -1.6449$.\n    The constraint becomes: $\\frac{\\tau - 7.95}{0.05} \\le -1.6449 \\implies \\tau \\le 7.95 - (0.05 \\times 1.6449) \\implies \\tau \\le 7.868$.\n\nCombining both constraints, the feasible range for the threshold is $\\tau \\in [6.436, 7.868]$.\n\n**2. Optimize the Threshold**\n\n*   **Criterion 3: Minimize false positives on compressed archives.**\n    We need to minimize $\\Pr[H_c \\ge \\tau] = \\Pr\\left[Z \\ge \\frac{\\tau - 7.6}{0.2}\\right]$.\n    This probability is a decreasing function of $\\tau$. To minimize it, we must choose the largest possible value of $\\tau$ from the feasible range.\n    Therefore, the optimal threshold is $\\tau_{\\text{opt}} = 7.868 \\approx 7.87$.\n\n**3. Evaluate the Options**\n\n*   **Option B** correctly identifies the optimal threshold as $\\tau \\approx 7.87$. At this threshold, the false positive rate on compressed files is $\\Pr[H_c \\ge 7.87] = \\Pr\\left[Z \\ge \\frac{7.87 - 7.6}{0.2}\\right] = \\Pr[Z \\ge 1.35] \\approx 0.0885$, or about $8.9\\%$. This rate is correctly described as \"nontrivial.\" The proposed complementary OS measures (COW snapshots, I/O rate limiting, whitelisting) are realistic and represent a sound, multi-layered security strategy.\n*   **Option A** chooses an invalid $\\tau=7.90$, which violates Constraint 2 (the detection rate would be only about $84\\%$). Its proposed countermeasure is unrealistic.\n*   **Option C** chooses the worst possible feasible threshold ($\\tau \\approx 6.44$), which maximizes false positives on compressed archives to nearly $100\\%$. Its proposed countermeasure is dangerously counter-productive.\n*   **Option D** chooses a suboptimal threshold ($\\tau=7.6$) with a $50\\%$ false positive rate on compressed files and proposes a reckless countermeasure (termination without logging).\n*   **Option E** chooses a suboptimal threshold ($\\tau=7.75$) and makes the factually incorrect assertion that high entropy uniquely identifies ransomware, ignoring the problem's own premise.\n\nTherefore, Option B is the only one that performs the correct optimization, accurately assesses the results, and proposes sound engineering solutions.", "answer": "$$\\boxed{B}$$", "id": "3673396"}, {"introduction": "Advanced malware no longer announces its presence; instead, it actively tries to blend in with normal system activity to achieve persistence and evade detection. This exercise focuses on process forensics, where you must differentiate legitimate but complex system behaviors (like daemonization and containerization) from subtle anomalies in the process tree that hint at a stealthy intruder. By analyzing these scenarios [@problem_id:3673363], you will learn why context is critical in modern threat detection and develop the analytical skills needed to design smarter, less noisy auditing strategies.", "problem": "An administrator of a multi-tenant Linux-like Operating System (OS) is investigating stealthy malware that attempts to hide in the process tree. Consider the following observations made from a host over a period of several hours, where each process record contains a Process Identifier (PID), Parent Process Identifier (PPID), command name, executable path, and basic metadata (user identifier, cgroup, and process state). All times and identifiers below are representative and internally consistent with typical POSIX process semantics.\n\n- Observation $1$: Several short-lived compiler or shell helper processes occasionally appear as zombies for approximately $0.02$ seconds because their parents are busy (e.g., due to high input/output). They are immediately reaped. These are rare and transient.\n- Observation $2$: A lightweight init inside a container (e.g., “tini”) with PID $2600$ is configured as a subreaper via a parent setting (using a process control flag) so that orphaned processes inside that container are adopted by this subreaper, not by the host init. All processes in this container belong to a dedicated Control Group (cgroup) hierarchy for the container (e.g., a path under a container slice).\n- Observation $3$: A supervised service “daemonX” starts via the host service manager and uses the double-fork pattern. The grandparent is the service manager, and the final daemon has PPID $1$ after its parent exits, but it is labeled and accounted for under the correct system service unit cgroup.\n- Observation $4$: A user-space process named “ksoftirqd/0” runs for $2$ hours with PPID $1$, owned by an unprivileged user. Its executable path shows “(deleted)” and its memory mappings indicate a user-space executable file was unlinked from the file system but remains loaded. It is not part of any known service unit cgroup and is not within any container cgroup.\n- Observation $5$: A user-launched “python” process with PID $5000$ fails to call a wait family of system calls on several children. These children remain zombies for more than $5$ minutes, accumulating as load increases. The parent continues running but does not reap them.\n\nYou must decide which auditing strategy most effectively highlights genuinely suspicious process-tree anomalies indicative of stealth (such as persistent zombies and unusual ancestry misused to hide) while minimizing unnecessary noise from expected behavior (such as transient zombies, legitimate daemonization, and container subreapers).\n\nUse only the following foundational facts about process management and accounting as your starting point:\n\n- Process creation and replacement: a child is created via fork- or clone-like mechanics and may subsequently replace its address space via an execution system call; the parent-child link is recorded via PPID.\n- Process termination and reaping: when a process terminates, its exit status remains associated with its PID until the parent collects it via a wait family of system calls; during that window, the process is a zombie.\n- Orphan adoption: if a parent terminates before the child, the child becomes an orphan and is adopted either by the process with PID $1$ or by a designated subreaper; this is expected for double-forked daemons and in container contexts where a subreaper is configured.\n- Kernel threads do not have user-space executable files; user-space processes that mimic kernel-thread naming (e.g., bracket-like names or names of known kernel threads) yet have user-space executable mappings are suspect if not otherwise explained by a supervisor or container context.\n\nWhich option below implements an auditing approach that will flag Observation $4$ and Observation $5$ as suspicious while suppressing noise from Observation $1$, Observation $2$, and Observation $3$?\n\nA. Configure the Linux Audit subsystem (AUDIT) to log all fork, clone, execution, and exit calls system-wide without filters. Trigger an alert for any zombie observed at any time, any orphan whose PPID equals $1$, and any process whose name is similar to a kernel-thread name. Do not exclude events from containers or supervised services.\n\nB. Use Extended Berkeley Packet Filter (eBPF) programs attached to kernel tracepoints for execution and exit to maintain a live parent-child map with timestamps, user identifiers, and cgroup membership. Raise alerts only when:\n   - A process name matches a kernel-thread-like pattern or a known kernel-thread name but the process has user-space executable mappings or an executable path (even if “(deleted)”), persists beyond a threshold (e.g., more than $60$ seconds), and is not part of a known service unit cgroup or a container cgroup.\n   - A zombie persists beyond a threshold (e.g., more than $60$ seconds), and its parent is still alive but not calling wait, or the zombie accumulates beyond a small count threshold within a short window. Suppress events where the parent is a known short-lived builder or helper under high load.\n   - Reparenting to PID $1$ occurs for a process not under the expected service manager cgroup and not under a container subreaper cgroup. Explicitly suppress reparenting events when the adopting parent is a designated subreaper or when the process belongs to a supervised service cgroup.\n\nC. Periodically sample process lists at intervals of $5$ minutes and flag any process whose name contains the letters “k” or “d,” any zombie regardless of age, and any process adopted by PID $1$. Do not consult cgroup or container metadata to reduce overhead.\n\nD. Audit only network-related system calls and low-numbered port bindings. Alert when a process both binds a port below $1024$ and has PPID $1$, on the premise that stealthy processes seek persistence via privileged network services. Ignore process lifecycle events to avoid performance impact.\n\nSelect the single best option.", "solution": "### Derivation of Solution\n\nThe core task is to devise a set of rules that can distinguish malicious or anomalous process behavior from legitimate, complex system behavior. A successful strategy must be nuanced, leveraging contextual information rather than relying on simple, absolute rules.\n\nLet's analyze what is required to correctly classify each observation:\n\n*   To suppress **Observation 1** (transient zombies) while flagging **Observation 5** (persistent zombies), the strategy must incorporate a **time threshold**. Zombies existing for less than a few seconds should be ignored, while those persisting for minutes should trigger an alert.\n*   To suppress **Observation 2** (container subreaper), the strategy must recognize that orphan adoption is not always performed by PID 1. It needs to be aware of the subreaper mechanism and, ideally, use **cgroup membership** to confirm that the reparenting is confined to a legitimate container context.\n*   To suppress **Observation 3** (legitimate daemon), the strategy must understand the double-fork pattern where a process is legitimately adopted by PID 1. The key differentiator is context, specifically that the process belongs to a known, supervised **system service cgroup**.\n*   To flag **Observation 4** (masquerading process), the strategy must combine multiple indicators of suspicion. A simple rule like \"PPID is 1\" or \"name looks like a kernel thread\" is insufficient. A robust rule would be: `(name matches kernel pattern) AND (is a user-space process) AND (is not in a legitimate service or container cgroup)`. The `(deleted)` executable path is a strong additional indicator of fileless malware.\n*   To flag **Observation 5** (zombie accumulation), the strategy must, as mentioned, use a **time threshold** to detect zombies that are not being reaped by their parent.\n\nIn summary, the ideal strategy is one that is stateful (tracking processes over time), context-aware (using cgroup and user metadata), and based on multi-conditional logic rather than single, noisy indicators.\n\n### Option-by-Option Analysis\n\n**A. Configure the Linux Audit subsystem (AUDIT) to log all fork, clone, execution, and exit calls system-wide without filters. Trigger an alert for any zombie observed at any time, any orphan whose PPID equals $1$, and any process whose name is similar to a kernel-thread name. Do not exclude events from containers or supervised services.**\n\n*   This strategy is excessively noisy and lacks the necessary sophistication.\n*   `\"alert for any zombie observed at any time\"`: This rule would incorrectly flag the benign transient zombies from **Observation 1**.\n*   `\"any orphan whose PPID equals 1\"`: This rule would incorrectly flag the legitimate `daemonX` from **Observation 3**.\n*   `\"Do not exclude events from containers or supervised services\"`: This explicitly rejects the use of cgroup and other contextual information, which is essential for distinguishing benign from suspicious behavior in Observations 2 and 3.\n*   While this strategy would likely flag Observations 4 and 5, it would do so amidst a flood of false positives from Observations 1 and 3, making it ineffective.\n*   **Verdict: Incorrect**\n\n**B. Use Extended Berkeley Packet Filter (eBPF) programs attached to kernel tracepoints for execution and exit to maintain a live parent-child map with timestamps, user identifiers, and cgroup membership. Raise alerts only when: ...**\n\n*   This strategy uses a powerful, low-overhead kernel tracing mechanism (eBPF) to gather the rich contextual data needed. Let's analyze its rules:\n    *   **Rule 1 (for masquerading):** `A process name matches a kernel-thread-like pattern ... but the process has user-space executable mappings ... and is not part of a known service unit cgroup or a container cgroup.` This rule is a precise formulation for detecting the anomaly in **Observation 4** while avoiding false positives. It correctly combines name, process type (user-space vs. kernel), and cgroup context.\n    *   **Rule 2 (for zombies):** `A zombie persists beyond a threshold (e.g., more than 60 seconds)...` This rule uses a time threshold to correctly flag the persistent zombies in **Observation 5** and correctly ignore the transient ones in **Observation 1**.\n    *   **Rule 3 (for reparenting):** `Reparenting to PID 1 occurs for a process not under the expected service manager cgroup and not under a container subreaper cgroup. Explicitly suppress reparenting events when the adopting parent is a designated subreaper or when the process belongs to a supervised service cgroup.` This logic precisely filters out the legitimate reparenting events from **Observation 2** (subreaper) and **Observation 3** (`daemonX` in service cgroup), ensuring that only suspicious reparenting (like in **Observation 4**) is flagged.\n*   This approach meets all the requirements identified in the derivation. It correctly flags Observations 4 and 5 while correctly suppressing Observations 1, 2, and 3.\n*   **Verdict: Correct**\n\n**C. Periodically sample process lists at intervals of $5$ minutes and flag any process whose name contains the letters “k” or “d,” any zombie regardless of age, and any process adopted by PID $1$. Do not consult cgroup or container metadata to reduce overhead.**\n\n*   This strategy is crude and ineffective.\n*   The sampling interval of 5 minutes is too large and may miss important events.\n*   The rule `\"name contains the letters 'k' or 'd'\"` is absurdly broad and would generate an enormous number of false positives (e.g., `systemd`, `dockerd`, `worker`, etc.), including flagging the benign `daemonX` from **Observation 3**.\n*   The rule `\"any zombie regardless of age\"` is flawed because it does not distinguish transient states from persistent problems. It would incorrectly flag **Observation 1** if a sample happened to coincide with the 0.02 second window.\n*   The rule `\"any process adopted by PID 1\"` is too broad and would incorrectly flag the legitimate daemon in **Observation 3**.\n*   The explicit decision to `\"Do not consult cgroup or container metadata\"` demonstrates a failure to use essential context, guaranteeing a high false-positive rate.\n*   **Verdict: Incorrect**\n\n**D. Audit only network-related system calls and low-numbered port bindings. Alert when a process both binds a port below $1024$ and has PPID $1$, on the premise that stealthy processes seek persistence via privileged network services. Ignore process lifecycle events to avoid performance impact.**\n\n*   This strategy is entirely misaligned with the problem definition.\n*   The problem describes anomalies in the **process lifecycle** (zombies, ancestry, masquerading). This option proposes to `\"Ignore process lifecycle events\"`, making it fundamentally incapable of detecting the specified phenomena.\n*   It makes an unsubstantiated assumption that the malware is network-facing. The malware in **Observation 4** or the bug in **Observation 5** might have no network activity at all. Therefore, this strategy would fail to detect them. This approach is searching for a different class of threat and is irrelevant to the observations provided.\n*   **Verdict: Incorrect**", "answer": "$$\\boxed{B}$$", "id": "3673363"}]}