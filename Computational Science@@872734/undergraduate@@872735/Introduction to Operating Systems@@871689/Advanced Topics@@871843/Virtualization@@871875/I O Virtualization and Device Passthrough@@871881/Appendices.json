{"hands_on_practices": [{"introduction": "Virtualization often requires mediating between modern guest operating systems and legacy hardware that may lack certain features. This exercise explores a common scenario: emulating scatter-gather I/O capabilities for a device that does not natively support them. By modeling the costs of this software emulation, known as bounce buffering, you will gain a concrete understanding of the performance overheads inherent in I/O virtualization and learn how to quantify them in terms of CPU cycles and memory bandwidth consumption [@problem_id:3648915].", "problem": "A hypervisor implements Input/Output (I/O) virtualization for a legacy Peripheral Component Interconnect Express (PCIe) storage device that lacks scatter-gather (SG) support. When a guest operating system issues an SG I/O request, the hypervisor must software-copy the non-contiguous guest buffers into a contiguous bounce buffer before the device performs Direct Memory Access (DMA). Assume the following realistic and measured costs for the copy path on a single core:\n\n- Per-byte copy cost is $c_{b} = 0.8$ cycles per byte.\n- Per-segment setup cost is $c_{s} = 300$ cycles per segment.\n- Per-I/O fixed cost is $c_{0} = 500$ cycles for bounce-buffer management.\n\nA typical workload has I/O sizes and segment counts distributed as follows, independently per I/O:\n- With probability $0.5$, the I/O size is $64$ KiB and the segment count is $8$.\n- With probability $0.3$, the I/O size is $128$ KiB and the segment count is $16$.\n- With probability $0.2$, the I/O size is $32$ KiB and the segment count is $4$.\n\nAssume $1$ KiB $= 1024$ bytes. Also assume the sustained Input/Output Operations Per Second (IOPS) rate is $R = 25000$ IOPS. For the purposes of memory bandwidth accounting, define the bandwidth consumed by the software copy as the sum of bytes read and bytes written by the copy per second; that is, each byte copied contributes twice to memory traffic.\n\nUsing only fundamental definitions of expected value, cycles as time quanta for the processor, and memory bandwidth as bytes per second, derive from first principles and compute:\n\n- The expected additional Central Processing Unit (CPU) cycles per I/O incurred by the software SG emulation.\n- The sustained memory bandwidth consumed by the software copy at the given IOPS rate, expressed in GiB/s.\n\nRound your answers to four significant figures. Express the final memory bandwidth in GiB/s. Provide both answers in a single row, in the order: cycles per I/O, GiB/s.", "solution": "The problem is subjected to validation against the specified criteria.\n\n**Step 1: Extract Givens**\n- **System Model**: A hypervisor implements Input/Output (I/O) virtualization for a legacy Peripheral Component Interconnect Express (PCIe) storage device lacking scatter-gather (SG) support. For SG requests, the hypervisor performs a software copy of non-contiguous guest buffers into a contiguous bounce buffer for Direct Memory Access (DMA).\n- **Cost Parameters**:\n  - Per-byte copy cost: $c_{b} = 0.8$ cycles/byte.\n  - Per-segment setup cost: $c_{s} = 300$ cycles/segment.\n  - Per-I/O fixed cost for bounce-buffer management: $c_{0} = 500$ cycles.\n- **Workload Distribution**:\n  - Case 1: Probability $P_1 = 0.5$, I/O size $S_1 = 64$ KiB, segment count $N_1 = 8$.\n  - Case 2: Probability $P_2 = 0.3$, I/O size $S_2 = 128$ KiB, segment count $N_2 = 16$.\n  - Case 3: Probability $P_3 = 0.2$, I/O size $S_3 = 32$ KiB, segment count $N_3 = 4$.\n- **Constants and Rates**:\n  - Unit conversion: $1$ KiB $= 1024$ bytes.\n  - Sustained I/O Operations Per Second rate: $R = 25000$ IOPS.\n- **Definitions**:\n  - Memory bandwidth consumed by the software copy is the sum of bytes read and bytes written per second. Each byte copied contributes twice to memory traffic.\n- **Required Outputs**:\n  1. The expected additional CPU cycles per I/O.\n  2. The sustained memory bandwidth consumed by the software copy, in GiB/s.\n- **Rounding**: Final answers must be rounded to four significant figures.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is evaluated as follows:\n- **Scientifically Grounded**: The problem is well-grounded in the principles of computer architecture and operating systems, specifically I/O virtualization. The scenario of emulating scatter-gather capabilities in software via bounce buffering is a standard technique. The provided cost values and I/O rates are realistic for performance analysis.\n- **Well-Posed**: The problem is fully specified. All necessary data, constants, and probabilistic distributions are provided. The objectives are clearly stated, and a unique, stable solution can be derived from the given model. The probabilities sum to $0.5 + 0.3 + 0.2 = 1.0$, ensuring consistency.\n- **Objective**: The problem statement is composed of objective, quantitative statements and definitions, free of subjective or ambiguous language.\n\n**Step 3: Verdict and Action**\nThe problem is deemed valid. A solution will be derived from first principles.\n\n**Solution Derivation**\n\nFirst, we establish a formal model for the additional CPU cycles incurred per I/O operation due to the software scatter-gather emulation. The total cost is a function of the I/O size $S$ (in bytes) and the number of segments $N$. This cost, $C(S, N)$, is the sum of three distinct components as defined in the problem: a fixed per-I/O cost, a per-segment cost, and a per-byte cost.\n\nThe cost function is:\n$$C(S, N) = c_{0} + N \\cdot c_{s} + S \\cdot c_{b}$$\n\nThe workload is characterized by a discrete probability distribution over three types of I/O operations. To find the expected additional CPU cycles per I/O, we must calculate the expected value of the cost function $C(S, N)$ over this distribution. The expected value, $E[C]$, of a function $g(x_i)$ of a discrete random variable is given by the fundamental definition $E[g(X)] = \\sum_{i} P(X=x_i) g(x_i)$. In our case, the outcomes are pairs $(S_i, N_i)$ with probabilities $P_i$.\n\nThe expected cost is therefore:\n$$E[C] = \\sum_{i=1}^{3} P_i \\cdot C(S_i, N_i) = P_1 \\cdot C(S_1, N_1) + P_2 \\cdot C(S_2, N_2) + P_3 \\cdot C(S_3, N_3)$$\n\nBefore calculating the costs, we must convert the I/O sizes from KiB to bytes, using the given conversion $1 \\text{ KiB} = 1024$ bytes.\n- $S_1 = 64 \\text{ KiB} = 64 \\times 1024 \\text{ bytes} = 65536 \\text{ bytes}$\n- $S_2 = 128 \\text{ KiB} = 128 \\times 1024 \\text{ bytes} = 131072 \\text{ bytes}$\n- $S_3 = 32 \\text{ KiB} = 32 \\times 1024 \\text{ bytes} = 32768 \\text{ bytes}$\n\nNow we calculate the individual costs for each case using the given constants $c_{0} = 500$, $c_{s} = 300$, and $c_{b} = 0.8$:\n- For Case 1 ($P_1 = 0.5$, $S_1 = 65536$, $N_1 = 8$):\n$$C_1 = c_{0} + N_1 \\cdot c_{s} + S_1 \\cdot c_{b} = 500 + 8 \\cdot 300 + 65536 \\cdot 0.8 = 500 + 2400 + 52428.8 = 55328.8 \\text{ cycles}$$\n- For Case 2 ($P_2 = 0.3$, $S_2 = 131072$, $N_2 = 16$):\n$$C_2 = c_{0} + N_2 \\cdot c_{s} + S_2 \\cdot c_{b} = 500 + 16 \\cdot 300 + 131072 \\cdot 0.8 = 500 + 4800 + 104857.6 = 110157.6 \\text{ cycles}$$\n- For Case 3 ($P_3 = 0.2$, $S_3 = 32768$, $N_3 = 4$):\n$$C_3 = c_{0} + N_3 \\cdot c_{s} + S_3 \\cdot c_{b} = 500 + 4 \\cdot 300 + 32768 \\cdot 0.8 = 500 + 1200 + 26214.4 = 27914.4 \\text{ cycles}$$\n\nWe can now compute the expected cycles per I/O:\n$$E[C] = 0.5 \\cdot (55328.8) + 0.3 \\cdot (110157.6) + 0.2 \\cdot (27914.4)$$\n$$E[C] = 27664.4 + 33047.28 + 5582.88 = 66294.56 \\text{ cycles/I/O}$$\nRounding to four significant figures, the expected cost is $66290$ cycles/I/O.\n\nNext, we derive the sustained memory bandwidth. The memory bandwidth is determined by the total amount of data copied per second. First, we find the expected size of a single I/O operation, $E[S]$, in bytes.\n$$E[S] = \\sum_{i=1}^{3} P_i \\cdot S_i = P_1 \\cdot S_1 + P_2 \\cdot S_2 + P_3 \\cdot S_3$$\n$$E[S] = 0.5 \\cdot (65536) + 0.3 \\cdot (131072) + 0.2 \\cdot (32768)$$\n$$E[S] = 32768 + 39321.6 + 6553.6 = 78643.2 \\text{ bytes/I/O}$$\n\nThe total rate of data copying, $D_{copy}$, is the expected size per I/O multiplied by the I/O rate $R$:\n$$D_{copy} = E[S] \\cdot R = 78643.2 \\frac{\\text{bytes}}{\\text{I/O}} \\times 25000 \\frac{\\text{I/O}}{\\text{s}} = 1966080000 \\frac{\\text{bytes}}{\\text{s}}$$\n\nThe problem defines the memory bandwidth, $B$, as the sum of bytes read and written. Since the software copy reads each byte from the guest's non-contiguous buffers and writes it to the hypervisor's contiguous bounce buffer, each byte copied generates two bytes of memory traffic.\n$$B = 2 \\cdot D_{copy} = 2 \\times 1966080000 \\frac{\\text{bytes}}{\\text{s}} = 3932160000 \\frac{\\text{bytes}}{\\text{s}}$$\n\nFinally, we must convert this bandwidth from bytes per second to gibibytes per second (GiB/s). Based on the provided unit $1 \\text{ KiB} = 1024$ bytes, we use binary prefixes. Therefore, $1 \\text{ GiB} = 1024^3 \\text{ bytes} = 2^{30} \\text{ bytes} = 1073741824 \\text{ bytes}$.\n$$B (\\text{in GiB/s}) = \\frac{3932160000}{1073741824} \\approx 3.662109375 \\text{ GiB/s}$$\nRounding to four significant figures, the consumed memory bandwidth is $3.662$ GiB/s.\n\nThe two requested values are the expected CPU cycles per I/O and the sustained memory bandwidth.\n- Expected CPU cycles per I/O: $66290$\n- Sustained memory bandwidth: $3.662$ GiB/s", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n66290 & 3.662\n\\end{pmatrix}\n}\n$$", "id": "3648915"}, {"introduction": "After quantifying virtualization overheads, the next step is to optimize them. Managing the IOMMU can be a significant source of performance cost, as operations like invalidating address translations often require expensive hypervisor interventions. This practice introduces batching as a powerful strategy to reduce these costs and challenges you to model the expected performance savings for a bursty I/O workload using first principles of probability [@problem_id:3648965].", "problem": "A system runs a device passthrough workload under a hypervisor that uses an Input-Output Memory Management Unit (IOMMU) with an Input-Output Translation Lookaside Buffer (IOTLB). Each Direct Memory Access (DMA) mapping teardown triggers an unmap operation that requires an IOTLB invalidation to ensure that stale translations are not used by the device. Under virtualization, each invalidation is performed by the hypervisor, incurring a Virtual Machine (VM) exit. Assume the following well-tested facts and modeling assumptions grounded in operating systems and probability:\n\n- Each VM exit costs a fixed number of cycles, denoted $c_{x}$, and each IOTLB invalidation costs a fixed number of cycles, denoted $c_{i}$, independent of how many I/O virtual addresses are being invalidated when the operation is a global or domain-wide flush.\n- An IOTLB invalidation is required for correctness after unmap to make updated page tables visible to the device. Without batching, the hypervisor performs one invalidation per unmap, thus one VM exit and one invalidation per unmap.\n- Unmap requests arrive in bursts due to the device completing groups of DMA operations. Let bursts arrive at a rate of $r$ bursts per second. In each burst, the number of unmaps $K$ is an independent geometric random variable with parameter $p$ on $\\{1,2,3,\\ldots\\}$, meaning $\\mathbb{P}(K=k)=(1-p)^{k-1}p$ and $\\mathbb{E}[K]=\\frac{1}{p}$. Within a burst, inter-arrival times are negligible relative to batching timers; between bursts, the idle time is large enough that any pending batch will be flushed at burst end.\n- Consider the batching strategy “size-threshold with long timeout”: the hypervisor accumulates unmap descriptors for up to $B$ unmaps and then issues a single invalidation (one VM exit plus one IOTLB invalidation) for that batch; if the burst ends with fewer than $B$ accumulated unmaps, the hypervisor flushes once at the end of the burst.\n\nUsing only these assumptions and first principles, compute the expected savings in cycles per second achieved by batching relative to the baseline (no batching). Use the parameter values $r=3000$ bursts/s, $p=0.05$, $B=16$, $c_{x}=9000$ cycles, and $c_{i}=3000$ cycles. Round your final answer to four significant figures. Express the result in cycles per second.", "solution": "The user wants me to solve the following problem:\nA system runs a device passthrough workload under a hypervisor that uses an Input-Output Memory Management Unit (IOMMU) with an Input-Output Translation Lookaside Buffer (IOTLB). Each Direct Memory Access (DMA) mapping teardown triggers an unmap operation that requires an IOTLB invalidation to ensure that stale translations are not used by the device. Under virtualization, each invalidation is performed by the hypervisor, incurring a Virtual Machine (VM) exit. Assume the following well-tested facts and modeling assumptions grounded in operating systems and probability:\n\n- Each VM exit costs a fixed number of cycles, denoted $c_{x}$, and each IOTLB invalidation costs a fixed number of cycles, denoted $c_{i}$, independent of how many I/O virtual addresses are being invalidated when the operation is a global or domain-wide flush.\n- An IOTLB invalidation is required for correctness after unmap to make updated page tables visible to the device. Without batching, the hypervisor performs one invalidation per unmap, thus one VM exit and one invalidation per unmap.\n- Unmap requests arrive in bursts due to the device completing groups of DMA operations. Let bursts arrive at a rate of $r$ bursts per second. In each burst, the number of unmaps $K$ is an independent geometric random variable with parameter $p$ on $\\{1,2,3,\\ldots\\}$, meaning $\\mathbb{P}(K=k)=(1-p)^{k-1}p$ and $\\mathbb{E}[K]=\\frac{1}{p}$. Within a burst, inter-arrival times are negligible relative to batching timers; between bursts, the idle time is large enough that any pending batch will be flushed at burst end.\n- Consider the batching strategy “size-threshold with long timeout”: the hypervisor accumulates unmap descriptors for up to $B$ unmaps and then issues a single invalidation (one VM exit plus one IOTLB invalidation) for that batch; if the burst ends with fewer than $B$ accumulated unmaps, the hypervisor flushes once at the end of the burst.\n\nUsing only these assumptions and first principles, compute the expected savings in cycles per second achieved by batching relative to the baseline (no batching). Use the parameter values $r=3000$ bursts/s, $p=0.05$, $B=16$, $c_{x}=9000$ cycles, and $c_{i}=3000$ cycles. Round your final answer to four significant figures. Express the result in cycles per second.\n\n### Step 1: Extract Givens\n- Cost of a VM exit: $c_x = 9000$ cycles\n- Cost of an IOTLB invalidation: $c_i = 3000$ cycles\n- Burst arrival rate: $r = 3000$ bursts/s\n- Number of unmaps per burst, $K$, is a geometric random variable on $\\{1, 2, 3, \\dots\\}$.\n- Probability mass function of $K$: $\\mathbb{P}(K=k) = (1-p)^{k-1}p$.\n- Parameter of geometric distribution: $p = 0.05$.\n- Batch size threshold: $B = 16$.\n- Batching strategy: Invalidation for every $B$ unmaps, or at the end of a burst for any remaining unmaps.\n- Baseline (no batching): One invalidation per unmap.\n- Each invalidation event triggers one VM exit and one IOTLB invalidation.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in the principles of operating systems, computer architecture, and probability theory. It describes a standard performance optimization problem (batching) for I/O virtualization, using a well-defined probabilistic model for workload generation. The concepts of VM exits, IOMMU, IOTLB, and DMA are standard in this field. The problem is well-posed, providing all necessary parameters and a clear objective. The language is objective and unambiguous. The problem setup is self-contained and internally consistent. There are no scientific flaws, missing data, or contradictions.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will proceed to derive the solution.\n\nThe objective is to compute the expected savings in cycles per second achieved by the batching strategy compared to the baseline (no batching). The savings, $S$, can be expressed as the difference between the expected cost per second without batching, $C_{base}$, and the expected cost per second with batching, $C_{batch}$.\n$$S = C_{base} - C_{batch}$$\nThe cost of a single invalidation event, which consists of one VM exit and one IOTLB invalidation, is constant and given by $C_{inv} = c_x + c_i$.\n\n**1. Expected Cost without Batching ($C_{base}$)**\n\nIn the baseline scenario, each unmap operation triggers one invalidation event. Therefore, the total cost per second is the product of the expected number of unmaps per second and the cost per invalidation.\n\nThe number of unmaps per burst, $K$, is a geometric random variable with parameter $p$ on the set $\\{1, 2, 3, \\ldots\\}$. The expected value of $K$ is given as:\n$$\\mathbb{E}[K] = \\frac{1}{p}$$\nBursts arrive at a rate of $r$ bursts per second. By Wald's identity or linearity of expectation over a fixed time interval, the expected number of unmaps per second, $\\lambda_{unmap}$, is:\n$$\\lambda_{unmap} = r \\cdot \\mathbb{E}[K] = \\frac{r}{p}$$\nSince each unmap causes one invalidation, the expected number of invalidations per second is also $\\frac{r}{p}$. The total expected cost per second for the baseline is:\n$$C_{base} = \\lambda_{unmap} \\cdot C_{inv} = \\frac{r}{p} (c_x + c_i)$$\n\n**2. Expected Cost with Batching ($C_{batch}$)**\n\nWith the batching strategy, multiple unmaps are grouped into a single invalidation event. For a burst containing $K$ unmaps, the hypervisor will issue one invalidation for every full batch of size $B$ and one final invalidation for any remaining unmaps at the end of the burst.\n\nThe number of full batches of size $B$ for $K$ unmaps is $\\lfloor \\frac{K}{B} \\rfloor$. If $K$ is not a multiple of $B$, there is a remainder of $K \\pmod B$ unmaps, which will trigger one additional invalidation at the end of the burst. The total number of invalidations for a burst of size $K$, let's call it $I_K$, is $\\lfloor \\frac{K}{B} \\rfloor$ if $K$ is a multiple of $B$ and $K>0$, and $\\lfloor \\frac{K}{B} \\rfloor + 1$ otherwise. This is precisely the definition of the ceiling function, $\\lceil \\frac{K}{B} \\rceil$.\nThus, the number of invalidations for a burst of size $K$ is $I_K = \\lceil \\frac{K}{B} \\rceil$.\n\nTo find the expected cost per second with batching, we first need the expected number of invalidations per burst, $\\mathbb{E}[I_K] = \\mathbb{E}[\\lceil \\frac{K}{B} \\rceil]$. For a non-negative integer-valued random variable $X$, its expectation can be calculated as $\\mathbb{E}[X] = \\sum_{j=1}^{\\infty} \\mathbb{P}(X \\ge j)$.\nLet $X = \\lceil \\frac{K}{B} \\rceil$. The condition $\\lceil \\frac{K}{B} \\rceil \\ge j$ for an integer $j \\ge 1$ is equivalent to $\\frac{K}{B} > j-1$, which simplifies to $K > (j-1)B$.\nSo, $\\mathbb{P}(\\lceil \\frac{K}{B} \\rceil \\ge j) = \\mathbb{P}(K > (j-1)B)$.\n\nFor a geometric random variable $K$ on $\\{1, 2, \\dots\\}$ with parameter $p$, the survival function is $\\mathbb{P}(K > n) = (1-p)^n$ for any integer $n \\ge 0$.\nSubstituting this into our expectation formula:\n$$\\mathbb{E}\\left[\\lceil \\frac{K}{B} \\rceil\\right] = \\sum_{j=1}^{\\infty} \\mathbb{P}(K > (j-1)B) = \\sum_{j=1}^{\\infty} (1-p)^{(j-1)B}$$\nThis is a geometric series. Let $m = j-1$ and let the common ratio be $q = (1-p)^B$. The sum becomes:\n$$\\sum_{m=0}^{\\infty} q^m = \\frac{1}{1-q}$$\nTherefore, the expected number of invalidations per burst is:\n$$\\mathbb{E}\\left[\\lceil \\frac{K}{B} \\rceil\\right] = \\frac{1}{1 - (1-p)^B}$$\nThe expected number of invalidations per second with batching, $\\lambda_{batch}$, is the product of the burst rate $r$ and the expected invalidations per burst:\n$$\\lambda_{batch} = r \\cdot \\mathbb{E}\\left[\\lceil \\frac{K}{B} \\rceil\\right] = \\frac{r}{1 - (1-p)^B}$$\nThe total expected cost per second with batching is:\n$$C_{batch} = \\lambda_{batch} \\cdot C_{inv} = \\frac{r}{1 - (1-p)^B} (c_x + c_i)$$\n\n**3. Expected Savings per Second ($S$)**\n\nThe expected savings are the difference between the baseline and batching costs:\n$$S = C_{base} - C_{batch} = \\frac{r}{p}(c_x + c_i) - \\frac{r}{1 - (1-p)^B}(c_x + c_i)$$\nFactoring out common terms, we get the final symbolic expression for the savings:\n$$S = r(c_x + c_i) \\left( \\frac{1}{p} - \\frac{1}{1 - (1-p)^B} \\right)$$\n\n**4. Numerical Calculation**\n\nNow, we substitute the given values into the formula:\n$r = 3000$\n$p = 0.05$\n$B = 16$\n$c_x = 9000$\n$c_i = 3000$\n\nFirst, calculate the constant terms:\n$c_x + c_i = 9000 + 3000 = 12000$\n$r(c_x + c_i) = 3000 \\times 12000 = 3.6 \\times 10^7$\n\nNext, calculate the terms inside the parentheses:\n$\\frac{1}{p} = \\frac{1}{0.05} = 20$\n$1-p = 1 - 0.05 = 0.95$\n\nNow, calculate the term for the batched case:\n$(1-p)^B = (0.95)^{16} \\approx 0.440126832$\n$1 - (1-p)^B \\approx 1 - 0.440126832 = 0.559873168$\n$\\frac{1}{1 - (1-p)^B} \\approx \\frac{1}{0.559873168} \\approx 1.786105005$\n\nNow, compute the difference inside the parentheses:\n$\\frac{1}{p} - \\frac{1}{1 - (1-p)^B} \\approx 20 - 1.786105005 = 18.213894995$\n\nFinally, calculate the total savings $S$:\n$S \\approx (3.6 \\times 10^7) \\times 18.213894995$\n$S \\approx 655700219.82$ cycles per second.\n\nThe problem requires rounding the final answer to four significant figures.\n$S \\approx 6.557 \\times 10^8$ cycles per second.", "answer": "$$\\boxed{6.557 \\times 10^8}$$", "id": "3648965"}, {"introduction": "Beyond performance, a primary function of I/O virtualization and the IOMMU is to provide robust security and isolation. This is achieved by strictly controlling which memory regions a device can access via DMA. In this final practice, you will step into the role of a system designer and implement the core logic of a DMA-level virtual firewall, turning abstract security policies into efficient, hot-path enforcement code and handling critical edge cases like address-space wrap-around [@problem_id:3648953].", "problem": "You are modeling the hot-path enforcement of a Direct Memory Access (DMA) virtual firewall under Input/Output Memory Management Unit (IOMMU) virtualization. The enforcement policy is a finite set of inclusive physical address ranges, and the workload is given as a scatter-gather list (a list of DMA segments), each segment described by a starting physical address and a nonnegative length in bytes. A scatter-gather list is permitted if and only if every segment is fully contained in at least one permitted range, under unsigned arithmetic on a fixed machine word size.\n\nUse the following fundamental base, without assuming any target formulas in advance:\n- A machine address space is modeled as the set $A = \\{ 0, 1, \\dots, 2^w - 1 \\}$ for a fixed width $w$ in bits. In this problem, $w = 64$.\n- Integer addition on $A$ is modulo $2^w$. Use the standard total order on the natural representatives of $A$: for $x, y \\in A$, the comparison $x \\le y$ means the ordinary integer comparison after interpreting $x$ and $y$ as integers in $\\{0,1,\\dots,2^w-1\\}$.\n- A permitted range is a closed interval $[a,b]$ with $a,b \\in A$ and $a \\le b$.\n- A DMA segment is a pair $(s,\\ell)$ with $s \\in A$ and $\\ell \\in \\mathbb{N}$, $\\ell \\ge 0$. Define its last address as $e = s + \\ell - 1$ computed in modulo $2^w$ arithmetic. A segment with $\\ell = 0$ touches no address and is considered permitted by definition. For $\\ell > 0$, to be admissible without wrap-around, it must satisfy $e \\ge s$ in the standard order; if $e < s$, wrap-around has occurred and the segment must be rejected.\n\nEnforcement must be based only on the following logically necessary conditions:\n- Normalization of policy ranges: the set of ranges is transformed into a sorted list by increasing start address and merged so that any overlapping or abutting ranges become a single range. Two ranges $[a_1, b_1]$ and $[a_2, b_2]$ overlap if $a_2 \\le b_1$, and they abut if $b_1 + 1 = a_2$ in the standard integer sense without overflow beyond $2^w - 1$.\n- Hot-path membership test: for each segment $(s,\\ell)$ with $\\ell > 0$ and no wrap-around, find a permitted range $[a,b]$ such that $a \\le s$ and $e \\le b$. If no such range exists, the segment is rejected. The scatter-gather list is permitted if and only if all segments are permitted.\n\nYour task is to write a complete program that:\n1. Implements normalization of ranges as a preprocessing step.\n2. Implements the hot-path check per segment using binary search over the normalized ranges to locate the candidate $[a,b]$ with the greatest $a \\le s$, followed by the bound check $e \\le b$.\n3. Applies this to each test case below and outputs, for each test case, a boolean $b \\in \\{0,1\\}$ indicating whether the entire scatter-gather list is permitted.\n\nUse $w = 64$ and inclusive ranges. All addresses and lengths are integers and require no physical units. Angles are not involved. No percentages are involved.\n\nTest suite (each test case consists of a policy and a scatter-gather list):\n- Test case $1$ (happy path):\n  - Policy $\\mathcal{P}_1 = \\{ [1000,1999], [3000,3999] \\}$.\n  - Scatter-gather $\\mathcal{S}_1 = \\{ (1000,500), (3500,100) \\}$.\n- Test case $2$ (boundary inclusive end):\n  - Policy $\\mathcal{P}_2 = \\{ [1000,1999], [3000,3999] \\}$.\n  - Scatter-gather $\\mathcal{S}_2 = \\{ (1900,100) \\}$.\n- Test case $3$ (partial overrun):\n  - Policy $\\mathcal{P}_3 = \\{ [1000,1999], [3000,3999] \\}$.\n  - Scatter-gather $\\mathcal{S}_3 = \\{ (1900,200) \\}$.\n- Test case $4$ (zero-length segment with empty policy):\n  - Policy $\\mathcal{P}_4 = \\varnothing$.\n  - Scatter-gather $\\mathcal{S}_4 = \\{ (5000,0) \\}$.\n- Test case $5$ (normalization by overlap):\n  - Policy $\\mathcal{P}_5 = \\{ [100,300], [200,400] \\}$.\n  - Scatter-gather $\\mathcal{S}_5 = \\{ (250,100) \\}$.\n- Test case $6$ (wrap-around rejection near the top of the address space):\n  - Let $M = 2^{64} - 1$. Policy $\\mathcal{P}_6 = \\{ [M-15, M] \\}$.\n  - Scatter-gather $\\mathcal{S}_6 = \\{ (M-9, 20) \\}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For the six test cases in the order listed above, print $[b_1,b_2,b_3,b_4,b_5,b_6]$ with no spaces and no trailing text, where each $b_i \\in \\{0,1\\}$ is the decision for test case $i$.\n- The program must be self-contained and take no input. All constants required by the test suite must be embedded in the program.", "solution": "We formalize the enforcement problem using set and interval arithmetic over unsigned machine addresses. The machine address space is $A = \\{0,1,\\dots,2^w - 1\\}$ with $w = 64$. Addition is modulo $2^w$, but the order $\\le$ is the usual order on $\\{0,1,\\dots,2^w - 1\\}$.\n\nA policy is a finite set of inclusive ranges $\\{[a_i,b_i]\\}$ where $a_i,b_i \\in A$ and $a_i \\le b_i$. A scatter-gather list is a finite sequence of segments $(s_j,\\ell_j)$ with $s_j \\in A$ and $\\ell_j \\in \\mathbb{N}$, $\\ell_j \\ge 0$. For a segment $(s,\\ell)$, define the last address as $e = s + \\ell - 1$ in modulo $2^w$ arithmetic. The segment is permitted if either $\\ell = 0$ or there exists a permitted range $[a,b]$ such that $a \\le s$ and $e \\le b$, provided no wrap-around occurred. A necessary and sufficient condition to detect wrap-around for $\\ell > 0$ is $e < s$. This follows from properties of modular addition: for $\\ell > 0$, the map $x \\mapsto x + \\ell - 1$ is strictly increasing on the natural numbers, so if computed modulo $2^w$ and the result $e$ is less than the start $s$ in the standard order, then the true sum exceeded $2^w - 1$ and wrapped.\n\nPrinciple-based design:\n- Normalization: To achieve $O(\\log n)$ hot-path checks, first sort the ranges by start address and merge any overlapping or abutting ranges. Two ranges $[a_1,b_1]$ and $[a_2,b_2]$ (with $a_1 \\le a_2$) overlap if $a_2 \\le b_1$, and abut if $b_1 + 1 = a_2$ without overflow beyond $2^w-1$. Merging replaces them by $[a_1, \\max(b_1,b_2)]$. Sorting and merging yields a list of disjoint ranges with strictly increasing starts.\n- Hot-path membership: For $(s,\\ell)$ with $\\ell = 0$, accept immediately. For $\\ell > 0$, compute $e = s + \\ell - 1$ modulo $2^w$. If $e < s$, reject due to wrap-around. Otherwise, binary search the normalized range list to find the range $[a,b]$ with the greatest $a \\le s$ (if it exists). If $e \\le b$, accept; otherwise, reject. Per segment, this performs $O(\\log n)$ comparisons on the normalized list, which is essential for hot-path efficiency.\n\nEdge-case reasoning:\n- Zero-length segments ($\\ell = 0$) have no touched addresses; by definition they are permitted regardless of policy content.\n- Abutting ranges must be merged so that a segment ending at $b$ and another starting at $b+1$ do not create gaps if policy intended continuity. Safe abutment detection must avoid overflow when $b = 2^w - 1$; in that case, only overlapping ($a \\le b$) can occur, and abutment beyond $b$ is impossible.\n- Wrap-around detection uses the condition $e < s$ for $\\ell > 0$, which precisely captures the modulo overflow in unsigned arithmetic.\n\nApplying to the test suite:\n- Test case $1$: $\\mathcal{P}_1 = \\{[1000,1999],[3000,3999]\\}$ is already normalized. For $(1000,500)$, $e = 1000 + 500 - 1 = 1499$, and $1499 \\le 1999$, permitted. For $(3500,100)$, $e = 3500 + 100 - 1 = 3599$, and $3599 \\le 3999$, permitted. Entire list permitted, so $b_1 = 1$.\n- Test case $2$: Same policy. For $(1900,100)$, $e = 1900 + 100 - 1 = 1999$, which satisfies $1999 \\le 1999$, permitted. Entire list permitted, so $b_2 = 1$.\n- Test case $3$: Same policy. For $(1900,200)$, $e = 1900 + 200 - 1 = 2099$, and the candidate range is $[1000,1999]$. Since $2099 \\nleq 1999$, reject the segment. Entire list rejected, so $b_3 = 0$.\n- Test case $4$: $\\mathcal{P}_4 = \\varnothing$. For $(5000,0)$, $\\ell = 0$, so it is permitted by definition. Entire list permitted, so $b_4 = 1$.\n- Test case $5$: $\\mathcal{P}_5 = \\{[100,300],[200,400]\\}$ normalizes to $\\{[100,400]\\}$. For $(250,100)$, $e = 250 + 100 - 1 = 349$, and $349 \\le 400$, permitted. Entire list permitted, so $b_5 = 1$.\n- Test case $6$: Let $M = 2^{64} - 1$, $\\mathcal{P}_6 = \\{[M-15,M]\\}$. For $(M-9,20)$, compute $e = (M-9) + 20 - 1 = M + 10$ modulo $2^{64}$, which equals $10 - 1 = 9$. Since $9 < M-9$, wrap-around occurred; reject. Entire list rejected, so $b_6 = 0$.\n\nTherefore, the program must output the single line $[1,1,0,1,1,0]$.\n\nAlgorithmic summary:\n- Normalize ranges in $O(n \\log n)$ time via sort and linear merge.\n- Check each segment in $O(\\log n)$ time via binary search and bound comparison, plus a constant-time wrap-around check.\n- Aggregate boolean results per test case as specified.\n\nThe final program embeds the test suite, executes the described logic, and prints the decisions in the required format as a single line.\n```c\n// The complete and compilable C program goes here.\n// Headers must adhere to the specified restrictions.\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n\ntypedef unsigned long long ull;\n\ntypedef struct {\n    ull start;\n    ull end; // inclusive\n} Range;\n\ntypedef struct {\n    ull start;\n    ull len; // bytes, >= 0\n} Segment;\n\ntypedef struct {\n    Range *ranges;\n    int num_ranges;\n    Segment *segs;\n    int num_segs;\n} TestCase;\n\n// Comparator for qsort: sort by start ascending, then end ascending\nstatic int cmp_range(const void *a, const void *b) {\n    const Range *ra = (const Range *)a;\n    const Range *rb = (const Range *)b;\n    if (ra->start < rb->start) return -1;\n    if (ra->start > rb->start) return 1;\n    if (ra->end < rb->end) return -1;\n    if (ra->end > rb->end) return 1;\n    return 0;\n}\n\n// Normalize ranges: sort and merge overlapping or abutting ranges.\n// Abutment is when prev.end + 1 == curr.start without overflow beyond max.\n// Returns a newly allocated array in *out with length *out_n (caller must free).\nstatic void normalize_ranges(const Range *in, int n, Range **out, int *out_n) {\n    *out = NULL;\n    *out_n = 0;\n    if (n <= 0) {\n        return;\n    }\n    Range *tmp = (Range *)malloc((size_t)n * sizeof(Range));\n    if (!tmp) exit(EXIT_FAILURE);\n    for (int i = 0; i < n; ++i) tmp[i] = in[i];\n    qsort(tmp, (size_t)n, sizeof(Range), cmp_range);\n\n    Range *res = (Range *)malloc((size_t)n * sizeof(Range));\n    if (!res) exit(EXIT_FAILURE);\n    int m = 0;\n    ull ULL_MAX_LOCAL = ~0ULL;\n\n    Range cur = tmp[0];\n    for (int i = 1; i < n; ++i) {\n        Range nxt = tmp[i];\n        int overlap_or_abut = 0;\n        if (cur.end == ULL_MAX_LOCAL) {\n            // Cannot abut beyond max; only overlap if nxt.start <= cur.end\n            if (nxt.start <= cur.end) overlap_or_abut = 1;\n        } else {\n            // Overlap if nxt.start <= cur.end; abut if nxt.start == cur.end + 1\n            if (nxt.start <= cur.end + 1ULL) overlap_or_abut = 1;\n        }\n        if (overlap_or_abut) {\n            if (nxt.end > cur.end) cur.end = nxt.end;\n        } else {\n            res[m++] = cur;\n            cur = nxt;\n        }\n    }\n    res[m++] = cur;\n\n    free(tmp);\n    *out = res;\n    *out_n = m;\n}\n\n// Binary search to find index of range with greatest start <= addr.\n// Returns index >= 0 if found, -1 otherwise.\nstatic int find_range_by_start_leq(const Range *ranges, int n, ull addr) {\n    int lo = 0, hi = n - 1, ans = -1;\n    while (lo <= hi) {\n        int mid = lo + (hi - lo) / 2;\n        if (ranges[mid].start <= addr) {\n            ans = mid;\n            lo = mid + 1;\n        } else {\n            hi = mid - 1;\n        }\n    }\n    return ans;\n}\n\n// Check a single segment against normalized ranges.\n// Returns 1 if permitted, 0 otherwise.\nstatic int check_segment(const Range *ranges, int n, ull s, ull len) {\n    if (len == 0ULL) {\n        return 1; // zero-length segment permitted\n    }\n    ull e = s + len - 1ULL;\n    if (e < s) {\n        // Wrap-around detected (unsigned arithmetic)\n        return 0;\n    }\n    int idx = find_range_by_start_leq(ranges, n, s);\n    if (idx < 0) return 0;\n    Range r = ranges[idx];\n    if (s >= r.start && e <= r.end) return 1;\n    return 0;\n}\n\n// Enforce a scatter-gather list against a policy.\nstatic int enforce_scatterlist(const Range *policy, int num_ranges, const Segment *segs, int num_segs) {\n    Range *norm = NULL;\n    int norm_n = 0;\n    normalize_ranges(policy, num_ranges, &norm, &norm_n);\n\n    int ok = 1;\n    for (int i = 0; i < num_segs; ++i) {\n        if (!check_segment(norm, norm_n, segs[i].start, segs[i].len)) {\n            ok = 0;\n            break;\n        }\n    }\n    free(norm);\n    return ok;\n}\n\nint main(void) {\n    // Define policies and scatter-gather lists for six test cases.\n\n    // Test cases 1-3 share the same policy.\n    Range p1[] = { {1000ULL, 1999ULL}, {3000ULL, 3999ULL} };\n    Segment s1[] = { {1000ULL, 500ULL}, {3500ULL, 100ULL} };     // expected permit\n    Segment s2[] = { {1900ULL, 100ULL} };                        // boundary inclusive end\n    Segment s3[] = { {1900ULL, 200ULL} };                        // partial overrun, expected reject\n\n    // Test case 4: empty policy, zero-length segment.\n    Range *p4 = NULL; // empty\n    Segment s4[] = { {5000ULL, 0ULL} };\n\n    // Test case 5: overlapping ranges require normalization.\n    Range p5[] = { {100ULL, 300ULL}, {200ULL, 400ULL} };\n    Segment s5[] = { {250ULL, 100ULL} };\n\n    // Test case 6: near 2^64 - 1 overflow/wrap-around.\n    ull M = ~0ULL; // 2^64 - 1 on typical platforms with 64-bit unsigned long long\n    Range p6[1];\n    p6[0].start = M - 15ULL;\n    p6[0].end   = M;\n    Segment s6[1];\n    s6[0].start = M - 9ULL;\n    s6[0].len   = 20ULL;\n\n    TestCase test_cases[6];\n    test_cases[0].ranges = p1; test_cases[0].num_ranges = (int)(sizeof(p1)/sizeof(p1[0]));\n    test_cases[0].segs   = s1; test_cases[0].num_segs   = (int)(sizeof(s1)/sizeof(s1[0]));\n\n    test_cases[1].ranges = p1; test_cases[1].num_ranges = (int)(sizeof(p1)/sizeof(p1[0]));\n    test_cases[1].segs   = s2; test_cases[1].num_segs   = (int)(sizeof(s2)/sizeof(s2[0]));\n\n    test_cases[2].ranges = p1; test_cases[2].num_ranges = (int)(sizeof(p1)/sizeof(p1[0]));\n    test_cases[2].segs   = s3; test_cases[2].num_segs   = (int)(sizeof(s3)/sizeof(s3[0]));\n\n    test_cases[3].ranges = p4; test_cases[3].num_ranges = 0;\n    test_cases[3].segs   = s4; test_cases[3].num_segs   = (int)(sizeof(s4)/sizeof(s4[0]));\n\n    test_cases[4].ranges = p5; test_cases[4].num_ranges = (int)(sizeof(p5)/sizeof(p5[0]));\n    test_cases[4].segs   = s5; test_cases[4].num_segs   = (int)(sizeof(s5)/sizeof(s5[0]));\n\n    test_cases[5].ranges = p6; test_cases[5].num_ranges = (int)(sizeof(p6)/sizeof(p6[0]));\n    test_cases[5].segs   = s6; test_cases[5].num_segs   = (int)(sizeof(s6)/sizeof(s6[0]));\n\n    int num_cases = (int)(sizeof(test_cases) / sizeof(test_cases[0]));\n    int *results = (int *)malloc((size_t)num_cases * sizeof(int));\n    if (!results) return EXIT_FAILURE;\n\n    for (int i = 0; i < num_cases; ++i) {\n        results[i] = enforce_scatterlist(test_cases[i].ranges,\n                                         test_cases[i].num_ranges,\n                                         test_cases[i].segs,\n                                         test_cases[i].num_segs);\n    }\n\n    // Print the results in the exact required format.\n    printf(\"[\");\n    for (int i = 0; i < num_cases; ++i) {\n        printf(\"%d\", results[i]);\n        if (i + 1 < num_cases) printf(\",\");\n    }\n    printf(\"]\");\n\n    free(results);\n    return EXIT_SUCCESS;\n}\n```", "answer": "$$ \\boxed{\\text{[1,1,0,1,1,0]}} $$", "id": "3648953"}]}