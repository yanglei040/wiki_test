{"hands_on_practices": [{"introduction": "The foundation of any correct nonblocking algorithm is ensuring that changes made by one thread are visible to others in a predictable order. Unlike traditional locks, atomic operations require programmers to explicitly manage memory visibility using ordering constraints. This first exercise [@problem_id:3664124] dives into this critical concept by presenting a common bug in a producer-consumer queue, challenging you to fix a data race by correctly applying C11 memory ordering semantics. Mastering this is the first step toward building reliable concurrent systems.", "problem": "A single-producer single-consumer (SPSC) queue implemented with International Organization for Standardization C 2011 (C11) atomics is intended to be nonblocking and correct on all mainstream hardware. The producer thread allocates a node, fully initializes its fields in ordinary (non-atomic) memory, and then publishes the node by storing its pointer into a shared atomic variable. The consumer thread spins until that shared atomic variable becomes non-null, then reads the node’s fields. The relevant steps are:\n\n- Producer thread:\n  1. Write the data field $d$ in the node $n$ with the value $1$ using ordinary non-atomic stores.\n  2. Publish the pointer to $n$ by performing an atomic store to the shared atomic pointer $H$ with $memory\\_order\\_release$.\n\n- Consumer thread:\n  1. Poll $H$ with an atomic load using $memory\\_order\\_relaxed$ until it becomes non-null, storing the result into a local pointer $p$.\n  2. Read the data field $d$ via $p$ in ordinary non-atomic memory and use it.\n\nAssume the initial state is $H = \\text{null}$ and $d = 0$. The intended invariant is: once the consumer observes $H \\neq \\text{null}$, it must subsequently read $d = 1$ from the published node. However, on architectures that permit weak ordering and in the C11 memory model, the above consumer code may sometimes observe $H \\neq \\text{null}$ and then still read $d = 0$. The core definitions that govern correctness in this setting are:\n\n- A store with $memory\\_order\\_release$ followed by a load with $memory\\_order\\_acquire$ of the same atomic object that reads from that store establishes a synchronizes-with relation, which in turn yields a happens-before edge that orders prior ordinary writes (such as to $d$) before later ordinary reads in the other thread.\n- In the absence of a synchronizes-with relation, ordinary non-atomic reads of $d$ in the consumer are not required to see the ordinary non-atomic writes to $d$ performed by the producer before the release store to $H$.\n- A compiler barrier prevents certain reorderings by the compiler but does not, by itself, provide inter-thread visibility guarantees unless combined with appropriate atomic operations or fences in the C11 model.\n\nConsider the described bug: the consumer uses $memory\\_order\\_relaxed$ for the load of $H$ and then immediately reads $d$. Which of the following modifications, applied to the consumer or producer code as specified, establish the required ordering and visibility guarantees so that once the consumer observes $H \\neq \\text{null}$, it must read $d = 1$? Choose all that apply.\n\nA. Change the consumer’s load of $H$ from $memory\\_order\\_relaxed$ to $memory\\_order\\_acquire$, keeping the producer’s store to $H$ as $memory\\_order\\_release$.\n\nB. Keep the consumer’s load of $H$ as $memory\\_order\\_relaxed$, but immediately after observing $H \\neq \\text{null}$ insert $atomic\\_thread\\_fence(memory\\_order\\_acquire)$ before reading $d$.\n\nC. Keep the consumer’s load of $H$ as $memory\\_order\\_relaxed$, and instead insert $atomic\\_signal\\_fence(memory\\_order\\_acquire)$ before reading $d$.\n\nD. Declare $H$ as $volatile$ and keep all memory orders unchanged.\n\nE. Change the producer’s store to $H$ from $memory\\_order\\_release$ to $memory\\_order\\_seq\\_cst$, leaving the consumer’s load of $H$ as $memory\\_order\\_relaxed$.", "solution": "The problem describes a data race on the non-atomic data field $d$. For the program to be correct, the producer's write to $d$ must *happen-before* the consumer's read of $d$. The C11 memory model establishes this `happens-before` relationship primarily through a `synchronizes-with` relationship between atomic operations.\n\nIn the original, flawed implementation:\n- Producer performs a non-atomic write: $d=1$.\n- Producer performs an atomic store: $H \\leftarrow n$ with $memory\\_order\\_release$.\n- Consumer performs an atomic load: $p \\leftarrow H$ with $memory\\_order\\_relaxed$.\n- Consumer performs a non-atomic read of $d$ via $p$.\n\nA $memory\\_order\\_release$ operation ensures that all prior memory writes in the same thread are visible to other threads that perform a $memory\\_order\\_acquire$ operation on the same atomic variable. The consumer's $memory\\_order\\_relaxed$ load does not create this link. It only guarantees the atomicity of the load itself, not any ordering with respect to other memory operations. Thus, there is no `synchronizes-with` relationship, no `happens-before` edge is formed for the access to $d$, and the consumer may read the stale value $d=0$ even after observing a non-null $H$.\n\nTo fix this, we must establish a `synchronizes-with` relationship between the producer's store and the consumer's subsequent actions. Let's analyze each proposed modification.\n\n**A. Change the consumer’s load of $H$ to $memory\\_order\\_acquire$.**\nThis modification creates the canonical `release-acquire` pairing. According to the C11 standard, a store to an atomic object with $memory\\_order\\_release$ `synchronizes-with` a load from the same atomic object with $memory\\_order\\_acquire$ that reads the value written. This establishes a `happens-before` relationship. By transitivity, the producer's write to $d$ *happens-before* the consumer's read of $d$. This correctly orders the memory accesses and guarantees the consumer will read $d=1$.\n**Verdict: Correct.**\n\n**B. Insert $atomic\\_thread\\_fence(memory\\_order\\_acquire)$ after the relaxed load.**\nThis uses a memory fence to establish ordering. An atomic store operation $A$ with $memory\\_order\\_release$ `synchronizes-with` an $atomic\\_thread\\_fence$ $B$ with $memory\\_order\\_acquire$ if there is an atomic load $L$ (which can be relaxed) that reads the value stored by $A$, and $L$ is sequenced-before $B$. This pattern correctly ensures that all memory writes that *happened-before* the producer's `release` store are visible to all memory reads that *happen-after* the consumer's `acquire` fence.\n**Verdict: Correct.**\n\n**C. Insert $atomic\\_signal\\_fence(memory\\_order\\_acquire)$.**\nAn $atomic\\_signal\\_fence$ only creates memory ordering guarantees within a single thread, typically between a signal handler and the thread it interrupted. It does not emit inter-core synchronization instructions (memory barriers) and cannot establish a `synchronizes-with` relationship between two different threads. The inter-thread visibility problem remains unsolved.\n**Verdict: Incorrect.**\n\n**D. Declare $H$ as $volatile$.**\nThe `volatile` keyword in C11 prevents the compiler from optimizing away memory accesses but provides no guarantees about memory ordering between different threads. It does not generate the memory fences required for cache coherence on multi-core systems. The original data race due to $memory\\_order\\_relaxed$ would persist.\n**Verdict: Incorrect.**\n\n**E. Change the producer’s store to $memory\\_order\\_seq\\_cst$.**\nA store with $memory\\_order\\_seq\\_cst$ acts as a `release` operation. While it is stronger than $memory\\_order\\_release$, it still requires a corresponding synchronizing operation in the consumer thread. As per the C11 standard, a `release` operation does not `synchronize-with` a $memory\\_order\\_relaxed$ load. The consumer's `relaxed` load still fails to establish the necessary `happens-before` relationship.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{AB}$$", "id": "3664124"}, {"introduction": "Even with atomic operations, subtle logical errors can arise. The A-B-A problem is a classic hazard in algorithms that use compare-and-swap (CAS), where a memory location is read (value A), modified by other threads (to B, then back to A), and then updated by the first thread, whose CAS succeeds on the now-stale assumption that nothing has changed. This practice [@problem_id:3664130] challenges you to analyze this problem quantitatively, calculating the necessary size of a \"tag\" to guarantee that such a logical error cannot occur within a given operational lifetime.", "problem": "A lock-free work-stealing double-ended queue (deque) is implemented as a circular buffer of capacity $C = 2^{20}$ slots. The shared top pointer is represented as a single machine word packing an index $i \\in \\{0, 1, \\dots, C - 1\\}$ and a tag $t \\in \\{0, 1, \\dots, 2^b - 1\\}$, written as the pair $(i, t)$. Thief threads use Compare-And-Swap (CAS) to steal from the top: they read the current $(i, t)$, compute a proposed new top, and then attempt a CAS that succeeds only if the current packed word equals their expected $(i, t)$. To mitigate the so-called A-B-A problem (commonly abbreviated as ABA), the tag $t$ is incremented by $1$ modulo $2^b$ on every successful change to the top by any thread, while the index $i$ advances by $1$ modulo $C$ on each successful steal.\n\nAssume a thief reads an initial pair $(i_0, t_0)$, and before it attempts its CAS, up to $M_{\\max} = 10^{12}$ successful top changes by other threads may occur. An ABA vulnerability arises if, within those changes, the packed word returns to the identical pair $(i_0, t_0)$, making the thief’s CAS succeed with a stale view even though the logical state has changed. In this implementation, an A-B-A requires that both the index and the tag return to their initial values, i.e., after some number $m$ of changes, $i_0 + m \\equiv i_0 \\pmod{C}$ and $t_0 + m \\equiv t_0 \\pmod{2^b}$ simultaneously.\n\nWhich option gives the smallest tag width $b$ (in bits) that guarantees no A-B-A can occur within any window of strictly fewer than $M_{\\max}$ successful top changes?\n\nA. $b = 20$\n\nB. $b = 30$\n\nC. $b = 40$\n\nD. $b = 50$", "solution": "The problem asks for the minimum tag width $b$ to prevent an ABA problem within a window of fewer than $M_{\\max} = 10^{12}$ operations. An ABA event occurs if the packed word $(i, t)$ returns to its initial value $(i_0, t_0)$ after some number of successful top changes, $m$.\n\nEach successful change increments both the index $i$ and the tag $t$. The index wraps around with a period of $C = 2^{20}$, and the tag wraps around with a period of $2^b$. For the packed word to return to its original value, both the index and the tag must return to their initial values simultaneously. This requires the number of changes, $m$, to be a multiple of both periods.\n\nMathematically, we need to find the smallest positive integer $m$ that satisfies:\n1. $m \\equiv 0 \\pmod{C}$\n2. $m \\equiv 0 \\pmod{2^b}$\n\nThis smallest value of $m$ is the least common multiple (LCM) of $C$ and $2^b$.\nGiven $C = 2^{20}$, the LCM is:\n$$ m_{\\text{ABA}} = \\text{lcm}(C, 2^b) = \\text{lcm}(2^{20}, 2^b) $$\nThe LCM of two powers of the same base is the base raised to the maximum of the exponents.\n$$ m_{\\text{ABA}} = 2^{\\max(20, b)} $$\nTo guarantee that no ABA problem can occur within a window of fewer than $M_{\\max}$ changes, the first possible occurrence of an ABA ($m_{\\text{ABA}}$) must be at least $M_{\\max}$.\n$$ m_{\\text{ABA}} \\ge M_{\\max} $$\n$$ 2^{\\max(20, b)} \\ge 10^{12} $$\nTo solve for the exponent, we take the base-2 logarithm of both sides:\n$$ \\max(20, b) \\ge \\log_2(10^{12}) $$\nUsing the logarithm property $\\log(x^y) = y \\log(x)$:\n$$ \\max(20, b) \\ge 12 \\cdot \\log_2(10) $$\nWe can approximate $\\log_2(10) \\approx 3.3219$.\n$$ \\max(20, b) \\ge 12 \\cdot 3.3219 $$\n$$ \\max(20, b) \\ge 39.863 $$\nSince $b$ must be an integer, the value of $\\max(20, b)$ must also be an integer. The smallest integer satisfying this inequality is $40$.\n$$ \\max(20, b) \\ge 40 $$\nThis inequality requires that the larger of $20$ and $b$ must be at least $40$. This is only true if $b \\ge 40$.\nTherefore, the smallest integer tag width $b$ that satisfies the condition is $b=40$.\n\nLet's check the options:\n- A. $b=20$: $\\max(20, 20) = 20$. $20 \\not\\ge 40$. Incorrect.\n- B. $b=30$: $\\max(20, 30) = 30$. $30 \\not\\ge 40$. Incorrect.\n- C. $b=40$: $\\max(20, 40) = 40$. $40 \\ge 40$. This is the smallest integer value for $b$ that satisfies the condition. Correct.\n- D. $b=50$: $\\max(20, 50) = 50$. $50 \\ge 40$. This is a valid width, but not the *smallest* required width. Incorrect.\n\nThus, a tag width of 40 bits is the minimum necessary to ensure the tag and index combination does not repeat until at least $2^{40} \\approx 1.1 \\times 10^{12}$ operations have occurred, which is greater than the specified maximum of $10^{12}-1$ intervening operations.", "answer": "$$\\boxed{C}$$", "id": "3664130"}, {"introduction": "With a solid grasp of memory ordering and the pitfalls of atomic updates, you are ready to build a complete, nonblocking data structure. This exercise [@problem_id:3664167] guides you through the implementation of a dictionary using the Read-Copy-Update (RCU) pattern, a highly efficient technique for read-mostly workloads. You will put theory into practice by managing immutable snapshots, publishing updates atomically, and implementing a safe memory reclamation scheme based on grace periods, integrating all the core concepts of nonblocking synchronization.", "problem": "You are to implement a Read-Copy-Update (RCU) dictionary that supports nonblocking readers and writers that publish new snapshots and defer reclamation of old snapshots until a grace period has elapsed. The educational context is an introduction to operating systems, focused on nonblocking synchronization at the advanced undergraduate level.\n\nFundamental base and definitions to use:\n- Atomic operations are indivisible with respect to concurrent execution. Let $x$ be an atomic variable; an atomic store is denoted $\\text{store}(x, v)$ and an atomic load is denoted $\\text{load}(x)$.\n- Memory ordering semantics: an acquire operation ensures that subsequent loads and stores in program order observe prior stores performed with release semantics by other threads. A release operation ensures that preceding loads and stores become visible to threads that perform an acquire of the published variable. Formally, if a writer performs $\\text{store\\_release}(x, v)$ and a reader performs $\\text{load\\_acquire}(x)$ and observes $v$, then the reader will observe all writes that happened-before the release in the writer.\n- In Read-Copy-Update, readers execute within read-side critical sections that never block, while writers publish a new root pointer to a fully formed copy (a snapshot) and retire the old root. Memory reclamation of retired snapshots is deferred until a grace period has elapsed, defined as the interval during which all readers that could have held references to the retired snapshot have exited their read-side critical sections.\n\nYour implementation must satisfy:\n- The dictionary maps string keys to integer values. Each snapshot is immutable once published.\n- Readers:\n  - A reader begins a read-side critical section by taking an acquire load of the global root pointer and incrementing a global atomic reader counter. Denote the reader counter by $R$.\n  - The reader traverses the snapshot without locks and without waiting, and ends the read-side critical section by decrementing $R$ with release semantics.\n- Writers:\n  - A writer creates a new snapshot by copying the current root and applying modifications (insertion, update, or deletion).\n  - The writer publishes the new root using a release store or an acquire-release exchange on the atomic root pointer.\n  - The old root is placed on a retired list. Reclamation of all retired roots may occur only when $\\text{load\\_acquire}(R) = 0$ (a grace period), at which point the writer frees all retired snapshots safely.\n\nAssume a single-process simulation with sequential steps that respect acquire-release semantics; you do not need to spawn actual threads. However, you must use atomic operations with acquire/release memory ordering to model the correct happens-before relationships.\n\nImplement the program to process the following test suite of scenarios. The initial dictionary snapshot contains three key-value pairs: $\\text{\"mode\"} \\mapsto 1$, $\\text{\"threads\"} \\mapsto 4$, $\\text{\"debug\"} \\mapsto 1$.\n\nTest suite:\n1. Happy path update:\n   - A writer updates $\\text{\"mode\"}$ to $2$ by publishing a new snapshot and retires the old root.\n   - A reader enters a read-side critical section, reads $\\text{\"mode\"}$ from its snapshot, then exits.\n   - Output for this test is the integer value the reader observed for $\\text{\"mode\"}$.\n2. Snapshot consistency under concurrent update:\n   - A reader enters, reads $\\text{\"threads\"}$ (initially $4$).\n   - A writer updates $\\text{\"threads\"}$ to $8$ by publishing a new snapshot and retires the old root.\n   - The same reader, still within its read-side critical section, reads $\\text{\"threads\"}$ again from its snapshot, then exits.\n   - Output for this test is the integer difference $d = v_{\\text{after}} - v_{\\text{before}}$ observed by the same reader inside the same critical section. A consistent snapshot implies $d = 0$.\n3. Deletion with deferred reclamation:\n   - A reader enters, reads the presence of key $\\text{\"debug\"}$ (presence encoded as $1$ if found, $0$ otherwise).\n   - A writer deletes $\\text{\"debug\"}$ by publishing a new snapshot and retires the old root.\n   - The same reader, still inside its read-side critical section, reads presence of $\\text{\"debug\"}$ again, then exits.\n   - A new reader enters and reads presence of $\\text{\"debug\"}$, then exits.\n   - Output for this test is an integer $b$ defined as $1$ if the first reader observed presence $1$ both before and during its critical section while the new reader observed presence $0$ after the deletion; otherwise $0$.\n4. Deferred frees across multiple writes:\n   - A reader enters and stays in its read-side critical section.\n   - A writer performs three successive publishes: updates $\\text{\"mode\"}$ to $3$, inserts $\\text{\"opt\"} \\mapsto 7$, and updates $\\text{\"threads\"}$ to $16$, retiring each old root on every publish.\n   - While the reader is still active, attempt reclamation (which must not reclaim anything since $R > 0$).\n   - The reader exits, then reclamation occurs and frees all retired roots.\n   - Output for this test is the integer number of retired roots freed in that reclamation step. With three publishes and a single reader deferring reclamation, the correct value is $3$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the tests: $[\\text{result1},\\text{result2},\\text{result3},\\text{result4}]$.\n\nAll outputs are integers. No physical units or angle units are involved. Percentages must not be used; presence must be encoded as integers as specified.\n\nYour program must be a complete, runnable program with no user input. Use atomic operations with acquire and release semantics to model nonblocking reader behavior and deferred freeing by writers.", "solution": "The problem requires the implementation of a dictionary using the Read-Copy-Update (RCU) nonblocking synchronization mechanism. The solution must correctly model the behavior of concurrent readers and writers according to specified acquire-release memory semantics, even within a single-threaded simulation.\n\n### Principle-Based Design\n\nThe solution is founded on the core principles of Read-Copy-Update (RCU), a synchronization technique optimized for read-mostly scenarios.\n\n1.  **Read-Side Critical Sections**: Readers operate without locks. They obtain a pointer to a consistent snapshot of the data and are guaranteed that this snapshot will not be modified or freed for the duration of their read-side critical section.\n2.  **Copy-on-Write Updates**: Writers do not modify data in place. Instead, they create a private copy of the data structure, apply their modifications to this copy, and then atomically \"publish\" the new version by updating a single global pointer.\n3.  **Deferred Reclamation**: Since readers might be traversing an old version of the data, writers cannot immediately free the memory associated with it. The reclamation of old data versions is deferred until a \"grace period\" has passed, which is defined as the time it takes for all readers that might have been using the old data to complete their critical sections.\n\n### Data Structures\n\nTo implement the RCU dictionary, the following data structures are employed:\n\n-   **Dictionary Node (`RCU_Node`)**: A standard singly-linked list node is used to represent a key-value pair.\n    ```c\n    typedef struct RCU_Node {\n        char* key;\n        int value;\n        struct RCU_Node* next;\n    } RCU_Node;\n    ```\n-   **Snapshot (`RCU_Snapshot`)**: A snapshot of the dictionary is simply a pointer to the head of a linked list of `RCU_Node`s. Since snapshots are immutable once published, this pointer provides access to a complete, consistent version of the dictionary.\n-   **Global Root Pointer (`g_rcu_root`)**: A global atomic pointer, `_Atomic(RCU_Snapshot) g_rcu_root`, points to the currently active snapshot. This is the central point of coordination between readers and writers.\n-   **Reader Counter (`g_reader_count`)**: A global atomic integer, `_Atomic int g_reader_count`, tracks the number of readers currently executing within a read-side critical section.\n-   **Retired List (`Retired_Node`)**: A simple, non-atomic linked list is used by writers to keep track of old snapshots that are pending reclamation.\n\n### Synchronization and Memory Ordering\n\nThe correctness of RCU hinges on strict memory ordering rules, which are implemented using C11/C23 `stdatomic.h` primitives.\n\n-   **Reader Enters Critical Section**: A reader begins by invoking a function analogous to `rcu_read_lock()`.\n    1.  It performs an atomic load of the global root pointer `g_rcu_root` with `memory_order_acquire` semantics. This acquire operation ensures that the reader sees all writes made by a writer before the writer published that root pointer. The reader now has a stable pointer to an immutable snapshot.\n    2.  It increments the global reader counter `g_reader_count` with `memory_order_relaxed`. This operation signals that a new reader is active. It can use relaxed ordering because the essential memory ordering was already established by the acquire load of the root pointer.\n\n-   **Reader Exits Critical Section**: Upon completion, the reader invokes a function analogous to `rcu_read_unlock()`.\n    1.  It decrements the reader counter with `memory_order_release` semantics. This release operation is critical; it ensures that all memory accesses performed by the reader within its critical section are visible to the writer's grace period detection logic.\n\n-   **Writer Publishes a New Snapshot**: A writer follows the \"copy-update-publish\" sequence.\n    1.  It creates a deep copy of the current snapshot.\n    2.  It applies all modifications (inserts, updates, deletes) to this private copy.\n    3.  It atomically swaps the global root pointer to publish the new version using `atomic_exchange_explicit` with `memory_order_acq_rel`. The `release` semantics make the new snapshot's contents visible to subsequent `acquire` loads by readers. The `acquire` semantics ensure the writer's view of memory is synchronized before retiring the old snapshot.\n    4.  The old snapshot pointer is added to the retired list.\n\n-   **Writer Reclaims Memory**: A writer can initiate memory reclamation by checking for the end of a grace period.\n    1.  The condition for a grace period having elapsed is `g_reader_count == 0`.\n    2.  The check is performed with `atomic_load_explicit(&g_reader_count, memory_order_acquire)`. This `acquire` synchronizes with the `release` decrement performed by readers exiting their critical sections. If the load returns $0$, the writer is guaranteed that any reader which might have held a reference to a retired snapshot has finished its work.\n    3.  If the condition is met, the writer can safely traverse the retired list and free all the memory associated with the old snapshots.\n\n### Test Scenario Execution\n\nThe implementation executes the four test scenarios sequentially.\n\n-   **Test 1**: A writer updates a value, and a subsequent reader correctly observes the new value of $2$.\n-   **Test 2**: A reader acquires a snapshot. A writer then publishes a new snapshot. The reader, still operating on its original, immutable snapshot, reads the same value twice, demonstrating snapshot isolation. The difference is $0$.\n-   **Test 3**: A reader (Reader 1) acquires a snapshot where key `\"debug\"` exists. A writer then deletes the key and publishes a new snapshot. Reader 1, still inside its critical section, re-reads and finds the key still present in its local snapshot. A new reader (Reader 2) then starts and acquires the new snapshot, correctly finding the key to be absent. This yields a result of $1$.\n-   **Test 4**: A reader remains active while a writer performs three successive updates, retiring three old snapshots. An attempt to reclaim memory fails because the reader is active (`g_reader_count > 0`). Only after the reader exits can a subsequent reclamation attempt succeed, freeing the $3$ retired snapshots.\n\nThis design correctly models the fundamental properties of RCU: nonblocking reads, snapshot consistency, and safe, deferred memory reclamation based on explicit grace period detection via acquire-release semantics.", "answer": "```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <stdatomic.h>\n#include <math.h>\n\n// A node in the dictionary's linked list.\ntypedef struct RCU_Node {\n    char* key;\n    int value;\n    struct RCU_Node* next;\n} RCU_Node;\n\n// A snapshot is a pointer to the head of the dictionary list.\ntypedef RCU_Node* RCU_Snapshot;\n\n// A node for the list of retired snapshots pending reclamation.\ntypedef struct Retired_Node {\n    RCU_Snapshot snapshot;\n    struct Retired_Node* next;\n} Retired_Node;\n\n// --- Global RCU State ---\n// The atomic pointer to the current version of the dictionary.\n_Atomic(RCU_Snapshot) g_rcu_root;\n// The atomic counter for active readers.\n_Atomic int g_reader_count;\n// The head of the list of retired snapshots. Only accessed by writers.\nRetired_Node* g_retired_list_head = NULL;\n\n// --- Helper Functions ---\n\n// Creates a new dictionary node (allocates memory for key).\nRCU_Node* create_node(const char* key, int value, RCU_Node* next) {\n    RCU_Node* node = (RCU_Node*)malloc(sizeof(RCU_Node));\n    if (!node) {\n        perror(\"malloc RCU_Node failed\");\n        exit(EXIT_FAILURE);\n    }\n    node->key = (char*)malloc(strlen(key) + 1);\n    if (!node->key) {\n        perror(\"malloc key failed\");\n        free(node);\n        exit(EXIT_FAILURE);\n    }\n    strcpy(node->key, key);\n    node->value = value;\n    node->next = next;\n    return node;\n}\n\n// Frees a complete snapshot (a linked list).\nvoid free_snapshot(RCU_Snapshot snapshot) {\n    RCU_Node* current = snapshot;\n    while (current != NULL) {\n        RCU_Node* temp = current;\n        current = current->next;\n        free(temp->key);\n        free(temp);\n    }\n}\n\n// Performs a deep copy of a snapshot.\nRCU_Snapshot copy_snapshot(RCU_Snapshot snapshot) {\n    if (snapshot == NULL) {\n        return NULL;\n    }\n    RCU_Node* old_curr = snapshot;\n    RCU_Node* new_head = create_node(old_curr->key, old_curr->value, NULL);\n    RCU_Node* new_curr = new_head;\n    old_curr = old_curr->next;\n\n    while (old_curr != NULL) {\n        new_curr->next = create_node(old_curr->key, old_curr->value, NULL);\n        new_curr = new_curr->next;\n        old_curr = old_curr->next;\n    }\n    return new_head;\n}\n\n// Inserts or updates a key in a given (copied) snapshot. Returns the new head.\nRCU_Snapshot dict_update(RCU_Snapshot snapshot, const char* key, int value) {\n    RCU_Node* curr = snapshot;\n    // Check if key exists for update\n    while (curr != NULL) {\n        if (strcmp(curr->key, key) == 0) {\n            curr->value = value;\n            return snapshot;\n        }\n        curr = curr->next;\n    }\n    // Key not found, insert at head\n    return create_node(key, value, snapshot);\n}\n\n// Deletes a key from a given (copied) snapshot. Returns the new head.\nRCU_Snapshot dict_delete(RCU_Snapshot snapshot, const char* key) {\n    if (snapshot == NULL) {\n        return NULL;\n    }\n    // If head node is the one to be deleted\n    if (strcmp(snapshot->key, key) == 0) {\n        RCU_Node* new_head = snapshot->next;\n        snapshot->next = NULL; // Detach it from the list\n        return new_head;\n    }\n    // Search for the node to delete\n    RCU_Node* curr = snapshot;\n    while (curr->next != NULL && strcmp(curr->next->key, key) != 0) {\n        curr = curr->next;\n    }\n    // If the node was found, bypass it\n    if (curr->next != NULL) {\n        RCU_Node* node_to_delete = curr->next;\n        curr->next = node_to_delete->next;\n        node_to_delete->next = NULL; // Detach\n    }\n    return snapshot;\n}\n\n// Looks for a key in a given snapshot. Returns a const pointer to the node.\nconst RCU_Node* dict_lookup(RCU_Snapshot snapshot, const char* key) {\n    const RCU_Node* curr = snapshot;\n    while (curr != NULL) {\n        if (strcmp(curr->key, key) == 0) {\n            return curr;\n        }\n        curr = curr->next;\n    }\n    return NULL;\n}\n\n\n// --- RCU Core Functions ---\n\n// Reader indicates start of a critical section.\nRCU_Snapshot rcu_read_lock() {\n    // Acquire load ensures we see a fully published snapshot.\n    RCU_Snapshot local_snapshot = atomic_load_explicit(&g_rcu_root, memory_order_acquire);\n    // Increment reader count. Relaxed is sufficient as ordering is handled by root load.\n    atomic_fetch_add_explicit(&g_reader_count, 1, memory_order_relaxed);\n    return local_snapshot;\n}\n\n// Reader indicates end of a critical section.\nvoid rcu_read_unlock() {\n    // Release decrement synchronizes with the writer's grace period check.\n    atomic_fetch_sub_explicit(&g_reader_count, 1, memory_order_release);\n}\n\n// Writer publishes a new snapshot.\nvoid rcu_publish(RCU_Snapshot new_snapshot) {\n    // Atomically swap the root pointer. Acq/Rel ensures ordering with readers and other writers.\n    RCU_Snapshot old_snapshot = atomic_exchange_explicit(&g_rcu_root, new_snapshot, memory_order_acq_rel);\n\n    // Add old snapshot to the retired list.\n    Retired_Node* retired_node = (Retired_Node*)malloc(sizeof(Retired_Node));\n    if (!retired_node) {\n        perror(\"malloc Retired_Node failed\");\n        exit(EXIT_FAILURE);\n    }\n    retired_node->snapshot = old_snapshot;\n    retired_node->next = g_retired_list_head;\n    g_retired_list_head = retired_node;\n}\n\n// Writer attempts to reclaim memory from retired snapshots.\nint rcu_synchronize() {\n    // Acquire load synchronizes-with reader's release decrement on the counter.\n    if (atomic_load_explicit(&g_reader_count, memory_order_acquire) == 0) {\n        int freed_count = 0;\n        Retired_Node* current = g_retired_list_head;\n        while (current != NULL) {\n            Retired_Node* temp = current;\n            current = current->next;\n            free_snapshot(temp->snapshot);\n            free(temp);\n            freed_count++;\n        }\n        g_retired_list_head = NULL;\n        return freed_count;\n    }\n    return 0;\n}\n\n\n// --- Test Scenarios ---\n\nint run_test1() {\n    // Writer updates \"mode\" to 2\n    RCU_Snapshot current_root = atomic_load(&g_rcu_root);\n    RCU_Snapshot new_root = copy_snapshot(current_root);\n    new_root = dict_update(new_root, \"mode\", 2);\n    rcu_publish(new_root);\n\n    // Reader enters, reads \"mode\", and exits\n    RCU_Snapshot reader_view = rcu_read_lock();\n    const RCU_Node* node = dict_lookup(reader_view, \"mode\");\n    int value = node ? node->value : -1; // -1 for not found\n    rcu_read_unlock();\n    \n    return value;\n}\n\nint run_test2() {\n    // Reader enters and reads \"threads\"\n    RCU_Snapshot reader_view = rcu_read_lock();\n    const RCU_Node* node_before = dict_lookup(reader_view, \"threads\");\n    int v_before = node_before ? node_before->value : -1;\n\n    // Writer updates \"threads\" to 8\n    RCU_Snapshot current_root = atomic_load(&g_rcu_root);\n    RCU_Snapshot new_root = copy_snapshot(current_root);\n    new_root = dict_update(new_root, \"threads\", 8);\n    rcu_publish(new_root);\n    \n    // The same reader reads \"threads\" again from its original snapshot\n    const RCU_Node* node_after = dict_lookup(reader_view, \"threads\");\n    int v_after = node_after ? node_after->value : -1;\n\n    // Reader exits\n    rcu_read_unlock();\n    \n    return v_after - v_before;\n}\n\nint run_test3() {\n    // Reader 1 enters and reads \"debug\"\n    RCU_Snapshot reader1_view = rcu_read_lock();\n    int p1_before = (dict_lookup(reader1_view, \"debug\") != NULL);\n\n    // Writer deletes \"debug\"\n    RCU_Snapshot current_root = atomic_load(&g_rcu_root);\n    RCU_Snapshot new_root = copy_snapshot(current_root);\n    new_root = dict_delete(new_root, \"debug\");\n    rcu_publish(new_root);\n    \n    // Reader 1 reads \"debug\" again and exits\n    int p1_after = (dict_lookup(reader1_view, \"debug\") != NULL);\n    rcu_read_unlock();\n\n    // New reader enters and reads \"debug\"\n    RCU_Snapshot reader2_view = rcu_read_lock();\n    int p2 = (dict_lookup(reader2_view, \"debug\") != NULL);\n    rcu_read_unlock();\n    \n    return (p1_before == 1 && p1_after == 1 && p2 == 0) ? 1 : 0;\n}\n\nint run_test4() {\n    // A reader enters and stays in its critical section\n    RCU_Snapshot reader_view = rcu_read_lock();\n    (void)reader_view; // The view itself isn't used, just the active reader state\n\n    // Three successive publishes by a writer\n    RCU_Snapshot root_v1 = atomic_load(&g_rcu_root);\n    RCU_Snapshot root_v2 = copy_snapshot(root_v1);\n    root_v2 = dict_update(root_v2, \"mode\", 3);\n    rcu_publish(root_v2);\n\n    RCU_Snapshot root_v3 = copy_snapshot(root_v2);\n    root_v3 = dict_update(root_v3, \"opt\", 7);\n    rcu_publish(root_v3);\n    \n    RCU_Snapshot root_v4 = copy_snapshot(root_v3);\n    root_v4 = dict_update(root_v4, \"threads\", 16);\n    rcu_publish(root_v4);\n\n    // Attempt reclamation while reader is active (must fail)\n    rcu_synchronize();\n\n    // Reader exits\n    rcu_read_unlock();\n    \n    // Attempt reclamation again (must succeed)\n    return rcu_synchronize();\n}\n\nint main(void) {\n    // --- Initial Setup ---\n    atomic_init(&g_reader_count, 0);\n    g_retired_list_head = NULL;\n    \n    RCU_Snapshot initial_snapshot = NULL;\n    initial_snapshot = dict_update(initial_snapshot, \"debug\", 1);\n    initial_snapshot = dict_update(initial_snapshot, \"threads\", 4);\n    initial_snapshot = dict_update(initial_snapshot, \"mode\", 1);\n    atomic_init(&g_rcu_root, initial_snapshot);\n\n    int results[4];\n\n    results[0] = run_test1();\n    rcu_synchronize(); // Clear retired list between tests\n\n    results[1] = run_test2();\n    rcu_synchronize();\n\n    results[2] = run_test3();\n    rcu_synchronize();\n    \n    results[3] = run_test4();\n\n    // Final cleanup of the last active root that was never retired\n    free_snapshot(atomic_load(&g_rcu_root));\n    // Final check to free any remaining junk in case of error in logic\n    rcu_synchronize();\n    \n    // Print the results in the EXACT required format\n    printf(\"[%d,%d,%d,%d]\\n\", results[0], results[1], results[2], results[3]);\n    \n    return EXIT_SUCCESS;\n}\n```", "id": "3664167"}]}