{"hands_on_practices": [{"introduction": "A stable operating system is the foundation of all computing, yet stability can be compromised by subtle bugs deep within the kernel. This exercise explores a classic cause of kernel crashes: integer overflow in timekeeping mechanisms. By analyzing how a finite-width counter wrap-around interacts with signed and unsigned arithmetic, you will derive the precise conditions to prevent a timer from firing prematurely, a bug that has plagued real-world kernels. This practice [@problem_id:3686534] highlights the critical importance of understanding low-level data representation and modular arithmetic in building robust systems.", "problem": "An Operating System (OS) kernel maintains a tick counter, commonly called the jiffies counter, denoted by $J$. The counter $J$ increments by $1$ on every tick and is represented in hardware as an unsigned $b$-bit integer, so arithmetic on $J$ is performed modulo $2^{b}$. At tick time $t$, a subsystem schedules a future check at time $E \\equiv t + \\Delta t \\pmod{2^{b}}$, where $\\Delta t$ is a positive integer measured in jiffies.\n\nThe kernel’s predicate for deciding whether the current tick value $n$ is “at or past the expiry” $E$ is implemented by first forming the $b$-bit difference $D \\equiv E - n \\pmod{2^{b}}$, then interpreting the $b$-bit quantity $D$ as a signed two’s-complement integer in the range $[-2^{b-1}, 2^{b-1} - 1]$, and finally declaring “at or past expiry” if and only if $D \\le 0$. The system has crashed in the past because certain large values of $\\Delta t$ cause the predicate to evaluate to true immediately at scheduling time $n = t$, triggering misordered execution and a fault.\n\nStarting only from the fundamental facts that unsigned $b$-bit arithmetic is modulo $2^{b}$ and that two’s-complement interpretation maps $b$-bit patterns to the signed range $[-2^{b-1}, 2^{b-1} - 1]$, derive the largest integer value of $\\Delta t$ (in jiffies) that guarantees, for every possible wrap-around behavior of $J$, that the predicate remains false for all $n \\in \\{t, t+1, \\dots, E-1\\}$ and becomes true at $n = E$ (and stays true thereafter). Express your final bound as a closed-form analytic expression in terms of $b$. No rounding is required. Express the bound in jiffies.", "solution": "The problem asks for the largest positive integer value of a time delay $\\Delta t$ such that a timer scheduled at time $t$ for expiry at time $E \\equiv t + \\Delta t \\pmod{2^b}$ does not trigger prematurely. The system's time counter, $J$, is a $b$-bit unsigned integer, so all time arithmetic is performed modulo $2^b$.\n\nFirst, we must formalize the expiry predicate. The check is performed at a given time $n$. The difference $D$ is calculated as an unsigned $b$-bit integer:\n$$D_u \\equiv E - n \\pmod{2^b}$$\nThis $b$-bit integer pattern, representing an unsigned value $D_u \\in [0, 2^b-1]$, is then interpreted as a signed two's-complement integer $D_s \\in [-2^{b-1}, 2^{b-1}-1]$. The relationship between the unsigned value $D_u$ and the signed value $D_s$ is as follows:\n$$\nD_s =\n\\begin{cases}\nD_u & \\text{if } 0 \\le D_u < 2^{b-1} \\\\\nD_u - 2^b & \\text{if } 2^{b-1} \\le D_u < 2^b\n\\end{cases}\n$$\nThe predicate for \"at or past expiry\" is $D_s \\le 0$. Let's determine for which unsigned values $D_u$ this condition holds:\n1.  If $D_u \\in [1, 2^{b-1}-1]$, then $D_s = D_u > 0$. The predicate is false.\n2.  If $D_u = 0$, then $D_s = 0$. The predicate $D_s \\le 0$ is true.\n3.  If $D_u \\in [2^{b-1}, 2^b-1]$, then $D_s = D_u - 2^b$. The maximum value of $D_s$ in this range is $(2^b-1) - 2^b = -1$, and the minimum is $2^{b-1} - 2^b = -2^{b-1}$. In this case, $D_s \\le -1$. The predicate $D_s \\le 0$ is true.\n\nTherefore, the predicate \"at or past expiry\" is true if and only if the unsigned difference $D_u$ is in the range $[2^{b-1}, 2^b-1]$ or if $D_u=0$. Conversely, the predicate is false (\"not yet expired\") if and only if $D_u \\in [1, 2^{b-1}-1]$.\n\nThe problem requires finding the largest positive integer $\\Delta t$ that satisfies two conditions for any starting time $t$:\nCondition A: The predicate is false for all ticks $n$ in the sequence starting from $t$ up to, but not including, $E$. This sequence of ticks can be represented as $n_k = (t+k) \\pmod{2^b}$ for $k \\in \\{0, 1, 2, \\dots, \\Delta t-1\\}$.\nCondition B: The predicate is true for $n=E$ and all subsequent ticks.\n\nLet's analyze Condition A. For each $k \\in \\{0, 1, \\dots, \\Delta t-1\\}$, we must ensure the predicate is false. This means the unsigned difference $D_u$ must fall within the \"not yet expired\" range $[1, 2^{b-1}-1]$.\nThe unsigned difference for a tick $n_k = (t+k) \\pmod{2^b}$ is:\n$$D_u(k) \\equiv E - n_k \\pmod{2^b}$$\nSubstituting the definitions of $E$ and $n_k$:\n$$D_u(k) \\equiv \\left( (t+\\Delta t)\\pmod{2^b} - (t+k)\\pmod{2^b} \\right) \\pmod{2^b}$$\nUsing the property $(a-b)\\pmod{m} \\equiv (a\\pmod{m} - b\\pmod{m})\\pmod{m}$, we get:\n$$D_u(k) \\equiv (t+\\Delta t - (t+k)) \\pmod{2^b} \\equiv (\\Delta t - k) \\pmod{2^b}$$\nSo, for Condition A to hold, we require:\n$$(\\Delta t - k) \\pmod{2^b} \\in [1, 2^{b-1}-1] \\quad \\forall k \\in \\{0, 1, \\dots, \\Delta t-1\\}$$\nLet's analyze this constraint.\nIf we choose a value of $\\Delta t$ such that $\\Delta t \\ge 2^{b-1}$, we can find a value of $k$ that violates the condition. Consider $k=0$ (the moment of scheduling). The difference is $D_u(0) \\equiv \\Delta t \\pmod{2^b}$. If $2^{b-1} \\le \\Delta t < 2^b$, then $D_u(0) = \\Delta t$, which is in the \"expired\" range $[2^{b-1}, 2^b-1]$. This causes an immediate, premature expiry, which is the bug described.\nMore generally, for any $\\Delta t \\ge 2^{b-1}$, we must show that there exists a $k \\in \\{0, 1, \\dots, \\Delta t-1\\}$ that violates the condition. Let us choose $k$ such that $\\Delta t - k = 2^{b-1}$. This gives $k = \\Delta t - 2^{b-1}$. Since $\\Delta t \\ge 2^{b-1}$, we have $k \\ge 0$. Also, since $2^{b-1} > 0$, we have $k < \\Delta t$. So this value of $k$ is in the specified range. For this $k$, the difference is:\n$$D_u(k) = (\\Delta t - (\\Delta t-2^{b-1})) \\pmod{2^b} = 2^{b-1} \\pmod{2^b} = 2^{b-1}$$\nThis value $2^{b-1}$ is not in the \"not yet expired\" range $[1, 2^{b-1}-1]$. Therefore, any choice of $\\Delta t \\ge 2^{b-1}$ will lead to a premature expiry at tick $n = t + (\\Delta t - 2^{b-1})$. Thus, we must have $\\Delta t < 2^{b-1}$.\n\nNow, let's consider any positive integer $\\Delta t$ such that $\\Delta t \\le 2^{b-1}-1$.\nThe values of $\\Delta t - k$ for $k \\in \\{0, 1, \\dots, \\Delta t-1\\}$ form the sequence:\n$$\\Delta t, \\Delta t-1, \\dots, 2, 1$$\nSince $1 \\le \\Delta t \\le 2^{b-1}-1$, every term in this sequence is positive and less than $2^b$. Therefore, the modulo operation $(\\dots)\\pmod{2^b}$ has no effect. The sequence of differences $D_u(k)$ is simply $\\{\\Delta t, \\Delta t-1, \\dots, 1\\}$.\nFurthermore, since the maximum value in this sequence is $\\Delta t$, and we have constrained $\\Delta t \\le 2^{b-1}-1$, every value in the sequence lies in the range $[1, 2^{b-1}-1]$. This is exactly the \"not yet expired\" range.\nThus, if $1 \\le \\Delta t \\le 2^{b-1}-1$, Condition A is satisfied.\n\nNext, let's analyze Condition B. At the expiry tick, $n=E$. The difference is:\n$$D_u \\equiv E - E \\pmod{2^b} = 0$$\nThe signed interpretation is $D_s=0$. The predicate $D_s \\le 0$ is true. This holds for any $\\Delta t$. For ticks after expiry, e.g., $n = (E+j) \\pmod{2^b}$ for $j \\ge 1$:\n$$D_u \\equiv E - (E+j) \\pmod{2^b} = -j \\pmod{2^b}$$\nThe unsigned result will be in the range $[2^b-j, 2^b-1]$, which is in the \"expired\" region (unless $j$ is a large multiple of $2^b$, in which case the difference is $0$). So Condition B is always satisfied.\n\nCombining the constraints, the requirement for correct timer behavior is $1 \\le \\Delta t < 2^{b-1}$, or more precisely $1 \\le \\Delta t \\le 2^{b-1}-1$ since $\\Delta t$ must be an integer. The question asks for the largest such integer value of $\\Delta t$. This is the upper bound of the derived valid range.\n\nThe largest integer value of $\\Delta t$ is $2^{b-1}-1$.", "answer": "$$\n\\boxed{2^{b-1} - 1}\n$$", "id": "3686534"}, {"introduction": "Beyond correctness, system performance is paramount. A fundamental operation affecting performance is the scheduler's decision to migrate a thread between CPU cores. This practice [@problem_id:3686454] guides you to build a quantitative model for this migration overhead from first principles, accounting for the time it takes to rebuild the thread's state in the new core's cache and Translation Lookaside Buffer (TLB). By modeling this cost as a function of the thread's memory footprint, you will gain a concrete understanding of data locality and its profound impact on application speed.", "problem": "You are given the task of quantifying and modeling the overhead incurred by operating system scheduler thread migrations as a function of the thread’s cache footprint. The goal is to design a program that, for a small test suite of scenarios, computes the total migration overhead in nanoseconds, based on a model grounded in fundamental principles of hierarchical caches and coherent shared memory. This program must produce its output as a single line containing a comma-separated list enclosed in square brackets.\n\nA scheduler migration moves a running thread from one processor core to another, which invalidates the thread’s private cache residency. Under a hierarchical cache design with Level-1 (L1), Level-2 (L2), and shared Last Level Cache (LLC), we focus on the dominant cold-start overhead components after a migration. Assume the following principles and core definitions as the base of your derivation:\n\n- A cache line is the minimum unit of cache fill. Let the cache line size be $\\ell$ bytes.\n- The shared Last Level Cache (LLC) of size $S_3$ bytes can hold at most $\\left\\lfloor S_3 / \\ell \\right\\rfloor$ cache lines; if the thread’s working set footprint $C$ exceeds $S_3$, only $\\left\\lfloor S_3 / \\ell \\right\\rfloor$ lines can be supplied from LLC and the remainder must be fetched from main memory.\n- The Translation Lookaside Buffer (TLB) is per-core; a migration discards TLB state and requires refilling at least one TLB entry per distinct page touched. Let the page size be $P$ bytes.\n- Let the per-line refill cost from LLC be $t_{\\text{llc}}$ nanoseconds, and the per-line refill cost from main memory be $t_{\\text{mem}}$ nanoseconds. Let the per-page TLB reload cost be $t_{\\text{tlb}}$ nanoseconds. Let the fixed scheduler bookkeeping cost per migration be $t_{\\text{sched}}$ nanoseconds.\n\nYou must derive, from these base principles only, a model for the per-migration overhead $\\Delta M(C)$ that accounts for the number of cache lines that must be fetched from the LLC versus main memory, and the number of page translations that must be re-established in the destination core’s TLB. Use the following logical constraints when deriving your model:\n\n- The number of distinct cache lines implied by a footprint $C$ is $\\lceil C / \\ell \\rceil$.\n- The LLC can supply at most $\\left\\lfloor S_3 / \\ell \\right\\rfloor$ lines per migration; any additional required lines are fetched from main memory.\n- The number of pages implicated by the footprint is $\\lceil C / P \\rceil$.\n\nThen, for a given number of induced migrations $m$, the total overhead is $T(m, C)$, which you must compute for each test case.\n\nPhysical and numerical units requirement: Express your final outputs in nanoseconds as floating-point values rounded to two decimal places.\n\nYour program must implement the above and produce results for the test suite below. Use the specified parameters exactly as given. All sizes are in bytes, all time costs are in nanoseconds.\n\nConstants (same for all test cases):\n- Cache line size $\\ell = 64$.\n- LLC size $S_3 = 8{,}388{,}608$.\n- Page size $P = 4{,}096$.\n- Per-line LLC refill cost $t_{\\text{llc}} = 30$.\n- Per-line memory refill cost $t_{\\text{mem}} = 100$.\n- Per-page TLB reload cost $t_{\\text{tlb}} = 5$.\n- Per-migration scheduler bookkeeping cost $t_{\\text{sched}} = 1{,}500$.\n\nTest suite (each case specifies footprint $C$ and number of migrations $m$):\n- Case A (happy path, small footprint fitting in LLC): $C = 262{,}144$, $m = 10$.\n- Case B (large footprint exceeding LLC): $C = 33{,}554{,}432$, $m = 3$.\n- Case C (boundary condition, footprint exactly equal to LLC): $C = 8{,}388{,}608$, $m = 1$.\n- Case D (edge case, zero migrations): $C = 1{,}048{,}576$, $m = 0$.\n- Case E (edge case, footprint smaller than one cache line): $C = 32$, $m = 5$.\n\nFinal output format specification:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The $i$-th element must be the total migration overhead $T(m, C)$ for the $i$-th test case in nanoseconds, rounded to two decimal places. For example, the output should look like $[x_1,x_2,x_3,x_4,x_5]$ where each $x_i$ is a floating-point number.", "solution": "The user-provided problem has been analyzed and is determined to be **valid**. It is scientifically grounded in the principles of computer architecture, well-posed, objective, and contains sufficient information to derive a unique solution for each test case.\n\nThe objective is to derive a model for the total overhead, $T(m, C)$, incurred by $m$ scheduler migrations for a thread with a cache footprint of size $C$. This model will be based on the provided first principles of cache, memory, and TLB behavior.\n\nThe total overhead, $T(m, C)$, is the product of the number of migrations, $m$, and the per-migration overhead, $\\Delta M(C)$. If $m=0$, the total overhead is $0$. For $m > 0$:\n$$T(m, C) = m \\cdot \\Delta M(C)$$\n\nThe per-migration overhead $\\Delta M(C)$ is the sum of three distinct components as defined in the problem:\n$1$. A fixed scheduler bookkeeping cost, $t_{\\text{sched}}$.\n$2$. A variable cost for reloading the Translation Lookaside Buffer (TLB), which we denote as $\\text{Cost}_{\\text{TLB}}(C)$.\n$3$. A variable cost for refilling the processor caches, which we denote as $\\text{Cost}_{\\text{cache}}(C)$.\n\nThus, the per-migration overhead is:\n$$\\Delta M(C) = t_{\\text{sched}} + \\text{Cost}_{\\text{TLB}}(C) + \\text{Cost}_{\\text{cache}}(C)$$\n\nWe shall now derive the functional form for each variable component based on the provided principles.\n\nFirst, we model the TLB reload cost, $\\text{Cost}_{\\text{TLB}}(C)$. A migration invalidates the core's TLB. The cost is proportional to the number of distinct memory pages the thread's footprint occupies. Given a page size of $P$ bytes and a footprint of $C$ bytes, the number of pages, $N_P(C)$, is the ceiling of the ratio $C/P$.\n$$N_P(C) = \\left\\lceil \\frac{C}{P} \\right\\rceil$$\nWith a per-page reload cost of $t_{\\text{tlb}}$, the total TLB overhead is:\n$$\\text{Cost}_{\\text{TLB}}(C) = N_P(C) \\cdot t_{\\text{tlb}} = \\left\\lceil \\frac{C}{P} \\right\\rceil \\cdot t_{\\text{tlb}}$$\n\nSecond, we model the cache refill cost, $\\text{Cost}_{\\text{cache}}(C)$. A migration forces the new core to fetch the thread's working set into its local caches. The data is fetched in units of cache lines of size $\\ell$. The total number of unique cache lines required for a footprint $C$ is given by:\n$$N_L(C) = \\left\\lceil \\frac{C}{\\ell} \\right\\rceil$$\nThese lines are fetched either from the shared Last Level Cache (LLC) or from main memory. The LLC has a finite capacity. The maximum number of cache lines the LLC can hold is:\n$$N_{L3}^{\\text{max}} = \\left\\lfloor \\frac{S_3}{\\ell} \\right\\rfloor$$\nwhere $S_3$ is the size of the LLC in bytes.\n\nThe model distinguishes between two scenarios for sourcing these cache lines:\n- If the thread's required lines $N_L(C)$ do not exceed the LLC's capacity $N_{L3}^{\\text{max}}$, all lines are presumably resident in the LLC and are fetched from there.\n- If the required lines $N_L(C)$ exceed the LLC's capacity $N_{L3}^{\\text{max}}$, the LLC can only supply up to its capacity. The remaining lines must be fetched from the much slower main memory.\n\nWe can formalize this by defining the number of lines fetched from the LLC, $N_{\\text{from\\_llc}}(C)$, and from main memory, $N_{\\text{from\\_mem}}(C)$:\n$$N_{\\text{from\\_llc}}(C) = \\min\\left( N_L(C), N_{L3}^{\\text{max}} \\right)$$\n$$N_{\\text{from\\_mem}}(C) = N_L(C) - N_{\\text{from\\_llc}}(C) = \\max\\left(0, N_L(C) - N_{L3}^{\\text{max}}\\right)$$\n\nThe total cache refill cost is the sum of costs from both sources, using their respective per-line refill costs, $t_{\\text{llc}}$ and $t_{\\text{mem}}$:\n$$\\text{Cost}_{\\text{cache}}(C) = \\left( N_{\\text{from\\_llc}}(C) \\cdot t_{\\text{llc}} \\right) + \\left( N_{\\text{from\\_mem}}(C) \\cdot t_{\\text{mem}} \\right)$$\n\nCombining all components, the complete formula for the per-migration overhead $\\Delta M(C)$ is:\n$$\\Delta M(C) = t_{\\text{sched}} + \\left( \\left\\lceil \\frac{C}{P} \\right\\rceil \\cdot t_{\\text{tlb}} \\right) + \\left( \\min\\left(\\left\\lceil \\frac{C}{\\ell} \\right\\rceil, \\left\\lfloor \\frac{S_3}{\\ell} \\right\\rfloor\\right) \\cdot t_{\\text{llc}} \\right) + \\left( \\max\\left(0, \\left\\lceil \\frac{C}{\\ell} \\right\\rceil - \\left\\lfloor \\frac{S_3}{\\ell} \\right\\rfloor\\right) \\cdot t_{\\text{mem}} \\right)$$\n\nWe now apply this model to the test suite using the provided constants:\n- $\\ell = 64$ bytes\n- $S_3 = 8,388,608$ bytes\n- $P = 4,096$ bytes\n- $t_{\\text{llc}} = 30$ ns\n- $t_{\\text{mem}} = 100$ ns\n- $t_{\\text{tlb}} = 5$ ns\n- $t_{\\text{sched}} = 1,500$ ns\n\nFirst, we calculate the LLC capacity in cache lines:\n$$N_{L3}^{\\text{max}} = \\left\\lfloor \\frac{8,388,608}{64} \\right\\rfloor = \\lfloor 131,072 \\rfloor = 131,072 \\text{ lines}$$\n\n**Case A**: $C = 262,144$, $m = 10$\n- $N_L(C) = \\lceil 262,144 / 64 \\rceil = 4,096$ lines\n- $N_P(C) = \\lceil 262,144 / 4,096 \\rceil = 64$ pages\n- Since $N_L(C) \\le N_{L3}^{\\text{max}}$, all lines are from LLC.\n- $\\Delta M(C) = 1,500 + (64 \\cdot 5) + (4,096 \\cdot 30) = 1,500 + 320 + 122,880 = 124,700$ ns\n- $T(m, C) = 10 \\cdot 124,700 = 1,247,000$ ns\n\n**Case B**: $C = 33,554,432$, $m = 3$\n- $N_L(C) = \\lceil 33,554,432 / 64 \\rceil = 524,288$ lines\n- $N_P(C) = \\lceil 33,554,432 / 4,096 \\rceil = 8,192$ pages\n- Since $N_L(C) > N_{L3}^{\\text{max}}$, lines are from both LLC and memory.\n- $N_{\\text{from\\_llc}} = 131,072$; $N_{\\text{from\\_mem}} = 524,288 - 131,072 = 393,216$\n- $\\Delta M(C) = 1,500 + (8,192 \\cdot 5) + (131,072 \\cdot 30) + (393,216 \\cdot 100)$\n- $\\Delta M(C) = 1,500 + 40,960 + 3,932,160 + 39,321,600 = 43,296,220$ ns\n- $T(m, C) = 3 \\cdot 43,296,220 = 129,888,660$ ns\n\n**Case C**: $C = 8,388,608$, $m = 1$\n- $N_L(C) = \\lceil 8,388,608 / 64 \\rceil = 131,072$ lines\n- $N_P(C) = \\lceil 8,388,608 / 4,096 \\rceil = 2,048$ pages\n- Here $N_L(C) = N_{L3}^{\\text{max}}$, so all lines are from LLC.\n- $\\Delta M(C) = 1,500 + (2,048 \\cdot 5) + (131,072 \\cdot 30) = 1,500 + 10,240 + 3,932,160 = 3,943,900$ ns\n- $T(m, C) = 1 \\cdot 3,943,900 = 3,943,900$ ns\n\n**Case D**: $C = 1,048,576$, $m = 0$\n- Since $m = 0$, no migrations occur.\n- $T(m, C) = 0$ ns\n\n**Case E**: $C = 32$, $m = 5$\n- $N_L(C) = \\lceil 32 / 64 \\rceil = 1$ line\n- $N_P(C) = \\lceil 32 / 4,096 \\rceil = 1$ page\n- Since $N_L(C) \\le N_{L3}^{\\text{max}}$, all lines are from LLC.\n- $\\Delta M(C) = 1,500 + (1 \\cdot 5) + (1 \\cdot 30) = 1,500 + 5 + 30 = 1,535$ ns\n- $T(m, C) = 5 \\cdot 1,535 = 7,675$ ns\n\nThe final results, rounded to two decimal places, are: A: $1,247,000.00$, B: $129,888,660.00$, C: $3,943,900.00$, D: $0.00$, E: $7,675.00$.", "answer": "```c\n// The complete and compilable C program goes here.\n// Headers must adhere to the specified restrictions.\n#include <stdio.h>\n#include <stdlib.h>\n\n// A struct to hold the parameters for a single test case.\ntypedef struct {\n    long long C_footprint;\n    int m_migrations;\n} TestCase;\n\nint main(void) {\n    // Define the constants from the problem statement.\n    const long long L_CACHE_LINE_SIZE = 64;\n    const long long S3_LLC_SIZE = 8388608;\n    const long long P_PAGE_SIZE = 4096;\n    const double T_LLC_REFILL_NS = 30.0;\n    const double T_MEM_REFILL_NS = 100.0;\n    const double T_TLB_RELOAD_NS = 5.0;\n    const double T_SCHED_NS = 1500.0;\n\n    // Define the test cases from the problem statement.\n    TestCase test_cases[] = {\n        {262144, 10},       // Case A\n        {33554432, 3},      // Case B\n        {8388608, 1},       // Case C\n        {1048576, 0},       // Case D\n        {32, 5}             // Case E\n    };\n\n    // Calculate the number of test cases.\n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    double results[num_cases];\n\n    // Calculate the result for each test case.\n    for (int i = 0; i < num_cases; ++i) {\n        long long C = test_cases[i].C_footprint;\n        int m = test_cases[i].m_migrations;\n\n        // If there are no migrations, the overhead is zero.\n        if (m == 0) {\n            results[i] = 0.0;\n            continue;\n        }\n\n        // Calculate the number of cache lines and pages using integer arithmetic\n        // to correctly implement the ceiling function: ceil(a/b) == (a+b-1)/b for integers a,b > 0.\n        // For C=0, this is 0. C is >= 32 in our cases, so this is safe.\n        long long n_lines = (C > 0) ? (C + L_CACHE_LINE_SIZE - 1) / L_CACHE_LINE_SIZE : 0;\n        long long n_pages = (C > 0) ? (C + P_PAGE_SIZE - 1) / P_PAGE_SIZE : 0;\n        \n        // Calculate the LLC capacity in cache lines. S3_LLC_SIZE is a multiple of L_CACHE_LINE_SIZE,\n        // so integer division is equivalent to floor().\n        long long n_llc_cap = S3_LLC_SIZE / L_CACHE_LINE_SIZE;\n\n        // Determine how many lines are fetched from LLC vs. main memory.\n        long long lines_from_llc;\n        long long lines_from_mem;\n\n        if (n_lines <= n_llc_cap) {\n            lines_from_llc = n_lines;\n            lines_from_mem = 0;\n        } else {\n            lines_from_llc = n_llc_cap;\n            lines_from_mem = n_lines - n_llc_cap;\n        }\n        \n        // Calculate the total overhead for a single migration.\n        // All calculations are promoted to double to prevent overflow and maintain precision.\n        double per_migration_overhead = T_SCHED_NS +\n                                        (double)n_pages * T_TLB_RELOAD_NS +\n                                        (double)lines_from_llc * T_LLC_REFILL_NS +\n                                        (double)lines_from_mem * T_MEM_REFILL_NS;\n        \n        // Calculate total overhead for m migrations.\n        results[i] = (double)m * per_migration_overhead;\n    }\n\n    // Print the results in the EXACT REQUIRED format before the final return statement.\n    // The format is a single line, comma-separated list in brackets, with no trailing newline.\n    printf(\"[%.2f,%.2f,%.2f,%.2f,%.2f]\", results[0], results[1], results[2], results[3], results[4]);\n\n    return EXIT_SUCCESS;\n}\n```", "id": "3686454"}, {"introduction": "In modern multi-core systems, performance is often dictated not by the speed of a single core, but by the costs of coordination and synchronization between them. This exercise [@problem_id:3686443] delves into one such cost: the 'TLB shootdown,' a necessary process for maintaining memory consistency that can become a significant bottleneck under certain workloads. You will apply principles from queuing theory to model the total delay, including time spent waiting for other cores to respond and contention for shared locks, providing a powerful lens through which to analyze and predict performance in concurrent environments.", "problem": "You are given a scenario in which frequent memory map operations trigger Translation Lookaside Buffer (TLB) shootdowns across multiple processor cores. A TLB shootdown requires that all other cores receive an Inter-Processor Interrupt (IPI) and acknowledge the invalidation of TLB entries before the initiating thread can proceed. The goal is to design a workload model that isolates the time blocked due solely to the shootdown mechanism under frequent memory map operations across $n$ threads and compute the expected blocking time per operation, denoted as $T_{shootdown}$, in microseconds.\n\nBase assumptions and definitions to be used:\n- Translation Lookaside Buffer (TLB): a cache of virtual-to-physical address translations maintained per core.\n- Inter-Processor Interrupt (IPI): a mechanism used to interrupt other cores to perform actions such as invalidating TLB entries.\n- There are $C$ online cores. When a thread initiates a TLB shootdown, IPIs are sent to the other $C - 1$ cores.\n- The acknowledgment time from each target core is an independent exponential random variable with rate parameter $\\lambda$ (in per microsecond).\n- Each memory map operation invalidates $L$ pages locally on the initiating core, incurring per-page work of $t_p$ microseconds. There is also an IPI broadcast setup cost of $t_b$ microseconds.\n- Across $n$ threads, each performs memory map operations at a rate of $r$ operations per second. The global TLB shootdown is protected by a single global lock, so concurrent shootdowns are serialized as a single-server queue. Assume a Poisson arrival process for shootdown requests and exponential service time governed by the quantities above.\n\nYour tasks:\n1. From these assumptions, derive the expected service time per shootdown, expressed as a function of $C$, $\\lambda$, $L$, $t_p$, and $t_b$, without introducing any unstated shortcuts.\n2. Using a principled single-server queuing model based on the stated assumptions, derive the expected blocking time per operation, $T_{shootdown}$, as a function of the service time and the aggregate arrival rate generated by $n$ threads each issuing $r$ operations per second.\n\nUnits and output requirements:\n- Express $T_{shootdown}$ in microseconds, rounded to six decimal places.\n- Angles do not apply in this problem.\n- Percentages must be expressed in decimal form when relevant and should not use the percentage sign.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,...]\").\n\nTest suite:\nCompute $T_{shootdown}$ for the following parameter sets. For each test case, all time quantities ($t_b$, $t_p$) are in microseconds, and $\\lambda$ is in per microsecond. The outputs must be a list of floating-point values corresponding to $T_{shootdown}$ for each case, in the order provided below.\n\n- Case A (happy path): $n = 4$, $C = 8$, $r = 1000$, $L = 1$, $t_b = 3$, $t_p = 0.05$, $\\lambda = 0.1$.\n- Case B (near-saturation boundary): $n = 8$, $C = 32$, $r = 1700$, $L = 512$, $t_b = 3$, $t_p = 0.05$, $\\lambda = 0.1$.\n- Case C (single-thread edge case): $n = 1$, $C = 8$, $r = 100$, $L = 1$, $t_b = 3$, $t_p = 0.05$, $\\lambda = 0.1$.\n- Case D (large $n$ but small per-thread rate): $n = 64$, $C = 32$, $r = 100$, $L = 16$, $t_b = 3$, $t_p = 0.05$, $\\lambda = 0.1$.\n\nFinal output format:\n- Your program should produce exactly one line of output: a single list in the format \"[x1,x2,x3,x4]\" where each $x_i$ is the computed $T_{shootdown}$ for the corresponding case, expressed in microseconds and rounded to six decimal places.", "solution": "The goal is to compute the expected blocking time per memory map operation that arises solely from Translation Lookaside Buffer (TLB) shootdowns under a workload with $n$ threads issuing frequent memory map operations. We proceed by deriving the expected service time for a single shootdown and then incorporate queuing effects due to serialization under a global lock. The derivation is grounded in well-established principles: properties of exponential random variables and basic single-server queueing theory.\n\nStep $1$: Expected barrier time across $C - 1$ cores. When a shootdown is initiated, the initiating core sends Inter-Processor Interrupts (IPIs) to the other $C - 1$ cores and waits until all have acknowledged. Let the acknowledgment time from each target core be an independent exponential random variable with rate $\\lambda$ (per microsecond). Denote the acknowledgment times as $X_1, X_2, \\ldots, X_{C-1}$, with $X_i \\sim \\text{Exponential}(\\lambda)$ and independent. The barrier completes when the slowest acknowledgment arrives, which is the maximum $M = \\max\\{X_1, X_2, \\ldots, X_{C-1}\\}$.\n\nFor independent and identically distributed exponential random variables, the expected maximum has a known relation via order statistics. Let $m = C - 1$. The expected maximum is\n$$\n\\mathbb{E}[M] = \\frac{H_m}{\\lambda},\n$$\nwhere $H_m$ is the $m$-th harmonic number,\n$$\nH_m = \\sum_{k=1}^{m} \\frac{1}{k}.\n$$\nThis result follows from the decomposition of order statistics of exponential random variables: the spacings between sorted exponentials are independent exponential variables with rates $m\\lambda, (m-1)\\lambda, \\ldots, \\lambda$, so the mean of the maximum is the sum of the means of these spacings,\n$$\n\\mathbb{E}[M] = \\frac{1}{m\\lambda} + \\frac{1}{(m-1)\\lambda} + \\cdots + \\frac{1}{\\lambda} = \\frac{H_m}{\\lambda}.\n$$\n\nStep $2$: Non-barrier costs per shootdown. Besides waiting for acknowledgments, there are local costs:\n- An IPI broadcast setup cost $t_b$ (in microseconds).\n- Local invalidation cost $L \\cdot t_p$ (in microseconds), for $L$ pages at $t_p$ microseconds per page.\n\nTherefore, the expected service time $S$ (in microseconds) for a single shootdown is the sum of these components:\n$$\nS = t_b + L t_p + \\frac{H_{C-1}}{\\lambda}.\n$$\n\nStep $3$: Arrival rate across $n$ concurrent threads. Each of the $n$ threads issues memory map operations at rate $r$ operations per second, so the aggregate arrival rate is\n$$\n\\alpha = n r \\quad \\text{(operations per second)}.\n$$\nTo match the units of $S$ (microseconds), convert the arrival rate to operations per microsecond:\n$$\na = \\frac{\\alpha}{10^6} = \\frac{n r}{10^6}.\n$$\n\nStep $4$: Serialization under a global shootdown lock. The global shootdown lock serializes shootdowns, which can be modeled as a single-server queue. Under the assumptions of a Poisson arrival process (due to independent threads issuing operations) and exponential service times (as derived above), the queue is an $\\text{M}/\\text{M}/1$ system with service rate\n$$\n\\mu = \\frac{1}{S} \\quad \\text{(operations per microsecond)}.\n$$\nDefine the server utilization\n$$\n\\rho = \\frac{a}{\\mu} = a S.\n$$\nFor a stable system, one must have $\\rho < 1$. The expected time in the system (waiting plus service) for $\\text{M}/\\text{M}/1$ is\n$$\nW = \\frac{1}{\\mu - a}.\n$$\nThis can be rewritten in terms of $S$ and $\\rho$:\n$$\nW = \\frac{1}{\\frac{1}{S} - a} = \\frac{S}{1 - a S} = \\frac{S}{1 - \\rho}.\n$$\nThe quantity $W$ represents the expected blocking time experienced by a thread during shootdown, because the thread waits for the lock and service to complete before proceeding. Therefore, the desired shootdown overhead per operation is\n$$\nT_{shootdown} = W = \\frac{S}{1 - \\rho} = \\frac{t_b + L t_p + \\frac{H_{C-1}}{\\lambda}}{1 - \\left(\\frac{n r}{10^6}\\right)\\left(t_b + L t_p + \\frac{H_{C-1}}{\\lambda}\\right)}.\n$$\n\nStep $5$: Algorithmic computation. To compute $T_{shootdown}$ for each test case:\n- Compute the harmonic number $H_{C-1} = \\sum_{k=1}^{C-1} \\frac{1}{k}$.\n- Compute $S = t_b + L t_p + \\frac{H_{C-1}}{\\lambda}$.\n- Compute $a = \\frac{n r}{10^6}$.\n- Compute $\\rho = a S$ and verify $\\rho < 1$.\n- Compute $T_{shootdown} = \\frac{S}{1 - \\rho}$ in microseconds.\n- Round to six decimal places for output.\n\nStep $6$: Edge cases and boundaries. The happy path has moderate utilization ($\\rho$ well below $1$). The near-saturation boundary is chosen such that $\\rho$ is close to $1$, highlighting the nonlinear increase in $T_{shootdown}$ near saturation. The single-thread case yields minimal queuing ($\\rho \\ll 1$). The large $n$ but small per-thread rate case stresses cross-core effects while keeping the system stable ($\\rho < 1$).\n\nImplementing the above steps yields a straightforward numerical program that computes $T_{shootdown}$ for all provided test inputs and prints them in the required single-line format.", "answer": "```c\n// The complete and compilable C program goes here.\n// Headers must adhere to the specified restrictions.\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n// No other headers are used.\n\ntypedef struct {\n    int n_threads;   // n\n    int cores;       // C\n    double r_ops_s;  // r (ops per second)\n    int pages_L;     // L\n    double t_b_us;   // t_b (microseconds)\n    double t_p_us;   // t_p (microseconds per page)\n    double lambda_per_us; // lambda (per microsecond)\n} TestCase;\n\n// Compute harmonic number H_m = sum_{k=1}^m (1/k)\nstatic double harmonic_number(int m) {\n    if (m <= 0) return 0.0;\n    double h = 0.0;\n    for (int k = 1; k <= m; ++k) {\n        h += 1.0 / (double)k;\n    }\n    return h;\n}\n\nint main(void) {\n    TestCase test_cases[] = {\n        // Case A (happy path): n = 4, C = 8, r = 1000, L = 1, t_b = 3, t_p = 0.05, lambda = 0.1\n        {4, 8, 1000.0, 1, 3.0, 0.05, 0.1},\n        // Case B (near-saturation boundary): n = 8, C = 32, r = 1700, L = 512, t_b = 3, t_p = 0.05, lambda = 0.1\n        {8, 32, 1700.0, 512, 3.0, 0.05, 0.1},\n        // Case C (single-thread edge case): n = 1, C = 8, r = 100, L = 1, t_b = 3, t_p = 0.05, lambda = 0.1\n        {1, 8, 100.0, 1, 3.0, 0.05, 0.1},\n        // Case D (large n, small per-thread rate): n = 64, C = 32, r = 100, L = 16, t_b = 3, t_p = 0.05, lambda = 0.1\n        {64, 32, 100.0, 16, 3.0, 0.05, 0.1}\n    };\n\n    int num_cases = (int)(sizeof(test_cases) / sizeof(test_cases[0]));\n    double results[sizeof(test_cases) / sizeof(test_cases[0])];\n\n    for (int i = 0; i < num_cases; ++i) {\n        TestCase tc = test_cases[i];\n        // Harmonic number H_{C-1}\n        int m = tc.cores - 1;\n        double Hm = harmonic_number(m);\n\n        // Expected barrier time: Hm / lambda (microseconds)\n        double barrier_us = Hm / tc.lambda_per_us;\n\n        // Service time S (microseconds): t_b + L*t_p + barrier\n        double S_us = tc.t_b_us + (double)tc.pages_L * tc.t_p_us + barrier_us;\n\n        // Arrival rate per microsecond: a = (n * r) / 1e6\n        double a_per_us = ((double)tc.n_threads * tc.r_ops_s) / 1e6;\n\n        // Utilization rho = a * S\n        double rho = a_per_us * S_us;\n\n        // Stability check: rho must be less than 1.0; if not, we still compute as per formula,\n        // but in realistic terms, the queue would be unstable. Here, the given test cases ensure rho < 1.\n        // Expected blocking time (microseconds): T_shootdown = S / (1 - rho)\n        double T_shootdown_us;\n        if (rho >= 1.0) {\n            // In case of accidental instability, denote a very large number to indicate blow-up.\n            T_shootdown_us = INFINITY;\n        } else {\n            T_shootdown_us = S_us / (1.0 - rho);\n        }\n\n        results[i] = T_shootdown_us;\n    }\n\n    // Print the results in the EXACT REQUIRED format\n    // Single line: [x1,x2,x3,x4] with six decimal places\n    printf(\"[\");\n    for (int i = 0; i < num_cases; ++i) {\n        // Round to six decimal places\n        // Use \"%.6f\" formatting\n        printf(\"%.6f\", results[i]);\n        if (i + 1 < num_cases) {\n            printf(\",\");\n        }\n    }\n    printf(\"]\");\n\n    return EXIT_SUCCESS;\n}\n```", "id": "3686443"}]}