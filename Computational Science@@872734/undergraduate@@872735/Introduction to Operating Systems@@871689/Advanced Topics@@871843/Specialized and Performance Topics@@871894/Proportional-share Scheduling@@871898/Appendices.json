{"hands_on_practices": [{"introduction": "To build a solid understanding of proportional-share scheduling, we begin with one of its most important implementations: stride scheduling. This exercise challenges you to perform a manual simulation of a hierarchical scheduler, where different groups of tasks compete for the CPU. By meticulously tracking the `pass` and `stride` values at each level, you will gain a concrete understanding of how this deterministic algorithm enforces proportional fairness in a scenario mirroring modern containerized systems [@problem_id:3673648].", "problem": "Consider a single Central Processing Unit (CPU) running a hierarchical proportional-share scheduler. Two control groups (cgroups) $G_{1}$ and $G_{2}$ contend for the CPU; within each cgroup, tasks contend according to their per-task shares. The scheduler uses hierarchical stride scheduling to implement proportional sharing. At the cgroup level, the scheduler maintains a per-cgroup pass value and a per-cgroup stride. At each scheduling decision, it selects the cgroup with the smallest pass value (ties break in favor of the lower numerical cgroup index), then increments that cgroup’s pass by its stride. Within the selected cgroup, the scheduler maintains per-task pass values and per-task strides, selects the task with the smallest pass (ties break in favor of the lower numerical task index), and then increments that task’s pass by its stride. All pass values start at $0$.\n\nYou are given the following configuration:\n- Cgroup shares: $S_{G_{1}} = 3$, $S_{G_{2}} = 2$.\n- Per-task shares in $G_{1}$: task $T_{1}$ has $s_{1} = 2$, task $T_{2}$ has $s_{2} = 1$.\n- Per-task shares in $G_{2}$: task $T_{3}$ has $s_{3} = 1$, task $T_{4}$ has $s_{4} = 3$.\n\nThe hierarchical stride scheduling uses the following stride constants:\n- Global constant $K = 30$ for cgroups, yielding the cgroup strides $\\text{stride}(G_{i}) = \\frac{K}{S_{G_{i}}}$.\n- Cgroup-local constants $K_{1} = 12$ for $G_{1}$ and $K_{2} = 12$ for $G_{2}$, yielding per-task strides within each cgroup as $\\text{stride}(T_{j}) = \\frac{K_{g}}{s_{j}}$ where $K_{g}$ is the constant for the cgroup containing task $T_{j}$.\n\nThe global identifiers of tasks are defined as follows: $T_{1}$ has identifier $1$, $T_{2}$ has identifier $2$, $T_{3}$ has identifier $3$, and $T_{4}$ has identifier $4$.\n\nStarting from all pass values equal to $0$, compute the global identifier (an integer) of the task that is selected at the $11$-th scheduling decision. No rounding is required; provide the final integer identifier.", "solution": "The problem requires the determination of the task scheduled at the $11$-th decision point by a hierarchical proportional-share scheduler. The scheduling discipline is specified as hierarchical stride scheduling. The process is deterministic, governed by pass values and strides for both control groups (cgroups) and individual tasks.\n\nFirst, we must compute the stride values for all schedulable entities. The stride is inversely proportional to the share, calculated using a provided constant.\n\nThe cgroup shares are $S_{G_{1}} = 3$ and $S_{G_{2}} = 2$. The global constant for cgroups is $K = 30$. The stride for each cgroup, $\\text{stride}(G_i)$, is given by $\\frac{K}{S_{G_i}}$.\nThe stride for cgroup $G_1$ is:\n$$ \\text{stride}(G_{1}) = \\frac{K}{S_{G_{1}}} = \\frac{30}{3} = 10 $$\nThe stride for cgroup $G_2$ is:\n$$ \\text{stride}(G_{2}) = \\frac{K}{S_{G_{2}}} = \\frac{30}{2} = 15 $$\n\nNext, we compute the strides for the tasks within each cgroup.\nFor cgroup $G_1$, the tasks are $T_1$ with share $s_1 = 2$ and $T_2$ with share $s_2 = 1$. The cgroup-local constant is $K_1 = 12$. The stride for a task $T_j$ in this group is $\\frac{K_1}{s_j}$.\nThe stride for task $T_1$ is:\n$$ \\text{stride}(T_{1}) = \\frac{K_1}{s_{1}} = \\frac{12}{2} = 6 $$\nThe stride for task $T_2$ is:\n$$ \\text{stride}(T_{2}) = \\frac{K_1}{s_{2}} = \\frac{12}{1} = 12 $$\n\nFor cgroup $G_2$, the tasks are $T_3$ with share $s_3 = 1$ and $T_4$ with share $s_4 = 3$. The cgroup-local constant is $K_2 = 12$. The stride for a task $T_j$ in this group is $\\frac{K_2}{s_j}$.\nThe stride for task $T_3$ is:\n$$ \\text{stride}(T_{3}) = \\frac{K_2}{s_{3}} = \\frac{12}{1} = 12 $$\nThe stride for task $T_4$ is:\n$$ \\text{stride}(T_{4}) = \\frac{K_2}{s_{4}} = \\frac{12}{3} = 4 $$\n\nThe initial pass values for all cgroups and tasks are $0$. Let $P(X)$ denote the pass value of entity $X$.\nInitial state: $P(G_1) = 0$, $P(G_2) = 0$, $P(T_1) = 0$, $P(T_2) = 0$, $P(T_3) = 0$, $P(T_4) = 0$.\nWe now simulate the scheduling process for $11$ steps.\n\nStep $1$:\n- Cgroup selection: $P(G_1) = 0$ and $P(G_2) = 0$. Tie is broken by lower index, so $G_1$ is selected.\n- Task selection (in $G_1$): $P(T_1) = 0$ and $P(T_2) = 0$. Tie is broken by lower index, so $T_1$ is selected.\n- Scheduled: $T_1$.\n- Update pass values: $P(T_1) \\leftarrow P(T_1) + \\text{stride}(T_1) = 0 + 6 = 6$. $P(G_1) \\leftarrow P(G_1) + \\text{stride}(G_1) = 0 + 10 = 10$.\n\nStep $2$:\n- Cgroup selection: $P(G_1) = 10$, $P(G_2) = 0$. Select $G_2$.\n- Task selection (in $G_2$): $P(T_3) = 0$, $P(T_4) = 0$. Tie, select $T_3$.\n- Scheduled: $T_3$.\n- Update pass values: $P(T_3) \\leftarrow 0 + 12 = 12$. $P(G_2) \\leftarrow 0 + 15 = 15$.\n\nStep $3$:\n- Cgroup selection: $P(G_1) = 10$, $P(G_2) = 15$. Select $G_1$.\n- Task selection (in $G_1$): $P(T_1) = 6$, $P(T_2) = 0$. Select $T_2$.\n- Scheduled: $T_2$.\n- Update pass values: $P(T_2) \\leftarrow 0 + 12 = 12$. $P(G_1) \\leftarrow 10 + 10 = 20$.\n\nStep $4$:\n- Cgroup selection: $P(G_1) = 20$, $P(G_2) = 15$. Select $G_2$.\n- Task selection (in $G_2$): $P(T_3) = 12$, $P(T_4) = 0$. Select $T_4$.\n- Scheduled: $T_4$.\n- Update pass values: $P(T_4) \\leftarrow 0 + 4 = 4$. $P(G_2) \\leftarrow 15 + 15 = 30$.\n\nStep $5$:\n- Cgroup selection: $P(G_1) = 20$, $P(G_2) = 30$. Select $G_1$.\n- Task selection (in $G_1$): $P(T_1) = 6$, $P(T_2) = 12$. Select $T_1$.\n- Scheduled: $T_1$.\n- Update pass values: $P(T_1) \\leftarrow 6 + 6 = 12$. $P(G_1) \\leftarrow 20 + 10 = 30$.\n\nStep $6$:\n- Cgroup selection: $P(G_1) = 30$, $P(G_2) = 30$. Tie, select $G_1$.\n- Task selection (in $G_1$): $P(T_1) = 12$, $P(T_2) = 12$. Tie, select $T_1$.\n- Scheduled: $T_1$.\n- Update pass values: $P(T_1) \\leftarrow 12 + 6 = 18$. $P(G_1) \\leftarrow 30 + 10 = 40$.\n\nStep $7$:\n- Cgroup selection: $P(G_1) = 40$, $P(G_2) = 30$. Select $G_2$.\n- Task selection (in $G_2$): $P(T_3) = 12$, $P(T_4) = 4$. Select $T_4$.\n- Scheduled: $T_4$.\n- Update pass values: $P(T_4) \\leftarrow 4 + 4 = 8$. $P(G_2) \\leftarrow 30 + 15 = 45$.\n\nStep $8$:\n- Cgroup selection: $P(G_1) = 40$, $P(G_2) = 45$. Select $G_1$.\n- Task selection (in $G_1$): $P(T_1) = 18$, $P(T_2) = 12$. Select $T_2$.\n- Scheduled: $T_2$.\n- Update pass values: $P(T_2) \\leftarrow 12 + 12 = 24$. $P(G_1) \\leftarrow 40 + 10 = 50$.\n\nStep $9$:\n- Cgroup selection: $P(G_1) = 50$, $P(G_2) = 45$. Select $G_2$.\n- Task selection (in $G_2$): $P(T_3) = 12$, $P(T_4) = 8$. Select $T_4$.\n- Scheduled: $T_4$.\n- Update pass values: $P(T_4) \\leftarrow 8 + 4 = 12$. $P(G_2) \\leftarrow 45 + 15 = 60$.\n\nStep $10$:\n- Cgroup selection: $P(G_1) = 50$, $P(G_2) = 60$. Select $G_1$.\n- Task selection (in $G_1$): $P(T_1) = 18$, $P(T_2) = 24$. Select $T_1$.\n- Scheduled: $T_1$.\n- Update pass values: $P(T_1) \\leftarrow 18 + 6 = 24$. $P(G_1) \\leftarrow 50 + 10 = 60$.\n\nStep $11$:\n- Cgroup selection: $P(G_1) = 60$, $P(G_2) = 60$. Tie, select $G_1$.\n- Task selection (in $G_1$): $P(T_1) = 24$, $P(T_2) = 24$. Tie, select $T_1$.\n- Scheduled: $T_1$.\n\nThe task selected at the $11$-th scheduling decision is $T_1$. The problem asks for the global identifier of this task. The identifier for $T_1$ is given as $1$.", "answer": "$$ \\boxed{1} $$", "id": "3673648"}, {"introduction": "While the conceptual model of stride scheduling assumes infinitely growing `pass` values, real-world systems use finite-width integers, leading to inevitable wraparound. This practice explores a critical implementation challenge where a naive comparison of `pass` values can break fairness, incorrectly favoring a task whose accumulator has just overflowed. You will analyze different comparison strategies and identify a modulo-safe method that preserves the scheduler's correctness, a crucial lesson in robust system design [@problem_id:3673643].", "problem": "An Operating System (OS) uses a proportional-share scheduler on a single Central Processing Unit (CPU) that implements stride scheduling. Each process $i$ has a fixed positive integer stride $s_i$ and a non-decreasing accumulator $pass_i$ that is incremented by $s_i$ each time the process runs. At each selection step, the scheduler chooses the process whose $pass_i$ is minimal among all ready processes, then runs it for one time slice and updates its $pass_i := pass_i + s_i$. The accumulator $pass_i$ is stored in an $N$-bit unsigned integer and thus evolves under modular arithmetic with modulus $2^N$.\n\nFoundational facts:\n- Proportional-share fairness is achieved by selecting the process with the minimal aggregate service measure $pass_i$, because lower $pass_i$ indicates less service delivered so far on the scheduler’s scaled axis.\n- Fixed-width machine integers perform arithmetic modulo $2^N$: for any integers $x, y$, the machine-level sum is $(x + y) \\bmod 2^N$.\n\nConsider $N = 8$, so arithmetic is modulo $2^8 = 256$. Three processes $P_1, P_2, P_3$ have strides $s_1 = 60$, $s_2 = 30$, $s_3 = 20$. Immediately before a selection step, the accumulators are\n$$pass_1 = 240,\\quad pass_2 = 250,\\quad pass_3 = 245.$$\nSuppose the system had just scheduled $P_1$ in the previous step and updated $pass_1 := pass_1 + s_1$. Because $N = 8$, this update is\n$$pass_1 := (240 + 60) \\bmod 256 = 300 \\bmod 256 = 44.$$\nThus the state at the current selection step is\n$$pass_1 = 44,\\quad pass_2 = 250,\\quad pass_3 = 245.$$\n\nFrom first principles:\n- The intended order is the order of the true (conceptual) non-modular $pass$ values, but the machine stores only the residues modulo $2^N$.\n- A naive unsigned comparison that directly orders residues by the usual less-than on $\\{0,1,\\dots,2^N-1\\}$ can misorder values near wraparound and bias the scheduler, because a large true value just past the wrap (e.g., $300$) appears numerically small (e.g., $44$). Any correct comparison must respect modular arithmetic and two’s-complement representation in such a way that it reproduces the intended order of the underlying non-modular $pass$ values whenever pairwise differences are within the half-range.\n\nAssume the system is configured such that for any two concurrently ready processes $i$ and $j$, the true (non-modular) difference of their $pass$ values lies in $(-2^{N-1}, 2^{N-1})$, which is satisfied here because no single increment exceeds $2^{N-1}$ and updates occur frequently.\n\nWhich of the following option(s) both correctly address wraparound bias and, under the given state, identify the next process selected by a modulo-safe minimum comparator? Select all that apply.\n\nA. Use the usual unsigned less-than on $\\{0,\\dots,2^N-1\\}$: pick the process with the numerically smallest stored $pass_i$. Under the given state, this selects $P_1$ because $44$ is the smallest.\n\nB. Define the comparison $a \\prec b$ by computing $d := (a - b) \\bmod 2^N$ and interpreting $d$ as a signed two’s-complement integer in $\\{-2^{N-1},\\dots,2^{N-1}-1\\}$. Then $a \\prec b$ if and only if $d < 0$. Under the given state, this selects $P_3$.\n\nC. Define $a \\prec b$ if and only if the unsigned difference $(a - b)$ is less than $2^{N-1}$. Under the given state, this selects $P_1$.\n\nD. Eliminate wraparound by resetting all $pass_i := 0$ when any addition overflows, since lower values mean less service. Under the given state, the next selection should be the process with the smallest stride (i.e., $P_3$).\n\nE. Equivalently to a signed comparison, shift the origin by $2^{N-1}$: define $a \\prec b$ if and only if $((a + 2^{N-1}) \\bmod 2^N) < ((b + 2^{N-1}) \\bmod 2^N)$ using unsigned less-than. Under the given state, this selects $P_3$.", "solution": "We begin from core definitions of proportional-share stride scheduling and modular arithmetic on fixed-width integers.\n\n1. Proportional-share stride scheduling:\n- Each process $i$ has a stride $s_i \\in \\mathbb{N}$ and an accumulator $pass_i \\in \\mathbb{Z}$ conceptualizing total scaled service.\n- The scheduler selects the process with minimal $pass_i$, runs it for one slice, then sets $pass_i := pass_i + s_i$.\n- This mechanism yields allocations proportional to $1/s_i$ because smaller stride implies more frequent selection to keep $pass$ values close.\n\n2. Fixed-width integer arithmetic:\n- On hardware, $pass_i$ is stored as an $N$-bit unsigned integer, so all updates are computed modulo $2^N$.\n- Thus, for any update $pass_i := pass_i + s_i$, the stored value becomes $(pass_i + s_i) \\bmod 2^N$.\n- The set of stored values is the residue class ring $\\mathbb{Z}_{2^N}$.\n\n3. Ordering challenge at wraparound:\n- The intended schedule must order the conceptual, non-modular $pass$ values to find the minimum.\n- However, comparing residues naively can misorder values near wrap. For example, a conceptual value $300$ is stored as $44$ when $N=8$, since $300 \\equiv 44 \\pmod{256}$. Directly comparing $44$ and $250$ as unsigned numbers incorrectly claims $44$ is smaller, even though $300 > 250$ in the non-modular sense.\n\n4. A modulo-safe comparator:\n- In two’s-complement arithmetic, signed integers represent residues $\\{0,\\dots,2^{N-1}-1\\}$ as non-negative and $\\{2^{N-1},\\dots,2^N-1\\}$ as negative values offset by $2^N$.\n- For two residues $a, b \\in \\mathbb{Z}_{2^N}$ that encode conceptual values whose true difference $(a - b)_{\\text{true}}$ lies in $(-2^{N-1}, 2^{N-1})$, the signed two’s-complement interpretation of $d := (a - b) \\bmod 2^N$ recovers the sign of $(a - b)_{\\text{true}}$:\n  - If $(a - b)_{\\text{true}} > 0$, then $d \\in \\{1,\\dots,2^{N-1}-1\\}$, which as signed is $d > 0$.\n  - If $(a - b)_{\\text{true}} < 0$, then $d \\in \\{2^{N-1}+1,\\dots,2^N-1\\}$, which as signed is $d - 2^N < 0$.\n- Therefore, defining $a \\prec b$ if and only if the signed interpretation of $d$ is negative reproduces the correct order of the non-modular values within the half-range window. Equivalently, adding $2^{N-1}$ to both operands and comparing as unsigned realizes the same signed ordering, because adding $2^{N-1}$ rotates the circle so that the sign bit becomes the most significant bit that flips order appropriately.\n\nApplying these principles to the given state:\n- The state after the prior update is $pass_1 = 44$, $pass_2 = 250$, $pass_3 = 245$, with the conceptual non-modular values being $pass_1^{\\ast} = 300$, $pass_2^{\\ast} = 250$, $pass_3^{\\ast} = 245$ (for the current epoch). The intended minimum is $pass_3^{\\ast} = 245$, because $245 < 250 < 300$.\n\nLet us test each option.\n\nOption A:\n- Proposal: use unsigned less-than on residues. Under this rule, we compare $44$, $250$, $245$ directly and pick $44$ (i.e., $P_1$).\n- Analysis: This contradicts the intended order, because $pass_1^{\\ast} = 300$ is larger than both $250$ and $245$. Wraparound causes $300 \\equiv 44 \\pmod{256}$, and the naive comparator sees $44$ as the smallest, which biases selection toward recently wrapped accumulators.\n- Verdict: Incorrect. It demonstrates the biased behavior rather than correcting it, and the chosen process $P_1$ is not the correct minimal under the intended conceptual order.\n\nOption B:\n- Proposal: compute $d := (a - b) \\bmod 2^N$ and interpret $d$ as signed; declare $a \\prec b$ iff $d < 0$.\n- First, compare $pass_1$ and $pass_2$: $d = (44 - 250) \\bmod 256 = (-206) \\bmod 256 = 50$. As an $8$-bit signed integer, $50$ is positive, so $pass_1 \\succ pass_2$ (i.e., $pass_1$ is larger).\n- Next, compare $pass_2$ and $pass_3$: $d = (250 - 245) \\bmod 256 = 5$, signed positive, so $pass_2 \\succ pass_3$.\n- Consequently, $pass_3$ is minimal, and the scheduler selects $P_3$.\n- This matches the conceptual minima: $245 < 250 < 300$, and all pairwise differences ($60$, $5$, $55$) lie within the half-range $(-128, 128)$.\n- Verdict: Correct. The comparator is modulo-safe and yields the correct next selection $P_3$.\n\nOption C:\n- Proposal: $a \\prec b$ iff the unsigned difference $(a - b)$ is less than $2^{N-1}$.\n- Test $pass_1$ vs $pass_2$: Compute $(a - b)$ as unsigned, $(44 - 250) \\bmod 256 = 50$, which is less than $128$, so the rule declares $44 \\prec 250$ and would favor $P_1$ as smaller than $P_2$.\n- But the conceptual order has $300 > 250$, so $P_1$ should not be considered smaller than $P_2$.\n- This formulation flips the desired relation for differences that are within the half-range. The condition $(a - b) < 2^{N-1}$ characterizes proximity, not order direction; it cannot distinguish whether $a$ is before or after $b$ in the linearized order without considering the sign.\n- Verdict: Incorrect. The criterion misclassifies the direction and selects $P_1$, which is wrong.\n\nOption D:\n- Proposal: reset all $pass_i := 0$ on overflow to avoid wrap complications, and then select by smallest stride.\n- Analysis: Resetting accumulators discards the history of service and thus destroys proportional-share fairness. The scheduler should not select by smallest stride; it should select by minimal $pass_i$ to preserve the invariant that accumulated service balances across processes according to their shares. Moreover, resetting all $pass_i$ to $0$ would create artificial ties and biases unrelated to the true service delivered. Even if one tried to reconstruct an order from stride magnitudes, that does not correspond to least service and would drive the system away from fair proportions.\n- Verdict: Incorrect. The proposed mechanism is not modulo-safe, violates first principles of stride scheduling, and the asserted next selection based on smallest stride is unfounded.\n\nOption E:\n- Proposal: shift both operands by $2^{N-1}$ and compare as unsigned: $a \\prec b$ iff $((a + 2^{N-1}) \\bmod 2^N) < ((b + 2^{N-1}) \\bmod 2^N)$.\n- This is equivalent to a signed comparison because adding $2^{N-1}$ maps the signed range $\\{-2^{N-1},\\dots,2^{N-1}-1\\}$ to the unsigned range $\\{0,\\dots,2^N-1\\}$ while preserving order.\n- Compute transformed values: for $N=8$, $2^{N-1} = 128$. We get\n  $$f(pass_1) = (44 + 128) \\bmod 256 = 172,$$\n  $$f(pass_2) = (250 + 128) \\bmod 256 = 378 \\bmod 256 = 122,$$\n  $$f(pass_3) = (245 + 128) \\bmod 256 = 373 \\bmod 256 = 117.$$\n- Comparing $f(pass_i)$ as unsigned yields $117 < 122 < 172$, so the minimal is $f(pass_3)$, hence $pass_3$ is minimal and $P_3$ is selected.\n- This matches the result from Option B and the conceptual minima.\n- Verdict: Correct. The method is modulo-safe and selects $P_3$.\n\nConclusion:\n- Options B and E are correct because they express modulo-safe comparisons that respect two’s-complement arithmetic and correctly identify $P_3$ as the next process. Options A, C, and D are incorrect: A illustrates the bias, C confuses magnitude with order direction, and D breaks the fairness principle by discarding accumulated service.", "answer": "$$\\boxed{BE}$$", "id": "3673643"}, {"introduction": "Beyond stride scheduling, other mechanisms like virtual runtime are used to implement proportional sharing, most notably in the Linux Completely Fair Scheduler (CFS). This practice moves from algorithmic mechanics to the core principles of fairness by presenting a conceptually flawed scheduler. You will diagnose a bug where virtual runtime is advanced based on wall-clock time instead of actual CPU usage, leading to severe fairness violations, and identify the fundamental correction required to restore the scheduler's integrity [@problem_id:3673692].", "problem": "An operating system scheduler intended to implement proportional-share scheduling maintains, for each thread $i$, a quantity called virtual runtime $v_i(t)$ and always selects the thread with the smallest $v_i(t)$ to run next. The design goal of proportional-share scheduling is that, when a set of threads are runnable, each thread $i$ receives a fraction of processor service proportional to a positive weight $w_i$, meaning that for any pair of runnable threads $i$ and $j$, the ratio of their accumulated processor service $S_i$ and $S_j$ over any sufficiently long interval satisfies $S_i/S_j = w_i/w_j$. A correctness invariant consistent with this goal is that the change in $v_i(t)$ over an interval should be a monotone function of the processor time actually consumed by thread $i$, scaled according to its weight, and should not increase while the thread is not executing on a processor.\n\nConsider two threads, $T_A$ and $T_B$, with weights $w_A = 2$ and $w_B = 1$. Over a wall-clock interval of length $T > 0$, thread $T_B$ is blocking for input/output for a fraction $p = 1/2$, making it runnable only for a total of $(1-p)T$ wall-clock time, while thread $T_A$ is continuously runnable. The scheduler has a bug: it updates each thread’s $v_i(t)$ using wall-clock time even when the thread is not running. Assume that $v_A(0) = v_B(0) = 0$.\n\nBased on the goal and invariant stated above, answer the following:\n\n- Under correct proportional-share accounting, compute the total processor service $S_A$ and $S_B$ each thread should receive over the interval $[0,T]$, and qualitatively describe how $v_A(T)$ and $v_B(T)$ should compare at $t = T$.\n- Under the buggy implementation that advances $v_i(t)$ using wall-clock time regardless of whether thread $i$ is running, compute $\\Delta v_A$ and $\\Delta v_B$ over $[0,T]$, and qualitatively describe how this affects the ordering of $v_A(T)$ and $v_B(T)$ and the resulting share when $T_B$ becomes runnable again.\n\nWhich of the following changes both identifies the root cause of the skew and is the minimal correction that restores proportional-share fairness while preserving the monotonicity of $v_i(t)$?\n\nA. Replace wall-clock accounting with per-thread on-CPU execution accounting: update $v_i$ only when thread $i$ is actually executing, by adding an amount proportional to the thread’s own consumed processor time and inversely related to $w_i$, i.e., $v_i \\leftarrow v_i + \\text{(on-CPU time of } i\\text{)} \\times f(w_i)$ for some fixed normalization function $f$ consistent with proportional-share fairness.\n\nB. Keep using wall-clock time for updates, but on wake-up subtract the thread’s sleep duration scaled by its weight from $v_i$, i.e., $v_i \\leftarrow v_i - \\text{(sleep time)} \\times g(w_i)$ for a suitable function $g$.\n\nC. Scale all virtual runtime increments by the number of runnable threads at each instant, i.e., $v_i \\leftarrow v_i + n_{\\text{runnable}} \\times \\text{(wall-clock increment)} \\times h(w_i)$ for some function $h$, so that $v_i$ grows faster when more threads are present.\n\nD. Freeze $v_i$ for any thread that performs input/output during $[0,T]$ so that it does not advance even when other threads run, thereby favoring interactive threads upon wake-up.\n\nSelect the single best option.", "solution": "The problem requires an analysis of a proportional-share scheduler, first under an ideal implementation and then under a buggy one, and finally to identify the correct fix for the bug.\n\n### Problem Validation\n\nThe problem statement describes a proportional-share scheduler using virtual runtime, a standard concept in operating systems (e.g., related to the Linux Completely Fair Scheduler). All givens are clearly defined: weights $w_A=2$ and $w_B=1$, thread behaviors (one CPU-bound, one I/O-bound with $p=1/2$), the nature of the bug (using wall-clock time instead of execution time), and initial conditions ($v_A(0)=v_B(0)=0$). The questions posed are specific and answerable based on these givens. The problem is scientifically grounded in computer science, well-posed, and objective. It contains no contradictions or ambiguities that would prevent a rigorous analysis. Therefore, the problem is valid.\n\n### Solution Derivation\n\nLet $S_i$ be the processor service time for thread $T_i$, and $v_i$ be its virtual runtime. The weights are $w_A=2$ and $w_B=1$. The total wall-clock interval is $T$. Thread $T_A$ is always runnable. Thread $T_B$ is runnable for a duration of $(1-p)T = (1-1/2)T = T/2$ and blocking for a duration of $pT = T/2$.\n\n**1. Correct Proportional-Share Accounting**\n\nUnder a correct implementation, processor time is shared according to weights only among the set of *runnable* threads.\n\n*   **Intervals where only $T_A$ is runnable:** This occurs when $T_B$ is blocking, which accounts for a total duration of $T/2$. During this time, $T_A$ receives $100\\%$ of the processor service. Thus, $T_A$ accumulates $T/2$ of service time.\n*   **Intervals where both $T_A$ and $T_B$ are runnable:** This has a total duration of $T/2$. During this time, they share the CPU according to their weights. The total weight is $w_A + w_B = 2 + 1 = 3$.\n    *   $T_A$'s fraction of service: $w_A / (w_A + w_B) = 2/3$.\n    *   $T_B$'s fraction of service: $w_B / (w_A + w_B) = 1/3$.\n    *   Processor service for $T_A$ in this period: $(2/3) \\times (T/2) = T/3$.\n    *   Processor service for $T_B$ in this period: $(1/3) \\times (T/2) = T/6$.\n\n*   **Total Processor Service over $[0, T]$:**\n    *   For $T_A$: $S_A = (\\text{service while } T_B \\text{ blocked}) + (\\text{service while both runnable}) = T/2 + T/3 = 5T/6$.\n    *   For $T_B$: $S_B = 0 + (\\text{service while both runnable}) = T/6$.\n    *   The total CPU utilization is $S_A + S_B = 5T/6 + T/6 = T$, which is correct as the CPU is always busy.\n\n*   **Comparison of Virtual Runtimes $v_A(T)$ and $v_B(T)$:**\n    A standard implementation of virtual runtime updates it as $\\Delta v_i = \\Delta S_i / w_i$. The invariant states that $v_i$ should not increase when the thread is not executing. When $T_B$ blocks, its $v_B$ is frozen. Meanwhile, $T_A$ runs and its $v_A$ increases. When $T_B$ becomes runnable again, it will have a much smaller virtual runtime ($v_B \\ll v_A$). A fair scheduler will then give $T_B$ priority to let it \"catch up\". The goal of the scheduler is to keep the virtual runtimes of all *runnable* threads approximately equal. Therefore, at the end of a sufficiently long interval $T$, after periods of blocking and catching up have occurred, a well-behaved scheduler should have driven the system toward a state where the virtual runtimes of the threads are balanced. Thus, qualitatively, we expect $v_A(T) \\approx v_B(T)$.\n\n**2. Buggy Implementation Analysis**\n\nThe bug is that $v_i(t)$ is updated using wall-clock time, even when thread $i$ is not running. The update is inversely proportional to the weight. We can model the rate of change as $dv_i/dt \\propto 1/w_i$.\n\n*   Over the interval $[0, T]$, both threads exist for the full duration of wall-clock time $T$.\n*   Let the change in virtual time be $\\Delta v_i = (\\text{wall-clock time}) / w_i$.\n*   Change in $v_A$: $\\Delta v_A = v_A(T) - v_A(0) = T/w_A = T/2$.\n*   Change in $v_B$: $\\Delta v_B = v_B(T) - v_B(0) = T/w_B = T/1 = T$.\n*   Therefore, at time $T$, we have $v_B(T) = v_B(0) + T = T$ and $v_A(T) = v_A(0) + T/2 = T/2$.\n\n*   **Effect on Scheduling:** The scheduler always selects the thread with the smallest $v_i(t)$. Since $v_A(t)$ increases at half the rate of $v_B(t)$ (i.e., $dv_A/dt = (1/2) dv_B/dt$), and they start at $v_A(0)=v_B(0)=0$, it will always be the case that $v_A(t) < v_B(t)$ for all $t > 0$. Consequently, the scheduler will *always* select thread $T_A$ to run, as long as it is runnable. Since $T_A$ is continuously runnable, it will receive $100\\%$ of the processor service, i.e., $S_A=T$ and $S_B=0$. This bug leads to the complete starvation of thread $T_B$, utterly failing the proportional-share goal. The high weight of $T_A$ paradoxically gives it an advantage, while the low weight of $T_B$—combined with its I/O activity—causes its virtual time to accumulate so rapidly that it never gets a chance to run.\n\n### Option-by-Option Analysis\n\nThe root cause of the bug is that virtual runtime, which should represent weighted CPU consumption, is instead being tied to the passage of wall-clock time. This incorrectly penalizes threads for time spent not running (either blocked or simply preempted).\n\n**A. Replace wall-clock accounting with per-thread on-CPU execution accounting...**\nThis option proposes to update $v_i$ only when thread $i$ executes, with an increment proportional to its consumed CPU time ($\\Delta S_i$) and inversely proportional to its weight ($w_i$). This is expressed as $v_i \\leftarrow v_i + \\Delta S_i \\times f(w_i)$ where $f(w_i) \\propto 1/w_i$. This is the canonical, correct implementation of virtual runtime for proportional-share scheduling. It ensures that a thread's virtual time only advances when it actually uses the processor, directly fixing the bug. This change is minimal as it replaces the incorrect time source (wall-clock) with the correct one (on-CPU time). It also preserves monotonicity, as CPU time consumed ($S_i$) is a non-decreasing quantity.\n**Verdict: Correct.**\n\n**B. Keep using wall-clock time for updates, but on wake-up subtract the thread’s sleep duration scaled by its weight...**\nThis option suggests patching the bug by \"refunding\" the virtual time accumulated during sleep. While this might partially address the issue for I/O-bound threads, it has two major flaws. First, it violates the stated invariant that the change in $v_i(t)$ should be a monotone function; subtracting a value makes $v_i(t)$ non-monotonic. Second, it does not fix the underlying problem that wall-clock time is used for accounting. When both $T_A$ and $T_B$ are runnable, their virtual times would still increase based on wall-clock time, meaning $v_B$ still increases faster than $v_A$ regardless of who is running, leading to starvation of $T_B$. It is not a complete fix.\n**Verdict: Incorrect.**\n\n**C. Scale all virtual runtime increments by the number of runnable threads at each instant...**\nThis option proposes adding another scaling factor, $n_{\\text{runnable}}$, but retains the fundamental flaw of using wall-clock time. A thread's virtual runtime would still increase even when it is not on the CPU. For instance, while $T_B$ is blocked, $n_{\\text{runnable}}=1$, and both $v_A$ and $v_B$ would increase based on wall-clock time, which is exactly the behavior that causes the problem for $T_B$. This modification does not address the root cause.\n**Verdict: Incorrect.**\n\n**D. Freeze $v_i$ for any thread that performs input/output...**\nThis option correctly identifies that a thread's virtual runtime should not advance while it is blocked for I/O. However, this is an incomplete fix. Like option B, it fails to address the case where multiple threads are runnable. The buggy scheduler would still use wall-clock time to advance the virtual runtimes of all runnable threads simultaneously, even those not currently executing. This would still cause the starvation of runnable threads with lower weights, as described in the buggy analysis. The minimal and complete correction must base virtual time updates on *actual execution*, not just filter out I/O periods.\n**Verdict: Incorrect.**\n\nIn summary, Option A is the only one that correctly identifies the root cause—the use of wall-clock time—and proposes the minimal, complete correction that restores fairness by basing virtual time on actual CPU execution time, consistent with the fundamental principles of proportional-share schedulers.", "answer": "$$\\boxed{A}$$", "id": "3673692"}]}