{"hands_on_practices": [{"introduction": "In an embedded system running a Real-Time Operating System (RTOS), the ability to preempt one task for another is not instantaneous. This exercise [@problem_id:3638732] demonstrates how to quantify the CPU time consumed by these context switches. By analyzing a real-time schedule and using empirical performance data, you will calculate the total OS overhead, a fundamental skill for capacity planning and performance optimization in resource-constrained environments.", "problem": "An embedded controller running a preemptive fixed-priority Real-Time Operating System (RTOS) on a Central Processing Unit (CPU) provides a cycle counter that increments once per core clock cycle. The cycle counter can be read in software immediately before and after a context switch to empirically determine the number of cycles spent in the operating system during a switch of the running thread. Measurements on this platform reveal two repeatable regimes for the per-switch cycle count: a cache-hot path of $c_{h} = 420$ cycles and a cache-cold path of $c_{c} = 900$ cycles. In steady-state operation, the cache-hot path occurs with probability $p_{h} = 0.75$ and the cache-cold path with probability $p_{c} = 0.25$. The CPU clock frequency is $f_{\\mathrm{clk}} = 168 \\times 10^{6}\\ \\mathrm{Hz}$. Assume that each change in the identity of the running task, including transitions to or from the idle task, incurs exactly one context switch whose cost is distributed as above. Ignore all other sources of overhead.\n\nA set of three independent periodic tasks is scheduled by rate-monotonic priority assignment (shorter period implies higher priority). Their periods and worst-case execution times (exclusive of operating system overhead) are:\n- Task $\\tau_{1}$ with period $T_{1} = 2\\,\\mathrm{ms}$ and execution time $C_{1} = 0.2\\,\\mathrm{ms}$,\n- Task $\\tau_{2}$ with period $T_{2} = 5\\,\\mathrm{ms}$ and execution time $C_{2} = 0.7\\,\\mathrm{ms}$,\n- Task $\\tau_{3}$ with period $T_{3} = 10\\,\\mathrm{ms}$ and execution time $C_{3} = 1.6\\,\\mathrm{ms}$.\n\nAssume fully preemptive scheduling, tickless operation (dispatches occur only on job releases that preempt the current task or on job completions), and worst-case synchronous releases at time $t = 0$ for all tasks. The idle task is always ready at the lowest priority.\n\nUsing only the fundamental relationships that (i) time equals cycles divided by frequency and (ii) processor utilization over an interval equals the fraction of that interval spent executing, determine the expected fraction of processor time within one hyperperiod spent performing context switches under the above schedule. Express your final answer as a decimal fraction without a percent sign, and round your answer to four significant figures.", "solution": "The user wants to determine the expected fraction of processor time spent on context switches. This quantity, which we can denote as $U_{sw}$, is defined as the total expected time spent on context switches over a characteristic interval, divided by the duration of that interval. For a set of periodic tasks, the characteristic interval is the hyperperiod, $H$.\n\nThe total expected time for context switches is the product of the number of context switches within the hyperperiod, $N_{sw}$, and the expected time for a single context switch, $E[T_{sw}]$.\n$$U_{sw} = \\frac{N_{sw} \\times E[T_{sw}]}{H}$$\n\nThe solution is structured as follows:\n1.  Calculate the expected time for a single context switch, $E[T_{sw}]$.\n2.  Determine the hyperperiod, $H$.\n3.  Determine the number of context switches, $N_{sw}$, within one hyperperiod by simulating the schedule.\n4.  Combine these values to calculate the final fraction $U_{sw}$.\n\n**1. Expected Time per Context Switch, $E[T_{sw}]$**\n\nThe problem provides the cycle counts for two types of context switches: a cache-hot path ($c_{h}$) and a cache-cold path ($c_{c}$), along with their respective probabilities of occurrence, $p_{h}$ and $p_{c}$.\nGiven values:\n-   $c_{h} = 420$ cycles\n-   $c_{c} = 900$ cycles\n-   $p_{h} = 0.75$\n-   $p_{c} = 0.25$\n\nThe expected number of cycles per context switch, $E[C_{sw}]$, is the weighted average:\n$$E[C_{sw}] = c_{h} p_{h} + c_{c} p_{c}$$\n$$E[C_{sw}] = (420 \\times 0.75) + (900 \\times 0.25) = 315 + 225 = 540 \\text{ cycles}$$\n\nThe CPU clock frequency is given as $f_{\\mathrm{clk}} = 168 \\times 10^{6}\\ \\mathrm{Hz}$. The expected time for a single context switch, $E[T_{sw}]$, is the expected number of cycles divided by the clock frequency:\n$$E[T_{sw}] = \\frac{E[C_{sw}]}{f_{\\mathrm{clk}}} = \\frac{540}{168 \\times 10^{6}} \\text{ s}$$\n\n**2. Hyperperiod, $H$**\n\nThe hyperperiod is the least common multiple (LCM) of the task periods.\nGiven periods:\n-   $T_{1} = 2\\,\\mathrm{ms}$\n-   $T_{2} = 5\\,\\mathrm{ms}$\n-   $T_{3} = 10\\,\\mathrm{ms}$\n\n$$H = \\mathrm{lcm}(T_{1}, T_{2}, T_{3}) = \\mathrm{lcm}(2, 5, 10) = 10\\,\\mathrm{ms}$$\n\n**3. Number of Context Switches in the Hyperperiod, $N_{sw}$**\n\nThe scheduling is rate-monotonic, so priority is assigned inversely to the period: Priority($\\tau_{1}$) > Priority($\\tau_{2}$) > Priority($\\tau_{3}$). The scheduling is preemptive, and all tasks are released synchronously at $t=0$. We must trace the execution over the hyperperiod ($0$ to $10\\,\\mathrm{ms}$) to count the context switches. A context switch occurs each time the identity of the running task changes.\n\n-   $t=0$: All tasks are released. The idle task is preempted by $\\tau_{1}$ (highest priority). **Switch 1**: Idle $\\rightarrow \\tau_{1}$.\n-   $t=0.2\\,\\mathrm{ms}$: $\\tau_{1}$ (job 1) completes ($C_{1}=0.2\\,\\mathrm{ms}$). $\\tau_{2}$ is the highest priority ready task. **Switch 2**: $\\tau_{1} \\rightarrow \\tau_{2}$.\n-   $t=0.9\\,\\mathrm{ms}$: $\\tau_{2}$ (job 1) completes ($C_{2}=0.7\\,\\mathrm{ms}$). $\\tau_{3}$ is the highest priority ready task. **Switch 3**: $\\tau_{2} \\rightarrow \\tau_{3}$.\n-   $t=2.0\\,\\mathrm{ms}$: A new job of $\\tau_{1}$ is released. It preempts the running task $\\tau_{3}$. **Switch 4**: $\\tau_{3} \\rightarrow \\tau_{1}$.\n-   $t=2.2\\,\\mathrm{ms}$: $\\tau_{1}$ (job 2) completes. $\\tau_{3}$ (which was preempted) is the highest priority ready task and resumes. **Switch 5**: $\\tau_{1} \\rightarrow \\tau_{3}$.\n-   $t=2.7\\,\\mathrm{ms}$: $\\tau_{3}$ completes. It ran for $1.1\\,\\mathrm{ms}$ before preemption and $0.5\\,\\mathrm{ms}$ after, totaling $C_{3}=1.6\\,\\mathrm{ms}$. No tasks are ready. The idle task runs. **Switch 6**: $\\tau_{3} \\rightarrow$ Idle.\n-   $t=4.0\\,\\mathrm{ms}$: A new job of $\\tau_{1}$ is released. It preempts the idle task. **Switch 7**: Idle $\\rightarrow \\tau_{1}$.\n-   $t=4.2\\,\\mathrm{ms}$: $\\tau_{1}$ (job 3) completes. The idle task runs. **Switch 8**: $\\tau_{1} \\rightarrow$ Idle.\n-   $t=5.0\\,\\mathrm{ms}$: A new job of $\\tau_{2}$ is released. It preempts the idle task. **Switch 9**: Idle $\\rightarrow \\tau_{2}$.\n-   $t=5.7\\,\\mathrm{ms}$: $\\tau_{2}$ (job 2) completes. The idle task runs. **Switch 10**: $\\tau_{2} \\rightarrow$ Idle.\n-   $t=6.0\\,\\mathrm{ms}$: A new job of $\\tau_{1}$ is released. It preempts the idle task. **Switch 11**: Idle $\\rightarrow \\tau_{1}$.\n-   $t=6.2\\,\\mathrm{ms}$: $\\tau_{1}$ (job 4) completes. The idle task runs. **Switch 12**: $\\tau_{1} \\rightarrow$ Idle.\n-   $t=8.0\\,\\mathrm{ms}$: A new job of $\\tau_{1}$ is released. It preempts the idle task. **Switch 13**: Idle $\\rightarrow \\tau_{1}$.\n-   $t=8.2\\,\\mathrm{ms}$: $\\tau_{1}$ (job 5) completes. The idle task runs. **Switch 14**: $\\tau_{1} \\rightarrow$ Idle.\n-   $t=10.0\\,\\mathrm{ms}$: The hyperperiod ends.\n\nThe total number of context switches in one hyperperiod is $N_{sw} = 14$.\n\n**4. Final Calculation**\n\nNow we can calculate the expected fraction of processor time spent on context switches, $U_{sw}$.\n$$U_{sw} = \\frac{N_{sw} \\times E[T_{sw}]}{H} = \\frac{14 \\times \\left(\\frac{540}{168 \\times 10^{6}}\\right)}{10 \\times 10^{-3}}$$\n$$U_{sw} = \\frac{14 \\times 540}{(168 \\times 10^{6}) \\times (10 \\times 10^{-3})} = \\frac{7560}{168 \\times 10^{4}} = \\frac{7560}{1,680,000}$$\nTo simplify the fraction:\n$$U_{sw} = \\frac{756}{168,000}$$\nSince $168 \\times 4.5 = 756$:\n$$U_{sw} = \\frac{4.5}{1000} = 0.0045$$\nThe problem requires the answer to be a decimal fraction rounded to four significant figures.\n$$0.0045 = 4.5 \\times 10^{-3}$$\nTo four significant figures, this is $4.500 \\times 10^{-3}$.", "answer": "$$\\boxed{4.500 \\times 10^{-3}}$$", "id": "3638732"}, {"introduction": "Memory is a strictly limited resource in most embedded systems, and exhausting it can lead to catastrophic failure. This practice [@problem_id:3638740] focuses on analyzing the worst-case stack memory usage, a critical task for ensuring system reliability. You will learn to calculate the maximum required stack size by considering the deepest possible nesting of tasks and preemptive interrupt service routines, a foundational technique for building robust and safe embedded software.", "problem": "A single-core microcontroller runs a preemptive real-time operating system with fixed-priority interrupt handling and a unified stack: both the currently running task and any preempting Interrupt Service Routine (ISR) frames are placed on the same last-in-first-out stack. At any instant, the live stack content is the concatenation (from base to top) of the interrupted task’s live frame followed by the frames of any nested ISRs in the order they arrived, with the most recently arrived ISR on top. Assume no recursion anywhere, each ISR is non-reentrant, and critical sections inside ISRs only mask same-or-lower priorities for negligible duration relative to preemption. There is no separate interrupt-only stack, and there is no memory protection unit.\n\nYou are given the following system characterization and measurements:\n- The currently running task has a measured worst-case live stack usage of $S_{\\text{task}} = 1408$ bytes at the instant just before the first interrupt can arrive.\n- There are $4$ ISRs with fixed distinct priorities. Denote them by $\\text{ISR}_{1}$ (highest priority), $\\text{ISR}_{2}$, $\\text{ISR}_{3}$, and $\\text{ISR}_{4}$ (lowest priority). The toolchain’s stack analyzer reports the following additional stack usage for each ISR when it is active (inclusive of its prologue/epilogue, register saves, local variables, and any of its internal call frames), measured relative to its caller’s frame being already on the stack:\n  - $\\Delta S_{1} = 224$ bytes for $\\text{ISR}_{1}$,\n  - $\\Delta S_{2} = 176$ bytes for $\\text{ISR}_{2}$,\n  - $\\Delta S_{3} = 144$ bytes for $\\text{ISR}_{3}$,\n  - $\\Delta S_{4} = 128$ bytes for $\\text{ISR}_{4}$.\n- The interrupt controller permits full preemption consistent with these priorities. In the worst case, a lower-priority ISR can be successively preempted by any strictly higher-priority ISR that arrives while it is running. Assume interrupt arrivals can adversarially align to maximize nesting depth subject to these priorities.\n- To detect rare overruns and allow for debugger canaries, the engineering policy mandates a fixed untouched guard band of $128$ bytes above the maximum live usage.\n\nUsing only the general principles that (i) the stack is last-in-first-out, (ii) preemptive fixed-priority interrupts can nest such that the instantaneous live stack equals the interrupted task frame plus all currently active ISR frames, and (iii) the required allocation must exceed the maximum possible instantaneous live usage by the fixed guard band, determine the minimum stack allocation $S_{\\text{alloc}}$ (in bytes) that guarantees no overflow in the worst case.\n\nExpress your final answer as a single integer number of bytes. Do not round; report the exact value.", "solution": "The problem requires the calculation of the minimum required stack allocation size for a preemptive real-time system with fixed-priority interrupts. The process begins with a formal validation of the problem statement.\n\n### Step 1: Extract Givens\nThe data and conditions explicitly provided in the problem statement are as follows:\n- **System Architecture**: A single-core microcontroller with a preemptive real-time operating system.\n- **Stack Model**: A unified, last-in-first-out (LIFO) stack for both tasks and Interrupt Service Routines (ISRs).\n- **Task Stack Usage**: The worst-case live stack usage of the running task at the moment of a potential preemption is $S_{\\text{task}} = 1408$ bytes.\n- **Interrupts**: There are $4$ ISRs with distinct fixed priorities.\n- **Priorities**: The priority hierarchy is $\\text{ISR}_{1} > \\text{ISR}_{2} > \\text{ISR}_{3} > \\text{ISR}_{4}$, where $\\text{ISR}_{1}$ has the highest priority.\n- **ISR Stack Deltas**: The additional stack usage for each active ISR is:\n  - $\\Delta S_{1} = 224$ bytes for $\\text{ISR}_{1}$.\n  - $\\Delta S_{2} = 176$ bytes for $\\text{ISR}_{2}$.\n  - $\\Delta S_{3} = 144$ bytes for $\\text{ISR}_{3}$.\n  - $\\Delta S_{4} = 128$ bytes for $\\text{ISR}_{4}$.\n- **Preemption Rules**: Full preemption is permitted according to the fixed priorities. A lower-priority ISR can be preempted by any strictly higher-priority ISR. Interrupt arrivals can align to maximize nesting depth.\n- **Safety Margin**: A fixed guard band of $S_{\\text{guard}} = 128$ bytes must be allocated above the maximum possible live stack usage.\n- **Goal**: Determine the minimum total stack allocation, $S_{\\text{alloc}}$, in bytes.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the established validation criteria.\n\n- **Scientifically Grounded**: The problem is based on the well-established principles of real-time operating systems, specifically worst-case execution analysis (WCEA) for stack memory. The model of a unified stack with fixed-priority preemptive interrupts is a standard scenario in embedded systems engineering.\n- **Well-Posed**: The problem provides all necessary numerical values ($S_{\\text{task}}$, all $\\Delta S_i$, $S_{\\text{guard}}$) and a clear, unambiguous process (preemptive nesting) to determine a unique solution for the total stack allocation.\n- **Objective**: The problem is stated in precise, objective language common to the field of computer engineering and operating systems. Terms like \"preemptive,\" \"fixed-priority,\" and \"ISR\" have standard definitions.\n\nThe problem statement does not exhibit any flaws. It is a scientifically sound, well-posed, and objective problem directly related to the characteristics of embedded operating systems.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be derived.\n\n### Derivation of the Solution\nThe core task is to determine the maximum possible instantaneous live stack usage, denoted as $S_{\\text{max\\_live}}$. The total required allocation, $S_{\\text{alloc}}$, will then be this maximum usage plus the mandatory guard band.\n\nThe system employs a unified stack and a fixed-priority preemptive scheduling model for interrupts. This means that if a low-priority ISR is executing, the arrival of a higher-priority interrupt will cause the low-priority ISR to be suspended and the high-priority ISR to begin executing. The stack frame for the new, higher-priority ISR is placed on top of the existing stack, which already contains the frames of the preempted task and the preempted lower-priority ISR.\n\nTo find the worst-case stack usage, we must identify the sequence of events that leads to the greatest nesting of function calls and interrupt service routines. According to the problem description, this occurs when events align \"to maximize nesting depth subject to these priorities.\"\n\nThe deepest possible nesting occurs when the system is in a state of maximum stack consumption from the base task, and then a sequence of interrupts arrives in increasing order of priority. The worst-case scenario unfolds as follows:\n\n1.  The main task is running and reaches its own maximum stack usage of $S_{\\text{task}} = 1408$ bytes.\n2.  At this exact moment, an interrupt corresponding to the lowest-priority ISR, $\\text{ISR}_{4}$, arrives. The task is preempted, and the frame for $\\text{ISR}_{4}$ is pushed onto the stack. The stack usage becomes $S_{\\text{task}} + \\Delta S_{4}$.\n3.  While $\\text{ISR}_{4}$ is executing, an interrupt for the next-higher-priority ISR, $\\text{ISR}_{3}$, arrives. $\\text{ISR}_{4}$ is preempted, and the frame for $\\text{ISR}_{3}$ is pushed onto the stack. The stack usage is now $S_{\\text{task}} + \\Delta S_{4} + \\Delta S_{3}$.\n4.  This process continues up the priority chain. While $\\text{ISR}_{3}$ is executing, it is preempted by $\\text{ISR}_{2}$. The stack usage becomes $S_{\\text{task}} + \\Delta S_{4} + \\Delta S_{3} + \\Delta S_{2}$.\n5.  Finally, while $\\text{ISR}_{2}$ is executing, it is preempted by the highest-priority ISR, $\\text{ISR}_{1}$. The frame for $\\text{ISR}_{1}$ is pushed onto the stack.\n\nAt this instant, just as $\\text{ISR}_{1}$ begins execution, the stack contains the frames for the original task and all four ISRs. This represents the maximum possible live stack usage, as no further preemption is possible ($\\text{ISR}_{1}$ is the highest priority) and all possible preempting entities are simultaneously active on the stack.\n\nThe maximum live stack usage, $S_{\\text{max\\_live}}$, is the sum of the base task's usage and the usage of all ISRs:\n$$S_{\\text{max\\_live}} = S_{\\text{task}} + \\Delta S_{1} + \\Delta S_{2} + \\Delta S_{3} + \\Delta S_{4}$$\nSubstituting the given values:\n$$S_{\\text{max\\_live}} = 1408 + 224 + 176 + 144 + 128$$\nThe sum of the ISR stack contributions is:\n$$\\sum_{i=1}^{4} \\Delta S_{i} = 224 + 176 + 144 + 128 = 672 \\text{ bytes}$$\nTherefore, the maximum live stack usage is:\n$$S_{\\text{max\\_live}} = 1408 + 672 = 2080 \\text{ bytes}$$\n\nThe problem mandates a fixed untouched guard band of $S_{\\text{guard}} = 128$ bytes must be added to this maximum live usage to determine the total required allocation, $S_{\\text{alloc}}$.\n$$S_{\\text{alloc}} = S_{\\text{max\\_live}} + S_{\\text{guard}}$$\nSubstituting the calculated and given values:\n$$S_{\\text{alloc}} = 2080 + 128 = 2208 \\text{ bytes}$$\n\nThis is the minimum stack size required to guarantee that no stack overflow will occur, even under the worst-case scenario of nested interrupt preemptions, while respecting the required safety guard band.", "answer": "$$\\boxed{2208}$$", "id": "3638740"}, {"introduction": "When concurrent tasks share resources, a low-priority task can unexpectedly delay a high-priority one, a dangerous phenomenon known as priority inversion. This exercise [@problem_id:3638756] explores how resource management policies like the Priority Ceiling Protocol (PCP) can control this problem by providing a bounded blocking time. You will apply response-time analysis to formally verify that, even with shared resources, all tasks can meet their deadlines, a cornerstone of real-time systems engineering.", "problem": "Consider a single-core embedded controller scheduled under fixed-priority Rate Monotonic Scheduling (RMS). Access to shared resources is controlled by the Priority Ceiling Protocol (PCP). There are four independent periodic tasks $\\tau_1$, $\\tau_2$, $\\tau_3$, and $\\tau_4$. Each task $\\tau_i$ has a period $T_i$, a worst-case execution time $C_i$, and a relative deadline $D_i$; assume $D_i = T_i$ for all $i$. All tasks are released synchronously at time $t = 0$, and there is no release jitter, context-switch overhead, or cache-related preemption delay. Preemptions are allowed. Higher priority corresponds to shorter period.\n\nTask parameters (periods in milliseconds):\n- $\\tau_1$: $T_1 = 10$, $C_1 = 1.5$. Within its execution, $\\tau_1$ executes a single critical section on resource $R_C$ of length $1$.\n- $\\tau_2$: $T_2 = 15$, $C_2 = 2$. $\\tau_2$ performs no shared-resource access.\n- $\\tau_3$: $T_3 = 25$, $C_3 = 4$. Within its execution, $\\tau_3$ executes a single critical section on resource $R_B$ of length $2$.\n- $\\tau_4$: $T_4 = 50$, $C_4 = 15$. Within its execution, $\\tau_4$ executes three disjoint critical sections: on resource $R_A$ of length $5$, on resource $R_B$ of length $1$, and on resource $R_C$ of length $2$.\n\nUnder RMS, the priority order is $\\tau_1 \\succ \\tau_2 \\succ \\tau_3 \\succ \\tau_4$. Under PCP, each resource’s ceiling is the highest task priority among all tasks that use that resource.\n\nUsing only the foundational definitions of RMS interference and the Priority Ceiling Protocol’s blocking property, determine the maximum blocking $B_{\\max}$ that can be incurred by $\\tau_3$ and compute the worst-case response time $R_3$. Then verify whether $R_3 \\le D_3$. Express the final response time in milliseconds and round your final answer to four significant figures.", "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, objective, and contains sufficient information for a unique solution.\n\n**Step 1: Extract Givens**\n-   Scheduling Algorithm: Fixed-priority Rate Monotonic Scheduling (RMS).\n-   Resource Protocol: Priority Ceiling Protocol (PCP).\n-   Tasks: Four independent periodic tasks $\\tau_1, \\tau_2, \\tau_3, \\tau_4$.\n-   Task Model: $D_i = T_i$, synchronous release at $t=0$, no jitter, no overheads.\n-   Task Parameters (periods and execution times in milliseconds):\n    -   $\\tau_1$: $T_1 = 10$, $C_1 = 1.5$. Uses resource $R_C$ for a duration of $1$ ms.\n    -   $\\tau_2$: $T_2 = 15$, $C_2 = 2$. No resource usage.\n    -   $\\tau_3$: $T_3 = 25$, $C_3 = 4$. Uses resource $R_B$ for a duration of $2$ ms.\n    -   $\\tau_4$: $T_4 = 50$, $C_4 = 15$. Uses $R_A$ (length $5$ ms), $R_B$ (length $1$ ms), and $R_C$ (length $2$ ms).\n-   Objective: Find the maximum blocking $B_3$ for $\\tau_3$, compute its worst-case response time $R_3$, and verify schedulability ($R_3 \\le D_3$).\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is based on established principles of real-time systems theory (RMS, PCP, Response-Time Analysis). The parameters are consistent and the problem is well-defined. The total processor utilization is $U = \\frac{1.5}{10} + \\frac{2}{15} + \\frac{4}{25} + \\frac{15}{50} = 0.15 + 0.133\\dots + 0.16 + 0.30 = 0.743\\dots < 1$, which is a necessary condition for schedulability on a single core. The problem is valid.\n\n**Step 3: Solution**\n\nThe solution proceeds by first determining the priority ceilings of the shared resources, then calculating the maximum blocking time for task $\\tau_3$, and finally using response-time analysis to find $R_3$.\n\n**Priority Assignment and Resource Ceilings**\nUnder Rate Monotonic Scheduling (RMS), task priority is inversely proportional to its period.\n-   $T_1=10$, $T_2=15$, $T_3=25$, $T_4=50$.\n-   Since $T_1 < T_2 < T_3 < T_4$, the priority ordering is $P(\\tau_1) > P(\\tau_2) > P(\\tau_3) > P(\\tau_4)$. Let $hp(i)$ be the set of tasks with priority higher than $\\tau_i$. So, $hp(3) = \\{\\tau_1, \\tau_2\\}$.\n\nThe Priority Ceiling Protocol (PCP) assigns a priority ceiling to each shared resource, equal to the highest priority of any task that can lock it.\n-   Resource $R_A$ is used by: $\\{\\tau_4\\}$. The ceiling is $C(R_A) = P(\\tau_4)$.\n-   Resource $R_B$ is used by: $\\{\\tau_3, \\tau_4\\}$. The ceiling is $C(R_B) = \\max\\{P(\\tau_3), P(\\tau_4)\\} = P(\\tau_3)$.\n-   Resource $R_C$ is used by: $\\{\\tau_1, \\tau_4\\}$. The ceiling is $C(R_C) = \\max\\{P(\\tau_1), P(\\tau_4)\\} = P(\\tau_1)$.\n\n**Maximum Blocking for $\\tau_3$ ($B_3$)**\nAccording to the Priority Ceiling Protocol, a task $\\tau_i$ can be blocked by a lower-priority task $\\tau_j$ only if $\\tau_j$ is currently holding a resource $R_k$ whose priority ceiling $C(R_k)$ is greater than or equal to the priority of $\\tau_i$. The maximum duration of such blocking is limited to the length of a single critical section of one lower-priority task.\n\nWe need to find the maximum blocking $B_3$ that task $\\tau_3$ can experience. The only task with a lower priority than $\\tau_3$ is $\\tau_4$. We examine the resources used by $\\tau_4$ to see which of its critical sections can cause blocking on $\\tau_3$.\n-   $\\tau_4$ uses $R_A$: Ceiling $C(R_A) = P(\\tau_4)$. Since $P(\\tau_4) < P(\\tau_3)$, this critical section cannot block $\\tau_3$.\n-   $\\tau_4$ uses $R_B$: Ceiling $C(R_B) = P(\\tau_3)$. Since $P(\\tau_3) \\ge P(\\tau_3)$, this critical section can block $\\tau_3$. The duration of this critical section for $\\tau_4$ is $1$ ms.\n-   $\\tau_4$ uses $R_C$: Ceiling $C(R_C) = P(\\tau_1)$. Since $P(\\tau_1) > P(\\tau_3)$, this critical section can block $\\tau_3$. The duration of this critical section for $\\tau_4$ is $2$ ms.\n\nThe maximum blocking time $B_3$ is the maximum duration among all possible blocking critical sections from lower-priority tasks.\n$$ B_3 = \\max\\{1, 2\\} = 2 \\text{ ms} $$\nThis is the value for $B_{\\max}$ incurred by $\\tau_3$.\n\n**Worst-Case Response Time for $\\tau_3$ ($R_3$)**\nThe worst-case response time of a task $\\tau_i$ is given by the following recursive equation, which accounts for its own execution time $C_i$, blocking from lower-priority tasks $B_i$, and interference from higher-priority tasks $\\sum_{j \\in hp(i)} \\left\\lceil \\frac{R_i}{T_j} \\right\\rceil C_j$.\n$$ R_i^{(k+1)} = C_i + B_i + \\sum_{j \\in hp(i)} \\left\\lceil \\frac{R_i^{(k)}}{T_j} \\right\\rceil C_j $$\nFor task $\\tau_3$, the equation is:\n$$ R_3 = C_3 + B_3 + \\left\\lceil \\frac{R_3}{T_1} \\right\\rceil C_1 + \\left\\lceil \\frac{R_3}{T_2} \\right\\rceil C_2 $$\nSubstituting the given values:\n$$ R_3 = 4 + 2 + \\left\\lceil \\frac{R_3}{10} \\right\\rceil (1.5) + \\left\\lceil \\frac{R_3}{15} \\right\\rceil (2) $$\n$$ R_3 = 6 + 1.5 \\left\\lceil \\frac{R_3}{10} \\right\\rceil + 2 \\left\\lceil \\frac{R_3}{15} \\right\\rceil $$\nWe solve this equation iteratively. A suitable initial guess is $R_3^{(0)} = C_3 + B_3 = 4 + 2 = 6$.\n-   Iteration 1:\n    $$ R_3^{(1)} = 6 + 1.5 \\left\\lceil \\frac{6}{10} \\right\\rceil + 2 \\left\\lceil \\frac{6}{15} \\right\\rceil = 6 + 1.5(1) + 2(1) = 6 + 1.5 + 2 = 9.5 $$\n-   Iteration 2:\n    $$ R_3^{(2)} = 6 + 1.5 \\left\\lceil \\frac{9.5}{10} \\right\\rceil + 2 \\left\\lceil \\frac{9.5}{15} \\right\\rceil = 6 + 1.5(1) + 2(1) = 6 + 1.5 + 2 = 9.5 $$\nSince $R_3^{(2)} = R_3^{(1)}$, the iteration has converged. The worst-case response time for $\\tau_3$ is $R_3 = 9.5$ ms.\n\n**Schedulability Verification**\nA task is schedulable if its worst-case response time is less than or equal to its relative deadline. For $\\tau_3$, we must check if $R_3 \\le D_3$.\n-   $R_3 = 9.5$ ms.\n-   $D_3 = T_3 = 25$ ms.\nThe condition $9.5 \\le 25$ is satisfied, so task $\\tau_3$ is schedulable.\n\nThe problem asks for the final response time rounded to four significant figures.\n$$ R_3 = 9.500 \\text{ ms} $$", "answer": "$$\\boxed{9.500}$$", "id": "3638756"}]}