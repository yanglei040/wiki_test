{"hands_on_practices": [{"introduction": "This first practice serves as a foundational exercise in applying Maximum Likelihood Estimation. We'll explore the binomial distribution, a cornerstone for modeling discrete events with two outcomes, such as success/failure or presence/absence. This problem of estimating a defect probability in manufacturing [@problem_id:1933626] provides a clear, intuitive entry point into the mechanics of MLE, establishing a method that is directly applicable to estimating parameters like allele frequencies in a population.", "problem": "A quality control engineer is monitoring the production of semiconductor wafers. Each wafer contains a large, fixed number of individual electronic components, denoted by $k$. The manufacturing process is such that each component has a constant, but unknown, probability $p$ of being defective, independently of all other components. The number of defective components on a single wafer can thus be modeled by a binomial distribution with parameters $k$ (number of trials) and $p$ (probability of success, i.e., being defective).\n\nTo estimate $p$, the engineer inspects a random sample of $n$ wafers and records the number of defective components on each one. Let the observed counts of defective components for this sample be $x_1, x_2, \\ldots, x_n$.\n\nDerive the maximum likelihood estimator, $\\hat{p}$, for the defect probability $p$. Express your answer as a single symbolic expression in terms of $k$, $n$, and the sample observations $x_1, x_2, \\ldots, x_n$.", "solution": "Let $X_{i}$ denote the number of defective components on wafer $i$, modeled as $X_{i} \\sim \\text{Binomial}(k, p)$ independently for $i=1,2,\\ldots,n$. The joint likelihood for observations $x_{1},\\ldots,x_{n}$ is\n$$\nL(p)=\\prod_{i=1}^{n}\\binom{k}{x_{i}} p^{x_{i}} (1-p)^{k-x_{i}}, \\quad 0 \\leq p \\leq 1.\n$$\nThe log-likelihood is\n$$\n\\ell(p)=\\sum_{i=1}^{n}\\ln\\binom{k}{x_{i}}+\\left(\\sum_{i=1}^{n}x_{i}\\right)\\ln p+\\left(nk-\\sum_{i=1}^{n}x_{i}\\right)\\ln(1-p).\n$$\nDifferentiate with respect to $p$ and set to zero:\n$$\n\\ell'(p)=\\frac{\\sum_{i=1}^{n}x_{i}}{p}-\\frac{nk-\\sum_{i=1}^{n}x_{i}}{1-p}=0.\n$$\nSolving for $p$ gives\n$$\n\\left(\\sum_{i=1}^{n}x_{i}\\right)(1-p)=p\\left(nk-\\sum_{i=1}^{n}x_{i}\\right) \\implies \\sum_{i=1}^{n}x_{i}=pnk,\n$$\nhence\n$$\n\\hat{p}=\\frac{\\sum_{i=1}^{n}x_{i}}{nk}.\n$$\nThe second derivative,\n$$\n\\ell''(p)=-\\frac{\\sum_{i=1}^{n}x_{i}}{p^{2}}-\\frac{nk-\\sum_{i=1}^{n}x_{i}}{(1-p)^{2}},\n$$\nis strictly negative for $p \\in (0,1)$, so this critical point is a maximum. Since $0 \\leq \\sum_{i=1}^{n}x_{i} \\leq nk$, the estimator lies in $[0,1]$, with boundary cases $\\hat{p}=0$ when $\\sum x_{i}=0$ and $\\hat{p}=1$ when $\\sum x_{i}=nk$.", "answer": "$$\\boxed{\\frac{\\sum_{i=1}^{n} x_{i}}{n k}}$$", "id": "1933626"}, {"introduction": "Real-world biological data often comes with limitations, such as detection thresholds that can lead to incomplete datasets. This practice addresses such a scenario, where observations of zero are systematically excluded from the data. By working with a zero-truncated Poisson distribution [@problem_id:1933615], you will learn the critical skill of modifying the likelihood function to account for the specific data-generating process, a common challenge in analyzing experimental results from techniques like sequencing or microscopy.", "problem": "A materials science company is developing high-purity optical fibers. The number of microscopic flaws in a one-meter segment of fiber is modeled by a Poisson distribution with an unknown rate parameter $\\lambda$. For quality control, an automated laser scanner inspects each segment. However, the scanner's software is configured such that it only records data for a fiber segment if it detects at least one flaw. Segments with zero flaws are passed without being entered into the quality control database.\n\nA data scientist is tasked with estimating the parameter $\\lambda$ using the available data. A random sample of recorded fiber segments is analyzed, and the sample mean of the flaw counts is found to be exactly 2.5.\n\nBased on this information, determine the Maximum Likelihood Estimate (MLE) for the parameter $\\lambda$. Choose the best answer from the options below.\n\nA. 2.05\n\nB. 2.22\n\nC. 2.50\n\nD. 2.81\n\nE. 3.00", "solution": "Let $Y \\sim \\text{Poisson}(\\lambda)$ denote the flaw count in a segment, but only observations with $Y \\geq 1$ are recorded. The observed data therefore follow the zero-truncated Poisson distribution:\n$$\nP(Y=k \\mid Y \\geq 1) = \\frac{\\exp(-\\lambda)\\lambda^{k}}{k!\\left(1 - \\exp(-\\lambda)\\right)}, \\quad k=1,2,\\dots\n$$\nGiven a sample $y_{1},\\dots,y_{n}$ from this distribution with sample mean $\\bar{y}=2.5$, the log-likelihood is\n$$\n\\ell(\\lambda) = \\sum_{i=1}^{n}\\left[-\\lambda + y_{i}\\ln \\lambda - \\ln(y_{i}!) - \\ln\\left(1 - \\exp(-\\lambda)\\right)\\right].\n$$\nDifferentiate and set to zero:\n$$\n\\frac{\\partial \\ell}{\\partial \\lambda} = -n + \\frac{\\sum_{i=1}^{n} y_{i}}{\\lambda} - n\\,\\frac{\\exp(-\\lambda)}{1 - \\exp(-\\lambda)} = 0.\n$$\nLet $m = \\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n} y_{i}$. Dividing by $n$ gives\n$$\n-1 + \\frac{m}{\\lambda} - \\frac{\\exp(-\\lambda)}{1 - \\exp(-\\lambda)} = 0,\n$$\nhence\n$$\n\\frac{m}{\\lambda} = 1 + \\frac{\\exp(-\\lambda)}{1 - \\exp(-\\lambda)} = \\frac{1}{1 - \\exp(-\\lambda)}.\n$$\nTherefore the MLE $\\hat{\\lambda}$ satisfies\n$$\nm = \\frac{\\lambda}{1 - \\exp(-\\lambda)}.\n$$\nEquivalently,\n$$\nm\\left(1 - \\exp(-\\lambda)\\right) = \\lambda \\quad \\Longrightarrow \\quad (m - \\lambda)\\exp(\\lambda) = m.\n$$\nLet $x = m - \\lambda$. Then $x\\exp(m - x) = m$, so $x\\exp(-x) = m\\exp(-m)$, which yields\n$$\nx = - W\\!\\left(-m\\exp(-m)\\right), \\quad \\text{so} \\quad \\hat{\\lambda} = m + W\\!\\left(-m\\exp(-m)\\right),\n$$\nwhere $W$ is the Lambert $W$ function. With $m=2.5$,\n$$\n- m\\exp(-m) = -2.5\\exp(-2.5) \\approx -0.2052,\n$$\nso $W(-0.2052) \\approx -0.27$ (since $y\\exp(y)$ at $y=-0.27$ is approximately $-0.206$), giving\n$$\n\\hat{\\lambda} \\approx 2.5 - 0.27 = 2.23.\n$$\nVerification in the estimating equation $m = \\lambda/(1 - \\exp(-\\lambda))$:\n- For $\\lambda = 2.22$, $\\exp(-\\lambda) \\approx 0.1086$, so $m \\approx 2.22/0.8914 \\approx 2.492$.\n- For $\\lambda = 2.23$, $\\exp(-\\lambda) \\approx 0.1075$, so $m \\approx 2.23/0.8925 \\approx 2.500$.\n\nThus the MLE is approximately $2.23$, and the closest option is $2.22$, which is choice B.", "answer": "$$\\boxed{B}$$", "id": "1933615"}, {"introduction": "We now apply the principles of MLE to a core problem in bioinformatics: quantifying the fidelity of DNA synthesis or sequencing. This exercise models the possible outcomes at each nucleotide position—match, substitution, or deletion—using a categorical distribution. By deriving the estimators for the error probabilities $\\alpha$ and $\\beta$ [@problem_id:2402385], you will see how MLE provides a rigorous framework for turning raw experimental counts into meaningful biological parameters, confirming the intuitive idea that the best estimate for a probability is its observed frequency.", "problem": "A biotechnology laboratory is validating a new Deoxyribonucleic Acid (DNA) synthesis machine by synthesizing a pool of molecules corresponding to a known template sequence. The template has length $L$ nucleotides. The machine synthesizes $N$ molecules independently. At each template position, the machine independently emits one of three outcomes for each molecule: a correct base (match), a wrong base (substitution), or no base (deletion). Insertions do not occur in this experiment. Let the substitution probability be $\\alpha$, the deletion probability be $\\beta$, and the match probability be $1-\\alpha-\\beta$, with constraints $\\alpha \\ge 0$, $\\beta \\ge 0$, and $\\alpha + \\beta \\le 1$. After sequencing and aligning the synthesized molecules to the template (alignment is unambiguous because insertions are absent), the laboratory aggregates counts across all $N$ molecules and all $L$ positions: the total number of substitutions $S$, the total number of deletions $D$, and the total number of matches $M$, where $M = N L - S - D$. Under the independence assumptions stated, treat each position in each molecule as an independent categorical trial with three outcomes and associated probabilities $(1-\\alpha-\\beta, \\alpha, \\beta)$.\n\nUsing Maximum Likelihood Estimation (MLE), write a program that, for each specified test case, computes the MLEs $\\hat{\\alpha}$ and $\\hat{\\beta}$ from the provided $(N,L,S,D)$ values. Your program must produce results rounded to $6$ decimal places as decimals (not percentages).\n\nTest suite:\n- Case $1$: $N=1000$, $L=50$, $S=120$, $D=30$.\n- Case $2$: $N=200$, $L=100$, $S=0$, $D=0$.\n- Case $3$: $N=5$, $L=2$, $S=0$, $D=10$.\n- Case $4$: $N=3$, $L=4$, $S=2$, $D=1$.\n- Case $5$: $N=50$, $L=120$, $S=600$, $D=0$.\n\nFinal output format:\n- For the above cases in order, output a single line containing a comma-separated list enclosed in square brackets with the sequence $[\\hat{\\alpha}_1,\\hat{\\beta}_1,\\hat{\\alpha}_2,\\hat{\\beta}_2,\\hat{\\alpha}_3,\\hat{\\beta}_3,\\hat{\\alpha}_4,\\hat{\\beta}_4,\\hat{\\alpha}_5,\\hat{\\beta}_5]$, where subscripts index the case number. For example, the required format is $[r_1,r_2,\\dots,r_{10}]$ with each $r_i$ rounded to $6$ decimal places.", "solution": "The experiment consists of a total of $T = N \\times L$ independent trials. Each trial can result in one of three outcomes: a substitution (with probability $\\alpha$), a deletion (with probability $\\beta$), or a match (with probability $1-\\alpha-\\beta$). The observed data are the total counts for these outcomes: $S$ substitutions, $D$ deletions, and $M = T - S - D$ matches.\n\nThe joint probability of observing these counts is described by the multinomial probability mass function. The likelihood function $L(\\alpha, \\beta)$ is proportional to this mass function:\n$$L(\\alpha, \\beta) \\propto \\alpha^S \\beta^D (1 - \\alpha - \\beta)^M$$\n\nTo simplify maximization, we work with the log-likelihood function, $\\ell(\\alpha, \\beta) = \\ln L(\\alpha, \\beta)$:\n$$\\ell(\\alpha, \\beta) = C + S \\ln(\\alpha) + D \\ln(\\beta) + M \\ln(1 - \\alpha - \\beta)$$\nwhere $C$ is a constant that does not depend on $\\alpha$ or $\\beta$.\n\nTo find the values of $\\alpha$ and $\\beta$ that maximize $\\ell$, we compute the partial derivatives and set them to zero:\n$$\\frac{\\partial \\ell}{\\partial \\alpha} = \\frac{S}{\\alpha} - \\frac{M}{1 - \\alpha - \\beta} = 0$$\n$$\\frac{\\partial \\ell}{\\partial \\beta} = \\frac{D}{\\beta} - \\frac{M}{1 - \\alpha - \\beta} = 0$$\n\nFrom these equations, we can see that $\\frac{S}{\\alpha} = \\frac{D}{\\beta}$, which gives $S\\beta = D\\alpha$.\n\nFrom the first equation, we have $S(1 - \\alpha - \\beta) = M\\alpha$. Substituting $M = T - S - D$:\n$$S - S\\alpha - S\\beta = (T - S - D)\\alpha$$\nNow, substitute $S\\beta = D\\alpha$:\n$$S - S\\alpha - D\\alpha = (T - S - D)\\alpha$$\n$$S = (S + D + T - S - D)\\alpha = T\\alpha$$\nThus, we find the Maximum Likelihood Estimate (MLE) for $\\alpha$:\n$$\\hat{\\alpha} = \\frac{S}{T} = \\frac{S}{NL}$$\n\nSimilarly, solving for $\\beta$ gives:\n$$\\hat{\\beta} = \\frac{D}{T} = \\frac{D}{NL}$$\n\nThe MLEs for the error probabilities are their observed frequencies in the data. This result is intuitive and is a general property of categorical and multinomial distributions. The solution is to apply these formulas to each test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the Maximum Likelihood Estimates (MLEs) for substitution and\n    deletion probabilities based on aggregated counts from a DNA synthesis experiment.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (N, L, S, D)\n    test_cases = [\n        (1000, 50, 120, 30),  # Case 1\n        (200, 100, 0, 0),    # Case 2\n        (5, 2, 0, 10),       # Case 3\n        (3, 4, 2, 1),        # Case 4\n        (50, 120, 600, 0)    # Case 5\n    ]\n\n    results = []\n    for N, L, S, D in test_cases:\n        # The total number of trials is the number of molecules (N)\n        # multiplied by the template length (L).\n        total_trials = N * L\n\n        # The Maximum Likelihood Estimate for the probability of an event in a\n        # categorical distribution is its observed frequency.\n        # This holds true even for edge cases where counts are zero or sum\n        # to the total number of trials.\n        if total_trials > 0:\n            alpha_hat = S / total_trials\n            beta_hat = D / total_trials\n        else:\n            # This case is not in the test suite but is handled for robustness.\n            # If there are no trials, the probabilities are undefined.\n            # We define them as 0.0 by convention.\n            alpha_hat = 0.0\n            beta_hat = 0.0\n        \n        # Append results formatted to 6 decimal places as required.\n        # Using f-string formatting ensures the correct number of decimal places,\n        # e.g., 0.1 becomes 0.100000.\n        results.append(f'{alpha_hat:.6f}')\n        results.append(f'{beta_hat:.6f}')\n\n    # Final print statement in the exact required format.\n    # The results list already contains formatted strings.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2402385"}]}