{"hands_on_practices": [{"introduction": "Our journey into the practical application of Mendelian Randomization begins with its most fundamental building block: the Wald ratio estimator. This exercise demonstrates how to calculate the causal effect of an exposure on an outcome using a single genetic instrument in a two-sample setting. Mastering this core calculation is essential for understanding the logic that underpins all more advanced MR techniques. [@problem_id:2854802]", "problem": "A single nucleotide polymorphism (SNP) $G$ acts as a cis-expression quantitative trait locus (cis-eQTL) for the expression level $E$ of a transcriptional regulator within a gene regulatory network, and is also associated with a complex trait $Y$. Consider a two-sample setting with non-overlapping samples so that the summary association estimates for $Y$ on $G$ and for $E$ on $G$ are statistically independent. Assume linear relationships, additivity on the appropriate scales, large-sample normality of the association estimates, and the standard instrumental variable assumptions for Mendelian Randomization (MR): instrument relevance, instrument independence from confounders, and exclusion of any pathway from $G$ to $Y$ other than through $E$. You are given the following summary estimates from regression analyses: the association of $Y$ on $G$ is $\\hat{\\beta}_{YG} = 0.10$ with standard error $\\mathrm{SE}(\\hat{\\beta}_{YG}) = 0.03$, and the association of $E$ on $G$ is $\\hat{\\beta}_{EG} = 0.25$ with standard error $\\mathrm{SE}(\\hat{\\beta}_{EG}) = 0.05$.\n\nUsing only the assumptions stated above, compute:\n- the MR causal effect estimate of $E$ on $Y$,\n- its standard error,\n- and the two-sided $p$-value for testing the null hypothesis that the causal effect is zero at significance level $\\alpha = 0.05$.\n\nReport your result as a row vector $\\left[\\hat{\\beta}_{\\mathrm{MR}}, \\mathrm{SE}(\\hat{\\beta}_{\\mathrm{MR}}), p\\right]$. Round each component to three significant figures. No units are required.", "solution": "The problem requires the computation of a Mendelian Randomization (MR) causal effect estimate, its standard error, and the corresponding p-value in a two-sample setting. We begin by validating the problem statement.\n\nThe givens are:\n- A single nucleotide polymorphism (SNP) $G$ is an instrumental variable (IV).\n- The exposure is the expression level $E$ of a transcriptional regulator.\n- The outcome is a complex trait $Y$.\n- A two-sample design is used with non-overlapping samples, ensuring statistical independence of the summary estimates.\n- Standard MR assumptions are stated to hold:\n    1. Instrument relevance: $G$ is associated with $E$.\n    2. Instrument independence from confounders: $G$ is independent of any unmeasured confounders of the $E-Y$ relationship.\n    3. Exclusion restriction: $G$ affects $Y$ only through $E$.\n- The association estimate of $Y$ on $G$ is $\\hat{\\beta}_{YG} = 0.10$.\n- The standard error of this estimate is $\\mathrm{SE}(\\hat{\\beta}_{YG}) = 0.03$.\n- The association estimate of $E$ on $G$ is $\\hat{\\beta}_{EG} = 0.25$.\n- The standard error of this estimate is $\\mathrm{SE}(\\hat{\\beta}_{EG}) = 0.05$.\n- Additivity, linearity, and large-sample normality of estimates are assumed.\n- The significance level for testing is $\\alpha = 0.05$.\n\nThe problem is scientifically grounded, well-posed, objective, and internally consistent. It describes a standard application of the Wald ratio estimator for two-sample Mendelian Randomization, a cornerstone method in genetic epidemiology and systems genetics. All necessary data and assumptions are provided to derive a unique, meaningful solution. The problem is therefore valid.\n\nWe proceed with the solution.\n\nFirst, we compute the MR estimate for the causal effect of $E$ on $Y$, denoted $\\beta_{EY}$. Under the given assumptions, this effect can be estimated by the ratio of the SNP-outcome association to the SNP-exposure association. This is the Wald ratio estimator, which for our summary data is:\n$$ \\hat{\\beta}_{\\mathrm{MR}} = \\frac{\\hat{\\beta}_{YG}}{\\hat{\\beta}_{EG}} $$\nSubstituting the provided values:\n$$ \\hat{\\beta}_{\\mathrm{MR}} = \\frac{0.10}{0.25} = 0.4 $$\n\nSecond, we compute the standard error of this estimate, $\\mathrm{SE}(\\hat{\\beta}_{\\mathrm{MR}})$. Since $\\hat{\\beta}_{YG}$ and $\\hat{\\beta}_{EG}$ are from non-overlapping samples, they are independent random variables. The variance of their ratio can be approximated using the first-order Taylor series expansion (the Delta method). For a function $f(x, y) = x/y$, the variance is approximated as:\n$$ \\mathrm{Var}\\left(\\frac{X}{Y}\\right) \\approx \\left(\\frac{\\mu_X}{\\mu_Y}\\right)^2 \\left( \\frac{\\mathrm{Var}(X)}{\\mu_X^2} + \\frac{\\mathrm{Var}(Y)}{\\mu_Y^2} \\right) $$\nApplying this to our estimates, where $\\mathrm{Var}(\\hat{\\beta}) = \\mathrm{SE}(\\hat{\\beta})^2$:\n$$ \\mathrm{Var}(\\hat{\\beta}_{\\mathrm{MR}}) \\approx \\left(\\frac{\\hat{\\beta}_{YG}}{\\hat{\\beta}_{EG}}\\right)^2 \\left( \\frac{\\mathrm{SE}(\\hat{\\beta}_{YG})^2}{\\hat{\\beta}_{YG}^2} + \\frac{\\mathrm{SE}(\\hat{\\beta}_{EG})^2}{\\hat{\\beta}_{EG}^2} \\right) $$\nA more direct and commonly used form derived from the Delta method is:\n$$ \\mathrm{Var}(\\hat{\\beta}_{\\mathrm{MR}}) \\approx \\frac{\\mathrm{SE}(\\hat{\\beta}_{YG})^2}{\\hat{\\beta}_{EG}^2} + \\frac{\\hat{\\beta}_{YG}^2 \\mathrm{SE}(\\hat{\\beta}_{EG})^2}{\\hat{\\beta}_{EG}^4} $$\nWe will use this formulation. Substituting the given values:\n$$ \\mathrm{Var}(\\hat{\\beta}_{\\mathrm{MR}}) \\approx \\frac{(0.03)^2}{(0.25)^2} + \\frac{(0.10)^2 (0.05)^2}{(0.25)^4} $$\n$$ \\mathrm{Var}(\\hat{\\beta}_{\\mathrm{MR}}) \\approx \\frac{0.0009}{0.0625} + \\frac{(0.01)(0.0025)}{0.00390625} $$\n$$ \\mathrm{Var}(\\hat{\\beta}_{\\mathrm{MR}}) \\approx 0.0144 + \\frac{0.000025}{0.00390625} = 0.0144 + 0.0064 = 0.0208 $$\nThe standard error is the square root of the variance:\n$$ \\mathrm{SE}(\\hat{\\beta}_{\\mathrm{MR}}) = \\sqrt{0.0208} \\approx 0.144222051... $$\n\nThird, we compute the two-sided p-value for the null hypothesis $H_0: \\beta_{\\mathrm{MR}} = 0$. Given the assumption of large-sample normality, the test statistic $Z$ follows a standard normal distribution $\\mathcal{N}(0, 1)$ under the null hypothesis.\n$$ Z = \\frac{\\hat{\\beta}_{\\mathrm{MR}} - 0}{\\mathrm{SE}(\\hat{\\beta}_{\\mathrm{MR}})} = \\frac{\\hat{\\beta}_{\\mathrm{MR}}}{\\mathrm{SE}(\\hat{\\beta}_{\\mathrm{MR}})} $$\nSubstituting the calculated values:\n$$ Z \\approx \\frac{0.4}{0.144222051...} \\approx 2.77350098... $$\nThe two-sided p-value is the probability of observing a test statistic at least as extreme as $|Z|$:\n$$ p = 2 \\times P(Z_{std} \\ge |Z|) = 2 \\times (1 - \\Phi(|Z|)) $$\nwhere $\\Phi$ is the cumulative distribution function of the standard normal distribution.\n$$ p \\approx 2 \\times (1 - \\Phi(2.7735)) \\approx 2 \\times (1 - 0.99723) \\approx 2 \\times 0.00277 = 0.00554 $$\n\nFinally, we report the results rounded to three significant figures as a row vector $[\\hat{\\beta}_{\\mathrm{MR}}, \\mathrm{SE}(\\hat{\\beta}_{\\mathrm{MR}}), p]$.\n- $\\hat{\\beta}_{\\mathrm{MR}} = 0.4$ rounded to three significant figures is $0.400$.\n- $\\mathrm{SE}(\\hat{\\beta}_{\\mathrm{MR}}) \\approx 0.14422...$ rounded to three significant figures is $0.144$.\n- $p \\approx 0.00554$ (already has three significant figures, $5, 5, 4$).\n\nThe final result is the vector $[0.400, 0.144, 0.00554]$.", "answer": "$$\\boxed{\\begin{pmatrix} 0.400  0.144  0.00554 \\end{pmatrix}}$$", "id": "2854802"}, {"introduction": "In practice, MR studies gain power and robustness by using multiple genetic instruments. This hands-on coding exercise moves from the single-instrument Wald ratio to the multi-instrument Inverse-Variance Weighted (IVW) method, the workhorse of modern MR. You will also implement MR-Egger regression and generate the components for a funnel plot, two essential tools for diagnosing and assessing the impact of horizontal pleiotropy and heterogeneity among your instruments. [@problem_id:2404096]", "problem": "You are given summary association data from Genome-Wide Association Study (GWAS) instruments, each being a Single Nucleotide Polymorphism (SNP), in the setting of Mendelian randomization (MR). For each SNP, you have the association with an exposure, denoted $ \\beta_{GX,i} $, and the association with an outcome, denoted $ \\beta_{GY,i} $, together with the standard error of the outcome association $ \\sigma_{GY,i} $. Assume the following fundamental base: (i) a linear causal model for the exposure–outcome relationship; (ii) instruments affect the outcome only through the exposure apart from any potential horizontal pleiotropy; (iii) sampling variability in $ \\beta_{GY,i} $ is quantified by $ \\sigma_{GY,i} $, and uncertainty in $ \\beta_{GX,i} $ is negligible relative to $ \\sigma_{GY,i} $ for the purpose of weighting; (iv) the causal effect is estimable by aggregating per-variant information using weighted least squares.\n\nYour task is to write a complete program that, for each test case described below, computes the numerical objects required to generate (a) a scatter plot of $ \\beta_{GY} $ versus $ \\beta_{GX} $ with both the intercept-constrained Inverse-Variance Weighted (IVW) regression line and the Mendelian randomization Egger (MR-Egger) regression line, and (b) a funnel plot of ratio estimates versus their standard errors to visually inspect for heterogeneity and pleiotropy. Instead of drawing any plot, your program must return the precise numerical quantities that define those plots.\n\nStarting only from the base principles above, implement the following computations for each test case:\n- Use weights $ w_i $ defined by the inverse of the outcome variance, i.e., $ w_i $ proportional to $ 1 / \\sigma_{GY,i}^2 $.\n- Compute the intercept-constrained IVW estimate of the causal slope, by solving the weighted least squares problem with intercept fixed to zero that minimizes $ \\sum_i w_i \\left( \\beta_{GY,i} - b \\, \\beta_{GX,i} \\right)^2 $ over $ b $.\n- Compute the MR-Egger weighted regression line with an unconstrained intercept, by minimizing $ \\sum_i w_i \\left( \\beta_{GY,i} - a - b \\, \\beta_{GX,i} \\right)^2 $ over $ a $ and $ b $.\n- Compute Cochran’s $ Q $ statistic for heterogeneity under the IVW fit and the corresponding $ I^2 $ heterogeneity metric, where $ Q $ compares the dispersion of the weighted residuals to their expected value under homogeneity.\n- For the funnel plot, compute the per-variant ratio estimate $ \\theta_i $ and its approximate standard error $ s_i $ under the assumption that uncertainty in $ \\beta_{GX,i} $ is negligible relative to $ \\sigma_{GY,i} $. Then compute the pseudo $ 95\\% $ funnel bounds for each variant around the pooled IVW effect as $ \\theta_{\\text{IVW}} \\pm 1.96 \\, s_i $.\n\nYour program must apply these computations to the following test suite. Each test case is defined by three lists of equal length: $ \\beta_{GX} $, $ \\beta_{GY} $, and $ \\sigma_{GY} $.\n\nTest case A (happy path; consistent instruments):\n- $ \\beta_{GX} = [\\, 0.08, \\, 0.12, \\, 0.10, \\, 0.15, \\, 0.07, \\, 0.11 \\,] $\n- $ \\beta_{GY} = [\\, 0.040, \\, 0.060, \\, 0.051, \\, 0.072, \\, 0.033, \\, 0.057 \\,] $\n- $ \\sigma_{GY} = [\\, 0.020, \\, 0.018, \\, 0.022, \\, 0.019, \\, 0.021, \\, 0.020 \\,] $\n\nTest case B (directional pleiotropy; nonzero intercept expected):\n- $ \\beta_{GX} = [\\, 0.05, \\, -0.04, \\, 0.09, \\, 0.12, \\, 0.03, \\, 0.07 \\,] $\n- $ \\beta_{GY} = [\\, 0.037, \\, 0.007, \\, 0.048, \\, 0.054, \\, 0.029, \\, 0.042 \\,] $\n- $ \\sigma_{GY} = [\\, 0.020, \\, 0.021, \\, 0.019, \\, 0.018, \\, 0.022, \\, 0.020 \\,] $\n\nTest case C (heterogeneity and a weak instrument):\n- $ \\beta_{GX} = [\\, 0.20, \\, 0.15, \\, 0.10, \\, 0.05, \\, 0.004 \\,] $\n- $ \\beta_{GY} = [\\, 0.080, \\, 0.070, \\, 0.045, \\, 0.050, \\, 0.010 \\,] $\n- $ \\sigma_{GY} = [\\, 0.015, \\, 0.015, \\, 0.016, \\, 0.020, \\, 0.020 \\,] $\n\nTest case D (balanced pleiotropy; heterogeneity with approximately zero intercept):\n- $ \\beta_{GX} = [\\, 0.10, \\, 0.12, \\, 0.09, \\, 0.11, \\, 0.08 \\,] $\n- $ \\beta_{GY} = [\\, 0.080, \\, 0.052, \\, 0.064, \\, 0.056, \\, 0.048 \\,] $\n- $ \\sigma_{GY} = [\\, 0.020, \\, 0.020, \\, 0.020, \\, 0.020, \\, 0.020 \\,] $\n\nImplementation and numerical requirements:\n- Treat all weights as $ w_i = 1 / \\sigma_{GY,i}^2 $.\n- For the funnel plot, compute $ \\theta_i = \\beta_{GY,i} / \\beta_{GX,i} $ and $ s_i = \\sigma_{GY,i} / \\lvert \\beta_{GX,i} \\rvert $.\n- Use the IVW slope for the pooled effect in the funnel plot bounds $ \\theta_{\\text{IVW}} \\pm 1.96 \\, s_i $.\n- For Cochran’s heterogeneity statistic under the IVW fit, compute $ Q $ and then $ I^2 = \\max \\left( 0, \\, \\dfrac{Q - (M - 1)}{Q} \\right) $ with $ M $ the number of variants. If $ Q = 0 $, set $ I^2 = 0 $.\n- Your program must output, for each test case, a list of nine elements in the following order:\n  1. the IVW slope (a float),\n  2. the MR-Egger slope (a float),\n  3. the MR-Egger intercept (a float),\n  4. the IVW Cochran’s $ Q $ (a float),\n  5. the IVW $ I^2 $ (a float),\n  6. the list of ratio estimates $ [ \\theta_i ] $,\n  7. the list of ratio standard errors $ [ s_i ] $,\n  8. the list of lower funnel bounds $ [ \\theta_{\\text{IVW}} - 1.96 \\, s_i ] $,\n  9. the list of upper funnel bounds $ [ \\theta_{\\text{IVW}} + 1.96 \\, s_i ] $.\n- Express all floats rounded to six decimal places.\n- Final output format: Your program should produce a single line of output containing the four per-test-case results aggregated as a comma-separated list enclosed in square brackets, with no spaces. That is, a single line of the form $ [r_A, r_B, r_C, r_D] $ where each $ r_\\cdot $ is the nine-element list described above.\n\nEdge conditions and scientific realism:\n- Enforce that $ \\lvert \\beta_{GX,i} \\rvert $ is not zero to avoid division by zero in ratio computations. The provided test suite satisfies this; in general, if any $ \\lvert \\beta_{GX,i} \\rvert $ were below a small threshold $ \\varepsilon $, the variant should be excluded from the ratio and funnel components while remaining consistent in regression fits if handled appropriately. In this test suite, no exclusions are necessary.", "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the established principles of Mendelian randomization (MR), a standard method in genetic epidemiology. The problem is well-posed, providing all necessary data and explicit mathematical definitions for the required computations. The language is objective and formal, free of ambiguity or subjective claims. It presents a solvable computational task based on verifiable statistical and mathematical principles.\n\nWe will now proceed with a systematic derivation of the required quantities. The context is the estimation of a causal effect of an exposure on an outcome using genetic variants as instrumental variables. For each of $M$ genetic variants (SNPs), we are given its estimated association with the exposure, $\\beta_{GX,i}$, its estimated association with the outcome, $\\beta_{GY,i}$, and the standard error of the latter, $\\sigma_{GY,i}$.\n\nThe weights for all weighted calculations are defined by the inverse of the outcome variance, assuming uncertainty in $\\beta_{GX,i}$ is negligible for this purpose:\n$$\nw_i = \\frac{1}{\\sigma_{GY,i}^2}\n$$\n\n**1. Intercept-Constrained Inverse-Variance Weighted (IVW) Slope**\n\nThe IVW method estimates the causal effect, $b$, by solving a weighted least squares problem that forces the regression line through the origin. This corresponds to the assumption of no horizontal pleiotropy. The objective is to minimize the sum of weighted squared residuals:\n$$\nS(b) = \\sum_{i=1}^{M} w_i \\left( \\beta_{GY,i} - b \\, \\beta_{GX,i} \\right)^2\n$$\nTo find the minimum, we set the derivative with respect to $b$ to zero:\n$$\n\\frac{dS}{db} = -2 \\sum_{i=1}^{M} w_i \\beta_{GX,i} \\left( \\beta_{GY,i} - b \\, \\beta_{GX,i} \\right) = 0\n$$\nSolving for $b$ yields the IVW estimate, which we denote $\\theta_{\\text{IVW}}$:\n$$\n\\theta_{\\text{IVW}} = \\frac{\\sum_{i=1}^{M} w_i \\beta_{GX,i} \\beta_{GY,i}}{\\sum_{i=1}^{M} w_i \\beta_{GX,i}^2}\n$$\n\n**2. Mendelian Randomization Egger (MR-Egger) Regression**\n\nThe MR-Egger method relaxes the no-pleiotropy assumption of the IVW method by allowing for a non-zero intercept in the regression of $\\beta_{GY,i}$ on $\\beta_{GX,i}$. The intercept, $a$, can be interpreted as an estimate of the average directional pleiotropic effect, while the slope, $b$, remains the estimate of the causal effect. We minimize the following objective function over both $a$ and $b$:\n$$\nS(a, b) = \\sum_{i=1}^{M} w_i \\left( \\beta_{GY,i} - a - b \\, \\beta_{GX,i} \\right)^2\n$$\nThis is a standard weighted linear regression problem. The solutions for the MR-Egger slope ($b_{\\text{Egger}}$) and intercept ($a_{\\text{Egger}}$) are given by the normal equations:\n$$\nb_{\\text{Egger}} = \\frac{ \\left(\\sum w_i\\right) \\left(\\sum w_i \\beta_{GX,i} \\beta_{GY,i}\\right) - \\left(\\sum w_i \\beta_{GX,i}\\right) \\left(\\sum w_i \\beta_{GY,i}\\right) }{ \\left(\\sum w_i\\right) \\left(\\sum w_i \\beta_{GX,i}^2\\right) - \\left(\\sum w_i \\beta_{GX,i}\\right)^2 }\n$$\n$$\na_{\\text{Egger}} = \\frac{\\sum w_i \\beta_{GY,i}}{\\sum w_i} - b_{\\text{Egger}} \\frac{\\sum w_i \\beta_{GX,i}}{\\sum w_i}\n$$\nThese formulas correspond to the standard solution for weighted least squares regression coefficients.\n\n**3. Cochran’s Q Statistic and I² Heterogeneity Metric**\n\nHeterogeneity among the instrument-specific causal estimates can indicate either violation of the MR assumptions (such as pleiotropy) or that the true causal effect differs for subsets of the population targeted by different instruments. Cochran’s $Q$ statistic for the IVW model quantifies this heterogeneity by summing the weighted squared differences between the individual ratio estimates and the pooled IVW estimate. It is calculated as:\n$$\nQ = \\sum_{i=1}^{M} w_i \\left( \\frac{\\beta_{GY,i}}{\\beta_{GX,i}} - \\theta_{\\text{IVW}} \\right)^2 \\beta_{GX,i}^2 = \\sum_{i=1}^{M} w_i \\left( \\beta_{GY,i} - \\theta_{\\text{IVW}} \\beta_{GX,i} \\right)^2\n$$\nUnder the null hypothesis of homogeneity (i.e., all instruments estimate the same causal effect), $Q$ follows a chi-squared distribution with $M-1$ degrees of freedom.\n\nThe $I^2$ statistic describes the percentage of variation across instruments that is due to heterogeneity rather than sampling error. It is derived from $Q$:\n$$\nI^2 = \\max\\left(0, \\frac{Q - (M-1)}{Q}\\right)\n$$\nIf $Q=0$, which is highly unlikely in practice, $I^2$ is defined as $0$.\n\n**4. Funnel Plot Components**\n\nA funnel plot is a visual tool to investigate heterogeneity and publication bias. It plots the effect size of each instrument against a measure of its precision.\n\n-   **Per-variant ratio estimate ($\\theta_i$):** This is the causal effect estimated from a single instrument $i$:\n    $$\n    \\theta_i = \\frac{\\beta_{GY,i}}{\\beta_{GX,i}}\n    $$\n-   **Standard error of the ratio estimate ($s_i$):** Using the delta method and the assumption that $\\beta_{GX,i}$ is measured with negligible error, the standard error of $\\theta_i$ is approximated as:\n    $$\n    s_i = \\text{SE}(\\theta_i) \\approx \\frac{\\sigma_{GY,i}}{\\lvert \\beta_{GX,i} \\rvert}\n    $$\n-   **Funnel plot bounds:** The funnel is constructed around the pooled IVW causal estimate, $\\theta_{\\text{IVW}}$. For a pseudo $95\\%$ confidence interval, the bounds for each variant $i$ are:\n    $$\n    \\text{Bounds}_i = \\theta_{\\text{IVW}} \\pm 1.96 \\, s_i\n    $$\n    The lower and upper bounds are $\\theta_{\\text{IVW}} - 1.96 \\, s_i$ and $\\theta_{\\text{IVW}} + 1.96 \\, s_i$, respectively.\n\nThe implementation will compute these nine quantities for each provided test case: the IVW slope, the MR-Egger slope and intercept, the Cochran's $Q$ and $I^2$ statistics for the IVW fit, and the lists of ratio estimates, their standard errors, and the corresponding lower and upper funnel bounds. All floating-point numbers will be rounded to six decimal places as required.", "answer": "```python\nimport numpy as np\n\ndef calculate_mr_metrics(beta_gx: list[float], beta_gy: list[float], sigma_gy: list[float]) - list:\n    \"\"\"\n    Computes Mendelian randomization metrics for a given set of summary statistics.\n\n    Args:\n        beta_gx: List of SNP-exposure associations.\n        beta_gy: List of SNP-outcome associations.\n        sigma_gy: List of standard errors for SNP-outcome associations.\n\n    Returns:\n        A list containing nine elements as specified in the problem description.\n    \"\"\"\n    # Convert lists to NumPy arrays for vectorized operations\n    bgx = np.array(beta_gx)\n    bgy = np.array(beta_gy)\n    sgy = np.array(sigma_gy)\n    \n    # 1. Weights\n    # w_i = 1 / sigma_GY,i^2\n    w = 1.0 / (sgy**2)\n    \n    # 2. IVW Slope (Intercept-constrained)\n    # theta_ivw = (sum w_i * beta_gx_i * beta_gy_i) / (sum w_i * beta_gx_i^2)\n    ivw_numerator = np.sum(w * bgx * bgy)\n    ivw_denominator = np.sum(w * bgx**2)\n    ivw_slope = ivw_numerator / ivw_denominator\n    \n    # 3. MR-Egger Slope and Intercept\n    # Weighted least squares regression of bgy on bgx with weights w\n    W = np.sum(w)\n    Swx = np.sum(w * bgx)\n    Swy = np.sum(w * bgy)\n    Swxx = np.sum(w * bgx**2)\n    Swxy = np.sum(w * bgx * bgy)\n    \n    egger_denominator = (W * Swxx - Swx**2)\n    if egger_denominator == 0:\n        # This case is unlikely with real data but handle for robustness\n        mr_egger_slope = np.nan\n        mr_egger_intercept = np.nan\n    else:\n        mr_egger_slope = (W * Swxy - Swx * Swy) / egger_denominator\n        mr_egger_intercept = (Swy / W) - mr_egger_slope * (Swx / W)\n\n    # 4. Cochran's Q for IVW\n    # Q = sum w_i * (beta_gy_i - theta_ivw * beta_gx_i)^2\n    cochran_q = np.sum(w * (bgy - ivw_slope * bgx)**2)\n    \n    # 5. I^2 for IVW\n    M = len(bgx)\n    df = M - 1\n    if cochran_q == 0:\n        i_squared = 0.0\n    else:\n        i_squared = max(0.0, (cochran_q - df) / cochran_q)\n\n    # 6. Ratio estimates (theta_i)\n    # theta_i = beta_gy_i / beta_gx_i\n    theta_i = bgy / bgx\n    \n    # 7. Ratio standard errors (s_i)\n    # s_i = sigma_gy_i / |beta_gx_i|\n    s_i = sgy / np.abs(bgx)\n    \n    # 8.  9. Funnel plot bounds\n    # lower/upper = theta_ivw +/- 1.96 * s_i\n    z_score = 1.96\n    funnel_lower_bounds = ivw_slope - z_score * s_i\n    funnel_upper_bounds = ivw_slope + z_score * s_i\n    \n    # Assemble results and round to 6 decimal places\n    results = [\n        round(ivw_slope, 6),\n        round(mr_egger_slope, 6),\n        round(mr_egger_intercept, 6),\n        round(cochran_q, 6),\n        round(i_squared, 6),\n        [round(val, 6) for val in theta_i],\n        [round(val, 6) for val in s_i],\n        [round(val, 6) for val in funnel_lower_bounds],\n        [round(val, 6) for val in funnel_upper_bounds],\n    ]\n    \n    return results\n\ndef format_result_list(res_list: list) - str:\n    \"\"\"Formats a single test case result list into the required string format.\"\"\"\n    str_parts = []\n    for item in res_list:\n        if isinstance(item, list):\n            formatted_list = f\"[{','.join([f'{x:.6f}' for x in item])}]\"\n            str_parts.append(formatted_list)\n        else:\n            str_parts.append(f\"{item:.6f}\")\n    return f\"[{','.join(str_parts)}]\"\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final output.\n    \"\"\"\n    test_cases = {\n        'A': {\n            \"beta_gx\": [0.08, 0.12, 0.10, 0.15, 0.07, 0.11],\n            \"beta_gy\": [0.040, 0.060, 0.051, 0.072, 0.033, 0.057],\n            \"sigma_gy\": [0.020, 0.018, 0.022, 0.019, 0.021, 0.020]\n        },\n        'B': {\n            \"beta_gx\": [0.05, -0.04, 0.09, 0.12, 0.03, 0.07],\n            \"beta_gy\": [0.037, 0.007, 0.048, 0.054, 0.029, 0.042],\n            \"sigma_gy\": [0.020, 0.021, 0.019, 0.018, 0.022, 0.020]\n        },\n        'C': {\n            \"beta_gx\": [0.20, 0.15, 0.10, 0.05, 0.004],\n            \"beta_gy\": [0.080, 0.070, 0.045, 0.050, 0.010],\n            \"sigma_gy\": [0.015, 0.015, 0.016, 0.020, 0.020]\n        },\n        'D': {\n            \"beta_gx\": [0.10, 0.12, 0.09, 0.11, 0.08],\n            \"beta_gy\": [0.080, 0.052, 0.064, 0.056, 0.048],\n            \"sigma_gy\": [0.020, 0.020, 0.020, 0.020, 0.020]\n        }\n    }\n\n    all_results_str = []\n    # Process cases in alphabetical order to match output format\n    for key in sorted(test_cases.keys()):\n        case = test_cases[key]\n        result = calculate_mr_metrics(case[\"beta_gx\"], case[\"beta_gy\"], case[\"sigma_gy\"])\n        all_results_str.append(format_result_list(result))\n\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```", "id": "2404096"}, {"introduction": "A key step in any rigorous analysis is testing the robustness of the findings. This exercise introduces the leave-one-out method, a powerful sensitivity analysis to ensure that the overall causal estimate is not disproportionately driven by a single, potentially pleiotropic, genetic variant. By systematically removing each instrument and recalculating the effect, you can identify influential variants and gain confidence in your results. [@problem_id:2404032]", "problem": "You are given summary-level genetic association data for multiple sets of Single Nucleotide Polymorphism (SNP) instruments used to estimate a causal effect using Mendelian Randomization (MR). For each SNP $i$ in a set of $K$ instruments, you are provided four real numbers: the association with the exposure $b_{X,i}$, its standard error $s_{X,i}$, the association with the outcome $b_{Y,i}$, and its standard error $s_{Y,i}$. Consider the following model: the causal effect parameter $\\beta$ is defined as the unique minimizer of the weighted sum of squared residuals\n$$\nQ(\\beta) \\equiv \\sum_{i=1}^{K} w_i \\left(b_{Y,i} - \\beta\\, b_{X,i}\\right)^2,\n$$\nwhere the weight of instrument $i$ is $w_i = 1/s_{Y,i}^2$. Define the full-data estimator $\\hat{\\beta}$ as the minimizer of $Q(\\beta)$. For each index $j \\in \\{0,1,\\dots,K-1\\}$, define the leave-one-out subset estimator $\\hat{\\beta}_{(-j)}$ as the minimizer of the analogous objective computed on the subset of all instruments excluding index $j$. Define the absolute influence of instrument $j$ as\n$$\nI_j \\equiv \\left|\\hat{\\beta}_{(-j)} - \\hat{\\beta}\\right|.\n$$\nLet $j^\\star$ be the index achieving the maximum absolute influence, that is $j^\\star \\in \\arg\\max_{0 \\le j \\le K-1} I_j$. In case of a tie, choose the smallest index.\n\nYour task is to write a complete, runnable program that, for each instrument set in the test suite provided below, computes:\n- the index $j^\\star$ as a zero-based integer,\n- the full-data estimate $\\hat{\\beta}$,\n- the ordered list $\\left[\\hat{\\beta}_{(-0)}, \\hat{\\beta}_{(-1)}, \\dots, \\hat{\\beta}_{(-(K-1))}\\right]$.\n\nAll floating-point outputs must be rounded to exactly six digits after the decimal point. The final program output must aggregate the results for all test cases into a single line containing a list, where each test case contributes a list of the form $[j^\\star, \\hat{\\beta}, [\\hat{\\beta}_{(-0)}, \\dots, \\hat{\\beta}_{(-(K-1))}]]$. The exact output format is thus a single line:\n\"[ [case1_jstar,case1_beta,[case1_loo_list]], [case2_jstar,case2_beta,[case2_loo_list]], ... ]\"\nwith no spaces added beyond those shown by the default comma separators.\n\nTest suite (each case specifies $K$, followed by aligned arrays of $b_X$, $s_X$, $b_Y$, $s_Y$):\n\n- Case A:\n  - $K = 6$\n  - $b_X = [0.10, 0.08, 0.12, 0.15, 0.09, 0.11]$\n  - $s_X = [0.01, 0.01, 0.01, 0.01, 0.01, 0.01]$\n  - $b_Y = [0.052, 0.039, 0.063, 0.073, 0.045, 0.125]$\n  - $s_Y = [0.02, 0.02, 0.02, 0.02, 0.02, 0.02]$\n\n- Case B:\n  - $K = 2$\n  - $b_X = [0.10, 0.12]$\n  - $s_X = [0.01, 0.01]$\n  - $b_Y = [0.050, 0.150]$\n  - $s_Y = [0.02, 0.02]$\n\n- Case C:\n  - $K = 5$\n  - $b_X = [0.07, 0.05, 0.005, 0.06, 0.08]$\n  - $s_X = [0.01, 0.01, 0.02, 0.01, 0.01]$\n  - $b_Y = [0.022, 0.014, 0.002, 0.018, 0.054]$\n  - $s_Y = [0.015, 0.015, 0.015, 0.015, 0.015]$\n\n- Case D:\n  - $K = 4$\n  - $b_X = [0.10, 0.10, 0.10, 0.10]$\n  - $s_X = [0.01, 0.01, 0.01, 0.01]$\n  - $b_Y = [0.050, 0.050, 0.110, -0.010]$\n  - $s_Y = [0.02, 0.02, 0.02, 0.02]$\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes one list in the form described above. For example (illustrative only): \"[[0,0.123456,[0.120000,0.130000]], [1,0.500000,[0.600000,0.400000]]]\".\n- Do not print any additional text or spaces.", "solution": "The problem requires the implementation of an algorithm to compute causal effect estimates using the Inverse-Variance Weighted (IVW) method from Mendelian Randomization (MR), and to perform a leave-one-out (LOO) sensitivity analysis to identify the most influential instrument. The problem is scientifically valid, well-posed, and based on established statistical principles in computational biology.\n\nThe core of the problem is to find the parameter $\\beta$ that minimizes the weighted sum of squared residuals, a standard weighted least squares problem. The objective function is given as:\n$$\nQ(\\beta) \\equiv \\sum_{i=0}^{K-1} w_i \\left(b_{Y,i} - \\beta\\, b_{X,i}\\right)^2\n$$\nHere, the index $i$ runs from $0$ to $K-1$ to align with zero-based array indexing. The inputs for each of the $K$ instruments are its association with the exposure, $b_{X,i}$, and the outcome, $b_{Y,i}$. The weight for each instrument's contribution to the sum of squares is given by the inverse of the variance of its outcome association, $w_i = 1/s_{Y,i}^2$. The standard errors of the exposure associations, $s_{X,i}$, are provided but not used in this specific IVW model, which assumes no measurement error in the exposure associations.\n\nTo find the full-data estimator $\\hat{\\beta}$ that minimizes $Q(\\beta)$, we take the derivative of $Q(\\beta)$ with respect to $\\beta$ and set it to zero:\n$$\n\\frac{dQ(\\beta)}{d\\beta} = \\sum_{i=0}^{K-1} w_i \\cdot 2 \\left(b_{Y,i} - \\beta\\, b_{X,i}\\right) \\cdot (-b_{X,i}) = 0\n$$\n$$\n\\sum_{i=0}^{K-1} w_i b_{X,i} \\left(b_{Y,i} - \\beta\\, b_{X,i}\\right) = 0\n$$\n$$\n\\sum_{i=0}^{K-1} w_i b_{X,i} b_{Y,i} - \\beta \\sum_{i=0}^{K-1} w_i b_{X,i}^2 = 0\n$$\nSolving for $\\beta$ yields the closed-form solution for the full-data estimator $\\hat{\\beta}$:\n$$\n\\hat{\\beta} = \\frac{\\sum_{i=0}^{K-1} w_i b_{X,i} b_{Y,i}}{\\sum_{i=0}^{K-1} w_i b_{X,i}^2}\n$$\nThis expression is equivalent to the slope of a weighted linear regression of $b_Y$ on $b_X$ with the intercept constrained to zero.\n\nThe next step is to compute the leave-one-out (LOO) estimators, $\\hat{\\beta}_{(-j)}$, for each instrument $j \\in \\{0, 1, \\dots, K-1\\}$. The estimator $\\hat{\\beta}_{(-j)}$ is calculated using the same formula as $\\hat{\\beta}$, but with sums taken over all instruments except for the $j$-th one. An efficient way to compute this is to first calculate the total sums for the full-data estimator and then subtract the contribution of the $j$-th instrument.\nLet $S_{XY} = \\sum_{i=0}^{K-1} w_i b_{X,i} b_{Y,i}$ and $S_{XX} = \\sum_{i=0}^{K-1} w_i b_{X,i}^2$. The full-data estimator is $\\hat{\\beta} = S_{XY} / S_{XX}$.\nThe LOO estimator $\\hat{\\beta}_{(-j)}$ is then:\n$$\n\\hat{\\beta}_{(-j)} = \\frac{\\sum_{i \\neq j} w_i b_{X,i} b_{Y,i}}{\\sum_{i \\neq j} w_i b_{X,i}^2} = \\frac{S_{XY} - w_j b_{X,j} b_{Y,j}}{S_{XX} - w_j b_{X,j}^2}\n$$\n\nThe absolute influence of instrument $j$, denoted as $I_j$, is defined as the magnitude of the change in the estimate when that instrument is removed:\n$$\nI_j = \\left|\\hat{\\beta}_{(-j)} - \\hat{\\beta}\\right|\n$$\n\nThe final task is to find the index $j^\\star$ corresponding to the instrument with the maximum absolute influence.\n$$\nj^\\star = \\arg\\max_{0 \\le j \\le K-1} I_j\n$$\nIn case of a tie in influence values, the problem specifies that the smallest index $j$ should be chosen.\n\nThe overall algorithm for each test case is as follows:\n1.  Receive the input data: $K$, arrays $b_X$, $s_X$, $b_Y$, and $s_Y$.\n2.  Compute the weights $w_i = 1/s_{Y,i}^2$ for each instrument $i$.\n3.  Calculate the sufficient statistics for the full dataset: the numerator $S_{XY} = \\sum w_i b_{X,i} b_{Y,i}$ and the denominator $S_{XX} = \\sum w_i b_{X,i}^2$.\n4.  Compute the full-data estimate $\\hat{\\beta} = S_{XY} / S_{XX}$.\n5.  Iterate from $j=0$ to $K-1$:\n    a. Calculate the leave-one-out estimate $\\hat{\\beta}_{(-j)}$ by subtracting the $j$-th instrument's contribution from the total sums: $\\hat{\\beta}_{(-j)} = (S_{XY} - w_j b_{X,j} b_{Y,j}) / (S_{XX} - w_j b_{X,j}^2)$.\n    b. Store each $\\hat{\\beta}_{(-j)}$ in an ordered list.\n6.  Calculate the absolute influence $I_j = |\\hat{\\beta}_{(-j)} - \\hat{\\beta}|$ for all $j$.\n7.  Find the index $j^\\star$ which maximizes $I_j$, using the smallest index in case of a tie.\n8.  Round the floating-point values ($\\hat{\\beta}$ and all $\\hat{\\beta}_{(-j)}$) to six decimal places.\n9.  Format the results for the test case as $[j^\\star, \\hat{\\beta}, [\\hat{\\beta}_{(-0)}, \\dots, \\hat{\\beta}_{(-(K-1))}]]$ and aggregate them for all test cases into a single output line as specified.\nThis procedure will be implemented in Python using the `numpy` library for efficient array computations.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Mendelian Randomization problem for a suite of test cases.\n\n    For each case, it computes the full-data causal effect estimate (`beta_hat`),\n    the leave-one-out estimates (`loo_betas`), and the index of the most\n    influential instrument (`j_star`).\n    \"\"\"\n    test_cases = [\n        {\n            \"K\": 6,\n            \"b_X\": [0.10, 0.08, 0.12, 0.15, 0.09, 0.11],\n            \"s_X\": [0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n            \"b_Y\": [0.052, 0.039, 0.063, 0.073, 0.045, 0.125],\n            \"s_Y\": [0.02, 0.02, 0.02, 0.02, 0.02, 0.02],\n        },\n        {\n            \"K\": 2,\n            \"b_X\": [0.10, 0.12],\n            \"s_X\": [0.01, 0.01],\n            \"b_Y\": [0.050, 0.150],\n            \"s_Y\": [0.02, 0.02],\n        },\n        {\n            \"K\": 5,\n            \"b_X\": [0.07, 0.05, 0.005, 0.06, 0.08],\n            \"s_X\": [0.01, 0.01, 0.02, 0.01, 0.01],\n            \"b_Y\": [0.022, 0.014, 0.002, 0.018, 0.054],\n            \"s_Y\": [0.015, 0.015, 0.015, 0.015, 0.015],\n        },\n        {\n            \"K\": 4,\n            \"b_X\": [0.10, 0.10, 0.10, 0.10],\n            \"s_X\": [0.01, 0.01, 0.01, 0.01],\n            \"b_Y\": [0.050, 0.050, 0.110, -0.010],\n            \"s_Y\": [0.02, 0.02, 0.02, 0.02],\n        },\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        b_x = np.array(case[\"b_X\"])\n        b_y = np.array(case[\"b_Y\"])\n        s_y = np.array(case[\"s_Y\"])\n\n        # Calculate weights w_i = 1/s_{Y,i}^2\n        w = 1.0 / (s_y**2)\n\n        # Calculate terms for the full-data estimator\n        num_full = np.sum(w * b_x * b_y)\n        den_full = np.sum(w * b_x**2)\n\n        # Handle division by zero if all b_x are zero, though not expected\n        if den_full == 0:\n            beta_hat = np.nan\n        else:\n            beta_hat = num_full / den_full\n\n        # Calculate leave-one-out (LOO) estimators\n        # Individual contributions to numerator and denominator\n        num_i = w * b_x * b_y\n        den_i = w * b_x**2\n\n        # Subtract individual contributions from the full sums\n        loo_nums = num_full - num_i\n        loo_dens = den_full - den_i\n        \n        # Avoid division by zero in LOO calculation\n        # If loo_den is 0, the corresponding beta is undefined. This can happen\n        # if after removing one instrument, all remaining b_x are zero.\n        with np.errstate(divide='ignore', invalid='ignore'):\n            loo_betas = np.divide(loo_nums, loo_dens)\n            loo_betas[np.isinf(loo_betas)] = np.nan\n\n        # Calculate absolute influence I_j = |beta_{(-j)} - beta|\n        influences = np.abs(loo_betas - beta_hat)\n\n        # Find index j_star with max influence.\n        # np.argmax returns the first occurrence in case of a tie, satisfying the rule.\n        j_star = np.nanargmax(influences) if not np.all(np.isnan(influences)) else -1\n\n        # Format results for this case.\n        # Rounding is handled by string formatting to 6 decimal places.\n        beta_hat_str = f\"{beta_hat:.6f}\"\n        loo_betas_str_list = [f\"{b:.6f}\" for b in loo_betas]\n        loo_list_str = f\"[{','.join(loo_betas_str_list)}]\"\n        case_result_str = f\"[{j_star},{beta_hat_str},{loo_list_str}]\"\n        \n        all_results.append(case_result_str)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "2404032"}]}