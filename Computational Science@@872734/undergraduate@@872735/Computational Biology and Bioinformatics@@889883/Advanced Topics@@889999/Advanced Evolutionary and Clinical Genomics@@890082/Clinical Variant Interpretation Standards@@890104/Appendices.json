{"hands_on_practices": [{"introduction": "The ACMG/AMP guidelines provide a structured framework for variant classification, but their application relies on a complex set of evidence combination rules. To implement these standards computationally, we must first translate this expert logic into a formal, deterministic algorithm [@problem_id:2378922]. This practice challenges you to build a classifier from the ground up, teaching you how to handle evidence counting, rule application, and conflict resolution, which are core skills in clinical bioinformatics.", "problem": "You are given the clinical variant interpretation framework of the American College of Medical Genetics and Genomics (ACMG). The evidence schema includes the following mutually exclusive pathogenic-leaning categories: Very Strong, Strong, Moderate, and Supporting; and benign-leaning categories: Stand-alone, Strong, and Supporting. In the ACMG schema, individual evidence codes belong to these categories as follows: Pathogenic-leaning Very Strong contains exactly the code $PVS1$; Pathogenic-leaning Strong contains $PS1,PS2,PS3,PS4$; Pathogenic-leaning Moderate contains $PM1,PM2,PM3,PM4,PM5,PM6$; Pathogenic-leaning Supporting contains $PP1,PP2,PP3,PP4,PP5$; Benign Stand-alone contains $BA1$; Benign Strong contains $BS1,BS2,BS3,BS4$; Benign Supporting contains $BP1,BP2,BP3,BP4,BP5,BP6,BP7$.\n\nFormalize the classification rules as a first-order logic specification over a universe $\\mathcal{V}$ of variants. For each variant $v \\in \\mathcal{V}$, define unary predicates $E_c(v)$ meaning “variant $v$ has evidence code $c$.” Define the following counting functions:\n- $n_{VS}(v) = \\begin{cases}1 & \\text{if } E_{PVS1}(v) \\\\ 0 & \\text{otherwise}\\end{cases}$,\n- $n_{S}^{\\mathrm{path}}(v) = \\sum_{c \\in \\{PS1,PS2,PS3,PS4\\}} \\mathbf{1}[E_c(v)]$,\n- $n_{M}(v) = \\sum_{c \\in \\{PM1,PM2,PM3,PM4,PM5,PM6\\}} \\mathbf{1}[E_c(v)]$,\n- $n_{P}^{\\mathrm{supp}}(v) = \\sum_{c \\in \\{PP1,PP2,PP3,PP4,PP5\\}} \\mathbf{1}[E_c(v)]$,\n- $n_{BA1}(v) = \\begin{cases}1 & \\text{if } E_{BA1}(v) \\\\ 0 & \\text{otherwise}\\end{cases}$,\n- $n_{S}^{\\mathrm{benign}}(v) = \\sum_{c \\in \\{BS1,BS2,BS3,BS4\\}} \\mathbf{1}[E_c(v)]$,\n- $n_{P}^{\\mathrm{benign}}(v) = \\sum_{c \\in \\{BP1,BP2,BP3,BP4,BP5,BP6,BP7\\}} \\mathbf{1}[E_c(v)]$.\n\nDefine classification predicates $\\mathrm{Path}(v)$, $\\mathrm{LikelyPath}(v)$, $\\mathrm{Benign}(v)$, and $\\mathrm{LikelyBenign}(v)$ according to the ACMG combination rules:\n\n- $\\mathrm{Path}(v)$ holds if and only if any of the following disjunctions is true:\n  - $n_{VS}(v) \\ge 1 \\wedge n_{S}^{\\mathrm{path}}(v) \\ge 1$,\n  - $n_{VS}(v) \\ge 1 \\wedge n_{M}(v) \\ge 2$,\n  - $n_{VS}(v) \\ge 1 \\wedge n_{M}(v) \\ge 1 \\wedge n_{P}^{\\mathrm{supp}}(v) \\ge 1$,\n  - $n_{VS}(v) \\ge 1 \\wedge n_{P}^{\\mathrm{supp}}(v) \\ge 2$,\n  - $n_{S}^{\\mathrm{path}}(v) \\ge 2$,\n  - $n_{S}^{\\mathrm{path}}(v) \\ge 1 \\wedge n_{M}(v) \\ge 3$,\n  - $n_{S}^{\\mathrm{path}}(v) \\ge 1 \\wedge n_{M}(v) \\ge 2 \\wedge n_{P}^{\\mathrm{supp}}(v) \\ge 2$,\n  - $n_{S}^{\\mathrm{path}}(v) \\ge 1 \\wedge n_{M}(v) \\ge 1 \\wedge n_{P}^{\\mathrm{supp}}(v) \\ge 4$,\n  - $n_{M}(v) \\ge 5$.\n\n- $\\mathrm{LikelyPath}(v)$ holds if and only if any of the following disjunctions is true (and $\\mathrm{Path}(v)$ is false):\n  - $n_{VS}(v) \\ge 1 \\wedge n_{M}(v) \\ge 1$,\n  - $n_{S}^{\\mathrm{path}}(v) \\ge 1 \\wedge n_{M}(v) \\in \\{1,2\\}$,\n  - $n_{S}^{\\mathrm{path}}(v) \\ge 1 \\wedge n_{P}^{\\mathrm{supp}}(v) \\ge 2$,\n  - $n_{M}(v) \\ge 3$,\n  - $n_{M}(v) \\ge 2 \\wedge n_{P}^{\\mathrm{supp}}(v) \\ge 2$,\n  - $n_{M}(v) \\ge 1 \\wedge n_{P}^{\\mathrm{supp}}(v) \\ge 4$.\n\n- $\\mathrm{Benign}(v)$ holds if and only if $n_{BA1}(v) \\ge 1$ or $n_{S}^{\\mathrm{benign}}(v) \\ge 2$.\n\n- $\\mathrm{LikelyBenign}(v)$ holds if and only if $n_{S}^{\\mathrm{benign}}(v) \\ge 1 \\wedge n_{P}^{\\mathrm{benign}}(v) \\ge 1$ or $n_{P}^{\\mathrm{benign}}(v) \\ge 2$, provided $\\mathrm{Benign}(v)$ is false.\n\nResolve conflicting evidence with the following decision logic to produce a single label per variant:\n- If $n_{BA1}(v) \\ge 1$, classify as Benign.\n- Else if $\\mathrm{Path}(v)$ and $\\lnot(\\mathrm{Benign}(v) \\lor \\mathrm{LikelyBenign}(v))$, classify as Pathogenic.\n- Else if $\\mathrm{Benign}(v)$ and $\\lnot(\\mathrm{Path}(v) \\lor \\mathrm{LikelyPath}(v))$, classify as Benign.\n- Else if $\\mathrm{LikelyPath}(v)$ and $\\lnot(\\mathrm{Path}(v) \\lor \\mathrm{Benign}(v) \\lor \\mathrm{LikelyBenign}(v))$, classify as Likely Pathogenic.\n- Else if $\\mathrm{LikelyBenign}(v)$ and $\\lnot(\\mathrm{Path}(v) \\lor \\mathrm{LikelyPath}(v) \\lor \\mathrm{Benign}(v))$, classify as Likely Benign.\n- Else, classify as Variant of Uncertain Significance.\n\nEncode the final classification as an integer function $f:\\mathcal{V}\\rightarrow \\{0,1,2,3,4\\}$ given by the mapping: Benign $\\mapsto 0$, Likely Benign $\\mapsto 1$, Variant of Uncertain Significance $\\mapsto 2$, Likely Pathogenic $\\mapsto 3$, Pathogenic $\\mapsto 4$.\n\nImplement a program that, for a fixed test suite of variants $v_1,\\dots,v_{12}$ with the specified evidence codes below, computes $f(v_i)$ for each and outputs the results in a single line as a comma-separated list enclosed in square brackets.\n\nUse the following test suite, in order:\n- Test case $1$: $\\{PVS1,PM2\\}$.\n- Test case $2$: $\\{PVS1,PP3,PP5\\}$.\n- Test case $3$: $\\{BA1\\}$.\n- Test case $4$: $\\{BP1,BP4\\}$.\n- Test case $5$: $\\{BS1,BS2\\}$.\n- Test case $6$: $\\{PS3,PM1,PP3,PP4,PP2\\}$.\n- Test case $7$: $\\{PM1,PM2,PM5\\}$.\n- Test case $8$: $\\{PS1,BS1\\}$.\n- Test case $9$: $\\{PM1,PP1,PP2,PP3,PP4\\}$.\n- Test case $10$: $\\{PS1,PS2\\}$.\n- Test case $11$: $\\{PVS1,PM2,BP4\\}$.\n- Test case $12$: $\\{BS1,BP1,PS1,PP1\\}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $\"[x_1,x_2,\\dots,x_{12}]\"$), where each $x_i$ is the integer $f(v_i)$ in the order specified above. No other output is permitted.", "solution": "We formalize the American College of Medical Genetics and Genomics (ACMG) evidence-based classification as a first-order logical system augmented with counting. Let $\\mathcal{V}$ denote the set of variants and let $E_c(v)$ be a unary predicate meaning variant $v$ has evidence code $c$. We induce counts of categories via summation over indicator predicates.\n\nFor each $v \\in \\mathcal{V}$, we define the counts:\n- $n_{VS}(v) = \\mathbf{1}[E_{PVS1}(v)]$,\n- $n_{S}^{\\mathrm{path}}(v) = \\sum_{c \\in \\{PS1,PS2,PS3,PS4\\}} \\mathbf{1}[E_c(v)]$,\n- $n_{M}(v) = \\sum_{c \\in \\{PM1,PM2,PM3,PM4,PM5,PM6\\}} \\mathbf{1}[E_c(v)]$,\n- $n_{P}^{\\mathrm{supp}}(v) = \\sum_{c \\in \\{PP1,PP2,PP3,PP4,PP5\\}} \\mathbf{1}[E_c(v)]$,\n- $n_{BA1}(v) = \\mathbf{1}[E_{BA1}(v)]$,\n- $n_{S}^{\\mathrm{benign}}(v) = \\sum_{c \\in \\{BS1,BS2,BS3,BS4\\}} \\mathbf{1}[E_c(v)]$,\n- $n_{P}^{\\mathrm{benign}}(v) = \\sum_{c \\in \\{BP1,BP2,BP3,BP4,BP5,BP6,BP7\\}} \\mathbf{1}[E_c(v)]$.\n\nThe core ACMG combination rules can be written as Boolean formulas. For the Pathogenic predicate:\n$\\mathrm{Path}(v)$ if and only if one of the following holds:\n- $n_{VS}(v) \\ge 1 \\wedge n_{S}^{\\mathrm{path}}(v) \\ge 1$,\n- $n_{VS}(v) \\ge 1 \\wedge n_{M}(v) \\ge 2$,\n- $n_{VS}(v) \\ge 1 \\wedge n_{M}(v) \\ge 1 \\wedge n_{P}^{\\mathrm{supp}}(v) \\ge 1$,\n- $n_{VS}(v) \\ge 1 \\wedge n_{P}^{\\mathrm{supp}}(v) \\ge 2$,\n- $n_{S}^{\\mathrm{path}}(v) \\ge 2$,\n- $n_{S}^{\\mathrm{path}}(v) \\ge 1 \\wedge n_{M}(v) \\ge 3$,\n- $n_{S}^{\\mathrm{path}}(v) \\ge 1 \\wedge n_{M}(v) \\ge 2 \\wedge n_{P}^{\\mathrm{supp}}(v) \\ge 2$,\n- $n_{S}^{\\mathrm{path}}(v) \\ge 1 \\wedge n_{M}(v) \\ge 1 \\wedge n_{P}^{\\mathrm{supp}}(v) \\ge 4$,\n- $n_{M}(v) \\ge 5$.\n\nFor Likely Pathogenic, the rules are weaker thresholds and explicitly exclude cases already satisfying Pathogenic:\n$\\mathrm{LikelyPath}(v)$ if and only if $\\lnot\\mathrm{Path}(v)$ and one of:\n- $n_{VS}(v) \\ge 1 \\wedge n_{M}(v) \\ge 1$,\n- $n_{S}^{\\mathrm{path}}(v) \\ge 1 \\wedge n_{M}(v) \\in \\{1,2\\}$,\n- $n_{S}^{\\mathrm{path}}(v) \\ge 1 \\wedge n_{P}^{\\mathrm{supp}}(v) \\ge 2$,\n- $n_{M}(v) \\ge 3$,\n- $n_{M}(v) \\ge 2 \\wedge n_{P}^{\\mathrm{supp}}(v) \\ge 2$,\n- $n_{M}(v) \\ge 1 \\wedge n_{P}^{\\mathrm{supp}}(v) \\ge 4$.\n\nFor Benign:\n$\\mathrm{Benign}(v)$ if and only if $n_{BA1}(v) \\ge 1$ or $n_{S}^{\\mathrm{benign}}(v) \\ge 2$.\n\nFor Likely Benign:\n$\\mathrm{LikelyBenign}(v)$ if and only if $\\lnot\\mathrm{Benign}(v)$ and either $n_{S}^{\\mathrm{benign}}(v) \\ge 1 \\wedge n_{P}^{\\mathrm{benign}}(v) \\ge 1$ or $n_{P}^{\\mathrm{benign}}(v) \\ge 2$.\n\nConflicting evidence must be resolved to a single label. In the absence of a quantitative framework, a conservative resolution is to assign Variant of Uncertain Significance when both benign-leaning and pathogenic-leaning conclusions are simultaneously supported at any of the decision thresholds, except where $BA1$ is present (which is stand-alone Benign). The decision sequence can be encoded as:\n- If $n_{BA1}(v) \\ge 1$, return Benign.\n- Else if $\\mathrm{Path}(v) \\wedge \\lnot(\\mathrm{Benign}(v) \\lor \\mathrm{LikelyBenign}(v))$, return Pathogenic.\n- Else if $\\mathrm{Benign}(v) \\wedge \\lnot(\\mathrm{Path}(v) \\lor \\mathrm{LikelyPath}(v))$, return Benign.\n- Else if $\\mathrm{LikelyPath}(v) \\wedge \\lnot(\\mathrm{Path}(v) \\lor \\mathrm{Benign}(v) \\lor \\mathrm{LikelyBenign}(v))$, return Likely Pathogenic.\n- Else if $\\mathrm{LikelyBenign}(v) \\wedge \\lnot(\\mathrm{Path}(v) \\lor \\mathrm{LikelyPath}(v) \\lor \\mathrm{Benign}(v))$, return Likely Benign.\n- Else return Variant of Uncertain Significance.\n\nDefine the final integer-encoded function $f$ with Benign $\\mapsto 0$, Likely Benign $\\mapsto 1$, Variant of Uncertain Significance $\\mapsto 2$, Likely Pathogenic $\\mapsto 3$, Pathogenic $\\mapsto 4$.\n\nApplying these rules to the specified test suite yields:\n- Test case $1$: $\\{PVS1,PM2\\}$ gives $n_{VS}=1$, $n_{M}=1$, so Likely Pathogenic; thus $f=3$.\n- Test case $2$: $\\{PVS1,PP3,PP5\\}$ gives $n_{VS}=1$, $n_{P}^{\\mathrm{supp}}=2$, so Pathogenic; thus $f=4$.\n- Test case $3$: $\\{BA1\\}$ triggers Benign stand-alone; thus $f=0$.\n- Test case $4$: $\\{BP1,BP4\\}$ gives $n_{P}^{\\mathrm{benign}}=2$, so Likely Benign; thus $f=1$.\n- Test case $5$: $\\{BS1,BS2\\}$ gives $n_{S}^{\\mathrm{benign}}=2$, so Benign; thus $f=0$.\n- Test case $6$: $\\{PS3,PM1,PP3,PP4,PP2\\}$ gives $n_{S}^{\\mathrm{path}}=1$, $n_{M}=1$, $n_{P}^{\\mathrm{supp}}=3$; this satisfies Likely Pathogenic via $n_{S}^{\\mathrm{path}} \\ge 1 \\wedge n_{P}^{\\mathrm{supp}} \\ge 2$ but not Pathogenic; thus $f=3$.\n- Test case $7$: $\\{PM1,PM2,PM5\\}$ gives $n_{M}=3$, so Likely Pathogenic; thus $f=3$.\n- Test case $8$: $\\{PS1,BS1\\}$ does not meet any decision thresholds and has conflicting evidence; thus Variant of Uncertain Significance; $f=2$.\n- Test case $9$: $\\{PM1,PP1,PP2,PP3,PP4\\}$ gives $n_{M}=1$, $n_{P}^{\\mathrm{supp}}=4$; this satisfies Likely Pathogenic via $n_{M} \\ge 1 \\wedge n_{P}^{\\mathrm{supp}} \\ge 4$ but not Pathogenic; thus $f=3$.\n- Test case $10$: $\\{PS1,PS2\\}$ gives $n_{S}^{\\mathrm{path}}=2$; Pathogenic; thus $f=4$.\n- Test case $11$: $\\{PVS1,PM2,BP4\\}$ gives Likely Pathogenic via $n_{VS} \\ge 1 \\wedge n_{M} \\ge 1$; benign evidence is insufficient for Likely Benign; thus $f=3$.\n- Test case $12$: $\\{BS1,BP1,PS1,PP1\\}$ gives Likely Benign via $n_{S}^{\\mathrm{benign}} \\ge 1 \\wedge n_{P}^{\\mathrm{benign}} \\ge 1$; pathogenic side does not reach a threshold, so there is no conflict; thus $f=1$.\n\nTherefore, the output, in order, is the list $[3,4,0,1,0,3,3,2,3,4,3,1]$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# ACMG evidence code sets by category\nPVS1_CODE = {\"PVS1\"}\nPS_CODES = {\"PS1\", \"PS2\", \"PS3\", \"PS4\"}\nPM_CODES = {\"PM1\", \"PM2\", \"PM3\", \"PM4\", \"PM5\", \"PM6\"}\nPP_CODES = {\"PP1\", \"PP2\", \"PP3\", \"PP4\", \"PP5\"}\nBA1_CODE = {\"BA1\"}\nBS_CODES = {\"BS1\", \"BS2\", \"BS3\", \"BS4\"}\nBP_CODES = {\"BP1\", \"BP2\", \"BP3\", \"BP4\", \"BP5\", \"BP6\", \"BP7\"}\n\n# Mapping of final labels to integers:\n# Benign -> 0; Likely Benign -> 1; VUS -> 2; Likely Pathogenic -> 3; Pathogenic -> 4\nLABELS = {\n    \"Benign\": 0,\n    \"Likely Benign\": 1,\n    \"VUS\": 2,\n    \"Likely Pathogenic\": 3,\n    \"Pathogenic\": 4,\n}\n\ndef counts(codes):\n    # Deduplicate codes for counting distinct ACMG criteria\n    s = set(codes)\n    n_vs = 1 if \"PVS1\" in s else 0\n    n_ps = sum(1 for c in s if c in PS_CODES)\n    n_pm = sum(1 for c in s if c in PM_CODES)\n    n_pp = sum(1 for c in s if c in PP_CODES)\n    n_ba1 = 1 if \"BA1\" in s else 0\n    n_bs = sum(1 for c in s if c in BS_CODES)\n    n_bp = sum(1 for c in s if c in BP_CODES)\n    return n_vs, n_ps, n_pm, n_pp, n_ba1, n_bs, n_bp\n\ndef classify_variant(codes):\n    n_vs, n_ps, n_pm, n_pp, n_ba1, n_bs, n_bp = counts(codes)\n\n    # Benign/Likely Benign\n    is_ba1 = n_ba1 >= 1\n    is_benign = is_ba1 or (n_bs >= 2)\n    is_likely_benign = (not is_benign) and ((n_bs >= 1 and n_bp >= 1) or (n_bp >= 2))\n\n    # Pathogenic/Likely Pathogenic\n    is_pathogenic = (\n        (n_vs >= 1 and n_ps >= 1)\n        or (n_vs >= 1 and n_pm >= 2)\n        or (n_vs >= 1 and n_pm >= 1 and n_pp >= 1)\n        or (n_vs >= 1 and n_pp >= 2)\n        or (n_ps >= 2)\n        or (n_ps >= 1 and n_pm >= 3)\n        or (n_ps >= 1 and n_pm >= 2 and n_pp >= 2)\n        or (n_ps >= 1 and n_pm >= 1 and n_pp >= 4)\n        or (n_pm >= 5)\n    )\n\n    is_likely_pathogenic = (not is_pathogenic) and (\n        (n_vs >= 1 and n_pm >= 1)\n        or (n_ps >= 1 and (n_pm in (1, 2)))\n        or (n_ps >= 1 and n_pp >= 2)\n        or (n_pm >= 3)\n        or (n_pm >= 2 and n_pp >= 2)\n        or (n_pm >= 1 and n_pp >= 4)\n    )\n\n    # Decision logic with conflict resolution\n    if is_ba1:\n        return LABELS[\"Benign\"]\n    if is_pathogenic and not (is_benign or is_likely_benign):\n        return LABELS[\"Pathogenic\"]\n    if is_benign and not (is_pathogenic or is_likely_pathogenic):\n        return LABELS[\"Benign\"]\n    if is_likely_pathogenic and not (is_pathogenic or is_benign or is_likely_benign):\n        return LABELS[\"Likely Pathogenic\"]\n    if is_likely_benign and not (is_pathogenic or is_likely_pathogenic or is_benign):\n        return LABELS[\"Likely Benign\"]\n    return LABELS[\"VUS\"]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        [\"PVS1\", \"PM2\"],  # 1\n        [\"PVS1\", \"PP3\", \"PP5\"],  # 2\n        [\"BA1\"],  # 3\n        [\"BP1\", \"BP4\"],  # 4\n        [\"BS1\", \"BS2\"],  # 5\n        [\"PS3\", \"PM1\", \"PP3\", \"PP4\", \"PP2\"],  # 6\n        [\"PM1\", \"PM2\", \"PM5\"],  # 7\n        [\"PS1\", \"BS1\"],  # 8\n        [\"PM1\", \"PP1\", \"PP2\", \"PP3\", \"PP4\"],  # 9\n        [\"PS1\", \"PS2\"],  # 10\n        [\"PVS1\", \"PM2\", \"BP4\"],  # 11\n        [\"BS1\", \"BP1\", \"PS1\", \"PP1\"],  # 12\n    ]\n\n    results = []\n    for case in test_cases:\n        result = classify_variant(case)\n        results.append(result)\n\n    # Final print statement in the exact required format (no spaces).\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2378922"}, {"introduction": "While rule-based systems provide consistency, they must be applied with critical oversight, as general rules can have important exceptions. The BA1 criterion, which classifies common variants as benign, is a prime example; its application can be misleading for recessive diseases where high carrier frequencies are expected [@problem_id:2378900]. In this exercise, you will use a population genetics model to derive a disease-specific upper bound for a variant's allele frequency, learning to quantitatively assess when the BA1 rule may be inappropriate.", "problem": "You are asked to formalize when application of the American College of Medical Genetics and Genomics (ACMG) evidence code BA1 (the “common variant” benign rule) could be misleading for clinical variant interpretation. Consider a single bi-allelic locus with population allele frequency $f \\in [0,1]$. A laboratory uses a fixed BA1 decision threshold $\\tau \\in (0,1)$: BA1 would be applied whenever $f \\ge \\tau$. For a specific Mendelian condition, you are given the following parameters: disease prevalence $p \\in (0,1)$, penetrance $r \\in (0,1]$, gene-level contribution $h \\in (0,1]$ (the proportion of all cases attributable to the gene), and an upper bound on the variant’s allelic contribution $a \\in (0,1]$ (the maximum proportion of the gene’s cases attributable to this single variant). The mode of inheritance $m$ is either Autosomal Recessive (AR) or Autosomal Dominant (AD). Assume Hardy–Weinberg Equilibrium (HWE), the rare-allele approximation for the AD model, and that the case fraction attributable to the variant equals the product $p \\cdot h \\cdot a$.\n\nDefine the “maximum allele frequency compatible with pathogenicity” under the provided model, $q_{\\max}(m)$, as the largest value of the population allele frequency $q$ such that the expected frequency of affected individuals due to the variant does not exceed the variant-attributable disease burden. Concretely, under the Autosomal Recessive (AR) model, affected individuals arise primarily from homozygotes, whose frequency under HWE is $q^2$, and penetrance $r$ scales observed disease; under the Autosomal Dominant (AD) model with the rare-allele approximation, affected individuals arise primarily from heterozygotes of expected frequency $2q$ and penetrance $r$ scales observed disease. Using these governing relationships, $q_{\\max}(m)$ is the solution obtained by equating the variant’s expected contribution under the model to $p \\cdot h \\cdot a$.\n\nYour task is to determine, for each provided case, whether BA1 “might be misleading.” For this problem, define the flag as a boolean that is true if and only if both conditions hold: $(\\mathrm{i})$ BA1 would be applied for the observed frequency, i.e., $f \\ge \\tau$, and $(\\mathrm{ii})$ the observed frequency does not exceed the model-consistent maximum, i.e., $f \\le q_{\\max}(m)$. Otherwise, the flag is false.\n\nImplement a program that, for each test case below, computes this flag and outputs all results in a single line as a comma-separated list enclosed in square brackets, preserving the order of cases. No units are required because all quantities are proportions in $[0,1]$.\n\nUse the following test suite. Each case is a tuple $(m, p, r, h, a, \\tau, f)$ with the parameters defined above:\n- Case A: (AR, p=0.004, r=1.0, h=0.5, a=0.5, $\\tau$=0.01, f=0.02)\n- Case B: (AR, p=0.0001, r=1.0, h=1.0, a=1.0, $\\tau$=0.01, f=0.02)\n- Case C: (AR, p=0.004, r=1.0, h=0.5, a=0.5, $\\tau$=0.03, f=0.02)\n- Case D: (AD, p=0.001, r=0.2, h=1.0, a=0.5, $\\tau$=0.0008, f=0.001)\n- Case E: (AR, p=0.0004, r=1.0, h=1.0, a=1.0, $\\tau$=0.02, f=0.02)\n- Case F: (AD, p=0.01, r=0.5, h=0.1, a=0.05, $\\tau$=0.0001, f=0.0002)\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[x_1,x_2,\\ldots,x_k]$), where each $x_i$ is either true or false, corresponding to Cases A through F in order.", "solution": "The problem requires a formal validation of its premises before a solution is attempted.\n\n### Step 1: Extract Givens\nThe provided parameters and definitions are as follows:\n- Population allele frequency of a variant: $f \\in [0,1]$.\n- BA1 decision threshold: $\\tau \\in (0,1)$. The BA1 rule is applied if $f \\ge \\tau$.\n- Disease prevalence: $p \\in (0,1)$.\n- Variant penetrance: $r \\in (0,1]$.\n- Gene-level contribution to disease: $h \\in (0,1]$.\n- Variant's allelic contribution to the gene's cases: $a \\in (0,1]$.\n- Mode of inheritance: $m \\in \\{\\text{Autosomal Recessive (AR), Autosomal Dominant (AD)}\\}$.\n- Assumptions: Hardy–Weinberg Equilibrium (HWE) holds, and the rare-allele approximation is used for the AD model.\n- The fraction of cases attributable to the variant is defined as the product $p \\cdot h \\cdot a$.\n- The \"maximum allele frequency compatible with pathogenicity,\" $q_{\\max}(m)$, is the largest allele frequency $q$ where the expected frequency of affected individuals due to the variant does not exceed the variant-attributable disease burden.\n- The governing relationships for the expected frequency of affected individuals for a variant with allele frequency $q$ and penetrance $r$ are:\n    - For AR: $q^2 r$.\n    - For AD (with rare-allele approximation): $2qr$.\n- The definition of the \"misleading\" flag is a boolean that is true if and only if two conditions are met:\n    1. $f \\ge \\tau$ (BA1 rule is applied).\n    2. $f \\le q_{\\max}(m)$ (the observed frequency is compatible with pathogenicity under the model).\n- The test cases provided are:\n    - Case A: $(m=\\text{AR},\\, p=0.004,\\, r=1.0,\\, h=0.5,\\, a=0.5,\\, \\tau=0.01,\\, f=0.02)$\n    - Case B: $(m=\\text{AR},\\, p=0.0001,\\, r=1.0,\\, h=1.0,\\, a=1.0,\\, \\tau=0.01,\\, f=0.02)$\n    - Case C: $(m=\\text{AR},\\, p=0.004,\\, r=1.0,\\, h=0.5,\\, a=0.5,\\, \\tau=0.03,\\, f=0.02)$\n    - Case D: $(m=\\text{AD},\\, p=0.001,\\, r=0.2,\\, h=1.0,\\, a=0.5,\\, \\tau=0.0008,\\, f=0.001)$\n    - Case E: $(m=\\text{AR},\\, p=0.0004,\\, r=1.0,\\, h=1.0,\\, a=1.0,\\, \\tau=0.02,\\, f=0.02)$\n    - Case F: $(m=\\text{AD},\\, p=0.01,\\, r=0.5,\\, h=0.1,\\, a=0.05,\\, \\tau=0.0001,\\, f=0.0002)$\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is subjected to validation against the specified criteria.\n- **Scientifically Grounded**: The problem is based on fundamental principles of population genetics, specifically the Hardy-Weinberg principle, and Mendelian inheritance. The parameters $p, r, h, a, f$ are standard metrics in medical and population genetics. The model, though simplified, provides a scientifically reasonable framework for estimating the maximum allele frequency of a pathogenic variant. The formulation does not violate any known scientific laws and is directly relevant to the field of computational biology and bioinformatics.\n- **Well-Posed**: The problem is clearly structured. It provides all necessary definitions, equations, and data for each test case. The objective is to compute a boolean flag based on a set of unambiguous conditions. A unique solution exists for each test case.\n- **Objective**: The problem is expressed in precise, mathematical language. It is free of ambiguity, subjectivity, or opinion-based claims.\n\nThe problem exhibits none of the specified flaws (e.g., factual unsoundness, incompleteness, contradiction, or poor structure). It is a self-contained, formalizable, and scientifically valid problem.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be provided.\n\n### Solution Derivation\nThe task is to determine if applying the ACMG BA1 criterion is \"misleading\" for a given set of parameters. This is defined as true if and only if $f \\ge \\tau$ and $f \\le q_{\\max}(m)$. The core of the problem is to derive and compute $q_{\\max}(m)$.\n\nThe quantity $q_{\\max}(m)$ represents the maximum allele frequency a variant can have while still being consistent with causing a certain fraction of a Mendelian disease. This maximum is found by equating the expected number of affected individuals from the variant to the total disease burden attributed to that variant.\n\nThe variant-attributable disease burden, which we denote as $B_v$, is given as:\n$$ B_v = p \\cdot h \\cdot a $$\nwhere $p$ is disease prevalence, $h$ is the gene-level contribution, and $a$ is the variant's allelic contribution.\n\nThe expected frequency of affected individuals, $A(q, m, r)$, depends on the mode of inheritance $m$, the allele frequency $q$, and the penetrance $r$.\n\n**1. Autosomal Recessive (AR) Model**\nFor an autosomal recessive condition, affected individuals are predominantly homozygotes for the pathogenic allele. Under Hardy-Weinberg Equilibrium, the frequency of homozygotes is $q^2$. With penetrance $r$, the frequency of affected individuals is:\n$$ A(q, \\text{AR}, r) = q^2 r $$\nTo find $q_{\\max}(\\text{AR})$, we set $A(q_{\\max}, \\text{AR}, r) = B_v$:\n$$ (q_{\\max}(\\text{AR}))^2 r = p \\cdot h \\cdot a $$\nSolving for $q_{\\max}(\\text{AR})$:\n$$ q_{\\max}(\\text{AR}) = \\sqrt{\\frac{p \\cdot h \\cdot a}{r}} $$\n\n**2. Autosomal Dominant (AD) Model**\nFor an autosomal dominant condition, and using the rare-allele approximation ($q \\ll 1$), affected individuals are predominantly heterozygotes. The frequency of heterozygotes under HWE is $2q(1-q)$, which approximates to $2q$ for small $q$. With penetrance $r$, the frequency of affected individuals is:\n$$ A(q, \\text{AD}, r) \\approx 2qr $$\nTo find $q_{\\max}(\\text{AD})$, we set $A(q_{\\max}, \\text{AD}, r) = B_v$:\n$$ 2q_{\\max}(\\text{AD}) r = p \\cdot h \\cdot a $$\nSolving for $q_{\\max}(\\text{AD})$:\n$$ q_{\\max}(\\text{AD}) = \\frac{p \\cdot h \\cdot a}{2r} $$\n\nThe \"misleading\" flag is then computed by evaluating the logical expression $(f \\ge \\tau) \\land (f \\le q_{\\max})$.\n\n### Calculations for Test Cases\n\n**Case A:** $(m=\\text{AR},\\, p=0.004,\\, r=1.0,\\, h=0.5,\\, a=0.5,\\, \\tau=0.01,\\, f=0.02)$\n1.  Calculate $q_{\\max}(\\text{AR})$:\n    $$ q_{\\max}(\\text{AR}) = \\sqrt{\\frac{0.004 \\cdot 0.5 \\cdot 0.5}{1.0}} = \\sqrt{0.001} \\approx 0.03162 $$\n2.  Check conditions:\n    - $f \\ge \\tau$: $0.02 \\ge 0.01$ is True.\n    - $f \\le q_{\\max}(\\text{AR})$: $0.02 \\le 0.03162$ is True.\n3.  Result: True $\\land$ True $\\implies$ True.\n\n**Case B:** $(m=\\text{AR},\\, p=0.0001,\\, r=1.0,\\, h=1.0,\\, a=1.0,\\, \\tau=0.01,\\, f=0.02)$\n1.  Calculate $q_{\\max}(\\text{AR})$:\n    $$ q_{\\max}(\\text{AR}) = \\sqrt{\\frac{0.0001 \\cdot 1.0 \\cdot 1.0}{1.0}} = \\sqrt{0.0001} = 0.01 $$\n2.  Check conditions:\n    - $f \\ge \\tau$: $0.02 \\ge 0.01$ is True.\n    - $f \\le q_{\\max}(\\text{AR})$: $0.02 \\le 0.01$ is False.\n3.  Result: True $\\land$ False $\\implies$ False.\n\n**Case C:** $(m=\\text{AR},\\, p=0.004,\\, r=1.0,\\, h=0.5,\\, a=0.5,\\, \\tau=0.03,\\, f=0.02)$\n1.  Calculate $q_{\\max}(\\text{AR})$:\n    $$ q_{\\max}(\\text{AR}) = \\sqrt{\\frac{0.004 \\cdot 0.5 \\cdot 0.5}{1.0}} = \\sqrt{0.001} \\approx 0.03162 $$\n2.  Check conditions:\n    - $f \\ge \\tau$: $0.02 \\ge 0.03$ is False.\n3.  Result: The first condition is false, so the combined result is False.\n\n**Case D:** $(m=\\text{AD},\\, p=0.001,\\, r=0.2,\\, h=1.0,\\, a=0.5,\\, \\tau=0.0008,\\, f=0.001)$\n1.  Calculate $q_{\\max}(\\text{AD})$:\n    $$ q_{\\max}(\\text{AD}) = \\frac{0.001 \\cdot 1.0 \\cdot 0.5}{2 \\cdot 0.2} = \\frac{0.0005}{0.4} = 0.00125 $$\n2.  Check conditions:\n    - $f \\ge \\tau$: $0.001 \\ge 0.0008$ is True.\n    - $f \\le q_{\\max}(\\text{AD})$: $0.001 \\le 0.00125$ is True.\n3.  Result: True $\\land$ True $\\implies$ True.\n\n**Case E:** $(m=\\text{AR},\\, p=0.0004,\\, r=1.0,\\, h=1.0,\\, a=1.0,\\, \\tau=0.02,\\, f=0.02)$\n1.  Calculate $q_{\\max}(\\text{AR})$:\n    $$ q_{\\max}(\\text{AR}) = \\sqrt{\\frac{0.0004 \\cdot 1.0 \\cdot 1.0}{1.0}} = \\sqrt{0.0004} = 0.02 $$\n2.  Check conditions:\n    - $f \\ge \\tau$: $0.02 \\ge 0.02$ is True.\n    - $f \\le q_{\\max}(\\text{AR})$: $0.02 \\le 0.02$ is True.\n3.  Result: True $\\land$ True $\\implies$ True.\n\n**Case F:** $(m=\\text{AD},\\, p=0.01,\\, r=0.5,\\, h=0.1,\\, a=0.05,\\, \\tau=0.0001,\\, f=0.0002)$\n1.  Calculate $q_{\\max}(\\text{AD})$:\n    $$ q_{\\max}(\\text{AD}) = \\frac{0.01 \\cdot 0.1 \\cdot 0.05}{2 \\cdot 0.5} = \\frac{0.00005}{1.0} = 0.00005 $$\n2.  Check conditions:\n    - $f \\ge \\tau$: $0.0002 \\ge 0.0001$ is True.\n    - $f \\le q_{\\max}(\\text{AD})$: $0.0002 \\le 0.00005$ is False.\n3.  Result: True $\\land$ False $\\implies$ False.\n\nThe final sequence of boolean results for cases A through F is: True, False, False, True, True, False.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes a 'misleading' flag for the application of the ACMG BA1 rule\n    for several test cases, based on a population genetics model.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (m, p, r, h, a, tau, f)\n    # m: Mode of inheritance ('AR' or 'AD')\n    # p: Disease prevalence\n    # r: Penetrance\n    # h: Gene-level contribution\n    # a: Variant's allelic contribution\n    # tau: BA1 decision threshold\n    # f: Observed population allele frequency\n    test_cases = [\n        ('AR', 0.004, 1.0, 0.5, 0.5, 0.01, 0.02),      # Case A\n        ('AR', 0.0001, 1.0, 1.0, 1.0, 0.01, 0.02),     # Case B\n        ('AR', 0.004, 1.0, 0.5, 0.5, 0.03, 0.02),      # Case C\n        ('AD', 0.001, 0.2, 1.0, 0.5, 0.0008, 0.001),    # Case D\n        ('AR', 0.0004, 1.0, 1.0, 1.0, 0.02, 0.02),     # Case E\n        ('AD', 0.01, 0.5, 0.1, 0.05, 0.0001, 0.0002),   # Case F\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        m, p, r, h, a, tau, f = case\n\n        # Calculate the variant-attributable disease burden\n        variant_burden = p * h * a\n\n        # Calculate the maximum allele frequency compatible with pathogenicity (q_max)\n        # based on the mode of inheritance.\n        q_max = 0.0\n        if m == 'AR':\n            # For Autosomal Recessive, q_max = sqrt((p*h*a) / r)\n            q_max = np.sqrt(variant_burden / r)\n        elif m == 'AD':\n            # For Autosomal Dominant, q_max = (p*h*a) / (2*r)\n            q_max = variant_burden / (2 * r)\n\n        # A \"misleading\" flag is True if both conditions are met:\n        # 1. BA1 would be applied for the observed frequency (f >= tau)\n        # 2. The observed frequency is compatible with the model (f <= q_max)\n        is_misleading = (f >= tau) and (f <= q_max)\n        \n        results.append(is_misleading)\n\n    # Format the final output as a comma-separated list of booleans\n    # within square brackets, e.g., [True,False,...]\n    # The default str() conversion for booleans ('True', 'False') is used.\n    # To get lowercase 'true'/'false', one would use str(r).lower().\n    # However, the standard representation is clearer.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2378900"}, {"introduction": "The original ACMG framework combines evidence using qualitative bins, but a more statistically rigorous approach is to use a Bayesian framework to quantify and accumulate evidence. This method treats each evidence code as a factor that updates the probability of pathogenicity [@problem_id:2378888]. In this practice, you will calculate posterior probabilities of pathogenicity by converting evidence into likelihood ratios ($LR$), providing a powerful lesson in probabilistic reasoning and its application to modern genomics.", "problem": "You will model the accumulation of American College of Medical Genetics and Genomics (ACMG) evidence codes as Bayesian updating of the prior probability of pathogenicity. Assume that each evidence code contributes a likelihood ratio in favor of pathogenicity, and that all evidence items are conditionally independent given the true pathogenicity state. Let the prior probability of pathogenicity be denoted by $p_0 \\in (0,1)$, and let the evidence be a finite sequence $E = (e_1, e_2, \\ldots, e_n)$ drawn from a fixed set of code categories. Define the prior odds as $O_0 = \\dfrac{p_0}{1 - p_0}$, the likelihood ratio as $\\operatorname{LR}(e_i)$ for each evidence $e_i$, and the posterior odds as\n$$\nO_{\\text{post}} = O_0 \\times \\prod_{i=1}^{n} \\operatorname{LR}(e_i).\n$$\nConvert odds back to probability via\n$$\np_{\\text{post}} = \\frac{O_{\\text{post}}}{1 + O_{\\text{post}}}.\n$$\nIf $E$ is empty, take the empty product to be $1$, so that $p_{\\text{post}} = p_0$.\n\nUse the following likelihood ratio calibration for ACMG evidence strengths, which are standard in the Bayesian reinterpretation of ACMG criteria. The likelihood ratios are in favor of pathogenicity; benign criteria use reciprocal values:\n- Pathogenic Very Strong ($\\text{PVS}$): $\\operatorname{LR} = 350$.\n- Pathogenic Strong ($\\text{PS}$): $\\operatorname{LR} = 18.7$.\n- Pathogenic Moderate ($\\text{PM}$): $\\operatorname{LR} = 4.3$.\n- Pathogenic Supporting ($\\text{PP}$): $\\operatorname{LR} = 2.08$.\n- Benign Stand-alone ($\\text{BA}$): $\\operatorname{LR} = \\dfrac{1}{350}$.\n- Benign Strong ($\\text{BS}$): $\\operatorname{LR} = \\dfrac{1}{18.7}$.\n- Benign Supporting ($\\text{BP}$): $\\operatorname{LR} = \\dfrac{1}{2.08}$.\n\nImplement a program that, for each test case, computes $p_{\\text{post}}$ according to the definitions above. Express each posterior probability as a decimal rounded to six digits after the decimal point.\n\nTest suite (each case is $(p_0, E)$):\n- Case $1$: $(p_0 = 0.1, E = [\\text{\"PS\"}, \\text{\"PM\"}, \\text{\"BP\"}])$.\n- Case $2$: $(p_0 = 0.1, E = [])$ (no evidence).\n- Case $3$: $(p_0 = 0.5, E = [\\text{\"PVS\"}])$.\n- Case $4$: $(p_0 = 0.99, E = [\\text{\"BS\"}])$.\n- Case $5$: $(p_0 = 0.01, E = [\\text{\"BA\"}])$.\n- Case $6$: $(p_0 = 0.2, E = [\\text{\"PP\"}, \\text{\"PP\"}, \\text{\"BP\"}])$.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the test suite, for example $[\\text{result}_1,\\text{result}_2,\\ldots]$. Each $\\text{result}_i$ must be a decimal number rounded to six digits after the decimal point, such as $[0.123456,0.500000,0.999000]$.", "solution": "The problem presented is scientifically sound and mathematically well-Posed. It is grounded in the established principles of Bayesian statistics, specifically applying Bayes' theorem in its odds-and-likelihood-ratio form to the problem of evidence integration in clinical variant interpretation. This approach is a recognized and published methodology for quantifying evidence strength under the American College of Medical Genetics and Genomics (ACMG) framework. Therefore, the problem is valid, and we proceed to the solution.\n\nThe core of the problem is Bayesian updating. Let $H$ be the hypothesis that a genetic variant is pathogenic, and $\\neg H$ be the complementary hypothesis that it is not. The prior probability of pathogenicity is given as $p_0 = P(H)$. The prior odds in favor of pathogenicity are defined as the ratio of the prior probability of the hypothesis to the prior probability of its complement:\n$$\nO_0 = \\frac{P(H)}{P(\\neg H)} = \\frac{p_0}{1 - p_0}\n$$\nWe are given a sequence of evidence items, $E = (e_1, e_2, \\ldots, e_n)$. For each piece of evidence $e_i$, its strength is quantified by a likelihood ratio, $\\operatorname{LR}(e_i)$, defined as:\n$$\n\\operatorname{LR}(e_i) = \\frac{P(e_i | H)}{P(e_i | \\neg H)}\n$$\nBayes' theorem in odds form states that the posterior odds are the product of the prior odds and the likelihood ratio: $O_{\\text{post}} = O_0 \\times \\operatorname{LR}(E)$. The problem states that the evidence items are conditionally independent given the true pathogenicity state. This critical assumption allows us to calculate the likelihood ratio for the entire sequence of evidence $E$ as the product of the individual likelihood ratios:\n$$\n\\operatorname{LR}(E) = \\operatorname{LR}(e_1, e_2, \\ldots, e_n) = \\prod_{i=1}^{n} \\operatorname{LR}(e_i)\n$$\nThus, the posterior odds, $O_{\\text{post}}$, after observing all evidence items in $E$, are calculated as:\n$$\nO_{\\text{post}} = O_0 \\times \\prod_{i=1}^{n} \\operatorname{LR}(e_i)\n$$\nIf the evidence set $E$ is empty, the product is taken to be $1$, so $O_{\\text{post}} = O_0$.\n\nFinally, the posterior odds are converted back to a posterior probability, $p_{\\text{post}} = P(H|E)$, using the formula:\n$$\np_{\\text{post}} = \\frac{O_{\\text{post}}}{1 + O_{\\text{post}}}\n$$\nThe problem provides the calibrated likelihood ratios for different ACMG evidence strength categories:\n- Pathogenic Very Strong ($\\text{PVS}$): $\\operatorname{LR} = 350$\n- Pathogenic Strong ($\\text{PS}$): $\\operatorname{LR} = 18.7$\n- Pathogenic Moderate ($\\text{PM}$): $\\operatorname{LR} = 4.3$\n- Pathogenic Supporting ($\\text{PP}$): $\\operatorname{LR} = 2.08$\n- Benign Stand-alone ($\\text{BA}$): $\\operatorname{LR} = 1/350$\n- Benign Strong ($\\text{BS}$): $\\operatorname{LR} = 1/18.7$\n- Benign Supporting ($\\text{BP}$): $\\operatorname{LR} = 1/2.08$\n\nWe will now apply this methodology to each test case.\n\nCase $1$: $(p_0 = 0.1, E = [\\text{\"PS\"}, \\text{\"PM\"}, \\text{\"BP\"}])$\n- Prior probability $p_0 = 0.1$.\n- Prior odds $O_0 = \\frac{0.1}{1 - 0.1} = \\frac{0.1}{0.9} = \\frac{1}{9}$.\n- Total likelihood ratio $\\operatorname{LR}_{\\text{total}} = \\operatorname{LR}(\\text{PS}) \\times \\operatorname{LR}(\\text{PM}) \\times \\operatorname{LR}(\\text{BP}) = 18.7 \\times 4.3 \\times \\frac{1}{2.08} = \\frac{80.41}{2.08}$.\n- Posterior odds $O_{\\text{post}} = \\frac{1}{9} \\times \\frac{80.41}{2.08} = \\frac{80.41}{18.72} \\approx 4.29540598$.\n- Posterior probability $p_{\\text{post}} = \\frac{4.29540598}{1 + 4.29540598} \\approx 0.8111580$. Rounded to six decimal places, this is $0.811158$.\n\nCase $2$: $(p_0 = 0.1, E = [])$\n- Prior probability $p_0 = 0.1$.\n- The evidence list is empty. The product of likelihood ratios is $1$.\n- Posterior odds $O_{\\text{post}} = O_0 = \\frac{0.1}{0.9} = \\frac{1}{9}$.\n- Posterior probability $p_{\\text{post}} = \\frac{1/9}{1 + 1/9} = \\frac{1}{10} = 0.1$. This is equivalent to $p_0$, as expected. Rounded to six decimal places, this is $0.100000$.\n\nCase $3$: $(p_0 = 0.5, E = [\\text{\"PVS\"}])$\n- Prior probability $p_0 = 0.5$.\n- Prior odds $O_0 = \\frac{0.5}{1 - 0.5} = 1$.\n- Total likelihood ratio $\\operatorname{LR}_{\\text{total}} = \\operatorname{LR}(\\text{PVS}) = 350$.\n- Posterior odds $O_{\\text{post}} = 1 \\times 350 = 350$.\n- Posterior probability $p_{\\text{post}} = \\frac{350}{1 + 350} = \\frac{350}{351} \\approx 0.997150997$. Rounded to six decimal places, this is $0.997151$.\n\nCase $4$: $(p_0 = 0.99, E = [\\text{\"BS\"}])$\n- Prior probability $p_0 = 0.99$.\n- Prior odds $O_0 = \\frac{0.99}{1 - 0.99} = \\frac{0.99}{0.01} = 99$.\n- Total likelihood ratio $\\operatorname{LR}_{\\text{total}} = \\operatorname{LR}(\\text{BS}) = \\frac{1}{18.7}$.\n- Posterior odds $O_{\\text{post}} = 99 \\times \\frac{1}{18.7} = \\frac{99}{18.7}$.\n- Posterior probability $p_{\\text{post}} = \\frac{99/18.7}{1 + 99/18.7} = \\frac{99}{18.7 + 99} = \\frac{99}{117.7} \\approx 0.841121495$. Rounded to six decimal places, this is $0.841121$.\n\nCase $5$: $(p_0 = 0.01, E = [\\text{\"BA\"}])$\n- Prior probability $p_0 = 0.01$.\n- Prior odds $O_0 = \\frac{0.01}{1 - 0.01} = \\frac{0.01}{0.99} = \\frac{1}{99}$.\n- Total likelihood ratio $\\operatorname{LR}_{\\text{total}} = \\operatorname{LR}(\\text{BA}) = \\frac{1}{350}$.\n- Posterior odds $O_{\\text{post}} = \\frac{1}{99} \\times \\frac{1}{350} = \\frac{1}{34650}$.\n- Posterior probability $p_{\\text{post}} = \\frac{1/34650}{1 + 1/34650} = \\frac{1}{34650 + 1} = \\frac{1}{34651} \\approx 0.000028859$. Rounded to six decimal places, this is $0.000029$.\n\nCase $6$: $(p_0 = 0.2, E = [\\text{\"PP\"}, \\text{\"PP\"}, \\text{\"BP\"}])$\n- Prior probability $p_0 = 0.2$.\n- Prior odds $O_0 = \\frac{0.2}{1 - 0.2} = \\frac{0.2}{0.8} = 0.25$.\n- Total likelihood ratio $\\operatorname{LR}_{\\text{total}} = \\operatorname{LR}(\\text{PP}) \\times \\operatorname{LR}(\\text{PP}) \\times \\operatorname{LR}(\\text{BP}) = 2.08 \\times 2.08 \\times \\frac{1}{2.08} = 2.08$.\n- Posterior odds $O_{\\text{post}} = 0.25 \\times 2.08 = 0.52$.\n- Posterior probability $p_{\\text{post}} = \\frac{0.52}{1 + 0.52} = \\frac{0.52}{1.52} = \\frac{13}{38} \\approx 0.342105263$. Rounded to six decimal places, this is $0.342105$.\n\nThe computed posterior probabilities for the six test cases are: $0.811158$, $0.100000$, $0.997151$, $0.841121$, $0.000029$, and $0.342105$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes posterior probabilities of pathogenicity based on a Bayesian\n    reinterpretation of ACMG evidence codes.\n    \"\"\"\n\n    # Define the likelihood ratio (LR) calibration for ACMG evidence strengths.\n    # The LRs are given in favor of pathogenicity.\n    lr_map = {\n        \"PVS\": 350.0,\n        \"PS\": 18.7,\n        \"PM\": 4.3,\n        \"PP\": 2.08,\n        \"BA\": 1.0 / 350.0,\n        \"BS\": 1.0 / 18.7,\n        \"BP\": 1.0 / 2.08,\n    }\n\n    # Define the test suite. Each case is a tuple (p0, evidence_list).\n    # p0 is the prior probability of pathogenicity.\n    test_cases = [\n        (0.1, [\"PS\", \"PM\", \"BP\"]),\n        (0.1, []),\n        (0.5, [\"PVS\"]),\n        (0.99, [\"BS\"]),\n        (0.01, [\"BA\"]),\n        (0.2, [\"PP\", \"PP\", \"BP\"]),\n    ]\n\n    results = []\n    for p0, evidence_codes in test_cases:\n        # Step 1: Calculate prior odds from prior probability p0.\n        # O_0 = p0 / (1 - p0)\n        # A check for p0=1 is good practice but not needed for given test cases.\n        prior_odds = p0 / (1.0 - p0)\n\n        # Step 2: Calculate the total likelihood ratio from the evidence codes.\n        # The total LR is the product of individual LRs due to conditional independence.\n        if not evidence_codes:\n            # The product of an empty set of LRs is 1.\n            total_lr = 1.0\n        else:\n            # Look up LR for each code and compute the product.\n            # np.prod is convenient for this.\n            lr_values = [lr_map[code] for code in evidence_codes]\n            total_lr = np.prod(lr_values)\n\n        # Step 3: Calculate posterior odds.\n        # O_post = O_0 * LR_total\n        posterior_odds = prior_odds * total_lr\n\n        # Step 4: Convert posterior odds back to posterior probability.\n        # p_post = O_post / (1 + O_post)\n        posterior_prob = posterior_odds / (1.0 + posterior_odds)\n\n        # Append the formatted result to the list.\n        # The result must be a string rounded to six decimal places.\n        results.append(f\"{posterior_prob:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2378888"}]}