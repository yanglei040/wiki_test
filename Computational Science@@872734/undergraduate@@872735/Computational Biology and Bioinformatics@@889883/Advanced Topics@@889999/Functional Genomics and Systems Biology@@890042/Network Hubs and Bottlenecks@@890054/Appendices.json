{"hands_on_practices": [{"introduction": "In biological networks, some proteins act as \"hubs\" by interacting with many partners, while others act as \"bottlenecks\" by connecting different functional modules. This exercise introduces a quantitative method to distinguish these roles using a composite score that weighs degree centrality against betweenness centrality [@problem_id:2409607]. By applying this metric, you will learn to classify key proteins and predict the distinct functional consequences of their removal.", "problem": "In a Protein-Protein Interaction (PPI) network modeled as an undirected, unweighted graph, the degree centrality of node $i$ is the number of its interaction partners, and the betweenness centrality of node $i$ is the fraction of all shortest paths in the network that pass through $i$. Let $D_i$ denote the degree centrality of node $i$ normalized to the interval $[0,1]$ (for example, by dividing by the maximum degree), and let $B_i$ denote the betweenness centrality of node $i$ normalized to the interval $[0,1]$ (for example, by dividing by the maximum possible betweenness in the network). Consider the hub–bottleneck discrepancy score\n$$\nS_i \\;=\\; k_d \\cdot D_i \\;-\\; k_b \\cdot B_i,\n$$\nwhere $k_d>0$ and $k_b>0$ are user-chosen weights that quantify the relative emphasis placed on hubness and bottleneckness, respectively. Larger positive $S_i$ indicates greater hub dominance relative to bottleneckness under the chosen weights, while more negative $S_i$ indicates greater bottleneck dominance relative to hubness.\n\nSuppose $k_d = 1.0$ and $k_b = 1.5$. For four proteins P1, P2, P3, and P4, the normalized centralities are:\n- P1: $D_1 = 0.80$, $B_1 = 0.20$.\n- P2: $D_2 = 0.30$, $B_2 = 0.60$.\n- P3: $D_3 = 0.70$, $B_3 = 0.70$.\n- P4: $D_4 = 0.10$, $B_4 = 0.05$.\n\nWhich of the following statements about $S_i$ and its biological interpretation are correct? Select all that apply.\n\nA. With the given weights, P1 has the largest positive $S_i$ and is hub-dominated; its removal would eliminate many local interactions but is comparatively less likely than a negative-$S_i$ node to disrupt inter-module shortest-path traffic.\n\nB. With the given weights, P2 is bottleneck-dominated and, relative to P1, is more likely to mediate inter-module communication via shortest paths; consequently, it may exhibit stronger effects in perturbations that assay path-dependent signal transfer.\n\nC. Although both $D_3$ and $B_3$ are high, $S_3<0$ under the given weights, illustrating that $S_i$ reflects relative emphasis; increasing $k_d$ above $k_b\\cdot \\dfrac{B_3}{D_3}$ would flip the sign of $S_3$.\n\nD. If $k_b$ is increased by a factor of $2$, then for all nodes with $B_i>0$, $S_i$ increases because a higher $k_b$ rewards bottleneckness.\n\nE. If $S_i \\approx 0$, then it must be that $D_i \\approx 0$ and $B_i \\approx 0$; therefore P4 is necessarily a peripheral, non-influential node.", "solution": "The primary task is to compute the hub-bottleneck discrepancy score $S_i$ for each protein using the formula $S_i = k_d \\cdot D_i - k_b \\cdot B_i$ with the given weights $k_d = 1.0$ and $k_b = 1.5$.\n\nFor protein P1:\n$$S_1 = (1.0 \\cdot 0.80) - (1.5 \\cdot 0.20) = 0.80 - 0.30 = 0.50$$\n\nFor protein P2:\n$$S_2 = (1.0 \\cdot 0.30) - (1.5 \\cdot 0.60) = 0.30 - 0.90 = -0.60$$\n\nFor protein P3:\n$$S_3 = (1.0 \\cdot 0.70) - (1.5 \\cdot 0.70) = 0.70 - 1.05 = -0.35$$\n\nFor protein P4:\n$$S_4 = (1.0 \\cdot 0.10) - (1.5 \\cdot 0.05) = 0.10 - 0.075 = 0.025$$\n\nSummary of scores: $S_1 = 0.50$, $S_2 = -0.60$, $S_3 = -0.35$, $S_4 = 0.025$.\nA positive score ($S_i > 0$) indicates hub dominance. A negative score ($S_i < 0$) indicates bottleneck dominance.\n\n**Option-by-Option Analysis**\n\n**A. With the given weights, P1 has the largest positive $S_i$ and is hub-dominated; its removal would eliminate many local interactions but is comparatively less likely than a negative-$S_i$ node to disrupt inter-module shortest-path traffic.**\n- We calculated $S_1 = 0.50$, which is the largest positive score.\n- Since $S_1 > 0$, P1 is classified as hub-dominated.\n- P1 has a very high degree centrality ($D_1 = 0.80$), so its removal would eliminate many local interactions.\n- The negative-$S_i$ nodes (P2 and P3) are bottleneck-dominated and have high betweenness. Removing P1 (with low betweenness $B_1 = 0.20$) is less likely to disrupt inter-module traffic than removing them. The statement is correct.\n**Verdict: Correct**\n\n**B. With the given weights, P2 is bottleneck-dominated and, relative to P1, is more likely to mediate inter-module communication via shortest paths; consequently, it may exhibit stronger effects in perturbations that assay path-dependent signal transfer.**\n- We calculated $S_2 = -0.60$. Since $S_2 < 0$, P2 is bottleneck-dominated.\n- P2's betweenness centrality ($B_2 = 0.60$) is significantly higher than P1's ($B_1 = 0.20$), making it a more likely mediator of inter-module communication.\n- A perturbation to a high-betweenness node like P2 will sever a large number of shortest paths, leading to a strong effect on path-dependent processes. The statement is correct.\n**Verdict: Correct**\n\n**C. Although both $D_3$ and $B_3$ are high, $S_3<0$ under the given weights, illustrating that $S_i$ reflects relative emphasis; increasing $k_d$ above $k_b\\cdot \\dfrac{B_3}{D_3}$ would flip the sign of $S_3$.**\n- For P3, $D_3 = 0.70$ and $B_3 = 0.70$ are high.\n- We calculated $S_3 = -0.35$, which is negative. This is because the weight for bottleneckness ($k_b=1.5$) is greater than for hubness ($k_d=1.0$).\n- To flip the sign of $S_3$ to positive, we need $S_3 > 0$, which means $k_d D_3 - k_b B_3 > 0$. Rearranging gives $k_d > k_b \\frac{B_3}{D_3}$. The mathematical derivation is correct.\n**Verdict: Correct**\n\n**D. If $k_b$ is increased by a factor of $2$, then for all nodes with $B_i>0$, $S_i$ increases because a higher $k_b$ rewards bottleneckness.**\n- Let the new score be $S_i' = k_d D_i - (2k_b) B_i$.\n- The change in score is $\\Delta S_i = S_i' - S_i = -k_b B_i$.\n- Since $k_b > 0$ and $B_i > 0$, the change $\\Delta S_i$ is strictly negative.\n- Therefore, increasing $k_b$ *decreases* the value of $S_i$. The statement is false.\n**Verdict: Incorrect**\n\n**E. If $S_i \\approx 0$, then it must be that $D_i \\approx 0$ and $B_i \\approx 0$; therefore P4 is necessarily a peripheral, non-influential node.**\n- The condition $S_i \\approx 0$ means $k_d D_i \\approx k_b B_i$. This is a balance equation and does not require $D_i$ and $B_i$ to be near zero. For example, a node with $D_i=0.6$ and $B_i=0.4$ would have $S_i = 1.0(0.6) - 1.5(0.4) = 0$.\n- The premise is a logical fallacy.\n**Verdict: Incorrect**", "answer": "$$\\boxed{ABC}$$", "id": "2409607"}, {"introduction": "While hubs, defined by high degree, are often considered critical nodes, their removal does not always fragment the network—a property of so-called \"fragile\" or redundant hubs. This hands-on coding practice challenges you to operationalize this concept by implementing a metric that quantifies the loss of global connectivity when a node is removed [@problem_id:2409629]. This exercise will deepen your understanding that a node's global importance is determined by more than just its number of direct connections.", "problem": "A biological interaction network can be modeled as a finite, undirected, simple graph $G=(V,E)$, where $V$ is the set of nodes (biomolecules) and $E$ is the set of undirected edges (interactions). For a node $v \\in V$, the degree $\\deg(v)$ is the number of edges incident to $v$. A node $v$ is called a hub if $\\deg(v) \\ge k_{\\text{hub}}$ for a specified integer threshold $k_{\\text{hub}} \\ge 1$. Define the removal effect of a node $v$ as follows: remove $v$ and all its incident edges to obtain a residual graph $G'=(V',E')$ with $V'=V \\setminus \\{v\\}$. Let the connected components of $G'$ have sizes $s_1,s_2,\\dots,s_m$ (so that $\\sum_{i=1}^{m} s_i = |V'|$). The number of unordered node pairs in $V'$ that remain mutually reachable is $\\sum_{i=1}^{m} \\binom{s_i}{2}$. The total number of unordered node pairs in $V'$ is $\\binom{|V'|}{2}$. Define the reachability fraction $R(v)$ by\n$$\nR(v) = \n\\begin{cases}\n1, & \\text{if } |V'| \\le 1,\\\\\n\\displaystyle \\frac{\\sum_{i=1}^{m} \\binom{s_i}{2}}{\\binom{|V'|}{2}}, & \\text{if } |V'| \\ge 2,\n\\end{cases}\n$$\nand the loss $L(v) = 1 - R(v)$. For a specified tolerance $\\tau \\in [0,1]$, a fragile hub is any hub $v$ with $L(v) \\le \\tau$. Your task is to determine, for each test case, the list of node indices that are fragile hubs, sorted in ascending order.\n\nUse the following test suite. In all cases, the graph is undirected and simple, node indices are integers, and all edges are unordered pairs of distinct node indices.\n\nTest case $1$ (redundantly bridged modules):\n- Nodes: $V_1 = \\{0,1,2,3,4,5,6,7,8\\}$, so $|V_1|=9$.\n- Edges: $E_1$ consists of all $\\binom{5}{2}$ edges among $\\{0,1,2,3,4\\}$, all $\\binom{4}{2}$ edges among $\\{5,6,7,8\\}$, and two inter-module edges $(2,5)$ and $(3,6)$. Explicitly,\n$$\nE_1 = \\{(0,1),(0,2),(0,3),(0,4),(1,2),(1,3),(1,4),(2,3),(2,4),(3,4),\n(5,6),(5,7),(5,8),(6,7),(6,8),(7,8),(2,5),(3,6)\\}.\n$$\n- Hub threshold: $k_{\\text{hub}}=5$.\n- Tolerance: $\\tau=0.05$.\n\nTest case $2$ (star topology):\n- Nodes: $V_2=\\{0,1,2,3,4,5,6\\}$, so $|V_2|=7$.\n- Edges: $E_2=\\{(0,1),(0,2),(0,3),(0,4),(0,5),(0,6)\\}$.\n- Hub threshold: $k_{\\text{hub}}=5$.\n- Tolerance: $\\tau=0.1$.\n\nTest case $3$ (redundant high-degree node on a cycle):\n- Nodes: $V_3=\\{0,1,2,3,4,5\\}$, so $|V_3|=6$.\n- Edges: $E_3$ is the $6$-cycle plus extra chords from node $0$ to nodes $2$, $3$, and $4$:\n$$\nE_3=\\{(0,1),(1,2),(2,3),(3,4),(4,5),(5,0),(0,2),(0,3),(0,4)\\}.\n$$\n- Hub threshold: $k_{\\text{hub}}=5$.\n- Tolerance: $\\tau=0.0$.\n\nFor each test case $i \\in \\{1,2,3\\}$, compute the set of fragile hubs as all nodes $v$ such that $\\deg(v) \\ge k_{\\text{hub}}$ and $L(v) \\le \\tau$. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each entry is the list (in ascending order) of fragile hub node indices for the corresponding test case. For example, the output format must be\n$$\n[\\,[\\text{case 1 indices}],\\,[\\text{case 2 indices}],\\,[\\text{case 3 indices}]\\,].\n$$\nIf a case has no fragile hubs, output an empty list $[\\,]$ for that case. No physical units or angles are involved in this problem. The required output types are lists of integers for each test case, aggregated as specified into a single line.", "solution": "**Methodology**\n\nThe solution for each test case is obtained by executing the following algorithm:\n1.  For the given graph $G=(V,E)$, compute the degree, $\\deg(v)$, for each node $v \\in V$.\n2.  Identify the set of hubs, $V_{\\text{hub}} = \\{v \\in V \\mid \\deg(v) \\ge k_{\\text{hub}}\\}$.\n3.  For each hub $v \\in V_{\\text{hub}}$:\n    a. Determine the residual graph $G'$ by removing node $v$. Let its node set be $V' = V \\setminus \\{v\\}$, with size $|V'| = |V|-1$.\n    b. Find the connected components of $G'$ and their sizes $s_1, s_2, \\dots, s_m$. This can be done using a graph traversal algorithm like BFS or DFS.\n    c. Calculate the loss $L(v)$. If $|V'| < 2$, $L(v) = 0$. Otherwise, compute the total number of pairs in $V'$, $\\binom{|V'|}{2}$, and the number of pairs that remain connected, $\\sum_{i=1}^{m} \\binom{s_i}{2}$. The reachability fraction is $R(v) = (\\sum_{i=1}^{m} \\binom{s_i}{2}) / \\binom{|V'|}{2}$, and the loss is $L(v) = 1 - R(v)$. The binomial coefficient $\\binom{n}{2}$ is calculated as $n(n-1)/2$.\n    d. Compare the loss with the tolerance: if $L(v) \\le \\tau$, then $v$ is a fragile hub.\n4.  Collect all identified fragile hub indices for the test case and present them as a sorted list.\n\n**Application to Test Cases**\n\n**Test Case 1:**\n- Graph $G_1=(V_1, E_1)$ with $|V_1|=9$, $k_{\\text{hub}}=5$, $\\tau=0.05$.\n- The hubs (degree $\\ge 5$) are $\\{2, 3\\}$.\n- For hub $v=2$: Removing node $2$ leaves the residual graph $G_1'$ with $|V_1'|=8$. The edge $(3,6)$ remains, so the graph is fully connected (one component of size $s_1=8$).\n  - $L(2) = 1 - \\frac{\\binom{8}{2}}{\\binom{8}{2}} = 0$. Since $0 \\le 0.05$, node $2$ is a fragile hub.\n- For hub $v=3$: Removing node $3$ leaves a residual graph where the edge $(2,5)$ remains, keeping it connected.\n  - $L(3) = 0$. Since $0 \\le 0.05$, node $3$ is a fragile hub.\n- The fragile hubs for case 1 are $\\{2, 3\\}$, sorted as $[2, 3]$.\n\n**Test Case 2:**\n- Star graph $G_2=(V_2, E_2)$ with $|V_2|=7$, $k_{\\text{hub}}=5$, $\\tau=0.1$.\n- The only hub is the center, node $0$ ($\\deg(0)=6$).\n- For hub $v=0$: Removing node $0$ leaves 6 isolated nodes. The components are 6 singletons ($s_i=1$).\n  - Number of connected pairs: $\\sum_{i=1}^6 \\binom{1}{2} = 0$.\n  - Total pairs in residual graph: $\\binom{6}{2} = 15$.\n  - $R(0) = 0/15 = 0$, so $L(0) = 1$. Since $1 \\not\\le 0.1$, node $0$ is not a fragile hub.\n- There are no fragile hubs for case 2. The result is an empty list, $[\\,]$.\n\n**Test Case 3:**\n- Graph $G_3=(V_3, E_3)$ with $|V_3|=6$, $k_{\\text{hub}}=5$, $\\tau=0.0$.\n- The only hub is node $0$ ($\\deg(0)=5$).\n- For hub $v=0$: Removing node $0$ leaves nodes $\\{1, 2, 3, 4, 5\\}$ connected in a path graph.\n  - The residual graph is connected (one component of size $s_1=5$).\n  - $L(0) = 1 - \\frac{\\binom{5}{2}}{\\binom{5}{2}} = 0$. Since $0 \\le 0.0$, node $0$ is a fragile hub.\n- The fragile hub for case 3 is $\\{0\\}$, sorted as $[0]$.\n\n**Consolidated Results**\n- Case 1: $[2, 3]$\n- Case 2: $[\\,]$\n- Case 3: $[0]$\nThe final output is constructed by aggregating these lists.", "answer": "```python\nimport numpy as np\nfrom scipy.special import comb\n\ndef solve():\n    \"\"\"\n    Solves the fragile hub identification problem for a given suite of test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"nodes\": list(range(9)),\n            \"edges\": [(0,1),(0,2),(0,3),(0,4),(1,2),(1,3),(1,4),(2,3),(2,4),(3,4),\n                      (5,6),(5,7),(5,8),(6,7),(6,8),(7,8),(2,5),(3,6)],\n            \"k_hub\": 5,\n            \"tau\": 0.05\n        },\n        {\n            \"nodes\": list(range(7)),\n            \"edges\": [(0,1),(0,2),(0,3),(0,4),(0,5),(0,6)],\n            \"k_hub\": 5,\n            \"tau\": 0.1\n        },\n        {\n            \"nodes\": list(range(6)),\n            \"edges\": [(0,1),(1,2),(2,3),(3,4),(4,5),(5,0),(0,2),(0,3),(0,4)],\n            \"k_hub\": 5,\n            \"tau\": 0.0\n        }\n    ]\n\n    final_results = []\n\n    for case in test_cases:\n        nodes = case[\"nodes\"]\n        edges = case[\"edges\"]\n        k_hub = case[\"k_hub\"]\n        tau = case[\"tau\"]\n        num_nodes = len(nodes)\n\n        # Build adjacency list\n        adj = {node: [] for node in nodes}\n        for u, v in edges:\n            adj[u].append(v)\n            adj[v].append(u)\n\n        # Calculate degrees and find hubs\n        degrees = {node: len(neighbors) for node, neighbors in adj.items()}\n        hubs = [node for node, deg in degrees.items() if deg >= k_hub]\n\n        fragile_hubs = []\n\n        for hub in hubs:\n            # 1. Define the residual graph\n            residual_nodes = [node for node in nodes if node != hub]\n            num_residual_nodes = len(residual_nodes)\n\n            if num_residual_nodes  2:\n                loss = 0.0\n            else:\n                # 2. Find connected components in the residual graph using DFS\n                visited = set()\n                component_sizes = []\n                for start_node in residual_nodes:\n                    if start_node not in visited:\n                        component_size = 0\n                        stack = [start_node]\n                        visited.add(start_node)\n                        while stack:\n                            current_node = stack.pop()\n                            component_size += 1\n                            for neighbor in adj[current_node]:\n                                # neighbor must be in the residual graph and not visited\n                                if neighbor != hub and neighbor not in visited:\n                                    visited.add(neighbor)\n                                    stack.append(neighbor)\n                        component_sizes.append(component_size)\n\n                # 3. Calculate Loss L(v)\n                sum_of_pairs_in_components = sum(comb(s, 2, exact=True) for s in component_sizes)\n                total_pairs_in_residual = comb(num_residual_nodes, 2, exact=True)\n                \n                if total_pairs_in_residual == 0:\n                    reachability_fraction = 1.0\n                else:\n                    reachability_fraction = sum_of_pairs_in_components / total_pairs_in_residual\n                \n                loss = 1.0 - reachability_fraction\n\n            # 4. Check if the hub is fragile\n            if loss = tau:\n                fragile_hubs.append(hub)\n\n        fragile_hubs.sort()\n        final_results.append(fragile_hubs)\n\n    # Format output as specified: [[...], [...], [...]]\n    results_str = [str(res).replace(\" \", \"\") for res in final_results]\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```", "id": "2409629"}, {"introduction": "Just as not all hubs are critical for global cohesion, not all bottlenecks are fragile points of failure. This advanced practice explores the concept of a \"robust bottleneck,\" a node with high betweenness centrality whose function is buffered by the network's plasticity [@problem_id:2409636]. You will implement an algorithm that combines betweenness centrality with a measure of global efficiency to identify nodes that, despite lying on many shortest paths, are not irreplaceable due to the presence of alternative routes.", "problem": "You are given undirected, unweighted graphs representing interaction networks, and you are asked to formalize and detect an example of a “robust bottleneck” in the sense used in computational biology and bioinformatics: a node with high betweenness centrality whose removal is effectively compensated by network plasticity through redundant routes. Your task is to write a program that, for each provided test graph, returns the list of all nodes that satisfy this property under a precise, mathematically defined criterion.\n\nThe fundamental bases to use are: the definition of an undirected graph, shortest paths, betweenness centrality, and network efficiency. Specifically, use the following definitions.\n\n- A graph is specified by an adjacency matrix $A \\in \\{0,1\\}^{n \\times n}$, where $A_{ij} = 1$ if and only if there is an undirected edge between nodes $i$ and $j$, with $A_{ii} = 0$ and $A_{ij} = A_{ji}$ for all $i,j$. Nodes are $0$-indexed from $\\{0,1,\\dots,n-1\\}$.\n- For nodes $s,t$, a shortest path is any path that realizes the minimal number of edges $d(s,t)$ between $s$ and $t$. If $s$ and $t$ are disconnected, define $d(s,t) = \\infty$.\n- The betweenness centrality $b(v)$ of node $v$ is the sum, over all unordered pairs $\\{s,t\\}$ with $s \\neq t$, $s \\neq v$, $t \\neq v$, of the fraction of shortest paths from $s$ to $t$ that pass through $v$. That is,\n$$\nb(v) = \\sum_{\\substack{s  t\\\\ s \\neq v \\neq t}} \\frac{\\sigma_{st}(v)}{\\sigma_{st}},\n$$\nwhere $\\sigma_{st}$ is the number of shortest paths between $s$ and $t$ and $\\sigma_{st}(v)$ is the number of such paths that pass through $v$.\n- The global efficiency of a graph on node set $V$ is\n$$\nE(V) = \\frac{2}{|V|(|V|-1)} \\sum_{\\substack{ij\\\\ i,j \\in V}} \\frac{1}{d(i,j)},\n$$\nwith the convention that $1/\\infty = 0$.\n\nTo formalize “effectively compensated by network plasticity,” for each candidate node $v$ we compare the efficiency among the remaining nodes $V \\setminus \\{v\\}$ before and after removing $v$:\n- Let $E_{\\text{before}}(v)$ denote the average of $1/d(i,j)$ over all unordered pairs $\\{i,j\\}$ with $ij$ and $i,j \\in V \\setminus \\{v\\}$, where $d(i,j)$ is computed in the original graph (with $v$ present).\n- Let $E_{\\text{after}}(v)$ denote the same average but with distances computed in the graph obtained by removing $v$ (i.e., the induced subgraph on $V \\setminus \\{v\\}$).\n- Define the relative efficiency drop\n$$\n\\Delta(v) = \\begin{cases}\n\\frac{E_{\\text{before}}(v)-E_{\\text{after}}(v)}{E_{\\text{before}}(v)},  \\text{if } E_{\\text{before}}(v)  0,\\\\\n0,  \\text{if } E_{\\text{before}}(v) = 0.\n\\end{cases}\n$$\n\nA node $v$ qualifies as a “robust bottleneck” if and only if it satisfies both:\n- High-betweenness criterion: $b(v) \\ge Q_q(b)$ and $b(v)  0$, where $Q_q(b)$ is the $q$-quantile of the multiset $\\{b(0),b(1),\\dots,b(n-1)\\}$ for a specified $q \\in (0,1)$.\n- Compensation criterion: $\\Delta(v) \\le \\tau$, for a specified tolerance $\\tau \\in [0,1]$.\n\nImplement an algorithm that, given a graph and the parameters $q$ and $\\tau$, returns the sorted list of all nodes that satisfy both criteria. Use exact shortest paths for unweighted graphs via breadth-first search and compute betweenness centrality exactly (for example, by a correct implementation of the unweighted variant of the Brandes algorithm). You must not assume any particular graph structure beyond what is given.\n\nTest Suite and Required Output:\n- Use the following three test cases, each given by an adjacency matrix with entries in $\\{0,1\\}$, and shared parameters $q$ and $\\tau$.\n\n- Test case $1$ (two modules connected by redundant middle layers):\n  - $n = 8$, nodes $\\{0,1,2,3,4,5,6,7\\}$.\n  - Adjacency matrix $A^{(1)}$ whose rows for nodes $0$ through $7$ are:\n    - Node $0$: $[0,1,1,0,0,0,1,1]$\n    - Node $1$: $[1,0,1,0,0,0,1,1]$\n    - Node $2$: $[1,1,0,0,0,0,1,1]$\n    - Node $3$: $[0,0,0,0,1,1,1,1]$\n    - Node $4$: $[0,0,0,1,0,1,1,1]$\n    - Node $5$: $[0,0,0,1,1,0,1,1]$\n    - Node $6$: $[1,1,1,1,1,1,0,0]$\n    - Node $7$: $[1,1,1,1,1,1,0,0]$\n  - Parameters: $q = 0.8$, $\\tau = 0.01$.\n\n- Test case $2$ (star graph):\n  - $n = 6$, nodes $\\{0,1,2,3,4,5\\}$.\n  - Adjacency matrix $A^{(2)}$ whose rows for nodes $0$ through $5$ are:\n    - Node $0$: $[0,1,1,1,1,1]$\n    - Node $1$: $[1,0,0,0,0,0]$\n    - Node $2$: $[1,0,0,0,0,0]$\n    - Node $3$: $[1,0,0,0,0,0]$\n    - Node $4$: $[1,0,0,0,0,0]$\n    - Node $5$: $[1,0,0,0,0,0]$\n  - Parameters: $q = 0.8$, $\\tau = 0.01$.\n\n- Test case $3$ (complete graph on four nodes):\n  - $n = 4$, nodes $\\{0,1,2,3\\}$.\n  - Adjacency matrix $A^{(3)}$ whose rows for nodes $0$ through $3$ are:\n    - Node $0$: $[0,1,1,1]$\n    - Node $1$: $[1,0,1,1]$\n    - Node $2$: $[1,1,0,1]$\n    - Node $3$: $[1,1,1,0]$\n  - Parameters: $q = 0.8$, $\\tau = 0.01$.\n\nFor each test case, output the zero-indexed list of nodes that satisfy both criteria, sorted in ascending order. Your program should produce a single line of output containing the results as a comma-separated list of lists, enclosed in square brackets, for the three test cases in order. For example, a format like $[[a,b],[c],[\\,]]$ with integers $a,b,c$ is required. There are no physical units or angles involved in this problem. All results must be integers, lists of integers, or empty lists; no percentages should be printed.\n\nYour program must be self-contained and take no input. It must implement correct shortest-path counting and exact betweenness centrality for unweighted, undirected graphs and apply the above definitions precisely. The final printed line should be exactly the specified aggregate list, with no extra text.", "solution": "The task is to identify a \"robust bottleneck,\" a node characterized by two properties: it has high betweenness centrality, but its removal does not critically damage the network's global efficiency. The solution requires implementing the precise mathematical criteria provided.\n\nThe overall algorithm for a given graph is as follows:\n1.  Compute the betweenness centrality for all nodes.\n2.  Identify the set of nodes that satisfy the high-betweenness criterion.\n3.  For each node, calculate the relative drop in network efficiency upon its removal.\n4.  Identify the set of nodes that satisfy the compensation (low efficiency drop) criterion.\n5.  The robust bottlenecks are the nodes in the intersection of these two sets.\n\n**1. High-Betweenness Criterion**\n\nA node $v$ is a high-betweenness node if its betweenness centrality $b(v)$ is positive and greater than or equal to the $q$-quantile of all centrality values, $Q_q(b)$. The betweenness centrality is defined as:\n$$\nb(v) = \\sum_{\\substack{s  t\\\\ s \\neq v \\neq t}} \\frac{\\sigma_{st}(v)}{\\sigma_{st}}\n$$\nWe compute $b(v)$ for all nodes using the Brandes algorithm, which is an efficient standard method for this task. After computing all $b(v)$ values, we calculate the quantile $Q_q(b)$ and find the set of nodes $V_{\\text{high-b}} = \\{v \\in V \\mid b(v) \\ge Q_q(b) \\land b(v)  0\\}$.\n\n**2. Compensation Criterion**\n\nThis criterion measures the network's ability to compensate for the removal of a node $v$. It is quantified by the relative efficiency drop, $\\Delta(v)$. This is calculated by comparing the sum of inverse shortest path distances between all pairs in the residual node set $V' = V \\setminus \\{v\\}$, before and after the removal of $v$.\n\n- The \"before\" sum is $S_{\\text{before}}(v) = \\sum_{i,j \\in V', ij} 1/d(i,j)$, where distances $d(i,j)$ are from the original graph.\n- The \"after\" sum is $S_{\\text{after}}(v) = \\sum_{i,j \\in V', ij} 1/d_v(i,j)$, where distances $d_v(i,j)$ are from the graph with $v$ removed.\n\nThe relative drop is $\\Delta(v) = (S_{\\text{before}}(v)-S_{\\text{after}}(v))/S_{\\text{before}}(v)$. A node $v$ is compensated if $\\Delta(v) \\le \\tau$. To calculate these sums, we need all-pairs shortest path (APSP) distances, which we find by running a Breadth-First Search (BFS) from each node.\n\n**3. Final Algorithm**\nThe final list of robust bottlenecks is the sorted intersection of nodes satisfying both the high-betweenness and compensation criteria. This procedure is deterministic and directly implements the problem's definitions.", "answer": "```python\nimport numpy as np\nfrom collections import deque\n\ndef _bfs_for_brandes(adj, s, n):\n    \"\"\"Performs BFS from source s to compute shortest paths info.\"\"\"\n    S = []\n    P = {i: [] for i in range(n)}\n    sigma = {i: 0 for i in range(n)}\n    sigma[s] = 1\n    d = {i: -1 for i in range(n)}\n    d[s] = 0\n    \n    Q = deque([s])\n    \n    while Q:\n        v = Q.popleft()\n        S.append(v)\n        \n        for w in adj.get(v, []):\n            if d[w]  0:\n                Q.append(w)\n                d[w] = d[v] + 1\n            \n            if d[w] == d[v] + 1:\n                sigma[w] += sigma[v]\n                P[w].append(v)\n    return S, P, sigma\n\ndef compute_betweenness_centrality(A):\n    \"\"\"Computes betweenness centrality using Brandes' algorithm for unweighted graphs.\"\"\"\n    n = A.shape[0]\n    if n == 0:\n        return {}\n    \n    adj = {i: [j for j, connected in enumerate(row) if connected] for i, row in enumerate(A)}\n    betweenness = {i: 0.0 for i in range(n)}\n\n    for s in range(n):\n        S, P, sigma = _bfs_for_brandes(adj, s, n)\n        delta = {i: 0.0 for i in range(n)}\n        \n        while S:\n            w = S.pop()\n            for v in P.get(w, []):\n                if sigma.get(w, 0) != 0:\n                    delta[v] += (sigma.get(v, 0) / sigma[w]) * (1.0 + delta.get(w, 0.0))\n            if w != s:\n                betweenness[w] += delta.get(w, 0.0)\n\n    # For undirected graphs, divide by 2\n    for v in range(n):\n        betweenness[v] /= 2.0\n    return betweenness\n\ndef get_apsp_distances(A):\n    \"\"\"Computes all-pairs shortest path distances using BFS from each node.\"\"\"\n    n = A.shape[0]\n    dist = np.full((n, n), np.inf, dtype=float)\n    \n    adj = {i: [j for j, connected in enumerate(row) if connected] for i, row in enumerate(A)}\n\n    for i in range(n):\n        dist[i, i] = 0\n        q = deque([(i, 0)])\n        visited = {i}\n        \n        while q:\n            u, d = q.popleft()\n            for v in adj.get(u, []):\n                if v not in visited:\n                    visited.add(v)\n                    dist[i, v] = d + 1\n                    q.append((v, d + 1))\n    return dist\n\ndef find_robust_bottlenecks(A, q, tau):\n    \"\"\"Finds robust bottlenecks in a graph based on centrality and efficiency criteria.\"\"\"\n    n = A.shape[0]\n    nodes = list(range(n))\n\n    # 1. High-betweenness criterion\n    centralities = compute_betweenness_centrality(A)\n    b_values = np.array(list(centralities.values()))\n    \n    if n = 1 or np.all(b_values == 0):\n        q_threshold = 0.0\n    else:\n        q_threshold = np.quantile(b_values, q, method='linear')\n    \n    high_b_nodes = {v for v, b in centralities.items() if b >= q_threshold and b > 0}\n    \n    if not high_b_nodes:\n        return []\n\n    # 2. Compensation criterion\n    dist_original = get_apsp_distances(A)\n    compensated_nodes = set()\n    \n    for v in nodes:\n        nodes_minus_v = [i for i in nodes if i != v]\n        \n        if len(nodes_minus_v)  2:\n            delta_v = 0.0\n        else:\n            sum_inv_dist_before = 0.0\n            for i_idx, i in enumerate(nodes_minus_v):\n                for j in nodes_minus_v[i_idx + 1:]:\n                    dist = dist_original[i, j]\n                    if np.isfinite(dist) and dist > 0:\n                        sum_inv_dist_before += 1.0 / dist\n            \n            if sum_inv_dist_before == 0.0:\n                delta_v = 0.0\n            else:\n                adj_minus_v = np.delete(np.delete(A, v, axis=0), v, axis=1)\n                dist_after = get_apsp_distances(adj_minus_v)\n                \n                sum_inv_dist_after = 0.0\n                for i in range(len(nodes_minus_v) - 1):\n                    for j in range(i + 1, len(nodes_minus_v)):\n                        dist = dist_after[i, j]\n                        if np.isfinite(dist) and dist > 0:\n                            sum_inv_dist_after += 1.0 / dist\n                \n                delta_v = (sum_inv_dist_before - sum_inv_dist_after) / sum_inv_dist_before\n        \n        if delta_v = tau:\n            compensated_nodes.add(v)\n            \n    result_nodes = sorted(list(high_b_nodes.intersection(compensated_nodes)))\n    return result_nodes\n\ndef solve():\n    \"\"\"Main function to run test cases and print results.\"\"\"\n    \n    # Shared parameters from the problem description\n    q = 0.8\n    tau = 0.01\n\n    # Test Case 1\n    A1 = np.array([\n        [0, 1, 1, 0, 0, 0, 1, 1],\n        [1, 0, 1, 0, 0, 0, 1, 1],\n        [1, 1, 0, 0, 0, 0, 1, 1],\n        [0, 0, 0, 0, 1, 1, 1, 1],\n        [0, 0, 0, 1, 0, 1, 1, 1],\n        [0, 0, 0, 1, 1, 0, 1, 1],\n        [1, 1, 1, 1, 1, 1, 0, 0],\n        [1, 1, 1, 1, 1, 1, 0, 0]\n    ])\n\n    # Test Case 2\n    A2 = np.array([\n        [0, 1, 1, 1, 1, 1],\n        [1, 0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 0, 0]\n    ])\n\n    # Test Case 3\n    A3 = np.array([\n        [0, 1, 1, 1],\n        [1, 0, 1, 1],\n        [1, 1, 0, 1],\n        [1, 1, 1, 0]\n    ])\n\n    test_cases = [A1, A2, A3]\n    \n    all_results = []\n    for A in test_cases:\n        result = find_robust_bottlenecks(A, q, tau)\n        all_results.append(str(result).replace(\" \", \"\"))\n\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "2409636"}]}