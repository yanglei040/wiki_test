{"hands_on_practices": [{"introduction": "A powerful and intuitive way to design a pharmacophore is to directly map the key interaction points within a protein's binding site. This practice [@problem_id:2440150] simulates this process by asking you to build a receptor-guided pharmacophore from the ground up. You will implement a simplified energy function to calculate the interaction between the receptor and virtual chemical probes, then use a grid search to identify energetically favorable \"hotspots\" that define the pharmacophore features, a core technique in structure-based drug design.", "problem": "You are given three-dimensional receptor binding site descriptions consisting of atoms with positions (in Angstroms), element types, and partial charges (dimensionless). Your task is to construct a receptor-guided pharmacophore by identifying spatial hotspots for three probe types: hydrogen-bond donor (D), hydrogen-bond acceptor (A), and hydrophobe (H). A receptor-guided pharmacophore feature is defined here as a local energy minimum for a virtual probe interacting with the receptor, subject to physically motivated interactions. You must implement a grid-based evaluation and return, for each probe type, a small, diversified set of local minima representing key interaction points. All final reported coordinates must be expressed in Angstroms, rounded to three decimals.\n\nFoundational basis and assumptions to use:\n- Electrostatic interaction is governed by Coulomb’s law: the interaction between charges depends on the product of charges and inverse powers of separation. In a heterogeneous medium, a distance-dependent dielectric is a common approximation. Use a distance-dependent dielectric proportional to separation to obtain an inverse-square dependence of electrostatic energy on separation.\n- Short-range steric exclusion is captured by the repulsive part of a van der Waals (vdW) interaction. Approximate this repulsion by a purely repulsive inverse-twelfth power of separation.\n- The hydrophobic effect can be approximated by a spatially decaying occupancy preference around nonpolar carbons. Model this as a spherically symmetric Gaussian well centered on carbon atoms for a hydrophobic probe.\n\nFrom these bases, construct an interaction energy for a probe of type $T \\in \\{\\mathrm{D}, \\mathrm{A}, \\mathrm{H}\\}$ at position $\\mathbf{x}$ relative to receptor atoms indexed by $i$ at positions $\\mathbf{r}_i$ with charges $q_i$:\n- Let $r_i(\\mathbf{x}) = \\max\\{ \\lVert \\mathbf{x} - \\mathbf{r}_i \\rVert_2, r_{\\mathrm{soft}} \\}$ for numerical stability at short range.\n- Electrostatic term: $E_{\\mathrm{elec}}(\\mathbf{x}) = \\sum_i \\dfrac{q_T \\, q_i}{r_i(\\mathbf{x})^2}$ where $q_T$ is the probe’s effective charge: $q_{\\mathrm{D}} = +0.4$, $q_{\\mathrm{A}} = -0.4$, $q_{\\mathrm{H}} = 0.0$ (dimensionless).\n- Steric repulsion term: $E_{\\mathrm{rep}}(\\mathbf{x}) = \\sum_i \\dfrac{k_{\\mathrm{rep}}}{r_i(\\mathbf{x})^{12}}$ with $k_{\\mathrm{rep}} = 0.01$.\n- Hydrophobic term (only for the hydrophobe probe $T = \\mathrm{H}$ and only from carbon atoms): $E_{\\mathrm{hyd}}(\\mathbf{x}) = - \\sum_{i \\in \\mathrm{carbons}} k_{\\mathrm{hyd}} \\, \\exp\\!\\left(-\\dfrac{r_i(\\mathbf{x})^2}{\\sigma^2}\\right)$ with $k_{\\mathrm{hyd}} = 0.3$ and $\\sigma = 2.0$.\n- Total energy for probe $T$: $E_T(\\mathbf{x}) = E_{\\mathrm{elec}}(\\mathbf{x}) + E_{\\mathrm{rep}}(\\mathbf{x}) + 1_{T=\\mathrm{H}} \\, E_{\\mathrm{hyd}}(\\mathbf{x})$.\n\nNumerical parameters and units:\n- Set $r_{\\mathrm{soft}} = 0.5$ Angstroms.\n- All energies are in arbitrary energy units (A.U.). You must not convert units.\n- Grid spacing is $\\Delta = 1.0$ Angstrom.\n\nLocal minima definition and selection:\n- Evaluate $E_T(\\mathbf{x})$ on a three-dimensional grid covering an axis-aligned bounding box defined per test case.\n- A grid point is a local minimum if its value is strictly less than the values at all of its adjacent neighbors in the $3 \\times 3 \\times 3$ cube excluding itself (that is, the $26$ immediate neighbors in three dimensions; for boundary points, compare only to in-bounds neighbors).\n- For each probe type $T$, rank all local minima by energy (ascending).\n- Diversify by spatial clustering: traverse ranked minima (best to worst) and keep a candidate only if it is at least $r_{\\mathrm{cluster}} = 1.0$ Angstrom away (Euclidean distance) from every previously accepted minimum for the same $T$.\n- Keep up to $K = 3$ minima per probe type per test case, subject to an energy cutoff $E_T(\\mathbf{x})  E_{\\mathrm{cut},T}$ with $E_{\\mathrm{cut},\\mathrm{D}} = -0.03$, $E_{\\mathrm{cut},\\mathrm{A}} = -0.03$, $E_{\\mathrm{cut},\\mathrm{H}} = -0.08$ (A.U.).\n- Report the coordinates of the kept minima for each probe type.\n\nTest suite (three cases):\n- Case 1:\n  - Receptor atoms:\n    - Oxygen ($\\mathrm{O}$): position $(0.0, 0.0, 0.0)$, $q = -0.5$.\n    - Nitrogen ($\\mathrm{N}$): position $(3.0, 0.0, 0.0)$, $q = +0.3$.\n    - Carbon ($\\mathrm{C}$): position $(0.0, 3.0, 0.0)$, $q = 0.0$.\n    - Carbon ($\\mathrm{C}$): position $(0.0, -3.0, 0.0)$, $q = 0.0$.\n  - Grid bounding box: center $(0.0, 0.0, 0.0)$, half-extent $4.0$ in each axis, spacing $\\Delta = 1.0$.\n- Case 2:\n  - Receptor atoms:\n    - Oxygen ($\\mathrm{O}$): position $(-2.0, -2.0, 0.0)$, $q = -0.4$.\n    - Oxygen ($\\mathrm{O}$): position $(2.0, 2.0, 0.0)$, $q = -0.4$.\n    - Nitrogen ($\\mathrm{N}$): position $(-2.0, 2.0, 0.0)$, $q = +0.3$.\n    - Carbon ($\\mathrm{C}$): position $(0.0, 0.0, 2.0)$, $q = 0.0$.\n  - Grid bounding box: center $(0.0, 0.0, 0.0)$, half-extent $3.0$ in each axis, spacing $\\Delta = 1.0$.\n- Case 3:\n  - Receptor atoms:\n    - Carbon ($\\mathrm{C}$): position $(-1.5, 0.0, 0.0)$, $q = 0.0$.\n    - Carbon ($\\mathrm{C}$): position $(1.5, 0.0, 0.0)$, $q = 0.0$.\n    - Carbon ($\\mathrm{C}$): position $(0.0, 2.0, 0.0)$, $q = 0.0$.\n  - Grid bounding box: center $(0.0, 0.0, 0.0)$, half-extent $3.0$ in each axis, spacing $\\Delta = 1.0$.\n\nProgram requirements:\n- Implement the energy model as described above from the foundational bases, evaluate on the specified grids, detect and select local minima as defined, and apply clustering and cutoffs.\n- For each test case, produce an ordered list of three lists $[\\mathrm{D}, \\mathrm{A}, \\mathrm{H}]$, where each of the three is a list of three-dimensional points $[x, y, z]$ (in Angstroms) corresponding to the selected minima for that probe type, rounded to three decimals.\n- Your program should produce a single line of output containing the results for all three test cases as a comma-separated list enclosed in square brackets. Concretely: a list of length three, where each element is itself the $[\\mathrm{D}, \\mathrm{A}, \\mathrm{H}]$ triple for a test case. Each coordinate must be rounded to three decimals and expressed in Angstroms. Example of required shape (not actual values): \n  - $[[[\\cdot,\\cdot,\\cdot],\\ldots],[[\\cdot,\\cdot,\\cdot],\\ldots],[[\\cdot,\\cdot,\\cdot],\\ldots]], \\ldots$ for the three cases.\n- The final output must be a single line with no extra text. All reported coordinates must be rounded to three decimals (Angstroms).", "solution": "The problem statement has been subjected to rigorous validation and is found to be scientifically sound and computationally well-posed. It presents a clearly defined task in computational drug design, specifically the generation of a receptor-guided pharmacophore. The physical model, while simplified, is based on established principles of molecular mechanics. All necessary parameters and algorithmic steps are provided, rendering the problem unambiguous and solvable. We proceed to the solution.\n\nThe core of the problem is to identify energetically favorable positions for three types of chemical probes—a hydrogen-bond donor ($D$), a hydrogen-bond acceptor ($A$), and a hydrophobic group ($H$)—within the binding site of a receptor. These favorable positions, or \"hotspots,\" are defined as local minima on a potential energy surface. The solution is constructed through a multi-step computational procedure.\n\n### 1. Potential Energy Functions\n\nThe interaction between a virtual probe of type $T \\in \\{D, A, H\\}$ at position $\\mathbf{x}$ and the receptor atoms is modeled by a potential energy function $E_T(\\mathbf{x})$. This function is a sum of electrostatic, steric repulsion, and, for the hydrophobic probe, hydrophobic interaction terms. Let the receptor consist of atoms indexed by $i$ at positions $\\mathbf{r}_i$ with partial charges $q_i$. The distance between the probe and atom $i$ is given by $d_i(\\mathbf{x}) = \\lVert \\mathbf{x} - \\mathbf{r}_i \\rVert_2$. To prevent numerical instability at vanishing separations, a softened distance, $r_i(\\mathbf{x})$, is used:\n$$\nr_i(\\mathbf{x}) = \\max \\{ d_i(\\mathbf{x}), r_{\\mathrm{soft}} \\}\n$$\nwhere the softening parameter is $r_{\\mathrm{soft}} = 0.5$ Angstroms.\n\nThe total energy $E_T(\\mathbf{x})$ is defined as:\n$$\nE_T(\\mathbf{x}) = E_{\\mathrm{elec}}(\\mathbf{x}) + E_{\\mathrm{rep}}(\\mathbf{x}) + \\delta_{TH} \\, E_{\\mathrm{hyd}}(\\mathbf{x})\n$$\nwhere $\\delta_{TH}$ is the Kronecker delta, equal to $1$ if the probe type $T$ is $H$ and $0$ otherwise.\n\n**1.1. Electrostatic Energy ($E_{\\mathrm{elec}}$)**\nThis term models the Coulombic interaction. The problem specifies a distance-dependent dielectric, leading to an inverse-square dependence of energy on separation. The probe has an effective charge $q_T$.\n$$\nE_{\\mathrm{elec}}(\\mathbf{x}) = \\sum_i \\frac{q_T \\, q_i}{r_i(\\mathbf{x})^2}\n$$\nThe probe charges are defined as $q_D = +0.4$, $q_A = -0.4$, and $q_H = 0.0$.\n\n**1.2. Steric Repulsion Energy ($E_{\\mathrm{rep}}$)**\nThis term models the strong, short-range repulsion between electron clouds, a consequence of the Pauli exclusion principle. It is approximated by an inverse-twelfth power law, a standard component of Lennard-Jones potentials.\n$$\nE_{\\mathrm{rep}}(\\mathbf{x}) = \\sum_i \\frac{k_{\\mathrm{rep}}}{r_i(\\mathbf{x})^{12}}\n$$\nThe repulsion strength constant is given as $k_{\\mathrm{rep}} = 0.01$.\n\n**1.3. Hydrophobic Energy ($E_{\\mathrm{hyd}}$)**\nThis term is specific to the hydrophobic probe ($T=H$) and models the tendency of nonpolar groups to cluster together to minimize disruption of the hydrogen-bonding network of a solvent (an effect implicitly modeled here). The interaction is attractive and is modeled as a sum of Gaussian wells centered on the receptor's nonpolar carbon atoms.\n$$\nE_{\\mathrm{hyd}}(\\mathbf{x}) = - \\sum_{i \\in \\text{carbons}} k_{\\mathrm{hyd}} \\exp\\left(-\\frac{r_i(\\mathbf{x})^2}{\\sigma^2}\\right)\n$$\nThe parameters for this potential are the strength $k_{\\mathrm{hyd}} = 0.3$ and the spatial extent $\\sigma = 2.0$ Angstroms.\n\n### 2. Grid-Based Evaluation\n\nThe continuous potential energy surface is discretized for computational analysis. For each test case, a three-dimensional grid of points is generated within a specified axis-aligned bounding box. The grid spacing is uniform, with $\\Delta = 1.0$ Angstrom. For each probe type $T$, the energy $E_T(\\mathbf{x})$ is computed at every grid point $\\mathbf{x}$, resulting in a three-dimensional array of energy values, which we denote as the energy grid.\n\n### 3. Identification of Local Minima\n\nA grid point is identified as a local minimum if its energy value is strictly less than the energy values of all its immediate neighbors. For a point in the interior of the grid, there are $3^3 - 1 = 26$ such neighbors. For points on the boundaries, faces, or corners of the grid, comparisons are made only with neighbors that lie within the grid. The algorithm iterates through every point on the energy grid and performs these comparisons to compile a list of all local minima, storing their grid coordinates and corresponding energy values.\n\n### 4. Selection and Diversification of Minima\n\nThe raw set of local minima must be filtered to yield a small, diverse set of the most significant interaction hotspots. This is accomplished through a sequential four-step process for each probe type.\n\n**4.1. Energy Cutoff:** Minima that are not sufficiently favorable are discarded. A candidate minimum at position $\\mathbf{x}$ is kept only if its energy $E_T(\\mathbf{x})$ is below a type-specific threshold:\n$$\nE_T(\\mathbf{x})  E_{\\mathrm{cut},T}\n$$\nThe cutoffs are given as $E_{\\mathrm{cut},D} = -0.03$, $E_{\\mathrm{cut},A} = -0.03$, and $E_{\\mathrm{cut},H} = -0.08$ (in arbitrary energy units).\n\n**4.2. Ranking:** The surviving minima are sorted in ascending order of their energy values, from most favorable to least favorable.\n\n**4.3. Spatial Clustering:** To ensure a diverse set of pharmacophore features, a spatial clustering procedure is applied. The algorithm iterates through the ranked list of minima. The first minimum (the one with the lowest energy) is always accepted. A subsequent minimum is accepted only if its position is at least a distance of $r_{\\mathrm{cluster}} = 1.0$ Angstrom away from all previously accepted minima for that same probe type. This prevents the selection of multiple redundant minima from the same pocket or interaction region.\n\n**4.4. Final Selection:** The process continues until a maximum of $K=3$ diverse, low-energy minima are accepted for each probe type. The final output for each probe type is the list of coordinates of these selected minima. If fewer than $K$ minima satisfy all criteria, the list will be correspondingly shorter. The coordinates are reported in Angstroms, rounded to three decimal places.\n\nThis entire procedure is systematically applied to each test case provided in the problem statement.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the pharmacophore generation for all test cases.\n    \"\"\"\n    \n    # Define physical and numerical parameters\n    PROBE_CHARGES = {'D': 0.4, 'A': -0.4, 'H': 0.0}\n    K_REP = 0.01\n    K_HYD = 0.3\n    SIGMA_HYD = 2.0\n    R_SOFT = 0.5\n    R_CLUSTER = 1.0\n    K_MAX_MINIMA = 3\n    ENERGY_CUTOFFS = {'D': -0.03, 'A': -0.03, 'H': -0.08}\n    PROBE_TYPES = ['D', 'A', 'H']\n\n    # Define the test cases from the problem statement.\n    # Each case: {atoms: [(pos, charge, type)], grid: (center, half_extent, spacing)}\n    test_cases = [\n        {\n            \"atoms\": [\n                (np.array([0.0, 0.0, 0.0]), -0.5, 'O'),\n                (np.array([3.0, 0.0, 0.0]), 0.3, 'N'),\n                (np.array([0.0, 3.0, 0.0]), 0.0, 'C'),\n                (np.array([0.0, -3.0, 0.0]), 0.0, 'C'),\n            ],\n            \"grid\": {\"center\": np.array([0.0, 0.0, 0.0]), \"half_extent\": 4.0, \"spacing\": 1.0},\n        },\n        {\n            \"atoms\": [\n                (np.array([-2.0, -2.0, 0.0]), -0.4, 'O'),\n                (np.array([2.0, 2.0, 0.0]), -0.4, 'O'),\n                (np.array([-2.0, 2.0, 0.0]), 0.3, 'N'),\n                (np.array([0.0, 0.0, 2.0]), 0.0, 'C'),\n            ],\n            \"grid\": {\"center\": np.array([0.0, 0.0, 0.0]), \"half_extent\": 3.0, \"spacing\": 1.0},\n        },\n        {\n            \"atoms\": [\n                (np.array([-1.5, 0.0, 0.0]), 0.0, 'C'),\n                (np.array([1.5, 0.0, 0.0]), 0.0, 'C'),\n                (np.array([0.0, 2.0, 0.0]), 0.0, 'C'),\n            ],\n            \"grid\": {\"center\": np.array([0.0, 0.0, 0.0]), \"half_extent\": 3.0, \"spacing\": 1.0},\n        },\n    ]\n\n    def calculate_energy(probe_pos, probe_type, atoms):\n        \"\"\"Calculates the interaction energy for a probe at a given position.\"\"\"\n        probe_charge = PROBE_CHARGES[probe_type]\n        e_elec, e_rep, e_hyd = 0.0, 0.0, 0.0\n\n        for atom_pos, atom_charge, atom_type in atoms:\n            dist = np.linalg.norm(probe_pos - atom_pos)\n            r = max(dist, R_SOFT)\n            \n            # Electrostatic term\n            e_elec += (probe_charge * atom_charge) / (r ** 2)\n            \n            # Repulsion term\n            e_rep += K_REP / (r ** 12)\n            \n            # Hydrophobic term\n            if probe_type == 'H' and atom_type == 'C':\n                e_hyd -= K_HYD * np.exp(-(r ** 2) / (SIGMA_HYD ** 2))\n                \n        return e_elec + e_rep + e_hyd\n\n    def solve_case(case):\n        \"\"\"Solves a single test case.\"\"\"\n        atoms = case[\"atoms\"]\n        center = case[\"grid\"][\"center\"]\n        half_extent = case[\"grid\"][\"half_extent\"]\n        spacing = case[\"grid\"][\"spacing\"]\n\n        # Generate grid coordinates\n        axis_coords = np.arange(center[0] - half_extent, center[0] + half_extent + spacing / 2, spacing)\n        grid_x, grid_y, grid_z = np.meshgrid(axis_coords, axis_coords, axis_coords, indexing='ij')\n        grid_shape = grid_x.shape\n        grid_points = np.stack([grid_x, grid_y, grid_z], axis=-1)\n\n        case_results = []\n        for probe_type in PROBE_TYPES:\n            # Calculate energy on the grid\n            energy_grid = np.zeros(grid_shape)\n            for i in range(grid_shape[0]):\n                for j in range(grid_shape[1]):\n                    for k in range(grid_shape[2]):\n                        probe_pos = grid_points[i, j, k]\n                        energy_grid[i, j, k] = calculate_energy(probe_pos, probe_type, atoms)\n\n            # Find local minima\n            local_minima = []\n            for i in range(grid_shape[0]):\n                for j in range(grid_shape[1]):\n                    for k in range(grid_shape[2]):\n                        val = energy_grid[i, j, k]\n                        is_min = True\n                        for di in [-1, 0, 1]:\n                            for dj in [-1, 0, 1]:\n                                for dk in [-1, 0, 1]:\n                                    if di == 0 and dj == 0 and dk == 0:\n                                        continue\n                                    ni, nj, nk = i + di, j + dj, k + dk\n                                    if 0 = ni  grid_shape[0] and 0 = nj  grid_shape[1] and 0 = nk  grid_shape[2]:\n                                        if energy_grid[ni, nj, nk] = val:\n                                            is_min = False\n                                            break\n                                if not is_min: break\n                            if not is_min: break\n                        if is_min:\n                            local_minima.append({\n                                'coord': grid_points[i, j, k],\n                                'energy': val\n                            })\n            \n            # Filter, sort, and diversify minima\n            # 1. Energy cutoff\n            filtered_minima = [m for m in local_minima if m['energy']  ENERGY_CUTOFFS[probe_type]]\n            \n            # 2. Sort by energy\n            sorted_minima = sorted(filtered_minima, key=lambda m: m['energy'])\n            \n            # 3. Diversify by clustering and limit to K\n            accepted_minima_coords = []\n            for minimum in sorted_minima:\n                if len(accepted_minima_coords) >= K_MAX_MINIMA:\n                    break\n                \n                is_distant_enough = True\n                for accepted_coord in accepted_minima_coords:\n                    if np.linalg.norm(minimum['coord'] - accepted_coord)  R_CLUSTER:\n                        is_distant_enough = False\n                        break\n                \n                if is_distant_enough:\n                    accepted_minima_coords.append(minimum['coord'])\n\n            case_results.append(accepted_minima_coords)\n\n        return case_results\n\n    # Process all test cases\n    all_results = [solve_case(case) for case in test_cases]\n\n    # Format the final output string\n    def format_point(p):\n        return f\"[{p[0]:.3f},{p[1]:.3f},{p[2]:.3f}]\"\n\n    def format_point_list(pl):\n        return f\"[{','.join(format_point(p) for p in pl)}]\"\n\n    def format_case_result(cr):\n        # cr is [D_points, A_points, H_points]\n        return f\"[{format_point_list(cr[0])},{format_point_list(cr[1])},{format_point_list(cr[2])}]\"\n\n    final_output_str = f\"[{','.join(format_case_result(r) for r in all_results)}]\"\n    print(final_output_str)\n\nsolve()\n```", "id": "2440150"}, {"introduction": "Moving from simple feature-matching to predictive modeling requires a more quantitative approach. This exercise [@problem_id:2414221] guides you through the process of weighting pharmacophore features based on their statistical enrichment in active versus inactive compounds. By applying a Bayesian framework, you will learn to calculate an \"importance weight\" for each feature, transforming a qualitative model into a more powerful, evidence-based scoring function that is central to modern machine learning in drug discovery.", "problem": "A pharmacophore model for small molecules is represented by a fixed set of binary features indexed by $j \\in \\{1,\\dots,d\\}$, where each feature encodes the presence or absence of a pharmacophoric element (for example, a hydrogen bond donor at a location) in a ligand. A dataset contains ligands labeled as active or inactive. For each feature $j$, let $x_{j} \\in \\{0,1\\}$ denote whether the feature is present in a ligand, and let $y \\in \\{0,1\\}$ denote the class label, where $y=1$ indicates active and $y=0$ indicates inactive. Assume the following probabilistic model: conditional on $y=c \\in \\{0,1\\}$ and for each feature $j$, $x_{j} \\mid y=c \\sim \\mathrm{Bernoulli}(\\theta^{(c)}_{j})$, where the parameters $\\theta^{(c)}_{j}$ are unknown and independent across $j$ and $c$. Assume independent Beta priors $\\theta^{(c)}_{j} \\sim \\mathrm{Beta}(\\alpha,\\beta)$ with fixed hyperparameters $\\alpha>0$ and $\\beta>0$ shared across all $j$ and $c$. For each feature $j$, the training data for class $c$ are summarized by $N^{(c)}$ total ligands and $n^{(c)}_{j}$ ligands in which $x_{j}=1$.\n\nDefine the importance weight of feature $j$ to be\n$$\nw_{j} \\equiv \\log\\left(\\frac{\\mathrm{odds}\\!\\left(\\mathbb{E}[\\theta^{(1)}_{j} \\mid \\text{data}]\\right)}{\\mathrm{odds}\\!\\left(\\mathbb{E}[\\theta^{(0)}_{j} \\mid \\text{data}]\\right)}\\right),\n$$\nwhere for any $p \\in (0,1)$, $\\mathrm{odds}(p) \\equiv \\dfrac{p}{1-p}$, and $\\mathbb{E}[\\theta^{(c)}_{j} \\mid \\text{data}]$ denotes the posterior mean of $\\theta^{(c)}_{j}$ under the model and prior above given the summarized counts. All logarithms are natural logarithms. The output for a test case is the list $[w_{1},\\dots,w_{d}]$ in the order of features.\n\nCompute $[w_{1},\\dots,w_{d}]$ for each of the following test cases. For each case, you are given the number of actives $N^{(1)}$, the number of inactives $N^{(0)}$, the active counts vector $[n^{(1)}_{1},\\dots,n^{(1)}_{d}]$, the inactive counts vector $[n^{(0)}_{1},\\dots,n^{(0)}_{d}]$, and the shared Beta prior hyperparameters $(\\alpha,\\beta)$.\n\nTest Suite:\n- Case $1$: $N^{(1)}=10$, $N^{(0)}=12$, $[n^{(1)}_{j}]_{j=1}^{4} = [6,2,8,0]$, $[n^{(0)}_{j}]_{j=1}^{4} = [1,5,6,0]$, $(\\alpha,\\beta)=(0.5,0.5)$.\n- Case $2$: $N^{(1)}=3$, $N^{(0)}=20$, $[n^{(1)}_{j}]_{j=1}^{3} = [0,3,0]$, $[n^{(0)}_{j}]_{j=1}^{3} = [10,0,1]$, $(\\alpha,\\beta)=(0.5,0.5)$.\n- Case $3$: $N^{(1)}=50$, $N^{(0)}=50$, $[n^{(1)}_{j}]_{j=1}^{4} = [25,50,0,1]$, $[n^{(0)}_{j}]_{j=1}^{4} = [25,50,0,2]$, $(\\alpha,\\beta)=(1.0,1.0)$.\n- Case $4$: $N^{(1)}=1$, $N^{(0)}=1$, $[n^{(1)}_{j}]_{j=1}^{2} = [1,0]$, $[n^{(0)}_{j}]_{j=1}^{2} = [0,1]$, $(\\alpha,\\beta)=(2.0,3.0)$.\n\nAnswer specification:\n- For each test case, compute the vector $[w_{1},\\dots,w_{d}]$ in natural logarithm units as defined above.\n- Return each $w_{j}$ rounded to $6$ decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the bracketed, comma-separated list for a test case. For example, the overall structure must be $[[r_{1,1},\\dots,r_{1,d_{1}}],[r_{2,1},\\dots,r_{2,d_{2}}],\\dots]$ with no spaces, where $r_{k,\\ell}$ denotes the rounded value for feature $\\ell$ in case $k$.", "solution": "The problem statement has been validated and is deemed acceptable. It presents a standard, well-posed problem in Bayesian statistical modeling applied to computational biology, specifically in the context of pharmacophore analysis. All necessary information is provided, the premises are scientifically sound, and there are no contradictions or ambiguities. We may proceed with the solution.\n\nThe problem requires the computation of a feature importance weight, $w_{j}$, defined as the log-odds ratio of posterior mean probabilities for a feature being present in active versus inactive molecules. The model is a Naive Bayes classifier with Bernoulli-distributed features and Beta-distributed priors on the Bernoulli parameters.\n\nLet us begin by formalizing the Bayesian inference for a single parameter $\\theta^{(c)}_{j}$, which is the probability of feature $j$ being present ($x_j=1$) in a ligand of class $c \\in \\{0, 1\\}$.\n\nThe prior distribution for the parameter $\\theta^{(c)}_{j}$ is given as a Beta distribution with hyperparameters $\\alpha$ and $\\beta$:\n$$\n\\theta^{(c)}_{j} \\sim \\mathrm{Beta}(\\alpha, \\beta)\n$$\nThe probability density function (PDF) is proportional to:\n$$\np(\\theta^{(c)}_{j}) \\propto (\\theta^{(c)}_{j})^{\\alpha-1} (1 - \\theta^{(c)}_{j})^{\\beta-1}\n$$\n\nThe data for feature $j$ and class $c$ consists of $N^{(c)}$ ligands, among which $n^{(c)}_{j}$ have the feature present ($x_j=1$) and $N^{(c)} - n^{(c)}_{j}$ have the feature absent ($x_j=0$). Assuming the ligands are independent and identically distributed, the likelihood of observing $n^{(c)}_{j}$ successes in $N^{(c)}$ trials follows a binomial distribution. The likelihood function for $\\theta^{(c)}_{j}$ is:\n$$\nL(\\text{data} \\mid \\theta^{(c)}_{j}) = P(n^{(c)}_{j} \\mid N^{(c)}, \\theta^{(c)}_{j}) \\propto (\\theta^{(c)}_{j})^{n^{(c)}_{j}} (1 - \\theta^{(c)}_{j})^{N^{(c)} - n^{(c)}_{j}}\n$$\n\nAccording to Bayes' theorem, the posterior distribution of $\\theta^{(c)}_{j}$ is proportional to the product of the prior and the likelihood:\n$$\np(\\theta^{(c)}_{j} \\mid \\text{data}) \\propto p(\\theta^{(c)}_{j}) \\cdot L(\\text{data} \\mid \\theta^{(c)}_{j})\n$$\n$$\np(\\theta^{(c)}_{j} \\mid \\text{data}) \\propto \\left((\\theta^{(c)}_{j})^{\\alpha-1} (1 - \\theta^{(c)}_{j})^{\\beta-1}\\right) \\cdot \\left((\\theta^{(c)}_{j})^{n^{(c)}_{j}} (1 - \\theta^{(c)}_{j})^{N^{(c)} - n^{(c)}_{j}}\\right)\n$$\nCombining terms, we get:\n$$\np(\\theta^{(c)}_{j} \\mid \\text{data}) \\propto (\\theta^{(c)}_{j})^{n^{(c)}_{j} + \\alpha - 1} (1 - \\theta^{(c)}_{j})^{N^{(c)} - n^{(c)}_{j} + \\beta - 1}\n$$\nThis expression is the kernel of a Beta distribution. This demonstrates the conjugacy of the Beta prior with the Bernoulli/Binomial likelihood. The posterior distribution is therefore:\n$$\n\\theta^{(c)}_{j} \\mid \\text{data} \\sim \\mathrm{Beta}(\\alpha', \\beta')\n$$\nwhere the posterior hyperparameters $\\alpha'$ and $\\beta'$ are:\n$$\n\\alpha' = n^{(c)}_{j} + \\alpha\n$$\n$$\n\\beta' = N^{(c)} - n^{(c)}_{j} + \\beta\n$$\n\nThe problem requires the posterior mean, $\\mathbb{E}[\\theta^{(c)}_{j} \\mid \\text{data}]$. For a random variable $X \\sim \\mathrm{Beta}(a,b)$, its expectation is $\\mathbb{E}[X] = \\frac{a}{a+b}$. Applying this to our posterior distribution, we find the posterior mean of $\\theta^{(c)}_{j}$:\n$$\n\\hat{\\theta}^{(c)}_{j} \\equiv \\mathbb{E}[\\theta^{(c)}_{j} \\mid \\text{data}] = \\frac{\\alpha'}{\\alpha' + \\beta'} = \\frac{n^{(c)}_{j} + \\alpha}{(n^{(c)}_{j} + \\alpha) + (N^{(c)} - n^{(c)}_{j} + \\beta)} = \\frac{n^{(c)}_{j} + \\alpha}{N^{(c)} + \\alpha + \\beta}\n$$\n\nNext, we compute the odds of this posterior mean probability. The odds function is defined as $\\mathrm{odds}(p) = \\frac{p}{1-p}$.\nFor $\\hat{\\theta}^{(c)}_{j}$, we have:\n$$\n1 - \\hat{\\theta}^{(c)}_{j} = 1 - \\frac{n^{(c)}_{j} + \\alpha}{N^{(c)} + \\alpha + \\beta} = \\frac{(N^{(c)} + \\alpha + \\beta) - (n^{(c)}_{j} + \\alpha)}{N^{(c)} + \\alpha + \\beta} = \\frac{N^{(c)} - n^{(c)}_{j} + \\beta}{N^{(c)} + \\alpha + \\beta}\n$$\nTherefore, the odds are:\n$$\n\\mathrm{odds}(\\hat{\\theta}^{(c)}_{j}) = \\frac{\\hat{\\theta}^{(c)}_{j}}{1 - \\hat{\\theta}^{(c)}_{j}} = \\frac{\\frac{n^{(c)}_{j} + \\alpha}{N^{(c)} + \\alpha + \\beta}}{\\frac{N^{(c)} - n^{(c)}_{j} + \\beta}{N^{(c)} + \\alpha + \\beta}} = \\frac{n^{(c)}_{j} + \\alpha}{N^{(c)} - n^{(c)}_{j} + \\beta}\n$$\n\nFinally, we substitute this expression into the definition of the importance weight $w_{j}$:\n$$\nw_{j} = \\log\\left(\\frac{\\mathrm{odds}(\\hat{\\theta}^{(1)}_{j})}{\\mathrm{odds}(\\hat{\\theta}^{(0)}_{j})}\\right) = \\log\\left( \\frac{\\frac{n^{(1)}_{j} + \\alpha}{N^{(1)} - n^{(1)}_{j} + \\beta}}{\\frac{n^{(0)}_{j} + \\alpha}{N^{(0)} - n^{(0)}_{j} + \\beta}} \\right)\n$$\nUsing the property of logarithms, $\\log(\\frac{A}{B}) = \\log(A) - \\log(B)$, this can be written as:\n$$\nw_{j} = \\log\\left(\\frac{n^{(1)}_{j} + \\alpha}{N^{(1)} - n^{(1)}_{j} + \\beta}\\right) - \\log\\left(\\frac{n^{(0)}_{j} + \\alpha}{N^{(0)} - n^{(0)}_{j} + \\beta}\\right)\n$$\nThis is the final, operational formula for computing the weight of each feature $j$. This formula is now applied to each of the provided test cases.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the pharmacophore feature weighting problem for the given test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'N1': 10, 'N0': 12, 'n1': np.array([6, 2, 8, 0]), 'n0': np.array([1, 5, 6, 0]), 'alpha': 0.5, 'beta': 0.5},\n        {'N1': 3, 'N0': 20, 'n1': np.array([0, 3, 0]), 'n0': np.array([10, 0, 1]), 'alpha': 0.5, 'beta': 0.5},\n        {'N1': 50, 'N0': 50, 'n1': np.array([25, 50, 0, 1]), 'n0': np.array([25, 50, 0, 2]), 'alpha': 1.0, 'beta': 1.0},\n        {'N1': 1, 'N0': 1, 'n1': np.array([1, 0]), 'n0': np.array([0, 1]), 'alpha': 2.0, 'beta': 3.0}\n    ]\n\n    # A helper function to compute weights for a single case.\n    def compute_weights(N1, N0, n1_vec, n0_vec, alpha, beta):\n        \"\"\"\n        Computes the importance weights w_j for a single test case.\n        \n        The formula for w_j is:\n        w_j = log(odds(E[theta_j^1|data])) - log(odds(E[theta_j^0|data]))\n            = log((n1_j + alpha) / (N1 - n1_j + beta)) - log((n0_j + alpha) / (N0 - n0_j + beta))\n        \n        Args:\n            N1 (int): Number of active ligands.\n            N0 (int): Number of inactive ligands.\n            n1_vec (np.ndarray): Counts of feature presence for active ligands.\n            n0_vec (np.ndarray): Counts of feature presence for inactive ligands.\n            alpha (float): Beta prior hyperparameter.\n            beta (float): Beta prior hyperparameter.\n        \n        Returns:\n            np.ndarray: An array of computed weights w_j.\n        \"\"\"\n        # Posterior odds for the active class (c=1)\n        odds1 = (n1_vec + alpha) / (N1 - n1_vec + beta)\n        \n        # Posterior odds for the inactive class (c=0)\n        odds0 = (n0_vec + alpha) / (N0 - n0_vec + beta)\n        \n        # Compute the log-odds ratio, which is the feature weight w_j\n        weights = np.log(odds1) - np.log(odds0)\n        \n        return weights\n\n    all_results_str = []\n    for case in test_cases:\n        # Extract parameters for the current case\n        N1 = case['N1']\n        N0 = case['N0']\n        n1_vec = case['n1']\n        n0_vec = case['n0']\n        alpha = case['alpha']\n        beta = case['beta']\n\n        # Calculate the weights for the current case\n        weights = compute_weights(N1, N0, n1_vec, n0_vec, alpha, beta)\n        \n        # Format the results for the current case to 6 decimal places\n        case_result_str = f\"[{','.join([f'{w:.6f}' for w in weights])}]\"\n        \n        all_results_str.append(case_result_str)\n\n    # Combine all case results into the final specified format\n    final_output = f\"[{','.join(all_results_str)}]\"\n    \n    # Print the final result string\n    print(final_output)\n\nsolve()\n```", "id": "2414221"}, {"introduction": "Building a model is straightforward, but proving its predictive power is the most critical and challenging step. This is especially true when your model is based on very limited data, where the risk of creating a model that is overfitted and fails to generalize is high. This exercise [@problem_id:2414165] is a practice in scientific rigor, challenging you to design a robust validation strategy for a pharmacophore built from only three active ligands, forcing you to consider concepts like cross-validation, the use of decoy sets, and statistical significance to ensure your model is truly useful.", "problem": "You are given a ligand-based pharmacophore model $\\mathcal{P}$ built from only $3$ known active ligands against a single protein target. Each active was prepared with a conformational ensemble, and $\\mathcal{P}$ consists of standard features (for example, hydrogen-bond donor, hydrogen-bond acceptor, aromatic ring, hydrophobe, positive ionizable) and excluded volumes. You have access to a large corporate compound library, a curated set of property-matched decoys for the known actives, and a small literature-derived set of known inactives for the same target. Wet-lab resources are limited, so any validation must be primarily computational. Which validation strategy is the most appropriate to assess whether $\\mathcal{P}$ generalizes beyond the training actives and truly enriches for actives while controlling for overfitting in the face of only $3$ training ligands?\n\nA. Use leave-one-out cross-validation across the $3$ actives to assess the stability of feature mapping, then perform retrospective virtual screening against an independent, property-matched decoy set and known inactives; quantify performance with Receiver Operating Characteristic (ROC) Area Under the Curve (AUC) and early enrichment metrics, and benchmark significance by comparing to randomized models generated via label permutation or feature scrambling.\n\nB. Declare validation successful if all $3$ training actives map every feature in $\\mathcal{P}$ at $0$ tolerance and achieve high pharmacophore fit scores; this demonstrates perfect internal consistency.\n\nC. Redock the $3$ actives into a homology model of the protein target, confirm low Root-Mean-Square Deviation (RMSD) for the docked poses relative to known or hypothesized binding modes, and infer that $\\mathcal{P}$ is validated if RMSD is low.\n\nD. Increase the number of pharmacophore features and add additional excluded volumes until no decoys in the corporate library match $\\mathcal{P}$; the absence of decoy matches indicates high specificity and thus successful validation.\n\nE. Perform a prospective test by selecting a few top-scoring compounds from the same pool used during model setup, test them in vitro, and accept the pharmacophore as validated if at least one hit shows measurable activity, without conducting any retrospective benchmarking against decoys or randomized controls.", "solution": "The problem statement must first be validated for scientific and logical integrity.\n\n**Step 1: Extract Givens**\n- A ligand-based pharmacophore model, denoted $\\mathcal{P}$, is provided.\n- $\\mathcal{P}$ was constructed from a training set of $3$ known active ligands for a single protein target.\n- Conformational ensembles were used for the active ligands.\n- $\\mathcal{P}$ is defined by standard pharmacophoric features (hydrogen-bond donor, hydrogen-bond acceptor, aromatic ring, hydrophobe, positive ionizable) and excluded volumes.\n- Available data includes: a large corporate compound library, a curated set of property-matched decoys for the known actives, and a small set of known inactives.\n- A key constraint is that wet-lab resources are limited.\n- The objective is to identify the most appropriate validation strategy to evaluate if $\\mathcal{P}$ generalizes, enriches for active compounds, and controls for overfitting, given the small training set size of $3$ ligands.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem statement is assessed against the required criteria.\n- **Scientifically Grounded**: The problem is firmly rooted in the established principles of computational drug discovery and specifically, pharmacophore modeling. The concepts of training sets, decoys, enrichment, overfitting, cross-validation, and statistical validation are standard and central to the field. The scenario of building a model from a very small number of actives (e.g., $3$) is a common and challenging real-world problem.\n- **Well-Posed**: The question is well-posed. It asks for the *most appropriate* strategy from a set of mutually exclusive options, requiring a comparative analysis based on best practices in cheminformatics.\n- **Objective**: The language is technical, precise, and free of subjective or ambiguous terminology.\n\nThe problem statement exhibits no flaws. It is scientifically sound, well-posed, objective, and describes a realistic and non-trivial challenge in computational biology.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. A solution will be derived by evaluating each option.\n\nThe fundamental challenge posed by a training set of size $N=3$ is the extremely high risk of overfitting. An overfitted model will perfectly capture the features of the training data but will fail to generalize to new, unseen compounds. Therefore, a valid strategy must rigorously assess the model's predictive power on independent data and quantify the statistical significance of its performance to ensure it is not a result of chance correlation.\n\n**Option-by-Option Analysis**\n\n**A. Use leave-one-out cross-validation across the $3$ actives to assess the stability of feature mapping, then perform retrospective virtual screening against an independent, property-matched decoy set and known inactives; quantify performance with Receiver Operating Characteristic (ROC) Area Under the Curve (AUC) and early enrichment metrics, and benchmark significance by comparing to randomized models generated via label permutation or feature scrambling.**\n\nThis option presents a multi-faceted and rigorous validation protocol.\n1.  **Leave-one-out cross-validation (LOOCV)**: With $N=3$ ligands, this means generating $3$ models, each trained on $2$ ligands and tested on the one held out. This directly assesses the stability and consensus of the pharmacophore features. If the resulting pharmacophores are wildly different, it suggests the model is unstable and not capturing a true common feature pattern.\n2.  **Retrospective virtual screening**: Screening the model against an independent test set of known inactives and, crucially, property-matched decoys is the gold standard for assessing a model's ability to distinguish actives from non-actives. Property-matching ensures that the model is discriminating based on specific 3D features rather than trivial physicochemical properties (e.g., molecular weight, hydrophobicity).\n3.  **Performance quantification (ROC AUC, enrichment)**: Using standard metrics like ROC AUC provides a robust measure of overall discriminatory power, while early enrichment metrics (e.g., Enrichment Factor) assess the model's practical utility in prioritizing a small fraction of a large library for experimental testing.\n4.  **Significance testing (randomized models)**: This is the most critical step for a small training set. By generating models from randomized data (e.g., training on decoys and testing on actives, or \"y-scrambling\") and comparing the performance of the real model $\\mathcal{P}$ to the distribution of performance from random models, one can calculate a p-value. This robustly demonstrates whether the model's performance is statistically significant or likely due to chance.\n\nThis comprehensive approach directly addresses the primary concerns of generalization, enrichment, and overfitting in a statistically sound manner.\n**Verdict: Correct.**\n\n**B. Declare validation successful if all $3$ training actives map every feature in $\\mathcal{P}$ at $0$ tolerance and achieve high pharmacophore fit scores; this demonstrates perfect internal consistency.**\n\nThis strategy is fundamentally flawed. It only assesses the model's performance on the data used to create it (the training set). By definition, a model can be constructed to fit its training data perfectly. This provides zero information about its ability to generalize to new compounds. This is a classic example of circular reasoning and demonstrates a misunderstanding of the concept of validation, which must involve performance on unseen data. A fit with $0$ tolerance is also physically meaningless and would guarantee failure on any molecule not identical to the training set conformation.\n**Verdict: Incorrect.**\n\n**C. Redock the $3$ actives into a homology model of the protein target, confirm low Root-Mean-Square Deviation (RMSD) for the docked poses relative to known or hypothesized binding modes, and infer that $\\mathcal{P}$ is validated if RMSD is low.**\n\nThis approach conflates the validation of a ligand-based model with that of a structure-based docking protocol. The pharmacophore $\\mathcal{P}$ is an abstract, ligand-based hypothesis. Its validity is determined by its ability to predict other active molecules, not by how well its training ligands dock into a protein structure. Furthermore, relying on a homology model introduces its own significant source of error. Low RMSD for the training ligands is not a measure of the pharmacophore's predictive or generalization power.\n**Verdict: Incorrect.**\n\n**D. Increase the number of pharmacophore features and add additional excluded volumes until no decoys in the corporate library match $\\mathcal{P}$; the absence of decoy matches indicates high specificity and thus successful validation.**\n\nThis describes a procedure for maximizing overfitting. By adding an excessive number of features and constraints, one can always create a model that is perfectly specific to the training set and excludes all other compounds, including decoys. Such a model will have perfect specificity but will almost certainly have zero sensitivity, meaning it will be unable to identify any new actives that are not nearly identical to the training ligands. A useful model must balance sensitivity and specificity. This strategy destroys this balance in favor of a useless, over-specified model.\n**Verdict: Incorrect.**\n\n**E. Perform a prospective test by selecting a few top-scoring compounds from the same pool used during model setup, test them in vitro, and accept the pharmacophore as validated if at least one hit shows measurable activity, without conducting any retrospective benchmarking against decoys or randomized controls.**\n\nWhile prospective testing is the ultimate confirmation of a model's utility, this specific strategy is scientifically weak and premature. The major flaw is the omission of retrospective benchmarking and statistical controls. Finding \"at least one hit\" from a small, cherry-picked set of compounds is anecdotal and could easily be a result of chance, especially given the limited wet-lab resources. Without comparing the model's performance to a null model (random chance), there is no way to know if it provides true enrichment. Committing precious experimental resources without first computationally verifying that the model is statistically significant and superior to random selection is an inefficient and risky strategy.\n**Verdict: Incorrect.**\n\nIn summary, only option A outlines a methodologically sound, state-of-the-art procedure for validating a pharmacophore model built from a small dataset, correctly prioritizing statistical rigor and the assessment of generalization before committing to expensive experiments.", "answer": "$$\\boxed{A}$$", "id": "2414165"}]}