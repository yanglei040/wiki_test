{"hands_on_practices": [{"introduction": "This first exercise provides a concrete starting point for understanding dual norms. By applying the fundamental definition of a dual norm to a vector with respect to the $\\ell_1$ norm, we can directly uncover the important duality relationship between the $\\ell_1$ and $\\ell_\\infty$ norms [@problem_id:977759]. This practice is key to building intuition for why certain pairs of norms are linked in optimization and analysis.", "problem": "Compute the dual norm of the vector $\\mathbf{z} = (3, 4)$ with respect to the $\\ell_1$ norm in $\\mathbb{R}^2$. The dual norm of a vector $\\mathbf{z}$ is defined as\n\n$$\n\\|\\mathbf{z}\\|_* = \\sup \\left\\{ \\left| \\langle \\mathbf{z}, \\mathbf{x} \\rangle \\right| : \\|\\mathbf{x}\\|_1 \\leq 1 \\right\\},\n$$\n\nwhere $\\langle \\mathbf{z}, \\mathbf{x} \\rangle = 3x_1 + 4x_2$ for $\\mathbf{x} = (x_1, x_2)$ and $\\|\\mathbf{x}\\|_1 = |x_1| + |x_2|$.", "solution": "We want \n$$\\|\\mathbf z\\|_*=\\sup_{\\|\\mathbf x\\|_1\\le1}|\\langle\\mathbf z,\\mathbf x\\rangle|\n=\\sup_{|x_1|+|x_2|\\le1}|3x_1+4x_2|.$$\nBy definition, the dual of the $\\ell_1$ norm is the $\\ell_\\infty$ norm, so\n$$\\|\\mathbf z\\|_*=\\|\\mathbf z\\|_\\infty=\\max\\{|3|,|4|\\}=4.$$\nAlternatively, one may set $x_1=\\alpha\\,\\mathrm{sign}(3)$, $x_2=(1-\\alpha)\\,\\mathrm{sign}(4)$ with $\\alpha\\in[0,1]$.  Then\n$$3x_1+4x_2=3\\alpha+4(1-\\alpha)=4-(4-3)\\alpha=4-\\alpha,$$\nwhose maximum over $\\alpha\\in[0,1]$ is $4$. \nHence $\\|\\mathbf z\\|_*=4\\,. $", "answer": "$$\\boxed{4}$$", "id": "977759"}, {"introduction": "After exploring the relationship between two different norms, we now turn to a special and significant case: the $\\ell_2$ norm. This problem demonstrates the concept of self-duality, where a norm is its own dual [@problem_id:977935]. The solution hinges on the celebrated Cauchy-Schwarz inequality, highlighting a deep connection between the geometric structure of Euclidean space and the algebraic definition of dual norms.", "problem": "Consider the vector space $\\mathbb{R}^2$ equipped with the standard inner product $\\langle \\mathbf{x}, \\mathbf{y} \\rangle = x_1 y_1 + x_2 y_2$. The $\\ell_2$ norm of a vector $\\mathbf{x} = (x_1, x_2)$ is defined as $\\|\\mathbf{x}\\|_2 = \\sqrt{x_1^2 + x_2^2}$. The dual norm of a vector $\\mathbf{z} \\in \\mathbb{R}^2$ with respect to the $\\ell_2$ norm is given by:\n\n$$\n\\|\\mathbf{z}\\|_* = \\sup \\left\\{ \\langle \\mathbf{z}, \\mathbf{x} \\rangle \\mid \\|\\mathbf{x}\\|_2 \\leq 1 \\right\\}.\n$$\n\nCompute the dual norm of the vector $\\mathbf{z} = (1, 1)$.", "solution": "1. The dual norm is defined by\n$$\n\\|\\mathbf{z}\\|_* = \\sup_{\\|\\mathbf{x}\\|_2 \\le 1} \\langle \\mathbf{z}, \\mathbf{x} \\rangle.\n$$\n2. By the Cauchy–Schwarz inequality,\n$$\n\\langle \\mathbf{z}, \\mathbf{x} \\rangle \\le \\|\\mathbf{z}\\|_2 \\,\\|\\mathbf{x}\\|_2 \\le \\|\\mathbf{z}\\|_2.\n$$\nHence the supremum is achieved when $\\mathbf{x}$ is in the direction of $\\mathbf{z}$ and equals $\\|\\mathbf{z}\\|_2$.\n3. For $\\mathbf{z}=(1,1)$,\n$$\n\\|\\mathbf{z}\\|_2 = \\sqrt{1^2 + 1^2} = \\sqrt{2}.\n$$\nTherefore,\n$$\n\\|\\mathbf{z}\\|_* = \\sqrt{2}.\n$$", "answer": "$$\\boxed{\\sqrt{2}}$$", "id": "977935"}, {"introduction": "To see how dual norms are applied in practice, this exercise connects them to the fundamental optimization task of projection onto a convex set. You will derive the projection onto an $\\ell_\\infty$ ball, a common constraint in machine learning models, and see that this set is precisely the dual ball of the $\\ell_1$ norm [@problem_id:3197835]. This example illustrates how understanding duality can reveal computationally efficient structures in seemingly complex problems.", "problem": "Let $n \\in \\mathbb{N}$ and consider the Euclidean projection of a vector $\\boldsymbol{v} \\in \\mathbb{R}^{n}$ onto the closed convex set $\\mathcal{C}_{\\infty}(\\tau) \\coloneqq \\{\\boldsymbol{x} \\in \\mathbb{R}^{n} : \\|\\boldsymbol{x}\\|_{\\infty} \\le \\tau\\}$, where $\\tau  0$ and $\\|\\cdot\\|_{\\infty}$ denotes the $\\ell_{\\infty}$ norm. Starting only from the definition of the Euclidean projection onto a nonempty closed convex set and the definition of the dual norm, do the following:\n\n1) Derive the structure of the Euclidean projection $\\Pi_{\\mathcal{C}_{\\infty}(\\tau)}(\\boldsymbol{v})$ by solving the defining optimization problem directly. In your derivation, determine whether the solution can be expressed as a coordinate-wise operation and justify your conclusion using first principles of convex optimization.\n\n2) Explain how $\\mathcal{C}_{\\infty}(\\tau)$ relates to the dual ball of the $\\ell_{1}$ norm, explicitly identifying the dual norm of $\\|\\cdot\\|_{1}$ and the associated dual ball.\n\n3) Apply your result to the concrete data\n$\\boldsymbol{v} = (\\,3.1,\\,-2.4,\\,1.8,\\,-0.9,\\,2.0,\\,-4.6\\,) \\in \\mathbb{R}^{6}$ and $\\tau = 2$ to compute the unique Euclidean projection $\\Pi_{\\mathcal{C}_{\\infty}(2)}(\\boldsymbol{v})$.\n\nProvide the final projected vector as your answer. You do not need to round; give exact values.", "solution": "The user-provided problem is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\n- A natural number $n \\in \\mathbb{N}$.\n- A vector $\\boldsymbol{v} \\in \\mathbb{R}^{n}$.\n- A closed convex set $\\mathcal{C}_{\\infty}(\\tau) \\coloneqq \\{\\boldsymbol{x} \\in \\mathbb{R}^{n} : \\|\\boldsymbol{x}\\|_{\\infty} \\le \\tau\\}$.\n- A positive scalar $\\tau  0$.\n- The norm $\\|\\cdot\\|_{\\infty}$ is the $\\ell_{\\infty}$ norm.\n- The task involves three parts:\n    1) Derive the Euclidean projection $\\Pi_{\\mathcal{C}_{\\infty}(\\tau)}(\\boldsymbol{v})$ by solving the defining optimization problem and determining if the operation is coordinate-wise.\n    2) Explain the relation between $\\mathcal{C}_{\\infty}(\\tau)$ and the dual ball of the $\\ell_{1}$ norm.\n    3) Apply the result to compute the projection for $\\boldsymbol{v} = (\\,3.1,\\,-2.4,\\,1.8,\\,-0.9,\\,2.0,\\,-4.6\\,) \\in \\mathbb{R}^{6}$ and $\\tau = 2$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed for validity based on scientific and mathematical principles.\n- **Scientifically Grounded:** The problem is set within the well-established mathematical field of convex analysis and optimization. The concepts of norms ($\\ell_{\\infty}$, $\\ell_{1}$), dual norms, convex sets, and Euclidean projection are standard and rigorously defined.\n- **Well-Posed:** The set $\\mathcal{C}_{\\infty}(\\tau)$ is a hypercube centered at the origin, which is a nonempty, closed, and convex subset of $\\mathbb{R}^{n}$. The theory of projections onto convex sets guarantees that for any point $\\boldsymbol{v} \\in \\mathbb{R}^{n}$, there exists a unique point in $\\mathcal{C}_{\\infty}(\\tau)$ that is closest to $\\boldsymbol{v}$ in the Euclidean sense. All information required for the derivation and computation is provided.\n- **Objective:** The problem is stated in precise, unambiguous mathematical language.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. It is a standard, well-posed problem in convex optimization that is free of scientific flaws, contradictions, or ambiguity. The solution process may proceed.\n\n---\n\n### Part 1: Derivation of the Projection Operator\n\nThe Euclidean projection of a vector $\\boldsymbol{v} \\in \\mathbb{R}^{n}$ onto a nonempty closed convex set $\\mathcal{C}$ is defined as the unique vector $\\boldsymbol{x}^* \\in \\mathcal{C}$ that minimizes the Euclidean distance to $\\boldsymbol{v}$. This is equivalent to minimizing the squared Euclidean norm of the difference, which is a strictly convex optimization problem. Let $\\boldsymbol{x}^* = \\Pi_{\\mathcal{C}_{\\infty}(\\tau)}(\\boldsymbol{v})$. Then $\\boldsymbol{x}^*$ is the solution to:\n$$\n\\boldsymbol{x}^* = \\arg\\min_{\\boldsymbol{x} \\in \\mathcal{C}_{\\infty}(\\tau)} \\frac{1}{2} \\|\\boldsymbol{x} - \\boldsymbol{v}\\|_{2}^{2}\n$$\nThe objective function is $f(\\boldsymbol{x}) = \\frac{1}{2} \\|\\boldsymbol{x} - \\boldsymbol{v}\\|_{2}^{2} = \\frac{1}{2} \\sum_{i=1}^{n} (x_i - v_i)^2$. The constraint set is $\\mathcal{C}_{\\infty}(\\tau) = \\{\\boldsymbol{x} \\in \\mathbb{R}^{n} : \\|\\boldsymbol{x}\\|_{\\infty} \\le \\tau\\}$. By definition of the $\\ell_{\\infty}$-norm, $\\|\\boldsymbol{x}\\|_{\\infty} = \\max_{i=1, \\dots, n} |x_i|$. The constraint $\\|\\boldsymbol{x}\\|_{\\infty} \\le \\tau$ is therefore equivalent to the set of $n$ independent constraints $|x_i| \\le \\tau$ for each $i \\in \\{1, \\dots, n\\}$. This can be written as $-\\tau \\le x_i \\le \\tau$.\n\nThe optimization problem is thus:\n$$\n\\begin{array}{ll}\n\\text{minimize}  \\frac{1}{2} \\sum_{i=1}^{n} (x_i - v_i)^2 \\\\\n\\text{subject to}  -\\tau \\le x_i \\le \\tau, \\quad \\text{for } i = 1, \\dots, n\n\\end{array}\n$$\nThe objective function is a sum of terms where each term depends only on a single variable $x_i$. The constraints are also decoupled, applying to each coordinate $x_i$ independently. This separability implies that the $n$-dimensional optimization problem can be decomposed into $n$ independent one-dimensional optimization problems:\n$$\n\\text{For each } i \\in \\{1, \\dots, n\\}, \\quad \\text{solve: } \\quad\n\\begin{array}{ll}\n\\text{minimize}  \\frac{1}{2} (x_i - v_i)^2 \\\\\n\\text{subject to}  x_i \\in [-\\tau, \\tau]\n\\end{array}\n$$\nThe unconstrained minimizer of $\\frac{1}{2} (x_i - v_i)^2$ is $x_i = v_i$.\n- If $v_i$ lies within the feasible interval $[-\\tau, \\tau]$ (i.e., $|v_i| \\le \\tau$), then a unique solution is $x_i^* = v_i$.\n- If $v_i  \\tau$, the quadratic function is minimized over the interval $[-\\tau, \\tau]$ at the endpoint closest to $v_i$, which is $x_i^* = \\tau$.\n- If $v_i  -\\tau$, the minimum is achieved at the other endpoint, $x_i^* = -\\tau$.\n\nThese three cases can be compactly expressed as projecting the scalar $v_i$ onto the interval $[-\\tau, \\tau]$. The solution for each component is:\n$$\nx_i^* = \\begin{cases}\n\\tau  \\text{if } v_i  \\tau \\\\\nv_i  \\text{if } -\\tau \\le v_i \\le \\tau \\\\\n-\\tau  \\text{if } v_i  -\\tau\n\\end{cases}\n$$\nThis operation is also known as clipping or saturation and can be written as $x_i^* = \\text{median}(-\\tau, v_i, \\tau)$ or $x_i^* = \\text{sign}(v_i) \\min(|v_i|, \\tau)$.\n\nThe structure of the projection $\\Pi_{\\mathcal{C}_{\\infty}(\\tau)}(\\boldsymbol{v})$ is a coordinate-wise operation. This is a direct consequence of the separability of both the objective function (squared Euclidean norm) and the constraint set (a hypercube aligned with the coordinate axes). From the first principles of convex optimization, because the problem decomposes into independent subproblems for each coordinate, the overall solution is simply the vector of the solutions to the subproblems.\n\n### Part 2: Relation to the Dual Norm of $\\|\\cdot\\|_1$\n\nThe dual norm $\\|\\cdot\\|_*$ of a norm $\\|\\cdot\\|$ on $\\mathbb{R}^n$ is defined by\n$$\n\\|\\boldsymbol{z}\\|_* \\coloneqq \\sup_{\\|\\boldsymbol{x}\\| \\le 1} \\boldsymbol{z}^{\\top}\\boldsymbol{x}\n$$\nWe seek the dual norm of the $\\ell_1$-norm, $\\|\\cdot\\|_1 = \\sum_{i=1}^n |x_i|$. Let $\\|\\cdot\\| = \\|\\cdot\\|_1$. Its dual is:\n$$\n\\|\\boldsymbol{z}\\|_* = \\sup_{\\|\\boldsymbol{x}\\|_1 \\le 1} \\sum_{i=1}^n z_i x_i\n$$\nTo maximize $\\sum_i z_i x_i$ subject to $\\sum_i |x_i| \\le 1$, we should align the vector $\\boldsymbol{x}$ with the component of $\\boldsymbol{z}$ that has the largest magnitude. Let $k = \\arg\\max_{i} |z_i|$, so that $|z_k| = \\|\\boldsymbol{z}\\|_{\\infty}$. We construct a vector $\\boldsymbol{x}$ with $x_k = \\text{sign}(z_k)$ and $x_i = 0$ for all $i \\neq k$. This vector satisfies the constraint $\\|\\boldsymbol{x}\\|_1 = |\\text{sign}(z_k)| = 1$. For this choice of $\\boldsymbol{x}$, the inner product is $\\boldsymbol{z}^{\\top}\\boldsymbol{x} = z_k x_k = z_k \\text{sign}(z_k) = |z_k| = \\|\\boldsymbol{z}\\|_{\\infty}$.\n\nBy the Hölder inequality for $\\ell_p$-norms, $|\\boldsymbol{z}^{\\top}\\boldsymbol{x}| \\le \\|\\boldsymbol{z}\\|_q \\|\\boldsymbol{x}\\|_p$ where $\\frac{1}{p} + \\frac{1}{q} = 1$. For $p=1$, we have $q=\\infty$. Thus, for any $\\boldsymbol{x}$ with $\\|\\boldsymbol{x}\\|_1 \\le 1$:\n$$\n\\boldsymbol{z}^{\\top}\\boldsymbol{x} \\le |\\boldsymbol{z}^{\\top}\\boldsymbol{x}| \\le \\|\\boldsymbol{z}\\|_{\\infty} \\|\\boldsymbol{x}\\|_1 \\le \\|\\boldsymbol{z}\\|_{\\infty}\n$$\nSince we found a feasible point $\\boldsymbol{x}$ that achieves this upper bound, the supremum is $\\|\\boldsymbol{z}\\|_{\\infty}$. Therefore, the dual norm of the $\\ell_1$-norm is the $\\ell_{\\infty}$-norm.\n\nThe unit dual ball associated with a norm $\\|\\cdot\\|$ is the set $\\{\\boldsymbol{z} \\in \\mathbb{R}^n : \\|\\boldsymbol{z}\\|_* \\le 1\\}$. For the $\\ell_1$-norm, the dual norm is $\\|\\cdot\\|_{\\infty}$, so its unit dual ball is $\\{\\boldsymbol{z} \\in \\mathbb{R}^n : \\|\\boldsymbol{z}\\|_{\\infty} \\le 1\\}$. This is precisely the set $\\mathcal{C}_{\\infty}(1)$.\nThe set given in the problem, $\\mathcal{C}_{\\infty}(\\tau) = \\{\\boldsymbol{x} \\in \\mathbb{R}^{n} : \\|\\boldsymbol{x}\\|_{\\infty} \\le \\tau\\}$, is the $\\ell_{\\infty}$-ball of radius $\\tau$. It is a scaled version of the unit dual ball of the $\\ell_1$-norm, where the scaling factor is $\\tau$.\n\n### Part 3: Application to Concrete Data\n\nWe are given the vector $\\boldsymbol{v} = (\\,3.1,\\,-2.4,\\,1.8,\\,-0.9,\\,2.0,\\,-4.6\\,) \\in \\mathbb{R}^{6}$ and the parameter $\\tau = 2$. The projection $\\boldsymbol{x}^* = \\Pi_{\\mathcal{C}_{\\infty}(2)}(\\boldsymbol{v})$ is computed by applying the coordinate-wise clipping operation derived in Part 1 to each component of $\\boldsymbol{v}$ with respect to the interval $[ -2, 2 ]$.\n\n- $v_1 = 3.1$: Since $3.1  2$, $x_1^* = 2$.\n- $v_2 = -2.4$: Since $-2.4  -2$, $x_2^* = -2$.\n- $v_3 = 1.8$: Since $-2 \\le 1.8 \\le 2$, $x_3^* = 1.8$.\n- $v_4 = -0.9$: Since $-2 \\le -0.9 \\le 2$, $x_4^* = -0.9$.\n- $v_5 = 2.0$: Since $-2 \\le 2.0 \\le 2$, $x_5^* = 2.0$.\n- $v_6 = -4.6$: Since $-4.6  -2$, $x_6^* = -2$.\n\nCombining these results gives the projected vector.\nThe unique Euclidean projection is $\\boldsymbol{x}^* = (\\,2, -2, 1.8, -0.9, 2, -2\\,)$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2  -2  1.8  -0.9  2  -2\n\\end{pmatrix}\n}\n$$", "id": "3197835"}]}