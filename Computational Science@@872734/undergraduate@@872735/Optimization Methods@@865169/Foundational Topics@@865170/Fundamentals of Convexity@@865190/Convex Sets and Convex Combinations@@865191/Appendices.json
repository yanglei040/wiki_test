{"hands_on_practices": [{"introduction": "The concept of an extreme point, or a 'corner' of a convex set, is fundamental to optimization theory. This practice will give you a direct, hands-on method to test if a given point is an extreme point by applying its core definition: trying to express it as a midpoint of two other distinct points within the set [@problem_id:3114506]. Successfully navigating this exercise builds a strong geometric intuition for the structure of polyhedra.", "problem": "Consider the polyhedron $\\mathcal{P} \\subset \\mathbb{R}^{3}$ defined by the intersection of half-spaces\n$$\n-x_{1} \\le 0,\\quad -x_{2} \\le 0,\\quad -x_{3} \\le 0,\\quad x_{1} + x_{2} + x_{3} \\le 6,\\quad 2 x_{1} + x_{2} \\le 5,\\quad x_{1} + 2 x_{3} \\le 5.\n$$\nLet $x^{\\star} \\in \\mathcal{P}$ be the point\n$$\nx^{\\star} = \\begin{pmatrix} \\frac{3}{2} \\\\ 2 \\\\ \\frac{7}{4} \\end{pmatrix}.\n$$\nA point $x$ in a convex set $\\mathcal{C}$ is called an extreme point if it cannot be represented as a strict convex combination $x = \\theta y + (1-\\theta) z$ with $y, z \\in \\mathcal{C}$, $y \\ne z$, and $\\theta \\in (0,1)$. To construct a convex combination-based test for extremality at $x^{\\star}$, attempt to express $x^{\\star}$ as the midpoint of two distinct feasible points, that is, $x^{\\star} = \\frac{1}{2}(y + z)$ with $y, z \\in \\mathcal{P}$ and $y \\ne z$. Restrict attention to symmetric perturbations of the form\n$$\ny = x^{\\star} + t d,\\qquad z = x^{\\star} - t d,\n$$\nwhere $t \\ge 0$ and $d \\in \\mathbb{R}^{3}$ has Euclidean norm $\\|d\\|_{2} = 1$, and require that any inequality that is tight at $x^{\\star}$ remains tight at $y$ and $z$. Using only the definitions of convex set, convex combination, extreme point, Euclidean norm, and linear inequality, determine the largest $t^{\\star} \\ge 0$ for which such $y$ and $z$ exist. Provide your final answer as a single exact expression (no rounding is required).", "solution": "The problem asks for the determination of the largest value $t^{\\star} \\ge 0$ such that points $y = x^{\\star} + t d$ and $z = x^{\\star} - t d$ are contained within a given polyhedron $\\mathcal{P}$, subject to specific constraints on the direction vector $d$.\n\nFirst, we write the six inequalities defining the polyhedron $\\mathcal{P} \\subset \\mathbb{R}^{3}$ in the standard form $a_i^T x \\le b_i$:\n1. $-x_{1} \\le 0$, which corresponds to $a_1^T = \\begin{pmatrix} -1 & 0 & 0 \\end{pmatrix}$ and $b_1 = 0$.\n2. $-x_{2} \\le 0$, which corresponds to $a_2^T = \\begin{pmatrix} 0 & -1 & 0 \\end{pmatrix}$ and $b_2 = 0$.\n3. $-x_{3} \\le 0$, which corresponds to $a_3^T = \\begin{pmatrix} 0 & 0 & -1 \\end{pmatrix}$ and $b_3 = 0$.\n4. $x_{1} + x_{2} + x_{3} \\le 6$, which corresponds to $a_4^T = \\begin{pmatrix} 1 & 1 & 1 \\end{pmatrix}$ and $b_4 = 6$.\n5. $2 x_{1} + x_{2} \\le 5$, which corresponds to $a_5^T = \\begin{pmatrix} 2 & 1 & 0 \\end{pmatrix}$ and $b_5 = 5$.\n6. $x_{1} + 2 x_{3} \\le 5$, which corresponds to $a_6^T = \\begin{pmatrix} 1 & 0 & 2 \\end{pmatrix}$ and $b_6 = 5$.\n\nThe given point is $x^{\\star} = \\begin{pmatrix} 3/2 \\\\ 2 \\\\ 7/4 \\end{pmatrix}$. We must first identify which of these inequalities are active (tight) at $x^{\\star}$.\n1. $-x^{\\star}_{1} = -3/2 < 0$. (Slack)\n2. $-x^{\\star}_{2} = -2 < 0$. (Slack)\n3. $-x^{\\star}_{3} = -7/4 < 0$. (Slack)\n4. $x^{\\star}_{1} + x^{\\star}_{2} + x^{\\star}_{3} = 3/2 + 2 + 7/4 = 6/4 + 8/4 + 7/4 = 21/4 = 5.25 < 6$. (Slack)\n5. $2 x^{\\star}_{1} + x^{\\star}_{2} = 2(3/2) + 2 = 3 + 2 = 5$. (Tight)\n6. $x^{\\star}_{1} + 2 x^{\\star}_{3} = 3/2 + 2(7/4) = 3/2 + 7/2 = 10/2 = 5$. (Tight)\n\nThe set of active (tight) inequality constraints at $x^{\\star}$ corresponds to indices $I_{tight} = \\{5, 6\\}$. The slack constraints correspond to indices $I_{slack} = \\{1, 2, 3, 4\\}$.\n\nThe problem states that any inequality that is tight at $x^{\\star}$ must remain tight at $y = x^{\\star} + t d$ and $z = x^{\\star} - t d$. For an inequality $a_i^T x \\le b_i$ with $i \\in I_{tight}$, we have $a_i^T x^{\\star} = b_i$. The condition for $y$ is $a_i^T y = b_i$, which implies $a_i^T (x^{\\star} + t d) = b_i$. This expands to $a_i^T x^{\\star} + t (a_i^T d) = b_i$. Since $a_i^T x^{\\star} = b_i$, this simplifies to $t (a_i^T d) = 0$. As we seek the largest $t^{\\star} \\ge 0$, we are interested in cases where $t > 0$, so we must have $a_i^T d = 0$. This condition must hold for all $i \\in I_{tight}$.\n\nThe direction vector $d = \\begin{pmatrix} d_1 \\\\ d_2 \\\\ d_3 \\end{pmatrix}$ must be orthogonal to the normal vectors of the tight constraints, $a_5$ and $a_6$.\n$a_5^T d = 2 d_1 + d_2 = 0 \\implies d_2 = -2 d_1$.\n$a_6^T d = d_1 + 2 d_3 = 0 \\implies d_3 = -d_1/2$.\nThe vector $d$ must be of the form $k \\begin{pmatrix} 1 \\\\ -2 \\\\ -1/2 \\end{pmatrix}$ for some scalar $k$. The problem also requires that $d$ has a Euclidean norm of $1$, i.e., $\\|d\\|_2=1$.\n$d_1^2 + d_2^2 + d_3^2 = d_1^2 + (-2d_1)^2 + (-d_1/2)^2 = 1$.\n$d_1^2 + 4d_1^2 + d_1^2/4 = 1 \\implies (5 + 1/4)d_1^2 = 1 \\implies (21/4)d_1^2 = 1$.\nThis gives $d_1^2 = 4/21$, so $d_1 = \\pm 2/\\sqrt{21}$. We can choose the positive sign without loss of generality (the negative sign would just swap the roles of $y$ and $z$).\n$d_1 = 2/\\sqrt{21}$.\n$d_2 = -2(2/\\sqrt{21}) = -4/\\sqrt{21}$.\n$d_3 = -(1/2)(2/\\sqrt{21}) = -1/\\sqrt{21}$.\nSo, the direction vector is $d = \\frac{1}{\\sqrt{21}} \\begin{pmatrix} 2 \\\\ -4 \\\\ -1 \\end{pmatrix}$.\n\nNow we must ensure that $y = x^{\\star} + t d$ and $z = x^{\\star} - t d$ satisfy the slack inequalities for all $t \\in [0, t^{\\star}]$. For any $i \\in I_{slack}$, we require $a_i^T (x^{\\star} \\pm t d) \\le b_i$.\nThis is equivalent to $a_i^T x^{\\star} \\pm t(a_i^T d) \\le b_i$.\nLet $\\delta_i = b_i - a_i^T x^{\\star} > 0$ for $i \\in I_{slack}$. The conditions become $\\pm t(a_i^T d) \\le \\delta_i$.\nSince $t \\ge 0$, these two inequalities can be combined into a single condition: $t|a_i^T d| \\le \\delta_i$.\nIf $a_i^T d \\ne 0$, this gives an upper bound on $t$: $t \\le \\frac{\\delta_i}{|a_i^T d|}$.\nThe largest possible $t^{\\star}$ must satisfy this for all $i \\in I_{slack}$. Thus,\n$$t^{\\star} = \\min_{i \\in I_{slack}, a_i^T d \\ne 0} \\left\\{ \\frac{b_i-a_i^T x^{\\star}}{|a_i^T d|} \\right\\}.$$\n\nWe calculate this value for each slack constraint:\n- For $i=1$: $a_1^T = (-1, 0, 0)$, $b_1=0$. $\\delta_1 = 0 - (-3/2) = 3/2$.\n$a_1^T d = \\frac{1}{\\sqrt{21}} (-1)(2) = -2/\\sqrt{21}$.\nBound: $t \\le \\frac{3/2}{|-2/\\sqrt{21}|} = \\frac{3\\sqrt{21}}{4}$.\n\n- For $i=2$: $a_2^T = (0, -1, 0)$, $b_2=0$. $\\delta_2 = 0 - (-2) = 2$.\n$a_2^T d = \\frac{1}{\\sqrt{21}} (-1)(-4) = 4/\\sqrt{21}$.\nBound: $t \\le \\frac{2}{|4/\\sqrt{21}|} = \\frac{2\\sqrt{21}}{4} = \\frac{\\sqrt{21}}{2}$.\n\n- For $i=3$: $a_3^T = (0, 0, -1)$, $b_3=0$. $\\delta_3 = 0 - (-7/4) = 7/4$.\n$a_3^T d = \\frac{1}{\\sqrt{21}} (-1)(-1) = 1/\\sqrt{21}$.\nBound: $t \\le \\frac{7/4}{|1/\\sqrt{21}|} = \\frac{7\\sqrt{21}}{4}$.\n\n- For $i=4$: $a_4^T = (1, 1, 1)$, $b_4=6$. $\\delta_4 = 6 - (21/4) = 3/4$.\n$a_4^T d = \\frac{1}{\\sqrt{21}} (2 - 4 - 1) = -3/\\sqrt{21}$.\nBound: $t \\le \\frac{3/4}{|-3/\\sqrt{21}|} = \\frac{\\sqrt{21}}{4}$.\n\nWe must find the minimum of these upper bounds to determine the largest permissible $t$:\n$$t^{\\star} = \\min \\left\\{ \\frac{3\\sqrt{21}}{4}, \\frac{\\sqrt{21}}{2}, \\frac{7\\sqrt{21}}{4}, \\frac{\\sqrt{21}}{4} \\right\\}.$$\nNoting that $\\frac{\\sqrt{21}}{2} = \\frac{2\\sqrt{21}}{4}$, the set of bounds is $\\{\\frac{3\\sqrt{21}}{4}, \\frac{2\\sqrt{21}}{4}, \\frac{7\\sqrt{21}}{4}, \\frac{\\sqrt{21}}{4}\\}$.\nThe minimum value in this set is $\\frac{\\sqrt{21}}{4}$.\nTherefore, the largest value $t^{\\star}$ is $\\frac{\\sqrt{21}}{4}$.", "answer": "$$\\boxed{\\frac{\\sqrt{21}}{4}}$$", "id": "3114506"}, {"introduction": "A key principle of linear programming states that optimal solutions are found at the extreme points of the feasible set. This exercise challenges you to first identify all extreme points of the $\\ell_1$ norm ball, a common set in modern data science, using the definition of a convex combination [@problem_id:3114531]. You will then leverage this geometric insight to solve an optimization problem, illustrating the powerful link between the geometry of convex sets and algorithmic efficiency.", "problem": "Let $B_1 \\subset \\mathbb{R}^4$ denote the $\\ell_1$ ball defined by $B_1 = \\{ x \\in \\mathbb{R}^4 : \\|x\\|_1 \\le 1 \\}$, where $\\|x\\|_1 = \\sum_{i=1}^4 |x_i|$. Consider the linear optimization problem\n$$\n\\max_{x \\in \\mathbb{R}^4} \\;\\; a^{\\mathsf{T}} x \\quad \\text{subject to} \\quad \\|x\\|_1 \\le 1\n$$\nwith the given vector $a = \\begin{pmatrix} 1 \\\\ -\\sqrt{2} \\\\ \\frac{\\pi}{4} \\\\ -\\frac{3}{5} \\end{pmatrix}$.\n\nUsing only the fundamental definitions of convex sets, convex combinations, extreme points, and the $\\ell_1$ norm, proceed as follows:\n\n1. Justify that every $x \\in B_1$ can be written as a convex combination of signed unit vectors and the origin by constructing explicit nonnegative weights $\\{w_i\\}_{i=0}^4$ summing to $1$ and vectors from $\\{0\\} \\cup \\{\\pm e_1, \\pm e_2, \\pm e_3, \\pm e_4\\}$, where $e_i$ denotes the $i$-th standard basis vector. Then rigorously argue that the only extreme points of $B_1$ are the signed unit vectors $\\{\\pm e_i : i \\in \\{1,2,3,4\\}\\}$.\n\n2. Using your conclusion from part $1$ together with first-principles inequalities, compute the optimal value of the optimization problem above. Provide your final answer in exact form (no rounding).", "solution": "**Part 1: Characterization of the $\\ell_1$ ball $B_1$ and its extreme points.**\n\nFirst, we show that any point $x \\in B_1$ can be expressed as a convex combination of the vectors in the set $V = \\{0\\} \\cup \\{\\pm e_1, \\pm e_2, \\pm e_3, \\pm e_4\\}$.\nLet $x = (x_1, x_2, x_3, x_4)^{\\mathsf{T}}$ be an arbitrary point in $B_1$. By definition, we have $\\|x\\|_1 = \\sum_{i=1}^4 |x_i| \\le 1$.\nWe can write the vector $x$ as a linear combination of the standard basis vectors: $x = \\sum_{i=1}^4 x_i e_i$.\nFor each non-zero component $x_i$, we can write $x_i = |x_i| \\text{sgn}(x_i)$, where $\\text{sgn}(x_i)$ is the sign function, which is $1$ if $x_i > 0$ and $-1$ if $x_i < 0$.\nSo, we can express $x$ as:\n$$x = \\sum_{i=1}^4 |x_i| (\\text{sgn}(x_i) e_i)$$\nwhere for any $i$ such that $x_i=0$, the corresponding term in the sum is zero. Let $v_i = \\text{sgn}(x_i) e_i$. Each $v_i$ is a signed standard basis vector, i.e., $v_i \\in \\{\\pm e_1, \\pm e_2, \\pm e_3, \\pm e_4\\}$ if $x_i \\ne 0$.\n\nLet $S = \\|x\\|_1 = \\sum_{i=1}^4 |x_i|$. We know $0 \\le S \\le 1$. We can now construct a convex combination for $x$. Consider the following representation:\n$$x = \\left( \\sum_{i=1}^4 |x_i| v_i \\right) + (1 - S) \\cdot 0$$\nThis is a linear combination of the vectors $\\{v_1, v_2, v_3, v_4, 0\\}$, which are all in the set $V$. The coefficients (weights) are $w_i = |x_i|$ for $i \\in \\{1,2,3,4\\}$, and $w_0 = 1 - S$.\nThese weights are non-negative, since $|x_i| \\ge 0$ and $S \\le 1$ implies $1-S \\ge 0$.\nThe sum of the weights is:\n$$\\sum_{i=1}^4 w_i + w_0 = \\sum_{i=1}^4 |x_i| + (1 - S) = S + (1 - S) = 1$$\nThus, we have explicitly written any $x \\in B_1$ as a convex combination of vectors from the set $V$. This implies that $B_1$ is the convex hull of $V$, i.e., $B_1 = \\text{conv}(V)$.\n\nNext, we identify the extreme points of $B_1$. By the Krein-Milman theorem, the set of extreme points of a compact convex set must be a subset of any set of points whose convex hull generates the set. Therefore, the extreme points of $B_1$ must be a subset of $V = \\{0\\} \\cup \\{\\pm e_1, \\pm e_2, \\pm e_3, \\pm e_4\\}$.\n\nLet's check which elements of $V$ are extreme points. An extreme point $p$ of a convex set $C$ cannot be written as $p = \\lambda y + (1-\\lambda)z$ for distinct points $y, z \\in C$ and $\\lambda \\in (0,1)$.\n\n- Is the origin $0$ an extreme point? No. We can write $0 = \\frac{1}{2}e_1 + \\frac{1}{2}(-e_1)$. Since $e_1 \\in B_1$ and $-e_1 \\in B_1$ are distinct points, $0$ is not an extreme point.\n\n- Are the signed unit vectors $\\{\\pm e_i\\}$ extreme points? Let's test $e_1$. Suppose $e_1 = \\lambda y + (1-\\lambda)z$ for some $y, z \\in B_1$ with $y \\ne z$ and $\\lambda \\in (0,1)$. The first component of this vector equation is $1 = \\lambda y_1 + (1-\\lambda)z_1$. Since $y, z \\in B_1$, we have $\\|y\\|_1 \\le 1$ and $\\|z\\|_1 \\le 1$, which implies $|y_1| \\le 1$ and $|z_1| \\le 1$. For a convex combination of two numbers not exceeding $1$ to be equal to $1$, both numbers must be $1$. Thus, $y_1=1$ and $z_1=1$.\nNow consider the norm of $y$: $\\|y\\|_1 = |y_1| + \\sum_{i=2}^4 |y_i| = 1 + \\sum_{i=2}^4 |y_i|$. Since $\\|y\\|_1 \\le 1$, we must have $\\sum_{i=2}^4 |y_i| \\le 0$. As the sum of non-negative terms, this forces $|y_2|=|y_3|=|y_4|=0$, so $y_2=y_3=y_4=0$. This means $y = (1,0,0,0)^{\\mathsf{T}} = e_1$. A similar argument for $z$ leads to $z = e_1$. This contradicts the assumption that $y \\ne z$. Therefore, $e_1$ must be an extreme point. The same argument holds for all other signed unit vectors $\\pm e_i$ for $i \\in \\{1,2,3,4\\}$.\n\nCombining these findings, the set of extreme points of $B_1$ is precisely $\\{\\pm e_1, \\pm e_2, \\pm e_3, \\pm e_4\\}$.\n\n**Part 2: Solving the optimization problem.**\n\nThe problem is to find the maximum of the linear function $f(x) = a^{\\mathsf{T}}x$ over the compact convex set $B_1$. A fundamental result in convex optimization is that the maximum of a linear function over a compact convex set is always attained at one of its extreme points.\nFrom Part 1, the extreme points of $B_1$ are the $8$ vectors $\\{\\pm e_i : i=1,2,3,4\\}$. Therefore, the maximum value of $a^{\\mathsf{T}}x$ is the maximum value in the set $\\{a^{\\mathsf{T}}v : v \\in \\{\\pm e_1, \\pm e_2, \\pm e_3, \\pm e_4\\}\\}$.\n\nLet's evaluate $a^{\\mathsf{T}}v$ for these extreme points.\nFor any $i \\in \\{1,2,3,4\\}$, $a^{\\mathsf{T}}e_i = a_i$ and $a^{\\mathsf{T}}(-e_i) = -a_i$.\nThe maximum value is therefore:\n$$ \\max_{x \\in B_1} a^{\\mathsf{T}}x = \\max_{i \\in \\{1,2,3,4\\}} \\{a_i, -a_i\\} = \\max_{i \\in \\{1,2,3,4\\}} |a_i| $$\nThis maximum value is the $\\ell_\\infty$ norm of the vector $a$, denoted by $\\|a\\|_\\infty$.\n\nThis conclusion is also reachable via first-principles inequalities, as requested. For any $x \\in B_1$:\n$$ a^{\\mathsf{T}}x = \\sum_{i=1}^4 a_i x_i \\le \\sum_{i=1}^4 |a_i x_i| = \\sum_{i=1}^4 |a_i| |x_i| $$\nLet $\\|a\\|_\\infty = \\max_j |a_j|$. Then $|a_i| \\le \\|a\\|_\\infty$ for all $i$.\n$$ \\sum_{i=1}^4 |a_i| |x_i| \\le \\sum_{i=1}^4 \\|a\\|_\\infty |x_i| = \\|a\\|_\\infty \\sum_{i=1}^4 |x_i| = \\|a\\|_\\infty \\|x\\|_1 $$\nSince $x \\in B_1$, we have $\\|x\\|_1 \\le 1$. Thus, we have the upper bound:\n$$ a^{\\mathsf{T}}x \\le \\|a\\|_\\infty $$\nThis upper bound is attained if we can find an $x^* \\in B_1$ such that $a^{\\mathsf{T}}x^* = \\|a\\|_\\infty$. Let $k$ be an index such that $|a_k| = \\|a\\|_\\infty$. Choose $x^* = \\text{sgn}(a_k) e_k$.\nThen $\\|x^*\\|_1 = |\\text{sgn}(a_k)| = 1$, so $x^* \\in B_1$.\nAnd $a^{\\mathsf{T}}x^* = a^{\\mathsf{T}}(\\text{sgn}(a_k)e_k) = \\text{sgn}(a_k) a_k = |a_k| = \\|a\\|_\\infty$.\nThis confirms that the maximum value is indeed $\\|a\\|_\\infty$.\n\nNow we compute this value for the given vector $a = \\begin{pmatrix} 1 \\\\ -\\sqrt{2} \\\\ \\frac{\\pi}{4} \\\\ -\\frac{3}{5} \\end{pmatrix}$.\nWe need to find the maximum of the absolute values of its components:\n$$ \\|a\\|_\\infty = \\max \\left\\{ |1|, |-\\sqrt{2}|, \\left|\\frac{\\pi}{4}\\right|, \\left|-\\frac{3}{5}\\right| \\right\\} = \\max \\left\\{ 1, \\sqrt{2}, \\frac{\\pi}{4}, \\frac{3}{5} \\right\\} $$\nLet's compare these values:\n- $1$\n- $\\sqrt{2} \\approx 1.414$\n- $\\frac{\\pi}{4} \\approx \\frac{3.14159}{4} \\approx 0.785$\n- $\\frac{3}{5} = 0.6$\nThe maximum of these values is $\\sqrt{2}$.\n\nThe optimal value of the optimization problem is $\\sqrt{2}$. This maximum is achieved at $x^* = \\text{sgn}(a_2)e_2 = (-1)e_2 = (0,-1,0,0)^{\\mathsf{T}}$.", "answer": "$$\n\\boxed{\\sqrt{2}}\n$$", "id": "3114531"}, {"introduction": "While convex sets offer powerful guarantees, many real-world problems involve non-convex constraints. This exercise provides a crucial diagnostic skill: demonstrating a set's non-convexity by showing that a convex combination of feasible points can become infeasible [@problem_id:3114525]. Furthermore, it introduces the powerful technique of convex relaxation, showing how a change of variables can transform a non-convex problem into a tractable convex one.", "problem": "Let $S \\subset \\mathbb{R}^{2}$ be defined by the nonconvex inequality $x_{1} x_{2} \\leq 1$ together with bound constraints $x_{1} \\in \\left[\\tfrac{1}{4}, 2\\right]$ and $x_{2} \\in \\left[\\tfrac{1}{4}, 2\\right]$. Recall the definition: a set $C$ is convex if for any $x, y \\in C$ and any $t \\in [0,1]$, the convex combination $t x + (1-t) y \\in C$. Using this fundamental definition and the monotonicity of the natural logarithm, address the following.\n\n1) Consider the two feasible points $x^{A} = \\left(\\tfrac{1}{4}, 2\\right)$ and $x^{B} = \\left(2, \\tfrac{1}{4}\\right)$ in $S$. Parameterize their convex combinations as $x(t) = t x^{A} + (1-t) x^{B}$ for $t \\in [0,1]$. Starting from first principles, derive the expression for the product $P(t) = x_{1}(t)\\, x_{2}(t)$ and use it to demonstrate that some convex combinations of $x^{A}$ and $x^{B}$ are infeasible with respect to $x_{1} x_{2} \\leq 1$.\n\n2) Using only the above definition and standard calculus on polynomials, determine the exact maximum value of the violation of feasibility along the segment, defined as\n$$\nV^{\\star} \\triangleq \\max_{t \\in [0,1]} \\big(P(t) - 1\\big).\n$$\nProvide $V^{\\star}$ in exact form (no rounding).\n\n3) Propose a convex relaxation that is valid on the positive orthant by introducing the change of variables $y_{i} = \\ln(x_{i})$ for $i \\in \\{1,2\\}$, where $\\ln$ denotes the natural logarithm. Use the monotonicity of $\\ln(\\cdot)$ to transform the multiplicative constraint and the bound constraints, and justify why the resulting feasible region in $(y_{1}, y_{2})$ is convex.\n\nYour final answer should be the exact value of $V^{\\star}$ from part $2$, expressed as a single reduced fraction or a closed-form expression. Do not round.", "solution": "### Part 1: Convex combinations and infeasibility\nWe are given two points $x^{A} = \\begin{pmatrix} \\frac{1}{4} \\\\ 2 \\end{pmatrix}$ and $x^{B} = \\begin{pmatrix} 2 \\\\ \\frac{1}{4} \\end{pmatrix}$. Their convex combination is $x(t) = t x^{A} + (1-t) x^{B}$ for $t \\in [0,1]$. The components of $x(t)$, denoted as $x_1(t)$ and $x_2(t)$, are:\n$$\nx_{1}(t) = t\\left(\\frac{1}{4}\\right) + (1-t)(2) = \\frac{1}{4}t + 2 - 2t = 2 - \\frac{7}{4}t\n$$\n$$\nx_{2}(t) = t(2) + (1-t)\\left(\\frac{1}{4}\\right) = 2t + \\frac{1}{4} - \\frac{1}{4}t = \\frac{1}{4} + \\frac{7}{4}t\n$$\nThe product $P(t) = x_{1}(t)\\, x_{2}(t)$ is derived by multiplying these two expressions:\n$$\nP(t) = \\left(2 - \\frac{7}{4}t\\right) \\left(\\frac{1}{4} + \\frac{7}{4}t\\right)\n$$\nExpanding the product:\n$$\nP(t) = 2\\left(\\frac{1}{4}\\right) + 2\\left(\\frac{7}{4}t\\right) - \\left(\\frac{7}{4}t\\right)\\left(\\frac{1}{4}\\right) - \\left(\\frac{7}{4}t\\right)\\left(\\frac{7}{4}t\\right)\n$$\n$$\nP(t) = \\frac{1}{2} + \\frac{14}{4}t - \\frac{7}{16}t - \\frac{49}{16}t^2\n$$\n$$\nP(t) = \\frac{1}{2} + \\left(\\frac{56}{16} - \\frac{7}{16}\\right)t - \\frac{49}{16}t^2\n$$\n$$\nP(t) = -\\frac{49}{16}t^2 + \\frac{49}{16}t + \\frac{1}{2}\n$$\nTo demonstrate that some convex combinations are infeasible, we need to show that $P(t) > 1$ for some $t \\in (0,1)$. Let's evaluate $P(t)$ at the midpoint of the interval, $t = \\frac{1}{2}$:\n$$\nP\\left(\\frac{1}{2}\\right) = -\\frac{49}{16}\\left(\\frac{1}{2}\\right)^2 + \\frac{49}{16}\\left(\\frac{1}{2}\\right) + \\frac{1}{2} = -\\frac{49}{64} + \\frac{49}{32} + \\frac{1}{2} = \\frac{-49 + 98 + 32}{64} = \\frac{81}{64}\n$$\nSince $81 > 64$, we have $P\\left(\\frac{1}{2}\\right) = \\frac{81}{64} > 1$. The point $x(\\frac{1}{2})$ is the midpoint of the segment connecting $x^A$ and $x^B$:\n$$\nx\\left(\\frac{1}{2}\\right) = \\frac{1}{2}x^A + \\frac{1}{2}x^B = \\frac{1}{2}\\begin{pmatrix} \\frac{1}{4}+2 \\\\ 2+\\frac{1}{4} \\end{pmatrix} = \\begin{pmatrix} \\frac{9}{8} \\\\ \\frac{9}{8} \\end{pmatrix}\n$$\nFor this point, $x_1 x_2 = \\frac{9}{8} \\cdot \\frac{9}{8} = \\frac{81}{64} > 1$, which violates the constraint $x_1 x_2 \\leq 1$. This confirms that the set $S$ is not convex, as a convex combination of two points in $S$ does not lie in $S$.\n\n### Part 2: Maximum violation of feasibility\nWe need to find the maximum value of the violation, $V^{\\star} = \\max_{t \\in [0,1]} \\big(P(t) - 1\\big)$. This is equivalent to finding the maximum of $P(t)$ on the interval $[0,1]$ and then subtracting $1$.\nThe function to maximize is the quadratic polynomial $P(t) = -\\frac{49}{16}t^2 + \\frac{49}{16}t + \\frac{1}{2}$. Since the coefficient of the $t^2$ term is negative ($-\\frac{49}{16} < 0$), the graph of $P(t)$ is a parabola opening downwards. Its maximum occurs at its vertex.\nTo find the vertex, we compute the derivative of $P(t)$ with respect to $t$ and set it to $0$:\n$$\nP'(t) = \\frac{d}{dt}\\left(-\\frac{49}{16}t^2 + \\frac{49}{16}t + \\frac{1}{2}\\right) = -2\\left(\\frac{49}{16}\\right)t + \\frac{49}{16} = -\\frac{49}{8}t + \\frac{49}{16}\n$$\nSetting $P'(t) = 0$:\n$$\n-\\frac{49}{8}t + \\frac{49}{16} = 0 \\implies \\frac{49}{8}t = \\frac{49}{16} \\implies t = \\frac{49}{16} \\cdot \\frac{8}{49} = \\frac{1}{2}\n$$\nThe critical point $t = \\frac{1}{2}$ lies within the interval $[0,1]$. As this is the vertex of a downward-opening parabola, it corresponds to the global maximum of $P(t)$. The maximum value of $P(t)$ is $P(\\frac{1}{2})$, which we already calculated to be $\\frac{81}{64}$.\nThe maximum violation $V^{\\star}$ is therefore:\n$$\nV^{\\star} = P\\left(\\frac{1}{2}\\right) - 1 = \\frac{81}{64} - 1 = \\frac{81 - 64}{64} = \\frac{17}{64}\n$$\n\n### Part 3: Convex relaxation\nThe problem is defined for $x_1, x_2 > 0$ due to the bound constraints. We introduce the change of variables $y_i = \\ln(x_i)$ for $i \\in \\{1,2\\}$, which implies $x_i = \\exp(y_i)$.\nThe original constraints are:\n1. $x_1 x_2 \\leq 1$\n2. $\\frac{1}{4} \\leq x_1 \\leq 2$\n3. $\\frac{1}{4} \\leq x_2 \\leq 2$\n\nWe transform these constraints into the $(y_1, y_2)$ space.\nFor the first constraint, $x_1 x_2 \\leq 1$, we apply the natural logarithm function $\\ln(\\cdot)$ to both sides. Since $\\ln(\\cdot)$ is a monotonically increasing function, the direction of the inequality is preserved:\n$$\n\\ln(x_1 x_2) \\leq \\ln(1)\n$$\nUsing the logarithm property $\\ln(ab) = \\ln(a) + \\ln(b)$, we get:\n$$\n\\ln(x_1) + \\ln(x_2) \\leq 0\n$$\nSubstituting $y_1 = \\ln(x_1)$ and $y_2 = \\ln(x_2)$, the constraint becomes a linear inequality:\n$$\ny_1 + y_2 \\leq 0\n$$\nFor the bound constraints on $x_1$, we again apply the monotonic $\\ln(\\cdot)$ function:\n$$\n\\ln\\left(\\frac{1}{4}\\right) \\leq \\ln(x_1) \\leq \\ln(2)\n$$\n$$\n\\ln(4^{-1}) \\leq y_1 \\leq \\ln(2) \\implies -\\ln(4) \\leq y_1 \\leq \\ln(2)\n$$\nSimilarly, for the bound constraints on $x_2$:\n$$\n\\ln\\left(\\frac{1}{4}\\right) \\leq \\ln(x_2) \\leq \\ln(2) \\implies -\\ln(4) \\leq y_2 \\leq \\ln(2)\n$$\nThe feasible region in the $(y_1, y_2)$ space, let's call it $S_y$, is defined by the following system of linear inequalities:\n\\begin{align*}\ny_1 + y_2 &\\leq 0 \\\\\ny_1 &\\geq -\\ln(4) \\\\\ny_1 &\\leq \\ln(2) \\\\\ny_2 &\\geq -\\ln(4) \\\\\ny_2 &\\leq \\ln(2)\n\\end{align*}\nTo justify why the resulting set $S_y$ is convex, we note that each of these five inequalities defines a closed half-space in $\\mathbb{R}^2$. For example, $f(y_1, y_2) = y_1 + y_2$ is an affine function, and the set of points where $f(y_1, y_2) \\leq 0$ is a half-space. It is a fundamental theorem of convex analysis that any half-space is a convex set. The set $S_y$ is the intersection of these five convex sets. Another fundamental theorem states that the intersection of any number of convex sets is itself a convex set. Therefore, the feasible region $S_y$ in the $(y_1, y_2)$ variables is a convex set (specifically, a convex polygon). This transformation is a standard technique used in geometric programming to convert a certain class of non-convex problems into convex ones.", "answer": "$$\n\\boxed{\\frac{17}{64}}\n$$", "id": "3114525"}]}