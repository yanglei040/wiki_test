{"hands_on_practices": [{"introduction": "Linear programs (LPs) represent the ideal setting where strong duality holds robustly. This first exercise provides foundational practice by asking you to derive the dual of a standard-form LP directly from the Lagrangian framework, rather than relying on memorized rules. By then solving a concrete instance using complementary slackness, you will gain a practical understanding of how primal and dual optimal solutions certify each other's optimality. [@problem_id:3139594]", "problem": "Consider the following minimization Linear Programming (LP) problem in standard inequality form: minimize the linear objective subject to linear inequality constraints and nonnegativity constraints,\n$$\\min_{x \\in \\mathbb{R}^{n}} \\; c^{\\top} x \\quad \\text{subject to} \\quad A x \\ge b, \\; x \\ge 0,$$\nwhere $A \\in \\mathbb{R}^{m \\times n}$, $b \\in \\mathbb{R}^{m}$, and $c \\in \\mathbb{R}^{n}$. Using the foundational Lagrangian duality framework and the definitions of weak and strong duality (without invoking any pre-memorized dual formula), derive the dual optimization problem corresponding to the above primal problem by introducing appropriate nonnegative Lagrange multipliers for each inequality constraint. Clearly state the resulting dual decision variables, constraints, and objective function.\n\nNext, specialize to the concrete instance with dimension $m = 3$ and $n = 2$ given by\n$$A = \\begin{pmatrix} 2  0 \\\\ 0  3 \\\\ 1  1 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 4 \\\\ 3 \\\\ 5 \\end{pmatrix}, \\quad c = \\begin{pmatrix} 5 \\\\ 4 \\end{pmatrix}.$$\nUse complementary slackness, derived from the Karush-Kuhn-Tucker (KKT) conditions for LP, to determine which of the primal constraints $A x \\ge b$ bind at optimality and which are slack for this instance. Then, infer a dual optimal solution and verify optimality via strong duality. Finally, compute the optimal primal objective value $c^{\\top} x^{\\star}$ for this instance and express it as an exact real number. No rounding is required for the final answer.", "solution": "### Part 1: Derivation of the Dual Problem\n\nThe primal problem is given as:\n$$\n\\min_{x \\in \\mathbb{R}^{n}} \\; c^{\\top} x \\quad \\text{subject to} \\quad A x \\ge b, \\; x \\ge 0\n$$\nTo apply the Lagrangian framework, we first express the inequality constraints in the form $f_i(x) \\le 0$. The constraints are:\n1.  $A x \\ge b \\iff b - A x \\le 0$ (a set of $m$ inequalities)\n2.  $x \\ge 0 \\iff -x \\le 0$ (a set of $n$ inequalities)\n\nWe introduce nonnegative Lagrange multipliers for each of these constraints. Let $\\lambda \\in \\mathbb{R}^m$ be the vector of multipliers for the constraints $b - A x \\le 0$, so $\\lambda \\ge 0$. Let $\\mu \\in \\mathbb{R}^n$ be the vector of multipliers for the constraints $-x \\le 0$, so $\\mu \\ge 0$.\n\nThe Lagrangian function $L(x, \\lambda, \\mu)$ is defined as the objective function plus the sum of multipliers times their corresponding constraint functions:\n$$\nL(x, \\lambda, \\mu) = c^{\\top} x + \\lambda^{\\top}(b - A x) + \\mu^{\\top}(-x)\n$$\nWe can rearrange the terms by collecting those involving the primal variable $x$:\n$$\nL(x, \\lambda, \\mu) = c^{\\top} x - \\lambda^{\\top} A x - \\mu^{\\top} x + \\lambda^{\\top} b\n$$\n$$\nL(x, \\lambda, \\mu) = (c^{\\top} - \\lambda^{\\top} A - \\mu^{\\top})x + b^{\\top} \\lambda\n$$\nThis can be written more compactly using transposes:\n$$\nL(x, \\lambda, \\mu) = (c - A^{\\top} \\lambda - \\mu)^{\\top}x + b^{\\top} \\lambda\n$$\nThe Lagrange dual function, denoted $g(\\lambda, \\mu)$, is defined as the infimum of the Lagrangian over the primal variable $x$:\n$$\ng(\\lambda, \\mu) = \\inf_{x \\in \\mathbb{R}^n} L(x, \\lambda, \\mu) = \\inf_{x \\in \\mathbb{R}^n} \\left[ (c - A^{\\top} \\lambda - \\mu)^{\\top}x + b^{\\top} \\lambda \\right]\n$$\nThe expression inside the infimum is an affine (linear plus constant) function of $x$. If the coefficient vector of $x$ is non-zero, i.e., $c - A^{\\top} \\lambda - \\mu \\ne 0$, then the function is unbounded below, and its infimum is $-\\infty$. To obtain a finite value for the dual function, the linear term in $x$ must vanish. This imposes a constraint on the dual variables $\\lambda$ and $\\mu$:\n$$\nc - A^{\\top} \\lambda - \\mu = 0\n$$\nWhen this condition holds, the Lagrangian becomes independent of $x$, and its value is simply $b^{\\top} \\lambda$. Therefore, the dual function is:\n$$\ng(\\lambda, \\mu) = \\begin{cases}\nb^{\\top}\\lambda  \\text{if } c - A^{\\top}\\lambda - \\mu = 0 \\\\\n-\\infty  \\text{otherwise}\n\\end{cases}\n$$\nThe dual problem is to maximize the dual function subject to the constraints on the dual variables:\n$$\n\\max_{\\lambda, \\mu} \\; g(\\lambda, \\mu) \\quad \\text{subject to} \\quad \\lambda \\ge 0, \\; \\mu \\ge 0\n$$\nMaximizing $g(\\lambda, \\mu)$ is equivalent to maximizing $b^{\\top}\\lambda$ subject to the condition that makes $g(\\lambda, \\mu)$ finite. The dual problem is thus:\n$$\n\\max_{\\lambda, \\mu} \\; b^{\\top}\\lambda \\quad \\text{subject to} \\quad c - A^{\\top}\\lambda - \\mu = 0, \\quad \\lambda \\ge 0, \\quad \\mu \\ge 0\n$$\nWe can eliminate the dual variable $\\mu$. The constraint $c - A^{\\top}\\lambda - \\mu = 0$ implies $\\mu = c - A^{\\top}\\lambda$. The nonnegativity constraint $\\mu \\ge 0$ then becomes $c - A^{\\top}\\lambda \\ge 0$, which is equivalent to $A^{\\top}\\lambda \\le c$.\n\nSubstituting this back into the optimization problem, we obtain the dual problem solely in terms of the dual variable $\\lambda$:\n-   Dual decision variables: $\\lambda \\in \\mathbb{R}^m$.\n-   Dual objective function: Maximize $b^{\\top}\\lambda$.\n-   Dual constraints: $A^{\\top}\\lambda \\le c$ and $\\lambda \\ge 0$.\n\nThe resulting dual problem is:\n$$\n\\max_{\\lambda \\in \\mathbb{R}^{m}} \\; b^{\\top} \\lambda \\quad \\text{subject to} \\quad A^{\\top}\\lambda \\le c, \\; \\lambda \\ge 0\n$$\n\n### Part 2: Analysis of the Concrete Instance\n\nThe problem gives the concrete instance:\n$$A = \\begin{pmatrix} 2  0 \\\\ 0  3 \\\\ 1  1 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 4 \\\\ 3 \\\\ 5 \\end{pmatrix}, \\quad c = \\begin{pmatrix} 5 \\\\ 4 \\end{pmatrix}$$\nLet $x = (x_1, x_2)^{\\top}$. The primal problem is:\n$$\n\\min_{x_1, x_2} \\; 5x_1 + 4x_2\n$$\nsubject to:\n$$\n\\begin{align*}\n2x_1 \\ge 4 \\\\\n3x_2 \\ge 3 \\\\\nx_1 + x_2 \\ge 5 \\\\\nx_1, x_2 \\ge 0\n\\end{align*}\n$$\nThese constraints simplify to $x_1 \\ge 2$, $x_2 \\ge 1$, and $x_1 + x_2 \\ge 5$. The nonnegativity constraints $x_1 \\ge 0, x_2 \\ge 0$ are redundant.\n\nTo find the optimal primal solution $x^{\\star}$, we can examine the vertices of the feasible region. The boundaries are $x_1=2$, $x_2=1$, and $x_1+x_2=5$. The vertices are the feasible intersections of these lines.\n-   Intersection of $x_1=2$ and $x_1+x_2=5$: $2+x_2=5 \\implies x_2=3$. The point is $(2, 3)$, which is feasible.\n-   Intersection of $x_2=1$ and $x_1+x_2=5$: $x_1+1=5 \\implies x_1=4$. The point is $(4, 1)$, which is feasible.\nThe objective function is $z(x_1, x_2) = 5x_1 + 4x_2$. We evaluate it at the vertices:\n-   At $(2, 3)$: $z = 5(2) + 4(3) = 10 + 12 = 22$.\n-   At $(4, 1)$: $z = 5(4) + 4(1) = 20 + 4 = 24$.\nThe minimum objective value is $22$, occurring at the optimal primal solution $x^{\\star} = (2, 3)^{\\top}$.\n\nNow we determine which constraints of $A x \\ge b$ are binding at $x^{\\star} = (2, 3)$:\n1.  $2x_1^{\\star} \\ge 4 \\implies 2(2) = 4$. This is **binding**.\n2.  $3x_2^{\\star} \\ge 3 \\implies 3(3) = 9  3$. This is **slack**.\n3.  $x_1^{\\star} + x_2^{\\star} \\ge 5 \\implies 2+3 = 5$. This is **binding**.\n\nThe Karush-Kuhn-Tucker (KKT) conditions for an LP imply complementary slackness. Let $\\lambda = (\\lambda_1, \\lambda_2, \\lambda_3)^{\\top}$ be the dual variable. The complementary slackness conditions are:\n-   $\\lambda_i ((Ax^{\\star})_i - b_i) = 0$ for $i=1, 2, 3$.\n-   $(c - A^{\\top}\\lambda^{\\star})_j x_j^{\\star} = 0$ for $j=1, 2$.\n\nFrom the first set of conditions, since the second primal constraint is slack, its corresponding dual variable must be zero: $\\lambda_2^{\\star} = 0$.\n\nFrom the second set of conditions:\n-   For $j=1$: $x_1^{\\star} = 2  0$, so the first dual constraint must be binding: $(A^{\\top}\\lambda^{\\star})_1 = c_1$.\n    Using $A^{\\top} = \\begin{pmatrix} 2  0  1 \\\\ 0  3  1 \\end{pmatrix}$, this is $2\\lambda_1^{\\star} + 0\\lambda_2^{\\star} + 1\\lambda_3^{\\star} = 5 \\implies 2\\lambda_1^{\\star} + \\lambda_3^{\\star} = 5$.\n-   For $j=2$: $x_2^{\\star} = 3  0$, so the second dual constraint must be binding: $(A^{\\top}\\lambda^{\\star})_2 = c_2$.\n    This is $0\\lambda_1^{\\star} + 3\\lambda_2^{\\star} + 1\\lambda_3^{\\star} = 4 \\implies 3\\lambda_2^{\\star} + \\lambda_3^{\\star} = 4$.\n\nWe now have a system of equations to find the dual optimal solution $\\lambda^{\\star}$:\n1.  $\\lambda_2^{\\star} = 0$\n2.  $2\\lambda_1^{\\star} + \\lambda_3^{\\star} = 5$\n3.  $3\\lambda_2^{\\star} + \\lambda_3^{\\star} = 4$\n\nSubstituting $\\lambda_2^{\\star}=0$ into the third equation gives $3(0) + \\lambda_3^{\\star} = 4$, so $\\lambda_3^{\\star} = 4$.\nSubstituting $\\lambda_3^{\\star}=4$ into the second equation gives $2\\lambda_1^{\\star} + 4 = 5$, so $2\\lambda_1^{\\star} = 1$, which means $\\lambda_1^{\\star} = \\frac{1}{2}$.\nThe inferred dual optimal solution is $\\lambda^{\\star} = (\\frac{1}{2}, 0, 4)^{\\top}$.\n\nTo verify optimality, we use strong duality. We check if the primal and dual objective values are equal.\n-   Primal optimal objective value: $p^{\\star} = c^{\\top}x^{\\star} = 5(2) + 4(3) = 22$.\n-   Dual optimal objective value: $d^{\\star} = b^{\\top}\\lambda^{\\star} = 4\\lambda_1^{\\star} + 3\\lambda_2^{\\star} + 5\\lambda_3^{\\star} = 4(\\frac{1}{2}) + 3(0) + 5(4) = 2 + 0 + 20 = 22$.\n\nSince $p^{\\star} = d^{\\star} = 22$, and both $x^{\\star}$ and $\\lambda^{\\star}$ are feasible for their respective problems (we must check dual feasibility for $\\lambda^{\\star}$: $\\lambda^{\\star} \\ge 0$ is true, and $A^{\\top}\\lambda^{\\star} \\le c$ is true since both constraints hold with equality), we have verified the optimality of both solutions.\n\nThe final request is to compute the optimal primal objective value $c^{\\top}x^{\\star}$. As calculated, this value is $22$.", "answer": "$$\n\\boxed{22}\n$$", "id": "3139594"}, {"introduction": "Moving beyond linear programs, this exercise explores duality in the broader context of convex optimization. For general convex problems, strong duality is not automatic and relies on constraint qualifications, such as Slater's condition, which ensure the feasible region is well-behaved. This practice will guide you through verifying Slater's condition for a convex quadratic program (QP) and using the powerful Karush-Kuhn-Tucker (KKT) conditions to find the optimal solution. [@problem_id:3198146]", "problem": "Consider the convex optimization problem over $x \\in \\mathbb{R}^{2}$ given by the objective $f(x) = \\frac{1}{2} x^{\\top} Q x + c^{\\top} x$ with linear inequality constraints and bound constraints. Let\n$$\nQ = \\begin{pmatrix}\n2  0 \\\\\n0  4\n\\end{pmatrix}, \\quad\nc = \\begin{pmatrix}\n-2 \\\\\n-6\n\\end{pmatrix}, \\quad\nA = \\begin{pmatrix}\n1  2 \\\\\n-1  1\n\\end{pmatrix}, \\quad\nb = \\begin{pmatrix}\n5 \\\\\n1\n\\end{pmatrix}, \\quad\nl = \\begin{pmatrix}\n0 \\\\\n0\n\\end{pmatrix}, \\quad\nu = \\begin{pmatrix}\n3 \\\\\n2\n\\end{datetime},\n$$\nThe constraints are $A x \\le b$ and $l \\le x \\le u$, interpreted componentwise. Using only fundamental definitions from convex optimization—namely the Lagrangian, the dual function, the dual problem, Karush–Kuhn–Tucker (KKT) conditions, and Slater's condition—perform the following:\n\n1. Construct the Lagrangian $L(x, \\lambda, \\mu, \\nu)$ by introducing Lagrange multipliers $\\lambda \\in \\mathbb{R}^{2}_{+}$ for the linear inequalities $A x \\le b$, $\\mu \\in \\mathbb{R}^{2}_{+}$ for the upper-bound inequalities $x - u \\le 0$, and $\\nu \\in \\mathbb{R}^{2}_{+}$ for the lower-bound inequalities $l - x \\le 0$.\n\n2. Derive the dual function $g(\\lambda, \\mu, \\nu)$ by minimizing the Lagrangian over $x \\in \\mathbb{R}^{2}$, and write the associated dual optimization problem.\n\n3. Show that strong duality holds for this problem by establishing Slater's condition via the existence of a point $x$ with $A x  b$ and $l  x  u$.\n\n4. Use the KKT conditions to determine primal and dual optimal solutions and compute the optimal objective value $p^{\\star}$.\n\nReport the single final answer as the exact value of $p^{\\star}$ with no rounding. No physical units are involved.", "solution": "### Solution\n\nThe primal optimization problem is:\n$$\n\\begin{aligned}\n\\text{minimize} \\quad  f(x) = \\frac{1}{2} x^{\\top} Q x + c^{\\top} x \\\\\n\\text{subject to} \\quad  A x - b \\le 0 \\\\\n x - u \\le 0 \\\\\n l - x \\le 0\n\\end{aligned}\n$$\nwhere $x = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} \\in \\mathbb{R}^2$. The objective function is convex because the Hessian matrix $Q$ is positive definite (its eigenvalues are $2$ and $4$, which are positive). The constraints are linear, defining a convex feasible set (a polytope).\n\n**1. The Lagrangian**\n\nWe introduce Lagrange multipliers $\\lambda \\in \\mathbb{R}^{2}_{+}$ for the constraints $A x - b \\le 0$, $\\mu \\in \\mathbb{R}^{2}_{+}$ for $x - u \\le 0$, and $\\nu \\in \\mathbb{R}^{2}_{+}$ for $l - x \\le 0$. The Lagrangian function $L(x, \\lambda, \\mu, \\nu)$ is defined as:\n$$\nL(x, \\lambda, \\mu, \\nu) = f(x) + \\lambda^{\\top}(A x - b) + \\mu^{\\top}(x - u) + \\nu^{\\top}(l - x)\n$$\nSubstituting the expressions for $f(x)$ and rearranging terms based on $x$:\n$$\nL(x, \\lambda, \\mu, \\nu) = \\frac{1}{2} x^{\\top} Q x + c^{\\top} x + \\lambda^{\\top} A x - \\lambda^{\\top} b + \\mu^{\\top} x - \\mu^{\\top} u + \\nu^{\\top} l - \\nu^{\\top} x\n$$\n$$\nL(x, \\lambda, \\mu, \\nu) = \\frac{1}{2} x^{\\top} Q x + (c^{\\top} + \\lambda^{\\top} A + \\mu^{\\top} - \\nu^{\\top}) x - (\\lambda^{\\top} b + \\mu^{\\top} u - \\nu^{\\top} l)\n$$\n\n**2. The Dual Function and Dual Problem**\n\nThe Lagrange dual function $g(\\lambda, \\mu, \\nu)$ is the infimum of the Lagrangian over $x$:\n$$\ng(\\lambda, \\mu, \\nu) = \\inf_{x \\in \\mathbb{R}^{2}} L(x, \\lambda, \\mu, \\nu)\n$$\nSince $L$ is a convex quadratic function of $x$ (because $Q$ is positive definite), its infimum is attained when its gradient with respect to $x$ is zero:\n$$\n\\nabla_x L(x, \\lambda, \\mu, \\nu) = Q x + c + A^{\\top}\\lambda + \\mu - \\nu = 0\n$$\nSolving for $x$, we get the unique minimizer $x^*(\\lambda, \\mu, \\nu)$:\n$$\nx^*(\\lambda, \\mu, \\nu) = -Q^{-1}(c + A^{\\top}\\lambda + \\mu - \\nu)\n$$\nSubstituting $x^*$ back into the Lagrangian expression, and using the fact that $(c + A^{\\top}\\lambda + \\mu - \\nu) = -Q x^*$:\n$$\ng(\\lambda, \\mu, \\nu) = \\frac{1}{2} (x^*)^{\\top} Q x^* + (c^{\\top} + \\lambda^{\\top} A + \\mu^{\\top} - \\nu^{\\top}) x^* - (b^{\\top}\\lambda + u^{\\top}\\mu - l^{\\top}\\nu)\n$$\n$$\ng(\\lambda, \\mu, \\nu) = \\frac{1}{2} (x^*)^{\\top} Q x^* - (x^*)^{\\top} Q x^* - (b^{\\top}\\lambda + u^{\\top}\\mu - l^{\\top}\\nu)\n$$\n$$\ng(\\lambda, \\mu, \\nu) = -\\frac{1}{2} (x^*)^{\\top} Q x^* - (b^{\\top}\\lambda + u^{\\top}\\mu - l^{\\top}\\nu)\n$$\nSubstituting the expression for $x^*$:\n$$\ng(\\lambda, \\mu, \\nu) = -\\frac{1}{2} (c + A^{\\top}\\lambda + \\mu - \\nu)^{\\top} Q^{-1} (c + A^{\\top}\\lambda + \\mu - \\nu) - b^{\\top}\\lambda - u^{\\top}\\mu + l^{\\top}\\nu\n$$\nThe dual problem is to maximize the dual function subject to the non-negativity of the multipliers:\n$$\n\\begin{aligned}\n\\text{maximize} \\quad  g(\\lambda, \\mu, \\nu) \\\\\n\\text{subject to} \\quad  \\lambda \\ge 0, \\mu \\ge 0, \\nu \\ge 0\n\\end{aligned}\n$$\n\n**3. Strong Duality and Slater's Condition**\n\nStrong duality holds if Slater's condition is satisfied. Since the constraints are all linear (affine), Slater's condition requires the existence of a point $x$ that is strictly feasible. That is, we need to find an $x = (x_1, x_2)^{\\top}$ such that $A x  b$ and $l  x  u$.\nThe strict inequalities are:\n1. $x_1 + 2x_2  5$\n2. $-x_1 + x_2  1$\n3. $0  x_1  3$\n4. $0  x_2  2$\n\nLet's test the point $x = \\begin{pmatrix} 1.5 \\\\ 1 \\end{pmatrix}$.\n1. $1.5 + 2(1) = 3.5  5$ (satisfied).\n2. $-1.5 + 1 = -0.5  1$ (satisfied).\n3. $0  1.5  3$ (satisfied).\n4. $0  1  2$ (satisfied).\nSince a strictly feasible point exists, Slater's condition holds. This implies that strong duality holds, i.e., the primal optimal value $p^{\\star}$ is equal to the dual optimal value $d^{\\star}$, and the dual optimum is attained.\n\n**4. KKT Conditions and Optimal Solution**\n\nBecause the problem is convex and Slater's condition holds, the Karush–Kuhn–Tucker (KKT) conditions are necessary and sufficient for optimality. A point $x^*$ is a primal optimum and $(\\lambda^*, \\mu^*, \\nu^*)$ is a dual optimum if and only if they satisfy the KKT conditions:\n\n1.  **Stationarity:** $\\nabla_x L(x^*, \\lambda^*, \\mu^*, \\nu^*) = 0 \\implies Qx^* + c + A^{\\top}\\lambda^* + \\mu^* - \\nu^* = 0$.\n2.  **Primal Feasibility:** $Ax^* - b \\le 0$, $x^* - u \\le 0$, $l - x^* \\le 0$.\n3.  **Dual Feasibility:** $\\lambda^* \\ge 0$, $\\mu^* \\ge 0$, $\\nu^* \\ge 0$.\n4.  **Complementary Slackness:** $\\lambda_i^*(A_i x^* - b_i) = 0$, $\\mu_j^*(x_j^* - u_j) = 0$, $\\nu_j^*(l_j - x_j^*) = 0$ for all components $i,j$.\n\nLet's first find the unconstrained minimum of $f(x)$ by setting its gradient to zero:\n$$\n\\nabla f(x) = Qx + c = \\begin{pmatrix} 2  0 \\\\ 0  4 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} + \\begin{pmatrix} -2 \\\\ -6 \\end{pmatrix} = \\begin{pmatrix} 2x_1 - 2 \\\\ 4x_2 - 6 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\nThis yields $x_1 = 1$ and $x_2 = 1.5$. Let's test if this point $x = \\begin{pmatrix} 1 \\\\ 1.5 \\end{pmatrix}$ is feasible.\n-   **Primal Feasibility check:**\n    -   $Ax \\le b$:\n        $1 + 2(1.5) = 4 \\le 5$ (True)\n        $-1 + 1.5 = 0.5 \\le 1$ (True)\n    -   $l \\le x \\le u$:\n        $0 \\le 1 \\le 3$ (True)\n        $0 \\le 1.5 \\le 2$ (True)\n\nThe unconstrained minimizer is feasible. Since it minimizes the objective function over all of $\\mathbb{R}^2$, it must also be the minimizer over the smaller feasible set. Thus, the primal optimal solution is $x^* = \\begin{pmatrix} 1 \\\\ 1.5 \\end{pmatrix}$.\n\nNow we determine the dual optimal variables. Since $x^*$ lies in the strict interior of the feasible region, all inequality constraints are inactive:\n-   $x_1^* + 2x_2^* - 5 = 4 - 5 = -1  0$\n-   $-x_1^* + x_2^* - 1 = 0.5 - 1 = -0.5  0$\n-   $x_1^* - 3 = 1 - 3 = -2  0$\n-   $x_2^* - 2 = 1.5 - 2 = -0.5  0$\n-   $0 - x_1^* = -1  0$\n-   $0 - x_2^* = -1.5  0$\n\nBy the complementary slackness conditions, since none of the inequality constraints are active (i.e., hold with equality), all Lagrange multipliers must be zero:\n$$\n\\lambda^* = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}, \\quad \\mu^* = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}, \\quad \\nu^* = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\nThis satisfies dual feasibility ($\\lambda^*, \\mu^*, \\nu^* \\ge 0$).\nFinally, we check the stationarity condition with these values:\n$$\nQx^* + c + A^{\\top}\\lambda^* + \\mu^* - \\nu^* = Qx^* + c = \\begin{pmatrix} 2(1) - 2 \\\\ 4(1.5) - 6 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\nThe stationarity condition is satisfied.\nThus, the primal-dual solution pair $(x^*, \\lambda^*, \\mu^*, \\nu^*)$ with $x^* = \\begin{pmatrix} 1 \\\\ 1.5 \\end{pmatrix}$ and all multipliers being zero, fulfills all KKT conditions.\n\nThe optimal objective value, $p^{\\star}$, is calculated by evaluating $f(x)$ at $x^*$:\n$$\np^{\\star} = f(x^*) = \\frac{1}{2} (x^*)^{\\top} Q x^* + c^{\\top} x^*\n$$\n$$\np^{\\star} = \\frac{1}{2} \\begin{pmatrix} 1  1.5 \\end{pmatrix} \\begin{pmatrix} 2  0 \\\\ 0  4 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1.5 \\end{pmatrix} + \\begin{pmatrix} -2  -6 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1.5 \\end{pmatrix}\n$$\n$$\np^{\\star} = \\frac{1}{2} \\left( 2(1)^2 + 4(1.5)^2 \\right) + (-2(1) - 6(1.5))\n$$\n$$\np^{\\star} = \\frac{1}{2} \\left( 2 + 4(2.25) \\right) + (-2 - 9)\n$$\n$$\np^{\\star} = \\frac{1}{2} (2 + 9) - 11 = \\frac{11}{2} - 11 = -\\frac{11}{2}\n$$\nAlternatively, using fractional representation: $x^* = \\begin{pmatrix} 1 \\\\ 3/2 \\end{pmatrix}$\n$$\np^{\\star} = \\frac{1}{2} \\left( 2(1)^2 + 4(\\frac{3}{2})^2 \\right) + (-2(1) - 6(\\frac{3}{2})) = \\frac{1}{2} \\left( 2 + 4(\\frac{9}{4}) \\right) + (-2 - 9) = \\frac{1}{2}(2+9) - 11 = \\frac{11}{2} - 11 = -\\frac{11}{2}\n$$\n\nThe optimal objective value is $-\\frac{11}{2}$.", "answer": "$$\n\\boxed{-\\frac{11}{2}}\n$$", "id": "3198146"}, {"introduction": "What happens when an optimization problem is not convex? This final exercise confronts this question directly by exploring a simple-looking but non-convex problem. You will calculate the optimal primal value $p^{\\star}$ and the optimal dual value $d^{\\star}$ and discover a non-zero duality gap ($p^{\\star} \\gt d^{\\star}$), a phenomenon that is impossible in well-behaved convex problems. This hands-on calculation provides a tangible illustration of the difference between weak duality, which always holds, and the special circumstances required for strong duality. [@problem_id:3217490]", "problem": "Consider the following constrained minimization problem with decision variables $x_{1}$ and $x_{2}$:\nMinimize $f(x_{1}, x_{2}) = x_{1} + x_{2}$ subject to the inequality constraints $x_{1} x_{2} \\geq 1$, $x_{1} \\geq 0$, and $x_{2} \\geq 0$.\nThis problem is non-convex when written in the standard inequality form $g_{i}(x_{1}, x_{2}) \\leq 0$ because the function $g(x_{1}, x_{2}) = 1 - x_{1} x_{2}$ is not convex, even though the feasible set is closed and nonempty. Using the foundational definition of the Lagrangian, the dual function as the infimum over the primal variables, and weak duality, determine the exact primal optimal value and the exact dual optimal value for this problem. Then compute the duality gap, defined as $p^{\\star} - d^{\\star}$, where $p^{\\star}$ is the primal optimal value and $d^{\\star}$ is the dual optimal value. Provide your final answer as a single exact number with no units. No rounding is required.", "solution": "### Primal Problem\nThe primal problem is to find the minimum value of $f(x_{1}, x_{2}) = x_{1} + x_{2}$ subject to the constraints $x_{1} x_{2} \\geq 1$, $x_{1} \\geq 0$, and $x_{2} \\geq 0$. Let $p^{\\star}$ denote the primal optimal value.\n\nThe constraints $x_{1} \\geq 0$, $x_{2} \\geq 0$, and $x_{1}x_{2} \\geq 1$ imply that we must have $x_{1}  0$ and $x_{2}  0$.\nBy the Arithmetic Mean-Geometric Mean (AM-GM) inequality, for any non-negative numbers $x_{1}$ and $x_{2}$, we have:\n$$ \\frac{x_{1} + x_{2}}{2} \\geq \\sqrt{x_{1}x_{2}} $$\nUsing the constraint $x_{1}x_{2} \\geq 1$, we can write:\n$$ \\sqrt{x_{1}x_{2}} \\geq \\sqrt{1} = 1 $$\nCombining these inequalities gives:\n$$ \\frac{x_{1} + x_{2}}{2} \\geq 1 $$\n$$ x_{1} + x_{2} \\geq 2 $$\nThis shows that the objective function $f(x_{1}, x_{2})$ is bounded below by $2$. The minimum value of $2$ is attainable if the equality in the AM-GM inequality holds, which occurs if and only if $x_{1} = x_{2}$.\nSubstituting $x_{1} = x_{2}$ into the constraint $x_{1}x_{2} \\geq 1$, we get:\n$$ x_{1}^{2} \\geq 1 $$\nSince $x_{1}  0$, this implies $x_{1} \\geq 1$. To achieve the minimum value of the sum $x_1+x_2 = 2x_1$, we must choose the smallest possible value for $x_1$, which is $x_{1} = 1$.\nThis gives the optimal point $(x_{1}^{\\star}, x_{2}^{\\star}) = (1, 1)$. This point satisfies all constraints: $1 \\times 1 = 1 \\geq 1$, $1 \\geq 0$, and $1 \\geq 0$.\nThe primal optimal value is the value of the objective function at this point:\n$$ p^{\\star} = f(1, 1) = 1 + 1 = 2 $$\n\n### Dual Problem\nTo formulate the dual problem, we first write the constraints in the standard form $g_{i}(x) \\leq 0$:\n1. $c_{1}(x_{1}, x_{2}) = 1 - x_{1}x_{2} \\leq 0$\n2. $c_{2}(x_{1}, x_{2}) = -x_{1} \\leq 0$\n3. $c_{3}(x_{1}, x_{2}) = -x_{2} \\leq 0$\n\nThe Lagrangian function $L(x_1, x_2, \\lambda_1, \\lambda_2, \\lambda_3)$ is defined as:\n$$ L(x_{1}, x_{2}, \\lambda_{1}, \\lambda_{2}, \\lambda_{3}) = f(x_{1}, x_{2}) + \\lambda_{1} c_{1}(x_{1}, x_{2}) + \\lambda_{2} c_{2}(x_{1}, x_{2}) + \\lambda_{3} c_{3}(x_{1}, x_{2}) $$\nwhere $\\lambda_{1}, \\lambda_{2}, \\lambda_{3} \\geq 0$ are the Lagrange multipliers (dual variables).\nSubstituting the functions, we have:\n$$ L(x_{1}, x_{2}, \\lambda) = (x_{1} + x_{2}) + \\lambda_{1}(1 - x_{1}x_{2}) + \\lambda_{2}(-x_{1}) + \\lambda_{3}(-x_{2}) $$\nWe can rearrange the terms by gathering coefficients of $x_{1}$ and $x_{2}$:\n$$ L(x_{1}, x_{2}, \\lambda) = (1 - \\lambda_{2})x_{1} + (1 - \\lambda_{3})x_{2} - \\lambda_{1}x_{1}x_{2} + \\lambda_{1} $$\nThe Lagrange dual function $q(\\lambda)$ is the infimum of the Lagrangian over the primal variables $x_{1}$ and $x_{2}$ (over their domain $\\mathbb{R}^2$):\n$$ q(\\lambda_{1}, \\lambda_{2}, \\lambda_{3}) = \\inf_{x_{1}, x_{2} \\in \\mathbb{R}} L(x_{1}, x_{2}, \\lambda_{1}, \\lambda_{2}, \\lambda_{3}) $$\nThe term $L(x_{1}, x_{2}, \\lambda)$ is a function of $x_1, x_2$ that includes a bilinear term $- \\lambda_{1}x_{1}x_{2}$.\nIf $\\lambda_{1}  0$, this function is a hyperbolic paraboloid, which is unbounded below. For any $\\lambda_1  0$, we can choose $x_1=x_2=x$ and let $x \\to \\infty$, which would make $L \\to -\\infty$ due to the $- \\lambda_1 x^2$ term. Thus, the infimum is $-\\infty$ if $\\lambda_{1}  0$.\nIf $\\lambda_{1} = 0$, the Lagrangian becomes a linear function:\n$$ L(x_{1}, x_{2}, \\lambda) = (1 - \\lambda_{2})x_{1} + (1 - \\lambda_{3})x_{2} $$\nFor the infimum of this linear function over $\\mathbb{R}^2$ to be finite (i.e., not $-\\infty$), the coefficients of $x_{1}$ and $x_{2}$ must be zero. This requires:\n$$ 1 - \\lambda_{2} = 0 \\implies \\lambda_{2} = 1 $$\n$$ 1 - \\lambda_{3} = 0 \\implies \\lambda_{3} = 1 $$\nSo, for the dual function to not be $-\\infty$, the dual variables must satisfy $\\lambda_{1} = 0$, $\\lambda_{2} = 1$, and $\\lambda_{3} = 1$. These values also satisfy the non-negativity constraints $\\lambda_i \\ge 0$.\nAt this specific point $(\\lambda_{1}, \\lambda_{2}, \\lambda_{3}) = (0, 1, 1)$, the Lagrangian is:\n$$ L(x_{1}, x_{2}, 0, 1, 1) = (1-1)x_{1} + (1-1)x_{2} - 0 \\cdot x_{1}x_{2} + 0 = 0 $$\nThe dual function value at this point is:\n$$ q(0, 1, 1) = \\inf_{x_{1}, x_{2} \\in \\mathbb{R}} 0 = 0 $$\nFor any other set of non-negative dual variables, $q(\\lambda) = -\\infty$.\n\nThe dual problem is to maximize the dual function $q(\\lambda)$ subject to $\\lambda_{i} \\geq 0$:\n$$ d^{\\star} = \\sup_{\\lambda_{1},\\lambda_{2},\\lambda_{3} \\geq 0} q(\\lambda_{1}, \\lambda_{2}, \\lambda_{3}) $$\nSince $q(\\lambda)$ is $0$ for one specific point and $-\\infty$ everywhere else, the supremum is $0$:\n$$ d^{\\star} = 0 $$\n\n### Duality Gap\nThe duality gap is the difference between the primal optimal value $p^{\\star}$ and the dual optimal value $d^{\\star}$:\n$$ \\text{Duality Gap} = p^{\\star} - d^{\\star} $$\nSubstituting the computed values:\n$$ \\text{Duality Gap} = 2 - 0 = 2 $$\nThe existence of this non-zero duality gap ($p^{\\star}  d^{\\star}$) is a consequence of the fact that the problem is not convex (specifically, the constraint function $1-x_1x_2$ is not convex), and therefore strong duality does not hold. Weak duality, which states $p^{\\star} \\geq d^{\\star}$, is always true and is satisfied here.", "answer": "$$\n\\boxed{2}\n$$", "id": "3217490"}]}