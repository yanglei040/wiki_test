{"hands_on_practices": [{"introduction": "This first exercise explores the stability of an optimal solution. Real-world parameters like costs or profits are rarely static, and this practice [@problem_id:3178640] demonstrates how to find the allowable range for an objective coefficient of a variable already in the optimal solution (a basic variable). Mastering this allows you to determine how much a parameter can fluctuate before the current optimal strategy becomes invalid, a crucial aspect of robust decision-making.", "problem": "Consider the parametric Linear Programming (LP) problem in standard form with decision variables $x_1$ and $x_2$ and slack variables $s_1$ and $s_2$:\n$$\n\\max z \\;=\\; c_1 x_1 + 3 x_2\n$$\nsubject to\n$$\nx_1 + 2 x_2 + s_1 \\;=\\; 8,\\quad 2 x_1 + x_2 + s_2 \\;=\\; 8,\\quad x_1, x_2, s_1, s_2 \\;\\ge\\; 0.\n$$\nSuppose the Simplex method has produced a current basis consisting of $\\{x_1, x_2\\}$ with the following final simplex tableau (basic rows shown; columns ordered as $x_1, x_2, s_1, s_2$):\n$$\n\\begin{array}{c|rrrr|r}\n  x_1  x_2  s_1  s_2  \\text{RHS} \\\\\n\\hline\nx_1  1  0  -\\frac{1}{3}  \\frac{2}{3}  \\frac{8}{3} \\\\\nx_2  0  1  \\frac{2}{3}  -\\frac{1}{3}  \\frac{8}{3}\n\\end{array}\n$$\nUsing only core definitions from Linear Programming and the structure of the Simplex tableau, derive the allowable interval of the objective coefficient $c_1$ such that the current basis $\\{x_1, x_2\\}$ remains optimal for the maximization problem. Report the exact lower and upper bounds as rational numbers. No rounding is required.", "solution": "### Step 1: Extract Givens\n- Objective function: $\\max z \\;=\\; c_1 x_1 + 3 x_2$\n- Constraints:\n  - $x_1 + 2 x_2 + s_1 \\;=\\; 8$\n  - $2 x_1 + x_2 + s_2 \\;=\\; 8$\n  - $x_1, x_2, s_1, s_2 \\;\\ge\\; 0$\n- Parametric coefficient to analyze: $c_1$\n- Current basis: $\\{x_1, x_2\\}$\n- Final simplex tableau for this basis:\n$$\n\\begin{array}{c|rrrr|r}\n  x_1  x_2  s_1  s_2  \\text{RHS} \\\\\n\\hline\nx_1  1  0  -\\frac{1}{3}  \\frac{2}{3}  \\frac{8}{3} \\\\\nx_2  0  1  \\frac{2}{3}  -\\frac{1}{3}  \\frac{8}{3}\n\\end{array}\n$$\n\n### Solution Derivation\nFor a maximization problem, the optimality condition for a basis is that the reduced costs for all non-basic variables must be non-positive ($\\bar{c}_j \\le 0$). The reduced cost for a variable $x_j$ is calculated as $\\bar{c}_j = c_j - z_j$, where $z_j = \\mathbf{c}_B^T \\mathbf{B}^{-1} \\mathbf{a}_j$. Therefore, for the current basis to remain optimal, we must have $c_j - \\mathbf{c}_B^T \\mathbf{B}^{-1} \\mathbf{a}_j \\le 0$ for all non-basic variables $j$.\n\nThe set of variables is $\\{x_1, x_2, s_1, s_2\\}$. The given basis is $\\{x_1, x_2\\}$, so the non-basic variables are $\\{s_1, s_2\\}$.\n\nThe objective function is $z = c_1 x_1 + 3 x_2 + 0 s_1 + 0 s_2$. The vector of objective coefficients for the basic variables is:\n$$ \\mathbf{c}_B^T = \\begin{pmatrix} c_1  3 \\end{pmatrix} $$\nThe objective coefficients for the non-basic variables are $c_{s_1} = 0$ and $c_{s_2} = 0$.\n\nThe final simplex tableau gives the matrix product $\\mathbf{B}^{-1}\\mathbf{A}$, where $\\mathbf{A}$ is the full constraint matrix. The columns of the final tableau under the non-basic variables correspond to $\\mathbf{B}^{-1}\\mathbf{a}_j$ for each non-basic variable $j$. From the tableau, we have:\n- For $s_1$: $\\mathbf{B}^{-1}\\mathbf{a}_{s_1} = \\begin{pmatrix} -\\frac{1}{3} \\\\ \\frac{2}{3} \\end{pmatrix}$.\n- For $s_2$: $\\mathbf{B}^{-1}\\mathbf{a}_{s_2} = \\begin{pmatrix} \\frac{2}{3} \\\\ -\\frac{1}{3} \\end{pmatrix}$.\n\nNow, we compute the reduced cost for each non-basic variable.\n\n1.  **Reduced cost for $s_1$**:\n    $$ z_{s_1} = \\mathbf{c}_B^T (\\mathbf{B}^{-1}\\mathbf{a}_{s_1}) = \\begin{pmatrix} c_1  3 \\end{pmatrix} \\begin{pmatrix} -\\frac{1}{3} \\\\ \\frac{2}{3} \\end{pmatrix} = -\\frac{1}{3}c_1 + 2 $$\n    The reduced cost is $\\bar{c}_{s_1} = c_{s_1} - z_{s_1} = 0 - (-\\frac{1}{3}c_1 + 2) = \\frac{1}{3}c_1 - 2$.\n    For optimality, this must be non-positive:\n    $$ \\frac{1}{3}c_1 - 2 \\le 0 \\implies \\frac{1}{3}c_1 \\le 2 \\implies c_1 \\le 6 $$\n\n2.  **Reduced cost for $s_2$**:\n    $$ z_{s_2} = \\mathbf{c}_B^T (\\mathbf{B}^{-1}\\mathbf{a}_{s_2}) = \\begin{pmatrix} c_1  3 \\end{pmatrix} \\begin{pmatrix} \\frac{2}{3} \\\\ -\\frac{1}{3} \\end{pmatrix} = \\frac{2}{3}c_1 - 1 $$\n    The reduced cost is $\\bar{c}_{s_2} = c_{s_2} - z_{s_2} = 0 - (\\frac{2}{3}c_1 - 1) = 1 - \\frac{2}{3}c_1$.\n    For optimality, this must be non-positive:\n    $$ 1 - \\frac{2}{3}c_1 \\le 0 \\implies 1 \\le \\frac{2}{3}c_1 \\implies 3 \\le 2c_1 \\implies c_1 \\ge \\frac{3}{2} $$\n\nTo ensure the current basis $\\{x_1, x_2\\}$ remains optimal, both conditions must be satisfied simultaneously. Combining the two inequalities, we obtain the allowable interval for $c_1$:\n$$ \\frac{3}{2} \\le c_1 \\le 6 $$\nThe lower bound for $c_1$ is $\\frac{3}{2}$ and the upper bound is $6$.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{3}{2}  6 \\end{pmatrix}}\n$$", "id": "3178640"}, {"introduction": "Building on the concept of stability, this next practice [@problem_id:3178669] addresses a different but equally important question: at what point does a currently excluded option become attractive? We will calculate the precise threshold for an objective coefficient of a non-basic variable that would justify its inclusion in the optimal solution. This type of \"tipping-point\" analysis is fundamental for evaluating potential improvements or new opportunities.", "problem": "Consider the following Linear Programming (LP) problem in standard inequality form with slack variables introduced to obtain equalities. The primal is a maximization problem:\n$$\n\\text{maximize } c_1 x_1 + c_2 x_2 + c_3 x_3\n$$\nsubject to\n$$\n\\begin{aligned}\n2 x_1 + x_2 + x_3 + s_1 = 8, \\\\\n- x_1 + 2 x_2 + 3 x_3 + s_2 = 10, \\\\\nx_1, x_2, x_3, s_1, s_2 \\geq 0,\n\\end{aligned}\n$$\nwhere $x_1, x_2, x_3$ are decision variables and $s_1, s_2$ are slack variables. The current optimal basis is reported to be $\\{ s_1, x_2 \\}$, with the associated basic feasible solution computed from the constraints. The objective coefficients are $c_1 = -4$, $c_2 = 7$, and $c_3$ is treated as a parameter that may vary.\n\nUsing only foundational definitions of LP duality, basic feasible solutions, and the Karush–Kuhn–Tucker (KKT) conditions, analyze the sensitivity of the optimal solution with respect to the single objective coefficient $c_3$ when the corresponding variable $x_3$ is currently nonbasic. In particular:\n- Determine the dual price vector (also called shadow prices) associated with the current basis.\n- Derive the reduced cost of $x_3$ as a function of $c_3$.\n- Compute the exact value of $c_3$ at which $x_3$ first becomes eligible to enter the basis (i.e., the threshold value where the sign condition for optimality is violated in a way that favors $x_3$ entering).\n\nProvide the final threshold as a single real number $c_3^\\star$. Express the answer exactly; do not round.", "solution": "The problem requires an analysis of the sensitivity of an optimal linear programming (LP) solution to a change in an objective function coefficient, $c_3$, for a nonbasic variable, $x_3$. The analysis must be based on foundational principles of duality and the Karush-Kuhn-Tucker (KKT) conditions.\n\nThe primal LP problem is given in standard form after introducing slack variables:\n$$\n\\text{maximize } z = c_1 x_1 + c_2 x_2 + c_3 x_3 + 0 s_1 + 0 s_2\n$$\nsubject to\n$$\n\\begin{aligned}\n2 x_1 + x_2 + x_3 + s_1 = 8 \\\\\n-x_1 + 2 x_2 + 3 x_3 + s_2 = 10 \\\\\nx_1, x_2, x_3, s_1, s_2 \\geq 0\n\\end{aligned}\n$$\nThe objective coefficients are $c_1 = -4$, $c_2 = 7$, and $c_3$ is a parameter.\nIn matrix form, we want to maximize $\\mathbf{c}^T \\mathbf{x}$ subject to $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$ and $\\mathbf{x} \\geq \\mathbf{0}$, where:\n$$ \\mathbf{x} = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ s_1 \\\\ s_2 \\end{pmatrix}, \\quad \\mathbf{c} = \\begin{pmatrix} -4 \\\\ 7 \\\\ c_3 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad \\mathbf{A} = \\begin{pmatrix} 2  1  1  1  0 \\\\ -1  2  3  0  1 \\end{pmatrix}, \\quad \\mathbf{b} = \\begin{pmatrix} 8 \\\\ 10 \\end{pmatrix} $$\nThe problem states that the current optimal basis is $\\mathcal{B} = \\{s_1, x_2\\}$. The set of basic variables is $\\mathbf{x}_B = [s_1, x_2]^T$ and the set of nonbasic variables is $\\mathbf{x}_N = [x_1, x_3, s_2]^T$.\n\nThe basis matrix, $\\mathbf{B}$, consists of the columns of $\\mathbf{A}$ corresponding to the basic variables, which are column $4$ ($s_1$) and column $2$ ($x_2$).\n$$ \\mathbf{B} = \\begin{pmatrix} 1  1 \\\\ 0  2 \\end{pmatrix} $$\nThe cost vector for the basic variables is $\\mathbf{c}_B = [c_{s_1}, c_{x_2}]^T = [0, 7]^T$.\n\nFirst, we verify that this basis corresponds to a basic feasible solution (BFS). The values of the basic variables are given by $\\mathbf{x}_B = \\mathbf{B}^{-1}\\mathbf{b}$. We compute the inverse of $\\mathbf{B}$:\n$$ \\mathbf{B}^{-1} = \\frac{1}{(1)(2) - (1)(0)} \\begin{pmatrix} 2  -1 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 1  -1/2 \\\\ 0  1/2 \\end{pmatrix} $$\nNow we compute the basic solution:\n$$ \\mathbf{x}_B = \\begin{pmatrix} s_1 \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} 1  -1/2 \\\\ 0  1/2 \\end{pmatrix} \\begin{pmatrix} 8 \\\\ 10 \\end{pmatrix} = \\begin{pmatrix} 8 - 5 \\\\ 0 + 5 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 5 \\end{pmatrix} $$\nSince $s_1 = 3 \\geq 0$ and $x_2 = 5 \\geq 0$, the solution is feasible. The full solution vector is $\\mathbf{x} = [0, 5, 0, 3, 0]^T$.\n\nThe dual price vector (or shadow prices), denoted by $\\mathbf{y}$, is associated with the constraints. For a given basis $\\mathbf{B}$, the dual prices are defined by the relation $\\mathbf{y}^T = \\mathbf{c}_B^T \\mathbf{B}^{-1}$. This definition ensures that the reduced costs of the basic variables are zero, a necessary condition for optimality.\n$$ \\mathbf{y}^T = \\begin{pmatrix} 0  7 \\end{pmatrix} \\begin{pmatrix} 1  -1/2 \\\\ 0  1/2 \\end{pmatrix} = \\begin{pmatrix} 0  7/2 \\end{pmatrix} $$\nThus, the dual price vector is $\\mathbf{y} = [y_1, y_2]^T = [0, 7/2]^T$.\n\nThe KKT conditions provide the fundamental basis for optimality. For an LP, they consist of primal feasibility, dual feasibility, and complementary slackness. The reduced cost of a variable $x_j$, denoted $\\bar{c}_j$, is directly related to the KKT multipliers. For a maximization problem, the reduced cost is defined as $\\bar{c}_j = c_j - \\mathbf{y}^T \\mathbf{A}_j$, where $\\mathbf{A}_j$ is the $j$-th column of the constraint matrix $\\mathbf{A}$. A solution is optimal if and only if all reduced costs are non-positive, $\\bar{c}_j \\leq 0$ for all $j$.\n\nWe compute the reduced costs for the nonbasic variables $x_1$, $x_3$, and $s_2$. The columns from $\\mathbf{A}$ are $\\mathbf{A}_1 = [2, -1]^T$, $\\mathbf{A}_3 = [1, 3]^T$, and $\\mathbf{A}_5 = [0, 1]^T$. The corresponding costs are $c_1=-4$, $c_3$, and $c_{s_2}=0$.\n\nThe reduced cost for $x_1$:\n$$ \\bar{c}_1 = c_1 - \\mathbf{y}^T \\mathbf{A}_1 = -4 - \\begin{pmatrix} 0  7/2 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix} = -4 - (-\\frac{7}{2}) = -\\frac{1}{2} $$\nThe reduced cost for $x_3$:\n$$ \\bar{c}_3 = c_3 - \\mathbf{y}^T \\mathbf{A}_3 = c_3 - \\begin{pmatrix} 0  7/2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix} = c_3 - \\frac{21}{2} $$\nThis is the reduced cost of $x_3$ as a function of $c_3$.\n\nThe reduced cost for $s_2$:\n$$ \\bar{c}_{s_2} = c_{s_2} - \\mathbf{y}^T \\mathbf{A}_5 = 0 - \\begin{pmatrix} 0  7/2 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = -\\frac{7}{2} $$\nFor the given basis to be optimal, all these reduced costs must be less than or equal to zero.\n$$ \\bar{c}_1 = -1/2 \\leq 0 \\quad (\\text{satisfied}) $$\n$$ \\bar{c}_{s_2} = -7/2 \\leq 0 \\quad (\\text{satisfied}) $$\n$$ \\bar{c}_3 = c_3 - \\frac{21}{2} \\leq 0 \\implies c_3 \\leq \\frac{21}{2} $$\nThe current basis is optimal as long as $c_3 \\leq 21/2$.\n\nA nonbasic variable becomes eligible to enter the basis if increasing its value from $0$ improves the objective function. For a maximization problem, this occurs when its reduced cost is positive, i.e., $\\bar{c}_j  0$. The threshold value, $c_3^\\star$, is the value of $c_3$ at which this condition is first met. This occurs at the boundary of the optimality region, where the reduced cost becomes zero.\n$$ \\bar{c}_3 = 0 \\implies c_3 - \\frac{21}{2} = 0 $$\n$$ c_3^\\star = \\frac{21}{2} $$\nFor any $c_3  21/2$, the reduced cost $\\bar{c}_3$ will be positive, signifying that the optimality condition is violated and $x_3$ is a candidate to enter the basis to increase the objective function value. Therefore, the threshold value is $21/2$.", "answer": "$$\\boxed{\\frac{21}{2}}$$", "id": "3178669"}, {"introduction": "To see these principles in a different light, this final practice [@problem_id:3178654] applies sensitivity analysis to a network optimization problem. We will analyze a shortest path problem where arc costs are linear functions of a parameter, $\\theta$. This exercise showcases the versatility of parametric analysis, as you will map out the complete sequence of optimal paths and the critical values of $\\theta$ at which the shortest path changes.", "problem": "Consider a directed acyclic network with nodes $s$, $a$, $b$, $c$, and $t$. Each arc $e$ has a parametric cost of the form $c_{e}(\\theta) = c_{e} + \\theta d_{e}$, where $\\theta \\in \\mathbb{R}$ is a parameter, $c_{e} \\in \\mathbb{R}$ is the base cost, and $d_{e} \\in \\mathbb{R}$ is the sensitivity coefficient. The available arcs and their coefficients are:\n- From $s$ to $a$: $c_{sa} = 4$, $d_{sa} = 1$.\n- From $s$ to $b$: $c_{sb} = 2$, $d_{sb} = 3$.\n- From $s$ to $c$: $c_{sc} = 10$, $d_{sc} = -2$.\n- From $a$ to $c$: $c_{ac} = 3$, $d_{ac} = 2$.\n- From $a$ to $t$: $c_{at} = 9$, $d_{at} = -1$.\n- From $b$ to $c$: $c_{bc} = 2$, $d_{bc} = 2$.\n- From $b$ to $t$: $c_{bt} = 7$, $d_{bt} = 0$.\n- From $c$ to $t$: $c_{ct} = 1$, $d_{ct} = 4$.\n\nA path cost is the sum of its arc costs. Using the foundational definition that the shortest path minimizes the total path cost, construct the parametric shortest path problem by explicitly writing the path-cost functions for all $s$–$t$ paths as functions of $\\theta$. Then determine the sequence of optimal paths as $\\theta$ varies over $\\mathbb{R}$ by identifying the critical values of $\\theta$ at which the optimal path changes. Report, as your final answer, the ordered set of these critical parameter values as a single row matrix using exact fractions. No rounding is required.", "solution": "### Step 1: Enumerate Paths and Formulate Cost Functions\nThe problem requires finding the sequence of shortest paths from node $s$ to node $t$ as the parameter $\\theta$ varies. First, we enumerate all simple paths from $s$ to $t$ and formulate their total cost functions, $f_i(\\theta) = C_i + \\theta D_i$.\n\n1.  Path $P_1: s \\rightarrow a \\rightarrow c \\rightarrow t$\n    $C_1 = c_{sa} + c_{ac} + c_{ct} = 4 + 3 + 1 = 8$\n    $D_1 = d_{sa} + d_{ac} + d_{ct} = 1 + 2 + 4 = 7$\n    $f_1(\\theta) = 8 + 7\\theta$\n\n2.  Path $P_2: s \\rightarrow a \\rightarrow t$\n    $C_2 = c_{sa} + c_{at} = 4 + 9 = 13$\n    $D_2 = d_{sa} + d_{at} = 1 + (-1) = 0$\n    $f_2(\\theta) = 13$\n\n3.  Path $P_3: s \\rightarrow b \\rightarrow c \\rightarrow t$\n    $C_3 = c_{sb} + c_{bc} + c_{ct} = 2 + 2 + 1 = 5$\n    $D_3 = d_{sb} + d_{bc} + d_{ct} = 3 + 2 + 4 = 9$\n    $f_3(\\theta) = 5 + 9\\theta$\n\n4.  Path $P_4: s \\rightarrow b \\rightarrow t$\n    $C_4 = c_{sb} + c_{bt} = 2 + 7 = 9$\n    $D_4 = d_{sb} + d_{bt} = 3 + 0 = 3$\n    $f_4(\\theta) = 9 + 3\\theta$\n\n5.  Path $P_5: s \\rightarrow c \\rightarrow t$\n    $C_5 = c_{sc} + c_{ct} = 10 + 1 = 11$\n    $D_5 = d_{sc} + d_{ct} = -2 + 4 = 2$\n    $f_5(\\theta) = 11 + 2\\theta$\n\n### Step 2: Find the Lower Envelope and Critical Values\nThe shortest path cost is $f^*(\\theta) = \\min \\{f_1(\\theta), f_2(\\theta), f_3(\\theta), f_4(\\theta), f_5(\\theta)\\}$. We need to find the breakpoints of this piecewise-linear, concave function.\n\n-   For $\\theta \\to -\\infty$, the cost is dominated by the term with the largest positive slope $D_i$. The minimum cost will be achieved by the path with the largest $D_i$, which is $D_3=9$. So, path $P_3$ is optimal for sufficiently small $\\theta$.\n-   For $\\theta \\to +\\infty$, the cost is dominated by the term with the smallest slope $D_i$. The minimum cost will be achieved by the path with the smallest $D_i$, which is $D_2=0$. So, path $P_2$ is optimal for sufficiently large $\\theta$.\n\nWe find the transitions by calculating intersection points. Starting with $P_3$ as optimal, we find where it intersects other path cost functions:\n- $f_3(\\theta) = f_1(\\theta) \\implies 5 + 9\\theta = 8 + 7\\theta \\implies 2\\theta = 3 \\implies \\theta = \\frac{3}{2}$\n- $f_3(\\theta) = f_2(\\theta) \\implies 5 + 9\\theta = 13 \\implies 9\\theta = 8 \\implies \\theta = \\frac{8}{9}$\n- $f_3(\\theta) = f_4(\\theta) \\implies 5 + 9\\theta = 9 + 3\\theta \\implies 6\\theta = 4 \\implies \\theta = \\frac{2}{3}$\n- $f_3(\\theta) = f_5(\\theta) \\implies 5 + 9\\theta = 11 + 2\\theta \\implies 7\\theta = 6 \\implies \\theta = \\frac{6}{7}$\n\nThe first transition from $P_3$ occurs at the smallest of these $\\theta$ values, which is $\\theta = \\frac{2}{3}$. For $\\theta  \\frac{2}{3}$, $P_3$ remains the optimal path. At $\\theta=\\frac{2}{3}$, the optimal path changes from $P_3$ to $P_4$. Thus, the first critical value is $\\theta_1 = \\frac{2}{3}$.\n\nFor $\\theta > \\frac{2}{3}$, path $P_4$ is the new candidate for the optimal path. We find its intersections with other paths:\n- $f_4(\\theta) = f_2(\\theta) \\implies 9 + 3\\theta = 13 \\implies 3\\theta = 4 \\implies \\theta = \\frac{4}{3}$.\n- $f_4(\\theta) = f_5(\\theta) \\implies 9 + 3\\theta = 11 + 2\\theta \\implies \\theta = 2$.\n(Intersections with $f_1$ and $f_3$ occur at $\\theta  \\frac{2}{3}$ and are not relevant for the *next* transition).\n\nThe next transition from $P_4$ occurs at the smaller of these new values, which is $\\theta = \\frac{4}{3}$. To confirm $P_4$ is optimal in the interval $[\\frac{2}{3}, \\frac{4}{3}]$, we note that for any $\\theta$ in this range, $f_4(\\theta)$ is less than or equal to $f_3(\\theta)$, $f_2(\\theta)$, and all other path costs. At $\\theta=\\frac{4}{3}$, the optimal path changes from $P_4$ to $P_2$. Thus, the second critical value is $\\theta_2 = \\frac{4}{3}$.\n\nFor $\\theta > \\frac{4}{3}$, path $P_2$ is the new optimal path. Since $P_2$ has the smallest slope ($D_2=0$), its cost function will not be intersected by any other path cost function for any $\\theta > \\frac{4}{3}$. Therefore, $P_2$ remains optimal for all $\\theta \\ge \\frac{4}{3}$.\n\n### Conclusion\nThe sequence of optimal paths is:\n- $P_3$ for $\\theta \\in (-\\infty, \\frac{2}{3}]$\n- $P_4$ for $\\theta \\in [\\frac{2}{3}, \\frac{4}{3}]$\n- $P_2$ for $\\theta \\in [\\frac{4}{3}, \\infty)$\n\nThe critical values of $\\theta$ where the optimal path changes are $\\frac{2}{3}$ and $\\frac{4}{3}$. The ordered set of these values is $\\{\\frac{2}{3}, \\frac{4}{3}\\}$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{2}{3}  \\frac{4}{3}\n\\end{pmatrix}\n}\n$$", "id": "3178654"}]}