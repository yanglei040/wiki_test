{"hands_on_practices": [{"introduction": "Duality theory is more than an abstract concept; it is a powerful technique for transforming optimization problems into more tractable forms. This first exercise guides you through the fundamental process of deriving a dual problem from first principles [@problem_id:3139654]. Starting with a common non-smooth problem—minimizing the maximum of several functions—you will use the epigraph transformation and Lagrangian duality to construct its elegant dual, revealing hidden geometric insights about the original problem's structure.", "problem": "Consider the family of affine functions $\\{a_{i}^{\\top} x - b_{i}\\}_{i=1}^{m}$ with $a_{i} \\in \\mathbb{R}^{n}$ and $b_{i} \\in \\mathbb{R}$, and the convex optimization problem\n$$\\min_{x \\in \\mathbb{R}^{n}} \\ \\max_{i \\in \\{1,\\dots,m\\}} \\ \\left(a_{i}^{\\top} x - b_{i}\\right).$$\nUsing the epigraph transformation, this can be written as\n$$\\min_{x \\in \\mathbb{R}^{n}, \\ t \\in \\mathbb{R}} \\ t \\quad \\text{subject to} \\quad a_{i}^{\\top} x - b_{i} \\le t \\ \\text{ for all } i \\in \\{1,\\dots,m\\}.$$\nStarting from the fundamental definition of the Lagrangian and the Lagrangian dual function for convex programs, derive the dual problem of this epigraph formulation. Interpret the dual feasibility conditions in terms of convex combinations of the vectors $\\{a_{i}\\}_{i=1}^{m}$.\n\nThen, for the concrete instance in $\\mathbb{R}^{2}$ with $m=3$ specified by\n$$a_{1}=\\begin{pmatrix}1\\\\0\\end{pmatrix}, \\quad a_{2}=\\begin{pmatrix}0\\\\1\\end{pmatrix}, \\quad a_{3}=\\begin{pmatrix}-1\\\\-1\\end{pmatrix}, \\quad b_{1}=1, \\quad b_{2}=2, \\quad b_{3}=3,$$\ncompute the optimal objective value $t^{\\star}$ of the original problem. Express the final answer as the exact value of $t^{\\star}$ (no rounding is required).", "solution": "The primal problem in epigraph form is a linear program with variables $x \\in \\mathbb{R}^n$ and $t \\in \\mathbb{R}$:\n$$\n\\begin{array}{ll}\n\\min_{x, t}  t \\\\\n\\text{subject to}  a_i^\\top x - t - b_i \\le 0, \\quad i=1, \\dots, m\n\\end{array}\n$$\nThe Lagrangian $L(x, t, \\lambda)$ is formed by introducing Lagrange multipliers $\\lambda_i \\ge 0$ for each of the $m$ inequality constraints:\n$$ L(x, t, \\lambda) = t + \\sum_{i=1}^m \\lambda_i (a_i^\\top x - t - b_i) $$\nwhere $\\lambda = (\\lambda_1, \\dots, \\lambda_m) \\in \\mathbb{R}^m$. To find the Lagrange dual function $g(\\lambda) = \\inf_{x,t} L(x, t, \\lambda)$, we rearrange the Lagrangian to group the primal variables $x$ and $t$:\n$$ L(x, t, \\lambda) = \\left( 1 - \\sum_{i=1}^m \\lambda_i \\right) t + \\left( \\sum_{i=1}^m \\lambda_i a_i^\\top \\right) x - \\sum_{i=1}^m \\lambda_i b_i $$\nThis expression is an affine function of $x$ and $t$. For its infimum to be bounded (i.e., not $-\\infty$), the coefficients of $x$ and $t$ must be zero:\n1.  $\\sum_{i=1}^m \\lambda_i a_i = 0$\n2.  $1 - \\sum_{i=1}^m \\lambda_i = 0 \\implies \\sum_{i=1}^m \\lambda_i = 1$\n\nIf these conditions hold, the Lagrangian is constant with respect to $x$ and $t$, and its value is $-\\sum_{i=1}^m \\lambda_i b_i$. Otherwise, its infimum is $-\\infty$.\nThe dual function is therefore:\n$$\ng(\\lambda) = \\begin{cases}\n- \\sum_{i=1}^m \\lambda_i b_i  \\text{if } \\sum_{i=1}^m \\lambda_i a_i = 0 \\text{ and } \\sum_{i=1}^m \\lambda_i = 1 \\\\\n-\\infty  \\text{otherwise}\n\\end{cases}\n$$\nThe dual problem is to maximize $g(\\lambda)$ subject to $\\lambda_i \\ge 0$. This is equivalent to:\n$$\n\\begin{array}{ll}\n\\max_{\\lambda \\in \\mathbb{R}^m}  -b^\\top \\lambda \\\\\n\\text{subject to}  \\sum_{i=1}^m \\lambda_i a_i = 0 \\\\\n \\sum_{i=1}^m \\lambda_i = 1 \\\\\n \\lambda_i \\ge 0, \\quad i=1, \\dots, m\n\\end{array}\n$$\nThe dual feasibility conditions $\\sum_{i=1}^m \\lambda_i = 1$ and $\\lambda_i \\ge 0$ mean that the vector $\\lambda$ defines a convex combination. The condition $\\sum_{i=1}^m \\lambda_i a_i = 0$ therefore means that the origin of $\\mathbb{R}^n$ must be expressible as a convex combination of the vectors $\\{a_i\\}_{i=1}^m$. Geometrically, the origin must lie within the convex hull of the points $\\{a_1, \\dots, a_m\\}$.\n\nFor the concrete instance, we solve the dual problem. The dual feasibility constraints are:\n$$ \\lambda_1 \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} + \\lambda_2 \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} + \\lambda_3 \\begin{pmatrix} -1 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} $$\n$$ \\lambda_1 + \\lambda_2 + \\lambda_3 = 1 $$\n$$ \\lambda_1, \\lambda_2, \\lambda_3 \\ge 0 $$\nThe vector equation gives a system of two linear equations:\n1. $\\lambda_1 - \\lambda_3 = 0 \\implies \\lambda_1 = \\lambda_3$\n2. $\\lambda_2 - \\lambda_3 = 0 \\implies \\lambda_2 = \\lambda_3$\nSo, $\\lambda_1 = \\lambda_2 = \\lambda_3$. Substituting this into the sum constraint:\n$$ \\lambda_1 + \\lambda_1 + \\lambda_1 = 1 \\implies 3\\lambda_1 = 1 \\implies \\lambda_1 = 1/3 $$\nThe unique feasible dual solution is $\\lambda^\\star = (1/3, 1/3, 1/3)$. Since the primal problem is a feasible linear program, strong duality holds, and the optimal primal objective value $t^\\star$ equals the optimal dual objective value $d^\\star$. We compute $d^\\star$ using the dual objective function:\n$$ d^\\star = - \\sum_{i=1}^3 b_i \\lambda_i^\\star = - \\left( 1 \\cdot \\frac{1}{3} + 2 \\cdot \\frac{1}{3} + 3 \\cdot \\frac{1}{3} \\right) = - \\frac{1}{3}(1+2+3) = - \\frac{6}{3} = -2 $$\nThus, the optimal objective value is $t^\\star = -2$.", "answer": "$$\\boxed{-2}$$", "id": "3139654"}, {"introduction": "Once we establish the primal and dual problems, their true power emerges from the relationship between their solutions. This exercise focuses on complementary slackness, a set of conditions that serve as a crucial \"optimality certificate\" linking a feasible primal solution with a feasible dual solution [@problem_id:3139561]. By working through a carefully constructed linear program with multiple optimal solutions, you will gain a hands-on understanding of how this fundamental principle holds, providing a robust check for optimality that transcends the uniqueness of the solutions themselves.", "problem": "Consider the following pair of Linear Programming (LP) problems in primal and dual form, respectively. The primal is\n$$\\min\\ c^{\\top}x \\quad \\text{subject to} \\quad Ax \\ge b,\\ x \\ge 0,$$\nand the dual is\n$$\\max\\ b^{\\top}y \\quad \\text{subject to} \\quad A^{\\top}y \\le c,\\ y \\ge 0,$$\nwhere\n$$A=\\begin{pmatrix}1  1 \\\\ 1  1\\end{pmatrix},\\quad b=\\begin{pmatrix}1 \\\\ 1\\end{pmatrix},\\quad c=\\begin{pmatrix}1 \\\\ 1\\end{pmatrix}.$$\nThis data intentionally introduces ties that produce multiple optimal solutions in both the primal and the dual. Using only core definitions of duality and complementary slackness (no shortcut formulas), determine the common optimal objective value shared by the primal and the dual. Express your final answer as a single real number. No rounding is required.", "solution": "Let $x = \\begin{pmatrix}x_1 \\\\ x_2\\end{pmatrix}$ and $y = \\begin{pmatrix}y_1 \\\\ y_2\\end{pmatrix}$. Substituting the given matrices and vectors, the primal problem is:\n$$ \\min\\ z_P = x_1 + x_2 $$\nsubject to:\n$$ x_1 + x_2 \\ge 1 $$\n$$ x_1 \\ge 0, \\quad x_2 \\ge 0 $$\nThe dual problem is:\n$$ \\max\\ z_D = y_1 + y_2 $$\nsubject to:\n$$ y_1 + y_2 \\le 1 $$\n$$ y_1 \\ge 0, \\quad y_2 \\ge 0 $$\nA fundamental result in LP duality states that a pair of feasible solutions, $x^*$ for the primal and $y^*$ for the dual, are optimal if and only if they satisfy the complementary slackness conditions. These conditions are:\n1.  $y^{*\\top}(Ax^* - b) = 0$\n2.  $x^{*\\top}(c - A^{\\top}y^*) = 0$\n\nWe can find the common optimal value by proposing a candidate pair of solutions $(x^*, y^*)$, verifying their feasibility, and then checking if they satisfy complementary slackness. If they do, they are optimal, and their objective values must be equal.\n\nLet's propose a candidate primal solution $x^* = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$ and a candidate dual solution $y^* = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$.\n\nFirst, we verify the feasibility of $x^*$:\n- Non-negativity: $x_1^* = 1 \\ge 0$ and $x_2^* = 0 \\ge 0$. This is satisfied.\n- Main constraints: $x_1^* + x_2^* = 1+0=1 \\ge 1$. This is satisfied.\nThus, $x^*$ is a feasible solution for the primal problem.\n\nNext, we verify the feasibility of $y^*$:\n- Non-negativity: $y_1^* = 1 \\ge 0$ and $y_2^* = 0 \\ge 0$. This is satisfied.\n- Main constraints: $y_1^* + y_2^* = 1+0=1 \\le 1$. This is satisfied.\nThus, $y^*$ is a feasible solution for the dual problem.\n\nNow, we check the complementary slackness conditions for the feasible pair $(x^*, y^*)$.\n\n**Condition 1:** $y^{*\\top}(Ax^* - b) = 0$.\nFirst, calculate the primal slack vector $s = Ax^* - b$:\n$$ s = \\begin{pmatrix}1  1 \\\\ 1  1\\end{pmatrix} \\begin{pmatrix}1 \\\\ 0\\end{pmatrix} - \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} - \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix} $$\nThen, compute the dot product:\n$$ y^{*\\top}s = \\begin{pmatrix}1  0\\end{pmatrix} \\begin{pmatrix}0 \\\\ 0\\end{pmatrix} = 1 \\cdot 0 + 0 \\cdot 0 = 0 $$\nThe first condition is satisfied.\n\n**Condition 2:** $x^{*\\top}(c - A^{\\top}y^*) = 0$.\nFirst, calculate the dual slack vector $t = c - A^{\\top}y^*$:\n$$ t = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} - \\begin{pmatrix}1  1 \\\\ 1  1\\end{pmatrix} \\begin{pmatrix}1 \\\\ 0\\end{pmatrix} = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} - \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix} $$\nThen, compute the dot product:\n$$ x^{*\\top}t = \\begin{pmatrix}1  0\\end{pmatrix} \\begin{pmatrix}0 \\\\ 0\\end{pmatrix} = 1 \\cdot 0 + 0 \\cdot 0 = 0 $$\nThe second condition is also satisfied.\n\nSince $x^*$ is primal feasible, $y^*$ is dual feasible, and both complementary slackness conditions hold, the pair $(x^*, y^*)$ is optimal for their respective problems. The strong duality theorem for linear programming states that their objective values must be equal. We can calculate this common optimal value from either problem.\n\nFor the primal problem, the optimal value is:\n$$ z_P^* = c^{\\top}x^* = \\begin{pmatrix}1  1\\end{pmatrix} \\begin{pmatrix}1 \\\\ 0\\end{pmatrix} = 1 \\cdot 1 + 1 \\cdot 0 = 1 $$\n\nFor the dual problem, the optimal value is:\n$$ z_D^* = b^{\\top}y^* = \\begin{pmatrix}1  1\\end{pmatrix} \\begin{pmatrix}1 \\\\ 0\\end{pmatrix} = 1 \\cdot 1 + 1 \\cdot 0 = 1 $$\n\nAs expected, the values are identical. This confirms that the common optimal objective value for the primal and dual problems is $1$.", "answer": "$$\\boxed{1}$$", "id": "3139561"}, {"introduction": "The connection between primal and dual problems extends beyond their optimal values to their very geometric structure. This practice explores a deeper aspect of this relationship: how the properties of one problem are reflected in its dual counterpart [@problem_id:3139608]. Using the more general framework of Fenchel duality, you will investigate a scenario where the primal problem has multiple solutions and discover how this corresponds to the strict convexity and unique solution of its dual, illustrating a beautiful symmetry in optimization theory.", "problem": "Consider the convex optimization problem on $\\mathbb{R}^{2}$ defined by the composite objective $f(x) + g(Ax)$, where $x = (x_{1}, x_{2})$, $A \\in \\mathbb{R}^{1 \\times 2}$, $f : \\mathbb{R}^{2} \\to \\mathbb{R} \\cup \\{+\\infty\\}$, and $g : \\mathbb{R} \\to \\mathbb{R}$. The components are specified as follows:\n- $f(x)$ is the indicator function of the axis-aligned square $[0,1]^{2}$, that is, $f(x) = 0$ if $x \\in [0,1]^{2}$ and $f(x) = +\\infty$ otherwise.\n- $g(y) = \\frac{1}{2}(y - a)^{2}$ with $a = \\frac{1}{2}$.\n- $A = [\\,1 \\ \\ 0\\,]$, so that $Ax = x_{1}$.\n\nUsing only the fundamental definitions of the Lagrangian, convex conjugates, and the Fenchel-Rockafellar duality construction, carry out the following tasks:\n1. Rigorously derive the Fenchel dual problem by introducing an auxiliary variable $y$ for the coupling $y = Ax$ and forming the Lagrangian. Express the dual objective explicitly in terms of the single dual variable $u \\in \\mathbb{R}$.\n2. Demonstrate that the primal problem has multiple optimal solutions by identifying a flat face in the feasible set along which the objective is minimized.\n3. Explain why the derived dual objective is strictly convex, and conclude the uniqueness of the dual optimizer.\n4. Compute the unique optimal dual variable $u^{\\star}$.\n\nAnswer specification:\n- Report only the numerical value of $u^{\\star}$.\n- No rounding is required.", "solution": "The primal problem is to find:\n$$ p^{\\star} = \\min_{x \\in \\mathbb{R}^{2}} \\{ f(x) + g(Ax) \\} $$\nSubstituting the given definitions, the problem is explicitly:\n$$ \\min_{x_1, x_2} \\left\\{ \\chi_{[0,1]^2}(x_1, x_2) + \\frac{1}{2}\\left(x_1 - \\frac{1}{2}\\right)^2 \\right\\} $$\nwhere $\\chi_S(x)$ is the indicator function of the set $S$. This is equivalent to minimizing $\\frac{1}{2}(x_1 - \\frac{1}{2})^2$ subject to the constraint $x = (x_1, x_2) \\in [0,1]^2$.\n\n**1. Derive the Fenchel Dual Problem**\nWe introduce an auxiliary variable $y \\in \\mathbb{R}$ and a constraint $y = Ax$. The problem becomes:\n$$ \\min_{x \\in \\mathbb{R}^{2}, y \\in \\mathbb{R}} \\{ f(x) + g(y) \\} \\quad \\text{subject to} \\quad Ax - y = 0 $$\nThe Fenchel-Rockafellar dual problem is to minimize $D(u) = f^{\\star}(-A^T u) + g^{\\star}(u)$ over the dual variable $u \\in \\mathbb{R}$. We compute the convex conjugates $f^{\\star}$ and $g^{\\star}$.\n\n- **Conjugate of $g$**: $g(y) = \\frac{1}{2}(y - \\frac{1}{2})^2$.\n$g^{\\star}(u) = \\sup_{y \\in \\mathbb{R}} \\left\\{ uy - \\frac{1}{2}\\left(y - \\frac{1}{2}\\right)^2 \\right\\}$. The maximum is found by setting the derivative with respect to $y$ to zero: $u - (y - \\frac{1}{2}) = 0 \\implies y = u + \\frac{1}{2}$. Substituting back gives $g^{\\star}(u) = u(u + \\frac{1}{2}) - \\frac{1}{2}u^2 = \\frac{1}{2}u^2 + \\frac{1}{2}u$.\n\n- **Conjugate of $f$**: $f(x) = \\chi_{[0,1]^2}(x)$. For a vector $v = (v_1, v_2) \\in \\mathbb{R}^2$:\n$f^{\\star}(v) = \\sup_{x \\in [0,1]^2} \\{ v^T x \\} = \\sup_{x_1 \\in [0,1], x_2 \\in [0,1]} \\{ v_1 x_1 + v_2 x_2 \\} = \\max(0, v_1) + \\max(0, v_2)$.\nWe need $f^{\\star}(-A^T u)$. Since $A = [\\,1 \\ \\ 0\\,]$, we have $-A^T u = \\begin{pmatrix} -u \\\\ 0 \\end{pmatrix}$.\nSo, $f^{\\star}(-A^T u) = f^{\\star}(-u, 0) = \\max(0, -u) + \\max(0, 0) = \\max(0, -u)$.\n\nThe dual objective function is the sum of these conjugates:\n$$ D(u) = \\max(0, -u) + \\frac{1}{2}u^2 + \\frac{1}{2}u $$\nThe dual problem is to minimize this $D(u)$ over $u \\in \\mathbb{R}$.\n\n**2. Multiple Primal Optimal Solutions**\nThe primal problem is $\\min_{x_1 \\in [0,1], x_2 \\in [0,1]} \\frac{1}{2}(x_1 - \\frac{1}{2})^2$.\nThe objective function depends only on $x_1$ and is minimized when $x_1$ is as close as possible to $\\frac{1}{2}$. Since $\\frac{1}{2} \\in [0,1]$, the minimum is achieved at $x_1^{\\star} = \\frac{1}{2}$, giving an objective value of $p^{\\star} = 0$. The objective function is independent of $x_2$. Therefore, any point $x^{\\star} = (\\frac{1}{2}, x_2)$ is an optimal solution for any choice of $x_2 \\in [0,1]$. The set of primal optimizers is the line segment $\\{(\\frac{1}{2}, x_2) \\mid x_2 \\in [0,1]\\}$, which is infinite.\n\n**3. Uniqueness of the Dual Optimizer**\nThe dual objective function $D(u)$ is the sum of a convex function, $D_1(u) = \\max(0, -u)$, and a strictly convex function, $D_2(u) = \\frac{1}{2}u^2 + \\frac{1}{2}u$ (since $D_2''(u) = 1 > 0$). The sum of a convex function and a strictly convex function is strictly convex. A strictly convex function has at most one minimizer. Since $D(u) \\to +\\infty$ as $|u| \\to \\infty$, a unique minimizer must exist.\n\n**4. Compute the Unique Optimal Dual Variable $u^{\\star}$**\nTo find the minimum of the non-differentiable convex function $D(u)$, we use subgradient optimality: $u^{\\star}$ is an optimizer if and only if $0 \\in \\partial D(u^{\\star})$.\nThe function $D(u)$ is piecewise differentiable:\n- For $u > 0$, $D(u) = \\frac{1}{2}u^2 + \\frac{1}{2}u$, so $D'(u) = u + \\frac{1}{2}$.\n- For $u  0$, $D(u) = -u + \\frac{1}{2}u^2 + \\frac{1}{2}u = \\frac{1}{2}u^2 - \\frac{1}{2}u$, so $D'(u) = u - \\frac{1}{2}$.\nThe function is not differentiable at $u=0$. We compute the subgradient at this point:\n- Right derivative: $D'_{+}(0) = \\lim_{u \\to 0^+} (u + \\frac{1}{2}) = \\frac{1}{2}$.\n- Left derivative: $D'_{-}(0) = \\lim_{u \\to 0^-} (u - \\frac{1}{2}) = -\\frac{1}{2}$.\nThe subgradient at $u=0$ is the interval $\\partial D(0) = [-\\frac{1}{2}, \\frac{1}{2}]$.\nThe optimality condition $0 \\in \\partial D(u^{\\star})$ is satisfied for $u^{\\star} = 0$, since $0 \\in [-\\frac{1}{2}, \\frac{1}{2}]$.\nThus, the unique optimal dual variable is $u^{\\star} = 0$.", "answer": "$$\\boxed{0}$$", "id": "3139608"}]}