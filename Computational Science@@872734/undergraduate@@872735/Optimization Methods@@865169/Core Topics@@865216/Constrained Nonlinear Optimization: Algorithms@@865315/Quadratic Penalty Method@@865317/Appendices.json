{"hands_on_practices": [{"introduction": "To build a solid foundation, our first practice involves an analytical derivation rather than numerical computation. By deriving the explicit path of the minimizer for a linearly constrained quadratic program, you will gain a precise understanding of how the penalized solution behaves as the penalty parameter $\\rho$ grows. This exercise [@problem_id:495741] reveals the underlying mechanics of the method in a clean, theoretical setting, forming the basis for understanding the numerical challenges that follow.", "problem": "Consider the general linearly constrained quadratic program (LCQP):\n$$\n\\begin{aligned}\n\\text{minimize} \\quad & f(\\mathbf{x}) = \\frac{1}{2}\\mathbf{x}^T Q \\mathbf{x} + \\mathbf{c}^T \\mathbf{x} \\\\\n\\text{subject to} \\quad & A\\mathbf{x} = \\mathbf{b}\n\\end{aligned}\n$$\nHere, $\\mathbf{x} \\in \\mathbb{R}^n$ is the optimization variable. The problem data consists of a symmetric positive definite matrix $Q \\in \\mathbb{R}^{n \\times n}$, a vector $\\mathbf{c} \\in \\mathbb{R}^n$, a matrix $A \\in \\mathbb{R}^{m \\times n}$ with full row rank ($m < n$), and a vector $\\mathbf{b} \\in \\mathbb{R}^m$.\n\nTo solve this constrained problem, we employ the quadratic penalty method. This method transforms the problem into a sequence of unconstrained optimization problems by adding a penalty term to the objective function. The resulting unconstrained objective function, known as the augmented objective function, is given by:\n$$\nL_\\rho(\\mathbf{x}) = f(\\mathbf{x}) + \\frac{\\rho}{2} \\|A\\mathbf{x} - \\mathbf{b}\\|_2^2\n$$\nwhere $\\rho > 0$ is a scalar penalty parameter. For any given $\\rho > 0$, the function $L_\\rho(\\mathbf{x})$ has a unique minimizer, which we denote by $\\mathbf{x}^*(\\rho)$. The path traced by this minimizer as $\\rho$ varies is called the trajectory of the minimizer.\n\nDerive the explicit analytical expression for this trajectory, $\\mathbf{x}^*(\\rho)$, in terms of the penalty parameter $\\rho$ and the problem data matrices and vectors $(Q, \\mathbf{c}, A, \\mathbf{b})$.", "solution": "The quadratic penalty method aims to find the minimum of the augmented objective function $L_\\rho(\\mathbf{x})$ for a sequence of increasing penalty parameters $\\rho$. The unique minimizer for a given $\\rho$ is denoted by $\\mathbf{x}^*(\\rho)$.\n\nThe augmented objective function is:\n$$\nL_\\rho(\\mathbf{x}) = \\frac{1}{2}\\mathbf{x}^T Q \\mathbf{x} + \\mathbf{c}^T \\mathbf{x} + \\frac{\\rho}{2} \\|A\\mathbf{x} - \\mathbf{b}\\|_2^2\n$$\nWe can expand the penalty term, which is the squared Euclidean norm:\n$$\n\\|A\\mathbf{x} - \\mathbf{b}\\|_2^2 = (A\\mathbf{x} - \\mathbf{b})^T(A\\mathbf{x} - \\mathbf{b}) = (\\mathbf{x}^T A^T - \\mathbf{b}^T)(A\\mathbf{x} - \\mathbf{b}) = \\mathbf{x}^T A^T A \\mathbf{x} - \\mathbf{x}^T A^T \\mathbf{b} - \\mathbf{b}^T A \\mathbf{x} + \\mathbf{b}^T \\mathbf{b}\n$$\nSince $\\mathbf{b}^T A \\mathbf{x}$ is a scalar, it equals its transpose $(\\mathbf{b}^T A \\mathbf{x})^T = \\mathbf{x}^T A^T \\mathbf{b}$. Thus, the penalty term becomes:\n$$\n\\|A\\mathbf{x} - \\mathbf{b}\\|_2^2 = \\mathbf{x}^T A^T A \\mathbf{x} - 2\\mathbf{b}^T A \\mathbf{x} + \\mathbf{b}^T \\mathbf{b}\n$$\nSubstituting this back into $L_\\rho(\\mathbf{x})$ gives:\n$$\nL_\\rho(\\mathbf{x}) = \\frac{1}{2}\\mathbf{x}^T Q \\mathbf{x} + \\mathbf{c}^T \\mathbf{x} + \\frac{\\rho}{2}(\\mathbf{x}^T A^T A \\mathbf{x} - 2\\mathbf{b}^T A \\mathbf{x} + \\mathbf{b}^T \\mathbf{b})\n$$\nTo find the minimizer $\\mathbf{x}^*(\\rho)$, we must find the point where the gradient of $L_\\rho(\\mathbf{x})$ with respect to $\\mathbf{x}$ is zero. We compute the gradient $\\nabla_{\\mathbf{x}} L_\\rho(\\mathbf{x})$:\n$$\n\\nabla_{\\mathbf{x}} L_\\rho(\\mathbf{x}) = \\nabla_{\\mathbf{x}}\\left(\\frac{1}{2}\\mathbf{x}^T Q \\mathbf{x}\\right) + \\nabla_{\\mathbf{x}}(\\mathbf{c}^T \\mathbf{x}) + \\frac{\\rho}{2} \\nabla_{\\mathbf{x}}(\\mathbf{x}^T A^T A \\mathbf{x} - 2\\mathbf{b}^T A \\mathbf{x} + \\mathbf{b}^T \\mathbf{b})\n$$\nUsing standard rules of matrix calculus (for symmetric $Q$ and $A^T A$):\n- $\\nabla_{\\mathbf{x}}(\\frac{1}{2}\\mathbf{x}^T M \\mathbf{x}) = M\\mathbf{x}$ for symmetric $M$.\n- $\\nabla_{\\mathbf{x}}(\\mathbf{v}^T \\mathbf{x}) = \\mathbf{v}$.\n\nThe gradient is:\n$$\n\\nabla_{\\mathbf{x}} L_\\rho(\\mathbf{x}) = Q\\mathbf{x} + \\mathbf{c} + \\frac{\\rho}{2}(2A^T A \\mathbf{x} - 2A^T\\mathbf{b})\n$$\n$$\n\\nabla_{\\mathbf{x}} L_\\rho(\\mathbf{x}) = Q\\mathbf{x} + \\mathbf{c} + \\rho(A^T A \\mathbf{x} - A^T\\mathbf{b})\n$$\nSetting the gradient to the zero vector to find the stationary point $\\mathbf{x}^*(\\rho)$:\n$$\nQ\\mathbf{x}^*(\\rho) + \\mathbf{c} + \\rho A^T A \\mathbf{x}^*(\\rho) - \\rho A^T\\mathbf{b} = \\mathbf{0}\n$$\nNow, we solve for $\\mathbf{x}^*(\\rho)$. Group the terms containing $\\mathbf{x}^*(\\rho)$:\n$$\n(Q + \\rho A^T A)\\mathbf{x}^*(\\rho) = \\rho A^T\\mathbf{b} - \\mathbf{c}\n$$\nTo confirm this stationary point is a minimum, we examine the Hessian matrix of $L_\\rho(\\mathbf{x})$, which is $\\nabla^2_{\\mathbf{x}} L_\\rho(\\mathbf{x})$:\n$$\n\\nabla^2_{\\mathbf{x}} L_\\rho(\\mathbf{x}) = Q + \\rho A^T A\n$$\nThe problem states that $Q$ is symmetric positive definite ($Q \\succ 0$). The matrix $A^T A$ is always positive semidefinite for any matrix $A$. Since $\\rho > 0$, the Hessian $Q + \\rho A^T A$ is the sum of a positive definite matrix and a positive semidefinite matrix, which results in a positive definite matrix. Therefore, $L_\\rho(\\mathbf{x})$ is a strictly convex function, and the stationary point is its unique global minimum.\n\nTo find the expression for $\\mathbf{x}^*(\\rho)$, we can invert the matrix $(Q + \\rho A^T A)$:\n$$\n\\mathbf{x}^*(\\rho) = (Q + \\rho A^T A)^{-1} (\\rho A^T\\mathbf{b} - \\mathbf{c})\n$$\nThis is the explicit expression for the trajectory of the minimizer as a function of $\\rho$.", "answer": "$$\n\\boxed{(Q + \\rho A^T A)^{-1} (\\rho A^T\\mathbf{b} - \\mathbf{c})}\n$$", "id": "495741"}, {"introduction": "Having seen the theoretical path to the solution, we now confront the primary numerical challenge of the quadratic penalty method. While theory dictates that we must let $\\rho \\to \\infty$ to enforce constraints perfectly, this coding simulation [@problem_id:3169152] demonstrates why this is computationally hazardous. You will observe firsthand how increasing $\\rho$ leads to an ill-conditioned Hessian matrix, making the unconstrained subproblems increasingly difficult and unstable to solve using standard methods like Newton's method.", "problem": "Consider the unconstrained reformulation of an equality-constrained problem via the quadratic penalty method in finite-dimensional Euclidean space. Let $\\mathbf{x} \\in \\mathbb{R}^n$, a twice continuously differentiable objective $f:\\mathbb{R}^n \\to \\mathbb{R}$, and a twice continuously differentiable constraint mapping $c:\\mathbb{R}^n \\to \\mathbb{R}^m$. Define the quadratic penalty objective $\\Phi(\\mathbf{x};\\rho) = f(\\mathbf{x}) + \\tfrac{\\rho}{2}\\lVert c(\\mathbf{x})\\rVert_2^2$ with penalty parameter $\\rho > 0$. Newton's method applied to $\\Phi(\\mathbf{x};\\rho)$ seeks a step $\\mathbf{p}$ at a base point $\\mathbf{x}$ by solving a linear system derived from the second-order Taylor expansion. The conditioning of the Hessian affects numerical stability, and the step length affects progress per iteration.\n\nStarting from fundamental definitions of the gradient $\\nabla$, Hessian $\\nabla^2$, the chain rule, and the Newton step determined by solving the system with the Hessian of $\\Phi(\\mathbf{x};\\rho)$ and gradient of $\\Phi(\\mathbf{x};\\rho)$, derive expressions needed to compute:\n1. The Newton step $\\mathbf{p}$ at a fixed base point $\\mathbf{x}$ for a given $\\rho$.\n2. The Euclidean norm $\\lVert \\mathbf{p} \\rVert_2$ of that step.\n3. The condition number of the Hessian of $\\Phi(\\mathbf{x};\\rho)$, defined as the ratio of its largest singular value to its smallest singular value, using the Singular Value Decomposition (SVD). If the smallest singular value is zero, the condition number is defined to be $+\\infty$.\n\nThen, implement a simulation that examines how gradually increasing the penalty parameter affects Hessian conditioning and Newton step sizes for several test cases. Use the update rule $\\rho_{k+1} = 10 \\rho_k$ with initial $\\rho_0 = 10^{-2}$ and simulate for $K=6$ values $\\{\\rho_0,\\rho_1,\\dots,\\rho_5\\}$.\n\nSimulation protocol:\n- For each test case, fix a base point $\\mathbf{x}_0$ and compute the Newton step $\\mathbf{p}_k$ at $\\mathbf{x}_0$ for each $\\rho_k$ without updating $\\mathbf{x}_0$ between different $\\rho_k$ values. This isolates the effect of $\\rho$ on Hessian conditioning and step size.\n- For each $\\rho_k$, compute the Hessian condition number of $\\nabla^2 \\Phi(\\mathbf{x}_0;\\rho_k)$ via SVD and the Euclidean step norm $\\lVert \\mathbf{p}_k \\rVert_2$ obtained by solving the Newton system. If the Hessian is singular or ill-conditioned, use a pseudoinverse to compute a minimum-norm step.\n\nTest suite (all in $\\mathbb{R}^2$):\n- Case A (symmetric positive definite, linear constraint): $f(\\mathbf{x}) = \\tfrac{1}{2}\\mathbf{x}^\\top Q \\mathbf{x}$ with $Q = \\begin{bmatrix}1 & 0 \\\\ 0 & 2\\end{bmatrix}$; $c(\\mathbf{x}) = [x_1 + x_2 - 1]$; base point $\\mathbf{x}_0 = [0,0]^\\top$.\n- Case B (nonlinear constraint causing potential indefiniteness): $f(\\mathbf{x}) = \\tfrac{1}{2}\\mathbf{x}^\\top Q \\mathbf{x}$ with $Q = \\begin{bmatrix}2 & 0 \\\\ 0 & 1\\end{bmatrix}$; $c(\\mathbf{x}) = [x_1^2 + x_2 - 1]$; base point $\\mathbf{x}_0 = [0.5,-0.2]^\\top$.\n- Case C (ill-conditioned objective, linear constraint improves conditioning): $f(\\mathbf{x}) = \\tfrac{1}{2}\\mathbf{x}^\\top Q \\mathbf{x}$ with $Q = \\begin{bmatrix}10^{-3} & 0 \\\\ 0 & 1\\end{bmatrix}$; $c(\\mathbf{x}) = [x_1 - 0.5]$; base point $\\mathbf{x}_0 = [1.0,1.0]^\\top$.\n\nScientific bases to use:\n- Newton's method definition for twice differentiable objectives: the step $\\mathbf{p}$ solves $\\nabla^2 \\Phi(\\mathbf{x};\\rho)\\,\\mathbf{p} = -\\nabla \\Phi(\\mathbf{x};\\rho)$.\n- Chain rule for gradients and Hessians of compositions and sums.\n- Definitions of Jacobian $J(\\mathbf{x})$ of $c(\\mathbf{x})$, and componentwise Hessians $\\nabla^2 c_i(\\mathbf{x})$.\n- Singular Value Decomposition for condition numbers of possibly indefinite symmetric matrices.\n\nAngle units are not involved. No physical units are involved.\n\nYour program must, for each test case, produce two lists of $K$ floating-point numbers:\n- The list of Hessian condition numbers for $\\rho_k$, $k=0,\\dots,5$.\n- The list of Newton step Euclidean norms for $\\rho_k$, $k=0,\\dots,5$.\n\nFinal output format:\nYour program should produce a single line of output containing a list of three test case summaries, each summary being a list of two lists as described above. Specifically, the output must be in the form\n$[\\,[\\,[\\text{cond}_{A,0},\\dots,\\text{cond}_{A,5}],\\,[\\lVert \\mathbf{p}_{A,0}\\rVert_2,\\dots,\\lVert \\mathbf{p}_{A,5}\\rVert_2]\\,],\\,[\\,[\\text{cond}_{B,0},\\dots,\\text{cond}_{B,5}],\\,[\\lVert \\mathbf{p}_{B,0}\\rVert_2,\\dots,\\lVert \\mathbf{p}_{B,5}\\rVert_2]\\,],\\,[\\,[\\text{cond}_{C,0},\\dots,\\text{cond}_{C,5}],\\,[\\lVert \\mathbf{p}_{C,0}\\rVert_2,\\dots,\\lVert \\mathbf{p}_{C,5}\\rVert_2]\\,]\\,]$.\n\nThe output values must be floating-point numbers. No additional text must be printed.", "solution": "The problem requires the derivation of key quantities for analyzing the quadratic penalty method and a numerical simulation of its behavior. The problem is self-contained, scientifically grounded in the principles of numerical optimization, and well-posed. We may therefore proceed with a solution.\n\nFirst, we derive the necessary expressions for the gradient and Hessian of the quadratic penalty objective function, the Newton step, and the Hessian condition number.\n\nThe quadratic penalty objective function is defined as:\n$$\n\\Phi(\\mathbf{x};\\rho) = f(\\mathbf{x}) + \\frac{\\rho}{2}\\lVert c(\\mathbf{x})\\rVert_2^2\n$$\nwhere $f:\\mathbb{R}^n \\to \\mathbb{R}$ is the objective function, $c:\\mathbb{R}^n \\to \\mathbb{R}^m$ is the constraint mapping, and $\\rho > 0$ is the penalty parameter. The squared norm of the constraint vector can be written as a sum of squares of its components, $c_i(\\mathbf{x})$:\n$$\n\\lVert c(\\mathbf{x})\\rVert_2^2 = c(\\mathbf{x})^\\top c(\\mathbf{x}) = \\sum_{i=1}^{m} c_i(\\mathbf{x})^2\n$$\n\n**1. Gradient of the Penalty Objective $\\nabla \\Phi(\\mathbf{x};\\rho)$**\n\nTo find the gradient of $\\Phi(\\mathbf{x};\\rho)$ with respect to $\\mathbf{x}$, we differentiate it term by term. The gradient of $f(\\mathbf{x})$ is simply $\\nabla f(\\mathbf{x})$. For the penalty term, we apply the chain rule. Let $g(\\mathbf{x}) = \\frac{\\rho}{2} \\sum_{i=1}^{m} c_i(\\mathbf{x})^2$. The $j$-th component of its gradient is:\n$$\n\\frac{\\partial g}{\\partial x_j} = \\frac{\\rho}{2} \\sum_{i=1}^{m} 2 c_i(\\mathbf{x}) \\frac{\\partial c_i(\\mathbf{x})}{\\partial x_j} = \\rho \\sum_{i=1}^{m} c_i(\\mathbf{x}) \\frac{\\partial c_i(\\mathbf{x})}{\\partial x_j}\n$$\nThis expression can be written in vector form. The Jacobian of the constraint mapping $c(\\mathbf{x})$ is an $m \\times n$ matrix $J(\\mathbf{x})$ with entries $(J(\\mathbf{x}))_{ij} = \\frac{\\partial c_i(\\mathbf{x})}{\\partial x_j}$. The expression $\\sum_{i=1}^{m} c_i(\\mathbf{x}) \\frac{\\partial c_i(\\mathbf{x})}{\\partial x_j}$ is the $j$-th component of the vector $J(\\mathbf{x})^\\top c(\\mathbf{x})$. Thus, the gradient of the penalty term is $\\rho J(\\mathbf{x})^\\top c(\\mathbf{x})$.\n\nCombining the terms, the full gradient of the penalty objective is:\n$$\n\\nabla \\Phi(\\mathbf{x};\\rho) = \\nabla f(\\mathbf{x}) + \\rho J(\\mathbf{x})^\\top c(\\mathbf{x})\n$$\n\n**2. Hessian of the Penalty Objective $\\nabla^2 \\Phi(\\mathbf{x};\\rho)$**\n\nTo find the Hessian, we differentiate the gradient expression with respect to $\\mathbf{x}^\\top$. The Hessian of $f(\\mathbf{x})$ is $\\nabla^2 f(\\mathbf{x})$. We need to compute the Hessian of the term $\\rho J(\\mathbf{x})^\\top c(\\mathbf{x})$.\nThis term can be viewed as the gradient of $\\frac{\\rho}{2}c(\\mathbf{x})^\\top c(\\mathbf{x})$. So we need the Hessian of $\\frac{\\rho}{2}c(\\mathbf{x})^\\top c(\\mathbf{x})$.\n$$\n\\nabla^2 \\left( \\frac{\\rho}{2} \\sum_{i=1}^m c_i(\\mathbf{x})^2 \\right) = \\frac{\\rho}{2} \\sum_{i=1}^m \\nabla^2(c_i(\\mathbf{x})^2)\n$$\nUsing the product rule for Hessians, $\\nabla^2(u^2) = \\nabla(2u\\nabla u) = 2(\\nabla u)(\\nabla u)^\\top + 2u\\nabla^2 u$, we get:\n$$\n\\nabla^2(c_i(\\mathbf{x})^2) = 2(\\nabla c_i(\\mathbf{x}))(\\nabla c_i(\\mathbf{x}))^\\top + 2c_i(\\mathbf{x})\\nabla^2 c_i(\\mathbf{x})\n$$\nwhere $\\nabla c_i(\\mathbf{x})$ is a column vector and $\\nabla^2 c_i(\\mathbf{x})$ is the Hessian of the $i$-th constraint function. Summing over all $i$:\n$$\n\\frac{\\rho}{2} \\sum_{i=1}^m \\left( 2(\\nabla c_i(\\mathbf{x}))(\\nabla c_i(\\mathbf{x}))^\\top + 2c_i(\\mathbf{x})\\nabla^2 c_i(\\mathbf{x}) \\right) = \\rho \\left( \\sum_{i=1}^m (\\nabla c_i(\\mathbf{x}))(\\nabla c_i(\\mathbf{x}))^\\top + \\sum_{i=1}^m c_i(\\mathbf{x})\\nabla^2 c_i(\\mathbf{x}) \\right)\n$$\nThe first summation, $\\sum_{i=1}^m (\\nabla c_i(\\mathbf{x}))(\\nabla c_i(\\mathbf{x}))^\\top$, is precisely the definition of the matrix product $J(\\mathbf{x})^\\top J(\\mathbf{x})$.\nTherefore, the Hessian of the penalty objective is:\n$$\n\\nabla^2 \\Phi(\\mathbf{x};\\rho) = \\nabla^2 f(\\mathbf{x}) + \\rho \\left( J(\\mathbf{x})^\\top J(\\mathbf{x}) + \\sum_{i=1}^m c_i(\\mathbf{x}) \\nabla^2 c_i(\\mathbf{x}) \\right)\n$$\n\n**3. Newton Step $\\mathbf{p}$ and its Norm**\n\nNewton's method for minimizing $\\Phi(\\mathbf{x};\\rho)$ involves finding a search direction (step) $\\mathbf{p}$ by solving the linear system derived from the second-order Taylor expansion around the current point $\\mathbf{x}$. This system is:\n$$\n\\nabla^2 \\Phi(\\mathbf{x};\\rho) \\mathbf{p} = -\\nabla \\Phi(\\mathbf{x};\\rho)\n$$\nThe Newton step $\\mathbf{p}$ is the solution to this $n \\times n$ system of linear equations. When the Hessian $\\nabla^2 \\Phi(\\mathbf{x};\\rho)$ is singular or ill-conditioned, we compute a minimum-norm solution using the pseudoinverse, denoted by $(\\cdot)^+$:\n$$\n\\mathbf{p} = -(\\nabla^2 \\Phi(\\mathbf{x};\\rho))^+ \\nabla \\Phi(\\mathbf{x};\\rho)\n$$\nThe Euclidean norm of this step is then computed as $\\lVert \\mathbf{p} \\rVert_2 = \\sqrt{\\mathbf{p}^\\top\\mathbf{p}}$.\n\n**4. Hessian Condition Number**\n\nThe condition number of the Hessian matrix $H_\\Phi = \\nabla^2 \\Phi(\\mathbf{x};\\rho)$ quantifies its sensitivity to perturbations. For a symmetric matrix, its singular values are the absolute values of its eigenvalues. The condition number is defined as the ratio of the largest singular value, $\\sigma_{\\max}$, to the smallest singular value, $\\sigma_{\\min}$:\n$$\n\\text{cond}(H_\\Phi) = \\frac{\\sigma_{\\max}(H_\\Phi)}{\\sigma_{\\min}(H_\\Phi)}\n$$\nThese singular values are computed using the Singular Value Decomposition (SVD) of $H_\\Phi$. If $\\sigma_{\\min} = 0$, the matrix is singular, and the condition number is defined to be $+\\infty$.\n\n**Simulation Procedure**\n\nThe simulation will implement these derived formulas for each of the three test cases. For each case, at a fixed base point $\\mathbf{x}_0$, we will iterate through a sequence of penalty parameters $\\rho_k = 10^{-2} \\times 10^k$ for $k \\in \\{0, 1, 2, 3, 4, 5\\}$. In each iteration, we will:\n1.  Evaluate the necessary components at $\\mathbf{x}_0$: $\\nabla f(\\mathbf{x}_0)$, $\\nabla^2 f(\\mathbf{x}_0)$, $c(\\mathbf{x}_0)$, $J(\\mathbf{x}_0)$, and $\\nabla^2 c_i(\\mathbf{x}_0)$.\n2.  Assemble the gradient $\\nabla \\Phi(\\mathbf{x}_0;\\rho_k)$ and the Hessian $H_\\Phi = \\nabla^2 \\Phi(\\mathbf{x}_0;\\rho_k)$.\n3.  Compute the SVD of $H_\\Phi$ to find its singular values and calculate the condition number.\n4.  Solve for the Newton step $\\mathbf{p}_k$ using the pseudoinverse of $H_\\Phi$.\n5.  Calculate the Euclidean norm $\\lVert \\mathbf{p}_k \\rVert_2$.\n6.  Collect the lists of condition numbers and step norms for each test case.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the quadratic penalty method simulation problem.\n    Derives and computes Newton steps and Hessian condition numbers for three test cases\n    as the penalty parameter rho increases.\n    \"\"\"\n\n    def run_simulation_case(case_params):\n        \"\"\"\n        Runs the simulation for a single test case.\n\n        Args:\n            case_params (dict): A dictionary containing the functions and data for a case.\n                - 'grad_f': Gradient of the objective function.\n                - 'hess_f': Hessian of the objective function.\n                - 'c_func': Constraint function(s).\n                - 'jac_c': Jacobian of the constraint function(s).\n                - 'hess_c': List of Hessians of each constraint component.\n                - 'x0': The base point for the simulation.\n\n        Returns:\n            list: A list containing two lists:\n                  - The list of Hessian condition numbers for each rho.\n                  - The list of Newton step norms for each rho.\n        \"\"\"\n        grad_f_func = case_params['grad_f']\n        hess_f_func = case_params['hess_f']\n        c_func = case_params['c_func']\n        jac_c_func = case_params['jac_c']\n        hess_c_funcs = case_params['hess_c']\n        x0 = case_params['x0']\n\n        rho_values = [10**(-2 + k) for k in range(6)]\n        \n        condition_numbers = []\n        step_norms = []\n\n        # Evaluate problem functions at the fixed base point x0\n        grad_f_x0 = grad_f_func(x0)\n        hess_f_x0 = hess_f_func(x0)\n        c_x0 = c_func(x0)\n        jac_c_x0 = jac_c_func(x0)\n        \n        # Calculate the sum term in the Hessian formula: sum(c_i * H_ci)\n        sum_c_hess_c = np.zeros_like(hess_f_x0)\n        for i in range(len(c_x0)):\n            sum_c_hess_c += c_x0[i] * hess_c_funcs[i](x0)\n\n        for rho in rho_values:\n            # 1. Assemble the gradient and Hessian of the penalty function\n            # Gradient: grad_Phi = grad_f + rho * J^T * c\n            grad_phi = grad_f_x0 + rho * jac_c_x0.T @ c_x0\n\n            # Hessian: hess_Phi = hess_f + rho * (J^T * J + sum(c_i * H_ci))\n            hess_phi = hess_f_x0 + rho * (jac_c_x0.T @ jac_c_x0 + sum_c_hess_c)\n\n            # 2. Compute the condition number from SVD\n            try:\n                singular_values = np.linalg.svd(hess_phi, compute_uv=False)\n                s_min = singular_values[-1]\n                s_max = singular_values[0]\n                \n                # Check for singularity\n                if s_min < 1e-16:\n                    cond_num = np.inf\n                else:\n                    cond_num = s_max / s_min\n            except np.linalg.LinAlgError:\n                cond_num = np.inf\n            condition_numbers.append(cond_num)\n\n            # 3. Compute the Newton step p using pseudoinverse\n            # H_phi * p = -g_phi  => p = -pinv(H_phi) * g_phi\n            try:\n                p = -np.linalg.pinv(hess_phi) @ grad_phi\n            except np.linalg.LinAlgError:\n                p = np.full_like(x0, np.nan) # Should not happen with pinv, but for robustness\n            \n            # 4. Compute the Euclidean norm of the step\n            p_norm = np.linalg.norm(p)\n            step_norms.append(p_norm)\n            \n        return [condition_numbers, step_norms]\n\n    # Definition of test cases\n    test_cases = [\n        { # Case A\n            'grad_f': lambda x: np.array([x[0], 2 * x[1]]),\n            'hess_f': lambda x: np.array([[1.0, 0.0], [0.0, 2.0]]),\n            'c_func': lambda x: np.array([x[0] + x[1] - 1.0]),\n            'jac_c': lambda x: np.array([[1.0, 1.0]]),\n            'hess_c': [lambda x: np.zeros((2, 2))],\n            'x0': np.array([0.0, 0.0])\n        },\n        { # Case B\n            'grad_f': lambda x: np.array([2 * x[0], x[1]]),\n            'hess_f': lambda x: np.array([[2.0, 0.0], [0.0, 1.0]]),\n            'c_func': lambda x: np.array([x[0]**2 + x[1] - 1.0]),\n            'jac_c': lambda x: np.array([[2 * x[0], 1.0]]),\n            'hess_c': [lambda x: np.array([[2.0, 0.0], [0.0, 0.0]])],\n            'x0': np.array([0.5, -0.2])\n        },\n        { # Case C\n            'grad_f': lambda x: np.array([1e-3 * x[0], x[1]]),\n            'hess_f': lambda x: np.array([[1e-3, 0.0], [0.0, 1.0]]),\n            'c_func': lambda x: np.array([x[0] - 0.5]),\n            'jac_c': lambda x: np.array([[1.0, 0.0]]),\n            'hess_c': [lambda x: np.zeros((2, 2))],\n            'x0': np.array([1.0, 1.0])\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result = run_simulation_case(case)\n        all_results.append(result)\n\n    # Format output to match [[case_A_res], [case_B_res], ...]\n    # where each case_res is [[conds],[norms]].\n    # The map(str, ...) and join will create a string like \"[[...]],[[...]]\"\n    # which is then wrapped in \"[\" and \"]\".\n    results_str = ','.join(map(str, all_results))\n    print(f\"[{results_str}]\")\n\n\nsolve()\n```", "id": "3169152"}, {"introduction": "This final practice explores the opposite scenario: what happens when the penalty parameter $\\rho$ is not large enough? If the penalty is too weak, the algorithm may prioritize minimizing the objective function at the expense of satisfying the constraints, leading to an \"optimal\" but infeasible solution. Through this coding exercise [@problem_id:3169194], you will see how different starting points can be drawn toward such infeasible stationary points, making the abstract risk of a small $\\rho$ a concrete and observable phenomenon.", "problem": "Consider the equality-constrained optimization problem: minimize a smooth objective $f(x)$ subject to nonlinear equality constraints $c(x)=0$, where $x=\\begin{bmatrix}x_1\\\\x_2\\end{bmatrix}\\in\\mathbb{R}^2$ and\n$$\nc(x)=\\begin{bmatrix}\\sin x_1 + x_2 \\\\ \\exp(x_1) - x_2\\end{bmatrix}.\n$$\nAll trigonometric functions must be evaluated in radians. The quadratic penalty method replaces the constrained problem with the unconstrained minimization of the penalty function\n$$\n\\phi_{\\rho}(x) = f(x) + \\frac{\\rho}{2}\\,\\lVert c(x)\\rVert_2^2,\n$$\nfor a positive penalty parameter $\\rho>0$. The method is grounded in the core definition that stationary points of $\\phi_{\\rho}$ satisfy the condition that the gradient of $\\phi_{\\rho}$ vanishes, and feasibility is measured by the residual norm $\\lVert c(x)\\rVert_2$.\n\nYou will implement the quadratic penalty method for the specific choice of objective\n$$\nf(x)=\\frac{1}{2}\\,\\lVert x - x^{\\dagger}\\rVert_2^2,\n$$\nwhere $x^{\\dagger}\\in\\mathbb{R}^2$ is defined as follows. Let $x_1^{\\dagger}$ be the unique root of $\\cos x_1 + \\exp(x_1)=0$ in the interval $[-2.0,-1.6]$, and set\n$$\nx_2^{\\dagger}=\\frac{\\exp(x_1^{\\dagger}) - \\sin(x_1^{\\dagger})}{2},\\quad x^{\\dagger}=\\begin{bmatrix}x_1^{\\dagger}\\\\x_2^{\\dagger}\\end{bmatrix}.\n$$\nStarting from the fundamental base that stationary points of unconstrained minimization satisfy the first-order condition $\\nabla \\phi_{\\rho}(x)=0$, derive and use a gradient-based algorithm to find local minimizers of $\\phi_{\\rho}$ for different penalty parameters $\\rho$ and initializations $x^{(0)}$. Your implementation must:\n- Compute $x^{\\dagger}$ as specified.\n- Form $\\phi_{\\rho}(x)$ and its gradient $\\nabla \\phi_{\\rho}(x)$ using only the fundamental definitions of $f(x)$, $c(x)$, and the Jacobian of $c(x)$.\n- Use a standard gradient-based solver to seek a stationary point of $\\phi_{\\rho}$ from a given initialization $x^{(0)}$.\n- Report feasibility by the residual $\\lVert c(x^{\\star})\\rVert_2$ at the found stationary point $x^{\\star}$.\n\nExperimentally demonstrate that poor starts can be attracted to infeasible stationary points when $\\rho$ is small. Use the following test suite of penalty parameters and initializations (angles in radians):\n1. Small penalty with a poor start near $x^{\\dagger}$: $\\rho=10^{-4}$, $x^{(0)}=x^{\\dagger}+\\begin{bmatrix}0.2\\\\-0.2\\end{bmatrix}$.\n2. Extremely small penalty and exact stationary start: $\\rho=10^{-6}$, $x^{(0)}=x^{\\dagger}$.\n3. Small penalty and a far-from-feasible start: $\\rho=10^{-3}$, $x^{(0)}=\\begin{bmatrix}-3.0\\\\1.0\\end{bmatrix}$.\n4. Moderate penalty and a start near the feasible manifold: $\\rho=1.0$, $x^{(0)}=\\begin{bmatrix}-2.7\\\\\\exp(-2.7)\\end{bmatrix}$.\n5. Large penalty and a poor start: $\\rho=100.0$, $x^{(0)}=x^{\\dagger}+\\begin{bmatrix}0.1\\\\0.0\\end{bmatrix}$.\n\nFor each case, minimize $\\phi_{\\rho}(x)$ and produce the scalar feasibility measure $\\lVert c(x^{\\star})\\rVert_2$, rounded to six decimal places.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3,r_4,r_5]$), where each $r_i$ is the rounded float $\\lVert c(x^{\\star})\\rVert_2$ for the corresponding test case.", "solution": "The user-provided problem is a valid exercise in computational optimization, specifically concerning the application of the quadratic penalty method to a nonlinear equality-constrained problem. The problem is scientifically grounded, well-posed, and all necessary data and definitions are provided for a unique solution to be determined.\n\nThe problem is to minimize a smooth objective function $f(x)$ subject to nonlinear equality constraints $c(x)=0$, where $x=\\begin{bmatrix}x_1\\\\x_2\\end{bmatrix}\\in\\mathbb{R}^2$. The specific functions are:\n$$\nf(x)=\\frac{1}{2}\\,\\lVert x - x^{\\dagger}\\rVert_2^2\n$$\n$$\nc(x)=\\begin{bmatrix}\\sin x_1 + x_2 \\\\ \\exp(x_1) - x_2\\end{bmatrix}\n$$\nThe target point $x^{\\dagger}=\\begin{bmatrix}x_1^{\\dagger}\\\\x_2^{\\dagger}\\end{bmatrix}$ is defined such that $x_1^{\\dagger}$ is the unique root of the equation $\\cos x_1 + \\exp(x_1)=0$ in the interval $[-2.0,-1.6]$, and $x_2^{\\dagger}=\\frac{\\exp(x_1^{\\dagger}) - \\sin(x_1^{\\dagger})}{2}$.\n\nThe quadratic penalty method replaces this constrained problem with a sequence of unconstrained problems by minimizing the penalty function $\\phi_{\\rho}(x)$ for a positive penalty parameter $\\rho > 0$:\n$$\n\\phi_{\\rho}(x) = f(x) + \\frac{\\rho}{2}\\,\\lVert c(x)\\rVert_2^2\n$$\nThe core of the method lies in finding stationary points of $\\phi_{\\rho}(x)$, which are points $x^{\\star}$ that satisfy the first-order necessary condition $\\nabla \\phi_{\\rho}(x^{\\star})=0$. We will use a gradient-based numerical solver to find such points.\n\nFirst, we must derive the gradient of the penalty function, $\\nabla \\phi_{\\rho}(x)$. By the sum rule of differentiation, the gradient is:\n$$\n\\nabla \\phi_{\\rho}(x) = \\nabla f(x) + \\nabla \\left( \\frac{\\rho}{2}\\,\\lVert c(x)\\rVert_2^2 \\right)\n$$\nLet's compute each term. The gradient of the objective function $f(x) = \\frac{1}{2}((x_1 - x_1^{\\dagger})^2 + (x_2 - x_2^{\\dagger})^2)$ is:\n$$\n\\nabla f(x) = \\begin{bmatrix} x_1 - x_1^{\\dagger} \\\\ x_2 - x_2^{\\dagger} \\end{bmatrix} = x - x^{\\dagger}\n$$\nFor the penalty term, we use the chain rule. The squared $2$-norm is $\\lVert c(x)\\rVert_2^2 = c(x)^T c(x)$. Its gradient is given by $2 J(x)^T c(x)$, where $J(x)$ is the Jacobian matrix of the constraint function $c(x)$. Thus, the gradient of the penalty term is:\n$$\n\\nabla \\left( \\frac{\\rho}{2}\\,\\lVert c(x)\\rVert_2^2 \\right) = \\frac{\\rho}{2} \\left( 2 J(x)^T c(x) \\right) = \\rho J(x)^T c(x)\n$$\nThe Jacobian of $c(x) = \\begin{bmatrix} c_1(x) \\\\ c_2(x) \\end{bmatrix} = \\begin{bmatrix} \\sin x_1 + x_2 \\\\ \\exp(x_1) - x_2 \\end{bmatrix}$ is:\n$$\nJ(x) = \\begin{bmatrix} \\frac{\\partial c_1}{\\partial x_1} & \\frac{\\partial c_1}{\\partial x_2} \\\\ \\frac{\\partial c_2}{\\partial x_1} & \\frac{\\partial c_2}{\\partial x_2} \\end{bmatrix} = \\begin{bmatrix} \\cos x_1 & 1 \\\\ \\exp(x_1) & -1 \\end{bmatrix}\n$$\nCombining these results, the full gradient of the penalty function is:\n$$\n\\nabla \\phi_{\\rho}(x) = (x - x^{\\dagger}) + \\rho J(x)^T c(x)\n$$\nSubstituting the expressions for $c(x)$ and $J(x)^T$:\n$$\n\\nabla \\phi_{\\rho}(x) = \\begin{bmatrix} x_1 - x_1^{\\dagger} \\\\ x_2 - x_2^{\\dagger} \\end{bmatrix} + \\rho \\begin{bmatrix} \\cos x_1 & \\exp(x_1) \\\\ 1 & -1 \\end{bmatrix} \\begin{bmatrix} \\sin x_1 + x_2 \\\\ \\exp(x_1) - x_2 \\end{bmatrix}\n$$\n\nThe numerical procedure is as follows:\n1.  Compute the target vector $x^{\\dagger}$. Find the root $x_1^{\\dagger}$ of $g(t) = \\cos t + \\exp t = 0$ on $[-2.0, -1.6]$ using a numerical root-finder. Then, calculate $x_2^{\\dagger}$ using its definition. All trigonometric function arguments are in radians.\n2.  For each test case, defined by a penalty parameter $\\rho$ and an initial guess $x^{(0)}$, we solve the unconstrained minimization problem for $\\phi_{\\rho}(x)$. A quasi-Newton method (specifically, BFGS) is suitable for this task, as it efficiently uses the gradient information we have derived.\n3.  The solver will return an approximate stationary point $x^{\\star}$ where $\\nabla \\phi_{\\rho}(x^{\\star}) \\approx 0$.\n4.  For each resulting $x^{\\star}$, we compute the feasibility measure, which is the constraint violation residual $\\lVert c(x^{\\star})\\rVert_2$. This value quantifies how well the solution satisfies the constraint $c(x)=0$.\n\nThe value of $\\rho$ controls the trade-off. For small $\\rho$, the term $\\nabla f(x) = x - x^{\\dagger}$ dominates, and the stationary point $x^{\\star}$ will be close to $x^{\\dagger}$, which is generally not a feasible point (i.e., $c(x^{\\dagger}) \\neq 0$). Consequently, the residual $\\lVert c(x^{\\star})\\rVert_2$ will be large. For large $\\rho$, the penalty term $\\rho J(x)^T c(x)$ dominates, forcing the stationary point $x^{\\star}$ to be near the feasible set where $c(x) \\approx 0$, leading to a small residual. The provided test cases are designed to illustrate this behavior.", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import brentq, minimize\n\ndef solve():\n    \"\"\"\n    Implements the quadratic penalty method for a constrained optimization problem.\n    The solution involves:\n    1. Computing a target point x_dagger based on a root-finding problem.\n    2. Defining the penalty function and its gradient for the quadratic penalty method.\n    3. Iterating through a set of test cases with varying penalty parameters (rho)\n       and initial guesses (x0).\n    4. Using a gradient-based solver (BFGS) to find a stationary point of the\n       penalty function for each case.\n    5. Reporting the feasibility, measured by the 2-norm of the constraints at the\n       found stationary point.\n    \"\"\"\n\n    # 1. Compute the target point x_dagger\n    # Define the function g(x1) = cos(x1) + exp(x1) to find its root.\n    g = lambda x1: np.cos(x1) + np.exp(x1)\n    \n    # Find the unique root x1_dagger in the interval [-2.0, -1.6].\n    x1_dagger = brentq(g, -2.0, -1.6)\n    \n    # Compute x2_dagger using the given formula.\n    x2_dagger = (np.exp(x1_dagger) - np.sin(x1_dagger)) / 2.0\n    \n    # Assemble the x_dagger vector.\n    x_dagger = np.array([x1_dagger, x2_dagger])\n\n    # 2. Define the core functions for the optimization problem\n    def f_obj(x, x_dagger_):\n        \"\"\"Objective function f(x) = 1/2 * ||x - x_dagger||^2.\"\"\"\n        return 0.5 * np.sum((x - x_dagger_)**2)\n\n    def c(x):\n        \"\"\"Vector of constraint functions c(x) = 0.\"\"\"\n        return np.array([np.sin(x[0]) + x[1], np.exp(x[0]) - x[1]])\n\n    def jac_c(x):\n        \"\"\"Jacobian of the constraint function c(x).\"\"\"\n        return np.array([[np.cos(x[0]), 1.0], \n                         [np.exp(x[0]), -1.0]])\n\n    # 3. Define the penalty function and its gradient\n    def phi_rho(x, rho, x_dagger_):\n        \"\"\"Penalty function phi_rho(x) = f(x) + rho/2 * ||c(x)||^2.\"\"\"\n        return f_obj(x, x_dagger_) + (rho / 2.0) * np.sum(c(x)**2)\n\n    def grad_phi_rho(x, rho, x_dagger_):\n        \"\"\"Gradient of the penalty function, grad_phi_rho(x).\"\"\"\n        # Grad(f) = x - x_dagger\n        grad_f_val = x - x_dagger_\n        # Grad(penalty) = rho * J(x)^T * c(x)\n        c_val = c(x)\n        jac_c_val = jac_c(x)\n        grad_penalty_val = rho * jac_c_val.T @ c_val\n        return grad_f_val + grad_penalty_val\n\n    # 4. Define the test suite\n    test_cases = [\n        (1e-4, x_dagger + np.array([0.2, -0.2])),\n        (1e-6, x_dagger),\n        (1e-3, np.array([-3.0, 1.0])),\n        (1.0, np.array([-2.7, np.exp(-2.7)])),\n        (100.0, x_dagger + np.array([0.1, 0.0]))\n    ]\n\n    results = []\n    # 5. Process each test case\n    for rho, x0 in test_cases:\n        # Find a stationary point of the penalty function using a quasi-Newton method.\n        res = minimize(\n            fun=phi_rho,\n            x0=x0,\n            args=(rho, x_dagger),\n            jac=grad_phi_rho,\n            method='BFGS'\n        )\n        x_star = res.x\n        \n        # Calculate the feasibility measure (constraint residual norm).\n        feasibility_residual = np.linalg.norm(c(x_star), 2)\n        \n        # Store the rounded result.\n        results.append(round(feasibility_residual, 6))\n\n    # 6. Print the final results in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3169194"}]}