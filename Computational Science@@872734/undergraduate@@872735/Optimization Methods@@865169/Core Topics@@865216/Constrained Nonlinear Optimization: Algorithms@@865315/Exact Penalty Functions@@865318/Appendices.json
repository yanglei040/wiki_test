{"hands_on_practices": [{"introduction": "To understand why an exact penalty function works, we must connect the penalty parameter to the underlying structure of the constrained problem. This first practice guides you through deriving the minimum penalty parameter $\\rho$ for an $\\ell_{1}$ penalty function by linking it directly to the Lagrange multiplier from the Karush-Kuhn-Tucker (KKT) conditions [@problem_id:3261558]. This exercise forms the theoretical bedrock for understanding the \"exactness\" property.", "problem": "Consider the convex quadratic program (QP) with a single linear equality constraint: minimize the function $f(x)$ subject to the constraint $g(x)=0$, where $x \\in \\mathbb{R}^{2}$, \n$$\nf(x) \\equiv \\frac{1}{2} x_{1}^{2} + x_{2}^{2} - 4 x_{1} - 2 x_{2}, \\qquad g(x) \\equiv x_{1} + x_{2} - 1.\n$$\nBecause the Hessian matrix of $f$ is positive definite, the constrained problem has a unique optimal solution. Define the $\\ell_{1}$ exact penalty function $F_{\\rho}(x)$ with penalty parameter $\\rho \\ge 0$ by\n$$\nF_{\\rho}(x) \\equiv f(x) + \\rho \\, |g(x)|.\n$$\nWork from first principles as follows. First, determine the unique optimal solution $x^{\\star}$ and the associated Lagrange multiplier $\\lambda^{\\star}$ for the constrained QP using the Karush–Kuhn–Tucker (KKT) conditions. Next, use the subdifferential characterization of optimality for convex, possibly nonsmooth functions to establish the necessary and sufficient condition on the penalty parameter $\\rho$ for which $x^{\\star}$ is also a global minimizer of $F_{\\rho}(x)$. Finally, determine the minimum value of $\\rho$ that guarantees that minimizing $F_{\\rho}(x)$ recovers the constrained solution $x^{\\star}$. Express your final answer as an exact value (no rounding). The final answer must be a single real number.", "solution": "The problem is to find the minimum value of the penalty parameter $\\rho$ such that the unconstrained minimizer of the exact penalty function $F_{\\rho}(x) \\equiv f(x) + \\rho |g(x)|$ coincides with the optimal solution of the equality-constrained QP. The fundamental tools are the Karush–Kuhn–Tucker (KKT) conditions for the equality-constrained convex program and the subdifferential optimality condition for convex, possibly nonsmooth functions.\n\nStep 1: Solve the equality-constrained QP and find the Lagrange multiplier. The Lagrangian for the constrained problem is\n$$\n\\mathcal{L}(x,\\lambda) \\equiv f(x) + \\lambda\\, g(x)\n= \\frac{1}{2} x_{1}^{2} + x_{2}^{2} - 4 x_{1} - 2 x_{2} + \\lambda (x_{1} + x_{2} - 1).\n$$\nThe gradient with respect to $x$ is\n$$\n\\nabla_{x} \\mathcal{L}(x,\\lambda) = \\begin{pmatrix} x_{1} - 4 + \\lambda \\\\ 2 x_{2} - 2 + \\lambda \\end{pmatrix}.\n$$\nThe KKT conditions for the equality-constrained convex problem are stationarity and primal feasibility:\n$$\nx_{1} - 4 + \\lambda = 0, \\qquad 2 x_{2} - 2 + \\lambda = 0, \\qquad x_{1} + x_{2} = 1.\n$$\nFrom the first two equations,\n$$\nx_{1} = 4 - \\lambda, \\qquad x_{2} = \\frac{2 - \\lambda}{2} = 1 - \\frac{\\lambda}{2}.\n$$\nImposing feasibility $x_{1} + x_{2} = 1$ gives\n$$\n(4 - \\lambda) + \\left(1 - \\frac{\\lambda}{2}\\right) = 1 \\;\\;\\Longrightarrow\\;\\; 5 - \\frac{3}{2}\\lambda = 1 \\;\\;\\Longrightarrow\\;\\; \\lambda^{\\star} = \\frac{8}{3}.\n$$\nThen\n$$\nx_{1}^{\\star} = 4 - \\frac{8}{3} = \\frac{4}{3}, \\qquad x_{2}^{\\star} = 1 - \\frac{1}{2}\\cdot \\frac{8}{3} = 1 - \\frac{4}{3} = -\\frac{1}{3}.\n$$\nThus the unique solution is $x^{\\star} = \\big(\\frac{4}{3}, -\\frac{1}{3}\\big)$ with Lagrange multiplier $\\lambda^{\\star} = \\frac{8}{3}$.\n\nStep 2: Subdifferential optimality for the exact penalty function. The function $F_{\\rho}(x) = f(x) + \\rho |g(x)|$ is convex because it is the sum of a convex quadratic and a nonnegative multiple of a convex absolute value of an affine function. The subdifferential of $|t|$ at $t = 0$ is the interval $[-1, 1]$, and the chain rule for subgradients of compositions with affine maps gives\n$$\n\\partial \\big(\\rho |g(x)|\\big)\\big|_{g(x)=0} = \\rho \\, \\{ s \\, \\nabla g(x) : s \\in [-1,1] \\}.\n$$\nSince $g(x) = x_{1} + x_{2} - 1$, we have $\\nabla g(x) = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$. The first-order optimality condition for a convex, possibly nonsmooth function $F_{\\rho}$ at a point $\\bar{x}$ is\n$$\n\\mathbf{0} \\in \\nabla f(\\bar{x}) + \\partial \\big(\\rho |g(\\bar{x})|\\big).\n$$\nWe investigate whether the constrained solution $x^{\\star}$ with $g(x^{\\star}) = 0$ can be a minimizer of $F_{\\rho}$. At $x^{\\star}$,\n$$\n\\mathbf{0} \\in \\nabla f(x^{\\star}) + \\rho \\, \\{ s \\, \\nabla g(x^{\\star}) : s \\in [-1,1] \\}.\n$$\nBy the KKT stationarity for the constrained problem, there exists $\\lambda^{\\star}$ such that\n$$\n\\nabla f(x^{\\star}) + \\lambda^{\\star} \\nabla g(x^{\\star}) = \\mathbf{0}.\n$$\nTherefore, the subgradient optimality condition at $x^{\\star}$ for $F_{\\rho}$ is equivalent to the existence of $s \\in [-1,1]$ with\n$$\n\\lambda^{\\star} = \\rho \\, s.\n$$\nSuch an $s$ exists if and only if $|\\lambda^{\\star}| \\le \\rho$.\n\nStep 3: Minimal penalty parameter. Since $F_{\\rho}$ is convex and $f$ is strongly convex, when the subgradient condition holds at $x^{\\star}$, the point $x^{\\star}$ is the unique global minimizer of $F_{\\rho}$. The necessary and sufficient condition for exactness at $x^{\\star}$ is $|\\lambda^{\\star}| \\le \\rho$. Hence, the minimum penalty parameter that guarantees recovery of $x^{\\star}$ by minimizing $F_{\\rho}$ is\n$$\n\\rho_{\\min} = |\\lambda^{\\star}| = \\left| \\frac{8}{3} \\right| = \\frac{8}{3}.\n$$\nTherefore, the required minimal value of the penalty parameter is $\\frac{8}{3}$.", "answer": "$$\\boxed{\\frac{8}{3}}$$", "id": "3261558"}, {"introduction": "Real-world optimization problems are not always guaranteed to have a feasible solution. This practice explores what the exact penalty method accomplishes in such a scenario, where the constraints are contradictory and the feasible set is empty [@problem_id:3126713]. By analyzing the minimizer of the penalty function, you will discover that it intelligently finds a point that best compromises between minimizing the objective and minimizing the constraint violation.", "problem": "Consider the constrained minimization problem with decision variable $x \\in \\mathbb{R}$:\nminimize $f(x)$ subject to $h_1(x) = 0$ and $h_2(x) = 0$, where $f(x) = (x - 2)^2$, $h_1(x) = x - 0$, and $h_2(x) = x - 1$. Let the feasible set be denoted by $\\mathcal{F} = \\{x \\in \\mathbb{R} : h_1(x) = 0,\\; h_2(x) = 0\\}$. For a penalty parameter $\\mu  0$, define the absolute-value-based exact penalty function\n$$\nP_\\mu(x) \\;=\\; f(x) \\;+\\; \\mu \\big(|h_1(x)| + |h_2(x)|\\big) \\;=\\; (x - 2)^2 + \\mu \\big(|x| + |x - 1|\\big).\n$$\nUse only fundamental definitions from constrained optimization: the feasible set $\\mathcal{F}$, the violation measure $v(x) := |h_1(x)| + |h_2(x)|$, and the exact penalty function $P_\\mu(x) = f(x) + \\mu\\, v(x)$. Based on these, reason about infeasibility, minimum violation, and the behavior of minimizers of $P_\\mu$ as $\\mu$ varies.\n\nWhich of the following statements are true? Select all that apply.\n\nA. The feasible set $\\mathcal{F}$ is empty; the minimum value of the violation measure $v(x) = |x| + |x - 1|$ equals $1$, and the set of minimizers of $v(x)$ is the interval $[0,1]$.\n\nB. For every $\\mu  0$, every global minimizer of $P_\\mu$ lies in the interval $[0,1]$.\n\nC. There exists $\\mu^\\star \\in \\mathbb{R}_{0}$ such that for all $\\mu \\ge \\mu^\\star$, every global minimizer of $P_\\mu$ is $x = 1$.\n\nD. As $\\mu \\to +\\infty$, any limit point of global minimizers of $P_\\mu$ must be a minimizer of $v(x)$, and among all minimizers of $v(x)$ it minimizes $f(x)$.\n\nE. For $\\mu \\in (0,1)$, the unique global minimizer of $P_\\mu$ is $x = 2 - \\mu$.", "solution": "## Derivation and Option Analysis\n\nThe core of the problem is to find the global minimizer(s) of the penalty function $P_\\mu(x)$ for $\\mu  0$.\nThe penalty function is given by:\n$$\nP_\\mu(x) = (x - 2)^2 + \\mu \\big(|x| + |x - 1|\\big)\n$$\n\n### Analysis of the Violation Measure\nFirst, let's analyze the violation measure $v(x) = |x| + |x - 1|$. This is a piecewise linear function:\n- For $x  0$: $v(x) = -x - (x-1) = -2x + 1$. This is a strictly decreasing linear function.\n- For $x \\in [0, 1]$: $v(x) = x - (x-1) = 1$. This is a constant function.\n- For $x  1$: $v(x) = x + (x-1) = 2x - 1$. This is a strictly increasing linear function.\n\nThe function $v(x)$ decreases for $x0$, is constant and equal to $1$ for $x \\in [0, 1]$, and increases for $x1$. Therefore, the minimum value of $v(x)$ is $1$, and this minimum is achieved for any $x$ in the interval $[0, 1]$. The set of minimizers of $v(x)$ is the closed interval $[0, 1]$.\n\n### Analysis of the Penalty Function Minimizer\nThe penalty function $P_\\mu(x)$ is the sum of a strictly convex function $f(x) = (x-2)^2$ and a convex function $\\mu v(x)$. Therefore, $P_\\mu(x)$ is strictly convex for any $\\mu0$. A strictly convex function has a unique global minimizer. We can find this minimizer by finding the point $x$ where the subgradient of $P_\\mu(x)$, denoted $\\partial P_\\mu(x)$, contains $0$.\n\nLet's analyze $P_\\mu(x)$ and its derivative/subgradient in a piecewise manner:\n1.  **For $x  0$**:\n    $P_\\mu(x) = (x - 2)^2 + \\mu(-2x + 1)$.\n    $P_\\mu'(x) = 2(x - 2) - 2\\mu = 2x - 4 - 2\\mu$.\n    Setting $P_\\mu'(x) = 0$ gives $x = 2 + \\mu$. Since $\\mu  0$, we have $x = 2 + \\mu  2$, which contradicts the condition $x  0$. So, the minimizer is not in $(-\\infty, 0)$. In fact, for $x0$, $P_\\mu'(x) = 2x-4-2\\mu  -4-2\\mu  0$, so $P_\\mu(x)$ is strictly decreasing on $(-\\infty, 0)$.\n\n2.  **For $x \\in (0, 1)$**:\n    $P_\\mu(x) = (x - 2)^2 + \\mu(1)$.\n    $P_\\mu'(x) = 2(x - 2)$.\n    Setting $P_\\mu'(x) = 0$ gives $x=2$, which is not in the interval $(0, 1)$. For $x \\in (0, 1)$, $P_\\mu'(x) = 2(x - 2)  0$, so $P_\\mu(x)$ is strictly decreasing on $(0, 1)$.\n\n3.  **For $x  1$**:\n    $P_\\mu(x) = (x - 2)^2 + \\mu(2x - 1)$.\n    $P_\\mu'(x) = 2(x - 2) + 2\\mu = 2x - 4 + 2\\mu$.\n    Setting $P_\\mu'(x) = 0$ gives $x = 2 - \\mu$. For this point to be in the interval $(1, \\infty)$, we need $2 - \\mu  1$, which implies $\\mu  1$. So, for $0  \\mu  1$, there is a stationary point at $x = 2 - \\mu$.\n\nThe function $P_\\mu(x)$ is not differentiable at $x=0$ and $x=1$. We must check conditions at these points using subgradients. A point $x_0$ is a minimizer if $0 \\in \\partial P_\\mu(x_0)$.\n\n4.  **At $x = 0$**: The subgradient is the interval between the left and right derivatives.\n    $P_{\\mu,-}'(0) = 2(0-2) - 2\\mu = -4 - 2\\mu$.\n    $P_{\\mu,+}'(0) = 2(0-2) = -4$.\n    $\\partial P_\\mu(0) = [-4 - 2\\mu, -4]$. Since $\\mu  0$, this interval contains only negative numbers. Thus, $0 \\notin \\partial P_\\mu(0)$, and $x=0$ is never a minimizer.\n\n5.  **At $x = 1$**:\n    $P_{\\mu,-}'(1) = 2(1-2) = -2$.\n    $P_{\\mu,+}'(1) = 2(1-2) + 2\\mu = -2 + 2\\mu$.\n    $\\partial P_\\mu(1) = [-2, -2 + 2\\mu]$.\n    For $x=1$ to be the minimizer, we need $0 \\in \\partial P_\\mu(1)$, which means the interval must span $0$. This requires $-2 \\le 0$ (which is true) and $-2 + 2\\mu \\ge 0$. The second condition simplifies to $2\\mu \\ge 2$, or $\\mu \\ge 1$.\n\n**Summary of Minimizers:**\n- If $0  \\mu  1$: The derivative is negative for all $x  2-\\mu$ (across all pieces) and positive for $x  2-\\mu$. The stationary point at $x = 2-\\mu$ is the unique global minimizer.\n- If $\\mu = 1$: The stationary point $x=2-\\mu = 1$. And the subgradient at $x=1$ is $[-2, 0]$, which contains $0$. The derivative is negative for $x1$ and positive for $x1$. Thus, $x=1$ is the unique global minimizer.\n- If $\\mu  1$: The candidate $x=2-\\mu$ is less than $1$ and hence not relevant for the region $x1$. The derivative $P_\\mu'(x)$ is negative for all $x1$. For $x1$, $P_\\mu'(x) = 2x - 4 + 2\\mu  2(1) - 4 + 2\\mu = 2\\mu - 2  0$. The function decreases until $x=1$ and increases thereafter. The minimizer is at $x=1$, consistent with our subgradient analysis ($\\mu \\ge 1$).\n\nSo, the unique global minimizer $x_\\mu^*$ is:\n$$\nx_\\mu^* =\n\\begin{cases}\n2-\\mu  \\text{if } 0  \\mu  1 \\\\\n1  \\text{if } \\mu \\ge 1\n\\end{cases}\n$$\n\n### Option-by-Option Analysis\n\n**A. The feasible set $\\mathcal{F}$ is empty; the minimum value of the violation measure $v(x) = |x| + |x - 1|$ equals $1$, and the set of minimizers of $v(x)$ is the interval $[0,1]$.**\n- Feasible set: $\\mathcal{F} = \\{x \\in \\mathbb{R} : x=0 \\text{ and } x-1=0\\}$. These conditions are contradictory ($x=0$ and $x=1$), so $\\mathcal{F} = \\emptyset$.\n- Violation measure: Our analysis of $v(x)$ showed its minimum value is $1$, attained on the interval $[0, 1]$.\n- All parts of the statement are correct.\n**Verdict: Correct**\n\n**B. For every $\\mu  0$, every global minimizer of $P_\\mu$ lies in the interval $[0,1]$.**\n- Let's test a value of $\\mu$ in the range $(0, 1)$, for example $\\mu = 0.5$.\n- The unique global minimizer is $x_{0.5}^* = 2 - 0.5 = 1.5$.\n- The value $1.5$ is not in the interval $[0, 1]$.\n- This provides a counterexample to the statement.\n**Verdict: Incorrect**\n\n**C. There exists $\\mu^\\star \\in \\mathbb{R}_{0}$ such that for all $\\mu \\ge \\mu^\\star$, every global minimizer of $P_\\mu$ is $x = 1$.**\n- Our analysis of the minimizer showed that for all $\\mu \\ge 1$, the unique global minimizer is $x = 1$.\n- We can choose $\\mu^\\star = 1$. This value is in $\\mathbb{R}_{0}$. The condition is satisfied.\n**Verdict: Correct**\n\n**D. As $\\mu \\to +\\infty$, any limit point of global minimizers of $P_\\mu$ must be a minimizer of $v(x)$, and among all minimizers of $v(x)$ it minimizes $f(x)$.**\n- This statement describes a standard theoretical result for exact penalty methods applied to infeasible problems. Let's verify it for our specific problem.\n- The minimizers of $v(x)$ are the points in the set $X_v^* = [0, 1]$.\n- We need to find the point in $X_v^*$ that minimizes $f(x) = (x-2)^2$. The function $f(x)$ is a parabola with its vertex at $x=2$. On the interval $[0, 1]$, $f(x)$ is strictly decreasing. Therefore, the minimum of $f(x)$ on $[0, 1]$ is uniquely attained at $x=1$.\n- So, the theory predicts that any limit point of minimizers $x_\\mu^*$ should be $1$.\n- From our explicit calculation of the minimizer, for $\\mu \\ge 1$, we have $x_\\mu^* = 1$. The sequence of minimizers for $\\mu \\to \\infty$ is constant at $1$.\n- The only limit point is $1$, which matches the theoretical prediction.\n**Verdict: Correct**\n\n**E. For $\\mu \\in (0,1)$, the unique global minimizer of $P_\\mu$ is $x = 2 - \\mu$.**\n- Our direct calculation of the minimizer for the case $0  \\mu  1$ yielded exactly $x_\\mu^* = 2 - \\mu$.\n- We also established that because $P_\\mu(x)$ is strictly convex, this minimizer is unique.\n**Verdict: Correct**", "answer": "$$\\boxed{ACDE}$$", "id": "3126713"}, {"introduction": "Bridging theory and computation is a crucial skill in modern optimization. In this hands-on exercise, you will implement the proximal gradient algorithm to solve a problem transformed by an exact penalty function [@problem_id:3126615]. This practice will require you to derive the necessary proximal operator from first principles and use your code to numerically verify the exactness threshold, solidifying your understanding of how these theoretical concepts are applied in practice.", "problem": "Consider the constrained optimization problem in $\\mathbb{R}^n$:\nminimize $f(x)$ subject to $x \\ge 0$ coordinate-wise, where $f(x) = \\frac{1}{2}\\lVert x - c \\rVert_2^2$ for a given vector $c \\in \\mathbb{R}^n$. An exact penalty approach replaces the constraints with a nonsmooth penalty $\\psi_\\mu(x) = \\mu \\sum_{i=1}^n \\max(0,-x_i)$, and minimizes the penalized objective $P_\\mu(x) = f(x) + \\psi_\\mu(x)$ for a penalty parameter $\\mu  0$. The proximal gradient method (Proximal Gradient (PG)) for minimizing $P_\\mu$ with a constant step-size $s  0$ alternates a gradient step on $f$ and a proximal step on $\\psi_\\mu$. Use only the following fundamental bases: the definition of the proximal operator, the definition of the gradient, the concept of Lipschitz continuity of gradients, and the Karush-Kuhn-Tucker (KKT) optimality conditions.\n\nTasks:\n1. Derive from first principles the proximal operator of the function $\\psi_\\mu(x)$, coordinate-wise, using only its definition and elementary calculus. You must not use any pre-derived \"shortcut\" formulas. The proximal operator of a function $\\phi$ at a point $y$ with parameter $t  0$ is defined by $\\operatorname{prox}_{t\\phi}(y) = \\arg\\min_{x} \\left\\{ \\frac{1}{2}\\lVert x - y \\rVert_2^2 + t \\phi(x) \\right\\}$.\n2. Using your derivation, implement the proximal gradient iteration for the composite function $P_\\mu(x) = f(x) + \\psi_\\mu(x)$, starting from $x^{(0)} = 0$, with a constant step-size $s$ satisfying $0  s \\le 1$. The gradient of $f$ must be derived from its definition.\n3. For a given $c$ and $\\mu$, determine whether the exact penalty is \"exact,\" meaning that the minimizer of $P_\\mu$ coincides with the solution to the constrained problem $\\min_{x \\ge 0} f(x)$. Use the Karush-Kuhn-Tucker (KKT) conditions to identify the threshold on $\\mu$ (in terms of the optimal multipliers) that guarantees exactness. In this special case, this threshold can be expressed in terms of the data $c$.\n4. For each test case below, run the proximal gradient method until convergence (you may stop when the successive iterates differ in $\\ell_2$-norm by less than $10^{-12}$ or after a maximum of $2000$ iterations, whichever comes first). Compare the final iterate to:\n   - the constrained solution $x^\\star_{\\text{con}} = \\arg\\min_{x \\ge 0} f(x)$ in cases where the penalty is exact (i.e., $\\mu$ at or above the threshold), and\n   - the unique minimizer of $P_\\mu$ in cases where the penalty is not exact (i.e., $\\mu$ below the threshold). In this separable setting, derive this minimizer coordinate-wise from first principles.\n5. Your program must output a single line containing a comma-separated list of the $\\ell_2$-norm differences between the final iterate and the appropriate target solution for each test case, enclosed in square brackets. Each number must be rounded to eight decimal places, with no spaces.\n\nDefinitions and facts to use as the fundamental base:\n- The proximal operator definition: $\\operatorname{prox}_{t\\phi}(y) = \\arg\\min_{x} \\left\\{ \\frac{1}{2}\\lVert x - y \\rVert_2^2 + t \\phi(x) \\right\\}$.\n- The gradient of $f(x) = \\frac{1}{2}\\lVert x - c \\rVert_2^2$ is $\\nabla f(x) = x - c$, derived from the definition of the gradient.\n- If $\\nabla f$ is $L$-Lipschitz continuous, then a constant step-size $s$ satisfying $0  s \\le \\frac{1}{L}$ ensures convergence of proximal gradient to a minimizer under standard convexity assumptions. In this problem, $L = 1$.\n- Exactness of the $\\ell_1$-type penalty hinges on choosing $\\mu$ not less than the largest optimal Lagrange multiplier from the Karush-Kuhn-Tucker (KKT) conditions of the constrained problem.\n\nTest suite:\n- Test case $1$: $c = [-2.0, 1.5, -0.3]$, $\\mu = 2.0$, $s = 1.0$. Use the constrained solution as the target.\n- Test case $2$: $c = [-2.0, 1.5, -0.3]$, $\\mu = 2.5$, $s = 0.25$. Use the constrained solution as the target.\n- Test case $3$: $c = [-2.0, -0.5]$, $\\mu = 0.7$, $s = 0.5$. Use the penalized minimizer as the target.\n- Test case $4$: $c = [0.0, -10^{-8}, 3\\cdot 10^{-9}]$, $\\mu = 10^{-8}$, $s = 1.0$. Use the constrained solution as the target.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each number rounded to eight decimal places and with no spaces, for example, $\"[0.00000000,0.12345678,0.00000001]\"$.", "solution": "The user's problem statement has been analyzed and is deemed valid. It is a well-posed problem in convex optimization, grounded in established mathematical principles, and contains all necessary information for a unique solution.\n\nThe problem asks for several derivations and a numerical implementation related to minimizing a quadratic function subject to non-negativity constraints, using an exact penalty method. The penalized problem is solved using the proximal gradient algorithm.\n\nThe primary constrained optimization problem is:\n$$ \\underset{x \\in \\mathbb{R}^n}{\\text{minimize}} \\quad f(x) = \\frac{1}{2}\\lVert x - c \\rVert_2^2 \\quad \\text{subject to} \\quad x \\ge 0 $$\nThe exact penalty method transforms this into an unconstrained problem by minimizing the composite function $P_\\mu(x) = f(x) + \\psi_\\mu(x)$, where $f(x)$ is the smooth part and $\\psi_\\mu(x)$ is the non-smooth penalty term.\nThe smooth part is $f(x) = \\frac{1}{2}\\lVert x - c \\rVert_2^2 = \\frac{1}{2}\\sum_{i=1}^n(x_i - c_i)^2$.\nThe non-smooth penalty is $\\psi_\\mu(x) = \\mu \\sum_{i=1}^n \\max(0, -x_i)$ for a penalty parameter $\\mu  0$.\n\nFirst, we address the analytical tasks required by the problem.\n\n**1. Derivation of the Proximal Operator of $\\psi_\\mu(x)$**\n\nThe proximal operator of a function $\\phi(x)$ with parameter $t  0$ is defined as:\n$$ \\operatorname{prox}_{t\\phi}(y) = \\arg\\min_{x \\in \\mathbb{R}^n} \\left\\{ \\frac{1}{2}\\lVert x - y \\rVert_2^2 + t \\phi(x) \\right\\} $$\nIn our case, the function is $t\\phi(x) = s\\psi_\\mu(x)$, where $s$ is the step-size. So we need to compute:\n$$ \\operatorname{prox}_{s\\psi_\\mu}(y) = \\arg\\min_{x \\in \\mathbb{R}^n} \\left\\{ \\frac{1}{2}\\lVert x - y \\rVert_2^2 + s \\mu \\sum_{i=1}^n \\max(0, -x_i) \\right\\} $$\nThe objective function inside the $\\arg\\min$ is separable with respect to the coordinates of $x$. This means we can minimize it by minimizing for each coordinate $x_i$ independently. For the $i$-th coordinate, the problem is:\n$$ [\\operatorname{prox}_{s\\psi_\\mu}(y)]_i = \\arg\\min_{x_i \\in \\mathbb{R}} \\left\\{ \\frac{1}{2}(x_i - y_i)^2 + s \\mu \\max(0, -x_i) \\right\\} $$\nLet $g(x_i) = \\frac{1}{2}(x_i - y_i)^2 + s \\mu \\max(0, -x_i)$. We analyze this by considering two cases for $x_i$:\n\nCase 1: $x_i \\ge 0$.\nIn this case, $\\max(0, -x_i) = 0$. The objective becomes $g_1(x_i) = \\frac{1}{2}(x_i - y_i)^2$. This is a simple quadratic, and its unconstrained minimizer is $x_i = y_i$. For this solution to be valid within the current case, we require $y_i \\ge 0$. If $y_i \\ge 0$, the minimum of $g_1(x_i)$ on $[0, \\infty)$ is at $x_i = y_i$.\n\nCase 2: $x_i  0$.\nIn this case, $\\max(0, -x_i) = -x_i$. The objective becomes $g_2(x_i) = \\frac{1}{2}(x_i - y_i)^2 - s \\mu x_i$. This is a convex quadratic. We find its minimizer by setting the derivative to zero:\n$$ \\frac{dg_2}{dx_i} = (x_i - y_i) - s\\mu = 0 \\implies x_i = y_i + s\\mu $$\nFor this solution to be valid within the current case, we require $y_i + s\\mu  0$, which is equivalent to $y_i  -s\\mu$.\n\nCase 3: Combining the cases.\nWe have determined the solution for $y_i \\ge 0$ (it is $x_i = y_i$) and for $y_i  -s\\mu$ (it is $x_i = y_i + s\\mu$). We must now consider the interval $-s\\mu \\le y_i  0$.\nIf $-s\\mu \\le y_i  0$:\n- The minimizer of $g_1(x_i)$ is $x_i=y_i  0$, which is outside the domain $x_i \\ge 0$. Since $g_1(x_i)$ is decreasing for $x_i  y_i$, its minimum on $[0, \\infty)$ occurs at the boundary point $x_i=0$.\n- The minimizer of $g_2(x_i)$ is $x_i=y_i+s\\mu \\ge 0$, which is outside the domain $x_i  0$. Since $g_2(x_i)$ is increasing for $x_i  y_i+s\\mu$, its minimum on $(-\\infty, 0)$ occurs at the boundary point $x_i=0$.\nSince both pieces of the function point towards $x_i = 0$ as the minimizer, the global minimum is at $x_i = 0$.\n\nSummarizing the three possibilities for the optimal $x_i$:\n$$ [\\operatorname{prox}_{s\\psi_\\mu}(y)]_i = \\begin{cases} y_i  \\text{if } y_i \\ge 0 \\\\ 0  \\text{if } -s\\mu  y_i  0 \\\\ y_i + s\\mu  \\text{if } y_i \\le -s\\mu \\end{cases} $$\nThis is the coordinate-wise formula for the proximal operator.\n\n**2. Proximal Gradient Iteration**\n\nThe proximal gradient (PG) method for minimizing $P_\\mu(x) = f(x) + \\psi_\\mu(x)$ is given by the iteration:\n$$ x^{(k+1)} = \\operatorname{prox}_{s\\psi_\\mu}(x^{(k)} - s \\nabla f(x^{(k)})) $$\nFirst, we derive the gradient of $f(x)$. Given $f(x) = \\frac{1}{2}\\sum_{i=1}^n(x_i - c_i)^2$, the partial derivative with respect to $x_j$ is $\\frac{\\partial f}{\\partial x_j} = \\frac{1}{2} \\cdot 2(x_j - c_j) = x_j - c_j$. Thus, the gradient is $\\nabla f(x) = x - c$. The Hessian is the identity matrix, so its largest eigenvalue is $1$, which means the gradient is $L$-Lipschitz continuous with $L=1$. The step-size $s$ must satisfy $0  s \\le 1/L = 1$, which is consistent with the problem statement.\n\nThe argument of the proximal operator in the PG iteration is:\n$$ y^{(k)} = x^{(k)} - s \\nabla f(x^{(k)}) = x^{(k)} - s(x^{(k)} - c) = (1-s)x^{(k)} + sc $$\nSo, the full update rule for iteration $k+1$ is $x^{(k+1)} = \\operatorname{prox}_{s\\psi_\\mu}(y^{(k)})$, which is computed coordinate-wise using the formula derived in the previous section.\n\n**3. Analysis of Exactness and Target Solutions**\n\nWe need to determine when the minimizer of the penalized problem $P_\\mu(x)$ coincides with the minimizer of the original constrained problem.\n\n**a) Solution to the Constrained Problem**\nThe problem is $\\min_{x \\ge 0} f(x)$. The Karush-Kuhn-Tucker (KKT) conditions provide the necessary and sufficient conditions for optimality. The Lagrangian is $\\mathcal{L}(x, \\lambda) = f(x) - \\lambda^T x = \\frac{1}{2}\\lVert x-c \\rVert_2^2 - \\sum_{i=1}^n \\lambda_i x_i$, where $\\lambda \\ge 0$ are the Lagrange multipliers.\nThe KKT conditions for a solution $x^\\star_{\\text{con}}$ with multipliers $\\lambda^\\star$ are:\n1. Stationarity: $\\nabla_x \\mathcal{L}(x^\\star_{\\text{con}}, \\lambda^\\star) = x^\\star_{\\text{con}} - c - \\lambda^\\star = 0$.\n2. Primal Feasibility: $x^\\star_{\\text{con}} \\ge 0$.\n3. Dual Feasibility: $\\lambda^\\star \\ge 0$.\n4. Complementary Slackness: $\\lambda_i^\\star x^\\star_{\\text{con}, i} = 0$ for all $i=1, \\dots, n$.\n\nFrom stationarity, $\\lambda^\\star = x^\\star_{\\text{con}} - c$. Substituting this into complementary slackness: $(x^\\star_{\\text{con}, i} - c_i)x^\\star_{\\text{con}, i} = 0$.\nFor each coordinate $i$:\n- If $x^\\star_{\\text{con}, i}  0$, then $x^\\star_{\\text{con}, i} - c_i = 0$, so $x^\\star_{\\text{con}, i} = c_i$. This requires $c_i  0$. The corresponding multiplier is $\\lambda_i^\\star = 0$.\n- If $x^\\star_{\\text{con}, i} = 0$, then from stationarity, $\\lambda_i^\\star = -c_i$. Dual feasibility requires $\\lambda_i^\\star \\ge 0$, so this case applies when $c_i \\le 0$.\nCombining these, the solution to the constrained problem is $x^\\star_{\\text{con}, i} = \\max(0, c_i)$. The optimal Lagrange multipliers are $\\lambda_i^\\star = \\max(0, -c_i)$. This solution is the projection of $c$ onto the non-negative orthant.\n\n**b) Solution to the Penalized Problem**\nThe minimizer $x^\\star_{\\text{pen}}$ of $P_\\mu(x) = f(x) + \\psi_\\mu(x)$ must satisfy the subdifferential optimality condition $0 \\in \\partial P_\\mu(x^\\star_{\\text{pen}})$.\nSince $f$ is smooth, $\\partial P_\\mu(x) = \\nabla f(x) + \\partial \\psi_\\mu(x) = x-c + \\mu \\partial \\sum_{i=1}^n\\max(0, -x_i)$. This condition is separable. For each coordinate $i$:\n$$ 0 \\in x^\\star_{\\text{pen}, i} - c_i + \\mu \\partial(\\max(0, -x_i)) $$\nThe subdifferential of $\\phi(z) = \\max(0, -z)$ is $\\partial\\phi(z) = \\{0\\}$ if $z0$, $[-1, 0]$ if $z=0$, and $\\{-1\\}$ if $z0$.\n- If $x^\\star_{\\text{pen}, i}  0$: $x^\\star_{\\text{pen}, i} - c_i + \\mu\\{0\\} = 0 \\implies x^\\star_{\\text{pen}, i} = c_i$. This choice is consistent only if $c_i  0$.\n- If $x^\\star_{\\text{pen}, i}  0$: $x^\\star_{\\text{pen}, i} - c_i + \\mu\\{-1\\} = 0 \\implies x^\\star_{\\text{pen}, i} = c_i + \\mu$. This choice is consistent only if $c_i + \\mu  0 \\implies c_i  -\\mu$.\n- If $x^\\star_{\\text{pen}, i} = 0$: $0 - c_i + \\mu[-1, 0] \\ni 0 \\implies c_i \\in [-\\mu, 0]$.\nIn summary, the minimizer of the penalized problem is:\n$$ x^\\star_{\\text{pen}, i} = \\begin{cases} c_i  \\text{if } c_i  0 \\\\ 0  \\text{if } -\\mu \\le c_i \\le 0 \\\\ c_i + \\mu  \\text{if } c_i  -\\mu \\end{cases} $$\n\n**c) Condition for Exactness**\nThe penalty is exact if $x^\\star_{\\text{pen}} = x^\\star_{\\text{con}}$. We compare their components.\n- If $c_i \\ge 0$: $x^\\star_{\\text{con}, i} = c_i$. The penalized solution is $x^\\star_{\\text{pen}, i} = c_i$ if $c_i  0$ and $x^\\star_{\\text{pen}, i} = 0$ if $c_i=0$ (since $0 \\in [-\\mu, 0]$). In both cases, $x^\\star_{\\text{con}, i} = x^\\star_{\\text{pen}, i}$.\n- If $c_i  0$: $x^\\star_{\\text{con}, i} = 0$. The penalized solution is $x^\\star_{\\text{pen}, i} = 0$ if $-\\mu \\le c_i  0$, but $x^\\star_{\\text{pen}, i} = c_i + \\mu \\ne 0$ if $c_i  -\\mu$.\nFor exactness ($x^\\star_{\\text{pen}} = x^\\star_{\\text{con}}$), we must have $x^\\star_{\\text{pen}, i} = 0$ for all $i$ where $c_i  0$. This requires that for all $i$, we avoid the case $c_i  -\\mu$. This is equivalent to requiring $\\mu \\ge -c_i$ for all $i$ where $c_i  0$. This condition can be written compactly as $\\mu \\ge \\max_{i: c_i0} (-c_i)$.\nThis threshold is precisely the largest optimal Lagrange multiplier $\\mu_{\\text{crit}} = \\max_i \\lambda_i^\\star = \\max_i \\max(0, -c_i)$. Thus, the penalty is exact if and only if $\\mu \\ge \\mu_{\\text{crit}}$.\n\n**4. Analysis for Test Cases**\n\n- **Test case 1:** $c = [-2.0, 1.5, -0.3]$, $\\mu = 2.0$, $s = 1.0$.\n  $\\mu_{\\text{crit}} = \\max(\\max(0, 2.0), \\max(0, -1.5), \\max(0, 0.3)) = \\max(2.0, 0, 0.3) = 2.0$.\n  Since $\\mu = 2.0 \\ge \\mu_{\\text{crit}}$, the penalty is exact.\n  Target solution is $x^\\star_{\\text{con}} = (\\max(0, -2.0), \\max(0, 1.5), \\max(0, -0.3)) = [0, 1.5, 0]$.\n\n- **Test case 2:** $c = [-2.0, 1.5, -0.3]$, $\\mu = 2.5$, $s = 0.25$.\n  $\\mu_{\\text{crit}} = 2.0$.\n  Since $\\mu = 2.5  \\mu_{\\text{crit}}$, the penalty is exact.\n  Target solution is $x^\\star_{\\text{con}} = [0, 1.5, 0]$.\n\n- **Test case 3:** $c = [-2.0, -0.5]$, $\\mu = 0.7$, $s = 0.5$.\n  $\\mu_{\\text{crit}} = \\max(\\max(0, 2.0), \\max(0, 0.5)) = \\max(2.0, 0.5) = 2.0$.\n  Since $\\mu = 0.7  \\mu_{\\text{crit}}$, the penalty is not exact.\n  Target solution is the penalized minimizer $x^\\star_{\\text{pen}}$:\n  $c_1 = -2.0  -\\mu = -0.7 \\implies x^\\star_{\\text{pen}, 1} = c_1 + \\mu = -2.0 + 0.7 = -1.3$.\n  $-\\mu = -0.7 \\le c_2 = -0.5 \\le 0 \\implies x^\\star_{\\text{pen}, 2} = 0$.\n  Target solution is $x^\\star_{\\text{pen}} = [-1.3, 0]$.\n\n- **Test case 4:** $c = [0.0, -10^{-8}, 3\\cdot 10^{-9}]$, $\\mu = 10^{-8}$, $s = 1.0$.\n  $\\mu_{\\text{crit}} = \\max(\\max(0, 0), \\max(0, 10^{-8}), \\max(0, -3\\cdot 10^{-9})) = \\max(0, 10^{-8}, 0) = 10^{-8}$.\n  Since $\\mu = 10^{-8} \\ge \\mu_{\\text{crit}}$, the penalty is exact.\n  Target solution is $x^\\star_{\\text{con}} = (\\max(0, 0), \\max(0, -10^{-8}), \\max(0, 3\\cdot 10^{-9})) = [0, 0, 3\\cdot 10^{-9}]$.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the optimization problem for a suite of test cases using the\n    Proximal Gradient method with an exact penalty function.\n    \"\"\"\n\n    test_cases = [\n        {'c': np.array([-2.0, 1.5, -0.3]), 'mu': 2.0, 's': 1.0},\n        {'c': np.array([-2.0, 1.5, -0.3]), 'mu': 2.5, 's': 0.25},\n        {'c': np.array([-2.0, -0.5]), 'mu': 0.7, 's': 0.5},\n        {'c': np.array([0.0, -1e-8, 3e-9]), 'mu': 1e-8, 's': 1.0},\n    ]\n\n    results = []\n    \n    # Convergence parameters\n    max_iter = 2000\n    tol = 1e-12\n\n    for case in test_cases:\n        c, mu, s = case['c'], case['mu'], case['s']\n        \n        # --- Determine the target solution ---\n        # The critical penalty parameter is the max of the optimal Lagrange multipliers\n        mu_crit = np.max(np.maximum(0, -c)) if np.any(c  0) else 0.0\n        \n        target_solution = np.zeros_like(c)\n        if mu = mu_crit:\n            # Exact penalty: target is the solution to the constrained problem\n            # x*_con = max(0, c_i) for each component\n            target_solution = np.maximum(0, c)\n        else:\n            # Not exact: target is the minimizer of the penalized problem\n            # x*_pen,i = c_i if c_i  0\n            # x*_pen,i = 0 if -mu = c_i = 0\n            # x*_pen,i = c_i + mu if c_i  -mu\n            x_pen = np.zeros_like(c)\n            mask_pos = c  0\n            mask_neg_small = (-mu = c)  (c = 0)\n            mask_neg_large = c  -mu\n            \n            x_pen[mask_pos] = c[mask_pos]\n            x_pen[mask_neg_small] = 0.0\n            x_pen[mask_neg_large] = c[mask_neg_large] + mu\n            target_solution = x_pen\n\n        # --- Proximal Gradient Method ---\n        x = np.zeros_like(c)\n        for _ in range(max_iter):\n            x_prev = x.copy()\n            \n            # Gradient step for the smooth part f(x)\n            # y = x - s * grad(f(x)) = x - s * (x - c)\n            y = (1 - s) * x + s * c\n            \n            # Proximal step for the non-smooth part psi_mu(x)\n            # prox(y)_i = y_i if y_i = 0\n            # prox(y)_i = 0 if -s*mu  y_i  0\n            # prox(y)_i = y_i + s*mu if y_i = -s*mu\n            x = np.zeros_like(y)\n            mask_pos = y = 0\n            mask_neg = y = -s * mu\n            \n            x[mask_pos] = y[mask_pos]\n            x[mask_neg] = y[mask_neg] + s * mu\n            \n            # Check for convergence\n            if np.linalg.norm(x - x_prev)  tol:\n                break\n        \n        # Calculate the L2 norm of the difference\n        diff = np.linalg.norm(x - target_solution)\n        results.append(f\"{diff:.8f}\")\n\n    # Print the final result in the specified format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3126615"}]}