{"hands_on_practices": [{"introduction": "This first practice provides a foundational exercise in understanding how merit functions operate. By comparing a squared $\\ell_2$-norm penalty with an $\\ell_1$-norm penalty, you will calculate the minimum penalty parameter $\\mu$ required to ensure a potential step is a descent direction. This analysis is crucial for building intuition about how different penalty formulations balance the competing goals of reducing the objective function and satisfying the constraints, a core concept in globalization strategies [@problem_id:3149223].", "problem": "Consider a smooth equality-constrained optimization problem with a single scalar constraint. At an iterate $x_k$, suppose we globalize a candidate step $p$ using a line search on a scalar merit function. Define two merit functions built from the same penalty parameter $\\mu  0$:\n- The squared two-norm merit: $\\phi_{2}(x;\\mu) = f(x) + \\frac{\\mu}{2}\\,c(x)^2$.\n- The one-norm merit: $\\phi_{1}(x;\\mu) = f(x) + \\mu\\,|c(x)|$.\n\nAssume the following local data at $x_k$:\n- The scalar constraint violation is $c(x_k) = 10^{-3}  0$.\n- Along the candidate step $p$, the directional derivative of the constraint is $\\nabla c(x_k)^\\top p = -1$, so moving along $p$ decreases the violation at unit rate.\n- Along $p$, the directional derivative of the objective is $\\nabla f(x_k)^\\top p = 0.05$, so moving along $p$ increases the objective.\n\nA standard backtracking Armijo line search requires that the merit function have a strictly negative directional derivative at $t=0$ to accept sufficiently small step sizes. Using only the fundamental definitions of directional derivatives and the chain rule, determine for each merit function the smallest penalty parameter $\\mu$ such that $p$ is a descent direction at $x_k$. Then compute the ratio\n$$\nR \\;=\\; \\frac{\\mu_{2,\\min}}{\\mu_{1,\\min}},\n$$\nwhere $\\mu_{2,\\min}$ corresponds to $\\phi_{2}$ and $\\mu_{1,\\min}$ corresponds to $\\phi_{1}$. Provide the numerical value of $R$ rounded to four significant figures. No units are required.", "solution": "The problem is valid as it is scientifically grounded in the principles of numerical optimization, is well-posed, objective, and internally consistent. We can proceed with a formal solution.\n\nLet a function $\\psi(x)$ be defined on $\\mathbb{R}^n$. The directional derivative of $\\psi$ at a point $x_k$ in the direction of a vector $p$ is given by\n$$\nD_p \\psi(x_k) = \\lim_{t \\to 0^+} \\frac{\\psi(x_k + tp) - \\psi(x_k)}{t}\n$$\nIf $\\psi$ is continuously differentiable at $x_k$, its directional derivative is given by $D_p \\psi(x_k) = \\nabla \\psi(x_k)^\\top p$. The direction $p$ is a descent direction for $\\psi$ at $x_k$ if $D_p \\psi(x_k)  0$. The problem requires us to find the minimum penalty parameter $\\mu$ for two different merit functions such that the given step $p$ is a descent direction.\n\nWe are provided with the following data at the iterate $x_k$:\n-   Objective function gradient component: $\\nabla f(x_k)^\\top p = 0.05$.\n-   Constraint function value: $c(x_k) = 10^{-3}$.\n-   Constraint Jacobian component: $\\nabla c(x_k)^\\top p = -1$.\n\n**Analysis of the squared two-norm merit function $\\phi_{2}(x;\\mu)$**\n\nThe squared two-norm merit function is defined as\n$$\n\\phi_{2}(x;\\mu) = f(x) + \\frac{\\mu}{2}\\,c(x)^2\n$$\nwhere $\\mu  0$ is the penalty parameter. Both $f(x)$ and $c(x)$ are smooth functions, so $\\phi_2(x;\\mu)$ is also smooth. We can find its directional derivative at $x_k$ in the direction $p$ using the chain rule:\n$$\nD_p \\phi_{2}(x_k; \\mu) = D_p f(x_k) + D_p \\left( \\frac{\\mu}{2} c(x)^2 \\right) \\Big|_{x_k}\n$$\nThe derivative of the penalty term is\n$$\nD_p \\left( \\frac{\\mu}{2} c(x)^2 \\right) \\Big|_{x_k} = \\frac{\\mu}{2} \\cdot 2 c(x_k) \\cdot D_p c(x_k) = \\mu \\, c(x_k) \\, (\\nabla c(x_k)^\\top p)\n$$\nTherefore, the directional derivative of the merit function is\n$$\nD_p \\phi_{2}(x_k; \\mu) = \\nabla f(x_k)^\\top p + \\mu \\, c(x_k) \\, (\\nabla c(x_k)^\\top p)\n$$\nFor $p$ to be a descent direction, we must have $D_p \\phi_{2}(x_k; \\mu)  0$. Substituting the given values:\n$$\n0.05 + \\mu \\, (10^{-3}) \\, (-1)  0\n$$\n$$\n0.05 - 10^{-3}\\mu  0\n$$\n$$\n0.05  10^{-3}\\mu\n$$\n$$\n\\mu  \\frac{0.05}{10^{-3}} = 50\n$$\nThe set of penalty parameters for which $p$ is a descent direction is $(50, \\infty)$. The problem asks for the smallest such parameter, which is the infimum of this set.\n$$\n\\mu_{2,\\min} = 50\n$$\n\n**Analysis of the one-norm merit function $\\phi_{1}(x;\\mu)$**\n\nThe one-norm merit function is defined as\n$$\n\\phi_{1}(x;\\mu) = f(x) + \\mu\\,|c(x)|\n$$\nTo find the directional derivative, we must handle the absolute value term $|c(x)|$. We use the fundamental definition of the directional derivative for the term $\\mu\\,|c(x)|$:\n$$\nD_p (\\mu\\,|c(x)|) \\Big|_{x_k} = \\mu \\lim_{t \\to 0^+} \\frac{|c(x_k+tp)| - |c(x_k)|}{t}\n$$\nWe are given that $c(x_k) = 10^{-3}  0$. Since $c(x)$ is a smooth function, we can use a first-order Taylor expansion for small $t  0$:\n$$\nc(x_k+tp) = c(x_k) + t (\\nabla c(x_k)^\\top p) + O(t^2)\n$$\nSubstituting the given values:\n$$\nc(x_k+tp) = 10^{-3} + t(-1) + O(t^2) = 10^{-3} - t + O(t^2)\n$$\nFor sufficiently small $t  0$, the value of $c(x_k+tp)$ will remain positive. Therefore, for $t \\to 0^+$, we have $|c(x_k+tp)| = c(x_k+tp)$ and $|c(x_k)| = c(x_k)$. The limit becomes:\n$$\n\\lim_{t \\to 0^+} \\frac{c(x_k+tp) - c(x_k)}{t}\n$$\nThis is the definition of the directional derivative of $c(x)$ at $x_k$ in the direction $p$, which is $\\nabla c(x_k)^\\top p$. So,\n$$\nD_p (\\mu\\,|c(x)|) \\Big|_{x_k} = \\mu (\\nabla c(x_k)^\\top p)\n$$\nThe directional derivative of the full merit function $\\phi_1$ is:\n$$\nD_p \\phi_{1}(x_k; \\mu) = \\nabla f(x_k)^\\top p + \\mu \\, (\\nabla c(x_k)^\\top p)\n$$\nFor $p$ to be a descent direction, we need $D_p \\phi_{1}(x_k; \\mu)  0$. Substituting the given values:\n$$\n0.05 + \\mu(-1)  0\n$$\n$$\n0.05 - \\mu  0\n$$\n$$\n\\mu  0.05\n$$\nThe smallest penalty parameter is the infimum of the set $(0.05, \\infty)$.\n$$\n\\mu_{1,\\min} = 0.05\n$$\n\n**Calculation of the Ratio R**\n\nThe problem asks for the ratio $R = \\frac{\\mu_{2,\\min}}{\\mu_{1,\\min}}$. Using the values we calculated:\n$$\nR = \\frac{50}{0.05} = \\frac{50}{5 \\times 10^{-2}} = \\frac{50}{5} \\times 10^2 = 10 \\times 100 = 1000\n$$\nThe problem specifies the answer should be rounded to four significant figures. The exact value is $1000$. To represent this with four significant figures, we can write it in scientific notation as $1.000 \\times 10^3$.", "answer": "$$\\boxed{1.000 \\times 10^{3}}$$", "id": "3149223"}, {"introduction": "While powerful, the common $\\ell_1$ exact penalty function introduces a key challenge: non-differentiability at the feasible set. This exercise delves into the mathematical consequences of this \"kink,\" requiring you to analyze its effect on the line search mechanism using the fundamental definition of directional derivatives. Successfully navigating this problem will deepen your understanding of why specialized techniques are needed to handle non-smoothness and ensure robust convergence [@problem_id:3149246].", "problem": "Consider the equality-constrained nonlinear program with a single variable $x \\in \\mathbb{R}$:\nminimize $f(x)$ subject to $g(x) = 0$,\nwhere $f(x) = (x - 2)^{2}$ and $g(x) = x^{2} - 1$. Let the exact penalty merit function be $\\Phi_{\\rho}(x) = f(x) + \\rho \\, |g(x)|$ with penalty parameter $\\rho > 0$. \n\nTask A: Using only core definitions of absolute value and directional derivatives, explain why $\\Phi_{\\rho}(x)$ has a nondifferentiable kink at every feasible point (that is, any $x$ satisfying $g(x) = 0$). Your explanation should explicitly reference the behavior of $|g(x)|$ at feasibility and how it affects differentiability of $\\Phi_{\\rho}(x)$.\n\nTask B: Globalization by line search relies on a sufficient-decrease (Armijo) condition. Suppose we stand at the feasible point $x^{\\ast} = 1$ and consider the unit search direction $d = 1$. Let the penalty parameter be $\\rho = \\frac{1}{2}$ and let the Armijo parameter be $c_{1} = 0.1$. If the line search uses the Clarke directional derivative (that is, the one-sided slope along $d$ at $x^{\\ast}$) as the slope estimate, compute the largest positive step length $\\alpha_{\\max}$ that satisfies the Armijo test\n$$\n\\Phi_{\\rho}(x^{\\ast} + \\alpha d) \\le \\Phi_{\\rho}(x^{\\ast}) + c_{1} \\, \\alpha \\, s_{g},\n$$\nwhere $s_{g}$ denotes the directional derivative of $\\Phi_{\\rho}$ at $x^{\\ast}$ along $d$. Express your final answer as an exact number. No rounding is required.\n\nTask C: Briefly propose a subgradient safeguard that a practical line search could employ near feasibility to handle the kink robustly. Your proposal should be stated in terms of quantities computable from $f$, $g$, $\\rho$, and the search direction $d$, and should not rely on any external “shortcut” formulas beyond fundamental definitions of directional derivatives and subgradients.", "solution": "The problem is validated as self-contained, scientifically grounded in the field of nonlinear optimization, and well-posed. All necessary functions, parameters, and conditions are explicitly provided, and there are no internal contradictions. We may proceed with the solution.\n\nThe problem asks for analysis of an equality-constrained nonlinear program, where we want to minimize $f(x) = (x-2)^2$ subject to $g(x) = x^2-1=0$. The optimization is approached using an exact penalty merit function $\\Phi_{\\rho}(x) = f(x) + \\rho \\, |g(x)|$ with a penalty parameter $\\rho > 0$.\n\n**Task A: Explanation of Nondifferentiability**\n\nA function is differentiable at a point if its directional derivative exists in all directions and is a linear function of the direction vector. The directional derivative of a function $\\Psi(x)$ at a point $x$ in the direction $d$ is defined as:\n$$\n\\Psi'(x; d) = \\lim_{\\alpha \\to 0^+} \\frac{\\Psi(x + \\alpha d) - \\Psi(x)}{\\alpha}\n$$\nFor $\\Psi(x)$ to be differentiable at $x$, it must be the case that $\\Psi'(x; d) = -\\Psi'(x; -d)$ for all directions $d$.\n\nLet $x_{\\text{feas}}$ be a feasible point, meaning $g(x_{\\text{feas}}) = 0$. The feasible points for the given problem are the roots of $x^2-1=0$, which are $x=1$ and $x=-1$. At any such point, the value of the merit function is $\\Phi_{\\rho}(x_{\\text{feas}}) = f(x_{\\text{feas}}) + \\rho |g(x_{\\text{feas}})| = f(x_{\\text{feas}})$.\n\nLet's compute the directional derivative of $\\Phi_{\\rho}(x)$ at $x_{\\text{feas}}$ in a direction $d$.\n$$\n\\Phi_{\\rho}'(x_{\\text{feas}}; d) = \\lim_{\\alpha \\to 0^+} \\frac{\\Phi_{\\rho}(x_{\\text{feas}} + \\alpha d) - \\Phi_{\\rho}(x_{\\text{feas}})}{\\alpha}\n$$\nSubstituting the definitions of $\\Phi_{\\rho}$ and using $g(x_{\\text{feas}})=0$:\n$$\n\\Phi_{\\rho}'(x_{\\text{feas}}; d) = \\lim_{\\alpha \\to 0^+} \\frac{[f(x_{\\text{feas}} + \\alpha d) + \\rho |g(x_{\\text{feas}} + \\alpha d)|] - f(x_{\\text{feas}})}{\\alpha}\n$$\nThis limit can be split, since both $f$ and $g$ are differentiable:\n$$\n\\Phi_{\\rho}'(x_{\\text{feas}}; d) = \\lim_{\\alpha \\to 0^+} \\frac{f(x_{\\text{feas}} + \\alpha d) - f(x_{\\text{feas}})}{\\alpha} + \\rho \\lim_{\\alpha \\to 0^+} \\frac{|g(x_{\\text{feas}} + \\alpha d)|}{\\alpha}\n$$\nThe first term is the definition of the directional derivative of $f(x)$, which is $f'(x_{\\text{feas}})d$.\nFor the second term, we use a first-order Taylor expansion of $g(x)$ around $x_{\\text{feas}}$:\n$g(x_{\\text{feas}} + \\alpha d) = g(x_{\\text{feas}}) + \\alpha \\, g'(x_{\\text{feas}})d + O(\\alpha^2) = \\alpha \\, g'(x_{\\text{feas}})d + O(\\alpha^2)$.\nSubstituting this into the limit:\n$$\n\\lim_{\\alpha \\to 0^+} \\frac{|\\alpha \\, g'(x_{\\text{feas}})d + O(\\alpha^2)|}{\\alpha} = \\lim_{\\alpha \\to 0^+} \\frac{\\alpha |g'(x_{\\text{feas}})d + O(\\alpha)|}{\\alpha} = |g'(x_{\\text{feas}})d|\n$$\nCombining the terms, the directional derivative of the merit function at a feasible point is:\n$$\n\\Phi_{\\rho}'(x_{\\text{feas}}; d) = f'(x_{\\text{feas}})d + \\rho |g'(x_{\\text{feas}})d|\n$$\nThe term $|g'(x_{\\text{feas}})d|$ is generally not linear in $d$. For $\\Phi_{\\rho}$ to be differentiable at $x_{\\text{feas}}$, we would need $\\Phi_{\\rho}'(x_{\\text{feas}}; d) = -\\Phi_{\\rho}'(x_{\\text{feas}}; -d)$. Let's check this condition:\n$$\n-\\Phi_{\\rho}'(x_{\\text{feas}}; -d) = -[f'(x_{\\text{feas}})(-d) + \\rho |g'(x_{\\text{feas}})(-d)|] = -[-f'(x_{\\text{feas}})d + \\rho |-g'(x_{\\text{feas}})d|] = f'(x_{\\text{feas}})d - \\rho |g'(x_{\\text{feas}})d|\n$$\nFor differentiability, we need $f'(x_{\\text{feas}})d + \\rho |g'(x_{\\text{feas}})d| = f'(x_{\\text{feas}})d - \\rho |g'(x_{\\text{feas}})d|$, which simplifies to $2\\rho |g'(x_{\\text{feas}})d| = 0$. Since $\\rho  0$, this requires $g'(x_{\\text{feas}})d = 0$.\n\nFor our specific problem, $g'(x) = 2x$. At the feasible points $x=1$ and $x=-1$, the gradient is $g'(1)=2$ and $g'(-1)=-2$, both of which are non-zero. Therefore, for any direction $d \\ne 0$, we have $g'(x_{\\text{feas}})d \\neq 0$. Consequently, the condition $g'(x_{\\text{feas}})d=0$ is not satisfied for all directions $d$, and the function $\\Phi_{\\rho}(x)$ is not differentiable at any feasible point. The presence of the term $|g'(x_{\\text{feas}})d|$ creates a \"kink\" in the function profile at $x_{\\text{feas}}$.\n\n**Task B: Armijo Condition Calculation**\n\nWe are given the point $x^{\\ast} = 1$, search direction $d=1$, penalty parameter $\\rho = \\frac{1}{2}$, and Armijo parameter $c_{1} = 0.1 = \\frac{1}{10}$. We need to find the largest $\\alpha_{\\max}0$ satisfying the Armijo condition:\n$$\n\\Phi_{\\rho}(x^{\\ast} + \\alpha d) \\le \\Phi_{\\rho}(x^{\\ast}) + c_{1} \\, \\alpha \\, s_{g}\n$$\nFirst, we compute each term in the inequality.\n\n1.  **Value at $x^{\\ast}$**:\n    $x^{\\ast}=1$ is feasible since $g(1) = 1^2 - 1 = 0$.\n    $f(x^{\\ast}) = f(1) = (1-2)^2 = 1$.\n    $\\Phi_{\\rho}(x^{\\ast}) = \\Phi_{\\frac{1}{2}}(1) = f(1) + \\frac{1}{2}|g(1)| = 1 + \\frac{1}{2}|0| = 1$.\n\n2.  **Directional derivative $s_{g}$**:\n    $s_{g}$ is the directional derivative of $\\Phi_{\\rho}$ at $x^{\\ast}=1$ along $d=1$. Using the formula from Task A:\n    $s_{g} = \\Phi_{\\rho}'(1; 1) = f'(1)(1) + \\rho |g'(1)(1)|$.\n    We have $f'(x) = 2(x-2)$, so $f'(1) = 2(1-2) = -2$.\n    We have $g'(x) = 2x$, so $g'(1) = 2(1) = 2$.\n    $s_{g} = (-2) + \\frac{1}{2}|2| = -2 + 1 = -1$.\n    The reference to the Clarke directional derivative is consistent, as for this function at this point, it coincides with the standard one-sided directional derivative.\n\n3.  **Value at the trial point**:\n    The trial point is $x^{\\ast} + \\alpha d = 1 + \\alpha$. For $\\alpha  0$.\n    $f(1+\\alpha) = ((1+\\alpha) - 2)^2 = (\\alpha - 1)^2 = \\alpha^2 - 2\\alpha + 1$.\n    $g(1+\\alpha) = (1+\\alpha)^2 - 1 = 1 + 2\\alpha + \\alpha^2 - 1 = \\alpha^2 + 2\\alpha$.\n    Since $\\alpha  0$, $g(1+\\alpha) = \\alpha(\\alpha+2)  0$, so $|g(1+\\alpha)| = \\alpha^2 + 2\\alpha$.\n    $\\Phi_{\\rho}(1+\\alpha) = f(1+\\alpha) + \\rho |g(1+\\alpha)| = (\\alpha^2 - 2\\alpha + 1) + \\frac{1}{2}(\\alpha^2 + 2\\alpha) = \\frac{3}{2}\\alpha^2 - \\alpha + 1$.\n\nNow, we substitute these into the Armijo inequality:\n$$\n\\frac{3}{2}\\alpha^2 - \\alpha + 1 \\le 1 + \\left(\\frac{1}{10}\\right) \\alpha (-1)\n$$\n$$\n\\frac{3}{2}\\alpha^2 - \\alpha \\le -\\frac{1}{10}\\alpha\n$$\nMove all terms to one side:\n$$\n\\frac{3}{2}\\alpha^2 - \\alpha + \\frac{1}{10}\\alpha \\le 0\n$$\n$$\n\\frac{3}{2}\\alpha^2 - \\frac{9}{10}\\alpha \\le 0\n$$\nFactor out $\\alpha$:\n$$\n\\alpha \\left(\\frac{3}{2}\\alpha - \\frac{9}{10}\\right) \\le 0\n$$\nSince we are seeking a positive step length $\\alpha  0$, we can divide by $\\alpha$ without changing the inequality direction:\n$$\n\\frac{3}{2}\\alpha - \\frac{9}{10} \\le 0\n$$\n$$\n\\frac{3}{2}\\alpha \\le \\frac{9}{10}\n$$\n$$\n\\alpha \\le \\frac{9}{10} \\cdot \\frac{2}{3} = \\frac{18}{30} = \\frac{3}{5}\n$$\nThe Armijo condition is satisfied for all $\\alpha$ in the interval $(0, \\frac{3}{5}]$. The largest positive step length is therefore $\\alpha_{\\max} = \\frac{3}{5}$.\n\n**Task C: Subgradient Safeguard Proposal**\n\nThe challenge in a line search for a nonsmooth merit function occurs when an iterate $x_k$ is very close to a point of nondifferentiability (i.e., when $|g(x_k)|$ is small). At such a point $x_k$ where $g(x_k) \\neq 0$, the merit function $\\Phi_{\\rho}(x)$ is differentiable, and its directional derivative along direction $d$ is:\n$$\ns_k = \\nabla\\Phi_{\\rho}(x_k)^Td = f'(x_k)d + \\rho \\, \\text{sign}(g(x_k)) g'(x_k)d\n$$\nIf a step $\\alpha$ is taken such that the line search crosses the feasible manifold (i.e., $g(x_k)$ and $g(x_k+\\alpha d)$ have opposite signs), the gradient of the merit function changes abruptly. The slope $s_k$ becomes a poor predictor of the function's behavior, potentially causing the line search to fail or require many backtracks.\n\nA robust safeguard can be implemented by modifying the slope used in the Armijo condition when the iterate is near the feasible set. The safeguard should use a slope model that accounts for the kink.\n\n**Proposal:** A practical line search could employ the following subgradient safeguard:\n\n1.  Define a small positive tolerance, $\\tau$.\n2.  At the current iterate $x$, compute the constraint value $g(x)$ and its derivative $g'(x)$.\n3.  Compute the derivatives $f'(x)$ and the search direction $d$.\n4.  If $|g(x)| \\ge \\tau$, the iterate is considered far from the kink. The standard directional derivative is used as the slope in the Armijo test:\n    $$s_{\\text{slope}} = f'(x)d + \\rho \\, \\text{sign}(g(x)) g'(x)d$$\n5.  If $|g(x)|  \\tau$, the iterate is close to the kink. To prevent the line search from being misled by a potentially overly optimistic descent estimate, the slope is replaced by the directional derivative at the kink itself, which is always greater than or equal to the standard one:\n    $$s_{\\text{slope}} = f'(x)d + \\rho \\, |g'(x)d|$$\nThis safeguarded slope $s_{\\text{slope}}$ is then used in the Armijo condition: $\\Phi_{\\rho}(x + \\alpha d) \\le \\Phi_{\\rho}(x) + c_{1} \\, \\alpha \\, s_{\\text{slope}}$. This procedure uses only quantities computable from the problem data ($f, g, \\rho$) and the current iterate/direction, and robustly handles the geometry of the kink by using a more conservative model for local descent when near the feasible set.", "answer": "$$\\boxed{\\frac{3}{5}}$$", "id": "3149246"}, {"introduction": "Theory comes to life in this hands-on coding practice, where you will observe the practical effects of non-smooth penalties on an optimization algorithm's behavior. By implementing a gradient descent method with both a non-smooth $\\ell_1$ merit function and its smoothed counterparts, you can directly measure phenomena like \"zig-zagging\" and excessive backtracking. This exercise provides tangible proof of how smoothing strategies can improve an algorithm's performance and illustrates the importance of globalization techniques in practice [@problem_id:3149286].", "problem": "Consider unconstrained minimization with globalization through line search for a merit function that combines a smooth objective and a penalty on an equality constraint. Let the objective be $f(\\mathbf{x}) = (x_1 - 1)^2 + \\kappa (x_2 - 1)^2$ with $\\mathbf{x} \\in \\mathbb{R}^2$, and let the single equality constraint residual be $c(\\mathbf{x}) = x_1 + x_2 - 1$. A general merit function is $\\Phi(\\mathbf{x}) = f(\\mathbf{x}) + \\mu \\,\\psi(c(\\mathbf{x}))$, where $\\mu  0$ is a penalty parameter and $\\psi$ is a penalty mapping from $\\mathbb{R}$ to $\\mathbb{R}_{\\ge 0}$.\n\nFundamental base and definitions:\n- Use the gradient-based descent method with backtracking line search and the Armijo sufficient decrease condition. At iteration $k$, the descent direction is $p_k = -\\nabla \\Phi(\\mathbf{x}_k)$ and the step length $\\alpha_k$ is chosen by backtracking until the Armijo condition $\\Phi(\\mathbf{x}_k + \\alpha_k p_k) \\le \\Phi(\\mathbf{x}_k) + \\sigma \\alpha_k \\nabla \\Phi(\\mathbf{x}_k)^\\top p_k$ holds for a fixed $\\sigma \\in (0,1)$.\n- The backtracking reduces the step length by a constant factor $\\beta \\in (0,1)$ until the Armijo condition is satisfied.\n- Globalization refers to the use of the merit function and line search to ensure convergence from arbitrary starting points.\n\nNonsmooth and smoothed penalties:\n- Nonsmooth penalty: $\\psi_{\\text{ns}}(t) = |t|$, which is nondifferentiable at $t = 0$ and can cause zig-zagging when coupled with gradient-based methods.\n- Smoothed penalties to mitigate zig-zagging:\n  1. Smooth absolute value: $\\psi_{\\sqrt{}}(t) = \\sqrt{t^2 + \\varepsilon^2}$, with $\\varepsilon  0$, a differentiable approximation of $|t|$.\n  2. Huber-type smoothing: $\\psi_{\\text{Huber}}(t) = \\begin{cases} \\dfrac{t^2}{2\\varepsilon},  |t| \\le \\varepsilon \\\\ |t| - \\dfrac{\\varepsilon}{2},  |t|  \\varepsilon \\end{cases}$, with $\\varepsilon  0$, which is continuously differentiable and agrees with the absolute value outside a neighborhood of the origin.\n\nYour task:\n- Implement gradient descent with backtracking line search using the Armijo condition for both the nonsmooth merit $\\Phi_{\\text{ns}}(\\mathbf{x}) = f(\\mathbf{x}) + \\mu |c(\\mathbf{x})|$ and a smoothed merit $\\Phi_{\\text{sm}}(\\mathbf{x}) = f(\\mathbf{x}) + \\mu \\psi_{\\text{sm}}(c(\\mathbf{x}))$, where $\\psi_{\\text{sm}}$ is either $\\psi_{\\sqrt{}}$ or $\\psi_{\\text{Huber}}$ as specified per test case.\n- Use the following fixed line search parameters: Armijo parameter $\\sigma = 10^{-4}$, backtracking reduction factor $\\beta = \\tfrac{1}{2}$, maximum number of backtracking reductions per iteration $M_{\\text{bt}} = 50$, termination tolerance on the gradient norm $\\tau = 10^{-6}$, and maximum iterations $N_{\\max} = 200$.\n- For the nonsmooth case at $c(\\mathbf{x}) = 0$, choose the subgradient $\\nabla |c| = \\operatorname{sign}(c) \\nabla c$ with $\\operatorname{sign}(0) = 0$ for definiteness.\n\nZig-zagging and globalization metrics:\n- Define the zig-zag count as the number of iterations $k \\ge 1$ for which the angle between successive descent directions $p_{k-1}$ and $p_k$ exceeds $\\frac{\\pi}{2}$, measured in radians. Angles must be computed and compared in radians.\n- Define the constraint sign-flip count as the number of iterations $k \\ge 1$ for which $\\operatorname{sign}(c(\\mathbf{x}_k)) \\neq \\operatorname{sign}(c(\\mathbf{x}_{k-1}))$.\n- Define the backtracking count as the total number of times the backtracking line search reduces the step length (i.e., the total number of unsuccessful Armijo tests that lead to $\\alpha \\leftarrow \\beta \\alpha$).\n- Record the final merit function value $\\Phi(\\mathbf{x}_{\\text{final}})$ upon termination.\n\nTest suite:\nFor each test case, run the algorithm twice: once with the nonsmooth merit and once with the specified smoothed merit. Use the stated parameters exactly.\n\n- Test case $1$: $\\mu = 50.0$, $\\kappa = 100.0$, $\\mathbf{x}_0 = (2.0, -1.0)$, $\\varepsilon = 10^{-3}$, smoothing method $\\psi_{\\sqrt{}}$.\n- Test case $2$: $\\mu = 200.0$, $\\kappa = 10.0$, $\\mathbf{x}_0 = (0.8, 0.8)$, $\\varepsilon = 10^{-3}$, smoothing method $\\psi_{\\sqrt{}}$.\n- Test case $3$: $\\mu = 100.0$, $\\kappa = 1000.0$, $\\mathbf{x}_0 = (-1.0, 2.0)$, $\\varepsilon = 10^{-4}$, smoothing method $\\psi_{\\text{Huber}}$.\n- Test case $4$: $\\mu = 20.0$, $\\kappa = 1.0$, $\\mathbf{x}_0 = (0.6, 0.4)$, $\\varepsilon = 10^{-3}$, smoothing method $\\psi_{\\sqrt{}}$.\n\nOutput specification:\n- For each test case, output a list of eight values in the order $[\\text{zigzag}_{\\text{ns}}, \\text{zigzag}_{\\text{sm}}, \\text{signflip}_{\\text{ns}}, \\text{signflip}_{\\text{sm}}, \\text{backtracks}_{\\text{ns}}, \\text{backtracks}_{\\text{sm}}, \\Phi_{\\text{ns, final}}, \\Phi_{\\text{sm, final}}]$. All angles, comparisons, and counts must use radians. Each value must be a boolean, integer, or floating-point number.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to a test case and is itself a list containing the eight values described above (for example, $[[\\dots],[\\dots],[\\dots],[\\dots]]$).", "solution": "The problem requires the implementation of a gradient descent algorithm with a backtracking line search to minimize a merit function. This merit function is composed of a quadratic objective function and a penalty term for an equality constraint. The core of the task is to compare the behavior of the algorithm when using a nonsmooth absolute value penalty versus two different smoothed approximations of it. The performance is evaluated based on metrics designed to quantify convergence difficulties like zig-zagging.\n\nFirst, we define the components of the problem.\nThe objective function is $f(\\mathbf{x}): \\mathbb{R}^2 \\to \\mathbb{R}$, given by:\n$$ f(\\mathbf{x}) = (x_1 - 1)^2 + \\kappa (x_2 - 1)^2 $$\nIts gradient, $\\nabla f(\\mathbf{x})$, is:\n$$ \\nabla f(\\mathbf{x}) = \\begin{pmatrix} 2(x_1 - 1) \\\\ 2\\kappa(x_2 - 1) \\end{pmatrix} $$\nThe equality constraint is expressed through a residual function $c(\\mathbf{x}): \\mathbb{R}^2 \\to \\mathbb{R}$:\n$$ c(\\mathbf{x}) = x_1 + x_2 - 1 $$\nThe gradient of the constraint residual, $\\nabla c(\\mathbf{x})$, is a constant vector:\n$$ \\nabla c(\\mathbf{x}) = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} $$\n\nThe merit function, $\\Phi(\\mathbf{x})$, combines the objective and constraint penalty:\n$$ \\Phi(\\mathbf{x}) = f(\\mathbf{x}) + \\mu \\psi(c(\\mathbf{x})) $$\nwhere $\\mu > 0$ is the penalty parameter and $\\psi$ is a penalty mapping. We analyze three forms of $\\psi$.\n\n1.  **Nonsmooth Merit Function ($\\Phi_{\\text{ns}}$)**\n    The penalty is the absolute value function, $\\psi_{\\text{ns}}(t) = |t|$.\n    The merit function is:\n    $$ \\Phi_{\\text{ns}}(\\mathbf{x}) = (x_1 - 1)^2 + \\kappa (x_2 - 1)^2 + \\mu |x_1 + x_2 - 1| $$\n    This function is not differentiable where $c(\\mathbf{x}) = 0$. We use its subgradient, defined using the chain rule for subdifferentials. The subderivative of $|t|$ is $\\operatorname{sign}(t)$ for $t \\neq 0$ and the interval $[-1, 1]$ for $t=0$. The problem specifies using $\\operatorname{sign}(0) = 0$.\n    The subgradient is:\n    $$ \\nabla \\Phi_{\\text{ns}}(\\mathbf{x}) = \\nabla f(\\mathbf{x}) + \\mu \\operatorname{sign}(c(\\mathbf{x})) \\nabla c(\\mathbf{x}) = \\begin{pmatrix} 2(x_1 - 1) \\\\ 2\\kappa(x_2 - 1) \\end{pmatrix} + \\mu \\operatorname{sign}(x_1 + x_2 - 1) \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} $$\n\n2.  **Smooth Absolute Value Merit Function ($\\Phi_{\\sqrt{}}$)**\n    The penalty is a smooth approximation of the absolute value, $\\psi_{\\sqrt{}}(t) = \\sqrt{t^2 + \\varepsilon^2}$, with $\\varepsilon > 0$.\n    The merit function is:\n    $$ \\Phi_{\\sqrt{}}(\\mathbf{x}) = f(\\mathbf{x}) + \\mu \\sqrt{c(\\mathbf{x})^2 + \\varepsilon^2} $$\n    This function is differentiable everywhere. Its gradient is found using the chain rule. The derivative of $\\psi_{\\sqrt{}}(t)$ is $\\psi'_{\\sqrt{}}(t) = \\frac{t}{\\sqrt{t^2 + \\varepsilon^2}}$.\n    The gradient is:\n    $$ \\nabla \\Phi_{\\sqrt{}}(\\mathbf{x}) = \\nabla f(\\mathbf{x}) + \\mu \\frac{c(\\mathbf{x})}{\\sqrt{c(\\mathbf{x})^2 + \\varepsilon^2}} \\nabla c(\\mathbf{x}) = \\begin{pmatrix} 2(x_1 - 1) \\\\ 2\\kappa(x_2 - 1) \\end{pmatrix} + \\mu \\frac{x_1 + x_2 - 1}{\\sqrt{(x_1 + x_2 - 1)^2 + \\varepsilon^2}} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} $$\n\n3.  **Huber-type Smoothed Merit Function ($\\Phi_{\\text{Huber}}$)**\n    The penalty is the Huber loss function, $\\psi_{\\text{Huber}}(t)$, which is continuously differentiable.\n    $$ \\psi_{\\text{Huber}}(t) = \\begin{cases} \\frac{t^2}{2\\varepsilon},  |t| \\le \\varepsilon \\\\ |t| - \\frac{\\varepsilon}{2},  |t| > \\varepsilon \\end{cases} $$\n    The merit function is $\\Phi_{\\text{Huber}}(\\mathbf{x}) = f(\\mathbf{x}) + \\mu \\psi_{\\text{Huber}}(c(\\mathbf{x}))$. The derivative of $\\psi_{\\text{Huber}}(t)$ is:\n    $$ \\psi'_{\\text{Huber}}(t) = \\begin{cases} \\frac{t}{\\varepsilon},  |t| \\le \\varepsilon \\\\ \\operatorname{sign}(t),  |t| > \\varepsilon \\end{cases} $$\n    The gradient of the merit function is:\n    $$ \\nabla \\Phi_{\\text{Huber}}(\\mathbf{x}) = \\nabla f(\\mathbf{x}) + \\mu \\psi'_{\\text{Huber}}(c(\\mathbf{x})) \\nabla c(\\mathbf{x}) = \\begin{pmatrix} 2(x_1 - 1) \\\\ 2\\kappa(x_2 - 1) \\end{pmatrix} + \\mu \\psi'_{\\text{Huber}}(x_1+x_2-1) \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} $$\n\nThe optimization algorithm is gradient descent. At each iteration $k$, starting from an initial point $\\mathbf{x}_0$, the next point $\\mathbf{x}_{k+1}$ is found by:\n$$ \\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k p_k $$\nwhere $p_k = -\\nabla \\Phi(\\mathbf{x}_k)$ is the descent direction (or a subgradient-based direction for $\\Phi_{\\text{ns}}$). The step length $\\alpha_k$ is determined by a backtracking line search, which starts with $\\alpha=1$ and successively reduces it by a factor $\\beta \\in (0,1)$ until the Armijo sufficient decrease condition is met:\n$$ \\Phi(\\mathbf{x}_k + \\alpha p_k) \\le \\Phi(\\mathbf{x}_k) + \\sigma \\alpha \\nabla \\Phi(\\mathbf{x}_k)^\\top p_k $$\nfor a fixed $\\sigma \\in (0,1)$. The process terminates when the norm of the gradient (or subgradient) is below a tolerance $\\tau$, i.e., $\\|\\nabla \\Phi(\\mathbf{x}_k)\\|_2 \\le \\tau$, or when a maximum number of iterations $N_{\\max}$ is reached.\n\nThe following metrics are computed to evaluate the algorithm's performance:\n- **Zig-zag count**: The number of iterations $k \\ge 1$ where the angle between successive descent directions $p_{k-1}$ and $p_k$ is greater than $\\frac{\\pi}{2}$ radians. This is calculated as the count of $k \\ge 1$ for which $\\arccos\\left(\\frac{p_k^\\top p_{k-1}}{\\|p_k\\|_2 \\|p_{k-1}\\|_2}\\right) > \\frac{\\pi}{2}$.\n- **Constraint sign-flip count**: The number of iterations $k \\ge 1$ where the sign of the constraint residual changes, i.e., $\\operatorname{sign}(c(\\mathbf{x}_k)) \\neq \\operatorname{sign}(c(\\mathbf{x}_{k-1}))$.\n- **Backtracking count**: The total number of times the step length $\\alpha$ is reduced during the entire optimization run.\n- **Final merit function value**: The value of $\\Phi(\\mathbf{x}_{\\text{final}})$ at the termination point.\n\nThe implementation will consist of a main loop that performs the gradient descent, applying the specified merit function and its gradient. After termination, the histories of iterates and descent directions are used to compute the required metrics. This process is repeated for each test case, once for the nonsmooth penalty and once for the specified smoothed penalty.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Global parameters defined in the problem statement\n    SIGMA = 1e-4\n    BETA = 0.5\n    M_BT = 50\n    TAU = 1e-6\n    N_MAX = 200\n\n    # Objective function and its gradient\n    def f(x, kappa):\n        return (x[0] - 1.0)**2 + kappa * (x[1] - 1.0)**2\n\n    def grad_f(x, kappa):\n        return np.array([2.0 * (x[0] - 1.0), 2.0 * kappa * (x[1] - 1.0)])\n\n    # Constraint residual and its gradient\n    def c(x):\n        return x[0] + x[1] - 1.0\n\n    def grad_c():\n        return np.array([1.0, 1.0])\n\n    # --- Merit Function Classes ---\n    class MeritFunction:\n        def __init__(self, kappa, mu):\n            self.kappa = kappa\n            self.mu = mu\n\n        def phi(self, x):\n            raise NotImplementedError\n\n        def grad_phi(self, x):\n            raise NotImplementedError\n\n    class NonsmoothMerit(MeritFunction):\n        def phi(self, x):\n            return f(x, self.kappa) + self.mu * np.abs(c(x))\n\n        def grad_phi(self, x):\n            c_val = c(x)\n            return grad_f(x, self.kappa) + self.mu * np.sign(c_val) * grad_c()\n\n    class SqrtMerit(MeritFunction):\n        def __init__(self, kappa, mu, epsilon):\n            super().__init__(kappa, mu)\n            self.epsilon = epsilon\n            self.epsilon_sq = epsilon**2\n\n        def phi(self, x):\n            c_val = c(x)\n            return f(x, self.kappa) + self.mu * np.sqrt(c_val**2 + self.epsilon_sq)\n\n        def grad_phi(self, x):\n            c_val = c(x)\n            denominator = np.sqrt(c_val**2 + self.epsilon_sq)\n            penalty_grad_factor = self.mu * c_val / denominator if denominator > 0 else 0\n            return grad_f(x, self.kappa) + penalty_grad_factor * grad_c()\n\n    class HuberMerit(MeritFunction):\n        def __init__(self, kappa, mu, epsilon):\n            super().__init__(kappa, mu)\n            self.epsilon = epsilon\n\n        def phi(self, x):\n            c_val = c(x)\n            if np.abs(c_val) = self.epsilon:\n                penalty = c_val**2 / (2.0 * self.epsilon)\n            else:\n                penalty = np.abs(c_val) - self.epsilon / 2.0\n            return f(x, self.kappa) + self.mu * penalty\n\n        def grad_phi(self, x):\n            c_val = c(x)\n            if np.abs(c_val) = self.epsilon:\n                penalty_deriv = c_val / self.epsilon\n            else:\n                penalty_deriv = np.sign(c_val)\n            return grad_f(x, self.kappa) + self.mu * penalty_deriv * grad_c()\n\n    # --- Optimizer ---\n    def run_optimizer(x0, merit_function):\n        x = np.array(x0, dtype=float)\n        \n        x_history = [x]\n        p_history = []\n        total_backtracks = 0\n        \n        for _ in range(N_MAX):\n            grad = merit_function.grad_phi(x)\n            \n            grad_norm = np.linalg.norm(grad)\n            if grad_norm = TAU:\n                break\n                \n            p = -grad\n            p_history.append(p)\n            \n            # Backtracking line search\n            phi_k = merit_function.phi(x)\n            grad_p_dot = np.dot(grad, p)\n            \n            alpha = 1.0\n            num_bt = 0\n            while num_bt  M_BT:\n                x_next = x + alpha * p\n                if merit_function.phi(x_next) = phi_k + SIGMA * alpha * grad_p_dot:\n                    break\n                alpha *= BETA\n                total_backtracks += 1\n                num_bt += 1\n            \n            x = x + alpha * p\n            x_history.append(x)\n            \n        x_final = x_history[-1]\n        phi_final = merit_function.phi(x_final)\n\n        # Zig-zag count\n        zigzag_count = 0\n        if len(p_history) > 1:\n            for i in range(1, len(p_history)):\n                p_prev, p_curr = p_history[i-1], p_history[i]\n                norm_prev, norm_curr = np.linalg.norm(p_prev), np.linalg.norm(p_curr)\n                if norm_prev > 1e-12 and norm_curr > 1e-12:\n                    cos_theta = np.dot(p_curr, p_prev) / (norm_curr * norm_prev)\n                    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n                    angle = np.arccos(cos_theta)\n                    if angle > np.pi / 2.0:\n                        zigzag_count += 1\n        \n        # Sign-flip count\n        signflip_count = 0\n        if len(x_history) > 1:\n            for i in range(1, len(x_history)):\n                c_prev = c(x_history[i-1])\n                c_curr = c(x_history[i])\n                if np.sign(c_curr) != np.sign(c_prev):\n                    signflip_count += 1\n                    \n        return zigzag_count, signflip_count, total_backtracks, phi_final\n\n    # --- Test Suite ---\n    test_cases = [\n        {'mu': 50.0, 'kappa': 100.0, 'x0': (2.0, -1.0), 'epsilon': 1e-3, 'smoothing': 'sqrt'},\n        {'mu': 200.0, 'kappa': 10.0, 'x0': (0.8, 0.8), 'epsilon': 1e-3, 'smoothing': 'sqrt'},\n        {'mu': 100.0, 'kappa': 1000.0, 'x0': (-1.0, 2.0), 'epsilon': 1e-4, 'smoothing': 'huber'},\n        {'mu': 20.0, 'kappa': 1.0, 'x0': (0.6, 0.4), 'epsilon': 1e-3, 'smoothing': 'sqrt'},\n    ]\n    \n    all_results = []\n    \n    for case in test_cases:\n        mu, kappa, x0, epsilon = case['mu'], case['kappa'], case['x0'], case['epsilon']\n        \n        # Run nonsmooth case\n        ns_merit = NonsmoothMerit(kappa, mu)\n        ns_metrics = run_optimizer(x0, ns_merit)\n        \n        # Run smoothed case\n        if case['smoothing'] == 'sqrt':\n            sm_merit = SqrtMerit(kappa, mu, epsilon)\n        else: # huber\n            sm_merit = HuberMerit(kappa, mu, epsilon)\n        \n        sm_metrics = run_optimizer(x0, sm_merit)\n        \n        case_results = [\n            ns_metrics[0], sm_metrics[0],  # zigzag\n            ns_metrics[1], sm_metrics[1],  # signflip\n            ns_metrics[2], sm_metrics[2],  # backtracks\n            ns_metrics[3], sm_metrics[3]   # phi_final\n        ]\n        all_results.append(case_results)\n        \n    formatted_results = []\n    for res_list in all_results:\n        formatted_list = f\"[{','.join(map(str, res_list))}]\"\n        formatted_results.append(formatted_list)\n    \n    final_output_string = f\"[[{all_results[0][0]},{all_results[0][1]},{all_results[0][2]},{all_results[0][3]},{all_results[0][4]},{all_results[0][5]},{all_results[0][6]:.10f},{all_results[0][7]:.10f}],[{all_results[1][0]},{all_results[1][1]},{all_results[1][2]},{all_results[1][3]},{all_results[1][4]},{all_results[1][5]},{all_results[1][6]:.10f},{all_results[1][7]:.10f}],[{all_results[2][0]},{all_results[2][1]},{all_results[2][2]},{all_results[2][3]},{all_results[2][4]},{all_results[2][5]},{all_results[2][6]:.10f},{all_results[2][7]:.10f}],[{all_results[3][0]},{all_results[3][1]},{all_results[3][2]},{all_results[3][3]},{all_results[3][4]},{all_results[3][5]},{all_results[3][6]:.10f},{all_results[3][7]:.10f}]]\"\n    print(final_output_string)\n\nsolve()\n```", "id": "3149286"}]}