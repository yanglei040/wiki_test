{"hands_on_practices": [{"introduction": "The dogleg method constructs a path to an optimal step, starting with the direction of steepest descent. The first key point on this path is the Cauchy point, which represents the minimizer of our model function along this descent direction, constrained to lie within the trust region. This practice ([@problem_id:2212704]) will give you hands-on experience in calculating this point and seeing how the trust-region radius $\\Delta$ determines the final step length.", "problem": "In the field of numerical optimization, trust-region methods are a class of algorithms for solving nonlinear programming problems. These methods iteratively find a step `p` by minimizing a model function `m(p)` of the true objective function within a \"trust region\" of radius $\\Delta$ around the current point $x_k$. The model is typically a quadratic approximation:\n$$m(p) = f(x_k) + g^T p + \\frac{1}{2} p^T B p$$\nwhere $g$ is the gradient of the objective function at $x_k$ and $B$ is an approximation to the Hessian matrix.\n\nA fundamental component of many trust-region algorithms (like the dogleg method) is the calculation of the Cauchy point, $p_C$. The Cauchy point is defined as the vector that minimizes the quadratic model $m(p)$ along the direction of steepest descent, subject to the constraint that the step lies within the trust region, i.e., $\\|p\\| \\le \\Delta$.\n\nConsider an optimization problem where, at the current iterate, the gradient is given by $g = \\begin{pmatrix} 3 \\\\ -4 \\end{pmatrix}$ and the Hessian approximation is the identity matrix, $B = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}$. The trust-region radius is set to $\\Delta = 4$.\n\nCalculate the Cauchy point $p_C$ for this scenario. Your answer should be a single 2x1 column vector containing exact fractions.", "solution": "The problem asks for the Cauchy point, $p_C$, which is the solution to the following constrained optimization problem:\n$$ \\min_{p} \\quad m(p) = f(x_k) + g^T p + \\frac{1}{2} p^T B p $$\n$$ \\text{subject to} \\quad p = -\\tau g \\text{ for some } \\tau \\ge 0, \\quad \\text{and} \\quad \\|p\\| \\le \\Delta $$\n\nThe direction of search is the steepest descent direction, $d = -g$. Any point along this direction can be parameterized as $p(\\tau) = -\\tau g$ for a scalar $\\tau \\ge 0$.\n\nFirst, we substitute this into the quadratic model $m(p)$ to obtain a function of a single variable, $\\tau$:\n$$ \\phi(\\tau) = m(-\\tau g) = f(x_k) + g^T(-\\tau g) + \\frac{1}{2} (-\\tau g)^T B (-\\tau g) $$\n$$ \\phi(\\tau) = f(x_k) - \\tau (g^T g) + \\frac{1}{2} \\tau^2 (g^T B g) $$\nThe constant term $f(x_k)$ does not affect the minimizer, so we can focus on minimizing the $\\tau$-dependent part.\n\nNext, we translate the trust-region constraint $\\|p\\| \\le \\Delta$ into a constraint on $\\tau$:\n$$ \\|p(\\tau)\\| = \\|-\\tau g\\| = |\\tau| \\|g\\| = \\tau \\|g\\| \\le \\Delta $$\nSince we are seeking a step in the descent direction, $\\tau \\ge 0$. Thus, the constraint on $\\tau$ is:\n$$ 0 \\le \\tau \\le \\frac{\\Delta}{\\|g\\|} $$\n\nNow, let's find the unconstrained minimizer of the quadratic $\\phi(\\tau)$ by taking its derivative with respect to $\\tau$ and setting it to zero. This will give us the optimal step length, $\\tau^*$, in the absence of the trust-region constraint.\n$$ \\frac{d\\phi}{d\\tau} = -g^T g + \\tau (g^T B g) = 0 $$\nSolving for $\\tau$, we get:\n$$ \\tau^* = \\frac{g^T g}{g^T B g} $$\nThe second derivative is $\\frac{d^2\\phi}{d\\tau^2} = g^T B g$. If this is positive, we have found a minimum.\n\nLet's compute the required quantities using the given values:\n$g = \\begin{pmatrix} 3 \\\\ -4 \\end{pmatrix}$, $B = I = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}$, and $\\Delta = 4$.\n\n1.  Calculate $g^T g$:\n    $g^T g = (3)(3) + (-4)(-4) = 9 + 16 = 25$.\n\n2.  Calculate $\\|g\\|$:\n    $\\|g\\| = \\sqrt{g^T g} = \\sqrt{25} = 5$.\n\n3.  Calculate $g^T B g$:\n    Since $B=I$, $g^T B g = g^T I g = g^T g = 25$.\n\nThe second derivative $g^T B g = 25  0$, so $\\phi(\\tau)$ is a convex parabola, and its unconstrained minimum is indeed at $\\tau^*$.\n\n4.  Calculate the unconstrained optimal step length $\\tau^*$:\n    $$ \\tau^* = \\frac{g^T g}{g^T B g} = \\frac{25}{25} = 1 $$\n\n5.  Determine the feasible interval for $\\tau$:\n    The constraint is $0 \\le \\tau \\le \\frac{\\Delta}{\\|g\\|}$.\n    $$ \\frac{\\Delta}{\\|g\\|} = \\frac{4}{5} = 0.8 $$\n    So, the feasible interval for $\\tau$ is $[0, 0.8]$.\n\n6.  Find the constrained optimal step length, $\\tau_C$. The unconstrained minimizer $\\tau^* = 1$ lies outside the feasible interval $[0, 0.8]$. Since $\\phi(\\tau)$ is a convex parabola with its minimum at $\\tau=1$, the minimum value of $\\phi(\\tau)$ over the interval $[0, 0.8]$ must occur at the boundary point closest to $\\tau=1$. This point is $\\tau = 0.8$.\n    Therefore, the step length for the Cauchy point is $\\tau_C = \\frac{\\Delta}{\\|g\\|} = \\frac{4}{5}$.\n\n7.  Calculate the Cauchy point $p_C$:\n    $$ p_C = -\\tau_C g = -\\frac{4}{5} \\begin{pmatrix} 3 \\\\ -4 \\end{pmatrix} = \\begin{pmatrix} -12/5 \\\\ 16/5 \\end{pmatrix} $$\n\nThe Cauchy point is $p_C = \\begin{pmatrix} -12/5 \\\\ 16/5 \\end{pmatrix}$. Let's verify its norm: $\\|p_C\\| = \\sqrt{(-12/5)^2 + (16/5)^2} = \\sqrt{\\frac{144+256}{25}} = \\sqrt{\\frac{400}{25}} = \\sqrt{16} = 4$, which is exactly equal to the trust-region radius $\\Delta$, as expected.", "answer": "$$\n\\boxed{\n\\begin{pmatrix} -\\frac{12}{5} \\\\ \\frac{16}{5} \\end{pmatrix}\n}\n$$", "id": "2212704"}, {"introduction": "When the unconstrained Newton step lies outside the trust region but the Cauchy point is inside, the dogleg method takes its characteristic \"dogleg\" turn. It finds a step by moving from the Cauchy point $p_U$ towards the Newton point $p_N$ until it hits the trust-region boundary. This exercise ([@problem_id:2212758]) focuses on this crucial interpolation, which elegantly balances the safety of the steepest descent direction with the efficiency of the Newton step.", "problem": "In the context of solving a trust-region subproblem in numerical optimization, the dogleg method is a popular technique for finding an approximate solution. This method constructs a trial step $p$ by following a path defined by two key vectors: the Cauchy point $p_U$ (the minimizer along the steepest descent direction) and the Newton point $p_N$ (the unconstrained minimizer of the quadratic model). The path consists of a line segment from the origin to $p_U$, followed by a line segment from $p_U$ to $p_N$. The final dogleg step $p$ is the point along this path that is farthest from the origin but still lies within the trust region, a sphere of radius $\\Delta$.\n\nConsider a specific iteration of an optimization algorithm where the Cauchy point and the Newton point are given by the vectors $p_U = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ and $p_N = \\begin{pmatrix} 4 \\\\ 4 \\end{pmatrix}$, respectively. The trust-region radius for this iteration is $\\Delta = 3$.\n\nDetermine the dogleg step vector $p$. Present your answer as a column vector with exact components.", "solution": "We are given $p_{U}=\\begin{pmatrix}1 \\\\ 1\\end{pmatrix}$, $p_{N}=\\begin{pmatrix}4 \\\\ 4\\end{pmatrix}$, and trust-region radius $\\Delta=3$. Compute the norms:\n$$\n\\|p_{U}\\|=\\sqrt{1^{2}+1^{2}}=\\sqrt{2},\\quad \\|p_{N}\\|=\\sqrt{4^{2}+4^{2}}=4\\sqrt{2}.\n$$\nSince $\\|p_{U}\\|\\Delta\\|p_{N}\\|$, the dogleg step lies on the segment from $p_{U}$ to $p_{N}$ and has norm exactly $\\Delta$. Parameterize the second segment by\n$$\np(\\tau)=p_{U}+\\tau\\,(p_{N}-p_{U}),\\quad \\tau\\in[0,1],\n$$\nwith $p_{N}-p_{U}=\\begin{pmatrix}3 \\\\ 3\\end{pmatrix}$. Then\n$$\np(\\tau)=\\begin{pmatrix}1+3\\tau \\\\ 1+3\\tau\\end{pmatrix},\\quad \\|p(\\tau)\\|^{2}=2\\,(1+3\\tau)^{2}.\n$$\nImpose the trust-region boundary condition $\\|p(\\tau)\\|=\\Delta$:\n$$\n2\\,(1+3\\tau)^{2}=9\\;\\Rightarrow\\;(1+3\\tau)^{2}=\\frac{9}{2}\\;\\Rightarrow\\;1+3\\tau=\\frac{3}{\\sqrt{2}},\n$$\nwhere the positive root is taken because $\\tau\\geq 0$. Hence\n$$\n3\\tau=\\frac{3}{\\sqrt{2}}-1\\;\\Rightarrow\\;\\tau=\\frac{1}{\\sqrt{2}}-\\frac{1}{3},\n$$\nwhich lies in $[0,1]$. Therefore\n$$\np=p(\\tau)=\\begin{pmatrix}1+3\\tau \\\\ 1+3\\tau\\end{pmatrix}=\\begin{pmatrix}\\frac{3}{\\sqrt{2}} \\\\ \\frac{3}{\\sqrt{2}}\\end{pmatrix}.\n$$\nEquivalently, rationalizing denominators gives $p=\\begin{pmatrix}\\frac{3\\sqrt{2}}{2} \\\\ \\frac{3\\sqrt{2}}{2}\\end{pmatrix}$. Both are exact forms.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{3\\sqrt{2}}{2} \\\\ \\frac{3\\sqrt{2}}{2}\\end{pmatrix}}$$", "id": "2212758"}, {"introduction": "Understanding the individual cases of the dogleg method is essential, but a truly robust implementation requires translating this knowledge into a coherent algorithm. The choice of the final step $p$ depends entirely on where the Newton step $p_N$ and the Cauchy step $p_U$ lie in relation to the trust-region boundary. This problem ([@problem_id:2212701]) challenges you to think like a programmer and select the correct conditional logic that covers all possible scenarios, solidifying your understanding of the complete dogleg procedure.", "problem": "In the field of numerical optimization, trust-region methods are a class of algorithms for solving unconstrained nonlinear programming problems. At each iteration, they define a \"trust region\" around the current point, within which a model of the objective function (typically a quadratic approximation) is considered reliable. The algorithm then seeks a step that minimizes this model within the trust region.\n\nThe dogleg method is a popular technique for approximately solving this trust-region subproblem. The subproblem is to find a step vector $p$ that minimizes the quadratic model\n$$m(p) = f_k + g^T p + \\frac{1}{2} p^T B p$$\nsubject to the constraint $\\|p\\|_2 \\le \\Delta$, where $g$ is the gradient of the objective function, $B$ is a positive definite approximation to the Hessian matrix, and $\\Delta  0$ is the trust-region radius. All vectors and matrices are evaluated at the current iterate $x_k$.\n\nThe dogleg method constructs a trial step $p$ by considering a piecewise linear path. This path connects the origin, the unconstrained minimizer along the steepest descent direction, and the unconstrained minimizer of the full quadratic model. These two key points are:\n1.  The quasi-Newton step, $p_N = -B^{-1}g$, which is the unconstrained minimizer of $m(p)$.\n2.  The steepest-descent step, $p_U = -\\frac{g^T g}{g^T B g}g$, which is the minimizer of $m(p)$ along the direction of the negative gradient $-g$.\n\nYour task is to select the correct block of conditional logic that a program would use to determine the trial step $p$ based on the trust-region radius $\\Delta$ and the Euclidean norms of $p_N$ and $p_U$. For the purposes of this problem, assume `norm(v)` calculates the Euclidean norm $\\|v\\|_2$.\n\nWhich of the following pseudocode fragments correctly implements the logic for choosing the dogleg step $p$?\n\nA.\n```\nIF norm(pN) = delta:\n  Set p = pN\nELSE:\n  IF norm(pU) = delta:\n    Set p = delta * (pU / norm(pU))\n  ELSE:\n    // Find scalar tau = 0 such that ||pU + tau*(pN - pU)|| = delta\n    Set p = pU + tau*(pN - pU)\n```\n\nB.\n```\nIF norm(pN) = delta:\n  Set p = pN\nELSE:\n  Set p = delta * (pN / norm(pN))\n```\n\nC.\n```\nIF norm(pN) = delta:\n  Set p = pN\nELSE:\n  Set p = delta * (pU / norm(pU))\n```\n\nD.\n```\nIF norm(pN) = delta:\n  Set p = pN\nELSE:\n  IF norm(pU)  delta:\n    Set p = delta * (pU / norm(pU))\n  ELSE:\n    // Find scalar tau = 0 such that ||pU + tau*(pN - pU)|| = delta\n    Set p = pU + tau*(pN - pU)\n```\n\nE.\n```\nIF norm(pU) = delta:\n  Set p = delta * (pU / norm(pU))\nELSE:\n  IF norm(pN) = delta:\n    Set p = pN\n  ELSE:\n    // Find scalar tau = 0 such that ||pU + tau*(pN - pU)|| = delta\n    Set p = pU + tau*(pN - pU)\n```", "solution": "We are solving the trust-region subproblem for the quadratic model\n$$\nm(p) = f_{k} + g^{T}p + \\frac{1}{2} p^{T} B p\n$$\nsubject to the constraint $\\|p\\|_{2} \\le \\Delta$, with $B$ positive definite. The dogleg method constructs a piecewise linear path consisting of two segments: from the origin to the steepest-descent (Cauchy) step $p_U$, and then from $p_U$ to the quasi-Newton step $p_N$. The definitions are\n$$\np_N = -B^{-1} g, \\quad p_U = -\\frac{g^{T} g}{g^{T} B g}\\, g.\n$$\n\nThe correct selection logic follows from three mutually exclusive cases determined by the trust-region radius $\\Delta$ and the norms of $p_N$ and $p_U$:\n\n1) If $\\|p_N\\|_{2} \\le \\Delta$, then the unconstrained minimizer $p_N$ is feasible. Since $B$ is positive definite, $p_N$ is the unique minimizer of $m(p)$ over all $p$, and being feasible, it is also the constrained minimizer. Therefore, set\n$$\np = p_N.\n$$\n\n2) Else, if $\\|p_N\\|_{2}  \\Delta$ and $\\|p_U\\|_{2} \\ge \\Delta$, then the trust-region boundary intersects the first segment of the dogleg path (from $0$ to $p_U$). The optimal step along this segment at the boundary is obtained by scaling $p_U$ to have length $\\Delta$:\n$$\np = \\Delta \\frac{p_U}{\\|p_U\\|_{2}}.\n$$\n\n3) Else, if $\\|p_N\\|_{2}  \\Delta$ and $\\|p_U\\|_{2}  \\Delta$, then the trust-region boundary intersects the second segment (from $p_U$ to $p_N$). We find the unique $\\tau \\in [0,1]$ such that\n$$\n\\|p_U + \\tau (p_N - p_U)\\|_{2} = \\Delta,\n$$\nand set\n$$\np = p_U + \\tau (p_N - p_U).\n$$\n\nComparing with the options:\n- Option A implements exactly this logic: first check $\\|p_N\\|_{2} \\le \\Delta$, else if $\\|p_U\\|_{2} \\ge \\Delta$ scale $p_U$ to the boundary, else solve for $\\tau$ along the dogleg segment from $p_U$ to $p_N$.\n- Option B incorrectly scales $p_N$ when it is outside, ignoring the dogleg path and the role of $p_U$.\n- Option C incorrectly always scales $p_U$ whenever $p_N$ is outside, even when $\\|p_U\\|_{2}  \\Delta$, which is not along the first segment boundary crossing.\n- Option D reverses the boundary cases for $p_U$: it scales $p_U$ when $\\|p_U\\|_{2}  \\Delta$, which is incorrect; in that case the boundary lies on the second segment, requiring the interpolation with $\\tau$.\n- Option E checks $\\|p_U\\|_{2} \\ge \\Delta$ before $\\|p_N\\|_{2} \\le \\Delta$, which can select the scaled $p_U$ even if $p_N$ is feasible; this violates the rule that $p_N$ should be chosen whenever it lies within the trust region.\n\nTherefore, the correct pseudocode fragment is Option A.", "answer": "$$\\boxed{A}$$", "id": "2212701"}]}