{"hands_on_practices": [{"introduction": "This first exercise introduces forward recursion in its most classic form: dynamic programming. We will tackle a production smoothing problem where the goal is to minimize inventory fluctuations over several periods. By defining the system's state as the cumulative deviation from a target, we can use a forward recursion to calculate the minimum possible cost to reach every feasible state at each stage, systematically building toward the optimal solution. This hands-on calculation [@problem_id:3130922] is fundamental for understanding how the principle of optimality is applied in practice.", "problem": "A manufacturer plans production over a discrete, finite horizon of $T=4$ periods to smooth inventory swings around a target average production. Let the per-period production decision be $x_t$ and the target average be $\\bar{x}$. Define the cumulative deviation (inventory deviation) state by the forward recursion $d_{t+1} = d_t + x_t - \\bar{x}$ with initial condition $d_1 = 0$. The per-period penalty for inventory swings is the absolute deviation of the next state, namely $|d_{t+1}|$. The terminal deviation must be zero, $d_{5} = 0$, to enforce end-of-horizon balance. The objective is to minimize the total penalty $\\sum_{t=1}^{4} |d_{t+1}|$ subject to the forward state recursion and the following time-varying production feasibility sets:\n- At $t=1$: $x_1 \\in \\{8,\\,10\\}$.\n- At $t=2$: $x_2 \\in \\{8,\\,12\\}$.\n- At $t=3$: $x_3 \\in \\{10,\\,12\\}$.\n- At $t=4$: $x_4 \\in \\{8,\\,10\\}$.\nTake $\\bar{x} = 10$.\nUsing the principle of optimality from dynamic programming, construct a forward recursion that propagates the minimal cumulative penalty to each reachable state $d_{t+1}$ and enforces the terminal constraint $d_5=0$. Then compute the minimal total penalty value $\\sum_{t=1}^{4} |d_{t+1}|$ achieved by an optimal production sequence that satisfies all constraints. Report your final answer as a single real number. No rounding is required.", "solution": "The user wants me to solve a dynamic programming problem using forward recursion. The problem is to find the minimum total penalty over a $T=4$ period horizon.\n\n### Step 1: Extract Givens\n-   Time horizon: $T=4$ periods.\n-   Production decision at period $t$: $x_t$.\n-   Target average production: $\\bar{x} = 10$.\n-   State variable: $d_t$, the cumulative deviation from the target average.\n-   State transition (forward recursion): $d_{t+1} = d_t + x_t - \\bar{x}$.\n-   Initial condition: $d_1 = 0$.\n-   Per-period penalty: $|d_{t+1}|$.\n-   Objective function to minimize: $\\sum_{t=1}^{4} |d_{t+1}|$.\n-   Terminal constraint: $d_5 = 0$.\n-   Production feasibility sets:\n    -   $t=1$: $x_1 \\in \\{8, 10\\}$.\n    -   $t=2$: $x_2 \\in \\{8, 12\\}$.\n    -   $t=3$: $x_3 \\in \\{10, 12\\}$.\n    -   $t=4$: $x_4 \\in \\{8, 10\\}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is a well-defined discrete-time finite-horizon optimal control problem. It is mathematically and logically self-contained. The state, control, dynamics, and cost are all clearly specified. The problem is scientifically grounded in the principles of dynamic programming and optimization theory. All terms are objective and precisely defined. It does not violate any scientific principles, is not ill-posed, and contains all necessary information for a solution. The constraints are not contradictory.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be provided.\n\nThis problem can be solved using a forward recursion approach, as suggested by the problem statement. We define the state of the system at the beginning of period $t$ by the cumulative deviation $d_t$. The decision variable is the production $x_t$. The state transition equation is given by $d_{t+1} = d_t + x_t - \\bar{x}$, with $\\bar{x}=10$. The initial state is $d_1 = 0$.\n\nLet $J_t(d_t)$ be the minimum cumulative penalty to reach state $d_t$ at the beginning of period $t$. The objective is to find $\\min \\sum_{t=1}^{4} |d_{t+1}|$ subject to the constraints. This is equivalent to finding the minimum value of $J_5(d_5=0)$. The forward recursion for the minimum cost is:\n$$J_{t+1}(d_{t+1}) = \\min_{d_t, x_t} \\{ J_t(d_t) + |d_{t+1}| \\}$$\nwhere the minimization is over all pairs of prior states $d_t$ and feasible decisions $x_t$ that result in the state $d_{t+1} = d_t + x_t - 10$.\n\nWe proceed stage by stage.\n\n**Stage 1: From $t=1$ to $t=2$**\nThe system starts in state $d_1 = 0$ with an initial cost of $J_1(0)=0$.\nThe available production decisions are $x_1 \\in \\{8, 10\\}$.\n\n-   If $x_1 = 8$: The next state is $d_2 = d_1 + x_1 - 10 = 0 + 8 - 10 = -2$.\n    The cumulative cost to reach this state is $J_2(-2) = J_1(0) + |d_2| = 0 + |-2| = 2$.\n-   If $x_1 = 10$: The next state is $d_2 = d_1 + x_1 - 10 = 0 + 10 - 10 = 0$.\n    The cumulative cost to reach this state is $J_2(0) = J_1(0) + |d_2| = 0 + |0| = 0$.\n\nAt the start of period $t=2$, the reachable states are $d_2 \\in \\{-2, 0\\}$ with minimum costs $J_2(-2)=2$ and $J_2(0)=0$.\n\n**Stage 2: From $t=2$ to $t=3$**\nThe available production decisions are $x_2 \\in \\{8, 12\\}$. We compute the next states $d_3$ and their costs from each reachable state $d_2$.\n\n-   From $d_2 = -2$ (with current cost $J_2(-2)=2$):\n    -   If $x_2 = 8$: $d_3 = -2 + 8 - 10 = -4$. New cost: $J_2(-2) + |-4| = 2 + 4 = 6$.\n    -   If $x_2 = 12$: $d_3 = -2 + 12 - 10 = 0$. New cost: $J_2(-2) + |0| = 2 + 0 = 2$.\n-   From $d_2 = 0$ (with current cost $J_2(0)=0$):\n    -   If $x_2 = 8$: $d_3 = 0 + 8 - 10 = -2$. New cost: $J_2(0) + |-2| = 0 + 2 = 2$.\n    -   If $x_2 = 12$: $d_3 = 0 + 12 - 10 = 2$. New cost: $J_2(0) + |2| = 0 + 2 = 2$.\n\nAt the start of period $t=3$, the reachable states are $d_3 \\in \\{-4, -2, 0, 2\\}$. Since no state is reached by multiple paths, we do not need to take a minimum. The minimum costs are:\n-   $J_3(-4) = 6$\n-   $J_3(-2) = 2$\n-   $J_3(0) = 2$\n-   $J_3(2) = 2$\n\n**Stage 3: From $t=3$ to $t=4$**\nThe available production decisions are $x_3 \\in \\{10, 12\\}$.\n\n-   From $d_3 = -4$ (cost $6$):\n    -   $x_3 = 10 \\implies d_4 = -4+10-10 = -4$. Cost: $6+|-4|=10$.\n    -   $x_3 = 12 \\implies d_4 = -4+12-10 = -2$. Cost: $6+|-2|=8$.\n-   From $d_3 = -2$ (cost $2$):\n    -   $x_3 = 10 \\implies d_4 = -2+10-10 = -2$. Cost: $2+|-2|=4$.\n    -   $x_3 = 12 \\implies d_4 = -2+12-10 = 0$. Cost: $2+|0|=2$.\n-   From $d_3 = 0$ (cost $2$):\n    -   $x_3 = 10 \\implies d_4 = 0+10-10 = 0$. Cost: $2+|0|=2$.\n    -   $x_3 = 12 \\implies d_4 = 0+12-10 = 2$. Cost: $2+|2|=4$.\n-   From $d_3 = 2$ (cost $2$):\n    -   $x_3 = 10 \\implies d_4 = 2+10-10 = 2$. Cost: $2+|2|=4$.\n    -   $x_3 = 12 \\implies d_4 = 2+12-10 = 4$. Cost: $2+|4|=6$.\n\nAt the start of period $t=4$, the reachable states are $d_4 \\in \\{-4, -2, 0, 2, 4\\}$. Some states are reached via multiple paths, so we apply the principle of optimality by taking the minimum cost for each state.\n-   $J_4(-4)$: Reached only from $d_3 = -4, x_3=10$. Cost $10$. So, $J_4(-4) = 10$.\n-   $J_4(-2)$: Reached from ($d_3=-4, x_3=12$) with cost $8$ and from ($d_3=-2, x_3=10$) with cost $4$. So, $J_4(-2) = \\min(8, 4) = 4$.\n-   $J_4(0)$: Reached from ($d_3=-2, x_3=12$) with cost $2$ and from ($d_3=0, x_3=10$) with cost $2$. So, $J_4(0) = \\min(2, 2) = 2$.\n-   $J_4(2)$: Reached from ($d_3=0, x_3=12$) with cost $4$ and from ($d_3=2, x_3=10$) with cost $4$. So, $J_4(2) = \\min(4, 4) = 4$.\n-   $J_4(4)$: Reached only from $d_3 = 2, x_3=12$. Cost $6$. So, $J_4(4) = 6$.\n\nSummary of minimum costs at $t=4$: $J_4(-4)=10$, $J_4(-2)=4$, $J_4(0)=2$, $J_4(2)=4$, $J_4(4)=6$.\n\n**Stage 4: From $t=4$ to $t=5$**\nThe available production decisions are $x_4 \\in \\{8, 10\\}$. We must enforce the terminal constraint $d_5=0$. The state transition is $d_5 = d_4 + x_4 - 10$. The constraint implies $0 = d_4 + x_4 - 10$, or $x_4 = 10 - d_4$.\nWe check which of the reachable states $d_4$ lead to a feasible $x_4$. The total cost will be $J_4(d_4) + |d_5| = J_4(d_4) + |0| = J_4(d_4)$.\n\n-   If $d_4 = -4$: Required $x_4 = 10 - (-4) = 14$. This is not in $\\{8, 10\\}$, so this path is infeasible.\n-   If $d_4 = -2$: Required $x_4 = 10 - (-2) = 12$. This is not in $\\{8, 10\\}$, so this path is infeasible.\n-   If $d_4 = 0$: Required $x_4 = 10 - 0 = 10$. This is in $\\{8, 10\\}$. This path is feasible. The total cost is $J_4(0) = 2$.\n-   If $d_4 = 2$: Required $x_4 = 10 - 2 = 8$. This is in $\\{8, 10\\}$. This path is feasible. The total cost is $J_4(2) = 4$.\n-   If $d_4 = 4$: Required $x_4 = 10 - 4 = 6$. This is not in $\\{8, 10\\}$, so this path is infeasible.\n\nThe possible total penalties for feasible production sequences are $2$ and $4$. The minimum of these is the optimal value.\nMinimal total penalty $= \\min(2, 4) = 2$.\nTo verify, an optimal sequence is $x=(10, 8, 12, 10)$. The states are $d_1=0 \\to d_2=0 \\to d_3=-2 \\to d_4=0 \\to d_5=0$. The total penalty is $|0| + |-2| + |0| + |0| = 2$.\nAnother optimal sequence is $x=(8, 12, 10, 10)$. The states are $d_1=0 \\to d_2=-2 \\to d_3=0 \\to d_4=0 \\to d_5=0$. The total penalty is $|-2| + |0| + |0| + |0| = 2$.\nThe minimal total penalty is $2$.", "answer": "$$\\boxed{2}$$", "id": "3130922"}, {"introduction": "Forward recursion is not limited to discrete-time dynamic programming. This next practice explores its application in a geometric context: finding the shortest possible path for a robot or vehicle through a series of constrained waypoints. The total path length is naturally defined by a forward recursion, where each step adds the length of the next segment. This problem [@problem_id:3131028] will challenge you to formulate and solve a continuous optimization problem, demonstrating how a recursive definition can serve as the objective function in a large-scale numerical optimization.", "problem": "Consider a discrete path planning problem in two dimensions where the decision variables are waypoints $x_t \\in \\mathbb{R}^2$ for time indices $t \\in \\{0,1,\\dots,T\\}$. The cumulative path length is defined by the fundamental geometric fact that the length of a polyline is the sum of Euclidean segment lengths. Starting from the base definition of Euclidean distance $\\|x\\|_2 = \\sqrt{x_1^2 + x_2^2}$ and the additivity of lengths along successive segments, define the cumulative distance recursively by $D_0 = 0$ and\n$$\nD_{t+1} = D_t + \\|x_{t+1} - x_t\\|_2\n$$\nfor all $t \\in \\{0,1,\\dots,T-1\\}$. The optimization goal is to choose the waypoints to minimize $D_T$ subject to forward obstacle constraints given by time-indexed convex safe sets and forward-progress constraints. The safe set at time $t$ is a convex polytope described by linear inequalities $A_t x_t \\le b_t$, and forward progress along the first coordinate is enforced by the linear inequalities $x_{t+1}^{(1)} \\ge x_t^{(1)}$ for all $t \\in \\{0,1,\\dots,T-1\\}$. The start and goal waypoints are fixed by the equalities $x_0 = s$ and $x_T = g$.\n\nYou must derive the optimization formulation from the above definitions and implement a program that solves the constrained optimization using a principled algorithmic design grounded in the additivity of distances and the structure of convex constraints. The final objective is the minimal cumulative distance $D_T$ for each provided test case.\n\nAll coordinates are dimensionless scalars, and no physical units apply. Angles are not involved in this problem. Your program must implement the forward recursion exactly to compute $D_T$ for any candidate set of waypoints and use it as the objective to be minimized.\n\nTest Suite:\nFor each test case below, $A_t$ and $b_t$ are specified implicitly by axis-aligned rectangles (convex polytopes) via bounds $x_t^{(1)} \\in [x_{\\min}(t), x_{\\max}(t)]$ and $x_t^{(2)} \\in [y_{\\min}(t), y_{\\max}(t)]$. Each rectangle corresponds to the halfspace system\n$$\nA_t = \\begin{bmatrix}\n1 & 0\\\\\n-1 & 0\\\\\n0 & 1\\\\\n0 & -1\n\\end{bmatrix},\\quad\nb_t = \\begin{bmatrix}\nx_{\\max}(t)\\\\\n- x_{\\min}(t)\\\\\ny_{\\max}(t)\\\\\n- y_{\\min}(t)\n\\end{bmatrix},\n$$\nso that $A_t x_t \\le b_t$ encodes the box constraints. For each test case, also enforce forward constraints $x_{t+1}^{(1)} \\ge x_t^{(1)}$ and endpoint equalities $x_0 = s$, $x_T = g$.\n\n- Test Case $1$ (happy path with a detour corridor):\n  - Horizon: $T = 6$.\n  - Start: $s = (0, 1)$.\n  - Goal: $g = (10, 1)$.\n  - Safe rectangles by time index $t = 0,1,2,3,4,5,6$:\n    - $t=0$: $x^{(1)} \\in [0, 2]$, $x^{(2)} \\in [0, 2]$.\n    - $t=1$: $x^{(1)} \\in [1.5, 3.5]$, $x^{(2)} \\in [0, 2]$.\n    - $t=2$: $x^{(1)} \\in [3.0, 5.0]$, $x^{(2)} \\in [0, 2]$.\n    - $t=3$: $x^{(1)} \\in [4.5, 6.5]$, $x^{(2)} \\in [2, 4]$.\n    - $t=4$: $x^{(1)} \\in [6.0, 8.0]$, $x^{(2)} \\in [2, 4]$.\n    - $t=5$: $x^{(1)} \\in [7.5, 9.5]$, $x^{(2)} \\in [0, 2]$.\n    - $t=6$: $x^{(1)} \\in [9.5, 11.5]$, $x^{(2)} \\in [0, 2]$.\n\n- Test Case $2$ (boundary case with start equal to goal):\n  - Horizon: $T = 1$.\n  - Start: $s = (2, 2)$.\n  - Goal: $g = (2, 2)$.\n  - Safe rectangles:\n    - $t=0$: $x^{(1)} \\in [1.0, 3.0]$, $x^{(2)} \\in [1.0, 3.0]$.\n    - $t=1$: $x^{(1)} \\in [1.5, 3.5]$, $x^{(2)} \\in [1.5, 3.5]$.\n\n- Test Case $3$ (edge case with a narrow detour forcing vertical motion):\n  - Horizon: $T = 5$.\n  - Start: $s = (0, 0)$.\n  - Goal: $g = (5, 0)$.\n  - Safe rectangles:\n    - $t=0$: $x^{(1)} \\in [0, 1]$, $x^{(2)} \\in [0, 1]$.\n    - $t=1$: $x^{(1)} \\in [0.8, 2]$, $x^{(2)} \\in [0, 1]$.\n    - $t=2$: $x^{(1)} \\in [1.8, 3]$, $x^{(2)} \\in [1.5, 2.5]$.\n    - $t=3$: $x^{(1)} \\in [2.8, 4]$, $x^{(2)} \\in [0, 1]$.\n    - $t=4$: $x^{(1)} \\in [3.8, 5]$, $x^{(2)} \\in [0, 1]$.\n    - $t=5$: $x^{(1)} \\in [4.5, 5.5]$, $x^{(2)} \\in [0, 1]$.\n\nYour program must do the following for each test case:\n- Formulate the constrained optimization problem that minimizes $D_T$ under the specified forward recursion, box constraints $A_t x_t \\le b_t$, forward progression constraints $x_{t+1}^{(1)} \\ge x_t^{(1)}$, and endpoint equalities $x_0 = s$, $x_T = g$.\n- Solve the optimization numerically and compute the optimized $D_T$ using the forward recursion definition.\n- Return a float for each test case equal to the optimized $D_T$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The values must be formatted as decimal floats with six digits after the decimal point, in the order of Test Case $1$, Test Case $2$, Test Case $3$, for example, $[d_1,d_2,d_3]$ where each $d_i$ is the optimized $D_T$ for the corresponding test case. No other text should be printed.", "solution": "The user has provided a path planning problem formulated as a constrained optimization task. The goal is to find a sequence of waypoints in a 2D plane that minimizes the total path length, subject to several constraints.\n\n### Step 1: Problem Validation\n\n**1. Extract Givens:**\n- **Decision Variables**: Waypoints $x_t \\in \\mathbb{R}^2$ for time indices $t \\in \\{0, 1, \\dots, T\\}$.\n- **Objective Function**: Minimize the cumulative path length $D_T$, defined by the forward recursion $D_0 = 0$ and $D_{t+1} = D_t + \\|x_{t+1} - x_t\\|_2$. This is equivalent to minimizing the sum of Euclidean lengths of the path segments: $D_T = \\sum_{t=0}^{T-1} \\|x_{t+1} - x_t\\|_2$.\n- **Constraints**:\n    1.  **Endpoint Equalities**: The start and goal waypoints are fixed: $x_0 = s$ and $x_T = g$.\n    2.  **Safe Set Constraints**: For each time $t$, the waypoint $x_t$ must lie within a convex polytope defined by linear inequalities $A_t x_t \\le b_t$. The test cases specify these as axis-aligned rectangles: $x_t^{(1)} \\in [x_{\\min}(t), x_{\\max}(t)]$ and $x_t^{(2)} \\in [y_{\\min}(t), y_{\\max}(t)]$.\n    3.  **Forward Progress Constraints**: The first coordinate of the waypoints must be non-decreasing: $x_{t+1}^{(1)} \\ge x_t^{(1)}$ for all $t \\in \\{0, 1, \\dots, T-1\\}$.\n- **Test Data**: Three test cases are provided, each with a specified horizon $T$, start point $s$, goal point $g$, and a sequence of rectangular safe sets for $t=0, \\dots, T$.\n\n**2. Validate Using Extracted Givens:**\n- **Scientifically Grounded**: The problem is a standard, well-established formulation in motion planning and optimization theory. It relies on fundamental mathematical concepts: Euclidean distance, convex sets (polytopes), and linear inequalities. It is scientifically sound.\n- **Well-Posed**: The objective function, being a sum of Euclidean norms, is a convex function. The constraint set is defined by the intersection of linear equalities and inequalities, which forms a convex set. Minimizing a convex function over a convex feasible set is a convex optimization problem. For the provided test cases, the feasible set is non-empty (the start and goal points lie within their respective safe sets, and the intermediate safe sets provide a continuous corridor). Therefore, a unique global minimum for the path length exists, and the problem is well-posed.\n- **Objective**: The problem is specified with precise, unambiguous mathematical language and definitions.\n- **Completeness and Consistency**: The problem statement is self-contained and provides all necessary information for each test case. The constraints are internally consistent. For example, the start and goal points are verified to be within their respective $t=0$ and $t=T$ safe rectangles.\n- **Other Flaws**: The problem is formalizable, realistic within its mathematical context, and non-trivial. It does not suffer from any of the other invalidity criteria.\n\n**Verdict**: The problem is **valid**.\n\n### Step 2: Optimization Problem Formulation\n\nThe task is to find a set of intermediate waypoints $x_1, x_2, \\dots, x_{T-1}$ that solve the following optimization problem:\n\n$$\n\\min_{x_1, \\dots, x_{T-1}} \\quad \\sum_{t=0}^{T-1} \\sqrt{(x_{t+1}^{(1)} - x_t^{(1)})^2 + (x_{t+1}^{(2)} - x_t^{(2)})^2}\n$$\n\nsubject to:\n\n1.  **Fixed Endpoints**:\n    - $x_0 = s$\n    - $x_T = g$\n\n2.  **Box Constraints**: For each intermediate waypoint $t \\in \\{1, \\dots, T-1\\}$:\n    - $x_{\\min}(t) \\le x_t^{(1)} \\le x_{\\max}(t)$\n    - $y_{\\min}(t) \\le x_t^{(2)} \\le y_{\\max}(t)$\n\n3.  **Forward Progress Constraints**: For each time step $t \\in \\{0, \\dots, T-1\\}$:\n    - $x_{t+1}^{(1)} - x_t^{(1)} \\ge 0$\n\nThis is a nonlinear programming (NLP) problem. Specifically, since the objective is convex and the constraints are linear, it is a convex optimization problem. Such problems can be reliably solved using numerical optimization algorithms like Sequential Least Squares Programming (SLSQP), which is available in the `scipy.optimize` library.\n\n### Step 3: Algorithmic Design\n\nThe solution will be implemented by structuring the problem for the `scipy.optimize.minimize` function.\n\n1.  **Decision Variables**: The optimization variables will be the coordinates of the intermediate waypoints, flattened into a single vector `z` of length $2(T-1)$:\n    $z = [x_1^{(1)}, x_1^{(2)}, x_2^{(1)}, x_2^{(2)}, \\dots, x_{T-1}^{(1)}, x_{T-1}^{(2)}]$.\n\n2.  **Objective Function**: A Python function will take the vector `z` as input, reconstruct the full path $(x_0, x_1, \\dots, x_T)$, and compute the total path length, which is the sum of the Euclidean distances between consecutive waypoints.\n\n3.  **Constraints**: The constraints will be provided to the solver in its required format:\n    - **Bounds**: The rectangular safe sets for $x_1, \\dots, x_{T-1}$ translate directly to lower and upper bounds on the elements of `z`.\n    - **Linear Inequalities**: The forward progress constraints, $x_{t+1}^{(1)} \\ge x_t^{(1)}$, are linear inequalities. These can be expressed in the form $C(z) \\ge 0$.\n        - For $t=0$, the constraint is $x_1^{(1)} \\ge s^{(1)}$. This can be incorporated into the lower bound of the first variable, $z[0]$.\n        - For $t=T-1$, the constraint is $g^{(1)} \\ge x_{T-1}^{(1)}$. This can be incorporated into the upper bound of the variable $z[2(T-2)]$.\n        - For intermediate steps $t \\in \\{1, \\dots, T-2\\}$, the constraint $x_{t+1}^{(1)} \\ge x_t^{(1)}$ relates two variables in `z` and will be passed as a generic inequality constraint to the solver.\n\n4.  **Initial Guess**: A good initial guess for the waypoints is crucial for solver performance. A simple and effective choice is a linear interpolation between the start point $s$ and goal point $g$. This initial path is then clipped to satisfy the box constraints for each waypoint, ensuring the starting point for the optimization is feasible with respect to the bounds.\n\n5.  **Solver Execution**: For each test case, the problem is constructed and solved using `scipy.optimize.minimize` with the 'SLSQP' method. The optimized objective function value, `res.fun`, provides the minimal path length $D_T$. A special case for $T=1$ is handled separately, where the path length is simply $\\|g-s\\|_2$ as there are no intermediate waypoints to optimize.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize, Bounds\n\ndef solve_single_case(case_data):\n    \"\"\"\n    Solves a single path planning optimization problem.\n    \"\"\"\n    T = case_data[\"T\"]\n    s = case_data[\"s\"]\n    g = case_data[\"g\"]\n    rects = case_data[\"rects\"]\n\n    # For T=1, there are no intermediate waypoints to optimize.\n    # The path length is simply the Euclidean distance between s and g.\n    if T = 1:\n        # Check feasibility (problem statement guarantees this)\n        s_in_box0 = (rects[0]['xmin'] = s[0] = rects[0]['xmax'] and\n                     rects[0]['ymin'] = s[1] = rects[0]['ymax'])\n        g_in_boxT = (rects[T]['xmin'] = g[0] = rects[T]['xmax'] and\n                     rects[T]['ymin'] = g[1] = rects[T]['ymax'])\n        forward_progress = g[0] >= s[0]\n        \n        if not (s_in_box0 and g_in_boxT and forward_progress):\n             # This path should not be taken based on problem validity.\n             return float('nan')\n             \n        return np.linalg.norm(g - s)\n\n    # Number of variables: (T-1) intermediate points, each with 2 coordinates.\n    num_vars = 2 * (T - 1)\n\n    # The optimization variables `z` are the flattened coordinates of x_1, ..., x_{T-1}\n    # z = [x_1_1, x_1_2, x_2_1, x_2_2, ..., x_{T-1}_1, x_{T-1}_2]\n\n    def objective_func(z):\n        \"\"\"\n        Calculates the total path length for a given set of intermediate waypoints.\n        \"\"\"\n        # Reshape z into a path of intermediate points\n        path_points = z.reshape((T - 1, 2))\n        \n        # Construct the full path including start and goal\n        full_path = np.vstack([s, path_points, g])\n        \n        # Calculate the sum of Euclidean distances between consecutive points\n        path_segments = np.diff(full_path, axis=0)\n        path_length = np.sum(np.linalg.norm(path_segments, axis=1))\n        \n        return path_length\n\n    # --- Define Constraints ---\n    \n    # 1. Box constraints from safe rectangles for intermediate waypoints x_1, ..., x_{T-1}\n    lower_bounds = np.zeros(num_vars)\n    upper_bounds = np.zeros(num_vars)\n    for t in range(1, T):\n        idx = 2 * (t - 1)\n        rect = rects[t]\n        lower_bounds[idx] = rect['xmin']\n        upper_bounds[idx] = rect['xmax']\n        lower_bounds[idx+1] = rect['ymin']\n        upper_bounds[idx+1] = rect['ymax']\n\n    # 2. Incorporate forward progress constraints into the bounds where possible\n    # For t=0: x_1^(1) >= x_0^(1) => z[0] >= s[0]\n    lower_bounds[0] = max(lower_bounds[0], s[0])\n    \n    # For t=T-1: x_T^(1) >= x_{T-1}^(1) => g[0] >= z[-2]\n    upper_bounds[-2] = min(upper_bounds[-2], g[0])\n\n    bounds = Bounds(lower_bounds, upper_bounds)\n\n    # 3. Forward progress constraints for intermediate points\n    # x_{t+1}^(1) >= x_t^(1) for t=1, ..., T-2\n    # This means z[2*t] >= z[2*(t-1)]\n    ineq_constraints = []\n    for t in range(1, T - 1):\n        # Constraint: z[2*t] - z[2*(t-1)] >= 0\n        # Use a default argument to correctly capture `t` in the lambda\n        fun = lambda z, t=t: z[2 * t] - z[2 * (t - 1)]\n        ineq_constraints.append({'type': 'ineq', 'fun': fun})\n\n    # --- Initial Guess ---\n    # Linearly interpolate between s and g, then clip to bounds\n    z0 = np.zeros(num_vars)\n    for t in range(1, T):\n        idx = 2 * (t - 1)\n        # Point on the straight line from s to g\n        pt = s + (t / T) * (g - s)\n        # Clip the point to be within the defined bounds for a feasible start\n        z0[idx] = np.clip(pt[0], lower_bounds[idx], upper_bounds[idx])\n        z0[idx+1] = np.clip(pt[1], lower_bounds[idx+1], upper_bounds[idx+1])\n        \n    # --- Solve Optimization Problem ---\n    res = minimize(\n        objective_func,\n        z0,\n        method='SLSQP',\n        bounds=bounds,\n        constraints=ineq_constraints,\n        options={'disp': False, 'ftol': 1e-9}\n    )\n                   \n    return res.fun\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the solver for each.\n    \"\"\"\n    test_cases = [\n        # Test Case 1\n        {\n            \"T\": 6,\n            \"s\": np.array([0., 1.]),\n            \"g\": np.array([10., 1.]),\n            \"rects\": [\n                {'xmin': 0.0, 'xmax': 2.0, 'ymin': 0.0, 'ymax': 2.0},\n                {'xmin': 1.5, 'xmax': 3.5, 'ymin': 0.0, 'ymax': 2.0},\n                {'xmin': 3.0, 'xmax': 5.0, 'ymin': 0.0, 'ymax': 2.0},\n                {'xmin': 4.5, 'xmax': 6.5, 'ymin': 2.0, 'ymax': 4.0},\n                {'xmin': 6.0, 'xmax': 8.0, 'ymin': 2.0, 'ymax': 4.0},\n                {'xmin': 7.5, 'xmax': 9.5, 'ymin': 0.0, 'ymax': 2.0},\n                {'xmin': 9.5, 'xmax': 11.5, 'ymin': 0.0, 'ymax': 2.0}\n            ]\n        },\n        # Test Case 2\n        {\n            \"T\": 1,\n            \"s\": np.array([2., 2.]),\n            \"g\": np.array([2., 2.]),\n            \"rects\": [\n                {'xmin': 1.0, 'xmax': 3.0, 'ymin': 1.0, 'ymax': 3.0},\n                {'xmin': 1.5, 'xmax': 3.5, 'ymin': 1.5, 'ymax': 3.5}\n            ]\n        },\n        # Test Case 3\n        {\n            \"T\": 5,\n            \"s\": np.array([0., 0.]),\n            \"g\": np.array([5., 0.]),\n            \"rects\": [\n                {'xmin': 0.0, 'xmax': 1.0, 'ymin': 0.0, 'ymax': 1.0},\n                {'xmin': 0.8, 'xmax': 2.0, 'ymin': 0.0, 'ymax': 1.0},\n                {'xmin': 1.8, 'xmax': 3.0, 'ymin': 1.5, 'ymax': 2.5},\n                {'xmin': 2.8, 'xmax': 4.0, 'ymin': 0.0, 'ymax': 1.0},\n                {'xmin': 3.8, 'xmax': 5.0, 'ymin': 0.0, 'ymax': 1.0},\n                {'xmin': 4.5, 'xmax': 5.5, 'ymin': 0.0, 'ymax': 1.0}\n            ]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        min_distance = solve_single_case(case)\n        results.append(f\"{min_distance:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3131028"}, {"introduction": "Our final practice ventures into the domain of decision-making under uncertainty, a common challenge in real-world engineering and finance. Here, we aim to allocate a limited budget over time to minimize the *expected* number of constraint violations in a stochastic system. This problem [@problem_id:3130969] builds upon the principles of the first exercise, using a forward dynamic programming approach to manage probabilistic outcomes. You will implement a recursion that propagates the minimum expected cost, highlighting how these methods can be adapted to find optimal strategies in the face of risk.", "problem": "You are given a finite-horizon stochastic resource allocation problem whose goal is to minimize the expected number of constraint violations. At each discrete time step $t \\in \\{0,1,\\dots,T-1\\}$ you choose a nonnegative scalar decision $x_t \\in \\mathbb{R}_{\\ge 0}$. The system is subject to a stochastic inequality constraint represented by the function $g_t(x_t,\\xi_t) = \\xi_t - x_t$, where $\\xi_t$ is a random variable. A violation at time $t$ occurs when $g_t(x_t,\\xi_t)  0$, equivalently when $\\xi_t  x_t$. Let the running violation count be the forward recursion\n$$\nV_{t+1} = V_t + \\mathbb{1}\\{\\xi_t  x_t\\}, \\quad V_0 = 0,\n$$\nwhere $\\mathbb{1}\\{\\cdot\\}$ denotes the indicator function. Your objective is to choose the sequence $(x_0,\\dots,x_{T-1})$ to minimize the expected total number of violations $\\mathbb{E}[V_T]$, subject to the total budget constraint $\\sum_{t=0}^{T-1} x_t \\le B$.\n\nAssume the following model and foundational facts:\n- For each $t$, the random variables $\\xi_t$ are independent and normally distributed with mean $\\mu_t$ and standard deviation $\\sigma_t$, written $\\xi_t \\sim \\mathcal{N}(\\mu_t,\\sigma_t^2)$.\n- The indicator function satisfies $\\mathbb{E}[\\mathbb{1}\\{A\\}] = \\mathbb{P}(A)$ for any event $A$.\n- Linearity of expectation holds: for random variables $Y_t$, $\\mathbb{E}\\Big[\\sum_t Y_t\\Big] = \\sum_t \\mathbb{E}[Y_t]$.\n- The survival function of a normal random variable is well-defined and numerically computable.\n\nStarting from these bases only (definitions and laws above), do the following.\n\n1) Derive a forward recursion for the conditional expectation of the violation count and conclude a non-asymptotic expression for $\\mathbb{E}[V_T]$ in terms of the decisions $x_t$ and the survival probabilities $\\mathbb{P}(\\xi_t  x_t)$.\n\n2) Reformulate the optimization of $\\mathbb{E}[V_T]$ under the budget constraint as a finite-horizon dynamic program over a discretized action space. Specifically, let the decision grid step be $\\Delta  0$ and restrict each $x_t$ to the grid $\\{0,\\Delta,2\\Delta,\\dots\\}$, so that the cumulative budget spent after $t$ steps is an integer multiple of $\\Delta$. Define a forward dynamic programming state $b_t \\in \\{0,\\Delta,2\\Delta,\\dots,B\\}$ representing the cumulative resource used by time $t$, and define a value function $F_t(b)$ as the minimal expected violation count achievable up to time $t$ using exactly budget $b$. Provide the forward recursion that updates $F_t$ to $F_{t+1}$ and explain how this realizes the forward recursion on expected violation counts while enforcing the budget feasibility $\\sum_{t=0}^{T-1} x_t \\le B$.\n\n3) Implement the forward recursion numerically for the following test suite. In each test case, you must compute:\n- the minimal expected number of violations $\\min \\mathbb{E}[V_T]$ over all $(x_t)$ lying on the grid,\n- and one corresponding grid-feasible optimal allocation $(x_0^\\star,\\dots,x_{T-1}^\\star)$ with $\\sum_{t=0}^{T-1} x_t^\\star \\le B$.\n\nUse the normal survival function to evaluate $\\mathbb{P}(\\xi_t  x_t)$ exactly (no Monte Carlo sampling). Your program must solve each test case by forward dynamic programming and output a single line containing a list of results, one per test case, where each test case result is a list whose first entry is the minimal expected number of violations and whose subsequent entries are the optimal allocations in temporal order.\n\nTest suite:\n- Case A: $T=4$, $\\mu=(1.5,2.0,1.0,3.0)$, $\\sigma=(0.5,1.0,1.5,0.75)$, $B=3.0$, $\\Delta=0.25$.\n- Case B: $T=3$, $\\mu=(0.0,0.5,-0.5)$, $\\sigma=(1.0,1.5,0.5)$, $B=0.0$, $\\Delta=0.5$.\n- Case C: $T=5$, $\\mu=(0.5,0.5,0.5,0.5,0.5)$, $\\sigma=(0.25,0.25,0.25,0.25,0.25)$, $B=5.0$, $\\Delta=0.5$.\n\nOutput format and numerical details:\n- For each test case, output a list whose first element is the minimal expected violation count rounded to six decimal places, followed by the optimal decisions $(x_0^\\star,\\dots,x_{T-1}^\\star)$ as decimal numbers (multiples of $\\Delta$). \n- Aggregate all test case results into a single list and print exactly one line containing that list without any additional text. For example, the printed line should have the form $[\\text{caseA},\\text{caseB},\\text{caseC}]$ where each $\\text{caseX}$ is itself a list as specified.\n- There are no physical units and no angles; all quantities are unitless real numbers.", "solution": "The user wants me to solve a finite-horizon stochastic resource allocation problem.\n\n### Step 1: Extract Givens\n- **Problem Type**: Finite-horizon stochastic resource allocation.\n- **Time Horizon**: Discrete time steps $t \\in \\{0, 1, \\dots, T-1\\}$.\n- **Decision Variables**: A sequence of nonnegative scalar decisions $(x_0, x_1, \\dots, x_{T-1})$, with $x_t \\in \\mathbb{R}_{\\ge 0}$.\n- **Stochastic Constraint Function**: $g_t(x_t, \\xi_t) = \\xi_t - x_t$.\n- **Constraint Violation Event**: A violation occurs at time $t$ if $g_t(x_t, \\xi_t)  0$, which is equivalent to $\\xi_t  x_t$.\n- **Random Variables**: For each $t$, $\\xi_t$ is an independent random variable with distribution $\\xi_t \\sim \\mathcal{N}(\\mu_t, \\sigma_t^2)$.\n- **State Variable (Violation Count)**: The running violation count $V_t$ follows the forward recursion $V_{t+1} = V_t + \\mathbb{1}\\{\\xi_t  x_t\\}$, with initial condition $V_0 = 0$. $\\mathbb{1}\\{\\cdot\\}$ is the indicator function.\n- **Objective Function**: Minimize the expected total number of violations, $\\mathbb{E}[V_T]$.\n- **Budget Constraint**: The total resource usage is limited: $\\sum_{t=0}^{T-1} x_t \\le B$.\n- **Provided Foundational Facts**:\n    1. $\\mathbb{E}[\\mathbb{1}\\{A\\}] = \\mathbb{P}(A)$ for any event $A$.\n    2. Linearity of expectation: $\\mathbb{E}\\left[\\sum_t Y_t\\right] = \\sum_t \\mathbb{E}[Y_t]$.\n    3. The survival function of a normal random variable is well-defined and computable.\n- **Task 1**: Derive a forward recursion for the conditional expectation of the violation count and a non-asymptotic expression for $\\mathbb{E}[V_T]$.\n- **Task 2**: Formulate a forward dynamic program over a discretized action space.\n    - Decision grid step: $\\Delta  0$, $x_t \\in \\{0, \\Delta, 2\\Delta, \\dots\\}$.\n    - DP state: $b_t \\in \\{0, \\Delta, \\dots, B\\}$, cumulative resource used by time $t$.\n    - Value function: $F_t(b)$, minimal expected violation count up to time $t$ using exactly budget $b$.\n    - Provide the forward DP recursion.\n- **Task 3**: Implement the forward DP numerically for three test cases and output the minimal expected violations and a corresponding optimal allocation policy.\n- **Test Cases**:\n    - Case A: $T=4$, $\\mu=(1.5, 2.0, 1.0, 3.0)$, $\\sigma=(0.5, 1.0, 1.5, 0.75)$, $B=3.0$, $\\Delta=0.25$.\n    - Case B: $T=3$, $\\mu=(0.0, 0.5, -0.5)$, $\\sigma=(1.0, 1.5, 0.5)$, $B=0.0$, $\\Delta=0.5$.\n    - Case C: $T=5$, $\\mu=(0.5, 0.5, 0.5, 0.5, 0.5)$, $\\sigma=(0.25, 0.25, 0.25, 0.25, 0.25)$, $B=5.0$, $\\Delta=0.5$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is subjected to a critical review based on the validation criteria.\n\n- **Scientifically Grounded**: The problem is formulated within the well-established mathematical frameworks of probability theory, stochastic processes, and dynamic programming. The use of normal distributions, expectation, and optimization is standard in engineering and operations research. The problem is scientifically sound.\n- **Well-Posed**: The problem is a standard resource allocation problem with a separable objective function and a linear constraint. The objective is to find a sequence of decisions $(x_0, \\dots, x_{T-1})$ that minimizes an expected value. Given the properties of the probability distributions (continuous and well-behaved), a solution exists. The discretization for the dynamic programming approach ensures a unique minimum value can be found. The problem is well-posed.\n- **Objective**: The problem is stated using precise mathematical language and definitions. All quantities are defined, and the objectives are unambiguous. It is free of subjective or opinion-based statements.\n- **Completeness**: All necessary information is provided: the time horizon $T$, the parameters $(\\mu_t, \\sigma_t)$ for the random variables at each stage, the total budget $B$, and the discretization step $\\Delta$. The problem is self-contained.\n- **Consistency**: There are no contradictory constraints or definitions.\n- **Relevance**: The problem directly addresses the topic of forward recursion and its application in optimization methods, specifically dynamic programming.\n\nThe problem statement does not exhibit any of the invalidity flaws. It is a standard, well-defined problem from the field of stochastic optimal control.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A full solution will be provided.\n\n### Solution Derivation and Dynamic Programming Formulation\n\n**1) Expression for the Expected Total Violations $\\mathbb{E}[V_T]$**\n\nThe total number of violations at the end of the horizon, $V_T$, is found by unrolling the given forward recursion for $V_{t+1}$:\n$$\nV_{t+1} = V_t + \\mathbb{1}\\{\\xi_t  x_t\\}, \\quad V_0 = 0\n$$\nUnrolling this from $t=0$ to $T-1$, we obtain:\n$$\nV_T = V_{T-1} + \\mathbb{1}\\{\\xi_{T-1}  x_{T-1}\\}\n$$\n$$\nV_T = \\left(V_{T-2} + \\mathbb{1}\\{\\xi_{T-2}  x_{T-2}\\}\\right) + \\mathbb{1}\\{\\xi_{T-1}  x_{T-1}\\}\n$$\n$$\n\\dots\n$$\n$$\nV_T = V_0 + \\sum_{t=0}^{T-1} \\mathbb{1}\\{\\xi_t  x_t\\}\n$$\nSince $V_0=0$, the total number of violations is simply the sum of the indicator functions over the horizon:\n$$\nV_T = \\sum_{t=0}^{T-1} \\mathbb{1}\\{\\xi_t  x_t\\}\n$$\nThe objective is to minimize the expectation of this quantity, $\\mathbb{E}[V_T]$. Using the provided principle of linearity of expectation, we can write:\n$$\n\\mathbb{E}[V_T] = \\mathbb{E}\\left[\\sum_{t=0}^{T-1} \\mathbb{1}\\{\\xi_t  x_t\\}\\right] = \\sum_{t=0}^{T-1} \\mathbb{E}[\\mathbb{1}\\{\\xi_t  x_t\\}]\n$$\nNow, using the second provided principle, $\\mathbb{E}[\\mathbb{1}\\{A\\}] = \\mathbb{P}(A)$, we have:\n$$\n\\mathbb{E}[V_T] = \\sum_{t=0}^{T-1} \\mathbb{P}(\\xi_t  x_t)\n$$\nThis is the non-asymptotic expression for the expected total violations. The quantity $\\mathbb{P}(\\xi_t  x_t)$ is the survival function of the normal random variable $\\xi_t \\sim \\mathcal{N}(\\mu_t, \\sigma_t^2)$ evaluated at $x_t$.\n\nThe problem also requests a forward recursion for the conditional expectation. Let $E_t = \\mathbb{E}[V_t]$. This represents the unconditional expected number of violations up to time $t-1$. The recursion for this quantity is derived as follows:\n$E_{t+1} = \\mathbb{E}[V_{t+1}] = \\mathbb{E}[V_t + \\mathbb{1}\\{\\xi_t  x_t\\}]$. By linearity of expectation and independence of $\\xi_t$ from past random variables, this becomes:\n$E_{t+1} = \\mathbb{E}[V_t] + \\mathbb{E}[\\mathbb{1}\\{\\xi_t  x_t\\}] = E_t + \\mathbb{P}(\\xi_t  x_t)$.\nWith the initial condition $E_0 = \\mathbb{E}[V_0] = 0$, this establishes the forward recursion for the expected violation count.\n\nThe optimization problem can now be stated as:\n$$\n\\min_{x_0, \\dots, x_{T-1}} \\sum_{t=0}^{T-1} \\mathbb{P}(\\xi_t  x_t)\n$$\nsubject to:\n$$\n\\sum_{t=0}^{T-1} x_t \\le B, \\quad x_t \\ge 0 \\quad \\forall t \\in \\{0, \\dots, T-1\\}\n$$\n\n**2) Forward Dynamic Programming Formulation**\n\nWe reformulate the problem using forward dynamic programming. The problem structure, with an additively separable objective and a linear sum constraint, is ideal for this approach.\n\n- **Stages**: The stages are indexed by time, $t = 0, 1, \\dots, T-1$.\n- **Discretization**: The decisions $x_t$ and budget $B$ are discretized into integer multiples of a step size $\\Delta  0$. We work with integer indices for budget levels to ensure numerical stability. The number of budget levels is $N_b = \\text{round}(B/\\Delta) + 1$. A budget index $k \\in \\{0, 1, \\dots, N_b-1\\}$ corresponds to a budget value of $k\\Delta$.\n- **State**: The state at stage $t$ is the cumulative budget spent up to and including that stage. Let $b_t = \\sum_{i=0}^t x_i$. The state space at stage $t$ is $\\{0, \\Delta, \\dots, B\\}$, which corresponds to integer indices $\\{0, 1, \\dots, N_b-1\\}$.\n- **Value Function**: As specified, $F_t(b)$ is the minimal expected violation count from stage $0$ up to stage $t$, using a cumulative budget of exactly $b$.\n- **Cost Function**: The cost incurred at stage $t$ with decision $x_t$ is $C_t(x_t) = \\mathbb{P}(\\xi_t  x_t)$.\n\nThe DP recursion proceeds as follows:\n\n**Initialization (Stage $t=0$):**\nAt the first stage, the decision $x_0$ determines the initial cumulative budget $b_0 = x_0$. The value function is the cost incurred at this stage.\nFor each possible cumulative budget $b \\in \\{0, \\Delta, \\dots, B\\}$:\n$$\nF_0(b) = C_0(b) = \\mathbb{P}(\\xi_0  b)\n$$\nWe also store the decision that leads to this state, which is simply $x_0 = b$. Let's use a policy table $\\pi_t(b)$ to store the optimal decision $x_t$ for achieving state $b$ at stage $t$. So, $\\pi_0(b) = b$.\n\n**Recursion (Stages $t=1, \\dots, T-1$):**\nTo compute the value function $F_t(b)$ for a cumulative budget $b$ at stage $t$, we consider all possible decisions $x_t \\in \\{0, \\Delta, \\dots, b\\}$ that could have been made at stage $t$. If we spend $x_t$ at stage $t$, the cumulative budget at the previous stage must have been $b - x_t$. The minimal cost to reach that previous state was $F_{t-1}(b - x_t)$. Thus, the new total cost is $F_{t-1}(b - x_t) + C_t(x_t)$. We choose the decision $x_t$ that minimizes this sum.\nFor each $t \\in \\{1, \\dots, T-1\\}$ and for each cumulative budget state $b \\in \\{0, \\Delta, \\dots, B\\}$:\n$$\nF_t(b) = \\min_{x_t \\in \\{0, \\Delta, \\dots, b\\}} \\left\\{ F_{t-1}(b - x_t) + C_t(x_t) \\right\\}\n$$\nThe corresponding optimal decision for this state is stored:\n$$\n\\pi_t(b) = \\arg\\min_{x_t \\in \\{0, \\Delta, \\dots, b\\}} \\left\\{ F_{t-1}(b - x_t) + C_t(x_t) \\right\\}\n$$\n\n**Final Solution and Policy Reconstruction:**\nAfter computing the value function table up to stage $T-1$, the overall minimum expected violation count is the minimum value in the final row of the table, since the total budget used can be any value up to $B$.\n$$\n\\min \\mathbb{E}[V_T] = \\min_{b \\in \\{0, \\Delta, \\dots, B\\}} F_{T-1}(b)\n$$\nLet $B^\\star$ be the optimal final cumulative budget that achieves this minimum:\n$$\nB^\\star = \\arg\\min_{b \\in \\{0, \\Delta, \\dots, B\\}} F_{T-1}(b)\n$$\nThe optimal allocation sequence $(x_0^\\star, x_1^\\star, \\dots, x_{T-1}^\\star)$ is reconstructed by backtracking from this final optimal state:\n- Let $b_{T-1}^\\star = B^\\star$.\n- $x_{T-1}^\\star = \\pi_{T-1}(b_{T-1}^\\star)$.\n- For $t = T-2, \\dots, 1$:\n    - The cumulative budget at stage $t$ was $b_t^\\star = b_{t+1}^\\star - x_{t+1}^\\star$.\n    - The decision was $x_t^\\star = \\pi_t(b_t^\\star)$.\n- Finally, for $t=0$:\n    - The cumulative budget at stage $0$ was $b_0^\\star = b_1^\\star - x_1^\\star$.\n    - The decision was $x_0^\\star = \\pi_0(b_0^\\star) = b_0^\\star$.\n\nThis procedure yields the minimum expected number of violations and a corresponding grid-feasible optimal allocation.\n\n**3) Numerical Implementation**\n\nThe logic described above is implemented in Python. The probability $\\mathbb{P}(\\xi_t  x_t)$ for $\\xi_t \\sim \\mathcal{N}(\\mu_t, \\sigma_t^2)$ is computed using the survival function `scipy.stats.norm.sf(x_t, loc=mu_t, scale=sigma_t)`. The DP table is built using `numpy` arrays, and the backtracking procedure recovers the optimal policy. The implementation handles the specified test cases and formats the output as required.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Solves a stochastic resource allocation problem using forward dynamic programming.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"T\": 4,\n            \"mu\": (1.5, 2.0, 1.0, 3.0),\n            \"sigma\": (0.5, 1.0, 1.5, 0.75),\n            \"B\": 3.0,\n            \"Delta\": 0.25,\n        },\n        {\n            \"T\": 3,\n            \"mu\": (0.0, 0.5, -0.5),\n            \"sigma\": (1.0, 1.5, 0.5),\n            \"B\": 0.0,\n            \"Delta\": 0.5,\n        },\n        {\n            \"T\": 5,\n            \"mu\": (0.5, 0.5, 0.5, 0.5, 0.5),\n            \"sigma\": (0.25, 0.25, 0.25, 0.25, 0.25),\n            \"B\": 5.0,\n            \"Delta\": 0.5,\n        },\n    ]\n\n    results = []\n\n    for case in test_cases:\n        T = case[\"T\"]\n        mu = case[\"mu\"]\n        sigma = case[\"sigma\"]\n        B = case[\"B\"]\n        Delta = case[\"Delta\"]\n\n        # Use integer indices for budget levels to avoid floating point issues\n        # Number of discrete budget levels\n        num_budget_levels = int(round(B / Delta)) + 1\n        \n        # DP table F[t][b_idx] stores the min cost up to stage t with cumulative budget b_idx*Delta\n        F = np.full((T, num_budget_levels), np.inf)\n        \n        # Policy table pi[t][b_idx] stores the optimal decision x_t\n        pi = np.full((T, num_budget_levels), np.nan)\n\n        # Precompute costs C[t][x_idx] = P(xi_t > x_idx*Delta)\n        # The decision x_t can be at most B\n        num_decision_levels = int(round(B / Delta)) + 1\n        C = np.zeros((T, num_decision_levels))\n        for t in range(T):\n            for x_idx in range(num_decision_levels):\n                x_val = x_idx * Delta\n                C[t, x_idx] = norm.sf(x_val, loc=mu[t], scale=sigma[t])\n\n        # Initialization (Stage t=0)\n        # The cumulative budget b_0 is simply the decision x_0\n        for b0_idx in range(num_budget_levels):\n            x0_idx = b0_idx\n            F[0, b0_idx] = C[0, x0_idx]\n            pi[0, b0_idx] = x0_idx * Delta\n\n        # Forward recursion (Stages t=1 to T-1)\n        for t in range(1, T):\n            for b_cum_idx in range(num_budget_levels):\n                min_cost = np.inf\n                best_xt_val = -1.0\n\n                # Iterate through possible decisions x_t at stage t\n                # The cumulative budget b_cum_idx is already given.\n                # The decision x_t can't be larger than the cumulative budget\n                max_xt_idx = b_cum_idx\n                for xt_idx in range(max_xt_idx + 1):\n                    b_prev_idx = b_cum_idx - xt_idx\n                    \n                    cost_at_t = C[t, xt_idx]\n                    total_cost = F[t - 1, b_prev_idx] + cost_at_t\n\n                    if total_cost  min_cost:\n                        min_cost = total_cost\n                        best_xt_val = xt_idx * Delta\n                \n                F[t, b_cum_idx] = min_cost\n                pi[t, b_cum_idx] = best_xt_val\n\n        # Find the final optimal solution\n        # The total budget can be = B, so we look for min cost across all final states\n        final_costs = F[T - 1, :]\n        min_total_cost = np.min(final_costs)\n        \n        # In case of ties, numpy.argmin returns the first occurrence\n        final_b_cum_idx = np.argmin(final_costs)\n        final_b_cum_val = final_b_cum_idx * Delta\n\n        # Backtrack to find the optimal allocation\n        x_opt = np.zeros(T)\n        current_b_cum = final_b_cum_val\n        for t in range(T - 1, -1, -1):\n            current_b_cum_idx = int(round(current_b_cum / Delta))\n            x_opt[t] = pi[t, current_b_cum_idx]\n            current_b_cum -= x_opt[t]\n        \n        # Format the output for the current case\n        case_result = [f\"{min_total_cost:.6f}\"]\n        case_result.extend([f\"{val}\" for val in x_opt])\n        results.append(case_result)\n\n    # Format the final output string as a list of lists\n    # Example: [[...], [...], [...]]\n    output_str = \"[\" + \",\".join([\"[\" + \",\".join(map(str, res)) + \"]\" for res in results]) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "3130969"}]}