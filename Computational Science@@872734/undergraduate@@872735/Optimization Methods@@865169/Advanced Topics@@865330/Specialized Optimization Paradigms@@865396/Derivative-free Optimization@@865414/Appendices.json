{"hands_on_practices": [{"introduction": "Many derivative-free optimization methods rely on an iterative search process, and a crucial element is deciding how large of a step to take at each iteration. This exercise explores a fundamental adaptive strategy used in Pattern Search algorithms, where the step size, $\\Delta$, is adjusted based on the outcome of the search. Understanding this simple but powerful logic—expanding when successful and contracting when not—provides a foundational insight into how many direct search methods navigate the solution space without gradients [@problem_id:2166475].", "problem": "An engineer is using a Pattern Search (PS) algorithm to optimize a system's performance, which is dependent on two parameters. The goal is to find the parameter values that minimize a cost function $f(x, y)$. The PS algorithm is an iterative, derivative-free method that adjusts a step size, $\\Delta$, based on the outcome of each iteration.\n\nThe step-size update rule for this particular implementation is defined as follows:\n- At the start of iteration $k$, the algorithm possesses a step size $\\Delta_k$.\n- If the iteration is **successful**, meaning a new set of parameters with a lower cost function value is found, the step size for the next iteration, $\\Delta_{k+1}$, remains the same: $\\Delta_{k+1} = \\Delta_k$.\n- If the iteration is **unsuccessful**, meaning no better parameter set is found after exploring the vicinity of the current best point, the step size is reduced for the next iteration using a contraction factor $\\theta$: $\\Delta_{k+1} = \\theta \\Delta_k$.\n\nThe optimization process begins with an initial step size of $\\Delta_0 = 1.00$. The contraction factor is given as $\\theta = 0.400$. The algorithm runs for five full iterations, with the outcomes recorded in sequence as: Success, Fail, Success, Fail, Fail.\n\nCalculate the value of the step size, denoted as $\\Delta_5$, after the completion of the fifth iteration. Provide your answer as a numerical value, rounded to three significant figures.", "solution": "We use the given step-size update rule: at the start of iteration $k$ the step size is $\\Delta_{k}$. After iteration $k$, if the iteration is successful, $\\Delta_{k+1} = \\Delta_{k}$; if it fails, $\\Delta_{k+1} = \\theta \\Delta_{k}$.\n\nWith initial $\\Delta_{0} = 1.00$ and contraction factor $\\theta = 0.400$, and the five outcomes in order: Success, Fail, Success, Fail, Fail, we update as follows (indexing iterations as $k=0,1,2,3,4$ to match $\\Delta_{0}$ being the initial step size):\n\nIteration $k=0$ (Success): \n$$\\Delta_{1} = \\Delta_{0}.$$\n\nIteration $k=1$ (Fail): \n$$\\Delta_{2} = \\theta \\Delta_{1}.$$\n\nIteration $k=2$ (Success): \n$$\\Delta_{3} = \\Delta_{2} = \\theta \\Delta_{1}.$$\n\nIteration $k=3$ (Fail): \n$$\\Delta_{4} = \\theta \\Delta_{3} = \\theta^{2} \\Delta_{1}.$$\n\nIteration $k=4$ (Fail): \n$$\\Delta_{5} = \\theta \\Delta_{4} = \\theta^{3} \\Delta_{1}.$$\n\nSince $\\Delta_{1} = \\Delta_{0}$, we have \n$$\\Delta_{5} = \\theta^{3} \\Delta_{0}.$$\n\nSubstituting the given numerical values and rounding to three significant figures,\n$$\\Delta_{5} = (0.400)^{3} \\times 1.00 = 0.0640.$$", "answer": "$$\\boxed{0.0640}$$", "id": "2166475"}, {"introduction": "Moving from single-point search methods, we now explore population-based heuristics inspired by nature. This problem delves into the core mechanics of Particle Swarm Optimization (PSO), a method that models the collective behavior of bird flocks or fish schools. You will calculate a single velocity update for one \"particle,\" observing how its movement is a blend of its own momentum, its personal best experience (the cognitive component), and the collective wisdom of the entire swarm (the social component) [@problem_id:2166499].", "problem": "An autonomous drone is part of a swarm searching for the location of a maximum intensity radio signal in a large, open field, which is modeled as a 2D Cartesian plane. The search is guided by the Particle Swarm Optimization (PSO) algorithm. At each time step, every drone updates its velocity based on its current velocity, its own best-found position, and the best-found position by any drone in the entire swarm.\n\nThe velocity update for a single particle (drone) at time step $t+1$ is given by the equation:\n$$ \\mathbf{v}(t+1) = \\omega \\mathbf{v}(t) + c_1 r_1 (\\mathbf{p} - \\mathbf{x}(t)) + c_2 r_2 (\\mathbf{g} - \\mathbf{x}(t)) $$\nwhere:\n- $\\mathbf{v}(t)$ is the drone's current velocity vector.\n- $\\mathbf{x}(t)$ is the drone's current position vector.\n- $\\mathbf{p}$ is the drone's personal best position found so far.\n- $\\mathbf{g}$ is the global best position found by the entire swarm so far.\n- $\\omega$ is the inertia weight, controlling the influence of the previous velocity.\n- $c_1$ and $c_2$ are the cognitive and social coefficients, respectively, which weight the influence of the personal and global best positions.\n- $r_1$ and $r_2$ are random numbers uniformly distributed in $[0, 1]$.\n\nConsider a specific drone at a particular time step $t$. The state of this drone and the swarm parameters are given as follows:\n- Current position: $$\\mathbf{x}(t) = \\begin{pmatrix} 8.0 \\\\ 14.0 \\end{pmatrix}$$\n- Current velocity: $$\\mathbf{v}(t) = \\begin{pmatrix} -1.0 \\\\ 2.0 \\end{pmatrix}$$\n- Personal best position: $$\\mathbf{p} = \\begin{pmatrix} 10.0 \\\\ 12.0 \\end{pmatrix}$$\n- Global best position: $$\\mathbf{g} = \\begin{pmatrix} 11.0 \\\\ 10.0 \\end{pmatrix}$$\n- Inertia weight: $\\omega = 0.7$\n- Cognitive coefficient: $c_1 = 1.5$\n- Social coefficient: $c_2 = 1.5$\nFor this specific update step, the generated random numbers are $r_1 = 0.4$ and $r_2 = 0.9$.\n\nCalculate the drone's new velocity vector, $\\mathbf{v}(t+1)$. All positions are given in meters and velocities in meters per second (m/s). Express your answer as a 2-element row matrix $[v_x, v_y]$ in m/s. Round each component of the vector to three significant figures.", "solution": "We apply the PSO velocity update rule\n$$\\mathbf{v}(t+1)=\\omega \\mathbf{v}(t)+c_{1}r_{1}\\left(\\mathbf{p}-\\mathbf{x}(t)\\right)+c_{2}r_{2}\\left(\\mathbf{g}-\\mathbf{x}(t)\\right).$$\nCompute the displacement vectors:\n$$\\mathbf{p}-\\mathbf{x}(t)=\\begin{pmatrix}10.0-8.0 \\\\ 12.0-14.0\\end{pmatrix}=\\begin{pmatrix}2 \\\\ -2\\end{pmatrix},\\quad \\mathbf{g}-\\mathbf{x}(t)=\\begin{pmatrix}11.0-8.0 \\\\ 10.0-14.0\\end{pmatrix}=\\begin{pmatrix}3 \\\\ -4\\end{pmatrix}.$$\nCompute each term:\n$$\\omega \\mathbf{v}(t)=0.7\\begin{pmatrix}-1.0 \\\\ 2.0\\end{pmatrix}=\\begin{pmatrix}-0.7 \\\\ 1.4\\end{pmatrix},$$\n$$c_{1}r_{1}\\left(\\mathbf{p}-\\mathbf{x}(t)\\right)=1.5\\cdot 0.4\\begin{pmatrix}2 \\\\ -2\\end{pmatrix}=0.6\\begin{pmatrix}2 \\\\ -2\\end{pmatrix}=\\begin{pmatrix}1.2 \\\\ -1.2\\end{pmatrix},$$\n$$c_{2}r_{2}\\left(\\mathbf{g}-\\mathbf{x}(t)\\right)=1.5\\cdot 0.9\\begin{pmatrix}3 \\\\ -4\\end{pmatrix}=1.35\\begin{pmatrix}3 \\\\ -4\\end{pmatrix}=\\begin{pmatrix}4.05 \\\\ -5.4\\end{pmatrix}.$$\nSum the contributions to obtain\n$$\\mathbf{v}(t+1)=\\begin{pmatrix}-0.7 \\\\ 1.4\\end{pmatrix}+\\begin{pmatrix}1.2 \\\\ -1.2\\end{pmatrix}+\\begin{pmatrix}4.05 \\\\ -5.4\\end{pmatrix}=\\begin{pmatrix}4.55 \\\\ -5.2\\end{pmatrix}.$$\nRounding each component to three significant figures gives\n$$\\mathbf{v}(t+1)=\\begin{pmatrix}4.55 \\\\ -5.20\\end{pmatrix}.$$\nExpressed as a row matrix, this is $\\begin{pmatrix}4.55  -5.20\\end{pmatrix}$ in meters per second.", "answer": "$$\\boxed{\\begin{pmatrix}4.55  -5.20\\end{pmatrix}}$$", "id": "2166499"}, {"introduction": "This advanced practice challenges you to transition from performing single-step calculations to building a complete optimization tool from scratch. You will implement a simple but effective trust-region method using a compass search, a technique that explores a set of fixed directions around the current point. By coding the algorithm and testing it on various functions, you will gain a deep appreciation for the interplay between step acceptance, trust-region radius updates, and the overall convergence behavior of a derivative-free optimizer [@problem_id:3117671].", "problem": "You are asked to implement and analyze a simple derivative-free trust-region optimization method in two dimensions. The goal is to investigate how the trust-region radius update rule influences convergence speed and stability for different objective functions and parameter choices. The fundamental base for this task consists of the definition of a trust region and the general mechanism of iterative optimization: starting from an initial point, propose steps within a neighborhood and accept steps that decrease the objective while updating the neighborhood size based on success or failure.\n\nDefinitions and setup:\n- Consider a function $f:\\mathbb{R}^2\\to\\mathbb{R}$ that can be evaluated at any point but for which gradients are not available. This falls under Derivative-Free Optimization (DFO).\n- A trust region is characterized by a radius $\\Delta_k  0$ at iteration $k$, which constrains the step $s_k$ to satisfy $\\|s_k\\|_2 \\le \\Delta_k$.\n- A step is deemed a success if it produces a strict decrease $f(x_k + s_k)  f(x_k)$, and a failure otherwise.\n- The trust-region radius update rule is:\n  $$\\Delta_{k+1} = \\gamma \\Delta_k \\text{ on success, and } \\Delta_{k+1} = \\beta \\Delta_k \\text{ on failure},$$\n  where $\\gamma  1$ and $0  \\beta  1$.\n- A simple search mechanism without derivatives (compass search) explores a finite set of directions $d \\in \\mathcal{D}$ and evaluates $f(x_k + s)$ for $s = \\Delta_k \\, d / \\|d\\|_2$ to respect the trust-region constraint. Use the direction set\n  $$\\mathcal{D} = \\{(1,0), (-1,0), (0,1), (0,-1), (1,1), (-1,1), (1,-1), (-1,-1)\\}.$$\n- Acceptance rule: if any trial point within these directions yields a strict decrease, accept the best-decreasing trial; otherwise declare failure and keep $x_{k+1} = x_k$.\n\nImplement the following in your program:\n1. A routine that, given an objective $f$, an initial point $x_0 \\in \\mathbb{R}^2$, an initial radius $\\Delta_0  0$, parameters $\\gamma  1$, $\\beta \\in (0,1)$, a maximum radius $\\Delta_{\\max}  0$, a tolerance $\\varepsilon  0$, and a maximum number of iterations $N_{\\max}$, performs iterative compass search within the trust region. At each iteration $k$, evaluate $f$ at the current point and along all directions in $\\mathcal{D}$ at step length $\\Delta_k$. Accept the best strict decrease, expand the radius by the factor $\\gamma$ (capped by $\\Delta_{\\max}$), or otherwise shrink the radius by the factor $\\beta$.\n2. Terminate when either the trust-region radius satisfies $\\Delta_k  \\varepsilon$ (declare convergence) or when $k$ reaches $N_{\\max}$ (declare non-convergence).\n3. Track and report:\n   - The total number of iterations $k_{\\text{end}}$ executed.\n   - The total number of function evaluations (including the current point and all trial points).\n   - The final objective value $f(x_{k_{\\text{end}}})$.\n   - A boolean flag indicating convergence (true if $\\Delta_k  \\varepsilon$ at termination).\n   - The failure fraction defined as the number of failure iterations divided by $k_{\\text{end}}$, expressed as a decimal.\n\nObjective functions to use:\n- Convex bowl (sphere): $$f_1(x) = x_1^2 + x_2^2.$$\n- Narrow valley (Rosenbrock): $$f_2(x) = 100\\left(x_2 - x_1^2\\right)^2 + \\left(1 - x_1\\right)^2.$$\n- Nondifferentiable absolute sum: $$f_3(x) = |x_1| + |x_2|.$$\n\nTest suite:\nRun the optimizer on the following parameter sets (each one is a separate test case). In every case, $x_0$ is two-dimensional and all scalars are real numbers.\n- Case A (happy path, convex bowl): $f=f_1$, $x_0 = [2.0, -1.5]$, $\\Delta_0 = 1.0$, $\\Delta_{\\max} = 10.0$, $\\gamma = 2.0$, $\\beta = 0.5$, $\\varepsilon = 10^{-6}$, $N_{\\max} = 500$.\n- Case B (narrow valley, moderate parameters): $f=f_2$, $x_0 = [-1.2, 1.0]$, $\\Delta_0 = 0.5$, $\\Delta_{\\max} = 10.0$, $\\gamma = 1.5$, $\\beta = 0.7$, $\\varepsilon = 10^{-6}$, $N_{\\max} = 1000$.\n- Case C (nondifferentiable, aggressive expansion, strong shrink): $f=f_3$, $x_0 = [3.0, -4.0]$, $\\Delta_0 = 1.0$, $\\Delta_{\\max} = 20.0$, $\\gamma = 3.0$, $\\beta = 0.2$, $\\varepsilon = 10^{-6}$, $N_{\\max} = 500$.\n- Case D (near-boundary parameters, slow radius change): $f=f_1$, $x_0 = [2.0, -1.5]$, $\\Delta_0 = 1.0$, $\\Delta_{\\max} = 10.0$, $\\gamma = 1.05$, $\\beta = 0.95$, $\\varepsilon = 10^{-6}$, $N_{\\max} = 500$.\n- Case E (narrow valley, very aggressive parameters): $f=f_2$, $x_0 = [-1.2, 1.0]$, $\\Delta_0 = 0.25$, $\\Delta_{\\max} = 10.0$, $\\gamma = 4.0$, $\\beta = 0.1$, $\\varepsilon = 10^{-6}$, $N_{\\max} = 1000$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case’s result must be a list in the form $[k_{\\text{end}}, \\text{evals}, f_{\\text{final}}, \\text{converged}, \\text{failure\\_fraction}]$ where $k_{\\text{end}}$ and $\\text{evals}$ are integers, $f_{\\text{final}}$ and $\\text{failure\\_fraction}$ are floats, and $\\text{converged}$ is a boolean. For example, the output should look like\n$$\\big[ [3,9,0.0,\\text{True},0.3333333333], [\\dots] \\big].$$", "solution": "The user requests the implementation and analysis of a derivative-free trust-region optimization algorithm based on a compass search strategy. The problem is well-defined, scientifically sound, and provides all necessary parameters and specifications for a complete implementation. The core of the task is to build an iterative optimizer and evaluate its performance on a suite of test cases involving standard benchmark functions.\n\n### Algorithm Design and Principles\n\nThe optimization method is an iterative process designed to find a local minimum of a function $f: \\mathbb{R}^2 \\to \\mathbb{R}$ without access to its derivatives. Starting from an initial point $x_0$, the algorithm generates a sequence of points $\\{x_k\\}_{k=0,1,2,\\dots}$ that ideally converges to a minimizer. Each iteration involves exploring the local neighborhood of the current point $x_k$ for a better point. This neighborhood is defined by a trust region, a ball of radius $\\Delta_k$ centered at $x_k$.\n\n**1. State Variables**\nThe state of the algorithm at iteration $k$ is defined by two main variables:\n- The current iterate, $x_k \\in \\mathbb{R}^2$.\n- The trust-region radius, $\\Delta_k  0$.\n\n**2. Step Generation: Compass Search**\nAt each iteration $k$, we probe a set of trial points around $x_k$. The directions for these probes are given by a fixed set of $8$ vectors:\n$$\n\\mathcal{D} = \\{(1,0), (-1,0), (0,1), (0,-1), (1,1), (-1,1), (1,-1), (-1,-1)\\}\n$$\nTo ensure the trial steps respect the trust region constraint $\\|s_k\\|_2 \\le \\Delta_k$, the actual steps $s$ are constructed by scaling the direction vectors $d \\in \\mathcal{D}$ to have a length of exactly $\\Delta_k$. A trial step is thus defined as:\n$$\ns = \\Delta_k \\frac{d}{\\|d\\|_2}\n$$\nThis creates $8$ trial points $x_k + s$ on the boundary of the trust region.\n\n**3. Step Acceptance and State Update**\nThe core logic of each iteration is to evaluate the objective function $f$ at all $8$ trial points and compare them to the value at the current point, $f(x_k)$.\n\n- **Success:** An iteration is successful if at least one trial point $x_k + s$ yields a strict improvement, i.e., $f(x_k + s)  f(x_k)$. If multiple trial points lead to an improvement, the one that results in the smallest function value is selected. Let this best step be $s^*$. The state is then updated as follows:\n  - The next iterate is accepted: $x_{k+1} = x_k + s^*$.\n  - The trust-region radius is expanded to explore a larger area in the next iteration, reflecting confidence in the current search direction. The new radius is $\\Delta_{k+1} = \\gamma \\Delta_k$, where $\\gamma  1$ is the expansion factor. This expansion is capped by a maximum allowable radius, $\\Delta_{\\max}$, so the update rule is $\\Delta_{k+1} = \\min(\\gamma \\Delta_k, \\Delta_{\\max})$.\n\n- **Failure:** An iteration is a failure if none of the $8$ trial points result in a function value strictly lower than $f(x_k)$. This suggests that the current trust-region radius $\\Delta_k$ is too large to find local improvement. The state is updated as follows:\n  - The position is not changed: $x_{k+1} = x_k$.\n  - The trust-region radius is contracted to focus the search on a smaller, more promising neighborhood. The new radius is $\\Delta_{k+1} = \\beta \\Delta_k$, where $0  \\beta  1$ is the contraction factor.\n\n**4. Termination Criteria**\nThe iterative process continues until one of two conditions is met:\n- **Convergence:** The algorithm terminates successfully if the trust-region radius becomes very small, i.e., $\\Delta_k  \\varepsilon$, where $\\varepsilon$ is a small positive tolerance. This indicates that the search has been refined to a very small scale, and $x_k$ is considered a close approximation of a local minimum.\n- **Maximum Iterations:** The algorithm terminates without convergence if the number of iterations $k$ reaches a predefined maximum, $N_{\\max}$. This serves as a safeguard against an excessively long or non-converging run.\n\n**5. Performance Metrics Calculation**\nTo analyze the algorithm's behavior, several metrics are tracked:\n- **Total Iterations ($k_{\\text{end}}$):** The total number of iterations performed before termination.\n- **Total Function Evaluations:** At the start, $f(x_0)$ is computed once. In each of the $k_{\\text{end}}$ iterations, the function is evaluated at all $8$ trial points. Thus, the total number of evaluations is $1 + 8 \\times k_{\\text{end}}$.\n- **Final Objective Value ($f_{\\text{final}}$):** The value of the objective function at the final point, $f(x_{k_{\\text{end}}})$.\n- **Convergence Flag:** A boolean value indicating whether termination was due to convergence ($\\Delta_k  \\varepsilon$) or reaching $N_{\\max}$.\n- **Failure Fraction:** The ratio of the number of failed iterations to the total number of iterations, $k_{\\text{end}}$. This metric provides insight into the efficiency of the search process.\n\n### Implementation\nThe implementation encapsulates this logic into a single function. This function takes the objective function, initial parameters, and control settings as input and returns the specified performance metrics. The core of the implementation involves a loop that executes the search-evaluate-update cycle. Vector operations are handled using the `numpy` library for efficiency and clarity. The test suite is executed by calling this function for each specified parameter set and collecting the results. The final output is formatted into a precise string representation as requested.", "answer": "```python\nimport numpy as np\n\ndef f1(x: np.ndarray) - float:\n    \"\"\"Convex bowl (sphere) function.\"\"\"\n    return x[0]**2 + x[1]**2\n\ndef f2(x: np.ndarray) - float:\n    \"\"\"Narrow valley (Rosenbrock) function.\"\"\"\n    return 100.0 * (x[1] - x[0]**2)**2 + (1.0 - x[0])**2\n\ndef f3(x: np.ndarray) - float:\n    \"\"\"Nondifferentiable absolute sum function.\"\"\"\n    return np.abs(x[0]) + np.abs(x[1])\n\ndef run_optimizer(f, x0, delta0, delta_max, gamma, beta, epsilon, n_max):\n    \"\"\"\n    Performs derivative-free trust-region optimization using compass search.\n    \"\"\"\n    x_k = np.array(x0, dtype=float)\n    delta_k = float(delta0)\n    k = 0\n    num_failures = 0\n\n    # Direction set from the problem description\n    D = np.array([\n        [1.0, 0.0], [-1.0, 0.0], [0.0, 1.0], [0.0, -1.0],\n        [1.0, 1.0], [-1.0, 1.0], [1.0, -1.0], [-1.0, -1.0]\n    ], dtype=float)\n\n    # Pre-normalize the direction vectors\n    norms = np.linalg.norm(D, axis=1)\n    D_normalized = D / norms[:, np.newaxis]\n\n    # Initial function evaluation\n    f_k = f(x_k)\n    total_evals = 1\n\n    while k  n_max:\n        if delta_k  epsilon:\n            break\n\n        # Generate trial points and evaluate\n        f_best_trial = f_k\n        best_s = None\n        \n        trial_steps = delta_k * D_normalized\n        total_evals += len(D_normalized)\n\n        for s in trial_steps:\n            x_trial = x_k + s\n            f_trial = f(x_trial)\n            if f_trial  f_best_trial:\n                f_best_trial = f_trial\n                best_s = s\n        \n        # Update based on success or failure\n        if best_s is not None:  # Success\n            x_k = x_k + best_s\n            f_k = f_best_trial\n            delta_k = min(gamma * delta_k, delta_max)\n        else:  # Failure\n            num_failures += 1\n            delta_k = beta * delta_k\n        \n        k += 1\n\n    # Prepare results\n    k_end = k\n    converged = delta_k  epsilon\n    f_final = f_k\n    failure_fraction = num_failures / k_end if k_end  0 else 0.0\n\n    return [k_end, total_evals, f_final, converged, failure_fraction]\n\ndef solve():\n    \"\"\"\n    Runs the optimizer on the test suite and prints the formatted results.\n    \"\"\"\n    functions = {\n        'f1': f1,\n        'f2': f2,\n        'f3': f3,\n    }\n\n    test_cases = [\n        # Case A\n        {'f_name': 'f1', 'x0': [2.0, -1.5], 'delta0': 1.0, 'delta_max': 10.0, \n         'gamma': 2.0, 'beta': 0.5, 'epsilon': 1e-6, 'n_max': 500},\n        # Case B\n        {'f_name': 'f2', 'x0': [-1.2, 1.0], 'delta0': 0.5, 'delta_max': 10.0,\n         'gamma': 1.5, 'beta': 0.7, 'epsilon': 1e-6, 'n_max': 1000},\n        # Case C\n        {'f_name': 'f3', 'x0': [3.0, -4.0], 'delta0': 1.0, 'delta_max': 20.0,\n         'gamma': 3.0, 'beta': 0.2, 'epsilon': 1e-6, 'n_max': 500},\n        # Case D\n        {'f_name': 'f1', 'x0': [2.0, -1.5], 'delta0': 1.0, 'delta_max': 10.0,\n         'gamma': 1.05, 'beta': 0.95, 'epsilon': 1e-6, 'n_max': 500},\n        # Case E\n        {'f_name': 'f2', 'x0': [-1.2, 1.0], 'delta0': 0.25, 'delta_max': 10.0,\n         'gamma': 4.0, 'beta': 0.1, 'epsilon': 1e-6, 'n_max': 1000},\n    ]\n\n    all_results = []\n    for case in test_cases:\n        f = functions[case.pop('f_name')]\n        result = run_optimizer(f, **case)\n        all_results.append(result)\n    \n    formatted_results = []\n    for res in all_results:\n        # Format: [k_end, evals, f_final, converged, failure_fraction]\n        # Python's default str for bool ('True'/'False') and float is sufficient.\n        inner_str = f\"[{res[0]},{res[1]},{res[2]},{res[3]},{res[4]}]\"\n        formatted_results.append(inner_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3117671"}]}