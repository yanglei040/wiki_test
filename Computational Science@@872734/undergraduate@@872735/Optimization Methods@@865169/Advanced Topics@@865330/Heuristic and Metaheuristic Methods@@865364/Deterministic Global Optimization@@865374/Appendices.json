{"hands_on_practices": [{"introduction": "A cornerstone of the Branch and Bound algorithm is the ability to compute a valid lower bound on the objective function over a given sub-domain. This is typically achieved by solving a \"convex relaxation,\" where the challenging non-convex parts of the problem are replaced by simpler, convex stand-ins that enclose the original feasible region. This first exercise [@problem_id:3118809] guides you through this fundamental process from first principles, demonstrating how to construct a tight convex relaxation for a non-convex function and use it to find a guaranteed lower bound on a least-squares objective.", "problem": "Consider the scalar decision variable $x$ constrained to an interval $[l,u]$ with $0<l<u$. A measurement model with saturation effects is given by the function $y(x)=\\min\\{M,x^{2}\\}$, where $M>0$ is a saturation level. A single-measurement least-squares misfit is defined as the objective $J(x)=\\left(y(x)-b\\right)^{2}$ for a given target $b\\in\\mathbb{R}$. In Deterministic Global Optimization using Branch and Bound (B&B), lower bounds on $J(x)$ over a current node $x\\in[l,u]$ can be obtained by convex relaxation. Starting from the fundamental definitions of convexity and the convex hull, derive a tight convex relaxation of the graph of $y=x^{2}$ over $x\\in[l,u]$ using the secant line through $(l,l^{2})$ and $(u,u^{2})$, and incorporate the saturation constraint $y\\leq M$ to construct a relaxation set in $(x,y)$. Then, use this relaxation to obtain an explicit lower bound on $\\min_{x\\in[l,u]} J(x)$.\n\nCarry out this derivation step by step, beginning from the definition of a convex function and the convex hull of a set, and conclude with a closed-form lower bound that depends only on $l$, $u$, $M$, and $b$. Finally, evaluate this lower bound numerically for $l=1$, $u=3$, $M=6$, and $b=8$, and provide the resulting bound on $\\min_{x\\in[1,3]} \\left(\\min\\{6,x^{2}\\}-8\\right)^{2}$. Round your final numerical answer to four significant figures.", "solution": "The problem requires the derivation of a lower bound for a non-convex optimization problem using convex relaxation, a cornerstone of deterministic global optimization methods like Branch and Bound.\n\nFirst, we reformulate the problem by introducing an auxiliary variable $y$ to handle the non-convex term. The original problem $\\min_{x \\in [l, u]} (\\min\\{M, x^2\\} - b)^2$ is equivalent to:\n$$ \\min_{x,y} (y-b)^2 $$\nsubject to:\n$$ y = \\min\\{M, x^2\\} $$\n$$ x \\in [l, u] $$\nThe equality constraint can be decomposed into a set of constraints defining the feasible region in the $(x,y)$-space: $y \\le M$, $y = x^2$, and $l \\le x \\le u$. The constraint $y=x^2$ is non-convex. To create a convex relaxation, we replace this non-convex constraint with its convex hull over the interval $x \\in [l, u]$.\n\nSince the function $f(x)=x^2$ is convex, the convex hull of its graph over $[l, u]$ is the region bounded below by the function itself and above by the secant line connecting the endpoints $(l, l^2)$ and $(u, u^2)$. The equation of the secant line $y_s(x)$ is:\n$$ y_s(x) = (l+u)x - lu $$\nThus, the non-convex constraint $y=x^2$ is relaxed to the convex set of inequalities:\n$$ x^2 \\le y \\le (l+u)x - lu $$\nThe complete convex relaxed feasible set $\\mathcal{R}$ is defined by:\n$$ \\mathcal{R} = \\{ (x,y) \\in \\mathbb{R}^2 \\mid l \\le x \\le u, \\quad x^2 \\le y \\le (l+u)x - lu, \\quad y \\le M \\} $$\nThe relaxed optimization problem, which provides a lower bound on the original problem, is:\n$$ L_B = \\min_{(x,y) \\in \\mathcal{R}} (y-b)^2 $$\nSince the objective function $(y-b)^2$ depends only on $y$, we can find the solution by first determining the feasible range of values for $y$ within the set $\\mathcal{R}$, and then minimizing the objective over this range. The range of $y$ for which there exists an $x \\in [l, u]$ satisfying $x^2 \\le y \\le (l+u)x - lu$ is the interval $[l^2, u^2]$. Combining this with the constraint $y \\le M$, the set of all possible values for $y$ in the relaxed problem is the interval $Y = [l^2, \\min(M, u^2)]$.\n\nThe lower bound problem now reduces to a simple one-dimensional minimization:\n$$ L_B = \\min_{y \\in [l^2, \\min(M, u^2)]} (y-b)^2 $$\nThe unconstrained minimum of $(y-b)^2$ occurs at $y=b$. The solution to the constrained problem is found by projecting the point $b$ onto the interval $[l^2, \\min(M, u^2)]$. Let $y_{min} = l^2$ and $y_{max} = \\min(M, u^2)$. The minimum value is achieved at the point in $[y_{min}, y_{max}]$ that is closest to $b$.\nThe lower bound $L_B$ is therefore given by the case-wise expression:\n$$ L_B = \\begin{cases} (l^2-b)^2 & \\text{if } b  l^2 \\\\ 0  \\text{if } l^2 \\le b \\le \\min(M, u^2) \\\\ (\\min(M, u^2)-b)^2  \\text{if } b > \\min(M, u^2) \\end{cases} $$\nThis is the required closed-form lower bound.\n\nWe now evaluate this bound for the given numerical values: $l=1$, $u=3$, $M=6$, and $b=8$.\nFirst, we determine the interval for $y$ in the relaxed problem:\n$$ y_{min} = l^2 = 1^2 = 1 $$\n$$ u^2 = 3^2 = 9 $$\n$$ y_{max} = \\min(M, u^2) = \\min(6, 9) = 6 $$\nThe interval is $Y = [1, 6]$. The target value is $b=8$.\nSince $b = 8 > 6 = y_{max}$, we are in the third case of the lower bound formula. The lower bound $L_B$ is:\n$$ L_B = (y_{max} - b)^2 = (6 - 8)^2 = (-2)^2 = 4 $$\nThe numerical lower bound on $\\min_{x\\in[1,3]} \\left(\\min\\{6,x^{2}\\}-8\\right)^{2}$ is $4$. Rounding to four significant figures gives $4.000$.", "answer": "$$\\boxed{4.000}$$", "id": "3118809"}, {"introduction": "While general-purpose relaxations are powerful, the most efficient optimization approaches often exploit the unique structure of a problem. Many objective functions in science and engineering are \"separable,\" meaning they can be expressed as a sum of functions of individual variables. This practice [@problem_id:3118759] shows how to leverage this separability to construct a valid lower bound by simply summing the convex envelopes of each component function, which is often much easier than relaxing the entire function at once. Furthermore, it introduces a sophisticated branching heuristic that uses the gap between the true function and its convex envelope to intelligently decide which variable to partition next.", "problem": "Consider a deterministic global minimization problem with a separable objective over a box with a single linear linking constraint. The objective is\n$$\nf(x) \\;=\\; \\sum_{i=1}^{3} f_i(x_i),\n$$\nwhere\n$$\nf_1(x_1) \\;=\\; \\sqrt{x_1}, \\quad f_2(x_2) \\;=\\; \\ln(x_2), \\quad f_3(x_3) \\;=\\; \\arctan(x_3),\n$$\nand the feasible set is\n$$\n\\mathcal{X} \\;=\\; \\left\\{ x \\in \\mathbb{R}^{3} \\;:\\; x_1 \\in [1,3],\\; x_2 \\in [2,5],\\; x_3 \\in [0,4],\\; x_1 + x_2 + x_3 \\;=\\; 7 \\right\\}.\n$$\nAll trigonometric functions are to be interpreted in radians.\n\nStarting from the definition of the convex envelope and the Branch and Bound (BnB) bounding principle, exploit separability to construct a valid root-node lower bound by summing the univariate convex envelopes of $f_i$ over the respective coordinate intervals and relaxing only through those envelopes. Then, use the linear linking constraint to compute the tightest separable lower bound over the box at the root node.\n\nNext, define the coordinate-wise envelope gap at the envelope-based optimizer $x^{\\star}$ as\n$$\ng_i \\;=\\; f_i\\!\\left(x_i^{\\star}\\right) \\;-\\; f_i^{\\mathrm{env}}\\!\\left(x_i^{\\star}\\right),\n$$\nwhere $f_i^{\\mathrm{env}}$ denotes the univariate convex envelope of $f_i$ on its interval. Identify the “worst” coordinate to branch on as the index $i$ that maximizes $g_i$.\n\nProvide:\n- The computed root-node lower bound as a single exact analytic expression.\n- The index (as an integer) of the worst coordinate according to the above rule.\n\nExpress your final answer using exact forms (e.g., $\\ln(5)$, $\\arctan(4)$). Do not round. Your final boxed answer must contain these two values as a single row matrix.", "solution": "The problem is to find a lower bound on a non-convex problem by constructing a convex relaxation. Since the objective function $f(x)$ is separable, we can relax it by summing the convex envelopes of its component functions, $f_i(x_i)$, over their respective intervals.\n\n**1. Constructing the Univariate Convex Envelopes**\n\nWe check the concavity of each function $f_i(x_i)$ on its interval. If a function is concave, its convex envelope is the secant line connecting its endpoints.\n- $f_1(x_1) = \\sqrt{x_1}$ on $[1,3]$: The second derivative is $f_1''(x_1) = -\\frac{1}{4}x_1^{-3/2}  0$, so the function is concave. Its convex envelope $f_1^{\\mathrm{env}}$ is the line connecting $(1, 1)$ and $(3, \\sqrt{3})$.\n- $f_2(x_2) = \\ln(x_2)$ on $[2,5]$: The second derivative is $f_2''(x_2) = -\\frac{1}{x_2^2}  0$, so the function is concave. Its convex envelope $f_2^{\\mathrm{env}}$ is the line connecting $(2, \\ln 2)$ and $(5, \\ln 5)$.\n- $f_3(x_3) = \\arctan(x_3)$ on $[0,4]$: The second derivative is $f_3''(x_3) = -\\frac{2x_3}{(1+x_3^2)^2} \\le 0$, so the function is concave. Its convex envelope $f_3^{\\mathrm{env}}$ is the line connecting $(0, 0)$ and $(4, \\arctan 4)$.\n\n**2. Solving the Relaxed Problem for the Lower Bound**\n\nThe relaxed problem is to minimize the sum of the linear convex envelopes subject to the original constraints:\n$$ \\min_{x} \\quad L(x) = f_1^{\\mathrm{env}}(x_1) + f_2^{\\mathrm{env}}(x_2) + f_3^{\\mathrm{env}}(x_3) $$\n$$ \\text{s.t.} \\quad x_1 \\in [1,3], \\quad x_2 \\in [2,5], \\quad x_3 \\in [0,4], \\quad x_1+x_2+x_3 = 7. $$\nThis is a Linear Program (LP). The objective function is $L(x) = \\sum_{i=1}^3 (m_i x_i + c_i)$, where $m_i$ are the slopes of the secant lines. To minimize this sum, we should assign the largest possible values of $x_i$ to the variables with the smallest slopes, and vice versa.\nThe slopes are:\n$$ m_1 = \\frac{\\sqrt{3} - 1}{2} \\approx 0.366 $$\n$$ m_2 = \\frac{\\ln(5) - \\ln(2)}{3} \\approx 0.305 $$\n$$ m_3 = \\frac{\\arctan(4)}{4} \\approx 0.332 $$\nThe slopes are ordered as $m_2  m_3  m_1$. Following a greedy strategy, we set the variable with the smallest slope ($x_2$) to its upper bound and the variable with the largest slope ($x_1$) to its lower bound:\n- $x_2^{\\star} = 5$ (upper bound of $[2,5]$).\n- $x_1^{\\star} = 1$ (lower bound of $[1,3]$).\nThe remaining variable, $x_3$, is determined by the linking constraint:\n- $x_3^{\\star} = 7 - x_1^{\\star} - x_2^{\\star} = 7 - 1 - 5 = 1$.\nThis solution $x^{\\star} = (1, 5, 1)$ is feasible as $1 \\in [0,4]$.\nThe root-node lower bound is the value of the relaxed objective $L(x)$ at $x^{\\star}$:\n$$ \\text{Lower Bound} = f_1^{\\mathrm{env}}(x_1^{\\star}) + f_2^{\\mathrm{env}}(x_2^{\\star}) + f_3^{\\mathrm{env}}(x_3^{\\star}) $$\n- Since $x_1^{\\star}=1$ is an endpoint, $f_1^{\\mathrm{env}}(1) = f_1(1) = \\sqrt{1} = 1$.\n- Since $x_2^{\\star}=5$ is an endpoint, $f_2^{\\mathrm{env}}(5) = f_2(5) = \\ln(5)$.\n- $f_3^{\\mathrm{env}}(1) = m_3 \\cdot x_3^{\\star} = \\frac{\\arctan(4)}{4} \\cdot 1 = \\frac{\\arctan(4)}{4}$.\nThe root-node lower bound is the sum:\n$$ \\text{Lower Bound} = 1 + \\ln(5) + \\frac{\\arctan(4)}{4}. $$\n\n**3. Identifying the Branching Variable**\n\nThe branching variable is chosen by finding the coordinate with the largest envelope gap, $g_i = f_i(x_i^{\\star}) - f_i^{\\mathrm{env}}(x_i^{\\star})$, at the relaxed solution $x^{\\star} = (1, 5, 1)$.\n- For $i=1$: $x_1^{\\star} = 1$. Since this is an endpoint of the interval, the function and its envelope coincide. Thus, $g_1 = f_1(1) - f_1^{\\mathrm{env}}(1) = 0$.\n- For $i=2$: $x_2^{\\star} = 5$. This is also an endpoint. Thus, $g_2 = f_2(5) - f_2^{\\mathrm{env}}(5) = 0$.\n- For $i=3$: $x_3^{\\star} = 1$. This point is in the interior of the interval $[0,4]$. The gap is non-zero.\n  $$ f_3(1) = \\arctan(1) = \\frac{\\pi}{4}. $$\n  $$ f_3^{\\mathrm{env}}(1) = \\frac{\\arctan(4)}{4}. $$\n  The gap is $g_3 = \\frac{\\pi}{4} - \\frac{\\arctan(4)}{4}$.\nSince $g_1=0$, $g_2=0$, and $g_3 > 0$, the maximum gap is $g_3$. Therefore, the coordinate to branch on is $i=3$.\nThe requested values are the root-node lower bound and the index of the worst coordinate, which are $1 + \\ln(5) + \\frac{\\arctan(4)}{4}$ and $3$, respectively.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1 + \\ln(5) + \\frac{\\arctan(4)}{4}  3\n\\end{pmatrix}\n}\n$$", "id": "3118759"}, {"introduction": "The efficiency of Branch and Bound is critically dependent not just on the quality of the bounds, but also on the \"branching\" strategy used to partition the search space. A poor choice of branching variable can lead to many unnecessary iterations, while a smart choice can rapidly prune large sections of the domain. This practice [@problem_id:3118754] explores this strategic aspect by focusing on the bilinear term $w = xy$, a common source of non-convexity. You will use the celebrated McCormick envelopes to build a relaxation and then quantitatively compare two different branching decisions, providing a clear illustration of how heuristics are used to guide the algorithm toward a solution more efficiently.", "problem": "Consider the nonconvex maximization problem with a single bilinear term:\nmaximize $w$ subject to $w = x y$, $x + y = 1$, $x \\in [0, 10]$, and $y \\in [0, 0.1]$. You will analyze a single step of deterministic global optimization using Branch and Bound (BnB) with a linear continuous relaxation built from the McCormick envelopes of the bilinear term.\n\nUse only the following foundational elements:\n- The definition of Branch and Bound (BnB) as a partitioning method that computes an upper bound for a maximization problem by solving relaxations over subregions, with the global upper bound after branching given by the maximum of the child-node relaxation optima.\n- The McCormick convex and concave envelopes for a bilinear term $w = x y$ over a rectangle $[x_L, x_U] \\times [y_L, y_U]$, namely the linear inequalities\n  $$\n  \\begin{aligned}\n  w \\ge x_L y + x y_L - x_L y_L, \\\\\n  w \\ge x_U y + x y_U - x_U y_U, \\\\\n  w \\le x_U y + x y_L - x_U y_L, \\\\\n  w \\le x_L y + x y_U - x_L y_U.\n  \\end{aligned}\n  $$\nThese are the only relaxations permitted for $w = x y$.\n\nAt the root node, the continuous relaxation uses $x \\in [0, 10]$, $y \\in [0, 0.1]$, together with $x + y = 1$. Next, compare two branching strategies:\n- Branch on $x$ at its midpoint, creating two child boxes $x \\in [0, 5]$ and $x \\in [5, 10]$ (with $y \\in [0, 0.1]$ unchanged).\n- Branch on $y$ at its midpoint, creating two child boxes $y \\in [0, 0.05]$ and $y \\in [0.05, 0.1]$ (with $x \\in [0, 10]$ unchanged).\n\nFor each strategy, compute the post-branching global upper bound given by the maximum of the two child-node continuous relaxation optimal values, using the McCormick envelopes updated with the tightened variable bounds and the linear constraint $x + y = 1$. Then, under the heuristic “choose the branching variable that minimizes this post-branching global upper bound,” determine which variable should be branched on. Finally, report the ratio\n$$\n\\frac{\\text{post-branching global upper bound after branching on } x}{\\text{post-branching global upper bound after branching on } y}.\n$$\nProvide your final answer as a single exact number (no rounding). No units are required.", "solution": "The problem is to find an upper bound for a maximization problem by solving a continuous relaxation. We relax the non-convex constraint $w = xy$ using the McCormick concave overestimators, which provide an upper bound on $w$:\n$$w \\le x_L y + x y_U - x_L y_U \\quad (W_A)$$\n$$w \\le x_U y + x y_L - x_U y_L \\quad (W_B)$$\nWe substitute the linear constraint $x=1-y$ into these inequalities to express the upper bound on $w$ as a function of $y$ alone:\n$W_A(y) = x_L y + (1-y) y_U - x_L y_U = (x_L - y_U)y + y_U(1 - x_L)$\n$W_B(y) = x_U y + (1-y) y_L - x_U y_L = (x_U - y_L)y + y_L(1 - x_U)$\n\nThe relaxed objective is to maximize $w_{rel}(y) = \\min(W_A(y), W_B(y))$, which is a concave function. The feasible region for $y$ is the effective interval $I_y = [\\max(y_L, 1-x_U), \\min(y_U, 1-x_L)]$. The maximum of the concave function $w_{rel}(y)$ over $I_y$ occurs at the intersection point $y_{int}$ where $W_A(y_{int}) = W_B(y_{int})$, provided $y_{int} \\in I_y$.\n\n**Strategy 1: Branch on $x$ at its midpoint, $x=5$.**\n\n*   **Child Node 1.1:** $x \\in [0, 5]$, $y \\in [0, 0.1]$.\n    Here, $x_L=0, x_U=5, y_L=0, y_U=0.1$. The feasible interval for $y$ is $I_y = [\\max(0, 1-5), \\min(0.1, 1-0)] = [0, 0.1]$.\n    The bounding functions are $W_A(y) = -0.1y + 0.1$ and $W_B(y) = 5y$. Their intersection is at $-0.1y_{int} + 0.1 = 5y_{int}$, which gives $y_{int} = \\frac{0.1}{5.1} = \\frac{1}{51}$. Since $y_{int} \\in [0, 0.1]$, the maximum is at this point. The upper bound is $w_{ub,1}^x = 5y_{int} = 5(\\frac{1}{51}) = \\frac{5}{51}$.\n\n*   **Child Node 1.2:** $x \\in [5, 10]$, $y \\in [0, 0.1]$.\n    The feasible interval for $y$ is $I_y = [\\max(0, 1-10), \\min(0.1, 1-5)] = [0, -4]$. The interval is empty, so this subproblem is infeasible. $w_{ub,2}^x = -\\infty$.\n\nThe post-branching global upper bound for branching on $x$ is $UB_x = \\max(\\frac{5}{51}, -\\infty) = \\frac{5}{51}$.\n\n**Strategy 2: Branch on $y$ at its midpoint, $y=0.05$.**\n\n*   **Child Node 2.1:** $x \\in [0, 10]$, $y \\in [0, 0.05]$.\n    Here, $x_L=0, x_U=10, y_L=0, y_U=0.05$. The feasible interval is $I_y = [0, 0.05]$. The bounding functions are $W_A(y) = -0.05y + 0.05$ and $W_B(y) = 10y$. Their intersection is at $y_{int} = \\frac{0.05}{10.05} = \\frac{1}{201}$. Since $y_{int} \\in [0, 0.05]$, the maximum is $w_{ub,1}^y = 10y_{int} = \\frac{10}{201}$.\n\n*   **Child Node 2.2:** $x \\in [0, 10]$, $y \\in [0.05, 0.1]$.\n    Here, $x_L=0, x_U=10, y_L=0.05, y_U=0.1$. The feasible interval is $I_y = [0.05, 0.1]$. The bounding functions are $W_A(y) = -0.1y + 0.1$ and $W_B(y) = 9.95y - 0.45$. Their intersection is at $y_{int} = \\frac{0.55}{10.05} = \\frac{11}{201}$. Since $y_{int} \\approx 0.0547 \\in [0.05, 0.1]$, the maximum is $w_{ub,2}^y = -0.1y_{int} + 0.1 = 0.1(1 - \\frac{11}{201}) = \\frac{1}{10}(\\frac{190}{201}) = \\frac{19}{201}$.\n\nThe post-branching global upper bound for branching on $y$ is $UB_y = \\max(\\frac{10}{201}, \\frac{19}{201}) = \\frac{19}{201}$.\n\n**Comparison and Final Calculation:**\nThe upper bound from branching on $x$ is $UB_x = \\frac{5}{51} \\approx 0.0980$. The upper bound from branching on $y$ is $UB_y = \\frac{19}{201} \\approx 0.0945$. Since $UB_y  UB_x$, the heuristic prefers to branch on $y$ as it provides a tighter global upper bound.\n\nThe required ratio is:\n$$ \\frac{UB_x}{UB_y} = \\frac{5/51}{19/201} = \\frac{5}{51} \\times \\frac{201}{19} = \\frac{5}{3 \\times 17} \\times \\frac{3 \\times 67}{19} = \\frac{5 \\times 67}{17 \\times 19} = \\frac{335}{323} $$", "answer": "$$\n\\boxed{\\frac{335}{323}}\n$$", "id": "3118754"}]}