{"hands_on_practices": [{"introduction": "To truly understand metaheuristics, one must build one. This exercise guides you through the implementation of the Cross-Entropy (CE) method, a powerful model-based search algorithm. By applying it to the classic 0-1 knapsack problem, you will gain first-hand experience with the complete cycle of sampling from a probabilistic model, repairing solutions, selecting an elite set, and updating the model's parameters to guide the search toward promising regions [@problem_id:3136467]. This practice illuminates the core principles of how algorithms can \"learn\" about a problem's structure.", "problem": "You will implement the Cross-Entropy method for a binary sampling distribution to solve a single-instance, $0$-$1$ knapsack problem and analyze sensitivity to the elite fraction. The Cross-Entropy method is a model-based stochastic search that iteratively updates a parameterized sampling distribution by minimizing the Kullback–Leibler divergence (also called cross-entropy) to a target distribution that concentrates on high-performing solutions. The sampling distribution family here is the product of independent Bernoulli distributions, one per item. The update is derived from first principles by maximizing the likelihood of an elite set of solutions under the model. You must implement the full method and return quantitative results for a specified test suite of elite fractions.\n\nKnapsack instance: Let $n$ denote the number of items, $\\mathbf{w} \\in \\mathbb{N}^{n}$ the weights, $\\mathbf{v} \\in \\mathbb{N}^{n}$ the values, and $C \\in \\mathbb{N}$ the capacity. Consider $n=15$, capacity $C=50$, with\n$\\mathbf{w} = [12,7,11,8,9,13,4,6,10,3,14,5,2,1,15]$ and\n$\\mathbf{v} = [36,14,22,21,19,32,9,17,25,8,28,12,5,3,34]$.\nA candidate solution is a vector $\\mathbf{x} \\in \\{0,1\\}^{n}$, with objective $f(\\mathbf{x}) = \\sum_{i=1}^{n} v_{i} x_{i}$ and feasibility constraint $\\sum_{i=1}^{n} w_{i} x_{i} \\le C$.\n\nSampling distribution: Use a vector of independent Bernoulli parameters $\\boldsymbol{\\theta} \\in (0,1)^{n}$, with the $i$-th bit sampled as $x_{i} \\sim \\text{Bernoulli}(\\theta_{i})$. Initialize $\\theta_{i} = 0.5$ for all $i$.\n\nFeasibility handling: To ensure feasibility, apply a deterministic repair operator to every sampled $\\mathbf{x}$ that violates the capacity. If $\\sum_{i} w_{i} x_{i}  C$, iteratively set $x_{j} \\leftarrow 0$ for items $j$ in increasing order of the ratio $r_{j} = v_{j} / w_{j}$ (that is, remove items with the smallest $v_{j}/w_{j}$ first) until $\\sum_{i} w_{i} x_{i} \\le C$. This operator must terminate in finitely many steps and produce a feasible solution.\n\nCross-Entropy iteration: At each iteration $t = 1,2,\\dots,T$, independently sample $N$ solutions from the current $\\boldsymbol{\\theta}$, repair them if needed, evaluate $f(\\cdot)$, and select the set of elites $\\mathcal{E}$ as the top $m$ solutions by objective value, where $m = \\max(1, \\lceil pN \\rceil)$ for a given elite fraction $p \\in (0,1]$. Update $\\boldsymbol{\\theta}$ by maximizing the likelihood of the elite set under the Bernoulli product model, using an exponential smoothing step with parameter $\\alpha \\in (0,1]$. After the update, project each $\\theta_{i}$ to the interval $[\\varepsilon, 1 - \\varepsilon]$ with $\\varepsilon \\in (0, 0.5)$ to avoid degeneracy. Maintain and return the best feasible objective value found across all samples and all iterations.\n\nFundamental base you must use and explicitly reason from in your design and derivation:\n- The definition of the $0$-$1$ knapsack problem: maximize $f(\\mathbf{x}) = \\sum_{i=1}^{n} v_{i} x_{i}$ subject to $\\sum_{i=1}^{n} w_{i} x_{i} \\le C$, with $\\mathbf{x} \\in \\{0,1\\}^{n}$.\n- The independent Bernoulli product family: for $\\mathbf{x} \\in \\{0,1\\}^{n}$, $p_{\\boldsymbol{\\theta}}(\\mathbf{x}) = \\prod_{i=1}^{n} \\theta_{i}^{x_{i}} (1-\\theta_{i})^{1 - x_{i}}$.\n- Maximum likelihood estimation for independent Bernoulli variables, applied to a finite elite dataset.\n- The definition of the Kullback–Leibler divergence and the equivalence between minimizing cross-entropy to a target distribution supported on elites and maximizing likelihood over the elite set.\n\nHyperparameters to use in your implementation:\n- Number of samples per iteration $N = 300$.\n- Number of iterations $T = 60$.\n- Smoothing parameter $\\alpha = 0.7$.\n- Probability floor $\\varepsilon = 0.05$.\n- Random number generator seed $s = 314159$ for all test cases.\n\nTest suite: You must evaluate the best objective value returned by the algorithm for each of the following elite fractions $p$:\n- Case $1$: $p = 0.05$.\n- Case $2$: $p = 0.20$.\n- Case $3$: $p = 0.50$.\n- Case $4$: $p = 0.90$.\n\nDesign for coverage: The test suite includes a small elite fraction $p = 0.05$ (aggressive updates), a moderate fraction $p = 0.20$, a balanced fraction $p = 0.50$, and a very large fraction $p = 0.90$ (conservative updates), to probe the bias–variance trade-off in the Cross-Entropy method.\n\nAnswer specification:\n- For each case, return the single integer equal to the best feasible objective value found by the algorithm after $T$ iterations.\n- Aggregate the results for the four cases into a single output line formatted exactly as a comma-separated list enclosed in square brackets, for example, $[r_{1},r_{2},r_{3},r_{4}]$, where each $r_{k}$ is an integer.\n- No physical units apply. Angles are not involved. Percentages must be input as decimals as provided.\n- Your program must produce exactly one line of output in the specified format and must not require any user input or external files.", "solution": "The problem requires the implementation of the Cross-Entropy (CE) method to find a high-quality solution for a specific instance of the $0$-$1$ knapsack problem. The sensitivity of the algorithm's performance to the elite fraction parameter, $p$, will be analyzed across a provided test suite.\n\nThe approach begins with a formal validation of the problem statement, which is found to be scientifically sound, well-posed, and complete. Following validation, a detailed, principle-based solution is derived and explained.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n*   **Problem**: $0$-$1$ knapsack problem.\n*   **Instance**:\n    *   Number of items: $n=15$.\n    *   Capacity: $C=50$.\n    *   Weights: $\\mathbf{w} = [12,7,11,8,9,13,4,6,10,3,14,5,2,1,15]$.\n    *   Values: $\\mathbf{v} = [36,14,22,21,19,32,9,17,25,8,28,12,5,3,34]$.\n*   **Solution Vector**: $\\mathbf{x} \\in \\{0,1\\}^{n}$.\n*   **Objective**: Maximize $f(\\mathbf{x}) = \\sum_{i=1}^{n} v_{i} x_{i}$.\n*   **Constraint**: $\\sum_{i=1}^{n} w_{i} x_{i} \\le C$.\n*   **Sampling Distribution**: Product of independent Bernoulli distributions with parameters $\\boldsymbol{\\theta} \\in (0,1)^{n}$.\n*   **Initialization**: $\\theta_{i} = 0.5$ for all $i$.\n*   **Feasibility Handling**: A deterministic repair operator that iteratively removes items from an overweight knapsack in increasing order of their value-to-weight ratio $r_j = v_j/w_j$.\n*   **CE Iteration**: Based on sampling, repair, evaluation, elite selection, and parameter update.\n*   **Fundamental Principles**: $0$-$1$ knapsack definition, Bernoulli product model, Maximum Likelihood Estimation (MLE) for Bernoulli variables, equivalence of KL-divergence minimization and MLE.\n*   **Hyperparameters**:\n    *   Samples per iteration: $N = 300$.\n    *   Iterations: $T = 60$.\n    *   Smoothing parameter: $\\alpha = 0.7$.\n    *   Probability floor: $\\varepsilon = 0.05$.\n    *   Random seed: $s = 314159$.\n*   **Test Suite**: Elite fractions $p \\in \\{0.05, 0.20, 0.50, 0.90\\}$.\n*   **Output**: Best feasible objective value found for each $p$, formatted as a list.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem is evaluated against the validation criteria:\n*   **Scientifically Grounded**: The problem is well-grounded in the established fields of optimization (Cross-Entropy method) and computer science (knapsack problem). The mathematical principles cited are correct.\n*   **Well-Posed**: All necessary data, parameters, and algorithmic steps are explicitly defined. The use of a fixed random seed ensures a unique and reproducible result for each test case.\n*   **Objective**: The problem is stated using precise, quantitative, and unbiased language.\n*   The problem exhibits no flaws such as scientific unsoundness, incompleteness, contradiction, or ambiguity. It is a standard, non-trivial computational problem that is perfectly verifiable.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. A complete solution will be provided.\n\n### Solution Derivation and Algorithmic Design\n\nThe Cross-Entropy method is a stochastic optimization algorithm that works by iteratively updating the parameters of a probability distribution over the solution space. The goal is to evolve the distribution so that it generates samples in regions of high objective value.\n\n**1. The Knapsack Problem and Probabilistic Model**\n\nThe problem is to select a subset of $n=15$ items to maximize total value without exceeding a weight capacity of $C=50$. A solution is a binary vector $\\mathbf{x} \\in \\{0,1\\}^{n}$, where $x_i=1$ if item $i$ is included and $x_i=0$ otherwise.\nThe objective function is $f(\\mathbf{x}) = \\mathbf{v}^T \\mathbf{x} = \\sum_{i=1}^{n} v_{i} x_{i}$, subject to the constraint $\\mathbf{w}^T \\mathbf{x} = \\sum_{i=1}^{n} w_{i} x_{i} \\le C$.\n\nWe define a parameterized probability distribution over the space of solutions $\\{0,1\\}^n$. As specified, this is a product of independent Bernoulli distributions:\n$$p_{\\boldsymbol{\\theta}}(\\mathbf{x}) = \\prod_{i=1}^{n} p(x_i | \\theta_i) = \\prod_{i=1}^{n} \\theta_{i}^{x_{i}} (1-\\theta_{i})^{1 - x_{i}}$$\nHere, $\\boldsymbol{\\theta} = (\\theta_1, \\dots, \\theta_n)$ is the vector of parameters, where $\\theta_i$ is the probability that item $i$ is included in a solution ($x_i=1$). Initially, all items have an equal chance of being selected: $\\theta_i^{(0)} = 0.5$ for all $i=1, \\dots, n$.\n\n**2. Parameter Update via Maximum Likelihood Estimation**\n\nThe core of the CE method is the update rule for $\\boldsymbol{\\theta}$. At each iteration $t$, we generate a population of $N$ candidate solutions from the current distribution $p_{\\boldsymbol{\\theta}^{(t-1)}}(\\mathbf{x})$. After repairing and evaluating these solutions, we select an \"elite set\" $\\mathcal{E}$ containing the $m$ best-performing solutions. The distribution for the next iteration, $\\boldsymbol{\\theta}^{(t)}$, is chosen to be \"closer\" to an ideal distribution that would only generate solutions from this elite set.\n\nMinimizing the Kullback-Leibler divergence (or cross-entropy) between $p_{\\boldsymbol{\\theta}}(\\mathbf{x})$ and this ideal target distribution is equivalent to maximizing the likelihood of the elite samples under our model $p_{\\boldsymbol{\\theta}}(\\mathbf{x})$.\n\nLet the elite set be $\\mathcal{E} = \\{\\mathbf{x}^{(1)}, \\mathbf{x}^{(2)}, \\dots, \\mathbf{x}^{(m)}\\}$. The likelihood function is:\n$$L(\\boldsymbol{\\theta}; \\mathcal{E}) = \\prod_{j=1}^{m} p_{\\boldsymbol{\\theta}}(\\mathbf{x}^{(j)}) = \\prod_{j=1}^{m} \\prod_{i=1}^{n} \\theta_{i}^{x_{i}^{(j)}} (1-\\theta_{i})^{1 - x_{i}^{(j)}}$$\nFor easier maximization, we use the log-likelihood:\n$$\\log L(\\boldsymbol{\\theta}; \\mathcal{E}) = \\sum_{j=1}^{m} \\sum_{i=1}^{n} \\left[ x_{i}^{(j)} \\log(\\theta_i) + (1-x_{i}^{(j)}) \\log(1-\\theta_i) \\right]$$\nTo find the parameters $\\boldsymbol{\\theta}$ that maximize this function, we take the partial derivative with respect to each $\\theta_k$ and set it to zero:\n$$\\frac{\\partial \\log L}{\\partial \\theta_k} = \\sum_{j=1}^{m} \\left[ \\frac{x_{k}^{(j)}}{\\theta_k} - \\frac{1-x_{k}^{(j)}}{1-\\theta_k} \\right] = 0$$\n$$\\frac{1}{\\theta_k} \\sum_{j=1}^{m} x_{k}^{(j)} = \\frac{1}{1-\\theta_k} \\sum_{j=1}^{m} (1-x_{k}^{(j)})$$\nSolving for $\\theta_k$ yields the maximum likelihood estimate, which we denote as $\\hat{\\theta}_k$:\n$$\\hat{\\theta}_k = \\frac{\\sum_{j=1}^{m} x_{k}^{(j)}}{m}$$\nThis elegant result shows that the optimal parameter $\\hat{\\theta}_k$ for the $k$-th item is simply the frequency of that item's inclusion across all solutions in the elite set.\n\n**3. Smoothed Update and Parameter Projection**\n\nTo prevent premature convergence and provide stability, the parameter update is smoothed using an exponential moving average with smoothing parameter $\\alpha$:\n$$\\boldsymbol{\\theta}^{(t)} = \\alpha \\hat{\\boldsymbol{\\theta}} + (1-\\alpha) \\boldsymbol{\\theta}^{(t-1)}$$\nA larger $\\alpha$ (like the specified $\\alpha=0.7$) gives more weight to the most recent elite set, leading to faster convergence, while a smaller $\\alpha$ leads to more conservative updates.\n\nFurthermore, to ensure that the search does not stagnate by having probabilities collapse to exactly $0$ or $1$, the updated parameters are projected into the interval $[\\varepsilon, 1-\\varepsilon]$. For each component $i$:\n$$\\theta_i^{(t)} \\leftarrow \\max(\\varepsilon, \\min(1-\\varepsilon, \\theta_i^{(t)}))$$\nWith $\\varepsilon=0.05$, every item always has at least a $5\\%$ chance of being sampled (or not sampled), maintaining some level of exploration.\n\n**4. Feasibility Repair Operator**\n\nSince sampling from the Bernoulli distribution does not respect the knapsack capacity constraint, a repair step is necessary. For any generated solution $\\mathbf{x}$ where $\\mathbf{w}^T\\mathbf{x}  C$, we must remove items until the constraint is met. The specified strategy is to remove items with the lowest value-to-weight ratio, $r_j = v_j/w_j$, first. This is a greedy choice that aims to preserve as much value as possible while reducing weight. This operator is applied to every generated sample before evaluation.\n\n**5. Complete Algorithm**\n\nThe full algorithm for a given elite fraction $p$ is as follows:\n\n1.  **Initialization**:\n    *   Set iteration counter $t \\leftarrow 0$.\n    *   Initialize Bernoulli parameters $\\boldsymbol{\\theta}^{(0)} \\leftarrow (0.5, 0.5, \\dots, 0.5)$.\n    *   Initialize best-found objective value $f_{best} \\leftarrow -\\infty$.\n    *   Pre-compute item indices sorted by $v_j/w_j$.\n    *   Set elite sample count $m = \\max(1, \\lceil pN \\rceil)$.\n\n2.  **Iteration Loop**: For $t = 1, \\dots, T$:\n    *   **Sampling**: Generate $N$ samples $\\{\\mathbf{x}^{(1)}, \\dots, \\mathbf{x}^{(N)}\\}$ by drawing $x_i^{(j)} \\sim \\text{Bernoulli}(\\theta_i^{(t-1)})$.\n    *   **Repair**: For each sample $\\mathbf{x}^{(j)}$: if $\\mathbf{w}^T\\mathbf{x}^{(j)}  C$, apply the repair operator until $\\mathbf{w}^T\\mathbf{x}^{(j)} \\le C$. Let the repaired samples be $\\{\\mathbf{x'}^{(1)}, \\dots, \\mathbf{x'}^{(N)}\\}$.\n    *   **Evaluation**: Compute the objective values $f(\\mathbf{x'}^{(j)})$ for all $j=1, \\dots, N$.\n    *   **Update Best**: $f_{best} \\leftarrow \\max(f_{best}, \\max_{j} f(\\mathbf{x'}^{(j)}))$.\n    *   **Elite Selection**: Identify the set $\\mathcal{E}$ of the $m$ repaired samples with the highest objective values.\n    *   **Parameter Update**:\n        a. Calculate MLE: $\\hat{\\theta}_i = \\frac{1}{m} \\sum_{\\mathbf{x'} \\in \\mathcal{E}} x'_i$ for all $i=1, \\dots, n$.\n        b. Smooth: $\\boldsymbol{\\theta}^{(t)} = \\alpha \\hat{\\boldsymbol{\\theta}} + (1-\\alpha) \\boldsymbol{\\theta}^{(t-1)}$.\n        c. Project: $\\theta_i^{(t)} \\leftarrow \\max(\\varepsilon, \\min(1-\\varepsilon, \\theta_i^{(t)}))$.\n\n3.  **Termination**: After $T$ iterations, return $f_{best}$.\n\nThis procedure is repeated for each value of $p$ in the test suite $\\{0.05, 0.20, 0.50, 0.90\\}$, with the random number generator re-initialized for each run to ensure fair, independent trials.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Implements the Cross-Entropy method for the 0-1 knapsack problem\n    and evaluates it for a suite of elite fraction parameters.\n    \"\"\"\n    \n    # Knapsack problem instance\n    n = 15\n    capacity = 50\n    weights = np.array([12, 7, 11, 8, 9, 13, 4, 6, 10, 3, 14, 5, 2, 1, 15])\n    values = np.array([36, 14, 22, 21, 19, 32, 9, 17, 25, 8, 28, 12, 5, 3, 34])\n\n    # Hyperparameters\n    N_SAMPLES = 300\n    N_ITERATIONS = 60\n    ALPHA = 0.7  # Smoothing parameter\n    EPSILON = 0.05  # Probability floor\n    SEED = 314159\n\n    # Test suite for elite fraction p\n    test_cases = [0.05, 0.20, 0.50, 0.90]\n    \n    # Pre-calculate value-to-weight ratios and sorted indices for repair\n    # Handle division by zero if a weight is 0, though not present in this data\n    with np.errstate(divide='ignore', invalid='ignore'):\n        ratios = values / weights\n    ratios[np.isinf(ratios)] = np.finfo(np.float64).max # If w=0, v>0, ratio is infinite\n    ratios[np.isnan(ratios)] = -1.0 # If w=0, v=0\n    \n    # Indices of items sorted by increasing v/w ratio\n    # Items with lower ratios will be removed first\n    sorted_indices_for_repair = np.argsort(ratios)\n    \n    final_results = []\n\n    for p_elite in test_cases:\n        # Initialize RNG for reproducibility for each test case\n        rng = np.random.default_rng(SEED)\n        \n        # Initialize Bernoulli parameters\n        theta = np.full(n, 0.5)\n        \n        # Track the best objective value found so far\n        best_overall_value = 0\n        \n        # Calculate number of elite samples\n        # m = max(1, ceil(p*N))\n        m_elite = max(1, int(math.ceil(p_elite * N_SAMPLES)))\n\n        for _ in range(N_ITERATIONS):\n            # 1. Sampling: Generate N samples from the Bernoulli distribution\n            # samples[i, j] is 1 if item j is in sample i, 0 otherwise\n            random_values = rng.random((N_SAMPLES, n))\n            samples = (random_values  theta).astype(int)\n            \n            repaired_samples = np.copy(samples)\n            \n            # 2. Feasibility Repair\n            for i in range(N_SAMPLES):\n                current_weight = np.dot(repaired_samples[i], weights)\n                if current_weight > capacity:\n                    # The sample is overweight, repair it\n                    # Iterate through items sorted by low v/w ratio\n                    for item_idx in sorted_indices_for_repair:\n                        if repaired_samples[i, item_idx] == 1:\n                            # Remove this item from the knapsack\n                            repaired_samples[i, item_idx] = 0\n                            current_weight -= weights[item_idx]\n                            if current_weight = capacity:\n                                # Repair complete for this sample\n                                break\n            \n            # 3. Evaluation\n            objective_values = np.dot(repaired_samples, values)\n\n            # 4. Update Best-So-Far\n            current_best_value = np.max(objective_values)\n            if current_best_value > best_overall_value:\n                best_overall_value = current_best_value\n            \n            # 5. Elite Selection\n            # Get indices of the top m_elite samples\n            elite_indices = np.argsort(objective_values)[-m_elite:]\n            elite_samples = repaired_samples[elite_indices]\n\n            # 6. Parameter Update\n            # a. MLE estimate\n            theta_hat = np.mean(elite_samples, axis=0)\n            \n            # b. Smoothing\n            theta = ALPHA * theta_hat + (1 - ALPHA) * theta\n            \n            # c. Projection\n            theta = np.clip(theta, EPSILON, 1 - EPSILON)\n\n        final_results.append(int(best_overall_value))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n\n```", "id": "3136467"}, {"introduction": "Many real-world optimization problems are defined by a vast number of constraints, making it computationally prohibitive to enforce them all simultaneously. This challenge calls for a \"lazy\" approach, where constraints are only considered when they are violated. This hands-on exercise introduces the powerful technique of lazy constraint addition, a strategy where the search algorithm dynamically builds its set of active constraints as it discovers them [@problem_id:3136523]. By implementing a heuristic that combines random sampling with a repair operator and a just-in-time learning mechanism, you will explore how to efficiently navigate enormous and complex feasible regions.", "problem": "Consider a binary decision vector $x \\in \\{0,1\\}^n$ and a family of constraints indexed by $i \\in \\{1,\\dots,m\\}$ of the form $g_i(x) \\le 0$, where $g_i(x)$ is defined by\n$$\ng_i(x) = \\sum_{j \\in S_i} x_j - b_i,\n$$\nwith $S_i \\subseteq \\{0,1,\\dots,n-1\\}$ and $b_i \\in \\mathbb{N}$. A vector $x$ is feasible if and only if $\\forall i \\in \\{1,\\dots,m\\}$, $g_i(x) \\le 0$. This problem asks you to implement a heuristic with lazy constraint addition (also called lazy cuts) and to measure how the discovery of constraints affects the rate of feasibility.\n\nStarting from the foundational definitions of feasibility (the property that all constraints are satisfied) and constraints defined by $g_i(x) \\le 0$, design a randomized heuristic search that, at iteration $t \\in \\{1,\\dots,T\\}$, samples a candidate $x^{(t)}$ using independent Bernoulli trials with sampling probability $p \\in (0,1)$ for each component. Specifically, before evaluating unknown constraints, project the sampled candidate onto the set of currently known (enforced) constraints by greedily flipping $1$-bits to $0$ within any violated known constraint until the constraint is satisfied. Formally, for every known constraint index $i$ and current $x$, repeatedly replace a position $j \\in S_i$ with $x_j = 1$ by $x_j \\leftarrow 0$ until $\\sum_{j \\in S_i} x_j \\le b_i$.\n\nUse lazy constraint addition as follows: initially, enforce no constraints. At each iteration, after projecting onto the known constraints, evaluate all constraints $g_i(x^{(t)})$ using an oracle that reveals violations. If any constraints are violated, i.e., if there exists $i$ such that $g_i(x^{(t)})  0$, add all such violated constraints to the enforced set for future iterations. Let the cumulative feasibility rate at horizon $T$ be\n$$\nR_T = \\frac{1}{T}\\sum_{t=1}^T \\mathbf{1}\\left\\{ \\forall i \\in \\{1,\\dots,m\\},\\ g_i\\left(x^{(t)}\\right) \\le 0 \\right\\},\n$$\nwhere $\\mathbf{1}\\{\\cdot\\}$ is the indicator function.\n\nImplement the above heuristic precisely and compute $R_T$ for each of the following test cases. Use a fixed Random Number Generator (RNG) seed per test case for reproducibility. In all cases, use sampling probability $p=0.5$. The constraints are given explicitly by their index sets $S_i$ and thresholds $b_i$. In all sets below, indices are zero-based.\n\nTest Suite:\n- Case $1$: $n=12$, $m=4$, $T=1000$, seed $7$.\n  $S_1=\\{0,1,2,3\\}$ with $b_1=2$;\n  $S_2=\\{4,5,6\\}$ with $b_2=1$;\n  $S_3=\\{2,5,8,9\\}$ with $b_3=2$;\n  $S_4=\\{7,8,9,10,11\\}$ with $b_4=2$.\n- Case $2$: $n=10$, $m=0$, $T=300$, seed $123$.\n  No constraints (the feasible set is all of $\\{0,1\\}^{10}$).\n- Case $3$: $n=15$, $m=5$, $T=1200$, seed $0$.\n  $S_1=\\{0,1,2\\}$ with $b_1=0$;\n  $S_2=\\{3,4,5\\}$ with $b_2=0$;\n  $S_3=\\{6,7,8\\}$ with $b_3=1$;\n  $S_4=\\{9,10,11,12\\}$ with $b_4=1$;\n  $S_5=\\{12,13,14\\}$ with $b_5=0$.\n- Case $4$: $n=20$, $m=3$, $T=1000$, seed $100$.\n  $S_1=\\{0,1,2,3,4,5,6,7,8,9\\}$ with $b_1=4$;\n  $S_2=\\{5,6,7,8,9,10,11,12,13,14\\}$ with $b_2=5$;\n  $S_3=\\{10,11,12,13,14,15,16,17,18,19\\}$ with $b_3=4$.\n- Case $5$: $n=8$, $m=3$, $T=800$, seed $2023$.\n  $S_1=\\{0,1,2,3,4\\}$ with $b_1=2$;\n  $S_2=\\{3,4,5,6\\}$ with $b_2=2$;\n  $S_3=\\{1,6,7\\}$ with $b_3=1$.\n\nYour program must:\n- Implement the lazy constraint addition heuristic described above, using the defined projection onto known constraints at each iteration.\n- Use the specified seeds for the Random Number Generator (RNG) to ensure deterministic behavior.\n- Compute the final feasibility rate $R_T$ for each test case.\n\nFinal Output Format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each entry is the final feasibility rate $R_T$ for the corresponding test case, rounded to three decimal places as a decimal in $[0,1]$. For example, print $[r_1,r_2,\\dots,r_5]$ where each $r_k$ is a float rounded to three decimal places.\n- No other text should be printed.", "solution": "The user has requested the implementation and evaluation of a specific randomized heuristic for solving a binary feasibility problem. The problem is defined by a set of linear inequality constraints over a binary decision vector. The heuristic employs a lazy constraint addition strategy.\n\n### Problem Definition and Key Concepts\n\nThe problem revolves around finding a binary vector $x \\in \\{0,1\\}^n$ that satisfies a set of $m$ linear constraints. Each constraint $i \\in \\{1, \\dots, m\\}$ is of the form:\n$$ g_i(x) \\le 0 $$\nwhere the function $g_i(x)$ is defined as:\n$$ g_i(x) = \\sum_{j \\in S_i} x_j - b_i $$\nHere, $S_i$ is a subset of the variable indices $\\{0, 1, \\dots, n-1\\}$, and $b_i$ is a non-negative integer threshold. A vector $x$ is deemed **feasible** if it satisfies all $m$ constraints.\n\nThe performance of the heuristic is measured by the **cumulative feasibility rate** $R_T$ over a horizon of $T$ iterations:\n$$ R_T = \\frac{1}{T}\\sum_{t=1}^T \\mathbf{1}\\left\\{ \\forall i \\in \\{1,\\dots,m\\},\\ g_i\\left(x^{(t)}\\right) \\le 0 \\right\\} $$\nwhere $x^{(t)}$ is the candidate solution at iteration $t$ and $\\mathbf{1}\\{\\cdot\\}$ is the indicator function, which is $1$ if its argument is true and $0$ otherwise.\n\n### Algorithmic Procedure\n\nThe specified heuristic is an iterative, randomized algorithm. At each iteration $t$, it performs the following sequence of operations:\n\n1.  **Initialization**: The algorithm begins with an empty set of enforced (or \"known\") constraints. The random number generator (RNG) is initialized with a specific seed for each test case to ensure reproducibility.\n\n2.  **Sampling**: A candidate solution $x_{cand}^{(t)}$ is generated by sampling each of its $n$ components independently from a Bernoulli distribution with parameter $p=0.5$. This is equivalent to choosing a vector from the entire space $\\{0,1\\}^n$ uniformly at random. This step represents the exploration phase of the search.\n\n3.  **Projection (Repair Operator)**: The randomly sampled vector $x_{cand}^{(t)}$ is unlikely to satisfy any pre-existing constraints. Therefore, a repair mechanism, termed \"projection,\" is applied. This step modifies the candidate vector to ensure it satisfies all constraints currently in the \"known\" set.\n    For each known constraint $i$ that is violated by the current vector, the algorithm calculates the excess sum, $\\Delta = \\left( \\sum_{j \\in S_i} x_j \\right) - b_i$. It then randomly selects $\\Delta$ components $x_j$ (where $j \\in S_i$ and $x_j=1$) and flips their values from $1$ to $0$. This greedily and minimally repairs the vector to satisfy constraint $i$.\n    A critical property of these constraints is that flipping a variable from $1$ to $0$ can only decrease the sum $\\sum_{j \\in S_k} x_j$ for any constraint $k$. Consequently, repairing a vector for one constraint can never cause a previously satisfied constraint to become violated. This makes the order of projections irrelevant, and a single pass over all known constraints guarantees that the resulting vector, which we denote $x^{(t)}$, satisfies all of them.\n\n4.  **Evaluation and Learning (Lazy Constraint Addition)**: The projected vector $x^{(t)}$ is then evaluated against *all* $m$ original constraints. An \"oracle\" reveals the full set of violated constraints.\n    - If $x^{(t)}$ satisfies all $m$ constraints, it is counted as a feasible solution for the current iteration.\n    - If one or more constraints are violated, the solution is infeasible for this iteration. Crucially, all newly discovered violated constraints are added to the set of known constraints. This is the \"lazy\" or \"just-in-time\" learning mechanism. By adding only violated constraints, the algorithm focuses its repair efforts on an incrementally constructed, relevant subset of the full constraint system.\n\n5.  **Termination and Calculation**: After $T$ iterations, the total count of feasible solutions is divided by $T$ to compute the final feasibility rate $R_T$.\n\nThis combination of random sampling, repairing, and learning from failure is a hallmark of many effective heuristics for hard combinatorial problems. The lazy addition of constraints is particularly useful when $m$ is very large, as it avoids the computational burden of handling all constraints from the start.\n\n### Implementation for Test Cases\n\nThe algorithm will be implemented in Python using the `numpy` library for efficient array operations and for its robust random number generation capabilities. Each test case is defined by its parameters ($n, m, T, \\text{seed}$) and the specific constraint definitions ($S_i, b_i$). The implementation will precisely follow the steps outlined above, ensuring that the specified RNG seed is used for each case to guarantee deterministic and verifiable results. The final output will be a list of the computed feasibility rates $R_T$, rounded to three decimal places.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_heuristic(n, m, T, seed, constraints, p):\n    \"\"\"\n    Implements the randomized heuristic with lazy constraint addition.\n\n    Args:\n        n (int): The dimension of the decision vector.\n        m (int): The total number of constraints.\n        T (int): The number of iterations (horizon).\n        seed (int): The seed for the random number generator.\n        constraints (list): A list of tuples, where each tuple is (S_i, b_i)\n                          representing a constraint. S_i is a list of indices.\n        p (float): The Bernoulli sampling probability.\n\n    Returns:\n        float: The cumulative feasibility rate R_T.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    # Use a set for efficient addition and checking of known constraint indices.\n    # The indices correspond to the 0-based index in the `constraints` list.\n    known_constraints_indices = set()\n    feasible_count = 0\n\n    if m == 0:\n        # If there are no constraints, any sampled vector is feasible.\n        return 1.0\n\n    for _ in range(T):\n        # 1. Sample a candidate x using independent Bernoulli trials\n        x_candidate = rng.choice([0, 1], size=n, p=[1 - p, p]).astype(np.int8)\n        \n        # 2. Project onto the set of currently known constraints\n        x_projected = np.copy(x_candidate)\n        \n        # Iterating over a sorted list for deterministic behavior, though order doesn't matter here.\n        sorted_known_indices = sorted(list(known_constraints_indices))\n\n        for i in sorted_known_indices:\n            S_i, b_i = constraints[i]\n            \n            current_sum = np.sum(x_projected[S_i])\n            \n            if current_sum > b_i:\n                num_flips_needed = int(current_sum - b_i)\n                \n                # Identify indices j in S_i where x_projected[j] is 1\n                flip_candidates = [j for j in S_i if x_projected[j] == 1]\n                \n                # Randomly choose which 1s to flip to 0s\n                indices_to_flip = rng.choice(flip_candidates, size=num_flips_needed, replace=False)\n                x_projected[indices_to_flip] = 0\n\n        # After projection, x_projected satisfies all known constraints.\n        \n        # 3. Evaluate all constraints on the projected candidate to find new violations\n        is_fully_feasible = True\n        newly_violated_constraint_indices = set()\n        \n        for i in range(m):\n            S_i, b_i = constraints[i]\n            \n            current_sum = np.sum(x_projected[S_i])\n            \n            if current_sum > b_i:\n                is_fully_feasible = False\n                newly_violated_constraint_indices.add(i)\n        \n        # If no constraints were violated, the solution is feasible for the original problem\n        if is_fully_feasible:\n            feasible_count += 1\n            \n        # 4. Add all newly violated constraints to the enforced set for subsequent iterations\n        known_constraints_indices.update(newly_violated_constraint_indices)\n        \n    # Calculate cumulative feasibility rate\n    if T == 0:\n        return 0.0\n    \n    return feasible_count / T\n\ndef solve():\n    # Define the test cases from the problem statement.\n    p = 0.5\n    test_cases = [\n        {\n            'n': 12, 'm': 4, 'T': 1000, 'seed': 7,\n            'constraints': [\n                (list({0,1,2,3}), 2),\n                (list({4,5,6}), 1),\n                (list({2,5,8,9}), 2),\n                (list({7,8,9,10,11}), 2)\n            ]\n        },\n        {\n            'n': 10, 'm': 0, 'T': 300, 'seed': 123,\n            'constraints': []\n        },\n        {\n            'n': 15, 'm': 5, 'T': 1200, 'seed': 0,\n            'constraints': [\n                (list({0,1,2}), 0),\n                (list({3,4,5}), 0),\n                (list({6,7,8}), 1),\n                (list({9,10,11,12}), 1),\n                (list({12,13,14}), 0)\n            ]\n        },\n        {\n            'n': 20, 'm': 3, 'T': 1000, 'seed': 100,\n            'constraints': [\n                (list(range(10)), 4),\n                (list(range(5, 15)), 5),\n                (list(range(10, 20)), 4)\n            ]\n        },\n        {\n            'n': 8, 'm': 3, 'T': 800, 'seed': 2023,\n            'constraints': [\n                (list({0,1,2,3,4}), 2),\n                (list({3,4,5,6}), 2),\n                (list({1,6,7}), 1)\n            ]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        rate = run_heuristic(case['n'], case['m'], case['T'], case['seed'], case['constraints'], p)\n        results.append(rate)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{r:.3f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3136523"}, {"introduction": "A critical question in applying any stochastic optimizer is \"When should I stop the search?\" Terminating too early may yield a suboptimal solution, while running it for too long wastes computational resources. This practice delves into the design and analysis of adaptive stopping criteria, which are essential for the practical deployment of heuristic methods [@problem_id:3136544]. Through a Monte Carlo simulation, you will model the diminishing returns of an optimization process and quantify the trade-off between the risk of premature stopping and the risk of delayed stopping, developing a deeper understanding of algorithm dynamics and control.", "problem": "You are asked to design, justify, and evaluate an adaptive stopping rule for a stochastic heuristic optimization process using only fundamental definitions from probability and statistics and standard algorithmic constructs. The goal is to quantify the trade-off between stopping prematurely and stopping too late.\n\nAssume an iterative heuristic optimizer produces a nonnegative scalar improvement sequence $\\{\\Delta_t\\}_{t=1}^{\\infty}$, where $\\Delta_t$ is the improvement in the objective value achieved at iteration $t$. Model the expected improvement by the exponentially decaying curve\n$$\n\\mathbb{E}[\\Delta_t] = A e^{-\\beta t},\n$$\nwith $A \\gt 0$ and $\\beta \\gt 0$. The observed improvement is\n$$\n\\Delta_t = \\max\\{0,\\, A e^{-\\beta t} + \\eta_t\\},\n$$\nwhere $\\{\\eta_t\\}$ are independent and identically distributed Gaussian noise terms with $\\eta_t \\sim \\mathcal{N}(0,\\sigma^2)$, and negative values are truncated at $0$ to enforce nonnegativity.\n\nDefine the following two stopping times.\n\n- Oracle stopping time. For a reference tolerance $\\epsilon_{\\text{true}} \\gt 0$, the oracle stop index is the smallest integer $t_{\\star}$ such that $\\mathbb{E}[\\Delta_t] \\le \\epsilon_{\\text{true}}$, that is,\n$$\nt_{\\star} = \\min\\{t \\in \\mathbb{N} : A e^{-\\beta t} \\le \\epsilon_{\\text{true}}\\}.\n$$\n\n- Adaptive moving-average rule. For a window length $w \\in \\mathbb{N}$ and an estimated tolerance $\\epsilon_{\\text{est}} \\gt 0$, define the moving average\n$$\n\\overline{\\Delta}_t = \\frac{1}{w} \\sum_{i=t-w+1}^{t} \\Delta_i \\quad \\text{for} \\quad t \\ge w.\n$$\nThe adaptive stop index is\n$$\n\\tau = \\min\\left\\{t \\in \\mathbb{N}: t \\ge w \\ \\text{and} \\ \\overline{\\Delta}_t \\le \\epsilon_{\\text{est}}\\right\\},\n$$\nwith the convention that if the set is empty up to a maximum allowed iteration $T_{\\max}$, then $\\tau$ is set to $T_{\\max}$.\n\nFor each parameter set below, perform a Monte Carlo experiment with $M$ independent runs. In each run, simulate the improvement sequence up to $T_{\\max}$ and record the adaptive stop index $\\tau$ and the oracle index $t_{\\star}$. Quantify:\n\n- Premature stopping risk as the fraction of runs where $\\tau \\lt t_{\\star}$.\n- Delayed stopping risk as the fraction of runs where $\\tau \\gt t_{\\star}$.\n\nBoth risks must be reported as decimal fractions in $[0,1]$ rounded to three decimals.\n\nUse the following test suite. Each tuple lists $(A,\\ \\beta,\\ \\sigma,\\ w,\\ \\epsilon_{\\text{est}},\\ \\epsilon_{\\text{true}},\\ T_{\\max},\\ M,\\ \\text{seed})$:\n\n- Test $1$: $(0.5, 0.05, 0.02, 10, 0.01, 0.01, 400, 4000, 123)$.\n- Test $2$: $(0.5, 0.05, 0.02, 5, 0.02, 0.01, 400, 4000, 456)$.\n- Test $3$: $(0.5, 0.05, 0.02, 20, 0.005, 0.01, 400, 4000, 789)$.\n- Test $4$: $(0.5, 0.05, 0.08, 3, 0.01, 0.01, 400, 4000, 42)$.\n- Test $5$: $(0.02, 0.1, 0.005, 5, 0.01, 0.01, 200, 4000, 321)$.\n\nRequirements and clarifications:\n\n- Angles do not appear in this problem; there is no angle unit to specify.\n- No physical units appear; all quantities are unitless scalars.\n- For each test, compute $t_{\\star}$ from the model definition of the oracle and ensure $t_{\\star} \\le T_{\\max}$ by the chosen parameters.\n- Your program must output a single line containing a list of floating-point numbers: for each test in the order given, output the premature risk followed by the delayed risk, both rounded to three decimals. Aggregate all tests into a single list. For example, the output format must be exactly like $[r_{1,\\text{prem}},r_{1,\\text{delay}},r_{2,\\text{prem}},\\dots,r_{5,\\text{delay}}]$ with no spaces.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3]$).", "solution": "The problem requires the design and evaluation of an adaptive stopping rule for a stochastic optimization process. This will be accomplished by comparing the performance of a practical, data-driven rule against a theoretical \"oracle\" rule through Monte Carlo simulation.\n\n### Fundamental Concepts\n\nThe core of the problem lies in the trade-off between exploration and exploitation, a classic theme in optimization. An iterative optimizer seeks to improve a solution over time. The improvement per iteration, denoted by $\\Delta_t$, is modeled as a stochastic process. We assume the expected improvement follows an exponential decay, a common model for processes with diminishing returns:\n$$\n\\mathbb{E}[\\Delta_t] = A e^{-\\beta t}\n$$\nHere, $A  0$ represents the initial scale of improvement and $\\beta  0$ is the decay rate. The observed improvement $\\Delta_t$ is a noisy version of this expectation:\n$$\n\\Delta_t = \\max\\{0,\\, A e^{-\\beta t} + \\eta_t\\}\n$$\nwhere $\\eta_t$ is a random noise term, modeled as an independent and identically distributed (i.i.d.) Gaussian variable, $\\eta_t \\sim \\mathcal{N}(0, \\sigma^2)$. The $\\max\\{0, \\cdot\\}$ operation ensures the observed improvement is nonnegative, which is physically meaningful.\n\n### The Oracle Stopping Rule\n\nAn ideal stopping rule would terminate the optimization process precisely when the *expected* future improvement drops below a meaningful threshold, $\\epsilon_{\\text{true}}$. This defines the oracle stopping time, $t_{\\star}$, which is inaccessible in a real-world scenario as it requires knowledge of the underlying model parameters $A$ and $\\beta$.\nThe oracle stop index $t_{\\star}$ is the smallest integer time $t$ for which the expected improvement is no greater than the true tolerance $\\epsilon_{\\text{true}}$:\n$$\nt_{\\star} = \\min\\{t \\in \\mathbb{N} : A e^{-\\beta t} \\le \\epsilon_{\\text{true}}\\}\n$$\nThis inequality can be solved for $t$:\n$$\nA e^{-\\beta t} \\le \\epsilon_{\\text{true}} \\implies e^{-\\beta t} \\le \\frac{\\epsilon_{\\text{true}}}{A} \\implies -\\beta t \\le \\ln\\left(\\frac{\\epsilon_{\\text{true}}}{A}\\right)\n$$\n$$\nt \\ge -\\frac{1}{\\beta} \\ln\\left(\\frac{\\epsilon_{\\text{true}}}{A}\\right) \\implies t \\ge \\frac{1}{\\beta} \\ln\\left(\\frac{A}{\\epsilon_{\\text{true}}}\\right)\n$$\nSince $t$ must be an integer, $t_{\\star}$ is the smallest integer satisfying this condition, which is found by taking the ceiling of the right-hand side. As $t$ must be a positive integer ($t \\in \\mathbb{N}$), we have:\n$$\nt_{\\star} = \\max\\left(1, \\left\\lceil \\frac{1}{\\beta} \\ln\\left(\\frac{A}{\\epsilon_{\\text{true}}}\\right) \\right\\rceil\\right)\n$$\nFor each set of parameters, $t_{\\star}$ is a deterministic, constant value that serves as our benchmark.\n\n### The Adaptive Stopping Rule\n\nA practical stopping rule cannot access $\\mathbb{E}[\\Delta_t]$ and must rely on the observable, noisy sequence $\\{\\Delta_t\\}$. The proposed adaptive rule uses a simple moving average to filter the noise and estimate the recent trend in improvement. The moving average over a window of size $w$ is defined as:\n$$\n\\overline{\\Delta}_t = \\frac{1}{w} \\sum_{i=t-w+1}^{t} \\Delta_i \\quad \\text{for} \\quad t \\ge w\n$$\nThe adaptive stop index, $\\tau$, is the first time $t$ (at or after the first full window is available at $t=w$) that this moving average drops below a specified estimated tolerance, $\\epsilon_{\\text{est}}$:\n$$\n\\tau = \\min\\left\\{t \\in \\mathbb{N}: t \\ge w \\ \\text{and} \\ \\overline{\\Delta}_t \\le \\epsilon_{\\text{est}}\\right\\}\n$$\nIf this condition is not met by a maximum iteration count $T_{\\max}$, we set $\\tau = T_{\\max}$.\n\nThe behavior of this rule is governed by the interplay of the window size $w$, the noise level $\\sigma$, and the chosen tolerance $\\epsilon_{\\text{est}}$.\n- A small $w$ makes the rule highly responsive but susceptible to noise, potentially causing premature stopping on a random dip or delayed stopping on a random spike.\n- A large $w$ provides better smoothing of the noise but introduces lag. The average $\\overline{\\Delta}_t$ will include older, larger values of $\\Delta_i$, potentially keeping the average above $\\epsilon_{\\text{est}}$ long after the true expected improvement has fallen below the threshold, leading to delayed stopping.\n\n### Monte Carlo Simulation and Risk Assessment\n\nSince $\\Delta_t$ is a random variable, the adaptive stopping time $\\tau$ is also a random variable. To evaluate the performance of the adaptive rule, we must analyze the distribution of $\\tau$ in relation to the fixed oracle time $t_{\\star}$. A Monte Carlo simulation is the appropriate tool for this analysis.\n\nThe procedure is as follows:\n1.  For a given set of parameters $(A, \\beta, \\sigma, w, \\epsilon_{\\text{est}}, \\epsilon_{\\text{true}}, T_{\\max}, M, \\text{seed})$, we first calculate the deterministic oracle time $t_{\\star}$.\n2.  We then conduct $M$ independent simulation runs.\n3.  In each run:\n    a. A sequence of random noise $\\{\\eta_t\\}_{t=1}^{T_{\\max}}$ is generated.\n    b. The sequence of observed improvements $\\{\\Delta_t\\}_{t=1}^{T_{\\max}}$ is computed.\n    c. The moving average sequence $\\{\\overline{\\Delta}_t\\}_{t=w}^{T_{\\max}}$ is calculated.\n    d. The adaptive stopping time $\\tau$ for that specific run is determined.\n4.  After $M$ runs, we have a sample of $M$ values for $\\tau$. We can then estimate the risks by counting outcomes:\n    - **Premature Stopping Risk**: The fraction of runs where the process stopped too early, i.e., $P(\\tau  t_{\\star}) \\approx \\frac{\\text{count}(\\tau  t_{\\star})}{M}$. This represents the risk of failing to achieve the full potential of the optimization.\n    - **Delayed Stopping Risk**: The fraction of runs where the process stopped too late, i.e., $P(\\tau  t_{\\star}) \\approx \\frac{\\text{count}(\\tau  t_{\\star})}{M}$. This represents the risk of wasting computational resources.\n\nThe Python implementation will carry out this simulation for each test case provided. The use of NumPy allows for efficient, vectorized operations to generate the sequences and compute the moving averages. Random number generation is controlled by a seed for reproducibility.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the Monte Carlo simulation for all test cases and print the results.\n    \"\"\"\n    # Test suite: (A, beta, sigma, w, eps_est, eps_true, T_max, M, seed)\n    test_cases = [\n        (0.5, 0.05, 0.02, 10, 0.01, 0.01, 400, 4000, 123),\n        (0.5, 0.05, 0.02, 5, 0.02, 0.01, 400, 4000, 456),\n        (0.5, 0.05, 0.02, 20, 0.005, 0.01, 400, 4000, 789),\n        (0.5, 0.05, 0.08, 3, 0.01, 0.01, 400, 4000, 42),\n        (0.02, 0.1, 0.005, 5, 0.01, 0.01, 200, 4000, 321),\n    ]\n\n    results = []\n    for params in test_cases:\n        premature_risk, delayed_risk = run_simulation(*params)\n        results.extend([round(premature_risk, 3), round(delayed_risk, 3)])\n\n    # Format output according to the problem specification\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_simulation(A, beta, sigma, w, eps_est, eps_true, T_max, M, seed):\n    \"\"\"\n    Performs a Monte Carlo simulation for a single set of parameters.\n\n    Args:\n        A (float): Initial improvement scale.\n        beta (float): Decay rate.\n        sigma (float): Standard deviation of Gaussian noise.\n        w (int): Moving average window size.\n        eps_est (float): Estimated tolerance for the adaptive rule.\n        eps_true (float): True tolerance for the oracle rule.\n        T_max (int): Maximum number of iterations.\n        M (int): Number of Monte Carlo runs.\n        seed (int): Seed for the random number generator.\n\n    Returns:\n        tuple[float, float]: A tuple containing the premature stopping risk and\n                             the delayed stopping risk.\n    \"\"\"\n    # Step 1: Calculate the deterministic oracle stopping time t_star\n    # t_star must be an integer t >= 1.\n    # The condition is t >= (1/beta) * ln(A / eps_true).\n    if A = eps_true:\n        t_star = 1\n    else:\n        t_star_val = (1 / beta) * np.log(A / eps_true)\n        t_star = int(np.ceil(t_star_val))\n        if t_star  1:\n            t_star = 1\n\n    # Step 2: Set up Monte Carlo simulation\n    rng = np.random.default_rng(seed)\n    premature_count = 0\n    delayed_count = 0\n    \n    # Generate time steps array (1-based index)\n    t_steps = np.arange(1, T_max + 1)\n    \n    # Pre-calculate the expected improvement curve\n    expected_delta = A * np.exp(-beta * t_steps)\n\n    for _ in range(M):\n        # Step 3a: Generate noise and observed improvements for one run\n        eta = rng.normal(loc=0, scale=sigma, size=T_max)\n        delta_t = np.maximum(0, expected_delta + eta)\n\n        # Step 3b: Calculate moving averages efficiently using cumulative sums\n        # This creates a sliding window of size w over delta_t\n        cumsum_delta = np.cumsum(delta_t)\n        # Pad with 0 for the t-w calculation\n        cumsum_delta_padded = np.concatenate(([0], cumsum_delta))\n        moving_sums = cumsum_delta_padded[w:] - cumsum_delta_padded[:-w]\n        moving_averages = moving_sums / w\n\n        # moving_averages[i] corresponds to the average at time t = i + w\n        \n        # Step 3c: Find the adaptive stopping time tau\n        # Find indices where the condition is met\n        below_threshold_indices = np.where(moving_averages = eps_est)[0]\n        \n        if below_threshold_indices.size > 0:\n            # The first index 'k' where the condition is met\n            first_idx = below_threshold_indices[0]\n            # Convert index back to time t. Index k corresponds to t = k + w.\n            tau = first_idx + w\n        else:\n            # If condition is never met, stop at T_max\n            tau = T_max\n\n        # Step 3d: Compare tau with t_star and update counters\n        if tau  t_star:\n            premature_count += 1\n        elif tau > t_star:\n            delayed_count += 1\n\n    # Step 4: Calculate risks\n    premature_risk = premature_count / M\n    delayed_risk = delayed_count / M\n\n    return premature_risk, delayed_risk\n\nif __name__ == \"__main__\":\n    solve()\n\n```", "id": "3136544"}]}