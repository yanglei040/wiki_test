{"hands_on_practices": [{"introduction": "To truly master the CAPM, we must look under the hood of the statistical engine that powers it. This first practice moves beyond theory by guiding you through the implementation of the Ordinary Least Squares (OLS) estimator from first principles. By manually coding the calculations to find the $\\alpha$ and $\\beta$ that minimize the sum of squared errors, you will gain a foundational, mechanical understanding of how financial data is translated into model parameters [@problem_id:2378983].", "problem": "You are given multiple samples of time series data for an asset, the market, and the risk-free rate. For each sample, assume the Capital Asset Pricing Model (CAPM) holds in the form\n$$\nr_{i,t} - r_{f,t} = \\alpha + \\beta \\left(r_{m,t} - r_{f,t}\\right) + \\varepsilon_t,\n$$\nfor periods indexed by $t = 1, \\ldots, T$, where $r_{i,t}$ is the asset’s return, $r_{m,t}$ is the market return, $r_{f,t}$ is the risk-free return, $\\alpha$ is the intercept, $\\beta$ is the slope on the market’s excess return, and $\\varepsilon_t$ is the residual. All returns are provided as decimals, not percentages.\n\nYour task is to compute, for each sample, the pair of parameters $(\\hat{\\alpha}, \\hat{\\beta})$ that minimize the sum of squared residuals\n$$\n\\sum_{t=1}^{T} \\left[\\left(r_{i,t} - r_{f,t}\\right) - \\left(\\alpha + \\beta \\left(r_{m,t} - r_{f,t}\\right)\\right)\\right]^2.\n$$\n\nUse the following test suite. For each test case, $r_i$ denotes the asset return series, $r_m$ denotes the market return series, and $r_f$ denotes the risk-free return series. Each series is given as an ordered list of length $T$.\n\n- Test Case 1 (general case, $T=5$):\n  - $r_m = [\\,0.012,\\, 0.018,\\, -0.005,\\, 0.010,\\, 0.022\\,]$\n  - $r_f = [\\,0.002,\\, 0.002,\\, 0.002,\\, 0.0025,\\, 0.0025\\,]$\n  - $r_i = [\\,0.015,\\, 0.0222,\\, -0.0054,\\, 0.0125,\\, 0.0269\\,]$\n\n- Test Case 2 (boundary with minimal observations, $T=2$):\n  - $r_m = [\\,0.02,\\, 0.05\\,]$\n  - $r_f = [\\,0.0,\\, 0.0\\,]$\n  - $r_i = [\\,0.07,\\, 0.16\\,]$\n\n- Test Case 3 (zero intercept, varying risk-free rate, $T=4$):\n  - $r_m = [\\,0.01,\\, 0.00,\\, 0.03,\\, -0.02\\,]$\n  - $r_f = [\\,0.002,\\, 0.002,\\, 0.0025,\\, 0.0015\\,]$\n  - $r_i = [\\,0.014,\\, -0.001,\\, 0.04375,\\, -0.03075\\,]$\n\n- Test Case 4 (negative intercept and slope, $T=3$):\n  - $r_m = [\\,0.015,\\, -0.010,\\, 0.005\\,]$\n  - $r_f = [\\,0.001,\\, 0.0015,\\, 0.001\\,]$\n  - $r_i = [\\,-0.008,\\, 0.00525,\\, -0.003\\,]$\n\nFor each test case, compute the estimates $(\\hat{\\alpha}, \\hat{\\beta})$ using the above criterion. Express all returns and results as decimals (no percentage signs). Your program should produce a single line of output containing the results for the four test cases as a list of lists, with each inner list containing $[\\hat{\\alpha}, \\hat{\\beta}]$ rounded to six decimal places, in the order of the test cases. The exact required output format is:\n$$\n[[\\hat{\\alpha}_1,\\hat{\\beta}_1],[\\hat{\\alpha}_2,\\hat{\\beta}_2],[\\hat{\\alpha}_3,\\hat{\\beta}_3],[\\hat{\\alpha}_4,\\hat{\\beta}_4]]\n$$\nprinted on a single line with commas separating values and lists, and with each float shown using exactly six digits after the decimal point.", "solution": "The problem presented is a standard exercise in econometrics, requiring the estimation of parameters for the Capital Asset Pricing Model (CAPM) using the method of Ordinary Least Squares (OLS). I will first validate the problem statement according to the required protocol.\n\n### Step 1: Extract Givens\n\nThe problem provides the following:\n\n- The CAPM equation:\n$$\nr_{i,t} - r_{f,t} = \\alpha + \\beta \\left(r_{m,t} - r_{f,t}\\right) + \\varepsilon_t\n$$\nwhere $t = 1, \\ldots, T$. The variables are defined as the asset’s return ($r_{i,t}$), the market return ($r_{m,t}$), the risk-free return ($r_{f,t}$), the intercept ($\\alpha$), the slope ($\\beta$), and the residual ($\\varepsilon_t$).\n\n- The objective function to be minimized is the sum of squared residuals (SSR):\n$$\n\\sum_{t=1}^{T} \\left[\\left(r_{i,t} - r_{f,t}\\right) - \\left(\\alpha + \\beta \\left(r_{m,t} - r_{f,t}\\right)\\right)\\right]^2\n$$\n\n- Four test cases with time series data for $r_m$, $r_f$, and $r_i$:\n  - Test Case 1 ($T=5$):\n    - $r_m = [\\,0.012,\\, 0.018,\\, -0.005,\\, 0.010,\\, 0.022\\,]$\n    - $r_f = [\\,0.002,\\, 0.002,\\, 0.002,\\, 0.0025,\\, 0.0025\\,]$\n    - $r_i = [\\,0.015,\\, 0.0222,\\, -0.0054,\\, 0.0125,\\, 0.0269\\,]$\n  - Test Case 2 ($T=2$):\n    - $r_m = [\\,0.02,\\, 0.05\\,]$\n    - $r_f = [\\,0.0,\\, 0.0\\,]$\n    - $r_i = [\\,0.07,\\, 0.16\\,]$\n  - Test Case 3 ($T=4$):\n    - $r_m = [\\,0.01,\\, 0.00,\\, 0.03,\\, -0.02\\,]$\n    - $r_f = [\\,0.002,\\, 0.002,\\, 0.0025,\\, 0.0015\\,]$\n    - $r_i = [\\,0.014,\\, -0.001,\\, 0.04375,\\, -0.03075\\,]$\n  - Test Case 4 ($T=3$):\n    - $r_m = [\\,0.015,\\, -0.010,\\, 0.005\\,]$\n    - $r_f = [\\,0.001,\\, 0.0015,\\, 0.001\\,]$\n    - $r_i = [\\,-0.008,\\, 0.00525,\\, -0.003\\,]$\n\n- The required output is a single-line string representing a list of lists, with each inner list containing the estimated parameters $[\\hat{\\alpha}, \\hat{\\beta}]$ rounded to six decimal places.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem is subjected to validation against the established criteria.\n\n- **Scientifically Grounded**: The problem is an application of linear regression, a fundamental statistical method, to the CAPM, a cornerstone model in financial economics. It is scientifically sound and a classic example in the field.\n- **Well-Posed**: The problem is to find parameters that minimize a sum of squares, which defines a standard Ordinary Least Squares (OLS) estimation. A unique solution for $(\\hat{\\alpha}, \\hat{\\beta})$ exists if and only if the independent variable (market excess return) is not constant. For all given test cases, the market excess return series exhibits variation, thus ensuring the existence of a unique solution. The case where $T=2$ (Test Case 2) is a boundary condition where the two parameters are determined exactly by the two data points, which is a well-defined mathematical problem.\n- **Objective**: The problem is formulated with precise mathematical equations and objective numerical data. There are no subjective or ambiguous statements.\n- **Incomplete or Contradictory Setup**: The problem is self-contained. All necessary data and definitions are provided. There are no contradictions.\n\n### Step 3: Verdict and Action\n\nThe problem statement is **valid**. It is a clear, consistent, and well-posed problem grounded in established financial and statistical theory. I will now proceed with the solution.\n\n### Solution Derivation\n\nThe problem is to find the parameters $\\hat{\\alpha}$ and $\\hat{\\beta}$ by minimizing the sum of squared residuals. This is a classic application of Ordinary Least Squares (OLS). Let us define the excess asset return as $y_t = r_{i,t} - r_{f,t}$ and the excess market return as $x_t = r_{m,t} - r_{f,t}$. The model simplifies to a simple linear regression:\n$$\ny_t = \\alpha + \\beta x_t + \\varepsilon_t\n$$\nThe objective is to minimize the sum of squared residuals, $S(\\alpha, \\beta)$:\n$$\nS(\\alpha, \\beta) = \\sum_{t=1}^{T} \\varepsilon_t^2 = \\sum_{t=1}^{T} (y_t - \\alpha - \\beta x_t)^2\n$$\nTo find the minimum, we take the first-order partial derivatives of $S$ with respect to $\\alpha$ and $\\beta$ and set them to zero.\n\nThe partial derivative with respect to $\\alpha$:\n$$\n\\frac{\\partial S}{\\partial \\alpha} = \\sum_{t=1}^{T} 2(y_t - \\alpha - \\beta x_t)(-1) = -2 \\left( \\sum_{t=1}^{T} y_t - T\\alpha - \\beta \\sum_{t=1}^{T} x_t \\right) = 0\n$$\nThis simplifies to the first normal equation:\n$$\n\\sum_{t=1}^{T} y_t = T\\hat{\\alpha} + \\hat{\\beta} \\sum_{t=1}^{T} x_t\n$$\nDividing by $T$, we get $\\bar{y} = \\hat{\\alpha} + \\hat{\\beta}\\bar{x}$, where $\\bar{y}$ and $\\bar{x}$ are the sample means of $y_t$ and $x_t$, respectively. This allows us to express $\\hat{\\alpha}$ as:\n$$\n\\hat{\\alpha} = \\bar{y} - \\hat{\\beta}\\bar{x}\n$$\n\nThe partial derivative with respect to $\\beta$:\n$$\n\\frac{\\partial S}{\\partial \\beta} = \\sum_{t=1}^{T} 2(y_t - \\alpha - \\beta x_t)(-x_t) = -2 \\left( \\sum_{t=1}^{T} x_t y_t - \\alpha \\sum_{t=1}^{T} x_t - \\beta \\sum_{t=1}^{T} x_t^2 \\right) = 0\n$$\nThis simplifies to the second normal equation:\n$$\n\\sum_{t=1}^{T} x_t y_t = \\hat{\\alpha} \\sum_{t=1}^{T} x_t + \\hat{\\beta} \\sum_{t=1}^{T} x_t^2\n$$\nSubstituting the expression for $\\hat{\\alpha}$ into the second normal equation:\n$$\n\\sum x_t y_t = (\\bar{y} - \\hat{\\beta}\\bar{x}) \\sum x_t + \\hat{\\beta} \\sum x_t^2\n$$\n$$\n\\sum x_t y_t = \\bar{y} \\sum x_t - \\hat{\\beta}\\bar{x} \\sum x_t + \\hat{\\beta} \\sum x_t^2\n$$\nRearranging to solve for $\\hat{\\beta}$:\n$$\n\\hat{\\beta} \\left( \\sum x_t^2 - \\bar{x} \\sum x_t \\right) = \\sum x_t y_t - \\bar{y} \\sum x_t\n$$\nUsing $\\sum x_t = T\\bar{x}$, we have:\n$$\n\\hat{\\beta} \\left( \\sum x_t^2 - T\\bar{x}^2 \\right) = \\sum x_t y_t - T\\bar{x}\\bar{y}\n$$\nThe terms in parentheses are the numerators of the sample variance and covariance, respectively (without the $1/T$ or $1/(T-1)$ scaling factor). Specifically, $\\sum(x_t-\\bar{x})^2 = \\sum x_t^2 - T\\bar{x}^2$ and $\\sum(x_t-\\bar{x})(y_t-\\bar{y}) = \\sum x_t y_t - T\\bar{x}\\bar{y}$. Thus, the estimator for $\\beta$ is given by the well-known formula:\n$$\n\\hat{\\beta} = \\frac{\\sum_{t=1}^{T} (x_t - \\bar{x})(y_t - \\bar{y})}{\\sum_{t=1}^{T} (x_t - \\bar{x})^2} = \\frac{\\text{Cov}(x, y)}{\\text{Var}(x)}\n$$\nThe algorithm will be implemented by first calculating the series $x_t$ and $y_t$ for each test case. Then, the sample means $\\bar{x}$ and $\\bar{y}$ are computed. Finally, $\\hat{\\beta}$ is calculated using the covariance-variance formula, and $\\hat{\\alpha}$ is found using its relationship with the means and $\\hat{\\beta}$. This procedure will be applied to each of the four test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the CAPM parameters alpha and beta for multiple test cases\n    using Ordinary Least Squares (OLS).\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1 (general case, T=5)\n        {\n            'r_m': np.array([0.012, 0.018, -0.005, 0.010, 0.022]),\n            'r_f': np.array([0.002, 0.002, 0.002, 0.0025, 0.0025]),\n            'r_i': np.array([0.015, 0.0222, -0.0054, 0.0125, 0.0269])\n        },\n        # Test Case 2 (boundary with minimal observations, T=2)\n        {\n            'r_m': np.array([0.02, 0.05]),\n            'r_f': np.array([0.0, 0.0]),\n            'r_i': np.array([0.07, 0.16])\n        },\n        # Test Case 3 (zero intercept, varying risk-free rate, T=4)\n        {\n            'r_m': np.array([0.01, 0.00, 0.03, -0.02]),\n            'r_f': np.array([0.002, 0.002, 0.0025, 0.0015]),\n            'r_i': np.array([0.014, -0.001, 0.04375, -0.03075])\n        },\n        # Test Case 4 (negative intercept and slope, T=3)\n        {\n            'r_m': np.array([0.015, -0.010, 0.005]),\n            'r_f': np.array([0.001, 0.0015, 0.001]),\n            'r_i': np.array([-0.008, 0.00525, -0.003])\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        r_m, r_f, r_i = case['r_m'], case['r_f'], case['r_i']\n\n        # Calculate excess returns\n        # y_t = r_i,t - r_f,t (dependent variable)\n        y = r_i - r_f\n        # x_t = r_m,t - r_f,t (independent variable)\n        x = r_m - r_f\n\n        # Calculate sample means\n        x_bar = np.mean(x)\n        y_bar = np.mean(y)\n\n        # Calculate the OLS estimator for beta (slope)\n        # beta_hat = Cov(x, y) / Var(x)\n        # Numerator: sum of cross-products of deviations from mean\n        numerator = np.sum((x - x_bar) * (y - y_bar))\n        # Denominator: sum of squared deviations from mean for x\n        denominator = np.sum((x - x_bar)**2)\n        \n        # Handle the edge case of T=2 where the fit is perfect but division by zero could occur if x values were identical.\n        # The problem validation confirmed this is not an issue for the given test cases.\n        beta_hat = numerator / denominator\n\n        # Calculate the OLS estimator for alpha (intercept)\n        # alpha_hat = y_bar - beta_hat * x_bar\n        alpha_hat = y_bar - beta_hat * x_bar\n\n        results.append([alpha_hat, beta_hat])\n\n    # Format the final output string exactly as required.\n    # The format [v1,v2] does not have a space after the comma.\n    # Using f-strings with a format specifier ensures exactly six decimal places.\n    formatted_results = []\n    for alpha, beta in results:\n        formatted_results.append(f\"[{alpha:.6f},{beta:.6f}]\")\n    \n    final_output_string = f\"[{','.join(formatted_results)}]\"\n    \n    print(final_output_string)\n\nsolve()\n```", "id": "2378983"}, {"introduction": "The classical linear model is a powerful tool, but its assumptions are often too restrictive for the complexities of financial markets. This exercise confronts a common real-world challenge: what to do when your model's residuals are correlated over time or have non-constant variance. You will learn to simulate such data, diagnose the problem of autocorrelation, and compute Newey-West standard errors, a robust technique essential for valid inference in time-series econometrics [@problem_id:2378979].", "problem": "You are given the task of assessing the validity of the Capital Asset Pricing Model (CAPM) for a single asset by estimating its intercept and slope parameters and evaluating residual autocorrelation. Consider the excess return model defined by the CAPM equation\n$$\ny_t = \\alpha + \\beta m_t + \\varepsilon_t,\n$$\nwhere $y_t$ is the asset excess return at time $t$, $m_t$ is the market excess return at time $t$, $\\alpha$ is the intercept, $\\beta$ is the market loading, and $\\varepsilon_t$ is the error term. All returns must be interpreted in decimal form.\n\nFor each test case specified below, you must simulate the processes for $\\{m_t\\}_{t=1}^T$ and $\\{\\varepsilon_t\\}_{t=1}^T$, construct $\\{y_t\\}_{t=1}^T$, and then:\n1. Estimate $\\alpha$ and $\\beta$ via ordinary least squares using the $T \\times 2$ regressor matrix $X$ with a column of ones and the observed $m_t$.\n2. Test the null hypothesis that the residuals $\\{\\hat{\\varepsilon}_t\\}$ are not autocorrelated up to lag $h$, using the large-sample chi-squared test with $h$ degrees of freedom based on the sample residual autocorrelations $\\{\\hat{r}_k\\}_{k=1}^h$.\n3. Compute the conventional ordinary least squares standard errors for $\\alpha$ and $\\beta$.\n4. Compute the Newey–West heteroskedasticity-and-autocorrelation-consistent standard errors for $\\alpha$ and $\\beta$ using the Bartlett kernel with truncation lag $L$.\n\nAll simulations must use a deterministic pseudo-random number generator with the specified seed per test case. For each test case, simulate according to the following general data-generating process. The market excess return $\\{m_t\\}$ follows\n$$\nm_t = \\mu_m + \\phi_m m_{t-1} + \\sigma_m z_t, \\quad m_0 = 0,\n$$\nand the idiosyncratic component $\\{u_t\\}$ follows\n$$\nu_t = \\rho\\, u_{t-1} + \\sigma_\\varepsilon w_t, \\quad u_0 = 0,\n$$\nwith $z_t$ and $w_t$ independent and identically distributed standard normal shocks, independent across $t$ and between sequences. The CAPM error is specified as\n$$\n\\varepsilon_t =\n\\begin{cases}\nu_t, & \\text{if } \\kappa = 0,\\\\\n\\left(1 + \\kappa \\lvert m_t \\rvert \\right) u_t, & \\text{if } \\kappa > 0.\n\\end{cases}\n$$\nThe observed asset excess return is then $y_t = \\alpha + \\beta m_t + \\varepsilon_t$. The risk-free rate is identically zero in all test cases.\n\nShock generation order must be fixed for reproducibility: for each $t$ from $1$ to $T$, first draw $z_t$ to update $m_t$, then draw $w_t$ to update $u_t$, and finally form $\\varepsilon_t$ and $y_t$. The pseudo-random generator must be initialized with the exact seed specified in each test case before generating any shocks, and all random draws must use that single generator in the stated order.\n\nUse the following test suite of parameter values, which together exercise typical, boundary, and edge-case behaviors. In each case, all parameters are scalars in decimal units, and $\\mu_m = 0$.\n\n- Case A (happy path, no residual autocorrelation): $T = 500$, $\\alpha = 0.001$, $\\beta = 1.2$, $\\phi_m = 0.1$, $\\sigma_m = 0.04$, $\\rho = 0$, $\\sigma_\\varepsilon = 0.02$, $\\kappa = 0$, $h = 4$, $L = 4$, seed $= 20240514$.\n- Case B (strong residual autocorrelation): $T = 500$, $\\alpha = 0.001$, $\\beta = 1.2$, $\\phi_m = 0.1$, $\\sigma_m = 0.04$, $\\rho = 0.6$, $\\sigma_\\varepsilon = 0.02$, $\\kappa = 0$, $h = 4$, $L = 4$, seed $= 20240515$.\n- Case C (small sample, moderate autocorrelation): $T = 60$, $\\alpha = 0.001$, $\\beta = 1.2$, $\\phi_m = 0.2$, $\\sigma_m = 0.05$, $\\rho = 0.5$, $\\sigma_\\varepsilon = 0.02$, $\\kappa = 0$, $h = 4$, $L = 4$, seed $= 20240516$.\n- Case D (heteroskedastic and autocorrelated errors): $T = 500$, $\\alpha = 0.001$, $\\beta = 1.2$, $\\phi_m = 0.1$, $\\sigma_m = 0.04$, $\\rho = 0.3$, $\\sigma_\\varepsilon = 0.02$, $\\kappa = 0.8$, $h = 4$, $L = 4$, seed $= 20240517$.\n\nYour program must compute, for each case, the following seven outputs in this exact order: the estimated $\\alpha$, the estimated $\\beta$, the ordinary least squares standard error of $\\alpha$, the ordinary least squares standard error of $\\beta$, the Newey–West standard error of $\\alpha$, the Newey–West standard error of $\\beta$, and a boolean indicating whether the null hypothesis of no autocorrelation up to lag $h$ is rejected at significance level $0.05$.\n\nFinal output format requirement: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a list in the order described above for the corresponding test case, with all floating-point values rounded to six decimal places. For example, the overall format must be\n$$\n\\left[ [\\alpha_1,\\beta_1,se^{\\mathrm{OLS}}_{\\alpha,1},se^{\\mathrm{OLS}}_{\\beta,1},se^{\\mathrm{NW}}_{\\alpha,1},se^{\\mathrm{NW}}_{\\beta,1},\\mathrm{Reject}_1], \\ldots \\right].\n$$", "solution": "The problem presented is a well-posed exercise in computational econometrics, specifically concerning the estimation of the Capital Asset Pricing Model (CAPM). It requires the simulation of financial time series data under different assumptions about the error structure, followed by the estimation of model parameters and a critical evaluation of the estimator's properties. The problem is scientifically sound, fully specified, and objective. We shall proceed with a detailed, principle-based solution.\n\nThe CAPM specifies a linear relationship between an asset's excess return, $y_t$, and the market's excess return, $m_t$:\n$$\ny_t = \\alpha + \\beta m_t + \\varepsilon_t\n$$\nwhere $t = 1, \\dots, T$ indexes time. The parameter $\\alpha$ is the asset's \"alpha,\" representing the excess return not explained by the market. The parameter $\\beta$ is the \"beta,\" measuring the asset's sensitivity to market movements. The term $\\varepsilon_t$ is the idiosyncratic error.\n\nThe first task is to simulate the time series $\\{y_t\\}_{t=1}^T$ and $\\{m_t\\}_{t=1}^T$ according to the provided data-generating process (DGP). For each test case, we must adhere strictly to the specified parameters and random number generator seed.\n\nThe market excess return, $\\{m_t\\}$, is generated by an autoregressive process of order one, AR($1$):\n$$\nm_t = \\phi_m m_{t-1} + \\sigma_m z_t, \\quad \\text{with } m_0 = 0\n$$\nwhere $\\{z_t\\}$ is a sequence of independent and identically distributed (i.i.d.) standard normal random variables.\n\nThe CAPM error term, $\\{\\varepsilon_t\\}$, is constructed from an underlying AR($1$) process, $\\{u_t\\}$:\n$$\nu_t = \\rho u_{t-1} + \\sigma_\\varepsilon w_t, \\quad \\text{with } u_0 = 0\n$$\nwhere $\\{w_t\\}$ is another i.i.d. standard normal sequence, independent of $\\{z_t\\}$. The structure of $\\varepsilon_t$ allows for conditional heteroskedasticity:\n$$\n\\varepsilon_t =\n\\begin{cases}\nu_t, & \\text{if } \\kappa = 0 \\text{ (homoskedasticity)},\\\\\n\\left(1 + \\kappa \\lvert m_t \\rvert \\right) u_t, & \\text{if } \\kappa > 0 \\text{ (heteroskedasticity)}.\n\\end{cases}\n$$\nWhen $\\kappa > 0$, the variance of the error term depends on the magnitude of the market return, a common feature in financial data.\n\nWith the simulated data, we perform the following estimations and tests.\n\n**1. Ordinary Least Squares (OLS) Estimation**\nThe parameters $\\alpha$ and $\\beta$ are estimated using OLS. We define the parameter vector $\\theta = [\\alpha, \\beta]^T$, the dependent variable vector $y = [y_1, \\dots, y_T]^T$, and the regressor matrix $X$, which is a $T \\times 2$ matrix with a column of ones and a column of market returns $\\{m_t\\}$.\n$$\nX = \\begin{bmatrix} 1 & m_1 \\\\ 1 & m_2 \\\\ \\vdots & \\vdots \\\\ 1 & m_T \\end{bmatrix}\n$$\nThe OLS estimator $\\hat{\\theta} = [\\hat{\\alpha}, \\hat{\\beta}]^T$ is given by the well-known formula:\n$$\n\\hat{\\theta} = (X^T X)^{-1} X^T y\n$$\n\n**2. OLS Standard Errors**\nUnder the classical OLS assumptions (including homoskedastic and non-autocorrelated errors, i.e., $\\mathbb{E}[\\varepsilon \\varepsilon^T | X] = \\sigma^2 I_T$), the covariance matrix of the estimator $\\hat{\\theta}$ is:\n$$\n\\text{Var}_{\\text{OLS}}(\\hat{\\theta}) = \\sigma^2 (X^T X)^{-1}\n$$\nThe error variance $\\sigma^2$ is unknown and is estimated from the residuals $\\hat{\\varepsilon}_t = y_t - \\hat{\\alpha} - \\hat{\\beta} m_t$. The unbiased estimator for $\\sigma^2$ is:\n$$\n\\hat{\\sigma}^2 = \\frac{1}{T-k} \\sum_{t=1}^T \\hat{\\varepsilon}_t^2\n$$\nwhere $k=2$ is the number of regressors. The estimated covariance matrix is then $\\widehat{\\text{Var}}_{\\text{OLS}}(\\hat{\\theta}) = \\hat{\\sigma}^2 (X^T X)^{-1}$. The standard errors for $\\hat{\\alpha}$ and $\\hat{\\beta}$ are the square roots of the diagonal elements of this matrix.\n\n**3. Test for Residual Autocorrelation**\nTo test the validity of the no-autocorrelation assumption, we use a large-sample test based on the sample autocorrelations of the residuals. We will employ the Ljung-Box Q-test. The null hypothesis is $H_0: r_1 = r_2 = \\dots = r_h = 0$, where $r_k$ is the population autocorrelation at lag $k$. The test statistic is:\n$$\nQ = T(T+2) \\sum_{k=1}^h \\frac{\\hat{r}_k^2}{T-k}\n$$\nwhere $\\hat{r}_k$ is the sample autocorrelation of the residuals at lag $k$. Under the null hypothesis, $Q$ follows a chi-squared distribution with $h$ degrees of freedom, $Q \\sim \\chi^2(h)$. We reject $H_0$ at a significance level of $0.05$ if the computed $Q$ statistic exceeds the $95^{th}$ percentile of the $\\chi^2(h)$ distribution.\n\n**4. Newey–West (HAC) Standard Errors**\nWhen the errors $\\{\\varepsilon_t\\}$ are heteroskedastic and/or autocorrelated, the OLS standard errors are inconsistent. We must use a Heteroskedasticity and Autocorrelation Consistent (HAC) covariance matrix estimator. The Newey-West estimator is a common choice. The HAC covariance matrix for $\\hat{\\theta}$ has the \"sandwich\" form:\n$$\n\\text{Var}_{\\text{NW}}(\\hat{\\theta}) = (X^T X)^{-1} \\hat{S} (X^T X)^{-1}\n$$\nHere, $\\hat{S}$ is an estimator of the long-run variance of the score vector $g_t = X_t \\varepsilon_t$, where $X_t = [1, m_t]^T$. The Newey-West estimator for $\\hat{S}$ is:\n$$\n\\hat{S} = \\sum_{t=1}^T g_t g_t^T + \\sum_{j=1}^L w_j \\sum_{t=j+1}^T (g_t g_{t-j}^T + g_{t-j} g_t^T)\n$$\nwhere $g_t = X_t \\hat{\\varepsilon}_t$. The problem specifies the Bartlett kernel, for which the weights $w_j$ are given by $w_j = 1 - \\frac{j}{L+1}$, and $L$ is the truncation lag. The Newey-West standard errors for $\\hat{\\alpha}$ and $\\hat{\\beta}$ are the square roots of the diagonal elements of the resulting $\\widehat{\\text{Var}}_{\\text{NW}}(\\hat{\\theta})$ matrix.\n\nThe following Python program implements this complete procedure for each specified test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport scipy.stats\n\ndef process_case(T, alpha, beta, phi_m, sigma_m, rho, sigma_eps, kappa, h, L, seed):\n    \"\"\"\n    Simulates time series data, estimates CAPM parameters, and computes standard errors.\n\n    Args:\n        T (int): Number of time periods.\n        alpha (float): True alpha.\n        beta (float): True beta.\n        phi_m (float): AR(1) coefficient for market return.\n        sigma_m (float): Volatility of market return shock.\n        rho (float): AR(1) coefficient for idiosyncratic error component.\n        sigma_eps (float): Volatility of idiosyncratic error shock.\n        kappa (float): Heteroskedasticity parameter.\n        h (int): Lag length for autocorrelation test.\n        L (int): Truncation lag for Newey-West estimator.\n        seed (int): Seed for the random number generator.\n\n    Returns:\n        list: A list containing estimated alpha, beta, OLS standard errors,\n              Newey-West standard errors, and autocorrelation test result.\n    \"\"\"\n    # 1. Data Generation\n    rng = np.random.default_rng(seed)\n    \n    m = np.zeros(T)\n    u = np.zeros(T)\n    eps = np.zeros(T)\n    y = np.zeros(T)\n\n    m_prev = 0.0\n    u_prev = 0.0\n    mu_m = 0.0 # As specified in the problem\n\n    for t in range(T):\n        z_t = rng.standard_normal()\n        w_t = rng.standard_normal()\n\n        # Market return process\n        m[t] = mu_m + phi_m * m_prev + sigma_m * z_t\n        m_prev = m[t]\n\n        # Idiosyncratic component process\n        u[t] = rho * u_prev + sigma_eps * w_t\n        u_prev = u[t]\n\n        # CAPM error term\n        if kappa == 0:\n            eps[t] = u[t]\n        else:\n            eps[t] = (1 + kappa * np.abs(m[t])) * u[t]\n        \n        # Asset excess return\n        y[t] = alpha + beta * m[t] + eps[t]\n\n    # 2. OLS Estimation\n    X = np.vstack([np.ones(T), m]).T\n    k = X.shape[1]\n    \n    try:\n        XTX_inv = np.linalg.inv(X.T @ X)\n    except np.linalg.LinAlgError:\n        # Handle cases of perfect multicollinearity, though unlikely here\n        return [np.nan] * 7\n\n    theta_hat = XTX_inv @ X.T @ y\n    alpha_hat, beta_hat = theta_hat[0], theta_hat[1]\n\n    # 3. OLS Standard Errors\n    residuals = y - X @ theta_hat\n    sigma2_hat = np.sum(residuals**2) / (T - k)\n    var_cov_ols = sigma2_hat * XTX_inv\n    se_alpha_ols = np.sqrt(var_cov_ols[0, 0])\n    se_beta_ols = np.sqrt(var_cov_ols[1, 1])\n\n    # 4. Residual Autocorrelation Test (Ljung-Box)\n    res_var = np.sum(residuals**2) / T\n    q_stat = 0.0\n    for j in range(1, h + 1):\n        # Sample autocovariance at lag j\n        res_acov_j = np.sum(residuals[j:] * residuals[:-j]) / T\n        # Sample autocorrelation at lag j\n        res_acor_j = res_acov_j / res_var\n        q_stat += (res_acor_j**2) / (T - j)\n        \n    q_stat *= T * (T + 2)\n    \n    chi2_crit_val = scipy.stats.chi2.ppf(0.95, df=h)\n    reject_h0 = q_stat > chi2_crit_val\n\n    # 5. Newey-West HAC Standard Errors\n    g = X * residuals[:, np.newaxis]  # T x k matrix of scores\n    \n    S_hat = g.T @ g\n    \n    for j in range(1, L + 1):\n        weight = 1.0 - j / (L + 1.0)\n        gamma_j = g[j:].T @ g[:-j]\n        S_hat += weight * (gamma_j + gamma_j.T)\n        \n    var_cov_nw = XTX_inv @ S_hat @ XTX_inv\n    se_alpha_nw = np.sqrt(var_cov_nw[0, 0])\n    se_beta_nw = np.sqrt(var_cov_nw[1, 1])\n\n    # 6. Collate and return results\n    return [alpha_hat, beta_hat, se_alpha_ols, se_beta_ols, se_alpha_nw, se_beta_nw, reject_h0]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # T, alpha, beta, phi_m, sigma_m, rho, sigma_eps, kappa, h, L, seed\n        (500, 0.001, 1.2, 0.1, 0.04, 0.0, 0.02, 0.0, 4, 4, 20240514), # Case A\n        (500, 0.001, 1.2, 0.1, 0.04, 0.6, 0.02, 0.0, 4, 4, 20240515), # Case B\n        (60, 0.001, 1.2, 0.2, 0.05, 0.5, 0.02, 0.0, 4, 4, 20240516),  # Case C\n        (500, 0.001, 1.2, 0.1, 0.04, 0.3, 0.02, 0.8, 4, 4, 20240517), # Case D\n    ]\n\n    results = []\n    for case in test_cases:\n        result = process_case(*case)\n        results.append(result)\n\n    # Format output string without extra spaces, rounding floats to 6 places\n    list_of_strings = []\n    for res_list in results:\n        inner_str_list = []\n        for item in res_list:\n            if isinstance(item, (float, np.floating)):\n                inner_str_list.append(f\"{item:.6f}\")\n            else:\n                inner_str_list.append(str(item))\n        inner_str = ','.join(inner_str_list)\n        list_of_strings.append(f\"[{inner_str}]\")\n    \n    final_output_str = f\"[{','.join(list_of_strings)}]\"\n    print(final_output_str)\n\nsolve()\n```", "id": "2378979"}, {"introduction": "When estimating CAPM $\\beta$ parameters for a large universe of stocks, individual OLS estimates can be subject to significant estimation error. This practice introduces the powerful and elegant concept of shrinkage estimation, using the famous James-Stein estimator to improve a portfolio of $\\beta$ estimates by pulling them towards their cross-sectional average. By applying this technique, you will see how borrowing information across assets can lead to more robust parameter estimates, a cornerstone of modern portfolio management and high-dimensional statistics [@problem_id:2378995].", "problem": "You are given a computational task grounded in the Capital Asset Pricing Model (CAPM) estimation. Consider a cross-section of assets indexed by $i \\in \\{1,\\dots,N\\}$ and a time index $t \\in \\{1,\\dots,T\\}$. For each asset $i$, excess returns $r_{i,t}$ and market excess returns $r_{m,t}$ are observed. For each asset $i$, define the ordinary least squares (OLS) regression of $r_{i,t}$ on an intercept and $r_{m,t}$,\n$$\nr_{i,t} = \\alpha_i + \\beta_i r_{m,t} + \\varepsilon_{i,t},\n$$\nwith OLS slope estimate $ \\hat{\\beta}_i $, intercept estimate $ \\hat{\\alpha}_i $, and residuals $ \\hat{\\varepsilon}_{i,t} = r_{i,t} - \\hat{\\alpha}_i - \\hat{\\beta}_i r_{m,t} $. Let $ \\bar{r}_m = T^{-1}\\sum_{t=1}^T r_{m,t} $ and $ S_{xx} = \\sum_{t=1}^T (r_{m,t} - \\bar{r}_m)^2 $. The OLS slope estimate satisfies\n$$\n\\hat{\\beta}_i = \\frac{\\sum_{t=1}^T (r_{m,t} - \\bar{r}_m)(r_{i,t} - \\bar{r}_i)}{S_{xx}}, \\quad \\text{where } \\bar{r}_i = T^{-1} \\sum_{t=1}^T r_{i,t}.\n$$\nDefine the residual variance estimate for asset $i$ as\n$$\n\\hat{\\sigma}_i^2 = \\frac{1}{T-2}\\sum_{t=1}^T \\hat{\\varepsilon}_{i,t}^2,\n$$\nand the standard error of $ \\hat{\\beta}_i $ as\n$$\n\\operatorname{se}(\\hat{\\beta}_i) = \\sqrt{\\frac{\\hat{\\sigma}_i^2}{S_{xx}}}.\n$$\n\nLet $ \\bar{\\beta} = N^{-1} \\sum_{i=1}^N \\hat{\\beta}_i $ denote the cross-sectional mean of OLS betas. Construct standardized components\n$$\nz_i = \\frac{\\hat{\\beta}_i - \\bar{\\beta}}{\\operatorname{se}(\\hat{\\beta}_i)} \\quad \\text{for } i=1,\\dots,N,\n$$\nand let $ \\|z\\|^2 = \\sum_{i=1}^N z_i^2 $. Define the positive-part James–Stein shrinkage factor\n$$\ns = \\begin{cases}\n\\max\\!\\left(0,\\, 1 - \\dfrac{N-2}{\\|z\\|^2}\\right), & \\text{if } \\|z\\|^2 > 0,\\\\\n0, & \\text{if } \\|z\\|^2 = 0,\n\\end{cases}\n$$\nwhich corresponds to the positive-part James–Stein estimator applied to the standardized vector $ z $ with target $ 0 $, i.e., shrinkage of $ \\hat{\\beta}_i $ toward $ \\bar{\\beta} $. The James–Stein shrunk beta for asset $i$ is then\n$$\n\\tilde{\\beta}_i = \\bar{\\beta} + s\\left(\\hat{\\beta}_i - \\bar{\\beta}\\right).\n$$\n\nYour task is to, for each provided test case, compute:\n1. The OLS slope vector $ (\\hat{\\beta}_1, \\dots, \\hat{\\beta}_N) $ and associated standard errors $ \\operatorname{se}(\\hat{\\beta}_i) $ using the formulas above.\n2. The positive-part James–Stein shrinkage factor $ s $ using the standardized vector $ z $ and the formula above.\n3. The James–Stein shrunk betas $ (\\tilde{\\beta}_1, \\dots, \\tilde{\\beta}_N) $.\n4. A comparison metric defined as the mean absolute deviation between the shrunk and OLS betas,\n$$\n\\operatorname{MAD} = \\frac{1}{N}\\sum_{i=1}^N \\left| \\tilde{\\beta}_i - \\hat{\\beta}_i \\right|.\n$$\n5. A boolean indicator that is true if and only if the positive-part boundary is active, i.e., if $ \\|z\\|^2 \\le 0 $ or if $ 1 - (N-2)/\\|z\\|^2 < 0 $, which implies $ s = 0 $ is used due to truncation.\n\nThe final output for each test case must be a list with three entries $[s, \\operatorname{MAD}, \\text{pp}]$, where $ s $ and $ \\operatorname{MAD} $ are floats rounded to exactly $ 6 $ decimal places, and $ \\text{pp} $ is a boolean. The program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, where each element is the three-entry list for a test case. For example, the output format should be like\n$$\n[\\,[s_1,\\operatorname{MAD}_1,\\text{pp}_1],[s_2,\\operatorname{MAD}_2,\\text{pp}_2],\\dots],\n$$\nwith the floats printed with exactly six decimal places.\n\nTest Suite (all returns are unitless decimal returns, e.g., $ 0.01 $ corresponds to $ 1 $ percent):\n- Test Case A (general case, $ T = 12 $, $ N = 5 $). Market excess returns\n$$\nr_m = [0.02,\\,-0.01,\\,0.03,\\,0.04,\\,-0.02,\\,0.01,\\,0.00,\\,0.05,\\,-0.03,\\,0.02,\\,0.01,\\,-0.04].\n$$\nAsset-specific parameters\n$$\n(\\alpha_i)_{i=1}^5 = [0.001,\\,-0.0005,\\,0.0008,\\,0.0,\\,-0.001], \\quad (\\beta_i)_{i=1}^5 = [0.8,\\,1.0,\\,1.2,\\,0.6,\\,1.5],\n$$\nidiosyncratic components $ \\varepsilon_{i,t} $ given by rows (for $ i=1 $ to $ 5 $) of\n$$\n\\begin{aligned}\n[&0.004,\\,-0.003,\\,0.002,\\,-0.0015,\\,0.0005,\\,-0.002,\\,0.001,\\,0.003,\\,-0.001,\\,0.0025,\\,-0.0035,\\,0.0045],\\\\\n[&-0.002,\\,0.0015,\\,-0.001,\\,0.0005,\\,-0.0005,\\,0.001,\\,-0.0015,\\,0.002,\\,-0.0025,\\,0.0015,\\,0.0005,\\,-0.001],\\\\\n[&0.003,\\,-0.002,\\,0.001,\\,-0.003,\\,0.0025,\\,-0.001,\\,0.0005,\\,0.0015,\\,-0.002,\\,0.002,\\,-0.0015,\\,0.0035],\\\\\n[&0.001,\\,-0.001,\\,0.0005,\\,0.0003,\\,-0.0008,\\,0.0009,\\,-0.0006,\\,0.0012,\\,-0.0007,\\,0.0004,\\,-0.0003,\\,0.0006],\\\\\n[&-0.004,\\,0.0035,\\,-0.0025,\\,0.0015,\\,-0.001,\\,0.002,\\,-0.002,\\,0.003,\\,-0.0035,\\,0.0025,\\,-0.002,\\,0.004]\n\\end{aligned}\n$$\nand asset returns constructed as\n$$\nr_{i,t} = \\alpha_i + \\beta_i r_{m,t} + \\varepsilon_{i,t}.\n$$\n\n- Test Case B (near-degenerate case with nearly identical betas, $ T = 10 $, $ N = 4 $). Market excess returns\n$$\nr_m = [0.01,\\,-0.02,\\,0.015,\\,0.005,\\,0.03,\\,-0.01,\\,0.02,\\,-0.015,\\,0.025,\\,0.0].\n$$\nAsset returns for each $ i \\in \\{1,2,3,4\\} $ are constructed as\n$$\nr_{i,t} = r_{m,t} + e_{i,t},\n$$\nwith idiosyncratic components $ e_{i,t} $ given by rows (for $ i=1 $ to $ 4 $) of\n$$\n\\begin{aligned}\n[&0.0003,\\,-0.0002,\\,0.0001,\\,-0.0001,\\,0.0002,\\,-0.0003,\\,0.0003,\\,-0.0002,\\,0.0001,\\,-0.0001],\\\\\n[&-0.0002,\\,0.0002,\\,-0.0001,\\,0.0001,\\,-0.0002,\\,0.0003,\\,-0.0003,\\,0.0002,\\,-0.0001,\\,0.0001],\\\\\n[&0.0001,\\,-0.0001,\\,0.0001,\\,-0.0001,\\,0.0001,\\,-0.0001,\\,0.0001,\\,-0.0001,\\,0.0001,\\,-0.0001],\\\\\n[&-0.0001,\\,0.0001,\\,-0.0001,\\,0.0001,\\,-0.0001,\\,0.0001,\\,-0.0001,\\,0.0001,\\,-0.0001,\\,0.0001]\n\\end{aligned}\n$$\n\n- Test Case C (boundary dimension case, $ T = 8 $, $ N = 2 $). Market excess returns\n$$\nr_m = [0.02,\\,0.01,\\,-0.015,\\,0.03,\\,-0.005,\\,0.025,\\,-0.02,\\,0.015].\n$$\nAsset returns are constructed with distinct slopes as\n$$\n\\begin{aligned}\nr_{1,t} &= 0.0005 + 0.7\\, r_{m,t} + u_t, \\\\\nr_{2,t} &= -0.0007 + 1.4\\, r_{m,t} + v_t,\n\\end{aligned}\n$$\nwhere\n$$\nu = [0.001,\\,-0.001,\\,0.0005,\\,-0.0005,\\,0.0008,\\,-0.0008,\\,0.001,\\,-0.001], \\quad\nv = [-0.0015,\\,0.001,\\,-0.0008,\\,0.0006,\\,-0.0007,\\,0.0005,\\,-0.0009,\\,0.0007].\n$$\n\nFinal Output Format:\n- Your program must produce a single line of output of the form\n$$\n[\\,[s_A,\\operatorname{MAD}_A,\\text{pp}_A],[s_B,\\operatorname{MAD}_B,\\text{pp}_B],[s_C,\\operatorname{MAD}_C,\\text{pp}_C]\\,],\n$$\nwhere test cases $ A, B, C $ correspond to the three cases above, each $ s $ and $ \\operatorname{MAD} $ is rounded to exactly $ 6 $ decimal places, and each $ \\text{pp} $ is a boolean. No other text must be printed.", "solution": "The problem is validated as scientifically sound, well-posed, objective, and self-contained. It presents a standard computational task from financial econometrics, involving Ordinary Least Squares (OLS) estimation and the application of a James-Stein shrinkage estimator to the estimated parameters. All formulas and data are provided explicitly and are consistent with established theory. The problem is therefore deemed **valid**. We proceed with the solution.\n\nThe objective is to compute a set of statistics for three distinct test cases. The procedure involves estimating the parameters of the Capital Asset Pricing Model (CAPM) for a cross-section of $N$ assets over $T$ time periods, and then applying a positive-part James-Stein shrinkage technique to the estimated slope coefficients ($\\beta_i$).\n\nThe computational steps for each test case are as follows:\n\n**Step 1: OLS Estimation of CAPM Parameters**\n\nFor each asset $i \\in \\{1, \\dots, N\\}$, we estimate the regression model:\n$$\nr_{i,t} = \\alpha_i + \\beta_i r_{m,t} + \\varepsilon_{i,t}\n$$\nFirst, we compute auxiliary quantities from the market excess returns $r_{m,t}$. Let $\\bar{r}_m = \\frac{1}{T}\\sum_{t=1}^T r_{m,t}$ be the sample mean of market returns. The sum of squared deviations is $S_{xx} = \\sum_{t=1}^T (r_{m,t} - \\bar{r}_m)^2$.\n\nFor each asset $i$, we compute its mean return $\\bar{r}_i = \\frac{1}{T}\\sum_{t=1}^T r_{i,t}$. The OLS estimate for the slope coefficient, $\\hat{\\beta}_i$, is given by:\n$$\n\\hat{\\beta}_i = \\frac{\\sum_{t=1}^T (r_{m,t} - \\bar{r}_m)(r_{i,t} - \\bar{r}_i)}{S_{xx}}\n$$\nThe OLS estimate for the intercept, $\\hat{\\alpha}_i$, is then:\n$$\n\\hat{\\alpha}_i = \\bar{r}_i - \\hat{\\beta}_i \\bar{r}_m\n$$\nUsing these estimates, we find the regression residuals for each observation:\n$$\n\\hat{\\varepsilon}_{i,t} = r_{i,t} - (\\hat{\\alpha}_i + \\hat{\\beta}_i r_{m,t})\n$$\nThe unbiased estimate of the residual variance is:\n$$\n\\hat{\\sigma}_i^2 = \\frac{1}{T-2}\\sum_{t=1}^T \\hat{\\varepsilon}_{i,t}^2\n$$\nFinally, the standard error of the slope estimate $\\hat{\\beta}_i$ is calculated as:\n$$\n\\operatorname{se}(\\hat{\\beta}_i) = \\sqrt{\\frac{\\hat{\\sigma}_i^2}{S_{xx}}}\n$$\nThese calculations are performed for all $N$ assets, yielding vectors of estimates $(\\hat{\\beta}_1, \\dots, \\hat{\\beta}_N)$ and standard errors $(\\operatorname{se}(\\hat{\\beta}_1), \\dots, \\operatorname{se}(\\hat{\\beta}_N))$.\n\n**Step 2: James-Stein Shrinkage Factor Calculation**\n\nThe James-Stein procedure shrinks the individual estimates $\\hat{\\beta}_i$ towards their cross-sectional mean, $\\bar{\\beta} = \\frac{1}{N} \\sum_{i=1}^N \\hat{\\beta}_i$.\n\nFirst, we construct a vector $z$ of standardized components, where each element $z_i$ measures the deviation of $\\hat{\\beta}_i$ from $\\bar{\\beta}$ in units of its standard error:\n$$\nz_i = \\frac{\\hat{\\beta}_i - \\bar{\\beta}}{\\operatorname{se}(\\hat{\\beta}_i)}\n$$\nWe then compute the squared Euclidean norm of this vector, $\\|z\\|^2 = \\sum_{i=1}^N z_i^2$.\n\nThe positive-part James-Stein shrinkage factor, $s$, is defined according to the problem statement as:\n$$\ns = \\begin{cases}\n\\max\\!\\left(0,\\, 1 - \\dfrac{N-2}{\\|z\\|^2}\\right), & \\text{if } \\|z\\|^2 > 0 \\\\\n0, & \\text{if } \\|z\\|^2 = 0\n\\end{cases}\n$$\nThis factor determines the degree of shrinkage. A value of $s=1$ implies no shrinkage, while $s=0$ implies full shrinkage to the mean $\\bar{\\beta}$. For the case $N \\le 2$, the term $N-2 \\le 0$, which leads to $s \\ge 1$ (if $\\|z\\|^2 > 0$). This is a known boundary case for the James-Stein estimator, where standard dominance results do not hold. We will strictly apply the given formula.\n\n**Step 3: Shrunk Betas and Mean Absolute Deviation**\n\nThe James-Stein shrunk estimate for each asset's beta, $\\tilde{\\beta}_i$, is a weighted average of the individual estimate $\\hat{\\beta}_i$ and the grand mean $\\bar{\\beta}$:\n$$\n\\tilde{\\beta}_i = \\bar{\\beta} + s(\\hat{\\beta}_i - \\bar{\\beta})\n$$\nThis can be rewritten as $\\tilde{\\beta}_i = (1-s)\\bar{\\beta} + s \\hat{\\beta}_i$.\n\nTo quantify the magnitude of the shrinkage adjustment, we compute the Mean Absolute Deviation ($\\operatorname{MAD}$) between the shrunk and OLS betas:\n$$\n\\operatorname{MAD} = \\frac{1}{N}\\sum_{i=1}^N |\\tilde{\\beta}_i - \\hat{\\beta}_i| = \\frac{1}{N}\\sum_{i=1}^N |(s-1)(\\hat{\\beta}_i - \\bar{\\beta})| = |1-s| \\frac{1}{N}\\sum_{i=1}^N |\\hat{\\beta}_i - \\bar{\\beta}|\n$$\n\n**Step 4: Positive-Part Boundary Indicator**\n\nWe determine the boolean indicator $\\text{pp}$. This indicator is true if the shrinkage factor $s$ is set to $0$ because the positive-part constraint is active. This occurs if $1 - \\frac{N-2}{\\|z\\|^2} \\le 0$ (for $\\|z\\|^2>0$) or if $\\|z\\|^2 = 0$. Both conditions are equivalent to $\\|z\\|^2 \\le N-2$ (assuming $N \\ge 2$, and that $1/0$ is treated as infinity). Thus, the indicator is computed as:\n$$\n\\text{pp} = (\\|z\\|^2 \\le N-2)\n$$\n\nThe entire procedure is implemented in a Python script to process the three given test cases and generate the required output in the specified format. The calculations are vectorized for efficiency using the `numpy` library.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run computations, and print results.\n    \"\"\"\n\n    # Test Case A Data\n    T_A = 12\n    N_A = 5\n    r_m_A = np.array([0.02, -0.01, 0.03, 0.04, -0.02, 0.01, 0.00, 0.05, -0.03, 0.02, 0.01, -0.04])\n    alpha_A = np.array([0.001, -0.0005, 0.0008, 0.0, -0.001])\n    beta_A = np.array([0.8, 1.0, 1.2, 0.6, 1.5])\n    eps_A = np.array([\n        [0.004, -0.003, 0.002, -0.0015, 0.0005, -0.002, 0.001, 0.003, -0.001, 0.0025, -0.0035, 0.0045],\n        [-0.002, 0.0015, -0.001, 0.0005, -0.0005, 0.001, -0.0015, 0.002, -0.0025, 0.0015, 0.0005, -0.001],\n        [0.003, -0.002, 0.001, -0.003, 0.0025, -0.001, 0.0005, 0.0015, -0.002, 0.002, -0.0015, 0.0035],\n        [0.001, -0.001, 0.0005, 0.0003, -0.0008, 0.0009, -0.0006, 0.0012, -0.0007, 0.0004, -0.0003, 0.0006],\n        [-0.004, 0.0035, -0.0025, 0.0015, -0.001, 0.002, -0.002, 0.003, -0.0035, 0.0025, -0.002, 0.004]\n    ])\n    R_A = alpha_A[:, np.newaxis] + beta_A[:, np.newaxis] * r_m_A[np.newaxis, :] + eps_A\n\n    # Test Case B Data\n    T_B = 10\n    N_B = 4\n    r_m_B = np.array([0.01, -0.02, 0.015, 0.005, 0.03, -0.01, 0.02, -0.015, 0.025, 0.0])\n    e_B = np.array([\n        [0.0003, -0.0002, 0.0001, -0.0001, 0.0002, -0.0003, 0.0003, -0.0002, 0.0001, -0.0001],\n        [-0.0002, 0.0002, -0.0001, 0.0001, -0.0002, 0.0003, -0.0003, 0.0002, -0.0001, 0.0001],\n        [0.0001, -0.0001, 0.0001, -0.0001, 0.0001, -0.0001, 0.0001, -0.0001, 0.0001, -0.0001],\n        [-0.0001, 0.0001, -0.0001, 0.0001, -0.0001, 0.0001, -0.0001, 0.0001, -0.0001, 0.0001]\n    ])\n    R_B = r_m_B[np.newaxis, :] + e_B\n\n    # Test Case C Data\n    T_C = 8\n    N_C = 2\n    r_m_C = np.array([0.02, 0.01, -0.015, 0.03, -0.005, 0.025, -0.02, 0.015])\n    u_C = np.array([0.001, -0.001, 0.0005, -0.0005, 0.0008, -0.0008, 0.001, -0.001])\n    v_C = np.array([-0.0015, 0.001, -0.0008, 0.0006, -0.0007, 0.0005, -0.0009, 0.0007])\n    r1_C = 0.0005 + 0.7 * r_m_C + u_C\n    r2_C = -0.0007 + 1.4 * r_m_C + v_C\n    R_C = np.array([r1_C, r2_C])\n    \n    test_cases = [\n        (T_A, N_A, r_m_A, R_A),\n        (T_B, N_B, r_m_B, R_B),\n        (T_C, N_C, r_m_C, R_C),\n    ]\n\n    results = []\n    for T, N, r_m, R in test_cases:\n        s, mad, pp = compute_case_statistics(T, N, r_m, R)\n        results.append(f\"[{s:.6f},{mad:.6f},{str(pp)}]\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef compute_case_statistics(T, N, r_m, R):\n    \"\"\"\n    Computes all required statistics for a single test case.\n\n    Args:\n        T (int): Number of time periods.\n        N (int): Number of assets.\n        r_m (np.ndarray): Market excess returns, shape (T,).\n        R (np.ndarray): Asset excess returns, shape (N, T).\n\n    Returns:\n        tuple: A tuple containing (s, MAD, pp).\n    \"\"\"\n    # Step 1: OLS Estimation (vectorized)\n    r_m_mean = r_m.mean()\n    r_m_dev = r_m - r_m_mean\n    S_xx = np.sum(r_m_dev**2)\n\n    R_mean = R.mean(axis=1)\n    # The formula for beta_hat using centered data\n    S_xy = (R - R_mean[:, np.newaxis]) @ r_m_dev\n    beta_hat = S_xy / S_xx\n    \n    alpha_hat = R_mean - beta_hat * r_m_mean\n    \n    eps_hat = R - (alpha_hat[:, np.newaxis] + beta_hat[:, np.newaxis] * r_m[np.newaxis, :])\n    sigma_sq_hat = np.sum(eps_hat**2, axis=1) / (T - 2)\n    se_beta_hat = np.sqrt(sigma_sq_hat / S_xx)\n\n    # Step 2: James-Stein Shrinkage Factor Calculation\n    beta_bar = beta_hat.mean()\n    \n    # Safely compute z_i, handling potential division by zero\n    z = np.divide(beta_hat - beta_bar, se_beta_hat, out=np.zeros_like(beta_hat), where=se_beta_hat!=0)\n      \n    z_norm_sq = np.sum(z**2)\n    \n    if z_norm_sq == 0:\n        s = 0.0\n    else:\n        s = max(0.0, 1.0 - (N - 2) / z_norm_sq)\n    \n    # Step 3: Shrunk Betas and MAD\n    beta_tilde = beta_bar + s * (beta_hat - beta_bar)\n    mad = np.mean(np.abs(beta_tilde - beta_hat))\n    \n    # Step 4: Positive-Part Boundary Indicator\n    pp = z_norm_sq = (N - 2)\n    \n    return s, mad, pp\n\nsolve()\n\n```", "id": "2378995"}]}