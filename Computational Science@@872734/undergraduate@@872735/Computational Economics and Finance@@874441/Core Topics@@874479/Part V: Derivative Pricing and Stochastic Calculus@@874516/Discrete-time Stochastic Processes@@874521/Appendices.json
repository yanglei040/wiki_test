{"hands_on_practices": [{"introduction": "Many phenomena in economics and finance, from the business cycle to a company's creditworthiness, can be modeled as a system transitioning between a finite number of states. This exercise provides hands-on practice building a foundational tool for this purpose: the discrete-time Markov chain [@problem_id:2388997]. By analyzing historical data, you will learn to estimate the probabilities of moving between states and to calculate the system's long-run stationary distribution, a key concept for understanding equilibrium and long-term forecasts.", "problem": "Consider a discrete-time credit rating system modeled as a first-order Markov chain on a finite state space. The state space is ordered as $S=\\{\\text{AAA},\\text{AA},\\text{A},\\text{BBB},\\text{Default}\\}$, which we index as $0,1,2,3,4$ respectively. You observe a time-ordered sequence of ratings $\\{X_t\\}_{t=0}^{T}$ taking values in $S$. Let $N_{ij}$ denote the count of one-step transitions from state $i$ to state $j$ in the observed sequence, that is, $N_{ij}=\\#\\{t \\in \\{0,\\ldots,T-1\\}\\,:\\,X_t=i,\\,X_{t+1}=j\\}$.\n\nYou must estimate the $5\\times 5$ transition probability matrix $P=\\left[P_{ij}\\right]$ using Laplace-smoothed maximum likelihood with pseudocount $\\alpha=1$. Specifically, for each $i\\in\\{0,1,2,3,4\\}$ and $j\\in\\{0,1,2,3,4\\}$, define\n$$\n\\widehat{P}_{ij}=\\frac{N_{ij}+\\alpha}{\\sum_{k=0}^{4} N_{ik}+5\\alpha},\n$$\nwith $\\alpha=1$. This yields a row-stochastic matrix with strictly positive entries.\n\nCompute the long-run (stationary) distribution $\\pi$ as the unique row vector with nonnegative entries that satisfies\n$$\n\\pi \\widehat{P}=\\pi,\\quad \\sum_{i=0}^{4}\\pi_i=1.\n$$\nReport the stationary distribution as a list of decimal numbers rounded to six decimal places in the specified state order $[\\pi_{\\text{AAA}},\\pi_{\\text{AA}},\\pi_{\\text{A}},\\pi_{\\text{BBB}},\\pi_{\\text{Default}}]$.\n\nUse the following test suite of observed sequences (each is a list of labels in $S$):\n\n- Test case $1$ (general case with upgrades and downgrades): \n  $[\\text{BBB},\\text{A},\\text{AA},\\text{AAA},\\text{AA},\\text{A},\\text{BBB},\\text{A},\\text{AA},\\text{AAA},\\text{AA},\\text{A},\\text{BBB},\\text{A},\\text{AA},\\text{AAA},\\text{AA},\\text{A},\\text{BBB},\\text{Default},\\text{A},\\text{AA},\\text{AAA},\\text{AA},\\text{A},\\text{BBB},\\text{A},\\text{AA},\\text{AAA},\\text{AA},\\text{A},\\text{BBB}]$.\n\n- Test case $2$ (boundary case with minimal information): \n  $[\\text{A},\\text{A}]$.\n\n- Test case $3$ (edge case with concentration in high ratings): \n  $[\\text{AAA},\\text{AA},\\text{AAA},\\text{AAA},\\text{AA},\\text{A},\\text{AAA},\\text{AAA},\\text{AAA},\\text{AA},\\text{A},\\text{AAA},\\text{AAA},\\text{AAA},\\text{AAA},\\text{AAA}]$.\n\nFor each test case, you must:\n1. Construct the smoothed estimator $\\widehat{P}$ using $\\alpha=1$ for all entries.\n2. Compute the stationary distribution $\\pi$ satisfying $\\pi \\widehat{P}=\\pi$ and $\\sum_i \\pi_i=1$.\n3. Round each component of $\\pi$ to six decimal places.\n\nFinal output format: Your program should produce a single line of output containing the results for all three test cases as a comma-separated list enclosed in square brackets, where each element is itself the list representation of the stationary distribution in the specified state order. For example, an admissible format is\n$[[\\pi^{(1)}_{\\text{AAA}},\\ldots,\\pi^{(1)}_{\\text{Default}}],[\\pi^{(2)}_{\\text{AAA}},\\ldots,\\pi^{(2)}_{\\text{Default}}],[\\pi^{(3)}_{\\text{AAA}},\\ldots,\\pi^{(3)}_{\\text{Default}}]]$,\nwith each number rounded to six decimal places. There are no physical units, angles, or percentages in this problem; all outputs must be decimals.", "solution": "The problem presented is a valid exercise in computational statistics and stochastic processes. It is scientifically grounded, well-posed, and objective. We shall proceed with a complete solution.\n\nThe problem requires us to estimate the stationary distribution of a discrete-time, first-order Markov chain. The state space is given as $S=\\{\\text{AAA}, \\text{AA}, \\text{A}, \\text{BBB}, \\text{Default}\\}$, which we shall index by integers $i \\in \\{0, 1, 2, 3, 4\\}$, respectively. We are given a time series of observations $\\{X_t\\}_{t=0}^{T}$.\n\nFirst, we must estimate the transition probability matrix, denoted by $P = [P_{ij}]$, where $P_{ij} = \\mathbb{P}(X_{t+1}=j | X_t=i)$. The problem specifies the use of a Laplace-smoothed maximum likelihood estimator. This is a Bayesian estimation method where a Dirichlet prior is placed on the rows of the transition matrix. For a given row $i$, the prior on the probability vector $[P_{i0}, \\dots, P_{i4}]$ is a symmetric Dirichlet distribution with concentration parameter $\\alpha$.\n\nLet $N_{ij}$ be the number of observed one-step transitions from state $i$ to state $j$ in the sequence. The formula for the smoothed estimator $\\widehat{P}_{ij}$ is given as:\n$$\n\\widehat{P}_{ij} = \\frac{N_{ij} + \\alpha}{\\sum_{k=0}^{4} N_{ik} + |S|\\alpha}\n$$\nwhere $|S|$ is the number of states, which is $5$. The problem specifies a pseudocount of $\\alpha=1$. Let $N_i = \\sum_{k=0}^{4} N_{ik}$ be the total number of transitions observed to originate from state $i$. The estimator simplifies to:\n$$\n\\widehat{P}_{ij} = \\frac{N_{ij} + 1}{N_i + 5}\n$$\nThis procedure ensures that every entry in the estimated transition matrix $\\widehat{P}$ is strictly positive, i.e., $\\widehat{P}_{ij}  0$ for all $i, j \\in S$. A Markov chain with a transition matrix having all positive entries is known as a regular Markov chain. A key property of a regular Markov chain on a finite state space is that it is ergodic and possesses a unique stationary distribution.\n\nThe stationary distribution is a row vector $\\pi = [\\pi_0, \\pi_1, \\pi_2, \\pi_3, \\pi_4]$ that satisfies two conditions:\n$1.$ $\\pi \\widehat{P} = \\pi$\n$2.$ $\\sum_{i=0}^{4} \\pi_i = 1$\n\nThe first condition, $\\pi \\widehat{P} = \\pi$, means that $\\pi$ is a left eigenvector of the matrix $\\widehat{P}$ with a corresponding eigenvalue of $\\lambda=1$. This can be rewritten as a system of homogeneous linear equations:\n$$\n\\pi (\\widehat{P} - I) = \\mathbf{0}\n$$\nwhere $I$ is the $5 \\times 5$ identity matrix and $\\mathbf{0}$ is a zero row vector. In transpose form, this is $(\\widehat{P}^T - I^T) \\pi^T = \\mathbf{0}^T$, or more simply, $(\\widehat{P}^T - I) \\pi^T = \\mathbf{0}$.\n\nSince $\\lambda=1$ is an eigenvalue of any row-stochastic matrix, the matrix $(\\widehat{P}^T - I)$ is singular, and its null space is non-trivial. For a regular Markov chain, the eigenspace corresponding to $\\lambda=1$ has dimension $1$. Therefore, the system $(\\widehat{P}^T - I) \\pi^T = \\mathbf{0}$ has a solution space of dimension $1$. To find the unique stationary distribution $\\pi$, we must impose the normalization condition $\\sum_{i=0}^{4} \\pi_i = 1$.\n\nNumerically, we can solve this by constructing a system of linear equations. We take the first $|S|-1=4$ linear equations from $(\\widehat{P}^T - I) \\pi^T = \\mathbf{0}$ and add the normalization equation. Let $A$ be the matrix whose first $4$ rows are the first $4$ rows of $(\\widehat{P}^T - I)$ and whose last row is a vector of all ones. Let $b$ be a column vector with $4$ zeros followed by a one. The system to solve is:\n$$\nA \\pi^T = b\n$$\nThe solution is given by $\\pi^T = A^{-1}b$. The existence and uniqueness of the solution is guaranteed by the regularity of $\\widehat{P}$.\n\nWe will apply this procedure to each of the three test cases.\n\n**Step 1: State Mapping and Transition Counting**\nFor each test sequence, we map the string labels to integer indices $\\{0, 1, 2, 3, 4\\}$. Then, we iterate through the sequence of length $T+1$ to count the $T$ transitions and populate the $5 \\times 5$ count matrix $N = [N_{ij}]$.\n\n**Step 2: Transition Matrix Estimation**\nUsing the count matrix $N$ and $\\alpha=1$, we compute the smoothed transition matrix $\\widehat{P}$ using the formula $\\widehat{P}_{ij} = (N_{ij} + 1) / (N_i + 5)$.\n\n**Step 3: Stationary Distribution Calculation**\nWe construct the matrix $A$ from $\\widehat{P}^T$ as described above and the vector $b = [0, 0, 0, 0, 1]^T$. We then solve the linear system $A \\pi^T = b$ for $\\pi^T$ using a standard linear algebra solver.\n\n**Step 4: Formatting**\nThe components of the resulting vector $\\pi$ are rounded to six decimal places as required. The final output is a list containing the rounded stationary distribution vectors for each test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n\n    state_map = {'AAA': 0, 'AA': 1, 'A': 2, 'BBB': 3, 'Default': 4}\n    num_states = len(state_map)\n    alpha = 1.0\n\n    test_cases = [\n        ['BBB','A','AA','AAA','AA','A','BBB','A','AA','AAA','AA','A','BBB','A','AA','AAA','AA','A','BBB','Default','A','AA','AAA','AA','A','BBB','A','AA','AAA','AA','A','BBB'],\n        ['A','A'],\n        ['AAA','AA','AAA','AAA','AA','A','AAA','AAA','AAA','AA','A','AAA','AAA','AAA','AAA','AAA']\n    ]\n\n    all_results = []\n\n    for sequence in test_cases:\n        # Step 1: Count transitions\n        counts = np.zeros((num_states, num_states), dtype=int)\n        int_sequence = [state_map[s] for s in sequence]\n        \n        for i in range(len(int_sequence) - 1):\n            from_state = int_sequence[i]\n            to_state = int_sequence[i+1]\n            counts[from_state, to_state] += 1\n\n        # Step 2: Estimate smoothed transition matrix P_hat\n        p_hat = np.zeros((num_states, num_states), dtype=float)\n        row_totals = np.sum(counts, axis=1)\n        \n        for i in range(num_states):\n            denominator = row_totals[i] + num_states * alpha\n            for j in range(num_states):\n                numerator = counts[i, j] + alpha\n                p_hat[i, j] = numerator / denominator\n\n        # Step 3: Compute the stationary distribution pi\n        # We need to solve pi * P_hat = pi, or pi * (P_hat - I) = 0,\n        # which is equivalent to (P_hat^T - I^T) * pi^T = 0^T.\n        # Let A = P_hat^T - I. We solve for the null space of A.\n        # We replace the last equation with the normalization condition sum(pi) = 1.\n        \n        A = (p_hat.T - np.identity(num_states))\n        A[-1, :] = 1.0  # Last row is for sum(pi_i) = 1\n        \n        b = np.zeros(num_states)\n        b[-1] = 1.0  # Corresponds to sum(pi_i) = 1\n        \n        try:\n            # Solve the linear system A * pi^T = b\n            pi = np.linalg.solve(A, b)\n            \n            # Ensure non-negativity and re-normalize for robustness\n            pi[pi  0] = 0\n            pi /= np.sum(pi)\n\n        except np.linalg.LinAlgError:\n            # Fallback for singular matrix if something unexpected happens\n            # For a regular P_hat, this shouldn't be reached.\n            # We can use eigenvector method as a backup.\n            # Find the right eigenvector of P_hat.T for eigenvalue 1\n            eigenvalues, eigenvectors = np.linalg.eig(p_hat.T)\n            # Find the eigenvector corresponding to eigenvalue 1\n            idx = np.argmin(np.abs(eigenvalues - 1.0))\n            pi = np.real(eigenvectors[:, idx])\n            # Normalize to get the probability distribution\n            pi = pi / np.sum(pi)\n\n        # Step 4: Round and format the result\n        rounded_pi = np.round(pi, 6).tolist()\n        all_results.append(rounded_pi)\n\n    # Final print statement in the exact required format.\n    # The default str() representation of a list of lists works. e.g., [[...], [...]]\n    print(str(all_results).replace(\" \", \"\"))\n\n\nsolve()\n```", "id": "2388997"}, {"introduction": "Often, the variables we care most about, like a company's 'true' value or an asset's long-term trend, are not directly observable and must be inferred from noisy data. This practice [@problem_id:2389012] introduces the Kalman filter, a powerful and widely-used algorithm for separating signal from noise. You will apply it to the engaging problem of estimating a basketball player's hidden 'true' shooting ability from their variable game-to-game performance, a classic example of state estimation.", "problem": "Consider a single hidden state representing a basketball player’s underlying shooting ability in a sequence of games. At each discrete time step $t \\in \\{1,2,\\dots,T\\}$, the player takes $n_t$ shots and makes $m_t$ shots. Define the observed shooting percentage as $y_t = m_t / n_t$ when $n_t \\gt 0$ and treat $y_t$ as missing when $n_t = 0$. Model the hidden ability and the observations using the following linear Gaussian state-space model:\n- Hidden state dynamics: $ \\theta_t = \\mu + \\phi \\left(\\theta_{t-1} - \\mu\\right) + w_t $, where $w_t \\sim \\mathcal{N}(0,q)$.\n- Observation equation (when $n_t \\gt 0$): $ y_t = \\theta_t + v_t $, where $v_t \\sim \\mathcal{N}(0, R_t)$.\n\nAssume $R_t$ is known and depends on $n_t$ via a binomial-sampling-inspired approximation for the variance of a sample mean: $ R_t = \\bar{p}(1-\\bar{p}) / n_t $, where $\\bar{p}$ is a fixed reference probability. When $n_t = 0$, treat the observation as missing and perform only the state prediction step (no update). All probabilities and variances must be expressed as decimals (for example, write $0.45$ instead of $45\\%$).\n\nYou are given the following fixed parameters:\n- Long-run mean: $\\mu = 0.45$.\n- Autoregressive coefficient: $\\phi = 0.90$.\n- State innovation variance: $q = 0.0005$.\n- Reference probability for the observation variance: $\\bar{p} = 0.45$ (use this in $R_t$).\n- Prior for the initial state: $\\theta_0 \\sim \\mathcal{N}(m_0, P_0)$ with $m_0 = 0.45$ and $P_0 = 0.01$.\n\nStarting from the prior $(m_0, P_0)$, implement the recursive filtering procedure that, at each time $t$, computes the one-step-ahead prediction for the state and its variance, then (if $n_t \\gt 0$) updates them with the observation $y_t$ using the linear Gaussian model above. If $n_t = 0$, skip the update and carry forward the prediction as the filtered state for that period.\n\nYour task is to write a complete program that:\n1. Implements the described time-varying-variance Kalman filter for the model specified above.\n2. Runs the filter on each of the following test suites of games (each suite is a sequence of $(m_t, n_t)$ pairs):\n   - Test case A (moderate attempts, varied outcomes):\n     - $[(5,11), (4,10), (7,12), (6,14), (2,6), (8,15), (3,8), (6,12), (7,16), (5,9)]$.\n   - Test case B (high attempts, relatively stable outcomes):\n     - $[(9,20), (10,22), (8,18), (11,24), (12,25), (9,19), (10,21), (12,26), (11,24), (13,28)]$.\n   - Test case C (some games with zero attempts; treat those as missing observations):\n     - $[(0,0), (3,5), (0,0), (4,4), (0,0), (2,10), (0,0), (5,10)]$.\n   - Test case D (volatile outcomes and attempts):\n     - $[(1,2), (0,5), (7,10), (1,12), (9,10), (0,3), (6,15), (2,2), (0,8), (10,12)]$.\n3. For each test case, outputs the final filtered posterior mean $\\hat{\\theta}_T$ and variance $P_T$ after processing the last game in the sequence.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case result must itself be a two-element list $[\\hat{\\theta}_T, P_T]$ with both values rounded to exactly six decimal places. For example, the overall output should look like:\n- $[[\\hat{\\theta}_T^{(A)}, P_T^{(A)}],[\\hat{\\theta}_T^{(B)}, P_T^{(B)}],[\\hat{\\theta}_T^{(C)}, P_T^{(C)}],[\\hat{\\theta}_T^{(D)}, P_T^{(D)}]]$,\nprinted as a single line.\n\nAngle units do not apply. Percentages must be expressed as decimals, not with a percentage sign. There are no physical units in this problem.", "solution": "The problem requires the implementation of a Kalman filter, a recursive algorithm for estimating the hidden state of a linear dynamical system from a series of noisy measurements. The system models a basketball player's shooting ability, $\\theta_t$, as a latent state that evolves over time.\n\nFirst, we formalize the problem within the framework of a linear Gaussian state-space model. The model consists of two equations: a state transition equation and an observation equation.\n\nThe state of the system is the player's shooting ability at time $t$, denoted by the scalar $\\theta_t$. The evolution of this state is described by an autoregressive process of order one, AR($1$), which is mean-reverting to a long-run mean $\\mu$.\n\nState Equation:\nThe hidden state dynamics are given by:\n$$ \\theta_t = \\mu + \\phi \\left(\\theta_{t-1} - \\mu\\right) + w_t $$\nThis can be rearranged into the standard linear form:\n$$ \\theta_t = \\phi \\theta_{t-1} + (1 - \\phi)\\mu + w_t $$\nwhere:\n- $\\theta_t$ is the state at time $t$.\n- $\\phi$ is the autoregressive coefficient, determining the persistence of the state. It is given as $\\phi=0.90$.\n- $\\mu$ is the long-run mean of the process, given as $\\mu=0.45$.\n- $w_t$ is the process noise, assumed to be a white noise process with $w_t \\sim \\mathcal{N}(0, q)$, where $q$ is the state innovation variance, given as $q=0.0005$.\n\nObservation Equation:\nThe observation at time $t$ is the player's observed shooting percentage, $y_t = m_t / n_t$, where $m_t$ is the number of made shots out of $n_t$ attempts. This observation is available only when $n_t  0$. The observation is modeled as a noisy measurement of the true underlying ability $\\theta_t$.\n$$ y_t = \\theta_t + v_t $$\nwhere:\n- $y_t$ is the observation at time $t$.\n- $v_t$ is the measurement noise, assumed to be a white noise process with $v_t \\sim \\mathcal{N}(0, R_t)$. The variance $R_t$ is time-dependent.\n\nThe measurement noise variance $R_t$ is approximated based on the variance of a sample proportion from a binomial distribution. Given $n_t$ trials, the variance of the sample proportion $y_t$ is approximately $p(1-p)/n_t$. The problem specifies using a fixed reference probability $\\bar{p}=0.45$ for this calculation:\n$$ R_t = \\frac{\\bar{p}(1 - \\bar{p})}{n_t} = \\frac{0.45(1 - 0.45)}{n_t} = \\frac{0.2475}{n_t} $$\nThis formulation makes $R_t$ time-varying, as it depends on the number of shot attempts $n_t$ in each game. When $n_t$ is large, $R_t$ is small, reflecting higher confidence in the observation.\n\nThe Kalman filter provides a recursive solution for estimating the posterior distribution of the state, $p(\\theta_t | y_{1:t})$. Since the model is linear and Gaussian, this posterior distribution is also Gaussian and can be fully characterized by its mean $\\hat{\\theta}_{t|t}$ and variance $P_{t|t}$.\n\nThe filtering process starts with a prior distribution for the initial state $\\theta_0 \\sim \\mathcal{N}(m_0, P_0)$, with given parameters $m_0 = 0.45$ and $P_0 = 0.01$. At each time step $t=1, 2, \\dots, T$, the algorithm performs two steps: a prediction step and an update step.\n\nLet the filtered posterior at time $t-1$ be $\\mathcal{N}(\\hat{\\theta}_{t-1|t-1}, P_{t-1|t-1})$.\n\nStep 1: Prediction (Time Update)\nIn this step, we predict the distribution of the state at time $t$ based on all information up to time $t-1$. The predicted (a priori) mean $\\hat{\\theta}_{t|t-1}$ and variance $P_{t|t-1}$ are computed.\n\nTaking the expectation of the state equation:\n$$ \\hat{\\theta}_{t|t-1} = \\mathbb{E}[\\phi \\theta_{t-1} + (1 - \\phi)\\mu + w_t | y_{1:t-1}] = \\phi \\hat{\\theta}_{t-1|t-1} + (1 - \\phi)\\mu $$\nThe variance of the prediction error is:\n$$ P_{t|t-1} = \\text{Var}(\\theta_t - \\hat{\\theta}_{t|t-1}) = \\text{Var}(\\phi(\\theta_{t-1} - \\hat{\\theta}_{t-1|t-1}) + w_t) $$\nSince the error $(\\theta_{t-1} - \\hat{\\theta}_{t-1|t-1})$ is uncorrelated with the process noise $w_t$, the variances add:\n$$ P_{t|t-1} = \\phi^2 \\text{Var}(\\theta_{t-1} - \\hat{\\theta}_{t-1|t-1}) + \\text{Var}(w_t) = \\phi^2 P_{t-1|t-1} + q $$\n\nStep 2: Update (Measurement Update)\nThis step refines the prediction using the new observation $y_t$ at time $t$. This is only performed if an observation is available (i.e., $n_t  0$).\n\nFirst, we compute the innovation, which is the discrepancy between the actual observation $y_t$ and its prediction:\n$$ \\tilde{y}_t = y_t - \\mathbb{E}[y_t | y_{1:t-1}] = y_t - \\mathbb{E}[\\theta_t + v_t | y_{1:t-1}] = y_t - \\hat{\\theta}_{t|t-1} $$\nThe variance of the innovation, or innovation covariance, is:\n$$ S_t = \\text{Var}(\\tilde{y}_t) = \\text{Var}((\\theta_t - \\hat{\\theta}_{t|t-1}) + v_t) = P_{t|t-1} + R_t $$\nThe optimal Kalman gain $K_t$ determines how much the prediction is adjusted based on the innovation. It is calculated to minimize the posterior error variance:\n$$ K_t = \\frac{\\text{Cov}(\\theta_t, \\tilde{y}_t)}{\\text{Var}(\\tilde{y}_t)} = \\frac{\\text{Cov}(\\theta_t, \\theta_t - \\hat{\\theta}_{t|t-1} + v_t)}{S_t} = \\frac{P_{t|t-1}}{S_t} = \\frac{P_{t|t-1}}{P_{t|t-1} + R_t} $$\nThe updated (a posteriori) state mean is a weighted average of the predicted mean and the observation:\n$$ \\hat{\\theta}_{t|t} = \\hat{\\theta}_{t|t-1} + K_t \\tilde{y}_t = \\hat{\\theta}_{t|t-1} + K_t (y_t - \\hat{\\theta}_{t|t-1}) $$\nThe updated (a posteriori) error variance is:\n$$ P_{t|t} = (1 - K_t) P_{t|t-1} $$\n\nHandling Missing Observations:\nIf $n_t = 0$, the observation $y_t$ is missing. In this scenario, no update can be performed. The best estimate for the state at time $t$ is simply the prediction from the previous step. Therefore, the posterior for time $t$ is set equal to the prior:\n$$ \\hat{\\theta}_{t|t} = \\hat{\\theta}_{t|t-1} $$\n$$ P_{t|t} = P_{t|t-1} $$\n\nThe overall algorithm is implemented for each test case as follows:\n1. Initialize the filter with the prior mean $\\hat{\\theta}_{0|0} = m_0 = 0.45$ and variance $P_{0|0} = P_0 = 0.01$.\n2. For each time step $t=1, \\dots, T$:\n   a. Perform the prediction step to compute $\\hat{\\theta}_{t|t-1}$ and $P_{t|t-1}$.\n   b. Check if $n_t  0$:\n      i. If true, calculate $y_t = m_t / n_t$ and $R_t = \\bar{p}(1-\\bar{p}) / n_t$. Perform the update step to compute $\\hat{\\theta}_{t|t}$ and $P_{t|t}$.\n      ii. If false, skip the update and set $\\hat{\\theta}_{t|t} = \\hat{\\theta}_{t|t-1}$ and $P_{t|t} = P_{t|t-1}$.\n3. The final values $\\hat{\\theta}_{T|T}$ and $P_{T|T}$ after processing the entire sequence are the desired outputs for each test case.", "answer": "```python\nimport numpy as np\n\ndef run_kalman_filter(data, mu, phi, q, p_bar, m0, P0):\n    \"\"\"\n    Implements the Kalman filter for the given state-space model.\n\n    Args:\n        data (list of tuples): A sequence of (m_t, n_t) pairs.\n        mu (float): Long-run mean of the state process.\n        phi (float): Autoregressive coefficient of the state process.\n        q (float): State innovation variance.\n        p_bar (float): Reference probability for observation variance.\n        m0 (float): Prior mean of the initial state.\n        P0 (float): Prior variance of the initial state.\n\n    Returns:\n        tuple: A tuple containing the final filtered posterior mean and variance.\n    \"\"\"\n    # Initialize the filtered state mean and variance with the prior\n    theta_filt = m0\n    P_filt = P0\n    \n    # Pre-calculate the numerator for the observation variance R_t\n    obs_var_numerator = p_bar * (1.0 - p_bar)\n\n    # Iterate through each time step (game)\n    for m_t, n_t in data:\n        # --- 1. Prediction Step ---\n        # Predict the next state mean\n        theta_pred = phi * theta_filt + mu * (1.0 - phi)\n        # Predict the next state variance\n        P_pred = phi**2 * P_filt + q\n\n        # --- 2. Update Step ---\n        # Check if there is an observation (n_t  0)\n        if n_t  0:\n            # Calculate the observation y_t\n            y_t = m_t / n_t\n            # Calculate the time-varying observation variance R_t\n            R_t = obs_var_numerator / n_t\n            \n            # Calculate the innovation covariance S_t\n            S_t = P_pred + R_t\n            \n            # Calculate the optimal Kalman gain K_t\n            K_t = P_pred / S_t\n            \n            # Update the state mean\n            theta_filt = theta_pred + K_t * (y_t - theta_pred)\n            \n            # Update the state variance\n            P_filt = (1.0 - K_t) * P_pred\n        else:\n            # If observation is missing (n_t = 0), the posterior is the prior\n            theta_filt = theta_pred\n            P_filt = P_pred\n            \n    return theta_filt, P_filt\n\ndef solve():\n    \"\"\"\n    Main function to define parameters, run test cases, and print results.\n    \"\"\"\n    # Fixed model parameters\n    mu = 0.45\n    phi = 0.90\n    q = 0.0005\n    p_bar = 0.45\n    \n    # Prior for the initial state\n    m0 = 0.45\n    P0 = 0.01\n\n    # Define the test cases from the problem statement\n    test_cases = [\n        # Test case A\n        [(5, 11), (4, 10), (7, 12), (6, 14), (2, 6), (8, 15), (3, 8), (6, 12), (7, 16), (5, 9)],\n        # Test case B\n        [(9, 20), (10, 22), (8, 18), (11, 24), (12, 25), (9, 19), (10, 21), (12, 26), (11, 24), (13, 28)],\n        # Test case C\n        [(0, 0), (3, 5), (0, 0), (4, 4), (0, 0), (2, 10), (0, 0), (5, 10)],\n        # Test case D\n        [(1, 2), (0, 5), (7, 10), (1, 12), (9, 10), (0, 3), (6, 15), (2, 2), (0, 8), (10, 12)]\n    ]\n\n    results = []\n    # Process each test case\n    for data in test_cases:\n        theta_T, P_T = run_kalman_filter(data, mu, phi, q, p_bar, m0, P0)\n        # Format the result for the current test case as a string\n        # with values rounded to six decimal places, enclosed in brackets.\n        results.append(f\"[{theta_T:.6f}, {P_T:.6f}]\")\n\n    # Final print statement in the exact required format.\n    # The output is a single line: a list of lists.\n    print(f\"[{','.join(results)}]\")\n\n# Execute the main function\nsolve()\n```", "id": "2389012"}, {"introduction": "Having practiced building and filtering models, we now delve into the fundamental structure of stochastic processes. The Doob-Meyer decomposition theorem offers a profound insight: any suitable process can be uniquely split into a predictable component (its 'drift') and an unpredictable martingale component (a 'pure game of chance'). In this final exercise [@problem_id:2388954], you will make this abstract theory concrete by numerically performing the decomposition on a standard autoregressive process, revealing the hidden structure that governs its evolution.", "problem": "You are given a discrete-time, real-valued, adapted process defined by an Autoregressive of order 1 (AR(1)) model. For each test case, the process is specified by parameters $\\mu$, $\\phi$, $\\sigma$, an initial value $X_0$, and a time horizon $T$. The dynamics are\n$$\nX_t \\;=\\; \\mu \\;+\\; \\phi\\,X_{t-1} \\;+\\; \\varepsilon_t,\\quad t=1,2,\\dots,T,\n$$\nwhere $\\{\\varepsilon_t\\}_{t\\ge 1}$ are independent and identically distributed Gaussian innovations with $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$, and the filtration is the natural filtration $\\mathcal{F}_t=\\sigma(X_0,\\varepsilon_1,\\dots,\\varepsilon_t)$.\n\nFor each test case:\n- Simulate one sample path $\\{X_t\\}_{t=0}^T$ with the specified parameters using the given random seed to initialize your pseudo-random number generator. Draw $\\varepsilon_t$ as independent Gaussian random variables with mean $0$ and standard deviation $\\sigma$.\n- Numerically compute the discrete-time Doob–Meyer (Doob) decomposition of $\\{X_t\\}$ into processes $\\{M_t\\}$ and $\\{A_t\\}$ such that\n$$\nX_t \\;=\\; X_0 \\;+\\; M_t \\;+\\; A_t,\\quad M_0=0,\\;A_0=0,\n$$\nwith $\\{M_t\\}$ a martingale with respect to $\\{\\mathcal{F}_t\\}$ and $\\{A_t\\}$ predictable with respect to $\\{\\mathcal{F}_t\\}$.\n- Report the pair of terminal values $[A_T, M_T]$ for that test case.\n\nTest suite:\n- Case 1 (general non-martingale): $\\mu=0.5$, $\\phi=0.8$, $\\sigma=1.0$, $X_0=0.7$, $T=12$, seed $=314159$.\n- Case 2 (martingale boundary): $\\mu=0.0$, $\\phi=1.0$, $\\sigma=0.8$, $X_0=1.2$, $T=10$, seed $=271828$.\n- Case 3 (deterministic edge): $\\mu=0.1$, $\\phi=0.9$, $\\sigma=0.0$, $X_0=-0.3$, $T=15$, seed $=42$.\n- Case 4 (unit root with drift): $\\mu=-0.2$, $\\phi=1.0$, $\\sigma=0.5$, $X_0=0.0$, $T=8$, seed $=7$.\n\nYour program must:\n- For each case, simulate exactly one path using the provided seed.\n- Compute terminal values $A_T$ and $M_T$ consistent with the discrete-time Doob decomposition definition with respect to the natural filtration.\n- Round each reported number to six decimal places.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element must be the two-element list $[A_T, M_T]$ for a test case, in the same order as above. For example, the overall output should look like\n`[[a1,m1],[a2,m2],[a3,m3],[a4,m4]]`\nbut with each $a_i$ and $m_i$ replaced by the corresponding rounded numeric values.", "solution": "The problem requires the numerical implementation of the discrete-time Doob-Meyer decomposition for an AR(1) process. The theorem states that any adapted process $\\{X_t\\}$ can be uniquely decomposed as $X_t = X_0 + M_t + A_t$, where $\\{M_t\\}$ is a martingale and $\\{A_t\\}$ is a predictable process, with initial conditions $M_0 = A_0 = 0$.\n\nThe decomposition is constructed from the process increments. The increment of the predictable component, $\\Delta A_t = A_t - A_{t-1}$, is defined as the conditional expectation of the process increment, given the past:\n$$\n\\Delta A_t = \\mathbb{E}[X_t - X_{t-1} | \\mathcal{F}_{t-1}]\n$$\nFor the given AR(1) process, $X_t = \\mu + \\phi X_{t-1} + \\varepsilon_t$, the process increment is $\\Delta X_t = \\mu + (\\phi - 1)X_{t-1} + \\varepsilon_t$.\nSince $X_{t-1}$ is known at time $t-1$ (i.e., it is $\\mathcal{F}_{t-1}$-measurable) and the innovation $\\varepsilon_t$ is independent of the past with $\\mathbb{E}[\\varepsilon_t] = 0$, the conditional expectation simplifies to:\n$$\n\\Delta A_t = \\mathbb{E}[\\mu + (\\phi - 1)X_{t-1} + \\varepsilon_t | \\mathcal{F}_{t-1}] = \\mu + (\\phi - 1)X_{t-1}\n$$\nThe increment of the martingale component, $\\Delta M_t = M_t - M_{t-1}$, is the remaining \"unpredictable\" part of the process increment:\n$$\n\\Delta M_t = (X_t - X_{t-1}) - \\Delta A_t = (\\mu + (\\phi - 1)X_{t-1} + \\varepsilon_t) - (\\mu + (\\phi - 1)X_{t-1}) = \\varepsilon_t\n$$\nThus, the martingale component is simply the accumulation of the innovations.\n\nThe terminal values $A_T$ and $M_T$ are found by summing these increments over the time horizon:\n$$\nA_T = \\sum_{t=1}^T \\Delta A_t = \\sum_{t=1}^T (\\mu + (\\phi - 1)X_{t-1})\n$$\n$$\nM_T = \\sum_{t=1}^T \\Delta M_t = \\sum_{t=1}^T \\varepsilon_t\n$$\nThe algorithm first simulates a single path $\\{X_t\\}_{t=0}^T$ using the given parameters and random seed. During the simulation, at each step $t$, it calculates the predictable increment $\\Delta A_t$ using the value of $X_{t-1}$ and adds it to a running total for $A_T$. The martingale component $M_T$ is simply the sum of all generated innovations $\\{\\varepsilon_t\\}_{t=1}^T$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Simulates AR(1) processes and computes the terminal values of their\n    Doob-Meyer decomposition components.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'mu': 0.5, 'phi': 0.8, 'sigma': 1.0, 'X0': 0.7, 'T': 12, 'seed': 314159},\n        {'mu': 0.0, 'phi': 1.0, 'sigma': 0.8, 'X0': 1.2, 'T': 10, 'seed': 271828},\n        {'mu': 0.1, 'phi': 0.9, 'sigma': 0.0, 'X0': -0.3, 'T': 15, 'seed': 42},\n        {'mu': -0.2, 'phi': 1.0, 'sigma': 0.5, 'X0': 0.0, 'T': 8, 'seed': 7},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        mu = case['mu']\n        phi = case['phi']\n        sigma = case['sigma']\n        X0 = case['X0']\n        T = case['T']\n        seed = case['seed']\n\n        # 1. Initialize RNG and generate all innovations\n        rng = np.random.default_rng(seed)\n        epsilons = rng.normal(loc=0.0, scale=sigma, size=T)\n\n        # 2. Initialize path array and terminal value accumulators\n        x_path = np.zeros(T + 1)\n        x_path[0] = X0\n        \n        A_T = 0.0\n\n        # 3. Simulate the path and compute the predictable component A_T\n        # The martingale component M_T is simply the sum of all innovations.\n        for t in range(1, T + 1):\n            # The t-th innovation corresponds to index t-1 in the epsilons array\n            epsilon_t = epsilons[t - 1]\n            x_prev = x_path[t - 1]\n            \n            # Update the process\n            x_path[t] = mu + phi * x_prev + epsilon_t\n            \n            # Increment for the predictable part A_t\n            # delta_A_t = E[X_t - X_{t-1} | F_{t-1}] = mu + (phi - 1) * X_{t-1}\n            delta_A_t = mu + (phi - 1) * x_prev\n            A_T += delta_A_t\n\n        # The martingale part M_T is the sum of innovations\n        M_T = np.sum(epsilons)\n        \n        # 4. Round to six decimal places as required\n        A_T_rounded = round(A_T, 6)\n        M_T_rounded = round(M_T, 6)\n        \n        results.append([A_T_rounded, M_T_rounded])\n\n    # 5. Format the final output string as a compact list of lists\n    # Each sublist [a, m] is formatted to ensure fixed precision and no spaces\n    string_parts = []\n    for res_pair in results:\n        a_str = f\"{res_pair[0]:.6f}\"\n        m_str = f\"{res_pair[1]:.6f}\"\n        string_parts.append(f\"[{a_str},{m_str}]\")\n        \n    final_output = f\"[{','.join(string_parts)}]\"\n\n    print(final_output)\n\nsolve()\n```", "id": "2388954"}]}