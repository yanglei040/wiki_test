{"hands_on_practices": [{"introduction": "Standard Gaussian quadrature rules are defined for specific intervals and weight functions, such as the Gauss-Legendre rule on $[-1, 1]$. However, many problems in finance require calculating expectations over arbitrary probability distributions. This practice [@problem_id:2396760] provides a crucial hands-on opportunity to master the change-of-variable technique, specifically using the inverse cumulative distribution function (or quantile function) to transform a standard quadrature rule to accurately compute expectations involving a lognormal random variable, a cornerstone of asset price modeling.", "problem": "Consider a strictly positive random variable $X$ defined by $X=\\exp(\\mu+\\sigma Z)$ where $Z$ is a standard normal random variable, $\\mu\\in\\mathbb{R}$, and $\\sigma > 0$. For a measurable function $g:\\mathbb{R}_{+}\\to\\mathbb{R}$, the expectation $\\mathbb{E}[g(X)]$ is given by $\\int_{0}^{\\infty} g(x) f_{X}(x)\\,\\mathrm{d}x$, where $f_{X}$ is the probability density function of the lognormal distribution induced by $(\\mu,\\sigma)$. Your task is to construct a numerical quadrature rule for $\\mathbb{E}[g(X)]$ by transforming a standard Gauss–Legendre quadrature rule on the interval $[-1,1]$ into a rule that integrates with respect to the law of $X$, in a manner that incorporates the change of measure into the transformed nodes and weights.\n\nThe program you write must compute the numerical approximations of $\\mathbb{E}[g(X)]$ for each of the following test cases, using exactly $n=96$ nodes from a standard Gauss–Legendre quadrature rule on $[-1,1]$:\n\n- Test case $1$: $\\mu=0$, $\\sigma=0.25$, $g(x)=x$.\n- Test case $2$: $\\mu=0.1$, $\\sigma=0.5$, $g(x)=x^{2}$.\n- Test case $3$: $\\mu=-0.2$, $\\sigma=0.3$, $g(x)=\\ln(x)$.\n- Test case $4$: $\\mu=0.05$, $\\sigma=0.6$, $g(x)=\\max(x-K,0)$ with $K=\\exp(\\mu)$.\n- Test case $5$: $\\mu=0$, $\\sigma=10^{-6}$, $g(x)=x$.\n\nAll angles, if any, must be in radians. There are no physical units involved in this problem. For numerical reporting, each approximation must be rounded to $12$ decimal places.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The order must follow the test cases above, so the required format is\n$[\\text{result}_{1},\\text{result}_{2},\\text{result}_{3},\\text{result}_{4},\\text{result}_{5}]$,\nwith each $\\text{result}_{i}$ a floating-point number rounded to $12$ decimal places. No additional text or formatting should be printed.", "solution": "The problem as stated is valid. It is scientifically grounded in the theory of mathematical finance and numerical analysis, specifically concerning the expectation of a function of a log-normally distributed random variable and its computation via Gaussian quadrature. The problem is well-posed, objective, and contains all necessary information to derive a unique solution. We will proceed.\n\nThe objective is to compute the expectation $\\mathbb{E}[g(X)]$ where the random variable $X$ follows a lognormal distribution, defined as $X = \\exp(\\mu + \\sigma Z)$ with $Z$ being a standard normal random variable, $Z \\sim N(0,1)$. The expectation is given by the integral:\n$$ \\mathbb{E}[g(X)] = \\int_{0}^{\\infty} g(x) f_X(x) \\,dx $$\nwhere $f_X(x)$ is the probability density function (PDF) of the lognormal distribution. A more direct path for numerical evaluation is to express the expectation in terms of the underlying standard normal variable $Z$. The expectation of a function of a random variable is defined as:\n$$ \\mathbb{E}[h(Z)] = \\int_{-\\infty}^{\\infty} h(z) f_Z(z) \\,dz $$\nwhere $f_Z(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-z^2/2)$ is the standard normal PDF.\nSubstituting $X = \\exp(\\mu + \\sigma Z)$ into $\\mathbb{E}[g(X)]$, we get:\n$$ \\mathbb{E}[g(X)] = \\mathbb{E}[g(\\exp(\\mu + \\sigma Z))] = \\int_{-\\infty}^{\\infty} g(\\exp(\\mu + \\sigma z)) \\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2} \\,dz $$\nThis integral is over an infinite domain $(-\\infty, \\infty)$. The problem requires its approximation using a standard Gauss-Legendre quadrature rule, which is defined on the finite interval $[-1, 1]$. To use this rule, we must transform the variable of integration to this interval.\n\nA standard and robust technique is the inverse transform sampling method, also known as the quantile function method. Let $\\Phi(z)$ be the cumulative distribution function (CDF) of the standard normal distribution. We perform a change of variable $u = \\Phi(z)$. This transformation maps the domain $z \\in (-\\infty, \\infty)$ to $u \\in (0, 1)$. The inverse transformation is $z = \\Phi^{-1}(u)$, where $\\Phi^{-1}$ is the quantile function (or probit function) of the standard normal distribution. The differential is given by $du = \\Phi'(z) dz = \\phi(z) dz = \\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2} dz$.\n\nSubstituting these into the expectation integral yields:\n$$ \\mathbb{E}[g(X)] = \\int_{0}^{1} g(\\exp(\\mu + \\sigma \\Phi^{-1}(u))) \\,du $$\nThe integral is now over the finite interval $(0, 1)$. To apply the Gauss-Legendre quadrature rule on $[-1, 1]$, we perform a final linear transformation of the integration variable. Let $u = \\frac{t+1}{2}$, which maps $t \\in [-1, 1]$ to $u \\in [0, 1]$. The differential is $du = \\frac{1}{2} dt$. The integral becomes:\n$$ \\mathbb{E}[g(X)] = \\int_{-1}^{1} g\\left(\\exp\\left(\\mu + \\sigma \\Phi^{-1}\\left(\\frac{t+1}{2}\\right)\\right)\\right) \\frac{1}{2} \\,dt $$\nThis integral is now in the canonical form $\\int_{-1}^{1} F(t) dt$ suitable for Gauss-Legendre quadrature, where the integrand is\n$$ F(t) = \\frac{1}{2} g\\left(\\exp\\left(\\mu + \\sigma \\Phi^{-1}\\left(\\frac{t+1}{2}\\right)\\right)\\right) $$\nThe $n$-point Gauss-Legendre quadrature approximation for an integral $\\int_{-1}^{1} F(t) dt$ is given by $\\sum_{i=1}^{n} w_i F(t_i)$, where $\\{t_i\\}_{i=1}^n$ are the nodes (roots of the $n$-th Legendre polynomial) and $\\{w_i\\}_{i=1}^n$ are the corresponding weights.\nTherefore, the numerical approximation for $\\mathbb{E}[g(X)]$ is:\n$$ \\mathbb{E}[g(X)] \\approx \\sum_{i=1}^{n} w_i \\left[ \\frac{1}{2} g\\left(\\exp\\left(\\mu + \\sigma \\Phi^{-1}\\left(\\frac{t_i+1}{2}\\right)\\right)\\right) \\right] $$\nwhere $n=96$ as specified. The nodes $t_i$ and weights $w_i$ are obtained from standard numerical libraries. The quantile function $\\Phi^{-1}$ is also a standard special function.\n\nThis method constructs a quadrature rule as required. We can define transformed nodes $\\tilde{x}_i$ and transformed weights $\\tilde{w}_i$ for approximating $\\int_0^\\infty g(x) f_X(x) dx$ directly. Let the transformed nodes be $\\tilde{x}_i = \\exp\\left(\\mu + \\sigma \\Phi^{-1}\\left(\\frac{t_i+1}{2}\\right)\\right)$ and the corresponding weights be $\\tilde{w}_i = w_i/2$. The approximation is then $\\sum_{i=1}^{n} \\tilde{w}_i g(\\tilde{x}_i)$. This demonstrates how the change of measure is incorporated into the construction.\n\nThe procedure for computation is as follows:\n1.  Obtain the $n=96$ standard Gauss-Legendre nodes $t_i$ and weights $w_i$ for the interval $[-1, 1]$.\n2.  For each test case, specified by parameters $\\mu$, $\\sigma$, and function $g(x)$:\n3.  For each node $t_i$:\n    a. Transform the node to the uniform domain $[0, 1]$: $u_i = (t_i+1)/2$.\n    b. Compute the standard normal quantile: $z_i = \\Phi^{-1}(u_i)$.\n    c. Compute the value of the lognormal variable: $x_i = \\exp(\\mu + \\sigma z_i)$.\n    d. Evaluate the function: $g(x_i)$.\n4.  Calculate the final sum: $\\text{Result} = \\frac{1}{2} \\sum_{i=1}^{n} w_i g(x_i)$.\n5.  Round the result to $12$ decimal places.\n\nThis algorithm will be implemented for all specified test cases.\n\n- **Test case 1**: $\\mu=0$, $\\sigma=0.25$, $g(x)=x$. Analytical solution: $\\mathbb{E}[X] = \\exp(\\mu+\\sigma^2/2) = \\exp(0.03125) \\approx 1.031735515784$.\n- **Test case 2**: $\\mu=0.1$, $\\sigma=0.5$, $g(x)=x^2$. Analytical solution: $\\mathbb{E}[X^2] = \\exp(2\\mu+2\\sigma^2) = \\exp(0.7) \\approx 2.013752707470$.\n- **Test case 3**: $\\mu=-0.2$, $\\sigma=0.3$, $g(x)=\\ln(x)$. Analytical solution: $\\mathbb{E}[\\ln(X)] = \\mathbb{E}[\\mu+\\sigma Z] = \\mu = -0.2$.\n- **Test case 4**: $\\mu=0.05$, $\\sigma=0.6$, $g(x)=\\max(x-K,0)$ with $K=\\exp(\\mu)$. This resembles a European call option payout. The analytical value is $e^{\\mu+\\sigma^2/2}\\Phi(\\sigma) - K\\Phi(0) \\approx 0.387819650393$.\n- **Test case 5**: $\\mu=0$, $\\sigma=10^{-6}$, $g(x)=x$. This tests numerical stability for small $\\sigma$. The analytical solution is $\\mathbb{E}[X] = \\exp(0.5 \\times 10^{-12}) \\approx 1.0 + 0.5 \\times 10^{-12}$. Rounded to 12 decimal places, this is $1.000000000001$.\n\nThe implementation will use `numpy` for vectorized calculations and `scipy.special` for `roots_legendre` and the inverse normal CDF `ndtri`.", "answer": "```python\nimport numpy as np\nfrom scipy.special import roots_legendre, ndtri\n\ndef solve():\n    \"\"\"\n    Computes numerical approximations of E[g(X)] for a lognormal variable X\n    using a transformed Gauss-Legendre quadrature rule.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each tuple contains: (mu, sigma, g_function, K)\n    # K is None if not applicable.\n    test_cases = [\n        (0.0, 0.25, lambda x, k: x, None),\n        (0.1, 0.5, lambda x, k: x**2, None),\n        (-0.2, 0.3, lambda x, k: np.log(x), None),\n        (0.05, 0.6, lambda x, k: np.maximum(x - k, 0), 'exp_mu'),\n        (0.0, 1e-6, lambda x, k: x, None)\n    ]\n    \n    n = 96  # Number of quadrature nodes as specified\n\n    # Get standard Gauss-Legendre nodes and weights for the interval [-1, 1]\n    t_nodes, l_weights = roots_legendre(n)\n\n    results = []\n    \n    for case in test_cases:\n        mu, sigma, g_func, k_spec = case\n        \n        # Determine the value of K if specified\n        K = None\n        if k_spec == 'exp_mu':\n            K = np.exp(mu)\n\n        # Vectorized calculation of the quadrature sum\n        # 1. Transform nodes from [-1, 1] to [0, 1] for CDF argument\n        u_nodes = (t_nodes + 1) / 2.0\n        \n        # 2. Compute standard normal quantiles (probit function)\n        # Add small epsilon to avoid u=0 or u=1 which result in inf\n        epsilon = 1e-16\n        u_nodes = np.clip(u_nodes, epsilon, 1 - epsilon)\n        z_nodes = ndtri(u_nodes)\n        \n        # 3. Compute the values of the lognormal variable at the transformed nodes\n        x_values = np.exp(mu + sigma * z_nodes)\n        \n        # 4. Evaluate the function g(x) for all x values\n        g_values = g_func(x_values, K)\n        \n        # 5. Compute the integral approximation using the quadrature rule\n        # The integral is transformed to 1/2 * integral on [-1, 1] dt\n        integral_approx = 0.5 * np.sum(l_weights * g_values)\n        \n        results.append(integral_approx)\n\n    # Format the final output as specified\n    formatted_results = [f\"{r:.12f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2396760"}, {"introduction": "The remarkable speed and accuracy of Gaussian quadrature depend on the smoothness of the integrand. This assumption is often violated in financial engineering, where payoff functions frequently contain non-differentiable points or \"kinks\", such as those in options or absolute value-based claims, which can severely degrade numerical accuracy. This exercise [@problem_id:2396765] introduces a robust and widely-used strategy to overcome this challenge: piecewise Gaussian quadrature. By splitting the integration domain at the point of non-differentiability, you can restore the method's high-order accuracy and reliably value complex derivatives.", "problem": "You are asked to implement a robust numerical valuation of a contingent claim in a risk-neutral, lognormal asset-pricing environment using piecewise Gaussian quadrature to handle a non-differentiable payoff. Consider an underlying asset with initial level $S_0$, continuously compounded risk-free rate $r$, volatility $\\sigma$, and maturity $T$. Under the standard no-arbitrage assumptions of the Black–Scholes model, the time-$T$ asset price $S_T$ is lognormally distributed with\n- $S_T = S_0 \\exp\\left((r - \\tfrac{1}{2}\\sigma^2)T + \\sigma \\sqrt{T}\\, Z\\right)$,\n- $Z \\sim \\mathcal{N}(0,1)$ independently of $S_0$.\n\nLet the payoff be $f(S_T) = \\lvert S_T - K \\rvert^{1/2}$, where $K$ is a fixed strike level. The arbitrage-free value at time $t=0$ is the discounted risk-neutral expectation\n$$\nV(S_0,K,r,\\sigma,T) = e^{-rT}\\,\\mathbb{E}\\left[\\lvert S_T - K \\rvert^{1/2}\\right].\n$$\n\nYour task is to:\n- Start from the risk-neutral valuation principle and the lognormality of $S_T$ under the Black–Scholes assumptions. Formulate the expectation as an integral over the standard normal variable $Z$ with density $\\varphi(z)$, ensuring that the integral is well-posed for the non-differentiable point at $S_T = K$.\n- Identify the unique point $z^\\star$ (if it exists) where the non-differentiability arises in the integrand via the condition $S_T(z^\\star) = K$. Explain how this point partitions the integration domain on $z$.\n- Develop a piecewise Gaussian quadrature method based on Gauss–Legendre rules on a truncated symmetric interval $[-L,L]$ for the standard normal variable $Z$, splitting the interval at $z^\\star$. Use a mapping from the canonical Gauss–Legendre nodes on $[-1,1]$ to each subinterval. Your design must discuss the choice of truncation level $L$ to control the tail error contributed by $\\lvert S_T - K \\rvert^{1/2}$ outside $[-L,L]$.\n- Implement the numerical approximation\n$$\nV \\approx e^{-rT}\\int_{-L}^{L} \\lvert S_0 \\exp\\left((r - \\tfrac{1}{2}\\sigma^2)T + \\sigma \\sqrt{T}\\, z\\right) - K \\rvert^{1/2} \\, \\varphi(z)\\, dz,\n$$\nusing a piecewise Gauss–Legendre quadrature that splits the integral at $z^\\star$ whenever $z^\\star \\in (-L,L)$, and otherwise applies a single Gauss–Legendre quadrature on $[-L,L]$. Here, $\\varphi(z)$ denotes the standard normal density. You must implement the general mapping formula for Gauss–Legendre on an arbitrary finite interval $[a,b]$ starting from its nodes and weights on $[-1,1]$, and your program must handle the edge cases $\\sigma = 0$ and $T = 0$ correctly according to first principles.\n- The program must be entirely self-contained. Do not read any input. Use only the parameters specified below and print the required output.\n\nParameter conventions and units:\n- All rates and volatilities are to be treated as dimensionless decimals (for example, $r = 0.05$ means $0.05$ per year, not $5$ percent).\n- Angles are not present; do not use degrees or radians anywhere.\n- Monetary quantities are unitless in this problem; report values as pure numbers.\n\nYour implementation must use the following test suite. For each case, compute the approximate value $V$ using your piecewise Gauss–Legendre method with a truncation level $L = 8$, and with $n_{\\text{left}} = 64$ nodes on the left subinterval and $n_{\\text{right}} = 64$ nodes on the right subinterval (if a subinterval is empty due to the split lying outside $[-L,L]$, apply a single Gauss–Legendre rule with $n_{\\text{left}} + n_{\\text{right}}$ nodes on $[-L,L]$):\n\n- Case $1$: $(S_0, K, r, \\sigma, T) = (100, 100, 0.02, 0.2, 1)$.\n- Case $2$: $(S_0, K, r, \\sigma, T) = (100, 20, 0.01, 0.3, 1.5)$.\n- Case $3$: $(S_0, K, r, \\sigma, T) = (100, 100, 0.0, 0.25, 10^{-6})$.\n- Case $4$: $(S_0, K, r, \\sigma, T) = (80, 120, 0.03, 1.0, 2.0)$.\n- Case $5$: $(S_0, K, r, \\sigma, T) = (100, 100, 0.05, 0.05, 1.0)$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must be ordered according to the five cases above and each value must be rounded to exactly $10$ decimal places. For example, a valid output line would look like\n$[v_1,v_2,v_3,v_4,v_5]$\nwhere each $v_i$ is a floating-point number with exactly $10$ digits after the decimal point.", "solution": "The problem as stated is valid. It is a well-posed problem in computational finance, grounded in the standard Black-Scholes asset pricing model. The problem is objective, self-contained, and provides all necessary data and definitions for a unique numerical solution. The core task involves the valuation of a European contingent claim with a non-standard payoff function, $f(S_T) = \\lvert S_T - K \\rvert^{1/2}$, which introduces a non-differentiability. The prescribed numerical method, piecewise Gaussian quadrature, is an appropriate and standard technique for handling such integrands to ensure numerical accuracy. There are no scientific or logical contradictions.\n\nWe proceed with a complete solution based on first principles.\n\n**1. Integral Formulation of the Valuation Problem**\n\nThe arbitrage-free value $V$ of the contingent claim is the discounted risk-neutral expectation of its payoff:\n$$\nV = e^{-rT} \\mathbb{E}\\left[ f(S_T) \\right] = e^{-rT} \\mathbb{E}\\left[ \\lvert S_T - K \\rvert^{1/2} \\right]\n$$\nUnder the Black-Scholes model assumptions, the terminal asset price $S_T$ is given by\n$$\nS_T = S_0 \\exp\\left( (r - \\tfrac{1}{2}\\sigma^2)T + \\sigma \\sqrt{T} Z \\right)\n$$\nwhere $Z$ is a standard normal random variable, $Z \\sim \\mathcal{N}(0,1)$. The expectation can be written as an integral over the probability density function $\\varphi(z)$ of $Z$, where $\\varphi(z) = \\frac{1}{\\sqrt{2\\pi}}e^{-z^2/2}$. Let $h(z)$ be the integrand function of the variable $z$:\n$$\nh(z) = \\left| S_0 \\exp\\left((r - \\tfrac{1}{2}\\sigma^2)T + \\sigma \\sqrt{T} z\\right) - K \\right|^{1/2} \\varphi(z)\n$$\nThe value of the claim is then\n$$\nV = e^{-rT} \\int_{-\\infty}^{\\infty} h(z) dz\n$$\n\n**2. Analysis of the Integrand and Non-differentiability**\n\nThe function $h(z)$ is non-differentiable where the argument of the absolute value function is zero. This point corresponds to $S_T = K$. The function $g(x) = |x|^{1/2}$ has a derivative $g'(x) = \\frac{1}{2\\sqrt{|x|}}\\text{sgn}(x)$ which is undefined at $x=0$. This singularity in the derivative significantly degrades the convergence rate of standard numerical integration methods, such as Gaussian quadrature, if applied naively over the entire domain.\n\nTo locate this point in terms of the integration variable $z$, we set $S_T(z) = K$:\n$$\nS_0 \\exp\\left((r - \\tfrac{1}{2}\\sigma^2)T + \\sigma \\sqrt{T} z\\right) = K\n$$\nSolving for $z$, provided $\\sigma > 0$ and $T > 0$:\n$$\n(r - \\tfrac{1}{2}\\sigma^2)T + \\sigma \\sqrt{T} z = \\ln(K/S_0)\n$$\n$$\n\\sigma \\sqrt{T} z = \\ln(K/S_0) - (r - \\tfrac{1}{2}\\sigma^2)T\n$$\nThis gives a unique point of non-differentiability, which we denote as $z^\\star$:\n$$\nz^\\star = \\frac{\\ln(K/S_0) - (r - \\tfrac{1}{2}\\sigma^2)T}{\\sigma \\sqrt{T}}\n$$\nThis expression is equivalent to $-d_2$ in the standard Black-Scholes option pricing formula. For the problem to be non-trivial, we assume $S_0 > 0$ and $K > 0$.\n\n**3. Piecewise Gaussian Quadrature Method**\n\nTo obtain an accurate numerical approximation of the integral, we employ a two-step strategy: domain truncation and piecewise quadrature.\n\nFirst, we truncate the infinite integration domain $(-\\infty, \\infty)$ to a finite, symmetric interval $[-L, L]$. The standard normal density $\\varphi(z)$ decays very rapidly as $|z| \\to \\infty$. The choice of $L=8$ as specified in the problem ensures that the neglected probability mass in the tails is of the order of $2\\Phi(-8) \\approx 1.24 \\times 10^{-15}$, which is negligible for most financial applications. The value of the claim is thus approximated by:\n$$\nV \\approx e^{-rT} \\int_{-L}^{L} h(z) dz\n$$\n\nSecond, to address the non-differentiability at $z^\\star$, we partition the integration interval $[-L, L]$ at this point. If $z^\\star \\in (-L, L)$, the integral is split into two parts:\n$$\n\\int_{-L}^{L} h(z) dz = \\int_{-L}^{z^\\star} h(z) dz + \\int_{z^\\star}^{L} h(z) dz\n$$\nOn each subinterval, $[-L, z^\\star]$ and $[z^\\star, L]$, the integrand is infinitely differentiable. This smoothness allows Gauss-Legendre quadrature to achieve its characteristic exponential convergence rate.\n\nIf $z^\\star \\notin (-L, L)$, the integrand is smooth over the entire interval $[-L, L]$, and a single Gauss-Legendre quadrature rule can be applied over the full interval.\n\nThe Gauss-Legendre quadrature approximates an integral over the canonical interval $[-1,1]$ as a weighted sum:\n$$\n\\int_{-1}^{1} f(x) dx \\approx \\sum_{i=1}^{n} w_i f(x_i)\n$$\nwhere $x_i$ are the nodes (roots of the $n$-th Legendre polynomial) and $w_i$ are the corresponding weights. To apply this to a generic interval $[a,b]$, we use the linear transformation $z(x) = \\frac{b-a}{2} x + \\frac{a+b}{2}$, with Jacobian $dz/dx = \\frac{b-a}{2}$. The integral becomes:\n$$\n\\int_{a}^{b} h(z) dz = \\int_{-1}^{1} h\\left(\\frac{b-a}{2}x + \\frac{a+b}{2}\\right) \\frac{b-a}{2} dx \\approx \\frac{b-a}{2} \\sum_{i=1}^{n} w_i h\\left(\\frac{b-a}{2}x_i + \\frac{a+b}{2}\\right)\n$$\nThis formula is applied to each subinterval with the specified number of nodes ($n_{\\text{left}}=64$ and $n_{\\text{right}}=64$).\n\n**4. Handling of Degenerate Cases**\n\nThe problem requires handling the cases where $\\sigma=0$ or $T=0$. In either situation, the stochastic term $\\sigma\\sqrt{T}Z$ vanishes. The terminal asset price $S_T$ becomes deterministic:\n$$\nS_T = S_0 \\exp(rT)\n$$\nThe valuation integral collapses as the expectation becomes trivial:\n$$\n\\mathbb{E}\\left[ \\lvert S_T - K \\rvert^{1/2} \\right] = \\lvert S_0 e^{rT} - K \\rvert^{1/2}\n$$\nThe value of the claim is then given by the simple closed-form expression:\n$$\nV = e^{-rT} \\lvert S_0 e^{rT} - K \\rvert^{1/2}\n$$\nOur implementation must correctly identify these cases and apply this formula, bypassing the numerical integration.\n\n**5. Algorithm Summary**\n\nFor a given set of parameters $(S_0, K, r, \\sigma, T)$:\n1. Check for degenerate cases: if $T \\approx 0$ or $\\sigma \\approx 0$, calculate $V$ using the deterministic formula.\n2. Otherwise, define the full integrand $h(z) = \\left| S_T(z) - K \\right|^{1/2} \\varphi(z)$.\n3. Calculate the split point $z^\\star$.\n4. Set truncation level $L=8$.\n5. If $z^\\star \\in (-L, L)$:\n    a. Apply Gauss-Legendre quadrature with $n_{\\text{left}}=64$ nodes on $[-L, z^\\star]$.\n    b. Apply Gauss-Legendre quadrature with $n_{\\text{right}}=64$ nodes on $[z^\\star, L]$.\n    c. The total integral is the sum of the results from (a) and (b).\n6. If $z^\\star \\notin (-L, L)$:\n    a. Apply Gauss-Legendre quadrature with $n=n_{\\text{left}} + n_{\\text{right}} = 128$ nodes on the single interval $[-L, L]$.\n7. The final value is $V = e^{-rT} \\times (\\text{total integral})$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import roots_legendre\n\ndef solve():\n    \"\"\"\n    Computes the value of a contingent claim with a non-differentiable payoff\n    using piecewise Gaussian quadrature, as specified in the problem statement.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        (100, 100, 0.02, 0.2, 1.0),\n        (100, 20, 0.01, 0.3, 1.5),\n        (100, 100, 0.0, 0.25, 1e-6),\n        (80, 120, 0.03, 1.0, 2.0),\n        (100, 100, 0.05, 0.05, 1.0),\n    ]\n\n    L = 8.0\n    n_left = 64\n    n_right = 64\n    \n    results = []\n\n    def gauss_legendre_quad(func, a, b, n):\n        \"\"\"\n        Performs Gauss-Legendre quadrature of a function 'func' over [a, b] using 'n' nodes.\n        Handles the case where a = b, returning 0.\n        \"\"\"\n        if np.isclose(a, b):\n            return 0.0\n        \n        nodes, weights = roots_legendre(n)\n        \n        # Map nodes from [-1, 1] to [a, b]\n        mapped_nodes = 0.5 * (b - a) * nodes + 0.5 * (a + b)\n        \n        # Evaluate the function at the mapped nodes\n        func_values = func(mapped_nodes)\n        \n        # Calculate the integral using the quadrature formula\n        integral = 0.5 * (b - a) * np.sum(weights * func_values)\n        \n        return integral\n\n    for case in test_cases:\n        S0, K, r, sigma, T = case\n\n        # Handle degenerate cases: deterministic asset price\n        if np.isclose(T, 0.0) or np.isclose(sigma, 0.0):\n            S_T = S0 * np.exp(r * T)\n            payoff = np.sqrt(np.abs(S_T - K))\n            value = np.exp(-r * T) * payoff\n            results.append(value)\n            continue\n            \n        # Define the integrand h(z) = |S_T(z) - K|^(1/2) * phi(z)\n        # where phi(z) is the standard normal PDF.\n        sqrt_T = np.sqrt(T)\n        drift = (r - 0.5 * sigma**2) * T\n        def integrand(z):\n            S_T = S0 * np.exp(drift + sigma * sqrt_T * z)\n            payoff_sqrt = np.sqrt(np.abs(S_T - K))\n            phi_z = (1.0 / np.sqrt(2.0 * np.pi)) * np.exp(-0.5 * z**2)\n            return payoff_sqrt * phi_z\n\n        # Find the non-differentiable point z_star\n        # where S_T(z_star) = K\n        #\n        # Note: We must ensure K/S0 > 0, which is true for all test cases.\n        # Catches potential warnings for log(0) if K is 0, though not in test data.\n        if K = 0 or S0 = 0:\n            # Fallback for ill-posed inputs not in test data\n            z_star = np.nan \n        else:\n            numerator = np.log(K / S0) - drift\n            denominator = sigma * sqrt_T\n            z_star = numerator / denominator\n\n        # Perform numerical integration\n        total_integral = 0.0\n        if -L  z_star  L:\n            # Piecewise quadrature: split at the singularity point\n            integral_left = gauss_legendre_quad(integrand, -L, z_star, n_left)\n            integral_right = gauss_legendre_quad(integrand, z_star, L, n_right)\n            total_integral = integral_left + integral_right\n        else:\n            # Singularity is outside the integration domain; use a single rule\n            total_integral = gauss_legendre_quad(integrand, -L, L, n_left + n_right)\n\n        # Discount the expected payoff to get the final value\n        value = np.exp(-r * T) * total_integral\n        results.append(value)\n\n    # Format the final output string as required\n    output_str = f\"[{','.join([f'{v:.10f}' for v in results])}]\"\n    print(output_str)\n\nsolve()\n```", "id": "2396765"}, {"introduction": "While standard quadrature families like Legendre and Hermite are powerful, their applicability is limited to classical weight functions. In practice, economists and financial analysts often work with empirical distributions derived from market data, which do not conform to these standard forms. This advanced practice [@problem_id:2396803] delves into the theoretical heart of numerical integration by guiding you through the construction of a custom Gaussian quadrature rule from first principles for an arbitrary discrete measure. By implementing the three-term recurrence for orthogonal polynomials and the Golub-Welsch algorithm, you will gain the ability to generate highly accurate, tailor-made integration schemes for any distribution you encounter.", "problem": "You are given a discrete proxy for the empirical distribution of daily log-returns of the Standard and Poor's $500$ (SP $500$) index. The proxy is a histogram summarized as a set of support points (bin centers) and corresponding probabilities that sum to $1$, representing a probability measure. Let the support points be the array $x \\in \\mathbb{R}^m$ and the corresponding strictly positive probabilities be the array $w \\in \\mathbb{R}_+^m$ with $\\sum_{i=1}^m w_i = 1$. In this problem, the arrays are fixed as\n- $x = [-0.04,\\,-0.03,\\,-0.02,\\,-0.01,\\,0.0,\\,0.01,\\,0.02,\\,0.03,\\,0.04]$,\n- $w = [0.01,\\,0.04,\\,0.10,\\,0.20,\\,0.30,\\,0.20,\\,0.10,\\,0.04,\\,0.01]$.\nThese values are unitless decimal returns and form a valid discrete probability distribution.\n\nYour task is to implement, from first principles, the three-term recurrence for orthonormal polynomials with respect to the inner product defined by the discrete measure $(x,w)$ and then to build the corresponding Gaussian quadrature rule of a given order. The derivation must start from the following base:\n- The discrete inner product is defined by $\\langle f,g\\rangle = \\sum_{i=1}^m w_i\\, f(x_i)\\, g(x_i)$ for any functions $f$ and $g$ for which the sum is finite.\n- A sequence $\\{p_k\\}_{k\\ge 0}$ of orthonormal polynomials satisfies $\\langle p_k,p_\\ell\\rangle = \\delta_{k\\ell}$, where $\\delta_{k\\ell}$ is the Kronecker delta, and each $p_k$ has degree $k$.\n- For any measure with finite moments, there exists a three-term recurrence of the form $x\\,p_k(x) = a_k\\,p_{k+1}(x) + b_k\\,p_k(x) + a_{k-1}\\,p_{k-1}(x)$ with $a_k > 0$, $b_k \\in \\mathbb{R}$, $p_{-1}\\equiv 0$, and $p_0$ normalized to have unit norm under the inner product.\n- By the spectral theorem for real symmetric matrices, the Gaussian quadrature nodes of order $n$ are the eigenvalues of the $n\\times n$ symmetric tridiagonal (Jacobi) matrix whose diagonal entries are $\\{b_0,\\dots,b_{n-1}\\}$ and whose sub- and super-diagonal entries are $\\{a_0,\\dots,a_{n-2}\\}$; the corresponding quadrature weights are proportional to the squares of the first components of the orthonormal eigenvectors, scaled by the zeroth moment $\\mu_0=\\langle 1,1\\rangle$.\n\nImplement the following algorithmic steps logically derived from these bases, without invoking any shortcut formulas:\n- Starting from $p_{-1}\\equiv 0$ and $p_0(x)\\equiv c$ chosen so that $\\langle p_0,p_0\\rangle = 1$, iteratively construct $p_{k+1}$ from $p_k$ and $p_{k-1}$ by orthogonalizing $x\\,p_k$ against $p_k$ and $p_{k-1}$, and normalizing using the given inner product to obtain the coefficients $a_k$ and $b_k$.\n- Assemble the Jacobi matrix of size $n$ for a requested quadrature order $n$.\n- Compute the $n$ Gaussian quadrature nodes and weights from the eigen-decomposition of the Jacobi matrix, noting that the weights must sum to $\\mu_0 = \\sum_{i=1}^m w_i$.\n\nDesign a program that, for each requested order $n$, validates the exactness property of the constructed Gaussian quadrature by testing monomials $f_k(x) = x^k$ for all integers $k \\in \\{0,1,\\dots,2n-1\\}$. For each $k$, compute the exact discrete expectation $\\sum_{i=1}^m w_i\\,x_i^k$ and the quadrature approximation $\\sum_{j=1}^n \\omega_j\\,\\xi_j^k$, where $\\{\\xi_j,\\omega_j\\}_{j=1}^n$ are the quadrature nodes and weights. Report, for each order $n$, the maximum absolute error over $k\\in\\{0,\\dots,2n-1\\}$.\n\nTest Suite:\n- Use the histogram arrays $x$ and $w$ specified above with $m=9$.\n- Evaluate the maximum absolute error for quadrature orders $n \\in \\{1,3,5,9\\}$.\n- Because these are unitless returns, no physical units are involved. Angles are not used. All final numerical answers must be plain real numbers.\n\nFinal Output Format:\n- Your program should produce a single line of output containing the four results (one per test case, in the order $n=1$, then $n=3$, then $n=5$, then $n=9$) as a comma-separated list enclosed in square brackets, for example, $[r_1,r_2,r_3,r_4]$, where each $r_i$ is the maximum absolute error (a real number) for the corresponding quadrature order.", "solution": "The posed problem is valid. It is scientifically grounded in the well-established theory of orthogonal polynomials and Gaussian quadrature, specifically the Golub-Welsch algorithm. The problem statement provides a complete and consistent set of givens, including the discrete measure and the precise algorithmic steps to be followed. It is well-posed, objective, and computationally feasible. We may therefore proceed with the solution.\n\nThe core of the task is to construct a Gaussian quadrature rule for a given discrete probability measure. This measure is defined by a set of support points $x = \\{x_i\\}_{i=1}^m$ and corresponding positive weights (probabilities) $w = \\{w_i\\}_{i=1}^m$, where $m=9$ and $\\sum_{i=1}^m w_i = 1$. The inner product of two functions $f$ and $g$ with respect to this measure is given by:\n$$\n\\langle f, g \\rangle = \\sum_{i=1}^{m} w_i f(x_i) g(x_i)\n$$\nThe procedure involves two main stages: first, the generation of recurrence coefficients for the family of orthonormal polynomials associated with this inner product; second, the use of these coefficients to construct a Jacobi matrix whose spectral properties yield the desired quadrature nodes and weights.\n\nThe foundation of the method is the three-term recurrence relation for a sequence of orthonormal polynomials $\\{p_k(x)\\}_{k \\ge 0}$, where $p_k(x)$ has degree $k$ and $\\langle p_k, p_j \\rangle = \\delta_{kj}$. The recurrence is:\n$$\nx\\,p_k(x) = a_k\\,p_{k+1}(x) + b_k\\,p_k(x) + a_{k-1}\\,p_{k-1}(x)\n$$\nwith the convention $p_{-1}(x) \\equiv 0$ and $a_{-1} = 0$. The coefficients $a_k \\in \\mathbb{R}_+$ and $b_k \\in \\mathbb{R}$ are determined by the orthogonality condition. We will construct these coefficients iteratively using the Stieltjes procedure.\n\n**Step 1: Iterative Construction of Recurrence Coefficients**\n\nWe begin by establishing the base of the orthonormal sequence. The polynomial $p_0(x)$ is a constant, $p_0(x) = c$. Its norm must be unity:\n$$\n\\langle p_0, p_0 \\rangle = \\langle c, c \\rangle = \\sum_{i=1}^{m} w_i c^2 = c^2 \\sum_{i=1}^{m} w_i = 1\n$$\nThe zeroth moment is $\\mu_0 = \\sum_{i=1}^{m} w_i = 1$ based on the given probabilities. Thus, $c^2 = 1$, and we choose $c=1$, which gives $p_0(x) = 1$.\n\nFor $k \\ge 0$, we derive the expressions for $b_k$ and $a_k$. Taking the inner product of the recurrence relation with $p_k(x)$:\n$$\n\\langle x\\,p_k, p_k \\rangle = a_k \\langle p_{k+1}, p_k \\rangle + b_k \\langle p_k, p_k \\rangle + a_{k-1} \\langle p_{k-1}, p_k \\rangle\n$$\nDue to orthonormality, $\\langle p_{j}, p_k \\rangle = \\delta_{jk}$. The equation simplifies to:\n$$\n\\langle x\\,p_k, p_k \\rangle = b_k \\cdot 1\n$$\nThis provides the formula for $b_k$:\n$$\nb_k = \\langle x\\,p_k, p_k \\rangle = \\sum_{i=1}^{m} w_i x_i [p_k(x_i)]^2\n$$\nSince the given distribution $(x, w)$ is symmetric around $0$, all odd moments are zero. This implies that the polynomials $p_k(x)$ will have definite parity (even for even $k$, odd for odd $k$). The term $x_i [p_k(x_i)]^2$ forms an odd function with respect to the symmetric measure, and thus its expectation is zero. Consequently, all coefficients $b_k$ will be zero. This provides a useful check for our computation.\n\nTo find $a_k$, we rearrange the recurrence relation to define an unnormalized polynomial $\\tilde{p}_{k+1}(x)$:\n$$\n\\tilde{p}_{k+1}(x) = (x - b_k) p_k(x) - a_{k-1} p_{k-1}(x)\n$$\nBy definition, $p_{k+1}(x)$ is the normalization of $\\tilde{p}_{k+1}(x)$. The normalization constant is $a_k$, which is the norm of $\\tilde{p}_{k+1}(x)$:\n$$\na_k = \\| \\tilde{p}_{k+1} \\| = \\sqrt{\\langle \\tilde{p}_{k+1}, \\tilde{p}_{k+1} \\rangle} = \\left( \\sum_{i=1}^{m} w_i [\\tilde{p}_{k+1}(x_i)]^2 \\right)^{1/2}\n$$\nThe next orthonormal polynomial is then $p_{k+1}(x) = \\tilde{p}_{k+1}(x) / a_k$.\n\nThis iterative process starts with $p_{-1}(x) \\equiv 0$ and $p_0(x) \\equiv 1$. For each $k=0, 1, 2, \\dots$, we compute $b_k$, then $\\tilde{p}_{k+1}(x)$, then $a_k$, and finally $p_{k+1}(x)$. In implementation, the polynomials are represented by vectors of their values at the support points $\\{x_i\\}$.\n\n**Step 2: Construction of the Gaussian Quadrature Rule**\n\nFor a quadrature rule of order $n$, we require the coefficients $\\{b_0, \\dots, b_{n-1}\\}$ and $\\{a_0, \\dots, a_{n-2}\\}$. These form the $n \\times n$ symmetric tridiagonal Jacobi matrix, $J_n$:\n$$\nJ_n = \\begin{pmatrix}\nb_0  a_0  0  \\cdots  0 \\\\\na_0  b_1  a_1  \\cdots  0 \\\\\n0  a_1  b_2  \\ddots  \\vdots \\\\\n\\vdots  \\vdots  \\ddots  \\ddots  a_{n-2} \\\\\n0  0  \\cdots  a_{n-2}  b_{n-1}\n\\end{pmatrix}\n$$\nThe Golub-Welsch algorithm states that the $n$ Gaussian quadrature nodes, $\\{\\xi_j\\}_{j=1}^n$, are the eigenvalues of $J_n$. The corresponding quadrature weights, $\\{\\omega_j\\}_{j=1}^n$, are derived from the first components of the normalized eigenvectors of $J_n$. Let $v_j$ be the normalized eigenvector corresponding to the eigenvalue $\\xi_j$. The weight $\\omega_j$ is given by:\n$$\n\\omega_j = \\mu_0 \\cdot (v_{j,1})^2\n$$\nwhere $v_{j,1}$ is the first component of the aigenvector $v_j$. Since $\\mu_0=1$, the weights are simply the squares of the first components of the eigenvectors.\n\n**Step 3: Validation of Exactness**\n\nA Gaussian quadrature rule of order $n$ is exact for all polynomials of degree up to $2n-1$. We verify this property by comparing the exact value of the integral (expectation) of monomials $f_k(x) = x^k$ with the value computed by our quadrature rule. For each $k \\in \\{0, 1, \\dots, 2n-1\\}$, we calculate:\n- The exact discrete integral: $E_k = \\langle x^k, 1 \\rangle = \\sum_{i=1}^m w_i x_i^k$.\n- The quadrature approximation: $Q_k = \\sum_{j=1}^n \\omega_j \\xi_j^k$.\n\nThe maximum absolute error across all tested monomials, $\\max_{k \\in \\{0, \\dots, 2n-1\\}} |E_k - Q_k|$, is reported for each requested order $n$. For the case where $n=m=9$, the Gaussian quadrature rule must exactly recover the nodes and weights of the original discrete measure, i.e., $\\{\\xi_j, \\omega_j\\} \\equiv \\{x_i, w_i\\}$ (up to permutation). Consequently, the error for $n=9$ is expected to be zero to within machine precision for any function, including all tested monomials.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom numpy.linalg import eigh\n\ndef solve():\n    \"\"\"\n    Implements the Golub-Welsch algorithm to construct Gaussian quadrature rules\n    for a discrete measure and validates their exactness.\n    \"\"\"\n    # Define the discrete measure (proxy for S 500 log-returns)\n    x = np.array([-0.04, -0.03, -0.02, -0.01, 0.0, 0.01, 0.02, 0.03, 0.04], dtype=np.float64)\n    w = np.array([0.01, 0.04, 0.10, 0.20, 0.30, 0.20, 0.10, 0.04, 0.01], dtype=np.float64)\n    m = len(x)\n\n    # Test suite of quadrature orders\n    test_cases = [1, 3, 5, 9]\n    max_order = max(test_cases)\n    \n    results = []\n\n    # --- Step 1: Compute recurrence coefficients using the Stieltjes procedure ---\n    # We need coefficients a_k up to k=max_order-2 and b_k up to k=max_order-1.\n    # The loop will compute a_k and b_k for k=0...max_order-1.\n    \n    a_coeffs = []\n    b_coeffs = []\n\n    # Initialization: p_(-1) = 0, p_0 = 1/sqrt(mu_0)\n    mu_0 = np.sum(w) # Should be 1.0\n    p_k_minus_1 = np.zeros(m, dtype=np.float64)\n    p_k = np.ones(m, dtype=np.float64) / np.sqrt(mu_0)\n    \n    # Iteratively find coefficients a_k and b_k\n    for k in range(max_order):\n        # Calculate b_k = x*p_k, p_k\n        # Note: Since the distribution is symmetric, all b_k will be zero.\n        b_k = np.sum(w * x * p_k**2)\n        b_coeffs.append(b_k)\n\n        # Calculate unnormalized p_{k+1}\n        # p_tilde_{k+1} = (x - b_k)*p_k - a_{k-1}*p_{k-1}\n        a_k_minus_1 = a_coeffs[k - 1] if k > 0 else 0.0\n        p_k_plus_1_tilde = (x - b_k) * p_k - a_k_minus_1 * p_k_minus_1\n\n        # Calculate a_k = ||p_tilde_{k+1}||\n        norm_sq = np.sum(w * p_k_plus_1_tilde**2)\n        a_k = np.sqrt(norm_sq)\n        a_coeffs.append(a_k)\n        \n        # Normalize to get p_{k+1}\n        # Handle the case a_k -> 0, which happens if order n reaches m.\n        # This indicates the termination of the orthogonal polynomial sequence.\n        if a_k  np.finfo(float).eps:\n            p_k_plus_1 = np.zeros(m, dtype=np.float64)\n        else:\n            p_k_plus_1 = p_k_plus_1_tilde / a_k\n\n        # Update for the next iteration\n        p_k_minus_1 = p_k\n        p_k = p_k_plus_1\n\n    # --- Step 2  3: Build Jacobi matrix, compute quadrature, and validate for each order n ---\n    for n in test_cases:\n        # Assemble the n x n Jacobi matrix (J_n)\n        diag = np.array(b_coeffs[:n])\n        off_diag = np.array(a_coeffs[:n-1]) if n > 1 else np.array([])\n        J_n = np.diag(diag) + np.diag(off_diag, k=1) + np.diag(off_diag, k=-1)\n        \n        # Eigen-decomposition gives quadrature nodes (eigenvalues) and weights (from eigenvectors)\n        # Using eigh as the matrix is symmetric.\n        nodes, evecs = eigh(J_n)\n        \n        # Weights are mu_0 * (first component of normalized eigenvectors)^2\n        # Since mu_0 = 1, weights are just the square of the first components.\n        weights = mu_0 * (evecs[0, :]**2)\n\n        # Validate exactness for polynomials of degree k = 0, 1, ..., 2n-1\n        max_abs_error = 0.0\n        for k in range(2 * n):\n            # Exact integral (discrete expectation)\n            exact_integral = np.sum(w * (x**k))\n            \n            # Quadrature approximation\n            # Note: 0^0 is 1, numpy handles this correctly for vectors.\n            quad_approx = np.sum(weights * (nodes**k))\n            \n            # Update maximum absolute error\n            abs_error = np.abs(exact_integral - quad_approx)\n            if abs_error > max_abs_error:\n                max_abs_error = abs_error\n        \n        results.append(max_abs_error)\n        \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2396803"}]}