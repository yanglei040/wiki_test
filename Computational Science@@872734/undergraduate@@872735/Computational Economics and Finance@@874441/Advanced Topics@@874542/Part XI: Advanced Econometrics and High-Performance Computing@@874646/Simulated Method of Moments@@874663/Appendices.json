{"hands_on_practices": [{"introduction": "Our first hands-on practice provides a foundational exercise in implementing the Simulated Method of Moments. We will estimate a key preference parameter in a classic life-cycle consumption model. By design, the 'empirical' data for this problem is generated by the model itself using a known parameter, turning the task into a model recovery exercise. This controlled environment is the perfect starting point to build and validate your SMM code, ensuring you have mastered the core loop of simulating moments and minimizing a well-defined objective function before tackling more complex, real-world scenarios [@problem_id:2430562].", "problem": "Consider a finite-horizon life-cycle consumption and saving model with Constant Relative Risk Aversion (CRRA) preferences. An individual lives for $T$ discrete periods, indexed by $t \\in \\{1,2,\\dots,T\\}$, starts with initial financial wealth $a_1 = 0$, and faces a constant gross real interest factor $1+r$. The period utility function is $u(c_t) = \\frac{c_t^{1-\\gamma}}{1-\\gamma}$ for $\\gamma \\neq 1$, where $\\gamma$ is the coefficient of relative risk aversion. The time discount factor is $\\beta \\in (0,1)$. The intertemporal budget constraint is\n$$\na_{t+1} = (1+r)\\,a_t + y_t - c_t \\quad \\text{for all } t \\in \\{1,2,\\dots,T\\},\n$$\nand the terminal (no-bequest) condition is $a_{T+1} = 0$. The income process is deterministic and piecewise defined by\n- $y_1 = 1$,\n- for $t \\in \\{1,2,\\dots,R-1\\}$, $y_{t+1} = y_t\\,(1+g)$,\n- for $t \\in \\{R+1,R+2,\\dots,T\\}$, $y_t = \\theta \\, y_R$,\nwhere $R$ is the retirement period, $g$ is the gross growth rate of labor income during working life, and $\\theta \\in (0,1)$ is the replacement ratio in retirement.\n\nAssume interior solutions and no uncertainty. The first-order necessary condition implies the Euler condition\n$$\n\\frac{u'(c_t)}{\\beta (1+r)} = u'(c_{t+1}) \\quad \\Longleftrightarrow \\quad c_{t+1} = c_t \\left(\\beta (1+r)\\right)^{1/\\gamma}.\n$$\nDefine $g_c(\\gamma) \\equiv \\left(\\beta (1+r)\\right)^{1/\\gamma}$ and let $c_t = c_1 \\, g_c(\\gamma)^{t-1}$. Imposing the intertemporal budget identity and the terminal condition $a_{T+1} = 0$ pins down $c_1$ from\n$$\n\\sum_{t=1}^{T} \\frac{c_t}{(1+r)^{t-1}} = \\sum_{t=1}^{T} \\frac{y_t}{(1+r)^{t-1}} \\quad \\Longleftrightarrow \\quad\nc_1(\\gamma) = \\frac{\\sum_{t=1}^{T} \\frac{y_t}{(1+r)^{t-1}}}{\\sum_{t=1}^{T} \\frac{g_c(\\gamma)^{t-1}}{(1+r)^{t-1}}}.\n$$\nGiven $c_1(\\gamma)$ and $g_c(\\gamma)$, generate $\\{c_t\\}_{t=1}^{T}$ and then $\\{a_t\\}_{t=1}^{T}$ forward using the budget recursion with $a_1=0$. For any selected set of periods $\\mathcal{S} \\subset \\{1,\\dots,T\\}$, define the model-implied moment vector as the wealth-to-income ratios\n$$\nm(\\gamma; \\mathcal{S}) = \\left[ \\frac{a_t}{y_t} \\right]_{t \\in \\mathcal{S}}.\n$$\n\nYou are asked to estimate the coefficient of relative risk aversion $\\gamma$ via the Simulated Method of Moments (SMM), where the target empirical moment vector equals the model-generated moment vector at a known reference value $\\gamma_{\\text{ref}}$ under the same parameters. Let the SMM objective be the unweighted quadratic loss\n$$\nQ(\\gamma) = \\sum_{t \\in \\mathcal{S}} \\left( \\frac{a_t(\\gamma)}{y_t} - \\frac{a_t(\\gamma_{\\text{ref}})}{y_t} \\right)^2,\n$$\nand restrict the parameter search to $\\gamma \\in [0.5, 10]$. The estimate $\\hat{\\gamma}$ is any minimizer of $Q(\\gamma)$ over this interval. All calculations are unit-free. Angles are not involved. No percentages are required.\n\nImplement a program that, for each parameter set in the test suite below, constructs the income profile $\\{y_t\\}_{t=1}^{T}$, forms the target moments using $\\gamma_{\\text{ref}}$, computes the SMM estimate $\\hat{\\gamma}$, and reports the estimates in the specified format.\n\nTest suite (each line is a complete case):\n- Case A: $\\beta = 0.99$, $r = 0.04$, $g = 0.02$, $T=40$, $R=30$, $\\theta=0.7$, $\\gamma_{\\text{ref}}=2.0$, $\\mathcal{S} = \\{5, 15, 25, 35\\}$.\n- Case B: $\\beta = 0.97$, $r = 0.04$, $g = 0.01$, $T=35$, $R=25$, $\\theta=0.6$, $\\gamma_{\\text{ref}}=3.0$, $\\mathcal{S} = \\{5, 12, 20, 30\\}$.\n- Case C: $\\beta = 0.995$, $r = 0.03$, $g = 0.015$, $T=45$, $R=35$, $\\theta=0.8$, $\\gamma_{\\text{ref}}=1.5$, $\\mathcal{S} = \\{10, 20, 30, 40\\}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the three estimated values $\\hat{\\gamma}$ for Cases A, B, and C, in that order, rounded to four decimal places, as a comma-separated list enclosed in square brackets, for example, $[\\hat{\\gamma}_A,\\hat{\\gamma}_B,\\hat{\\gamma}_C]$.", "solution": "The problem requires the estimation of the coefficient of relative risk aversion, $\\gamma$, within a deterministic finite-horizon life-cycle model. The estimation is to be performed using the Simulated Method of Moments (SMM). A critical feature of this problem is its design as a model recovery exercise. The target \"empirical\" moments for the estimation are generated by the very same model, but with a known, fixed parameter $\\gamma_{\\text{ref}}$. By construction, the SMM objective function, $Q(\\gamma)$, which is a sum of squared differences, will have a true global minimum of $0$ at the point $\\gamma = \\gamma_{\\text{ref}}$. The objective is therefore to implement a numerical procedure that can correctly identify this known minimum for several parameterizations.\n\nThe solution methodology proceeds through a series of well-defined computational steps for each test case provided.\n\nFirst, for each set of parameters, we construct the deterministic income profile $\\{y_t\\}_{t=1}^{T}$. Given the life span $T$, retirement period $R$, income growth rate $g$, and pension replacement ratio $\\theta$, the income sequence is defined piecewise:\n$$\ny_1 = 1\n$$\n$$\ny_t = y_{t-1}(1+g) = (1+g)^{t-1} \\quad \\text{for } t \\in \\{2, \\dots, R\\}\n$$\n$$\ny_t = \\theta \\cdot y_R = \\theta (1+g)^{R-1} \\quad \\text{for } t \\in \\{R+1, \\dots, T\\}\n$$\nThis profile serves as an exogenous input to the agent's optimization problem.\n\nSecond, a core function is designed to solve the agent's life-cycle problem for any given candidate value of $\\gamma$ and the model's structural parameters. This function computes the wealth-to-income ratios that serve as the model's moments. The procedure is as follows:\n\n1.  Calculate the gross growth factor of consumption, $g_c$. This factor is derived from the model's first-order necessary condition (the Euler equation) and depends on $\\gamma$, the time discount factor $\\beta$, and the gross real interest factor $(1+r)$:\n    $$\n    g_c(\\gamma) = \\left(\\beta (1+r)\\right)^{1/\\gamma}\n    $$\n    For the Constant Relative Risk Aversion (CRRA) utility function $u(c_t) = c_t^{1-\\gamma}/(1-\\gamma)$, the marginal utility is $u'(c_t)=c_t^{-\\gamma}$. The Euler equation $u'(c_t) = \\beta(1+r)u'(c_{t+1})$ becomes $c_t^{-\\gamma} = \\beta(1+r)c_{t+1}^{-\\gamma}$, which directly yields the expression for $g_c$ as the ratio $c_{t+1}/c_t$.\n\n2.  Determine the level of initial consumption, $c_1$. This is pinned down by the lifetime budget constraint, which equates the present value of lifetime consumption to the present value of lifetime resources (initial wealth plus lifetime income). With initial financial wealth $a_1=0$ and the terminal no-bequest condition $a_{T+1}=0$, the constraint is:\n    $$\n    \\sum_{t=1}^{T} \\frac{c_t}{(1+r)^{t-1}} = \\sum_{t=1}^{T} \\frac{y_t}{(1+r)^{t-1}}\n    $$\n    By substituting the relationship $c_t = c_1 \\cdot g_c(\\gamma)^{t-1}$, we isolate $c_1$:\n    $$\n    c_1(\\gamma) = \\frac{\\sum_{t=1}^{T} y_t (1+r)^{-(t-1)}}{\\sum_{t=1}^{T} (g_c(\\gamma)/(1+r))^{t-1}}\n    $$\n    The numerator is the present value of the income stream ('human wealth'), and the denominator can be calculated as the sum of a geometric series.\n\n3.  Generate the complete consumption path $\\{c_t\\}_{t=1}^{T}$ and wealth path $\\{a_t\\}_{t=1}^{T+1}$.\n    - The consumption path is determined by $c_t = c_1 \\cdot g_c(\\gamma)^{t-1}$ for $t \\in \\{1, \\dots, T\\}$.\n    - The wealth path is computed by iterating the intertemporal budget constraint forward, starting from $a_1=0$:\n      $$\n      a_{t+1} = (1+r) a_t + y_t - c_t \\quad \\text{for } t \\in \\{1, \\dots, T\\}\n      $$\n\n4.  Calculate the model-implied moments. For a specified set of periods $\\mathcal{S} \\subset \\{1, \\dots, T\\}$, the moments are the wealth-to-income ratios:\n    $$\n    m(\\gamma; \\mathcal{S}) = \\left[ \\frac{a_t(\\gamma)}{y_t} \\right]_{t \\in \\mathcal{S}}\n    $$\n\nThird, the SMM objective function $Q(\\gamma)$ is formulated. For each test case, we first compute the target moment vector $m_{\\text{target}} = m(\\gamma_{\\text{ref}}; \\mathcal{S})$ by running the model-solving function with the known reference parameter $\\gamma_{\\text{ref}}$. The objective function for the minimization is then the unweighted sum of squared deviations between the moments from a candidate $\\gamma$ and these target moments:\n$$\nQ(\\gamma) = \\sum_{t \\in \\mathcal{S}} \\left( \\frac{a_t(\\gamma)}{y_t} - \\frac{a_t(\\gamma_{\\text{ref}})}{y_t} \\right)^2 = \\| m(\\gamma; \\mathcal{S}) - m_{\\text{target}} \\|_2^2\n$$\n\nFinally, for each test case, the estimate $\\hat{\\gamma}$ is found by numerically minimizing $Q(\\gamma)$ over the given search interval $\\gamma \\in [0.5, 10]$:\n$$\n\\hat{\\gamma} = \\arg\\min_{\\gamma \\in [0.5, 10]} Q(\\gamma)\n$$\nA bounded scalar optimization routine is employed for this purpose. The implemented algorithm will apply this full procedure to each of the three test cases (A, B, C) to obtain the estimates $\\hat{\\gamma}_A$, $\\hat{\\gamma}_B$, and $\\hat{\\gamma}_C$. As this is a recovery exercise, the numerical estimate $\\hat{\\gamma}$ is expected to coincide with $\\gamma_{\\text{ref}}$ up to the tolerance of the numerical optimizer.", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\n\ndef solve():\n    \"\"\"\n    Solves for the SMM estimate of gamma for a series of life-cycle model parameterizations.\n    \"\"\"\n    test_cases = [\n        # Case A\n        {'beta': 0.99, 'r': 0.04, 'g': 0.02, 'T': 40, 'R': 30, 'theta': 0.7, 'gamma_ref': 2.0, 'S': [5, 15, 25, 35]},\n        # Case B\n        {'beta': 0.97, 'r': 0.04, 'g': 0.01, 'T': 35, 'R': 25, 'theta': 0.6, 'gamma_ref': 3.0, 'S': [5, 12, 20, 30]},\n        # Case C\n        {'beta': 0.995, 'r': 0.03, 'g': 0.015, 'T': 45, 'R': 35, 'theta': 0.8, 'gamma_ref': 1.5, 'S': [10, 20, 30, 40]},\n    ]\n\n    results = []\n\n    def generate_income_profile(T, R, g, theta):\n        \"\"\"Generates the deterministic income profile over the life cycle.\"\"\"\n        y = np.zeros(T)\n        y[0] = 1.0\n        # Working years income growth\n        for t in range(1, R):\n            y[t] = y[t-1] * (1.0 + g)\n        # Retirement years income\n        if R  T:\n            y_R = y[R-1]\n            for t in range(R, T):\n                y[t] = theta * y_R\n        return y\n\n    def get_moments(gamma, beta, r, T, S_indices, income_profile):\n        \"\"\"\n        Solves the model for a given gamma and returns the wealth-to-income moments.\n        S_indices must be 0-based.\n        \"\"\"\n        R_gross = 1.0 + r\n        \n        # 1. Calculate consumption growth factor\n        g_c = (beta * R_gross)**(1.0 / gamma)\n\n        # 2. Calculate initial consumption c1\n        discount_factors = R_gross**(-np.arange(T))\n        pv_income = np.sum(income_profile * discount_factors)\n        \n        consumption_growth_discfactors = (g_c / R_gross)**np.arange(T)\n        pv_consumption_factor = np.sum(consumption_growth_discfactors)\n        \n        c1 = pv_income / pv_consumption_factor\n\n        # 3. Generate consumption and wealth paths\n        # Consumption path c_t for t=1,...,T\n        c_path = c1 * (g_c**np.arange(T))\n        \n        # Wealth path a_{t+1} for t=1,...,T, with a_1=0\n        # a_path[t] corresponds to a_{t+1}\n        a_path = np.zeros(T + 1) # a_1, ..., a_{T+1}\n        \n        for t in range(T):\n            a_path[t+1] = R_gross * a_path[t] + income_profile[t] - c_path[t]\n\n        # 4. Compute moments (wealth-to-income ratios)\n        # a_path[t] is a_{t+1}, so a_t is a_path[t-1]. S_indices is already t-1.\n        wealth_at_S = a_path[S_indices]\n        income_at_S = income_profile[S_indices]\n        \n        # Handle cases where income might be zero, though not in this problem's setup\n        moments = np.divide(wealth_at_S, income_at_S, \n                            out=np.zeros_like(wealth_at_S, dtype=float), \n                            where=income_at_S!=0)\n        return moments\n\n    for case in test_cases:\n        T, R, g, theta = case['T'], case['R'], case['g'], case['theta']\n        beta, r, gamma_ref = case['beta'], case['r'], case['gamma_ref']\n        S = case['S']\n        \n        # S contains 1-based periods, convert to 0-based indices for numpy arrays\n        S_indices = np.array(S) - 1\n\n        # Generate income profile once per case\n        income_profile = generate_income_profile(T, R, g, theta)\n\n        # Compute target moments using gamma_ref\n        target_moments = get_moments(gamma_ref, beta, r, T, S_indices, income_profile)\n\n        # Define the SMM objective function\n        def objective_function(gamma):\n            model_moments = get_moments(gamma, beta, r, T, S_indices, income_profile)\n            return np.sum((model_moments - target_moments)**2)\n\n        # Numerically minimize the objective function\n        # The minimizer should recover gamma_ref\n        res = minimize_scalar(\n            objective_function,\n            bounds=(0.5, 10.0),\n            method='bounded'\n        )\n        \n        estimated_gamma = round(res.x, 4)\n        results.append(f\"{estimated_gamma:.4f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2430562"}, {"introduction": "Moving from a controlled exercise to a more realistic application, our next practice delves into the heart of modern macroeconomics. Here, you will use SMM to estimate structural parameters of a Real Business Cycle (RBC) model, a cornerstone for understanding economic fluctuations. This problem requires you to handle stochastic shocks, simulate time series for key macroeconomic variables, and compute moments based on the Hodrick-Prescott filter—a standard tool for business cycle analysis. Successfully completing this exercise [@problem_id:2430572] will build your skills in applying SMM to dynamic stochastic models, a common task in academic research and policy analysis.", "problem": "You are asked to implement a complete, runnable program that uses the Simulated Method of Moments (SMM) to estimate the depreciation rate $\\,\\delta\\,$ and the capital share $\\,\\alpha\\,$ in a Real Business Cycle (RBC) model. Your program must generate synthetic “observed” data, construct moments from the Hodrick–Prescott (HP) filtered time series of output and investment, and estimate parameters by matching simulated moments to observed moments.\n\nFundamental base:\n- Competitive neoclassical growth environment with capital $\\,k_t\\,$ and an exogenous technology shock.\n- Cobb–Douglas production with fixed labor normalized to $\\,1\\,$: $\\,y_t = \\exp(z_t)\\,k_{t-1}^{\\alpha}\\,$.\n- Capital accumulation: $\\,k_t = (1-\\delta)\\,k_{t-1} + i_t\\,$.\n- Technology shock: $\\,z_t = \\rho z_{t-1} + \\varepsilon_t\\,$ with $\\,\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)\\,$ independently over time.\n- Discount factor $\\,\\beta \\in (0,1)\\,$ fixed and known.\n- In steady state under the Euler condition, $\\,1 = \\beta\\left[\\alpha k^{\\alpha-1} + 1 - \\delta\\right]\\,$. Around the steady state, a first-order approximation motivates using a constant investment share equal to its steady-state value, so that $\\,i_t = s^* y_t\\,$, where\n$$\ns^* \\equiv \\frac{i^*}{y^*} = \\frac{\\delta \\alpha}{\\beta^{-1} - 1 + \\delta}.\n$$\nThis yields a scientifically coherent reduced form that preserves resource feasibility and links $\\,s^*\\,$ to $\\,\\alpha\\,$ and $\\,\\delta\\,$ via the steady-state Euler condition.\n\nMoment construction:\n- Given a univariate time series $\\,x_t\\,$, the Hodrick–Prescott (HP) filter defines $\\,\\{\\tau_t\\}\\,$ (the trend) as the minimizer of\n$$\n\\sum_{t=1}^T (x_t - \\tau_t)^2 + \\lambda \\sum_{t=3}^T \\left[(\\tau_t - \\tau_{t-1}) - (\\tau_{t-1} - \\tau_{t-2})\\right]^2,\n$$\nwith smoothing parameter $\\,\\lambda > 0\\,$. The cyclical component is $\\,c_t = x_t - \\tau_t\\,$. The first-order conditions can be written as a symmetric positive-definite five-diagonal linear system $\\,A(\\lambda)\\,\\tau = x\\,$, which you must solve numerically. Use $\\,\\lambda = 1600\\,$ (quarterly convention).\n- From the HP-filtered cyclical components of output and investment, construct the following moments:\n    1. $\\,m_1\\,$: the sample standard deviation of the output cycle $\\,c^y_t\\,$.\n    2. $\\,m_2\\,$: the sample standard deviation of the investment cycle $\\,c^i_t\\,$.\n    3. $\\,m_3\\,$: the sample mean of the investment share $\\,i_t / y_t\\,$.\n    4. $\\,m_4\\,$: the first-order sample autocorrelation of the output cycle $\\,c^y_t\\,$.\n\nSimulated Method of Moments (SMM):\n- Let $\\,\\theta = (\\delta,\\alpha)\\,$ be the parameter vector to estimate, with bounds $\\,\\delta \\in (0,1)\\,$ and $\\,\\alpha \\in (0,1)\\,$.\n- Given a fixed set of shocks $\\,\\{\\varepsilon_t\\}_{t=1}^{T+B}\\,$ (where $\\,B\\,$ is a burn-in), simulate model-implied $\\,\\{y_t,i_t\\}\\,$ under $\\,\\theta\\,$, drop the first $\\,B\\,$ observations, and compute the moment vector $\\,\\hat{m}(\\theta)\\,$ from the remaining $\\,T\\,$ observations.\n- Using the same shock realization, construct the “observed” moments $\\,\\hat{m}^{\\text{obs}}\\,$ by simulating the model at the “true” parameter $\\,\\theta_0\\,$.\n- Use the identity matrix as the weighting matrix. Minimize the objective\n$$\nQ(\\theta) = \\left[\\hat{m}(\\theta) - \\hat{m}^{\\text{obs}}\\right]^\\top \\left[\\hat{m}(\\theta) - \\hat{m}^{\\text{obs}}\\right].\n$$\n\nImplementation details to enforce:\n- Use $\\,\\beta = 0.99\\,$. For all test cases, set the HP filter smoothing parameter to $\\,\\lambda = 1600\\,$.\n- For reproducibility and to reduce simulation noise in the SMM objective, the same shock sequence must be used for observed data generation and for every evaluation of $\\,\\hat{m}(\\theta)\\,$ during estimation.\n- For numerical stability and efficiency, form the five-diagonal HP matrix $\\,A(\\lambda)\\,$ explicitly and solve the linear system $\\,A(\\lambda)\\,\\tau = x\\,$ using a sparse direct solver. Reuse the same factorization across objective evaluations within each test case.\n\nTest suite:\nImplement and run your estimator on the following three test cases. For each case, you must:\n- Fix the seed, generate shocks $\\,\\varepsilon_t\\,$, simulate observed data at the true parameter, compute observed moments, and then run SMM to estimate $\\,(\\delta,\\alpha)\\,$ using the specified bounds.\n- Use sample size $\\,T\\,$, burn-in $\\,B = 100\\,$, autoregressive coefficient $\\,\\rho\\,$, and innovation standard deviation $\\,\\sigma\\,$ as given.\n\nTest cases:\n1. Case A:\n    - Seed: $\\,123\\,$\n    - True parameters: $\\,\\delta_0 = 0.025\\,$, $\\,\\alpha_0 = 0.35\\,$\n    - Shock process: $\\,\\rho = 0.9\\,$, $\\,\\sigma = 0.007\\,$\n    - Sample size: $\\,T = 240\\,$\n2. Case B:\n    - Seed: $\\,456\\,$\n    - True parameters: $\\,\\delta_0 = 0.08\\,$, $\\,\\alpha_0 = 0.25\\,$\n    - Shock process: $\\,\\rho = 0.95\\,$, $\\,\\sigma = 0.01\\,$\n    - Sample size: $\\,T = 240\\,$\n3. Case C:\n    - Seed: $\\,789\\,$\n    - True parameters: $\\,\\delta_0 = 0.01\\,$, $\\,\\alpha_0 = 0.40\\,$\n    - Shock process: $\\,\\rho = 0.8\\,$, $\\,\\sigma = 0.005\\,$\n    - Sample size: $\\,T = 200\\,$\n\nParameter bounds for estimation in all cases:\n- $\\,\\delta \\in [0.005,\\,0.15]\\,$, $\\,\\alpha \\in [0.15,\\,0.5]\\,$.\n\nAngle units and physical units:\n- No physical or angle units are involved. All values are pure numbers.\n\nRequired final output format:\n- Your program must print a single line containing a list of lists with the estimated parameters for the three cases in the order A, B, C. Each inner list must be $[\\hat{\\delta},\\hat{\\alpha}]$ with each element rounded to four decimal places. For example:\n\"[[0.0250,0.3500],[0.0800,0.2500],[0.0100,0.4000]]\"\nYour program must produce exactly one line, with no additional text or spaces beyond standard comma separation inside the list. The numbers must be rounded to four decimals.", "solution": "The problem presented is a standard and well-defined exercise in computational macroeconomics. It asks for the estimation of structural parameters of a Real Business Cycle (RBC) model using the Simulated Method of Moments (SMM). All components of the problem—the model specification, the moment conditions, the estimation methodology, and the numerical implementation details—are scientifically grounded, internally consistent, and complete. Therefore, the problem is valid and admits a rigorous solution.\n\nThe objective is to estimate the parameter vector $\\theta = (\\delta, \\alpha)$, where $\\delta$ is the capital depreciation rate and $\\alpha$ is the capital share in a Cobb-Douglas production function. We will proceed by first specifying the procedure for simulating the economic model, then detailing the construction of the statistical moments, and finally outlining the SMM estimation framework.\n\n**1. Model Simulation**\n\nThe model's dynamics are driven by an exogenous technology shock process, $z_t$, which follows a first-order autoregressive process:\n$$\nz_t = \\rho z_{t-1} + \\varepsilon_t, \\quad \\varepsilon_t \\sim \\mathcal{N}(0, \\sigma^2)\n$$\nwhere $\\rho$ is the persistence parameter, and $\\sigma$ is the standard deviation of the innovation $\\varepsilon_t$. The simulation begins by generating a sequence of $T+B$ shocks, where $T$ is the sample size and $B$ is the burn-in period.\n\nGiven a parameter vector $\\theta = (\\delta, \\alpha)$ and the fixed discount factor $\\beta = 0.99$, the steady-state investment share, $s^*$, is determined by the steady-state Euler equation. This yields:\n$$\ns^* = \\frac{i^*}{y^*} = \\frac{\\delta \\alpha}{\\beta^{-1} - 1 + \\delta}\n$$\nThe problem specifies a simplified investment rule where the investment-output ratio is constant at this steady-state value for all periods: $i_t = s^* y_t$.\n\nThe simulation logic for the time series of capital ($k_t$), output ($y_t$), and investment ($i_t$) proceeds iteratively for $t = 1, \\dots, T+B$. We start with capital at its non-stochastic steady-state value, $k_0 = k^*$, given by:\n$$\nk^* = \\left(\\frac{\\alpha}{\\beta^{-1} - 1 + \\delta}\\right)^{\\frac{1}{1-\\alpha}}\n$$\nThen, for each period $t$:\n1. Output $y_t$ is produced using capital from the previous period, $k_{t-1}$, and the current technology level, $z_t$:\n   $$\n   y_t = \\exp(z_t) k_{t-1}^{\\alpha}\n   $$\n2. Investment $i_t$ is determined as a constant fraction $s^*$ of current output:\n   $$\n   i_t = s^* y_t\n   $$\n3. The capital stock for the next period, $k_t$, is updated according to the law of motion:\n   $$\n   k_t = (1-\\delta) k_{t-1} + i_t\n   $$\nAfter simulating for $T+B$ periods, the initial $B=100$ observations are discarded to mitigate the influence of initial conditions, leaving a sample of size $T$.\n\n**2. Moment Construction**\n\nThe estimation procedure relies on matching four statistical moments derived from the simulated time series. These moments are calculated after detrending the output and investment series using the Hodrick-Prescott (HP) filter.\n\nFor a given time series $\\{x_t\\}_{t=1}^T$, the HP filter separates it into a trend component $\\{\\tau_t\\}_{t=1}^T$ and a cyclical component $\\{c_t\\}_{t=1}^T$ where $c_t = x_t - \\tau_t$. The trend is found by solving the following minimization problem:\n$$\n\\min_{\\{\\tau_t\\}} \\left( \\sum_{t=1}^T (x_t - \\tau_t)^2 + \\lambda \\sum_{t=3}^T \\left[(\\tau_t - \\tau_{t-1}) - (\\tau_{t-1} - \\tau_{t-2})\\right]^2 \\right)\n$$\nwith the smoothing parameter fixed at $\\lambda = 1600$. The first-order conditions of this problem yield a system of linear equations, $A(\\lambda)\\tau = x$, where $\\tau = [\\tau_1, \\dots, \\tau_T]^\\top$ and $x = [x_1, \\dots, x_T]^\\top$. The matrix $A(\\lambda)$ is a symmetric, pentadiagonal matrix of size $T \\times T$. For rows $i$ from $3$ to $T-2$, the structure is defined by the equation:\n$$\n\\lambda\\tau_{i-2} - 4\\lambda\\tau_{i-1} + (1+6\\lambda)\\tau_i - 4\\lambda\\tau_{i+1} + \\lambda\\tau_{i+2} = x_i\n$$\nThe first two and last two rows have a slightly different structure due to the boundaries of the summation. This linear system must be constructed and solved numerically. For efficiency, we will construct $A(\\lambda)$ as a sparse matrix and compute its LU factorization once per test case. This factorization can then be reused to solve for the trend component of both the output and investment series multiple times during the optimization process.\n\nLet $c^y_t$ and $c^i_t$ be the cyclical components of output and investment, respectively. The four moments are:\n1. $m_1$: The sample standard deviation of the output cycle, $\\text{std}(c^y)$.\n2. $m_2$: The sample standard deviation of the investment cycle, $\\text{std}(c^i)$.\n3. $m_3$: The sample mean of the investment-output ratio, $\\text{mean}(i_t/y_t)$. Under the model's specification, this is simply $s^*$.\n4. $m_4$: The first-order sample autocorrelation of the output cycle, $\\text{corr}(c^y_t, c^y_{t-1})$.\n\n**3. SMM Estimation Procedure**\n\nThe SMM estimator $\\hat{\\theta}$ is found by minimizing a quadratic form of the difference between moments computed from the data and moments simulated from the model.\nThe procedure is as follows:\n1.  **Generate \"Observed\" Data**: For each test case, we first fix the random seed and generate a single, fixed sequence of innovations $\\{\\varepsilon_t\\}_{t=1}^{T+B}$. Using the true parameters $\\theta_0 = (\\delta_0, \\alpha_0)$, we simulate the model to produce the \"observed\" time series for output and investment. From these series, we compute the \"observed\" moment vector, $\\hat{m}^{\\text{obs}} = [m_1^{\\text{obs}}, m_2^{\\text{obs}}, m_3^{\\text{obs}}, m_4^{\\text{obs}}]^\\top$.\n\n2.  **Define Objective Function**: The objective function, $Q(\\theta)$, to be minimized is the sum of squared differences between simulated and observed moments. The problem specifies an identity weighting matrix, so the function is:\n    $$\n    Q(\\theta) = \\left[\\hat{m}(\\theta) - \\hat{m}^{\\text{obs}}\\right]^\\top \\left[\\hat{m}(\\theta) - \\hat{m}^{\\text{obs}}\\right] = \\sum_{j=1}^{4} \\left( \\hat{m}_j(\\theta) - \\hat{m}_j^{\\text{obs}} \\right)^2\n    $$\n    To evaluate $Q(\\theta)$ for a given candidate parameter vector $\\theta$, we simulate the model using $\\theta$ and the *very same sequence of innovations* $\\{\\varepsilon_t\\}$ that was used to generate the observed data. We then compute the simulated moment vector $\\hat{m}(\\theta)$ and calculate the objective function value. Using the same shocks for both observed and simulated data turns the stochastic estimation problem into a deterministic one, significantly improving numerical stability.\n\n3.  **Numerical Minimization**: We use a numerical optimization algorithm, specifically L-BFGS-B, to find the parameter vector $\\hat{\\theta} = (\\hat{\\delta}, \\hat{\\alpha})$ that minimizes $Q(\\theta)$ subject to the specified bounds: $\\delta \\in [0.005, 0.15]$ and $\\alpha \\in [0.15, 0.5]$. The starting point for the optimization is chosen as the midpoint of these bounds.\n\nThis completes the logical design of the estimator. The final implementation will encapsulate these steps in a Python program.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.sparse import diags\nfrom scipy.sparse.linalg import splu\n\ndef solve():\n    \"\"\"\n    Main function to run SMM estimation for all test cases.\n    \"\"\"\n    beta = 0.99\n    lambd = 1600.0  # HP filter lambda\n    B = 100        # Burn-in period\n\n    test_cases = [\n        {\n            'seed': 123, 'true_params': (0.025, 0.35), 'shock_params': (0.9, 0.007),\n            'T': 240, 'bounds': [(0.005, 0.15), (0.15, 0.5)]\n        },\n        {\n            'seed': 456, 'true_params': (0.08, 0.25), 'shock_params': (0.95, 0.01),\n            'T': 240, 'bounds': [(0.005, 0.15), (0.15, 0.5)]\n        },\n        {\n            'seed': 789, 'true_params': (0.01, 0.40), 'shock_params': (0.8, 0.005),\n            'T': 200, 'bounds': [(0.005, 0.15), (0.15, 0.5)]\n        }\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        seed = case['seed']\n        true_delta, true_alpha = case['true_params']\n        rho, sigma = case['shock_params']\n        T = case['T']\n        bounds = case['bounds']\n\n        np.random.seed(seed)\n        shocks_z = np.random.normal(0.0, sigma, T + B)\n\n        # Pre-compute HP filter solver for this sample size\n        hp_solver = get_hp_solver(T, lambd)\n\n        # Generate \"observed\" data and moments\n        y_obs, i_obs = simulate_rbc(true_delta, true_alpha, rho, T, B, beta, shocks_z)\n        moments_obs = calculate_moments(y_obs, i_obs, hp_solver)\n\n        # SMM objective function\n        def smm_objective(theta):\n            delta, alpha = theta\n            y_sim, i_sim = simulate_rbc(delta, alpha, rho, T, B, beta, shocks_z)\n            \n            # If simulation fails (e.g., non-positive capital), return a large penalty\n            if np.any(np.isnan(y_sim)) or np.any(np.isinf(y_sim)):\n                return 1e12\n\n            moments_sim = calculate_moments(y_sim, i_sim, hp_solver)\n            \n            # Using identity weighting matrix, Q is sum of squared errors\n            return np.sum((moments_sim - moments_obs)**2)\n\n        # Initial guess for optimizer (midpoint of bounds)\n        x0 = [(b[0] + b[1]) / 2.0 for b in bounds]\n\n        # Run optimizer\n        result = minimize(smm_objective, x0, method='L-BFGS-B', bounds=bounds)\n\n        # Store estimated parameters rounded to 4 decimal places\n        estimated_params = np.round(result.x, 4).tolist()\n        all_results.append(estimated_params)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\".replace(\" \", \"\"))\n\ndef simulate_rbc(delta, alpha, rho, T, B, beta, shocks_z):\n    \"\"\"\n    Simulates the RBC model for T+B periods and returns the last T observations.\n    \"\"\"\n    total_len = T + B\n    y = np.zeros(total_len)\n    i = np.zeros(total_len)\n    k = np.zeros(total_len + 1)\n    z = np.zeros(total_len)\n\n    # Steady state investment share\n    s_star = (delta * alpha) / (1/beta - 1 + delta)\n\n    # Steady state capital as initial value\n    k_ss = (alpha / (1/beta - 1 + delta))**(1 / (1 - alpha))\n    k[0] = k_ss\n\n    for t in range(total_len):\n        if t == 0:\n            z[t] = shocks_z[t]\n        else:\n            z[t] = rho * z[t-1] + shocks_z[t]\n        \n        # Guard against non-positive capital which can occur with bad parameters\n        if k[t] = 0:\n            return np.full(T, np.nan), np.full(T, np.nan)\n\n        y[t] = np.exp(z[t]) * (k[t]**alpha)\n        i[t] = s_star * y[t]\n        k[t+1] = (1 - delta) * k[t] + i[t]\n\n    # Return time series after burn-in\n    return y[B:], i[B:]\n\ndef get_hp_solver(T, lambd):\n    \"\"\"\n    Constructs and factorizes the HP filter matrix A(lambda).\n    Returns a solver object.\n    \"\"\"\n    # Main diagonal\n    diag_0 = np.ones(T)\n    diag_0[0] = 1.0 + lambd\n    diag_0[1] = 1.0 + 5.0 * lambd\n    diag_0[T-2] = 1.0 + 5.0 * lambd\n    diag_0[T-1] = 1.0 + lambd\n    diag_0[2:T-2] = 1.0 + 6.0 * lambd\n\n    # First off-diagonal\n    diag_1 = np.full(T-1, -4.0 * lambd)\n    diag_1[0] = -2.0 * lambd\n    diag_1[T-2] = -2.0 * lambd\n\n    # Second off-diagonal\n    diag_2 = np.full(T-2, lambd)\n\n    mat = diags(\n        [diag_2, diag_1, diag_0, diag_1, diag_2],\n        [2, 1, 0, -1, -2],\n        format='csc'\n    )\n    return splu(mat)\n\ndef calculate_moments(y, i, hp_solver):\n    \"\"\"\n    Calculates the four moments from output and investment series.\n    \"\"\"\n    # HP filter\n    tau_y = hp_solver.solve(y)\n    c_y = y - tau_y\n    tau_i = hp_solver.solve(i)\n    c_i = i - tau_i\n\n    # Moment 1: Std dev of output cycle\n    m1 = np.std(c_y, ddof=1)\n    \n    # Moment 2: Std dev of investment cycle\n    m2 = np.std(c_i, ddof=1)\n\n    # Moment 3: Mean of investment share\n    m3 = np.mean(i / y)\n\n    # Moment 4: Autocorrelation of output cycle\n    m4 = np.corrcoef(c_y[1:], c_y[:-1])[0, 1]\n\n    return np.array([m1, m2, m3, m4])\n\nsolve()\n```", "id": "2430572"}, {"introduction": "This final practice addresses a critical and subtle challenge in SMM and numerical optimization: the problem of identification and multi-modal objective functions. A successful estimation not only depends on correct code but also on whether the model's parameters are uniquely identified by the chosen moments. Through a cleverly designed yet simple model, this exercise [@problem_id:2430609] demonstrates how the SMM objective function can possess multiple local minima, causing the final estimate to depend heavily on the optimizer's starting point. This provides a crucial lesson on the importance of exploring the parameter space and understanding the identification properties of your model.", "problem": "You are asked to construct and analyze a one-parameter structural model in which the Simulated Method of Moments (SMM) objective function is multi-modal. Consider the following setup. Let the observed data be generated by the data generating process (DGP)\n$$\ny_t^{\\text{obs}} \\;=\\; \\sin(\\theta_0)\\,x_t \\;+\\; \\varepsilon_t,\\quad t=1,\\dots,n,\n$$\nwhere $x_t \\sim \\mathcal{N}(0,1)$ and $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$ are independent draws. The unknown scalar structural parameter $\\theta$ is measured in radians. For any candidate value $\\theta$, define a simulation mapping using the same sequences of shocks as the observed data (i.e., common random numbers) by\n$$\ny_t(\\theta) \\;=\\; \\sin(\\theta)\\,x_t \\;+\\; \\varepsilon_t,\\quad t=1,\\dots,n.\n$$\nDefine the moment vector as\n$$\nm(\\theta) \\;=\\; \\begin{bmatrix}\n\\frac{1}{n}\\sum_{t=1}^n y_t(\\theta)^2 \\\\\n\\frac{1}{n}\\sum_{t=1}^n y_t(\\theta)^4\n\\end{bmatrix},\n\\qquad\nm^{\\text{obs}} \\;=\\; \\begin{bmatrix}\n\\frac{1}{n}\\sum_{t=1}^n \\big(y_t^{\\text{obs}}\\big)^2 \\\\\n\\frac{1}{n}\\sum_{t=1}^n \\big(y_t^{\\text{obs}}\\big)^4\n\\end{bmatrix}.\n$$\nLet the SMM objective be\n$$\nJ(\\theta) \\;=\\; \\big(m(\\theta)-m^{\\text{obs}}\\big)^\\top W \\big(m(\\theta)-m^{\\text{obs}}\\big),\n$$\nwhere $W=\\text{diag}(w_1,w_2)$ is a given diagonal weighting matrix with positive diagonal entries. You must restrict $\\theta$ to the closed interval $[-4,4]$ (radians). For each test case below, you must:\n- Generate $x_t$ and $\\varepsilon_t$ using the specified pseudorandom seed and sample size $n$.\n- Construct the observed data using the specified $\\theta_0$ and $\\sigma$.\n- Using the same sequences $\\{x_t\\}$ and $\\{\\varepsilon_t\\}$ for all $\\theta$, define $J(\\theta)$ on $[-4,4]$.\n- Starting from each provided initial value $s$ (in radians), compute a local minimizer $\\widehat{\\theta}(s)\\in[-4,4]$ of $J(\\theta)$.\n\nThe test suite consists of three cases that vary sample size, noise level, weighting, and the true parameter to probe the multi-modality of the SMM objective:\n\n- Test case A:\n  - $n=1000$\n  - $\\theta_0=1.0$\n  - $\\sigma=0.3$\n  - $W=\\text{diag}(1.0,1.0)$\n  - Seed $=202311$\n  - Starting values (in radians): $[0.10,\\,2.50,\\,-3.00]$\n\n- Test case B:\n  - $n=200$\n  - $\\theta_0=1.0$\n  - $\\sigma=1.0$\n  - $W=\\text{diag}(1.0,10.0)$\n  - Seed $=13579$\n  - Starting values (in radians): $[0.20,\\,3.10,\\,-2.00]$\n\n- Test case C:\n  - $n=1000$\n  - $\\theta_0=2.8$\n  - $\\sigma=0.3$\n  - $W=\\text{diag}(0.5,2.0)$\n  - Seed $=77$\n  - Starting values (in radians): $[2.70,\\,0.20,\\,-0.50]$\n\nAngle units must be in radians. There are no physical units in the final answers.\n\nYour program must compute, for each test case, the three local minimizers $\\widehat{\\theta}(s)$ corresponding to the three specified starting values. The final output must aggregate the results across all test cases into a single line, formatted as a comma-separated list enclosed in square brackets, in the order of the starting values as listed above for each test case. Concretely, the output must be\n$$\n\\big[\\widehat{\\theta}_A(s_1),\\;\\widehat{\\theta}_A(s_2),\\;\\widehat{\\theta}_A(s_3),\\;\\widehat{\\theta}_B(s_1),\\;\\widehat{\\theta}_B(s_2),\\;\\widehat{\\theta}_B(s_3),\\;\\widehat{\\theta}_C(s_1),\\;\\widehat{\\theta}_C(s_2),\\;\\widehat{\\theta}_C(s_3)\\big],\n$$\nwhere the subscript indicates the test case. Each entry must be a real number (float). The program must not read any input and must use the specified seeds exactly as provided to ensure deterministic results. The angle unit is radians. The output must be a single line as specified with no additional text.", "solution": "The core of the problem is to implement the Simulated Method of Moments (SMM) objective function $J(\\theta)$ and find its local minima for several parameterizations. This exercise demonstrates how the choice of moments can lead to a multi-modal objective function, where the final estimate depends on the optimizer's starting point. The multi-modality arises from a non-injective mapping from the structural parameter $\\theta$ to the moments of the simulated data.\n\nLet us first examine the population moments, which are the theoretical expectations of the sample moments as the sample size $n \\to \\infty$. The simulated variable $y_t(\\theta)$ is the sum of two independent, zero-mean normal random variables: $\\sin(\\theta)x_t \\sim \\mathcal{N}(0, \\sin^2(\\theta))$ and $\\varepsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$. Therefore, $y_t(\\theta) \\sim \\mathcal{N}(0, \\sigma_y^2(\\theta))$, where the variance is $\\sigma_y^2(\\theta) = \\sin^2(\\theta) + \\sigma^2$.\n\nThe chosen moments are the second and fourth raw moments of $y_t(\\theta)$. Their population counterparts are derived from the properties of the normal distribution:\n- The second raw moment: $\\mathbb{E}[y_t(\\theta)^2] = \\text{Var}(y_t(\\theta)) = \\sin^2(\\theta) + \\sigma^2$.\n- The fourth raw moment: $\\mathbb{E}[y_t(\\theta)^4] = 3 \\cdot (\\text{Var}(y_t(\\theta)))^2 = 3(\\sin^2(\\theta) + \\sigma^2)^2$.\n\nBoth population moments depend only on $\\sin^2(\\theta)$. The SMM estimator seeks a value $\\widehat{\\theta}$ that minimizes the distance between the simulated moments $m(\\theta)$ and the observed moments $m^{\\text{obs}}$. In a large sample, the objective function $J(\\theta)$ will be minimized when the population moments match, which requires:\n$$\n\\sin^2(\\theta) = \\sin^2(\\theta_0).\n$$\nThis condition implies $|\\sin(\\theta)| = |\\sin(\\theta_0)|$. Due to the periodic and symmetric nature of the sine function, multiple values of $\\theta$ within the interval $[-4, 4]$ can satisfy this equation. For instance, if $\\theta_0$ is a solution, then so are $-\\theta_0$, $\\pi - \\theta_0$, and $\\theta_0 - \\pi$, provided they lie within the domain. For a finite sample, the objective function surface is perturbed by sampling noise, but it will still exhibit local minima near these multiple population-level solutions. This is the fundamental reason for the multi-modality of the SMM objective function in this model.\n\nThe algorithm to solve this problem is as follows:\n1. For each test case, initialize a pseudorandom number generator with the specified seed and generate the common random shocks $\\{x_t\\}_{t=1}^n$ and $\\{\\varepsilon_t\\}_{t=1}^n$.\n2. Construct the observed data series $y_t^{\\text{obs}} = \\sin(\\theta_0) x_t + \\varepsilon_t$ and compute the observed moment vector $m^{\\text{obs}}$.\n3. Define the objective function $J(\\theta)$. For a given $\\theta$, this function calculates the simulated data $y_t(\\theta)$, the simulated moment vector $m(\\theta)$, and the quadratic form $J(\\theta) = (m(\\theta) - m^{\\text{obs}})^\\top W (m(\\theta) - m^{\\text{obs}})$.\n4. For each specified starting value $s$, use a numerical optimization algorithm (L-BFGS-B) to find a local minimizer $\\widehat{\\theta}(s)$ of $J(\\theta)$ on the interval $[-4, 4]$.\n5. Aggregate all found minimizers into a single list and format it as required for the final output.\nThis procedure is implemented in the provided Python code using the `numpy` and `scipy` libraries.", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Solves for the local minimizers of a multi-modal SMM objective function\n    for three distinct test cases.\n    \"\"\"\n    # Define the test cases as specified in the problem statement.\n    test_cases = [\n        # Case A\n        {\n            \"n\": 1000, \"theta0\": 1.0, \"sigma\": 0.3, \"W_diag\": [1.0, 1.0],\n            \"seed\": 202311, \"starts\": [0.10, 2.50, -3.00]\n        },\n        # Case B\n        {\n            \"n\": 200, \"theta0\": 1.0, \"sigma\": 1.0, \"W_diag\": [1.0, 10.0],\n            \"seed\": 13579, \"starts\": [0.20, 3.10, -2.00]\n        },\n        # Case C\n        {\n            \"n\": 1000, \"theta0\": 2.8, \"sigma\": 0.3, \"W_diag\": [0.5, 2.0],\n            \"seed\": 77, \"starts\": [2.70, 0.20, -0.50]\n        }\n    ]\n\n    all_results = []\n    bounds = [(-4.0, 4.0)]\n\n    def compute_moments(y_data):\n        \"\"\"Computes the second and fourth moments of the data.\"\"\"\n        m1 = np.mean(y_data**2)\n        m2 = np.mean(y_data**4)\n        return np.array([m1, m2])\n\n    for case in test_cases:\n        n = case[\"n\"]\n        theta0 = case[\"theta0\"]\n        sigma = case[\"sigma\"]\n        W_diag = np.array(case[\"W_diag\"])\n        seed = case[\"seed\"]\n        starts = case[\"starts\"]\n\n        # 1. Generate shocks using the specified seed.\n        rng = np.random.default_rng(seed)\n        x_shocks = rng.normal(loc=0.0, scale=1.0, size=n)\n        eps_shocks = rng.normal(loc=0.0, scale=sigma, size=n)\n\n        # 2. Generate observed data and compute observed moments.\n        y_obs = np.sin(theta0) * x_shocks + eps_shocks\n        m_obs = compute_moments(y_obs)\n\n        # 3. Define the SMM objective function J(theta).\n        def smm_objective(theta):\n            # This function uses variables from the outer scope:\n            # x_shocks, eps_shocks, m_obs, W_diag.\n            # Convert theta to float to ensure numpy functions work as expected.\n            theta_val = float(theta)\n\n            # Simulate data with the candidate theta\n            y_sim = np.sin(theta_val) * x_shocks + eps_shocks\n\n            # Compute simulated moments\n            m_sim = compute_moments(y_sim)\n\n            # Compute moment differences\n            g = m_sim - m_obs\n\n            # Compute the SMM objective value\n            J = (g**2) @ W_diag\n            return J\n\n        # 4. Find local minimizers for each starting value.\n        case_results = []\n        for s in starts:\n            res = minimize(\n                smm_objective,\n                x0=s,\n                method='L-BFGS-B',\n                bounds=bounds\n            )\n            # The result is in res.x, which is an array. Extract the scalar.\n            case_results.append(res.x[0])\n        \n        all_results.extend(case_results)\n\n    # 5. Format and print the final output as a comma-separated list in brackets.\n    # The output format must be exact, with no extra text or newlines.\n    print(f\"[{','.join(f'{r:.8f}' for r in all_results)}]\")\n\nsolve()\n```", "id": "2430609"}]}