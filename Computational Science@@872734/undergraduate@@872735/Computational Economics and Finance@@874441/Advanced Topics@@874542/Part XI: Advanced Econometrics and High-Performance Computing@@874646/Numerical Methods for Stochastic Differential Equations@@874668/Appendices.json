{"hands_on_practices": [{"introduction": "Before diving into complex applications, it is crucial to understand the fundamental trade-off between computational simplicity and accuracy. This first practice provides a direct comparison between the widely used Euler-Maruyama scheme and an exact sampling method for the Ornstein-Uhlenbeck process. By quantifying the Mean-Squared Error under a fixed computational budget, you will gain a concrete understanding of why and by how much an exact solution, when available, outperforms a basic numerical approximation [@problem_id:2415924].", "problem": "Consider the mean-reverting short-rate model widely used in computational economics and finance, the Ornstein–Uhlenbeck process (also called the Vasicek model), defined by the stochastic differential equation (SDE)\n$$\ndX_t = \\kappa(\\theta - X_t)\\,dt + \\sigma\\,dW_t,\\quad X_0 = x_0,\n$$\nwhere $X_t$ is the state variable (for instance, a short interest rate), $\\kappa  0$ is the mean-reversion speed, $\\theta$ is the long-run mean, $\\sigma  0$ is the diffusion coefficient, and $W_t$ is a standard Brownian motion. Your task is to demonstrate numerically, from first principles, that when estimating the expectation $E[X_T]$ at a fixed time $T$, sampling the exact solution at discrete times is more efficient than using the Euler–Maruyama scheme, when efficiency is measured by mean-squared error per unit of simulation cost under a fixed computational budget.\n\nWork from the following fundamental base:\n- The definition of an Itô stochastic differential equation and Itô integral for $dX_t = a(X_t,t)\\,dt + b(X_t,t)\\,dW_t$.\n- The Ornstein–Uhlenbeck process is a linear SDE; linear first-order SDEs can be solved using integrating factors.\n- The Euler–Maruyama scheme is obtained by time-discretizing the SDE using the definition of the Itô integral over a small interval $[t_n,t_{n+1}]$ with step size $\\Delta$ and approximating the drift and diffusion at the left endpoint.\n\nTasks:\n1) Derive, using an integrating factor, the exact discrete-time transition of the Ornstein–Uhlenbeck process over a single step of size $\\Delta$, that is, obtain an expression for $X_{t+\\Delta}$ given $X_t$ as an affine function of $X_t$ plus a Gaussian innovation. Express its mean and variance as functions of $\\kappa$, $\\theta$, $\\sigma$, and $\\Delta$.\n\n2) Derive the Euler–Maruyama update for one step of size $\\Delta$ for this SDE by applying the definition of the Itô integral over $[t_n,t_{n+1}]$ and approximating the drift and diffusion at $t_n$.\n\n3) For a fixed terminal time $T$, define a computational budget measured by the total number of Gaussian random variables generated:\n$$\nC = M \\times N,\n$$\nwhere $N = T/\\Delta$ is the number of time steps per path (assume $T/\\Delta$ is an integer) and $M$ is the number of simulated paths. For a fair comparison at fixed cost, you must hold $C$ constant while varying $\\Delta$, setting $M = \\lfloor C/N \\rfloor$.\n\n4) For each parameter configuration below, and for each time step $\\Delta$ given for that configuration, simulate $M$ independent paths up to time $T$ using:\n- The exact discrete-time transition you derived in Task $1$ (exact sampling).\n- The Euler–Maruyama scheme you derived in Task $2$ (Euler scheme).\n\nUse the same Gaussian innovations for both methods at each step and for each path to ensure a fair, variance-reduced comparison. For each configuration and $\\Delta$, estimate the mean-squared error (MSE) of the Monte Carlo estimator of $E[X_T]$ by\n$$\n\\widehat{\\mathrm{MSE}} = \\left(\\overline{X}_T - \\mu_T\\right)^2 + \\frac{S_T^2}{M},\n$$\nwhere $\\overline{X}_T$ is the sample mean of $X_T$ across $M$ paths, $S_T^2$ is the sample variance of $X_T$ across $M$ paths, and $\\mu_T = E[X_T]$ is the exact mean implied by the exact solution of the SDE at time $T$. Report, for each configuration and $\\Delta$, the ratio\n$$\nR = \\frac{\\widehat{\\mathrm{MSE}}_{\\mathrm{Euler}}}{\\widehat{\\mathrm{MSE}}_{\\mathrm{Exact}}},\n$$\nat the same computational budget $C$.\n\n5) Randomness control and fairness:\n- For each configuration index $i \\in \\{0,1,2\\}$, use a base integer seed $s_i$. For the $j$-th step size in that configuration, use seed $s_i + j$ to generate a matrix of independent standard normal random variables $Z \\in \\mathbb{R}^{M \\times N}$. Reuse the same $Z$ for both the exact and Euler methods within that configuration and step size.\n\nImplementation and numerical specifications:\n- No physical units are involved in this problem.\n- Angles are not involved in this problem.\n- Percentages are not involved; any fractional quantities must be expressed as decimals or fractions.\n- The final program must be a single, complete, runnable program that performs all computations and produces the specified output with no user input.\n\nTest suite of parameter configurations:\n- Configuration $0$: $\\kappa = 1.2$, $\\theta = 0.04$, $\\sigma = 0.25$, $x_0 = 0.03$, $T = 1.0$, step sizes $\\Delta \\in \\{0.2, 0.05, 0.01\\}$, base seed $s_0 = 13579$.\n- Configuration $1$: $\\kappa = 3.0$, $\\theta = 0.02$, $\\sigma = 0.15$, $x_0 = 0.08$, $T = 0.5$, step sizes $\\Delta \\in \\{0.1, 0.05, 0.01\\}$, base seed $s_1 = 24680$.\n- Configuration $2$: $\\kappa = 0.3$, $\\theta = 0.01$, $\\sigma = 0.05$, $x_0 = 0.00$, $T = 2.0$, step sizes $\\Delta \\in \\{0.4, 0.1, 0.02\\}$, base seed $s_2 = 11223$.\n\nIn all configurations, set the computational budget to the same value $C = 2{,}000{,}000$, and set $M = \\lfloor C/N \\rfloor$.\n\nFinal output specification:\n- Your program should produce a single line of output containing the $9$ ratios $R$ (three per configuration, in the order of configurations and step sizes as listed above) as a comma-separated list enclosed in square brackets, with each ratio rounded to $6$ decimal places. For example, an output with three ratios would look like $[1.234000,1.050000,1.002345]$.", "solution": "The problem as stated is valid. It is scientifically grounded in the established theory of stochastic differential equations and numerical analysis, it is well-posed with all necessary parameters and conditions provided, and it is objective, relying on precise mathematical definitions. I will proceed with the solution.\n\nThe problem requires a numerical comparison between two methods for simulating the Ornstein-Uhlenbeck process, which is described by the stochastic differential equation (SDE):\n$$ dX_t = \\kappa(\\theta - X_t)\\,dt + \\sigma\\,dW_t, \\quad X_0 = x_0 $$\nwhere $\\kappa  0$, $\\theta$, and $\\sigma  0$ are constants. This is a linear SDE.\n\nFirst, I will derive the required simulation schemes.\n\n**1. Derivation of the Exact Discrete-Time Transition**\n\nThe SDE can be rewritten as:\n$$ dX_t + \\kappa X_t dt = \\kappa \\theta dt + \\sigma dW_t $$\nThis is a first-order linear differential equation. We employ an integrating factor, $I(t) = e^{\\int \\kappa dt} = e^{\\kappa t}$. Multiplying the SDE by $e^{\\kappa t}$ gives:\n$$ e^{\\kappa t} dX_t + \\kappa e^{\\kappa t} X_t dt = \\kappa \\theta e^{\\kappa t} dt + \\sigma e^{\\kappa t} dW_t $$\nBy the Itô product rule, the left-hand side is the differential of $e^{\\kappa t} X_t$:\n$$ d(e^{\\kappa t} X_t) = \\kappa \\theta e^{\\kappa t} dt + \\sigma e^{\\kappa t} dW_t $$\nWe integrate this expression from an arbitrary time $t$ to $t+\\Delta$:\n$$ \\int_t^{t+\\Delta} d(e^{\\kappa s} X_s) = \\int_t^{t+\\Delta} \\kappa \\theta e^{\\kappa s} ds + \\int_t^{t+\\Delta} \\sigma e^{\\kappa s} dW_s $$\n$$ e^{\\kappa (t+\\Delta)} X_{t+\\Delta} - e^{\\kappa t} X_t = \\kappa \\theta \\left[ \\frac{e^{\\kappa s}}{\\kappa} \\right]_t^{t+\\Delta} + \\sigma \\int_t^{t+\\Delta} e^{\\kappa s} dW_s $$\n$$ e^{\\kappa (t+\\Delta)} X_{t+\\Delta} = e^{\\kappa t} X_t + \\theta (e^{\\kappa (t+\\Delta)} - e^{\\kappa t}) + \\sigma \\int_t^{t+\\Delta} e^{\\kappa s} dW_s $$\nMultiplying by $e^{-\\kappa(t+\\Delta)}$, we isolate $X_{t+\\Delta}$:\n$$ X_{t+\\Delta} = X_t e^{-\\kappa\\Delta} + \\theta (1 - e^{-\\kappa\\Delta}) + \\sigma \\int_t^{t+\\Delta} e^{-\\kappa(t+\\Delta - s)} dW_s $$\nThe stochastic integral term is an Itô integral of a deterministic function, which results in a normally distributed random variable with mean zero. Its variance is calculated using the Itô isometry:\n$$ \\mathrm{Var}\\left( \\int_t^{t+\\Delta} e^{-\\kappa(t+\\Delta - s)} dW_s \\right) = \\int_t^{t+\\Delta} \\left( e^{-\\kappa(t+\\Delta - s)} \\right)^2 ds = \\int_t^{t+\\Delta} e^{-2\\kappa(t+\\Delta - s)} ds $$\nWith a change of variable $u = s - t$, this becomes:\n$$ \\int_0^{\\Delta} e^{-2\\kappa(\\Delta - u)} du = e^{-2\\kappa\\Delta} \\int_0^{\\Delta} e^{2\\kappa u} du = e^{-2\\kappa\\Delta} \\left[ \\frac{e^{2\\kappa u}}{2\\kappa} \\right]_0^{\\Delta} = \\frac{1 - e^{-2\\kappa\\Delta}}{2\\kappa} $$\nTherefore, the stochastic integral can be represented as $\\sqrt{\\frac{1 - e^{-2\\kappa\\Delta}}{2\\kappa}} Z_{t+\\Delta}$, where $Z_{t+\\Delta} \\sim \\mathcal{N}(0, 1)$.\nThe exact discrete-time transition rule is:\n$$ X_{t+\\Delta} = X_t e^{-\\kappa\\Delta} + \\theta(1 - e^{-\\kappa\\Delta}) + \\sigma \\sqrt{\\frac{1 - e^{-2\\kappa\\Delta}}{2\\kappa}} Z_{t+\\Delta} $$\nGiven $X_t$, the conditional distribution of $X_{t+\\Delta}$ is Gaussian with:\n- Mean: $E[X_{t+\\Delta} | X_t] = X_t e^{-\\kappa\\Delta} + \\theta(1 - e^{-\\kappa\\Delta})$\n- Variance: $\\mathrm{Var}(X_{t+\\Delta} | X_t) = \\sigma^2 \\frac{1 - e^{-2\\kappa\\Delta}}{2\\kappa}$\n\n**2. Derivation of the Euler–Maruyama Update**\n\nThe Euler–Maruyama scheme approximates the SDE by discretizing its integral form over a small time step $\\Delta = t_{n+1} - t_n$.\n$$ X_{t_{n+1}} - X_{t_n} = \\int_{t_n}^{t_{n+1}} \\kappa(\\theta - X_s) ds + \\int_{t_n}^{t_{n+1}} \\sigma dW_s $$\nThe scheme approximates the integrands as constant over the interval $[t_n, t_{n+1}]$, evaluated at the left endpoint $t_n$:\n$$ \\int_{t_n}^{t_{n+1}} \\kappa(\\theta - X_s) ds \\approx \\kappa(\\theta - X_{t_n})\\Delta $$\n$$ \\int_{t_n}^{t_{n+1}} \\sigma dW_s = \\sigma (W_{t_{n+1}} - W_{t_n}) = \\sigma \\sqrt{\\Delta} Z_{n+1} $$\nwhere $Z_{n+1} \\sim \\mathcal{N}(0, 1)$. Combining these gives the update rule, where we denote $X_n \\equiv X_{t_n}$:\n$$ X_{n+1} = X_n + \\kappa(\\theta - X_n)\\Delta + \\sigma\\sqrt{\\Delta}Z_{n+1} $$\nThis is the required Euler-Maruyama discretization for the Ornstein-Uhlenbeck process.\n\n**3. Numerical Experiment Design and Evaluation**\n\nThe objective is to compare the efficiency of the exact sampling method and the Euler-Maruyama scheme. Efficiency is measured by the mean-squared error (MSE) of the Monte Carlo estimator for $E[X_T]$ under a fixed computational budget $C$.\n\nThe computational budget is defined as $C = M \\times N$, where $M$ is the number of simulated paths and $N$ is the number of time steps per path. We are given $T$ and a step size $\\Delta$, so $N = T/\\Delta$. The number of paths is then $M = \\lfloor C/N \\rfloor$. This setup ensures that for any choice of $\\Delta$, the total number of generated Gaussian random numbers is approximately constant.\n\nFor each simulation run (defined by a set of parameters and a step size $\\Delta$), we perform the following:\n1.  Generate an $M \\times N$ matrix of independent standard normal deviates, $Z$. This matrix is used for both the exact and Euler simulations to ensure a fair comparison with reduced variance.\n2.  Simulate $M$ paths from $t=0$ to $t=T$ using both the exact transition and the Euler-Maruyama scheme, starting from $X_0 = x_0$.\n3.  For each method, this produces a vector of $M$ final states at time $T$. We compute the sample mean $\\overline{X}_T$ and sample variance $S_T^2$.\n4.  The true analytical mean of the process at time $T$ is obtained by solving the ODE for the expectation, $d\\mu_t/dt = \\kappa(\\theta - \\mu_t)$, which yields $\\mu_T = E[X_T] = \\theta + (x_0 - \\theta)e^{-\\kappa T}$.\n5.  The estimated MSE for each method is calculated using the prescribed formula:\n    $$ \\widehat{\\mathrm{MSE}} = \\left(\\overline{X}_T - \\mu_T\\right)^2 + \\frac{S_T^2}{M} $$\n    The term $(\\overline{X}_T - \\mu_T)^2$ captures the squared error of the sample mean, which is composed of both bias and statistical fluctuation. The term $S_T^2/M$ is an estimate of the variance of the sample mean.\n6.  Finally, we compute the ratio of the estimated MSEs:\n    $$ R = \\frac{\\widehat{\\mathrm{MSE}}_{\\mathrm{Euler}}}{\\widehat{\\mathrm{MSE}}_{\\mathrm{Exact}}} $$\nA ratio $R  1$ indicates that the Euler-Maruyama scheme is less efficient (produces a higher MSE for the same computational cost) than the exact sampling method. The weak convergence error (bias) of the Euler method, which grows with $\\Delta$, is expected to be the primary driver of this difference in efficiency. The exact sampler is, by definition, free of this bias.\n\nThe following program implements this entire procedure for the specified test configurations.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by simulating the Ornstein-Uhlenbeck process using\n    the exact method and the Euler-Maruyama scheme, and computes the ratio\n    of their Mean-Squared Errors.\n    \"\"\"\n\n    # Test suite of parameter configurations.\n    test_cases = [\n        # Configuration 0\n        {\n            \"params\": {\"kappa\": 1.2, \"theta\": 0.04, \"sigma\": 0.25, \"x0\": 0.03, \"T\": 1.0},\n            \"deltas\": [0.2, 0.05, 0.01],\n            \"base_seed\": 13579\n        },\n        # Configuration 1\n        {\n            \"params\": {\"kappa\": 3.0, \"theta\": 0.02, \"sigma\": 0.15, \"x0\": 0.08, \"T\": 0.5},\n            \"deltas\": [0.1, 0.05, 0.01],\n            \"base_seed\": 24680\n        },\n        # Configuration 2\n        {\n            \"params\": {\"kappa\": 0.3, \"theta\": 0.01, \"sigma\": 0.05, \"x0\": 0.00, \"T\": 2.0},\n            \"deltas\": [0.4, 0.1, 0.02],\n            \"base_seed\": 11223\n        }\n    ]\n\n    C = 2_000_000\n    results = []\n\n    for case_config in test_cases:\n        p = case_config[\"params\"]\n        kappa, theta, sigma, x0, T = p[\"kappa\"], p[\"theta\"], p[\"sigma\"], p[\"x0\"], p[\"T\"]\n        \n        # Calculate the true mean at time T for MSE calculation.\n        mu_T = theta + (x0 - theta) * np.exp(-kappa * T)\n\n        for j, delta in enumerate(case_config[\"deltas\"]):\n            # Set up simulation parameters\n            N = int(T / delta)\n            M = C // N\n            seed = case_config[\"base_seed\"] + j\n            \n            # Generate all standard normal random variables at once\n            rng = np.random.default_rng(seed)\n            Z = rng.standard_normal(size=(M, N))\n\n            # --- Exact Simulation ---\n            X_exact = np.full(M, x0, dtype=np.float64)\n            # Precompute constants for the exact update rule\n            e_neg_kd = np.exp(-kappa * delta)\n            var_term = sigma * np.sqrt((1 - np.exp(-2 * kappa * delta)) / (2 * kappa))\n            for i in range(N):\n                X_exact = X_exact * e_neg_kd + theta * (1 - e_neg_kd) + var_term * Z[:, i]\n\n            # --- Euler-Maruyama Simulation ---\n            X_euler = np.full(M, x0, dtype=np.float64)\n            # Precompute constant for the Euler update rule\n            sqrt_delta = np.sqrt(delta)\n            for i in range(N):\n                X_euler = X_euler + kappa * (theta - X_euler) * delta + sigma * sqrt_delta * Z[:, i]\n            \n            # --- Calculate MSE for both methods ---\n            # MSE for Exact method\n            mean_exact = np.mean(X_exact)\n            var_exact = np.var(X_exact, ddof=1) if M > 1 else 0.0\n            mse_exact = (mean_exact - mu_T)**2 + var_exact / M\n\n            # MSE for Euler method\n            mean_euler = np.mean(X_euler)\n            var_euler = np.var(X_euler, ddof=1) if M > 1 else 0.0\n            mse_euler = (mean_euler - mu_T)**2 + var_euler / M\n\n            # Avoid division by zero, although MSE_exact should be positive\n            if mse_exact > 0:\n                ratio = mse_euler / mse_exact\n            else:\n                # If exact MSE is zero, Euler MSE must also be zero for a ratio of 1\n                ratio = 1.0 if mse_euler == 0 else np.inf\n            \n            results.append(f\"{ratio:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\n# Execute the simulation and print the results.\nsolve()\n```", "id": "2415924"}, {"introduction": "The choice of stochastic integral—Itô or Stratonovich—is one of the most subtle yet consequential decisions in modeling with SDEs. This exercise moves beyond simple accuracy to explore how this choice impacts the qualitative behavior of a system, such as its long-term stability. You will discover through both analytical derivation and numerical simulation that the two interpretations can lead to opposite conclusions, turning a stable system into an unstable one, thereby highlighting the critical importance of matching the mathematical model to the underlying phenomenon [@problem_id:2415964].", "problem": "You are asked to design, analyze, and verify numerically a case where the Itô and Stratonovich interpretations of the same symbolic stochastic differential equation yield opposite long-term stability assessments. Work strictly within the parametric family of linear, multiplicative-noise models used in computational economics and finance:\n$$\ndX_t = \\alpha\\,X_t\\,dt + \\beta\\,X_t\\,\\star\\,dW_t, \n$$\nwhere $X_t$ is a real-valued state, $\\alpha \\in \\mathbb{R}$ is a constant drift coefficient, $\\beta \\in \\mathbb{R}$ is a constant diffusion loading, $W_t$ is a standard Wiener process, and $\\star$ denotes either the Itô interpretation (write $dW_t$) or the Stratonovich interpretation (write $\\circ\\,dW_t$). Your goal is to show, from first principles, why the long-run almost-sure growth rate of $X_t$ depends on interpretation, construct a parameter set where the stability conclusions are opposite, and then verify this numerically.\n\nStarting point for your reasoning:\n- Definitions of the Itô and Stratonovich integrals and their distinct chain rules.\n- The Itô-to-Stratonovich conversion rule for stochastic integrals applied to sufficiently smooth integrands.\n- The definition of almost-sure long-run growth rate of $X_t$, namely the limit of $\\frac{1}{T}\\ln|X_T|$ as $T \\to \\infty$, when this limit exists.\n\nYour tasks:\n1) Derive, from the above fundamentals and without invoking any pre-packaged “shortcut” formulas, explicit expressions for the almost-sure long-run growth rate under the Itô interpretation and under the Stratonovich interpretation for the family $dX_t = \\alpha X_t\\,dt + \\beta X_t\\,\\star\\,dW_t$.\n2) Identify constant coefficients $\\alpha$ and $\\beta$ for which the Itô interpretation predicts long-run stability to $0$ (negative growth rate) while the Stratonovich interpretation predicts long-run instability (positive growth rate). Explain your choice logically using your derived expressions.\n3) Implement two numerical schemes to approximate sample paths and empirical growth rates:\n   - For the Itô interpretation: the Euler–Maruyama method, applied to $dX_t = \\alpha X_t\\,dt + \\beta X_t\\,dW_t$.\n   - For the Stratonovich interpretation: a strong order-$1$ Stratonovich-consistent method, such as the stochastic Heun method, applied to $dX_t = \\alpha X_t\\,dt + \\beta X_t \\circ dW_t$.\n   Use a single path (no ensemble averaging), with $X_0 = 1$, time horizon $T$, and uniform step size $\\Delta t$. Generate the Brownian increments $\\Delta W_n \\sim \\mathcal{N}(0,\\Delta t)$ with a fixed random seed to ensure reproducibility. Compute the empirical long-run growth rate as $\\widehat{g} = \\frac{1}{T}\\ln|X_T|$ for each interpretation.\n\n4) Classify stability numerically for each interpretation using a three-way decision with tolerance $\\varepsilon$: “stable” if $\\widehat{g}  -\\varepsilon$, “unstable” if $\\widehat{g}  \\varepsilon$, and “neutral” otherwise.\n\n5) Compare the numerical classification against the theoretical classification you derived in Task 1), and return a boolean indicating agreement for each test case.\n\nSimulation parameters to use for all test cases:\n- Initial condition: $X_0 = 1$.\n- Time horizon: $T = 1000$.\n- Time step: $\\Delta t = 10^{-3}$.\n- Tolerance for classification: $\\varepsilon = 2\\times 10^{-2}$.\n- Pseudorandom number generator seed: $12345$.\n- Angle or physical units are not applicable here.\n\nTest suite (five cases), each given as $(\\alpha,\\beta)$:\n- Case A (opposite-stability target): $(\\alpha,\\beta) = (0.05, 0.4)$.\n- Case B (both stable): $(\\alpha,\\beta) = (-0.05, 0.2)$.\n- Case C (both unstable): $(\\alpha,\\beta) = (0.2, 0.1)$.\n- Case D (Itô near-neutral boundary): $(\\alpha,\\beta) = (0.08, 0.4)$.\n- Case E (Stratonovich near-neutral boundary): $(\\alpha,\\beta) = (0.0, 0.4)$.\n\nRequired outputs:\n- For each case, compute the empirical growth rates under both interpretations using the specified numerical schemes, classify them with tolerance $\\varepsilon$, compare to your theoretical classification from Task 1), and output a boolean for agreement.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., “[True,False,True,True,False]”).\n\nNotes on numerical implementation:\n- For the Itô Euler–Maruyama step applied to $dX_t = \\alpha X_t\\,dt + \\beta X_t\\,dW_t$, the one-step update over $\\Delta t$ with increment $\\Delta W$ is $X_{n+1} = X_n + \\alpha X_n \\Delta t + \\beta X_n \\Delta W$.\n- For a Stratonovich-consistent stochastic Heun step applied to $dX_t = \\alpha X_t\\,dt + \\beta X_t \\circ dW_t$, first form the predictor $X_n^\\ast = X_n + \\alpha X_n \\Delta t + \\beta X_n \\Delta W$, then $X_{n+1} = X_n + \\tfrac{1}{2}\\left[\\alpha X_n + \\alpha X_n^\\ast\\right]\\Delta t + \\tfrac{1}{2}\\left[\\beta X_n + \\beta X_n^\\ast\\right]\\Delta W$.\n\nFinal output format:\n- A single line with a Python-style list of booleans in the exact order of the five test cases above, no spaces, e.g., “[True,True,False,True,True]”.", "solution": "The problem posed is a valid exercise in stochastic calculus and numerical methods for stochastic differential equations (SDEs). It is scientifically grounded, well-posed, objective, and complete. All parameters and methods are specified, allowing for a unique and reproducible solution. I will proceed with the derivation and numerical verification.\n\nThe problem centers on the stochastic differential equation for geometric Brownian motion:\n$$\ndX_t = \\alpha\\,X_t\\,dt + \\beta\\,X_t\\,\\star\\,dW_t\n$$\nwhere $\\alpha, \\beta \\in \\mathbb{R}$ are constant coefficients, $W_t$ is a standard Wiener process, and $\\star$ signifies that the stochastic integral may be interpreted in either the Itô or the Stratonovich sense. We are tasked to demonstrate that the choice of interpretation can lead to different conclusions about the long-term stability of the solution $X_t$. Stability is assessed via the almost-sure long-run growth rate, defined as $g = \\lim_{T \\to \\infty} \\frac{1}{T}\\ln|X_T|$.\n\nWe will derive the growth rate for each interpretation, identify parameters for which the stability conclusions are opposite, and then numerically verify these theoretical findings.\n\n**Task 1: Derivation of Long-Run Growth Rates**\n\nTo analyze the long-term behavior of $X_t$, we study the dynamics of $Y_t = \\ln(X_t)$. Since the initial condition is $X_0 = 1  0$ and the SDE is linear, the solution $X_t$ will not cross zero, so we can work with $\\ln(X_t)$ instead of $\\ln|X_t|$. We apply the appropriate chain rule for each interpretation to the function $f(x) = \\ln(x)$, for which $f'(x) = 1/x$ and $f''(x) = -1/x^2$.\n\n**Itô Interpretation**\n\nThe SDE is $dX_t = \\alpha X_t dt + \\beta X_t dW_t$. We apply Itô's lemma for $Y_t = f(X_t)$:\n$$\ndY_t = f'(X_t)dX_t + \\frac{1}{2}f''(X_t)(dX_t)^2\n$$\nThe quadratic variation term $(dX_t)^2$ is computed using the multiplication rules $dt \\cdot dt = 0$, $dt \\cdot dW_t = 0$, and $dW_t \\cdot dW_t = dt$.\n$$\n(dX_t)^2 = (\\alpha X_t dt + \\beta X_t dW_t)^2 = \\beta^2 X_t^2 (dW_t)^2 = \\beta^2 X_t^2 dt\n$$\nSubstituting the derivatives and $(dX_t)^2$ into the lemma:\n$$\ndY_t = \\frac{1}{X_t}(\\alpha X_t dt + \\beta X_t dW_t) + \\frac{1}{2}\\left(-\\frac{1}{X_t^2}\\right)(\\beta^2 X_t^2 dt)\n$$\n$$\ndY_t = (\\alpha dt + \\beta dW_t) - \\frac{1}{2}\\beta^2 dt = \\left(\\alpha - \\frac{1}{2}\\beta^2\\right)dt + \\beta dW_t\n$$\nIntegrating from $t=0$ to $t=T$:\n$$\nY_T - Y_0 = \\int_{0}^{T}\\left(\\alpha - \\frac{1}{2}\\beta^2\\right)ds + \\int_{0}^{T}\\beta dW_s = \\left(\\alpha - \\frac{1}{2}\\beta^2\\right)T + \\beta W_T\n$$\nWith $X_0 = 1$, we have $Y_0 = \\ln(1) = 0$. Thus, $\\ln(X_T) = (\\alpha - \\frac{1}{2}\\beta^2)T + \\beta W_T$. The almost-sure long-run growth rate is then:\n$$\ng_{\\text{Itô}} = \\lim_{T \\to \\infty} \\frac{1}{T}\\ln(X_T) = \\lim_{T \\to \\infty} \\left[ \\left(\\alpha - \\frac{1}{2}\\beta^2\\right) + \\beta \\frac{W_T}{T} \\right]\n$$\nBy the law of the iterated logarithm, $\\lim_{T \\to \\infty} W_T/T = 0$ almost surely. Therefore, the growth rate is:\n$$\ng_{\\text{Itô}} = \\alpha - \\frac{1}{2}\\beta^2\n$$\n\n**Stratonovich Interpretation**\n\nThe SDE is $dX_t = \\alpha X_t dt + \\beta X_t \\circ dW_t$. The Stratonovich chain rule has the same form as the ordinary chain rule: $d(f(X_t)) = f'(X_t) \\circ dX_t$.\nApplying this to $Y_t = \\ln(X_t)$:\n$$\ndY_t = \\frac{1}{X_t} \\circ dX_t = \\frac{1}{X_t} \\circ (\\alpha X_t dt + \\beta X_t \\circ dW_t) = \\alpha dt + \\beta \\circ dW_t\n$$\nIntegrating from $t=0$ to $t=T$:\n$$\nY_T - Y_0 = \\int_{0}^{T} \\alpha ds + \\int_{0}^{T} \\beta \\circ dW_s = \\alpha T + \\beta W_T\n$$\nWith $Y_0=0$, we have $\\ln(X_T) = \\alpha T + \\beta W_T$. The growth rate is:\n$$\ng_{\\text{Stratonovich}} = \\lim_{T \\to \\infty} \\frac{1}{T}\\ln(X_T) = \\lim_{T \\to \\infty} \\left[ \\alpha + \\beta \\frac{W_T}{T} \\right] = \\alpha\n$$\nThis result can be confirmed by converting the Stratonovich SDE to its Itô equivalent. The correction term is $\\frac{1}{2} b(x) b'(x)$, where $b(x) = \\beta x$. This gives $\\frac{1}{2}(\\beta x)(\\beta) = \\frac{1}{2}\\beta^2 x$. The equivalent Itô SDE is $dX_t = (\\alpha X_t + \\frac{1}{2}\\beta^2 X_t) dt + \\beta X_t dW_t$. The drift coefficient for this Itô form is $\\alpha' = \\alpha + \\frac{1}{2}\\beta^2$. Using the Itô growth rate formula $g = \\alpha' - \\frac{1}{2}\\beta^2$, we get $g = (\\alpha + \\frac{1}{2}\\beta^2) - \\frac{1}{2}\\beta^2 = \\alpha$, which is consistent.\n\n**Task 2: Identification of Parameters for Opposite Stability**\n\nWe seek parameters $(\\alpha, \\beta)$ such that the signs of $g_{\\text{Itô}}$ and $g_{\\text{Stratonovich}}$ are opposite, leading to different stability conclusions. Let us require the Itô system to be stable ($g  0$) and the Stratonovich system to be unstable ($g  0$).\n1.  Unstability under Stratonovich: $g_{\\text{Stratonovich}} = \\alpha  0$.\n2.  Stability under Itô: $g_{\\text{Itô}} = \\alpha - \\frac{1}{2}\\beta^2  0$.\n\nThese two conditions combine to yield the inequality $0  \\alpha  \\frac{1}{2}\\beta^2$. Any pair $(\\alpha, \\beta)$ satisfying this will produce the desired opposing stability behaviors. The problem provides Case A with $(\\alpha, \\beta) = (0.05, 0.4)$. Let us check this choice.\nHere, $\\alpha = 0.05$ and $\\frac{1}{2}\\beta^2 = \\frac{1}{2}(0.4)^2 = 0.08$. The condition $0  0.05  0.08$ is satisfied.\nFor these parameters:\n- $g_{\\text{Itô}} = 0.05 - 0.08 = -0.03  0$, predicting stability ($\\lim_{t\\to\\infty}X_t = 0$).\n- $g_{\\text{Stratonovich}} = 0.05  0$, predicting instability ($\\lim_{t\\to\\infty}X_t = \\infty$).\nThe choice of parameters is logical and correctly illustrates the phenomenon.\n\n**Tasks 3, 4, and 5: Numerical Verification**\n\nWe will now implement the numerical schemes and verify the theoretical classifications for the given test suite. The implementation will use the Euler-Maruyama method for the Itô SDE and the stochastic Heun method for the Stratonovich SDE. A single path of the Wiener process will be generated and used for both simulations in each test case to ensure a direct comparison. The numerical growth rate is computed as $\\widehat{g} = \\frac{1}{T}\\ln|X_T|$. Stability is classified numerically by comparing $\\widehat{g}$ against a tolerance $\\varepsilon = 2 \\times 10^{-2}$. The numerical classifications will be compared against the theoretical classifications derived from the formulas for $g_{\\text{Itô}}$ and $g_{\\text{Stratonovich}}$ using the same tolerance $\\varepsilon$. The final output for each case is a boolean, which is `True` if and only if both numerical classifications match their theoretical counterparts.\n\nThe theoretical classifications for the five test cases are as follows, using the rule: \"stable\" if $g  -0.02$, \"unstable\" if $g  0.02$, and \"neutral\" otherwise.\n\n- **Case A** $(\\alpha, \\beta) = (0.05, 0.4)$:\n  $g_{\\text{Itô}} = -0.03$ (Stable), $g_{\\text{Stratonovich}} = 0.05$ (Unstable).\n- **Case B** $(\\alpha, \\beta) = (-0.05, 0.2)$:\n  $g_{\\text{Itô}} = -0.05 - 0.5(0.2)^2 = -0.07$ (Stable), $g_{\\text{Stratonovich}} = -0.05$ (Stable).\n- **Case C** $(\\alpha, \\beta) = (0.2, 0.1)$:\n  $g_{\\text{Itô}} = 0.2 - 0.5(0.1)^2 = 0.195$ (Unstable), $g_{\\text{Stratonovich}} = 0.2$ (Unstable).\n- **Case D** $(\\alpha, \\beta) = (0.08, 0.4)$:\n  $g_{\\text{Itô}} = 0.08 - 0.5(0.4)^2 = 0.0$ (Neutral), $g_{\\text{Stratonovich}} = 0.08$ (Unstable).\n- **Case E** $(\\alpha, \\beta) = (0.0, 0.4)$:\n  $g_{\\text{Itô}} = 0.0 - 0.5(0.4)^2 = -0.08$ (Stable), $g_{\\text{Stratonovich}} = 0.0$ (Neutral).\n\nThe code in the final answer will perform the simulations and comparisons.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Analyzes the stability of a linear SDE under Itô and Stratonovich\n    interpretations, comparing theoretical predictions with numerical simulations.\n    \"\"\"\n\n    # --- Simulation Parameters ---\n    X0 = 1.0\n    T = 1000.0\n    dt = 1e-3\n    epsilon = 2e-2\n    seed = 12345\n\n    # --- Test Cases ---\n    test_cases = [\n        (0.05, 0.4),   # Case A\n        (-0.05, 0.2),  # Case B\n        (0.2, 0.1),    # Case C\n        (0.08, 0.4),   # Case D\n        (0.0, 0.4),    # Case E\n    ]\n\n    # --- Generate Wiener Path ---\n    # The same path is used for all test cases and both interpretations\n    # to ensure consistency and reproducibility.\n    num_steps = int(T / dt)\n    rng = np.random.default_rng(seed)\n    dW = rng.normal(0.0, np.sqrt(dt), num_steps)\n\n    def classify_stability(g, eps):\n        \"\"\"Classifies stability based on growth rate g and tolerance eps.\"\"\"\n        if g  -eps:\n            return \"stable\"\n        if g > eps:\n            return \"unstable\"\n        return \"neutral\"\n\n    results = []\n    for alpha, beta in test_cases:\n        # --- 1. Theoretical Classification ---\n        g_ito_theo = alpha - 0.5 * beta**2\n        g_strato_theo = alpha\n\n        theo_class_ito = classify_stability(g_ito_theo, epsilon)\n        theo_class_strato = classify_stability(g_strato_theo, epsilon)\n\n        # --- 2. Numerical Simulation: Itô (Euler-Maruyama) ---\n        x_ito = X0\n        for i in range(num_steps):\n            x_ito = x_ito * (1.0 + alpha * dt + beta * dW[i])\n\n        # Compute and classify empirical growth rate\n        g_ito_num = np.log(np.abs(x_ito)) / T if x_ito != 0 else -np.inf\n        num_class_ito = classify_stability(g_ito_num, epsilon)\n\n        # --- 3. Numerical Simulation: Stratonovich (Heun) ---\n        x_strato = X0\n        for i in range(num_steps):\n            # Predictor step\n            x_pred = x_strato * (1.0 + alpha * dt + beta * dW[i])\n            # Corrector step\n            x_strato = x_strato \\\n                + 0.5 * (alpha * x_strato + alpha * x_pred) * dt \\\n                + 0.5 * (beta * x_strato + beta * x_pred) * dW[i]\n\n        # Compute and classify empirical growth rate\n        g_strato_num = np.log(np.abs(x_strato)) / T if x_strato != 0 else -np.inf\n        num_class_strato = classify_stability(g_strato_num, epsilon)\n\n        # --- 4. Comparison ---\n        # Agreement is True if both numerical classifications match their\n        # theoretical counterparts.\n        agreement = (theo_class_ito == num_class_ito) and \\\n                    (theo_class_strato == num_class_strato)\n        results.append(agreement)\n\n    # --- Final Output ---\n    # Must be a single line with a list of booleans, as specified.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2415964"}, {"introduction": "In real-world financial engineering, efficiency is paramount. This final practice places you in the role of a quantitative analyst tasked with pricing a European option using a Monte Carlo simulation, where you face a classic dilemma: the bias-variance trade-off. By implementing an Euler-Maruyama-based simulation under a fixed computational budget, you will empirically determine the optimal simulation time step, $\\Delta t$, that minimizes the total error, balancing the discretization bias against the statistical variance of the estimator [@problem_id:2415926].", "problem": "Design and implement a complete program that performs a principled, simulation-based selection of the optimal time step $\\Delta t$ for a Monte Carlo estimator of a European call option price under a Geometric Brownian Motion (GBM) model. The method must quantify and balance the trade-off that decreasing $\\Delta t$ reduces discretization bias but increases computational cost for a fixed budget.\n\nYou must work within the following rigorous specification.\n\nModel and estimator definition:\n- Asset dynamics under the risk-neutral measure are given by the stochastic differential equation (SDE) $dS_t = r S_t \\, dt + \\sigma S_t \\, dW_t$ with initial condition $S_0  0$, constant risk-free rate $r \\ge 0$, and constant volatility $\\sigma \\ge 0$ over horizon $[0,T]$. The process $W_t$ is a standard Wiener process.\n- The target quantity is the arbitrage-free price of a European call option with strike $K$, maturity $T$, and payoff $f(S_T) = \\max(S_T - K, 0)$, discounted at the risk-free rate. The exact reference price is the classical Black–Scholes closed-form value, which you must compute to serve as ground truth.\n- The numerical estimator must use the Euler–Maruyama scheme to discretize the SDE with a uniform grid of $N$ steps on $[0,T]$ where $N = T / \\Delta t$ is an integer, and time step $\\Delta t = T/N$. One Euler–Maruyama step from $S_k$ to $S_{k+1}$ is $S_{k+1} = S_k + r S_k \\Delta t + \\sigma S_k \\sqrt{\\Delta t} Z_k$ with $Z_k \\sim \\mathcal{N}(0,1)$ independent and identically distributed. For each simulation path, the discounted payoff is $\\exp(-rT)\\max(S_N - K, 0)$, and the Monte Carlo estimator is the sample mean across $M$ independent paths.\n\nCost model and budget constraint:\n- The computational cost is defined as the total number of Euler–Maruyama time steps simulated across all paths, which equals $M \\times N$ for a given choice of $N$. For each test case, you are given a hard budget $C_{\\max}$ (in Euler steps). You must enforce the constraint $M \\times N \\le C_{\\max}$ by choosing $M = \\max\\{1, \\lfloor C_{\\max}/N \\rfloor\\}$ for any candidate $N$.\n\nError metric and empirical risk minimization:\n- For a fixed $\\Delta t$ (equivalently $N$) and its implied $M$, define a single-run estimator $\\hat{V}$ as the Monte Carlo sample mean of the discounted payoff using $M$ paths.\n- Use the exact Black–Scholes value $V^\\star$ as the ground truth. For a single run, define the squared error as $(\\hat{V} - V^\\star)^2$.\n- To reduce randomness when comparing different $\\Delta t$, estimate the mean squared error (MSE) for a given $\\Delta t$ by averaging the squared error over $R$ independent replications, each with fresh randomness but the same $M$ and $N$. That is, for each candidate $\\Delta t$, compute $\\widehat{\\mathrm{MSE}}(\\Delta t) = \\frac{1}{R}\\sum_{i=1}^R (\\hat{V}^{(i)} - V^\\star)^2$.\n- The optimal time step is the $\\Delta t$ that minimizes $\\widehat{\\mathrm{MSE}}(\\Delta t)$ over a provided finite candidate set. In case of a numerical tie (equal values within absolute tolerance $\\varepsilon = 10^{-12}$), select the largest $\\Delta t$ among the minimizers.\n\nImplementation constraints:\n- Use only the Euler–Maruyama scheme; do not use exact discretization of GBM for simulation.\n- Use independent standard normal draws across time and paths within each replication; use independent replications when averaging.\n- For each test case, evaluate a prescribed finite set of candidate steps $\\{\\Delta t_j\\}$, each constructed as $\\Delta t_j = T/N_j$ with $N_j \\in \\mathbb{N}$ provided below.\n\nTest suite:\n- For each test case, return the chosen $\\Delta t$ that minimizes the estimated MSE under the budget, as a floating-point number in years.\n- Use exactly $R = 12$ replications per candidate.\n- For numerical stability and reproducibility, you must fix all random number generator seeds deterministically in a way that does not depend on library or platform specifics beyond the language and libraries specified in the execution environment.\n\nParameters and candidate sets:\n- Case A (happy path):\n  - $S_0 = 100$, $K = 100$, $r = 0.05$, $\\sigma = 0.20$, $T = 1.0$, $C_{\\max} = 100{,}000$.\n  - Candidate numbers of steps $N \\in \\{8, 16, 32, 64, 128\\}$, hence $\\Delta t \\in \\{T/8, T/16, T/32, T/64, T/128\\}$.\n- Case B (low volatility and shorter maturity):\n  - $S_0 = 100$, $K = 100$, $r = 0.02$, $\\sigma = 0.05$, $T = 0.5$, $C_{\\max} = 50{,}000$.\n  - Candidate numbers of steps $N \\in \\{4, 8, 16, 32, 64\\}$, hence $\\Delta t \\in \\{T/4, T/8, T/16, T/32, T/64\\}$.\n- Case C (high volatility and longer maturity):\n  - $S_0 = 100$, $K = 110$, $r = 0.03$, $\\sigma = 0.60$, $T = 2.0$, $C_{\\max} = 150{,}000$.\n  - Candidate numbers of steps $N \\in \\{8, 16, 32, 64, 128\\}$, hence $\\Delta t \\in \\{T/8, T/16, T/32, T/64, T/128\\}$.\n\nFinal output format:\n- Your program must output a single line containing a Python-style list with exactly three floating-point numbers corresponding to the chosen $\\Delta t$ (in years) for Case A, Case B, and Case C, in that order.\n- Each $\\Delta t$ must be rounded to exactly $6$ decimal places.\n- The output must have no additional text. For example, the syntactic form must be like $\\texttt{[a,b,c]}$.\n\nYour submission must be a complete, runnable program that performs all computations as specified and prints the required single-line output.", "solution": "The problem requires designing a procedure to select an optimal time step, $\\Delta t$, for the numerical simulation of a European call option price. The selection must be based on minimizing the mean squared error (MSE) of a Monte Carlo estimator under a fixed computational budget. This task embodies a fundamental trade-off in computational science: the balance between discretization error and statistical error.\n\nThe underlying financial model is the Geometric Brownian Motion (GBM) for a non-dividend-paying stock, described by the stochastic differential equation (SDE) under the risk-neutral measure $\\mathbb{Q}$:\n$$\ndS_t = r S_t \\, dt + \\sigma S_t \\, dW_t\n$$\nHere, $S_t$ is the asset price at time $t$, $r$ is the constant risk-free interest rate, $\\sigma$ is the constant volatility, and $W_t$ is a standard Wiener process under $\\mathbb{Q}$.\n\nThe target of our estimation is the price of a European call option at time $t=0$, given by the discounted expected payoff at maturity $T$:\n$$\nV(S_0, 0) = \\mathbb{E}^{\\mathbb{Q}}[\\exp(-rT) \\max(S_T - K, 0) | S_0]\n$$\nwhere $K$ is the strike price. This theoretical price, denoted $V^\\star$, serves as our ground truth and is given by the Black-Scholes formula:\n$$\nV^\\star = S_0 \\Phi(d_1) - K \\exp(-rT) \\Phi(d_2)\n$$\nwith\n$$\nd_1 = \\frac{\\ln(S_0/K) + (r + \\frac{1}{2}\\sigma^2)T}{\\sigma\\sqrt{T}} \\quad \\text{and} \\quad d_2 = d_1 - \\sigma\\sqrt{T}\n$$\nHere, $\\Phi(\\cdot)$ represents the cumulative distribution function (CDF) of the standard normal distribution $\\mathcal{N}(0,1)$.\n\nThe numerical estimator is constructed using the Euler-Maruyama scheme to discretize the SDE over a uniform time grid $0 = t_0  t_1  \\dots  t_N = T$, where $t_k = k \\Delta t$ and the time step is $\\Delta t = T/N$. The discrete-time evolution of the asset price is:\n$$\nS_{k+1} = S_k(1 + r \\Delta t + \\sigma \\sqrt{\\Delta t} Z_k)\n$$\nfor $k = 0, 1, \\dots, N-1$, where $Z_k$ are independent and identically distributed random variables drawn from $\\mathcal{N}(0,1)$.\n\nA single Monte Carlo simulation path generates a final asset price $S_N$. The price of the option is estimated by averaging the discounted payoffs over $M$ independent paths:\n$$\n\\hat{V} = \\frac{1}{M} \\sum_{j=1}^{M} \\exp(-rT) \\max(S_N^{(j)} - K, 0)\n$$\nThe total computational cost is defined as $C = M \\times N$. A fixed budget $C_{\\max}$ imposes the constraint $M \\times N \\le C_{\\max}$. For a chosen number of time steps $N$, the number of simulation paths $M$ is maximized under this budget: $M = \\max\\{1, \\lfloor C_{\\max}/N \\rfloor\\}$.\n\nThe core of the problem lies in the analysis of the Mean Squared Error (MSE) of the estimator $\\hat{V}$ with respect to the true value $V^\\star$:\n$$\n\\text{MSE}(\\Delta t) = \\mathbb{E}[(\\hat{V} - V^\\star)^2] = (\\mathbb{E}[\\hat{V}] - V^\\star)^2 + \\text{Var}(\\hat{V})\n$$\nThe MSE decomposes into two components:\n$1$. Squared Bias, $(\\mathbb{E}[\\hat{V}] - V^\\star)^2$: This term captures the systematic error introduced by the Euler-Maruyama discretization. The weak error of this scheme is of order $O(\\Delta t)$, so the squared bias is approximately proportional to $(\\Delta t)^2$. Increasing $N$ (decreasing $\\Delta t$) reduces this bias.\n$2$. Variance, $\\text{Var}(\\hat{V})$: This term captures the statistical error from the Monte Carlo sampling. It is given by $\\frac{1}{M} \\text{Var}(\\exp(-rT)\\max(S_N - K, 0))$. Since $M \\approx C_{\\max}/N = C_{\\max} \\Delta t / T$, the variance is approximately proportional to $1/M$, and thus proportional to $N$ or $1/\\Delta t$. Increasing $N$ (decreasing $\\Delta t$) requires a corresponding decrease in $M$ to stay within budget, which increases the variance.\n\nThis establishes the fundamental trade-off: decreasing $\\Delta t$ reduces discretization bias but increases statistical variance. The optimal $\\Delta t$ is the one that minimizes the total MSE.\n\nThe specified algorithm is an empirical risk minimization procedure. Since the true MSE is unknown, we estimate it. For each candidate time step $\\Delta t_j$ (corresponding to $N_j=T/\\Delta t_j$), we compute an empirical MSE, $\\widehat{\\mathrm{MSE}}(\\Delta t_j)$. This is done by performing $R$ independent replications of the entire Monte Carlo estimation process. For each replication $i \\in \\{1, \\dots, R\\}$, a new set of $M$ paths is simulated to produce an estimate $\\hat{V}^{(i)}$. The empirical MSE is then:\n$$\n\\widehat{\\mathrm{MSE}}(\\Delta t_j) = \\frac{1}{R} \\sum_{i=1}^{R} (\\hat{V}^{(i)} - V^\\star)^2\n$$\nThe value of $R$ is fixed at $12$. This averaging over $R$ replications provides a more stable estimate of the MSE for a given $\\Delta t_j$ than a single squared error measurement.\n\nThe final step is to select the optimal $\\Delta t$ from a given finite set of candidates $\\{\\Delta t_j\\}$. The algorithm iterates through each candidate, calculates its $\\widehat{\\mathrm{MSE}}$, and identifies the minimum $\\widehat{\\mathrm{MSE}}$ value achieved. The corresponding $\\Delta t_j$ is selected. A tie-breaking rule is specified: if multiple candidates yield an MSE value within a numerical tolerance of $\\varepsilon = 10^{-12}$ of the minimum, the one with the largest $\\Delta t$ (smallest $N$) is chosen. This is a sensible heuristic, as it favors the computationally cheaper option among equivalent performers.\n\nFor implementation, path simulations for all $M$ paths are performed simultaneously using vectorized operations in NumPy for superior performance. To ensure reproducibility, the random number generator is seeded deterministically. For each test case, a base seed is used. From this, unique and deterministic seeds are generated for each candidate $N$ and for each of the $R$ replications, ensuring that the randomness is controlled and independent across all distinct estimation tasks.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\n#\n# MIT License\n#\n# Copyright (c) 2024, The Strict Russian Professor\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n#\n\ndef black_scholes_call(S0, K, T, r, sigma):\n    \"\"\"\n    Computes the Black-Scholes price for a European call option.\n    \"\"\"\n    if sigma == 0:\n        return np.maximum(0.0, S0 * np.exp(r * T) - K) * np.exp(-r * T)\n    d1 = (np.log(S0 / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n    d2 = d1 - sigma * np.sqrt(T)\n    price = S0 * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n    return price\n\ndef vectorized_monte_carlo(S0, K, T, r, sigma, N, M, rng):\n    \"\"\"\n    Estimates European call option price using a vectorized Euler-Maruyama simulation.\n    \"\"\"\n    dt = T / N\n    S = np.full(M, S0, dtype=np.float64)\n\n    for _ in range(N):\n        Z = rng.standard_normal(size=M)\n        S = S * (1 + r * dt + sigma * np.sqrt(dt) * Z)\n\n    payoffs = np.maximum(S - K, 0)\n    discounted_mean_payoff = np.exp(-r * T) * np.mean(payoffs)\n    return discounted_mean_payoff\n\ndef estimate_mse(S0, K, T, r, sigma, C_max, N, R, V_star, base_seed):\n    \"\"\"\n    Estimates the Mean Squared Error for a given N by averaging over R replications.\n    \"\"\"\n    M = max(1, C_max // N)\n    squared_errors = []\n\n    for i in range(R):\n        seed = base_seed + i\n        rng = np.random.default_rng(seed)\n        V_hat = vectorized_monte_carlo(S0, K, T, r, sigma, N, M, rng)\n        sq_err = (V_hat - V_star)**2\n        squared_errors.append(sq_err)\n\n    return np.mean(squared_errors)\n\ndef find_optimal_dt(S0, K, T, r, sigma, C_max, N_candidates, case_base_seed):\n    \"\"\"\n    Finds the optimal time step dt by minimizing empirical MSE over a set of candidates.\n    \"\"\"\n    R = 12\n    V_star = black_scholes_call(S0, K, T, r, sigma)\n    \n    mse_results = []\n    \n    for i, N in enumerate(N_candidates):\n        # Assign a unique, deterministic block of seeds for each candidate N\n        N_base_seed = case_base_seed + i * R\n        \n        mse = estimate_mse(S0, K, T, r, sigma, C_max, N, R, V_star, N_base_seed)\n        dt = T / N\n        mse_results.append({'mse': mse, 'dt': dt})\n\n    min_mse = min(res['mse'] for res in mse_results)\n    \n    tolerance = 1e-12\n    \n    # Filter for candidates that are within the tolerance of the minimum MSE\n    minimizers = [res for res in mse_results if abs(res['mse'] - min_mse)  tolerance]\n    \n    # Tie-breaking: select the largest dt among the minimizers\n    optimal_dt = max(res['dt'] for res in minimizers)\n    \n    return optimal_dt\n\ndef solve():\n    \"\"\"\n    Main solver function to process test cases and print results.\n    \"\"\"\n    test_cases = [\n        {   # Case A\n            'params': {'S0': 100.0, 'K': 100.0, 'T': 1.0, 'r': 0.05, 'sigma': 0.20},\n            'C_max': 100000,\n            'N_candidates': [8, 16, 32, 64, 128],\n            'seed': 1234\n        },\n        {   # Case B\n            'params': {'S0': 100.0, 'K': 100.0, 'T': 0.5, 'r': 0.02, 'sigma': 0.05},\n            'C_max': 50000,\n            'N_candidates': [4, 8, 16, 32, 64],\n            'seed': 5678\n        },\n        {   # Case C\n            'params': {'S0': 100.0, 'K': 110.0, 'T': 2.0, 'r': 0.03, 'sigma': 0.60},\n            'C_max': 150000,\n            'N_candidates': [8, 16, 32, 64, 128],\n            'seed': 9101\n        }\n    ]\n\n    final_results = []\n    for case in test_cases:\n        optimal_dt = find_optimal_dt(\n            S0=case['params']['S0'],\n            K=case['params']['K'],\n            T=case['params']['T'],\n            r=case['params']['r'],\n            sigma=case['params']['sigma'],\n            C_max=case['C_max'],\n            N_candidates=case['N_candidates'],\n            case_base_seed=case['seed']\n        )\n        final_results.append(optimal_dt)\n        \n    print(f\"[{','.join(f'{res:.6f}' for res in final_results)}]\")\n\nsolve()\n```", "id": "2415926"}]}