{"hands_on_practices": [{"introduction": "Affine models serve as a powerful bridge between abstract economic theories and observable market data. This practice [@problem_id:2370016] demonstrates this by building a model where the short rate, $r_t$, is driven by a latent state vector, $x_t$, representing the time-varying coefficients of a monetary policy rule. You will learn the fundamental mechanics of deriving the affine pricing recursions and using least squares to estimate these unobservable macroeconomic factors directly from a cross-section of bond yields.", "problem": "You are asked to implement and test a calibration routine for a Gaussian Affine Term Structure Model (ATSM) in which the short rate is generated by a Taylor-type policy rule whose coefficients are the latent state variables. The model must be specified and solved under the risk-neutral measure. All interest rates and yields must be handled as decimals (for example, an annual yield of $2$ percent is written as $0.02$), and no percentage sign is allowed in the output. The goal is to recover, from synthetic yield curve observations at a single date, the latent Taylor-rule weights on inflation and unemployment that enter the short rate.\n\nFundamental base and model setup:\n- Work under the risk-neutral measure, with the absence of arbitrage implying that a zero-coupon bond price at time $t$ is the conditional expectation of the discounted payoff. Formally, for a zero-coupon bond maturing in $n$ years, the price is $P_t(n) \\equiv \\mathbb{E}_t^{\\mathbb{Q}}\\left[\\exp\\left(-\\sum_{j=0}^{n-1} r_{t+j}\\right)\\right]$, where $\\mathbb{Q}$ denotes the risk-neutral measure.\n- The short rate is generated by a Taylor-type rule with time-varying coefficients treated as the state, with $r_t = \\delta_0 + \\delta_1^\\top x_t$, where $x_t \\in \\mathbb{R}^2$ collects the Taylor-rule weights on inflation and unemployment, respectively.\n- The state is Gaussian and follows a first-order linear process under the risk-neutral measure, $x_{t+1} = \\mu + \\Phi x_t + \\Sigma \\varepsilon_{t+1}$, where $\\varepsilon_{t+1} \\sim \\mathcal{N}(0, I)$, $\\mu \\in \\mathbb{R}^2$, $\\Phi \\in \\mathbb{R}^{2\\times 2}$ is stable, and $\\Sigma \\in \\mathbb{R}^{2\\times 2}$ is lower-triangular. The market price of risk is zero so that the physical and risk-neutral dynamics coincide.\n\nTasks to implement:\n1) Starting from the risk-neutral pricing identity and the Gaussian linear state dynamics, derive and implement the exponential-affine solution for zero-coupon bond prices. In particular, show that there exist sequences $\\{A_n\\}_{n\\ge 0}$ and $\\{B_n\\}_{n\\ge 0}$ such that $\\log P_t(n) = -A_n - B_n^\\top x_t$, and obtain their recursions by conditioning forward one step. Then define model-implied $n$-year zero-coupon yields as $y_t(n) \\equiv -\\frac{1}{n}\\log P_t(n)$.\n2) Given a cross-section of $N$ maturities at a single date $t$, show how to estimate the latent state $x_t$ via least squares by exploiting the linear relation $y_t(n)\\,n - A_n = B_n^\\top x_t$. Implement a numerically stable algorithm to compute the least-squares estimate $\\hat{x}_t$ from the overidentified system.\n3) For each parameter set in the test suite below, generate synthetic observed yields $y^{\\text{obs}}(n)$ by evaluating the affine yield formula at the true state $x_t^{\\star}$ and adding a deterministic measurement disturbance $\\epsilon_n$. Then estimate $\\hat{x}_t$ by least squares and compute the in-sample root mean squared error (RMSE) across maturities between model-implied and observed yields.\n\nCalibration objective and reporting:\n- For each test case, with maturities $\\mathcal{N} = \\{1,2,5,10\\}$ years, construct $y^{\\text{obs}}(n) = \\frac{A_n + B_n^\\top x_t^{\\star}}{n} + \\epsilon_n$, estimate $\\hat{x}_t$, and compute $\\text{RMSE} \\equiv \\sqrt{\\frac{1}{|\\mathcal{N}|}\\sum_{n\\in \\mathcal{N}} \\left(y^{\\text{obs}}(n) - \\frac{A_n + B_n^\\top \\hat{x}_t}{n}\\right)^2}$.\n- Your program must output, for each test case, the three-tuple comprising the two components of $\\hat{x}_t$ followed by the RMSE, all rounded to six decimal places. Aggregate the results for all test cases in the order they are listed below into a single flat list.\n- Final output format requirement: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For example, if there are three test cases, the output must look like \"[x1_case1,x2_case1,rmse_case1,x1_case2,x2_case2,rmse_case2,x1_case3,x2_case3,rmse_case3]\".\n\nTest suite (all numbers are decimals and must be used exactly as specified):\n- Common maturities: $\\mathcal{N} = \\{\\,1,\\,2,\\,5,\\,10\\,\\}$ (years).\n\n- Test Case 1:\n  - Short-rate loadings: $\\delta_0 = 0.005$, $\\delta_1 = [\\pi, u]^\\top$ with $\\pi = 0.02$, $u = 0.06$.\n  - Risk-neutral state dynamics: $\\mu = [0.3,\\, -0.1]^\\top$, $\\Phi = \\begin{bmatrix}0.8 & 0\\\\0 & 0.5\\end{bmatrix}$, $\\Sigma = \\operatorname{diag}(0.1,\\,0.1)$.\n  - True state at time $t$: $x_t^{\\star} = [1.0,\\,0.5]^\\top$.\n  - Measurement disturbances across maturities: $\\epsilon = [0.0000,\\,0.0000,\\,0.0000,\\,0.0000]^\\top$.\n\n- Test Case 2 (near-boundary persistence):\n  - Short-rate loadings: $\\delta_0 = 0.004$, $\\delta_1 = [\\pi, u]^\\top$ with $\\pi = 0.03$, $u = 0.05$.\n  - Risk-neutral state dynamics: $\\mu = [-0.05,\\,0.02]^\\top$, $\\Phi = \\begin{bmatrix}0.99 & 0\\\\0 & 0.95\\end{bmatrix}$, $\\Sigma = \\operatorname{diag}(0.05,\\,0.02)$.\n  - True state at time $t$: $x_t^{\\star} = [0.7,\\,-0.3]^\\top$.\n  - Measurement disturbances: $\\epsilon = [0.0001,\\,-0.0001,\\,0.0001,\\,-0.0001]^\\top$.\n\n- Test Case 3 (heterogeneous persistence and larger volatility):\n  - Short-rate loadings: $\\delta_0 = 0.002$, $\\delta_1 = [\\pi, u]^\\top$ with $\\pi = 0.01$, $u = 0.08$.\n  - Risk-neutral state dynamics: $\\mu = [-0.2,\\,0.4]^\\top$, $\\Phi = \\begin{bmatrix}0.3 & 0\\\\0 & 0.7\\end{bmatrix}$, $\\Sigma = \\operatorname{diag}(0.2,\\,0.1)$.\n  - True state at time $t$: $x_t^{\\star} = [1.2,\\,0.2]^\\top$.\n  - Measurement disturbances: $\\epsilon = [0.0002,\\,0.0000,\\,-0.0002,\\,0.0000]^\\top$.\n\nProgram requirements:\n- Implement the affine recursion for bond prices from first principles as described above.\n- Use numerically stable linear algebra to solve the least-squares problem for $\\hat{x}_t$.\n- For each test case, return the three numbers $(\\hat{x}_{t,1}, \\hat{x}_{t,2}, \\text{RMSE})$, all rounded to six decimal places.\n- Final output: A single line with a flat list of $9$ floats (three per test case) in the exact order of the test suite and with the exact formatting described above. No other output is permitted.", "solution": "The problem statement is a valid exercise in computational finance. It describes the calibration of a discrete-time Gaussian Affine Term Structure Model (ATSM) using synthetic yield curve data. The model is fully specified, the objectives are clear, and the problem is scientifically sound and well-posed. We proceed with the solution.\n\nThe solution is structured in three parts: first, the derivation of the recursive formulas for the affine coefficients; second, the formulation of the state vector estimation problem via ordinary least squares; and third, the specification of the algorithm to be implemented.\n\n**1. Derivation of Affine Recursions**\n\nThe model is defined under the risk-neutral measure $\\mathbb{Q}$. The price of a zero-coupon bond at time $t$ with $n$ periods to maturity, $P_t(n)$, is given by the risk-neutral expectation of the discounted payoff:\n$$\nP_t(n) = \\mathbb{E}_t^{\\mathbb{Q}}\\left[\\exp\\left(-\\sum_{j=0}^{n-1} r_{t+j}\\right)\\right]\n$$\nwhere $r_t$ is the short rate. By the law of iterated expectations, this can be written recursively:\n$$\nP_t(n) = \\mathbb{E}_t^{\\mathbb{Q}}\\left[\\exp(-r_t) \\cdot \\exp\\left(-\\sum_{j=1}^{n-1} r_{t+j}\\right)\\right] = \\mathbb{E}_t^{\\mathbb{Q}}\\left[\\exp(-r_t) \\cdot P_{t+1}(n-1)\\right]\n$$\nThe model assumes an exponential-affine form for the bond price, which we write as:\n$$\nP_t(n) = \\exp(-A_n - B_n^\\top x_t)\n$$\nwhere $A_n$ is a scalar and $B_n \\in \\mathbb{R}^2$. The short rate $r_t$ and the state vector $x_t$ are specified as:\n$$\nr_t = \\delta_0 + \\delta_1^\\top x_t\n$$\n$$\nx_{t+1} = \\mu + \\Phi x_t + \\Sigma \\varepsilon_{t+1}, \\quad \\varepsilon_{t+1} \\sim \\mathcal{N}(0, I)\n$$\nSubstituting these into the recursive pricing equation:\n$$\n\\exp(-A_n - B_n^\\top x_t) = \\mathbb{E}_t^{\\mathbb{Q}}\\left[ \\exp\\left(-(\\delta_0 + \\delta_1^\\top x_t)\\right) \\exp\\left(-A_{n-1} - B_{n-1}^\\top x_{t+1}\\right) \\right]\n$$\nSince terms involving $t$-dated variables are known at time $t$, they can be taken out of the expectation:\n$$\n\\exp(-A_n - B_n^\\top x_t) = \\exp(-\\delta_0 - \\delta_1^\\top x_t - A_{n-1}) \\mathbb{E}_t^{\\mathbb{Q}}\\left[ \\exp\\left(-B_{n-1}^\\top x_{t+1}\\right) \\right]\n$$\nWe now evaluate the expectation by substituting the dynamics of $x_{t+1}$:\n$$\n\\mathbb{E}_t^{\\mathbb{Q}}\\left[ \\exp\\left(-B_{n-1}^\\top (\\mu + \\Phi x_t + \\Sigma \\varepsilon_{t+1})\\right) \\right] = \\exp\\left(-B_{n-1}^\\top \\mu - B_{n-1}^\\top \\Phi x_t\\right) \\mathbb{E}_t^{\\mathbb{Q}}\\left[\\exp\\left(-B_{n-1}^\\top \\Sigma \\varepsilon_{t+1}\\right)\\right]\n$$\nThe remaining expectation involves the random variable $Z = -B_{n-1}^\\top \\Sigma \\varepsilon_{t+1}$. Since $\\varepsilon_{t+1} \\sim \\mathcal{N}(0, I)$, $Z$ is a scalar normal variable with mean $\\mathbb{E}[Z]=0$ and variance $\\text{Var}(Z) = (-B_{n-1}^\\top \\Sigma) \\mathbb{E}[\\varepsilon_{t+1}\\varepsilon_{t+1}^\\top] (-B_{n-1}^\\top \\Sigma)^\\top = B_{n-1}^\\top \\Sigma \\Sigma^\\top B_{n-1}$. The moment-generating function of a normal variable $Y \\sim \\mathcal{N}(m, \\sigma^2)$ at point $s$ is $\\mathbb{E}[\\exp(sY)] = \\exp(sm + \\frac{1}{2}s^2\\sigma^2)$. For $Z$, evaluated at $s=1$, we have:\n$$\n\\mathbb{E}_t^{\\mathbb{Q}}\\left[\\exp(Z)\\right] = \\exp\\left(\\frac{1}{2}\\text{Var}(Z)\\right) = \\exp\\left(\\frac{1}{2} B_{n-1}^\\top \\Sigma \\Sigma^\\top B_{n-1}\\right)\n$$\nSubstituting this back and taking logarithms of both sides yields:\n$$\n-A_n - B_n^\\top x_t = (-\\delta_0 - A_{n-1} - B_{n-1}^\\top \\mu + \\frac{1}{2} B_{n-1}^\\top \\Sigma \\Sigma^\\top B_{n-1}) - (\\delta_1^\\top + B_{n-1}^\\top \\Phi) x_t\n$$\nThis identity must hold for any state $x_t$. By matching the intercept and the coefficient of $x_t$, we obtain the following recursions for $A_n$ and $B_n$:\n$$\nB_n = \\Phi^\\top B_{n-1} + \\delta_1\n$$\n$$\nA_n = A_{n-1} + \\delta_0 + B_{n-1}^\\top \\mu - \\frac{1}{2} B_{n-1}^\\top \\Sigma \\Sigma^\\top B_{n-1}\n$$\nThe recursions are initialized for a zero-maturity bond, $P_t(0)=1$, for which $\\log P_t(0)=0$. This implies $-A_0 - B_0^\\top x_t=0$ for all $x_t$, which requires the initial conditions:\n$$\nA_0 = 0, \\quad B_0 = \\mathbf{0} \\in \\mathbb{R}^2\n$$\n\n**2. State Estimation via Least Squares**\n\nThe model-implied yield for an $n$-period bond is defined as $y_t(n) = -\\frac{1}{n} \\log P_t(n)$. Using the affine structure:\n$$\ny_t(n) = \\frac{A_n + B_n^\\top x_t}{n}\n$$\nGiven a set of observed yields $\\{y^{\\text{obs}}(n_i)\\}_{i=1}^N$ for maturities $\\mathcal{N}=\\{n_1, \\dots, n_N\\}$, we aim to estimate the unobserved state vector $x_t$. Rearranging the yield equation provides a linear relationship:\n$$\nn \\cdot y_t(n) - A_n = B_n^\\top x_t\n$$\nObserved yields are assumed to be generated by the model at the true state $x_t^\\star$ plus a measurement disturbance $\\epsilon_n$:\n$$\ny^{\\text{obs}}(n) = \\frac{A_n + B_n^\\top x_t^\\star}{n} + \\epsilon_n\n$$\nSubstituting this into the linear relationship gives:\n$$\nn \\cdot y^{\\text{obs}}(n) - A_n = B_n^\\top x_t^\\star + n \\cdot \\epsilon_n\n$$\nFor a set of $N$ maturities, we can stack these equations to form an overdetermined linear system. Let $Z$ be an $N \\times 1$ vector with elements $Z_i = n_i \\cdot y^{\\text{obs}}(n_i) - A_{n_i}$, and let $\\mathbf{B}$ be an $N \\times 2$ matrix whose rows are $B_{n_i}^\\top$. The system is:\n$$\nZ = \\mathbf{B} x_t + \\nu\n$$\nwhere $\\nu$ is a vector of pricing errors. The least-squares estimate $\\hat{x}_t$ minimizes the sum of squared errors, $\\|Z - \\mathbf{B} x_t\\|^2$, and is given by the solution to the normal equations:\n$$\n\\hat{x}_t = (\\mathbf{B}^\\top \\mathbf{B})^{-1} \\mathbf{B}^\\top Z\n$$\nThis system should be solved using a numerically stable method, such as QR decomposition or Singular Value Decomposition (SVD), which is implemented in standard scientific computing libraries.\n\n**3. Algorithmic Implementation and Evaluation**\n\nFor each test case, the calibration procedure is as follows:\n1.  Initialize $A_0 = 0$ and $B_0 = [0, 0]^\\top$.\n2.  Iteratively compute and store the coefficients $\\{A_n, B_n\\}$ for $n=1, \\dots, 10$ using the derived recursions.\n3.  For the specified maturities $\\mathcal{N} = \\{1, 2, 5, 10\\}$, generate the synthetic \"observed\" yields $y^{\\text{obs}}(n)$ using the provided true state $x_t^{\\star}$ and measurement disturbances $\\epsilon_n$.\n4.  Construct the $4 \\times 1$ target vector $Z$ where the $i$-th element is $n_i \\cdot y^{\\text{obs}}(n_i) - A_{n_i}$.\n5.  Construct the $4 \\times 2$ regressor matrix $\\mathbf{B}$ where the $i$-th row is $B_{n_i}^\\top$.\n6.  Solve the linear least-squares problem $Z = \\mathbf{B} \\hat{x}_t$ to find the estimated state vector $\\hat{x}_t$.\n7.  Calculate the model-implied yields $y^{\\text{model}}(n) = (A_n + B_n^\\top \\hat{x}_t)/n$ for each $n \\in \\mathcal{N}$ using the estimated $\\hat{x}_t$.\n8.  Compute the in-sample Root Mean Squared Error (RMSE) between the observed and model-implied yields:\n    $$\n    \\text{RMSE} = \\sqrt{\\frac{1}{|\\mathcal{N}|}\\sum_{n\\in \\mathcal{N}} (y^{\\text{obs}}(n) - y^{\\text{model}}(n))^2}\n    $$\n9.  The final result for the test case is the tuple $(\\hat{x}_{t,1}, \\hat{x}_{t,2}, \\text{RMSE})$, with each value rounded to six decimal places.\n\nThis procedure is deterministic and directly implements the theoretical framework on the provided data.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the ATSM calibration problem for all test cases.\n    \"\"\"\n\n    test_cases = [\n        # Test Case 1\n        {\n            \"delta0\": 0.005,\n            \"delta1\": np.array([0.02, 0.06]),\n            \"mu\": np.array([0.3, -0.1]),\n            \"Phi\": np.array([[0.8, 0.0], [0.0, 0.5]]),\n            \"Sigma\": np.array([[0.1, 0.0], [0.0, 0.1]]),\n            \"x_true\": np.array([1.0, 0.5]),\n            \"epsilon\": np.array([0.0000, 0.0000, 0.0000, 0.0000]),\n        },\n        # Test Case 2\n        {\n            \"delta0\": 0.004,\n            \"delta1\": np.array([0.03, 0.05]),\n            \"mu\": np.array([-0.05, 0.02]),\n            \"Phi\": np.array([[0.99, 0.0], [0.0, 0.95]]),\n            \"Sigma\": np.array([[0.05, 0.0], [0.0, 0.02]]),\n            \"x_true\": np.array([0.7, -0.3]),\n            \"epsilon\": np.array([0.0001, -0.0001, 0.0001, -0.0001]),\n        },\n        # Test Case 3\n        {\n            \"delta0\": 0.002,\n            \"delta1\": np.array([0.01, 0.08]),\n            \"mu\": np.array([-0.2, 0.4]),\n            \"Phi\": np.array([[0.3, 0.0], [0.0, 0.7]]),\n            \"Sigma\": np.array([[0.2, 0.0], [0.0, 0.1]]),\n            \"x_true\": np.array([1.2, 0.2]),\n            \"epsilon\": np.array([0.0002, 0.0000, -0.0002, 0.0000]),\n        },\n    ]\n\n    maturities = np.array([1, 2, 5, 10])\n    max_maturity = np.max(maturities)\n\n    all_results = []\n\n    for case in test_cases:\n        delta0 = case[\"delta0\"]\n        delta1 = case[\"delta1\"]\n        mu = case[\"mu\"]\n        Phi = case[\"Phi\"]\n        Sigma = case[\"Sigma\"]\n        x_true = case[\"x_true\"]\n        epsilon = case[\"epsilon\"]\n\n        # 1. Compute affine coefficients A_n and B_n\n        A = np.zeros(max_maturity + 1)\n        B = np.zeros((max_maturity + 1, 2))\n        \n        A[0] = 0.0\n        B[0, :] = 0.0\n\n        Sigma_SigmaT = Sigma @ Sigma.T\n\n        for n in range(1, max_maturity + 1):\n            B[n, :] = Phi.T @ B[n-1, :] + delta1\n            A[n] = A[n-1] + delta0 + B[n-1, :].T @ mu - 0.5 * B[n-1, :].T @ Sigma_SigmaT @ B[n-1, :]\n\n        # 2. Generate synthetic observed yields\n        y_obs = np.zeros(len(maturities))\n        for i, n in enumerate(maturities):\n            y_obs[i] = (A[n] + B[n, :].T @ x_true) / n + epsilon[i]\n            \n        # 3. Set up and solve the least squares problem\n        num_maturities = len(maturities)\n        Z_vector = np.zeros(num_maturities)\n        B_matrix = np.zeros((num_maturities, 2))\n\n        for i, n in enumerate(maturities):\n            Z_vector[i] = n * y_obs[i] - A[n]\n            B_matrix[i, :] = B[n, :]\n            \n        # Solve for x_hat using numerically stable lstsq\n        x_hat, _, _, _ = np.linalg.lstsq(B_matrix, Z_vector, rcond=None)\n        \n        # 4. Compute model-implied yields and RMSE\n        y_model = np.zeros(num_maturities)\n        for i, n in enumerate(maturities):\n            y_model[i] = (A[n] + B[n, :].T @ x_hat) / n\n\n        rmse = np.sqrt(np.mean((y_obs - y_model)**2))\n\n        # 5. Append results rounded to 6 decimal places\n        all_results.append(round(x_hat[0], 6))\n        all_results.append(round(x_hat[1], 6))\n        all_results.append(round(rmse, 6))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "2370016"}, {"introduction": "While minimizing price or yield errors is a common calibration strategy, more advanced methods offer greater statistical rigor. This exercise [@problem_id:2370055] introduces an information-theoretic approach by framing calibration as the minimization of the Kullback-Leibler (KL) divergence. You will work with a one-factor Vasicek model and learn how to find parameters that make the model's implied cross-sectional distribution of bond prices as close as possible to an observed empirical distribution, providing a powerful alternative to standard least-squares.", "problem": "Consider an Affine Term Structure Model (ATSM) of the one-factor Vasicek type for the risk-neutral short rate process, where the short rate $r_t$ evolves as $dr_t = \\kappa(\\theta - r_t)\\,dt + \\sigma\\,dW_t$ under the risk-neutral measure. The parameters are the mean-reversion speed $\\kappa$, the long-run mean $\\theta$, the volatility $\\sigma$, and the initial short rate $r_0$. For a maturity $T \\ge 0$, the model-implied zero-coupon bond price at time $0$ is given by\n$$\nP(0,T) = \\exp\\!\\big(A(T) - B(T)\\,r_0\\big),\n$$\nwhere\n$$\nB(T) = \\frac{1 - e^{-\\kappa T}}{\\kappa},\n\\qquad\nA(T) = \\left(\\theta - \\frac{\\sigma^2}{2\\kappa^2}\\right)\\big(B(T) - T\\big) - \\frac{\\sigma^2}{4\\kappa}\\,B(T)^2,\n$$\nwith the conventions that for $T=0$ one has $B(0)=0$ and $A(0)=0$. For a finite set of maturities $\\{T_i\\}_{i=1}^n$ with $T_i \\ge 0$, define the model-implied cross-sectional distribution over these maturities by normalizing the bond prices:\n$$\nq_i(\\kappa,\\theta,\\sigma,r_0) = \\frac{P(0,T_i)}{\\sum_{j=1}^n P(0,T_j)} \\quad \\text{for } i=1,\\dots,n.\n$$\nLet $\\{p_i\\}_{i=1}^n$ be an empirical cross-sectional distribution over the same maturities, with $p_i > 0$ and $\\sum_{i=1}^n p_i = 1$. Define the Kullback–Leibler (KL) divergence (using the natural logarithm) from the empirical distribution to the model-implied distribution by\n$$\nD_{\\mathrm{KL}}\\big(p \\,\\|\\, q(\\kappa,\\theta,\\sigma,r_0)\\big) \\;=\\; \\sum_{i=1}^n p_i \\,\\log\\!\\left(\\frac{p_i}{q_i(\\kappa,\\theta,\\sigma,r_0)}\\right).\n$$\nFormulate the calibration problem as the minimization of $D_{\\mathrm{KL}}$ over the parameter vector $(\\kappa,\\theta,\\sigma,r_0)$, subject to $\\kappa>0$ and $\\sigma>0$. Assume no-arbitrage and risk-neutral valuation hold. There are no physical units in this problem. Angles are not involved.\n\nTest Suite. For each of the following three cases, the maturities $\\{T_i\\}$ and empirical distributions $\\{p_i\\}$ are specified. In every case, use the maturities exactly as given (in years), and use the empirical probabilities exactly as provided (they already sum to $1$):\n\n- Case $1$:\n  - Maturities: $\\{0.25,\\,0.5,\\,1.0,\\,2.0,\\,5.0,\\,10.0\\}$.\n  - Empirical distribution: $\\{0.27,\\,0.25,\\,0.20,\\,0.15,\\,0.08,\\,0.05\\}$.\n\n- Case $2$ (includes a boundary maturity at zero):\n  - Maturities: $\\{0.0,\\,0.25,\\,0.5,\\,1.0,\\,4.0,\\,7.0\\}$.\n  - Empirical distribution: $\\{0.35,\\,0.25,\\,0.18,\\,0.12,\\,0.06,\\,0.04\\}$.\n\n- Case $3$ (includes very long maturities):\n  - Maturities: $\\{0.5,\\,1.0,\\,1.5,\\,2.0,\\,5.0,\\,15.0,\\,30.0\\}$.\n  - Empirical distribution: $\\{0.26,\\,0.21,\\,0.17,\\,0.14,\\,0.10,\\,0.07,\\,0.05\\}$.\n\nParameter Domain. Restrict the search to the economically plausible set\n$$\n\\kappa \\in [10^{-4},\\,5.0],\\quad \\theta \\in [-0.05,\\,0.15],\\quad \\sigma \\in [10^{-5},\\,0.2],\\quad r_0 \\in [-0.02,\\,0.2].\n$$\n\nRequired Output. For each case in the order given above, compute the minimized value of $D_{\\mathrm{KL}}$ over $(\\kappa,\\theta,\\sigma,r_0)$ subject to the stated domain. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each minimized value rounded to $10$ decimal places, for example, $\\big[\\text{result}_1,\\text{result}_2,\\text{result}_3\\big]$.", "solution": "The problem presented is a well-defined task in computational finance. It requires the calibration of a one-factor Vasicek term structure model to empirically observed data. The calibration is formulated as a numerical optimization problem, specifically, the minimization of the Kullback-Leibler (KL) divergence between a model-implied probability distribution and a given empirical distribution. This is a rigorous and standard approach. We will proceed with a principled solution.\n\nThe core of the problem is to find the parameter vector $\\mathbf{x} = (\\kappa, \\theta, \\sigma, r_0)$ that minimizes the objective function $D_{\\mathrm{KL}}(p \\,\\|\\, q(\\mathbf{x}))$. The vector $\\mathbf{x}$ consists of the Vasicek model parameters: $\\kappa$ (mean-reversion speed), $\\theta$ (long-run mean), $\\sigma$ (volatility), and the initial short rate $r_0$. The optimization is performed over a specified, bounded domain for these parameters.\n\nThe objective function, the KL divergence, is given by:\n$$\nD_{\\mathrm{KL}}\\big(p \\,\\|\\, q(\\mathbf{x})\\big) = \\sum_{i=1}^n p_i \\log\\left(\\frac{p_i}{q_i(\\mathbf{x})}\\right)\n$$\nwhere $\\{p_i\\}_{i=1}^n$ is the fixed empirical distribution and $\\{q_i(\\mathbf{x})\\}_{i=1}^n$ is the model-implied distribution, which depends on the parameters $\\mathbf{x}$. The model-implied probabilities are derived from the zero-coupon bond prices $P(0, T_i)$ for a set of maturities $\\{T_i\\}_{i=1}^n$:\n$$\nq_i(\\mathbf{x}) = \\frac{P(0,T_i; \\mathbf{x})}{\\sum_{j=1}^n P(0,T_j; \\mathbf{x})}\n$$\nIn the Vasicek model, under the risk-neutral measure, the bond price is an exponential-affine function of the short rate:\n$$\nP(0,T) = \\exp\\big(A(T) - B(T)r_0\\big)\n$$\nThe functions $A(T)$ and $B(T)$ are themselves functions of the model parameters. Specifically, for a maturity $T > 0$:\n$$\nB(T; \\kappa) = \\frac{1 - e^{-\\kappa T}}{\\kappa}\n$$\n$$\nA(T; \\kappa, \\theta, \\sigma) = \\left(\\theta - \\frac{\\sigma^2}{2\\kappa^2}\\right)\\big(B(T) - T\\big) - \\frac{\\sigma^2}{4\\kappa}\\,B(T)^2\n$$\nFor the boundary case $T=0$, the conventions $A(0)=0$ and $B(0)=0$ are used, which correctly implies $P(0,0)=1$.\n\nThe problem is to solve the constrained non-linear optimization problem:\n$$\n\\min_{\\mathbf{x} \\in \\mathcal{D}} D_{\\mathrm{KL}}(p \\,\\|\\, q(\\mathbf{x}))\n$$\nThe search domain $\\mathcal{D}$ is the hyper-rectangle defined by:\n$\\kappa \\in [10^{-4}, 5.0]$, $\\theta \\in [-0.05, 0.15]$, $\\sigma \\in [10^{-5}, 0.2]$, and $r_0 \\in [-0.02, 0.2]$.\n\nThe objective function is non-linear and its dependencies on the parameters are complex, potentially leading to a landscape with multiple local minima. A simple gradient-based local optimizer might fail to find the global minimum. Therefore, a global optimization algorithm is the appropriate choice. We will use the `differential_evolution` algorithm provided by the `scipy.optimize` library. This is a population-based stochastic optimization method that is robust for finding the global minimum of functions over box-constrained domains.\n\nFor numerical stability, especially when dealing with exponentials, it is prudent to work with logarithms. The objective function can be rewritten as:\n$$\nD_{\\mathrm{KL}} = \\sum_{i=1}^n p_i (\\log p_i - \\log q_i)\n$$\nThe term $\\log q_i$ is computed as $\\log q_i = \\log P(0,T_i) - \\log(\\sum_j P(0,T_j))$. The sum of exponentials in the denominator is numerically unstable if computed directly. We can use the log-sum-exp stabilization trick:\n$$\n\\log\\left(\\sum_{j=1}^n P(0,T_j)\\right) = \\log\\left(\\sum_{j=1}^n \\exp\\big(\\log P(0,T_j)\\big)\\right)\n$$\nwhere $\\log P(0,T_j) = A(T_j) - B(T_j)r_0$. The `scipy.special.logsumexp` function implements this computation robustly.\n\nThe implementation will consist of a primary function that defines the objective $D_{\\mathrm{KL}}$ as a function of the parameter vector $\\mathbf{x}$. This function will be passed to the `differential_evolution` solver along with the specified bounds for the parameters. This process will be repeated for each of the three test cases, and the minimized KL divergence value will be recorded. A fixed seed for the random number generator is used to ensure the reproducibility of the optimization results.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import differential_evolution\nfrom scipy.special import logsumexp\n\ndef vasicek_bond_price_components(params, T_values):\n    \"\"\"\n    Calculates the A(T) and B(T) components for the Vasicek model bond price.\n    \n    Args:\n        params (list or np.ndarray): A list of parameters [kappa, theta, sigma, r0].\n            r0 is not used in this function but is part of the standard parameter vector.\n        T_values (np.ndarray): An array of maturities T.\n    \n    Returns:\n        (np.ndarray, np.ndarray): A tuple containing the A(T) and B(T) arrays.\n    \"\"\"\n    kappa, theta, sigma, _ = params\n    T_values = np.asarray(T_values, dtype=float)\n    \n    A_T = np.zeros_like(T_values)\n    B_T = np.zeros_like(T_values)\n    \n    # Isolate non-zero maturities to avoid division by zero in formulas.\n    # The convention for T=0 is A(0)=0, B(0)=0, which is handled by the initialization.\n    non_zero_T_mask = T_values > 1e-9\n\n    if np.any(non_zero_T_mask):\n        T = T_values[non_zero_T_mask]\n        \n        # The parameter domain for kappa is [1e-4, 5.0], so kappa is never zero.\n        # Direct computation of B(T) is safe.\n        exp_minus_kappa_T = np.exp(-kappa * T)\n        B_T_vals = (1.0 - exp_minus_kappa_T) / kappa\n        \n        # Calculate A(T) using the formula from the problem statement.\n        term_B_minus_T = B_T_vals - T\n        kappa_sq = kappa * kappa\n        sigma_sq = sigma * sigma\n        \n        A_T_vals = (theta - sigma_sq / (2.0 * kappa_sq)) * term_B_minus_T - \\\n                   (sigma_sq / (4.0 * kappa)) * (B_T_vals**2)\n        \n        # Assign calculated values to the corresponding positions in the arrays.\n        B_T[non_zero_T_mask] = B_T_vals\n        A_T[non_zero_T_mask] = A_T_vals\n        \n    return A_T, B_T\n\ndef kl_divergence_objective(params, T_values, p_dist):\n    \"\"\"\n    Objective function calculating the KL divergence for Vasicek model calibration.\n    \n    Args:\n        params (list or np.ndarray): A list of parameters [kappa, theta, sigma, r0].\n        T_values (np.ndarray): An array of maturities T.\n        p_dist (np.ndarray): The empirical probability distribution.\n        \n    Returns:\n        float: The KL divergence D_KL(p || q).\n    \"\"\"\n    kappa, theta, sigma, r0 = params\n    \n    # Calculate A(T) and B(T)\n    A_T, B_T = vasicek_bond_price_components(params, T_values)\n    \n    # Calculate the logarithm of bond prices\n    log_P_0_T = A_T - B_T * r0\n\n    # Handle potential numerical overflows from intermediate calculations\n    if np.any(np.isnan(log_P_0_T)) or np.any(np.isinf(log_P_0_T)):\n        return np.inf\n\n    # Calculate log of model-implied probabilities q_i using log-sum-exp for stability\n    log_S = logsumexp(log_P_0_T)\n    log_q_dist = log_P_0_T - log_S\n    \n    # Calculate KL divergence: D_KL(p || q) = sum(p_i * (log(p_i) - log(q_i)))\n    # The problem specifies p_i > 0, so log(p_dist) is safe.\n    kl_div = np.sum(p_dist * (np.log(p_dist) - log_q_dist))\n    \n    return kl_div\n\ndef solve():\n    \"\"\"\n    Main function to solve the calibration problem for all test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\n            np.array([0.25, 0.5, 1.0, 2.0, 5.0, 10.0]),\n            np.array([0.27, 0.25, 0.20, 0.15, 0.08, 0.05])\n        ),\n        (\n            np.array([0.0, 0.25, 0.5, 1.0, 4.0, 7.0]),\n            np.array([0.35, 0.25, 0.18, 0.12, 0.06, 0.04])\n        ),\n        (\n            np.array([0.5, 1.0, 1.5, 2.0, 5.0, 15.0, 30.0]),\n            np.array([0.26, 0.21, 0.17, 0.14, 0.10, 0.07, 0.05])\n        )\n    ]\n\n    # Define the parameter search domain (bounds for the optimizer)\n    bounds = [\n        (1e-4, 5.0),    # kappa\n        (-0.05, 0.15),  # theta\n        (1e-5, 0.2),    # sigma\n        (-0.02, 0.2)    # r0\n    ]\n\n    results = []\n    for maturities, emp_dist in test_cases:\n        # Define the objective function for the current case\n        objective_func = lambda p: kl_divergence_objective(p, maturities, emp_dist)\n        \n        # Perform global optimization using differential evolution to find the minimum KL divergence\n        # A seed is used for reproducibility of the stochastic optimization process.\n        result = differential_evolution(objective_func, bounds, seed=42)\n        \n        # The minimized value of the objective function\n        min_kl_divergence = result.fun\n        results.append(min_kl_divergence)\n\n    # Format the results to 10 decimal places as required.\n    results_str = [f\"{r:.10f}\" for r in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```", "id": "2370055"}, {"introduction": "The power of the affine framework extends far beyond modeling a single yield curve. This advanced practice [@problem_id:2370052] challenges you to build and calibrate a joint model for two distinct but related markets: interest rates and equity volatility. You will implement a two-factor model, combining a Vasicek process for the short-rate factor and a Cox-Ingersoll-Ross (CIR) process for stochastic variance, to simultaneously price bond yields and VIX futures, a core skill in modern asset pricing.", "problem": "You are tasked with constructing and calibrating a joint affine term structure model that simultaneously prices continuously compounded zero-coupon interest rate yields and the term structure of the Cboe Volatility Index (VIX) futures. All quantities must be expressed in annualized units as decimals. For example, an annualized yield of two tenths must be written as $0.2$, and an annualized variance of four hundredths must be written as $0.04$. Angles do not appear in this problem, so no angle unit is required.\n\nThe model is specified under the risk-neutral probability measure, denoted by $\\mathbb{Q}$. The state consists of two independent one-dimensional factors: an Ornstein–Uhlenbeck factor for interest rates and a Cox–Ingersoll–Ross factor for equity variance. The dynamics are:\n- Interest rate factor: $dx_t = k_x (\\theta_x - x_t)\\,dt + \\sigma_x\\,dW^{(1)}_t$, where $W^{(1)}$ is a standard Brownian motion.\n- Short rate: $r_t = \\delta_0 + x_t$.\n- Equity instantaneous variance factor: $dv_t = k_v (\\theta_v - v_t)\\,dt + \\sigma_v \\sqrt{v_t}\\,dW^{(2)}_t$, where $W^{(2)}$ is an independent standard Brownian motion.\n\nAssume independence between $W^{(1)}$ and $W^{(2)}$. The parameter vector to calibrate is $p = [k_x,\\theta_x,\\sigma_x,\\delta_0,x_0,k_v,\\theta_v,v_0]$, where $x_0 = x_t$ and $v_0 = v_t$ at time $t$ are the current states. All parameters that represent rates, volatilities, or levels must be nonnegative, except $x_0$ which may be negative.\n\nFor a maturity $\\tau > 0$, the model price of a zero-coupon bond is defined by its risk-neutral valuation:\n$$\nP(t,t+\\tau) \\equiv \\mathbb{E}^{\\mathbb{Q}}\\!\\left[\\exp\\!\\left(-\\int_t^{t+\\tau} r_s\\,ds\\right)\\Big|\\,x_t\\right],\n$$\nand the model yield is defined as the continuously compounded annualized yield\n$$\ny(\\tau) \\equiv -\\frac{1}{\\tau}\\,\\ln P(t,t+\\tau).\n$$\n\nFor a VIX futures contract maturing at time $T \\ge 0$, let $\\Delta = 30/365$ years be the VIX window length. In this problem, define the VIX futures quote as the square root of the risk-neutral expected average annualized variance over $[T,T+\\Delta]$:\n$$\nF_{\\mathrm{VIX}}(T) \\equiv \\left(\\frac{1}{\\Delta}\\,\\mathbb{E}^{\\mathbb{Q}}\\!\\left[\\int_T^{T+\\Delta} v_s\\,ds\\ \\Big|\\ v_t\\right]\\right)^{1/2}.\n$$\nAll $F_{\\mathrm{VIX}}(T)$ must be expressed as decimals (for example, $0.2$), not percentages.\n\nYour program must implement from first principles the valuation definitions above, derive any necessary intermediate relationships, and calibrate the parameter vector $p$ by minimizing the sum of squared differences between observed and model-implied quantities for each test case described below. You must use only the model, the definitions, and the data given in this problem statement.\n\nTest Suite. For each test case, the observed market data must be generated exactly from the model using the provided true parameters $p^{\\mathrm{true}}$ and the definitions of $P(t,t+\\tau)$ and $F_{\\mathrm{VIX}}(T)$ above (i.e., the data are noise-free). Then, calibrate $p$ using least squares to recover the true parameters from these observables, subject to natural nonnegativity constraints and reasonable bounds. For each test case, report a boolean that is true if and only if all components of the calibrated parameter vector $\\hat{p}$ satisfy $|\\hat{p}_i - p^{\\mathrm{true}}_i| \\le \\varepsilon_i$ for the tolerance vector\n$$\n\\varepsilon = [0.05,\\ 0.005,\\ 0.005,\\ 0.002,\\ 0.005,\\ 0.10,\\ 0.005,\\ 0.010].\n$$\n\nUse $\\Delta = 30/365$ years in all cases. The maturities and true parameters for each test are:\n\n- Case 1 (baseline):\n  - Yield maturities $\\tau = [0.25,\\ 1.0,\\ 2.0,\\ 5.0,\\ 10.0]$ years.\n  - VIX futures maturities $T = [0.0,\\ 0.25,\\ 0.5,\\ 1.0]$ years.\n  - True parameters $p^{\\mathrm{true}} = [0.6,\\ 0.02,\\ 0.02,\\ 0.01,\\ 0.015,\\ 1.5,\\ 0.04,\\ 0.05]$.\n\n- Case 2 (low-rate, low-variance):\n  - Yield maturities $\\tau = [0.25,\\ 1.0,\\ 2.0,\\ 5.0,\\ 10.0]$ years.\n  - VIX futures maturities $T = [0.0,\\ 0.25,\\ 0.5,\\ 1.0]$ years.\n  - True parameters $p^{\\mathrm{true}} = [0.5,\\ 0.01,\\ 0.01,\\ 0.0,\\ 0.005,\\ 2.0,\\ 0.02,\\ 0.015]$.\n\n- Case 3 (slow mean reversion, long end):\n  - Yield maturities $\\tau = [0.5,\\ 3.0,\\ 7.0,\\ 15.0,\\ 20.0]$ years.\n  - VIX futures maturities $T = [0.0,\\ 0.5,\\ 1.0,\\ 2.0]$ years.\n  - True parameters $p^{\\mathrm{true}} = [0.2,\\ 0.03,\\ 0.015,\\ 0.005,\\ 0.025,\\ 0.8,\\ 0.06,\\ 0.08]$.\n\nYour program must:\n1. For each test case, generate the observed yields and VIX futures exactly from the model with the given $p^{\\mathrm{true}}$.\n2. Calibrate $\\hat{p}$ by minimizing the sum of squared deviations between model-implied and observed yields and VIX futures for that case.\n3. Check the absolute deviations $|\\hat{p}_i - p^{\\mathrm{true}}_i|$ against the tolerance vector $\\varepsilon$.\n4. Aggregate the three boolean results into a single list.\n\nFinal output format. Your program should produce a single line of output containing the three boolean results as a comma-separated list enclosed in square brackets, for example, \"[True,False,True]\". No other text should be printed. All rates, volatilities, and variances must be treated as annualized decimals throughout.", "solution": "The problem presented is a well-posed calibration task within the established framework of computational finance. It requires the construction and calibration of a two-factor affine term structure model. The state variables comprise an Ornstein-Uhlenbeck (Vasicek) process for the interest rate factor and a Cox-Ingersoll-Ross (CIR) process for the stochastic variance factor. The problem is scientifically grounded, internally consistent, and contains all necessary information for a unique solution. Therefore, it is deemed valid, and a full solution is provided below.\n\nThe core of the solution lies in deriving the analytical, closed-form expressions for the model-implied observables: the zero-coupon yield curve $y(\\tau)$ and the VIX futures term structure $F_{\\mathrm{VIX}}(T)$. Due to the specified independence of the underlying Brownian motions $W^{(1)}_t$ and $W^{(2)}_t$, the calibration problem fortuitously decouples into two separate, smaller optimization problems. One calibrates the interest rate parameters from yield data, and the other calibrates the variance process parameters from VIX futures data.\n\n**1. Interest Rate Model and Yield Curve**\n\nThe short rate $r_t$ is defined as an affine function of the state variable $x_t$:\n$$\nr_t = \\delta_0 + x_t\n$$\nwhere $x_t$ follows the Ornstein-Uhlenbeck process under the risk-neutral measure $\\mathbb{Q}$:\n$$\ndx_t = k_x (\\theta_x - x_t)\\,dt + \\sigma_x\\,dW^{(1)}_t\n$$\nThis structure is a variant of the Vasicek model. The price of a zero-coupon bond maturing at time $t+\\tau$ is given by the risk-neutral expectation:\n$$\nP(t, t+\\tau) = \\mathbb{E}^{\\mathbb{Q}}\\!\\left[\\exp\\!\\left(-\\int_t^{t+\\tau} r_s\\,ds\\right)\\Big|\\,x_t\\right] = \\mathbb{E}^{\\mathbb{Q}}\\!\\left[\\exp\\!\\left(-\\int_t^{t+\\tau} (\\delta_0 + x_s)\\,ds\\right)\\Big|\\,x_t\\right]\n$$\nThis separates into $P(t, t+\\tau) = \\exp(-\\delta_0 \\tau) \\mathbb{E}^{\\mathbb{Q}}\\!\\left[\\exp\\!\\left(-\\int_t^{t+\\tau} x_s\\,ds\\right)\\Big|\\,x_t\\right]$.\nFor an affine model, the bond price takes the exponential-affine form. The expectation term is the standard bond price in a Vasicek model with zero constant drift, which can be written as $\\exp(A_x(\\tau) - B_x(\\tau)x_t)$. Thus, the full bond price is:\n$$\nP(t, t+\\tau) = \\exp(A_x(\\tau) - \\delta_0 \\tau - B_x(\\tau)x_t)\n$$\nwhere $B_x(\\tau)$ and $A_x(\\tau)$ are solutions to Riccati-type ordinary differential equations derived from the Feynman-Kac theorem. The solutions are:\n$$\nB_x(\\tau) = \\frac{1 - e^{-k_x \\tau}}{k_x}\n$$\n$$\nA_x(\\tau) = (\\theta_x - \\frac{\\sigma_x^2}{2k_x^2})(B_x(\\tau) - \\tau) - \\frac{\\sigma_x^2}{4k_x}B_x^2(\\tau)\n$$\nThe continuously compounded yield $y(\\tau)$ is then found from its definition:\n$$\ny(\\tau) = -\\frac{1}{\\tau} \\ln P(t, t+\\tau) = -\\frac{1}{\\tau} (A_x(\\tau) - \\delta_0 \\tau - B_x(\\tau)x_t) = \\frac{B_x(\\tau)}{\\tau}x_t - \\frac{A_x(\\tau)}{\\tau} + \\delta_0\n$$\nThis provides a closed-form expression for the yield for a given maturity $\\tau$ as a function of the parameters $\\{k_x, \\theta_x, \\sigma_x, \\delta_0\\}$ and the current state $x_t$.\n\n**2. Equity Variance Model and VIX Futures**\n\nThe instantaneous variance $v_t$ is governed by the CIR process:\n$$\ndv_t = k_v (\\theta_v - v_t)\\,dt + \\sigma_v \\sqrt{v_t}\\,dW^{(2)}_t\n$$\nThe VIX futures quote $F_{\\mathrm{VIX}}(T)$ is defined by the expected future average variance:\n$$\nF_{\\mathrm{VIX}}(T)^2 = \\frac{1}{\\Delta}\\,\\mathbb{E}^{\\mathbb{Q}}\\!\\left[\\int_T^{T+\\Delta} v_s\\,ds\\ \\Big|\\ v_t\\right]\n$$\nBy linearity of expectation and Fubini's theorem, we can interchange the expectation and integral operators:\n$$\n\\mathbb{E}^{\\mathbb{Q}}\\!\\left[\\int_T^{T+\\Delta} v_s\\,ds\\ \\Big|\\ v_t\\right] = \\int_T^{T+\\Delta} \\mathbb{E}^{\\mathbb{Q}}[v_s | v_t]\\,ds\n$$\nFor a CIR process, the conditional expectation of the future state is known in closed form:\n$$\n\\mathbb{E}^{\\mathbb{Q}}[v_s | v_t] = v_t e^{-k_v (s-t)} + \\theta_v (1 - e^{-k_v (s-t)})\n$$\nIntegrating this expression from $s=T$ to $s=T+\\Delta$ (with current time being $t$) yields the expected total variance:\n$$\n\\int_T^{T+\\Delta} \\mathbb{E}^{\\mathbb{Q}}[v_s | v_t]\\,ds = \\frac{v_t - \\theta_v}{k_v} (e^{-k_v (T-t)} - e^{-k_v (T+\\Delta-t)}) + \\theta_v \\Delta\n$$\nDividing by $\\Delta$ gives the expected average variance. Setting $t=0$ for simplicity, we obtain the squared VIX futures value:\n$$\nF_{\\mathrm{VIX}}(T)^2 = (v_0 - \\theta_v) e^{-k_v T} \\frac{1 - e^{-k_v \\Delta}}{k_v \\Delta} + \\theta_v\n$$\nNotably, this expression depends on the parameters $\\{k_v, \\theta_v\\}$ and the current state $v_0$, but it is independent of the volatility-of-variance parameter $\\sigma_v$. This is a crucial observation, as it means $\\sigma_v$ is not identifiable from VIX futures data alone, and the problem is structured correctly by excluding it from the parameter vector to be calibrated.\n\n**3. Calibration Procedure**\n\nThe calibration is performed by minimizing the sum of squared errors (SSE) between the model-implied values and the observed market (in this case, synthetically generated) data. The objective function $L(p)$ for the parameter vector $p = [k_x,\\theta_x,\\sigma_x,\\delta_0,x_0,k_v,\\theta_v,v_0]$ is:\n$$\nL(p) = \\sum_{i} (y^{\\text{model}}(\\tau_i; p) - y^{\\text{obs}}(\\tau_i))^2 + \\sum_{j} (F^{\\text{model}}_{\\mathrm{VIX}}(T_j; p) - F^{\\text{obs}}_{\\mathrm{VIX}}(T_j))^2\n$$\nDue to the independence of the factors, this objective function separates into two components:\n$$\nL(p) = L_x(k_x,\\theta_x,\\sigma_x,\\delta_0,x_0) + L_v(k_v,\\theta_v,v_0)\n$$\nThis allows us to perform two independent minimizations:\n1.  Calibrate $p_x = [k_x,\\theta_x,\\sigma_x,\\delta_0,x_0]$ by minimizing $L_x$ using yield data.\n2.  Calibrate $p_v = [k_v,\\theta_v,v_0]$ by minimizing $L_v$ using VIX futures data.\n\nThe minimizations are carried out using a numerical optimization routine, specifically the L-BFGS-B algorithm, which accommodates box constraints. The constraints on the parameters are: $k_x, \\sigma_x, k_v, v_0 \\ge \\epsilon > 0$ (to maintain numerical stability) and $\\theta_x, \\delta_0, \\theta_v \\ge 0$. The parameter $x_0$ is unconstrained.\n\nFor numerical stability, when the mean-reversion parameters $k_x$ or $k_v$ approach zero, the functions are evaluated using their corresponding Taylor series expansions to avoid catastrophic cancellation and division by zero.\n\nFor each test case, the program first generates the \"observed\" data using the provided true parameters $p^{\\mathrm{true}}$. Then, starting from a generic initial guess, it runs the two calibration procedures to find the estimated parameter vector $\\hat{p}$. Finally, it checks if the absolute difference between each component of $\\hat{p}$ and $p^{\\mathrm{true}}$ is within the specified tolerance vector $\\varepsilon$.", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Solves the affine term structure model calibration problem for the given test cases.\n    \"\"\"\n    \n    # Global constants\n    DELTA = 30.0 / 365.0\n    EPSILON = np.array([0.05, 0.005, 0.005, 0.002, 0.005, 0.10, 0.005, 0.010])\n\n    def yield_model(p_x, taus):\n        \"\"\"\n        Computes yields for the Vasicek-type model.\n        p_x: [k_x, theta_x, sigma_x, delta_0, x_0]\n        \"\"\"\n        k_x, theta_x, sigma_x, delta_0, x_0 = p_x\n        taus = np.asarray(taus, dtype=float)\n\n        # Handle k_x -> 0 case for numerical stability using a Taylor expansion\n        if abs(k_x) < 1e-8:\n            tau_sq = taus**2\n            yields = (x_0 + delta_0 \n                      - sigma_x**2 * tau_sq / 6.0\n                      - k_x * taus / 2.0 * (x_0 - theta_x))\n            return yields\n        \n        B_x = (1.0 - np.exp(-k_x * taus)) / k_x\n        A_x = ((theta_x - sigma_x**2 / (2.0 * k_x**2)) * (B_x - taus)\n               - (sigma_x**2 / (4.0 * k_x)) * B_x**2)\n        \n        log_p = A_x - delta_0 * taus - B_x * x_0\n        yields = -log_p / taus\n        return yields\n\n    def vix_futures_model(p_v, Ts):\n        \"\"\"\n        Computes VIX futures quotes for the CIR model.\n        p_v: [k_v, theta_v, v_0]\n        \"\"\"\n        k_v, theta_v, v_0 = p_v\n        Ts = np.asarray(Ts, dtype=float)\n\n        # Handle k_v -> 0 case for numerical stability\n        if abs(k_v) < 1e-8:\n            avg_var = v_0 - k_v * (v_0 - theta_v) * (Ts + DELTA / 2.0)\n            avg_var = np.maximum(avg_var, 0)\n            return np.sqrt(avg_var)\n        \n        factor = (1.0 - np.exp(-k_v * DELTA)) / (k_v * DELTA)\n        avg_var = (v_0 - theta_v) * np.exp(-k_v * Ts) * factor + theta_v\n        # Ensure variance is non-negative before taking the square root\n        avg_var = np.maximum(avg_var, 0)\n        \n        return np.sqrt(avg_var)\n\n    test_cases = [\n        {\n            \"tau_yields\": [0.25, 1.0, 2.0, 5.0, 10.0],\n            \"T_vix\": [0.0, 0.25, 0.5, 1.0],\n            \"p_true\": np.array([0.6, 0.02, 0.02, 0.01, 0.015, 1.5, 0.04, 0.05]),\n        },\n        {\n            \"tau_yields\": [0.25, 1.0, 2.0, 5.0, 10.0],\n            \"T_vix\": [0.0, 0.25, 0.5, 1.0],\n            \"p_true\": np.array([0.5, 0.01, 0.01, 0.0, 0.005, 2.0, 0.02, 0.015]),\n        },\n        {\n            \"tau_yields\": [0.5, 3.0, 7.0, 15.0, 20.0],\n            \"T_vix\": [0.0, 0.5, 1.0, 2.0],\n            \"p_true\": np.array([0.2, 0.03, 0.015, 0.005, 0.025, 0.8, 0.06, 0.08]),\n        },\n    ]\n\n    results = []\n    \n    # Define common initial guesses for the optimizers\n    p0_x = np.array([0.4, 0.025, 0.025, 0.01, 0.02])\n    p0_v = np.array([1.0, 0.05, 0.05])\n    \n    # Define bounds for parameters\n    bounds_x = [(1e-6, None), (0, None), (1e-6, None), (0, None), (None, None)]\n    bounds_v = [(1e-6, None), (0, None), (1e-6, None)]\n\n    for case in test_cases:\n        p_true = case[\"p_true\"]\n        tau_yields = case[\"tau_yields\"]\n        T_vix = case[\"T_vix\"]\n        \n        p_true_x = p_true[:5]\n        p_true_v = p_true[5:]\n        \n        # 1. Generate observed data from the true model\n        y_obs = yield_model(p_true_x, tau_yields)\n        f_obs = vix_futures_model(p_true_v, T_vix)\n        \n        # 2. Calibrate parameters\n        \n        # --- Interest rate part ---\n        def objective_x(p_x):\n            y_model = yield_model(p_x, tau_yields)\n            error = np.sum((y_model - y_obs)**2)\n            return error\n\n        res_x = minimize(objective_x, p0_x, method='L-BFGS-B', bounds=bounds_x, options={'ftol': 1e-12})\n        p_hat_x = res_x.x\n\n        # --- Variance part ---\n        def objective_v(p_v):\n            f_model = vix_futures_model(p_v, T_vix)\n            error = np.sum((f_model - f_obs)**2)\n            return error\n\n        res_v = minimize(objective_v, p0_v, method='L-BFGS-B', bounds=bounds_v, options={'ftol': 1e-12})\n        p_hat_v = res_v.x\n        \n        p_hat = np.concatenate((p_hat_x, p_hat_v))\n        \n        # 3. Check against tolerances\n        is_close = np.all(np.abs(p_hat - p_true) <= EPSILON)\n        results.append(is_close)\n\n    # 4. Print final result in the required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2370052"}]}