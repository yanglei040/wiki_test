{"hands_on_practices": [{"introduction": "This exercise provides a foundational look at latency hiding, the primary motivation for instruction sequencing. By analyzing a long-latency divide operation, you'll see how a compiler can rearrange code to fill potential pipeline stalls with useful, independent work. This practice quantifies the direct performance benefit of smart scheduling on a simple, in-order processor. [@problem_id:3647160]", "problem": "A compiler targets an in-order, single-issue pipeline with the following characteristics grounded in standard pipeline semantics for dependences and latencies. The machine can issue at most $1$ instruction per cycle. An instruction that uses the result of a prior instruction can issue only when all of its source operands are available. Each instruction has a fixed producer-to-consumer latency equal to the number of cycles between the issue of the producer and the earliest cycle at which a dependent consumer can issue with zero stall. The integer Arithmetic Logic Unit (ALU) operations have latency $1$ cycle. The integer divide operation has latency $L_{\\text{div}}$ cycles. Assume structural hazards are absent and functional units are always available when operands are ready.\n\nConsider a loop body that, in a naive unscheduled form, executes the following sequence per iteration:\n- Compute $t \\leftarrow a / b$ using an integer divide with latency $L_{\\text{div}}$.\n- Immediately use $t$ in a dependent integer ALU operation $u \\leftarrow t + c$.\n- Execute $M$ integer ALU operations that are independent of both the divide result $t$ and its consumer $u$. These $M$ operations can be freely reordered relative to the divide and its consumer as long as their mutual program order among themselves is preserved, and all have latency $1$ cycle.\n\nA compiler performs local instruction scheduling to hide as much of the divide latency as possible by interleaving some of the $M$ independent integer ALU operations between the divide that produces $t$ and the consumer that uses $t$. Assume no other constraints prevent such motion, and that the machine must still issue in order.\n\nGiven $L_{\\text{div}} = 19$ and $M = 12$, derive from first principles the number of cycles per iteration saved by this scheduling relative to the naive order where the consumer of $t$ is placed immediately after the divide. Express your answer as an integer number of cycles saved per iteration. Do not round; express the final answer in cycles.", "solution": "This problem requires an analysis of pipeline stalls due to data dependencies in a simple in-order, single-issue processor. We must determine the number of cycles saved by reordering instructions to hide the long latency of a divide operation. The total number of cycles for an iteration is defined as the number of cycles from the issue of the first instruction to the issue of the last instruction, inclusive. On a single-issue machine, this is equivalent to the total number of issue slots (busy or stalled) required for the sequence.\n\nLet us first analyze the total cycles per iteration for the naive, unscheduled instruction sequence. The sequence is:\n$1$. `div`: $t \\leftarrow a / b$\n$2$. `add`: $u \\leftarrow t + c$\n$3$. $M$ independent ALU operations.\n\nThe machine is in-order and single-issue. Let the `div` instruction issue at cycle $C_0$. The `add` instruction is data-dependent on the `div` instruction, which has a latency of $L_{\\text{div}}$ cycles. By definition, this means a dependent instruction can issue no earlier than $L_{\\text{div}}$ cycles after the `div` instruction has issued. So, the `add` instruction cannot issue before cycle $C_0 + L_{\\text{div}}$.\n\nIn the naive sequence, the `add` instruction immediately follows the `div`. The pipeline will attempt to issue the `add` at cycle $C_0 + 1$. However, because the operand $t$ is not ready, the pipeline must stall. The stalls will occupy the issue slots from cycle $C_0 + 1$ up to, but not including, cycle $C_0 + L_{\\text{div}}$. The number of stall cycles is $(C_0 + L_{\\text{div}} - 1) - (C_0 + 1) + 1 = L_{\\text{div}} - 1$.\n\nThe total number of cycles, $T_{\\text{naive}}$, is the sum of cycles for issuing each instruction and any interposed stalls:\n- $1$ cycle for the `div` instruction to issue.\n- $L_{\\text{div}} - 1$ cycles of pipeline stall.\n- $1$ cycle for the dependent `add` instruction to issue.\n- $M$ cycles for the $M$ independent ALU operations to issue sequentially.\n\nSumming these, the total cycles for the naive sequence is:\n$$T_{\\text{naive}} = 1 + (L_{\\text{div}} - 1) + 1 + M = L_{\\text{div}} + M + 1$$\n\nNext, we analyze the total cycles for the optimized, scheduled instruction sequence. The compiler moves the $M$ independent operations between the `div` and the dependent `add` to hide the divide latency. The scheduled sequence is:\n$1$. `div`: $t \\leftarrow a / b$\n$2$. $M$ independent ALU operations.\n$3$. `add`: $u \\leftarrow t + c$\n\nLet the `div` instruction issue at cycle $C_0$. Since the following $M$ ALU operations are independent, they can be issued in the subsequent cycles, one per cycle.\n- The `div` instruction issues at cycle $C_0$.\n- The $M$ independent operations issue at cycles $C_0+1, C_0+2, \\dots, C_0+M$.\n\nAfter the last of the $M$ independent operations has issued at cycle $C_0+M$, the pipeline is ready to issue the `add` instruction at cycle $C_0+M+1$. However, the `add` is still data-dependent on the `div`. The result $t$ is available at cycle $C_0 + L_{\\text{div}}$. Therefore, the `add` instruction can only issue at the later of these two times: the time it becomes available in the instruction stream and the time its data dependency is resolved.\nThe issue cycle for the `add` is $C_{\\text{issue,add}} = \\max(C_0+M+1, C_0+L_{\\text{div}})$.\nLet's normalize by setting $C_0 = 0$. The `add` issues at cycle $\\max(M+1, L_{\\text{div}})$.\n\nThe total number of cycles for the scheduled sequence, $T_{\\text{scheduled}}$, can be calculated by summing the issue slots.\n- $1$ cycle for the `div` instruction.\n- $M$ cycles for the $M$ independent operations.\n- A potential stall period before the `add` can issue.\n- $1$ cycle for the `add` instruction.\n\nThe `div` and the $M$ operations issue back-to-back, taking $M+1$ cycles. At this point, it is cycle $M+1$ (assuming we start at cycle $1$). The `add` is ready to issue. The data from `div` is ready at cycle $1+L_{\\text{div}}$. The `add` can issue at cycle $\\max(M+2, 1+L_{\\text{div}})$, if we consider issue cycles.\nLet's re-derive by counting slots. The number of slots for `div` and the $M$ ops is $M+1$. The time elapsed is $M+1$ cycles. The number of cycles passed between `div` issue and `add` being ready to issue (structurally) is $M+1$. The required time separation is $L_{\\text{div}}$. If $M+1  L_{\\text{div}}$, we need to stall for $L_{\\text{div}} - (M+1)$ cycles.\nThe total cycles are:\n$T_{\\text{scheduled}} = (\\text{cycles for div}) + (\\text{cycles for M ops}) + (\\text{stall cycles}) + (\\text{cycles for add})$\n$T_{\\text{scheduled}} = 1 + M + \\max(0, L_{\\text{div}} - (M+1)) + 1 = M+2 + \\max(0, L_{\\text{div}}-M-1)$.\nIf $M+1 \\ge L_{\\text{div}}$, $T_{\\text{scheduled}} = M+2$.\nIf $M+1  L_{\\text{div}}$, $T_{\\text{scheduled}} = M+2 + L_{\\text{div}}-M-1 = L_{\\text{div}}+1$.\nThis can be expressed as $T_{\\text{scheduled}} = \\max(M+2, L_{\\text{div}}+1)$.\n\nThe number of cycles saved, $\\Delta T$, is the difference between the naive and scheduled execution times:\n$\\Delta T = T_{\\text{naive}} - T_{\\text{scheduled}}$\n$\\Delta T = (L_{\\text{div}} + M + 1) - \\max(M+2, L_{\\text{div}}+1)$\n\nLet's evaluate this based on the relationship between $M$ and $L_{\\text{div}}$.\nCase 1: $M+1 \\ge L_{\\text{div}}$ (or $M \\ge L_{\\text{div}}-1$). This means there are enough independent instructions to completely hide the divide latency.\nIn this case, $\\max(M+2, L_{\\text{div}}+1) = M+2$.\n$\\Delta T = (L_{\\text{div}} + M + 1) - (M+2) = L_{\\text{div}} - 1$.\nThe number of saved cycles equals the number of stall cycles in the naive schedule, which is $L_{\\text{div}}-1$.\n\nCase 2: $M+1  L_{\\text{div}}$ (or $M  L_{\\text{div}}-1$). There are not enough independent instructions to fully hide the latency.\nIn this case, $\\max(M+2, L_{\\text{div}}+1) = L_{\\text{div}}+1$.\n$\\Delta T = (L_{\\text{div}} + M + 1) - (L_{\\text{div}}+1) = M$.\nThe number of saved cycles equals the number of independent instructions, $M$, that could be used to fill the stall slots.\n\nCombining these two cases, the number of cycles saved is the number of stall slots ($L_{\\text{div}}-1$) that can be filled by the available $M$ independent instructions. This is given by:\n$$\\Delta T = \\min(M, L_{\\text{div}}-1)$$\n\nWe are given the values $L_{\\text{div}} = 19$ and $M=12$.\nWe calculate the number of potential stall cycles:\n$L_{\\text{div}}-1 = 19-1 = 18$.\nWe have $M=12$ independent instructions.\nSince $M  L_{\\text{div}}-1$ ($12  18$), we are in the second case. We can only fill $12$ of the $18$ stall slots.\nThe number of cycles saved is:\n$$\\Delta T = \\min(12, 18) = 12$$\n\nThe number of cycles saved per iteration is $12$.", "answer": "$$\n\\boxed{12}\n$$", "id": "3647160"}, {"introduction": "Moving beyond simple arithmetic, this problem delves into the complexities of memory operations. Reordering loads and stores offers significant performance potential but is only safe if the operations are independent, a fact established by alias analysis. This exercise asks you to verify the correctness of such a reordering and then calculate the speedup achieved by scheduling an independent load before a store, thereby minimizing pipeline stalls. [@problem_id:3647175]", "problem": "Consider a single-threaded program compiled for an in-order, single-issue pipeline that enforces Sequential Consistency (SC). The compiler is deciding whether to move a load above a preceding store. The original sequence in a basic block is:\n- store: $*q = y$\n- load: $x = *p$\n- add: $z = x + k$\nAssume the following:\n- Alias analysis has proved $p \\neq q$ throughout the basic block.\n- A load has latency $L = 4$ cycles; its destination register becomes available exactly $L$ cycles after the load issues.\n- A store and an add each require $1$ cycle to issue.\n- The pipeline issues at most one instruction per cycle and cannot issue an instruction whose operands are not ready; when an instruction is not issuable due to dependency, a bubble (an idle cycle) is inserted.\n- There are no other instructions available to fill bubbles and no structural hazards beyond those implied by the above latencies.\n\nUsing fundamental definitions of memory dependence and the SC memory model, analyze whether moving the load $x = *p$ above the store $*q = y$ is semantics-preserving under the assumption $p \\neq q$. Then, quantify the performance impact by computing the speedup factor $S$, defined as the ratio of the total number of issue cycles needed to issue the three instructions with the original order to the total number of issue cycles needed after reordering the load above the store. Express $S$ as an exact value. No rounding is required.", "solution": "The analysis is divided into two parts: first, determining if the instruction reordering is semantics-preserving, and second, quantifying the performance impact.\n\n**Part 1: Correctness of Reordering**\n\nThe original instruction sequence is:\n$1.$ `store: *q = y`\n$2.$ `load: x = *p`\n$3.$ `add: z = x + k`\n\nThe proposed reordered sequence is:\n$1.$ `load: x = *p`\n$2.$ `store: *q = y`\n$3.$ `add: z = x + k`\n\nThe reordering involves moving a `load` instruction above a preceding `store` instruction. In general, interchanging memory operations can violate program semantics. The primary concern is a memory dependence, specifically a Read-After-Write (RAW) dependence, also known as a true dependence. A RAW dependence exists if the `store` writes to a memory location that the `load` subsequently reads.\n\nIn this case, the `store` writes to the memory location at address $q$, and the `load` reads from the memory location at address $p$. A RAW dependence exists if and only if $p=q$. However, the problem statement explicitly provides that alias analysis has proven $p \\neq q$. This guarantee means the `store` and `load` operations access distinct memory locations. Consequently, there is no memory dependence between them.\n\nThe governing memory model is Sequential Consistency (SC). For a single-threaded program, SC requires that memory operations appear to execute in the order specified by the program. However, this constraint applies to the observable effects of dependent operations. Since the `store` to $*q$ and the `load` from $*p$ are independent ($p \\neq q$), reordering them does not change the value loaded into $x$ or the final value stored at address $q$. The `add` instruction's behavior is also unchanged as it depends only on the value of $x$, which is correctly fetched from $*p$. Therefore, the reordering is a semantics-preserving transformation.\n\n**Part 2: Performance Analysis and Speedup Calculation**\n\nWe analyze the number of issue cycles required for both sequences on the given in-order, single-issue pipeline. A cycle in which no instruction can be issued due to a data dependency is called a bubble or a stall.\n\n**Original Sequence Execution:**\nThe sequence is (`store`, `load`, `add`). The `add` instruction has a true data dependence (RAW) on the `load` instruction through the register $x$. The load latency is given as $L=4$ cycles. An instruction dependent on a load's result can issue $L$ cycles after the load itself issues.\n\n- Cycle $1$: The `store: *q = y` instruction is issued. It completes in $1$ cycle.\n- Cycle $2$: The `load: x = *p` instruction is issued. Its result, $x$, will be available for a subsequent instruction to use at the beginning of cycle $T_{\\text{issue}} + L = 2 + 4 = 6$.\n- Cycle $3$: The pipeline attempts to issue `add: z = x + k`. This instruction depends on the register $x$. As determined above, $x$ is not available until cycle $6$. The pipeline must stall. A bubble is inserted.\n- Cycle $4$: Pipeline stalls. A bubble is inserted.\n- Cycle $5$: Pipeline stalls. A bubble is inserted.\n- Cycle $6$: The value of $x$ is now available. The `add: z = x + k` instruction is issued.\n\nThe last instruction issues on cycle $6$. The total number of cycles to issue the three instructions is $T_{\\text{original}} = 6$.\n\n**Reordered Sequence Execution:**\nThe sequence is (`load`, `store`, `add`). The `store` is independent of the `load`. The `add` still depends on the `load`.\n\n- Cycle $1$: The `load: x = *p` instruction is issued. Its result, $x$, will be available at the beginning of cycle $T_{\\text{issue}} + L = 1 + 4 = 5$.\n- Cycle $2$: The pipeline attempts to issue the next instruction, `store: *q = y`. This instruction has no dependencies on the in-flight `load`. The in-order pipeline can issue it.\n- Cycle $3$: The pipeline attempts to issue `add: z = x + k`. This instruction depends on register $x$, which is not available until cycle $5$. The pipeline stalls. A bubble is inserted.\n- Cycle $4$: Pipeline stalls. A bubble is inserted.\n- Cycle $5$: The value of $x$ is now available. The `add: z = x + k` instruction is issued.\n\nThe last instruction issues on cycle $5$. The total number of cycles to issue the three instructions is $T_{\\text{reordered}} = 5$.\n\nThe reordering allows the independent `store` instruction to be executed during the `load`'s latency period, effectively hiding one cycle of the stall that would otherwise occur.\n\n**Speedup Calculation:**\nThe speedup factor $S$ is defined as the ratio of the original execution time to the reordered execution time.\n\n$$ S = \\frac{T_{\\text{original}}}{T_{\\text{reordered}}} $$\n\nSubstituting the calculated values:\n\n$$ S = \\frac{6}{5} $$\n\nThe speedup is an exact value, as requested.", "answer": "$$\\boxed{\\frac{6}{5}}$$", "id": "3647175"}, {"introduction": "This final practice combines the principles of data dependency and resource management in a realistic, superscalar processor model. You will be tasked with identifying the critical path that defines the minimum possible execution time and then constructing a complete, cycle-by-cycle schedule that achieves this bound. This exercise simulates the complex balancing act a real-world compiler performs to maximize instruction-level parallelism. [@problem_id:3647154]", "problem": "Consider a basic block with $n=8$ instructions to be scheduled on a single-issue core with multiple functional units and explicit resource limits. The goal is to compute a critical path for the dependence structure and to construct a legal schedule that achieves the critical-path length, if possible. The instruction set and machine model are as follows.\n\nMachine model:\n- Up to $2$ instructions may be issued per cycle.\n- There are $2$ load/store units (each can accept at most $1$ memory operation per cycle; the memory system is dual-ported, so up to $2$ memory operations can issue in the same cycle).\n- There is $1$ integer add unit for addition and subtraction.\n- There is $1$ multiply unit.\n- All functional units are fully pipelined.\n- Operation latencies (measured as cycles from issue to result availability) are: load $=$ $2$, add $=$ $1$, multiply $=$ $3$, store $=$ $1$.\n- An instruction may be issued only when all of its operands are available. If instruction $u$ has latency $\\ell(u)$ and is issued at cycle $s(u)$, then its result is available at cycle $r(u)=s(u)+\\ell(u)$.\n- A store requires its value operand to be available at issue time and occupies one load/store unit for $1$ cycle.\n\nBasic block (registers $r_i$ and memory locations $M[\\cdot]$ are architectural):\n- $I_1$: $r_1 \\leftarrow M[a]$ (load)\n- $I_2$: $r_2 \\leftarrow M[b]$ (load)\n- $I_3$: $r_3 \\leftarrow r_1 \\times r_2$ (multiply)\n- $I_4$: $r_4 \\leftarrow r_3 + r_5$ (add), where $r_5$ is already available at cycle $0$\n- $I_5$: $r_6 \\leftarrow r_4 + r_7$ (add), where $r_7$ is already available at cycle $0$\n- $I_6$: $M[c] \\leftarrow r_6$ (store)\n- $I_7$: $r_8 \\leftarrow r_2 + r_9$ (add), where $r_9$ is already available at cycle $0$\n- $I_8$: $r_{10} \\leftarrow r_8 + r_{11}$ (add), where $r_{11}$ is already available at cycle $0$\n\nData dependences:\n- $I_3$ depends on $I_1$ and $I_2$.\n- $I_4$ depends on $I_3$.\n- $I_5$ depends on $I_4$.\n- $I_6$ depends on $I_5$.\n- $I_7$ depends on $I_2$.\n- $I_8$ depends on $I_7$.\n- All other pairs are independent unless implied by the above.\n\nTasks:\n- Using the definitions of data dependence and instruction latency, determine the length (in cycles) of a critical path in the dependence structure of this basic block, ignoring resource contention but respecting data readiness.\n- Then, subject to the resource limits stated above, propose a legal cycle-by-cycle schedule that achieves this critical-path bound if it is achievable.\n- Report the minimal completion time (makespan) in cycles for this basic block under the stated model. Your final answer must be a single integer number of cycles. No rounding is required.", "solution": "The primary goal is to find the minimal completion time (makespan) for the given basic block. This is a two-step process: first, determine the lower bound on the makespan by calculating the length of the critical path in the data dependence graph (DDG), ignoring resource constraints. Second, attempt to construct a schedule that meets this lower bound while respecting all resource constraints.\n\n#### Part 1: Critical Path Analysis\nThe critical path is the longest path through the DDG, where the length of a path is the minimum time required to execute the sequence of instructions on that path. The length is determined by the sum of latencies. Let $s(I)$ be the issue cycle of an instruction $I$ and $r(I)$ be the cycle its result is available, with $r(I) = s(I) + \\ell(I)$. For a dependency $I_A \\to I_B$, the earliest issue time for $I_B$ is $s(I_B) \\geq r(I_A)$. We assume execution starts at cycle $1$.\n\nThe dependencies form two main paths in the DDG:\n1.  Path A: $I_1 \\to I_3 \\to I_4 \\to I_5 \\to I_6$ (and the parallel path starting with $I_2$)\n2.  Path B: $I_2 \\to I_7 \\to I_8$\n\nLet's calculate the length of each path, which represents the earliest completion time if only that path existed.\n\n**Calculation for Path A ($I_1 \\to I_3 \\to I_4 \\to I_5 \\to I_6$):**\n- $I_1$ (load, $\\ell=2$) has no dependencies in the block. It can issue at cycle $1$.\n  - Earliest issue time $s(I_1) = 1$.\n  - Result available at $r(I_1) = s(I_1) + \\ell(I_1) = 1 + 2 = 3$.\n- $I_2$ (load, $\\ell=2$) can also issue at cycle $1$. Its result is also available at $r(I_2) = 1 + 2 = 3$.\n- $I_3$ (multiply, $\\ell=3$) depends on $I_1$ and $I_2$. It can issue when both results are ready.\n  - Earliest issue time $s(I_3) = \\max(r(I_1), r(I_2)) = \\max(3, 3) = 3$.\n  - Result available at $r(I_3) = s(I_3) + \\ell(I_3) = 3 + 3 = 6$.\n- $I_4$ (add, $\\ell=1$) depends on $I_3$.\n  - Earliest issue time $s(I_4) = r(I_3) = 6$.\n  - Result available at $r(I_4) = s(I_4) + \\ell(I_4) = 6 + 1 = 7$.\n- $I_5$ (add, $\\ell=1$) depends on $I_4$.\n  - Earliest issue time $s(I_5) = r(I_4) = 7$.\n  - Result available at $r(I_5) = s(I_5) + \\ell(I_5) = 7 + 1 = 8$.\n- $I_6$ (store, $\\ell=1$) depends on $I_5$.\n  - Earliest issue time $s(I_6) = r(I_5) = 8$.\n  - This instruction executes during cycle $8$ and completes at the end of cycle $8$.\nThe total time for this path is $8$ cycles.\n\n**Calculation for Path B ($I_2 \\to I_7 \\to I_8$):**\n- $I_2$ (load, $\\ell=2$) can issue at cycle $1$.\n  - Earliest issue time $s(I_2) = 1$.\n  - Result available at $r(I_2) = 1+2 = 3$.\n- $I_7$ (add, $\\ell=1$) depends on $I_2$.\n  - Earliest issue time $s(I_7) = r(I_2) = 3$.\n  - Result available at $r(I_7) = 3+1 = 4$.\n- $I_8$ (add, $\\ell=1$) depends on $I_7$.\n  - Earliest issue time $s(I_8) = r(I_7) = 4$.\n  - Result available at $r(I_8) = 4+1 = 5$.\nThe last instruction on this path completes at the end of cycle $5$.\n\nThe critical path is the longest path, which is Path A. Therefore, the minimum possible makespan for this basic block, dictated by data dependencies, is $8$ cycles.\n\n#### Part 2: Resource-Constrained Schedule\nNow, we must construct a schedule that respects the resource limits: $2$ issue slots, $2$ load/store units, $1$ add unit, and $1$ multiply unit per cycle. The goal is to achieve the makespan of $8$ cycles.\n\nWe can construct the schedule cycle by cycle:\n\n- **Cycle 1:**\n  - Ready instructions: $I_1, I_2$.\n  - Schedule: Issue $I_1$ (load) and $I_2$ (load).\n  - Resources used: $2$ issue slots, $2$ load/store units. This is valid.\n  - Results available: $r(I_1) = 1+2=3$, $r(I_2) = 1+2=3$.\n\n- **Cycle 2:**\n  - Ready instructions: None. We are waiting for $I_1$ and $I_2$ to complete.\n  - Schedule: Stall.\n  - Resources used: None.\n\n- **Cycle 3:**\n  - Ready instructions: At the start of cycle $3$, the results of $I_1$ and $I_2$ are available. This makes $I_3$ (depends on $I_1, I_2$) and $I_7$ (depends on $I_2$) ready.\n  - Schedule: Issue $I_3$ (multiply) and $I_7$ (add).\n  - Resources used: $2$ issue slots, $1$ multiply unit, $1$ add unit. This is valid.\n  - Results available: $r(I_3) = 3+3=6$, $r(I_7) = 3+1=4$.\n\n- **Cycle 4:**\n  - Ready instructions: At the start of cycle $4$, the result of $I_7$ is available. This makes $I_8$ (depends on $I_7$) ready.\n  - Schedule: Issue $I_8$ (add).\n  - Resources used: $1$ issue slot, $1$ add unit. This is valid.\n  - Result available: $r(I_8) = 4+1=5$.\n\n- **Cycle 5:**\n  - Ready instructions: None. The next instruction on the critical path, $I_4$, is waiting for $I_3$, whose result is not available until cycle $6$. The side path ($I_8$) is complete.\n  - Schedule: Stall.\n  - Resources used: None.\n\n- **Cycle 6:**\n  - Ready instructions: At the start of cycle $6$, the result of $I_3$ is available. This makes $I_4$ (depends on $I_3$) ready.\n  - Schedule: Issue $I_4$ (add).\n  - Resources used: $1$ issue slot, $1$ add unit. This is valid.\n  - Result available: $r(I_4) = 6+1=7$.\n\n- **Cycle 7:**\n  - Ready instructions: At the start of cycle $7$, the result of $I_4$ is available. This makes $I_5$ (depends on $I_4$) ready.\n  - Schedule: Issue $I_5$ (add).\n  - Resources used: $1$ issue slot, $1$ add unit. This is valid.\n  - Result available: $r(I_5) = 7+1=8$.\n\n- **Cycle 8:**\n  - Ready instructions: At the start of cycle $8$, the result of $I_5$ is available. This makes $I_6$ (depends on $I_5$) ready.\n  - Schedule: Issue $I_6$ (store).\n  - Resources used: $1$ issue slot, $1$ load/store unit. This is valid.\n  - The instruction executes in cycle $8$ and completes at the end of cycle $8$.\n\nThe constructed schedule is legal as it respects all data dependencies and resource constraints at every cycle. The final instruction, $I_6$, completes its execution at the end of cycle $8$. The minimal completion time for this basic block is $8$ cycles.", "answer": "$$\\boxed{8}$$", "id": "3647154"}]}