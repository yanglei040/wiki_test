{"hands_on_practices": [{"introduction": "Understanding devirtualization begins with its economic rationale: is the optimization worth the cost? This first exercise guides you through building a simple but powerful cost-benefit model. By analyzing the expected performance gain, you will learn to quantify the trade-offs involved in replacing a virtual call with a guarded direct call and appreciate the sensitivity of this optimization to profiling accuracy [@problem_id:3637422].", "problem": "A compiler is considering devirtualization at a polymorphic call site in an object-oriented language. In the baseline, the call is performed via a virtual dispatch whose per-invocation latency is a constant $c_{indirect}$ cycles. Under devirtualization, the compiler inserts a runtime type guard that executes on every invocation and, if the predicted hot receiver class is present, performs a direct call; otherwise, it falls back to the original indirect call. Assume a linear expected-cost model based on the law of total expectation and the following primitive facts: the direct call latency is a constant $c_{direct}$ cycles; the guard has a constant overhead $c_{guard}$ cycles paid on every invocation; the hot receiver case occurs with probability $p_{hot}$. Starting from these fundamentals, derive an expression for the expected per-invocation performance gain $g$ of devirtualization relative to the baseline.\n\nFor a specific call site, measurements yield $c_{indirect} = 17$ cycles, $c_{direct} = 4$ cycles, and $c_{guard} = 3$ cycles. A Profile-Guided Optimization (PGO) run estimates $p_{hot}$ as $p_{hot}^{est} = 0.88$, but a subsequent run-time sampling in a Just-In-Time (JIT) compiler shows the true hot-case probability is $p_{hot}^{true} = 0.786$.\n\nTasks:\n- Using the derived expression for $g$, compute the expected gain under the estimate, $g^{est}$, and under the true probability, $g^{true}$.\n- Derive the first-order sensitivity $\\frac{\\partial g}{\\partial p_{hot}}$ and use it to quantify how $g$ changes with misestimation of $p_{hot}$.\n- Report the absolute error in expected gain, $|g^{true} - g^{est}|$, in cycles. Round your reported answer to four significant figures and express it in cycles.", "solution": "The baseline expected per-invocation cost is $c_{indirect}$ because every call is dispatched indirectly. Under devirtualization, the runtime type guard executes on every invocation and contributes a constant $c_{guard}$ cycles. With probability $p_{hot}$, the direct call is taken at cost $c_{direct}$; with probability $1 - p_{hot}$, the indirect call is taken at cost $c_{indirect}$. By the law of total expectation and linearity of expectation, the expected cost with devirtualization is\n$$\n\\text{Cost}_{\\text{devirt}} = c_{guard} + p_{hot}\\,c_{direct} + (1 - p_{hot})\\,c_{indirect}.\n$$\nThe expected per-invocation gain $g$ is the baseline cost minus the devirtualized cost:\n$$\ng = c_{indirect} - \\left(c_{guard} + p_{hot}\\,c_{direct} + (1 - p_{hot})\\,c_{indirect}\\right).\n$$\nAlgebra simplifies this expression:\n\n$$\n\\begin{aligned}\ng &= c_{indirect} - c_{guard} - p_{hot}\\,c_{direct} - (1 - p_{hot})\\,c_{indirect} \\\\\n  &= c_{indirect} - c_{guard} - p_{hot}\\,c_{direct} - c_{indirect} + p_{hot}\\,c_{indirect} \\\\\n  &= p_{hot}\\,(c_{indirect} - c_{direct}) - c_{guard}.\n\\end{aligned}\n$$\n\nThis is the expected gain model that follows from the fundamental expected-value reasoning.\n\nNext, compute the expected gain under the estimate and the true probability. Using $c_{indirect} = 17$, $c_{direct} = 4$, and $c_{guard} = 3$, we have $c_{indirect} - c_{direct} = 17 - 4 = 13$.\n\nFor the estimate $p_{hot}^{est} = 0.88$,\n\n$$\ng^{est} = p_{hot}^{est}\\,(c_{indirect} - c_{direct}) - c_{guard} = 0.88 \\cdot 13 - 3 = 11.44 - 3 = 8.44.\n$$\n\n\nFor the true probability $p_{hot}^{true} = 0.786$,\n\n$$\ng^{true} = p_{hot}^{true}\\,(c_{indirect} - c_{direct}) - c_{guard} = 0.786 \\cdot 13 - 3 = 10.218 - 3 = 7.218.\n$$\n\n\nThe absolute error in expected gain due to misestimation is\n\n$$\n|g^{true} - g^{est}| = |7.218 - 8.44| = | -1.222| = 1.222.\n$$\n\n\nTo analyze sensitivity, differentiate $g$ with respect to $p_{hot}$:\n\n$$\n\\frac{\\partial g}{\\partial p_{hot}} = c_{indirect} - c_{direct}.\n$$\n\nThus, the first-order change in $g$ for a small change $\\Delta p_{hot}$ is approximately\n\n$$\n\\Delta g \\approx \\frac{\\partial g}{\\partial p_{hot}} \\,\\Delta p_{hot} = (c_{indirect} - c_{direct})\\,\\Delta p_{hot}.\n$$\n\nBecause $g$ is exactly linear in $p_{hot}$, this first-order approximation is exact for any $\\Delta p_{hot}$:\n\n$$\ng(p_{hot}^{true}) - g(p_{hot}^{est}) = (c_{indirect} - c_{direct})\\,(p_{hot}^{true} - p_{hot}^{est}).\n$$\n\nHere, $\\Delta p_{hot} = p_{hot}^{true} - p_{hot}^{est} = 0.786 - 0.88 = -0.094$, so\n\n$$\n|g^{true} - g^{est}| = |(c_{indirect} - c_{direct})\\,\\Delta p_{hot}| = |13 \\cdot (-0.094)| = 1.222.\n$$\n\n\nRounded to four significant figures and expressed in cycles, the absolute error is $1.222$ cycles.", "answer": "$$\\boxed{1.222}$$", "id": "3637422"}, {"introduction": "After grasping the performance trade-offs, the next question is how a compiler can prove that devirtualization is safe. This practice moves from quantitative analysis to the logical foundations of program analysis, using a concrete Java example [@problem_id:3637449]. You will explore how a compiler synthesizes information from class hierarchy analysis, alias analysis, and the semantics of language features like `final` fields to deduce an object's precise type and enable this powerful optimization.", "problem": "An optimizing compiler for the Java programming language applies devirtualization techniques by specializing virtual calls when it can prove the dynamic type of the receiver at the call site. Consider the following small Java program that uses a subclass-distinguishing final field and an enumeration instead of numeric tags:\n\n```java\nenum Tag { CONST, ADD }\nabstract class Node {\n  final Tag tag;\n  Node(Tag t) { this.tag = t; }\n  abstract int eval();\n}\nfinal class Const extends Node {\n  final int value;\n  Const(int v) { super(Tag.CONST); this.value = v; }\n  int eval() { return value; }\n}\nfinal class Add extends Node {\n  final Node l, r;\n  Add(Node l, Node r) { super(Tag.ADD); this.l = l; this.r = r; }\n  int eval() { return l.eval() + r.eval(); }\n}\nclass Factory {\n  static Node mk(boolean b, int v) {\n    if (b) return new Const(v);\n    else return new Add(new Const(v), new Const(v));\n  }\n}\nclass Use {\n  static int run(boolean b, int v) {\n    Node n = Factory.mk(b, v);\n    if (n.tag == Tag.CONST) {\n      return ((Const) n).eval();\n    } else {\n      return n.eval();\n    }\n  }\n}\n```\n\nAssume the compiler employs:\n- Sparse Conditional Constant Propagation (SCCP; a data-flow analysis that propagates constant values through the control-flow graph),\n- Class Hierarchy Analysis (CHA; a static analysis that bounds the set of possible dynamic receiver classes),\n- Points-to analysis (an alias analysis that tracks which allocation sites a reference variable `n` may point to under the program’s control-flow), and\n- The Java Language Specification semantics for final fields (final fields are assigned during construction and are not subsequently modified under well-defined conditions of safe publication).\n\nStarting from the fundamental definitions of dynamic dispatch (a method call resolution based on the dynamic type of the receiver object at runtime), data-flow constant propagation (flow-sensitive inference of constant values), and alias analysis (reasoning about references and mutations through them), and without assuming any special-case formulas, determine which of the following assumption sets are sufficient to allow the compiler to (i) propagate the final field value `tag` from the object’s allocation site to the branch, (ii) establish that the branch condition `n.tag == Tag.CONST` implies the receiver’s exact dynamic type is `Const` in the then-branch and `Add` in the else-branch, and hence (iii) compile direct calls to `Const.eval` and `Add.eval` without runtime guards.\n\nChoose the single best option.\n\nA. The field `tag` is declared final and assigned only in each subclass constructor to a unique enumeration constant (`Tag.CONST` for `Const` and `Tag.ADD` for `Add`); classes `Const` and `Add` are declared final; there are no reflective or low-level writes (for example, via `java.lang.reflect` or `sun.misc.Unsafe`) to `tag`; points-to analysis proves that the receiver `n` at the call site comes from the constructors of `Const` or `Add`; a closed-world assumption holds for Class Hierarchy Analysis (CHA), so no other subclasses of `Node` are possible. Under these conditions, SCCP can propagate `tag` values, the mapping from `tag` to subclass is injective among reachable allocation sites, and devirtualization to direct calls is sound without runtime guards.\n\nB. Declaring `tag` as final alone is sufficient; neither alias analysis nor Class Hierarchy Analysis is needed, and reflective updates or dynamic class loading do not affect the soundness of devirtualization.\n\nC. Escape analysis proves that `n` does not escape the method `Use.run`; therefore, the compiler can replace the virtual call with a direct call target unconditionally, regardless of `tag`.\n\nD. The compiler treats the check `n.tag == Tag.CONST` as equivalent to an `instanceof Const` test and devirtualizes based on that presumption, even without proving that each subclass constructor assigns a distinct `tag` value or ruling out reflective writes; open-world dynamic class loading is allowed.", "solution": "The user has provided a problem from the domain of compiler optimizations, specifically concerning the devirtualization of virtual method calls in an object-oriented language like Java. The task is to validate the problem statement and, if valid, to determine which set of assumptions is sufficient for a compiler to perform a specific devirtualization based on a manually implemented type tag.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\nThe problem statement provides the following information:\n1.  **Code Snippet:**\n    *   An enumeration `Tag` with constants `Tag.CONST` and `Tag.ADD`.\n    *   An `abstract` class `Node` with a `final Tag tag` field and an `abstract int eval()` method.\n    *   A `final` class `Const` that extends `Node`, stores an `int value`, sets its `tag` to `Tag.CONST` in the constructor, and implements `eval()` to return `value`.\n    *   A `final` class `Add` that extends `Node`, stores two `Node` references `l` and `r`, sets its `tag` to `Tag.ADD` in the constructor, and implements `eval()` to return `l.eval() + r.eval()`.\n    *   A `Factory` class with a static method `mk(boolean b, int v)` that, depending on the boolean `b`, returns either a `new Const(v)` or a `new Add(...)`.\n    *   A `Use` class with a static method `run(boolean b, int v)` that creates a `Node n` via the `Factory` and then executes a conditional: `if (n.tag == Tag.CONST)`.\n2.  **Assumed Compiler Analyses:**\n    *   Sparse Conditional Constant Propagation (SCCP).\n    *   Class Hierarchy Analysis (CHA).\n    *   Points-to analysis.\n3.  **Assumed Language Semantics:**\n    *   Java Language Specification (JLS) semantics for `final` fields.\n4.  **Goal for the Compiler:**\n    *   (i) Propagate the `tag` field's value from the object allocation site to the branch condition.\n    *   (ii) Prove that the condition `n.tag == Tag.CONST` implies the receiver's dynamic type is `Const` in the `then`-branch and `Add` in the `else`-branch.\n    *   (iii) Compile direct calls to `Const.eval()` and `Add.eval()` without runtime guards.\n5.  **Question:**\n    *   Determine which of the provided assumption sets is sufficient to achieve this goal.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem is evaluated against the validation criteria:\n*   **Scientifically Grounded:** The problem is firmly located within compiler theory and practice. Devirtualization using class hierarchy analysis, guard-based type inference (here, using a manual tag), and constant propagation are standard, well-documented optimization techniques. The Java code provides a canonical example. The problem is sound.\n*   **Well-Posed:** The problem provides a clear context, a concrete code example, a list of available program analyses, and a precise goal. It asks for a sufficient set of conditions from a multiple-choice list. This structure leads to a single, best answer based on established principles of program analysis. The problem is well-posed.\n*   **Objective:** The problem is described using precise, technical terminology from computer science (`devirtualization`, `SCCP`, `CHA`, `points-to analysis`, `dynamic dispatch`, `final fields`). There is no ambiguity or subjective language.\n\nThe problem does not exhibit any of the invalidity flaws. It is not scientifically unsound, incomplete, ambiguous, or trivial. It is a substantive question about the interplay of several advanced compiler optimizations.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is **valid**. The solution process will now proceed.\n\n### Derivation from First Principles\n\nThe objective is to soundly devirtualize the `eval()` calls inside `Use.run`. The core of the method is:\n```java\nNode n = Factory.mk(b, v);\nif (n.tag == Tag.CONST) {\n  return ((Const) n).eval();\n} else {\n  return n.eval();\n}\n```\nThe call `((Const) n).eval()` is already direct due to the static type of the expression after the cast. The challenge lies in the virtual call `n.eval()` within the `else`-branch. To devirtualize it to a direct call to `Add.eval()`, the compiler must prove that the dynamic type of the object referenced by `n` is `Add` in that program path.\n\nThis requires the compiler to chain together several pieces of information, corresponding to the three sub-goals in the prompt:\n\n1.  **Propagating the `tag` value:** To reason about the condition `n.tag == Tag.CONST`, the compiler must determine the possible values of `n.tag`.\n    *   **Points-to analysis** is required to determine that the reference `n` can point to objects created at two specific allocation sites: `new Const(v)` and `new Add(...)` within `Factory.mk`.\n    *   The `tag` field is `final`. According to JLS semantics, its value is set during construction and does not change.\n    *   By analyzing the constructors, the compiler sees that the `Const` allocation site initializes `tag` to the constant `Tag.CONST`, and the `Add` site initializes `tag` to `Tag.ADD`.\n    *   **Sparse Conditional Constant Propagation (SCCP)** can use the flow information from points-to analysis and the immutability of the `final` field to propagate these constant values. It concludes that a read of `n.tag` will yield either `Tag.CONST` or `Tag.ADD`.\n\n2.  **Correlating `tag` value with dynamic type:** This is the crucial inferential step.\n    *   In the `then`-branch, the condition `n.tag == Tag.CONST` holds. The compiler needs to prove that this implies the type of `n` is `Const`.\n    *   In the `else`-branch, the condition `n.tag != Tag.CONST` holds. The compiler needs to prove this implies the type of `n` is `Add`.\n    *   To establish this correlation, the compiler must know the complete set of types that `n` could possibly have and the `tag` value associated with each.\n    *   **Class Hierarchy Analysis (CHA)** discovers the subclasses of `Node`. In this code, it finds `Const` and `Add`.\n    *   However, Java supports dynamic class loading. A new subclass of `Node` could be loaded at runtime. To rule this out, the compiler must operate under a **closed-world assumption**, which posits that the classes seen at compile time are the only classes that will exist at runtime. With this assumption, CHA can guarantee that `Const` and `Add` are the *only* possible concrete types for an object of static type `Node`.\n    *   The compiler can then build a mapping: Type `Const` $\\rightarrow$ `tag` is `Tag.CONST`; Type `Add` $\\rightarrow$ `tag` is `Tag.ADD`. Since `Tag.CONST` $\\neq$ `Tag.ADD`, this mapping is injective for the set of known subclasses.\n    *   This logic depends on the immutability of the `tag` value post-construction. While `final` provides this guarantee, mechanisms like reflection (`java.lang.reflect.Field.set`) or `sun.misc.Unsafe` can circumvent it. Therefore, a sound compiler must also assume **no such reflective or low-level writes** occur.\n    *   Given all these conditions, the compiler can conclude: if `n.tag == Tag.CONST`, the type must be `Const`. If `n.tag != Tag.CONST`, since the only other possible type is `Add`, the type must be `Add`.\n\n3.  **Compiling to direct calls:**\n    *   With the type of `n` proven in both branches, devirtualization is straightforward. The call in the `then`-branch is already direct. In the `else`-branch, the compiler can replace the virtual call `n.eval()` with a direct call to `Add.eval()`. No runtime type checks (guards) are needed.\n\n### Option-by-Option Analysis\n\n**A. The field `tag` is declared `final` and assigned only in each subclass constructor to a unique enumeration constant (`Tag.CONST` for `Const` and `Tag.ADD` for `Add`); classes `Const` and `Add` are declared `final`; there are no reflective or low-level writes (for example, via `java.lang.reflect` or `sun.misc.Unsafe`) to `tag`; points-to analysis proves that the receiver `n` at the call site comes from the constructors of `Const` or `Add`; a closed-world assumption holds for Class Hierarchy Analysis (CHA), so no other subclasses of `Node` are possible. Under these conditions, SCCP can propagate `tag` values, the mapping from `tag` to subclass is injective among reachable allocation sites, and devirtualization to direct calls is sound without runtime guards.**\n\nThis option comprehensively lists all the necessary conditions derived from first principles: the `final` and uniquely assigned `tag`, the absence of reflective writes, the use of points-to analysis, and the critical role of CHA under a closed-world assumption. It correctly describes the consequences: SCCP can propagate values, the tag-to-type mapping is injective, and devirtualization is sound.\n\n**Verdict:** **Correct**.\n\n**B. Declaring `tag` as `final` alone is sufficient; neither alias analysis nor Class Hierarchy Analysis is needed, and reflective updates or dynamic class loading do not affect the soundness of devirtualization.**\n\nThis option is incorrect on multiple grounds.\n*   Declaring `tag` as `final` is not sufficient. Without alias (points-to) analysis, the compiler cannot connect the reference `n` to the allocation sites where `tag` is initialized.\n*   Without CHA (and a closed-world view), the compiler cannot prove that `n.tag != Tag.CONST` implies the type is `Add`, as other unknown subclasses of `Node` might exist.\n*   Allowing reflective updates would break the constancy of `tag`, making the check useless. Allowing open-world dynamic class loading breaks the reasoning for the `else`-branch.\n\n**Verdict:** **Incorrect**.\n\n**C. Escape analysis proves that `n` does not escape the method `Use.run`; therefore, the compiler can replace the virtual call with a direct call target unconditionally, regardless of `tag`.**\n\nThis option misapplies the concept of escape analysis. While it is true that the object `n` does not escape the method `Use.run`, this fact alone does not determine its concrete type. The type of `n` depends on the data-flow from the parameter `b`. Escape analysis helps with optimizations like stack allocation or lock elision, but it does not resolve data-dependent type uncertainty. The claim that the call can be devirtualized \"unconditionally, regardless of `tag`\" is false, as the compiler would not know *which* direct call to make (`Const.eval` or `Add.eval`).\n\n**Verdict:** **Incorrect**.\n\n**D. The compiler treats the check `n.tag == Tag.CONST` as equivalent to an `instanceof Const` test and devirtualizes based on that presumption, even without proving that each subclass constructor assigns a distinct `tag` value or ruling out reflective writes; open-world dynamic class loading is allowed.**\n\nThis option describes an unsound and incorrect compiler. A compiler cannot make a \"presumption\" of equivalence without proof.\n*   If the compiler does not prove the tag assignment is distinct (e.g., if `Add` also used `Tag.CONST`), the presumption is false.\n*   If reflective writes are possible, the `tag` value at the check site may have no relation to the object's original type.\n*   If open-world loading is allowed, `n.tag != Tag.CONST` does not imply the type is `Add`, invalidating the devirtualization in the `else`-branch.\nA compiler making such assumptions would generate incorrect code that could lead to runtime errors (e.g., `ClassCastException` or calling the wrong method).\n\n**Verdict:** **Incorrect**.", "answer": "$$\\boxed{A}$$", "id": "3637449"}, {"introduction": "Devirtualization is not just an abstract concept; it requires concrete implementation choices with real-world consequences for system performance. In this final practice, you will step into the role of a compiler designer and evaluate two competing strategies for tracking object types: fat pointers and external side tables [@problem_id:3637444]. This exercise will challenge you to model and compare not only lookup latency but also memory overhead, providing a holistic view of the engineering trade-offs involved.", "problem": "A compiler implementer is evaluating two mechanisms for enabling devirtualization in an object-oriented runtime on a 64-bit architecture: (i) fat pointers that carry a type identifier inline, and (ii) an external side table mapping object addresses to type identifiers. The implementer wants to compare the two approaches quantitatively in terms of memory overhead and virtual-call lookup latency and then aggregate these into a single scalar total cost in Central Processing Unit (CPU) cycles for a given workload.\n\nAssume the following foundational facts and definitions:\n- A baseline pointer occupies $8$ bytes. A fat pointer carries an additional $4$-byte type identifier and, due to alignment, its size rounds up to $16$ bytes. Thus, the extra memory per pointer due to fattening is the difference between $16$ and $8$ bytes.\n- The side table uses open addressing with linear probing under the standard uniform hashing model. Each table entry stores an $8$-byte object address and a $4$-byte type identifier, plus $4$ bytes of padding to align entries to $16$ bytes. With load factor $\\rho$, the table’s capacity is $N/\\rho$ entries for $N$ objects, ignoring ceiling effects for large $N$.\n- For successful lookups under the uniform hashing model with linear probing, the textbook expected number of probes is to be used.\n- Each probe to the side table costs $c$ cycles. Reading a type identifier already present in a register via fat pointer costs $t_f$ cycles.\n- To combine memory overhead and latency into a single scalar cost over the whole run, assume an amortized memory penalty factor $w_m$ cycles per byte of extra memory footprint. The total cost of a scheme is defined as the sum of the memory cost over the run and the dynamic lookup cost over all virtual calls.\n\nConsider a program that allocates $N = 10^{6}$ objects. Each object has on average $d = 3$ outgoing pointer fields resident on the heap. Each object participates in $V = 20$ virtual calls that require a type identifier for devirtualization. The side table operates at load factor $\\rho = 0.8$ with per-probe cost $c = 4$ cycles. The fat pointer lookup cost is $t_f = 1$ cycle. The amortized memory penalty is $w_m = 0.5$ cycles per byte.\n\nUsing only the base definitions and well-tested formulas and facts, derive from first principles:\n- The total memory overhead in bytes for fat pointers and for the side table.\n- The expected lookup latency in cycles per virtual call for fat pointers and for the side table.\n- The total cost over the entire run for each scheme, defined as $C_{\\text{fat}} = w_m \\cdot M_{\\text{fat}} + N \\cdot V \\cdot \\ell_{\\text{fat}}$ and $C_{\\text{side}} = w_m \\cdot M_{\\text{side}} + N \\cdot V \\cdot \\ell_{\\text{side}}$.\n\nThen compute the scalar difference $\\Delta C = C_{\\text{fat}} - C_{\\text{side}}$. Express the final result in cycles. Provide your final answer as a single number. Do not round.", "solution": "The task is to perform a quantitative comparison of two devirtualization mechanisms: fat pointers and a side table. This is achieved by computing a total cost metric for each, which amalgamates memory overhead and lookup latency into a single scalar value measured in CPU cycles. We will then calculate the difference in these total costs.\n\nThe provided parameters are:\n- Number of objects: $N = 10^{6}$\n- Average number of outgoing pointer fields per object: $d = 3$\n- Number of virtual calls per object: $V = 20$\n- Side table load factor: $\\rho = 0.8$\n- Side table probe cost: $c = 4$ cycles\n- Fat pointer lookup cost: $t_f = 1$ cycle\n- Amortized memory penalty factor: $w_m = 0.5$ cycles/byte\n\nThe total cost for the fat pointer scheme is given by $C_{\\text{fat}} = w_m \\cdot M_{\\text{fat}} + N \\cdot V \\cdot \\ell_{\\text{fat}}$, and for the side table scheme by $C_{\\text{side}} = w_m \\cdot M_{\\text{side}} + N \\cdot V \\cdot \\ell_{\\text{side}}$. We will systematically derive each component.\n\nFirst, we determine the memory overhead for each scheme.\n\n**1. Total Memory Overhead ($M$)**\n\n**For Fat Pointers ($M_{\\text{fat}}$):**\nA fat pointer's size is given as $16$ bytes, whereas a baseline pointer is $8$ bytes. The extra memory per pointer is thus $16 - 8 = 8$ bytes. The program has $N$ objects, and each object has an average of $d$ outgoing pointers. Therefore, the total number of pointers that are \"fattened\" is $N \\cdot d$. The total memory overhead is the product of the number of pointers and the extra memory per pointer.\n$$M_{\\text{fat}} = (N \\cdot d) \\cdot (16 \\text{ bytes} - 8 \\text{ bytes})$$\nSubstituting the given values:\n$$M_{\\text{fat}} = (10^{6} \\cdot 3) \\cdot 8 = 24 \\times 10^{6} \\text{ bytes}$$\n\n**For the Side Table ($M_{\\text{side}}$):**\nThe side table is an open-addressing hash table that maps object addresses to type identifiers. It needs to store information for all $N$ objects. With a load factor $\\rho$, the table's capacity (number of entries) must be $N/\\rho$ to accommodate $N$ objects. Each entry consists of an $8$-byte object address, a $4$-byte type identifier, and $4$ bytes of padding, for a total entry size of $16$ bytes. The total memory overhead is the total size of the hash table.\n$$M_{\\text{side}} = \\left(\\frac{N}{\\rho}\\right) \\cdot (\\text{entry size})$$\nSubstituting the given values:\n$$M_{\\text{side}} = \\left(\\frac{10^{6}}{0.8}\\right) \\cdot 16 = (1.25 \\times 10^{6}) \\cdot 16 = 20 \\times 10^{6} \\text{ bytes}$$\n\nSecond, we determine the expected lookup latency per virtual call.\n\n**2. Expected Lookup Latency ($\\ell$)**\n\n**For Fat Pointers ($\\ell_{\\text{fat}}$):**\nThe problem states that the cost of reading the type identifier from a fat pointer is given by the constant $t_f$.\n$$\\ell_{\\text{fat}} = t_f = 1 \\text{ cycle}$$\n\n**For the Side Table ($\\ell_{\\text{side}}$):**\nThe latency is the time taken for a successful lookup in the hash table. The problem specifies using the textbook formula for the expected number of probes in a successful search in a hash table with linear probing under the uniform hashing assumption. This is:\n$$E[\\text{probes}] = \\frac{1}{2} \\left(1 + \\frac{1}{1 - \\rho}\\right)$$\nThe lookup latency is the expected number of probes multiplied by the cost per probe, $c$.\n$$\\ell_{\\text{side}} = c \\cdot E[\\text{probes}] = c \\cdot \\frac{1}{2} \\left(1 + \\frac{1}{1 - \\rho}\\right)$$\nSubstituting the given values:\n$$\\ell_{\\text{side}} = 4 \\cdot \\frac{1}{2} \\left(1 + \\frac{1}{1 - 0.8}\\right) = 2 \\left(1 + \\frac{1}{0.2}\\right) = 2(1 + 5) = 12 \\text{ cycles}$$\n\nThird, we calculate the total cost for each scheme over the entire run. The total number of virtual calls is $N \\cdot V$.\n\n**3. Total Cost ($C$)**\n\n**For Fat Pointers ($C_{\\text{fat}}$):**\nThe total cost is the sum of the amortized memory cost and the total dynamic lookup cost.\n$$C_{\\text{fat}} = w_m \\cdot M_{\\text{fat}} + (N \\cdot V) \\cdot \\ell_{\\text{fat}}$$\n$$C_{\\text{fat}} = (0.5) \\cdot (24 \\times 10^{6}) + (10^{6} \\cdot 20) \\cdot 1$$\n$$C_{\\text{fat}} = 12 \\times 10^{6} + 20 \\times 10^{6} = 32 \\times 10^{6} \\text{ cycles}$$\n\n**For the Side Table ($C_{\\text{side}}$):**\nSimilarly, the total cost for the side table is:\n$$C_{\\text{side}} = w_m \\cdot M_{\\text{side}} + (N \\cdot V) \\cdot \\ell_{\\text{side}}$$\n$$C_{\\text{side}} = (0.5) \\cdot (20 \\times 10^{6}) + (10^{6} \\cdot 20) \\cdot 12$$\n$$C_{\\text{side}} = 10 \\times 10^{6} + 240 \\times 10^{6} = 250 \\times 10^{6} \\text{ cycles}$$\n\nFinally, we compute the requested scalar difference $\\Delta C = C_{\\text{fat}} - C_{\\text{side}}$.\n\n**4. Cost Difference ($\\Delta C$)**\n$$\\Delta C = C_{\\text{fat}} - C_{\\text{side}}$$\n$$\\Delta C = (32 \\times 10^{6}) - (250 \\times 10^{6})$$\n$$\\Delta C = -218 \\times 10^{6} \\text{ cycles}$$\nThis is equivalent to the single number $-218000000$.", "answer": "$$\\boxed{-218000000}$$", "id": "3637444"}]}