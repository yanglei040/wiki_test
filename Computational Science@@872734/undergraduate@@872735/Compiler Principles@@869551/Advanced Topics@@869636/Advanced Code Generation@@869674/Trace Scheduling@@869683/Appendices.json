{"hands_on_practices": [{"introduction": "Trace scheduling begins by identifying the most frequently executed path, or \"trace,\" through a program's control flow graph. This selection is not arbitrary; it's a calculated decision based on profiling data and a cost-benefit analysis. This exercise [@problem_id:3676420] guides you through deriving and applying a fundamental heuristic for trace selection, quantifying the expected performance impact of optimizing a given path. By modeling the trade-off between the potential speedup from speculation and the penalty of recovery, you will learn how a compiler makes intelligent choices about where to focus its optimization efforts.", "problem": "Trace scheduling is a compilation technique that selects a high-probability path (a trace) in a Control Flow Graph (CFG) and applies speculative code motion to optimize that path while compensating off-trace execution with recovery code. Consider an edge in a CFG on which an optimization may be speculatively applied. Let the edge’s dynamic execution probability be denoted by $p$, the estimated cycle savings if the optimization is realized on that edge be denoted by $b$ (benefit), and the estimated cycle overhead of compensation if the speculation fails be denoted by $c$ (cost). Assume the following principles hold:\n- The observed performance effect of speculative optimization on a single edge is modeled as a random variable that takes the value $b$ if the edge executes and the value $-c$ if the edge does not execute.\n- The expected performance impact is the average under the edge’s execution probability $p$.\n- Scores for distinct edges within a trace aggregate additively under the independence of their performance effects.\n- The scoring function $w(p,b,c)$ is linear in both $b$ and $c$, strictly increasing in $b$, strictly decreasing in $c$, and satisfies the normalization constraints $w(1,b,0)=b$ and $w(0,0,c)=-c$.\n\nTask 1: Using only the principles above and the definition of expectation from probability theory, derive a closed-form analytic expression for the edge scoring function $w(p,b,c)$.\n\nTask 2: Apply your derived scoring function to choose the primary trace in the following CFG. The CFG has a start node $S$ with two branches leading to two distinct paths that reconverge at node $D$. The two candidate traces are:\n- Trace $T_1$: $S \\rightarrow B_1 \\rightarrow C \\rightarrow D$\n- Trace $T_2$: $S \\rightarrow B_2 \\rightarrow E \\rightarrow D$\n\nFor each edge, the profile execution probability $p$, benefit $b$ (in cycles), and cost $c$ (in cycles) are provided:\n- Edge $e_1: S \\rightarrow B_1$: $p=0.7$, $b=8$, $c=3$\n- Edge $e_2: B_1 \\rightarrow C$: $p=0.9$, $b=5$, $c=2$\n- Edge $e_3: C \\rightarrow D$: $p=0.95$, $b=4$, $c=4$\n- Edge $e_4: S \\rightarrow B_2$: $p=0.3$, $b=12$, $c=9$\n- Edge $e_5: B_2 \\rightarrow E$: $p=0.8$, $b=6$, $c=1$\n- Edge $e_6: E \\rightarrow D$: $p=0.85$, $b=3$, $c=5$\n\nCompute the total score of each trace by summing the edge scores along the trace and choose the trace with the higher total score as the primary trace. Report the total score of the selected trace. Express your answer in cycles. No rounding is required.", "solution": "The problem is evaluated to be valid as it is scientifically grounded in compiler theory, well-posed, objective, and self-contained. All necessary information is provided, and the premises are consistent with a standard heuristic model for trace selection.\n\n**Part 1: Derivation of the Edge Scoring Function**\n\nThe problem asks for the derivation of an edge scoring function $w(p, b, c)$ based on a set of principles derived from probability theory.\n\nThe first principle states that the performance effect of a speculative optimization on a single edge is a random variable, let's call it $X$. This random variable can take two values:\n1.  A benefit of $b$ cycles if the optimization is successful, which occurs when the edge is executed. The probability of this event is given as $p$.\n2.  A cost of $c$ cycles (represented as a negative benefit, $-c$) if the optimization is unsuccessful (i.e., speculation fails), which occurs when the edge is not executed. The probability of this event is therefore $1-p$.\n\nThe second principle states that the scoring function $w(p, b, c)$ is the expected performance impact. The expected value of a discrete random variable is the sum of the product of each possible value and its probability. Applying this definition to the random variable $X$:\n$$\nE[X] = \\sum_{i} x_i P(X=x_i)\n$$\nIn our case, the values are $b$ and $-c$, with probabilities $p$ and $1-p$, respectively.\n$$\nw(p, b, c) = E[X] = (b \\cdot p) + ((-c) \\cdot (1-p))\n$$\nSimplifying this expression gives the closed-form analytic expression for the scoring function:\n$$\nw(p, b, c) = bp - c(1-p)\n$$\nWe must verify this derived function against the remaining principles stated in the problem.\n- **Linearity**: The function $w(p, b, c) = p \\cdot b + (p-1) \\cdot c$ is a linear function of both $b$ and $c$. This is satisfied.\n- **Monotonicity**: To check if it is strictly increasing in $b$, we take the partial derivative with respect to $b$:\n$$\n\\frac{\\partial w}{\\partial b} = p\n$$\nSince $p$ is a probability, $0 \\le p \\le 1$. For any edge that has a non-zero probability of execution ($p>0$), the function is strictly increasing in $b$.\nTo check if it is strictly decreasing in $c$, we take the partial derivative with respect to $c$:\n$$\n\\frac{\\partial w}{\\partial c} = -(1-p) = p-1\n$$\nSince $p \\le 1$, $p-1 \\le 0$. For any edge where speculation can fail ($p1$), the function is strictly decreasing in $c$. Both monotonicity conditions are satisfied for non-trivial cases.\n- **Normalization**: We check the two normalization constraints:\n$$\nw(1, b, 0) = b \\cdot 1 - 0 \\cdot (1-1) = b\n$$\n$$\nw(0, 0, c) = 0 \\cdot 0 - c \\cdot (1-0) = -c\n$$\nBoth constraints are satisfied. The derived function $w(p,b,c) = bp - c(1-p)$ is correct.\n\n**Part 2: Application to the Control Flow Graph**\n\nThe third principle states that the total score for a trace is the sum of the scores of its constituent edges. We will now apply the derived scoring function to each edge in the two candidate traces, $T_1$ and $T_2$.\n\n**Trace $T_1$: $S \\rightarrow B_1 \\rightarrow C \\rightarrow D$**\nThis trace consists of edges $e_1$, $e_2$, and $e_3$.\n\n- **Edge $e_1: S \\rightarrow B_1$**: $p_1=0.7$, $b_1=8$, $c_1=3$.\n$$\nw_1 = b_1 p_1 - c_1(1-p_1) = 8(0.7) - 3(1-0.7) = 5.6 - 3(0.3) = 5.6 - 0.9 = 4.7\n$$\n- **Edge $e_2: B_1 \\rightarrow C$**: $p_2=0.9$, $b_2=5$, $c_2=2$.\n$$\nw_2 = b_2 p_2 - c_2(1-p_2) = 5(0.9) - 2(1-0.9) = 4.5 - 2(0.1) = 4.5 - 0.2 = 4.3\n$$\n- **Edge $e_3: C \\rightarrow D$**: $p_3=0.95$, $b_3=4$, $c_3=4$.\n$$\nw_3 = b_3 p_3 - c_3(1-p_3) = 4(0.95) - 4(1-0.95) = 3.8 - 4(0.05) = 3.8 - 0.2 = 3.6\n$$\n\nThe total score for trace $T_1$ is the sum of the individual edge scores:\n$$\n\\text{Score}(T_1) = w_1 + w_2 + w_3 = 4.7 + 4.3 + 3.6 = 12.6\n$$\n\n**Trace $T_2$: $S \\rightarrow B_2 \\rightarrow E \\rightarrow D$**\nThis trace consists of edges $e_4$, $e_5$, and $e_6$.\n\n- **Edge $e_4: S \\rightarrow B_2$**: $p_4=0.3$, $b_4=12$, $c_4=9$.\n$$\nw_4 = b_4 p_4 - c_4(1-p_4) = 12(0.3) - 9(1-0.3) = 3.6 - 9(0.7) = 3.6 - 6.3 = -2.7\n$$\n- **Edge $e_5: B_2 \\rightarrow E$**: $p_5=0.8$, $b_5=6$, $c_5=1$.\n$$\nw_5 = b_5 p_5 - c_5(1-p_5) = 6(0.8) - 1(1-0.8) = 4.8 - 1(0.2) = 4.8 - 0.2 = 4.6\n$$\n- **Edge $e_6: E \\rightarrow D$**: $p_6=0.85$, $b_6=3$, $c_6=5$.\n$$\nw_6 = b_6 p_6 - c_6(1-p_6) = 3(0.85) - 5(1-0.85) = 2.55 - 5(0.15) = 2.55 - 0.75 = 1.8\n$$\n\nThe total score for trace $T_2$ is the sum of these scores:\n$$\n\\text{Score}(T_2) = w_4 + w_5 + w_6 = -2.7 + 4.6 + 1.8 = 3.7\n$$\n\n**Conclusion**\n\nTo select the primary trace, we compare the total scores:\n$\\text{Score}(T_1) = 12.6$\n$\\text{Score}(T_2) = 3.7$\n\nSince $12.6 > 3.7$, trace $T_1$ has the higher score and is chosen as the primary trace. The problem asks for the total score of the selected trace.\nThe total score of the selected trace $T_1$ is $12.6$ cycles.", "answer": "$$\n\\boxed{12.6}\n$$", "id": "3676420"}, {"introduction": "Once a trace is selected, the compiler can perform aggressive code transformations, such as moving instructions across basic block boundaries. A common and powerful optimization is hoisting a memory load to execute earlier, but this is only safe if it doesn't violate data dependencies, particularly with preceding stores. This problem [@problem_id:3676434] challenges you to design a correct and robust mechanism for speculatively hoisting a load over a store with ambiguous aliasing. You will need to devise a precise runtime check to validate the speculation and outline a recovery path to ensure program correctness when the speculation fails.", "problem": "In trace scheduling, a compiler selects a probable path (the trace) and performs aggressive, sometimes speculative, code motion, subject to preserving the program’s semantics. A fundamental base for reasoning is the dependence model: a reordering of two memory operations is legal if and only if it does not violate data dependences induced by aliasing. Specifically, for a store to memory location with byte-address interval $[P, P + w_s - 1]$ and a load from $[Q, Q + w_l - 1]$ (where $P, Q$ are the integer addresses and $w_s, w_l$ are the access widths in bytes), a reordering that moves the load before the store is semantically safe if and only if the intervals are disjoint, that is, if and only if $[P, P + w_s - 1] \\cap [Q, Q + w_l - 1] = \\emptyset$. When compile-time alias analysis cannot prove non-aliasing, speculative motion may be made correct by inserting runtime checks (RC) and recovery.\n\nConsider the following intermediate representation (three-address, in Static Single Assignment (SSA) form for scalars only), where memory is byte-addressable and accesses may be unaligned. All addresses are valid (non-faulting), and all memory operations are sequentially consistent. Access sizes are $w_s = 4$ and $w_l = 4$ bytes. Let the hot trace be $\\text{B0} \\rightarrow \\text{B1} \\rightarrow \\text{B2} \\rightarrow \\text{B4}$.\n\n- Block $\\text{B0}$:\n  - $1: t_0 \\leftarrow g(x)$\n  - $2: \\text{goto B1}$\n\n- Block $\\text{B1}$:\n  - $3: *p \\leftarrow h(t_0)$\n  - $4: \\text{if } c \\text{ then goto B2 else goto B3}$\n\n- Block $\\text{B2}$ (on-trace):\n  - $5: v \\leftarrow *q$\n  - $6: y_1 \\leftarrow v + k$\n  - $7: \\text{goto B4}$\n\n- Block $\\text{B3}$ (off-trace):\n  - $8: y_2 \\leftarrow y_0 + k$\n  - $9: \\text{goto B4}$\n\n- Block $\\text{B4}$:\n  - $10: y \\leftarrow \\phi(y_1, y_2)$\n\nHere $p, q$ are address-valued variables, $k$ is a scalar, and $g(\\cdot), h(\\cdot)$ are side-effect-free arithmetic functions. The store at instruction $3$ writes $w_s = 4$ bytes to address interval $[P, P + 3]$ where $P$ is the integer value of $p$. The load at instruction $5$ reads $w_l = 4$ bytes from $[Q, Q + 3]$ where $Q$ is the integer value of $q$. Compile-time alias analysis produces alias uncertainty $U$, meaning it cannot prove $[P, P + 3] \\cap [Q, Q + 3] = \\emptyset$ on the hot trace.\n\nYour task is to choose, among the options below, a legal trace schedule that hoists the load at instruction $5$ above the store at instruction $3$ on the hot trace, along with a correct and sufficient set of runtime checks (RC) to validate the speculation and an outline of a recovery path that preserves the original semantics on all flows when the check fails. The runtime check should be expressed using integer address comparisons over $P, Q, w_s, w_l$ and must be correct under the stated assumptions (byte-addressable memory, possibly unaligned $4$-byte accesses). Recovery must ensure that, upon RC failure, the observable effects are as if the original program executed.\n\nWhich option is correct?\n\nA. Schedule: In $\\text{B1}$, insert RC at new instruction $3'$: compute $P \\leftarrow \\operatorname{uaddr}(p)$ and $Q \\leftarrow \\operatorname{uaddr}(q)$, then test $((P + w_s \\le Q) \\lor (Q + w_l \\le P))$. If RC passes, execute new $4'$: $v_{\\text{hoist}} \\leftarrow *$ $q$, then execute original $3$: $*$ $p \\leftarrow h(t_0)$, then original branch $4$. In $\\text{B2}$, replace $5$ by $5'$: $v \\leftarrow v_{\\text{hoist}}$. Insert a single recovery block $\\text{R}$ with the following outline: on RC failure at $3'$, branch to $\\text{R}$, which executes original $3$ (the store), then executes the original control and use sites in program order: if $c$ then perform $v \\leftarrow *$ $q$ and $y_1 \\leftarrow v + k$ and jump to $\\text{B4}$, else perform $y_2 \\leftarrow y_0 + k$ and jump to $\\text{B4}$. No other changes. Here $\\operatorname{uaddr}(\\cdot)$ denotes the unsigned integer address of a pointer.\n\nB. Schedule: Move $5$ to the end of $\\text{B0}$ (before any code in $\\text{B1}$), with no RC, on the grounds that loads and stores that use different SSA names commute. In $\\text{B2}$, replace $5$ by the hoisted value. No recovery is necessary because the load has no side effects.\n\nC. Schedule: Hoist $5$ to immediately before $3$ in $\\text{B1}$ and insert RC that tests only $(P \\neq Q)$. If RC passes, use the hoisted value in $\\text{B2}$; if RC fails, fall through and execute $3$ and the rest as in the original code. No separate recovery block is needed.\n\nD. Schedule: Keep $5$ after $3$ but move it from $\\text{B2}$ to the end of $\\text{B1}$ after the branch $4$, so that the load is executed before knowing $c$. Insert RC that tests $((P + w_s  Q) \\lor (Q + w_l  P))$. If RC fails, execute $3$ first, then execute $5$ again to ensure the latest value. No additional recovery is needed because the load is still after the store.", "solution": "The user seeks to identify the correct implementation of a speculative code motion in trace scheduling. The specific task is to hoist a load instruction over a store instruction on a hot trace, which requires a runtime check (RC) and a recovery path to preserve program semantics in case the speculation is unsafe.\n\nFirst, we establish the fundamental principles governing this transformation.\nThe program contains a store instruction $3: *p \\leftarrow h(t_0)$ in block $\\text{B1}$ and a load instruction $5: v \\leftarrow *q$ in block $\\text{B2}$. The hot trace is $\\text{B0} \\rightarrow \\text{B1} \\rightarrow \\text{B2} \\rightarrow \\text{B4}$. The goal is to move the load at instruction $5$ to a position before the store at instruction $3$.\n\nThe store writes $w_s = 4$ bytes to the memory interval $I_s = [P, P + w_s - 1] = [P, P + 3]$, where $P$ is the integer value of the address in pointer $p$. The load reads $w_l = 4$ bytes from the memory interval $I_l = [Q, Q + w_l - 1] = [Q, Q + 3]$, where $Q$ is the integer value of the address in pointer $q$.\n\nIn the original program order on the hot trace, the load executes after the store. If the memory intervals $I_s$ and $I_l$ overlap, the load reads a value potentially written by the store. This constitutes a true data dependence, also known as a Read-After-Write (RAW) dependence.\n\nHoisting the load to execute before the store would mean the load reads the value in memory *before* the store has a chance to update it. If the intervals $I_s$ and $I_l$ overlap, this reordering changes the value read by the load, thus violating the program's semantics. The reordering is only legal if the intervals do not overlap.\n\nThe problem states that compile-time alias analysis cannot prove that the pointers $p$ and $q$ do not alias. Therefore, speculative execution is required. The load is moved aggressively, and a runtime check (RC) is inserted to verify the safety of this speculation at execution time.\n\nThe condition for safe reordering is that the memory intervals are disjoint, as stated in the problem: $I_s \\cap I_l = \\emptyset$. For two intervals $[a, b]$ and $[c, d]$, they are disjoint if and only if one interval ends before the other begins. Applying this to our memory accesses, the condition is:\n$$(P + w_s - 1  Q) \\lor (Q + w_l - 1  P)$$\nSince memory addresses are integers, the strict inequality $a  b$ is equivalent to $a + 1 \\le b$. Thus, the condition can be rewritten as:\n$$(P + w_s \\le Q) \\lor (Q + w_l \\le P)$$\nGiven $w_s = 4$ and $w_l = 4$, the correct runtime check is:\n$$((P + 4 \\le Q) \\lor (Q + 4 \\le P))$$\nThis is the condition the RC must test. If it evaluates to true, the speculation was safe, and the program can proceed using the speculatively loaded value.\n\nIf the RC fails, it implies that the memory intervals might overlap ($I_s \\cap I_l \\neq \\emptyset$). To preserve the original program semantics, the execution must revert to the original, non-speculative order. This is the purpose of recovery code. The recovery path must ensure that:\n1.  The store (`$*p \\leftarrow \\dots$`) is executed.\n2.  The original control flow (the conditional branch `if c`) is executed.\n3.  If the original path was to $\\text{B2}$ (i.e., $c$ is true), the load (`$v \\leftarrow *q$`) is executed *after* the store, and the subsequent computation (`$y_1 \\leftarrow v + k$`) is performed.\n4.  If the original path was to $\\text{B3}$ (i.e., $c$ is false), the code in $\\text{B3}$ is executed as normal.\n\nFinally, we consider the control speculation. The load is moved from a conditionally executed block ($\\text{B2}$) to an unconditionally executed block ($\\text{B1}$) on the trace. This is safe because the problem states that all memory accesses are valid (non-faulting).\n\nWith these principles established, we evaluate each option.\n\n**A. Schedule: In $\\text{B1}$, insert RC at new instruction $3'$: compute $P \\leftarrow \\operatorname{uaddr}(p)$ and $Q \\leftarrow \\operatorname{uaddr}(q)$, then test $((P + w_s \\le Q) \\lor (Q + w_l \\le P))$. If RC passes, execute new $4'$: $v_{\\text{hoist}} \\leftarrow *$ $q$, then execute original $3$: $*$ $p \\leftarrow h(t_0)$, then original branch $4$. In $\\text{B2}$, replace $5$ by $5'$: $v \\leftarrow v_{\\text{hoist}}$. Insert a single recovery block $\\text{R}$ with the following outline: on RC failure at $3'$, branch to $\\text{R}$, which executes original $3$ (the store), then executes the original control and use sites in program order: if $c$ then perform $v \\leftarrow *$ $q$ and $y_1 \\leftarrow v + k$ and jump to $\\text{B4}$, else perform $y_2 \\leftarrow y_0 + k$ and jump to $\\text{B4}$. No other changes. Here $\\operatorname{uaddr}(\\cdot)$ denotes the unsigned integer address of a pointer.**\n\n*   **Runtime Check**: The RC is specified as `$((P + w_s \\le Q) \\lor (Q + w_l \\le P))$`. This matches our derived correct condition for disjoint intervals precisely.\n*   **Speculative Path (RC passes)**: The code hoists the load (`$v_{\\text{hoist}} \\leftarrow *q$`) before the store (`$*p \\leftarrow h(t_0)$`). In block $\\text{B2}$, the result of the hoisted load is used. This correctly implements the speculative schedule.\n*   **Recovery Path (RC fails)**: On failure, a branch is taken to a recovery block $\\text{R}$. This block first executes the store (`$*p \\leftarrow h(t_0)$`). Then, it correctly re-creates the original program's control flow by checking $c$ and executing the respective code from blocks $\\text{B2}$ or $\\text{B3}$. This faithfully restores the original program semantics for all possible control flows following the store.\n\nThis option provides a completely correct and robust implementation of the speculative load hoist, including the correct RC and a comprehensive recovery mechanism.\n\n**Verdict: Correct**\n\n**B. Schedule: Move $5$ to the end of $\\text{B0}$ (before any code in $\\text{B1}$), with no RC, on the grounds that loads and stores that use different SSA names commute. In $\\text{B2}$, replace $5$ by the hoisted value. No recovery is necessary because the load has no side effects.**\n\nThe reasoning provided is fundamentally flawed. Static Single Assignment (SSA) form applies to scalar values (registers or variables), not to memory locations accessed through pointers. The fact that the pointers $p$ and $q$ are different SSA variables provides no information about the memory they point to. They could be aliases, pointing to the same or overlapping memory regions. Reordering a load and a store that may alias without a runtime check is a violation of data dependence and is semantically incorrect.\n\n**Verdict: Incorrect**\n\n**C. Schedule: Hoist $5$ to immediately before $3$ in $\\text{B1}$ and insert RC that tests only $(P \\neq Q)$. If RC passes, use the hoisted value in $\\text{B2}$; if RC fails, fall through and execute $3$ and the rest as in the original code. No separate recovery block is needed.**\n\nThe proposed runtime check, $P \\neq Q$, is insufficient. The memory accesses are $4$ bytes wide ($w_s=4, w_l=4$) and potentially unaligned. If, for instance, $P = 100$ and $Q = 101$, then $P \\neq Q$, but the store interval $[100, 103]$ and the load interval $[101, 104]$ overlap. Performing the load before the store would be an error. The check must account for the access widths, which this one fails to do. The description of recovery is also vague and incomplete compared to option A.\n\n**Verdict: Incorrect**\n\n**D. Schedule: Keep $5$ after $3$ but move it from $\\text{B2}$ to the end of $\\text{B1}$ after the branch $4$, so that the load is executed before knowing $c$. Insert RC that tests $((P + w_s  Q) \\lor (Q + w_l  P))$. If RC fails, execute $3$ first, then execute $5$ again to ensure the latest value. No additional recovery is needed because the load is still after the store.**\n\nThis option is flawed in multiple ways.\n1.  **Schedule Goal**: The primary goal is to hoist the load *above the store*. This schedule explicitly keeps the load *after* the store (`Keep $5$ after $3$`), so it fails to meet the specified objective.\n2.  **Schedule Logic**: Placing an instruction in a basic block *after* the terminating branch is logically impossible. This indicates a misunderstanding of control flow.\n3.  **Runtime Check**: The proposed RC is `$((P + w_s  Q) \\lor (Q + w_l  P))$`. This is subtly incorrect. As derived earlier, the correct boundary condition for integer addresses uses $\\le$. For example, if the store interval is $[100, 103]$ and the load interval is $[104, 107]$, then $P=100$, $w_s=4$, $Q=104$. The intervals are disjoint. However, $P+w_s = 104$, so the condition $P+w_s  Q$ (i.e., $104  104$) is false. The check is too strict and would incorrectly signal a potential alias in this case.\n4.  **Recovery**: The justification for \"no additional recovery\" is based on the fact that the load remains after the store, but this contradicts the entire premise of speculative reordering across a potential data dependence.\n\n**Verdict: Incorrect**\n\nIn summary, only Option A presents a schedule that achieves the stated goal with a mathematically correct runtime check and a complete, correct recovery mechanism that preserves program semantics on all execution paths.", "answer": "$$\\boxed{A}$$", "id": "3676434"}, {"introduction": "The ultimate goal of trace scheduling is to generate a highly parallelized instruction schedule for the target architecture. After selecting and transforming a trace, the final step is to arrange the instructions to execute in the minimum amount of time, respecting all hardware constraints and data dependencies. This hands-on scheduling puzzle [@problem_id:3676472] places you in the role of the scheduler for a VLIW processor. You will minimize the execution time (makespan) of a code sequence by carefully orchestrating the use of multiple functional units, navigating instruction latencies, and honoring both data and control dependencies.", "problem": "Consider a Very Long Instruction Word (VLIW) pipeline model with three fully pipelined functional units: a load unit with latency $L_{load}=4$, an adder with latency $L_{add}=1$, and a multiplier with latency $L_{mul}=3$. Each functional unit can accept at most one new instruction per cycle, and there is a global issue width $W=2$ (at most two instructions may be issued per cycle across all units). An instruction’s result becomes available exactly $L$ cycles after its issue, and a dependent instruction may be issued in the same cycle its operands become available. Assume that all memory accesses are independent (no aliasing), there are no stores, and arithmetic instructions are side-effect free. The selected hot trace passes through a conditional branch, and we assume that speculative motion of arithmetic instructions across the branch is permitted, but loads cannot be issued before the branch resolves. The branch predicate is computed in the trace by an addition.\n\nThe program trace comprises the following instructions with explicit data dependencies forming a Directed Acyclic Graph (DAG):\n\n- $L_1$: $\\text{r}_1 \\leftarrow \\text{M}[p]$ (load), no dependencies.\n- $L_2$: $\\text{r}_2 \\leftarrow \\text{M}[q]$ (load), no dependencies.\n- $A_1$: $\\text{r}_3 \\leftarrow \\text{r}_1 + \\text{r}_2$ (add), depends on $L_1$ and $L_2$.\n- $M_1$: $\\text{r}_4 \\leftarrow \\text{r}_3 \\times s$ (mul), depends on $A_1$.\n- $A_2$: $\\text{r}_5 \\leftarrow \\text{r}_4 + \\text{r}_2$ (add), depends on $M_1$ and $L_2$.\n- $A_3$: $\\text{r}_6 \\leftarrow u + v$ (add), no dependencies; the branch resolves when $A_3$ completes.\n- $L_3$: $\\text{r}_8 \\leftarrow \\text{M}[r]$ (load), control-dependent on the branch and cannot be issued before the branch resolves.\n- $M_2$: $\\text{r}_9 \\leftarrow \\text{r}_8 \\times \\text{r}_4$ (mul), depends on $L_3$ and $M_1$.\n- $A_4$: $\\text{r}_{10} \\leftarrow \\text{r}_9 + \\text{r}_3$ (add), depends on $M_2$ and $A_1$.\n- $M_3$: $\\text{r}_{12} \\leftarrow \\text{r}_5 \\times \\text{r}_3$ (mul), depends on $A_2$ and $A_1$.\n- $A_5$: $\\text{r}_{11} \\leftarrow \\text{r}_{10} + \\text{r}_{12}$ (add), depends on $A_4$ and $M_3$.\n\nAssume that the inputs $p$, $q$, $r$, $s$, $u$, and $v$ are available at cycle $0$, and measure cycles starting at issue cycle $0$. Respect all data dependencies, control constraints (loads cannot precede branch resolution), per-unit issue limits, and the global issue width $W=2$.\n\nSchedule this trace to minimize the makespan $T$, defined as the cycle at which $A_5$ completes, starting from the first issue at cycle $0$. Provide the minimal $T$ in cycles. No rounding is required; express $T$ as an integer number of cycles.", "solution": "The user-provided problem is a well-posed instruction scheduling exercise for a Very Long Instruction Word (VLIW) architecture. All specified constraints—functional unit latencies, issue width, and data/control dependencies—are clear, consistent, and scientifically grounded in the principles of computer architecture and compiler design. The problem is therefore deemed valid and a formal solution is constructed below.\n\nThe objective is to determine the minimum makespan, $T$, for the given sequence of instructions. The makespan is defined as the completion cycle of the final instruction, $A_5$. We start at cycle $0$.\n\nLet $t_{issue}(I)$ be the cycle in which instruction $I$ is issued, and $t_{complete}(I)$ be the cycle in which its result is available. For an instruction with latency $L$, the completion time is $t_{complete}(I) = t_{issue}(I) + L$. An instruction can only be issued if all its data dependencies are met (i.e., its operands are available), its control dependencies are resolved, and the required hardware resources are available.\n\nThe hardware parameters are:\n- Load unit latency: $L_{load} = 4$ cycles. There is $1$ load unit.\n- Adder unit latency: $L_{add} = 1$ cycle. There is $1$ adder unit.\n- Multiplier unit latency: $L_{mul} = 3$ cycles. There is $1$ multiplier unit.\n- Global issue width: $W=2$ instructions per cycle.\n\nThe instruction dependencies are as follows:\n- $A_1$ depends on $L_1$ and $L_2$.\n- $M_1$ depends on $A_1$.\n- $A_2$ depends on $M_1$ and $L_2$.\n- $L_3$ is control-dependent on $A_3$ (cannot issue before $A_3$ completes).\n- $M_2$ depends on $L_3$ and $M_1$.\n- $A_4$ depends on $M_2$ and $A_1$.\n- $M_3$ depends on $A_2$ and $A_1$.\n- $A_5$ depends on $A_4$ and $M_3$.\n\nThe solution involves constructing an optimal schedule. A critical step is to analyze the constraints imposed by the dependencies and the limited resources. The single load unit for three load instructions ($L_1, L_2, L_3$) and the long load latency ($L_{load}=4$) represent a primary bottleneck.\n\nFirst, we determine the optimal scheduling for the three load instructions, which must be serialized. Let their issue cycles be $t_{issue}(L_1), t_{issue}(L_2), t_{issue}(L_3)$. To minimize the makespan, these should be scheduled as early as possible, occupying the load unit at cycles $0$, $1$, and $2$ in some permutation.\n\nThe instruction $A_3$ (latency $L_{add}=1$) has no data dependencies. However, it resolves a branch condition that gates the execution of $L_3$. This imposes the control dependency $t_{issue}(L_3) \\ge t_{complete}(A_3) = t_{issue}(A_3) + 1$. To allow $L_3$ to be issued as early as possible, $A_3$ must be issued at cycle $0$. This is possible as it can be co-issued with another instruction from a different functional unit, subject to the global issue width $W=2$.\nIf we issue $A_3$ at cycle $0$, it completes at cycle $t_{complete}(A_3) = 0 + 1 = 1$. The constraint on $L_3$ becomes $t_{issue}(L_3) \\ge 1$. This means $L_3$ cannot be issued at cycle $0$.\n\nThe issue slots for the loads are cycles $0, 1, 2$. Since $t_{issue}(L_3) \\ge 1$, the instruction issued at cycle $0$ must be either $L_1$ or $L_2$. The other two loads will be issued at cycles $1$ and $2$. This leads to two primary scenarios for the load instruction ordering:\n\nCase 1: $L_1$ and $L_2$ are prioritized. The issue sequence for loads is $(L_1, L_2, L_3)$ or $(L_2, L_1, L_3)$. Let's analyze the case with issue times $t_{issue}(L_1)=0$, $t_{issue}(L_2)=1$, and $t_{issue}(L_3)=2$.\n- $t_{complete}(L_1) = 0+4=4$.\n- $t_{complete}(L_2) = 1+4=5$.\n- $t_{complete}(L_3) = 2+4=6$.\n\nNow we calculate the earliest possible completion times for the dependent instructions (this is an ASAP schedule, which we will later verify against all resource constraints):\n- $A_1$ depends on $L_1, L_2$: $t_{issue}(A_1) \\ge \\max(t_c(L_1), t_c(L_2)) = 5$. With $L_{add}=1$, $t_{complete}(A_1) \\ge 5+1=6$.\n- $M_1$ depends on $A_1$: $t_{issue}(M_1) \\ge 6$. With $L_{mul}=3$, $t_{complete}(M_1) \\ge 6+3=9$.\n- $A_2$ depends on $M_1, L_2$: $t_{issue}(A_2) \\ge \\max(9, 5) = 9$. With $L_{add}=1$, $t_{complete}(A_2) \\ge 9+1=10$.\n- $M_2$ depends on $L_3, M_1$: $t_{issue}(M_2) \\ge \\max(6, 9) = 9$. With $L_{mul}=3$, $t_{complete}(M_2) \\ge 9+3=12$.\n- $M_3$ depends on $A_2, A_1$: $t_{issue}(M_3) \\ge \\max(10, 6) = 10$. With $L_{mul}=3$, $t_{complete}(M_3) \\ge 10+3=13$.\n- $A_4$ depends on $M_2, A_1$: $t_{issue}(A_4) \\ge \\max(12, 6) = 12$. With $L_{add}=1$, $t_{complete}(A_4) \\ge 12+1=13$.\n- $A_5$ depends on $A_4, M_3$: $t_{issue}(A_5) \\ge \\max(13, 13) = 13$. With $L_{add}=1$, $t_{complete}(A_5) \\ge 13+1=14$.\nThis analysis establishes a lower bound on the makespan of $T \\ge 14$ cycles for this load ordering.\n\nCase 2: $L_3$ is prioritized over $L_2$. The issue sequence for loads is $(L_1, L_3, L_2)$ with issue times $t_{issue}(L_1)=0$, $t_{issue}(L_3)=1$, and $t_{issue}(L_2)=2$.\n- $t_{complete}(L_1) = 0+4=4$.\n- $t_{complete}(L_3) = 1+4=5$.\n- $t_{complete}(L_2) = 2+4=6$.\n\nNow we calculate the earliest completion times:\n- $A_1$ depends on $L_1, L_2$: $t_{issue}(A_1) \\ge \\max(4, 6) = 6$. So, $t_{complete}(A_1) \\ge 6+1=7$.\n- $M_1$ depends on $A_1$: $t_{issue}(M_1) \\ge 7$. So, $t_{complete}(M_1) \\ge 7+3=10$.\n- $A_2$ depends on $M_1, L_2$: $t_{issue}(A_2) \\ge \\max(10, 6) = 10$. So, $t_{complete}(A_2) \\ge 10+1=11$.\n- $M_2$ depends on $L_3, M_1$: $t_{issue}(M_2) \\ge \\max(5, 10) = 10$. So, $t_{complete}(M_2) \\ge 10+3=13$.\n- $M_3$ depends on $A_2, A_1$: $t_{issue}(M_3) \\ge \\max(11, 7) = 11$. So, $t_{complete}(M_3) \\ge 11+3=14$.\n- $A_4$ depends on $M_2, A_1$: $t_{issue}(A_4) \\ge \\max(13, 7) = 13$. So, $t_{complete}(A_4) \\ge 13+1=14$.\n- $A_5$ depends on $A_4, M_3$: $t_{issue}(A_5) \\ge \\max(14, 14) = 14$. So, $t_{complete}(A_5) \\ge 14+1=15$.\nThis load ordering yields a minimum makespan of $T=15$ cycles.\n\nComparing the two cases, the minimal makespan is $14$ cycles, achieved by prioritizing the issue of loads $L_1$ and $L_2$. A specific schedule that achieves this makespan is constructed below, validating that the lower bound of $14$ is achievable.\n\nOptimal Schedule ($T=14$):\n- Cycle $0$: Issue $L_1$ (Load unit) and $A_3$ (Add unit). ($W=2$ used). $A_3$ completes at cycle $1$. $L_1$ completes at cycle $4$.\n- Cycle $1$: Issue $L_2$ (Load unit). ($W=1$ used). $L_2$ completes at cycle $5$.\n- Cycle $2$: Issue $L_3$ (Load unit). ($W=1$ used). $L_3$ can be issued as $A_3$ is complete. $L_3$ completes at cycle $6$.\n- Cycles $3, 4$: Idle.\n- Cycle $5$: Issue $A_1$ (Add unit). Operands from $L_1$ (ready at cycle $4$) and $L_2$ (ready at cycle $5$) are available. $A_1$ completes at cycle $6$.\n- Cycle $6$: Issue $M_1$ (Mul unit). Operand from $A_1$ (ready at cycle $6$) is available. $M_1$ completes at cycle $9$.\n- Cycles $7, 8$: Idle.\n- Cycle $9$: Issue $A_2$ (Add unit) and $M_2$ (Mul unit). ($W=2$ used).\n  - $A_2$ operands from $M_1$ (ready at $9$) and $L_2$ (ready at $5$) are available. $A_2$ completes at cycle $10$.\n  - $M_2$ operands from $L_3$ (ready at $6$) and $M_1$ (ready at $9$) are available. $M_2$ completes at cycle $12$.\n- Cycle $10$: Issue $M_3$ (Mul unit). Operands from $A_2$ (ready at $10$) and $A_1$ (ready at $6$) are available. $M_3$ completes at cycle $13$.\n- Cycle $11$: Idle.\n- Cycle $12$: Issue $A_4$ (Add unit). Operands from $M_2$ (ready at $12$) and $A_1$ (ready at $6$) are available. $A_4$ completes at cycle $13$.\n- Cycle $13$: Issue $A_5$ (Add unit). Operands from $A_4$ (ready at $13$) and $M_3$ (ready at $13$) are available. $A_5$ completes at cycle $14$.\n\nThis schedule is valid, respects all constraints, and achieves the calculated lower bound. Therefore, the minimal makespan is $14$ cycles.", "answer": "$$\\boxed{14}$$", "id": "3676472"}]}