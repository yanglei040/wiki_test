{"hands_on_practices": [{"introduction": "Software pipelining aims to execute loops faster by overlapping iterations, but its performance is ultimately limited by the processor's available functional units. This first practice explores the concept of the Resource-Constrained Minimum Initiation Interval ($ResMII$), which represents the theoretical speed limit imposed by hardware resources. By calculating $ResMII$, you will learn to identify the specific hardware units that act as bottlenecks, a crucial first step in performance analysis and scheduling. [@problem_id:3670535]", "problem": "A compiler schedules a loop for a Very Long Instruction Word (VLIW) processor using software pipelining. The processor has multiple identical functional units per type. Assume the following for the loop and machine:\n\n- The machine has $U_{\\text{ALU}} = 4$ arithmetic logic units (ALUs), $U_{\\text{MUL}} = 2$ multiply units, $U_{\\text{MEM}} = 1$ memory unit, and $U_{\\text{SFU}} = 1$ special function unit (SFU).\n- Each operation of a given type occupies exactly one corresponding unit for exactly one cycle when issued. Ignore all latencies, loop-carried dependences, bypass restrictions, and structural hazards beyond unit multiplicity. Assume unbounded registers and that every iteration must execute the stated number of operations of each type.\n- The loop body per iteration contains $11$ ALU operations, $3$ multiply operations, $4$ memory operations (loads or stores), and $1$ SFU operation.\n\nUsing only resource considerations, determine the resource-constrained minimum initiation interval (ResMII), defined as the tightest lower bound on the initiation interval imposed by finite resource multiplicities. Also indicate which unit types are resource bottlenecks under this bound. For grading, provide only the numerical value of $\\text{ResMII}$ as your final answer; include your reasoning about bottlenecks in your working. Provide an exact integer value; no rounding is required.", "solution": "The user wants to determine the resource-constrained minimum initiation interval ($\\text{ResMII}$) for a software-pipelined loop on a VLIW processor.\n\nThis problem is a classic application of principles from compiler theory and computer architecture, specifically concerning instruction-level parallelism and resource scheduling. The problem is scientifically grounded, well-posed, objective, and contains all necessary information for a unique solution. The simplifying assumption to ignore latencies and dependencies is a standard pedagogical tool to isolate the effect of resource constraints. The problem is therefore deemed **valid**.\n\nThe initiation interval, denoted as $II$, is the number of clock cycles between the start of successive iterations in a software-pipelined loop. In a steady state, one complete loop iteration is initiated every $II$ cycles.\n\nFor any given functional unit type $R$, let $U_R$ be the number of available units and $N_R$ be the number of operations of that type required by a single loop iteration. In a steady-state execution with an initiation interval of $II$, the total number of available operation slots for type $R$ over the course of $II$ cycles is $U_R \\times II$. To sustain the loop, this capacity must be sufficient to accommodate the $N_R$ operations required by each iteration. This leads to the fundamental resource constraint inequality for each resource type $R$:\n$$N_R \\le U_R \\times II$$\nThis inequality can be rearranged to find a lower bound on the initiation interval imposed by resource type $R$:\n$$II \\ge \\frac{N_R}{U_R}$$\nSince the initiation interval must be an integer number of clock cycles, the minimum initiation interval for resource type $R$, denoted $MII_R$, is the smallest integer satisfying this condition. This is found by taking the ceiling of the ratio:\n$$MII_R = \\left\\lceil \\frac{N_R}{U_R} \\right\\rceil$$\nThe overall resource-constrained minimum initiation interval, $\\text{ResMII}$, is the most stringent of these individual lower bounds. That is, it is the maximum of the $MII_R$ values over all resource types, as the loop can only proceed as fast as its most constrained resource allows.\n$$\\text{ResMII} = \\max_{R} (MII_R)$$\nThe problem provides the following data:\n- Number of required ALU operations per iteration: $N_{\\text{ALU}} = 11$\n- Number of available ALUs: $U_{\\text{ALU}} = 4$\n- Number of required multiply operations per iteration: $N_{\\text{MUL}} = 3$\n- Number of available multiply units: $U_{\\text{MUL}} = 2$\n- Number of required memory operations per iteration: $N_{\\text{MEM}} = 4$\n- Number of available memory units: $U_{\\text{MEM}} = 1$\n- Number of required SFU operations per iteration: $N_{\\text{SFU}} = 1$\n- Number of available SFUs: $U_{\\text{SFU}} = 1$\n\nWe now calculate the minimum initiation interval for each resource type:\nFor the arithmetic logic units (ALUs):\n$$MII_{\\text{ALU}} = \\left\\lceil \\frac{N_{\\text{ALU}}}{U_{\\text{ALU}}} \\right\\rceil = \\left\\lceil \\frac{11}{4} \\right\\rceil = \\lceil 2.75 \\rceil = 3$$\nFor the multiply units (MULs):\n$$MII_{\\text{MUL}} = \\left\\lceil \\frac{N_{\\text{MUL}}}{U_{\\text{MUL}}} \\right\\rceil = \\left\\lceil \\frac{3}{2} \\right\\rceil = \\lceil 1.5 \\rceil = 2$$\nFor the memory unit (MEM):\n$$MII_{\\text{MEM}} = \\left\\lceil \\frac{N_{\\text{MEM}}}{U_{\\text{MEM}}} \\right\\rceil = \\left\\lceil \\frac{4}{1} \\right\\rceil = \\lceil 4 \\rceil = 4$$\nFor the special function unit (SFU):\n$$MII_{\\text{SFU}} = \\left\\lceil \\frac{N_{\\text{SFU}}}{U_{\\text{SFU}}} \\right\\rceil = \\left\\lceil \\frac{1}{1} \\right\\rceil = \\lceil 1 \\rceil = 1$$\nThe overall $\\text{ResMII}$ is the maximum of these individual values:\n$$\\text{ResMII} = \\max(\\{MII_{\\text{ALU}}, MII_{\\text{MUL}}, MII_{\\text{MEM}}, MII_{\\text{SFU}}\\})$$\n$$\\text{ResMII} = \\max(\\{3, 2, 4, 1\\}) = 4$$\nThe resource type(s) that determine the value of $\\text{ResMII}$ are the bottlenecks. In this case, $MII_{\\text{MEM}} = 4$, which is the maximum value. Therefore, the memory unit is the resource bottleneck, as it imposes the tightest constraint on the loop's execution rate. The required $\\text{ResMII}$ is $4$ cycles.", "answer": "$$\\boxed{4}$$", "id": "3670535"}, {"introduction": "Beyond hardware limits, the speed of a pipelined loop is also constrained by the data dependencies between its iterations. This exercise focuses on the Recurrence-Constrained Minimum Initiation Interval ($RecMII$), which arises from loop-carried dependencies where an operation in one iteration depends on the result from a previous iteration. Understanding how to calculate this bound from an operation's latency ($l$) and the dependence distance ($d$) is fundamental to correctly scheduling loops while respecting data flow constraints. [@problem_id:3670523]", "problem": "Consider a simple loop whose body contains a single operation $x$ that produces a value used to compute the next instance of $x$ across iterations. Concretely, assume a loop of the form $x(i) = f(x(i-2))$, where the computation $f$ is implemented by a single operation $x$ with latency $l = 5$ cycles, and the loop-carried dependence distance is $d = 2$. A compiler attempts to construct a modulo schedule for this loop using Software Pipelining, assigning the operation $x$ a fixed cycle offset $t(x)$ within a kernel of Initiation Interval (II), where the Initiation Interval (II) is the number of cycles between the start of two consecutive loop iterations. The dependence is a self-dependence from $x(i-2)$ to $x(i)$ of distance $d = 2$ and latency $l = 5$.\n\nUsing only fundamental definitions of dependence distance $d$, latency $l$, and Initiation Interval (II), and the fact that a modulo schedule assigns a single fixed offset $t(x)$ to each operation within the kernel (independent of iteration index), determine which of the following statements are correct.\n\nA. The recurrence lower bound for this loop enforces $II \\ge \\lceil l/d \\rceil = \\lceil 5/2 \\rceil = 3$, because summing time-difference constraints around the single self-dependence cycle yields $0 \\ge l - d \\cdot II$.\n\nB. A modulo schedule with $II = 2$ can still satisfy the dependence by choosing offsets so that $t(x,i) - t(x,i-2) = 1$, making the elapsed time between $x(i-2)$ and $x(i)$ equal to $5$ cycles.\n\nC. A valid minimal schedule pattern is $II = 3$ with $t(x) = 0$, so successive instances of $x$ start at cycles $\\{0, 3, 6, \\dots\\}$; the elapsed time from $x(i-2)$ to $x(i)$ is $2 \\cdot II = 6 \\ge l = 5$, satisfying the dependence.\n\nD. With $II = 3$, a staggered pattern $t(x,i) = (i \\bmod 3)$ is valid and reduces register pressure, because the dependence inequality allows positive slack for different iteration offsets.\n\nE. If resource constraints permit, any $II \\ge 3$ satisfies the dependence, and when $II = 3$ any fixed offset choice $t(x) \\in \\{0, 1, 2\\}$ yields a correct schedule since the self-dependence is met.\n\nF. The minimal Initiation Interval is independent of $d$; only latency $l$ matters, so the minimal $II$ is $\\lceil 5/1 \\rceil = 5$.", "solution": "The problem statement is analyzed for validity.\n\n**Step 1: Extract Givens**\n- Loop body consists of a single operation, denoted as $x$.\n- The loop computes $x(i) = f(x(i-2))$.\n- The operation $x$ has a latency $l = 5$ cycles.\n- The loop-carried dependence is a self-dependence from $x(i-2)$ to $x(i)$.\n- The dependence distance is $d = 2$ iterations.\n- The scheduling method is Software Pipelining, constructing a modulo schedule.\n- The operation $x$ is assigned a fixed cycle offset $t(x)$ within a kernel.\n- The Initiation Interval, $II$, is the number of cycles between the start of two consecutive loop iterations.\n- The offset $t(x)$ is independent of the iteration index $i$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is a standard exercise in compiler theory, specifically concerning modulo scheduling for software pipelining. The concepts of latency ($l$), dependence distance ($d$), and Initiation Interval ($II$) are fundamental to this field. The problem is correctly framed within established compiler optimization principles.\n- **Well-Posed:** The problem is well-posed. It provides all necessary parameters ($l=5$, $d=2$) to determine the constraints on the Initiation Interval $II$. The question is specific and has a unique, verifiable answer based on the theory.\n- **Objective:** The language is technical, precise, and free of subjective elements.\n- **Incomplete or Contradictory Setup:** The setup is self-consistent and complete. The relationship $x(i) = f(x(i-2))$ is consistently described as a self-dependence with a distance of $d=2$.\n- **Ill-Posed or Poorly Structured:** The terminology is standard and unambiguous within the context of compiler design. The problem defines its terms clearly (e.g., \"fixed cycle offset $t(x)$ ... independent of iteration index\").\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. A solution will be derived and the options evaluated.\n\n**Derivation of the Fundamental Constraint**\n\nThe core principle of modulo scheduling is to satisfy all data dependencies. Let $T(op, i)$ be the absolute start time of an operation `op` in iteration $i$. In a modulo schedule with a fixed offset $t(op)$ for the operation and an Initiation Interval $II$, this start time is given by:\n$$T(op, i) = t(op) + i \\cdot II$$\nwhere we can set the start time of the first iteration's kernel to cycle $0$ without loss of generality.\n\nThe problem describes a loop-carried self-dependence for operation $x$. The value produced by operation $x$ in iteration $i-d$ is consumed by operation $x$ in iteration $i$.\n- The producing operation instance is $x$ from iteration $i-d$. It starts at time $T(x, i-d) = t(x) + (i-d) \\cdot II$.\n- The result of this operation is available after its latency, $l$. Thus, the value is ready at time $T(x, i-d) + l$.\n- The consuming operation instance is $x$ from iteration $i$. It starts at time $T(x, i) = t(x) + i \\cdot II$.\n\nFor the dependence to be satisfied, the consumer must not start before the value is ready:\n$$T(x, i) \\ge T(x, i-d) + l$$\nSubstituting the expressions for the start times:\n$$t(x) + i \\cdot II \\ge (t(x) + (i-d) \\cdot II) + l$$\nThe terms $t(x)$ and $i \\cdot II$ appear on both sides and can be simplified:\n$$i \\cdot II \\ge i \\cdot II - d \\cdot II + l$$\nThis simplifies to the fundamental recurrence constraint for a self-dependence in a modulo schedule:\n$$d \\cdot II \\ge l$$\nAn alternative but equivalent formulation often seen in literature states that for a dependence from operation $u$ to $v$ with distance $d$ and latency $l$, the offsets must satisfy $t(v) - t(u) \\ge l - d \\cdot II$. For a self-dependence, $u=v=x$, so $t(x) - t(x) = 0$, yielding $0 \\ge l - d \\cdot II$, which is the same as $d \\cdot II \\ge l$.\n\nUsing the given values $l=5$ and $d=2$:\n$$2 \\cdot II \\ge 5$$\n$$II \\ge \\frac{5}{2} = 2.5$$\nSince the Initiation Interval $II$ must be an integer number of cycles, the minimum possible value for $II$ is:\n$$II_{min} = \\lceil 2.5 \\rceil = 3$$\nThis lower bound is known as the Recurrence-constrained Minimum Initiation Interval ($RecMII$). The overall Minimum Initiation Interval ($MII$) is the maximum of the $RecMII$ and the Resource-constrained MII ($ResMII$). Since the loop body has only one operation, the resource constraints are minimal ($ResMII=1$ if there is at least one functional unit for $x$), so the recurrence is the limiting factor. Thus, the minimal $II$ is $3$.\n\n**Option-by-Option Analysis**\n\n**A. The recurrence lower bound for this loop enforces $II \\ge \\lceil l/d \\rceil = \\lceil 5/2 \\rceil = 3$, because summing time-difference constraints around the single self-dependence cycle yields $0 \\ge l - d \\cdot II$.**\nThis statement presents the fundamental inequality in the form $0 \\ge l - d \\cdot II$, which is equivalent to the $d \\cdot II \\ge l$ derived above. It correctly substitutes the values of $l=5$ and $d=2$ to get $II \\ge 5/2$, and then correctly takes the ceiling to find the minimum integer $II$, which is $3$. The reasoning and the result are perfectly sound.\n**Verdict: Correct**\n\n**B. A modulo schedule with $II = 2$ can still satisfy the dependence by choosing offsets so that $t(x,i) - t(x,i-2) = 1$, making the elapsed time between $x(i-2)$ and $x(i)$ equal to $5$ cycles.**\nThis statement is incorrect for two reasons. First, as derived, any valid schedule must have $II \\ge 3$. An $II$ of $2$ violates the recurrence constraint ($2 \\cdot 2 = 4 \\not\\ge 5$). Second, the problem explicitly defines a modulo schedule as having a \"single fixed offset $t(x)$ ... independent of iteration index\". This option proposes using an iteration-dependent offset, written as $t(x,i)$, which contradicts the definition of the scheduling model being used.\n**Verdict: Incorrect**\n\n**C. A valid minimal schedule pattern is $II = 3$ with $t(x) = 0$, so successive instances of $x$ start at cycles $\\{0, 3, 6, \\dots\\}$; the elapsed time from $x(i-2)$ to $x(i)$ is $2 \\cdot II = 6 \\ge l = 5$, satisfying the dependence.**\nThis statement proposes a specific, valid schedule. The minimal $II$ is indeed $3$. A fixed offset of $t(x)=0$ is a valid choice. With $t(x)=0$ and $II=3$, the start time for instance $i$ is $T(x,i) = 0 + i \\cdot 3 = 3i$, leading to start times of $\\{0, 3, 6, \\dots\\}$. The time elapsed between the start of operation $x$ in iteration $i-2$ and iteration $i$ is $T(x,i) - T(x,i-2) = 3i - 3(i-2) = 6$. Alternatively, this elapsed time is always $d \\cdot II = 2 \\cdot 3 = 6$ cycles. The dependence is satisfied because this elapsed time ($6$ cycles) is greater than or equal to the latency ($l=5$ cycles). The statement is a correct and concrete illustration of a valid minimal schedule.\n**Verdict: Correct**\n\n**D. With $II = 3$, a staggered pattern $t(x,i) = (i \\bmod 3)$ is valid and reduces register pressure, because the dependence inequality allows positive slack for different iteration offsets.**\nThis statement, like option B, proposes a scheduling scheme where the offset depends on the iteration index $i$. This is not a standard modulo schedule as defined in the problem (\"a single fixed offset $t(x)$\"). While such \"staggered\" or \"swing\" modulo schedules exist as a more advanced technique (and might indeed affect register pressure), this option incorrectly labels it as a valid pattern under the specified constraints of the problem.\n**Verdict: Incorrect**\n\n**E. If resource constraints permit, any $II \\ge 3$ satisfies the dependence, and when $II = 3$ any fixed offset choice $t(x) \\in \\{0, 1, 2\\}$ yields a correct schedule since the self-dependence is met.**\nThis statement consists of two parts.\nFirst, \"any $II \\ge 3$ satisfies the dependence\". The dependence inequality is $2 \\cdot II \\ge 5$. For any integer $II \\ge 3$, this is true (e.g., if $II=3$, $6 \\ge 5$; if $II=4$, $8 \\ge 5$, etc.). This part is correct.\nSecond, \"when $II = 3$ any fixed offset choice $t(x) \\in \\{0, 1, 2\\}$ yields a correct schedule\". As shown in the derivation, the fixed offset $t(x)$ cancels out of the inequality for a self-dependence ($t(x) - t(x) \\ge l - d \\cdot II$). This means the choice of $t(x)$ does not affect whether the recurrence constraint is met. Therefore, any choice of a fixed offset is valid for satisfying this specific dependence. The set $\\{0, 1, 2\\}$ represents all possible offsets modulo $II=3$. This part is also correct.\n**Verdict: Correct**\n\n**F. The minimal Initiation Interval is independent of $d$; only latency $l$ matters, so the minimal $II$ is $\\lceil 5/1 \\rceil = 5$.**\nThis statement is fundamentally false. The derivation $d \\cdot II \\ge l$ clearly shows that the minimal $II$ depends on both the latency $l$ and the dependence distance $d$. The statement's claim that $II$ is \"independent of $d$\" is incorrect. It then proceeds to calculate a minimal $II$ by incorrectly assuming $d=1$, which contradicts the given information that $d=2$.\n**Verdict: Incorrect**", "answer": "$$\\boxed{ACE}$$", "id": "3670523"}, {"introduction": "Choosing the smallest possible Initiation Interval ($II$) seems optimal, but it can create a new problem: high register pressure. Overlapping many iterations simultaneously means more temporary values must be kept \"live\" at the same time, potentially exceeding the processor's register file capacity. This practice guides you through a realistic trade-off analysis, where you must weigh the speed benefits of a lower $II$ against the performance cost of spilling registers to memory, allowing you to find the true optimal schedule. [@problem_id:3670551]", "problem": "A loop is being modulo-scheduled using software pipelining on a processor with a rotating register file. Consider a single logical iteration of the modulo-scheduled kernel. Within this kernel, there are three temporaries whose live windows, measured from the cycle of definition to the cycle of last use inclusive within the kernel schedule, have lengths $L_{A} = 5$, $L_{B} = 7$, and $L_{C} = 2$ cycles. Two candidate Initiation Interval (II) choices, $II = 2$ and $II = 3$, are both feasible with respect to recurrence and functional-unit resources in the absence of spilling. The machine has a hard limit of maximum simultaneously live rotating registers $R_{\\max} = 7$.\n\nAssume the following modeling assumptions for steady state:\n- A temporary contributes as many simultaneously live instances in steady state as the number of kernel starts that occur within its live window.\n- If the sum of simultaneously live instances over all temporaries exceeds $R_{\\max}$ for a chosen $II$, you must spill exactly the excess number of simultaneously live instances per original loop iteration to satisfy the register limit. Spilling one simultaneously live instance induces one store after the definition and one load before the use; together these two memory operations impose an amortized steady-state overhead of $\\delta = 0.5$ cycles per original iteration due to partial overlap with other instructions.\n- Ignore prologue and epilogue. Use an additive steady-state cost model in which the estimated cycles per original iteration is $C(II) = II + \\delta \\cdot s(II)$, where $s(II)$ is the number of spilled simultaneously live instances per original iteration required to satisfy the $R_{\\max}$ constraint for that $II$.\n\nAmong the two candidates $II = 2$ and $II = 3$, determine which $II$ minimizes $C(II)$ under these assumptions. Report only the chosen $II$ as your final answer. No rounding is required, and no units should be included in the final answer.", "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n**Step 1: Extract Givens**\nThe following data are provided in the problem statement:\n- Live window lengths of three temporaries: $L_{A} = 5$ cycles, $L_{B} = 7$ cycles, $L_{C} = 2$ cycles.\n- Two candidate Initiation Intervals (II): $II \\in \\{2, 3\\}$.\n- Maximum number of simultaneously live rotating registers: $R_{\\max} = 7$.\n- Model for the number of simultaneously live instances of a temporary: the number of kernel starts within its live window.\n- Spilling rule: If the total number of required registers exceeds $R_{\\max}$, the number of spills per original iteration, $s(II)$, is the exact excess.\n- Spilling overhead: $\\delta = 0.5$ cycles per spilled instance per original iteration.\n- Steady-state cost model: $C(II) = II + \\delta \\cdot s(II)$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is well-defined within the context of compiler theory, specifically software pipelining for instruction-level parallelism. The concepts of Initiation Interval (II), live windows, rotating registers, and register spilling are standard. The model for calculating register pressure and performance cost is a simplified but consistent and common formulation used in this field. The number of simultaneously live instances of a temporary with live window length $L$ for a given $II$ is correctly modeled as $\\lceil L/II \\rceil$. All necessary data are provided, the constraints are clear, and there are no contradictions. The problem is scientifically grounded, well-posed, and objective.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A solution will be provided.\n\nThe objective is to determine which of the two candidate Initiation Intervals, $II = 2$ or $II = 3$, results in a lower steady-state cost per original iteration, $C(II)$. The cost is a function of the $II$ itself and the overhead from any necessary register spilling.\n\nFirst, we must calculate the total number of simultaneously live registers required, $R(II)$, for each candidate $II$. The number of simultaneously live instances for a single temporary with a live window of length $L$ is given by $N = \\lceil L/II \\rceil$. The total register requirement is the sum of these values over all temporaries.\n$$R(II) = \\lceil \\frac{L_A}{II} \\rceil + \\lceil \\frac{L_B}{II} \\rceil + \\lceil \\frac{L_C}{II} \\rceil$$\n\nNext, we determine the number of spills required, $s(II)$, by comparing $R(II)$ to the machine's limit, $R_{\\max}$.\n$$s(II) = \\max(0, R(II) - R_{\\max})$$\n\nFinally, we calculate the cost $C(II)$ for each candidate using the given formula.\n$$C(II) = II + \\delta \\cdot s(II)$$\n\nLet us analyze the two cases.\n\n**Case 1: $II = 2$**\nThe given live window lengths are $L_{A} = 5$, $L_{B} = 7$, and $L_{C} = 2$.\nThe number of live instances for each temporary is:\n- For temporary A: $N_A(2) = \\lceil \\frac{L_A}{2} \\rceil = \\lceil \\frac{5}{2} \\rceil = \\lceil 2.5 \\rceil = 3$.\n- For temporary B: $N_B(2) = \\lceil \\frac{L_B}{2} \\rceil = \\lceil \\frac{7}{2} \\rceil = \\lceil 3.5 \\rceil = 4$.\n- For temporary C: $N_C(2) = \\lceil \\frac{L_C}{2} \\rceil = \\lceil \\frac{2}{2} \\rceil = \\lceil 1 \\rceil = 1$.\n\nThe total required registers for $II=2$ is the sum:\n$$R(2) = N_A(2) + N_B(2) + N_C(2) = 3 + 4 + 1 = 8$$\nThe machine has a limit of $R_{\\max} = 7$ registers. Since $R(2) = 8  R_{\\max} = 7$, register spilling is required. The number of spills per original iteration is the excess:\n$$s(2) = R(2) - R_{\\max} = 8 - 7 = 1$$\nNow we can calculate the cost for $II = 2$ using the overhead $\\delta = 0.5$:\n$$C(2) = II + \\delta \\cdot s(2) = 2 + (0.5) \\cdot 1 = 2 + 0.5 = 2.5$$\n\n**Case 2: $II = 3$**\nThe given live window lengths are $L_{A} = 5$, $L_{B} = 7$, and $L_{C} = 2$.\nThe number of live instances for each temporary is:\n- For temporary A: $N_A(3) = \\lceil \\frac{L_A}{3} \\rceil = \\lceil \\frac{5}{3} \\rceil = \\lceil 1.66... \\rceil = 2$.\n- For temporary B: $N_B(3) = \\lceil \\frac{L_B}{3} \\rceil = \\lceil \\frac{7}{3} \\rceil = \\lceil 2.33... \\rceil = 3$.\n- For temporary C: $N_C(3) = \\lceil \\frac{L_C}{3} \\rceil = \\lceil \\frac{2}{3} \\rceil = \\lceil 0.66... \\rceil = 1$.\n\nThe total required registers for $II=3$ is the sum:\n$$R(3) = N_A(3) + N_B(3) + N_C(3) = 2 + 3 + 1 = 6$$\nThe machine limit is $R_{\\max} = 7$. Since $R(3) = 6 \\le R_{\\max} = 7$, no register spilling is required.\n$$s(3) = \\max(0, R(3) - R_{\\max}) = \\max(0, 6 - 7) = 0$$\nThe cost for $II = 3$ is:\n$$C(3) = II + \\delta \\cdot s(3) = 3 + (0.5) \\cdot 0 = 3$$\n\n**Comparison and Conclusion**\nWe compare the costs for the two candidate Initiation Intervals:\n- $C(2) = 2.5$ cycles per original iteration.\n- $C(3) = 3$ cycles per original iteration.\n\nSince $C(2)  C(3)$, the Initiation Interval that minimizes the steady-state cost is $II = 2$. Even though a smaller $II$ increases register pressure and forces a spill, the performance gain from a shorter initiation interval outweighs the cost of the spill overhead in this case.", "answer": "$$\\boxed{2}$$", "id": "3670551"}]}