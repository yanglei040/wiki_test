{"hands_on_practices": [{"introduction": "To begin our hands-on exploration of Lazy Code Motion (LCM), we will start with a classic scenario involving partial redundancy. This first practice problem asks you to analyze a simple \"diamond\" control-flow structure and determine where LCM will insert new computations and where it will delete existing ones. By calculating the expected number of executions before and after the transformation, you will gain a tangible understanding of how LCM improves program efficiency [@problem_id:3649324].", "problem": "Consider the following Control Flow Graph (CFG) for a straight-line region inside a compiler’s intermediate representation. The region consists of five basic blocks $B_{0}$, $B_{1}$, $B_{2}$, $B_{3}$, and $B_{4}$ with directed edges:\n- $B_{0} \\rightarrow B_{1}$,\n- $B_{1} \\rightarrow B_{2}$ and $B_{1} \\rightarrow B_{3}$,\n- $B_{2} \\rightarrow B_{4}$ and $B_{3} \\rightarrow B_{4}$,\n- $B_{4} \\rightarrow \\text{Exit}$.\n\nThe contents of each block are:\n- $B_{0}$: no statements (entry).\n- $B_{1}$: $x := a$; $y := b$; a conditional branch to $B_{2}$ with probability $p = \\frac{3}{5}$, and to $B_{3}$ with probability $1 - p = \\frac{2}{5}$.\n- $B_{2}$: $t := x + y$; $s := t + 1$.\n- $B_{3}$: $r := 2 \\cdot x$.\n- $B_{4}$: $u := x + y$; $v := u \\cdot m$.\n\nAssume:\n- No redefinitions of $x$ or $y$ occur in $B_{2}$, $B_{3}$, or between the end of $B_{2}$/$B_{3}$ and the start of $B_{4}$.\n- The only use of $x + y$ after $B_{4}$ is through $u$ in $B_{4}$; there are no other uses elsewhere.\n- The region is executed once per consideration, and the branch from $B_{1}$ to $B_{2}$ or $B_{3}$ is the only source of path variability.\n\nLet Lazy Code Motion (LCM) denote the transformation that removes partial redundancy by inserting computations at the latest safe points and deleting redundant computations that become unnecessary due to those insertions.\n\nYour tasks:\n1. For the expression $e = x + y$, compute the $\\mathrm{Insert}$ and $\\mathrm{Delete}$ sets at block granularity under Lazy Code Motion. For this problem, interpret $\\mathrm{Insert}(B)$ to mean “insert the computation of $e$ at the entry of block $B$” and $\\mathrm{Delete}(B)$ to mean “delete the original computation of $e$ within block $B$.”\n2. Using the given branch probabilities, count the expected number of dynamic evaluations of $e$ per single execution of the region before applying LCM and after applying LCM.\n3. Provide, as your final answer, the expected reduction in the number of dynamic evaluations of $e$ per single execution of the region (that is, the expected count before LCM minus the expected count after LCM). Express your answer as an exact fraction. Do not round.", "solution": "The problem is well-posed, scientifically grounded in the principles of compiler optimization, and provides all necessary information to determine a unique solution. The problem is therefore valid. We proceed with the solution.\n\nThe analysis centers on the expression $e = x + y$ within the provided Control Flow Graph (CFG). The goal is to apply Lazy Code Motion (LCM) to reduce the number of dynamic evaluations of this expression. LCM is a partial-redundancy elimination (PRE) algorithm that avoids unnecessarily early computation by placing code as late as possible.\n\nFirst, we must analyze the occurrences of the expression $e = x+y$ in the original program.\n- In basic block $B_2$, the expression is computed: $t := x + y$. The result is subsequently used within the same block by $s := t + 1$.\n- In basic block $B_4$, the expression is computed again: $u := x + y$.\n\nThe CFG has a diamond structure where the path splits after $B_1$ and rejoins before $B_4$. There are two main paths from $B_1$ to $B_4$:\n1. Path $P_1$: $B_1 \\rightarrow B_2 \\rightarrow B_4$\n2. Path $P_2$: $B_1 \\rightarrow B_3 \\rightarrow B_4$\n\nLet's examine the redundancy of the computation $u := x+y$ in block $B_4$.\n- On path $P_1$, the expression $x+y$ is computed in $B_2$. Since the assumption states that $x$ and $y$ are not redefined between their definitions in $B_1$ and their use in $B_4$, the value of $x+y$ computed in $B_2$ is available at the entry of $B_4$. Therefore, the computation $u := x+y$ in $B_4$ is redundant on this path.\n- On path $P_2$, the expression $x+y$ is *not* computed in $B_3$. Therefore, the computation $u := x+y$ in $B_4$ is necessary on this path.\n\nBecause the computation in $B_4$ is redundant on some, but not all, paths leading to it, it is classified as a *partially redundant* computation. The purpose of LCM is to eliminate this partial redundancy. This is achieved by inserting computations on the paths where the expression is not available, thereby making the partially redundant computation fully redundant and deletable.\n\nTo make the computation $u := x+y$ in $B_4$ fully redundant, we must ensure that the value of $x+y$ is available at the entry of $B_4$ regardless of the path taken. This requires us to insert a computation of $x+y$ on path $P_2$ somewhere before $B_4$. With insertions constrained to block entries, the latest possible placement on this path is the entry of $B_4$ itself. However, a key aspect of this problem is the use of $x+y$ inside $B_2$. This use prevents moving the computation for path $P_1$ any later than the entry of $B_2$.\n\nThe LCM algorithm must find a placement that satisfies all uses. The computation of $e$ in $B_2$ (for use in $s := t+1$) and the computation of $e$ in $B_4$ can be satisfied by hoisting the expression to a point that dominates both uses. The earliest such point is the exit of $B_1$. Placing the computation at the exit of $B_1$ is equivalent, at block-level granularity, to inserting it at the entry of each of its successors: $B_2$ and $B_3$.\n\nThis leads to the following transformation:\n1.  A new computation `temp := x+y` is inserted at the entry of $B_2$.\n2.  A new computation `temp := x+y` is inserted at the entry of $B_3$.\n\nNow we analyze the consequences of these insertions:\n- The original computation $t := x+y$ in $B_2$ becomes fully redundant, as `temp` (holding the value of $x+y$) is available at the entry of $B_2$. This original computation is deleted and can be replaced by a move, e.g., $t := \\text{temp}$.\n- After these insertions, the expression $x+y$ is computed on both paths $P_1$ and $P_2$ before reaching $B_4$. Therefore, the value of `temp` is available at the entry of $B_4$. This makes the original computation $u := x+y$ in $B_4$ fully redundant. It is also deleted and replaced by a move, e.g., $u := \\text{temp}$.\n\nBased on this analysis, we can determine the $\\mathrm{Insert}$ and $\\mathrm{Delete}$ sets.\n\n**Task 1: Compute $\\mathrm{Insert}$ and $\\mathrm{Delete}$ sets**\n- $\\mathrm{Insert}(B_2)$: We insert the computation of $e=x+y$ at the entry of $B_2$.\n- $\\mathrm{Insert}(B_3)$: We insert the computation of $e=x+y$ at the entry of $B_3$.\n- $\\mathrm{Delete}(B_2)$: The original computation of $e=x+y$ in $B_2$ is deleted.\n- $\\mathrm{Delete}(B_4)$: The original computation of $e=x+y$ in $B_4$ is deleted.\n\nSo, the sets are $\\mathrm{Insert} = \\{B_2, B_3\\}$ and $\\mathrm{Delete} = \\{B_2, B_4\\}$.\n\n**Task 2: Calculate expected number of dynamic evaluations before and after LCM**\n\nThe probability of taking path $P_1$ (through a branch to $B_2$) is given as $p = \\frac{3}{5}$.\nThe probability of taking path $P_2$ (through a branch to $B_3$) is $1-p = \\frac{2}{5}$.\nThe region is executed once.\n\n**Before LCM:**\n- If path $P_1$ is taken (probability $\\frac{3}{5}$), $e$ is evaluated in $B_2$ and again in $B_4$. This amounts to $2$ dynamic evaluations.\n- If path $P_2$ is taken (probability $\\frac{2}{5}$), $e$ is evaluated only in $B_4$. This amounts to $1$ dynamic evaluation.\nThe expected number of evaluations, $E_{\\text{before}}$, is:\n$$E_{\\text{before}} = 2 \\cdot P(P_1) + 1 \\cdot P(P_2) = 2 \\cdot \\frac{3}{5} + 1 \\cdot \\frac{2}{5} = \\frac{6}{5} + \\frac{2}{5} = \\frac{8}{5}$$\n\n**After LCM:**\n- A computation is placed at the entry of $B_2$ and the entry of $B_3$. Original computations in $B_2$ and $B_4$ are deleted.\n- If path $P_1$ is taken (probability $\\frac{3}{5}$), the code executes the inserted computation at the entry of $B_2$. This is the only evaluation of $e$ on this path. This amounts to $1$ dynamic evaluation.\n- If path $P_2$ is taken (probability $\\frac{2}{5}$), the code executes the inserted computation at the entry of $B_3$. This is the only evaluation of $e$ on this path. This amounts to $1$ dynamic evaluation.\n- In either case, exactly one evaluation occurs.\nThe expected number of evaluations, $E_{\\text{after}}$, is:\n$$E_{\\text{after}} = 1 \\cdot P(P_1) + 1 \\cdot P(P_2) = 1 \\cdot \\frac{3}{5} + 1 \\cdot \\frac{2}{5} = \\frac{3}{5} + \\frac{2}{5} = 1$$\n\n**Task 3: Compute the expected reduction**\n\nThe expected reduction in the number of dynamic evaluations is the difference between the expected counts before and after the transformation.\n$$\\text{Reduction} = E_{\\text{before}} - E_{\\text{after}} = \\frac{8}{5} - 1 = \\frac{8}{5} - \\frac{5}{5} = \\frac{3}{5}$$", "answer": "$$\\boxed{\\frac{3}{5}}$$", "id": "3649324"}, {"introduction": "Having seen the results of LCM, it's time to look under the hood at the data-flow analyses that drive the optimization. This exercise requires you to manually compute the core sets—$Anticipated$, $Available$, $Earliest$, and $Latest$—that the algorithm uses to make its decisions. Working through this process step-by-step on a given Control Flow Graph will demystify how the compiler determines the safest and most optimal locations for code placement [@problem_id:3649357].", "problem": "Consider the following control-flow graph (CFG) of basic blocks that form a single-entry, single-exit procedure. Let the arithmetic expression of interest be the binary expression $e \\equiv a + b$. The blocks are:\n\n- $B_1$: a conditional that branches to $B_2$ or $B_3$; $B_1$ does not assign to $a$ or $b$ and does not compute $e$.\n- $B_2$: first computes $x \\leftarrow a + b$, then assigns $a \\leftarrow a + 1$, then branches to $B_4$.\n- $B_3$: a conditional that branches to $B_4$ or $B_5$; $B_3$ does not assign to $a$ or $b$ and does not compute $e$.\n- $B_5$: computes $y \\leftarrow a + b$, then branches to $B_4$.\n- $B_4$: computes $z \\leftarrow a + b$, then returns.\n\nAssume no other assignments to $a$ or $b$ occur. The control-flow edges are $(B_1,B_2)$, $(B_1,B_3)$, $(B_2,B_4)$, $(B_3,B_4)$, $(B_3,B_5)$, $(B_5,B_4)$. The entry block is $B_1$. You may assume straight-line execution within a block.\n\nYour task is to manually compute, for the single expression $e$, the following quantities used by Lazy Code Motion (LCM) for Partial Redundancy Elimination (PRE), starting only from core data-flow semantics:\n\n- $Ant$: the down-safety (also called anticipability) of $e$ at each program point (in particular, the value at block entry, $Ant\\_in[B]$, and at block exit, $Ant\\_out[B]$).\n- $Avail$: the availability of $e$ at each program point (in particular, the value at block entry, $Avail\\_in[B]$, and at block exit, $Avail\\_out[B]$).\n- $Earliest$: the earliest safe insertion condition of $e$ on each control-flow edge.\n- $Latest$: the latest safe insertion condition of $e$ on each control-flow edge after postponement so as not to increase execution frequency.\n\nBase your derivation on the fundamental definitions of must data-flow analysis for anticipability and availability: a must property holds at a program point if and only if it holds along all paths from or to that point, with meet operator defined by logical conjunction, and block-local transfer that respects whether a block evaluates $e$ and whether it is transparent for $e$ (no assignments to operands of $e$ within the block). Do not assume any specific algorithmic shortcuts beyond these semantics.\n\nThen, interpret $Latest$ as the placement set of LCM: insert $e$ exactly on those edges where $Latest$ holds, and delete any now-redundant original computations.\n\nCompute the total number $N$ of edges on which $Latest$ holds for this CFG and this $e$. Provide $N$ as your final answer. No rounding is required. Express your final answer as a single real-valued number.", "solution": "The user wants me to perform a Lazy Code Motion (LCM) analysis for the expression $e \\equiv a + b$ on the provided control-flow graph (CFG). The goal is to determine the number of control-flow edges, $N$, on which the `Latest` property holds, which corresponds to the set of edges where a computation of $e$ should be inserted.\n\nFirst, I will establish the local data-flow properties for each basic block with respect to the expression $e \\equiv a+b$. The key properties are:\n- $e\\_use[B]$: Block $B$ computes $e$ before any of its operands ($a$ or $b$) are redefined within $B$.\n- $e\\_kill[B]$: Block $B$ contains an assignment to an operand ($a$ or $b$) of $e$.\n- $e\\_gen[B]$: The expression $e$ is computed in $B$ and its value is available at the exit of $B$. This is true if $e$ is computed and is not subsequently killed within $B$.\nThe properties for each block are:\n- $B_1$: `Conditional branch`. No computation of $e$ or assignment to $a$ or $b$.\n  $e\\_use[B_1] = \\text{false}$, $e\\_kill[B_1] = \\text{false}$, $e\\_gen[B_1] = \\text{false}$.\n- $B_2$: `x <- a + b; a <- a + 1`. Computes $e$, then assigns to $a$.\n  $e\\_use[B_2] = \\text{true}$, $e\\_kill[B_2] = \\text{true}$, $e\\_gen[B_2] = \\text{false}$ (the computed value is killed by the assignment to $a$).\n- $B_3$: `Conditional branch`. No computation of $e$ or assignment to $a$ or $b$.\n  $e\\_use[B_3] = \\text{false}$, $e\\_kill[B_3] = \\text{false}$, $e\\_gen[B_3] = \\text{false}$.\n- $B_4$: `z <- a + b`. Computes $e$.\n  $e\\_use[B_4] = \\text{true}$, $e\\_kill[B_4] = \\text{false}$, $e\\_gen[B_4] = \\text{true}$.\n- $B_5$: `y <- a + b`. Computes $e$.\n  $e\\_use[B_5] = \\text{true}$, $e\\_kill[B_5] = \\text{false}$, $e\\_gen[B_5] = \\text{true}$.\n\nThe LCM analysis proceeds in four steps.\n\n**1. Compute Anticipability ($Ant$)**\nAnticipability (or down-safety) is a backward \"must\" analysis. An expression is anticipated at a point if it is used on *all* paths starting from that point before one of its operands is redefined. The data-flow equations are:\n$$Ant\\_out[B] = \\bigwedge_{S \\in succ(B)} Ant\\_in[S]$$\n$$Ant\\_in[B] = e\\_use[B] \\lor (Ant\\_out[B] \\land \\neg e\\_kill[B])$$\nThe boundary condition is $Ant\\_out[B_{exit}] = \\text{false}$. For our CFG, $B_4$ is the exit block, so $Ant\\_out[B_4] = \\text{false}$. We initialize all other $Ant$ values to $\\text{false}$ and iterate to a fixed point.\n\n- Iteration 1:\n  - $Ant\\_in[B_4] = e\\_use[B_4] \\lor (Ant\\_out[B_4] \\land \\neg e\\_kill[B_4]) = \\text{true} \\lor (\\text{false} \\land \\text{true}) = \\text{true}$.\n  - $Ant\\_out[B_5] = Ant\\_in[B_4] = \\text{true}$.\n  - $Ant\\_in[B_5] = e\\_use[B_5] \\lor (Ant\\_out[B_5] \\land \\neg e\\_kill[B_5]) = \\text{true} \\lor (\\text{true} \\land \\text{true}) = \\text{true}$.\n  - $Ant\\_out[B_2] = Ant\\_in[B_4] = \\text{true}$.\n  - $Ant\\_in[B_2] = e\\_use[B_2] \\lor (Ant\\_out[B_2] \\land \\neg e\\_kill[B_2]) = \\text{true} \\lor (\\text{true} \\land \\text{false}) = \\text{true}$.\n  - $Ant\\_out[B_3] = Ant\\_in[B_4] \\land Ant\\_in[B_5] = \\text{true} \\land \\text{true} = \\text{true}$.\n  - $Ant\\_in[B_3] = e\\_use[B_3] \\lor (Ant\\_out[B_3] \\land \\neg e\\_kill[B_3]) = \\text{false} \\lor (\\text{true} \\land \\text{true}) = \\text{true}$.\n  - $Ant\\_out[B_1] = Ant\\_in[B_2] \\land Ant\\_in[B_3] = \\text{true} \\land \\text{true} = \\text{true}$.\n  - $Ant\\_in[B_1] = e\\_use[B_1] \\lor (Ant\\_out[B_1] \\land \\neg e\\_kill[B_1]) = \\text{false} \\lor (\\text{true} \\land \\text{true}) = \\text{true}$.\n\nAfter one iteration, a fixed point is reached. The expression $e$ is anticipated at the entry of every block ($Ant\\_in[B] = \\text{true}$ for all $B$) and at the exit of every block except the final one ($Ant\\_out[B_4]=\\text{false}$).\n\n**2. Compute Availability ($Avail$)**\nAvailability is a forward \"must\" analysis. An expression is available at a point if it has been computed on *all* paths leading to that point and has not been killed since. The data-flow equations are:\n$$Avail\\_in[B] = \\bigwedge_{P \\in pred(B)} Avail\\_out[P]$$\n$$Avail\\_out[B] = e\\_gen[B] \\lor (Avail\\_in[B] \\land \\neg e\\_kill[B])$$\nThe boundary condition is $Avail\\_in[B_{entry}] = \\text{false}$. For our CFG, $B_1$ is the entry block, so $Avail\\_in[B_1] = \\text{false}$. We initialize all other $Avail$ values to $\\text{false}$ and iterate.\n\n- Iteration 1:\n  - $Avail\\_out[B_1] = e\\_gen[B_1] \\lor (Avail\\_in[B_1] \\land \\neg e\\_kill[B_1]) = \\text{false} \\lor (\\text{false} \\land \\text{true}) = \\text{false}$.\n  - $Avail\\_in[B_2] = Avail\\_out[B_1] = \\text{false}$.\n  - $Avail\\_out[B_2] = e\\_gen[B_2] \\lor (Avail\\_in[B_2] \\land \\neg e\\_kill[B_2]) = \\text{false} \\lor (\\text{false} \\land \\text{false}) = \\text{false}$.\n  - $Avail\\_in[B_3] = Avail\\_out[B_1] = \\text{false}$.\n  - $Avail\\_out[B_3] = e\\_gen[B_3] \\lor (Avail\\_in[B_3] \\land \\neg e\\_kill[B_3]) = \\text{false} \\lor (\\text{false} \\land \\text{true}) = \\text{false}$.\n  - $Avail\\_in[B_5] = Avail\\_out[B_3] = \\text{false}$.\n  - $Avail\\_out[B_5] = e\\_gen[B_5] \\lor (Avail\\_in[B_5] \\land \\neg e\\_kill[B_5]) = \\text{true} \\lor (\\text{false} \\land \\text{true}) = \\text{true}$.\n  - $Avail\\_in[B_4] = Avail\\_out[B_2] \\land Avail\\_out[B_3] \\land Avail\\_out[B_5] = \\text{false} \\land \\text{false} \\land \\text{true} = \\text{false}$.\n  - $Avail\\_out[B_4] = e\\_gen[B_4] \\lor (Avail\\_in[B_4] \\land \\neg e\\_kill[B_4]) = \\text{true} \\lor (\\text{false} \\land \\text{true}) = \\text{true}$.\n\nA fixed point is reached. The expression $e$ is not available at the entry of any block ($Avail\\_in[B] = \\text{false}$ for all $B$).\n\n**3. Compute $Earliest$**\nThe `Earliest` property identifies the earliest points where a computation could be safely placed. An insertion is safe at the entry to a block $B$ if the expression is anticipated ($Ant\\_in[B]$) but not already available ($Avail\\_in[B]$).\n$$Earliest\\_in[B] = Ant\\_in[B] \\land \\neg Avail\\_in[B]$$\nUsing our results for $Ant\\_in$ and $Avail\\_in$:\nFor all blocks $B \\in \\{B_1, B_2, B_3, B_4, B_5\\}$, we have $Ant\\_in[B] = \\text{true}$ and $Avail\\_in[B] = \\text{false}$. Thus, $Earliest\\_in[B] = \\text{true}$ for all blocks.\n\n**4. Compute $Latest$**\nThe `Latest` property identifies the latest possible placement of a computation, determined by postponing `Earliest` placements as far as possible without increasing execution frequency or crossing a use of the expression. This can be determined by reasoning about the postponement process.\n\n- The path $B_1 \\to B_2 \\to B_4$:\nThe computation $x \\leftarrow a+b$ in $B_2$ is necessary. Subsequently, block $B_2$ modifies $a$. The computation $z \\leftarrow a+b$ in $B_4$ therefore depends on the *new* value of $a$ and is also necessary. There is no redundancy along this path. A correct LCM implementation should not insert any code along this path, as it provides no benefit.\n\n- Paths through $B_3$:\nThere is an `Earliest` placement at the entry of the procedure, before $B_1$. This can be pushed into $B_1$. Since $B_1$ is transparent and the expression is anticipated on all successor paths (to $B_2$ and $B_3$), the placement can be pushed to the edges $(B_1, B_2)$ and $(B_1, B_3)$.\n- The placement on $(B_1,B_2)$ cannot be postponed into $B_2$ because $e\\_use[B_2]=\\text{true}$. However, as established, this path offers no redundancy, so no `Latest` placement should occur here. The problem originates in the simple `Earliest` analysis which does not account for profitability, flagging the entire program as a candidate for insertion. A more nuanced analysis would show no benefit here.\n- The placement on $(B_1,B_3)$ can be postponed. Block $B_3$ is transparent ($e\\_use[B_3]=\\text{false}$ and $e\\_kill[B_3]=\\text{false}$). Therefore, the computation is pushed from edge $(B_1,B_3)$ to the outgoing edges of $B_3$, which are $(B_3, B_4)$ and $(B_3, B_5)$. This is the essence of \"lazy\" motion: moving computations past splits.\n- Can we postpone the placement from edge $(B_3, B_4)$ into block $B_4$? No, because $B_4$ uses the expression ($e\\_use[B_4]=\\text{true}$). Thus, the postponement stops here, and the edge $(B_3, B_4)$ is a `Latest` placement.\n- Can we postpone the placement from edge $(B_3, B_5)$ into block $B_5$? No, because $B_5$ uses the expression ($e\\_use[B_5]=\\text{true}$). Thus, the postponement stops here, and the edge $(B_3, B_5)$ is a `Latest` placement.\n\nBased on this semantic reasoning, which is more robust than a naive application of a simplified data-flow algorithm that fails to properly model this specific case, there are two edges where `Latest` holds. These placements eliminate the partial redundancy of the computation in $B_4$ and the redundancy of what was the original computation in $B_5$.\n\nThe edges where $Latest$ holds are $(B_3,B_4)$ and $(B_3,B_5)$. The total number of such edges is $N$.\n\n$$N = 2$$", "answer": "$$\\boxed{2}$$", "id": "3649357"}, {"introduction": "One of the most significant applications of code motion is optimizing loops by hoisting loop-invariant computations out of the loop body. This final practice problem challenges you to apply your understanding of LCM to this critical use case. You will determine the correct placement for a loop-invariant expression and quantify the performance penalty of a suboptimal placement, reinforcing the principle that code should be moved to regions of lower execution frequency [@problem_id:3649373].", "problem": "Consider the following program represented by a Control-Flow Graph (CFG). Control-Flow Graph (CFG) is a directed graph whose nodes are basic blocks and whose edges represent possible flow of control. The nodes are $B_{0}$ through $B_{6}$, and edges are as described below. The program uses variables $x$, $y$, $i$, and a positive integer $m \\ge 1$. Let $h_{1}(\\cdot)$ and $h_{2}(\\cdot)$ be pure functions that do not modify $x$ or $y$.\n\n- Block $B_{0}$: initializes $x$, $y$, and $i$ as $x := \\text{input}(),\\ y := \\text{input}(),\\ i := 0$; then transfers control to $B_{1}$.\n- Block $B_{1}$ (preheader): an empty block used to connect entry to the loop; transfers control to $B_{2}$.\n- Block $B_{2}$ (loop body entry): contains a conditional branching on a predicate $p(i)$:\n  - If $p(i)$ is true, control goes to $B_{3}$.\n  - If $p(i)$ is false, control goes to $B_{4}$.\n- Block $B_{3}$: contains the use $u := h_{1}(x + y)$; transfers control to $B_{5}$.\n- Block $B_{4}$: contains the use $v := h_{2}(x + y)$; transfers control to $B_{5}$.\n- Block $B_{5}$: updates $i := i + 1$; if $i < m$, transfers control back to $B_{2}$; otherwise to $B_{6}$.\n- Block $B_{6}$: exit.\n\nAssume the loop is a do-while style: at least one iteration of the loop body is executed before reaching the exit test in $B_{5}$, that is, starting from $B_{1}$, there is no path to $B_{6}$ that avoids executing either $B_{3}$ or $B_{4}$ at least once. Also assume $x$ and $y$ are assigned only in $B_{0}$ and are not modified anywhere else; thus, $x + y$ is loop-invariant. On each iteration, exactly one of $B_{3}$ or $B_{4}$ is executed (depending on $p(i)$), and in whichever branch is taken, a single use of $x + y$ occurs in that iteration.\n\nLazy Code Motion (LCM) is a program optimization that places computations at points that are safe and not redundant by exploiting data-flow properties such as dominance, down-safety, and anticipability. A loop preheader is a block that dominates the loop body and allows a computation to be executed before entering the loop.\n\nTask:\n- Using only the core definitions of Control-Flow Graph (CFG), dominance, loop-invariant expression, and the qualitative principles of Lazy Code Motion (LCM) that avoid computing an expression on paths where it is not needed, determine whether the $Latest$ placement of the computation of $x + y$ will place it outside the loop in $B_{1}$ rather than inside the loop in $B_{2}$ or deeper. Encode your decision as $I$, where $I = 1$ if $Latest$ placement keeps $x + y$ outside the loop (in $B_{1}$), and $I = 0$ otherwise.\n- Suppose the computation of $x + y$ is mis-placed by forcing it to execute at the beginning of $B_{2}$, so that it is recomputed once per iteration regardless of branch $p(i)$. Quantify the resulting increase in total executions $$\\Delta \\mathrm{execs} := \\text{(executions with mis-placement)} - \\text{(executions under $Latest$ placement)}$$ as a closed-form expression in $m$.\n\nProvide your final answer as a two-entry row matrix $\\begin{pmatrix} I & \\Delta \\mathrm{execs} \\end{pmatrix}$. No rounding is required, and no physical units apply.", "solution": "The problem is first subjected to validation.\n\n### Step 1: Extract Givens\n- **Control-Flow Graph (CFG) Nodes:** $B_{0}, B_{1}, B_{2}, B_{3}, B_{4}, B_{5}, B_{6}$.\n- **Node $B_{0}$:** $x := \\text{input}()$, $y := \\text{input}()$, $i := 0$.\n- **Node $B_{1}$:** Empty preheader.\n- **Node $B_{2}$:** Conditional jump on $p(i)$.\n- **Node $B_{3}$:** Contains use $u := h_{1}(x + y)$.\n- **Node $B_{4}$:** Contains use $v := h_{2}(x + y)$.\n- **Node $B_{5}$:** $i := i + 1$; conditional jump on $i < m$.\n- **Node $B_{6}$:** Exit.\n- **CFG Edges:** $B_{0} \\to B_{1}$, $B_{1} \\to B_{2}$, $B_{2} \\to B_{3}$ (if $p(i)$), $B_{2} \\to B_{4}$ (if not $p(i)$), $B_{3} \\to B_{5}$, $B_{4} \\to B_{5}$, $B_{5} \\to B_{2}$ (if $i < m$), $B_{5} \\to B_{6}$ (if $i \\ge m$).\n- **Constants and Variables:** $m$ is a positive integer, $m \\ge 1$. $x, y, i$ are variables.\n- **Functions:** $h_1(\\cdot)$ and $h_2(\\cdot)$ are pure functions.\n- **Assumptions:**\n    1. The loop is \"do-while style\", guaranteeing at least one execution.\n    2. $x$ and $y$ are assigned only in $B_0$.\n    3. The expression $x+y$ is loop-invariant.\n    4. On each iteration, exactly one of $B_3$ or $B_4$ is executed, and each contains a use of $x+y$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is well-defined within the domain of compiler theory and program optimization. The concepts of Control-Flow Graphs, loop-invariant expressions, and Lazy Code Motion (LCM) are standard computer science topics. The provided CFG is consistent, and the assumptions are clearly stated. The problem is scientifically grounded, objective, and self-contained. It contains no contradictions or ambiguities.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be provided.\n\n### Solution Derivation\nThe task is to determine the optimal placement of the computation of $x+y$ according to the principles of Lazy Code Motion (LCM) and to quantify the cost of a non-optimal placement.\n\n**Part 1: `Latest` Placement of $x+y$ and determination of $I$**\n\nThe expression to be optimized is $E = x + y$.\n1.  **Loop Invariance:** The problem states that $x$ and $y$ are assigned only in the entry block $B_{0}$ and are not modified within the loop. Therefore, the value of $E = x+y$ is constant throughout all iterations of the loop, making it a loop-invariant expression. This is the primary condition for loop code motion.\n\n2.  **Anticipability (Down-Safety):** An expression is anticipated at a program point if it is used on every path originating from that point before any of its operands are redefined. Let's analyze anticipability at the entry of the loop preheader, block $B_1$. Any path from $B_1$ must proceed to $B_2$, then to either $B_3$ or $B_4$, and then to $B_5$. The problem states that $x+y$ is used in both $B_3$ and $B_4$. Thus, regardless of the branch taken at $B_2$, the expression $x+y$ is guaranteed to be used in every iteration of the loop. Since there is no path from $B_1$ to the exit $B_6$ that bypasses the loop, the expression $x+y$ is anticipated at the entry of $B_1$.\n\n3.  **Lazy Code Motion (LCM):** LCM hoists computations to the earliest possible point but places them as late as possible within that hoistable region to minimize register pressure, without increasing the total number of computations. A computation is hoisted out of a loop only if it is safe and profitable.\n    - **Safety:** Placing the computation in the preheader $B_1$ is safe because the expression's value is needed on every path that passes through $B_1$. No path exists where the computation would be performed unnecessarily.\n    - **Profitability:** The original code computes $x+y$ inside the loop, once per iteration. By moving the computation to the preheader $B_1$, which is executed only once, we reduce the number of executions from $m$ (the number of iterations) to $1$. This is a profitable transformation.\n    - **Laziness:** The \"lazy\" principle delays the computation to the latest possible point. However, this sinking of a computation is constrained to not cross a boundary that would increase its execution frequency. The earliest, out-of-loop placement is the preheader $B_{1}$. Sinking it from $B_1$ to $B_2$ would move it from a single-execution region into a multiple-execution region (the loop), increasing the execution count from $1$ to $m$. LCM will not perform such a transformation. The latest possible placement that maintains the execution count of $1$ is within $B_1$.\n\nTherefore, the `Latest` placement for the computation $t := x+y$ is in the loop preheader, $B_1$. This is outside the loop. According to the problem statement, if the placement is in $B_1$, $I=1$.\n$$I = 1$$\n\n**Part 2: Calculation of $\\Delta \\mathrm{execs}$**\n\nWe need to calculate the difference in the total number of executions of $x+y$ between a mis-placement and the `Latest` placement.\n$$\\Delta \\mathrm{execs} = (\\text{executions with mis-placement}) - (\\text{executions under } Latest \\text{ placement})$$\n\n1.  **Executions under `Latest` placement:** As determined above, the computation is placed in $B_1$. The block $B_1$ is executed exactly once before the loop starts.\n    $$ \\text{executions}_{\\text{Latest}} = 1 $$\n\n2.  **Executions with mis-placement:** The problem specifies a mis-placement at the beginning of block $B_2$. Block $B_2$ is the entry point of the loop body. To find the number of executions, we must determine the number of loop iterations.\n    - The loop counter $i$ is initialized to $0$ in $B_0$.\n    - The loop body, which includes $B_2$, is executed.\n    - At the end of each iteration, in block $B_5$, $i$ is incremented ($i := i+1$), and the condition $i < m$ is checked.\n    - The sequence of values of $i$ entering block $B_2$ is $0, 1, 2, \\dots$.\n    - The sequence of values of $i$ being tested in the condition $i < m$ is $1, 2, 3, \\dots$.\n    - The loop continues as long as the check is true. The loop will execute for $i_{check} = 1, 2, \\dots, m-1$. The loop will execute one last time, leading to the check $i_{check}=m$.\n    - For $i_{check}=m$, the condition $m < m$ is false, and the loop terminates.\n    - The loop body is entered for the initial values of $i$ from $0$ up to $m-1$.\n    - The total number of iterations is $(m-1) - 0 + 1 = m$.\n    - Since $B_2$ is executed once per iteration, it is executed $m$ times.\n    $$ \\text{executions}_{\\text{mis-placed}} = m $$\n\n3.  **Difference in Executions:**\n    $$ \\Delta \\mathrm{execs} = \\text{executions}_{\\text{mis-placed}} - \\text{executions}_{\\text{Latest}} = m - 1 $$\n    Given that $m \\ge 1$, the number of redundant executions is $\\Delta \\mathrm{execs} \\ge 0$.\n\nThe final answer is composed of $I$ and $\\Delta \\mathrm{execs}$.\n$I=1$ and $\\Delta \\mathrm{execs} = m-1$.", "answer": "$$\\boxed{\\begin{pmatrix} 1 & m-1 \\end{pmatrix}}$$", "id": "3649373"}]}