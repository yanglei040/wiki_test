{"hands_on_practices": [{"introduction": "Any compiler optimization must first and foremost preserve the original program's meaning. This exercise [@problem_id:3654403] challenges you to apply loop unswitching correctly in the presence of complex control flow. By analyzing how `continue` statements alter the execution path, you'll practice ensuring the transformed code is semantically equivalent to the original.", "problem": "Consider the following loop in an imperative language with C-like control-flow semantics. The condition on the branch is loop-invariant, meaning it does not change across iterations of the loop, and there are no abnormal exits (no exceptions or non-local gotos). The semantics of a continue statement are as follows: when encountered inside a loop, execution immediately proceeds to the loop’s update expression and then to the loop header test for the next iteration.\n\nOriginal loop:\nfor (int $i$ = $0$; $i$  $N$; ++$i$) {\n  if ($flag$) {\n    if ($A(i)$) { $logA(i)$; continue; }\n    $S_1(i)$;\n  } else {\n    if ($B(i)$) { $logB(i)$; continue; }\n    $S_2(i)$;\n  }\n  $S_3(i)$;\n  $T(i)$;\n}\n\nAssume the following:\n- The boolean $flag$ is loop-invariant: it is not modified within the loop, so its value is identical for every iteration $i$.\n- The functions and statements $A(i)$, $B(i)$, $logA(i)$, $logB(i)$, $S_1(i)$, $S_2(i)$, $S_3(i)$, and $T(i)$ may have side effects but do not alter $i$, $N$, or $flag$, and do not cause abnormal control flow.\n- The only early exits from the loop body are via the shown continue statements.\n- There are no data dependences that would be violated by duplicating the loop body (e.g., no writes to shared loop-invariant state that would be incorrectly duplicated by unswitching).\n\nLoop unswitching is a transformation that hoists a loop-invariant conditional out of a loop by duplicating the loop and placing a specialized version under each outcome of the invariant condition. The transformation must preserve the per-iteration control-flow and side-effect ordering implied by continues. Which of the following transformed programs correctly applies loop unswitching to preserve the original semantics for all $N$ and both values of $flag$?\n\nA)\nif ($flag$) {\n  for (int $i$ = $0$; $i$  $N$; ++$i$) {\n    if ($A(i)$) { $logA(i)$; continue; }\n    $S_1(i)$;\n    $S_3(i)$;\n    $T(i)$;\n  }\n} else {\n  for (int $i$ = $0$; $i$  $N$; ++$i$) {\n    if ($B(i)$) { $logB(i)$; continue; }\n    $S_2(i)$;\n    $S_3(i)$;\n    $T(i)$;\n  }\n}\n\nB)\nif ($flag$) {\n  for (int $i$ = $0$; $i$  $N$; ++$i$) {\n    $S_3(i)$;\n    $T(i)$;\n    if ($A(i)$) { $logA(i)$; continue; }\n    $S_1(i)$;\n  }\n} else {\n  for (int $i$ = $0$; $i$  $N$; ++$i$) {\n    $S_3(i)$;\n    $T(i)$;\n    if ($B(i)$) { $logB(i)$; continue; }\n    $S_2(i)$;\n  }\n}\n\nC)\nfor (int $i$ = $0$; $i$  $N$; ++$i$) {\n  if ($flag$) {\n    if ($A(i)$) { $logA(i)$; }  // continue removed\n    $S_1(i)$;\n  } else {\n    if ($B(i)$) { $logB(i)$; }  // continue removed\n    $S_2(i)$;\n  }\n  $S_3(i)$;\n  $T(i)$;\n}\n\nD)\nif ($flag$) {\n  for (int $i$ = $0$; $i$  $N$; ++$i$) {\n    if ($A(i)$) { $logA(i)$; continue; }\n    $S_1(i)$;\n  }\n} else {\n  for (int $i$ = $0$; $i$  $N$; ++$i$) {\n    if ($B(i)$) { $logB(i)$; continue; }\n    $S_2(i)$;\n  }\n}\n// $S_3(i)$ and $T(i)$ executed outside the unswitched loops (missing per-iteration placement)\n\nSelect the option that preserves the original per-iteration semantics under loop unswitching, including correct handling of continue-caused early exits and side-effect ordering.", "solution": "The user has provided a problem concerning the compiler optimization known as loop unswitching. The task is to validate the problem statement and, if valid, determine which of the proposed code transformations correctly preserves the semantics of the original loop.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\nThe problem provides the following:\n- **Original Loop Code:**\n  ```c\n  for (int $i$ = $0$; $i$  $N$; ++$i$) {\n    if ($flag$) {\n      if ($A(i)$) { $logA(i)$; continue; }\n      $S_1(i)$;\n    } else {\n      if ($B(i)$) { $logB(i)$; continue; }\n      $S_2(i)$;\n    }\n    $S_3(i)$;\n    $T(i)$;\n  }\n  ```\n- **Control-Flow Semantics:**\n    - The language is C-like.\n    - `continue` causes execution to jump to the loop update (`++$i$`) and then the loop test (`$i$  $N$`), skipping the remainder of the loop body for the current iteration.\n- **Assumptions:**\n    - The boolean variable `$flag$` is loop-invariant (its value is constant throughout the loop's execution).\n    - Functions and statements `$A(i)$, $B(i)$, $logA(i)$, $logB(i)$, $S_1(i)$, $S_2(i)$, $S_3(i)$, $T(i)$` may have side effects but do not modify `$i$`, `$N$`, or `$flag$`.\n    - No abnormal control flow (e.g., exceptions, `goto`) other than the specified `continue` statements.\n    - No data dependences are violated by loop duplication.\n- **Core Task:**\n    - Loop unswitching is defined as hoisting a loop-invariant conditional out of a loop by duplicating the loop.\n    - The correct transformation must preserve the per-iteration control-flow and side-effect ordering.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem statement is evaluated against the validation criteria.\n- **Scientifically Grounded:** The problem is set in the context of compiler optimizations, a standard topic in computer science. Loop unswitching is a well-established technique. The C-like semantics are precisely defined. The problem is scientifically and factually sound.\n- **Well-Posed:** The problem asks to identify which transformation among a set of options is semantically equivalent to the original code. This is a well-defined question with a unique correct answer based on logical analysis of program control flow.\n- **Objective:** The problem is stated in terms of code and explicit semantic rules. The correctness criterion—preservation of semantics—is objective and verifiable.\n- **Completeness and Consistency:** The problem provides all necessary information: the original code, the rules of execution (`continue` semantics), and key assumptions (loop-invariance of `$flag$`, absence of certain side effects). The setup is self-contained and free of contradictions.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. It is a well-formed problem in the domain of compiler principles. The solution process can proceed.\n\n### Derivation and Option Analysis\n\nThe fundamental task is to trace the execution path for a single iteration of the original loop and ensure the transformed code replicates it exactly.\n\n**Analysis of the Original Loop**\n\nLet's analyze the sequence of operations for an arbitrary iteration `$i$`.\n1. The loop-invariant conditional `if ($flag$)` is evaluated.\n2. **Case `$flag$ is true`:**\n   - The condition `$A(i)$` is evaluated.\n   - If `$A(i)$` is true, `$logA(i)$` is executed, and the `continue` statement is triggered. This immediately skips the execution of `$S_1(i)$, $S_3(i)$, and $T(i)$`. The loop proceeds to the next iteration (`++$i$`).\n   - If `$A(i)$` is false, `$S_1(i)$` is executed, followed by `$S_3(i)$` and `$T(i)$`. The loop then proceeds to the next iteration.\n    *Summary for `$flag$ is true`:\n      - Path 1: `$A(i)$ true $\\implies$ execute `$logA(i)$`.\n      - Path 2: `$A(i)$ false $\\implies$ execute `$S_1(i), S_3(i), T(i)$`.\n3. **Case `$flag$ is false`:**\n   - The condition `$B(i)$` is evaluated.\n   - If `$B(i)$` is true, `$logB(i)$` is executed, and the `continue` statement is triggered. This immediately skips the execution of `$S_2(i)$, $S_3(i)$, and $T(i)$`. The loop proceeds to the next iteration.\n   - If `$B(i)$` is false, `$S_2(i)$` is executed, followed by `$S_3(i)$` and `$T(i)$`. The loop then proceeds to the next iteration.\n    *Summary for `$flag$ is false`:\n      - Path 1: `$B(i)$ true $\\implies$ execute `$logB(i)$`.\n      - Path 2: `$B(i)$ false $\\implies$ execute `$S_2(i), S_3(i), T(i)$`.\n\n**Loop Unswitching Transformation**\n\nThe transformation moves the `if ($flag$)` outside the loop, creating two specialized loops.\n\n- **The `if` branch (for `$flag$ is true`):** The loop body should contain only the code that executes when `$flag$` is true. Based on our analysis, this is:\n  ```c\n  if ($A(i)$) { $logA(i)$; continue; }\n  $S_1(i)$;\n  $S_3(i)$;\n  $T(i)$;\n  ```\n  This is because `$S_3(i)$` and `$T(i)$` are common to all paths that do not `continue`.\n\n- **The `else` branch (for `$flag$ is false`):** The loop body should contain only the code that executes when `$flag$` is false. Based on our analysis, this is:\n  ```c\n  if ($B(i)$) { $logB(i)$; continue; }\n  $S_2(i)$;\n  $S_3(i)$;\n  $T(i)$;\n  ```\n\nCombining these into the unswitched structure gives the following correct transformation:\n```c\nif ($flag$) {\n  for (int $i$ = $0$; $i$  $N$; ++$i$) {\n    if ($A(i)$) { $logA(i)$; continue; }\n    $S_1(i)$;\n    $S_3(i)$;\n    $T(i)$;\n  }\n} else {\n  for (int $i$ = $0$; $i$  $N$; ++$i$) {\n    if ($B(i)$) { $logB(i)$; continue; }\n    $S_2(i)$;\n    $S_3(i)$;\n    $T(i)$;\n  }\n}\n```\n\nNow, we evaluate each provided option against this derived correct transformation.\n\n**Option-by-Option Analysis**\n\n**A)**\n```c\nif ($flag$) {\n  for (int $i$ = $0$; $i$  $N$; ++$i$) {\n    if ($A(i)$) { $logA(i)$; continue; }\n    $S_1(i)$;\n    $S_3(i)$;\n    $T(i)$;\n  }\n} else {\n  for (int $i$ = $0$; $i$  $N$; ++$i$) {\n    if ($B(i)$) { $logB(i)$; continue; }\n    $S_2(i)$;\n    $S_3(i)$;\n    $T(i)$;\n  }\n}\n```\nThis code exactly matches the transformation derived from first principles. For the `$flag$` true case, it correctly executes `$logA(i)$` and skips the rest if `$A(i)$` is true, or executes `$S_1(i), S_3(i), T(i)$` otherwise. It does the same for the `$flag$` false case with `$B(i)$` and `$S_2(i)`. The control flow and side-effect ordering are preserved for all cases.\n**Verdict: Correct.**\n\n**B)**\n```c\nif ($flag$) {\n  for (int $i$ = $0$; $i$  $N$; ++$i$) {\n    $S_3(i)$;\n    $T(i)$;\n    if ($A(i)$) { $logA(i)$; continue; }\n    $S_1(i)$;\n  }\n} // ... and similar for the else branch\n```\nThis transformation incorrectly reorders the statements. In the original loop, if `$flag$` is true and `$A(i)$` is true, `$S_3(i)$` and `$T(i)$` are *not* executed. In this transformed code, `$S_3(i)$` and `$T(i)$` are executed unconditionally at the beginning of every iteration. This violates the original program's semantics.\n**Verdict: Incorrect.**\n\n**C)**\n```c\nfor (int $i$ = $0$; $i$  $N$; ++$i$) {\n  if ($flag$) {\n    if ($A(i)$) { $logA(i)$; }  // continue removed\n    $S_1(i)$;\n  } // ... and similar for the else branch\n  $S_3(i)$;\n  $T(i)$;\n}\n```\nThis is not loop unswitching; it is a modification of the original loop where the `continue` statements are removed. In the original loop, if `$flag$` is true and `$A(i)$` is true, the `continue` prevents `$S_1(i)$, $S_3(i)$, and $T(i)$` from executing. In this modified code, all of these statements are executed regardless of the value of `$A(i)$`. This alters the control flow significantly.\n**Verdict: Incorrect.**\n\n**D)**\n```c\nif ($flag$) {\n  for (int $i$ = $0$; $i$  $N$; ++$i$) {\n    if ($A(i)$) { $logA(i)$; continue; }\n    $S_1(i)$;\n  }\n} else {\n  for (int $i$ = $0$; $i$  $N$; ++$i$) {\n    if ($B(i)$) { $logB(i)$; continue; }\n    $S_2(i)$;\n  }\n}\n// S_3(i) and T(i) executed outside the unswitched loops...\n```\nThis transformation omits the statements `$S_3(i)$` and `$T(i)$` from inside the duplicated loops. In the original code, `$S_3(i)$` and `$T(i)$` are executed in every iteration that does not hit a `continue`. By removing them from the loop bodies, this transformation fails to preserve the original program's behavior and side effects.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{A}$$", "id": "3654403"}, {"introduction": "Beyond ensuring correctness, the primary goal of optimizations like loop unswitching is to boost performance by improving how the code interacts with hardware. This practice problem [@problem_id:3654402] demonstrates how unswitching can dramatically improve memory access patterns and reduce cache misses. You will quantitatively analyze the difference in cache performance between a sequential and a strided memory access pattern, a fundamental concept in high-performance computing.", "problem": "Consider square matrices $A$, $B$, and $C$ of dimension $n \\times n$, stored in contiguous row-major layout in main memory, with each element occupying $w$ bytes. The computation to be performed is the matrix product accumulation defined by the triply nested loop order $(i,k,j)$: for each fixed $i$, for each $k$, read a scalar from $A$ according to a loop-invariant flag $t$ indicating whether $A$ was pre-transposed, and then update all entries in the $i$-th row of $C$ using the entire $k$-th row of $B$. Concretely, for each pair $(i,k)$, the code reads either $A[i][k]$ when $t$ is false (not transposed) or $A[k][i]$ when $t$ is true (transposed), binds this value to a scalar that is then reused across the inner loop over $j$, and accumulates $C[i][j] \\leftarrow C[i][j] + a \\cdot B[k][j]$ for all $j$ in $\\{0,1,\\dots,n-1\\}$.\n\nThe branch on $t$ is loop-invariant with respect to the $i$, $k$, and $j$ loops. Apply the transformation known as loop unswitching to produce two specialized versions of the computation: one for the $t=\\text{false}$ case and one for the $t=\\text{true}$ case. Use the following cache model and assumptions to estimate the cache behavior attributable solely to reads of $A$:\n\n- The processor has a Level-1 (L1) cache that is fully associative with Least Recently Used (LRU) replacement, and a cache line size of $L$ bytes.\n- Let $p = \\frac{L}{w}$ denote the number of matrix elements that fit in one cache line; assume $p$ is a positive integer and that $n$ is an exact multiple of $p$.\n- Each $A$ element read for a given $(i,k)$ is reused across the entire inner loop over $j$ without additional $A$ loads, but reuse of $A$ lines across different $(i,k)$ pairs is negligible due to streaming accesses in $B$ and updates to $C$. Therefore, count one cache line fill the first time any element from a line of $A$ is accessed within a given outer-loop iteration $i$, and do not count further cross-iteration reuse.\n- Do not include any cache behavior from $B$ or $C$; only count cache line fills caused by accesses to $A$.\n\nStarting from definitions of row-major addressing and basic properties of loop unswitching, derive the total number of L1 cache line fills caused by reads from $A$ across the entire computation in each specialized version ($t=\\text{false}$ and $t=\\text{true}$), and then provide a single closed-form analytical expression for the difference between these totals, defined as \n$$\\Delta = \\text{fills}_{t=\\text{true}} - \\text{fills}_{t=\\text{false}}.$$\n\nExpress your final answer in terms of $n$ and $p$. No numerical evaluation is required; provide the exact analytic expression.", "solution": "The problem as stated is valid. It is scientifically grounded in the principles of computer architecture and compiler optimization, specifically cache behavior analysis and loop transformations. The problem is well-posed, with all necessary parameters ($n$, $p$), a clear computational model, and a defined objective. The language is objective and the assumptions, while simplifying, are explicit and consistent.\n\nThe core task is to analyze the number of cache line fills for accesses to a matrix $A$ in two different scenarios resulting from loop unswitching. Loop unswitching is a compiler optimization that moves a loop-invariant conditional branch outside of a loop, duplicating the loop body inside each path of the branch.\n\nThe original loop structure is:\n`for i = 0 to n-1:`\n  `for k = 0 to n-1:`\n    `if t:`\n      `a = A[k][i]`\n    `else:`\n      `a = A[i][k]`\n    `for j = 0 to n-1:`\n      `C[i][j] += a * B[k][j]`\n\nApplying loop unswitching on the loop-invariant flag $t$ yields two separate code blocks:\n\nCase $1$: $t=\\text{false}$\n`for i = 0 to n-1:`\n  `for k = 0 to n-1:`\n    `a = A[i][k]`\n    `for j = 0 to n-1:`\n      `C[i][j] += a * B[k][j]`\n\nCase $2$: $t=\\text{true}$\n`for i = 0 to n-1:`\n  `for k = 0 to n-1:`\n    `a = A[k][i]`\n    `for j = 0 to n-1:`\n      `C[i][j] += a * B[k][j]`\n\nWe will now analyze the number of cache line fills for reads from matrix $A$ in each case, based on the provided cache model. The matrices are stored in a contiguous row-major layout. The memory address of an element $A[r][c]$ can be expressed as $\\text{Addr}(A[r][c]) = \\text{Addr}(A[0][0]) + (r \\cdot n + c) \\cdot w$, where $w$ is the size of each element in bytes.\n\nA cache line has a size of $L$ bytes, and contains $p = \\frac{L}{w}$ elements. The problem specifies that we must count cache fills based on the rule: \"count one cache line fill the first time any element from a line of A is accessed within a given outer-loop iteration $i$, and do not count further cross-iteration reuse.\" This implies that our analysis for each iteration of the outer loop over $i$ is independent, and we sum the fills from each such iteration.\n\n**Analysis for $t=\\text{false}$ (Not Transposed Access)**\n\nIn this case, the access pattern for matrix $A$ is $A[i][k]$. The loops are ordered with $i$ as the outer loop and $k$ as the inner loop for the access to $A$.\nFor a fixed outer loop index $i$, the inner loop `for k = 0 to n-1` accesses the elements $A[i][0], A[i][1], \\dots, A[i][n-1]$.\nThis sequence of accesses corresponds to a sequential scan of the $i$-th row of matrix $A$. Since the matrix is in row-major layout, these elements are contiguous in memory.\nWhen $A[i][0]$ is accessed, a cache miss occurs, and the cache line containing the first $p$ elements of that row ($A[i][0]$ through $A[i][p-1]$) is loaded. This accounts for $1$ cache fill.\nThe subsequent $p-1$ accesses, to $A[i][1], \\dots, A[i][p-1]$, will be cache hits.\nThe next access, to $A[i][p]$, will cause another cache miss, loading the second cache line of the row. This continues across the entire row.\nSince a row contains $n$ elements and each cache line holds $p$ elements, and $n$ is an exact multiple of $p$, the number of cache lines that comprise a single row is exactly $\\frac{n}{p}$.\nTherefore, for each iteration of the outer loop (for each fixed $i$), accessing one full row of $A$ results in $\\frac{n}{p}$ cache fills.\n\nAccording to the specified counting rule, we sum these fills over all iterations of the outer loop, from $i=0$ to $i=n-1$.\nThe total number of fills is:\n$$ \\text{fills}_{t=\\text{false}} = \\sum_{i=0}^{n-1} \\frac{n}{p} = n \\cdot \\frac{n}{p} = \\frac{n^2}{p} $$\n\n**Analysis for $t=\\text{true}$ (Transposed Access)**\n\nIn this case, the access pattern for matrix $A$ is $A[k][i]$.\nFor a fixed outer loop index $i$, the inner loop `for k = 0 to n-1` accesses the elements $A[0][i], A[1][i], \\dots, A[n-1][i]$.\nThis sequence of accesses corresponds to a scan of the $i$-th column of matrix $A$.\nLet's examine the memory locations of two consecutive accesses in this sequence: $A[k][i]$ and $A[k+1][i]$.\n$\\text{Addr}(A[k][i]) = \\text{Addr}(A[0][0]) + (k \\cdot n + i) \\cdot w$\n$\\text{Addr}(A[k+1][i]) = \\text{Addr}(A[0][0]) + ((k+1) \\cdot n + i) \\cdot w$\nThe difference in their addresses is:\n$$ \\Delta \\text{Addr} = ((k+1)n + i)w - (kn + i)w = nw $$\nThe stride between consecutive memory accesses is $n \\cdot w$ bytes.\nThe size of a cache line is $L = p \\cdot w$ bytes.\nThe problem states $n$ is a multiple of $p$, which implies $n \\ge p$. Therefore, the stride $n \\cdot w$ is greater than or equal to the cache line size $p \\cdot w$. This means that each element in the column access sequence $A[0][i], A[1][i], \\dots, A[n-1][i]$ resides in a different cache line.\n\nTo be more rigorous, let's analyze the cache line index for an element $A[k][i]$. Assuming the matrix base address is $0$ for simplicity, the cache line index for the address $(kn+i)w$ is $\\lfloor \\frac{(kn+i)w}{L} \\rfloor = \\lfloor \\frac{kn+i}{p} \\rfloor$.\nSince $n$ is a multiple of $p$, we can write $n = m \\cdot p$ for some integer $m \\ge 1$.\nThe line index for $A[k][i]$ is $\\lfloor \\frac{k(mp)+i}{p} \\rfloor = \\lfloor km + \\frac{i}{p} \\rfloor = km + \\lfloor \\frac{i}{p} \\rfloor$.\nFor a fixed $i$, as $k$ increments, the term $km$ ensures that each value of $k$ from $0$ to $n-1$ produces a unique cache line index. Specifically, the line index for $A[k_1][i]$ and $A[k_2][i]$ will be different if $k_1 \\ne k_2$.\nTherefore, each of the $n$ accesses within the inner loop over $k$ results in a cache miss.\nFor each iteration of the outer loop (for each fixed $i$), there are $n$ cache fills.\n\nSumming over all iterations of the outer loop from $i=0$ to $i=n-1$:\n$$ \\text{fills}_{t=\\text{true}} = \\sum_{i=0}^{n-1} n = n \\cdot n = n^2 $$\n\n**Calculating the Difference**\n\nThe problem asks for the difference $\\Delta = \\text{fills}_{t=\\text{true}} - \\text{fills}_{t=\\text{false}}$.\nSubstituting the derived expressions:\n$$ \\Delta = n^2 - \\frac{n^2}{p} $$\nFactoring out the $n^2$ term gives the final analytical expression:\n$$ \\Delta = n^2 \\left(1 - \\frac{1}{p}\\right) $$\nThis expression represents the increase in cache misses when switching from a spatially local access pattern (row-wise on a row-major matrix) to a non-local one (column-wise).", "answer": "$$ \\boxed{n^2 \\left(1 - \\frac{1}{p}\\right)} $$", "id": "3654402"}, {"introduction": "In practice, compilers must make intelligent decisions about when to apply an optimization, as transformations are not always a clear win. This final exercise [@problem_id:3654414] puts you in the role of a compiler designer, performing a cost-benefit analysis for loop unswitching. Using a detailed performance model that includes both gains from vectorization and costs like instruction-cache pressure, you will determine the precise break-even point where this transformation becomes profitable.", "problem": "Consider a tight inner loop of $N$ iterations in a numerical kernel. The loop body contains a loop-invariant Boolean condition whose true/false outcome is fixed for an entire invocation of the loop but varies across invocations. The baseline implementation tests the condition inside the loop on every iteration and executes either a heavier or lighter path accordingly. A compiler optimization, loop unswitching, clones the loop into two versions specialized for the true and false outcomes, moving the condition outside the loop so that no per-iteration conditional branch remains. Profiling provides a hot/cold probability $p$ that the condition is true for a given invocation.\n\nAssume the following cost model (all cycle costs are empirically measured on the target microarchitecture and are per invocation unless stated per iteration):\n- Baseline per-iteration common work cost: $C$ cycles.\n- Baseline per-iteration conditional branch overhead: $b$ cycles.\n- Heavy-path per-iteration extra work (only when the condition is true): $H$ cycles.\n- Light-path per-iteration extra work (only when the condition is false): $L$ cycles.\n- After loop unswitching, the conditional branch is removed, but there is an instruction cache (I-cache) pressure penalty of $s$ cycles per iteration in the specialized loops.\n- After loop unswitching, there is a one-time cloning overhead of $d$ cycles per invocation (e.g., due to additional code fetch and preheader duplication) that applies regardless of which specialized loop runs.\n- After loop unswitching, the heavy path is vectorized with speedup factor $v1$, so its per-iteration extra work becomes $H/v$ cycles. The light path is unchanged.\n\nLet $N = 5 \\times 10^{5}$, $C = 2$, $b = 1.2$, $H = 12$, $L = 4$, $s = 0.3$, $d = 6.0 \\times 10^{5}$, and $v = 3$. Using the foundational definition of expected value for a Bernoulli outcome across invocations and a first-principles additive cost model, derive the break-even probability $p_{\\mathrm{crit}}$ such that for $p  p_{\\mathrm{crit}}$ loop unswitching yields a lower expected total cycles per invocation than the baseline. Compute $p_{\\mathrm{crit}}$ numerically and round your answer to four significant figures. Express your final answer as a unitless probability.", "solution": "The problem is found to be valid as it is scientifically grounded in compiler optimization principles, well-posed with a unique solution, and objective in its formulation. All necessary data and definitions are provided, and there are no contradictions.\n\nThe first step is to derive the expected total cycle cost for the baseline implementation, denoted as $E[T_{\\mathrm{base}}]$. The loop runs for $N$ iterations. In each iteration, there is a common work cost $C$ and a conditional branch overhead $b$. The condition is true with probability $p$, adding an extra work cost of $H$. The condition is false with probability $1-p$, adding an extra work cost of $L$. The total cost for a single invocation is therefore dependent on the outcome of the loop-invariant condition.\n\nIf the condition is true (probability $p$), the total cost is:\n$$T_{\\mathrm{base, true}} = N(C + b + H)$$\n\nIf the condition is false (probability $1-p$), the total cost is:\n$$T_{\\mathrm{base, false}} = N(C + b + L)$$\n\nThe expected total cost per invocation, $E[T_{\\mathrm{base}}]$, is the weighted average of these two outcomes:\n$$E[T_{\\mathrm{base}}] = p \\cdot T_{\\mathrm{base, true}} + (1-p) \\cdot T_{\\mathrm{base, false}}$$\n$$E[T_{\\mathrm{base}}] = p \\cdot N(C + b + H) + (1-p) \\cdot N(C + b + L)$$\nExpanding and collecting terms:\n$$E[T_{\\mathrm{base}}] = N(C+b)(p + (1-p)) + N(pH + (1-p)L)$$\n$$E[T_{\\mathrm{base}}] = N(C+b) + N(pH + L - pL) = N(C+b+L) + pN(H-L)$$\n\nNext, we derive the expected total cycle cost for the loop-unswitched implementation, $E[T_{\\mathrm{opt}}]$. In this version, there is a one-time cloning overhead of $d$ cycles. The conditional branch is moved outside the loop. The per-iteration branch overhead $b$ is eliminated, but an I-cache pressure penalty of $s$ cycles per iteration is introduced.\n\nIf the condition is true (probability $p$), the specialized loop for the true case runs. The heavy path work is vectorized, reducing its cost from $H$ to $H/v$. The total cost for this path is:\n$$T_{\\mathrm{opt, true}} = d + N(C + \\frac{H}{v} + s)$$\n\nIf the condition is false (probability $1-p$), the specialized loop for the false case runs. The light path is not vectorized. The total cost for this path is:\n$$T_{\\mathrm{opt, false}} = d + N(C + L + s)$$\n\nThe expected total cost per invocation for the optimized version is:\n$$E[T_{\\mathrm{opt}}] = p \\cdot T_{\\mathrm{opt, true}} + (1-p) \\cdot T_{\\mathrm{opt, false}}$$\n$$E[T_{\\mathrm{opt}}] = p \\left(d + N(C + \\frac{H}{v} + s)\\right) + (1-p) \\left(d + N(C + L + s)\\right)$$\nExpanding and collecting terms:\n$$E[T_{\\mathrm{opt}}] = d(p + (1-p)) + N(C+s)(p+(1-p)) + N\\left(p\\frac{H}{v} + (1-p)L\\right)$$\n$$E[T_{\\mathrm{opt}}] = d + N(C+s) + N\\left(p\\frac{H}{v} + L - pL\\right) = d + N(C+s+L) + pN\\left(\\frac{H}{v}-L\\right)$$\n\nThe break-even probability, $p_{\\mathrm{crit}}$, is the value of $p$ where the expected costs are equal: $E[T_{\\mathrm{base}}] = E[T_{\\mathrm{opt}}]$. Loop unswitching is beneficial for $p  p_{\\mathrm{crit}}$, as stated in the problem.\n\nSetting the two expected cost expressions equal:\n$$N(C+b+L) + p_{\\mathrm{crit}}N(H-L) = d + N(C+s+L) + p_{\\mathrm{crit}}N\\left(\\frac{H}{v}-L\\right)$$\nWe can simplify by canceling the common term $N(C+L)$ from both sides:\n$$Nb + p_{\\mathrm{crit}}N(H-L) = d + Ns + p_{\\mathrm{crit}}N\\left(\\frac{H}{v}-L\\right)$$\nNow, we group terms containing $p_{\\mathrm{crit}}$ on one side:\n$$p_{\\mathrm{crit}}N(H-L) - p_{\\mathrm{crit}}N\\left(\\frac{H}{v}-L\\right) = d + Ns - Nb$$\n$$p_{\\mathrm{crit}}N\\left((H-L) - \\left(\\frac{H}{v}-L\\right)\\right) = d + N(s-b)$$\n$$p_{\\mathrm{crit}}N\\left(H - L - \\frac{H}{v} + L\\right) = d + N(s-b)$$\n$$p_{\\mathrm{crit}}N\\left(H - \\frac{H}{v}\\right) = d + N(s-b)$$\n$$p_{\\mathrm{crit}}NH\\left(1 - \\frac{1}{v}\\right) = d + N(s-b)$$\nSolving for $p_{\\mathrm{crit}}$:\n$$p_{\\mathrm{crit}} = \\frac{d + N(s-b)}{NH\\left(1 - \\frac{1}{v}\\right)}$$\n\nNow, we substitute the given numerical values:\n$N = 5 \\times 10^{5}$\n$C = 2$\n$b = 1.2$\n$H = 12$\n$L = 4$\n$s = 0.3$\n$d = 6.0 \\times 10^{5}$\n$v = 3$\n\nFirst, calculate the numerator:\n$$d + N(s-b) = (6.0 \\times 10^{5}) + (5 \\times 10^{5})(0.3 - 1.2)$$\n$$= 6.0 \\times 10^{5} + (5 \\times 10^{5})(-0.9)$$\n$$= 6.0 \\times 10^{5} - 4.5 \\times 10^{5} = 1.5 \\times 10^{5}$$\n\nNext, calculate the denominator:\n$$NH\\left(1 - \\frac{1}{v}\\right) = (5 \\times 10^{5}) \\cdot 12 \\cdot \\left(1 - \\frac{1}{3}\\right)$$\n$$= (5 \\times 10^{5}) \\cdot 12 \\cdot \\left(\\frac{2}{3}\\right)$$\n$$= (5 \\times 10^{5}) \\cdot 8 = 40 \\times 10^{5} = 4.0 \\times 10^{6}$$\n\nFinally, compute $p_{\\mathrm{crit}}$:\n$$p_{\\mathrm{crit}} = \\frac{1.5 \\times 10^{5}}{4.0 \\times 10^{6}} = \\frac{1.5}{40} = 0.0375$$\n\nThe problem requires the answer to be rounded to four significant figures. The calculated value $0.0375$ has three significant figures. To express it with four, we add a trailing zero, which is significant in this context.\n$$p_{\\mathrm{crit}} = 0.03750$$\nThis is the break-even probability. For any probability $p  0.03750$, loop unswitching provides a performance benefit under this cost model.", "answer": "$$\\boxed{0.03750}$$", "id": "3654414"}]}