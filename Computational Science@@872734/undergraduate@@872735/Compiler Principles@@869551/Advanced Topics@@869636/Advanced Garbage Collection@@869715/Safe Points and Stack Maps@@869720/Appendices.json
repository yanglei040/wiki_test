{"hands_on_practices": [{"introduction": "Implementing safepoints requires balancing correctness with performance. A key decision for a compiler engineer is *how* to implement the polling mechanism that checks if the runtime needs to pause a thread. This exercise explores the performance trade-offs between two common strategies—an inline conditional check versus an unconditional call to a runtime stub—by modeling their costs based on microarchitectural parameters like branch misprediction penalties [@problem_id:3669414]. Understanding this trade-off is fundamental to designing efficient managed runtimes.", "problem": "Consider a managed runtime that inserts a safepoint poll into a tight loop at every iteration so that garbage collection and deoptimization can be initiated safely. A safepoint is a program point where all thread stacks are in a known state and all live references are discoverable using stack maps. A stack map records, for each safepoint, the locations of live object references in registers and memory to allow precise garbage collection. Two compiler strategies for implementing a safepoint poll are commonly used: (i) inline polling, where a conditional check is emitted in the loop body; and (ii) a callout to a runtime stub, where the loop body performs an unconditional call into a stub that handles the safepoint protocol and returns.\n\nAssume a Just-In-Time (JIT) compiler targets two architectures, labeled $\\mathcal{A}$ and $\\mathcal{B}$. Let the branch misprediction rate for the conditional branch used by the inline poll be $p \\in [0,1]$. Use the following cost modeling assumptions grounded in standard microarchitectural definitions:\n- A conditional branch has a base execution cost of $b$ cycles (including compare and branch micro-operations) and, when mispredicted, incurs an additional penalty of $m$ cycles due to pipeline flush and frontend redirection.\n- A load from a hot polling memory location (for example, a page-protected flag or polling page) has a cost of $l$ cycles when performed in the loop body. When performed inside the runtime stub, the same load has a cost of $l_{s}$ cycles.\n- An unconditional call to the stub followed by a return has a combined overhead of $c$ cycles on the hot path when no safepoint is actually taken. This overhead includes return stack manipulation and frontend costs but excludes any branch misprediction, since the call is unconditional and the stub’s fast path is branchless with respect to the return.\n- The safepoint is not taken in the hot path; you are modeling the polling overhead only.\n\nFor inline polling, the loop body performs a load of the polling location and a conditional branch; the expected per-iteration overhead is the sum of base costs plus the expected misprediction penalty. For the callout approach, the loop body performs an unconditional call and return; the stub executes a load and immediately returns if no safepoint is requested, with no conditional branch in the fast path.\n\nUsing the above principles, derive from first principles the break-even misprediction probability $p^{\\ast}$ at which the expected per-iteration overhead of inline polling equals that of the callout approach. Then, evaluate $p^{\\ast}$ numerically for the following two architectures:\n\n- Architecture $\\mathcal{A}$: $l = 4$ cycles, $b = 1$ cycle, $m = 18$ cycles, $c = 9$ cycles, $l_{s} = 4$ cycles.\n- Architecture $\\mathcal{B}$: $l = 3$ cycles, $b = 2$ cycles, $m = 12$ cycles, $c = 8$ cycles, $l_{s} = 3$ cycles.\n\nReport the pair $\\left(p^{\\ast}_{\\mathcal{A}}, p^{\\ast}_{\\mathcal{B}}\\right)$ as plain dimensionless numbers. Round your numerical results to four significant figures. Express the final answer as a row vector using the LaTeX $\\texttt{pmatrix}$ environment as specified.", "solution": "The problem requires the derivation of a break-even misprediction probability, denoted as $p^{\\ast}$, at which two different compiler strategies for implementing safepoint polls exhibit equal performance overhead. The two strategies are inline polling and a callout to a runtime stub. We will first establish the cost models for each strategy based on the provided microarchitectural parameters, then solve for the break-even probability $p^{\\ast}$ symbolically, and finally compute the numerical values for the two specified architectures, $\\mathcal{A}$ and $\\mathcal{B}$.\n\nLet $C_{\\text{inline}}$ represent the expected per-iteration overhead for the inline polling strategy. The problem states that this strategy consists of a memory load and a conditional branch executed in the loop body. The total cost is the sum of the costs of these operations.\nThe cost of the load from a hot polling memory location is given as $l$.\nThe cost of the conditional branch has two components: a base execution cost $b$ and a potential penalty for misprediction. The branch is mispredicted with a probability $p$, incurring an additional cost of $m$ cycles. The expected cost of the branch is therefore the sum of its base cost and the expected penalty, which is $b + p \\times m$.\nThus, the total expected overhead for inline polling is:\n$$C_{\\text{inline}} = l + b + pm$$\n\nNext, let $C_{\\text{callout}}$ represent the per-iteration overhead for the callout strategy. This strategy involves an unconditional call to a runtime stub, which then performs the memory load. We are interested in the hot path where no safepoint is actually taken.\nThe cost of the unconditional call and its corresponding return is given as $c$.\nThe cost of the memory load, when performed inside the stub, is given as $l_s$.\nThe problem specifies that the call is unconditional and the stub's fast path is branchless, so there are no branch misprediction costs to consider for this strategy on the hot path.\nThe total overhead for the callout strategy is the sum of these two components:\n$$C_{\\text{callout}} = c + l_s$$\n\nThe break-even misprediction probability, $p^{\\ast}$, is the specific value of $p$ where the costs of the two strategies are equal: $C_{\\text{inline}} = C_{\\text{callout}}$. We can establish the equation:\n$$l + b + p^{\\ast}m = c + l_s$$\n\nWe now solve this equation for $p^{\\ast}$ to find the general symbolic expression for the break-even probability:\n$$p^{\\ast}m = c + l_s - l - b$$\n$$p^{\\ast} = \\frac{c + l_s - l - b}{m}$$\n\nThis expression provides the break-even probability in terms of the architectural cost parameters. We will now use this formula to calculate the numerical values for the two given architectures.\n\nFor Architecture $\\mathcal{A}$, the parameters are provided as:\n$l = 4$ cycles\n$b = 1$ cycle\n$m = 18$ cycles\n$c = 9$ cycles\n$l_s = 4$ cycles\n\nSubstituting these values into our derived expression for $p^{\\ast}$:\n$$p^{\\ast}_{\\mathcal{A}} = \\frac{9 + 4 - 4 - 1}{18} = \\frac{8}{18} = \\frac{4}{9}$$\nTo express this as a decimal rounded to four significant figures:\n$$p^{\\ast}_{\\mathcal{A}} \\approx 0.4444$$\n\nFor Architecture $\\mathcal{B}$, the parameters are provided as:\n$l = 3$ cycles\n$b = 2$ cycles\n$m = 12$ cycles\n$c = 8$ cycles\n$l_s = 3$ cycles\n\nSubstituting these values into the expression for $p^{\\ast}$:\n$$p^{\\ast}_{\\mathcal{B}} = \\frac{8 + 3 - 3 - 2}{12} = \\frac{6}{12} = \\frac{1}{2}$$\nAs a decimal, this is exactly $0.5$. To adhere to the requirement of rounding to four significant figures, we express this as:\n$$p^{\\ast}_{\\mathcal{B}} = 0.5000$$\n\nThe final result is the pair of these two probabilities, $(p^{\\ast}_{\\mathcal{A}}, p^{\\ast}_{\\mathcal{B}})$. For any given architecture, if the actual branch misprediction rate $p$ is greater than $p^{\\ast}$, the callout strategy is more efficient. If $p$ is less than $p^{\\ast}$, inline polling is the preferred, lower-overhead strategy.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.4444 & 0.5000\n\\end{pmatrix}\n}\n$$", "id": "3669414"}, {"introduction": "Beyond performance, the absolute foremost requirement of a safepoint is correctness: the program's state must precisely match the description provided by the stack map. This \"bug hunt\" exercise presents a classic and subtle error where a function's epilogue modifies the stack pointer ($SP$) *before* the safepoint poll, causing a mismatch between the actual machine state and the stack map's assumptions [@problem_id:3669416]. By analyzing this scenario, you will learn to appreciate the strict ordering constraints necessary to ensure a precise garbage collector can always find every live reference.", "problem": "A compiler for a precise garbage-collected language targets a conventional architecture with a stack pointer ($SP$) and an optional frame pointer ($FP$). The calling convention specifies that a callee allocates its frame in the prologue by subtracting a nonzero frame size $k$ from $SP$ and restores $SP$ in the epilogue by adding $k$ to $SP$. The garbage collector (GC) is stop-the-world and relies on precise stack maps: there exists a mapping function $\\mathsf{Map}: PC \\rightarrow \\{(\\text{reg}, \\ell)\\}$ from a program counter ($PC$) to a set of root locations, each either a register or a memory location described by a base ($SP$ or $FP$) and an offset $\\ell$. At a safepoint, the GC scanner uses the current $PC$ and $\\mathsf{Map}$ to enumerate all live roots and then traces the object graph.\n\nConsider a bug hunt in which a callee’s epilogue modifies $SP$ before safepoint scanning. In particular, the compiler places a safepoint poll instruction in the callee’s epilogue after $SP$ has been restored to its caller value $SP_{\\text{post}} = SP_{\\text{pre}} + k$, but the stack map for that poll point was generated relative to the pre-epilogue state and expects $SP_{\\text{pre}}$. Suppose a live pointer $p$ was spilled to memory at offset $o$ relative to $SP_{\\text{pre}}$, i.e., at address $SP_{\\text{pre}} + o$, and $\\mathsf{Map}$ for the safepoint identifies this root as $\\langle SP, o \\rangle$. If the GC is triggered exactly at the safepoint poll in the epilogue, the scanner reads $\\langle SP_{\\text{post}}, o \\rangle$ and may fail to find $p$, potentially leading to premature reclamation.\n\nFrom first principles:\n- A precise GC requires that, at any safepoint, the machine state ($SP$, $FP$, registers) and the stack map agree on the frame layout; that is, if $\\mathsf{Map}(PC)$ references $\\langle SP, o \\rangle$, then the actual $SP$ must equal the $SP$ that was assumed when $\\mathsf{Map}(PC)$ was constructed.\n- The calling convention guarantees that the prologue and epilogue adjust $SP$ by exactly $k$ and that all stack-resident locals reside at fixed offsets relative to the $SP$ used during normal execution.\n- The safepoint mechanism must ensure quiescence at well-defined program points where liveness and location information are precise.\n\nYou are asked to both fix the bug with ordering constraints in code generation and propose a method to verify the fix using instrumented pauses that exacerbate the race window. Which option correctly specifies a sufficient ordering constraint to prevent the mismatch and a sound verification method?\n\nA. Constrain code generation so that any safepoint poll in an epilogue is placed before the $SP$ restoration, i.e., the poll executes with $SP = SP_{\\text{pre}}$, and ensure that the stack map for that poll point is constructed for the pre-epilogue state. Verify by inserting an instrumented pause immediately after the safepoint poll: a busy-wait loop that spins on a global flag $G$ until another thread triggers the GC, thereby maximizing the chance of stopping at the poll; then stress-test with live pointers spilled at offsets $\\{o_i\\}$ and check that no root is lost. \n\nB. Switch all stack maps to use $FP$-relative offsets only, ignoring $SP$ entirely, and remove the safepoint poll from callee epilogues. Verify by enabling a conservative fallback that scans the entire stack, comparing survivor sets; if they match, conclude the fix is correct.\n\nC. Increase the frequency of safepoint polls and insert them after returns at call sites in the caller, leaving the callee epilogue unchanged. Verify by counting the number of safepoint hits during execution and observing that the program no longer crashes.\n\nD. Insert a memory fence instruction between the $SP$ restoration and the safepoint poll to prevent reordering, and modify the GC scanner to reread $SP$ twice and average the values to reduce transient inconsistency. Verify by microbenchmarking fence overhead without checking root accuracy.\n\nE. Recompute the stack map at runtime at each safepoint by walking the current stack frames and inferring offsets, thereby avoiding reliance on precomputed maps. Verify by printing inferred maps and visually inspecting that $SP$ and offsets look plausible.\n\nSelect the correct option(s).", "solution": "The fundamental requirement for precise garbage collection is agreement between the abstract description of roots in the stack map and the concrete machine state at the moment of scanning. Formally, if $\\mathsf{Map}(PC)$ contains entries $\\langle B, o \\rangle$ for base $B \\in \\{SP, FP\\}$, then the scanner must read memory at addresses $B_{\\text{actual}} + o$, where $B_{\\text{actual}}$ equals the base value assumed by $\\mathsf{Map}$ when constructed. Any divergence between $B_{\\text{actual}}$ and the assumed base invalidates the correspondence between addresses and the actual root set.\n\nGiven the calling convention, the callee epilogue performs $SP \\leftarrow SP + k$, where $k > 0$ is the frame size. If the safepoint poll is placed after this adjustment, but the stack map for that poll expects $SP = SP_{\\text{pre}}$, then the scanner will read at $SP_{\\text{post}} + o = (SP_{\\text{pre}} + k) + o$, which differs by $k$ from the intended address $SP_{\\text{pre}} + o$. This can lead to missing the spilled pointer $p$.\n\nTherefore, the fix must enforce an ordering constraint that aligns the poll’s machine state with its stack map. Two equivalent strategies exist in principle: either move the poll earlier so that $SP = SP_{\\text{pre}}$ when scanning, and build $\\mathsf{Map}$ for that state, or keep the poll after restoration and rebuild $\\mathsf{Map}$ for the post-epilogue state such that entries use $\\langle SP_{\\text{post}}, o' \\rangle$ with new offsets $o'$. The thumbnail mandates “fix with ordering constraints and verify with instrumented pauses,” which matches the former: constrain codegen so $SP$ is not modified before the safepoint poll, and verify via a deliberate pause that raises the likelihood of stopping at exactly that point.\n\nVerification must be designed to increase the probability of hitting the safepoint and to catch state mismatches. An instrumented pause immediately after the poll widens the window in which the GC can stop the world with the callee in the epilogue. To prove correctness, one should create tests with roots spilled at multiple offsets $\\{o_i\\}$ and check that, under stress (concurrent GC triggers during the pause), no roots are lost, e.g., by retaining objects and validating that none are reclaimed prematurely.\n\nAnalyze each option:\n\nA. This option imposes the necessary ordering constraint: place the safepoint poll before restoring $SP$, ensuring $SP = SP_{\\text{pre}}$ at the poll, and build the stack map for the pre-epilogue state. This guarantees that the scanner reads at addresses $SP_{\\text{pre}} + o$ matching $\\mathsf{Map}$. The verification via an instrumented busy-wait after the poll is appropriate: by spinning until a GC trigger, we maximize the chance of stopping with the callee in the epilogue while $SP$ remains the pre-epilogue value, thus validating that spilled roots at offsets $\\{o_i\\}$ are correctly found. This is Correct.\n\nB. Switching to $FP$-relative offsets may be impossible or insufficient because $FP$ may be omitted or repurposed under optimization, and removing safepoint polls from epilogues reduces safepoint coverage, potentially harming latency. Moreover, enabling a conservative fallback for verification does not prove the precise mechanism is correct; conservative scanning can mask errors by over-approximating roots. The verification criterion (comparing survivor sets under conservative scanning) is unsound for proving precision correctness. This is Incorrect.\n\nC. Increasing the frequency of safepoint polls and moving them to after returns at call sites does not address the fundamental mismatch between $SP$ and the stack map at the epilogue poll. Counting safepoint hits does not constitute correctness verification; it measures frequency, not precision. Furthermore, placing polls after returns changes program points and can still suffer from state mismatches at call-site edges if maps are inconsistent. This is Incorrect.\n\nD. Memory fences do not solve the logical mismatch; they only constrain hardware reordering. The stack map expects a particular $SP$ value, and rereading $SP$ twice and “averaging” is nonsensical because $SP$ is not a quantity to average; it is a pointer value. Microbenchmarking fence overhead ignores root accuracy and does not verify correctness. This is Incorrect.\n\nE. Recomputing stack maps at runtime defeats the purpose of precise precomputed maps and is generally expensive and complex; “inferring offsets” reliably requires full symbolic information and is not guaranteed. Printing inferred maps and visually inspecting is not a sound verification method. This is Incorrect.\n\nTherefore, the only option that both correctly fixes the ordering and provides a sound verification strategy with instrumented pauses is option A.", "answer": "$$\\boxed{A}$$", "id": "3669416"}, {"introduction": "A compiler can only generate correct stack maps for code it fully understands, which creates a significant challenge when integrating with low-level, opaque code like inline assembly. If a programmer hides a managed object reference in a register that the compiler doesn't know about, a garbage collection cycle can lead to memory corruption. This practice problem explores this \"hidden pointer\" issue and prompts you to evaluate standard, sound solutions like safepoint fences and handle-based indirection that are used to maintain GC safety in real-world systems [@problem_id:3669445].", "problem": "A managed runtime implements a precise, relocating garbage collector and uses cooperative safe points, inserted as explicit polls at well-defined program locations. By definition, at a safe point, every live reference to a managed object must be discoverable by the garbage collector via a stack map that precisely enumerates all live references and their locations (stack slots and registers). Consider the following simplified C-like function targeting an x86-64 application binary interface, where inline assembly is used. The inline assembly stashes a managed reference into a callee-saved register and later uses it. The runtime inserts a safe point poll between these two uses.\n\nCode sketch (illustrative, not to be compiled as-is):\n```c\ntypedef struct Obj { int f; } Obj;\n\nvoid g(Obj* p) {\n  // Stash the managed pointer into rbx using inline assembly.\n  asm volatile(\n    \"mov %0, %%rbx\\t\"\n    :\n    : \"r\"(p)\n    : \"rbx\", \"memory\"\n  );\n\n  // A cooperative safe point poll that may trigger garbage collection.\n  safepoint_poll();\n\n  // Later, still use the hidden copy in rbx via inline assembly.\n  asm volatile(\n    \"mov (%%rbx), %%eax\\t\"  // read field f\n    :\n    :\n    : \"rbx\", \"rax\", \"memory\"\n  );\n}\n```\n\nAssume the following baseline facts:\n- The garbage collector is precise and relocating: it may move objects during collection, and it assumes that all live references at a safe point are discoverable from the stack map. It does not conservatively scan non-enumerated stack words or registers.\n- The compiler builds stack maps only from its internal liveness of managed references and explicit annotations; it does not inspect inline assembly semantics.\n- A safe point poll may result in a collection. If a live reference is not enumerated in the stack map at that poll, the collector may move the object without updating the hidden copy, leading to memory corruption when that copy is later dereferenced.\n\nIn the code above, the first inline assembly copies the managed reference into register rbx, but the surrounding compiler cannot “see” that rbx contains a managed reference that remains live past the poll. Thus, at the poll, the stack map may omit this reference. You must choose how to make this program sound under the precise, relocating collector.\n\nWhich of the following changes are sound ways to fix the program so that it remains correct even if a collection occurs at the poll? Select all that apply.\n\nA. Surround the region from the first inline assembly through the second inline assembly with a safepoint fence (that is, prevent insertion or execution of polls or calls inside this region), moving any safe point poll outside the fenced region. Ensure the fenced region does not call into code that might block or poll. This guarantees no collection can occur while the reference is hidden in rbx.\n\nB. Keep the safepoint_poll in place, but explicitly publish the managed reference to the compiler’s stack map machinery so it remains live across the poll. For example, materialize the reference in a dedicated spill slot that is declared as a garbage collector root, or use a compiler-recognized keepalive so that the stack map at the poll enumerates the reference’s location (whether spilled or in a designated register).\n\nC. Rely on the platform calling convention and a \"memory\" clobber: since rbx is callee-saved and the assembly lists \"memory\" in the clobbers, the runtime will implicitly scan rbx at the poll even if it is not listed in the stack map, so no extra work is needed.\n\nD. Force conservative enumeration by having the runtime conservatively scan all general-purpose registers and all stack words at every safe point, without changing the assembly. This avoids the need to annotate the reference specifically.\n\nE. Replace the raw reference with a heap handle: before the first inline assembly, register a handle for p in the runtime’s handle table; the inline assembly must load from and store through this handle when it needs the object; after the second inline assembly, unregister the handle. Since the handle is a known root, the garbage collector will update it on relocation, and the inline assembly will observe the updated address even if a collection occurs at the poll.", "solution": "The core problem is a violation of the garbage collector's invariants. A managed pointer is hidden from the compiler in register `rbx` via inline assembly. The compiler's liveness analysis is unaware of this, so the pointer is not included in the stack map for the `safepoint_poll()`. A precise, relocating GC will therefore not find or update this pointer, leading to a dangling pointer if the object is moved or reclaimed. A sound solution must either (1) prevent the GC from running while the pointer is hidden, or (2) make the GC aware of the pointer.\n\nLet's analyze the options:\n*   **A. Safepoint Fence:** This approach prevents a GC from occurring in the fenced region. The hidden pointer in `rbx` remains valid because the object it points to cannot be moved. This is a sound and common strategy for short, non-blocking critical sections of native code.\n*   **B. Explicitly Publish the Reference:** This approach makes the compiler aware of the reference's liveness. Using a compiler intrinsic like `GC.KeepAlive` or a special annotation forces the compiler to include the reference in the stack map for the safepoint. The GC can then find and update it correctly. This is also a sound and idiomatic solution.\n*   **C. Rely on Calling Convention/Clobbers:** This is incorrect. ABI rules like \"callee-saved\" are for function call boundaries, not for GC safepoints. The \"memory\" clobber informs the compiler about potential memory side effects, not about the contents of registers. The precise GC relies solely on the stack map.\n*   **D. Force Conservative Scanning:** This is incorrect as it changes the fundamental contract of the system (from precise to conservative), rather than fixing the program to work correctly with the existing precise GC.\n*   **E. Use a Handle:** This is a sound solution based on indirection. A handle is a stable reference (typically a pointer to a location in a runtime-managed table) that is known to the GC. The inline code would use the handle to get the object's current address. If the GC moves the object, it updates the handle, so the code always gets the correct address.\n\nTherefore, options A, B, and E are all sound methods to fix the program.", "answer": "$$\\boxed{ABE}$$", "id": "3669445"}]}