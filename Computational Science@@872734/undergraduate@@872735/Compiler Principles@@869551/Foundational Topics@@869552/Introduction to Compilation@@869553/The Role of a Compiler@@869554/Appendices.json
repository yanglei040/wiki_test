{"hands_on_practices": [{"introduction": "A compiler's foremost duty is to preserve the meaning of the original program, a principle known as the \"as-if\" rule. This exercise explores this directive through constant folding and its interaction with language features like short-circuit evaluation. By analyzing hypothetical scenarios involving side effects, you will see how a seemingly straightforward optimization, if applied naively, can alter a program's observable behavior and thus violate the compiler's fundamental contract of correctness [@problem_id:3674643].", "problem": "You are designing a constant-folding pass in a compiler for a first-order, call-by-value imperative language with Boolean connectives and short-circuit evaluation. Short-circuit evaluation is defined by the core operational rule: in an expression $E_1 \\land E_2$, the compiler’s abstract machine evaluates $E_1$ first to a Boolean $b_1 \\in \\{0,1\\}$ (possibly producing side effects); if $b_1 = 0$, the result is $0$ and $E_2$ is not evaluated; if $b_1 = 1$, then $E_2$ is evaluated and its result is returned. Dually, in $E_1 \\lor E_2$, the machine evaluates $E_1$ first to $b_1 \\in \\{0,1\\}$; if $b_1 = 1$, the result is $1$ and $E_2$ is not evaluated; if $b_1 = 0$, then $E_2$ is evaluated and its result is returned. Function calls may have side effects on global state. The compiler translates source to an Intermediate Representation (IR), and performs constant folding on the IR to reduce expressions using identities such as $E \\land 0 \\equiv 0$, $E \\lor 1 \\equiv 1$, and $\\lnot 0 \\equiv 1$, whenever their operands are syntactic constants, in order to reduce runtime cost. The role of the compiler is to preserve observational behavior: for any source expression, the sequence of externally visible effects and the resulting value must be the same after optimization.\n\nAssume a function $h()$ increments a global counter $g$ by $1$ each time it is called (this increment is the only observable side effect), and returns a Boolean that may be $0$ or $1$ depending on runtime conditions unknown at compile time. Let the initial value of $g$ be arbitrary. Consider the following source-level Boolean expressions, each evaluated in a context that inspects both the final counter value $g$ and the Boolean result of the expression.\n\nSelect all options for which an eager constant folding step that replaces the entire expression by a constant using Boolean identities, without first accounting for short-circuit evaluation and potential side effects, could change observable behavior (that is, could change whether $h()$ is called and thus the final value of $g$, or could change the returned Boolean).\n\nA. $h() \\land 0$\n\nB. $0 \\land h()$\n\nC. $1 \\lor h()$\n\nD. $h() \\lor 1$\n\nE. $\\lnot 0 \\land h()$", "solution": "The \"as-if\" rule requires that the observable behavior of the program is preserved. Here, observable behavior includes side effects (calls to `h()`) and the final Boolean result. Short-circuit evaluation dictates the order of evaluation and whether both operands of a logical connective are evaluated.\n\nLet's analyze each case:\n\n*   **A. `$h() \\land 0$`**: According to short-circuit rules, the left operand `$h()$` is evaluated first. This call has the side effect of incrementing the global counter `g`. If the compiler eagerly folds the entire expression to the constant `0`, the call to `$h()$` is eliminated, and the side effect does not occur. This changes the observable behavior.\n\n*   **B. `$0 \\land h()`**: The left operand is `0` (false). Short-circuit evaluation stops here and returns `0` without evaluating the right operand, `$h()$`. Eagerly folding this to `0` produces the same result and has the same lack of side effects. Observable behavior is unchanged.\n\n*   **C. `$1 \\lor h()`**: The left operand is `1` (true). Short-circuit evaluation stops here and returns `1` without evaluating `$h()$`. Eagerly folding this to `1` produces the same result and has the same lack of side effects. Observable behavior is unchanged.\n\n*   **D. `$h() \\lor 1$`**: The left operand `$h()$` is evaluated first, causing the side effect of incrementing `g`. If the compiler folds the expression to the constant `1`, the call to `$h()$` is eliminated. This changes the observable behavior.\n\n*   **E. `$\\lnot 0 \\land h()`**: This expression is equivalent to `$1 \\land h()$`. The left operand is `1` (true). Short-circuit evaluation proceeds to evaluate the right operand, `$h()$`, causing a side effect. An eager constant folder cannot reduce the entire expression to a constant, as the result of `$h()` is unknown. It could only fold `$\\lnot 0$` to `1`, resulting in `$1 \\land h()$`, which still evaluates `$h()$`. Therefore, observable behavior is unchanged compared to the original expression.\n\nBased on this analysis, options A and D are the cases where a naive, eager constant folding would alter the program's observable behavior.", "answer": "$$\n\\boxed{AD}\n$$", "id": "3674643"}, {"introduction": "Once correctness is guaranteed, a compiler's goal is to improve performance, which often involves balancing competing factors. This practice explores the classic trade-off between the benefits of loop unrolling and the costs of increased register pressure. Using the provided quantitative cost model, you will calculate the break-even point where one optimization strategy becomes more favorable than another, providing insight into the data-driven decisions a compiler must make [@problem_id:3674633].", "problem": "Consider a simple loop that computes a linear transform over arrays, where the compiler’s role includes choosing transformations (such as loop unrolling) and managing register allocation to minimize execution time. The loop body per original iteration requires a certain number of live temporaries, and the machine has a finite register file. When the compiler unrolls the loop by a factor $u$, some temporaries are shared across the $u$ fused iterations while others are unique to each iteration. If the total number of simultaneously live values exceeds the number of available registers $R$, the compiler’s register allocator must generate spills to memory, each incurring an additional cycle cost $s$.\n\nUse the following scientifically plausible and self-consistent model and parameters:\n\n- The base compute cost per original iteration is $c$ cycles. For this scenario, $c = 20$.\n- The control and address-update overhead per original iteration is $h$ cycles. For this scenario, $h = 30$.\n- The available registers are $R = 13$.\n- The immediately live temporaries that are shared across a $u$-fold unrolled chunk are $L_{\\text{shared}} = 5$ (for example, loop index, base pointers for $A$, $B$, $C$, and a loop-invariant scalar).\n- The immediately live temporaries that are unique per original iteration are $L_{\\text{iter}} = 3$ (for example, the values loaded from $B[i]$ and $C[i]$, and an intermediate product $C[i]\\times D$).\n- The total number of simultaneously live temporaries at the peak of the unrolled chunk is modeled as $L(u) = L_{\\text{shared}} + u\\,L_{\\text{iter}}$.\n- If $L(u)  R$, the number of spilled values is $S(u) = L(u) - R$, otherwise $S(u) = 0$.\n- The spill cost parameter $s$ represents the total cycle penalty per spilled value per $u$-iteration chunk (for example, a combined load and store for that spilled value). The per-original-iteration spill penalty is then $\\frac{s\\,S(u)}{u}$.\n- The average cycles per original iteration under unroll factor $u$ is modeled as\n$$\nC(u) \\;=\\; c \\;+\\; \\frac{h}{u} \\;+\\; \\frac{s\\,S(u)}{u}.\n$$\n\nIn this setting, unrolling by $u=2$ yields $L(2) = 5 + 2\\cdot 3 = 11 \\leq 13$, so $S(2)=0$. Unrolling by $u=3$ yields $L(3) = 5 + 3\\cdot 3 = 14  13$, so $S(3)=14-13=1$.\n\nUsing the above model, determine the break-even spill cost $s^{\\star}$ (in cycles) at which the compiler is indifferent between unroll factor $u=2$ (no spills) and unroll factor $u=3$ (one spill per chunk), that is, the value of $s$ such that $C(2)=C(3)$. Express the final answer in cycles. No rounding is required.", "solution": "A compiler’s role includes transforming source programs into target machine code while optimizing performance under machine constraints. Two relevant foundational facts are:\n\n- Loop unrolling reduces control-flow overhead by amortizing branch and index-update work over $u$ iterations, thereby contributing a term $\\frac{h}{u}$ to the per-original-iteration cost.\n- Register allocation is constrained by a finite register file of size $R$. If the peak number of simultaneously live temporaries $L(u)$ exceeds $R$, the excess $S(u)=\\max(0,L(u)-R)$ must be spilled to memory, and each spilled value contributes an additional cycle penalty. Under the stated model, the per-original-iteration spill penalty is $\\frac{s\\,S(u)}{u}$ because $s$ is per chunk of $u$ iterations.\n\nCombining these from first principles yields the per-original-iteration cost model\n$$\nC(u) \\;=\\; c \\;+\\; \\frac{h}{u} \\;+\\; \\frac{s\\,S(u)}{u},\n$$\nwhere $c$ is the base compute cost per original iteration, $h$ is the per-iteration control and address-update overhead, and $s$ is the spill cost per spilled value per $u$-iteration chunk.\n\nWe are given:\n- $c = 20$,\n- $h = 30$,\n- $R = 13$,\n- $L_{\\text{shared}} = 5$,\n- $L_{\\text{iter}} = 3$,\n- $L(u) = L_{\\text{shared}} + u\\,L_{\\text{iter}}$,\n- $S(u) = \\max\\big(0,\\,L(u) - R\\big)$.\n\nCompute the liveness and spills for the specific unroll factors:\n- For $u=2$, \n$$\nL(2) \\;=\\; 5 + 2\\cdot 3 \\;=\\; 11,\n$$\nand since $11 \\leq 13$, \n$$\nS(2) \\;=\\; 0.\n$$\nTherefore,\n$$\nC(2) \\;=\\; c + \\frac{h}{2} + \\frac{s\\,S(2)}{2} \\;=\\; 20 + \\frac{30}{2} + \\frac{s\\cdot 0}{2} \\;=\\; 20 + 15 \\;=\\; 35.\n$$\n\n- For $u=3$,\n$$\nL(3) \\;=\\; 5 + 3\\cdot 3 \\;=\\; 14,\n$$\nand since $14  13$,\n$$\nS(3) \\;=\\; 14 - 13 \\;=\\; 1.\n$$\nTherefore,\n$$\nC(3) \\;=\\; c + \\frac{h}{3} + \\frac{s\\,S(3)}{3} \\;=\\; 20 + \\frac{30}{3} + \\frac{s\\cdot 1}{3} \\;=\\; 20 + 10 + \\frac{s}{3} \\;=\\; 30 + \\frac{s}{3}.\n$$\n\nWe seek the break-even spill cost $s^{\\star}$ such that $C(2) = C(3)$. Set the expressions equal and solve for $s$:\n$$\n35 \\;=\\; 30 + \\frac{s}{3}\n\\;\\;\\Longrightarrow\\;\\;\n\\frac{s}{3} \\;=\\; 5\n\\;\\;\\Longrightarrow\\;\\;\ns \\;=\\; 15.\n$$\n\nThus, the break-even spill cost is $s^{\\star} = 15$ cycles: if $s  15$ cycles, unrolling to $u=3$ is beneficial; if $s  15$ cycles, unrolling to $u=2$ (which avoids spills) is better under this model. This quantifies the trade-off the compiler must evaluate between reduced control overhead and increased register pressure due to unrolling.", "answer": "$$\\boxed{15}$$", "id": "3674633"}, {"introduction": "Effective optimization requires a deep understanding of the target hardware's capabilities, making the compiler a crucial bridge between software and hardware. This problem delves into the instruction selection phase, where the compiler maps intermediate code onto specific machine instructions. You will analyze how the choice of addressing modes can impact resource usage, demonstrating how a sophisticated compiler leverages hardware features to reduce register pressure and generate more efficient code [@problem_id:3674621].", "problem": "A compiler backend must map an Intermediate Representation (IR) to a target Instruction Set Architecture (ISA). Consider a target machine that supports memory operands with a complex addressing mode of the form base-plus-index-with-shift-plus-displacement, which we denote as $[\\mathrm{B} + \\mathrm{I} \\ll s + d]$, where $\\mathrm{B}$ is a base register, $\\mathrm{I}$ is an index register, $s$ is a small nonnegative shift amount, and $d$ is a small displacement. The machine also supports post-increment addressing of the form $[\\mathrm{B}]^{+}$ that updates $\\mathrm{B}$ by a small stride after the memory access. Assume that the compiler’s backend performs instruction selection before register allocation but may use a cost model that estimates register pressure during selection. Register pressure is defined as the maximum, over program points, of the number of simultaneously live temporaries, that is, $\\max_{t} \\left|L(t)\\right|$, where $L(t)$ is the set of IR temporaries live at program point $t$. \n\nConsider the following loop in a high-level language, which the frontend has lowered into a three-address IR in Static Single Assignment (SSA) form:\nThere are arrays $A$ and $B$, a loop index $i$, a loop bound $N$, and a scalar accumulator $s$ initially equal to $0$. The loop body computes $s \\leftarrow s + A[i] + B[2 \\cdot i + c]$ and then increments $i$ by $1$ until $i = N$. Here $c$ is a compile-time constant. The base addresses of $A$ and $B$ reside in dedicated temporaries $\\mathrm{baseA}$ and $\\mathrm{baseB}$, and the element size is such that a shift $s$ can encode the scale for $i$.\n\nAt a hot loop header, due to the Application Binary Interface (ABI) constraints and co-resident values, there are only $4$ allocatable general-purpose registers available for the loop body. The backend must choose for each array access either:\n- to materialize the effective address in a separate temporary (for example, compute $\\mathrm{addr} \\leftarrow \\mathrm{baseB} + (i \\ll s) + d$ using arithmetic instructions, then load from $[\\mathrm{addr}]$), or\n- to fold the address computation into the memory operation by using the complex addressing mode $[\\mathrm{baseB} + i \\ll s + d]$, or\n- when legal, to use a post-increment form to update the base after the access and avoid explicit induction-variable updates.\n\nSelect all statements that are correct about how a well-designed backend selects instruction forms based on addressing modes and about a scenario in which complex addressing reduces register pressure.\n\nA. A cost model that combines estimated cycle costs with a register-pressure term can prefer a complex addressing form because folding $[\\mathrm{baseB} + i \\ll s + d]$ into the load removes the temporary that would otherwise hold the effective address, reducing the maximum number of simultaneously live temporaries and potentially avoiding a spill when only $4$ registers are allocatable.\n\nB. Complex addressing always reduces the dynamic instruction count and therefore is always preferred regardless of microarchitectural costs or register-pressure effects.\n\nC. In a loop that linearly traverses $A$ (for example, loading $A[i]$ each iteration), using a post-increment addressing mode for $A$ can reduce register pressure by keeping the evolving pointer in a single physical register and eliminating a separate add instruction and the live temporary it would create for the updated pointer.\n\nD. The decision between folding and materializing effective addresses cannot be made until after register allocation, because only a final physical register assignment reveals spills; therefore, instruction selection must be deferred until after register allocation.\n\nE. If the target lacks base-plus-index folding for $B[2 \\cdot i + c]$ but has a load-effective-address instruction that computes the address without memory traffic, the backend should prefer materializing the address in a separate temporary to increase instruction-level parallelism even when this pushes the live temporaries above the $4$ available registers and forces a spill, as the increased parallelism dominates spill costs in general.", "solution": "This problem tests the understanding of trade-offs made during the instruction selection phase of a compiler, particularly regarding the use of complex addressing modes to manage register pressure. A well-designed compiler backend uses a cost model to weigh instruction performance against resource usage.\n\nLet's analyze each statement:\n\n**A. Correct.** Materializing an effective address (e.g., `addr = base + index * scale`) requires a separate temporary register to hold the `addr` value. By using a complex addressing mode (e.g., `load [base + index * scale]`), the address calculation is folded into the memory instruction. This eliminates the need for the `addr` temporary, reducing the peak number of live registers (register pressure). With a tight budget of 4 registers, this reduction can be the difference between fitting all values in registers versus requiring a costly spill to memory. A cost model that accounts for register pressure would favor this choice to avoid spills.\n\n**B. Incorrect.** The statement \"always preferred\" is too strong. While complex addressing modes reduce the number of instructions, they can sometimes be slower on certain microarchitectures (e.g., have higher latency or take more cycles in the address generation unit) than a sequence of simpler, faster arithmetic instructions. A sophisticated compiler's cost model considers these microarchitectural details, not just the static instruction count.\n\n**C. Correct.** Post-increment addressing (`[ptr]^+`) combines a memory access with a pointer update in a single instruction. The alternative is to use a separate `add` instruction to compute the next address (`ptr_next = ptr + stride`). This `add` creates a new temporary (`ptr_next`), increasing register pressure. The post-increment mode updates the pointer register in place, eliminating both the separate `add` instruction and the extra temporary, thus reducing register pressure.\n\n**D. Incorrect.** The dominant design in modern compilers (like LLVM and GCC) is to perform instruction selection *before* register allocation. Instruction selection does not operate blindly; it uses a cost model that *estimates* register pressure based on the number of live virtual registers. This estimate is used to guide the choice of instructions to minimize the chance of spills later on. Reversing the phases can lead to suboptimal code, as the register allocator would not know the constraints of the instructions yet to be selected.\n\n**E. Incorrect.** This statement claims that the benefit of increased Instruction-Level Parallelism (ILP) from separating an address calculation from a load \"dominates spill costs in general.\" This is fundamentally false. A register spill involves memory operations (store and load), which have very high latency (tens to hundreds of cycles). The ILP gain from separating two dependent instructions is typically a few cycles at most. The penalty of a spill almost always outweighs such minor ILP gains, making it a poor trade-off, especially in a hot loop.\n\nTherefore, the correct statements are A and C.", "answer": "$$\\boxed{AC}$$", "id": "3674621"}]}