{"hands_on_practices": [{"introduction": "Many boundary value problems in astrophysics, particularly those involving stellar structure or gravitational fields, are formulated in spherical coordinates. This often leads to ordinary differential equations with terms like $\\frac{2}{r} y'(r)$, which are singular at the origin $r=0$. This exercise guides you through the essential analytical technique of finding a series solution near such a regular singular point, a crucial first step before any numerical integration can begin. Mastering this method allows you to enforce physical regularity conditions and generate accurate starting points for your numerical solver.", "problem": "In computational astrophysics, spherically symmetric scalar fields governed by linear physics often reduce to an Ordinary Differential Equation (ODE) involving the radial part of the three-dimensional Laplacian. For a spherically symmetric scalar field $y(r)$, the radial Laplacian is $\\nabla^{2} y = y'' + \\frac{2}{r} y'$, derived from the divergence theorem in spherical coordinates under spherical symmetry. Consider the Boundary Value Problem (BVP) near the stellar center ($r=0$) for the linear ODE\n$$\ny''(r) + \\frac{2}{r} y'(r) + q(r)\\,y(r) = f(r),\n$$\nwhere $q(r)$ and $f(r)$ are analytic functions of $r$ in a neighborhood of $r=0$ and encode background coefficients and source terms, respectively. Assume the Taylor expansions\n$$\nq(r) = q_{0} + q_{1} r + q_{2} r^{2} + q_{3} r^{3} + q_{4} r^{4} + O(r^{5}),\n\\qquad\nf(r) = f_{0} + f_{1} r + f_{2} r^{2} + f_{3} r^{3} + f_{4} r^{4} + O(r^{5}),\n$$\nwith constants $q_{0}, q_{1}, q_{2}, q_{3}, q_{4}$ and $f_{0}, f_{1}, f_{2}, f_{3}, f_{4}$, and seek a local analytic series solution of the form\n$$\ny(r) = a_{0} + a_{1} r + a_{2} r^{2} + a_{3} r^{3} + a_{4} r^{4} + O(r^{5})\n$$\nthat is consistent with central regularity at $r=0$ (that is, $y(r)$ remains finite and the operator $y'' + \\frac{2}{r} y'$ has no singularity at $r=0$). Starting from the fundamental identity for the radial Laplacian and the given ODE, enforce the central regularity condition and derive the recurrence relations by substituting the series expansions and matching coefficients of like powers of $r$ up to order $O(r^{4})$ in the ODE. Provide explicit analytic expressions for $a_{1}$, $a_{2}$, $a_{3}$, and $a_{4}$ in terms of $a_{0}$ and the Taylor coefficients $q_{0}, q_{1}, q_{2}, q_{3}, q_{4}$ and $f_{0}, f_{1}, f_{2}, f_{3}, f_{4}$. Express your final answer as a single row matrix containing $a_{1}$, $a_{2}$, $a_{3}$, and $a_{4}$. No rounding is required and no physical units should appear in the final expression.", "solution": "The problem as stated is valid. It is a well-posed mathematical problem grounded in the standard physical context of differential equations in computational astrophysics. The problem is self-contained, objective, and its solution can be derived through rigorous mathematical procedures.\n\nThe given ordinary differential equation (ODE) is\n$$\ny''(r) + \\frac{2}{r} y'(r) + q(r)\\,y(r) = f(r)\n$$\nwhere $r$ is the radial coordinate. The functions $q(r)$, $f(r)$, and the solution $y(r)$ are assumed to be analytic around $r=0$ and can be represented by their Taylor series expansions:\n$$\nq(r) = \\sum_{n=0}^{\\infty} q_n r^n = q_{0} + q_{1} r + q_{2} r^{2} + \\dots\n$$\n$$\nf(r) = \\sum_{n=0}^{\\infty} f_n r^n = f_{0} + f_{1} r + f_{2} r^{2} + \\dots\n$$\n$$\ny(r) = \\sum_{n=0}^{\\infty} a_n r^n = a_{0} + a_{1} r + a_{2} r^{2} + a_{3} r^{3} + \\dots\n$$\nThe derivatives of $y(r)$ are given by the series:\n$$\ny'(r) = \\sum_{n=1}^{\\infty} n a_n r^{n-1} = a_1 + 2a_2 r + 3a_3 r^2 + \\dots\n$$\n$$\ny''(r) = \\sum_{n=2}^{\\infty} n(n-1) a_n r^{n-2} = 2a_2 + 6a_3 r + 12a_4 r^2 + \\dots\n$$\nThe point $r=0$ is a regular singular point of the ODE. The condition of \"central regularity\" requires that the solution $y(r)$ remains finite at $r=0$ and that the operator term $y'' + \\frac{2}{r} y'$ does not introduce a singularity. Let us analyze this operator term by substituting the series for $y'(r)$:\n$$\n\\frac{2}{r} y'(r) = \\frac{2}{r} \\left( a_1 + 2a_2 r + 3a_3 r^2 + \\dots \\right) = \\frac{2a_1}{r} + 4a_2 + 6a_3 r + \\dots\n$$\nFor the operator $y'' + \\frac{2}{r} y'$ to be regular (non-singular) at $r=0$, the term proportional to $r^{-1}$ must vanish. All other terms in the ODE expansion are of order $r^0$ or higher. Thus, we must enforce the condition:\n$$\n2a_1 = 0 \\implies a_1 = 0\n$$\nThis is the mathematical manifestation of the central regularity condition for this problem, equivalent to requiring the first derivative of the scalar field to vanish at the center, $y'(0)=0$.\n\nWith $a_1=0$, the series for $y(r)$ and its derivatives simplify. We substitute these into the ODE. To facilitate matching coefficients, we can rewrite the ODE as:\n$$\ny''(r) + \\frac{2}{r} y'(r) = f(r) - q(r)y(r)\n$$\nLet's expand the left-hand side (LHS) and right-hand side (RHS) in powers of $r$.\nThe LHS becomes:\n$$\n\\text{LHS} = \\left( 2a_2 + 6a_3 r + 12a_4 r^2 + \\dots \\right) + \\frac{2}{r} \\left( 2a_2 r + 3a_3 r^2 + 4a_4 r^3 + \\dots \\right)\n$$\n$$\n\\text{LHS} = \\left( 2a_2 + 6a_3 r + 12a_4 r^2 + \\dots \\right) + \\left( 4a_2 + 6a_3 r + 8a_4 r^2 + \\dots \\right)\n$$\n$$\n\\text{LHS} = 6a_2 + 12a_3 r + 20a_4 r^2 + \\dots = \\sum_{n=0}^{\\infty} (n+2)(n+3) a_{n+2} r^n\n$$\nThe RHS involves the product of the series for $q(r)$ and $y(r)$, remembering that $a_1=0$:\n$$\nq(r)y(r) = (q_0 + q_1 r + q_2 r^2 + \\dots)(a_0 + a_2 r^2 + a_3 r^3 + \\dots)\n$$\nExpanding this product up to the $r^2$ term:\n\\begin{itemize}\n    \\item Power $r^0$: $q_0 a_0$\n    \\item Power $r^1$: $q_1 a_0$\n    \\item Power $r^2$: $q_2 a_0 + q_0 a_2$\n\\end{itemize}\nSo the expansion for the RHS is:\n$$\n\\text{RHS} = (f_0 + f_1 r + f_2 r^2 + \\dots) - (q_0 a_0 + q_1 a_0 r + (q_2 a_0 + q_0 a_2) r^2 + \\dots)\n$$\n$$\n\\text{RHS} = (f_0 - q_0 a_0) + (f_1 - q_1 a_0) r + (f_2 - q_2 a_0 - q_0 a_2) r^2 + \\dots\n$$\nBy equating the coefficients of like powers of $r$ from the LHS and RHS, we derive the recurrence relations for the coefficients $a_n$.\n\nCoefficient of $r^0$:\n$$\n6a_2 = f_0 - q_0 a_0 \\implies a_2 = \\frac{1}{6}(f_0 - q_0 a_0)\n$$\n\nCoefficient of $r^1$:\n$$\n12a_3 = f_1 - q_1 a_0 \\implies a_3 = \\frac{1}{12}(f_1 - q_1 a_0)\n$$\n\nCoefficient of $r^2$:\n$$\n20a_4 = f_2 - q_2 a_0 - q_0 a_2\n$$\nWe substitute the expression for $a_2$ into this equation:\n$$\n20a_4 = f_2 - q_2 a_0 - q_0 \\left( \\frac{1}{6}(f_0 - q_0 a_0) \\right)\n$$\n$$\n20a_4 = f_2 - q_2 a_0 - \\frac{1}{6} q_0 f_0 + \\frac{1}{6} q_0^2 a_0\n$$\n$$\na_4 = \\frac{1}{20} \\left( f_2 - \\frac{1}{6} q_0 f_0 + a_0 \\left( \\frac{1}{6} q_0^2 - q_2 \\right) \\right)\n$$\nTo write this in a more compact form, we find a common denominator:\n$$\na_4 = \\frac{1}{20} \\left( \\frac{6f_2 - q_0 f_0}{6} + a_0 \\frac{q_0^2 - 6q_2}{6} \\right)\n$$\n$$\na_4 = \\frac{1}{120} \\left( 6f_2 - q_0 f_0 + a_0 (q_0^2 - 6q_2) \\right)\n$$\nIn summary, the coefficients are:\n\\begin{itemize}\n    \\item $a_1 = 0$\n    \\item $a_2 = \\frac{1}{6}(f_0 - q_0 a_0)$\n    \\item $a_3 = \\frac{1}{12}(f_1 - q_1 a_0)$\n    \\item $a_4 = \\frac{1}{120} \\left[ 6f_2 - q_0 f_0 + a_0 (q_0^2 - 6q_2) \\right]$\n\\end{itemize}\nThese expressions provide the first few coefficients of the regular series solution at the origin in terms of the initial value $a_0 = y(0)$ and the series coefficients of the known functions $q(r)$ and $f(r)$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 0  \\frac{1}{6}(f_0 - q_0 a_0)  \\frac{1}{12}(f_1 - q_1 a_0)  \\frac{1}{120} \\left[ 6f_2 - q_0 f_0 + a_0 (q_0^2 - 6q_2) \\right] \\end{pmatrix}}\n$$", "id": "3527899"}, {"introduction": "While linear boundary value problems can often be solved with finite difference methods, many real-world astrophysical systems are governed by nonlinear equations. This practice introduces the powerful shooting method, combined with Newton's method, to tackle such problems. You will derive the necessary sensitivity equations from first principles, which is key to finding the correct \"shot\" efficiently, and then construct a complete algorithm to solve a nonlinear BVP representative of radiative-conductive equilibrium.", "problem": "Consider a simplified, nondimensional model of steady one-dimensional radiative-conductive equilibrium relevant to computational astrophysics. In this model, the dimensionless temperature profile $y(x)$ on the slab $x \\in [0,1]$ is governed by the nonlinear ordinary differential equation $y''(x) + \\alpha y(x)^3 = 0$, where $\\alpha \\ge 0$ is a given dimensionless parameter that encodes the relative strength of volumetric cooling to conduction. The boundary conditions are $y(0) = a$ and $y(1) = b$, where $a$ and $b$ are prescribed dimensionless boundary temperatures. All variables and parameters are nondimensional, and no physical units are required.\n\nYou will use the shooting method with Newton updates to satisfy the right boundary condition at $x=1$. Introduce the first-order system by defining $v(x) = y'(x)$ and treating the unknown initial slope $s = y'(0)$ as the shooting parameter. For any value of $s$, the initial value problem is\n$y'(x) = v(x)$, $v'(x) = -\\alpha y(x)^3$, with $y(0) = a$ and $v(0) = s$,\nwhich yields a terminal value $y(1;s)$. Define the scalar boundary residual $R(s) = y(1;s) - b$. A root $s^\\star$ of $R(s)$ enforces the right boundary condition $y(1) = b$.\n\nTask 1 (Derivation): Starting only from the first-order system and the definition of the sensitivity $z(x) = \\partial y(x;s)/\\partial s$, derive the initial value problem that $z(x)$ satisfies, including all required initial conditions. Your derivation must proceed from the chain rule and the linearization of the right-hand side with respect to the state variables, without invoking any prepackaged sensitivity formulas.\n\nTask 2 (Algorithm design): Using your derived sensitivity equation, express the Newton update for $s$ in terms of $R(s)$ and the sensitivity $z(x)$. Specify precisely which quantity evaluated at $x=1$ enters the update and why. Then outline a numerically stable algorithm that:\n- integrates the coupled state and sensitivity equations from $x=0$ to $x=1$ for a given $s$,\n- computes a Newton step for $s$ using the sensitivity,\n- applies basic damping if necessary to ensure residual decrease,\n- and terminates when $|R(s)|  \\varepsilon$ for a specified tolerance $\\varepsilon$.\n\nTask 3 (Implementation and test suite): Implement a complete, runnable program that:\n- Integrates the coupled system for $(y,v)$ and the sensitivity for $z$ required by your Newton update over $x \\in [0,1]$ for each test case,\n- Uses Newton’s method with simple backtracking damping and a maximum of $50$ iterations to find $s^\\star$ such that $|R(s^\\star)|  10^{-10}$, starting from the initial guess $s_0 = b - a$,\n- Produces as output the list of converged shooting parameters `[s_1^\\star, s_2^\\star, s_3^\\star]` for the following three test cases (each specified by $(\\alpha, a, b)$):\n  1. $(\\alpha, a, b) = (0.0, 1.0, 0.2)$,\n  2. $(\\alpha, a, b) = (2.0, 1.0, 0.5)$,\n  3. $(\\alpha, a, b) = (10.0, 1.0, 0.2)$.\n\nAll variables are dimensionless. Your program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, `[s_1^\\star,s_2^\\star,s_3^\\star]`. The entries must be floating-point numbers. Do not print any additional text.", "solution": "The user-provided problem has been validated and is determined to be a valid, well-posed problem in computational science. It is scientifically grounded as a simplified model of physical phenomena, mathematically consistent, complete in its specification, and free from ambiguity or subjective content. We may therefore proceed with a solution.\n\nThe problem requires solving the nonlinear two-point boundary value problem (BVP) given by the ordinary differential equation (ODE)\n$$\ny''(x) + \\alpha y(x)^3 = 0, \\quad x \\in [0,1]\n$$\nwith boundary conditions $y(0) = a$ and $y(1) = b$. The parameter $\\alpha \\ge 0$ is a given constant. The solution will be found using the shooting method, where the BVP is converted into an initial value problem (IVP) whose solution is driven to satisfy the boundary condition at $x=1$ via Newton's method.\n\n### Task 1: Derivation of the Sensitivity Equation\n\nThe second-order ODE is first converted into a system of two first-order ODEs. Let $y(x)$ be the dimensionless temperature and $v(x) = y'(x)$ be its spatial derivative. The system is:\n$$\n\\begin{cases}\ny'(x) = v(x) \\\\\nv'(x) = -\\alpha y(x)^3\n\\end{cases}\n$$\nThe shooting method treats the unknown initial slope $s = y'(0) = v(0)$ as a parameter to be found. The initial conditions for the IVP are therefore:\n$$\n\\begin{cases}\ny(0;s) = a \\\\\nv(0;s) = s\n\\end{cases}\n$$\nwhere the notation emphasizes the dependence of the solution on the parameter $s$.\n\nThe sensitivity of the solution with respect to $s$ is required for Newton's method. We define the sensitivity functions for $y$ and $v$ as:\n$$\nz(x) = \\frac{\\partial y(x;s)}{\\partial s}, \\quad w(x) = \\frac{\\partial v(x;s)}{\\partial s}\n$$\nTo find the differential equations governing $z(x)$ and $w(x)$, we differentiate the first-order system with respect to $s$. Assuming sufficient smoothness of the solutions, we can interchange the order of differentiation with respect to $x$ and $s$:\n$$\n\\frac{d}{dx}\\left(\\frac{\\partial y}{\\partial s}\\right) = \\frac{\\partial}{\\partial s}(v) \\implies z'(x) = w(x)\n$$\n$$\n\\frac{d}{dx}\\left(\\frac{\\partial v}{\\partial s}\\right) = \\frac{\\partial}{\\partial s}(-\\alpha y^3) \\implies w'(x) = -\\alpha \\frac{\\partial(y^3)}{\\partial s}\n$$\nUsing the chain rule for the second equation:\n$$\nw'(x) = -\\alpha \\left(\\frac{d(y^3)}{dy} \\frac{\\partial y}{\\partial s}\\right) = -\\alpha (3y^2) z(x) = -3\\alpha y(x)^2 z(x)\n$$\nThis gives the system of linear ODEs for the sensitivities:\n$$\n\\begin{cases}\nz'(x) = w(x) \\\\\nw'(x) = -3\\alpha y(x)^2 z(x)\n\\end{cases}\n$$\nThe initial conditions for this system are found by differentiating the IVP's initial conditions with respect to $s$:\n$$\nz(0) = \\frac{\\partial y(0;s)}{\\partial s} = \\frac{\\partial (a)}{\\partial s} = 0\n$$\n$$\nw(0) = \\frac{\\partial v(0;s)}{\\partial s} = \\frac{\\partial (s)}{\\partial s} = 1\n$$\nCombining the two first-order sensitivity equations, we obtain the requested second-order initial value problem for $z(x)$:\n$$\nz''(x) + 3\\alpha y(x)^2 z(x) = 0\n$$\nwith initial conditions $z(0) = 0$ and $z'(0) = 1$. This is a linear, homogeneous ODE for $z(x)$, but its coefficient, $3\\alpha y(x)^2$, depends on the solution of the original nonlinear state equation. Therefore, the state system and the sensitivity system must be integrated simultaneously.\n\n### Task 2: Algorithm Design\n\nThe shooting method aims to find a root $s^\\star$ of the scalar residual function $R(s)$, defined as the difference between the computed and desired values at the right boundary:\n$$\nR(s) = y(1;s) - b\n$$\nWe seek $s^\\star$ such that $R(s^\\star) = 0$. Newton's method provides an iterative scheme for finding this root:\n$$\ns_{k+1} = s_k - \\frac{R(s_k)}{R'(s_k)}\n$$\nwhere $s_k$ is the estimate of $s^\\star$ at iteration $k$. The derivative $R'(s)$ is found by differentiating the residual function with respect to $s$:\n$$\nR'(s) = \\frac{d}{ds} \\left( y(1;s) - b \\right) = \\frac{\\partial y(1;s)}{\\partial s}\n$$\nBy the definition of the sensitivity $z(x)$, this derivative is precisely the value of $z$ at $x=1$:\n$$\nR'(s) = z(1;s)\n$$\nThus, the specific quantity evaluated at $x=1$ that enters the update is $z(1)$, the sensitivity of the terminal temperature to the initial slope. The Newton update formula is:\n$$\ns_{k+1} = s_k - \\frac{y(1;s_k) - b}{z(1;s_k)}\n$$\nThe complete, numerically stable algorithm is as follows:\n\n1.  **Initialization**:\n    - Set the tolerance $\\varepsilon = 10^{-10}$ and maximum iterations $N_{\\text{max}} = 50$.\n    - Set the initial guess for the shooting parameter: $s_0 = b - a$.\n    - Set the iteration counter $k = 0$.\n\n2.  **Newton Iteration Loop**: For $k=0, 1, 2, \\dots, N_{\\text{max}}-1$:\n    a. **Coupled System Integration**: Define the augmented state vector $\\mathbf{U}(x) = [y(x), v(x), z(x), w(x)]^T$. The governing system is a set of four first-order ODEs:\n       $$\n       \\mathbf{U}'(x) = \\begin{bmatrix} v \\\\ -\\alpha y^3 \\\\ w \\\\ -3\\alpha y^2 z \\end{bmatrix}\n       $$\n       Integrate this system over the domain $x \\in [0, 1]$ with the initial condition $\\mathbf{U}(0) = [a, s_k, 0, 1]^T$. A high-quality adaptive solver (like a Runge-Kutta method) is used. Let the solution at $x=1$ be $\\mathbf{U}(1) = [y_1, v_1, z_1, w_1]^T$.\n\n    b. **Convergence Check**: Compute the residual $R(s_k) = y_1 - b$. If $|R(s_k)|  \\varepsilon$, the iteration has converged. Terminate and return $s_k$ as the solution $s^\\star$.\n\n    c. **Newton Step Calculation**: Compute the full Newton step $\\Delta s = -R(s_k) / z_1$.\n\n    d. **Damping (Backtracking Line Search)**: To ensure that the step reduces the magnitude of the residual, a backtracking strategy is employed.\n       i. Start with a damping factor $\\lambda = 1$.\n       ii. For a fixed number of attempts, propose a trial update $s_{\\text{trial}} = s_k + \\lambda \\Delta s$.\n       iii. To evaluate the new residual $R(s_{\\text{trial}})$, integrate only the original $2 \\times 2$ state system ($y', v'$) with the initial slope $s_{\\text{trial}}$. Let this give $y_{\\text{trial}}(1)$. The new residual is $R(s_\\text{trial}) = y_{\\text{trial}}(1) - b$.\n       iv. If $|R(s_\\text{trial})|  |R(s_k)|$, accept the step by setting $s_{k+1} = s_{\\text{trial}}$ and break the backtracking loop.\n       v. If the step is not accepted, reduce the damping factor (e.g., $\\lambda \\leftarrow \\lambda/2$) and repeat from (ii).\n       vi. If the backtracking loop completes without finding an improved step, take the smallest attempted step as a precaution.\n\n    e. **Update**: Set $s_k \\leftarrow s_{k+1}$ and continue to the next iteration.\n\n3.  **Termination**: If the loop completes without convergence, report that the method failed to converge within the specified number of iterations.\n\n### Task 3: Implementation\n\nThe algorithm described above is implemented in Python using the `numpy` and `scipy` libraries. The function `scipy.integrate.solve_ivp` with the `RK45` method and stringent tolerances is used for numerical integration. The implementation is tested against the three specified cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef solve_case(alpha, a, b):\n    \"\"\"\n    Solves the BVP for a given set of parameters (alpha, a, b) using a Newton-Raphson\n    shooting method with sensitivity analysis and backtracking line search.\n    \"\"\"\n    TOL = 1e-10\n    MAX_ITER = 50\n    s_k = float(b - a)  # Initial guess for the shooting parameter y'(0)\n\n    def state_rhs(x, u, alpha_val):\n        \"\"\"ODE system for state variables [y, v] only.\"\"\"\n        y, v = u\n        return [v, -alpha_val * y**3]\n\n    def compute_residual(s_val, alpha_val, a_val, b_val):\n        \"\"\"Computes the boundary residual R(s) = y(1;s) - b for a given s.\"\"\"\n        u0 = [a_val, s_val]\n        sol = solve_ivp(\n            state_rhs, [0, 1], u0, args=(alpha_val,), \n            method='RK45', atol=1e-12, rtol=1e-12\n        )\n        y1 = sol.y[0, -1]\n        return y1 - b_val\n\n    def coupled_rhs(x, U, alpha_val):\n        \"\"\"Coupled ODE system for state [y,v] and sensitivity [z,w].\"\"\"\n        y, v, z, w = U\n        dy_dx = v\n        dv_dx = -alpha_val * y**3\n        dz_dx = w\n        dw_dx = -3 * alpha_val * y**2 * z\n        return [dy_dx, dv_dx, dz_dx, dw_dx]\n\n    for k in range(MAX_ITER):\n        # 1. Integrate the coupled state and sensitivity system\n        U0 = [a, s_k, 0.0, 1.0]\n        sol = solve_ivp(\n            coupled_rhs, [0, 1], U0, args=(alpha,), \n            method='RK45', atol=1e-12, rtol=1e-12\n        )\n        y1, _, z1, _ = sol.y[:, -1]\n\n        # 2. Compute residual and check for convergence\n        residual = y1 - b\n        if abs(residual)  TOL:\n            return s_k\n\n        # 3. Compute Newton step\n        deriv = z1  # R'(s) = z(1)\n        if abs(deriv)  1e-14:\n            raise RuntimeError(f\"Shooting method failed: derivative is near zero for case {(alpha, a, b)}.\")\n        \n        ds = -residual / deriv\n\n        # 4. Damping with backtracking line search\n        current_residual_norm = abs(residual)\n        lambda_val = 1.0\n        \n        # Backtracking loop to find a step that decreases the residual norm\n        for _ in range(10): # At most 10 backtracking steps\n            s_trial = s_k + lambda_val * ds\n            trial_residual = compute_residual(s_trial, alpha, a, b)\n            \n            if abs(trial_residual)  current_residual_norm:\n                s_k = s_trial\n                break # Accepted step\n            \n            lambda_val /= 2.0\n        else:\n            # If no step reduction worked, take the smallest one attempted\n            s_k = s_k + lambda_val * ds\n\n    raise RuntimeError(f\"Newton's method did not converge within {MAX_ITER} iterations for case {(alpha, a, b)}.\")\n\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0.0, 1.0, 0.2),\n        (2.0, 1.0, 0.5),\n        (10.0, 1.0, 0.2),\n    ]\n\n    results = []\n    for case in test_cases:\n        alpha, a, b = case\n        s_star = solve_case(alpha, a, b)\n        results.append(s_star)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.15f}' for r in results)}]\")\n\nsolve()\n```", "id": "3527875"}, {"introduction": "A crucial part of mastering numerical methods is understanding their failure modes. This exercise explores a classic scenario where the shooting method breaks down not due to numerical instability, but because of the underlying mathematical structure of the boundary value problem itself. By analyzing a simple linear ODE, you will discover how the existence of non-unique solutions, a hallmark of eigenvalue problems, renders the standard shooting approach indeterminate and learn to identify the need for reformulating the problem.", "problem": "Consider the boundary value problem (BVP) for the ordinary differential equation (ODE) $y'' + \\pi^2 y = 0$ subject to $y(0)=0$ and $y(1)=0$. In the classical shooting method, one replaces the BVP by an initial value problem (IVP) with an unknown initial slope $s$, namely $y'' + \\pi^2 y = 0$, $y(0)=0$, $y'(0)=s$, and defines the target function $F(s)$ as the terminal mismatch $F(s) = y(1;s) - 0$, where $y(x;s)$ denotes the IVP solution obtained by integrating from $x=0$ to $x=1$. A derivative $F'(s)$ for use in a Newton update can be obtained by differentiating the ODE with respect to $s$ to form the variational (sensitivity) equation for $z(x) = \\partial y/\\partial s$ with initial data $z(0)=0$, $z'(0)=1$.\n\nBased on first principles of linear ODE theory, uniqueness of IVPs, and the definition of the shooting map $s \\mapsto F(s)$ and its derivative via the variational equation, determine which of the following statements are correct for this problem.\n\nA. For every $s \\in \\mathbb{R}$, the value $F(s)$ is equal to $0$. Consequently, Newton and secant shooting updates are undefined or indeterminate, and this reflects a genuine nonuniqueness of the underlying BVP.\n\nB. The failure of Newton shooting here is primarily due to numerical stiffness. Reducing the IVP solver step size or tolerance will generically make $F'(s) \\neq 0$ and restore convergence.\n\nC. The derivative $F'(s)$ equals $z(1)$, where $z$ satisfies the variational equation $z'' + \\pi^2 z = 0$ with $z(0)=0$, $z'(0)=1$, and in this case $F'(s)=0$. Therefore, the Jacobian required by Newton’s method is singular.\n\nD. Switching to multiple shooting without changing the mathematical formulation resolves the ambiguity and yields a unique $s$ because the additional continuity conditions eliminate the nonuniqueness.\n\nE. A consistent remedy is to augment the problem to remove the amplitude indeterminacy, for example by treating $\\lambda$ in $y'' + \\lambda y = 0$ as an unknown and adding a normalization such as $\\|y\\|_2 = \\left(\\int_0^1 y(x)^2\\,dx\\right)^{1/2} = 1$. One can then apply a two-parameter shooting method in $(s,\\lambda)$ to obtain a well-posed system that determines both an eigenvalue and a normalized eigenfunction.", "solution": "The user has provided a problem concerning the application of the shooting method to a linear boundary value problem.\n\n### Step 1: Extract Givens\n- The Boundary Value Problem (BVP) is the ordinary differential equation (ODE) $y'' + \\pi^2 y = 0$ with boundary conditions $y(0)=0$ and $y(1)=0$.\n- The shooting method converts this to an Initial Value Problem (IVP): $y'' + \\pi^2 y = 0$, with initial conditions $y(0)=0$ and $y'(0)=s$, where $s$ is an unknown initial slope.\n- The target function to be zeroed is $F(s) = y(1;s)$, where $y(x;s)$ is the solution of the IVP. The target value is $0$.\n- The derivative $F'(s)$ is obtained from the variational (sensitivity) equation for $z(x) = \\partial y/\\partial s$. The problem states this equation is derived by differentiating the ODE with respect to $s$ and that the initial conditions for $z(x)$ are $z(0)=0$ and $z'(0)=1$.\n- It is given that $F'(s) = z(1)$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement describes a standard, textbook example of applying the shooting method to a linear homogeneous BVP which is also a simple eigenvalue problem.\n- **Scientifically Grounded (Critical):** Yes. The problem is based entirely on established principles of ordinary differential equations, boundary value problems, and numerical methods (specifically the shooting method and Newton's method). The given ODE is the simple harmonic oscillator equation, and the BVP is a Sturm-Liouville eigenvalue problem.\n- **Well-Posed:** Yes. The problem statement itself is well-posed. It asks for an analysis of the behavior of a specific numerical method applied to a specific, well-defined mathematical problem. The properties of the underlying BVP (e.g., non-uniqueness of its solution) are the subject of the inquiry, not a flaw in the problem statement.\n- **Objective (Critical):** Yes. The language is formal, precise, and free of any subjective or ambiguous terminology.\n- **Completeness and Consistency:** The problem provides all necessary definitions and equations to perform the requested analysis. The ODE, boundary conditions, and the setup of the shooting method, including the variational equation, are all clearly specified and are mutually consistent.\n- **Other Flaws:** The problem does not exhibit any of the other flaws listed in the validation criteria. It is a formal, verifiable, and non-trivial question within the field of numerical analysis.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. A full solution and evaluation of options will be performed.\n\n### Derivation\nFirst, we analyze the IVP associated with the shooting method:\n$y'' + \\pi^2 y = 0$, with $y(0)=0$ and $y'(0)=s$.\nThe characteristic equation is $r^2 + \\pi^2 = 0$, which gives roots $r = \\pm i\\pi$.\nThe general solution to the ODE is $y(x) = C_1 \\cos(\\pi x) + C_2 \\sin(\\pi x)$.\nWe apply the initial conditions:\n$1$. $y(0)=0 \\implies C_1 \\cos(0) + C_2 \\sin(0) = C_1 = 0$.\nThe solution is thus of the form $y(x) = C_2 \\sin(\\pi x)$.\n$2$. $y'(x) = \\pi C_2 \\cos(\\pi x)$. So, $y'(0)=s \\implies \\pi C_2 \\cos(0) = \\pi C_2 = s$, which means $C_2 = s/\\pi$.\nThe solution to the IVP, denoted by $y(x;s)$, is:\n$$y(x;s) = \\frac{s}{\\pi} \\sin(\\pi x)$$\n\nNext, we define the target function $F(s)$:\n$F(s) = y(1;s)$, where the shooting method aims to find $s$ such that $F(s)=0$.\nSubstituting $x=1$ into the IVP solution:\n$$F(s) = y(1;s) = \\frac{s}{\\pi} \\sin(\\pi \\cdot 1) = \\frac{s}{\\pi} \\sin(\\pi) = \\frac{s}{\\pi} \\cdot 0 = 0$$\nThis shows that $F(s)=0$ for all possible values of the initial slope $s \\in \\mathbb{R}$.\n\nNow, we analyze the derivative of the target function, $F'(s)$. The problem states this is found using the variational equation for $z(x) = \\partial y/\\partial s$.\nThe IVP for $z(x)$ is given as:\n$z'' + \\pi^2 z = 0$, with $z(0)=0$ and $z'(0)=1$.\nThis is the same ODE as for $y(x)$, but with different initial conditions. The general solution is $z(x) = D_1 \\cos(\\pi x) + D_2 \\sin(\\pi x)$.\nApplying the initial conditions for $z(x)$:\n$1$. $z(0)=0 \\implies D_1 \\cos(0) + D_2 \\sin(0) = D_1 = 0$.\nThe solution is thus of the form $z(x) = D_2 \\sin(\\pi x)$.\n$2$. $z'(x) = \\pi D_2 \\cos(\\pi x)$. So, $z'(0)=1 \\implies \\pi D_2 \\cos(0) = \\pi D_2 = 1$, which means $D_2 = 1/\\pi$.\nThe solution to the variational IVP is:\n$$z(x) = \\frac{1}{\\pi} \\sin(\\pi x)$$\nThe derivative of the target function is $F'(s) = z(1)$.\n$$F'(s) = z(1) = \\frac{1}{\\pi} \\sin(\\pi \\cdot 1) = \\frac{1}{\\pi} \\sin(\\pi) = 0$$\nSo, the derivative $F'(s)$ is also identically zero for all $s \\in \\mathbb{R}$.\n\nThe original BVP is a linear homogeneous problem of the form $L(y) = 0$ with homogeneous boundary conditions. It has the trivial solution $y(x) \\equiv 0$. Non-trivial solutions exist if and only if the parameter $\\pi^2$ is an eigenvalue of the operator $-d^2/dx^2$ with Dirichlet boundary conditions on $[0,1]$. The eigenvalues are $(\\pi n)^2$ for $n=1, 2, 3, ...$. Since our problem uses $\\lambda = \\pi^2$ (for $n=1$), it is an eigenvalue problem being solved at an eigenvalue. The corresponding solutions (eigenfunctions) are of the form $y(x) = C \\sin(\\pi x)$ for any constant $C$. This constitutes a one-parameter family of solutions, meaning the solution to the BVP is not unique.\n\n### Option-by-Option Analysis\n\n**A. For every $s \\in \\mathbb{R}$, the value $F(s)$ is equal to $0$. Consequently, Newton and secant shooting updates are undefined or indeterminate, and this reflects a genuine nonuniqueness of the underlying BVP.**\nOur derivation shows that $F(s) = 0$ for all $s \\in \\mathbb{R}$.\nThe Newton's method update step is $s_{k+1} = s_k - F(s_k)/F'(s_k)$. Since both $F(s_k)=0$ and $F'(s_k)=0$, the update is the indeterminate form $0/0$.\nThe secant method update step is $s_{k+1} = s_k - F(s_k) \\frac{s_k - s_{k-1}}{F(s_k) - F(s_{k-1})}$. Since $F(s)$ is always $0$, the denominator is $F(s_k) - F(s_{k-1}) = 0 - 0 = 0$, making the update undefined or indeterminate.\nThe fact that $F(s)=0$ for any choice of $s$ means that any initial slope $s$ leads to a trajectory $y(x;s)$ that satisfies both boundary conditions. The family of BVP solutions is $y(x) = (s/\\pi) \\sin(\\pi x)$, where $s$ can be any real number. This is precisely the \"genuine nonuniqueness\" of the BVP solution. The statement is entirely accurate.\nVerdict: **Correct**.\n\n**B. The failure of Newton shooting here is primarily due to numerical stiffness. Reducing the IVP solver step size or tolerance will generically make $F'(s) \\neq 0$ and restore convergence.**\nThe ODE $y'' + \\pi^2 y = 0$ describes simple harmonic motion, with a smooth, non-stiff solution $y(x) \\propto \\sin(\\pi x)$. Stiffness is characterized by rapidly decaying transients or disparate time scales, which are absent here. The failure is not numerical but structural to the problem itself. Our analytical derivations show $F'(s) \\equiv 0$. Numerical errors might produce a small, non-zero machine-precision number for $F'(s)$, but this is an artifact and will not \"restore convergence\" in any meaningful way. The problem is that every $s$ is a root of $F(s)=0$, so there is no unique root to converge to.\nVerdict: **Incorrect**.\n\n**C. The derivative $F'(s)$ equals $z(1)$, where $z$ satisfies the variational equation $z'' + \\pi^2 z = 0$ with $z(0)=0$, $z'(0)=1$, and in this case $F'(s)=0$. Therefore, the Jacobian required by Newton’s method is singular.**\nThis statement correctly identifies that $F'(s)=z(1)$ based on the sensitivity equation. It also correctly states the IVP governing $z(x)$. Our derivation confirmed that the solution is $z(x)=(1/\\pi)\\sin(\\pi x)$, leading to $z(1)=0$, and thus $F'(s)=0$. For a scalar function $F(s)$, the Jacobian is the $1 \\times 1$ matrix $[F'(s)]$. Since $F'(s)=0$, the Jacobian is $[0]$, which is singular (its determinant is $0$). This accurately describes the mathematical reason for the failure of the Newton update step.\nVerdict: **Correct**.\n\n**D. Switching to multiple shooting without changing the mathematical formulation resolves the ambiguity and yields a unique $s$ because the additional continuity conditions eliminate the nonuniqueness.**\nMultiple shooting is a numerical technique designed to improve the stability of shooting methods for long integration intervals or for problems whose solutions are highly sensitive to initial conditions. It does this by breaking the interval into smaller pieces and imposing continuity at the interfaces. However, it does not change the underlying BVP. If the BVP itself has a non-unique solution (a family of solutions), the system of algebraic equations generated by the multiple shooting method will also be underdetermined, reflecting this same non-uniqueness. It cannot manufacture a unique solution where none exists. The ambiguity is inherent to the problem's formulation as an eigenvalue problem.\nVerdict: **Incorrect**.\n\n**E. A consistent remedy is to augment the problem to remove the amplitude indeterminacy, for example by treating $\\lambda$ in $y'' + \\lambda y = 0$ as an unknown and adding a normalization such as $\\|y\\|_2 = \\left(\\int_0^1 y(x)^2\\,dx\\right)^{1/2} = 1$. One can then apply a two-parameter shooting method in $(s,\\lambda)$ to obtain a well-posed system that determines both an eigenvalue and a normalized eigenfunction.**\nThis statement correctly identifies the core issue: the problem is an eigenvalue problem, and eigenfunctions are only defined up to a multiplicative constant (amplitude indeterminacy). To obtain a unique solution, one must add an additional constraint. A normalization condition, such as setting the L2-norm $\\|y\\|_2$ to $1$, is the standard way to fix the amplitude. This reframes the problem as finding an eigenpair $(\\lambda, y(x))$. A two-parameter shooting method, with unknowns such as the initial slope $s=y'(0)$ and the eigenvalue $\\lambda$, can then be used. The two target conditions would be $y(1)=0$ and $\\int_0^1 y(x)^2 dx = 1$. This creates a system of two equations for two unknowns, which is generally well-posed and can be solved with a multi-variable Newton's method to find both the eigenvalue and a unique (up to sign) normalized eigenfunction. This is the correct conceptual remedy.\nVerdict: **Correct**.", "answer": "$$\\boxed{ACE}$$", "id": "3256926"}]}