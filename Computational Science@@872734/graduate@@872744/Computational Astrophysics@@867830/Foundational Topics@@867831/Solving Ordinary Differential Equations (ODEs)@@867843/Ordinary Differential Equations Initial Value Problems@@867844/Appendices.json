{"hands_on_practices": [{"introduction": "Before deploying sophisticated ODE solvers, it is crucial to understand how they are constructed from first principles. This exercise grounds you in the Taylor series analysis that underpins the accuracy of linear multistep methods, which are workhorses in computational astrophysics for evolving everything from fluid parcels to orbital elements. By deriving the coefficients for the second-order Adams-Bashforth (explicit) and Adams-Moulton (implicit) schemes, you will gain a concrete understanding of how local accuracy is achieved and appreciate the fundamental difference between predictor and corrector formulas [@problem_id:3528239].", "problem": "In computational astrophysics, time integration of ordinary differential equations arises in tasks such as evolving the orbital separation of a compact binary under gravitational radiation reaction or the internal energy of a fluid parcel in a collapsing protostellar core. Consider a generic initial value problem for a scalar observable $y(t)$ governed by a smooth right-hand side $f(t,y)$ through the fundamental relation $y'(t) = f(t,y)$, with $y(t_0)$ given. The exact integral form over a uniform step of size $h>0$ from $t_n$ to $t_{n+1} = t_n + h$ is\n$$\ny(t_{n+1}) = y(t_n) + \\int_{t_n}^{t_{n+1}} f\\big(t, y(t)\\big)\\,dt.\n$$\nTo construct multistep formulas that are second-order accurate, postulate two quadrature ansatzes for approximating the integral $\\int_{t_n}^{t_{n+1}} f\\big(t,y(t)\\big)\\,dt$:\n\n- An explicit two-step predictor consistent with the Adams–Bashforth family that uses past samples,\n$$\n\\int_{t_n}^{t_{n+1}} f\\big(t,y(t)\\big)\\,dt \\approx h\\left[\\alpha_0\\, f\\big(t_n,y(t_n)\\big) + \\alpha_1\\, f\\big(t_{n-1},y(t_{n-1})\\big)\\right],\n$$\nwith unknown coefficients $\\alpha_0$ and $\\alpha_1$.\n\n- An implicit one-step corrector consistent with the Adams–Moulton family that uses the present and future samples,\n$$\n\\int_{t_n}^{t_{n+1}} f\\big(t,y(t)\\big)\\,dt \\approx h\\left[\\beta_0\\, f\\big(t_{n+1},y(t_{n+1})\\big) + \\beta_1\\, f\\big(t_n,y(t_n)\\big)\\right],\n$$\nwith unknown coefficients $\\beta_0$ and $\\beta_1$.\n\nUsing only the integral representation above and Taylor expansions of $f\\big(t,y(t)\\big)$ about $t_n$ along the exact solution, derive the coefficients $\\alpha_0$, $\\alpha_1$, $\\beta_0$, and $\\beta_1$ by requiring that, for any sufficiently smooth $f$, each ansatz reproduces the exact integral up to and including terms of order $h^2$ in the local truncation error (i.e., the resulting methods are of order $2$). Express your final answer as a single row matrix containing, in order, $\\alpha_0$, $\\alpha_1$, $\\beta_0$, and $\\beta_1$. No rounding is required, and report exact rational values.", "solution": "The problem requires the derivation of coefficients for two quadrature formulas used in predictor-corrector methods for solving ordinary differential equations. The derivation must ensure that the resulting numerical integration methods are second-order accurate. This is achieved by matching the Taylor series expansion of the quadrature formulas to the Taylor series expansion of the exact integral.\n\nLet the function to be integrated be denoted by $F(t) = f\\big(t, y(t)\\big)$, where $y(t)$ is the exact solution to the differential equation $y'(t) = f(t,y)$. We assume $F(t)$ is sufficiently smooth to possess the necessary derivatives. The time steps are uniform, such that $t_{k} = t_n + (k-n)h$ for an integer $k$.\n\nFirst, we expand the exact integral $I = \\int_{t_n}^{t_{n+1}} F(t)\\,dt$ in a Taylor series around the point $t_n$. To do this, we expand the integrand $F(t)$ about $t_n$:\n$$\nF(t) = F(t_n) + F'(t_n)(t-t_n) + \\frac{F''(t_n)}{2!}(t-t_n)^2 + O\\big((t-t_n)^3\\big)\n$$\nIntegrating this expansion from $t_n$ to $t_{n+1} = t_n + h$:\n$$\nI = \\int_{t_n}^{t_n+h} \\left[ F(t_n) + F'(t_n)(t-t_n) + \\frac{F''(t_n)}{2}(t-t_n)^2 + \\dots \\right] dt\n$$\n$$\nI = \\left[ F(t_n)(t-t_n) + F'(t_n)\\frac{(t-t_n)^2}{2} + F''(t_n)\\frac{(t-t_n)^3}{6} + \\dots \\right]_{t_n}^{t_n+h}\n$$\nSubstituting the limits of integration yields the series for the exact integral in powers of $h$:\n$$\nI = h F(t_n) + \\frac{h^2}{2} F'(t_n) + \\frac{h^3}{6} F''(t_n) + O(h^4)\n$$\nHere, $F(t_n)$ is used as a shorthand for $F(t_n)$, $F'(t_n)$ for $\\frac{dF}{dt}|_{t=t_n}$, and so forth. A numerical method is of order $2$ if the local truncation error is $O(h^3)$. This requires that the approximation to the integral $I$ must match the exact expansion up to the term of order $h^2$.\n\n**Derivation of the Predictor Coefficients ($\\alpha_0, \\alpha_1$)**\n\nThe explicit two-step predictor formula is given by the ansatz:\n$$\nI \\approx I_p = h\\left[\\alpha_0\\, F(t_n) + \\alpha_1\\, F(t_{n-1})\\right]\n$$\nTo create a power series in $h$ for this approximation, we expand $F(t_{n-1})$ about $t_n$. Since $t_{n-1} = t_n - h$:\n$$\nF(t_{n-1}) = F(t_n) + F'(t_n)(t_{n-1}-t_n) + O\\big((t_{n-1}-t_n)^2\\big) = F(t_n) - h F'(t_n) + O(h^2)\n$$\nSubstituting this into the expression for $I_p$:\n$$\nI_p = h\\left[\\alpha_0\\, F(t_n) + \\alpha_1\\, \\big(F(t_n) - h F'(t_n) + O(h^2)\\big)\\right]\n$$\n$$\nI_p = h\\left[(\\alpha_0 + \\alpha_1)F(t_n) - \\alpha_1 h F'(t_n) + O(h^2)\\right]\n$$\n$$\nI_p = (\\alpha_0 + \\alpha_1)h F(t_n) - \\alpha_1 h^2 F'(t_n) + O(h^3)\n$$\nFor second-order accuracy, we equate the coefficients of terms in the expansions of $I$ and $I_p$ up to order $h^2$:\n$$\nI   = 1 \\cdot h F(t_n) + \\frac{1}{2} h^2 F'(t_n) + O(h^3)\n$$\n$$\nI_p = (\\alpha_0 + \\alpha_1)h F(t_n) - \\alpha_1 h^2 F'(t_n) + O(h^3)\n$$\nComparing the coefficients of $h F(t_n)$ and $h^2 F'(t_n)$:\n1.  Coefficient of $h F(t_n)$: $1 = \\alpha_0 + \\alpha_1$\n2.  Coefficient of $h^2 F'(t_n)$: $\\frac{1}{2} = -\\alpha_1$\n\nFrom the second equation, we find $\\alpha_1 = -\\frac{1}{2}$.\nSubstituting this into the first equation: $\\alpha_0 + (-\\frac{1}{2}) = 1$, which gives $\\alpha_0 = \\frac{3}{2}$.\nThus, the coefficients for the second-order Adams-Bashforth predictor are $\\alpha_0 = \\frac{3}{2}$ and $\\alpha_1 = -\\frac{1}{2}$.\n\n**Derivation of the Corrector Coefficients ($\\beta_0, \\beta_1$)**\n\nThe implicit one-step corrector formula is given by the ansatz:\n$$\nI \\approx I_c = h\\left[\\beta_0\\, F(t_{n+1}) + \\beta_1\\, F(t_n)\\right]\n$$\nTo create a power series in $h$ for this approximation, we expand $F(t_{n+1})$ about $t_n$. Since $t_{n+1} = t_n + h$:\n$$\nF(t_{n+1}) = F(t_n) + F'(t_n)(t_{n+1}-t_n) + O\\big((t_{n+1}-t_n)^2\\big) = F(t_n) + h F'(t_n) + O(h^2)\n$$\nSubstituting this into the expression for $I_c$:\n$$\nI_c = h\\left[\\beta_0\\, \\big(F(t_n) + h F'(t_n) + O(h^2)\\big) + \\beta_1\\, F(t_n)\\right]\n$$\n$$\nI_c = h\\left[(\\beta_0 + \\beta_1)F(t_n) + \\beta_0 h F'(t_n) + O(h^2)\\right]\n$$\n$$\nI_c = (\\beta_0 + \\beta_1)h F(t_n) + \\beta_0 h^2 F'(t_n) + O(h^3)\n$$\nAgain, we equate coefficients with the expansion of the exact integral $I$:\n$$\nI   = 1 \\cdot h F(t_n) + \\frac{1}{2} h^2 F'(t_n) + O(h^3)\n$$\n$$\nI_c = (\\beta_0 + \\beta_1)h F(t_n) + \\beta_0 h^2 F'(t_n) + O(h^3)\n$$\nComparing the coefficients of $h F(t_n)$ and $h^2 F'(t_n)$:\n1.  Coefficient of $h F(t_n)$: $1 = \\beta_0 + \\beta_1$\n2.  Coefficient of $h^2 F'(t_n)$: $\\frac{1}{2} = \\beta_0$\n\nFrom the second equation, we find $\\beta_0 = \\frac{1}{2}$.\nSubstituting this into the first equation: $\\frac{1}{2} + \\beta_1 = 1$, which gives $\\beta_1 = \\frac{1}{2}$.\nThus, the coefficients for the second-order Adams-Moulton corrector (which is the trapezoidal rule) are $\\beta_0 = \\frac{1}{2}$ and $\\beta_1 = \\frac{1}{2}$.\n\nIn summary, the derived coefficients are:\n$\\alpha_0 = \\frac{3}{2}$\n$\\alpha_1 = -\\frac{1}{2}$\n$\\beta_0 = \\frac{1}{2}$\n$\\beta_1 = \\frac{1}{2}$", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{3}{2}  -\\frac{1}{2}  \\frac{1}{2}  \\frac{1}{2} \\end{pmatrix}}\n$$", "id": "3528239"}, {"introduction": "For many astrophysical problems, stability, not formal accuracy, is the limiting factor for a simulation. This is especially true for stiff systems, where physical timescales span many orders of magnitude. This practice moves from method construction to stability analysis, demonstrating how the abstract concept of a stability region has direct, practical consequences for choosing a viable timestep in a simulation of a thermonuclear flash in a degenerate stellar core [@problem_id:3528288].", "problem": "A fully implicit Backward Differentiation Formula (BDF) method is used in stiff initial value problems to advance the solution of the Dahlquist test equation $y'(t) = \\lambda y(t)$, where $\\lambda \\in \\mathbb{C}$ represents the spectrum of the linearized operator in a computational astrophysics model. Consider the second-order Backward Differentiation Formula (BDF2), defined by approximating the derivative at the new time level $t_{n+1}$ with a second-order backward difference and equating it to the right-hand side evaluated at $t_{n+1}$:\n$$\\frac{3 y_{n+1} - 4 y_n + y_{n-1}}{2 h} = f(t_{n+1}, y_{n+1}),$$\nwhere $h$ is the constant step size and $f(t, y) = \\lambda y$ for the test equation. The absolute stability region for a linear multistep method is the set of complex numbers $z = h \\lambda$ such that, for the recurrence induced by the test equation, all characteristic roots have modulus strictly less than $1$, with a simple root at $1$ at $z = 0$ permitted by zero-stability.\n\nTask 1: Derive the exact parametric expression of the absolute-stability boundary of BDF2 by assuming a characteristic root of unit modulus and expressing the boundary as $z(\\varphi)$, where $\\varphi \\in [0, 2\\pi)$ is in radians.\n\nTask 2: In degenerate core flash simulations, the diffusion-dominated thermal response can be locally linearized to $y'(t) = -\\Lambda y(t)$ with $\\Lambda  0$, reflecting strong damping of temperature perturbations on the timescale $\\Lambda^{-1}$. For operational robustness, require the per-step magnitude of the numerical amplification factor of this stiff mode to be at most $r = 0.2$. Using the BDF2 recurrence on the test equation, obtain the minimum step size $h_{\\min}$ that guarantees this per-step damping requirement for real negative $z = - h \\Lambda$. Evaluate $h_{\\min}$ for $\\Lambda = 2.0 \\times 10^{3}\\ \\text{s}^{-1}$ and round your numerical answer to four significant figures. Express $h_{\\min}$ in seconds.\n\nYour final answer must include:\n- The exact analytic expression $z(\\varphi)$ for the stability boundary in terms of $\\varphi$ in radians.\n- The rounded numerical value of $h_{\\min}$ in seconds, to four significant figures.", "solution": "The problem has been validated and is determined to be a well-posed, scientifically grounded problem in numerical analysis as applied to computational astrophysics.\n\nThe problem is divided into two tasks. The first is to derive the absolute stability boundary for the second-order Backward Differentiation Formula (BDF2). The second is to apply a specific damping requirement to determine a minimum step size for a given stiff ordinary differential equation (ODE).\n\n**Task 1: Derivation of the Absolute-Stability Boundary**\n\nThe BDF2 method is given by the recurrence relation:\n$$ \\frac{3 y_{n+1} - 4 y_n + y_{n-1}}{2 h} = f(t_{n+1}, y_{n+1}) $$\nWe analyze this method using the Dahlquist test equation, $y'(t) = \\lambda y(t)$, where $\\lambda \\in \\mathbb{C}$. For this equation, the right-hand side is $f(t_{n+1}, y_{n+1}) = \\lambda y_{n+1}$. Substituting this into the BDF2 formula gives:\n$$ \\frac{3 y_{n+1} - 4 y_n + y_{n-1}}{2 h} = \\lambda y_{n+1} $$\nMultiplying by $2h$ and rearranging the terms to group by time steps yields:\n$$ 3 y_{n+1} - 4 y_n + y_{n-1} = 2h\\lambda y_{n+1} $$\n$$ (3 - 2h\\lambda) y_{n+1} - 4 y_n + y_{n-1} = 0 $$\nLet $z = h\\lambda$. The recurrence relation can be written as:\n$$ (3 - 2z) y_{n+1} - 4 y_n + y_{n-1} = 0 $$\nTo find the characteristic roots of this linear constant-coefficient difference equation, we substitute the ansatz $y_k = \\xi^k$:\n$$ (3 - 2z) \\xi^{n+1} - 4 \\xi^n + \\xi^{n-1} = 0 $$\nDividing by $\\xi^{n-1}$ (assuming $\\xi \\neq 0$), we obtain the characteristic polynomial for the amplification factor $\\xi$:\n$$ (3 - 2z) \\xi^2 - 4 \\xi + 1 = 0 $$\nThe absolute stability boundary is the set of $z \\in \\mathbb{C}$ for which at least one characteristic root $\\xi$ has a modulus of one. We therefore set $\\xi = \\exp(i\\varphi)$, where $\\varphi \\in [0, 2\\pi)$ is a real-valued parameter. Substituting this into the characteristic equation:\n$$ (3 - 2z) (\\exp(i\\varphi))^2 - 4 \\exp(i\\varphi) + 1 = 0 $$\n$$ (3 - 2z) \\exp(i2\\varphi) - 4 \\exp(i\\varphi) + 1 = 0 $$\nWe now solve for $z$ as a function of $\\varphi$:\n$$ 3 \\exp(i2\\varphi) - 2z \\exp(i2\\varphi) - 4 \\exp(i\\varphi) + 1 = 0 $$\n$$ 2z \\exp(i2\\varphi) = 3 \\exp(i2\\varphi) - 4 \\exp(i\\varphi) + 1 $$\n$$ z(\\varphi) = \\frac{3 \\exp(i2\\varphi) - 4 \\exp(i\\varphi) + 1}{2 \\exp(i2\\varphi)} $$\nSimplifying this expression gives the parametric form of the stability boundary:\n$$ z(\\varphi) = \\frac{3}{2} - \\frac{4 \\exp(i\\varphi)}{2 \\exp(i2\\varphi)} + \\frac{1}{2 \\exp(i2\\varphi)} $$\n$$ z(\\varphi) = \\frac{3}{2} - 2 \\exp(-i\\varphi) + \\frac{1}{2} \\exp(-i2\\varphi) $$\nThis is the required analytic expression for the absolute-stability boundary of the BDF2 method.\n\n**Task 2: Minimum Step Size for Damping Requirement**\n\nIn the second task, we consider the specific ODE $y'(t) = -\\Lambda y(t)$ with $\\Lambda  0$. This corresponds to the Dahlquist test equation with $\\lambda = -\\Lambda$. The parameter $z$ is therefore real and negative: $z = h\\lambda = -h\\Lambda$.\n\nThe characteristic equation remains $(3 - 2z) \\xi^2 - 4 \\xi + 1 = 0$. Substituting $z = -h\\Lambda$:\n$$ (3 + 2h\\Lambda) \\xi^2 - 4 \\xi + 1 = 0 $$\nThe roots $\\xi$ of this quadratic equation are the per-step amplification factors:\n$$ \\xi = \\frac{-(-4) \\pm \\sqrt{(-4)^2 - 4(3+2h\\Lambda)(1)}}{2(3+2h\\Lambda)} = \\frac{4 \\pm \\sqrt{16 - 12 - 8h\\Lambda}}{2(3+2h\\Lambda)} = \\frac{4 \\pm \\sqrt{4 - 8h\\Lambda}}{2(3+2h\\Lambda)} $$\n$$ \\xi = \\frac{2 \\pm \\sqrt{1 - 2h\\Lambda}}{3+2h\\Lambda} $$\nThe nature of the roots depends on the sign of the discriminant, $1 - 2h\\Lambda$. Let $x = h\\Lambda$. Since $h0$ and $\\Lambda0$, we have $x0$.\n\nCase 1: $1 - 2x \\ge 0$, which implies $0  x \\le \\frac{1}{2}$.\nIn this case, the roots are real. The two roots are $\\xi_1 = \\frac{2 + \\sqrt{1 - 2x}}{3+2x}$ and $\\xi_2 = \\frac{2 - \\sqrt{1 - 2x}}{3+2x}$. The dominant root (largest in magnitude) is $\\xi_1$. Let $G(z)$ be the amplification factor, so $|G(z)| = |\\xi_1|$.\nThe requirement is that the magnitude of the amplification factor be at most $r=0.2$.\nLet's analyze the function $g(x) = \\frac{2 + \\sqrt{1 - 2x}}{3+2x}$ for $x \\in (0, \\frac{1}{2}]$.\nAt $x \\to 0$, $g(x) \\to \\frac{2+\\sqrt{1}}{3} = 1$.\nAt $x = \\frac{1}{2}$, $g(\\frac{1}{2}) = \\frac{2+0}{3+1} = \\frac{1}{2} = 0.5$.\nThe function $g(x)$ is monotonically decreasing on this interval. Since its minimum value is $0.5$, which is greater than the required maximum of $0.2$, there is no solution for $h$ in the range $0  h\\Lambda \\le \\frac{1}{2}$ that satisfies the damping requirement.\n\nCase 2: $1 - 2x  0$, which implies $x  \\frac{1}{2}$.\nIn this case, the roots are a complex conjugate pair:\n$$ \\xi = \\frac{2 \\pm i\\sqrt{2x - 1}}{3+2x} $$\nThe magnitude of both roots is identical:\n$$ |G(z)| = |\\xi| = \\sqrt{\\left(\\frac{2}{3+2x}\\right)^2 + \\left(\\frac{\\sqrt{2x-1}}{3+2x}\\right)^2} = \\sqrt{\\frac{4 + (2x-1)}{(3+2x)^2}} = \\sqrt{\\frac{3+2x}{(3+2x)^2}} = \\frac{1}{\\sqrt{3+2x}} $$\nThe damping requirement is $|G(z)| \\le r = 0.2$. Substituting back $x = h\\Lambda$:\n$$ \\frac{1}{\\sqrt{3+2h\\Lambda}} \\le 0.2 $$\nTo solve for $h$, we can square both sides (as both are positive):\n$$ \\frac{1}{3+2h\\Lambda} \\le (0.2)^2 = 0.04 $$\n$$ 1 \\le 0.04(3+2h\\Lambda) $$\n$$ \\frac{1}{0.04} \\le 3+2h\\Lambda $$\n$$ 25 \\le 3+2h\\Lambda $$\n$$ 22 \\le 2h\\Lambda $$\n$$ h\\Lambda \\ge 11 $$\nThis implies that the step size $h$ must satisfy $h \\ge \\frac{11}{\\Lambda}$. This condition, $h\\Lambda \\ge 11$, is consistent with the assumption for this case, $h\\Lambda  \\frac{1}{2}$.\nThe minimum step size $h_{\\min}$ that guarantees the required damping is:\n$$ h_{\\min} = \\frac{11}{\\Lambda} $$\nWe are given $\\Lambda = 2.0 \\times 10^3\\ \\text{s}^{-1}$. Substituting this value:\n$$ h_{\\min} = \\frac{11}{2.0 \\times 10^3\\ \\text{s}^{-1}} = 5.5 \\times 10^{-3}\\ \\text{s} $$\nThe problem requires the answer to be rounded to four significant figures.\n$$ h_{\\min} = 5.500 \\times 10^{-3}\\ \\text{s} $$\n\nThe final answer consists of the expression for $z(\\varphi)$ and the numerical value for $h_{\\min}$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{3}{2} - 2\\exp(-i\\varphi) + \\frac{1}{2}\\exp(-i2\\varphi)  5.500 \\times 10^{-3}\n\\end{pmatrix}\n}\n$$", "id": "3528288"}, {"introduction": "Astrophysical nucleosynthesis represents one of the most challenging classes of stiff initial value problems, where species abundances can vary by dozens of orders of magnitude. This hands-on coding exercise introduces a professional-level technique—dimensionless scaling of variables—to tame this stiffness and improve solver performance. You will derive and implement a scaled version of a minimal alpha-chain network, allowing you to quantitatively measure the profound impact that problem formulation has on the numerical efficiency and robustness of a stiff integrator [@problem_id:3528222].", "problem": "You are to study a minimal but stiff nuclear reaction network and quantify the numerical impact of a dimensionless scaling of variables on an initial value problem for ordinary differential equations, within the context of computational astrophysics. The goal is to derive the governing equations from first principles, implement both the original and a dimensionless-scaled formulation, integrate both with a stiff solver, and compute quantitative performance and conditioning metrics that can be automatically tested. All times must be expressed in seconds, and all requested outputs are dimensionless real numbers.\n\nStart from the fundamental base that the time evolution of species abundances in a well-mixed network is governed by the law of mass action and stoichiometric conservation. Consider a three-isotope alpha chain with the following effective reactions at constant thermodynamic state:\n- Effective triple-alpha production of carbon: $3\\, {}^{4}\\mathrm{He} \\rightarrow {}^{12}\\mathrm{C}$.\n- Alpha capture on carbon producing oxygen: ${}^{12}\\mathrm{C} + {}^{4}\\mathrm{He} \\rightarrow {}^{16}\\mathrm{O}$.\n\nLet the dynamical variables be the dimensionless abundances per baryon $Y_{\\mathrm{He}}(t)$, $Y_{\\mathrm{C}}(t)$, and $Y_{\\mathrm{O}}(t)$, which are nonnegative and satisfy nucleon conservation under the specified network. Let $k_{3\\alpha}$ denote an effective rate coefficient for the triple-alpha reaction and $k_{\\alpha C}$ denote an effective rate coefficient for the alpha capture on carbon. Treat $k_{3\\alpha}$ and $k_{\\alpha C}$ as constant parameters with dimensions chosen such that the following standard mass-action forms are valid for the production terms in units of inverse seconds: the effective triple-alpha rate term is proportional to $Y_{\\mathrm{He}}^{3}$ with proportionality constant $k_{3\\alpha}$, and the alpha-capture rate term is proportional to $Y_{\\mathrm{He}} Y_{\\mathrm{C}}$ with proportionality constant $k_{\\alpha C}$. Using only these definitions and stoichiometric conservation, derive the closed system of ordinary differential equations for the vector $\\mathbf{y}(t) = \\left[Y_{\\mathrm{He}}(t), Y_{\\mathrm{C}}(t), Y_{\\mathrm{O}}(t)\\right]^{\\top}$.\n\nDefine the unscaled initial value problem over a finite time interval $\\left[t_{0}, t_{f}\\right]$ by the derived system with initial condition $\\mathbf{y}(t_{0}) = \\mathbf{y}_{0}$. For the stiff integration, you must:\n- Use the Backward Differentiation Formula (BDF) method with an analytic Jacobian $\\mathbf{J}_{\\mathbf{y}}(t, \\mathbf{y}) = \\partial \\mathbf{f} / \\partial \\mathbf{y}$.\n- Enable dense output to evaluate the solution at arbitrary intermediate times.\n- Use a relative tolerance of $10^{-9}$ and an absolute tolerance vector of $\\left[10^{-18}, 10^{-18}, 10^{-18}\\right]$ for $\\left[Y_{\\mathrm{He}}, Y_{\\mathrm{C}}, Y_{\\mathrm{O}}\\right]$ respectively.\n\nNow construct a dimensionless scaled formulation designed to reduce dynamic range. Choose a fixed diagonal scaling matrix $\\mathbf{S} = \\mathrm{diag}\\left(s_{\\mathrm{He}}, s_{\\mathrm{C}}, s_{\\mathrm{O}}\\right)$ with $s_{\\mathrm{He}} = 1$, $s_{\\mathrm{C}} = 10^{-6}$, and $s_{\\mathrm{O}} = 10^{-12}$. Define scaled variables $\\mathbf{x}(\\tau) = \\mathbf{S}^{-1} \\mathbf{y}(t)$ and a scaled time $\\tau = t / t_{\\mathrm{ref}}$ with the time scale $t_{\\mathrm{ref}} = 1 / k_{\\alpha C}$. Use only the chain rule and the mass-action forms to derive the transformed initial value problem in the form $\\mathrm{d} \\mathbf{x} / \\mathrm{d} \\tau = \\mathbf{g}(\\mathbf{x})$ with an analytic Jacobian $\\mathbf{J}_{\\mathbf{x}}(\\mathbf{x}) = \\partial \\mathbf{g} / \\partial \\mathbf{x}$. Integrate the scaled system with the same solver settings, but in scaled time $\\tau$, and use the analytic Jacobian appropriate to the scaled system. Map any time-based diagnostics for the scaled run back to physical seconds using $t = \\tau \\, t_{\\mathrm{ref}}$ as needed.\n\nFor each run (unscaled and scaled), compute the following diagnostics:\n- Accepted step sizes: if the solver returns accepted time points $\\{t_{i}\\}_{i=0}^{N}$, compute the sequence of accepted step sizes $\\Delta t_{i} = t_{i+1} - t_{i}$ for $i = 0, \\dots, N-1$; compute the mean $\\overline{\\Delta t}$ and the median $\\widetilde{\\Delta t}$. For the scaled run, convert accepted steps in $\\tau$ to physical seconds via multiplication by $t_{\\mathrm{ref}}$. All times are in seconds.\n- Jacobian conditioning of the implicit linearization: for three physical times $t_{0}$ (initial), $t_{\\mathrm{mid}} = (t_{0} + t_{f})/2$ (midpoint), and $t_{f}$ (final), evaluate the solver’s implicit linear system matrix $\\mathbf{M} = \\mathbf{I} - h \\mathbf{J}$ using $h$ equal to the median accepted step size from that run and the appropriate Jacobian for that formulation. For the unscaled run, use $\\mathbf{J} = \\mathbf{J}_{\\mathbf{y}}$ evaluated at the state $\\mathbf{y}(t)$; for the scaled run, use $\\mathbf{J} = \\mathbf{J}_{\\mathbf{x}}$ evaluated at $\\mathbf{x}(\\tau)$ with $\\tau = t / t_{\\mathrm{ref}}$. Compute the $2$-norm condition number $\\kappa_{2}(\\mathbf{M})$ at each of the three times and then take the arithmetic mean of these three values to obtain a single conditioning metric for that run.\n\nQuantify the impact of scaling using the following three dimensionless metrics for each test case:\n- The ratio of mean conditioning metrics $\\mathcal{R}_{\\kappa} = \\left(\\text{mean } \\kappa_{2} \\text{ for unscaled}\\right) / \\left(\\text{mean } \\kappa_{2} \\text{ for scaled}\\right)$.\n- The ratio of mean accepted physical step sizes $\\mathcal{R}_{\\Delta t} = \\left(\\overline{\\Delta t}\\ \\text{for scaled}\\right) / \\left(\\overline{\\Delta t}\\ \\text{for unscaled}\\right)$.\n- The ratio of function evaluations $\\mathcal{R}_{\\mathrm{nfev}} = \\left(\\mathrm{nfev}\\ \\text{for unscaled}\\right) / \\left(\\mathrm{nfev}\\ \\text{for scaled}\\right)$ reported by the solver.\n\nTest Suite and parameter specifications:\n- Initial condition for all cases: $\\mathbf{y}_{0} = \\left[0.98,\\ 10^{-12},\\ 10^{-20}\\right]^{\\top}$ at $t_{0} = 0$ seconds.\n- Case A (stiff, fast alpha capture): $k_{3\\alpha} = 10^{-4}\\ \\mathrm{s}^{-1}$, $k_{\\alpha C} = 10^{3}\\ \\mathrm{s}^{-1}$, $t_{f} = 10^{-2}$ seconds.\n- Case B (very stiff, extremely fast alpha capture): $k_{3\\alpha} = 10^{-6}\\ \\mathrm{s}^{-1}$, $k_{\\alpha C} = 10^{5}\\ \\mathrm{s}^{-1}$, $t_{f} = 10^{-5}$ seconds.\n- Case C (mild stiffness, slower kinetics): $k_{3\\alpha} = 10^{-2}\\ \\mathrm{s}^{-1}$, $k_{\\alpha C} = 10^{2}\\ \\mathrm{s}^{-1}$, $t_{f} = 10^{-1}$ seconds.\n\nImplementation requirements:\n- Use the Backward Differentiation Formula (BDF) method with analytic Jacobians and dense output enabled.\n- Use relative tolerance $10^{-9}$ and absolute tolerance vector $\\left[10^{-18}, 10^{-18}, 10^{-18}\\right]$.\n- For each case, compute $\\mathcal{R}_{\\kappa}$, $\\mathcal{R}_{\\Delta t}$, and $\\mathcal{R}_{\\mathrm{nfev}}$ as defined above.\n\nFinal output format:\n- Your program should produce a single line of output containing a list of three lists, one per test case, in the same order as the cases above. Each inner list must contain the three floats $\\left[\\mathcal{R}_{\\kappa}, \\mathcal{R}_{\\Delta t}, \\mathcal{R}_{\\mathrm{nfev}}\\right]$ in that order, without any units. The exact format is a Python-style list literal, for example: \"[[1.23,0.45,3.67],[...],[...]]\".", "solution": "The user-provided problem is a well-posed and scientifically grounded exercise in computational astrophysics and numerical analysis. It requires the derivation and numerical solution of a system of ordinary differential equations (ODEs) for a simplified nuclear reaction network. The core task is to compare an unscaled formulation against a dimensionless, scaled formulation and quantify the impact on numerical performance. The problem is self-contained, with all necessary parameters, initial conditions, and metric definitions provided. It adheres to established principles of chemical kinetics (law of mass action) and numerical methods for stiff ODEs.\n\n### 1. Derivation of the Unscaled ODE System\n\nThe problem describes a three-isotope alpha chain with two effective reactions:\n1.  Triple-alpha: $3\\, {}^{4}\\mathrm{He} \\rightarrow {}^{12}\\mathrm{C}$\n2.  Alpha capture on Carbon: ${}^{12}\\mathrm{C} + {}^{4}\\mathrm{He} \\rightarrow {}^{16}\\mathrm{O}$\n\nThe state vector is $\\mathbf{y}(t) = \\left[Y_{\\mathrm{He}}(t), Y_{\\mathrm{C}}(t), Y_{\\mathrm{O}}(t)\\right]^{\\top}$, representing the dimensionless abundances. The time evolution of these abundances is governed by the law of mass action.\n\nLet $R_1$ be the rate of the triple-alpha reaction and $R_2$ be the rate of the alpha-capture reaction. The problem states that the production term for ${}^{12}\\mathrm{C}$ from the triple-alpha reaction is $k_{3\\alpha} Y_{\\mathrm{He}}^{3}$ and the production term for ${}^{16}\\mathrm{O}$ from alpha capture is $k_{\\alpha C} Y_{\\mathrm{He}} Y_{\\mathrm{C}}$. This implies that the rates of change due to production are $\\left.dY_{\\mathrm{C}}/dt\\right|_{\\text{prod},1} = k_{3\\alpha} Y_{\\mathrm{He}}^{3}$ and $\\left.dY_{\\mathrm{O}}/dt\\right|_{\\text{prod},2} = k_{\\alpha C} Y_{\\mathrm{He}} Y_{\\mathrm{C}}$.\n\nBased on the stoichiometry of the reactions, we can write the full system of ODEs, $\\mathrm{d}\\mathbf{y}/\\mathrm{d}t = \\mathbf{f}(\\mathbf{y})$:\n\nFor the triple-alpha reaction ($3\\mathrm{He} \\to \\mathrm{C}$), for every one ${}^{12}\\mathrm{C}$ nucleus created, three ${}^{4}\\mathrm{He}$ nuclei are destroyed. Thus:\n$\\frac{\\mathrm{d}Y_{\\mathrm{He}}}{\\mathrm{d}t} \\bigg|_{1} = -3 \\left( \\frac{\\mathrm{d}Y_{\\mathrm{C}}}{\\mathrm{d}t} \\bigg|_{\\text{prod},1} \\right) = -3 k_{3\\alpha} Y_{\\mathrm{He}}^{3}$\n$\\frac{\\mathrm{d}Y_{\\mathrm{C}}}{\\mathrm{d}t} \\bigg|_{1} = +k_{3\\alpha} Y_{\\mathrm{He}}^{3}$\n\nFor the alpha capture reaction ($\\mathrm{C} + \\mathrm{He} \\to \\mathrm{O}$), for every one ${}^{16}\\mathrm{O}$ nucleus created, one ${}^{12}\\mathrm{C}$ and one ${}^{4}\\mathrm{He}$ nucleus are destroyed. Thus:\n$\\frac{\\mathrm{d}Y_{\\mathrm{He}}}{\\mathrm{d}t} \\bigg|_{2} = - \\left( \\frac{\\mathrm{d}Y_{\\mathrm{O}}}{\\mathrm{d}t} \\bigg|_{\\text{prod},2} \\right) = -k_{\\alpha C} Y_{\\mathrm{He}} Y_{\\mathrm{C}}$\n$\\frac{\\mathrm{d}Y_{\\mathrm{C}}}{\\mathrm{d}t} \\bigg|_{2} = - \\left( \\frac{\\mathrm{d}Y_{\\mathrm{O}}}{\\mathrm{d}t} \\bigg|_{\\text{prod},2} \\right) = -k_{\\alpha C} Y_{\\mathrm{He}} Y_{\\mathrm{C}}$\n$\\frac{\\mathrm{d}Y_{\\mathrm{O}}}{\\mathrm{d}t} \\bigg|_{2} = +k_{\\alpha C} Y_{\\mathrm{He}} Y_{\\mathrm{C}}$\n\nCombining these terms gives the final system:\n$$\n\\frac{\\mathrm{d}Y_{\\mathrm{He}}}{\\mathrm{d}t} = f_1(\\mathbf{y}) = -3 k_{3\\alpha} Y_{\\mathrm{He}}^{3} - k_{\\alpha C} Y_{\\mathrm{He}} Y_{\\mathrm{C}}\n$$\n$$\n\\frac{\\mathrm{d}Y_{\\mathrm{C}}}{\\mathrm{d}t} = f_2(\\mathbf{y}) = k_{3\\alpha} Y_{\\mathrm{He}}^{3} - k_{\\alpha C} Y_{\\mathrm{He}} Y_{\\mathrm{C}}\n$$\n$$\n\\frac{\\mathrm{d}Y_{\\mathrm{O}}}{\\mathrm{d}t} = f_3(\\mathbf{y}) = k_{\\alpha C} Y_{\\mathrm{He}} Y_{\\mathrm{C}}\n$$\n\nThe Jacobian matrix $\\mathbf{J}_{\\mathbf{y}} = \\partial \\mathbf{f} / \\partial \\mathbf{y}$ is:\n$$\n\\mathbf{J}_{\\mathbf{y}} = \n\\begin{pmatrix}\n\\frac{\\partial f_1}{\\partial Y_{\\mathrm{He}}}  \\frac{\\partial f_1}{\\partial Y_{\\mathrm{C}}}  \\frac{\\partial f_1}{\\partial Y_{\\mathrm{O}}} \\\\\n\\frac{\\partial f_2}{\\partial Y_{\\mathrm{He}}}  \\frac{\\partial f_2}{\\partial Y_{\\mathrm{C}}}  \\frac{\\partial f_2}{\\partial Y_{\\mathrm{O}}} \\\\\n\\frac{\\partial f_3}{\\partial Y_{\\mathrm{He}}}  \\frac{\\partial f_3}{\\partial Y_{\\mathrm{C}}}  \\frac{\\partial f_3}{\\partial Y_{\\mathrm{O}}}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n-9 k_{3\\alpha} Y_{\\mathrm{He}}^{2} - k_{\\alpha C} Y_{\\mathrm{C}}  -k_{\\alpha C} Y_{\\mathrm{He}}  0 \\\\\n3 k_{3\\alpha} Y_{\\mathrm{He}}^{2} - k_{\\alpha C} Y_{\\mathrm{C}}  -k_{\\alpha C} Y_{\\mathrm{He}}  0 \\\\\nk_{\\alpha C} Y_{\\mathrm{C}}  k_{\\alpha C} Y_{\\mathrm{He}}  0\n\\end{pmatrix}\n$$\n\n### 2. Derivation of the Scaled ODE System\n\nWe introduce scaled variables $\\mathbf{x}(\\tau) = \\mathbf{S}^{-1} \\mathbf{y}(t)$ and scaled time $\\tau = t / t_{\\mathrm{ref}}$, where $\\mathbf{S} = \\mathrm{diag}(s_{\\mathrm{He}}, s_{\\mathrm{C}}, s_{\\mathrm{O}})$ and $t_{\\mathrm{ref}} = 1 / k_{\\alpha C}$. The unscaled variables are $\\mathbf{y}(t) = \\mathbf{S} \\mathbf{x}(\\tau)$.\n\nUsing the chain rule, we transform the derivative:\n$$\n\\frac{\\mathrm{d}\\mathbf{y}}{\\mathrm{d}t} = \\frac{\\mathrm{d}(\\mathbf{S}\\mathbf{x})}{\\mathrm{d}t} = \\mathbf{S} \\frac{\\mathrm{d}\\mathbf{x}}{\\mathrm{d}\\tau} \\frac{\\mathrm{d}\\tau}{\\mathrm{d}t} = \\mathbf{S} \\frac{\\mathrm{d}\\mathbf{x}}{\\mathrm{d}\\tau} \\frac{1}{t_{\\mathrm{ref}}}\n$$\nSubstituting this into the unscaled ODE system $\\mathrm{d}\\mathbf{y}/\\mathrm{d}t = \\mathbf{f}(\\mathbf{y})$:\n$$\n\\frac{\\mathbf{S}}{t_{\\mathrm{ref}}} \\frac{\\mathrm{d}\\mathbf{x}}{\\mathrm{d}\\tau} = \\mathbf{f}(\\mathbf{S}\\mathbf{x}) \\implies \\frac{\\mathrm{d}\\mathbf{x}}{\\mathrm{d}\\tau} = t_{\\mathrm{ref}} \\mathbf{S}^{-1} \\mathbf{f}(\\mathbf{S}\\mathbf{x})\n$$\nThe right-hand side is the new function $\\mathbf{g}(\\mathbf{x})$. Let's write out its components, substituting $Y_{\\mathrm{He}} = s_{\\mathrm{He}}x_{\\mathrm{He}}$, $Y_{\\mathrm{C}} = s_{\\mathrm{C}}x_{\\mathrm{C}}$, $t_{\\mathrm{ref}} = 1/k_{\\alpha C}$, and defining the dimensionless ratio $\\gamma = k_{3\\alpha}/k_{\\alpha C}$:\n\n$g_1(x) = \\frac{t_{\\mathrm{ref}}}{s_{\\mathrm{He}}} f_1(\\mathbf{S x}) = \\frac{1}{k_{\\alpha C}s_{\\mathrm{He}}} \\left( -3 k_{3\\alpha} (s_{\\mathrm{He}}x_{\\mathrm{He}})^3 - k_{\\alpha C} (s_{\\mathrm{He}}x_{\\mathrm{He}})(s_{\\mathrm{C}}x_{\\mathrm{C}}) \\right) = -3\\gamma \\frac{s_{\\mathrm{He}}^3}{s_{\\mathrm{He}}} x_{\\mathrm{He}}^3 - \\frac{s_{\\mathrm{He}}s_{\\mathrm{C}}}{s_{\\mathrm{He}}} x_{\\mathrm{He}}x_{\\mathrm{C}}$\n$g_2(x) = \\frac{t_{\\mathrm{ref}}}{s_{\\mathrm{C}}} f_2(\\mathbf{S x}) = \\frac{1}{k_{\\alpha C}s_{\\mathrm{C}}} \\left( k_{3\\alpha} (s_{\\mathrm{He}}x_{\\mathrm{He}})^3 - k_{\\alpha C} (s_{\\mathrm{He}}x_{\\mathrm{He}})(s_{\\mathrm{C}}x_{\\mathrm{C}}) \\right) = \\gamma \\frac{s_{\\mathrm{He}}^3}{s_{\\mathrm{C}}} x_{\\mathrm{He}}^3 - \\frac{s_{\\mathrm{He}}s_{\\mathrm{C}}}{s_{\\mathrm{C}}} x_{\\mathrm{He}}x_{\\mathrm{C}}$\n$g_3(x) = \\frac{t_{\\mathrm{ref}}}{s_{\\mathrm{O}}} f_3(\\mathbf{S x}) = \\frac{1}{k_{\\alpha C}s_{\\mathrm{O}}} \\left( k_{\\alpha C} (s_{\\mathrm{He}}x_{\\mathrm{He}})(s_{\\mathrm{C}}x_{\\mathrm{C}}) \\right) = \\frac{s_{\\mathrm{He}}s_{\\mathrm{C}}}{s_{\\mathrm{O}}} x_{\\mathrm{He}}x_{\\mathrm{C}}$\n\nUsing the specified scaling constants $s_{\\mathrm{He}}=1$, $s_{\\mathrm{C}}=10^{-6}$, and $s_{\\mathrm{O}}=10^{-12}$:\n$$\ng_1(\\mathbf{x}) = -3 \\gamma x_{\\mathrm{He}}^{3} - s_{\\mathrm{C}} x_{\\mathrm{He}} x_{\\mathrm{C}}\n$$\n$$\ng_2(\\mathbf{x}) = \\frac{\\gamma}{s_{\\mathrm{C}}} x_{\\mathrm{He}}^{3} - x_{\\mathrm{He}} x_{\\mathrm{C}}\n$$\n$$\ng_3(\\mathbf{x}) = \\frac{s_{\\mathrm{C}}}{s_{\\mathrm{O}}} x_{\\mathrm{He}} x_{\\mathrm{C}}\n$$\n\nThe Jacobian of the scaled system, $\\mathbf{J}_{\\mathbf{x}} = \\partial \\mathbf{g} / \\partial \\mathbf{x}$, is:\n$$\n\\mathbf{J}_{\\mathbf{x}} = \n\\begin{pmatrix}\n-9 \\gamma x_{\\mathrm{He}}^{2} - s_{\\mathrm{C}} x_{\\mathrm{C}}  -s_{\\mathrm{C}} x_{\\mathrm{He}}  0 \\\\\n\\frac{3\\gamma}{s_{\\mathrm{C}}} x_{\\mathrm{He}}^{2} - x_{\\mathrm{C}}  -x_{\\mathrm{He}}  0 \\\\\n\\frac{s_{\\mathrm{C}}}{s_{\\mathrm{O}}} x_{\\mathrm{C}}  \\frac{s_{\\mathrm{C}}}{s_{\\mathrm{O}}} x_{\\mathrm{He}}  0\n\\end{pmatrix}\n$$\n\n### 3. Numerical Integration and Diagnostics\n\nFor each test case, we solve both the unscaled and scaled systems using the BDF method from $t_0=0$ to $t_f$. The scaled system is solved from $\\tau_0=0$ to $\\tau_f = t_f/t_{\\mathrm{ref}}$.\nThe following diagnostics are computed for each run:\n- **Mean and Median Step Sizes**: The sequence of accepted step sizes, $\\Delta t_i$ for the unscaled run and $\\Delta \\tau_i$ for the scaled run, are collected. For comparison, the scaled steps are converted to physical time: $\\Delta t_i^{\\text{scaled}} = \\Delta \\tau_i \\cdot t_{\\mathrm{ref}}$. The means $\\overline{\\Delta t}$ and medians $\\widetilde{\\Delta t}$ are then computed.\n- **Jacobian Conditioning**: The matrix $\\mathbf{M} = \\mathbf{I} - h \\mathbf{J}$ is constructed. For the unscaled run, $\\mathbf{J}=\\mathbf{J}_{\\mathbf{y}}$ and $h=\\widetilde{\\Delta t}^{\\text{unscaled}}$. For the scaled run, $\\mathbf{J}=\\mathbf{J}_{\\mathbf{x}}$ and $h=\\widetilde{\\Delta \\tau}^{\\text{scaled}}$. The matrix is evaluated at three physical times ($t_0$, $(t_0+t_f)/2$, $t_f$) and their corresponding scaled times. The $2$-norm condition number $\\kappa_2(\\mathbf{M})$ is computed at each time, and the three values are averaged.\n- **Function Evaluations**: The total number of function evaluations, `nfev`, is obtained from the solver.\n\nFinally, three dimensionless ratios are computed to quantify the impact of scaling:\n- $\\mathcal{R}_{\\kappa} = \\left(\\text{mean } \\kappa_{2} \\text{ for unscaled}\\right) / \\left(\\text{mean } \\kappa_{2} \\text{ for scaled}\\right)$\n- $\\mathcal{R}_{\\Delta t} = \\left(\\overline{\\Delta t}\\ \\text{for scaled}\\right) / \\left(\\overline{\\Delta t}\\ \\text{for unscaled}\\right)$\n- $\\mathcal{R}_{\\mathrm{nfev}} = \\left(\\mathrm{nfev}\\ \\text{for unscaled}\\right) / \\left(\\mathrm{nfev}\\ \\text{for scaled}\\right)$\n\nThe implementation will follow these derivations and procedures.", "answer": "```python\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\n# --- Problem Definition: Unscaled System ---\n\ndef f_unscaled(t, y, k_3a, k_ac):\n    \"\"\"RHS of the unscaled ODE system dy/dt = f(t, y).\"\"\"\n    y_he, y_c, y_o = y[0], y[1], y[2]\n    \n    # Reaction rates based on problem definition\n    term_3a = k_3a * y_he**3\n    term_ac = k_ac * y_he * y_c\n    \n    dy_he_dt = -3.0 * term_3a - term_ac\n    dy_c_dt = term_3a - term_ac\n    dy_o_dt = term_ac\n    \n    return np.array([dy_he_dt, dy_c_dt, dy_o_dt])\n\ndef jac_unscaled(t, y, k_3a, k_ac):\n    \"\"\"Jacobian of the unscaled ODE system.\"\"\"\n    y_he, y_c = y[0], y[1]\n    \n    J = np.zeros((3, 3), dtype=np.float64)\n    \n    # df1/dy\n    J[0, 0] = -9.0 * k_3a * y_he**2 - k_ac * y_c\n    J[0, 1] = -k_ac * y_he\n    \n    # df2/dy\n    J[1, 0] = 3.0 * k_3a * y_he**2 - k_ac * y_c\n    J[1, 1] = -k_ac * y_he\n    \n    # df3/dy\n    J[2, 0] = k_ac * y_c\n    J[2, 1] = k_ac * y_he\n    \n    return J\n\n# --- Problem Definition: Scaled System ---\n\n# Scaling constants are fixed for all test cases\nS_DIAG = np.array([1.0, 1e-6, 1e-12])\nS_HE, S_C, S_O = S_DIAG[0], S_DIAG[1], S_DIAG[2]\n\ndef g_scaled(tau, x, gamma):\n    \"\"\"RHS of the scaled ODE system dx/dtau = g(tau, x).\"\"\"\n    x_he, x_c = x[0], x[1]\n    \n    g1 = -3.0 * gamma * x_he**3 - S_C * x_he * x_c\n    g2 = (gamma / S_C) * x_he**3 - x_he * x_c\n    g3 = (S_C / S_O) * x_he * x_c\n    \n    return np.array([g1, g2, g3])\n\ndef jac_scaled(tau, x, gamma):\n    \"\"\"Jacobian of the scaled ODE system.\"\"\"\n    x_he, x_c = x[0], x[1]\n    \n    J = np.zeros((3, 3), dtype=np.float64)\n    \n    # dg1/dx\n    J[0, 0] = -9.0 * gamma * x_he**2 - S_C * x_c\n    J[0, 1] = -S_C * x_he\n    \n    # dg2/dx\n    J[1, 0] = (3.0 * gamma / S_C) * x_he**2 - x_c\n    J[1, 1] = -x_he\n    \n    # dg3/dx\n    J[2, 0] = (S_C / S_O) * x_c\n    J[2, 1] = (S_C / S_O) * x_he\n    \n    return J\n\ndef run_and_analyze(case_params):\n    \"\"\"\n    Runs both unscaled and scaled simulations for a given case and computes metrics.\n    \"\"\"\n    k_3a, k_ac, tf = case_params\n    y0 = np.array([0.98, 1e-12, 1e-20])\n    t0 = 0.0\n    rtol = 1e-9\n    atol = np.array([1e-18, 1e-18, 1e-18])\n    t_span = [t0, tf]\n    t_eval_points = np.array([t0, (t0 + tf) / 2.0, tf])\n\n    # --- Unscaled Run ---\n    unscaled_sol = solve_ivp(\n        fun=f_unscaled,\n        t_span=t_span,\n        y0=y0,\n        method='BDF',\n        jac=jac_unscaled,\n        dense_output=True,\n        rtol=rtol,\n        atol=atol,\n        args=(k_3a, k_ac)\n    )\n\n    unscaled_steps_t = np.diff(unscaled_sol.t)\n    mean_dt_unscaled = np.mean(unscaled_steps_t)\n    median_dt_unscaled = np.median(unscaled_steps_t)\n    nfev_unscaled = unscaled_sol.nfev\n\n    y_at_evals = unscaled_sol.sol(t_eval_points)\n    kappas_unscaled = []\n    for i in range(len(t_eval_points)):\n        y_i = y_at_evals[:, i]\n        J = jac_unscaled(t_eval_points[i], y_i, k_3a, k_ac)\n        M = np.identity(3, dtype=np.float64) - median_dt_unscaled * J\n        kappas_unscaled.append(np.linalg.cond(M, 2))\n    mean_kappa_unscaled = np.mean(kappas_unscaled)\n\n    # --- Scaled Run ---\n    t_ref = 1.0 / k_ac\n    gamma = k_3a / k_ac\n    x0 = y0 / S_DIAG\n    tau_span = [t / t_ref for t in t_span]\n    \n    scaled_sol = solve_ivp(\n        fun=g_scaled,\n        t_span=tau_span,\n        y0=x0,\n        method='BDF',\n        jac=jac_scaled,\n        dense_output=True,\n        rtol=rtol,\n        atol=atol, # Using same atol as per problem statement\n        args=(gamma,)\n    )\n\n    scaled_steps_tau = np.diff(scaled_sol.t)\n    mean_dt_scaled = np.mean(scaled_steps_tau * t_ref)\n    median_dtau_scaled = np.median(scaled_steps_tau) # Step size h is in integration variable units (tau)\n    nfev_scaled = scaled_sol.nfev\n\n    tau_eval_points = t_eval_points / t_ref\n    x_at_evals = scaled_sol.sol(tau_eval_points)\n    kappas_scaled = []\n    for i in range(len(tau_eval_points)):\n        x_i = x_at_evals[:, i]\n        J = jac_scaled(tau_eval_points[i], x_i, gamma)\n        M = np.identity(3, dtype=np.float64) - median_dtau_scaled * J\n        kappas_scaled.append(np.linalg.cond(M, 2))\n    mean_kappa_scaled = np.mean(kappas_scaled)\n\n    # --- Compute Ratios ---\n    # Handle potential division by zero if a metric is zero, though unlikely.\n    R_kappa = mean_kappa_unscaled / mean_kappa_scaled if mean_kappa_scaled != 0 else np.inf\n    R_dt = mean_dt_scaled / mean_dt_unscaled if mean_dt_unscaled != 0 else np.inf\n    R_nfev = float(nfev_unscaled) / float(nfev_scaled) if nfev_scaled != 0 else np.inf\n    \n    return [R_kappa, R_dt, R_nfev]\n\ndef solve():\n    \"\"\"Main solver function to run all test cases and print results.\"\"\"\n    # Test cases: [k_3alpha (s^-1), k_alphaC (s^-1), t_f (s)]\n    test_cases = [\n        # Case A\n        (1e-4, 1e3, 1e-2),\n        # Case B\n        (1e-6, 1e5, 1e-5),\n        # Case C\n        (1e-2, 1e2, 1e-1)\n    ]\n    \n    # Use a high precision for numpy printing to match string formatting\n    np.set_printoptions(precision=16)\n\n    all_results = []\n    for case in test_cases:\n        result_metrics = run_and_analyze(case)\n        all_results.append(result_metrics)\n    \n    # Format according to spec: \"[[1.23,0.45,3.67],[...],[...]]\"\n    # str(list) provides the required formatting.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3528222"}]}