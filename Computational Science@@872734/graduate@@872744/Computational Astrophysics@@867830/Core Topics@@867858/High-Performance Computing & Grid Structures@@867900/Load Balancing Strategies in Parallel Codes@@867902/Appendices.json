{"hands_on_practices": [{"introduction": "Effective load balancing begins with the ability to precisely quantify imbalance and predict its impact on performance. This exercise grounds these concepts in a practical scenario involving a hydrodynamics code with a simple domain decomposition [@problem_id:3516510]. By calculating standard imbalance metrics and applying a performance model that accounts for both computation and communication, you will develop a foundational understanding of how workload distribution dictates the real-world efficiency and speedup of a parallel application.", "problem": "A uniform Cartesian mesh hydrodynamics solver advances one explicit Godunov timestep with domain decomposition across $P=8$ processors. The per-processor local update counts (number of cell-updates performed this timestep) are\n$$\nw_1=1200,\\quad w_2=1150,\\quad w_3=1230,\\quad w_4=1070,\\quad w_5=1180,\\quad w_6=940,\\quad w_7=1110,\\quad w_8=1260.\n$$\nThe time per cell-update is $\\tau=1.0\\times 10^{-6}\\ \\mathrm{s}$. During the timestep, each processor performs two nearest-neighbor ghost exchanges. For processor $i$, each ghost exchange message contains $m_i$ thousand scalars, with\n$$\nm_1=80,\\quad m_2=75,\\quad m_3=78,\\quad m_4=70,\\quad m_5=76,\\quad m_6=60,\\quad m_7=74,\\quad m_8=82.\n$$\nAssume a point-to-point message time model $t_{\\mathrm{msg}}=\\alpha+\\beta n$ where $n$ is the number of scalars in the message, $\\alpha=1.2\\times 10^{-4}\\ \\mathrm{s}$, and $\\beta=2.5\\times 10^{-8}\\ \\mathrm{s}$ per scalar. The timestep ends with a binary-tree global reduction to compute the Courant–Friedrichs–Lewy (CFL) number, incurring a barrier time of $3$ stages with per-stage cost $\\gamma=1.6\\times 10^{-4}\\ \\mathrm{s}$. Assume no overlap between computation and communication, no hidden latencies, and negligible input/output and host overheads.\n\nUsing standard definitions from parallel performance analysis, do the following:\n- Compute the mean workload $\\bar{w}$, the standard deviation $\\sigma$, the coefficient of variation $CV=\\sigma/\\bar{w}$, and the imbalance factor $I=w_{\\max}/\\bar{w}$.\n- Predict the serial time $T_1$ and the parallel time $T_P$ for the timestep under the assumptions above.\n- Compute the efficiency $E$ and the speedup $S$.\n\nRound the speedup $S$ to four significant figures. Express your final answer as the speedup, with no units.", "solution": "The problem asks for several performance metrics for a parallel hydrodynamics solver executed on $P=8$ processors. We compute these metrics systematically.\n\nFirst, we analyze the workload distribution. The per-processor workloads are given as:\n$w_1=1200$, $w_2=1150$, $w_3=1230$, $w_4=1070$, $w_5=1180$, $w_6=940$, $w_7=1110$, $w_8=1260$.\n\nThe total workload $W$ is the sum of the individual processor workloads:\n$$\nW = \\sum_{i=1}^{P} w_i = 1200 + 1150 + 1230 + 1070 + 1180 + 940 + 1110 + 1260 = 9140 \\text{ cell-updates}\n$$\nThe mean workload $\\bar{w}$ is:\n$$\n\\bar{w} = \\frac{W}{P} = \\frac{9140}{8} = 1142.5 \\text{ cell-updates}\n$$\nThe population standard deviation of the workload $\\sigma$ is calculated as:\n$$\n\\sigma = \\sqrt{\\frac{1}{P} \\sum_{i=1}^{P} (w_i - \\bar{w})^2} = \\sqrt{\\frac{1}{8} \\left[ (57.5)^2 + (7.5)^2 + (87.5)^2 + (-72.5)^2 + (37.5)^2 + (-202.5)^2 + (-32.5)^2 + (117.5)^2 \\right]}\n$$\n$$\n\\sigma = \\sqrt{\\frac{73550}{8}} = \\sqrt{9193.75} \\approx 95.884\n$$\nThe coefficient of variation $CV$, which measures the relative load imbalance, is:\n$$\nCV = \\frac{\\sigma}{\\bar{w}} = \\frac{95.884}{1142.5} \\approx 0.08392\n$$\nThe maximum workload is $w_{\\max} = \\max_i(w_i) = 1260$. The imbalance factor $I$ is:\n$$\nI = \\frac{w_{\\max}}{\\bar{w}} = \\frac{1260}{1142.5} \\approx 1.1028\n$$\nNext, we compute the serial and parallel execution times. The time per cell-update is $\\tau = 1.0 \\times 10^{-6}\\ \\mathrm{s}$.\n\nThe serial time $T_1$ is the time required to complete the total workload on a single processor, with no communication overhead:\n$$\nT_1 = W \\times \\tau = 9140 \\times (1.0 \\times 10^{-6}\\ \\mathrm{s}) = 9.14 \\times 10^{-3}\\ \\mathrm{s}\n$$\nThe parallel time $T_P$ is determined by the slowest processor in a bulk synchronous model (no overlap between computation and communication). It is the sum of the maximum computation time $T_{\\text{comp}}$ and the total communication time $T_{\\text{comm}}$.\n$$\nT_P = T_{\\text{comp}} + T_{\\text{comm}}\n$$\nThe computation time is limited by the processor with the maximum workload $w_{\\max}$:\n$$\nT_{\\text{comp}} = w_{\\max} \\times \\tau = 1260 \\times (1.0 \\times 10^{-6}\\ \\mathrm{s}) = 1.26 \\times 10^{-3}\\ \\mathrm{s}\n$$\nThe communication time consists of two components: ghost cell exchange time $T_{\\text{ghost}}$ and global reduction time $T_{\\text{redux}}$. The cost of the ghost exchange phase is determined by the processor with the largest message size, $n_{\\max} = 82000$ scalars.\n$$\nT_{\\text{ghost}} = 2 \\times (\\alpha + \\beta n_{\\max}) = 2 \\times \\left(1.2 \\times 10^{-4}\\ \\mathrm{s} + (2.5 \\times 10^{-8}\\ \\mathrm{s}/\\text{scalar}) \\times 82000\\ \\text{scalars}\\right)\n$$\n$$\nT_{\\text{ghost}} = 2 \\times (1.2 \\times 10^{-4}\\ \\mathrm{s} + 2.05 \\times 10^{-3}\\ \\mathrm{s}) = 2 \\times (2.17 \\times 10^{-3}\\ \\mathrm{s}) = 4.34 \\times 10^{-3}\\ \\mathrm{s}\n$$\nThe global reduction incurs a barrier time of $3$ stages:\n$$\nT_{\\text{redux}} = 3 \\times \\gamma = 3 \\times (1.6 \\times 10^{-4}\\ \\mathrm{s}) = 4.8 \\times 10^{-4}\\ \\mathrm{s} = 0.48 \\times 10^{-3}\\ \\mathrm{s}\n$$\nThe total communication time is:\n$$\nT_{\\text{comm}} = T_{\\text{ghost}} + T_{\\text{redux}} = 4.34 \\times 10^{-3}\\ \\mathrm{s} + 0.48 \\times 10^{-3}\\ \\mathrm{s} = 4.82 \\times 10^{-3}\\ \\mathrm{s}\n$$\nThe total parallel time for the timestep is:\n$$\nT_P = T_{\\text{comp}} + T_{\\text{comm}} = 1.26 \\times 10^{-3}\\ \\mathrm{s} + 4.82 \\times 10^{-3}\\ \\mathrm{s} = 6.08 \\times 10^{-3}\\ \\mathrm{s}\n$$\nFinally, we compute the speedup $S$ and efficiency $E$. Speedup is the ratio of serial to parallel time:\n$$\nS = \\frac{T_1}{T_P} = \\frac{9.14 \\times 10^{-3}\\ \\mathrm{s}}{6.08 \\times 10^{-3}\\ \\mathrm{s}} = \\frac{9.14}{6.08} \\approx 1.503289...\n$$\nEfficiency is the speedup per processor:\n$$\nE = \\frac{S}{P} = \\frac{1.503289...}{8} \\approx 0.1879\n$$\nThe problem requests the speedup $S$ rounded to four significant figures.\n$$\nS \\approx 1.503\n$$", "answer": "$$\n\\boxed{1.503}\n$$", "id": "3516510"}, {"introduction": "While simple load imbalance metrics are useful, the performance of complex, multi-physics simulations is often governed by the intricate dependencies between different computational tasks. This practice introduces the work-span model, where a timestep is represented as a Directed Acyclic Graph (DAG) [@problem_id:3516579]. By calculating the total work ($T_1$) and the critical path length ($T_{\\infty}$), you will learn to identify the fundamental limit on parallel speedup imposed by the algorithm's structure, a concept crucial for co-designing algorithms and hardware.", "problem": "Consider a single explicit timestep of a uniform Cartesian mesh astrophysical solver that combines self-gravity via Fast Fourier Transform (FFT), compressible hydrodynamics, and radiation transport, executed on a one-dimensional domain decomposition into $P=4$ subdomains along the $x$-direction. The parallel execution is modeled as a weighted directed acyclic graph (DAG) where nodes represent tasks with execution times and edges represent dependencies; the work-span model defines the total work $T_1$ as the sum of all node times and the critical path length $T_{\\infty}$ as the length of the longest path in time from the DAG’s start to finish. All tasks are assumed to be non-preemptive and edge latencies are negligible. The timestep’s phases and their task structure are as follows.\n\nGravity phase: A global three-dimensional FFT-based Poisson solve is abstracted into three serial tasks: forward transform $\\mathcal{F}$ of duration $t_{\\mathcal{F}}=24\\,\\mathrm{ms}$, convolution with the Green’s function $\\mathcal{K}$ of duration $t_{\\mathcal{K}}=3\\,\\mathrm{ms}$, and inverse transform $\\mathcal{F}^{-1}$ of duration $t_{\\mathcal{F}^{-1}}=25\\,\\mathrm{ms}$. These tasks are strictly ordered as $\\mathcal{F} \\rightarrow \\mathcal{K} \\rightarrow \\mathcal{F}^{-1}$.\n\nHydrodynamics phase: For each subdomain $i \\in \\{1,2,3,4\\}$, hydrodynamics begins after gravity completes. Within subdomain $i$ there are three tasks: a pair of boundary exchanges $\\mathrm{H\\_exL}(i)$ then $\\mathrm{H\\_exR}(i)$, each of duration $1\\,\\mathrm{ms}$, executed sequentially to represent serialized use of the network interface: $\\mathrm{H\\_exL}(i) \\rightarrow \\mathrm{H\\_exR}(i)$; an interior update $\\mathrm{H\\_int}(i)$ of duration $6\\,\\mathrm{ms}$ that depends only on gravity and is independent of exchanges; and a boundary update $\\mathrm{H\\_bnd}(i)$ of duration $2\\,\\mathrm{ms}$ that depends on completion of $\\mathrm{H\\_exR}(i)$. Radiation cannot start until all subdomains complete both interior and boundary updates; model this with a zero-time barrier node $\\mathrm{H\\_bar}$ that has incoming edges from $\\mathrm{H\\_int}(i)$ and $\\mathrm{H\\_bnd}(i)$ for all $i$.\n\nRadiation transport phase: There are $G=3$ angular groups indexed by $g \\in \\{1,2,3\\}$, each performing a left-to-right sweep across subdomains. For each group $g$ and subdomain index $j \\in \\{1,2,3,4\\}$, there is a local update $\\mathrm{R\\_upd}(g,j)$ of duration $3\\,\\mathrm{ms}$ followed by sending outgoing flux $\\mathrm{R\\_comm}(g,j)$ of duration $1\\,\\mathrm{ms}$. The sweep pipeline is $\\mathrm{R\\_upd}(g,1)$ depends on $\\mathrm{H\\_bar}$, $\\mathrm{R\\_comm}(g,1)$ depends on $\\mathrm{R\\_upd}(g,1)$, then for $j>1$ the update depends on the previous subdomain’s communication: $\\mathrm{R\\_upd}(g,j)$ depends on $\\mathrm{R\\_comm}(g,j-1)$, and $\\mathrm{R\\_comm}(g,j)$ depends on $\\mathrm{R\\_upd}(g,j)$. The three groups are independent and may execute concurrently once $\\mathrm{H\\_bar}$ is reached.\n\nDefine the DAG implied by the above in terms of nodes and edges, and compute the critical path length $T_{\\infty}$ and the total work $T_1$ for the entire timestep. Express both $T_{\\infty}$ and $T_1$ in milliseconds. No rounding is required; give exact values.", "solution": "The objective is to compute the total work, $T_1$, and the critical path length, $T_{\\infty}$, for the directed acyclic graph (DAG) described. All values are in milliseconds (ms).\n\nFirst, we calculate the total work, $T_1$, by summing the execution times of all tasks.\n1.  **Gravity Phase Work ($W_{\\text{gravity}}$):** This phase has three serial tasks.\n    $W_{\\text{gravity}} = t_{\\mathcal{F}} + t_{\\mathcal{K}} + t_{\\mathcal{F}^{-1}} = 24 + 3 + 25 = 52$ ms.\n\n2.  **Hydrodynamics Phase Work ($W_{\\text{hydro}}$):** Tasks are performed on each of the $P=4$ subdomains. The work per subdomain is the sum of its task durations: $t_{\\mathrm{H\\_exL}} + t_{\\mathrm{H\\_exR}} + t_{\\mathrm{H\\_int}} + t_{\\mathrm{H\\_bnd}} = 1 + 1 + 6 + 2 = 10$ ms.\n    $W_{\\text{hydro}} = P \\times 10 = 4 \\times 10 = 40$ ms.\n\n3.  **Radiation Transport Phase Work ($W_{\\text{rad}}$):** Tasks for $G=3$ groups across $P=4$ subdomains. The work per group per subdomain is $t_{\\mathrm{R\\_upd}} + t_{\\mathrm{R\\_comm}} = 3 + 1 = 4$ ms.\n    $W_{\\text{rad}} = G \\times P \\times 4 = 3 \\times 4 \\times 4 = 48$ ms.\n\nThe total work $T_1$ is the sum of the work from all phases:\n$T_1 = W_{\\text{gravity}} + W_{\\text{hydro}} + W_{\\text{rad}} = 52 + 40 + 48 = 140$ ms.\n\nNext, we calculate the critical path length, $T_{\\infty}$, which is the longest path of dependent tasks.\n1.  **Gravity Phase Path:** The tasks are sequential. The path length is the sum of their durations.\n    $T_{\\text{gravity}} = 24 + 3 + 25 = 52$ ms.\n\n2.  **Hydrodynamics Phase Path:** This phase starts after gravity completes. For each subdomain, two branches start at $t=52$ ms:\n    -   Interior path: $T_{\\text{gravity}} + t_{\\mathrm{H\\_int}} = 52 + 6 = 58$ ms.\n    -   Boundary path: $T_{\\text{gravity}} + t_{\\mathrm{H\\_exL}} + t_{\\mathrm{H\\_exR}} + t_{\\mathrm{H\\_bnd}} = 52 + 1 + 1 + 2 = 56$ ms.\n    The synchronization barrier $\\mathrm{H\\_bar}$ is cleared at the maximum of these path times:\n    $T_{\\text{hydro}} = \\max(58, 56) = 58$ ms.\n\n3.  **Radiation Transport Phase Path:** This phase starts after the hydro barrier clears at $t=58$ ms. The three angular groups run in parallel, and since they are identical, we only need to trace the path of one group's sweep across the four subdomains.\n    -   Subdomain 1: Starts at 58 ms. Finishes update at $58+3=61$ ms. Finishes communication at $61+1=62$ ms.\n    -   Subdomain 2: Starts at 62 ms. Finishes update at $62+3=65$ ms. Finishes communication at $65+1=66$ ms.\n    -   Subdomain 3: Starts at 66 ms. Finishes update at $66+3=69$ ms. Finishes communication at $69+1=70$ ms.\n    -   Subdomain 4: Starts at 70 ms. Finishes update at $70+3=73$ ms. Finishes communication at $73+1=74$ ms.\n\nThe critical path length $T_{\\infty}$ is the completion time of the final task in the DAG, which is 74 ms.\nThe critical path is:\n$\\mathcal{F} \\rightarrow \\mathcal{K} \\rightarrow \\mathcal{F}^{-1} \\rightarrow \\mathrm{H\\_int} \\rightarrow \\mathrm{H\\_bar} \\rightarrow \\mathrm{R\\_upd}(g,1) \\rightarrow \\mathrm{R\\_comm}(g,1) \\rightarrow \\dots \\rightarrow \\mathrm{R\\_comm}(g,4)$.\nIts total duration is $52 + 6 + 4 \\times (3+1) = 58 + 16 = 74$ ms.\n\nThe computed values are $T_1 = 140$ ms and $T_{\\infty} = 74$ ms.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n74 & 140\n\\end{pmatrix}\n}\n$$", "id": "3516579"}, {"introduction": "In dynamic simulations, such as cosmological $N$-body calculations, computational load evolves, rendering any static work distribution suboptimal over time. This necessitates periodic rebalancing, which introduces its own overhead. This exercise places you in the role of a performance engineer, tasked with modeling the trade-off between the cost of growing imbalance and the cost of migration during repartitioning [@problem_id:3516560]. By minimizing the total runtime, you will derive an optimal repartitioning frequency, a key skill in tuning the performance of long-running, adaptive simulations.", "problem": "Consider a cosmological $N$-body simulation advanced in time on a distributed-memory cluster using the Message Passing Interface (MPI). The simulation employs a dynamic domain decomposition based on a space-filling curve to balance computational load across $P$ processes. Gravitational clustering drives inhomogeneity in particle distribution, which, in the absence of immediate repartitioning, produces a growing load imbalance. Let the fractional slowdown due to load imbalance be represented by a dimensionless function $\\eta(t)$, defined such that the instantaneous effective runtime rate is multiplied by $(1+\\eta(t))$, with $\\eta(t)\\ge 0$ and $\\eta(0)=0$. Empirically, over windows shorter than the dynamical time, assume $\\eta(t)$ grows approximately linearly between repartition events at a rate $\\dot{\\eta}>0$, and that a repartition event resets $\\eta(t)$ to approximately $0$.\n\nEach repartition event triggers particle and metadata migration with wall-clock cost modeled as $C_{m}=\\alpha\\, m+\\beta\\, b$, where $m$ is the number of messages and $b$ is the total migrated bytes during that event, $\\alpha$ is the effective per-message latency time, and $\\beta$ is the effective per-byte transmission time. Over a given time window of length $H>0$, suppose we choose to repartition periodically with frequency $f>0$ (period $\\tau=1/f$), and that $m$ and $b$ are the mean values per repartition over the window and can be treated as independent of $f$ under the chosen partitioner’s incremental strategy.\n\nUsing first principles of performance modeling, derive an analytic expression for the optimal repartition frequency $f^{\\star}$ that minimizes the total runtime $T_{\\text{total}}$ over the window of length $H$, where $T_{\\text{total}}$ is the sum of the baseline runtime without imbalance or repartition, the cumulative imbalance-induced overhead integrated over time, and the cumulative migration cost due to repartition events. Assume repartition events are instantaneous except for the additive migration cost $C_{m}$ and that the imbalance grows linearly between events. Express your final answer as a closed-form analytic expression in terms of $\\alpha$, $\\beta$, $m$, $b$, and $\\dot{\\eta}$. No numerical evaluation is required. If you find multiple stationary points, identify the one that minimizes $T_{\\text{total}}$.", "solution": "We aim to find the optimal repartition frequency $f^{\\star}$ that minimizes the total runtime $T_{\\text{total}}$ over a simulation window of length $H$. $T_{\\text{total}}$ is the sum of the time spent on computation (including imbalance overhead) and the time spent on migration.\n\n1.  **Modeling Total Runtime**\n    The total runtime can be expressed as a function of the repartition frequency $f$, or equivalently, the period $\\tau = 1/f$.\n    -   **Computational Time:** The simulation is divided into periods of length $\\tau$. Within each period, the imbalance function $\\eta(t')$ grows linearly from 0, so $\\eta(t') = \\dot{\\eta}t'$ for $t' \\in [0, \\tau)$. The wall-clock time required to advance one period of simulation time is found by integrating the slowdown factor:\n        $$ T_{\\text{period}} = \\int_{0}^{\\tau} (1 + \\eta(t')) dt' = \\int_{0}^{\\tau} (1 + \\dot{\\eta}t') dt' = \\left[ t' + \\frac{1}{2}\\dot{\\eta}{t'}^2 \\right]_{0}^{\\tau} = \\tau + \\frac{1}{2}\\dot{\\eta}\\tau^2 $$\n        The number of such periods in a simulation of length $H$ is $H/\\tau$. Thus, the total computational time $T_{\\text{comp}}$ is:\n        $$ T_{\\text{comp}} = \\frac{H}{\\tau} \\left( \\tau + \\frac{1}{2}\\dot{\\eta}\\tau^2 \\right) = H + \\frac{1}{2}H\\dot{\\eta}\\tau $$\n        Substituting $\\tau=1/f$, the computational time becomes:\n        $$ T_{\\text{comp}}(f) = H + \\frac{H\\dot{\\eta}}{2f} $$\n        The first term $H$ is the baseline runtime, and the second is the cumulative overhead from imbalance.\n\n    -   **Migration Cost:** A repartition event occurs at the end of each period. The number of repartitions in a window of length $H$ is $H/\\tau = Hf$. The cost of each event is $C_{m} = \\alpha m + \\beta b$. The total migration cost $T_{\\text{mig}}$ is:\n        $$ T_{\\text{mig}}(f) = (Hf)C_m = Hf(\\alpha m + \\beta b) $$\n\n    -   **Total Runtime:** Summing the two components gives the total runtime as a function of frequency:\n        $$ T_{\\text{total}}(f) = T_{\\text{comp}}(f) + T_{\\text{mig}}(f) = \\left(H + \\frac{H\\dot{\\eta}}{2f}\\right) + Hf(\\alpha m + \\beta b) $$\n\n2.  **Optimization**\n    To find the optimal frequency $f^{\\star}$ that minimizes $T_{\\text{total}}$, we take the derivative with respect to $f$ and set it to zero.\n    $$ \\frac{dT_{\\text{total}}}{df} = \\frac{d}{df} \\left( H + \\frac{H\\dot{\\eta}}{2}f^{-1} + H(\\alpha m + \\beta b)f \\right) $$\n    $$ \\frac{dT_{\\text{total}}}{df} = -\\frac{H\\dot{\\eta}}{2f^2} + H(\\alpha m + \\beta b) $$\n    Setting the derivative to zero yields:\n    $$ H(\\alpha m + \\beta b) = \\frac{H\\dot{\\eta}}{2f^2} $$\n    Since $H > 0$, we can simplify and solve for $f^2$:\n    $$ f^2 = \\frac{\\dot{\\eta}}{2(\\alpha m + \\beta b)} $$\n    As frequency must be positive, we take the positive square root:\n    $$ f^{\\star} = \\sqrt{\\frac{\\dot{\\eta}}{2(\\alpha m + \\beta b)}} $$\n    To confirm this is a minimum, we check the second derivative:\n    $$ \\frac{d^2T_{\\text{total}}}{df^2} = \\frac{d}{df} \\left( -\\frac{H\\dot{\\eta}}{2}f^{-2} + H(\\alpha m + \\beta b) \\right) = \\frac{H\\dot{\\eta}}{f^3} $$\n    Since $H > 0$, $\\dot{\\eta} > 0$, and $f > 0$, the second derivative is always positive. This confirms that $T_{\\text{total}}(f)$ is a convex function for $f>0$ and that $f^{\\star}$ corresponds to a global minimum.", "answer": "$$\n\\boxed{\\sqrt{\\frac{\\dot{\\eta}}{2(\\alpha m + \\beta b)}}}\n$$", "id": "3516560"}]}