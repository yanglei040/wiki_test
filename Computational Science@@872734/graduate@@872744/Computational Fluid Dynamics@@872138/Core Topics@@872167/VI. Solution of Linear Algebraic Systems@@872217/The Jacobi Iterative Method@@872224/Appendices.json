{"hands_on_practices": [{"introduction": "Before delving into the theoretical underpinnings of convergence, it is essential to gain a mechanical feel for how the Jacobi method operates. This first practice exercise focuses on the fundamental procedure: performing a single iterative step. By applying the Jacobi update formula to a small, well-behaved system, you will see firsthand how the solution vector is updated component-by-component, laying the groundwork for understanding the method's behavior over many iterations [@problem_id:1396123].", "problem": "Consider the system of linear equations $A\\mathbf{x} = \\mathbf{b}$, where the matrix $A$ and the vector $\\mathbf{b}$ are given by:\n$$\nA = \\begin{pmatrix} 10  -1  2 \\\\ 1  11  -1 \\\\ 2  -1  10 \\end{pmatrix}, \\quad \\mathbf{b} = \\begin{pmatrix} 6 \\\\ 25 \\\\ -11 \\end{pmatrix}\n$$\nStarting with the initial approximation $\\mathbf{x}^{(0)} = (0, 0, 0)^T$, perform a single iteration of the Jacobi method to find the next approximation $\\mathbf{x}^{(1)}$. Express your answer as a column vector with exact fractional components.", "solution": "For the Jacobi method applied to $A\\mathbf{x}=\\mathbf{b}$ with $A=\\left(a_{ij}\\right)$, the iteration is defined componentwise by\n$$\nx_{i}^{(k+1)}=\\frac{1}{a_{ii}}\\left(b_{i}-\\sum_{\\substack{j=1 \\\\ j\\neq i}}^{n}a_{ij}\\,x_{j}^{(k)}\\right).\n$$\nFor the given system\n$$\n\\begin{aligned}\n10x_{1}-x_{2}+2x_{3}=6,\\\\\nx_{1}+11x_{2}-x_{3}=25,\\\\\n2x_{1}-x_{2}+10x_{3}=-11,\n\\end{aligned}\n$$\nthe Jacobi updates are\n$$\nx_{1}^{(k+1)}=\\frac{1}{10}\\left(6+x_{2}^{(k)}-2x_{3}^{(k)}\\right),\\quad\nx_{2}^{(k+1)}=\\frac{1}{11}\\left(25-x_{1}^{(k)}+x_{3}^{(k)}\\right),\\quad\nx_{3}^{(k+1)}=\\frac{1}{10}\\left(-11-2x_{1}^{(k)}+x_{2}^{(k)}\\right).\n$$\nWith the initial approximation $\\mathbf{x}^{(0)}=(0,0,0)^{T}$, substituting $x_{1}^{(0)}=0$, $x_{2}^{(0)}=0$, and $x_{3}^{(0)}=0$ gives\n$$\nx_{1}^{(1)}=\\frac{1}{10}\\left(6+0-2\\cdot 0\\right)=\\frac{3}{5},\\quad\nx_{2}^{(1)}=\\frac{1}{11}\\left(25-0+0\\right)=\\frac{25}{11},\\quad\nx_{3}^{(1)}=\\frac{1}{10}\\left(-11-2\\cdot 0+0\\right)=-\\frac{11}{10}.\n$$\nTherefore,\n$$\n\\mathbf{x}^{(1)}=\\begin{pmatrix}\\frac{3}{5}\\\\ \\frac{25}{11}\\\\ -\\frac{11}{10}\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{3}{5}\\\\ \\frac{25}{11}\\\\ -\\frac{11}{10}\\end{pmatrix}}$$", "id": "1396123"}, {"introduction": "Having seen *how* the Jacobi iteration is performed, we now turn to the critical question of *when* it works. An iterative method is useless if it does not converge to the true solution. This exercise moves from mechanics to theory, guiding you through the calculation of the Jacobi iteration matrix and its spectral radius—the key determinant of convergence [@problem_id:3503366]. Mastering this analysis provides the necessary and sufficient condition to guarantee that the iterations will succeed.", "problem": "Consider a two-field linearized, steady multiphysics coupling between a diffusion-like process and a reaction-like process discretized over a single representative control volume, resulting in a $2 \\times 2$ algebraic system $A x = b$ with \n$$A = \\begin{bmatrix} 4  1 \\\\ 1  3 \\end{bmatrix}, \\quad b = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}.$$\nAssume the system arises from a consistent finite-volume balance and that the matrix $A$ is symmetric positive definite (SPD), a property often satisfied for coupled elliptic operators after appropriate stabilization and consistent coupling. Starting solely from the core definition of the Jacobi method as a fixed-point iteration that decouples the diagonal part of $A$ from its off-diagonal remainder, and using the fundamental fact from linear fixed-point theory that a linear iteration $x^{k+1} = T x^{k} + c$ converges for any initial guess if and only if the spectral radius $\\rho(T)$ is strictly less than $1$, perform the following:\n\n1. Derive the Jacobi iteration matrix for this system by splitting $A$ into its diagonal and off-diagonal parts. \n2. Compute the spectral radius of the derived Jacobi iteration matrix by exact eigenanalysis.\n3. Based on the spectral radius, determine whether the Jacobi method converges for any initial guess.\n\nExpress your final answer as a single row matrix with six entries, containing the four entries of the Jacobi iteration matrix in row-major order, followed by the spectral radius, followed by an indicator variable for convergence, where $1$ denotes convergence and $0$ denotes non-convergence. No rounding is required; provide exact analytic values. The final answer must be unitless.", "solution": "The problem asks us to analyze the convergence of the Jacobi iterative method for the linear system $A x = b$, where\n$$ A = \\begin{bmatrix} 4  1 \\\\ 1  3 \\end{bmatrix}, \\quad x = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}, \\quad b = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} $$\nThe Jacobi method is a fixed-point iteration derived by splitting the matrix $A$ into its diagonal part $D$, its strictly lower triangular part $L$, and its strictly upper triangular part $U$, such that $A = D + L + U$. The system $Ax=b$ can be rewritten as $(D + L + U)x = b$. The Jacobi iteration is defined by rearranging this equation to solve for the next iteration $x^{k+1}$ using the entries on the diagonal:\n$$ D x^{k+1} = -(L+U)x^k + b $$\nThis can be expressed in the standard form of a linear fixed-point iteration, $x^{k+1} = T_J x^k + c$, by isolating $x^{k+1}$:\n$$ x^{k+1} = -D^{-1}(L+U)x^k + D^{-1}b $$\nThe matrix $T_J = -D^{-1}(L+U)$ is the Jacobi iteration matrix. The convergence of the method for any initial guess $x^0$ is guaranteed if and only if the spectral radius of $T_J$, denoted by $\\rho(T_J)$, is strictly less than $1$. The spectral radius is the maximum absolute value of the eigenvalues of $T_J$.\n\n**1. Derive the Jacobi iteration matrix**\n\nFirst, we decompose the given matrix $A$ into its components $D$, $L$, and $U$.\n$$ A = \\begin{bmatrix} 4  1 \\\\ 1  3 \\end{bmatrix} $$\nThe diagonal part $D$ is:\n$$ D = \\begin{bmatrix} 4  0 \\\\ 0  3 \\end{bmatrix} $$\nThe strictly lower and upper triangular parts are:\n$$ L = \\begin{bmatrix} 0  0 \\\\ 1  0 \\end{bmatrix}, \\quad U = \\begin{bmatrix} 0  1 \\\\ 0  0 \\end{bmatrix} $$\nThe sum of the off-diagonal parts is:\n$$ L+U = \\begin{bmatrix} 0  1 \\\\ 1  0 \\end{bmatrix} $$\nNext, we compute the inverse of the diagonal matrix $D$:\n$$ D^{-1} = \\begin{bmatrix} 4^{-1}  0 \\\\ 0  3^{-1} \\end{bmatrix} = \\begin{bmatrix} \\frac{1}{4}  0 \\\\ 0  \\frac{1}{3} \\end{bmatrix} $$\nNow we can compute the Jacobi iteration matrix $T_J = -D^{-1}(L+U)$:\n$$ T_J = - \\begin{bmatrix} \\frac{1}{4}  0 \\\\ 0  \\frac{1}{3} \\end{bmatrix} \\begin{bmatrix} 0  1 \\\\ 1  0 \\end{bmatrix} = - \\begin{bmatrix} (\\frac{1}{4})(0) + (0)(1)  (\\frac{1}{4})(1) + (0)(0) \\\\ (0)(0) + (\\frac{1}{3})(1)  (0)(1) + (\\frac{1}{3})(0) \\end{bmatrix} $$\n$$ T_J = - \\begin{bmatrix} 0  \\frac{1}{4} \\\\ \\frac{1}{3}  0 \\end{bmatrix} = \\begin{bmatrix} 0  -\\frac{1}{4} \\\\ -\\frac{1}{3}  0 \\end{bmatrix} $$\n\n**2. Compute the spectral radius of the Jacobi matrix**\n\nTo find the spectral radius $\\rho(T_J)$, we must find the eigenvalues of $T_J$ by solving the characteristic equation $\\det(T_J - \\lambda I) = 0$, where $I$ is the identity matrix.\n$$ \\det \\left( \\begin{bmatrix} 0  -\\frac{1}{4} \\\\ -\\frac{1}{3}  0 \\end{bmatrix} - \\lambda \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix} \\right) = 0 $$\n$$ \\det \\begin{bmatrix} -\\lambda  -\\frac{1}{4} \\\\ -\\frac{1}{3}  -\\lambda \\end{bmatrix} = 0 $$\nThe determinant is calculated as:\n$$ (-\\lambda)(-\\lambda) - \\left(-\\frac{1}{4}\\right)\\left(-\\frac{1}{3}\\right) = 0 $$\n$$ \\lambda^2 - \\frac{1}{12} = 0 $$\nSolving for $\\lambda$, we find the eigenvalues:\n$$ \\lambda^2 = \\frac{1}{12} $$\n$$ \\lambda = \\pm \\sqrt{\\frac{1}{12}} = \\pm \\frac{1}{\\sqrt{4 \\times 3}} = \\pm \\frac{1}{2\\sqrt{3}} $$\nTo rationalize the denominator, we multiply the numerator and denominator by $\\sqrt{3}$:\n$$ \\lambda = \\pm \\frac{\\sqrt{3}}{2\\sqrt{3}\\sqrt{3}} = \\pm \\frac{\\sqrt{3}}{6} $$\nThe two eigenvalues are $\\lambda_1 = \\frac{\\sqrt{3}}{6}$ and $\\lambda_2 = -\\frac{\\sqrt{3}}{6}$. The spectral radius $\\rho(T_J)$ is the maximum of the absolute values of these eigenvalues:\n$$ \\rho(T_J) = \\max\\left( \\left|\\frac{\\sqrt{3}}{6}\\right|, \\left|-\\frac{\\sqrt{3}}{6}\\right| \\right) = \\max\\left( \\frac{\\sqrt{3}}{6}, \\frac{\\sqrt{3}}{6} \\right) = \\frac{\\sqrt{3}}{6} $$\n\n**3. Determine convergence**\n\nThe Jacobi method converges for any initial guess if and only if $\\rho(T_J)  1$. We must check if $\\frac{\\sqrt{3}}{6}  1$.\nSince $1  3  36$, we have $\\sqrt{1}  \\sqrt{3}  \\sqrt{36}$, which means $1  \\sqrt{3}  6$.\nDividing by $6$, we get $\\frac{1}{6}  \\frac{\\sqrt{3}}{6}  1$.\nSince $\\frac{\\sqrt{3}}{6}  1$, the Jacobi method is guaranteed to converge for any initial guess. The corresponding convergence indicator is $1$.\n\nThe final answer is a row matrix containing the four entries of $T_J$ ($T_{11}, T_{12}, T_{21}, T_{22}$), the spectral radius $\\rho(T_J)$, and the convergence indicator ($1$).\nThe entries are: $0$, $-\\frac{1}{4}$, $-\\frac{1}{3}$, $0$, $\\frac{\\sqrt{3}}{6}$, and $1$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 0  -\\frac{1}{4}  -\\frac{1}{3}  0  \\frac{\\sqrt{3}}{6}  1 \\end{pmatrix}}\n$$", "id": "3503366"}, {"introduction": "In real-world computational fluid dynamics (CFD), matrices derived from discretized Partial Differential Equations are often too large for their spectral radius to be computed directly. Instead, practitioners rely on enforcing sufficient conditions that guarantee convergence, such as strict diagonal dominance. This advanced practice demonstrates how this theoretical concept is applied to a discretized advection-diffusion equation, a cornerstone of transport phenomena [@problem_id:3374690]. You will determine the amount of artificial stabilization needed to make the system amenable to the Jacobi method, a common task in developing robust numerical schemes.", "problem": "Consider the steady, one-dimensional linear advection–diffusion equation for a scalar field $\\,\\phi(x)\\,$ on the interval $\\,[0,L]\\,$ with uniform advection speed $\\,U \\ge 0\\,$ and molecular diffusivity $\\,K  0\\,$:\n$$\nU \\,\\frac{d \\phi}{dx} \\;-\\; K \\,\\frac{d^{2}\\phi}{dx^{2}} \\;=\\; f(x),\n$$\nsubject to Dirichlet boundary conditions $\\,\\phi(0)=\\phi_{L}\\,$ and $\\,\\phi(L)=\\phi_{R}\\,$. Discretize the interior using a uniform grid with $\\,N\\,$ interior unknowns and spacing $\\,h = L/(N+1)\\,$. Approximate the advection and diffusion terms by second-order central differences at each interior node $\\,x_{i}\\,$:\n$$\nU \\,\\frac{\\phi_{i+1}-\\phi_{i-1}}{2h} \\;-\\; K \\,\\frac{\\phi_{i-1} - 2\\phi_{i} + \\phi_{i+1}}{h^{2}} \\;=\\; f_{i}.\n$$\nAugment the discrete operator by two stabilization mechanisms commonly employed in computational fluid dynamics: \n- a second-order artificial viscosity $\\,\\varepsilon \\ge 0\\,$ (with the same physical units as $\\,K\\,$) added to the diffusion operator, and \n- a zeroth-order artificial damping coefficient $\\,s \\ge 0\\,$ applied locally at each interior node.\n\nThus, the stabilized linear system for the interior unknowns has the form $\\,A \\phi = b\\,$, where $\\,A\\,$ is tridiagonal with coefficients to be determined from the above discretization and stabilizations. It is known that a sufficient condition for convergence of the Jacobi iterative method applied to $\\,A \\phi = b\\,$ is that $\\,A\\,$ is strictly diagonally dominant by rows.\n\nStarting from these discretizations and the definition of strict diagonal dominance by rows, derive the minimal value $\\,s_{\\min}(U,K,\\varepsilon,h)\\,$ such that, for any $\\,s  s_{\\min}\\,$, the coefficient matrix $\\,A\\,$ is strictly diagonally dominant by rows at every interior node. Express your answer as a single closed-form analytic expression in terms of $\\,U, K, \\varepsilon,\\,$ and $\\,h\\,$. Express the final answer in inverse time units (that is, the same units as $\\,U/h\\,$ and $\\,K/h^{2}\\,$). No numerical values are to be substituted or rounded.", "solution": "To find the minimal value $s_{\\min}$, we must first construct the matrix $A$ and then apply the condition of strict diagonal dominance.\n\nThe given discrete equation at an interior node $i$ is:\n$$\nU \\frac{\\phi_{i+1}-\\phi_{i-1}}{2h} - K \\frac{\\phi_{i-1} - 2\\phi_{i} + \\phi_{i+1}}{h^{2}} = f_{i}\n$$\nWe incorporate the two stabilization mechanisms. First, the artificial viscosity $\\varepsilon$ is added to the physical diffusivity $K$, resulting in an effective diffusivity $K_{eff} = K+\\varepsilon$. Second, the local artificial damping adds a term $s\\phi_i$ to the left-hand side of the operator. The stabilized discrete equation becomes:\n$$\nU \\frac{\\phi_{i+1}-\\phi_{i-1}}{2h} - (K+\\varepsilon) \\frac{\\phi_{i-1} - 2\\phi_{i} + \\phi_{i+1}}{h^{2}} + s\\phi_i = f_{i}\n$$\nTo determine the coefficients of the matrix $A$, we rearrange this equation to group terms by the unknowns $\\phi_{i-1}$, $\\phi_i$, and $\\phi_{i+1}$:\n$$\n\\left(-\\frac{U}{2h} - \\frac{K+\\varepsilon}{h^2}\\right)\\phi_{i-1} + \\left(\\frac{2(K+\\varepsilon)}{h^2} + s\\right)\\phi_i + \\left(\\frac{U}{2h} - \\frac{K+\\varepsilon}{h^2}\\right)\\phi_{i+1} = f_i\n$$\nThis equation defines the entries of the $i$-th row of the tridiagonal matrix $A$ for the interior nodes. For $i=1, \\dots, N$, the non-zero entries of row $i$ are:\n- Sub-diagonal ($j=i-1$): $A_{i, i-1} = -\\frac{U}{2h} - \\frac{K+\\varepsilon}{h^2}$\n- Diagonal ($j=i$): $A_{i, i} = \\frac{2(K+\\varepsilon)}{h^2} + s$\n- Super-diagonal ($j=i+1$): $A_{i, i+1} = \\frac{U}{2h} - \\frac{K+\\varepsilon}{h^2}$\n\nFor the first row ($i=1$), the $\\phi_0$ term involves a known boundary value and is moved to the right-hand side, so $A_{1,0}$ is not part of the matrix $A$. Similarly for the last row ($i=N$), the $\\phi_{N+1}$ term is moved to the right-hand side.\n\nA matrix $A$ is strictly diagonally dominant by rows if for every row $i$, the absolute value of the diagonal element is strictly greater than the sum of the absolute values of all other elements in that row:\n$$\n|A_{i,i}|  \\sum_{j \\neq i} |A_{i,j}|\n$$\nSince $A$ is tridiagonal, this condition becomes:\n- For $i=1$: $|A_{1,1}|  |A_{1,2}|$\n- For $1  i  N$: $|A_{i,i}|  |A_{i, i-1}| + |A_{i, i+1}|$\n- For $i=N$: $|A_{N,N}|  |A_{N, N-1}|$\n\nLet's analyze the condition for a generic interior row ($1  i  N$), as this involves the sum of two off-diagonal terms and is typically the most restrictive case.\n\nThe diagonal element is $A_{i,i} = \\frac{2(K+\\varepsilon)}{h^2} + s$. Since $K0$, $\\varepsilon \\ge 0$, $s \\ge 0$, and $h0$, $A_{i,i}$ is strictly positive. Thus, $|A_{i,i}| = \\frac{2(K+\\varepsilon)}{h^2} + s$.\n\nThe off-diagonal elements' absolute values are:\n$|A_{i, i-1}| = \\left|-\\frac{U}{2h} - \\frac{K+\\varepsilon}{h^2}\\right| = \\frac{U}{2h} + \\frac{K+\\varepsilon}{h^2}$ (since $U \\ge 0$)\n$|A_{i, i+1}| = \\left|\\frac{U}{2h} - \\frac{K+\\varepsilon}{h^2}\\right|$\n\nThe strict diagonal dominance condition for an interior row is:\n$$\n\\frac{2(K+\\varepsilon)}{h^2} + s  \\left(\\frac{U}{2h} + \\frac{K+\\varepsilon}{h^2}\\right) + \\left|\\frac{U}{2h} - \\frac{K+\\varepsilon}{h^2}\\right|\n$$\nSubtracting $\\frac{K+\\varepsilon}{h^2}$ from both sides gives:\n$$\n\\frac{K+\\varepsilon}{h^2} + s  \\frac{U}{2h} + \\left|\\frac{U}{2h} - \\frac{K+\\varepsilon}{h^2}\\right|\n$$\nWe analyze this inequality by considering two cases for the term inside the absolute value, which is related to the cell Péclet number $Pe = \\frac{Uh}{K+\\varepsilon}$. The sign depends on whether $\\frac{U}{2h} \\ge \\frac{K+\\varepsilon}{h^2}$ or not, which is equivalent to $Pe \\ge 2$.\n\nCase 1: $\\frac{U}{2h} \\ge \\frac{K+\\varepsilon}{h^2}$ (i.e., $Pe \\ge 2$)\nIn this case, $\\left|\\frac{U}{2h} - \\frac{K+\\varepsilon}{h^2}\\right| = \\frac{U}{2h} - \\frac{K+\\varepsilon}{h^2}$. The inequality becomes:\n$$\n\\frac{K+\\varepsilon}{h^2} + s  \\frac{U}{2h} + \\left(\\frac{U}{2h} - \\frac{K+\\varepsilon}{h^2}\\right)\n$$\n$$\n\\frac{K+\\varepsilon}{h^2} + s  \\frac{U}{h} - \\frac{K+\\varepsilon}{h^2}\n$$\nSolving for $s$:\n$$\ns  \\frac{U}{h} - \\frac{2(K+\\varepsilon)}{h^2}\n$$\n\nCase 2: $\\frac{U}{2h}  \\frac{K+\\varepsilon}{h^2}$ (i.e., $Pe  2$)\nIn this case, $\\left|\\frac{U}{2h} - \\frac{K+\\varepsilon}{h^2}\\right| = - \\left(\\frac{U}{2h} - \\frac{K+\\varepsilon}{h^2}\\right) = \\frac{K+\\varepsilon}{h^2} - \\frac{U}{2h}$. The inequality becomes:\n$$\n\\frac{K+\\varepsilon}{h^2} + s  \\frac{U}{2h} + \\left(\\frac{K+\\varepsilon}{h^2} - \\frac{U}{2h}\\right)\n$$\n$$\n\\frac{K+\\varepsilon}{h^2} + s  \\frac{K+\\varepsilon}{h^2}\n$$\nSolving for $s$:\n$$\ns  0\n$$\n\nCombining these two cases, the condition for $s$ to ensure strict diagonal dominance for any interior row is:\n$$\ns  \\max\\left(0, \\frac{U}{h} - \\frac{2(K+\\varepsilon)}{h^2}\\right)\n$$\nNow, we must verify that this condition is also sufficient for the boundary rows ($i=1$ and $i=N$).\nFor $i=1$: $|A_{1,1}||A_{1,2}| \\implies \\frac{2(K+\\varepsilon)}{h^2} + s  \\left|\\frac{U}{2h} - \\frac{K+\\varepsilon}{h^2}\\right|$.\nFor $i=N$: $|A_{N,N}||A_{N,N-1}| \\implies \\frac{2(K+\\varepsilon)}{h^2} + s  \\left|-\\frac{U}{2h} - \\frac{K+\\varepsilon}{h^2}\\right| = \\frac{U}{2h} + \\frac{K+\\varepsilon}{h^2}$.\nThe interior row condition is $\\frac{2(K+\\varepsilon)}{h^2} + s  \\left(\\frac{U}{2h} + \\frac{K+\\varepsilon}{h^2}\\right) + \\left|\\frac{U}{2h} - \\frac{K+\\varepsilon}{h^2}\\right|$. Since both terms on the right side are non-negative, the right-hand side for the interior row condition is greater than or equal to the right-hand side for either boundary row. Therefore, satisfying the condition for the interior rows guarantees it for the boundary rows.\n\nThe minimal value $s_{\\min}$ for the damping coefficient is the threshold value from this most restrictive condition.\n$$\ns_{\\min}(U,K,\\varepsilon,h) = \\max\\left(0, \\frac{U}{h} - \\frac{2(K+\\varepsilon)}{h^2}\\right)\n$$\nThe units of $U/h$ are $(length/time)/length = 1/time$. The units of $(K+\\varepsilon)/h^2$ are $(length^2/time)/length^2 = 1/time$. The expression for $s_{\\min}$ is thus in inverse time units, as required.", "answer": "$$\n\\boxed{\\max\\left(0, \\frac{U}{h} - \\frac{2(K+\\varepsilon)}{h^{2}}\\right)}\n$$", "id": "3374690"}]}