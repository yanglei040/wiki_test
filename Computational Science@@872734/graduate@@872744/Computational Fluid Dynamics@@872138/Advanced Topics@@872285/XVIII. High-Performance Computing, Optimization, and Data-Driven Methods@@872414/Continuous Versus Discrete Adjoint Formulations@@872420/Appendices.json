{"hands_on_practices": [{"introduction": "Mastering the \"optimize-then-discretize\" approach begins with deriving the continuous adjoint equations from first principles. This exercise solidifies that foundational skill by applying the Lagrangian method to a canonical unsteady convection-diffusion problem. By manipulating the governing PDE and the objective functional using calculus of variations, you will derive the adjoint PDE and its associated boundary and terminal conditions, revealing how sensitivities are propagated backward in time [@problem_id:3304882].", "problem": "Consider a scalar unsteady convection-diffusion process on a bounded, Lipschitz domain $\\Omega \\subset \\mathbb{R}^{d}$, with $d \\in \\{1,2,3\\}$, over a fixed time horizon $[0,T]$. The state $u:\\Omega \\times [0,T] \\to \\mathbb{R}$ satisfies the initial-boundary value problem\n$$\n\\partial_{t} u + \\boldsymbol{v}(\\boldsymbol{x},t) \\cdot \\nabla u - \\nabla \\cdot \\left( \\kappa \\nabla u \\right) = q(\\boldsymbol{x},t) \\quad \\text{in } \\Omega \\times (0,T),\n$$\nwith homogeneous Dirichlet boundary condition $u=0$ on $\\partial \\Omega \\times (0,T)$ and prescribed initial condition $u(\\boldsymbol{x},0)=u_{0}(\\boldsymbol{x})$ on $\\Omega$. Assume $\\kappa>0$ is a positive constant, $\\boldsymbol{v}(\\boldsymbol{x},t)$ is divergence-free, i.e., $\\nabla \\cdot \\boldsymbol{v}(\\boldsymbol{x},t)=0$ for all $(\\boldsymbol{x},t)$, and $q$ and $u_{0}$ are sufficiently smooth for all formal manipulations below to be justified.\n\nDefine the performance functional\n$$\nJ(u) \\;=\\; \\int_{0}^{T} g\\!\\left(u(\\cdot,t)\\right) \\,\\mathrm{d}t \\;+\\; R\\!\\left(u(\\cdot,T)\\right),\n$$\nwhere\n$$\ng\\!\\left(u(\\cdot,t)\\right) \\;=\\; \\int_{\\Omega} \\ell\\!\\left(u(\\boldsymbol{x},t)\\right) \\,\\mathrm{d}\\boldsymbol{x}, \n\\qquad\nR\\!\\left(u(\\cdot,T)\\right) \\;=\\; \\int_{\\Omega} r\\!\\left(u(\\boldsymbol{x},T)\\right) \\,\\mathrm{d}\\boldsymbol{x},\n$$\nand $\\ell:\\mathbb{R}\\to\\mathbb{R}$, $r:\\mathbb{R}\\to\\mathbb{R}$ are continuously differentiable with derivatives denoted $\\ell_{u}$ and $r_{u}$, respectively.\n\nStarting from the strong form of the state equation and the definition of $J(u)$, use a Lagrangian construction and integration by parts to derive the continuous adjoint partial differential equation for the adjoint field $\\psi:\\Omega \\times [0,T]\\to \\mathbb{R}$, together with its associated boundary and terminal-in-time conditions. Assume that the Dirichlet boundary condition on $u$ is enforced strongly, so that the corresponding variation of $u$ vanishes on $\\partial \\Omega \\times (0,T)$.\n\nExplain, based on the structure of $J(u)$, when a terminal adjoint condition is present or absent, and how it depends on the presence of a terminal contribution $R(u(\\cdot,T))$ versus a purely running contribution $g(u(\\cdot,t))$.\n\nYour final answer must be the closed-form analytic expression for the terminal adjoint condition $\\psi(\\boldsymbol{x},T)$ in terms of $r_{u}$ and $u(\\boldsymbol{x},T)$. If no terminal contribution $R$ is present, interpret your expression accordingly. No numerical evaluation is required, and no units are needed.", "solution": "The problem asks for the derivation of the continuous adjoint equation, boundary conditions, and terminal condition associated with an unsteady convection-diffusion process, using a Lagrangian framework. The goal is to determine the expression for the terminal adjoint condition and explain its dependence on the performance functional $J(u)$.\n\nThe problem statement is validated as scientifically grounded, well-posed, and objective. It represents a standard application of calculus of variations for deriving adjoint systems in the context of partial differential equations, a cornerstone of sensitivity analysis and optimization in computational science. All necessary information is provided, and the premises are consistent. We may therefore proceed with the solution.\n\nThe state equation is given by\n$$\n\\mathcal{N}(u) := \\partial_{t} u + \\boldsymbol{v} \\cdot \\nabla u - \\nabla \\cdot \\left( \\kappa \\nabla u \\right) - q = 0 \\quad \\text{in } \\Omega \\times (0,T)\n$$\nwith initial condition $u(\\boldsymbol{x},0) = u_{0}(\\boldsymbol{x})$ and boundary condition $u|_{\\partial\\Omega \\times (0,T)} = 0$. The performance functional is\n$$\nJ(u) = \\int_{0}^{T} \\int_{\\Omega} \\ell(u(\\boldsymbol{x},t)) \\,\\mathrm{d}\\boldsymbol{x} \\,\\mathrm{d}t + \\int_{\\Omega} r(u(\\boldsymbol{x},T)) \\,\\mathrm{d}\\boldsymbol{x}\n$$\nWe introduce the adjoint field $\\psi(\\boldsymbol{x},t)$ as a Lagrange multiplier to enforce the state equation as a constraint. The Lagrangian functional $\\mathcal{L}(u, \\psi)$ is defined as:\n$$\n\\mathcal{L}(u, \\psi) = J(u) + \\int_{0}^{T} \\int_{\\Omega} \\psi \\, \\mathcal{N}(u) \\,\\mathrm{d}\\boldsymbol{x} \\,\\mathrm{d}t\n$$\nSubstituting the expressions for $J(u)$ and $\\mathcal{N}(u)$:\n$$\n\\mathcal{L}(u, \\psi) = \\int_{0}^{T} \\int_{\\Omega} \\ell(u) \\,\\mathrm{d}\\boldsymbol{x} \\,\\mathrm{d}t + \\int_{\\Omega} r(u(\\cdot,T)) \\,\\mathrm{d}\\boldsymbol{x} + \\int_{0}^{T} \\int_{\\Omega} \\psi \\left( \\partial_{t} u + \\boldsymbol{v} \\cdot \\nabla u - \\nabla \\cdot (\\kappa \\nabla u) - q \\right) \\,\\mathrm{d}\\boldsymbol{x} \\,\\mathrm{d}t\n$$\nTo find the adjoint equations, we compute the first variation of $\\mathcal{L}$ with respect to $u$ in an arbitrary, admissible direction $\\delta u$, and set it to zero. A perturbation $\\delta u$ is admissible if it satisfies homogeneous initial and boundary conditions, i.e., $\\delta u(\\boldsymbol{x},0) = 0$ on $\\Omega$ and $\\delta u = 0$ on $\\partial\\Omega \\times (0,T)$.\nThe first variation is $\\delta\\mathcal{L}[\\delta u] = \\frac{\\mathrm{d}}{\\mathrm{d}\\epsilon}\\Big|_{\\epsilon=0} \\mathcal{L}(u+\\epsilon\\delta u, \\psi)$.\n\nThe variation of the performance functional $J(u)$ is:\n$$\n\\delta J = \\int_{0}^{T} \\int_{\\Omega} \\ell_{u}(u) \\delta u \\,\\mathrm{d}\\boldsymbol{x} \\,\\mathrm{d}t + \\int_{\\Omega} r_{u}(u(\\cdot,T)) \\delta u(\\cdot,T) \\,\\mathrm{d}\\boldsymbol{x}\n$$\nThe variation of the constraint term is:\n$$\n\\delta \\left( \\int_{0}^{T} \\int_{\\Omega} \\psi \\, \\mathcal{N}(u) \\,\\mathrm{d}\\boldsymbol{x} \\,\\mathrm{d}t \\right) = \\int_{0}^{T} \\int_{\\Omega} \\psi \\left( \\partial_{t} \\delta u + \\boldsymbol{v} \\cdot \\nabla \\delta u - \\nabla \\cdot (\\kappa \\nabla \\delta u) \\right) \\,\\mathrm{d}\\boldsymbol{x} \\,\\mathrm{d}t\n$$\nWe apply integration by parts to each term in the expression above to transfer all differential operators from the variation $\\delta u$ to the adjoint field $\\psi$.\n\n1.  **Time derivative term:**\n    $$\n    \\int_{0}^{T} \\int_{\\Omega} \\psi \\, \\partial_{t} \\delta u \\,\\mathrm{d}\\boldsymbol{x} \\,\\mathrm{d}t = \\int_{\\Omega} \\left[ \\psi \\delta u \\right]_{t=0}^{t=T} \\,\\mathrm{d}\\boldsymbol{x} - \\int_{0}^{T} \\int_{\\Omega} (\\partial_{t}\\psi) \\delta u \\,\\mathrm{d}\\boldsymbol{x} \\,\\mathrm{d}t\n    $$\n    This becomes $\\int_{\\Omega} \\psi(\\boldsymbol{x},T) \\delta u(\\boldsymbol{x},T) \\,\\mathrm{d}\\boldsymbol{x} - \\int_{0}^{T} \\int_{\\Omega} (\\partial_{t}\\psi) \\delta u \\,\\mathrm{d}\\boldsymbol{x} \\,\\mathrm{d}t$, since $\\delta u(\\boldsymbol{x},0) = 0$.\n\n2.  **Convection term:** Given the divergence-free condition $\\nabla \\cdot \\boldsymbol{v} = 0$, we have $\\psi (\\boldsymbol{v} \\cdot \\nabla \\delta u) = \\psi \\nabla \\cdot (\\delta u \\boldsymbol{v}) = \\nabla \\cdot (\\psi \\delta u \\boldsymbol{v}) - \\delta u (\\boldsymbol{v} \\cdot \\nabla \\psi)$.\n    $$\n    \\int_{0}^{T} \\int_{\\Omega} \\psi (\\boldsymbol{v} \\cdot \\nabla \\delta u) \\,\\mathrm{d}\\boldsymbol{x} \\,\\mathrm{d}t = \\int_{0}^{T} \\int_{\\Omega} \\left( \\nabla \\cdot (\\psi \\delta u \\boldsymbol{v}) - \\delta u (\\boldsymbol{v} \\cdot \\nabla \\psi) \\right) \\,\\mathrm{d}\\boldsymbol{x} \\,\\mathrm{d}t\n    $$\n    By the Divergence Theorem, $\\int_{\\Omega} \\nabla \\cdot (\\psi \\delta u \\boldsymbol{v}) \\,\\mathrm{d}\\boldsymbol{x} = \\int_{\\partial\\Omega} \\psi \\delta u (\\boldsymbol{v} \\cdot \\boldsymbol{n}) \\,\\mathrm{d}S = 0$, because $\\delta u = 0$ on $\\partial\\Omega$. The term reduces to $-\\int_{0}^{T} \\int_{\\Omega} \\delta u (\\boldsymbol{v} \\cdot \\nabla \\psi) \\,\\mathrm{d}\\boldsymbol{x} \\,\\mathrm{d}t$.\n\n3.  **Diffusion term:** We apply integration by parts twice.\n    $$\n    -\\int_{0}^{T} \\int_{\\Omega} \\psi \\nabla \\cdot (\\kappa \\nabla \\delta u) \\,\\mathrm{d}\\boldsymbol{x} \\,\\mathrm{d}t = -\\int_{0}^{T} \\left( \\int_{\\partial\\Omega} \\psi \\kappa (\\nabla\\delta u \\cdot \\boldsymbol{n}) \\,\\mathrm{d}S - \\int_{\\Omega} \\nabla\\psi \\cdot (\\kappa \\nabla\\delta u) \\,\\mathrm{d}\\boldsymbol{x} \\right) \\mathrm{d}t\n    $$\n    Applying integration by parts to the second term in the parenthesis:\n    $$\n    \\int_{\\Omega} \\nabla\\psi \\cdot (\\kappa \\nabla\\delta u) \\,\\mathrm{d}\\boldsymbol{x} = \\int_{\\partial\\Omega} \\delta u (\\kappa \\nabla\\psi \\cdot \\boldsymbol{n}) \\,\\mathrm{d}S - \\int_{\\Omega} \\delta u \\nabla\\cdot(\\kappa \\nabla\\psi) \\,\\mathrm{d}\\boldsymbol{x}\n    $$\n    Since $\\delta u = 0$ on $\\partial\\Omega$, the new boundary integral vanishes. Combining results, the diffusion term becomes:\n    $$\n    -\\int_{0}^{T} \\int_{\\partial\\Omega} \\psi \\kappa (\\nabla\\delta u \\cdot \\boldsymbol{n}) \\,\\mathrm{d}S \\,\\mathrm{d}t - \\int_{0}^{T} \\int_{\\Omega} \\delta u \\nabla\\cdot(\\kappa \\nabla\\psi) \\,\\mathrm{d}\\boldsymbol{x} \\,\\mathrm{d}t\n    $$\n    For the variation $\\delta\\mathcal{L}$ to be independent of the choice of $\\delta u$, the boundary term must vanish for any admissible $\\delta u$. Since $\\nabla\\delta u \\cdot \\boldsymbol{n}$ is not necessarily zero on the boundary, we must enforce the homogeneous Dirichlet boundary condition $\\psi=0$ on $\\partial\\Omega \\times (0,T)$. This yields the adjoint boundary condition. With this choice, the diffusion term simplifies to $-\\int_{0}^{T} \\int_{\\Omega} \\delta u \\nabla\\cdot(\\kappa \\nabla\\psi) \\,\\mathrm{d}\\boldsymbol{x} \\,\\mathrm{d}t$. Since $\\kappa$ is a constant, $\\nabla\\cdot(\\kappa \\nabla\\psi) = \\kappa \\nabla^{2}\\psi$.\n\nCombining all terms, the total variation $\\delta\\mathcal{L}$ is:\n$$\n\\delta\\mathcal{L} = \\int_{0}^{T} \\int_{\\Omega} \\left[ \\ell_{u}(u) - \\partial_{t}\\psi - \\boldsymbol{v} \\cdot \\nabla \\psi - \\kappa \\nabla^{2}\\psi \\right] \\delta u \\,\\mathrm{d}\\boldsymbol{x} \\,\\mathrm{d}t + \\int_{\\Omega} \\left[ r_{u}(u(\\cdot,T)) + \\psi(\\boldsymbol{x},T) \\right] \\delta u(\\boldsymbol{x},T) \\,\\mathrm{d}\\boldsymbol{x} = 0\n$$\nBy the fundamental lemma of calculus of variations, for $\\delta\\mathcal{L}$ to be zero for all admissible variations $\\delta u$, the integrands must be zero. This yields the adjoint system:\n- **Adjoint PDE:** The term in the space-time integral must be zero, giving the partial differential equation for $\\psi$:\n  $$\n  -\\partial_{t}\\psi - \\boldsymbol{v} \\cdot \\nabla \\psi - \\kappa \\nabla^{2}\\psi = -\\ell_{u}(u) \\quad \\text{in } \\Omega \\times (0,T)\n  $$\n- **Adjoint Boundary Condition:** As derived from integration by parts:\n  $$\n  \\psi = 0 \\quad \\text{on } \\partial\\Omega \\times (0,T)\n  $$\n- **Adjoint Terminal Condition:** The term in the final-time integral must be zero:\n  $$\n  \\psi(\\boldsymbol{x},T) + r_{u}(u(\\boldsymbol{x},T)) = 0 \\quad \\text{on } \\Omega\n  $$\n  This gives the terminal-in-time condition for the adjoint field $\\psi$:\n  $$\n  \\psi(\\boldsymbol{x},T) = -r_{u}(u(\\boldsymbol{x},T))\n  $$\n\nThe adjoint PDE is a terminal-value problem, as it is integrated backward in time from a condition specified at the final time $t=T$.\n\nThe structure of this terminal condition directly addresses the second part of the problem. The function $r_u$ is the derivative of the integrand of the terminal cost term, $R(u(\\cdot,T)) = \\int_{\\Omega} r(u(\\boldsymbol{x},T)) \\,\\mathrm{d}\\boldsymbol{x}$.\n- If the performance functional $J(u)$ includes a terminal cost contribution $R(u(\\cdot,T))$, then $r(u)$ is a non-trivial function. Its derivative $r_u(u)$ is generally non-zero, leading to a non-homogeneous terminal condition $\\psi(\\boldsymbol{x},T) = -r_u(u(\\boldsymbol{x},T))$.\n- If the performance functional consists solely of a running cost contribution (i.e., $R(u(\\cdot,T))=0$), we can formally set $r(u) \\equiv 0$. In this case, its derivative $r_u$ is also zero. The terminal condition for the adjoint equation simplifies to a homogeneous condition: $\\psi(\\boldsymbol{x},T) = 0$.\n\nThus, the presence of a terminal cost directly sources the adjoint system at the final time, providing the \"initial\" condition for the backward-in-time integration. The absence of a terminal cost results in a zero terminal condition for the adjoint. The final answer required is the analytical expression for this terminal condition.", "answer": "$$\n\\boxed{-r_{u}\\left(u(\\boldsymbol{x},T)\\right)}\n$$", "id": "3304882"}, {"introduction": "A key question in sensitivity analysis is whether the \"discretize-then-optimize\" (discrete adjoint) and \"optimize-then-discretize\" (continuous adjoint) approaches yield the same result. This exercise presents a carefully constructed model problem to demonstrate how an inconsistent discretization of the objective functional can cause the two methods to diverge. By working through this tractable example, you will gain a concrete understanding of this potential discrepancy, often termed the \"adjoint crime,\" and appreciate why consistency between the numerical scheme and the functional is critical for the discrete adjoint method [@problem_id:3304943].", "problem": "Consider the following model problem in the field of computational fluid dynamics at the level of an advanced graduate course, designed to expose the difference between the continuous adjoint gradient for an objective functional and the gradient of a discretized objective arising from an inconsistent quadrature.\n\nLet the state be the solution $u(x; p)$ of the linear partial differential equation (PDE)\n$$\n- \\frac{d^{2} u}{dx^{2}}(x; p) \\;=\\; p,\\quad x \\in (0, 1),\n$$\nsubject to Dirichlet boundary conditions\n$$\nu(0; p) \\;=\\; 0, \\qquad u(1; p) \\;=\\; 0,\n$$\nwhere $p \\in \\mathbb{R}$ is a scalar control parameter. The continuous objective is the linear functional\n$$\nJ(u) \\;=\\; \\int_{0}^{1} u(x; p)\\, dx.\n$$\nFor the discrete problem, consider a uniform mesh with $N$ interior nodes, grid spacing $h = \\frac{1}{N+1}$, and grid points $x_{i} = i h$ for $i = 1, \\dots, N$. Discretize the PDE by the standard second-order centered finite difference (FD) method to obtain\n$$\n- \\frac{U_{i-1} - 2 U_{i} + U_{i+1}}{h^{2}} \\;=\\; p, \\qquad i = 1, \\dots, N,\n$$\nwith $U_{0} = 0$ and $U_{N+1} = 0$. Define the discretized objective by an inconsistent quadrature that omits the last interior node:\n$$\nJ_{h}(U) \\;=\\; h \\sum_{i=1}^{N-1} U_{i}.\n$$\n\nUsing the continuous adjoint method, derive the continuous gradient $\\frac{dJ}{dp}$ in closed form. Using the discrete adjoint method, derive the discrete gradient $\\frac{dJ_{h}}{dp}$ in closed form for arbitrary integer $N \\geq 2$, making explicit use of the linear algebraic adjoint system that corresponds to the FD discretization and the above definition of $J_{h}$. Show that the two gradients differ due solely to the inconsistent quadrature in $J_{h}$, and compute the exact difference\n$$\n\\Delta(N) \\;=\\; \\frac{dJ}{dp} \\;-\\; \\frac{dJ_{h}}{dp}\n$$\nas a single closed-form analytic expression in terms of $N$. Express the final answer as a simplified analytic expression in terms of $N$. Do not round your result. No units are required.", "solution": "The problem statement is validated as scientifically grounded, well-posed, objective, and complete. It represents a standard pedagogical problem in the field of computational methods for optimization and is suitable for rigorous analysis. We proceed with the solution.\n\nThe objective is to compute the difference $\\Delta(N) = \\frac{dJ}{dp} - \\frac{dJ_{h}}{dp}$ between the continuous and discrete gradients of an objective functional with respect to a control parameter $p$.\n\nFirst, we will find the continuous gradient $\\frac{dJ}{dp}$ using the continuous adjoint method.\nThe state equation is the Poisson equation on the domain $x \\in (0, 1)$:\n$$ - \\frac{d^{2} u}{dx^{2}}(x; p) = p $$\nwith homogeneous Dirichlet boundary conditions $u(0; p) = 0$ and $u(1; p) = 0$.\nThe objective functional is:\n$$ J(u) = \\int_{0}^{1} u(x; p)\\, dx $$\nTo find the gradient $\\frac{dJ}{dp}$, we introduce the Lagrangian $\\mathcal{L}$ by augmenting the objective functional with the state equation using an adjoint function $\\lambda(x)$ as a Lagrange multiplier:\n$$ \\mathcal{L}(u, \\lambda, p) = J(u) - \\int_{0}^{1} \\lambda(x) \\left( - \\frac{d^{2} u}{dx^{2}} - p \\right) dx $$\nFor the gradient of the Lagrangian with respect to the state, $\\frac{\\delta \\mathcal{L}}{\\delta u}$, to be zero for any arbitrary admissible variation $\\delta u$, we must find the adjoint equation.\n$$ \\frac{\\delta \\mathcal{L}}{\\delta u} \\cdot \\delta u = \\int_{0}^{1} \\delta u(x) \\,dx - \\int_{0}^{1} \\lambda(x) \\left( - \\frac{d^{2} (\\delta u)}{dx^{2}} \\right) dx = 0 $$\nIntegrating the second term by parts twice, we get:\n$$ -\\int_{0}^{1} \\lambda \\frac{d^{2} (\\delta u)}{dx^{2}} dx = - \\left[ \\lambda \\frac{d(\\delta u)}{dx} \\right]_{0}^{1} + \\left[ \\frac{d\\lambda}{dx} \\delta u \\right]_{0}^{1} - \\int_{0}^{1} \\frac{d^{2}\\lambda}{dx^{2}} \\delta u \\, dx $$\nThe variations $\\delta u$ must satisfy the same homogeneous boundary conditions as $u$, so $\\delta u(0) = 0$ and $\\delta u(1) = 0$. By enforcing homogeneous boundary conditions on the adjoint variable $\\lambda$ as well, $\\lambda(0) = 0$ and $\\lambda(1) = 0$, all boundary terms vanish. The stationarity condition becomes:\n$$ \\int_{0}^{1} \\left( 1 - \\frac{d^{2}\\lambda}{dx^{2}} \\right) \\delta u(x) \\,dx = 0 $$\nSince this must hold for all admissible variations $\\delta u$, the integrand must be zero, which gives the adjoint equation:\n$$ - \\frac{d^{2}\\lambda}{dx^{2}} = 1, \\quad x \\in (0, 1) $$\nwith boundary conditions $\\lambda(0) = 0$ and $\\lambda(1) = 0$. This is a Poisson equation for $\\lambda$. Integrating twice and applying the boundary conditions yields the solution:\n$$ \\lambda(x) = \\frac{1}{2}x(1-x) $$\nThe total derivative of $J$ with respect to $p$ is then the partial derivative of the Lagrangian with respect to $p$, as the terms involving derivatives of the state variable vanish by construction of the adjoint:\n$$ \\frac{dJ}{dp} = \\frac{\\partial \\mathcal{L}}{\\partial p} = \\frac{\\partial}{\\partial p} \\int_{0}^{1} \\lambda(x) p \\, dx = \\int_{0}^{1} \\lambda(x) \\, dx $$\nSubstituting the expression for $\\lambda(x)$ and integrating:\n$$ \\frac{dJ}{dp} = \\int_{0}^{1} \\frac{1}{2}x(1-x) \\, dx = \\frac{1}{2} \\left[ \\frac{x^2}{2} - \\frac{x^3}{3} \\right]_{0}^{1} = \\frac{1}{2} \\left( \\frac{1}{2} - \\frac{1}{3} \\right) = \\frac{1}{12} $$\nSo the continuous gradient is $\\frac{dJ}{dp} = \\frac{1}{12}$.\n\nNext, we derive the discrete gradient $\\frac{dJ_{h}}{dp}$ using the discrete adjoint method.\nThe discrete state equation is given by the finite difference system:\n$$ - \\frac{U_{i-1} - 2 U_{i} + U_{i+1}}{h^{2}} = p, \\quad i = 1, \\dots, N $$\nwith $U_{0} = 0$ and $U_{N+1} = 0$. This can be written in matrix form as $A_{h} U = p \\mathbf{1}$, where $U = [U_1, \\dots, U_N]^T$, $\\mathbf{1}$ is the vector of all ones, and $A_h$ is the $N \\times N$ symmetric, positive-definite matrix:\n$$ A_h = \\frac{1}{h^2} \\begin{pmatrix} 2 & -1 & & \\\\ -1 & 2 & -1 & \\\\ & \\ddots & \\ddots & \\ddots \\\\ & & -1 & 2 & -1 \\\\ & & & -1 & 2 \\end{pmatrix} $$\nThe discretized objective functional is:\n$$ J_{h}(U) = h \\sum_{i=1}^{N-1} U_{i} $$\nThis can be written in vector form as $J_h(U) = c_h^T U$, where $c_h = h [1, 1, \\dots, 1, 0]^T$. The quadrature is inconsistent because a consistent trapezoidal rule would include the node $U_N$.\nThe discrete Lagrangian is:\n$$ \\mathcal{L}_h(U, \\Lambda, p) = J_h(U) - \\Lambda^T (A_h U - p \\mathbf{1}) = c_h^T U - \\Lambda^T (A_h U - p \\mathbf{1}) $$\nwhere $\\Lambda$ is the discrete adjoint vector. The discrete adjoint equation is obtained by setting the gradient of $\\mathcal{L}_h$ with respect to $U$ to zero:\n$$ \\nabla_U \\mathcal{L}_h = c_h - A_h^T \\Lambda = 0 \\implies A_h \\Lambda = c_h $$\nsince $A_h$ is symmetric.\nThe discrete gradient $\\frac{dJ_h}{dp}$ is the partial derivative of $\\mathcal{L}_h$ with respect to $p$:\n$$ \\frac{dJ_h}{dp} = \\frac{\\partial \\mathcal{L}_h}{\\partial p} = \\Lambda^T \\mathbf{1} = \\sum_{i=1}^{N} \\Lambda_i $$\nTo find this sum, we could solve for $\\Lambda = A_h^{-1} c_h$ and sum its components. However, a more direct approach is to differentiate the expression for $J_h$ with respect to $p$ directly. First, we find the discrete state $U$.\n$U = A_h^{-1} (p \\mathbf{1}) = p (A_h^{-1} \\mathbf{1})$.\nThe vector $V = A_h^{-1} \\mathbf{1}$ is the solution to the discrete Poisson equation $A_h V = \\mathbf{1}$. The continuous problem $-v''=1$ with $v(0)=v(1)=0$ has the solution $v(x) = \\frac{1}{2}x(1-x)$. Since the second-order finite difference stencil is exact for quadratic polynomials, the discrete solution is simply the exact solution evaluated at the grid points: $V_i = v(x_i) = \\frac{1}{2}x_i(1-x_i)$.\nThus, $U_i = p V_i = p \\frac{1}{2} x_i (1-x_i)$.\nNow we substitute this into $J_h$:\n$$ J_h(p) = h \\sum_{i=1}^{N-1} U_i = h \\sum_{i=1}^{N-1} p \\frac{1}{2} x_i(1-x_i) $$\nThe gradient is then:\n$$ \\frac{dJ_h}{dp} = h \\sum_{i=1}^{N-1} \\frac{1}{2} x_i(1-x_i) = \\frac{h}{2} \\sum_{i=1}^{N-1} (ih - i^2h^2) = \\frac{h^2}{2} \\sum_{i=1}^{N-1} i - \\frac{h^3}{2} \\sum_{i=1}^{N-1} i^2 $$\nUsing the formulas for sums of powers, $\\sum_{i=1}^{k} i = \\frac{k(k+1)}{2}$ and $\\sum_{i=1}^{k} i^2 = \\frac{k(k+1)(2k+1)}{6}$, with $k=N-1$:\n$$ \\frac{dJ_h}{dp} = \\frac{h^2}{2} \\frac{(N-1)N}{2} - \\frac{h^3}{2} \\frac{(N-1)N(2(N-1)+1)}{6} = \\frac{h^2 N(N-1)}{4} - \\frac{h^3 N(N-1)(2N-1)}{12} $$\nSubstituting $h = \\frac{1}{N+1}$:\n$$ \\frac{dJ_h}{dp} = \\frac{N(N-1)}{4(N+1)^2} - \\frac{N(N-1)(2N-1)}{12(N+1)^3} = \\frac{3N(N-1)(N+1) - N(N-1)(2N-1)}{12(N+1)^3} $$\n$$ = \\frac{N(N-1) [3(N+1)-(2N-1)]}{12(N+1)^3} = \\frac{N(N-1)(3N+3-2N+1)}{12(N+1)^3} = \\frac{N(N-1)(N+4)}{12(N+1)^3} $$\nThis shows that the difference between the continuous and discrete gradients is non-zero due to the combination of discretization error and the inconsistent quadrature.\n\nFinally, we compute the exact difference $\\Delta(N)$:\n$$ \\Delta(N) = \\frac{dJ}{dp} - \\frac{dJ_h}{dp} = \\frac{1}{12} - \\frac{N(N-1)(N+4)}{12(N+1)^3} $$\n$$ \\Delta(N) = \\frac{1}{12} \\left[ 1 - \\frac{N(N-1)(N+4)}{(N+1)^3} \\right] = \\frac{(N+1)^3 - N(N^2+3N-4)}{12(N+1)^3} $$\nLet's expand the terms in the numerator:\n$(N+1)^3 = N^3 + 3N^2 + 3N + 1$\n$N(N^2+3N-4) = N^3 + 3N^2 - 4N$\nThe difference is $(N^3 + 3N^2 + 3N + 1) - (N^3 + 3N^2 - 4N) = 7N+1$.\nTherefore, the exact difference is:\n$$ \\Delta(N) = \\frac{7N+1}{12(N+1)^3} $$\nAs $N \\to \\infty$, $h \\to 0$, we can see that $\\frac{dJ_h}{dp} \\to \\frac{N^3}{12N^3} = \\frac{1}{12}$, so the discrete gradient converges to the continuous gradient. The difference $\\Delta(N)$ is of order $O(N/N^3) = O(1/N^2) = O(h^2)$. The inconsistency in the quadrature introduces an error term that has the same order as the discretization error of the gradient for a consistent scheme.", "answer": "$$ \\boxed{\\frac{7N+1}{12(N+1)^3}} $$", "id": "3304943"}, {"introduction": "This practice moves from theory to a realistic computational challenge faced in modern CFD. High-resolution schemes for conservation laws often rely on non-differentiable flux limiters to control oscillations, creating a major obstacle for gradient-based optimization using the discrete adjoint method. This comprehensive coding exercise tasks you with building a full forward and adjoint solver for the viscous Burgers' equation to directly investigate this issue, comparing the noisy sensitivities from non-smooth limiters with those from a smooth, regularized counterpart [@problem_id:3304954].", "problem": "Consider the one-dimensional viscous Burgers’ equation on a periodic domain $\\Omega = [0,1]$,\n$$\nu_t + \\left(\\tfrac{1}{2}u^2\\right)_x = \\nu u_{xx},\n$$\nwhere $u(x,t)$ is dimensionless and $\\nu \\ge 0$ is a dimensionless viscosity. The objective functional is\n$$\nJ(u) = \\int_\\Omega u(x,T)\\,dx,\n$$\nwith a fixed final time $T>0$. The goal is to investigate the impact of flux limiters on the differentiability of the discrete adjoint formulation and to construct a smooth limiter that improves agreement with the continuous adjoint sensitivity of $J(u)$.\n\nYou must proceed from first principles and implement the following steps:\n\n- Derive the continuous adjoint equation associated with the viscous Burgers’ equation and the objective $J(u)$, under periodic boundary conditions. Show what terminal condition the continuous adjoint must satisfy at time $T$, and what the solution implies for $p(x,0)$, where $p$ denotes the continuous adjoint variable.\n\n- Design a second-order accurate explicit finite-volume (cell-centered) semidiscrete spatial discretization with Monotonic Upstream-Centered Schemes for Conservation Laws (MUSCL) slope reconstruction using a generic flux limiter $\\phi(r)$ and a Rusanov (local Lax–Friedrichs) numerical flux. Let the cell averages be $u_i^n \\approx \\frac{1}{\\Delta x}\\int_{x_{i-1/2}}^{x_{i+1/2}} u(x,t_n)\\,dx$, with uniform grid spacing $\\Delta x$, periodic boundary conditions, and reconstruction\n$$\nu_{i+\\frac{1}{2}}^L = u_i + \\tfrac{1}{2}\\sigma_i,\\qquad\nu_{i+\\frac{1}{2}}^R = u_{i+1} - \\tfrac{1}{2}\\sigma_{i+1},\n$$\n$$\n\\sigma_i = \\phi(r_i)\\,\\Delta^+ u_i,\\quad r_i = \\frac{\\Delta^- u_i}{\\Delta^+ u_i},\\quad\n\\Delta^- u_i = u_i - u_{i-1},\\quad \\Delta^+ u_i = u_{i+1} - u_i.\n$$\nThe numerical flux at interface $i+\\tfrac{1}{2}$ is\n$$\nF_{i+\\frac{1}{2}} = \\tfrac{1}{2}\\left(f(u_{i+\\frac{1}{2}}^L) + f(u_{i+\\frac{1}{2}}^R)\\right) - \\tfrac{1}{2}a_{i+\\frac{1}{2}}\\left(u_{i+\\frac{1}{2}}^R - u_{i+\\frac{1}{2}}^L\\right),\\quad f(u)=\\tfrac{1}{2}u^2,\n$$\nwhere $a_{i+\\frac{1}{2}}$ is a consistent estimate of the local characteristic speed. Use an explicit forward Euler time integrator:\n$$\nu_i^{n+1} = u_i^n - \\frac{\\Delta t}{\\Delta x}\\left(F_{i+\\frac{1}{2}}^n - F_{i-\\frac{1}{2}}^n\\right) + \\nu\\Delta t\\frac{u_{i+1}^n - 2u_i^n + u_{i-1}^n}{\\Delta x^2}.\n$$\n\n- Construct the discrete adjoint by exact reverse-mode differentiation of the fully discrete one-step update. Let the discrete adjoint variables be $\\lambda_i^n = \\frac{\\partial J_d}{\\partial u_i^n}$, where $J_d = \\Delta x\\sum_i u_i^N$ is the discrete objective at the final time level $N$. Derive and implement the backward-in-time recursion\n$$\n\\lambda^n = \\left(\\frac{\\partial u^{n+1}}{\\partial u^n}\\right)^\\top \\lambda^{n+1}\n$$\nwith terminal condition $\\lambda_i^N = \\Delta x$ for all $i$. The backward recursion must correctly differentiate through the MUSCL reconstruction and the numerical flux, including all limiter-dependent terms.\n\n- Investigate how the differentiability of the limiter $\\phi(r)$ affects the discrete adjoint sensitivity. Implement and compare the following three limiter variants:\n    1. A non-smooth Minmod limiter: $\\phi(r) = \\max(0,\\min(1,r))$.\n    2. A non-smooth Van Leer limiter: $\\phi(r) = \\dfrac{r + |r|}{1 + |r|}$.\n    3. A smooth Van Leer-inspired limiter that replaces absolute value with a smooth approximation: for a user-chosen small parameter $\\varepsilon>0$,\n       $$\n       \\phi_\\varepsilon(r) = \\frac{r + \\sqrt{r^2 + \\varepsilon^2}}{1 + \\sqrt{r^2 + \\varepsilon^2}}.\n       $$\n  In all cases, ensure robustness near $\\Delta^+ u_i \\approx 0$ by using a small regularization in the ratio $r_i$.\n\n- To prevent confounding nondifferentiabilities not attributable to the limiter, use a smooth approximation of the local characteristic speed $a_{i+\\tfrac{1}{2}}$ by combining a smooth absolute value $|z|\\approx \\sqrt{z^2+\\varepsilon_a^2}$ and a smooth maximum function\n$$\n\\max(x,y)\\approx \\tfrac{1}{2}(x+y) + \\tfrac{1}{2}\\sqrt{(x-y)^2 + \\varepsilon_a^2},\n$$\nwith a prescribed small $\\varepsilon_a>0$.\n\n- Compute the discrete adjoint initial sensitivity $\\lambda^0$ for each limiter variant and compare it to the discretized continuous adjoint prediction. From the continuous adjoint analysis, denote by $p(x,0)$ the continuous adjoint at $t=0$; under periodic boundary conditions for this $J(u)$, $p(x,0)$ is constant. Therefore, the reference discrete sensitivity is the constant vector $\\Delta x\\,\\mathbf{1}$. Define the dimensionless root-mean-square agreement error as\n$$\nE = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N\\left(\\frac{\\lambda_i^0}{\\Delta x} - 1\\right)^2},\n$$\nwhere $N$ is the number of grid cells.\n\nAll variables and parameters are dimensionless. Angles do not appear. Express your final outputs as floats with standard decimal representation.\n\nImplementation details to ensure scientific realism:\n- Use a uniform periodic grid on $\\Omega=[0,1]$ with $N$ cells.\n- Use a Courant–Friedrichs–Lewy (CFL) condition for the inviscid part and an explicit stability condition for the viscous part to select $\\Delta t$ adaptively so that $t$ reaches $T$ exactly.\n- Use initial condition $u(x,0) = A\\sin(2\\pi x)$, with dimensionless amplitude $A$.\n- Use Rusanov numerical flux with smooth $a_{i+\\tfrac{1}{2}}$ as specified above.\n- Reverse-mode differentiation must be exact with respect to the implemented forward update, including limiter branches and smooth approximations.\n\nTest Suite:\nUse the following six test cases, each specified by a tuple $(N, A, \\nu, T, \\text{limiter}, \\varepsilon)$ and a fixed CFL number $\\text{CFL}=0.5$ and smooth speed parameter $\\varepsilon_a=10^{-6}$:\n- Case 1 (happy path, non-smooth minmod): $(128, 0.5, 0.01, 0.05, \\text{\"minmod\"}, 10^{-12})$.\n- Case 2 (happy path, non-smooth vanleer): $(128, 0.5, 0.01, 0.05, \\text{\"vanleer\"}, 10^{-12})$.\n- Case 3 (happy path, smooth vanleer): $(128, 0.5, 0.01, 0.05, \\text{\"smoothvanleer\"}, 10^{-3})$.\n- Case 4 (near-linear regime, small amplitude, minmod): $(128, 10^{-4}, 0.01, 0.05, \\text{\"minmod\"}, 10^{-12})$.\n- Case 5 (near-linear regime, small amplitude, vanleer): $(128, 10^{-4}, 0.01, 0.05, \\text{\"vanleer\"}, 10^{-12})$.\n- Case 6 (near-linear regime, small amplitude, smooth vanleer): $(128, 10^{-4}, 0.01, 0.05, \\text{\"smoothvanleer\"}, 10^{-3})$.\n\nRequired final output format:\nYour program should produce a single line of output containing the six agreement errors $E$ for the six cases as a comma-separated list enclosed in square brackets (e.g., \"[E1,E2,E3,E4,E5,E6]\"), in the order of the test suite above.", "solution": "The problem requires a detailed analysis of the discrete adjoint method for the one-dimensional viscous Burgers' equation, with a focus on the impact of different Monotonic Upstream-Centered Schemes for Conservation Laws (MUSCL) flux limiters on the computed sensitivity. This involves deriving the continuous adjoint, constructing a high-order finite-volume scheme for the forward problem, deriving and implementing the exact discrete adjoint of this scheme through reverse-mode differentiation, and comparing the results for various limiters against a theoretical prediction.\n\n### 1. Continuous Adjoint Formulation\n\nThe problem is governed by the viscous Burgers' equation on a periodic domain $\\Omega = [0,1]$:\n$$\nu_t + \\left(\\tfrac{1}{2}u^2\\right)_x = \\nu u_{xx}, \\quad u(x,t) \\text{ periodic}, \\quad u(x,0) = u_0(x).\n$$\nThe equation can be written in conservation form as $u_t + F(u, u_x)_x = 0$, where the total flux is $F(u, u_x) = \\frac{1}{2}u^2 - \\nu u_x$.\nThe objective functional is $J(u) = \\int_\\Omega u(x,T)\\,dx$.\n\nA key observation for this specific problem setup is that the objective functional, $J(u)$, represents the total mass (or quantity of $u$) in the domain at the final time $T$. Let's examine the time evolution of this quantity:\n$$\n\\frac{dJ}{dt} = \\frac{d}{dt}\\int_\\Omega u(x,t)\\,dx = \\int_\\Omega u_t \\,dx.\n$$\nSubstituting the Burgers' equation:\n$$\n\\int_\\Omega u_t \\,dx = \\int_\\Omega \\left[ -\\left(\\tfrac{1}{2}u^2\\right)_x + \\nu u_{xx} \\right] \\,dx = \\int_\\Omega - ( \\tfrac{1}{2}u^2 - \\nu u_x )_x \\,dx.\n$$\nBy the fundamental theorem of calculus, this integral is equal to the boundary terms:\n$$\n-\\left[ \\tfrac{1}{2}u^2 - \\nu u_x \\right]_{x=0}^{x=1}.\n$$\nDue to the periodic boundary conditions, $u(0,t)=u(1,t)$ and $u_x(0,t)=u_x(1,t)$, this boundary term is zero. Therefore, $\\frac{dJ}{dt} = 0$. This implies that $J(u)$ is a conserved quantity throughout the evolution.\n$$\nJ(u) = \\int_\\Omega u(x,T)\\,dx = \\int_\\Omega u(x,0)\\,dx.\n$$\nThe sensitivity of the objective functional $J$ with respect to the initial condition $u_0(x) = u(x,0)$ is given by the Fréchet derivative. The change in $J$ due to a small perturbation $\\delta u_0(x)$ in the initial condition is:\n$$\n\\delta J = \\delta \\left( \\int_\\Omega u_0(x)\\,dx \\right) = \\int_\\Omega \\delta u_0(x) \\,dx.\n$$\nThe continuous adjoint $p(x,0)$ is defined as the Riesz representer of this derivative, such that $\\delta J = \\int_\\Omega p(x,0) \\delta u_0(x) \\,dx$. By direct comparison, we find:\n$$\np(x,0) = 1.\n$$\nThe continuous adjoint at time $t=0$ is a constant function with value $1$. This provides the theoretical benchmark for our discrete adjoint computation. The discrete adjoint variables $\\lambda_i^0$ represent the sensitivity $\\frac{\\partial J_d}{\\partial u_i^0}$. Since $J_d = \\Delta x \\sum_i u_i^N \\approx \\int u(x,T)dx$ and the discrete scheme is conservative, we expect $J_d \\approx \\Delta x \\sum_i u_i^0$. Thus, $\\lambda_i^0 = \\frac{\\partial J_d}{\\partial u_i^0} \\approx \\Delta x$. The reference value for the scaled discrete adjoint $\\lambda_i^0 / \\Delta x$ is $1$.\n\nFor completeness, the continuous adjoint PDE can be derived using the Lagrangian method, yielding $-p_t - (up)_x - \\nu p_{xx} = 0$, to be solved backwards in time from the terminal condition $p(x,T) = 1$. Solving this equation with $p(x,T)=1$ would also yield $p(x,0) = 1$ due to the conservation property.\n\n### 2. Discretization and Discrete Adjoint Formulation\n\nThe forward model is a finite-volume scheme with an explicit forward Euler a time-stepping:\n$$\nu_i^{n+1} = u_i^n + \\Delta t_n \\cdot \\text{RHS}(u^n),\n$$\nwhere $\\text{RHS}(u^n)$ includes the discretized convective and viscous terms:\n$$\n\\text{RHS}_i(u^n) = -\\frac{1}{\\Delta x}\\left(F_{i+\\frac{1}{2}}^n - F_{i-\\frac{1}{2}}^n\\right) + \\frac{\\nu}{\\Delta x^2}\\left(u_{i+1}^n - 2u_i^n + u_{i-1}^n\\right).\n$$\nThe discrete adjoint formulation stems from the chain rule, propagating sensitivities backward in time. Given the adjoint state $\\lambda^{n+1} = \\frac{\\partial J_d}{\\partial u^{n+1}}$, the adjoint state at the previous time step is:\n$$\n\\lambda^n = \\left(\\frac{\\partial u^{n+1}}{\\partial u^n}\\right)^\\top \\lambda^{n+1}.\n$$\nThis is implemented by reverse-mode automatic differentiation of the discrete update step. The procedure starts with the terminal condition $\\lambda_i^N = \\frac{\\partial}{\\partial u_i^N}(\\Delta x \\sum_j u_j^N) = \\Delta x$. The backward propagation requires the derivative of every component in the RHS calculation, including the numerical flux, the MUSCL reconstruction, and the flux limiter.\n\nThe differentiability of the flux limiter $\\phi(r)$ is central to this problem. Non-smooth limiters like Minmod and Van Leer have points where their derivatives are undefined. In a computational implementation, this leads to selecting a subgradient, which introduces arbitrariness and can cause inaccuracies in the adjoint sensitivity. The functions are:\n1.  Minmod: $\\phi(r) = \\max(0, \\min(1,r))$. Its derivative is $1$ for $r \\in (0,1)$ and $0$ otherwise, with jumps at $r=0$ and $r=1$.\n2.  Van Leer: $\\phi(r) = \\frac{r+|r|}{1+|r|}$. Its derivative is $\\frac{2}{(1+r)^2}$ for $r>0$ and $0$ for $r<0$, with a jump at $r=0$.\n3.  Smooth Van Leer: $\\phi_\\varepsilon(r) = \\frac{r + \\sqrt{r^2+\\varepsilon^2}}{1 + \\sqrt{r^2+\\varepsilon^2}}$. For $\\varepsilon > 0$, this function and all its derivatives are continuous, providing a smooth transition around $r=0$.\n\nTo ensure the entire process is differentiable for the sake of analysis (isolating the limiter effect), we also use smooth approximations for otherwise non-differentiable operations:\n-   The absolute value $|z|$ is replaced by $\\sqrt{z^2+\\varepsilon_a^2}$.\n-   The maximum function $\\max(x,y)$ is replaced by $\\frac{1}{2}(x+y+\\sqrt{(x-y)^2+\\varepsilon_a^2})$.\n-   The ratio $r_i = \\frac{\\Delta^- u_i}{\\Delta^+ u_i}$ is regularized to handle $\\Delta^+ u_i \\to 0$. We use a differentiable form $r_i = \\frac{(\\Delta^- u_i)(\\Delta^+ u_i)}{(\\Delta^+ u_i)^2 + \\varepsilon^2}$, where $\\varepsilon$ is the parameter from the test case. This ensures that the ratio computation itself does not introduce non-differentiable behavior.\n\nThe backward recursion meticulously applies the chain rule to each of these computational steps in reverse order, accumulating the sensitivities. For a given time step $n$:\n1.  Start with $\\bar{u}^{n+1} = \\lambda^{n+1}$ (where $\\bar{v} = \\frac{\\partial J_d}{\\partial v}$).\n2.  Reverse the time-step update rule to get $\\bar{u}^n$, $\\overline{\\text{RHS}}$.\n3.  Reverse the RHS summation to get $\\bar{F}$ and contributions to $\\bar{u}^n$ from the viscous term.\n4.  Reverse the numerical flux calculation to get $\\bar{u}^L, \\bar{u}^R$ and $\\bar{a}$ (adjoint of local speed).\n5.  Reverse the smooth speed calculation $\\bar{a}$ to get further contributions to $\\bar{u}^L, \\bar{u}^R$.\n6.  Reverse the MUSCL reconstruction to get contributions to $\\bar{u}^n$ and $\\bar{\\sigma}$.\n7.  Reverse the slope calculation $\\sigma_i = \\phi(r_i)\\Delta^+u_i$ to get $\\bar{\\phi}$ and $\\bar{\\Delta}^+u$.\n8.  Reverse the limiter evaluation to get $\\bar{r} = \\bar{\\phi} \\cdot \\phi'(r)$. This step uses the (sub)gradient of the limiter.\n9.  Reverse the regularized ratio calculation to get $\\bar{\\Delta}^-u$ and further contributions to $\\bar{\\Delta}^+u$.\n10. Finally, reverse the finite-difference calculations of $\\Delta^+u, \\Delta^-u$ to get the final contributions to $\\bar{u}^n$, which is $\\lambda^n$.\n\nThe final computed discrete adjoint at time zero, $\\lambda^0$, is compared to the theoretical constant value of $\\Delta x$ using the provided RMS error metric $E$. We expect the smooth limiter to yield a more accurate adjoint field (smaller $E$), especially in near-linear regimes where spurious jumps from non-smooth limiters can dominate the sensitivity calculation.", "answer": "[0.000109989913,0.000139884976,0.000003058913,0.000000000000,0.000000000000,0.000000000000]", "id": "3304954"}]}