{"hands_on_practices": [{"introduction": "Before applying the detailed balance condition to construct sophisticated algorithms, it is crucial to understand its fundamental properties and how to verify them. This first exercise provides a direct application of Kolmogorov's cycle criterion, a powerful result that connects the abstract definition of reversibility to a simple, verifiable condition on the transition probabilities of a finite-state Markov chain. By working through this problem, you will solidify your understanding of how detailed balance imposes strong structural constraints on the dynamics of a chain and practice solving for the unique stationary distribution that it guarantees.", "problem": "Consider a discrete-time Markov chain (MC) on the state space $\\{1,2,3\\}$ with transition probabilities given by the following stochastic matrix $P = (P_{ij})$:\n$$\nP \\;=\\;\n\\begin{pmatrix}\nP_{11}  P_{12}  P_{13} \\\\\nP_{21}  P_{22}  P_{23} \\\\\nP_{31}  P_{32}  P_{33}\n\\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n\\frac{2}{5}  \\frac{2}{5}  \\frac{1}{5} \\\\\n\\frac{1}{2}  \\frac{1}{6}  \\frac{1}{3} \\\\\n\\frac{3}{10}  \\frac{2}{5}  \\frac{3}{10}\n\\end{pmatrix}.\n$$\nReversibility (detailed balance) with respect to a strictly positive invariant distribution $\\pi = (\\pi_{1},\\pi_{2},\\pi_{3})$ means $\\pi_{i} P_{ij} = \\pi_{j} P_{ji}$ for all $i,j \\in \\{1,2,3\\}$. A classical criterion for reversibility involves cycle constraints along closed loops. Starting from core definitions of a discrete-time Markov chain, stationarity, and detailed balance, derive the cycle criterion for a three-state chain and then use it to decide whether detailed balance can hold for some strictly positive $\\pi$ for the above $P$. If it can, solve for $\\pi$ with the normalization $\\sum_{i=1}^{3} \\pi_{i} = 1$. If detailed balance cannot hold, justify the conclusion by the cycle criterion. Express your final answer as the normalized vector $\\pi$; no rounding is required and the answer must be exact.", "solution": "The problem statement is a valid exercise in the theory of discrete-time Markov chains. It is self-contained, mathematically sound, and well-posed. We shall proceed with the solution.\n\nFirst, we establish the theoretical foundation as requested by the problem statement.\n\nA discrete-time Markov chain on a finite state space $\\mathcal{S}$ is a sequence of random variables $\\{X_n\\}_{n \\ge 0}$ taking values in $\\mathcal{S}$ that satisfies the Markov property: for any states $i, j, i_0, \\ldots, i_{n-1} \\in \\mathcal{S}$,\n$$\nP(X_{n+1}=j | X_n=i, X_{n-1}=i_{n-1}, \\dots, X_0=i_0) = P(X_{n+1}=j | X_n=i).\n$$\nFor a time-homogeneous chain, this probability is independent of $n$ and is denoted by the transition probability $P_{ij} = P(X_{n+1}=j | X_n=i)$. These probabilities form the transition matrix $P = (P_{ij})$.\n\nA probability distribution $\\pi = (\\pi_i)_{i \\in \\mathcal{S}}$ is called a stationary or invariant distribution if it is a fixed point of the transition operation. That is, if the chain is in state $i$ with probability $\\pi_i$ at time $n$, it will be in state $j$ with probability $\\pi_j$ at time $n+1$. This is expressed by the equation $\\pi = \\pi P$, which in component form is:\n$$\n\\pi_j = \\sum_{i \\in \\mathcal{S}} \\pi_i P_{ij} \\quad \\text{for all } j \\in \\mathcal{S}.\n$$\n\nA Markov chain is said to be reversible, or to satisfy the detailed balance condition with respect to a distribution $\\pi$, if for all states $i, j \\in \\mathcal{S}$:\n$$\n\\pi_i P_{ij} = \\pi_j P_{ji}.\n$$\nThe detailed balance condition is a sufficient, but not necessary, condition for stationarity. To prove this, we sum the detailed balance equation over all states $i$:\n$$\n\\sum_{i \\in \\mathcal{S}} \\pi_i P_{ij} = \\sum_{i \\in \\mathcal{S}} \\pi_j P_{ji}\n$$\nThe left-hand side is the $j$-th component of the vector product $\\pi P$. The right-hand side can be simplified by factoring out $\\pi_j$:\n$$\n\\sum_{i \\in \\mathcal{S}} \\pi_j P_{ji} = \\pi_j \\sum_{i \\in \\mathcal{S}} P_{ji}\n$$\nSince the sum of probabilities over all possible destination states from a given state $j$ must be one, the rows of the transition matrix sum to one: $\\sum_{i \\in \\mathcal{S}} P_{ji} = 1$. Therefore, the right-hand side simplifies to $\\pi_j$. By equating the left- and right-hand sides, we recover the stationarity (or global balance) condition:\n$$\n\\sum_{i \\in \\mathcal{S}} \\pi_i P_{ij} = \\pi_j\n$$\n\nNext, we derive the cycle criterion (Kolmogorov's criterion for reversibility). Assume the detailed balance condition $\\pi_i P_{ij} = \\pi_j P_{ji}$ holds for a strictly positive distribution $\\pi > 0$. Consider any closed loop (cycle) of states $i_1, i_2, \\ldots, i_k, i_1$. From the detailed balance condition, we can write:\n$$\n\\frac{P_{i_m i_{m+1}}}{P_{i_{m+1} i_m}} = \\frac{\\pi_{i_{m+1}}}{\\pi_{i_m}}\n$$\nfor any adjacent pair of states in the cycle, provided the transition probabilities in the denominator are non-zero.\nTaking the product around the cycle $i_1 \\to i_2 \\to \\dots \\to i_k \\to i_1$ (where $i_{k+1}=i_1$):\n$$\n\\prod_{m=1}^{k} \\frac{P_{i_m i_{m+1}}}{P_{i_{m+1} i_m}} = \\frac{P_{i_1 i_2}}{P_{i_2 i_1}} \\cdot \\frac{P_{i_2 i_3}}{P_{i_3 i_2}} \\cdots \\frac{P_{i_k i_1}}{P_{i_1 i_k}} = \\frac{\\pi_{i_2}}{\\pi_{i_1}} \\cdot \\frac{\\pi_{i_3}}{\\pi_{i_2}} \\cdots \\frac{\\pi_{i_1}}{\\pi_{i_k}} = 1.\n$$\nThis implies that the product of transition probabilities along any cycle must equal the product of transition probabilities along the same cycle in the reverse direction:\n$$\nP_{i_1 i_2} P_{i_2 i_3} \\cdots P_{i_k i_1} = P_{i_1 i_k} P_{i_k i_{k-1}} \\cdots P_{i_2 i_1}.\n$$\nFor a three-state chain on $\\mathcal{S}=\\{1, 2, 3\\}$, any cycle longer than $3$ is composed of smaller cycles. The cycles of length $2$ (e.g., $1 \\to 2 \\to 1$) give the trivial identity $P_{12}P_{21} = P_{12}P_{21}$. Thus, it suffices to check the condition for the cycle of length $3$: $1 \\to 2 \\to 3 \\to 1$. The criterion is:\n$$\nP_{12} P_{23} P_{31} = P_{13} P_{32} P_{21}.\n$$\nThe product on the left corresponds to the path $1 \\to 2 \\to 3 \\to 1$, and the product on the right corresponds to the reverse path $1 \\to 3 \\to 2 \\to 1$.\n\nWe now apply this criterion to the given transition matrix:\n$$\nP =\n\\begin{pmatrix}\n\\frac{2}{5}  \\frac{2}{5}  \\frac{1}{5} \\\\\n\\frac{1}{2}  \\frac{1}{6}  \\frac{1}{3} \\\\\n\\frac{3}{10}  \\frac{2}{5}  \\frac{3}{10}\n\\end{pmatrix}.\n$$\nThe relevant transition probabilities are:\n$P_{12} = \\frac{2}{5}$, $P_{23} = \\frac{1}{3}$, $P_{31} = \\frac{3}{10}$.\n$P_{13} = \\frac{1}{5}$, $P_{32} = \\frac{2}{5}$, $P_{21} = \\frac{1}{2}$.\n\nWe compute the product for the cycle $1 \\to 2 \\to 3 \\to 1$:\n$$\nP_{12} P_{23} P_{31} = \\left(\\frac{2}{5}\\right) \\left(\\frac{1}{3}\\right) \\left(\\frac{3}{10}\\right) = \\frac{6}{150} = \\frac{1}{25}.\n$$\nNext, we compute the product for the reverse cycle $1 \\to 3 \\to 2 \\to 1$:\n$$\nP_{13} P_{32} P_{21} = \\left(\\frac{1}{5}\\right) \\left(\\frac{2}{5}\\right) \\left(\\frac{1}{2}\\right) = \\frac{2}{50} = \\frac{1}{25}.\n$$\nSince $P_{12} P_{23} P_{31} = P_{13} P_{32} P_{21}$, the cycle criterion is satisfied. Therefore, a strictly positive invariant distribution $\\pi$ satisfying the detailed balance condition exists for this Markov chain.\n\nWe now solve for this distribution $\\pi = (\\pi_1, \\pi_2, \\pi_3)$. The detailed balance equations are:\n1. $\\pi_1 P_{12} = \\pi_2 P_{21} \\implies \\pi_1 \\left(\\frac{2}{5}\\right) = \\pi_2 \\left(\\frac{1}{2}\\right)$\n2. $\\pi_2 P_{23} = \\pi_3 P_{32} \\implies \\pi_2 \\left(\\frac{1}{3}\\right) = \\pi_3 \\left(\\frac{2}{5}\\right)$\n\nFrom equation (1), we express $\\pi_2$ in terms of $\\pi_1$:\n$$\n\\pi_2 = \\pi_1 \\frac{2/5}{1/2} = \\pi_1 \\left(\\frac{4}{5}\\right).\n$$\nFrom equation (2), we express $\\pi_3$ in terms of $\\pi_2$:\n$$\n\\pi_3 = \\pi_2 \\frac{1/3}{2/5} = \\pi_2 \\left(\\frac{5}{6}\\right).\n$$\nSubstituting the expression for $\\pi_2$:\n$$\n\\pi_3 = \\left(\\frac{4}{5}\\pi_1\\right) \\left(\\frac{5}{6}\\right) = \\frac{4}{6}\\pi_1 = \\frac{2}{3}\\pi_1.\n$$\nNow we have $\\pi_2 = \\frac{4}{5}\\pi_1$ and $\\pi_3 = \\frac{2}{3}\\pi_1$. We use the normalization condition $\\sum_{i=1}^{3} \\pi_i = 1$:\n$$\n\\pi_1 + \\pi_2 + \\pi_3 = 1\n$$\n$$\n\\pi_1 + \\frac{4}{5}\\pi_1 + \\frac{2}{3}\\pi_1 = 1\n$$\n$$\n\\pi_1 \\left(1 + \\frac{4}{5} + \\frac{2}{3}\\right) = 1\n$$\nTo sum the fractions, we find a common denominator, which is $15$:\n$$\n\\pi_1 \\left(\\frac{15}{15} + \\frac{12}{15} + \\frac{10}{15}\\right) = 1\n$$\n$$\n\\pi_1 \\left(\\frac{15+12+10}{15}\\right) = 1\n$$\n$$\n\\pi_1 \\left(\\frac{37}{15}\\right) = 1 \\implies \\pi_1 = \\frac{15}{37}.\n$$\nNow we find $\\pi_2$ and $\\pi_3$:\n$$\n\\pi_2 = \\frac{4}{5}\\pi_1 = \\frac{4}{5} \\left(\\frac{15}{37}\\right) = \\frac{12}{37}.\n$$\n$$\n\\pi_3 = \\frac{2}{3}\\pi_1 = \\frac{2}{3} \\left(\\frac{15}{37}\\right) = \\frac{10}{37}.\n$$\nThus, the unique normalized stationary distribution that satisfies detailed balance is $\\pi = \\left(\\frac{15}{37}, \\frac{12}{37}, \\frac{10}{37}\\right)$. All components are strictly positive, as required. A final check confirms normalization: $\\frac{15}{37} + \\frac{12}{37} + \\frac{10}{37} = \\frac{37}{37} = 1$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{15}{37}  \\frac{12}{37}  \\frac{10}{37}\n\\end{pmatrix}\n}\n$$", "id": "3302632"}, {"introduction": "The detailed balance condition is the cornerstone of the Metropolis-Hastings algorithm, one of the most important tools in computational science. However, its power lies in its precise application; even subtle misunderstandings of the proposal mechanism can lead to algorithms that fail to sample from the intended target distribution. This practice problem presents a common scenario where a seemingly intuitive, state-dependent proposal scheme breaks detailed balance if a naive acceptance rule is used. By first demonstrating the failure and then deriving the correct acceptance probability from first principles, you will gain a deeper appreciation for why the full Hastings ratio, accounting for proposal densities, is essential for ensuring correctness.", "problem": "Consider a finite-state Markov Chain Monte Carlo (MCMC) method on the state space $\\{0,1,2\\}$ targeting the distribution $\\pi$ with $\\pi(0)=\\frac{1}{2}$, $\\pi(1)=\\frac{1}{3}$, and $\\pi(2)=\\frac{1}{6}$. Two deterministic proposal kernels are available: a clockwise kernel $K^{+}$ defined by $K^{+}(x,y)=1$ if $y\\equiv x+1\\ \\pmod{3}$ and $K^{+}(x,y)=0$ otherwise, and a counterclockwise kernel $K^{-}$ defined by $K^{-}(x,y)=1$ if $y\\equiv x-1\\ \\pmod{3}$ and $K^{-}(x,y)=0$ otherwise. The proposal mechanism is a state-dependent mixture: at the current state $x$, $K^{+}$ is selected with weight $w(x)$ and $K^{-}$ with weight $1-w(x)$, where $w(0)=\\frac{3}{4}$, $w(1)=\\frac{1}{2}$, and $w(2)=\\frac{1}{4}$. Thus the one-step proposal probability is $q(x,y)=w(x)K^{+}(x,y)+\\big(1-w(x)\\big)K^{-}(x,y)$.\n\nSuppose a practitioner implements a naive acceptance rule that incorrectly assumes a symmetric proposal and uses $\\alpha_{\\mathrm{naive}}(x,y)=\\min\\big(1,\\frac{\\pi(y)}{\\pi(x)}\\big)$ for all $x\\neq y$. Using only the definition of detailed balance, namely that $\\pi(x)P(x,y)=\\pi(y)P(y,x)$ for all states $x,y$ with $x\\neq y$ where $P(x,y)=q(x,y)\\alpha(x,y)$ denotes the transition kernel, and the rules of probability, compute the ratio\n$$\\rho=\\frac{\\pi(0)\\,q(0,1)\\,\\alpha_{\\mathrm{naive}}(0,1)}{\\pi(1)\\,q(1,0)\\,\\alpha_{\\mathrm{naive}}(1,0)}$$\nto demonstrate that detailed balance is broken for the pair $(0,1)$ under this naive rule.\n\nThen, starting from the same foundational definition of detailed balance and without assuming any shortcut formulas, derive the acceptance probability $\\alpha_{\\mathrm{corr}}(0,1)$ that restores reversibility for the transition from $0$ to $1$ under the given state-dependent mixture proposal $q(x,y)$. Express your final answer as a single reduced fraction. No rounding is required.", "solution": "The analysis of the problem will be conducted in two parts. First, we will demonstrate that the naive acceptance rule violates the detailed balance condition by computing the specified ratio $\\rho$. Second, we will derive the correct acceptance probability $\\alpha_{\\mathrm{corr}}(0,1)$ that restores detailed balance for the transition from state $0$ to $1$.\n\nThe given parameters are:\nState space: $S = \\{0, 1, 2\\}$\nTarget distribution: $\\pi(0) = \\frac{1}{2}$, $\\pi(1) = \\frac{1}{3}$, $\\pi(2) = \\frac{1}{6}$\nClockwise proposal: $K^{+}(x,y)=1$ if $y \\equiv x+1 \\pmod{3}$\nCounterclockwise proposal: $K^{-}(x,y)=1$ if $y \\equiv x-1 \\pmod{3}$\nState-dependent mixture weights: $w(0)=\\frac{3}{4}$, $w(1)=\\frac{1}{2}$, $w(2)=\\frac{1}{4}$\nCombined proposal probability: $q(x,y)=w(x)K^{+}(x,y)+\\big(1-w(x)\\big)K^{-}(x,y)$\n\nThe fundamental condition for detailed balance (reversibility) states that for a Markov chain with stationary distribution $\\pi$ and transition probabilities $P(x,y)$, the rate of transition from state $x$ to $y$ must equal the rate of transition from $y$ to $x$ in equilibrium. For any pair of distinct states $x, y \\in S$, this is expressed as:\n$$ \\pi(x) P(x,y) = \\pi(y) P(y,x) $$\nFor a Metropolis-Hastings-type algorithm, the transition probability for $x \\neq y$ is given by $P(x,y) = q(x,y)\\alpha(x,y)$, where $q(x,y)$ is the proposal probability and $\\alpha(x,y)$ is the acceptance probability.\n\n### Part 1: Violation of Detailed Balance with the Naive Rule\n\nWe are asked to compute the ratio $\\rho = \\frac{\\pi(0)\\,q(0,1)\\,\\alpha_{\\mathrm{naive}}(0,1)}{\\pi(1)\\,q(1,0)\\,\\alpha_{\\mathrm{naive}}(1,0)}$ to show that detailed balance is broken for the pair of states $(0,1)$. Detailed balance holds if and only if this ratio is equal to $1$.\n\nFirst, we compute the necessary proposal probabilities $q(0,1)$ and $q(1,0)$.\nFor the transition $0 \\to 1$:\nThe proposed state $y=1$ is clockwise from the current state $x=0$, since $1 \\equiv 0+1 \\pmod{3}$. Thus, $K^{+}(0,1)=1$ and $K^{-}(0,1)=0$.\nThe proposal probability is:\n$q(0,1) = w(0)K^{+}(0,1) + (1-w(0))K^{-}(0,1) = w(0) \\cdot 1 + (1-w(0)) \\cdot 0 = w(0) = \\frac{3}{4}$.\n\nFor the transition $1 \\to 0$:\nThe proposed state $y=0$ is counterclockwise from the current state $x=1$, since $0 \\equiv 1-1 \\pmod{3}$. Thus, $K^{+}(1,0)=0$ and $K^{-}(1,0)=1$.\nThe proposal probability is:\n$q(1,0) = w(1)K^{+}(1,0) + (1-w(1))K^{-}(1,0) = w(1) \\cdot 0 + (1-w(1)) \\cdot 1 = 1-w(1) = 1-\\frac{1}{2} = \\frac{1}{2}$.\n\nNext, we compute the acceptance probabilities using the naive rule $\\alpha_{\\mathrm{naive}}(x,y)=\\min\\left(1,\\frac{\\pi(y)}{\\pi(x)}\\right)$.\nFor the transition $0 \\to 1$:\n$\\alpha_{\\mathrm{naive}}(0,1) = \\min\\left(1, \\frac{\\pi(1)}{\\pi(0)}\\right) = \\min\\left(1, \\frac{1/3}{1/2}\\right) = \\min\\left(1, \\frac{2}{3}\\right) = \\frac{2}{3}$.\n\nFor the transition $1 \\to 0$:\n$\\alpha_{\\mathrm{naive}}(1,0) = \\min\\left(1, \\frac{\\pi(0)}{\\pi(1)}\\right) = \\min\\left(1, \\frac{1/2}{1/3}\\right) = \\min\\left(1, \\frac{3}{2}\\right) = 1$.\n\nNow we can compute the numerator and denominator of $\\rho$.\nThe forward flux (proportional to probability flow from $0$ to $1$) is:\n$\\pi(0)\\,q(0,1)\\,\\alpha_{\\mathrm{naive}}(0,1) = \\frac{1}{2} \\cdot \\frac{3}{4} \\cdot \\frac{2}{3} = \\frac{6}{24} = \\frac{1}{4}$.\n\nThe reverse flux (proportional to probability flow from $1$ to $0$) is:\n$\\pi(1)\\,q(1,0)\\,\\alpha_{\\mathrm{naive}}(1,0) = \\frac{1}{3} \\cdot \\frac{1}{2} \\cdot 1 = \\frac{1}{6}$.\n\nThe ratio $\\rho$ is therefore:\n$$ \\rho = \\frac{1/4}{1/6} = \\frac{6}{4} = \\frac{3}{2} $$\nSince $\\rho = \\frac{3}{2} \\neq 1$, the forward and reverse fluxes are not balanced. This demonstrates that the naive acceptance rule, which ignores the asymmetry in the proposal distribution $q(x,y)$, fails to satisfy the detailed balance condition for the pair $(0,1)$.\n\n### Part 2: Derivation of the Correct Acceptance Probability\n\nTo restore detailed balance, the acceptance probability $\\alpha_{\\mathrm{corr}}(x,y)$ must be chosen such that for all $x \\neq y$:\n$$ \\pi(x) q(x,y) \\alpha_{\\mathrm{corr}}(x,y) = \\pi(y) q(y,x) \\alpha_{\\mathrm{corr}}(y,x) $$\nWe must find a solution for $\\alpha_{\\mathrm{corr}}(x,y)$ and $\\alpha_{\\mathrm{corr}}(y,x)$ that satisfies this equation while also adhering to the constraint that acceptance probabilities must be in the interval $[0,1]$. A standard method, which maximizes acceptance rates, is to set one of the probabilities to its maximum possible value, $1$.\n\nLet's rearrange the equation:\n$$ \\frac{\\alpha_{\\mathrm{corr}}(x,y)}{\\alpha_{\\mathrm{corr}}(y,x)} = \\frac{\\pi(y) q(y,x)}{\\pi(x) q(x,y)} $$\nDefine the Metropolis-Hastings ratio $R_{xy} = \\frac{\\pi(y) q(y,x)}{\\pi(x) q(x,y)}$.\nCase 1: $R_{xy} \\le 1$. We wish to maximize the acceptance probabilities. We can set the larger of the two, $\\alpha_{\\mathrm{corr}}(y,x)$, to its maximum value of $1$. The equation then dictates that $\\alpha_{\\mathrm{corr}}(x,y) = R_{xy}$. Since $R_{xy} \\le 1$, this choice is valid. So, $\\alpha_{\\mathrm{corr}}(x,y) = R_{xy}$ and $\\alpha_{\\mathrm{corr}}(y,x) = 1$.\n\nCase 2: $R_{xy}  1$. In this case, $\\frac{1}{R_{xy}}  1$. We can set $\\alpha_{\\mathrm{corr}}(x,y)$ to its maximum value, $1$. The equation then requires that $1 = R_{xy} \\cdot \\alpha_{\\mathrm{corr}}(y,x)$, which gives $\\alpha_{\\mathrm{corr}}(y,x) = \\frac{1}{R_{xy}}$. Since $\\frac{1}{R_{xy}}  1$, this choice is valid. So, $\\alpha_{\\mathrm{corr}}(x,y) = 1$ and $\\alpha_{\\mathrm{corr}}(y,x) = \\frac{1}{R_{xy}}$.\n\nThese two cases can be expressed compactly using the minimum function:\n$$ \\alpha_{\\mathrm{corr}}(x,y) = \\min\\left(1, R_{xy}\\right) = \\min\\left(1, \\frac{\\pi(y) q(y,x)}{\\pi(x) q(x,y)}\\right) $$\nThis is the general form of the Metropolis-Hastings acceptance probability.\n\nWe now apply this formula to find the specific value of $\\alpha_{\\mathrm{corr}}(0,1)$. We need to compute the ratio $R_{01}$:\n$$ R_{01} = \\frac{\\pi(1) q(1,0)}{\\pi(0) q(0,1)} $$\nUsing the values we have already calculated:\n$\\pi(0) = \\frac{1}{2}$\n$\\pi(1) = \\frac{1}{3}$\n$q(0,1) = \\frac{3}{4}$\n$q(1,0) = \\frac{1}{2}$\n\nThe numerator is $\\pi(1) q(1,0) = \\frac{1}{3} \\cdot \\frac{1}{2} = \\frac{1}{6}$.\nThe denominator is $\\pi(0) q(0,1) = \\frac{1}{2} \\cdot \\frac{3}{4} = \\frac{3}{8}$.\n\nThe ratio is:\n$$ R_{01} = \\frac{1/6}{3/8} = \\frac{1}{6} \\cdot \\frac{8}{3} = \\frac{8}{18} = \\frac{4}{9} $$\nFinally, the correct acceptance probability for the transition from $0$ to $1$ is:\n$$ \\alpha_{\\mathrm{corr}}(0,1) = \\min\\left(1, \\frac{4}{9}\\right) = \\frac{4}{9} $$\nThis value, when used in the MCMC simulation, will ensure that the detailed balance condition is satisfied for the pair of states $(0,1)$.", "answer": "$$ \\boxed{\\frac{4}{9}} $$", "id": "3302655"}, {"introduction": "While the detailed balance condition is a sufficient condition to ensure a Markov chain converges to a desired target distribution, it is not a necessary one. In fact, modern MCMC research has shown that intentionally designing non-reversible chains can lead to significantly faster convergence, a property measured by the spectral gap. This computational exercise guides you through the process of \"lifting\" a simple, reversible random walk into a larger, non-reversible chain that preserves the same stationary distribution but moves with a persistent probabilistic flow. By computing the non-zero probability current and observing the improved spectral gap, you will gain hands-on experience with the principles behind non-reversible MCMC and its advantages over traditional, diffusive samplers.", "problem": "Consider a discrete-time Markov chain with a finite state space and let $P$ denote its transition matrix. A probability distribution $\\pi$ on the state space is stationary if it satisfies $\\pi P = \\pi$. The chain is said to satisfy detailed balance (also called reversibility) with respect to $\\pi$ if for every pair of states $x$ and $y$ one has $\\pi(x) P(x,y) = \\pi(y) P(y,x)$. For any chain (reversible or not), define the absolute spectral gap $\\gamma(P)$ by $\\gamma(P) = 1 - \\max\\{|\\lambda| : \\lambda \\in \\mathrm{spec}(P), \\lambda \\neq 1\\}$, where $\\mathrm{spec}(P)$ denotes the spectrum of $P$ and $|\\cdot|$ denotes the modulus of a complex number. For steady-state probability flows, define the net probability current on a directed edge $x \\to y$ by $J(x \\to y) = \\pi(x) P(x,y) - \\pi(y) P(y,x)$.\n\nYour task is to construct a simple reversible base chain on a cycle graph and then construct a nonreversible lifted chain (with a direction \"spin\") that preserves the same stationary distribution while violating detailed balance, and to compute the spectral gaps and a net circulation of steady-state probability current.\n\n1. Base chain construction. Let $C_n$ be the cycle graph on $n$ nodes labeled $\\{0,1,\\ldots,n-1\\}$. Define the base chain transition matrix $P_{\\mathrm{base}} \\in \\mathbb{R}^{n \\times n}$ by\n- $P_{\\mathrm{base}}(i,i) = p_{\\mathrm{stay}}$,\n- $P_{\\mathrm{base}}(i,(i+1) \\bmod n) = \\frac{1 - p_{\\mathrm{stay}}}{2}$,\n- $P_{\\mathrm{base}}(i,(i-1) \\bmod n) = \\frac{1 - p_{\\mathrm{stay}}}{2}$,\nfor each $i \\in \\{0,1,\\ldots,n-1\\}$. The stationary distribution for this chain is uniform on $\\{0,\\ldots,n-1\\}$, i.e., $\\pi(i) = \\frac{1}{n}$.\n\n2. Lifted chain construction. Define the lifted state space $\\Omega = \\{0,1,\\ldots,n-1\\} \\times \\{+,-\\}$. For parameters $n$ and a flip probability $r \\in [0,1]$, define $P_{\\mathrm{lift}} \\in \\mathbb{R}^{(2n) \\times (2n)}$ by the following transitions:\n- From $(i,+)$, move to $((i+1) \\bmod n, +)$ with probability $1 - r$, and flip to $(i,-)$ with probability $r$.\n- From $(i,-)$, move to $((i-1) \\bmod n, -)$ with probability $1 - r$, and flip to $(i,+)$ with probability $r$.\nThe stationary distribution for this chain is uniform on $\\Omega$, i.e., $\\pi^*(i,+) = \\pi^*(i,-) = \\frac{1}{2n}$.\n\n3. Net probability current and circulation. For the lifted chain, define the oriented cycle $\\mathcal{C}_+ = \\big\\{(0,+) \\to (1,+) \\to \\cdots \\to (n-1,+) \\to (0,+)\\big\\}$. Compute the scalar circulation $J_+$ along $\\mathcal{C}_+$ given by\n$$\nJ_+ = \\sum_{i=0}^{n-1} J\\big( (i,+) \\to ((i+1) \\bmod n, +) \\big).\n$$\n\n4. Spectral gap comparison. Compute the absolute spectral gaps $\\gamma(P_{\\mathrm{base}})$ and $\\gamma(P_{\\mathrm{lift}})$ as defined above, and determine whether the lifted chain improves the spectral gap, i.e., whether $\\gamma(P_{\\mathrm{lift}}) > \\gamma(P_{\\mathrm{base}})$.\n\nImplementation requirements:\n- Construct $P_{\\mathrm{base}}$ and $P_{\\mathrm{lift}}$ exactly as specified.\n- Compute eigenvalues numerically and evaluate $\\gamma(P)$ by removing the eigenvalue at $1$ (within numerical tolerance) and taking $1 -$ the largest modulus among the remaining eigenvalues. If all remaining eigenvalues have modulus strictly less than $1$, the gap is positive; if some have modulus equal to $1$, the gap is zero.\n- Use the uniform stationary distributions described above to compute $J(x \\to y)$ and $J_+$.\n\nTest suite:\nProvide results for the following parameter sets $(n, p_{\\mathrm{stay}}, r)$:\n- Case A (general \"happy path\"): $(n, p_{\\mathrm{stay}}, r) = (10, 0.2, 0.1)$.\n- Case B (boundary flip rate): $(n, p_{\\mathrm{stay}}, r) = (10, 0.2, 0.0)$.\n- Case C (non-lazy odd cycle): $(n, p_{\\mathrm{stay}}, r) = (15, 0.0, 0.2)$.\n- Case D (high laziness): $(n, p_{\\mathrm{stay}}, r) = (50, 0.9, 0.05)$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list of four-element lists, one per test case, where each per-case list is\n$$\n\\big[ \\gamma(P_{\\mathrm{base}}), \\ \\gamma(P_{\\mathrm{lift}}), \\ \\mathbf{1}\\{\\gamma(P_{\\mathrm{lift}}) > \\gamma(P_{\\mathrm{base}})\\}, \\ J_+ \\big],\n$$\nwith the first two entries returned as floating-point numbers, the third entry as an integer ($0$ or $1$), and the fourth entry as a floating-point number. For example, your program should print something of the form\n$$\n\\big[ [\\cdots], [\\cdots], [\\cdots], [\\cdots] \\big].\n$$\nNo physical units are involved in this problem. Angles are not used. Percentages must be represented as decimals if needed, but no percentage symbols are used.", "solution": "The problem requires the construction and analysis of two Markov chains on a cycle graph: a standard reversible (base) chain and a non-reversible lifted chain. The objective is to compute and compare their spectral gaps and to quantify the non-reversibility of the lifted chain via its net probability circulation.\n\n### 1. The Base Chain: Reversible Random Walk on a Cycle Graph\n\nThe base chain is defined on the state space $\\{0, 1, \\ldots, n-1\\}$, representing the vertices of a cycle graph $C_n$. The transition matrix $P_{\\mathrm{base}} \\in \\mathbb{R}^{n \\times n}$ is given by:\n$$\nP_{\\mathrm{base}}(i, j) =\n\\begin{cases}\np_{\\mathrm{stay}}  \\text{if } j = i \\\\\n\\frac{1 - p_{\\mathrm{stay}}}{2}  \\text{if } j = (i \\pm 1) \\bmod n \\\\\n0  \\text{otherwise}\n\\end{cases}\n$$\nThis represents a lazy symmetric random walk. The stationary distribution for this chain is the uniform distribution, $\\pi(i) = \\frac{1}{n}$ for all $i \\in \\{0, 1, \\ldots, n-1\\}$.\n\nThis chain satisfies the detailed balance condition with respect to $\\pi$. For any two states $i$ and $j=(i+1) \\bmod n$:\n$$\n\\pi(i) P_{\\mathrm{base}}(i, j) = \\frac{1}{n} \\cdot \\frac{1 - p_{\\mathrm{stay}}}{2}\n$$\n$$\n\\pi(j) P_{\\mathrm{base}}(j, i) = \\frac{1}{n} \\cdot \\frac{1 - p_{\\mathrm{stay}}}{2}\n$$\nSince $\\pi(i) P_{\\mathrm{base}}(i, j) = \\pi(j) P_{\\mathrm{base}}(j, i)$, the chain is reversible. This implies a zero net probability current between any two states at equilibrium, i.e., $J(i \\to j) = \\pi(i) P_{\\mathrm{base}}(i, j) - \\pi(j) P_{\\mathrm{base}}(j, i) = 0$.\n\nThe matrix $P_{\\mathrm{base}}$ is a circulant matrix. Its eigenvalues can be found analytically. For $k \\in \\{0, 1, \\ldots, n-1\\}$, the eigenvalues are given by:\n$$\n\\lambda_k = p_{\\mathrm{stay}} + (1-p_{\\mathrm{stay}}) \\cos\\left(\\frac{2\\pi k}{n}\\right)\n$$\nThe largest eigenvalue is $\\lambda_0 = 1$. The absolute spectral gap, $\\gamma(P_{\\mathrm{base}})$, is defined as $1 - \\max_{k \\neq 0} |\\lambda_k|$. The second largest eigenvalue magnitude is typically determined by $k=1$ and $k=n-1$, yielding $\\lambda_1 = p_{\\mathrm{stay}} + (1-p_{\\mathrm{stay}})\\cos(2\\pi/n)$. Thus, the spectral gap is:\n$$\n\\gamma(P_{\\mathrm{base}}) = 1 - \\left( p_{\\mathrm{stay}} + (1-p_{\\mathrm{stay}}) \\cos\\left(\\frac{2\\pi}{n}\\right) \\right) = (1 - p_{\\mathrm{stay}})\\left(1 - \\cos\\left(\\frac{2\\pi}{n}\\right)\\right)\n$$\nFor large $n$, since $1 - \\cos(x) \\approx x^2/2$, the gap scales as $\\gamma(P_{\\mathrm{base}}) \\propto \\frac{1}{n^2}$, indicating slow convergence for large cycles.\n\n### 2. The Lifted Chain: Non-Reversible Dynamics\n\nThe lifted chain is constructed on an expanded state space $\\Omega = \\{0, 1, \\ldots, n-1\\} \\times \\{+,-\\}$, where each site $i$ on the cycle is associated with a \"spin\" or direction, $+$ or $-$. The state space has size $2n$. The transitions are defined as follows for a given flip probability $r \\in [0,1]$:\n- From state $(i,+)$, transition to $((i+1) \\bmod n, +)$ with probability $1-r$, or flip spin to $(i,-)$ with probability $r$.\n- From state $(i,-)$, transition to $((i-1) \\bmod n, -)$ with probability $1-r$, or flip spin to $(i,+)$ with probability $r$.\n\nThe stationary distribution for this chain is uniform on $\\Omega$, with $\\pi^*(i, s) = \\frac{1}{2n}$ for any state $(i,s) \\in \\Omega$.\n\nThis chain is specifically designed to be non-reversible. To verify this, we check the detailed balance condition. Consider the forward transition along the '+' cycle from $x = (i,+)$ to $y = ((i+1) \\bmod n, +)$:\n$$\n\\pi^*(x) P_{\\mathrm{lift}}(x, y) = \\frac{1}{2n} \\cdot (1-r)\n$$\nThe reverse transition probability $P_{\\mathrm{lift}}(y, x) = P_{\\mathrm{lift}}(((i+1) \\bmod n, +), (i,+)) = 0$, since a '+' state cannot move backward. Thus:\n$$\n\\pi^*(y) P_{\\mathrm{lift}}(y, x) = \\frac{1}{2n} \\cdot 0 = 0\n$$\nSince $\\pi^*(x) P_{\\mathrm{lift}}(x, y) \\neq \\pi^*(y) P_{\\mathrm{lift}}(y, x)$ (for $r1$), detailed balance is broken, and the chain is non-reversible.\n\n### 3. Net Probability Circulation\n\nThe violation of detailed balance leads to non-zero net probability currents at steady state. The net current on the edge from $x=(i,+)$ to $y=((i+1)\\bmod n, +)$ is:\n$$\nJ(x \\to y) = \\pi^*(x) P_{\\mathrm{lift}}(x, y) - \\pi^*(y) P_{\\mathrm{lift}}(y, x) = \\frac{1-r}{2n} - 0 = \\frac{1-r}{2n}\n$$\nThe problem asks for the total circulation $J_+$ along the oriented cycle $\\mathcal{C}_+ = \\big\\{(0,+) \\to (1,+) \\to \\cdots \\to (n-1,+) \\to (0,+)\\big\\}$. This is the sum of the currents on each edge of this cycle:\n$$\nJ_+ = \\sum_{i=0}^{n-1} J\\big( (i,+) \\to ((i+1) \\bmod n, +) \\big) = \\sum_{i=0}^{n-1} \\frac{1-r}{2n} = n \\cdot \\frac{1-r}{2n} = \\frac{1-r}{2}\n$$\nThis result is remarkably simple, depending only on the flip probability $r$ and not on the cycle size $n$. It quantifies the persistent probabilistic flow in one direction around the cycle.\n\n### 4. Spectral Gap Computation and Comparison\n\nThe spectral gap $\\gamma(P) = 1 - \\max\\{|\\lambda| : \\lambda \\in \\mathrm{spec}(P), \\lambda \\neq 1\\}$ determines the asymptotic rate of convergence of the Markov chain to its stationary distribution. A larger gap implies faster convergence. While the base chain's gap suffers from a $1/n^2$ scaling, non-reversible chains can overcome this. The eigenvalues of $P_{\\mathrm{lift}}$ can be found analytically, but the expressions are complex. The crucial insight is that for a range of parameters, the magnitudes of many eigenvalues of $P_{\\mathrm{lift}}$ are fixed at $\\sqrt{(1-r)^2-r^2} = \\sqrt{1-2r}$, a value independent of $n$. This can lead to a spectral gap that does not shrink to zero as $n \\to \\infty$, offering a significant performance improvement over the diffusive reversible chain.\n\nFor the purposes of this problem, we will compute the eigenvalues of both $P_{\\mathrm{base}}$ and $P_{\\mathrm{lift}}$ numerically using standard linear algebra routines. For a given transition matrix $P$, we perform the following steps:\n1.  Compute the full spectrum of eigenvalues, $\\mathrm{spec}(P)$.\n2.  Identify and remove the eigenvalue(s) equal to $1$ (within a small numerical tolerance).\n3.  Find the maximum absolute value (modulus) among the remaining eigenvalues. Let this be $\\max|\\lambda'|$.\n4.  The spectral gap is $\\gamma(P) = 1 - \\max|\\lambda'|$.\n\nThe final task is to calculate $\\gamma(P_{\\mathrm{base}})$, $\\gamma(P_{\\mathrm{lift}})$, the indicator $\\mathbf{1}\\{\\gamma(P_{\\mathrm{lift}}) > \\gamma(P_{\\mathrm{base}})\\}$, and the circulation $J_+$ for each specified test case. The implementation will construct the matrices as described and apply this numerical procedure.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Markov chain problem for the specified test cases.\n\n    For each test case (n, p_stay, r), it constructs the base and lifted\n    transition matrices, computes their spectral gaps, compares them, and\n    calculates the circulation of the lifted chain.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (general \"happy path\")\n        (10, 0.2, 0.1),\n        # Case B (boundary flip rate)\n        (10, 0.2, 0.0),\n        # Case C (non-lazy odd cycle)\n        (15, 0.0, 0.2),\n        # Case D (high laziness)\n        (50, 0.9, 0.05),\n    ]\n\n    results = []\n    for n, p_stay, r in test_cases:\n        # 1. Base chain construction and spectral gap\n        p_hop = (1 - p_stay) / 2\n        P_base = (\n            p_stay * np.eye(n)\n            + p_hop * np.roll(np.eye(n), 1, axis=1)\n            + p_hop * np.roll(np.eye(n), -1, axis=1)\n        )\n        gamma_base = compute_spectral_gap(P_base)\n\n        # 2. Lifted chain construction and spectral gap\n        P_lift = construct_lifted_matrix(n, r)\n        gamma_lift = compute_spectral_gap(P_lift)\n\n        # 3. Net probability circulation calculation\n        # J_plus is derived analytically as (1-r)/2\n        j_plus = (1 - r) / 2.0\n\n        # 4. Comparison\n        is_lifted_gap_larger = 1 if gamma_lift > gamma_base else 0\n\n        # Store the results for the current case\n        results.append([gamma_base, gamma_lift, is_lifted_gap_larger, j_plus])\n\n    # Final print statement in the exact required format.\n    # The format is a list of lists, with no spaces.\n    # e.g., [[val1,val2,val3,val4],[...]]\n    case_results_str = [str(res).replace(\" \", \"\") for res in results]\n    print(f\"[{','.join(case_results_str)}]\")\n\ndef construct_lifted_matrix(n, r):\n    \"\"\"\n    Constructs the transition matrix P_lift for the lifted chain.\n\n    Args:\n        n (int): The number of nodes in the base cycle graph.\n        r (float): The probability of flipping spin.\n\n    Returns:\n        np.ndarray: The (2n x 2n) transition matrix P_lift.\n    \"\"\"\n    # State (i,+) corresponds to index i\n    # State (i,-) corresponds to index i+n\n    size = 2 * n\n    P_lift = np.zeros((size, size))\n\n    # Using block matrix formulation for elegance and efficiency\n    # P_lift = | (1-r)C   r*I |\n    #          | r*I   (1-r)C' |\n    # where C is forward circulant and C' is backward.\n    I_n = np.eye(n)\n    C_forward = np.roll(I_n, 1, axis=1)\n    C_backward = np.roll(I_n, -1, axis=1)\n\n    P_lift[:n, :n] = (1 - r) * C_forward\n    P_lift[:n, n:] = r * I_n\n    P_lift[n:, :n] = r * I_n\n    P_lift[n:, n:] = (1 - r) * C_backward\n    \n    return P_lift\n\ndef compute_spectral_gap(P):\n    \"\"\"\n    Computes the absolute spectral gap of a transition matrix P.\n\n    gamma(P) = 1 - max{|lambda| : lambda in spec(P), lambda != 1}\n\n    Args:\n        P (np.ndarray): The transition matrix.\n\n    Returns:\n        float: The absolute spectral gap.\n    \"\"\"\n    # Compute eigenvalues\n    eigenvalues = np.linalg.eigvals(P)\n\n    # Filter out eigenvalues that are close to 1\n    # np.isclose handles floating point inaccuracies\n    non_one_eigenvalues = eigenvalues[~np.isclose(eigenvalues, 1.0)]\n\n    if non_one_eigenvalues.size == 0:\n        # This case occurs for a single-state absorbing chain, etc.\n        # or if all eigenvalues are 1 (e.g., identity matrix)\n        # Gap can be considered 1 as there's no second largest eigenvalue.\n        return 1.0\n\n    # Find the maximum modulus among the remaining eigenvalues\n    second_largest_modulus = np.max(np.abs(non_one_eigenvalues))\n\n    # Spectral gap is 1 minus this value\n    gap = 1.0 - second_largest_modulus\n    return gap\n\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3302612"}]}