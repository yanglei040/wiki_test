{"hands_on_practices": [{"introduction": "The core innovation of Delayed Rejection (DR) is giving a rejected proposal a second chance, but this requires a carefully constructed acceptance probability to maintain detailed balance. This exercise dives into the theoretical heart of the DR algorithm, tasking you with deriving the acceptance rule for a three-stage process [@problem_id:3302333]. By working through the logic, you will gain a deep appreciation for the elegant symmetry required between the multi-stage forward and reverse paths to ensure the resulting Markov chain is valid.", "problem": "Consider a target probability density known up to a normalizing constant, denoted by $\\pi(x)$ on $\\mathbb{R}^{d}$, and a Markov chain constructed by the Metropolis–Hastings (MH) method within the broader framework of Markov Chain Monte Carlo (MCMC). A delayed rejection (DR) scheme extends MH by allowing a second attempt, third attempt, and so on, after a rejection, using stage-specific proposal kernels with potentially increasing local adaptation. In DR of order $k$, one uses a family of proposal densities $\\{q_{j}(\\cdot)\\}_{j=1}^{k}$, where $q_{1}(x,\\cdot)$ is the first-stage kernel and subsequently $q_{j}(x,y_{1},\\ldots,y_{j-1},\\cdot)$ for $j \\ge 2$ may depend on the current state and the previously proposed points. Acceptance probabilities are chosen so that the resulting Markov transition kernel satisfies detailed balance with respect to $\\pi(\\cdot)$.\n\nSuppose we operate a DR scheme with $k=3$ stages. At a given iteration, from a current state $x$, we draw $y_{1} \\sim q_{1}(x,\\cdot)$ and attempt a standard MH accept/reject decision. If the proposal is rejected, we draw $y_{2} \\sim q_{2}(x,y_{1},\\cdot)$ and attempt a second-stage accept/reject. If rejected again, we draw $y_{3} \\sim q_{3}(x,y_{1},y_{2},\\cdot)$ and attempt a third-stage accept/reject, with acceptance probability denoted $\\alpha_{3}(x,y_{1},y_{2},y_{3})$. The acceptance probabilities at earlier stages are denoted by $\\alpha_{1}(x,y_{1})$ and $\\alpha_{2}(x,y_{1},y_{2})$, respectively. Assume that all proposal densities are everywhere positive on their supports and that all acceptance probabilities are chosen to enforce detailed balance and build a reversible Markov chain with respect to $\\pi(\\cdot)$.\n\nUsing the detailed balance principle and the fact that each stage-$j$ proposal in the forward path must be paired with the corresponding reverse path composed of $j$ nested proposals and $j-1$ rejections when viewed from the proposed state back to the current state, identify the correct explicit formula for the third-stage acceptance probability $\\alpha_{3}(x,y_{1},y_{2},y_{3})$ and describe the computational implications of evaluating the reverse-path quantities and the need for stored proposals.\n\nWhich option is correct?\n\nA. $\\alpha_{3}(x,y_{1},y_{2},y_{3}) = \\min\\Bigg\\{1,\\; \\dfrac{\\pi(y_{3})\\, q_{1}(y_{3},y_{2})\\, q_{2}(y_{3},y_{2},y_{1})\\, q_{3}(y_{3},y_{2},y_{1},x)\\, \\big(1-\\alpha_{1}(y_{3},y_{2})\\big)\\, \\big(1-\\alpha_{2}(y_{3},y_{2},y_{1})\\big)}{\\pi(x)\\, q_{1}(x,y_{1})\\, q_{2}(x,y_{1},y_{2})\\, q_{3}(x,y_{1},y_{2},y_{3})\\, \\big(1-\\alpha_{1}(x,y_{1})\\big)\\, \\big(1-\\alpha_{2}(x,y_{1},y_{2})\\big)} \\Bigg\\}$. Computationally, one must evaluate reverse-path proposal densities and reverse-path rejections, which generally requires target evaluations at $y_{1}$, $y_{2}$, and $y_{3}$; forward-path quantities $\\alpha_{1}(x,y_{1})$ and $\\alpha_{2}(x,y_{1},y_{2})$ should be stored to avoid recomputation. Memory and arithmetic costs grow on the order of $\\mathcal{O}(k)$ with the number of stages, and caching of $\\pi(\\cdot)$ and $q_{j}(\\cdot)$ evaluations is crucial to control overhead.\n\nB. $\\alpha_{3}(x,y_{1},y_{2},y_{3}) = \\min\\Bigg\\{1,\\; \\dfrac{\\pi(y_{3})\\, q_{1}(y_{3},x)\\, q_{2}(y_{3},x)\\, q_{3}(y_{3},x)}{\\pi(x)\\, q_{1}(x,y_{1})\\, q_{2}(x,y_{1},y_{2})\\, q_{3}(x,y_{1},y_{2},y_{3})} \\Bigg\\}$. Computationally, since only proposal densities appear, there is no need to evaluate any acceptance probabilities from previous stages nor to store intermediate proposals, so the memory and computational costs are negligible beyond evaluating the proposals.\n\nC. $\\alpha_{3}(x,y_{1},y_{2},y_{3}) = \\min\\Bigg\\{1,\\; \\dfrac{\\pi(y_{3})\\, q_{1}(y_{2},y_{3})\\, q_{2}(y_{1},y_{2},y_{3})\\, q_{3}(x,y_{1},y_{2},y_{3})\\, \\big(1-\\alpha_{1}(y_{2},y_{3})\\big)\\, \\big(1-\\alpha_{2}(y_{1},y_{2},y_{3})\\big)}{\\pi(x)\\, q_{1}(x,y_{1})\\, q_{2}(x,y_{1},y_{2})\\, q_{3}(x,y_{1},y_{2},y_{3})\\, \\big(1-\\alpha_{1}(x,y_{1})\\big)\\, \\big(1-\\alpha_{2}(x,y_{1},y_{2})\\big)} \\Bigg\\}$. Computationally, reverse-path rejections are unnecessary because the third stage directly mirrors the forward proposals; thus, only forward rejections should be stored.\n\nD. $\\alpha_{3}(x,y_{1},y_{2},y_{3}) = \\min\\Bigg\\{1,\\; \\dfrac{\\pi(y_{3})\\, q_{1}(y_{3},y_{2})\\, q_{2}(y_{3},y_{2},y_{1})\\, q_{3}(y_{3},y_{2},y_{1},x)\\, \\alpha_{1}(y_{3},y_{2})\\, \\alpha_{2}(y_{3},y_{2},y_{1})}{\\pi(x)\\, q_{1}(x,y_{1})\\, q_{2}(x,y_{1},y_{2})\\, q_{3}(x,y_{1},y_{2},y_{3})\\, \\alpha_{1}(x,y_{1})\\, \\alpha_{2}(x,y_{1},y_{2})} \\Bigg\\}$. Computationally, because acceptance probabilities rather than rejection probabilities appear, one can discard earlier proposals without loss, and no reverse-path evaluations are required as they cancel by symmetry.", "solution": "The acceptance probability for any stage in a Delayed Rejection scheme is derived from the generalized detailed balance condition. This condition ensures that the probability flow for a multi-step forward path from state $x$ to state $y_j$ is equal to the probability flow for the corresponding multi-step reverse path from $y_j$ back to $x$.\n\nFor a three-stage DR move from $x$ to $y_3$, the forward path involves proposing $y_1$ and rejecting it, then proposing $y_2$ and rejecting it, and finally proposing $y_3$ and accepting it. The probability density for this sequence of events is proportional to:\n$$\n\\pi(x) \\cdot q_1(x, y_1) [1-\\alpha_1(x, y_1)] \\cdot q_2(x, y_1, y_2) [1-\\alpha_2(x, y_1, y_2)] \\cdot q_3(x, y_1, y_2, y_3) \\cdot \\alpha_3(x, y_1, y_2, y_3)\n$$\nThe corresponding reverse path is constructed symmetrically: starting from $y_3$, one must propose $y_2$ and reject it, then propose $y_1$ and reject it, and finally propose $x$ and accept it. The probability density for this reverse sequence is proportional to:\n$$\n\\pi(y_3) \\cdot q_1(y_3, y_2) [1-\\alpha_1(y_3, y_2)] \\cdot q_2(y_3, y_2, y_1) [1-\\alpha_2(y_3, y_2, y_1)] \\cdot q_3(y_3, y_2, y_1, x) \\cdot \\alpha_3(y_3, y_2, y_1, x)\n$$\nTo satisfy detailed balance, we equate the flow densities for the forward move ($x \\to y_3$) and the reverse move ($y_3 \\to x$). The acceptance probability $\\alpha_3$ is then chosen with a standard Metropolis-Hastings form, which sets it to $\\min(1, \\text{ratio})$, where the ratio is formed by the parts of the flow densities excluding the final acceptance probabilities. This gives the formula:\n$$\n\\alpha_3(x,y_{1},y_{2},y_{3}) = \\min\\Bigg\\{1,\\; \\dfrac{\\pi(y_{3})\\, q_{1}(y_{3},y_{2})\\, \\big(1-\\alpha_{1}(y_{3},y_{2})\\big)\\, q_{2}(y_{3},y_{2},y_{1})\\, \\big(1-\\alpha_{2}(y_{3},y_{2},y_{1})\\big)\\, q_{3}(y_{3},y_{2},y_{1},x)}{\\pi(x)\\, q_{1}(x,y_{1})\\, \\big(1-\\alpha_{1}(x,y_{1})\\big)\\, q_{2}(x,y_{1},y_{2})\\, \\big(1-\\alpha_{2}(x,y_{1},y_{2})\\big)\\, q_{3}(x,y_{1},y_{2},y_{3})} \\Bigg\\}\n$$\nComparing this derived formula to the options:\n\n- **Option A** presents this exact formula. The construction correctly balances the probability flow of the forward path ($x \\to y_1 \\to y_2 \\to y_3$) with the reverse path ($y_3 \\to y_2 \\to y_1 \\to x$). It correctly includes the rejection probabilities $(1-\\alpha_j)$ for intermediate steps. The accompanying computational analysis is also accurate: evaluating the reverse path requires caching previously computed values of $\\pi(\\cdot)$ and the proposal densities, and the overall cost scales with the number of stages.\n\n- **Option B** is incorrect as it omits the crucial rejection probability factors $(1-\\alpha_j)$ and uses an incorrect structure for the reverse proposal densities.\n\n- **Option C** uses incorrectly structured proposal and acceptance probability terms for the reverse path (e.g., $q_1(y_2, y_3)$).\n\n- **Option D** is fundamentally flawed because it uses acceptance probabilities ($\\alpha_j$) instead of rejection probabilities ($1-\\alpha_j$) for the intermediate steps, which contradicts the logic of a multi-stage rejection scheme.\n\nTherefore, Option A is the only correct choice.", "answer": "$$\\boxed{A}$$", "id": "3302333"}, {"introduction": "While Delayed Rejection aims to salvage rejections, the related Delayed Acceptance (DA) strategy seeks to avoid expensive computations in the first place by using a cheap surrogate for pre-screening proposals. This practice explores the mechanics and consequences of the DA framework, including its relationship to standard Metropolis-Hastings [@problem_id:3302339]. You will analyze how DA correctly preserves the target distribution while uncovering the fundamental trade-off between computational savings and sampling quality, which hinges on the accuracy of the surrogate.", "problem": "Consider a target probability density $\\pi(x)$ known up to a normalizing constant on a measurable state space $\\mathcal{X}$, and a proposal kernel $q(y \\mid x)$ used in a Metropolis–Hastings (MH) algorithm. The standard MH acceptance probability is defined by the detailed-balance-preserving rule\n$$\n\\alpha_{\\mathrm{MH}}(x,y) \\equiv \\min\\left\\{1,\\; r(x,y)\\right\\}, \\quad r(x,y) \\equiv \\frac{\\pi(y)\\, q(x \\mid y)}{\\pi(x)\\, q(y \\mid x)}.\n$$\nA delayed acceptance (DA) strategy introduces a computationally cheaper surrogate $\\tilde{\\pi}(x)$ for $\\pi(x)$ and screens proposals in two stages:\n- Stage $1$ computes a first-stage acceptance probability $\\alpha_{1}(x,y)$ using $\\tilde{\\pi}$ and $q$, and accepts with probability $\\alpha_{1}(x,y)$.\n- Conditional on stage $1$ acceptance, stage $2$ computes a second-stage acceptance probability $\\alpha_{2}(x,y)$ that uses $\\pi$, $\\tilde{\\pi}$, and $q$ to correct for the surrogate, and accepts with probability $\\alpha_{2}(x,y)$.\nThe overall DA acceptance probability for a proposed move $x \\to y$ is $\\alpha_{\\mathrm{DA}}(x,y) \\equiv \\alpha_{1}(x,y)\\, \\alpha_{2}(x,y)$. A standard construction chooses\n$$\n\\alpha_{1}(x,y) \\equiv \\min\\left\\{1,\\; r_{1}(x,y)\\right\\}, \\quad r_{1}(x,y) \\equiv \\frac{\\tilde{\\pi}(y)\\, q(x \\mid y)}{\\tilde{\\pi}(x)\\, q(y \\mid x)},\n$$\nand\n$$\n\\alpha_{2}(x,y) \\equiv \\min\\left\\{1,\\; \\frac{r(x,y)}{r_{1}(x,y)}\\right\\} \\;=\\; \\min\\left\\{1,\\; \\frac{\\pi(y)}{\\pi(x)} \\cdot \\frac{\\tilde{\\pi}(x)}{\\tilde{\\pi}(y)}\\right\\},\n$$\nso that stage $1$ uses the surrogate ratio and stage $2$ applies an exact correction.\n\nAssume the computational cost to evaluate $\\tilde{\\pi}(x)$ is $c_{\\mathrm{s}}>0$ and the cost to evaluate $\\pi(x)$ is $c_{\\mathrm{f}}\\gg c_{\\mathrm{s}}$. In standard MH, each iteration incurs cost approximately $c_{\\mathrm{f}}$, while in DA each iteration incurs cost $c_{\\mathrm{s}} + c_{\\mathrm{f}}\\, \\alpha_{1}(x,y)$ on average. Let $\\mathcal{P}$ denote the MH transition kernel and $\\mathcal{P}_{\\mathrm{DA}}$ denote the DA transition kernel induced by the above acceptance probabilities.\n\nSelect all statements that are correct about the relationship between delayed acceptance and Metropolis–Hastings, and about the effect of a poor surrogate $\\tilde{\\pi}$ on mixing:\n\nA. If $\\tilde{\\pi} \\equiv \\pi$, then $\\alpha_{\\mathrm{DA}}(x,y) = \\alpha_{\\mathrm{MH}}(x,y)$ for all $x,y \\in \\mathcal{X}$, and $\\mathcal{P}_{\\mathrm{DA}}$ coincides with $\\mathcal{P}$, i.e., the DA chain has the same transition probabilities and path distribution as standard Metropolis–Hastings.\n\nB. If $\\tilde{\\pi}(x) \\equiv c\\, \\pi(x)$ for some constant $c>0$, then $\\alpha_{\\mathrm{DA}}(x,y) = \\alpha_{\\mathrm{MH}}(x,y)$ for all $x,y \\in \\mathcal{X}$, so DA reduces to standard Metropolis–Hastings.\n\nC. If $\\tilde{\\pi}$ severely underestimates $\\pi$ in high-probability regions (e.g., $\\tilde{\\pi}(y) \\ll \\pi(y)$ when $\\pi(y)$ is large), then the first-stage acceptance $\\alpha_{1}(x,y)$ will be small for proposals toward those regions, making $\\alpha_{\\mathrm{DA}}(x,y) < \\alpha_{\\mathrm{MH}}(x,y)$ on many pairs $(x,y)$. This can reduce the spectral gap of $\\mathcal{P}_{\\mathrm{DA}}$ relative to $\\mathcal{P}$ and increase asymptotic variance per unit time, even though the average per-iteration cost $c_{\\mathrm{s}} + c_{\\mathrm{f}}\\, \\alpha_{1}$ is smaller than $c_{\\mathrm{f}}$.\n\nD. Because DA screens proposals cheaply before applying $\\pi$, it always yields a larger overall acceptance probability than standard Metropolis–Hastings, and therefore strictly better mixing, regardless of the choice of $\\tilde{\\pi}$.\n\nE. Provided $\\tilde{\\pi}(x) > 0$ for all $x \\in \\mathcal{X}$, the DA construction with $\\alpha_{1}$ and $\\alpha_{2}$ as above yields a transition kernel $\\mathcal{P}_{\\mathrm{DA}}$ that is reversible with respect to $\\pi$, and thus has $\\pi$ as its invariant distribution.\n\nChoose all that apply.", "solution": "Let's analyze each statement based on the provided definitions for the Delayed Acceptance (DA) and standard Metropolis-Hastings (MH) algorithms.\n\n**A.** If we set $\\tilde{\\pi}(x) = \\pi(x)$ for all $x$, the first-stage ratio $r_1(x,y)$ becomes identical to the full MH ratio $r(x,y)$. This makes the first-stage acceptance probability $\\alpha_1(x,y)$ equal to the standard MH acceptance probability $\\alpha_{\\mathrm{MH}}(x,y)$. The second-stage ratio $\\frac{\\pi(y)\\tilde{\\pi}(x)}{\\pi(x)\\tilde{\\pi}(y)}$ becomes $\\frac{\\pi(y)\\pi(x)}{\\pi(x)\\pi(y)} = 1$, so the second-stage acceptance probability $\\alpha_2(x,y)$ is always 1. The overall acceptance probability $\\alpha_{\\mathrm{DA}}(x,y) = \\alpha_1(x,y) \\cdot \\alpha_2(x,y)$ is therefore equal to $\\alpha_{\\mathrm{MH}}(x,y)$. Since the acceptance probabilities are identical, the transition kernels are identical, and the DA chain is statistically indistinguishable from the standard MH chain. Thus, this statement is correct.\n\n**B.** If we set $\\tilde{\\pi}(x) = c \\pi(x)$ for some constant $c>0$, the constant $c$ cancels out in both the numerator and denominator of the first-stage ratio $r_1(x,y)$ and the second-stage ratio. The result is identical to the analysis in A: $r_1(x,y) = r(x,y)$ and the second-stage ratio is 1. Therefore, $\\alpha_{\\mathrm{DA}}(x,y) = \\alpha_{\\mathrm{MH}}(x,y)$, and the DA scheme reduces to standard Metropolis-Hastings. This is expected, as the MH algorithm is invariant to the normalization of the target density. Thus, this statement is correct.\n\n**C.** The overall DA acceptance probability is $\\alpha_{\\mathrm{DA}}(x,y) = \\min\\{1, r_1\\} \\min\\{1, r/r_1\\}$, while the MH acceptance probability is $\\alpha_{\\mathrm{MH}}(x,y) = \\min\\{1, r\\}$. It is a general inequality that $\\min\\{1, u\\}\\min\\{1, v\\} \\le \\min\\{1, uv\\}$ for non-negative $u, v$. Thus, $\\alpha_{\\mathrm{DA}} \\le \\alpha_{\\mathrm{MH}}$ always. If the surrogate $\\tilde{\\pi}$ severely underestimates $\\pi$ in important regions, the first-stage acceptance $\\alpha_1$ will be unnecessarily low for moves into those regions, causing the overall acceptance probability $\\alpha_{\\mathrm{DA}}$ to be strictly smaller than $\\alpha_{\\mathrm{MH}}$. By Peskun's theorem, a lower acceptance probability (poorer exploration) leads to higher or equal asymptotic variance per iteration. While DA reduces the cost per iteration, if the surrogate is poor, the increase in variance can be so large that the overall efficiency (measured per unit time) decreases. The statement correctly identifies this critical trade-off. Thus, this statement is correct.\n\n**D.** This statement makes two incorrect claims. First, as shown in the analysis for C, DA always yields a *smaller or equal* overall acceptance probability, not a larger one. Second, better mixing is not guaranteed and depends critically on the quality of the surrogate $\\tilde{\\pi}$. A poor surrogate can severely degrade mixing. Thus, this statement is incorrect.\n\n**E.** The validity of the DA algorithm rests on the fact that its transition kernel $\\mathcal{P}_{\\mathrm{DA}}$ satisfies the detailed balance condition with respect to the true target $\\pi$. The two-stage acceptance probability is constructed by factoring the MH ratio $r(x,y)$ into $r_1(x,y)$ and $r_2(x,y) = r(x,y)/r_1(x,y)$. This construction guarantees that the ratio of acceptance probabilities $\\alpha_{\\mathrm{DA}}(x,y)/\\alpha_{\\mathrm{DA}}(y,x)$ is equal to $r(x,y)$, which is precisely the requirement for detailed balance with respect to $\\pi$. A reversible chain with respect to $\\pi$ is guaranteed to have $\\pi$ as its invariant distribution (assuming irreducibility, which requires the support condition $\\tilde{\\pi}(x) > 0$ when $\\pi(x) > 0$). Thus, this statement is correct.\n\nBased on the analysis, statements A, B, C, and E are correct.", "answer": "$$\\boxed{ABCE}$$", "id": "3302339"}, {"introduction": "A statistically valid algorithm is not necessarily a practical one; its utility depends on its efficiency. This exercise moves from theoretical correctness to a quantitative analysis of performance, asking you to determine when a Delayed Rejection scheme provides a net benefit over a standard sampler [@problem_id:3302307]. By formulating a criterion based on expected jump distance and computational cost, you will develop a framework for making informed decisions about whether to implement DR in a given problem.", "problem": "Consider a two-stage Delayed Rejection (DR) variant of the Metropolis–Hastings algorithm within Markov Chain Monte Carlo (MCMC), targeting a probability density $\\pi(x)$ on $\\mathbb{R}^d$. Let the current state be $X \\in \\mathbb{R}^d$. The stage-$1$ proposal is $Y \\sim q_1(X,\\cdot)$ with acceptance probability\n$$\n\\alpha_1(X,Y) \\;=\\; \\min\\!\\left\\{1, \\;\\frac{\\pi(Y)\\,q_1(Y,X)}{\\pi(X)\\,q_1(X,Y)}\\right\\}.\n$$\nIf the stage-$1$ proposal is rejected, a stage-$2$ proposal $Z \\sim q_2(X,Y,\\cdot)$ is drawn and accepted with probability $\\alpha_2(X,Y,Z)$ chosen so that the resulting Markov chain is reversible with respect to $\\pi$. A common choice (Mira’s two-stage delayed rejection acceptance) is\n$$\n\\alpha_2(X,Y,Z) \\;=\\; \\min\\!\\left\\{1, \\; \\frac{\\pi(Z)\\,q_1(Z,Y)\\,\\big(1-\\alpha_1(Z,Y)\\big)\\,q_2(Z,Y,X)}{\\pi(X)\\,q_1(X,Y)\\,\\big(1-\\alpha_1(X,Y)\\big)\\,q_2(X,Y,Z)}\\right\\}.\n$$\nDefine the following expected quantities under the stationary regime:\n- $p_1 \\;=\\; \\mathbb{E}\\!\\left[\\alpha_1(X,Y)\\right]$, the stage-$1$ acceptance probability.\n- $p_2 \\;=\\; \\mathbb{E}\\!\\left[\\alpha_2(X,Y,Z)\\,\\big|\\,\\text{stage-$1$ rejection}\\right]$, the stage-$2$ acceptance probability conditional on stage-$1$ rejection.\n- $J_1 \\;=\\; \\mathbb{E}\\!\\left[\\|Y-X\\|^2 \\,\\big|\\,\\text{stage-$1$ acceptance}\\right]$, the conditional expected squared jump distance at stage $1$, where $\\|\\cdot\\|$ is the Euclidean norm.\n- $J_2 \\;=\\; \\mathbb{E}\\!\\left[\\|Z-X\\|^2 \\,\\big|\\,\\text{stage-$2$ acceptance}\\right]$, the conditional expected squared jump distance at stage $2$.\n\nAssume a cost model in which the expected computational time per iteration comprises a stage-$1$ cost $c_1>0$ that is always incurred, plus an incremental stage-$2$ cost $c_2>0$ that is incurred only when stage-$1$ rejects. For the one-stage baseline that uses only $q_1$ (no delayed rejection), the efficiency is measured by the expected squared jump distance per unit time, defined as the expected squared jump per iteration divided by the expected computational time per iteration.\n\nWhich option correctly identifies a quantitative criterion for when DR yields a net efficiency gain over the one-stage baseline, expressed in terms of the expected squared jump distance per unit time, and also highlights realistic cases where DR may not improve efficiency because of a poor choice of $q_2$ or increased computational cost?\n\nA. DR is more efficient than the baseline if\n$$\n\\frac{p_1\\,J_1 + (1-p_1)\\,p_2\\,J_2}{\\,c_1 + (1-p_1)\\,c_2\\,} \\;>\\; \\frac{p_1\\,J_1}{\\,c_1\\,}.\n$$\nDR may fail to improve efficiency when $q_2$ is overly local so that $J_2$ is negligible relative to $J_1$ (for example, a very small step size yielding $J_2 \\approx 0$), or when the stage-$2$ mechanism substantially increases cost (for example, $c_2 \\gg c_1$ due to expensive local curvature computations), so the left-hand side falls below the baseline.\n\nB. DR always improves efficiency because any additional acceptance strictly increases the expected squared jump distance per unit time. A valid criterion is\n$$\n\\frac{p_1\\,J_1 + p_2\\,J_2}{\\,c_1 + c_2\\,} \\;>\\; \\frac{p_1\\,J_1}{\\,c_1\\,},\n$$\nand no choice of $q_2$ or costs $c_2$ can make DR worse than the baseline.\n\nC. DR is beneficial if and only if $p_2>p_1$ and $c_2<c_1$. Poor choices of $q_2$ only matter through the acceptance rate $p_2$, not through the jump distance, so the only relevant criterion is $p_2>p_1$.\n\nD. DR is more efficient than the baseline if\n$$\n\\frac{p_1\\,J_1}{\\,c_1 + c_2\\,} \\;<\\; \\frac{p_1\\,J_1 + p_2\\,J_2}{\\,c_1\\,}.\n$$\nDR may fail when $q_2$ has low acceptance, but its jump magnitude $J_2$ does not enter the decision because only acceptance rates drive efficiency.\n\nE. DR may be harmful because the stage-$2$ correction can change the invariant distribution away from $\\pi$, so efficiency comparisons are ill-posed. A conservative criterion is to ensure $q_2$ leaves $\\pi$ invariant by itself, in which case DR improves efficiency unconditionally.", "solution": "To determine the criterion for efficiency gain, we must first define the efficiency for the baseline Metropolis-Hastings (MH) algorithm and the two-stage Delayed Rejection (DR) algorithm using the provided metric: Expected Squared Jump Distance per Unit Time.\n\n**1. Efficiency of the Baseline Algorithm**\n-   **Expected Squared Jump Distance per Iteration**: A jump occurs if the stage-1 proposal is accepted (probability $p_1$), with conditional expected squared distance $J_1$. If rejected (probability $1-p_1$), the jump distance is 0. The total expected squared jump is $p_1 J_1 + (1-p_1) \\cdot 0 = p_1 J_1$.\n-   **Expected Computational Time per Iteration**: The baseline algorithm only performs stage 1, incurring a cost of $c_1$.\n-   **Baseline Efficiency**: \n    $$ \\text{Eff}_{\\text{baseline}} = \\frac{p_1 J_1}{c_1} $$\n\n**2. Efficiency of the DR Algorithm**\n-   **Expected Squared Jump Distance per Iteration**: A jump occurs either at stage 1 (probability $p_1$, expected distance $J_1$) or at stage 2. Stage 2 is reached with probability $(1-p_1)$ and a jump occurs with conditional probability $p_2$, for a total probability of $(1-p_1)p_2$. The conditional expected squared distance for a stage-2 jump is $J_2$. The total expected squared jump is the sum of contributions from both stages: $p_1 J_1 + (1-p_1) p_2 J_2$.\n-   **Expected Computational Time per Iteration**: The stage-1 cost $c_1$ is always incurred. The stage-2 cost $c_2$ is incurred only if stage 1 rejects, which happens with probability $(1-p_1)$. The total expected time is $c_1 + (1-p_1) c_2$.\n-   **DR Efficiency**:\n    $$ \\text{Eff}_{\\text{DR}} = \\frac{p_1 J_1 + (1-p_1) p_2 J_2}{c_1 + (1-p_1) c_2} $$\n\n**3. Criterion for Efficiency Gain**\nDR is more efficient than the baseline if $\\text{Eff}_{\\text{DR}} > \\text{Eff}_{\\text{baseline}}$. This gives the inequality:\n$$ \\frac{p_1 J_1 + (1-p_1) p_2 J_2}{c_1 + (1-p_1) c_2} > \\frac{p_1 J_1}{c_1} $$\nThis inequality shows that the benefit from the second stage, represented by the term $(1-p_1)p_2 J_2$, must be large enough to offset the additional computational cost, $(1-p_1)c_2$.\n\n**Analysis of Options:**\n-   **Option A** correctly presents this derived inequality and accurately describes the conditions under which DR might fail to improve efficiency: if the additional jump distance $J_2$ from the second stage is negligible, or if the cost $c_2$ of the second stage is too high. This matches our analysis.\n-   **Option B** is incorrect because it falsely claims DR always improves efficiency and uses an incorrect formula for DR's efficiency, omitting the crucial $(1-p_1)$ factors.\n-   **Option C** is incorrect as it oversimplifies the criterion, ignoring the critical role of jump distance $J_2$ and providing conditions that are neither necessary nor sufficient.\n-   **Option D** presents a mathematically nonsensical inequality and incorrectly claims that jump magnitude is irrelevant to efficiency.\n-   **Option E** is incorrect because the DR algorithm is constructed to preserve the target distribution $\\pi$, making the efficiency comparison well-posed. The claim of unconditional improvement is also false.\n\nTherefore, Option A provides the correct quantitative criterion and qualitative analysis.", "answer": "$$\\boxed{A}$$", "id": "3302307"}]}