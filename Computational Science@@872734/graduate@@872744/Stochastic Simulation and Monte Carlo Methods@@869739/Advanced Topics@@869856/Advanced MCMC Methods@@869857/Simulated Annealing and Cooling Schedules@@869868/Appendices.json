{"hands_on_practices": [{"introduction": "The essence of simulated annealing lies in the trade-off between exploring the energy landscape by accepting uphill moves and exploiting promising regions by descending in energy. The temperature $T$ is the crucial parameter that mediates this balance. This exercise asks you to quantify this dynamic by deriving the expected change in energy after a single step of the algorithm for a given temperature $T_0$ [@problem_id:3339546]. Completing this derivation provides a foundational, first-principles understanding of how temperature directly governs the local behavior of the search process.", "problem": "Consider Simulated Annealing (SA) with the Metropolis acceptance rule at a fixed initial temperature $T_0$, where the energy increment proposal $\\Delta E$ is generated by a symmetric Laplace (double exponential) distribution with scale parameter $b>0$, that is, with probability density function $f(\\Delta E) = \\frac{1}{2b}\\exp\\!\\big(-|\\Delta E|/b\\big)$. Assume the Boltzmann constant is normalized to $k_B = 1$ so that both temperature and energy are in the same dimensionless units. The Metropolis acceptance probability for a proposed move that changes the energy by $\\Delta E$ at temperature $T$ is $a(\\Delta E; T) = \\min\\!\\big(1, \\exp(-\\Delta E/T)\\big)$.\n\nStarting only from these definitions, derive a closed-form analytic expression for the expected one-step change in energy under the Metropolis rule at the initial temperature $T_0$, denoted by $\\mathbb{E}[\\Delta E_{\\text{step}}]$, where a rejected proposal contributes zero energy change. Your derivation must quantify the trade-off that a large $T_0$ increases acceptance of uphill moves and slows expected energy descent.\n\nProvide your final answer as a single closed-form expression in terms of $b$ and $T_0$. No numerical approximation or rounding is required.", "solution": "The problem statement is validated as scientifically grounded, well-posed, and objective. It is a standard theoretical problem in the field of stochastic simulation and Monte Carlo methods, specifically concerning the Simulated Annealing (SA) algorithm. All necessary components for a derivation are provided, and there are no contradictions or ambiguities.\n\nThe objective is to derive a closed-form expression for the expected one-step change in energy, denoted by $\\mathbb{E}[\\Delta E_{\\text{step}}]$, at a fixed initial temperature $T_0$. A proposed energy change, $\\Delta E$, is generated from a symmetric Laplace distribution with probability density function (PDF) $f(\\Delta E) = \\frac{1}{2b}\\exp(-|\\Delta E|/b)$, where $b>0$. This proposal is accepted or rejected according to the Metropolis acceptance rule, $a(\\Delta E; T_0) = \\min(1, \\exp(-\\Delta E/T_0))$. The Boltzmann constant is normalized such that $k_B=1$. If a move is accepted, the system's energy changes by $\\Delta E$. If a move is rejected, the energy change is $0$.\n\nThe expected one-step change in energy is found by integrating over all possible proposed energy changes $\\Delta E$. For each proposal, the resulting energy change is $\\Delta E$ if the move is accepted (with probability $a(\\Delta E; T_0)$) and $0$ if the move is rejected (with probability $1 - a(\\Delta E; T_0)$). The expected value is thus the integral of the proposed change $\\Delta E$ multiplied by its acceptance probability, weighted by the probability density of the proposal itself.\n\n$$\n\\mathbb{E}[\\Delta E_{\\text{step}}] = \\int_{-\\infty}^{\\infty} \\Delta E \\cdot a(\\Delta E; T_0) \\cdot f(\\Delta E) \\, d(\\Delta E)\n$$\n\nThe Metropolis acceptance probability $a(\\Delta E; T_0)$ has a piecewise definition based on the sign of $\\Delta E$:\n1.  If $\\Delta E \\le 0$ (a \"downhill\" move, energy decreases or stays the same), then $-\\Delta E/T_0 \\ge 0$, and $\\exp(-\\Delta E/T_0) \\ge 1$. Thus, $a(\\Delta E; T_0) = 1$.\n2.  If $\\Delta E > 0$ (an \"uphill\" move, energy increases), then $-\\Delta E/T_0  0$, and $\\exp(-\\Delta E/T_0)  1$. Thus, $a(\\Delta E; T_0) = \\exp(-\\Delta E/T_0)$.\n\nWe can split the integral into two parts corresponding to these two cases:\n$$\n\\mathbb{E}[\\Delta E_{\\text{step}}] = \\int_{-\\infty}^{0} \\Delta E \\cdot (1) \\cdot f(\\Delta E) \\, d(\\Delta E) + \\int_{0}^{\\infty} \\Delta E \\cdot \\exp(-\\Delta E/T_0) \\cdot f(\\Delta E) \\, d(\\Delta E)\n$$\n\nNext, we substitute the given PDF $f(\\Delta E) = \\frac{1}{2b}\\exp(-|\\Delta E|/b)$, noting that $|\\Delta E| = -\\Delta E$ for $\\Delta E  0$ and $|\\Delta E| = \\Delta E$ for $\\Delta E > 0$.\n\nFor the first integral, $I_1$ (downhill moves):\n$$\nI_1 = \\int_{-\\infty}^{0} \\Delta E \\cdot \\frac{1}{2b}\\exp(-(-\\Delta E)/b) \\, d(\\Delta E) = \\frac{1}{2b} \\int_{-\\infty}^{0} \\Delta E \\exp(\\Delta E/b) \\, d(\\Delta E)\n$$\nWe use integration by parts, $\\int u \\, dv = uv - \\int v \\, du$. Let $u = \\Delta E$ and $dv = \\exp(\\Delta E/b) \\, d(\\Delta E)$. Then $du = d(\\Delta E)$ and $v = b\\exp(\\Delta E/b)$.\n$$\nI_1 = \\frac{1}{2b} \\left( \\left[ \\Delta E \\cdot b\\exp(\\Delta E/b) \\right]_{-\\infty}^{0} - \\int_{-\\infty}^{0} b\\exp(\\Delta E/b) \\, d(\\Delta E) \\right)\n$$\n$$\nI_1 = \\frac{1}{2} \\left( \\left[ \\Delta E \\exp(\\Delta E/b) \\right]_{-\\infty}^{0} - \\int_{-\\infty}^{0} \\exp(\\Delta E/b) \\, d(\\Delta E) \\right)\n$$\nThe first term evaluates to $(0 \\cdot \\exp(0)) - \\lim_{\\Delta E \\to -\\infty} (\\Delta E \\exp(\\Delta E/b)) = 0 - 0 = 0$. The integral evaluates to:\n$$\nI_1 = -\\frac{1}{2} \\left[ b\\exp(\\Delta E/b) \\right]_{-\\infty}^{0} = -\\frac{b}{2} \\left( \\exp(0) - \\lim_{\\Delta E \\to -\\infty} \\exp(\\Delta E/b) \\right) = -\\frac{b}{2}(1 - 0) = -\\frac{b}{2}\n$$\n\nFor the second integral, $I_2$ (uphill moves):\n$$\nI_2 = \\int_{0}^{\\infty} \\Delta E \\cdot \\exp(-\\Delta E/T_0) \\cdot \\frac{1}{2b}\\exp(-\\Delta E/b) \\, d(\\Delta E)\n$$\n$$\nI_2 = \\frac{1}{2b} \\int_{0}^{\\infty} \\Delta E \\cdot \\exp\\left(-\\Delta E\\left(\\frac{1}{T_0} + \\frac{1}{b}\\right)\\right) \\, d(\\Delta E)\n$$\nLet the coefficient in the exponent be $\\alpha = \\frac{1}{T_0} + \\frac{1}{b} = \\frac{b+T_0}{bT_0}$.\n$$\nI_2 = \\frac{1}{2b} \\int_{0}^{\\infty} \\Delta E \\cdot \\exp(-\\alpha \\Delta E) \\, d(\\Delta E)\n$$\nWe use integration by parts again. Let $u = \\Delta E$ and $dv = \\exp(-\\alpha \\Delta E) \\, d(\\Delta E)$. Then $du = d(\\Delta E)$ and $v = -\\frac{1}{\\alpha}\\exp(-\\alpha \\Delta E)$.\n$$\nI_2 = \\frac{1}{2b} \\left( \\left[ -\\frac{\\Delta E}{\\alpha}\\exp(-\\alpha \\Delta E) \\right]_{0}^{\\infty} - \\int_{0}^{\\infty} \\left(-\\frac{1}{\\alpha}\\right)\\exp(-\\alpha \\Delta E) \\, d(\\Delta E) \\right)\n$$\nThe first term evaluates to $\\lim_{\\Delta E \\to \\infty}(-\\frac{\\Delta E}{\\alpha}\\exp(-\\alpha \\Delta E)) - (0) = 0 - 0 = 0$. The integral becomes:\n$$\nI_2 = \\frac{1}{2b} \\cdot \\frac{1}{\\alpha} \\int_{0}^{\\infty} \\exp(-\\alpha \\Delta E) \\, d(\\Delta E) = \\frac{1}{2b\\alpha} \\left[ -\\frac{1}{\\alpha}\\exp(-\\alpha \\Delta E) \\right]_{0}^{\\infty}\n$$\n$$\nI_2 = \\frac{1}{2b\\alpha^2} \\left( - \\lim_{\\Delta E \\to \\infty} \\exp(-\\alpha \\Delta E) - (-\\exp(0)) \\right) = \\frac{1}{2b\\alpha^2} (0 + 1) = \\frac{1}{2b\\alpha^2}\n$$\nSubstituting $\\alpha = \\frac{b+T_0}{bT_0}$:\n$$\nI_2 = \\frac{1}{2b} \\left( \\frac{bT_0}{b+T_0} \\right)^2 = \\frac{1}{2b} \\frac{b^2 T_0^2}{(b+T_0)^2} = \\frac{b T_0^2}{2(b+T_0)^2}\n$$\nThe total expected energy change is the sum of the two parts:\n$$\n\\mathbb{E}[\\Delta E_{\\text{step}}] = I_1 + I_2 = -\\frac{b}{2} + \\frac{b T_0^2}{2(b+T_0)^2}\n$$\nTo obtain a single fractional expression, we find a common denominator:\n$$\n\\mathbb{E}[\\Delta E_{\\text{step}}] = \\frac{-b(b+T_0)^2 + bT_0^2}{2(b+T_0)^2} = \\frac{b \\left( T_0^2 - (b+T_0)^2 \\right)}{2(b+T_0)^2}\n$$\n$$\n= \\frac{b \\left( T_0^2 - (b^2 + 2bT_0 + T_0^2) \\right)}{2(b+T_0)^2} = \\frac{b(-b^2 - 2bT_0)}{2(b+T_0)^2}\n$$\n$$\n= \\frac{-b^2(b+2T_0)}{2(b+T_0)^2}\n$$\nThis final expression quantifies the trade-off. As $T_0 \\to 0$, $\\mathbb{E}[\\Delta E_{\\text{step}}] \\to -\\frac{b^2(b)}{2b^2} = -b/2$, indicating rapid energy descent as only downhill moves are accepted. As $T_0 \\to \\infty$, $\\mathbb{E}[\\Delta E_{\\text{step}}] \\to 0$, since all moves are accepted, and the expected change equals the mean of the symmetric proposal distribution, which is $0$. A larger $T_0$ thus slows the expected descent rate, allowing for more exploration.", "answer": "$$\n\\boxed{-\\frac{b^2(b+2T_0)}{2(b+T_0)^2}}\n$$", "id": "3339546"}, {"introduction": "While a high temperature permits exploration, the ultimate goal of annealing is to cool the system into a global energy minimum. A cooling schedule, which defines the temperature $T_k$ at each iteration $k$, is therefore essential. This practice problem illustrates the critical danger of a poorly chosen schedule—specifically, one that cools too rapidly [@problem_id:3339511]. By analyzing a simplified energy barrier model, you will calculate the probability that the algorithm becomes 'quenched' in a local minimum, failing to find the true solution because the temperature drops before a key exploratory move can be accepted.", "problem": "Consider Simulated Annealing (SA) driven by the Metropolis acceptance rule within the framework of Markov Chain Monte Carlo (MCMC). At iteration $k$, the temperature is $T_k$, and an uphill proposal that raises the energy by $\\Delta E$ is accepted with probability $\\exp\\!\\big(-\\Delta E / T_k\\big)$. Construct a one-dimensional double-well energy landscape in which the system is initially trapped in a local minimum, and the only way to enter the basin of the global minimum is to accept at least one uphill move that increases the energy by exactly $D$. Assume that at each iteration $k$ the proposal mechanism independently attempts such a barrier-climbing move with probability $q$, and otherwise proposes moves that do not change basins. The temperature schedule is exponential, $T_k = T_0 \\alpha^k$ with $T_0 = 1$ and $\\alpha = \\tfrac{1}{2}$. Take $D = 5$, $q = 0.2$, and suppose the annealing is run for $N = 100$ iterations. Using only the SA foundations stated above, derive from first principles the exact expression for the probability of failing to cross the barrier by time $N$, and evaluate it numerically.\n\nRound your final numerical answer to six significant figures. The failure probability is dimensionless; do not include any units in your final answer.", "solution": "The problem statement is critically validated before proceeding to a solution.\n\n### Step 1: Extract Givens\n- **Algorithm**: Simulated Annealing (SA) using the Metropolis acceptance rule.\n- **System**: A one-dimensional double-well energy landscape.\n- **Initial State**: The system is trapped in a local minimum.\n- **Barrier Crossing Condition**: To enter the global minimum's basin, the system must accept at least one uphill move that increases the energy by exactly $\\Delta E = D$.\n- **Proposal Mechanism**: At each iteration $k$, a barrier-climbing move (uphill by $D$) is proposed with probability $q$. Other proposed moves do not lead to a change of basins. Proposals at each iteration are independent.\n- **Acceptance Probability**: An uphill proposal with energy increase $\\Delta E$ at temperature $T_k$ is accepted with probability $\\exp(-\\Delta E / T_k)$.\n- **Temperature Schedule**: $T_k = T_0 \\alpha^k$, an exponential cooling schedule.\n- **Parameters**:\n    - Energy barrier height: $D = 5$.\n    - Proposal probability for the barrier-climbing move: $q = 0.2$.\n    - Total number of iterations: $N = 100$.\n    - Initial temperature: $T_0 = 1$.\n    - Cooling factor: $\\alpha = \\frac{1}{2}$.\n- **Objective**: Derive the exact expression for the probability of failing to cross the barrier by time $N$, and evaluate it numerically, rounded to six significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed for validity:\n- **Scientifically Grounded**: The problem is based on the well-established principles of Simulated Annealing, Markov Chain Monte Carlo methods, and the Metropolis-Hastings algorithm. The use of a simplified double-well potential is a standard and valid theoretical construct for analyzing the behavior of such algorithms. All concepts are from mainstream computational physics and statistics.\n- **Well-Posed**: All necessary parameters ($D, q, N, T_0, \\alpha$) and functional forms (the cooling schedule, the acceptance probability) are explicitly provided. The objective is clearly defined: calculate a specific probability. The conditions are sufficient to derive a unique, meaningful solution.\n- **Objective**: The problem is stated in precise, quantitative, and unbiased language. It is free from subjective claims.\n\nThe problem does not exhibit any of the invalidity flags. It is scientifically sound, formally complete, and objective.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A solution will be derived from first principles as requested.\n\n### Derivation of the Solution\nThe objective is to find the probability that the system fails to transition from the local minimum to the basin of the global minimum within $N$ iterations. According to the problem statement, such a transition requires the acceptance of at least one specific uphill move of energy increase $D$. A failure to transition means that no such move is accepted in any of the $N$ iterations.\n\nLet the iterations be indexed by $k$, where $k$ runs from $0$ to $N-1$.\nAt any given iteration $k$, a successful barrier crossing can occur only if two independent events happen in sequence:\n1.  A barrier-climbing move with energy increase $D$ is proposed. The probability of this event is given as $p_{\\text{propose}} = q$.\n2.  This proposed move is accepted. The move is uphill with energy change $\\Delta E = D$. At temperature $T_k$, the Metropolis acceptance probability is $p_{\\text{accept}}(k) = \\exp\\left(-\\frac{\\Delta E}{T_k}\\right) = \\exp\\left(-\\frac{D}{T_k}\\right)$.\n\nThe temperature at iteration $k$ is given by the exponential cooling schedule $T_k = T_0 \\alpha^k$.\nSubstituting this into the acceptance probability gives:\n$$p_{\\text{accept}}(k) = \\exp\\left(-\\frac{D}{T_0 \\alpha^k}\\right)$$\n\nThe probability of a successful barrier crossing at iteration $k$, let's call it $P_k(\\text{cross})$, is the product of the probabilities of proposing the move and accepting it, as these are independent events:\n$$P_k(\\text{cross}) = p_{\\text{propose}} \\times p_{\\text{accept}}(k) = q \\exp\\left(-\\frac{D}{T_0 \\alpha^k}\\right)$$\n\nThe problem asks for the probability of *failing* to cross the barrier. This means that for every iteration $k$ from $0$ to $N-1$, the system does *not* cross the barrier. The probability of not crossing at a single iteration $k$ is the complement of crossing:\n$$P_k(\\text{not cross}) = 1 - P_k(\\text{cross}) = 1 - q \\exp\\left(-\\frac{D}{T_0 \\alpha^k}\\right)$$\n\nThe problem states that the proposal mechanism is independent at each iteration. Therefore, the event of failing to cross at one iteration is independent of the events at all other iterations. The total probability of failing to cross the barrier over all $N$ iterations, $P(\\text{failure})$, is the product of the probabilities of failing at each individual iteration:\n$$P(\\text{failure}) = \\prod_{k=0}^{N-1} P_k(\\text{not cross})$$\n\nSubstituting the expression for $P_k(\\text{not cross})$, we obtain the exact analytical expression for the failure probability:\n$$P(\\text{failure}) = \\prod_{k=0}^{N-1} \\left( 1 - q \\exp\\left(-\\frac{D}{T_0 \\alpha^k}\\right) \\right)$$\n\nThis is the required expression derived from first principles. Now, we must evaluate it numerically using the provided parameter values: $D=5$, $q=0.2$, $N=100$, $T_0=1$, and $\\alpha=\\frac{1}{2}$.\n\nSubstituting these values into the expression:\n$$P(\\text{failure}) = \\prod_{k=0}^{100-1} \\left( 1 - 0.2 \\cdot \\exp\\left(-\\frac{5}{1 \\cdot \\left(\\frac{1}{2}\\right)^k}\\right) \\right)$$\n$$P(\\text{failure}) = \\prod_{k=0}^{99} \\left( 1 - 0.2 \\cdot \\exp\\left(-5 \\cdot 2^k\\right) \\right)$$\n\nThis is a product of $100$ terms. Let's analyze the terms:\nFor $k=0$: term is $1 - 0.2 \\cdot \\exp(-5)$.\nFor $k=1$: term is $1 - 0.2 \\cdot \\exp(-10)$.\nFor $k=2$: term is $1 - 0.2 \\cdot \\exp(-20)$.\nAs $k$ increases, the exponent $-5 \\cdot 2^k$ becomes very large and negative. The term $\\exp(-5 \\cdot 2^k)$ approaches $0$ extremely rapidly. Consequently, the factors in the product approach $1$ very quickly, and the value of the product converges after only a few terms.\n\nThe numerical evaluation of this product yields:\n$$P(\\text{failure}) = (1 - 0.2 \\cdot \\exp(-5)) \\times (1 - 0.2 \\cdot \\exp(-10)) \\times (1 - 0.2 \\cdot \\exp(-20)) \\times \\dots$$\n$$P(\\text{failure}) \\approx (0.99865241) \\times (0.99999092) \\times (0.9999999996) \\times \\dots$$\n$$P(\\text{failure}) \\approx 0.998643339274...$$\n\nRounding this result to six significant figures, we get $0.998643$.", "answer": "$$\\boxed{0.998643}$$", "id": "3339511"}, {"introduction": "As the previous exercises demonstrate, a fixed, pre-determined cooling schedule can be both critical and fragile. A more robust and modern approach is to devise an *adaptive* schedule that adjusts the temperature based on the algorithm's observed performance. This hands-on coding exercise guides you through the implementation of such a controller based on the Robbins-Monro algorithm, a classic method from stochastic approximation theory [@problem_id:3339494]. Your task is to dynamically steer the algorithm's acceptance rate towards a desired target, providing a practical lesson in how control theory can make optimization algorithms more intelligent and effective.", "problem": "You are asked to design and implement a stochastic approximation controller for the temperature in a simulated annealing Markov chain such that the empirical acceptance rate is steered toward a user-specified target. The adaptation is defined by the Robbins–Monro update\n$$\nT_{k+1} \\;=\\; T_k \\;+\\; \\gamma_k \\,\\big( A^\\ast - \\hat{A}_k \\big),\n$$\nwhere $T_k$ is the temperature after batch $k$, $A^\\ast$ is the target acceptance rate, $\\hat{A}_k$ is the empirical acceptance rate observed in batch $k$ of the Markov chain moves, and $\\gamma_k$ is a step size. The goal is to analyze the impact of the step-size sequence $\\{\\gamma_k\\}$ on stability and accuracy in steering the empirical acceptance rate towards the target.\n\nYour program must implement the following components from first principles:\n- A Metropolis–Hastings Markov chain with proposal $y = x + \\varepsilon$, where $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$ is a Gaussian increment with variance $\\sigma^2$. The energy is $E(x) = \\tfrac{1}{2} x^2$, and the acceptance probability at temperature $T$ is\n$$\n\\alpha(x,y;T) \\;=\\; \\min\\!\\left(1, \\exp\\!\\left( -\\frac{E(y) - E(x)}{T} \\right)\\right).\n$$\n- An empirical acceptance rate estimator $\\hat{A}_k$ computed over a batch of $M$ proposals at fixed temperature $T_k$.\n- The Robbins–Monro temperature update $T_{k+1} = T_k + \\gamma_k (A^\\ast - \\hat{A}_k)$ with positivity enforced as $T_{k+1} \\leftarrow \\max(T_{\\min}, T_{k+1})$ for a small floor $T_{\\min} > 0$.\n\nFundamental base for derivation and analysis:\n- Metropolis–Hastings acceptance probability and the definition of simulated annealing temperature.\n- Robbins–Monro stochastic approximation for solving for a root of a function in noise, together with classical step-size conditions such as $\\sum_{k=0}^\\infty \\gamma_k = \\infty$ and $\\sum_{k=0}^\\infty \\gamma_k^2  \\infty$.\n- Monotonicity of expected acceptance as a function of $T$ under symmetric proposals for log-concave targets, which implies a unique temperature solving $A(T) = A^\\ast$ for a feasible $A^\\ast \\in (0,1)$.\n\nImplementation details to ensure reproducibility and universal applicability:\n- Use dimension $d = 1$ with $E(x) = \\tfrac{1}{2}x^2$ and proposal variance $\\sigma^2 = 1$. Initialize at $x_0 = 0$ and $T_0 = 2$.\n- Use batches of size $M = 30$ Metropolis–Hastings proposals per batch.\n- Run $K = 2500$ batches for each test case.\n- Use the target acceptance $A^\\ast = 0.4$.\n- Use a fixed pseudo-random seed equal to $12345$.\n- Enforce a minimal temperature of $T_{\\min} = 10^{-8}$ in the update to maintain positivity.\n- For assessing stability and accuracy, compute over the last $L = 300$ batches:\n  1. The mean acceptance $\\overline{A}_{\\text{last}}$ as the mean of the last $L$ empirical acceptance rates.\n  2. The standard deviation $\\mathrm{sd}(T)$ of the temperatures over the last $L$ batches.\n  3. The minimum and maximum temperatures $T_{\\min,\\text{obs}}$ and $T_{\\max,\\text{obs}}$ over all $K$ batches.\n- Declare a test case to be “stable and accurate” if all the following hold:\n  1. $|\\overline{A}_{\\text{last}} - A^\\ast| \\le 0.05$,\n  2. $\\mathrm{sd}(T) \\le 0.5$,\n  3. $T_{\\min,\\text{obs}} \\ge 10^{-8}$ and $T_{\\max,\\text{obs}} \\le 10$.\n- Use a family of step sizes of the form $\\gamma_k = c/(k+1)^\\alpha$ for parameters $(\\alpha,c)$. The special case $\\alpha = 0$ denotes a constant step size $\\gamma_k \\equiv c$.\n\nTest suite:\n- Case $1$: $(\\alpha, c) = (1.0, 1.5)$.\n- Case $2$: $(\\alpha, c) = (0.6, 0.7)$.\n- Case $3$: $(\\alpha, c) = (0.49, 0.7)$.\n- Case $4$: $(\\alpha, c) = (1.2, 0.1)$.\n- Case $5$: $(\\alpha, c) = (0.0, 0.05)$.\n\nYour program must, for each test case, run the adaptive simulated annealing procedure described above, evaluate the three criteria, and return a boolean indicating whether the case is “stable and accurate.” Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[ \\text{True}, \\text{False}, \\dots ]$). No additional output is permitted.\n\nAngle units are not applicable. No physical units are involved. All numerical outputs must be dimensionless real numbers or booleans as specified.", "solution": "The problem is valid. It presents a well-posed and scientifically grounded task in the domain of adaptive Monte Carlo methods. All parameters, conditions, and objectives are specified with sufficient precision to permit a unique and reproducible solution. The task is to implement an adaptive simulated annealing algorithm where the temperature is dynamically adjusted to maintain a target acceptance rate, and to analyze its performance under different parameterizations of the adaptation step size.\n\nThe solution is constructed by integrating three core components: a Metropolis-Hastings sampler for a specified energy function, a Robbins-Monro stochastic approximation controller for the temperature, and a systematic evaluation procedure based on defined criteria for stability and accuracy.\n\n1.  **Metropolis-Hastings Sampler**\n\nThe foundation of the simulation is a Metropolis-Hastings (MH) Markov chain designed to sample from a target probability distribution. The target distribution's density is proportional to $\\exp(-E(x)/T)$, where $E(x)$ is the energy function and $T$ is the temperature. For this problem, the energy function is given for a one-dimensional state $x \\in \\mathbb{R}$ as\n$$\nE(x) = \\frac{1}{2}x^2.\n$$\nThis energy function corresponds to a target distribution that is a Gaussian with mean $0$ and variance $T$.\n\nThe MH algorithm proceeds via a proposal-acceptance mechanism.\n- **Proposal Generation**: A new state $y$ is proposed from the current state $x$ using a symmetric proposal distribution. Specifically, the proposal is $y = x + \\varepsilon$, where the increment $\\varepsilon$ is drawn from a normal distribution with mean $0$ and variance $\\sigma^2$. The problem specifies $\\sigma^2 = 1$.\n- **Acceptance Probability**: The proposed state $y$ is accepted with probability $\\alpha(x, y; T)$, defined as\n$$\n\\alpha(x,y;T) = \\min\\!\\left(1, \\exp\\!\\left( -\\frac{E(y) - E(x)}{T} \\right)\\right).\n$$\nIf the proposal is accepted, the new state of the chain becomes $y$; otherwise, the state remains $x$. The symmetry of the proposal distribution $\\mathcal{N}(0, \\sigma^2)$ simplifies the acceptance ratio, as the Hastings term is equal to $1$.\n\n2.  **Robbins-Monro Temperature Controller**\n\nThe goal is not to sample at a fixed temperature, but to adapt the temperature $T$ such that the long-term average acceptance rate of the MH sampler approaches a specified target value, $A^\\ast = 0.4$. This is a stochastic root-finding problem: we seek the temperature $T$ that solves the equation $A(T) - A^\\ast = 0$, where $A(T)$ is the expected acceptance rate at temperature $T$. Since we can only observe noisy estimates of $A(T)$—the empirical acceptance rates $\\hat{A}_k$ from finite batches—we use the Robbins-Monro (RM) stochastic approximation algorithm.\n\nThe RM update rule for the temperature after batch $k$ is given by:\n$$\nT_{k+1} = T_k + \\gamma_k (A^\\ast - \\hat{A}_k).\n$$\nHere, $T_k$ is the temperature used for batch $k$, $\\hat{A}_k$ is the empirical acceptance rate observed during that batch (computed over $M=30$ MH steps), and $\\gamma_k$ is a positive step-size parameter. The logic of the update is intuitive: if the observed acceptance rate $\\hat{A}_k$ is higher than the target $A^\\ast$, the term $(A^\\ast - \\hat{A}_k)$ is negative, and the temperature is decreased. This makes proposals less likely to be accepted, reducing the acceptance rate. Conversely, if $\\hat{A}_k  A^\\ast$, the temperature is increased. To ensure the temperature remains physically meaningful (i.e., positive), the updated value is floored at a small positive constant $T_{\\min} = 10^{-8}$.\n\n3.  **Step-Size Sequence Analysis**\n\nThe behavior of the RM algorithm is critically dependent on the choice of the step-size sequence $\\{\\gamma_k\\}$. The problem specifies a family of sequences of the form $\\gamma_k = c/(k+1)^\\alpha$, where $k$ is the batch index starting from $0$. The classical convergence conditions for RM are:\n$$\n\\sum_{k=0}^\\infty \\gamma_k = \\infty \\quad \\text{and} \\quad \\sum_{k=0}^\\infty \\gamma_k^2  \\infty.\n$$\n- The first condition, the \"infinite sum\" condition, ensures that the algorithm has enough \"energy\" to escape any initial state and reach the target. For our chosen form, this condition is met if and only if $\\alpha \\le 1$.\n- The second condition, the \"square-summable\" condition, ensures that the step sizes diminish quickly enough to average out the noise from the empirical estimates $\\hat{A}_k$, leading to convergence. This condition is met if and only if $\\alpha > 0.5$.\n\nThe test cases are designed to probe the practical consequences of satisfying or violating these conditions:\n- **Case 1**: $(\\alpha,c) = (1.0, 1.5)$. Here, $\\alpha=1.0$ satisfies both conditions (marginally for the first). Convergence is expected, although it may be slow.\n- **Case 2**: $(\\alpha,c) = (0.6, 0.7)$. Here, $0.5  \\alpha \\le 1$, satisfying both conditions robustly. This is a theoretically ideal range, so good performance is expected.\n- **Case 3**: $(\\alpha,c) = (0.49, 0.7)$. Here, $\\alpha  0.5$, violating the square-summable condition. The step sizes do not decay fast enough, so the temperature is expected to exhibit persistent, high-amplitude oscillations, failing the stability criterion $\\mathrm{sd}(T) \\le 0.5$.\n- **Case 4**: $(\\alpha,c) = (1.2, 0.1)$. Here, $\\alpha > 1$, violating the infinite sum condition. The step sizes may decay too rapidly, preventing the temperature from fully converging to the correct value if the initial temperature $T_0=2$ is far from the target. This can result in a systematic bias, failing the accuracy criterion $|\\overline{A}_{\\text{last}} - A^\\ast| \\le 0.05$.\n- **Case 5**: $(\\alpha,c) = (0.0, 0.05)$. This corresponds to a constant step size $\\gamma_k=0.05$, which violates the square-summable condition. The temperature will not converge to a point but will instead wander in a stationary distribution around the target, leading to a non-vanishing standard deviation. This would likely fail the stability criterion $\\mathrm{sd}(T) \\le 0.5$.\n\n4.  **Simulation and Evaluation Protocol**\n\nFor each test case defined by a pair $(\\alpha, c)$, a single simulation run is performed for $K=2500$ batches. The simulation is initialized with $x_0 = 0$, $T_0 = 2$, and a fixed pseudo-random seed of $12345$ for reproducibility.\n\nAfter each run, the stored histories of temperatures and empirical acceptance rates are used to evaluate performance against three specific criteria:\n1.  **Accuracy**: The mean of the empirical acceptance rates over the final $L=300$ batches, $\\overline{A}_{\\text{last}}$, must be close to the target: $|\\overline{A}_{\\text{last}} - A^\\ast| \\le 0.05$.\n2.  **Stability**: The standard deviation of the temperature values over the final $L=300$ batches, $\\mathrm{sd}(T)$, must be small: $\\mathrm{sd}(T) \\le 0.5$.\n3.  **Bounds**: The temperature must remain within a reasonable range throughout the entire simulation of $K$ batches: $T_{\\min,\\text{obs}} \\ge 10^{-8}$ and $T_{\\max,\\text{obs}} \\le 10$.\n\nA test case is deemed \"stable and accurate\" if and only if all three of these conditions are met. The final output is a boolean list indicating the outcome for each case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the adaptive simulated annealing simulations for all test cases.\n    \"\"\"\n    # Global parameters defined in the problem statement.\n    D_DIM = 1\n    SIGMA_SQ = 1.0\n    SIGMA = np.sqrt(SIGMA_SQ)\n    X0 = 0.0\n    T0 = 2.0\n    M_BATCH_SIZE = 30\n    K_NUM_BATCHES = 2500\n    L_LAST_BATCHES = 300\n    A_STAR = 0.4\n    T_MIN = 1e-8\n    SEED = 12345\n\n    # Test cases: (alpha, c) parameters for the step size gamma_k = c / (k+1)^alpha.\n    test_cases = [\n        (1.0, 1.5),  # Case 1\n        (0.6, 0.7),  # Case 2\n        (0.49, 0.7), # Case 3\n        (1.2, 0.1),  # Case 4\n        (0.0, 0.05)   # Case 5\n    ]\n\n    results = []\n\n    # Iterate through each test case.\n    for alpha, c in test_cases:\n        # Re-initialize the random number generator for each case to ensure reproducibility.\n        rng = np.random.default_rng(SEED)\n        \n        # Initialize state variables for the simulation.\n        x_current = X0\n        t_current = T0\n        \n        # Arrays to store the history of temperatures and acceptance rates.\n        temp_history = np.zeros(K_NUM_BATCHES)\n        acceptance_rate_history = np.zeros(K_NUM_BATCHES)\n        \n        # Main simulation loop over K batches.\n        for k in range(K_NUM_BATCHES):\n            # Record the temperature for the current batch.\n            temp_history[k] = t_current\n\n            accept_count = 0\n            # Inner loop for M Metropolis-Hastings proposals within a batch.\n            for _ in range(M_BATCH_SIZE):\n                # 1. Propose a new state y from the current state x.\n                # Proposal is y = x + epsilon, where epsilon ~ N(0, sigma^2).\n                epsilon = rng.normal(loc=0.0, scale=SIGMA)\n                y_proposal = x_current + epsilon\n                \n                # 2. Calculate the change in energy E(x) = 0.5 * x^2.\n                e_current = 0.5 * x_current**2\n                e_proposal = 0.5 * y_proposal**2\n                delta_e = e_proposal - e_current\n                \n                # 3. Calculate the acceptance probability.\n                # alpha(x,y;T) = min(1, exp(-delta_E / T))\n                if delta_e  0:\n                    acceptance_prob = 1.0\n                else:\n                    # Avoid division by zero, though t_current is floored at T_MIN  0.\n                    acceptance_prob = np.exp(-delta_e / t_current)\n                \n                # 4. Accept or reject the proposal.\n                if rng.uniform(0.0, 1.0)  acceptance_prob:\n                    x_current = y_proposal\n                    accept_count += 1\n            \n            # --- End of Batch ---\n            # Calculate the empirical acceptance rate for the batch.\n            a_hat_k = accept_count / M_BATCH_SIZE\n            acceptance_rate_history[k] = a_hat_k\n            \n            # Calculate the step size gamma_k.\n            gamma_k = c / ((k + 1)**alpha)\n            \n            # Update the temperature using the Robbins-Monro rule.\n            t_next = t_current + gamma_k * (A_STAR - a_hat_k)\n            \n            # Enforce the positivity constraint (temperature floor).\n            t_next = max(T_MIN, t_next)\n            \n            # Set the temperature for the next batch.\n            t_current = t_next\n            \n        # --- Post-Simulation Analysis for the current test case ---\n        \n        # 1. Mean acceptance rate over the last L batches.\n        a_last_mean = np.mean(acceptance_rate_history[-L_LAST_BATCHES:])\n        \n        # 2. Standard deviation of the temperature over the last L batches.\n        t_last_std = np.std(temp_history[-L_LAST_BATCHES:])\n        \n        # 3. Minimum and maximum observed temperatures over all K batches.\n        t_min_obs = np.min(temp_history)\n        t_max_obs = np.max(temp_history)\n        \n        # Evaluate the \"stable and accurate\" criteria.\n        cond1 = np.abs(a_last_mean - A_STAR) = 0.05\n        cond2 = t_last_std = 0.5\n        cond3 = (t_min_obs = T_MIN) and (t_max_obs = 10.0)\n        \n        # The result for the case is True if all conditions are met.\n        is_stable_and_accurate = cond1 and cond2 and cond3\n        results.append(str(is_stable_and_accurate))\n\n    # Print the final list of results in the required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3339494"}]}