{"hands_on_practices": [{"introduction": "To design effective particle filters, it is crucial to understand the sources of statistical error. This exercise provides a foundational analysis by deriving the variance of the auxiliary particle filter (APF) estimator for the normalizing constant. By decomposing the variance into components arising from the ancestor resampling and the state proposal steps, you will gain insight into how design choices influence filter performance and discover the theoretical conditions for a zero-variance, or \"optimal,\" filter [@problem_id:3290186].", "problem": "Consider a Feynman–Kac model specified by a Markov transition kernel $M_t(x_{t-1}, \\mathrm{d}x_t)$ that admits a density $\\ell_k(x) := \\ell(x \\mid x_{t-1}^k)$ with respect to a common reference measure, and a nonnegative potential function $G_t(x)$. At time $t-1$, assume a fixed weighted particle approximation $\\{x_{t-1}^k, \\bar{w}_{t-1}^k\\}_{k=1}^N$ with $\\sum_{k=1}^N \\bar{w}_{t-1}^k = 1$. Define the incremental normalizing constant\n$$\nc_t \\;=\\; \\sum_{k=1}^N \\bar{w}_{t-1}^k \\int G_t(x)\\,\\ell_k(x)\\,\\mathrm{d}x.\n$$\nAn Auxiliary Particle Filter (APF) uses adjustment multipliers $\\nu_k  0$ to define ancestor selection probabilities\n$$\n\\pi_k \\;=\\; \\frac{\\bar{w}_{t-1}^k \\,\\nu_k}{\\sum_{j=1}^N \\bar{w}_{t-1}^j \\,\\nu_j}, \n\\qquad \nC \\;:=\\; \\sum_{j=1}^N \\bar{w}_{t-1}^j \\,\\nu_j,\n$$\nand, conditional on selecting ancestor index $K=k$, a proposal $q_k(\\mathrm{d}x)$ for $x_t$. The single-sample APF importance contribution is\n$$\nH_k(x) \\;:=\\; C \\,\\frac{G_t(x)\\,\\ell_k(x)}{\\nu_k\\,q_k(x)}.\n$$\nLet $\\{(K_i, X_i)\\}_{i=1}^N$ be generated by an unbiased resampling scheme $\\mathcal{R}$ for the ancestor indices with expected counts $\\mathbb{E}[N_k]=N\\pi_k$, where $N_k := \\sum_{i=1}^N \\mathbf{1}\\{K_i=k\\}$, followed by conditionally independent proposals $X_i \\sim q_{K_i}$. The APF estimator of $c_t$ is\n$$\n\\hat{c}_t \\;=\\; \\frac{1}{N}\\sum_{i=1}^N H_{K_i}(X_i).\n$$\n\nStarting from the definitions of importance sampling and the law of total variance, derive the conditional variance of $\\hat{c}_t$ given $\\{x_{t-1}^k, \\bar{w}_{t-1}^k\\}_{k=1}^N$ in the following form:\n- Express it in terms of the vector of per-ancestor conditional means $\\boldsymbol{\\mathfrak{m}} \\in \\mathbb{R}^N$ with entries $\\mathfrak{m}_k := \\mathbb{E}_{q_k}[H_k(X)]$, the per-ancestor conditional variances $v_k := \\mathrm{Var}_{q_k}[H_k(X)]$, and the covariance matrix of the ancestor count vector $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N})$ induced by the resampling scheme $\\mathcal{R}$.\n- Then specialize your expression by substituting the explicit $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N})$ for the following two schemes:\n  1. Multinomial resampling, for which $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) = N\\big(\\mathrm{Diag}(\\boldsymbol{\\pi}) - \\boldsymbol{\\pi}\\boldsymbol{\\pi}^{\\top}\\big)$.\n  2. Residual resampling, where $a_k := \\lfloor N\\pi_k \\rfloor$, $R := N - \\sum_{k=1}^N a_k$, $r_k := \\frac{N\\pi_k - a_k}{R}$ (for $R0$), and $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) = R\\big(\\mathrm{Diag}(\\mathbf{r}) - \\mathbf{r}\\mathbf{r}^{\\top}\\big)$ with the convention $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N})=\\mathbf{0}$ if $R=0$.\n\nFinally, using only the definitions above, identify conditions on the proposals $q_k$ and adjustment multipliers $\\nu_k$ under which this conditional variance is minimized, and state the minimal value. Your final answer must be a single closed-form analytic expression for the conditional variance in terms of $\\boldsymbol{\\pi}$, $\\{v_k\\}$, $\\boldsymbol{\\mathfrak{m}}$, and $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N})$. Do not include units. If you introduce any additional symbols, define them explicitly in your derivation. Your final answer must be an analytic expression, not an inequality or an equation with unspecified terms.", "solution": "The problem requires the derivation of the conditional variance of the Auxiliary Particle Filter (APF) estimator $\\hat{c}_t$ for the incremental normalizing constant $c_t$, given the state of the system at time $t-1$, which is encapsulated by the particle set $\\{x_{t-1}^k, \\bar{w}_{t-1}^k\\}_{k=1}^N$. All expectations, variances, and covariances derived henceforth are conditional on this information.\n\nFirst, we establish the necessary definitions from the problem statement. The estimator for $c_t$ is given by\n$$\n\\hat{c}_t = \\frac{1}{N}\\sum_{i=1}^N H_{K_i}(X_i)\n$$\nwhere $\\{K_i\\}_{i=1}^N$ are the ancestor indices drawn via a resampling scheme $\\mathcal{R}$, and $X_i \\sim q_{K_i}$ are the proposed states. The randomness in $\\hat{c}_t$ arises from two sources: the random selection of ancestor indices $\\{K_i\\}$, and the random generation of the states $\\{X_i\\}$.\n\nTo analyze the variance, it is convenient to rewrite the estimator in terms of the ancestor count vector $\\mathbf{N} = (N_1, \\dots, N_N)^\\top$, where $N_k = \\sum_{i=1}^N \\mathbf{1}\\{K_i=k\\}$ is the number of times ancestor $k$ is chosen. The estimator becomes\n$$\n\\hat{c}_t = \\frac{1}{N} \\sum_{k=1}^N \\sum_{j=1}^{N_k} Y_j^{(k)}\n$$\nwhere each $Y_j^{(k)}$ is an independent draw of the random variable defined by $H_k(X)$ with $X \\sim q_k(\\cdot)$. The distribution of $Y_j^{(k)}$ depends only on the ancestor index $k$.\n\nWe apply the law of total variance, conditioning on the random count vector $\\mathbf{N}$:\n$$\n\\mathrm{Var}(\\hat{c}_t) = \\mathbb{E}_{\\mathbf{N}}[\\mathrm{Var}(\\hat{c}_t \\mid \\mathbf{N})] + \\mathrm{Var}_{\\mathbf{N}}(\\mathbb{E}[\\hat{c}_t \\mid \\mathbf{N}])\n$$\n\nLet's compute the two terms on the right-hand side.\n\n1.  **Inner Conditional Expectation and its Variance:**\n    We first compute the expectation of $\\hat{c}_t$ conditional on a realization of the count vector $\\mathbf{N}$.\n    $$\n    \\mathbb{E}[\\hat{c}_t \\mid \\mathbf{N}] = \\mathbb{E}\\left[ \\frac{1}{N} \\sum_{k=1}^N \\sum_{j=1}^{N_k} Y_j^{(k)} \\;\\Bigg|\\; \\mathbf{N} \\right]\n    $$\n    By linearity of expectation and since the draws $Y_j^{(k)}$ are independent given $\\mathbf{N}$,\n    $$\n    \\mathbb{E}[\\hat{c}_t \\mid \\mathbf{N}] = \\frac{1}{N} \\sum_{k=1}^N N_k \\, \\mathbb{E}[Y_j^{(k)}]\n    $$\n    The problem defines $\\mathfrak{m}_k := \\mathbb{E}_{q_k}[H_k(X)]$ as the per-ancestor conditional mean. Thus, $\\mathbb{E}[Y_j^{(k)}] = \\mathfrak{m}_k$.\n    $$\n    \\mathbb{E}[\\hat{c}_t \\mid \\mathbf{N}] = \\frac{1}{N} \\sum_{k=1}^N N_k \\mathfrak{m}_k = \\frac{1}{N} \\mathbf{N}^\\top \\boldsymbol{\\mathfrak{m}}\n    $$\n    where $\\boldsymbol{\\mathfrak{m}}$ is the column vector with entries $\\mathfrak{m}_k$. The second term of the law of total variance is the variance of this quantity with respect to the distribution of $\\mathbf{N}$ induced by the resampling scheme $\\mathcal{R}$:\n    $$\n    \\mathrm{Var}_{\\mathbf{N}}(\\mathbb{E}[\\hat{c}_t \\mid \\mathbf{N}]) = \\mathrm{Var}_{\\mathbf{N}}\\left( \\frac{1}{N} \\boldsymbol{\\mathfrak{m}}^\\top \\mathbf{N} \\right) = \\frac{1}{N^2} \\mathrm{Var}_{\\mathbf{N}}(\\boldsymbol{\\mathfrak{m}}^\\top \\mathbf{N})\n    $$\n    Using the general formula for the variance of a linear combination of a random vector, $\\mathrm{Var}(\\mathbf{A}^\\top \\mathbf{X}) = \\mathbf{A}^\\top \\mathrm{Cov}(\\mathbf{X}) \\mathbf{A}$, we get:\n    $$\n    \\mathrm{Var}_{\\mathbf{N}}(\\mathbb{E}[\\hat{c}_t \\mid \\mathbf{N}]) = \\frac{1}{N^2} \\boldsymbol{\\mathfrak{m}}^\\top \\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) \\boldsymbol{\\mathfrak{m}}\n    $$\n\n2.  **Inner Conditional Variance and its Expectation:**\n    Next, we compute the variance of $\\hat{c}_t$ conditional on $\\mathbf{N}$.\n    $$\n    \\mathrm{Var}(\\hat{c}_t \\mid \\mathbf{N}) = \\mathrm{Var}\\left( \\frac{1}{N} \\sum_{k=1}^N \\sum_{j=1}^{N_k} Y_j^{(k)} \\;\\Bigg|\\; \\mathbf{N} \\right)\n    $$\n    Given $\\mathbf{N}$, the terms for different $k$ are independent, and for a fixed $k$, the terms $Y_j^{(k)}$ are i.i.d.\n    $$\n    \\mathrm{Var}(\\hat{c}_t \\mid \\mathbf{N}) = \\frac{1}{N^2} \\sum_{k=1}^N \\mathrm{Var}\\left( \\sum_{j=1}^{N_k} Y_j^{(k)} \\right) = \\frac{1}{N^2} \\sum_{k=1}^N N_k \\mathrm{Var}(Y_j^{(k)})\n    $$\n    The problem defines $v_k := \\mathrm{Var}_{q_k}[H_k(X)]$ as the per-ancestor conditional variance. Thus, $\\mathrm{Var}(Y_j^{(k)}) = v_k$.\n    $$\n    \\mathrm{Var}(\\hat{c}_t \\mid \\mathbf{N}) = \\frac{1}{N^2} \\sum_{k=1}^N N_k v_k\n    $$\n    The first term of the law of total variance is the expectation of this quantity:\n    $$\n    \\mathbb{E}_{\\mathbf{N}}[\\mathrm{Var}(\\hat{c}_t \\mid \\mathbf{N})] = \\mathbb{E}_{\\mathbf{N}}\\left[ \\frac{1}{N^2} \\sum_{k=1}^N N_k v_k \\right] = \\frac{1}{N^2} \\sum_{k=1}^N \\mathbb{E}[N_k] v_k\n    $$\n    We are given that the resampling scheme is unbiased, meaning $\\mathbb{E}[N_k] = N \\pi_k$.\n    $$\n    \\mathbb{E}_{\\mathbf{N}}[\\mathrm{Var}(\\hat{c}_t \\mid \\mathbf{N})] = \\frac{1}{N^2} \\sum_{k=1}^N (N \\pi_k) v_k = \\frac{1}{N} \\sum_{k=1}^N \\pi_k v_k\n    $$\n\n**General Variance Expression:**\nCombining the two terms, we obtain the general expression for the conditional variance of $\\hat{c}_t$:\n$$\n\\mathrm{Var}(\\hat{c}_t) = \\frac{1}{N} \\sum_{k=1}^N \\pi_k v_k + \\frac{1}{N^2} \\boldsymbol{\\mathfrak{m}}^\\top \\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) \\boldsymbol{\\mathfrak{m}}\n$$\n\n**Specialization for Resampling Schemes:**\n\n1.  **Multinomial Resampling:**\n    The covariance matrix is given as $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) = N\\big(\\mathrm{Diag}(\\boldsymbol{\\pi}) - \\boldsymbol{\\pi}\\boldsymbol{\\pi}^{\\top}\\big)$. Substituting this into the general formula:\n    $$\n    \\boldsymbol{\\mathfrak{m}}^\\top \\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) \\boldsymbol{\\mathfrak{m}} = N \\boldsymbol{\\mathfrak{m}}^\\top (\\mathrm{Diag}(\\boldsymbol{\\pi}) - \\boldsymbol{\\pi}\\boldsymbol{\\pi}^{\\top}) \\boldsymbol{\\mathfrak{m}} = N \\left( \\sum_{k=1}^N \\pi_k \\mathfrak{m}_k^2 - \\left(\\sum_{k=1}^N \\pi_k \\mathfrak{m}_k\\right)^2 \\right)\n    $$\n    The total variance is:\n    $$\n    \\mathrm{Var}(\\hat{c}_t) = \\frac{1}{N}\\sum_k \\pi_k v_k + \\frac{N}{N^2}\\left(\\sum_k \\pi_k \\mathfrak{m}_k^2 - \\left(\\sum_k \\pi_k \\mathfrak{m}_k\\right)^2\\right) = \\frac{1}{N} \\left( \\sum_k \\pi_k (v_k + \\mathfrak{m}_k^2) - \\left(\\sum_k \\pi_k \\mathfrak{m}_k\\right)^2 \\right)\n    $$\n    Since $v_k + \\mathfrak{m}_k^2 = \\mathbb{E}_{q_k}[H_k(X)^2]$, this simplifies to the variance of a sample mean from an i.i.d. population, as expected for multinomial sampling.\n\n2.  **Residual Resampling:**\n    The covariance matrix is $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) = R\\big(\\mathrm{Diag}(\\mathbf{r}) - \\mathbf{r}\\mathbf{r}^{\\top}\\big)$ for $R  0$ and $\\mathbf{0}$ for $R=0$.\n    If $R=0$, the counts $N_k$ are deterministic, so $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N})=\\mathbf{0}$ and the variance is $\\mathrm{Var}(\\hat{c}_t) = \\frac{1}{N} \\sum_{k=1}^N \\pi_k v_k$.\n    If $R0$, the variance is:\n    $$\n    \\mathrm{Var}(\\hat{c}_t) = \\frac{1}{N} \\sum_{k=1}^N \\pi_k v_k + \\frac{R}{N^2} \\boldsymbol{\\mathfrak{m}}^\\top (\\mathrm{Diag}(\\mathbf{r}) - \\mathbf{r}\\mathbf{r}^{\\top}) \\boldsymbol{\\mathfrak{m}}\n    $$\n    $$\n    \\mathrm{Var}(\\hat{c}_t) = \\frac{1}{N} \\sum_{k=1}^N \\pi_k v_k + \\frac{R}{N^2} \\left( \\sum_{k=1}^N r_k \\mathfrak{m}_k^2 - \\left(\\sum_{k=1}^N r_k \\mathfrak{m}_k\\right)^2 \\right)\n    $$\n\n**Variance Minimization:**\nThe variance is a sum of non-negative terms. It is minimized when both terms are zero.\nThe first term, $\\frac{1}{N} \\sum_{k=1}^N \\pi_k v_k$, is zero if and only if $v_k = 0$ for all $k$ such that $\\pi_k  0$. The variance $v_k = \\mathrm{Var}_{q_k}[H_k(X)]$ is zero if and only if the random variable $H_k(X)$ is a constant for all $X$ in the support of $q_k(x)$.\n$$\nH_k(x) = C \\frac{G_t(x)\\,\\ell_k(x)}{\\nu_k\\,q_k(x)} = \\text{constant (w.r.t. } x)\n$$\nThis condition is satisfied by choosing the proposal density $q_k(x)$ to be proportional to $G_t(x)\\ell_k(x)$. The normalized optimal proposal is:\n$$\nq_k^{\\text{opt}}(x) = \\frac{G_t(x)\\ell_k(x)}{\\int G_t(y)\\ell_k(y)\\,\\mathrm{d}y}\n$$\nUnder this choice, $v_k=0$ for all $k$.\n\nThe variance then reduces to the second term: $\\frac{1}{N^2} \\boldsymbol{\\mathfrak{m}}^\\top \\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) \\boldsymbol{\\mathfrak{m}}$. This term is zero if $\\boldsymbol{\\mathfrak{m}}$ is in the null space of $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N})$. For resampling schemes, the total count $\\sum_k N_k = N$ is fixed, which implies $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) \\mathbf{1} = \\mathbf{0}$, where $\\mathbf{1}$ is the vector of ones. Thus, if we can make $\\boldsymbol{\\mathfrak{m}}$ a constant vector, i.e., $\\mathfrak{m}_k$ is independent of $k$, the second term will vanish.\nLet's examine $\\mathfrak{m}_k$ under the optimal proposal $q_k=q_k^{\\text{opt}}$:\n$$\n\\mathfrak{m}_k = \\mathbb{E}_{q_k^{\\text{opt}}}[H_k(X)] = C \\frac{\\int G_t(y)\\ell_k(y)\\,\\mathrm{d}y}{\\nu_k}\n$$\nTo make $\\mathfrak{m}_k$ independent of $k$, we must choose $\\nu_k$ to be proportional to $\\int G_t(y)\\ell_k(y)\\,\\mathrm{d}y$. Let's set $\\nu_k = \\int G_t(y)\\ell_k(y)\\,\\mathrm{d}y$. With this choice:\n$$\n\\mathfrak{m}_k = C = \\sum_{j=1}^N \\bar{w}_{t-1}^j \\nu_j = \\sum_{j=1}^N \\bar{w}_{t-1}^j \\int G_t(y)\\ell_j(y)\\,\\mathrm{d}y = c_t\n$$\nSo $\\mathfrak{m}_k = c_t$ for all $k$. The vector $\\boldsymbol{\\mathfrak{m}}$ is $c_t \\mathbf{1}$, and $\\boldsymbol{\\mathfrak{m}}^\\top \\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) \\boldsymbol{\\mathfrak{m}} = c_t^2 \\mathbf{1}^\\top \\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) \\mathbf{1} = 0$.\n\nTherefore, the conditional variance is minimized and equals $0$ under the following conditions:\n1.  Proposals: $q_k(x) \\propto G_t(x)\\ell_k(x)$ for each $k$.\n2.  Adjustment multipliers: $\\nu_k \\propto \\int G_t(x)\\ell_k(x)\\,\\mathrm{d}x$ for each $k$.\n\nUnder these \"fully adapted\" or \"optimal\" choices, the estimator $\\hat{c}_t$ becomes exactly $c_t$, hence its variance is zero. This, however, requires computing the integrals $\\int G_t(x)\\ell_k(x)\\,\\mathrm{d}x$, which is often as hard as the original problem.\n\nThe principal result requested is the general expression for the conditional variance.", "answer": "$$\n\\boxed{\\frac{1}{N} \\sum_{k=1}^N \\pi_k v_k + \\frac{1}{N^2} \\boldsymbol{\\mathfrak{m}}^{\\top} \\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) \\boldsymbol{\\mathfrak{m}}}\n$$", "id": "3290186"}, {"introduction": "Many real-world systems can be described by conditionally linear-Gaussian state-space models, which present a special opportunity for variance reduction. This practice guides you through the construction of a Rao-Blackwellized particle filter (RBPF), a powerful hybrid approach that combines particle-based sampling for a discrete switching process with exact Kalman smoothing for the continuous linear dynamics. By working through a concrete example, you will see how replacing sampling with analytical integration leads to more accurate and efficient state estimation [@problem_id:3290212].", "problem": "Consider a Switching Linear Gaussian State-Space Model (SLG-SSM) in which a discrete regime process $z_{t} \\in \\{1,2\\}$ controls the linear dynamics of a continuous latent state $s_{t} \\in \\mathbb{R}$. The joint model is defined by the following fundamental components:\n\n- The discrete regime process $\\{z_{t}\\}_{t=0}^{T}$ is a homogeneous first-order Markov chain with initial distribution $p(z_{0})$ and transition matrix $A = [a_{ij}]$, where $a_{ij} = p(z_{t} = j \\mid z_{t-1} = i)$.\n- The continuous latent dynamics are linear-Gaussian conditioned on $z_{t}$:\n$$\ns_{t} = A_{z_{t}} s_{t-1} + \\eta_{t}, \\quad \\eta_{t} \\sim \\mathcal{N}(0, Q_{z_{t}}).\n$$\n- Observations are conditionally linear-Gaussian:\n$$\ny_{t} = H s_{t} + \\epsilon_{t}, \\quad \\epsilon_{t} \\sim \\mathcal{N}(0, R),\n$$\nwith $H = 1$.\n\nYou are to work within the Rao-Blackwellized Particle Filter (RBPF; Rao-Blackwellization replaces sampling of linear-Gaussian components by exact conditional inference) paradigm, augmented with an Auxiliary Particle Filter (APF; auxiliary proposals use one-step lookahead likelihoods) perspective to construct a hybrid forward-backward smoother: the discrete path $z_{0:T}$ is sampled using forward-backward methodology with backward sampling weights informed by linear-Gaussian predictive likelihoods, and the continuous trajectory $s_{0:T}$ is smoothed by Kalman smoothing conditioned on the sampled $z_{0:T}$.\n\nStart from the core definitions of Bayesian smoothing, the Hidden Markov Model (HMM) forward-backward decomposition, and linear-Gaussian filtering and smoothing. Derive a principled hybrid forward-backward smoother for the RBPF that:\n\n1. Samples $z_{0:T}$ from the exact smoothed distribution $p(z_{0:T} \\mid y_{0:T})$ using backward sampling weights that are constructed from forward regime-filtering messages and the regime-conditioned linear-Gaussian predictive likelihoods $p(y_{t+1} \\mid y_{0:t}, z_{t})$ (this is the APF lookahead principle).\n2. Applies Rauch–Tung–Striebel (RTS) Kalman smoothing to $s_{0:T}$ conditional on the sampled $z_{0:T}$.\n3. Uses the law of iterated expectations to express the smoothed expectation of a general functional $\\phi(z_{t}, s_{t})$ as a decomposition over $z_{t}$ with regime-conditioned linear-Gaussian moments for $s_{t}$.\n\nThen, instantiate and compute a specific smoothed expectation for a short horizon. Let $T=1$, with parameters\n- $p(z_{0} = 1) = 0.5$, $p(z_{0} = 2) = 0.5$,\n- $A = \\begin{pmatrix} 0.8  0.2 \\\\ 0.3  0.7 \\end{pmatrix}$,\n- $A_{1} = 1.0$, $Q_{1} = 0.5$; $A_{2} = 0.5$, $Q_{2} = 0.5$,\n- $H = 1$, $R = 0.25$,\n- $s_{0} \\sim \\mathcal{N}(m_{0}, P_{0})$ with $m_{0} = 0$ and $P_{0} = 1$,\nand observed values $y_{0} = 0.2$, $y_{1} = 0.3$.\n\nFor the functional $\\phi(z_{1}, s_{1}) = z_{1} s_{1}$, compute the smoothed expectation $\\mathbb{E}[\\phi(z_{1}, s_{1}) \\mid y_{0}, y_{1}]$ exactly under the specified model using the hybrid smoother you derived. Round your final numerical answer to four significant figures. No physical units are involved.", "solution": "The problem asks for the computation of the smoothed expectation $\\mathbb{E}[\\phi(z_1, s_1) \\mid y_0, y_1]$ for the functional $\\phi(z_1, s_1) = z_1 s_1$, given a specific SLG-SSM and data.\n\nFirst, we establish the theoretical framework for the hybrid smoother. The core idea of a Rao-Blackwellized filter/smoother for an SLG-SSM is to marginalize out the continuous, linear-Gaussian states $s_t$ analytically, while dealing with the discrete, non-linear switching process $z_t$. The full posterior distribution $p(z_{0:T}, s_{0:T} \\mid y_{0:T})$ can be factored as:\n$$\np(z_{0:T}, s_{0:T} \\mid y_{0:T}) = p(s_{0:T} \\mid z_{0:T}, y_{0:T}) p(z_{0:T} \\mid y_{0:T})\n$$\nConditionally on a specific realization of the discrete path $z_{0:T} = \\{z_0, \\dots, z_T\\}$, the model becomes a standard linear-Gaussian state-space model. For such a model, the smoothed distribution of the continuous states, $p(s_{0:T} \\mid z_{0:T}, y_{0:T})$, is a multivariate Gaussian. Its mean and covariance can be computed exactly using a Kalman filter forward pass followed by a Rauch-Tung-Striebel (RTS) backward smoothing pass.\n\nThe remaining challenge is to handle the posterior distribution of the discrete paths, $p(z_{0:T} \\mid y_{0:T})$. For a large time horizon $T$, the number of paths $K^{T+1}$ (where $K$ is the number of discrete states) is too large for exact enumeration. In such cases, a particle filter (like an Auxiliary Particle Filter) is used to approximate this distribution by sampling a representative set of paths. However, for the given problem with $T=1$ and $K=2$, the number of paths is only $2^2=4$. We can therefore compute the posterior probability for each path exactly, bypassing the need for sampling.\n\nThe smoothed expectation of a functional $\\phi(z_t, s_t)$ is found by the law of total expectation:\n$$\n\\mathbb{E}[\\phi(z_t, s_t) \\mid y_{0:T}] = \\mathbb{E}_{z_{0:T} \\mid y_{0:T}} \\left[ \\mathbb{E}_{s_{0:T} \\mid z_{0:T}, y_{0:T}} [\\phi(z_t, s_t)] \\right]\n$$\nFor our specific problem, $t=1$, $T=1$, and $\\phi(z_1, s_1) = z_1 s_1$. The expectation becomes:\n$$\n\\mathbb{E}[z_1 s_1 \\mid y_{0:1}] = \\sum_{z_0=1}^2 \\sum_{z_1=1}^2 \\mathbb{E}[z_1 s_1 \\mid y_{0:1}, z_0, z_1] p(z_0, z_1 \\mid y_{0:1})\n$$\nSince $z_0$ and $z_1$ are given in the inner conditional expectation, this simplifies to:\n$$\n\\mathbb{E}[z_1 s_1 \\mid y_{0:1}] = \\sum_{i=1}^2 \\sum_{j=1}^2 j \\cdot \\mathbb{E}[s_1 \\mid y_{0:1}, z_0=i, z_1=j] \\cdot p(z_0=i, z_1=j \\mid y_{0:1})\n$$\nTo compute this, we need two components for each of the four paths $(i,j)$:\n1. The posterior probability of the path, $p(z_0=i, z_1=j \\mid y_{0:1})$.\n2. The smoothed mean of $s_1$, $\\mathbb{E}[s_1 \\mid y_{0:1}, z_0=i, z_1=j]$. Since $t=T=1$, this is equivalent to the filtered mean, which we denote $m_{1|1}^{(i,j)}$.\n\nThe posterior path probability is given by Bayes' rule:\n$$\np(z_0=i, z_1=j \\mid y_{0:1}) = \\frac{p(y_{0:1} \\mid z_0=i, z_1=j) p(z_0=i, z_1=j)}{p(y_{0:1})}\n$$\nThe unnormalized weight for each path $(i,j)$ is $\\tilde{w}_{i,j} = p(z_0=i, z_1=j, y_{0:1})$. Using the chain rule of probability:\n$\\tilde{w}_{i,j} = p(y_1 \\mid y_0, z_0=i, z_1=j) p(y_0 \\mid z_0=i) p(z_1=j \\mid z_0=i) p(z_0=i)$.\nThe term $p(y_1 \\mid y_0, z_0=i, z_1=j)$ is the predictive likelihood from a Kalman filter run along the path $(i,j)$. The term $p(y_0 \\mid z_0=i)$ is the likelihood of the first observation.\n\nNow we instantiate the computation with the given parameters:\n- $p(z_0=1) = 0.5$, $p(z_0=2) = 0.5$.\n- $A=\\begin{pmatrix} 0.8  0.2 \\\\ 0.3  0.7 \\end{pmatrix}$, so $a_{11}=0.8, a_{12}=0.2, a_{21}=0.3, a_{22}=0.7$.\n- For $z_t=1$: $A_1=1.0$, $Q_1=0.5$.\n- For $z_t=2$: $A_2=0.5$, $Q_2=0.5$.\n- $H=1$, $R=0.25$.\n- Prior for $s_0$: $s_0 \\sim \\mathcal{N}(m_0, P_0)$ with $m_0=0$ and $P_0=1$.\n- Observations: $y_0=0.2$, $y_1=0.3$.\n\n**Step 1: Process observation $y_0$**\nThe prior on $s_0$, $p(s_0)=\\mathcal{N}(s_0; 0, 1)$, is independent of $z_0$. We perform a Kalman update for $s_0$ using $y_0=0.2$.\n- Prior mean $m_{0|-1} = 0$, prior covariance $P_{0|-1} = 1$.\n- Innovation covariance: $S_0 = H P_{0|-1} H^T + R = 1 \\cdot 1 \\cdot 1 + 0.25 = 1.25$.\n- Kalman gain: $K_0 = P_{0|-1} H^T S_0^{-1} = 1 \\cdot 1 \\cdot (1.25)^{-1} = 0.8$.\n- Posterior mean: $m_{0|0} = m_{0|-1} + K_0 (y_0 - H m_{0|-1}) = 0 + 0.8(0.2 - 0) = 0.16$.\n- Posterior covariance: $P_{0|0} = (I - K_0 H) P_{0|-1} = (1 - 0.8 \\cdot 1) \\cdot 1 = 0.2$.\nThe posterior distribution $p(s_0 \\mid y_0) = \\mathcal{N}(s_0; 0.16, 0.2)$ is common to all paths, as the prior was independent of $z_0$. Let's denote $m_{0|0}^{(i)} = 0.16$ and $P_{0|0}^{(i)} = 0.2$ for $i \\in \\{1,2\\}$.\n\n**Step 2: Process observation $y_1$ for each path $(i,j)$**\nWe compute the path-specific filtered means $m_{1|1}^{(i,j)}$ and predictive likelihoods $p(y_1 \\mid y_0, z_0=i, z_1=j)$. Since $m_{0|0}$ and $P_{0|0}$ are common, these quantities will only depend on the value of $z_1=j$.\n\nCase 1: $z_1=1$ (Paths $(1,1)$ and $(2,1)$)\n- Predict step:\n  $m_{1|0}^{(1)} = A_1 m_{0|0} = 1.0 \\cdot 0.16 = 0.16$.\n  $P_{1|0}^{(1)} = A_1 P_{0|0} A_1^T + Q_1 = 1.0^2 \\cdot 0.2 + 0.5 = 0.7$.\n- Update step with $y_1=0.3$:\n  Innovation covariance: $S_1^{(1)} = H P_{1|0}^{(1)} H^T + R = 0.7 + 0.25 = 0.95$.\n  Kalman gain: $K_1^{(1)} = P_{1|0}^{(1)} H^T (S_1^{(1)})^{-1} = 0.7 \\cdot (0.95)^{-1} = \\frac{14}{19}$.\n  Posterior mean: $m_{1|1}^{(1)} = m_{1|0}^{(1)} + K_1^{(1)}(y_1 - H m_{1|0}^{(1)}) = 0.16 + \\frac{14}{19}(0.3 - 0.16) = \\frac{16}{100} + \\frac{14}{19} \\cdot \\frac{14}{100} = \\frac{4}{25} + \\frac{196}{1900} = \\frac{304+196}{1900} = \\frac{500}{1900} = \\frac{5}{19}$.\n- Predictive likelihood value is proportional to $L_1^{(1)} = \\mathcal{N}(y_1; m_{1|0}^{(1)}, S_1^{(1)}) = \\mathcal{N}(0.3; 0.16, 0.95)$.\n\nCase 2: $z_1=2$ (Paths $(1,2)$ and $(2,2)$)\n- Predict step:\n  $m_{1|0}^{(2)} = A_2 m_{0|0} = 0.5 \\cdot 0.16 = 0.08$.\n  $P_{1|0}^{(2)} = A_2 P_{0|0} A_2^T + Q_2 = 0.5^2 \\cdot 0.2 + 0.5 = 0.05 + 0.5 = 0.55$.\n- Update step with $y_1=0.3$:\n  Innovation covariance: $S_1^{(2)} = H P_{1|0}^{(2)} H^T + R = 0.55 + 0.25 = 0.80$.\n  Kalman gain: $K_1^{(2)} = P_{1|0}^{(2)} H^T (S_1^{(2)})^{-1} = 0.55 \\cdot (0.80)^{-1} = \\frac{11}{16}$.\n  Posterior mean: $m_{1|1}^{(2)} = m_{1|0}^{(2)} + K_1^{(2)}(y_1 - H m_{1|0}^{(2)}) = 0.08 + \\frac{11}{16}(0.3 - 0.08) = \\frac{8}{100} + \\frac{11}{16} \\cdot \\frac{22}{100} = \\frac{2}{25} + \\frac{242}{1600} = \\frac{128+242}{1600} = \\frac{370}{1600} = \\frac{37}{160}$.\n- Predictive likelihood value is proportional to $L_1^{(2)} = \\mathcal{N}(y_1; m_{1|0}^{(2)}, S_1^{(2)}) = \\mathcal{N}(0.3; 0.08, 0.80)$.\n\n**Step 3: Compute path probabilities**\nThe unnormalized weight of a path $(i,j)$ is $\\tilde{w}_{i,j} = p(z_0=i) \\cdot a_{ij} \\cdot L_1^{(j)}$. The likelihood of $y_0$ is common and can be dropped.\nLet $l_1 = L_1^{(1)}$ and $l_2 = L_1^{(2)}$.\n$\\tilde{w}_{1,1} = p(z_0=1) a_{11} l_1 = 0.5 \\cdot 0.8 \\cdot l_1 = 0.4 l_1$.\n$\\tilde{w}_{1,2} = p(z_0=1) a_{12} l_2 = 0.5 \\cdot 0.2 \\cdot l_2 = 0.1 l_2$.\n$\\tilde{w}_{2,1} = p(z_0=2) a_{21} l_1 = 0.5 \\cdot 0.3 \\cdot l_1 = 0.15 l_1$.\n$\\tilde{w}_{2,2} = p(z_0=2) a_{22} l_2 = 0.5 \\cdot 0.7 \\cdot l_2 = 0.35 l_2$.\n\nThe total weight is $W = \\tilde{w}_{1,1}+\\tilde{w}_{1,2}+\\tilde{w}_{2,1}+\\tilde{w}_{2,2} = (0.4+0.15)l_1 + (0.1+0.35)l_2 = 0.55 l_1 + 0.45 l_2$.\nThe posterior probability of a path is $p(z_0=i, z_1=j \\mid y_{0:1}) = \\tilde{w}_{i,j}/W$.\n\n**Step 4: Compute the final expectation**\nThe expectation is $\\mathbb{E}[z_1 s_1 \\mid y_{0:1}] = \\sum_{i,j} j \\cdot \\frac{\\tilde{w}_{i,j}}{W} \\cdot m_{1|1}^{(j)}$.\n$= \\frac{1}{W} \\left( 1 \\cdot \\tilde{w}_{1,1} m_{1|1}^{(1)} + 2 \\cdot \\tilde{w}_{1,2} m_{1|1}^{(2)} + 1 \\cdot \\tilde{w}_{2,1} m_{1|1}^{(1)} + 2 \\cdot \\tilde{w}_{2,2} m_{1|1}^{(2)} \\right)$\n$= \\frac{1}{W} \\left( (\\tilde{w}_{1,1}+\\tilde{w}_{2,1}) m_{1|1}^{(1)} + 2(\\tilde{w}_{1,2}+\\tilde{w}_{2,2}) m_{1|1}^{(2)} \\right)$\n$= \\frac{1}{W} \\left( 0.55 l_1 m_{1|1}^{(1)} + 2 \\cdot 0.45 l_2 m_{1|1}^{(2)} \\right)$\nLet's compute the ratio $\\rho = l_2/l_1$:\n$\\rho = \\frac{\\mathcal{N}(0.3; 0.08, 0.80)}{\\mathcal{N}(0.3; 0.16, 0.95)} = \\frac{(2\\pi \\cdot 0.80)^{-1/2} \\exp(-\\frac{0.22^2}{2 \\cdot 0.80})}{(2\\pi \\cdot 0.95)^{-1/2} \\exp(-\\frac{0.14^2}{2 \\cdot 0.95})} = \\sqrt{\\frac{0.95}{0.80}} \\exp\\left(-\\frac{0.0484}{1.6} + \\frac{0.0196}{1.9}\\right)$\n$\\rho = \\sqrt{1.1875} \\exp(-0.03025 + 0.0103157...) = 1.08972... \\times \\exp(-0.0199342...) \\approx 1.08972 \\times 0.98026 \\approx 1.06822$.\nNow, substitute $\\rho$ into the expectation expression, dividing numerator and denominator by $l_1$:\n$\\mathbb{E}[z_1 s_1 \\mid y_{0:1}] = \\frac{0.55 m_{1|1}^{(1)} + 0.90 \\rho m_{1|1}^{(2)}}{0.55 + 0.45 \\rho}$\nUsing $m_{1|1}^{(1)} = 5/19$ and $m_{1|1}^{(2)} = 37/160 = 0.23125$:\n$\\mathbb{E}[z_1 s_1 \\mid y_{0:1}] \\approx \\frac{0.55 \\cdot (5/19) + 0.90 \\cdot 1.06822 \\cdot 0.23125}{0.55 + 0.45 \\cdot 1.06822}$\n$\\approx \\frac{0.144737 + 0.961398 \\cdot 0.23125}{0.55 + 0.480699} \\approx \\frac{0.144737 + 0.222274}{1.030699} \\approx \\frac{0.367011}{1.030699} \\approx 0.356089$.\nRounding to four significant figures, the result is $0.3561$.\nAlternatively, we can compute the marginal probabilities $p(z_1=j \\mid y_{0:1})$ first.\n$p(z_1=1 \\mid y_{0:1}) = \\frac{0.55 l_1}{W} = \\frac{0.55}{0.55+0.45\\rho} \\approx \\frac{0.55}{1.030699} \\approx 0.533616$.\n$p(z_1=2 \\mid y_{0:1}) = \\frac{0.45 l_2}{W} = \\frac{0.45\\rho}{0.55+0.45\\rho} \\approx \\frac{0.480699}{1.030699} \\approx 0.466384$.\n$\\mathbb{E}[z_1 s_1 \\mid y_{0:1}] = 1 \\cdot p(z_1=1 \\mid y_{0:1}) \\cdot m_{1|1}^{(1)} + 2 \\cdot p(z_1=2 \\mid y_{0:1}) \\cdot m_{1|1}^{(2)}$\n$\\approx 0.533616 \\cdot (5/19) + 2 \\cdot 0.466384 \\cdot 0.23125$\n$\\approx 0.140425 + 2 \\cdot 0.107843 \\approx 0.140425 + 0.215686 \\approx 0.356111$.\nThe result, rounded to four significant figures, is $0.3561$.", "answer": "$$\n\\boxed{0.3561}\n$$", "id": "3290212"}, {"introduction": "Beyond estimating latent states, Rao-Blackwellized particle filters are powerful tools for learning the static parameters of a model from data. This exercise challenges you to connect the output of an RBPF to the principles of statistical inference by deriving an expression for the observed Fisher information. Understanding this connection is key to assessing parameter identifiability and quantifying the uncertainty of your estimates in complex state-space models [@problem_id:3290191].", "problem": "Consider the following conditionally linear-Gaussian state-space model with a latent discrete regime sequence. Let $\\{s_{t}\\}_{t=1}^{T}$ be a time-homogeneous Markov chain on a finite state space $\\mathcal{S}=\\{1,2\\}$ with known transition matrix $\\Pi$ and known initial distribution. Conditional on $\\{s_{t}\\}$, the latent state process $\\{x_{t}\\}_{t=0}^{T}$ and observations $\\{y_{t}\\}_{t=1}^{T}$ satisfy\n$$\nx_{0} \\sim \\mathcal{N}\\!\\left(0,\\sigma_{0}^{2}\\right), \\quad x_{t} = \\theta\\, x_{t-1} + v_{t}, \\quad v_{t} \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}\\!\\left(0,\\sigma_{v}^{2}\\right),\n$$\n$$\ny_{t} = x_{t} + w_{t}, \\quad w_{t} \\,\\big|\\, s_{t}=j \\,\\sim\\, \\mathcal{N}\\!\\left(0, \\sigma_{w,j}^{2}\\right), \\quad j \\in \\mathcal{S},\n$$\nwith known $\\sigma_{0}^{2}  0$, $\\sigma_{v}^{2}  0$, and $\\{\\sigma_{w,j}^{2}\\}_{j \\in \\mathcal{S}}$. The unknown static parameter is $\\theta \\in (-1,1)$.\n\nSuppose you run an Auxiliary Particle Filter (APF) combined with Rao-Blackwellization, often called an Auxiliary Rao-Blackwellized Particle Filter (RBPF), that targets the posterior $p(s_{1:T} \\mid y_{1:T}, \\theta)$ using a one-step look-ahead auxiliary proposal based on predictive likelihoods, while marginalizing the linear-Gaussian state $\\{x_{t}\\}$ via Kalman filtering and smoothing conditional on each sampled regime trajectory $\\{s_{t}^{(i)}\\}_{t=1}^{T}$. This produces a weighted particle approximation $\\{w^{(i)}, s_{1:T}^{(i)}\\}_{i=1}^{N}$ to $p(s_{1:T} \\mid y_{1:T}, \\theta)$, and, for each particle $i$, exact Gaussian smoothing moments for $\\{x_{t}\\}$ conditional on $s_{1:T}^{(i)}$:\n$$\n\\mu_{t}^{(i)} = \\mathbb{E}\\!\\left[x_{t} \\mid y_{1:T}, s_{1:T}^{(i)}, \\theta\\right], \\quad P_{t}^{(i)} = \\operatorname{Var}\\!\\left(x_{t} \\mid y_{1:T}, s_{1:T}^{(i)}, \\theta\\right), \\quad C_{t}^{(i)} = \\operatorname{Cov}\\!\\left(x_{t}, x_{t-1} \\mid y_{1:T}, s_{1:T}^{(i)}, \\theta\\right).\n$$\n\nLet the log-marginal likelihood be $\\ell(\\theta) \\equiv \\ln p(y_{1:T} \\mid \\theta)$, the score be $S(\\theta) \\equiv \\partial \\ell(\\theta)/\\partial \\theta$, and the observed Fisher information be $I_{\\text{obs}}(\\theta) \\equiv -\\partial^{2} \\ell(\\theta)/\\partial \\theta^{2}$. Starting only from fundamental definitions of score and observed Fisher information for incomplete-data models, and from the joint density factorization $p(x_{0:T}, s_{1:T}, y_{1:T} \\mid \\theta) = p(x_{0}) \\prod_{t=1}^{T} p(x_{t} \\mid x_{t-1}, \\theta) \\, p(y_{t} \\mid x_{t}, s_{t}) \\, p(s_{t} \\mid s_{t-1})$, derive a closed-form analytic expression for $I_{\\text{obs}}(\\theta)$ expressed entirely in terms of conditional expectations and variances with respect to the joint smoothing distribution $p(x_{0:T}, s_{1:T} \\mid y_{1:T}, \\theta)$.\n\nYour derivation must:\n- Begin from the definitions of the score and observed Fisher information for the marginal likelihood of $\\{y_{t}\\}$.\n- Use only identities that can be justified from first principles, such as the law of iterated expectations and differentiation under the integral sign, applied to the complete-data log-density.\n- Make explicit which parts of the complete-data log-density depend on $\\theta$ and isolate those contributions.\n- Conclude with a single closed-form analytic expression for $I_{\\text{obs}}(\\theta)$ that depends on $T$, $\\sigma_{v}^{2}$, $\\theta$, and expectations and variances of polynomial functions of $\\{x_{t}\\}$ under $p(x_{0:T}, s_{1:T} \\mid y_{1:T}, \\theta)$.\n\nState clearly the final analytic expression for $I_{\\text{obs}}(\\theta)$. No numerical evaluation is required. The final answer must be a single closed-form analytic expression. No units are involved. Do not provide an inequality or an equation to be solved.", "solution": "The problem requires the derivation of a closed-form analytic expression for the observed Fisher information, $I_{\\text{obs}}(\\theta)$, for the marginal likelihood of the observations $\\{y_{t}\\}_{t=1}^{T}$. The derivation must start from fundamental definitions and be expressed in terms of conditional moments with respect to the joint smoothing distribution $p(x_{0:T}, s_{1:T} \\mid y_{1:T}, \\theta)$.\n\nLet the complete data be denoted by $(X, S, Y)$, where $X = \\{x_t\\}_{t=0}^T$, $S = \\{s_t\\}_{t=1}^T$, and $Y = \\{y_t\\}_{t=1}^T$. The latent variables are $Z = (X, S)$. The parameter to be estimated is $\\theta$. The log-marginal likelihood is $\\ell(\\theta) = \\ln p(Y \\mid \\theta)$. The observed Fisher information is defined as $I_{\\text{obs}}(\\theta) = -\\frac{\\partial^2 \\ell(\\theta)}{\\partial \\theta^2}$.\n\nOur derivation will be based on the relationship between the observed-data log-likelihood and the complete-data log-likelihood, $\\ell_c(\\theta) = \\ln p(X, S, Y \\mid \\theta)$. The joint density of the complete data is given by\n$$p(x_{0:T}, s_{1:T}, y_{1:T} \\mid \\theta) = p(x_{0}) p(s_1) \\left(\\prod_{t=2}^{T} p(s_{t} \\mid s_{t-1})\\right) \\left(\\prod_{t=1}^{T} p(x_{t} \\mid x_{t-1}, \\theta) p(y_{t} \\mid x_{t}, s_{t})\\right)$$\nTaking the natural logarithm, we obtain the complete-data log-likelihood:\n$$\\ell_c(\\theta) = \\ln p(x_0) + \\ln p(s_1) + \\sum_{t=2}^T \\ln p(s_t|s_{t-1}) + \\sum_{t=1}^T \\ln p(y_t|x_t,s_t) + \\sum_{t=1}^T \\ln p(x_t|x_{t-1},\\theta)$$\nWe inspect each term for its dependence on $\\theta$. Only the term $\\sum_{t=1}^T \\ln p(x_t|x_{t-1},\\theta)$ depends on $\\theta$. The state transition is $x_t = \\theta x_{t-1} + v_t$ with $v_t \\sim \\mathcal{N}(0, \\sigma_v^2)$, which means $p(x_t \\mid x_{t-1}, \\theta)$ is the density of a Gaussian distribution $\\mathcal{N}(x_t; \\theta x_{t-1}, \\sigma_v^2)$.\nTherefore, up to a constant that is independent of $\\theta$, the complete-data log-likelihood is:\n$$\\ell_c(\\theta) = -\\frac{1}{2\\sigma_v^2} \\sum_{t=1}^T (x_t - \\theta x_{t-1})^2 + C$$\nwhere $C$ consolidates all terms not involving $\\theta$.\n\nThe derivation of $I_{\\text{obs}}(\\theta)$ relies on Louis's identity, which expresses the observed information in terms of moments of the complete-data score and information. We first compute these quantities.\n\nThe complete-data score, $S_c(\\theta; Z)$, is the first derivative of $\\ell_c(\\theta)$ with respect to $\\theta$:\n$$S_c(\\theta; Z) = \\frac{\\partial \\ell_c(\\theta)}{\\partial \\theta} = \\frac{\\partial}{\\partial \\theta} \\left( -\\frac{1}{2\\sigma_v^2} \\sum_{t=1}^T (x_t - \\theta x_{t-1})^2 \\right) = \\frac{1}{\\sigma_v^2} \\sum_{t=1}^T (x_t - \\theta x_{t-1}) x_{t-1}$$\nThe complete-data information, $I_c(\\theta; Z)$, is the negative of the second derivative of $\\ell_c(\\theta)$:\n$$I_c(\\theta; Z) = -\\frac{\\partial^2 \\ell_c(\\theta)}{\\partial \\theta^2} = -\\frac{\\partial}{\\partial \\theta} \\left( \\frac{1}{\\sigma_v^2} \\sum_{t=1}^T (x_t x_{t-1} - \\theta x_{t-1}^2) \\right) = \\frac{1}{\\sigma_v^2} \\sum_{t=1}^T x_{t-1}^2$$\n\nThe score function for the observed data, $S(\\theta) = \\frac{\\partial \\ell(\\theta)}{\\partial \\theta}$, can be expressed as the expectation of the complete-data score conditional on the observed data:\n$$S(\\theta) = \\mathbb{E}[S_c(\\theta; Z) \\mid Y, \\theta]$$\nThe observed Fisher information is $I_{\\text{obs}}(\\theta) = -\\frac{\\partial S(\\theta)}{\\partial \\theta}$. Applying the derivative with respect to $\\theta$ and using the product rule for differentiation under the integral sign:\n$$I_{\\text{obs}}(\\theta) = -\\frac{\\partial}{\\partial \\theta} \\int S_c(\\theta; Z) p(Z \\mid Y, \\theta) dZ = -\\int \\frac{\\partial S_c(\\theta; Z)}{\\partial \\theta} p(Z \\mid Y, \\theta) dZ - \\int S_c(\\theta; Z) \\frac{\\partial p(Z \\mid Y, \\theta)}{\\partial \\theta} dZ$$\nUsing the identity $\\frac{\\partial p(Z \\mid Y, \\theta)}{\\partial \\theta} = p(Z \\mid Y, \\theta) (S_c(\\theta; Z) - S(\\theta))$, we have:\n$$I_{\\text{obs}}(\\theta) = -\\mathbb{E}\\left[\\frac{\\partial S_c(\\theta; Z)}{\\partial \\theta} \\mid Y, \\theta\\right] - \\mathbb{E}[S_c(\\theta; Z)(S_c(\\theta; Z) - S(\\theta)) \\mid Y, \\theta]$$\n$$I_{\\text{obs}}(\\theta) = \\mathbb{E}[I_c(\\theta; Z) \\mid Y, \\theta] - (\\mathbb{E}[S_c(\\theta; Z)^2 \\mid Y, \\theta] - S(\\theta)\\mathbb{E}[S_c(\\theta; Z) \\mid Y, \\theta])$$\nSince $S(\\theta) = \\mathbb{E}[S_c(\\theta; Z) \\mid Y, \\theta]$, the second part becomes the variance:\n$$I_{\\text{obs}}(\\theta) = \\mathbb{E}[I_c(\\theta; Z) \\mid Y, \\theta] - \\operatorname{Var}[S_c(\\theta; Z) \\mid Y, \\theta]$$\nThis is Louis's identity. The expectations and variance are taken with respect to the joint smoothing distribution $p(Z \\mid Y, \\theta) = p(x_{0:T}, s_{1:T} \\mid y_{1:T}, \\theta)$.\n\nWe now substitute our expressions for $I_c(\\theta; Z)$ and $S_c(\\theta; Z)$ into this identity.\n\nThe first term is the expectation of the complete-data information:\n$$\\mathbb{E}[I_c(\\theta; Z) \\mid y_{1:T}, \\theta] = \\mathbb{E}\\left[\\frac{1}{\\sigma_v^2} \\sum_{t=1}^T x_{t-1}^2 \\mid y_{1:T}, \\theta\\right] = \\frac{1}{\\sigma_v^2} \\sum_{t=1}^T \\mathbb{E}\\left[x_{t-1}^2 \\mid y_{1:T}, \\theta\\right]$$\n\nThe second term is the variance of the complete-data score:\n$$\\operatorname{Var}[S_c(\\theta; Z) \\mid y_{1:T}, \\theta] = \\operatorname{Var}\\left[\\frac{1}{\\sigma_v^2} \\sum_{t=1}^T (x_t - \\theta x_{t-1})x_{t-1} \\mid y_{1:T}, \\theta\\right]$$\nUsing the property $\\operatorname{Var}(aX) = a^2\\operatorname{Var}(X)$, we get:\n$$\\operatorname{Var}[S_c(\\theta; Z) \\mid y_{1:T}, \\theta] = \\frac{1}{(\\sigma_v^2)^2} \\operatorname{Var}\\left[\\sum_{t=1}^T (x_t x_{t-1} - \\theta x_{t-1}^2) \\mid y_{1:T}, \\theta\\right]$$\n\nCombining these two terms gives the final expression for the observed Fisher information. The expectations and variances are with respect to the joint smoothing distribution over both state sequences $\\{x_t\\}$ and regime sequences $\\{s_t\\}$, conditional on the observations $\\{y_t\\}$ and parameter $\\theta$.\n\nThe resulting closed-form analytic expression is:\n$$I_{\\text{obs}}(\\theta) = \\frac{1}{\\sigma_v^2} \\sum_{t=1}^T \\mathbb{E}\\left[x_{t-1}^2 \\mid y_{1:T}, \\theta\\right] - \\frac{1}{(\\sigma_v^2)^2} \\operatorname{Var}\\left[\\sum_{t=1}^T \\left(x_t x_{t-1} - \\theta x_{t-1}^2\\right) \\mid y_{1:T}, \\theta\\right]$$\nThis expression adheres to all requirements of the problem statement. It is a single analytic expression for $I_{\\text{obs}}(\\theta)$ in terms of the model parameters and moments of polynomial functions of the latent states under the joint smoothing distribution.", "answer": "$$\\boxed{\\frac{1}{\\sigma_{v}^{2}} \\sum_{t=1}^{T} \\mathbb{E}\\left[x_{t-1}^{2} \\mid y_{1:T}, \\theta\\right] - \\frac{1}{\\left(\\sigma_{v}^{2}\\right)^{2}} \\operatorname{Var}\\left[\\sum_{t=1}^{T} \\left(x_{t} x_{t-1} - \\theta x_{t-1}^{2}\\right) \\mid y_{1:T}, \\theta\\right]}$$", "id": "3290191"}]}