{"hands_on_practices": [{"introduction": "To truly master low-discrepancy methods, we must first get our hands dirty with the definition of discrepancy itself. This first exercise challenges you to calculate the star discrepancy, $D_N^*$, for a simple one-dimensional point set from first principles [@problem_id:3318540]. Completing this calculation will provide a tangible feel for how discrepancy measures uniformity and will reveal the fundamental reason why even the best point sets in one dimension can have a discrepancy that decays no faster than order $N^{-1}$.", "problem": "Let $N \\in \\mathbb{N}$ and consider the one-dimensional point set $P_N=\\{u_i\\}_{i=1}^{N}$ with $u_i = i/N$ in the unit interval. The star discrepancy $D_N^{*}(P)$ of a finite point set $P \\subset [0,1]$ in dimension $s=1$ is defined by\n$$\nD_N^{*}(P) \\;=\\; \\sup_{t \\in [0,1]} \\left| \\frac{1}{N} \\sum_{i=1}^{N} \\mathbf{1}\\{u_i \\in [0,t)\\} \\;-\\; t \\right|,\n$$\nwhere $\\mathbf{1}\\{\\cdot\\}$ denotes the indicator function. Starting from this definition and the basic properties of empirical distribution functions, compute the exact value of $D_N^{*}(P_N)$ for the given equispaced set $P_N$. Then, using only first principles about piecewise-constant empirical distribution functions and the fact that $t \\mapsto t$ is continuous, explain why the magnitude of $D_N^{*}(P)$ cannot decay faster than order $N^{-1}$ in one dimension, by proving a universal lower bound of the form $c/N$ for some constant $c0$ that does not depend on $P$. Your final numerical answer must be the exact value of $D_N^{*}(P_N)$ expressed as a single closed-form expression in $N$. Do not round.", "solution": "The problem asks for two distinct results: first, to compute the exact star discrepancy $D_N^{*}(P_N)$ for a specific one-dimensional equispaced point set $P_N=\\{u_i\\}_{i=1}^{N}$ with $u_i = i/N$; and second, to prove a universal lower bound on the star discrepancy for any one-dimensional point set, demonstrating that its convergence rate cannot be faster than $N^{-1}$.\n\nLet us begin by defining the primary objects. The empirical distribution function for a point set $P = \\{u_i\\}_{i=1}^{N} \\subset [0,1]$ is given by\n$$F_N(t) = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbf{1}\\{u_i \\in [0,t)\\}$$\nwhere $\\mathbf{1}\\{\\cdot\\}$ is the indicator function. The star discrepancy is the supremum norm of the difference between the empirical distribution function and the uniform distribution function $F(t) = t$:\n$$D_N^{*}(P) = \\sup_{t \\in [0,1]} |F_N(t) - t|$$\nLet us denote the discrepancy function as $D(t) = F_N(t) - t$.\n\n**Part 1: Calculation of $D_N^{*}(P_N)$ for the equispaced set**\n\nThe given point set is $P_N = \\{1/N, 2/N, \\dots, N/N=1\\}$. The points are already ordered. Note that the definition of $F_N(t)$ involves counting points $u_i$ in the half-open interval $[0,t)$, i.e., $u_i  t$.\n\nWe analyze the function $F_N(t)$ for $t \\in [0,1]$. The function $F_N(t)$ is a step function that changes its value only when $t$ crosses one of the points $u_i = i/N$. Let's analyze $F_N(t)$ on intervals defined by these points.\n\nLet $k$ be an integer from $0$ to $N$.\nFor $t$ in the interval $[k/N, (k+1)/N)$ for $k \\in \\{0, 1, \\dots, N-1\\}$:\nThe points $u_i = i/N$ from the set $P_N$ that satisfy $u_i  t$ are precisely $\\{1/N, 2/N, \\dots, k/N\\}$. There are $k$ such points. For $k=0$, there are no points.\nThus, for $t \\in [k/N, (k+1)/N)$, the empirical distribution function is $F_N(t) = k/N$.\n\nNow we compute the discrepancy function $D(t) = F_N(t) - t$ on these intervals:\nFor $t \\in [k/N, (k+1)/N)$, we have $D(t) = k/N - t$.\nSince $k/N \\le t  (k+1)/N$, it follows that $k/N - (k+1)/N  D(t) \\le k/N - k/N$, which simplifies to $-1/N  D(t) \\le 0$.\nThe magnitude of the discrepancy function on this interval is $|D(t)| = |k/N - t| = t - k/N$.\nThis is a monotonically increasing function of $t$ on the interval $[k/N, (k+1)/N)$. Therefore, its supremum on this interval is attained as $t$ approaches the right endpoint:\n$$\\sup_{t \\in [k/N, (k+1)/N)} |D(t)| = \\lim_{t \\to ((k+1)/N)^-} (t - k/N) = \\frac{k+1}{N} - \\frac{k}{N} = \\frac{1}{N}$$\nThis result holds for each $k \\in \\{0, 1, \\dots, N-1\\}$.\n\nFinally, we must consider the point $t=1$. At $t=1$, the interval is $[0,1)$, so we count the points $u_i  1$. These points are $\\{1/N, 2/N, \\dots, (N-1)/N\\}$. There are $N-1$ such points.\nSo, $F_N(1) = (N-1)/N$.\nThe discrepancy at $t=1$ is $|D(1)| = |F_N(1) - 1| = |\\frac{N-1}{N} - 1| = |-\\frac{1}{N}| = \\frac{1}{N}$.\n\nThe star discrepancy $D_N^{*}(P_N)$ is the supremum of $|D(t)|$ over the entire interval $[0,1]$. Since on each subinterval $[k/N, (k+1)/N)$ the supremum of $|D(t)|$ is $1/N$, and the value at $t=1$ is also $1/N$, the overall supremum is\n$$D_N^{*}(P_N) = \\frac{1}{N}$$\n\n**Part 2: Universal Lower Bound for $D_N^{*}(P)$**\n\nNext, we prove that for any one-dimensional point set $P = \\{u_1, u_2, \\dots, u_N\\}$ in $[0,1]$, the star discrepancy $D_N^*(P)$ is bounded below by $c/N$ for some universal constant $c  0$. We will use first principles regarding the properties of the functions involved.\n\nLet the points of $P$ be sorted, $0 \\le u_1 \\le u_2 \\le \\dots \\le u_N \\le 1$. We add auxiliary points $u_0 = 0$ and $u_{N+1}=1$.\nThe function $F_N(t)$ is a right-continuous step function. It is constant on any interval $[u_i, u_{i+1})$ for $i=0, \\dots, N$, assuming distinct points for simplicity of notation. The argument holds in general.\nAt each point $u_i$ in the set $P$, the function $F_N(t)$ exhibits a jump. Let's analyze the discrepancy function $D(t) = F_N(t) - t$ around one such point $u_i$.\n\nLet us consider the values of $D(t)$ just before and just after a point $u_i$. To handle multiple points at the same location, let $m_i = \\#\\{j : u_j  u_i\\}$ be the number of points strictly to the left of $u_i$, and $m'_i = \\#\\{j : u_j \\le u_i\\}$ be the number of points less than or equal to $u_i$. The number of points exactly at location $u_i$ is $j_i = m'_i - m_i \\ge 1$.\n\nIn the small interval just to the left of $u_i$, say for $t \\in (u_i-\\epsilon, u_i)$, $F_N(t)$ equals $m_i/N$. As $t \\to u_i^-$, the discrepancy function approaches:\n$$D(u_i^-) = \\lim_{t \\to u_i^-} D(t) = \\frac{m_i}{N} - u_i$$\nIn the small interval just to the right of $u_i$, say for $t \\in (u_i, u_i+\\epsilon)$, $F_N(t)$ equals $m'_i/N$. As $t \\to u_i^+$, the discrepancy function approaches:\n$$D(u_i^+) = \\lim_{t \\to u_i^+} D(t) = \\frac{m'_i}{N} - u_i = \\frac{m_i + j_i}{N} - u_i$$\nThe difference between these two limiting values is\n$$D(u_i^+) - D(u_i^-) = \\frac{j_i}{N}$$\n\nLet $K = D_N^*(P) = \\sup_{t \\in [0,1]} |D(t)|$. By the definition of the supremum, the values of $|D(t)|$ for all $t$, including the limits from the left and right at discontinuity points, must be less than or equal to $K$.\nTherefore, we must have:\n$$|D(u_i^-)| \\le K \\quad \\text{and} \\quad |D(u_i^+)| \\le K$$\nLet $x = D(u_i^-)$. Then $D(u_i^+) = x + j_i/N$. The conditions are $|x| \\le K$ and $|x + j_i/N| \\le K$.\n\nUsing the triangle inequality, we can write:\n$$ \\frac{j_i}{N} = \\left| \\frac{j_i}{N} \\right| = \\left| (x + \\frac{j_i}{N}) - x \\right| \\le \\left| x + \\frac{j_i}{N} \\right| + |-x| = \\left| x + \\frac{j_i}{N} \\right| + |x| $$\nApplying the bounds from the definition of $K$:\n$$ \\frac{j_i}{N} \\le K + K = 2K$$\nSince there is at least one point in the set $P$, there is at least one location $u_i$ where a jump occurs, so there exists an $i$ for which $j_i \\ge 1$. For that jump, we have:\n$$ \\frac{1}{N} \\le \\frac{j_i}{N} \\le 2K$$\nThis leads to the inequality $K \\ge 1/(2N)$.\n\nThus, for any $N$-point set $P$ in one dimension, its star discrepancy has the lower bound:\n$$D_N^*(P) \\ge \\frac{1}{2N}$$\nThis demonstrates that the discrepancy cannot decay to zero faster than the order $N^{-1}$. The constant $c$ in the problem description is $1/2$.\nThis completes the required explanation.\n\nThe final answer requested is the exact value of $D_N^*(P_N)$ computed in the first part.", "answer": "$$\\boxed{\\frac{1}{N}}$$", "id": "3318540"}, {"introduction": "Having learned how to measure non-uniformity, the next logical step is to construct a point set that is explicitly designed to be uniform. This exercise guides you through the algebraic construction of a small two-dimensional digital $(t,m,s)$-net [@problem_id:3318561]. By choosing generating matrices and generating the points, you will see how principles from linear algebra over finite fields translate directly into the powerful equidistribution properties of these sequences.", "problem": "Consider the construction of a digital net in base $2$ for quasi-Monte Carlo (QMC) methods, using the foundational definition of a digital $(t,m,s)$-net over the Galois Field (GF) of two elements, denoted $\\mathrm{GF}(2)$. A digital $(t,m,s)$-net in base $2$ is specified by $s$ binary generating matrices $C_{1},\\dots,C_{s}$ of size $m \\times m$, and for each integer $n \\in \\{0,1,\\dots,2^{m}-1\\}$ with binary expansion $n = a_{0} + a_{1} 2 + \\cdots + a_{m-1} 2^{m-1}$, the point $\\boldsymbol{x}_{n} \\in [0,1)^{s}$ has coordinates $x_{j} = \\sum_{r=1}^{m} y_{j,r} 2^{-r}$, where $y_{j} = C_{j} a$ is computed over $\\mathrm{GF}(2)$ and $a = (a_{0},\\dots,a_{m-1})^{\\top}$. The $(t,m,s)$-net property is determined by a linear independence condition on initial row blocks of the generating matrices, ensuring coverage regularity of elementary intervals.\n\nUsing only these principles:\n- Construct a specific digital $(t,m,s)$-net with $b=2$, $s=2$, $m=3$, and $t=1$ by choosing explicit binary generating matrices $C_{1}$ and $C_{2}$ of size $3 \\times 3$ over $\\mathrm{GF}(2)$ that satisfy the required linear independence condition for $t=1$.\n- Using your matrices, list the $2^{m} = 8$ points $\\boldsymbol{x}_{n} \\in [0,1)^{2}$ for $n=0,1,\\dots,7$.\n- Finally, determine the exact number of these points lying in the elementary interval $[0,\\tfrac{1}{2}) \\times [0,\\tfrac{1}{2})$.\n\nProvide the count of points in $[0,\\tfrac{1}{2}) \\times [0,\\tfrac{1}{2})$ as your final answer. No rounding is required, and no units are involved.", "solution": "The problem requires the construction of a specific digital $(t,m,s)$-net, the generation of its points, and the subsequent counting of points that fall within a specified sub-interval of the unit hypercube. The parameters for the net are given as base $b=2$, dimension $s=2$, resolution $m=3$, and quality parameter $t=1$.\n\nFirst, we formalize the condition for a set of points to be a digital $(t,m,s)$-net. A set of $b^m$ points in $[0,1)^s$ forms a digital $(t,m,s)$-net in base $b$ if every elementary interval of volume $b^{t-m}$ contains exactly $b^t$ points. This property is guaranteed if the $s$ generating matrices, $C_1, \\dots, C_s$, each of size $m \\times m$ over the Galois field $\\mathrm{GF}(b)$, satisfy a specific linear independence condition.\n\nFor the given parameters $b=2$, $s=2$, $m=3$, and $t=1$, the volume of the elementary intervals in question is $b^{t-m} = 2^{1-3} = 2^{-2} = \\frac{1}{4}$. The number of points in each such interval must be $b^t = 2^1 = 2$.\nThe linear independence condition that the generating matrices must satisfy is as follows: for any pair of non-negative integers $(d_1, d_2)$ such that $d_1 + d_2 = m-t = 3-1=2$, the set of vectors consisting of the first $d_1$ rows of matrix $C_1$ and the first $d_2$ rows of matrix $C_2$ must be linearly independent over $\\mathrm{GF}(2)$. The possible pairs $(d_1, d_2)$ satisfying $d_1+d_2=2$ are $(2,0)$, $(1,1)$, and $(0,2)$.\n\nOur first task is to construct two $3 \\times 3$ binary matrices, $C_1$ and $C_2$, that meet these criteria. A standard and valid choice is to select the identity matrix for $C_1$ and then construct a suitable $C_2$. Let us define:\n$$\nC_1 = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{pmatrix}, \\quad C_2 = \\begin{pmatrix} 0  1  0 \\\\ 0  0  1 \\\\ 1  0  0 \\end{pmatrix}\n$$\nWe must verify that this choice satisfies the linear independence conditions:\n1.  For $(d_1, d_2) = (2,0)$: We consider the first $2$ rows of $C_1$. These are the vectors $(1,0,0)$ and $(0,1,0)$. They are linearly independent over $\\mathrm{GF}(2)$.\n2.  For $(d_1, d_2) = (1,1)$: We consider the first row of $C_1$, which is $(1,0,0)$, and the first row of $C_2$, which is $(0,1,0)$. These two vectors are linearly independent over $\\mathrm{GF}(2)$.\n3.  For $(d_1, d_2) = (0,2)$: We consider the first $2$ rows of $C_2$. These are the vectors $(0,1,0)$ and $(0,0,1)$. They are linearly independent over $\\mathrm{GF}(2)$.\nSince all conditions are met, this choice of $C_1$ and $C_2$ generates a valid $(1,3,2)$-net.\n\nNext, we generate the $2^m=2^3=8$ points of the net. For each integer $n \\in \\{0, 1, \\dots, 7\\}$, we first find its binary expansion $n = a_0 + a_1 2^1 + a_2 2^2$, which gives the input vector $a = (a_0, a_1, a_2)^\\top$. The coordinates of the point $\\boldsymbol{x}_n = (x_1, x_2)$ are determined by the vectors $y_1=C_1 a$ and $y_2=C_2 a$, where arithmetic is in $\\mathrm{GF}(2)$.\nFor $y_j = (y_{j,1}, y_{j,2}, y_{j,3})^\\top$, the coordinate is $x_j = \\sum_{r=1}^3 y_{j,r} 2^{-r}$.\nUsing our chosen matrices:\n$y_1 = C_1 a = I a = (a_0, a_1, a_2)^\\top$\n$y_2 = C_2 a = \\begin{pmatrix} 0  1  0 \\\\ 0  0  1 \\\\ 1  0  0 \\end{pmatrix} \\begin{pmatrix} a_0 \\\\ a_1 \\\\ a_2 \\end{pmatrix} = \\begin{pmatrix} a_1 \\\\ a_2 \\\\ a_0 \\end{pmatrix}$\n\nWe can now list the $8$ points:\n-   $n=0$: $a=(0,0,0)^\\top$. $y_1=(0,0,0)^\\top \\implies x_1=0$. $y_2=(0,0,0)^\\top \\implies x_2=0$. Point: $(0,0)$.\n-   $n=1$: $a=(1,0,0)^\\top$. $y_1=(1,0,0)^\\top \\implies x_1=\\frac{1}{2}$. $y_2=(0,0,1)^\\top \\implies x_2=\\frac{1}{8}$. Point: $(\\frac{1}{2}, \\frac{1}{8})$.\n-   $n=2$: $a=(0,1,0)^\\top$. $y_1=(0,1,0)^\\top \\implies x_1=\\frac{1}{4}$. $y_2=(1,0,0)^\\top \\implies x_2=\\frac{1}{2}$. Point: $(\\frac{1}{4}, \\frac{1}{2})$.\n-   $n=3$: $a=(1,1,0)^\\top$. $y_1=(1,1,0)^\\top \\implies x_1=\\frac{1}{2}+\\frac{1}{4}=\\frac{3}{4}$. $y_2=(1,0,1)^\\top \\implies x_2=\\frac{1}{2}+\\frac{1}{8}=\\frac{5}{8}$. Point: $(\\frac{3}{4}, \\frac{5}{8})$.\n-   $n=4$: $a=(0,0,1)^\\top$. $y_1=(0,0,1)^\\top \\implies x_1=\\frac{1}{8}$. $y_2=(0,1,0)^\\top \\implies x_2=\\frac{1}{4}$. Point: $(\\frac{1}{8}, \\frac{1}{4})$.\n-   $n=5$: $a=(1,0,1)^\\top$. $y_1=(1,0,1)^\\top \\implies x_1=\\frac{1}{2}+\\frac{1}{8}=\\frac{5}{8}$. $y_2=(0,1,1)^\\top \\implies x_2=\\frac{1}{4}+\\frac{1}{8}=\\frac{3}{8}$. Point: $(\\frac{5}{8}, \\frac{3}{8})$.\n-   $n=6$: $a=(0,1,1)^\\top$. $y_1=(0,1,1)^\\top \\implies x_1=\\frac{1}{4}+\\frac{1}{8}=\\frac{3}{8}$. $y_2=(1,1,0)^\\top \\implies x_2=\\frac{1}{2}+\\frac{1}{4}=\\frac{3}{4}$. Point: $(\\frac{3}{8}, \\frac{3}{4})$.\n-   $n=7$: $a=(1,1,1)^\\top$. $y_1=(1,1,1)^\\top \\implies x_1=\\frac{1}{2}+\\frac{1}{4}+\\frac{1}{8}=\\frac{7}{8}$. $y_2=(1,1,1)^\\top \\implies x_2=\\frac{7}{8}$. Point: $(\\frac{7}{8}, \\frac{7}{8})$.\n\nFinally, we must determine the number of these points lying in the elementary interval $[0,\\frac{1}{2}) \\times [0,\\frac{1}{2})$. A point $(x_1, x_2)$ is in this interval if and only if $0 \\le x_1  \\frac{1}{2}$ and $0 \\le x_2  \\frac{1}{2}$.\nThe condition $x_j  \\frac{1}{2}$ is equivalent to the first fractional binary digit of $x_j$ being $0$. This first digit is $y_{j,1}$. Thus, we are counting the number of points for which $y_{1,1}=0$ and $y_{2,1}=0$.\nFrom our generating formulas, this translates to the conditions:\n$y_{1,1} = a_0 = 0$\n$y_{2,1} = a_1 = 0$\nThe third component of the input vector, $a_2$, is unconstrained and can be either $0$ or $1$. This gives us two possible input vectors $a$:\n1.  $a=(0,0,0)^\\top$: This corresponds to $n=0$, and the point is $\\boldsymbol{x}_0 = (0,0)$.\n2.  $a=(0,0,1)^\\top$: This corresponds to $n=4$, and the point is $\\boldsymbol{x}_4 = (\\frac{1}{8},\\frac{1}{4})$.\n\nBoth points, $\\boldsymbol{x}_0=(0,0)$ and $\\boldsymbol{x}_4=(\\frac{1}{8},\\frac{1}{4})$, satisfy the conditions $x_1 \\frac{1}{2}$ and $x_2 \\frac{1}{2}$. The other six points correspond to cases where $a_0=1$ or $a_1=1$ (or both), leading to $x_1 \\ge \\frac{1}{2}$ or $x_2 \\ge \\frac{1}{2}$.\nTherefore, exactly two points from the constructed set lie in the specified interval. This result confirms the theoretical expectation for a $(1,3,2)$-net, as the interval has volume $2^{t-m}$ and thus must contain $2^t=2$ points.", "answer": "$$\\boxed{2}$$", "id": "3318561"}, {"introduction": "Low-discrepancy sequences are powerful tools for quasi-Monte Carlo (QMC) integration, but their performance is not guaranteed without careful thought. This computational experiment explores a critical practical issue: the interaction between a QMC point set and an integrand with a boundary singularity [@problem_id:3318589]. By observing how a seemingly innocuous choice in mapping the points can drastically affect the integration error, you will gain crucial insight into the robust application of these advanced numerical tools.", "problem": "Consider quasi-Monte Carlo integration on the unit interval with low-discrepancy sequences. Let $f_{\\alpha,0}(x) = x^{-\\alpha}$ and $f_{\\alpha,1}(x) = (1-x)^{-\\alpha}$ for $x \\in (0,1)$ and $\\alpha \\in (0,1)$, each an integrable boundary singularity. The integral of either function over $[0,1]$ is given by $\\int_{0}^{1} x^{-\\alpha} \\, dx = \\int_{0}^{1} (1-x)^{-\\alpha} \\, dx = \\frac{1}{1-\\alpha}$ for $0  \\alpha  1$, which is finite. Low-discrepancy sequences are understood through the notion of discrepancy and the quasi-Monte Carlo error bound that depends on the variation (in the sense of Hardy and Krause) of the integrand and the star-discrepancy of the point set. When the integrand has a boundary singularity, the variation is unbounded and the usual error bounds degenerate, making the qualitative behavior of the estimator sensitive to how the boundary points are treated. In particular, mapping samples to include or exclude a singular boundary can change the observed error.\n\nStarting from these definitions and facts, design a small computational experiment that demonstrates how mapping samples from $(0,1)$ to either $(0,1]$ or $[0,1)$ can materially affect the quasi-Monte Carlo error for integrands with boundary singularities. The experiment must use a deterministic low-discrepancy sequence in one dimension and two mapping conventions:\n- The $[0,1)$ mapping: use the points as generated in $[0,1)$, potentially including $x=0$ exactly.\n- The $(0,1]$ mapping: use the transformation $x \\mapsto 1 - x$, which maps $[0,1)$ to $(0,1]$, potentially including $x=1$ exactly.\n\nTo ensure numerical stability when an evaluation would otherwise be undefined due to hitting a singular boundary exactly, you must evaluate $f_{\\alpha,0}$ at $x$ via $x \\leftarrow \\max(x,\\varepsilon)$ and $f_{\\alpha,1}$ at $x$ via $(1-x) \\leftarrow \\max(1-x,\\varepsilon)$, where $\\varepsilon$ is the smallest positive floating-point number representable in double precision. This clipping is purely for safe computation and does not alter the analytical integral, which remains $\\frac{1}{1-\\alpha}$.\n\nImplement the estimator as the arithmetic mean of the function values at the low-discrepancy points. Use the following deterministic low-discrepancy sequence:\n- The one-dimensional Sobol sequence with no scrambling and a power-of-two sample size $N = 2^{m}$ generated by a base-$2$ construction. The points should be generated exactly as $2^{m}$ points for each specified $N$.\n\nFor each test case, compute the absolute error $E = \\left|\\hat{I} - \\frac{1}{1-\\alpha}\\right|$, where $\\hat{I}$ is the quasi-Monte Carlo estimator.\n\nYour program must implement and report the errors for the following test suite, which is chosen to cover different singularity locations, singularity strengths, sample sizes, and mappings:\n- Singularity at $x=0$ ($f_{\\alpha,0}$), $\\alpha = 0.25$, $N = 2^{5} = 32$, mapping $[0,1)$.\n- Singularity at $x=0$ ($f_{\\alpha,0}$), $\\alpha = 0.25$, $N = 2^{5} = 32$, mapping $(0,1]$.\n- Singularity at $x=0$ ($f_{\\alpha,0}$), $\\alpha = 0.25$, $N = 2^{10} = 1024$, mapping $[0,1)$.\n- Singularity at $x=0$ ($f_{\\alpha,0}$), $\\alpha = 0.25$, $N = 2^{10} = 1024$, mapping $(0,1]$.\n- Singularity at $x=0$ ($f_{\\alpha,0}$), $\\alpha = 0.75$, $N = 2^{5} = 32$, mapping $[0,1)$.\n- Singularity at $x=0$ ($f_{\\alpha,0}$), $\\alpha = 0.75$, $N = 2^{5} = 32$, mapping $(0,1]$.\n- Singularity at $x=0$ ($f_{\\alpha,0}$), $\\alpha = 0.75$, $N = 2^{10} = 1024$, mapping $[0,1)$.\n- Singularity at $x=0$ ($f_{\\alpha,0}$), $\\alpha = 0.75$, $N = 2^{10} = 1024$, mapping $(0,1]$.\n- Singularity at $x=1$ ($f_{\\alpha,1}$), $\\alpha = 0.25$, $N = 2^{5} = 32$, mapping $[0,1)$.\n- Singularity at $x=1$ ($f_{\\alpha,1}$), $\\alpha = 0.25$, $N = 2^{5} = 32$, mapping $(0,1]$.\n- Singularity at $x=1$ ($f_{\\alpha,1}$), $\\alpha = 0.25$, $N = 2^{10} = 1024$, mapping $[0,1)$.\n- Singularity at $x=1$ ($f_{\\alpha,1}$), $\\alpha = 0.25$, $N = 2^{10} = 1024$, mapping $(0,1]$.\n- Singularity at $x=1$ ($f_{\\alpha,1}$), $\\alpha = 0.75$, $N = 2^{5} = 32$, mapping $[0,1)$.\n- Singularity at $x=1$ ($f_{\\alpha,1}$), $\\alpha = 0.75$, $N = 2^{5} = 32$, mapping $(0,1]$.\n- Singularity at $x=1$ ($f_{\\alpha,1}$), $\\alpha = 0.75$, $N = 2^{10} = 1024$, mapping $[0,1)$.\n- Singularity at $x=1$ ($f_{\\alpha,1}$), $\\alpha = 0.75$, $N = 2^{10} = 1024$, mapping $(0,1]$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the exact order listed above (from the first bullet to the last). Each entry must be a floating-point number representing the absolute error $E$ for that test case as defined above. No physical units are involved; all quantities are dimensionless. The program must be self-contained and require no user input.", "solution": "The problem requires a computational demonstration of how mapping conventions for a low-discrepancy point set affect the error of a quasi-Monte Carlo (QMC) estimator when the integrand possesses a boundary singularity.\n\n**1. Principles of Quasi-Monte Carlo Integration**\nThe QMC method approximates the definite integral of a function $f$ over the unit hypercube $[0,1)^s$ by averaging the function's values over a deterministic set of $N$ points, $\\{x_0, x_1, \\dots, x_{N-1}\\}$, chosen to be highly uniform. For a one-dimensional integral over $[0,1]$, the estimator is:\n$$\n\\hat{I}_N(f) = \\frac{1}{N} \\sum_{i=0}^{N-1} f(x_i)\n$$\nThe error of this estimator depends on the properties of both the function $f$ and the point set. The Koksma-Hlawka inequality provides an error bound of the form $E \\le V(f) D_N^*$, where $V(f)$ is the variation of the function in the sense of Hardy and Krause and $D_N^*$ is the star-discrepancy of the point set.\n\n**2. Integrands with Boundary Singularities**\nThe specified integrands are $f_{\\alpha,0}(x) = x^{-\\alpha}$ and $f_{\\alpha,1}(x) = (1-x)^{-\\alpha}$, where $\\alpha \\in (0,1)$. These functions are integrable on $[0,1]$, with the true value of the integral being:\n$$\nI(\\alpha) = \\int_{0}^{1} x^{-\\alpha} \\, dx = \\int_{0}^{1} (1-x)^{-\\alpha} \\, dx = \\left[ \\frac{x^{1-\\alpha}}{1-\\alpha} \\right]_0^1 = \\frac{1}{1-\\alpha}\n$$\nHowever, these functions have infinite variation, $V(f) = \\infty$, due to the singularities at $x=0$ and $x=1$, respectively. Consequently, the standard Koksma-Hlawka error bound is not useful, and the convergence behavior of the QMC estimator becomes more complex and sensitive to the placement of the points $x_i$, particularly near the singularities.\n\n**3. The Sobol Sequence and its Critical Property**\nThe experiment uses the one-dimensional Sobol sequence. A fundamental property of the standard base-$2$ construction of this sequence is that for a set of $N=2^m$ points, the first point is always $x_0 = 0$. This property is the linchpin of the experiment.\n\n**4. Analysis of Mapping Conventions**\nThe experiment compares two mappings for the Sobol points $x_i \\in [0,1)$:\n- **$[0,1)$ mapping**: The evaluation points are $p_i = x_i$.\n- **$(0,1]$ mapping**: The evaluation points are $p_i = 1 - x_i$.\n\nLet us analyze the effect of these mappings for each integrand.\n\n**Case A: Singularity at $x=0$ ($f_{\\alpha,0}(x) = x^{-\\alpha}$)**\n- **$[0,1)$ mapping**: The points used are the Sobol points $x_i$ themselves. The first point is $p_0 = x_0 = 0$. The evaluation $f_{\\alpha,0}(p_0)$ hits the singularity directly. The problem specifies a numerical clipping rule: the evaluation $0^{-\\alpha}$ is computed as $\\varepsilon^{-\\alpha}$, where $\\varepsilon$ is the smallest positive double-precision float. This yields an enormous value, which will dominate the sum $\\sum f(p_i)$ and make the estimator $\\hat{I}_N$ extremely large, resulting in a very high absolute error $E = |\\hat{I}_N - I(\\alpha)|$.\n- **$(0,1]$ mapping**: The points used are $p_i = 1 - x_i$. The first point becomes $p_0 = 1 - x_0 = 1$. The function value is $f_{\\alpha,0}(1) = 1^{-\\alpha} = 1$. All other points $p_i$ are in $(0, 1)$, bounded away from the singularity at $0$. No evaluation points are pathologically close to the singularity, so the QMC estimator is expected to be well-behaved and yield a comparatively small error.\n\n**Case B: Singularity at $x=1$ ($f_{\\alpha,1}(x) = (1-x)^{-\\alpha}$)**\n- **$[0,1)$ mapping**: The points used are $p_i = x_i \\in [0,1)$. All points are strictly less than $1$ except for the non-existent case of $N \\to \\infty$. Thus, no point directly hits the singularity at $x=1$. We expect a well-behaved estimator and a small error.\n- **$(0,1]$ mapping**: The points used are $p_i = 1 - x_i$. The first point becomes $p_0 = 1 - x_0 = 1$. The evaluation $f_{\\alpha,1}(p_0) = (1-1)^{-\\alpha} = 0^{-\\alpha}$ hits the singularity. As in Case A, the clipping rule will produce the value $\\varepsilon^{-\\alpha}$, leading to a massive estimation error.\n\n**5. Algorithm Design**\nThe computational procedure for each test case is as follows:\n1.  Define the test case parameters: the function type ($f_{\\alpha,0}$ or $f_{\\alpha,1}$), the singularity strength $\\alpha$, the number of points $N$, and the mapping ($[0,1)$ or $(0,1]$).\n2.  Generate the first $N$ points of the one-dimensional unscrambled Sobol sequence, $\\{x_i\\}_{i=0}^{N-1}$, using a standard library function.\n3.  Apply the chosen mapping to produce the evaluation points $\\{p_i\\}$.\n4.  Determine the vector of values $\\{v_i\\}$ that form the base of the power function. For $f_{\\alpha,0}(p_i)$, this is $v_i = p_i$. For $f_{\\alpha,1}(p_i)$, this is $v_i = 1 - p_i$.\n5.  Apply the numerical stability clipping: replace any $v_i=0$ with $\\varepsilon$. This is implemented as $v'_i = \\max(v_i, \\varepsilon)$.\n6.  Calculate the function values $f_i = (v'_i)^{-\\alpha}$.\n7.  Compute the QMC estimate $\\hat{I}_N = \\frac{1}{N} \\sum_{i=0}^{N-1} f_i$.\n8.  Calculate the true integral value $I(\\alpha) = \\frac{1}{1-\\alpha}$.\n9.  Compute the absolute error $E = |\\hat{I}_N - I(\\alpha)|$.\n10. Store the error $E$.\n\nThis procedure systematically executes the described experiment and will produce a set of error values demonstrating the predicted behavior: the mapping that causes an evaluation point to coincide with a singularity will produce a dramatically larger error than the mapping that avoids it. The provided Python code implements this algorithm precisely.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import qmc\n\ndef solve():\n    \"\"\"\n    Performs a computational experiment to demonstrate the effect of point set\n    mapping on QMC integration error for functions with boundary singularities.\n    \"\"\"\n    # Define the smallest positive double-precision float for numerical stability.\n    EPSILON = np.finfo(float).tiny\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Singularity at x=0 (f_alpha_0)\n        {'func': 'f_alpha_0', 'alpha': 0.25, 'N': 32, 'mapping': '[0,1)'},\n        {'func': 'f_alpha_0', 'alpha': 0.25, 'N': 32, 'mapping': '(0,1]'},\n        {'func': 'f_alpha_0', 'alpha': 0.25, 'N': 1024, 'mapping': '[0,1)'},\n        {'func': 'f_alpha_0', 'alpha': 0.25, 'N': 1024, 'mapping': '(0,1]'},\n        {'func': 'f_alpha_0', 'alpha': 0.75, 'N': 32, 'mapping': '[0,1)'},\n        {'func': 'f_alpha_0', 'alpha': 0.75, 'N': 32, 'mapping': '(0,1]'},\n        {'func': 'f_alpha_0', 'alpha': 0.75, 'N': 1024, 'mapping': '[0,1)'},\n        {'func': 'f_alpha_0', 'alpha': 0.75, 'N': 1024, 'mapping': '(0,1]'},\n        # Singularity at x=1 (f_alpha_1)\n        {'func': 'f_alpha_1', 'alpha': 0.25, 'N': 32, 'mapping': '[0,1)'},\n        {'func': 'f_alpha_1', 'alpha': 0.25, 'N': 32, 'mapping': '(0,1]'},\n        {'func': 'f_alpha_1', 'alpha': 0.25, 'N': 1024, 'mapping': '[0,1)'},\n        {'func': 'f_alpha_1', 'alpha': 0.25, 'N': 1024, 'mapping': '(0,1]'},\n        {'func': 'f_alpha_1', 'alpha': 0.75, 'N': 32, 'mapping': '[0,1)'},\n        {'func': 'f_alpha_1', 'alpha': 0.75, 'N': 32, 'mapping': '(0,1]'},\n        {'func': 'f_alpha_1', 'alpha': 0.75, 'N': 1024, 'mapping': '[0,1)'},\n        {'func': 'f_alpha_1', 'alpha': 0.75, 'N': 1024, 'mapping': '(0,1]'},\n    ]\n\n    results = []\n    for case in test_cases:\n        N = case['N']\n        alpha = case['alpha']\n        mapping = case['mapping']\n        func_type = case['func']\n\n        # Generate the first N points of the 1D Sobol sequence.\n        # Per the problem, N is a power of 2. Re-initializing the sampler ensures\n        # we get the first N points, including the critical point at x=0.\n        sampler = qmc.Sobol(d=1, scramble=False)\n        base_points = sampler.random(n=N).flatten()\n\n        # Apply the specified mapping to get the evaluation points.\n        if mapping == '[0,1)':\n            eval_points = base_points\n        elif mapping == '(0,1]':\n            eval_points = 1 - base_points\n        else:\n            # This case should not be reached with the given test suite.\n            raise ValueError(f\"Unknown mapping type: {mapping}\")\n\n        # Determine the argument to the power function based on integrand type.\n        # For f_alpha_0(x) = x**(-alpha), the argument is the point itself.\n        # For f_alpha_1(x) = (1-x)**(-alpha), the argument is (1 - point).\n        if func_type == 'f_alpha_0':\n            values_to_power = eval_points\n        else: # func_type == 'f_alpha_1'\n            values_to_power = 1 - eval_points\n\n        # Apply clipping for numerical stability before exponentiation.\n        # This handles cases where values_to_power contains a 0.\n        clipped_values = np.maximum(values_to_power, EPSILON)\n        \n        # Evaluate the function at the points.\n        f_values = clipped_values**(-alpha)\n\n        # Compute the QMC estimate (arithmetic mean).\n        qmc_estimate = np.mean(f_values)\n\n        # Compute the true integral value.\n        true_integral = 1 / (1 - alpha)\n\n        # Compute and store the absolute error.\n        error = np.abs(qmc_estimate - true_integral)\n        results.append(error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3318589"}]}