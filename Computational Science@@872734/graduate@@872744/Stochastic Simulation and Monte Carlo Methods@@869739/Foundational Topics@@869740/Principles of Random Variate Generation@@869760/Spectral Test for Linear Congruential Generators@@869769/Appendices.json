{"hands_on_practices": [{"introduction": "Before we can leverage computational tools to analyze complex generators, it is essential to build a solid theoretical foundation. This exercise guides you through the fundamental mechanics of the spectral test from first principles. By deriving the dual lattice condition and performing a direct calculation for a simple Linear Congruential Generator (LCG), you will uncover the intimate link between the generator's algebraic parameters and the geometric structure of its output points, forming a crucial first step toward mastering this powerful analytical technique [@problem_id:3318079].", "problem": "A Linear Congruential Generator (LCG) is defined by the recurrence $X_{n+1} \\equiv a X_n + c \\pmod{m}$ with integers $m \\geq 2$, $0 \\leq a < m$, and $0 \\leq c < m$, and the normalized output $U_n = X_n/m \\in [0,1)$. In the context of stochastic simulation and Monte Carlo methods, the spectral test evaluates the lattice structure formed by the set of $t$-dimensional output tuples $S_t = \\{(U_n, U_{n+1}, \\dots, U_{n+t-1}) : n \\in \\mathbb{Z}\\}$.\n\nUsing only the fundamental definition of the LCG and standard properties of modular arithmetic and linear forms, do the following:\n\n1. Define rigorously the spectral test in dimension $t$ for an LCG, including the notion of the dual lattice of $S_t$ and the figure of merit based on the shortest nonzero dual vector in the Euclidean norm.\n2. Starting from the recurrence $X_{n+1} \\equiv a X_n + c \\pmod{m}$ and the normalized outputs $U_n = X_n/m$, derive the dual lattice associated with the set of $t$-tuples $(U_n,\\dots,U_{n+t-1})$, expressing it explicitly as a subset of $\\mathbb{Z}^t$ in terms of $a$ and $m$.\n3. For the specific LCG with parameters $(m,a,c) = (31,3,0)$ in dimension $t=2$, compute the Euclidean norm of the shortest nonzero vector in the dual lattice you derived. Provide the final numerical value exactly (no rounding), and express it as a single real number or a single closed-form analytic expression.", "solution": "The problem as stated is valid. It is scientifically grounded in the established theory of pseudo-random number generation, specifically the analysis of Linear Congruential Generators (LCGs) via the spectral test. The problem is well-posed, with all necessary parameters and definitions provided, leading to a unique and verifiable solution. It is objective and contains no metaphysical or subjective claims. The tasks are logically sequenced and directly relevant to the topic of stochastic simulation and Monte Carlo methods.\n\nWe will proceed by first defining the spectral test, then deriving the general form of the dual lattice for an LCG, and finally computing the required norm for the specific parameters given.\n\n### Part 1: Definition of the Spectral Test\n\nA Linear Congruential Generator is defined by the recurrence relation $X_{n+1} \\equiv a X_n + c \\pmod{m}$, from which normalized outputs $U_n = X_n / m$ are obtained. The spectral test assesses the quality of an LCG by examining the geometric structure of the set of $t$-dimensional vectors of successive outputs, $S_t = \\{(U_n, U_{n+1}, \\dots, U_{n+t-1}) : n \\in \\mathbb{Z}\\}$.\n\nThe points in $S_t$ do not fill the $t$-dimensional unit hypercube $[0,1)^t$ uniformly, but are instead confined to a finite number of parallel hyperplanes. This discrete structure is a manifestation of a mathematical object called a lattice. The full set of integer vectors $\\mathbf{z} = (z_1, \\dots, z_t)$ that satisfy the LCG's recurrence congruences forms a lattice $L_t$. The points of the LCG, $(X_n, \\dots, X_{n+t-1})$, form a subset of this lattice (or a shifted version of it if $c \\neq 0$).\n\nThe spectral test is defined through the analysis of the **dual lattice**, denoted $L_t^*$. The dual lattice $L_t^*$ is the set of all integer vectors $\\mathbf{v} = (v_1, \\dots, v_t) \\in \\mathbb{Z}^t$ such that the dot product $\\mathbf{v} \\cdot \\mathbf{u}$ is an integer for every vector $\\mathbf{u} \\in S_t$:\n$$L_t^* = \\{\\mathbf{v} \\in \\mathbb{Z}^t \\mid \\forall \\mathbf{u} \\in S_t, \\mathbf{v} \\cdot \\mathbf{u} \\in \\mathbb{Z}\\}$$\nGeometrically, a non-zero vector $\\mathbf{v} \\in L_t^*$ is normal to a family of parallel hyperplanes given by $\\mathbf{v} \\cdot \\mathbf{x} = k$ for integers $k$, upon which all points of the generator's output lie. The distance between adjacent hyperplanes in this family is $1/||\\mathbf{v}||_2$, where $||\\cdot||_2$ denotes the Euclidean norm.\n\nFor a generator to be considered \"good,\" its output points should be as uniformly distributed as possible, implying the lattice structure should be \"fine\" rather than \"coarse.\" This means the minimum distance between any family of parallel hyperplanes containing all the points should be as large as possible. This is equivalent to finding the shortest possible non-zero vector in the dual lattice.\n\nThe **figure of merit** for the spectral test in dimension $t$, denoted $\\nu_t$, is therefore the Euclidean norm of the shortest non-zero vector in the dual lattice $L_t^*$:\n$$\\nu_t = \\min \\{ ||\\mathbf{v}||_2 \\mid \\mathbf{v} \\in L_t^*, \\mathbf{v} \\neq \\mathbf{0} \\}$$\nA larger value of $\\nu_t$ indicates a better (finer) lattice structure for the LCG in dimension $t$.\n\n### Part 2: Derivation of the Dual Lattice\n\nTo derive the explicit form of the dual lattice, we start with its definition. A vector $\\mathbf{v} = (v_1, \\dots, v_t) \\in \\mathbb{Z}^t$ is in $L_t^*$ if and only if $\\mathbf{v} \\cdot \\mathbf{U}_n \\in \\mathbb{Z}$ for all generated vectors $\\mathbf{U}_n = (U_n, \\dots, U_{n+t-1})$. Using the normalization $U_k = X_k/m$, this condition is equivalent to:\n$$\\frac{1}{m} \\sum_{j=1}^{t} v_j X_{n+j-1} \\in \\mathbb{Z}$$\nThis, in turn, is equivalent to the congruence:\n$$\\sum_{j=1}^{t} v_j X_{n+j-1} \\equiv 0 \\pmod{m}$$\nThis congruence must hold for all integer sequences $(X_n, X_{n+1}, \\dots)$ produced by the LCG.\n\nThe structure of the dual lattice is related to the fundamental spacing of the generator's lattice, which is determined by the multiplicative part of the recurrence. The additive constant $c$ merely induces a rigid translation of the entire lattice of points, which does not affect the dual lattice. Therefore, we can analyze the dual lattice by considering the homogeneous case where $c=0$, i.e., $X_{n+1} \\equiv a X_n \\pmod{m}$. This recurrence implies $X_{n+k} \\equiv a^k X_n \\pmod{m}$ for any $k \\geq 0$.\n\nSubstituting this into our congruence condition for the dual lattice vectors:\n$$\\sum_{j=1}^{t} v_j (a^{j-1} X_n) \\equiv 0 \\pmod{m}$$\n$$X_n \\left( \\sum_{j=1}^{t} v_j a^{j-1} \\right) \\equiv 0 \\pmod{m}$$\nFor a non-trivial generator (one that does not produce a constant sequence of zeros), the state $X_n$ will take on various non-zero values modulo $m$. For the above congruence to hold for all possible values of $X_n$, the coefficient of $X_n$ must be a multiple of $m$. Thus, we arrive at the defining condition for the dual lattice:\n$$\\sum_{j=1}^{t} v_j a^{j-1} \\equiv 0 \\pmod{m}$$\nThe dual lattice $L_t^*$ is therefore the set of all integer vectors $\\mathbf{v} = (v_1, \\dots, v_t)$ that satisfy this linear congruence:\n$$L_t^* = \\left\\{ \\mathbf{v} \\in \\mathbb{Z}^t \\mid v_1 + a v_2 + a^2 v_3 + \\dots + a^{t-1} v_t \\equiv 0 \\pmod m \\right\\}$$\nThis is the explicit expression for the dual lattice in terms of $a$ and $m$.\n\n### Part 3: Computation for $(m,a,c)=(31,3,0)$ in $t=2$\n\nWe are given the parameters $m=31$, $a=3$, and $t=2$. We seek the Euclidean norm of the shortest non-zero vector in the dual lattice $L_2^*$. Using the derived condition from Part 2 for $t=2$:\n$$L_2^* = \\left\\{ (v_1, v_2) \\in \\mathbb{Z}^2 \\mid v_1 + a v_2 \\equiv 0 \\pmod m \\right\\}$$\nSubstituting the given values:\n$$v_1 + 3v_2 \\equiv 0 \\pmod{31}$$\nThis congruence implies that $v_1$ can be expressed in terms of $v_2$ and an integer $k$:\n$$v_1 = -3v_2 + 31k, \\quad \\text{for } v_2, k \\in \\mathbb{Z}$$\nThe vectors in the dual lattice are of the form $\\mathbf{v} = (-3v_2 + 31k, v_2)$. We want to find the minimum Euclidean norm of such a vector, subject to the constraint that $\\mathbf{v} \\neq \\mathbf{0}$, which is equivalent to $(v_2, k) \\neq (0,0)$.\n\nThe squared Euclidean norm is:\n$$||\\mathbf{v}||_2^2 = v_1^2 + v_2^2 = (-3v_2 + 31k)^2 + v_2^2$$\nWe now search for integers $v_2$ and $k$ that minimize this positive-definite quadratic form. Let's analyze the expression by considering small integer values for $k$.\n\nCase 1: $k=0$.\nThe squared norm becomes $||\\mathbf{v}||_2^2 = (-3v_2)^2 + v_2^2 = 9v_2^2 + v_2^2 = 10v_2^2$.\nTo find the shortest non-zero vector, we take the smallest non-zero integer magnitude for $v_2$, which is $|v_2|=1$. Let's choose $v_2=1$. This gives $v_1 = -3(1) + 31(0) = -3$. The vector is $(-3, 1)$.\nThe squared norm is $||\\mathbf{v}||_2^2 = 10(1)^2 = 10$.\n\nCase 2: $k=1$.\nThe squared norm is $||\\mathbf{v}||_2^2 = (-3v_2 + 31)^2 + v_2^2 = 10v_2^2 - 186v_2 + 961$.\nThis is a parabola in $v_2$ that opens upwards. Its minimum occurs at $v_2 = -(-186)/(2 \\cdot 10) = 9.3$. We must check the neighboring integer values, $v_2=9$ and $v_2=10$.\nIf $v_2=9$: $v_1 = -3(9) + 31(1) = -27 + 31 = 4$. Vector is $(4, 9)$.\n$||\\mathbf{v}||_2^2 = 4^2 + 9^2 = 16 + 81 = 97$.\nIf $v_2=10$: $v_1 = -3(10) + 31(1) = -30 + 31 = 1$. Vector is $(1, 10)$.\n$||\\mathbf{v}||_2^2 = 1^2 + 10^2 = 1 + 100 = 101$.\nThe minimum for $k=1$ is $97$, which is greater than $10$.\n\nCase 3: $k=-1$.\nThe squared norm is $||\\mathbf{v}||_2^2 = (-3v_2 - 31)^2 + v_2^2 = 10v_2^2 + 186v_2 + 961$.\nThe minimum occurs at $v_2 = -186/20 = -9.3$. We check the integers $v_2=-9$ and $v_2=-10$.\nIf $v_2=-9$: $v_1 = -3(-9) + 31(-1) = 27 - 31 = -4$. Vector is $(-4, -9)$.\n$||\\mathbf{v}||_2^2 = (-4)^2 + (-9)^2 = 16 + 81 = 97$.\nThis is again greater than $10$.\n\nFor $|k| \\geq 2$, the term $(31k)^2$ alone is at least $(31 \\times 2)^2 = 62^2 = 3844$, which is much larger than $10$. The minimum of the quadratic form $10v_2^2 - 186kv_2 + 961k^2$ is bounded below by approximately $96.1k^2$, which grows rapidly with $k$. It is clear that larger magnitudes of $k$ will not yield a smaller norm.\n\nBy comparing the results, the minimum squared norm is $10$, achieved by the vectors $(\\mp 3, \\pm 1)$. The Euclidean norm of the shortest non-zero vector in the dual lattice is the square root of this value.\n$$\\nu_2 = \\min \\{ ||\\mathbf{v}||_2 \\mid \\mathbf{v} \\in L_2^*, \\mathbf{v} \\neq \\mathbf{0} \\} = \\sqrt{10}$$\nThe final answer is requested as an exact numerical value.", "answer": "$$\\boxed{\\sqrt{10}}$$", "id": "3318079"}, {"introduction": "With the theoretical groundwork in place, we now move to computational analysis, where the practical implications of the spectral test become apparent. This practice challenges you to implement and evaluate several LCGs, including a historically infamous example known for its poor performance in three dimensions. By using a computational proxy for the spectral test based on singular value decomposition, you will directly visualize and quantify the undesirable planar structures that a poor generator can produce, bridging the gap between abstract lattice theory and concrete generator failure [@problem_id:2442705].", "problem": "You will implement and quantitatively evaluate a three-dimensional manifestation of the spectral test for linear congruential generators, focusing on whether the triplets $\\left(u_i,u_{i+1},u_{i+2}\\right)$ fill the unit cube $\\left[0,1\\right)^3$ uniformly or collapse onto a small number of nearly parallel planes. Your program must be a complete, runnable implementation that produces a single-line output as specified below.\n\nBackground and fundamental base: A Linear Congruential Generator (LCG) is defined by\n$$\nx_{n+1} \\equiv (a x_n + c) \\;\\; \\mathrm{mod} \\;\\; m,\n\\quad\nu_n = \\frac{x_n}{m},\n$$\nwith integer modulus $m$, multiplier $a$, increment $c$, and seed $x_0$. If the $u_n$ are ideal independent uniform random variables on $\\left[0,1\\right)$, then the point set of triplets $\\left(u_i,u_{i+1},u_{i+2}\\right)$ should fill $\\left[0,1\\right)^3$ without visible structure. However, for many LCGs, these points lie on a relatively small number of planes due to the underlying lattice structure. The spectral test in $t$ dimensions assesses this by examining short vectors in the dual lattice; in $3$ dimensions, this manifests as detecting layering of points on parallel planes. We will approximate this detection by projecting the triplets onto the direction of minimal variance and counting how many distinct layers are occupied after quantization. Additionally, we will cross-check uniform fill with a Pearson Chi-Square ($\\chi^2$) test on a $3$-dimensional histogram.\n\nYour tasks:\n- Implement an LCG generator from first principles for given $(m,a,c,x_0)$ and produce $N$ values $u_n \\in [0,1)$.\n- Form the $3$-dimensional point cloud of consecutive triplets $\\left(u_i,u_{i+1},u_{i+2}\\right)$ for $i=0,\\dots,N-3$.\n- Implement two diagnostics:\n  1. A Pearson Chi-Square ($\\chi^2$) occupancy test on a $3$-dimensional histogram:\n     - Partition each axis into $B$ equal bins with $B=8$, yielding $B^3$ voxels.\n     - Let $M=N-2$ be the number of triplets. Under the null hypothesis of independent uniform fill, the expected count per voxel is $E = M / B^3$.\n     - Compute the statistic\n       $$\n       \\chi^2 = \\sum_{j=1}^{B^3} \\frac{(O_j - E)^2}{E},\n       $$\n       where $O_j$ is the observed count in voxel $j$.\n     - Use the chi-square distribution with $\\nu = B^3 - 1$ degrees of freedom to compute the survival function (the right-tail probability, i.e., the $p$-value). Declare a histogram-uniformity failure if the $p$-value is less than $\\alpha = 0.001$.\n  2. A plane-layer occupancy score approximating the spectral test:\n     - Center the $M \\times 3$ data matrix $P$ whose rows are $\\left(u_i,u_{i+1},u_{i+2}\\right)$ by subtracting the column means to obtain $P_c$.\n     - Compute the singular value decomposition $P_c = U \\Sigma V^\\top$. Let $v_3$ be the right singular vector corresponding to the smallest singular value (the direction of minimal variance).\n     - Project onto this direction to obtain the scalar sequence $t_i = (P_c v_3)_i$ for $i = 0,\\dots,M-1$.\n     - Linearly map $\\{t_i\\}$ to the interval $\\left[0,1\\right]$ using $t_i' = (t_i - \\min t)/(\\max t - \\min t)$.\n     - Quantize $\\{t_i'\\}$ into $B_p$ equally spaced bins with $B_p = 256$, count the number of occupied bins $K_\\mathrm{occ}$, and declare a planar-layer failure if $K_\\mathrm{occ} \\leq P_\\mathrm{th}$ with $P_\\mathrm{th} = 32$.\n- Combine the two diagnostics for a final decision: declare that the generator fails to fill the cube uniformly if either the histogram-uniformity test fails or the planar-layer test fails.\n\nTest suite:\nProvide results for the following cases, each specified by $(m,a,c,x_0,N)$:\n- Case $1$ (known bad in $3$D): $m = 2^{31}$, $a = 65539$, $c = 0$, $x_0 = 1$, $N = 50000$.\n- Case $2$ (minimal standard multiplicative, generally good in low dimensions): $m = 2^{31} - 1$, $a = 16807$, $c = 0$, $x_0 = 1$, $N = 50000$.\n- Case $3$ (deliberately small modulus, highly degenerate): $m = 2^{16}$, $a = 109$, $c = 0$, $x_0 = 1$, $N = 50000$.\n- Case $4$ (popular $32$-bit LCG with smaller sample size): $m = 2^{32}$, $a = 1664525$, $c = 1013904223$, $x_0 = 12345$, $N = 8192$.\n\nAnswer specification:\n- For each case, your program must output a boolean indicating whether the generator fails according to the combined criterion described above (boolean True means \"fails\", boolean False means \"passes\").\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the cases listed above (e.g., $\\left[\\mathrm{result}_1,\\mathrm{result}_2,\\mathrm{result}_3,\\mathrm{result}_4\\right]$).\n- No physical units or angles are involved. Do not print any additional text.\n\nScientific realism, principles, and constraints:\n- Build from the definition of an LCG, the concept of independent uniform variates, and the well-established Pearson Chi-Square test with the chi-square distribution.\n- The plane-layer occupancy is a principled approximation for the $3$-dimensional spectral test: if $\\left(u_i,u_{i+1},u_{i+2}\\right)$ lie on a small number of parallel planes, projection along a normal direction collapses the data into a small number of quantized layers, making $K_\\mathrm{occ}$ small.\n- Use exactly $\\alpha = 0.001$, $B = 8$, $B^3 = 512$, $B_p = 256$, and $P_\\mathrm{th} = 32$ as specified above for all cases.", "solution": "The user has submitted a problem for validation and solution.\n\n### Step 1: Extract Givens\n\nThe problem statement provides the following definitions, parameters, and procedures:\n\n1.  **Linear Congruential Generator (LCG) Definition**:\n    - Recurrence relation: $x_{n+1} \\equiv (a x_n + c) \\pmod m$\n    - Normalized output: $u_n = x_n / m$\n    - Parameters: modulus $m$, multiplier $a$, increment $c$, seed $x_0$.\n\n2.  **Point Cloud Formation**:\n    - Form triplets $(u_i, u_{i+1}, u_{i+2})$ for $i=0, \\dots, N-3$.\n    - The total number of triplets is $M = N-2$.\n\n3.  **Diagnostic 1: Pearson Chi-Square ($\\chi^2$) Test**:\n    - Partition the unit cube $[0,1)^3$ into $B^3$ voxels.\n    - Number of bins per axis: $B = 8$. Total voxels: $B^3 = 512$.\n    - Expected count per voxel: $E = M / B^3$.\n    - Chi-square statistic: $\\chi^2 = \\sum_{j=1}^{B^3} \\frac{(O_j - E)^2}{E}$, where $O_j$ is the observed count in voxel $j$.\n    - Degrees of freedom: $\\nu = B^3 - 1 = 511$.\n    - Failure condition: The p-value (survival function of the $\\chi^2$ distribution) is less than the significance level $\\alpha = 0.001$.\n\n4.  **Diagnostic 2: Plane-Layer Occupancy Score**:\n    - Center the $M \\times 3$ data matrix $P$ of triplets to get $P_c$.\n    - Compute the Singular Value Decomposition (SVD): $P_c = U \\Sigma V^\\top$.\n    - Identify the direction of minimal variance, $v_3$, which is the right singular vector corresponding to the smallest singular value.\n    - Project the centered data onto this direction: $t_i = (P_c v_3)_i$.\n    - Normalize the projections: $t_i' = (t_i - \\min t)/(\\max t - \\min t)$ to map them to $[0,1]$.\n    - Quantize $\\{t_i'\\}$ into $B_p = 256$ bins.\n    - Count the number of occupied bins, $K_\\mathrm{occ}$.\n    - Failure condition: $K_\\mathrm{occ} \\leq P_\\mathrm{th}$, where the threshold is $P_\\mathrm{th} = 32$.\n\n5.  **Combined Failure Criterion**:\n    - The generator fails if either the $\\chi^2$ test fails OR the plane-layer test fails.\n\n6.  **Test Cases** (specified as $(m, a, c, x_0, N)$):\n    - Case 1: $(2^{31}, 65539, 0, 1, 50000)$\n    - Case 2: $(2^{31} - 1, 16807, 0, 1, 50000)$\n    - Case 3: $(2^{16}, 109, 0, 1, 50000)$\n    - Case 4: $(2^{32}, 1664525, 1013904223, 12345, 8192)$\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem is subjected to validation against the specified criteria.\n\n-   **Scientifically Grounded**: The problem is firmly rooted in computational physics and statistics. Linear Congruential Generators, the Pearson $\\chi^2$ test, and the spectral test are all standard, well-established topics. The plane-layer occupancy score is a direct and practical implementation of the principle behind the spectral test, using Singular Value Decomposition to find the direction of minimal variance—a standard technique from Principal Component Analysis. The problem is scientifically sound and free of pseudoscience.\n\n-   **Well-Posed**: The problem is well-posed. All parameters ($m, a, c, x_0, N$), constants ($B, \\alpha, B_p, P_\\mathrm{th}$), and methodologies are explicitly defined. The task is to compute a boolean outcome for each of the four distinct cases, which allows for a unique and stable solution.\n\n-   **Objective**: The language is precise, mathematical, and algorithmic. It is free of subjectivity or opinion.\n\n-   **Incomplete or Contradictory Setup**: The problem is self-contained. It provides all necessary information to proceed with a computational solution. There are no contradictions in the provided data or constraints.\n\n-   **Unrealistic or Infeasible**: The computations required are feasible on standard hardware. The parameters for the LCGs are representative of generators found in scientific literature and practice. The number of points $N$ is large enough for statistical significance but small enough for efficient computation.\n\n-   **Ill-Posed or Poorly Structured**: The problem is structured logically, guiding the user from data generation to the application of two distinct tests and a final combined conclusion. The terms are well-defined.\n\n-   **Outside Scientific Verifiability**: The results are computationally deterministic and verifiable. An independent implementation following the same specifications should produce identical results.\n\n### Step 3: Verdict and Action\n\nThe problem is **valid**. It is scientifically sound, well-posed, objective, and computationally tractable. I will proceed with providing a complete solution.\n\n### Solution\n\nThe objective is to assess the quality of four specific Linear Congruential Generators (LCGs) by testing whether the point cloud of successive triplets $(u_i, u_{i+1}, u_{i+2})$ uniformly fills the three-dimensional unit cube. This is accomplished using two quantitative tests: a Pearson $\\chi^2$ test for volumetric occupancy and an approximate spectral test based on planar collapse.\n\n**Step 1: LCG Sequence Generation**\nFirst, for each case defined by the parameters $(m, a, c, x_0)$, we generate a sequence of $N$ integers $\\{x_n\\}_{n=0}^{N-1}$ using the recurrence relation $x_{n+1} \\equiv (a x_n + c) \\pmod m$. The initial value is $x_0$. It is critical to perform the intermediate calculation $a \\cdot x_n$ using a sufficiently large integer type (e.g., 64-bit integer or Python's arbitrary-precision integers) to prevent overflow, as the product can exceed the capacity of a 32-bit integer, which is the order of magnitude of the modulus $m$ in several cases. The integer sequence is then normalized to produce floating-point numbers in the interval $[0,1)$ via the transformation $u_n = x_n / m$.\n\n**Step 2: Formation of 3D Point Cloud**\nFrom the sequence $\\{u_n\\}_{n=0}^{N-1}$, we construct $M = N-2$ overlapping triplets $p_i = (u_i, u_{i+1}, u_{i+2})$ for $i = 0, \\dots, N-3$. These $M$ points form a point cloud in the unit cube $[0,1)^3$. For computational purposes, they are arranged into an $M \\times 3$ matrix $P$.\n\n**Step 3: Test 1 - Pearson $\\chi^2$ Goodness-of-Fit Test**\nThis test evaluates the null hypothesis $H_0$ that the triplets are drawn from a uniform distribution over the unit cube.\n1.  The cube is partitioned into a grid of $B^3$ disjoint voxels, with $B=8$. This gives $8^3 = 512$ voxels.\n2.  The observed number of points, $O_j$, falling into each voxel $j$ is counted. This is achieved by computing a 3D histogram of the point cloud $P$.\n3.  Under $H_0$, the expected number of points in any given voxel is uniform: $E = M / B^3 = (N-2) / 512$.\n4.  The $\\chi^2$ statistic is calculated as the sum of squared, normalized deviations of observed from expected counts:\n    $$\n    \\chi^2 = \\sum_{j=1}^{B^3} \\frac{(O_j - E)^2}{E}\n    $$\n5.  If $H_0$ is true, this statistic approximately follows a chi-square distribution with $\\nu = B^3 - 1 = 511$ degrees of freedom. We compute the $p$-value, which is the probability of observing a $\\chi^2$ value as large or larger than the one measured, assuming $H_0$ is true. This corresponds to the survival function of the distribution, $p = P(\\chi^2_\\nu \\geq \\chi^2_\\mathrm{observed})$.\n6.  The test is declared a \"failure\" if this $p$-value is below the specified significance level $\\alpha = 0.001$. A small $p$-value suggests that the observed distribution of points is significantly different from uniform.\n\n**Step 4: Test 2 - Planar Layer Occupancy Score**\nThis test is a practical approximation of the spectral test, designed to detect if the points, rather than filling space, are confined to a small number of parallel planes—a classic failure mode of LCGs.\n1.  The point cloud is centered by subtracting the mean of each coordinate, yielding the matrix $P_c = P - \\bar{P}$, where $\\bar{P}$ contains the column-wise means of $P$.\n2.  We perform a Singular Value Decomposition (SVD) on the centered data matrix: $P_c = U \\Sigma V^\\top$. The columns of $V$ (or rows of $V^\\top$) represent the principal axes of the point cloud's distribution. The corresponding singular values in the diagonal matrix $\\Sigma$ are proportional to the standard deviation of the data along these axes.\n3.  The direction of minimal variance in the data is given by the principal axis corresponding to the smallest singular value. This vector, denoted $v_3$, is the last column of $V$ (or last row of $V^\\top$). If the points lie on planes, this direction will be approximately normal to these planes.\n4.  The centered data points are projected onto this direction by computing the dot products $t = P_c v_3$. This collapses the 3D data into a 1D sequence of scalar values.\n5.  These scalar projections $\\{t_i\\}$ are linearly rescaled to fit into the interval $[0,1]$ using the transformation $t'_i = (t_i - \\min(t)) / (\\max(t) - \\min(t))$.\n6.  The rescaled projections $\\{t'_i\\}$ are quantized into $B_p = 256$ bins. We then count the number of bins that are non-empty, which we call the number of occupied layers, $K_\\mathrm{occ}$.\n7.  If the original points were confined to a small number of planes, their projections will cluster into a small number of locations. The test is declared a \"failure\" if $K_\\mathrm{occ}$ is less than or equal to a threshold $P_\\mathrm{th} = 32$.\n\n**Step 5: Final Evaluation**\nFor each of the four test cases, both tests are performed. The generator is judged to fail to fill the unit cube uniformly (result is `True`) if the condition (`chi2_fails` OR `plane_fails`) is met. Otherwise, it passes (result is `False`). The boolean results for the four cases, in order, are then reported.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Main function to run the LCG tests and print the final results.\n    \"\"\"\n    \n    # Test cases defined as (m, a, c, x0, N)\n    test_cases = [\n        # Case 1: RANDU, known bad 3D generator\n        {'m': 2**31, 'a': 65539, 'c': 0, 'x0': 1, 'N': 50000},\n        # Case 2: Park-Miller (MINSTD), generally good in low dimensions\n        {'m': 2**31 - 1, 'a': 16807, 'c': 0, 'x0': 1, 'N': 50000},\n        # Case 3: Small modulus, highly degenerate\n        {'m': 2**16, 'a': 109, 'c': 0, 'x0': 1, 'N': 50000},\n        # Case 4: Numerical Recipes LCG, smaller sample size\n        {'m': 2**32, 'a': 1664525, 'c': 1013904223, 'x0': 12345, 'N': 8192},\n    ]\n    \n    # Test parameters\n    params = {\n        'B': 8,           # Number of bins per axis for Chi-square test\n        'alpha': 0.001,   # Significance level for Chi-square p-value\n        'Bp': 256,        # Number of bins for plane-layer test\n        'P_th': 32        # Occupied bin threshold for plane-layer test\n    }\n    \n    results = []\n    for case in test_cases:\n        fails = run_lcg_test(case['m'], case['a'], case['c'], case['x0'], case['N'], params)\n        results.append(fails)\n        \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_lcg_test(m, a, c, x0, N, params):\n    \"\"\"\n    Performs the full LCG quality analysis for a single case.\n    \n    Returns:\n        bool: True if the generator fails, False otherwise.\n    \"\"\"\n    # Step 1: Generate LCG sequence\n    # Use Python's arbitrary-precision integers to avoid overflow during generation\n    x_seq = [0] * N\n    x_seq[0] = x0\n    for i in range(N - 1):\n        x_seq[i+1] = (a * x_seq[i] + c) % m\n    \n    u = np.array(x_seq, dtype=np.float64) / m\n    \n    # Step 2: Form 3D point cloud\n    M = N - 2\n    if M <= 0:\n        # Not enough points to form even one triplet\n        return True # Fails by default if not enough data\n        \n    # Create triplets (u_i, u_{i+1}, u_{i+2})\n    P = np.stack((u[:-2], u[1:-1], u[2:]), axis=1)\n\n    # Step 3: Pearson Chi-Square Test\n    B = params['B']\n    alpha = params['alpha']\n    \n    observed_counts, _ = np.histogramdd(\n        P, bins=B, range=((0, 1), (0, 1), (0, 1))\n    )\n    \n    B_cubed = B**3\n    expected_count = M / B_cubed\n    \n    # Calculate Chi-square statistic\n    # Use where to avoid division by zero if expected_count is zero\n    chi2_stat = np.sum(\n        np.divide((observed_counts - expected_count)**2, expected_count, \n                  out=np.zeros_like(observed_counts, dtype=np.float64), \n                  where=expected_count!=0)\n    )\n    \n    dof = B_cubed - 1\n    p_value = chi2.sf(chi2_stat, dof)\n    \n    chi2_fails = p_value < alpha\n\n    # Step 4: Plane-Layer Occupancy Score\n    Bp = params['Bp']\n    P_th = params['P_th']\n    \n    # Center the data\n    P_c = P - np.mean(P, axis=0)\n    \n    # Compute SVD. We only need Vh (V transpose).\n    try:\n        _, _, Vh = np.linalg.svd(P_c, full_matrices=False)\n    except np.linalg.LinAlgError:\n        # SVD can fail if the matrix is degenerate, e.g., all points are identical.\n        # This is a catastrophic failure of the generator.\n        return True\n\n    # Direction of minimal variance is the last row of Vh\n    v3 = Vh[-1, :]\n    \n    # Project data onto this direction\n    t = P_c @ v3\n    \n    # Handle case where t has zero range (all projections are identical)\n    t_min, t_max = t.min(), t.max()\n    if t_max == t_min:\n        K_occ = 1\n    else:\n        # Normalize projections to [0, 1]\n        t_prime = (t - t_min) / (t_max - t_min)\n        \n        # Quantize and count occupied bins\n        # np.histogram is robust for this task\n        counts, _ = np.histogram(t_prime, bins=Bp, range=(0, 1))\n        K_occ = np.count_nonzero(counts)\n    \n    plane_fails = K_occ <= P_th\n\n    # Step 5: Combined Decision\n    return chi2_fails or plane_fails\n\nsolve()\n```", "id": "2442705"}, {"introduction": "The ultimate test of understanding is often not analysis, but synthesis. This final practice flips the conventional problem on its head, moving you from the role of an analyst to that of a designer. Instead of evaluating a given LCG, you will solve an inverse problem: given a set of desired (and flawed) hyperplane structures, your task is to engineer the LCG parameters $(a,m)$ that produce them. This exercise solidifies your understanding by using the principles of the spectral test as a creative tool for construction [@problem_id:3345804].", "problem": "Consider a Linear Congruential Generator (LCG) defined by the recurrence $x_{n+1} \\equiv a x_n \\pmod{m}$ with integer multiplier $a$ and modulus $m$, and no additive increment. For a fixed dimension $t \\geq 2$, it is well known that blocks of $t$ successive outputs form points on a lattice in $\\mathbb{R}^t$ after scaling by $1/m$. The spectral test assesses the quality of such generators by examining the dual lattice: integer vectors that define families of parallel hyperplanes on which the points lie. In this problem, you will formulate and solve an inverse design problem guided by first principles, using only core definitions and recurrence properties.\n\nStarting from the recurrence definition and the interpretation of the $t$-dimensional point $(x_n, x_{n+1}, \\ldots, x_{n+t-1})$, derive the necessary and sufficient condition under which an integer normal vector $h = (h_0, h_1, \\ldots, h_{t-1}) \\in \\mathbb{Z}^t$ corresponds to a family of hyperplanes that contains all such $t$-tuples for a given $(a,m)$. Then, based on this condition, pose the following inverse problem:\n\nGiven a set of $r$ desired hyperplane normals $h^{(1)}, \\ldots, h^{(r)} \\in \\mathbb{Z}^t$, and integer bounds $2 \\leq a \\leq A_{\\max}$ and $2 \\leq m \\leq M_{\\max}$, choose $(a,m)$ that makes each $h^{(i)}$ as close as possible to being a short vector in the dual lattice associated with the LCG. Define the feasibility of a choice $(a,m)$ as the existence of exact dual-lattice membership for all $h^{(i)}$, and define an approximation error in a dimensionless form (no physical units) that measures how far each $h^{(i)}$ is from satisfying the derived congruence condition. Your derivation must start from the recurrence $x_{n+1} \\equiv a x_n \\pmod{m}$ and the definition of the $t$-dimensional sequence points, and proceed to a condition expressed entirely in terms of $(a,m)$ and the coefficients of $h^{(i)}$, without appealing to pre-stated spectral test formulas.\n\nAlgorithmic task:\n- For each integer $a$ with $2 \\leq a \\leq A_{\\max}$, compute the quantities implied by your derived condition for each $h^{(i)}$. Search over $m$ in the range $2 \\leq m \\leq M_{\\max}$ to determine:\n  1. Whether there exists a nontrivial exact solution (feasible), i.e., all $h^{(i)}$ satisfy the derived condition simultaneously.\n  2. If not feasible, the $m$ that minimizes the maximum dimensionless approximation error across $i=1,\\ldots,r$, with ties broken in favor of larger $m$.\n- Over all $a$, select the $(a,m)$ pair that is feasible if any feasible pair exists; among feasible pairs, prefer the largest $m$ (with ties broken by the smallest $a$). If no feasible pair exists, select the pair that minimizes the maximum approximation error (then prefer larger $m$, then smaller $a$).\n\nReport, for each test case:\n- The selected $a$ (integer).\n- The selected $m$ (integer).\n- A feasibility flag (boolean).\n- The maximal approximation error across $h^{(i)}$ (float).\n- The individual approximation errors for each $h^{(i)}$ (floats), in the order given.\n\nThe approximation error is a pure number and must be given as a decimal.\n\nTest suite:\nFor each test case below, $t$ is the length of each normal vector. Use the provided $A_{\\max}$ and $M_{\\max}$.\n\n1. Happy-path single-constraint case (guaranteed feasibility at multiple $a$):\n   - $t=5$, $r=1$,\n   - $h^{(1)} = (20,-9,1,0,0)$,\n   - $A_{\\max} = 50$, $M_{\\max} = 5000$.\n\n2. Conflicting constraints case (no nontrivial exact feasibility):\n   - $t=5$, $r=2$,\n   - $h^{(1)} = (20,-9,1,0,0)$, $h^{(2)} = (1,0,0,0,0)$,\n   - $A_{\\max} = 50$, $M_{\\max} = 5000$.\n\n3. Multi-constraint case with nontrivial common structure:\n   - $t=5$, $r=3$,\n   - $h^{(1)} = (0,-1,0,1,0)$, $h^{(2)} = (0,-1,1,0,0)$, $h^{(3)} = (0,0,-1,0,1)$,\n   - $A_{\\max} = 30$, $M_{\\max} = 1000$.\n\n4. Boundary case with minimal modulus:\n   - $t=4$, $r=1$,\n   - $h^{(1)} = (1,1,1,1)$,\n   - $A_{\\max} = 3$, $M_{\\max} = 2$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case result is itself a comma-separated list in square brackets. For example, the overall shape must be like\n$[ [\\text{case1\\_elements}], [\\text{case2\\_elements}], \\ldots ]$,\nwith no spaces in the line. Concretely, each inner list must be\n$[a,m,\\text{feasible},E_{\\max},E_1,\\ldots,E_r]$ where $E_{\\max}$ and $E_i$ are decimals.\n\nAll angles and physical units are irrelevant in this problem; all reported quantities are unitless. The only accepted types for each element are boolean, integer, or float. Your program must be self-contained and produce the exact single-line output in the required format when run.", "solution": "The user wants me to act as a meticulous STEM professor.\n\nMy task is to first validate a given problem statement and then, if it's valid, provide a detailed solution and a Python script to solve it.\n\nThe problem is about the spectral test for Linear Congruential Generators (LCGs).\n\nLet's break down the problem statement and follow the required validation steps.\n\n**Step 1: Extract Givens**\n\n- **LCG Definition**: $x_{n+1} \\equiv a x_n \\pmod{m}$\n- **Multiplier**: $a$, an integer.\n- **Modulus**: $m$, an integer.\n- **No additive increment**: $c=0$.\n- **Dimension**: $t \\geq 2$.\n- **$t$-dimensional points**: $u_n = (x_n, x_{n+1}, \\ldots, x_{n+t-1})$. These points, after scaling by $1/m$, lie on a lattice in $\\mathbb{R}^t$.\n- **Dual Lattice**: The spectral test examines the dual lattice. The vectors of this dual lattice are integer vectors $h = (h_0, h_1, \\ldots, h_{t-1}) \\in \\mathbb{Z}^t$. These vectors define families of parallel hyperplanes containing the points $u_n$.\n- **Derivation Task**: Derive the necessary and sufficient condition for an integer vector $h$ to be a normal vector for a family of hyperplanes containing all $t$-tuples $u_n$. The derivation must start from the recurrence and the definition of $u_n$.\n- **Inverse Problem**: Given a set of $r$ desired hyperplane normals $h^{(1)}, \\ldots, h^{(r)} \\in \\mathbb{Z}^t$ and bounds $2 \\leq a \\leq A_{\\max}$ and $2 \\leq m \\leq M_{\\max}$, choose $(a,m)$ to make each $h^{(i)}$ \"as close as possible\" to being a short vector in the dual lattice.\n- **Feasibility Definition**: A pair $(a,m)$ is feasible if all $h^{(i)}$ are exact dual-lattice members.\n- **Approximation Error Definition**: Define a dimensionless error that measures how far each $h^{(i)}$ is from satisfying the derived condition.\n- **Algorithmic Task**:\n    - Iterate $a$ from $2$ to $A_{\\max}$.\n    - For each $a$, iterate $m$ from $2$ to $M_{\\max}$.\n    - For each pair $(a,m)$:\n        - Check for feasibility: all $h^{(i)}$ satisfy the condition.\n        - If not feasible, calculate the maximum dimensionless approximation error across all $h^{(i)}$.\n    - The search logic for $(m)$ for a fixed $a$ is:\n        1. Find if a feasible $m$ exists.\n        2. If not, find the $m$ that minimizes the maximum error. Tie-break with larger $m$.\n- **Selection Criteria**:\n    1. If any feasible $(a,m)$ pairs exist: select the one with the largest $m$. If there's a tie in $m$, select the one with the smallest $a$.\n    2. If no feasible pairs exist: select the $(a,m)$ pair that minimizes the maximum approximation error. If there's a tie in error, select the one with the largest $m$. If there's a tie in both error and $m$, select the one with the smallest $a$.\n- **Reported values per test case**:\n    - `a` (integer)\n    - `m` (integer)\n    - `feasible` (boolean)\n    - `E_max` (float, maximum approximation error)\n    - `E_1, E_2, ...` (floats, individual approximation errors)\n- **Approximation Error format**: \"pure number\", \"decimal\".\n- **Test Cases**:\n    1. $t=5, r=1, h^{(1)} = (20,-9,1,0,0), A_{\\max} = 50, M_{\\max} = 5000$.\n    2. $t=5, r=2, h^{(1)} = (20,-9,1,0,0), h^{(2)} = (1,0,0,0,0), A_{\\max} = 50, M_{\\max} = 5000$.\n    3. $t=5, r=3, h^{(1)} = (0,-1,0,1,0), h^{(2)} = (0,-1,1,0,0), h^{(3)} = (0,0,-1,0,1), A_{\\max} = 30, M_{\\max} = 1000$.\n    4. $t=4, r=1, h^{(1)} = (1,1,1,1), A_{\\max} = 3, M_{\\max} = 2$.\n- **Output Format**: Single line, `[[case1_results], [case2_results], ...]`. Inner list: `[a,m,feasible,E_max,E_1,...,E_r]`. No spaces.\n\n**Step 2: Validate Using Extracted Givens**\n\n1.  **Scientific or Factual Unsoundness**: The problem is correctly framed within the mathematical theory of Linear Congruential Generators and the spectral test, a standard method for assessing their quality. The concepts are standard and factually sound.\n2.  **Non-Formalizable or Irrelevant**: The problem is directly and formally related to the specified topic.\n3.  **Incomplete or Contradictory Setup**: The problem is self-contained. It requires the derivation of the central condition and an error metric, but provides all necessary first principles to do so. The recurrence relation, the definition of the vector sequence, and the concept of a dual lattice vector are sufficient to derive the necessary condition. The definition of the optimization problem, including the search space, objective function, and tie-breaking rules, is complete and unambiguous.\n4.  **Unrealistic or Infeasible**: The parameters and bounds provided in the test cases are computationally manageable and do not involve any physical inconsistencies.\n5.  **Ill-Posed or Poorly Structured**: The problem is well-posed. The derivation leads to a unique formal condition. The optimization procedure is explicitly defined with a clear hierarchy of criteria, ensuring a unique solution exists.\n6.  **Pseudo-Profound, Trivial, or Tautological**: The problem is non-trivial, requiring a sound derivation from first principles and the implementation of a specific multi-objective optimization algorithm. It correctly tests the understanding of the underlying theory.\n7.  **Outside Scientific Verifiability**: The problem is a formal mathematical and computational exercise, and its solution is fully verifiable.\n\n**Verdict**: The problem is valid.\n\n### Step-by-Step Solution\n\n#### Part 1: Derivation of the Dual Lattice Condition\n\nThe problem requires us to derive the condition for an integer vector $h \\in \\mathbb{Z}^t$ to be a member of the dual lattice associated with a Linear Congruential Generator (LCG).\n\n1.  **LCG and State Vectors**: The LCG is defined by the recurrence relation $x_{n+1} \\equiv a x_n \\pmod{m}$, where $a$ is the multiplier and $m$ is the modulus. We consider sequences of $t$ consecutive outputs, which form vectors $u_n = (x_n, x_{n+1}, \\ldots, x_{n+t-1}) \\in \\mathbb{Z}_m^t$.\n\n2.  **Lattice and Hyperplanes**: The points of the LCG, when scaled by $1/m$, form a set of vectors $v_n = u_n / m$ within the $t$-dimensional unit hypercube $[0,1)^t$. These points do not fill the space uniformly but lie on a finite number of parallel hyperplanes. A family of such hyperplanes is defined by an integer normal vector $h = (h_0, h_1, \\ldots, h_{t-1}) \\in \\mathbb{Z}^t$. A point $v$ lies on one of these hyperplanes if its dot product with $h$ is an integer, i.e., $h \\cdot v = k$ for some $k \\in \\mathbb{Z}$.\n\n3.  **Condition for Containment**: For all points $v_n$ generated by the LCG to lie on this family of hyperplanes, the condition $h \\cdot v_n \\in \\mathbb{Z}$ must hold for all $n$. Substituting $v_n = u_n/m$, we get:\n    $$\n    h \\cdot \\frac{u_n}{m} = \\frac{1}{m} \\sum_{i=0}^{t-1} h_i x_{n+i} \\in \\mathbb{Z}\n    $$\n    This is equivalent to the congruence relation:\n    $$\n    \\sum_{i=0}^{t-1} h_i x_{n+i} \\equiv 0 \\pmod{m}\n    $$\n    This condition must hold for any sequence $(x_n, x_{n+1}, \\ldots)$ produced by the generator.\n\n4.  **Using the LCG Recurrence**: We can express each component $x_{n+i}$ in terms of the initial value of the sequence, $x_n$, by repeatedly applying the LCG recurrence:\n    $$\n    x_{n+1} \\equiv a x_n \\pmod{m}\n    $$\n    $$\n    x_{n+2} \\equiv a x_{n+1} \\equiv a(a x_n) \\equiv a^2 x_n \\pmod{m}\n    $$\n    $$\n    \\vdots\n    $$\n    $$\n    x_{n+i} \\equiv a^i x_n \\pmod{m}\n    $$\n\n5.  **Final Condition**: Substituting this into the congruence from step 3:\n    $$\n    \\sum_{i=0}^{t-1} h_i (a^i x_n) \\pmod{m} \\equiv 0 \\pmod{m}\n    $$\n    We can factor out $x_n$:\n    $$\n    x_n \\left( \\sum_{i=0}^{t-1} h_i a^i \\right) \\equiv 0 \\pmod{m}\n    $$\n    For a good LCG (e.g., one with a full period), the state $x_n$ will take on many different values modulo $m$, including values coprime to $m$. For this equation to hold universally for all $x_n$ (including, for instance, $x_n=1$, which can be set as an initial seed), the term in the parenthesis must be a multiple of $m$. This yields the necessary and sufficient condition for $h$ to be a vector in the dual lattice:\n    $$\n    S(h,a) \\equiv \\sum_{i=0}^{t-1} h_i a^i \\equiv 0 \\pmod{m}\n    $$\n\n#### Part 2: Definition of the Approximation Error\n\nWhen the condition $S(h,a) \\equiv 0 \\pmod{m}$ is not met, we need a measure of \"how far\" it is from being satisfied. This is the approximation error.\n\n1.  **Distance to Feasibility**: The condition fails if $S(h,a)$ is not a multiple of $m$. The magnitude of this failure can be quantified by the distance from $S(h,a)$ to the nearest integer multiple of $m$. This distance is given by $\\min_{k \\in \\mathbb{Z}} |S(h,a) - k \\cdot m|$.\n\n2.  **Calculating the Distance**: Let $rem = S(h,a) \\pmod m$, where the result of the modulo operation is taken in the range $[0, m-1]$. The distance to the nearest multiple of $m$ is then $\\min(rem, m - rem)$.\n\n3.  **Dimensionless Error**: To create a dimensionless error measure, we normalize this distance by the modulus $m$. The approximation error for a given normal vector $h$ and LCG parameters $(a,m)$ is therefore defined as:\n    $$\n    E(h,a,m) = \\frac{1}{m} \\min\\left( S(h,a) \\pmod m, m - (S(h,a) \\pmod m) \\right)\n    $$\n    This error $E$ is a pure number in the range $[0, 0.5]$. An error of $E=0$ signifies that $h$ is an exact dual lattice vector (feasibility), while an error of $E=0.5$ represents the worst possible case.\n\n#### Part 3: Algorithmic Design for the Inverse Problem\n\nThe task is to find the optimal pair $(a,m)$ from the given ranges that satisfies a hierarchical set of criteria for a given set of normal vectors $\\{h^{(1)}, \\ldots, h^{(r)}\\}$.\n\n1.  **Search Strategy**: The problem requires a search over all possible integer pairs $(a,m)$ where $2 \\leq a \\leq A_{\\max}$ and $2 \\leq m \\leq M_{\\max}$. The selection process is structured as a two-level optimization. First, for each value of $a$, we find the \"best\" corresponding value of $m$. Then, we compare these best pairs across all values of $a$ to find the overall global optimum.\n\n2.  **Inner Optimization (Finding best $m$ for a given $a$)**: For a fixed $a$, we iterate through all possible $m \\in [2, M_{\\max}]$. For each pair $(a,m)$, we calculate the individual errors $E_i = E(h^{(i)}, a, m)$ for all $i=1, \\ldots, r$, and find the maximum error $E_{\\max}(a,m) = \\max_{i} E_i$.\n    - We maintain two pieces of information for the current $a$:\n        - The largest $m$ found so far that results in a feasible solution ($E_{\\max}=0$).\n        - The non-feasible solution $(m, E_{\\max})$ that has the smallest $E_{\\max}$. Ties in $E_{\\max}$ are broken by choosing the larger $m$.\n    - After checking all $m$, if any feasible solution was found, the candidate for this $a$ is the feasible solution with the largest $m$. Otherwise, it is the best non-feasible solution found.\n\n3.  **Outer Optimization (Finding best overall $(a,m)$ pair)**: We maintain a single global best solution found so far across all values of $a$. As we generate the best candidate pair for each $a$, we compare it to the current global best using the specified hierarchical criteria:\n    - **Criterion 1 (Feasibility)**: A feasible solution is always preferred over a non-feasible one.\n    - **Criterion 2 (Error Maximization - for non-feasible pairs)**: If comparing two non-feasible solutions, the one with the smaller maximum error $E_{\\max}$ is preferred.\n    - **Criterion 3 (Modulus Maximization)**: If the primary criterion (feasibility or error) results in a tie, the solution with the larger modulus $m$ is preferred.\n    - **Criterion 4 (Multiplier Minimization)**: If all preceding criteria result in a tie, the solution with the smaller multiplier $a$ is preferred. This is handled naturally by iterating $a$ in increasing order and only updating the best solution on strict improvement in the higher-priority criteria.\n\n4.  **Final Reporting**: Once the entire search space has been explored, the globally optimal pair $(a,m)$ is determined. For this pair, we re-calculate the individual errors $E_i$ for each $h^{(i)}$, the maximum error $E_{\\max}$, and the feasibility flag. These values are then formatted and reported as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the LCG inverse design problem for a suite of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: Happy-path single-constraint case\n        {\n            \"A_max\": 50, \"M_max\": 5000,\n            \"h_vectors\": [np.array([20, -9, 1, 0, 0], dtype=object)]\n        },\n        # Case 2: Conflicting constraints case\n        {\n            \"A_max\": 50, \"M_max\": 5000,\n            \"h_vectors\": [np.array([20, -9, 1, 0, 0], dtype=object),\n                          np.array([1, 0, 0, 0, 0], dtype=object)]\n        },\n        # Case 3: Multi-constraint case with common structure\n        {\n            \"A_max\": 30, \"M_max\": 1000,\n            \"h_vectors\": [np.array([0, -1, 0, 1, 0], dtype=object),\n                          np.array([0, -1, 1, 0, 0], dtype=object),\n                          np.array([0, 0, -1, 0, 1], dtype=object)]\n        },\n        # Case 4: Boundary case with minimal modulus\n        {\n            \"A_max\": 3, \"M_max\": 2,\n            \"h_vectors\": [np.array([1, 1, 1, 1], dtype=object)]\n        }\n    ]\n\n    all_results_str = []\n    \n    for case in test_cases:\n        A_max = case[\"A_max\"]\n        M_max = case[\"M_max\"]\n        h_vectors = case[\"h_vectors\"]\n        t_dim = len(h_vectors[0])\n\n        # Global best solution tracking\n        best_sol = {\n            'a': -1, 'm': -1, \n            'feasible': False, 'error': float('inf')\n        }\n\n        for a in range(2, A_max + 1):\n            # Pre-compute S(h, a) for each h vector for the current 'a'\n            # Using Python's arbitrary-precision integers\n            powers = np.array([pow(a, i) for i in range(t_dim)], dtype=object)\n            s_values = [h @ powers for h in h_vectors]\n\n            # Find the best 'm' for the current 'a'\n            best_feasible_m_for_a = -1\n            best_approx_m_for_a = -1\n            min_error_for_a = float('inf')\n\n            for m in range(2, M_max + 1):\n                errors = []\n                for s in s_values:\n                    rem = s % m\n                    dist = min(rem, m - rem)\n                    errors.append(dist / m)\n                \n                max_error = max(errors) if errors else 0.0\n\n                if max_error == 0.0:\n                    if m > best_feasible_m_for_a:\n                        best_feasible_m_for_a = m\n                else:\n                    if max_error < min_error_for_a:\n                        min_error_for_a = max_error\n                        best_approx_m_for_a = m\n                    elif max_error == min_error_for_a:\n                        if m > best_approx_m_for_a:\n                            best_approx_m_for_a = m\n            \n            # Determine the candidate solution for the current 'a'\n            current_a_sol = {}\n            if best_feasible_m_for_a != -1:\n                current_a_sol = {'a': a, 'm': best_feasible_m_for_a, 'feasible': True, 'error': 0.0}\n            elif best_approx_m_for_a != -1:\n                current_a_sol = {'a': a, 'm': best_approx_m_for_a, 'feasible': False, 'error': min_error_for_a}\n            else:\n                continue # No valid m found for this a\n\n            # Compare current 'a's candidate with the global best\n            # Criterion 1: Feasibility\n            if current_a_sol['feasible'] and not best_sol['feasible']:\n                best_sol = current_a_sol\n            elif current_a_sol['feasible'] == best_sol['feasible']:\n                if not current_a_sol['feasible']:\n                    # Criterion 2: Error (for non-feasible)\n                    if current_a_sol['error'] < best_sol['error']:\n                        best_sol = current_a_sol\n                        continue\n                    if current_a_sol['error'] > best_sol['error']:\n                        continue\n                \n                # Criterion 3: Modulus\n                if current_a_sol['m'] > best_sol['m']:\n                    best_sol = current_a_sol\n                # Criterion 4 (Multiplier) is handled by loop order and not updating on ties for m\n\n        # Finalize the result for the current test case\n        final_a = best_sol['a']\n        final_m = best_sol['m']\n        final_feasible = best_sol['feasible']\n        \n        # Recalculate errors for the chosen (a,m) pair\n        final_errors = []\n        if final_a != -1:\n            powers = np.array([pow(final_a, i) for i in range(t_dim)], dtype=object)\n            s_values = [h @ powers for h in h_vectors]\n            for s in s_values:\n                rem = s % final_m\n                dist = min(rem, final_m - rem)\n                final_errors.append(float(dist / final_m))\n        \n        max_final_error = max(final_errors) if final_errors else 0.0\n\n        # Assemble the final list for this case\n        case_result_list = [\n            final_a, final_m, \"true\" if final_feasible else \"false\", \n            max_final_error, *final_errors\n        ]\n        \n        # Format to string without spaces\n        case_result_str = f\"[{','.join(map(str, case_result_list))}]\"\n        all_results_str.append(case_result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```", "id": "3345804"}]}