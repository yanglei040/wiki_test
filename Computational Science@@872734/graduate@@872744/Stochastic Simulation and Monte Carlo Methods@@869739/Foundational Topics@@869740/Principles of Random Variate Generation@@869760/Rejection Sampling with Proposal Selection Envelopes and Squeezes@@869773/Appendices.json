{"hands_on_practices": [{"introduction": "The efficiency of rejection sampling depends critically on how tightly the proposal envelope conforms to the target density. For the important class of log-concave distributions, constructing an envelope from tangents to the log-density is a powerful technique, forming the basis of Adaptive Rejection Sampling (ARS). This exercise [@problem_id:3335755] provides a hands-on derivation of the relationship between the envelope's design—specifically, the placement of support points—and the sampler's acceptance rate. By optimizing the placement of these points for a standard normal target, you will develop a concrete understanding of the trade-offs that govern the performance of adaptive samplers.", "problem": "Consider a target probability density function $f(x)$ on $\\mathbb{R}$ that is log-concave, meaning $\\log f(x)$ is a concave function. In rejection sampling, one constructs an envelope function $g(x)$ such that $g(x) \\geq f(x)$ for all $x$, draws $X$ from the normalized envelope, and accepts $X$ with probability $f(X)/g(X)$. The average acceptance rate $\\alpha$ equals the ratio of the integral of $f$ to the integral of $g$. A standard way to construct efficient envelopes for log-concave targets is to use tangent lines to $\\log f$ to build a piecewise linear upper hull $u(x)$, and then take the envelope $g(x) = \\exp(u(x))$. This is the core idea behind Adaptive Rejection Sampling (ARS).\n\nYou will analyze the trade-off between the number and placement of support points (where tangents are taken) and the resulting acceptance rate $\\alpha$ for a specific, well-studied log-concave target and a restricted class of envelopes, using first principles from rejection sampling.\n\nLet the target be the standard normal density $f(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\!\\left(-\\frac{x^{2}}{2}\\right)$, which satisfies log-concavity. Consider constructing a piecewise-exponential envelope $g(x)$ from tangent lines to $\\log f(x)$ at two symmetric support points $\\{-a, +a\\}$ for some $a  0$. Let $l(x) = \\log f(x)$, and let $u_{-a}(x)$ and $u_{+a}(x)$ be the tangent lines to $l$ at $x = -a$ and $x = +a$, respectively. Define the upper hull $u(x) = \\min\\{u_{-a}(x), u_{+a}(x)\\}$ and set $g(x) = \\exp(u(x))$. Because $l$ is concave, $u(x) \\geq l(x)$ and hence $g(x) \\geq f(x)$.\n\nStarting from the fundamental rejection sampling fact that the average acceptance rate equals the ratio of the integrals of the target and the envelope, and using only the definitions above (without introducing any shortcut formulas), do the following:\n\n1. Derive a closed-form expression for the acceptance rate $\\alpha(a)$ as a function of $a$ for the envelope $g$ defined by the two symmetric support points $\\{-a, +a\\}$.\n2. Using the acceptance-rate-as-integral-ratio principle, define the expected number of target evaluations per accepted draw as $J(a) = 1/\\alpha(a)$, under the simplifying assumption that the overhead to sample from the piecewise-exponential envelope and to determine the active segment is negligible compared to evaluating $f(x)$; this isolates the core trade-off driven by the envelope’s tightness.\n3. Determine the value $a^{\\star}  0$ that minimizes $J(a)$ over this class of two-support-point envelopes, and the corresponding optimal acceptance rate $\\alpha^{\\star} = \\alpha(a^{\\star})$. Provide both $a^{\\star}$ and $\\alpha^{\\star}$ as exact expressions.\n\nYour final answer must be a single row matrix containing $a^{\\star}$ and $\\alpha^{\\star}$. No numerical rounding is required, and no units are to be included in the final expressions. Explain, based on your derivation, how the placement of support points affects $\\alpha$ and thus the evaluation cost $J$, thereby quantifying the trade-off in this restricted two-point design. Also briefly comment, conceptually, on how increasing the number of support points generally impacts $\\alpha$ and $J$ for log-concave targets constructed via tangent envelopes and how a squeeze function would further affect evaluation cost without changing $\\alpha$.", "solution": "The problem is first validated to ensure it is scientifically sound, self-contained, and well-posed.\n\n**Step 1: Extract Givens**\n-   Target probability density function: $f(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^{2}}{2}\\right)$ on $\\mathbb{R}$.\n-   Property: $f(x)$ is log-concave.\n-   Envelope construction: The envelope $g(x)$ is constructed from tangent lines to $l(x) = \\log f(x)$ at two symmetric support points $\\{-a, +a\\}$ for $a  0$.\n-   Function definitions:\n    -   $l(x) = \\log f(x)$.\n    -   $u_{-a}(x)$ and $u_{+a}(x)$ are the tangent lines to $l(x)$ at $x=-a$ and $x=+a$.\n    -   $u(x) = \\min\\{u_{-a}(x), u_{+a}(x)\\}$.\n    -   $g(x) = \\exp(u(x))$.\n-   Core principle: The average acceptance rate is $\\alpha = \\frac{\\int_{-\\infty}^{\\infty} f(x) \\,dx}{\\int_{-\\infty}^{\\infty} g(x) \\,dx}$.\n-   Cost function: Expected number of target evaluations per accepted draw is $J(a) = 1/\\alpha(a)$.\n-   Objectives:\n    1.  Derive the closed-form expression for the acceptance rate $\\alpha(a)$.\n    2.  Define $J(a)$.\n    3.  Find the optimal value $a^{\\star}  0$ that minimizes $J(a)$ and the corresponding optimal acceptance rate $\\alpha^{\\star} = \\alpha(a^{\\star})$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is valid. It is a well-posed mathematical exercise firmly grounded in the theory of rejection sampling and Adaptive Rejection Sampling (ARS). The target function is the standard normal density, and its log-concavity is a known property. The construction of the envelope from tangents is a standard technique for log-concave densities. All terms are clearly defined, the objectives are unambiguous, and no scientific or logical flaws are present. The simplifying assumption about the cost $J(a)$ is explicitly stated and serves to isolate the primary trade-off related to the envelope's tightness.\n\n**Step 3: Verdict and Action**\nThe problem is valid and a full solution will be provided.\n\n**Derivation of the Solution**\n\nThe solution proceeds by first constructing the envelope function $g(x)$, then calculating its integral to find the acceptance rate $\\alpha(a)$, and finally optimizing this rate with respect to the support point parameter $a$.\n\nFirst, we define the logarithm of the target density, $l(x)$:\n$$l(x) = \\ln(f(x)) = \\ln\\left(\\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right)\\right) = -\\frac{1}{2}\\ln(2\\pi) - \\frac{x^2}{2}$$\nThe derivative, $l'(x)$, is required to define the tangent lines:\n$$l'(x) = -x$$\nThe equation of a tangent line to $l(x)$ at a point $x_0$ is given by $y(x) = l(x_0) + l'(x_0)(x - x_0)$. We find the two tangent lines at the support points $x_0 = a$ and $x_0 = -a$.\n\nFor the support point $x_0 = a$:\n$l(a) = -\\frac{1}{2}\\ln(2\\pi) - \\frac{a^2}{2}$\n$l'(a) = -a$\nThe tangent line $u_{+a}(x)$ is:\n$$u_{+a}(x) = \\left(-\\frac{1}{2}\\ln(2\\pi) - \\frac{a^2}{2}\\right) - a(x-a) = -\\frac{1}{2}\\ln(2\\pi) + \\frac{a^2}{2} - ax$$\n\nFor the support point $x_0 = -a$:\n$l(-a) = -\\frac{1}{2}\\ln(2\\pi) - \\frac{a^2}{2}$\n$l'(-a) = -(-a) = a$\nThe tangent line $u_{-a}(x)$ is:\n$$u_{-a}(x) = \\left(-\\frac{1}{2}\\ln(2\\pi) - \\frac{a^2}{2}\\right) + a(x-(-a)) = -\\frac{1}{2}\\ln(2\\pi) + \\frac{a^2}{2} + ax$$\n\nThe upper hull $u(x)$ is the minimum of these two lines:\n$$u(x) = \\min\\{u_{-a}(x), u_{+a}(x)\\} = \\min\\left\\{-\\frac{1}{2}\\ln(2\\pi) + \\frac{a^2}{2} + ax, -\\frac{1}{2}\\ln(2\\pi) + \\frac{a^2}{2} - ax\\right\\}$$\nThis simplifies to:\n$$u(x) = -\\frac{1}{2}\\ln(2\\pi) + \\frac{a^2}{2} - a|x|$$\nThe two tangent lines intersect when $u_{-a}(x) = u_{+a}(x)$, which implies $ax = -ax$, so $2ax=0$. Since $a0$, this occurs at $x=0$. For $x  0$, $u_{-a}(x)  u_{+a}(x)$, and for $x  0$, $u_{+a}(x)  u_{-a}(x)$.\n\nThe envelope function $g(x)$ is the exponential of the upper hull $u(x)$:\n$$g(x) = \\exp(u(x)) = \\exp\\left(-\\frac{1}{2}\\ln(2\\pi) + \\frac{a^2}{2} - a|x|\\right) = \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(\\frac{a^2}{2}\\right)\\exp(-a|x|)$$\n\nThe average acceptance rate $\\alpha(a)$ is given by the ratio of the integrals of $f(x)$ and $g(x)$. The integral of the target density $f(x)$ over $\\mathbb{R}$ is, by definition, $1$:\n$$\\int_{-\\infty}^{\\infty} f(x) \\,dx = 1$$\nNext, we calculate the integral of the envelope function $g(x)$:\n$$\\int_{-\\infty}^{\\infty} g(x) \\,dx = \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(\\frac{a^2}{2}\\right) \\int_{-\\infty}^{\\infty} \\exp(-a|x|) \\,dx$$\nThe integral of $\\exp(-a|x|)$ can be computed by exploiting symmetry:\n$$\\int_{-\\infty}^{\\infty} \\exp(-a|x|) \\,dx = 2 \\int_{0}^{\\infty} \\exp(-ax) \\,dx = 2 \\left[-\\frac{1}{a}\\exp(-ax)\\right]_{0}^{\\infty} = 2\\left(0 - \\left(-\\frac{1}{a}\\right)\\right) = \\frac{2}{a}$$\nSubstituting this result back, the integral of the envelope is:\n$$I_g(a) = \\int_{-\\infty}^{\\infty} g(x) \\,dx = \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(\\frac{a^2}{2}\\right) \\frac{2}{a} = \\frac{2}{a\\sqrt{2\\pi}}\\exp\\left(\\frac{a^2}{2}\\right)$$\n\nNow we can write the expression for the acceptance rate $\\alpha(a)$:\n$$\\alpha(a) = \\frac{\\int f(x) \\,dx}{\\int g(x) \\,dx} = \\frac{1}{I_g(a)} = \\frac{a\\sqrt{2\\pi}}{2\\exp\\left(\\frac{a^2}{2}\\right)} = \\frac{a\\sqrt{2\\pi}}{2} \\exp\\left(-\\frac{a^2}{2}\\right)$$\nThis is the closed-form expression for the acceptance rate as a function of $a$. The cost function is $J(a) = 1/\\alpha(a)$.\n\nTo find the optimal support point placement $a^{\\star}$, we must minimize $J(a)$, which is equivalent to maximizing $\\alpha(a)$ for $a  0$. We compute the derivative of $\\alpha(a)$ with respect to $a$ and set it to zero.\n$$\\frac{d\\alpha}{da} = \\frac{d}{da}\\left[\\frac{\\sqrt{2\\pi}}{2} \\left(a \\exp\\left(-\\frac{a^2}{2}\\right)\\right)\\right]$$\nUsing the product rule:\n$$\\frac{d\\alpha}{da} = \\frac{\\sqrt{2\\pi}}{2} \\left[1 \\cdot \\exp\\left(-\\frac{a^2}{2}\\right) + a \\cdot \\exp\\left(-\\frac{a^2}{2}\\right) \\cdot (-a)\\right] = \\frac{\\sqrt{2\\pi}}{2} (1-a^2) \\exp\\left(-\\frac{a^2}{2}\\right)$$\nSetting the derivative to zero:\n$$\\frac{d\\alpha}{da} = 0 \\implies (1-a^2) = 0$$\nSince we require $a0$, the only critical point is $a=1$. To confirm this is a maximum, we examine the sign of the first derivative. For $0  a  1$, $1-a^2  0$ and $\\frac{d\\alpha}{da}  0$, so $\\alpha(a)$ is increasing. For $a  1$, $1-a^2  0$ and $\\frac{d\\alpha}{da}  0$, so $\\alpha(a)$ is decreasing. Thus, $a=1$ yields the global maximum for $\\alpha(a)$ over $a0$.\n\nThe optimal support point parameter is therefore:\n$$a^{\\star} = 1$$\nThe corresponding optimal acceptance rate, $\\alpha^{\\star}$, is found by substituting $a^{\\star}=1$ into the expression for $\\alpha(a)$:\n$$\\alpha^{\\star} = \\alpha(1) = \\frac{1 \\cdot \\sqrt{2\\pi}}{2} \\exp\\left(-\\frac{1^2}{2}\\right) = \\frac{\\sqrt{2\\pi}}{2} \\exp\\left(-\\frac{1}{2}\\right) = \\frac{\\sqrt{2\\pi}}{2\\sqrt{e}} = \\sqrt{\\frac{2\\pi}{4e}} = \\sqrt{\\frac{\\pi}{2e}}$$\n\n**Analysis of Trade-offs and Extensions**\n\nThe parameter $a$ controls the placement of the support points. The expression $\\alpha(a) = \\frac{a\\sqrt{2\\pi}}{2} \\exp\\left(-\\frac{a^2}{2}\\right)$ quantifies the trade-off. If $a$ is very small (close to $0$), the support points are near the mode. The tangents are nearly horizontal, creating a loose envelope with a large area, leading to a low acceptance rate ($\\alpha(a) \\to 0$ as $a \\to 0$). Conversely, if $a$ is very large, the support points are far in the tails. The tangents are very steep, creating a tight fit in the tails but forming an extremely high and narrow peak at $x=0$. The area of the envelope, dominated by this peak, becomes large again, and the acceptance rate also approaches zero ($\\alpha(a) \\to 0$ as $a \\to \\infty$). The optimal value $a^{\\star}=1$ represents the an optimal balance, placing the support points at one standard deviation from the mean, which minimizes the total area under the envelope $g(x)$ and thereby maximizes the acceptance rate $\\alpha$. This minimizes the expected number of draws $J(a)$ needed to obtain one accepted sample.\n\nIncreasing the number of support points would allow for a more refined piecewise linear upper hull $u(x)$. Since the new hull is the minimum of a larger set of tangent lines, it must lie at or below the two-point hull: $u_{\\text{new}}(x) \\leq u(x)$ for all $x$. This results in a tighter envelope, $g_{\\text{new}}(x) \\leq g(x)$, a smaller envelope integral $\\int g_{\\text{new}}(x)dx$, and thus a higher acceptance rate $\\alpha$. This reduces the cost $J$. This is the principle behind Adaptive Rejection Sampling, where points are added iteratively to improve the envelope.\n\nA squeeze function $s(x)$ is a function satisfying $0 \\le s(x) \\le f(x)$ for all $x$. In a rejection sampler, one can perform a cheap pre-test: if a uniform deviate $U$ satisfies $U \\cdot g(X) \\le s(X)$, the sample $X$ is accepted without evaluating $f(X)$. This is possible because $s(X) \\le f(X)$ guarantees that $U \\cdot g(X) \\le f(X)$ is also true. The total acceptance rate $\\alpha$ remains unchanged, as it is ultimately determined by the ratio of the areas under $f(x)$ and $g(x)$. However, the squeeze reduces the *average number of evaluations of the target function $f(x)$* per accepted sample. By allowing some samples to be accepted \"for free,\" an efficient squeeze function (one whose integral is close to that of $f(x)$) can substantially lower the overall computational cost, especially when $f(x)$ is expensive to compute, without altering the fundamental acceptance probability $\\alpha$.", "answer": "$$ \\boxed{ \\begin{pmatrix} 1  \\sqrt{\\frac{\\pi}{2e}} \\end{pmatrix} } $$", "id": "3335755"}, {"introduction": "Stochastic algorithms are increasingly applied to sensitive data, creating a need to integrate methods with privacy-preserving techniques. This practice problem [@problem_id:3335750] extends rejection sampling to a setting where the target distribution's parameters are derived from a private dataset. By injecting carefully calibrated noise via the Laplace mechanism to achieve $\\varepsilon$-differential privacy, you will explore the direct impact of this privacy guarantee on the sampling efficiency. The exercise requires you to quantify this \"cost of privacy\" by deriving how the privacy-ensuring noise inflates the rejection envelope constant $M$ and, consequently, reduces the expected acceptance probability.", "problem": "Consider a one-dimensional target density that is log-concave and data-dependent through a location parameter, specifically a Laplace distribution with known scale parameter $b_0  0$ and data-dependent location parameter $\\mu(D)$:\n$$\nf(x \\mid D) \\;=\\; \\frac{1}{2 b_0} \\exp\\!\\Big(-\\frac{|x - \\mu(D)|}{b_0}\\Big), \\quad x \\in \\mathbb{R}.\n$$\nAssume the dataset $D$ consists of $n$ real-valued observations bounded in the unit interval, so that any neighboring datasets differ in exactly one entry and the empirical mean has global sensitivity $\\Delta_1 = 1/n$. To construct an adaptive envelope for rejection sampling with a proposal that tracks the data-dependent location, we privatize the support-point update for $\\mu(D)$ via the Laplace mechanism: we release\n$$\n\\widetilde{\\mu} \\;=\\; \\widehat{\\mu}(D) \\;+\\; \\eta, \\quad \\eta \\sim \\text{Laplace}(s), \\quad s \\;=\\; \\frac{\\Delta_1}{\\varepsilon} \\;=\\; \\frac{1}{n \\varepsilon},\n$$\nwhere $\\varepsilon  0$ is the privacy budget and $\\widehat{\\mu}(D)$ is any location estimator of $\\mu(D)$ with sensitivity bounded by $\\Delta_1$ (for example, the empirical mean). Use the proposal density\n$$\nq(x \\mid \\widetilde{\\mu}) \\;=\\; \\frac{1}{2 b_0} \\exp\\!\\Big(-\\frac{|x - \\widetilde{\\mu}|}{b_0}\\Big),\n$$\nand define the rejection sampler envelope constant $M(\\eta)$ as the smallest constant such that\n$$\nf(x \\mid D) \\;\\le\\; M(\\eta)\\, q(x \\mid \\widetilde{\\mu}) \\quad \\text{for all } x \\in \\mathbb{R}.\n$$\nAssume $n \\varepsilon b_0  1$ so that the expectations below are finite.\n\nUsing only foundational definitions from rejection sampling, log-concavity, and $\\varepsilon$-differential privacy (DP) together with the Laplace mechanism, derive from first principles:\n\n1. An explicit expression for $M(\\eta)$ in terms of $b_0$ and $|\\eta|$ obtained by comparing $f(\\cdot \\mid D)$ and $q(\\cdot \\mid \\widetilde{\\mu})$ pointwise.\n2. The expected envelope inflation $\\mathbb{E}[M(\\eta)]$ with respect to the noise $\\eta \\sim \\text{Laplace}(s)$.\n3. The expected acceptance probability of the rejection sampler, $\\mathbb{E}[1/M(\\eta)]$, with respect to the noise $\\eta$.\n\nYou may use that the acceptance probability of rejection sampling with envelope $M(\\eta)\\,q(x \\mid \\widetilde{\\mu})$ equals $\\int q(x \\mid \\widetilde{\\mu}) \\frac{f(x \\mid D)}{M(\\eta)\\,q(x \\mid \\widetilde{\\mu})}\\,dx \\,=\\, \\frac{1}{M(\\eta)}$. Express your final answer as a closed-form row matrix containing, in this order, the expressions for $\\mathbb{E}[M(\\eta)]$ and $\\mathbb{E}[1/M(\\eta)]$ as functions of $n$, $\\varepsilon$, and $b_0$. No numerical rounding is required.", "solution": "The user has asked for a detailed derivation of the expected envelope inflation and the expected acceptance probability for a rejection sampler using a data-dependent Laplace target density and a privatized Laplace proposal density.\n\nThe problem will be solved in three stages as requested, following a validation step.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n- **Target Density**: $f(x \\mid D) = \\frac{1}{2 b_0} \\exp\\left(-\\frac{|x - \\mu(D)|}{b_0}\\right)$, with $b_0  0$.\n- **Dataset Properties**: $D$ has $n$ real-valued observations in $[0, 1]$. Neighboring datasets differ in one entry.\n- **Estimator Sensitivity**: The empirical mean has global sensitivity $\\Delta_1 = 1/n$.\n- **Privatized Location**: $\\widetilde{\\mu} = \\widehat{\\mu}(D) + \\eta$.\n- **Noise Distribution**: $\\eta \\sim \\text{Laplace}(s)$, where $s = \\frac{\\Delta_1}{\\varepsilon} = \\frac{1}{n \\varepsilon}$ for a privacy budget $\\varepsilon  0$.\n- **Estimator**: $\\widehat{\\mu}(D)$ is a location estimator of $\\mu(D)$ with sensitivity bounded by $\\Delta_1$.\n- **Proposal Density**: $q(x \\mid \\widetilde{\\mu}) = \\frac{1}{2 b_0} \\exp\\left(-\\frac{|x - \\widetilde{\\mu}|}{b_0}\\right)$.\n- **Envelope Constant**: $M(\\eta)$ is the smallest constant such that $f(x \\mid D) \\le M(\\eta)\\, q(x \\mid \\widetilde{\\mu})$ for all $x \\in \\mathbb{R}$.\n- **Assumption**: $n \\varepsilon b_0  1$.\n- **Acceptance Probability**: The acceptance probability is $1/M(\\eta)$.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem is scientifically grounded, well-posed, and objective. It draws on standard, verifiable principles from statistics (Laplace distribution, rejection sampling) and computer science (differential privacy, Laplace mechanism). The setup is self-contained and logically consistent. The one point of ambiguity is the relationship between $\\mu(D)$ and $\\widehat{\\mu}(D)$. However, the requirement that the first result, $M(\\eta)$, be expressed solely in terms of $b_0$ and $|\\eta|$ implicitly resolves this ambiguity by requiring that the difference $\\widehat{\\mu}(D) - \\mu(D)$ be zero. Without this assumption, the result for $M(\\eta)$ would depend on this difference, which is not provided. This interpretation makes the problem well-posed. The problem is formalizable and directly pertains to the specified topic. All constraints and data are consistent.\n\n**Step 3: Verdict and Action**\n\nThe problem is deemed **valid**. A full solution will be provided.\n\n### Derivation of the quantities of interest\n\nThe solution proceeds by first deriving an expression for the envelope constant $M(\\eta)$, and then using this expression to compute the required expectations $\\mathbb{E}[M(\\eta)]$ and $\\mathbb{E}[1/M(\\eta)]$.\n\n**1. Expression for the envelope constant $M(\\eta)$**\n\nBy definition, $M(\\eta)$ is the smallest constant satisfying the inequality $f(x \\mid D) \\le M(\\eta) q(x \\mid \\widetilde{\\mu})$, which implies that $M(\\eta)$ must be the supremum of the ratio of the two densities over their support:\n$$\nM(\\eta) = \\sup_{x \\in \\mathbb{R}} \\frac{f(x \\mid D)}{q(x \\mid \\widetilde{\\mu})}\n$$\nSubstituting the expressions for the target and proposal densities, we get:\n$$\nM(\\eta) = \\sup_{x \\in \\mathbb{R}} \\frac{\\frac{1}{2 b_0} \\exp\\left(-\\frac{|x - \\mu(D)|}{b_0}\\right)}{\\frac{1}{2 b_0} \\exp\\left(-\\frac{|x - \\widetilde{\\mu}|}{b_0}\\right)} = \\sup_{x \\in \\mathbb{R}} \\exp\\left( \\frac{|x - \\widetilde{\\mu}| - |x - \\mu(D)|}{b_0} \\right)\n$$\nSince the exponential function is monotonically increasing, we can find the supremum by maximizing the argument of the exponential:\n$$\n\\ln(M(\\eta)) = \\frac{1}{b_0} \\sup_{x \\in \\mathbb{R}} \\left( |x - \\widetilde{\\mu}| - |x - \\mu(D)| \\right)\n$$\nBy the reverse triangle inequality, for any real numbers $a$, $b$, and $c$, we have $|a - b| \\le |a-c| + |c-b|$, which can be rearranged to $|a-c| - |b-c| \\le |a-b|$. Applying this with $c=x$, $a=\\widetilde{\\mu}$, and $b=\\mu(D)$, we have:\n$$\n|x - \\widetilde{\\mu}| - |x - \\mu(D)| \\le |\\widetilde{\\mu} - \\mu(D)|\n$$\nThis upper bound is attained, for example, for any $x$ on the ray extending from $\\mu(D)$ away from $\\widetilde{\\mu}$. Thus, the supremum is exactly $|\\widetilde{\\mu} - \\mu(D)|$.\n$$\n\\sup_{x \\in \\mathbb{R}} \\left( |x - \\widetilde{\\mu}| - |x - \\mu(D)| \\right) = |\\widetilde{\\mu} - \\mu(D)|\n$$\nThe problem states that $M(\\eta)$ must be expressed in terms of $b_0$ and $|\\eta|$. We have $\\widetilde{\\mu} = \\widehat{\\mu}(D) + \\eta$. This implies that $|\\widetilde{\\mu} - \\mu(D)| = |\\widehat{\\mu}(D) - \\mu(D) + \\eta|$. For this expression to depend only on $|\\eta|$, we must assume that the estimator is exact for the given data $D$, i.e., $\\widehat{\\mu}(D) = \\mu(D)$. This is a reasonable simplifying assumption given the phrasing of the problem. Under this assumption, we have:\n$$\n|\\widetilde{\\mu} - \\mu(D)| = |\\mu(D) + \\eta - \\mu(D)| = |\\eta|\n$$\nTherefore, the envelope constant is:\n$$\nM(\\eta) = \\exp\\left(\\frac{|\\eta|}{b_0}\\right)\n$$\n\n**2. Expected envelope inflation $\\mathbb{E}[M(\\eta)]$**\n\nThe noise $\\eta$ is drawn from a Laplace distribution with scale $s$, $\\eta \\sim \\text{Laplace}(s)$, which has the probability density function $p(\\eta) = \\frac{1}{2s} \\exp\\left(-\\frac{|\\eta|}{s}\\right)$. The expectation of $M(\\eta)$ is found by integrating $M(\\eta)$ against this density:\n$$\n\\mathbb{E}[M(\\eta)] = \\int_{-\\infty}^{\\infty} M(\\eta) p(\\eta) d\\eta = \\int_{-\\infty}^{\\infty} \\exp\\left(\\frac{|\\eta|}{b_0}\\right) \\frac{1}{2s} \\exp\\left(-\\frac{|\\eta|}{s}\\right) d\\eta\n$$\nWe can simplify the integrand:\n$$\n\\mathbb{E}[M(\\eta)] = \\frac{1}{2s} \\int_{-\\infty}^{\\infty} \\exp\\left(|\\eta|\\left(\\frac{1}{b_0} - \\frac{1}{s}\\right)\\right) d\\eta\n$$\nThe integrand is an even function of $\\eta$, so we can integrate over the positive real axis and multiply by $2$:\n$$\n\\mathbb{E}[M(\\eta)] = 2 \\cdot \\frac{1}{2s} \\int_{0}^{\\infty} \\exp\\left(\\eta\\left(\\frac{1}{b_0} - \\frac{1}{s}\\right)\\right) d\\eta = \\frac{1}{s} \\int_{0}^{\\infty} \\exp\\left(\\eta\\frac{s - b_0}{s b_0}\\right) d\\eta\n$$\nFor this integral to converge, the coefficient of $\\eta$ in the exponent must be negative. This requires $s - b_0  0$, or $s  b_0$. Substituting $s = \\frac{1}{n\\varepsilon}$, this condition is $\\frac{1}{n\\varepsilon}  b_0$, which is equivalent to $n\\varepsilon b_0  1$. This is precisely the assumption given in the problem statement.\nEvaluating the integral:\n$$\n\\mathbb{E}[M(\\eta)] = \\frac{1}{s} \\left[ \\frac{1}{\\frac{s - b_0}{s b_0}} \\exp\\left(\\eta\\frac{s - b_0}{s b_0}\\right) \\right]_{0}^{\\infty} = \\frac{1}{s} \\left( 0 - \\frac{s b_0}{s - b_0} \\right) = \\frac{b_0}{b_0 - s}\n$$\nFinally, we substitute $s = \\frac{1}{n\\varepsilon}$ to express the result in terms of $n$, $\\varepsilon$, and $b_0$:\n$$\n\\mathbb{E}[M(\\eta)] = \\frac{b_0}{b_0 - \\frac{1}{n\\varepsilon}} = \\frac{b_0}{\\frac{n\\varepsilon b_0 - 1}{n\\varepsilon}} = \\frac{n\\varepsilon b_0}{n\\varepsilon b_0 - 1}\n$$\n\n**3. Expected acceptance probability $\\mathbb{E}[1/M(\\eta)]$**\n\nThe acceptance probability for a given $\\eta$ is $1/M(\\eta)$. We need to find its expectation with respect to the distribution of $\\eta$. We have $1/M(\\eta) = \\exp\\left(-\\frac{|\\eta|}{b_0}\\right)$.\n$$\n\\mathbb{E}[1/M(\\eta)] = \\int_{-\\infty}^{\\infty} \\frac{1}{M(\\eta)} p(\\eta) d\\eta = \\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{|\\eta|}{b_0}\\right) \\frac{1}{2s} \\exp\\left(-\\frac{|\\eta|}{s}\\right) d\\eta\n$$\nSimplifying the integrand:\n$$\n\\mathbb{E}[1/M(\\eta)] = \\frac{1}{2s} \\int_{-\\infty}^{\\infty} \\exp\\left(-|\\eta|\\left(\\frac{1}{b_0} + \\frac{1}{s}\\right)\\right) d\\eta\n$$\nAgain, the integrand is an even function:\n$$\n\\mathbb{E}[1/M(\\eta)] = 2 \\cdot \\frac{1}{2s} \\int_{0}^{\\infty} \\exp\\left(-\\eta\\left(\\frac{1}{b_0} + \\frac{1}{s}\\right)\\right) d\\eta = \\frac{1}{s} \\int_{0}^{\\infty} \\exp\\left(-\\eta\\frac{s+b_0}{sb_0}\\right) d\\eta\n$$\nThe coefficient in the exponent is always negative since $s, b_0  0$, so the integral always converges. Evaluating the integral:\n$$\n\\mathbb{E}[1/M(\\eta)] = \\frac{1}{s} \\left[ \\frac{1}{-\\frac{s+b_0}{sb_0}} \\exp\\left(-\\eta\\frac{s+b_0}{sb_0}\\right) \\right]_{0}^{\\infty} = \\frac{1}{s} \\left( 0 - \\frac{-sb_0}{s+b_0} \\right) = \\frac{b_0}{s+b_0}\n$$\nSubstituting $s = \\frac{1}{n\\varepsilon}$:\n$$\n\\mathbb{E}[1/M(\\eta)] = \\frac{b_0}{\\frac{1}{n\\varepsilon} + b_0} = \\frac{b_0}{\\frac{1 + n\\varepsilon b_0}{n\\varepsilon}} = \\frac{n\\varepsilon b_0}{1 + n\\varepsilon b_0}\n$$\nThe final answer requires a row matrix containing $\\mathbb{E}[M(\\eta)]$ and $\\mathbb{E}[1/M(\\eta)]$ in that order.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{n \\varepsilon b_0}{n \\varepsilon b_0 - 1}  \\frac{n \\varepsilon b_0}{n \\varepsilon b_0 + 1} \\end{pmatrix}}\n$$", "id": "3335750"}, {"introduction": "A correct algorithm on paper can fail in practice if implemented without regard for the limitations of computer arithmetic. The fundamental rejection sampling condition, $f(x) \\le M g(x)$, is a precise mathematical inequality that can be violated by floating-point rounding errors, compromising the statistical validity of the entire simulation. This exercise [@problem_id:3335791] challenges you to move from an algorithmic model to a robust numerical implementation. You will reason about floating-point error bounds to formulate a certification test that guarantees the envelope condition holds, ensuring the correctness of your sampler in a real-world computational environment.", "problem": "Consider the classical rejection sampling setup for simulating from a target distribution whose unnormalized density is $f(x)$ on a measurable domain $\\mathcal{X}$, using a proposal density $g(x)$ and an envelope constant $M  0$ such that the exact-envelope condition $f(x) \\le M g(x)$ holds for all $x \\in \\mathcal{X}$. The acceptance probability per draw, when $f$ is a probability density and $g$ is a probability density, is $1/M$. In floating-point arithmetic compliant with Institute of Electrical and Electronics Engineers 754 (IEEE 754), numerical rounding errors may cause direct tests of $f(x) \\le M g(x)$ to be unreliable if implemented naively. A robust numerical certification must therefore account for rounding errors in both $f$ and $g$ evaluations to avoid violating the envelope and compromising correctness.\n\nAssume the following fundamental base:\n- In IEEE 754, for any basic arithmetic operation $\\circ \\in \\{+, -, \\times, \\div\\}$ on real numbers $a$ and $b$, the floating-point result $\\operatorname{fl}(a \\circ b)$ satisfies $\\operatorname{fl}(a \\circ b) = (a \\circ b)(1 + \\delta)$ with $|\\delta| \\le u$, where $u$ is the unit roundoff (machine precision), and similarly for elementary functions when they are implemented with backward error guarantees.\n- For composite evaluations of $f$ and $g$, suppose a priori analysis provides data-dependent relative error bounds $\\varepsilon_f(x)$ and $\\varepsilon_g(x)$ such that the computed values $\\hat{f}(x)$ and $\\hat{g}(x)$ satisfy $\\hat{f}(x) = f(x)(1 + \\delta_f(x))$ and $\\hat{g}(x) = g(x)(1 + \\delta_g(x))$ with $|\\delta_f(x)| \\le \\varepsilon_f(x)$ and $|\\delta_g(x)| \\le \\varepsilon_g(x)$ for all $x \\in \\mathcal{X}$. These bounds arise from well-tested backward error analyses combining the unit roundoff $u$ across the operations used to evaluate $f$ and $g$.\n- A squeeze function $s(x)$ is any computable function satisfying $0 \\le s(x) \\le f(x)$ for all $x \\in \\mathcal{X}$. If $U \\sim \\mathrm{Uniform}(0, 1)$ and $X \\sim g$, then whenever $U \\le s(X)/(M g(X))$ the point can be accepted without computing $f(X)$, which reduces computational cost and can mitigate efficiency loss due to conservative envelopes.\n\nYour implementation must robustly certify the condition $f(x) \\le M g(x)$ at runtime using only $\\hat{f}(x)$ and $\\hat{g}(x)$ and the error bounds $\\varepsilon_f(x)$ and $\\varepsilon_g(x)$. In addition, you must propose a safe method for inflating $M$ to a new envelope constant to guard against rounding errors while minimizing acceptance-rate degradation.\n\nWhich option below correctly formulates a robust floating-point certification test and a safe inflation strategy that minimizes efficiency loss under the stated assumptions?\n\nA. Use the bounds to form a worst-case upper bound for $f(x)$ and a worst-case lower bound for $M g(x)$. Certify the envelope by checking\n$$\\frac{\\hat{f}(x)}{1 - \\varepsilon_f(x)} \\;\\le\\; M \\,\\frac{\\hat{g}(x)}{1 + \\varepsilon_g(x)}.$$\nIf per-evaluation certification is not desired, inflate the envelope to a data-dependent local constant\n$$M'(x) \\;=\\; M \\,\\frac{1 + \\varepsilon_f(x)}{1 - \\varepsilon_g(x)},$$\nor conservatively to a global constant\n$$M' \\;=\\; M \\,\\frac{1 + \\varepsilon_f^\\star}{1 - \\varepsilon_g^\\star},$$\nwhere $\\varepsilon_f^\\star \\ge \\sup_{x \\in \\mathcal{X}} \\varepsilon_f(x)$ and $\\varepsilon_g^\\star \\ge \\sup_{x \\in \\mathcal{X}} \\varepsilon_g(x)$. This inflation is safe because it compensates for the worst-case upward pull on $f$ and downward pull on $g$, and its impact on the acceptance rate is limited to a multiplicative factor $\\frac{1 + \\varepsilon_f^\\star}{1 - \\varepsilon_g^\\star}$. To further reduce efficiency loss, incorporate a squeeze $s(x)$ computed with downward rounding so that $\\hat{s}(x) \\le s(x)$, enabling acceptances without evaluating $f(x)$ whenever $U \\le \\hat{s}(x)/(M' \\hat{g}(x))$.\n\nB. Certify by checking\n$$\\hat{f}(x) \\;\\le\\; M \\,\\hat{g}(x)\\,\\bigl(1 + \\varepsilon_f(x) + \\varepsilon_g(x)\\bigr),$$\nand inflate with\n$$M' \\;=\\; M \\,\\bigl(1 + \\varepsilon_f^\\star + \\varepsilon_g^\\star\\bigr).$$\nThis additive aggregation of relative errors is sufficient because errors are small, and it minimizes acceptance-rate reduction.\n\nC. Use an additive tolerance. Certify by\n$$\\hat{f}(x) \\;\\le\\; M \\,\\hat{g}(x) \\;+\\; \\tau(x), \\quad \\text{where} \\quad \\tau(x) \\;=\\; u \\,\\max\\{\\hat{f}(x),\\,M \\hat{g}(x)\\}.$$\nInflate $M$ via\n$$M' \\;=\\; M \\;+\\; \\frac{\\tau^\\star}{\\inf_{x \\in \\mathcal{X}} g(x)}, \\quad \\tau^\\star \\;\\ge\\; \\sup_{x \\in \\mathcal{X}} \\tau(x),$$\nto recover the envelope globally.\n\nD. With directed rounding, compute $\\hat{f}^\\uparrow(x)$ in round-to $+\\infty$ mode and $\\hat{g}^\\downarrow(x)$ in round-to $-\\infty$ mode, then certify by\n$$\\hat{f}^\\uparrow(x) \\;\\le\\; M \\,\\hat{g}^\\downarrow(x).$$\nInflate $M$ as\n$$M' \\;=\\; M \\,(1 + u)^k,$$\nwhere $k$ is the number of floating-point operations used to evaluate $g$, which safely covers rounding error while keeping acceptance nearly unchanged.", "solution": "The problem is valid and can be solved by applying principles of floating-point error analysis to the inequalities governing rejection sampling.\n\n### I. Derivation of a Robust Certification Test\n\nThe core theoretical condition for rejection sampling is $f(x) \\le M g(x)$ for all $x \\in \\mathcal{X}$. We are given the computed values $\\hat{f}(x)$ and $\\hat{g}(x)$ with known relative error bounds $\\varepsilon_f(x)$ and $\\varepsilon_g(x)$. The relationships are:\n$$\n\\hat{f}(x) = f(x)(1 + \\delta_f(x)), \\quad |\\delta_f(x)| \\le \\varepsilon_f(x) \\\\\n\\hat{g}(x) = g(x)(1 + \\delta_g(x)), \\quad |\\delta_g(x)| \\le \\varepsilon_g(x)\n$$\nFrom these, we can express the true values $f(x)$ and $g(x)$ in terms of the computed values:\n$$\nf(x) = \\frac{\\hat{f}(x)}{1 + \\delta_f(x)} \\quad \\text{and} \\quad g(x) = \\frac{\\hat{g}(x)}{1 + \\delta_g(x)}\n$$\nAssuming $\\varepsilon_f(x)  1$ and $\\varepsilon_g(x)  1$ (which is a necessity for meaningful computation), we can establish rigorous intervals for the true values:\n$$\n\\frac{\\hat{f}(x)}{1 + \\varepsilon_f(x)} \\le f(x) \\le \\frac{\\hat{f}(x)}{1 - \\varepsilon_f(x)} \\\\\n\\frac{\\hat{g}(x)}{1 + \\varepsilon_g(x)} \\le g(x) \\le \\frac{\\hat{g}(x)}{1 - \\varepsilon_g(x)}\n$$\nTo robustly certify that $f(x) \\le M g(x)$ holds, we must show that the worst-case value of $f(x)$ is no greater than the worst-case value of $M g(x)$. The worst case corresponds to the upper bound of $f(x)$ and the lower bound of $M g(x)$.\n$$\nf_{\\text{upper}}(x) = \\frac{\\hat{f}(x)}{1 - \\varepsilon_f(x)} \\\\\n(M g)_{\\text{lower}}(x) = M g_{\\text{lower}}(x) = M \\frac{\\hat{g}(x)}{1 + \\varepsilon_g(x)}\n$$\nThus, the robust certification test, which must hold true for the condition $f(x) \\le M g(x)$ to be guaranteed, is:\n$$\nf_{\\text{upper}}(x) \\le (M g)_{\\text{lower}}(x) \\implies \\frac{\\hat{f}(x)}{1 - \\varepsilon_f(x)} \\le M \\frac{\\hat{g}(x)}{1 + \\varepsilon_g(x)}\n$$\n\n### II. Derivation of a Safe Inflation Strategy\n\nIf we do not wish to perform the certification test for each evaluation, we can instead use an inflated constant $M'  M$ that guarantees correctness. The correctness of the sampling procedure relies on the implemented acceptance probability, $\\hat{p}_{acc}(x) = \\frac{\\hat{f}(x)}{M' \\hat{g}(x)}$, being no greater than the true acceptance probability scaled by $M/M'$, i.e., $\\frac{f(x)}{M' g(x)}$. Ultimately, to prevent false acceptances, we must ensure that any point accepted by the floating-point algorithm would also be accepted by the exact algorithm. The implemented acceptance condition is $U \\le \\frac{\\hat{f}(X)}{M' \\hat{g}(X)}$ for a drawn $X \\sim g$ and $U \\sim \\mathrm{Uniform}(0,1)$. The true condition is $U \\le \\frac{f(X)}{M g(X)}$.\nTo guarantee correctness, the implemented acceptance ratio must be a lower bound on the true one:\n$$\n\\frac{\\hat{f}(x)}{M' \\hat{g}(x)} \\le \\frac{f(x)}{M g(x)}\n$$\nSubstituting the relationships $\\hat{f}(x) = f(x)(1+\\delta_f)$ and $\\hat{g}(x) = g(x)(1+\\delta_g)$:\n$$\n\\frac{f(x)(1+\\delta_f)}{M' g(x)(1+\\delta_g)} \\le \\frac{f(x)}{M g(x)}\n$$\n$$\n\\frac{1+\\delta_f}{M'(1+\\delta_g)} \\le \\frac{1}{M} \\implies M(1+\\delta_f) \\le M'(1+\\delta_g)\n$$\nTo ensure this holds for all possible errors, we must find an $M'$ that satisfies the inequality in the worst case. The term $\\frac{1+\\delta_f}{1+\\delta_g}$ is maximized when the numerator $1+\\delta_f$ is maximized and the denominator $1+\\delta_g$ is minimized:\n$$\n\\max(\\text{numerator}) = 1 + \\varepsilon_f(x) \\\\\n\\min(\\text{denominator}) = 1 - \\varepsilon_g(x)\n$$\nSo, we must choose $M'$ such that:\n$$\nM' \\ge M \\frac{1+\\varepsilon_f(x)}{1-\\varepsilon_g(x)}\n$$\nTo minimize the impact on the acceptance rate (which is $1/M'$), we should choose the smallest possible $M'$. This gives a local inflation strategy:\n$$\nM'(x) = M \\frac{1+\\varepsilon_f(x)}{1-\\varepsilon_g(x)}\n$$\nFor a globally constant $M'$, we must take the supremum over all $x \\in \\mathcal{X}$:\n$$\nM' = \\sup_{x \\in \\mathcal{X}} \\left( M \\frac{1+\\varepsilon_f(x)}{1-\\varepsilon_g(x)} \\right) = M \\sup_{x \\in \\mathcal{X}} \\left( \\frac{1+\\varepsilon_f(x)}{1-\\varepsilon_g(x)} \\right)\n$$\nUsing conservative global bounds $\\varepsilon_f^\\star \\ge \\sup_x \\varepsilon_f(x)$ and $\\varepsilon_g^\\star \\ge \\sup_x \\varepsilon_g(x)$, a safe global constant is:\n$$\nM' = M \\frac{1+\\varepsilon_f^\\star}{1-\\varepsilon_g^\\star}\n$$\n\n### III. Option-by-Option Analysis\n\n*   **A.** This option presents the certification test $\\frac{\\hat{f}(x)}{1 - \\varepsilon_f(x)} \\le M \\frac{\\hat{g}(x)}{1 + \\varepsilon_g(x)}$ and the inflation strategy $M' = M \\frac{1 + \\varepsilon_f^\\star}{1 - \\varepsilon_g^\\star}$. These match our derivations precisely. It correctly identifies that the impact on acceptance rate is a multiplicative factor. It also correctly states that for a safe squeeze test, one should use a computed value $\\hat{s}(x)$ that is a guaranteed lower bound on $s(x)$ (e.g., via downward rounding), and test against the inflated envelope $M'\\hat{g}(x)$. Every part of this option is consistent with a rigorous numerical analysis. **Correct**.\n\n*   **B.** This option proposes a certification test and inflation based on additive error aggregation, e.g., $M' = M (1 + \\varepsilon_f^\\star + \\varepsilon_g^\\star)$. This comes from a first-order approximation: $\\frac{1+\\varepsilon_f}{1-\\varepsilon_g} \\approx (1+\\varepsilon_f)(1+\\varepsilon_g) \\approx 1+\\varepsilon_f+\\varepsilon_g$. This is not a rigorous bound. A strict inequality is required for \"safe\" and \"robust\" certification, not an approximation. Higher-order terms are ignored, which can lead to an unsafe envelope constant $M'$ that is too small. Furthermore, the certification test proposed is also based on a faulty approximation. **Incorrect**.\n\n*   **C.** This option introduces an additive tolerance $\\tau(x)$ which is not derived from the provided relative error bounds $\\varepsilon_f(x)$ and $\\varepsilon_g(x)$. The form $\\tau(x) = u \\max\\{\\dots\\}$ is heuristic and only accounts for the error of a single operation, not the composite functions $f$ and $g$. The additive inflation strategy $M' = M + \\tau^\\star/\\inf g(x)$ is dimensionally inconsistent (if $g$ is a density, it has units of $1/\\text{volume}$) and can lead to pathologically large inflation if $\\inf g(x)$ is close to zero. The approach is inconsistent with the problem's premises. **Incorrect**.\n\n*   **D.** This option proposes using directed rounding, i.e., computing an upper bound $\\hat{f}^\\uparrow(x)$ for $f(x)$ and a lower bound $\\hat{g}^\\downarrow(x)$ for $g(x)$. The test $\\hat{f}^\\uparrow(x) \\le M \\hat{g}^\\downarrow(x)$ is a valid method for robust certification. However, the problem statement premises the availability of computed values $\\hat{f}(x)$ and $\\hat{g}(x)$ with a posteriori error bounds $\\varepsilon_f, \\varepsilon_g$, implying standard (e.g., round-to-nearest) arithmetic, not a special directed rounding mode. Therefore, this option proposes a different implementation methodology rather than a solution based on the given tools. Additionally, the inflation strategy $M' = M(1+u)^k$ is flawed as it only accounts for forward error propagation in $g$ and completely ignores the error in $f$. **Incorrect**.", "answer": "$$\\boxed{A}$$", "id": "3335791"}]}