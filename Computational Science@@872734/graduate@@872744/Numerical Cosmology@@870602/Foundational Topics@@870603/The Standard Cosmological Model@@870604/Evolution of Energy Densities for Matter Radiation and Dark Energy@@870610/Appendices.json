{"hands_on_practices": [{"introduction": "To understand the history of our universe, we must be able to model how its primary constituents evolve over cosmic time. This first exercise provides a foundational experience in numerical cosmology by tasking you with building an integrator for the energy densities of matter, radiation, and dark energy. Beyond simply solving the system, this practice guides you to diagnose and quantify numerical stiffness—a crucial challenge that arises when evolving a system with vastly different characteristic timescales, such as the rapid dilution of radiation compared to matter in the early universe [@problem_id:3470916].", "problem": "You are asked to build a complete, runnable program that numerically evolves the energy densities of non-relativistic matter, radiation, and dark energy in a spatially flat Friedmann–Lemaître–Robertson–Walker (FLRW) universe, using the e-fold variable $N=\\ln a$ as the independent variable. The goal is twofold: to implement the evolution using a numerical ordinary differential equation solver with $N$ as the independent variable, and to quantify the numerical stiffness near very small scale factor $a\\sim 10^{-8}$, where radiation dominates, by comparing a non-stiff and a stiff solver.\n\nFundamental base:\n- The continuity equation for a homogeneous fluid with energy density $\\rho$ and pressure $p$ is $d\\rho/dt + 3H(\\rho + p)=0$, where $H$ is the Hubble parameter and $t$ is cosmic time.\n- Defining the equation of state parameter $w(a) = p/\\rho$, the continuity equation implies $d\\ln \\rho/d\\ln a = -3(1+w(a))$.\n- Choose $N=\\ln a$ as independent variable. Then $d\\rho/dN = -3(1+w(a))\\rho$.\n\nModel assumptions:\n- Three non-interacting components evolve independently with their own equations of state: matter with $w_m = 0$, radiation with $w_r = 1/3$, and dark energy with a time-varying equation of state described by the Chevallier–Polarski–Linder (CPL) parameterization $w(a) = w_0 + w_a (1-a)$, where $w_0$ and $w_a$ are constants.\n- All densities are normalized to the present-day critical density so that they are dimensionless. Denote present-day values at $a=1$ by $\\Omega_{m0}$, $\\Omega_{r0}$, and $\\Omega_{DE0}$, with $\\Omega_{DE0} = 1 - (\\Omega_{m0} + \\Omega_{r0})$.\n\nEquations to evolve in the independent variable $N=\\ln a$:\n- Matter: $d\\rho_m/dN = -3 \\rho_m$.\n- Radiation: $d\\rho_r/dN = -4 \\rho_r$.\n- Dark energy: $d\\rho_{DE}/dN = -3\\bigl(1 + w(a)\\bigr)\\rho_{DE}$ with $w(a)=w_0+w_a(1-a)$ and $a = e^N$.\n\nQuantifying stiffness:\n- Let $J(N)$ be the Jacobian matrix of the right-hand side with respect to the state vector $(\\rho_m,\\rho_r,\\rho_{DE})$. For this autonomous linear-in-state system, $J(N)$ is diagonal with eigenvalues\n$$\n\\lambda_m(N) = -3,\\quad \\lambda_r(N) = -4,\\quad \\lambda_{DE}(N) = -3\\bigl(1 + w(a)\\bigr).\n$$\n- Define an instantaneous stiffness indicator at a given $N$ by\n$$\nS(N) = \\frac{\\max\\{|\\lambda_m(N)|,|\\lambda_r(N)|,|\\lambda_{DE}(N)|\\}}{\\max\\left(\\min\\{|\\lambda_m(N)|,|\\lambda_r(N)|,|\\lambda_{DE}(N)|\\}, \\varepsilon\\right)},\n$$\nwhere $\\varepsilon$ is a small positive number used to avoid division by zero in cases where $|\\lambda_{DE}(N)|$ vanishes, for example when $w(a)=-1$. Use $\\varepsilon = 10^{-12}$.\n- Define an empirical numerical stiffness score by comparing the number of right-hand side evaluations used by a non-stiff explicit solver versus a stiff implicit solver to integrate from $N=0$ to $N=\\ln(10^{-8})$. Specifically, integrate once with Runge–Kutta of order 5(4) (\"RK45\") and once with backward differentiation formula (\"BDF\") using the same tolerances, and compute\n$$\nR = \\frac{\\text{number of right-hand side evaluations (RK45)}}{\\text{number of right-hand side evaluations (BDF)}}.\n$$\nA value $R1$ indicates that the stiff solver achieves the same accuracy with fewer right-hand side evaluations, which is typical for stiff regimes.\n\nNumerical setup:\n- Independent variable domain: $N \\in [\\ln(10^{-8}), 0]$. Implement integration from $N=0$ down to $N=\\ln(10^{-8})$.\n- Initial conditions at $N=0$ (that is, at $a=1$): $\\rho_m(0)=\\Omega_{m0}$, $\\rho_r(0)=\\Omega_{r0}$, $\\rho_{DE}(0)=\\Omega_{DE0}$, with $\\Omega_{DE0} = 1 - (\\Omega_{m0}+\\Omega_{r0})$.\n- Use the same absolute and relative tolerances for both solvers: relative tolerance $\\mathrm{rtol} = 10^{-10}$ and absolute tolerance $\\mathrm{atol} = 10^{-12}$. Use the same right-hand side and its Jacobian for both solvers.\n\nOutputs to compute for each test case:\n- Let $N_{\\min}=\\ln(10^{-8})$ and $a_{\\min}=10^{-8}$. For each parameter set below, compute:\n  1. The ratio $\\rho_r(N_{\\min})/\\rho_m(N_{\\min})$ as a float.\n  2. The instantaneous stiffness indicator $S(N_{\\min})$ as a float.\n  3. The empirical numerical stiffness score $R$ as a float.\n\nAll three outputs are dimensionless and must be reported as floats rounded to six significant figures.\n\nTest suite (four test cases):\n- Case 1 (baseline Lambda Cold Dark Matter): $\\Omega_{m0}=0.315$, $\\Omega_{r0}=9.2\\times 10^{-5}$, $w_0=-1.0$, $w_a=0.0$.\n- Case 2 (mildly evolving dark energy with phantom today): $\\Omega_{m0}=0.30$, $\\Omega_{r0}=9.2\\times 10^{-5}$, $w_0=-0.95$, $w_a=-0.10$.\n- Case 3 (strong early-time deviation from cosmological constant): $\\Omega_{m0}=0.30$, $\\Omega_{r0}=9.2\\times 10^{-5}$, $w_0=-1.0$, $w_a=0.50$.\n- Case 4 (edge case with negligible radiation today): $\\Omega_{m0}=0.30$, $\\Omega_{r0}=1.0\\times 10^{-10}$, $w_0=-1.0$, $w_a=0.0$.\n\nImplementation requirements:\n- Use a standard numerical ODE interface that supports both an explicit Runge–Kutta 5(4) method and an implicit backward differentiation formula method with user-supplied Jacobian. Integrate from $N=0$ to $N_{\\min}$ for each method and count the number of right-hand side evaluations to compute $R$.\n- Evaluate $S(N_{\\min})$ using the analytical eigenvalues at $a=a_{\\min}$ and $\\varepsilon=10^{-12}$.\n- Compute $\\rho_r(N_{\\min})/\\rho_m(N_{\\min})$ from the numerical solution at $N_{\\min}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of four inner lists, one per test case, with no spaces, in the exact order of the test suite. Each inner list must contain the three floats in the order specified above, rounded to six significant figures. For example:\n\"[[x11,x12,x13],[x21,x22,x23],[x31,x32,x33],[x41,x42,x43]]\"", "solution": "The problem posed is a valid and well-defined exercise in numerical cosmology, grounded in the standard cosmological model. It requires the numerical integration of a system of ordinary differential equations (ODEs) that describe the evolution of the energy densities of matter, radiation, and dark energy. The problem is scientifically sound, with all parameters and equations being standard in the field. It is computationally feasible and all necessary information for a unique solution is provided.\n\nThe theoretical framework is the spatially flat Friedmann–Lemaître–Robertson–Walker (FLRW) model of the universe. The evolution of the energy density $\\rho$ of a perfect fluid component with pressure $p$ is governed by the continuity equation, $d\\rho/dt + 3H(\\rho+p) = 0$. By introducing the equation of state parameter $w=p/\\rho$ and changing the independent variable from cosmic time $t$ to the number of e-folds $N = \\ln a$, where $a$ is the cosmological scale factor, the continuity equation transforms into a first-order ODE for each component:\n$$\n\\frac{d\\rho}{dN} = -3(1+w)\\rho\n$$\nThe universe is modeled as a non-interacting mixture of three components:\n1.  **Non-relativistic matter** (cold dark matter and baryons), for which pressure is negligible, so $w_m = 0$.\n2.  **Radiation** (photons and relativistic neutrinos), which has an equation of state $w_r = 1/3$.\n3.  **Dark energy**, a component with negative pressure responsible for the accelerated expansion of the universe. Its equation of state is described by the Chevallier–Polarski–Linder (CPL) parameterization, $w(a) = w_0 + w_a(1-a)$, where $w_0$ and $w_a$ are constants. With $a=e^N$, this is $w(N) = w_0 + w_a(1-e^N)$.\n\nThe energy densities $\\rho_m$, $\\rho_r$, and $\\rho_{DE}$ are normalized to the critical density at the present day ($N=0$, $a=1$), so their initial values are the present-day density parameters $\\Omega_{m0}$, $\\Omega_{r0}$, and $\\Omega_{DE0}$. The assumption of a flat universe imposes the constraint $\\Omega_{m0} + \\Omega_{r0} + \\Omega_{DE0} = 1$.\n\nThis leads to the following system of coupled first-order ODEs for the state vector $\\vec{\\rho}(N) = [\\rho_m(N), \\rho_r(N), \\rho_{DE}(N)]^T$:\n$$\n\\frac{d\\rho_m}{dN} = -3(1+w_m)\\rho_m = -3\\rho_m\n$$\n$$\n\\frac{d\\rho_r}{dN} = -3(1+w_r)\\rho_r = -3(1+1/3)\\rho_r = -4\\rho_r\n$$\n$$\n\\frac{d\\rho_{DE}}{dN} = -3(1+w(e^N))\\rho_{DE} = -3\\left(1 + w_0 + w_a(1-e^N)\\right)\\rho_{DE}\n$$\nThese equations are to be solved numerically over the domain $N \\in [\\ln(10^{-8}), 0]$, integrating backward from the initial conditions at $N=0$: $\\rho_m(0) = \\Omega_{m0}$, $\\rho_r(0) = \\Omega_{r0}$, and $\\rho_{DE}(0) = \\Omega_{DE0}$.\n\nA key aspect of the problem is to investigate the numerical stiffness of this system. Stiffness arises in an ODE system when there are two or more very different scales of the independent variable on which the dependent variables are changing. It is characterized by the eigenvalues of the Jacobian matrix of the system's right-hand side function, $J_{ij} = \\partial f_i / \\partial \\rho_j$. For the given system, the Jacobian is diagonal:\n$$\nJ(N) = \\begin{pmatrix} -3  0  0 \\\\ 0  -4  0 \\\\ 0  0  -3(1+w(e^N)) \\end{pmatrix}\n$$\nThe eigenvalues are simply the diagonal entries: $\\lambda_m = -3$, $\\lambda_r = -4$, and $\\lambda_{DE}(N) = -3(1+w(e^N))$. The stiffness of the system is related to the ratio of the largest to the smallest magnitude of these eigenvalues. We quantify this with the instantaneous stiffness indicator:\n$$\nS(N) = \\frac{\\max\\{|\\lambda_m|, |\\lambda_r|, |\\lambda_{DE}(N)|\\}}{\\max(\\min\\{|\\lambda_m|, |\\lambda_r|, |\\lambda_{DE}(N)|\\}, \\varepsilon)}\n$$\nwhere $\\varepsilon = 10^{-12}$ prevents division by zero, particularly relevant for the standard $\\Lambda$CDM model where $w_0=-1$ and $w_a=0$, making $\\lambda_{DE}(N) = 0$ for all $N$.\n\nThe algorithmic approach involves the following steps for each test case:\n1.  Initialize parameters ($\\Omega_{m0}$, $\\Omega_{r0}$, $w_0$, $w_a$), initial conditions for $\\vec{\\rho}$ at $N=0$, and the integration interval $N \\in [\\ln(10^{-8}), 0]$.\n2.  Define the right-hand side (RHS) function for the ODE system and its analytical Jacobian matrix.\n3.  Numerically integrate the system from $N=0$ to $N_{\\min} = \\ln(10^{-8})$ using two different solvers from `scipy.integrate.solve_ivp`:\n    a. An explicit Runge-Kutta method of order 5(4) (`RK45`), which is efficient for non-stiff problems.\n    b. An implicit method based on backward differentiation formulas (`BDF`), which is designed for stiff problems and can utilize the provided Jacobian to improve performance.\n4.  For both integrations, use identical high-precision tolerances ($\\mathrm{rtol} = 10^{-10}$, $\\mathrm{atol} = 10^{-12}$) to ensure an accurate solution.\n5.  Record the number of RHS evaluations (`nfev`) from each solver run.\n6.  From the computed solution at $N_{\\min}$, calculate the ratio of radiation to matter energy density, $\\rho_r(N_{\\min})/\\rho_m(N_{\\min})$.\n7.  Calculate the instantaneous stiffness indicator $S(N_{\\min})$ using the analytical formula for the eigenvalues at $a_{\\min}=e^{N_{\\min}}=10^{-8}$.\n8.  Calculate the empirical numerical stiffness score $R$ as the ratio of `nfev` from `RK45` to that from `BDF`. A large $R  1$ indicates that the `BDF` solver was significantly more efficient, confirming the system's stiffness.\n9.  The three computed floating-point values are then rounded to six significant figures for final output. This process is repeated for all four test cases provided.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef solve():\n    \"\"\"\n    Numerically evolves energy densities in an FLRW universe and quantifies\n    numerical stiffness for different cosmological models.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (baseline Lambda Cold Dark Matter)\n        (0.315, 9.2e-5, -1.0, 0.0),\n        # Case 2 (mildly evolving dark energy with phantom today)\n        (0.30, 9.2e-5, -0.95, -0.10),\n        # Case 3 (strong early-time deviation from cosmological constant)\n        (0.30, 9.2e-5, -1.0, 0.50),\n        # Case 4 (edge case with negligible radiation today)\n        (0.30, 1.0e-10, -1.0, 0.0),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        Omega_m0, Omega_r0, w0, wa = case\n        Omega_DE0 = 1.0 - (Omega_m0 + Omega_r0)\n\n        # Numerical setup\n        N_min = np.log(1e-8)\n        N_span = [0, N_min]\n        rho0 = np.array([Omega_m0, Omega_r0, Omega_DE0])\n        rtol = 1e-10\n        atol = 1e-12\n\n        def rhs(N, rho, w0_val, wa_val):\n            \"\"\"Right-hand side of the ODE system d(rho)/dN.\"\"\"\n            rho_m, rho_r, rho_de = rho\n            a = np.exp(N)\n            w_de = w0_val + wa_val * (1 - a)\n            \n            drho_m_dN = -3.0 * rho_m\n            drho_r_dN = -4.0 * rho_r\n            drho_de_dN = -3.0 * (1.0 + w_de) * rho_de\n            \n            return np.array([drho_m_dN, drho_r_dN, drho_de_dN])\n\n        def jac(N, rho, w0_val, wa_val):\n            \"\"\"Jacobian of the RHS function.\"\"\"\n            a = np.exp(N)\n            w_de = w0_val + wa_val * (1.0 - a)\n            \n            J = np.zeros((3, 3))\n            J[0, 0] = -3.0\n            J[1, 1] = -4.0\n            J[2, 2] = -3.0 * (1.0 + w_de)\n            return J\n\n        # --- Integration with non-stiff solver (RK45) ---\n        sol_rk45 = solve_ivp(\n            fun=rhs,\n            t_span=N_span,\n            y0=rho0,\n            method='RK45',\n            rtol=rtol,\n            atol=atol,\n            args=(w0, wa)\n        )\n        nfev_rk45 = sol_rk45.nfev\n        rho_final = sol_rk45.y[:, -1]\n\n        # --- Integration with stiff solver (BDF) ---\n        sol_bdf = solve_ivp(\n            fun=rhs,\n            t_span=N_span,\n            y0=rho0,\n            method='BDF',\n            jac=jac,\n            rtol=rtol,\n            atol=atol,\n            args=(w0, wa)\n        )\n        nfev_bdf = sol_bdf.nfev\n\n        # --- Compute the three required outputs ---\n\n        # 1. Ratio rho_r / rho_m at N_min\n        rho_m_final, rho_r_final, _ = rho_final\n        ratio_rho = rho_r_final / rho_m_final if rho_m_final != 0 else np.inf\n\n        # 2. Instantaneous stiffness indicator S(N_min)\n        a_min = 1e-8\n        epsilon = 1e-12\n        w_de_min = w0 + wa * (1.0 - a_min)\n        \n        lambda_m_abs = 3.0\n        lambda_r_abs = 4.0\n        lambda_de_abs = np.abs(-3.0 * (1.0 + w_de_min))\n        \n        abs_lambdas = np.array([lambda_m_abs, lambda_r_abs, lambda_de_abs])\n        max_lambda = np.max(abs_lambdas)\n        min_lambda = np.min(abs_lambdas)\n        \n        stiffness_indicator = max_lambda / max(min_lambda, epsilon)\n\n        # 3. Empirical numerical stiffness score R\n        stiffness_score = nfev_rk45 / nfev_bdf if nfev_bdf != 0 else np.inf\n\n        # Format results to six significant figures\n        def format_six_sf(value):\n            return float(f'{value:.6g}')\n\n        case_results = [\n            format_six_sf(ratio_rho),\n            format_six_sf(stiffness_indicator),\n            format_six_sf(stiffness_score)\n        ]\n        all_results.append(case_results)\n\n    # Final print statement in the exact required format.\n    inner_strings = [f\"[{','.join(map(str, r))}]\" for r in all_results]\n    print(f\"[{','.join(inner_strings)}]\")\n\nsolve()\n```", "id": "3470916"}, {"introduction": "Accurately evolving individual energy densities is only half the battle; combining them to compute cosmological observables like the Hubble parameter presents its own numerical pitfalls. Because the energy densities of radiation, matter, and dark energy scale differently with the expansion factor $a$, their relative contributions to the total energy budget vary by dozens of orders of magnitude across cosmic history. This exercise illuminates the problem of \"loss of significance\" in finite-precision arithmetic and provides hands-on experience implementing a compensated summation strategy to maintain accuracy when calculating the total energy density from its vastly different components [@problem_id:3470934].", "problem": "You are asked to study the numerical stability of computing the Hubble expansion rate as a function of the cosmic scale factor using finite-precision arithmetic and to implement a robust compensated summation strategy that mitigates floating-point cancellation when summing terms of vastly different magnitudes. Work in a spatially homogeneous and isotropic Universe whose expansion is governed by the Friedmann equation with perfect fluid components. The dimensionless expansion rate is defined as $E(a) \\equiv H(a)/H_{0}$, where $a$ is the cosmological scale factor normalized to $a=1$ today, $H(a)$ is the Hubble parameter, and $H_{0}$ is its present value. Assume the following components contribute to the total energy budget: radiation with density parameter $\\Omega_{r}$, non-relativistic matter with density parameter $\\Omega_{m}$, spatial curvature with density parameter $\\Omega_{k}$, and dark energy parametrized by a constant equation-of-state parameter $w$ with density parameter $\\Omega_{\\mathrm{de}}$. The total energy budget at $a=1$ satisfies $\\Omega_{r} + \\Omega_{m} + \\Omega_{k} + \\Omega_{\\mathrm{de}} = 1$. For constant $w$, the energy densities scale as powers of $a$ according to the standard perfect-fluid continuity equation in an expanding Universe.\n\nStarting from the Friedmann equation from general relativity and the perfect-fluid continuity equation, one can express the dimensionless expansion rate as\n$$\nE(a)^{2} = \\Omega_{r}\\, a^{-4} + \\Omega_{m}\\, a^{-3} + \\Omega_{k}\\, a^{-2} + \\Omega_{\\mathrm{de}}\\, a^{-3(1+w)}.\n$$\nIn practical numerical cosmology computations, $\\Omega_{k}$ is often not specified directly but is computed by residual closure as\n$$\n\\Omega_{k} = 1 - \\left(\\Omega_{r} + \\Omega_{m} + \\Omega_{\\mathrm{de}}\\right).\n$$\nWhen computing $E(a)$ at extreme values of $a$, the individual terms can differ by many orders of magnitude, and naive floating-point summation in finite precision can suffer from severe rounding and cancellation errors. Your task is to quantify this effect in single precision and to implement a compensated summation strategy that reduces the error without changing the physical model.\n\nYou must implement a program that:\n- Computes a high-precision reference $E_{\\mathrm{ref}}(a)$ in double precision by evaluating $E(a)$ as given above using $\\Omega_{k}$ obtained from the double-precision residual, and summing the components in any reasonable order in double precision.\n- Computes a naive single-precision estimate $E_{\\mathrm{naive}}(a)$ by:\n  - Casting all input parameters and $a$ to single precision, computing $\\Omega_{k}$ from the single-precision residual, forming the four contributions in single precision, and summing them in a fixed left-to-right order to obtain $E(a)^{2}$ in single precision, followed by a square root. If, due solely to finite precision, the intermediate single-precision sum of contributions is negative, set it to zero before taking the square root.\n- Computes an improved single-precision estimate $E_{\\mathrm{comp}}(a)$ that differs from the naive method only in how the four contributions are aggregated: use a compensated summation strategy that minimizes cancellation, for example by summing the contributions in increasing order of magnitude with a single-pass compensated summation (such as Kahan-style compensation), all in single precision, and then taking the square root. As above, if the compensated sum is negative due solely to rounding, set it to zero before taking the square root.\n\nFor each test case below, evaluate a logarithmically spaced grid of $a$ values from $a_{\\min}$ to $a_{\\max}$ inclusive, and report the maximum relative error over the grid for both the naive and compensated single-precision methods, where the relative error at a given $a$ is\n$$\n\\varepsilon(a) = \\frac{\\left|E_{\\mathrm{method}}(a) - E_{\\mathrm{ref}}(a)\\right|}{E_{\\mathrm{ref}}(a)}.\n$$\nAll quantities in this problem are dimensionless; therefore, no physical units are required in the answer.\n\nTest suite specification:\n- Use a grid of $N=200$ logarithmically spaced points in $a \\in \\left[10^{-8}, 10^{4}\\right]$ for each test case.\n- For each test case, the program must output two floating-point numbers: the maximum relative error for the naive single-precision summation and for the compensated single-precision summation, in that order.\n\nTest cases:\n1. Standard late-time composition with a small radiation component and a cosmological constant:\n   - $\\Omega_{r} = 8.24\\times 10^{-5}$, $\\Omega_{m} = 0.315$, $\\Omega_{\\mathrm{de}} = 0.6849176$, $w = -1$, $a_{\\min} = 10^{-8}$, $a_{\\max} = 10^{4}$.\n2. Highly skewed budget with dark energy domination and minuscule matter and radiation:\n   - $\\Omega_{r} = 1\\times 10^{-12}$, $\\Omega_{m} = 1\\times 10^{-6}$, $\\Omega_{\\mathrm{de}} = 0.999999$, $w = -1$, $a_{\\min} = 10^{-8}$, $a_{\\max} = 10^{4}$.\n3. Phantom dark energy with $w-1$ and negligible radiation:\n   - $\\Omega_{r} = 1\\times 10^{-10}$, $\\Omega_{m} = 0.05$, $\\Omega_{\\mathrm{de}} = 0.95$, $w = -1.1$, $a_{\\min} = 10^{-8}$, $a_{\\max} = 10^{4}$.\n\nFinal output format requirement:\n- Your program should produce a single line of output containing the six results as a comma-separated list enclosed in square brackets in the following order:\n  - $[\\varepsilon_{\\max}^{\\mathrm{naive}}(\\mathrm{case}\\,1), \\varepsilon_{\\max}^{\\mathrm{comp}}(\\mathrm{case}\\,1), \\varepsilon_{\\max}^{\\mathrm{naive}}(\\mathrm{case}\\,2), \\varepsilon_{\\max}^{\\mathrm{comp}}(\\mathrm{case}\\,2), \\varepsilon_{\\max}^{\\mathrm{naive}}(\\mathrm{case}\\,3), \\varepsilon_{\\max}^{\\mathrm{comp}}(\\mathrm{case}\\,3)]$.\n- Each entry must be a floating-point number. The program must not print any other text.", "solution": "The user has requested a solution to a numerical cosmology problem involving the computation of the Hubble expansion rate, with a focus on mitigating floating-point errors.\n\n### **Problem Statement Validation**\n\n**1. Extraction of Givens:**\n- **Model**: Spatially homogeneous and isotropic Universe.\n- **Governing Equation**: Friedmann equation.\n- **Definition**: Dimensionless expansion rate $E(a) \\equiv H(a)/H_{0}$.\n- **Components**: Radiation ($\\Omega_{r}$), matter ($\\Omega_{m}$), curvature ($\\Omega_{k}$), and dark energy ($\\Omega_{\\mathrm{de}}$ with constant equation-of-state parameter $w$).\n- **Constraint**: $\\Omega_{r} + \\Omega_{m} + \\Omega_{k} + \\Omega_{\\mathrm{de}} = 1$.\n- **Formula for $E(a)^{2}$**: $E(a)^{2} = \\Omega_{r}\\, a^{-4} + \\Omega_{m}\\, a^{-3} + \\Omega_{k}\\, a^{-2} + \\Omega_{\\mathrm{de}}\\, a^{-3(1+w)}$.\n- **$\\Omega_{k}$ Calculation**: $\\Omega_{k} = 1 - \\left(\\Omega_{r} + \\Omega_{m} + \\Omega_{\\mathrm{de}}\\right)$.\n- **Numerical Tasks**:\n    1.  **$E_{\\mathrm{ref}}(a)$**: Compute in double precision.\n    2.  **$E_{\\mathrm{naive}}(a)$**: Cast inputs to single precision, compute terms, sum left-to-right. Clamp negative sum to $0$.\n    3.  **$E_{\\mathrm{comp}}(a)$**: Same as naive, but sum terms using a compensated strategy (sorted by magnitude, then Kahan summation). Clamp negative sum to $0$.\n- **Error Metric**: Maximum relative error $\\varepsilon_{\\max} = \\max_a \\left|E_{\\mathrm{method}}(a) - E_{\\mathrm{ref}}(a)\\right|/E_{\\mathrm{ref}}(a)$.\n- **Grid**: $N=200$ logarithmically spaced points in $a \\in \\left[10^{-8}, 10^{4}\\right]$.\n- **Test Cases**:\n    1. $\\Omega_{r} = 8.24\\times 10^{-5}$, $\\Omega_{m} = 0.315$, $\\Omega_{\\mathrm{de}} = 0.6849176$, $w = -1$.\n    2. $\\Omega_{r} = 1\\times 10^{-12}$, $\\Omega_{m} = 1\\times 10^{-6}$, $\\Omega_{\\mathrm{de}} = 0.999999$, $w = -1$.\n    3. $\\Omega_{r} = 1\\times 10^{-10}$, $\\Omega_{m} = 0.05$, $\\Omega_{\\mathrm{de}} = 0.95$, $w = -1.1$.\n- **Output**: A single line `[...]` with six comma-separated floating-point numbers.\n\n**2. Validation using Extracted Givens:**\n- **Scientifically Grounded**: The problem is based on the standard model of cosmology, specifically the Friedmann equation. The scaling relations for the energy densities of radiation ($\\rho_r \\propto a^{-4}$), matter ($\\rho_m \\propto a^{-3}$), curvature ($\\rho_k \\propto a^{-2}$), and dark energy with constant $w$ ($\\rho_{\\mathrm{de}} \\propto a^{-3(1+w)}$) are correct. The provided equation for $E(a)^2$ is a direct and correct consequence of these principles.\n- **Well-Posed**: The problem is well-defined. The inputs are specified, the computational methods are described unambiguously, and the desired output is precise. A unique, stable numerical solution exists.\n- **Objective**: The language is precise and free of subjectivity. The parameters given for the test cases are physically plausible values used in modern cosmology.\n- **Completeness and Consistency**: The problem provides all necessary data and equations. The test cases are for a flat universe ($\\Omega_k = 0$ in exact arithmetic), which is consistent with current cosmological observations. The use of a residual calculation for $\\Omega_k$ is standard practice and introduces the kind of floating-point subtleties the problem aims to investigate.\n- **Feasibility**: The requested computations are standard and feasible within the specified environment. The range of the scale factor $a$ is large, which is precisely what makes the numerical stability issue prominent and the problem interesting.\n\n**3. Verdict and Action:**\nThe problem is **valid**. It is a well-posed, scientifically sound exercise in numerical analysis as applied to a fundamental calculation in physical cosmology. The task is to quantify the improvement of a robust summation algorithm over a naive approach when dealing with finite-precision arithmetic. I will now proceed with the solution.\n\n### **Principle-Based Design and Solution**\n\nThe problem requires us to compute the dimensionless Hubble expansion rate, $E(a)$, which describes the expansion of the universe. Its evolution is governed by the constituent energy densities, as encapsulated in the Friedmann equation.\n\n**1. Physical Model and Governing Equation**\nThe expansion history of a homogeneous and isotropic universe is described by the Friedmann equation. In terms of the dimensionless density parameters $\\Omega_i$ (fractional energy density of component $i$ today), the dimensionless expansion rate $E(a) = H(a)/H_0$ is given by:\n$$\nE(a)^{2} = \\Omega_{r}\\, a^{-4} + \\Omega_{m}\\, a^{-3} + \\Omega_{k}\\, a^{-2} + \\Omega_{\\mathrm{de}}\\, a^{-3(1+w)}\n$$\nwhere $a$ is the scale factor, and the subscripts $r$, $m$, $k$, and $\\mathrm{de}$ refer to radiation, non-relativistic matter, spatial curvature, and dark energy, respectively. The density parameters are defined at $a=1$ and must sum to unity, $\\Omega_{r} + \\Omega_{m} + \\Omega_{k} + \\Omega_{\\mathrm{de}} = 1$. The problem specifies that $\\Omega_k$ is determined by this closure relation. The exponents on the scale factor $a$ reflect how the energy density of each component is diluted by cosmic expansion.\n\n**2. The Numerical Challenge: Loss of Significance**\nThe core of the problem lies in the numerical evaluation of the sum for $E(a)^2$. The scale factor $a$ spans twelve orders of magnitude, from $10^{-8}$ (the early, hot, dense universe) to $10^{4}$ (the far future). This causes the four terms in the sum to have vastly different magnitudes.\n\nFor example, in the early universe ($a \\ll 1$), the radiation term $\\Omega_{r}a^{-4}$ is dominant. At $a=10^{-8}$, this term is on the order of $\\sim 10^{-5} \\times (10^{-8})^{-4} = 10^{27}$, while the dark energy term (for $w=-1$) is $\\sim 0.7$. When using finite-precision arithmetic, such as single precision (`float32`), adding a very small number to a very large one results in the smaller number being effectively discarded. This phenomenon, known as \"swamping\" or \"loss of significance\", leads to a loss of accuracy. A naive summation `A + B + C + D` is highly susceptible to this error.\n\n**3. Algorithmic Implementation Strategy**\nTo quantify and mitigate this error, we implement three different computational methods:\n\n- **Reference Solution ($E_{\\mathrm{ref}}$)**: This is our \"ground truth\". All calculations are performed using double-precision arithmetic (`numpy.float64`), which offers approximately $15-17$ decimal digits of precision. This high precision minimizes rounding errors, providing a reliable benchmark against which to compare the single-precision methods. The summation order is not critical due to the high precision available.\n\n- **Naive Single-Precision Solution ($E_{\\mathrm{naive}}$)**: Here, all parameters and intermediate calculations are cast to single precision (`numpy.float32`), which has only about $7$ decimal digits of precision. The four terms contributing to $E(a)^2$ are summed in a fixed left-to-right order. This method is expected to suffer significant accuracy loss due to swamping, especially at the extremes of the scale factor range. As specified, if rounding errors cause the sum to be negative, it is clamped to $0$ before taking the square root, a necessary step for physical realism.\n\n- **Compensated Single-Precision Solution ($E_{\\mathrm{comp}}$)**: This method also uses single precision but employs a more sophisticated summation strategy to reduce error. The strategy combines two heuristics:\n    1.  **Sorting**: The four terms are first sorted in increasing order of their absolute magnitude. Summing from smallest to largest is a general technique to reduce rounding errors, as it tends to keep the running sum and the next term to be added closer in magnitude.\n    2.  **Kahan Summation**: A single-pass compensated summation algorithm, specifically the Kahan summation algorithm, is then applied to the sorted terms. This algorithm maintains an additional floating-point variable, the *compensation* (`c`), which accumulates the roundoff error from each addition. This captured error is then reintroduced into the sum at the next step. The core logic of the Kahan algorithm for a running sum `s` and new term `x` is:\n        - `y = x - c` (Correct the term with the previous error)\n        - `t = s + y` (Add the corrected term to the sum; error may occur here)\n        - `c = (t - s) - y` (Calculate the new error)\n        - `s = t` (Update the sum)\n    This procedure effectively tracks the \"lost\" low-order bits and significantly improves the accuracy of the final sum. The final sum is also clamped to $0$ if it becomes negative due to residual rounding errors.\n\nFinally, the maximum relative error for the naive and compensated methods is computed over the grid of $a$ values with respect to the double-precision reference solution. This quantifies the performance of each single-precision strategy.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the numerical cosmology problem by computing and comparing Hubble expansion rates.\n\n    This function iterates through a set of predefined cosmological test cases. For each case,\n    it calculates the dimensionless Hubble expansion rate E(a) over a logarithmic grid of\n    scale factors 'a' using three distinct methods:\n    1. A high-precision reference method using double-precision floating-point numbers.\n    2. A naive method using single-precision numbers and a standard left-to-right summation.\n    3. An improved method using single-precision numbers but with a compensated summation\n       (sorting terms by magnitude and applying Kahan's algorithm).\n\n    It then calculates the maximum relative error of the naive and compensated methods against\n    the reference result and stores these errors. Finally, it prints all collected errors\n    in the specified format.\n    \"\"\"\n\n    test_cases = [\n        # (Omega_r, Omega_m, Omega_de, w, a_min, a_max)\n        (8.24e-5, 0.315, 0.6849176, -1.0, 1e-8, 1e4),\n        (1e-12, 1e-6, 0.999999, -1.0, 1e-8, 1e4),\n        (1e-10, 0.05, 0.95, -1.1, 1e-8, 1e4)\n    ]\n    N = 200\n    results = []\n\n    for case in test_cases:\n        Omega_r_in, Omega_m_in, Omega_de_in, w_in, a_min, a_max = case\n        a_grid = np.logspace(np.log10(a_min), np.log10(a_max), N)\n\n        # 1. High-precision reference calculation (double precision)\n        E_ref = np.zeros_like(a_grid, dtype=np.float64)\n        Or, Om, Ode, w = np.float64(Omega_r_in), np.float64(Omega_m_in), np.float64(Omega_de_in), np.float64(w_in)\n        Ok = np.float64(1.0) - (Or + Om + Ode)\n        w_exp = np.float64(-3.0) * (np.float64(1.0) + w)\n        for i, a_val in enumerate(a_grid):\n            a = np.float64(a_val)\n            term_r = Or * np.power(a, -4.0)\n            term_m = Om * np.power(a, -3.0)\n            term_k = Ok * np.power(a, -2.0)\n            term_de = Ode * np.power(a, w_exp)\n            E_sq = term_r + term_m + term_k + term_de\n            E_ref[i] = np.sqrt(E_sq if E_sq  0 else 0.0)\n\n        # 2. Naive single-precision calculation\n        E_naive = np.zeros_like(a_grid, dtype=np.float32)\n        Or_32, Om_32, Ode_32, w_32 = np.float32(Omega_r_in), np.float32(Omega_m_in), np.float32(Omega_de_in), np.float32(w_in)\n        Ok_32 = np.float32(1.0) - (Or_32 + Om_32 + Ode_32)\n        w_exp_32 = np.float32(-3.0) * (np.float32(1.0) + w_32)\n        for i, a_val in enumerate(a_grid):\n            a_32 = np.float32(a_val)\n            term_r = Or_32 * np.power(a_32, np.float32(-4.0))\n            term_m = Om_32 * np.power(a_32, np.float32(-3.0))\n            term_k = Ok_32 * np.power(a_32, np.float32(-2.0))\n            term_de = Ode_32 * np.power(a_32, w_exp_32)\n            # Naive left-to-right summation\n            E_sq_32 = term_r + term_m + term_k + term_de\n            E_naive[i] = np.sqrt(E_sq_32 if E_sq_32  0 else np.float32(0.0))\n\n        # 3. Compensated single-precision calculation\n        E_comp = np.zeros_like(a_grid, dtype=np.float32)\n        for i, a_val in enumerate(a_grid):\n            a_32 = np.float32(a_val)\n            term_r = Or_32 * np.power(a_32, np.float32(-4.0))\n            term_m = Om_32 * np.power(a_32, np.float32(-3.0))\n            term_k = Ok_32 * np.power(a_32, np.float32(-2.0))\n            term_de = Ode_32 * np.power(a_32, w_exp_32)\n            \n            terms = [term_r, term_m, term_k, term_de]\n            \n            # Sort terms by increasing absolute magnitude\n            sorted_terms = sorted(terms, key=abs)\n            \n            # Kahan compensated summation\n            s = np.float32(0.0)\n            c = np.float32(0.0)\n            for x in sorted_terms:\n                y = x - c\n                t = s + y\n                c = (t - s) - y\n                s = t\n            E_sq_32 = s\n            E_comp[i] = np.sqrt(E_sq_32 if E_sq_32  0 else np.float32(0.0))\n\n        # Calculate maximum relative errors, avoiding division by zero if E_ref is zero\n        \n        # Naive error\n        err_naive = np.zeros_like(E_ref)\n        # E_ref should not be zero for these cosmological parameters\n        non_zero_mask = E_ref != 0\n        err_naive[non_zero_mask] = np.abs(E_naive[non_zero_mask] - E_ref[non_zero_mask]) / E_ref[non_zero_mask]\n        max_err_naive = np.max(err_naive)\n        \n        # Compensated error\n        err_comp = np.zeros_like(E_ref)\n        err_comp[non_zero_mask] = np.abs(E_comp[non_zero_mask] - E_ref[non_zero_mask]) / E_ref[non_zero_mask]\n        max_err_comp = np.max(err_comp)\n\n        results.extend([max_err_naive, max_err_comp])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3470934"}, {"introduction": "Modern cosmological models often explore scenarios where the dark energy equation of state parameter, $w(a)$, is not a constant but evolves, sometimes crossing the \"phantom divide\" at $w=-1$. Naively integrating the evolution equations through such a crossing can lead to numerical instabilities or singularities. This advanced practice demonstrates a powerful regularization technique: by evolving the logarithm of the energy density, $\\ln\\rho$, and employing a physically motivated smoothed model for $w(a)$, you can ensure the stability and accuracy of the simulation. This exercise is key to developing robust code capable of exploring the frontiers of dark energy theory [@problem_id:3470966].", "problem": "Consider a spatially homogeneous and isotropic universe described by the Friedmann–Lemaître–Robertson–Walker (FLRW) metric. For a single perfect fluid with energy density $\\rho(a)$ and pressure $p(a)$, assume the equation of state $p(a) = w(a)\\,\\rho(a)$ where $w(a)$ may cross the value $-1$ as a function of scale factor $a$. Denote the number of e-folds by $N = \\ln a$. Starting only from energy conservation for a perfect fluid in an FLRW spacetime and the change of variables from cosmic time to $N$, design a numerical procedure that evolves $\\rho(a)$ across a crossing of $w(a) = -1$ without introducing numerical singularities. The design must use the logarithm of the energy density as the evolved variable and must implement a smoothed $w(N)$ near the crossing.\n\nYour program must implement the following components:\n\n- A smoothed crossing model for the equation of state parameter,\n  $$w_{\\mathrm{smooth}}(N; A, N_c, \\Delta) = -1 + A\\,\\tanh\\!\\left(\\frac{N - N_c}{\\Delta}\\right),$$\n  where $A$ is the amplitude of the departure from $-1$, $N_c$ is the e-fold at which the crossing $w = -1$ occurs, and $\\Delta$ is the smoothing width.\n\n- A discontinuous step model for comparison,\n  $$w_{\\mathrm{step}}(N; A, N_c) = -1 + A\\,\\mathrm{sgn}(N - N_c),$$\n  with the convention $\\mathrm{sgn}(0) = 0$ so that $w_{\\mathrm{step}}(N_c; A, N_c) = -1$.\n\n- A regularized integrator that evolves the logarithm of the energy density using $N$ as the independent variable and $w_{\\mathrm{smooth}}(N)$ as defined above. Use a fixed-step fourth-order Runge–Kutta (RK4) scheme on $N \\in [N_i, N_f]$ with step size $h_{\\mathrm{reg}}$.\n\n- A naive comparator that evolves the energy density directly using $w_{\\mathrm{step}}(N)$ with a fixed-step explicit Euler scheme on the same interval with step size $h_{\\mathrm{naive}}$.\n\nInitialization and normalization:\n- Use $a_i$ for the initial scale factor and $a_f$ for the final scale factor, with $N_i = \\ln a_i$ and $N_f = \\ln a_f$.\n- Initialize the energy density as $\\rho(a_i) = \\rho_i$ and express all outputs as dimensionless quantities relative to $\\rho_i$. No physical units are required.\n\nAnalytic check:\n- For the smoothed model $w_{\\mathrm{smooth}}(N)$, the integral of the source term is exactly tractable. Use this to provide an analytic expression for $\\rho(a_f)$ and compare against the numerical result from the regularized integrator.\n\nTest suite:\nImplement and run the following four test cases with the specified parameters. In all cases, take $\\rho_i = 1$ and $a_i = 10^{-4}$, so $N_i = \\ln(10^{-4})$, and $a_f = 1$, so $N_f = 0$.\n\n1. Happy path regularized evolution:\n   - $A = 0.2$, $N_c = -2.0$, $\\Delta = 0.2$, $h_{\\mathrm{reg}} = 0.01$.\n   - Compute the final dimensionless energy density $\\rho(a_f)$ using the regularized integrator.\n\n2. Boundary case $w = -1$:\n   - $A = 0.0$, $N_c = -2.0$, $\\Delta = 0.2$, $h_{\\mathrm{reg}} = 0.01$.\n   - Compute the ratio $\\rho(a_f)/\\rho(a_i)$ using the regularized integrator.\n\n3. Instability check for a coarse naive scheme:\n   - $A = 1.0$, $N_c = -1.0$, $h_{\\mathrm{naive}} = 0.5$ (the smoothing width $\\Delta$ is irrelevant for the step model).\n   - Evolve using the naive explicit Euler scheme with $w_{\\mathrm{step}}(N)$. Return a boolean indicating whether any step produced $\\rho  0$.\n\n4. Accuracy check against the analytic solution:\n   - $A = 0.5$, $N_c = -2.0$, $\\Delta = 0.05$, $h_{\\mathrm{reg}} = 0.01$.\n   - Compute the absolute relative error between the regularized numerical $\\rho(a_f)$ and the exact analytic $\\rho(a_f)$ derived from the smoothed model.\n\nFinal output format:\n- Your program should produce a single line of output containing the results of the four test cases as a comma-separated list enclosed in square brackets (for example, $[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4]$).\n- The results should be, respectively: a float, a float, a boolean, and a float, in the order of the test cases listed above.", "solution": "The problem statement has been meticulously reviewed and is determined to be valid. It is scientifically grounded in the standard cosmological model, is self-contained with all necessary parameters and definitions, and is well-posed, leading to a unique and meaningful solution for each specified task. The problem addresses a relevant numerical challenge in computational cosmology—the stable evolution of fluid densities across a phantom divide crossing ($w = -1$)—and is structured as a clear, objective, and verifiable exercise.\n\nWe begin by establishing the fundamental theoretical framework. The conservation of energy-momentum in a Friedmann–Lemaître–Robertson–Walker (FLRW) universe for a perfect fluid with energy density $\\rho$ and pressure $p$ is described by the continuity equation:\n$$\n\\dot{\\rho} + 3H(\\rho + p) = 0\n$$\nwhere the dot denotes a derivative with respect to cosmic time $t$, and $H = \\dot{a}/a$ is the Hubble parameter, with $a$ being the scale factor. Using the equation of state $p(a) = w(a)\\rho(a)$, this becomes:\n$$\n\\dot{\\rho} + 3\\frac{\\dot{a}}{a}(1 + w(a))\\rho = 0\n$$\nRearranging terms gives:\n$$\n\\frac{d\\rho}{\\rho} = -3(1 + w(a))\\frac{da}{a}\n$$\nThe problem specifies using the number of e-folds, $N = \\ln a$, as the independent variable. The differential relationship is $dN = d(\\ln a) = da/a$. Substituting this into the equation yields the primary ordinary differential equation (ODE) for the energy density as a function of $N$:\n$$\n\\frac{d\\rho}{\\rho dN} = -3(1 + w(N))\n$$\nThis can be written as:\n$$\n\\frac{d\\rho}{dN} = -3(1 + w(N))\\rho(N)\n$$\nA potential numerical issue arises when $w(N)$ approaches $-1$. If one formulates the problem in a way that involves division by $(1+w)$, a singularity occurs. The \"naive\" approach of evolving $\\rho$ directly using an explicit numerical method can also lead to instability, as will be demonstrated.\n\nA more robust \"regularized\" method, as suggested by the problem, is to evolve the logarithm of the energy density, $y(N) = \\ln \\rho(N)$. Differentiating $y(N)$ with respect to $N$ gives:\n$$\n\\frac{dy}{dN} = \\frac{d(\\ln\\rho)}{dN} = \\frac{1}{\\rho}\\frac{d\\rho}{dN}\n$$\nSubstituting our previous expression for $d\\rho/dN$, we arrive at the regularized ODE:\n$$\n\\frac{dy}{dN} = -3(1 + w(N))\n$$\nThis formulation is advantageous because the right-hand side is no longer proportional to the variable being evolved, $\\rho$. When $w(N) \\to -1$, the derivative $dy/dN \\to 0$, correctly implying that $\\ln\\rho$ (and thus $\\rho$) becomes constant. The equation is stable and non-stiff across the crossing.\n\nFor the regularized integrator, we use the smoothed equation of state parameter:\n$$\nw_{\\mathrm{smooth}}(N) = -1 + A\\tanh\\left(\\frac{N - N_c}{\\Delta}\\right)\n$$\nSubstituting this into the regularized ODE gives:\n$$\n\\frac{dy}{dN} = -3\\left(1 + \\left(-1 + A\\tanh\\left(\\frac{N - N_c}{\\Delta}\\right)\\right)\\right) = -3A\\tanh\\left(\\frac{N - N_c}{\\Delta}\\right)\n$$\nThis ODE, $y'(N) = f(N)$, is solved numerically using a fixed-step fourth-order Runge-Kutta (RK4) scheme on the interval $N \\in [N_i, N_f]$ with initial condition $y(N_i) = \\ln \\rho_i$. For a step from $N_k$ to $N_{k+1} = N_k + h_{\\mathrm{reg}}$, the update is:\n$$\ny_{k+1} = y_k + \\frac{1}{6}(k_1 + 2k_2 + 2k_3 + k_4)\n$$\nwhere $f(N) = -3A\\tanh\\left(\\frac{N - N_c}{\\Delta}\\right)$ and\n$$\n\\begin{aligned}\nk_1 = h_{\\mathrm{reg}} f(N_k) \\\\\nk_2 = h_{\\mathrm{reg}} f(N_k + h_{\\mathrm{reg}}/2) \\\\\nk_3 = h_{\\mathrm{reg}} f(N_k + h_{\\mathrm{reg}}/2) \\\\\nk_4 = h_{\\mathrm{reg}} f(N_k + h_{\\mathrm{reg}})\n\\end{aligned}\n$$\n\nFor the naive comparator, we use the direct ODE for $\\rho(N)$ with the discontinuous step model:\n$$\nw_{\\mathrm{step}}(N) = -1 + A\\,\\mathrm{sgn}(N - N_c)\n$$\nThe ODE is:\n$$\n\\frac{d\\rho}{dN} = -3\\left(1 + \\left(-1 + A\\,\\mathrm{sgn}(N - N_c)\\right)\\right)\\rho = -3A\\,\\mathrm{sgn}(N - N_c)\\,\\rho\n$$\nThe explicit Euler scheme with step size $h_{\\mathrm{naive}}$ gives the update rule:\n$$\n\\rho_{k+1} = \\rho_k + h_{\\mathrm{naive}} \\left(-3A\\,\\mathrm{sgn}(N_k - N_c)\\,\\rho_k\\right) = \\rho_k \\left(1 - 3 A h_{\\mathrm{naive}}\\,\\mathrm{sgn}(N_k - N_c)\\right)\n$$\nInstability, such as the energy density becoming unphysically negative ($\\rho  0$), can occur if the update factor $(1 - 3 A h_{\\mathrm{naive}}\\,\\mathrm{sgn}(N_k - N_c))$ becomes negative. This is a known limitation of the explicit Euler method for certain ODEs and step sizes. For Test Case 3, with $A=1.0$ and $h_{\\mathrm{naive}}=0.5$, the factor is $1 - 1.5\\,\\mathrm{sgn}(N_k - N_c)$. For any step where $N_k  N_c$, $\\mathrm{sgn}(\\cdot)=1$, and the factor is $-0.5$, causing $\\rho$ to flip sign and become negative.\n\nFinally, we derive the exact analytic solution for the smoothed model to perform an accuracy check. We integrate the regularized ODE from $N_i$ to $N_f$:\n$$\n\\int_{y(N_i)}^{y(N_f)} dy = \\int_{N_i}^{N_f} -3A\\tanh\\left(\\frac{N - N_c}{\\Delta}\\right) dN\n$$\n$$\n\\ln(\\rho(N_f)) - \\ln(\\rho(N_i)) = -3A\\Delta \\left[ \\ln\\left(\\cosh\\left(\\frac{N - N_c}{\\Delta}\\right)\\right) \\right]_{N_i}^{N_f}\n$$\n$$\n\\ln\\left(\\frac{\\rho(N_f)}{\\rho(N_i)}\\right) = -3A\\Delta \\left( \\ln\\left(\\cosh\\left(\\frac{N_f - N_c}{\\Delta}\\right)\\right) - \\ln\\left(\\cosh\\left(\\frac{N_i - N_c}{\\Delta}\\right)\\right) \\right)\n$$\n$$\n\\ln\\left(\\frac{\\rho(N_f)}{\\rho(N_i)}\\right) = 3A\\Delta \\ln\\left(\\frac{\\cosh\\left(\\frac{N_i - N_c}{\\Delta}\\right)}{\\cosh\\left(\\frac{N_f - N_c}{\\Delta}\\right)}\\right)\n$$\nExponentiating both sides yields the exact solution for the final energy density:\n$$\n\\rho(N_f) = \\rho(N_i) \\left( \\frac{\\cosh\\left(\\frac{N_i - N_c}{\\Delta}\\right)}{\\cosh\\left(\\frac{N_f - N_c}{\\Delta}\\right)} \\right)^{3A\\Delta}\n$$\nThis expression will be used to validate the accuracy of the RK4 integrator in Test Case 4.\n\nThe implementation will now proceed according to these derivations for each of the four test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Executes the four test cases specified in the problem statement\n    and prints the results in the required format.\n    \"\"\"\n\n    # --- Global Parameters ---\n    a_i = 1e-4\n    a_f = 1.0\n    rho_i = 1.0\n    \n    N_i = np.log(a_i)\n    N_f = np.log(a_f)\n\n    # --- Helper Functions ---\n\n    def run_regularized_rk4(A, Nc, Delta, h_reg):\n        \"\"\"\n        Implements the regularized integrator using a 4th-order Runge-Kutta scheme.\n        Evolves y = ln(rho) from N_i to N_f.\n        \"\"\"\n        y = np.log(rho_i) # Initial condition y_i = ln(rho_i)\n\n        # The right-hand side of the ODE dy/dN = f(N, y)\n        # In this regularized case, f is independent of y.\n        def f(N):\n            return -3.0 * A * np.tanh((N - Nc) / Delta)\n\n        # Determine the number of steps and create the grid of N values\n        num_steps = int(round((N_f - N_i) / h_reg))\n        N_vals = np.linspace(N_i, N_f, num_steps + 1)\n        # The actual step size resulting from the linspace grid\n        h_actual = N_vals[1] - N_vals[0]\n\n        for i in range(num_steps):\n            N_k = N_vals[i]\n            \n            # RK4 steps for y' = f(N)\n            k1 = h_actual * f(N_k)\n            k2 = h_actual * f(N_k + 0.5 * h_actual)\n            # Since f is independent of y, k2 and k3 are identical\n            k3 = k2 \n            k4 = h_actual * f(N_k + h_actual)\n            \n            y += (k1 + 2.0 * k2 + 2.0 * k3 + k4) / 6.0\n        \n        return np.exp(y) # Return final rho = exp(y_f)\n\n    def run_naive_euler(A, Nc, h_naive):\n        \"\"\"\n        Implements the naive comparator using an explicit Euler scheme.\n        Evolves rho directly and checks for instability (rho  0).\n        \"\"\"\n        rho = rho_i\n        instability_detected = False\n\n        # The right-hand side of the ODE drho/dN = g(N, rho)\n        def g(N, current_rho):\n            # The problem specifies sgn(0)=0, which np.sign provides.\n            return -3.0 * A * np.sign(N - Nc) * current_rho\n            \n        num_steps = int(round((N_f - N_i) / h_naive))\n        N_vals = np.linspace(N_i, N_f, num_steps + 1)\n        h_actual = N_vals[1] - N_vals[0]\n\n        for i in range(num_steps):\n            N_k = N_vals[i]\n            \n            # Explicit Euler step\n            rho += h_actual * g(N_k, rho)\n            \n            if rho  0:\n                instability_detected = True\n                # We can break early as the condition is met.\n                break\n        \n        return instability_detected\n\n    def calculate_analytic(A, Nc, Delta):\n        \"\"\"\n        Calculates the exact final energy density using the derived analytic formula.\n        \"\"\"\n        # Exponent term\n        exponent = 3.0 * A * Delta\n        \n        # Numerator and denominator of the base\n        # Using cosh with large arguments is fine within float64 limits here.\n        num_arg = (N_i - Nc) / Delta\n        den_arg = (N_f - Nc) / Delta\n        \n        base = np.cosh(num_arg) / np.cosh(den_arg)\n        \n        rho_f_exact = rho_i * (base**exponent)\n        \n        return rho_f_exact\n\n    # --- Test Cases ---\n    results = []\n\n    # Case 1: Happy path regularized evolution\n    params_1 = {'A': 0.2, 'Nc': -2.0, 'Delta': 0.2, 'h_reg': 0.01}\n    rho_f_1 = run_regularized_rk4(**params_1)\n    results.append(rho_f_1)\n\n    # Case 2: Boundary case w = -1\n    params_2 = {'A': 0.0, 'Nc': -2.0, 'Delta': 0.2, 'h_reg': 0.01}\n    rho_f_2 = run_regularized_rk4(**params_2)\n    # The problem asks for the ratio rho(a_f)/rho(a_i)\n    ratio_2 = rho_f_2 / rho_i\n    results.append(ratio_2)\n\n    # Case 3: Instability check for a coarse naive scheme\n    params_3 = {'A': 1.0, 'Nc': -1.0, 'h_naive': 0.5}\n    instability_3 = run_naive_euler(**params_3)\n    results.append(instability_3)\n\n    # Case 4: Accuracy check against the analytic solution\n    params_4 = {'A': 0.5, 'Nc': -2.0, 'Delta': 0.05, 'h_reg': 0.01}\n    rho_f_numerical_4 = run_regularized_rk4(**params_4)\n    rho_f_analytic_4 = calculate_analytic(A=params_4['A'], Nc=params_4['Nc'], Delta=params_4['Delta'])\n    relative_error_4 = np.abs(rho_f_numerical_4 - rho_f_analytic_4) / rho_f_analytic_4\n    results.append(relative_error_4)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3470966"}]}