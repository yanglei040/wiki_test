{"hands_on_practices": [{"introduction": "At the heart of simulating modified gravity lies the task of solving a partial differential equation (PDE) for the new scalar degree of freedom, $f_R$. The first step is to translate the continuous PDE into a system of algebraic equations that a computer can solve through a process called discretization. This exercise builds the foundational skill of deriving a finite-difference approximation from first principles, providing a concrete understanding of how continuous physical laws are represented in a numerical simulation and focusing on the standard seven-point stencil for the Laplacian, $\\nabla^2$, a cornerstone of many grid-based solvers. [@problem_id:3487331]", "problem": "Consider the quasi-static, sub-horizon limit of a modified gravity theory of the type $f(R)$, in which the scalar field $f_{R}$ obeys an elliptic partial differential equation (PDE) that couples to the matter density contrast. In comoving Cartesian coordinates $\\boldsymbol{x}=(x,y,z)$ with scale factor $a$, the equation takes the form\n$$\n\\nabla^{2} f_{R}(\\boldsymbol{x}) \\;=\\; \\frac{a^{2}}{3}\\Big[\\,\\delta R\\big(f_{R}(\\boldsymbol{x})\\big) \\;-\\; 8\\pi G\\,\\delta\\rho(\\boldsymbol{x})\\,\\Big],\n$$\nwhere $\\delta R\\big(f_{R}\\big)$ denotes the perturbation of the Ricci scalar as a local functional of $f_{R}$, $G$ is the Newtonian gravitational constant, and $\\delta\\rho$ is the matter density perturbation.\n\nYou will discretize this equation on a uniform, three-dimensional Cartesian mesh representing a single cosmological time slice with fixed $a$. Let the grid be defined by points $\\boldsymbol{x}_{i,j,k}=(x_{i},y_{j},z_{k})$ with uniform spacing $\\Delta x=\\Delta y=\\Delta z=h$, and let $f_{R\\,i,j,k}$ denote the value of $f_{R}$ at the grid point $(i,j,k)$. Similarly, define $\\delta\\rho_{i,j,k}$ and evaluate $\\delta R$ locally as $\\delta R\\!\\big(f_{R\\,i,j,k}\\big)$.\n\nStarting from the definition of the Laplacian operator in Cartesian coordinates and the Taylor expansion of a smooth function on a uniform grid, derive a second-order accurate, central finite-difference stencil for the Laplacian $\\nabla^{2} f_{R}$ at an interior grid point $(i,j,k)$. Use only the foundational definitions of derivatives and Taylor expansions to establish the order of accuracy of your stencil. Then write the discrete version of the elliptic equation at $(i,j,k)$ using your Laplacian approximation and the local evaluations of $\\delta R$ and $\\delta\\rho$.\n\nYour final answer must be the single, closed-form analytic expression that gives the second-order accurate finite-difference stencil for $\\nabla^{2} f_{R}$ at $(i,j,k)$. No units are required. Do not round; give the exact symbolic expression.", "solution": "The starting point is the definition of the Laplacian operator in Cartesian coordinates,\n$$\n\\nabla^{2} f_{R} \\;=\\; \\frac{\\partial^{2} f_{R}}{\\partial x^{2}} \\;+\\; \\frac{\\partial^{2} f_{R}}{\\partial y^{2}} \\;+\\; \\frac{\\partial^{2} f_{R}}{\\partial z^{2}}.\n$$\nOn a uniform grid with spacing $h$ in each direction, we construct second-order accurate approximations to each second derivative by using the central finite-difference formula derived from the Taylor expansion.\n\nConsider a one-dimensional smooth function $g$ defined on uniform points $x_{i}=x_{0}+i h$. The Taylor expansions about $x_{i}$ are\n\\begin{align*}\ng(x_{i}+h) = g(x_{i}) \\;+\\; h\\,g'(x_{i}) \\;+\\; \\frac{h^{2}}{2}\\,g''(x_{i}) \\;+\\; \\frac{h^{3}}{6}\\,g^{(3)}(x_{i}) \\;+\\; \\frac{h^{4}}{24}\\,g^{(4)}(\\xi_{+}), \\\\\ng(x_{i}-h) = g(x_{i}) \\;-\\; h\\,g'(x_{i}) \\;+\\; \\frac{h^{2}}{2}\\,g''(x_{i}) \\;-\\; \\frac{h^{3}}{6}\\,g^{(3)}(x_{i}) \\;+\\; \\frac{h^{4}}{24}\\,g^{(4)}(\\xi_{-}),\n\\end{align*}\nfor some $\\xi_{+}$ and $\\xi_{-}$ in the intervals $(x_{i},x_{i}+h)$ and $(x_{i}-h,x_{i})$, respectively. Adding these two expansions and subtracting $2 g(x_{i})$ yields\n$$\ng(x_{i}+h) - 2 g(x_{i}) + g(x_{i}-h) \\;=\\; h^{2} g''(x_{i}) \\;+\\; \\frac{h^{4}}{12}\\,g^{(4)}(\\xi),\n$$\nfor some $\\xi$ between $x_{i}-h$ and $x_{i}+h$. Dividing by $h^{2}$ gives the central difference approximation for the second derivative,\n$$\n\\frac{g(x_{i}+h) - 2 g(x_{i}) + g(x_{i}-h)}{h^{2}} \\;=\\; g''(x_{i}) \\;+\\; \\mathcal{O}\\!\\left(h^{2}\\right).\n$$\nThis shows the central second difference is second-order accurate.\n\nApply this construction to $f_{R}$ in each Cartesian direction independently. Denote $f_{R\\,i,j,k} \\equiv f_{R}(x_{i},y_{j},z_{k})$. Then\n\\begin{align*}\n\\frac{\\partial^{2} f_{R}}{\\partial x^{2}}\\bigg|_{(i,j,k)} \\approx \\frac{f_{R\\,i+1,j,k} - 2 f_{R\\,i,j,k} + f_{R\\,i-1,j,k}}{h^{2}}, \\\\\n\\frac{\\partial^{2} f_{R}}{\\partial y^{2}}\\bigg|_{(i,j,k)} \\approx \\frac{f_{R\\,i,j+1,k} - 2 f_{R\\,i,j,k} + f_{R\\,i,j-1,k}}{h^{2}}, \\\\\n\\frac{\\partial^{2} f_{R}}{\\partial z^{2}}\\bigg|_{(i,j,k)} \\approx \\frac{f_{R\\,i,j,k+1} - 2 f_{R\\,i,j,k} + f_{R\\,i,j,k-1}}{h^{2}}.\n\\end{align*}\nSumming the three approximations produces the standard second-order accurate seven-point finite-difference stencil for the Laplacian on a uniform Cartesian grid:\n$$\n\\nabla^{2} f_{R}\\big|_{(i,j,k)} \\;\\approx\\; \\frac{f_{R\\,i+1,j,k} + f_{R\\,i-1,j,k} + f_{R\\,i,j+1,k} + f_{R\\,i,j-1,k} + f_{R\\,i,j,k+1} + f_{R\\,i,j,k-1} - 6 f_{R\\,i,j,k}}{h^{2}},\n$$\nwith truncation error $\\mathcal{O}\\!\\left(h^{2}\\right)$ inherited from the one-dimensional second derivative approximations.\n\nTo discretize the elliptic scalar field equation, one evaluates the right-hand side locally at $(i,j,k)$, using the functional dependence $\\delta R\\!\\big(f_{R\\,i,j,k}\\big)$ and the sampled density contrast $\\delta\\rho_{i,j,k}$. The resulting discrete equation at an interior grid point is\n$$\n\\frac{f_{R\\,i+1,j,k} + f_{R\\,i-1,j,k} + f_{R\\,i,j+1,k} + f_{R\\,i,j-1,k} + f_{R\\,i,j,k+1} + f_{R\\,i,j,k-1} - 6 f_{R\\,i,j,k}}{h^{2}}\n\\;=\\;\n\\frac{a^{2}}{3}\\Big[\\,\\delta R\\!\\big(f_{R\\,i,j,k}\\big) \\;-\\; 8\\pi G\\,\\delta\\rho_{i,j,k}\\,\\Big],\n$$\nwhich is second-order accurate in $h$ for smooth $f_{R}$.\n\nThe requested final expression, the second-order accurate finite-difference stencil for $\\nabla^{2} f_{R}$ at $(i,j,k)$, is the numerator divided by $h^{2}$ shown above.", "answer": "$$\\boxed{\\frac{f_{R\\,i+1,j,k}+f_{R\\,i-1,j,k}+f_{R\\,i,j+1,k}+f_{R\\,i,j-1,k}+f_{R\\,i,j,k+1}+f_{R\\,i,j,k-1}-6 f_{R\\,i,j,k}}{h^{2}}}$$", "id": "3487331"}, {"introduction": "Once we can solve the field equations, a critical step is to verify that our numerical solver produces the correct physical results. A powerful validation technique is to compare the numerical output against a known analytic solution in a simplified scenario, such as the Yukawa-like potential that arises in linearized $f(R)$ gravity. This practice guides you through building and validating a spectral solver, learning to handle source regularization and quantify solver accuracy against an analytic benchmark—a fundamental practice in computational science. [@problem_id:3487375]", "problem": "You are tasked with validating a numerical solver for the modified gravity Helmholtz-type field equation that arises in linearized $f(R)$ gravity when the scalar degree of freedom has a finite Compton wavelength. Starting from fundamental physical principles and well-tested numerical facts, the goal is to compare a Fourier-space solver for the static field equation of a point-source in a periodic cubic domain to the known analytic Yukawa-type solution and quantify deviations as grid resolution is varied.\n\nBegin from the following base:\n- The modified gravitational potential in linearized $f(R)$ gravity is mediated by a scalar mode with a mass parameter $m$ that produces screened, Yukawa-type behavior. In the static, weak-field limit with non-relativistic sources, the scalar potential obeys a modified Poisson equation of Helmholtz form, which is a linear Partial Differential Equation (PDE).\n- The three-dimensional Fast Fourier Transform (FFT) on a uniform grid converts spatial convolution and differential operators into algebraic operations in wave number space, enabling spectral solvers for linear PDEs on periodic domains.\n- The Green’s function for the three-dimensional Helmholtz operator characterizes the analytic point-mass response and has Yukawa-like radial decay.\n\nConstruct a complete program that:\n1. Solves the static linear PDE on a cubic, periodic box of side length $L$ using a uniform grid with $N$ points per dimension. Assume dimensionless units with $G=1$ (Newton’s gravitational constant), total point mass $M=1$, and box size $L=1$.\n2. Approximates the point source at the box center by a narrow, normalized three-dimensional Gaussian density with standard deviation $\\sigma$ chosen proportional to the grid spacing so that $\\sigma = \\alpha \\, \\Delta x$, where $\\Delta x = L/N$ and $\\alpha$ is a fixed constant. Normalize the Gaussian to ensure that the discrete integral over the box equals $M$ to machine precision. The Gaussian regularization is necessary to avoid aliasing and to make the discrete FFT-based solver stable.\n3. Uses a spectral Helmholtz solver: transform the density $\\rho(\\mathbf{x})$ to wave number space, apply the algebraic Helmholtz kernel, and transform back to configuration space to obtain the potential $\\Phi(\\mathbf{x})$ on the grid. Use the angular wave number components $k_x$, $k_y$, $k_z$, constructed from the FFT frequency conventions for a periodic box of side $L$, and apply the appropriate discrete kernel factor of the Helmholtz operator.\n4. Compares the numerical potential $\\Phi(\\mathbf{x})$ to the analytic Yukawa-like point-mass potential for the same $m$ at grid points with radii $r$ in a shell $r \\in [r_{\\min}, r_{\\max}]$, where $r_{\\min} = 2 \\Delta x$ and $r_{\\max} = L/4$. This excludes the singular core and minimizes contamination from periodic images, while providing a fair measure of solver quality within the box. Correct for the physically irrelevant constant offset by fitting and subtracting the best constant that minimizes the squared difference on the comparison shell.\n5. Computes a single scalar deviation metric per test case: the relative root-mean-square (RMS) error\n$$\n\\varepsilon_{\\mathrm{RMS}} = \\sqrt{\\frac{\\sum_{i \\in \\mathcal{S}} \\left(\\Phi_{\\mathrm{num}}(\\mathbf{x}_i) - c^\\star - \\Phi_{\\mathrm{an}}(r_i)\\right)^2}{\\sum_{i \\in \\mathcal{S}} \\left(\\Phi_{\\mathrm{an}}(r_i)\\right)^2}},\n$$\nwhere $\\mathcal{S}$ denotes the set of grid points with $r_i \\in [r_{\\min}, r_{\\max}]$, $\\Phi_{\\mathrm{num}}$ is the numerical solution, $\\Phi_{\\mathrm{an}}$ is the analytic Yukawa-like solution for a point mass, $r_i$ is the radial distance to the source, and $c^\\star$ is the constant offset chosen to minimize the numerator. Report $\\varepsilon_{\\mathrm{RMS}}$ rounded to $6$ decimal places.\n\nUse the following test suite of parameter values to probe accuracy across resolution and Yukawa range:\n- Case $1$ (coarse resolution, moderate range): $(N, m) = (16, 10)$.\n- Case $2$ (baseline resolution, moderate range): $(N, m) = (32, 10)$.\n- Case $3$ (high resolution, moderate range): $(N, m) = (64, 10)$.\n- Case $4$ (very high resolution, moderate range): $(N, m) = (128, 10)$.\n- Case $5$ (baseline resolution, short range): $(N, m) = (64, 50)$.\n- Case $6$ (baseline resolution, longer range): $(N, m) = (32, 5)$.\n\nAll quantities are in dimensionless units with $L=1$, $G=1$, $M=1$, and angles, if any, are not used. The Gaussian width factor should be fixed to $\\alpha = 0.5$ for all cases.\n\nYour program should produce a single line of output containing the six $\\varepsilon_{\\mathrm{RMS}}$ results in the order of the cases above as a comma-separated list enclosed in square brackets (e.g., $[\\varepsilon_1,\\varepsilon_2,\\varepsilon_3,\\varepsilon_4,\\varepsilon_5,\\varepsilon_6]$), with each $\\varepsilon_i$ rounded to $6$ decimal places.", "solution": "The problem requires the validation of a numerical spectral solver for the static, linear field equation in a modified theory of gravity ($f(R)$ gravity). This involves solving the Helmholtz equation on a periodic cubic domain with a regularized point source and comparing the numerical result to the known analytic solution. The comparison is quantified by the relative root-mean-square error over a specified region of the domain.\n\n### 1. Underlying Physical Model and Governing Equation\n\nIn the weak-field, static limit, a class of $f(R)$ modified gravity theories introduces a scalar degree of freedom that modifies the standard Newtonian gravitational potential. This scalar field is massive, with a mass parameter denoted by $m$. Its presence leads to a screening mechanism where the gravitational interaction reverts to the standard Newtonian form at short distances but is suppressed at distances larger than the scalar's Compton wavelength, $\\lambda_C \\sim 1/m$.\n\nThe combined gravitational potential, $\\Phi(\\mathbf{x})$, sourced by a non-relativistic mass density $\\rho(\\mathbf{x})$, is described by a modified Poisson equation of the Helmholtz type:\n$$\n(\\nabla^2 - m^2) \\Phi(\\mathbf{x}) = 4\\pi G \\rho(\\mathbf{x})\n$$\nwhere $\\nabla^2$ is the Laplace operator and $G$ is the gravitational constant. For this problem, we work in dimensionless units where the box size is $L=1$, the total mass is $M=1$, and Newton's constant is $G=1$. The equation becomes:\n$$\n(\\nabla^2 - m^2) \\Phi(\\mathbf{x}) = 4\\pi \\rho(\\mathbf{x})\n$$\nFor a point mass $M$ located at the origin, i.e., $\\rho(\\mathbf{x}) = M \\delta(\\mathbf{x})$, the analytic solution to this equation in an infinite domain is the Yukawa potential:\n$$\n\\Phi_{\\mathrm{an}}(r) = - \\frac{G M e^{-mr}}{r}\n$$\nwhere $r = |\\mathbf{x}|$ is the radial distance from the source. With our choice of units ($G=1$, $M=1$), this simplifies to:\n$$\n\\Phi_{\\mathrm{an}}(r) = - \\frac{e^{-mr}}{r}\n$$\nThis analytic solution serves as the benchmark against which our numerical solution will be compared.\n\n### 2. Numerical Solution via Spectral Method\n\nWe solve the Helmholtz equation on a periodic cubic domain of side length $L=1$, discretized into a uniform grid of $N \\times N \\times N$ points. The grid spacing is $\\Delta x = L/N$. The periodicity of the domain makes the Fourier spectral method an exceptionally efficient and accurate choice.\n\nThe method leverages the convolution theorem and the differentiation property of the Fourier Transform. The Fourier transform of the Laplacian operator is $\\mathcal{F}[\\nabla^2 f(\\mathbf{x})] = -k^2 \\tilde{f}(\\mathbf{k})$, where $\\tilde{f}(\\mathbf{k})$ is the Fourier transform of $f(\\mathbf{x})$ and $k=|\\mathbf{k}|$ is the magnitude of the wave vector $\\mathbf{k}$. Applying the Fourier transform to the Helmholtz equation converts the partial differential equation into a simple algebraic equation in wave number space:\n$$\n(-k^2 - m^2) \\tilde{\\Phi}(\\mathbf{k}) = 4\\pi \\tilde{\\rho}(\\mathbf{k})\n$$\nHere, $\\tilde{\\Phi}(\\mathbf{k})$ and $\\tilde{\\rho}(\\mathbf{k})$ are the discrete Fourier transforms of the potential and density fields on the grid, respectively. We can solve directly for the potential in Fourier space:\n$$\n\\tilde{\\Phi}(\\mathbf{k}) = - \\frac{4\\pi \\tilde{\\rho}(\\mathbf{k})}{k^2 + m^2}\n$$\nThis expression is the Helmholtz kernel applied in Fourier space. Since all test cases have $m  0$, the denominator $k^2+m^2$ is strictly positive for all real wave vectors $\\mathbf{k}$, so the operation is well-defined for all modes, including the $k=0$ (DC) mode.\n\nThe numerical solution $\\Phi_{\\mathrm{num}}(\\mathbf{x})$ in configuration space is then recovered by performing an inverse Fourier transform on $\\tilde{\\Phi}(\\mathbf{k})$.\n\n### 3. Implementation Details\n\n**Source Regularization**: A true point mass, represented by a Dirac delta function $\\delta(\\mathbf{x})$, is singular and cannot be represented on a discrete grid without aliasing errors. We regularize the source by modeling it as a narrow, three-dimensional Gaussian function centered at the origin of the coordinate system:\n$$\n\\rho(\\mathbf{x}) = A \\exp\\left(-\\frac{r^2}{2\\sigma^2}\\right)\n$$\nThe standard deviation $\\sigma$ is chosen to be a fraction of the grid spacing, $\\sigma = \\alpha \\Delta x$, with $\\alpha = 0.5$. The normalization constant $A$ is set such that the discrete integral over the box equals the total mass $M=1$: $\\sum_{i,j,k} \\rho(\\mathbf{x}_{ijk}) (\\Delta x)^3 = M$.\n\n**Computational Workflow**:\n1.  **Grid Setup**: A three-dimensional coordinate grid is constructed, centered at the origin. Let the coordinates for one dimension be $x_i = (-L/2 + i \\cdot \\Delta x)$ for $i=0, \\dots, N-1$.\n2.  **Density Field**: The normalized Gaussian density $\\rho(\\mathbf{x})$ is computed on this centered grid.\n3.  **Forward FFT**: For use with standard FFT algorithms, the centered grid data $\\rho(\\mathbf{x})$ is shifted using `ifftshift` to place the origin at the array index $(0,0,0)$. The 3D Fast Fourier Transform (`fftn`) is then applied to obtain $\\tilde{\\rho}(\\mathbf{k})$.\n4.  **Wave Vector Grid**: A corresponding grid of wave vectors $\\mathbf{k}=(k_x, k_y, k_z)$ is generated using the `fftfreq` function, which produces wave numbers in the order expected by the FFT algorithm: $k_i = 2\\pi f_i$, where $f_i$ are the spatial frequencies.\n5.  **Kernel Application**: The algebraic Helmholtz kernel is applied element-wise to $\\tilde{\\rho}(\\mathbf{k})$ to compute $\\tilde{\\Phi}(\\mathbf{k})$.\n6.  **Inverse FFT**: The inverse 3D FFT (`ifftn`) is applied to $\\tilde{\\Phi}(\\mathbf{k})$ to obtain the potential in configuration space (in FFT order).\n7.  **Final Potential**: The result is shifted back to the centered representation using `fftshift`, and the real part is taken to yield the numerical potential $\\Phi_{\\mathrm{num}}(\\mathbf{x})$.\n\n### 4. Error Analysis and Validation Metric\n\nThe accuracy of the numerical solver is assessed by comparing $\\Phi_{\\mathrm{num}}$ to the analytic solution $\\Phi_{\\mathrm{an}}$.\n\n**Comparison Region**: The comparison is restricted to a spherical shell $\\mathcal{S}$ defined by radii $r \\in [r_{\\min}, r_{\\max}]$, where $r_{\\min} = 2\\Delta x$ and $r_{\\max} = L/4$. This choice serves two purposes:\n-   Excluding $r  2\\Delta x$ avoids the region near the source where the Gaussian regularization causes the numerical potential to deviate significantly from the singular $1/r$ behavior of the true point-mass solution.\n-   Excluding $r  L/4$ minimizes contamination from periodic images of the source, which are inherent to the periodic boundary conditions of the solver but absent in the infinite-domain analytic formula.\n\n**Offset Correction**: The $k=0$ mode of the potential, which represents the average value over the box, has no physical consequence as only potential gradients are observable. The numerical and analytic solutions may differ by an arbitrary constant offset. To ensure a fair comparison, we calculate and subtract the optimal constant offset $c^\\star$ that minimizes the mean-squared error between the two solutions on the shell $\\mathcal{S}$. This is simply the mean of the difference:\n$$\nc^\\star = \\frac{1}{|\\mathcal{S}|} \\sum_{i \\in \\mathcal{S}} \\left( \\Phi_{\\mathrm{num}}(\\mathbf{x}_i) - \\Phi_{\\mathrm{an}}(r_i) \\right)\n$$\nwhere $|\\mathcal{S}|$ is the number of grid points in the shell.\n\n**Error Metric**: The final accuracy is quantified by the relative root-mean-square (RMS) error, $\\varepsilon_{\\mathrm{RMS}}$, defined as:\n$$\n\\varepsilon_{\\mathrm{RMS}} = \\sqrt{\\frac{\\sum_{i \\in \\mathcal{S}} \\left(\\Phi_{\\mathrm{num}}(\\mathbf{x}_i) - c^\\star - \\Phi_{\\mathrm{an}}(r_i)\\right)^2}{\\sum_{i \\in \\mathcal{S}} \\left(\\Phi_{\\mathrm{an}}(r_i)\\right)^2}}\n$$\nThis metric provides a normalized measure of the deviation of the numerical solution from the true physical behavior, after accounting for the physically irrelevant constant offset. A smaller $\\varepsilon_{\\mathrm{RMS}}$ indicates a more accurate solver.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        (16, 10),  # Case 1\n        (32, 10),  # Case 2\n        (64, 10),  # Case 3\n        (128, 10), # Case 4\n        (64, 50),  # Case 5\n        (32, 5),   # Case 6\n    ]\n\n    results = []\n    for N, m in test_cases:\n        epsilon_rms = run_simulation(N, m)\n        results.append(round(epsilon_rms, 6))\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_simulation(N, m):\n    \"\"\"\n    Performs a single simulation for a given grid resolution N and mass parameter m.\n\n    Args:\n        N (int): Number of grid points per dimension.\n        m (float): Mass parameter for the Yukawa potential.\n\n    Returns:\n        float: The calculated relative RMS error epsilon_RMS.\n    \"\"\"\n    # --- 1. Define Constants and Grid Parameters ---\n    L = 1.0  # Box size\n    M = 1.0  # Total mass\n    G = 1.0  # Gravitational constant\n    alpha = 0.5  # Gaussian width factor\n\n    dx = L / N  # Grid spacing\n    sigma = alpha * dx  # Gaussian standard deviation\n\n    # --- 2. Create Centered Coordinate Grid ---\n    # Create monotonic coordinates from -L/2 to L/2\n    x_1d = -L/2 + np.arange(N) * dx\n    xg, yg, zg = np.meshgrid(x_1d, x_1d, x_1d, indexing='ij')\n\n    # Calculate radial distance from the center (0,0,0) for each grid point\n    r = np.sqrt(xg**2 + yg**2 + zg**2)\n\n    # --- 3. Create Regularized Source Density ---\n    # Centered Gaussian density profile\n    rho = np.exp(-r**2 / (2 * sigma**2))\n\n    # Normalize so that the discrete integral sum(rho_ijk * dx^3) equals M\n    rho_sum = np.sum(rho)\n    rho *= M / (rho_sum * dx**3)\n\n    # --- 4. Spectral Solver ---\n    # Shift the centered density to be compatible with FFT (origin at index 0)\n    rho_fft_ordered = np.fft.ifftshift(rho)\n\n    # Fourier transform the density\n    rho_k = np.fft.fftn(rho_fft_ordered)\n\n    # Create the grid of wave numbers (k)\n    k_vals = 2 * np.pi * np.fft.fftfreq(N, d=dx)\n    kx, ky, kz = np.meshgrid(k_vals, k_vals, k_vals, indexing='ij')\n    k_squared = kx**2 + ky**2 + kz**2\n\n    # Apply the Helmholtz kernel in Fourier space\n    # phi_k = -4 * pi * G * rho_k / (k^2 + m^2)\n    # Since m  0, the denominator is never zero.\n    phi_k = -4 * np.pi * G * rho_k / (k_squared + m**2)\n    \n    # Inverse Fourier transform to get the potential in configuration space\n    phi_fft_ordered = np.fft.ifftn(phi_k)\n\n    # Shift the result back to a centered representation and take the real part\n    phi_num = np.fft.fftshift(phi_fft_ordered).real\n\n    # --- 5. Error Calculation ---\n    # Define the comparison shell\n    r_min = 2 * dx\n    r_max = L / 4\n    shell_mask = (r = r_min)  (r = r_max)\n\n    # Select numerical solution and radial distances within the shell\n    phi_num_shell = phi_num[shell_mask]\n    r_shell = r[shell_mask]\n\n    # Calculate analytic Yukawa solution on the shell\n    # phi_an = -G * M * exp(-m*r) / r\n    # r_shell is guaranteed to be non-zero due to r_min  0\n    phi_an_shell = -G * M * np.exp(-m * r_shell) / r_shell\n\n    # Calculate the best-fit constant offset c_star\n    diff = phi_num_shell - phi_an_shell\n    c_star = np.mean(diff)\n\n    # Calculate the numerator and denominator for the relative RMS error\n    numerator = np.sum((phi_num_shell - c_star - phi_an_shell)**2)\n    denominator = np.sum(phi_an_shell**2)\n    \n    # Calculate final error metric, avoiding division by zero\n    if denominator == 0:\n        epsilon_rms = 0.0 if numerator == 0 else np.inf\n    else:\n        epsilon_rms = np.sqrt(numerator / denominator)\n\n    return epsilon_rms\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3487375"}, {"introduction": "The full equations of $f(R)$ gravity are nonlinear, making them significantly more challenging to solve than their linearized counterparts. Efficiently tackling such equations requires advanced numerical techniques like the Newton-multigrid method, which combines the fast convergence of Newton's method for nonlinear problems with the optimal efficiency of multigrid methods for the resulting linear systems. This advanced practice challenges you to construct the core components of a research-grade nonlinear solver, gaining hands-on experience with the sophisticated algorithms used in modern cosmological codes to simulate the complex dynamics of modified gravity. [@problem_id:3487385]", "problem": "Consider a dimensionless scalar field equation representing the quasi-static limit of metric $f(R)$ gravity for the $f_{R}$ scalar on a square domain. Let $u(x,y)$ denote the dimensionless field $u \\equiv f_{R} / \\bar{f}_{R}$, where $\\bar{f}_{R}$ is a homogeneous background value. In the high-curvature regime relevant to cosmological structure formation, the trace of the modified Einstein equations implies a nonlinear elliptic Partial Differential Equation (PDE) of the schematic form\n$$\n\\nabla^{2} u = \\kappa \\left( u^{-n} - 1 \\right) + s(x,y),\n$$\nwhere $\\kappa  0$ is a dimensionless coupling constant that encodes the strength of the modification to General Relativity, $n  0$ controls the nonlinearity, and $s(x,y)$ is a dimensionless source proportional to the matter density perturbation. Assume a unit square domain $[0,1] \\times [0,1]$ with Dirichlet boundary conditions $u = 1$ on $\\partial \\Omega$. Angles inside any trigonometric functions must be interpreted in radians.\n\nStarting from fundamental principles and well-tested numerical methods, construct a Newton–multigrid V-cycle solver for the nonlinear elliptic PDE. The design must begin from:\n- The definition of the elliptic operator and the finite-difference approximation of $\\nabla^{2}$ on a uniform grid.\n- Newton’s method (also known as Newton–Raphson) applied to the nonlinear residual to produce a sequence of linearized correction problems.\n- A multigrid V-cycle to approximately solve the linearized system $J(u) \\, \\delta u = -R(u)$ at each Newton step, where $R(u)$ is the discrete nonlinear residual and $J(u)$ is the Jacobian of the discretized operator.\n\nYour construction must specify:\n1. The discrete residual $R(u)$ using a second-order centered finite-difference approximation of $\\nabla^{2}$ on a uniform grid of size $N \\times N$ with spacing $h$, under Dirichlet boundary conditions $u=1$ on the boundary nodes.\n2. The Jacobian assembly for the local nonlinear term, including the analytical expression for its derivative with respect to $u$ that contributes to the diagonal of $J(u)$.\n3. The relaxation scheme on each grid level to act as a smoother for the linearized system. Use weighted Jacobi with relaxation parameter $\\omega \\in (0,1)$.\n4. The coarse-grid correction, including:\n   - Full-weighting restriction of the residual to the next coarser grid.\n   - Bilinear prolongation of the coarse-grid correction back to the finer grid.\n   - Re-linearization on the coarse grid using the restricted $u$ to assemble the coarse-grid Jacobian diagonal consistently.\n5. Robust convergence criteria based on residual reduction. Let $\\| R(u) \\|_{2}$ denote the discrete $L^{2}$ norm computed with the grid spacing $h$. Define the initial residual norm $\\| R(u^{(0)}) \\|_{2}$ at the starting guess $u^{(0)}$. The Newton iteration is deemed converged if both conditions hold:\n   - The reduction ratio $\\rho \\equiv \\| R(u^{(k)}) \\|_{2} / \\| R(u^{(0)}) \\|_{2}$ satisfies $\\rho \\le \\theta$ for a prescribed threshold $\\theta$.\n   - The absolute residual norm satisfies $\\| R(u^{(k)}) \\|_{2} \\le \\varepsilon$, for a prescribed tolerance $\\varepsilon$.\nUse a maximum number of Newton iterations to prevent infinite loops. Implement a simple line search or step damping to maintain positivity of $u$ in the interior nodes during updates.\n\nDiscretization requirements:\n- Use a uniform grid of size $N \\times N$ with $N = 2^{\\ell} + 1$ for some integer $\\ell \\ge 3$, so that standard coarsening is possible down to a $3 \\times 3$ grid.\n- Use second-order centered finite differences for $\\nabla^{2}$ on interior nodes, with the discrete stencil $[1,1,-4,1,1]/h^{2}$.\n- The source $s(x,y)$ must be specified as\n$$\ns(x,y) = A \\left[ \\sin(2\\pi x) \\sin(2\\pi y) + \\tfrac{1}{4} \\sin(4\\pi x) \\sin(2\\pi y) \\right],\n$$\nwith amplitude $A$ a dimensionless scalar. Angles are in radians.\n\nNewton–multigrid specifications:\n- The Jacobian $J(u)$ is the sum of the discrete Laplacian and the diagonal contribution from the derivative of the nonlinear term. For the nonlinear term $\\kappa(u^{-n} - 1)$, its derivative with respect to $u$ is $\\kappa n u^{-n-1}$, which contributes a pointwise diagonal term on the grid. Use a small positive $\\epsilon$ to avoid division by zero in $u^{-n}$ and $u^{-n-1}$ by evaluating $u$ as $\\max(u,\\epsilon)$ when needed.\n- Use weighted Jacobi smoothing with relaxation factor $\\omega$ and a fixed number $\\nu_{1}$ of pre-smoothing iterations and $\\nu_{2}$ of post-smoothing iterations on each level.\n- Use full-weighting restriction and bilinear prolongation for grid transfers.\n- At the coarsest level, replace the coarse-grid solve by additional relaxation iterations on that grid.\n\nConvergence criteria and output:\n- Compute the discrete $L^{2}$ norm of the residual as\n$$\n\\| R(u) \\|_{2} = \\left( h^{2} \\sum_{i,j} R(u)_{i,j}^{2} \\right)^{1/2}.\n$$\n- For each test case, report whether the solver meets the convergence criteria ($\\rho \\le \\theta$ and $\\| R(u) \\|_{2} \\le \\varepsilon$) within the maximum number of Newton iterations. The output for each case must be a boolean, with $\\mathrm{True}$ indicating successful convergence and $\\mathrm{False}$ otherwise.\n\nTest suite:\nProvide a program that runs the solver for the following parameter sets. In all cases, Dirichlet boundary conditions $u=1$ are imposed, the initial guess is $u^{(0)} \\equiv 1$, the angles in $s(x,y)$ are in radians, and the final output must be a single line containing the results as a comma-separated list enclosed in square brackets.\n\n- Case 1 (happy path): $N=65$, $\\kappa=1.0$, $n=1.0$, $A=0.1$, $\\omega=0.8$, $\\nu_{1}=3$, $\\nu_{2}=3$, maximum Newton iterations $=20$, $\\theta=10^{-6}$, $\\varepsilon=10^{-8}$.\n- Case 2 (stronger nonlinearity): $N=33$, $\\kappa=2.0$, $n=2.0$, $A=0.3$, $\\omega=0.75$, $\\nu_{1}=4$, $\\nu_{2}=4$, maximum Newton iterations $=25$, $\\theta=10^{-6}$, $\\varepsilon=10^{-8}$.\n- Case 3 (near-linear regime): $N=65$, $\\kappa=0.2$, $n=1.0$, $A=0.05$, $\\omega=0.8$, $\\nu_{1}=3$, $\\nu_{2}=3$, maximum Newton iterations $=15$, $\\theta=10^{-7}$, $\\varepsilon=10^{-9}$.\n- Case 4 (coarser grid, moderate nonlinearity): $N=17$, $\\kappa=1.5$, $n=1.5$, $A=0.2$, $\\omega=0.7$, $\\nu_{1}=4$, $\\nu_{2}=4$, maximum Newton iterations $=20$, $\\theta=10^{-6}$, $\\varepsilon=10^{-8}$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[b_{1},b_{2},b_{3},b_{4}]$), where each $b_{i}$ is a boolean indicating convergence for the corresponding test case.", "solution": "This problem requires the construction of a Newton-multigrid solver to find the numerical solution for a nonlinear elliptic partial differential equation (PDE) arising in the context of $f(R)$ gravity. The approach combines Newton's method to linearize the nonlinear system and a multigrid V-cycle to efficiently solve the resulting linear system at each iteration. This document outlines the principled derivation of the algorithm.\n\n### Algorithmic Construction\n\nThe core of the problem is to find the solution $u(x,y)$ that satisfies the PDE. We will use a finite difference discretization and solve the resulting system of nonlinear algebraic equations using Newton's method, with each linear step accelerated by a multigrid V-cycle.\n\n**1. Discretization and Nonlinear Residual**\n\nWe define a uniform grid with points $(x_i, y_j) = (ih, jh)$ for $i,j \\in \\{0, \\dots, N-1\\}$, where $h=1/(N-1)$. Let $u_{i,j} \\approx u(x_i, y_j)$. The PDE can be rewritten as a residual equation $R(u) = 0$, where\n$$\nR(u) \\equiv \\nabla^2 u - \\kappa(u^{-n} - 1) - s(x,y) = 0.\n$$\nUsing a second-order centered finite difference approximation for the Laplacian, the discrete residual for an interior node $(i,j)$ is:\n$$\nR(u)_{i,j} = \\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2} - \\kappa\\left(u_{i,j}^{-n} - 1\\right) - s_{i,j} = 0.\n$$\nFor boundary nodes, $u_{i,j}=1$, and the residual is not defined. We seek a grid function $u$ that makes $R(u)_{i,j}=0$ for all interior nodes $i,j \\in \\{1, \\dots, N-2\\}$.\n\n**2. Newton's Method for Nonlinear Systems**\n\nNewton's method iteratively finds the root of $R(u)=0$. Given an approximation $u^{(k)}$, the next approximation $u^{(k+1)} = u^{(k)} + \\delta u$ is found by solving the linearized system:\n$$\nR(u^{(k+1)}) \\approx R(u^{(k)}) + J(u^{(k)}) \\delta u = 0,\n$$\nwhere $J(u)$ is the Jacobian matrix of $R(u)$. This leads to the linear system for the correction $\\delta u$:\n$$\nJ(u^{(k)}) \\delta u = -R(u^{(k)}).\n$$\nThe Jacobian is the matrix of partial derivatives, $J_{ab} = \\partial R_a / \\partial u_b$, where $a$ and $b$ are indices over the grid points. The operator consists of two parts: the discrete Laplacian and the derivative of the nonlinear term. The derivative of the term $-\\kappa(u^{-n}-1)$ with respect to $u$ at a point $(i,j)$ is $+\\kappa n u_{i,j}^{-n-1}$. This only affects the diagonal elements of the Jacobian. Thus, the action of the Jacobian on a grid function $\\delta u$ is:\n$$\n(J(u)\\delta u)_{i,j} = (\\nabla_h^2 \\delta u)_{i,j} + \\left(\\kappa n u_{i,j}^{-n-1}\\right) \\delta u_{i,j}.\n$$\nAfter solving for $\\delta u$, we update the solution with a damped step: $u^{(k+1)} = u^{(k)} + \\alpha \\delta u$, where $\\alpha \\in (0,1]$ is a damping factor chosen to ensure $u^{(k+1)}_{i,j}  0$ for all interior nodes.\n\n**3. Multigrid V-Cycle for the Linear System**\n\nAt each Newton step, we must solve a linear system of the form $Ax=b$, where $A=J(u^{(k)})$, $x=\\delta u$, and $b=-R(u^{(k)})$. This is done approximately using one V-cycle of a geometric multigrid method.\n\nA V-cycle consists of the following recursive steps, moving from a fine grid (level $\\ell$) to a coarse grid (level $\\ell-1$):\n\n1.  **Pre-smoothing**: Apply $\\nu_1$ iterations of a smoother (weighted Jacobi) to the system $Ax=b$ on the current grid to get an approximate solution $x'$. The weighted Jacobi iteration for a generic linear system $Ax=b$ is:\n    $$\n    x^{(m+1)} = (1-\\omega)x^{(m)} + \\omega D^{-1}(b - (A-D)x^{(m)}),\n    $$\n    where $D$ is the diagonal of $A$. For our specific Jacobian $J(u)$, the diagonal entry is $J_{ii} = -4/h^2 + \\kappa n u_{i,j}^{-n-1}$.\n\n2.  **Coarse-Grid Correction**:\n    -   Compute the residual of the linear system: $r' = b - Ax'$.\n    -   Restrict the residual to the next coarser grid: $r_c = \\mathcal{R}(r')$. We use **full-weighting restriction**, a weighted average of a $3\\times3$ block of fine-grid points.\n    -   The problem on the coarse grid is $A_c e_c = r_c$, where $e_c$ is the coarse-grid representation of the error $e' = x-x'$. The problem states we must **re-linearize** on the coarse grid. This means we restrict the current nonlinear solution $u$ to get $u_c = \\mathcal{R}(u)$ and then assemble the coarse-grid operator $A_c = J(u_c)$.\n    -   Solve $A_c e_c = r_c$ recursively by calling the V-cycle on the coarse grid. At the coarsest level (a $3\\times3$ grid), the system is solved by applying a larger number of smoothing iterations.\n    -   Prolongate the error correction back to the fine grid: $e' = \\mathcal{P}(e_c)$. We use **bilinear prolongation (interpolation)**.\n    -   Correct the fine-grid solution: $x'' = x' + e'$.\n\n3.  **Post-smoothing**: Apply $\\nu_2$ iterations of the smoother to $Ax=b$ with $x''$ as the initial guess to get the final approximation for this level.\n\n**4. Convergence Criteria**\n\nThe outer Newton loop terminates when the $L^2$ norm of the nonlinear residual $R(u^{(k)})$ is sufficiently small. The discrete $L^2$ norm is defined as $\\|R(u)\\|_{2} = \\sqrt{h^2 \\sum_{i,j} (R(u)_{i,j})^2}$. Two conditions must be met:\n1.  Relative reduction: The ratio of the current residual norm to the initial residual norm, $\\rho = \\|R(u^{(k)})\\|_2 / \\|R(u^{(0)})\\|_2$, must be less than a threshold $\\theta$.\n2.  Absolute tolerance: The current residual norm, $\\|R(u^{(k)})\\|_2$, must be less than a tolerance $\\varepsilon$.\nA maximum number of iterations is also enforced to prevent non-termination. The boolean result for each test case reflects whether these criteria are met.", "answer": "```python\nimport numpy as np\nfrom math import log2\n\n# A small constant to prevent division by zero in u^(-n) terms.\nU_EPSILON = 1e-12\n\ndef _create_levels_data(N_finest):\n    \"\"\"Creates a list of dictionaries holding data for each grid level.\"\"\"\n    if N_finest  3 or log2(N_finest - 1) != int(log2(N_finest - 1)):\n        raise ValueError(\"N must be of the form 2**l + 1 for integer l = 1.\")\n    l_finest = int(log2(N_finest - 1))\n    levels_data = []\n    # Levels go from finest (l_finest) down to coarsest (l=1, N=3)\n    for l in range(l_finest, 0, -1):\n        N = 2**l + 1\n        h = 1.0 / (N - 1)\n        levels_data.append({'N': N, 'h': h})\n    return levels_data\n\ndef _setup_source_term(N, A):\n    \"\"\"Initializes the source term s(x,y) on the grid.\"\"\"\n    x_coords = np.linspace(0.0, 1.0, N)\n    xx, yy = np.meshgrid(x_coords, x_coords)\n    s = A * (np.sin(2 * np.pi * xx) * np.sin(2 * np.pi * yy) + 0.25 * np.sin(4 * np.pi * xx) * np.sin(2 * np.pi * yy))\n    return s\n\ndef _calculate_residual(u, s, h, kappa, n):\n    \"\"\"Calculates the nonlinear residual R(u) on the interior of the grid.\"\"\"\n    res = np.zeros_like(u)\n    u_reg = np.maximum(u, U_EPSILON)\n    \n    lap_u = (u[:-2, 1:-1] + u[2:, 1:-1] + u[1:-1, :-2] + u[1:-1, 2:] - 4 * u[1:-1, 1:-1]) / h**2\n    nonlinear_term = kappa * (u_reg[1:-1, 1:-1]**(-n) - 1.0)\n    \n    res[1:-1, 1:-1] = lap_u - nonlinear_term - s[1:-1, 1:-1]\n    return res\n\ndef _calculate_l2_norm(r, h):\n    \"\"\"Calculates the discrete L2 norm of a grid function over interior points.\"\"\"\n    return np.sqrt(h**2 * np.sum(r[1:-1, 1:-1]**2))\n\ndef _calculate_jacobian_diag_inner(u_inner, h, kappa, n):\n    \"\"\"Calculates the diagonal of the Jacobian J(u) on interior points.\"\"\"\n    u_reg_inner = np.maximum(u_inner, U_EPSILON)\n    diag_inner = -4.0 / h**2 + kappa * n * u_reg_inner**(-n-1)\n    return diag_inner\n\ndef _apply_J(x, u, h, kappa, n):\n    \"\"\"Applies the Jacobian operator J(u) to a grid function x.\"\"\"\n    res = np.zeros_like(x)\n    lap_x_inner = (x[:-2, 1:-1] + x[2:, 1:-1] + x[1:-1, :-2] + x[1:-1, 2:] - 4 * x[1:-1, 1:-1]) / h**2\n    \n    u_reg_inner = np.maximum(u[1:-1, 1:-1], U_EPSILON)\n    jac_diag_term_inner = (kappa * n * u_reg_inner**(-n-1)) * x[1:-1, 1:-1]\n    \n    res[1:-1, 1:-1] = lap_x_inner + jac_diag_term_inner\n    return res\n\ndef _relax(x, b, u, h, kappa, n, omega, nu):\n    \"\"\"Performs nu sweeps of weighted Jacobi relaxation for J(u)x=b.\"\"\"\n    diag_J_inner = _calculate_jacobian_diag_inner(u[1:-1, 1:-1], h, kappa, n)\n\n    for _ in range(nu):\n        lap_x_term = (x[:-2, 1:-1] + x[2:, 1:-1] + x[1:-1, :-2] + x[1:-1, 2:])\n        \n        x_jacobi_inner = (b[1:-1, 1:-1] - lap_x_term / h**2) / diag_J_inner\n        \n        x[1:-1, 1:-1] = (1.0 - omega) * x[1:-1, 1:-1] + omega * x_jacobi_inner\n    return x\n\ndef _restrict(f):\n    \"\"\"Performs full-weighting restriction from a fine grid f to a coarse grid c.\"\"\"\n    Nf = f.shape[0]\n    Nc = (Nf - 1) // 2 + 1\n    c = np.zeros((Nc, Nc))\n    \n    # Interior points\n    c[1:-1, 1:-1] = ( f[1:-2:2, 1:-2:2] + f[1:-2:2, 3::2] + f[3::2, 1:-2:2] + f[3::2, 3::2] + # corners (w=1)\n                    (f[1:-2:2, 2:-1:2] + f[3::2, 2:-1:2] + f[2:-1:2, 1:-2:2] + f[2:-1:2, 3::2]) * 2.0 + # edges (w=2)\n                     f[2:-1:2, 2:-1:2] * 4.0 ) / 16.0 # center (w=4)\n\n    # Boundaries\n    c[0, :] = f[0, ::2]\n    c[-1, :] = f[-1, ::2]\n    c[:, 0] = f[::2, 0]\n    c[:, -1] = f[::2, -1]\n    \n    return c\n    \ndef _prolongate(c):\n    \"\"\"Performs bilinear prolongation from a coarse grid c to a fine grid f.\"\"\"\n    Nc = c.shape[0]\n    Nf = (Nc - 1) * 2 + 1\n    f = np.zeros((Nf, Nf))\n    \n    f[::2, ::2] = c\n    f[1::2, ::2] = (c[:-1, :] + c[1:, :]) / 2.0\n    f[::2, 1::2] = (c[:, :-1] + c[:, 1:]) / 2.0\n    f[1::2, 1::2] = (c[:-1, :-1] + c[1:, :-1] + c[:-1, 1:] + c[1:, 1:]) / 4.0\n    return f\n\ndef _v_cycle(level_idx, b, levels_u, levels_data, params):\n    \"\"\"A single multigrid V-cycle to approximately solve J(u)x = b.\"\"\"\n    kappa, n = params['kappa'], params['n']\n    omega, nu1, nu2 = params['omega'], params['nu1'], params['nu2']\n    \n    u = levels_u[level_idx]\n    h = levels_data[level_idx]['h']\n    \n    x = np.zeros_like(b)\n\n    if level_idx == len(levels_data) - 1: # Coarsest level\n        coarsest_sweeps = 2 * (nu1 + nu2) * (level_idx + 1)\n        x = _relax(x, b, u, h, kappa, n, omega, coarsest_sweeps)\n        return x\n\n    # 1. Pre-smoothing\n    x = _relax(x, b, u, h, kappa, n, omega, nu1)\n\n    # 2. Coarse-grid correction\n    res_fine = b - _apply_J(x, u, h, kappa, n)\n    res_coarse = _restrict(res_fine)\n    \n    correction_coarse = _v_cycle(level_idx + 1, res_coarse, levels_u, levels_data, params)\n    \n    correction_fine = _prolongate(correction_coarse)\n    x += correction_fine\n\n    # 3. Post-smoothing\n    x = _relax(x, b, u, h, kappa, n, omega, nu2)\n    \n    return x\n\ndef run_case(N, kappa, n, A, omega, nu1, nu2, max_newton, theta, epsilon_conv):\n    \"\"\"Runs the Newton-MG solver for a single test case.\"\"\"\n    try:\n        levels_data = _create_levels_data(N)\n    except ValueError as e:\n        print(f\"Error setting up grid: {e}\")\n        return False\n        \n    h_finest = levels_data[0]['h']\n\n    u = np.ones((N, N))\n    s = _setup_source_term(N, A)\n\n    r0 = _calculate_residual(u, s, h_finest, kappa, n)\n    norm_r0 = _calculate_l2_norm(r0, h_finest)\n    if norm_r0  epsilon_conv:\n        return True\n\n    for _ in range(max_newton):\n        r_k = _calculate_residual(u, s, h_finest, kappa, n)\n        norm_r_k = _calculate_l2_norm(r_k, h_finest)\n\n        if norm_r_k = epsilon_conv and norm_r_k / norm_r0 = theta:\n            return True\n\n        b = -r_k\n        \n        levels_u = [u]\n        for i in range(len(levels_data) - 1):\n            levels_u.append(_restrict(levels_u[-1]))\n\n        mg_params = {'kappa': kappa, 'n': n, 'omega': omega, 'nu1': nu1, 'nu2': nu2}\n\n        delta_u = _v_cycle(0, b, levels_u, levels_data, mg_params)\n        \n        alpha = 1.0\n        for _ in range(10): # Line search iterations\n            u_new = u + alpha * delta_u\n            if np.min(u_new[1:-1, 1:-1])  U_EPSILON:\n                break\n            alpha /= 2.0\n        else: # If loop completes without break\n            return False # Failed to find a positive update\n\n        u = u_new\n\n    return False\n\ndef solve():\n    test_cases = [\n        {'N': 65, 'kappa': 1.0, 'n': 1.0, 'A': 0.1, 'omega': 0.8, 'nu1': 3, 'nu2': 3, 'max_newton': 20, 'theta': 1e-6, 'epsilon_conv': 1e-8},\n        {'N': 33, 'kappa': 2.0, 'n': 2.0, 'A': 0.3, 'omega': 0.75, 'nu1': 4, 'nu2': 4, 'max_newton': 25, 'theta': 1e-6, 'epsilon_conv': 1e-8},\n        {'N': 65, 'kappa': 0.2, 'n': 1.0, 'A': 0.05, 'omega': 0.8, 'nu1': 3, 'nu2': 3, 'max_newton': 15, 'theta': 1e-7, 'epsilon_conv': 1e-9},\n        {'N': 17, 'kappa': 1.5, 'n': 1.5, 'A': 0.2, 'omega': 0.7, 'nu1': 4, 'nu2': 4, 'max_newton': 20, 'theta': 1e-6, 'epsilon_conv': 1e-8},\n    ]\n\n    results = []\n    for case in test_cases:\n        converged = run_case(**case)\n        results.append(str(converged))\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3487385"}]}