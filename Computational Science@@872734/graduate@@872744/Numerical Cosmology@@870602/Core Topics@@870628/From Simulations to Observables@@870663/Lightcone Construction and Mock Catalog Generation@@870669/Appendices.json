{"hands_on_practices": [{"introduction": "Before we can construct a detailed mock catalog, we must first understand the fundamental population of objects that inhabit our simulated universe. This practice provides a crucial first step, connecting the theoretical halo mass function—a key prediction of cosmological structure formation—to the concrete task of calculating the expected number of dark matter halos within a specific cosmic volume. By working through this calculation, you will gain hands-on experience with the statistical foundations that underpin all mock catalog generation [@problem_id:3477518].", "problem": "In the construction of a past lightcone for a mock halo catalog in numerical cosmology, consider a thin comoving shell of volume $\\Delta V$ within which the halo population is statistically homogeneous. The differential halo mass function is specified by the function $dn/dM$, defined as the comoving number density of halos per unit mass interval. Assume that halos more massive than a threshold mass $M_{\\min}$ are included with unit selection probability and halos below $M_{\\min}$ are excluded. Model the halo mass function in this shell by the form\n$$\n\\frac{dn}{dM} \\;=\\; A\\,\\left(\\frac{M}{M_{\\star}}\\right)^{-1} \\exp\\!\\left(-\\frac{M}{M_{\\star}}\\right)\\,\\frac{1}{M_{\\star}} \\quad ,\n$$\nwhere $A$ is a constant amplitude with units of $\\mathrm{Mpc}^{-3}$, and $M_{\\star}$ is a characteristic mass. You are given the following shell and model parameters:\n$$\n\\Delta V \\;=\\; 1.00 \\times 10^{8}\\,\\mathrm{Mpc}^{3} \\quad , \\quad A \\;=\\; 3.00 \\times 10^{-6}\\,\\mathrm{Mpc}^{-3} \\quad , \\quad M_{\\star} \\;=\\; 1.00 \\times 10^{13}\\,\\mathrm{M}_{\\odot} \\quad , \\quad M_{\\min} \\;=\\; 1.00 \\times 10^{13}\\,\\mathrm{M}_{\\odot} \\; .\n$$\nUsing only fundamental definitions of number counts in a volume and the Poisson point-process assumption for halo sampling, compute:\n1. The expected number of halos in the shell above $M_{\\min}$.\n2. The Poisson sampling variance of that number.\n\nExpress the final answer as two numbers in the order $(\\text{expected number}, \\text{Poisson variance})$ with no units. Round your answer to four significant figures.", "solution": "The problem requires the calculation of two quantities for a population of dark matter halos within a comoving volume shell: the expected number of halos above a minimum mass, and the Poisson sampling variance of this number. The solution will proceed in two parts, addressing each of these required calculations.\n\nFirst, we calculate the expected number of halos, which we denote as $N_{\\mathrm{exp}}$. The fundamental definition of the expected number of objects in a volume $\\Delta V$ is the product of their comoving number density, $n$, and the volume itself.\n$$\nN_{\\mathrm{exp}} = n \\times \\Delta V\n$$\nThe comoving number density, $n$, of halos with mass greater than a threshold mass $M_{\\min}$ is obtained by integrating the differential halo mass function, $\\frac{dn}{dM}$, over all relevant masses. Since halos below $M_{\\min}$ are excluded (i.e., have a selection probability of zero) and halos above $M_{\\min}$ are included with unit probability, the integration range is from $M_{\\min}$ to infinity.\n$$\nn(M > M_{\\min}) = \\int_{M_{\\min}}^{\\infty} \\frac{dn}{dM} \\, dM\n$$\nThe problem provides the functional form for the differential halo mass function:\n$$\n\\frac{dn}{dM} = A \\left(\\frac{M}{M_{\\star}}\\right)^{-1} \\exp\\left(-\\frac{M}{M_{\\star}}\\right) \\frac{1}{M_{\\star}}\n$$\nSubstituting this form into the integral for $n$:\n$$\nn = \\int_{M_{\\min}}^{\\infty} A \\left(\\frac{M}{M_{\\star}}\\right)^{-1} \\exp\\left(-\\frac{M}{M_{\\star}}\\right) \\frac{1}{M_{\\star}} \\, dM\n$$\nWe can simplify the expression inside the integral:\n$$\nn = A \\int_{M_{\\min}}^{\\infty} \\frac{M_{\\star}}{M} \\exp\\left(-\\frac{M}{M_{\\star}}\\right) \\frac{1}{M_{\\star}} \\, dM = A \\int_{M_{\\min}}^{\\infty} \\frac{1}{M} \\exp\\left(-\\frac{M}{M_{\\star}}\\right) \\, dM\n$$\nTo solve this integral, we perform a change of variables. Let $u = \\frac{M}{M_{\\star}}$. Then $M = u M_{\\star}$ and $dM = M_{\\star} du$. The limits of integration also change: when $M = M_{\\min}$, $u = \\frac{M_{\\min}}{M_{\\star}}$; when $M \\to \\infty$, $u \\to \\infty$. The integral becomes:\n$$\nn = A \\int_{M_{\\min}/M_{\\star}}^{\\infty} \\frac{1}{u M_{\\star}} \\exp(-u) \\, (M_{\\star} du) = A \\int_{M_{\\min}/M_{\\star}}^{\\infty} \\frac{\\exp(-u)}{u} \\, du\n$$\nThis integral is the definition of the first exponential integral function, $E_1(x)$, defined as:\n$$\nE_1(x) = \\int_{x}^{\\infty} \\frac{\\exp(-t)}{t} \\, dt\n$$\nThus, the number density is given by:\n$$\nn = A \\, E_1\\left(\\frac{M_{\\min}}{M_{\\star}}\\right)\n$$\nNow, we can find the expected number of halos, $N_{\\mathrm{exp}}$, by multiplying by the volume $\\Delta V$:\n$$\nN_{\\mathrm{exp}} = A \\, E_1\\left(\\frac{M_{\\min}}{M_{\\star}}\\right) \\, \\Delta V\n$$\nWe are given the following parameter values:\n$$\n\\Delta V = 1.00 \\times 10^{8}\\,\\mathrm{Mpc}^{3} \\quad , \\quad A = 3.00 \\times 10^{-6}\\,\\mathrm{Mpc}^{-3} \\quad , \\quad M_{\\star} = 1.00 \\times 10^{13}\\,\\mathrm{M}_{\\odot} \\quad , \\quad M_{\\min} = 1.00 \\times 10^{13}\\,\\mathrm{M}_{\\odot}\n$$\nThe ratio of the minimum mass to the characteristic mass is:\n$$\n\\frac{M_{\\min}}{M_{\\star}} = \\frac{1.00 \\times 10^{13}\\,\\mathrm{M}_{\\odot}}{1.00 \\times 10^{13}\\,\\mathrm{M}_{\\odot}} = 1\n$$\nSubstituting the numerical values into the expression for $N_{\\mathrm{exp}}$:\n$$\nN_{\\mathrm{exp}} = (3.00 \\times 10^{-6}\\,\\mathrm{Mpc}^{-3}) \\times E_1(1) \\times (1.00 \\times 10^{8}\\,\\mathrm{Mpc}^{3})\n$$\n$$\nN_{\\mathrm{exp}} = 3.00 \\times 1.00 \\times 10^{-6} \\times 10^{8} \\times E_1(1) = 300 \\, E_1(1)\n$$\nThe value of the exponential integral function at $1$ is a standard mathematical constant, $E_1(1) \\approx 0.219383934$.\n$$\nN_{\\mathrm{exp}} \\approx 300 \\times 0.219383934 \\approx 65.81518\n$$\nRounding to four significant figures, we get:\n$$\nN_{\\mathrm{exp}} \\approx 65.82\n$$\nSecond, we calculate the Poisson sampling variance of the number of halos. The problem explicitly states that we should assume a Poisson point-process for halo sampling. A fundamental property of a random variable $K$ that follows a Poisson distribution with mean (expected value) $\\lambda$ is that its variance is also equal to $\\lambda$. That is, if $K \\sim \\mathrm{Poisson}(\\lambda)$, then $E[K] = \\lambda$ and $\\mathrm{Var}(K) = \\lambda$.\nIn this problem, the number of halos, $N$, in the volume $\\Delta V$ is assumed to be a Poisson random variable. Its expected value is $E[N] = N_{\\mathrm{exp}}$. Therefore, its variance is:\n$$\n\\mathrm{Var}(N) = E[N] = N_{\\mathrm{exp}}\n$$\nUsing the value for $N_{\\mathrm{exp}}$ we just calculated:\n$$\n\\mathrm{Var}(N) \\approx 65.81518\n$$\nRounding to four significant figures, the variance is:\n$$\n\\mathrm{Var}(N) \\approx 65.82\n$$\nThe requested answer is the pair $(\\text{expected number}, \\text{Poisson variance})$. Both values are approximately $65.82$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n65.82  65.82\n\\end{pmatrix}\n}\n$$", "id": "3477518"}, {"introduction": "Cosmological simulations provide data in discrete time snapshots, yet an observer's past lightcone is a continuous surface through spacetime. This exercise tackles the core practical challenge of lightcone construction: accurately interpolating galaxy properties between these snapshots to determine where and when they cross our line of sight. You will compare different interpolation strategies and quantify their inherent errors, gaining insight into the trade-offs required to build a high-fidelity mock catalog that correctly represents galaxy positions and velocities [@problem_id:3477498].", "problem": "You are to design and evaluate a snapshot interpolation scheme for constructing a past lightcone in a spatially flat Friedmann–Lemaître–Robertson–Walker (FLRW) cosmology and generating mock galaxy catalogs. The goal is to ensure that the interpolated galaxy positions and velocities at the lightcone intersection satisfy a specified tolerance, and to empirically quantify the error budget as a function of snapshot spacing in redshift and the choice of interpolating in comoving versus physical coordinates. Your program must implement the following, starting only from the fundamental definitions below.\n\nConsider a flat Universe with matter density parameter $\\Omega_{\\mathrm{m}}$, dark energy density parameter $\\Omega_{\\Lambda} = 1 - \\Omega_{\\mathrm{m}}$, present-day Hubble parameter $H_0$, and speed of light $c$. The Hubble expansion rate as a function of redshift $z$ is\n$$\nH(z) = H_0 \\sqrt{\\Omega_{\\mathrm{m}}(1+z)^3 + \\Omega_{\\Lambda}}.\n$$\nThe comoving radial distance is\n$$\n\\chi(z) = \\frac{c}{H_0} \\int_{0}^{z} \\frac{dz'}{\\sqrt{\\Omega_{\\mathrm{m}}(1+z')^3 + \\Omega_{\\Lambda}}}.\n$$\nCosmic time and redshift are related by\n$$\n\\frac{dt}{dz} = -\\frac{1}{(1+z) H(z)}.\n$$\nAssume radial one-dimensional motion along the positive $x$-axis. Let $a(z) = \\frac{1}{1+z}$ denote the scale factor. Let the peculiar velocity in physical coordinates be constant for each galaxy, equal to $u_{\\mathrm{p}}$ (in $\\mathrm{km/s}$). Let the comoving coordinate be $x(z)$ (in $\\mathrm{Mpc}$). From $u = a \\, dx/dt$, a constant $u_{\\mathrm{p}}$ implies\n$$\n\\frac{dx}{dt} = \\frac{u_{\\mathrm{p}}}{a(z)},\n$$\nand therefore, using $\\frac{dz}{dt} = -(1+z) H(z)$, one obtains\n$$\n\\frac{dx}{dz} = - \\frac{u_{\\mathrm{p}}}{H(z)} \\cdot \\left(\\frac{\\mathrm{Mpc/Gyr}}{\\mathrm{km/s}}\\right),\n$$\nwhen $H(z)$ is expressed in $\\mathrm{Gyr}^{-1}$ and $u_{\\mathrm{p}}$ is converted to $\\mathrm{Mpc/Gyr}$ consistently. Hence, for a galaxy with initial condition $x(z_{\\max}) = x_0$ at $z_{\\max}$ and constant $u_{\\mathrm{p}}$, the exact comoving trajectory is\n$$\nx(z) = x_0 - u_{\\mathrm{p}}^{(\\mathrm{Mpc/Gyr})} \\int_{z_{\\max}}^{z} \\frac{dz'}{H(z')},\n$$\nwhere $u_{\\mathrm{p}}^{(\\mathrm{Mpc/Gyr})}$ is $u_{\\mathrm{p}}$ converted to $\\mathrm{Mpc/Gyr}$.\n\nDefine the past lightcone of an observer at the origin by the condition that the event $(x,z)$ lies on the lightcone if $x(z) = \\chi(z)$. The exact crossing redshift $z_\\star$ for a given galaxy is the unique root of\n$$\nf(z) = x(z) - \\chi(z) = 0,\n$$\nfor $z \\in [0, z_{\\max}]$.\n\nThe numerical interpolation problem: You have simulation snapshots at discrete redshifts $z_k = z_{\\max} - k \\, \\Delta z$ for integers $k \\ge 0$ until $z$ reaches $0$. For a target galaxy, denote its exact values at snapshots by $x_k = x(z_k)$, $t_k = t(z_k)$, $a_k = a(z_k)$, $r_k = a_k x_k$, $u_k = u_{\\mathrm{p}}$ (constant), and $v_{c,k} = dx/dt \\big|_{z_k} = u_{\\mathrm{p}}/a_k$ in $\\mathrm{Mpc/Gyr}$. Consider two linear-in-time interpolation schemes on the interval $[z_i, z_{i+1}]$ that brackets $z_\\star$:\n\nScheme C (comoving-space interpolation): interpolate $x(t)$ and $v_c(t)=dx/dt$ linearly in $t$ between $(t_i, x_i, v_{c,i})$ and $(t_{i+1}, x_{i+1}, v_{c,i+1})$, then solve for the estimated crossing redshift $\\hat{z}$ from\n$$\nx_{\\mathrm{lin}}(t(\\hat{z})) - \\chi(\\hat{z}) = 0,\n$$\nand estimate the physical peculiar velocity at the crossing by\n$$\n\\hat{u} = a(\\hat{z}) \\, v_{c,\\mathrm{lin}}(t(\\hat{z})),\n$$\nconverted to $\\mathrm{km/s}$.\n\nScheme P (physical-space interpolation): interpolate $r(t)=a x$ and $u(t)$ linearly in $t$ between $(t_i, r_i, u_i)$ and $(t_{i+1}, r_{i+1}, u_{i+1})$, then solve for the estimated crossing redshift $\\hat{z}$ from\n$$\n\\frac{r_{\\mathrm{lin}}(t(\\hat{z}))}{a(\\hat{z})} - \\chi(\\hat{z}) = 0,\n$$\nand estimate the physical peculiar velocity at the crossing by\n$$\n\\hat{u} = u_{\\mathrm{lin}}(t(\\hat{z})).\n$$\n\nYou must compute, for each galaxy and each scheme, the exact crossing redshift $z_\\star$ and the estimated crossing redshift $\\hat{z}$. Quantify the lightcone position error as the absolute comoving radial error\n$$\n\\Delta \\chi = \\left| \\chi(\\hat{z}) - \\chi(z_\\star) \\right| \\quad \\text{in} \\ \\mathrm{Mpc},\n$$\nand the velocity error as\n$$\n\\Delta u = \\left| \\hat{u} - u_{\\mathrm{p}} \\right| \\quad \\text{in} \\ \\mathrm{km/s}.\n$$\nAggregate the errors across all galaxies by taking the maximum over the galaxy set for each scheme and snapshot spacing.\n\nScientific and numerical setup to be used by your program:\n- Cosmology: $\\Omega_{\\mathrm{m}} = 0.3$, $\\Omega_{\\Lambda} = 0.7$, $H_0 = 70 \\ \\mathrm{km \\, s^{-1} \\, Mpc^{-1}}$, $c = 299792.458 \\ \\mathrm{km/s}$.\n- Redshift range: $z_{\\max} = 2$, $z_{\\min} = 0$.\n- Galaxy set at $z_{\\max}$: four galaxies with $(x_0, u_{\\mathrm{p}})$ equal to $(50, 200)$, $(100, 400)$, $(150, 800)$, and $(200, 1200)$, where $x_0$ is in $\\mathrm{Mpc}$ and $u_{\\mathrm{p}}$ is in $\\mathrm{km/s}$, all moving radially outward.\n- Interpolation schemes: Scheme C (comoving) and Scheme P (physical), as defined above.\n- Snapshot spacings: $\\Delta z \\in \\{0.5, 0.2, 0.1, 0.05\\}$.\n- Tolerances to assess but not directly printed: position tolerance $\\tau_{\\chi} = 0.1 \\ \\mathrm{Mpc}$ and velocity tolerance $\\tau_{u} = 10 \\ \\mathrm{km/s}$; your program should compute errors but the final output is not the boolean pass/fail, it is the numerical error magnitudes.\n\nTest suite and required outputs:\n- Define eight test cases, ordered as\n  $$\n  (\\Delta z, \\text{scheme}) \\in \\{(0.5, \\text{C}), (0.5, \\text{P}), (0.2, \\text{C}), (0.2, \\text{P}), (0.1, \\text{C}), (0.1, \\text{P}), (0.05, \\text{C}), (0.05, \\text{P})\\}.\n  $$\n- For each test case, aggregate across the four galaxies and return two floats: the maximum $\\Delta \\chi$ in $\\mathrm{Mpc}$ and the maximum $\\Delta u$ in $\\mathrm{km/s}$, each rounded to six decimals.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the following order:\n  $$\n  [\\max \\Delta \\chi_{1}, \\max \\Delta u_{1}, \\max \\Delta \\chi_{2}, \\max \\Delta u_{2}, \\ldots, \\max \\Delta \\chi_{8}, \\max \\Delta u_{8}],\n  $$\n  where the index runs over the eight test cases in the precise order specified above. Distances must be in $\\mathrm{Mpc}$ and velocities in $\\mathrm{km/s}$, both rounded to six decimals.\n\nYour implementation must rely only on the definitions and integrals given, compute $H(z)$ in $\\mathrm{Gyr}^{-1}$ when needed for time integrals, convert units consistently using exact constants internally, and solve for the lightcone crossings by robust root-finding on the bracketing snapshot interval for each scheme. No external data or input is allowed; all values must be defined inside your program.", "solution": "The user has provided a valid, well-posed problem in numerical cosmology. The task is to implement and evaluate two snapshot-based interpolation schemes for lightcone construction. This solution will present a step-by-step derivation and algorithmic design, starting from the fundamental principles laid out in the problem statement.\n\n### 1. Cosmological Framework and Fundamental Quantities\n\nThe problem is set in a spatially flat Friedmann–Lemaître–Robertson–Walker (FLRW) universe, governed by the standard cosmological parameters: matter density $\\Omega_{\\mathrm{m}} = 0.3$, dark energy density $\\Omega_{\\Lambda} = 0.7$, and the present-day Hubble parameter $H_0 = 70 \\ \\mathrm{km \\, s^{-1} \\, Mpc^{-1}}$. The speed of light is $c = 299792.458 \\ \\mathrm{km/s}$.\n\nThe core of the problem involves calculations with redshift-dependent quantities. For consistency, especially in numerical integration involving time, we convert all relevant quantities into a system of units based on Megaparsecs (Mpc) and Gigayears (Gyr).\n\nThe conversion factor from $\\mathrm{km/s}$ to $\\mathrm{Mpc/Gyr}$ is derived as:\n$$\n1 \\frac{\\mathrm{km}}{\\mathrm{s}} = \\frac{1 \\ \\mathrm{km}}{1 \\ \\mathrm{s}} \\times \\frac{1 \\ \\mathrm{Mpc}}{3.08567758 \\times 10^{19} \\ \\mathrm{km}} \\times \\frac{3.15576 \\times 10^{16} \\ \\mathrm{s}}{1 \\ \\mathrm{Gyr}} \\approx 1.02269 \\times 10^{-3} \\frac{\\mathrm{Mpc}}{\\mathrm{Gyr}}\n$$\nUsing this, we can express $H_0$ in $\\mathrm{Gyr}^{-1}$:\n$$\nH_0 = 70 \\ \\mathrm{km \\, s^{-1} \\, Mpc^{-1}} \\times (1.02269 \\times 10^{-3} \\ \\mathrm{Mpc \\, Gyr^{-1}} / \\mathrm{km \\, s^{-1}}) \\approx 0.071588 \\ \\mathrm{Gyr}^{-1}\n$$\nThe Hubble parameter at redshift $z$ is then:\n$$\nH(z) = H_0 \\sqrt{\\Omega_{\\mathrm{m}}(1+z)^3 + \\Omega_{\\Lambda}}\n$$\nwhere $H(z)$ is computed in $\\mathrm{Gyr}^{-1}$.\n\nThe comoving radial distance $\\chi(z)$ from an observer at $z=0$ to an object at redshift $z$ is given by the integral:\n$$\n\\chi(z) = \\frac{c}{H_0} \\int_{0}^{z} \\frac{dz'}{\\sqrt{\\Omega_{\\mathrm{m}}(1+z')^3 + \\Omega_{\\Lambda}}}\n$$\nThis integral is computed numerically. The pre-factor $c/H_0$ gives the distance in $\\mathrm{Mpc}$.\n\nThe relationship between cosmic time $t$ and redshift $z$ is differential:\n$$\n\\frac{dt}{dz} = -\\frac{1}{(1+z) H(z)}\n$$\nTo find the cosmic time $t(z)$ at a given redshift, we integrate this relation. For convenience, we define a reference time $t(z_{\\max})=0$, yielding:\n$$\nt(z) = \\int_{z_{\\max}}^{z} \\frac{-dz'}{(1+z') H(z')} = \\int_{z}^{z_{\\max}} \\frac{dz'}{(1+z') H(z')}\n$$\nThis integral is also computed numerically.\n\n### 2. Exact Galaxy Trajectory and Lightcone Crossing\n\nA galaxy is assumed to have a constant physical peculiar velocity $u_{\\mathrm{p}}$. Its comoving coordinate $x(z)$ evolves according to:\n$$\nx(z) = x_0 - u_{\\mathrm{p}}^{(\\mathrm{Mpc/Gyr})} \\int_{z_{\\max}}^{z} \\frac{dz'}{H(z')} = x_0 + u_{\\mathrm{p}}^{(\\mathrm{Mpc/Gyr})} \\int_{z}^{z_{\\max}} \\frac{dz'}{H(z')}\n$$\nwhere $x_0$ is the comoving position at $z_{\\max}=2$ and $u_{\\mathrm{p}}^{(\\mathrm{Mpc/Gyr})}$ is the peculiar velocity converted to $\\mathrm{Mpc/Gyr}$.\n\nThe past lightcone is defined by the set of spacetime events $(x, z)$ where the comoving distance to the observer equals the radial comoving coordinate of the event: $x = \\chi(z)$. The exact lightcone crossing redshift, $z_\\star$, for a given galaxy is the unique root of the equation:\n$$\nf(z) = x(z) - \\chi(z) = 0\n$$\nThe function $f(z)$ is strictly monotonic, as it is the difference between a decreasing function of $z$ ($x(z)$) and an increasing function of $z$ ($\\chi(z)$). At $z=0$, $x(0)  0$ and $\\chi(0)=0$, so $f(0)  0$. At $z=z_{\\max}$, $x(z_{\\max})$ is a small initial position while $\\chi(z_{\\max})$ is large, so $f(z_{\\max})  0$. This guarantees a unique root $z_\\star \\in (0, z_{\\max})$. We find this root using a numerical root-finding algorithm like the Brent-Dekker method (`brentq`) on an interval bracketing the root.\n\n### 3. Interpolation Schemes and Error Estimation\n\nThe core of the problem is to approximate the lightcone crossing using data from discrete simulation snapshots. Snapshots are available at redshifts $z_k = z_{\\max} - k \\Delta z$. For a galaxy, we first identify the snapshot interval $[z_{i+1}, z_i]$ that brackets the true crossing $z_\\star$ by finding where the sign of $f(z_k) = x(z_k) - \\chi(z_k)$ changes.\n\nWithin this bracketing interval, we apply one of two interpolation schemes, both linear in cosmic time $t$. For a quantity $Q(t)$, the linear interpolant is:\n$$\nQ_{\\mathrm{lin}}(t) = Q_i + (Q_{i+1} - Q_i) \\frac{t - t_i}{t_{i+1} - t_i}\n$$\nwhere $(t_i, Q_i)$ and $(t_{i+1}, Q_{i+1})$ are the values at the bracketing snapshots.\n\n**Scheme C (Comoving-space interpolation):**\n1.  **Position:** The comoving position $x(t)$ is interpolated linearly. The estimated crossing redshift $\\hat{z}$ is found by solving:\n    $$\n    x_{\\mathrm{lin}}(t(\\hat{z})) - \\chi(\\hat{z}) = 0\n    $$\n2.  **Velocity:** The comoving velocity $v_c(t) = dx/dt = u_{\\mathrm{p}}/a(t)$ is interpolated linearly. The estimated physical peculiar velocity is:\n    $$\n    \\hat{u} = a(\\hat{z}) \\, v_{c,\\mathrm{lin}}(t(\\hat{z}))\n    $$\n    Since $v_c$ is not truly linear in $t$, this scheme introduces a velocity error.\n\n**Scheme P (Physical-space interpolation):**\n1.  **Position:** The physical position $r(t) = a(t)x(t)$ is interpolated linearly. The estimated crossing redshift $\\hat{z}$ is found by solving:\n    $$\n    \\frac{r_{\\mathrm{lin}}(t(\\hat{z}))}{a(\\hat{z})} - \\chi(\\hat{z}) = 0\n    $$\n2.  **Velocity:** The physical velocity $u(t) = u_{\\mathrm{p}}$ is interpolated linearly. Since $u_{\\mathrm{p}}$ is constant by assumption, $u_i = u_{i+1} = u_{\\mathrm{p}}$. The linear interpolant is therefore constant:\n    $$\n    \\hat{u} = u_{\\mathrm{lin}}(t(\\hat{z})) = u_{\\mathrm{p}}\n    $$\n    Consequently, for this scheme, the velocity error $\\Delta u$ is analytically zero.\n\nIn both schemes, solving for $\\hat{z}$ requires a numerical root-finder, as the equations involve the non-linear functions $t(z)$, $a(z)$, and $\\chi(z)$. The bracketing interval $[z_{i+1}, z_i]$ remains valid for finding $\\hat{z}$.\n\nFinally, the errors are quantified as:\n-   Position error: $\\Delta \\chi = | \\chi(\\hat{z}) - \\chi(z_\\star) |$ in Mpc.\n-   Velocity error: $\\Delta u = | \\hat{u} - u_{\\mathrm{p}} |$ in km/s.\n\nFor each test case (a pair of $\\Delta z$ and scheme), the maximum errors across the four specified galaxies are computed and reported.\n\n### 4. Algorithmic Implementation\n\nThe implementation encapsulates the cosmological calculations within a class to manage parameters and cache results of computationally expensive integrations, improving performance. The main logic iterates through the specified test cases. For each case, it iterates through the galaxies, performs the following steps, and aggregates the maximum errors:\n1.  Define cosmological model and galaxy properties.\n2.  Generate snapshot redshifts for the given $\\Delta z$.\n3.  For each galaxy, determine the exact crossing $z_\\star$ and the bracketing snapshot interval $[z_{i+1}, z_i]$.\n4.  Gather the required data ($t, x, a, r, v_c, u$) at snapshots $z_i$ and $z_{i+1}$.\n5.  Apply the specified interpolation scheme (C or P) to define the new equation for the crossing redshift.\n6.  Solve for the estimated crossing $\\hat{z}$ using a root-finder.\n7.  Calculate the estimated velocity $\\hat{u}$ based on the scheme.\n8.  Compute errors $\\Delta \\chi$ and $\\Delta u$ and update the running maxima for the current test case.\nThe final results are formatted into a single string as required.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import quad\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Main function to solve the lightcone interpolation problem.\n    \"\"\"\n\n    class Cosmology:\n        \"\"\"\n        Encapsulates cosmological parameters and functions.\n        Uses caching for expensive integral calculations.\n        \"\"\"\n        def __init__(self, omega_m, omega_l, h0_kms_mpc, c_kms, z_max):\n            self.OMEGA_M = omega_m\n            self.OMEGA_L = omega_l\n            self.H0_KMS_MPC = h0_kms_mpc\n            self.C_KMS = c_kms\n            self.Z_MAX = z_max\n\n            # Unit Conversion Constants\n            # 1 Gyr in seconds based on 365.25 days/year\n            SEC_PER_GYR = 1e9 * 365.25 * 24 * 3600\n            # 1 Mpc in km\n            KM_PER_MPC = 3.08567758149e19\n            \n            # Conversion factor from km/s to Mpc/Gyr\n            self.MPC_GYR_PER_KM_S = SEC_PER_GYR / KM_PER_MPC\n            \n            # H0 in Gyr^-1\n            self.H0_PER_GYR = self.H0_KMS_MPC * self.MPC_GYR_PER_KM_S\n            \n            # Speed of light in Mpc/Gyr\n            self.C_MPC_GYR = self.C_KMS * self.MPC_GYR_PER_KM_S\n            \n            # Comoving distance prefactor c/H0 in Mpc\n            self.C_OVER_H0_MPC = self.C_KMS / self.H0_KMS_MPC\n\n            self._cache = {}\n\n        def E_z(self, z):\n            return np.sqrt(self.OMEGA_M * (1 + z)**3 + self.OMEGA_L)\n\n        def H_z_gyr(self, z):\n            return self.H0_PER_GYR * self.E_z(z)\n\n        def chi_z(self, z):\n            if ('chi', z) in self._cache:\n                return self._cache[('chi', z)]\n            if z == 0:\n                return 0.0\n            \n            integrand = lambda zp: 1.0 / self.E_z(zp)\n            result, _ = quad(integrand, 0, z)\n            val = self.C_OVER_H0_MPC * result\n            self._cache[('chi', z)] = val\n            return val\n\n        def t_z(self, z):\n            if ('t', z) in self._cache:\n                return self._cache[('t', z)]\n            if z == self.Z_MAX:\n                return 0.0\n            \n            integrand = lambda zp: 1.0 / ((1 + zp) * self.H_z_gyr(zp))\n            result, _ = quad(integrand, z, self.Z_MAX)\n            self._cache[('t', z)] = result\n            return result\n\n        def integral_one_over_H(self, z_lower, z_upper):\n            key = ('int_1/H', z_lower, z_upper)\n            if key in self._cache:\n                return self._cache[key]\n            \n            integrand = lambda zp: 1.0 / self.H_z_gyr(zp)\n            result, _ = quad(integrand, z_lower, z_upper)\n            self._cache[key] = result\n            return result\n    \n    class Galaxy:\n        def __init__(self, cosmo, x0, u_p_kms):\n            self.cosmo = cosmo\n            self.x0 = x0  # Mpc at z_max\n            self.u_p_kms = u_p_kms  # km/s\n            self.u_p_mpcgyr = u_p_kms * cosmo.MPC_GYR_PER_KM_S\n            self._cache_x = {}\n\n        def x_z(self, z):\n            if z in self._cache_x:\n                return self._cache_x[z]\n            if z == self.cosmo.Z_MAX:\n                return self.x0\n            \n            integral_val = self.cosmo.integral_one_over_H(z, self.cosmo.Z_MAX)\n            val = self.x0 + self.u_p_mpcgyr * integral_val\n            self._cache_x[z] = val\n            return val\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0.5, 'C'), (0.5, 'P'),\n        (0.2, 'C'), (0.2, 'P'),\n        (0.1, 'C'), (0.1, 'P'),\n        (0.05, 'C'), (0.05, 'P'),\n    ]\n\n    # Initialize Cosmology\n    cosmo = Cosmology(omega_m=0.3, omega_l=0.7, h0_kms_mpc=70.0, c_kms=299792.458, z_max=2.0)\n\n    # Initialize Galaxies\n    galaxy_params = [(50, 200), (100, 400), (150, 800), (200, 1200)]\n    galaxies = [Galaxy(cosmo, x0, u_p) for x0, u_p in galaxy_params]\n    \n    final_results = []\n\n    for delta_z, scheme in test_cases:\n        max_delta_chi = 0.0\n        max_delta_u = 0.0\n\n        num_snaps = int(np.ceil(cosmo.Z_MAX / delta_z)) + 1\n        snapshot_redshifts = np.linspace(cosmo.Z_MAX, 0, num_snaps)\n\n        for gal in galaxies:\n            f_exact = lambda z: gal.x_z(z) - cosmo.chi_z(z)\n            \n            # Find bracketing interval\n            f_vals = np.array([f_exact(z) for z in snapshot_redshifts])\n            \n            # Sign change indicates interval containing the root\n            signs = np.sign(f_vals)\n            sign_changes = np.where(np.diff(signs))[0]\n            \n            if len(sign_changes) == 0:\n                # Should not happen for the given parameters\n                continue\n            \n            idx_upper = sign_changes[0]\n            z_upper = snapshot_redshifts[idx_upper]     # z_i\n            z_lower = snapshot_redshifts[idx_upper + 1] # z_{i+1}\n\n            # 1. Find exact crossing z_star\n            z_star = brentq(f_exact, z_lower, z_upper)\n            chi_star = cosmo.chi_z(z_star)\n\n            # 2. Prepare snapshot data for interpolation\n            t_upper = cosmo.t_z(z_upper)\n            t_lower = cosmo.t_z(z_lower)\n            delta_t_snap = t_lower - t_upper\n\n            # 3. Interpolation and solving for z_hat\n            z_hat = 0.0\n            u_hat_kms = 0.0\n\n            if scheme == 'C':\n                x_upper = gal.x_z(z_upper)\n                x_lower = gal.x_z(z_lower)\n                \n                def g_c(z):\n                    tz = cosmo.t_z(z)\n                    x_lin_t = x_upper + (x_lower - x_upper) * (tz - t_upper) / delta_t_snap\n                    return x_lin_t - cosmo.chi_z(z)\n                \n                z_hat = brentq(g_c, z_lower, z_upper)\n                \n                a_upper, a_lower, a_hat = 1/(1+z_upper), 1/(1+z_lower), 1/(1+z_hat)\n                v_c_upper = gal.u_p_mpcgyr / a_upper\n                v_c_lower = gal.u_p_mpcgyr / a_lower\n                t_hat = cosmo.t_z(z_hat)\n                \n                v_c_lin_hat = v_c_upper + (v_c_lower - v_c_upper) * (t_hat - t_upper) / delta_t_snap\n                u_hat_mpcgyr = a_hat * v_c_lin_hat\n                u_hat_kms = u_hat_mpcgyr / cosmo.MPC_GYR_PER_KM_S\n\n            elif scheme == 'P':\n                a_upper, a_lower = 1/(1+z_upper), 1/(1+z_lower)\n                x_upper, x_lower = gal.x_z(z_upper), gal.x_z(z_lower)\n                r_upper, r_lower = a_upper * x_upper, a_lower * x_lower\n\n                def g_p(z):\n                    tz = cosmo.t_z(z)\n                    az = 1.0 / (1.0 + z)\n                    r_lin_t = r_upper + (r_lower - r_upper) * (tz - t_upper) / delta_t_snap\n                    return (r_lin_t / az) - cosmo.chi_z(z)\n                \n                z_hat = brentq(g_p, z_lower, z_upper)\n                u_hat_kms = gal.u_p_kms\n\n            # 4. Calculate errors\n            chi_hat = cosmo.chi_z(z_hat)\n            delta_chi = abs(chi_hat - chi_star)\n            delta_u = abs(u_hat_kms - gal.u_p_kms)\n\n            # 5. Update max errors\n            max_delta_chi = max(max_delta_chi, delta_chi)\n            max_delta_u = max(max_delta_u, delta_u)\n\n        final_results.append(f\"{max_delta_chi:.6f}\")\n        final_results.append(f\"{max_delta_u:.6f}\")\n        \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(final_results)}]\")\n\nsolve()\n```", "id": "3477498"}, {"introduction": "Mock catalogs are indispensable tools for understanding and controlling systematic errors in cosmological analyses. This practice demonstrates a critical application by exploring how assuming an incorrect background cosmology can systematically bias our measurements of cosmic distances, a phenomenon known as the Alcock-Paczynski effect. By calculating this bias, you will see firsthand why mock catalogs are essential for validating analysis pipelines and interpreting results from real galaxy surveys [@problem_id:3477460].", "problem": "Consider a spatially homogeneous and isotropic universe described by the Friedmann-Lemaître-Robertson-Walker (FLRW) metric, with matter density parameter $\\Omega_m$, cosmological constant density parameter $\\Omega_\\Lambda$, and reduced Hubble constant $h$ such that $H_0 = 100\\,h$ in units of $\\mathrm{km\\,s^{-1}\\,Mpc^{-1}}$. Let $\\Omega_k = 1 - \\Omega_m - \\Omega_\\Lambda$ denote the curvature density parameter. In this setting, the expansion rate as a function of redshift $z$ is defined by the dimensionless function $E(z)$ satisfying the Friedmann equation, and the comoving radial distance $\\chi(z)$ is defined by a line-of-sight integral that depends on $E(z)$. The transverse comoving distance $D_M(z)$ is related to $\\chi(z)$ through the spatial curvature, and the line-of-sight comoving distance per unit redshift is given by $c/H(z)$, where $c$ is the speed of light.\n\nIn the construction of lightcone mock catalogs, observed angles and redshifts are mapped to three-dimensional comoving coordinates using a chosen background cosmology $(\\Omega_m^{\\mathrm{fid}}, \\Omega_\\Lambda^{\\mathrm{fid}}, h^{\\mathrm{fid}})$. If the true background cosmology is $(\\Omega_m^{\\mathrm{true}}, \\Omega_\\Lambda^{\\mathrm{true}}, h^{\\mathrm{true}})$, then the inferred Baryon Acoustic Oscillation (BAO) distances measured from the mocks will be systematically biased relative to their true values because the mapping depends on the cosmology used to construct $\\chi(z)$ and $H(z)$.\n\nStarting from the FLRW metric and the Friedmann equation, and without introducing any shortcut formulas, implement a program that:\n\n- Computes the dimensionless expansion rate $E(z)$ from the Friedmann equation for arbitrary $(\\Omega_m, \\Omega_\\Lambda, h)$, including nonzero spatial curvature $\\Omega_k$, and then computes $H(z) = H_0 E(z)$ with $H_0 = 100\\,h$ in $\\mathrm{km\\,s^{-1}\\,Mpc^{-1}}$.\n- Computes the comoving radial distance $\\chi(z) = \\dfrac{c}{H_0} \\int_0^z \\dfrac{dz'}{E(z')}$ in $\\mathrm{Mpc}$, where the speed of light $c$ must be taken as $c = 299792.458$ in $\\mathrm{km\\,s^{-1}}$.\n- Computes the transverse comoving distance $D_M(z)$ from $\\chi(z)$ with full curvature dependence. For $\\Omega_k = 0$, $D_M(z)$ equals $\\chi(z)$. For $\\Omega_k \\neq 0$, use the appropriate curved-space relation based on the standard curvature-dependent geodesic distance mapping, expressed in terms of the curvature-normalized trigonometric or hyperbolic functions.\n- Defines the inferred transverse BAO distance bias at redshift $z$ as the fractional difference between the transverse comoving distance computed with the fiducial cosmology and that computed with the true cosmology, namely $\\Delta_\\perp(z) = \\dfrac{D_M^{\\mathrm{fid}}(z)}{D_M^{\\mathrm{true}}(z)} - 1$.\n- Defines the inferred radial BAO distance bias at redshift $z$ as the fractional difference between the line-of-sight comoving distance per unit redshift computed with the fiducial cosmology and that computed with the true cosmology, namely $\\Delta_\\parallel(z) = \\dfrac{\\left(c/H^{\\mathrm{fid}}(z)\\right)}{\\left(c/H^{\\mathrm{true}}(z)\\right)} - 1$.\n\nAll intermediate distances must be computed in $\\mathrm{Mpc}$. The final outputs must be dimensionless decimal numbers. For numerical integration, you must use a method whose accuracy is controlled by absolute and relative tolerances appropriate for advanced graduate-level numerical cosmology work; ensure numerical robustness across the provided test suite.\n\nTest Suite:\n- Case $1$ (happy path, small deviations in all parameters): $\\Omega_m^{\\mathrm{true}} = 0.315$, $\\Omega_\\Lambda^{\\mathrm{true}} = 0.685$, $h^{\\mathrm{true}} = 0.674$; $\\Omega_m^{\\mathrm{fid}} = 0.310$, $\\Omega_\\Lambda^{\\mathrm{fid}} = 0.690$, $h^{\\mathrm{fid}} = 0.680$; $z = 0.8$.\n- Case $2$ (open geometry in fiducial cosmology): $\\Omega_m^{\\mathrm{true}} = 0.315$, $\\Omega_\\Lambda^{\\mathrm{true}} = 0.685$, $h^{\\mathrm{true}} = 0.674$; $\\Omega_m^{\\mathrm{fid}} = 0.280$, $\\Omega_\\Lambda^{\\mathrm{fid}} = 0.680$, $h^{\\mathrm{fid}} = 0.670$; $z = 1.2$.\n- Case $3$ (closed geometry in fiducial cosmology): $\\Omega_m^{\\mathrm{true}} = 0.315$, $\\Omega_\\Lambda^{\\mathrm{true}} = 0.685$, $h^{\\mathrm{true}} = 0.674$; $\\Omega_m^{\\mathrm{fid}} = 0.350$, $\\Omega_\\Lambda^{\\mathrm{fid}} = 0.680$, $h^{\\mathrm{fid}} = 0.700$; $z = 0.3$.\n- Case $4$ (zero curvature, pure $h$ offset): $\\Omega_m^{\\mathrm{true}} = 0.315$, $\\Omega_\\Lambda^{\\mathrm{true}} = 0.685$, $h^{\\mathrm{true}} = 0.674$; $\\Omega_m^{\\mathrm{fid}} = 0.315$, $\\Omega_\\Lambda^{\\mathrm{fid}} = 0.685$, $h^{\\mathrm{fid}} = 0.700$; $z = 0.8$.\n- Case $5$ (boundary, no bias expected): $\\Omega_m^{\\mathrm{true}} = 0.315$, $\\Omega_\\Lambda^{\\mathrm{true}} = 0.685$, $h^{\\mathrm{true}} = 0.674$; $\\Omega_m^{\\mathrm{fid}} = 0.315$, $\\Omega_\\Lambda^{\\mathrm{fid}} = 0.685$, $h^{\\mathrm{fid}} = 0.674$; $z = 0.8$.\n\nYour program must produce the biases $\\Delta_\\perp(z)$ and $\\Delta_\\parallel(z)$ for each case, rounded to six decimal places, and a single line of output containing the values in the order of the test suite as a comma-separated list enclosed in square brackets. The required final output format is:\n$[\\Delta_\\perp^{(1)}, \\Delta_\\parallel^{(1)}, \\Delta_\\perp^{(2)}, \\Delta_\\parallel^{(2)}, \\Delta_\\perp^{(3)}, \\Delta_\\parallel^{(3)}, \\Delta_\\perp^{(4)}, \\Delta_\\parallel^{(4)}, \\Delta_\\perp^{(5)}, \\Delta_\\parallel^{(5)}]$.\nAll outputs must be dimensionless decimals rounded to six decimal places, without any percentage sign.", "solution": "This problem requires calculating the systematic biases on cosmological distance measurements that arise when assuming an incorrect background cosmology—a phenomenon known as the Alcock-Paczynski effect. The solution involves computing key cosmological quantities for both a \"true\" and a \"fiducial\" (assumed) cosmology and then comparing them.\n\n### 1. Fundamental Cosmological Quantities\n\nThe calculation for each cosmology is based on the Friedmann equation, which describes the expansion of the universe.\nGiven the parameters $(\\Omega_m, \\Omega_\\Lambda, h)$, we first compute the curvature density parameter $\\Omega_k = 1 - \\Omega_m - \\Omega_\\Lambda$ and the Hubble constant $H_0 = 100\\,h \\, \\mathrm{km\\,s^{-1}\\,Mpc^{-1}}$.\n\n**Hubble Parameter at Redshift z, $H(z)$**:\nThe expansion rate at any redshift $z$ is given by $H(z) = H_0 E(z)$, where $E(z)$ is the dimensionless expansion rate:\n$$\nE(z) = \\sqrt{\\Omega_m (1+z)^3 + \\Omega_k (1+z)^2 + \\Omega_\\Lambda}\n$$\n\n**Transverse Comoving Distance, $D_M(z)$**:\nThis distance is a function of the comoving radial distance, $\\chi(z)$, and the spatial curvature $\\Omega_k$. The comoving radial distance is found by integrating along the line of sight:\n$$\n\\chi(z) = \\frac{c}{H_0} \\int_0^z \\frac{dz'}{E(z')}\n$$\nThis integral must be computed numerically. The transverse comoving distance $D_M(z)$ is then:\n$$\nD_M(z) = \\begin{cases}\n\\frac{c}{H_0\\sqrt{\\Omega_k}} \\sinh\\left(\\frac{H_0 \\sqrt{\\Omega_k}}{c} \\chi(z)\\right)  \\text{if } \\Omega_k  0 \\text{ (open)} \\\\\n\\chi(z)  \\text{if } \\Omega_k = 0 \\text{ (flat)} \\\\\n\\frac{c}{H_0\\sqrt{-\\Omega_k}} \\sin\\left(\\frac{H_0 \\sqrt{-\\Omega_k}}{c} \\chi(z)\\right)  \\text{if } \\Omega_k  0 \\text{ (closed)}\n\\end{cases}\n$$\n\n### 2. Calculating the Biases\n\nWith these fundamental quantities defined, we can compute the biases for each test case. For a given redshift $z$, we calculate $H^{\\mathrm{true}}(z)$, $D_M^{\\mathrm{true}}(z)$, $H^{\\mathrm{fid}}(z)$, and $D_M^{\\mathrm{fid}}(z)$ by applying the above equations to the true and fiducial parameter sets.\n\n**Transverse Bias, $\\Delta_\\perp(z)$**:\nThis bias affects distances measured perpendicular to the line of sight (e.g., from an object's angular size). It is the fractional difference in the transverse comoving distances:\n$$\n\\Delta_\\perp(z) = \\frac{D_M^{\\mathrm{fid}}(z)}{D_M^{\\mathrm{true}}(z)} - 1\n$$\n\n**Radial Bias, $\\Delta_\\parallel(z)$**:\nThis bias affects distances measured along the line of sight (e.g., from redshift differences). It is the fractional difference in the line-of-sight comoving distance per unit redshift, $c/H(z)$. This simplifies to a ratio of the Hubble parameters:\n$$\n\\Delta_\\parallel(z) = \\frac{c/H^{\\mathrm{fid}}(z)}{c/H^{\\mathrm{true}}(z)} - 1 = \\frac{H^{\\mathrm{true}}(z)}{H^{\\mathrm{fid}}(z)} - 1\n$$\n\n### 3. Algorithmic Procedure\n\nThe overall algorithm for each test case is:\n1.  Define the `true` and `fiducial` cosmological parameters and the target redshift `z`.\n2.  For the `true` cosmology, compute $D_M^{\\mathrm{true}}(z)$ and $H^{\\mathrm{true}}(z)$ using numerical integration for the comoving distance.\n3.  For the `fiducial` cosmology, compute $D_M^{\\mathrm{fid}}(z)$ and $H^{\\mathrm{fid}}(z)$ using the same method.\n4.  Substitute these four values into the equations for $\\Delta_\\perp(z)$ and $\\Delta_\\parallel(z)$ to obtain the two biases.\n5.  Collect and format the results as requested.\n\nThis procedure is repeated for all five test cases to generate the final output array.", "answer": "```python\nimport numpy as np\nfrom scipy.integrate import quad\n\ndef solve():\n    \"\"\"\n    Solves the cosmological distance bias problem for the given test suite.\n    \"\"\"\n    \n    # Speed of light in km/s as specified in the problem\n    C_KM_S = 299792.458\n\n    test_cases = [\n        # Case 1 (happy path, small deviations)\n        {'true': {'omega_m': 0.315, 'omega_lambda': 0.685, 'h': 0.674},\n         'fid': {'omega_m': 0.310, 'omega_lambda': 0.690, 'h': 0.680},\n         'z': 0.8},\n        # Case 2 (open fiducial cosmology)\n        {'true': {'omega_m': 0.315, 'omega_lambda': 0.685, 'h': 0.674},\n         'fid': {'omega_m': 0.280, 'omega_lambda': 0.680, 'h': 0.670},\n         'z': 1.2},\n        # Case 3 (closed fiducial cosmology)\n        {'true': {'omega_m': 0.315, 'omega_lambda': 0.685, 'h': 0.674},\n         'fid': {'omega_m': 0.350, 'omega_lambda': 0.680, 'h': 0.700},\n         'z': 0.3},\n        # Case 4 (pure h offset, zero curvature)\n        {'true': {'omega_m': 0.315, 'omega_lambda': 0.685, 'h': 0.674},\n         'fid': {'omega_m': 0.315, 'omega_lambda': 0.685, 'h': 0.700},\n         'z': 0.8},\n        # Case 5 (boundary, no bias expected)\n        {'true': {'omega_m': 0.315, 'omega_lambda': 0.685, 'h': 0.674},\n         'fid': {'omega_m': 0.315, 'omega_lambda': 0.685, 'h': 0.674},\n         'z': 0.8},\n    ]\n\n    def compute_cosmological_quantities(omega_m, omega_lambda, h, z):\n        \"\"\"\n        Computes H(z) and D_M(z) for a given cosmology and redshift.\n\n        Args:\n            omega_m (float): Matter density parameter.\n            omega_lambda (float): Cosmological constant density parameter.\n            h (float): Reduced Hubble constant.\n            z (float): Redshift.\n\n        Returns:\n            tuple: A tuple containing (D_M(z), H(z)).\n        \"\"\"\n        H0 = 100.0 * h  # Hubble constant in km/s/Mpc\n        omega_k = 1.0 - omega_m - omega_lambda\n\n        def e_inv(zp):\n            # The integrand 1/E(z')\n            e_squared = omega_m * (1 + zp)**3 + omega_k * (1 + zp)**2 + omega_lambda\n            return 1.0 / np.sqrt(e_squared)\n\n        # Numerically integrate 1/E(z') from 0 to z\n        # High precision tolerances as required for numerical cosmology work\n        integral_val, _ = quad(e_inv, 0, z, epsabs=1e-12, epsrel=1e-12)\n\n        # Calculate D_M(z) based on curvature\n        # Small tolerance for checking if the universe is flat\n        if abs(omega_k)  1e-9:\n            # Flat geometry: Omega_k = 0\n            # D_M(z) = chi(z)\n            chi = (C_KM_S / H0) * integral_val\n            D_M = chi\n        else:\n            # The Hubble radius divided by sqrt(|Omega_k|)\n            d_h_sqrt_k = (C_KM_S / H0) / np.sqrt(abs(omega_k))\n            # Argument for sinh/sin function\n            arg = np.sqrt(abs(omega_k)) * integral_val\n\n            if omega_k > 0:\n                # Open geometry: Omega_k > 0\n                D_M = d_h_sqrt_k * np.sinh(arg)\n            else: # omega_k  0\n                # Closed geometry: Omega_k  0\n                D_M = d_h_sqrt_k * np.sin(arg)\n\n        # Calculate H(z)\n        Ez = 1.0 / e_inv(z)\n        Hz = H0 * Ez\n        \n        return D_M, Hz\n\n    results = []\n    for case in test_cases:\n        p_true = case['true']\n        p_fid = case['fid']\n        z = case['z']\n\n        Dm_true, H_true = compute_cosmological_quantities(\n            p_true['omega_m'], p_true['omega_lambda'], p_true['h'], z\n        )\n        \n        Dm_fid, H_fid = compute_cosmological_quantities(\n            p_fid['omega_m'], p_fid['omega_lambda'], p_fid['h'], z\n        )\n\n        # Calculate biases\n        delta_perp = (Dm_fid / Dm_true - 1.0) if Dm_true != 0 else 0\n        delta_para = (H_true / H_fid - 1.0) if H_fid != 0 else 0\n\n        # Format and append results\n        results.append(f\"{delta_perp:.6f}\")\n        results.append(f\"{delta_para:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3477460"}]}