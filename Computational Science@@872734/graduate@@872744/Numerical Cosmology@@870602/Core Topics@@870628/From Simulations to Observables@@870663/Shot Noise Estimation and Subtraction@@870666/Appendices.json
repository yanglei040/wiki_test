{"hands_on_practices": [{"introduction": "The theoretical ideal of a uniform survey rarely matches reality. Cosmological surveys have complex geometries and spatially varying selection functions, meaning the mean number density of tracers, $\\bar{n}(\\mathbf{x})$, is not constant. This practice guides you through deriving and implementing the shot-noise term for the widely used Feldman-Kaiser-Peacock (FKP) estimator, which is designed for such inhomogeneous surveys. By starting from the first principles of a Poisson point process, you will build a robust power spectrum estimator and validate its shot-noise subtraction, a foundational skill for analyzing large-scale structure data [@problem_id:3486501].", "problem": "Implement a complete program that constructs and validates a Feldman–Kaiser–Peacock (FKP) weighted power spectrum estimator for a cubic periodic survey with a spatially varying selection function. The objective is to start from the statistical properties of an inhomogeneous Poisson point process and derive the exact shot-noise subtraction term required for an unbiased estimator of the power spectrum. The derivation must begin from the first principles of a point process with intensity and its two-point statistics, and must not assume any specialized shortcut formula. Then, implement the estimator in a discretized, grid-based setting and validate it against random catalogs generated from the known selection function.\n\nYou are given the following setup, which must be used consistently across all parts:\n\n- Consider a cubic box of side length $L$ with periodic boundary conditions. All positions are in box-length units, and all quantities to be printed are real numbers without physical units.\n- Represent the continuous number density field by a discretized grid with $N^3$ cubic cells of equal volume $\\Delta V = L^3 / N^3$, indexed by $i \\in \\{1,\\dots,N^3\\}$. Define the cell-centered mean number density $\\bar n_i \\equiv \\bar n(\\mathbf x_i)$ and let $n_i$ denote the random realization of the number density in that cell. For an inhomogeneous Poisson process, the number of points in cell $i$ is Poisson-distributed with mean $\\mu_i = \\bar n_i \\Delta V$, and $n_i = \\text{Poisson}(\\mu_i)/\\Delta V$.\n- Define a real, nonnegative weight field $w(\\mathbf x)$, discretized as $w_i \\equiv w(\\mathbf x_i)$.\n- Define the weighted fluctuation field on the grid as $F_i = w_i \\left(n_i - \\bar n_i\\right)$.\n- Define the discrete Fourier transform of $F_i$ on the grid as an approximation to the continuous transform,\n  $$ F(\\mathbf k) \\approx \\Delta V \\sum_{i=1}^{N^3} F_i \\, e^{i \\mathbf k \\cdot \\mathbf x_i}, $$\n  using the standard discrete Fourier transform conventions on a periodic grid. All wavevectors $\\mathbf k$ are in units of the fundamental mode $2\\pi / L$ determined by the grid Fourier transform.\n\nYour tasks:\n\n1. From the definition of an inhomogeneous Poisson point process with intensity $\\bar n(\\mathbf x)$ and its two-point covariance, and the definition of the weighted field $F(\\mathbf x) = w(\\mathbf x)\\left[n(\\mathbf x) - \\bar n(\\mathbf x)\\right]$, derive the exact $k$-independent shot-noise term $S$ that must be subtracted from $|F(\\mathbf k)|^2$ to obtain an unbiased estimator of the power spectrum amplitude in the absence of clustering, when the estimator is normalized by the square of the survey-weight integral $I_1$. Your derivation must start from\n   - The defining property of a Poisson point process: for infinitesimal volumes $d^3x$, the counts are Poisson with mean $\\bar n(\\mathbf x) d^3x$, and\n   - The covariance of number densities: for general two-point statistics, $\\langle n(\\mathbf x) n(\\mathbf y) \\rangle = \\bar n(\\mathbf x) \\bar n(\\mathbf y) \\left[1 + \\xi(\\mathbf x,\\mathbf y)\\right] + \\bar n(\\mathbf x) \\delta_{\\rm D}(\\mathbf x - \\mathbf y)$,\n   where $\\delta_{\\rm D}$ is the Dirac delta distribution and $\\xi$ is the two-point correlation function.\n   Do not assume any special-case or shortcut expressions for $S$ in advance. State clearly the normalization integral you use, and obtain a closed-form expression for $S$ in terms of spatial integrals over $\\bar n(\\mathbf x)$ and $w(\\mathbf x)$.\n\n2. Implement the discretized estimator on a three-dimensional grid as follows:\n   - Compute $I_1$ and the derived $S$ using the discrete sums that approximate the corresponding spatial integrals.\n   - Generate Poisson-distributed number densities per cell consistent with $\\bar n_i$.\n   - Compute the Fourier transform $F(\\mathbf k)$ on the grid using the discrete Fourier transform of $F_i$, multiplied by $\\Delta V$.\n   - For each nonzero $\\mathbf k$-mode, form\n     $$ \\hat P(\\mathbf k) = \\frac{|F(\\mathbf k)|^2}{I_1^2} - S, $$\n     and aggregate statistics as specified in the test suite below.\n   - The weight field $w(\\mathbf x)$ may be arbitrary; for one of the test cases, use the FKP weight $w_{\\rm FKP}(\\mathbf x) = \\left[1 + \\bar n(\\mathbf x) P_0\\right]^{-1}$ with a given constant $P_0$.\n\n3. Validate the shot-noise subtraction in three test cases by printing the requested scalar quantities. All requested outputs are dimensionless.\n\nTest suite and required outputs:\n\n- Test case A (uniform baseline consistency):\n  - Parameters: $L = 200$, $N = 48$, $\\bar n(\\mathbf x) = n_0$ with $n_0 = 2 \\times 10^{-3}$, and $w(\\mathbf x) \\equiv 1$.\n  - Compute the discrete-shot term from your general formula using the grid sums, and compare it to the uniform-field limit prediction that follows from first principles for constant $\\bar n$ and constant $w$. Let $V = L^3$ and denote the uniform prediction by $S_{\\rm unif}$. Output the absolute difference $\\left|S_{\\rm grid} - S_{\\rm unif}\\right|$ as a single float for this test case.\n\n- Test case B (nonuniform selection validated by random catalogs):\n  - Parameters: $L = 200$, $N = 48$, spatially varying mean density\n    $$ \\bar n(\\mathbf x) = n_0 \\left[1 + a \\sin\\left(\\frac{2\\pi x}{L}\\right)\\sin\\left(\\frac{2\\pi y}{L}\\right)\\sin\\left(\\frac{2\\pi z}{L}\\right)\\right], $$\n    with $n_0 = 2 \\times 10^{-3}$ and $a = 0.4$. Use $w(\\mathbf x) \\equiv 1$.\n  - Compute $S_{\\rm grid}$ from your general formula on the grid.\n  - Independently estimate the same quantity by Monte Carlo integration using a random catalog drawn from the probability density proportional to $\\bar n(\\mathbf x)$ over the box. Use a sufficiently large number of Monte Carlo samples and return the Monte Carlo estimate $S_{\\rm MC}$ for the same expression, based on importance sampling with the target proportional to $\\bar n(\\mathbf x)$.\n  - Output the absolute difference $\\left|S_{\\rm grid} - S_{\\rm MC}\\right|$ as a single float for this test case.\n\n- Test case C (FKP-weighted end-to-end null test):\n  - Parameters: $L = 200$, $N = 48$, the same $\\bar n(\\mathbf x)$ as in Test case B, FKP weight with $P_0 = 5000$.\n  - Draw a Poisson realization per cell consistent with $\\bar n_i$ and compute $\\hat P(\\mathbf k)$ for all nonzero $\\mathbf k$-modes using your estimator with the derived $S$.\n  - Output the absolute value of the mean of $\\hat P(\\mathbf k)$ over all nonzero modes, as a single float. In the absence of clustering, this quantity should be close to zero if the shot-noise subtraction is correct.\n\nFinal output format:\n\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of Test cases A, B, and C:\n  - For Test case A: the float $\\left|S_{\\rm grid} - S_{\\rm unif}\\right|$.\n  - For Test case B: the float $\\left|S_{\\rm grid} - S_{\\rm MC}\\right|$.\n  - For Test case C: the float $\\left|\\langle \\hat P(\\mathbf k) \\rangle_{\\mathbf k \\ne 0}\\right|$.\n- Example format (numbers shown are placeholders): \"[0.00123,4.56e-06,0.0000789]\".", "solution": "The user-provided problem statement has been validated and is deemed sound, well-posed, and scientifically grounded. We proceed with the solution, which comprises a theoretical derivation followed by an explanation of the numerical implementation and validation tests.\n\n### 1. Derivation of the Shot-Noise Term\n\nThe objective is to derive the shot-noise subtraction term $S$ for the power spectrum estimator $\\hat P(\\mathbf k)$. The derivation begins from the first principles of an inhomogeneous Poisson point process.\n\nThe weighted fluctuation field $F(\\mathbf{x})$ is defined as:\n$$\nF(\\mathbf{x}) = w(\\mathbf{x}) \\left[ n(\\mathbf{x}) - \\bar{n}(\\mathbf{x}) \\right]\n$$\nwhere $n(\\mathbf{x})$ is the realized number density, $\\bar{n}(\\mathbf{x})$ is the mean number density (or intensity) of the Poisson process, and $w(\\mathbf{x})$ is a spatial weight function.\n\nThe Fourier transform of this field is given by:\n$$\nF(\\mathbf{k}) = \\int_V F(\\mathbf{x}) e^{i \\mathbf{k} \\cdot \\mathbf{x}} d^3x\n$$\nThe problem defines the power spectrum estimator for a mode $\\mathbf{k}$ as:\n$$\n\\hat P(\\mathbf{k}) = \\frac{|F(\\mathbf{k})|^2}{I_1^2} - S\n$$\nFor this estimator to be unbiased in the absence of physical clustering, its expectation value must be zero. The shot-noise term $S$ must therefore be equal to the expectation value of the first term under the null hypothesis of no clustering.\n$$\nS = \\left\\langle \\frac{|F(\\mathbf{k})|^2}{I_1^2} \\right\\rangle_{\\xi=0}\n$$\nHere, $\\xi$ denotes the two-point correlation function. We compute the numerator, $\\langle |F(\\mathbf{k})|^2 \\rangle_{\\xi=0}$.\n\nFirst, we expand $|F(\\mathbf{k})|^2 = F(\\mathbf{k}) F^*(\\mathbf{k})$:\n$$\n\\langle|F(\\mathbf{k})|^2\\rangle = \\left\\langle \\left( \\int_V F(\\mathbf{x}) e^{i \\mathbf{k} \\cdot \\mathbf{x}} d^3x \\right) \\left( \\int_V F(\\mathbf{y}) e^{-i \\mathbf{k} \\cdot \\mathbf{y}} d^3y \\right) \\right\\rangle\n$$\nBy linearity of the expectation operator, this becomes:\n$$\n\\langle|F(\\mathbf{k})|^2\\rangle = \\iint_V \\langle F(\\mathbf{x}) F(\\mathbf{y}) \\rangle e^{i \\mathbf{k} \\cdot (\\mathbf{x} - \\mathbf{y})} d^3x d^3y\n$$\nNext, we evaluate the two-point correlation function of the weighted field, $\\langle F(\\mathbf{x}) F(\\mathbf{y}) \\rangle$:\n$$\n\\langle F(\\mathbf{x}) F(\\mathbf{y}) \\rangle = \\langle w(\\mathbf{x})[n(\\mathbf{x}) - \\bar{n}(\\mathbf{x})] w(\\mathbf{y})[n(\\mathbf{y}) - \\bar{n}(\\mathbf{y})] \\rangle = w(\\mathbf{x}) w(\\mathbf{y}) \\left[ \\langle n(\\mathbf{x}) n(\\mathbf{y}) \\rangle - \\bar{n}(\\mathbf{x})\\bar{n}(\\mathbf{y}) \\right]\n$$\nThe problem provides the covariance for a general point process:\n$$\n\\langle n(\\mathbf{x}) n(\\mathbf{y}) \\rangle = \\bar{n}(\\mathbf{x}) \\bar{n}(\\mathbf{y}) [1 + \\xi(\\mathbf{x}, \\mathbf{y})] + \\bar{n}(\\mathbf{x}) \\delta_{\\rm D}(\\mathbf{x} - \\mathbf{y})\n$$\nwhere $\\delta_{\\rm D}$ is the Dirac delta distribution. Substituting this into the expression for $\\langle F(\\mathbf{x}) F(\\mathbf{y}) \\rangle$:\n$$\n\\langle F(\\mathbf{x}) F(\\mathbf{y}) \\rangle = w(\\mathbf{x}) w(\\mathbf{y}) \\left[ \\bar{n}(\\mathbf{x}) \\bar{n}(\\mathbf{y}) \\xi(\\mathbf{x}, \\mathbf{y}) + \\bar{n}(\\mathbf{x}) \\delta_{\\rm D}(\\mathbf{x} - \\mathbf{y}) \\right]\n$$\nWe are interested in the shot-noise contribution, which is the value in the absence of clustering, i.e., $\\xi(\\mathbf{x}, \\mathbf{y}) = 0$.\n$$\n\\langle F(\\mathbf{x}) F(\\mathbf{y}) \\rangle_{\\xi=0} = w(\\mathbf{x}) w(\\mathbf{y}) \\bar{n}(\\mathbf{x}) \\delta_{\\rm D}(\\mathbf{x} - \\mathbf{y})\n$$\nDue to the delta function $\\delta_{\\rm D}(\\mathbf{x} - \\mathbf{y})$, this expression is non-zero only when $\\mathbf{x} = \\mathbf{y}$. We can thus replace $w(\\mathbf{y})$ with $w(\\mathbf{x})$:\n$$\n\\langle F(\\mathbf{x}) F(\\mathbf{y}) \\rangle_{\\xi=0} = w(\\mathbf{x})^2 \\bar{n}(\\mathbf{x}) \\delta_{\\rm D}(\\mathbf{x} - \\mathbf{y})\n$$\nNow, we substitute this back into the integral for $\\langle |F(\\mathbf{k})|^2 \\rangle$:\n$$\n\\langle |F(\\mathbf{k})|^2 \\rangle_{\\xi=0} = \\iint_V w(\\mathbf{x})^2 \\bar{n}(\\mathbf{x}) \\delta_{\\rm D}(\\mathbf{x} - \\mathbf{y}) e^{i \\mathbf{k} \\cdot (\\mathbf{x} - \\mathbf{y})} d^3x d^3y\n$$\nIntegrating over $\\mathbf{y}$ collapses the delta function:\n$$\n\\langle |F(\\mathbf{k})|^2 \\rangle_{\\xi=0} = \\int_V w(\\mathbf{x})^2 \\bar{n}(\\mathbf{x}) e^{i \\mathbf{k} \\cdot (\\mathbf{x} - \\mathbf{x})} d^3x = \\int_V w(\\mathbf{x})^2 \\bar{n}(\\mathbf{x}) d^3x\n$$\nThis quantity represents the total power from shot noise, and it is independent of the wavevector $\\mathbf{k}$. Let us denote this integral as $I_S$:\n$$\nI_S = \\int_V w(\\mathbf{x})^2 \\bar{n}(\\mathbf{x}) d^3x\n$$\nThe problem states the estimator is normalized by $I_1^2$, where $I_1$ is a \"survey-weight integral.\" A standard and logical choice for this integral in this context is:\n$$\nI_1 = \\int_V w(\\mathbf{x}) \\bar{n}(\\mathbf{x}) d^3x\n$$\nThis integral is proportional to the weighted expectation of the total number of objects in the survey. We will adopt this definition.\n\nWith these definitions, the shot-noise term $S$ that ensures $\\langle \\hat P(\\mathbf{k}) \\rangle_{\\xi=0} = 0$ is:\n$$\nS = \\frac{\\langle |F(\\mathbf{k})|^2 \\rangle_{\\xi=0}}{I_1^2} = \\frac{\\int_V w(\\mathbf{x})^2 \\bar{n}(\\mathbf{x}) d^3x}{\\left( \\int_V w(\\mathbf{x}) \\bar{n}(\\mathbf{x}) d^3x \\right)^2}\n$$\nThis is the final expression for the shot-noise subtraction term.\n\n### 2. Discretized Implementation and Validation Plan\n\nThe continuous derivation is now translated into a discrete algorithm for a cubic grid of $N^3$ cells, each of volume $\\Delta V = (L/N)^3$. The integrals are replaced by sums over the grid cells, indexed by $i$:\n$$\nI_S \\rightarrow I_{S, \\text{grid}} = \\sum_{i=1}^{N^3} w_i^2 \\bar{n}_i \\Delta V\n$$\n$$\nI_1 \\rightarrow I_{1, \\text{grid}} = \\sum_{i=1}^{N^3} w_i \\bar{n}_i \\Delta V\n$$\nThe discrete shot-noise term is then:\n$$\nS_{\\text{grid}} = \\frac{I_{S, \\text{grid}}}{I_{1, \\text{grid}}^2}\n$$\nThe discrete Fourier transform of the fluctuation field $F_i = w_i(n_i - \\bar{n}_i)$ is given as $F(\\mathbf k) \\approx \\Delta V \\sum_i F_i e^{i \\mathbf k \\cdot \\mathbf x_i}$. This can be efficiently computed using the Fast Fourier Transform (FFT). Specifically, if $\\mathcal{F}$ denotes the `ifftn` routine (which uses a positive exponent) from `numpy.fft`, then $F(\\mathbf k)$ for the grid of wavevectors is calculated as $L^3 \\times \\mathcal{F}[F_i]$. The magnitude squared is then $|F(\\mathbf k)|^2$.\n\nThe validation plan proceeds with the three test cases specified.\n\n**Test Case A (Uniform Baseline Consistency):**\nHere, $\\bar{n}(\\mathbf{x}) = n_0$ and $w(\\mathbf{x}) = 1$. The discrete formula for $S_{\\text{grid}}$ gives:\n$S_{\\text{grid}} = \\frac{\\sum_i 1^2 n_0 \\Delta V}{(\\sum_i 1 \\cdot n_0 \\Delta V)^2} = \\frac{N^3 n_0 \\Delta V}{(N^3 n_0 \\Delta V)^2} = \\frac{n_0 L^3}{(n_0 L^3)^2} = \\frac{1}{n_0 L^3}$.\nThe uniform-field limit prediction, $S_{\\text{unif}}$, derived from first principles, yields the same result. The test requires computing the absolute difference $|S_{\\text{grid}} - S_{\\text{unif}}|$ which should be zero, up to floating-point precision.\n\n**Test Case B (Nonuniform Selection Validated by Monte Carlo):**\nHere, $\\bar{n}(\\mathbf{x})$ is spatially varying and $w(\\mathbf{x}) = 1$. $S_{\\text{grid}}$ is computed using the general discrete formula.\nFor the Monte Carlo estimation $S_{\\text{MC}}$, we must estimate the quantity $S = 1 / \\int_V \\bar{n}(\\mathbf{x}) d^3x$. The integral $I_{\\text{norm}} = \\int_V \\bar{n}(\\mathbf{x}) d^3x$ is estimated using rejection sampling, as specified. We define a bounding box for $\\bar{n}(\\mathbf{x})$ with height $n_{\\text{max}} = \\max_{\\mathbf x} \\bar{n}(\\mathbf{x})$. We generate $N_{\\text{tot}}$ uniform random points $(\\mathbf{x}_j, u_j)$ in the volume $V \\times [0, n_{\\text{max}}]$. The number of accepted points, $N_{\\text{acc}}$, are those for which $u_j < \\bar{n}(\\mathbf{x}_j)$. The integral is then estimated as $\\hat{I}_{\\text{norm}} = (N_{\\text{acc}} / N_{\\text{tot}}) \\times n_{\\text{max}} \\times L^3$. Then, $S_{\\text{MC}} = 1/\\hat{I}_{\\text{norm}}$. The test computes $|S_{\\text{grid}} - S_{\\text{MC}}|$.\n\n**Test Case C (FKP-Weighted End-to-End Null Test):**\nThis test validates the entire estimator pipeline. With a spatially varying $\\bar{n}(\\mathbf{x})$ and the FKP weight $w_{\\text{FKP}}(\\mathbf{x}) = [1 + \\bar{n}(\\mathbf{x}) P_0]^{-1}$, we first compute the shot-noise term $S$ using the full discrete formula. Then, we generate a single realization of the Poisson field: for each cell $i$, the number of objects $N_i$ is drawn from a Poisson distribution with mean $\\mu_i = \\bar{n}_i \\Delta V$. This gives the realized density $n_i = N_i / \\Delta V$. From this, we compute the fluctuation field $F_i$, its Fourier transform $F(\\mathbf{k})$, and finally the estimated power spectrum $\\hat P(\\mathbf{k}) = |F(\\mathbf{k})|^2/I_{1,\\text{grid}}^2 - S$ for all non-zero wavevectors. Since the underlying field has no clustering, the expectation of $\\hat P(\\mathbf{k})$ is zero. The test computes the absolute value of the mean of $\\hat P(\\mathbf{k})$ over all $\\mathbf{k} \\neq \\mathbf{0}$. For a single realization, this value will be small but non-zero, representing the sample variance. Averaging over many modes reduces this variance, so the result should be close to zero.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and validates the FKP weighted power spectrum estimator's\n    shot-noise subtraction term.\n    \"\"\"\n\n    def get_shot_noise(n_bar, w, L, N):\n        \"\"\"\n        Computes the shot noise term S from the derived formula on a grid.\n        S = (Integral(w^2 * n_bar) / Integral(w * n_bar)^2)\n        \"\"\"\n        delta_V = (L / N)**3\n        \n        # Numerator integral: I_S = Integral(w^2 * n_bar dV)\n        integrand_S = w**2 * n_bar\n        I_S_grid = np.sum(integrand_S) * delta_V\n        \n        # Denominator integral: I_1 = Integral(w * n_bar dV)\n        integrand_1 = w * n_bar\n        I_1_grid = np.sum(integrand_1) * delta_V\n        \n        S_grid = I_S_grid / (I_1_grid**2)\n        return S_grid, I_1_grid\n\n    # --- Test Case A: Uniform Baseline Consistency ---\n    def test_case_a():\n        L = 200.0\n        N = 48\n        n0 = 2.0e-3\n        \n        # Setup grid\n        n_bar_grid = np.full((N, N, N), n0)\n        w_grid = np.ones((N, N, N))\n        \n        # Compute S_grid from the general formula\n        S_grid, _ = get_shot_noise(n_bar_grid, w_grid, L, N)\n        \n        # Compute S_unif from the analytical prediction for a uniform field\n        V = L**3\n        S_unif = 1.0 / (n0 * V)\n        \n        return np.abs(S_grid - S_unif)\n\n    # --- Test Case B: Nonuniform Selection Validation by MC ---\n    def test_case_b():\n        L = 200.0\n        N = 48\n        n0 = 2.0e-3\n        a = 0.4\n        \n        # Setup grid and fields\n        grid_coords = np.linspace(0, L, N, endpoint=False) + 0.5 * (L/N)\n        X, Y, Z = np.meshgrid(grid_coords, grid_coords, grid_coords, indexing='ij')\n        \n        k_factor = 2.0 * np.pi / L\n        sin_term = np.sin(k_factor * X) * np.sin(k_factor * Y) * np.sin(k_factor * Z)\n        n_bar_grid = n0 * (1.0 + a * sin_term)\n        w_grid = np.ones((N, N, N))\n        \n        # Compute S_grid from the general formula\n        S_grid, _ = get_shot_noise(n_bar_grid, w_grid, L, N)\n        \n        # Compute S_MC by Monte Carlo integration (rejection sampling)\n        N_tot = 2 * 10**7\n        n_max = n0 * (1.0 + a)\n        V = L**3\n        \n        # Using vectorized operations for efficiency\n        rand_pos = np.random.uniform(0, L, (N_tot, 3))\n        rand_u = np.random.uniform(0, n_max, N_tot)\n        \n        n_bar_values = n0 * (1.0 + a * np.prod(np.sin(k_factor * rand_pos), axis=1))\n        \n        N_acc = np.sum(rand_u < n_bar_values)\n        \n        I_norm_mc = (N_acc / N_tot) * n_max * V\n        S_mc = 1.0 / I_norm_mc\n        \n        return np.abs(S_grid - S_mc)\n\n    # --- Test Case C: FKP-Weighted End-to-End Null Test ---\n    def test_case_c():\n        L = 200.0\n        N = 48\n        n0 = 2.0e-3\n        a = 0.4\n        P0 = 5000.0\n        \n        # Setup grid and fields\n        delta_V = (L / N)**3\n        grid_coords = np.linspace(0, L, N, endpoint=False) + 0.5 * (L/N)\n        X, Y, Z = np.meshgrid(grid_coords, grid_coords, grid_coords, indexing='ij')\n        \n        k_factor = 2.0 * np.pi / L\n        sin_term = np.sin(k_factor * X) * np.sin(k_factor * Y) * np.sin(k_factor * Z)\n        n_bar_grid = n0 * (1.0 + a * sin_term)\n        \n        # FKP weights\n        w_grid = 1.0 / (1.0 + n_bar_grid * P0)\n        \n        # Compute shot noise S and normalization I_1\n        S, I_1_grid = get_shot_noise(n_bar_grid, w_grid, L, N)\n        \n        # Generate a Poisson realization\n        mu_grid = n_bar_grid * delta_V\n        np.random.seed(42) # for reproducibility\n        N_grid = np.random.poisson(mu_grid)\n        n_grid = N_grid / delta_V\n        \n        # Compute the fluctuation field\n        F_grid = w_grid * (n_grid - n_bar_grid)\n        \n        # Compute its Fourier transform. F(k) = L^3 * ifftn(F_i)\n        F_k_grid = L**3 * np.fft.ifftn(F_grid)\n        \n        # Compute the unbiased power spectrum estimator P_hat(k)\n        P_hat_k = np.abs(F_k_grid)**2 / I_1_grid**2 - S\n        \n        # Calculate the mean of P_hat(k) over all k != 0 modes\n        # The k=0 mode is at index (0,0,0)\n        num_modes = N**3 - 1\n        mean_P_hat = (np.sum(P_hat_k) - P_hat_k[0, 0, 0]) / num_modes\n        \n        return np.abs(mean_P_hat)\n\n    # Run all test cases and collect results\n    results = [\n        test_case_a(),\n        test_case_b(),\n        test_case_c()\n    ]\n    \n    # Format and print the final output string\n    print(f\"[{','.join(f'{r:.6e}' for r in results)}]\")\n\nsolve()\n\n```", "id": "3486501"}, {"introduction": "Moving from continuous theory to discrete computation on a grid introduces numerical artifacts that can bias power spectrum measurements. This exercise focuses on how mass assignment schemes (like NGP, CIC, and TSC) and aliasing affect the estimation of shot noise. You will systematically benchmark these schemes, with and without the corrective technique of interlacing, to quantify the residual bias in the measured shot noise power and identify the optimal numerical choices for a given grid resolution [@problem_id:3486486].", "problem": "You are asked to design and implement a complete, runnable program that benchmarks shot-noise subtraction in a periodic cubic volume under different mass-assignment schemes, with and without interlacing, using a first-principles alias-sum model. The goal is to quantify the residual shot-noise bias in the isotropic power spectrum after subtracting the baseline Poisson shot noise, and to identify which mass-assignment scheme minimizes the bias for a fixed grid size. The setting, definitions, and required outputs are specified below.\n\nConsider a periodic, cubic, three-dimensional ($3$-dimensional) box of side length $L$, discretized on a uniform grid with $N$ cells per side, cell size $\\Delta x = L/N$, and one-particle mass-assignment deposit onto the grid. The discrete Fourier transform of the grid is taken using the standard convention for discrete Fourier modes. Let the fundamental wavenumber be $k_{\\mathrm{f}} = 2\\pi/L$ and the per-axis Nyquist wavenumber be $k_{\\mathrm{N}} = \\pi/\\Delta x = \\pi N/L$. For a homogeneous Poisson point process of mean number density $\\bar{n}$, the ensemble-average continuous power spectrum is white, with amplitude $P_{\\mathrm{shot}} = 1/\\bar{n}$ in units of volume (i.e., $L^{3}$). Mass assignment convolves the field with a kernel and sampling on a grid induces aliasing; after deconvolving by the mass-assignment window in Fourier space, the estimated power spectrum $P_{\\mathrm{est}}(k)$ differs from the true constant $P_{\\mathrm{shot}}$ by residual alias contributions. Interlacing (using the average of two grids, one shifted by half a cell along each axis, with the appropriate Fourier-phase compensation) cancels all alias images whose integer image-vector components sum to an odd integer, reducing aliasing power.\n\nYou must proceed from these fundamental bases:\n- The definition of a Poisson point process in a periodic volume and the fact that its ensemble-average two-point correlation function vanishes at nonzero separation, implying a white power spectrum with amplitude $P_{\\mathrm{shot}}$.\n- Convolution in real space corresponds to multiplication by a window in Fourier space, and uniform sampling on a grid produces periodic replication of the continuous spectrum in Fourier space (Poisson summation).\n- The mass-assignment windows for B-spline schemes of order $p \\in \\{0,1,2,3\\}$ in one dimension are $W_{p}^{(1\\mathrm{D})}(k) = \\left[\\mathrm{sinc}\\left(k \\Delta x/2\\right)\\right]^{p+1}$, where $\\mathrm{sinc}(x) \\equiv \\sin(x)/x$, and in three dimensions $W_{p}^{(3\\mathrm{D})}(k_{x},k_{y},k_{z}) = \\prod_{i\\in\\{x,y,z\\}} W_{p}^{(1\\mathrm{D})}(k_{i})$. These correspond respectively to Nearest Grid Point (NGP, $p=0$), Cloud-In-Cell (CIC, $p=1$), Triangular-Shaped-Cloud (TSC, $p=2$), and Piecewise-Cubic-Spline (PCS, $p=3$).\n- After deconvolution by $W_{p}^{(3\\mathrm{D})}$, the residual alias power at wavevector $\\boldsymbol{k}$ from images shifted by integer vectors $\\boldsymbol{m} \\in \\mathbb{Z}^{3}\\setminus\\{\\boldsymbol{0}\\}$ with spacing $2 k_{\\mathrm{N}}$ per axis is controlled by the window ratio $\\left|W_{p}^{(3\\mathrm{D})}\\left(\\boldsymbol{k} + 2 k_{\\mathrm{N}} \\boldsymbol{m}\\right)/W_{p}^{(3\\mathrm{D})}(\\boldsymbol{k})\\right|^{2}$. With interlacing, only images with even parity $\\sum_{i} m_{i}$ even contribute; odd-parity images cancel.\n\nUse these facts to derive a computable expression for the fractional residual shot-noise bias at a discrete mode $\\boldsymbol{k}$, defined as the ratio\n$$\n\\mathcal{R}_{p}(\\boldsymbol{k}) \\equiv \\frac{P_{\\mathrm{est}}(\\boldsymbol{k}) - P_{\\mathrm{shot}}}{P_{\\mathrm{shot}}} ,\n$$\nin terms of the mass-assignment window and the discrete alias images. Then, spherically average over all discrete Fourier modes with magnitudes $k$ in the range $0 < k \\leq \\alpha \\, k_{\\mathrm{N}}$ to obtain the mean bias $\\overline{\\mathcal{R}}_{p}(\\alpha)$ for each scheme. Here $\\alpha \\in (0,1]$ is a fractional cutoff relative to the per-axis Nyquist wavenumber. Because the ratio is dimensionless, there is no unit-carrying output required; you must still maintain dimensional consistency in intermediate reasoning. For numerical evaluation, truncate the alias sum to a cube of integer image vectors with $|m_{i}| \\leq m_{\\max}$ for each axis and $\\boldsymbol{m} \\neq \\boldsymbol{0}$; with interlacing, include only even-parity images with $\\sum_{i} m_{i}$ even.\n\nYour program must:\n- Fix the box size to $L = 1$ (arbitrary volume units), and the grid to $N = 32$ per side, so that all reported values of the power spectrum are in units of $L^{3} = 1$ and the fractional residuals are dimensionless.\n- Consider the four schemes $p \\in \\{0,1,2,3\\}$ corresponding to NGP, CIC, TSC, PCS, respectively.\n- For each chosen $\\alpha$, compute the mean fractional residual $\\overline{\\mathcal{R}}_{p}(\\alpha)$ by averaging $\\mathcal{R}_{p}(\\boldsymbol{k})$ over all discrete Fourier modes with $0 < k \\leq \\alpha \\, k_{\\mathrm{N}}$.\n- Do this both without interlacing and with interlacing as defined above.\n- Identify, for each $\\alpha$, the scheme index $p$ that minimizes $\\overline{\\mathcal{R}}_{p}(\\alpha)$ in the non-interlaced case and in the interlaced case.\n\nTest suite and required output:\n- Use $m_{\\max} = 3$.\n- Evaluate three cutoff values $\\alpha \\in \\{0.5, 0.7, 0.95\\}$.\n- For each $\\alpha$, output four values in order: the integer index $p$ that minimizes $\\overline{\\mathcal{R}}_{p}(\\alpha)$ without interlacing, the integer index $p$ that minimizes $\\overline{\\mathcal{R}}_{p}(\\alpha)$ with interlacing, the corresponding minimal mean residual without interlacing (a float), and the corresponding minimal mean residual with interlacing (a float). The mapping is $p = 0 \\rightarrow$ NGP, $p = 1 \\rightarrow$ CIC, $p = 2 \\rightarrow$ TSC, $p = 3 \\rightarrow$ PCS.\n- Your program should produce a single line of output containing the results for the three $\\alpha$ values, concatenated in order $\\alpha = 0.5$, then $\\alpha = 0.7$, then $\\alpha = 0.95$, as a comma-separated list enclosed in square brackets (e.g., \"[$p_{0.5}^{\\mathrm{no}},p_{0.5}^{\\mathrm{int}},\\overline{\\mathcal{R}}_{0.5}^{\\mathrm{no}},\\overline{\\mathcal{R}}_{0.5}^{\\mathrm{int}},p_{0.7}^{\\mathrm{no}},\\dots$]\"). All numbers must be printed in their native numeric format (integers for scheme indices and floating-point numbers for residuals).", "solution": "The problem requires the design and implementation of a program to benchmark shot-noise subtraction techniques in numerical cosmology. The core task is to calculate the mean fractional residual shot-noise bias for different mass-assignment schemes, with and without interlacing, and identify the optimal scheme for given parameters. The solution must be derived from first principles.\n\n### Step 1: Theoretical Derivation\n\nThe analysis begins with a homogeneous Poisson distribution of particles in a periodic cubic box of volume $V=L^3$. The ensemble-average power spectrum of such a process is \"white\" noise, meaning it is constant for all wavenumbers $\\boldsymbol{k} \\neq \\boldsymbol{0}$. Its amplitude is given by $P_{\\mathrm{shot}} = 1/\\bar{n}$, where $\\bar{n}$ is the mean number density of particles.\n\nWhen estimating the power spectrum numerically, the continuous particle distribution is first assigned to a discrete grid. This process is equivalent to convolving the continuous density field $\\rho(\\boldsymbol{x})$ with a mass-assignment kernel $W_p^{(3\\mathrm{D}, \\text{real})}(\\boldsymbol{x})$ and then sampling the result on a grid of $N^3$ cells with spacing $\\Delta x = L/N$.\n\nAccording to the convolution theorem, this operation corresponds to multiplication in Fourier space. The continuous Fourier transform of the grid-assigned density is $\\tilde{\\rho}_g(\\boldsymbol{k}) = \\tilde{\\rho}(\\boldsymbol{k}) W_p^{(3\\mathrm{D})}(\\boldsymbol{k})$, where $\\tilde{\\rho}(\\boldsymbol{k})$ is the Fourier transform of the particle density and $W_p^{(3\\mathrm{D})}(\\boldsymbol{k})$ is the Fourier transform of the kernel, known as the mass-assignment window function.\n\nThe subsequent sampling on a grid causes aliasing in Fourier space. The discrete Fourier transform (DFT) of the sampled field at a discrete wavevector $\\boldsymbol{k}_{\\text{d}}$ is given by the Poisson summation formula, which sums contributions from the continuous spectrum at all wavevectors that are congruent modulo the sampling frequency. The sampling wavevector is $k_s = 2\\pi/\\Delta x = 2k_{\\text{N}}$, where $k_{\\text{N}} = \\pi/\\Delta x$ is the Nyquist wavenumber. The DFT mode $\\hat{\\rho}_g(\\boldsymbol{k}_{\\text{d}})$ is thus:\n$$\n\\hat{\\rho}_g(\\boldsymbol{k}_{\\text{d}}) \\propto \\sum_{\\boldsymbol{m} \\in \\mathbb{Z}^3} \\tilde{\\rho}_g(\\boldsymbol{k}_{\\text{d}} + 2k_{\\text{N}}\\boldsymbol{m}) = \\sum_{\\boldsymbol{m} \\in \\mathbb{Z}^3} \\tilde{\\rho}(\\boldsymbol{k}_{\\text{d}} + 2k_{\\text{N}}\\boldsymbol{m}) W_p^{(3\\mathrm{D})}(\\boldsymbol{k}_{\\text{d}} + 2k_{\\text{N}}\\boldsymbol{m})\n$$\nwhere $\\boldsymbol{m}$ is a vector of integers.\n\nThe raw power spectrum from the DFT, $\\hat{P}_{\\text{raw}}(\\boldsymbol{k}_{\\text{d}})$, is proportional to the ensemble average of the squared modulus of the Fourier modes. For a Poisson process, the phases of $\\tilde{\\rho}(\\boldsymbol{k})$ are random and uncorrelated at different $\\boldsymbol{k}$. Therefore, the ensemble average of cross-terms vanishes:\n$$\n\\hat{P}_{\\text{raw}}(\\boldsymbol{k}_{\\text{d}}) \\propto \\langle|\\hat{\\rho}_g(\\boldsymbol{k}_{\\text{d}})|^2\\rangle = \\sum_{\\boldsymbol{m} \\in \\mathbb{Z}^3} \\langle|\\tilde{\\rho}(\\boldsymbol{k}_{\\text{d}} + 2k_{\\text{N}}\\boldsymbol{m})|^2\\rangle |W_p^{(3\\mathrm{D})}(\\boldsymbol{k}_{\\text{d}} + 2k_{\\text{N}}\\boldsymbol{m})|^2\n$$\nSince the underlying power spectrum is white noise, $\\langle|\\tilde{\\rho}(\\boldsymbol{k})|^2\\rangle/V = P_{\\text{shot}}$ for any $\\boldsymbol{k} \\neq \\boldsymbol{0}$. Normalizing correctly, the raw power is:\n$$\n\\hat{P}_{\\text{raw}}(\\boldsymbol{k}_{\\text{d}}) = P_{\\text{shot}} \\sum_{\\boldsymbol{m} \\in \\mathbb{Z}^3} |W_p^{(3\\mathrm{D})}(\\boldsymbol{k}_{\\text{d}} + 2k_{\\text{N}}\\boldsymbol{m})|^2\n$$\nTo obtain the estimated power spectrum $P_{\\text{est}}(\\boldsymbol{k}_{\\text{d}})$, we must deconvolve the effect of the mass-assignment window at the principal frequency ($\\boldsymbol{m}=\\boldsymbol{0}$). This is done by dividing the raw power by $|W_p^{(3\\mathrm{D})}(\\boldsymbol{k}_{\\text{d}})|^2$:\n$$\nP_{\\text{est}}(\\boldsymbol{k}_{\\text{d}}) = \\frac{\\hat{P}_{\\text{raw}}(\\boldsymbol{k}_{\\text{d}})}{|W_p^{(3\\mathrm{D})}(\\boldsymbol{k}_{\\text{d}})|^2} = P_{\\text{shot}} \\sum_{\\boldsymbol{m} \\in \\mathbb{Z}^3} \\frac{|W_p^{(3\\mathrm{D})}(\\boldsymbol{k}_{\\text{d}} + 2k_{\\text{N}}\\boldsymbol{m})|^2}{|W_p^{(3\\mathrm{D})}(\\boldsymbol{k}_{\\text{d}})|^2}\n$$\nThe fractional residual shot-noise bias $\\mathcal{R}_p(\\boldsymbol{k}_{\\text{d}})$ is defined as $(P_{\\text{est}} - P_{\\text{shot}}) / P_{\\text{shot}}$. Substituting the expression for $P_{\\text{est}}$ and separating the $\\boldsymbol{m}=\\boldsymbol{0}$ term from the sum gives:\n$$\n\\mathcal{R}_p(\\boldsymbol{k}_{\\text{d}}) = \\left( \\frac{|W_p^{(3\\mathrm{D})}(\\boldsymbol{k}_{\\text{d}})|^2}{|W_p^{(3\\mathrm{D})}(\\boldsymbol{k}_{\\text{d}})|^2} + \\sum_{\\boldsymbol{m} \\in \\mathbb{Z}^3\\setminus\\{\\boldsymbol{0}\\}} \\frac{|W_p^{(3\\mathrm{D})}(\\boldsymbol{k}_{\\text{d}} + 2k_{\\text{N}}\\boldsymbol{m})|^2}{|W_p^{(3\\mathrm{D})}(\\boldsymbol{k}_{\\text{d}})|^2} \\right) - 1\n$$\n$$\n\\mathcal{R}_p(\\boldsymbol{k}_{\\text{d}}) = \\sum_{\\boldsymbol{m} \\in \\mathbb{Z}^3\\setminus\\{\\boldsymbol{0}\\}} \\left| \\frac{W_p^{(3\\mathrm{D})}(\\boldsymbol{k}_{\\text{d}} + 2k_{\\text{N}}\\boldsymbol{m})}{W_p^{(3\\mathrm{D})}(\\boldsymbol{k}_{\\text{d}})} \\right|^2\n$$\nThis expression quantifies the residual power from aliased images after subtracting the primary shot noise power.\n\nThe B-spline window functions are given by $W_{p}^{(1\\mathrm{D})}(k) = [\\mathrm{sinc}(k \\Delta x/2)]^{p+1}$ and $W_{p}^{(3\\mathrm{D})}(\\boldsymbol{k}) = \\prod_{i\\in\\{x,y,z\\}} W_{p}^{(1\\mathrm{D})}(k_{i})$. A discrete wavevector component is $k_i = n_i (2\\pi/L)$, where $n_i$ is an integer mode index. The alias-shifted component is $k_i' = k_i + 2k_{\\text{N}}m_i = (n_i + N m_i)(2\\pi/L)$. The argument of the sinc function becomes $k_i \\Delta x/2 = n_i \\pi/N$ and $k_i' \\Delta x/2 = (n_i + N m_i)\\pi/N$. Using the property $\\sin(x+m\\pi) = (-1)^m \\sin(x)$, the ratio of 1D window functions simplifies significantly:\n$$\n\\frac{W_p^{(1\\mathrm{D})}(k_i')}{W_p^{(1\\mathrm{D})}(k_i)} = \\left( \\frac{\\mathrm{sinc}((n_i/N + m_i)\\pi)}{\\mathrm{sinc}(n_i\\pi/N)} \\right)^{p+1} = \\left( \\frac{(-1)^{m_i} n_i}{n_i + N m_i} \\right)^{p+1}\n$$\nThis simplified form is valid for $n_i \\neq 0$. If $n_i=0$, the ratio is $0$ for $m_i \\neq 0$ and $1$ for $m_i=0$. The fractional bias for a mode with integer indices $\\boldsymbol{n}=(n_x, n_y, n_z)$ is:\n$$\n\\mathcal{R}_p(\\boldsymbol{n}) = \\sum_{\\boldsymbol{m} \\in \\mathbb{Z}^3\\setminus\\{\\boldsymbol{0}\\}} \\left| \\prod_{j \\in \\{x,y,z\\}} \\left( \\frac{(-1)^{m_j} n_j}{n_j+N m_j} \\right)^{p+1} \\right|^2 = \\sum_{\\boldsymbol{m} \\in \\mathbb{Z}^3\\setminus\\{\\boldsymbol{0}\\}} \\left( \\prod_{j \\in \\{x,y,z\\}} \\left( \\frac{n_j}{n_j+N m_j} \\right)^{p+1} \\right)^2\n$$\nThe factor $(-1)^{\\sum m_j}$ vanishes upon squaring.\n\nFor an interlaced scheme, the density fields of two grids shifted by $\\Delta x/2$ relative to each other are averaged after phase correction. This procedure cancels alias images $\\boldsymbol{m}$ where the sum of components $\\sum_i m_i$ is odd. The formula for $\\mathcal{R}_p(\\boldsymbol{n})$ remains the same, but the sum is restricted to vectors $\\boldsymbol{m}$ with even parity $\\sum_i m_i$.\n\n### Step 2: Algorithmic Design\n\nThe program will implement the derived formula for $\\mathcal{R}_p(\\boldsymbol{n})$ and perform the required averaging and comparison.\n\n1.  **Constants and Grids**: Define numerical parameters $L=1$, $N=32$, $m_{\\max}=3$, and the set of orders $p \\in \\{0,1,2,3\\}$. Generate 3D grids representing the integer mode indices $n_x, n_y, n_z$ using `numpy.fft.fftfreq` and `numpy.meshgrid`. Calculate the corresponding wavevector magnitudes $|\\boldsymbol{k}|$.\n2.  **Alias Vectors**: Generate a list of all alias vectors $\\boldsymbol{m}=(m_x, m_y, m_z)$ where $|m_i| \\le m_{\\max}$ and $\\boldsymbol{m} \\neq \\boldsymbol{0}$.\n3.  **Iteration over Scenarios**: Loop through each value of $\\alpha \\in \\{0.5, 0.7, 0.95\\}$.\n    *   For each $\\alpha$, determine the wavenumber cutoff $k_{\\text{cut}} = \\alpha k_{\\text{N}}$ and create a boolean mask for all grid modes $\\boldsymbol{k}$ satisfying $0 < |\\boldsymbol{k}| \\le k_{\\text{cut}}$.\n    *   Loop through each scheme order $p \\in \\{0, 1, 2, 3\\}$.\n    *   For both non-interlaced and interlaced cases:\n        1.  Initialize a 3D grid for the total residual bias $\\mathcal{R}_p$ to zeros.\n        2.  Loop through each alias vector $\\boldsymbol{m}$. For the interlaced case, skip vectors with odd parity ($\\sum_i m_i$ is odd).\n        3.  For each vector $\\boldsymbol{m}$, calculate the 3D grid of alias contributions. This is done by computing the product of 1D ratio terms, `(n_j / (n_j + N*m_j))`, for each axis, taking care to handle the $n_j=0$ case correctly (where the ratio is zero if $m_j \\neq 0$).\n        4.  Raise the resulting total ratio grid to the power of $2(p+1)$ and add it to the total residual bias grid $\\mathcal{R}_p$.\n        5.  After summing over all relevant $\\boldsymbol{m}$, calculate the mean residual bias by averaging the values in the $\\mathcal{R}_p$ grid over the active modes selected by the wavenumber mask.\n    *   Store the computed mean biases for each $p$.\n4.  **Result Aggregation**: For the current $\\alpha$, find the scheme index $p$ that results in the minimum mean bias for the non-interlaced and interlaced cases, respectively. Record these indices and their corresponding minimum bias values.\n5.  **Output**: Concatenate the results for all $\\alpha$ values into a single list and print it in the specified comma-separated format.\n\nThis structured approach directly maps the derived physical model onto a computationally efficient and robust algorithm using vectorized `NumPy` operations.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the minimal residual shot-noise bias for different mass-assignment\n    schemes as specified in the problem statement.\n    \"\"\"\n    # Problem parameters\n    L = 1.0\n    N = 32\n    m_max = 3\n    alphas = [0.5, 0.7, 0.95]\n    p_orders = [0, 1, 2, 3]  # NGP, CIC, TSC, PCS\n\n    # Derived constants\n    Delta_x = L / N\n    k_f = 2 * np.pi / L\n    k_N = np.pi / Delta_x\n\n    # Generate integer mode indices n_i for the DFT grid\n    # np.fft.fftfreq(N) gives [0, 1/N, .. N/2/N, .., -1/N]\n    # Multiply by N to get integer indices [0, 1, .. N/2, .., -1]\n    n_vals = np.fft.fftfreq(N) * N\n    nx, ny, nz = np.meshgrid(n_vals, n_vals, n_vals, indexing='ij')\n\n    # Calculate wavenumber magnitudes for each grid point\n    kx = nx * k_f\n    ky = ny * k_f\n    kz = nz * k_f\n    k_mags = np.sqrt(kx**2 + ky**2 + kz**2)\n\n    # Generate list of alias vectors m != 0\n    m_vectors = []\n    for mx in m_vals:\n        for my in m_vals:\n            for mz in m_vals:\n                if mx == 0 and my == 0 and mz == 0:\n                    continue\n                m_vectors.append((mx, my, mz))\n\n    final_results = []\n\n    def get_ratio_contrib(n_grid, m_val, N_grid):\n        \"\"\"\n        Calculates the contribution to the alias ratio for one axis.\n        The ratio is n / (n + N*m).\n        \"\"\"\n        if m_val == 0:\n            # If m_j = 0, the ratio is 1, so it doesn't contribute to the product.\n            return np.ones_like(n_grid, dtype=float)\n        else:\n            # If m_j != 0, the ratio is n_j / (n_j + N*m_j).\n            # This is 0 if n_j = 0.\n            # We use np.divide to handle n_j=0 safely.\n            ratio = np.divide(n_grid, n_grid + N_grid * m_val,\n                              out=np.zeros_like(n_grid, dtype=float),\n                              where=(n_grid != 0))\n            return ratio\n\n    for alpha in alphas:\n        k_cutoff = alpha * k_N\n        # Mask for averaging: 0 < k <= alpha * k_N\n        mask = (k_mags > 0) & (k_mags <= k_cutoff)\n\n        results_no_interlace = []\n        results_interlace = []\n\n        for p in p_orders:\n            # Non-interlaced case\n            R_grid_no_interlace = np.zeros((N, N, N), dtype=float)\n            for mx, my, mz in m_vectors:\n                ratio_x = get_ratio_contrib(nx, mx, N)\n                ratio_y = get_ratio_contrib(ny, my, N)\n                ratio_z = get_ratio_contrib(nz, mz, N)\n                \n                total_ratio = ratio_x * ratio_y * ratio_z\n                term = total_ratio**(2 * (p + 1))\n                R_grid_no_interlace += term\n            \n            mean_R_no_interlace = np.mean(R_grid_no_interlace[mask])\n            results_no_interlace.append(mean_R_no_interlace)\n\n            # Interlaced case\n            R_grid_interlace = np.zeros((N, N, N), dtype=float)\n            for mx, my, mz in m_vectors:\n                # Skip odd-parity images for interlacing\n                if (mx + my + mz) % 2 != 0:\n                    continue\n                \n                ratio_x = get_ratio_contrib(nx, mx, N)\n                ratio_y = get_ratio_contrib(ny, my, N)\n                ratio_z = get_ratio_contrib(nz, mz, N)\n\n                total_ratio = ratio_x * ratio_y * ratio_z\n                term = total_ratio**(2 * (p + 1))\n                R_grid_interlace += term\n            \n            mean_R_interlace = np.mean(R_grid_interlace[mask])\n            results_interlace.append(mean_R_interlace)\n\n        # Find the scheme p that minimizes the residual for the current alpha\n        min_R_no_interlace = min(results_no_interlace)\n        min_p_no_interlace = p_orders[results_no_interlace.index(min_R_no_interlace)]\n\n        min_R_interlace = min(results_interlace)\n        min_p_interlace = p_orders[results_interlace.index(min_R_interlace)]\n\n        final_results.extend([min_p_no_interlace, min_p_interlace,\n                              min_R_no_interlace, min_R_interlace])\n\n    # Print the final concatenated results in the required format\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n\n```", "id": "3486486"}, {"introduction": "A common and perplexing issue in power spectrum analysis is obtaining unphysical negative bandpowers at high wavenumbers after shot-noise subtraction. This problem is often ambiguous: is it due to an incorrect shot-noise estimate, or is it an artifact of the survey window function leaking power from large to small scales? This practice introduces a powerful diagnostic technique using mock catalogs to disentangle these effects, providing a clear methodology for identifying the root cause of such anomalies in real-world data [@problem_id:3486487].", "problem": "You are given a set of measured bandpowers that become negative at high $k$ after subtracting $1/\\bar n$. In the context of numerical cosmology, consider a one-dimensional toy model for a survey window to design a principled diagnostic that distinguishes between over-subtraction of shot noise and window-induced leakage of large-scale power. The diagnostic must be based on window-convolved mock bandpowers constructed from a controllable underlying power spectrum. The final deliverable is a complete, runnable program that implements the diagnostic and outputs the classification for a provided test suite.\n\nStart from the following foundational bases:\n\n- The galaxy overdensity field in real space, multiplied by a survey window function $W(x)$, corresponds in Fourier space to the true spectrum convolved with the window kernel. Specifically, multiplication in configuration space corresponds to convolution in Fourier space.\n- For Poisson sampling of discrete tracers, the shot noise contribution to the power spectrum is approximately constant and equal to $1/\\bar n$ where $\\bar n$ is the mean number density.\n- The measured pseudo-bandpowers under a window are modeled as the window-convolved true power plus a constant shot noise term.\n\nDesign a diagnostic procedure using two sets of window-convolved mock bandpowers:\n\n- Construct a mock with full large-scale power characterized by a smooth spectrum $P_{\\mathrm{true}}(k)$.\n- Construct a mock in which large-scale power is suppressed below a cutoff $k_{\\mathrm{cut}}$, yielding a modified spectrum $P_{\\mathrm{cut}}(k)$.\n\nUse the same survey window in both mocks. For the survey window, model the real-space window as a top-hat of length $L$, whose Fourier-space kernel is proportional to the squared sinc function of the wavenumber difference. Discretize the wavenumber into $N$ bins on a uniform grid between a minimum and maximum value, and approximate the window convolution as a discrete mixing by a matrix whose entries depend only on the wavenumber differences, normalized in a way that preserves total power across each output row. Use the following true spectrum form for the full mock:\n$$\nP_{\\mathrm{true}}(k) = \\frac{A_0}{1 + \\left(\\frac{k}{k_0}\\right)^2}.\n$$\nDefine the cut mock by setting $P_{\\mathrm{cut}}(k) = 0$ for $k \\le k_{\\mathrm{cut}}$ and $P_{\\mathrm{cut}}(k) = P_{\\mathrm{true}}(k)$ for $k > k_{\\mathrm{cut}}$.\n\nGiven a value for the true mean density $\\bar n_{\\mathrm{true}}$ and an assumed value $\\bar n_{\\mathrm{assumed}}$, construct the pseudo bandpowers as the window-convolved power plus the constant shot noise $1/\\bar n_{\\mathrm{true}}$. From these mocks, define the following diagnostic quantities calculated over the high-$k$ subset of bins comprising the top fraction $f_{\\mathrm{high}}$ of the wavenumber grid:\n\n- The effective shot-noise estimate $S_{\\mathrm{eff}}$ as the mean of the high-$k$ region of the cut mock pseudo bandpowers.\n- The leakage metric $L_{\\mathrm{metric}}$ as the difference between the mean of the high-$k$ region of the full mock pseudo bandpowers and the mean of the high-$k$ region of the cut mock pseudo bandpowers.\n\nClassify the cause of negative bandpowers at high $k$ as follows, using a threshold $\\tau = 0.05 \\times \\left(1/\\bar n_{\\mathrm{assumed}}\\right)$:\n\n- Over-subtraction if $1/\\bar n_{\\mathrm{assumed}} - S_{\\mathrm{eff}} > \\tau$ and $L_{\\mathrm{metric} } \\le \\tau$.\n- Window-induced leakage if $L_{\\mathrm{metric}} > \\tau$ and $1/\\bar n_{\\mathrm{assumed}} - S_{\\mathrm{eff}} \\le \\tau$.\n- Ambiguous if both conditions above are simultaneously true or both are false.\n\nYour program must implement the above diagnostic and produce classifications for the following test suite. Each test case provides $\\left(N, L, A_0, k_0, \\bar n_{\\mathrm{true}}, \\bar n_{\\mathrm{assumed}}, k_{\\mathrm{cut}}, f_{\\mathrm{high}}\\right)$:\n\n- Test case $1$ (happy path over-subtraction): $\\left(256, 200.0, 10^{-3}, 0.05, 1000.0, 800.0, 0.03, 0.3\\right)$.\n- Test case $2$ (happy path leakage): $\\left(256, 20.0, 5\\times 10^{-3}, 0.02, 1000.0, 1000.0, 0.03, 0.3\\right)$.\n- Test case $3$ (mixed contribution, edge case): $\\left(256, 20.0, 3\\times 10^{-3}, 0.02, 1000.0, 900.0, 0.03, 0.3\\right)$.\n- Test case $4$ (boundary, no strong effect): $\\left(256, 200.0, 10^{-3}, 0.05, 1000.0, 1000.0, 0.03, 0.3\\right)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases. Use the following integer codes for the classification: $0$ for over-subtraction, $1$ for leakage, and $2$ for ambiguous. For example, the output format must be $\\left[0,1,2,2\\right]$ if those were the results.\n\nAll computations are dimensionless; no physical units are required. Angles are not involved. Express all derived numerical answers internally as floating point values. The final output must be a list of integers as described above on a single line.", "solution": "The problem requires the design and implementation of a diagnostic procedure to distinguish between two potential causes for negative power spectrum bandpowers at high wavenumbers ($k$) after shot noise subtraction: $1$) over-subtraction of shot noise due to an incorrect estimate of the mean galaxy density ($\\bar{n}$), and $2$) leakage of power from large scales (low $k$) to small scales (high $k$) induced by the survey window function. The diagnostic is constructed within a simplified $1$-dimensional toy model.\n\nThe core principle is to construct two mock datasets that isolate these effects. One mock contains the full cosmological power, while the second has its large-scale power artificially removed. By comparing these mocks, we can quantify the leakage contribution and disentangle it from effects related to shot noise. The entire procedure is implemented as a sequence of well-defined computational steps.\n\nFirst, we establish the computational domain. The continuous wavenumber $k$ is discretized into $N$ uniform bins over a finite range $[k_{\\min}, k_{\\max}]$. Based on the characteristic scales of the problem ($k_0 \\approx 0.02-0.05$), a reasonable range is chosen, for instance, $k_{\\min} = 0$ to $k_{\\max} = 1.0$. The center of each bin $i$ is denoted by $k_i$.\n\nNext, we define the underlying theoretical power spectra. The full, smooth power spectrum, $P_{\\mathrm{true}}(k)$, is modeled by a Lorentzian-like function:\n$$\nP_{\\mathrm{true}}(k) = \\frac{A_0}{1 + \\left(\\frac{k}{k_0}\\right)^2}\n$$\nwhere $A_0$ is the amplitude and $k_0$ is a characteristic scale. To isolate the effects of large-scale power, a second spectrum, $P_{\\mathrm{cut}}(k)$, is defined. This \"cut\" spectrum is identical to $P_{\\mathrm{true}}(k)$ but is set to zero below a certain cutoff wavenumber, $k_{\\mathrm{cut}}$:\n$$\nP_{\\mathrm{cut}}(k) = \\begin{cases} 0 & k \\le k_{\\mathrm{cut}} \\\\ P_{\\mathrm{true}}(k) & k > k_{\\mathrm{cut}} \\end{cases}\n$$\nThese two spectra, represented as vectors evaluated at the bin centers $k_i$, serve as the ground truth for our mock observations.\n\nThe effect of a survey window function must be modeled. In configuration space, the observed galaxy field is the true field multiplied by the window function $W(x)$. In Fourier space, this corresponds to the convolution of the true power spectrum with the window's power spectrum, or kernel. For a top-hat window of length $L$, the Fourier kernel is proportional to a squared sinc function. This convolution is approximated discretely by a mixing matrix $M$. The element $M_{ij}$ quantifies how much power from an input bin $k_j$ \"leaks\" into an output bin $k_i$. It is given by:\n$$\nM_{ij} \\propto \\mathrm{sinc}^2\\left(\\frac{L(k_i - k_j)}{2}\\right)\n$$\nwhere the sinc function is $\\mathrm{sinc}(x) = \\sin(x)/x$. The matrix $M$ is constructed such that each row sums to $1$ ($\\sum_j M_{ij} = 1$ for all $i$). This normalization ensures that a flat input spectrum remains flat after convolution, conserving power in a specific sense.\n\nWith these components, we construct the mock pseudo-bandpowers. These mimic what would be measured in a real survey. They are the window-convolved true power plus a constant shot noise term, $1/\\bar{n}_{\\mathrm{true}}$, determined by the true mean density of tracers:\n$$\n\\vec{P}_{\\mathrm{pseudo}}^{\\mathrm{full}} = M \\cdot \\vec{P}_{\\mathrm{true}} + \\frac{1}{\\bar{n}_{\\mathrm{true}}}\n$$\n$$\n\\vec{P}_{\\mathrm{pseudo}}^{\\mathrm{cut}} = M \\cdot \\vec{P}_{\\mathrm{cut}} + \\frac{1}{\\bar{n}_{\\mathrm{true}}}\n$$\nHere, $\\vec{P}_{\\mathrm{true}}$ and $\\vec{P}_{\\mathrm{cut}}$ are the vectors of power spectrum values at each $k_i$, and $M \\cdot \\vec{P}$ denotes matrix-vector multiplication.\n\nThe diagnostic relies on two quantities computed over a \"high-$k$\" region, defined as the top fraction $f_{\\mathrm{high}}$ of the wavenumber bins.\nThe first diagnostic is the effective shot-noise estimate, $S_{\\mathrm{eff}}$. It is the mean of the high-$k$ pseudo-bandpowers of the cut mock:\n$$\nS_{\\mathrm{eff}} = \\mathrm{mean}\\left( \\left(\\vec{P}_{\\mathrm{pseudo}}^{\\mathrm{cut}}\\right)_{\\mathrm{high-}k} \\right)\n$$\nBy using the cut mock, we have removed the primary source of leakage (power at $k \\le k_{\\mathrm{cut}}$). Thus, $S_{\\mathrm{eff}}$ represents the sum of the true shot noise and any residual power leaked from intermediate scales ($k > k_{\\mathrm{cut}}$) into the high-$k$ region.\n\nThe second diagnostic is the leakage metric, $L_{\\mathrm{metric}}$. It is the difference between the mean high-$k$ power in the full and cut mocks:\n$$\nL_{\\mathrm{metric}} = \\mathrm{mean}\\left( \\left(\\vec{P}_{\\mathrm{pseudo}}^{\\mathrm{full}}\\right)_{\\mathrm{high-}k} \\right) - \\mathrm{mean}\\left( \\left(\\vec{P}_{\\mathrm{pseudo}}^{\\mathrm{cut}}\\right)_{\\mathrm{high-}k} \\right)\n$$\nThis difference cancels out the common shot noise term and any leakage from $k > k_{\\mathrm{cut}}$, perfectly isolating the power that has leaked from large scales ($k \\le k_{\\mathrm{cut}}$) into the high-$k$ band.\n\nFinally, a classification is made based on these metrics. The assumed shot noise to be subtracted is $1/\\bar{n}_{\\mathrm{assumed}}$. The deviation from the effective shot noise is $1/\\bar{n}_{\\mathrm{assumed}} - S_{\\mathrm{eff}}$. We define a significance threshold $\\tau = 0.05 \\times (1/\\bar{n}_{\\mathrm{assumed}})$.\n- **Over-subtraction (Code $0$)**: This is declared if the shot noise discrepancy is significant while the leakage is not: $1/\\bar{n}_{\\mathrm{assumed}} - S_{\\mathrm{eff}} > \\tau$ AND $L_{\\mathrm{metric}} \\le \\tau$. This indicates that the negative bandpowers are primarily caused by subtracting too large a shot noise value.\n- **Window-induced leakage (Code $1$)**: This is declared if the leakage is significant while the shot noise discrepancy is small: $L_{\\mathrm{metric}} > \\tau$ AND $1/\\bar{n}_{\\mathrm{assumed}} - S_{\\mathrm{eff}} \\le \\tau$. This points to power from low-$k$ modes contaminating the high-$k$ bins as the main issue.\n- **Ambiguous (Code $2$)**: This category is for cases where both effects are significant ($L_{\\mathrm{metric}} > \\tau$ and $1/\\bar{n}_{\\mathrm{assumed}} - S_{\\mathrm{eff}} > \\tau$) or neither is significant ($L_{\\mathrm{metric}} \\le \\tau$ and $1/\\bar{n}_{\\mathrm{assumed}} - S_{\\mathrm{eff}} \\le \\tau$).\n\nThis principled, model-based approach provides a quantitative and automatable method for diagnosing the source of anomalies in cosmological power spectrum estimates.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef _run_diagnostic_case(params):\n    \"\"\"\n    Runs the diagnostic procedure for a single test case.\n\n    Args:\n        params (tuple): A tuple containing the parameters for the test case:\n            (N, L, A0, k0, n_true, n_assumed, k_cut, f_high).\n\n    Returns:\n        int: The classification code (0, 1, or 2).\n    \"\"\"\n    # Step 0: Unpack parameters\n    N, L, A0, k0, n_true, n_assumed, k_cut, f_high = params\n\n    # Step 1: Set up the wavenumber grid\n    # Assuming a fixed, reasonable k-range for all cases is sufficient for the diagnostic.\n    k_min, k_max = 0.0, 1.0\n    delta_k = (k_max - k_min) / N\n    # Bin centers\n    k_bins = k_min + (np.arange(N) + 0.5) * delta_k\n    \n    # Step 2: Define the underlying power spectra\n    P_true = A0 / (1.0 + (k_bins / k0)**2)\n    P_cut = np.where(k_bins <= k_cut, 0, P_true)\n\n    # Step 3: Construct the window convolution matrix M\n    # Create a matrix of wavenumber differences: k_diff[i, j] = k_bins[i] - k_bins[j]\n    k_diff_matrix = k_bins[:, np.newaxis] - k_bins[np.newaxis, :]\n    \n    # The argument for the sinc function is L * (ki - kj) / 2\n    # To use np.sinc(x) = sin(pi*x)/(pi*x), the argument should be x = arg / pi.\n    sinc_arg = L * k_diff_matrix / (2.0 * np.pi)\n    \n    # Unnormalized mixing matrix M_ij ~ sinc^2(L*(ki-kj)/2)\n    M_unnormalized = np.sinc(sinc_arg)**2\n    \n    # Normalize rows to sum to 1\n    row_sums = M_unnormalized.sum(axis=1, keepdims=True)\n    # Avoid division by zero, though unlikely as diagonal elements are 1 before normalization\n    row_sums[row_sums == 0] = 1.0\n    M = M_unnormalized / row_sums\n\n    # Step 4: Calculate convolved power spectra\n    P_conv_true = M @ P_true\n    P_conv_cut = M @ P_cut\n\n    # Step 5: Construct pseudo-bandpowers\n    shot_noise_true = 1.0 / n_true\n    P_pseudo_full = P_conv_true + shot_noise_true\n    P_pseudo_cut = P_conv_cut + shot_noise_true\n\n    # Step 6: Calculate diagnostic quantities\n    # Define high-k region indices\n    num_high_k_bins = int(N * f_high)\n    high_k_indices = slice(N - num_high_k_bins, N)\n\n    # Effective shot-noise estimate\n    S_eff = np.mean(P_pseudo_cut[high_k_indices])\n\n    # Leakage metric\n    # L_metric = mean(P_pseudo_full_high) - mean(P_pseudo_cut_high)\n    # This simplifies to mean over the convolution of the difference spectrum\n    P_diff = P_true - P_cut\n    P_conv_diff = M @ P_diff\n    L_metric = np.mean(P_conv_diff[high_k_indices])\n\n    # Step 7: Classify the case\n    shot_noise_assumed = 1.0 / n_assumed\n    tau = 0.05 * shot_noise_assumed\n\n    cond_oversub = (shot_noise_assumed - S_eff) > tau\n    cond_leakage = L_metric > tau\n\n    if cond_oversub and not cond_leakage:\n        return 0  # Over-subtraction\n    elif not cond_oversub and cond_leakage:\n        return 1  # Window-induced leakage\n    else:\n        # This covers (cond_oversub and cond_leakage) or (not cond_oversub and not cond_leakage)\n        return 2  # Ambiguous\n\ndef solve():\n    \"\"\"\n    Main function to run the diagnostic on the test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple: (N, L, A0, k0, n_true, n_assumed, k_cut, f_high)\n    test_cases = [\n        (256, 200.0, 1e-3, 0.05, 1000.0, 800.0, 0.03, 0.3),    # Case 1\n        (256, 20.0, 5e-3, 0.02, 1000.0, 1000.0, 0.03, 0.3),  # Case 2\n        (256, 20.0, 3e-3, 0.02, 1000.0, 900.0, 0.03, 0.3),    # Case 3\n        (256, 200.0, 1e-3, 0.05, 1000.0, 1000.0, 0.03, 0.3),  # Case 4\n    ]\n\n    results = []\n    for case in test_cases:\n        result = _run_diagnostic_case(case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3486487"}]}