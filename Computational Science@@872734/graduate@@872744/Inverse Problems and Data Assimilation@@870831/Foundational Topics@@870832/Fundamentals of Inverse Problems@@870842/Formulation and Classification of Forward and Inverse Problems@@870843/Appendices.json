{"hands_on_practices": [{"introduction": "Understanding the formulation of an inverse problem is incomplete without a way to quantify its inherent difficulty. This exercise introduces the condition number, a fundamental concept that measures the sensitivity of a problem's solution to perturbations in the data. By calculating the condition number from an operator's singular values, you will gain a concrete understanding of how it provides a worst-case bound on error amplification, explaining why even small measurement noise can render a naive solution useless for ill-conditioned problems [@problem_id:3382306].", "problem": "Consider a linear forward model $y = A x$ between finite-dimensional Hilbert spaces endowed with the Euclidean norm, where $A:\\mathbb{R}^{3}\\to\\mathbb{R}^{3}$ is a bounded, invertible linear operator. The corresponding inverse problem is to recover $x$ from noisy data $y^{\\delta} = y + \\eta$, with an unknown perturbation $\\eta$. The singular value decomposition (SVD) of $A$ has singular values $\\sigma_{1}$, $\\sigma_{2}$, and $\\sigma_{3}$, ordered so that $\\sigma_{1} \\ge \\sigma_{2} \\ge \\sigma_{3} > 0$. Suppose that for this operator one has $\\sigma_{1} = 18$, $\\sigma_{2} = 5$, and $\\sigma_{3} = 0.09$.\n\nUsing only core definitions from linear operator theory on Euclidean spaces, compute the condition number of the forward operator with respect to the Euclidean norm. Then, interpret its epistemic meaning for the reliability of solutions to the inverse problem in terms of worst-case amplification of data perturbations by the data-to-solution map. Your final reported result must be the computed condition number as a single real number without units. No rounding is necessary.", "solution": "The problem asks for two things: first, the computation of the condition number of a linear operator $A$, and second, an interpretation of its meaning in the context of an associated inverse problem. The operator $A$ maps from $\\mathbb{R}^{3}$ to $\\mathbb{R}^{3}$, which are finite-dimensional Hilbert spaces when endowed with the standard inner product and the induced Euclidean norm, denoted as $\\|\\cdot\\|$. The Euclidean norm is equivalent to the $L^2$ norm, so we will use the notation $\\|\\cdot\\|_2$.\n\nThe condition number of a linear operator $A$ with respect to a specific norm, denoted $\\kappa(A)$, is defined as the product of the norm of the operator and the norm of its inverse:\n$$\n\\kappa(A) = \\|A\\| \\|A^{-1}\\|\n$$\nThe problem specifies the use of the Euclidean norm. For a matrix or linear operator $A$, the induced $2$-norm, $\\|A\\|_2$, is defined as:\n$$\n\\|A\\|_2 = \\sup_{x \\neq 0} \\frac{\\|Ax\\|_2}{\\|x\\|_2}\n$$\nA fundamental result from linear algebra states that the $2$-norm of an operator $A$ is equal to its largest singular value, $\\sigma_{\\max}$. The singular values of $A$ are the square roots of the eigenvalues of the self-adjoint operator $A^*A$, where $A^*$ is the adjoint of $A$.\n\nThe problem provides the singular values of $A$ as $\\sigma_{1} = 18$, $\\sigma_{2} = 5$, and $\\sigma_{3} = 0.09$, ordered such that $\\sigma_{1} \\ge \\sigma_{2} \\ge \\sigma_{3} > 0$. Therefore, the largest singular value is $\\sigma_{\\max} = \\sigma_{1} = 18$.\nThe $2$-norm of the operator $A$ is thus:\n$$\n\\|A\\|_2 = \\sigma_{1} = 18\n$$\nNext, we must find the norm of the inverse operator, $\\|A^{-1}\\|_2$. The operator $A$ is stated to be invertible, which is consistent with the fact that all its singular values are strictly positive ($\\sigma_3 = 0.09 > 0$). If the singular values of $A$ are $\\sigma_i$, then the singular values of its inverse, $A^{-1}$, are $\\sigma_i^{-1}$.\nThe norm of the inverse operator, $\\|A^{-1}\\|_2$, is equal to the largest singular value of $A^{-1}$. Since the singular values of $A$ are ordered $\\sigma_1 \\ge \\sigma_2 \\ge \\sigma_3 > 0$, their reciprocals will be ordered as $\\sigma_3^{-1} \\ge \\sigma_2^{-1} \\ge \\sigma_1^{-1} > 0$.\nTherefore, the largest singular value of $A^{-1}$ is $\\sigma_3^{-1}$.\n$$\n\\|A^{-1}\\|_2 = \\sigma_{\\max}(A^{-1}) = (\\sigma_{\\min}(A))^{-1} = \\frac{1}{\\sigma_3} = \\frac{1}{0.09}\n$$\nWe can now compute the condition number with respect to the $2$-norm, $\\kappa_2(A)$:\n$$\n\\kappa_2(A) = \\|A\\|_2 \\|A^{-1}\\|_2 = \\sigma_{1} \\cdot \\frac{1}{\\sigma_{3}} = \\frac{\\sigma_{1}}{\\sigma_{3}}\n$$\nSubstituting the given values:\n$$\n\\kappa_2(A) = \\frac{18}{0.09} = \\frac{18}{\\frac{9}{100}} = 18 \\cdot \\frac{100}{9} = 2 \\cdot 100 = 200\n$$\n\nThe second part of the problem requires an interpretation of this result for the reliability of solutions to the inverse problem. The inverse problem is to find $x$ given noisy data $y^{\\delta}$. The \"true\" noise-free data is $y = Ax$, and the corresponding true solution is $x = A^{-1}y$. The measured data is $y^{\\delta} = y + \\eta$, where $\\eta$ is an unknown perturbation. A naive solution to the inverse problem would be to directly apply the inverse operator to the noisy data:\n$$\nx^{\\delta} = A^{-1}y^{\\delta} = A^{-1}(y + \\eta) = A^{-1}y + A^{-1}\\eta = x + A^{-1}\\eta\n$$\nThe error in the solution is $\\Delta x = x^{\\delta} - x = A^{-1}\\eta$. We are interested in how the relative error in the data, $\\frac{\\|\\eta\\|_2}{\\|y\\|_2}$, propagates to the relative error in the solution, $\\frac{\\|\\Delta x\\|_2}{\\|x\\|_2}$.\nWe have the following inequalities:\n$$\n\\|\\Delta x\\|_2 = \\|A^{-1}\\eta\\|_2 \\le \\|A^{-1}\\|_2 \\|\\eta\\|_2\n$$\nAnd from the forward model $y=Ax$:\n$$\n\\|y\\|_2 = \\|Ax\\|_2 \\le \\|A\\|_2 \\|x\\|_2 \\implies \\|x\\|_2 \\ge \\frac{\\|y\\|_2}{\\|A\\|_2}\n$$\nCombining these two inequalities, we can bound the relative error in the solution:\n$$\n\\frac{\\|\\Delta x\\|_2}{\\|x\\|_2} \\le \\frac{\\|A^{-1}\\|_2 \\|\\eta\\|_2}{\\frac{\\|y\\|_2}{\\|A\\|_2}} = \\|A\\|_2 \\|A^{-1}\\|_2 \\frac{\\|\\eta\\|_2}{\\|y\\|_2} = \\kappa_2(A) \\frac{\\|\\eta\\|_2}{\\|y\\|_2}\n$$\nThis inequality demonstrates the epistemic meaning of the condition number. It represents the worst-case amplification factor for the relative error. Specifically, the relative error in the computed solution can be up to $\\kappa_2(A)$ times the relative error in the measurement data.\nIn this case, $\\kappa_2(A) = 200$. This indicates that the inverse problem is ill-conditioned. A value of $200$ means that a small relative error in the data can be amplified by a factor of up to $200$ in the solution. For instance, if the measurement data $y^{\\delta}$ has a relative noise level of $1\\%$ (i.e., $\\frac{\\|\\eta\\|_2}{\\|y\\|_2} = 0.01$), the relative error in the solution $\\frac{\\|\\Delta x\\|_2}{\\|x\\|_2}$ could be as large as $200 \\times 0.01 = 2$, which corresponds to a $200\\%$ error. This signifies that the naive solution $x^{\\delta} = A^{-1}y^{\\delta}$ is highly unreliable and potentially meaningless, as the error can be larger than the solution itself. Such a high condition number necessitates the use of regularization techniques to obtain a stable and meaningful approximate solution to the inverse problem.", "answer": "$$\\boxed{200}$$", "id": "3382306"}, {"introduction": "While the condition number gives a global measure of instability, the Discrete Picard Condition offers a more refined diagnostic tool to analyze specific measurement data. This practice demonstrates how to inspect the components of your data in the basis of the forward operator's singular vectors. By comparing the decay rate of the data coefficients $|u_i^\\top y|$ to the decay of the singular values $\\sigma_i$, you can identify the point at which information from the true signal is drowned out by noise, making it clear why regularization is a necessity, not just an option [@problem_id:3382319].", "problem": "Consider a linear forward model $y = A x_{\\text{true}} + e$ where $A \\in \\mathbb{R}^{m \\times n}$ is a compact operator arising from a linearized observation operator in data assimilation, $x_{\\text{true}} \\in \\mathbb{R}^{n}$ is the unknown state, $y \\in \\mathbb{R}^{m}$ is the data, and $e \\in \\mathbb{R}^{m}$ is additive measurement noise. Let $A = U \\Sigma V^\\top$ denote the Singular Value Decomposition (SVD), with singular values $\\sigma_1 \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_r > 0$ where $r = \\operatorname{rank}(A)$, and left and right singular vectors $\\{u_i\\}_{i=1}^r$ and $\\{v_i\\}_{i=1}^r$.\n\nSuppose $m = n = 200$ and the singular values of $A$ are known to follow a polynomial decay $\\sigma_i \\approx i^{-2}$ for $i = 1,2,\\ldots,200$. A measurement campaign produces $y$ such that the empirical coefficients $|u_i^\\top y|$ satisfy the following behavior:\n- For $1 \\le i \\le 30$, $|u_i^\\top y| \\approx 0.5\\, i^{-3}$.\n- For $31 \\le i \\le 200$, $|u_i^\\top y| \\approx 2 \\times 10^{-5}$ (a noise floor, independent of $i$ within the measurement precision).\n\nYou are asked to assess the Picard condition by comparing the decay of $|u_i^\\top y|$ with the decay of $\\sigma_i$, and from this comparison deduce whether solving the naive least squares (LS) problem $\\min_x \\|A x - y\\|_2^2$ without regularization is feasible in the sense of producing a stable estimate of $x_{\\text{true}}$ from the noisy data.\n\nWhich of the following statements is most accurate?\n\nA. The Picard condition holds for all $i$ because $|u_i^\\top y|$ decays faster than $\\sigma_i$, so naive LS without regularization yields a stable solution.\n\nB. The Picard condition holds only for the low-index range where the data coefficients decay ($i \\le 30$), but is violated in the noise-dominated tail ($i \\ge 31$) where $|u_i^\\top y|$ stops decaying relative to $\\sigma_i$; consequently, naive LS amplifies noise and is not feasible without regularization.\n\nC. The Picard condition compares $|u_i^\\top y|$ to $\\sigma_i^2$, and because $|u_i^\\top y|$ decays faster than $\\sigma_i^2$, naive LS is stable.\n\nD. The decay of $|u_i^\\top y|$ is irrelevant to stability; feasibility of naive LS depends only on the behavior of $|v_i^\\top x_{\\text{true}}|$, so naive LS is feasible in this setting.", "solution": "We begin by recalling the formal solution to the linear least squares problem $\\min_x \\|A x - y\\|_2^2$. For a matrix $A$ with Singular Value Decomposition (SVD) $A = U \\Sigma V^\\top$, where $U$ and $V$ are orthogonal matrices and $\\Sigma$ is a diagonal matrix of singular values $\\sigma_i$, the solution is given by $x_{\\text{LS}} = A^{\\dagger}y$, where $A^{\\dagger} = V \\Sigma^{\\dagger} U^\\top$ is the Moore-Penrose pseudoinverse. Since the problem specifies $m = n = 200$ and provides singular values for all $i$ from $1$ to $200$, we assume the matrix $A$ has full rank, so $A^{\\dagger} = A^{-1} = V \\Sigma^{-1} U^\\top$.\n\nThe solution can be written as a sum over the singular components:\n$$\nx_{\\text{LS}} = \\sum_{i=1}^{n} \\frac{u_i^\\top y}{\\sigma_i} v_i\n$$\nwhere $\\{u_i\\}$ and $\\{v_i\\}$ are the columns of $U$ and $V$ respectively (the left and right singular vectors).\n\nThe data $y$ is given by $y = A x_{\\text{true}} + e$, where $x_{\\text{true}}$ is the true unknown state and $e$ is measurement noise. Substituting this into the solution formula yields:\n$$\nx_{\\text{LS}} = \\sum_{i=1}^{n} \\frac{u_i^\\top (A x_{\\text{true}} + e)}{\\sigma_i} v_i\n$$\nWe can split this into two parts. The first part involves the true signal:\n$u_i^\\top A x_{\\text{true}} = u_i^\\top (U \\Sigma V^\\top) x_{\\text{true}} = (\\text{row } i \\text{ of } U^\\top)(U \\Sigma V^\\top) x_{\\text{true}} = e_i^\\top \\Sigma V^\\top x_{\\text{true}} = \\sigma_i v_i^\\top x_{\\text{true}}$.\nHere, $e_i$ is the $i$-th standard basis vector.\nThe second part is the projection of the noise: $u_i^\\top e$.\nThus, the solution becomes:\n$$\nx_{\\text{LS}} = \\sum_{i=1}^{n} \\frac{\\sigma_i v_i^\\top x_{\\text{true}} + u_i^\\top e}{\\sigma_i} v_i = \\sum_{i=1}^{n} (v_i^\\top x_{\\text{true}}) v_i + \\sum_{i=1}^{n} \\frac{u_i^\\top e}{\\sigma_i} v_i\n$$\nThe first summation, $\\sum_{i=1}^{n} (v_i^\\top x_{\\text{true}}) v_i$, is the projection of $x_{\\text{true}}$ onto the basis $\\{v_i\\}$, which reconstructs $x_{\\text{true}}$ itself. Therefore:\n$$\nx_{\\text{LS}} = x_{\\text{true}} + \\sum_{i=1}^{n} \\frac{u_i^\\top e}{\\sigma_i} v_i\n$$\nThe stability of the solution is determined by the magnitude of the error term, $\\sum_{i=1}^{n} \\frac{u_i^\\top e}{\\sigma_i} v_i$. The problem is ill-posed because the singular values $\\sigma_i$ decay to zero. If the noise coefficients $u_i^\\top e$ do not decay at least as fast, the ratio $\\frac{u_i^\\top e}{\\sigma_i}$ will be large for large $i$, leading to the amplification of noise and an unstable solution.\n\nThe Discrete Picard Condition provides a practical way to diagnose this instability. It requires that for a stable reconstruction, the coefficients $|u_i^\\top y|$ must decay faster than the singular values $\\sigma_i$. If this condition is violated, it indicates that the noise component $u_i^\\top e$ is dominating the signal component $\\sigma_i v_i^\\top x_{\\text{true}}$, and the division by the small $\\sigma_i$ will amplify this noise.\n\nLet's analyze the given data with this condition in mind:\nGiven: $\\sigma_i \\approx i^{-2}$.\n\nCase 1: $1 \\le i \\le 30$\nWe have $|u_i^\\top y| \\approx 0.5\\, i^{-3}$.\nLet's examine the ratio that appears in the solution sum:\n$$\n\\frac{|u_i^\\top y|}{\\sigma_i} \\approx \\frac{0.5\\, i^{-3}}{i^{-2}} = 0.5\\, i^{-1}\n$$\nIn this range of indices, the ratio decays. The coefficients of the solution expansion are well-behaved. This suggests that for $i \\le 30$, the data is dominated by the true signal, and the Picard condition is satisfied.\n\nCase 2: $31 \\le i \\le 200$\nWe have $|u_i^\\top y| \\approx 2 \\times 10^{-5}$, which is a constant noise floor.\nNow, the ratio becomes:\n$$\n\\frac{|u_i^\\top y|}{\\sigma_i} \\approx \\frac{2 \\times 10^{-5}}{i^{-2}} = (2 \\times 10^{-5}) i^2\n$$\nIn this range, the ratio *grows* quadratically with $i$. This is a clear violation of the Picard condition. The constant value of $|u_i^\\top y|$ indicates that any underlying signal component has fallen below the noise level, so $|u_i^\\top y| \\approx |u_i^\\top e|$. The division by the rapidly decaying $\\sigma_i$ will cause extreme amplification of these noise components in the solution $x_{\\text{LS}}$.\n\nConsequently, the naive least squares solution, which sums over all $i$ up to $200$, will be dominated by large, erroneous, high-frequency components coming from the $i \\ge 31$ terms. This makes the solution highly unstable and physically meaningless. Regularization techniques (such as Truncated SVD, where one would cut off the sum at $i \\approx 30$) are required to obtain a stable and meaningful estimate of $x_{\\text{true}}$.\n\nNow we evaluate the given options:\n\nA. The Picard condition holds for all $i$ because $|u_i^\\top y|$ decays faster than $\\sigma_i$, so naive LS without regularization yields a stable solution.\nThis is **Incorrect**. The statement that $|u_i^\\top y|$ decays faster than $\\sigma_i$ is only true for $i \\le 30$. For $i \\ge 31$, $|u_i^\\top y|$ is approximately constant, hence decaying much slower than $\\sigma_i$. The conclusion that naive LS is stable is false.\n\nB. The Picard condition holds only for the low-index range where the data coefficients decay ($i \\le 30$), but is violated in the noise-dominated tail ($i \\ge 31$) where $|u_i^\\top y|$ stops decaying relative to $\\sigma_i$; consequently, naive LS amplifies noise and is not feasible without regularization.\nThis is **Correct**. This statement accurately describes the situation derived from our analysis. It correctly identifies the two regimes, correctly assesses the Picard condition in each, and draws the correct conclusion about the feasibility of the naive LS solution.\n\nC. The Picard condition compares $|u_i^\\top y|$ to $\\sigma_i^2$, and because $|u_i^\\top y|$ decays faster than $\\sigma_i^2$, naive LS is stable.\nThis is **Incorrect**. The stability of the LS solution $x_{\\text{LS}} = \\sum (u_i^\\top y / \\sigma_i) v_i$ depends on the behavior of the coefficients $u_i^\\top y / \\sigma_i$. Thus, the relevant comparison is between $|u_i^\\top y|$ and $\\sigma_i$, not $\\sigma_i^2$. The fundamental premise of the comparison is wrong.\n\nD. The decay of $|u_i^\\top y|$ is irrelevant to stability; feasibility of naive LS depends only on the behavior of $|v_i^\\top x_{\\text{true}}|$, so naive LS is feasible in this setting.\nThis is **Incorrect**. The stability of the solution computed from noisy data $y$ is critically dependent on the properties of $y$, which includes the noise $e$. As shown in the derivation of the error term, the instability arises directly from the amplification of noise coefficients $u_i^\\top e$, which are a component of $u_i^\\top y$. Claiming that the decay of $|u_i^\\top y|$ is irrelevant is a fundamental misunderstanding of how noise affects inverse problems. While the properties of $x_{\\text{true}}$ (reflected in $|v_i^\\top x_{\\text{true}}|$) determine the signal component, it is the interplay between signal, noise, and the operator's singular values that dictates stability.", "answer": "$$\\boxed{B}$$", "id": "3382319"}, {"introduction": "Moving from analytical understanding to computational practice introduces new challenges, chief among them the risk of flawed validation. This exercise addresses the \"inverse crime,\" a critical methodological pitfall where the same numerical model used for inversion is also used to generate synthetic test data. By reasoning through different validation protocols, you will learn to distinguish between naive setups that produce misleadingly optimistic results and robust procedures that realistically account for model error, a crucial skill for developing and testing reliable inversion algorithms [@problem_id:3382288].", "problem": "Consider a forward problem in which a physical law, for example a Partial Differential Equation (PDE), maps an unknown parameter field $u$ to a state $s(u)$, and an observation operator $H$ extracts predicted measurements $y_{\\text{pred}} = H s(u)$. Define the forward map $\\mathcal{F}(u) = H s(u)$, so that data acquisition is modeled as $y = \\mathcal{F}(u) + \\eta$, where $\\eta$ denotes observational noise. Inverse problems seek to infer $u$ from $y$. In practice, both data generation and inversion use discrete numerical approximations of $\\mathcal{F}$ with mesh size $h$ and solver order $p$, for example the Finite Element Method (FEM), Discontinuous Galerkin (DG), or Finite Volume (FV). Let $\\mathcal{F}^{\\dagger}$ denote the high-fidelity map used to synthesize “truth” data, and let $\\mathcal{F}$ denote the map used inside the inversion; these maps may differ due to discretization choices or solver families. A common practice in algorithm testing is to generate synthetic data $y^{\\dagger} = \\mathcal{F}^{\\dagger}(u^{\\dagger}) + \\eta$ using a known “ground-truth” parameter $u^{\\dagger}$ and then solve the inverse problem with the same or different forward map $\\mathcal{F}$.\n\nStarting from the definitions above and the foundational notions of well-posedness (existence, uniqueness, and stability) and model–data consistency, reason about the consequences of choosing $\\mathcal{F}^{\\dagger} = \\mathcal{F}$ with identical discretizations. Identify which options correctly explain the “inverse crime” and propose a scientifically sound validation protocol that separates the meshes or solvers used for synthetic data generation and inversion to avoid optimistic error estimates. Your selection should reflect how discretization mismatch, model discrepancy, and realistic noise affect identifiability, residual structure, and posterior or regularized estimates.\n\nChoose all options that are correct.\n\nA. Generate synthetic data $y^{\\dagger} = \\mathcal{F}^{\\dagger}(u^{\\dagger}) + \\eta$ with a higher-fidelity forward map (e.g., $h_{\\text{gen}} < h_{\\text{inv}}$ or $p_{\\text{gen}} > p_{\\text{inv}}$), then perform inversion with a lower-fidelity map $\\mathcal{F}$ on a distinct mesh and possibly a different solver family, while injecting realistic noise $\\eta \\sim \\mathcal{N}(0,\\Gamma)$ calibrated to the sensing process. Validate by out-of-sample predictive checks: simulate $y_{\\text{test}} = \\mathcal{F}^{\\dagger}(u_{\\text{est}}) + \\tilde{\\eta}$ on fresh conditions and quantify misfit distribution and uncertainty. This protocol avoids the inverse crime by ensuring $\\mathcal{F}^{\\dagger} \\neq \\mathcal{F}$ and $h_{\\text{gen}} \\neq h_{\\text{inv}}$.\n\nB. To eliminate approximation bias, use the identical solver, polynomial order, and mesh ($\\mathcal{F}^{\\dagger} = \\mathcal{F}$, $h_{\\text{gen}} = h_{\\text{inv}}$, $p_{\\text{gen}} = p_{\\text{inv}}$) to both generate data and invert, and set $\\eta = 0$, arguing that this isolates algorithmic performance. This practice prevents inverse crime because any error then reflects only the inversion routine.\n\nC. Use different meshes ($h_{\\text{gen}} \\neq h_{\\text{inv}}$) but enforce zero noise $\\eta = 0$ and tune boundary conditions so that $u^{\\dagger}$ yields an exact solution in both discretizations. Report reconstruction error from a single realization $y^{\\dagger}$. This avoids inverse crime because mesh separation alone ensures realistic assessment.\n\nD. Implement a solver-split protocol: generate $y^{\\dagger}$ with Discontinuous Galerkin on a fine mesh ($p_{\\text{gen}}$ high, $h_{\\text{gen}}$ small), invert with Finite Volume or Finite Element on a coarser mesh ($p_{\\text{inv}}$ lower, $h_{\\text{inv}}$ larger), and include a structured model-discrepancy term $\\delta(x)$ in the likelihood, treating $y = \\mathcal{F}(u) + \\delta + \\eta$ with a prior on $\\delta$ to capture operator mismatch. Validate via cross-configuration tests and mesh refinement studies to check robustness. This explicitly avoids inverse crime by decoupling $\\mathcal{F}^{\\dagger}$ and $\\mathcal{F}$ and accounting for discrepancy.\n\nE. Split sensors into “training” and “test” subsets while keeping $\\mathcal{F}^{\\dagger} = \\mathcal{F}$, $h_{\\text{gen}} = h_{\\text{inv}}$, and $p_{\\text{gen}} = p_{\\text{inv}}$. If the reconstruction fits the training sensors well but not the test sensors, conclude that inverse crime has been avoided because the test split provides an unbiased error estimate.\n\nSelect all correct options.", "solution": "The problem asks for an analysis of the \"inverse crime\" in the context of numerical inverse problems and to identify sound protocols for its avoidance.\n\nFirst, let us formalize the concepts presented. The forward problem is described by a map $\\mathcal{F}$, which takes a parameter field $u$ and produces predicted data $y_{\\text{pred}} = \\mathcal{F}(u)$. In a real-world experiment, we measure data $y_{obs}$, which are related to some true, unknown parameter field $u_{true}$ by $y_{obs} = \\mathcal{F}_{true}(u_{true}) + \\eta$, where $\\mathcal{F}_{true}$ represents the true physical process and $\\eta$ is measurement noise.\n\nIn computational practice, we cannot work with $\\mathcal{F}_{true}$. We use a numerical model $\\mathcal{F}$ (e.g., a PDE solver on a discrete mesh) to approximate it. The goal of the inverse problem is to find an estimate of $u_{true}$, let's call it $u_{est}$, by fitting the model predictions $\\mathcal{F}(u)$ to the observed data $y_{obs}$. A typical approach is to solve an optimization problem, such as Tikhonov regularization:\n$$u_{est} = \\arg\\min_{u} \\| \\mathcal{F}(u) - y_{obs} \\|^2 + \\alpha \\| L(u) \\|^2$$\nwhere $\\alpha > 0$ is a regularization parameter and $L$ is a regularization operator.\n\nWhen testing inversion algorithms, real data $y_{obs}$ and the corresponding $u_{true}$ are often unavailable. Therefore, we resort to using synthetic data. This is where the \"inverse crime\" can be committed.\n\nThe **inverse crime** is the practice of generating synthetic data $y^{\\dagger}$ using the *exact same* numerical model $\\mathcal{F}$ that will be used for the inversion. That is, we set the \"truth\" model $\\mathcal{F}^{\\dagger}$ to be identical to the inversion model $\\mathcal{F}$. The synthetic data is generated as $y^{\\dagger} = \\mathcal{F}(u^{\\dagger}) + \\eta$ for some known ground-truth parameter $u^{\\dagger}$.\n\nThe fundamental flaw in this practice is that it artificially eliminates **model error**, which is the discrepancy between the true physics and the numerical approximation, i.e., $\\mathcal{F}_{true}(u) \\neq \\mathcal{F}(u)$. By setting $\\mathcal{F}^{\\dagger} = \\mathcal{F}$, the data $y^{\\dagger}$ (ignoring noise for a moment) lies perfectly in the range of the forward operator used for inversion: $y^{\\dagger} \\in \\text{range}(\\mathcal{F})$. In this scenario, the inverse problem can, in principle, be solved perfectly by finding $u=u^{\\dagger}$. Any remaining error is attributed solely to the inversion algorithm's imperfections (e.g., failure to converge, finding a local minimum) or the effect of the noise $\\eta$. This leads to a gross underestimation of the error that would be encountered in a real-world application, where model error is unavoidable and often a dominant source of uncertainty. A robust inversion method must be ableto handle data that is inconsistent with the forward model $\\mathcal{F}$.\n\nA scientifically sound validation protocol must therefore ensure that $\\mathcal{F}^{\\dagger} \\neq \\mathcal{F}$, thereby introducing a realistic level of model error into the test. This difference can be achieved by using different discretizations (mesh size $h$, polynomial order $p$), or even entirely different numerical methods (e.g., Finite Element vs. Finite Volume).\n\nWith this foundation, let us evaluate the given options.\n\n**A. Generate synthetic data $y^{\\dagger} = \\mathcal{F}^{\\dagger}(u^{\\dagger}) + \\eta$ with a higher-fidelity forward map (e.g., $h_{\\text{gen}} < h_{\\text{inv}}$ or $p_{\\text{gen}} > p_{\\text{inv}}$), then perform inversion with a lower-fidelity map $\\mathcal{F}$ on a distinct mesh and possibly a different solver family, while injecting realistic noise $\\eta \\sim \\mathcal{N}(0,\\Gamma)$ calibrated to the sensing process. Validate by out-of-sample predictive checks: simulate $y_{\\text{test}} = \\mathcal{F}^{\\dagger}(u_{\\text{est}}) + \\tilde{\\eta}$ on fresh conditions and quantify misfit distribution and uncertainty. This protocol avoids the inverse crime by ensuring $\\mathcal{F}^{\\dagger} \\neq \\mathcal{F}$ and $h_{\\text{gen}} \\neq h_{\\text{inv}}$.**\n\nThis option describes a state-of-the-art, scientifically robust validation protocol.\n1.  **Avoiding the Inverse Crime**: It explicitly states that the data-generating map $\\mathcal{F}^{\\dagger}$ is different from and of higher fidelity than the inversion map $\\mathcal{F}$ ($h_{\\text{gen}} < h_{\\text{inv}}$ or $p_{\\text{gen}} > p_{\\text{inv}}$). This ensures that the synthetic data $y^{\\dagger}$ does not perfectly lie in the range of the inversion operator $\\mathcal{F}$, thus introducing realistic model-discretization error.\n2.  **Realistic Noise**: It includes realistic, calibrated noise $\\eta \\sim \\mathcal{N}(0, \\Gamma)$, which is essential for testing the algorithm's performance under uncertainty.\n3.  **Robust Validation**: It goes beyond simple reconstruction error and proposes out-of-sample predictive checks. This tests the generalization capability of the estimated model $u_{est}$, which is a much stronger form of validation.\nThe reasoning provided is entirely correct.\n**Verdict: Correct**\n\n**B. To eliminate approximation bias, use the identical solver, polynomial order, and mesh ($\\mathcal{F}^{\\dagger} = \\mathcal{F}$, $h_{\\text{gen}} = h_{\\text{inv}}$, $p_{\\text{gen}} = p_{\\text{inv}}$) to both generate data and invert, and set $\\eta = 0$, arguing that this isolates algorithmic performance. This practice prevents inverse crime because any error then reflects only the inversion routine.**\n\nThis option describes the quintessential \"inverse crime\". Setting $\\mathcal{F}^{\\dagger} = \\mathcal{F}$ and $\\eta = 0$ creates a perfectly idealized scenario where the data $y^{\\dagger} = \\mathcal{F}(u^{\\dagger})$ is perfectly achievable by the inversion model. The argument that this \"isolates algorithmic performance\" is precisely the misleading justification for this flawed practice. It tests the algorithm in a scenario that has no model error, which is never the case in reality. The statement that this \"prevents inverse crime\" is a direct contradiction of the term's definition.\n**Verdict: Incorrect**\n\n**C. Use different meshes ($h_{\\text{gen}} \\neq h_{\\text{inv}}$) but enforce zero noise $\\eta = 0$ and tune boundary conditions so that $u^{\\dagger}$ yields an exact solution in both discretizations. Report reconstruction error from a single realization $y^{\\dagger}$. This avoids inverse crime because mesh separation alone ensures realistic assessment.**\n\nThis option is subtly flawed. While using different meshes ($h_{\\text{gen}} \\neq h_{\\text{inv}}$) is a necessary step to avoid the inverse crime, the additional constraint that \"$u^{\\dagger}$ yields an exact solution in both discretizations\" completely undermines this step. This happens, for instance, if the true solution is a low-degree polynomial that can be represented exactly by both the coarse and fine finite element spaces. In this case, for the specific ground truth $u^{\\dagger}$, the discretization error is artificially zero. Therefore, $\\mathcal{F}^{\\dagger}(u^{\\dagger}) = \\mathcal{F}(u^{\\dagger})$, and we are back to a situation analogous to the inverse crime, even with different meshes. The claim that \"mesh separation alone ensures realistic assessment\" is false under this contrived setup. Furthermore, setting $\\eta=0$ makes the test less realistic.\n**Verdict: Incorrect**\n\n**D. Implement a solver-split protocol: generate $y^{\\dagger}$ with Discontinuous Galerkin on a fine mesh ($p_{\\text{gen}}$ high, $h_{\\text{gen}}$ small), invert with Finite Volume or Finite Element on a coarser mesh ($p_{\\text{inv}}$ lower, $h_{\\text{inv}}$ larger), and include a structured model-discrepancy term $\\delta(x)$ in the likelihood, treating $y = \\mathcal{F}(u) + \\delta + \\eta$ with a prior on $\\delta$ to capture operator mismatch. Validate via cross-configuration tests and mesh refinement studies to check robustness. This explicitly avoids inverse crime by decoupling $\\mathcal{F}^{\\dagger}$ and $\\mathcal{F}$ and accounting for discrepancy.**\n\nThis describes an advanced and highly principled approach.\n1.  **Decoupling Models**: It avoids the inverse crime by using not only different meshes ($h_{\\text{gen}}$ vs. $h_{\\text{inv}}$) and orders ($p_{\\text{gen}}$ vs. $p_{\\text{inv}}$) but also different solver families (DG vs. FV/FEM). This ensures a significant and realistic discrepancy between $\\mathcal{F}^{\\dagger}$ and $\\mathcal{F}$.\n2.  **Explicit Discrepancy Modeling**: It goes a step further than option A by explicitly including a model discrepancy term $\\delta$ in the statistical model. This is a very sophisticated way to handle the fact that the model $\\mathcal{F}$ is known to be imperfect. By placing a prior on $\\delta$, this approach allows for the quantification of model uncertainty itself.\n3.  **Robust Validation**: The mention of cross-configuration tests and mesh refinement studies points to a thorough verification process.\nThis protocol represents a best practice for assessing inverse problem methodologies.\n**Verdict: Correct**\n\n**E. Split sensors into “training” and “test” subsets while keeping $\\mathcal{F}^{\\dagger} = \\mathcal{F}$, $h_{\\text{gen}} = h_{\\text{inv}}$, and $p_{\\text{gen}} = p_{\\text{inv}}$. If the reconstruction fits the training sensors well but not the test sensors, conclude that inverse crime has been avoided because the test split provides an unbiased error estimate.**\n\nThis option is fundamentally misguided. It commits the inverse crime by using $\\mathcal{F}^{\\dagger} = \\mathcal{F}$. Splitting sensors into training and test sets is a form of cross-validation, which is useful for guarding against overfitting to *observational noise* and assessing generalization across the spatial domain. However, it does absolutely nothing to address *model error*. Since the data at both training and test locations are generated by the same model $\\mathcal{F}$, a good reconstruction $u_{est} \\approx u^{\\dagger}$ will necessarily yield predictions $\\mathcal{F}(u_{est})$ that fit the data well at *all* sensor locations, including the test set (up to noise $\\eta$). A significant discrepancy between training and test fit would likely indicate an issue with the inversion algorithm (e.g., extreme overfitting) rather than a successful avoidance of the inverse crime. The premise that this procedure avoids the inverse crime is false.\n**Verdict: Incorrect**", "answer": "$$\\boxed{AD}$$", "id": "3382288"}]}