{"hands_on_practices": [{"introduction": "The core of any trust-region algorithm is its adaptive control mechanism. This mechanism determines whether a computed trial step is 'good enough' and how to adjust the size of the trusted region for the next iteration. This first practice [@problem_id:3428714] isolates this fundamental decision-making process, allowing you to apply the rules governing step acceptance and radius updates based on the all-important trust-region ratio, $\\rho_{k}$.", "problem": "Consider a regularized nonlinear inverse problem in data assimilation with objective function $J(x)$ representing a weighted least-squares misfit plus Tikhonov-type regularization. At iteration $k$ of a Gauss–Newton (GN) trust-region method, a quadratic model $m_{k}(s)$ is constructed and a step $s_{k}$ is computed subject to the trust-region constraint $\\|s\\| \\leq \\Delta_{k}$. In the standard trust-region framework, the step acceptance and the subsequent update of the trust-region radius are governed by the trust-region ratio $\\rho_{k}$ together with two thresholds $\\eta_{1}$ and $\\eta_{2}$ and scaling parameters. Assume the following update policy is used:\n- If $\\rho_{k}  \\eta_{1}$, the step is rejected and $\\Delta_{k+1} = \\gamma_{\\mathrm{dec}} \\,\\Delta_{k}$.\n- If $\\eta_{1} \\leq \\rho_{k} \\leq \\eta_{2}$, the step is accepted and $\\Delta_{k+1} = \\Delta_{k}$.\n- If $\\rho_{k}  \\eta_{2}$, the step is accepted and $\\Delta_{k+1} = \\min\\{\\gamma_{\\mathrm{inc}} \\,\\Delta_{k}, \\Delta_{\\max}\\}$.\n\nYou are given the following iteration data:\n- Predicted reduction $m_{k}(0) - m_{k}(s_{k}) = 0.2$.\n- Actual reduction $J(x_{k}) - J(x_{k} + s_{k}) = 0.15$.\n- Thresholds $\\eta_{1} = 0.25$ and $\\eta_{2} = 0.75$.\n- Current trust-region radius $\\Delta_{k} = 1.2$.\n- Scaling parameters $\\gamma_{\\mathrm{dec}} = 0.5$, $\\gamma_{\\mathrm{inc}} = 1.5$, and maximum radius $\\Delta_{\\max} = 10$.\n\nUsing the standard definition of the trust-region ratio $\\rho_{k}$ and the update policy above, compute the value of $\\rho_{k}$ and the updated trust-region radius $\\Delta_{k+1}$. Express your final result as exact values; no rounding is required. Provide your final answer as a two-entry row matrix containing $\\rho_{k}$ and $\\Delta_{k+1}$, in that order.", "solution": "The user has provided a problem concerning the update of the trust-region radius in a trust-region optimization method. I will begin by validating the problem statement.\n\n### Step 1: Extract Givens\nThe problem provides the following information and definitions for a trust-region method at iteration $k$:\n- Objective function: $J(x)$\n- Quadratic model of the objective function change: $m_{k}(s)$\n- Step computed at iteration $k$: $s_{k}$\n- Trust-region constraint: $\\|s\\| \\leq \\Delta_{k}$\n- The trust-region ratio: $\\rho_{k}$\n- Threshold parameters: $\\eta_{1}$ and $\\eta_{2}$\n- Radius scaling parameters: $\\gamma_{\\mathrm{dec}}$, $\\gamma_{\\mathrm{inc}}$, $\\Delta_{\\max}$\n\nThe update policy for the trust-region radius $\\Delta_{k+1}$ is given as:\n1.  If $\\rho_{k}  \\eta_{1}$: The step is rejected, and $\\Delta_{k+1} = \\gamma_{\\mathrm{dec}} \\,\\Delta_{k}$.\n2.  If $\\eta_{1} \\leq \\rho_{k} \\leq \\eta_{2}$: The step is accepted, and $\\Delta_{k+1} = \\Delta_{k}$.\n3.  If $\\rho_{k}  \\eta_{2}$: The step is accepted, and $\\Delta_{k+1} = \\min\\{\\gamma_{\\mathrm{inc}} \\,\\Delta_{k}, \\Delta_{\\max}\\}$.\n\nThe specific numerical values for the current iteration $k$ are:\n- Predicted reduction in the model: $m_{k}(0) - m_{k}(s_{k}) = 0.2$\n- Actual reduction in the objective function: $J(x_{k}) - J(x_{k} + s_{k}) = 0.15$\n- Thresholds: $\\eta_{1} = 0.25$ and $\\eta_{2} = 0.75$\n- Current trust-region radius: $\\Delta_{k} = 1.2$\n- Scaling parameters: $\\gamma_{\\mathrm{dec}} = 0.5$, $\\gamma_{\\mathrm{inc}} = 1.5$, and $\\Delta_{\\max} = 10$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is well-posed, scientifically grounded, and internally consistent. It describes a standard algorithm from the field of numerical optimization, specifically the trust-region method, which is widely used for solving nonlinear least-squares and inverse problems. All necessary data and definitions are provided to compute the requested quantities. The values are numerically plausible. There are no contradictions, ambiguities, or violations of scientific principles. The problem is a straightforward application of the definitions and rules of the trust-region framework.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. I will proceed with the solution.\n\n### Solution\nThe task is to compute the trust-region ratio $\\rho_{k}$ and the updated trust-region radius $\\Delta_{k+1}$ based on the provided data and update policy.\n\nFirst, we compute the trust-region ratio $\\rho_{k}$. The standard definition of this ratio is the actual reduction in the objective function divided by the predicted reduction from the quadratic model.\n$$\n\\rho_{k} = \\frac{\\text{Actual Reduction}}{\\text{Predicted Reduction}} = \\frac{J(x_{k}) - J(x_{k} + s_{k})}{m_{k}(0) - m_{k}(s_{k})}\n$$\nUsing the given values:\n- Actual Reduction = $0.15$\n- Predicted Reduction = $0.2$\n\nWe can substitute these values into the formula for $\\rho_{k}$:\n$$\n\\rho_{k} = \\frac{0.15}{0.2} = \\frac{15}{20} = \\frac{3}{4}\n$$\nSo, the value of the trust-region ratio is $\\rho_{k} = 0.75$.\n\nNext, we must determine the update rule for the trust-region radius $\\Delta_{k+1}$. This requires comparing $\\rho_{k}$ with the given thresholds $\\eta_{1} = 0.25$ and $\\eta_{2} = 0.75$.\nWe have $\\rho_{k} = 0.75$. Let us check the three cases of the update policy:\n1.  Is $\\rho_{k}  \\eta_{1}$? This corresponds to $0.75  0.25$, which is false.\n2.  Is $\\eta_{1} \\leq \\rho_{k} \\leq \\eta_{2}$? This corresponds to $0.25 \\leq 0.75 \\leq 0.75$. This statement is true.\n3.  Is $\\rho_{k}  \\eta_{2}$? This corresponds to $0.75  0.75$, which is false.\n\nSince the second condition is met ($\\eta_{1} \\leq \\rho_{k} \\leq \\eta_{2}$), the corresponding update rule is applied. According to the problem statement, for this case, the step $s_{k}$ is accepted and the trust-region radius is not changed.\n$$\n\\Delta_{k+1} = \\Delta_{k}\n$$\nThe problem specifies that the current trust-region radius is $\\Delta_{k} = 1.2$. Therefore, the updated radius is:\n$$\n\\Delta_{k+1} = 1.2\n$$\nTo express the results as exact fractions, we have $\\rho_{k} = \\frac{3}{4}$ and $\\Delta_{k+1} = 1.2 = \\frac{12}{10} = \\frac{6}{5}$.\n\nThe two computed values are $\\rho_{k} = \\frac{3}{4}$ and $\\Delta_{k+1} = \\frac{6}{5}$. The final answer should be presented as a two-entry row matrix containing these values in order.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{3}{4}  \\frac{6}{5} \\end{pmatrix}}\n$$", "id": "3428714"}, {"introduction": "Having mastered the logic of step evaluation, we now turn to computing the step itself. A cornerstone of methods for nonlinear least-squares problems is the Gauss-Newton (GN) step, which represents an optimal move within the local quadratic model. This exercise [@problem_id:3428663] guides you through calculating this step for a simple linear inverse problem and implementing the most basic trust-region enforcement: checking if the step is within bounds and scaling it to the boundary if it is not.", "problem": "Consider the linear inverse problem defined by the quadratic objective $J(x)=\\tfrac{1}{2}\\|A x - b\\|^{2}$ with the Euclidean norm, where\n$$\nA=\\begin{pmatrix}3  1 \\\\ 1  2\\end{pmatrix}, \\quad b=\\begin{pmatrix}7 \\\\ 8\\end{pmatrix}.\n$$\nAt the current iterate $x_{k}=\\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$ and with trust-region radius $\\Delta=1$ (using the Euclidean norm), compute the Gauss–Newton (GN) step for minimizing $J(x)$, check whether it satisfies the trust-region (TR) constraint $\\|s\\|\\le \\Delta$, and, if it violates the constraint, construct a scaled step along the GN direction that lies exactly on the boundary of the TR. Report the final adopted TR step $s_{\\mathrm{tr}}$ as a row vector. Do not round your answer. Express your final answer without units.", "solution": "The problem requires the computation of a trust-region step for a given linear inverse problem. The process involves first calculating the Gauss-Newton (GN) step, then checking if it lies within the trust region, and if not, scaling it to lie on the trust-region boundary.\n\nThe objective function to be minimized is $J(x) = \\frac{1}{2}\\|Ax - b\\|^2$, where the norm is the Euclidean norm. The given parameters are:\n$$\nA=\\begin{pmatrix}3  1 \\\\ 1  2\\end{pmatrix}, \\quad b=\\begin{pmatrix}7 \\\\ 8\\end{pmatrix}\n$$\nThe current iterate is $x_{k}=\\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$ and the trust-region radius is $\\Delta=1$.\n\nThe Gauss-Newton method approximates the objective function at $x_k$ with a quadratic model:\n$$\nm_k(s) = J(x_k) + \\nabla J(x_k)^T s + \\frac{1}{2} s^T H_{gn} s\n$$\nwhere $s$ is the step from $x_k$, $\\nabla J(x_k)$ is the gradient of $J$ at $x_k$, and $H_{gn}$ is the Gauss-Newton approximation of the Hessian.\n\nThe gradient of $J(x)$ is given by:\n$$\n\\nabla J(x) = A^T(Ax - b)\n$$\nThe Hessian of $J(x)$ is:\n$$\n\\nabla^2 J(x) = A^T A\n$$\nFor a linear least-squares problem, the Gauss-Newton approximation to the Hessian is the exact Hessian, so $H_{gn} = A^T A$.\n\nAt the current iterate $x_k = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$, the gradient is:\n$$\n\\nabla J(x_k) = A^T(A \\cdot \\mathbf{0} - b) = -A^T b\n$$\nThe Gauss-Newton step, $s_{gn}$, is the unconstrained minimizer of the model $m_k(s)$. It is found by solving the linear system $H_{gn} s_{gn} = -\\nabla J(x_k)$:\n$$\n(A^T A) s_{gn} = -(-A^T b) = A^T b\n$$\nFirst, we compute the matrix $A^T A$ and the vector $A^T b$. Since $A$ is symmetric, $A^T=A$.\n$$\nA^T A = A^2 = \\begin{pmatrix}3  1 \\\\ 1  2\\end{pmatrix} \\begin{pmatrix}3  1 \\\\ 1  2\\end{pmatrix} = \\begin{pmatrix}3(3)+1(1)  3(1)+1(2) \\\\ 1(3)+2(1)  1(1)+2(2)\\end{pmatrix} = \\begin{pmatrix}10  5 \\\\ 5  5\\end{pmatrix}\n$$\n$$\nA^T b = A b = \\begin{pmatrix}3  1 \\\\ 1  2\\end{pmatrix} \\begin{pmatrix}7 \\\\ 8\\end{pmatrix} = \\begin{pmatrix}3(7)+1(8) \\\\ 1(7)+2(8)\\end{pmatrix} = \\begin{pmatrix}29 \\\\ 23\\end{pmatrix}\n$$\nNow we solve the system $(A^T A) s_{gn} = A^T b$ for $s_{gn} = \\begin{pmatrix}s_1 \\\\ s_2\\end{pmatrix}$:\n$$\n\\begin{pmatrix}10  5 \\\\ 5  5\\end{pmatrix} \\begin{pmatrix}s_1 \\\\ s_2\\end{pmatrix} = \\begin{pmatrix}29 \\\\ 23\\end{pmatrix}\n$$\nThis gives the pair of linear equations:\n$1.$ $10s_1 + 5s_2 = 29$\n$2.$ $5s_1 + 5s_2 = 23$\n\nSubtracting the second equation from the first gives:\n$5s_1 = 6 \\implies s_1 = \\frac{6}{5}$\nSubstituting $s_1 = \\frac{6}{5}$ into the second equation:\n$5\\left(\\frac{6}{5}\\right) + 5s_2 = 23 \\implies 6 + 5s_2 = 23 \\implies 5s_2 = 17 \\implies s_2 = \\frac{17}{5}$\nThus, the Gauss-Newton step is:\n$$\ns_{gn} = \\begin{pmatrix} \\frac{6}{5} \\\\ \\frac{17}{5} \\end{pmatrix}\n$$\nNext, we must check whether this step satisfies the trust-region constraint, $\\|s\\| \\le \\Delta$, with $\\Delta=1$. We calculate the Euclidean norm of $s_{gn}$:\n$$\n\\|s_{gn}\\| = \\sqrt{\\left(\\frac{6}{5}\\right)^2 + \\left(\\frac{17}{5}\\right)^2} = \\sqrt{\\frac{36}{25} + \\frac{289}{25}} = \\sqrt{\\frac{325}{25}} = \\sqrt{13}\n$$\nSince $\\sqrt{13} \\approx 3.6055$, we have $\\|s_{gn}\\| = \\sqrt{13} > 1 = \\Delta$. The Gauss-Newton step violates the trust-region constraint.\n\nThe problem instructs us to \"construct a scaled step along the GN direction that lies exactly on the boundary of the TR.\" This means the adopted trust-region step, $s_{tr}$, must be in the same direction as $s_{gn}$ but with a magnitude equal to the trust-region radius $\\Delta$.\nThe direction of $s_{gn}$ is given by the unit vector $\\frac{s_{gn}}{\\|s_{gn}\\|}$. We scale this direction by $\\Delta$ to obtain $s_{tr}$:\n$$\ns_{tr} = \\Delta \\frac{s_{gn}}{\\|s_{gn}\\|}\n$$\nSubstituting the known values $\\Delta=1$, $\\|s_{gn}\\|=\\sqrt{13}$, and $s_{gn} = \\begin{pmatrix} \\frac{6}{5} \\\\ \\frac{17}{5} \\end{pmatrix}$:\n$$\ns_{tr} = 1 \\cdot \\frac{1}{\\sqrt{13}} \\begin{pmatrix} \\frac{6}{5} \\\\ \\frac{17}{5} \\end{pmatrix} = \\begin{pmatrix} \\frac{6}{5\\sqrt{13}} \\\\ \\frac{17}{5\\sqrt{13}} \\end{pmatrix}\n$$\nTo rationalize the denominator for a standard representation:\n$$\ns_{tr} = \\begin{pmatrix} \\frac{6\\sqrt{13}}{5 \\cdot 13} \\\\ \\frac{17\\sqrt{13}}{5 \\cdot 13} \\end{pmatrix} = \\begin{pmatrix} \\frac{6\\sqrt{13}}{65} \\\\ \\frac{17\\sqrt{13}}{65} \\end{pmatrix}\n$$\nThe problem asks for the answer as a row vector. Therefore, the final adopted trust-region step is the transpose of this vector.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{6\\sqrt{13}}{65}  \\frac{17\\sqrt{13}}{65}\n\\end{pmatrix}\n}\n$$", "id": "3428663"}, {"introduction": "While the Gauss-Newton step is often effective, it can be unreliable when the model is a poor approximation or the problem is ill-conditioned. A more robust and classic strategy is the dogleg method, which constructs an intelligent path that interpolates between the conservative steepest-descent direction and the ambitious Gauss-Newton direction. This advanced practice [@problem_id:3428678] challenges you to build this dogleg step from first principles and introduces the Mahalanobis norm, a statistically-motivated metric crucial for handling weighted inverse problems.", "problem": "Consider a nonlinear weighted least-squares inverse problem with residual vector $\\mathbf{r} \\in \\mathbb{R}^{2}$ and Jacobian $\\mathbf{J} \\in \\mathbb{R}^{2 \\times 2}$. At a current iterate, approximate the objective by the Gauss–Newton quadratic model\n$$\nm(\\mathbf{s}) \\;=\\; \\tfrac{1}{2}\\,\\|\\mathbf{r} + \\mathbf{J}\\,\\mathbf{s}\\|_{\\mathbf{C}^{-1}}^{2},\n$$\nwhere $\\|\\mathbf{v}\\|_{\\mathbf{C}^{-1}} := \\sqrt{\\mathbf{v}^{\\top}\\mathbf{C}^{-1}\\mathbf{v}}$ is the Mahalanobis norm induced by the symmetric positive definite (SPD) covariance matrix $\\mathbf{C} \\in \\mathbb{R}^{2 \\times 2}$. The trust-region subproblem is to reduce $m(\\mathbf{s})$ subject to the Mahalanobis trust-region constraint $\\|\\mathbf{s}\\|_{\\mathbf{C}^{-1}} \\le \\Delta$.\n\nUse only fundamental definitions of the Gauss–Newton model, its gradient and approximate Hessian, and the steepest-descent (Cauchy) step for a quadratic form to construct the classical dogleg step with respect to the Mahalanobis norm. The data are\n$$\n\\mathbf{C} \\;=\\; \\begin{bmatrix} 1  0 \\\\ 0  9 \\end{bmatrix}, \n\\quad \\mathbf{J} \\;=\\; \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}, \n\\quad \\mathbf{r} \\;=\\; \\begin{bmatrix} 2 \\\\ 3 \\end{bmatrix}, \n\\quad \\Delta \\;=\\; 2.\n$$\nProceed as follows:\n- Derive the gradient $\\mathbf{g}$ and approximate Hessian $\\mathbf{B}$ of the quadratic model $q(\\mathbf{s}) = \\tfrac{1}{2}\\mathbf{s}^{\\top}\\mathbf{B}\\,\\mathbf{s} + \\mathbf{g}^{\\top}\\mathbf{s}$ from first principles.\n- Derive the steepest-descent step (Cauchy point) $\\mathbf{s}_{\\mathrm{SD}}$ by minimizing $q(-\\alpha\\,\\mathbf{g})$ over $\\alpha \\ge 0$.\n- Compute the Gauss–Newton step $\\mathbf{s}_{\\mathrm{GN}}$ by solving $\\mathbf{B}\\,\\mathbf{s}_{\\mathrm{GN}} = -\\mathbf{g}$.\n- Using the Mahalanobis norm induced by $\\mathbf{C}^{-1}$ as the trust-region norm, determine which dogleg case applies and compute the dogleg step $\\mathbf{s}_{\\mathrm{DL}}$ accordingly. Verify that $\\|\\mathbf{s}_{\\mathrm{DL}}\\|_{\\mathbf{C}^{-1}} \\le \\Delta$.\n\nReport as your final answer the exact scalar $\\lambda$ such that $\\mathbf{s}_{\\mathrm{DL}} = -\\lambda\\,\\mathbf{g}$. No numerical rounding is required, and no units are involved. Express the final answer as a single closed-form expression.", "solution": "The problem is valid as it is self-contained, scientifically grounded in the field of numerical optimization, and mathematically well-posed. All necessary data and definitions are provided. I will proceed with the solution by following the specified steps.\n\nThe Gauss-Newton quadratic model of the objective function is given by\n$$m(\\mathbf{s}) = \\tfrac{1}{2}\\,\\|\\mathbf{r} + \\mathbf{J}\\,\\mathbf{s}\\|_{\\mathbf{C}^{-1}}^{2}$$\nwhere $\\|\\mathbf{v}\\|_{\\mathbf{C}^{-1}} = \\sqrt{\\mathbf{v}^{\\top}\\mathbf{C}^{-1}\\mathbf{v}}$. Expanding this expression, we get:\n$$m(\\mathbf{s}) = \\tfrac{1}{2}\\,(\\mathbf{r} + \\mathbf{J}\\,\\mathbf{s})^{\\top}\\mathbf{C}^{-1}(\\mathbf{r} + \\mathbf{J}\\,\\mathbf{s}) = \\tfrac{1}{2}\\,(\\mathbf{r}^{\\top}\\mathbf{C}^{-1}\\mathbf{r} + 2\\mathbf{r}^{\\top}\\mathbf{C}^{-1}\\mathbf{J}\\,\\mathbf{s} + \\mathbf{s}^{\\top}\\mathbf{J}^{\\top}\\mathbf{C}^{-1}\\mathbf{J}\\,\\mathbf{s})$$\nThis model is approximated by a general quadratic form $q(\\mathbf{s}) = \\frac{1}{2}\\mathbf{s}^{\\top}\\mathbf{B}\\,\\mathbf{s} + \\mathbf{g}^{\\top}\\mathbf{s} + \\text{constant}$.\n\n### Step 1: Derive Gradient $\\mathbf{g}$ and Approximate Hessian $\\mathbf{B}$\nBy comparing the expanded form of $m(\\mathbf{s})$ with the general quadratic $q(\\mathbf{s})$, we identify the gradient $\\mathbf{g}$ and the approximate Hessian $\\mathbf{B}$ at $\\mathbf{s}=\\mathbf{0}$:\n$$\\mathbf{g} = \\nabla m(\\mathbf{s})|_{\\mathbf{s}=\\mathbf{0}} = \\mathbf{J}^{\\top}\\mathbf{C}^{-1}\\mathbf{r}$$\n$$\\mathbf{B} = \\nabla^2 m(\\mathbf{s})|_{\\mathbf{s}=\\mathbf{0}} = \\mathbf{J}^{\\top}\\mathbf{C}^{-1}\\mathbf{J}$$\nThe given data are:\n$$\n\\mathbf{C} = \\begin{bmatrix} 1  0 \\\\ 0  9 \\end{bmatrix}, \\quad \\mathbf{J} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}, \\quad \\mathbf{r} = \\begin{bmatrix} 2 \\\\ 3 \\end{bmatrix}\n$$\nThe inverse of the covariance matrix $\\mathbf{C}$ is:\n$$\\mathbf{C}^{-1} = \\begin{bmatrix} 1  0 \\\\ 0  \\frac{1}{9} \\end{bmatrix}$$\nNow, we compute $\\mathbf{g}$ and $\\mathbf{B}$:\n$$\\mathbf{g} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}^{\\top} \\begin{bmatrix} 1  0 \\\\ 0  \\frac{1}{9} \\end{bmatrix} \\begin{bmatrix} 2 \\\\ 3 \\end{bmatrix} = \\begin{bmatrix} 1  0 \\\\ 0  \\frac{1}{9} \\end{bmatrix} \\begin{bmatrix} 2 \\\\ 3 \\end{bmatrix} = \\begin{bmatrix} 2 \\\\ \\frac{1}{3} \\end{bmatrix}$$\n$$\\mathbf{B} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}^{\\top} \\begin{bmatrix} 1  0 \\\\ 0  \\frac{1}{9} \\end{bmatrix} \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix} = \\begin{bmatrix} 1  0 \\\\ 0  \\frac{1}{9} \\end{bmatrix}$$\nNote that in this specific problem, $\\mathbf{B} = \\mathbf{C}^{-1}$.\n\n### Step 2: Derive the Steepest-Descent Step (Cauchy Point) $\\mathbf{s}_{\\mathrm{SD}}$\nThe problem defines $\\mathbf{s}_{\\mathrm{SD}}$ as the unconstrained minimizer of $q(\\mathbf{s})$ along the steepest-descent direction $-\\mathbf{g}$. We set $\\mathbf{s}(\\alpha) = -\\alpha\\mathbf{g}$ for $\\alpha \\ge 0$ and find the $\\alpha$ that minimizes $q(\\mathbf{s}(\\alpha))$:\n$$q(-\\alpha\\mathbf{g}) = \\tfrac{1}{2}(-\\alpha\\mathbf{g})^{\\top}\\mathbf{B}(-\\alpha\\mathbf{g}) + \\mathbf{g}^{\\top}(-\\alpha\\mathbf{g}) = \\tfrac{1}{2}\\alpha^2(\\mathbf{g}^{\\top}\\mathbf{B}\\mathbf{g}) - \\alpha(\\mathbf{g}^{\\top}\\mathbf{g})$$\nTo find the minimum, we differentiate with respect to $\\alpha$ and set the result to zero:\n$$\\frac{d}{d\\alpha}q(-\\alpha\\mathbf{g}) = \\alpha(\\mathbf{g}^{\\top}\\mathbf{B}\\mathbf{g}) - (\\mathbf{g}^{\\top}\\mathbf{g}) = 0$$\nThe optimal step length is $\\alpha^* = \\frac{\\mathbf{g}^{\\top}\\mathbf{g}}{\\mathbf{g}^{\\top}\\mathbf{B}\\mathbf{g}}$.\nLet's compute the scalar products:\n$$\\mathbf{g}^{\\top}\\mathbf{g} = \\begin{bmatrix} 2  \\frac{1}{3} \\end{bmatrix} \\begin{bmatrix} 2 \\\\ \\frac{1}{3} \\end{bmatrix} = 2^2 + (\\frac{1}{3})^2 = 4 + \\frac{1}{9} = \\frac{37}{9}$$\n$$\\mathbf{g}^{\\top}\\mathbf{B}\\mathbf{g} = \\begin{bmatrix} 2  \\frac{1}{3} \\end{bmatrix} \\begin{bmatrix} 1  0 \\\\ 0  \\frac{1}{9} \\end{bmatrix} \\begin{bmatrix} 2 \\\\ \\frac{1}{3} \\end{bmatrix} = \\begin{bmatrix} 2  \\frac{1}{27} \\end{bmatrix} \\begin{bmatrix} 2 \\\\ \\frac{1}{3} \\end{bmatrix} = 4 + \\frac{1}{81} = \\frac{324+1}{81} = \\frac{325}{81}$$\nSo, the step length is:\n$$\\alpha^* = \\frac{37/9}{325/81} = \\frac{37}{9} \\cdot \\frac{81}{325} = \\frac{37 \\cdot 9}{325} = \\frac{333}{325}$$\nThe unconstrained steepest-descent step is:\n$$\\mathbf{s}_{\\mathrm{SD}} = -\\alpha^*\\mathbf{g} = -\\frac{333}{325}\\begin{bmatrix} 2 \\\\ \\frac{1}{3} \\end{bmatrix}$$\n\n### Step 3: Compute the Gauss-Newton Step $\\mathbf{s}_{\\mathrm{GN}}$\nThe Gauss-Newton step $\\mathbf{s}_{\\mathrm{GN}}$ minimizes the quadratic model $q(\\mathbf{s})$ without constraints. It is the solution to the linear system $\\mathbf{B}\\mathbf{s}_{\\mathrm{GN}} = -\\mathbf{g}$.\n$$\\mathbf{s}_{\\mathrm{GN}} = -\\mathbf{B}^{-1}\\mathbf{g}$$\nThe inverse of $\\mathbf{B}$ is $\\mathbf{B}^{-1} = (\\mathbf{C}^{-1})^{-1} = \\mathbf{C} = \\begin{bmatrix} 1  0 \\\\ 0  9 \\end{bmatrix}$.\n$$\\mathbf{s}_{\\mathrm{GN}} = - \\begin{bmatrix} 1  0 \\\\ 0  9 \\end{bmatrix} \\begin{bmatrix} 2 \\\\ \\frac{1}{3} \\end{bmatrix} = - \\begin{bmatrix} 2 \\\\ 3 \\end{bmatrix} = \\begin{bmatrix} -2 \\\\ -3 \\end{bmatrix}$$\n\n### Step 4: Determine the Dogleg Step $\\mathbf{s}_{\\mathrm{DL}}$\nThe classical dogleg path connects the origin, the unconstrained steepest-descent step $\\mathbf{s}_{\\mathrm{SD}}$, and the Gauss-Newton step $\\mathbf{s}_{\\mathrm{GN}}$. The dogleg step $\\mathbf{s}_{\\mathrm{DL}}$ is the point on this path that is furthest from the origin while still satisfying the trust-region constraint $\\|\\mathbf{s}\\|_{\\mathbf{C}^{-1}} \\le \\Delta$, where $\\Delta=2$.\n\nFirst, we check if $\\mathbf{s}_{\\mathrm{GN}}$ is within the trust region:\n$$\\|\\mathbf{s}_{\\mathrm{GN}}\\|_{\\mathbf{C}^{-1}}^2 = \\mathbf{s}_{\\mathrm{GN}}^{\\top}\\mathbf{C}^{-1}\\mathbf{s}_{\\mathrm{GN}} = \\begin{bmatrix} -2  -3 \\end{bmatrix} \\begin{bmatrix} 1  0 \\\\ 0  \\frac{1}{9} \\end{bmatrix} \\begin{bmatrix} -2 \\\\ -3 \\end{bmatrix} = (-2)^2 + (-3)\\left(-\\frac{3}{9}\\right) = 4 + 1 = 5$$\n$$\\|\\mathbf{s}_{\\mathrm{GN}}\\|_{\\mathbf{C}^{-1}} = \\sqrt{5}$$\nSince $\\sqrt{5} > 2$, $\\mathbf{s}_{\\mathrm{GN}}$ is outside the trust region.\n\nNext, we check if $\\mathbf{s}_{\\mathrm{SD}}$ is within the trust region. The norm is $\\|\\mathbf{s}_{\\mathrm{SD}}\\|_{\\mathbf{C}^{-1}} = \\alpha^*\\|\\mathbf{g}\\|_{\\mathbf{C}^{-1}}$.\n$$\\|\\mathbf{g}\\|_{\\mathbf{C}^{-1}}^2 = \\mathbf{g}^{\\top}\\mathbf{C}^{-1}\\mathbf{g} = \\mathbf{g}^{\\top}\\mathbf{B}\\mathbf{g} = \\frac{325}{81}$$\n$$\\|\\mathbf{g}\\|_{\\mathbf{C}^{-1}} = \\sqrt{\\frac{325}{81}} = \\frac{\\sqrt{25 \\cdot 13}}{9} = \\frac{5\\sqrt{13}}{9}$$\n$$\\|\\mathbf{s}_{\\mathrm{SD}}\\|_{\\mathbf{C}^{-1}} = \\alpha^*\\|\\mathbf{g}\\|_{\\mathbf{C}^{-1}} = \\frac{333}{325} \\cdot \\frac{5\\sqrt{13}}{9} = \\frac{37 \\cdot 9}{65 \\cdot 5} \\cdot \\frac{5\\sqrt{13}}{9} = \\frac{37\\sqrt{13}}{65}$$\nTo compare this with $\\Delta=2$, we check if $37\\sqrt{13} > 65 \\cdot 2 = 130$. This is equivalent to $\\sqrt{13} > \\frac{130}{37} \\approx 3.51$. Since $3.6^2 = 12.96$ and $3.7^2 = 13.69$, $\\sqrt{13}$ is approximately $3.606$, which is greater than $3.51$. Thus, $\\|\\mathbf{s}_{\\mathrm{SD}}\\|_{\\mathbf{C}^{-1}} > \\Delta$.\n\nSince both the unconstrained steepest-descent step $\\mathbf{s}_{\\mathrm{SD}}$ and the Gauss-Newton step $\\mathbf{s}_{\\mathrm{GN}}$ lie outside the trust region, the dogleg path intersects the trust-region boundary on its first segment (the line from the origin to $\\mathbf{s}_{\\mathrm{SD}}$). The dogleg step $\\mathbf{s}_{\\mathrm{DL}}$ is therefore in the steepest-descent direction $-\\mathbf{g}$ and lies on the boundary of the trust region.\nThis means $\\mathbf{s}_{\\mathrm{DL}}$ takes the form $\\mathbf{s}_{\\mathrm{DL}} = -\\lambda\\mathbf{g}$ for some scalar $\\lambda > 0$, and it must satisfy $\\|\\mathbf{s}_{\\mathrm{DL}}\\|_{\\mathbf{C}^{-1}} = \\Delta$.\n$$\\|-\\lambda\\mathbf{g}\\|_{\\mathbf{C}^{-1}} = \\lambda\\|\\mathbf{g}\\|_{\\mathbf{C}^{-1}} = \\Delta$$\nSolving for $\\lambda$:\n$$\\lambda = \\frac{\\Delta}{\\|\\mathbf{g}\\|_{\\mathbf{C}^{-1}}} = \\frac{2}{5\\sqrt{13}/9} = \\frac{18}{5\\sqrt{13}}$$\nThis is the required scalar $\\lambda$. The dogleg step is $\\mathbf{s}_{\\mathrm{DL}} = -\\frac{18}{5\\sqrt{13}}\\mathbf{g}$.\n\nAs a verification, by construction, $\\|\\mathbf{s}_{\\mathrm{DL}}\\|_{\\mathbf{C}^{-1}} = \\lambda \\|\\mathbf{g}\\|_{\\mathbf{C}^{-1}} = \\frac{18}{5\\sqrt{13}} \\cdot \\frac{5\\sqrt{13}}{9} = \\frac{18}{9} = 2 = \\Delta$. The constraint is satisfied.\nThe final answer is the exact value of $\\lambda$.", "answer": "$$\n\\boxed{\\frac{18}{5\\sqrt{13}}}\n$$", "id": "3428678"}]}