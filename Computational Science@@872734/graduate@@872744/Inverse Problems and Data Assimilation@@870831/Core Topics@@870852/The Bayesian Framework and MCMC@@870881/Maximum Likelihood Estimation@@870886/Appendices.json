{"hands_on_practices": [{"introduction": "Maximum Likelihood Estimation often serves as the theoretical bedrock for parameter inference, but real-world applications frequently involve physical constraints, such as positivity or conservation laws. This exercise bridges theory and practice by demonstrating how to incorporate such constraints into the MLE framework [@problem_id:3402122]. You will formulate a constrained estimation problem and use the powerful Karush-Kuhn-Tucker (KKT) conditions to characterize and compute the optimal solution, a fundamental skill in geophysical and engineering data assimilation.", "problem": "Consider a linear-Gaussian observation model used in data assimilation: the unknown state parameter vector $\\theta \\in \\mathbb{R}^{n}$ is to be estimated from an observed data vector $y \\in \\mathbb{R}^{n}$ modeled as $y \\mid \\theta \\sim \\mathcal{N}(H\\theta, R)$, where $H \\in \\mathbb{R}^{n \\times n}$ is a known forward operator and $R \\in \\mathbb{R}^{n \\times n}$ is a known symmetric positive definite covariance matrix. The goal is to perform Maximum Likelihood Estimation (MLE) subject to linear inequality constraints that encode admissible physical bounds, modeled by a convex polyhedral set\n$$\n\\Theta \\;=\\; \\{\\theta \\in \\mathbb{R}^{n} : C\\theta \\le d\\},\n$$\nwhere $C \\in \\mathbb{R}^{m \\times n}$ and $d \\in \\mathbb{R}^{m}$, with the inequality understood componentwise.\n\nStarting from the definition of Maximum Likelihood Estimation (MLE), the Gaussian likelihood, and the basic principles of constrained optimization, perform the following:\n\n1. Formulate the constrained MLE problem as an optimization problem over $\\Theta$.\n2. Derive, from first principles, the Karush-Kuhn-Tucker (KKT) conditions that characterize an optimal solution $\\hat{\\theta}$, expressing these conditions in terms of the gradient of the log-likelihood $\\nabla \\ell(\\theta)$ and a vector of Lagrange multipliers $\\lambda \\in \\mathbb{R}^{m}$.\n3. Specialize to the case $n=2$ with $H = I_{2}$, $R = I_{2}$, and constraints defined by\n$$\nC \\;=\\; \\begin{pmatrix} -1  0 \\\\ 0  -1 \\\\ 1  1 \\end{pmatrix}, \\quad d \\;=\\; \\begin{pmatrix} 0 \\\\ 0 \\\\ 2 \\end{pmatrix},\n$$\nwhich enforce $\\theta_{1} \\ge 0$, $\\theta_{2} \\ge 0$, and $\\theta_{1} + \\theta_{2} \\le 2$. Given the observed data vector $y = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$, compute the constrained MLE $\\hat{\\theta}$.\n\nAssume that the Slater condition holds (i.e., there exists a strictly feasible $\\bar{\\theta}$ with $C\\bar{\\theta}  d$), ensuring that KKT conditions are both necessary and sufficient for optimality in this concave maximization over a convex set. Express your final answer as the row matrix $\\begin{pmatrix} \\hat{\\theta}_{1}  \\hat{\\theta}_{2} \\end{pmatrix}$ using the $\\mathrm{pmatrix}$ environment. No rounding is required and no physical units are involved.", "solution": "The problem is validated to be scientifically grounded, well-posed, objective, complete, and consistent. It is a standard problem in constrained optimization applied to statistical estimation. We proceed with the solution, which is divided into three parts as requested.\n\n### Part 1: Formulation of the Constrained MLE Problem\n\nThe problem is to estimate the state vector $\\theta \\in \\mathbb{R}^{n}$ from the observation vector $y \\in \\mathbb{R}^{n}$, given the linear-Gaussian model $y \\mid \\theta \\sim \\mathcal{N}(H\\theta, R)$. The likelihood function, $L(\\theta; y)$, is the probability density function of the observation $y$ evaluated at the given data, viewed as a function of the parameter $\\theta$. For a multivariate normal distribution, this is:\n$$\nL(\\theta; y) = p(y \\mid \\theta) = \\frac{1}{(2\\pi)^{n/2} (\\det(R))^{1/2}} \\exp\\left(-\\frac{1}{2}(y - H\\theta)^T R^{-1} (y - H\\theta)\\right)\n$$\nMaximum Likelihood Estimation (MLE) seeks the value of $\\theta$ that maximizes this likelihood function. It is often more convenient to work with the natural logarithm of the likelihood, the log-likelihood function $\\ell(\\theta; y)$, because the logarithm is a strictly increasing function, and maximizing $\\ell(\\theta; y)$ is equivalent to maximizing $L(\\theta; y)$.\n$$\n\\ell(\\theta; y) = \\ln(L(\\theta; y)) = -\\frac{n}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln(\\det(R)) - \\frac{1}{2}(y - H\\theta)^T R^{-1} (y - H\\theta)\n$$\nThe estimation is subject to the constraint that $\\theta$ must belong to the convex polyhedral set $\\Theta = \\{\\theta \\in \\mathbb{R}^{n} : C\\theta \\le d\\}$.\n\nThe constrained MLE problem is to find the $\\theta$ that maximizes $\\ell(\\theta; y)$ subject to this constraint. Noting that the first two terms in the expression for $\\ell(\\theta; y)$ are constant with respect to $\\theta$, maximizing $\\ell(\\theta; y)$ is equivalent to minimizing the quadratic term:\n$$\nJ(\\theta) = \\frac{1}{2}(y - H\\theta)^T R^{-1} (y - H\\theta)\n$$\nThis is a weighted least-squares cost function. The constrained MLE problem can thus be formulated as the following optimization problem over the set $\\Theta$:\n$$\n\\hat{\\theta} = \\arg\\max_{\\theta \\in \\Theta} \\ell(\\theta; y) \\quad \\text{or equivalently} \\quad \\hat{\\theta} = \\arg\\min_{\\theta \\in \\Theta} J(\\theta)\n$$\nAs a formal optimization problem statement:\n$$\n\\text{maximize} \\quad -\\frac{1}{2}(y - H\\theta)^T R^{-1} (y - H\\theta) \\quad \\text{subject to} \\quad C\\theta \\le d\n$$\n\n### Part 2: Derivation of the KKT Conditions\n\nWe formulate the problem as a standard constrained maximization problem. Let the objective function be $f(\\theta) = \\ell(\\theta; y)$ and the constraints be $g_j(\\theta) \\le 0$ for $j=1, \\dots, m$. The constraints $C\\theta \\le d$ can be written component-wise as $c_j^T\\theta - d_j \\le 0$, where $c_j^T$ is the $j$-th row of $C$ and $d_j$ is the $j$-th component of $d$. So, $g_j(\\theta) = c_j^T\\theta - d_j$.\n\nThe Lagrangian function $\\mathcal{L}(\\theta, \\lambda)$ is formed by adding the constraints to the objective function, weighted by Lagrange multipliers $\\lambda \\in \\mathbb{R}^{m}$:\n$$\n\\mathcal{L}(\\theta, \\lambda) = f(\\theta) - \\sum_{j=1}^{m} \\lambda_j g_j(\\theta) = \\ell(\\theta; y) - \\lambda^T(C\\theta - d)\n$$\nThe Karush-Kuhn-Tucker (KKT) conditions are necessary (and in this convex problem, sufficient) conditions for an optimal solution $\\hat{\\theta}$ with corresponding Lagrange multipliers $\\hat{\\lambda}$. The conditions are:\n\n1.  **Stationarity of the Lagrangian**: The gradient of the Lagrangian with respect to $\\theta$ must be zero at the solution $\\hat{\\theta}$.\n    $$\n    \\nabla_{\\theta} \\mathcal{L}(\\hat{\\theta}, \\hat{\\lambda}) = \\nabla_{\\theta}\\ell(\\hat{\\theta}) - C^T \\hat{\\lambda} = 0\n    $$\n    First, we compute the gradient of the log-likelihood.\n    $$\n    \\nabla_{\\theta}\\ell(\\theta) = \\nabla_{\\theta}\\left[-\\frac{1}{2}(y - H\\theta)^T R^{-1} (y - H\\theta)\\right]\n    $$\n    Expanding the quadratic form: $(y - H\\theta)^T R^{-1} (y - H\\theta) = y^T R^{-1} y - 2y^T R^{-1} H\\theta + \\theta^T H^T R^{-1} H\\theta$.\n    The gradient is:\n    $$\n    \\nabla_{\\theta}\\ell(\\theta) = -\\frac{1}{2}(-2H^T R^{-1} y + 2H^T R^{-1} H\\theta) = H^T R^{-1}y - H^T R^{-1}H\\theta = H^T R^{-1}(y - H\\theta)\n    $$\n    So the stationarity condition is: $H^T R^{-1}(y - H\\hat{\\theta}) - C^T \\hat{\\lambda} = 0$.\n\n2.  **Primal Feasibility**: The solution $\\hat{\\theta}$ must satisfy the original constraints.\n    $$\n    C\\hat{\\theta} \\le d\n    $$\n\n3.  **Dual Feasibility**: The Lagrange multipliers for inequality constraints must be non-negative.\n    $$\n    \\hat{\\lambda} \\ge 0 \\quad (\\text{component-wise})\n    $$\n\n4.  **Complementary Slackness**: For each constraint, either the constraint is active (equality holds) or the corresponding Lagrange multiplier is zero.\n    $$\n    \\hat{\\lambda}_j (c_j^T\\hat{\\theta} - d_j) = 0 \\quad \\text{for } j=1, \\dots, m\n    $$\n    This can be written compactly as $\\mathrm{diag}(\\hat{\\lambda})(C\\hat{\\theta} - d) = 0$.\n\n### Part 3: Specific Case Computation\n\nWe are given the specific case where $n=2$, $H=I_2$, $R=I_2$, $y = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$, $C = \\begin{pmatrix} -1  0 \\\\ 0  -1 \\\\ 1  1 \\end{pmatrix}$, and $d = \\begin{pmatrix} 0 \\\\ 0 \\\\ 2 \\end{pmatrix}$.\nThe optimization problem is to minimize $J(\\theta) = \\frac{1}{2}(y-\\theta)^T(y-\\theta) = \\frac{1}{2}\\|\\theta-y\\|^2_2$ subject to the constraints. This is geometrically equivalent to finding the point $\\hat{\\theta}$ in the feasible set $\\Theta$ that is closest to $y$.\n\nThe constraints are:\n1.  $-\\theta_1 \\le 0 \\implies \\theta_1 \\ge 0$\n2.  $-\\theta_2 \\le 0 \\implies \\theta_2 \\ge 0$\n3.  $\\theta_1 + \\theta_2 \\le 2$\n\nFirst, let's find the unconstrained minimum, which is simply $\\theta_{unc} = y = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$. We check if this point is in the feasible set $\\Theta$:\n1.  $\\theta_1 = 2 \\ge 0$ (satisfied).\n2.  $\\theta_2 = 1 \\ge 0$ (satisfied).\n3.  $\\theta_1 + \\theta_2 = 2+1=3 \\le 2$ (violated).\n\nSince the unconstrained solution lies outside the feasible set, the constrained solution $\\hat{\\theta}$ must lie on the boundary of $\\Theta$. We use the KKT conditions derived in Part 2 to find $\\hat{\\theta}$.\n\nThe KKT conditions for this specific case are:\n-   **Stationarity**: For $H=I_2, R=I_2$, $\\nabla\\ell(\\theta) = y - \\theta$. The stationarity condition is $y - \\hat{\\theta} - C^T\\hat{\\lambda} = 0$.\n    $$\n    \\hat{\\theta} = y - C^T \\hat{\\lambda}\n    $$\n    With $y=\\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$ and $C^T=\\begin{pmatrix} -1  0  1 \\\\ 0  -1  1 \\end{pmatrix}$:\n    $$\n    \\begin{pmatrix} \\hat{\\theta}_1 \\\\ \\hat{\\theta}_2 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} - \\begin{pmatrix} -1  0  1 \\\\ 0  -1  1 \\end{pmatrix} \\begin{pmatrix} \\lambda_1 \\\\ \\lambda_2 \\\\ \\lambda_3 \\end{pmatrix} = \\begin{pmatrix} 2 + \\lambda_1 - \\lambda_3 \\\\ 1 + \\lambda_2 - \\lambda_3 \\end{pmatrix}\n    $$\n-   **Primal Feasibility**: $-\\hat{\\theta}_1 \\le 0$, $-\\hat{\\theta}_2 \\le 0$, $\\hat{\\theta}_1+\\hat{\\theta}_2 \\le 2$.\n-   **Dual Feasibility**: $\\lambda_1 \\ge 0$, $\\lambda_2 \\ge 0$, $\\lambda_3 \\ge 0$.\n-   **Complementary Slackness**:\n    $\\lambda_1(-\\hat{\\theta}_1) = 0$\n    $\\lambda_2(-\\hat{\\theta}_2) = 0$\n    $\\lambda_3(\\hat{\\theta}_1 + \\hat{\\theta}_2 - 2) = 0$\n\nWe analyze cases based on which constraints are active. Since only the third constraint was violated by the unconstrained solution, we hypothesize that only this constraint is active for the constrained solution.\n\nCase: Constraint 3 is active, constraints 1 and 2 are inactive.\nThis implies $\\hat{\\theta}_1 + \\hat{\\theta}_2 - 2 = 0$, and from complementary slackness, $\\lambda_1=0$ and $\\lambda_2=0$. We expect $\\lambda_3  0$.\n\nWith $\\lambda_1=0$ and $\\lambda_2=0$, the stationarity equations become:\n$$\n\\hat{\\theta}_1 = 2 - \\lambda_3\n$$\n$$\n\\hat{\\theta}_2 = 1 - \\lambda_3\n$$\nSubstituting these into the active constraint equation:\n$$\n(2 - \\lambda_3) + (1 - \\lambda_3) = 2\n$$\n$$\n3 - 2\\lambda_3 = 2 \\implies 2\\lambda_3 = 1 \\implies \\lambda_3 = \\frac{1}{2}\n$$\nThe value $\\lambda_3 = \\frac{1}{2}$ satisfies dual feasibility ($\\lambda_3 \\ge 0$). Now we find the corresponding $\\hat{\\theta}$:\n$$\n\\hat{\\theta}_1 = 2 - \\frac{1}{2} = \\frac{3}{2}\n$$\n$$\n\\hat{\\theta}_2 = 1 - \\frac{1}{2} = \\frac{1}{2}\n$$\nWe must verify that this solution satisfies all KKT conditions.\n-   **Stationarity**: Satisfied by construction.\n-   **Primal Feasibility**:\n    1.  $\\hat{\\theta}_1 = \\frac{3}{2} \\ge 0$ (satisfied).\n    2.  $\\hat{\\theta}_2 = \\frac{1}{2} \\ge 0$ (satisfied).\n    3.  $\\hat{\\theta}_1 + \\hat{\\theta}_2 = \\frac{3}{2} + \\frac{1}{2} = 2 \\le 2$ (satisfied, active).\n-   **Dual Feasibility**: $\\hat{\\lambda} = \\begin{pmatrix} 0  0  \\frac{1}{2} \\end{pmatrix}^T \\ge 0$ (satisfied).\n-   **Complementary Slackness**:\n    1.  $\\lambda_1(-\\hat{\\theta}_1) = 0 \\cdot (-\\frac{3}{2}) = 0$ (satisfied).\n    2.  $\\lambda_2(-\\hat{\\theta}_2) = 0 \\cdot (-\\frac{1}{2}) = 0$ (satisfied).\n    3.  $\\lambda_3(\\hat{\\theta}_1+\\hat{\\theta}_2-2) = \\frac{1}{2}(2-2) = 0$ (satisfied).\n\nSince we have found a point $(\\hat{\\theta}, \\hat{\\lambda})$ that satisfies all KKT conditions, and the problem is a convex optimization problem (concave objective, convex constraints) for which Slater's condition is assumed to hold, this point is the unique global maximum likelihood estimate.\n\nThe constrained MLE is $\\hat{\\theta} = \\begin{pmatrix} 3/2 \\\\ 1/2 \\end{pmatrix}$.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{3}{2}  \\frac{1}{2} \\end{pmatrix}}\n$$", "id": "3402122"}, {"introduction": "The elegant asymptotic properties of the Maximum Likelihood Estimator, namely its $\\sqrt{n}$-consistency and asymptotic normality, are not universally guaranteed; they rely on crucial regularity conditions regarding the likelihood function's smoothness and support. This problem challenges you to analyze a case where these conditions are violated, forcing a return to first principles to derive the estimator's true asymptotic behavior [@problem_id:3402145]. By working through this non-standard example, you will gain a deeper appreciation for the theoretical underpinnings of MLE and the importance of verifying its assumptions.", "problem": "Consider a data assimilation setting where an operational forecast model predicts a constant state $x^{\\star} \\in \\mathbb{R}$ exactly, and the observational system produces independent measurement residuals $r_{1}, r_{2}, \\dots, r_{n}$ defined by $r_{i} = y_{i} - x^{\\star}$, where $y_{i}$ are the observed values. Assume the residuals are independent and identically distributed according to a uniform distribution on the interval $[-\\theta, \\theta]$, where $\\theta  0$ is an unknown instrument error bound to be inferred. The statistical model for the residuals thus has density\n$$\nf(r \\mid \\theta) = \\frac{1}{2\\theta} \\,\\mathbf{1}\\{|r| \\leq \\theta\\},\n$$\nwhere $\\mathbf{1}\\{\\cdot\\}$ denotes the indicator function. Let $\\theta_{0}  0$ denote the true unknown bound of the measurement error. In this model, the support of the likelihood depends on the parameter, and the log-likelihood is not differentiable in $\\theta$ at sample-dependent points. This violates standard regularity conditions used to derive asymptotic normality of Maximum Likelihood Estimators (MLEs), such as differentiability of the log-likelihood and parameter-independent support.\n\nTasks:\n1. Starting from the definition of the likelihood under independence, derive the Maximum Likelihood Estimator (MLE) $\\hat{\\theta}_{n}$ for $\\theta$ in terms of the observed residuals $r_{1}, \\dots, r_{n}$.\n2. Prove that $\\hat{\\theta}_{n}$ is a consistent estimator of $\\theta_{0}$.\n3. Derive the exact cumulative distribution function of the statistic $Z_{n} = n(\\theta_{0} - \\hat{\\theta}_{n})$.\n4. Using first principles of order statistics and limiting arguments, compute the limiting Laplace transform (which equals the moment generating function of $Z_{n}$ evaluated on the negative half-line) defined for $s \\geq 0$ by\n$$\n\\lim_{n \\to \\infty} \\mathbb{E}\\big[\\exp(-s \\, n(\\theta_{0} - \\hat{\\theta}_{n}))\\big].\n$$\n\nYour final answer must be a single closed-form analytic expression in terms of $s$ and $\\theta_{0}$. No rounding is required and no physical units apply. Conclude, based on your derivation, whether the classical $\\sqrt{n}$-asymptotic normality for the MLE holds in this example and explain why or why not, but do not include this discussion in the final answer expression.", "solution": "We begin from the joint likelihood under independence. For residuals $r_{1}, \\dots, r_{n}$ with density $f(r \\mid \\theta) = (2\\theta)^{-1} \\mathbf{1}\\{|r| \\leq \\theta\\}$, the joint likelihood is\n$$\nL(\\theta; r_{1}, \\dots, r_{n}) = \\prod_{i=1}^{n} \\frac{1}{2\\theta} \\,\\mathbf{1}\\{|r_{i}| \\leq \\theta\\} = \\frac{1}{(2\\theta)^{n}} \\prod_{i=1}^{n} \\mathbf{1}\\{|r_{i}| \\leq \\theta\\}.\n$$\nThe indicator product $\\prod_{i=1}^{n} \\mathbf{1}\\{|r_{i}| \\leq \\theta\\}$ equals $1$ if and only if $\\theta \\geq \\max_{1 \\leq i \\leq n} |r_{i}|$, and is $0$ otherwise. Denote the sample maximum of absolute residuals by\n$$\nM_{n} := \\max_{1 \\leq i \\leq n} |r_{i}|.\n$$\nThen the likelihood can be rewritten as\n$$\nL(\\theta; r_{1}, \\dots, r_{n}) = \\frac{1}{(2\\theta)^{n}} \\,\\mathbf{1}\\{\\theta \\geq M_{n}\\}.\n$$\nFor any fixed data realization, $L(\\theta)$ is decreasing in $\\theta$ over the feasible set $\\{\\theta \\geq M_{n}\\}$. Therefore, the Maximum Likelihood Estimator (MLE) is the smallest $\\theta$ in the feasible set:\n$$\n\\hat{\\theta}_{n} = M_{n} = \\max_{1 \\leq i \\leq n} |r_{i}|.\n$$\n\nNext, we establish consistency of $\\hat{\\theta}_{n}$ for $\\theta_{0}$. Under the true parameter $\\theta_{0}$, the residuals $r_{i}$ are independent and identically distributed on $[-\\theta_{0}, \\theta_{0}]$. The cumulative distribution function (CDF) of $M_{n}$ can be computed directly. For $m \\in [0, \\theta_{0}]$,\n$$\n\\mathbb{P}(M_{n} \\leq m) = \\prod_{i=1}^{n} \\mathbb{P}(|r_{i}| \\leq m) = \\left(\\frac{m}{\\theta_{0}}\\right)^{n}.\n$$\nHence,\n$$\n\\mathbb{P}\\big(\\theta_{0} - M_{n}  \\varepsilon\\big) = \\mathbb{P}\\big(M_{n}  \\theta_{0} - \\varepsilon\\big) = \\left(\\frac{\\theta_{0} - \\varepsilon}{\\theta_{0}}\\right)^{n},\n$$\nwhich converges to $0$ exponentially fast in $n$ for every fixed $\\varepsilon  0$. Therefore, $\\theta_{0} - M_{n} \\to 0$ in probability, and by standard subsequence arguments (or by the Borelâ€“Cantelli Lemma using independence), one can strengthen this to almost sure convergence:\n$$\n\\hat{\\theta}_{n} = M_{n} \\xrightarrow{\\text{a.s.}} \\theta_{0}.\n$$\nThus, $\\hat{\\theta}_{n}$ is consistent for $\\theta_{0}$.\n\nWe now derive the exact distribution of $Z_{n} = n(\\theta_{0} - \\hat{\\theta}_{n}) = n(\\theta_{0} - M_{n})$. For $z \\in [0, n\\theta_{0}]$, we have\n$$\n\\mathbb{P}(Z_{n} \\geq z) = \\mathbb{P}\\big(n(\\theta_{0} - M_{n}) \\geq z\\big) = \\mathbb{P}\\left(M_{n} \\leq \\theta_{0} - \\frac{z}{n}\\right) = \\left(1 - \\frac{z}{n\\theta_{0}}\\right)^{n}.\n$$\nConsequently, the CDF of $Z_{n}$ is\n$$\nF_{Z_{n}}(z) = \\mathbb{P}(Z_{n} \\leq z) = 1 - \\left(1 - \\frac{z}{n\\theta_{0}}\\right)^{n}, \\quad \\text{for } z \\in [0, n\\theta_{0}],\n$$\nand $F_{Z_{n}}(z) = 0$ for $z  0$, $F_{Z_{n}}(z) = 1$ for $z \\geq n\\theta_{0}$.\n\nWe now compute the limiting Laplace transform of $Z_{n}$. For $s \\geq 0$, consider\n$$\n\\Lambda_{n}(s) := \\mathbb{E}\\big[\\exp(-s Z_{n})\\big] = \\int_{0}^{n\\theta_{0}} \\exp(-s z) \\, \\mathrm{d}F_{Z_{n}}(z).\n$$\nUsing the CDF expression above, for fixed $z \\geq 0$ and large $n$,\n$$\nF_{Z_{n}}(z) \\to 1 - \\exp\\left(-\\frac{z}{\\theta_{0}}\\right),\n$$\nsince $\\left(1 - \\frac{z}{n\\theta_{0}}\\right)^{n} \\to \\exp\\left(-\\frac{z}{\\theta_{0}}\\right)$ as $n \\to \\infty$. This identifies the limiting distribution of $Z_{n}$ as an exponential distribution with rate $1/\\theta_{0}$, i.e., with density\n$$\nf(z) = \\frac{1}{\\theta_{0}} \\exp\\left(-\\frac{z}{\\theta_{0}}\\right), \\quad z \\geq 0.\n$$\nTherefore, the limiting Laplace transform exists and equals the Laplace transform of this exponential law:\n$$\n\\lim_{n \\to \\infty} \\mathbb{E}\\big[\\exp(-s Z_{n})\\big] = \\int_{0}^{\\infty} \\exp(-s z) \\,\\frac{1}{\\theta_{0}} \\exp\\left(-\\frac{z}{\\theta_{0}}\\right) \\,\\mathrm{d}z = \\frac{1}{1 + s \\theta_{0}}, \\quad s \\geq 0.\n$$\n\nFinally, we discuss the failure of classical $\\sqrt{n}$-asymptotic normality for the MLE $\\hat{\\theta}_{n}$. In regular parametric models with parameter-independent support and differentiable log-likelihood, the Maximum Likelihood Estimator (MLE) is typically asymptotically normal with $\\sqrt{n}$ scaling, i.e., $\\sqrt{n}(\\hat{\\theta}_{n} - \\theta_{0}) \\Rightarrow \\mathcal{N}(0, I(\\theta_{0})^{-1})$, where $I(\\theta_{0})$ is Fisher information. Here, the support depends on $\\theta$ and the log-likelihood is non-differentiable at $\\theta = M_{n}$, violating regularity. The derived limit shows that the correct scaling is $n$ rather than $\\sqrt{n}$, and the limiting distribution is exponential rather than Gaussian. Hence, the classical asymptotic normality fails in this inverse problem data assimilation example due to parameter-dependent support and non-differentiability of the log-likelihood.", "answer": "$$\\boxed{\\frac{1}{1 + s \\theta_{0}}}$$", "id": "3402145"}, {"introduction": "In modern data assimilation, we often seek to estimate parameters within complex, dynamic models, such as those described by state-space formalisms and the Kalman filter. This requires optimizing the likelihood function with respect to model parameters, a task that hinges on efficiently computing its gradient. This advanced practice guides you through the derivation and implementation of the likelihood gradient for the observation error covariance $R$, introducing you to the powerful forward sensitivity method, which is conceptually similar to the backpropagation algorithms that drive modern machine learning [@problem_id:3402165].", "problem": "Consider a linear, time-invariant, discrete-time, Gaussian state-space model with state dimension $n$ and observation dimension $m$:\n- State dynamics: $x_{t+1} = A x_t + w_t$, where $w_t \\sim \\mathcal{N}(0, Q)$ and $Q \\in \\mathbb{R}^{n \\times n}$ is symmetric positive definite.\n- Observation model: $y_t = H x_t + v_t$, where $v_t \\sim \\mathcal{N}(0, R)$ and $R \\in \\mathbb{R}^{m \\times m}$ is symmetric positive definite.\n\nLet the Kalman filter be run with the standard predict-update recursions using a given initial posterior mean $x_{0|0}$ and covariance $P_{0|0}$. Denote the one-step-ahead predicted mean and covariance by $x_{t|t-1}$ and $P_{t|t-1}$. Define the innovation $e_t = y_t - H x_{t|t-1}$ and its covariance $S_t = H P_{t|t-1} H^\\top + R$. The negative innovations log-likelihood (dropping the additive constant independent of $R$) over a time window $t=1,\\dots,T$ is\n$$\nJ(R) = \\frac{1}{2} \\sum_{t=1}^{T} \\left[ \\log \\det S_t + e_t^\\top S_t^{-1} e_t \\right].\n$$\n\nTask: Derive, from first principles using the definitions of the Kalman filter and standard matrix calculus identities, how to compute the gradient of $J(R)$ with respect to $R$ using either:\n- discrete-time forward sensitivity equations that propagate derivatives of $x_{t|t-1}$ and $P_{t|t-1}$ with respect to the entries of $R$, or\n- reverse-mode differentiation (backpropagation) through the Kalman filter recursions.\n\nYour program must implement one correct approach (either forward sensitivity or backpropagation) and compute the gradient of $J(R)$ with respect to a parameterization of $R$ as specified in the test suite below.\n\nFundamental base for derivation:\n- The Kalman filter predict-update definitions for $x_{t|t-1}$, $P_{t|t-1}$, $x_{t|t}$, $P_{t|t}$, the innovation $e_t$, covariance $S_t$, and gain $K_t$.\n- Matrix calculus identities: $\\mathrm{d} \\log \\det S = \\mathrm{tr}(S^{-1} \\mathrm{d}S)$ and $\\mathrm{d} S^{-1} = - S^{-1} (\\mathrm{d}S) S^{-1}$.\n\nAngle units are not applicable. There are no physical units.\n\nTest suite:\nImplement the computation of the gradient for the following three test cases. For each case, compute the gradient(s) of $J(R)$ with respect to the specified parameter(s) of $R$, using the initial posterior $(x_{0|0}, P_{0|0})$ at time $t=0$, followed by the standard predict step to obtain $(x_{1|0}, P_{1|0})$ before incorporating $y_1$.\n\n- Case 1 (scalar observation, scalar parameter):\n  - Dimensions: $n=2$, $m=1$, $T=5$.\n  - $A = \\begin{bmatrix} 0.9  0.1 \\\\ 0  0.7 \\end{bmatrix}$, $H = \\begin{bmatrix} 1.0  0.5 \\end{bmatrix}$.\n  - $Q = \\begin{bmatrix} 0.05  0 \\\\ 0  0.02 \\end{bmatrix}$.\n  - Initial posterior: $x_{0|0} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$, $P_{0|0} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$.\n  - Observations: $y_1=0.8$, $y_2=0.4$, $y_3=-0.2$, $y_4=0.1$, $y_5=0.0$.\n  - Parameterization: $R = r I_1$ with $r = 0.5$.\n  - Output for this case: a single float equal to $\\frac{\\partial J}{\\partial r}$.\n\n- Case 2 (near-degenerate observation noise, scalar parameter):\n  - Same as Case 1 except the parameterization is $R = r I_1$ with $r = 10^{-6}$.\n  - Output for this case: a single float equal to $\\frac{\\partial J}{\\partial r}$.\n\n- Case 3 (two-dimensional observation, diagonal parameterization):\n  - Dimensions: $n=2$, $m=2$, $T=4$.\n  - $A = \\begin{bmatrix} 1.0  0.2 \\\\ 0  0.9 \\end{bmatrix}$, $H = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$.\n  - $Q = \\begin{bmatrix} 0.1  0 \\\\ 0  0.1 \\end{bmatrix}$.\n  - Initial posterior: $x_{0|0} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$, $P_{0|0} = \\begin{bmatrix} 0.5  0 \\\\ 0  0.5 \\end{bmatrix}$.\n  - Observations (column vectors): $y_1=\\begin{bmatrix} 0.1 \\\\ -0.1 \\end{bmatrix}$, $y_2=\\begin{bmatrix} 0.2 \\\\ 0.0 \\end{bmatrix}$, $y_3=\\begin{bmatrix} 0.0 \\\\ 0.1 \\end{bmatrix}$, $y_4=\\begin{bmatrix} -0.1 \\\\ 0.2 \\end{bmatrix}$.\n  - Parameterization: $R = \\mathrm{diag}(r_1, r_2)$ with $(r_1, r_2) = (0.05, 0.2)$.\n  - Output for this case: a list of two floats $[\\frac{\\partial J}{\\partial r_1}, \\frac{\\partial J}{\\partial r_2}]$.\n\nRequirements:\n- Your derivation must start from the Kalman filter definitions and the listed matrix calculus identities, without citing or using any pre-derived gradient formulas.\n- Your implementation may use either forward sensitivity propagation or backpropagation through the filter recursions, but it must be exact up to floating-point arithmetic.\n- Numerical stability: use symmetric positive definite operations where appropriate; ensure $S_t$ is treated as invertible.\n\nFinal Output Format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The first two entries are floats for Cases 1 and 2, and the third entry is a list of two floats for Case 3. For example: \"[g1,g2,[g3_1,g3_2]]\".\n- Each float must be rounded to six decimal places (use standard rounding to nearest, with halfway cases rounded away from zero or to nearest even depending on your language's default).", "solution": "The user wants to compute the gradient of the negative log-likelihood function, $J(R)$, for a linear Gaussian state-space model with respect to parameters in the observation noise covariance matrix, $R$. The derivation will be based on the forward sensitivity analysis method, which propagates the derivatives of the Kalman filter states alongside the states themselves.\n\n### 1. Preliminaries: Kalman Filter and Cost Function\n\nFirst, we state the definitions for the discrete-time Kalman filter. Given a state-space model:\n- State dynamics: $x_{t+1} = A x_t + w_t$, with $w_t \\sim \\mathcal{N}(0, Q)$\n- Observation model: $y_t = H x_t + v_t$, with $v_t \\sim \\mathcal{N}(0, R)$\n\nThe Kalman filter recursions proceed as follows for $t=1, \\dots, T$, starting with an initial posterior estimate $x_{0|0}$ and its covariance $P_{0|0}$.\n\n**Predict Step:**\n$$x_{t|t-1} = A x_{t-1|t-1}$$\n$$P_{t|t-1} = A P_{t-1|t-1} A^\\top + Q$$\n\n**Update Step:**\n$$e_t = y_t - H x_{t|t-1} \\quad (\\text{Innovation})$$\n$$S_t = H P_{t|t-1} H^\\top + R \\quad (\\text{Innovation Covariance})$$\n$$K_t = P_{t|t-1} H^\\top S_t^{-1} \\quad (\\text{Kalman Gain})$$\n$$x_{t|t} = x_{t|t-1} + K_t e_t \\quad (\\text{Updated State Mean})$$\n$$P_{t|t} = (I - K_t H) P_{t|t-1} \\quad (\\text{Updated State Covariance})$$\n\nThe negative log-likelihood function to be minimized (equivalent to maximizing the likelihood) with respect to $R$ is given as:\n$$J(R) = \\frac{1}{2} \\sum_{t=1}^{T} \\left[ \\log \\det S_t + e_t^\\top S_t^{-1} e_t \\right]$$\n\n### 2. Gradient Derivation via Forward Sensitivity Analysis\n\nWe aim to compute the gradient of $J(R)$ with respect to a scalar parameter $\\theta$ upon which $R$ depends. Let $X'$ denote the derivative of a quantity $X$ with respect to $\\theta$, i.e., $X' = \\frac{\\mathrm{d}X}{\\mathrm{d}\\theta}$.\n\nThe total gradient is the sum of gradients from each time step:\n$$\\frac{\\mathrm{d}J}{\\mathrm{d}\\theta} = \\sum_{t=1}^{T} \\frac{\\mathrm{d}J_t}{\\mathrm{d}\\theta}, \\quad \\text{where } J_t = \\frac{1}{2} \\left[ \\log \\det S_t + e_t^\\top S_t^{-1} e_t \\right]$$\n\nTo find the expression for $\\frac{\\mathrm{d}J_t}{\\mathrm{d}\\theta}$, we use the chain rule and standard matrix calculus identities: $\\mathrm{d} \\log \\det S = \\mathrm{tr}(S^{-1} \\mathrm{d}S)$ and $\\mathrm{d} S^{-1} = -S^{-1} (\\mathrm{d}S) S^{-1}$.\n\nThe differential of $J_t$ is:\n$$\\mathrm{d}J_t = \\frac{1}{2} \\left[ \\mathrm{d}(\\log \\det S_t) + \\mathrm{d}(e_t^\\top S_t^{-1} e_t) \\right]$$\n$$\\mathrm{d}J_t = \\frac{1}{2} \\left[ \\mathrm{tr}(S_t^{-1} \\mathrm{d}S_t) + (\\mathrm{d}e_t^\\top) S_t^{-1} e_t + e_t^\\top (\\mathrm{d}S_t^{-1}) e_t + e_t^\\top S_t^{-1} \\mathrm{d}e_t \\right]$$\nSince $e_t^\\top S_t^{-1} \\mathrm{d}e_t$ is a scalar, it equals its transpose $\\mathrm{d}e_t^\\top S_t^{-1} e_t$.\n$$\\mathrm{d}J_t = \\frac{1}{2} \\left[ \\mathrm{tr}(S_t^{-1} \\mathrm{d}S_t) + 2 e_t^\\top S_t^{-1} \\mathrm{d}e_t - e_t^\\top S_t^{-1} (\\mathrm{d}S_t) S_t^{-1} e_t \\right]$$\nUsing the trace identity $u^\\top M v = \\mathrm{tr}(v u^\\top M)$:\n$$e_t^\\top S_t^{-1} (\\mathrm{d}S_t) S_t^{-1} e_t = \\mathrm{tr}( S_t^{-1} e_t e_t^\\top S_t^{-1} \\mathrm{d}S_t )$$\nSubstituting this back, we can group terms involving $\\mathrm{d}S_t$:\n$$\\mathrm{d}J_t = \\mathrm{tr}\\left( \\frac{1}{2} (S_t^{-1} - S_t^{-1} e_t e_t^\\top S_t^{-1}) \\mathrm{d}S_t \\right) + e_t^\\top S_t^{-1} \\mathrm{d}e_t$$\nDividing by $\\mathrm{d}\\theta$, we obtain the gradient for a single time step:\n$$\\frac{\\mathrm{d}J_t}{\\mathrm{d}\\theta} = \\mathrm{tr}\\left( \\frac{1}{2} (S_t^{-1} - S_t^{-1} e_t e_t^\\top S_t^{-1}) S_t' \\right) + e_t^\\top S_t^{-1} e_t'$$\nThis expression depends on the sensitivities $S_t' = \\frac{\\mathrm{d}S_t}{\\mathrm{d}\\theta}$ and $e_t' = \\frac{\\mathrm{d}e_t}{\\mathrm{d}\\theta}$. To calculate these, we must propagate the sensitivities of the Kalman filter states through the recursions.\n\n### 3. Sensitivity Propagation Equations\n\nWe derive the propagation equations for the sensitivities by differentiating the Kalman filter equations with respect to $\\theta$. The initial sensitivities are zero: $x'_{0|0} = 0$ and $P'_{0|0} = 0$, as the initial state is assumed not to depend on $R$.\n\n**Sensitivity Predict Step:**\n$$x'_{t|t-1} = \\frac{\\mathrm{d}}{\\mathrm{d}\\theta}(A x_{t-1|t-1}) = A x'_{t-1|t-1}$$\n$$P'_{t|t-1} = \\frac{\\mathrm{d}}{\\mathrm{d}\\theta}(A P_{t-1|t-1} A^\\top + Q) = A P'_{t-1|t-1} A^\\top$$\n(since $A$ and $Q$ do not depend on $\\theta$).\n\n**Sensitivity Update Step:**\nFirst, we find the sensitivities of the innovation and its covariance. Note that the observation $y_t$ is constant data.\n$$e'_t = \\frac{\\mathrm{d}}{\\mathrm{d}\\theta}(y_t - H x_{t|t-1}) = -H x'_{t|t-1}$$\n$$S'_t = \\frac{\\mathrm{d}}{\\mathrm{d}\\theta}(H P_{t|t-1} H^\\top + R) = H P'_{t|t-1} H^\\top + R'$$\nwhere $R' = \\frac{\\mathrm{d}R}{\\mathrm{d}\\theta}$.\n\nNext, we differentiate the Kalman gain $K_t$:\n$$K'_t = \\frac{\\mathrm{d}}{\\mathrm{d}\\theta}(P_{t|t-1} H^\\top S_t^{-1}) = P'_{t|t-1} H^\\top S_t^{-1} + P_{t|t-1} H^\\top (S_t^{-1})'$$\n$$K'_t = P'_{t|t-1} H^\\top S_t^{-1} - P_{t|t-1} H^\\top S_t^{-1} S'_t S_t^{-1} = P'_{t|t-1} H^\\top S_t^{-1} - K_t S'_t S_t^{-1}$$\n\nFinally, we find the sensitivities of the posterior state and covariance:\n$$x'_{t|t} = \\frac{\\mathrm{d}}{\\mathrm{d}\\theta}(x_{t|t-1} + K_t e_t) = x'_{t|t-1} + K'_t e_t + K_t e'_t$$\n$$P'_{t|t} = \\frac{\\mathrm{d}}{\\mathrm{d}\\theta}((I - K_t H) P_{t|t-1}) = -K'_t H P_{t|t-1} + (I - K_t H) P'_{t|t-1}$$\n\n### 4. Algorithm Summary\n\nFor each parameter $\\theta_k$ of $R$:\n1.  Initialize filter states $x_{0|0}$, $P_{0|0}$ and sensitivity states $x'_{0|0}=0$, $P'_{0|0}=0$.\n2.  Initialize total gradient $\\frac{\\mathrm{d}J}{\\mathrm{d}\\theta_k} = 0$.\n3.  Compute $R'_k = \\frac{\\partial R}{\\partial \\theta_k}$.\n4.  For $t = 1, \\dots, T$:\n    a. Run a single step of the standard Kalman filter (predict and update) to compute $x_{t|t}$, $P_{t|t}$, and all intermediate quantities ($e_t, S_t, K_t$, etc.).\n    b. Run a single step of the sensitivity propagation equations (predict and update) to compute $x'_{t|t}$ and $P'_{t|t}$, using the values from the standard filter.\n    c. Compute the gradient contribution at time $t$, $\\frac{\\mathrm{d}J_t}{\\mathrm{d}\\theta_k}$, using the formula derived in Section 2.\n    d. Add this contribution to the total gradient: $\\frac{\\mathrm{d}J}{\\mathrm{d}\\theta_k} \\mathrel{+}= \\frac{\\mathrm{d}J_t}{\\mathrm{d}\\theta_k}$.\n5.  The final sum is the desired gradient $\\frac{\\partial J}{\\partial \\theta_k}$.\n\nThis procedure provides an exact gradient and is implemented in the provided code. To ensure numerical stability, the covariance matrices $P_{t|t}$ and $P'_{t|t}$ are explicitly symmetrized after each update.", "answer": "```python\nimport numpy as np\n\ndef custom_round(val: float, ndigits: int = 6) - float:\n    \"\"\"\n    Rounds a float to a specified number of decimal places, with halfway cases\n    rounded away from zero.\n    \"\"\"\n    if val == 0:\n        return 0.0\n    factor = 10**ndigits\n    return (int(val * factor + 0.5 * np.sign(val))) / factor\n\ndef compute_gradient(case_data: dict) - list[float] | float:\n    \"\"\"\n    Computes the gradient of the negative log-likelihood J(R) with respect to\n    parameters of R using forward sensitivity analysis.\n    \"\"\"\n    A = case_data['A']\n    H = case_data['H']\n    Q = case_data['Q']\n    x00 = case_data['x00']\n    P00 = case_data['P00']\n    y_obs = case_data['y']\n    T = case_data['T']\n    n = case_data['n']\n    \n    param_values = case_data['param_values']\n    param_names = case_data['param_names']\n    \n    gradients = []\n    \n    for i, _ in enumerate(param_names):\n        # Re-initialize for each parameter's gradient calculation\n        x_post = x00.copy()\n        P_post = P00.copy()\n        \n        x_prime_post = np.zeros_like(x00)\n        P_prime_post = np.zeros_like(P00)\n        \n        total_gradient = 0.0\n        \n        for t in range(T):\n            # Form R and R' for the current parameter\n            if case_data['id'] == 3: # Case 3: R=diag(r1, r2)\n                R_val_arr = np.array(param_values)\n                R = np.diag(R_val_arr)\n                R_prime_diag = np.zeros_like(R_val_arr)\n                R_prime_diag[i] = 1.0\n                R_prime = np.diag(R_prime_diag)\n            else: # Case 1  2: R = r * I\n                r_val = param_values[0]\n                R = np.array([[r_val]])\n                R_prime = np.array([[1.0]])\n\n            y_t = y_obs[t]\n            \n            # --- Standard Filter Step ---\n            # Predict\n            x_prior = A @ x_post\n            P_prior = A @ P_post @ A.T + Q\n            \n            # --- Sensitivity Filter Step ---\n            # Predict\n            x_prime_prior = A @ x_prime_post\n            P_prime_prior = A @ P_prime_post @ A.T\n            \n            # --- Standard Filter Update ---\n            e_t = y_t - H @ x_prior\n            S_t = H @ P_prior @ H.T + R\n            try:\n                S_t_inv = np.linalg.inv(S_t)\n            except np.linalg.LinAlgError:\n                # Add jitter for numerical stability if S_t is singular\n                S_t_inv = np.linalg.inv(S_t + np.eye(S_t.shape[0]) * 1e-12)\n\n            K_t = P_prior @ H.T @ S_t_inv\n            \n            # --- Sensitivity of Update Terms ---\n            e_prime_t = -H @ x_prime_prior\n            S_prime_t = H @ P_prime_prior @ H.T + R_prime\n            K_prime_t = P_prime_prior @ H.T @ S_t_inv - K_t @ S_prime_t @ S_t_inv\n            \n            # --- Gradient Calculation ---\n            # grad(J_t) = 0.5 * [tr(S_inv * S') - e.T*S_inv*S'*S_inv*e + 2*e.T*S_inv*e']\n            grad_Jt_term1 = np.trace(S_t_inv @ S_prime_t)\n            grad_Jt_term2 = -e_t.T @ S_t_inv @ S_prime_t @ S_t_inv @ e_t\n            grad_Jt_term3 = 2 * e_t.T @ S_t_inv @ e_prime_t\n            grad_Jt = 0.5 * (grad_Jt_term1 + grad_Jt_term2 + grad_Jt_term3)\n            \n            total_gradient += grad_Jt.item()\n\n            # --- Update Filter States ---\n            x_post = x_prior + K_t @ e_t\n            P_post_temp = (np.eye(n) - K_t @ H) @ P_prior\n            P_post = 0.5 * (P_post_temp + P_post_temp.T) # Enforce symmetry\n            \n            # --- Update Sensitivity States ---\n            x_prime_post = x_prime_prior + K_prime_t @ e_t + K_t @ e_prime_t\n            P_prime_post_temp = (np.eye(n) - K_t @ H) @ P_prime_prior - K_prime_t @ H @ P_prior\n            P_prime_post = 0.5 * (P_prime_post_temp + P_prime_post_temp.T) # Enforce symmetry\n            \n        gradients.append(custom_round(total_gradient, 6))\n\n    return gradients[0] if len(gradients) == 1 else gradients\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run computations, and print results.\n    \"\"\"\n    test_cases = [\n        {\n            'id': 1,\n            'n': 2, 'm': 1, 'T': 5,\n            'A': np.array([[0.9, 0.1], [0, 0.7]]),\n            'H': np.array([[1.0, 0.5]]),\n            'Q': np.array([[0.05, 0], [0, 0.02]]),\n            'x00': np.array([[0], [0]]),\n            'P00': np.array([[1, 0], [0, 1]]),\n            'y': [np.array([[v]]) for v in [0.8, 0.4, -0.2, 0.1, 0.0]],\n            'param_names': ['r'],\n            'param_values': [0.5]\n        },\n        {\n            'id': 2,\n            'n': 2, 'm': 1, 'T': 5,\n            'A': np.array([[0.9, 0.1], [0, 0.7]]),\n            'H': np.array([[1.0, 0.5]]),\n            'Q': np.array([[0.05, 0], [0, 0.02]]),\n            'x00': np.array([[0], [0]]),\n            'P00': np.array([[1, 0], [0, 1]]),\n            'y': [np.array([[v]]) for v in [0.8, 0.4, -0.2, 0.1, 0.0]],\n            'param_names': ['r'],\n            'param_values': [1e-6]\n        },\n        {\n            'id': 3,\n            'n': 2, 'm': 2, 'T': 4,\n            'A': np.array([[1.0, 0.2], [0, 0.9]]),\n            'H': np.array([[1, 0], [0, 1]]),\n            'Q': np.array([[0.1, 0], [0, 0.1]]),\n            'x00': np.array([[0], [0]]),\n            'P00': np.array([[0.5, 0], [0, 0.5]]),\n            'y': [np.array([[0.1], [-0.1]]), np.array([[0.2], [0.0]]), \n                  np.array([[0.0], [0.1]]), np.array([[ -0.1], [0.2]])],\n            'param_names': ['r1', 'r2'],\n            'param_values': [0.05, 0.2]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = compute_gradient(case)\n        results.append(result)\n    \n    # Format the final output string exactly as required\n    result_str = f\"[{results[0]},{results[1]},{results[2]}]\"\n    print(result_str)\n\nsolve()\n```", "id": "3402165"}]}