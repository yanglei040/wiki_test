{"hands_on_practices": [{"introduction": "The heart of any Markov chain Monte Carlo method is the mechanism that decides whether to accept a proposed new state or remain at the current one. This exercise provides a concrete, step-by-step calculation of the Metropolis-Hastings acceptance probability, demystifying the core engine of MCMC sampling [@problem_id:3400306]. By working with a non-Gaussian Laplace noise model, you will see how the data misfit term naturally takes the form of an $\\ell_1$ norm, connecting the algorithm to principles of robust statistics.", "problem": "Consider a linear inverse problem in which the observed data vector $y \\in \\mathbb{R}^{2}$ is related to an unknown parameter vector $x \\in \\mathbb{R}^{2}$ through a forward operator $G \\in \\mathbb{R}^{2 \\times 2}$ and additive noise, $y = G x + \\varepsilon$. Assume the noise components $\\varepsilon_{i}$ are independent and identically distributed according to the Laplace distribution with zero mean and known scale parameter $b  0$, so that each component has density $p(\\varepsilon_{i}) = \\frac{1}{2 b} \\exp\\!\\big(-|\\varepsilon_{i}|/b\\big)$. Assume a Gaussian prior $x \\sim \\mathcal{N}(m, C)$, where $m \\in \\mathbb{R}^{2}$ and $C \\in \\mathbb{R}^{2 \\times 2}$ is symmetric positive definite. You will use the Bayesian posterior to construct a Metropolis–Hastings (MH) step with a symmetric random-walk proposal.\n\nUse the following concrete specification:\n- $G = \\begin{pmatrix} 2  -1 \\\\ 0.5  1 \\end{pmatrix}$,\n- $y = \\begin{pmatrix} 1.2 \\\\ -0.3 \\end{pmatrix}$,\n- $b = 0.25$,\n- $m = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$,\n- $C = \\begin{pmatrix} 1  0 \\\\ 0  4 \\end{pmatrix}$,\n- current state $x^{(k)} = \\begin{pmatrix} 0.2 \\\\ -0.4 \\end{pmatrix}$,\n- proposed state $x' = \\begin{pmatrix} 0.5 \\\\ -0.7 \\end{pmatrix}$,\n- the proposal is symmetric in the sense that $q(x' \\mid x^{(k)}) = q(x^{(k)} \\mid x')$.\n\nTasks:\n1. Starting from the Laplace density and the independence of $\\varepsilon_{i}$, derive the data-dependent negative log-likelihood $\\Phi(x)$ (defined up to an additive constant independent of $x$), and then evaluate $\\Phi(x^{(k)})$ and $\\Phi(x')$ numerically for the given values.\n2. Using Bayes’ rule and the Gaussian prior, define the prior potential $\\Psi(x) = \\frac{1}{2} (x - m)^{\\top} C^{-1} (x - m)$, and derive an explicit expression for the Metropolis–Hastings acceptance ratio $r = \\frac{\\pi(x' \\mid y)}{\\pi(x^{(k)} \\mid y)}$ in terms of $\\Phi$ and $\\Psi$. Evaluate $r$ numerically for the given values and compute the acceptance probability $\\alpha = \\min\\{1, r\\}$.\n\nExpress the final acceptance probability $\\alpha$ as a decimal and round your answer to four significant figures. No units are required.", "solution": "The user has provided a well-defined Bayesian inverse problem and asks for the computation of the Metropolis-Hastings acceptance probability for a specific state transition. The problem is scientifically and mathematically sound, self-contained, and all necessary data and definitions are provided. We proceed with the solution.\n\n### Task 1: Negative Log-Likelihood\n\nThe problem specifies that the noise components $\\varepsilon_i$ are independent and identically distributed according to a Laplace distribution with zero mean and scale parameter $b$. The probability density for a single noise component is $p(\\varepsilon_i) = \\frac{1}{2b}\\exp(-|\\varepsilon_i|/b)$. Given the independence, the joint probability density for the noise vector $\\varepsilon = \\begin{pmatrix} \\varepsilon_1  \\varepsilon_2 \\end{pmatrix}^\\top$ is the product of the individual densities:\n$$ p(\\varepsilon) = p(\\varepsilon_1) p(\\varepsilon_2) = \\left(\\frac{1}{2b}\\exp\\left(-\\frac{|\\varepsilon_1|}{b}\\right)\\right) \\left(\\frac{1}{2b}\\exp\\left(-\\frac{|\\varepsilon_2|}{b}\\right)\\right) = \\frac{1}{4b^2}\\exp\\left(-\\frac{|\\varepsilon_1| + |\\varepsilon_2|}{b}\\right) $$\nIn terms of the $L_1$ norm, where $\\|\\varepsilon\\|_1 = |\\varepsilon_1| + |\\varepsilon_2|$, this is:\n$$ p(\\varepsilon) = \\frac{1}{4b^2}\\exp\\left(-\\frac{\\|\\varepsilon\\|_1}{b}\\right) $$\nThe likelihood function $p(y|x)$ is the probability density of the observation $y$ given the parameter $x$. This is equivalent to the probability density of the noise $\\varepsilon = y - Gx$:\n$$ p(y|x) = \\frac{1}{4b^2}\\exp\\left(-\\frac{\\|y - Gx\\|_1}{b}\\right) $$\nThe negative log-likelihood is $-\\ln(p(y|x))$:\n$$ -\\ln(p(y|x)) = -\\ln\\left(\\frac{1}{4b^2}\\right) - \\ln\\left(\\exp\\left(-\\frac{\\|y - Gx\\|_1}{b}\\right)\\right) = \\ln(4b^2) + \\frac{1}{b}\\|y - Gx\\|_1 $$\nThe problem defines the negative log-likelihood $\\Phi(x)$ up to an additive constant that is independent of $x$. We can therefore drop the term $\\ln(4b^2)$ and define $\\Phi(x)$ as:\n$$ \\Phi(x) = \\frac{1}{b}\\|y - Gx\\|_1 $$\nNow we evaluate $\\Phi(x)$ for the current state $x^{(k)}$ and the proposed state $x'$. The given values are $G = \\begin{pmatrix} 2  -1 \\\\ 0.5  1 \\end{pmatrix}$, $y = \\begin{pmatrix} 1.2 \\\\ -0.3 \\end{pmatrix}$, $b = 0.25$, $x^{(k)} = \\begin{pmatrix} 0.2 \\\\ -0.4 \\end{pmatrix}$, and $x' = \\begin{pmatrix} 0.5 \\\\ -0.7 \\end{pmatrix}$.\n\nFor the current state $x^{(k)}$:\n$$ Gx^{(k)} = \\begin{pmatrix} 2  -1 \\\\ 0.5  1 \\end{pmatrix} \\begin{pmatrix} 0.2 \\\\ -0.4 \\end{pmatrix} = \\begin{pmatrix} 2(0.2) - 1(-0.4) \\\\ 0.5(0.2) + 1(-0.4) \\end{pmatrix} = \\begin{pmatrix} 0.8 \\\\ -0.3 \\end{pmatrix} $$\n$$ y - Gx^{(k)} = \\begin{pmatrix} 1.2 \\\\ -0.3 \\end{pmatrix} - \\begin{pmatrix} 0.8 \\\\ -0.3 \\end{pmatrix} = \\begin{pmatrix} 0.4 \\\\ 0 \\end{pmatrix} $$\n$$ \\|y - Gx^{(k)}\\|_1 = |0.4| + |0| = 0.4 $$\n$$ \\Phi(x^{(k)}) = \\frac{1}{0.25} \\|y - Gx^{(k)}\\|_1 = 4 \\times 0.4 = 1.6 $$\n\nFor the proposed state $x'$:\n$$ Gx' = \\begin{pmatrix} 2  -1 \\\\ 0.5  1 \\end{pmatrix} \\begin{pmatrix} 0.5 \\\\ -0.7 \\end{pmatrix} = \\begin{pmatrix} 2(0.5) - 1(-0.7) \\\\ 0.5(0.5) + 1(-0.7) \\end{pmatrix} = \\begin{pmatrix} 1.7 \\\\ -0.45 \\end{pmatrix} $$\n$$ y - Gx' = \\begin{pmatrix} 1.2 \\\\ -0.3 \\end{pmatrix} - \\begin{pmatrix} 1.7 \\\\ -0.45 \\end{pmatrix} = \\begin{pmatrix} -0.5 \\\\ 0.15 \\end{pmatrix} $$\n$$ \\|y - Gx'\\|_1 = |-0.5| + |0.15| = 0.5 + 0.15 = 0.65 $$\n$$ \\Phi(x') = \\frac{1}{0.25} \\|y - Gx'\\|_1 = 4 \\times 0.65 = 2.6 $$\n\n### Task 2: Prior Potential and Acceptance Probability\n\nThe prior potential is given as $\\Psi(x) = \\frac{1}{2}(x - m)^{\\top}C^{-1}(x - m)$. The prior mean is $m = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$ and the prior covariance is $C = \\begin{pmatrix} 1  0 \\\\ 0  4 \\end{pmatrix}$. The inverse of the covariance matrix is:\n$$ C^{-1} = \\begin{pmatrix} 1^{-1}  0 \\\\ 0  4^{-1} \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  0.25 \\end{pmatrix} $$\nWith $m = 0$, the prior potential simplifies to $\\Psi(x) = \\frac{1}{2}x^{\\top}C^{-1}x$. For $x = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$:\n$$ \\Psi(x) = \\frac{1}{2} \\begin{pmatrix} x_1  x_2 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  0.25 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \\frac{1}{2}(x_1^2 + 0.25x_2^2) $$\nWe evaluate $\\Psi(x)$ for $x^{(k)}$ and $x'$.\n\nFor the current state $x^{(k)} = \\begin{pmatrix} 0.2 \\\\ -0.4 \\end{pmatrix}$:\n$$ \\Psi(x^{(k)}) = \\frac{1}{2}((0.2)^2 + 0.25(-0.4)^2) = \\frac{1}{2}(0.04 + 0.25(0.16)) = \\frac{1}{2}(0.04 + 0.04) = 0.04 $$\n\nFor the proposed state $x' = \\begin{pmatrix} 0.5 \\\\ -0.7 \\end{pmatrix}$:\n$$ \\Psi(x') = \\frac{1}{2}((0.5)^2 + 0.25(-0.7)^2) = \\frac{1}{2}(0.25 + 0.25(0.49)) = \\frac{1}{2}(0.25 + 0.1225) = \\frac{1}{2}(0.3725) = 0.18625 $$\n\nThe posterior distribution $\\pi(x|y)$ is, by Bayes' rule, proportional to the product of the likelihood and the prior: $\\pi(x|y) \\propto p(y|x)p(x)$. In terms of the negative potentials, $p(y|x) \\propto \\exp(-\\Phi(x))$ and $p(x) \\propto \\exp(-\\Psi(x))$. Therefore:\n$$ \\pi(x|y) \\propto \\exp(-(\\Phi(x) + \\Psi(x))) $$\nThe Metropolis-Hastings acceptance ratio $r$ for a symmetric proposal distribution is the ratio of the posterior probabilities:\n$$ r = \\frac{\\pi(x'|y)}{\\pi(x^{(k)}|y)} = \\frac{\\exp(-(\\Phi(x') + \\Psi(x')))}{\\exp(-(\\Phi(x^{(k)}) + \\Psi(x^{(k)})))} = \\exp((\\Phi(x^{(k)}) + \\Psi(x^{(k)})) - (\\Phi(x') + \\Psi(x'))) $$\nSubstituting the numerical values we computed:\n$$ \\Phi(x^{(k)}) = 1.6 \\quad , \\quad \\Psi(x^{(k)}) = 0.04 $$\n$$ \\Phi(x') = 2.6 \\quad , \\quad \\Psi(x') = 0.18625 $$\nThe exponent of $r$ is:\n$$ (1.6 + 0.04) - (2.6 + 0.18625) = 1.64 - 2.78625 = -1.14625 $$\nSo, the acceptance ratio is:\n$$ r = \\exp(-1.14625) \\approx 0.31780517 $$\nThe acceptance probability $\\alpha$ is defined as $\\alpha = \\min\\{1, r\\}$. Since $r  1$:\n$$ \\alpha = r = \\exp(-1.14625) \\approx 0.31780517 $$\nRounding to four significant figures as requested gives $\\alpha \\approx 0.3178$.", "answer": "$$\n\\boxed{0.3178}\n$$", "id": "3400306"}, {"introduction": "Generating a long sequence of samples from the posterior is only the first step; we must also critically assess the quality and efficiency of our MCMC sampler. Since successive samples in the chain are correlated, not all of them provide new information. This practice delves into the essential post-processing analysis of MCMC output, guiding you through the derivation of the integrated autocorrelation time ($\\tau_{\\mathrm{int}}$), a crucial metric that quantifies the number of correlated samples equivalent to a single independent draw [@problem_id:3400386].", "problem": "Consider a linear Gaussian inverse problem with unknown parameter field $u \\in \\mathbb{R}^{d}$, data $y \\in \\mathbb{R}^{m}$, forward operator $A \\in \\mathbb{R}^{m \\times d}$, and additive noise $y = A u + \\eta$, where $\\eta \\sim \\mathcal{N}(0, \\Gamma_{\\eta})$ and $u \\sim \\mathcal{N}(m_{0}, \\Gamma_{0})$. A Markov chain Monte Carlo (MCMC) method is used to sample from the posterior distribution of $u$ given $y$. Consider a scalar summary $f(u)$, such as a linear functional $f(u) = \\ell^{\\top} u$ with $\\ell \\in \\mathbb{R}^{d}$. Assume the Markov chain for $f(u)$ is strictly stationary and ergodic and, for the purpose of analysis, can be approximated by a Gaussian autoregressive process of order one, $\\text{AR}(1)$, with autoregressive parameter $\\phi \\in (-1,1)$:\n$$\nx_{n} = \\phi \\, x_{n-1} + \\epsilon_{n}, \\quad \\epsilon_{n} \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^{2}), \\quad n \\geq 1,\n$$\nwhere $x_{n} := f(u_{n})$ denotes the scalar summary along the Markov chain in stationarity.\n\nYou are told that for the chain under consideration, the autoregressive coefficient is $\\phi = 0.75$ and the stationary variance $\\mathrm{Var}(x_{n}) = \\sigma_{x}^{2}$ is finite and positive. Starting from the fundamental definitions of autocovariance and variance of the sample mean of a correlated stationary sequence, and without assuming any target formulas:\n\n1. Define the lag-$k$ autocorrelation function for the scalar summary $f(u)$ along the chain, and, under the $\\text{AR}(1)$ approximation, derive the exact expression for the lag-$k$ autocorrelation in terms of $\\phi$.\n\n2. Starting from the variance of the sample mean $\\bar{x}_{N} = \\frac{1}{N} \\sum_{n=1}^{N} x_{n}$ for a stationary correlated sequence, derive the concept of an integrated autocorrelation time, denoted by $\\tau_{\\mathrm{int}}$, such that the variance of $\\bar{x}_{N}$ can be written as $\\mathrm{Var}(\\bar{x}_{N}) \\approx \\sigma_{x}^{2} \\, \\tau_{\\mathrm{int}} / N$ for large $N$, and express $\\tau_{\\mathrm{int}}$ in terms of the lag-$k$ autocorrelations.\n\n3. Propose a finite-sample, bias-corrected estimator for $\\tau_{\\mathrm{int}}$ based on the unbiased sample autocovariances\n$$\n\\hat{\\gamma}_{k} := \\frac{1}{N-k} \\sum_{n=1}^{N-k} \\big(x_{n} - \\bar{x}_{N}\\big)\\big(x_{n+k} - \\bar{x}_{N}\\big), \\quad k \\geq 0,\n$$\nthe sample autocorrelations $\\hat{\\rho}_{k} := \\hat{\\gamma}_{k}/\\hat{\\gamma}_{0}$, and a compactly supported window $w_{k}$, for example the Bartlett window $w_{k} := 1 - \\frac{k}{m+1}$ for $0 \\leq k \\leq m$ and $w_{k} := 0$ for $k  m$, where $m$ is a truncation lag chosen as a function of $N$. Derive the corresponding windowed estimator $\\hat{\\tau}_{\\mathrm{int}}^{\\mathrm{win}}$ and explain qualitatively how this reduces finite-sample bias relative to the naive unwindowed sum.\n\nFinally, for the given $\\phi = 0.75$, compute the exact value of $\\tau_{\\mathrm{int}}$ implied by the $\\text{AR}(1)$ approximation. Your final answer must be a single real-valued number, and no rounding is required. No units should be used.", "solution": "The problem is validated as self-contained, scientifically grounded, and well-posed. It presents a standard, albeit detailed, exercise in the statistical analysis of Markov chain Monte Carlo (MCMC) output, which is central to a rigorous application of MCMC for inverse problems. We proceed with the solution, which is broken down into the three requested derivations followed by the final numerical computation.\n\nLet $\\{x_n\\}_{n=1}^N$ be the sequence of the scalar summary $f(u_n)$ from a stationary MCMC run. The process is assumed to be strictly stationary and ergodic, with mean $E[x_n] = \\mu$ and finite variance $\\mathrm{Var}(x_n) = \\sigma_x^2$. For the purpose of covariance and correlation calculations, we can analyze the centered process $x'_n = x_n - \\mu$, which has zero mean, without loss of generality. Hereafter, we will assume $\\mu=0$ to simplify notation.\n\n**1. Lag-$k$ Autocorrelation for an AR(1) Process**\n\nThe lag-$k$ autocovariance function, $\\gamma_k$, of a stationary process $\\{x_n\\}$ is defined as the covariance between observations separated by $k$ time steps:\n$$\n\\gamma_k := \\mathrm{Cov}(x_n, x_{n+k}) = E[x_n x_{n+k}]\n$$\nThe lag-$k$ autocorrelation function, $\\rho_k$, is the normalized autocovariance:\n$$\n\\rho_k := \\frac{\\gamma_k}{\\gamma_0} = \\frac{\\mathrm{Cov}(x_n, x_{n+k})}{\\mathrm{Var}(x_n)}\n$$\nwhere $\\gamma_0 = \\mathrm{Var}(x_n) = \\sigma_x^2$.\n\nWe are given that the process is approximated by a Gaussian autoregressive process of order one, AR($1$):\n$$\nx_n = \\phi x_{n-1} + \\epsilon_n, \\quad \\epsilon_n \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^2)\n$$\nwhere the noise terms $\\epsilon_n$ are independent and identically distributed, and are also independent of past values of the process, i.e., $E[x_{n-j} \\epsilon_n] = 0$ for $j0$.\n\nTo find $\\gamma_k$, we multiply the AR($1$) equation for $x_{n+k}$ by $x_n$ and take the expectation:\n$$\nE[x_n x_{n+k}] = E[x_n (\\phi x_{n+k-1} + \\epsilon_{n+k})] = \\phi E[x_n x_{n+k-1}] + E[x_n \\epsilon_{n+k}]\n$$\nFor $k  0$, $x_n$ is a function of noise terms up to time $n$, so it is independent of $\\epsilon_{n+k}$. Thus, $E[x_n \\epsilon_{n+k}] = E[x_n]E[\\epsilon_{n+k}] = 0$. This yields the Yule-Walker equation for an AR($1$) process:\n$$\n\\gamma_k = \\phi \\gamma_{k-1}, \\quad \\text{for } k \\geq 1\n$$\nThis is a recursive relationship. Starting with $k=1$, we get $\\gamma_1 = \\phi \\gamma_0$. For $k=2$, $\\gamma_2 = \\phi \\gamma_1 = \\phi^2 \\gamma_0$. By induction, the general solution is:\n$$\n\\gamma_k = \\phi^k \\gamma_0, \\quad \\text{for } k \\geq 0\n$$\nDividing by $\\gamma_0$, we obtain the lag-$k$ autocorrelation:\n$$\n\\rho_k = \\frac{\\gamma_k}{\\gamma_0} = \\phi^k\n$$\n\n**2. Derivation of the Integrated Autocorrelation Time**\n\nThe sample mean of the sequence is $\\bar{x}_N = \\frac{1}{N} \\sum_{n=1}^{N} x_n$. We start by deriving its variance:\n$$\n\\mathrm{Var}(\\bar{x}_N) = \\mathrm{Var}\\left(\\frac{1}{N} \\sum_{n=1}^{N} x_n\\right) = \\frac{1}{N^2} \\mathrm{Var}\\left(\\sum_{n=1}^{N} x_n\\right)\n$$\nUsing the linearity of the covariance operator:\n$$\n\\mathrm{Var}(\\bar{x}_N) = \\frac{1}{N^2} \\sum_{n=1}^{N} \\sum_{m=1}^{N} \\mathrm{Cov}(x_n, x_m)\n$$\nDue to stationarity, $\\mathrm{Cov}(x_n, x_m) = \\gamma_{|n-m|}$. We can rewrite the double summation by grouping terms with the same lag $k = |n-m|$:\n$$\n\\sum_{n=1}^{N} \\sum_{m=1}^{N} \\gamma_{|n-m|} = N\\gamma_0 + \\sum_{k=1}^{N-1} 2(N-k) \\gamma_k\n$$\nThe factor $2(N-k)$ is the number of pairs $(n,m)$ in the $N \\times N$ grid of indices such that $|n-m|=k$. Substituting this back into the variance expression:\n$$\n\\mathrm{Var}(\\bar{x}_N) = \\frac{1}{N^2} \\left[ N\\gamma_0 + 2 \\sum_{k=1}^{N-1} (N-k) \\gamma_k \\right]\n$$\nFactoring out $N\\gamma_0$:\n$$\n\\mathrm{Var}(\\bar{x}_N) = \\frac{\\gamma_0}{N} \\left[ 1 + 2 \\sum_{k=1}^{N-1} \\frac{N-k}{N} \\frac{\\gamma_k}{\\gamma_0} \\right] = \\frac{\\sigma_x^2}{N} \\left[ 1 + 2 \\sum_{k=1}^{N-1} \\left(1 - \\frac{k}{N}\\right) \\rho_k \\right]\n$$\nFor a large number of samples $N$, and for a process where the autocorrelations $\\rho_k$ decay sufficiently quickly, the summation can be approximated. For $k \\ll N$, the term $(1 - k/N) \\approx 1$. If the sum converges, we can extend the limit to infinity:\n$$\n\\mathrm{Var}(\\bar{x}_N) \\approx \\frac{\\sigma_x^2}{N} \\left( 1 + 2 \\sum_{k=1}^{\\infty} \\rho_k \\right) \\quad \\text{for large } N\n$$\nThe integrated autocorrelation time, $\\tau_{\\mathrm{int}}$, is defined such that $\\mathrm{Var}(\\bar{x}_N) \\approx \\frac{\\sigma_x^2 \\tau_{\\mathrm{int}}}{N}$. Comparing this definition with our derived approximation, we identify $\\tau_{\\mathrm{int}}$ as:\n$$\n\\tau_{\\mathrm{int}} = 1 + 2 \\sum_{k=1}^{\\infty} \\rho_k\n$$\nThis quantity relates the variance of the sample mean of a correlated sequence to the variance of the sample mean of an i.i.d. sequence of the same length. The effective sample size is often defined as $N_{\\mathrm{eff}} = N/\\tau_{\\mathrm{int}}$.\n\n**3. Finite-Sample Windowed Estimator for $\\tau_{\\mathrm{int}}$**\n\nIn practice, $\\tau_{\\mathrm{int}}$ must be estimated from a finite sample of length $N$. A naive estimator would truncate the infinite sum and plug in sample autocorrelations: $\\hat{\\tau}_{\\mathrm{int}} = 1 + 2 \\sum_{k=1}^{m} \\hat{\\rho}_k$. This estimator suffers from high variance because sample autocorrelations $\\hat{\\rho}_k$ are themselves noisy estimates, especially for large $k$. The sum can be dominated by this noise, leading to poor and even negative estimates of $\\tau_{\\mathrm{int}}$.\n\nA better approach is to use a windowed, bias-corrected estimator. We are given the unbiased sample autocovariance estimator:\n$$\n\\hat{\\gamma}_{k} := \\frac{1}{N-k} \\sum_{n=1}^{N-k} \\big(x_{n} - \\bar{x}_{N}\\big)\\big(x_{n+k} - \\bar{x}_{N}\\big)\n$$\nThe corresponding sample autocorrelation is $\\hat{\\rho}_{k} := \\hat{\\gamma}_{k} / \\hat{\\gamma}_{0}$. A windowed estimator for $\\tau_{\\mathrm{int}}$ is constructed by weighting the sample autocorrelations with a window function $w_k$ that decays to zero. This reduces the contribution of the noisy, high-lag terms.\nThe general form of the windowed estimator is:\n$$\n\\hat{\\tau}_{\\mathrm{int}}^{\\mathrm{win}} = 1 + 2 \\sum_{k=1}^{N-1} w_k \\hat{\\rho}_k\n$$\nUsing the specified Bartlett window, $w_k = 1 - \\frac{k}{m+1}$ for $0 \\leq k \\leq m$ and $w_k=0$ for $k  m$, the estimator becomes:\n$$\n\\hat{\\tau}_{\\mathrm{int}}^{\\mathrm{win}} = 1 + 2 \\sum_{k=1}^{m} \\left(1 - \\frac{k}{m+1}\\right) \\hat{\\rho}_k\n$$\nHere, $m$ is a truncation lag, chosen such that $m \\ll N$.\n\nThe windowing procedure reduces the finite-sample bias and variance of the estimator. The naive summation $\\sum_{k=1}^m \\hat{\\rho}_k$ has a positive bias because the noise in the $\\hat{\\rho}_k$ terms does not average to zero, and can accumulate. By down-weighting the $\\hat{\\rho}_k$ for larger $k$, which are the most uncertain, the window function systematically reduces the variance of the final estimate. While this introduces a deterministic bias (by altering the weights from unity), it often leads to a substantial reduction in the mean squared error of the estimator. The Bartlett window, in particular, corresponds to a specific method of spectral density estimation and guarantees a non-negative estimate for $\\tau_{\\mathrm{int}}$, which is a physically necessary property.\n\n**Final Calculation**\n\nWe need to compute the exact value of $\\tau_{\\mathrm{int}}$ for an AR($1$) process with $\\phi = 0.75$.\nFrom Part 1, we have $\\rho_k = \\phi^k$. From Part 2, the expression for $\\tau_{\\mathrm{int}}$ is:\n$$\n\\tau_{\\mathrm{int}} = 1 + 2 \\sum_{k=1}^{\\infty} \\rho_k = 1 + 2 \\sum_{k=1}^{\\infty} \\phi^k\n$$\nThe sum is an infinite geometric series. Since $|\\phi| = 0.75  1$, the series converges to:\n$$\n\\sum_{k=1}^{\\infty} \\phi^k = \\frac{\\phi}{1-\\phi}\n$$\nSubstituting this into the expression for $\\tau_{\\mathrm{int}}$:\n$$\n\\tau_{\\mathrm{int}} = 1 + 2 \\left( \\frac{\\phi}{1-\\phi} \\right) = \\frac{1-\\phi}{1-\\phi} + \\frac{2\\phi}{1-\\phi} = \\frac{1-\\phi+2\\phi}{1-\\phi} = \\frac{1+\\phi}{1-\\phi}\n$$\nNow, we substitute the given value $\\phi = 0.75$:\n$$\n\\tau_{\\mathrm{int}} = \\frac{1+0.75}{1-0.75} = \\frac{1.75}{0.25} = \\frac{7/4}{1/4} = 7\n$$\nThe exact integrated autocorrelation time for this process is $7$.", "answer": "$$\n\\boxed{7}\n$$", "id": "3400386"}, {"introduction": "Beyond the mechanics of the algorithm, a crucial skill in solving inverse problems is designing scientifically valid numerical experiments. This is especially true when using synthetic data to test an inversion methodology. This exercise tackles a common and subtle pitfall known as the \"inverse crime,\" where using the same numerical model to generate and invert data leads to artificially optimistic results and an underestimation of true uncertainty [@problem_id:3400263]. Understanding this concept is vital for producing credible and realistic assessments of your MCMC-based inference framework.", "problem": "Consider a Bayesian inverse problem in which an unknown parameter vector $\\theta \\in \\Theta \\subset \\mathbb{R}^{p}$ is inferred from data $y \\in \\mathbb{R}^{m}$ through a forward map $G(\\theta)$ defined by a continuum model (for example, a partial differential equation) and an observation operator $\\mathcal{O} : \\mathcal{U} \\to \\mathbb{R}^{m}$, where $\\mathcal{U}$ denotes the state space of model outputs. Assume the forward map is computed numerically, yielding a family of discretized solvers $\\{G_{h}(\\theta)\\}_{h \\in \\mathcal{H}}$, indexed by a discretization parameter $h$ (for example, mesh size, time step, or polynomial degree). Synthetic data are generated according to\n$$\ny = \\mathcal{O} G_{h_{\\mathrm{data}}}(\\theta^\\dagger) + \\eta,\n$$\nwhere $\\theta^\\dagger$ is the ground-truth parameter and $\\eta \\sim \\mathcal{N}(0,\\Gamma)$ represents observational noise with covariance $\\Gamma \\in \\mathbb{R}^{m \\times m}$, and the prior density $\\pi_{0}(\\theta)$ is specified. Inference is performed using MCMC (Markov chain Monte Carlo) targeting the posterior\n$$\n\\pi(\\theta \\mid y) \\propto \\exp\\!\\left( -\\tfrac{1}{2} \\big\\| y - \\mathcal{O} G_{h_{\\mathrm{infer}}}(\\theta) \\big\\|_{\\Gamma^{-1}}^{2} \\right) \\, \\pi_{0}(\\theta),\n$$\nwhere $\\|\\cdot\\|_{\\Gamma^{-1}}$ denotes the norm induced by the inverse covariance and $h_{\\mathrm{infer}}$ is the discretization used in the inference code.\n\nStarting from Bayes’ rule, the definition of the forward map, and the concept of model error induced by discretization (i.e., the mismatch $e_{h}(\\theta) \\equiv \\mathcal{O} G_{h_{\\mathrm{data}}}(\\theta) - \\mathcal{O} G_{h_{\\mathrm{infer}}}(\\theta)$), reason about how the choice of $h_{\\mathrm{data}}$ and $h_{\\mathrm{infer}}$ impacts posterior concentration and algorithmic performance in synthetic studies. In particular, analyze the phenomenon commonly called the “inverse crime” in this context, and determine which experimental designs properly avoid it by separating the discretizations used for data generation and inference.\n\nSelect all options that are correct.\n\nA. The inverse crime in MCMC-based inverse problems occurs when synthetic data are generated and subsequently inverted using the same forward solver and discretization, so that $h_{\\mathrm{data}} = h_{\\mathrm{infer}}$ and $\\mathcal{O} G_{h_{\\mathrm{data}}}(\\cdot) \\equiv \\mathcal{O} G_{h_{\\mathrm{infer}}}(\\cdot)$, often with negligible noise, yielding artificially optimistic posterior concentration and algorithmic performance.\n\nB. The inverse crime primarily refers to mis-specifying the prior density $\\pi_{0}(\\theta)$; it can be avoided by choosing a more diffuse prior, even when $h_{\\mathrm{data}} = h_{\\mathrm{infer}}$.\n\nC. A valid strategy to avoid the inverse crime is to generate data with a finer discretization than used in inference, such as $h_{\\mathrm{data}} \\ll h_{\\mathrm{infer}}$ and $\\eta \\sim \\mathcal{N}(0,\\Gamma)$ nondegenerate, then perform inference with $\\mathcal{O} G_{h_{\\mathrm{infer}}}(\\theta)$ while quantifying the discretization-induced mismatch $e_{h}(\\theta)$ in the likelihood.\n\nD. To avoid the inverse crime, one should set $\\eta = 0$ and use identical discretizations for data generation and inference ($h_{\\mathrm{data}} = h_{\\mathrm{infer}}$), but add strong regularization through the prior so that posterior contraction is not misleading.\n\nE. A valid strategy to avoid the inverse crime is to use different forward models or fidelity levels at the two stages, i.e., $h_{\\mathrm{data}} \\neq h_{\\mathrm{infer}}$ and possibly distinct numerical solvers, and to augment the likelihood with a model discrepancy term $\\delta \\sim \\mathcal{N}(0,\\Sigma_{\\delta})$ so that\n$$\ny = \\mathcal{O} G_{h_{\\mathrm{infer}}}(\\theta) + \\delta + \\eta, \\quad \\text{with} \\quad \\delta \\perp \\eta,\n$$\neffectively replacing $\\Gamma$ by $\\Gamma + \\Sigma_{\\delta}$ in the misfit to account for $e_{h}(\\theta)$.\n\nF. The inverse crime can be avoided by using longer burn-in and heavier thinning in MCMC, keeping $h_{\\mathrm{data}} = h_{\\mathrm{infer}}$; this separates the sampler’s trajectory sufficiently from the data generation procedure.", "solution": "The user wants me to validate the problem statement and then, if valid, solve the problem by analyzing the provided options.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\nThe problem statement provides the following information:\n-   An unknown parameter vector `$\\theta \\in \\Theta \\subset \\mathbb{R}^{p}$`.\n-   Observed data `$y \\in \\mathbb{R}^{m}$`.\n-   A forward map `$G(\\theta)$` defined by a continuum model.\n-   An observation operator `$\\mathcal{O} : \\mathcal{U} \\to \\mathbb{R}^{m}$`, where `$\\mathcal{U}$` is the state space of model outputs.\n-   A family of discretized solvers `$\\{G_{h}(\\theta)\\}_{h \\in \\mathcal{H}}`, indexed by a discretization parameter `$h$`.\n-   A synthetic data generation model: `$y = \\mathcal{O} G_{h_{\\mathrm{data}}}(\\theta^\\dagger) + \\eta$`.\n-   The ground-truth parameter is `$\\theta^\\dagger$`.\n-   The observational noise is `$\\eta \\sim \\mathcal{N}(0,\\Gamma)$`, where `$\\Gamma \\in \\mathbb{R}^{m \\times m}` is the covariance matrix.\n-   A specified prior density `$\\pi_{0}(\\theta)$`.\n-   The posterior distribution targeted for inference: `$\\pi(\\theta \\mid y) \\propto \\exp\\!\\left( -\\tfrac{1}{2} \\big\\| y - \\mathcal{O} G_{h_{\\mathrm{infer}}}(\\theta) \\big\\|_{\\Gamma^{-1}}^{2} \\right) \\, \\pi_{0}(\\theta)`.\n-   The discretization used for inference is `$h_{\\mathrm{infer}}$`.\n-   The norm `$\\|\\cdot\\|_{\\Gamma^{-1}}$` is induced by the inverse covariance `$\\Gamma^{-1}$`.\n-   The discretization-induced model error (mismatch) is defined as `$e_{h}(\\theta) \\equiv \\mathcal{O} G_{h_{\\mathrm{data}}}(\\theta) - \\mathcal{O} G_{h_{\\mathrm{infer}}}(\\theta)$`.\n-   The task is to analyze the impact of the choice of `$h_{\\mathrm{data}}$` and `$h_{\\mathrm{infer}}$` on posterior inference, particularly the phenomenon of the \"inverse crime,\" and identify correct experimental designs to avoid it.\n\n**Step 2: Validate Using Extracted Givens**\n\n-   **Scientifically Grounded**: The problem is well-grounded in the field of computational science and engineering, specifically in Bayesian inverse problems and uncertainty quantification. All concepts—Bayes' rule, forward models, discretization error, MCMC, prior/posterior distributions, and likelihood functions—are standard. The \"inverse crime\" is a well-known informal term in this community for the specific methodological flaw described.\n-   **Well-Posed**: The problem is well-posed. It presents a clear and standard mathematical framework for a Bayesian inverse problem and asks for a conceptual analysis of a specific methodological issue. The question is structured to assess understanding of model misspecification in synthetic data studies. A meaningful analysis is possible based on the provided information.\n-   **Objective**: The problem is stated in precise, objective, and formal mathematical language. It is free of ambiguity, subjective claims, or bias.\n\nThe problem statement does not violate any of the invalidity criteria. It is scientifically sound, formalizable, complete, and poses a non-trivial, verifiable question relevant to the topic.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. I will proceed to derive the solution and evaluate the options.\n\n### Solution Derivation\n\nThe core of the problem lies in the relationship between the true data-generating process and the model assumed for inference. Bayes' rule states that the posterior is proportional to the likelihood times the prior: `$\\pi(\\theta|y) \\propto \\pi(y|\\theta)\\pi_0(\\theta)$`.\n\nThe problem states that the data `$y$` are generated as:\n$$\ny = \\mathcal{O} G_{h_{\\mathrm{data}}}(\\theta^\\dagger) + \\eta, \\quad \\eta \\sim \\mathcal{N}(0,\\Gamma)\n$$\nHere, `$G_{h_{\\mathrm{data}}}$` is the forward model used to simulate the data.\n\nThe inference, however, uses a potentially different model, `$G_{h_{\\mathrm{infer}}}$`. The likelihood function is specified as:\n$$\n\\pi(y|\\theta) \\propto \\exp\\!\\left( -\\tfrac{1}{2} \\big\\| y - \\mathcal{O} G_{h_{\\mathrm{infer}}}(\\theta) \\big\\|_{\\Gamma^{-1}}^{2} \\right)\n$$\nThis likelihood implicitly assumes the statistical model `$y = \\mathcal{O} G_{h_{\\mathrm{infer}}}(\\theta) + \\epsilon$`, where the total error `$\\epsilon$` is assumed to be distributed as `$\\mathcal{N}(0,\\Gamma)$`.\n\nLet's examine the residual term `$r(\\theta) = y - \\mathcal{O} G_{h_{\\mathrm{infer}}}(\\theta)$` inside the likelihood by substituting the expression for `$y$`:\n$$\nr(\\theta) = \\left( \\mathcal{O} G_{h_{\\mathrm{data}}}(\\theta^\\dagger) + \\eta \\right) - \\mathcal{O} G_{h_{\\mathrm{infer}}}(\\theta)\n$$\nWe can rearrange this as:\n$$\nr(\\theta) = \\left( \\mathcal{O} G_{h_{\\mathrm{data}}}(\\theta^\\dagger) - \\mathcal{O} G_{h_{\\mathrm{data}}}(\\theta) \\right) + \\left( \\mathcal{O} G_{h_{\\mathrm{data}}}(\\theta) - \\mathcal{O} G_{h_{\\mathrm{infer}}}(\\theta) \\right) + \\eta\n$$\nUsing the problem's definition for the discretization mismatch `$e_h(\\theta) = \\mathcal{O} G_{h_{\\mathrm{data}}}(\\theta) - \\mathcal{O} G_{h_{\\mathrm{infer}}}(\\theta)`, this becomes:\n$$\nr(\\theta) = \\left( \\mathcal{O} G_{h_{\\mathrm{data}}}(\\theta^\\dagger) - \\mathcal{O} G_{h_{\\mathrm{data}}}(\\theta) \\right) + e_h(\\theta) + \\eta\n$$\n\nThe \"inverse crime\" occurs when we set `$h_{\\mathrm{data}} = h_{\\mathrm{infer}}$`. In this case, `$G_{h_{\\mathrm{data}}}(\\cdot) \\equiv G_{h_{\\mathrm{infer}}}(\\cdot)`, which means the discretization error `$e_h(\\theta) \\equiv 0$` for all `$\\theta$`. The residual simplifies to:\n$$\nr(\\theta) = \\mathcal{O} G_{h_{\\mathrm{data}}}(\\theta^\\dagger) - \\mathcal{O} G_{h_{\\mathrm{data}}}(\\theta) + \\eta\n$$\nThe posterior is maximized when the Mahalanobis distance `$\\|r(\\theta)\\|_{\\Gamma^{-1}}^2$` is minimized. In this scenario, the model used for inference has access to the exact same functional form that produced the data (ignoring the noise). The only difference between the model prediction `$\\mathcal{O} G_{h_{\\mathrm{data}}}(\\theta)$` and the noiseless data `$\\mathcal{O} G_{h_{\\mathrm{data}}}(\\theta^\\dagger)$` is the parameter `$\\theta$`. The posterior will thus concentrate around `$\\theta^\\dagger$`, and the width of the posterior will be determined solely by the observational noise `$\\eta$` and the sensitivity of `$G_{h_{\\mathrm{data}}}$` with respect to `$\\theta$`. This is an artificially ideal situation because in any real application, our model `$G_{h_{\\mathrm{infer}}}$` is only an approximation to the true physical process, so there is always a non-zero model error. Committing the inverse crime thus leads to a gross underestimation of the true posterior uncertainty.\n\nTo avoid the inverse crime, one must introduce a deliberate mismatch between the data-generating model and the inference model. A standard way to do this is to use different discretizations, `$h_{\\mathrm{data}} \\neq h_{\\mathrm{infer}}$`. Typically, one uses a much finer discretization for data generation (`$h_{\\mathrm{data}}$` is \"small\") to better represent the \"true\" continuum physics, and a coarser, computationally cheaper discretization for inference (`$h_{\\mathrm{infer}}$` is \"large\"). In this case, `$e_h(\\theta) \\neq 0$`.\n\nThe presence of the non-zero term `$e_h(\\theta)$` means that the likelihood model is misspecified, as it only accounts for the observational noise `$\\eta$` with covariance `$\\Gamma$`, while the true total error is `$e_h(\\theta) + \\eta$`. At the true parameter value `$\\theta=\\theta^\\dagger$`, the residual is `$r(\\theta^\\dagger) = e_h(\\theta^\\dagger) + \\eta$`. A principled approach must account for this additional source of error. One common way is to treat the model inadequacy `$e_h(\\theta)$` as a random variable `$\\delta$`, often modeled as a zero-mean Gaussian process independent of `$\\eta$`. The total error is then `$\\epsilon = \\delta + \\eta`, which, under assumptions of independence and Gaussianity (`$\\delta \\sim \\mathcal{N}(0, \\Sigma_\\delta)$`, `$\\eta \\sim \\mathcal{N}(0, \\Gamma)$`), is also Gaussian: `$\\epsilon \\sim \\mathcal{N}(0, \\Gamma + \\Sigma_\\delta)`. The likelihood should then use the modified covariance `$\\Gamma_{\\mathrm{total}} = \\Gamma + \\Sigma_\\delta`.\n\n### Option-by-Option Analysis\n\n**A. The inverse crime in MCMC-based inverse problems occurs when synthetic data are generated and subsequently inverted using the same forward solver and discretization, so that $h_{\\mathrm{data}} = h_{\\mathrm{infer}}$ and $\\mathcal{O} G_{h_{\\mathrm{data}}}(\\cdot) \\equiv \\mathcal{O} G_{h_{\\mathrm{infer}}}(\\cdot)$, often with negligible noise, yielding artificially optimistic posterior concentration and algorithmic performance.**\nThis is a precise and accurate description of the inverse crime. Using `$h_{\\mathrm{data}} = h_{\\mathrm{infer}}$` makes the model error term `$e_h(\\theta)$` vanish, which is an unrealistic assumption for any real-world problem. This flawed assumption leads to an underestimation of uncertainty, manifesting as overly concentrated posteriors (\"artificially optimistic posterior concentration\") and potentially easier MCMC sampling (\"artificially optimistic algorithmic performance\").\n**Verdict: Correct.**\n\n**B. The inverse crime primarily refers to mis-specifying the prior density $\\pi_{0}(\\theta)$; it can be avoided by choosing a more diffuse prior, even when $h_{\\mathrm{data}} = h_{\\mathrm{infer}}$.**\nThis is incorrect. The inverse crime is a structural problem with the likelihood function, specifically the forward model used within it, not the prior distribution `$\\pi_{0}(\\theta)$`. The problem is that the likelihood assumes the model is perfect. Using a more diffuse prior will generally lead to a wider posterior, but it does not correct the fundamental incorrectness of the model's form relative to the data, and the resulting posterior will still be misleadingly centered and shaped according to a flawed model.\n**Verdict: Incorrect.**\n\n**C. A valid strategy to avoid the inverse crime is to generate data with a finer discretization than used in inference, such as $h_{\\mathrm{data}} \\ll h_{\\mathrm{infer}}$ and $\\eta \\sim \\mathcal{N}(0,\\Gamma)$ nondegenerate, then perform inference with $\\mathcal{O} G_{h_{\\mathrm{infer}}}(\\theta)$ while quantifying the discretization-induced mismatch $e_{h}(\\theta)$ in the likelihood.**\nThis describes a valid and principled approach. Step one is to break the identity of the models by using a finer discretization for data generation (`$h_{\\mathrm{data}} \\ll h_{\\mathrm{infer}}$`, where smaller `$h$` means finer discretization) than for inference. Step two is to explicitly account for the resulting mismatch `$e_h(\\theta)$` in the likelihood. This prevents the model from being misspecified and leads to a more realistic assessment of uncertainty. This statement captures the essence of a sound methodology.\n**Verdict: Correct.**\n\n**D. To avoid the inverse crime, one should set $\\eta = 0$ and use identical discretizations for data generation and inference ($h_{\\mathrm{data}} = h_{\\mathrm{infer}}$), but add strong regularization through the prior so that posterior contraction is not misleading.**\nThis is incorrect. Using `$h_{\\mathrm{data}} = h_{\\mathrm{infer}}$` *is* the inverse crime. Setting the noise `$\\eta=0$` exacerbates the problem, creating a deterministic inversion scenario where the data lies perfectly within the model's range. Adding strong prior regularization is a form of regularization, but it does not solve the underlying problem of assuming a perfect model. It simply biases the solution towards the prior, which is a different effect and does not constitute a valid method for avoiding the inverse crime.\n**Verdict: Incorrect.**\n\n**E. A valid strategy to avoid the inverse crime is to use different forward models or fidelity levels at the two stages, i.e., $h_{\\mathrm{data}} \\neq h_{\\mathrm{infer}}$ and possibly distinct numerical solvers, and to augment the likelihood with a model discrepancy term $\\delta \\sim \\mathcal{N}(0,\\Sigma_{\\delta})$ so that $y = \\mathcal{O} G_{h_{\\mathrm{infer}}}(\\theta) + \\delta + \\eta$, with $\\delta \\perp \\eta,$ effectively replacing $\\Gamma$ by $\\Gamma + \\Sigma_{\\delta}$ in the misfit to account for $e_{h}(\\theta)$.**\nThis option provides a specific and correct implementation of the strategy described in option C. Using `$h_{\\mathrm{data}} \\neq h_{\\mathrm{infer}}$` is the first key step. The second is to explicitly account for the model discrepancy by augmenting the statistical model. Modeling the discrepancy `$\\delta` as a zero-mean Gaussian process with covariance `$\\Sigma_{\\delta}` that is independent of the observation noise `$\\eta` is a standard and well-accepted method (often associated with the Kennedy-O'Hagan framework). The resulting total error covariance is indeed `$\\Gamma + \\Sigma_{\\delta}`, leading to a correctly specified likelihood that accounts for both sources of error.\n**Verdict: Correct.**\n\n**F. The inverse crime can be avoided by using longer burn-in and heavier thinning in MCMC, keeping $h_{\\mathrm{data}} = h_{\\mathrm{infer}}$; this separates the sampler’s trajectory sufficiently from the data generation procedure.**\nThis is incorrect. MCMC diagnostics and post-processing techniques like burn-in and thinning are tools for ensuring the quality of the sample-based approximation of a *given* posterior distribution. They have no effect on the target posterior distribution `$\\pi(\\theta|y)$` itself. If the posterior is flawed due to the inverse crime (`$h_{\\mathrm{data}} = h_{\\mathrm{infer}}$`), the sampler will simply converge to and explore that flawed distribution. No amount of burn-in or thinning can correct a problem in the formulation of the posterior.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{ACE}$$", "id": "3400263"}]}