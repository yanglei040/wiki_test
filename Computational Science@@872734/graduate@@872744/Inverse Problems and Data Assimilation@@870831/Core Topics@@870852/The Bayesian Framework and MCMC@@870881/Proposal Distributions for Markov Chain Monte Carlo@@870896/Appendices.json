{"hands_on_practices": [{"introduction": "The Random Walk Metropolis (RWM) algorithm is a cornerstone of MCMC methods, but its efficiency critically depends on the proposal step size. A step that is too small leads to slow exploration, while a step that is too large results in constant rejections. This practice delves into the theoretical underpinnings of optimal proposal scaling in high-dimensional spaces, guiding you to derive a famous rule-of-thumb that balances proposal size and acceptance rate to maximize sampler efficiency [@problem_id:3415063].", "problem": "Consider a linear inverse problem with a Gaussian prior and additive Gaussian observational noise, resulting in a Gaussian posterior over the state vector $x \\in \\mathbb{R}^{d}$ with mean $\\mu$ and covariance matrix $C \\in \\mathbb{R}^{d \\times d}$, that is, the posterior density is $\\pi(x) = \\mathcal{N}(\\mu, C)$. You seek to sample from $\\pi(x)$ using Markov chain Monte Carlo (MCMC), specifically the Random Walk Metropolis (RWM) algorithm, with a symmetric Gaussian proposal of the form\n$$\nq(x' \\mid x) = \\mathcal{N}\\big(x, \\Sigma_{\\text{prop}}\\big), \\quad \\Sigma_{\\text{prop}} = s^{2} C,\n$$\nwhere $s  0$ is a scalar step-size and $C$ serves as a preconditioner targeting the posterior covariance structure.\n\nUsing a whitened coordinate transformation $u = C^{-1/2}(x - \\mu)$ so that the target becomes standard Gaussian $\\mathcal{N}(0, I_{d})$, the proposal in whitened coordinates is $u' = u + s z$ for $z \\sim \\mathcal{N}(0, I_{d})$. In high dimensions, to avoid vanishing or exploding acceptance probabilities, it is standard to consider the scaling $s = \\ell / \\sqrt{d}$, where $\\ell  0$ is a dimensionless step-size constant.\n\nStarting from fundamental definitions of the Random Walk Metropolis acceptance probability and asymptotic distributional approximations valid for large $d$, derive the approximate large-$d$ acceptance probability as a function of $\\ell$, and then define an efficiency metric based on the expected squared jump distance (ESJD) in the whitened coordinates. Determine the value of $\\ell$ that maximizes this efficiency, and hence obtain the optimal proposal covariance $\\Sigma_{\\text{prop}}^{\\star}$ in the original coordinates as a function of $d$ and $C$.\n\nExpress your final answer for $\\Sigma_{\\text{prop}}^{\\star}$ as a single closed-form expression in terms of $d$ and $C$, with the optimal step-size constant $\\ell^{\\star}$ rounded to three significant figures. No units are required for the final expression.", "solution": "We begin by recalling the Random Walk Metropolis (RWM) acceptance probability for a symmetric proposal. Given a current state $x$ and proposed state $x'$, the acceptance probability is\n$$\n\\alpha(x, x') = \\min\\Big(1, \\frac{\\pi(x')}{\\pi(x)}\\Big).\n$$\nFor a Gaussian target $\\pi(x) = \\mathcal{N}(\\mu, C)$, it is convenient to work in whitened coordinates $u = C^{-1/2}(x - \\mu)$ so that the target density becomes $\\pi(u) \\propto \\exp\\big(-\\|u\\|^{2}/2\\big)$, i.e., standard Gaussian $\\mathcal{N}(0, I_{d})$. The proposal is taken as\n$$\nu' = u + s z, \\quad z \\sim \\mathcal{N}(0, I_{d}).\n$$\nTo obtain a nondegenerate limit for the acceptance probability as the dimension $d$ grows, we adopt the scaling\n$$\ns = \\frac{\\ell}{\\sqrt{d}},\n$$\nwhere $\\ell  0$ is a dimensionless step-size constant to be determined.\n\nThe acceptance ratio in whitened coordinates is\n$$\nr(u, u') = \\frac{\\pi(u')}{\\pi(u)} = \\exp\\Big(-\\frac{1}{2}\\big(\\|u'\\|^{2} - \\|u\\|^{2}\\big)\\Big).\n$$\nDefine the proposal increment $\\delta = u' - u = s z = \\frac{\\ell}{\\sqrt{d}} z$. Then\n$$\n\\|u'\\|^{2} - \\|u\\|^{2} = \\|u + \\delta\\|^{2} - \\|u\\|^{2} = 2 u \\cdot \\delta + \\|\\delta\\|^{2},\n$$\nand hence the log acceptance ratio is\n$$\nA = \\ln r(u, u') = - u \\cdot \\delta - \\frac{1}{2} \\|\\delta\\|^{2} = - \\frac{\\ell}{\\sqrt{d}} u \\cdot z - \\frac{1}{2} \\frac{\\ell^{2}}{d} \\|z\\|^{2}.\n$$\nWe analyze $A$ in the limit $d \\to \\infty$. Since $u \\sim \\mathcal{N}(0, I_{d})$ and $z \\sim \\mathcal{N}(0, I_{d})$ are independent, we consider the random sum\n$$\n\\frac{1}{\\sqrt{d}} u \\cdot z = \\frac{1}{\\sqrt{d}} \\sum_{i=1}^{d} u_{i} z_{i}.\n$$\nThe terms $u_{i} z_{i}$ are independent, mean-zero, and have variance $1$ by independence and standard Gaussian properties. By the Central Limit Theorem (CLT), we have\n$$\n\\frac{1}{\\sqrt{d}} u \\cdot z \\Rightarrow W \\sim \\mathcal{N}(0, 1),\n$$\nas $d \\to \\infty$. Moreover, by the Law of Large Numbers, $\\|z\\|^{2}/d \\to 1$ almost surely as $d \\to \\infty$. Therefore, in the large-$d$ limit, the log acceptance ratio converges in distribution to\n$$\nA \\Rightarrow - \\ell W - \\frac{\\ell^{2}}{2}, \\quad W \\sim \\mathcal{N}(0, 1).\n$$\nThe acceptance probability, averaged over the stationary distribution of $u$ and the proposal $z$, then converges to\n$$\n\\alpha(\\ell) = \\mathbb{E}\\big[ \\min\\big(1, \\exp(A)\\big) \\big] = \\mathbb{E}\\big[ \\min\\big(1, \\exp(- \\ell W - \\frac{\\ell^{2}}{2})\\big) \\big],\n$$\nwith $W \\sim \\mathcal{N}(0, 1)$. We compute this expectation explicitly. Let $\\phi(w) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-w^{2}/2)$ denote the standard normal probability density function (PDF), and $\\Phi$ its cumulative distribution function (CDF). Observe that\n$$\n\\min\\big(1, \\exp(- \\ell W - \\frac{\\ell^{2}}{2})\\big) =\n\\begin{cases}\n1,  \\text{if } - \\ell W - \\frac{\\ell^{2}}{2} \\ge 0 \\iff W \\le - \\frac{\\ell}{2}, \\\\\n\\exp(- \\ell W - \\frac{\\ell^{2}}{2}),  \\text{if } W  - \\frac{\\ell}{2}.\n\\end{cases}\n$$\nThus\n$$\n\\alpha(\\ell) = \\int_{-\\infty}^{- \\ell/2} \\phi(w) \\, dw + \\int_{- \\ell/2}^{\\infty} \\exp\\Big(- \\ell w - \\frac{\\ell^{2}}{2}\\Big) \\phi(w) \\, dw.\n$$\nNote that\n$$\n\\exp\\Big(- \\ell w - \\frac{\\ell^{2}}{2}\\Big) \\phi(w) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\Big( - \\frac{w^{2}}{2} - \\ell w - \\frac{\\ell^{2}}{2} \\Big) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\Big( - \\frac{(w + \\ell)^{2}}{2} \\Big) = \\phi(w + \\ell).\n$$\nTherefore,\n$$\n\\alpha(\\ell) = \\Phi\\Big( - \\frac{\\ell}{2} \\Big) + \\int_{- \\ell/2}^{\\infty} \\phi(w + \\ell) \\, dw = \\Phi\\Big( - \\frac{\\ell}{2} \\Big) + \\int_{\\ell/2}^{\\infty} \\phi(u) \\, du = \\Phi\\Big( - \\frac{\\ell}{2} \\Big) + \\big(1 - \\Phi(\\ell/2)\\big).\n$$\nUsing the symmetry $\\Phi(-a) = 1 - \\Phi(a)$, we obtain\n$$\n\\alpha(\\ell) = 2 \\Phi\\Big( - \\frac{\\ell}{2} \\Big).\n$$\n\nWe now define the efficiency metric based on expected squared jump distance (ESJD) in whitened coordinates. The squared jump length is $\\|\\delta\\|^{2} = \\frac{\\ell^{2}}{d} \\|z\\|^{2}$, and $\\|z\\|^{2} \\approx d$ for large $d$. Hence, the ESJD in the whitened coordinates is asymptotically\n$$\nJ(\\ell) = \\mathbb{E}\\big[ \\|\\delta\\|^{2} \\, \\text{accept} \\big] \\approx \\ell^{2} \\, \\alpha(\\ell) = \\ell^{2} \\cdot 2 \\Phi\\Big( - \\frac{\\ell}{2} \\Big).\n$$\nWe seek $\\ell^{\\star}$ maximizing $J(\\ell)$. Differentiate:\n$$\n\\alpha(\\ell) = 2 \\Phi\\Big( - \\frac{\\ell}{2} \\Big), \\quad \\alpha'(\\ell) = 2 \\cdot \\Big( - \\frac{1}{2} \\Big) \\phi\\Big( \\frac{\\ell}{2} \\Big) = - \\phi\\Big( \\frac{\\ell}{2} \\Big).\n$$\nThus\n$$\nJ'(\\ell) = 2 \\ell \\alpha(\\ell) + \\ell^{2} \\alpha'(\\ell) = 2 \\ell \\cdot 2 \\Phi\\Big( - \\frac{\\ell}{2} \\Big) - \\ell^{2} \\phi\\Big( \\frac{\\ell}{2} \\Big).\n$$\nSetting $J'(\\ell) = 0$ and dividing by $\\ell  0$ gives the first-order condition\n$$\n4 \\Phi\\Big( - \\frac{\\ell}{2} \\Big) = \\ell \\, \\phi\\Big( \\frac{\\ell}{2} \\Big).\n$$\nThis transcendental equation admits a unique positive solution $\\ell^{\\star}$, which we determine numerically. Using standard root-finding (for example, Newton's method) applied to\n$$\nf(\\ell) = \\ell \\, \\phi\\Big( \\frac{\\ell}{2} \\Big) - 4 \\Phi\\Big( - \\frac{\\ell}{2} \\Big),\n$$\nwe find\n$$\n\\ell^{\\star} \\approx 2.38,\n$$\nand the corresponding optimal acceptance rate is\n$$\n\\alpha(\\ell^{\\star}) = 2 \\Phi\\Big( - \\frac{\\ell^{\\star}}{2} \\Big) \\approx 2 \\Phi(-1.19) \\approx 0.234,\n$$\na well-known near-optimal acceptance rate for RWM in high dimensions.\n\nMapping back to the original coordinates, the optimal scaling is $s^{\\star} = \\ell^{\\star}/\\sqrt{d}$, and the optimal proposal covariance is\n$$\n\\Sigma_{\\text{prop}}^{\\star} = (s^{\\star})^{2} C = \\frac{\\ell^{\\star 2}}{d} \\, C.\n$$\nWith $\\ell^{\\star}$ rounded to three significant figures, the optimal covariance is\n$$\n\\Sigma_{\\text{prop}}^{\\star} = \\frac{(2.38)^{2}}{d} \\, C.\n$$\nThis choice achieves near-optimal efficiency in the sense of maximizing the asymptotic ESJD for Random Walk Metropolis targeting a $d$-dimensional Gaussian posterior with covariance $C$.", "answer": "$$\\boxed{\\frac{(2.38)^{2}}{d}\\,C}$$", "id": "3415063"}, {"introduction": "While the RWM algorithm is simple, more advanced methods like the Metropolis-Adjusted Langevin Algorithm (MALA) can achieve faster convergence by using gradient information to guide proposals. However, this statistical efficiency comes at a price: computing gradients can be expensive, especially for models constrained by partial differential equations (PDEs). This exercise provides a hands-on analysis of this critical trade-off, asking you to quantify the computational cost of a MALA step relative to an RWM step in a realistic scientific computing scenario [@problem_id:3415120].", "problem": "Consider a Bayesian inverse problem constrained by a partial differential equation (PDE), where the unknown parameter field $m$ enters a forward model defined by an operator $A(m)$ through the state equation $A(m) u = f$ on a bounded domain, with suitable boundary conditions. Observations are given by $d = S u + \\varepsilon$, where $S$ is a linear observation operator and $\\varepsilon$ is additive observational noise modeled as a zero-mean Gaussian with covariance matrix $\\Gamma$. The log-posterior density over $m$ is defined by the sum of a log-prior and a data misfit term derived from the Gaussian likelihood, so that evaluating the log-posterior at a given $m$ requires solving the forward PDE for $u$.\n\nIn Markov chain Monte Carlo (MCMC; Markov chain Monte Carlo), two proposal mechanisms are considered for generating new states in parameter space:\n\n- A random-walk proposal with symmetric Gaussian increments, which does not use gradients.\n- The Metropolis Adjusted Langevin Algorithm (MALA; Metropolis Adjusted Langevin Algorithm), which uses the gradient of the log-posterior with respect to $m$ to construct a drift.\n\nTo compute the gradient of the log-posterior with respect to $m$ in PDE-constrained settings, assume the standard adjoint-state method: given the current forward solution $u$ at parameter $m$, one solves the adjoint PDE to obtain an adjoint state $p$, from which $\\nabla \\log \\pi(m \\mid d)$ is assembled. Assume the following cost model:\n\n- A single forward PDE solve has computational cost $C_f$.\n- A single adjoint PDE solve has computational cost $C_a$.\n- All other operations (assembly, vector algebra, draws from Gaussian distributions, and evaluation of the prior) have negligible cost compared to PDE solves.\n\nAssume the following cache policy and acceptance computation, consistent with the Metropolis–Hastings algorithm:\n\n- At each iteration, the forward solution $u$ and log-posterior at the current parameter $m$ are already available from the previous accepted step.\n- For a random-walk proposal, generating a proposal $y$ requires no gradient evaluations, and the acceptance probability depends on evaluating the log-posterior at $y$, which requires a forward solve for $u(y)$.\n- For a MALA proposal with step size $h$, proposals are drawn as $y = x + \\frac{h}{2} \\nabla \\log \\pi(x \\mid d) + \\sqrt{h} \\, \\eta$, with $\\eta$ a standard Gaussian in parameter space. The Metropolis–Hastings acceptance ratio involves both $\\log \\pi(y \\mid d)$ and the reverse proposal density $q(x \\mid y)$, which requires $\\nabla \\log \\pi(y \\mid d)$, hence one adjoint solve at $y$. Computing $\\nabla \\log \\pi(x \\mid d)$ at the current state requires one adjoint solve at $x$, given the cached forward solution.\n\nUnder these assumptions, derive a closed-form expression for the ratio of the computational cost per proposal of MALA to that of the random-walk proposal, expressed solely in terms of $C_f$ and $C_a$. Provide your final answer as a single analytic expression. No rounding is required, and no units are needed in the final answer.", "solution": "The objective is to determine the ratio of the computational cost per proposal for the Metropolis-Adjusted Langevin Algorithm (MALA) to that of a standard random-walk (RW) Metropolis algorithm, within the context of a PDE-constrained Bayesian inverse problem. The costs are to be expressed in terms of the cost of a single forward PDE solve, denoted $C_f$, and the cost of a single adjoint PDE solve, denoted $C_a$. All other computational costs are assumed to be negligible.\n\nFirst, let's analyze the computational cost per proposal for the random-walk Metropolis algorithm. Let the current state of the Markov chain be $m$. The problem states that the forward solution $u(m)$ and the log-posterior $\\log \\pi(m \\mid d)$ are available from the previous accepted step and are thus cached.\n1.  A proposal $y$ is generated from a symmetric distribution, such as $y = m + \\eta$ where $\\eta$ is a draw from a zero-mean Gaussian. According to the problem statement, this step has negligible cost.\n2.  To compute the Metropolis-Hastings acceptance probability, $\\alpha = \\min\\left(1, \\frac{\\pi(y \\mid d)}{\\pi(m \\mid d)}\\right)$, we need to evaluate the posterior density at the proposed state $y$. This involves evaluating $\\log \\pi(y \\mid d)$.\n3.  The problem states that evaluating the log-posterior at a given parameter requires solving the forward PDE. Therefore, to compute $\\log \\pi(y \\mid d)$, one must first solve the state equation $A(y)u = f$ for the state $u(y)$.\n4.  The cost of this single forward PDE solve is $C_f$.\n5.  All subsequent operations (e.g., computing the data misfit, evaluating the prior, drawing a random number for the acceptance test) are assumed to have negligible cost.\n\nThus, the total computational cost per proposal for the random-walk Metropolis algorithm, denoted $\\text{Cost}_{\\text{RW}}$, is dominated by the single forward PDE solve.\n$$\n\\text{Cost}_{\\text{RW}} = C_f\n$$\n\nNext, we analyze the computational cost per proposal for the Metropolis-Adjusted Langevin Algorithm (MALA). Let the current state of the chain be $x$. As before, the forward solution $u(x)$ and log-posterior $\\log \\pi(x \\mid d)$ are cached.\n1.  A proposal $y$ is generated using a gradient-based drift term: $y = x + \\frac{h}{2} \\nabla \\log \\pi(x \\mid d) + \\sqrt{h} \\, \\eta$. To construct this proposal, the gradient of the log-posterior at the current state, $\\nabla \\log \\pi(x \\mid d)$, must be computed.\n2.  The problem specifies using the adjoint-state method for this gradient computation. Since the forward solution $u(x)$ is already available (cached), computing the gradient requires only a single solve of the adjoint PDE. The cost of this operation is $C_a$.\n3.  After computing the gradient, the proposal $y$ is formed. The algebraic operations for this have negligible cost.\n4.  The Metropolis-Hastings acceptance probability for MALA is $\\alpha = \\min\\left(1, \\frac{\\pi(y \\mid d) q(x \\mid y)}{\\pi(x \\mid d) q(y \\mid x)}\\right)$. To evaluate this ratio, we need to compute two terms: the log-posterior at the proposal, $\\log \\pi(y \\mid d)$, and the density of the reverse proposal, $q(x \\mid y)$.\n5.  To evaluate $\\log \\pi(y \\mid d)$, we must, as in the random-walk case, solve the forward PDE at $y$ to obtain $u(y)$. The cost of this forward solve is $C_f$.\n6.  To evaluate the reverse proposal density $q(x \\mid y)$, we must compute the drift term for a proposal starting from $y$. This drift term depends on the gradient at the proposed state, $\\nabla \\log \\pi(y \\mid d)$.\n7.  To compute $\\nabla \\log \\pi(y \\mid d)$ using the adjoint-state method, we need the forward solution $u(y)$ and the corresponding adjoint solution $p(y)$. The forward solution $u(y)$ was already computed in the previous step (cost $C_f$). Therefore, we now only need to solve the adjoint PDE at state $y$. The cost of this second adjoint solve is $C_a$.\n\nSumming the costs of the dominant operations for a single MALA proposal:\n- One adjoint solve at the current state $x$ to compute the proposal drift: $C_a$.\n- One forward solve at the proposed state $y$ to evaluate the posterior: $C_f$.\n- One adjoint solve at the proposed state $y$ to compute the reverse proposal density: $C_a$.\n\nThe total computational cost per proposal for the MALA algorithm, denoted $\\text{Cost}_{\\text{MALA}}$, is the sum of these costs.\n$$\n\\text{Cost}_{\\text{MALA}} = C_a + C_f + C_a = C_f + 2C_a\n$$\n\nFinally, we compute the desired ratio of the computational cost per proposal of MALA to that of the random-walk proposal.\n$$\n\\text{Ratio} = \\frac{\\text{Cost}_{\\text{MALA}}}{\\text{Cost}_{\\text{RW}}} = \\frac{C_f + 2C_a}{C_f}\n$$\nThis expression can be simplified as:\n$$\n\\text{Ratio} = 1 + \\frac{2C_a}{C_f}\n$$\nHowever, the form showing the ratio of total costs is more direct. Both are equivalent. We will provide the unsimplified fraction.", "answer": "$$\n\\boxed{\\frac{C_f + 2C_a}{C_f}}\n$$", "id": "3415120"}, {"introduction": "For complex, high-dimensional targets like the latent trajectory in a state-space model, simple random-walk proposals can be extremely inefficient. A far more powerful approach is to design a \"block proposal\" that updates the entire trajectory at once using a distribution that approximates the true posterior. This advanced practice challenges you to construct such a proposal using an Unscented Kalman Smoother, demonstrating how to build a highly effective, model-aware independence sampler for a challenging nonlinear and non-Gaussian data assimilation problem [@problem_id:3415098].", "problem": "Consider a one-dimensional nonlinear state-space model used in data assimilation. The latent trajectory is denoted by $x_{0:T} = (x_0, x_1, \\dots, x_T)$. The latent dynamics and observation model are specified as follows.\n\n- Latent dynamics: $x_{t+1} = f(x_t) + \\varepsilon_t$ with $\\varepsilon_t \\sim \\mathcal{N}(0, Q)$ independently over $t$, and $x_0 \\sim \\mathcal{N}(m_0, P_0)$. Here $\\mathcal{N}$ denotes the Gaussian distribution.\n- Observation model: $y_t \\mid x_t \\sim \\text{Laplace}(h(x_t), b)$ independently over $t$, with probability density function $p(y_t \\mid x_t) = \\frac{1}{2 b} \\exp\\left(-\\frac{|y_t - h(x_t)|}{b}\\right)$, where $b  0$ is the Laplace scale parameter.\n\nYou are to construct an independence block proposal for $x_{0:T}$ using an Unscented Kalman Smoother (UKS) as follows.\n\n- Use an Unscented Kalman Filter (UKF) with the observation noise approximated by a Gaussian whose variance matches the Laplace variance. The Laplace distribution with scale $b$ has variance $2 b^2$, so use a Gaussian approximation $\\mathcal{N}(0, R)$ with $R = 2 b^2$ for the UKF measurement update.\n- Use the standard Unscented Transform in one dimension with parameters $\\alpha$, $\\beta$, and $\\kappa$ to compute sigma points, their weights, and propagated means and covariances.\n- Perform a Rauch–Tung–Striebel smoothing step in the unscented setting to obtain the backward conditionals $q(x_T \\mid y_{0:T}) = \\mathcal{N}(m_{T\\mid T}, P_{T\\mid T})$ and, for $t = 0, \\dots, T-1$, the conditional densities $q(x_t \\mid x_{t+1}, y_{0:T}) = \\mathcal{N}(\\mu_t + J_t (x_{t+1} - m_{t+1\\mid t}), S_t)$, where $J_t$ is the smoothing gain computed from the filtered covariance at time $t$, the one-step predicted covariance at time $t+1$, and their cross-covariance. The backward simulation proposal $q(x_{0:T} \\mid y_{0:T})$ factorizes as $q(x_T \\mid y_{0:T}) \\prod_{t=0}^{T-1} q(x_t \\mid x_{t+1}, y_{0:T})$.\n\nUsing this proposal, consider an independence Metropolis–Hastings move on the full block $x_{0:T}$, with target proportional to the true posterior density under the non-Gaussian likelihood,\n$$\n\\pi(x_{0:T}) \\propto p(x_0) \\prod_{t=0}^{T-1} p(x_{t+1} \\mid x_t) \\prod_{t=0}^T p(y_t \\mid x_t),\n$$\nand proposal $q(x_{0:T} \\mid y_{0:T})$ as above. The acceptance probability for a proposed sample $x'_{0:T}$ from $q(\\cdot \\mid y_{0:T})$ against a fixed current trajectory $x_{0:T}$ is the independence Metropolis–Hastings acceptance derived from detailed balance.\n\nYour program must:\n\n- Implement the one-dimensional Unscented Kalman Filter and Unscented Rauch–Tung–Striebel smoother using the Gaussian approximation $R = 2 b^2$ for the measurement noise variance, and parameters $\\alpha$, $\\beta$, and $\\kappa$.\n- Implement backward simulation to draw a single sample $x'_{0:T}$ from $q(x_{0:T} \\mid y_{0:T})$, using a provided random seed for reproducibility.\n- Compute the natural logarithm of the posterior density $\\log \\pi(x_{0:T})$ up to and including all normalization constants under the true model (with Laplace likelihood) for any given trajectory $x_{0:T}$.\n- Compute the natural logarithm of the proposal density $\\log q(x_{0:T} \\mid y_{0:T})$ using the backward factorization specified above.\n- Compute the independence Metropolis–Hastings acceptance probability $a(x_{0:T}, x'_{0:T})$ for moving from a fixed current trajectory $x_{0:T}$ to the proposed $x'_{0:T}$ using the exact formula that follows from detailed balance and the above densities. Express the acceptance probability as a real number in $[0, 1]$.\n\nAssume the following fundamental base facts without further derivation.\n\n- Bayes’ rule for the posterior factorization and independence assumptions across time and observations.\n- The Metropolis–Hastings detailed balance condition and the form of the acceptance probability for independence proposals.\n- The Unscented Transform in one dimension with $L = 1$, $\\lambda = \\alpha^2 (L + \\kappa) - L$, sigma points $x^{(0)} = m$, $x^{(1)} = m + \\sqrt{(L + \\lambda) P}$, $x^{(2)} = m - \\sqrt{(L + \\lambda) P}$; weights for the mean $W_0^{(m)} = \\frac{\\lambda}{L + \\lambda}$, $W_0^{(c)} = \\frac{\\lambda}{L + \\lambda} + (1 - \\alpha^2 + \\beta)$, and $W_i^{(m)} = W_i^{(c)} = \\frac{1}{2(L + \\lambda)}$ for $i \\in \\{1, 2\\}$.\n\nUse the following test suite of parameter sets. In all cases, use the current trajectory $x_{t} = 0$ for all $t \\in \\{0, \\dots, T\\}$.\n\n- Test A (happy path, identity observation):\n  - Time horizon: $T = 3$.\n  - Dynamics: $f(x) = 0.7 x + 0.3 \\sin(x)$, process variance $Q = 0.01$.\n  - Observation: $h(x) = x$, Laplace scale $b = 0.3$.\n  - Prior: $m_0 = 0$, $P_0 = 1$.\n  - Unscented parameters: $\\alpha = 0.8$, $\\beta = 2.0$, $\\kappa = 0$.\n  - Observations: $y_{0:3} = [0.0, 0.2, -0.1, 0.1]$.\n  - Random seed for proposal sampling: $s = 12345$.\n\n- Test B (boundary case $T = 0$):\n  - Time horizon: $T = 0$.\n  - Dynamics: $f(x) = 0.7 x + 0.3 \\sin(x)$, process variance $Q = 0.01$.\n  - Observation: $h(x) = x$, Laplace scale $b = 0.1$.\n  - Prior: $m_0 = 0$, $P_0 = 1$.\n  - Unscented parameters: $\\alpha = 0.5$, $\\beta = 2.0$, $\\kappa = 0$.\n  - Observations: $y_{0} = [0.5]$.\n  - Random seed for proposal sampling: $s = 42$.\n\n- Test C (nonlinear observation):\n  - Time horizon: $T = 5$.\n  - Dynamics: $f(x) = 0.7 x + 0.3 \\sin(x)$, process variance $Q = 0.01$.\n  - Observation: $h(x) = 0.5 x^2$, Laplace scale $b = 0.5$.\n  - Prior: $m_0 = 0$, $P_0 = 1$.\n  - Unscented parameters: $\\alpha = 0.6$, $\\beta = 2.0$, $\\kappa = 0$.\n  - Observations: $y_{0:5} = [0.2, 0.1, 0.15, 0.05, 0.0, 0.1]$.\n  - Random seed for proposal sampling: $s = 2021$.\n\nYour program should produce, for each test, the independence Metropolis–Hastings acceptance probability $a(x_{0:T}, x'_{0:T})$ as a floating-point number rounded to six decimal places. The final output must be a single line containing the three acceptance probabilities in the order Test A, Test B, Test C, formatted as a comma-separated list inside square brackets, for example, $[a_A, a_B, a_C]$.\n\nNo physical units are involved. All angles are in radians where applicable. All percentages, if any, must be expressed as decimals.\n\nYour program must not require any input and must strictly follow the output format described above.", "solution": "The core task is to compute the acceptance probability for an independence Metropolis-Hastings (IMH) update for the entire state trajectory $x_{0:T}$.\n\n**The Metropolis-Hastings Framework**\nThe goal is to sample from the posterior distribution $\\pi(x_{0:T} \\mid y_{0:T})$, which, by Bayes' theorem, is proportional to the product of the likelihood and the prior:\n$$\n\\pi(x_{0:T} \\mid y_{0:T}) \\propto p(y_{0:T} \\mid x_{0:T}) p(x_{0:T})\n$$\nGiven the model's conditional independence structure, this expands to:\n$$\n\\pi(x_{0:T}) \\propto p(x_0) \\prod_{t=0}^{T-1} p(x_{t+1} \\mid x_t) \\prod_{t=0}^T p(y_t \\mid x_t)\n$$\nwhere the component densities are:\n- Prior: $p(x_0) = \\mathcal{N}(x_0; m_0, P_0)$\n- Dynamics: $p(x_{t+1} \\mid x_t) = \\mathcal{N}(x_{t+1}; f(x_t), Q)$\n- Likelihood: $p(y_t \\mid x_t) = \\text{Laplace}(y_t; h(x_t), b)$\n\nThe IMH algorithm generates a candidate state $x'_{0:T}$ from a proposal distribution $q(x'_{0:T} \\mid y_{0:T})$ that is independent of the current state $x_{0:T}$. The proposal is accepted with probability:\n$$\na(x_{0:T}, x'_{0:T}) = \\min\\left(1, \\frac{\\pi(x'_{0:T}) q(x_{0:T} \\mid y_{0:T})}{\\pi(x_{0:T}) q(x'_{0:T} \\mid y_{0:T})}\\right)\n$$\nTo make this ratio numerically stable, we compute its logarithm:\n$$\n\\log(\\text{ratio}) = \\left(\\log \\pi(x'_{0:T}) - \\log q(x'_{0:T} \\mid y_{0:T})\\right) - \\left(\\log \\pi(x_{0:T}) - \\log q(x_{0:T} \\mid y_{0:T})\\right)\n$$\n\n**Proposal Construction: The Unscented Kalman Smoother (UKS)**\nA good proposal distribution should approximate the target posterior. Here, we construct a Gaussian approximation using a UKS. This involves two main stages: a forward filter pass and a backward smoothing/sampling pass.\n\n**Approximation**: The true observation model has a Laplace likelihood, which is non-Gaussian. To use the Kalman filtering framework, we approximate the observation noise as Gaussian, $\\mathcal{N}(0, R)$, choosing the variance $R$ to match that of the Laplace distribution, i.e., $R = 2b^2$.\n\n**Stage A: Forward Unscented Kalman Filter (UKF)**\nThe UKF propagates the mean and covariance of the state distribution through the nonlinear dynamics and observation models using the Unscented Transform (UT). The UT deterministically selects a set of \"sigma points\" around the current mean, propagates them through the nonlinear function, and computes a weighted average to obtain the new mean and covariance.\n\nFor each time step $t=0, \\dots, T$:\n1.  **Prediction (for $t  0$)**: The filtered state from the previous step, $\\mathcal{N}(m_{t-1|t-1}, P_{t-1|t-1})$, is propagated through the dynamics function $f(x)$ using the UT. The process noise covariance $Q$ is added to yield the predicted state distribution $\\mathcal{N}(m_{t|t-1}, P_{t|t-1})$.\n2.  **Update**: The predicted state is propagated through the observation function $h(x)$ using the UT to find the predicted observation $\\hat{y}_t$ and its covariance $P_{yy}$, along with the state-observation cross-covariance $P_{xy}$. The Kalman gain $K_t$ is computed, and the state mean and covariance are updated using the actual observation $y_t$ to produce the filtered distribution $\\mathcal{N}(m_{t|t}, P_{t|t})$.\n\nThis forward pass provides a sequence of filtered distributions $\\{ \\mathcal{N}(m_{t|t}, P_{t|t}) \\}_{t=0}^T$ and predicted distributions $\\{ \\mathcal{N}(m_{t+1|t}, P_{t+1|t}) \\}_{t=0}^{T-1}$. We also store the cross-covariances $C_t = \\text{Cov}(x_t, f(x_t))$ from each prediction step, which are essential for the smoother.\n\n**Stage B: Backward Simulation**\nThe proposal distribution $q(x_{0:T} \\mid y_{0:T})$ is defined by a backward factorization based on the smoother:\n$$\nq(x_{0:T} \\mid y_{0:T}) = q(x_T \\mid y_{0:T}) \\prod_{t=T-1}^{0} q(x_t \\mid x_{t+1}, y_{0:T})\n$$\nThe terms are defined as follows:\n- The final state is drawn from the final filtered distribution: $q(x_T \\mid y_{0:T}) = \\mathcal{N}(x_T; m_{T|T}, P_{T|T})$.\n- The backward conditional kernels are also Gaussian, $q(x_t \\mid x_{t+1}, y_{0:T}) = \\mathcal{N}(x_t; \\tilde{m}_t, \\tilde{P}_t)$, with parameters derived from the forward filter's stored values (this is a Rauch-Tung-Striebel-type backward recursion):\n    - **Smoother Gain**: $J_t = C_t / P_{t+1|t}$\n    - **Smoothed Mean**: $\\tilde{m}_t = m_{t|t} + J_t (x_{t+1} - m_{t+1|t})$\n    - **Smoothed Covariance**: $\\tilde{P}_t = P_{t|t} - J_t C_t^T$\n\nSampling a trajectory $x'_{0:T}$ proceeds by first drawing $x'_T \\sim \\mathcal{N}(m_{T|T}, P_{T|T})$ and then iterating backwards from $t=T-1$ to $0$, drawing $x'_t \\sim \\mathcal{N}(\\tilde{m}_t(x'_{t+1}), \\tilde{P}_t)$.\n\n**Density Evaluation**\nTo compute the acceptance probability, we need to evaluate the log-densities $\\log \\pi(\\cdot)$ and $\\log q(\\cdot)$ for both the current trajectory $x_{0:T}$ (where $x_t=0$) and the proposed trajectory $x'_{0:T}$.\n\n- **Log-Target Density $\\log \\pi(x_{0:T})$**: This is the sum of the log-PDFs of the true model components, including all normalization constants:\n  $$\n  \\log \\pi(x_{0:T}) = \\log \\mathcal{N}(x_0; m_0, P_0) + \\sum_{t=0}^{T-1} \\log \\mathcal{N}(x_{t+1}; f(x_t), Q) + \\sum_{t=0}^T \\log \\text{Laplace}(y_t; h(x_t), b)\n  $$\n- **Log-Proposal Density $\\log q(x_{0:T} \\mid y_{0:T})$**: This is the sum of the log-PDFs of the Gaussian backward kernels, evaluated at the given trajectory:\n  $$\n  \\log q(x_{0:T} \\mid y_{0:T}) = \\log \\mathcal{N}(x_T; m_{T|T}, P_{T|T}) + \\sum_{t=T-1}^{0} \\log \\mathcal{N}(x_t; \\tilde{m}_t(x_{t+1}), \\tilde{P}_t)\n  $$\n\nWith these four log-density values, the acceptance probability $a = \\min(1, \\exp(\\log(\\text{ratio})))$ is readily computed. The case for $T=0$ simplifies to a single UKF update step, with no backward recursion.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm, laplace\n\ndef solve():\n    \"\"\"\n    Main solver function that processes all test cases and prints the final result.\n    \"\"\"\n\n    def unscented_transform(m, P, func, alpha, beta, kappa, func_args=None):\n        \"\"\"\n        Performs the 1D unscented transform.\n        \"\"\"\n        if func_args is None:\n            func_args = {}\n        \n        L = 1\n        lambda_ = alpha**2 * (L + kappa) - L\n        \n        # Sigma points\n        sqrt_term = np.sqrt((L + lambda_) * P)\n        sigmas = np.array([m, m + sqrt_term, m - sqrt_term])\n        \n        # Propagate sigma points\n        y_sigmas = np.array([func(s, **func_args) for s in sigmas])\n        \n        # Weights for mean\n        W_m = np.full(2 * L + 1, 1 / (2 * (L + lambda_)))\n        W_m[0] = lambda_ / (L + lambda_)\n        \n        # Weights for covariance\n        W_c = np.copy(W_m)\n        W_c[0] += (1 - alpha**2 + beta)\n        \n        # Propagated mean and covariance\n        y_hat = np.sum(W_m * y_sigmas)\n        P_yy = np.sum(W_c * (y_sigmas - y_hat)**2)\n        \n        # Cross-covariance\n        P_xy = np.sum(W_c * (sigmas - m) * (y_sigmas - y_hat))\n        \n        return y_hat, P_yy, P_xy\n\n    def run_ukf_smoother(y, f, h, Q, b, m0, P0, alpha, beta, kappa):\n        \"\"\"\n        Runs the Unscented Kalman Filter and stores parameters for the smoother.\n        \"\"\"\n        T = len(y) - 1\n        R = 2 * b**2\n\n        # Storage for filter outputs\n        m_filt = np.zeros(T + 1)\n        P_filt = np.zeros(T + 1)\n        m_pred = np.zeros(T) if T  0 else np.array([])\n        P_pred = np.zeros(T) if T  0 else np.array([])\n        C_cross = np.zeros(T) if T  0 else np.array([])\n\n        m_prior, P_prior = m0, P0\n\n        for t in range(T + 1):\n            # Update step\n            y_pred, P_yy, P_xy = unscented_transform(m_prior, P_prior, h, alpha, beta, kappa)\n            S_t = P_yy + R\n            K_t = P_xy / S_t\n            \n            m_filt[t] = m_prior + K_t * (y[t] - y_pred)\n            P_filt[t] = P_prior - K_t * S_t * K_t\n            \n            # Prediction step for next time step (if not last step)\n            if t  T:\n                m_next_pred, P_next_pred_ff, C_t = unscented_transform(\n                    m_filt[t], P_filt[t], f, alpha, beta, kappa)\n                \n                m_pred[t] = m_next_pred\n                P_pred[t] = P_next_pred_ff + Q\n                C_cross[t] = C_t\n                \n                m_prior, P_prior = m_pred[t], P_pred[t]\n\n        return {\n            \"m_filt\": m_filt, \"P_filt\": P_filt,\n            \"m_pred\": m_pred, \"P_pred\": P_pred,\n            \"C_cross\": C_cross, \"T\": T\n        }\n\n    def backward_sample(proposal_params, seed):\n        \"\"\"\n        Draws one sample from the proposal distribution via backward simulation.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        T = proposal_params[\"T\"]\n        m_filt, P_filt = proposal_params[\"m_filt\"], proposal_params[\"P_filt\"]\n        m_pred, P_pred = proposal_params[\"m_pred\"], proposal_params[\"P_pred\"]\n        C_cross = proposal_params[\"C_cross\"]\n\n        x_prime = np.zeros(T + 1)\n        \n        # Sample final state\n        x_prime[T] = rng.normal(m_filt[T], np.sqrt(P_filt[T]))\n\n        # Backward sampling loop\n        for t in range(T - 1, -1, -1):\n            J_t = C_cross[t] / P_pred[t]\n            mu_t = m_filt[t] + J_t * (x_prime[t+1] - m_pred[t])\n            S_t = P_filt[t] - J_t * C_cross[t]\n            # Ensure S_t is non-negative for robustness\n            if S_t  0: S_t = 1e-12 \n            x_prime[t] = rng.normal(mu_t, np.sqrt(S_t))\n        \n        return x_prime\n\n    def log_target_pdf(x, y, f, h, Q, b, m0, P0):\n        \"\"\"\n        Computes the log of the true posterior density (up to a constant).\n        \"\"\"\n        T = len(x) - 1\n        log_p = norm.logpdf(x[0], loc=m0, scale=np.sqrt(P0))\n        \n        for t in range(T):\n            f_xt = f(x[t])\n            log_p += norm.logpdf(x[t+1], loc=f_xt, scale=np.sqrt(Q))\n        \n        for t in range(T + 1):\n            h_xt = h(x[t])\n            log_p += laplace.logpdf(y[t], loc=h_xt, scale=b)\n            \n        return log_p\n\n    def log_proposal_pdf(x, proposal_params):\n        \"\"\"\n        Computes the log of the proposal density.\n        \"\"\"\n        T = proposal_params[\"T\"]\n        m_filt, P_filt = proposal_params[\"m_filt\"], proposal_params[\"P_filt\"]\n        m_pred, P_pred = proposal_params[\"m_pred\"], proposal_params[\"P_pred\"]\n        C_cross = proposal_params[\"C_cross\"]\n        \n        log_q = norm.logpdf(x[T], loc=m_filt[T], scale=np.sqrt(P_filt[T]))\n\n        for t in range(T - 1, -1, -1):\n            J_t = C_cross[t] / P_pred[t]\n            mu_t = m_filt[t] + J_t * (x[t+1] - m_pred[t])\n            S_t = P_filt[t] - J_t * C_cross[t]\n            if S_t  0: S_t = 1e-12\n            log_q += norm.logpdf(x[t], loc=mu_t, scale=np.sqrt(S_t))\n            \n        return log_q\n\n    def calculate_acceptance_prob(params):\n        \"\"\"\n        Orchestrates the calculation for a single test case.\n        \"\"\"\n        T = params[\"T\"]\n        x_current = np.zeros(T + 1)\n        \n        f = lambda x: params[\"f_params\"][\"a\"] * x + params[\"f_params\"][\"b\"] * np.sin(x)\n        h = params[\"h_func\"]\n\n        # 1. Run UKS to get proposal parameters\n        proposal_params = run_ukf_smoother(\n            params[\"y\"], f, h, params[\"Q\"], params[\"b\"],\n            params[\"m0\"], params[\"P0\"], params[\"alpha\"], params[\"beta\"], params[\"kappa\"]\n        )\n\n        # 2. Draw a sample from the proposal\n        x_proposed = backward_sample(proposal_params, params[\"seed\"])\n\n        # 3. Compute log target densities\n        log_pi_current = log_target_pdf(\n            x_current, params[\"y\"], f, h, params[\"Q\"], params[\"b\"], params[\"m0\"], params[\"P0\"]\n        )\n        log_pi_proposed = log_target_pdf(\n            x_proposed, params[\"y\"], f, h, params[\"Q\"], params[\"b\"], params[\"m0\"], params[\"P0\"]\n        )\n\n        # 4. Compute log proposal densities\n        log_q_current = log_proposal_pdf(x_current, proposal_params)\n        log_q_proposed = log_proposal_pdf(x_proposed, proposal_params)\n        \n        # 5. Compute acceptance probability\n        log_ratio = (log_pi_proposed - log_q_proposed) - (log_pi_current - log_q_current)\n        \n        acceptance_prob = min(1.0, np.exp(log_ratio))\n        return acceptance_prob\n\n    f_params = {\"a\": 0.7, \"b\": 0.3}\n\n    test_cases = [\n        # Test A\n        {\n            \"T\": 3, \"Q\": 0.01, \"h_func\": lambda x: x, \"b\": 0.3,\n            \"m0\": 0.0, \"P0\": 1.0, \"alpha\": 0.8, \"beta\": 2.0, \"kappa\": 0.0,\n            \"y\": np.array([0.0, 0.2, -0.1, 0.1]), \"seed\": 12345, \"f_params\": f_params\n        },\n        # Test B\n        {\n            \"T\": 0, \"Q\": 0.01, \"h_func\": lambda x: x, \"b\": 0.1,\n            \"m0\": 0.0, \"P0\": 1.0, \"alpha\": 0.5, \"beta\": 2.0, \"kappa\": 0.0,\n            \"y\": np.array([0.5]), \"seed\": 42, \"f_params\": f_params\n        },\n        # Test C\n        {\n            \"T\": 5, \"Q\": 0.01, \"h_func\": lambda x: 0.5 * x**2, \"b\": 0.5,\n            \"m0\": 0.0, \"P0\": 1.0, \"alpha\": 0.6, \"beta\": 2.0, \"kappa\": 0.0,\n            \"y\": np.array([0.2, 0.1, 0.15, 0.05, 0.0, 0.1]), \"seed\": 2021, \"f_params\": f_params\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        prob = calculate_acceptance_prob(case)\n        results.append(f\"{prob:.6f}\")\n    \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3415098"}]}