{"hands_on_practices": [{"introduction": "The first step in mastering inverse scattering is to deeply understand the forward problem under simplifying assumptions. The Born approximation provides the most fundamental linearization, revealing a direct link between the scattering potential and the far-field data. This exercise [@problem_id:3392438] guides you through an analytical calculation that makes this connection explicit, showing that the far-field pattern is proportional to the Fourier transform of the scattering contrast.", "problem": "Consider time-harmonic scalar acoustic scattering in three spatial dimensions, where the total field $u(x)$ satisfies the free-space Helmholtz equation with scattering contrast $q(x)$,\n$$\n\\Delta u(x) + k^{2}\\big(1+q(x)\\big)u(x) = 0,\n$$\nfor wavenumber $k0$. The incident field is the plane wave $u_{\\mathrm{inc}}(x) = \\exp\\big(i k\\, d\\cdot x\\big)$ with incidence direction $d\\in\\mathbb{S}^{2}$, where $\\mathbb{S}^{2}$ denotes the unit sphere in $\\mathbb{R}^{3}$. The scattered field $u^{s}(x) = u(x) - u_{\\mathrm{inc}}(x)$ satisfies the Sommerfeld radiation condition and admits the standard far-field asymptotic\n$$\nu^{s}(x) = \\frac{\\exp\\big(i k |x|\\big)}{|x|}u_{\\infty}(\\hat x,d) + \\mathcal{O}\\!\\left(\\frac{1}{|x|^{2}}\\right),\\quad |x|\\to\\infty,\\quad \\hat x := \\frac{x}{|x|}\\in\\mathbb{S}^{2}.\n$$\nStarting from the free-space Green’s function for the Helmholtz operator, the Lippmann–Schwinger representation, and the first Born approximation (replace the total field in the volume integral by the incident plane wave), derive the Born far-field $u_{\\infty}(\\hat x,d)$ for the spherically symmetric Gaussian-shaped contrast\n$$\nq(x) \\;=\\; \\alpha\\,\\exp\\!\\left(-\\frac{|x|^{2}}{a^{2}}\\right),\n$$\nwhere $\\alpha\\in\\mathbb{R}$ and $a0$ are given constants. Then, model the angular resolution of the Born far-field pattern by the full width at half maximum (FWHM) of the scattered intensity $|u_{\\infty}(\\theta)|^{2}$ as a function of the scattering angle $\\theta := \\arccos\\!\\big(\\hat x\\cdot d\\big)\\in[0,\\pi]$. Obtain a closed-form analytic expression for the FWHM, denoted $\\Delta\\theta_{\\mathrm{FWHM}}$, explicitly in terms of $a$ and $k$. \n\nYour final answers must be exact closed-form expressions. Express the angular width $\\Delta\\theta_{\\mathrm{FWHM}}$ in radians. If you perform any small-angle approximation, clearly state it as an intermediate step, but the requested final expression for $\\Delta\\theta_{\\mathrm{FWHM}}$ must be exact (i.e., without approximation). Provide your final answers as a pair, in the order: the Born far-field $u_{\\infty}(\\hat x,d)$, and $\\Delta\\theta_{\\mathrm{FWHM}}$ in radians.", "solution": "The user wants to solve a direct scattering problem within the Born approximation. The steps are to first validate the problem, then derive the Born far-field scattering amplitude for a Gaussian potential, and finally calculate the full width at half maximum (FWHM) of the resulting scattered intensity.\n\n### Step 1: Extract Givens\n- Governing Equation: $\\Delta u(x) + k^{2}\\big(1+q(x)\\big)u(x) = 0$\n- Wavenumber: $k0$\n- Scattering Contrast: $q(x) = \\alpha\\,\\exp\\!\\left(-\\frac{|x|^{2}}{a^{2}}\\right)$, with $\\alpha\\in\\mathbb{R}$ and $a0$.\n- Incident Field: $u_{\\mathrm{inc}}(x) = \\exp\\big(i k\\, d\\cdot x\\big)$, with direction $d\\in\\mathbb{S}^{2}$.\n- Total Field: $u(x)$\n- Scattered Field: $u^{s}(x) = u(x) - u_{\\mathrm{inc}}(x)$\n- Far-field Asymptotics: $u^{s}(x) = \\frac{\\exp\\big(i k |x|\\big)}{|x|}u_{\\infty}(\\hat x,d) + \\mathcal{O}\\!\\left(\\frac{1}{|x|^{2}}\\right)$ for $|x|\\to\\infty$, where $\\hat x = x/|x|\\in\\mathbb{S}^{2}$.\n- Scattering Angle: $\\theta := \\arccos\\!\\big(\\hat x\\cdot d\\big)\\in[0,\\pi]$\n- Required Method: Start from the Lippmann–Schwinger representation and use the first Born approximation.\n- Required Outputs:\n    1. A closed-form analytic expression for the Born far-field amplitude $u_{\\infty}(\\hat x,d)$.\n    2. A closed-form analytic expression for the FWHM of the scattered intensity $|u_{\\infty}(\\theta)|^{2}$, denoted $\\Delta\\theta_{\\mathrm{FWHM}}$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is based on the Helmholtz equation, the Lippmann-Schwinger equation, and the Born approximation, which are standard, fundamental concepts in wave scattering theory (e.g., in acoustics, electromagnetism, and quantum mechanics). The use of a Gaussian potential is a common and physically meaningful model.\n- **Well-Posed**: The problem is a direct calculation. It asks for the derivation of a specific quantity (the far-field amplitude) and a property of it (FWHM) under a well-defined approximation (Born) for a specified potential. The steps are mathematically sound and lead to a unique solution.\n- **Objective**: The problem is stated in precise, objective mathematical language, free from ambiguity or subjective elements.\n- **Completeness and Consistency**: All necessary equations, definitions, and parameters are provided. The definitions are standard and consistent with each other and with the established literature in scattering theory.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is a standard exercise in scattering theory. I will proceed with the solution.\n\n### Derivation of the Born Far-Field Amplitude\nThe time-harmonic acoustic wave equation can be rewritten as the inhomogeneous Helmholtz equation:\n$$\n\\Delta u(x) + k^{2}u(x) = -k^{2}q(x)u(x)\n$$\nThis equation can be expressed in an integral form, known as the Lippmann-Schwinger equation, using the free-space Green's function for the Helmholtz operator, $G(x,y) = \\frac{\\exp(ik|x-y|)}{4\\pi|x-y|}$:\n$$\nu(x) = u_{\\mathrm{inc}}(x) + \\int_{\\mathbb{R}^3} G(x,y) \\left(-k^2 q(y) u(y)\\right) d^3y\n$$\nThe scattered field $u^s(x) = u(x) - u_{\\mathrm{inc}}(x)$ is therefore given by:\n$$\nu^s(x) = -k^2 \\int_{\\mathbb{R}^3} \\frac{\\exp(ik|x-y|)}{4\\pi|x-y|} q(y) u(y) d^3y\n$$\nThe first Born approximation consists of replacing the unknown total field $u(y)$ inside the integral with the known incident field $u_{\\mathrm{inc}}(y) = \\exp(ik d\\cdot y)$. The Born-approximated scattered field $u^s_B(x)$ is:\n$$\nu^s_B(x) = -k^2 \\int_{\\mathbb{R}^3} \\frac{\\exp(ik|x-y|)}{4\\pi|x-y|} q(y) \\exp(ik d\\cdot y) d^3y\n$$\nTo find the far-field amplitude $u_\\infty(\\hat x, d)$, we consider the limit $|x|\\to\\infty$. In this limit, we use the approximations:\n$$\n|x-y| \\approx |x| - \\hat x \\cdot y \\quad \\text{and} \\quad \\frac{1}{|x-y|} \\approx \\frac{1}{|x|}\n$$\nSubstituting these into the integral for $u^s_B(x)$:\n$$\nu^s_B(x) \\approx -k^2 \\int_{\\mathbb{R}^3} \\frac{\\exp(ik(|x| - \\hat x \\cdot y))}{4\\pi|x|} q(y) \\exp(ik d\\cdot y) d^3y\n$$\n$$\nu^s_B(x) \\approx \\frac{\\exp(ik|x|)}{|x|} \\left[ -\\frac{k^2}{4\\pi} \\int_{\\mathbb{R}^3} q(y) \\exp(-ik\\hat x \\cdot y) \\exp(ik d \\cdot y) d^3y \\right]\n$$\nBy comparing this with the given asymptotic form $u^s(x) = \\frac{\\exp(ik|x|)}{|x|}u_{\\infty}(\\hat x,d) + \\mathcal{O}(|x|^{-2})$, we identify the Born far-field amplitude:\n$$\nu_{\\infty}(\\hat x,d) = -\\frac{k^2}{4\\pi} \\int_{\\mathbb{R}^3} q(y) \\exp\\big(ik(d - \\hat x)\\cdot y\\big) d^3y\n$$\nThis expression shows that the far-field amplitude is proportional to the 3D Fourier transform of the scattering contrast $q(y)$ evaluated at the spatial frequency vector $k(\\hat x - d)$.\nNow, we substitute the given Gaussian contrast $q(y) = \\alpha \\exp(-|y|^2/a^2)$:\n$$\nu_{\\infty}(\\hat x,d) = -\\frac{\\alpha k^2}{4\\pi} \\int_{\\mathbb{R}^3} \\exp\\left(-\\frac{|y|^2}{a^2}\\right) \\exp\\big(i k(d - \\hat x)\\cdot y\\big) d^3y\n$$\nThe integral is a standard Gaussian integral, which is the 3D Fourier transform of a Gaussian function. The general formula for the Fourier transform of a Gaussian is:\n$$\n\\int_{\\mathbb{R}^3} \\exp(-b|y|^2) \\exp(i v \\cdot y) d^3y = \\left(\\frac{\\pi}{b}\\right)^{3/2} \\exp\\left(-\\frac{|v|^2}{4b}\\right)\n$$\nIn our case, $b = 1/a^2$ and the vector $v = k(d-\\hat x)$. Therefore, the integral evaluates to:\n$$\n\\int_{\\mathbb{R}^3} \\exp\\left(-\\frac{|y|^2}{a^2}\\right) \\exp\\big(i k(d - \\hat x)\\cdot y\\big) d^3y = \\left(\\frac{\\pi}{1/a^2}\\right)^{3/2} \\exp\\left(-\\frac{|k(d-\\hat x)|^2}{4(1/a^2)}\\right) = (\\pi a^2)^{3/2} \\exp\\left(-\\frac{k^2 a^2 |d-\\hat x|^2}{4}\\right)\n$$\nLet's simplify the term $|d-\\hat x|^2$. Since $d$ and $\\hat x$ are unit vectors,\n$$\n|d-\\hat x|^2 = (d-\\hat x)\\cdot(d-\\hat x) = |d|^2 + |\\hat x|^2 - 2(d\\cdot\\hat x) = 1 + 1 - 2(d\\cdot \\hat x) = 2(1 - d\\cdot\\hat x)\n$$\nSubstituting this back into the exponential term:\n$$\n\\exp\\left(-\\frac{k^2 a^2}{4} \\cdot 2(1-d\\cdot\\hat x)\\right) = \\exp\\left(-\\frac{k^2 a^2}{2}(1-d\\cdot\\hat x)\\right)\n$$\nNow, substitute the result of the integral back into the expression for $u_\\infty(\\hat x, d)$:\n$$\nu_{\\infty}(\\hat x,d) = -\\frac{\\alpha k^2}{4\\pi} \\left[ \\pi^{3/2} a^3 \\exp\\left(-\\frac{k^2 a^2}{2}(1-d\\cdot\\hat x)\\right) \\right]\n$$\nSimplifying the pre-factor gives the first part of the final answer:\n$$\nu_{\\infty}(\\hat x,d) = -\\frac{\\alpha k^2 a^3 \\sqrt{\\pi}}{4} \\exp\\left(-\\frac{k^2 a^2}{2}(1 - \\hat x \\cdot d)\\right)\n$$\n\n### Derivation of the FWHM\nThe scattered intensity is given by $I = |u_{\\infty}(\\hat x,d)|^2$. Since the dependence on $\\hat x$ and $d$ is only through their dot product, we can write the intensity as a function of the scattering angle $\\theta = \\arccos(\\hat x \\cdot d)$:\n$$\nI(\\theta) = \\left| -\\frac{\\alpha k^2 a^3 \\sqrt{\\pi}}{4} \\exp\\left(-\\frac{k^2 a^2}{2}(1 - \\cos\\theta)\\right) \\right|^2\n$$\n$$\nI(\\theta) = \\frac{\\alpha^2 k^4 a^6 \\pi}{16} \\exp\\left(-k^2 a^2(1 - \\cos\\theta)\\right)\n$$\nThe maximum intensity $I_{\\mathrm{max}}$ occurs at the minimum value of the argument in the exponent, which is when $1-\\cos\\theta$ is minimal. This happens at $\\theta=0$ (forward scattering), where $\\cos(0)=1$.\n$$\nI_{\\mathrm{max}} = I(0) = \\frac{\\alpha^2 k^4 a^6 \\pi}{16}\n$$\nThe Full Width at Half Maximum (FWHM), denoted $\\Delta\\theta_{\\mathrm{FWHM}}$, is the width of the intensity profile at half of its maximum value. The intensity profile $I(\\theta)$ is an even function of $\\theta$, symmetric about $\\theta=0$. We find the angle $\\theta^*0$ where the intensity is half its maximum, i.e., $I(\\theta^*) = I_{\\mathrm{max}}/2$. The FWHM is then given by $\\Delta\\theta_{\\mathrm{FWHM}} = 2\\theta^*$.\nThe condition $I(\\theta^*) = I_{\\mathrm{max}}/2$ gives:\n$$\n\\frac{\\alpha^2 k^4 a^6 \\pi}{16} \\exp\\left(-k^2 a^2(1 - \\cos\\theta^*)\\right) = \\frac{1}{2} \\frac{\\alpha^2 k^4 a^6 \\pi}{16}\n$$\n$$\n\\exp\\left(-k^2 a^2(1 - \\cos\\theta^*)\\right) = \\frac{1}{2}\n$$\nTaking the natural logarithm of both sides:\n$$\n-k^2 a^2(1 - \\cos\\theta^*) = \\ln\\left(\\frac{1}{2}\\right) = -\\ln(2)\n$$\n$$\n1 - \\cos\\theta^* = \\frac{\\ln(2)}{k^2 a^2}\n$$\nSolving for $\\cos\\theta^*$:\n$$\n\\cos\\theta^* = 1 - \\frac{\\ln(2)}{k^2 a^2}\n$$\nThe half-width angle $\\theta^*$ is then:\n$$\n\\theta^* = \\arccos\\left(1 - \\frac{\\ln(2)}{k^2 a^2}\\right)\n$$\nThis expression yields a real angle $\\theta^*$ provided that the argument of $\\arccos$ is in $[-1, 1]$, which requires $k^2 a^2 \\ge \\ln(2)/2$. Assuming this condition holds, the FWHM is:\n$$\n\\Delta\\theta_{\\mathrm{FWHM}} = 2\\theta^* = 2\\arccos\\left(1 - \\frac{\\ln(2)}{k^2 a^2}\\right)\n$$\nThis is the second part of the final answer.", "answer": "$$\n\\boxed{\\begin{pmatrix} -\\frac{\\alpha k^{2} a^{3} \\sqrt{\\pi}}{4} \\exp\\left(-\\frac{k^{2} a^{2}}{2}(1 - \\hat x \\cdot d)\\right)  2\\arccos\\left(1 - \\frac{\\ln(2)}{k^{2}a^{2}}\\right) \\end{pmatrix}}\n$$", "id": "3392438"}, {"introduction": "Linearizations like the Born and Rytov approximations are invaluable, but their validity is limited to specific regimes, typically involving weak scattering or small phase perturbations. This hands-on numerical experiment [@problem_id:3392387] challenges you to move from analytical formulas to computational practice. By implementing and comparing these linearizations against a full numerical solution, you will develop a quantitative intuition for their domains of accuracy, a critical skill for diagnosing and designing effective inversion algorithms.", "problem": "Consider time-harmonic scalar waves governed by the Helmholtz equation in three spatial dimensions with a compactly supported relative contrast. Let $q: \\mathbb{R}^3 \\to \\mathbb{C}$ be the contrast, and let $k  0$ be the wavenumber. The total field $u(x)$ obeys $(\\Delta + k^2(1 + q(x))) u(x) = 0$ with incident plane wave $u^{\\mathrm{i}}(x) = e^{i k d \\cdot x}$, for a unit incident direction $d \\in \\mathbb{S}^2$. The scattered field satisfies the Lippmann–Schwinger integral equation\n$$\nu(x) = u^{\\mathrm{i}}(x) + k^2 \\int_{\\mathbb{R}^3} G_k(x,y) \\, q(y) \\, u(y) \\, \\mathrm{d}y,\n$$\nwhere $G_k(x,y) = \\dfrac{e^{ik |x-y|}}{4\\pi |x-y|}$ is the free-space Green's function in three dimensions. The far-field pattern is given by\n$$\nu^\\infty(\\hat{x}, d) = \\frac{k^2}{4\\pi} \\int_{\\mathbb{R}^3} e^{-i k \\hat{x} \\cdot y} \\, q(y) \\, u(y) \\, \\mathrm{d}y, \\quad \\hat{x} \\in \\mathbb{S}^2.\n$$\nTwo classical first-order linearizations are the Born approximation and the Rytov approximation. The Born approximation replaces $u(y)$ by $u^{\\mathrm{i}}(y)$ in the integral. The Rytov approximation represents $u(x) = u^{\\mathrm{i}}(x) e^{\\psi(x)}$ and linearizes $\\psi(x)$, yielding a first-order phase $\\psi_1(x)$ satisfying\n$$\n\\psi_1(x) \\approx k^2 \\int_{\\mathbb{R}^3} G_k(x,y) \\, q(y) \\, e^{i k d \\cdot (y - x)} \\, \\mathrm{d}y,\n$$\nand the Rytov field $u^{\\mathrm{R}}(x) \\approx u^{\\mathrm{i}}(x) \\, e^{\\psi_1(x)}$.\n\nYour task is to design and implement a numerical experiment that distinguishes regimes in which the second-order error $O(\\|q\\|^2)$ in the far-field pattern $u^\\infty(\\hat{x},d)$ is negligible for each linearization and to validate the prediction using the Lippmann–Schwinger residual. The experiment must be carried out in a three-dimensional setting with a compactly supported $q(x)$ inside a ball of radius $R$ centered at the origin. All quantities are dimensionless.\n\nFundamental base and derivation requirements:\n- Begin from the Helmholtz equation and the Lippmann–Schwinger integral equation as stated. Use the provided Green's function and far-field representation.\n- Define a dimensionless smallness predictor that estimates when second-order terms $O(\\|q\\|^2)$ are negligible in the far field. Use a norm-based bound derived from the operator form of the Lippmann–Schwinger equation to motivate the predictor. You must justify the predictor qualitatively and implement it quantitatively.\n- Define the Lippmann–Schwinger residual for a candidate internal field $v(x)$ discretized at points $\\{x_i\\}$ as\n$$\n\\mathcal{R}[v] = \\frac{\\left\\|v - u^{\\mathrm{i}} - k^2 \\int G_k(\\cdot,y) q(y) v(y) \\, \\mathrm{d}y \\right\\|_{L^2(\\Omega)}}{\\|v\\|_{L^2(\\Omega)}},\n$$\nand approximate it using your discrete quadrature.\n- Compute and compare the Born and Rytov predictions of the far-field amplitude in the forward direction $\\hat{x} = d$. Validate them against a numerically computed reference solution obtained by solving the discretized Lippmann–Schwinger integral equation for $u(x)$.\n- Provide and use a tolerance $\\varepsilon$ to decide when the second-order error is negligible, and report both the residuals and the far-field relative errors.\n\nDiscretization and algorithm:\n- Discretize the support ball of radius $R$ using a cubic grid of spacing $h$, retaining grid points that lie within the ball $\\|x\\| \\le R$. Use uniform volume weights $\\Delta V = h^3$ for retained points. Exclude diagonal singularities by setting the kernel to zero on the diagonal.\n- Assemble the dense Green's function matrix $G_{ij} = \\dfrac{e^{i k |x_i - x_j|}}{4\\pi |x_i - x_j|}$ for $i \\ne j$ and $G_{ii} = 0$.\n- Let the contrast be a Gaussian $q(x) = a \\exp\\!\\left(-\\frac{\\|x\\|^2}{2\\sigma^2}\\right)$ with amplitude $a$ and width $\\sigma$.\n- Solve the discrete Lippmann–Schwinger equation for the internal field $u$,\n$$\nu = u^{\\mathrm{i}} + k^2 \\, \\Delta V \\, G \\, (q \\odot u),\n$$\nas a linear system $(I - k^2 \\Delta V \\, G \\, \\mathrm{diag}(q)) u = u^{\\mathrm{i}}$.\n- Compute the Born internal field $u^{\\mathrm{B}} = u^{\\mathrm{i}} + k^2 \\Delta V \\, G \\, (q \\odot u^{\\mathrm{i}})$.\n- Compute the first-order Rytov phase $\\psi_1$ by\n$$\n\\psi_{1,i} = k^2 \\Delta V \\sum_{j} G_{ij} \\, q_j \\, e^{i k \\, d \\cdot (x_j - x_i)},\n$$\nand then $u^{\\mathrm{R}}_i = u^{\\mathrm{i}}_i \\, e^{\\psi_{1,i}}$.\n- Compute far-field amplitudes in the forward direction $\\hat{x} = d$ by discrete quadrature,\n$$\nu^\\infty(d,d) \\approx \\frac{k^2}{4\\pi} \\, \\Delta V \\sum_j e^{-i k \\, d \\cdot x_j} \\, q_j \\, u_j,\n$$\nand analogously for $u^{\\mathrm{B}}$ and $u^{\\mathrm{R}}$.\n\nPrediction and validation:\n- Define the smallness predictor $\\mu = k^2 R^2 \\|q\\|_{\\infty}$ and report it. Justify that for $\\mu \\ll 1$, second-order terms are negligible in the far-field.\n- Define the residuals $\\mathcal{R}[u^{\\mathrm{B}}]$ and $\\mathcal{R}[u^{\\mathrm{R}}]$ by discretizing the $L^2$ norm using the grid and weights.\n- Define the far-field relative errors, for a reference far-field $u^\\infty_{\\mathrm{ref}}$ from the solved $u$,\n$$\ne_{\\mathrm{B}} = \\frac{|u^\\infty_{\\mathrm{B}} - u^\\infty_{\\mathrm{ref}}|}{\\max(|u^\\infty_{\\mathrm{ref}}|, \\delta)}, \\quad e_{\\mathrm{R}} = \\frac{|u^\\infty_{\\mathrm{R}} - u^\\infty_{\\mathrm{ref}}|}{\\max(|u^\\infty_{\\mathrm{ref}}|, \\delta)},\n$$\nwith a small $\\delta$ to avoid division by zero.\n- Use a tolerance $\\varepsilon$ and decide that the second-order error is negligible if both the residual and the far-field relative error are below $\\varepsilon$.\n\nTest suite:\n- Use $d = (1,0,0)$ and $\\hat{x} = d$ for all tests. Let $R = 0.25$ and $h = R/2$ so that points are sampled from a $5 \\times 5 \\times 5$ grid inside the ball. Use volume weight $\\Delta V = h^3$ uniformly.\n- Let the tolerance be $\\varepsilon = 0.05$ and $\\delta = 10^{-12}$.\n- Consider four test cases with parameters $(k, a, \\sigma)$:\n    1. $k = 5$, $a = 0.02$, $\\sigma = 0.10$.\n    2. $k = 10$, $a = 0.10$, $\\sigma = 0.10$.\n    3. $k = 20$, $a = 0.50$, $\\sigma = 0.08$.\n    4. $k = 2$, $a = 0.30$, $\\sigma = 0.10$.\n\nAnswer specification and final output format:\n- For each test case, compute and return a list of six values: $[\\mu, \\mathcal{R}[u^{\\mathrm{B}}], \\mathcal{R}[u^{\\mathrm{R}}], e_{\\mathrm{B}}, e_{\\mathrm{R}}, b]$, where $b$ is the integer $1$ if $e_{\\mathrm{R}}  e_{\\mathrm{B}}$ and $0$ otherwise.\n- Your program should produce a single line of output containing the results for the four test cases as a comma-separated list enclosed in square brackets of lists, for example, $[[\\text{case1}],[\\text{case2}],[\\text{case3}],[\\text{case4}]]$.", "solution": "The user wants me to act as a meticulous STEM professor to solve a problem in inverse scattering theory.\n\nMy first task is to critically validate the problem statement.\n\n**Problem Validation - Step 1: Extract Givens**\n\n1.  **Governing Equation**: Time-harmonic scalar waves described by the Helmholtz equation $(\\Delta + k^2(1 + q(x))) u(x) = 0$.\n2.  **Contrast**: $q: \\mathbb{R}^3 \\to \\mathbb{C}$ is a compactly supported relative contrast.\n3.  **Wavenumber**: $k  0$.\n4.  **Incident Field**: Plane wave $u^{\\mathrm{i}}(x) = e^{i k d \\cdot x}$, with $d \\in \\mathbb{S}^2$.\n5.  **Integral Equation**: Lippmann–Schwinger equation: $u(x) = u^{\\mathrm{i}}(x) + k^2 \\int_{\\mathbb{R}^3} G_k(x,y) \\, q(y) \\, u(y) \\, \\mathrm{d}y$.\n6.  **Green's Function**: $G_k(x,y) = \\dfrac{e^{ik |x-y|}}{4\\pi |x-y|}$ in 3D.\n7.  **Far-Field Pattern**: $u^\\infty(\\hat{x}, d) = \\frac{k^2}{4\\pi} \\int_{\\mathbb{R}^3} e^{-i k \\hat{x} \\cdot y} \\, q(y) \\, u(y) \\, \\mathrm{d}y$, with $\\hat{x} \\in \\mathbb{S}^2$.\n8.  **Born Approximation**: $u(y)$ is replaced by $u^{\\mathrm{i}}(y)$ in the integral.\n9.  **Rytov Approximation**: $u(x) = u^{\\mathrm{i}}(x) e^{\\psi(x)}$; linearize $\\psi(x)$. The first-order phase $\\psi_1(x)$ is given by $\\psi_1(x) \\approx k^2 \\int_{\\mathbb{R}^3} G_k(x,y) \\, q(y) \\, e^{i k d \\cdot (y - x)} \\, \\mathrm{d}y$. The Rytov field is $u^{\\mathrm{R}}(x) \\approx u^{\\mathrm{i}}(x) \\, e^{\\psi_1(x)}$.\n10. **Task Objective**: Distinguish regimes where second-order error $O(\\|q\\|^2)$ is negligible for each linearization. Validate with Lippmann–Schwinger residual.\n11. **Setting**: 3D, contrast $q(x)$ compactly supported in a ball of radius $R$ at the origin. All quantities dimensionless.\n12. **Smallness Predictor**: Define $\\mu = k^2 R^2 \\|q\\|_{\\infty}$ and justify it as a predictor for when $O(\\|q\\|^2)$ terms are negligible.\n13. **Residual Definition**: $\\mathcal{R}[v] = \\frac{\\left\\|v - u^{\\mathrm{i}} - k^2 \\int G_k(\\cdot,y) q(y) v(y) \\, \\mathrm{d}y \\right\\|_{L^2(\\Omega)}}{\\|v\\|_{L^2(\\Omega)}}$, where $\\Omega$ is the support of $q$.\n14. **Comparison**: Compare Born and Rytov far-field amplitudes in the forward direction $\\hat{x} = d$ against a reference solution from the full Lippmann-Schwinger equation.\n15. **Tolerance**: Use a tolerance $\\varepsilon$ to decide if second-order error is negligible (residual and relative error must be below $\\varepsilon$).\n16. **Discretization**:\n    - Support: Ball of radius $R$.\n    - Grid: Cubic grid with spacing $h$, keeping points with $\\|x\\| \\le R$.\n    - Weights: Uniform volume elements $\\Delta V = h^3$.\n    - Green's Matrix: $G_{ij} = \\dfrac{e^{i k |x_i - x_j|}}{4\\pi |x_i - x_j|}$ for $i \\ne j$, and $G_{ii} = 0$.\n17. **Contrast Form**: Gaussian $q(x) = a \\exp\\!\\left(-\\frac{\\|x\\|^2}{2\\sigma^2}\\right)$.\n18. **Numerical Solution (Reference)**: Solve the linear system $(I - k^2 \\Delta V \\, G \\, \\mathrm{diag}(q)) u = u^{\\mathrm{i}}$ for the internal field $u$.\n19. **Numerical Solution (Born)**: Compute internal field $u^{\\mathrm{B}} = u^{\\mathrm{i}} + k^2 \\Delta V \\, G \\, (q \\odot u^{\\mathrm{i}})$.\n20. **Numerical Solution (Rytov)**: Compute phase $\\psi_{1,i} = k^2 \\Delta V \\sum_{j} G_{ij} \\, q_j \\, e^{i k \\, d \\cdot (x_j - x_i)}$, then field $u^{\\mathrm{R}}_i = u^{\\mathrm{i}}_i \\, e^{\\psi_{1,i}}$.\n21. **Numerical Far-Field**: $u^\\infty(d,d) \\approx \\frac{k^2}{4\\pi} \\, \\Delta V \\sum_j e^{-i k \\, d \\cdot x_j} \\, q_j \\, u_j$ for reference, Born, and Rytov fields.\n22. **Relative Error Definition**: $e_{\\mathrm{approx}} = \\frac{|u^\\infty_{\\mathrm{approx}} - u^\\infty_{\\mathrm{ref}}|}{\\max(|u^\\infty_{\\mathrm{ref}}|, \\delta)}$.\n23. **Test Parameters**:\n    - $d = (1,0,0)$ and $\\hat{x} = d$.\n    - $R = 0.25$.\n    - $h = R/2 = 0.125$.\n    - Grid: $5 \\times 5 \\times 5$ grid of points within the ball.\n    - $\\Delta V = h^3$.\n    - $\\varepsilon = 0.05$.\n    - $\\delta = 10^{-12}$.\n24. **Test Cases**:\n    1. $(k, a, \\sigma) = (5, 0.02, 0.10)$.\n    2. $(k, a, \\sigma) = (10, 0.10, 0.10)$.\n    3. $(k, a, \\sigma) = (20, 0.50, 0.08)$.\n    4. $(k, a, \\sigma) = (2, 0.30, 0.10)$.\n25. **Output format**: List of six values per case: $[\\mu, \\mathcal{R}[u^{\\mathrm{B}}], \\mathcal{R}[u^{\\mathrm{R}}], e_{\\mathrm{B}}, e_{\\mathrm{R}}, b]$, where $b=1$ if $e_{\\mathrm{R}}  e_{\\mathrm{B}}$, else $b=0$. The final output should be a list of these lists.\n\n**Problem Validation - Step 2: Validate Using Extracted Givens**\n\n1.  **Scientifically Grounded (Critical)**: The problem is securely rooted in the mathematical physics of wave scattering, employing standard formalisms such as the Helmholtz equation, the Lippmann-Schwinger integral equation, and the Born and Rytov approximations. These are canonical topics in scattering theory. **Verdict: Pass.**\n2.  **Well-Posed**: The problem sets up a clear numerical experiment with all necessary parameters and procedures defined. The task is to compute specific quantities based on a fully described model. The existence and uniqueness of the solution to the specified linear system are expected for the given weak-to-moderate scattering regimes. **Verdict: Pass.**\n3.  **Objective (Critical)**: The problem is stated using precise, unambiguous mathematical and computational terminology. The quantities to be computed are defined by explicit formulas. **Verdict: Pass.**\n4.  **Flaw Checklist**:\n    - Scientific/Factual Unsoundness: None.\n    - Non-Formalizable/Irrelevant: None. The problem is a core exercise in computational inverse problems.\n    - Incomplete/Contradictory Setup: The problem's components are self-consistent and sufficient to proceed. The discretization scheme, while simplified (e.g., $G_{ii}=0$), is explicitly and unambiguously defined.\n    - Unrealistic/Infeasible: The physical and numerical parameters are within reasonable bounds for a computational study.\n    - Ill-Posed/Poorly Structured: None.\n    - Pseudo-Profound/Trivial: Not trivial. The problem requires a non-trivial implementation of a boundary integral equation solver and an understanding of the associated physics.\n    - Outside Scientific Verifiability: The results are computationally verifiable.\n\n**Problem Validation - Step 3: Verdict and Action**\n\nThe problem is valid. It is a well-defined numerical experiment in computational wave physics based on established principles. I will proceed with formulating and implementing the solution.\n\n### Justification of the Smallness Predictor\n\nThe Lippmann-Schwinger equation, $u(x) = u^{\\mathrm{i}}(x) + k^2 \\int_{\\Omega} G_k(x,y) q(y) u(y) \\mathrm{d}y$, where $\\Omega$ is the support of the contrast $q$, can be written in operator form as $u = u^{\\mathrm{i}} + \\mathcal{T}u$. Here, the operator $\\mathcal{T}$ is defined by $(\\mathcal{T}v)(x) = k^2 \\int_{\\Omega} G_k(x,y) q(y) v(y) \\mathrm{d}y$. This equation has the formal solution $u = (I - \\mathcal{T})^{-1} u^{\\mathrm{i}}$.\n\nWhen the operator norm $\\|\\mathcal{T}\\|$ is less than $1$, we can expand this solution as a Neumann series:\n$$\nu = \\sum_{n=0}^{\\infty} \\mathcal{T}^n u^{\\mathrm{i}} = u^{\\mathrm{i}} + \\mathcal{T} u^{\\mathrm{i}} + \\mathcal{T}^2 u^{\\mathrm{i}} + \\dots\n$$\nThe Born approximation, $u^{\\mathrm{B}} = u^{\\mathrm{i}} + \\mathcal{T} u^{\\mathrm{i}}$, retains only the first-order scattering term. The error in this approximation is therefore governed by the second- and higher-order terms, starting with $\\mathcal{T}^2 u^{\\mathrm{i}}$. The magnitude of these terms, and thus the accuracy of the approximation, depends on the norm of $\\mathcal{T}$.\n\nTo estimate $\\|\\mathcal{T}\\|$, we consider its action on a function $v$ in the $L^\\infty(\\Omega)$ norm:\n$$\n\\|\\mathcal{T}v\\|_{\\infty} = \\sup_{x \\in \\Omega} \\left| k^2 \\int_{\\Omega} G_k(x,y) q(y) v(y) \\mathrm{d}y \\right| \\le k^2 \\|q\\|_{\\infty} \\|v\\|_{\\infty} \\sup_{x \\in \\Omega} \\int_{\\Omega} |G_k(x,y)| \\mathrm{d}y\n$$\nwhere $|G_k(x,y)| = (4\\pi |x-y|)^{-1}$. The domain $\\Omega$ is a ball of radius $R$. The integral $\\int_{\\Omega} |x-y|^{-1} \\mathrm{d}y$ is maximized for $x$ at the center of the ball, yielding the value $2\\pi R^2$. Therefore,\n$$\n\\sup_{x \\in \\Omega} \\int_{\\Omega} |G_k(x,y)| \\mathrm{d}y = \\sup_{x \\in \\Omega} \\frac{1}{4\\pi} \\int_{\\Omega} \\frac{1}{|x-y|} \\mathrm{d}y \\le \\frac{1}{4\\pi} (2\\pi R^2) = \\frac{1}{2} R^2\n$$\nThis leads to the bound $\\|\\mathcal{T}\\|_{\\infty} \\le \\frac{1}{2} k^2 R^2 \\|q\\|_{\\infty}$. The dimensionless quantity $\\mu = k^2 R^2 \\|q\\|_{\\infty}$ thus serves as an order-of-magnitude estimate for $\\|\\mathcal{T}\\|$. If $\\mu \\ll 1$, the Neumann series converges rapidly, and the second-order error term, proportional to $\\|\\mathcal{T}\\|^2 \\approx \\mu^2$, is negligible. This justifies $\\mu$ as a predictor for the validity of first-order approximations.\n\n### Numerical Implementation Strategy\n\nThe numerical experiment is conducted by discretizing the continuous equations over a grid of points within the scattering-object's support.\n\n1.  **Discretization**: The support ball of radius $R=0.25$ is discretized using points from a cubic grid with spacing $h=0.125$, retaining only the $N$ points $\\{x_i\\}$ inside the ball. The integral operators are replaced by matrix-vector products with uniform volume element $\\Delta V = h^3$.\n\n2.  **Reference Solution**: The discretized Lippmann-Schwinger equation becomes a linear system for the vector of internal field values $\\mathbf{u} = [u(x_1), \\dots, u(x_N)]^T$:\n    $$\n    (I - k^2 \\Delta V G Q) \\mathbf{u} = \\mathbf{u}^{\\mathrm{i}}\n    $$\n    Here, $I$ is the identity matrix, $G$ is the $N \\times N$ matrix with entries $G_{ij} = G_k(x_i, x_j)$ (for $i \\neq j$, $0$ otherwise), $Q = \\mathrm{diag}(q(x_1), \\dots, q(x_N))$, and $\\mathbf{u}^{\\mathrm{i}}$ is the vector of incident field values. This system is solved for the reference field $\\mathbf{u}_{\\mathrm{ref}}$.\n\n3.  **Approximate Solutions**:\n    -   The Born internal field is computed directly: $\\mathbf{u}_{\\mathrm{B}} = \\mathbf{u}^{\\mathrm{i}} + k^2 \\Delta V G Q \\mathbf{u}^{\\mathrm{i}}$.\n    -   The Rytov phase $\\psi_1(x) \\approx u^{\\mathrm{s}}_{\\mathrm{B}}(x) / u^{\\mathrm{i}}(x)$, where $u^{\\mathrm{s}}_{\\mathrm{B}}$ is the scattered part of the Born field. Discretely, the phase vector is $\\boldsymbol{\\psi}_1 = (k^2 \\Delta V G Q \\mathbf{u}^{\\mathrm{i}}) \\oslash \\mathbf{u}^{\\mathrm{i}}$, where $\\oslash$ denotes element-wise division. The Rytov field is then $\\mathbf{u}_{\\mathrm{R}} = \\mathbf{u}^{\\mathrm{i}} \\odot \\exp(\\boldsymbol{\\psi}_1)$, with $\\odot$ as element-wise multiplication.\n\n4.  **Far-Field and Metrics**:\n    -   The far-field amplitude in the forward direction $\\hat{x}=d$ is computed by a discrete sum:\n        $$\n        u^\\infty(d,d) \\approx \\frac{k^2}{4\\pi} \\Delta V \\sum_{j=1}^{N} e^{-i k d \\cdot x_j} q_j u_j = \\frac{k^2}{4\\pi} \\Delta V (\\mathbf{u}^{\\mathrm{i}})^{\\dagger} Q \\mathbf{u}\n        $$\n        This formula is applied to $\\mathbf{u}_{\\mathrm{ref}}$, $\\mathbf{u}_{\\mathrm{B}}$, and $\\mathbf{u}_{\\mathrm{R}}$ to get $u^\\infty_{\\mathrm{ref}}$, $u^\\infty_{\\mathrm{B}}$, and $u^\\infty_{\\mathrm{R}}$.\n    -   The relative errors $e_{\\mathrm{B}}$ and $e_{\\mathrm{R}}$ are computed using the provided formula against $u^\\infty_{\\mathrm{ref}}$.\n    -   The Lippmann-Schwinger residual for an approximate field $\\mathbf{v}$ (either $\\mathbf{u}_{\\mathrm{B}}$ or $\\mathbf{u}_{\\mathrm{R}}$) is calculated as:\n        $$\n        \\mathcal{R}[\\mathbf{v}] = \\frac{\\|\\mathbf{v} - \\mathbf{u}^{\\mathrm{i}} - k^2 \\Delta V G Q \\mathbf{v}\\|_2}{\\|\\mathbf{v}\\|_2}\n        $$\n        The Euclidean norms $(\\|\\cdot\\|_2)$ are used, as the constant factor $\\sqrt{\\Delta V}$ from the discrete $L^2$ norm cancels in the ratio.\n\nFor each test case, these quantities are computed and compiled into the specified output format.", "answer": "```python\nimport numpy as np\nfrom scipy.spatial.distance import cdist\n\ndef solve():\n    \"\"\"\n    Main function to run the numerical experiment for all test cases.\n    \"\"\"\n    \n    # Define fixed parameters for the experiment\n    R = 0.25\n    h = R / 2.0\n    d_vec = np.array([1.0, 0.0, 0.0])\n    delta = 1e-12\n    dV = h**3\n\n    # Generate grid points within the sphere of radius R\n    coords = []\n    indices_1d = np.arange(-2, 3) \n    for i in indices_1d:\n        for j in indices_1d:\n            for l in indices_1d:\n                # The condition is ||x|| = R, which is || (ih,jh,kh) || = 2h\n                # So, h^2(i^2+j^2+k^2) = (2h)^2 - i^2+j^2+k^2 = 4\n                if i**2 + j**2 + l**2 = 4:\n                    coords.append([i * h, j * h, l * h])\n    x_pts = np.array(coords)\n    N = x_pts.shape[0]\n\n    # Pre-compute distance matrix and incident field structure\n    dist_matrix = cdist(x_pts, x_pts)\n\n    # Define the test cases from the problem statement\n    test_cases = [\n        (5.0, 0.02, 0.10),\n        (10.0, 0.10, 0.10),\n        (20.0, 0.50, 0.08),\n        (2.0, 0.30, 0.10),\n    ]\n\n    all_results = []\n    for k, a, sigma in test_cases:\n        # 1. Construct case-specific vectors and matrices\n        u_inc = np.exp(1j * k * (x_pts @ d_vec))\n        q_vec = a * np.exp(-np.sum(x_pts**2, axis=1) / (2 * sigma**2))\n        \n        # Green's function matrix\n        G = np.zeros((N, N), dtype=np.complex128)\n        mask = dist_matrix  0\n        G[mask] = np.exp(1j * k * dist_matrix[mask]) / (4 * np.pi * dist_matrix[mask])\n        \n        # 2. Reference solution (solving the full Lippmann-Schwinger system)\n        Q_diag = np.diag(q_vec)\n        system_matrix = np.eye(N) - (k**2 * dV) * (G @ Q_diag)\n        u_ref = np.linalg.solve(system_matrix, u_inc)\n        \n        # 3. Approximate solutions (Born and Rytov)\n        u_born_s = (k**2 * dV) * (G @ (q_vec * u_inc))\n        u_born = u_inc + u_born_s\n        \n        psi1 = u_born_s / u_inc\n        u_rytv = u_inc * np.exp(psi1)\n        \n        # 4. Far-field amplitudes in the forward direction\n        u_inc_conj = np.conj(u_inc)\n        common_factor = (k**2 / (4 * np.pi)) * dV\n        \n        u_inf_ref = common_factor * np.sum(u_inc_conj * q_vec * u_ref)\n        u_inf_born = common_factor * np.sum(u_inc_conj * q_vec * u_born)\n        u_inf_rytv = common_factor * np.sum(u_inc_conj * q_vec * u_rytv)\n        \n        # 5. Compute validation metrics\n        # Smallness predictor\n        mu = k**2 * R**2 * np.abs(a)\n        \n        # Lippmann-Schwinger residuals (using vector 2-norm)\n        res_num_born = u_born - u_inc - (k**2 * dV) * G @ (q_vec * u_born)\n        residual_born = np.linalg.norm(res_num_born) / np.linalg.norm(u_born)\n        \n        res_num_rytv = u_rytv - u_inc - (k**2 * dV) * G @ (q_vec * u_rytv)\n        residual_rytv = np.linalg.norm(res_num_rytv) / np.linalg.norm(u_rytv)\n        \n        # Far-field relative errors\n        denom = max(np.abs(u_inf_ref), delta)\n        e_born = np.abs(u_inf_born - u_inf_ref) / denom\n        e_rytv = np.abs(u_inf_rytv - u_inf_ref) / denom\n        \n        # Comparison flag\n        b = int(e_rytv  e_born)\n        \n        all_results.append([mu, residual_born, residual_rytv, e_born, e_rytv, b])\n\n    # Final print statement in the exact required format\n    case_strings = [f\"[{','.join(f'{v:.8f}' for v in r)}]\" for r in all_results]\n    print(f\"[{','.join(case_strings)}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3392387"}, {"introduction": "Real-world applications often involve strong scattering and require moving beyond linear models to full-waveform inversion (FWI). This advanced practice [@problem_id:3392423] simulates a modern research task: designing and testing a complete inversion pipeline for a non-linear problem. You will tackle challenges like ill-posedness by implementing Total Variation (TV) regularization and address computational complexity using the adjoint-state method to efficiently compute gradients, culminating in a hybrid strategy that leverages a fast qualitative method to improve the convergence of the quantitative inversion.", "problem": "Consider the inverse scattering problem for a scalar frequency-domain wave in one spatial dimension. Let the spatial domain be the closed interval $\\left[0,1\\right]$, and let $N$ be the number of grid nodes with uniform spacing $h = \\dfrac{1}{N-1}$. Impose homogeneous Dirichlet boundary conditions at $x=0$ and $x=1$. Denote by $M = N-2$ the number of interior nodes, which are the degrees of freedom of the state variable.\n\nThe forward model is given by the linear elliptic partial differential equation\n$$\n- \\dfrac{d^2 u(x)}{dx^2} + k^2 \\left( 1 + q(x) \\right) u(x) = f(x), \\quad x \\in (0,1),\n$$\nwith $u(0)=0$ and $u(1)=0$, where $k  0$ is the wavenumber, $q(x)$ is the unknown scattering potential (dimensionless contrast), $u(x)$ is the total field, and $f(x)$ represents a source. Use standard second-order central finite differences on the interior nodes to discretize $- \\dfrac{d^2}{dx^2}$ into the symmetric positive-definite tridiagonal matrix $\\mathbf{L} \\in \\mathbb{R}^{M \\times M}$ with diagonal entries $\\dfrac{2}{h^2}$ and off-diagonals $\\dfrac{-1}{h^2}$. Let $\\mathbf{q} \\in \\mathbb{R}^{M}$ be the discretized contrast, and let $\\mathbf{A}(\\mathbf{q}) = \\mathbf{L} + k^2 \\operatorname{diag}(\\mathbf{1} + \\mathbf{q})$ be the discrete forward operator. For a given source vector $\\mathbf{f} \\in \\mathbb{R}^{M}$, the discrete field satisfies\n$$\n\\mathbf{A}(\\mathbf{q}) \\mathbf{u} = \\mathbf{f}.\n$$\nAssume there are $S$ source configurations $\\left\\{ \\mathbf{f}_j \\right\\}_{j=1}^S$, resulting in solutions $\\left\\{ \\mathbf{u}_j \\right\\}_{j=1}^S$. Let $\\mathbf{P} \\in \\mathbb{R}^{R \\times M}$ be the restriction (sampling) operator that extracts field values at $R$ receiver nodes. For a fixed but unknown true contrast $\\mathbf{q}^{\\mathrm{true}}$, the measured data are $\\left\\{ \\mathbf{y}_j \\right\\}_{j=1}^S$ with\n$$\n\\mathbf{y}_j = \\mathbf{P} \\mathbf{u}_j^{\\mathrm{true}} + \\boldsymbol{\\eta}_j, \\quad \\text{where} \\quad \\mathbf{A}(\\mathbf{q}^{\\mathrm{true}}) \\mathbf{u}_j^{\\mathrm{true}} = \\mathbf{f}_j,\n$$\nand $\\boldsymbol{\\eta}_j$ is additive measurement noise.\n\nYour task is to design, implement, and test a hybrid qualitative-quantitative inversion pipeline to reconstruct $\\mathbf{q}$ from $\\left\\{ \\mathbf{y}_j \\right\\}_{j=1}^S$:\n\n- Step $1$ (qualitative support detection): Use a sampling indicator derived from background fields to estimate the support of $\\mathbf{q}^{\\mathrm{true}}$. Let $\\mathbf{u}_{0,j}$ solve $\\mathbf{A}(\\mathbf{0}) \\mathbf{u}_{0,j} = \\mathbf{f}_j$. Define the residuals $\\mathbf{r}_j = \\mathbf{y}_j - \\mathbf{P}\\mathbf{u}_{0,j}$. Let $\\mathbf{v}_j$ solve the adjoint background problem $\\mathbf{A}(\\mathbf{0}) \\mathbf{v}_j = \\mathbf{P}^{\\top} \\mathbf{r}_j$. Define the pointwise indicator \n$$\n\\mathbf{s} = \\sum_{j=1}^{S} \\left| \\mathbf{u}_{0,j} \\odot \\mathbf{v}_j \\right| \\in \\mathbb{R}^M,\n$$\nwhere $\\odot$ denotes the elementwise product and absolute value is applied elementwise. Normalize $\\mathbf{s}$ by its maximum value to lie in $\\left[0,1\\right]$. Select a support mask $\\mathbf{m} \\in \\left\\{0,1\\right\\}^M$ by thresholding at a given level $\\tau \\in (0,1)$, i.e., set $\\mathbf{m}_i = 1$ if $\\mathbf{s}_i \\ge \\tau \\max(\\mathbf{s})$ and $\\mathbf{m}_i = 0$ otherwise.\n\n- Step $2$ (quantitative inversion with smoothed Total Variation (TV) regularization): Solve the unconstrained optimization problem\n$$\n\\min_{\\mathbf{q} \\in \\mathbb{R}^M, \\, \\mathbf{q} \\ge \\mathbf{0}} \\; \\Phi(\\mathbf{q}) \\equiv \\dfrac{1}{2} \\sum_{j=1}^S \\left\\| \\mathbf{P}\\mathbf{u}_j(\\mathbf{q}) - \\mathbf{y}_j \\right\\|_2^2 \\;+\\; \\alpha \\sum_{i=1}^{M-1} \\sqrt{\\left( \\mathbf{q}_{i+1} - \\mathbf{q}_i \\right)^2 + \\epsilon},\n$$\nwhere $\\alpha  0$ is the regularization weight and $\\epsilon  0$ is a smoothing parameter. For each source $j$, the state $\\mathbf{u}_j(\\mathbf{q})$ satisfies $\\mathbf{A}(\\mathbf{q}) \\mathbf{u}_j(\\mathbf{q}) = \\mathbf{f}_j$. Use gradient-based optimization with an adjoint-state gradient for the data misfit and the exact gradient of the smoothed TV term.\n\nDefine two initialization strategies:\n\n- Baseline: random initialization $\\mathbf{q}^{(0)}_{\\mathrm{rand}}$ sampled componentwise from a uniform distribution on $\\left[0, a_{\\max}\\right]$ for a specified $a_{\\max}  0$.\n\n- Support-seeded: A qualitative initialization $\\mathbf{q}^{(0)}_{\\mathrm{sup}} = a^\\star \\mathbf{m}$, where $a^\\star \\in \\left[0, a_{\\max}\\right]$ is chosen to minimize the data misfit along the ray $\\left\\{ a \\mathbf{m} : a \\in \\left[0, a_{\\max}\\right] \\right\\}$ by a simple discrete line search evaluated at finitely many points, followed by a small random perturbation to avoid determinism.\n\nQuantify the improvement in the empirical basin of attraction as follows. For each test case, run $T$ independent trials. In each trial, run the quantitative inversion for a fixed number of iterations starting from $\\mathbf{q}^{(0)}_{\\mathrm{rand}}$ and classify the result as successful if the relative reconstruction error \n$$\n\\mathrm{rel\\_err} = \\dfrac{\\left\\| \\widehat{\\mathbf{q}} - \\mathbf{q}^{\\mathrm{true}} \\right\\|_2}{\\left\\| \\mathbf{q}^{\\mathrm{true}} \\right\\|_2}\n$$\nis less than or equal to a prescribed tolerance $\\rho$. Repeat the $T$ trials starting from perturbed support-seeded initializations and classify success with the same criterion. The empirical basin-of-attraction gain is defined as\n$$\n\\mathrm{gain} = \\left(\\dfrac{\\text{number of successful support-seeded trials}}{T}\\right) - \\left(\\dfrac{\\text{number of successful baseline trials}}{T}\\right).\n$$\n\nYour program must implement the above hybrid pipeline and produce the gains for the following test suite. All numerical values are dimensionless.\n\nTest Suite Specifications:\n\n- Case $\\mathbf{1}$ (happy path):\n  - $N = 80$, $M = 78$, $k = 25$.\n  - Sources: $S = 3$ at interior indices $\\left\\{2, 6, 10\\right\\}$ (counting from $0$ to $M-1$).\n  - Receivers: $R = 3$ at interior indices $\\left\\{M-6, M-4, M-2\\right\\}$.\n  - True contrast: $\\mathbf{q}^{\\mathrm{true}}$ equals $a_{\\mathrm{true}} = 1.0$ on two intervals $[i_1, i_2]$ and $[i_3, i_4]$, where $i_1 = \\lfloor 0.30 M \\rfloor$, $i_2 = \\lfloor 0.40 M \\rfloor$, $i_3 = \\lfloor 0.65 M \\rfloor$, $i_4 = \\lfloor 0.75 M \\rfloor$, and zero elsewhere.\n  - Noise: additive Gaussian with standard deviation equal to $\\sigma \\left\\| \\mathbf{y} \\right\\|_2$ for each source, with $\\sigma = 0.01$.\n  - Qualitative threshold $\\tau = 0.60$.\n  - TV parameters: $\\alpha = 0.02$, $\\epsilon = 10^{-6}$.\n  - Optimization: step size $\\delta = 10^{-3}$, iterations $K = 60$, projection $\\mathbf{q} \\ge \\mathbf{0}$ after each step.\n  - Initialization bounds: $a_{\\max} = 1.5$, line search samples $L = 8$.\n  - Trials: $T = 6$, success tolerance $\\rho = 0.25$.\n\n- Case $\\mathbf{2}$ (limited illumination, higher noise):\n  - $N = 80$, $M = 78$, $k = 25$.\n  - Sources: $S = 1$ at interior index $\\left\\{2\\right\\}$.\n  - Receivers: $R = 3$ at interior indices $\\left\\{M-6, M-4, M-2\\right\\}$.\n  - True contrast: same two-interval structure as Case $\\mathbf{1}$ with $a_{\\mathrm{true}} = 1.0$.\n  - Noise: $\\sigma = 0.02$.\n  - Qualitative threshold $\\tau = 0.60$.\n  - TV parameters: $\\alpha = 0.03$, $\\epsilon = 10^{-6}$.\n  - Optimization: $\\delta = 10^{-3}$, $K = 60$.\n  - Initialization bounds: $a_{\\max} = 1.5$, $L = 8$.\n  - Trials: $T = 6$, success tolerance $\\rho = 0.30$.\n\n- Case $\\mathbf{3}$ (low contrast):\n  - $N = 80$, $M = 78$, $k = 25$.\n  - Sources: $S = 3$ at interior indices $\\left\\{2, 6, 10\\right\\}$.\n  - Receivers: $R = 3$ at interior indices $\\left\\{M-6, M-4, M-2\\right\\}$.\n  - True contrast: single interval $[i_1, i_2]$ with $i_1 = \\lfloor 0.40 M \\rfloor$, $i_2 = \\lfloor 0.55 M \\rfloor$, amplitude $a_{\\mathrm{true}} = 0.40$, zero elsewhere.\n  - Noise: $\\sigma = 0.01$.\n  - Qualitative threshold $\\tau = 0.50$.\n  - TV parameters: $\\alpha = 0.02$, $\\epsilon = 10^{-6}$.\n  - Optimization: $\\delta = 10^{-3}$, $K = 60$.\n  - Initialization bounds: $a_{\\max} = 0.8$, $L = 8$.\n  - Trials: $T = 6$, success tolerance $\\rho = 0.35$.\n\n- Case $\\mathbf{4}$ (higher wavenumber):\n  - $N = 80$, $M = 78$, $k = 35$.\n  - Sources: $S = 3$ at interior indices $\\left\\{2, 6, 10\\right\\}$.\n  - Receivers: $R = 3$ at interior indices $\\left\\{M-6, M-4, M-2\\right\\}$.\n  - True contrast: same as Case $\\mathbf{1}$ with $a_{\\mathrm{true}} = 1.0$.\n  - Noise: $\\sigma = 0.015$.\n  - Qualitative threshold $\\tau = 0.60$.\n  - TV parameters: $\\alpha = 0.03$, $\\epsilon = 10^{-6}$.\n  - Optimization: $\\delta = 10^{-3}$, $K = 60$.\n  - Initialization bounds: $a_{\\max} = 1.5$, $L = 8$.\n  - Trials: $T = 6$, success tolerance $\\rho = 0.30$.\n\nImplementation requirements:\n\n- Use the discrete adjoint-state method to compute the gradient of the data misfit. If $\\mathbf{r}_j = \\mathbf{P}\\mathbf{u}_j(\\mathbf{q}) - \\mathbf{y}_j$ and the adjoint $\\mathbf{p}_j$ solves $\\mathbf{A}(\\mathbf{q}) \\mathbf{p}_j = \\mathbf{P}^{\\top} \\mathbf{r}_j$, the data-misfit gradient contribution is \n$$\n\\nabla_{\\mathbf{q}} \\left( \\dfrac{1}{2} \\sum_{j=1}^S \\left\\| \\mathbf{P}\\mathbf{u}_j(\\mathbf{q}) - \\mathbf{y}_j \\right\\|_2^2 \\right) \\;=\\; - k^2 \\sum_{j=1}^S \\left( \\mathbf{u}_j(\\mathbf{q}) \\odot \\mathbf{p}_j \\right).\n$$\n- The gradient of the smoothed total variation is\n$$\n\\nabla_{\\mathbf{q}} \\left( \\sum_{i=1}^{M-1} \\sqrt{\\left( \\mathbf{q}_{i+1} - \\mathbf{q}_i \\right)^2 + \\epsilon} \\right) \\;=\\; \\mathbf{D}^{\\top} \\left( \\dfrac{\\mathbf{D}\\mathbf{q}}{\\sqrt{(\\mathbf{D}\\mathbf{q})^2 + \\epsilon}} \\right),\n$$\nwhere $\\mathbf{D} \\in \\mathbb{R}^{(M-1)\\times M}$ is the forward difference operator and division and square root are applied elementwise. Implement the corresponding discrete vector formula without forming $\\mathbf{D}$ explicitly.\n\n- Use projected gradient descent with step size $\\delta$, projection onto the nonnegative orthant componentwise after each step, and $K$ iterations.\n\n- The qualitative initialization amplitude $a^\\star$ must be selected by a discrete line search over $L$ uniformly spaced values in $\\left[0, a_{\\max}\\right]$, minimizing the data misfit along $a \\mathbf{m}$.\n\nFinal output format:\n\n- Your program should produce a single line of output containing the gains for Cases $\\mathbf{1}$ to $\\mathbf{4}$ in order, as a comma-separated list enclosed in square brackets (e.g., $\\left[ g_1, g_2, g_3, g_4 \\right]$). Each $g_i$ must be a decimal number in standard floating-point notation.\n\nNo external input is provided; all parameters must be set as specified above and the program must be self-contained and reproducible.", "solution": "We derive the algorithm from fundamental definitions of the discrete forward model, the adjoint-state method for the gradient of a PDE-constrained problem, and the smoothed total variation regularization.\n\nDiscretization and forward operator: The one-dimensional negative Laplacian under homogeneous Dirichlet boundary conditions on the uniform interior grid is discretized by the tridiagonal matrix $\\mathbf{L} \\in \\mathbb{R}^{M\\times M}$ with entries $\\dfrac{2}{h^2}$ on the diagonal and $\\dfrac{-1}{h^2}$ on the first sub- and super-diagonals. The Helmholtz-type discrete operator including a spatially varying contrast $\\mathbf{q}$ is \n$$\n\\mathbf{A}(\\mathbf{q}) = \\mathbf{L} + k^2 \\operatorname{diag}(\\mathbf{1} + \\mathbf{q}).\n$$\nGiven a set of sources $\\left\\{\\mathbf{f}_j\\right\\}_{j=1}^S$, the state variables $\\left\\{\\mathbf{u}_j\\right\\}_{j=1}^S$ are obtained by solving $\\mathbf{A}(\\mathbf{q}) \\mathbf{u}_j = \\mathbf{f}_j$. The data misfit for measurements sampled by the restriction matrix $\\mathbf{P}$ is\n$$\n\\Phi_{\\mathrm{mis}}(\\mathbf{q}) = \\dfrac{1}{2} \\sum_{j=1}^S \\left\\| \\mathbf{P} \\mathbf{u}_j(\\mathbf{q}) - \\mathbf{y}_j \\right\\|_2^2.\n$$\n\nAdjoint-state gradient derivation: We derive the gradient of $\\Phi_{\\mathrm{mis}}(\\mathbf{q})$ with respect to $\\mathbf{q}$ by the Lagrangian method. Introduce Lagrange multipliers $\\left\\{\\boldsymbol{\\lambda}_j\\right\\}_{j=1}^S$ and define the Lagrangian\n$$\n\\mathcal{L}(\\mathbf{q}, \\{ \\mathbf{u}_j \\}, \\{ \\boldsymbol{\\lambda}_j \\}) = \\dfrac{1}{2}\\sum_{j=1}^S \\left\\| \\mathbf{P}\\mathbf{u}_j - \\mathbf{y}_j \\right\\|_2^2 + \\sum_{j=1}^S \\boldsymbol{\\lambda}_j^{\\top} \\left( \\mathbf{A}(\\mathbf{q})\\mathbf{u}_j - \\mathbf{f}_j \\right).\n$$\nThe stationarity with respect to $\\mathbf{u}_j$ yields the adjoint equations:\n$$\n\\dfrac{\\partial \\mathcal{L}}{\\partial \\mathbf{u}_j} = \\mathbf{P}^{\\top} \\left( \\mathbf{P}\\mathbf{u}_j - \\mathbf{y}_j \\right) + \\mathbf{A}(\\mathbf{q})^{\\top} \\boldsymbol{\\lambda}_j = \\mathbf{0}.\n$$\nBecause $\\mathbf{A}(\\mathbf{q})$ is symmetric, this becomes $\\mathbf{A}(\\mathbf{q}) \\boldsymbol{\\lambda}_j = - \\mathbf{P}^{\\top} \\left( \\mathbf{P}\\mathbf{u}_j - \\mathbf{y}_j \\right)$. Define the adjoint variables $\\mathbf{p}_j = -\\boldsymbol{\\lambda}_j$, which satisfy\n$$\n\\mathbf{A}(\\mathbf{q}) \\mathbf{p}_j = \\mathbf{P}^{\\top} \\left( \\mathbf{P}\\mathbf{u}_j - \\mathbf{y}_j \\right) \\equiv \\mathbf{P}^{\\top} \\mathbf{r}_j,\n$$\nwhere $\\mathbf{r}_j$ are residuals. The derivative of the Lagrangian with respect to $\\mathbf{q}$ uses the fact that $\\dfrac{\\partial \\mathbf{A}}{\\partial \\mathbf{q}_i} = k^2 \\mathbf{E}_i$, where $\\mathbf{E}_i$ is the diagonal matrix with a $1$ at $(i,i)$ and zeros elsewhere. Therefore,\n$$\n\\dfrac{\\partial \\mathcal{L}}{\\partial \\mathbf{q}_i} = \\sum_{j=1}^S \\boldsymbol{\\lambda}_j^{\\top} k^2 \\mathbf{E}_i \\mathbf{u}_j = k^2 \\sum_{j=1}^S \\boldsymbol{\\lambda}_j(i) \\, \\mathbf{u}_j(i) = - k^2 \\sum_{j=1}^S \\mathbf{p}_j(i) \\, \\mathbf{u}_j(i).\n$$\nCollecting all components, the gradient of the data misfit is\n$$\n\\nabla \\Phi_{\\mathrm{mis}}(\\mathbf{q}) = - k^2 \\sum_{j=1}^S \\left( \\mathbf{u}_j(\\mathbf{q}) \\odot \\mathbf{p}_j(\\mathbf{q}) \\right).\n$$\n\nSmoothed total variation gradient: The smoothed total variation is\n$$\n\\mathrm{TV}_{\\epsilon}(\\mathbf{q}) = \\sum_{i=1}^{M-1} \\sqrt{\\left( \\mathbf{q}_{i+1} - \\mathbf{q}_i \\right)^2 + \\epsilon}.\n$$\nLet $\\mathbf{w} \\in \\mathbb{R}^{M-1}$ be the normalized forward differences, with components\n$$\n\\mathbf{w}_i = \\dfrac{\\mathbf{q}_{i+1} - \\mathbf{q}_i}{\\sqrt{\\left( \\mathbf{q}_{i+1} - \\mathbf{q}_i \\right)^2 + \\epsilon}}, \\quad i = 1, \\dots, M-1.\n$$\nThe gradient of $\\mathrm{TV}_{\\epsilon}(\\mathbf{q})$ is then the negative discrete divergence of $\\mathbf{w}$, yielding in vector form\n$$\n\\nabla \\mathrm{TV}_{\\epsilon}(\\mathbf{q}) = \\mathbf{D}^{\\top} \\mathbf{w},\n$$\nwhere $\\mathbf{D}$ is the forward difference operator. In coordinates, this becomes\n$$\n\\left[ \\nabla \\mathrm{TV}_{\\epsilon}(\\mathbf{q}) \\right]_1 = - \\mathbf{w}_1, \\quad \\left[ \\nabla \\mathrm{TV}_{\\epsilon}(\\mathbf{q}) \\right]_i = \\mathbf{w}_{i-1} - \\mathbf{w}_i \\; \\text{ for } \\; 2 \\le i \\le M-1, \\quad \\left[ \\nabla \\mathrm{TV}_{\\epsilon}(\\mathbf{q}) \\right]_M = \\mathbf{w}_{M-1}.\n$$\n\nProjected gradient descent: The total objective is $\\Phi(\\mathbf{q}) = \\Phi_{\\mathrm{mis}}(\\mathbf{q}) + \\alpha \\mathrm{TV}_{\\epsilon}(\\mathbf{q})$. Given a step size $\\delta  0$, perform iterations\n$$\n\\mathbf{q}^{(k+1)} = \\Pi_{\\ge 0} \\left( \\mathbf{q}^{(k)} - \\delta \\left[ \\nabla \\Phi_{\\mathrm{mis}}(\\mathbf{q}^{(k)}) + \\alpha \\nabla \\mathrm{TV}_{\\epsilon}(\\mathbf{q}^{(k)}) \\right] \\right), \\quad k = 0, 1, \\dots, K-1,\n$$\nwhere $\\Pi_{\\ge 0}$ denotes componentwise projection onto the nonnegative orthant. The step size $\\delta$ is fixed as prescribed; the symmetry and positive-definiteness of $\\mathbf{A}(\\mathbf{q})$ ensure well-posed forward and adjoint solves.\n\nQualitative sampling indicator: For a computationally inexpensive support detection, use background solutions and an adjoint driven by residuals. For each source $j$, compute the background field $\\mathbf{u}_{0,j}$ by solving $\\mathbf{A}(\\mathbf{0}) \\mathbf{u}_{0,j} = \\mathbf{f}_j$. Let $\\mathbf{r}_j = \\mathbf{y}_j - \\mathbf{P}\\mathbf{u}_{0,j}$. Solve $\\mathbf{A}(\\mathbf{0}) \\mathbf{v}_j = \\mathbf{P}^{\\top} \\mathbf{r}_j$. Then form the indicator\n$$\n\\mathbf{s} = \\sum_{j=1}^S \\left| \\mathbf{u}_{0,j} \\odot \\mathbf{v}_j \\right|.\n$$\nThis indicator is motivated by reciprocity and topological sensitivity for perturbations: the product $\\mathbf{u}_{0,j}(x) \\mathbf{v}_j(x)$ relates to the sensitivity of the misfit with respect to a localized contrast change at the point $x$. Thresholding the normalized $\\mathbf{s}$ at $\\tau$ yields the support mask $\\mathbf{m}$.\n\nInitialization schemes:\n\n- Baseline random: Draw $\\mathbf{q}^{(0)}_{\\mathrm{rand}}$ componentwise from $\\mathcal{U}(0, a_{\\max})$. This explores the space of initial guesses without prior support information.\n\n- Support-seeded: Given $\\mathbf{m}$, consider the one-parameter family $\\left\\{ a \\mathbf{m} : a \\in [0, a_{\\max}] \\right\\}$. For $L$ uniform candidates $a_{\\ell} \\in [0, a_{\\max}]$, compute the data misfit $\\Phi_{\\mathrm{mis}}(a_{\\ell} \\mathbf{m})$ and select $a^\\star = \\arg\\min_{\\ell} \\Phi_{\\mathrm{mis}}(a_{\\ell} \\mathbf{m})$. Set $\\mathbf{q}^{(0)}_{\\mathrm{sup}} = a^\\star \\mathbf{m} + \\boldsymbol{\\xi}$ where $\\boldsymbol{\\xi}$ is a small nonnegative random perturbation to avoid determinism, then project to nonnegativity.\n\nEmpirical basin-of-attraction gain: For each case, generate noisy data $\\left\\{ \\mathbf{y}_j \\right\\}$ once using $\\mathbf{q}^{\\mathrm{true}}$ and fixed noise statistics. Then run $T$ independent trials of the quantitative inversion from random initializations and from perturbed support-seeded initializations (with the same data). Count the number of trials with relative error not exceeding the tolerance $\\rho$. The gain is the difference in success rates. This quantifies how support detection increases the probability of converging to an acceptable reconstruction within the given computational budget.\n\nAlgorithmic structure for each case:\n\n- Build $\\mathbf{L}$, select source and receiver indices, form $\\mathbf{P}$.\n\n- Define $\\mathbf{q}^{\\mathrm{true}}$ according to the case specification.\n\n- Generate noisy data: For each $j$, solve $\\mathbf{A}(\\mathbf{q}^{\\mathrm{true}})\\mathbf{u}_j^{\\mathrm{true}} = \\mathbf{f}_j$, set $\\mathbf{y}_j = \\mathbf{P}\\mathbf{u}_j^{\\mathrm{true}} + \\boldsymbol{\\eta}_j$, where each $\\boldsymbol{\\eta}_j$ is Gaussian with standard deviation $\\sigma \\left\\| \\mathbf{y}_j \\right\\|_2$.\n\n- Compute background fields $\\mathbf{u}_{0,j}$ and residuals $\\mathbf{r}_j$; solve adjoints to form $\\mathbf{s}$; threshold at $\\tau$ to get $\\mathbf{m}$, with a fallback to ensure nonempty support if necessary.\n\n- Determine $a^\\star$ by a discrete line search on $L$ candidates; define $\\mathbf{q}^{(0)}_{\\mathrm{sup}}$.\n\n- For each trial in baseline and support-seeded groups, run $K$ iterations of projected gradient descent with step $\\delta$ and TV parameters $\\alpha$ and $\\epsilon$; project to $\\mathbf{q} \\ge \\mathbf{0}$ after each step.\n\n- Compute the relative error of the final estimate and count success if it does not exceed $\\rho$.\n\n- Compute the gain as the difference in success rates.\n\nThe output is a single line with the gains for Cases $\\mathbf{1}$ to $\\mathbf{4}$, formatted as a comma-separated list enclosed in brackets. This pipeline adheres to the underlying physics via the discrete forward model, employs a principled adjoint-state gradient, incorporates edge-preserving smoothed total variation regularization, and uses a qualitative indicator grounded in reciprocity to enhance initialization and empirically expand the basin of attraction.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse import diags, csr_matrix\nfrom scipy.sparse.linalg import spsolve\n\ndef build_laplacian(M, h):\n    # Discrete -d2/dx2 with Dirichlet BCs on interior (size M)\n    main = (2.0 / (h * h)) * np.ones(M)\n    off = (-1.0 / (h * h)) * np.ones(M - 1)\n    L = diags([off, main, off], offsets=[-1, 0, 1], format='csr')\n    return L\n\ndef build_A(L, k, q):\n    # A(q) = L + k^2 * diag(1 + q)\n    M = L.shape[0]\n    diag_add = (k * k) * (1.0 + q)\n    A = L + diags(diag_add, offsets=0, format='csr')\n    return A\n\ndef solve_forward(A, f):\n    return spsolve(A, f)\n\ndef make_P(M, recv_idx):\n    # P extracts entries at recv_idx\n    R = len(recv_idx)\n    data = np.ones(R)\n    rows = np.arange(R)\n    cols = np.array(recv_idx, dtype=int)\n    P = csr_matrix((data, (rows, cols)), shape=(R, M))\n    return P\n\ndef tv_grad_1d(q, eps):\n    # Gradient of smoothed 1D TV: D^T ( D q / sqrt((D q)^2 + eps) )\n    dq = q[1:] - q[:-1]  # size M-1\n    denom = np.sqrt(dq * dq + eps)\n    w = dq / denom\n    M = q.size\n    g = np.zeros_like(q)\n    # [0] = -w[0]\n    g[0] = -w[0]\n    # middle entries\n    g[1:-1] = w[:-1] - w[1:]\n    # last\n    g[-1] = w[-1]\n    return g\n\ndef energy(q, L, k, sources, P, y_list, alpha, eps):\n    # Compute objective: 0.5 sum ||P u(q) - y||^2 + alpha TV_eps(q)\n    A = build_A(L, k, q)\n    mis = 0.0\n    for f, y in zip(sources, y_list):\n        u = solve_forward(A, f)\n        r = P.dot(u) - y\n        mis += 0.5 * float(r.T @ r)\n    dq = q[1:] - q[:-1]\n    tv = np.sum(np.sqrt(dq * dq + eps))\n    return mis + alpha * tv\n\ndef grad_data(q, L, k, sources, P, y_list):\n    # Adjoint-state gradient of data misfit\n    A = build_A(L, k, q)\n    M = L.shape[0]\n    grad = np.zeros(M)\n    for f, y in zip(sources, y_list):\n        u = solve_forward(A, f)\n        r = P.dot(u) - y\n        rhs_adj = P.T.dot(r)\n        p = solve_forward(A, rhs_adj)\n        grad += -(k * k) * (u * p)\n    return grad\n\ndef projected_gradient_descent(q0, L, k, sources, P, y_list, alpha, eps, step, iters):\n    q = q0.copy()\n    for _ in range(iters):\n        g_data = grad_data(q, L, k, sources, P, y_list)\n        g_tv = tv_grad_1d(q, eps)\n        q = q - step * (g_data + alpha * g_tv)\n        q[q  0.0] = 0.0\n    return q\n\ndef qualitative_support(L, k, sources, P, y_list, tau):\n    # Background fields and adjoints for indicator\n    M = L.shape[0]\n    A0 = build_A(L, k, np.zeros(M))\n    s = np.zeros(M)\n    for f, y in zip(sources, y_list):\n        u0 = solve_forward(A0, f)\n        r = P.dot(u0) - y\n        rhs_adj = P.T.dot(r)\n        v = solve_forward(A0, rhs_adj)\n        s += np.abs(u0 * v)\n    maxs = np.max(s) if np.max(s)  0 else 1.0\n    s_norm = s / maxs\n    mask = s_norm = tau\n    # Fallback: ensure nonempty support\n    if not np.any(mask):\n        # pick top 10% largest entries\n        m = max(1, M // 10)\n        idx = np.argsort(s_norm)[-m:]\n        mask = np.zeros(M, dtype=bool)\n        mask[idx] = True\n    return mask.astype(float), s_norm\n\ndef line_search_amplitude(mask, L, k, sources, P, y_list, amax, Lsamp):\n    # Discrete line search over a in [0, amax] to minimize data misfit\n    M = L.shape[0]\n    best_a = 0.0\n    best_val = np.inf\n    a_vals = np.linspace(0.0, amax, Lsamp)\n    for a in a_vals:\n        q = a * mask\n        A = build_A(L, k, q)\n        mis = 0.0\n        for f, y in zip(sources, y_list):\n            u = solve_forward(A, f)\n            r = P.dot(u) - y\n            mis += 0.5 * float(r.T @ r)\n        if mis  best_val:\n            best_val = mis\n            best_a = a\n    return best_a\n\ndef generate_true_q(M, case_id):\n    q_true = np.zeros(M)\n    if case_id in [1, 2, 4]:\n        i1 = int(np.floor(0.30 * M))\n        i2 = int(np.floor(0.40 * M))\n        i3 = int(np.floor(0.65 * M))\n        i4 = int(np.floor(0.75 * M))\n        q_true[i1:i2] = 1.0\n        q_true[i3:i4] = 1.0\n    elif case_id == 3:\n        i1 = int(np.floor(0.40 * M))\n        i2 = int(np.floor(0.55 * M))\n        q_true[i1:i2] = 0.40\n    return q_true\n\ndef setup_case(case):\n    N = case['N']\n    M = N - 2\n    h = 1.0 / (N - 1)\n    L = build_laplacian(M, h)\n    k = case['k']\n    # Sources: delta at given interior indices\n    src_idx = case['src_idx']\n    sources = []\n    for si in src_idx:\n        f = np.zeros(M)\n        f[si] = 1.0\n        sources.append(f)\n    # Receivers\n    rec_idx = case['rec_idx']\n    P = make_P(M, rec_idx)\n    # True q\n    q_true = generate_true_q(M, case['case_id'])\n    # Generate observations\n    y_list = []\n    A_true = build_A(L, k, q_true)\n    for f in sources:\n        u_true = solve_forward(A_true, f)\n        y = P.dot(u_true)\n        # Add noise with specified fraction sigma * ||y||2\n        sigma = case['sigma']\n        rng = np.random.default_rng(case['noise_seed'])\n        noise = rng.normal(loc=0.0, scale=sigma * np.linalg.norm(y), size=y.shape)\n        y_noisy = y + noise\n        y_list.append(y_noisy)\n        case['noise_seed'] += 1  # different noise per source\n    return L, k, sources, P, y_list, q_true\n\ndef run_trials(case):\n    L, k, sources, P, y_list, q_true = setup_case(case)\n    M = L.shape[0]\n    # Qualitative support\n    mask, s_norm = qualitative_support(L, k, sources, P, y_list, case['tau'])\n    # Amplitude line search\n    a_star = line_search_amplitude(mask, L, k, sources, P, y_list, case['amax'], case['Lsamp'])\n    # Define initializers\n    T = case['T']\n    step = case['step']\n    iters = case['iters']\n    alpha = case['alpha']\n    eps = case['eps']\n    tol = case['tol']\n    # Baseline trials\n    rng_base = np.random.default_rng(case['base_seed'])\n    success_base = 0\n    for t in range(T):\n        q0 = rng_base.uniform(low=0.0, high=case['amax'], size=M)\n        qhat = projected_gradient_descent(q0, L, k, sources, P, y_list, alpha, eps, step, iters)\n        rel_err = np.linalg.norm(qhat - q_true) / max(1e-12, np.linalg.norm(q_true))\n        if rel_err = tol:\n            success_base += 1\n    # Support-seeded trials with small random perturbations\n    rng_sup = np.random.default_rng(case['sup_seed'])\n    success_sup = 0\n    for t in range(T):\n        perturb = np.abs(rng_sup.normal(loc=0.0, scale=0.05 * max(1e-8, a_star), size=M))\n        q0s = a_star * mask + perturb\n        qhat = projected_gradient_descent(q0s, L, k, sources, P, y_list, alpha, eps, step, iters)\n        rel_err = np.linalg.norm(qhat - q_true) / max(1e-12, np.linalg.norm(q_true))\n        if rel_err = tol:\n            success_sup += 1\n    gain = (success_sup / T) - (success_base / T)\n    return gain\n\ndef solve():\n    # Define the test cases as per the problem statement.\n    # Indices relative to interior 0..M-1\n    N = 80\n    M = N - 2\n    rec_idx = [M - 6, M - 4, M - 2]\n    cases = [\n        {\n            'case_id': 1,\n            'N': 80, 'k': 25,\n            'src_idx': [2, 6, 10],\n            'rec_idx': rec_idx,\n            'sigma': 0.01,\n            'tau': 0.60,\n            'alpha': 0.02,\n            'eps': 1e-6,\n            'step': 1e-3,\n            'iters': 60,\n            'amax': 1.5,\n            'Lsamp': 8,\n            'T': 6,\n            'tol': 0.25,\n            'noise_seed': 123,\n            'base_seed': 1001,\n            'sup_seed': 2001,\n        },\n        {\n            'case_id': 2,\n            'N': 80, 'k': 25,\n            'src_idx': [2],\n            'rec_idx': rec_idx,\n            'sigma': 0.02,\n            'tau': 0.60,\n            'alpha': 0.03,\n            'eps': 1e-6,\n            'step': 1e-3,\n            'iters': 60,\n            'amax': 1.5,\n            'Lsamp': 8,\n            'T': 6,\n            'tol': 0.30,\n            'noise_seed': 223,\n            'base_seed': 1002,\n            'sup_seed': 2002,\n        },\n        {\n            'case_id': 3,\n            'N': 80, 'k': 25,\n            'src_idx': [2, 6, 10],\n            'rec_idx': rec_idx,\n            'sigma': 0.01,\n            'tau': 0.50,\n            'alpha': 0.02,\n            'eps': 1e-6,\n            'step': 1e-3,\n            'iters': 60,\n            'amax': 0.8,\n            'Lsamp': 8,\n            'T': 6,\n            'tol': 0.35,\n            'noise_seed': 323,\n            'base_seed': 1003,\n            'sup_seed': 2003,\n        },\n        {\n            'case_id': 4,\n            'N': 80, 'k': 35,\n            'src_idx': [2, 6, 10],\n            'rec_idx': rec_idx,\n            'sigma': 0.015,\n            'tau': 0.60,\n            'alpha': 0.03,\n            'eps': 1e-6,\n            'step': 1e-3,\n            'iters': 60,\n            'amax': 1.5,\n            'Lsamp': 8,\n            'T': 6,\n            'tol': 0.30,\n            'noise_seed': 423,\n            'base_seed': 1004,\n            'sup_seed': 2004,\n        },\n    ]\n\n    results = []\n    for case in cases:\n        gain = run_trials(case)\n        results.append(gain)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3392423"}]}