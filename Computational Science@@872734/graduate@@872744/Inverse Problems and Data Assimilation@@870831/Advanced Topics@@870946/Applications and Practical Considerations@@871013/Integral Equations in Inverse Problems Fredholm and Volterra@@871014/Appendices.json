{"hands_on_practices": [{"introduction": "We begin our hands-on exploration with a classic example: the Abel integral equation. This is a type of Volterra equation of the first kind that arises in various fields, from mechanics to medical imaging. While many inverse problems are ill-posed, the Abel equation is a special case that admits an exact analytical inversion formula. This exercise [@problem_id:3391691] provides valuable practice in manipulating integral operators, requiring the use of fundamental tools like Fubini's theorem and differentiation under the integral sign to uncover the hidden function $f(s)$.", "problem": "Consider the Abel-type Volterra integral equation of the first kind on the interval $[0,1]$,\n$$\ng(s) \\;=\\; \\int_{0}^{s} \\frac{f(t)}{\\sqrt{s-t}}\\, dt,\\quad s\\in(0,1],\n$$\nwhere $f$ is an unknown function and $g$ is a given function. Assume $f\\in C([0,1])$, $g\\in C^{1}([0,1])$, and $g(0)=0$. Starting only from foundational results of real analysis and integral calculus—specifically, the properties of Volterra integral operators, Fubini’s theorem for iterated integrals, and differentiation under the integral sign—derive an explicit inversion formula that expresses $f(s)$ pointwise for $s\\in(0,1)$ purely in terms of $g$. Your derivation must justify any interchange of the order of integration and any differentiation under the integral sign by citing appropriate regularity or integrability conditions implied by the stated assumptions.\n\nProvide your final result as a single closed-form analytic expression for $f(s)$ in terms of $g$. Do not include intermediate steps, inequalities, or equations in your final answer. No rounding is required.", "solution": "The user wants to find the solution $f(s)$ to the Abel-type Volterra integral equation of the first kind:\n$$\ng(s) \\;=\\; \\int_{0}^{s} \\frac{f(t)}{\\sqrt{s-t}}\\, dt, \\quad s\\in(0,1]\n$$\nThe provided assumptions are that $f$ is a continuous function on $[0,1]$ (i.e., $f \\in C([0,1])$), $g$ is a continuously differentiable function on $[0,1]$ (i.e., $g \\in C^1([0,1])$), and $g(0)=0$. The derivation must be based on foundational principles of calculus and real analysis.\n\nThe method to solve this equation involves applying a specific integral operator to both sides of the equation. For an arbitrary $x \\in (0,1]$, we multiply both sides of the equation (with the variable $s$) by the kernel $(x-s)^{-1/2}$ and integrate with respect to $s$ from $0$ to $x$:\n$$\n\\int_{0}^{x} \\frac{g(s)}{\\sqrt{x-s}} ds \\;=\\; \\int_{0}^{x} \\frac{1}{\\sqrt{x-s}} \\left( \\int_{0}^{s} \\frac{f(t)}{\\sqrt{s-t}} dt \\right) ds\n$$\nThe right-hand side (RHS) is a double integral over a triangular region in the $s$-$t$ plane:\n$$\n\\text{RHS} \\;=\\; \\int_{0}^{x} \\int_{0}^{s} \\frac{f(t)}{\\sqrt{(x-s)(s-t)}} dt\\,ds\n$$\nThe domain of integration is $D = \\{(t,s) \\in \\mathbb{R}^2 \\mid 0 \\le s \\le x, 0 \\le t \\le s \\}$. We wish to interchange the order of integration. This is permissible by Fubini's theorem if the integral of the absolute value of the integrand over $D$ is finite. Since $f \\in C([0,1])$, it is bounded on $[0,1]$, so there exists a constant $M > 0$ such that $|f(t)| \\le M$ for all $t \\in [0,1]$.\n$$\n\\int_{0}^{x} \\int_{0}^{s} \\frac{|f(t)|}{\\sqrt{(x-s)(s-t)}} dt\\,ds \\;\\le\\; M \\int_{0}^{x} \\frac{1}{\\sqrt{x-s}} \\left( \\int_{0}^{s} \\frac{1}{\\sqrt{s-t}} dt \\right) ds\n$$\nThe inner integral evaluates to:\n$$\n\\int_{0}^{s} (s-t)^{-1/2} dt \\;=\\; \\left[-2(s-t)^{1/2}\\right]_{t=0}^{t=s} \\;=\\; 2\\sqrt{s}\n$$\nSubstituting this back, the outer integral becomes:\n$$\nM \\int_{0}^{x} \\frac{2\\sqrt{s}}{\\sqrt{x-s}} ds \\;=\\; 2M \\int_{0}^{x} \\sqrt{\\frac{s}{x-s}} ds\n$$\nThis is an improper integral which is convergent. Its value can be shown to be $2M \\cdot (\\pi x/2) = M\\pi x$. Since the integral of the absolute value of the integrand is finite, Fubini's theorem applies.\n\nWe can now change the order of integration. The domain $D$ can be re-described as $\\{(t,s) \\in \\mathbb{R}^2 \\mid 0 \\le t \\le x, t \\le s \\le x \\}$. The RHS integral becomes:\n$$\n\\text{RHS} \\;=\\; \\int_{0}^{x} f(t) \\left( \\int_{t}^{x} \\frac{ds}{\\sqrt{(x-s)(s-t)}} \\right) dt\n$$\nThe inner integral with respect to $s$ is a standard form. Let's evaluate it using the substitution $s = t \\cos^2\\theta + x \\sin^2\\theta$. Then $ds = 2(x-t)\\sin\\theta\\cos\\theta \\, d\\theta$. The limits change from $s=t$ to $\\theta=0$ and from $s=x$ to $\\theta=\\pi/2$. The terms under the square root become:\n$s-t = (x-t)\\sin^2\\theta$\n$x-s = (x-t)\\cos^2\\theta$\nThe inner integral becomes:\n$$\n\\int_{0}^{\\pi/2} \\frac{2(x-t)\\sin\\theta\\cos\\theta \\, d\\theta}{\\sqrt{(x-t)^2 \\sin^2\\theta \\cos^2\\theta}} \\;=\\; \\int_{0}^{\\pi/2} \\frac{2(x-t)\\sin\\theta\\cos\\theta \\, d\\theta}{(x-t)\\sin\\theta\\cos\\theta} \\;=\\; \\int_{0}^{\\pi/2} 2 \\,d\\theta \\;=\\; \\pi\n$$\nThe inner integral evaluates to the constant $\\pi$, a key result in the theory of Abel's equation.\nSubstituting this result back into the expression for the RHS:\n$$\n\\text{RHS} \\;=\\; \\int_{0}^{x} f(t) \\cdot \\pi \\, dt \\;=\\; \\pi \\int_{0}^{x} f(t) dt\n$$\nEquating this with the left-hand side from our first step, we have:\n$$\n\\pi \\int_{0}^{x} f(t) dt \\;=\\; \\int_{0}^{x} \\frac{g(s)}{\\sqrt{x-s}} ds\n$$\nTo recover $f(x)$, we differentiate both sides with respect to $x$. Given that $f(t)$ is continuous, the Fundamental Theorem of Calculus (Part 1) applies to the left side:\n$$\n\\frac{d}{dx} \\left( \\pi \\int_{0}^{x} f(t) dt \\right) \\;=\\; \\pi f(x)\n$$\nEquating the derivatives gives:\n$$\n\\pi f(x) \\;=\\; \\frac{d}{dx} \\left( \\int_{0}^{x} \\frac{g(s)}{\\sqrt{x-s}} ds \\right)\n$$\nThis provides an explicit formula for $f(x)$. The validity of taking the derivative on the right side is guaranteed by the assumption that $g \\in C^1([0,1])$ and $g(0)=0$. To show this, we can integrate by parts the integral on the right:\n$$\n\\int_{0}^{x} \\frac{g(s)}{\\sqrt{x-s}} ds = \\left[g(s)(-2\\sqrt{x-s})\\right]_{s=0}^{s=x} - \\int_{0}^{x} g'(s)(-2\\sqrt{x-s})ds\n$$\nThe boundary term at $s=x$ is $0$. The boundary term at $s=0$ is $-g(0)(-2\\sqrt{x})$, which is $0$ since $g(0)=0$. Thus, the expression becomes $2\\int_{0}^{x} g'(s)\\sqrt{x-s}ds$. The derivative of this expression with respect to $x$ can be taken using the Leibniz integral rule, and it yields $\\int_0^x \\frac{g'(s)}{\\sqrt{x-s}}ds$, which is well-defined because $g'$ is continuous. This confirms the well-definedness of the derivative operator in our solution.\n\nThe problem asks for an expression for $f(s)$. Replacing the variable $x$ with $s$ and the dummy integration variable $s$ with $t$, we obtain the final inversion formula:\n$$\nf(s) \\;=\\; \\frac{1}{\\pi} \\frac{d}{ds} \\int_{0}^{s} \\frac{g(t)}{\\sqrt{s-t}} dt\n$$\nThis formula expresses the unknown function $f(s)$ pointwise in terms of the given function $g(s)$ and standard mathematical operations, as required.", "answer": "$$\\boxed{\\frac{1}{\\pi} \\frac{d}{ds} \\int_{0}^{s} \\frac{g(t)}{\\sqrt{s-t}}\\, dt}$$", "id": "3391691"}, {"introduction": "Moving from the direct solvability of Volterra equations, we now confront the subtleties of Fredholm equations of the second kind. For equations of the form $f - \\lambda K f = g$, a solution may not exist for every $g$, or it may not be unique. This practice [@problem_id:3391730] guides you through constructing a specific scenario to demonstrate the celebrated Fredholm alternative, which provides the precise conditions for solvability. By engaging with this problem, you will develop a concrete understanding of null spaces, operator adjoints, and the structure of solution sets for this important class of equations.", "problem": "Consider the Hilbert space $L^{2}(0,1)$, representing a one-dimensional state variable $f$ over the spatial interval $[0,1]$ in a stylized inverse problem from data assimilation with an integral observation operator. You are to explicitly construct a measurable kernel $k:[0,1]\\times[0,1]\\to\\mathbb{R}$ and a scalar $\\lambda\\in\\mathbb{R}$ such that the associated integral operator $(Kf)(x)=\\int_{0}^{1}k(x,t)f(t)\\,dt$ yields a non-invertible operator $I-\\lambda K:L^{2}(0,1)\\to L^{2}(0,1)$. Using only fundamental operator-theoretic principles and integral identities, determine the structure of the null space and range of $I-\\lambda K$ and deduce necessary and sufficient solvability conditions for the Fredholm integral equation of the second kind\n$$\nf-\\lambda Kf=g,\n$$\nwith a given $g\\in L^{2}(0,1)$. Then, specializing to your explicit construction of $k$ and $\\lambda$, let $g(x)=x-\\frac{1}{2}$ and determine the unique minimal-norm solution in $L^{2}(0,1)$ of the equation $f-\\lambda Kf=g$. Provide the explicit analytic expression for this minimal-norm solution $f(x)$. No numerical rounding is required. Express your final answer as a closed-form expression in $x$ without units.", "solution": "The problem requires the construction of a specific Fredholm integral equation of the second kind, $(I-\\lambda K)f=g$, that is not generally invertible. We must then determine the conditions for its solvability and find the unique minimal-norm solution for a given function $g(x)$.\n\nFirst, we construct the integral operator $K$ and choose the scalar $\\lambda$ such that $I-\\lambda K$ is non-invertible. The simplest way to achieve this is to select a degenerate kernel of rank one. Let the kernel be $k(x,t) = 1$ for all $(x,t) \\in [0,1] \\times [0,1]$. The corresponding integral operator is given by:\n$$\n(Kf)(x) = \\int_{0}^{1} 1 \\cdot f(t) \\, dt\n$$\nThis operator maps any function $f \\in L^2(0,1)$ to a constant function equal to the integral of $f$ over the interval $[0,1]$. To analyze the invertibility of $I-\\lambda K$, we examine the spectrum of $K$. An eigenvalue $\\mu$ and corresponding eigenfunction $\\phi$ must satisfy $K\\phi = \\mu\\phi$.\n$$\n\\int_{0}^{1} \\phi(t) \\, dt = \\mu \\phi(x)\n$$\nThe left-hand side is a constant, let's call it $C$. Thus, $\\mu \\phi(x) = C$. If $\\mu \\neq 0$, then $\\phi(x) = C/\\mu$ must be a constant function. Let's test a non-zero constant function, say $\\phi(x) = A$ for some $A \\neq 0$.\n$$\n(KA)(x) = \\int_{0}^{1} A \\, dt = A\n$$\nThe eigenvalue equation is $A = \\mu A$, which for $A \\neq 0$ implies $\\mu = 1$. Thus, the operator $K$ has a single non-zero eigenvalue $\\mu=1$, and its corresponding eigenspace is the set of all constant functions, spanned by the function $\\phi(x)=1$.\n\nThe operator $I-\\lambda K$ is non-invertible if and only if $1$ is an eigenvalue of the operator $\\lambda K$. The eigenvalues of $\\lambda K$ are $\\lambda\\mu$. For $1$ to be an eigenvalue of $\\lambda K$, we must have $\\lambda\\mu=1$. Since the only non-zero eigenvalue of $K$ is $\\mu=1$, we must choose $\\lambda=1$.\nWith this choice, our problem becomes solving the equation $(I-K)f=g$, or:\n$$\nf(x) - \\int_{0}^{1} f(t) \\, dt = g(x)\n$$\nThe operator $K$ is a Hilbert-Schmidt operator since its kernel is square-integrable: $\\int_0^1\\int_0^1 |k(x,t)|^2 \\,dx\\,dt = \\int_0^1\\int_0^1 1^2 \\,dx\\,dt = 1  \\infty$. Therefore, $K$ is a compact operator on $L^2(0,1)$. The Fredholm alternative applies to the operator $I-K$.\n\nAccording to the Fredholm alternative, since the homogeneous equation $(I-K)\\phi=0$ has non-trivial solutions (namely, any constant function), the inhomogeneous equation $(I-K)f=g$ has a solution if and only if $g$ is orthogonal to the null space of the adjoint operator, $(I-K^*)$. The kernel is real and symmetric, $k(x,t) = 1 = k(t,x)$, so the operator $K$ is self-adjoint, i.e., $K^*=K$.\nThe null space of $I-K$ is the eigenspace of $K$ for eigenvalue $1$, which is $\\mathcal{N}(I-K) = \\text{span}\\{1\\}$.\nSince $K^*=K$, the null space of the adjoint is the same: $\\mathcal{N}(I-K^*) = \\text{span}\\{1\\}$.\nThe solvability condition for $f-Kf=g$ is that $g$ must be orthogonal to every function in $\\mathcal{N}(I-K^*)$. It is sufficient to test for orthogonality against the basis function $\\psi(x)=1$:\n$$\n\\langle g, \\psi \\rangle = \\int_{0}^{1} g(x) \\overline{\\psi(x)} \\, dx = \\int_{0}^{1} g(x) \\cdot 1 \\, dx = 0\n$$\nThus, a solution exists if and only if the integral of $g(x)$ over $[0,1]$ is zero. This corresponds to the condition that $g$ must lie in the range of the operator $I-K$, which is the orthogonal complement of the null space of the adjoint, $\\mathcal{R}(I-K) = (\\mathcal{N}(I-K^*))^{\\perp} = (\\text{span}\\{1\\})^{\\perp}$.\n\nWe are given the function $g(x) = x - \\frac{1}{2}$. We check the solvability condition:\n$$\n\\int_{0}^{1} g(x) \\, dx = \\int_{0}^{1} \\left(x - \\frac{1}{2}\\right) \\, dx = \\left[\\frac{x^2}{2} - \\frac{x}{2}\\right]_{0}^{1} = \\left(\\frac{1}{2} - \\frac{1}{2}\\right) - 0 = 0\n$$\nThe condition is satisfied, so solutions exist. To find them, let $C = \\int_{0}^{1} f(t) \\, dt$. The equation becomes:\n$$\nf(x) - C = x - \\frac{1}{2} \\implies f(x) = x - \\frac{1}{2} + C\n$$\nThis represents the general form of any solution. Substituting this form back into the definition of $C$ gives $C = \\int_{0}^{1} (t - \\frac{1}{2} + C) \\, dt = \\int_{0}^{1} (t - \\frac{1}{2}) \\, dt + \\int_{0}^{1} C \\, dt = 0 + C$, which is $C=C$. This confirms that any constant $C \\in \\mathbb{R}$ yields a valid solution. The set of all solutions is the affine subspace $f_p + \\mathcal{N}(I-K)$, where $f_p(x) = x-\\frac{1}{2}$ is a particular solution and $\\mathcal{N}(I-K)=\\text{span}\\{C \\cdot 1\\}$.\n\nThe problem asks for the unique minimal-norm solution. In a Hilbert space, the element of an affine subspace with the minimum norm is the one that is orthogonal to the direction space of the subspace. Here, the direction space is the null space $\\mathcal{N}(I-K)=\\text{span}\\{1\\}$. The minimal-norm solution, let's call it $f_m$, must therefore be orthogonal to the basis function of the null space, i.e., $\\langle f_m, 1 \\rangle = 0$.\nWe need to find the value of $C$ such that the solution $f(x) = x - \\frac{1}{2} + C$ satisfies this orthogonality condition:\n$$\n\\int_{0}^{1} \\left(x - \\frac{1}{2} + C\\right) \\, dx = 0\n$$\n$$\n\\int_{0}^{1} \\left(x - \\frac{1}{2}\\right) \\, dx + \\int_{0}^{1} C \\, dx = 0\n$$\nAs calculated before, the first integral is $0$. The second integral is $C$. So we have $0 + C = 0$, which implies $C=0$.\nTherefore, the unique minimal-norm solution is obtained by setting $C=0$ in the general solution.\n\nThe minimal-norm solution is $f(x) = x - \\frac{1}{2}$.", "answer": "$$\n\\boxed{x-\\frac{1}{2}}\n$$", "id": "3391730"}, {"introduction": "Our final practice tackles the quintessential challenge of inverse problems: the ill-posedness of Fredholm integral equations of the first kind. These equations are notoriously sensitive to noise, a property rooted in the spectral nature of the integral operator. This exercise [@problem_id:3391739] makes this abstract concept tangible by having you discretize an operator and analyze the resulting linear system. You will discover how the smooth kernel's rapidly decaying eigenvalues translate directly into an exploding condition number for the discrete matrix, revealing the practical origin of numerical instability in solving inverse problems.", "problem": "Consider a Fredholm integral equation of the first kind on the interval $[0,1]$,\n$$\n(Kf)(s) = \\int_{0}^{1} k(s,t)\\,f(t)\\,dt = g(s),\n$$\nwhere $k(s,t)$ is a continuous symmetric kernel and $g(s)$ is a known function. In inverse problems, discretization via the Nyström method generates a linear system that approximates the integral operator. Your tasks are as follows:\n\n1. Using the kernel\n$$\nk(s,t) = \\min(s,t) - s\\,t,\n$$\nderive the Nyström discretization with the midpoint quadrature rule on $[0,1]$. Let the quadrature nodes be $t_{j} = \\frac{j-\\frac{1}{2}}{N}$ for $j=1,\\dots,N$ and weights $w_{j} = \\frac{1}{N}$. Collocate the integral equation at the same set of points $s_{i} = t_{i}$, $i=1,\\dots,N$, to obtain the linear system $A\\mathbf{f} \\approx \\mathbf{g}$, where $\\mathbf{f} = \\big(f(t_{1}),\\dots,f(t_{N})\\big)^{\\top}$ and $\\mathbf{g} = \\big(g(s_{1}),\\dots,g(s_{N})\\big)^{\\top}$. Write an explicit formula for the entries $A_{ij}$ in terms of $s_{i}$, $t_{j}$, and $w_{j}$.\n\n2. Starting from the definition of an eigenpair $(\\lambda,\\varphi)$ of the integral operator $K$, that is\n$$\n\\int_{0}^{1} \\big(\\min(s,t) - s\\,t\\big)\\,\\varphi(t)\\,dt = \\lambda\\,\\varphi(s),\n$$\nderive, by differentiating with respect to $s$ and using appropriate boundary conditions implied by the kernel, the ordinary differential equation satisfied by $\\varphi(s)$ and determine the eigenvalues $\\lambda_{n}$ and eigenfunctions $\\varphi_{n}(s)$.\n\n3. Use the spectral characterization from part 2 and the fact that the Nyström discretization with a consistent quadrature rule yields a symmetric positive definite matrix whose spectrum converges to that of the continuous operator to justify the asymptotic behavior of the condition number $\\kappa(A)$ of the Nyström matrix $A$ as $N$ increases. Here the condition number is defined as $\\kappa(A) = \\sigma_{\\max}(A)/\\sigma_{\\min}(A)$, where $\\sigma_{\\max}(A)$ and $\\sigma_{\\min}(A)$ denote the largest and smallest singular values of $A$.\n\nState your final result for the leading-order asymptotic expression of $\\kappa(A)$ as a closed-form analytic expression in $N$. No units are required. Do not provide an inequality. If you must approximate, provide the leading-order term only, without lower-order corrections.", "solution": "The user has provided a three-part problem concerning a Fredholm integral equation of the first kind. I will first validate the problem and then proceed to a complete solution.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   **Integral Equation:** $(Kf)(s) = \\int_{0}^{1} k(s,t)\\,f(t)\\,dt = g(s)$ for $s \\in [0,1]$.\n-   **Kernel:** $k(s,t) = \\min(s,t) - s\\,t$. It is stated to be continuous and symmetric.\n-   **Part 1 Givens (Nyström Discretization):**\n    -   Quadrature rule: Midpoint rule.\n    -   Quadrature nodes: $t_{j} = \\frac{j-\\frac{1}{2}}{N}$ for $j=1,\\dots,N$.\n    -   Quadrature weights: $w_{j} = \\frac{1}{N}$.\n    -   Collocation points: $s_{i} = t_{i} = \\frac{i-\\frac{1}{2}}{N}$ for $i=1,\\dots,N$.\n    -   Task: Find the explicit formula for the entries $A_{ij}$ of the matrix in the system $A\\mathbf{f} \\approx \\mathbf{g}$.\n-   **Part 2 Givens (Eigenproblem):**\n    -   Eigenvalue equation: $\\int_{0}^{1} \\big(\\min(s,t) - s\\,t\\big)\\,\\varphi(t)\\,dt = \\lambda\\,\\varphi(s)$.\n    -   Task: Derive the differential equation for $\\varphi(s)$ and find the eigenvalues $\\lambda_{n}$ and eigenfunctions $\\varphi_{n}(s)$.\n-   **Part 3 Givens (Condition Number):**\n    -   The Nyström matrix $A$ is stated to be symmetric positive definite.\n    -   The spectrum of $A$ converges to that of the continuous operator $K$.\n    -   Condition number definition: $\\kappa(A) = \\sigma_{\\max}(A)/\\sigma_{\\min}(A)$.\n    -   Task: Justify and find the leading-order asymptotic expression for $\\kappa(A)$ as $N \\to \\infty$.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded:** The problem is a standard exercise in the theory of integral equations and their numerical solution. The kernel $k(s,t) = \\min(s,t) - st$ is the Green's function for the second-order differential operator $L=-d^2/ds^2$ with Dirichlet boundary conditions $\\varphi(0)=0$ and $\\varphi(1)=0$. This is a well-established fact in the study of boundary value problems. All parts of the problem are based on sound mathematical principles.\n-   **Well-Posed:** Each part of the problem is well-defined and has a unique, meaningful solution. The steps are logically connected to guide the solver from the continuous problem to the analysis of its discretization.\n-   **Objective:** The problem is stated in precise mathematical language, free from any subjectivity or ambiguity.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is scientifically sound, well-posed, and objective. I will now proceed with providing a complete solution.\n\n### Solution\n\n**Part 1: Nyström Discretization**\n\nThe Fredholm integral equation is given by\n$$\n\\int_{0}^{1} k(s,t)\\,f(t)\\,dt = g(s).\n$$\nThe Nyström method approximates the integral using a quadrature rule. Using the given midpoint rule with nodes $t_j$ and weights $w_j$, the integral is approximated as:\n$$\n\\int_{0}^{1} k(s,t)\\,f(t)\\,dt \\approx \\sum_{j=1}^{N} w_j k(s, t_j) f(t_j).\n$$\nTo obtain a linear system, we collocate the equation at the points $s_i = t_i$. This yields:\n$$\n\\sum_{j=1}^{N} w_j k(s_i, t_j) f(t_j) \\approx g(s_i), \\quad \\text{for } i=1,\\dots,N.\n$$\nThis is a linear system of the form $A\\mathbf{f} \\approx \\mathbf{g}$, where $\\mathbf{f}$ is the vector with entries $f_j = f(t_j)$ and $\\mathbf{g}$ is the vector with entries $g_i = g(s_i)$. The entries of the matrix $A$ are given by\n$$\nA_{ij} = w_j k(s_i, t_j).\n$$\nSubstituting the given expressions for the kernel, weights, nodes, and collocation points:\n-   $k(s_i, t_j) = \\min(s_i, t_j) - s_i t_j$\n-   $w_j = \\frac{1}{N}$\n-   $s_i = t_i = \\frac{i-\\frac{1}{2}}{N}$\n-   $t_j = \\frac{j-\\frac{1}{2}}{N}$\n\nThe matrix entries $A_{ij}$ are:\n$$\nA_{ij} = \\frac{1}{N} \\left[ \\min\\left(\\frac{i-\\frac{1}{2}}{N}, \\frac{j-\\frac{1}{2}}{N}\\right) - \\left(\\frac{i-\\frac{1}{2}}{N}\\right)\\left(\\frac{j-\\frac{1}{2}}{N}\\right) \\right].\n$$\nThis is the explicit formula for the entries of the Nyström matrix $A$.\n\n**Part 2: Eigenvalue Problem for the Integral Operator**\n\nWe are tasked with solving the eigenvalue problem for the integral operator $K$:\n$$\n\\lambda \\varphi(s) = \\int_{0}^{1} (\\min(s,t) - st) \\varphi(t) dt.\n$$\nTo convert this integral equation into a differential equation, we first split the integral at $t=s$:\n$$\n\\lambda \\varphi(s) = \\int_{0}^{s} (t - st) \\varphi(t) dt + \\int_{s}^{1} (s - st) \\varphi(t) dt.\n$$\n$$\n\\lambda \\varphi(s) = (1-s) \\int_{0}^{s} t \\varphi(t) dt + s \\int_{s}^{1} (1-t) \\varphi(t) dt.\n$$\nWe differentiate this equation with respect to $s$ using the Leibniz integral rule:\n$$\n\\lambda \\varphi'(s) = \\frac{d}{ds} \\left[ (1-s) \\int_{0}^{s} t \\varphi(t) dt + s \\int_{s}^{1} (1-t) \\varphi(t) dt \\right]\n$$\n$$\n\\lambda \\varphi'(s) = -\\int_{0}^{s} t\\varphi(t)dt + (1-s)(s\\varphi(s)) + \\int_{s}^{1}(1-t)\\varphi(t)dt + s(-(1-s)\\varphi(s))\n$$\n$$\n\\lambda \\varphi'(s) = -\\int_{0}^{s} t\\varphi(t)dt + s(1-s)\\varphi(s) + \\int_{s}^{1}(1-t)\\varphi(t)dt - s(1-s)\\varphi(s)\n$$\n$$\n\\lambda \\varphi'(s) = \\int_{s}^{1} (1-t)\\varphi(t)dt - \\int_{0}^{s} t\\varphi(t)dt.\n$$\nDifferentiating a second time with respect to $s$:\n$$\n\\lambda \\varphi''(s) = \\frac{d}{ds} \\left[ \\int_{s}^{1} (1-t)\\varphi(t)dt - \\int_{0}^{s} t\\varphi(t)dt \\right]\n$$\n$$\n\\lambda \\varphi''(s) = -(1-s)\\varphi(s) - s\\varphi(s) = -s\\varphi(s) - \\varphi(s) + s\\varphi(s) = -\\varphi(s).\n$$\nThis gives the ordinary differential equation:\n$$\n\\varphi''(s) + \\frac{1}{\\lambda} \\varphi(s) = 0.\n$$\nNext, we determine the boundary conditions. From the expression for $\\lambda \\varphi(s)$, we evaluate at $s=0$:\n$$\n\\lambda \\varphi(0) = (1-0) \\int_{0}^{0} t \\varphi(t) dt + 0 \\cdot \\int_{0}^{1} (1-t) \\varphi(t) dt = 0.\n$$\nFor non-trivial eigensolutions, we must have $\\lambda \\neq 0$, which implies $\\varphi(0)=0$.\nEvaluating at $s=1$:\n$$\n\\lambda \\varphi(1) = (1-1) \\int_{0}^{1} t \\varphi(t) dt + 1 \\cdot \\int_{1}^{1} (1-t) \\varphi(t) dt = 0.\n$$\nThis implies $\\varphi(1)=0$.\nWe now have a Sturm-Liouville problem consisting of the ODE $\\varphi''(s) + \\mu \\varphi(s) = 0$ with $\\mu=1/\\lambda$ and boundary conditions $\\varphi(0)=0$, $\\varphi(1)=0$.\nThe general solution to the ODE is $\\varphi(s) = C_1 \\cos(\\sqrt{\\mu}s) + C_2 \\sin(\\sqrt{\\mu}s)$.\nApplying the boundary conditions:\n-   $\\varphi(0) = 0 \\implies C_1 \\cos(0) + C_2 \\sin(0) = C_1 = 0$.\n-   $\\varphi(s)$ must be of the form $\\varphi(s) = C_2 \\sin(\\sqrt{\\mu}s)$.\n-   $\\varphi(1) = 0 \\implies C_2 \\sin(\\sqrt{\\mu}) = 0$.\nFor a non-trivial solution ($C_2 \\neq 0$), we require $\\sin(\\sqrt{\\mu})=0$. This occurs when $\\sqrt{\\mu} = n\\pi$ for any integer $n$. We take $n=1, 2, 3, \\dots$ for distinct, non-trivial solutions.\nThe eigenvalues of the differential operator are $\\mu_n = (n\\pi)^2$.\nSince $\\lambda = 1/\\mu$, the eigenvalues of the integral operator $K$ are:\n$$\n\\lambda_n = \\frac{1}{(n\\pi)^2}, \\quad n=1, 2, 3, \\dots\n$$\nThe corresponding unnormalized eigenfunctions are:\n$$\n\\varphi_n(s) = \\sin(n\\pi s).\n$$\nThe normalized eigenfunctions are $\\sqrt{2}\\sin(n\\pi s)$.\n\n**Part 3: Asymptotic Behavior of the Condition Number**\n\nThe condition number of the matrix $A$ is defined as $\\kappa(A) = \\sigma_{\\max}(A)/\\sigma_{\\min}(A)$, where $\\sigma_{\\max}(A)$ and $\\sigma_{\\min}(A)$ are the largest and smallest singular values of $A$.\nThe kernel $k(s,t)$ is symmetric. The quadrature rule uses equal weights $w_j = 1/N$. The matrix entries are $A_{ij} = \\frac{1}{N}k(s_i, t_j)$. With $s_i=t_i$, we have $A_{ij} = \\frac{1}{N}k(t_i, t_j)$. Since $k(t_i, t_j)=k(t_j, t_i)$, the matrix $A$ is symmetric.\nThe integral operator $K$ is positive definite on the space of functions orthogonal to the null space (which is only the zero function here), as its eigenvalues $\\lambda_n = 1/(n\\pi)^2$ are all positive. For large enough $N$, the discrete approximation $A$ will also be positive definite. For a symmetric positive definite matrix, its singular values are its eigenvalues. Thus, $\\kappa(A) = \\nu_{\\max}(A)/\\nu_{\\min}(A)$, where $\\nu$ denotes the eigenvalues of $A$.\n\nThe problem states that the spectrum of the Nyström matrix $A$ converges to that of the continuous operator $K$. This is a key result from the theory of numerical integral equations. It implies that for large $N$, the set of $N$ eigenvalues of the matrix $A$, which we denote $\\{\\nu_k\\}_{k=1}^N$ in decreasing order, provides a good approximation to the first $N$ eigenvalues of the operator $K$, $\\{\\lambda_k\\}_{k=1}^N$.\n\n1.  **Largest Eigenvalue:** The largest eigenvalue of $A$, $\\nu_{\\max}(A) = \\nu_1$, will approximate the largest (principal) eigenvalue of $K$. From Part 2, this is $\\lambda_1$.\n    $$\n    \\sigma_{\\max}(A) = \\nu_1 \\approx \\lambda_1 = \\frac{1}{\\pi^2}.\n    $$\n2.  **Smallest Eigenvalue:** The $N$ eigenvalues of the discrete system correspond to the $N$ modes that can be resolved on the grid. The smallest eigenvalue of $A$, $\\nu_{\\min}(A)=\\nu_N$, corresponds to the highest-frequency mode representable by the discretization. It is therefore reasonable to approximate $\\nu_N$ by the $N$-th eigenvalue of the continuous operator, $\\lambda_N$.\n    $$\n    \\sigma_{\\min}(A) = \\nu_N \\approx \\lambda_N = \\frac{1}{(N\\pi)^2}.\n    $$\n3.  **Condition Number:** Using these asymptotic approximations, we can find the leading-order behavior of the condition number $\\kappa(A)$:\n    $$\n    \\kappa(A) = \\frac{\\sigma_{\\max}(A)}{\\sigma_{\\min}(A)} \\approx \\frac{\\lambda_1}{\\lambda_N} = \\frac{1/(\\pi^2)}{1/((N\\pi)^2)} = \\frac{(N\\pi)^2}{\\pi^2} = N^2.\n    $$\nThe severe ill-conditioning, growing quadratically with $N$, is characteristic of the discretization of Fredholm integral equations of the first kind with smooth kernels (so-called ill-posed problems). The leading-order asymptotic expression for the condition number is $N^2$.", "answer": "$$\\boxed{N^2}$$", "id": "3391739"}]}