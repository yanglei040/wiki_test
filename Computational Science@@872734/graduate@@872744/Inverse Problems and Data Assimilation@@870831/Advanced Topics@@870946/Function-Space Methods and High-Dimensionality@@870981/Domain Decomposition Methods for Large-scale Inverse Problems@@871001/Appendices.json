{"hands_on_practices": [{"introduction": "This first exercise provides a foundational, hands-on look at the algebra of non-overlapping domain decomposition. By manually performing block Gaussian elimination on a small, discrete system, you will derive the Schur complement system for the interface unknowns. This practice is essential for understanding the core mechanism of substructuring methods, where the computational bottleneck of a large-scale problem is reduced to solving a smaller, denser system on the subdomain interfaces [@problem_id:3377575].", "problem": "Consider a single linearized Gauss–Newton step for a Tikhonov-regularized inverse source identification problem constrained by a Poisson-type partial differential equation. The computational domain is decomposed into two non-overlapping subdomains, and the state is discretized with $6$ degrees of freedom, grouped into two subdomain vectors of size $3$ each. Interface continuity is imposed via two equality constraints, one per interface degree of freedom. In the standard Lagrange-multiplier formulation, the linear system takes the saddle-point form\n$$\n\\begin{pmatrix}\n\\mathbf{K}  \\mathbf{B}^{\\top} \\\\\n\\mathbf{B}  \\mathbf{0}\n\\end{pmatrix}\n\\begin{pmatrix}\n\\mathbf{u} \\\\\n\\boldsymbol{\\lambda}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\mathbf{f} \\\\\n\\mathbf{0}\n\\end{pmatrix},\n$$\nwhere $\\mathbf{u}\\in\\mathbb{R}^{6}$ collects the subdomain state unknowns, $\\boldsymbol{\\lambda}\\in\\mathbb{R}^{2}$ are the interface Lagrange multipliers, $\\mathbf{K}\\in\\mathbb{R}^{6\\times 6}$ is block diagonal with two $3\\times 3$ subdomain operators, and $\\mathbf{B}\\in\\mathbb{R}^{2\\times 6}$ enforces interface continuity.\n\nAssume that each subdomain operator is the standard one-dimensional Poisson stiffness on a uniform grid with Dirichlet boundary conditions, namely\n$$\n\\mathbf{K}_1=\\mathbf{K}_2=\\begin{pmatrix}\n2  -1  0 \\\\\n-1  2  -1 \\\\\n0  -1  2\n\\end{pmatrix},\n$$\nand that\n$$\n\\mathbf{K}=\\mathrm{diag}(\\mathbf{K}_1,\\mathbf{K}_2).\n$$\nLet the ordering of $\\mathbf{u}$ be $\\mathbf{u}=\\begin{pmatrix}u_{1,a}  u_{1,b}  u_{1,c}  u_{2,a}  u_{2,b}  u_{2,c}\\end{pmatrix}^{\\top}$, and impose the two interface continuity constraints $u_{1,b}-u_{2,a}=0$ and $u_{1,c}-u_{2,b}=0$, i.e.,\n$$\n\\mathbf{B}=\\begin{pmatrix}\n0  1  0  -1  0  0 \\\\\n0  0  1  0  -1  0\n\\end{pmatrix}.\n$$\nTake the right-hand side to be\n$$\n\\mathbf{f}=\\begin{pmatrix}1  0  0  0  1  0\\end{pmatrix}^{\\top}.\n$$\n\nStarting from the first-order optimality (Karush–Kuhn–Tucker) conditions for the constrained least-squares subproblem and using block Gaussian elimination as the only algebraic tool, eliminate the interior state variables $\\mathbf{u}$ to form the Schur complement on the interface multipliers, and then solve the reduced system for $\\boldsymbol{\\lambda}$. Back-substitute to recover $\\mathbf{u}$. Finally, report the determinant of the $2\\times 2$ Schur complement matrix on the interface multipliers as an exact rational number. No rounding is required. Your final answer must be a single real number without units.", "solution": "The problem statement has been validated and is deemed a well-posed problem in numerical linear algebra, arising from the domain decomposition of a partial differential equation. We may therefore proceed with a formal solution.\n\nThe system to be solved is a saddle-point linear system given by the Karush–Kuhn–Tucker (KKT) conditions for a constrained optimization problem. The system is expressed in block matrix form as:\n$$\n\\begin{pmatrix}\n\\mathbf{K}  \\mathbf{B}^{\\top} \\\\\n\\mathbf{B}  \\mathbf{0}\n\\end{pmatrix}\n\\begin{pmatrix}\n\\mathbf{u} \\\\\n\\boldsymbol{\\lambda}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\mathbf{f} \\\\\n\\mathbf{0}\n\\end{pmatrix}\n$$\nThis corresponds to two block equations:\n$$\n\\mathbf{K}\\mathbf{u} + \\mathbf{B}^{\\top}\\boldsymbol{\\lambda} = \\mathbf{f} \\quad (1)\n$$\n$$\n\\mathbf{B}\\mathbf{u} = \\mathbf{0} \\quad (2)\n$$\nThe task is to solve this system by first forming a Schur complement system for the Lagrange multipliers $\\boldsymbol{\\lambda}$. This is achieved through block Gaussian elimination.\n\nFirst, we must establish that the matrix $\\mathbf{K}$ is invertible. The matrix $\\mathbf{K}$ is given as $\\mathbf{K}=\\mathrm{diag}(\\mathbf{K}_1,\\mathbf{K}_2)$, where:\n$$\n\\mathbf{K}_1=\\mathbf{K}_2=\\begin{pmatrix} 2  -1  0 \\\\ -1  2  -1 \\\\ 0  -1  2 \\end{pmatrix}\n$$\nThis is a symmetric tridiagonal matrix. Its determinant is $\\det(\\mathbf{K}_1) = 2(2 \\cdot 2 - (-1)(-1)) - (-1)(-1 \\cdot 2 - 0) = 2(3) - 2 = 4$. Since the determinant is non-zero, $\\mathbf{K}_1$ is invertible. As $\\mathbf{K}_2 = \\mathbf{K}_1$, it is also invertible. Consequently, $\\mathbf{K}$, being block diagonal with invertible blocks, is itself invertible.\n\nFrom equation (1), we can formally express $\\mathbf{u}$ as:\n$$\n\\mathbf{u} = \\mathbf{K}^{-1}(\\mathbf{f} - \\mathbf{B}^{\\top}\\boldsymbol{\\lambda})\n$$\nSubstituting this expression for $\\mathbf{u}$ into equation (2) eliminates the state variables $\\mathbf{u}$:\n$$\n\\mathbf{B} \\left( \\mathbf{K}^{-1}(\\mathbf{f} - \\mathbf{B}^{\\top}\\boldsymbol{\\lambda}) \\right) = \\mathbf{0}\n$$\nBy linearity, we can distribute $\\mathbf{B}$:\n$$\n\\mathbf{B}\\mathbf{K}^{-1}\\mathbf{f} - \\mathbf{B}\\mathbf{K}^{-1}\\mathbf{B}^{\\top}\\boldsymbol{\\lambda} = \\mathbf{0}\n$$\nRearranging this equation yields the Schur complement system for $\\boldsymbol{\\lambda}$:\n$$\n(\\mathbf{B}\\mathbf{K}^{-1}\\mathbf{B}^{\\top})\\boldsymbol{\\lambda} = \\mathbf{B}\\mathbf{K}^{-1}\\mathbf{f}\n$$\nThe Schur complement matrix, which we denote by $\\mathbf{S}$, is the $2 \\times 2$ matrix on the left-hand side:\n$$\n\\mathbf{S} = \\mathbf{B}\\mathbf{K}^{-1}\\mathbf{B}^{\\top}\n$$\nThe problem requires the calculation of the determinant of $\\mathbf{S}$. To compute $\\mathbf{S}$, we first need the inverse of $\\mathbf{K}$. Since $\\mathbf{K} = \\mathrm{diag}(\\mathbf{K}_1, \\mathbf{K}_2)$, its inverse is $\\mathbf{K}^{-1} = \\mathrm{diag}(\\mathbf{K}_1^{-1}, \\mathbf{K}_2^{-1})$. We compute $\\mathbf{K}_1^{-1}$ using the adjugate method:\n$$\n\\mathbf{K}_1^{-1} = \\frac{1}{\\det(\\mathbf{K}_1)}\\mathrm{adj}(\\mathbf{K}_1)^{\\top} = \\frac{1}{4} \\begin{pmatrix} 3  2  1 \\\\ 2  4  2 \\\\ 1  2  3 \\end{pmatrix}\n$$\nAs $\\mathbf{K}_1 = \\mathbf{K}_2$, we have $\\mathbf{K}_2^{-1} = \\mathbf{K}_1^{-1}$. Thus,\n$$\n\\mathbf{K}^{-1} = \\frac{1}{4} \\begin{pmatrix}\n3  2  1  0  0  0 \\\\\n2  4  2  0  0  0 \\\\\n1  2  3  0  0  0 \\\\\n0  0  0  3  2  1 \\\\\n0  0  0  2  4  2 \\\\\n0  0  0  1  2  3\n\\end{pmatrix}\n$$\nThe matrix $\\mathbf{B}$ is given as:\n$$\n\\mathbf{B}=\\begin{pmatrix}\n0  1  0  -1  0  0 \\\\\n0  0  1  0  -1  0\n\\end{pmatrix}\n$$\nWe now compute the product $\\mathbf{B}\\mathbf{K}^{-1}$:\n$$\n\\mathbf{B}\\mathbf{K}^{-1} = \\begin{pmatrix}\n0  1  0  -1  0  0 \\\\\n0  0  1  0  -1  0\n\\end{pmatrix} \\frac{1}{4} \\begin{pmatrix}\n3  2  1  0  0  0 \\\\\n2  4  2  0  0  0 \\\\\n1  2  3  0  0  0 \\\\\n0  0  0  3  2  1 \\\\\n0  0  0  2  4  2 \\\\\n0  0  0  1  2  3\n\\end{pmatrix}\n$$\nThe first row of the result is $\\frac{1}{4}$ times (row $2$ of $\\mathbf{K}^{-1}$'s block - row $4$ of $\\mathbf{K}^{-1}$'s block), and the second row is $\\frac{1}{4}$ times (row $3$ of $\\mathbf{K}^{-1}$'s block - row $5$ of $\\mathbf{K}^{-1}$'s block). This yields:\n$$\n\\mathbf{B}\\mathbf{K}^{-1} = \\frac{1}{4} \\begin{pmatrix}\n2  4  2  -3  -2  -1 \\\\\n1  2  3  -2  -4  -2\n\\end{pmatrix}\n$$\nNext, we multiply this result by $\\mathbf{B}^{\\top}$ to form $\\mathbf{S}$:\n$$\n\\mathbf{B}^{\\top} = \\begin{pmatrix} 0  0 \\\\ 1  0 \\\\ 0  1 \\\\ -1  0 \\\\ 0  -1 \\\\ 0  0 \\end{pmatrix}\n$$\n$$\n\\mathbf{S} = (\\mathbf{B}\\mathbf{K}^{-1})\\mathbf{B}^{\\top} = \\frac{1}{4} \\begin{pmatrix}\n2  4  2  -3  -2  -1 \\\\\n1  2  3  -2  -4  -2\n\\end{pmatrix} \\begin{pmatrix} 0  0 \\\\ 1  0 \\\\ 0  1 \\\\ -1  0 \\\\ 0  -1 \\\\ 0  0 \\end{pmatrix}\n$$\nPerforming the matrix multiplication:\n$$\nS_{11} = \\frac{1}{4} (2(0) + 4(1) + 2(0) - 3(-1) - 2(0) - 1(0)) = \\frac{1}{4}(4+3) = \\frac{7}{4}\n$$\n$$\nS_{12} = \\frac{1}{4} (2(0) + 4(0) + 2(1) - 3(0) - 2(-1) - 1(0)) = \\frac{1}{4}(2+2) = \\frac{4}{4} = 1\n$$\n$$\nS_{21} = \\frac{1}{4} (1(0) + 2(1) + 3(0) - 2(-1) - 4(0) - 2(0)) = \\frac{1}{4}(2+2) = \\frac{4}{4} = 1\n$$\n$$\nS_{22} = \\frac{1}{4} (1(0) + 2(0) + 3(1) - 2(0) - 4(-1) - 2(0)) = \\frac{1}{4}(3+4) = \\frac{7}{4}\n$$\nThe Schur complement matrix is therefore:\n$$\n\\mathbf{S} = \\begin{pmatrix} \\frac{7}{4}  1 \\\\ 1  \\frac{7}{4} \\end{pmatrix}\n$$\nThe problem asks for the determinant of this matrix.\n$$\n\\det(\\mathbf{S}) = \\left(\\frac{7}{4}\\right)\\left(\\frac{7}{4}\\right) - (1)(1) = \\frac{49}{16} - 1 = \\frac{49}{16} - \\frac{16}{16} = \\frac{33}{16}\n$$\nThis is the required value. For completeness, one could solve for $\\boldsymbol{\\lambda}$ using $\\mathbf{S}\\boldsymbol{\\lambda} = \\mathbf{B}\\mathbf{K}^{-1}\\mathbf{f}$ and then back-substitute to find $\\mathbf{u} = \\mathbf{K}^{-1}(\\mathbf{f} - \\mathbf{B}^{\\top}\\boldsymbol{\\lambda})$. However, the final answer requested is solely the determinant of $\\mathbf{S}$.", "answer": "$$\\boxed{\\frac{33}{16}}$$", "id": "3377575"}, {"introduction": "Moving from direct to iterative approaches, this practice explores the multiplicative Schwarz method, a classic iterative domain decomposition technique. For the simple one-dimensional problem presented, this method is equivalent to the Gauss-Seidel iteration on the global system, providing a clear link between DDM and classical numerical linear algebra. This exercise will help you build intuition for how solutions can be constructed through a sequence of local solves and information exchange across interfaces [@problem_id:3377577].", "problem": "Consider the one-dimensional Poisson problem $-u''(x)=f(x)$ on the domain $\\Omega=[0,1]$ with Dirichlet boundary conditions $u(0)=0$ and $u(1)=0$. This forward model arises as the state equation in a linearized step of a parameter estimation problem constrained by partial differential equations, where solving the discretized state equation is a subtask within a Gauss–Newton iteration in data assimilation. Partition $\\Omega$ into two nonoverlapping subdomains $\\Omega_{1}=[0,0.5]$ and $\\Omega_{2}=[0.5,1]$, and enforce continuity at the interface $x=0.5$ through the multiplicative Schwarz iteration, which sequentially updates the subdomain solutions while passing interface data from the previous iterate to the next subproblem.\n\nDiscretize the domain using a uniform mesh with four nodes $x_{0}=0$, $x_{1}=\\frac{1}{3}$, $x_{2}=\\frac{2}{3}$, and $x_{3}=1$, and use the second-order central difference approximation for the second derivative. Treat the endpoints as Dirichlet nodes, so the unknowns are the interior nodal values $u_{1}\\approx u(x_{1})$ and $u_{2}\\approx u(x_{2})$. Assume a constant source $f(x)\\equiv 1$, and assemble the standard discrete operator based on the second-order difference formula for $-u''(x)$.\n\nStarting from the initial guess $u^{(0)}=(0,0)^{\\top}$, perform exactly one step of the multiplicative Schwarz iteration, updating first on $\\Omega_{1}$ and then on $\\Omega_{2}$, with the interface coupling realized by using the most recent available value of the neighbor unknown at each stage. Compute the resulting iterate $u^{(1)}$ and the residuals $r^{(0)}=f-Au^{(0)}$ and $r^{(1)}=f-Au^{(1)}$, where $A$ is the assembled discrete operator and $f$ is the discrete right-hand side vector. Quantify the residual reduction by the ratio $\\|r^{(1)}\\|_{2}/\\|r^{(0)}\\|_{2}$, using the Euclidean two-norm.\n\nExpress your final answer as a single exact real number or a single closed-form analytic expression. No units are required, and no rounding is necessary.", "solution": "### Step 1: Extract Givens\n- **Governing Equation**: One-dimensional Poisson problem $-u''(x) = f(x)$.\n- **Domain**: $\\Omega = [0, 1]$.\n- **Boundary Conditions**: Dirichlet conditions $u(0)=0$ and $u(1)=0$.\n- **Source Term**: $f(x) \\equiv 1$.\n- **Domain Decomposition**: Two non-overlapping subdomains $\\Omega_1 = [0, 0.5]$ and $\\Omega_2 = [0.5, 1]$.\n- **Discretization**: Uniform mesh with four nodes $x_0=0$, $x_1=\\frac{1}{3}$, $x_2=\\frac{2}{3}$, and $x_3=1$.\n- **Unknowns**: Interior nodal values $u_1 \\approx u(x_1)$ and $u_2 \\approx u(x_2)$.\n- **Numerical Method**: Second-order central difference approximation for the second derivative.\n- **Iteration Scheme**: One step of the multiplicative Schwarz iteration, updating first on $\\Omega_1$, then on $\\Omega_2$. Interface coupling uses the most recent available value.\n- **Initial Condition**: Initial guess for the solution is $\\mathbf{u}^{(0)} = (0, 0)^\\top$.\n- **Task**: Compute the iterate $\\mathbf{u}^{(1)}$ and residuals $\\mathbf{r}^{(0)} = \\mathbf{f} - A\\mathbf{u}^{(0)}$ and $\\mathbf{r}^{(1)} = \\mathbf{f} - A\\mathbf{u}^{(1)}$. Quantify the residual reduction via the ratio $\\|\\mathbf{r}^{(1)}\\|_2 / \\|\\mathbf{r}^{(0)}\\|_2$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is a standard exercise in numerical analysis, specifically the application of an iterative method (described as multiplicative Schwarz, which in this context simplifies to the Gauss-Seidel method) to a linear system arising from the finite difference discretization of a Poisson equation.\n- **Scientifically Grounded**: The problem is based on fundamental principles of numerical methods for partial differential equations. The Poisson equation, finite differences, and iterative solvers like Schwarz/Gauss-Seidel are well-established concepts. No scientific or factual unsoundness is present.\n- **Well-Posed**: The problem is well-posed. The discretization of the Poisson equation with Dirichlet boundary conditions yields a symmetric positive-definite matrix, guaranteeing a unique solution. The Gauss-Seidel method is convergent for such systems.\n- **Objective**: The problem is stated using precise, objective mathematical language.\n- **Completeness and Consistency**: All necessary data (domain, boundary conditions, source term, discretization, initial guess, and iterative procedure) are provided and are self-consistent.\n- **Feasibility and Realism**: The described setup is a simplified but realistic representation of a computational task in scientific computing. The values and conditions are standard.\n\n### Step 3: Verdict and Action\nThe problem is valid. A detailed solution will be provided.\n\n### Solution\n\nThe one-dimensional Poisson problem is given by:\n$$ -u''(x) = f(x) \\quad \\text{for } x \\in (0,1) $$\nwith boundary conditions $u(0) = 0$ and $u(1) = 0$. The source term is $f(x) = 1$.\n\nThe domain is discretized with nodes $x_0=0$, $x_1=\\frac{1}{3}$, $x_2=\\frac{2}{3}$, and $x_3=1$. The uniform step size is $h = x_{i+1} - x_i = \\frac{1}{3}$. The unknowns are the values at the interior nodes, $\\mathbf{u} = (u_1, u_2)^\\top$, where $u_1 \\approx u(x_1)$ and $u_2 \\approx u(x_2)$. The boundary values are $u_0 = u(x_0) = 0$ and $u_3 = u(x_3) = 0$.\n\nThe second derivative $-u''(x)$ is approximated using a second-order central difference formula at a node $x_i$:\n$$ -u''(x_i) \\approx \\frac{-u(x_{i-1}) + 2u(x_i) - u(x_{i+1})}{h^2} $$\nApplying this approximation at the interior nodes $x_1$ and $x_2$:\nAt $x_1 = \\frac{1}{3}$:\n$$ \\frac{-u_0 + 2u_1 - u_2}{h^2} = f(x_1) = 1 $$\nSince $u_0 = 0$ and $h^2 = (\\frac{1}{3})^2 = \\frac{1}{9}$, this equation becomes:\n$$ \\frac{2u_1 - u_2}{1/9} = 1 \\implies 18u_1 - 9u_2 = 1 $$\nAt $x_2 = \\frac{2}{3}$:\n$$ \\frac{-u_1 + 2u_2 - u_3}{h^2} = f(x_2) = 1 $$\nSince $u_3 = 0$, this equation becomes:\n$$ \\frac{-u_1 + 2u_2}{1/9} = 1 \\implies -9u_1 + 18u_2 = 1 $$\nThese two linear equations form a system $A\\mathbf{u} = \\mathbf{f}$:\n$$ \\begin{pmatrix} 18  -9 \\\\ -9  18 \\end{pmatrix} \\begin{pmatrix} u_1 \\\\ u_2 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} $$\nHere, the discrete operator is $A = \\begin{pmatrix} 18  -9 \\\\ -9  18 \\end{pmatrix}$ and the discrete right-hand side is $\\mathbf{f} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$.\n\nThe multiplicative Schwarz iteration updates sequentially on subdomains. The first subdomain $\\Omega_1 = [0, 0.5]$ contains the node $x_1$. The second subdomain $\\Omega_2 = [0.5, 1]$ contains the node $x_2$. The update rule is described as using the most recent available values. This procedure on this non-overlapping decomposition is equivalent to the Gauss-Seidel iteration on the system $A\\mathbf{u}=\\mathbf{f}$.\n\nThe Gauss-Seidel iteration proceeds as follows, given an iterate $\\mathbf{u}^{(k)} = (u_1^{(k)}, u_2^{(k)})^\\top$:\n1. Update $u_1$ using the first equation and the old value $u_2^{(k)}$:\n$$ 18u_1^{(k+1)} - 9u_2^{(k)} = 1 \\implies u_1^{(k+1)} = \\frac{1 + 9u_2^{(k)}}{18} $$\n2. Update $u_2$ using the second equation and the newly computed value $u_1^{(k+1)}$:\n$$ -9u_1^{(k+1)} + 18u_2^{(k+1)} = 1 \\implies u_2^{(k+1)} = \\frac{1 + 9u_1^{(k+1)}}{18} $$\n\nWe perform one step of this iteration starting from the initial guess $\\mathbf{u}^{(0)} = (0, 0)^\\top$. So, $u_1^{(0)} = 0$ and $u_2^{(0)} = 0$.\n\nFor $k=0$:\n1. Compute $u_1^{(1)}$:\n$$ u_1^{(1)} = \\frac{1 + 9u_2^{(0)}}{18} = \\frac{1 + 9(0)}{18} = \\frac{1}{18} $$\n2. Compute $u_2^{(1)}$:\n$$ u_2^{(1)} = \\frac{1 + 9u_1^{(1)}}{18} = \\frac{1 + 9(\\frac{1}{18})}{18} = \\frac{1 + \\frac{1}{2}}{18} = \\frac{\\frac{3}{2}}{18} = \\frac{3}{36} = \\frac{1}{12} $$\nThe iterate after one step is $\\mathbf{u}^{(1)} = ( \\frac{1}{18}, \\frac{1}{12} )^\\top$.\n\nNext, we calculate the residuals $\\mathbf{r}^{(0)}$ and $\\mathbf{r}^{(1)}$, where the residual is defined as $\\mathbf{r} = \\mathbf{f} - A\\mathbf{u}$.\n\nThe initial residual $\\mathbf{r}^{(0)}$ is:\n$$ \\mathbf{r}^{(0)} = \\mathbf{f} - A\\mathbf{u}^{(0)} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} - \\begin{pmatrix} 18  -9 \\\\ -9  18 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} $$\nThe Euclidean norm of the initial residual is:\n$$ \\|\\mathbf{r}^{(0)}\\|_2 = \\sqrt{1^2 + 1^2} = \\sqrt{2} $$\n\nThe residual after one iteration, $\\mathbf{r}^{(1)}$, is:\n$$ \\mathbf{r}^{(1)} = \\mathbf{f} - A\\mathbf{u}^{(1)} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} - \\begin{pmatrix} 18  -9 \\\\ -9  18 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{18} \\\\ \\frac{1}{12} \\end{pmatrix} $$\nFirst, compute the product $A\\mathbf{u}^{(1)}$:\n$$ A\\mathbf{u}^{(1)} = \\begin{pmatrix} 18(\\frac{1}{18}) - 9(\\frac{1}{12}) \\\\ -9(\\frac{1}{18}) + 18(\\frac{1}{12}) \\end{pmatrix} = \\begin{pmatrix} 1 - \\frac{9}{12} \\\\ -\\frac{9}{18} + \\frac{18}{12} \\end{pmatrix} = \\begin{pmatrix} 1 - \\frac{3}{4} \\\\ -\\frac{1}{2} + \\frac{3}{2} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{4} \\\\ 1 \\end{pmatrix} $$\nNow, compute $\\mathbf{r}^{(1)}$:\n$$ \\mathbf{r}^{(1)} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} - \\begin{pmatrix} \\frac{1}{4} \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} \\frac{3}{4} \\\\ 0 \\end{pmatrix} $$\nThe Euclidean norm of this residual is:\n$$ \\|\\mathbf{r}^{(1)}\\|_2 = \\sqrt{ \\left(\\frac{3}{4}\\right)^2 + 0^2 } = \\sqrt{\\frac{9}{16}} = \\frac{3}{4} $$\n\nFinally, we compute the ratio of the residual norms to quantify the reduction:\n$$ \\frac{\\|\\mathbf{r}^{(1)}\\|_2}{\\|\\mathbf{r}^{(0)}\\|_2} = \\frac{\\frac{3}{4}}{\\sqrt{2}} = \\frac{3}{4\\sqrt{2}} $$\nTo rationalize the denominator, we multiply the numerator and denominator by $\\sqrt{2}$:\n$$ \\frac{3\\sqrt{2}}{4\\sqrt{2}\\sqrt{2}} = \\frac{3\\sqrt{2}}{4(2)} = \\frac{3\\sqrt{2}}{8} $$\nThis is the required residual reduction ratio.", "answer": "$$\\boxed{\\frac{3\\sqrt{2}}{8}}$$", "id": "3377577"}, {"introduction": "This final practice synthesizes the concepts of domain decomposition and inverse problems in a realistic, computational setting. You will implement a substructuring solver and embed it within a Gauss–Newton framework to tackle a nonlinear parameter estimation problem. This capstone exercise demonstrates how domain decomposition methods serve as powerful linear solvers for the large-scale systems that arise at each step of an iterative optimization algorithm [@problem_id:3377614].", "problem": "Consider the one-dimensional nonlinear diffusion boundary value problem\n$$ -\\frac{d}{dx}\\big(\\kappa(m(x)) \\frac{du(x)}{dx}\\big) = f(x), \\quad x \\in (0,1), \\quad u(0)=0,\\;u(1)=0, $$\nwhere the diffusion is nonlinear in a scalar parameter field via $\\kappa(m)=\\exp(m)$. The domain $(0,1)$ is decomposed into two non-overlapping subdomains $\\Omega_1=(0,0.5]$ and $\\Omega_2=[0.5,1)$ with continuity of state and flux at the interface. The parameter field is restricted to be piecewise constant across the decomposition, $m(x)=m_1$ on $\\Omega_1$ and $m(x)=m_2$ on $\\Omega_2$, so that $\\kappa(x)=\\exp(m_1)$ on $\\Omega_1$ and $\\kappa(x)=\\exp(m_2)$ on $\\Omega_2$.\n\nDiscretize the interval $[0,1]$ using a uniform grid with $N=33$ nodes at points $x_i = i h$, where $h = 1/(N-1)$ and $i \\in \\{0,1,\\dots,N-1\\}$. Let the interface be at node index $i_{\\mathrm{I}} = 16$ (i.e., $x_{i_{\\mathrm{I}}}=0.5$). Approximate the diffusion operator using the standard second-order conservative finite-difference stencil with variable coefficients, where edge-centered coefficients $\\kappa_{i+\\frac{1}{2}}$ are constant on each subdomain and taken to be $\\exp(m_1)$ for edges $i+\\frac{1}{2} \\in \\{0.5,1.5,\\dots,15.5\\}$ and $\\exp(m_2)$ for edges $i+\\frac{1}{2} \\in \\{16.5,17.5,\\dots,31.5\\}$. Use source term values $f_i = 1$ at all interior nodes $i \\in \\{1,2,\\dots,N-2\\}$ and $f_0=f_{N-1}=0$. Impose Dirichlet boundary conditions at $x_0=0$ and $x_{N-1}=1$. Enforce continuity of the discrete solution at the interface and the discrete balance of outward fluxes across the interface node using a Schur-complement or substructuring argument that couples the two subdomain solves through the interface unknown.\n\nDefine the observation operator that samples the discrete state at node indices $\\{6,12,20,26\\}$, corresponding to spatial locations $\\{x_6,x_{12},x_{20},x_{26}\\} = \\{6h,12h,20h,26h\\}$. Generate synthetic data by solving the forward problem with the ground-truth parameters $m_{\\mathrm{true}} = [0.2,-0.1]$ to obtain the discrete solution $u^{\\mathrm{true}}$, extracting its observed components $y^{\\mathrm{true}} \\in \\mathbb{R}^4$, and adding a fixed noise vector $\\eta = [10^{-4},-2\\cdot 10^{-4},1.5\\cdot 10^{-4},-10^{-4}]$ (in the same units as $u$) to obtain data $d = y^{\\mathrm{true}} + \\eta$.\n\nFor a given initial guess $m^{(0)}=[m^{(0)}_1,m^{(0)}_2]$, perform one Gauss–Newton step for the Tikhonov-regularized least-squares problem with zero-order regularization and identity data covariance,\n$$ \\min_{m \\in \\mathbb{R}^2} \\; \\frac{1}{2}\\|F(m)-d\\|_2^2 + \\frac{\\gamma}{2}\\|m - m_{\\mathrm{ref}}\\|_2^2, $$\nwhere $F(m)$ maps the parameter pair $m$ to the $4$ observations, $m_{\\mathrm{ref}}=[0,0]$, and $\\gamma0$ is the regularization parameter. Use the Gauss–Newton linearization of the data misfit at $m^{(0)}$ and compute the parameter increment by solving the $2\\times 2$ linear system that arises from the normal equations with the Gauss–Newton approximation to the Hessian. The Jacobian action must be obtained via sensitivity equations derived from the linearization of the discrete forward model, and all forward and sensitivity linear systems must be solved using the two-subdomain decomposition with coupling at the interface as described above. After computing the updated parameter $m^{(1)}=m^{(0)}+\\delta m$, report the change in the data misfit,\n$$ \\Delta \\Phi = \\frac{1}{2}\\|F(m^{(0)})-d\\|_2^2 - \\frac{1}{2}\\|F(m^{(1)})-d\\|_2^2. $$\n\nYour program must implement the above and run the following test suite of three cases, each specified by an initial guess and a regularization parameter:\n- Case A (happy path): $m^{(0)} = [0.0,0.0]$, $\\gamma = 10^{-2}$.\n- Case B (high-contrast initial guess): $m^{(0)} = [-1.0,1.0]$, $\\gamma = 10^{-2}$.\n- Case C (strong regularization): $m^{(0)} = [0.0,0.0]$, $\\gamma = 1.0$.\n\nAll computations are nondimensional; no physical units are required. Angles are not involved. Percentages are not involved.\n\nYour program should produce a single line of output containing the three misfit decreases for Cases A, B, and C, respectively, as a comma-separated list enclosed in square brackets, with each number printed as a decimal float rounded to six digits after the decimal point (e.g., $[0.123456,0.000001,0.987654]$).", "solution": "The problem requires performing one Gauss-Newton optimization step for a parameter estimation problem governed by a one-dimensional nonlinear diffusion equation. The solution process involves several stages: numerical discretization of the PDE, implementation of a domain decomposition solver, generation of synthetic data, derivation and solution of sensitivity equations for the Jacobian, and finally, the assembly and solution of the Gauss-Newton system.\n\nFirst, we define the discretized forward problem. The governing equation is\n$$ -\\frac{d}{dx}\\left(\\kappa(m(x)) \\frac{du(x)}{dx}\\right) = f(x), \\quad x \\in (0,1) $$\nwith boundary conditions $u(0)=0$ and $u(1)=0$. The domain is discretized with $N=33$ nodes $x_i = i h$ for $i \\in \\{0, 1, \\dots, N-1\\}$, where $h=1/(N-1) = 1/32$. The parameter field is piecewise constant: $m(x)=m_1$ on $\\Omega_1=(0, 0.5]$ and $m(x)=m_2$ on $\\Omega_2=[0.5, 1)$, so the diffusion coefficient is $\\kappa(x)=\\kappa_1=\\exp(m_1)$ on $\\Omega_1$ and $\\kappa(x)=\\kappa_2=\\exp(m_2)$ on $\\Omega_2$.\n\nUsing a conservative finite-difference scheme on the interior nodes $i \\in \\{1, 2, \\dots, N-2\\}$, we obtain the discrete equation:\n$$ -\\frac{1}{h}\\left( \\kappa_{i+\\frac{1}{2}} \\frac{u_{i+1}-u_i}{h} - \\kappa_{i-\\frac{1}{2}} \\frac{u_i-u_{i-1}}{h} \\right) = f_i $$\nThis forms a system of linear equations $A(m)u_{int} = f_{int}$ for the vector of $N-2=31$ interior unknowns $u_{int} = [u_1, u_2, \\dots, u_{31}]^T$. The source term is $f_i=1$ for all interior nodes. The boundary conditions $u_0=0$ and $u_{32}=0$ are incorporated.\n\nThe problem specifies a domain decomposition approach based on substructuring. The interior nodes are partitioned into three sets: unknowns in $\\Omega_1$ ($u_{\\Omega_1} = [u_1, \\dots, u_{15}]^T$), the unknown at the interface $i_I=16$ ($u_I = u_{16}$), and unknowns in $\\Omega_2$ ($u_{\\Omega_2} = [u_{17}, \\dots, u_{31}]^T$). The system is reordered as:\n$$\n\\begin{pmatrix}\nA_{11}  0  A_{1I} \\\\\n0  A_{22}  A_{2I} \\\\\nA_{I1}  A_{I2}  A_{II}\n\\end{pmatrix}\n\\begin{pmatrix}\nu_{\\Omega_1} \\\\\nu_{\\Omega_2} \\\\\nu_I\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nf_{\\Omega_1} \\\\\nf_{\\Omega_2} \\\\\nf_I\n\\end{pmatrix}\n$$\nThe diagonal blocks $A_{11}$ and $A_{22}$ are $15 \\times 15$ symmetric tridiagonal matrices representing the discrete Laplacian on each subdomain with Dirichlet conditions at the exterior boundary and the interface:\n$$ A_{11} = \\frac{\\kappa_1}{h^2} \\text{tridiag}(-1, 2, -1), \\quad A_{22} = \\frac{\\kappa_2}{h^2} \\text{tridiag}(-1, 2, -1) $$\nThe coupling blocks arise from the finite-difference equation at the interface node $i_I=16$:\n$$ \\frac{1}{h^2} (-\\kappa_1 u_{15} + (\\kappa_1 + \\kappa_2) u_{16} - \\kappa_2 u_{17}) = f_{16} $$\nThis defines $A_{II} = (\\kappa_1+\\kappa_2)/h^2$ and the off-diagonal coupling vectors.\n\nThis block system is solved using a Schur complement reduction. The interface unknown $u_I$ is found by solving the Schur complement system:\n$$ S u_I = f_I - A_{I1} A_{11}^{-1} f_{\\Omega_1} - A_{I2} A_{22}^{-1} f_{\\Omega_2} $$\nwhere the Schur complement $S$ is a scalar given by $S = A_{II} - A_{I1} A_{11}^{-1} A_{1I} - A_{I2} A_{22}^{-1} A_{2I}$. The required matrix-vector products involving the inverse of $A_{11}$ and $A_{22}$ are computed by solving linear systems on each subdomain. Once $u_I$ is known, the subdomain solutions are found by back-substitution:\n$$ u_{\\Omega_1} = A_{11}^{-1} (f_{\\Omega_1} - A_{1I} u_I), \\quad u_{\\Omega_2} = A_{22}^{-1} (f_{\\Omega_2} - A_{2I} u_I) $$\nThis procedure defines the forward operator $F(m)$, which maps the parameter vector $m=[m_1, m_2]^T$ to the vector of $4$ observations at nodes $\\{6, 12, 20, 26\\}$.\n\nSynthetic data $d$ are generated by computing $d = F(m_{\\mathrm{true}}) + \\eta$, with $m_{\\mathrm{true}}=[0.2,-0.1]$ and $\\eta = [10^{-4}, -2 \\cdot 10^{-4}, 1.5 \\cdot 10^{-4}, -10^{-4}]$. The inverse problem is to find $m$ that minimizes the Tikhonov-regularized cost function:\n$$ \\min_{m \\in \\mathbb{R}^2} \\; \\mathcal{J}(m) = \\frac{1}{2}\\|F(m)-d\\|_2^2 + \\frac{\\gamma}{2}\\|m - m_{\\mathrm{ref}}\\|_2^2 $$\nwith $m_{\\mathrm{ref}}=[0,0]$. We perform one Gauss-Newton step starting from an initial guess $m^{(0)}$. The parameter update $\\delta m$ is found by solving the $2 \\times 2$ linear system originating from the normal equations:\n$$ (J^T J + \\gamma I) \\delta m = J^T(d - F(m^{(0)})) - \\gamma(m^{(0)} - m_{\\mathrm{ref}}) $$\nwhere $J$ is the Jacobian matrix of $F$ evaluated at $m^{(0)}$, and $I$ is the $2 \\times 2$ identity matrix.\n\nThe columns of the Jacobian, $J_j = \\partial F / \\partial m_j$ for $j \\in \\{1,2\\}$, are computed using sensitivity analysis. Differentiating the forward system $A(m)u_{int}(m) = f_{int}$ with respect to $m_j$ yields a linear system for the sensitivity vector $s_j = \\partial u_{int} / \\partial m_j$:\n$$ A(m) s_j = -\\frac{\\partial A(m)}{\\partial m_j} u_{int}(m) =: g_j $$\nThis system for $s_j$ involves the same matrix $A(m)$ as the forward problem and is solved efficiently using the same Schur complement method. The right-hand side vector $g_j$ is assembled from the derivative of the discrete operator. For $j=1$, the non-zero components of $g_1$ correspond to equations for nodes $i \\in \\{1, \\dots, 16\\}$, and for $j=2$, they correspond to nodes $i \\in \\{16, \\dots, 31\\}$. Specifically, using the fact that $(A u)_i = f_i$, the components of the sensitivity right-hand-sides at $m^{(0)}$ are:\n$$\n(g_1)_i = \\begin{cases} -f_i = -1  \\text{if } i \\in \\{1, \\dots, 15\\} \\\\ -\\frac{\\kappa_1}{h^2}(-u_{15}+u_{16})  \\text{if } i=16 \\\\ 0  \\text{otherwise} \\end{cases}\n$$\n$$\n(g_2)_i = \\begin{cases} -\\frac{\\kappa_2}{h^2}(u_{16}-u_{17})  \\text{if } i=16 \\\\ -f_i = -1  \\text{if } i \\in \\{17, \\dots, 31\\} \\\\ 0  \\text{otherwise} \\end{cases}\n$$\nAfter solving for $s_1$ and $s_2$, the Jacobian columns are obtained by applying the observation operator: $J_j = s_j|_{\\text{obs_indices}}$.\n\nThe algorithmic procedure for each test case is as follows:\n1.  Given $m^{(0)}$ and $\\gamma$, solve the forward problem for $u^{(0)}=u(m^{(0)})$ to find the predicted data $F(m^{(0)})$ and the initial data misfit $\\Phi_0 = \\frac{1}{2}\\|F(m^{(0)})-d\\|_2^2$.\n2.  Compute the sensitivity right-hand-sides $g_1$ and $g_2$ using $u^{(0)}$ and $m^{(0)}$.\n3.  Solve the sensitivity systems $A(m^{(0)})s_j=g_j$ for $s_1$ and $s_2$.\n4.  Form the $4 \\times 2$ Jacobian matrix $J$ from the observed components of $s_1$ and $s_2$.\n5.  Assemble and solve the $2 \\times 2$ Gauss-Newton system for the parameter update $\\delta m$.\n6.  Compute the updated parameter $m^{(1)} = m^{(0)} + \\delta m$.\n7.  Solve the forward problem for $u^{(1)}=u(m^{(1)})$ to find the new predicted data $F(m^{(1)})$ and the final data misfit $\\Phi_1 = \\frac{1}{2}\\|F(m^{(1)})-d\\|_2^2$.\n8.  The final result is the change in data misfit, $\\Delta \\Phi = \\Phi_0 - \\Phi_1$.\nThis procedure is repeated for each of the three test cases specified.", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import solve_banded\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the entire process for the given test cases.\n    \"\"\"\n    N = 33\n    h = 1.0 / (N - 1)\n    i_I = 16  # Interface node index\n\n    # Observation nodes (1-based index)\n    obs_nodes = np.array([6, 12, 20, 26])\n    # Corresponding 0-based index in the interior solution vector u_int[0...30]\n    obs_indices_in_u_int = obs_nodes - 1\n\n    # Ground truth and data generation\n    m_true = np.array([0.2, -0.1])\n    eta = np.array([1e-4, -2e-4, 1.5e-4, -1e-4])\n    m_ref = np.array([0.0, 0.0])\n\n    u_true_int, _ = solve_forward(m_true, N, h, i_I)\n    y_true = u_true_int[obs_indices_in_u_int]\n    d = y_true + eta\n    \n    # Test cases\n    test_cases = [\n        # Case A\n        {'m0': np.array([0.0, 0.0]), 'gamma': 1e-2},\n        # Case B\n        {'m0': np.array([-1.0, 1.0]), 'gamma': 1e-2},\n        # Case C\n        {'m0': np.array([0.0, 0.0]), 'gamma': 1.0},\n    ]\n\n    results = []\n    for case in test_cases:\n        m0 = case['m0']\n        gamma = case['gamma']\n\n        # 1. Evaluate forward model and Jacobian at m0\n        u0_int, F_m0 = solve_forward(m0, N, h, i_I, obs_indices_in_u_int)\n        \n        g1_rhs = compute_sensitivity_rhs(m0, u0_int, 1, h, N, i_I)\n        g2_rhs = compute_sensitivity_rhs(m0, u0_int, 2, h, N, i_I)\n        \n        s1_int, J_col1 = solve_forward(m0, N, h, i_I, obs_indices_in_u_int, rhs=g1_rhs)\n        s2_int, J_col2 = solve_forward(m0, N, h, i_I, obs_indices_in_u_int, rhs=g2_rhs)\n        \n        J = np.vstack((J_col1, J_col2)).T\n\n        # 2. Compute misfit and Gauss-Newton step\n        residual = d - F_m0\n        phi0 = 0.5 * np.dot(residual, residual)\n\n        H_GN = J.T @ J + gamma * np.eye(2)\n        rhs_GN = J.T @ residual - gamma * (m0 - m_ref)\n        \n        delta_m = np.linalg.solve(H_GN, rhs_GN)\n        m1 = m0 + delta_m\n\n        # 3. Evaluate forward model at m1 and compute final misfit\n        _, F_m1 = solve_forward(m1, N, h, i_I, obs_indices_in_u_int)\n        phi1 = 0.5 * np.dot(d - F_m1, d - F_m1)\n\n        delta_phi = phi0 - phi1\n        results.append(delta_phi)\n\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\n\ndef solve_schur_system(k1, k2, h, i_I, rhs_int):\n    \"\"\"\n    Solves a linear system using the Schur complement (substructuring) method.\n    `rhs_int` is the right-hand side for the interior nodes [1, ..., N-2].\n    \"\"\"\n    num_sub_nodes = i_I - 1  # 15 nodes in each subdomain interior\n\n    # Partition the RHS\n    rhs1 = rhs_int[:num_sub_nodes]\n    rhs_I = rhs_int[num_sub_nodes]\n    rhs2 = rhs_int[num_sub_nodes+1:]\n\n    # Build subdomain matrices A11 and A22 (banded format for solve_banded)\n    # A = diag(d) + diag(e, 1) + diag(e, -1) has banded form:\n    # [e, d, e] -> ab = [[0, *e], [d], [*e, 0]]\n    A11_banded = np.zeros((3, num_sub_nodes))\n    A11_banded[0, 1:] = -1.0\n    A11_banded[1, :] = 2.0\n    A11_banded[2, :-1] = -1.0\n    A11_banded *= k1 / h**2\n\n    A22_banded = np.zeros((3, num_sub_nodes))\n    A22_banded[0, 1:] = -1.0\n    A22_banded[1, :] = 2.0\n    A22_banded[2, :-1] = -1.0\n    A22_banded *= k2 / h**2\n\n    # Coupling vectors\n    A1I = np.zeros(num_sub_nodes); A1I[-1] = -k1 / h**2\n    A2I = np.zeros(num_sub_nodes); A2I[0] = -k2 / h**2\n    AI1 = A1I\n    AI2 = A2I\n\n    # Interface 'matrix'\n    AII = (k1 + k2) / h**2\n\n    # Solve for constituents of Schur complement system\n    # v1 = A11^{-1} f1\n    v1 = solve_banded((1, 1), A11_banded, rhs1)\n    # v2 = A22^{-1} f2\n    v2 = solve_banded((1, 1), A22_banded, rhs2)\n    # w1 = A11^{-1} A1I\n    w1 = solve_banded((1, 1), A11_banded, A1I)\n    # w2 = A22^{-1} A2I\n    w2 = solve_banded((1, 1), A22_banded, A2I)\n    \n    # Schur complement and its RHS (both are scalars)\n    S = AII - np.dot(AI1, w1) - np.dot(AI2, w2)\n    rhs_S = rhs_I - np.dot(AI1, v1) - np.dot(AI2, v2)\n    \n    # Solve for interface unknown\n    u_I = rhs_S / S\n    \n    # Back-substitute for subdomain unknowns\n    u1 = v1 - w1 * u_I\n    u2 = v2 - w2 * u_I\n    \n    # Assemble full interior solution\n    u_int = np.concatenate((u1, [u_I], u2))\n    return u_int\n\n\ndef solve_forward(m, N, h, i_I, obs_indices_in_u_int=None, rhs=None):\n    \"\"\"\n    Solves the forward or sensitivity problem. If rhs is None, solves the\n    forward problem with source f=1. Otherwise, solves with the given rhs.\n    Returns the full interior solution and optionally the observed values.\n    \"\"\"\n    k1, k2 = np.exp(m[0]), np.exp(m[1])\n    num_int_nodes = N - 2\n\n    if rhs is None:\n        # Standard forward problem RHS (f_i = 1 for all interior nodes)\n        rhs = np.ones(num_int_nodes)\n        \n    u_int = solve_schur_system(k1, k2, h, i_I, rhs)\n\n    if obs_indices_in_u_int is not None:\n        return u_int, u_int[obs_indices_in_u_int]\n    return u_int, None\n\n\ndef compute_sensitivity_rhs(m, u_int, param_idx, h, N, i_I):\n    \"\"\"\n    Computes the right-hand side vector g_j for the sensitivity equation.\n    param_idx is 1 for m1, 2 for m2.\n    \"\"\"\n    k1, k2 = np.exp(m[0]), np.exp(m[1])\n    num_int_nodes = N - 2\n    num_sub_nodes = i_I - 1\n\n    g = np.zeros(num_int_nodes)\n    \n    u_full = np.concatenate(([0], u_int, [0]))\n    u_15 = u_full[i_I - 1]\n    u_16 = u_full[i_I]\n    u_17 = u_full[i_I + 1]\n\n    if param_idx == 1:\n        g[:num_sub_nodes] = -1.0 # correspoding to nodes 1...15\n        g[num_sub_nodes] = -(k1 / h**2) * (-u_15 + u_16)\n    elif param_idx == 2:\n        g[num_sub_nodes] = -(k2 / h**2) * (u_16 - u_17)\n        g[num_sub_nodes+1:] = -1.0 # correspoding to nodes 17...31\n    \n    return g\n\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3377614"}]}