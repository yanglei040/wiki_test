{"hands_on_practices": [{"introduction": "A robust implementation of the projected gradient method begins with the proper selection of the step size, which guarantees convergence. This fundamental parameter is directly tied to the Lipschitz constant of the objective function's gradient, a quantity that is often expensive to compute exactly. This first practice [@problem_id:3414873] will guide you through the essential skill of deriving and implementing computable bounds for the Lipschitz constant, using them to build a provably convergent solver for a constrained inverse problem.", "problem": "Consider the convex quadratic program that arises in linear inverse problems and data assimilation: minimize the Tikhonov-regularized least-squares objective over a box constraint,\n$$\n\\min_{x \\in \\mathbb{R}^n} \\; J(x) = \\frac{1}{2}\\,\\|A x - b\\|_2^2 + \\frac{\\gamma}{2}\\,\\|x\\|_2^2 \\quad \\text{subject to} \\quad \\ell \\le x \\le u,\n$$\nwhere $A \\in \\mathbb{R}^{m \\times n}$, $b \\in \\mathbb{R}^m$, $\\gamma \\ge 0$, and the inequalities are componentwise with $\\ell, u \\in \\mathbb{R}^n$ and $\\ell_i \\le u_i$ for all $i$. The gradient of $J$ is Lipschitz continuous with constant $L = \\|Q\\|_2$, where $Q = A^\\top A + \\gamma I_n$ and $\\|\\cdot\\|_2$ denotes the spectral norm. The projected gradient method iterates\n$$\nx^{k+1} = \\Pi_{[\\ell,u]}\\Big(x^k - \\alpha \\,\\nabla J(x^k)\\Big),\n$$\nwhere $\\Pi_{[\\ell,u]}$ is the Euclidean projection onto the box $[\\ell,u]$ and $\\alpha > 0$ is the step size. A standard global convergence guarantee for projected gradient on convex objectives requires choosing $\\alpha \\in (0, 2/L)$, and a monotone descent choice is $\\alpha \\in (0, 1/L]$.\n\nTasks:\n- Starting from the definitions of the spectral norm and submultiplicative matrix norms, derive a computable upper bound $\\overline{L}$ on $L = \\|Q\\|_2$ that does not require computing the eigenvalues of $Q$. Your derivation must use only foundational properties of norms and linear operators and must not assume formulas beyond those properties. You may assume access to a routine that computes matrix-vector products with $Q$ but not necessarily direct access to the entries of $Q$ itself.\n- Using the Power Iteration method on $Q$, derive a computable numerical lower bound $\\underline{L}$ on $L$ that converges to $L$ as the iteration count grows. Your derivation must begin from the variational characterization of the spectral norm for symmetric positive semidefinite matrices and the definition of the Rayleigh quotient, and must not assume any specific convergence rate a priori.\n- Explain, based on the above, how to choose a rigorously safe step size $\\alpha$ for the projected gradient method using a provable upper bound $\\overline{L}$, and how to use $\\underline{L}$ from power iteration to assess the conservativeness of $\\overline{L}$ during algorithm design.\n\nThen, implement a program that:\n- Computes a rigorous upper bound $\\overline{L}$ and a numerical lower bound $\\underline{L}$ for each test case using only the permissible operations (matrix-vector products and basic matrix norms).\n- Runs the projected gradient method with $\\alpha = 1/\\overline{L}$ until convergence, using the stopping criterion $\\|x^{k+1} - x^k\\|_2 \\le \\varepsilon$ or a maximum number of iterations $K_{\\max}$, whichever occurs first.\n- Reports, for each test case, three floats: the lower bound $\\underline{L}$, the upper bound $\\overline{L}$, and the final objective value $J(x^{\\star})$ at the returned point $x^{\\star}$.\n\nFundamental base you must use:\n- The variational characterization for symmetric positive semidefinite $Q$: $L = \\|Q\\|_2 = \\max_{\\|v\\|_2=1} v^\\top Q v$.\n- The Rayleigh quotient $R_Q(v) = \\frac{v^\\top Q v}{v^\\top v}$ for $v \\ne 0$.\n- Submultiplicativity and norm dominance for consistent matrix norms, including $\\|M\\|_2 \\le \\sqrt{\\|M\\|_1 \\|M\\|_\\infty}$ and $\\|X+Y\\| \\le \\|X\\| + \\|Y\\|$ for any consistent matrix norm $\\|\\cdot\\|$.\n- Nonexpansiveness of the Euclidean projection onto a closed convex set and basic properties of projected gradient descent on convex objectives.\n\nTest suite:\n- Case $1$: \n  - $A = \\begin{bmatrix} 3 & 1 & 0 \\\\ 1 & 4 & 1 \\\\ 0 & 1 & 2 \\end{bmatrix}$, $b = \\begin{bmatrix} 1 \\\\ 0 \\\\ -1 \\end{bmatrix}$, $\\gamma = 0.2$.\n  - $\\ell = \\begin{bmatrix} -0.5 \\\\ -0.5 \\\\ -0.5 \\end{bmatrix}$, $u = \\begin{bmatrix} 2 \\\\ 2 \\\\ 2 \\end{bmatrix}$, $x^0 = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$.\n- Case $2$:\n  - $A = \\begin{bmatrix} 1 & 2 & 3 \\\\ 2 & 4 & 6 \\end{bmatrix}$, $b = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$, $\\gamma = 0$.\n  - $\\ell = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$, $u = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix}$, $x^0 = \\begin{bmatrix} 0.3 \\\\ 0.3 \\\\ 0.3 \\end{bmatrix}$.\n- Case $3$:\n  - $A = \\begin{bmatrix} 2 & 0 & -1 \\\\ 0 & 1 & 1 \\\\ 1 & -1 & 0 \\\\ 0 & 2 & 3 \\end{bmatrix}$, $b = \\begin{bmatrix} 1 \\\\ -1 \\\\ 0 \\\\ 2 \\end{bmatrix}$, $\\gamma = 3.0$.\n  - $\\ell = \\begin{bmatrix} -0.1 \\\\ -0.1 \\\\ -0.1 \\end{bmatrix}$, $u = \\begin{bmatrix} 0.1 \\\\ 0.1 \\\\ 0.1 \\end{bmatrix}$, $x^0 = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$.\n\nAlgorithmic parameters to use in all cases:\n- Power iteration maximum iterations $K_{\\mathrm{pow}} = 200$ and tolerance $\\varepsilon_{\\mathrm{pow}} = 10^{-10}$.\n- Projected gradient maximum iterations $K_{\\max} = 20000$ and tolerance $\\varepsilon = 10^{-9}$.\n- For the upper bound, use only provably valid inequalities. For example, you may use $\\|Q\\|_2 \\le \\sqrt{\\|Q\\|_1 \\|Q\\|_\\infty}$ and also the structure $Q = A^\\top A + \\gamma I_n$ to infer $\\|Q\\|_2 \\le \\|A\\|_2^2 + \\gamma \\le \\|A\\|_1 \\|A\\|_\\infty + \\gamma$. You must select a rigorous $\\overline{L}$ and may take the minimum of multiple rigorous upper bounds to reduce conservativeness.\n\nProgramming and output requirements:\n- Your program must compute, for each test case, the numerical lower bound $\\underline{L}$ obtained as the final Rayleigh quotient from power iteration on $Q$, the rigorous upper bound $\\overline{L}$ selected as described, and the final objective $J(x^\\star)$ after running projected gradient with step size $\\alpha = 1/\\overline{L}$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain, in order, for Case $1$, Case $2$, and Case $3$, the triplets $\\left(\\underline{L}, \\overline{L}, J(x^\\star)\\right)$ flattened into a single list. Each float must be rounded to $6$ decimal places. For example, the output format must be exactly \n$[\\underline{L}_1,\\overline{L}_1,J_1,\\underline{L}_2,\\overline{L}_2,J_2,\\underline{L}_3,\\overline{L}_3,J_3]$.", "solution": "The problem is well-posed and scientifically grounded. It presents a standard convex optimization problem arising in inverse problems and data assimilation, namely, the minimization of a Tikhonov-regularized least-squares functional subject to box constraints. All data, parameters, and objectives are clearly defined, constituting a valid problem in numerical optimization and scientific computing. We proceed with the solution.\n\nThe objective function to minimize is\n$$\nJ(x) = \\frac{1}{2}\\,\\|A x - b\\|_2^2 + \\frac{\\gamma}{2}\\,\\|x\\|_2^2\n$$\nsubject to the componentwise constraints $\\ell \\le x \\le u$. The gradient of $J(x)$ is\n$$\n\\nabla J(x) = A^\\top(Ax - b) + \\gamma x = (A^\\top A + \\gamma I_n)x - A^\\top b.\n$$\nLet the Hessian matrix be $Q = A^\\top A + \\gamma I_n$. The gradient can then be written as $\\nabla J(x) = Qx - c$, where $c = A^\\top b$. Since $Q$ is constant, the Hessian of $J(x)$ is $\\nabla^2 J(x) = Q$. The matrix $A^\\top A$ is always positive semidefinite. Since $\\gamma \\ge 0$, the matrix $Q$ is symmetric and positive semidefinite. If $\\gamma > 0$ or $A$ has full column rank, $Q$ is positive definite, and $J(x)$ is strictly convex.\n\nThe Lipschitz constant of the gradient, $L$, is the spectral norm (the largest eigenvalue, since $Q$ is symmetric positive semidefinite) of the Hessian: $L = \\|Q\\|_2 = \\lambda_{\\max}(Q)$.\n\n**Derivation of a Computable Upper Bound $\\overline{L}$**\n\nThe goal is to find an upper bound $\\overline{L}$ on $L = \\|Q\\|_2$ that does not require an eigenvalue decomposition. We use fundamental properties of matrix norms.\n\nA known inequality relating the spectral norm to the $1$-norm and $\\infty$-norm for any matrix $M \\in \\mathbb{R}^{n \\times n}$ is $\\|M\\|_2 \\le \\sqrt{\\|M\\|_1 \\|M\\|_\\infty}$. The $1$-norm is the maximum absolute column sum, and the $\\infty$-norm is the maximum absolute row sum.\n$$\n\\|M\\|_1 = \\max_{1 \\le j \\le n} \\sum_{i=1}^n |M_{ij}|, \\quad \\|M\\|_\\infty = \\max_{1 \\le i \\le n} \\sum_{j=1}^n |M_{ij}|.\n$$\nOur Hessian matrix is $Q = A^\\top A + \\gamma I_n$. Since $A^\\top A$ is symmetric and $\\gamma I_n$ is symmetric, $Q$ is symmetric. For any symmetric matrix $M$, we have $\\|M\\|_1 = \\|M\\|_\\infty$.\nApplying this to $Q$, the inequality becomes $\\|Q\\|_2 \\le \\sqrt{\\|Q\\|_1 \\|Q\\|_1} = \\|Q\\|_1$.\nTherefore, a valid and computable upper bound on $L$ is $\\overline{L} = \\|Q\\|_1$.\n$$\nL = \\|Q\\|_2 \\le \\|Q\\|_1 = \\max_{j} \\sum_{i=1}^n |Q_{ij}|.\n$$\nSince the problem provides explicit matrices for $A$, we can form $Q = A^\\top A + \\gamma I_n$ and compute its $1$-norm.\n\nAn alternative bound can be derived using the triangle and submultiplicative properties of norms:\n$$\nL = \\|Q\\|_2 = \\|A^\\top A + \\gamma I_n\\|_2 \\le \\|A^\\top A\\|_2 + \\|\\gamma I_n\\|_2.\n$$\nWe have $\\|\\gamma I_n\\|_2 = \\gamma$ for $\\gamma \\ge 0$. Also, $\\|A^\\top A\\|_2 \\le \\|A^\\top\\|_2 \\|A\\|_2$. Since $\\|A^\\top\\|_2 = \\|A\\|_2$, this simplifies to $\\|A^\\top A\\|_2 \\le \\|A\\|_2^2$. This gives $L \\le \\|A\\|_2^2 + \\gamma$. While correct, computing $\\|A\\|_2$ directly is an eigenvalue problem itself. We can further bound $\\|A\\|_2 \\le \\sqrt{\\|A\\|_1 \\|A\\|_\\infty}$. This yields the bound $L \\le \\|A\\|_1 \\|A\\|_\\infty + \\gamma$. It has been shown via the sub-additivity and sub-multiplicativity of the $1$-norm that $\\|Q\\|_1 = \\|A^\\top A + \\gamma I_n\\|_1 \\le \\|A^\\top A\\|_1 + \\|\\gamma I_n\\|_1 \\le \\|A^\\top\\|_1 \\|A\\|_1 + \\gamma = \\|A\\|_\\infty \\|A\\|_1 + \\gamma$. This demonstrates that the bound $\\|Q\\|_1$ is generally tighter than or equal to $\\|A\\|_1\\|A\\|_\\infty + \\gamma$. We will therefore select $\\overline{L} = \\|Q\\|_1$ as our rigorous and computable upper bound.\n\n**Derivation of a Computable Lower Bound $\\underline{L}$**\n\nThe Lipschitz constant $L$ is the largest eigenvalue of the symmetric positive semidefinite matrix $Q$. The variational characterization of the largest eigenvalue is given by\n$$\nL = \\lambda_{\\max}(Q) = \\max_{v \\in \\mathbb{R}^n, v \\ne 0} \\frac{v^\\top Q v}{v^\\top v}.\n$$\nThe expression $R_Q(v) = \\frac{v^\\top Q v}{v^\\top v}$ is the Rayleigh quotient. This characterization immediately implies that for any non-zero vector $v \\in \\mathbb{R}^n$, the Rayleigh quotient $R_Q(v)$ is a lower bound on $L$: $R_Q(v) \\le L$.\n\nTo find a tight lower bound, we need to find a vector $v$ that is a good approximation of the eigenvector corresponding to $\\lambda_{\\max}(Q)$. The Power Iteration method is designed for this purpose. The algorithm generates a sequence of vectors that converges to the dominant eigenvector.\n\nThe procedure is as follows:\n$1$. Start with an initial vector $v^0$ with $\\|v^0\\|_2 = 1$ (e.g., a randomly generated vector).\n$2$. For $k = 0, 1, 2, \\dots$:\n    $$\n    w^{k+1} = Q v^k\n    $$\n    $$\n    v^{k+1} = \\frac{w^{k+1}}{\\|w^{k+1}\\|_2}\n    $$\n$3$. The sequence of vectors $\\{v^k\\}$ converges to an eigenvector associated with the eigenvalue of largest magnitude. Since $Q$ is positive semidefinite, this is $\\lambda_{\\max}(Q) = L$.\n$4$. At each iteration $k$, the Rayleigh quotient $R_Q(v^k)$ provides a lower bound on $L$. As $k \\to \\infty$, $v^k$ aligns with the dominant eigenvector, and $R_Q(v^k)$ converges to $L$. It can be proven that the sequence $\\{R_Q(v^k)\\}$ is non-decreasing.\n\nTherefore, by running the Power Iteration for a sufficient number of steps, the final Rayleigh quotient, $\\underline{L} = R_Q(v^{\\text{final}})$, provides a high-quality numerical lower bound on $L$.\n\n**Step Size Choice and Conservativeness Assessment**\n\nThe projected gradient method iteration is $x^{k+1} = \\Pi_{[\\ell,u]}(x^k - \\alpha \\nabla J(x^k))$. For a convex objective function $J$ with an $L$-Lipschitz continuous gradient, convergence to a minimizer is guaranteed if the step size $\\alpha$ is chosen in the interval $\\alpha \\in (0, 2/L)$. A choice of $\\alpha \\in (0, 1/L]$ additionally guarantees that the objective function values are non-increasing, i.e., $J(x^{k+1}) \\le J(x^k)$, which is a desirable property for stable convergence.\n\nThe exact value of $L$ is typically not known. However, we have derived a provable upper bound $\\overline{L}$ such that $L \\le \\overline{L}$. By choosing the step size $\\alpha = 1/\\overline{L}$, we ensure that $0 < \\alpha \\le 1/L$. This choice is therefore \"rigorously safe\" because it is guaranteed to lie within the interval that ensures monotone convergence.\n\nThe rate of convergence of the gradient method is influenced by the step size. A step size that is too small can lead to very slow convergence. The ideal step size is close to the upper limit of the stability range, so a choice based on $L$ (e.g., $1/L$) is better than one based on a loose upper bound $\\overline{L} \\gg L$.\n\nThe lower bound $\\underline{L}$ obtained from Power Iteration provides an excellent approximation of the true value of $L$, i.e., $\\underline{L} \\approx L$. We can use $\\underline{L}$ to assess the quality, or \"conservativeness,\" of our upper bound $\\overline{L}$ by computing the ratio $\\overline{L} / \\underline{L}$.\n- If $\\overline{L} / \\underline{L} \\approx 1$, the upper bound is tight, and the step size $\\alpha = 1/\\overline{L}$ is close to optimal.\n- If $\\overline{L} / \\underline{L} \\gg 1$, the upper bound is loose, and the step size is overly conservative, which may significantly slow down the convergence of the projected gradient algorithm. This assessment can inform the decision to either seek a tighter bound for $\\overline{L}$ or employ an adaptive step-size strategy like a line search.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the constrained quadratic optimization problem using the projected gradient method\n    for three distinct test cases. For each case, it computes lower and upper bounds for the\n    Lipschitz constant of the gradient and the final objective value.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"A\": np.array([[3, 1, 0], [1, 4, 1], [0, 1, 2]], dtype=np.float64),\n            \"b\": np.array([1, 0, -1], dtype=np.float64),\n            \"gamma\": 0.2,\n            \"l\": np.array([-0.5, -0.5, -0.5], dtype=np.float64),\n            \"u\": np.array([2, 2, 2], dtype=np.float64),\n            \"x0\": np.array([0, 0, 0], dtype=np.float64),\n        },\n        {\n            \"A\": np.array([[1, 2, 3], [2, 4, 6]], dtype=np.float64),\n            \"b\": np.array([1, 2], dtype=np.float64),\n            \"gamma\": 0.0,\n            \"l\": np.array([0, 0, 0], dtype=np.float64),\n            \"u\": np.array([1, 1, 1], dtype=np.float64),\n            \"x0\": np.array([0.3, 0.3, 0.3], dtype=np.float64),\n        },\n        {\n            \"A\": np.array([[2, 0, -1], [0, 1, 1], [1, -1, 0], [0, 2, 3]], dtype=np.float64),\n            \"b\": np.array([1, -1, 0, 2], dtype=np.float64),\n            \"gamma\": 3.0,\n            \"l\": np.array([-0.1, -0.1, -0.1], dtype=np.float64),\n            \"u\": np.array([0.1, 0.1, 0.1], dtype=np.float64),\n            \"x0\": np.array([0, 0, 0], dtype=np.float64),\n        },\n    ]\n\n    # Algorithmic Parameters\n    K_pow = 200\n    eps_pow = 1e-10\n    K_max = 20000\n    eps_pgd = 1e-9\n\n    results = []\n\n    for case in test_cases:\n        A = case[\"A\"]\n        b = case[\"b\"]\n        gamma = case[\"gamma\"]\n        l_bound = case[\"l\"]\n        u_bound = case[\"u\"]\n        x = case[\"x0\"].copy()\n        \n        m, n = A.shape\n        \n        # Form the Hessian Q = A^T A + gamma * I\n        Q = A.T @ A + gamma * np.eye(n)\n        \n        # --- 1. Compute rigorous upper bound L_upper ---\n        # L_upper = ||Q||_1, which is the maximum absolute column sum.\n        # For a symmetric matrix Q, ||Q||_1 = ||Q||_inf.\n        L_upper = np.max(np.sum(np.abs(Q), axis=0))\n\n        # --- 2. Compute numerical lower bound L_lower using Power Iteration ---\n        # Start with a random vector\n        np.random.seed(0) # for reproducibility\n        v = np.random.rand(n)\n        v = v / np.linalg.norm(v)\n        \n        L_lower_val = 0.0\n        for _ in range(K_pow):\n            w = Q @ v\n            v_new = w / np.linalg.norm(w)\n            # Check for convergence\n            if np.linalg.norm(v_new - v) < eps_pow:\n                v = v_new\n                break\n            v = v_new\n        \n        # Final Rayleigh quotient is the lower bound\n        L_lower = v.T @ (Q @ v)\n\n        # --- 3. Run Projected Gradient Method ---\n        alpha = 1.0 / L_upper\n        c = A.T @ b\n\n        for _ in range(K_max):\n            grad_J = Q @ x - c\n            x_unconstrained = x - alpha * grad_J\n            x_next = np.clip(x_unconstrained, l_bound, u_bound)\n            \n            # Check stopping criterion\n            if np.linalg.norm(x_next - x) < eps_pgd:\n                x = x_next\n                break\n            x = x_next\n\n        x_star = x\n\n        # --- 4. Compute final objective value J(x*) ---\n        residual_norm_sq = np.linalg.norm(A @ x_star - b)**2\n        regularizer_norm_sq = np.linalg.norm(x_star)**2\n        J_final = 0.5 * residual_norm_sq + (gamma / 2.0) * regularizer_norm_sq\n        \n        results.extend([L_lower, L_upper, J_final])\n\n    # Format the final output\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3414873"}, {"introduction": "The power of the projected gradient method lies in its ability to handle complex constraints, which are encapsulated in the projection operator $\\mathcal{P}_C$. While projection onto simple sets is straightforward, many applications in data assimilation involve intricate feasible sets like the probability simplex, $\\Delta$. This exercise [@problem_id:3414855] challenges you to look inside this critical \"black box\" by deriving an efficient, non-trivial projection algorithm from its first principles in convex optimization, a skill essential for adapting PGD to advanced problem structures.", "problem": "Consider the Euclidean projection onto a closed convex set $C \\subset \\mathbb{R}^n$, defined for any $x \\in \\mathbb{R}^n$ as $P_C(x) = \\arg\\min_{z \\in C} \\frac{1}{2}\\|z - x\\|_2^2$. In many inverse problems and data assimilation applications, decision variables represent probability distributions over $n$ states and must lie in the probability simplex $C = \\Delta = \\{z \\in \\mathbb{R}^n : z_i \\ge 0,\\ \\sum_{i=1}^n z_i = 1\\}$. The projection $P_\\Delta(x)$ is used within projected gradient methods to enforce feasibility after a gradient descent step. Starting from the principles of convex optimization and the optimality conditions for constrained quadratic minimization, derive an algorithm that runs in $O(n\\log n)$ time to compute $P_\\Delta(x)$ for any $x \\in \\mathbb{R}^n$. The derivation must begin from the Karush–Kuhn–Tucker (KKT) optimality conditions and justify the algorithm’s correctness by proving that the computed point satisfies the necessary and sufficient conditions for optimality.\n\nYour program must implement the resulting $O(n\\log n)$ algorithm and apply it to the following test suite of inputs $x \\in \\mathbb{R}^n$:\n- Test case $1$: $x = [0.2, -0.1, 0.4, 2.0, 0.3]$.\n- Test case $2$: $x = [0.1, 0.2, 0.3, 0.4, 0.0]$.\n- Test case $3$: $x = [-1.0, -2.0, -3.0]$.\n- Test case $4$: $x = [5.0]$.\n- Test case $5$: $x = [0.5, 0.5, 0.5, 0.5]$.\n- Test case $6$: $x = [0.0, -0.5, 0.0, 0.7, 0.8]$.\n\nFor each test case, compute the projected vector $P_\\Delta(x)$ using your $O(n\\log n)$ algorithm. Each result must be a list of floating-point numbers. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[result1,result2,result3]$ where each $resultk$ is the projected vector for the $k$-th test case). No physical units or angle units are involved in this problem. The outputs are the projected vectors themselves, which are quantifiable as lists of floating-point numbers. The test suite covers a general case, an already feasible point, a case with all entries negative, a scalar boundary case, a case with identical positive entries, and a mixed case with zeros and negatives, thereby testing correctness, feasibility, and edge conditions.", "solution": "The problem requires the derivation and implementation of an efficient algorithm to compute the Euclidean projection of a vector $x \\in \\mathbb{R}^n$ onto the probability simplex, $\\Delta$. The probability simplex is the set $\\Delta = \\{z \\in \\mathbb{R}^n : \\sum_{i=1}^n z_i = 1, z_i \\ge 0 \\text{ for all } i\\}$. The projection $P_\\Delta(x)$ is the unique solution $z^*$ to the following constrained quadratic optimization problem:\n$$\n\\text{minimize} \\quad f(z) = \\frac{1}{2}\\|z - x\\|_2^2 = \\frac{1}{2}\\sum_{i=1}^n (z_i - x_i)^2\n$$\n$$\n\\text{subject to} \\quad \\sum_{i=1}^n z_i = 1 \\quad \\text{and} \\quad z_i \\ge 0 \\quad \\text{for } i=1, \\dots, n.\n$$\nThis is a convex optimization problem, as the objective function is strictly convex and the feasible set $\\Delta$ is convex. Therefore, the Karush-Kuhn-Tucker (KKT) conditions are both necessary and sufficient for optimality. We begin by formulating the Lagrangian of the problem.\n\nThe Lagrangian $L(z, \\lambda, \\nu)$ is given by:\n$$\nL(z, \\lambda, \\nu) = \\frac{1}{2}\\sum_{i=1}^n (z_i - x_i)^2 - \\sum_{i=1}^n \\lambda_i z_i - \\nu \\left( \\sum_{i=1}^n z_i - 1 \\right)\n$$\nwhere $\\lambda_i \\ge 0$ are the Lagrange multipliers for the non-negativity constraints $z_i \\ge 0$, and $\\nu$ is the Lagrange multiplier for the equality constraint $\\sum_{i=1}^n z_i = 1$. The KKT conditions for an optimal point $z^*$ are as follows:\n\n1.  **Stationarity**: The gradient of the Lagrangian with respect to $z$ must vanish at $z^*$:\n    $$\n    \\frac{\\partial L}{\\partial z_i}\\bigg|_{z=z^*} = (z_i^* - x_i) - \\lambda_i - \\nu = 0 \\quad \\implies \\quad z_i^* = x_i + \\lambda_i + \\nu\n    $$\n\n2.  **Primal Feasibility**: The solution $z^*$ must lie in the feasible set $\\Delta$:\n    $$\n    \\sum_{i=1}^n z_i^* = 1 \\quad \\text{and} \\quad z_i^* \\ge 0 \\quad \\text{for all } i\n    $$\n\n3.  **Dual Feasibility**: The multipliers for the inequality constraints must be non-negative:\n    $$\n    \\lambda_i \\ge 0 \\quad \\text{for all } i\n    $$\n\n4.  **Complementary Slackness**:\n    $$\n    \\lambda_i z_i^* = 0 \\quad \\text{for all } i\n    $$\n\nFrom the complementary slackness condition, for each component $i$, either $\\lambda_i = 0$ or $z_i^* = 0$.\n-   If $z_i^* > 0$, then complementary slackness implies $\\lambda_i = 0$. The stationarity condition then simplifies to $z_i^* = x_i + \\nu$. As $z_i^* > 0$, we have $x_i+\\nu > 0$.\n-   If $z_i^* = 0$, then $\\lambda_i \\ge 0$. The stationarity condition gives $0 = x_i + \\lambda_i + \\nu$, which means $\\lambda_i = -x_i - \\nu$. The dual feasibility condition $\\lambda_i \\ge 0$ implies $-x_i - \\nu \\ge 0$, or $x_i + \\nu \\le 0$.\n\nLet's introduce a single threshold parameter $\\theta = -\\nu$. The conditions for $z_i^*$ can be unified:\n-   If $x_i - \\theta > 0$, then $z_i^* > 0$ and $\\lambda_i=0$, so $z_i^* = x_i - \\theta$.\n-   If $x_i - \\theta \\le 0$, then $z_i^* = 0$.\n\nThis can be expressed compactly for all $i$ as:\n$$\nz_i^* = \\max(0, x_i - \\theta) = (x_i - \\theta)_+\n$$\nThe problem is now reduced to finding the correct value of the scalar threshold $\\theta$. We can determine $\\theta$ by enforcing the primal feasibility constraint $\\sum_{i=1}^n z_i^* = 1$:\n$$\n\\sum_{i=1}^n \\max(0, x_i - \\theta) = 1\n$$\nLet $g(\\theta) = \\sum_{i=1}^n \\max(0, x_i - \\theta)$. This function is continuous, piecewise linear, and monotonically non-increasing. We need to find the root $\\theta$ of the equation $g(\\theta) = 1$. A direct analytical solution is difficult, but we can design an efficient algorithm based on the properties of $g(\\theta)$.\n\nConsider sorting the components of $x$ in descending order: $u_1 \\ge u_2 \\ge \\dots \\ge u_n$. The terms $\\max(0, u_i - \\theta)$ will become non-zero in this order as $\\theta$ decreases. Let $\\rho$ be the number of positive components in the final solution $z^*$. These will correspond to the $\\rho$ largest components of $x$. Thus, we have $z_i^* > 0$ for indices $i$ corresponding to $u_1, \\dots, u_\\rho$, and $z_i^* = 0$ for indices corresponding to $u_{\\rho+1}, \\dots, u_n$. This implies that the threshold $\\theta$ must satisfy $u_\\rho - \\theta > 0$ and $u_{\\rho+1} - \\theta \\le 0$, i.e., $u_{\\rho+1} \\le \\theta < u_\\rho$.\n\nFor this assumed $\\rho$, the sum constraint becomes:\n$$\n\\sum_{j=1}^\\rho (u_j - \\theta) + \\sum_{j=\\rho+1}^n 0 = 1\n$$\n$$\n\\left(\\sum_{j=1}^\\rho u_j\\right) - \\rho\\theta = 1\n$$\nSolving for $\\theta$ yields a candidate threshold for each possible $\\rho$:\n$$\n\\theta_\\rho = \\frac{1}{\\rho}\\left(\\sum_{j=1}^\\rho u_j - 1\\right)\n$$\nThe correct $\\rho$ is the one for which this $\\theta_\\rho$ is consistent with the assumption $u_{\\rho+1} \\le \\theta_\\rho < u_\\rho$. We only need to find the largest index $\\rho \\in \\{1, \\dots, n\\}$ that satisfies the condition $u_\\rho > \\theta_\\rho$. Let this index be $\\rho^*$.\nThe condition $u_\\rho > \\theta_\\rho$ is equivalent to $\\rho u_\\rho > \\sum_{j=1}^\\rho u_j - 1$.\nLet's show that if $\\rho^*$ is the largest index satisfying this, then the second condition $u_{\\rho^*+1} \\le \\theta_{\\rho^*}$ also holds. Assume for contradiction that $u_{\\rho^*+1} > \\theta_{\\rho^*}$. This implies $(\\rho^*+1) u_{\\rho^*+1} > \\rho^* u_{\\rho^*+1} > \\rho^* \\theta_{\\rho^*}$. Also, $(\\sum_{j=1}^{\\rho^*} u_j - 1) + u_{\\rho^*+1} = \\rho^*\\theta_{\\rho^*} + u_{\\rho^*+1}$.\nConsider the condition for $\\rho^*+1$:\n$$(\\rho^*+1)u_{\\rho^*+1} > \\sum_{j=1}^{\\rho^*+1} u_j - 1 = \\left(\\sum_{j=1}^{\\rho^*} u_j - 1\\right) + u_{\\rho^*+1} = \\rho^*\\theta_{\\rho^*} + u_{\\rho^*+1}$$\nThis simplifies to $\\rho^* u_{\\rho^*+1} > \\rho^* \\theta_{\\rho^*}$, or $u_{\\rho^*+1} > \\theta_{\\rho^*}$, which is our assumption. This means that if $u_{\\rho^*+1} > \\theta_{\\rho^*}$, then $\\rho^*+1$ would also satisfy the test condition, contradicting that $\\rho^*$ is the largest such index. Therefore, we must have $u_{\\rho^*+1} \\le \\theta_{\\rho^*}$.\n\nThis leads to the following $O(n\\log n)$ algorithm:\n1.  Sort the input vector $x$ in descending order to obtain the vector $u$. This takes $O(n\\log n)$ time.\n2.  Find the value $\\rho$ which is the largest index $j \\in \\{1, \\dots, n\\}$ satisfying $u_j > \\frac{1}{j}(\\sum_{i=1}^j u_i - 1)$. This can be done in $O(n)$ time by iterating from $j=1$ to $n$ while maintaining a running sum of the $u_i$.\n3.  With this $\\rho$, compute the final threshold $\\theta = \\frac{1}{\\rho}(\\sum_{i=1}^\\rho u_i - 1)$. This requires the sum computed in the previous step and takes $O(1)$ time.\n4.  Compute the projection $z^*$ using the original vector $x$ and the threshold $\\theta$: $z_i^* = \\max(0, x_i - \\theta)$ for $i=1, \\dots, n$. This step takes $O(n)$ time.\n\nThe dominant step is the initial sort, so the total time complexity is $O(n\\log n)$. The resulting vector $z^*$ is guaranteed by this construction to satisfy the KKT conditions and is therefore the unique optimal solution.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It computes the projection of several vectors onto the probability simplex\n    and prints the results in the specified format.\n    \"\"\"\n\n    def project_to_simplex(x: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Computes the Euclidean projection of a vector x onto the probability simplex.\n\n        The algorithm takes O(n log n) time due to the sorting step. The\n        derivation is based on the Karush-Kuhn-Tucker (KKT) conditions for\n        the constrained quadratic optimization problem.\n\n        Args:\n            x: A numpy array representing the vector to be projected.\n\n        Returns:\n            A numpy array representing the projected vector.\n        \"\"\"\n        n = x.shape[0]\n        \n        # If the vector is already in the simplex, return it.\n        # This is an optional optimization, the main algorithm handles this case correctly.\n        if np.sum(x) == 1 and np.all(x >= 0):\n            return x\n\n        # Sort the vector x in descending order.\n        u = np.sort(x)[::-1]\n\n        # Compute the cumulative sum of the sorted vector.\n        cssv = np.cumsum(u)\n        \n        # Find the largest rho such that u_rho > (1/rho) * (sum_{i=1}^{rho} u_i - 1).\n        # This is done in a vectorized way for efficiency.\n        # The equation is rearranged to avoid division inside the loop:\n        # rho * u_rho > sum_{i=1}^{rho} u_i - 1\n        indices = np.arange(1, n + 1)\n        condition = u * indices > cssv - 1\n        \n        # The last index where the condition is true gives us the correct rho.\n        # np.where returns a tuple of arrays, we need the first one.\n        # The set of indices satisfying the condition is never empty for n>=1.\n        rho_idx = np.where(condition)[0][-1]\n        rho = rho_idx + 1\n\n        # Compute the threshold theta using the found rho.\n        theta = (cssv[rho_idx] - 1) / rho\n\n        # Compute the projection by applying the threshold.\n        # z_i = max(x_i - theta, 0)\n        z = np.maximum(x - theta, 0)\n\n        return z\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        np.array([0.2, -0.1, 0.4, 2.0, 0.3]),\n        np.array([0.1, 0.2, 0.3, 0.4, 0.0]),\n        np.array([-1.0, -2.0, -3.0]),\n        np.array([5.0]),\n        np.array([0.5, 0.5, 0.5, 0.5]),\n        np.array([0.0, -0.5, 0.0, 0.7, 0.8]),\n    ]\n\n    results = []\n    for case in test_cases:\n        projected_vector = project_to_simplex(case)\n        # Convert the result to a list of floats for correct string formatting.\n        results.append(str(projected_vector.tolist()))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3414855"}, {"introduction": "Enforcing constraints is a central theme in inverse problems, and explicit projection is not the only available tool. This final practice [@problem_id:3414810] provides a comparative study between projected gradient descent and an alternative, the log-barrier interior-point method, for enforcing positivity. By implementing and analyzing both algorithms, you will gain valuable insights into their distinct behaviors, particularly near the boundary of the feasible set, and learn to critically evaluate the trade-offs between these fundamental strategies.", "problem": "Consider a linear inverse problem with a bounded, positive state. Let $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ be a known linear observation operator with full column rank and let $\\mathbf{b} \\in \\mathbb{R}^{m}$ be given measurements. The target is to estimate the state vector $\\mathbf{x} \\in \\mathbb{R}^{n}$ from the data by minimizing the least squares misfit subject to strict positivity, that is, minimize the objective $J(\\mathbf{x}) = \\tfrac{1}{2}\\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{b} \\rVert_2^2$ subject to $\\mathbf{x} \\in \\mathbb{R}_{++}^{n}$, where $\\mathbb{R}_{++}^{n}$ denotes the set of vectors with strictly positive entries. This strict positivity constraint models prior knowledge in data assimilation that the physical quantities represented by $\\mathbf{x}$, such as concentrations or densities, must be positive.\n\nTwo algorithmic strategies are to be investigated and compared:\n\n1. Projected Gradient Descent (PGD): The iteration is of the form $\\mathbf{x}^{k+1} = \\mathcal{P}_{\\mathbb{R}_{+}^{n}}\\!\\left(\\mathbf{x}^{k} - \\alpha \\nabla J(\\mathbf{x}^{k})\\right)$, where $\\nabla J(\\mathbf{x})$ is the gradient of $J$ and $\\mathcal{P}_{\\mathbb{R}_{+}^{n}}$ denotes the orthogonal projection onto the nonnegative orthant $\\mathbb{R}_{+}^{n} = \\{\\mathbf{x} \\in \\mathbb{R}^{n} : x_i \\ge 0, \\ \\forall i\\}$. This method imposes nonnegativity explicitly by projection. It is known that for a choice of step size parameter $\\alpha \\in (0, 1/L)$, where $L$ is any Lipschitz constant of the gradient $\\nabla J$, the sequence of iterates exhibits descent in the objective for convex $J$.\n\n2. Log-barrier surrogate for strict positivity: Define the barrier-augmented objective $J_{\\mu}(\\mathbf{x}) = \\tfrac{1}{2}\\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{b} \\rVert_2^2 - \\mu \\sum_{i=1}^{n} \\log(x_i)$, where $\\mu > 0$ is a barrier parameter. This surrogate enforces strict positivity $\\mathbf{x} \\in \\mathbb{R}_{++}^{n}$ implicitly by penalizing approaches to the boundary $x_i \\downarrow 0$. The gradient descent iteration is of the form $\\mathbf{x}^{k+1} = \\mathbf{x}^{k} - \\alpha \\nabla J_{\\mu}(\\mathbf{x}^{k})$, with a step size $\\alpha > 0$ selected to maintain positivity and descent. Near the boundary $x_i \\downarrow 0$, the barrier term dominates the behavior due to the divergence of the derivative of $-\\log(x_i)$.\n\nStarting only from the fundamental facts that the gradient of a least squares objective $J(\\mathbf{x}) = \\tfrac{1}{2}\\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{b} \\rVert_2^2$ is $\\nabla J(\\mathbf{x}) = \\mathbf{A}^{\\top}(\\mathbf{A}\\mathbf{x} - \\mathbf{b})$, that the Lipschitz constant of $\\nabla J$ is bounded by the spectral norm squared $L = \\lVert \\mathbf{A} \\rVert_2^2$, that the orthogonal projection $\\mathcal{P}_{\\mathbb{R}_{+}^{n}}$ onto the nonnegative orthant acts componentwise, and that the derivative of $\\log(x)$ is $1/x$, complete the following tasks:\n\n- Derive the explicit form of the PGD update map for this problem, ensuring that the choice of step size uses a valid Lipschitz bound of the gradient and that the projection enforces nonnegativity componentwise.\n\n- Derive the explicit form of the gradient of the barrier-augmented objective $J_{\\mu}(\\mathbf{x})$ and design a positivity-preserving, descent-enforcing step size selection rule that is compatible with a gradient descent iteration. The rule must guarantee that if $\\mathbf{x}^{k} \\in \\mathbb{R}_{++}^{n}$ then $\\mathbf{x}^{k+1} \\in \\mathbb{R}_{++}^{n}$ while ensuring objective descent in $J_{\\mu}$. This is to be done without employing any shortcut formulas beyond the aforementioned fundamental facts.\n\n- Implement both algorithms to convergence with a stopping rule that is based on the successive iterate difference. Use a fixed initial guess with strictly positive components for both methods. For the PGD, implement the projection onto $\\mathbb{R}_{+}^{n}$ explicitly. For the barrier method, ensure the positivity-preserving step rule is enforced at every iteration.\n\n- Compare the near-boundary behavior of the two methods on the following test suite of cases. There are no physical units in this problem; all quantities are dimensionless.\n\nTest Suite (each case is specified by $(\\mathbf{A}, \\mathbf{b}, \\mu, \\mathbf{x}^{0}, \\text{tolerances})$):\n1. Case 1 (one-dimensional, boundary-dominant): $n = 1$, $\\mathbf{A} = [1]$, $\\mathbf{b} = [10^{-6}]$, $\\mu = 10^{-6}$, initial guess $\\mathbf{x}^{0} = [10^{-3}]$, stopping tolerance $\\epsilon = 10^{-12}$, maximum iterations $N_{\\max} = 20000$.\n2. Case 2 (two-dimensional, ill-conditioning across coordinates): $n = 2$, $\\mathbf{A} = \\mathrm{diag}(1, 10^{-2})$, $\\mathbf{b} = [10^{-3}, 10^{-5}]^{\\top}$, $\\mu = 10^{-5}$, initial guess $\\mathbf{x}^{0} = [10^{-3}, 10^{-3}]^{\\top}$, stopping tolerance $\\epsilon = 10^{-12}$, maximum iterations $N_{\\max} = 20000$.\n3. Case 3 (ten-dimensional, convolutional blur and zeros in the truth): $n = 10$, $\\mathbf{A} \\in \\mathbb{R}^{10 \\times 10}$ is the Toeplitz convolution matrix associated with kernel $\\mathbf{h} = [0.25, 0.5, 0.25]$ with zero-padding at the boundaries, i.e., $(\\mathbf{A}\\mathbf{x})_i = 0.25 x_{i-1} + 0.5 x_i + 0.25 x_{i+1}$ with $x_0 = x_{n+1} = 0$, and $\\mathbf{b} = \\mathbf{A}\\mathbf{x}_{\\mathrm{true}}$, where $\\mathbf{x}_{\\mathrm{true}} = [0.0, 0.1, 0.0, 0.2, 0.0, 0.05, 0.0, 0.1, 0.0, 0.0]^{\\top}$. Additive noise is negligible and can be taken as zero for reproducibility. Take $\\mu = 10^{-6}$, initial guess $\\mathbf{x}^{0} = 10^{-3}\\cdot \\mathbf{1}$ (the vector with all entries equal to $10^{-3}$), stopping tolerance $\\epsilon = 10^{-12}$, maximum iterations $N_{\\max} = 50000$.\n\nYour program must, for each case, produce three scalar quantities that quantify near-boundary behavior:\n- The minimum component value of the final PGD solution, $\\min_i x^{\\star}_{\\mathrm{PGD}, i}$.\n- The minimum component value of the final barrier solution, $\\min_i x^{\\star}_{\\mathrm{bar}, i}$.\n- The difference in final least squares misfit between the PGD and barrier solutions, $J(\\mathbf{x}^{\\star}_{\\mathrm{PGD}}) - J(\\mathbf{x}^{\\star}_{\\mathrm{bar}})$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the nine results (three per case, in the order listed above for Case 1, then Case 2, then Case 3) as a comma-separated list enclosed in square brackets (e.g., \"[r1,r2,r3,r4,r5,r6,r7,r8,r9]\"). Only this single line must be printed. Angles are not involved; no unit conversion is required. All outputs are dimensionless floating-point numbers.", "solution": "The problem presented is a valid, well-posed, and scientifically grounded task in the field of numerical optimization for inverse problems. It involves the minimization of a convex quadratic objective function subject to positivity constraints, a standard problem in data assimilation and other scientific domains. All provided information is self-contained, mathematically consistent, and sufficient for the derivation and implementation of the specified algorithms. We proceed with the solution.\n\nThe core problem is to find a state vector $\\mathbf{x}$ that minimizes the least-squares objective function:\n$$\nJ(\\mathbf{x}) = \\frac{1}{2}\\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{b} \\rVert_2^2\n$$\nsubject to the constraint that all components of $\\mathbf{x}$ are strictly positive, i.e., $\\mathbf{x} \\in \\mathbb{R}_{++}^{n}$, where $(\\mathbf{x})_i = x_i > 0$ for all $i=1, \\dots, n$. Since the minimizer may lie on the boundary of this set, we practically seek a solution in the closure, $\\mathbf{x} \\in \\mathbb{R}_{+}^{n}$, where $x_i \\ge 0$.\n\n### Projected Gradient Descent (PGD)\n\nThe Projected Gradient Descent method iteratively refines an estimate $\\mathbf{x}^k$ by first taking a step in the negative gradient direction and then projecting the result onto the feasible set.\n\n**1. Gradient Derivation:**\nThe gradient of the objective function $J(\\mathbf{x})$ is provided as a fundamental fact:\n$$\n\\nabla J(\\mathbf{x}) = \\mathbf{A}^{\\top}(\\mathbf{A}\\mathbf{x} - \\mathbf{b})\n$$\n\n**2. PGD Update Rule:**\nThe iterative update is given by $\\mathbf{x}^{k+1} = \\mathcal{P}_{\\mathbb{R}_{+}^{n}}\\!\\left(\\mathbf{x}^{k} - \\alpha \\nabla J(\\mathbf{x}^{k})\\right)$. This consists of two steps:\n- A gradient descent step: $\\mathbf{y}^{k+1} = \\mathbf{x}^{k} - \\alpha \\nabla J(\\mathbf{x}^{k})$.\n- A projection step: $\\mathbf{x}^{k+1} = \\mathcal{P}_{\\mathbb{R}_{+}^{n}}(\\mathbf{y}^{k+1})$.\n\n**3. Step Size $\\alpha$:**\nFor the convergence of gradient descent, the step size $\\alpha$ must satisfy $\\alpha \\in (0, 2/L)$, where $L$ is the Lipschitz constant of the gradient $\\nabla J(\\mathbf{x})$. The problem provides a tighter sufficient condition, $\\alpha \\in (0, 1/L)$, and a valid bound for the Lipschitz constant, $L = \\lVert \\mathbf{A} \\rVert_2^2 = \\sigma_{\\max}^2(\\mathbf{A})$, where $\\sigma_{\\max}(\\mathbf{A})$ is the largest singular value of $\\mathbf{A}$. A fixed step size $\\alpha$ can be chosen from this interval, for instance, $\\alpha = c / \\lVert \\mathbf{A} \\rVert_2^2$ for a constant $c \\in (0, 1)$, like $c=0.99$.\n\n**4. Projection Operator $\\mathcal{P}_{\\mathbb{R}_{+}^{n}}$:**\nThe orthogonal projection onto the non-negative orthant $\\mathbb{R}_{+}^{n}$ acts component-wise. For any vector $\\mathbf{y} \\in \\mathbb{R}^n$, its projection $\\mathbf{x} = \\mathcal{P}_{\\mathbb{R}_{+}^{n}}(\\mathbf{y})$ is defined by:\n$$\nx_i = (\\mathbf{x})_i = \\max(y_i, 0) \\quad \\text{for } i=1, \\dots, n\n$$\n\n**5. Explicit PGD Update Map:**\nCombining these elements, the explicit update map from $\\mathbf{x}^k$ to $\\mathbf{x}^{k+1}$ is:\n$$\n\\mathbf{x}^{k+1} = \\max\\left(\\mathbf{x}^k - \\alpha \\left( \\mathbf{A}^{\\top}(\\mathbf{A}\\mathbf{x}^k - \\mathbf{b}) \\right), \\mathbf{0}\\right)\n$$\nwhere the $\\max$ function is applied component-wise. This algorithm finds a solution in $\\mathbb{R}_{+}^{n}$. If the true minimizer has zero components, this method is capable of finding them by setting the corresponding components of the iterate to exactly $0$.\n\n### Log-Barrier Method\n\nThe log-barrier method, a type of interior-point method, incorporates the positivity constraint into the objective function via a penalty term. This creates a surrogate objective $J_{\\mu}(\\mathbf{x})$ that is minimized without explicit constraints, but whose structure prevents iterates from reaching the boundary of the feasible set.\n\n**1. Barrier-Augmented Objective:**\nThe surrogate objective is defined as:\n$$\nJ_{\\mu}(\\mathbf{x}) = J(\\mathbf{x}) - \\mu \\sum_{i=1}^{n} \\log(x_i) = \\frac{1}{2}\\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{b} \\rVert_2^2 - \\mu \\sum_{i=1}^{n} \\log(x_i)\n$$\nwhere $\\mu > 0$ is the barrier parameter. The term $-\\mu \\log(x_i)$ diverges to $+\\infty$ as $x_i \\to 0^+$, thus penalizing iterates that approach the boundary.\n\n**2. Gradient of the Barrier Objective:**\nUsing the linearity of the gradient operator and the given fundamental facts, we derive $\\nabla J_{\\mu}(\\mathbf{x})$:\n$$\n\\nabla J_{\\mu}(\\mathbf{x}) = \\nabla \\left(\\frac{1}{2}\\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{b} \\rVert_2^2\\right) - \\nabla \\left(\\mu \\sum_{i=1}^{n} \\log(x_i)\\right)\n$$\nThe gradient of the log-barrier term is:\n$$\n\\nabla \\left(\\mu \\sum_{i=1}^{n} \\log(x_i)\\right) = \\mu \\begin{bmatrix} \\partial/\\partial x_1 \\\\ \\vdots \\\\ \\partial/\\partial x_n \\end{bmatrix} \\sum_{j=1}^{n} \\log(x_j) = \\mu \\begin{bmatrix} 1/x_1 \\\\ \\vdots \\\\ 1/x_n \\end{bmatrix} = \\mu \\mathbf{x}^{\\circ -1}\n$$\nwhere $\\mathbf{x}^{\\circ -1}$ denotes the component-wise inverse of $\\mathbf{x}$.\nTherefore, the full gradient is:\n$$\n\\nabla J_{\\mu}(\\mathbf{x}) = \\mathbf{A}^{\\top}(\\mathbf{A}\\mathbf{x} - \\mathbf{b}) - \\mu \\mathbf{x}^{\\circ -1}\n$$\n\n**3. Positivity-Preserving and Descent-Enforcing Step Size Rule:**\nThe update is a standard gradient descent step, $\\mathbf{x}^{k+1} = \\mathbf{x}^k - \\alpha_k \\nabla J_{\\mu}(\\mathbf{x}^k)$. We must design a rule for selecting the step size $\\alpha_k > 0$ that guarantees both positivity ($x_i^{k+1} > 0$ for all $i$) and descent ($J_{\\mu}(\\mathbf{x}^{k+1}) < J_{\\mu}(\\mathbf{x}^k)$).\n\n- **Positivity Preservation:** For each component $i$, we require $x_i^{k+1} = x_i^k - \\alpha_k (\\nabla J_{\\mu}(\\mathbf{x}^k))_i > 0$. Let $\\mathbf{g}_{\\mu}^k = \\nabla J_{\\mu}(\\mathbf{x}^k)$.\n  If $(g_{\\mu}^k)_i \\le 0$, the $i$-th component is non-decreasing, and the condition holds for any $\\alpha_k > 0$.\n  If $(g_{\\mu}^k)_i > 0$, we must have $\\alpha_k < x_i^k / (g_{\\mu}^k)_i$.\n  To satisfy this for all components simultaneously, the step size must be bounded by the minimum of these ratios:\n  $$\n  \\alpha_{\\text{max}} = \\min_{i \\text{ s.t. } (g_{\\mu}^k)_i > 0} \\left\\{ \\frac{x_i^k}{(g_{\\mu}^k)_i} \\right\\}\n  $$\n  Any step size $\\alpha_k \\in (0, \\alpha_{\\text{max}})$ will ensure $\\mathbf{x}^{k+1} \\in \\mathbb{R}_{++}^n$.\n\n- **Descent Enforcement:** A fixed step size is not robust because the Lipschitz constant of $\\nabla J_{\\mu}$ depends on $\\mathbf{x}$ and can be arbitrarily large near the boundary. A backtracking line search is a standard and effective method. The rule is as follows:\n  1.  Set backtracking parameters: a sufficient decrease constant $c \\in (0, 1)$ (e.g., $c=10^{-4}$) and a shrinkage factor $\\tau \\in (0, 1)$ (e.g., $\\tau=0.5$).\n  2.  Calculate the search direction $\\mathbf{d}^k = -\\mathbf{g}_{\\mu}^k = -\\nabla J_{\\mu}(\\mathbf{x}^k)$.\n  3.  Set an initial trial step size $\\alpha$. A safe and aggressive choice is a fraction of the maximum positivity-preserving step, e.g., $\\alpha = \\beta \\alpha_{\\text{max}}$ with $\\beta \\in (0, 1)$ (e.g., $\\beta=0.99$).\n  4.  While the Armijo condition is not satisfied:\n      $$\n      J_{\\mu}(\\mathbf{x}^k + \\alpha \\mathbf{d}^k) > J_{\\mu}(\\mathbf{x}^k) + c \\alpha (\\mathbf{g}_{\\mu}^k)^{\\top} \\mathbf{d}^k\n      $$\n      which simplifies to:\n      $$\n      J_{\\mu}(\\mathbf{x}^k - \\alpha \\mathbf{g}_{\\mu}^k) > J_{\\mu}(\\mathbf{x}^k) - c \\alpha \\lVert \\mathbf{g}_{\\mu}^k \\rVert_2^2\n      $$\n      shrink the step size: $\\alpha \\leftarrow \\tau \\alpha$.\n  5.  Set $\\alpha_k = \\alpha$.\n\nThis procedure guarantees that each step is strictly positive and decreases the value of the barrier objective function $J_{\\mu}$. Unlike PGD, the barrier method will always produce a solution with strictly positive components, which approach zero as $\\mu \\to 0$ for components that are zero in the true minimizer of $J$.\n\n### Comparison of Near-Boundary Behavior\n\n- **PGD:** The projection operator $\\max(\\cdot, 0)$ is non-differentiable at $0$, but it allows the algorithm to place components of the solution vector $\\mathbf{x}^{\\star}_{\\mathrm{PGD}}$ exactly on the boundary of the feasible set, i.e., $x_i^{\\star} = 0$. This is advantageous when the true underlying physical state is known to have zero values (e.g., zero concentration or density in some regions).\n\n- **Log-Barrier:** The log-barrier term $-\\mu \\log(x_i)$ creates a gradient component $-\\mu/x_i$ that grows infinitely large as $x_i \\to 0^+$. This acts as a repulsive force, preventing any component from ever becoming zero. The solution $\\mathbf{x}^{\\star}_{\\mathrm{bar}}$ will always be in the strict interior $\\mathbb{R}_{++}^n$. The minimal components of $\\mathbf{x}^{\\star}_{\\mathrm{bar}}$ will be small positive values, the magnitude of which depends on the barrier parameter $\\mu$. Consequently, $J(\\mathbf{x}^{\\star}_{\\mathrm{PGD}})$, which is minimized over $\\mathbb{R}_{+}^{n}$, will generally be less than or equal to $J(\\mathbf{x}^{\\star}_{\\mathrm{bar}})$, which is the result of minimizing a perturbed objective $J_\\mu$.", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import toeplitz\n\ndef solve_pgd(A, b, x0, tol, n_max):\n    \"\"\"\n    Solves the non-negatively constrained least squares problem using Projected Gradient Descent (PGD).\n    min 0.5 * ||Ax - b||^2 s.t. x >= 0.\n    \"\"\"\n    x = np.copy(x0)\n    AtA = A.T @ A\n    Atb = A.T @ b\n    \n    # Lipschitz constant of the gradient is the max eigenvalue of A^T A, which is ||A||_2^2\n    try:\n        # np.linalg.norm(A, 2) can be slow for large matrices, but fine for these cases.\n        L = np.linalg.norm(A, 2)**2\n        if L == 0:  # Handle zero matrix case\n            L = 1.0\n    except np.linalg.LinAlgError:\n        L = np.linalg.norm(AtA, 2) # Fallback if norm(A, 2) fails\n\n    alpha = 0.99 / L  # Fixed step size satisfying alpha < 1/L\n\n    for _ in range(n_max):\n        grad = AtA @ x - Atb\n        x_new = x - alpha * grad\n        x_new = np.maximum(x_new, 0) # Projection step\n        \n        if np.linalg.norm(x_new - x) < tol:\n            x = x_new\n            break\n        x = x_new\n        \n    return x\n\ndef solve_barrier(A, b, mu, x0, tol, n_max):\n    \"\"\"\n    Solves the strictly positive least squares problem using a log-barrier method.\n    min 0.5 * ||Ax - b||^2 - mu * sum(log(x_i)).\n    \"\"\"\n    x = np.copy(x0)\n    AtA = A.T @ A\n    Atb = A.T @ b\n\n    # Backtracking line search parameters\n    c1 = 1e-4\n    tau = 0.5\n\n    for k in range(n_max):\n        # Prevent x components from being exactly zero or negative due to numerical error\n        x[x <= 0] = np.finfo(float).eps\n\n        # Calculate gradient of barrier objective J_mu\n        grad_mu = (AtA @ x - Atb) - mu / x\n        \n        # Calculate max step size to preserve positivity\n        pos_grad_indices = grad_mu > 0\n        if not np.any(pos_grad_indices):\n            alpha_max_pos = 1.0 # All gradient components non-positive, can take a large step\n        else:\n            alpha_max_pos = np.min(x[pos_grad_indices] / grad_mu[pos_grad_indices])\n        \n        alpha = 0.99 * alpha_max_pos\n\n        # Perform backtracking line search\n        J_mu_k = 0.5 * np.sum((A @ x - b)**2) - mu * np.sum(np.log(x))\n        descent_term = c1 * alpha * (grad_mu @ grad_mu)\n\n        while True:\n            x_new = x - alpha * grad_mu\n            \n            # Ensure new iterate is strictly positive for log evaluation\n            if np.any(x_new <= 0):\n                alpha *= tau\n                descent_term *= tau\n                if alpha < 1e-20: # Step size too small\n                     break\n                continue\n\n            J_mu_new = 0.5 * np.sum((A @ x_new - b)**2) - mu * np.sum(np.log(x_new))\n            \n            if J_mu_new <= J_mu_k - c1 * alpha * np.dot(grad_mu, grad_mu): # Armijo condition check\n                break\n            \n            alpha *= tau\n            if alpha < 1e-20: # Step size too small\n                x_new = x\n                break\n\n        if np.linalg.norm(x_new - x) < tol:\n            x = x_new\n            break\n        x = x_new\n    \n    return x\n\ndef calculate_metrics(A, b, x_pgd, x_bar):\n    \"\"\"Calculates the three required performance metrics.\"\"\"\n    min_pgd = np.min(x_pgd)\n    min_bar = np.min(x_bar)\n    \n    j_pgd = 0.5 * np.linalg.norm(A @ x_pgd - b)**2\n    j_bar = 0.5 * np.linalg.norm(A @ x_bar - b)**2\n    \n    diff_j = j_pgd - j_bar\n    return min_pgd, min_bar, diff_j\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    # Test Suite (A, b, mu, x0, tol, n_max)\n    case1_A = np.array([[1.0]])\n    case1_b = np.array([1e-6])\n    case1_mu = 1e-6\n    case1_x0 = np.array([1e-3])\n    case1_tol = 1e-12\n    case1_nmax = 20000\n\n    case2_A = np.diag([1.0, 1e-2])\n    case2_b = np.array([1e-3, 1e-5])\n    case2_mu = 1e-5\n    case2_x0 = np.array([1e-3, 1e-3])\n    case2_tol = 1e-12\n    case2_nmax = 20000\n\n    n3 = 10\n    c3 = np.zeros(n3)\n    c3[0] = 0.5\n    c3[1] = 0.25\n    case3_A = toeplitz(c3)\n    case3_x_true = np.array([0.0, 0.1, 0.0, 0.2, 0.0, 0.05, 0.0, 0.1, 0.0, 0.0])\n    case3_b = case3_A @ case3_x_true\n    case3_mu = 1e-6\n    case3_x0 = 1e-3 * np.ones(n3)\n    case3_tol = 1e-12\n    case3_nmax = 50000\n    \n    test_cases = [\n        (case1_A, case1_b, case1_mu, case1_x0, case1_tol, case1_nmax),\n        (case2_A, case2_b, case2_mu, case2_x0, case2_tol, case2_nmax),\n        (case3_A, case3_b, case3_mu, case3_x0, case3_tol, case3_nmax),\n    ]\n\n    results = []\n    for A, b, mu, x0, tol, n_max in test_cases:\n        x_pgd = solve_pgd(A, b, x0, tol, n_max)\n        x_bar = solve_barrier(A, b, mu, x0, tol, n_max)\n        \n        metrics = calculate_metrics(A, b, x_pgd, x_bar)\n        results.extend(metrics)\n\n    # Format output as specified\n    print(f\"[{','.join(f'{v:.15e}' for v in results)}]\")\n\nsolve()\n```", "id": "3414810"}]}