{"hands_on_practices": [{"introduction": "A cornerstone of solving constrained inverse problems is the projected gradient method. This exercise provides direct, hands-on practice implementing this fundamental algorithm for the common case of bound constraints [@problem_id:3371700]. By coding a single iteration, you will engage with the two critical components of the method: taking a descent step along the negative gradient and then projecting the result back onto the feasible set to maintain the constraints. This practice is invaluable for building intuition on how iterative methods navigate complex objective landscapes while respecting physical or statistical limitations on the solution.", "problem": "Consider the bound-constrained quadratic inverse problem in finite dimensions. Let $A \\in \\mathbb{R}^{m \\times n}$, $b \\in \\mathbb{R}^{m}$, and $\\lambda > 0$. Define the Tikhonov-regularized least-squares objective\n$$\nf(x) \\equiv \\tfrac{1}{2}\\|A x - b\\|_2^2 + \\tfrac{\\lambda}{2}\\|x\\|_2^2, \\quad x \\in \\mathbb{R}^n.\n$$\nImpose simple bound constraints $l \\le x \\le u$ componentwise, where $l, u \\in \\mathbb{R}^n$ with $l_i \\le u_i$ for all $i$. The Euclidean projection onto the feasible set $[l,u]$ is defined componentwise by\n$$\n\\Pi_{[l,u]}(y)_i \\equiv \\min\\{\\max\\{y_i, l_i\\}, u_i\\}, \\quad i = 1,\\dots,n.\n$$\nYou are asked to implement one iteration of the projected gradient method with backtracking line search that respects the projection mapping. Start from a current iterate $x \\in [l,u]$, compute a projected trial point\n$$\nx^+(t) \\equiv \\Pi_{[l,u]}\\bigl(x - t \\nabla f(x)\\bigr),\n$$\nand choose a step length $t$ via Armijo backtracking so that the sufficient decrease condition holds while respecting the projection:\n$$\nf\\bigl(x^+(t)\\bigr) \\le f(x) + \\sigma \\, \\nabla f(x)^{\\top} \\bigl(x^+(t) - x\\bigr).\n$$\nUse the following base rules and definitions only:\n- The objective $f$ is as given above.\n- The Euclidean projection $\\Pi_{[l,u]}$ is as defined above.\n- The gradient $\\nabla f(x)$ must be derived from first principles for the given $f$.\n- The Armijo backtracking must start at initial step $t_0 = 1$ and reduce the step by a fixed factor $\\beta \\in (0,1)$, here $\\beta = 0.5$, until the sufficient decrease condition is met or until the step size falls below a minimum threshold $t_{\\min} = 10^{-12}$.\n- The Armijo parameter is $\\sigma = 10^{-4}$.\n\nImplement a program that, for each test case below, performs exactly one such projected gradient iteration from the provided $x$:\n- Compute $\\nabla f(x)$.\n- Starting from $t = t_0$, repeatedly evaluate the Armijo condition using $x^+(t)$ and reduce $t \\leftarrow \\beta t$ if it is not satisfied, always maintaining $x^+(t)$ via the projection $\\Pi_{[l,u]}$.\n- Terminate the backtracking when the condition holds or $t  t_{\\min}$.\n- Return the accepted $t$ and the corresponding objective value $f\\bigl(x^+(t)\\bigr)$.\n\nTest suite (each case specifies $(A,b,\\lambda,l,u,x)$):\n1. Happy-path, interior iterate:\n   - $A = \\begin{bmatrix} 3  0  1 \\\\ 0  2  -1 \\end{bmatrix}$, $b = \\begin{bmatrix} 1 \\\\ -2 \\end{bmatrix}$, $\\lambda = 0.1$,\n   - $l = \\begin{bmatrix} -5 \\\\ -5 \\\\ -5 \\end{bmatrix}$, $u = \\begin{bmatrix} 5 \\\\ 5 \\\\ 5 \\end{bmatrix}$, $x = \\begin{bmatrix} 0.5 \\\\ -0.5 \\\\ 1.0 \\end{bmatrix}$.\n2. Lower-bound activation:\n   - $A = \\begin{bmatrix} 2  -1 \\\\ -1  2 \\end{bmatrix}$, $b = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$, $\\lambda = 0.01$,\n   - $l = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$, $u = \\begin{bmatrix} 10 \\\\ 10 \\end{bmatrix}$, $x = \\begin{bmatrix} 0.1 \\\\ 0.2 \\end{bmatrix}$.\n3. Upper-bound activation:\n   - $A = \\begin{bmatrix} 1  3 \\\\ 2  0 \\end{bmatrix}$, $b = \\begin{bmatrix} 4 \\\\ -1 \\end{bmatrix}$, $\\lambda = 0.05$,\n   - $l = \\begin{bmatrix} -1 \\\\ -1 \\end{bmatrix}$, $u = \\begin{bmatrix} 0.2 \\\\ 0.3 \\end{bmatrix}$, $x = \\begin{bmatrix} 0.19 \\\\ 0.29 \\end{bmatrix}$.\n4. Zero-gradient edge case:\n   - $A = \\begin{bmatrix} 2 \\end{bmatrix}$, $b = \\begin{bmatrix} 4 \\end{bmatrix}$, $\\lambda = 1.0$,\n   - $l = \\begin{bmatrix} 0 \\end{bmatrix}$, $u = \\begin{bmatrix} 10 \\end{bmatrix}$, $x = \\begin{bmatrix} 1.6 \\end{bmatrix}$.\n5. Backtracking shrink in a stiff one-dimensional problem:\n   - $A = \\begin{bmatrix} 3 \\end{bmatrix}$, $b = \\begin{bmatrix} 1 \\end{bmatrix}$, $\\lambda = 1.0$,\n   - $l = \\begin{bmatrix} -5 \\end{bmatrix}$, $u = \\begin{bmatrix} 5 \\end{bmatrix}$, $x = \\begin{bmatrix} 0.0 \\end{bmatrix}$.\n\nAngle units are not applicable. No physical units are involved.\n\nYour program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case result must be the list $[t,f^+]$, where $t$ is the accepted step length and $f^+ = f\\bigl(x^+(t)\\bigr)$ is the objective at the projected point. Both $t$ and $f^+$ must be printed as decimal numbers rounded to six decimal places. The final output format is thus a single line like\n\"[ [t_1,f_1], [t_2,f_2], [t_3,f_3], [t_4,f_4], [t_5,f_5] ]\"\nwith each $t_i$ and $f_i$ rounded to six decimal places and no extra text.\n\nConstants for the backtracking must be fixed as $t_0 = 1$, $\\beta = 0.5$, $\\sigma = 10^{-4}$, $t_{\\min} = 10^{-12}$, identical for all test cases.\n\nDerive all needed expressions from first principles and implement the method accordingly.", "solution": "The user has provided a well-defined problem in the field of numerical optimization, specifically concerning constrained inverse problems. The task is to implement a single iteration of the projected gradient method with an Armijo-type backtracking line search for a bound-constrained quadratic objective function. The problem is scientifically sound, mathematically consistent, and provides all necessary components for a unique solution.\n\nFirst, we must derive the gradient of the objective function, $f(x)$, which is defined as:\n$$\nf(x) \\equiv \\tfrac{1}{2}\\|A x - b\\|_2^2 + \\tfrac{\\lambda}{2}\\|x\\|_2^2\n$$\nHere, $A \\in \\mathbb{R}^{m \\times n}$, $b \\in \\mathbb{R}^{m}$, $x \\in \\mathbb{R}^n$, and $\\lambda > 0$ is a scalar regularization parameter. The squared Euclidean norms can be expressed using inner products:\n$$\nf(x) = \\tfrac{1}{2}(A x - b)^{\\top}(A x - b) + \\tfrac{\\lambda}{2} x^{\\top}x\n$$\nExpanding the first term:\n$$\n(A x - b)^{\\top}(A x - b) = (x^{\\top}A^{\\top} - b^{\\top})(A x - b) = x^{\\top}A^{\\top}A x - x^{\\top}A^{\\top}b - b^{\\top}A x + b^{\\top}b\n$$\nSince $b^{\\top}A x$ is a scalar, it is equal to its transpose $(b^{\\top}A x)^{\\top} = x^{\\top}A^{\\top}b$. Thus, the expression simplifies to:\n$$\nf(x) = \\tfrac{1}{2}(x^{\\top}A^{\\top}A x - 2 b^{\\top}A x + b^{\\top}b) + \\tfrac{\\lambda}{2} x^{\\top}x\n$$\nTo find the gradient $\\nabla f(x)$, we differentiate $f(x)$ with respect to the vector $x$. Using standard results from matrix calculus where $\\nabla_x(x^\\top C x) = (C+C^\\top)x$ and $\\nabla_x(c^\\top x) = c$:\n$$\n\\nabla f(x) = \\tfrac{1}{2}(2 A^{\\top}A x - 2 A^{\\top}b) + \\tfrac{\\lambda}{2}(2x)\n$$\nSimplifying this expression yields the gradient:\n$$\n\\nabla f(x) = A^{\\top}(A x - b) + \\lambda x\n$$\nThis is the analytical gradient we will use in our algorithm.\n\nThe core of the task is to perform one iteration of the projected gradient method. Starting from a feasible point $x$ (i.e., $l \\le x \\le u$), the method proceeds as follows:\n\n1.  **Compute the gradient**: Calculate $g = \\nabla f(x)$ at the current iterate $x$.\n\n2.  **Backtracking Line Search**: Find a suitable step length $t > 0$ that ensures sufficient decrease in the objective function, while respecting the bound constraints. The search starts with an initial step length $t_0 = 1$ and iteratively reduces it by a factor $\\beta = 0.5$ until a condition is met.\n\n    For a given step length $t$, a trial point is first computed by taking a step in the negative gradient direction, and then projecting it back onto the feasible set $[l, u]$. The feasible set is a hyperrectangle (a box), and the projection $\\Pi_{[l,u]}$ is applied componentwise:\n    $$\n    x^+(t) = \\Pi_{[l,u]}(x - t g)\n    $$\n    where $(\\Pi_{[l,u]}(y))_i = \\min\\{\\max\\{y_i, l_i\\}, u_i\\}$.\n\n    The step length $t$ is considered acceptable if it satisfies the Armijo-type sufficient decrease condition, which is adapted for the projected path:\n    $$\n    f(x^+(t)) \\le f(x) + \\sigma g^{\\top}(x^+(t) - x)\n    $$\n    The parameter $\\sigma = 10^{-4}$ controls how much decrease is deemed sufficient. The term $g^{\\top}(x^+(t) - x)$ represents the directional derivative along the feasible arc from $x$ to $x^+(t)$.\n\n    The backtracking process is as follows:\n    a.  Start with $t=t_0 = 1$.\n    b.  Compute $x^+(t)$ and $f(x^+(t))$.\n    c.  Check if the Armijo condition is satisfied.\n    d.  If it is satisfied, the step length $t$ is accepted, and the line search terminates.\n    e.  If it is not satisfied, the step length is reduced: $t \\leftarrow \\beta t$.\n    f.  This process is repeated. The termination also occurs if the step length $t$ falls below a minimum threshold $t_{\\min} = 10^{-12}$. If the loop terminates because $t  t_{\\min}$, the values corresponding to this final small $t$ are returned.\n\nThe final output for each test case will be the accepted step length $t$ and the objective function value at the new point, $f(x^+(t))$.\n\nThe implementation will be done in Python using the `numpy` library for efficient vector and matrix operations. A function will encapsulate the logic for a single iteration, taking the problem data $(A,b,\\lambda,l,u,x)$ as input. This function will compute the gradient, perform the backtracking loop as described, and return the final step size and objective value. The main script will iterate through the provided test suite and format the results as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the projected gradient method.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            # Happy-path, interior iterate\n            \"A\": np.array([[3.0, 0.0, 1.0], [0.0, 2.0, -1.0]]),\n            \"b\": np.array([1.0, -2.0]),\n            \"lambda\": 0.1,\n            \"l\": np.array([-5.0, -5.0, -5.0]),\n            \"u\": np.array([5.0, 5.0, 5.0]),\n            \"x\": np.array([0.5, -0.5, 1.0]),\n        },\n        {\n            # Lower-bound activation\n            \"A\": np.array([[2.0, -1.0], [-1.0, 2.0]]),\n            \"b\": np.array([0.0, 1.0]),\n            \"lambda\": 0.01,\n            \"l\": np.array([0.0, 0.0]),\n            \"u\": np.array([10.0, 10.0]),\n            \"x\": np.array([0.1, 0.2]),\n        },\n        {\n            # Upper-bound activation\n            \"A\": np.array([[1.0, 3.0], [2.0, 0.0]]),\n            \"b\": np.array([4.0, -1.0]),\n            \"lambda\": 0.05,\n            \"l\": np.array([-1.0, -1.0]),\n            \"u\": np.array([0.2, 0.3]),\n            \"x\": np.array([0.19, 0.29]),\n        },\n        {\n            # Zero-gradient edge case\n            \"A\": np.array([[2.0]]),\n            \"b\": np.array([4.0]),\n            \"lambda\": 1.0,\n            \"l\": np.array([0.0]),\n            \"u\": np.array([10.0]),\n            \"x\": np.array([1.6]),\n        },\n        {\n            # Backtracking shrink in a stiff one-dimensional problem\n            \"A\": np.array([[3.0]]),\n            \"b\": np.array([1.0]),\n            \"lambda\": 1.0,\n            \"l\": np.array([-5.0]),\n            \"u\": np.array([5.0]),\n            \"x\": np.array([0.0]),\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        t, f_plus = projected_gradient_iteration(\n            case[\"A\"], case[\"b\"], case[\"lambda\"],\n            case[\"l\"], case[\"u\"], case[\"x\"]\n        )\n        results.append(f\"[{t:.6f}, {f_plus:.6f}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\ndef objective_function(A, b, lam, x):\n    \"\"\"Computes the Tikhonov-regularized objective function.\"\"\"\n    residual = A @ x - b\n    loss = 0.5 * np.linalg.norm(residual)**2\n    reg = (lam / 2.0) * np.linalg.norm(x)**2\n    return loss + reg\n\ndef gradient(A, b, lam, x):\n    \"\"\"Computes the gradient of the objective function.\"\"\"\n    return A.T @ (A @ x - b) + lam * x\n\ndef projection(y, l, u):\n    \"\"\"Projects a vector y onto the box [l, u].\"\"\"\n    return np.minimum(np.maximum(y, l), u)\n\ndef projected_gradient_iteration(A, b, lam, l, u, x):\n    \"\"\"\n    Performs one iteration of projected gradient descent with Armijo backtracking.\n    \"\"\"\n    # Backtracking parameters\n    t_0 = 1.0\n    beta = 0.5\n    sigma = 1e-4\n    t_min = 1e-12\n\n    # Compute values at current point x\n    f_x = objective_function(A, b, lam, x)\n    grad_f_x = gradient(A, b, lam, x)\n    \n    t = t_0\n    while True:\n        # Compute projected trial point\n        x_plus_t = projection(x - t * grad_f_x, l, u)\n        \n        # Compute objective at trial point\n        f_x_plus_t = objective_function(A, b, lam, x_plus_t)\n        \n        # Check Armijo condition\n        armijo_rhs = f_x + sigma * np.dot(grad_f_x, x_plus_t - x)\n        \n        if f_x_plus_t = armijo_rhs:\n            # Step size is accepted\n            return t, f_x_plus_t\n        \n        # If condition is not met, check termination for small step\n        if t  t_min:\n            # Terminate because step size is too small, returning last tried values\n            return t, f_x_plus_t\n            \n        # Reduce step size\n        t *= beta\n\nsolve()\n```", "id": "3371700"}, {"introduction": "The power of projected-gradient methods lies in the projection operator, but its form is not always trivial. This practice moves beyond simple box constraints to tackle the projection onto a Second-Order Cone (SOC), a structure central to many modern regularization techniques like group sparsity [@problem_id:3371711]. Deriving this projection from first principles using Karush-Kuhn-Tucker (KKT) conditions is a crucial skill, equipping you to design and analyze optimization algorithms for problems with more sophisticated geometric constraints.", "problem": "Consider a projected-gradient step that arises in a constrained formulation of an inverse problem in data assimilation, where a slack variable $t \\in \\mathbb{R}$ and a state increment $u \\in \\mathbb{R}^{n-1}$ are constrained by the Second-Order Cone (SOC) $\\mathcal{K} = \\{(s,x) \\in \\mathbb{R} \\times \\mathbb{R}^{n-1} : \\|x\\|_{2} \\le s\\}$. The Euclidean projection onto a nonempty, closed, and convex set is defined as the minimizer of the squared Euclidean distance. Starting from this definition, and using only first principles of convex optimization (existence and uniqueness of projections onto closed convex sets, convexity of norms, and Karush–Kuhn–Tucker optimality conditions), derive the explicit formula for the Euclidean projection $\\Pi_{\\mathcal{K}}(t,u)$ of an arbitrary point $(t,u) \\in \\mathbb{R} \\times \\mathbb{R}^{n-1}$ onto $\\mathcal{K}$. Your derivation must systematically characterize and justify all three regimes $t > \\|u\\|_{2}$, $t  -\\|u\\|_{2}$, and the remaining case, including the value of the Lagrange multiplier and the structure of the optimizer.\n\nFinally, for the specific instance with $n = 4$ and $(t,u) = (1,(2,-1,2))$, compute the projection $\\Pi_{\\mathcal{K}}(t,u)$ exactly. Do not round. Express your final answer as a single explicit vector expression with four entries, corresponding to the projected scalar followed by the projected $(n-1)$-dimensional vector, with no units.", "solution": "The problem asks for the derivation of the formula for the Euclidean projection of a point $(t,u) \\in \\mathbb{R} \\times \\mathbb{R}^{n-1}$ onto the second-order cone $\\mathcal{K}$, and then to apply this formula to a specific case. The second-order cone is defined as $\\mathcal{K} = \\{(s,x) \\in \\mathbb{R} \\times \\mathbb{R}^{n-1} : \\|x\\|_{2} \\le s\\}$.\n\nBy definition, the Euclidean projection $\\Pi_{\\mathcal{K}}(t,u)$ is the unique point $(\\hat{s}, \\hat{x}) \\in \\mathcal{K}$ that minimizes the squared Euclidean distance to $(t,u)$. This can be formulated as a convex optimization problem:\n$$\n\\begin{aligned}\n \\underset{s,x}{\\text{minimize}}   f(s,x) = \\frac{1}{2} \\|(s,x) - (t,u)\\|_2^2 = \\frac{1}{2} ((s-t)^2 + \\|x-u\\|_2^2) \\\\\n \\text{subject to}   g(s,x) = \\|x\\|_2 - s \\le 0\n\\end{aligned}\n$$\nThe objective function $f(s,x)$ is strictly convex, and the constraint set $\\mathcal{K}$ is a non-empty, closed, and convex set. Therefore, a unique solution exists. We use the Karush–Kuhn–Tucker (KKT) conditions to find this solution.\n\nThe Lagrangian function for this problem is:\n$$\n\\mathcal{L}(s, x, \\lambda) = \\frac{1}{2} (s-t)^2 + \\frac{1}{2} \\|x-u\\|_2^2 + \\lambda (\\|x\\|_2 - s)\n$$\nwhere $\\lambda \\in \\mathbb{R}$ is the Lagrange multiplier associated with the inequality constraint. The KKT conditions for an optimal point $(\\hat{s}, \\hat{x})$ and a multiplier $\\lambda$ are:\n\n$1$. **Stationarity**: The gradient of the Lagrangian with respect to the primal variables must be zero.\n$$\n\\nabla_s \\mathcal{L}(\\hat{s}, \\hat{x}, \\lambda) = (\\hat{s}-t) - \\lambda = 0\n$$\n$$\n\\nabla_x \\mathcal{L}(\\hat{s}, \\hat{x}, \\lambda) = (\\hat{x}-u) + \\lambda \\nabla (\\|\\hat{x}\\|_2) = 0\n$$\n$2$. **Primal Feasibility**: The point $(\\hat{s}, \\hat{x})$ must be in the feasible set.\n$$\n\\|\\hat{x}\\|_2 - \\hat{s} \\le 0\n$$\n$3$. **Dual Feasibility**: The Lagrange multiplier for an inequality constraint of the form $g(x) \\le 0$ must be non-negative.\n$$\n\\lambda \\ge 0\n$$\n$4$. **Complementary Slackness**:\n$$\n\\lambda (\\|\\hat{x}\\|_2 - \\hat{s}) = 0\n$$\n\nFrom complementary slackness, either $\\lambda=0$ or $\\|\\hat{x}\\|_2 - \\hat{s} = 0$. We analyze these cases to characterize the solution.\n\n**Regime 1: The point $(t,u)$ is inside the cone, $t \\ge \\|u\\|_2$.**\nLet us test the hypothesis that the projection is the point itself, $(\\hat{s}, \\hat{x}) = (t,u)$, which implies that the constraint is inactive. According to complementary slackness, this would require $\\lambda=0$.\nWe check if $(\\hat{s}, \\hat{x}) = (t,u)$ and $\\lambda=0$ satisfy the KKT conditions, under the assumption $t \\ge \\|u\\|_2$.\n$1$. Stationarity:\n$\\hat{s}-t-\\lambda = t-t-0 = 0$. (Satisfied)\nThe stationarity condition for $x$ becomes $\\hat{x}-u = t-u = 0$, which is satisfied by our choice.\n$2$. Primal Feasibility: $\\|\\hat{x}\\|_2 - \\hat{s} = \\|u\\|_2 - t \\le 0$. This is true by our initial assumption for this regime.\n$3$. Dual Feasibility: $\\lambda=0 \\ge 0$. (Satisfied)\n$4$. Complementary Slackness: $\\lambda(\\|\\hat{x}\\|_2-\\hat{s})=0(\\|u\\|_2-t)=0$. (Satisfied)\nAll KKT conditions are satisfied. Thus, if $t \\ge \\|u\\|_2$, the point is its own projection.\nThe optimizer is $(\\hat{s}, \\hat{x}) = (t,u)$. The Lagrange multiplier is $\\lambda=0$. This covers the case $t > \\|u\\|_2$ as requested.\n\n**Case 2: The point $(t,u)$ is outside the cone.**\nThis implies that the projection $(\\hat{s}, \\hat{x})$ must lie on the boundary of $\\mathcal{K}$, so $\\|\\hat{x}\\|_2 = \\hat{s}$. By complementary slackness, this allows for $\\lambda>0$.\n\n**Regime 2: The projection is the apex of the cone, $t \\le -\\|u\\|_2$.**\nLet us test the hypothesis that the projection is the apex $(\\hat{s}, \\hat{x}) = (0,0)$.\n$1$. Stationarity:\nFrom $\\hat{s}-t-\\lambda=0$ with $\\hat{s}=0$, we get $\\lambda = -t$.\nThe derivative of the norm $\\|x\\|_2$ at $x=0$ is not a single vector but a subdifferential set, $\\partial\\|0\\|_2 = \\{z \\in \\mathbb{R}^{n-1} : \\|z\\|_2 \\le 1\\}$. The stationarity condition for $x$ becomes $0-u + \\lambda z = 0$ for some $z \\in \\partial\\|0\\|_2$, which means $u=\\lambda z$.\n$2$. Primal Feasibility: $\\|\\hat{x}\\|_2 - \\hat{s} = \\|0\\|_2 - 0 = 0 \\le 0$. (Satisfied)\n$3$. Dual Feasibility: $\\lambda=-t \\ge 0$, which implies $t \\le 0$.\n$4$. Complementary Slackness: $\\lambda (0-0)=0$. (Satisfied)\nThe conditions require $u=\\lambda z = (-t)z$ and $t \\le 0$. Taking the Euclidean norm gives $\\|u\\|_2 = \\|(-t)z\\|_2 = |-t| \\|z\\|_2$. Since $t \\le 0$, we have $|-t|=-t$. Thus, $\\|u\\|_2 = (-t)\\|z\\|_2$. As $\\|z\\|_2 \\le 1$, this leads to the condition $\\|u\\|_2 \\le -t$, or $t \\le -\\|u\\|_2$.\nSo, if $t \\le -\\|u\\|_2$, the projection is $(\\hat{s}, \\hat{x}) = (0,0)$.\nThe optimizer is $(\\hat{s}, \\hat{x}) = (0,0)$. The Lagrange multiplier is $\\lambda=-t$. This covers the case $t  -\\|u\\|_2$ as requested.\n\n**Regime 3: The projection is on the side of the cone, $-\\|u\\|_2  t  \\|u\\|_2$.**\nIn this case, the projection is on the boundary, so $\\|\\hat{x}\\|_2 = \\hat{s}$, but is not the apex, so $\\hat{x} \\ne 0$. The gradient $\\nabla (\\|\\hat{x}\\|_2)$ is well-defined and equals $\\hat{x}/\\|\\hat{x}\\|_2$. Let's assume $u \\ne 0$, as $u=0$ implies $t=0$ for this regime, and $(0,0)$ projects to itself.\nThe KKT conditions are:\n$1$. $\\hat{s} = t+\\lambda$.\n$2$. $\\hat{x}-u + \\lambda \\frac{\\hat{x}}{\\|\\hat{x}\\|_2}=0 \\implies u = \\hat{x}\\left(1+\\frac{\\lambda}{\\|\\hat{x}\\|_2}\\right)$. This shows $u$ and $\\hat{x}$ are collinear. We can write $\\hat{x}=\\alpha u$ for some $\\alpha>0$.\n$3$. $\\lambda>0$.\n$4$. $\\|\\hat{x}\\|_2 = \\hat{s}$.\nSubstituting $\\hat{x}=\\alpha u$ into the second stationarity condition, we get $u = \\alpha u(1+\\frac{\\lambda}{\\|\\alpha u\\|_2}) \\implies 1 = \\alpha(1+\\frac{\\lambda}{\\alpha\\|u\\|_2}) = \\alpha + \\frac{\\lambda}{\\|u\\|_2}$. Thus, $\\alpha=1-\\frac{\\lambda}{\\|u\\|_2}$.\nNow we use the boundary condition $\\|\\hat{x}\\|_2 = \\hat{s}$ along with $\\hat{s}=t+\\lambda$:\n$\\|\\alpha u\\|_2 = t+\\lambda \\implies \\alpha\\|u\\|_2 = t+\\lambda$.\nSubstituting the expression for $\\alpha$:\n$(1-\\frac{\\lambda}{\\|u\\|_2})\\|u\\|_2 = t+\\lambda \\implies \\|u\\|_2 - \\lambda = t+\\lambda$.\nSolving for $\\lambda$ yields $2\\lambda = \\|u\\|_2-t$, so $\\lambda = \\frac{\\|u\\|_2-t}{2}$.\nThe condition $\\lambda>0$ implies $\\|u\\|_2-t>0$, or $t\\|u\\|_2$. Also, for $\\alpha>0$ we need $\\lambda  \\|u\\|_2$, which implies $\\frac{\\|u\\|_2-t}{2}  \\|u\\|_2 \\implies \\|u\\|_2-t  2\\|u\\|_2 \\implies -t  \\|u\\|_2$, or $t > -\\|u\\|_2$.\nThis confirms the validity of this case for $-\\|u\\|_2  t  \\|u\\|_2$.\nNow we find the optimizer $(\\hat{s}, \\hat{x})$:\n$\\hat{s} = t+\\lambda = t + \\frac{\\|u\\|_2-t}{2} = \\frac{t+\\|u\\|_2}{2}$.\nTo find $\\hat{x}$, we first find $\\alpha$:\n$\\alpha = 1 - \\frac{\\lambda}{\\|u\\|_2} = 1 - \\frac{(\\|u\\|_2-t)/2}{\\|u\\|_2} = 1 - \\frac{\\|u\\|_2-t}{2\\|u\\|_2} = \\frac{2\\|u\\|_2 - (\\|u\\|_2-t)}{2\\|u\\|_2} = \\frac{t+\\|u\\|_2}{2\\|u\\|_2}$.\n$\\hat{x} = \\alpha u = \\left(\\frac{t+\\|u\\|_2}{2\\|u\\|_2}\\right) u$.\nThe optimizer is $(\\hat{s}, \\hat{x}) = \\left(\\frac{t+\\|u\\|_2}{2}, \\left(\\frac{t+\\|u\\|_2}{2\\|u\\|_2}\\right)u\\right)$.\nThe Lagrange multiplier is $\\lambda = \\frac{\\|u\\|_2-t}{2}$.\n\n**Specific Instance Calculation**\nWe are given $n=4$ and the point $(t,u) = (1, (2,-1,2))$.\nFirst, we compute the norm of $u$:\n$$\n\\|u\\|_2 = \\sqrt{2^2+(-1)^2+2^2} = \\sqrt{4+1+4} = \\sqrt{9} = 3\n$$\nWe have $t=1$. We compare $t$ to $\\|u\\|_2$:\n$t=1$ and $\\|u\\|_2=3$.\nSince $-3 \\le 1 \\le 3$, we have $-\\|u\\|_2 \\le t \\le \\|u\\|_2$. This falls into Regime $3$.\nThe projection is given by the formula:\n$$\n(\\hat{s}, \\hat{x}) = \\left(\\frac{t+\\|u\\|_2}{2}, \\left(\\frac{t+\\|u\\|_2}{2\\|u\\|_2}\\right)u\\right)\n$$\nSubstituting the values $t=1$, $\\|u\\|_2=3$, and $u=(2,-1,2)$:\nThe scalar component $\\hat{s}$ is:\n$$\n\\hat{s} = \\frac{1+3}{2} = \\frac{4}{2} = 2\n$$\nThe vector component $\\hat{x}$ is:\n$$\n\\hat{x} = \\left(\\frac{1+3}{2 \\cdot 3}\\right)u = \\frac{4}{6}u = \\frac{2}{3}u = \\frac{2}{3}(2, -1, 2) = \\left(\\frac{4}{3}, -\\frac{2}{3}, \\frac{4}{3}\\right)\n$$\nThe projected point $\\Pi_{\\mathcal{K}}(t,u)$ is a vector in $\\mathbb{R}^4$ formed by $(\\hat{s}, \\hat{x})$.\n$$\n\\Pi_{\\mathcal{K}}(1, (2,-1,2)) = \\left(2, \\frac{4}{3}, -\\frac{2}{3}, \\frac{4}{3}\\right)\n$$\nThis is the final result for the specific instance.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2  \\frac{4}{3}  -\\frac{2}{3}  \\frac{4}{3}\n\\end{pmatrix}\n}\n$$", "id": "3371711"}, {"introduction": "Many cutting-edge inverse problems involve non-smooth regularizers like Total Variation (TV), for which simple projected gradient methods are inefficient. This exercise introduces a more powerful tool: a primal-dual splitting algorithm, specifically the Chambolle–Pock method [@problem_id:3371670]. By executing a single iteration by hand, you will see how the problem is lifted into a primal-dual space, where complex objectives are decoupled into simpler steps involving a gradient update and a projection, giving you a concrete understanding of how these advanced algorithms operate.", "problem": "Consider the one-dimensional total variation regularized least-squares inverse problem on a uniform grid with three unknowns. Let the primal variable be $u \\in \\mathbb{R}^{3}$, the data be $y \\in \\mathbb{R}^{3}$, and the discrete forward difference operator $D \\in \\mathbb{R}^{2 \\times 3}$ be\n$$\nD \\;=\\; \\begin{pmatrix}\n-1  1  0\\\\\n0  -1  1\n\\end{pmatrix}.\n$$\nConsider the composite convex objective\n$$\n\\min_{u \\in \\mathbb{R}^{3}} \\; h(u) \\;+\\; g(Du),\n$$\nwith the data fidelity $h(u) = \\tfrac{1}{2}\\|u - y\\|_{2}^{2}$ and the regularizer $g(z) = \\lambda \\|z\\|_{1}$ for $z \\in \\mathbb{R}^{2}$ and $\\lambda > 0$. Work with the saddle-point formulation derived from convex conjugacy of $g$ and use a primal-dual splitting scheme in which the dual variable is updated by Euclidean projection onto an $\\ell_{\\infty}$ ball and the primal variable is updated by a single explicit gradient descent step on $h$ plus the linear coupling term.\n\nUse the following concrete data and parameters:\n- $y = \\begin{pmatrix} 0 \\\\ 1 \\\\ 2 \\end{pmatrix}$,\n- $\\lambda = 1.5$,\n- primal step size $\\tau = 0.2$,\n- dual step size $\\sigma = 1.0$,\n- extrapolation parameter $\\theta = 1$ for the over-relaxed primal variable,\n- initialization $u^{0} = \\begin{pmatrix} 1 \\\\ -2 \\\\ 3 \\end{pmatrix}$, $u^{-1} = u^{0}$, and $p^{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$.\n\nStarting from the definitions of convex conjugate, saddle-point formulation, and projection onto a closed convex set, derive the single-iteration update $(u^{0}, p^{0}) \\mapsto (u^{1}, p^{1})$ of the Primal-Dual Hybrid Gradient (PDHG) method (also known as the Chambolle–Pock scheme) specialized to this problem, where the primal update is taken as one explicit gradient descent step on $h$ and the dual update is the Euclidean projection of an affine argument onto the $\\ell_{\\infty}$ ball associated with $g^{\\ast}$. Carry out all calculations explicitly for the given data and parameters.\n\nReport as your final answer the exact value of the second component of $u^{1}$, namely $u^{1}_{2}$. No rounding is required, and no units are needed.", "solution": "The problem is to find the next iterate $(u^1, p^1)$ of a primal-dual algorithm for the optimization problem\n$$\n\\min_{u \\in \\mathbb{R}^{3}} \\frac{1}{2}\\|u - y\\|_{2}^{2} + \\lambda\\|Du\\|_{1}.\n$$\nThis is an instance of the general problem $\\min_u h(u) + g(Du)$. The problem can be reformulated as a saddle-point problem:\n$$\n\\min_{u} \\max_{p} \\left( h(u) + \\langle Du, p \\rangle - g^{\\ast}(p) \\right),\n$$\nwhere $g^{\\ast}(p)$ is the convex conjugate of $g(z) = \\lambda \\|z\\|_{1}$. The conjugate function is defined as\n$$\ng^{\\ast}(p) = \\sup_{z \\in \\mathbb{R}^2} (\\langle p, z \\rangle - \\lambda \\|z\\|_{1}) = \\sup_{z \\in \\mathbb{R}^2} \\sum_{i=1}^2 (p_i z_i - \\lambda |z_i|).\n$$\nThis supremum is finite ($0$) if and only if $|p_i| \\le \\lambda$ for all $i$. Otherwise, it is infinite. Therefore, $g^{\\ast}(p)$ is the indicator function of the set $C = \\{p \\in \\mathbb{R}^2 \\mid \\|p\\|_{\\infty} \\le \\lambda\\}$.\n$$\ng^{\\ast}(p) = I_C(p) = \\begin{cases} 0  \\text{if } \\|p\\|_{\\infty} \\le \\lambda \\\\ \\infty  \\text{otherwise} \\end{cases}.\n$$\nThe problem specifies a primal-dual scheme. Starting from $(u^k, u^{k-1}, p^k)$, the next iterate $(u^{k+1}, p^{k+1})$ is computed as follows:\n\n1.  **Extrapolation**: An over-relaxed primal variable $\\bar{u}^k$ is computed.\n    $$\n    \\bar{u}^k = u^k + \\theta(u^k - u^{k-1})\n    $$\n\n2.  **Dual Update**: The dual variable $p^{k+1}$ is updated using the proximal operator of $g^\\ast$.\n    $$\n    p^{k+1} = \\text{prox}_{\\sigma g^{\\ast}}(p^k + \\sigma D \\bar{u}^k)\n    $$\n    Since $g^{\\ast}$ is the indicator function of the convex set $C$, its proximal operator is the Euclidean projection onto $C$, denoted $\\Pi_C$.\n    $$\n    p^{k+1} = \\Pi_C(p^k + \\sigma D \\bar{u}^k)\n    $$\n    The projection onto the $\\ell_{\\infty}$-ball of radius $\\lambda$ is given component-wise by $(\\Pi_C(q))_i = \\text{sign}(q_i) \\min(|q_i|, \\lambda)$.\n\n3.  **Primal Update**: The primal variable $u^{k+1}$ is updated by an explicit gradient step on the Lagrangian with respect to $u$. The problem states this is \"a single explicit gradient descent step on $h$ plus the linear coupling term\". This corresponds to:\n    $$\n    u^{k+1} = u^k - \\tau (\\nabla_u \\mathcal{L}(u^k, p^{k+1})) = u^k - \\tau (\\nabla h(u^k) + D^T p^{k+1})\n    $$\n    The gradient of the data fidelity term $h(u) = \\frac{1}{2}\\|u - y\\|_{2}^{2}$ is $\\nabla h(u) = u-y$. So the update is:\n    $$\n    u^{k+1} = u^k - \\tau(u^k - y + D^T p^{k+1})\n    $$\n\nWe now apply these steps for the first iteration ($k=0$) using the provided data.\nThe parameters are $\\lambda = 1.5 = \\frac{3}{2}$, $\\tau=0.2 = \\frac{1}{5}$, $\\sigma = 1.0$, and $\\theta = 1.0$.\nThe initial values are $u^0 = \\begin{pmatrix} 1 \\\\ -2 \\\\ 3 \\end{pmatrix}$, $u^{-1} = u^0$, $p^0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$, and $y = \\begin{pmatrix} 0 \\\\ 1 \\\\ 2 \\end{pmatrix}$.\n\n**Step 1: Extrapolation**\n$$\n\\bar{u}^0 = u^0 + \\theta(u^0 - u^{-1}) = u^0 + 1.0(u^0 - u^0) = u^0 = \\begin{pmatrix} 1 \\\\ -2 \\\\ 3 \\end{pmatrix}\n$$\n\n**Step 2: Dual Update for $p^1$**\nWe first compute the argument of the projection operator.\n$$\np^0 + \\sigma D \\bar{u}^0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} + 1.0 \\begin{pmatrix} -1  1  0\\\\ 0  -1  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -2 \\\\ 3 \\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} (-1)(1) + (1)(-2) + (0)(3) \\\\ (0)(1) + (-1)(-2) + (1)(3) \\end{pmatrix} = \\begin{pmatrix} -1 - 2 \\\\ 2 + 3 \\end{pmatrix} = \\begin{pmatrix} -3 \\\\ 5 \\end{pmatrix}\n$$\nNow, we project this vector onto the $\\ell_{\\infty}$-ball $C = \\{ p \\in \\mathbb{R}^2 \\mid \\|p\\|_{\\infty} \\le \\frac{3}{2} \\}$.\n$$\np_1^1 = \\text{sign}(-3) \\min(|-3|, \\tfrac{3}{2}) = -1 \\cdot \\frac{3}{2} = -\\frac{3}{2}\n$$\n$$\np_2^1 = \\text{sign}(5) \\min(|5|, \\tfrac{3}{2}) = 1 \\cdot \\frac{3}{2} = \\frac{3}{2}\n$$\nSo, the updated dual variable is $p^1 = \\begin{pmatrix} -3/2 \\\\ 3/2 \\end{pmatrix}$.\n\n**Step 3: Primal Update for $u^1$**\nWe use the update rule $u^1 = u^0 - \\tau(u^0 - y + D^T p^1)$. First, we compute the term in the parentheses.\nThe transpose of $D$ is $D^T = \\begin{pmatrix} -1  0 \\\\ 1  -1 \\\\ 0  1 \\end{pmatrix}$.\n$$\nu^0 - y = \\begin{pmatrix} 1 \\\\ -2 \\\\ 3 \\end{pmatrix} - \\begin{pmatrix} 0 \\\\ 1 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -3 \\\\ 1 \\end{pmatrix}\n$$\n$$\nD^T p^1 = \\begin{pmatrix} -1  0 \\\\ 1  -1 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} -3/2 \\\\ 3/2 \\end{pmatrix} = \\begin{pmatrix} (-1)(-3/2) + (0)(3/2) \\\\ (1)(-3/2) + (-1)(3/2) \\\\ (0)(-3/2) + (1)(3/2) \\end{pmatrix} = \\begin{pmatrix} 3/2 \\\\ -3/2 - 3/2 \\\\ 3/2 \\end{pmatrix} = \\begin{pmatrix} 3/2 \\\\ -3 \\\\ 3/2 \\end{pmatrix}\n$$\nSumming these terms:\n$$\nu^0 - y + D^T p^1 = \\begin{pmatrix} 1 \\\\ -3 \\\\ 1 \\end{pmatrix} + \\begin{pmatrix} 3/2 \\\\ -3 \\\\ 3/2 \\end{pmatrix} = \\begin{pmatrix} 1 + 3/2 \\\\ -3 - 3 \\\\ 1 + 3/2 \\end{pmatrix} = \\begin{pmatrix} 5/2 \\\\ -6 \\\\ 5/2 \\end{pmatrix}\n$$\nNow, we complete the update for $u^1$ with $\\tau = 1/5$.\n$$\nu^1 = u^0 - \\tau \\begin{pmatrix} 5/2 \\\\ -6 \\\\ 5/2 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -2 \\\\ 3 \\end{pmatrix} - \\frac{1}{5} \\begin{pmatrix} 5/2 \\\\ -6 \\\\ 5/2 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -2 \\\\ 3 \\end{pmatrix} - \\begin{pmatrix} 1/2 \\\\ -6/5 \\\\ 1/2 \\end{pmatrix}\n$$\n$$\nu^1 = \\begin{pmatrix} 1 - 1/2 \\\\ -2 - (-6/5) \\\\ 3 - 1/2 \\end{pmatrix} = \\begin{pmatrix} 1/2 \\\\ -10/5 + 6/5 \\\\ 5/2 \\end{pmatrix} = \\begin{pmatrix} 1/2 \\\\ -4/5 \\\\ 5/2 \\end{pmatrix}\n$$\nThe problem asks for the second component of $u^1$, which is $u^1_2$.\n$$\nu^1_2 = -\\frac{4}{5}\n$$", "answer": "$$\\boxed{-\\frac{4}{5}}$$", "id": "3371670"}]}