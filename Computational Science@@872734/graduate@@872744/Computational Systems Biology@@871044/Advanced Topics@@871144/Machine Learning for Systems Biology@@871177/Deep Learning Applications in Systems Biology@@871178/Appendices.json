{"hands_on_practices": [{"introduction": "To model systems defined by interactions, such as protein signaling pathways, we need architectures that explicitly use the network structure. Graph Neural Networks (GNNs) are designed for this purpose, operating by passing information between connected nodes. This first practice invites you to perform the core calculation of a Graph Convolutional Network (GCN) layer by hand, demystifying how these models learn by aggregating features from a node's local neighborhood [@problem_id:3299390].", "problem": "Consider a small protein signaling network represented as an undirected graph where nodes correspond to proteins and edges indicate experimentally observed physical interactions. Let the network have $3$ proteins labeled $P_1$, $P_2$, and $P_3$, with the symmetric adjacency matrix $\\mathbf{A}$ given by\n$$\n\\mathbf{A}=\\begin{pmatrix}\n0 & 1 & 0 \\\\\n1 & 0 & 1 \\\\\n0 & 1 & 0\n\\end{pmatrix}.\n$$\nIn a Graph Convolutional Network (GCN), messages are propagated with self-loops and symmetric normalization. Self-loops are added by forming $\\tilde{\\mathbf{A}}=\\mathbf{A}+\\mathbf{I}$, and the degree matrix $\\tilde{\\mathbf{D}}$ is defined by $\\tilde{D}_{ii}=\\sum_{j} \\tilde{A}_{ij}$. Symmetric normalization uses the operator $\\tilde{\\mathbf{D}}^{-1/2}\\tilde{\\mathbf{A}}\\tilde{\\mathbf{D}}^{-1/2}$. The node feature matrix $\\mathbf{H}\\in\\mathbb{R}^{3\\times 2}$ collects two biologically meaningful features per protein (for instance, a basal activity and a phosphorylation-associated activity), and the layer’s weight matrix is $\\mathbf{W}\\in\\mathbb{R}^{2\\times 1}$. The nonlinear activation is the Rectified Linear Unit (ReLU), defined by $\\sigma(x)=\\max\\{0,x\\}$.\n\nSuppose the initial node feature matrix and the weight matrix are\n$$\n\\mathbf{H}=\\begin{pmatrix}\n2 & 0 \\\\\n1 & 1 \\\\\n0 & 2\n\\end{pmatrix},\n\\qquad\n\\mathbf{W}=\\begin{pmatrix}\n1 \\\\\n-2\n\\end{pmatrix}.\n$$\nUsing one GCN layer with self-loops and symmetric normalization as described, compute the single activated scalar feature of protein $P_2$ (the second node) after the layer. Express your answer exactly as a closed-form real number. No rounding is required, and no units are needed.", "solution": "The problem asks for the computation of the activated scalar feature for protein $P_2$ after a single layer of a Graph Convolutional Network (GCN). The layer's operation is defined by the propagation rule:\n$$\n\\mathbf{H}' = \\sigma(\\tilde{\\mathbf{D}}^{-1/2}\\tilde{\\mathbf{A}}\\tilde{\\mathbf{D}}^{-1/2} \\mathbf{H} \\mathbf{W})\n$$\nwhere $\\mathbf{H}$ is the input feature matrix, $\\mathbf{W}$ is the weight matrix, $\\sigma$ is the ReLU activation function, and the term $\\tilde{\\mathbf{D}}^{-1/2}\\tilde{\\mathbf{A}}\\tilde{\\mathbf{D}}^{-1/2}$ is the symmetrically normalized adjacency matrix with self-loops.\n\nFirst, we establish the given matrices. The adjacency matrix $\\mathbf{A}$ for the $3$-protein network is:\n$$\n\\mathbf{A}=\\begin{pmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 1 & 0 \\end{pmatrix}\n$$\nThe initial node feature matrix $\\mathbf{H} \\in \\mathbb{R}^{3\\times 2}$ and the weight matrix $\\mathbf{W} \\in \\mathbb{R}^{2\\times 1}$ are:\n$$\n\\mathbf{H}=\\begin{pmatrix}\n2 & 0 \\\\\n1 & 1 \\\\\n0 & 2\n\\end{pmatrix},\n\\qquad\n\\mathbf{W}=\\begin{pmatrix}\n1 \\\\\n-2\n\\end{pmatrix}\n$$\n\nThe calculation proceeds in several steps:\n\n1.  **Add self-loops to the adjacency matrix.**\n    This is done by computing $\\tilde{\\mathbf{A}} = \\mathbf{A} + \\mathbf{I}$, where $\\mathbf{I}$ is the $3 \\times 3$ identity matrix.\n    $$\n    \\tilde{\\mathbf{A}} = \\begin{pmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 1 & 0 \\end{pmatrix} + \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 1 & 0 \\\\ 1 & 1 & 1 \\\\ 0 & 1 & 1 \\end{pmatrix}\n    $$\n\n2.  **Compute the degree matrix $\\tilde{\\mathbf{D}}$.**\n    The diagonal entries of $\\tilde{\\mathbf{D}}$ are the row sums of $\\tilde{\\mathbf{A}}$.\n    -   $\\tilde{D}_{11} = 1 + 1 + 0 = 2$\n    -   $\\tilde{D}_{22} = 1 + 1 + 1 = 3$\n    -   $\\tilde{D}_{33} = 0 + 1 + 1 = 2$\n    So, the degree matrix is:\n    $$\n    \\tilde{\\mathbf{D}} = \\begin{pmatrix} 2 & 0 & 0 \\\\ 0 & 3 & 0 \\\\ 0 & 0 & 2 \\end{pmatrix}\n    $$\n\n3.  **Compute the symmetrically normalized adjacency matrix $\\hat{\\mathbf{A}} = \\tilde{\\mathbf{D}}^{-1/2}\\tilde{\\mathbf{A}}\\tilde{\\mathbf{D}}^{-1/2}$.**\n    First, we find $\\tilde{\\mathbf{D}}^{-1/2}$ by taking the inverse square root of the diagonal elements of $\\tilde{\\mathbf{D}}$.\n    $$\n    \\tilde{\\mathbf{D}}^{-1/2} = \\begin{pmatrix} 2^{-1/2} & 0 & 0 \\\\ 0 & 3^{-1/2} & 0 \\\\ 0 & 0 & 2^{-1/2} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} & 0 & 0 \\\\ 0 & \\frac{1}{\\sqrt{3}} & 0 \\\\ 0 & 0 & \\frac{1}{\\sqrt{2}} \\end{pmatrix}\n    $$\n    Now we perform the matrix multiplication:\n    $$\n    \\hat{\\mathbf{A}} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} & 0 & 0 \\\\ 0 & \\frac{1}{\\sqrt{3}} & 0 \\\\ 0 & 0 & \\frac{1}{\\sqrt{2}} \\end{pmatrix} \\begin{pmatrix} 1 & 1 & 0 \\\\ 1 & 1 & 1 \\\\ 0 & 1 & 1 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{\\sqrt{2}} & 0 & 0 \\\\ 0 & \\frac{1}{\\sqrt{3}} & 0 \\\\ 0 & 0 & \\frac{1}{\\sqrt{2}} \\end{pmatrix}\n    $$\n    $$\n    \\hat{\\mathbf{A}} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} & 0 \\\\ \\frac{1}{\\sqrt{3}} & \\frac{1}{\\sqrt{3}} & \\frac{1}{\\sqrt{3}} \\\\ 0 & \\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{\\sqrt{2}} & 0 & 0 \\\\ 0 & \\frac{1}{\\sqrt{3}} & 0 \\\\ 0 & 0 & \\frac{1}{\\sqrt{2}} \\end{pmatrix}\n    $$\n    $$\n    \\hat{\\mathbf{A}} = \\begin{pmatrix} \\frac{1}{2} & \\frac{1}{\\sqrt{6}} & 0 \\\\ \\frac{1}{\\sqrt{6}} & \\frac{1}{3} & \\frac{1}{\\sqrt{6}} \\\\ 0 & \\frac{1}{\\sqrt{6}} & \\frac{1}{2} \\end{pmatrix}\n    $$\n\n4.  **Compute the linear transformation part, $\\mathbf{Z} = \\hat{\\mathbf{A}}\\mathbf{H}\\mathbf{W}$.**\n    It is computationally efficient to first calculate the product $\\mathbf{X} = \\mathbf{H}\\mathbf{W}$.\n    $$\n    \\mathbf{X} = \\begin{pmatrix} 2 & 0 \\\\ 1 & 1 \\\\ 0 & 2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} = \\begin{pmatrix} (2)(1) + (0)(-2) \\\\ (1)(1) + (1)(-2) \\\\ (0)(1) + (2)(-2) \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -1 \\\\ -4 \\end{pmatrix}\n    $$\n    Now we compute $\\mathbf{Z} = \\hat{\\mathbf{A}}\\mathbf{X}$.\n    $$\n    \\mathbf{Z} = \\begin{pmatrix} \\frac{1}{2} & \\frac{1}{\\sqrt{6}} & 0 \\\\ \\frac{1}{\\sqrt{6}} & \\frac{1}{3} & \\frac{1}{\\sqrt{6}} \\\\ 0 & \\frac{1}{\\sqrt{6}} & \\frac{1}{2} \\end{pmatrix} \\begin{pmatrix} 2 \\\\ -1 \\\\ -4 \\end{pmatrix}\n    $$\n    The problem only requires the feature for protein $P_2$, which corresponds to the second element of the final output vector. We compute the second element of $\\mathbf{Z}$, denoted $Z_2$.\n    $$\n    Z_2 = \\left(\\frac{1}{\\sqrt{6}}\\right)(2) + \\left(\\frac{1}{3}\\right)(-1) + \\left(\\frac{1}{\\sqrt{6}}\\right)(-4)\n    $$\n    $$\n    Z_2 = \\frac{2}{\\sqrt{6}} - \\frac{1}{3} - \\frac{4}{\\sqrt{6}} = -\\frac{2}{\\sqrt{6}} - \\frac{1}{3}\n    $$\n\n5.  **Apply the ReLU activation function.**\n    The activation function is $\\sigma(x) = \\max\\{0, x\\}$. We need to apply this to $Z_2$.\n    The value of $Z_2$ is $-\\frac{2}{\\sqrt{6}} - \\frac{1}{3}$. Since both terms are negative, their sum is negative.\n    $$\n    Z_2 < 0\n    $$\n    The activated feature for protein $P_2$, denoted $H'_{2}$, is:\n    $$\n    H'_{2} = \\sigma(Z_2) = \\max\\{0, -\\frac{2}{\\sqrt{6}} - \\frac{1}{3}\\} = 0\n    $$\nThe single activated scalar feature of protein $P_2$ is $0$.", "answer": "$$\\boxed{0}$$", "id": "3299390"}, {"introduction": "A primary aim of systems biology is to predict the functional consequences of interventions, such as a gene knockdown. However, models trained on purely observational data learn correlations, which can fail to predict causal effects due to unmeasured confounding variables. This exercise guides you through a quantitative comparison of an observational prediction versus a true causal effect within a Structural Causal Model, highlighting the fundamental difference between seeing and doing [@problem_id:3299366].", "problem": "Consider a gene regulatory module modeled as a linear Structural Causal Model (SCM) with a known Directed Acyclic Graph (DAG). The DAG has nodes $C$ (an unobserved cellular context variable), $G_1$ (a transcription factor subject to knockdown), $G_2$ (a downstream gene), and $Y$ (a phenotypic output). The directed edges are $C \\rightarrow G_1$, $C \\rightarrow Y$, $G_1 \\rightarrow G_2$, and $G_1 \\rightarrow Y$, $G_2 \\rightarrow Y$. The SCM is specified by the following linear-Gaussian structural equations:\n$$\nC \\sim \\mathcal{N}(\\mu_C,\\sigma_C^2), \\quad G_1 = a_{CG_1} C + \\varepsilon_1, \\quad G_2 = a_{12} G_1 + \\varepsilon_2, \\quad Y = b_{2Y} G_2 + b_{1Y} G_1 + b_{CY} C + \\varepsilon_Y,\n$$\nwhere $\\varepsilon_1 \\sim \\mathcal{N}(0,\\sigma_1^2)$, $\\varepsilon_2 \\sim \\mathcal{N}(0,\\sigma_2^2)$, and $\\varepsilon_Y \\sim \\mathcal{N}(0,\\sigma_Y^2)$ are mutually independent and independent of $C$. All variables represent steady-state levels, measured in consistent unitless relative expression or activity units.\n\nYou are given numerical parameters: $\\mu_C = 0.5$, $\\sigma_C^2 = 1.0$, $a_{CG_1} = 1.3$, $\\sigma_1^2 = 0.4$, $a_{12} = 0.8$, $\\sigma_2^2 = 0.3$, $b_{2Y} = 2.0$, $b_{1Y} = 0.5$, $b_{CY} = 1.1$, and $\\sigma_Y^2 = 0.2$.\n\nA systematic knockdown sets the transcription factor $G_1$ to the fixed level $g^* = 0.2$. Using the truncated factorization definition of interventional distributions for SCMs, derive the interventional expectation $\\mathbb{E}[Y \\mid \\mathrm{do}(G_1 = g^*)]$ for this knockdown.\n\nSeparately, consider a deep neural predictor trained purely on observational data pairs $(G_1,Y)$ to minimize expected squared error. Assume infinite data and sufficient capacity so that the learned predictor converges to the observational conditional expectation $\\mathbb{E}[Y \\mid G_1 = g^*]$. Derive this observational expectation under the given SCM.\n\nFinally, compute the numerical difference between the observational predictor and the interventional effect under the knockdown, defined as\n$$\n\\Delta \\equiv \\mathbb{E}[Y \\mid G_1 = g^*] - \\mathbb{E}[Y \\mid \\mathrm{do}(G_1 = g^*)].\n$$\nProvide the value of $\\Delta$ as a unitless real number. Round your answer to four significant figures.", "solution": "### Derivation of the Interventional Expectation\n\nThe interventional expectation $\\mathbb{E}[Y \\mid \\mathrm{do}(G_1 = g^*)]$ is calculated using a modified SCM. The $\\mathrm{do}(G_1 = g^*)$ operation replaces the structural equation for $G_1$ with the assignment $G_1 = g^*$, effectively removing the influence of its parent, $C$.\n\nThe modified SCM is:\n$C \\sim \\mathcal{N}(\\mu_C, \\sigma_C^2)$\n$G_1 = g^*$\n$G_2 = a_{12} G_1 + \\varepsilon_2 = a_{12} g^* + \\varepsilon_2$\n$Y = b_{2Y} G_2 + b_{1Y} G_1 + b_{CY} C + \\varepsilon_Y$\n\nWe compute the expectation of $Y$ under this new model. By the linearity of expectation:\n$$\n\\mathbb{E}[Y \\mid \\mathrm{do}(G_1 = g^*)] = \\mathbb{E}[b_{2Y} G_2 + b_{1Y} G_1 + b_{CY} C + \\varepsilon_Y]\n$$\n$$\n= b_{2Y} \\mathbb{E}[G_2] + b_{1Y} \\mathbb{E}[G_1] + b_{CY} \\mathbb{E}[C] + \\mathbb{E}[\\varepsilon_Y]\n$$\nThe expectations of the individual components are:\n- $\\mathbb{E}[G_1] = g^*$ (since $G_1$ is a constant).\n- The distribution of $C$ is unaffected by the intervention on its child $G_1$, so $\\mathbb{E}[C] = \\mu_C$.\n- The noise term has a mean of zero, $\\mathbb{E}[\\varepsilon_Y] = 0$.\n- $\\mathbb{E}[G_2] = \\mathbb{E}[a_{12} g^* + \\varepsilon_2] = a_{12} g^* + \\mathbb{E}[\\varepsilon_2] = a_{12} g^*$.\n\nSubstituting these into the equation for the expectation of $Y$:\n$$\n\\mathbb{E}[Y \\mid \\mathrm{do}(G_1 = g^*)] = b_{2Y} (a_{12} g^*) + b_{1Y} g^* + b_{CY} \\mu_C\n$$\n$$\n= (a_{12}b_{2Y} + b_{1Y}) g^* + b_{CY} \\mu_C\n$$\nThis expression represents the causal effect of setting $G_1$ to $g^*$ on $Y$.\n\n### Derivation of the Observational Conditional Expectation\n\nThe observational conditional expectation $\\mathbb{E}[Y \\mid G_1 = g^*]$ is calculated using the original, unmodified SCM. The premise is that a predictor trained on infinite observational data to minimize squared error will converge to this quantity.\n$$\n\\mathbb{E}[Y \\mid G_1 = g^*] = \\mathbb{E}[b_{2Y} G_2 + b_{1Y} G_1 + b_{CY} C + \\varepsilon_Y \\mid G_1 = g^*]\n$$\nUsing the linearity of conditional expectation:\n$$\n= b_{2Y} \\mathbb{E}[G_2 \\mid G_1 = g^*] + b_{1Y} \\mathbb{E}[G_1 \\mid G_1 = g^*] + b_{CY} \\mathbb{E}[C \\mid G_1 = g^*] + \\mathbb{E}[\\varepsilon_Y \\mid G_1 = g^*]\n$$\nWe evaluate each term:\n- $\\mathbb{E}[G_1 \\mid G_1 = g^*] = g^*$.\n- Since $\\varepsilon_Y$ is independent of all other variables, $\\mathbb{E}[\\varepsilon_Y \\mid G_1 = g^*] = \\mathbb{E}[\\varepsilon_Y] = 0$.\n- $G_2 = a_{12}G_1 + \\varepsilon_2$. Since $\\varepsilon_2$ is independent of $C$ and $\\varepsilon_1$, it is independent of $G_1$. Thus, $\\mathbb{E}[G_2 \\mid G_1 = g^*] = \\mathbb{E}[a_{12}G_1 + \\varepsilon_2 \\mid G_1 = g^*] = a_{12}g^* + \\mathbb{E}[\\varepsilon_2] = a_{12}g^*$.\n- The key term is $\\mathbb{E}[C \\mid G_1 = g^*]$. $C$ and $G_1$ are jointly Gaussian because $G_1$ is a linear function of $C$ and an independent Gaussian noise term.\nThe joint distribution of $(C, G_1)$ is bivariate normal. The parameters of this distribution are:\n$\\mathbb{E}[C] = \\mu_C$\n$\\mathrm{Var}(C) = \\sigma_C^2$\n$\\mathbb{E}[G_1] = \\mathbb{E}[a_{CG_1}C + \\varepsilon_1] = a_{CG_1}\\mathbb{E}[C] + \\mathbb{E}[\\varepsilon_1] = a_{CG_1}\\mu_C$\n$\\mathrm{Var}(G_1) = \\mathrm{Var}(a_{CG_1}C + \\varepsilon_1) = a_{CG_1}^2 \\mathrm{Var}(C) + \\mathrm{Var}(\\varepsilon_1) = a_{CG_1}^2 \\sigma_C^2 + \\sigma_1^2$\n$\\mathrm{Cov}(C, G_1) = \\mathrm{Cov}(C, a_{CG_1}C + \\varepsilon_1) = a_{CG_1}\\mathrm{Var}(C) = a_{CG_1}\\sigma_C^2$\n\nThe formula for conditional expectation in a bivariate normal system is:\n$$\n\\mathbb{E}[C \\mid G_1 = g^*] = \\mathbb{E}[C] + \\frac{\\mathrm{Cov}(C, G_1)}{\\mathrm{Var}(G_1)} (g^* - \\mathbb{E}[G_1])\n$$\nSubstituting the derived parameters:\n$$\n\\mathbb{E}[C \\mid G_1 = g^*] = \\mu_C + \\frac{a_{CG_1}\\sigma_C^2}{a_{CG_1}^2 \\sigma_C^2 + \\sigma_1^2} (g^* - a_{CG_1}\\mu_C)\n$$\nAssembling the full expression for $\\mathbb{E}[Y \\mid G_1 = g^*]$:\n$$\n\\mathbb{E}[Y \\mid G_1 = g^*] = b_{2Y}(a_{12}g^*) + b_{1Y}g^* + b_{CY}\\left(\\mu_C + \\frac{a_{CG_1}\\sigma_C^2}{a_{CG_1}^2 \\sigma_C^2 + \\sigma_1^2} (g^* - a_{CG_1}\\mu_C)\\right)\n$$\n$$\n= (a_{12}b_{2Y} + b_{1Y})g^* + b_{CY}\\mu_C + b_{CY}\\frac{a_{CG_1}\\sigma_C^2}{a_{CG_1}^2 \\sigma_C^2 + \\sigma_1^2} (g^* - a_{CG_1}\\mu_C)\n$$\nThis expression represents the prediction for $Y$ based on observing $G_1=g^*$, which includes confounding bias from the unobserved common cause $C$.\n\n### Calculation of the Difference $\\Delta$\n\nThe difference $\\Delta$ is the observational prediction minus the interventional effect.\n$$\n\\Delta = \\mathbb{E}[Y \\mid G_1 = g^*] - \\mathbb{E}[Y \\mid \\mathrm{do}(G_1 = g^*)]\n$$\nSubtracting the two derived expressions:\n$$\n\\Delta = \\left[(a_{12}b_{2Y} + b_{1Y})g^* + b_{CY}\\mu_C + b_{CY}\\frac{a_{CG_1}\\sigma_C^2}{a_{CG_1}^2 \\sigma_C^2 + \\sigma_1^2} (g^* - a_{CG_1}\\mu_C)\\right] - \\left[(a_{12}b_{2Y} + b_{1Y}) g^* + b_{CY} \\mu_C\\right]\n$$\nThe common terms cancel, leaving the confounding bias term:\n$$\n\\Delta = b_{CY}\\frac{a_{CG_1}\\sigma_C^2}{a_{CG_1}^2 \\sigma_C^2 + \\sigma_1^2} (g^* - a_{CG_1}\\mu_C)\n$$\nThis term arises from the \"backdoor path\" $G_1 \\leftarrow C \\rightarrow Y$. Observing $G_1$ allows inference about the state of the unobserved confounder $C$, which also affects $Y$.\n\n### Numerical Computation\n\nWe substitute the given numerical values into the expression for $\\Delta$:\n$\\mu_C = 0.5$, $\\sigma_C^2 = 1.0$, $a_{CG_1} = 1.3$, $\\sigma_1^2 = 0.4$, $b_{CY} = 1.1$, and $g^* = 0.2$.\n\nFirst, calculate the components of the expression:\nThe term $(g^* - a_{CG_1}\\mu_C)$:\n$$\n0.2 - (1.3 \\times 0.5) = 0.2 - 0.65 = -0.45\n$$\nThe fractional term $\\frac{a_{CG_1}\\sigma_C^2}{a_{CG_1}^2 \\sigma_C^2 + \\sigma_1^2}$:\n$$\n\\frac{1.3 \\times 1.0}{(1.3)^2 \\times 1.0 + 0.4} = \\frac{1.3}{1.69 + 0.4} = \\frac{1.3}{2.09}\n$$\nNow, assemble $\\Delta$:\n$$\n\\Delta = 1.1 \\times \\left(\\frac{1.3}{2.09}\\right) \\times (-0.45)\n$$\n$$\n\\Delta = \\frac{1.1 \\times 1.3 \\times (-0.45)}{2.09} = \\frac{-0.6435}{2.09}\n$$\n$$\n\\Delta \\approx -0.3078947368...\n$$\nRounding to four significant figures, we get $\\Delta = -0.3079$.", "answer": "$$\n\\boxed{-0.3079}\n$$", "id": "3299366"}, {"introduction": "After establishing the importance of interventions for causal discovery, the next logical question is: which experiment should we perform to learn the most? This final practice introduces the powerful framework of Bayesian active learning for optimal experimental design. You will explore how to select a perturbation that is expected to provide the maximal information gain about underlying model parameters, a cornerstone of model-driven scientific discovery [@problem_id:3299340].", "problem": "You are given a Bayesian Deep State-Space Model (DSSM) of single-step dynamics under a CRISPR perturbation. The latent state is a vector $x \\in \\mathbb{R}^n$, the perturbation is $u \\in \\mathbb{R}^m$, and the unknown model parameters $\\theta \\in \\mathbb{R}^p$ have a Gaussian prior. Your task is to formulate and implement an active learning strategy that, for each provided test case, selects the perturbation $u$ that maximizes the expected information gain $\\mathbb{E}[\\Delta I(\\theta; \\mathcal{D} \\cup (x,u))]$ about $\\theta$ after observing the next single measurement. Use zero-based indexing for perturbation selection.\n\nThe DSSM is specified as follows. The latent dynamics are given by a one-step deep mapping\n$$\nx' = f(x, u) = W_2 \\,\\tanh\\!\\left(W_1 \\begin{bmatrix} x \\\\ u \\end{bmatrix}\\right),\n$$\nwhere $\\tanh(\\cdot)$ is applied elementwise. The observation model is a deep emission with linear parameterization,\n$$\ny = \\theta^\\top \\psi(x') + \\varepsilon, \\quad \\psi(x') = \\tanh(A x'),\n$$\nwhere $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_y^2)$ is Gaussian measurement noise.\n\nYou must base your derivation on principled definitions: Bayes' rule, the definition of Mutual Information (MI) as the expected Kullback–Leibler (KL) divergence between posterior and prior, and the standard properties of Gaussian distributions. Do not invoke any shortcut formulas not derived from these bases. Under the given model, the expected information gain for a single observation is to be computed by appropriately linearizing the observation with respect to $\\theta$ and using the Gaussian prior and noise assumptions.\n\nThe DSSM weight matrices used across all test cases are:\n$$\nW_1 = \\begin{bmatrix}\n0.8 & -0.5 & 0.3 & 1.0 & -0.7 \\\\\n0.1 & 0.9 & -1.2 & 0.5 & 0.3 \\\\\n-0.6 & 0.4 & 0.8 & -0.9 & 1.1 \\\\\n1.2 & -0.8 & 0.2 & 0.3 & -0.4\n\\end{bmatrix}, \\quad\nW_2 = \\begin{bmatrix}\n0.5 & -0.2 & 0.1 & 0.7 \\\\\n-0.3 & 0.8 & -0.5 & 0.2 \\\\\n0.4 & 0.0 & 0.6 & -0.1\n\\end{bmatrix}, \\quad\nA = \\begin{bmatrix}\n1.0 & -0.5 & 0.2 \\\\\n-0.3 & 0.7 & -0.9 \\\\\n0.6 & 0.1 & 0.4\n\\end{bmatrix}.\n$$\nThese correspond to $n=3$, $m=2$, $h=4$, $p=3$, with $W_1 \\in \\mathbb{R}^{h \\times (n+m)}$, $W_2 \\in \\mathbb{R}^{n \\times h}$, and $A \\in \\mathbb{R}^{p \\times n}$. The prior over $\\theta$ is $\\mathcal{N}(\\mu, \\Sigma)$ with mean $\\mu \\in \\mathbb{R}^p$ (not needed for the expected information gain in this setup) and covariance $\\Sigma \\in \\mathbb{R}^{p \\times p}$.\n\nFormulate the expected information gain for a single measurement under this model from first principles, and implement the following selection algorithm: for each candidate perturbation $u$, compute $x' = f(x,u)$, then compute $\\psi(x')$, then compute the expected information gain based on the Gaussian prior covariance $\\Sigma$ and noise variance $\\sigma_y^2$, and pick the $u$ that maximizes it.\n\nYour program must use the following test suite, which covers typical and edge scenarios. For each test case, you will receive a current state $x$, prior covariance $\\Sigma$, measurement noise standard deviation $\\sigma_y$, and a list of candidate perturbations $u$.\n\nTest case $1$ (happy path):\n- $x = \\begin{bmatrix} 0.5 \\\\ -0.3 \\\\ 0.1 \\end{bmatrix}$\n- $\\Sigma = \\mathrm{diag}\\!\\big(\\begin{bmatrix} 0.4 \\\\ 0.3 \\\\ 0.2 \\end{bmatrix}\\big)$\n- $\\sigma_y = 0.1$\n- Candidates $u$: $\\left\\{ \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}, \\begin{bmatrix} 0.5 \\\\ -0.5 \\end{bmatrix}, \\begin{bmatrix} 1.0 \\\\ 0.2 \\end{bmatrix}, \\begin{bmatrix} -0.8 \\\\ 0.9 \\end{bmatrix} \\right\\}$\n\nTest case $2$ (high-noise regime):\n- $x = \\begin{bmatrix} 0.2 \\\\ 0.9 \\\\ -1.2 \\end{bmatrix}$\n- $\\Sigma = \\mathrm{diag}\\!\\big(\\begin{bmatrix} 0.8 \\\\ 0.1 \\\\ 0.05 \\end{bmatrix}\\big)$\n- $\\sigma_y = 1.0$\n- Candidates $u$: $\\left\\{ \\begin{bmatrix} -0.3 \\\\ 0.7 \\end{bmatrix}, \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}, \\begin{bmatrix} 1.5 \\\\ -1.5 \\end{bmatrix}, \\begin{bmatrix} -2.0 \\\\ 2.0 \\end{bmatrix} \\right\\}$\n\nTest case $3$ (near-degenerate prior covariance and saturation test):\n- $x = \\begin{bmatrix} -0.1 \\\\ 0.0 \\\\ 0.05 \\end{bmatrix}$\n- $\\Sigma = \\mathrm{diag}\\!\\big(\\begin{bmatrix} 10^{-6} \\\\ 10^{-6} \\\\ 10^{-6} \\end{bmatrix}\\big)$\n- $\\sigma_y = 0.2$\n- Candidates $u$: $\\left\\{ \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}, \\begin{bmatrix} 3.0 \\\\ -3.0 \\end{bmatrix}, \\begin{bmatrix} -5.0 \\\\ 5.0 \\end{bmatrix}, \\begin{bmatrix} 0.1 \\\\ 0.1 \\end{bmatrix} \\right\\}$\n\nYour program should evaluate all candidate $u$ for each test case, select the perturbation maximizing the expected information gain, and output, for each test case, the zero-based index of the selected $u$ followed by the expected information gain value for that selected $u$ rounded to six decimal places. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., `[i_1,g_1,i_2,g_2,i_3,g_3]`), where $i_k$ is an integer and $g_k$ is a float.\n\nNo physical units or angle units apply in this problem. All outputs must be numeric primitives as specified above.", "solution": "The problem statement has been validated and is deemed valid. It is scientifically grounded in Bayesian inference and information theory, mathematically well-posed, and internally consistent with all necessary data and definitions provided.\n\nThe objective is to select a perturbation $u$ from a set of candidates that maximizes the expected information gain about the model parameters $\\theta \\in \\mathbb{R}^p$ after a single experiment. An experiment consists of applying the perturbation $u$ to the system in state $x$ and observing the next measurement $y$. The expected information gain is the mutual information, $I(\\theta; Y | x, u)$, between the parameter vector $\\theta$ and the future observation $Y$, conditioned on the experimental design defined by the current state $x$ and the chosen perturbation $u$.\n\nThe problem is framed within a Bayesian context. The parameters $\\theta$ are treated as a random variable with a prior distribution. The observation model provides the likelihood of an observation given the parameters.\n\n1.  **Prior Distribution**: The prior belief about the parameters $\\theta$ is described by a $p$-dimensional multivariate Gaussian distribution with a known covariance matrix $\\Sigma \\in \\mathbb{R}^{p \\times p}$.\n    $$\n    p(\\theta) = \\mathcal{N}(\\theta | \\mu, \\Sigma)\n    $$\n    The prior mean $\\mu$ is not required for this calculation.\n\n2.  **Likelihood Function**: The observation model is given by $y = \\theta^\\top \\psi(x') + \\varepsilon$, where $\\psi(x') = \\tanh(A x')$ is a feature vector derived from the next latent state $x'$, and $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_y^2)$ is Gaussian noise. For a fixed experimental design $(x, u)$, the vector $\\psi = \\psi(f(x,u))$ is a constant vector. The model for the observation $y$ is thus $y = \\psi^\\top\\theta + \\varepsilon$, which is a standard linear-in-parameters model. The likelihood of observing $y$ given $\\theta$ is:\n    $$\n    p(y | \\theta, \\psi) = \\mathcal{N}(y | \\psi^\\top\\theta, \\sigma_y^2)\n    $$\n\nThe mutual information $I(\\theta; Y | \\psi)$ is defined as the reduction in the entropy of $\\theta$ after observing $Y$:\n$$\nI(\\theta; Y | \\psi) = H(\\theta) - H(\\theta | Y)\n$$\nwhere $H(\\theta)$ is the entropy of the prior distribution $p(\\theta)$, and $H(\\theta | Y) = \\mathbb{E}_{y \\sim p(y)}[H(p(\\theta|y))]$ is the conditional entropy of $\\theta$ given $Y$.\n\nThe entropy of a $p$-dimensional Gaussian distribution with covariance matrix $S$ is given by:\n$$\nH(\\mathcal{N}) = \\frac{1}{2} \\ln \\det(2\\pi e S) = \\frac{p}{2} \\ln(2\\pi e) + \\frac{1}{2} \\ln \\det(S)\n$$\nThe entropy of the prior distribution $p(\\theta) = \\mathcal{N}(\\theta | \\mu, \\Sigma)$ is therefore:\n$$\nH(\\theta) = \\frac{p}{2} \\ln(2\\pi e) + \\frac{1}{2} \\ln \\det(\\Sigma)\n$$\nAccording to Bayes' rule, the posterior distribution $p(\\theta|y)$ is proportional to the product of the likelihood and the prior, $p(\\theta|y) \\propto p(y|\\theta, \\psi) p(\\theta)$. Since both the prior and the likelihood are Gaussian (with respect to $\\theta$), the posterior is also Gaussian, $p(\\theta | y, \\psi) = \\mathcal{N}(\\theta | \\mu_{\\text{post}}, \\Sigma_{\\text{post}})$. The posterior covariance matrix $\\Sigma_{\\text{post}}$ for this Bayesian linear regression model is given by:\n$$\n\\Sigma_{\\text{post}} = \\left( \\Sigma^{-1} + \\frac{1}{\\sigma_y^2} \\psi \\psi^\\top \\right)^{-1}\n$$\nCrucially, $\\Sigma_{\\text{post}}$ depends on the prior covariance $\\Sigma$, the noise variance $\\sigma_y^2$, and the feature vector $\\psi$, but it does not depend on the specific measurement outcome $y$.\n\nThe entropy of the posterior distribution is:\n$$\nH(p(\\theta|y)) = \\frac{p}{2} \\ln(2\\pi e) + \\frac{1}{2} \\ln \\det(\\Sigma_{\\text{post}})\n$$\nSince this expression does not depend on $y$, the conditional entropy $H(\\theta|Y)$ is simply equal to the posterior entropy:\n$$\nH(\\theta | Y) = \\mathbb{E}_{y \\sim p(y)}[H(p(\\theta|y))] = H(p(\\theta|y)) = \\frac{p}{2} \\ln(2\\pi e) + \\frac{1}{2} \\ln \\det(\\Sigma_{\\text{post}})\n$$\nSubstituting the expressions for the prior and conditional entropies into the mutual information formula yields:\n$$\nI(\\theta; Y | \\psi) = \\left( \\frac{p}{2} \\ln(2\\pi e) + \\frac{1}{2} \\ln \\det(\\Sigma) \\right) - \\left( \\frac{p}{2} \\ln(2\\pi e) + \\frac{1}{2} \\ln \\det(\\Sigma_{\\text{post}}) \\right)\n$$\n$$\nI(\\theta; Y | \\psi) = \\frac{1}{2} \\left[ \\ln \\det(\\Sigma) - \\ln \\det(\\Sigma_{\\text{post}}) \\right] = \\frac{1}{2} \\ln \\left( \\frac{\\det(\\Sigma)}{\\det(\\Sigma_{\\text{post}})} \\right)\n$$\nUsing the expression for $\\Sigma_{\\text{post}}$:\n$$\nI(\\theta; Y | \\psi) = \\frac{1}{2} \\ln \\left( \\frac{\\det(\\Sigma)}{\\det\\left( (\\Sigma^{-1} + \\frac{1}{\\sigma_y^2} \\psi \\psi^\\top)^{-1} \\right)} \\right) = \\frac{1}{2} \\ln \\left( \\det(\\Sigma) \\det\\left( \\Sigma^{-1} + \\frac{1}{\\sigma_y^2} \\psi \\psi^\\top \\right) \\right)\n$$\nFactoring out $\\Sigma^{-1}$:\n$$\nI(\\theta; Y | \\psi) = \\frac{1}{2} \\ln \\left( \\det(\\Sigma) \\det\\left( \\Sigma^{-1} \\left( I + \\frac{1}{\\sigma_y^2} \\Sigma \\psi \\psi^\\top \\right) \\right) \\right)\n$$\nUsing the property $\\det(AB) = \\det(A)\\det(B)$ and that $\\det(\\Sigma)\\det(\\Sigma^{-1}) = 1$:\n$$\nI(\\theta; Y | \\psi) = \\frac{1}{2} \\ln \\det\\left( I + \\frac{1}{\\sigma_y^2} \\Sigma \\psi \\psi^\\top \\right)\n$$\nNow, we apply the matrix determinant lemma, which states that $\\det(I + CD) = \\det(I + DC)$. Let $C = \\frac{1}{\\sigma_y^2} \\Sigma \\psi$ (a $p \\times 1$ matrix) and $D = \\psi^\\top$ (a $1 \\times p$ matrix).\n$$\n\\det\\left( I_{p \\times p} + \\left(\\frac{1}{\\sigma_y^2} \\Sigma \\psi\\right) (\\psi^\\top) \\right) = \\det\\left( I_{1 \\times 1} + (\\psi^\\top) \\left(\\frac{1}{\\sigma_y^2} \\Sigma \\psi\\right) \\right)\n$$\nThe right-hand side is the determinant of a $1 \\times 1$ matrix (a scalar), which is the scalar itself.\n$$\n\\det\\left( 1 + \\frac{1}{\\sigma_y^2} \\psi^\\top \\Sigma \\psi \\right) = 1 + \\frac{1}{\\sigma_y^2} \\psi^\\top \\Sigma \\psi\n$$\nThus, the final expression for the expected information gain is:\n$$\nI(u) = \\frac{1}{2} \\ln \\left( 1 + \\frac{1}{\\sigma_y^2} \\psi(u)^\\top \\Sigma \\psi(u) \\right)\n$$\nwhere the dependence on the choice of perturbation $u$ is made explicit.\n\nThe computational algorithm for each test case is as follows:\n1.  Initialize a maximum gain variable to a negative value and a best index variable.\n2.  For each candidate perturbation $u_i$ in the provided list:\n    a. Construct the input vector by concatenating the current state $x$ and the perturbation $u_i$: $v = \\begin{bmatrix} x \\\\ u_i \\end{bmatrix}$.\n    b. Compute the next latent state $x'$ using the deep dynamics function: $x' = W_2 \\,\\tanh\\!\\left(W_1 v \\right)$.\n    c. Compute the observation feature vector $\\psi$: $\\psi = \\tanh(A x')$.\n    d. Compute the quadratic form $q = \\psi^\\top \\Sigma \\psi$.\n    e. Calculate the expected information gain $G_i = \\frac{1}{2} \\ln \\left( 1 + q / \\sigma_y^2 \\right)$.\n    f. Compare $G_i$ with the current maximum gain. If $G_i$ is greater, update the maximum gain to $G_i$ and the best index to $i$.\n3.  After iterating through all candidate perturbations, the best index and its corresponding maximum gain are the result for the test case.\nThis procedure is repeated for all test cases.", "answer": "```\n[3,1.353347,0,0.063415,2,0.000010]\n```", "id": "3299340"}]}