{"hands_on_practices": [{"introduction": "A foundational challenge in synthetic biology is controlling the state of engineered bistable systems, such as the genetic toggle switch. This practice guides you through designing a time-optimal control strategy to flip such a switch, a task analogous to finding the fastest possible way to change a cell's phenotype. By applying Pontryagin's Maximum Principle, you will discover the theoretical structure of the optimal input—a \"bang-bang\" schedule—and implement a numerical solution that also accounts for a practical constraint on metabolic burden [@problem_id:3335261].", "problem": "Consider a single-coordinate reduced-order model of a bistable gene toggle switch derived from standard mutual-repression dynamics under quasi-steady-state elimination of fast variables. The gene expression difference coordinate $x(t)$ obeys the cubic normal form\n$$\n\\dot{x}(t) = a\\,x(t) - b\\,x^3(t) + c + k\\,u(t),\n$$\nwhere $a0$ and $b0$ encode effective linear gain and cubic saturation, $c$ is an asymmetry parameter modeling basal transcriptional bias, $k0$ is the inducer actuation gain, and $u(t)\\in\\{0,u_{\\max}\\}$ is a bang-bang induction schedule. The metabolic burden associated with induction is modeled by the inequality constraint\n$$\n\\int_{0}^{T} \\gamma\\,u^2(t)\\,dt \\leq B,\n$$\nwhere $\\gamma0$ is the burden coefficient and $B0$ is the total allowable burden budget. The control objective is to flip the toggle from an initial state $x(0)=x_A$ located in the basin of attraction of the $x_A$ well to a target region corresponding to the opposite well, defined as $x(T)\\geq x_B$, in minimum time $T$, while respecting the burden constraint.\n\nStarting from the fundamental bases of computational systems biology and control, namely ordinary differential equation dynamics of gene regulation and Pontryagin's Maximum Principle, design an optimal bang-bang schedule $u(t)\\in\\{0,u_{\\max}\\}$ that minimizes the flipping time subject to the burden constraint for this one-dimensional reduced system. Your derivation and algorithm must be principle-based and should not assume any pre-specified switching times or schedules. Explicitly incorporate the burden constraint into the optimality conditions.\n\nThe final program must numerically compute, for a given parameter set, the minimal flipping time $T$ in minutes, rounded to three decimal places. If the target cannot be reached under the given burden budget (i.e., no schedule with $u(t)\\in\\{0,u_{\\max}\\}$ satisfies both state and burden constraints), output the boolean value $\\mathrm{False}$.\n\nUse the following test suite of parameter values, expressed in scientifically plausible units: gene expression $x$ in arbitrary units, time in minutes, and $u$ in induction-rate units such that $k\\,u$ has units of gene expression per minute. For all cases, set $a=1$, $b=1$, $k=1$, $u_{\\max}=0.5$, $\\gamma=2$, $x_A=-1.5$, and $x_B=0.8$.\n\n- Case $1$ (general happy path): $c=0$, $B=100$.\n- Case $2$ (boundary burden equality): $c=0$, $B$ chosen to exactly match the minimum burden required to run $u(t)=u_{\\max}$ from $t=0$ until the target is reached; that is, $B=\\gamma\\,u_{\\max}^2\\,T^\\star$, where $T^\\star$ is the minimal time under full induction. Your program must compute $T^\\star$ internally for this case and then set $B$ accordingly before computing the reported minimal flipping time.\n- Case $3$ (budget-limited with positive drift assist): $c=0.5$, $B=0.5$.\n- Case $4$ (infeasible due to negative drift dominance): $c=-0.5$, $B=0.5$.\n\nScientific realism requirements:\n- All dynamics and constraints must be respected. Assume continuous-time evolution and deterministic dynamics as written.\n- You must use event-based integration to detect when $x(t)$ first satisfies $x(t)\\geq x_B$.\n- When the burden budget $B$ is insufficient to sustain $u(t)=u_{\\max}$ until the target is reached, consider the optimal two-phase bang-bang schedule implied by first principles: apply $u(t)=u_{\\max}$ until the burden is exhausted at time $t=T_{\\mathrm{budget}}=B/(\\gamma u_{\\max}^2)$, then set $u(t)=0$ and rely solely on the autonomous drift to reach the target, if possible.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of Cases $1$–$4$. Each entry must be either a float (minimal flipping time in minutes, rounded to three decimal places) or the boolean value $\\mathrm{False}$ if infeasible. For example, a valid output with four cases would look like $[12.345,8.765,\\mathrm{False},3.210]$.", "solution": "We begin from the gene regulatory dynamics modeled as a single-coordinate cubic normal form\n$$\n\\dot{x}(t) = a\\,x(t) - b\\,x^3(t) + c + k\\,u(t),\n$$\nwith $u(t)\\in\\{0,u_{\\max}\\}$ and initial condition $x(0)=x_A$. The target is the set $\\{x\\mid x\\geq x_B\\}$, and the metabolic burden is constrained by\n$$\n\\int_{0}^{T} \\gamma\\,u^2(t)\\,dt \\leq B.\n$$\nThe system dynamics capture a reduced description of a bistable toggle switch: for $c\\approx 0$, the cubic vector field $a\\,x(t) - b\\,x^3(t)$ produces two stable wells near $\\pm\\sqrt{a/b}$, and the term $k\\,u(t)$ tilts the landscape toward the positive well when the induction is on. The asymmetry parameter $c$ breaks the symmetry by biasing the drift toward either the positive ($c0$) or negative ($c0$) side.\n\nWe formulate the minimum-time problem subject to an isoperimetric (integral) inequality constraint using Pontryagin's Maximum Principle. Define the Hamiltonian\n$$\nH(x,\\lambda,u) = 1 + \\lambda\\left(a\\,x - b\\,x^3 + c + k\\,u\\right) + \\mu\\,\\gamma\\,u^2,\n$$\nwhere $\\lambda(t)$ is the adjoint variable and $\\mu\\geq 0$ is the Lagrange multiplier associated with the burden constraint. The adjoint dynamics follow\n$$\n\\dot{\\lambda}(t) = -\\frac{\\partial H}{\\partial x}(x,\\lambda,u) = -\\lambda\\left(a - 3b\\,x^2\\right),\n$$\nwith the transversality condition appropriate to the minimum-time target-hitting problem. For minimum-time problems, the constant term $1$ in $H$ reflects the cost rate. The control $u(t)\\in\\{0,u_{\\max}\\}$ must minimize $H$ pointwise almost everywhere. Because $H$ is affine in $u$ except for the quadratic penalty term associated with $\\mu$, the minimizer over the discrete set $\\{0,u_{\\max}\\}$ compares the two Hamiltonian values:\n$$\nH(x,\\lambda,u_{\\max}) - H(x,\\lambda,0) = \\lambda\\,k\\,u_{\\max} + \\mu\\,\\gamma\\,u_{\\max}^2.\n$$\nThus the optimal control is bang-bang with a switching rule determined by the sign of the switching function\n$$\n\\sigma(t) = \\lambda(t)\\,k + \\mu\\,\\gamma\\,u_{\\max}.\n$$\nIf $\\sigma(t)0$ then $u(t)=u_{\\max}$, and if $\\sigma(t)0$ then $u(t)=0$. In our setting, $k0$ and the system is one-dimensional and monotone in $u$. For minimum-time reachability from $x_Ax_B$ under positive actuation gain $k0$, the adjoint typically maintains a sign such that the control employs its extreme value $u_{\\max}$ until either the target is reached or the burden constraint becomes active (i.e., $\\mu0$ and the integral saturates). Because the burden constraint is an inequality, if the target can be reached before exhausting the budget, the multiplier satisfies $\\mu=0$ (complementary slackness) and the control is $u(t)=u_{\\max}$ up to the first hitting time. If the budget is insufficient to complete the transition under $u_{\\max}$ alone, the constraint becomes active. In this case, the canonical structure of minimum-time bang-bang controls for monotone systems implies at most one switch: apply $u(t)=u_{\\max}$ until the budget is exhausted, then set $u(t)=0$ for the remainder. Any additional switching to $u(t)=0$ earlier would only delay the transition without providing benefit, because the dynamics satisfy $\\partial \\dot{x}/\\partial u = k  0$.\n\nTherefore, the optimal schedule is characterized by the following two-phase structure:\n- Phase $1$: $u(t)=u_{\\max}$ for $0\\leq t\\leq T_1$, where $T_1$ is either the first hitting time of the target under full induction or the budget exhaustion time $T_{\\mathrm{budget}}=B/(\\gamma u_{\\max}^2)$, whichever occurs first.\n- Phase $2$: If the target is not reached by $t=T_{\\mathrm{budget}}$, set $u(t)=0$ and rely on the autonomous drift $\\dot{x}=a\\,x - b\\,x^3 + c$ to reach the target, provided the positive drift toward $x\\geq x_B$ is dynamically feasible.\n\nQuantification proceeds as follows. For given parameters, define the event function\n$$\ng(x) = x - x_B,\n$$\nand compute the first time $T^\\star$ such that $g(x(T^\\star))=0$ under $u(t)=u_{\\max}$ starting from $x(0)=x_A$. If $T^\\star$ is finite and the associated burden $B^\\star=\\gamma\\,u_{\\max}^2\\,T^\\star$ satisfies $B\\geq B^\\star$, then the minimal flipping time is $T=T^\\star$. If $BB^\\star$, define $T_{\\mathrm{budget}}=B/(\\gamma u_{\\max}^2)$ and simulate a two-phase trajectory: integrate with $u(t)=u_{\\max}$ on $[0,T_{\\mathrm{budget}}]$ and then with $u(t)=0$ on $[T_{\\mathrm{budget}},\\infty)$ until $x(t)$ first satisfies $x(t)\\geq x_B$. If such a time exists, the minimal flipping time is $T=T_{\\mathrm{budget}}+T_2$, where $T_2$ is the additional time needed under zero induction. If the target is not reached under the second phase dynamics (e.g., due to negative drift dominance from $c0$ yielding a single negative attractor), then the problem is infeasible and we report $\\mathrm{False}$.\n\nAlgorithmic design:\n- Use an event-based ordinary differential equation integrator to robustly detect the first hitting time of $x_B$. The event function $g(x)=x-x_B$ is set as terminal and restricted to positive direction crossings to avoid false detections due to numerical oscillations.\n- For Case $2$, compute $T^\\star$ under full induction and then set $B=\\gamma\\,u_{\\max}^2\\,T^\\star$ to satisfy the boundary burden equality. The reported minimal time is then $T^\\star$.\n- Numerical stability is ensured by tight tolerances in the integrator and reasonable upper bounds on simulation time. If the target event does not trigger within a generous time horizon under zero induction for the second phase, the instance is considered infeasible.\n\nUnits and outputs:\n- Time $T$ is reported in minutes.\n- The final program outputs $4$ entries corresponding to Cases $1$–$4$ as a single line list. Each entry is either a float rounded to three decimal places (minutes) or the boolean $\\mathrm{False}$.\n\nThis design adheres to Pontryagin's Maximum Principle structure for minimum-time problems and leverages the monotonicity of the one-dimensional reduced-order gene toggle model to justify the single-switch bang-bang schedule, while explicitly incorporating the integral metabolic burden constraint.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Runtime environment: Python 3.12, numpy 1.23.5, scipy 1.11.4\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef dynamics(t, x, a, b, c, k, u):\n    # dx/dt = a*x - b*x^3 + c + k*u\n    return a * x[0] - b * (x[0] ** 3) + c + k * u\n\ndef hit_event_factory(x_target):\n    # Event function g(x) = x - x_target; detect crossing in positive direction.\n    def event(t, x):\n        return x[0] - x_target\n    event.terminal = True\n    event.direction = 1.0\n    return event\n\ndef simulate_phase(a, b, c, k, u, x_init, t_span, x_target, rtol=1e-8, atol=1e-10, max_step=np.inf):\n    # Simulate dynamics over t_span with constant u, detect first time x = x_target.\n    event = hit_event_factory(x_target)\n    sol = solve_ivp(\n        fun=lambda t, x: dynamics(t, x, a, b, c, k, u),\n        t_span=t_span,\n        y0=[x_init],\n        events=event,\n        rtol=rtol,\n        atol=atol,\n        max_step=max_step\n    )\n    return sol\n\ndef minimal_flipping_time(a, b, c, k, u_max, gamma, B, x_init, x_target, boundary_match=False):\n    # Compute minimal flipping time under optimal bang-bang schedule with burden constraint.\n    # If boundary_match is True, first compute full-induction minimal time T*, then set B accordingly.\n    # Returns float time in minutes or False if infeasible.\n    # Phase 1: full induction to compute T* if needed.\n    sol_full = simulate_phase(a, b, c, k, u_max, x_init, (0.0, 1e4), x_target)\n    if sol_full.t_events[0].size  0:\n        T_star = sol_full.t_events[0][0]\n        burden_star = gamma * (u_max ** 2) * T_star\n    else:\n        # Even with full induction for long time horizon, target not reached; infeasible.\n        return False\n\n    if boundary_match:\n        # Set B to exact burden needed under full induction until hitting.\n        B = burden_star\n\n    # Budget-based decision\n    if gamma == 0 or u_max == 0:\n        T_budget = np.inf\n    else:\n        T_budget = B / (gamma * (u_max ** 2))\n\n    if T_budget = T_star:\n        # Budget sufficient to keep u = u_max until target is reached; minimal time is T_star.\n        return T_star\n    else:\n        # Two-phase schedule: u = u_max until T_budget, then u = 0 and rely on autonomous drift.\n        # Simulate phase 1 up to T_budget to get state at switch.\n        sol_phase1 = simulate_phase(a, b, c, k, u_max, x_init, (0.0, T_budget), x_target)\n        if sol_phase1.t_events[0].size  0:\n            # Rare case: reached earlier than T_budget due to numerical tolerance; use event time.\n            return sol_phase1.t_events[0][0]\n        x_switch = sol_phase1.y[0, -1]\n        # Phase 2: u = 0 from T_budget onward\n        sol_phase2 = simulate_phase(a, b, c, k, 0.0, x_switch, (T_budget, T_budget + 1e4), x_target)\n        if sol_phase2.t_events[0].size  0:\n            T2 = sol_phase2.t_events[0][0] - T_budget\n            return T_budget + T2\n        else:\n            # Target not reached under autonomous drift; infeasible under given budget.\n            return False\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Common parameters: a=1, b=1, k=1, u_max=0.5, gamma=2, x_init=-1.5, x_target=0.8\n    test_cases = [\n        # Case 1: c=0, B=100\n        {\"a\": 1.0, \"b\": 1.0, \"c\": 0.0, \"k\": 1.0, \"u_max\": 0.5, \"gamma\": 2.0, \"B\": 100.0,\n         \"x_init\": -1.5, \"x_target\": 0.8, \"boundary_match\": False},\n        # Case 2: c=0, B chosen to exactly match burden under full induction to target (boundary case)\n        {\"a\": 1.0, \"b\": 1.0, \"c\": 0.0, \"k\": 1.0, \"u_max\": 0.5, \"gamma\": 2.0, \"B\": None,\n         \"x_init\": -1.5, \"x_target\": 0.8, \"boundary_match\": True},\n        # Case 3: c=0.5 (positive drift assist), B=0.5 (budget-limited)\n        {\"a\": 1.0, \"b\": 1.0, \"c\": 0.5, \"k\": 1.0, \"u_max\": 0.5, \"gamma\": 2.0, \"B\": 0.5,\n         \"x_init\": -1.5, \"x_target\": 0.8, \"boundary_match\": False},\n        # Case 4: c=-0.5 (negative drift dominance), B=0.5 (likely infeasible)\n        {\"a\": 1.0, \"b\": 1.0, \"c\": -0.5, \"k\": 1.0, \"u_max\": 0.5, \"gamma\": 2.0, \"B\": 0.5,\n         \"x_init\": -1.5, \"x_target\": 0.8, \"boundary_match\": False},\n    ]\n\n    results = []\n    for case in test_cases:\n        a = case[\"a\"]; b = case[\"b\"]; c = case[\"c\"]; k = case[\"k\"]\n        u_max = case[\"u_max\"]; gamma = case[\"gamma\"]; B = case[\"B\"]\n        x_init = case[\"x_init\"]; x_target = case[\"x_target\"]\n        boundary_match = case[\"boundary_match\"]\n\n        T = minimal_flipping_time(a, b, c, k, u_max, gamma, B, x_init, x_target, boundary_match=boundary_match)\n        if isinstance(T, bool):\n            results.append(\"False\")\n        else:\n            results.append(f\"{T:.3f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3335261"}, {"introduction": "Beyond static switches, many biological processes are governed by oscillators that keep time. This exercise explores how to synchronize a synthetic gene oscillator with an external reference signal, a key task in applications like coordinated tissue development or timed drug delivery. You will use the powerful technique of phase reduction to simplify the complex dynamics of the oscillator into a single phase variable, which allows for the analytical derivation and implementation of a minimum-energy control law [@problem_id:3335265].", "problem": "Consider a synthetic gene oscillator (for example, a three-gene repressilator) modeled at the protein concentration level by an ordinary differential equation of the form $\\dot{x} = f(x) + B u$, where $x \\in \\mathbb{R}^n$ denotes the state, $u(t) \\in \\mathbb{R}$ is a scalar light input, and $B \\in \\mathbb{R}^{n \\times 1}$ maps light to the state. Assume the unforced system possesses a stable limit cycle with angular frequency $\\omega_{\\mathrm{ref}}$, and that light perturbs the phase through a known phase response curve (PRC). Using first-order phase reduction near the limit cycle and the Central Dogma of molecular biology (transcription-translation processes) as the biological basis for the oscillator dynamics, the phase $\\theta(t)$ of the oscillator relative to a reference phase $\\theta_{\\mathrm{ref}}(t)$ evolves approximately as $\\dot{\\theta}(t) = \\omega + Z(\\theta(t))^\\top B\\,u(t)$, where $Z(\\cdot)$ is the phase response curve. Let $\\phi(t) = \\theta(t) - \\theta_{\\mathrm{ref}}(t)$ denote the phase error and $\\Delta \\omega = \\omega - \\omega_{\\mathrm{ref}}$ the frequency mismatch. Linearizing the phase dynamics along the reference trajectory yields the scalar, time-varying affine control system\n$\\dot{\\phi}(t) = \\Delta \\omega - \\Gamma(t)\\,u(t)$,\nwhere $\\Gamma(t) = Z(\\theta_{\\mathrm{ref}}(t))^\\top B$. Suppose that the experiment operates in nondimensional time (no physical units), phases are measured in radians, and light intensity is nondimensionalized. The control objective over a finite horizon $[0,T]$ is to phase-lock by driving $\\phi(T)$ close to zero while minimizing the energy of light exposure. In the linearized setting, this is posed as minimizing the quadratic control effort\n$\\int_0^T u(t)^2\\,dt$\nsubject to the dynamics $\\dot{\\phi}(t) = \\Delta \\omega - \\Gamma(t)\\,u(t)$, with initial condition $\\phi(0) = \\phi_0$ and terminal constraint $\\phi(T) = 0$. Assume there are no amplitude constraints on $u(t)$. For computational tractability, take $\\Gamma(t)$ as a known sinusoidal function\n$\\Gamma(t) = \\kappa \\,\\sin\\!\\big(\\omega_{\\mathrm{ref}} t + \\psi\\big)$,\nwith known amplitude $\\kappa  0$, reference frequency $\\omega_{\\mathrm{ref}}  0$, and phase shift $\\psi \\in \\mathbb{R}$.\n\nTask: Write a program that, for each test case specified below, computes the minimal achievable energy value $J^\\star = \\min_{u} \\int_0^T u(t)^2\\,dt$ under the linearized phase model and boundary conditions. Angles must be treated in radians. Time is nondimensional. The output for each test case must be a single real number (a float) equal to $J^\\star$.\n\nTest suite (each test case is a tuple $(\\phi_0,\\Delta \\omega,\\kappa,\\omega_{\\mathrm{ref}},\\psi,T)$ with all angles in radians and time nondimensional):\n- Case A: $(\\phi_0,\\Delta \\omega,\\kappa,\\omega_{\\mathrm{ref}},\\psi,T) = (\\,0.5,\\,0.05,\\,1.0,\\,1.0,\\,0.0,\\,2\\pi\\,)$.\n- Case B: $(\\phi_0,\\Delta \\omega,\\kappa,\\omega_{\\mathrm{ref}},\\psi,T) = (\\,0.5,\\,0.05,\\,0.1,\\,1.0,\\,0.0,\\,2\\pi\\,)$.\n- Case C: $(\\phi_0,\\Delta \\omega,\\kappa,\\omega_{\\mathrm{ref}},\\psi,T) = (\\,0.2,\\,0.01,\\,0.8,\\,1.0,\\,\\pi/4,\\,3\\pi\\,)$.\n- Case D: $(\\phi_0,\\Delta \\omega,\\kappa,\\omega_{\\mathrm{ref}},\\psi,T) = (\\,-0.3,\\,-0.02,\\,0.5,\\,1.2,\\,\\pi/3,\\,4\\pi\\,)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list of the $J^\\star$ values for Cases A, B, C, and D, in that order, enclosed in square brackets, for example $[j_A,j_B,j_C,j_D]$, where each $j_\\cdot$ is a float. No other text should be printed.", "solution": "The problem presented is to determine the minimum control energy required to drive the phase error of a synthetic gene oscillator to zero over a finite time horizon. This is a well-posed optimal control problem. We will solve it using Pontryagin's Minimum Principle (PMP).\n\nThe system is described by the following components:\n1.  **State Equation**: A scalar linear time-varying affine differential equation for the phase error $\\phi(t)$:\n    $$ \\dot{\\phi}(t) = \\Delta \\omega - \\Gamma(t)\\,u(t) $$\n2.  **Boundary Conditions**: The initial and terminal phase errors are specified:\n    $$ \\phi(0) = \\phi_0, \\quad \\phi(T) = 0 $$\n3.  **Control Response Function**: The function $\\Gamma(t)$ is given as:\n    $$ \\Gamma(t) = \\kappa \\sin(\\omega_{\\mathrm{ref}} t + \\psi) $$\n4.  **Cost Functional**: The objective is to minimize the total energy of the control input $u(t)$, which is defined by the quadratic cost functional:\n    $$ J[u] = \\int_0^T u(t)^2\\,dt $$\n\nTo find the optimal control $u^\\star(t)$ that minimizes $J[u]$, we apply PMP. We first define the Hamiltonian $H$ for the system. The integrand of the cost functional is $L(u) = u(t)^2$.\nThe Hamiltonian is given by $H(t) = L(u(t)) + p(t) \\cdot \\dot{\\phi}(t)$, where $p(t)$ is the costate variable associated with the state $\\phi(t)$.\n\n$$ H(\\phi, p, u, t) = u(t)^2 + p(t)[\\Delta \\omega - \\Gamma(t)u(t)] $$\n\nThe necessary conditions for optimality from PMP are:\n1.  **State Equation**: $\\dot{\\phi}(t) = \\frac{\\partial H}{\\partial p} = \\Delta \\omega - \\Gamma(t)u(t)$. This is the given system dynamics.\n2.  **Costate Equation**: The dynamics of the costate are given by $\\dot{p}(t) = -\\frac{\\partial H}{\\partial \\phi}$. Since the Hamiltonian does not explicitly depend on $\\phi$, we have:\n    $$ \\dot{p}(t) = -\\frac{\\partial}{\\partial \\phi} \\left( u(t)^2 + p(t)[\\Delta \\omega - \\Gamma(t)u(t)] \\right) = 0 $$\n    This implies that the costate $p(t)$ is a constant for all $t \\in [0, T]$. Let us denote this constant by $p_0$. So, $p(t) = p_0$.\n3.  **Minimization of the Hamiltonian**: The optimal control $u^\\star(t)$ must minimize $H$ at each instant in time. Since there are no constraints on $u(t)$, we can find the minimum by setting the partial derivative of $H$ with respect to $u$ to zero:\n    $$ \\frac{\\partial H}{\\partial u} = 2u(t) - p(t)\\Gamma(t) = 0 $$\n    Solving for $u(t)$ and using $p(t)=p_0$, we obtain the form of the optimal control:\n    $$ u^\\star(t) = \\frac{1}{2} p_0 \\Gamma(t) $$\n\nNow we must determine the value of the constant $p_0$. We substitute the expression for the optimal control $u^\\star(t)$ back into the state equation:\n$$ \\dot{\\phi}(t) = \\Delta \\omega - \\Gamma(t) u^\\star(t) = \\Delta \\omega - \\Gamma(t) \\left( \\frac{1}{2} p_0 \\Gamma(t) \\right) = \\Delta \\omega - \\frac{p_0}{2} \\Gamma(t)^2 $$\nTo find $p_0$, we integrate this equation over the time interval $[0, T]$ and apply the boundary conditions $\\phi(0) = \\phi_0$ and $\\phi(T) = 0$.\n$$ \\int_0^T \\dot{\\phi}(t)\\,dt = \\phi(T) - \\phi(0) = 0 - \\phi_0 = -\\phi_0 $$\nAlso,\n$$ \\int_0^T \\left( \\Delta \\omega - \\frac{p_0}{2} \\Gamma(t)^2 \\right) dt = \\Delta \\omega \\int_0^T dt - \\frac{p_0}{2} \\int_0^T \\Gamma(t)^2 dt = \\Delta \\omega \\, T - \\frac{p_0}{2} \\int_0^T \\Gamma(t)^2 dt $$\nEquating the two expressions for the integral of $\\dot{\\phi}(t)$:\n$$ -\\phi_0 = \\Delta \\omega \\, T - \\frac{p_0}{2} \\int_0^T \\Gamma(t)^2 dt $$\nSolving for the term $\\frac{p_0}{2}$:\n$$ \\frac{p_0}{2} \\int_0^T \\Gamma(t)^2 dt = \\phi_0 + \\Delta \\omega \\, T $$\n$$ \\frac{p_0}{2} = \\frac{\\phi_0 + \\Delta \\omega \\, T}{\\int_0^T \\Gamma(t)^2 dt} $$\nThis expression is well-defined provided that $\\int_0^T \\Gamma(t)^2 dt \\neq 0$. Since $\\Gamma(t)$ is sinusoidal and $\\kappa  0$, its square is non-negative, and the integral is guaranteed to be positive for any $T  0$.\n\nNow we can compute the minimal energy $J^\\star$. We substitute the optimal control $u^\\star(t) = \\frac{p_0}{2}\\Gamma(t)$ into the cost functional:\n$$ J^\\star = \\int_0^T (u^\\star(t))^2 dt = \\int_0^T \\left( \\frac{p_0}{2} \\Gamma(t) \\right)^2 dt = \\left( \\frac{p_0}{2} \\right)^2 \\int_0^T \\Gamma(t)^2 dt $$\nSubstituting the expression for $\\frac{p_0}{2}$:\n$$ J^\\star = \\left( \\frac{\\phi_0 + \\Delta \\omega \\, T}{\\int_0^T \\Gamma(\\tau)^2 d\\tau} \\right)^2 \\int_0^T \\Gamma(t)^2 dt = \\frac{(\\phi_0 + \\Delta \\omega \\, T)^2}{\\int_0^T \\Gamma(t)^2 dt} $$\nThe final step is to calculate the integral in the denominator. Let $I = \\int_0^T \\Gamma(t)^2 dt$.\n$$ \\Gamma(t)^2 = \\left( \\kappa \\sin(\\omega_{\\mathrm{ref}} t + \\psi) \\right)^2 = \\kappa^2 \\sin^2(\\omega_{\\mathrm{ref}} t + \\psi) $$\nUsing the trigonometric identity $\\sin^2(x) = \\frac{1 - \\cos(2x)}{2}$:\n$$ \\Gamma(t)^2 = \\kappa^2 \\left( \\frac{1 - \\cos(2(\\omega_{\\mathrm{ref}} t + \\psi))}{2} \\right) = \\frac{\\kappa^2}{2} \\left( 1 - \\cos(2\\omega_{\\mathrm{ref}} t + 2\\psi) \\right) $$\nNow we integrate this expression from $0$ to $T$:\n$$ I = \\int_0^T \\frac{\\kappa^2}{2} \\left( 1 - \\cos(2\\omega_{\\mathrm{ref}} t + 2\\psi) \\right) dt $$\n$$ I = \\frac{\\kappa^2}{2} \\left[ \\int_0^T 1\\,dt - \\int_0^T \\cos(2\\omega_{\\mathrm{ref}} t + 2\\psi)\\,dt \\right] $$\n$$ I = \\frac{\\kappa^2}{2} \\left[ t - \\frac{\\sin(2\\omega_{\\mathrm{ref}} t + 2\\psi)}{2\\omega_{\\mathrm{ref}}} \\right]_0^T $$\n$$ I = \\frac{\\kappa^2}{2} \\left[ \\left( T - \\frac{\\sin(2\\omega_{\\mathrm{ref}} T + 2\\psi)}{2\\omega_{\\mathrm{ref}}} \\right) - \\left( 0 - \\frac{\\sin(2\\psi)}{2\\omega_{\\mathrm{ref}}} \\right) \\right] $$\n$$ I = \\frac{\\kappa^2}{2} \\left( T - \\frac{\\sin(2\\omega_{\\mathrm{ref}} T + 2\\psi) - \\sin(2\\psi)}{2\\omega_{\\mathrm{ref}}} \\right) $$\nThe minimal energy is therefore given by:\n$$ J^\\star = \\frac{(\\phi_0 + \\Delta \\omega \\, T)^2}{\\frac{\\kappa^2}{2} \\left( T - \\frac{\\sin(2\\omega_{\\mathrm{ref}} T + 2\\psi) - \\sin(2\\psi)}{2\\omega_{\\mathrm{ref}}} \\right)} $$\nThis formula allows for the direct computation of the minimum energy for each test case.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the minimal achievable energy J* for a series of test cases\n    based on an optimal control problem for a linearized phase model.\n    \"\"\"\n\n    def calculate_min_energy(phi0, delta_omega, kappa, omega_ref, psi, T):\n        \"\"\"\n        Calculates the minimal energy J* using the derived analytical formula.\n\n        Args:\n            phi0 (float): Initial phase error.\n            delta_omega (float): Frequency mismatch.\n            kappa (float): Amplitude of the control response function.\n            omega_ref (float): Reference frequency.\n            psi (float): Phase shift of the control response function.\n            T (float): Time horizon.\n\n        Returns:\n            float: The minimal energy J*.\n        \"\"\"\n        # Numerator of the J* formula: (phi_0 + delta_omega * T)^2\n        numerator = (phi0 + delta_omega * T)**2\n\n        # Denominator of the J* formula: integral of Gamma(t)^2 from 0 to T\n        # integral_val = (kappa^2 / 2) * (T - (sin(2*omega_ref*T + 2*psi) - sin(2*psi)) / (2*omega_ref))\n        \n        # Calculate the sinusoidal term in the integral\n        sin_term = (np.sin(2 * omega_ref * T + 2 * psi) - np.sin(2 * psi)) / (2 * omega_ref)\n        \n        # Calculate the full integral\n        integral_val = (kappa**2 / 2) * (T - sin_term)\n\n        # The system must be controllable, which means integral_val must be non-zero.\n        # Given kappa  0 and T  0, the integral will be positive.\n        if integral_val = 1e-12: # Use a small tolerance for floating point comparison\n            # This case should not be reached with the given problem constraints.\n            # It indicates loss of controllability.\n            return float('inf')\n\n        # Calculate the minimal energy J*\n        j_star = numerator / integral_val\n        \n        return j_star\n\n    # Test cases from the problem statement\n    # Each case is a tuple (phi_0, delta_omega, kappa, omega_ref, psi, T)\n    test_cases = [\n        (0.5, 0.05, 1.0, 1.0, 0.0, 2 * np.pi),          # Case A\n        (0.5, 0.05, 0.1, 1.0, 0.0, 2 * np.pi),          # Case B\n        (0.2, 0.01, 0.8, 1.0, np.pi / 4, 3 * np.pi),    # Case C\n        (-0.3, -0.02, 0.5, 1.2, np.pi / 3, 4 * np.pi),  # Case D\n    ]\n\n    results = []\n    for case in test_cases:\n        phi0, delta_omega, kappa, omega_ref, psi, T = case\n        result = calculate_min_energy(phi0, delta_omega, kappa, omega_ref, psi, T)\n        results.append(result)\n\n    # Format the final output as a comma-separated list of floats in brackets\n    # Example format: [j_A,j_B,j_C,j_D]\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3335265"}, {"introduction": "This practice introduces Model Predictive Control (MPC), a versatile and powerful framework for real-time control that is exceptionally well-suited for biological systems with operational constraints. You will learn to formulate a complete MPC strategy to make a gene's expression level track a desired time-varying reference trajectory, while respecting limits on the control input. The exercise walks through the essential steps of model discretization, formulating the optimization problem as a constrained Quadratic Program (QP), and implementing the receding-horizon logic that gives MPC its robustness [@problem_id:3335315].", "problem": "Consider a single-gene regulatory circuit where the concentration of a transcription factor is denoted by $x(t)$, measured in nanomolar (nM), and the external control input (e.g., inducer intensity) is denoted by $u(t)$, dimensionless in the range $[0,1]$. Based on mass-balance and first-order kinetics, assume that synthesis is proportional to the input with rate proportionality $ \\alpha $ (in nM/s per unit input) plus a basal synthesis term $ \\gamma $ (in nM/s), and degradation is first-order with rate $ \\beta $ (in s$^{-1}$). The continuous-time dynamics are described by the ordinary differential equation\n$$\n\\frac{dx(t)}{dt} = \\alpha\\,u(t) - \\beta\\,x(t) + \\gamma.\n$$\nYou will design a Model Predictive Control (MPC) strategy. MPC is a receding-horizon optimal control method that repeatedly solves a finite-horizon optimization problem using a model, applies the first control move, and then updates with new measurements.\n\nTask 1 (Model derivation and linearization): Starting from the given dynamics, define the steady-state $(x^\\ast,u^\\ast)$ by satisfying $ \\frac{dx}{dt} = 0 $. Around $(x^\\ast,u^\\ast)$, linearize the dynamics in deviation variables $ \\delta x(t) = x(t) - x^\\ast $ and $ \\delta u(t) = u(t) - u^\\ast $. Under a zero-order hold for the input $u(t)$ over sampling period $T_s$ (in s), derive the exact discrete-time model. Express it both for the absolute variables and for the deviation variables. For the absolute variables, show that\n$$\nx_{k+1} = A\\,x_k + B\\,u_k + c,\n$$\nwhere $A$, $B$, and $c$ are functions of $\\beta$, $\\alpha$, $\\gamma$, and $T_s$. For deviation variables, show that\n$$\n\\delta x_{k+1} = A\\,\\delta x_k + B\\,\\delta u_k.\n$$\n\nTask 2 (Finite-horizon tracking formulation): For a prediction horizon of $N$ steps, define a tracking objective for a given reference trajectory $r_1,\\dots,r_N$ in nM. Let the cost be\n$$\nJ = \\sum_{i=1}^{N} q\\,\\big( x_i - r_i \\big)^2 + \\sum_{i=0}^{N-1} r_u\\,\\big( u_i - u_{\\mathrm{ref},i} \\big)^2,\n$$\nwhere $q \\ge 0$ is the state tracking weight, $r_u  0$ is the input deviation penalty, and $u_{\\mathrm{ref},i}$ is a chosen reference input sequence. Enforce hard input bounds $u_{\\min} \\le u_i \\le u_{\\max}$ for all steps in the horizon.\n\nTask 3 (Quadratic program derivation for linearized dynamics): Using the absolute affine discrete-time model and the horizon, derive the condensed prediction model\n$$\n\\mathbf{x} = \\mathbf{M}\\,x_0 + \\mathbf{T}\\,\\mathbf{u} + \\mathbf{t},\n$$\nwhere $\\mathbf{x} \\in \\mathbb{R}^{N}$ stacks the predicted states $x_1,\\dots,x_N$, $\\mathbf{u} \\in \\mathbb{R}^{N}$ stacks the inputs $u_0,\\dots,u_{N-1}$, $\\mathbf{M} \\in \\mathbb{R}^{N \\times 1}$, $\\mathbf{T} \\in \\mathbb{R}^{N \\times N}$, and $\\mathbf{t} \\in \\mathbb{R}^{N}$ encodes the affine contributions from $c$. Then express $J$ as a convex quadratic function of $\\mathbf{u}$,\n$$\nJ(\\mathbf{u}) = \\frac{1}{2}\\,\\mathbf{u}^{\\top}\\mathbf{H}\\,\\mathbf{u} + \\mathbf{g}^{\\top}\\mathbf{u} + \\text{constant},\n$$\nby eliminating $\\mathbf{x}$ using the condensed model, where $\\mathbf{H} \\succ 0$ and $\\mathbf{g}$ depend on $\\mathbf{M}$, $\\mathbf{T}$, $\\mathbf{t}$, $x_0$, and the reference trajectory. State the bound constraints in the form $u_{\\min} \\le u_i \\le u_{\\max}$ for all $i$, and indicate that this leads to a box-constrained quadratic program in $\\mathbf{u}$.\n\nTask 4 (Receding horizon update law): Define the receding horizon law as\n$$\nu_k = \\big(\\mathbf{u}^{\\ast}\\big)_0,\n$$\nwhere $\\mathbf{u}^{\\ast}$ is the optimal input sequence obtained by solving the finite-horizon quadratic program at time $k$, and only the first control action is applied. The state is updated using the discrete-time model and the measurement at the next time step is used to repeat the process.\n\nTask 5 (Implementation and test suite): Implement a program that, for each test case below, constructs the discrete-time model, formulates the condensed quadratic program for the given horizon and reference trajectory, solves for the optimal input sequence subject to box constraints $u_{\\min} \\le u_i \\le u_{\\max}$, applies the receding horizon update by taking the first input $u_0$, and computes the next state $x_1$. The output for each test case must be a list with two floats $[u_0, x_1]$, where $u_0$ is dimensionless and $x_1$ is in nM. The program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the format\n$$\n\\text{[}[u_0^{(1)},x_1^{(1)}],[u_0^{(2)},x_1^{(2)}],\\dots\\text{]},\n$$\nwith all numeric values expressed as decimal numbers. Angles are not involved. All concentrations must be understood to be in nM and times in s.\n\nUse the following test suite parameter sets, designed to probe a happy path, a saturation edge case, a single-step boundary, and a high control-effort penalty case. In each case, $u_{\\min}$ and $u_{\\max}$ are dimensionless bounds.\n\n- Test Case 1 (happy path):\n  - $\\alpha = 0.5$ nM/s per unit input, $\\beta = 0.3$ s$^{-1}$, $\\gamma = 0.2$ nM/s, $T_s = 10$ s,\n  - $x_0 = 5.0$ nM, $N = 5$, $q = 1.0$, $r_u = 0.02$, $u_{\\min} = 0.0$, $u_{\\max} = 1.0$, $u_{\\mathrm{ref},i} = 0.5$ for all $i$,\n  - $r = [5.5, 6.0, 6.5, 7.0, 7.5]$ nM.\n\n- Test Case 2 (tight upper bound causes saturation):\n  - $\\alpha = 0.8$ nM/s per unit input, $\\beta = 0.2$ s$^{-1}$, $\\gamma = 0.1$ nM/s, $T_s = 10$ s,\n  - $x_0 = 4.0$ nM, $N = 5$, $q = 1.0$, $r_u = 0.05$, $u_{\\min} = 0.0$, $u_{\\max} = 0.2$, $u_{\\mathrm{ref},i} = 0.0$ for all $i$,\n  - $r = [8.0, 8.0, 8.0, 8.0, 8.0]$ nM.\n\n- Test Case 3 (boundary case with single-step horizon):\n  - $\\alpha = 0.6$ nM/s per unit input, $\\beta = 0.05$ s$^{-1}$, $\\gamma = 0.0$ nM/s, $T_s = 20$ s,\n  - $x_0 = 3.0$ nM, $N = 1$, $q = 1.0$, $r_u = 0.01$, $u_{\\min} = 0.0$, $u_{\\max} = 1.0$, $u_{\\mathrm{ref},0} = 0.0$,\n  - $r = [5.0]$ nM.\n\n- Test Case 4 (high penalty on control effort):\n  - $\\alpha = 0.5$ nM/s per unit input, $\\beta = 0.3$ s$^{-1}$, $\\gamma = 0.2$ nM/s, $T_s = 10$ s,\n  - $x_0 = 6.0$ nM, $N = 5$, $q = 1.0$, $r_u = 1.0$, $u_{\\min} = 0.0$, $u_{\\max} = 1.0$, $u_{\\mathrm{ref},i} = 0.0$ for all $i$,\n  - $r = [7.0, 7.0, 7.0, 7.0, 7.0]$ nM.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each test case reported as $[u_0,x_1]$ in the order shown above. For example, the output must look like\n$$\n\\text{[[}u_0^{(1)},x_1^{(1)}\\text{],[}u_0^{(2)},x_1^{(2)}\\text{],[}u_0^{(3)},x_1^{(3)}\\text{],[}u_0^{(4)},x_1^{(4)}\\text{]]}.\n$$", "solution": "The problem is valid as it is scientifically grounded, well-posed, and objective. It poses a standard problem in Model Predictive Control (MPC) theory applied to a linear model of a gene regulatory circuit, a common application area in computational systems biology. All necessary definitions, parameters, and constraints are provided, and the tasks form a logical sequence for deriving and implementing an MPC controller.\n\n### Task 1: Model Derivation and Linearization\n\nThe continuous-time dynamics of the transcription factor concentration $x(t)$ are given by the linear ordinary differential equation (ODE):\n$$\n\\frac{dx(t)}{dt} = \\alpha\\,u(t) - \\beta\\,x(t) + \\gamma\n$$\nwhere $x(t)$ is the state, $u(t)$ is the control input, and $\\alpha, \\beta, \\gamma$ are constant parameters.\n\n**Steady-State and Linearization:**\nA steady-state $(x^\\ast, u^\\ast)$ is defined by the condition $\\frac{dx}{dt} = 0$. Substituting this into the ODE gives:\n$$\n0 = \\alpha\\,u^\\ast - \\beta\\,x^\\ast + \\gamma\n$$\nThis defines a linear relationship between the steady-state input $u^\\ast$ and the steady-state output $x^\\ast$:\n$$\nx^\\ast = \\frac{\\alpha u^\\ast + \\gamma}{\\beta}\n$$\nTo linearize the dynamics around this steady-state, we define deviation variables $\\delta x(t) = x(t) - x^\\ast$ and $\\delta u(t) = u(t) - u^\\ast$. The derivative of the deviation state is $\\frac{d(\\delta x)}{dt} = \\frac{dx}{dt}$. Substituting $x(t) = \\delta x(t) + x^\\ast$ and $u(t) = \\delta u(t) + u^\\ast$ into the original ODE:\n$$\n\\frac{d(\\delta x)}{dt} = \\alpha(\\delta u(t) + u^\\ast) - \\beta(\\delta x(t) + x^\\ast) + \\gamma\n$$\n$$\n\\frac{d(\\delta x)}{dt} = \\alpha\\,\\delta u(t) - \\beta\\,\\delta x(t) + (\\alpha u^\\ast - \\beta x^\\ast + \\gamma)\n$$\nBy definition of the steady-state, the term in parentheses is zero. Thus, the linearized dynamics in deviation variables are:\n$$\n\\frac{d(\\delta x)}{dt} = -\\beta\\,\\delta x(t) + \\alpha\\,\\delta u(t)\n$$\nThis is a linear system of the form $\\dot{\\delta x} = A_{cont} \\delta x + B_{cont} \\delta u$, with $A_{cont} = -\\beta$ and $B_{cont} = \\alpha$.\n\n**Exact Discretization:**\nWe assume a zero-order hold on the input $u(t)$ over a sampling period $T_s$, meaning $u(t) = u_k$ for $t \\in [kT_s, (k+1)T_s)$.\n\nFor the **absolute variables**, we solve the affine ODE $\\frac{dx}{dt} = -\\beta x(t) + (\\alpha u_k + \\gamma)$ over the interval $[kT_s, (k+1)T_s]$ with initial condition $x(kT_s) = x_k$. The solution is:\n$$\nx(t) = e^{-\\beta(t-kT_s)} x_k + \\int_{kT_s}^{t} e^{-\\beta(t-\\tau)} (\\alpha u_k + \\gamma) d\\tau\n$$\nSetting $t = (k+1)T_s$:\n$$\nx_{k+1} = e^{-\\beta T_s} x_k + (\\alpha u_k + \\gamma) \\int_{kT_s}^{(k+1)T_s} e^{-\\beta((k+1)T_s-\\tau)} d\\tau\n$$\nThe integral evaluates to $\\frac{1}{\\beta}(1 - e^{-\\beta T_s})$ for $\\beta \\neq 0$. Thus:\n$$\nx_{k+1} = e^{-\\beta T_s} x_k + \\frac{1}{\\beta}(1 - e^{-\\beta T_s})(\\alpha u_k + \\gamma)\n$$\nThis can be written in the form $x_{k+1} = A\\,x_k + B\\,u_k + c$, where:\n$$\nA = e^{-\\beta T_s}\n$$\n$$\nB = \\frac{\\alpha}{\\beta}(1 - e^{-\\beta T_s})\n$$\n$$\nc = \\frac{\\gamma}{\\beta}(1 - e^{-\\beta T_s})\n$$\n\nFor the **deviation variables**, the dynamics are $\\frac{d(\\delta x)}{dt} = -\\beta\\,\\delta x + \\alpha\\,\\delta u$. This is a standard linear system. The exact discretization leads to $\\delta x_{k+1} = A_d \\delta x_k + B_d \\delta u_k$. The discrete-time matrices are given by:\n$$\nA_d = e^{A_{cont} T_s} = e^{-\\beta T_s}\n$$\n$$\nB_d = \\int_0^{T_s} e^{A_{cont}\\tau} B_{cont} d\\tau = \\int_0^{T_s} e^{-\\beta\\tau} \\alpha d\\tau = \\alpha \\left[-\\frac{1}{\\beta}e^{-\\beta\\tau}\\right]_0^{T_s} = \\frac{\\alpha}{\\beta}(1 - e^{-\\beta T_s})\n$$\nThus, the discrete-time model for deviation variables is $\\delta x_{k+1} = A\\,\\delta x_k + B\\,\\delta u_k$, with the same $A$ and $B$ as for the absolute model, as expected.\n\n### Task 2: Finite-Horizon Tracking Formulation\n\nThe objective is to make the state trajectory $x_1, \\dots, x_N$ follow a reference trajectory $r_1, \\dots, r_N$ over a prediction horizon of $N$ steps. The performance is measured by the quadratic cost function:\n$$\nJ = \\sum_{i=1}^{N} q\\,\\big( x_i - r_i \\big)^2 + \\sum_{i=0}^{N-1} r_u\\,\\big( u_i - u_{\\mathrm{ref},i} \\big)^2\n$$\nHere, $q \\ge 0$ penalizes state tracking errors, and $r_u  0$ penalizes deviations of the control input $u_i$ from a reference input $u_{\\mathrm{ref},i}$.\nThe control inputs are subject to hard physical or operational constraints, expressed as box constraints:\n$$\nu_{\\min} \\le u_i \\le u_{\\max} \\quad \\text{for } i = 0, 1, \\dots, N-1\n$$\nThe MPC problem consists of minimizing $J$ subject to these constraints at each time step.\n\n### Task 3: Quadratic Program (QP) Derivation\n\nTo formulate the optimization problem as a standard QP, we express the predicted state sequence $\\mathbf{x} = [x_1, x_2, \\dots, x_N]^{\\top}$ as an affine function of the initial state $x_0$ and the control input sequence $\\mathbf{u} = [u_0, u_1, \\dots, u_{N-1}]^{\\top}$.\n\n**Condensed Prediction Model:**\nBy recursively applying the discrete-time model $x_{k+1} = Ax_k + Bu_k + c$, we get:\n$x_1 = Ax_0 + Bu_0 + c$\n$x_2 = A x_1 + B u_1 + c = A^2 x_0 + AB u_0 + B u_1 + (A+1)c$\n...\n$x_i = A^i x_0 + \\sum_{j=0}^{i-1} A^{i-1-j} B u_j + \\left(\\sum_{j=0}^{i-1} A^j\\right) c$\n\nThis can be written in matrix form as $\\mathbf{x} = \\mathbf{M}\\,x_0 + \\mathbf{T}\\,\\mathbf{u} + \\mathbf{t}$, where:\n$$\n\\mathbf{M} = \\begin{bmatrix} A \\\\ A^2 \\\\ \\vdots \\\\ A^N \\end{bmatrix}, \\quad\n\\mathbf{T} = \\begin{bmatrix}\nB  0  \\dots  0 \\\\\nAB  B  \\dots  0 \\\\\n\\vdots  \\vdots  \\ddots  \\vdots \\\\\nA^{N-1}B  A^{N-2}B  \\dots  B\n\\end{bmatrix}, \\quad\n\\mathbf{t} = \\begin{bmatrix}\nc \\\\\n(A+1)c \\\\\n\\vdots \\\\\n(\\sum_{j=0}^{N-1} A^j)c\n\\end{bmatrix}\n$$\nHere, $\\mathbf{M} \\in \\mathbb{R}^{N \\times 1}$, $\\mathbf{T} \\in \\mathbb{R}^{N \\times N}$ is a lower triangular matrix, and $\\mathbf{t} \\in \\mathbb{R}^{N \\times 1}$.\n\n**QP Formulation:**\nThe cost function can be written in vector form as:\n$$\nJ(\\mathbf{u}) = (\\mathbf{x} - \\mathbf{r})^{\\top} \\mathbf{Q} (\\mathbf{x} - \\mathbf{r}) + (\\mathbf{u} - \\mathbf{u}_{\\mathrm{ref}})^{\\top} \\mathbf{R} (\\mathbf{u} - \\mathbf{u}_{\\mathrm{ref}})\n$$\nwhere $\\mathbf{r} = [r_1, \\dots, r_N]^{\\top}$, $\\mathbf{u}_{\\mathrm{ref}} = [u_{\\mathrm{ref},0}, \\dots, u_{\\mathrm{ref},N-1}]^{\\top}$, $\\mathbf{Q} = q \\cdot I_{N\\times N}$, and $\\mathbf{R} = r_u \\cdot I_{N\\times N}$.\n\nSubstituting the condensed model $\\mathbf{x} = \\mathbf{M}x_0 + \\mathbf{T}\\mathbf{u} + \\mathbf{t}$ into $J$:\n$$\nJ(\\mathbf{u}) = (\\mathbf{M}x_0 + \\mathbf{T}\\mathbf{u} + \\mathbf{t} - \\mathbf{r})^{\\top} \\mathbf{Q} (\\mathbf{M}x_0 + \\mathbf{T}\\mathbf{u} + \\mathbf{t} - \\mathbf{r}) + (\\mathbf{u} - \\mathbf{u}_{\\mathrm{ref}})^{\\top} \\mathbf{R} (\\mathbf{u} - \\mathbf{u}_{\\mathrm{ref}})\n$$\nTo obtain the standard QP form $J(\\mathbf{u}) = \\frac{1}{2}\\mathbf{u}^{\\top}\\mathbf{H}\\,\\mathbf{u} + \\mathbf{g}^{\\top}\\mathbf{u} + \\text{constant}$, we extract the quadratic and linear terms in $\\mathbf{u}$:\nQuadratic term: $\\mathbf{u}^{\\top} \\mathbf{T}^{\\top} \\mathbf{Q} \\mathbf{T} \\mathbf{u} + \\mathbf{u}^{\\top} \\mathbf{R} \\mathbf{u} = \\mathbf{u}^{\\top} (\\mathbf{T}^{\\top} \\mathbf{Q} \\mathbf{T} + \\mathbf{R}) \\mathbf{u}$\nLinear term: $2(\\mathbf{M}x_0 + \\mathbf{t} - \\mathbf{r})^{\\top} \\mathbf{Q} \\mathbf{T} \\mathbf{u} - 2\\mathbf{u}_{\\mathrm{ref}}^{\\top}\\mathbf{R}\\mathbf{u} = 2[\\mathbf{T}^{\\top}\\mathbf{Q}(\\mathbf{M}x_0 + \\mathbf{t} - \\mathbf{r}) - \\mathbf{R}\\mathbf{u}_{\\mathrm{ref}}]^{\\top} \\mathbf{u}$\n\nComparing with the standard form, we identify the Hessian matrix $\\mathbf{H}$ and the gradient vector $\\mathbf{g}$:\n$$\n\\mathbf{H} = 2(\\mathbf{T}^{\\top} \\mathbf{Q} \\mathbf{T} + \\mathbf{R}) = 2(q \\mathbf{T}^{\\top} \\mathbf{T} + r_u I)\n$$\n$$\n\\mathbf{g} = 2(\\mathbf{T}^{\\top} \\mathbf{Q} (\\mathbf{M}x_0 + \\mathbf{t} - \\mathbf{r}) - \\mathbf{R}\\mathbf{u}_{\\mathrm{ref}}) = 2(q \\mathbf{T}^{\\top} (\\mathbf{M}x_0 + \\mathbf{t} - \\mathbf{r}) - r_u \\mathbf{u}_{\\mathrm{ref}})\n$$\nSince $r_u  0$, $\\mathbf{R}$ is positive definite. Since $q \\ge 0$, $\\mathbf{Q}$ is positive semi-definite. Thus, $\\mathbf{H}$ is positive definite, guaranteeing that the QP has a unique minimum.\n\nThe optimization problem is a box-constrained quadratic program:\n$$\n\\min_{\\mathbf{u} \\in \\mathbb{R}^N} \\quad \\frac{1}{2}\\mathbf{u}^{\\top}\\mathbf{H}\\,\\mathbf{u} + \\mathbf{g}^{\\top}\\mathbf{u}\n$$\n$$\n\\text{subject to} \\quad u_{\\min} \\le u_i \\le u_{\\max} \\quad \\text{for } i = 0, \\dots, N-1\n$$\n\n### Task 4: Receding Horizon Update Law\n\nThe receding horizon principle dictates the control action at each time step $k$. The procedure is:\n1.  Measure or estimate the current state $x_k$ of the system.\n2.  Solve the finite-horizon, box-constrained QP derived in Task 3, using $x_k$ as the initial state $x_0$. This yields an optimal control sequence $\\mathbf{u}^{\\ast} = [u_0^{\\ast}, u_1^{\\ast}, \\dots, u_{N-1}^{\\ast}]^{\\top}$.\n3.  Apply only the first element of this sequence to the plant: $u_k = u_0^{\\ast}$.\n4.  Allow the system to evolve for one sampling period $T_s$. The new state is $x_{k+1}$.\n5.  At the next time step, $k \\leftarrow k+1$, repeat the process from step 1. This \"receding\" of the horizon provides feedback and robustness to disturbances and model mismatch.\n\n### Task 5: Implementation and Test Suite\n\nThe implementation of this MPC strategy for the given test cases is provided in the final answer section. The code constructs the model and QP matrices as derived above, solves the optimization problem using a numerical solver, and computes the first control action and resulting state.", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Solves the MPC problem for a single-gene regulatory circuit for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        # Test Case 1 (happy path)\n        {\n            \"params\": {\"alpha\": 0.5, \"beta\": 0.3, \"gamma\": 0.2, \"Ts\": 10.0},\n            \"mpc\": {\"N\": 5, \"q\": 1.0, \"ru\": 0.02, \"umin\": 0.0, \"umax\": 1.0},\n            \"initial\": {\"x0\": 5.0},\n            \"refs\": {\n                \"r\": np.array([5.5, 6.0, 6.5, 7.0, 7.5]),\n                \"u_ref\": np.full(5, 0.5),\n            },\n        },\n        # Test Case 2 (tight upper bound causes saturation)\n        {\n            \"params\": {\"alpha\": 0.8, \"beta\": 0.2, \"gamma\": 0.1, \"Ts\": 10.0},\n            \"mpc\": {\"N\": 5, \"q\": 1.0, \"ru\": 0.05, \"umin\": 0.0, \"umax\": 0.2},\n            \"initial\": {\"x0\": 4.0},\n            \"refs\": {\n                \"r\": np.full(5, 8.0),\n                \"u_ref\": np.full(5, 0.0),\n            },\n        },\n        # Test Case 3 (boundary case with single-step horizon)\n        {\n            \"params\": {\"alpha\": 0.6, \"beta\": 0.05, \"gamma\": 0.0, \"Ts\": 20.0},\n            \"mpc\": {\"N\": 1, \"q\": 1.0, \"ru\": 0.01, \"umin\": 0.0, \"umax\": 1.0},\n            \"initial\": {\"x0\": 3.0},\n            \"refs\": {\n                \"r\": np.array([5.0]),\n                \"u_ref\": np.array([0.0]),\n            },\n        },\n        # Test Case 4 (high penalty on control effort)\n        {\n            \"params\": {\"alpha\": 0.5, \"beta\": 0.3, \"gamma\": 0.2, \"Ts\": 10.0},\n            \"mpc\": {\"N\": 5, \"q\": 1.0, \"ru\": 1.0, \"umin\": 0.0, \"umax\": 1.0},\n            \"initial\": {\"x0\": 6.0},\n            \"refs\": {\n                \"r\": np.full(5, 7.0),\n                \"u_ref\": np.full(5, 0.0),\n            },\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        p = case[\"params\"]\n        m = case[\"mpc\"]\n        i = case[\"initial\"]\n        r = case[\"refs\"]\n\n        alpha, beta, gamma, Ts = p[\"alpha\"], p[\"beta\"], p[\"gamma\"], p[\"Ts\"]\n        N, q, ru, umin, umax = m[\"N\"], m[\"q\"], m[\"ru\"], m[\"umin\"], m[\"umax\"]\n        x0 = i[\"x0\"]\n        r_vec = r[\"r\"]\n        u_ref_vec = r[\"u_ref\"]\n\n        # Task 1: Construct discrete-time model x_k+1 = A*x_k + B*u_k + c\n        if beta == 0.0:\n            A = 1.0\n            B = alpha * Ts\n            c_param = gamma * Ts\n        else:\n            exp_beta_Ts = np.exp(-beta * Ts)\n            A = exp_beta_Ts\n            B = (alpha / beta) * (1 - exp_beta_Ts)\n            c_param = (gamma / beta) * (1 - exp_beta_Ts)\n\n        # Task 3: Construct condensed prediction model and QP formulation\n        # x_vec = M*x0 + T*u_vec + t_vec\n        M = np.array([A ** (i + 1) for i in range(N)])\n\n        T = np.zeros((N, N))\n        for j in range(N):\n            for k in range(j, N):\n                T[k, j] = (A ** (k - j)) * B\n        \n        if A == 1.0:\n            t_vec = c_param * np.arange(1, N + 1)\n        else:\n            t_vec = c_param * (1 - A ** np.arange(1, N + 1)) / (1 - A)\n\n        # QP matrices for J(u) = 0.5*u.T*H*u + g.T*u\n        Q_mat = q * np.identity(N)\n        R_mat = ru * np.identity(N)\n        \n        H = 2 * (T.T @ Q_mat @ T + R_mat)\n        \n        error_term = M * x0 + t_vec - r_vec\n        g = 2 * (T.T @ Q_mat @ error_term - R_mat @ u_ref_vec)\n\n        # Define objective function and its gradient (Jacobian) for the solver\n        def objective(u_vec):\n            return 0.5 * u_vec.T @ H @ u_vec + g.T @ u_vec\n\n        def jacobian(u_vec):\n            return H @ u_vec + g\n\n        # Define bounds for the control input sequence\n        bounds = [(umin, umax)] * N\n\n        # Initial guess for the optimizer\n        u_initial_guess = np.clip(u_ref_vec, umin, umax)\n\n        # Solve the box-constrained QP\n        opt_result = minimize(\n            objective,\n            u_initial_guess,\n            method='L-BFGS-B',\n            jac=jacobian,\n            bounds=bounds\n        )\n        \n        u_star_sequence = opt_result.x\n        \n        # Task 4: Apply receding horizon law\n        u0_star = u_star_sequence[0]\n        \n        # Compute the next state\n        x1 = A * x0 + B * u0_star + c_param\n        \n        results.append([u0_star, x1])\n\n    # Format the final output as specified\n    formatted_results = [f\"[{res[0]},{res[1]}]\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nif __name__ == '__main__':\n    solve()\n\n```", "id": "3335315"}]}