{"hands_on_practices": [{"introduction": "The dynamics of biological systems are often described by nonlinear differential equations. To apply the powerful tools of linear control theory, a critical first step is to create a linear approximation of the system around a desired operating point. This exercise [@problem_id:3326409] guides you through the process of linearizing the classic chemostat model, a cornerstone of bioprocess engineering, to derive a state-space representation of the form $\\delta \\dot{x} = A\\,\\delta x + B\\,\\delta u$ which is essential for designing controllers like linear MPC.", "problem": "You are designing a linear Model Predictive Control (MPC) strategy for a continuous stirred-tank bioreactor (chemostat) hosting a synthetic gene circuit. The linearization must be carried out on the host biomass and substrate sub-dynamics that constrain circuit behavior. Consider the classical chemostat model with Monod kinetics for microbial growth:\n$$\n\\begin{aligned}\n\\frac{d x_1}{dt} &= \\big(\\mu(x_2) - u\\big)\\,x_1, \\\\\n\\frac{d x_2}{dt} &= u\\,(S_{\\mathrm{in}} - x_2) - \\frac{1}{Y}\\,\\mu(x_2)\\,x_1,\n\\end{aligned}\n$$\nwhere $x_1$ is the biomass concentration, $x_2$ is the limiting substrate concentration, $u$ is the dilution rate (the manipulated input), $S_{\\mathrm{in}}$ is the influent substrate concentration, $Y$ is the yield coefficient, and $\\mu(x_2)$ is the specific growth rate given by the Monod relation\n$$\n\\mu(x_2) = \\mu_{\\max}\\,\\frac{x_2}{K_S + x_2}.\n$$\nUse the following physically consistent parameter values: $\\mu_{\\max} = 0.6$ h$^{-1}$, $K_S = 0.1$ g L$^{-1}$, $Y = 0.5$ g g$^{-1}$, $S_{\\mathrm{in}} = 10$ g L$^{-1}$, and a nominal dilution rate $u^{\\star} = 0.3$ h$^{-1}$. Work at the non-washout steady state $(x_1^{\\star}, x_2^{\\star})$ associated with $u^{\\star}$.\n\nTasks:\n1) Compute the positive steady state $(x_1^{\\star}, x_2^{\\star})$ consistent with $u^{\\star}$.\n2) Linearize the dynamics about $(x_1^{\\star}, x_2^{\\star}, u^{\\star})$ to obtain the continuous-time state-space linear model\n$$\n\\delta \\dot{x} = A\\,\\delta x + B\\,\\delta u,\n$$\nand provide the explicit matrices $A$ and $B$ in terms of the given parameters evaluated at the steady state.\n3) Justify the validity of the linear approximation for small deviations using Taylorâ€™s theorem with remainder. In particular, by computing the second derivatives of the right-hand side with respect to the state, show that the neglected remainder satisfies a quadratic bound of the form\n$$\n\\|\\mathcal{R}(\\delta x)\\|_2 \\le \\frac{1}{2}\\,L\\,\\|\\delta x\\|_2^2\n$$\nin a neighborhood of the steady state, and explain how such a bound implies local validity of the linearization for sufficiently small $\\|\\delta x\\|_2$ when $\\delta u = 0$.\n4) Finally, compute the spectral radius $\\rho(A)$ of the linearized matrix $A$ at the given steady state.\n\nAnswer specification: Report only the numerical value of the spectral radius $\\rho(A)$ as the final answer. Express the result in h$^{-1}$ and round your answer to four significant figures. Do not include units in your final boxed answer.", "solution": "The problem is evaluated and found to be valid. It is scientifically grounded in standard bioprocess engineering principles (chemostat dynamics with Monod kinetics), well-posed with all necessary parameters provided, and objective in its formulation. The tasks are mathematically formalizable and lead to a unique solution. We proceed with the solution.\n\nThe system of ordinary differential equations for the chemostat is given by:\n$$\n\\begin{aligned}\n\\frac{d x_1}{dt} &= f_1(x_1, x_2, u) = \\big(\\mu(x_2) - u\\big)\\,x_1 \\\\\n\\frac{d x_2}{dt} &= f_2(x_1, x_2, u) = u\\,(S_{\\mathrm{in}} - x_2) - \\frac{1}{Y}\\,\\mu(x_2)\\,x_1\n\\end{aligned}\n$$\nwhere the specific growth rate $\\mu(x_2)$ is given by the Monod equation:\n$$\n\\mu(x_2) = \\mu_{\\max}\\,\\frac{x_2}{K_S + x_2}\n$$\nThe provided parameter values are: $\\mu_{\\max} = 0.6$ h$^{-1}$, $K_S = 0.1$ g L$^{-1}$, $Y = 0.5$ g g$^{-1}$, $S_{\\mathrm{in}} = 10$ g L$^{-1}$. The nominal dilution rate is $u^{\\star} = 0.3$ h$^{-1}$.\n\n**1) Computation of a non-washout steady state $(x_1^{\\star}, x_2^{\\star})$**\nAt steady state, the time derivatives are zero:\n$$\n\\begin{aligned}\n\\frac{d x_1}{dt} &= 0 \\implies \\big(\\mu(x_2^{\\star}) - u^{\\star}\\big)\\,x_1^{\\star} = 0 \\\\\n\\frac{d x_2}{dt} &= 0 \\implies u^{\\star}\\,(S_{\\mathrm{in}} - x_2^{\\star}) - \\frac{1}{Y}\\,\\mu(x_2^{\\star})\\,x_1^{\\star} = 0\n\\end{aligned}\n$$\nFor a non-washout steady state, we must have $x_1^{\\star} > 0$. The first equation then implies:\n$$\n\\mu(x_2^{\\star}) - u^{\\star} = 0 \\implies \\mu(x_2^{\\star}) = u^{\\star}\n$$\nSubstituting the Monod expression and the given parameters:\n$$\n\\mu_{\\max}\\,\\frac{x_2^{\\star}}{K_S + x_2^{\\star}} = u^{\\star} \\implies 0.6\\,\\frac{x_2^{\\star}}{0.1 + x_2^{\\star}} = 0.3\n$$\nSolving for $x_2^{\\star}$:\n$$\n\\frac{x_2^{\\star}}{0.1 + x_2^{\\star}} = \\frac{0.3}{0.6} = 0.5\n$$\n$$\nx_2^{\\star} = 0.5\\,(0.1 + x_2^{\\star}) = 0.05 + 0.5\\,x_2^{\\star}\n$$\n$$\n0.5\\,x_2^{\\star} = 0.05 \\implies x_2^{\\star} = 0.1 \\text{ g L}^{-1}\n$$\nNow, we use the second steady-state equation and substitute $\\mu(x_2^{\\star}) = u^{\\star}$:\n$$\nu^{\\star}\\,(S_{\\mathrm{in}} - x_2^{\\star}) - \\frac{1}{Y}\\,u^{\\star}\\,x_1^{\\star} = 0\n$$\nSince $u^{\\star} = 0.3 \\neq 0$, we can divide by $u^{\\star}$:\n$$\n(S_{\\mathrm{in}} - x_2^{\\star}) - \\frac{1}{Y}\\,x_1^{\\star} = 0 \\implies x_1^{\\star} = Y\\,(S_{\\mathrm{in}} - x_2^{\\star})\n$$\nSubstituting the known values:\n$$\nx_1^{\\star} = 0.5 \\times (10 - 0.1) = 0.5 \\times 9.9 = 4.95 \\text{ g L}^{-1}\n$$\nThe non-washout steady state is $(x_1^{\\star}, x_2^{\\star}) = (4.95, 0.1)$.\n\n**2) Linearization of the dynamics**\nWe linearize the system $\\dot{x} = f(x, u)$ around the steady state $(x^{\\star}, u^{\\star})$, where $x = [x_1, x_2]^T$ and $u$ is the scalar input. The linearized model is $\\delta \\dot{x} = A\\,\\delta x + B\\,\\delta u$, where the matrices $A$ (Jacobian) and $B$ are given by:\n$$\nA = \\frac{\\partial f}{\\partial x}\\bigg|_{\\star} = \\begin{pmatrix} \\frac{\\partial f_1}{\\partial x_1} & \\frac{\\partial f_1}{\\partial x_2} \\\\ \\frac{\\partial f_2}{\\partial x_1} & \\frac{\\partial f_2}{\\partial x_2} \\end{pmatrix}\\bigg|_{\\star}, \\quad B = \\frac{\\partial f}{\\partial u}\\bigg|_{\\star} = \\begin{pmatrix} \\frac{\\partial f_1}{\\partial u} \\\\ \\frac{\\partial f_2}{\\partial u} \\end{pmatrix}\\bigg|_{\\star}\n$$\nThe partial derivatives are:\n$\\frac{\\partial f_1}{\\partial x_1} = \\mu(x_2) - u$\n$\\frac{\\partial f_1}{\\partial x_2} = x_1 \\frac{d\\mu}{dx_2}$\n$\\frac{\\partial f_2}{\\partial x_1} = -\\frac{1}{Y}\\mu(x_2)$\n$\\frac{\\partial f_2}{\\partial x_2} = -u - \\frac{1}{Y}x_1\\frac{d\\mu}{dx_2}$\n$\\frac{\\partial f_1}{\\partial u} = -x_1$\n$\\frac{\\partial f_2}{\\partial u} = S_{\\mathrm{in}} - x_2$\n\nThe derivative of the Monod function is $\\frac{d\\mu}{dx_2} = \\frac{\\mu_{\\max} K_S}{(K_S + x_2)^2}$.\nWe evaluate these derivatives at the steady state $(x_1^{\\star}, x_2^{\\star}, u^{\\star}) = (4.95, 0.1, 0.3)$.\nFirst, we compute $\\frac{d\\mu}{dx_2}$ at $x_2^{\\star}=0.1$:\n$$\n\\frac{d\\mu}{dx_2}\\bigg|_{x_2^{\\star}} = \\frac{0.6 \\times 0.1}{(0.1 + 0.1)^2} = \\frac{0.06}{0.2^2} = \\frac{0.06}{0.04} = 1.5 \\text{ h}^{-1} (\\text{g L}^{-1})^{-1}\n$$\nNow we compute the elements of matrix $A$:\n$A_{11} = \\mu(x_2^{\\star}) - u^{\\star} = u^{\\star} - u^{\\star} = 0$\n$A_{12} = x_1^{\\star} \\frac{d\\mu}{dx_2}\\bigg|_{x_2^{\\star}} = 4.95 \\times 1.5 = 7.425$\n$A_{21} = -\\frac{1}{Y}\\mu(x_2^{\\star}) = -\\frac{u^{\\star}}{Y} = -\\frac{0.3}{0.5} = -0.6$\n$A_{22} = -u^{\\star} - \\frac{1}{Y}x_1^{\\star}\\frac{d\\mu}{dx_2}\\bigg|_{x_2^{\\star}} = -u^{\\star} - \\frac{1}{Y}A_{12} = -0.3 - \\frac{1}{0.5}(7.425) = -0.3 - 14.85 = -15.15$\nThe state matrix $A$ is:\n$$\nA = \\begin{pmatrix} 0 & 7.425 \\\\ -0.6 & -15.15 \\end{pmatrix}\n$$\nNow we compute the elements of matrix $B$:\n$B_{1} = -x_1^{\\star} = -4.95$\n$B_{2} = S_{\\mathrm{in}} - x_2^{\\star} = 10 - 0.1 = 9.9$\nThe input matrix $B$ is:\n$$\nB = \\begin{pmatrix} -4.95 \\\\ 9.9 \\end{pmatrix}\n$$\n\n**3) Justification of the linear approximation**\nLet $x = x^{\\star} + \\delta x$. For the autonomous case ($\\delta u = 0$), the dynamics are $\\dot{x} = f(x)$. Taylor's theorem with integral remainder for the vector function $f$ expanded around $x^{\\star}$ is:\n$$\nf(x^{\\star} + \\delta x) = f(x^{\\star}) + \\frac{\\partial f}{\\partial x}\\bigg|_{x^{\\star}}\\delta x + \\mathcal{R}(\\delta x)\n$$\nwhere $\\mathcal{R}(\\delta x) = \\int_0^1 (1-s) H_f(x^{\\star}+s\\delta x)(\\delta x, \\delta x) ds$, with $H_f$ being the tensor of second partial derivatives of $f$. Since $\\dot{x} = \\delta \\dot{x}$ and $f(x^{\\star})=0$, we have $\\delta \\dot{x} = A \\delta x + \\mathcal{R}(\\delta x)$.\nThe validity of the linear approximation $\\delta \\dot{x} \\approx A \\delta x$ depends on the remainder term $\\mathcal{R}(\\delta x)$ being negligible compared to the linear term $A \\delta x$ for small $\\|\\delta x\\|_2$.\nThe components of the remainder term are quadratically bounded if the second partial derivatives of $f$ are bounded in a neighborhood of $x^{\\star}$. We verify this by computing them:\n$\\frac{\\partial^2 f_1}{\\partial x_1^2} = 0$, $\\frac{\\partial^2 f_2}{\\partial x_1^2} = 0$\n$\\frac{\\partial^2 f_1}{\\partial x_1 \\partial x_2} = \\frac{d\\mu}{dx_2} = \\frac{\\mu_{\\max} K_S}{(K_S + x_2)^2}$\n$\\frac{\\partial^2 f_2}{\\partial x_1 \\partial x_2} = -\\frac{1}{Y}\\frac{d\\mu}{dx_2} = -\\frac{\\mu_{\\max} K_S}{Y(K_S + x_2)^2}$\n$\\frac{d^2\\mu}{dx_2^2} = \\frac{-2 \\mu_{\\max} K_S}{(K_S + x_2)^3}$\n$\\frac{\\partial^2 f_1}{\\partial x_2^2} = x_1 \\frac{d^2\\mu}{dx_2^2} = \\frac{-2 x_1 \\mu_{\\max} K_S}{(K_S + x_2)^3}$\n$\\frac{\\partial^2 f_2}{\\partial x_2^2} = -\\frac{1}{Y}x_1 \\frac{d^2\\mu}{dx_2^2} = \\frac{2 x_1 \\mu_{\\max} K_S}{Y(K_S + x_2)^3}$\nSince $K_S > 0$ and we consider a neighborhood of the positive steady state where $x_1 > 0$ and $x_2 > 0$, all denominators are non-zero. The second derivatives are continuous, rational functions of $x_1$ and $x_2$. Thus, in any compact (closed and bounded) neighborhood of $x^{\\star}$, they are bounded. This boundedness guarantees the existence of a constant $L > 0$ such that the remainder as a whole satisfies $\\|\\mathcal{R}(\\delta x)\\|_2 \\le \\frac{1}{2} L \\|\\delta x\\|_2^2$.\nThe linear approximation is valid for small $\\|\\delta x\\|_2$ because the error, which is of order $O(\\|\\delta x\\|_2^2)$, becomes negligible relative to the linear term, which is of order $O(\\|\\delta x\\|_2)$. Specifically, the ratio of the norms $\\frac{\\|\\mathcal{R}(\\delta x)\\|_2}{\\|A \\delta x\\|_2} \\le \\frac{\\frac{1}{2} L \\|\\delta x\\|_2^2}{\\sigma_{\\min}(A)\\|\\delta x\\|_2} = \\frac{L}{2\\sigma_{\\min}(A)}\\|\\delta x\\|_2$, which tends to $0$ as $\\|\\delta x\\|_2 \\to 0$ (assuming the system is not degenerate, i.e., $\\sigma_{\\min}(A) > 0$). This confirms the local validity of the linearization.\n\n**4) Computation of the spectral radius $\\rho(A)$**\nThe spectral radius is the maximum absolute value of the eigenvalues of $A$. The eigenvalues $\\lambda$ are the roots of the characteristic equation $\\det(A - \\lambda I) = 0$.\n$$\n\\det \\begin{pmatrix} 0-\\lambda & 7.425 \\\\ -0.6 & -15.15-\\lambda \\end{pmatrix} = 0\n$$\n$$\n(-\\lambda)(-15.15-\\lambda) - (7.425)(-0.6) = 0\n$$\n$$\n15.15\\lambda + \\lambda^2 + 4.455 = 0\n$$\n$$\n\\lambda^2 + 15.15\\lambda + 4.455 = 0\n$$\nWe solve this quadratic equation for $\\lambda$:\n$$\n\\lambda = \\frac{-15.15 \\pm \\sqrt{15.15^2 - 4(1)(4.455)}}{2} = \\frac{-15.15 \\pm \\sqrt{229.5225 - 17.82}}{2}\n$$\n$$\n\\lambda = \\frac{-15.15 \\pm \\sqrt{211.7025}}{2} = \\frac{-15.15 \\pm 14.55}{2}\n$$\nThe two eigenvalues are:\n$$\n\\lambda_1 = \\frac{-15.15 + 14.55}{2} = \\frac{-0.6}{2} = -0.3\n$$\n$$\n\\lambda_2 = \\frac{-15.15 - 14.55}{2} = \\frac{-29.7}{2} = -14.85\n$$\nThe eigenvalues are $\\lambda_1 = -0.3$ h$^{-1}$ and $\\lambda_2 = -14.85$ h$^{-1}$. Both are real and negative, indicating that the steady state is a stable node.\nThe spectral radius $\\rho(A)$ is:\n$$\n\\rho(A) = \\max(|\\lambda_1|, |\\lambda_2|) = \\max(|-0.3|, |-14.85|) = \\max(0.3, 14.85) = 14.85\n$$\nThe value $14.85$ is already expressed with four significant figures as required.", "answer": "$$\\boxed{14.85}$$", "id": "3326409"}, {"introduction": "After obtaining a linear model, we must assess its fundamental properties to understand the limits of control and estimation. This practice [@problem_id:3326458] explores the crucial concepts of controllability and observability in the context of a synthetic gene circuit. You will learn to determine whether a system's states can be fully manipulated by the input (controllability) and whether they can be inferred from the output measurements (observability), providing insight into how experimental design choices affect our ability to monitor and regulate cellular processes.", "problem": "A synthetic gene expression module is operated under Model Predictive Control (MPC) to regulate protein abundance in a microbial chassis. The module is linearized around an operating point to yield a continuous-time linear time-invariant (LTI) model with two states: messenger ribonucleic acid (mRNA) concentration $x_{1}$ and protein concentration $x_{2}$. The single control input $u$ is the inducer level affecting transcription, and the single measured output $y$ is the protein fluorescence. The linearized dynamics and measurement are given by\n$$\n\\dot{x}_{1} = -\\gamma_{m} x_{1} + \\alpha u,\\quad \\dot{x}_{2} = k_{t} x_{1} - \\gamma_{p} x_{2},\\quad y = x_{2},\n$$\nwith parameter values $\\gamma_{m} = 0.24\\,\\text{min}^{-1}$, $\\gamma_{p} = 0.06\\,\\text{min}^{-1}$, $k_{t} = 0.12\\,\\text{min}^{-1}$, and $\\alpha = 0.80\\,\\text{min}^{-1}$.\n\nTo improve assay stability, a reporter is added that binds proportionally to the protein and has its own degradation. This introduces a third state $x_{3}$ (reporter concentration) with dynamics and measurement\n$$\n\\dot{x}_{3} = k_{r} x_{2} - \\gamma_{r} x_{3},\\quad y_{\\text{rep}} = x_{3},\n$$\nwith $k_{r} = 0.50\\,\\text{min}^{-1}$ and $\\gamma_{r} = 0.02\\,\\text{min}^{-1}$. The input $u$ remains the single actuator, and the output is changed to the single reporter fluorescence $y_{\\text{rep}}$.\n\nStarting from the standard definitions of controllability and observability for continuous-time LTI systems, compute:\n- the controllability matrix and observability matrix for the original two-state system, and determine their ranks;\n- the observability matrix for the augmented three-state reporter system, and determine its rank.\n\nDecide whether adding the reporter, while keeping a single measured output (now the reporter), degrades observability relative to the original system. For the final answer, report the result as the row matrix\n$$\\begin{pmatrix} r_{c}^{(2)} & r_{o}^{(2)} & r_{o}^{(3)} & d \\end{pmatrix},$$\nwhere $r_{c}^{(2)}$ is the rank of the two-state controllability matrix, $r_{o}^{(2)}$ is the rank of the two-state observability matrix, $r_{o}^{(3)}$ is the rank of the three-state observability matrix with reporter output, and $d$ equals $1$ if observability is degraded by adding the reporter and $0$ otherwise. Express the final row matrix entries as integers with no units. No rounding is required.", "solution": "The problem requires an analysis of the controllability and observability of two related linear time-invariant (LTI) systems derived from a synthetic gene expression module. Let the general form of a continuous-time LTI system be\n$$\n\\dot{\\mathbf{x}}(t) = A\\mathbf{x}(t) + B\\mathbf{u}(t)\n$$\n$$\n\\mathbf{y}(t) = C\\mathbf{x}(t) + D\\mathbf{u}(t)\n$$\nwhere $\\mathbf{x}$ is the state vector of dimension $n$, $\\mathbf{u}$ is the input vector, and $\\mathbf{y}$ is the output vector. For the systems in this problem, the feedthrough matrix $D$ is zero.\n\nThe controllability of the pair $(A, B)$ is determined by the rank of the controllability matrix $\\mathcal{C}$. For a single-input system, this matrix is given by\n$$\n\\mathcal{C} = \\begin{pmatrix} B & AB & A^2B & \\cdots & A^{n-1}B \\end{pmatrix}\n$$\nThe system is fully controllable if $\\text{rank}(\\mathcal{C}) = n$.\n\nThe observability of the pair $(A, C)$ is determined by the rank of the observability matrix $\\mathcal{O}$. For a single-output system, this matrix is given by\n$$\n\\mathcal{O} = \\begin{pmatrix} C \\\\ CA \\\\ CA^2 \\\\ \\vdots \\\\ CA^{n-1} \\end{pmatrix}\n$$\nThe system is fully observable if $\\text{rank}(\\mathcal{O}) = n$.\n\nFirst, we analyze the original two-state system. The state vector is $\\mathbf{x} = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$. The dynamics are given by $\\dot{x}_{1} = -\\gamma_{m} x_{1} + \\alpha u$ and $\\dot{x}_{2} = k_{t} x_{1} - \\gamma_{p} x_{2}$, with the output $y = x_2$.\nThe state-space matrices are:\n$$\nA^{(2)} = \\begin{pmatrix} -\\gamma_m & 0 \\\\ k_t & -\\gamma_p \\end{pmatrix}, \\quad B^{(2)} = \\begin{pmatrix} \\alpha \\\\ 0 \\end{pmatrix}, \\quad C^{(2)} = \\begin{pmatrix} 0 & 1 \\end{pmatrix}\n$$\nSubstituting the given parameter values $\\gamma_{m} = 0.24$, $\\gamma_{p} = 0.06$, $k_{t} = 0.12$, and $\\alpha = 0.80$:\n$$\nA^{(2)} = \\begin{pmatrix} -0.24 & 0 \\\\ 0.12 & -0.06 \\end{pmatrix}, \\quad B^{(2)} = \\begin{pmatrix} 0.80 \\\\ 0 \\end{pmatrix}, \\quad C^{(2)} = \\begin{pmatrix} 0 & 1 \\end{pmatrix}\n$$\nThe dimension of this system is $n=2$.\n\nTo determine controllability, we compute the controllability matrix $\\mathcal{C}^{(2)} = \\begin{pmatrix} B^{(2)} & A^{(2)}B^{(2)} \\end{pmatrix}$.\nFirst, we calculate the product $A^{(2)}B^{(2)}$:\n$$\nA^{(2)}B^{(2)} = \\begin{pmatrix} -0.24 & 0 \\\\ 0.12 & -0.06 \\end{pmatrix} \\begin{pmatrix} 0.80 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} (-0.24)(0.80) \\\\ (0.12)(0.80) \\end{pmatrix} = \\begin{pmatrix} -0.192 \\\\ 0.096 \\end{pmatrix}\n$$\nThe controllability matrix is:\n$$\n\\mathcal{C}^{(2)} = \\begin{pmatrix} 0.80 & -0.192 \\\\ 0 & 0.096 \\end{pmatrix}\n$$\nThe rank of $\\mathcal{C}^{(2)}$ is found by computing its determinant:\n$$\n\\det(\\mathcal{C}^{(2)}) = (0.80)(0.096) - (-0.192)(0) = 0.0768\n$$\nSince $\\det(\\mathcal{C}^{(2)}) \\neq 0$, the matrix is full rank. The rank of the controllability matrix is $r_c^{(2)} = 2$. The system is fully controllable.\n\nNext, to determine observability, we compute the observability matrix $\\mathcal{O}^{(2)} = \\begin{pmatrix} C^{(2)} \\\\ C^{(2)}A^{(2)} \\end{pmatrix}$.\nFirst, we calculate the product $C^{(2)}A^{(2)}$:\n$$\nC^{(2)}A^{(2)} = \\begin{pmatrix} 0 & 1 \\end{pmatrix} \\begin{pmatrix} -0.24 & 0 \\\\ 0.12 & -0.06 \\end{pmatrix} = \\begin{pmatrix} 0.12 & -0.06 \\end{pmatrix}\n$$\nThe observability matrix is:\n$$\n\\mathcal{O}^{(2)} = \\begin{pmatrix} 0 & 1 \\\\ 0.12 & -0.06 \\end{pmatrix}\n$$\nThe rank of $\\mathcal{O}^{(2)}$ is found by computing its determinant:\n$$\n\\det(\\mathcal{O}^{(2)}) = (0)(-0.06) - (1)(0.12) = -0.12\n$$\nSince $\\det(\\mathcal{O}^{(2)}) \\neq 0$, the matrix is full rank. The rank of the observability matrix is $r_o^{(2)} = 2$. The system is fully observable.\n\nNow, we analyze the augmented three-state system with the reporter. The state vector is $\\mathbf{x} = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix}$. The dynamics are extended with $\\dot{x}_{3} = k_{r} x_{2} - \\gamma_{r} x_{3}$, and the output is changed to $y_{\\text{rep}} = x_3$. The dimension of this system is $n=3$.\nThe new state-space matrices are:\n$$\nA^{(3)} = \\begin{pmatrix} -\\gamma_m & 0 & 0 \\\\ k_t & -\\gamma_p & 0 \\\\ 0 & k_r & -\\gamma_r \\end{pmatrix}, \\quad C^{(3)} = \\begin{pmatrix} 0 & 0 & 1 \\end{pmatrix}\n$$\nSubstituting the new parameter values $k_r = 0.50$ and $\\gamma_r = 0.02$:\n$$\nA^{(3)} = \\begin{pmatrix} -0.24 & 0 & 0 \\\\ 0.12 & -0.06 & 0 \\\\ 0 & 0.50 & -0.02 \\end{pmatrix}, \\quad C^{(3)} = \\begin{pmatrix} 0 & 0 & 1 \\end{pmatrix}\n$$\nWe are asked for the rank of the observability matrix $\\mathcal{O}^{(3)} = \\begin{pmatrix} C^{(3)} \\\\ C^{(3)}A^{(3)} \\\\ C^{(3)}(A^{(3)})^2 \\end{pmatrix}$.\nWe compute the rows of $\\mathcal{O}^{(3)}$:\nThe first row is $C^{(3)} = \\begin{pmatrix} 0 & 0 & 1 \\end{pmatrix}$.\nThe second row is $C^{(3)}A^{(3)}$:\n$$\nC^{(3)}A^{(3)} = \\begin{pmatrix} 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} -0.24 & 0 & 0 \\\\ 0.12 & -0.06 & 0 \\\\ 0 & 0.50 & -0.02 \\end{pmatrix} = \\begin{pmatrix} 0 & 0.50 & -0.02 \\end{pmatrix}\n$$\nThe third row is $C^{(3)}(A^{(3)})^2$. First we compute $(A^{(3)})^2$:\n$$\n(A^{(3)})^2 = \\begin{pmatrix} -0.24 & 0 & 0 \\\\ 0.12 & -0.06 & 0 \\\\ 0 & 0.50 & -0.02 \\end{pmatrix} \\begin{pmatrix} -0.24 & 0 & 0 \\\\ 0.12 & -0.06 & 0 \\\\ 0 & 0.50 & -0.02 \\end{pmatrix} = \\begin{pmatrix} 0.0576 & 0 & 0 \\\\ -0.036 & 0.0036 & 0 \\\\ 0.06 & -0.04 & 0.0004 \\end{pmatrix}\n$$\nThen, we compute $C^{(3)}(A^{(3)})^2$:\n$$\nC^{(3)}(A^{(3)})^2 = \\begin{pmatrix} 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0.0576 & 0 & 0 \\\\ -0.036 & 0.0036 & 0 \\\\ 0.06 & -0.04 & 0.0004 \\end{pmatrix} = \\begin{pmatrix} 0.06 & -0.04 & 0.0004 \\end{pmatrix}\n$$\nThe observability matrix for the three-state system is:\n$$\n\\mathcal{O}^{(3)} = \\begin{pmatrix} 0 & 0 & 1 \\\\ 0 & 0.50 & -0.02 \\\\ 0.06 & -0.04 & 0.0004 \\end{pmatrix}\n$$\nTo find its rank, we compute the determinant:\n$$\n\\det(\\mathcal{O}^{(3)}) = 0 \\cdot \\det\\begin{pmatrix} 0.50 & -0.02 \\\\ -0.04 & 0.0004 \\end{pmatrix} - 0 \\cdot \\det\\begin{pmatrix} 0 & -0.02 \\\\ 0.06 & 0.0004 \\end{pmatrix} + 1 \\cdot \\det\\begin{pmatrix} 0 & 0.50 \\\\ 0.06 & -0.04 \\end{pmatrix}\n$$\n$$\n\\det(\\mathcal{O}^{(3)}) = 1 \\cdot ((0)(-0.04) - (0.50)(0.06)) = -0.03\n$$\nSince $\\det(\\mathcal{O}^{(3)}) \\neq 0$, the matrix is full rank. The rank of the observability matrix for the three-state system is $r_o^{(3)} = 3$.\n\nFinally, we must decide if observability is degraded. The original two-state system is fully observable since $r_o^{(2)} = 2$, which equals its number of states. The augmented three-state system is also fully observable since $r_o^{(3)} = 3$, which equals its number of states. Since the system remains fully observable after the addition of the reporter and the change in measurement, observability is not degraded in the sense of being lost. Therefore, the degradation indicator $d$ is $0$.\n\nThe required results are: $r_c^{(2)} = 2$, $r_o^{(2)} = 2$, $r_o^{(3)} = 3$, and $d = 0$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2 & 2 & 3 & 0\n\\end{pmatrix}\n}\n$$", "id": "3326458"}, {"introduction": "Effective control often requires anticipating the future, but time delays in actuation and measurement can complicate prediction. This exercise [@problem_id:3326498] tackles the common challenge of input delays in discrete-time systems, a frequent issue in biological control applications. By constructing an augmented state-space model, you will implement a practical method for delay compensation that forms the core of predictive controllers, allowing them to make informed decisions based on accurate future state predictions.", "problem": "Consider a linearized, discrete-time, Single-Input Single-Output (SISO) model of a transcription-translation module in synthetic biology controlled by an inducer input, where the protein concentration is the measured output. The discrete-time dynamics are modeled as a linear time-invariant system with an integer-valued, discrete-time input delay of $d$ steps. Let $x_k \\in \\mathbb{R}^n$ denote the state vector at step $k$, $u_k \\in \\mathbb{R}$ the scalar inducer at step $k$, and $y_k \\in \\mathbb{R}$ the scalar protein readout. The system obeys\n$$\nx_{k+1} = A_d x_k + B_d u_{k-d}, \\quad y_k = C x_k,\n$$\nwhere $A_d \\in \\mathbb{R}^{n \\times n}$, $B_d \\in \\mathbb{R}^{n \\times 1}$, and $C \\in \\mathbb{R}^{1 \\times n}$ are given. All states and inputs are dimensionless.\n\nYour task is to construct the standard delay-compensated augmented model used in Model Predictive Control (MPC), and to simulate $d$-step-ahead predictions over a finite horizon. Start from the fundamental state-update law for discrete-time linear systems and the definition of an integer input delay, and systematically derive the augmented state dynamics that remove the explicit delay by embedding a shift register of past inputs into the state. Do not assume any pre-built formulas beyond the basic state-update law.\n\nPrecisely, do the following:\n- Construct an augmented state $z_k$ by stacking the original state $x_k$ with a finite, ordered memory of past inputs required to represent the delayed actuation as a delay-free augmented system. From first principles, derive the augmented state transition matrix $A_{\\text{aug}}$, input matrix $B_{\\text{aug}}$, and output matrix $C_{\\text{aug}}$ for general integer delay $d \\ge 0$ and SISO input.\n- Using the augmented delay-free representation, simulate open-loop predictions over a finite horizon of $H$ steps. Given an initial state $x_k$, a sequence of the $d$ most recent past inputs $\\{u_{k-d}, u_{k-d+1}, \\dots, u_{k-1}\\}$ in chronological order, and a planned future input sequence $\\{u_k, u_{k+1}, \\dots, u_{k+H-1}\\}$, compute the sequence of predicted outputs $\\{y_{k+1}, y_{k+2}, \\dots, y_{k+H}\\}$. You must compute these predictions by iterating the augmented delay-free model; directly substituting delayed inputs into the original delayed model is not permitted.\n- Ensure your algorithm works for the boundary case $d=0$ (no input delay), in which case the augmented model reduces to the original model.\n\nUse the following fixed system matrices, corresponding to a two-state linearized gene expression module ($n=2$):\n$$\nA_d = \\begin{bmatrix} 0.85 & 0.00 \\\\ 0.15 & 0.90 \\end{bmatrix}, \\quad B_d = \\begin{bmatrix} 0.10 \\\\ 0.02 \\end{bmatrix}, \\quad C = \\begin{bmatrix} 0 & 1 \\end{bmatrix}.\n$$\n\nTest suite:\nFor each test case, you are given $(d, H, x_k, \\{u_{k-d},\\dots,u_{k-1}\\}, \\{u_k,\\dots,u_{k+H-1}\\})$. All vectors are given in standard Euclidean coordinates, and inputs are scalar. Use the data below exactly as specified.\n\n- Test case $1$ (general happy path): \n  - $d = 2$, $H=5$\n  - $x_k = \\begin{bmatrix} 0.5 \\\\ 0.2 \\end{bmatrix}$\n  - Past inputs $\\{u_{k-2}, u_{k-1}\\} = \\{0.0, 0.1\\}$\n  - Planned inputs $\\{u_k, u_{k+1}, u_{k+2}, u_{k+3}, u_{k+4}\\} = \\{0.2, 0.2, 0.1, 0.0, 0.0\\}$\n\n- Test case $2$ (boundary, no delay): \n  - $d = 0$, $H=4$\n  - $x_k = \\begin{bmatrix} 0.1 \\\\ 0.0 \\end{bmatrix}$\n  - Past inputs: empty sequence\n  - Planned inputs $\\{u_k, u_{k+1}, u_{k+2}, u_{k+3}\\} = \\{0.3, 0.0, 0.0, 0.0\\}$\n\n- Test case $3$ (edge, delay dominates horizon): \n  - $d = 3$, $H=3$\n  - $x_k = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}$\n  - Past inputs $\\{u_{k-3}, u_{k-2}, u_{k-1}\\} = \\{0.5, 0.5, 0.5\\}$\n  - Planned inputs $\\{u_k, u_{k+1}, u_{k+2}\\} = \\{0.0, 0.0, 0.0\\}$\n\nFinal output format:\n- Your program must compute, for each test case, the list of predicted outputs $\\{y_{k+1}, \\dots, y_{k+H}\\}$, rounded to $6$ decimal places.\n- All states and inputs are dimensionless; no physical units are required in the output.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a list of floats corresponding to one test case, for example: $\\texttt{[[a\\_1,\\dots,a\\_H],[b\\_1,\\dots,b\\_H],[c\\_1,\\dots,c\\_H]]}$, with each $a_i$, $b_i$, $c_i$ rounded to $6$ decimal places.", "solution": "The objective is to derive the delay-compensated augmented state-space model for a given discrete-time linear time-invariant (LTI) system with an integer input delay $d$, and then use this model to predict future outputs over a finite horizon $H$.\n\nThe original system dynamics are given by:\n$$\nx_{k+1} = A_d x_k + B_d u_{k-d} \\quad (1)\n$$\n$$\ny_k = C x_k \\quad (2)\n$$\nwhere $x_k \\in \\mathbb{R}^n$ is the state vector, $u_k \\in \\mathbb{R}$ is the scalar input, and $y_k \\in \\mathbb{R}$ is the scalar output at time step $k$. The input $u_k$ affects the state $x$ only after a delay of $d$ time steps. To create a standard delay-free model of the form $z_{k+1} = A_{\\text{aug}} z_k + B_{\\text{aug}} u_k$, we must augment the state vector to include a memory of the past $d$ inputs.\n\n### Derivation of the Augmented Model for $d \\ge 1$\n\nLet us define an augmented state vector $z_k \\in \\mathbb{R}^{n+d}$ that concatenates the original state $x_k$ with the sequence of the last $d$ inputs that have been applied but have not yet affected the state. We define the augmented state $z_k$ at time step $k$ in chronological order of inputs:\n$$\nz_k = \\begin{bmatrix}\nx_k \\\\\nu_{k-d} \\\\\nu_{k-d+1} \\\\\n\\vdots \\\\\nu_{k-1}\n\\end{bmatrix}\n$$\nThe dimension of $z_k$ is $(n+d) \\times 1$. Our goal is to find the matrices $A_{\\text{aug}}$ and $B_{\\text{aug}}$ such that $z_{k+1} = A_{\\text{aug}} z_k + B_{\\text{aug}} u_k$.\n\nFirst, let's write out the expression for $z_{k+1}$:\n$$\nz_{k+1} = \\begin{bmatrix}\nx_{k+1} \\\\\nu_{k-d+1} \\\\\nu_{k-d+2} \\\\\n\\vdots \\\\\nu_k\n\\end{bmatrix}\n$$\nNow, we express each component of $z_{k+1}$ in terms of the components of $z_k$ and the current input $u_k$.\n\n1.  **Dynamics of $x_{k+1}$**: From the original state equation (1), we have $x_{k+1} = A_d x_k + B_d u_{k-d}$. Both $x_k$ and $u_{k-d}$ are present in our augmented state $z_k$. Specifically, $x_k$ constitutes the first $n$ elements of $z_k$, and $u_{k-d}$ is the $(n+1)$-th element (using 1-based indexing).\n\n2.  **Dynamics of the input buffer**: The input buffer in $z_{k+1}$ is a left-shifted version of the buffer in $z_k$, with the new input $u_k$ appended at the end. This is because the oldest input $u_{k-d}$ has now been 'consumed' by the state dynamics.\n\nCombining these observations, we can write the state update for $z_{k+1}$ as a linear transformation of $z_k$ plus a term for the new input $u_k$. This can be expressed in the desired matrix form $z_{k+1} = A_{\\text{aug}} z_k + B_{\\text{aug}} u_k$ by defining $A_{\\text{aug}}$ and $B_{\\text{aug}}$ as follows:\n\n$$\nA_{\\text{aug}} = \\begin{bmatrix}\nA_d & B_d & \\mathbf{0}_{n \\times 1} & \\cdots & \\mathbf{0}_{n \\times 1} \\\\\n\\mathbf{0}_{1 \\times n} & 0 & 1 & \\cdots & 0 \\\\\n\\mathbf{0}_{1 \\times n} & 0 & 0 & \\ddots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & 1 \\\\\n\\mathbf{0}_{1 \\times n} & 0 & 0 & \\cdots & 0\n\\end{bmatrix} \\in \\mathbb{R}^{(n+d) \\times (n+d)}\n$$\n\n$$\nB_{\\text{aug}} = \\begin{bmatrix} \\mathbf{0}_{n \\times 1} \\\\ 0 \\\\ \\vdots \\\\ 0 \\\\ 1 \\end{bmatrix} \\in \\mathbb{R}^{(n+d) \\times 1}\n$$\n\nThe output equation $y_k = C x_k$ must also be expressed in terms of the augmented state $z_k$. Since $y_k$ depends only on $x_k$, we have:\n$$\ny_k = \\begin{bmatrix} C & \\mathbf{0}_{1 \\times d} \\end{bmatrix} z_k\n$$\nThus, the augmented output matrix is:\n$$\nC_{\\text{aug}} = \\begin{bmatrix} C & \\mathbf{0}_{1 \\times d} \\end{bmatrix} \\in \\mathbb{R}^{1 \\times (n+d)}\n$$\n\n### Boundary Case: No Delay ($d=0$)\n\nWhen $d=0$, the input delay is zero. The original system equations become:\n$$\nx_{k+1} = A_d x_k + B_d u_k, \\quad y_k = C x_k\n$$\nThe system is already in a standard delay-free form. No state augmentation is necessary. In this case, the \"augmented\" system is identical to the original system:\n-   $z_k = x_k$\n-   $A_{\\text{aug}} = A_d$\n-   $B_{\\text{aug}} = B_d$\n-   $C_{\\text{aug}} = C$\n\n### Simulation Procedure for Open-Loop Predictions\n\nGiven an initial state $x_k$, a history of the past $d$ inputs $\\{u_{k-d}, \\dots, u_{k-1}\\}$, and a planned sequence of future inputs $\\{u_k, \\dots, u_{k+H-1}\\}$, we can predict the future outputs $\\{y_{k+1}, \\dots, y_{k+H}\\}$ by iterating the augmented model.\n\n1.  **Construct Initial Augmented State**: At time $k$, assemble the initial augmented state vector $z_k$ using the given $x_k$ and the past inputs.\n    -   If $d \\ge 1$: $z_k = [x_k^T, u_{k-d}, \\dots, u_{k-1}]^T$.\n    -   If $d = 0$: $z_k = x_k$.\n\n2.  **Iterate Dynamics**: Sequentially compute the future augmented states and outputs for $j$ from $0$ to $H-1$. Let the current augmented state be $z_{\\text{curr}}$ and the current input be $u_{\\text{curr}}$.\n    -   Initialize: $z_{\\text{curr}} = z_k$.\n    -   For $j=0, 1, \\dots, H-1$:\n        a.  Set the current input: $u_{\\text{curr}} = u_{k+j}$.\n        b.  Compute the next augmented state: $z_{\\text{next}} = A_{\\text{aug}} z_{\\text{curr}} + B_{\\text{aug}} u_{\\text{curr}}$.\n        c.  Compute the predicted output at the next time step: $y_{k+j+1} = C_{\\text{aug}} z_{\\text{next}}$.\n        d.  Store $y_{k+j+1}$.\n        e.  Update the state for the next iteration: $z_{\\text{curr}} = z_{\\text{next}}$.\n\n3.  **Collect Results**: The stored sequence of outputs $\\{y_{k+1}, y_{k+2}, \\dots, y_{k+H}\\}$ is the desired prediction.\nThis procedure correctly simulates the system's evolution, accounting for the input delay by propagating inputs through the augmented state's shift register.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the model predictive control problem for synthetic biology as described.\n    It computes open-loop predictions for a linearized gene expression module\n    with input delay by deriving and iterating an augmented state-space model.\n    \"\"\"\n    \n    # Fixed system parameters as per the problem statement\n    A_d = np.array([[0.85, 0.00], [0.15, 0.90]])\n    B_d = np.array([[0.10], [0.02]])\n    C = np.array([[0, 1]])\n    n = A_d.shape[0]\n\n    # Test cases from the problem statement\n    test_cases = [\n        {\n            \"d\": 2, \"H\": 5,\n            \"x_k\": np.array([[0.5], [0.2]]),\n            \"past_inputs\": [0.0, 0.1],\n            \"planned_inputs\": [0.2, 0.2, 0.1, 0.0, 0.0]\n        },\n        {\n            \"d\": 0, \"H\": 4,\n            \"x_k\": np.array([[0.1], [0.0]]),\n            \"past_inputs\": [],\n            \"planned_inputs\": [0.3, 0.0, 0.0, 0.0]\n        },\n        {\n            \"d\": 3, \"H\": 3,\n            \"x_k\": np.array([[0.0], [0.0]]),\n            \"past_inputs\": [0.5, 0.5, 0.5],\n            \"planned_inputs\": [0.0, 0.0, 0.0]\n        }\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        d = case[\"d\"]\n        H = case[\"H\"]\n        x_k = case[\"x_k\"]\n        past_inputs = case[\"past_inputs\"]\n        planned_inputs = case[\"planned_inputs\"]\n\n        if d == 0:\n            # Boundary case: no delay, no augmentation needed.\n            A_aug = A_d\n            B_aug = B_d\n            C_aug = C\n            z_k = x_k\n        else:\n            # General case: d >= 1. Construct augmented system.\n            aug_dim = n + d\n            \n            # Construct A_aug\n            A_aug = np.zeros((aug_dim, aug_dim))\n            A_aug[0:n, 0:n] = A_d  # Top-left block is A_d\n            A_aug[0:n, n:n+1] = B_d  # Input u_{k-d} affects x\n            # Shift register part\n            for i in range(d - 1):\n                A_aug[n + i, n + i + 1] = 1.0\n\n            # Construct B_aug\n            B_aug = np.zeros((aug_dim, 1))\n            B_aug[aug_dim - 1, 0] = 1.0  # New input u_k enters at the end of the register\n\n            # Construct C_aug\n            C_aug = np.zeros((1, aug_dim))\n            C_aug[0, 0:n] = C  # Output depends only on original state x\n\n            # Construct initial augmented state z_k\n            past_inputs_col = np.array(past_inputs).reshape(-1, 1)\n            z_k = np.vstack((x_k, past_inputs_col))\n\n        # --- Simulation Loop ---\n        y_predictions = []\n        z_current = z_k\n        \n        for j in range(H):\n            u_current = planned_inputs[j]\n            \n            # Propagate the augmented state one step forward\n            z_next = A_aug @ z_current + B_aug * u_current\n            \n            # Calculate the predicted output\n            y_next = C_aug @ z_next\n            \n            y_predictions.append(round(y_next[0, 0], 6))\n            \n            # Update state for the next iteration\n            z_current = z_next\n            \n        all_results.append(y_predictions)\n\n    # Format the final output string as specified\n    # e.g., [[val1,val2],[val3,val4]]\n    # Using string replace is a simple way to match the no-space format\n    # without adding forbidden library dependencies like json.\n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "3326498"}]}