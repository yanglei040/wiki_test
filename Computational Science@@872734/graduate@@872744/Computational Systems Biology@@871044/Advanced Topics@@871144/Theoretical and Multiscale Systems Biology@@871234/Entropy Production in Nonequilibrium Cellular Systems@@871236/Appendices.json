{"hands_on_practices": [{"introduction": "To begin our exploration of entropy production, we will analyze a foundational model of a molecular machine. This exercise [@problem_id:3305766] walks you through the essential steps of identifying a non-equilibrium steady state and quantifying its thermodynamic cost. By applying Kolmogorov’s criterion and calculating the steady-state probability currents, you will compute the total entropy production rate for a simple three-state cycle, building a concrete understanding of how directed biological processes dissipate energy.", "problem": "A chemostatted cellular transporter cycles through three coarse-grained conformational states $1 \\to 2 \\to 3 \\to 1$ while exchanging adenosine triphosphate (ATP) and adenosine diphosphate (ADP) with the environment. The coarse-grained dynamics of the conformational states is modeled as a continuous-time Markov jump process on the three states with bidirectional transitions along the ring. Due to maintained chemical potential differences in the environment, clockwise transitions are catalyzed faster than counterclockwise transitions.\n\nSpecifically, the nonzero transition rates (in $\\mathrm{s}^{-1}$) are\n$$\nk_{12} = 4,\\quad k_{23} = 4,\\quad k_{31} = 4,\\quad k_{21} = 1,\\quad k_{32} = 1,\\quad k_{13} = 1,\n$$\nand $k_{ij} = 0$ for all other ordered pairs $(i,j)$.\n\nTasks:\n- Apply Kolmogorov’s criterion to determine whether detailed balance holds in this network.\n- If detailed balance does not hold, compute the stationary distribution $\\{\\pi_1,\\pi_2,\\pi_3\\}$, the steady-state probability currents $J_{ij}$ for each edge $(i,j)$, and the total steady-state entropy production rate $\\dot S_{\\mathrm{tot}}$ using the standard framework of stochastic thermodynamics for Markov jump processes.\n\nAssume the natural logarithm and that the total entropy production rate $\\dot S_{\\mathrm{tot}}$ is defined in units of the Boltzmann constant $k_B$ (that is, the final numerical value should be expressed in $k_B\\,\\mathrm{s}^{-1}$). Round your final reported value of $\\dot S_{\\mathrm{tot}}$ to four significant figures. Report only the numerical value of $\\dot S_{\\mathrm{tot}}$ in $k_B\\,\\mathrm{s}^{-1}$ as your final answer.", "solution": "The problem will first be validated for scientific soundness, completeness, and consistency. Upon confirmation of its validity, a step-by-step solution will be provided.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\nThe problem provides the following information:\n- A system consisting of a cellular transporter cycling through three conformational states: $1$, $2$, and $3$.\n- The dynamics are described by a continuous-time Markov jump process on these states.\n- The network topology is a three-state ring: $1 \\leftrightarrow 2 \\leftrightarrow 3 \\leftrightarrow 1$.\n- The non-zero transition rates are given in units of $\\mathrm{s}^{-1}$:\n  - $k_{12} = 4$\n  - $k_{23} = 4$\n  - $k_{31} = 4$\n  - $k_{21} = 1$\n  - $k_{32} = 1$\n  - $k_{13} = 1$\n- All other transition rates $k_{ij}$ are zero.\n- The tasks are:\n  1. Use Kolmogorov’s criterion to test for detailed balance.\n  2. If detailed balance is violated, compute the stationary distribution $\\{\\pi_1, \\pi_2, \\pi_3\\}$, the steady-state probability currents $J_{ij}$, and the total steady-state entropy production rate $\\dot S_{\\mathrm{tot}}$.\n- The total entropy production rate $\\dot S_{\\mathrm{tot}}$ is to be expressed in units of the Boltzmann constant $k_B$, and the final numerical value is to be rounded to four significant figures.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientifically Grounded:** The problem describes a coarse-grained model of a molecular motor, a standard topic in computational systems biology and biophysics. The use of a continuous-time Markov process to model conformational dynamics and the framework of stochastic thermodynamics for calculating entropy production are well-established scientific principles. The problem is scientifically sound.\n- **Well-Posed:** The problem provides all necessary information (states, topology, and all non-zero transition rates) to uniquely determine the stationary distribution, currents, and entropy production rate. The tasks are clearly defined.\n- **Objective:** The problem is stated using precise mathematical and physical terminology, free of subjective or ambiguous language.\n\n**Step 3: Verdict and Action**\n\nThe problem is deemed valid as it is scientifically grounded, well-posed, objective, and self-contained. A full solution will be provided.\n\n### Solution\n\n**1. Kolmogorov’s Criterion and Detailed Balance**\n\nA stationary Markov process satisfies the condition of detailed balance if, for every pair of states $i$ and $j$, the steady-state flux from $i$ to $j$ equals the flux from $j$ to $i$. This is expressed as:\n$$\nk_{ij}\\pi_i = k_{ji}\\pi_j\n$$\nKolmogorov’s criterion for detailed balance states that a system is in detailed balance if and only if for any closed loop of states $i_1 \\to i_2 \\to \\dots \\to i_n \\to i_1$, the product of the forward transition rates equals the product of the reverse transition rates:\n$$\n\\prod_{k=1}^{n} k_{i_k i_{k+1}} = \\prod_{k=1}^{n} k_{i_{k+1} i_k}\n$$\nwhere $i_{n+1} = i_1$.\n\nIn this problem, the network consists of a single cycle $1 \\to 2 \\to 3 \\to 1$. We apply Kolmogorov's criterion to this cycle.\nThe product of clockwise (forward) rates is:\n$$\nk_{12} k_{23} k_{31} = 4 \\times 4 \\times 4 = 64\n$$\nThe product of counter-clockwise (reverse) rates is:\n$$\nk_{21} k_{32} k_{13} = 1 \\times 1 \\times 1 = 1\n$$\nSince $64 \\neq 1$, the condition for detailed balance is violated. The system is in a non-equilibrium steady state (NESS) sustained by a net cyclic probability flux.\n\n**2. Stationary Distribution $\\{\\pi_1, \\pi_2, \\pi_3\\}$**\n\nAt steady state, the probability distribution $\\vec{\\pi} = (\\pi_1, \\pi_2, \\pi_3)^T$ is constant, meaning $\\frac{d\\pi_i}{dt}=0$ for all $i \\in \\{1, 2, 3\\}$. The master equation for the steady state is $\\mathbf{Q}\\vec{\\pi} = \\vec{0}$, where $\\mathbf{Q}$ is the transition rate matrix. This yields a system of linear equations representing the balance of probability flow into and out of each state:\n\\begin{align*}\n\\frac{d\\pi_1}{dt} &= k_{21}\\pi_2 + k_{31}\\pi_3 - (k_{12}+k_{13})\\pi_1 = 0 \\\\\n\\frac{d\\pi_2}{dt} &= k_{12}\\pi_1 + k_{32}\\pi_3 - (k_{21}+k_{23})\\pi_2 = 0 \\\\\n\\frac{d\\pi_3}{dt} &= k_{13}\\pi_1 + k_{23}\\pi_2 - (k_{31}+k_{32})\\pi_3 = 0\n\\end{align*}\nSubstituting the given rates:\n\\begin{align*}\n1 \\cdot \\pi_2 + 4 \\cdot \\pi_3 - (4+1)\\pi_1 &= 0 \\implies \\pi_2 + 4\\pi_3 - 5\\pi_1 = 0 \\\\\n4 \\cdot \\pi_1 + 1 \\cdot \\pi_3 - (1+4)\\pi_2 &= 0 \\implies 4\\pi_1 + \\pi_3 - 5\\pi_2 = 0 \\\\\n1 \\cdot \\pi_1 + 4 \\cdot \\pi_2 - (4+1)\\pi_3 &= 0 \\implies \\pi_1 + 4\\pi_2 - 5\\pi_3 = 0\n\\end{align*}\nThis system of equations must be solved along with the normalization condition:\n$$\n\\pi_1 + \\pi_2 + \\pi_3 = 1\n$$\nFrom the second equation, we express $\\pi_3$ as $\\pi_3 = 5\\pi_2 - 4\\pi_1$. Substituting this into the first equation:\n$$\n\\pi_2 + 4(5\\pi_2 - 4\\pi_1) - 5\\pi_1 = 0 \\implies \\pi_2 + 20\\pi_2 - 16\\pi_1 - 5\\pi_1 = 0 \\implies 21\\pi_2 - 21\\pi_1 = 0 \\implies \\pi_1 = \\pi_2\n$$\nSince $\\pi_1 = \\pi_2$, the relation $\\pi_3 = 5\\pi_2 - 4\\pi_1$ simplifies to $\\pi_3 = 5\\pi_1 - 4\\pi_1 = \\pi_1$.\nThus, we find that $\\pi_1 = \\pi_2 = \\pi_3$. Using the normalization condition:\n$$\n\\pi_1 + \\pi_1 + \\pi_1 = 1 \\implies 3\\pi_1 = 1 \\implies \\pi_1 = \\frac{1}{3}\n$$\nTherefore, the stationary distribution is uniform:\n$$\n\\pi_1 = \\frac{1}{3}, \\quad \\pi_2 = \\frac{1}{3}, \\quad \\pi_3 = \\frac{1}{3}\n$$\nThis result is expected, as the transition rate matrix $\\mathbf{Q}$ is a circulant matrix, which has a uniform stationary distribution.\n\n**3. Steady-State Probability Currents $J_{ij}$**\n\nThe net probability current from state $i$ to state $j$ at steady state is defined as:\n$$\nJ_{ij} = k_{ij}\\pi_i - k_{ji}\\pi_j\n$$\nWe calculate the currents for the edges in the cycle:\n$$\nJ_{12} = k_{12}\\pi_1 - k_{21}\\pi_2 = 4 \\cdot \\frac{1}{3} - 1 \\cdot \\frac{1}{3} = \\frac{3}{3} = 1 \\, \\mathrm{s}^{-1}\n$$\n$$\nJ_{23} = k_{23}\\pi_2 - k_{32}\\pi_3 = 4 \\cdot \\frac{1}{3} - 1 \\cdot \\frac{1}{3} = \\frac{3}{3} = 1 \\, \\mathrm{s}^{-1}\n$$\n$$\nJ_{31} = k_{31}\\pi_3 - k_{13}\\pi_1 = 4 \\cdot \\frac{1}{3} - 1 \\cdot \\frac{1}{3} = \\frac{3}{3} = 1 \\, \\mathrm{s}^{-1}\n$$\nThe currents are equal along the cycle, $J_{12} = J_{23} = J_{31} = 1 \\, \\mathrm{s}^{-1}$, indicating a constant net probability flux of $J_{\\text{cycle}} = 1 \\, \\mathrm{s}^{-1}$ in the clockwise direction $1 \\to 2 \\to 3 \\to 1$.\n\n**4. Total Steady-State Entropy Production Rate $\\dot S_{\\mathrm{tot}}$**\n\nThe total entropy production rate for a system described by a Markov jump process can be calculated by summing the contributions from each fundamental cycle. In this case, there is only one cycle. The formula is:\n$$\n\\dot S_{\\mathrm{tot}} = J_{\\text{cycle}} \\mathcal{A}_{\\text{cycle}}\n$$\nwhere $J_{\\text{cycle}}$ is the net cycle current and $\\mathcal{A}_{\\text{cycle}}$ is the thermodynamic affinity of the cycle. The affinity is given by:\n$$\n\\mathcal{A}_{\\text{cycle}} = k_B \\ln\\left(\\frac{\\prod_{\\text{clockwise}} k_{ij}}{\\prod_{\\text{counter-clockwise}} k_{ji}}\\right)\n$$\nFor the cycle $1 \\to 2 \\to 3 \\to 1$:\n$$\n\\mathcal{A}_{\\text{cycle}} = k_B \\ln\\left(\\frac{k_{12}k_{23}k_{31}}{k_{21}k_{32}k_{13}}\\right)\n$$\nThe entropy production rate in units of $k_B$ is:\n$$\n\\frac{\\dot S_{\\mathrm{tot}}}{k_B} = J_{\\text{cycle}} \\ln\\left(\\frac{k_{12}k_{23}k_{31}}{k_{21}k_{32}k_{13}}\\right)\n$$\nSubstituting the known values for the current and rates:\n$$\n\\frac{\\dot S_{\\mathrm{tot}}}{k_B} = (1 \\, \\mathrm{s}^{-1}) \\times \\ln\\left(\\frac{4 \\times 4 \\times 4}{1 \\times 1 \\times 1}\\right) = \\ln(64) \\, \\mathrm{s}^{-1}\n$$\nTo obtain the required numerical value, we compute the natural logarithm of $64$:\n$$\n\\ln(64) \\approx 4.158883083...\n$$\nRounding this value to four significant figures gives:\n$$\n\\frac{\\dot S_{\\mathrm{tot}}}{k_B} \\approx 4.159 \\, \\mathrm{s}^{-1}\n$$", "answer": "$$\\boxed{4.159}$$", "id": "3305766"}, {"introduction": "Real-world biological measurements are often limited, providing only a partial view of complex molecular processes. This exercise [@problem_id:3305753] explores the important consequences of such incomplete information on thermodynamic inference. You will calculate both the true entropy production of a complete system and the 'apparent' entropy production that would be measured by an observer with access to only a subset of states, thereby quantifying the thermodynamic 'gap' created by hidden dynamics.", "problem": "A membrane transporter in a nonequilibrium cellular environment cycles among three conformational states $A \\leftrightarrow B \\leftrightarrow C \\leftrightarrow A$ as a continuous-time Markov jump process. The system is maintained out of equilibrium by constant chemical driving, and it is in a nonequilibrium steady state. All transitions are single-step along the ring with rate constants (in $\\mathrm{s}^{-1}$): $k_{AB} = 8$, $k_{BA} = 3$, $k_{BC} = 6$, $k_{CB} = 2$, $k_{CA} = 5$, $k_{AC} = 1$. Throughout, take Boltzmann’s constant $k_{B}$ as the entropy unit.\n\nAn experimentalist can only observe states $A$ and $B$; state $C$ is unobserved. From a long single-molecule time series, the following statistics are measured on the observed pair:\n- Long-time fractions of time in the observed states: $p_{A}^{\\mathrm{meas}} = \\frac{51}{166}$ and $p_{B}^{\\mathrm{meas}} = \\frac{58}{166}$.\n- Long-time direct jump rates between the observed states (counts per unit time of $A \\to B$ and $B \\to A$ jumps that occur without visiting $C$ in between): $r_{AB}^{\\mathrm{meas}} = \\frac{204}{83}\\ \\mathrm{s}^{-1}$ and $r_{BA}^{\\mathrm{meas}} = \\frac{87}{83}\\ \\mathrm{s}^{-1}$.\n\nUse the following foundations:\n- The steady state of a continuous-time Markov chain is defined by the stationary solution of the master equation $\\frac{d\\boldsymbol{p}}{dt} = \\boldsymbol{p} \\boldsymbol{Q}$ with $\\boldsymbol{p} \\boldsymbol{Q} = \\boldsymbol{0}$ and $\\sum_{i} p_{i} = 1$, where $\\boldsymbol{Q}$ is the rate matrix.\n- In stochastic thermodynamics (ST), the steady-state entropy production rate of a Markov jump process equals the sum over transitions of the probability current times the thermodynamic force (affinity) for each transition, computed from steady-state flows. For any pair of states $i$ and $j$, the steady-state probability current is $J_{ij} = k_{ij} p_{i} - k_{ji} p_{j}$ and the force is $\\ln\\!\\left(\\frac{k_{ij} p_{i}}{k_{ji} p_{j}}\\right)$.\n\nTasks:\n1. Compute the true steady-state entropy production rate $\\sigma_{\\mathrm{true}}$ of the full three-state system using only the fundamental definitions above.\n2. Compute the apparent entropy production rate $\\sigma_{\\mathrm{app}}$ that an observer restricted to the pair $\\{A,B\\}$ would compute if they use only the observed direct transitions $A \\leftrightarrow B$ and the measured steady-state flows for that edge, ignoring state $C$. Use the measured statistics provided.\n3. Compute the gap $\\Delta \\sigma = \\sigma_{\\mathrm{true}} - \\sigma_{\\mathrm{app}}$.\n\nExpress the final result for $\\Delta \\sigma$ in units of $k_{B}\\,\\mathrm{s}^{-1}$ and round your single numerical answer to four significant figures.", "solution": "The problem describes a continuous-time Markov jump process on three states $\\{A, B, C\\}$ in a nonequilibrium steady state (NESS). We are asked to compute and compare two measures of entropy production: one for the full system and one for an observer restricted to a subsystem.\n\nFirst, we determine the steady-state probabilities $p_A$, $p_B$, and $p_C$. The rate matrix $\\boldsymbol{Q}$ for the system is constructed from the given rate constants $k_{ij}$ (in units of $\\mathrm{s}^{-1}$): $k_{AB} = 8$, $k_{BA} = 3$, $k_{BC} = 6$, $k_{CB} = 2$, $k_{CA} = 5$, and $k_{AC} = 1$. The matrix elements are $Q_{ij} = k_{ij}$ for $i \\neq j$ and $Q_{ii} = -\\sum_{j \\neq i} k_{ij}$.\n$$\n\\boldsymbol{Q} = \\begin{pmatrix} -(k_{AB}+k_{AC}) & k_{AB} & k_{AC} \\\\ k_{BA} & -(k_{BA}+k_{BC}) & k_{BC} \\\\ k_{CA} & k_{CB} & -(k_{CA}+k_{CB}) \\end{pmatrix} = \\begin{pmatrix} -(8+1) & 8 & 1 \\\\ 3 & -(3+6) & 6 \\\\ 5 & 2 & -(5+2) \\end{pmatrix} = \\begin{pmatrix} -9 & 8 & 1 \\\\ 3 & -9 & 6 \\\\ 5 & 2 & -7 \\end{pmatrix}\n$$\nThe steady-state probability vector $\\boldsymbol{p} = (p_A, p_B, p_C)$ is the solution to the master equation $\\boldsymbol{p}\\boldsymbol{Q} = \\boldsymbol{0}$, subject to the normalization condition $\\sum_i p_i = 1$. This gives a system of linear equations:\n$$\n-9p_A + 3p_B + 5p_C = 0 \\\\\n8p_A - 9p_B + 2p_C = 0 \\\\\np_A + 6p_B - 7p_C = 0 \\\\\np_A + p_B + p_C = 1\n$$\nSolving this system, we can express $p_A$ and $p_B$ in terms of $p_C$ using two of the balance equations. For example, from the second and third equations, we find $p_A = \\frac{51}{57} p_C$ and $p_B = \\frac{58}{57} p_C$. Substituting these into the normalization condition:\n$$\n\\frac{51}{57} p_C + \\frac{58}{57} p_C + p_C = 1 \\implies \\left(\\frac{51+58+57}{57}\\right)p_C = 1 \\implies \\frac{166}{57}p_C = 1\n$$\nThis yields $p_C = \\frac{57}{166}$. The other probabilities are then $p_A = \\frac{51}{57} \\times \\frac{57}{166} = \\frac{51}{166}$ and $p_B = \\frac{58}{57} \\times \\frac{57}{166} = \\frac{58}{166}$. These calculated probabilities match the provided measured values $p_A^{\\mathrm{meas}}$ and $p_B^{\\mathrm{meas}}$.\n\n**1. True Steady-State Entropy Production Rate ($\\sigma_{\\mathrm{true}}$)**\nThe total entropy production rate for a Markov jump process in NESS is the sum of contributions from each transition pair. For a unicyclic system, this simplifies to the product of the cycle current $J$ and the cycle affinity $\\mathcal{A}$.\nThe cycle current $J$ is the net flow around the ring, which must be equal for each edge in the steady state: $J = J_{AB} = J_{BC} = J_{CA}$. Let's calculate $J$ using the edge $A \\leftrightarrow B$:\n$$\nJ = J_{AB} = k_{AB} p_A - k_{BA} p_B = 8 \\left(\\frac{51}{166}\\right) - 3 \\left(\\frac{58}{166}\\right) = \\frac{408 - 174}{166} = \\frac{234}{166} = \\frac{117}{83} \\ \\mathrm{s}^{-1}\n$$\nThe cycle affinity $\\mathcal{A}$ is the logarithm of the ratio of the product of forward rates to the product of backward rates around the cycle:\n$$\n\\mathcal{A} = \\ln\\left(\\frac{k_{AB}k_{BC}k_{CA}}{k_{BA}k_{CB}k_{AC}}\\right) = \\ln\\left(\\frac{8 \\times 6 \\times 5}{3 \\times 2 \\times 1}\\right) = \\ln\\left(\\frac{240}{6}\\right) = \\ln(40)\n$$\nThe true entropy production rate is then:\n$$\n\\sigma_{\\mathrm{true}} = J \\mathcal{A} = \\frac{117}{83} \\ln(40) \\ k_{B}\\,\\mathrm{s}^{-1}\n$$\n\n**2. Apparent Entropy Production Rate ($\\sigma_{\\mathrm{app}}$)**\nThe apparent entropy production rate is what an observer would compute seeing only the direct transitions between states $A$ and $B$. This calculation is based on the \"measured steady-state flows for that edge\", which are given as $r_{AB}^{\\mathrm{meas}}$ and $r_{BA}^{\\mathrm{meas}}$. These correspond to the one-way fluxes between $A$ and $B$:\n$$\nr_{AB}^{\\mathrm{meas}} = k_{AB} p_A = 8 \\left(\\frac{51}{166}\\right) = \\frac{408}{166} = \\frac{204}{83} \\ \\mathrm{s}^{-1} \\\\\nr_{BA}^{\\mathrm{meas}} = k_{BA} p_B = 3 \\left(\\frac{58}{166}\\right) = \\frac{174}{166} = \\frac{87}{83} \\ \\mathrm{s}^{-1}\n$$\nThe problem states these values are measured, and our calculation verifies their consistency. The apparent entropy production is constructed from the apparent current $J_{\\mathrm{app}}$ and apparent force $\\mathcal{F}_{\\mathrm{app}}$ for the observed edge:\nThe apparent current is the net flow: $J_{\\mathrm{app}} = r_{AB}^{\\mathrm{meas}} - r_{BA}^{\\mathrm{meas}} = \\frac{204}{83} - \\frac{87}{83} = \\frac{117}{83} \\ \\mathrm{s}^{-1}$, which is identical to the cycle current $J$.\nThe apparent force is the logarithm of the ratio of the one-way flows:\n$$\n\\mathcal{F}_{\\mathrm{app}} = \\ln\\left(\\frac{r_{AB}^{\\mathrm{meas}}}{r_{BA}^{\\mathrm{meas}}}\\right) = \\ln\\left(\\frac{k_{AB}p_A}{k_{BA}p_B}\\right) = \\ln\\left(\\frac{204/83}{87/83}\\right) = \\ln\\left(\\frac{204}{87}\\right) = \\ln\\left(\\frac{68}{29}\\right)\n$$\nThe apparent entropy production rate is the product of these two quantities:\n$$\n\\sigma_{\\mathrm{app}} = J_{\\mathrm{app}} \\mathcal{F}_{\\mathrm{app}} = \\frac{117}{83} \\ln\\left(\\frac{68}{29}\\right) \\ k_{B}\\,\\mathrm{s}^{-1}\n$$\nThis quantity represents the contribution to the total entropy production from the single edge $A \\leftrightarrow B$.\n\n**3. The Gap ($\\Delta \\sigma$)**\nThe gap $\\Delta \\sigma$ is the difference between the true and apparent entropy production rates. This represents the hidden entropy production occurring in the unobserved part of the system ($B \\leftrightarrow C \\leftrightarrow A$).\n$$\n\\Delta \\sigma = \\sigma_{\\mathrm{true}} - \\sigma_{\\mathrm{app}} = \\frac{117}{83} \\ln(40) - \\frac{117}{83} \\ln\\left(\\frac{68}{29}\\right)\n$$\nUsing the property of logarithms, $\\ln(x) - \\ln(y) = \\ln(x/y)$:\n$$\n\\Delta \\sigma = \\frac{117}{83} \\ln\\left(\\frac{40}{68/29}\\right) = \\frac{117}{83} \\ln\\left(\\frac{40 \\times 29}{68}\\right)\n$$\nSince $40 = 4 \\times 10$ and $68 = 4 \\times 17$:\n$$\n\\Delta \\sigma = \\frac{117}{83} \\ln\\left(\\frac{10 \\times 29}{17}\\right) = \\frac{117}{83} \\ln\\left(\\frac{290}{17}\\right) \\ k_{B}\\,\\mathrm{s}^{-1}\n$$\nTo find the numerical value, we compute:\n$$\n\\Delta \\sigma = \\frac{117}{83} \\times \\ln\\left(\\frac{290}{17}\\right) \\approx 1.40963855 \\times \\ln(17.0588235) \\approx 1.40963855 \\times 2.836667 \\approx 3.998539 \\ k_{B}\\,\\mathrm{s}^{-1}\n$$\nRounding the result to four significant figures gives $3.999 \\ k_{B}\\,\\mathrm{s}^{-1}$.", "answer": "$$\n\\boxed{3.999}\n$$", "id": "3305753"}, {"introduction": "Cellular processes are not static; they are dynamically regulated by time-varying signals. This computational practice [@problem_id:3305715] delves into the thermodynamics of such periodically driven systems, using a synthetic bistable switch as a case study. You will implement a numerical simulation to explore how different control protocol shapes affect the total entropy production, tackling a fundamental question in optimal control: how to achieve a desired system behavior with minimal thermodynamic dissipation.", "problem": "A synthetic bistable toggle switch in a cell can be coarse-grained as a two-state continuous-time Markov chain with states labeled by $A$ and $B$, representing dominance of one gene over the other. The nonequilibrium control is applied through a periodic stimulus with protocol shape $\\lambda(t)$ of period $T$, which modulates the depth of the basins of attraction and thereby the transition rates. The goal is to compute the entropy production per period and determine, among several candidate periodic shapes, which protocol shape minimizes entropy production while achieving a specified robustness target quantified by a basin depth constraint.\n\nFundamental base:\n1. The master equation for the two-state Markov process with time-dependent transition rates $k_{A \\to B}(t)$ and $k_{B \\to A}(t)$ governs the probability $p_A(t)$ of being in state $A$ and $p_B(t)=1-p_A(t)$ of being in state $B$:\n$$\n\\frac{dp_A}{dt} = -p_A(t)\\,k_{A \\to B}(t) + p_B(t)\\,k_{B \\to A}(t).\n$$\n2. The instantaneous entropy production rate for a Markov jump process (Schnakenberg formula) in natural units (nats per second) is\n$$\n\\sigma(t) = J(t)\\,\\ln\\left(\\frac{k_{A \\to B}(t)\\,p_A(t)}{k_{B \\to A}(t)\\,p_B(t)}\\right),\n$$\nwhere the net probability current is\n$$\nJ(t) = p_A(t)\\,k_{A \\to B}(t) - p_B(t)\\,k_{B \\to A}(t).\n$$\n3. The relation between basin depth and rates is constructed to satisfy detailed balance in the instantaneous limit by setting\n$$\n\\Delta U(t) = U_B(t) - U_A(t) = \\Delta U_{\\text{base}} + c\\,\\lambda(t),\n$$\nand imposing\n$$\n\\frac{k_{A \\to B}(t)}{k_{B \\to A}(t)} = e^{-\\beta \\Delta U(t)},\n$$\nwith a symmetric splitting of the modulation\n$$\nk_{A \\to B}(t) = k_0\\,e^{-\\frac{\\beta}{2}\\Delta U(t)}, \\quad k_{B \\to A}(t) = k_0\\,e^{+\\frac{\\beta}{2}\\Delta U(t)},\n$$\nwhere $k_0$ is a baseline rate in $\\text{s}^{-1}$, $\\beta$ is the inverse thermal energy scale $1/(k_{\\mathrm{B}}T)$ in natural units, and $\\Delta U(t)$ is a basin depth difference in nats.\n\nRobustness constraint and protocol shapes:\n- The robustness target is a required time-averaged basin depth $\\Delta U_{\\text{target}}$ over one period $T$:\n$$\n\\frac{1}{T}\\int_0^T \\Delta U(t)\\,dt = \\Delta U_{\\text{target}}.\n$$\nUsing $\\Delta U(t) = \\Delta U_{\\text{base}} + c\\,\\lambda(t)$, this implies\n$$\n\\frac{1}{T}\\int_0^T \\lambda(t)\\,dt = m = \\frac{\\Delta U_{\\text{target}} - \\Delta U_{\\text{base}}}{c}.\n$$\n- To ensure fair comparison for different protocol shapes given a fixed stimulus budget, constrain the root-mean-square (RMS) of the protocol over one period to a fixed value $L_{\\mathrm{rms}}$:\n$$\n\\sqrt{\\frac{1}{T}\\int_0^T \\lambda^2(t)\\,dt} = L_{\\mathrm{rms}}.\n$$\nLet $S(t)$ be a zero-mean, unit-amplitude periodic shape, and parametrize $\\lambda(t)$ as\n$$\n\\lambda(t) = m + s\\,S(t),\n$$\nwith $s$ chosen to satisfy the RMS constraint. For a given shape $S(t)$, the scaling is\n$$\ns = \\frac{\\sqrt{L_{\\mathrm{rms}}^2 - m^2}}{\\sqrt{\\frac{1}{T}\\int_0^T S^2(t)\\,dt}},\n$$\nif $L_{\\mathrm{rms}}^2 \\ge m^2$, and $s=0$ otherwise. The candidate shapes $S(t)$ to be evaluated are:\n- Sine wave: $S_{\\sin}(t) = \\sin\\left(\\frac{2\\pi t}{T}\\right)$ with $\\frac{1}{T}\\int_0^T S_{\\sin}^2(t)\\,dt = \\frac{1}{2}$.\n- Square wave: $S_{\\mathrm{sq}}(t) = \\mathrm{sign}\\left(\\sin\\left(\\frac{2\\pi t}{T}\\right)\\right)$ with $\\frac{1}{T}\\int_0^T S_{\\mathrm{sq}}^2(t)\\,dt = 1$.\n- Triangle wave: $S_{\\triangle}(t)$ defined piecewise with amplitude $1$ and zero mean over $[0,T)$, for example\n$$\nS_{\\triangle}(t) =\n\\begin{cases}\n4\\phi - 1, & \\phi \\in [0,\\frac{1}{2}) \\\\\n-4\\phi + 3, & \\phi \\in [\\frac{1}{2},1)\n\\end{cases}\n$$\nwhere $\\phi = \\left(\\frac{t}{T}\\right) \\bmod 1$, and $\\frac{1}{T}\\int_0^T S_{\\triangle}^2(t)\\,dt = \\frac{1}{3}$.\n\nObjective:\n- For each candidate shape, compute the protocol $\\lambda(t)$ that satisfies the average depth and RMS constraints, evolve the master equation to the periodic steady state, and then compute the total entropy production per period\n$$\n\\Sigma = \\int_0^T \\sigma(t)\\,dt\n$$\nin nats per period. Among the candidate shapes, identify the one that minimizes $\\Sigma$.\n\nAlgorithmic requirements:\n- Numerically integrate the master equation with a fixed time step $\\Delta t$ over multiple periods to reach the periodic steady state. Use an explicit high-order method such as the fourth-order Runge–Kutta method. Clip probabilities to the open interval $(0,1)$ to avoid numerical singularities in the logarithm.\n- Compute $\\sigma(t)$ at each time step using the Schnakenberg expression and integrate $\\Sigma$ over the last period using a suitable numerical quadrature.\n\nUnits and output:\n- Time parameters are specified in seconds, rates in $\\text{s}^{-1}$, and entropy production output must be in nats per period. The final output of your program must be a single line containing the results for all test cases as a comma-separated list enclosed in square brackets, where each result is the integer index of the entropy-minimizing shape: $0$ for sine, $1$ for square, and $2$ for triangle.\n\nTest suite:\nFor each test case, the parameters are given as a tuple $(\\beta, k_0, \\Delta U_{\\text{base}}, \\Delta U_{\\text{target}}, c, T, L_{\\mathrm{rms}}, N_{\\text{trans}})$, where $N_{\\text{trans}}$ is the number of transient periods to simulate before computing entropy production on the final period.\n\nUse the following test cases:\n- Case 1 (moderate driving, happy path): $(1.0, 0.5, 0.5, 1.0, 1.0, 10.0, 0.6, 10)$\n- Case 2 (quasi-static slow driving): $(1.0, 0.5, 0.5, 1.0, 1.0, 100.0, 0.6, 6)$\n- Case 3 (fast driving, nonadiabatic): $(1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.4, 20)$\n- Case 4 (minimal control beyond mean requirement): $(1.0, 0.5, 0.5, 1.0, 1.0, 10.0, 0.51, 10)$\n- Case 5 (strong coupling and moderate period): $(1.5, 0.5, 0.3, 0.9, 2.0, 5.0, 0.7, 12)$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4,result5]\") where each \"result\" is the integer shape index that minimizes the total entropy production per period for the corresponding test case.", "solution": "The problem requires finding the periodic control protocol, among three candidates (sine, square, triangle wave), that minimizes the total entropy production per period for a bistable cellular switch. This system is modeled as a two-state continuous-time Markov process subject to constraints on the control protocol. The solution necessitates a numerical approach, which is organized into the following principled steps: protocol parametrization, simulation of the system's dynamics to find the periodic steady state, and subsequent calculation of the entropy production.\n\n**1. Protocol Parametrization**\n\nThe control protocol $\\lambda(t)$ is periodic with period $T$. It is constrained by a target time-averaged basin depth and a fixed root-mean-square (RMS) value. These constraints determine the specific form of $\\lambda(t)$ for each candidate shape.\n\nThe protocol is parametrized as $\\lambda(t) = m + s\\,S(t)$, where $S(t)$ is a zero-mean, unit-amplitude periodic function representing the shape (sine, square, or triangle), $m$ is the mean, and $s$ is the amplitude scaling factor.\n\n-   The mean $m$ is fixed by the robustness constraint on the time-averaged basin depth, $\\frac{1}{T}\\int_0^T \\Delta U(t)\\,dt = \\Delta U_{\\text{target}}$. Given $\\Delta U(t) = \\Delta U_{\\text{base}} + c\\,\\lambda(t)$, and that $\\frac{1}{T}\\int_0^T S(t)\\,dt = 0$, we find:\n    $$m = \\frac{1}{T}\\int_0^T \\lambda(t)\\,dt = \\frac{\\Delta U_{\\text{target}} - \\Delta U_{\\text{base}}}{c}$$\n-   The scaling factor $s$ is determined by the RMS constraint, $\\sqrt{\\frac{1}{T}\\int_0^T \\lambda^2(t)\\,dt} = L_{\\mathrm{rms}}$. Squaring this and substituting $\\lambda(t) = m + s\\,S(t)$ yields:\n    $$L_{\\mathrm{rms}}^2 = \\frac{1}{T}\\int_0^T (m + s\\,S(t))^2\\,dt = m^2 + s^2 \\left(\\frac{1}{T}\\int_0^T S^2(t)\\,dt\\right)$$\n    Solving for $s$ gives:\n    $$s = \\frac{\\sqrt{L_{\\mathrm{rms}}^2 - m^2}}{\\sqrt{\\frac{1}{T}\\int_0^T S^2(t)\\,dt}}$$\n    This is valid if $L_{\\mathrm{rms}}^2 \\ge m^2$. If $L_{\\mathrm{rms}}^2 < m^2$, the constraint cannot be satisfied with a real $s$, so we take $s=0$. The problem provides the mean-square values for each shape: $1/2$ for sine, $1$ for square, and $1/3$ for triangle.\n\n**2. System Dynamics and Numerical Simulation**\n\nThe system's state is described by the probability $p_A(t)$ of being in state $A$. The time evolution of $p_A(t)$ is governed by the master equation:\n$$ \\frac{dp_A}{dt} = -p_A(t)\\,k_{A \\to B}(t) + (1-p_A(t))\\,k_{B \\to A}(t) $$\nThis is a first-order linear ordinary differential equation (ODE) with time-dependent coefficients. The transition rates $k_{A \\to B}(t)$ and $k_{B \\to A}(t)$ depend on the protocol $\\lambda(t)$ via the basin depth difference $\\Delta U(t)$:\n$$ \\Delta U(t) = \\Delta U_{\\text{base}} + c\\,\\lambda(t) $$\n$$ k_{A \\to B}(t) = k_0\\,e^{-\\frac{\\beta}{2}\\Delta U(t)}, \\quad k_{B \\to A}(t) = k_0\\,e^{+\\frac{\\beta}{2}\\Delta U(t)} $$\nSince the rates are periodic with period $T$, the system evolves to a unique periodic steady state, where $p_A(t+T) = p_A(t)$. To find this state, we numerically integrate the ODE from an arbitrary initial condition (e.g., $p_A(0)=0.5$) for a number of transient periods ($N_{\\text{trans}}$) until the solution becomes periodic.\n\nThe integration is performed using the fourth-order Runge-Kutta (RK4) method with a fixed time step $\\Delta t$, chosen to be a small fraction of the period $T$ (e.g., $\\Delta t = T/2000$) to ensure numerical stability and accuracy. Let $f(t, p_A) = \\frac{dp_A}{dt}$. The RK4 update rule from time $t_i$ to $t_{i+1} = t_i + \\Delta t$ is:\n$$ p_A(t_{i+1}) = p_A(t_i) + \\frac{\\Delta t}{6}(k_1 + 2k_2 + 2k_3 + k_4) $$\nwhere:\n$$ k_1 = f(t_i, p_A(t_i)) $$\n$$ k_2 = f(t_i + \\frac{\\Delta t}{2}, p_A(t_i) + \\frac{\\Delta t}{2}k_1) $$\n$$ k_3 = f(t_i + \\frac{\\Delta t}{2}, p_A(t_i) + \\frac{\\Delta t}{2}k_2) $$\n$$ k_4 = f(t_i + \\Delta t, p_A(t_i) + \\Delta t k_3) $$\nTo prevent numerical issues with the logarithm in the entropy formula, the probability $p_A$ is clipped to remain within a small epsilon of the interval $(0, 1)$ after each step.\n\n**3. Entropy Production Calculation**\n\nOnce the system has reached the periodic steady state, we compute the total entropy production $\\Sigma$ over one period. The instantaneous entropy production rate $\\sigma(t)$ is given by the Schnakenberg formula:\n$$ \\sigma(t) = J(t)\\,\\ln\\left(\\frac{k_{A \\to B}(t)\\,p_A(t)}{k_{B \\to A}(t)\\,p_B(t)}\\right) $$\nwhere $p_B(t) = 1 - p_A(t)$ and the net probability current $J(t)$ is:\n$$ J(t) = p_A(t)\\,k_{A \\to B}(t) - p_B(t)\\,k_{B \\to A}(t) $$\nThe argument of the logarithm can be simplified using the relation $\\frac{k_{A \\to B}(t)}{k_{B \\to A}(t)} = e^{-\\beta \\Delta U(t)}$, yielding:\n$$ \\sigma(t) = J(t) \\left(-\\beta \\Delta U(t) + \\ln\\left(\\frac{p_A(t)}{1-p_A(t)}\\right)\\right) $$\nThe total entropy production per period, $\\Sigma$, is the integral of $\\sigma(t)$ over the final period of the simulation:\n$$ \\Sigma = \\int_{N_{\\text{trans}}T}^{(N_{\\text{trans}}+1)T} \\sigma(t)\\,dt $$\nThis integral is computed numerically using the trapezoidal rule, summing the values of $\\sigma(t_i)\\Delta t$ calculated at each time step $t_i$ of the final period.\n\n**4. Optimization**\n\nThe procedure outlined above is executed for each of the three candidate protocol shapes (sine, square, triangle). The resulting total entropy production values, $\\Sigma_{\\sin}$, $\\Sigma_{\\text{sq}}$, and $\\Sigma_{\\triangle}$, are compared. The shape corresponding to the minimum value of $\\Sigma$ is identified as the optimal protocol for the given set of parameters. This process is repeated for each test case provided.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# A small constant for clipping probabilities to avoid log(0) or division by zero.\nEPS = 1e-12\n\ndef s_sin(t, T):\n    \"\"\"Sine wave shape function.\"\"\"\n    return np.sin(2 * np.pi * t / T)\n\ndef s_sq(t, T):\n    \"\"\"Square wave shape function.\"\"\"\n    val = np.sign(np.sin(2 * np.pi * t / T))\n    # Ensure it's -1 or 1 for robustness if t is an exact multiple of T/2\n    if isinstance(val, np.ndarray):\n        val[val == 0] = 1.0 # Arbitrarily set to 1 at discontinuities\n    elif val == 0:\n        val = 1.0\n    return val\n\ndef s_triangle_vec(t, T):\n    \"\"\"Vectorized triangle wave shape function.\"\"\"\n    phi = (t / T) % 1.0\n    return np.where(phi < 0.5, 4 * phi - 1, -4 * phi + 3)\n\n# Dictionary of shape properties: (shape_function, mean_square_integral)\nSHAPES = {\n    0: (s_sin, 0.5),           # Index 0 for sine\n    1: (s_sq, 1.0),            # Index 1 for square\n    2: (s_triangle_vec, 1.0 / 3.0) # Index 2 for triangle\n}\n\ndef dpA_dt(t, p_A, params):\n    \"\"\"\n    Calculates the derivative dp_A/dt for the master equation.\n    f(t, p_A) = k_BA(t) - p_A(t) * (k_AB(t) + k_BA(t))\n    \"\"\"\n    beta, k0, c, T, m, s, S_func, dU_base = params\n    \n    # Calculate protocol and rates at time t\n    lambda_t = m + s * S_func(t, T)\n    dU_t = dU_base + c * lambda_t\n    \n    k_ab_t = k0 * np.exp(-0.5 * beta * dU_t)\n    k_ba_t = k0 * np.exp(0.5 * beta * dU_t)\n    \n    return k_ba_t - p_A * (k_ab_t + k_ba_t)\n\ndef compute_total_entropy(case_params, shape_idx):\n    \"\"\"\n    Computes the total entropy production per period for a given protocol shape.\n    \"\"\"\n    beta, k0, dU_base, dU_target, c, T, L_rms, N_trans = case_params\n    \n    # Numerical integration parameters\n    N_steps_per_period = 2000\n    dt = T / N_steps_per_period\n    total_steps = (N_trans + 1) * N_steps_per_period\n    \n    # Calculate protocol parameters m and s\n    m = (dU_target - dU_base) / c\n    S_func, S_sq_int = SHAPES[shape_idx]\n    \n    if L_rms**2 < m**2:\n        s = 0.0\n    else:\n        s = np.sqrt(L_rms**2 - m**2) / np.sqrt(S_sq_int)\n        \n    ode_params = (beta, k0, c, T, m, s, S_func, dU_base)\n    \n    # RK4 integration to find the periodic steady state\n    p_A = np.zeros(total_steps + 1)\n    p_A[0] = 0.5  # Initial condition\n    \n    time_points = np.linspace(0, (N_trans + 1) * T, total_steps + 1)\n    \n    for i in range(total_steps):\n        t_i = time_points[i]\n        p_A_i = p_A[i]\n        \n        # RK4 steps\n        k1 = dpA_dt(t_i, p_A_i, ode_params)\n        k2 = dpA_dt(t_i + dt/2, p_A_i + dt/2 * k1, ode_params)\n        k3 = dpA_dt(t_i + dt/2, p_A_i + dt/2 * k2, ode_params)\n        k4 = dpA_dt(t_i + dt, p_A_i + dt * k3, ode_params)\n        \n        p_A[i+1] = p_A_i + (dt/6) * (k1 + 2*k2 + 2*k3 + k4)\n        \n        # Clip probability to avoid numerical singularities\n        p_A[i+1] = np.clip(p_A[i+1], EPS, 1.0 - EPS)\n        \n    # Extract the last period for entropy calculation\n    start_idx = N_trans * N_steps_per_period\n    final_p_A = p_A[start_idx:]\n    final_t = time_points[start_idx:]\n    \n    # Compute instantaneous entropy production rate sigma(t) over the last period\n    lambda_t = m + s * S_func(final_t, T)\n    dU_t = dU_base + c * lambda_t\n    \n    k_ab_t = k0 * np.exp(-0.5 * beta * dU_t)\n    k_ba_t = k0 * np.exp(0.5 * beta * dU_t)\n    \n    final_p_B = 1.0 - final_p_A\n    \n    # Net probability current J(t)\n    J_t = final_p_A * k_ab_t - final_p_B * k_ba_t\n    \n    # Affinity term in the entropy production formula\n    log_term = -beta * dU_t + np.log(final_p_A / final_p_B)\n    \n    sigma_t = J_t * log_term\n    \n    # Integrate total entropy production Sigma using trapezoidal rule\n    Sigma = np.trapz(sigma_t, final_t)\n    \n    return Sigma\n\ndef solve():\n    \"\"\"\n    Main solver function to run all test cases and find the entropy-minimizing shape.\n    \"\"\"\n    test_cases = [\n        # (beta, k0, dU_base, dU_target, c, T, L_rms, N_trans)\n        (1.0, 0.5, 0.5, 1.0, 1.0, 10.0, 0.6, 10),\n        (1.0, 0.5, 0.5, 1.0, 1.0, 100.0, 0.6, 6),\n        (1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.4, 20),\n        (1.0, 0.5, 0.5, 1.0, 1.0, 10.0, 0.51, 10),\n        (1.5, 0.5, 0.3, 0.9, 2.0, 5.0, 0.7, 12)\n    ]\n\n    results = []\n    for case in test_cases:\n        entropies = []\n        for shape_idx in range(len(SHAPES)):\n            sigma_total = compute_total_entropy(case, shape_idx)\n            entropies.append(sigma_total)\n        \n        # Find the index of the shape that minimizes entropy production\n        min_entropy_idx = np.argmin(entropies)\n        results.append(min_entropy_idx)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3305715"}]}