{"hands_on_practices": [{"introduction": "To build a solid understanding of the Linear Noise Approximation (LNA), we begin with its foundations. This first exercise guides you through deriving a key component of the LNA—the diffusion coefficient—directly from the Chemical Master Equation for a simple birth-death process. By explicitly calculating this term, you will gain a first-principles appreciation for how the stochastic nature of individual birth and death events contributes to the overall noise in a system. [@problem_id:3323858]", "problem": "Consider a single-species birth-death process in a well-mixed compartment of volume $\\Omega$, with molecular count denoted by $X$. The reaction scheme is: birth $\\varnothing \\to X$ and death $X \\to \\varnothing$. Assume standard stochastic mass-action kinetics with propensities $a_{+}(X)=\\alpha \\Omega$ for birth and $a_{-}(X)=k X$ for death, where $\\alpha$ and $k$ are positive constants, and define the macroscopic concentration $\\phi$ via $X=\\Omega \\phi$. Using the van Kampen system-size expansion up to the linear noise approximation (LNA), let $\\xi$ denote the concentration fluctuation defined by $X=\\Omega \\phi + \\Omega^{1/2}\\xi$. In the LNA, the probability density for $\\xi$ obeys a linear Fokker–Planck equation with a state-dependent diffusion coefficient $D(\\phi)$ that captures the intrinsic noise intensity at concentration $\\phi$.\n\nStarting from the Chemical Master Equation and the definition of stoichiometry for the two reactions, derive the explicit expression for $D(\\phi)$ in terms of $\\alpha$, $k$, and $\\phi$. Then, interpret how the separate birth and death reactions contribute to the instantaneous variance growth of $X$ at the macroscopic concentration $\\phi$. Express your final answer as a single closed-form analytic expression for $D(\\phi)$. No numerical evaluation is required and no units need to be reported in the final answer.", "solution": "The problem requires the derivation of the diffusion coefficient $D(\\phi)$ for a single-species birth-death process within the framework of the Linear Noise Approximation (LNA). We begin with the Chemical Master Equation (CME), which governs the time evolution of the probability $P(X, t)$ of having $X$ molecules at time $t$.\n\nThe reactions are:\n1. Birth: $\\varnothing \\xrightarrow{\\alpha\\Omega} X$, with stoichiometry $S_+ = +1$ and propensity $a_+(X) = \\alpha\\Omega$.\n2. Death: $X \\xrightarrow{kX} \\varnothing$, with stoichiometry $S_- = -1$ and propensity $a_-(X) = kX$.\n\nThe CME for this system is:\n$$\n\\frac{\\partial P(X, t)}{\\partial t} = [a_+(X-1)P(X-1, t) - a_+(X)P(X, t)] + [a_-(X+1)P(X+1, t) - a_-(X)P(X, t)]\n$$\nSubstituting the given propensities:\n$$\n\\frac{\\partial P(X, t)}{\\partial t} = [\\alpha\\Omega P(X-1, t) - \\alpha\\Omega P(X, t)] + [k(X+1)P(X+1, t) - kX P(X, t)]\n$$\n\nThe next step is to apply the van Kampen system-size expansion. We decompose the molecular count $X$ into a deterministic, macroscopic part and a stochastic fluctuation part:\n$$\nX(t) = \\Omega\\phi(t) + \\Omega^{1/2}\\xi(t)\n$$\nHere, $\\phi(t)$ is the macroscopic concentration and $\\xi(t)$ is the fluctuation variable. The probability distribution $P(X, t)$ is transformed into a distribution for the fluctuation, $\\Pi(\\xi, t)$, such that $P(X, t)dX = \\Pi(\\xi, t)d\\xi$. Since $dX = \\Omega^{1/2}d\\xi$, we have $P(X, t) = \\Omega^{-1/2}\\Pi(\\xi, t)$.\n\nThe time derivative on the left-hand side of the CME transforms as:\n$$\n\\frac{\\partial}{\\partial t} P(X, t) = \\frac{\\partial}{\\partial t} \\left(\\Omega^{-1/2}\\Pi(\\xi, t)\\right) = \\Omega^{-1/2}\\frac{\\partial \\Pi}{\\partial t} + \\Omega^{-1/2} \\frac{\\partial \\Pi}{\\partial \\xi} \\frac{\\partial \\xi}{\\partial t}\n$$\nFrom the definition of $\\xi$, we have $\\frac{\\partial \\xi}{\\partial t} = -\\Omega^{1/2} \\frac{d\\phi}{dt}$. Thus, the LHS becomes:\n$$\n\\frac{\\partial P(X, t)}{\\partial t} = \\Omega^{-1/2}\\frac{\\partial \\Pi}{\\partial t} - \\Omega^{1/2}\\frac{d\\phi}{dt}\\frac{\\partial \\Pi}{\\partial \\xi}\n$$\n\nNow we expand the terms on the right-hand side of the CME. We use the Kramers-Moyal expansion, which can be expressed using shift operators $E_X^n f(X) = f(X+n)$. The CME can be written as:\n$$\n\\frac{\\partial P(X, t)}{\\partial t} = \\sum_{j \\in \\{+,-\\}} (E_X^{-S_j} - 1)[a_j(X) P(X, t)]\n$$\nThe shift operator acting on functions of $X$ can be expanded in terms of derivatives with respect to $\\xi$, using $\\frac{\\partial}{\\partial X} = \\Omega^{-1/2}\\frac{\\partial}{\\partial \\xi}$:\n$$\nE_X^{-S_j} = \\exp\\left(-S_j \\frac{\\partial}{\\partial X}\\right) = \\exp\\left(-S_j \\Omega^{-1/2} \\frac{\\partial}{\\partial \\xi}\\right)\n$$\nExpanding the exponential operator up to second order yields:\n$$\nE_X^{-S_j} - 1 \\approx -S_j \\Omega^{-1/2} \\frac{\\partial}{\\partial \\xi} + \\frac{1}{2} S_j^2 \\Omega^{-1} \\frac{\\partial^2}{\\partial \\xi^2}\n$$\nThe propensity terms are expanded around the macroscopic state $\\Omega\\phi$:\n$$\na_j(X) = a_j(\\Omega\\phi + \\Omega^{1/2}\\xi) \\approx a_j(\\Omega\\phi) + \\Omega^{1/2}\\xi \\frac{da_j}{dX}\\bigg|_{X=\\Omega\\phi}\n$$\nLet's define the macroscopic rate functions $F_j(\\phi) = \\Omega^{-1}a_j(\\Omega\\phi)$.\nFor the birth reaction: $F_+(\\phi) = \\Omega^{-1}(\\alpha\\Omega) = \\alpha$.\nFor the death reaction: $F_-(\\phi) = \\Omega^{-1}(k\\Omega\\phi) = k\\phi$.\n\nThe term $[a_j(X) P(X, t)]$ in the CME is expanded as:\n$$\na_j(\\Omega\\phi + \\Omega^{1/2}\\xi) \\Omega^{-1/2}\\Pi(\\xi, t) \\approx [\\Omega F_j(\\phi) + \\dots] \\Omega^{-1/2}\\Pi = \\Omega^{1/2}F_j(\\phi)\\Pi(\\xi, t) + \\mathcal{O}(\\Omega^0)\n$$\nSubstituting these expansions into the RHS of the CME:\n$$\n\\sum_j \\left(-S_j \\Omega^{-1/2} \\frac{\\partial}{\\partial \\xi} + \\frac{1}{2} S_j^2 \\Omega^{-1} \\frac{\\partial^2}{\\partial \\xi^2} + \\dots\\right) \\left[ (a_j(\\Omega\\phi) + \\dots)\\Omega^{-1/2}\\Pi \\right]\n$$\nWe collect terms by powers of $\\Omega$.\n\nThe highest order term is $\\Omega^{1/2}$. Equating terms of this order from the LHS and RHS:\n$$\n-\\Omega^{1/2}\\frac{d\\phi}{dt}\\frac{\\partial \\Pi}{\\partial \\xi} = \\sum_j \\left( -S_j \\Omega^{-1/2} \\frac{\\partial}{\\partial \\xi}\\right) (a_j(\\Omega\\phi) \\Omega^{-1/2} \\Pi) = \\sum_j -S_j (\\Omega^{-1}a_j(\\Omega\\phi))\\Omega^{1/2}\\frac{\\partial\\Pi}{\\partial\\xi}\n$$\n$$\n-\\frac{d\\phi}{dt}\\frac{\\partial \\Pi}{\\partial \\xi} = -\\left(\\sum_j S_j F_j(\\phi)\\right) \\frac{\\partial \\Pi}{\\partial \\xi}\n$$\nThis must hold for any $\\Pi$, giving the macroscopic rate equation:\n$$\n\\frac{d\\phi}{dt} = \\sum_j S_j F_j(\\phi) = S_+ F_+(\\phi) + S_- F_-(\\phi) = (+1)\\alpha + (-1)k\\phi = \\alpha - k\\phi\n$$\nThis equation describes the evolution of the deterministic, macroscopic concentration.\n\nTo find the diffusion coefficient, we examine the terms of order $\\Omega^0$. This requires a more careful expansion of the RHS.\n$$\nRHS = \\sum_j \\left(E_X^{-S_j} - 1\\right)[a_j(X) P(X, t)]\n$$\nThe full equation, after dividing by $\\Omega^{-1/2}$, is:\n$$\n\\frac{\\partial \\Pi}{\\partial t} - \\Omega \\frac{d\\phi}{dt}\\frac{\\partial \\Pi}{\\partial \\xi} = \\sum_j \\left[ a_j(X-S_j)\\Pi(\\xi-S_j\\Omega^{-1/2},t) - a_j(X)\\Pi(\\xi,t) \\right]\n$$\nExpanding the RHS to the next order and matching with the $\\Omega^0$ term on the LHS gives the linear Fokker-Planck equation. A general result from the van Kampen expansion is that the resulting Fokker-Planck equation for $\\xi$ is:\n$$\n\\frac{\\partial \\Pi}{\\partial t} = -J(\\phi) \\frac{\\partial}{\\partial \\xi}(\\xi \\Pi) + \\frac{1}{2} D(\\phi) \\frac{\\partial^2 \\Pi}{\\partial \\xi^2}\n$$\nwhere $J(\\phi)$ is related to the Jacobian of the macroscopic system and $D(\\phi)$ is the diffusion coefficient. The diffusion coefficient is given by the general formula:\n$$\nD(\\phi) = \\sum_j S_j^2 F_j(\\phi)\n$$\nUsing the stoichiometry vectors and macroscopic rates for our system:\n$S_+ = +1$, $F_+(\\phi) = \\alpha$\n$S_- = -1$, $F_-(\\phi) = k\\phi$\nWe can compute $D(\\phi)$:\n$$\nD(\\phi) = S_+^2 F_+(\\phi) + S_-^2 F_-(\\phi) = (+1)^2 (\\alpha) + (-1)^2 (k\\phi)\n$$\n$$\nD(\\phi) = \\alpha + k\\phi\n$$\nThis is the explicit expression for the diffusion coefficient in the LNA.\n\nThe problem also asks for an interpretation of the contributions from the birth and death reactions. The diffusion term in the Fokker-Planck equation, $\\frac{1}{2} D(\\phi) \\frac{\\partial^2 \\Pi}{\\partial \\xi^2}$, governs the rate of increase of the variance of the fluctuations. The rate of change of the variance of $\\xi$, denoted $V_\\xi = \\langle \\xi^2 \\rangle - \\langle \\xi \\rangle^2$, is given by $\\frac{dV_\\xi}{dt} = -2J(\\phi) V_\\xi + D(\\phi)$. The term $D(\\phi)$ represents the instantaneous growth rate of the variance of $\\xi$ due to the stochastic nature of the reactions.\n\nThe variance of the molecular count $X$ is $\\text{Var}(X) = \\Omega V_\\xi$. The instantaneous growth of this variance due to stochastic events is $\\Omega D(\\phi)$:\n$$\n\\text{Growth rate of Var}(X) = \\Omega D(\\phi) = \\Omega(\\alpha + k\\phi) = \\alpha\\Omega + k\\Omega\\phi\n$$\nWe can recognize the terms on the right-hand side:\n- $\\alpha\\Omega = a_+(\\Omega\\phi)$ is the macroscopic propensity of the birth reaction.\n- $k\\Omega\\phi = a_-(\\Omega\\phi)$ is the macroscopic propensity of the death reaction.\n\nThe instantaneous growth of variance for a set of random events is given by $\\sum_j (\\Delta X_j)^2 \\times (\\text{rate}_j)$, where $\\Delta X_j$ is the change in state and $\\text{rate}_j$ is the frequency of the event. For chemical reactions, this corresponds to $\\sum_j S_j^2 a_j(X)$. Evaluated at the macroscopic level, this is $\\sum_j S_j^2 a_j(\\Omega\\phi)$.\n- Birth reaction contribution: $S_+^2 a_+(\\Omega\\phi) = (+1)^2 (\\alpha\\Omega) = \\alpha\\Omega$.\n- Death reaction contribution: $S_-^2 a_-(\\Omega\\phi) = (-1)^2 (k\\Omega\\phi) = k\\Omega\\phi$.\nThe total variance growth rate for the particle number $X$ is the sum of these contributions, $\\alpha\\Omega + k\\Omega\\phi$. The diffusion coefficient $D(\\phi)$ for the concentration fluctuation $\\xi$ is this total variance growth rate scaled by the system size $\\Omega$.\nTherefore, the term $\\alpha$ in $D(\\phi)$ is the scaled contribution from the birth reaction, and the term $k\\phi$ is the scaled contribution from the death reaction. The birth reaction provides a constant noise source, while the noise from the death reaction is proportional to the concentration.", "answer": "$$\n\\boxed{\\alpha + k\\phi}\n$$", "id": "3323858"}, {"introduction": "Having established the basics, we now apply the LNA framework to a cornerstone of molecular biology: the two-stage model of gene expression. This practice requires you to employ the full matrix formalism of the LNA, including the stoichiometry matrix, the Jacobian of the deterministic system, and the diffusion matrix. By solving the resulting Lyapunov equation, you will calculate the noise characteristics of a multi-component system, a practical and essential skill for analyzing real biological networks. [@problem_id:3323872]", "problem": "Consider a well-mixed single-cell gene expression system with two chemical species, messenger RNA $\\mathrm{mRNA}$ and protein $\\mathrm{Protein}$, undergoing the following elementary reactions with mass-action kinetics: transcription $\\emptyset \\xrightarrow{k_m} \\mathrm{mRNA}$, translation $\\mathrm{mRNA} \\xrightarrow{k_p} \\mathrm{mRNA}+ \\mathrm{Protein}$, and first-order degradations $\\mathrm{mRNA}\\xrightarrow{\\gamma_m}\\emptyset$, $\\mathrm{Protein}\\xrightarrow{\\gamma_p}\\emptyset$. Let the state vector be $\\phi(t) = (m(t), p(t))^{\\top}$, where $m(t)$ and $p(t)$ denote the deterministic concentrations or copy-number means scaled to a fixed system size. Using the standard definitions of the stoichiometry matrix $S$ and the macroscopic rate function $f(\\phi) = S\\,a(\\phi)$ with mass-action propensities $a(\\phi)$, construct $S$ and the Jacobian $A(\\phi^{\\ast}) = \\left.\\frac{\\partial f}{\\partial \\phi}\\right|_{\\phi=\\phi^{\\ast}}$ evaluated at the deterministic steady state $\\phi^{\\ast}$. Then, invoking the Linear Noise Approximation (LNA), determine the stationary variance of protein copy-number fluctuations, i.e., the $(2,2)$-entry of the steady-state covariance matrix of fluctuations around $\\phi^{\\ast}$. Express your final answer as a single closed-form analytic expression in terms of $k_m$, $k_p$, $\\gamma_m$, and $\\gamma_p$. Do not include any units. No numerical evaluation is required.", "solution": "The problem is a standard, well-posed exercise in computational systems biology. All necessary information is provided, the model is physically and mathematically sound, and the objective is clearly defined. The problem is valid.\n\nThe system consists of two species, $\\mathrm{mRNA}$ and $\\mathrm{Protein}$, with concentrations or mean copy numbers denoted by the state vector $\\phi(t) = (m(t), p(t))^{\\top}$. The four elementary reactions are:\n1. Transcription: $\\emptyset \\xrightarrow{k_m} \\mathrm{mRNA}$\n2. Translation: $\\mathrm{mRNA} \\xrightarrow{k_p} \\mathrm{mRNA}+ \\mathrm{Protein}$\n3. mRNA degradation: $\\mathrm{mRNA}\\xrightarrow{\\gamma_m}\\emptyset$\n4. Protein degradation: $\\mathrm{Protein}\\xrightarrow{\\gamma_p}\\emptyset$\n\nFirst, we construct the stoichiometry matrix $S$, which describes the net change in species copy numbers for each reaction. With species ordered as $(m, p)$ and reactions as $(1, 2, 3, 4)$, the net changes are:\n$R_1: \\Delta m=1, \\Delta p=0$\n$R_2: \\Delta m=0, \\Delta p=1$\n$R_3: \\Delta m=-1, \\Delta p=0$\n$R_4: \\Delta m=0, \\Delta p=-1$\nThe stoichiometry matrix $S$ is a $2 \\times 4$ matrix:\n$$S = \\begin{pmatrix} 1 & 0 & -1 & 0 \\\\ 0 & 1 & 0 & -1 \\end{pmatrix}$$\nThe propensity vector $a(\\phi)$ contains the rates for each reaction, which follow mass-action kinetics:\n$$a(\\phi) = \\begin{pmatrix} k_m \\\\ k_p m \\\\ \\gamma_m m \\\\ \\gamma_p p \\end{pmatrix}$$\nThe macroscopic rate equation is given by $\\frac{d\\phi}{dt} = f(\\phi) = S a(\\phi)$:\n$$\\frac{d\\phi}{dt} = \\begin{pmatrix} \\frac{dm}{dt} \\\\ \\frac{dp}{dt} \\end{pmatrix} = \\begin{pmatrix} 1 & 0 & -1 & 0 \\\\ 0 & 1 & 0 & -1 \\end{pmatrix} \\begin{pmatrix} k_m \\\\ k_p m \\\\ \\gamma_m m \\\\ \\gamma_p p \\end{pmatrix} = \\begin{pmatrix} k_m - \\gamma_m m \\\\ k_p m - \\gamma_p p \\end{pmatrix}$$\nTo find the deterministic steady state $\\phi^{\\ast} = (m^{\\ast}, p^{\\ast})^{\\top}$, we set $\\frac{d\\phi}{dt} = 0$:\n$$k_m - \\gamma_m m^{\\ast} = 0 \\implies m^{\\ast} = \\frac{k_m}{\\gamma_m}$$\n$$k_p m^{\\ast} - \\gamma_p p^{\\ast} = 0 \\implies p^{\\ast} = \\frac{k_p m^{\\ast}}{\\gamma_p} = \\frac{k_p}{\\gamma_p} \\left(\\frac{k_m}{\\gamma_m}\\right) = \\frac{k_m k_p}{\\gamma_m \\gamma_p}$$\nNext, we compute the Jacobian matrix $A = \\frac{\\partial f}{\\partial \\phi}$ evaluated at the steady state $\\phi^{\\ast}$:\n$$A = \\left.\\begin{pmatrix} \\frac{\\partial}{\\partial m}(k_m - \\gamma_m m) & \\frac{\\partial}{\\partial p}(k_m - \\gamma_m m) \\\\ \\frac{\\partial}{\\partial m}(k_p m - \\gamma_p p) & \\frac{\\partial}{\\partial p}(k_p m - \\gamma_p p) \\end{pmatrix}\\right|_{\\phi=\\phi^{\\ast}} = \\begin{pmatrix} -\\gamma_m & 0 \\\\ k_p & -\\gamma_p \\end{pmatrix}$$\nThe Jacobian is independent of the state $\\phi$, so $A(\\phi^{\\ast}) = A$.\n\nThe Linear Noise Approximation (LNA) models the dynamics of the covariance matrix of fluctuations, $C(t)$, via the Lyapunov equation: $\\frac{dC}{dt} = A C + C A^{\\top} + E$. At steady state, $\\frac{dC}{dt}=0$, so the steady-state covariance matrix $C_{ss}$ satisfies:\n$$A C_{ss} + C_{ss} A^{\\top} = -E$$\nThe diffusion matrix $E$ is defined as $E = S \\text{diag}(a(\\phi^{\\ast})) S^{\\top}$. First, we evaluate the propensities at steady state:\n$$a(\\phi^{\\ast}) = \\begin{pmatrix} k_m \\\\ k_p m^{\\ast} \\\\ \\gamma_m m^{\\ast} \\\\ \\gamma_p p^{\\ast} \\end{pmatrix} = \\begin{pmatrix} k_m \\\\ k_p \\frac{k_m}{\\gamma_m} \\\\ \\gamma_m \\frac{k_m}{\\gamma_m} \\\\ \\gamma_p \\frac{k_m k_p}{\\gamma_m \\gamma_p} \\end{pmatrix} = \\begin{pmatrix} k_m \\\\ \\frac{k_m k_p}{\\gamma_m} \\\\ k_m \\\\ \\frac{k_m k_p}{\\gamma_m} \\end{pmatrix}$$\nNow we compute $E$:\n$$E = \\begin{pmatrix} 1 & 0 & -1 & 0 \\\\ 0 & 1 & 0 & -1 \\end{pmatrix} \\begin{pmatrix} k_m & 0 & 0 & 0 \\\\ 0 & \\frac{k_m k_p}{\\gamma_m} & 0 & 0 \\\\ 0 & 0 & k_m & 0 \\\\ 0 & 0 & 0 & \\frac{k_m k_p}{\\gamma_m} \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\\\ -1 & 0 \\\\ 0 & -1 \\end{pmatrix}$$\n$$E = \\begin{pmatrix} k_m & 0 & -k_m & 0 \\\\ 0 & \\frac{k_m k_p}{\\gamma_m} & 0 & -\\frac{k_m k_p}{\\gamma_m} \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\\\ -1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 2k_m & 0 \\\\ 0 & \\frac{2k_m k_p}{\\gamma_m} \\end{pmatrix}$$\nLet $C_{ss} = \\begin{pmatrix} C_{11} & C_{12} \\\\ C_{21} & C_{22} \\end{pmatrix}$, where $C_{12} = C_{21}$. The Lyapunov equation becomes:\n$$\\begin{pmatrix} -\\gamma_m & 0 \\\\ k_p & -\\gamma_p \\end{pmatrix} \\begin{pmatrix} C_{11} & C_{12} \\\\ C_{12} & C_{22} \\end{pmatrix} + \\begin{pmatrix} C_{11} & C_{12} \\\\ C_{12} & C_{22} \\end{pmatrix} \\begin{pmatrix} -\\gamma_m & k_p \\\\ 0 & -\\gamma_p \\end{pmatrix} = \\begin{pmatrix} -2k_m & 0 \\\\ 0 & -\\frac{2k_m k_p}{\\gamma_m} \\end{pmatrix}$$\nPerforming the matrix multiplication gives:\n$$\\begin{pmatrix} -2\\gamma_m C_{11} & k_p C_{11} - \\gamma_m C_{12} - \\gamma_p C_{12} \\\\ k_p C_{11} - \\gamma_m C_{12} - \\gamma_p C_{12} & 2k_p C_{12} - 2\\gamma_p C_{22} \\end{pmatrix} = \\begin{pmatrix} -2k_m & 0 \\\\ 0 & -\\frac{2k_m k_p}{\\gamma_m} \\end{pmatrix}$$\nThis yields a system of three linear equations:\n1.  $-2\\gamma_m C_{11} = -2k_m \\implies C_{11} = \\frac{k_m}{\\gamma_m}$\n2.  $k_p C_{11} - (\\gamma_m + \\gamma_p)C_{12} = 0 \\implies C_{12} = \\frac{k_p C_{11}}{\\gamma_m + \\gamma_p} = \\frac{k_p (k_m/\\gamma_m)}{\\gamma_m + \\gamma_p} = \\frac{k_m k_p}{\\gamma_m(\\gamma_m + \\gamma_p)}$\n3.  $2k_p C_{12} - 2\\gamma_p C_{22} = -\\frac{2k_m k_p}{\\gamma_m} \\implies \\gamma_p C_{22} = k_p C_{12} + \\frac{k_m k_p}{\\gamma_m}$\n\nWe want to find $C_{22}$, the $(2,2)$-entry of the covariance matrix, which represents the variance of protein copy-number fluctuations. From equation $(3)$:\n$$C_{22} = \\frac{k_p}{\\gamma_p} C_{12} + \\frac{k_m k_p}{\\gamma_m \\gamma_p}$$\nSubstituting the expression for $C_{12}$ from equation $(2)$:\n$$C_{22} = \\frac{k_p}{\\gamma_p} \\left( \\frac{k_m k_p}{\\gamma_m(\\gamma_m + \\gamma_p)} \\right) + \\frac{k_m k_p}{\\gamma_m \\gamma_p}$$\n$$C_{22} = \\frac{k_m k_p^2}{\\gamma_m \\gamma_p (\\gamma_m + \\gamma_p)} + \\frac{k_m k_p}{\\gamma_m \\gamma_p}$$\nTo combine the terms, we find a common denominator:\n$$C_{22} = \\frac{k_m k_p^2}{\\gamma_m \\gamma_p (\\gamma_m + \\gamma_p)} + \\frac{k_m k_p (\\gamma_m + \\gamma_p)}{\\gamma_m \\gamma_p (\\gamma_m + \\gamma_p)}$$\n$$C_{22} = \\frac{k_m k_p^2 + k_m k_p \\gamma_m + k_m k_p \\gamma_p}{\\gamma_m \\gamma_p (\\gamma_m + \\gamma_p)}$$\nFactoring out $k_m k_p$ from the numerator gives the final expression:\n$$C_{22} = \\frac{k_m k_p (\\gamma_m + \\gamma_p + k_p)}{\\gamma_m \\gamma_p (\\gamma_m + \\gamma_p)}$$\nThis expression represents the stationary variance of protein copy-number fluctuations.", "answer": "$$\\boxed{\\frac{k_m k_p (\\gamma_m + \\gamma_p + k_p)}{\\gamma_m \\gamma_p (\\gamma_m + \\gamma_p)}}$$", "id": "3323872"}, {"introduction": "The LNA is a powerful tool, but it is one of several approximation methods used in stochastic modeling. This final practice encourages a critical comparison between the LNA and the family of moment closure approximations (MCAs) for a simple nonlinear system. By deriving the exact but unclosed moment equations, you will uncover the \"moment closure problem\" and appreciate the fundamentally different strategies that LNA and MCAs use to create a tractable system of equations, providing a deeper understanding of their respective assumptions and limitations. [@problem_id:3323813]", "problem": "Consider the single-species birth–annihilation network under mass-action kinetics in a well-mixed volume $\\,\\Omega\\,$:\n- $\\varnothing \\xrightarrow{k_1\\,\\Omega} X$ (zeroth-order birth),\n- $2X \\xrightarrow{k_2/\\Omega} \\varnothing$ (bimolecular annihilation),\nwhere $k_1$ and $k_2$ are positive constants, and the factor of $1/\\Omega$ in the bimolecular propensity ensures a consistent thermodynamic limit. Let $X(t)$ denote the molecule count of $X$ at time $t$.\n\nTask 1. Starting from the Chemical Master Equation (CME), derive the exact time-evolution equations for the first moment $\\mu(t) = \\mathbb{E}[X(t)]$ and the second moment $m_2(t) = \\mathbb{E}[X(t)^2]$. Identify any terms that render the second-moment dynamics unclosed.\n\nTask 2. Using the van Kampen system-size expansion and the Linear Noise Approximation (LNA), derive:\n- the deterministic macroscopic drift for the concentration $\\phi(t) = \\mu(t)/\\Omega$,\n- and the linear covariance dynamics for the concentration fluctuations (denoted by $\\Sigma_c(t)$), explicitly in terms of the Jacobian of the macroscopic drift and a diffusion matrix constructed from the stoichiometry and macroscopic reaction rates.\n\nTask 3. Based on your derivations, select the statement that most accurately characterizes where and why moment closure approximations (e.g., normal/Gaussian or log-normal closures) introduce bias relative to the LNA when estimating covariances in bimolecular systems like the one above.\n\nOptions:\nA. For the birth–annihilation network, the exact second-moment dynamics contain a contribution proportional to $\\mathbb{E}[X^3]$. The LNA yields the covariance by solving a Lyapunov equation that depends only on the Jacobian of the macroscopic drift and a diffusion matrix evaluated at the macroscopic mean, thereby avoiding any closure of $\\mathbb{E}[X^3]$. Normal (Gaussian) and log-normal closures introduce bias relative to the LNA precisely by replacing $\\mathbb{E}[X^3]$ (and, in multivariate systems, mixed third moments) with functions of the mean and covariance; the sign and magnitude of the bias depend on the skewness and the curvature of the propensities, and vanish only for linear (at most unimolecular) networks.\n\nB. In bimolecular mass-action systems, the LNA already assumes a Gaussian state distribution and hence enforces $\\mathbb{E}[X^3] = \\mu^3 + 3\\mu\\,\\mathrm{Var}(X)$; therefore Gaussian closure is unbiased by construction with respect to the LNA.\n\nC. Any bias introduced by moment closures relative to the LNA originates from the diffusion term only, because the drift contribution to $\\mathrm{d}\\Sigma/\\mathrm{d}t$ depends on stoichiometry alone and is therefore identical under different closures.\n\nD. For the birth–annihilation network at stationarity and large system size, the Gaussian and log-normal closures both converge to the LNA covariance, and for finite size they necessarily overestimate the covariance relative to the LNA, regardless of parameter values.", "solution": "The problem statement is valid. It presents a standard, well-defined problem in stochastic chemical kinetics that is scientifically grounded, objective, and contains all necessary information for a rigorous mathematical analysis.\n\n### Task 1: Exact Moment Dynamics\n\nFirst, we define the stochastic model. The system involves one species, $X$, and two reactions:\n1.  **Birth**: $\\varnothing \\xrightarrow{k_1\\,\\Omega} X$. This is a zeroth-order reaction. The number of molecules of $X$, denoted by $n$, changes by $S_1 = +1$. The propensity function is $w_1(n) = k_1\\Omega$.\n2.  **Annihilation**: $2X \\xrightarrow{k_2/\\Omega} \\varnothing$. This is a bimolecular reaction. The number of molecules changes by $S_2 = -2$. The standard mass-action propensity for this reaction, using the notation conventional in chemical physics that leads to the deterministic rate equation $\\frac{d\\phi}{dt} = k_1 - k_2\\phi^2$ where $\\phi$ is the concentration, is $w_2(n) = \\frac{k_2}{2\\Omega}n(n-1)$. Here, $n(n-1)/2$ is the number of distinct pairs of $X$ molecules, and $k_2/\\Omega$ is the rate constant per pair.\n\nThe time evolution of the expectation of any function of the state, $f(n)$, is given by the master equation:\n$$ \\frac{d\\mathbb{E}[f(X)]}{dt} = \\sum_{j=1}^{2} \\mathbb{E}[w_j(X) (f(X+S_j) - f(X))] $$\n\n**First Moment Dynamics ($\\mu(t) = \\mathbb{E}[X(t)]$)**\nLet $f(X) = n$.\n$$ \\frac{d\\mu}{dt} = \\mathbb{E}[w_1(n)((n+1)-n) + w_2(n)((n-2)-n)] $$\n$$ \\frac{d\\mu}{dt} = \\mathbb{E}[w_1(n) \\cdot (+1) + w_2(n) \\cdot (-2)] $$\nSubstituting the propensities:\n$$ \\frac{d\\mu}{dt} = \\mathbb{E}\\left[k_1\\Omega - 2 \\cdot \\frac{k_2}{2\\Omega} n(n-1)\\right] = k_1\\Omega - \\frac{k_2}{\\Omega}\\mathbb{E}[n^2 - n] $$\nUsing the definitions $\\mu = \\mathbb{E}[n]$ and $m_2 = \\mathbb{E}[n^2]$:\n$$ \\frac{d\\mu}{dt} = k_1\\Omega - \\frac{k_2}{\\Omega}(m_2 - \\mu) $$\nThis equation for the first moment is not closed, as it depends on the second moment $m_2$.\n\n**Second Moment Dynamics ($m_2(t) = \\mathbb{E}[X(t)^2]$)**\nLet $f(X) = n^2$.\n$$ \\frac{dm_2}{dt} = \\mathbb{E}[w_1(n)((n+1)^2-n^2) + w_2(n)((n-2)^2-n^2)] $$\n$$ \\frac{dm_2}{dt} = \\mathbb{E}[w_1(n)(2n+1) + w_2(n)(-4n+4)] $$\nSubstituting the propensities:\n$$ \\frac{dm_2}{dt} = \\mathbb{E}\\left[k_1\\Omega(2n+1) + \\frac{k_2}{2\\Omega}n(n-1)(-4(n-1))\\right] $$\n$$ \\frac{dm_2}{dt} = \\mathbb{E}\\left[2k_1\\Omega n + k_1\\Omega - \\frac{2k_2}{\\Omega}n(n-1)^2\\right] $$\nTaking the expectation:\n$$ \\frac{dm_2}{dt} = 2k_1\\Omega\\mu + k_1\\Omega - \\frac{2k_2}{\\Omega}\\mathbb{E}[n(n^2-2n+1)] $$\n$$ \\frac{dm_2}{dt} = 2k_1\\Omega\\mu + k_1\\Omega - \\frac{2k_2}{\\Omega}(\\mathbb{E}[n^3] - 2\\mathbb{E}[n^2] + \\mathbb{E}[n]) $$\nUsing the moment definitions, including $m_3 = \\mathbb{E}[n^3]$:\n$$ \\frac{dm_2}{dt} = 2k_1\\Omega\\mu + k_1\\Omega - \\frac{2k_2}{\\Omega}(m_3 - 2m_2 + \\mu) $$\nThis equation for the second moment is not closed. The term that renders it unclosed is the one originating from the bimolecular annihilation reaction, which introduces a dependency on the third moment, $m_3 = \\mathbb{E}[X^3]$.\n\n### Task 2: Linear Noise Approximation (LNA)\n\nThe LNA is derived from the van Kampen system-size expansion, where the particle count $n(t)$ is decomposed into a macroscopic part and fluctuations:\n$$ n(t) = \\Omega\\phi(t) + \\sqrt{\\Omega}\\xi(t) $$\nwhere $\\phi(t)$ is the macroscopic concentration and $\\xi(t)$ represents fluctuations, with $\\mathbb{E}[\\xi(t)]=0$.\n\n**Macroscopic Drift for Concentration $\\phi(t)$**\nThe macroscopic rate equation is obtained from the leading-order terms of the propensities evaluated at the macroscopic limit, $n \\approx \\Omega\\phi$:\n$$ \\frac{d\\phi}{dt} = \\sum_{j=1}^{2} S_j \\frac{w_j(\\Omega\\phi)}{\\Omega} $$\nThe macroscopic propensities are:\n$w_1(\\Omega\\phi) = k_1\\Omega$\n$w_2(\\Omega\\phi) = \\frac{k_2}{2\\Omega}(\\Omega\\phi)(\\Omega\\phi-1) \\approx \\frac{k_2\\Omega}{2}\\phi^2$ for large $\\Omega$.\nThus, the macroscopic drift for $\\phi(t)$ is:\n$$ \\frac{d\\phi}{dt} = (+1)\\frac{k_1\\Omega}{\\Omega} + (-2)\\frac{k_2\\Omega\\phi^2/2}{\\Omega} = k_1 - k_2\\phi^2 $$\n\n**Linear Covariance Dynamics for Concentration Fluctuations $\\Sigma_c(t)$**\nThe covariance of concentration fluctuations is $\\Sigma_c(t) = \\text{Var}(n(t)/\\Omega) = \\frac{1}{\\Omega^2}\\text{Var}(n(t))$. In the LNA, its dynamics are governed by a Lyapunov equation:\n$$ \\frac{d\\Sigma_c}{dt} = J_c \\Sigma_c + \\Sigma_c J_c^T + D_c $$\nFor a single-variable system, this simplifies to $\\frac{d\\Sigma_c}{dt} = 2J_c\\Sigma_c + D_c$.\n\nThe **Jacobian**, $J_c$, is the derivative of the macroscopic drift vector field with respect to the concentration vector. Here it's a scalar:\n$$ J_c = \\frac{d}{d\\phi}(k_1 - k_2\\phi^2) = -2k_2\\phi $$\n\nThe **diffusion matrix**, $D_c$, is given by:\n$$ D_c = \\frac{1}{\\Omega^2} \\sum_{j=1}^{2} S_j S_j^T w_j(\\Omega\\phi) $$\nFor this scalar system:\n$$ D_c = \\frac{1}{\\Omega^2} \\left( S_1^2 w_1(\\Omega\\phi) + S_2^2 w_2(\\Omega\\phi) \\right) $$\n$$ D_c = \\frac{1}{\\Omega^2} \\left( (+1)^2 (k_1\\Omega) + (-2)^2 \\left(\\frac{k_2\\Omega}{2}\\phi^2\\right) \\right) $$\n$$ D_c = \\frac{1}{\\Omega^2} (k_1\\Omega + 2k_2\\Omega\\phi^2) = \\frac{k_1 + 2k_2\\phi^2}{\\Omega} $$\n\nCombining these, the linear covariance dynamics for $\\Sigma_c(t)$ are:\n$$ \\frac{d\\Sigma_c}{dt} = 2(-2k_2\\phi)\\Sigma_c + \\frac{k_1 + 2k_2\\phi^2}{\\Omega} $$\n$$ \\frac{d\\Sigma_c}{dt} = -4k_2\\phi\\Sigma_c + \\frac{k_1 + 2k_2\\phi^2}{\\Omega} $$\nHere, $\\phi(t)$ is the solution to the deterministic macroscopic drift equation. Note that the LNA provides a closed set of equations for the mean and variance, where the mean dynamics are independent of the variance.\n\n### Task 3: Comparison of Moment Closure and LNA\n\nThis task requires us to characterize the source of bias in moment closure approximations (MCAs) relative to the LNA. Our derivations provide the necessary foundation.\n\n**A. Correct.** This statement accurately describes the core differences.\n1.  \"...the exact second-moment dynamics contain a contribution proportional to $\\mathbb{E}[X^3]$.\" Our derivation in Task 1 shows precisely this, with the term $-\\frac{2k_2}{\\Omega}m_3$ in the equation for $\\frac{dm_2}{dt}$.\n2.  \"The LNA yields the covariance by solving a Lyapunov equation that depends only on the Jacobian... and a diffusion matrix..., thereby avoiding any closure of $\\mathbb{E}[X^3]$.\" Our derivation in Task 2 confirms this. The LNA produces a closed system for the first two moments by linearizing the process dynamics around the deterministic mean, a procedure that does not involve or require any information about third or higher moments of the exact distribution.\n3.  \"Normal (Gaussian) and log-normal closures introduce bias relative to the LNA precisely by replacing $\\mathbb{E}[X^3]$... with functions of the mean and covariance\". This is the definition of a moment closure approximation. To solve the unclosed hierarchy from Task 1, MCAs must postulate a relationship between the unclosed moment (e.g., $m_3$) and lower-order moments (e.g., $\\mu, m_2$). For example, a Gaussian closure assumes the third central moment is zero, which implies $m_3 = 3\\mu m_2 - 2\\mu^3$. This explicit approximation is fundamentally different from the LNA's approach.\n4.  \"...the sign and magnitude of the bias depend on the skewness and the curvature of the propensities, and vanish only for linear (at most unimolecular) networks.\" This is a correct and profound summary. The bias of an MCA (like Gaussian closure) is related to how much the true distribution's skewness deviates from the assumed value (zero). The error in the LNA is related to the magnitude of the nonlinear terms (curvature) in the propensity functions that are truncated in the expansion. For systems with only linear propensities (zeroth- and first-order reactions), the moment equations are already closed, the LNA is exact, and no approximations are needed.\n\n**B. Incorrect.** This option incorrectly claims the LNA assumes a Gaussian state distribution. The LNA is a systematic expansion in powers of $\\Omega^{-1/2}$. A Gaussian process emerges as the leading-order approximation for the fluctuations, but this is a result, not a starting assumption about the state variable $X$. More importantly, the LNA is not equivalent to Gaussian closure for nonlinear systems. The dynamics derived from Gaussian closure are different from those of the LNA. For instance, the Gaussian closure dynamics for the mean concentration, $\\phi = \\mu/\\Omega$, would be $\\frac{d\\phi}{dt} = k_1 - k_2(\\Sigma_c + \\phi^2 - \\phi/\\Omega)$, which depends on the variance $\\Sigma_c$ and differs from the LNA's deterministic mean dynamics $\\frac{d\\phi}{dt} = k_1-k_2\\phi^2$.\n\n**C. Incorrect.** This statement claims bias originates only from the diffusion term. This is false. The drift contribution to the covariance dynamics, given by $J_c\\Sigma_c + \\Sigma_c J_c^T$, also differs. The Jacobian $J_c$ in the LNA is evaluated along the deterministic trajectory $\\phi(t)$. In MCAs, the drift term in the resulting covariance equation is a more complex function that depends on the coupled evolution of the mean and covariance. For example, in the Gaussian closure case, the effective \"Jacobian\" would depend on the moments themselves, not just a pre-computed deterministic path. Therefore, both drift and diffusion contributions differ between the approximation schemes.\n\n**D. Incorrect.** While it is true that at the large system size limit ($\\Omega \\to \\infty$), valid MCAs and the LNA typically converge to the same result, the second claim is false. It states that for finite size, MCAs \"necessarily overestimate the covariance relative to the LNA, regardless of parameter values.\" This is an overly strong and incorrect generalization. The performance of moment closures is highly system- and parameter-dependent. For certain systems and parameter regimes, the Gaussian closure is known to be unstable and can even predict unphysical negative variances. It can also underestimate the true variance. There is no universal rule that MCAs always overestimate the variance compared to the LNA.\n\nIn summary, option A provides the most accurate and comprehensive explanation of the fundamental differences between the LNA and moment closure approximations as applied to this system. The bias arises because they are different approximation schemes that handle the unclosed moment hierarchy in fundamentally different ways: LNA by linearizing the stochastic process, and MCA by approximating higher moments directly in the exact moment equations.", "answer": "$$\\boxed{A}$$", "id": "3323813"}]}