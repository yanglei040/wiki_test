{"hands_on_practices": [{"introduction": "Understanding the connection between stochastic and deterministic models is the cornerstone of designing hybrid simulation strategies. This foundational exercise guides you through an analytical derivation of the mean and variance for a simple linear birth-death process, a building block for many biological models. By comparing the evolution of the stochastic mean $\\mathbb{E}[X(t)]$ to its deterministic counterpart, you will uncover the conditions under which the macroscopic rate equations perfectly capture the average behavior of the system, providing a key insight into the validity of deterministic approximations [@problem_id:3319363].", "problem": "Consider a well-mixed, single-species system in a fixed volume where molecules of species $X$ are produced by a zero-order source and removed by first-order decay. In the stochastic description as a continuous-time Markov jump process, the two reactions are $X \\xrightarrow{k_b} X+1$ with propensity $a_b(x) = k_b$ and $X \\xrightarrow{k_d} \\emptyset$ with propensity $a_d(x) = k_d x$, where $k_b > 0$ and $k_d > 0$ are constants and $x$ denotes the current molecular count. Assume the initial condition $X(0) = x_0$ is a known nonnegative integer.\n\nStarting from the chemical master equation framework and the generator identity for moments of Markov jump processes, derive the time evolution equations for the first two moments $\\mathbb{E}[X(t)]$ and $\\mathbb{E}[X(t)^2]$. Solve these equations to obtain explicit closed-form expressions for $\\mathbb{E}[X(t)]$ and $\\mathrm{Var}[X(t)]$ under the Stochastic Simulation Algorithm (SSA). Then, compare $\\mathbb{E}[X(t)]$ to the solution $c(t)$ of the deterministic ordinary differential equation $\\dot{c}(t) = k_b - k_d c(t)$ with $c(0) = x_0$.\n\nExpress your final answer as the ordered pair $\\left(\\mathbb{E}[X(t)], \\mathrm{Var}[X(t)]\\right)$ in a single row matrix. No rounding is required, and no units should be included in the final expressions.", "solution": "The problem is first validated to ensure it is scientifically sound, well-posed, and complete.\n\n**Step 1: Extract Givens**\n- System: A well-mixed, single-species system in a fixed volume.\n- Species: $X$.\n- State variable: $x$, the molecular count of $X$.\n- Reaction 1 (production): $X \\xrightarrow{k_b} X+1$, with propensity $a_b(x) = k_b$.\n- Reaction 2 (decay): $X \\xrightarrow{k_d} \\emptyset$, with propensity $a_d(x) = k_d x$.\n- Constants: $k_b > 0$, $k_d > 0$.\n- Initial condition: $X(0) = x_0$, a known non-negative integer.\n- Framework: Chemical Master Equation (CME).\n- Tasks:\n  1. Derive time evolution equations for $\\mathbb{E}[X(t)]$ and $\\mathbb{E}[X(t)^2]$.\n  2. Solve for closed-form expressions for $\\mathbb{E}[X(t)]$ and $\\mathrm{Var}[X(t)]$.\n  3. Compare $\\mathbb{E}[X(t)]$ with the solution $c(t)$ of the deterministic ODE $\\dot{c}(t) = k_b - k_d c(t)$, $c(0)=x_0$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem describes a linear birth-death process, a fundamental and well-understood model in stochastic chemical kinetics. The reactions and propensities are standard representations of zero-order production and first-order decay. The notation $X \\xrightarrow{k_b} X+1$ with propensity $a_b(x) = k_b$ unambiguously defines a zero-order birth process. All parameters and initial conditions are provided, making the problem self-contained and well-posed. The tasks involve standard mathematical derivations within this framework. The problem is scientifically grounded, objective, and does not violate any of the invalidity criteria.\n\n**Step 3: Verdict and Action**\nThe problem is deemed valid. A full solution will be provided.\n\n**Derivation of Moment Equations**\n\nThe time evolution of the expectation of any function $f(X(t))$ of the state of a continuous-time Markov jump process is given by the generator identity:\n$$\n\\frac{d}{dt}\\mathbb{E}[f(X(t))] = \\mathbb{E}[\\mathcal{L}f(X(t))]\n$$\nwhere $\\mathcal{L}$ is the generator of the process. For a chemical reaction network, the generator acts on a function $f(x)$ as:\n$$\n\\mathcal{L}f(x) = \\sum_{j} a_j(x) [f(x+v_j) - f(x)]\n$$\nHere, $j$ indexes the reactions, $a_j(x)$ is the propensity of reaction $j$, and $v_j$ is the change in the state variable $x$ due to reaction $j$.\n\nFor the given system, we have two reactions:\n1.  Birth: $a_1(x) = k_b$, $v_1 = +1$.\n2.  Death: $a_2(x) = k_d x$, $v_2 = -1$.\n\nThe generator is therefore:\n$$\n\\mathcal{L}f(x) = k_b [f(x+1) - f(x)] + k_d x [f(x-1) - f(x)]\n$$\n\n**Time Evolution of the Mean, $\\mathbb{E}[X(t)]$**\n\nTo find the equation for the first moment, we set $f(x) = x$.\n$$\n\\mathcal{L}x = k_b [(x+1) - x] + k_d x [(x-1) - x] = k_b(1) + k_d x(-1) = k_b - k_d x\n$$\nApplying the generator identity and the linearity of the expectation operator:\n$$\n\\frac{d}{dt}\\mathbb{E}[X(t)] = \\mathbb{E}[\\mathcal{L}X(t)] = \\mathbb{E}[k_b - k_d X(t)] = k_b - k_d \\mathbb{E}[X(t)]\n$$\nLet $\\mu(t) = \\mathbb{E}[X(t)]$. We have the first-order linear ordinary differential equation (ODE):\n$$\n\\frac{d\\mu(t)}{dt} = k_b - k_d \\mu(t)\n$$\nwith the initial condition $\\mu(0) = \\mathbb{E}[X(0)] = x_0$.\n\n**Comparison with the Deterministic Model**\n\nThe deterministic rate equation is given as $\\dot{c}(t) = k_b - k_d c(t)$, with $c(0) = x_0$. This ODE is mathematically identical to the ODE for the mean of the stochastic process, $\\mu(t)$. Therefore, their solutions will be identical: $\\mu(t) = c(t)$. This property holds because all reaction propensities are linear functions of the state variable $x$.\n\n**Solving for the Mean, $\\mathbb{E}[X(t)]$**\n\nWe solve the ODE $\\frac{d\\mu}{dt} + k_d \\mu = k_b$. The integrating factor is $I(t) = \\exp(\\int k_d dt) = \\exp(k_d t)$.\n$$\n\\frac{d}{dt} (\\mu(t) \\exp(k_d t)) = k_b \\exp(k_d t)\n$$\nIntegrating both sides with respect to $t$:\n$$\n\\mu(t) \\exp(k_d t) = \\int k_b \\exp(k_d t) dt = \\frac{k_b}{k_d} \\exp(k_d t) + C\n$$\nwhere $C$ is the integration constant.\n$$\n\\mu(t) = \\frac{k_b}{k_d} + C \\exp(-k_d t)\n$$\nUsing the initial condition $\\mu(0) = x_0$:\n$$\nx_0 = \\frac{k_b}{k_d} + C \\implies C = x_0 - \\frac{k_b}{k_d}\n$$\nSubstituting $C$ back into the solution gives the explicit expression for the mean:\n$$\n\\mathbb{E}[X(t)] = \\frac{k_b}{k_d} + \\left(x_0 - \\frac{k_b}{k_d}\\right) \\exp(-k_d t)\n$$\n\n**Time Evolution of the Variance, $\\mathrm{Var}[X(t)]$**\n\nThe variance is defined as $\\mathrm{Var}[X(t)] = \\mathbb{E}[X(t)^2] - (\\mathbb{E}[X(t)])^2$. A more direct approach than finding $\\mathbb{E}[X(t)^2]$ first is to derive the ODE for the variance itself. Let $V(t) = \\mathrm{Var}[X(t)]$.\n$$\n\\frac{dV(t)}{dt} = \\frac{d}{dt}\\mathbb{E}[X(t)^2] - 2\\mathbb{E}[X(t)]\\frac{d}{dt}\\mathbb{E}[X(t)]\n$$\nFirst, we find the ODE for the second moment, $m_2(t) = \\mathbb{E}[X(t)^2]$, by setting $f(x)=x^2$.\n$$\n\\mathcal{L}x^2 = k_b [(x+1)^2 - x^2] + k_d x [(x-1)^2 - x^2]\n$$\n$$\n\\mathcal{L}x^2 = k_b (2x+1) + k_d x (-2x+1) = 2k_b x + k_b - 2k_d x^2 + k_d x = -2k_d x^2 + (2k_b + k_d)x + k_b\n$$\nTaking the expectation:\n$$\n\\frac{dm_2(t)}{dt} = \\mathbb{E}[\\mathcal{L}X(t)^2] = -2k_d \\mathbb{E}[X(t)^2] + (2k_b + k_d)\\mathbb{E}[X(t)] + k_b\n$$\n$$\n\\frac{dm_2(t)}{dt} = -2k_d m_2(t) + (2k_b + k_d)\\mu(t) + k_b\n$$\nNow substitute this and the ODE for $\\mu(t)$ into the derivative of the variance:\n$$\n\\frac{dV(t)}{dt} = [-2k_d m_2(t) + (2k_b + k_d)\\mu(t) + k_b] - 2\\mu(t)[k_b - k_d \\mu(t)]\n$$\n$$\n\\frac{dV(t)}{dt} = -2k_d m_2(t) + 2k_b\\mu(t) + k_d\\mu(t) + k_b - 2k_b\\mu(t) + 2k_d\\mu(t)^2\n$$\n$$\n\\frac{dV(t)}{dt} = -2k_d m_2(t) + 2k_d\\mu(t)^2 + k_d\\mu(t) + k_b\n$$\n$$\n\\frac{dV(t)}{dt} = -2k_d [m_2(t) - \\mu(t)^2] + k_d\\mu(t) + k_b\n$$\nThis simplifies to the ODE for the variance:\n$$\n\\frac{dV(t)}{dt} = -2k_d V(t) + k_d\\mu(t) + k_b\n$$\nThe initial condition is $V(0) = \\mathrm{Var}[X(0)] = \\mathrm{Var}[x_0] = 0$, since $x_0$ is a deterministic value.\n\n**Solving for the Variance, $\\mathrm{Var}[X(t)]$**\n\nWe solve the ODE $\\frac{dV}{dt} + 2k_d V = k_d\\mu(t) + k_b$ by substituting the expression for $\\mu(t)$:\n$$\n\\frac{dV}{dt} + 2k_d V = k_d\\left[\\frac{k_b}{k_d} + \\left(x_0 - \\frac{k_b}{k_d}\\right) \\exp(-k_d t)\\right] + k_b\n$$\n$$\n\\frac{dV}{dt} + 2k_d V = k_b + (k_d x_0 - k_b)\\exp(-k_d t) + k_b = 2k_b + (k_d x_0 - k_b)\\exp(-k_d t)\n$$\nThe integrating factor is $I(t) = \\exp(\\int 2k_d dt) = \\exp(2k_d t)$.\n$$\n\\frac{d}{dt}(V(t)\\exp(2k_d t)) = 2k_b \\exp(2k_d t) + (k_d x_0 - k_b)\\exp(k_d t)\n$$\nIntegrating with respect to $t$:\n$$\nV(t)\\exp(2k_d t) = \\int [2k_b \\exp(2k_d t) + (k_d x_0 - k_b)\\exp(k_d t)] dt\n$$\n$$\nV(t)\\exp(2k_d t) = 2k_b \\frac{\\exp(2k_d t)}{2k_d} + (k_d x_0 - k_b) \\frac{\\exp(k_d t)}{k_d} + C'\n$$\n$$\nV(t)\\exp(2k_d t) = \\frac{k_b}{k_d}\\exp(2k_d t) + \\left(x_0 - \\frac{k_b}{k_d}\\right)\\exp(k_d t) + C'\n$$\nDividing by $\\exp(2k_d t)$:\n$$\nV(t) = \\frac{k_b}{k_d} + \\left(x_0 - \\frac{k_b}{k_d}\\right)\\exp(-k_d t) + C'\\exp(-2k_d t)\n$$\nUsing the initial condition $V(0)=0$:\n$$\n0 = \\frac{k_b}{k_d} + \\left(x_0 - \\frac{k_b}{k_d}\\right) + C' = x_0 + C' \\implies C' = -x_0\n$$\nSubstituting $C'$ provides the final expression for the variance:\n$$\n\\mathrm{Var}[X(t)] = \\frac{k_b}{k_d} + \\left(x_0 - \\frac{k_b}{k_d}\\right)\\exp(-k_d t) - x_0\\exp(-2k_d t)\n$$\nThis expression can be rearranged to highlight the contributions from the process's intrinsic stochasticity and the relaxation from the initial state:\n$$\n\\mathrm{Var}[X(t)] = \\frac{k_b}{k_d}(1-\\exp(-k_d t)) + x_0 \\exp(-k_d t)(1 - \\exp(-k_d t))\n$$\nFactoring out $(1 - \\exp(-k_d t))$ yields a compact form:\n$$\n\\mathrm{Var}[X(t)] = \\left(\\frac{k_b}{k_d} + x_0 \\exp(-k_d t)\\right)\\left(1 - \\exp(-k_d t)\\right)\n$$\n\n**Final Expressions**\nThe mean of the process is:\n$$\n\\mathbb{E}[X(t)] = \\frac{k_b}{k_d} + \\left(x_0 - \\frac{k_b}{k_d}\\right) \\exp(-k_d t)\n$$\nThe variance of the process is:\n$$\n\\mathrm{Var}[X(t)] = \\left(\\frac{k_b}{k_d} + x_0 \\exp(-k_d t)\\right)\\left(1 - \\exp(-k_d t)\\right)\n$$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{k_b}{k_d} + \\left(x_0 - \\frac{k_b}{k_d}\\right) \\exp(-k_d t) & \\left(\\frac{k_b}{k_d} + x_0 \\exp(-k_d t)\\right)\\left(1 - \\exp(-k_d t)\\right)\n\\end{pmatrix}\n}\n$$", "id": "3319363"}, {"introduction": "While the mean behavior of linear systems may align perfectly between stochastic and deterministic models in theory, practical hybrid algorithms often introduce numerical errors. This practice delves into the analysis of such errors by focusing on a common technique known as Lie-Trotter splitting, where different parts of the system are evolved sequentially. By deriving the exact splitting error for the mean of a species in a simple cascade, you will develop the essential skill of quantifying the local accuracy of a numerical method, a critical step in assessing the reliability and performance of any custom hybrid simulator [@problem_id:3319355].", "problem": "Consider the linear reaction network in computational systems biology\n$$A \\xrightarrow{k_{1}} B \\xrightarrow{k_{2}} \\emptyset$$,\nwhere $A$ is treated deterministically and $B$ is treated stochastically. Let $t \\geq 0$ be a reference time and denote the initial molecular counts by $A(t)=a$ and $B(t)=b$, with $a \\geq 0$ and $b \\geq 0$. The deterministic species $A$ evolves according to the ordinary differential equation (ODE)\n$$\n\\frac{dA}{dt} = -k_{1} A,\n$$\nand the stochastic species $B$ is modeled as a Continuous-Time Markov Chain (CTMC) governed by the Chemical Master Equation (CME) with time-dependent birth propensity $k_{1} A(t)$ and linear death propensity $k_{2} B(t)$. Assume $k_{1} > 0$, $k_{2} > 0$, and $k_{1} \\neq k_{2}$.\n\nA hybrid Lie–Trotter splitting step of size $h>0$ is defined as follows: first evolve $A$ deterministically for a duration $h$ to obtain $\\tilde{A} = a \\exp(-k_{1} h)$; then, holding $A$ fixed at $\\tilde{A}$ for the duration of the stochastic substep, evolve $B$ stochastically over the same duration $h$ as a linear birth–death process with constant birth rate $k_{1} \\tilde{A}$ and linear death rate $k_{2} B$.\n\nStarting from the fundamental laws and core definitions above (ODE dynamics for $A$ and CME-driven mean dynamics for $B$), derive:\n\n1. The exact mean of $B$ at time $t+h$, denoted $\\mathbb{E}[B(t+h)]$, under the fully coupled hybrid model where $A(t+s) = a \\exp(-k_{1} s)$ drives the birth process of $B$ for $s \\in [0,h]$.\n2. The split-step mean of $B$ at time $t+h$, denoted $\\mathbb{E}_{\\mathrm{split}}[B(t+h)]$, produced by the Lie–Trotter hybrid step described above.\n3. The splitting error in the mean over one step $h$, defined as\n$$\nE(h) = \\mathbb{E}_{\\mathrm{split}}[B(t+h)] - \\mathbb{E}[B(t+h)].\n$$\n\nThen, using a series expansion in $h$ derived from first principles and without invoking any shortcut formulas, verify the predicted local order of accuracy of the Lie–Trotter splitting for the mean of $B$ by explicitly identifying the lowest nonzero power of $h$ in $E(h)$. Your final answer must be the closed-form analytic expression for $E(h)$, simplified as far as possible. No rounding is required, and no physical units should be included in the final expression.", "solution": "The problem statement has been validated and is deemed valid. It is scientifically grounded in the principles of computational systems biology, well-posed with a complete and consistent set of definitions and constraints, mathematically formalizable, and objective. We may therefore proceed with the solution.\n\nThe problem asks for the derivation of the exact mean evolution of species $B$, the mean evolution under a Lie-Trotter splitting scheme, and the resulting single-step error. The analysis will be performed over a time interval of duration $h$, from a reference time $t$ to $t+h$. Let $s$ be the time elapsed since $t$, so $s \\in [0,h]$. The initial conditions at $s=0$ (time $t$) are $A(0)=a$ and $B(0)=b$.\n\nFirst, we establish the governing equation for the mean of the stochastic species $B$. The number of molecules of $B$, denoted by the random variable $B(t+s)$, changes due to two reactions: a birth reaction $A \\to B$ and a death reaction $B \\to \\emptyset$. The time evolution of the mean $\\mu_B(s) = \\mathbb{E}[B(t+s)]$ is given by the sum of the expected rates of change. The change for the birth reaction is $+1$ with propensity $k_1 A(t+s)$, and for the death reaction is $-1$ with propensity $k_2 B(t+s)$. The exact ODE for the mean is therefore:\n$$\n\\frac{d\\mu_B}{ds} = (+1) \\mathbb{E}[k_1 A(t+s)] + (-1) \\mathbb{E}[k_2 B(t+s)]\n$$\nSince $A$ is a deterministic species, $\\mathbb{E}[k_1 A(t+s)] = k_1 A(t+s)$. Since the death propensity is linear in $B$, the expectation operator commutes with the propensity function, i.e., $\\mathbb{E}[k_2 B(t+s)] = k_2 \\mathbb{E}[B(t+s)] = k_2 \\mu_B(s)$. The initial condition is $\\mu_B(0) = \\mathbb{E}[B(t)] = \\mathbb{E}[b] = b$.\n\nThus, the ODE for the mean of $B$ is:\n$$\n\\frac{d\\mu_B}{ds} = k_1 A(t+s) - k_2 \\mu_B(s)\n$$\n\n**1. Exact Mean of $B$ at time $t+h$**\n\nFor the fully coupled hybrid model, the evolution of $A$ is given by $\\frac{dA}{dt'} = -k_1 A$ with $A(t)=a$. The solution over the interval $[t, t+h]$ is $A(t+s) = a \\exp(-k_1 s)$ for $s \\in [0,h]$. Substituting this into the ODE for $\\mu_B(s)$ yields:\n$$\n\\frac{d\\mu_B}{ds} + k_2 \\mu_B(s) = k_1 a \\exp(-k_1 s)\n$$\nThis is a first-order linear non-homogeneous differential equation. We solve it using an integrating factor $I(s) = \\exp(\\int k_2 ds) = \\exp(k_2 s)$.\n$$\n\\frac{d}{ds} \\left( \\mu_B(s) \\exp(k_2 s) \\right) = k_1 a \\exp(-k_1 s) \\exp(k_2 s) = k_1 a \\exp((k_2 - k_1)s)\n$$\nIntegrating from $s=0$ to $s=h$:\n$$\n\\int_{0}^{h} \\frac{d}{ds'} \\left( \\mu_B(s') \\exp(k_2 s') \\right) ds' = \\int_{0}^{h} k_1 a \\exp((k_2 - k_1)s') ds'\n$$\n$$\n\\left[ \\mu_B(s') \\exp(k_2 s') \\right]_{0}^{h} = k_1 a \\left[ \\frac{\\exp((k_2 - k_1)s')}{k_2 - k_1} \\right]_{0}^{h}\n$$\nThe integration is valid since $k_1 \\neq k_2$.\n$$\n\\mu_B(h) \\exp(k_2 h) - \\mu_B(0) \\exp(0) = \\frac{k_1 a}{k_2 - k_1} \\left( \\exp((k_2 - k_1)h) - 1 \\right)\n$$\nUsing $\\mu_B(0) = b$ and $\\mathbb{E}[B(t+h)] = \\mu_B(h)$:\n$$\n\\mathbb{E}[B(t+h)] \\exp(k_2 h) - b = \\frac{k_1 a}{k_2 - k_1} \\left( \\exp(k_2 h)\\exp(-k_1 h) - 1 \\right)\n$$\nSolving for $\\mathbb{E}[B(t+h)]$:\n$$\n\\mathbb{E}[B(t+h)] = b \\exp(-k_2 h) + \\frac{k_1 a}{k_2 - k_1} \\left( \\exp(-k_1 h) - \\exp(-k_2 h) \\right)\n$$\n\n**2. Split-step Mean of $B$ at time $t+h$**\n\nThe Lie-Trotter splitting method decouples the evolution into two substeps over the interval of duration $h$.\nSubstep 1: Evolve $A$ deterministically for $h$.\nThe value of $A$ at the end of this substep is $\\tilde{A} = A(t) \\exp(-k_1 h) = a \\exp(-k_1 h)$.\n\nSubstep 2: Evolve $B$ stochastically for $h$, but with the birth rate held constant at the value determined by $\\tilde{A}$. The birth propensity is $k_1 \\tilde{A} = k_1 a \\exp(-k_1 h)$. Let $\\mu_{\\mathrm{split}}(s) = \\mathbb{E}_{\\mathrm{split}}[B(t+s)]$. The governing ODE for the mean of $B$ in this substep is:\n$$\n\\frac{d\\mu_{\\mathrm{split}}}{ds} + k_2 \\mu_{\\mathrm{split}}(s) = k_1 a \\exp(-k_1 h)\n$$\nThis is a linear ODE with a constant forcing term. The initial condition is $\\mu_{\\mathrm{split}}(0) = b$. The solution is:\n$$\n\\mu_{\\mathrm{split}}(s) = \\left( b - \\frac{k_1 a \\exp(-k_1 h)}{k_2} \\right) \\exp(-k_2 s) + \\frac{k_1 a \\exp(-k_1 h)}{k_2}\n$$\nWe evaluate this at $s=h$ to find the mean at time $t+h$:\n$$\n\\mathbb{E}_{\\mathrm{split}}[B(t+h)] = \\mu_{\\mathrm{split}}(h) = \\left( b - \\frac{k_1 a \\exp(-k_1 h)}{k_2} \\right) \\exp(-k_2 h) + \\frac{k_1 a \\exp(-k_1 h)}{k_2}\n$$\n$$\n\\mathbb{E}_{\\mathrm{split}}[B(t+h)] = b \\exp(-k_2 h) + \\frac{k_1 a \\exp(-k_1 h)}{k_2} \\left( 1 - \\exp(-k_2 h) \\right)\n$$\n\n**3. Splitting Error $E(h)$ and Order of Accuracy**\n\nThe splitting error in the mean after one step is $E(h) = \\mathbb{E}_{\\mathrm{split}}[B(t+h)] - \\mathbb{E}[B(t+h)]$.\n$$\nE(h) = \\left[ b \\exp(-k_2 h) + \\frac{k_1 a \\exp(-k_1 h)}{k_2} (1 - \\exp(-k_2 h)) \\right] - \\left[ b \\exp(-k_2 h) + \\frac{k_1 a}{k_2 - k_1} (\\exp(-k_1 h) - \\exp(-k_2 h)) \\right]\n$$\nThe terms involving $b$ cancel out.\n$$\nE(h) = k_1 a \\left[ \\frac{\\exp(-k_1 h) - \\exp(-(k_1+k_2)h)}{k_2} - \\frac{\\exp(-k_1 h) - \\exp(-k_2 h)}{k_2 - k_1} \\right]\n$$\nTo simplify, we find a common denominator $k_2(k_2 - k_1)$:\n$$\nE(h) = \\frac{k_1 a}{k_2(k_2-k_1)} \\left[ (k_2-k_1)(\\exp(-k_1 h) - \\exp(-(k_1+k_2)h)) - k_2(\\exp(-k_1 h) - \\exp(-k_2 h)) \\right]\n$$\nExpanding the terms in the square brackets:\n$$\n(k_2-k_1)\\exp(-k_1 h) - (k_2-k_1)\\exp(-(k_1+k_2)h) - k_2\\exp(-k_1 h) + k_2\\exp(-k_2 h)\n$$\n$$\n= -k_1 \\exp(-k_1 h) + k_2 \\exp(-k_2 h) - (k_2-k_1)\\exp(-(k_1+k_2)h)\n$$\nSo the closed-form expression for the error is:\n$$\nE(h) = \\frac{k_1 a}{k_2(k_2 - k_1)} \\left[ k_2 \\exp(-k_2 h) - k_1 \\exp(-k_1 h) - (k_2 - k_1) \\exp(-(k_1+k_2)h) \\right]\n$$\nTo verify the local order of accuracy, we perform a Taylor series expansion of $E(h)$ for small $h$. Let $T(h) = k_2 \\exp(-k_2 h) - k_1 \\exp(-k_1 h) - (k_2 - k_1) \\exp(-(k_1+k_2)h)$.\nWe use the expansion $\\exp(x) = 1 + x + \\frac{x^2}{2} + O(x^3)$.\nThe constant term ($h^0$) of $T(h)$ is:\n$k_2(1) - k_1(1) - (k_2-k_1)(1) = k_2 - k_1 - k_2 + k_1 = 0$.\nThe linear term ($h^1$) of $T(h)$ is:\n$k_2(-k_2 h) - k_1(-k_1 h) - (k_2 - k_1)(-(k_1+k_2)h) = (-k_2^2 + k_1^2 + (k_2 - k_1)(k_1+k_2))h = (-k_2^2 + k_1^2 + k_2^2 - k_1^2)h = 0$.\nSince the $h^0$ and $h^1$ terms are zero, we proceed to the $h^2$ term. The coefficient of $h^2/2$ in $T(h)$ is:\n$k_2(-k_2)^2 - k_1(-k_1)^2 - (k_2 - k_1)(-(k_1+k_2))^2 = k_2^3 - k_1^3 - (k_2-k_1)(k_1+k_2)^2$\n$= k_2^3 - k_1^3 - (k_2-k_1)(k_1^2 + 2k_1 k_2 + k_2^2)$\n$= k_2^3 - k_1^3 - (k_2k_1^2 + 2k_1k_2^2 + k_2^3 - k_1^3 - 2k_1^2 k_2 - k_1k_2^2)$\n$= k_2^3 - k_1^3 - (k_2^3 - k_1^3 - k_1^2k_2 + k_1k_2^2)$\n$= k_1^2k_2 - k_1k_2^2 = k_1k_2(k_1-k_2)$.\nSo, for small $h$, $T(h) \\approx \\frac{h^2}{2} k_1 k_2 (k_1-k_2)$.\nSubstituting this into the expression for $E(h)$:\n$$\nE(h) \\approx \\frac{k_1 a}{k_2(k_2 - k_1)} \\left( \\frac{h^2}{2} k_1 k_2 (k_1-k_2) \\right) = \\frac{k_1 a}{k_2(k_2 - k_1)} \\left( -\\frac{h^2}{2} k_1 k_2 (k_2-k_1) \\right) = -\\frac{1}{2} k_1^2 a h^2\n$$\nThe lowest non-zero power of $h$ in the error expansion is $h^2$. This shows that the local error in the mean is of order $2$, which is characteristic of first-order splitting schemes like the Lie-Trotter method. The problem asks for the closed-form analytic expression for $E(h)$, which was derived above.", "answer": "$$\n\\boxed{\\frac{k_1 a}{k_2(k_2 - k_1)} \\left[ k_2 \\exp(-k_2 h) - k_1 \\exp(-k_1 h) - (k_2 - k_1) \\exp(-(k_1+k_2)h) \\right]}\n$$", "id": "3319355"}, {"introduction": "This practice transitions from analytical exercises to a hands-on computational challenge: implementing a hybrid simulator for a classic, non-linear biological circuit. The genetic toggle switch is a benchmark system where stochastic noise in promoter binding is not just a nuisance but the driving force behind its bistable function. In this exercise [@problem_id:3319361], you will design and code a hybrid model that strategically applies stochastic simulation to the low-copy-number promoter states while treating the more abundant mRNA and protein populations deterministically, thereby preserving essential biological behavior while achieving significant computational speedup.", "problem": "You are tasked with designing and implementing a hybrid simulation algorithm for a benchmark genetic toggle-switch network in computational systems biology that uses a combination of stochastic and deterministic methods to preserve bistability while improving computational performance. The network consists of two genes, denoted by $A$ and $B$, that mutually repress each other's transcription via binding to promoter sites.\n\nThe species are as follows:\n- Promoter states for gene $A$: $P_A^{\\mathrm{free}}$ and $P_A^{\\mathrm{bound}}$.\n- Promoter states for gene $B$: $P_B^{\\mathrm{free}}$ and $P_B^{\\mathrm{bound}}$.\n- Messenger RNA: $m_A$ and $m_B$ (molecules).\n- Protein: $A$ and $B$ (molecules).\n\nThe reactions (following the law of mass action) are:\n- Promoter binding and unbinding (stochastic):\n  - $B + P_A^{\\mathrm{free}} \\xrightarrow{k_{\\mathrm{on},A}} P_A^{\\mathrm{bound}}$,\n  - $P_A^{\\mathrm{bound}} \\xrightarrow{k_{\\mathrm{off},A}} B + P_A^{\\mathrm{free}}$,\n  - $A + P_B^{\\mathrm{free}} \\xrightarrow{k_{\\mathrm{on},B}} P_B^{\\mathrm{bound}}$,\n  - $P_B^{\\mathrm{bound}} \\xrightarrow{k_{\\mathrm{off},B}} A + P_B^{\\mathrm{free}}$.\n- Transcription (deterministic), dependent on promoter occupancy:\n  - If $P_A^{\\mathrm{free}}$, transcription rate $r_A = \\alpha_A$; if $P_A^{\\mathrm{bound}}$, transcription rate $r_A = \\ell_A$ (leak).\n  - If $P_B^{\\mathrm{free}}$, transcription rate $r_B = \\alpha_B$; if $P_B^{\\mathrm{bound}}$, transcription rate $r_B = \\ell_B$ (leak).\n- Translation and degradation (deterministic):\n  - $m_A \\xrightarrow{\\beta_A} A$,\n  - $m_B \\xrightarrow{\\beta_B} B$,\n  - Degradation $m_A \\xrightarrow{\\delta_{m,A}} \\varnothing$, $m_B \\xrightarrow{\\delta_{m,B}} \\varnothing$, $A \\xrightarrow{\\delta_{p,A}} \\varnothing$, $B \\xrightarrow{\\delta_{p,B}} \\varnothing$.\n\nYou must partition the reactions such that promoter binding and unbinding are simulated stochastically, while transcription, translation, and degradation are simulated deterministically. The deterministic part should be integrated using a fixed-step explicit method, and the stochastic part should be simulated using a discrete-time approximation of an inhomogeneous Poisson process based on instantaneous propensities. Specifically, during each time step of size $\\Delta t$:\n- For $P_A$:\n  - If $P_A^{\\mathrm{free}}$, the binding propensity is $a_{\\mathrm{bind},A}(t) = k_{\\mathrm{on},A} \\, B(t)$ and the binding probability over $\\Delta t$ is $p_{\\mathrm{bind},A} = 1 - e^{-a_{\\mathrm{bind},A}(t)\\,\\Delta t}$.\n  - If $P_A^{\\mathrm{bound}}$, the unbinding propensity is $a_{\\mathrm{unbind},A} = k_{\\mathrm{off},A}$ and the unbinding probability over $\\Delta t$ is $p_{\\mathrm{unbind},A} = 1 - e^{-a_{\\mathrm{unbind},A}\\,\\Delta t}$.\n- For $P_B$:\n  - If $P_B^{\\mathrm{free}}$, the binding propensity is $a_{\\mathrm{bind},B}(t) = k_{\\mathrm{on},B} \\, A(t)$ with probability $p_{\\mathrm{bind},B} = 1 - e^{-a_{\\mathrm{bind},B}(t)\\,\\Delta t}$.\n  - If $P_B^{\\mathrm{bound}}$, the unbinding propensity is $a_{\\mathrm{unbind},B} = k_{\\mathrm{off},B}$ with probability $p_{\\mathrm{unbind},B} = 1 - e^{-a_{\\mathrm{unbind},B}\\,\\Delta t}$.\n\nThe deterministic updates for $m_A$, $m_B$, $A$, and $B$ must use explicit Euler integration:\n$$\nm_A(t+\\Delta t) = m_A(t) + \\Delta t \\left(r_A(t) - \\delta_{m,A} \\, m_A(t)\\right), \\quad\nA(t+\\Delta t) = A(t) + \\Delta t \\left(\\beta_A \\, m_A(t) - \\delta_{p,A} \\, A(t)\\right),\n$$\n$$\nm_B(t+\\Delta t) = m_B(t) + \\Delta t \\left(r_B(t) - \\delta_{m,B} \\, m_B(t)\\right), \\quad\nB(t+\\Delta t) = B(t) + \\Delta t \\left(\\beta_B \\, m_B(t) - \\delta_{p,B} \\, B(t)\\right).\n$$\nClamp $m_A$, $m_B$, $A$, and $B$ to be nonnegative after each update.\n\nScientific basis and constraints for your design:\n- The hybrid scheme is a piecewise deterministic Markov process (PDMP), derived by partitioning the Chemical Master Equation (CME) into a stochastic subsystem for discrete promoter states and a deterministic subsystem for large-copy-number species under the reaction-rate approximation.\n- To preserve bistability, stochasticity must be retained in the promoter-binding dynamics, which mediate noise-driven switching between attractor states.\n- Deterministic integration of $m_A$, $m_B$, $A$, and $B$ improves performance and is justified when their copy numbers are moderate to large.\n\nInitial conditions for all simulations:\n- At time $t=0$, set $m_A(0) = 0$, $m_B(0) = 0$, $A(0) = 0$, $B(0) = 0$ (all in molecules), and $P_A^{\\mathrm{free}}$, $P_B^{\\mathrm{free}}$.\n- Time step is $\\Delta t = 1\\,\\mathrm{s}$.\n- Total simulation horizon is $T = 2000\\,\\mathrm{s}$.\n- For each parameter set, run $N = 100$ independent replicate simulations to form the empirical distribution of the final protein difference $D = A(T) - B(T)$, recorded in molecules.\n\nYour program must estimate the number of modes in the empirical distribution of $D$ by:\n- Computing a histogram using the Freedman–Diaconis rule for bin width, smoothing the counts with a short symmetric kernel, and counting local maxima above a fraction of the global maximum.\n\nDesign the following test suite of parameter sets (all rates in $\\mathrm{s^{-1}}$, and $k_{\\mathrm{on}}$ values are per molecule per second so that the propensity $k_{\\mathrm{on}} \\times (\\text{molecular count})$ has units of $\\mathrm{s}^{-1}$):\n1. Symmetric, bistable benchmark (happy path):\n   - $\\alpha_A = \\alpha_B = 5$, $\\ell_A = \\ell_B = 0.02$, $\\beta_A = \\beta_B = 0.5$,\n   - $\\delta_{m,A} = \\delta_{m,B} = 0.1$, $\\delta_{p,A} = \\delta_{p,B} = 0.005$,\n   - $k_{\\mathrm{on},A} = k_{\\mathrm{on},B} = 2\\times 10^{-4}$, $k_{\\mathrm{off},A} = k_{\\mathrm{off},B} = 5\\times 10^{-4}$.\n   Expected behavior: two well-separated modes in $D$ due to mutually exclusive promoter occupancy.\n2. Weakened repression (boundary condition approaching unimodality):\n   - $\\alpha_A = \\alpha_B = 5$, $\\ell_A = \\ell_B = 0.02$, $\\beta_A = \\beta_B = 0.5$,\n   - $\\delta_{m,A} = \\delta_{m,B} = 0.1$, $\\delta_{p,A} = \\delta_{p,B} = 0.005$,\n   - $k_{\\mathrm{on},A} = k_{\\mathrm{on},B} = 1\\times 10^{-4}$, $k_{\\mathrm{off},A} = k_{\\mathrm{off},B} = 2\\times 10^{-2}$.\n   Expected behavior: frequent unbinding leads to frequent switching and a single broad mode around $D \\approx 0$.\n3. Strong repression and persistence (edge case with highly stable modes):\n   - $\\alpha_A = \\alpha_B = 5$, $\\ell_A = \\ell_B = 0.02$, $\\beta_A = \\beta_B = 0.5$,\n   - $\\delta_{m,A} = \\delta_{m,B} = 0.1$, $\\delta_{p,A} = \\delta_{p,B} = 0.005$,\n   - $k_{\\mathrm{on},A} = k_{\\mathrm{on},B} = 4\\times 10^{-4}$, $k_{\\mathrm{off},A} = k_{\\mathrm{off},B} = 2\\times 10^{-4}$.\n   Expected behavior: two modes with larger separation and longer residence times.\n\nUnits:\n- Time must be in $\\mathrm{s}$.\n- Molecular counts are in molecules (dimensionless counts).\n\nFinal output specification:\n- For each parameter set, compute the integer number of modes detected in the empirical distribution of $D$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For instance, if the three cases have $2$, $1$, and $2$ modes respectively, the output must be exactly formatted as $[2,1,2]$.", "solution": "The problem requires the design and implementation of a hybrid stochastic–deterministic simulation algorithm for a genetic toggle-switch network. The problem is scientifically sound, well-posed, and provides sufficient detail to construct a unique and meaningful solution. The model is a standard representation of a genetic toggle switch, and the proposed hybrid simulation strategy, a form of a Piecewise Deterministic Markov Process (PDMP), is an established method in computational systems biology. The parameters and initial conditions are fully specified. The minor ambiguity in the mode-counting procedure will be resolved by making standard, explicit assumptions as detailed below.\n\nThe core of the problem is to simulate a system where some events (promoter binding/unbinding) are rare and fundamentally stochastic, driving system-level state switching (bistability), while other processes (transcription, translation, degradation) involve larger numbers of molecules and can be approximated deterministically for computational efficiency.\n\nThe system state at any time $t$ is described by the tuple $(m_A(t), m_B(t), A(t), B(t), P_A(t), P_B(t))$, where $m_A, m_B, A, B$ are the molecular counts of mRNA and proteins, and $P_A, P_B$ represent the discrete states of the promoters (free or bound). We will represent the free state as $0$ and the bound state as $1$.\n\nThe simulation proceeds in discrete time steps of size $\\Delta t = 1\\,\\mathrm{s}$ for a total duration of $T = 2000\\,\\mathrm{s}$. At each step, from time $t$ to $t+\\Delta t$, we update the system state according to the partitioned dynamics.\n\nFirst, we address the stochastic update of the promoter states, $P_A$ and $P_B$. The transition between free and bound states is modeled as an inhomogeneous Poisson process, approximated over the discrete time interval $\\Delta t$. The probability of a state change depends on the current state of the system.\n\n- For promoter $A$:\n  - If it is free at time $t$ ($P_A(t)=0$), it can be bound by a molecule of protein $B$. The propensity for this reaction is $a_{\\mathrm{bind},A}(t) = k_{\\mathrm{on},A} B(t)$. The probability of this event occurring in the interval $[t, t+\\Delta t]$ is $p_{\\mathrm{bind},A} = 1 - \\exp(-a_{\\mathrm{bind},A}(t)\\Delta t)$.\n  - If it is bound at time $t$ ($P_A(t)=1$), it can unbind. The propensity for this is constant: $a_{\\mathrm{unbind},A} = k_{\\mathrm{off},A}$. The probability of unbinding is $p_{\\mathrm{unbind},A} = 1 - \\exp(-a_{\\mathrm{unbind},A}\\Delta t)$.\n- A symmetric set of rules applies to promoter $B$, with its state transitions depending on the concentration of protein $A$.\n\nSecond, we perform the deterministic update of the continuous-valued species (mRNA and protein molecule counts) using the explicit Euler method. The problem specifies that the rates $r_A(t)$ and $r_B(t)$ for the Euler step are determined by the promoter states at the beginning of the interval, time $t$.\n\n- The transcription rates are:\n  - $r_A(t) = \\alpha_A$ if $P_A(t)=0$ (free), and $r_A(t) = \\ell_A$ if $P_A(t)=1$ (bound).\n  - $r_B(t) = \\alpha_B$ if $P_B(t)=0$ (free), and $r_B(t) = \\ell_B$ if $P_B(t)=1$ (bound).\n- The Euler-discretized ordinary differential equations are:\n$$\nm_A(t+\\Delta t) = m_A(t) + \\Delta t \\left(r_A(t) - \\delta_{m,A} \\, m_A(t)\\right)\n$$\n$$\nA(t+\\Delta t) = A(t) + \\Delta t \\left(\\beta_A \\, m_A(t) - \\delta_{p,A} \\, A(t)\\right)\n$$\nAnd similarly for $m_B$ and $B$. After each update, the molecular counts are clamped to be non-negative, ensuring physical realism.\n\nThe overall algorithm for a single simulation trajectory is as follows:\n1. Initialize the state at $t=0$: $m_A(0)=0$, $m_B(0)=0$, $A(0)=0$, $B(0)=0$, and promoters $P_A(0)=0, P_B(0)=0$ (free).\n2. For each time step $i$ from $0$ to $(T/\\Delta t) - 1$, with $t_i = i \\Delta t$:\n    a. Determine transcription rates $r_A(t_i)$ and $r_B(t_i)$ based on $P_A(t_i)$ and $P_B(t_i)$.\n    b. Calculate the new molecular counts $m_A(t_{i+1}), A(t_{i+1}), m_B(t_{i+1}), B(t_{i+1})$ using the explicit Euler formulae and the values at $t_i$. Enforce non-negativity.\n    c. Calculate the transition probabilities for the promoters based on the state at $t_i$.\n    d. Generate a random number for each promoter to decide if its state flips, determining $P_A(t_{i+1})$ and $P_B(t_{i+1})$.\n3. After the loop completes, record the final protein difference $D = A(T) - B(T)$.\n\nThis process is repeated $N=100$ times for each of the three parameter sets, yielding an empirical distribution of $D$ for each case.\n\nFinally, we analyze this distribution to count its modes. The problem outlines a procedure which we specify completely as follows:\n1.  **Binning**: A histogram of the $N=100$ values of $D$ is computed. The bin width $h$ is determined by the Freedman-Diaconis rule: $h = 2 \\frac{\\mathrm{IQR}(D)}{N^{1/3}}$.\n2.  **Smoothing**: The histogram counts are smoothed to reduce noise. We will use a 3-point symmetric triangular kernel $[0.25, 0.5, 0.25]$ applied via convolution.\n3.  **Peak Detection**: Local maxima in the smoothed histogram are identified. A point is a local maximum if its value is strictly greater than its two immediate neighbors.\n4.  **Thresholding**: To filter out minor fluctuations, only local maxima with a height greater than $10\\%$ of the global maximum height in the smoothed histogram are counted. This threshold is a reasonable choice for distinguishing significant modes from noise.\n\nThe final output is the number of modes detected for each of the three parameter sets.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the hybrid simulation for the three test cases\n    and print the detected number of modes for each.\n    \"\"\"\n\n    # Define the three test cases as dictionaries of parameters.\n    # Base parameters common to all cases\n    base_params = {\n        'alpha_A': 5.0, 'alpha_B': 5.0, 'ell_A': 0.02, 'ell_B': 0.02,\n        'beta_A': 0.5, 'beta_B': 0.5, 'delta_m_A': 0.1, 'delta_m_B': 0.1,\n        'delta_p_A': 0.005, 'delta_p_B': 0.005,\n    }\n\n    test_cases = [\n        # Case 1: Symmetric, bistable benchmark\n        {**base_params, 'k_on_A': 2e-4, 'k_on_B': 2e-4, 'k_off_A': 5e-4, 'k_off_B': 5e-4},\n        # Case 2: Weakened repression (unimodal)\n        {**base_params, 'k_on_A': 1e-4, 'k_on_B': 1e-4, 'k_off_A': 2e-2, 'k_off_B': 2e-2},\n        # Case 3: Strong repression (highly stable modes)\n        {**base_params, 'k_on_A': 4e-4, 'k_on_B': 4e-4, 'k_off_A': 2e-4, 'k_off_B': 2e-4},\n    ]\n\n    # Simulation constants\n    T = 2000.0\n    DT = 1.0\n    N_REPLICATES = 100\n    \n    # Mode counting parameters\n    MODE_THRESHOLD_FRACTION = 0.1\n    SMOOTHING_KERNEL = np.array([0.25, 0.5, 0.25])\n\n    rng = np.random.default_rng(seed=42) # for reproducible results\n\n    results = []\n    for params in test_cases:\n        final_diffs = []\n        for _ in range(N_REPLICATES):\n            d = run_simulation(params, T, DT, rng)\n            final_diffs.append(d)\n        \n        n_modes = count_modes(\n            np.array(final_diffs), \n            SMOOTHING_KERNEL, \n            MODE_THRESHOLD_FRACTION\n        )\n        results.append(n_modes)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_simulation(params, T, dt, rng):\n    \"\"\"\n    Runs a single trajectory of the hybrid simulation.\n    \n    Args:\n        params (dict): Dictionary of model parameters.\n        T (float): Total simulation time.\n        dt (float): Time step.\n        rng (np.random.Generator): Random number generator instance.\n\n    Returns:\n        float: The final difference D = A(T) - B(T).\n    \"\"\"\n    # Initial conditions\n    m_a, m_b = 0.0, 0.0\n    prot_a, prot_b = 0.0, 0.0\n    p_a_free, p_b_free = 1, 1 # 1 for free, 0 for bound\n\n    num_steps = int(T / dt)\n\n    for _ in range(num_steps):\n        # Store current state for calculations within this time step\n        m_a_t, m_b_t = m_a, m_b\n        prot_a_t, prot_b_t = prot_a, prot_b\n        p_a_free_t, p_b_free_t = p_a_free, p_b_free\n\n        # --- Stochastic update of promoter states ---\n        # Based on state at time t\n        \n        # Promoter A\n        if p_a_free_t == 1: # free -> bound?\n            propensity = params['k_on_A'] * prot_b_t\n            prob_bind = 1.0 - np.exp(-propensity * dt)\n            if rng.random() < prob_bind:\n                p_a_free = 0\n        else: # bound -> free?\n            propensity = params['k_off_A']\n            prob_unbind = 1.0 - np.exp(-propensity * dt)\n            if rng.random() < prob_unbind:\n                p_a_free = 1\n        \n        # Promoter B\n        if p_b_free_t == 1: # free -> bound?\n            propensity = params['k_on_B'] * prot_a_t\n            prob_bind = 1.0 - np.exp(-propensity * dt)\n            if rng.random() < prob_bind:\n                p_b_free = 0\n        else: # bound -> free? \n            propensity = params['k_off_B']\n            prob_unbind = 1.0 - np.exp(-propensity * dt)\n            if rng.random() < prob_unbind:\n                p_b_free = 1\n\n        # --- Deterministic update of mRNA and proteins ---\n        # Based on state at time t\n        r_a = params['alpha_A'] if p_a_free_t == 1 else params['ell_A']\n        r_b = params['alpha_B'] if p_b_free_t == 1 else params['ell_B']\n\n        # Update mRNA\n        m_a = m_a_t + dt * (r_a - params['delta_m_A'] * m_a_t)\n        m_b = m_b_t + dt * (r_b - params['delta_m_B'] * m_b_t)\n        \n        # Update proteins\n        prot_a = prot_a_t + dt * (params['beta_A'] * m_a_t - params['delta_p_A'] * prot_a_t)\n        prot_b = prot_b_t + dt * (params['beta_B'] * m_b_t - params['delta_p_B'] * prot_b_t)\n\n        # Clamp to non-negative\n        m_a = max(0.0, m_a)\n        m_b = max(0.0, m_b)\n        prot_a = max(0.0, prot_a)\n        prot_b = max(0.0, prot_b)\n        \n    return prot_a - prot_b\n\n\ndef count_modes(data, kernel, threshold_frac):\n    \"\"\"\n    Counts the number of modes in a 1D data array using a histogram-based method.\n    \n    Args:\n        data (np.ndarray): Array of data points.\n        kernel (np.ndarray): Smoothing kernel.\n        threshold_frac (float): Fraction of the global max for peak thresholding.\n\n    Returns:\n        int: The number of detected modes.\n    \"\"\"\n    if len(data) < 3:\n        return 1\n        \n    # 1. Binning using Freedman-Diaconis rule\n    try:\n        counts, bin_edges = np.histogram(data, bins='fd')\n    except ValueError:\n        # Fallback if 'fd' fails (e.g., zero variance)\n        counts, bin_edges = np.histogram(data, bins=10)\n\n    if len(counts) < 3:\n      # Not enough bins to find local maxima with a 3-point kernel\n      return 1 if len(counts) > 0 else 0\n\n    # 2. Smoothing\n    smoothed_counts = np.convolve(counts, kernel, mode='same')\n    \n    # 3. Peak Finding & 4. Thresholding\n    global_max = np.max(smoothed_counts)\n    if global_max == 0:\n        return 0\n        \n    threshold = threshold_frac * global_max\n    \n    modes = 0\n    # Iterate from the second to the second-to-last bin to check for local maxima\n    for i in range(1, len(smoothed_counts) - 1):\n        is_local_max = smoothed_counts[i] > smoothed_counts[i-1] and \\\n                       smoothed_counts[i] > smoothed_counts[i+1]\n        \n        if is_local_max and smoothed_counts[i] > threshold:\n            modes += 1\n            \n    # Handle edge case where a single peak might exist at the edge\n    # or the data is monotonic, producing no peaks in the center.\n    if modes == 0 and np.any(smoothed_counts > 0):\n        return 1\n        \n    return modes\n\nsolve()\n```", "id": "3319361"}]}