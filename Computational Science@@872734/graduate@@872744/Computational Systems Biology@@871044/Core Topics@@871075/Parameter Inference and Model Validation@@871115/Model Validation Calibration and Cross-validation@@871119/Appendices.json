{"hands_on_practices": [{"introduction": "The cornerstone of model validation is the quantitative comparison of model predictions against experimental data. This practice establishes a computational foundation by asking you to implement several key performance metrics, including the Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and the probabilistic log score. By applying these metrics to a simulated oscillating system with known sources of error, you will gain direct experience with how different scoring rules penalize prediction inaccuracies and quantify predictive uncertainty, a fundamental skill for any modeling endeavor [@problem_id:3327278].", "problem": "You are tasked with quantitatively validating a simulated cytokine time-course model against observed data under known phase shifts and predictive uncertainty, and to analyze the robustness properties of different performance metrics. Consider a single cytokine trajectory generated by an oscillatory regulatory network that, in the absence of noise, can be represented by a sinusoidal mean trajectory. Let the deterministic mean trajectory be given by $y_{\\mathrm{true}}(t) = B + A \\sin(\\omega t)$ for time $t \\ge 0$, with amplitude $A$, baseline level $B$, and angular frequency $\\omega$. Observations are collected at discrete times $t_k = k \\Delta t$ for $k \\in \\{0,1,\\dots,T-1\\}$ with fixed step $\\Delta t$. The observed data are $y_{\\mathrm{obs}}(t_k) = y_{\\mathrm{true}}(t_k) + \\varepsilon_k$, where $\\varepsilon_k$ are independent and identically distributed Gaussian perturbations with zero mean and variance $\\sigma_{\\mathrm{obs}}^2$. The simulator outputs a phase-shifted mean trajectory $y_{\\mathrm{sim}}(t_k;\\phi) = B + A \\sin(\\omega t_k + \\phi)$, where $\\phi$ is a phase shift. Assume that the simulator’s predictive distribution at time $t_k$ is univariate Normal with mean $y_{\\mathrm{sim}}(t_k;\\phi)$ and standard deviation $\\sigma_{\\mathrm{pred}}$; that is, $y \\mid t_k \\sim \\mathcal{N}(y_{\\mathrm{sim}}(t_k;\\phi), \\sigma_{\\mathrm{pred}}^2)$. Angles must be interpreted in radians.\n\nYour program must do the following:\n- Generate the observed trajectory by sampling $\\varepsilon_k \\sim \\mathcal{N}(0,\\sigma_{\\mathrm{obs}}^2)$ using a pseudo-random number generator with seed fixed to $314159$, so that results are reproducible.\n- For each specified test case, compute the following metrics between $y_{\\mathrm{sim}}(t_k;\\phi)$ and $y_{\\mathrm{obs}}(t_k)$ over the indicated subset of time indices $k$:\n  1. Root Mean Squared Error (RMSE): the square root of the mean of squared errors.\n  2. Mean Absolute Error (MAE): the mean of absolute errors.\n  3. Time-averaged log score: the empirical average, over the selected time indices, of the log predictive density under the Normal model with mean $y_{\\mathrm{sim}}(t_k;\\phi)$ and standard deviation $\\sigma_{\\mathrm{pred}}$.\n\nUse the following fixed settings for data generation:\n- Amplitude $A = 2.0$.\n- Baseline $B = 5.0$.\n- Angular frequency $\\omega = 1.0$.\n- Time step $\\Delta t = 0.05$.\n- Number of time points $T = 200$.\n- Observation noise standard deviation $\\sigma_{\\mathrm{obs}} = 0.5$.\n- Random seed $314159$ for generating $\\{\\varepsilon_k\\}_{k=0}^{T-1}$.\n\nAngles are in radians. There are no physical units for the cytokine concentration in this problem, and angles must be treated in radians. No angles in degrees are permitted.\n\nTest Suite (each test case is a triple $(\\phi, \\sigma_{\\mathrm{pred}}, \\mathcal{K})$ where $\\mathcal{K}$ is the subset of indices to include):\n- Case $1$: $\\phi = 0.0$, $\\sigma_{\\mathrm{pred}} = 0.5$, $\\mathcal{K} = \\{0,1,\\dots,T-1\\}$ (all indices).\n- Case $2$: $\\phi = 0.2$, $\\sigma_{\\mathrm{pred}} = 0.5$, $\\mathcal{K} = \\{0,1,\\dots,T-1\\}$.\n- Case $3$: $\\phi = \\pi$, $\\sigma_{\\mathrm{pred}} = 0.5$, $\\mathcal{K} = \\{0,1,\\dots,T-1\\}$.\n- Case $4$: $\\phi = 0.2$, $\\sigma_{\\mathrm{pred}} = 2.0$, $\\mathcal{K} = \\{0,1,\\dots,T-1\\}$.\n- Case $5$: $\\phi = 0.2$, $\\sigma_{\\mathrm{pred}} = 0.1$, $\\mathcal{K} = \\{0,1,\\dots,T-1\\}$.\n- Case $6$: $\\phi = 0.2$, $\\sigma_{\\mathrm{pred}} = 0.5$, $\\mathcal{K} = \\{0,1,2,3,4\\}$ (the first five indices only).\n\nImplementation notes and requirements:\n- Angles must be in radians.\n- For each case, compute the three metrics over the specified index set $\\mathcal{K}$ only.\n- Report each metric as a floating-point number rounded to $6$ decimal places.\n- The final program output must be a single line containing a list of length $6$, where each element is a list of length $3$ corresponding to $\\left[\\mathrm{RMSE}, \\mathrm{MAE}, \\mathrm{AvgLogScore}\\right]$ for the corresponding test case, in the same order as above.\n\nFundamental bases you may use without further justification include: properties of the Normal distribution, the definition of absolute value and squared error, and the definitions of empirical means. You must treat the time-averaged log score as the empirical average of the log predictive density evaluated at $y_{\\mathrm{obs}}(t_k)$ under the Normal model with mean $y_{\\mathrm{sim}}(t_k;\\phi)$ and standard deviation $\\sigma_{\\mathrm{pred}}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $\\left[\\left[\\cdot,\\cdot,\\cdot\\right],\\dots\\right]$).", "solution": "The problem statement has been analyzed and is deemed valid. It is scientifically grounded in the principles of computational modeling and statistical model validation, is well-posed with a complete and consistent set of parameters and definitions, and is objective in its formulation. A unique and verifiable solution can be computed.\n\nThe task is to compute three performance metrics (Root Mean Squared Error, Mean Absolute Error, and Time-Averaged Log Score) to evaluate a simulated time-series model against a synthetically generated observed trajectory. The process is divided into two main stages: data generation and metric computation.\n\nFirst, we generate the \"observed\" data. This is done once and the same data is used for all test cases to ensure a fair comparison.\nThe discrete time points are given by $t_k = k \\Delta t$ for $k \\in \\{0, 1, \\dots, T-1\\}$, where the number of points is $T=200$ and the time step is $\\Delta t = 0.05$.\nThe true, noise-free underlying trajectory is a sinusoid:\n$$ y_{\\mathrm{true}}(t_k) = B + A \\sin(\\omega t_k) $$\nwith amplitude $A=2.0$, baseline $B=5.0$, and angular frequency $\\omega=1.0$.\nThe observed data, $y_{\\mathrm{obs}}(t_k)$, are generated by adding Gaussian noise to this true trajectory:\n$$ y_{\\mathrm{obs}}(t_k) = y_{\\mathrm{true}}(t_k) + \\varepsilon_k $$\nwhere $\\varepsilon_k$ are independent and identically distributed random variables drawn from a Normal distribution with mean $0$ and standard deviation $\\sigma_{\\mathrm{obs}}=0.5$. That is, $\\varepsilon_k \\sim \\mathcal{N}(0, \\sigma_{\\mathrm{obs}}^2)$. The generation of the sequence $\\{\\varepsilon_k\\}_{k=0}^{T-1}$ is performed using a pseudo-random number generator initialized with a fixed seed of $314159$ to ensure reproducibility.\n\nSecond, for each of the six test cases specified, we compute the validation metrics. A test case is defined by a triplet $(\\phi, \\sigma_{\\mathrm{pred}}, \\mathcal{K})$, where $\\phi$ is the phase shift in the simulator, $\\sigma_{\\mathrm{pred}}$ is the standard deviation of the simulator's predictive distribution, and $\\mathcal{K}$ is the subset of time indices over which the metrics are computed.\n\nThe simulated trajectory for a given phase shift $\\phi$ is:\n$$ y_{\\mathrm{sim}}(t_k; \\phi) = B + A \\sin(\\omega t_k + \\phi) $$\nFor each time point $t_k$ with index $k \\in \\mathcal{K}$, the error is defined as the difference between the observed and simulated values:\n$$ e_k = y_{\\mathrm{obs}}(t_k) - y_{\\mathrm{sim}}(t_k; \\phi) $$\nLet $N_{\\mathcal{K}} = |\\mathcal{K}|$ be the number of indices in the set $\\mathcal{K}$. The three metrics are calculated as follows:\n\n1.  **Root Mean Squared Error (RMSE)**: This metric measures the square root of the average squared error.\n    $$ \\mathrm{RMSE} = \\sqrt{\\frac{1}{N_{\\mathcal{K}}} \\sum_{k \\in \\mathcal{K}} e_k^2} $$\n\n2.  **Mean Absolute Error (MAE)**: This metric measures the average absolute error.\n    $$ \\mathrm{MAE} = \\frac{1}{N_{\\mathcal{K}}} \\sum_{k \\in \\mathcal{K}} |e_k| $$\n\n3.  **Time-averaged Log Score**: This is a proper scoring rule that evaluates the quality of a probabilistic forecast. It is the empirical average of the log predictive probability density. The predictive distribution is given as $\\mathcal{N}(y_{\\mathrm{sim}}(t_k; \\phi), \\sigma_{\\mathrm{pred}}^2)$. The probability density function for a normal distribution is $p(y; \\mu, \\sigma^2) = (2\\pi\\sigma^2)^{-1/2} \\exp(-(y-\\mu)^2 / (2\\sigma^2))$. The log-density evaluated at the observation $y_{\\mathrm{obs}}(t_k)$ is:\n    $$ \\log p(y_{\\mathrm{obs}}(t_k)) = \\log \\left( \\frac{1}{\\sqrt{2\\pi\\sigma_{\\mathrm{pred}}^2}} \\exp\\left(-\\frac{(y_{\\mathrm{obs}}(t_k) - y_{\\mathrm{sim}}(t_k; \\phi))^2}{2\\sigma_{\\mathrm{pred}}^2}\\right) \\right) $$\n    $$ = -\\frac{1}{2}\\log(2\\pi\\sigma_{\\mathrm{pred}}^2) - \\frac{e_k^2}{2\\sigma_{\\mathrm{pred}}^2} = -\\log(\\sigma_{\\mathrm{pred}}) - \\frac{1}{2}\\log(2\\pi) - \\frac{e_k^2}{2\\sigma_{\\mathrm{pred}}^2} $$\n    The time-averaged log score is the mean of these values over the indices in $\\mathcal{K}$:\n    $$ \\mathrm{AvgLogScore} = \\frac{1}{N_{\\mathcal{K}}} \\sum_{k \\in \\mathcal{K}} \\left( -\\log(\\sigma_{\\mathrm{pred}}) - \\frac{1}{2}\\log(2\\pi) - \\frac{e_k^2}{2\\sigma_{\\mathrm{pred}}^2} \\right) $$\n    This can be simplified by factoring out constant terms and recognizing the Mean Squared Error (MSE), $\\mathrm{MSE} = \\frac{1}{N_{\\mathcal{K}}} \\sum_{k \\in \\mathcal{K}} e_k^2 = \\mathrm{RMSE}^2$:\n    $$ \\mathrm{AvgLogScore} = -\\log(\\sigma_{\\mathrm{pred}}) - \\frac{1}{2}\\log(2\\pi) - \\frac{\\mathrm{MSE}}{2\\sigma_{\\mathrm{pred}}^2} $$\n\nFor each test case, the program will first select the relevant subsets of $y_{\\mathrm{obs}}$ and $t$ based on $\\mathcal{K}$, then compute $y_{\\mathrm{sim}}$, and finally calculate the three metrics using the formulas above. Each resulting metric is rounded to $6$ decimal places.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    # Fixed settings for data generation\n    A = 2.0\n    B = 5.0\n    omega = 1.0\n    delta_t = 0.05\n    T = 200\n    sigma_obs = 0.5\n    seed = 314159\n\n    # Generate the time vector\n    t = np.arange(T) * delta_t\n\n    # Generate the true trajectory\n    y_true = B + A * np.sin(omega * t)\n\n    # Generate the observed trajectory with reproducible noise\n    rng = np.random.default_rng(seed)\n    noise = rng.normal(loc=0.0, scale=sigma_obs, size=T)\n    y_obs = y_true + noise\n\n    # Define the test suite\n    test_cases = [\n        {'phi': 0.0, 'sigma_pred': 0.5, 'K': range(T)},\n        {'phi': 0.2, 'sigma_pred': 0.5, 'K': range(T)},\n        {'phi': np.pi, 'sigma_pred': 0.5, 'K': range(T)},\n        {'phi': 0.2, 'sigma_pred': 2.0, 'K': range(T)},\n        {'phi': 0.2, 'sigma_pred': 0.1, 'K': range(T)},\n        {'phi': 0.2, 'sigma_pred': 0.5, 'K': range(T)[0:5]}\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        phi = case['phi']\n        sigma_pred = case['sigma_pred']\n        # Convert K (which might be a range) to a list of indices for slicing\n        k_indices = np.array(list(case['K']))\n\n        # Select the subset of data based on indices in K\n        t_subset = t[k_indices]\n        y_obs_subset = y_obs[k_indices]\n\n        # Generate the simulated trajectory for the subset\n        y_sim_subset = B + A * np.sin(omega * t_subset + phi)\n\n        # Calculate errors\n        errors = y_obs_subset - y_sim_subset\n\n        # 1. Root Mean Squared Error (RMSE)\n        mse = np.mean(errors**2)\n        rmse = np.sqrt(mse)\n\n        # 2. Mean Absolute Error (MAE)\n        mae = np.mean(np.abs(errors))\n\n        # 3. Time-averaged log score\n        # AvgLogScore = -log(sigma_pred) - 0.5*log(2*pi) - MSE/(2*sigma_pred^2)\n        log_score_term1 = -np.log(sigma_pred)\n        log_score_term2 = -0.5 * np.log(2 * np.pi)\n        log_score_term3 = -mse / (2 * sigma_pred**2)\n        avg_log_score = log_score_term1 + log_score_term2 + log_score_term3\n\n        # Store rounded results\n        case_results = [\n            round(rmse, 6),\n            round(mae, 6),\n            round(avg_log_score, 6)\n        ]\n        all_results.append(case_results)\n\n    # Format the final output string as [[r1,r2,r3],[r1,r2,r3],...]\n    # Using str() on a list adds spaces, so we build the string manually.\n    sublist_strs = []\n    for res_list in all_results:\n        # Format each sublist as \"[v1,v2,v3]\" without spaces\n        sublist_str = f\"[{res_list[0]},{res_list[1]},{res_list[2]}]\"\n        sublist_strs.append(sublist_str)\n    \n    final_output = f\"[{','.join(sublist_strs)}]\"\n\n    print(final_output)\n\nsolve()\n```", "id": "3327278"}, {"introduction": "Effective modeling goes beyond passively evaluating predictions; it involves actively using the model to guide future research. This exercise introduces forward sensitivity analysis, a powerful technique to dissect how a model's output behavior depends on its underlying parameters. You will implement sensitivity equations for a signaling cascade model to prioritize which parameters most influence the output and to determine the most informative time points for data collection using D-optimal design principles, thereby connecting model analysis directly to efficient experimental strategy [@problem_id:3327223].", "problem": "You are given a minimal mechanistic signaling cascade described by ordinary differential equations with unknown kinetic parameters. Your task is to derive forward sensitivity equations from first principles, implement them for the model, and use the computed local sensitivities to prioritize parameters and to select informative measurement time points for parameter estimation via an information-theoretic criterion. The program you write must compute results for a provided test suite, and produce a single-line aggregated output in the format specified below.\n\nStart from the following fundamental base: a continuously differentiable dynamical system defined by the state equation $\\dot{x}(t) = f(x(t), \\theta, t)$, where $x(t) \\in \\mathbb{R}^{n}$ is the state vector, $\\theta \\in \\mathbb{R}^{p}$ is the constant parameter vector, and $f$ is smooth in its arguments. Define the local forward sensitivity matrix $S(t) = \\frac{\\partial x(t)}{\\partial \\theta} \\in \\mathbb{R}^{n \\times p}$ and the model output $y(t) \\in \\mathbb{R}^{m}$ with $y(t) = h(x(t), \\theta, t)$ sufficiently smooth. You may assume measurements are corrupted by independent, zero-mean Gaussian noise with variance $\\sigma^{2}$ per output component and time point, and that the Fisher Information Matrix (FIM) at discrete measurement times $\\{t_i\\}_{i=1}^{N}$ is given by a sum of outer products of the output sensitivities, whitened by the noise variance.\n\nModel definition. Consider a three-state receptor-kinase-reporter signaling cascade with a constant ligand input. Let $x(t) = [x_{1}(t), x_{2}(t), x_{3}(t)]^{\\top}$ denote, respectively, the ligand-bound receptor fraction, the active kinase fraction, and the phosphorylated reporter fraction. Let the total receptor, kinase, and reporter abundances be constants $R_{\\mathrm{tot}}$, $K_{\\mathrm{tot}}$, and $P_{\\mathrm{tot}}$. The ligand concentration is a constant step input $L(t) = L_{0}$. The dynamical model is\n$$\n\\begin{aligned}\n\\dot{x}_{1} &= k_{\\mathrm{on}}\\,L_{0}\\,\\big(R_{\\mathrm{tot}} - x_{1}\\big) - k_{\\mathrm{off}}\\,x_{1}, \\\\\n\\dot{x}_{2} &= k_{1}\\,x_{1}\\,\\big(K_{\\mathrm{tot}} - x_{2}\\big) - k_{2}\\,x_{2}, \\\\\n\\dot{x}_{3} &= k_{3}\\,x_{2}\\,\\big(P_{\\mathrm{tot}} - x_{3}\\big) - k_{4}\\,x_{3}.\n\\end{aligned}\n$$\nThe parameter vector is $\\theta = [k_{\\mathrm{on}}, k_{\\mathrm{off}}, k_{1}, k_{2}, k_{3}, k_{4}]^{\\top}$. The initial condition is $x(0) = [0, 0, 0]^{\\top}$. The measured output is the phosphorylated reporter, $y(t) = x_{3}(t)$.\n\nTasks to implement in your program for each test case:\n1. Derive and implement the forward sensitivity equations for $S(t) = \\frac{\\partial x(t)}{\\partial \\theta}$ associated with the model above. Use the canonical result that $S$ satisfies a linear time-varying matrix ordinary differential equation of the form $\\dot{S}(t) = A(t)\\,S(t) + B(t)$ with $S(0) = 0$, where $A(t) = \\frac{\\partial f}{\\partial x}(x(t), \\theta, t)$ and $B(t) = \\frac{\\partial f}{\\partial \\theta}(x(t), \\theta, t)$, and that $y(t) = C\\,x(t)$ with $C = [0,0,1]$ so that $\\frac{\\partial y}{\\partial \\theta}(t) = C\\,S(t)$.\n2. For a given set of candidate measurement times $\\{t_i\\}$, compute the local output sensitivities $\\frac{\\partial y}{\\partial \\theta}(t_i)$ at those times.\n3. Parameter prioritization: For a specified subset of parameters $\\mathcal{J} \\subset \\{0,1,2,3,4,5\\}$, compute a whitened, dimensionless score for each $j \\in \\mathcal{J}$ defined by\n$$\n\\mathrm{score}_{j} = \\left( \\sum_{i=1}^{N} \\frac{\\big(\\theta_{j}\\,\\frac{\\partial y}{\\partial \\theta_{j}}(t_{i})\\big)^{2}}{\\sigma^{2}} \\right)^{1/2}.\n$$\nReport the global index $j^{\\star} \\in \\mathcal{J}$ with the largest score (ties broken by the smallest index).\n4. Time-point selection by D-optimal design: For a given integer $K \\ge 1$, select $K$ distinct time indices from the candidate set to maximize the determinant of the Fisher Information Matrix over the selected times for the parameter subset $\\mathcal{J}$:\n$$\n\\mathcal{F} = \\sum_{i \\in \\mathcal{I}} \\frac{1}{\\sigma^{2}}\\,g(t_{i})\\,g(t_{i})^{\\top},\n$$\nwhere $g(t_{i}) \\in \\mathbb{R}^{|\\mathcal{J}|}$ is the vector of output sensitivities at $t_{i}$ restricted to $\\mathcal{J}$, and $\\mathcal{I}$ is the chosen index set with $|\\mathcal{I}| = K$. Return the lexicographically first index set among those maximizing the determinant (numerically compare determinants with an absolute tolerance of $10^{-12}$). If $K = 1$ and $|\\mathcal{J}| > 1$, the determinant is zero because $\\mathcal{F}$ has rank one; this is acceptable. If $K = 1$ and $|\\mathcal{J}| = 1$, the determinant equals the scalar Fisher Information.\n\nUnits: All quantities are unitless in this problem, and no angle units are involved.\n\nNumerical requirements:\n- Integrate the augmented system for $x(t)$ and $S(t)$ using a numerically stable method with sufficiently tight tolerances to ensure reproducibility.\n- Use zero-based indexing for all parameter and time-point indices in the output.\n\nTest suite. Your program must run the following three test cases, compute the requested quantities, and aggregate the results as specified. For each case, $R_{\\mathrm{tot}} = 1.0$, $K_{\\mathrm{tot}} = 1.0$, and $P_{\\mathrm{tot}} = 1.0$.\n\n- Test case 1 (general informative regime):\n  - Parameters $\\theta = [1.0, 0.2, 0.5, 0.1, 0.7, 0.1]$.\n  - Ligand level $L_{0} = 1.0$.\n  - Candidate times $t_{i}$: the grid from $0$ to $40$ in steps of $5$, i.e., $[0, 5, 10, 15, 20, 25, 30, 35, 40]$.\n  - Parameter subset $\\mathcal{J} = \\{0, 2, 4\\}$ (that is, $k_{\\mathrm{on}}$, $k_{1}$, $k_{3}$).\n  - Noise standard deviation $\\sigma = 0.05$.\n  - Select $K = 2$ time points by the D-optimality criterion.\n\n- Test case 2 (late-time, information-poor regime):\n  - Parameters $\\theta = [1.0, 1.5, 0.5, 1.0, 0.7, 1.0]$.\n  - Ligand level $L_{0} = 1.0$.\n  - Candidate times $t_{i}$: $[50, 100, 150, 200]$.\n  - Parameter subset $\\mathcal{J} = \\{0, 2\\}$ (that is, $k_{\\mathrm{on}}$, $k_{1}$).\n  - Noise standard deviation $\\sigma = 0.05$.\n  - Select $K = 2$ time points by the D-optimality criterion.\n\n- Test case 3 (single-parameter, single-time selection):\n  - Parameters $\\theta = [1.0, 0.2, 0.5, 0.1, 0.7, 0.1]$.\n  - Ligand level $L_{0} = 1.0$.\n  - Candidate times $t_{i}$: the grid from $0$ to $20$ in steps of $2$, i.e., $[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20]$.\n  - Parameter subset $\\mathcal{J} = \\{4\\}$ (that is, only $k_{3}$).\n  - Noise standard deviation $\\sigma = 0.10$.\n  - Select $K = 1$ time point by the D-optimality criterion.\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case’s result must itself be a list of four items:\n- The prioritized parameter index $j^{\\star}$ (an integer, zero-based, in the global index set $\\{0,1,2,3,4,5\\}$).\n- The first selected time index (an integer, zero-based within that test case’s candidate time array).\n- The second selected time index (an integer, zero-based within that test case’s candidate time array); if $K=1$, set this to $-1$.\n- The D-optimal determinant value for the selected set (a float).\n\nThus the program must print exactly a single line in the form:\n[[j1,t11,t12,det1],[j2,t21,t22,det2],[j3,t31,t32,det3]]", "solution": "The problem is a valid and well-posed exercise in computational systems biology, specifically addressing parameter identifiability and optimal experimental design through forward sensitivity analysis. It is scientifically grounded in the principles of chemical kinetics and information theory (Fisher Information). The model, while simplified, represents a canonical signaling cascade, and the tasks required—deriving and integrating sensitivity equations, computing parameter scores, and performing D-optimal experimental design—are standard and computationally tractable methods in the field. All necessary data and constraints for each test case are provided, and there are no internal contradictions.\n\nThe solution proceeds as follows:\nFirst, we derive the governing equations for the local forward sensitivities. Second, we formulate an augmented system of ordinary differential equations (ODEs) that combines the original model states with their sensitivities. Third, we integrate this system numerically to obtain state and sensitivity trajectories at specified time points. Fourth, using these sensitivities, we perform parameter prioritization based on a dimensionless sensitivity score. Finally, we select optimal measurement time points by maximizing the determinant of the Fisher Information Matrix (FIM), a criterion known as D-optimal design.\n\n**Derivation of the Forward Sensitivity Equations**\nThe dynamical system is given by $\\dot{x}(t) = f(x(t), \\theta)$, with the state vector $x(t) = [x_{1}(t), x_{2}(t), x_{3}(t)]^{\\top}$ and the parameter vector $\\theta = [k_{\\mathrm{on}}, k_{\\mathrm{off}}, k_{1}, k_{2}, k_{3}, k_{4}]^{\\top}$. The vector field $f$ is:\n$$\nf(x, \\theta) = \\begin{pmatrix}\n\\theta_0 L_0 (R_{\\text{tot}} - x_1) - \\theta_1 x_1 \\\\\n\\theta_2 x_1 (K_{\\text{tot}} - x_2) - \\theta_3 x_2 \\\\\n\\theta_4 x_2 (P_{\\text{tot}} - x_3) - \\theta_5 x_3\n\\end{pmatrix}\n$$\nThe sensitivity matrix $S(t) = \\frac{\\partial x(t)}{\\partial \\theta} \\in \\mathbb{R}^{3 \\times 6}$ evolves according to the matrix ODE $\\dot{S}(t) = A(t)S(t) + B(t)$, with initial condition $S(0) = 0$. The matrices $A(t) = \\frac{\\partial f}{\\partial x}$ (the Jacobian) and $B(t) = \\frac{\\partial f}{\\partial \\theta}$ are functions of the state $x(t)$ and parameters $\\theta$.\n\nThe Jacobian matrix $A(t)$ is calculated as:\n$$\nA(t) = \\frac{\\partial f}{\\partial x} = \\begin{pmatrix}\n-\\theta_0 L_0 - \\theta_1 & 0 & 0 \\\\\n\\theta_2(K_{\\text{tot}} - x_2(t)) & -\\theta_2 x_1(t) - \\theta_3 & 0 \\\\\n0 & \\theta_4(P_{\\text{tot}} - x_3(t)) & -\\theta_4 x_2(t) - \\theta_5\n\\end{pmatrix}\n$$\nThe parameter gradient matrix $B(t)$ is a $3 \\times 6$ matrix calculated as:\n$$\nB(t) = \\frac{\\partial f}{\\partial \\theta} = \\begin{pmatrix}\nL_0(R_{\\text{tot}} - x_1) & -x_1 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & x_1(K_{\\text{tot}} - x_2) & -x_2 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & x_2(P_{\\text{tot}} - x_3) & -x_3\n\\end{pmatrix}\n$$\nwhere the state dependencies $x_i(t)$ are shown without the argument for brevity.\n\n**Numerical Implementation**\nTo solve for both $x(t)$ and $S(t)$ simultaneously, we construct an augmented state vector $z(t) = [x(t)^{\\top}, \\mathrm{vec}(S(t))^{\\top}]^{\\top} \\in \\mathbb{R}^{21}$. The dynamics of this augmented system, $\\dot{z}(t)$, are defined by the original state equations and the sensitivity equations. This system of $21$ ODEs is then solved numerically using a high-fidelity integration scheme (`scipy.integrate.solve_ivp` with stringent tolerances, $rtol=10^{-8}$, $atol=10^{-10}$) from the initial condition $z(0) = 0$. The solution is evaluated at the specified candidate time points $\\{t_i\\}$. The output is $y(t) = x_{3}(t)$, so the output sensitivity with respect to parameter $\\theta_j$ is given by $\\frac{\\partial y}{\\partial \\theta_j}(t) = S_{3j}(t)$ (using $1$-based indexing for the state $x_3$ and its corresponding sensitivity row).\n\n**Parameter Prioritization**\nFor each parameter $\\theta_j$ in the specified subset $\\mathcal{J}$, a dimensionless score is computed. This score quantifies the overall influence of the parameter on the measured output $y(t)$ across all candidate time points, scaled by the parameter's nominal value and the measurement noise. The formula is:\n$$\n\\mathrm{score}_{j} = \\left( \\sum_{i=1}^{N} \\frac{\\big(\\theta_{j}\\,\\frac{\\partial y}{\\partial \\theta_{j}}(t_{i})\\big)^{2}}{\\sigma^{2}} \\right)^{1/2}\n$$\nThe parameter $j^{\\star} \\in \\mathcal{J}$ yielding the highest score is identified as the most influential, and thus a priority for accurate estimation. Ties are resolved by selecting the smallest parameter index.\n\n**D-Optimal Time Point Selection**\nThe goal is to select a subset of $K$ measurement times that are maximally informative about the parameter subset $\\mathcal{J}$. We use a D-optimality criterion, which seeks to maximize the determinant of the Fisher Information Matrix (FIM), $\\mathcal{F}$. A larger determinant corresponds to a smaller volume of the parameter confidence ellipsoid, implying more precise parameter estimates. For a set of time indices $\\mathcal{I}$ with $|\\mathcal{I}|=K$, the FIM is:\n$$\n\\mathcal{F} = \\sum_{i \\in \\mathcal{I}} \\frac{1}{\\sigma^{2}}\\,g(t_{i})\\,g(t_{i})^{\\top}\n$$\nHere, $g(t_i) \\in \\mathbb{R}^{|\\mathcal{J}|}$ is the vector of output sensitivities evaluated at time $t_i$, restricted to the parameters in $\\mathcal{J}$. We perform a combinatorial search over all possible combinations of $K$ time points from the candidate set. For each combination, we compute $\\det(\\mathcal{F})$ and identify the set of time indices that yields the maximum determinant. In cases where the number of selected time points $K$ is less than the number of parameters of interest $|\\mathcal{J}|$, the FIM will be singular and its determinant will be zero. In such scenarios, the selection is determined by the tie-breaking rule, which specifies choosing the lexicographically first set of indices that achieves the maximum determinant value.", "answer": "```python\nimport numpy as np\nfrom scipy.integrate import solve_ivp\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Main solver function that processes all test cases and prints the final result.\n    \"\"\"\n    R_TOT, K_TOT, P_TOT = 1.0, 1.0, 1.0\n\n    def augmented_ode(t, z, theta, L0):\n        \"\"\"\n        Defines the augmented ODE system for states (x) and sensitivities (S).\n        z: flattened vector [x1, x2, x3, S11, S12, ..., S36]\n        theta: parameter vector [k_on, k_off, k1, k2, k3, k4]\n        \"\"\"\n        x = z[:3]\n        S = z[3:].reshape((3, 6))\n\n        k_on, k_off, k1, k2, k3, k4 = theta\n\n        # State equations (dx/dt)\n        dx1_dt = k_on * L0 * (R_TOT - x[0]) - k_off * x[0]\n        dx2_dt = k1 * x[0] * (K_TOT - x[1]) - k2 * x[1]\n        dx3_dt = k3 * x[1] * (P_TOT - x[2]) - k4 * x[2]\n        dx_dt = np.array([dx1_dt, dx2_dt, dx3_dt])\n\n        # Jacobian matrix A = df/dx\n        A = np.zeros((3, 3))\n        A[0, 0] = -k_on * L0 - k_off\n        A[1, 0] = k1 * (K_TOT - x[1])\n        A[1, 1] = -k1 * x[0] - k2\n        A[2, 1] = k3 * (P_TOT - x[2])\n        A[2, 2] = -k3 * x[1] - k4\n        \n        # Gradient matrix B = df/d_theta\n        B = np.zeros((3, 6))\n        B[0, 0] = L0 * (R_TOT - x[0])\n        B[0, 1] = -x[0]\n        B[1, 2] = x[0] * (K_TOT - x[1])\n        B[1, 3] = -x[1]\n        B[2, 4] = x[1] * (P_TOT - x[2])\n        B[2, 5] = -x[2]\n\n        # Sensitivity equations dS/dt = A*S + B\n        dS_dt = A @ S + B\n\n        dz_dt = np.concatenate((dx_dt, dS_dt.flatten()))\n        return dz_dt\n\n    def solve_for_case(case_params):\n        \"\"\"\n        Processes a single test case.\n        \"\"\"\n        theta, L0, candidate_times, param_subset_J, sigma, K = case_params\n        \n        # 1. Integrate the augmented ODE system\n        ode_func = lambda t, z: augmented_ode(t, z, np.array(theta), L0)\n        z0 = np.zeros(3 + 3 * 6)\n        t_span = (0, max(candidate_times) if candidate_times else 0)\n        \n        if t_span[1] == 0:\n            sol_y = z0.reshape(-1, 1) if candidate_times else np.array([[] for _ in range(len(z0))])\n            if candidate_times:\n                 sol_y = np.tile(z0.reshape(-1, 1), (1, len(candidate_times)))\n        else:\n            sol = solve_ivp(\n                ode_func, t_span, z0, t_eval=candidate_times,\n                method='RK45', rtol=1e-8, atol=1e-10\n            )\n            sol_y = sol.y\n\n        # Output sensitivity dy/d_theta = dx3/d_theta is the 3rd row of S (index 2)\n        num_times = len(candidate_times)\n        output_sens = np.zeros((6, num_times))\n        for j in range(6):\n            output_sens[j, :] = sol_y[3 + 2 * 6 + j, :]\n\n        # 2. Parameter prioritization\n        scores = {}\n        for j in param_subset_J:\n            sens_j_values = output_sens[j, :]\n            theta_j = theta[j]\n            sum_sq = np.sum(((theta_j * sens_j_values) / sigma)**2)\n            scores[j] = np.sqrt(sum_sq)\n\n        j_star = -1\n        max_score = -1.0\n        for j in sorted(list(param_subset_J)):\n            if scores[j] > max_score:\n                max_score = scores[j]\n                j_star = j\n            \n        # 3. Time-point selection by D-optimality\n        num_candidates = len(candidate_times)\n        candidate_indices = range(num_candidates)\n        \n        best_indices = None\n        max_det = -1.0\n        \n        g_all_times = output_sens[list(sorted(list(param_subset_J))), :]\n        \n        for current_indices in combinations(candidate_indices, K):\n            fim_dim = len(param_subset_J)\n            fim = np.zeros((fim_dim, fim_dim))\n            \n            for i_time in current_indices:\n                g_ti = g_all_times[:, i_time]\n                fim += np.outer(g_ti, g_ti)\n            \n            fim /= (sigma**2)\n            current_det = np.linalg.det(fim)\n            \n            if current_det > max_det + 1e-12:\n                max_det = current_det\n                best_indices = current_indices\n        \n        # Handle cases where all determinants are zero, e.g., K  |J|\n        if best_indices is None and K = num_candidates:\n            best_indices = next(combinations(candidate_indices, K))\n            max_det = 0.0\n\n        t_indices_out = list(best_indices)\n        if K == 1:\n            t_indices_out.append(-1)\n\n        return [j_star, t_indices_out[0], t_indices_out[1], max_det]\n\n    test_cases = [\n        # Test case 1\n        ([1.0, 0.2, 0.5, 0.1, 0.7, 0.1], 1.0, list(np.arange(0, 40.1, 5.0)),\n         {0, 2, 4}, 0.05, 2),\n        # Test case 2\n        ([1.0, 1.5, 0.5, 1.0, 0.7, 1.0], 1.0, [50., 100., 150., 200.],\n         {0, 2}, 0.05, 2),\n        # Test case 3\n        ([1.0, 0.2, 0.5, 0.1, 0.7, 0.1], 1.0, list(np.arange(0, 20.1, 2.0)),\n         {4}, 0.10, 1),\n    ]\n\n    results = []\n    for case in test_cases:\n        results.append(solve_for_case(case))\n        \n    print(f\"[{','.join(f'[{r[0]},{r[1]},{r[2]},{r[3]}]' for r in results)}]\")\n\nsolve()\n```", "id": "3327223"}, {"introduction": "In Bayesian modeling, it is not enough for a model to make accurate predictions; the entire inferential procedure must be statistically sound and its uncertainty quantification reliable. This practice delves into advanced Bayesian validation techniques, moving beyond simple goodness-of-fit. You will implement posterior predictive checks using the Wasserstein distance to diagnose model misfit and, critically, use simulation-based calibration (SBC) to assess whether your Bayesian inference workflow is well-calibrated, ensuring that your posterior distributions are trustworthy representations of parameter uncertainty [@problem_id:3327305].", "problem": "You are asked to implement posterior predictive checks and simulation-based calibration for a stochastic gene regulatory network modeled as a linear birth-death process for messenger ribonucleic acid (mRNA) counts. The model assumes a single gene producing mRNA at a constant transcription rate $k$ and degradation at rate $\\gamma$, starting from $y(0) = 0$. For independent cell observations at fixed times $t$, the generative model implies that the mRNA count $Y(t)$ follows a discrete distribution.\n\nBase principles and definitions:\n- The linear birth-death process with constant immigration rate $k$ and linear death rate $\\gamma$ is a classical stochastic process in chemical kinetics. The mean $\\mu(t)$ of $Y(t)$ solves the ordinary differential equation $d\\mu(t)/dt = k - \\gamma \\mu(t)$ with $\\mu(0) = 0$, yielding $\\mu(t) = \\frac{k}{\\gamma}\\left(1 - e^{-\\gamma t}\\right)$.\n- The Poisson superposition and thinning properties imply that the integrated effect of a constant-rate birth process with linear decay leads to a count distribution that is Poisson with mean $\\mu(t)$. Therefore $Y(t) \\sim \\operatorname{Poisson}(\\mu(t))$ for each fixed $t$ under this model.\n- For independent observations $\\{y_i\\}_{i=1}^n$ at times $\\{t_i\\}$ with known $\\gamma$, the likelihood for $k$ factorizes as $y_i \\sim \\operatorname{Poisson}(c_i k)$ where $c_i = \\frac{1 - e^{-\\gamma t_i}}{\\gamma}$.\n- With a Gamma prior on $k$, denoted $k \\sim \\operatorname{Gamma}(\\alpha_0, \\beta_0)$ in the shape-rate parameterization, the posterior is $k \\mid \\{y_i,t_i\\} \\sim \\operatorname{Gamma}(\\alpha_0 + \\sum_i y_i, \\beta_0 + \\sum_i c_i)$.\n\nYour tasks:\n1) Posterior predictive checks across time using the first Wasserstein distance. For each test case below, generate an observed dataset by sampling the specified number of cells at each time $t$ from the model with the given true parameters. Using a Gamma prior on $k$, compute the posterior distribution over $k$ by pooling all observations across times using the model that $y_i \\sim \\operatorname{Poisson}(c_i k)$ with $c_i = \\frac{1 - e^{-\\gamma_{\\text{assumed}} t_i}}{\\gamma_{\\text{assumed}}}$. Let $\\hat{k}$ be the posterior mean $\\hat{k} = \\frac{\\alpha_{\\text{post}}}{\\beta_{\\text{post}}}$. Define the model-predicted distribution at time $t$ as $p_{\\text{pred}}(y \\mid t, \\hat{k}) = \\operatorname{Poisson}\\left(\\hat{k}\\,\\frac{1 - e^{-\\gamma_{\\text{assumed}} t}}{\\gamma_{\\text{assumed}}}\\right)$. Let $p_{\\text{obs}}(y \\mid t)$ be the empirical distribution of the observed sample at time $t$. For each $t$ in the test case, approximate the one-dimensional first Wasserstein distance $W\\!\\left(p_{\\text{pred}}(\\cdot \\mid \\hat{k}), p_{\\text{obs}}\\right)$ by drawing a synthetic sample from $p_{\\text{pred}}(\\cdot \\mid t, \\hat{k})$ of the same size as the observed sample and using the standard one-dimensional Wasserstein distance between the two samples. Report the average of these distances across the times in the test case as a single float for that case.\n\n2) Simulation-based calibration (SBC) via rank statistics. For each test case, define a prior $k \\sim \\operatorname{Gamma}(\\alpha_0,\\beta_0)$ on the transcription rate. Repeat the following for $R$ replications: sample $k^{(r)}$ from the prior, generate a dataset at the specified times using the true degradation rate $\\gamma_{\\text{true}}$, compute the posterior $k \\mid \\text{data}$ under the assumed $\\gamma_{\\text{assumed}}$ and the same prior, draw $M$ independent posterior samples $\\{\\tilde{k}_m^{(r)}\\}_{m=1}^M$, and compute the rank statistic $r^{(r)} = \\#\\{m : \\tilde{k}_m^{(r)}  k^{(r)}\\}$, which lies in $\\{0,1,\\dots,M\\}$ for continuous posteriors. Aggregate $\\{r^{(r)}\\}_{r=1}^R$ into a histogram over $\\{0,\\dots,M\\}$ and perform a chi-squared goodness-of-fit test against the discrete uniform distribution. Let $p_{\\text{SBC}}$ be the resulting p-value. Define a calibration pass indicator as $\\text{pass} = \\text{True}$ if $p_{\\text{SBC}} \\ge \\alpha$ and $\\text{False}$ otherwise, for the provided significance level $\\alpha$ in the test case. Report this boolean for each case.\n\nComputational and statistical details:\n- All random number generation must be reproducible by setting a fixed seed at the beginning of your program.\n- Use the shape-rate parameterization for the Gamma distribution. If you use libraries that parameterize Gamma by shape-scale, you must convert using $\\text{scale} = 1/\\text{rate}$.\n- The first Wasserstein distance in one dimension may be computed using the standard definition in terms of integrals of quantile functions; in code, you may use any numerically correct implementation for one-dimensional samples that returns a nonnegative real value.\n\nTest suite:\nImplement your program to run the following three test cases. For each case, generate an observed dataset for the posterior predictive checks using the specified $k_\\star$ and $\\gamma_{\\text{true}}$, and use the same data to compute the posterior and $\\hat{k}$.\n\n- Case 1 (well-specified, informative):\n  - $\\gamma_{\\text{true}} = 1.1$\n  - $\\gamma_{\\text{assumed}} = 1.1$\n  - Times $t \\in \\{0.2, 0.6, 1.0, 2.0\\}$\n  - Cells per time $N = 200$\n  - Prior on $k$: $k \\sim \\operatorname{Gamma}(\\alpha_0 = 2.0, \\beta_0 = 0.3)$\n  - Data-generation transcription rate for posterior predictive checks: $k_\\star = 7.0$\n  - SBC settings: $R = 840$ replications, $M = 20$ posterior samples per replication, significance $\\alpha = 0.01$\n\n- Case 2 (misspecified degradation rate):\n  - $\\gamma_{\\text{true}} = 1.1$\n  - $\\gamma_{\\text{assumed}} = 2.2$\n  - Times $t \\in \\{0.2, 0.6, 1.0, 2.0\\}$\n  - Cells per time $N = 200$\n  - Prior on $k$: $k \\sim \\operatorname{Gamma}(\\alpha_0 = 2.0, \\beta_0 = 0.3)$\n  - Data-generation transcription rate for posterior predictive checks: $k_\\star = 7.0$\n  - SBC settings: $R = 840$, $M = 20$, $\\alpha = 0.01$\n\n- Case 3 (edge case: small samples and early times):\n  - $\\gamma_{\\text{true}} = 1.0$\n  - $\\gamma_{\\text{assumed}} = 1.0$\n  - Times $t \\in \\{0.05, 0.1, 0.2, 0.4\\}$\n  - Cells per time $N = 20$\n  - Prior on $k$: $k \\sim \\operatorname{Gamma}(\\alpha_0 = 1.5, \\beta_0 = 0.5)$\n  - Data-generation transcription rate for posterior predictive checks: $k_\\star = 5.0$\n  - SBC settings: $R = 420$, $M = 20$, $\\alpha = 0.01$\n\nRequired final output:\n- Your program must produce a single line containing a Python list where, for each case in order, you append two entries: first, the average Wasserstein distance across times as a float; second, the SBC calibration pass indicator as a boolean. Therefore, the final output must be a single line in the exact format\n  \"[w1,pass1,w2,pass2,w3,pass3]\"\nwith no additional text, where $w1$, $w2$, and $w3$ are floats and $pass1$, $pass2$, and $pass3$ are booleans.", "solution": "The user has provided a valid, well-posed, and scientifically grounded problem in computational systems biology. The task is to implement and apply two standard model validation techniques—posterior predictive checks (PPC) and simulation-based calibration (SBC)—to a stochastic model of gene expression.\n\nThe model describes the number of messenger ribonucleic acid (mRNA) molecules, $Y(t)$, at time $t$ for a single gene. The dynamics are modeled as a linear birth-death process with a constant transcription (birth) rate $k$ and a first-order degradation (death) rate $\\gamma$. Assuming an initial state of zero mRNA molecules, $Y(0)=0$, the count $Y(t)$ at any time $t>0$ follows a Poisson distribution, $Y(t) \\sim \\operatorname{Poisson}(\\mu(t))$. The mean of this distribution, $\\mu(t)$, is given by the solution to the ordinary differential equation for the average molecule count, which is $\\mu(t) = \\frac{k}{\\gamma}\\left(1 - e^{-\\gamma t}\\right)$.\n\nFor Bayesian inference on the transcription rate $k$, a conjugate prior is used. Given a Gamma prior on $k$, $k \\sim \\operatorname{Gamma}(\\alpha_0, \\beta_0)$, where $\\alpha_0$ is the shape and $\\beta_0$ is the rate, and a set of independent observations $\\{y_i\\}_{i=1}^n$ at corresponding times $\\{t_i\\}_{i=1}^n$, the posterior distribution for $k$ is also a Gamma distribution. The likelihood for a single observation $y_i$ is $\\operatorname{Poisson}(k \\cdot c_i)$, where $c_i = \\frac{1 - e^{-\\gamma t_i}}{\\gamma}$ is a time-dependent constant (assuming $\\gamma$ is known). Due to the properties of the Gamma-Poisson conjugate model, the posterior distribution is given by:\n$$\nk \\mid \\{y_i,t_i\\} \\sim \\operatorname{Gamma}\\left(\\alpha_0 + \\sum_{i=1}^n y_i, \\beta_0 + \\sum_{i=1}^n c_i\\right)\n$$\nWe denote the posterior parameters as $\\alpha_{\\text{post}} = \\alpha_0 + \\sum y_i$ and $\\beta_{\\text{post}} = \\beta_0 + \\sum c_i$.\n\nThe implementation will consist of two main parts, corresponding to the two tasks specified.\n\n**Task 1: Posterior Predictive Checks (PPC)**\n\nThe goal of PPC is to assess the goodness-of-fit of the model by comparing observed data to data simulated from the fitted model. For each test case, the procedure is as follows:\n$1$. **Generate an \"observed\" dataset**: For each specified time $t$ in the test case, we generate $N$ samples from the Poisson distribution with its mean calculated using the true parameters $k_\\star$ and $\\gamma_{\\text{true}}$. This simulates collecting data from $N$ independent cells. The mean is $\\mu_{\\text{true}}(t) = \\frac{k_\\star}{\\gamma_{\\text{true}}}\\left(1 - e^{-\\gamma_{\\text{true}} t}\\right)$.\n$2$. **Perform Bayesian inference**: Using the entire dataset generated in step $1$ (pooling data from all time points), we compute the posterior distribution of $k$. This step uses the specified prior $\\operatorname{Gamma}(\\alpha_0, \\beta_0)$ and the assumed degradation rate $\\gamma_{\\text{assumed}}$. The posterior parameters are $\\alpha_{\\text{post}} = \\alpha_0 + \\sum y_i$ and $\\beta_{\\text{post}} = \\beta_0 + \\sum_i N \\cdot \\frac{1 - e^{-\\gamma_{\\text{assumed}} t_i}}{\\gamma_{\\text{assumed}}}$.\n$3$. **Estimate transcription rate**: The point estimate for the transcription rate, $\\hat{k}$, is taken as the mean of the posterior distribution, $\\hat{k} = \\alpha_{\\text{post}} / \\beta_{\\text{post}}$.\n$4$. **Generate a \"predicted\" dataset**: For each time $t$, we generate a new synthetic dataset of size $N$ from the model, using the estimated parameter $\\hat{k}$ and the assumed degradation rate $\\gamma_{\\text{assumed}}$. The distribution for this is $p_{\\text{pred}}(y \\mid t, \\hat{k}) = \\operatorname{Poisson}\\left(\\hat{k} \\frac{1 - e^{-\\gamma_{\\text{assumed}} t}}{\\gamma_{\\text{assumed}}}\\right)$.\n$5$. **Calculate discrepancy**: The discrepancy between the observed and predicted data at each time $t$ is quantified using the first Wasserstein distance, $W_1$. For two one-dimensional empirical distributions represented by samples $u = \\{u_j\\}_{j=1}^N$ and $v = \\{v_j\\}_{j=1}^N$, the distance is calculated as $W_1 = \\frac{1}{N} \\sum_{j=1}^N |u_{(j)} - v_{(j)}|$, where $u_{(j)}$ and $v_{(j)}$ are the $j$-th order statistics (i.e., the sorted samples).\n$6$. **Average the discrepancy**: The final result for this task is the average of the Wasserstein distances computed across all time points.\n\n**Task 2: Simulation-Based Calibration (SBC)**\n\nSBC is a method to diagnose potential miscalibration in a Bayesian inference procedure. It checks whether, on average, the posterior distributions correctly represent the uncertainty about parameters. The procedure requires a simulation loop:\n$1$. **Define prior and simulation parameters**: We use the prior $k \\sim \\operatorname{Gamma}(\\alpha_0,\\beta_0)$ and simulation settings ($R$ replications, $M$ posterior samples).\n$2$. **Execute $R$ replications**: For each replication $r=1, \\dots, R$:\n    a. A \"true\" parameter value $k^{(r)}$ is drawn from the prior distribution: $k^{(r)} \\sim \\operatorname{Gamma}(\\alpha_0, \\beta_0)$.\n    b. A synthetic dataset is generated using this $k^{(r)}$ and the true degradation rate, $\\gamma_{\\text{true}}$.\n    c. Bayesian inference is performed on this synthetic dataset using the same prior and the assumed degradation rate $\\gamma_{\\text{assumed}}$ to obtain the posterior $\\operatorname{Gamma}(\\alpha_{\\text{post}}^{(r)}, \\beta_{\\text{post}}^{(r)})$.\n    d. $M$ samples, $\\{\\tilde{k}_m^{(r)}\\}_{m=1}^M$, are drawn from this posterior distribution.\n    e. The rank statistic is computed: $r^{(r)} = \\sum_{m=1}^M \\mathbb{I}(\\tilde{k}_m^{(r)}  k^{(r)})$, where $\\mathbb{I}(\\cdot)$ is the indicator function. The rank counts how many posterior samples are smaller than the true value used to generate the data.\n$3$. **Analyze rank distribution**: A well-calibrated inference procedure should produce ranks that are uniformly distributed on the integers $\\{0, 1, \\dots, M\\}$. We collect all $R$ ranks and form a histogram with $M+1$ bins.\n$4$. **Statistical Test**: A chi-squared ($\\chi^2$) goodness-of-fit test is performed to check if the observed distribution of ranks is consistent with a discrete uniform distribution. The expected frequency for each rank is $E = R / (M+1)$.\n$5$. **Calibration Verdict**: The p-value from the $\\chi^2$ test, $p_{\\text{SBC}}$, is compared against a pre-defined significance level $\\alpha$. The calibration is considered to \"pass\" if $p_{\\text{SBC}} \\ge \\alpha$, indicating no significant deviation from uniformity. A \"fail\" ($p_{\\text{SBC}}  \\alpha$) suggests the inference procedure is miscalibrated, which is expected when the model is misspecified (e.g., $\\gamma_{\\text{assumed}} \\ne \\gamma_{\\text{true}}$).\n\nThe code will implement these two procedures for each of the three test cases provided, ensuring reproducibility by using a fixed random seed.", "answer": "```python\n# A solver agent that generates a solution and final answer for a given problem.\nimport numpy as np\nfrom scipy.stats import chisquare\n\ndef run_posterior_predictive_check(case, rng):\n    \"\"\"\n    Performs the posterior predictive check and computes the average Wasserstein distance.\n    \"\"\"\n    # Unpack case parameters\n    gamma_true = case['gamma_true']\n    gamma_assumed = case['gamma_assumed']\n    times = np.array(case['times'])\n    N = case['N']\n    prior_alpha = case['prior_alpha']\n    prior_beta = case['prior_beta']\n    k_star = case['k_star']\n\n    # 1. Generate an \"observed\" dataset using true parameters\n    observed_data_by_time = {}\n    all_y_obs = []\n    \n    for t in times:\n        mu_true = (k_star / gamma_true) * (1 - np.exp(-gamma_true * t))\n        y_obs_at_t = rng.poisson(mu_true, size=N)\n        observed_data_by_time[t] = y_obs_at_t\n        all_y_obs.extend(y_obs_at_t)\n\n    # 2. Compute posterior using the generated data and assumed gamma\n    sum_y = np.sum(all_y_obs)\n    \n    # Calculate sum c_i for posterior beta\n    c_coeffs = (1 - np.exp(-gamma_assumed * times)) / gamma_assumed\n    sum_c = N * np.sum(c_coeffs)\n\n    alpha_post = prior_alpha + sum_y\n    beta_post = prior_beta + sum_c\n    \n    # 3. Estimate k as posterior mean\n    k_hat = alpha_post / beta_post\n    \n    # 4. Compute Wasserstein distances\n    wasserstein_distances = []\n    for i, t in enumerate(times):\n        # Generate predicted data\n        mu_pred = k_hat * c_coeffs[i]\n        \n        # Guard against non-positive means in edge cases\n        if mu_pred = 0:\n            y_pred = np.zeros(N, dtype=int)\n        else:\n            y_pred = rng.poisson(mu_pred, size=N)\n        \n        # Retrieve observed data for this time point\n        y_obs_at_t = observed_data_by_time[t]\n        \n        # Calculate 1D Wasserstein distance\n        y_obs_sorted = np.sort(y_obs_at_t)\n        y_pred_sorted = np.sort(y_pred)\n        w_dist = np.mean(np.abs(y_obs_sorted - y_pred_sorted))\n        wasserstein_distances.append(w_dist)\n        \n    return np.mean(wasserstein_distances)\n\ndef run_simulation_based_calibration(case, rng):\n    \"\"\"\n    Performs simulation-based calibration and returns the pass/fail indicator.\n    \"\"\"\n    # Unpack case parameters\n    gamma_true = case['gamma_true']\n    gamma_assumed = case['gamma_assumed']\n    times = np.array(case['times'])\n    N = case['N']\n    prior_alpha = case['prior_alpha']\n    prior_beta = case['prior_beta']\n    R = case['R']\n    M = case['M']\n    alpha_sig = case['alpha_sig']\n\n    ranks = np.zeros(R, dtype=int)\n    \n    # Pre-calculate sum of c_i coefficients, which is constant across replications\n    c_coeffs_assumed = (1 - np.exp(-gamma_assumed * times)) / gamma_assumed\n    sum_c_for_posterior = N * np.sum(c_coeffs_assumed)\n\n    for r in range(R):\n        # 1. Sample k_true from the prior\n        k_true_r = rng.gamma(shape=prior_alpha, scale=1.0/prior_beta)\n        \n        # 2. Generate synthetic data using k_true_r and gamma_true\n        sum_y = 0\n        mean_rates_true = (k_true_r / gamma_true) * (1 - np.exp(-gamma_true * times))\n        for mu_true in mean_rates_true:\n            # Poisson mean must be non-negative\n            if mu_true = 0: continue\n            y_obs_t = rng.poisson(mu_true, size=N)\n            sum_y += np.sum(y_obs_t)\n            \n        # 3. Compute posterior for k\n        alpha_post = prior_alpha + sum_y\n        beta_post = prior_beta + sum_c_for_posterior\n        \n        # 4. Draw samples from the posterior\n        k_posterior_samples = rng.gamma(shape=alpha_post, scale=1.0/beta_post, size=M)\n        \n        # 5. Compute the rank statistic\n        rank = np.sum(k_posterior_samples  k_true_r)\n        ranks[r] = rank\n        \n    # 6. Perform Chi-squared goodness-of-fit test\n    # Bins are 0, 1, ..., M, for a total of M+1 bins\n    observed_counts = np.bincount(ranks, minlength=M + 1)\n    \n    # Expected count per bin under the uniform hypothesis\n    expected_count = R / (M + 1)\n    \n    _, p_value = chisquare(f_obs=observed_counts, f_exp=expected_count)\n    \n    # 7. Return calibration pass indicator\n    return p_value >= alpha_sig\n\ndef solve():\n    # Set a fixed seed for reproducibility.\n    RNG = np.random.default_rng(seed=12345)\n\n    test_cases = [\n        # Case 1: well-specified model\n        {\n            'gamma_true': 1.1, 'gamma_assumed': 1.1, \n            'times': [0.2, 0.6, 1.0, 2.0], 'N': 200,\n            'prior_alpha': 2.0, 'prior_beta': 0.3, \n            'k_star': 7.0, 'R': 840, 'M': 20, 'alpha_sig': 0.01\n        },\n        # Case 2: misspecified model (gamma is wrong)\n        {\n            'gamma_true': 1.1, 'gamma_assumed': 2.2, \n            'times': [0.2, 0.6, 1.0, 2.0], 'N': 200,\n            'prior_alpha': 2.0, 'prior_beta': 0.3, \n            'k_star': 7.0, 'R': 840, 'M': 20, 'alpha_sig': 0.01\n        },\n        # Case 3: edge case (small samples, early times)\n        {\n            'gamma_true': 1.0, 'gamma_assumed': 1.0, \n            'times': [0.05, 0.1, 0.2, 0.4], 'N': 20,\n            'prior_alpha': 1.5, 'prior_beta': 0.5, \n            'k_star': 5.0, 'R': 420, 'M': 20, 'alpha_sig': 0.01\n        },\n    ]\n\n    final_results = []\n    \n    for case in test_cases:\n        # Task 1: Posterior Predictive Checks\n        avg_w_dist = run_posterior_predictive_check(case, RNG)\n        \n        # Task 2: Simulation-Based Calibration\n        sbc_pass = run_simulation_based_calibration(case, RNG)\n\n        final_results.extend([avg_w_dist, sbc_pass])\n\n    # Format the boolean values to lowercase as per Python's str() behavior\n    formatted_results = [f\"{x:.10f}\" if isinstance(x, float) else str(x).lower() for x in final_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3327305"}]}