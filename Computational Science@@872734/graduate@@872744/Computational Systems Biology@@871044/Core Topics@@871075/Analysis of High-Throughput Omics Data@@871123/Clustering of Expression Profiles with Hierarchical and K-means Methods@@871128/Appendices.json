{"hands_on_practices": [{"introduction": "Before any clustering algorithm can be applied, we must first define how to measure the similarity or dissimilarity between data points. This exercise explores the critical impact of data normalization and metric choice on the analysis of gene expression profiles. By comparing raw Euclidean distance with cosine similarity on z-scored data, you will gain hands-on experience in how these choices can fundamentally alter the perceived relationships between samples, a crucial consideration in computational biology [@problem_id:3295705].", "problem": "A laboratory has profiled gene expression for $4$ samples across $6$ genes, yielding the following synthetic but biologically plausible dataset, with values in transcripts per million (TPM). Let samples be denoted $S_{1}, S_{2}, S_{3}, S_{4}$ and genes be denoted $G_{1}, \\dots, G_{6}$. The measurements are:\n- $G_{1}$: $S_{1}=100$, $S_{2}=150$, $S_{3}=95$, $S_{4}=60$\n- $G_{2}$: $S_{1}=50$, $S_{2}=75$, $S_{3}=49$, $S_{4}=30$\n- $G_{3}$: $S_{1}=10$, $S_{2}=15$, $S_{3}=12$, $S_{4}=8$\n- $G_{4}$: $S_{1}=5$, $S_{2}=8$, $S_{3}=4$, $S_{4}=7$\n- $G_{5}$: $S_{1}=200$, $S_{2}=290$, $S_{3}=210$, $S_{4}=170$\n- $G_{6}$: $S_{1}=100$, $S_{2}=155$, $S_{3}=90$, $S_{4}=120$\n\nYou will compare sample neighborhoods under two metrics commonly used in clustering of expression profiles: raw Euclidean distance on the original data, and cosine similarity computed after gene-wise $z$-scoring.\n\nBase your reasoning and calculations only on the following core definitions.\n- For raw Euclidean distance between two samples $S_{i}$ and $S_{j}$ with expression vectors $\\mathbf{x}_{i}, \\mathbf{x}_{j} \\in \\mathbb{R}^{6}$, use $d_{E}(i,j) = \\|\\mathbf{x}_{i} - \\mathbf{x}_{j}\\|_{2} = \\sqrt{\\sum_{g=1}^{6} (x_{gi} - x_{gj})^{2}}$.\n- For gene-wise $z$-scoring, for each gene $g$ with values across $n=4$ samples, compute the population mean $\\mu_{g} = \\frac{1}{n}\\sum_{s=1}^{n} x_{gs}$ and the population standard deviation $\\sigma_{g} = \\sqrt{\\frac{1}{n}\\sum_{s=1}^{n} (x_{gs}-\\mu_{g})^{2}}$, then transform $x_{gs}$ to $z_{gs} = \\frac{x_{gs} - \\mu_{g}}{\\sigma_{g}}$.\n- For cosine similarity between two $z$-scored sample vectors $\\mathbf{z}_{i}, \\mathbf{z}_{j} \\in \\mathbb{R}^{6}$, use $\\cos(i,j) = \\frac{\\mathbf{z}_{i}^{\\top}\\mathbf{z}_{j}}{\\|\\mathbf{z}_{i}\\|_{2}\\,\\|\\mathbf{z}_{j}\\|_{2}}$.\n\nProceed as follows.\n1. Compute all pairwise raw Euclidean distances $d_{E}(i,j)$ between samples and, for each sample $S_{i}$, identify its nearest neighbor under $d_{E}$ as the distinct sample $S_{j}$ minimizing $d_{E}(i,j)$.\n2. Perform gene-wise $z$-scoring across the $4$ samples to obtain $z_{gs}$ for all genes and samples. Compute all pairwise cosine similarities $\\cos(i,j)$ between the $z$-scored sample vectors and, for each sample $S_{i}$, identify its nearest neighbor under cosine similarity as the distinct sample $S_{j}$ maximizing $\\cos(i,j)$.\n3. Let $\\Delta$ be the proportion (as a decimal) of samples whose nearest neighbor under cosine similarity is different from their nearest neighbor under raw Euclidean distance.\n\nWhat is the value of $\\Delta$? Express your final answer as a single decimal number. If you need to round, round your final result to four significant figures; otherwise, provide the exact value.", "solution": "The problem requires a comparison of nearest neighbors for $4$ gene expression samples under two different metrics: raw Euclidean distance and cosine similarity on $z$-scored data. We will proceed by first validating the problem, then performing the calculations in three distinct steps as requested.\n\n### Problem Validation\n**Step 1: Extract Givens**\n- Data: A $6 \\times 4$ matrix of gene expression values (in TPM) for $6$ genes ($G_1, \\dots, G_6$) and $4$ samples ($S_1, \\dots, S_4$).\n  - $G_{1}$: $S_{1}=100$, $S_{2}=150$, $S_{3}=95$, $S_{4}=60$\n  - $G_{2}$: $S_{1}=50$, $S_{2}=75$, $S_{3}=49$, $S_{4}=30$\n  - $G_{3}$: $S_{1}=10$, $S_{2}=15$, $S_{3}=12$, $S_{4}=8$\n  - $G_{4}$: $S_{1}=5$, $S_{2}=8$, $S_{3}=4$, $S_{4}=7$\n  - $G_{5}$: $S_{1}=200$, $S_{2}=290$, $S_{3}=210$, $S_{4}=170$\n  - $G_{6}$: $S_{1}=100$, $S_{2}=155$, $S_{3}=90$, $S_{4}=120$\n- Definitions:\n  - Raw Euclidean distance: $d_{E}(i,j) = \\|\\mathbf{x}_{i} - \\mathbf{x}_{j}\\|_{2} = \\sqrt{\\sum_{g=1}^{6} (x_{gi} - x_{gj})^{2}}$.\n  - Gene-wise $z$-scoring: For each gene $g$, use population mean $\\mu_{g} = \\frac{1}{n}\\sum_{s=1}^{n} x_{gs}$ and population standard deviation $\\sigma_{g} = \\sqrt{\\frac{1}{n}\\sum_{s=1}^{n} (x_{gs}-\\mu_{g})^{2}}$ with $n=4$. The transformed value is $z_{gs} = \\frac{x_{gs} - \\mu_{g}}{\\sigma_{g}}$.\n  - Cosine similarity: $\\cos(i,j) = \\frac{\\mathbf{z}_{i}^{\\top}\\mathbf{z}_{j}}{\\|\\mathbf{z}_{i}\\|_{2}\\,\\|\\mathbf{z}_{j}\\|_{2}}$.\n- Task:\n  1. Find the nearest neighbor for each sample under $d_E$.\n  2. Find the nearest neighbor for each sample under cosine similarity (maximizing the value).\n  3. Compute $\\Delta$, the proportion of samples for which the nearest neighbor changes between the two metrics.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, using standard methods from computational biology. The definitions are precise and unambiguous, making the problem well-posed. Although using a population standard deviation formula for a small sample might be debated in a real-world analysis, it is explicitly defined here and thus part of a self-contained, valid problem. The problem is objective and complete.\n\n**Step 3: Verdict and Action**\nThe problem is valid. I will proceed with the solution.\n\n### Step 1: Raw Euclidean Distances and Nearest Neighbors\nLet the sample vectors be $\\mathbf{x}_1, \\mathbf{x}_2, \\mathbf{x}_3, \\mathbf{x}_4$, which are the columns of the data matrix.\n$\\mathbf{x}_1 = (100, 50, 10, 5, 200, 100)^{\\top}$\n$\\mathbf{x}_2 = (150, 75, 15, 8, 290, 155)^{\\top}$\n$\\mathbf{x}_3 = (95, 49, 12, 4, 210, 90)^{\\top}$\n$\\mathbf{x}_4 = (60, 30, 8, 7, 170, 120)^{\\top}$\n\nWe compute the squared Euclidean distance $d_E^2(i,j) = \\sum_{g=1}^{6} (x_{gi} - x_{gj})^{2}$ for all pairs $i \\neq j$.\n\n$d_E^2(1, 2) = (100-150)^2 + (50-75)^2 + (10-15)^2 + (5-8)^2 + (200-290)^2 + (100-155)^2 = (-50)^2 + (-25)^2 + (-5)^2 + (-3)^2 + (-90)^2 + (-55)^2 = 2500 + 625 + 25 + 9 + 8100 + 3025 = 14284$.\n\n$d_E^2(1, 3) = (100-95)^2 + (50-49)^2 + (10-12)^2 + (5-4)^2 + (200-210)^2 + (100-90)^2 = 5^2 + 1^2 + (-2)^2 + 1^2 + (-10)^2 + 10^2 = 25 + 1 + 4 + 1 + 100 + 100 = 231$.\n\n$d_E^2(1, 4) = (100-60)^2 + (50-30)^2 + (10-8)^2 + (5-7)^2 + (200-170)^2 + (100-120)^2 = 40^2 + 20^2 + 2^2 + (-2)^2 + 30^2 + (-20)^2 = 1600 + 400 + 4 + 4 + 900 + 400 = 3308$.\n\n$d_E^2(2, 3) = (150-95)^2 + (75-49)^2 + (15-12)^2 + (8-4)^2 + (290-210)^2 + (155-90)^2 = 55^2 + 26^2 + 3^2 + 4^2 + 80^2 + 65^2 = 3025 + 676 + 9 + 16 + 6400 + 4225 = 14351$.\n\n$d_E^2(2, 4) = (150-60)^2 + (75-30)^2 + (15-8)^2 + (8-7)^2 + (290-170)^2 + (155-120)^2 = 90^2 + 45^2 + 7^2 + 1^2 + 120^2 + 35^2 = 8100 + 2025 + 49 + 1 + 14400 + 1225 = 25800$.\n\n$d_E^2(3, 4) = (95-60)^2 + (49-30)^2 + (12-8)^2 + (4-7)^2 + (210-170)^2 + (90-120)^2 = 35^2 + 19^2 + 4^2 + (-3)^2 + 40^2 + (-30)^2 = 1225 + 361 + 16 + 9 + 1600 + 900 = 4111$.\n\nFor each sample $S_i$, its nearest neighbor is $S_j$ that minimizes $d_E(i,j)$, which is equivalent to minimizing $d_E^2(i,j)$.\n- For $S_1$: $\\min(d_E^2(1,2), d_E^2(1,3), d_E^2(1,4)) = \\min(14284, 231, 3308) = 231$. The nearest neighbor is $S_3$.\n- For $S_2$: $\\min(d_E^2(2,1), d_E^2(2,3), d_E^2(2,4)) = \\min(14284, 14351, 25800) = 14284$. The nearest neighbor is $S_1$.\n- For $S_3$: $\\min(d_E^2(3,1), d_E^2(3,2), d_E^2(3,4)) = \\min(231, 14351, 4111) = 231$. The nearest neighbor is $S_1$.\n- For $S_4$: $\\min(d_E^2(4,1), d_E^2(4,2), d_E^2(4,3)) = \\min(3308, 25800, 4111) = 3308$. The nearest neighbor is $S_1$.\n\nThe nearest neighbors under raw Euclidean distance ($NN_E$) are:\n$NN_E(S_1) = S_3$, $NN_E(S_2) = S_1$, $NN_E(S_3) = S_1$, $NN_E(S_4) = S_1$.\n\n### Step 2: Cosine Similarity and Nearest Neighbors\nFirst, we perform gene-wise $z$-scoring. For each gene $g$, we calculate its mean $\\mu_g$ and population standard deviation $\\sigma_g$ across the $4$ samples.\n$G_1: \\mu_1 = 101.25, \\sigma_1^2 = 1029.6875$\n$G_2: \\mu_2 = 51, \\sigma_2^2 = 255.5$\n$G_3: \\mu_3 = 11.25, \\sigma_3^2 = 6.6875$\n$G_4: \\mu_4 = 6, \\sigma_4^2 = 2.5$\n$G_5: \\mu_5 = 217.5, \\sigma_5^2 = 1968.75$\n$G_6: \\mu_6 = 116.25, \\sigma_6^2 = 617.1875$\n\nNext, we calculate the $z$-scored vectors $\\mathbf{z}_i$ for each sample. The components are $z_{gs} = (x_{gs} - \\mu_g) / \\sigma_g$.\n$$\nz_{gs} =\n\\begin{pmatrix}\n-0.03895 & 1.51918 & -0.19477 & -1.28546 \\\\\n-0.06256 & 1.50148 & -0.12512 & -1.31380 \\\\\n-0.48337 & 1.44971 & 0.28994 & -1.25678 \\\\\n-0.63246 & 1.26491 & -1.26491 & 0.63246 \\\\\n-0.39442 & 1.63403 & -0.16904 & -1.07057 \\\\\n-0.65410 & 1.55982 & -1.05663 & 0.15091\n\\end{pmatrix}\n$$\nThe sample vectors $\\mathbf{z}_1, \\mathbf{z}_2, \\mathbf{z}_3, \\mathbf{z}_4$ are the columns of this matrix. We compute the pairwise cosine similarities $\\cos(i,j) = \\frac{\\mathbf{z}_i \\cdot \\mathbf{z}_j}{\\|\\mathbf{z}_i\\| \\|\\mathbf{z}_j\\|}$.\n\nFirst, we calculate the squared norms $\\|\\mathbf{z}_i\\|^2_2 = \\sum_{g=1}^6 z_{gi}^2$:\n$\\|\\mathbf{z}_1\\|^2 = 1.2225$, so $\\|\\mathbf{z}_1\\| = 1.1057$\n$\\|\\mathbf{z}_2\\|^2 = 13.3679$, so $\\|\\mathbf{z}_2\\| = 3.6562$\n$\\|\\mathbf{z}_3\\|^2 = 2.8827$, so $\\|\\mathbf{z}_3\\| = 1.6979$\n$\\|\\mathbf{z}_4\\|^2 = 6.5258$, so $\\|\\mathbf{z}_4\\| = 2.5546$\n\nNext, we calculate the dot products $\\mathbf{z}_i \\cdot \\mathbf{z}_j = \\sum_{g=1}^6 z_{gi} z_{gj}$:\n$\\mathbf{z}_1 \\cdot \\mathbf{z}_2 = -3.3188$\n$\\mathbf{z}_1 \\cdot \\mathbf{z}_3 = 1.4330$\n$\\mathbf{z}_1 \\cdot \\mathbf{z}_4 = 0.6632$\n$\\mathbf{z}_2 \\cdot \\mathbf{z}_3 = -3.5875$\n$\\mathbf{z}_2 \\cdot \\mathbf{z}_4 = -6.4627$\n$\\mathbf{z}_3 \\cdot \\mathbf{z}_4 = -0.7283$\n\nFinally, we compute the cosine similarities:\n$\\cos(1, 2) = \\frac{-3.3188}{(1.1057)(3.6562)} \\approx -0.8210$\n$\\cos(1, 3) = \\frac{1.4330}{(1.1057)(1.6979)} \\approx 0.7634$\n$\\cos(1, 4) = \\frac{0.6632}{(1.1057)(2.5546)} \\approx 0.2348$\n$\\cos(2, 3) = \\frac{-3.5875}{(3.6562)(1.6979)} \\approx -0.5779$\n$\\cos(2, 4) = \\frac{-6.4627}{(3.6562)(2.5546)} \\approx -0.6919$\n$\\cos(3, 4) = \\frac{-0.7283}{(1.6979)(2.5546)} \\approx -0.1679$\n\nThe nearest neighbor for $S_i$ is $S_j$ that maximizes $\\cos(i,j)$.\n- For $S_1$: $\\max(\\cos(1,2), \\cos(1,3), \\cos(1,4)) = \\max(-0.8210, 0.7634, 0.2348) = 0.7634$. The nearest neighbor is $S_3$.\n- For $S_2$: $\\max(\\cos(2,1), \\cos(2,3), \\cos(2,4)) = \\max(-0.8210, -0.5779, -0.6919) = -0.5779$. The nearest neighbor is $S_3$.\n- For $S_3$: $\\max(\\cos(3,1), \\cos(3,2), \\cos(3,4)) = \\max(0.7634, -0.5779, -0.1679) = 0.7634$. The nearest neighbor is $S_1$.\n- For $S_4$: $\\max(\\cos(4,1), \\cos(4,2), \\cos(4,3)) = \\max(0.2348, -0.6919, -0.1679) = 0.2348$. The nearest neighbor is $S_1$.\n\nThe nearest neighbors under cosine similarity ($NN_{cos}$) are:\n$NN_{cos}(S_1) = S_3$, $NN_{cos}(S_2) = S_3$, $NN_{cos}(S_3) = S_1$, $NN_{cos}(S_4) = S_1$.\n\n### Step 3: Comparison and Calculation of $\\Delta$\nWe compare the nearest neighbors found in Step 1 and Step 2.\n\n| Sample | $NN_E$ | $NN_{cos}$ | Neighbor Changed? |\n|---|---|---|---|\n| $S_1$ | $S_3$ | $S_3$ | No |\n| $S_2$ | $S_1$ | $S_3$ | Yes |\n| $S_3$ | $S_1$ | $S_1$ | No |\n| $S_4$ | $S_1$ | $S_1$ | No |\n\nOut of the $4$ samples, only $S_2$ has a different nearest neighbor when the metric is changed from raw Euclidean distance to cosine similarity on $z$-scored data.\nThe number of samples with a different nearest neighbor is $1$.\nThe total number of samples is $4$.\nThe proportion $\\Delta$ is the ratio of these two numbers.\n$$\n\\Delta = \\frac{1}{4} = 0.25\n$$", "answer": "$$\\boxed{0.25}$$", "id": "3295705"}, {"introduction": "A key challenge in clustering is to determine the optimal number of clusters and to assess the quality of the resulting partition. The silhouette width provides a powerful internal validation metric, quantifying how well each data point fits within its assigned cluster compared to neighboring clusters. This practice will guide you through calculating and interpreting silhouette scores to select the most meaningful number of clusters from a hierarchical clustering result, a fundamental skill for validating any partitioning of your data [@problem_id:3295659].", "problem": "You are given expression profiles for $6$ genes measured across $2$ conditions, represented as points in $\\mathbb{R}^2$. Let the gene-expression vectors be\n$G_1=(0,0)$, $G_2=\\left(\\frac{1}{5},\\frac{1}{10}\\right)$, $G_3=\\left(5,\\frac{51}{10}\\right)$, $G_4=\\left(\\frac{51}{10},\\frac{49}{10}\\right)$, $G_5=(10,0)$, $G_6=\\left(\\frac{51}{5},-\\frac{1}{10}\\right)$.\nAll pairwise dissimilarities are Euclidean distances. A hierarchical agglomerative clustering is performed using the unweighted pair group method with arithmetic mean (UPGMA, average linkage). The resulting dendrogram merges clusters in the following sequence with the stated merge heights (ties broken in the order shown):\n$1)$ merge $\\{G_1\\}$ and $\\{G_2\\}$ at height $h_{\\mathrm{pair}}=\\sqrt{\\frac{1}{20}}=\\frac{1}{2\\sqrt{5}}$,\n$2)$ merge $\\{G_3\\}$ and $\\{G_4\\}$ at height $h_{\\mathrm{pair}}$,\n$3)$ merge $\\{G_5\\}$ and $\\{G_6\\}$ at height $h_{\\mathrm{pair}}$,\n$4)$ merge $\\{G_1,G_2\\}$ and $\\{G_3,G_4\\}$ at height\n$$h_2=\\frac{1}{40}\\Big(\\sqrt{5101}+\\sqrt{5002}+2\\sqrt{1201}+\\sqrt{4705}\\Big),$$\n$5)$ merge $\\{G_1,G_2,G_3,G_4\\}$ and $\\{G_5,G_6\\}$ at height\n$$h_3=\\frac{1}{2}\\left(\\frac{5}{2}+\\frac{1}{40}\\big(\\sqrt{10405}+\\sqrt{9605}+2\\sqrt{2501}\\big)+\\frac{1}{20}\\sqrt{5101}+\\frac{101}{40}\\sqrt{2}\\right).$$\nYou will evaluate the average silhouette width for cuts producing $k\\in\\{2,3,4\\}$ clusters. Use the standard definition of the silhouette of an observation $i$,\n$$s(i)=\\frac{b(i)-a(i)}{\\max\\{a(i),b(i)\\}},$$\nwhere $a(i)$ is the mean dissimilarity of $i$ to all other members of its cluster, and $b(i)$ is the minimum, over all other clusters, of the mean dissimilarity from $i$ to the members of that cluster. Adopt the common convention that if the cluster of $i$ has size $1$, then $a(i)=0$ and $s(i)=0$.\nCompute the average silhouette width under each cut for $k\\in\\{2,3,4\\}$ using the original pairwise distances among $G_1,\\dots,G_6$, then select the cut that maximizes the average silhouette width and justify the choice quantitatively. Report the optimal number of clusters $k^{\\star}$ as an integer. No rounding is required for the final answer.", "solution": "The user has provided a problem that requires the validation of a clustering result by calculating the average silhouette width for different numbers of clusters, $k$. The final goal is to determine the optimal number of clusters, $k^{\\star}$, which maximizes this metric.\n\n### Step 1: Problem Validation\n\nFirst, we must meticulously validate the problem statement.\n\n#### Step 1.1: Extract Givens\nThe given data points are six gene-expression vectors in $\\mathbb{R}^2$:\n$G_1=(0,0)$, $G_2=\\left(\\frac{1}{5},\\frac{1}{10}\\right)$, $G_3=\\left(5,\\frac{51}{10}\\right)$, $G_4=\\left(\\frac{51}{10},\\frac{49}{10}\\right)$, $G_5=(10,0)$, $G_6=\\left(\\frac{51}{5},-\\frac{1}{10}\\right)$.\n\nThe dissimilarity measure is the Euclidean distance, $d(G_i, G_j)$.\nThe clustering method is hierarchical agglomerative clustering using UPGMA (average linkage).\nThe merge sequence is given as:\n1. $\\{G_1\\}, \\{G_2\\}$ at height $h_{\\mathrm{pair}}=\\sqrt{\\frac{1}{20}}$.\n2. $\\{G_3\\}, \\{G_4\\}$ at height $h_{\\mathrm{pair}}$.\n3. $\\{G_5\\}, \\{G_6\\}$ at height $h_{\\mathrm{pair}}$.\n4. $\\{G_1, G_2\\}, \\{G_3, G_4\\}$ at height $h_2=\\frac{1}{40}\\Big(\\sqrt{5101}+\\sqrt{5002}+2\\sqrt{1201}+\\sqrt{4705}\\Big)$.\n5. $\\{G_1, G_2, G_3, G_4\\}, \\{G_5, G_6\\}$ at height $h_3=\\frac{1}{2}\\left(\\frac{5}{2}+\\frac{1}{40}\\big(\\sqrt{10405}+\\sqrt{9605}+2\\sqrt{2501}\\big)+\\frac{1}{20}\\sqrt{5101}+\\frac{101}{40}\\sqrt{2}\\right)$.\n\nThe silhouette of an observation $i$ is $s(i)=\\frac{b(i)-a(i)}{\\max\\{a(i),b(i)\\}}$, where $a(i)$ is the mean dissimilarity of $i$ to its own cluster members and $b(i)$ is the minimum of mean dissimilarities from $i$ to other clusters. If a cluster containing $i$ has size $1$, then $a(i)=0$ and $s(i)=0$.\n\nThe task is to find the optimal number of clusters $k^{\\star} \\in \\{2, 3, 4\\}$ that maximizes the average silhouette width.\n\n#### Step 1.2: Validate Using Extracted Givens\nThe problem is scientifically grounded in computational biology and is stated objectively. The critical point to validate is its internal consistency: does the provided UPGMA hierarchy correctly correspond to the given data points?\n\nThe UPGMA distance between two clusters $C_A$ and $C_B$ is the average of all pairwise distances between their members: $d(C_A, C_B) = \\frac{1}{|C_A||C_B|} \\sum_{i \\in C_A, j \\in C_B} d(G_i, G_j)$. For two singleton clusters $\\{G_i\\}$ and $\\{G_j\\}$, this is simply $d(G_i, G_j)$.\n\nLet's verify the initial merges at height $h_{\\mathrm{pair}}$:\n$d(G_1,G_2)^2 = (\\frac{1}{5}-0)^2 + (\\frac{1}{10}-0)^2 = \\frac{1}{25} + \\frac{1}{100} = \\frac{4+1}{100} = \\frac{5}{100} = \\frac{1}{20}$. So, $d(G_1,G_2) = \\sqrt{\\frac{1}{20}}$.\n$d(G_3,G_4)^2 = (\\frac{51}{10}-5)^2 + (\\frac{49}{10}-\\frac{51}{10})^2 = (\\frac{1}{10})^2 + (-\\frac{2}{10})^2 = \\frac{1}{100} + \\frac{4}{100} = \\frac{5}{100} = \\frac{1}{20}$. So, $d(G_3,G_4) = \\sqrt{\\frac{1}{20}}$.\n$d(G_5,G_6)^2 = (\\frac{51}{5}-10)^2 + (-\\frac{1}{10}-0)^2 = (\\frac{1}{5})^2 + (-\\frac{1}{10})^2 = \\frac{1}{25} + \\frac{1}{100} = \\frac{1}{20}$. So, $d(G_5,G_6) = \\sqrt{\\frac{1}{20}}$.\nThe first three merges at height $h_{\\mathrm{pair}} = \\sqrt{1/20}$ are consistent with the data.\n\nNext, we verify the merge height $h_2$ for clusters $C_{12}=\\{G_1, G_2\\}$ and $C_{34}=\\{G_3, G_4\\}$.\n$h_2 = d(C_{12}, C_{34}) = \\frac{1}{4}(d(G_1,G_3) + d(G_1,G_4) + d(G_2,G_3) + d(G_2,G_4))$.\nThe required squared distances are:\n$d(G_1,G_3)^2 = 5^2 + (\\frac{51}{10})^2 = 25 + \\frac{2601}{100} = \\frac{5101}{100}$.\n$d(G_1,G_4)^2 = (\\frac{51}{10})^2 + (\\frac{49}{10})^2 = \\frac{2601+2401}{100} = \\frac{5002}{100}$.\n$d(G_2,G_3)^2 = (5-\\frac{1}{5})^2 + (\\frac{51}{10}-\\frac{1}{10})^2 = (\\frac{24}{5})^2 + 5^2 = \\frac{576}{25}+25 = \\frac{576+625}{25} = \\frac{1201}{25}$. So $d(G_2,G_3) = \\frac{\\sqrt{1201}}{5} = \\frac{2\\sqrt{1201}}{10}$.\n$d(G_2,G_4)^2 = (\\frac{51}{10}-\\frac{1}{5})^2 + (\\frac{49}{10}-\\frac{1}{10})^2 = (\\frac{49}{10})^2 + (\\frac{48}{10})^2 = \\frac{2401+2304}{100} = \\frac{4705}{100}$.\nSumming the distances and averaging:\n$h_2 = \\frac{1}{4}\\left(\\frac{\\sqrt{5101}}{10} + \\frac{\\sqrt{5002}}{10} + \\frac{2\\sqrt{1201}}{10} + \\frac{\\sqrt{4705}}{10}\\right) = \\frac{1}{40}(\\sqrt{5101}+\\sqrt{5002}+2\\sqrt{1201}+\\sqrt{4705})$, which matches the problem statement. The problem appears internally consistent. A similar, though more tedious, verification shows that $h_3$ is also correct.\n\n#### Step 1.3: Verdict and Action\nThe problem is well-defined, objective, scientifically sound, and internally consistent. It is a valid problem. We proceed to solve it.\n\n### Step 2: Solution\n\nThe hierarchical clustering defines a set of nested partitions. Cutting the dendrogram at different levels yields different numbers of clusters. The partitions corresponding to $k \\in \\{2, 3, 4\\}$ are determined by stopping the agglomeration process at the step where $k$ clusters remain.\n- For $k=4$, we stop after the second merge: $C^{(4)}_1=\\{G_1, G_2\\}$, $C^{(4)}_2=\\{G_3, G_4\\}$, $C^{(4)}_3=\\{G_5\\}$, $C^{(4)}_4=\\{G_6\\}$.\n- For $k=3$, we stop after the third merge: $C^{(3)}_1=\\{G_1, G_2\\}$, $C^{(3)}_2=\\{G_3, G_4\\}$, $C^{(3)}_3=\\{G_5, G_6\\}$.\n- For $k=2$, we stop after the fourth merge: $C^{(2)}_1=\\{G_1, G_2, G_3, G_4\\}$, $C^{(2)}_2=\\{G_5, G_6\\}$.\n\nWe must compute the average silhouette width, $\\bar{S}_k = \\frac{1}{6}\\sum_{i=1}^6 s_k(i)$, for each $k$ and find the maximum. We will perform a comparative analysis.\n\n#### Analysis for $k=3$\nThis clustering corresponds to the three natural pairs of points.\nLet's analyze the silhouette score for a generic point, e.g., $G_1 \\in C^{(3)}_1$.\n- Intra-cluster dissimilarity: $a_3(1) = d(G_1, G_2) = \\sqrt{1/20}$.\n- Inter-cluster dissimilarity: $b_3(1) = \\min\\{d(G_1, C^{(3)}_2), d(G_1, C^{(3)}_3)\\}$.\n  $d(G_1, C^{(3)}_2) = \\frac{1}{2}(d(G_1,G_3)+d(G_1,G_4)) = \\frac{1}{20}(\\sqrt{5101}+\\sqrt{5002}) \\approx 7.1$.\n  $d(G_1, C^{(3)}_3) = \\frac{1}{2}(d(G_1,G_5)+d(G_1,G_6)) = \\frac{1}{2}(10+\\sqrt{104.05}) \\approx 10.1$.\n  So $b_3(1) = \\frac{1}{20}(\\sqrt{5101}+\\sqrt{5002})$.\nSince $a_3(1) \\approx 0.224$ and $b_3(1) \\approx 7.1$, $b_3(1) \\gg a_3(1)$.\nThe silhouette score is $s_3(1) = \\frac{b_3(1)-a_3(1)}{b_3(1)} = 1 - \\frac{a_3(1)}{b_3(1)}$, which is a value close to $1$.\nBy the geometric arrangement of the points, a similar situation holds for all six points. For any point $G_i$, its intra-cluster distance $a_3(i)$ is the small value $\\sqrt{1/20}$, while its average distance to the 'neighboring' cluster, $b_3(i)$, is large (on the order of $7$). Thus, all six silhouette scores $s_3(i)$ will be positive and close to $1$. This indicates a very strong clustering structure.\n\n#### Comparison of $k=3$ and $k=4$\nFor the $k=4$ partition, the clusters are $C^{(4)}_1=\\{G_1, G_2\\}$, $C^{(4)}_2=\\{G_3, G_4\\}$, $C^{(4)}_3=\\{G_5\\}$, $C^{(4)}_4=\\{G_6\\}$.\n- For $i \\in \\{1,2,3,4\\}$, the point's own cluster is identical to the $k=3$ case. For instance, for $G_1$, $a_4(1) = d(G_1,G_2) = a_3(1)$.\n- The 'neighboring' clusters are now singletons. For $G_1$, $b_4(1) = \\min\\{d(G_1,C^{(4)}_2), d(G_1,C^{(4)}_3), d(G_1,C^{(4)}_4) \\}$.\n  $d(G_1,C^{(4)}_2) = d(G_1, C^{(3)}_2) \\approx 7.1$. This is the same as for $k=3$.\n  $d(G_1,C^{(4)}_3) = d(G_1,G_5)=10$.\n  $d(G_1,C^{(4)}_4) = d(G_1,G_6)=\\sqrt{104.05}\\approx 10.2$.\n  The minimum is unchanged: $b_4(1) = d(G_1,C^{(4)}_2) = b_3(1)$.\n  Therefore, for $i \\in \\{1,2,3,4\\}$, we have $s_4(i) = s_3(i)$.\n- For $i \\in \\{5,6\\}$, the points are in singleton clusters. By the problem's convention, $a_4(5)=0, s_4(5)=0$ and $a_4(6)=0, s_4(6)=0$.\nThe average silhouette widths are:\n$\\bar{S}_3 = \\frac{1}{6} \\left( \\sum_{i=1}^4 s_3(i) + s_3(5) + s_3(6) \\right)$\n$\\bar{S}_4 = \\frac{1}{6} \\left( \\sum_{i=1}^4 s_4(i) + s_4(5) + s_4(6) \\right) = \\frac{1}{6} \\left( \\sum_{i=1}^4 s_3(i) + 0 + 0 \\right)$\nAs established for the $k=3$ case, $G_5$ and $G_6$ form a tight cluster $\\{G_5,G_6\\}$ far from others, ensuring $s_3(5)>0$ and $s_3(6)>0$. Specifically, $a_3(5)=d(G_5,G_6)=\\sqrt{1/20}$ and $b_3(5)=\\frac{1}{2}(d(G_5,G_3)+d(G_5,G_4)) = \\frac{1}{20}(\\sqrt{5101}+\\sqrt{4802}) > a_3(5)$. Thus $s_3(5) > 0$.\nSince $s_3(5)$ and $s_3(6)$ are positive terms, it is rigorously established that $\\bar{S}_3 > \\bar{S}_4$.\n\n#### Comparison of $k=3$ and $k=2$\nFor the $k=2$ partition, the clusters are $C^{(2)}_1=\\{G_1,G_2,G_3,G_4\\}$ and $C^{(2)}_2=\\{G_5,G_6\\}$.\nLet's analyze a point in the newly merged cluster, e.g., $G_1 \\in C^{(2)}_1$.\n- Intra-cluster dissimilarity: $a_2(1) = \\frac{1}{3}(d(G_1,G_2) + d(G_1,G_3) + d(G_1,G_4))$.\n  $a_2(1) = \\frac{1}{3}(\\sqrt{1/20} + \\sqrt{51.01} + \\sqrt{50.02}) \\approx \\frac{1}{3}(0.224+7.14+7.07) \\approx 4.81$.\n  This is a dramatic increase from $a_3(1) \\approx 0.224$. Points $G_3$ and $G_4$ are now considered 'in the same cluster' as $G_1$, but are geographically distant.\n- Inter-cluster dissimilarity: $b_2(1) = d(G_1, C^{(2)}_2) = \\frac{1}{2}(d(G_1,G_5)+d(G_1,G_6)) \\approx 10.1$.\nThe silhouette score is $s_2(1) = \\frac{b_2(1)-a_2(1)}{b_2(1)} \\approx \\frac{10.1 - 4.81}{10.1} \\approx 0.52$.\nThis represents a sharp drop from $s_3(1) \\approx 1 - \\frac{0.224}{7.1} \\approx 0.97$.\nThis sharp drop in silhouette score occurs for all points in $C^{(2)}_1$ ($G_1, G_2, G_3, G_4$) because merging the two spatially distinct clusters $\\{G_1,G_2\\}$ and $\\{G_3,G_4\\}$ results in a non-compact cluster with large internal distances.\nNow consider a point in the other cluster, $G_5 \\in C^{(2)}_2$.\n- $a_2(5) = d(G_5,G_6) = \\sqrt{1/20}$. This is the same as $a_3(5)$.\n- $b_2(5) = d(G_5, C^{(2)}_1) = \\frac{1}{4}(d(G_5,G_1)+d(G_5,G_2)+d(G_5,G_3)+d(G_5,G_4)) = \\frac{1}{2}(d(G_5,C_1^{(3)})+d(G_5,C_2^{(3)})) \\approx \\frac{1}{2}(9.9+7.0) = 8.45$.\n  Recall that for $k=3$, $b_3(5) = \\min\\{d(G_5,C_1^{(3)}), d(G_5,C_2^{(3)})\\} \\approx 7.0$.\n  Since $b_2(5) > b_3(5)$ and $a_2(5) = a_3(5)$, the silhouette score $s_2(5) = 1 - a_2(5)/b_2(5)$ will be slightly greater than $s_3(5) = 1 - a_3(5)/b_3(5)$.\nHowever, the substantial decrease in the four scores for $G_1, \\dots, G_4$ far outweighs the minor increase in the two scores for $G_5, G_6$. The average silhouette width will thus be significantly lower for $k=2$ than for $k=3$.\nTherefore, we can conclude that $\\bar{S}_2 < \\bar{S}_3$.\n\n#### Conclusion\nWe have demonstrated through quantitative reasoning that $\\bar{S}_2 < \\bar{S}_3$ and $\\bar{S}_4 < \\bar{S}_3$. The average silhouette width is maximized for $k=3$. This corresponds to the visually obvious clustering of the data into three distinct pairs. The optimal number of clusters is $k^{\\star}=3$.", "answer": "$$\\boxed{3}$$", "id": "3295659"}, {"introduction": "The results of a single clustering run can be sensitive to the algorithm's parameters or stochastic initialization. To find truly robust biological groupings, we often integrate results from multiple analyses. This exercise demonstrates how consensus clustering provides a framework for summarizing multiple partitions into a single co-association matrix, revealing the most stable relationships across different runs and increasing confidence in your findings [@problem_id:3295668].", "problem": "A common approach in computational systems biology to assess the stability of clusters of gene expression profiles across multiple runs of different clustering algorithms is to compute the consensus co-association matrix and then extract robust clusters as connected components of a thresholded consensus graph. Consider a small gene expression study with $n=7$ genes, labeled $g_1,\\dots,g_7$, profiled across $p$ biological conditions. Suppose that three independent clustering runs ($R=3$) were performed on the same standardized expression matrix: one agglomerative hierarchical clustering with average linkage cut to $k=3$ clusters, one $k$-means run with $k=3$, and one agglomerative hierarchical clustering with Ward linkage cut to $k=2$. The resulting partitions are as follows:\n- Run $A$ (hierarchical, average linkage, $k=3$): $C^{(A)}_1=\\{g_1,g_2,g_3\\}$, $C^{(A)}_2=\\{g_4,g_5\\}$, $C^{(A)}_3=\\{g_6,g_7\\}$.\n- Run $B$ ($k$-means, $k=3$): $C^{(B)}_1=\\{g_1,g_2\\}$, $C^{(B)}_2=\\{g_3,g_4,g_5\\}$, $C^{(B)}_3=\\{g_6,g_7\\}$.\n- Run $C$ (hierarchical, Ward linkage, $k=2$): $C^{(C)}_1=\\{g_1,g_2,g_3,g_4,g_5\\}$, $C^{(C)}_2=\\{g_6,g_7\\}$.\n\nBy definition, the consensus matrix $C \\in \\mathbb{R}^{n \\times n}$ has entries $C_{ij}$ equal to the fraction of runs among the $R=3$ in which $g_i$ and $g_j$ are assigned to the same cluster, with the convention $C_{ii}=1$ for all $i$. A consensus graph is obtained by thresholding $C$ at level $\\tau=\\frac{2}{3}$ to form an undirected graph on the $n$ genes, with an edge between $g_i$ and $g_j$ if and only if $C_{ij} \\ge \\tau$. Robust consensus clusters are then defined as the connected components of this thresholded graph.\n\nUsing only the above fundamental definitions, compute the consensus matrix $C$, construct the thresholded consensus graph at $\\tau=\\frac{2}{3}$, extract the connected components, and report the number of consensus clusters (i.e., the number of connected components). Your final answer must be a single integer with no units. No rounding is required.", "solution": "The problem is validated as sound. It is scientifically grounded in the established methods of consensus clustering in computational biology, well-posed with all necessary data and definitions, and objective in its formulation. We can therefore proceed with the solution.\n\nThe objective is to find the number of robust consensus clusters, which are defined as the connected components of a thresholded consensus graph. The process involves three main steps: 1) computing the consensus matrix $C$, 2) constructing the consensus graph by applying a threshold $\\tau$, and 3) identifying the connected components of this graph.\n\nThe problem involves $n=7$ genes, labeled $g_1, g_2, \\dots, g_7$, and $R=3$ clustering runs, denoted $A$, $B$, and $C$. The partitions for each run are:\n- Run $A$: $C^{(A)}_1=\\{g_1,g_2,g_3\\}$, $C^{(A)}_2=\\{g_4,g_5\\}$, $C^{(A)}_3=\\{g_6,g_7\\}$.\n- Run $B$: $C^{(B)}_1=\\{g_1,g_2\\}$, $C^{(B)}_2=\\{g_3,g_4,g_5\\}$, $C^{(B)}_3=\\{g_6,g_7\\}$.\n- Run $C$: $C^{(C)}_1=\\{g_1,g_2,g_3,g_4,g_5\\}$, $C^{(C)}_2=\\{g_6,g_7\\}$.\n\nThe consensus matrix $C$ is a $7 \\times 7$ matrix where the entry $C_{ij}$ is the fraction of runs in which genes $g_i$ and $g_j$ are in the same cluster. The matrix is symmetric ($C_{ij} = C_{ji}$) and has ones on the diagonal ($C_{ii}=1$). We only need to compute the entries for $i < j$.\n\nLet's define a co-association event indicator, $M_{ij}^{(k)}$, as $1$ if genes $g_i$ and $g_j$ are in the same cluster in run $k \\in \\{A, B, C\\}$, and $0$ otherwise. The consensus matrix entry is then $C_{ij} = \\frac{1}{R} \\sum_{k \\in \\{A,B,C\\}} M_{ij}^{(k)}$. Here, $R=3$.\n\nWe systematically compute the co-association counts for all pairs ($g_i, g_j$) with $i<j$:\n- Pair $(g_1, g_2)$: Same cluster in runs $A, B, C$. Count = $3$. $C_{12} = \\frac{3}{3}=1$.\n- Pair $(g_1, g_3)$: Same cluster in runs $A, C$. Count = $2$. $C_{13} = \\frac{2}{3}$.\n- Pair $(g_1, g_4)$: Same cluster in run $C$. Count = $1$. $C_{14} = \\frac{1}{3}$.\n- Pair $(g_1, g_5)$: Same cluster in run $C$. Count = $1$. $C_{15} = \\frac{1}{3}$.\n- Pairs $(g_1, g_6), (g_1, g_7)$: Never in the same cluster. Count = $0$. $C_{16}=C_{17}=0$.\n\n- Pair $(g_2, g_3)$: Same cluster in runs $A, C$. Count = $2$. $C_{23} = \\frac{2}{3}$.\n- Pair $(g_2, g_4)$: Same cluster in run $C$. Count = $1$. $C_{24} = \\frac{1}{3}$.\n- Pair $(g_2, g_5)$: Same cluster in run $C$. Count = $1$. $C_{25} = \\frac{1}{3}$.\n- Pairs $(g_2, g_6), (g_2, g_7)$: Never in the same cluster. Count = $0$. $C_{26}=C_{27}=0$.\n\n- Pair $(g_3, g_4)$: Same cluster in runs $B, C$. Count = $2$. $C_{34} = \\frac{2}{3}$.\n- Pair $(g_3, g_5)$: Same cluster in runs $B, C$. Count = $2$. $C_{35} = \\frac{2}{3}$.\n- Pairs $(g_3, g_6), (g_3, g_7)$: Never in the same cluster. Count = $0$. $C_{36}=C_{37}=0$.\n\n- Pair $(g_4, g_5)$: Same cluster in runs $A, B, C$. Count = $3$. $C_{45} = \\frac{3}{3}=1$.\n- Pairs $(g_4, g_6), (g_4, g_7)$: Never in the same cluster. Count = $0$. $C_{46}=C_{47}=0$.\n\n- Pairs $(g_5, g_6), (g_5, g_7)$: Never in the same cluster. Count = $0$. $C_{56}=C_{57}=0$.\n\n- Pair $(g_6, g_7)$: Same cluster in runs $A, B, C$. Count = $3$. $C_{67} = \\frac{3}{3}=1$.\n\nThe full consensus matrix $C$ is:\n$$\nC = \n\\begin{pmatrix}\n1 & 1 & \\frac{2}{3} & \\frac{1}{3} & \\frac{1}{3} & 0 & 0 \\\\\n1 & 1 & \\frac{2}{3} & \\frac{1}{3} & \\frac{1}{3} & 0 & 0 \\\\\n\\frac{2}{3} & \\frac{2}{3} & 1 & \\frac{2}{3} & \\frac{2}{3} & 0 & 0 \\\\\n\\frac{1}{3} & \\frac{1}{3} & \\frac{2}{3} & 1 & 1 & 0 & 0 \\\\\n\\frac{1}{3} & \\frac{1}{3} & \\frac{2}{3} & 1 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 1 & 1 \\\\\n0 & 0 & 0 & 0 & 0 & 1 & 1\n\\end{pmatrix}\n$$\n\nNext, we construct the consensus graph by creating an edge between genes $g_i$ and $g_j$ if and only if $C_{ij} \\ge \\tau$, where the threshold is given as $\\tau = \\frac{2}{3}$. Let $A$ be the adjacency matrix of this graph, where $A_{ij}=1$ if an edge exists and $A_{ij}=0$ otherwise.\nWe identify the pairs $(i,j)$ for which $C_{ij} \\ge \\frac{2}{3}$:\n- $C_{12} = 1 \\ge \\frac{2}{3} \\implies$ Edge $(g_1, g_2)$ exists.\n- $C_{13} = \\frac{2}{3} \\ge \\frac{2}{3} \\implies$ Edge $(g_1, g_3)$ exists.\n- $C_{23} = \\frac{2}{3} \\ge \\frac{2}{3} \\implies$ Edge $(g_2, g_3)$ exists.\n- $C_{34} = \\frac{2}{3} \\ge \\frac{2}{3} \\implies$ Edge $(g_3, g_4)$ exists.\n- $C_{35} = \\frac{2}{3} \\ge \\frac{2}{3} \\implies$ Edge $(g_3, g_5)$ exists.\n- $C_{45} = 1 \\ge \\frac{2}{3} \\implies$ Edge $(g_4, g_5)$ exists.\n- $C_{67} = 1 \\ge \\frac{2}{3} \\implies$ Edge $(g_6, g_7)$ exists.\nNo other off-diagonal entries meet the threshold.\n\nThe set of edges in the consensus graph is $E = \\{(g_1, g_2), (g_1, g_3), (g_2, g_3), (g_3, g_4), (g_3, g_5), (g_4, g_5), (g_6, g_7)\\}$.\n\nFinally, we find the connected components of this graph.\n- Starting with $g_1$: it is connected to $g_2$ and $g_3$.\n- Node $g_3$ is connected to $g_1$, $g_2$, $g_4$, and $g_5$. This means all genes in the set $\\{g_1, g_2, g_3, g_4, g_5\\}$ are connected to each other (e.g., $g_1$ is connected to $g_4$ via the path $g_1 \\to g_3 \\to g_4$). Thus, $\\{g_1, g_2, g_3, g_4, g_5\\}$ forms a single connected component.\n- The remaining genes are $g_6$ and $g_7$. There is an edge $(g_6, g_7)$. There are no edges connecting these two genes to any of the genes in the first component. Therefore, $\\{g_6, g_7\\}$ forms a second, distinct connected component.\n\nThe robust consensus clusters are these two connected components:\n1. $\\{g_1, g_2, g_3, g_4, g_5\\}$\n2. $\\{g_6, g_7\\}$\n\nThe number of consensus clusters is the number of connected components, which is $2$.", "answer": "$$\\boxed{2}$$", "id": "3295668"}]}