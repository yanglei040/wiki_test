{"hands_on_practices": [{"introduction": "The modularity of a network partition can be expressed as a quadratic form involving the modularity matrix, $Q = \\frac{1}{4m} s^T B s$. Maximizing this quantity is computationally hard, but spectral methods offer a powerful approximation. This practice guides you through implementing a spectral bipartitioning algorithm, which connects the problem of community detection to the fundamental linear algebra concept of eigenvectors [@problem_id:3328768]. By computing the leading eigenvector of the modularity matrix, you will gain hands-on experience translating abstract theory into a practical tool for network analysis.", "problem": "You are given the task of implementing a spectral bipartitioning method grounded in the modularity framework for small, undirected, unweighted protein–protein interaction (PPI) networks. The goal is to compute a two-way community assignment by thresholding the entries of the leading eigenvector of the modularity matrix. Use only fundamental definitions from network science and linear algebra to construct your method.\n\nDefinitions and requirements:\n- Let $A \\in \\{0,1\\}^{n \\times n}$ denote the symmetric adjacency matrix of an undirected, unweighted network with $n$ nodes, zero diagonal, and entries $A_{ij} = 1$ if and only if there is an edge between nodes $i$ and $j$. Let $k_i = \\sum_{j=1}^{n} A_{ij}$ denote the degree of node $i$, and let $2m = \\sum_{i=1}^{n} k_i = \\sum_{i=1}^{n} \\sum_{j=1}^{n} A_{ij}$ denote twice the number of edges.\n- Under the configuration model null model, the expected number of edges between nodes $i$ and $j$ is $k_i k_j / (2m)$. The modularity matrix is $B \\in \\mathbb{R}^{n \\times n}$ with entries $B_{ij} = A_{ij} - \\frac{k_i k_j}{2m}$.\n- Compute the leading eigenpair of $B$, where the leading eigenvalue $\\lambda_{\\max}$ is the largest real eigenvalue (by value, not magnitude), and the corresponding eigenvector $v_{\\max}$ is any associated unit-norm eigenvector.\n- Assign nodes to two communities using the thresholding rule $s_i = +1$ if $v_{\\max,i} \\ge 0$ and $s_i = -1$ if $v_{\\max,i}  0$. This produces a two-way assignment vector $s \\in \\{-1,+1\\}^n$; entries exactly equal to $0$ must be assigned to $+1$.\n- For the bipartition encoded by $s$, compute the modularity value\n$$\nQ = \\frac{1}{4m} \\sum_{i=1}^{n}\\sum_{j=1}^{n} B_{ij} s_i s_j,\n$$\nwhich is equivalent to the standard modularity definition specialized to two groups. If $2m = 0$, define $Q = 0$ by convention.\n- Define an informative split as a bipartition for which $\\lambda_{\\max} > 0$ and both communities are non-empty (i.e., there exists at least one $i$ with $s_i = +1$ and at least one $j$ with $s_j = -1$).\n\nImplement a program that, for each test case below:\n- Constructs $B$ from $A$ using the configuration model.\n- Computes the leading eigenpair $(\\lambda_{\\max}, v_{\\max})$ of $B$ via a symmetric eigenvalue decomposition.\n- Forms $s$ by thresholding $v_{\\max}$ at $0$ as specified.\n- Computes $Q$ for that $s$.\n- Reports a result of the form $[\\lambda_{\\max}, s\\_list, Q, informative]$, where $\\lambda_{\\max}$ and $Q$ are rounded to six decimal places, $s\\_list$ is a list of integers in $\\{-1, +1\\}$, and $informative$ is a boolean.\n\nTest suite (three undirected, unweighted PPI-like networks), each fully specified in purely combinatorial terms:\n- Test case $1$ (two-module structure with a single bridge): $n = 8$, nodes $\\{0,1,2,3\\}$ form a $4$-clique, nodes $\\{4,5,6,7\\}$ form another $4$-clique, and there is exactly one inter-module edge connecting node $3$ to node $4$. All other pairs across the two cliques are non-adjacent, and no self-loops exist.\n- Test case $2$ (star-like interaction hub): $n = 6$, node $0$ is connected to each node in $\\{1,2,3,4,5\\}$, and there are no other edges; no self-loops exist.\n- Test case $3$ (dense background with no informative split): $n = 5$, the network is the complete graph $K_5$ (every pair of distinct nodes is connected), with no self-loops.\n\nFinal output format:\n- Your program should produce a single line of output containing a list of results, one per test case, in the order of the test suite above. Each result must be a list of the form $[\\lambda_{\\max}, s\\_list, Q, informative]$, with $\\lambda_{\\max}$ and $Q$ rounded to six decimal places, $s\\_list$ a list of $-1$ and $+1$ of length $n$, and $informative$ a boolean. The entire output must be a single list enclosing the three per-case results. For example: $[[\\dots],[\\dots],[\\dots]]$.", "solution": "The problem requires the implementation of a spectral bipartitioning algorithm for undirected, unweighted networks based on the modularity matrix. The solution will be designed following the principles of network science and linear algebra as specified.\n\nThe core principle behind this method is the maximization of modularity, a quality function for community detection. For a partition of a network into communities, modularity, denoted $Q$, measures the fraction of edges that fall within the given communities minus the expected such fraction if edges were distributed randomly according to the configuration model. The configuration model is a null model where the degree sequence of the network is preserved.\n\nThe general formula for modularity is:\n$$\nQ = \\frac{1}{2m} \\sum_{i,j} \\left( A_{ij} - \\frac{k_i k_j}{2m} \\right) \\delta(c_i, c_j)\n$$\nwhere $A$ is the adjacency matrix, $k_i$ is the degree of node $i$, $2m$ is the total number of edges times two (i.e., the sum of all degrees), and $\\delta(c_i, c_j)$ is the Kronecker delta, which is $1$ if nodes $i$ and $j$ are in the same community ($c_i = c_j$) and $0$ otherwise.\n\nThe term in the parenthesis is the entry $B_{ij}$ of the modularity matrix $B$, so $B = A - \\frac{1}{2m} k k^T$, where $k$ is the column vector of node degrees.\n\nFor a bipartition into two communities, we can represent the community assignment by a vector $s \\in \\{-1, +1\\}^n$. If nodes $i$ and $j$ are in the same community, $s_i s_j = 1$; if they are in different communities, $s_i s_j = -1$. The term $\\delta(c_i, c_j)$ can be related to $s_i s_j$ by $\\delta(c_i, c_j) = \\frac{1}{2}(1 + s_i s_j)$. Substituting this into the modularity formula and using the fact that $\\sum_{i,j} B_{ij} = 0$, we arrive at the expression for modularity given in the problem statement:\n$$\nQ = \\frac{1}{4m} \\sum_{i,j} B_{ij} s_i s_j = \\frac{1}{4m} s^T B s\n$$\nMaximizing $Q$ is equivalent to maximizing the quadratic form $s^T B s$. This is an NP-hard integer optimization problem. The spectral method provides an approximate solution by relaxing the constraint that $s_i$ must be one of $-1$ or $+1$. We instead allow the entries of the vector to be any real numbers, and maximize $v^T B v$ subject to the normalization constraint $\\|v\\|=1$. By the Rayleigh-Ritz theorem, the vector $v$ that maximizes this quantity is the eigenvector corresponding to the largest eigenvalue of the matrix $B$. This is the leading eigenvector, $v_{\\max}$.\n\nThe resulting real-valued vector $v_{\\max}$ is then converted back into a discrete partitioning vector $s$ by a simple thresholding scheme. The sign of each component $v_{\\max, i}$ determines the community assignment for node $i$.\n\nThe implementation will proceed in the following steps for each provided test case:\n\n1.  **Construct the Adjacency Matrix $A$**: Based on the combinatorial description of each test network, an $n \\times n$ NumPy array representing the adjacency matrix $A$ will be constructed.\n\n2.  **Compute Network Properties**: From $A$, the degree vector $k$ is calculated by summing the rows of $A$. The total degree sum, $2m$, is calculated by summing the elements of $k$. A special case for $2m=0$ (an empty graph) is handled as specified, setting $Q=0$.\n\n3.  **Construct the Modularity Matrix $B$**: Using the formula $B_{ij} = A_{ij} - \\frac{k_i k_j}{2m}$, the modularity matrix $B$ is constructed. In matrix notation, this is $B = A - \\frac{1}{2m} k k^T$, where $k k^T$ is the outer product of the degree vector with itself.\n\n4.  **Compute the Leading Eigenpair**: A symmetric eigenvalue decomposition is performed on the modularity matrix $B$. Since $B$ is a real symmetric matrix, its eigenvalues are real and its eigenvectors form an orthonormal basis. We use `numpy.linalg.eigh`, which is designed for symmetric matrices and returns eigenvalues in ascending order. The leading eigenvalue $\\lambda_{\\max}$ is the last element of the returned array of eigenvalues, and the leading eigenvector $v_{\\max}$ is the last column of the returned matrix of eigenvectors.\n\n5.  **Determine the Bipartition**: The partitioning vector $s$ is created from $v_{\\max}$ according to the thresholding rule: $s_i = +1$ if the $i$-th component $v_{\\max,i} \\ge 0$, and $s_i = -1$ if $v_{\\max,i}  0$.\n\n6.  **Calculate Modularity $Q$**: The modularity $Q$ for the obtained partition $s$ is calculated using the matrix form of the given formula: $Q = \\frac{s^T B s}{4m}$. This is implemented using matrix-vector products.\n\n7.  **Assess the Split**: The split is classified as 'informative' if two conditions are met: the leading eigenvalue $\\lambda_{\\max}$ is strictly positive, and the resulting partition $s$ contains both $+1$ and $-1$ values (i.e., both communities are non-empty).\n\n8.  **Format the Output**: The final result for each test case is assembled into a list containing $\\lambda_{\\max}$ and $Q$ rounded to six decimal places, the list representation of the partition vector $s$, and the boolean value indicating if the split was informative. The results for all test cases are collected into a single list for the final output.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the spectral bipartitioning problem for the given test cases.\n    \"\"\"\n\n    def analyze_network(A: np.ndarray):\n        \"\"\"\n        Performs spectral bipartitioning on a network given its adjacency matrix.\n        \n        Args:\n            A (np.ndarray): The symmetric adjacency matrix of the network.\n\n        Returns:\n            list: A list containing the rounded leading eigenvalue, the partition vector,\n                  the rounded modularity, and a boolean indicating if the split is informative.\n        \"\"\"\n        n = A.shape[0]\n        if n == 0:\n            return [0.0, [], 0.0, False]\n\n        k = A.sum(axis=1)\n        two_m = k.sum()\n\n        if two_m == 0:\n            s_list = [1] * n if n  0 else []\n            return [0.0, s_list, 0.0, False]\n\n        # Construct the modularity matrix B\n        B = A - np.outer(k, k) / two_m\n\n        # Eigenvalue decomposition for the symmetric matrix B\n        # numpy.linalg.eigh returns eigenvalues in ascending order\n        eigenvalues, eigenvectors = np.linalg.eigh(B)\n\n        # The leading eigenpair corresponds to the largest eigenvalue\n        lambda_max = eigenvalues[-1]\n        v_max = eigenvectors[:, -1]\n\n        # Create partition vector s from the leading eigenvector v_max\n        # s_i = +1 if v_max_i = 0, s_i = -1 if v_max_i  0\n        s = np.ones(n, dtype=int)\n        s[v_max  0] = -1\n\n        # Calculate modularity Q for the partition s\n        # Q = (1/(4m)) * s^T * B * s. Here, two_m is 2m, so 4m = 2 * two_m.\n        Q = (s.T @ B @ s) / (2 * two_m)\n\n        # Determine if the split is informative\n        is_lambda_positive = lambda_max  1e-12 # Use a small tolerance for float comparison\n        has_both_communities = len(np.unique(s)) == 2\n        informative = bool(is_lambda_positive and has_both_communities)\n\n        # Format results\n        lambda_max_rounded = round(float(lambda_max), 6)\n        Q_rounded = round(float(Q), 6)\n        s_list = s.tolist()\n\n        return [lambda_max_rounded, s_list, Q_rounded, informative]\n\n    # --- Test Case 1: Two modules with a bridge ---\n    n1 = 8\n    A1 = np.zeros((n1, n1), dtype=int)\n    # First 4-clique (nodes 0, 1, 2, 3)\n    for i in range(4):\n        for j in range(i + 1, 4):\n            A1[i, j] = A1[j, i] = 1\n    # Second 4-clique (nodes 4, 5, 6, 7)\n    for i in range(4, 8):\n        for j in range(i + 1, 8):\n            A1[i, j] = A1[j, i] = 1\n    # Bridge between node 3 and node 4\n    A1[3, 4] = A1[4, 3] = 1\n\n    # --- Test Case 2: Star graph ---\n    n2 = 6\n    A2 = np.zeros((n2, n2), dtype=int)\n    # Node 0 is connected to all other nodes\n    for i in range(1, n2):\n        A2[0, i] = A2[i, 0] = 1\n\n    # --- Test Case 3: Complete graph K5 ---\n    n3 = 5\n    A3 = np.ones((n3, n3), dtype=int) - np.eye(n3, dtype=int)\n\n    test_cases = [A1, A2, A3]\n\n    results = []\n    for A in test_cases:\n        result = analyze_network(A)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # The string representation of a list in Python includes spaces after commas.\n    # The boilerplate format string ensures the output conforms to the problem's example.\n    # Example item: `[2.413793, [1, 1, 1, 1, -1, -1, -1, -1], 0.357322, True]`\n    # `str()` of this list produces `'[2.413793, [1, 1, 1, 1, -1, -1, -1, -1], 0.357322, True]'`\n    # `','.join(map(str, results))` joins these strings with commas.\n    # The outer `f\"[{...}]\"` wraps the whole thing in brackets.\n    # This combination correctly produces the format `[[...],[...],[...]]`.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3328768"}, {"introduction": "The modularity score quantifies how much denser the connections are within communities compared to a random baseline. But what if this baseline, or null model, is poorly chosen? This practice explores a crucial pitfall where a simplistic null model fails to account for inherent network properties like degree heterogeneity, a common feature in biological networks [@problem_id:3328725]. Through a direct comparison, you will see how a mis-specified model can create spurious modules and appreciate why the degree-preserving configuration model is the standard for robust community detection.", "problem": "In a protein–protein interaction network in a single eukaryotic cell type, suppose there are $N=1000$ proteins represented as nodes in a simple undirected graph (no self-loops). The degree sequence exhibits pronounced heterogeneity: $h=10$ hub proteins each have degree $20$, and the remaining $N-h=990$ proteins each have degree $2$. The network was generated by randomly wiring stubs uniformly at random subject to the degree sequence (degree-preserving random wiring), and there is no true mesoscale community structure in the generative process beyond the degree heterogeneity itself. Consider the partition $\\mathcal{P}_1$ that places all hubs in one module and all non-hubs in a second module.\n\nTwo null models for expected edges are considered for modularity-based community scoring:\n- A homogeneous Bernoulli null in which every pair of distinct nodes is connected independently with probability $p$ chosen to match the observed edge density across the entire graph.\n- A degree-preserving null in which the expected number of edges between nodes $i$ and $j$ is proportional to $k_i k_j$ and matches the configuration model.\n\nLet $m$ denote the total number of edges, $K_H$ the sum of degrees of the hub set, $K_L$ the sum of degrees of the non-hub set, $n_H$ the number of hubs, and $n_L$ the number of non-hubs. Using first principles for expected edge counts under each null model and the core definition of modularity as the difference between observed and null-expected within-module edge density appropriately normalized, analyze the contribution of the hub module in $\\mathcal{P}_1$ to the modularity under both nulls. Then, reason about whether the homogeneous Bernoulli null will produce spurious modules in the presence of extreme degree heterogeneity and propose a corrected null that avoids this pitfall in computational systems biology networks such as Protein–Protein Interaction (PPI) graphs.\n\nSelect all statements that are correct:\n\nA. Under the homogeneous Bernoulli null, the contribution of the hub module in $\\mathcal{P}_1$ to the modularity is positive and of order approximately $7.5\\times 10^{-3}$, creating an apparent module around hubs in a network that in reality has no true communities beyond degree heterogeneity.\n\nB. Under the degree-preserving null, the expected modularity of any partition of a graph generated by degree-preserving random wiring is $0$ in expectation, and for $\\mathcal{P}_1$ the hub-module contribution is approximately $-8.4\\times 10^{-4}$, showing that the apparent signal in A arises from null mis-specification.\n\nC. A suitable correction for the spurious modularity is to retain the homogeneous Bernoulli null but replace $p$ by a value estimated only from the hub nodes.\n\nD. A corrected null for networks with heavy-tailed degrees is a degree-corrected model (for example, the configuration model or a degree-corrected stochastic block model) in which the expected number of edges between $i$ and $j$ scales with $k_i k_j$, thereby preventing hub-driven spurious modules.\n\nE. Splitting the non-hub module into many small communities will reduce the positive contribution of the hub module under the homogeneous Bernoulli null.", "solution": "The problem statement has been validated and is deemed sound. It is scientifically grounded, well-posed, objective, and contains all necessary information for a rigorous analysis.\n\nWe begin by calculating the fundamental properties of the network described.\nThe total number of nodes is $N=1000$.\nThe number of hub proteins is $n_H = 10$, each with degree $k_{hub} = 20$.\nThe number of non-hub proteins is $n_L = 990$, each with degree $k_{non-hub} = 2$.\nThe sum of all degrees in the network is $2m = \\sum_{i} k_i$.\n$$ 2m = n_H \\cdot k_{hub} + n_L \\cdot k_{non-hub} = (10)(20) + (990)(2) = 200 + 1980 = 2180 $$\nThus, the total number of edges in the network is $m = 1090$.\n\nThe partition $\\mathcal{P}_1$ consists of two modules: the hub module $C_H$ (containing the $n_H=10$ hubs) and the non-hub module $C_L$ (containing the $n_L=990$ non-hubs).\nThe sum of degrees for the hub module is $K_H = n_H \\cdot k_{hub} = 10 \\cdot 20 = 200$.\nThe sum of degrees for the non-hub module is $K_L = n_L \\cdot k_{non-hub} = 990 \\cdot 2 = 1980$.\nAs a check, $K_H + K_L = 200 + 1980 = 2180 = 2m$.\n\nThe general definition of modularity $Q$ for a partition is:\n$$ Q = \\sum_{C} \\left( \\frac{L_C}{m} - \\frac{E_C}{m} \\right) $$\nwhere the sum is over all modules $C$ in the partition, $L_C$ is the number of edges with both endpoints within module $C$, and $E_C$ is the expected number of edges within module $C$ under a specified null model. The contribution of a single module $C$ to the total modularity is $Q_C = (L_C - E_C)/m$.\n\nThe problem states the network is generated by degree-preserving random wiring, which corresponds to the configuration model. In such a network, the number of edges within any module, $L_C$, is a random variable. We will use its expected value, $E[L_C]$, in places where $L_C$ is required, as this represents the properties of a typical graph generated by this process. For the hub module $C_H$, the graph is simple (no self-loops), so the expected number of internal edges, which we will use for $L_H$, is:\n$$ L_H \\approx E[L_H] = \\sum_{ij, i,j \\in C_H} \\frac{k_i k_j}{2m} $$\nSince all hubs have the same degree $k_{hub}=20$, this simplifies to:\n$$ L_H \\approx \\binom{n_H}{2} \\frac{k_{hub}^2}{2m} = \\frac{10 \\cdot 9}{2} \\cdot \\frac{20^2}{2180} = 45 \\cdot \\frac{400}{2180} = \\frac{18000}{2180} \\approx 8.25688 $$\n\nNow we evaluate each statement.\n\n**A. Under the homogeneous Bernoulli null, the contribution of the hub module in $\\mathcal{P}_1$ to the modularity is positive and of order approximately $7.5\\times 10^{-3}$, creating an apparent module around hubs in a network that in reality has no true communities beyond degree heterogeneity.**\n\nFor the homogeneous Bernoulli null model, every pair of distinct nodes is connected with a uniform probability $p$. This probability is set to match the overall edge density of the graph:\n$$ p = \\frac{m}{\\binom{N}{2}} = \\frac{1090}{\\frac{1000 \\cdot 999}{2}} = \\frac{1090}{499500} \\approx 0.00218218 $$\nThe expected number of edges within the hub module $C_H$ under this null is $E_H^{Bernoulli}$:\n$$ E_H^{Bernoulli} = p \\cdot \\binom{n_H}{2} = (0.00218218) \\cdot \\frac{10 \\cdot 9}{2} = (0.00218218) \\cdot 45 \\approx 0.09820 $$\nThe contribution of the hub module to modularity is:\n$$ Q_{C_H}^{Bernoulli} = \\frac{L_H - E_H^{Bernoulli}}{m} \\approx \\frac{8.25688 - 0.09820}{1090} = \\frac{8.15868}{1090} \\approx 0.007485 $$\nThis value is positive and equal to $7.485 \\times 10^{-3}$, which is approximately $7.5 \\times 10^{-3}$. Since the number of observed edges within the hub cluster ($L_H \\approx 8.26$) is much larger than expected under a homogeneous random model ($E_H^{Bernoulli} \\approx 0.10$), the modularity metric gives a strong positive signal. This signal is spurious because it arises from the failure of the null model to account for degree heterogeneity, not from any underlying community structure in the generative process.\nThe statement is **Correct**.\n\n**B. Under the degree-preserving null, the expected modularity of any partition of a graph generated by degree-preserving random wiring is $0$ in expectation, and for $\\mathcal{P}_1$ the hub-module contribution is approximately $-8.4\\times 10^{-4}$, showing that the apparent signal in A arises from null mis-specification.**\n\nThe degree-preserving null (configuration model) posits that the expected number of edges between nodes $i$ and $j$ is $P_{ij} = k_i k_j / (2m)$. The standard modularity formulation for this null uses the expected fraction of within-module edges for a multigraph, which is $(K_C/(2m))^2$. The contribution of module $C_H$ is thus:\n$$ Q_{C_H}^{Config} = \\frac{L_H}{m} - \\left( \\frac{K_H}{2m} \\right)^2 $$\nUsing $L_H \\approx E[L_H] \\approx 8.25688$ for the simple graph:\n$$ Q_{C_H}^{Config} \\approx \\frac{8.25688}{1090} - \\left( \\frac{200}{2180} \\right)^2 \\approx 0.0075751 - (0.091743)^2 \\approx 0.0075751 - 0.0084168 \\approx -0.0008417 $$\nThis value is $-8.417 \\times 10^{-4}$, which is approximately $-8.4 \\times 10^{-4}$. The reason the expected contribution is not exactly zero is that we are using the actual expected number of edges in a simple graph for $L_H$, while the standard modularity formula's null term implicitly corresponds to a multigraph (it includes self-loops). This small negative value reflects the contribution of expected self-loops that are forbidden in a simple graph. The statement that the expected modularity is approximately zero is conceptually correct, and the calculation is accurate. This result correctly indicates that, once degree heterogeneity is accounted for, the hubs do not form a module, confirming that the signal in A was an artifact of the wrong null model.\nThe statement is **Correct**.\n\n**C. A suitable correction for the spurious modularity is to retain the homogeneous Bernoulli null but replace $p$ by a value estimated only from the hub nodes.**\n\nThis proposal suggests calculating a local edge density $p_H = L_H / \\binom{n_H}{2}$ and using it as the null probability. While this would make the contribution of the hub module itself close to zero, it is not a principled correction. A null model must apply consistently across the entire network to provide a statistically valid baseline. Applying a different null probability for different parts of the network is ad-hoc and not a \"model\" in a meaningful sense. Using the high density of the hubs ($p_H \\approx 8.257/45 \\approx 0.183$) as a global probability $p$ would be grossly incorrect, as it would predict $p \\binom{N}{2} \\approx 0.183 \\times 499500 \\approx 91400$ total edges, whereas only $m=1090$ exist. The proper correction is to change the functional form of the null model, not to cherry-pick its parameters.\nThe statement is **Incorrect**.\n\n**D. A corrected null for networks with heavy-tailed degrees is a degree-corrected model (for example, the configuration model or a degree-corrected stochastic block model) in which the expected number of edges between $i$ and $j$ scales with $k_i k_j$, thereby preventing hub-driven spurious modules.**\n\nThis statement accurately describes the standard and accepted solution to the problem of degree heterogeneity in community detection. The configuration model, where the expected number of edges $E_{ij}$ is proportional to $k_i k_j$, directly accounts for the fact that high-degree nodes will naturally form more connections. By using this as a baseline, modularity measures deviations from this degree-driven expectation, rather than deviations from a homogeneous random state. This prevents high-degree nodes from being automatically grouped into spurious communities simply because they are highly connected. As demonstrated in the analysis of option B, using this null model correctly removes the spurious community signal found in option A. The Degree-Corrected Stochastic Block Model (DC-SBM) is a more general and powerful model built on the same principle.\nThe statement is **Correct**.\n\n**E. Splitting the non-hub module into many small communities will reduce the positive contribution of the hub module under the homogeneous Bernoulli null.**\n\nThe contribution of a specific module to the total modularity score is calculated based only on the properties of that module and the global properties of the network and null model. The formula for the contribution of the hub module, $Q_{C_H}^{Bernoulli} = (L_H - p \\binom{n_H}{2}) / m$, depends on $L_H$ (internal hub edges), $n_H$ (number of hubs), $p$ (global edge density), and $m$ (total edges). None of these quantities change when the *other* module (the non-hubs) is sub-divided. Therefore, partitioning the non-hub module has no effect on the calculated contribution of the hub module.\nThe statement is **Incorrect**.", "answer": "$$\\boxed{ABD}$$", "id": "3328725"}, {"introduction": "Biological systems are organized hierarchically, and community structure in molecular networks often exists at multiple scales. This advanced practice moves beyond finding a single partition by introducing the resolution parameter $\\gamma$, which allows you to tune the characteristic size of communities you wish to detect. You will implement a full computational pipeline that combines a greedy optimization algorithm with statistical enrichment analysis to select a biologically relevant resolution scale, providing an authentic taste of a systems biology research workflow [@problem_id:3328724].", "problem": "You are given a scenario grounded in computational systems biology where gene coexpression is modeled as an undirected, weighted network whose community structure is assessed across multiple resolution parameters. The task is to implement a complete, self-contained program that selects an appropriate resolution scale by matching detected module sizes to known pathway sizes through enrichment analysis.\n\nStart from the following foundational definitions and facts.\n\n- A gene coexpression network is modeled as an undirected weighted graph with a symmetric weight matrix $W \\in \\mathbb{R}^{N \\times N}$, where $W_{ij} \\geq 0$ denotes the coexpression strength between gene $i$ and gene $j$, $W_{ij} = W_{ji}$ for all $i,j$, and $W_{ii} = 0$ for all $i$. The total weight is $2m = \\sum_{i=1}^{N} \\sum_{j=1}^{N} W_{ij}$, which for an undirected graph equals $2$ times the sum of weights over unordered pairs. The strength of node $i$ is $k_i = \\sum_{j=1}^{N} W_{ij}$.\n\n- The modularity with resolution parameter $\\gamma$ is defined as\n$$\nQ(\\gamma) \\;=\\; \\frac{1}{2m} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\left( W_{ij} \\;-\\; \\gamma \\frac{k_i k_j}{2m} \\right) \\mathbf{1}\\{c_i = c_j\\},\n$$\nwhere $c_i$ is the community label of node $i$, and $\\mathbf{1}\\{\\cdot\\}$ denotes the indicator function. Larger values of $Q(\\gamma)$ correspond, in this framework, to better community partitions at resolution $\\gamma$.\n\n- Gene set enrichment of a module (community) $S \\subseteq \\{1,\\dots,N\\}$ against a pathway $P \\subseteq \\{1,\\dots,N\\}$ on the same universe of $N$ genes is assessed by the tail probability of the Hypergeometric distribution: if $X \\sim \\mathrm{Hypergeometric}(N, K, n)$ with $K = |P|$ and $n = |S|$, then the one-sided $p$-value for observing an overlap of size $k = |S \\cap P|$ or larger is $p = \\mathbb{P}[X \\ge k]$. A conservative multiple testing correction is the Bonferroni correction: for $T$ simultaneous tests, the family-wise error rate at level $\\alpha$ is controlled by rejecting those with $p  \\alpha / T$.\n\nYour program must do the following for each test case:\n\n1. For each specified $\\gamma$ value in a provided finite grid, compute a partition of the nodes into communities by greedily maximizing modularity starting from the singleton partition and iteratively merging the pair of communities that yields the largest strictly positive gain in modularity at that $\\gamma$; stop when no merge yields a strictly positive gain. You must start this agglomerative optimization from singletons independently for each $\\gamma$. You should derive and implement any expressions you need from the above fundamental definitions; no further formulas are given.\n\n2. For each partition at each $\\gamma$, perform enrichment analysis against the given pathway collection:\n   - For each module $S$ and each pathway $P$, compute the Hypergeometric tail $p$-value $p(S,P)$ as described above.\n   - Let $T$ be the total number of module–pathway pairs, i.e., $T = (\\text{number of modules}) \\times (\\text{number of pathways})$. Use Bonferroni correction with significance level $\\alpha = 0.05$, i.e., treat $p(S,P)  \\alpha/T$ as significant.\n   - Count how many modules have at least one significant enrichment with any pathway. Denote this count by $E(\\gamma)$.\n\n3. Select $\\gamma^\\star$ for the test case by the following rule:\n   - Primary criterion: maximize $E(\\gamma)$.\n   - Secondary tie-breaker: among those with maximal $E(\\gamma)$, choose the $\\gamma$ whose number of modules is closest (in absolute difference) to the number of pathways.\n   - Final tie-breaker: if still tied, choose the smallest numerical $\\gamma$.\n\nYour program should produce a single line of output containing the selected $\\gamma^\\star$ for each test case, in the order given below, as a comma-separated list enclosed in square brackets (e.g., \"[$\\gamma_1^\\star,\\gamma_2^\\star,\\dots$]\").\n\nImplement and evaluate your program on the following test suite. In all cases, the gene universe is $\\{0,1,\\dots,N-1\\}$ and all $W_{ii} = 0$.\n\nTest Case A (structured network with background genes):\n- Network size: $N = 10$ with nodes $\\{0,1,\\dots,9\\}$.\n- Pathways: $P_1 = \\{0,1,2,3\\}$, $P_2 = \\{4,5,6,7\\}$.\n- Weight construction:\n  - For $i \\ne j$ both in $P_1$ or both in $P_2$, set $W_{ij} = 1.0$.\n  - Within $P_1$, for the pairs $\\{0,1\\}$ and $\\{2,3\\}$, add an increment of +0.3 to $W_{ij}$.\n  - For $i \\in P_1$ and $j \\in P_2$ (or vice versa), set $W_{ij} = 0.2$.\n  - For background nodes $B = \\{8,9\\}$ and $j \\in P_1 \\cup P_2$, set $W_{ij} = 0.1$ when $i \\in B$ (and symmetrically).\n  - For the pair $\\{8,9\\}$, set $W_{89} = W_{98} = 0.05$.\n- Resolution grid: $\\Gamma_A = [0.5, 1.0, 2.0]$.\n\nTest Case B (uniform complete network):\n- Network size: $N = 6$ with nodes $\\{0,1,\\dots,5\\}$.\n- Pathways: $P_1 = \\{0,1,2\\}$, $P_2 = \\{3,4,5\\}$.\n- Weight construction: for $i \\ne j$, set $W_{ij} = 1.0$.\n- Resolution grid: $\\Gamma_B = [0.5, 1.0, 2.0]$.\n\nTest Case C (three-group network with asymmetric intergroup coupling and substructure):\n- Network size: $N = 12$ with nodes $\\{0,1,\\dots,11\\}$.\n- Pathways: $P_1 = \\{0,1,2,3\\}$, $P_2 = \\{4,5,6,7\\}$, $P_3 = \\{8,9,10,11\\}$.\n- Weight construction:\n  - For $i \\ne j$ within the same pathway, set $W_{ij} = 1.0$.\n  - Within each pathway, for the subpairs $\\{0,1\\}$, $\\{2,3\\}$, $\\{4,5\\}$, $\\{6,7\\}$, $\\{8,9\\}$, $\\{10,11\\}$, add an increment of +0.4 to $W_{ij}$.\n  - For $i \\in P_1$ and $j \\in P_2$ (or vice versa), set $W_{ij} = 0.5$.\n  - For $i \\in P_1 \\cup P_2$ and $j \\in P_3$ (or vice versa), set $W_{ij} = 0.1$.\n- Resolution grid: $\\Gamma_C = [0.3, 1.0, 2.0]$.\n\nAngle units are not applicable. No physical units are involved. All numeric answers must be treated as dimensionless. Your program must output the selected $\\gamma^\\star$ values as real numbers in a single line formatted as a comma-separated list enclosed in square brackets, with no additional whitespace or text, in the order [Test Case A, Test Case B, Test Case C].", "solution": "The user-provided problem is valid. It is scientifically grounded in the fields of network science and computational systems biology, well-posed with a clear objective and deterministic procedures, and all necessary data and definitions are provided. The task is to implement a multi-step computational pipeline to select an optimal resolution parameter, $\\gamma^\\star$, for community detection in gene coexpression networks. The selection is based on matching detected modules to known biological pathways.\n\nThe solution is implemented by following a three-part procedure for each test case: (1) community detection for each $\\gamma$ in a given grid, (2) enrichment analysis of the resulting partitions against known pathways, and (3) selection of the optimal $\\gamma^\\star$ based on a tiered set of criteria.\n\nFirst, we define the mathematical and algorithmic basis for the solution. The network is an undirected weighted graph with $N$ nodes (genes) and a symmetric weight matrix $W$, where $W_{ij}$ represents coexpression strength. The strength of a node $i$ is $k_i = \\sum_j W_{ij}$, and the total weight in the network is $2m = \\sum_i k_i = \\sum_{i,j} W_{ij}$.\n\nThe modularity $Q$ of a network partition at a given resolution $\\gamma$ is\n$$\nQ(\\gamma) \\;=\\; \\frac{1}{2m} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\left( W_{ij} \\;-\\; \\gamma \\frac{k_i k_j}{2m} \\right) \\mathbf{1}\\{c_i = c_j\\}\n$$\nwhere $c_i$ is the community assignment of node $i$. This can be expressed as a sum over communities $C$:\n$$\nQ(\\gamma) = \\sum_C \\left[ \\frac{\\Sigma_{in}(C)}{2m} - \\gamma \\left( \\frac{\\Sigma_{tot}(C)}{2m} \\right)^2 \\right]\n$$\nwhere $\\Sigma_{in}(C) = \\sum_{i,j \\in C} W_{ij}$ is the sum of weights of all edges within community $C$ (with each edge counted twice), and $\\Sigma_{tot}(C) = \\sum_{i \\in C} k_i$ is the sum of strengths of all nodes in $C$.\n\nThe community detection is performed via a greedy agglomerative algorithm. Starting with each node in its own community (the singleton partition), we iteratively merge the pair of communities that yields the largest strictly positive increase in modularity, $\\Delta Q(\\gamma)$. The change in modularity from merging two communities $C_a$ and $C_b$ is derived as:\n$$\n\\Delta Q(C_a, C_b) = 2 \\left( \\frac{\\sum_{i \\in C_a, j \\in C_b} W_{ij}}{2m} - \\gamma \\frac{\\left(\\sum_{i \\in C_a} k_i\\right) \\left(\\sum_{j \\in C_b} k_j\\right)}{(2m)^2} \\right)\n$$\nThe merging process terminates when no pair of communities can be merged to produce a strictly positive $\\Delta Q(\\gamma)$. This procedure is performed independently for each value of $\\gamma$ in the specified grid.\n\nSecond, for each partition obtained, we perform gene set enrichment analysis. For each detected module $S$ and each known pathway $P$, we assess the significance of their overlap. This is quantified by the $p$-value from a Hypergeometric test. The probability of observing an overlap of size $k = |S \\cap P|$ or greater is given by $p = \\mathbb{P}[X \\ge k]$, where $X \\sim \\mathrm{Hypergeometric}(N, K, n)$, with $N$ being the total number of genes in the universe, $K=|P|$ the size of the pathway, and $n=|S|$ the size of the module. This $p$-value is calculated as:\n$$\np(S,P) \\;=\\; \\sum_{i=k}^{\\min(n,K)} \\frac{\\binom{K}{i} \\binom{N-K}{n-i}}{\\binom{N}{n}}\n$$\nTo account for multiple comparisons, a Bonferroni correction is applied. A module-pathway pair is deemed significant if its $p$-value is less than $\\alpha/T$, where $\\alpha=0.05$ and $T$ is the total number of tests (number of modules multiplied by the number of pathways). We then compute $E(\\gamma)$, the total count of modules that have a significant enrichment with at least one pathway.\n\nThird, we select the optimal resolution parameter $\\gamma^\\star$ by applying a three-tiered rule to the results obtained across all tested $\\gamma$ values:\n1.  Primary criterion: Select the $\\gamma$ value(s) that maximize the number of enriched modules, $E(\\gamma)$.\n2.  Secondary criterion (tie-breaker): From the candidates selected in the first step, choose the $\\gamma$ for which the number of detected modules is closest to the number of known pathways, i.e., minimize $|\\text{number of modules} - \\text{number of pathways}|$.\n3.  Tertiary criterion (final tie-breaker): If a tie persists, choose the smallest numerical value of $\\gamma$.\n\nThe implementation will construct the specific weight matrix $W$ for each test case, then execute this entire pipeline to determine $\\gamma^\\star$. The final program consolidates this logic into a self-contained script that processes all test cases and outputs the results in the specified format. The Hypergeometric survival function from the `scipy.stats` library is used for efficient and accurate calculation of $p$-values.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import hypergeom\n\ndef greedy_modularity_maximization(W, gamma, N):\n    \"\"\"Performs greedy modularity maximization for a given gamma.\"\"\"\n    k = W.sum(axis=1)\n    m2 = k.sum()\n    if m2 == 0:\n        return [{i} for i in range(N)]\n\n    # Initial state: each node is a community\n    communities = {i: {i} for i in range(N)}\n    active_comms = list(range(N))\n    \n    # Community-level properties\n    Sig_tot = {i: k[i] for i in range(N)}\n    Sig_ab = {i: {j: W[i, j] for j in range(N)} for i in range(N)}\n\n    while len(active_comms)  1:\n        best_delta_Q = 0.0\n        best_pair = None\n\n        # Find best pair to merge among active communities\n        for i_idx, comm_i in enumerate(active_comms):\n            for j_idx in range(i_idx + 1, len(active_comms)):\n                comm_j = active_comms[j_idx]\n                \n                sum_weights_between = Sig_ab[comm_i][comm_j]\n                sum_strengths_i = Sig_tot[comm_i]\n                sum_strengths_j = Sig_tot[comm_j]\n                \n                delta_Q = 2 * (sum_weights_between / m2 - gamma * sum_strengths_i * sum_strengths_j / (m2**2))\n\n                if delta_Q  best_delta_Q:\n                    best_delta_Q = delta_Q\n                    best_pair = (min(comm_i, comm_j), max(comm_i, comm_j))\n        \n        if best_pair is None:\n            break\n        \n        # Perform the merge\n        i, j = best_pair\n        \n        communities[i].update(communities[j])\n        del communities[j]\n        \n        for k_comm in active_comms:\n            if k_comm != i and k_comm != j:\n                new_weight_ik = Sig_ab[i][k_comm] + Sig_ab[j][k_comm]\n                Sig_ab[i][k_comm] = new_weight_ik\n                Sig_ab[k_comm][i] = new_weight_ik\n        \n        del Sig_ab[j]\n        for k_comm in Sig_ab:\n            if j in Sig_ab[k_comm]:\n                del Sig_ab[k_comm][j]\n\n        Sig_tot[i] += Sig_tot[j]\n        del Sig_tot[j]\n        \n        active_comms.remove(j)\n\n    return list(communities.values())\n\ndef perform_enrichment_analysis(modules, pathways, N):\n    \"\"\"Calculates the number of enriched modules.\"\"\"\n    num_modules = len(modules)\n    num_pathways = len(pathways)\n\n    if num_modules == 0 or num_pathways == 0:\n        return 0\n\n    T = num_modules * num_pathways\n    alpha = 0.05\n    threshold = alpha / T if T  0 else 0.0\n    \n    enriched_module_count = 0\n    for module_nodes in modules:\n        s_set = set(module_nodes)\n        n_size = len(s_set)\n        if n_size == 0 or n_size == N: continue\n\n        is_enriched = False\n        for pathway_nodes in pathways:\n            p_set = set(pathway_nodes)\n            K_size = len(p_set)\n            k_overlap = len(s_set.intersection(p_set))\n            \n            if k_overlap  0:\n                # hypergeom.sf computes P[X  x], so P[X = k] = sf(k-1)\n                # M=pop size, n=successes in pop, N=sample size\n                p_val = hypergeom.sf(k_overlap - 1, N, K_size, n_size)\n            else:\n                p_val = 1.0\n\n            if p_val  threshold:\n                is_enriched = True\n                break\n        \n        if is_enriched:\n            enriched_module_count += 1\n            \n    return enriched_module_count\n\ndef select_gamma(W, N, pathways, gamma_grid):\n    \"\"\"Selects the best gamma based on the specified criteria.\"\"\"\n    results = []\n    for gamma in gamma_grid:\n        modules = greedy_modularity_maximization(W, gamma, N)\n        num_modules = len(modules)\n        E_gamma = perform_enrichment_analysis(modules, pathways, N)\n        results.append({\n            \"gamma\": gamma,\n            \"E\": E_gamma,\n            \"num_modules\": num_modules\n        })\n    \n    max_E = -1\n    for res in results:\n        if res[\"E\"]  max_E:\n            max_E = res[\"E\"]\n            \n    candidates_E = [res for res in results if res[\"E\"] == max_E]\n    \n    if len(candidates_E) == 1:\n        return candidates_E[0][\"gamma\"]\n    \n    num_pathways = len(pathways)\n    min_diff = float('inf')\n    for res in candidates_E:\n        diff = abs(res[\"num_modules\"] - num_pathways)\n        if diff  min_diff:\n            min_diff = diff\n            \n    candidates_diff = [res for res in candidates_E if abs(res[\"num_modules\"] - num_pathways) == min_diff]\n    \n    min_gamma = float('inf')\n    best_gamma = None\n    for res in candidates_diff:\n        if res[\"gamma\"]  min_gamma:\n            min_gamma = res[\"gamma\"]\n            best_gamma = res[\"gamma\"]\n    \n    return best_gamma\n\ndef solve():\n    \"\"\"Main function to solve all test cases.\"\"\"\n    # Test Case A\n    N_A = 10\n    P_A1 = {0, 1, 2, 3}\n    P_A2 = {4, 5, 6, 7}\n    pathways_A = [P_A1, P_A2]\n    B_A = {8, 9}\n    W_A = np.zeros((N_A, N_A))\n    for i in range(N_A):\n        for j in range(i + 1, N_A):\n            w = 0.0\n            if (i in P_A1 and j in P_A1) or (i in P_A2 and j in P_A2):\n                w = 1.0\n            elif (i in P_A1 and j in P_A2) or (i in P_A2 and j in P_A1):\n                w = 0.2\n            elif (i in B_A and j not in B_A) or (j in B_A and i not in B_A):\n                w = 0.1\n            elif i in B_A and j in B_A:\n                w = 0.05\n            W_A[i, j] = W_A[j, i] = w\n    W_A[0, 1] += 0.3; W_A[1, 0] += 0.3\n    W_A[2, 3] += 0.3; W_A[3, 2] += 0.3\n    gamma_grid_A = [0.5, 1.0, 2.0]\n    gamma_star_A = select_gamma(W_A, N_A, pathways_A, gamma_grid_A)\n\n    # Test Case B\n    N_B = 6\n    pathways_B = [{0, 1, 2}, {3, 4, 5}]\n    W_B = np.ones((N_B, N_B))\n    np.fill_diagonal(W_B, 0)\n    gamma_grid_B = [0.5, 1.0, 2.0]\n    gamma_star_B = select_gamma(W_B, N_B, pathways_B, gamma_grid_B)\n    \n    # Test Case C\n    N_C = 12\n    P_C1, P_C2, P_C3 = {0, 1, 2, 3}, {4, 5, 6, 7}, {8, 9, 10, 11}\n    pathways_C = [P_C1, P_C2, P_C3]\n    W_C = np.zeros((N_C, N_C))\n    all_pathways_C = [P_C1, P_C2, P_C3]\n    node_to_pathway = {node: i for i, p in enumerate(all_pathways_C) for node in p}\n    for i in range(N_C):\n        for j in range(i + 1, N_C):\n            p_i, p_j = node_to_pathway[i], node_to_pathway[j]\n            w = 0.0\n            if p_i == p_j:\n                w = 1.0\n            elif (p_i in {0, 1} and p_j in {0, 1}):\n                w = 0.5\n            else:\n                w = 0.1\n            W_C[i, j] = W_C[j, i] = w\n    subpairs = [(0, 1), (2, 3), (4, 5), (6, 7), (8, 9), (10, 11)]\n    for u, v in subpairs:\n        W_C[u, v] += 0.4\n        W_C[v, u] += 0.4\n    gamma_grid_C = [0.3, 1.0, 2.0]\n    gamma_star_C = select_gamma(W_C, N_C, pathways_C, gamma_grid_C)\n\n    final_results = [gamma_star_A, gamma_star_B, gamma_star_C]\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n\n```", "id": "3328724"}]}