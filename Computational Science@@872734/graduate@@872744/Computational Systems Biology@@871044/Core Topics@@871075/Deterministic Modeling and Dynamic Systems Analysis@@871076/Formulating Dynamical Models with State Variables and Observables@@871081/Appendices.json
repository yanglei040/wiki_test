{"hands_on_practices": [{"introduction": "Biological systems are often described by complex networks of reactions, and a full mass-action model can be mathematically and parametrically unwieldy. A crucial skill for a modeler is to simplify these detailed descriptions into more tractable forms using physically-grounded assumptions. This exercise [@problem_id:3310431] guides you through applying the quasi-steady-state approximation (QSSA) to a phosphorylation cycle, a ubiquitous motif in cell signaling. By performing this model reduction, you will derive the famous Michaelis-Menten rate laws from first principles and gain critical insight into the concepts of lumped parameters and structural identifiability.", "problem": "A single-site phosphorylation cycle is implemented in vitro with a kinase and a phosphatase acting on a substrate. The substrate has an unphosphorylated form $X$ and a phosphorylated form $X_{P}$. The kinase $E$ and phosphatase $F$ reversibly bind their respective substrates to form complexes $C_{1}$ and $C_{2}$, followed by catalytic conversion. The reaction scheme is\n$$\nX + E \\xrightleftharpoons[k_{-1}]{k_{1}} C_{1} \\xrightarrow{k_{\\text{cat},1}} X_{P} + E, \\qquad\nX_{P} + F \\xrightleftharpoons[k_{-2}]{k_{2}} C_{2} \\xrightarrow{k_{\\text{cat},2}} X + F,\n$$\nwith total enzyme concentrations $E_{T}$ and $F_{T}$ conserved, and the system is well-mixed and closed with fixed total substrate $X_{T}$. Let the observable be $y(t) = X_{P}(t)$, and denote $x(t) = X(t)$, $c_{1}(t) = C_{1}(t)$, $c_{2}(t) = C_{2}(t)$, $e(t) = E(t)$, and $f(t) = F(t)$. All reactions obey mass-action kinetics, and $E_{T} = e + c_{1}$, $F_{T} = f + c_{2}$.\n\nStarting from mass-action kinetics and conservation laws as fundamental bases, perform variable elimination to demonstrate the dynamic equivalence between the full mass-action formulation with state variables $(x, y, c_{1}, c_{2}, e, f)$ and a reduced formulation in terms of the observable $y(t)$ and the substrate conservation $X_{T}$. Specifically:\n\n1. Apply the quasi-steady-state approximation (QSSA) for the complexes $C_{1}$ and $C_{2}$ and the catalytic regime assumption that enzymes are in catalytic amounts relative to substrate, so that complex contributions to the substrate conservation are negligible, i.e., $X_{T} \\approx x + y$.\n\n2. Eliminate $e$ and $f$ using the enzyme conservation relations and eliminate $c_{1}$ and $c_{2}$ using the quasi-steady-state approximation to obtain a single input-free ordinary differential equation for $y(t)$ of the form\n$$\n\\frac{dy}{dt} = f\\!\\left(y; X_{T}, V_{1}, K_{M,1}, V_{2}, K_{M,2}\\right),\n$$\nwith appropriate lumped parameters $V_{1}$, $K_{M,1}$, $V_{2}$, and $K_{M,2}$ defined in terms of the microscopic rate constants and totals.\n\n3. Explain briefly, using first principles of model reduction and observability, how the lumped parameters you obtain determine structural identifiability of the reduced model from measurements of $y(t)$ alone, and why individual microscopic rate constants cannot be identified without additional experimental information.\n\nYour final reported answer must be the explicit closed-form expression for the right-hand side $f\\!\\left(y; X_{T}, V_{1}, K_{M,1}, V_{2}, K_{M,2}\\right)$ as a single analytic expression. Do not include intermediate steps or parameter definitions in the final answer. No numerical evaluation is required. Express your final answer without units.", "solution": "We begin by formulating the complete system of ordinary differential equations (ODEs) describing the concentrations of all species based on the principle of mass-action kinetics. Let $x(t)$, $y(t)$, $e(t)$, $f(t)$, $c_1(t)$, and $c_2(t)$ denote the concentrations of $X$, $X_P$, $E$, $F$, $C_1$, and $C_2$, respectively. The reaction scheme is:\n$$\nX + E \\xrightleftharpoons[k_{-1}]{k_{1}} C_{1} \\xrightarrow{k_{\\text{cat},1}} X_{P} + E\n$$\n$$\nX_{P} + F \\xrightleftharpoons[k_{-2}]{k_{2}} C_{2} \\xrightarrow{k_{\\text{cat},2}} X + F\n$$\nThe corresponding ODEs are:\n$$\n\\frac{dc_{1}}{dt} = k_{1} x e - (k_{-1} + k_{\\text{cat},1}) c_{1}\n$$\n$$\n\\frac{dc_{2}}{dt} = k_{2} y f - (k_{-2} + k_{\\text{cat},2}) c_{2}\n$$\n$$\n\\frac{dy}{dt} = k_{\\text{cat},1} c_{1} - k_{2} y f + k_{-2} c_{2}\n$$\nThe system is subject to conservation laws for total enzyme concentrations, $E_{T}$ and $F_{T}$, and total substrate, $X_{T}$:\n$$\nE_{T} = e(t) + c_{1}(t)\n$$\n$$\nF_{T} = f(t) + c_{2}(t)\n$$\n$$\nX_{T} = x(t) + y(t) + c_{1}(t) + c_{2}(t)\n$$\nThe problem specifies two key assumptions for model reduction. First, the quasi-steady-state approximation (QSSA) is applied to the enzyme-substrate complexes, which are assumed to reach equilibrium much faster than the substrate concentrations change. This implies $\\frac{dc_{1}}{dt} \\approx 0$ and $\\frac{dc_{2}}{dt} \\approx 0$.\nApplying the QSSA to the ODE for $c_1$:\n$$\n0 \\approx k_{1} x e - (k_{-1} + k_{\\text{cat},1}) c_{1} \\implies c_{1} \\approx \\frac{k_{1} x e}{k_{-1} + k_{\\text{cat},1}}\n$$\nWe eliminate the free enzyme concentration $e$ using the conservation law $e = E_{T} - c_{1}$:\n$$\nc_{1} (k_{-1} + k_{\\text{cat},1}) \\approx k_{1} x (E_{T} - c_{1})\n$$\n$$\nc_{1} (k_{-1} + k_{\\text{cat},1} + k_{1} x) \\approx k_{1} x E_{T}\n$$\n$$\nc_{1} \\approx \\frac{k_{1} x E_{T}}{k_{-1} + k_{\\text{cat},1} + k_{1} x} = \\frac{x E_{T}}{\\frac{k_{-1} + k_{\\text{cat},1}}{k_{1}} + x}\n$$\nWe define the Michaelis constant for the kinase, $K_{M,1} = \\frac{k_{-1} + k_{\\text{cat},1}}{k_{1}}$, yielding the familiar Michaelis-Menten form:\n$$\nc_{1} \\approx \\frac{E_{T} x}{K_{M,1} + x}\n$$\nSimilarly, applying the QSSA to the ODE for $c_2$ and using $f = F_{T} - c_{2}$:\n$$\n0 \\approx k_{2} y f - (k_{-2} + k_{\\text{cat},2}) c_{2} \\implies c_{2} \\approx \\frac{k_{2} y (F_{T} - c_{2})}{k_{-2} + k_{\\text{cat},2}}\n$$\n$$\nc_{2} (k_{-2} + k_{\\text{cat},2} + k_{2} y) \\approx k_{2} y F_{T}\n$$\n$$\nc_{2} \\approx \\frac{k_{2} y F_{T}}{k_{-2} + k_{\\text{cat},2} + k_{2} y} = \\frac{y F_{T}}{\\frac{k_{-2} + k_{\\text{cat},2}}{k_{2}} + y}\n$$\nDefining the Michaelis constant for the phosphatase, $K_{M,2} = \\frac{k_{-2} + k_{\\text{cat},2}}{k_{2}}$, we obtain:\n$$\nc_{2} \\approx \\frac{F_{T} y}{K_{M,2} + y}\n$$\nNow, we find the reduced ODE for the observable $y = X_P$. The full ODE is $\\frac{dy}{dt} = k_{\\text{cat},1} c_{1} - k_{2} y f + k_{-2} c_{2}$. From the QSSA for $c_2$, we have $k_{2} y f - k_{-2} c_{2} = k_{\\text{cat},2} c_2$. Substituting this into the ODE for $y$ simplifies it significantly:\n$$\n\\frac{dy}{dt} = k_{\\text{cat},1} c_1 - (k_{2} y f - k_{-2} c_2) = k_{\\text{cat},1} c_{1} - k_{\\text{cat},2} c_{2}\n$$\nThis equation represents the net rate of change of the phosphorylated substrate as the difference between the kinase-catalyzed production rate and the phosphatase-catalyzed consumption rate.\nWe now substitute the QSSA expressions for $c_1$ and $c_2$ into this equation:\n$$\n\\frac{dy}{dt} \\approx k_{\\text{cat},1} \\left(\\frac{E_{T} x}{K_{M,1} + x}\\right) - k_{\\text{cat},2} \\left(\\frac{F_{T} y}{K_{M,2} + y}\\right)\n$$\nThe second assumption is that the total concentrations of the enzymes are catalytic, meaning $E_T \\ll X_T$ and $F_T \\ll X_T$. This justifies neglecting the amount of substrate sequestered in complexes, leading to the approximation $X_{T} \\approx x(t) + y(t)$. We use this to eliminate $x$:\n$$\nx(t) \\approx X_{T} - y(t)\n$$\nSubstituting this into the ODE gives an equation solely in terms of $y$:\n$$\n\\frac{dy}{dt} = k_{\\text{cat},1} E_{T} \\frac{X_{T} - y}{K_{M,1} + (X_{T} - y)} - k_{\\text{cat},2} F_{T} \\frac{y}{K_{M,2} + y}\n$$\nFinally, we define the maximal velocities for the kinase and phosphatase reactions as $V_{1} = k_{\\text{cat},1} E_{T}$ and $V_{2} = k_{\\text{cat},2} F_{T}$, respectively. These parameters represent the maximum rate of each reaction, achieved at saturating substrate concentrations. The final reduced ODE is:\n$$\n\\frac{dy}{dt} = \\frac{V_{1} (X_{T} - y)}{K_{M,1} + X_{T} - y} - \\frac{V_{2} y}{K_{M,2} + y}\n$$\nThis is the required function $f(y; X_{T}, V_{1}, K_{M,1}, V_{2}, K_{M,2})$.\n\nFor the third part of the problem, concerning structural identifiability: the process of model reduction has transformed a high-dimensional parameter space of microscopic constants $\\{k_1, k_{-1}, k_{\\text{cat},1}, k_2, k_{-2}, k_{\\text{cat},2}, E_T, F_T\\}$ into a low-dimensional space of lumped, effective parameters $\\{V_1, K_{M,1}, V_2, K_{M,2}\\}$. The dynamics of the observable, $y(t)$, are entirely determined by this reduced set of four parameters (assuming $X_T$ is known). By measuring $y(t)$ and its derivative $\\frac{dy}{dt}$ over a sufficient range, one can, in principle, uniquely determine the numerical values of $V_1$, $K_{M,1}$, $V_2$, and $K_{M,2}$. Thus, these lumped parameters are structurally identifiable from measurements of $y(t)$ alone.\nHowever, the microscopic rate constants are not. The mapping from the microscopic to the lumped parameters is many-to-one. For example, $V_1 = k_{\\text{cat},1} E_T$ and $K_{M,1} = (k_{-1} + k_{\\text{cat},1}) / k_1$. From a measured value of $V_1$, one can only determine the product $k_{\\text{cat},1} E_T$, not the individual values. An infinite number of combinations of $k_1$, $k_{-1}$, and $k_{\\text{cat},1}$ can yield the same value of $K_{M,1}$. Because it is impossible to uniquely solve for the eight microscopic parameters from the four equations defining the lumped parameters, the microscopic parameters are structurally non-identifiable. Determining them would require additional experiments designed to isolate subsystems or measure specific parameters directly (e.g., binding assays to determine $k_1/k_{-1}$).", "answer": "$$\n\\boxed{\\frac{V_{1} (X_{T} - y)}{K_{M,1} + X_{T} - y} - \\frac{V_{2} y}{K_{M,2} + y}}\n$$", "id": "3310431"}, {"introduction": "While we formulate models in the continuous domain of time, their simulation on computers and comparison with experimental data inherently occur at discrete time points. It is therefore essential to master the translation of a continuous-time model into an accurate discrete-time representation. This exercise [@problem_id:3310413] provides hands-on experience with the exact discretization of a linear time-invariant (LTI) model of gene expression using the zero-order hold (ZOH) method, a cornerstone technique for numerical simulation and systems identification.", "problem": "A two-state model of gene expression dynamics is used to describe messenger ribonucleic acid (mRNA) and protein concentrations in a single cell under transcriptional activation. The continuous-time model is a linear time-invariant (LTI) ordinary differential equation (ODE) of the form $\\frac{d\\mathbf{x}}{dt} = A \\mathbf{x} + B u$, with the observable (protein) given by $y = C \\mathbf{x} + D u$. The state vector is $\\mathbf{x} = \\begin{pmatrix} x_{m} \\\\ x_{p} \\end{pmatrix}$, where $x_{m}$ is mRNA concentration and $x_{p}$ is protein concentration. The model matrices and parameters are defined by biologically plausible first-order degradation and translation:\n- $A = \\begin{pmatrix} -\\gamma_{m} & 0 \\\\ k_{\\mathrm{tl}} & -\\gamma_{p} \\end{pmatrix}$,\n- $B = \\begin{pmatrix} k_{\\mathrm{tx}} \\\\ 0 \\end{pmatrix}$,\n- $C = \\begin{pmatrix} 0 & 1 \\end{pmatrix}$,\n- $D = 0$,\nwhere $\\gamma_{m} = 0.2$ min$^{-1}$, $\\gamma_{p} = 0.05$ min$^{-1}$, $k_{\\mathrm{tl}} = 0.6$ min$^{-1}$, and $k_{\\mathrm{tx}} = 1.2$ nM min$^{-1}$.\n\nAssume a Zero-Order Hold (ZOH) input scheme in which the input $u(t)$ is held constant over each sampling interval of width $\\Delta t = 10$ minutes, with discrete input samples $u[k]$ applied at times $t = k \\Delta t$. Consider a step activation $u[k] = u_{0}$ with $u_{0} = 2$ (dimensionless) for all $k \\ge 0$, and an initial condition $\\mathbf{x}(0) = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$ nM.\n\nStarting from the continuous-time ODE and the ZOH definition, construct the exact discrete-time state-space model $\\mathbf{x}[k+1] = A_{d} \\mathbf{x}[k] + B_{d} u[k]$, $y[k] = C \\mathbf{x}[k] + D u[k]$ at sampling period $\\Delta t$, by identifying $A_{d}$ and $B_{d}$ from first principles. Then, using this model, compute the observable protein concentration $y[2]$ (nanomolar) at the second sampling instant $t = 2 \\Delta t$, under the given step input and initial condition.\n\nExpress the final observable concentration in nanomolar (nM). Round your answer to four significant figures.", "solution": "The problem requires the construction of an exact discrete-time state-space model from a given continuous-time linear time-invariant (LTI) model, and then using it to compute a specific value of the observable output.\n\nThe continuous-time model is given by:\n$$ \\frac{d\\mathbf{x}}{dt} = A \\mathbf{x} + B u $$\n$$ y = C \\mathbf{x} + D u $$\nwhere the state vector is $\\mathbf{x} = \\begin{pmatrix} x_{m} \\\\ x_{p} \\end{pmatrix}$, representing mRNA and protein concentrations. The matrices and parameters are:\n- $A = \\begin{pmatrix} -\\gamma_{m} & 0 \\\\ k_{\\mathrm{tl}} & -\\gamma_{p} \\end{pmatrix}$\n- $B = \\begin{pmatrix} k_{\\mathrm{tx}} \\\\ 0 \\end{pmatrix}$\n- $C = \\begin{pmatrix} 0 & 1 \\end{pmatrix}$\n- $D = 0$\n- $\\gamma_{m} = 0.2$ min$^{-1}$, $\\gamma_{p} = 0.05$ min$^{-1}$, $k_{\\mathrm{tl}} = 0.6$ min$^{-1}$, $k_{\\mathrm{tx}} = 1.2$ nM min$^{-1}$.\n\nThe process involves discretizing the continuous-time system under a Zero-Order Hold (ZOH) on the input $u(t)$. With a ZOH, the input is held constant over each sampling interval $\\Delta t$, i.e., $u(t) = u[k]$ for $t \\in [k\\Delta t, (k+1)\\Delta t)$.\n\nThe solution to the continuous-time state equation over one sampling interval, from $t_k = k\\Delta t$ to $t_{k+1} = (k+1)\\Delta t$, is given by the variation of constants formula:\n$$ \\mathbf{x}(t_{k+1}) = e^{A(t_{k+1}-t_k)} \\mathbf{x}(t_k) + \\int_{t_k}^{t_{k+1}} e^{A(t_{k+1}-\\tau)} B u(\\tau) d\\tau $$\nLetting $\\mathbf{x}[k] = \\mathbf{x}(k\\Delta t)$ and substituting $u(\\tau) = u[k]$ for the interval, we get:\n$$ \\mathbf{x}[k+1] = e^{A\\Delta t} \\mathbf{x}[k] + \\left( \\int_{k\\Delta t}^{(k+1)\\Delta t} e^{A((k+1)\\Delta t-\\tau)} d\\tau \\right) B u[k] $$\nBy changing the integration variable to $\\sigma = (k+1)\\Delta t - \\tau$, the integral becomes $\\int_{0}^{\\Delta t} e^{A\\sigma} d\\sigma$.\nThus, the exact discrete-time model is:\n$$ \\mathbf{x}[k+1] = A_d \\mathbf{x}[k] + B_d u[k] $$\nwhere\n$$ A_d = e^{A\\Delta t} $$\n$$ B_d = \\left( \\int_{0}^{\\Delta t} e^{A\\sigma} d\\sigma \\right) B $$\nSince the matrix $A$ is invertible (its determinant is $\\gamma_m \\gamma_p \\neq 0$), the integral for $B_d$ can be calculated as $B_d = A^{-1}(e^{A\\Delta t} - I)B = A^{-1}(A_d - I)B$.\n\nFirst, we find $A_d = e^{A\\Delta t}$. The matrix $A$ is lower triangular. The matrix exponential $e^{At}$ can be calculated by solving the underlying system of ODEs or by diagonalization. The result is:\n$$ e^{At} = \\begin{pmatrix} e^{-\\gamma_{m}t} & 0 \\\\ \\frac{k_{\\mathrm{tl}}}{\\gamma_{p}-\\gamma_{m}}(e^{-\\gamma_{m}t} - e^{-\\gamma_{p}t}) & e^{-\\gamma_{p}t} \\end{pmatrix} $$\nSubstituting $t=\\Delta t$, we get $A_d$:\n$$ A_d = \\begin{pmatrix} e^{-\\gamma_{m}\\Delta t} & 0 \\\\ \\frac{k_{\\mathrm{tl}}}{\\gamma_{p}-\\gamma_{m}}(e^{-\\gamma_{m}\\Delta t} - e^{-\\gamma_{p}\\Delta t}) & e^{-\\gamma_{p}\\Delta t} \\end{pmatrix} $$\n\nNext, we find $B_d$. The first component, $(B_d)_1$, corresponds to the change in $x_m$ due to the input. We can find it by integrating the first state equation: $dx_m/dt = -\\gamma_m x_m + k_{tx} u$. The contribution from the input $u[k]$ over $[0, \\Delta t]$ with zero initial state is $\\frac{k_{\\mathrm{tx}}}{\\gamma_m}(1 - e^{-\\gamma_m\\Delta t})u[k]$. Thus:\n$$ (B_d)_1 = \\frac{k_{\\mathrm{tx}}}{\\gamma_m}(1 - e^{-\\gamma_m\\Delta t}) $$\nThe second component, $(B_d)_2$, can be found using the formula $B_d = A^{-1}(A_d-I)B$. This yields:\n$$ (B_d)_2 = \\frac{k_{\\mathrm{tl}}k_{\\mathrm{tx}}}{\\gamma_m\\gamma_p} \\left( 1 + \\frac{\\gamma_m e^{-\\gamma_p \\Delta t} - \\gamma_p e^{-\\gamma_m \\Delta t}}{\\gamma_p - \\gamma_m} \\right) $$\n\nNow we substitute the numerical values:\n- $\\gamma_{m} = 0.2$ min$^{-1}$\n- $\\gamma_{p} = 0.05$ min$^{-1}$\n- $k_{\\mathrm{tl}} = 0.6$ min$^{-1}$\n- $k_{\\mathrm{tx}} = 1.2$ nM min$^{-1}$\n- $\\Delta t = 10$ min\n- $u[k] = 2$ for $k \\ge 0$\n- $\\mathbf{x}[0] = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$\n\nThe exponents are:\n- $\\gamma_m \\Delta t = 0.2 \\times 10 = 2$\n- $\\gamma_p \\Delta t = 0.05 \\times 10 = 0.5$\nSo, $e^{-\\gamma_m \\Delta t} = e^{-2}$ and $e^{-\\gamma_p \\Delta t} = e^{-0.5}$.\n\nCalculating the elements of $A_d$:\n$$ (A_d)_{11} = e^{-2} \\approx 0.135335 $$\n$$ (A_d)_{21} = \\frac{0.6}{0.05-0.2}(e^{-2} - e^{-0.5}) = \\frac{0.6}{-0.15}(e^{-2} - e^{-0.5}) = -4(0.135335 - 0.606531) \\approx 1.884784 $$\n$$ (A_d)_{22} = e^{-0.5} \\approx 0.606531 $$\nSo,\n$$ A_d \\approx \\begin{pmatrix} 0.135335 & 0 \\\\ 1.884784 & 0.606531 \\end{pmatrix} $$\n\nCalculating the elements of $B_d$:\n$$ (B_d)_1 = \\frac{1.2}{0.2}(1 - e^{-2}) = 6(1 - 0.135335) \\approx 5.18799 $$\n$$ (B_d)_2 = \\frac{0.6 \\times 1.2}{0.2 \\times 0.05} \\left( 1 + \\frac{0.2 e^{-0.5} - 0.05 e^{-2}}{0.05 - 0.2} \\right) = 72 \\left( 1 + \\frac{0.2(0.606531) - 0.05(0.135335)}{-0.15} \\right) $$\n$$ (B_d)_2 \\approx 72 \\left( 1 + \\frac{0.1213062 - 0.00676675}{-0.15} \\right) = 72 \\left( 1 - \\frac{0.11453945}{0.15} \\right) = 72(1 - 0.7635963) \\approx 17.02106 $$\nSo,\n$$ B_d \\approx \\begin{pmatrix} 5.18799 \\\\ 17.02106 \\end{pmatrix} $$\n\nWe can now compute the state vectors at the sampling instants. The initial state is $\\mathbf{x}[0] = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$ and the input is $u[k] = 2$.\n\nFor $k=0$:\n$$ \\mathbf{x}[1] = A_d \\mathbf{x}[0] + B_d u[0] = A_d \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} + B_d (2) = 2 B_d $$\n$$ \\mathbf{x}[1] \\approx 2 \\begin{pmatrix} 5.18799 \\\\ 17.02106 \\end{pmatrix} = \\begin{pmatrix} 10.37598 \\\\ 34.04212 \\end{pmatrix} $$\n\nFor $k=1$:\n$$ \\mathbf{x}[2] = A_d \\mathbf{x}[1] + B_d u[1] $$\n$$ \\mathbf{x}[2] \\approx \\begin{pmatrix} 0.135335 & 0 \\\\ 1.884784 & 0.606531 \\end{pmatrix} \\begin{pmatrix} 10.37598 \\\\ 34.04212 \\end{pmatrix} + \\begin{pmatrix} 5.18799 \\\\ 17.02106 \\end{pmatrix} (2) $$\nThe observable is $y[k] = C \\mathbf{x}[k] = \\begin{pmatrix} 0 & 1 \\end{pmatrix} \\mathbf{x}[k] = x_p[k]$. We need to compute $y[2] = x_p[2]$, which is the second component of $\\mathbf{x}[2]$.\n$$ x_p[2] \\approx (1.884784)(10.37598) + (0.606531)(34.04212) + (17.02106)(2) $$\n$$ x_p[2] \\approx 19.5564 + 20.6483 + 34.04212 $$\n$$ x_p[2] \\approx 74.24682 $$\nThe problem asks for the answer to be rounded to four significant figures.\n$$ y[2] = x_p[2] \\approx 74.25 $$", "answer": "$$\\boxed{74.25}$$", "id": "3310471"}, {"introduction": "A well-formulated dynamical model is more than a set of equations; it is a hypothesis about how a system functions, and its power lies in its ability to predict emergent behaviors. This practice [@problem_id:3310471] delves into the analysis of a nonlinear model representing a genetic feedback loop, a common architecture for cellular decision-making. By identifying the system's equilibrium points and analyzing their local stability using the Jacobian matrix, you will uncover how such a simple circuit can give rise to bistability, a key mechanism for generating distinct and robust cellular phenotypes.", "problem": "Consider a reduced two-gene feedback module written in terms of dimensionless deviations from a basal steady state. Let the state vector be $x(t)$ and $y(t)$, where $x$ and $y$ represent small, signed deviations of two interacting protein concentrations from their respective basal levels. Around this operating point, assume the interaction nonlinearities can be captured by the lowest-order odd polynomial consistent with symmetry and mass-balance degradation, leading to the ordinary differential equations (ODE)\n$$\n\\frac{dx}{dt} \\;=\\; -\\,x \\;+\\; k\\,y \\;-\\; y^{3}, \n\\qquad\n\\frac{dy}{dt} \\;=\\; -\\,y \\;+\\; k\\,x \\;-\\; x^{3},\n$$\nwhere $k$ is a positive dimensionless feedback strength parameter. The observable (what is measured experimentally) is a linear readout of the two proteins given by\n$$\nz \\;=\\; x \\;+\\; 2\\,y,\n$$\nwhich can be interpreted, for example, as a fluorescence channel more sensitive to $y$ than to $x$. All variables and parameters are dimensionless.\n\nTasks:\n- Using only foundational principles for deterministic dynamical systems, namely that equilibria satisfy $\\frac{dx}{dt} = 0$ and $\\frac{dy}{dt} = 0$, and that local stability is determined by the eigenvalues of the Jacobian matrix of the vector field evaluated at equilibria, compute all equilibrium points of the system in terms of $k$ and analyze the local stability of each equilibrium by evaluating the Jacobian eigenvalues.\n- Interpret the biological implications of the different stability types you find (for example, asymptotically stable nodes, saddles, and unstable equilibria) in the context of phenotype selection and basin boundaries in a feedback gene module.\n- Assume $k$ lies in the range $1 < k < 2$. Among the equilibria present in this regime, there is exactly one equilibrium with $x>0$ and $y>0$ that is asymptotically stable. Let $(x^{\\star},y^{\\star})$ denote this equilibrium. What is the closed-form expression for the observable $z^{\\star} = x^{\\star} + 2\\,y^{\\star}$ in terms of $k$?\n\nAnswer format:\n- Provide a single closed-form analytic expression for $z^{\\star}$ in terms of $k$. Do not include units. Do not provide intermediate steps in the final answer box. No rounding is required.", "solution": "We start from the definitions: equilibria solve $\\frac{dx}{dt}=0$ and $\\frac{dy}{dt}=0$. Local stability is determined by the eigenvalues of the Jacobian matrix $J(x,y)$ of the vector field at each equilibrium. If all eigenvalues have negative real parts, the equilibrium is locally asymptotically stable; if one eigenvalue has positive real part and another negative, the equilibrium is a saddle.\n\nStep $1$: Compute equilibria. Set\n$$\n0 \\;=\\; -\\,x \\;+\\; k\\,y \\;-\\; y^{3}, \\qquad 0 \\;=\\; -\\,y \\;+\\; k\\,x \\;-\\; x^{3}.\n$$\nWe look for symmetric equilibria on the diagonal $x=y$ and antisymmetric equilibria on the anti-diagonal $y=-x$; these arise naturally due to the symmetry of the right-hand sides under interchange of $x$ and $y$.\n\n- Diagonal equilibria $x=y=s$: Substituting $x=y=s$ yields\n$$\n0 \\;=\\; -\\,s \\;+\\; k\\,s \\;-\\; s^{3} \\;=\\; s\\big(k-1-s^{2}\\big).\n$$\nThus $s=0$ or $s^{2}=k-1$. Therefore, diagonal equilibria are\n$$\n(x,y) \\;=\\; (0,0) \\quad\\text{and}\\quad (x,y)\\;=\\;(\\pm \\sqrt{k-1}, \\pm \\sqrt{k-1}),\n$$\nthe latter existing when $k>1$.\n\n- Anti-diagonal equilibria $y=-x=s'$ with $x=s$ and $y=-s$: Substituting $y=-x$ into the first equation gives\n$$\n0 \\;=\\; -\\,x \\;+\\; k(-x) \\;-\\; (-x)^{3} \\;=\\; -\\,(1+k)\\,x \\;+\\; x^{3} \\;=\\; x\\big(x^{2}-(k+1)\\big).\n$$\nThus $x=0$ or $x^{2}=k+1$. The corresponding equilibria are\n$$\n(x,y)\\;=\\;(0,0)\\quad\\text{and}\\quad (x,y)\\;=\\;(\\pm \\sqrt{k+1}, \\mp \\sqrt{k+1}),\n$$\nthe latter existing when $k>-1$. The point $(0,0)$ has already been found. Therefore, for $k>1$, there are five equilibria:\n$$\n(0,0),\\quad (\\sqrt{k-1},\\sqrt{k-1}),\\quad (-\\sqrt{k-1},-\\sqrt{k-1}),\\quad (\\sqrt{k+1},-\\sqrt{k+1}),\\quad (-\\sqrt{k+1},\\sqrt{k+1}).\n$$\n\nStep $2$: Compute the Jacobian and classify equilibria by eigenvalues. The Jacobian matrix is\n$$\nJ(x,y) \\;=\\; \\begin{pmatrix}\n\\frac{\\partial}{\\partial x}\\big(-x + k y - y^{3}\\big) & \\frac{\\partial}{\\partial y}\\big(-x + k y - y^{3}\\big) \\\\\n\\frac{\\partial}{\\partial x}\\big(-y + k x - x^{3}\\big) & \\frac{\\partial}{\\partial y}\\big(-y + k x - x^{3}\\big)\n\\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n-1 & k - 3 y^{2} \\\\\nk - 3 x^{2} & -1\n\\end{pmatrix}.\n$$\n\n- At $(0,0)$: We have $J(0,0) = \\begin{pmatrix} -1 & k \\\\ k & -1 \\end{pmatrix}$. The eigenvalues of a matrix $\\begin{pmatrix} a & b \\\\ b & a \\end{pmatrix}$ are $a\\pm b$. Hence\n$$\n\\lambda_{1,2}(0,0) \\;=\\; -1 \\pm k.\n$$\nFor $k>1$, one eigenvalue is positive (namely $-1+k$) and one is negative (namely $-1-k$), so $(0,0)$ is a saddle.\n\n- At $(\\pm \\sqrt{k-1}, \\pm \\sqrt{k-1})$: Let $s=\\sqrt{k-1}$, so $x=y=s$ or $x=y=-s$. In either case $x^{2}=y^{2}=s^{2}=k-1$. Then\n$$\nJ(s,s) \\;=\\; \\begin{pmatrix} -1 & k - 3 s^{2} \\\\ k - 3 s^{2} & -1 \\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix} -1 & 3 - 2k \\\\ 3 - 2k & -1 \\end{pmatrix},\n$$\nbecause $k - 3 s^{2} = k - 3(k-1) = 3 - 2k$. The eigenvalues are\n$$\n\\lambda_{1,2}(s,s) \\;=\\; -1 \\pm (3 - 2k) \\;=\\; 2(1-k),\\;\\; 2(k-2).\n$$\nFor $1<k<2$, both eigenvalues are negative, so both $(\\sqrt{k-1},\\sqrt{k-1})$ and $(-\\sqrt{k-1},-\\sqrt{k-1})$ are asymptotically stable nodes. For $k>2$, one eigenvalue is positive and one negative, so they become saddles.\n\n- At $(\\pm \\sqrt{k+1}, \\mp \\sqrt{k+1})$: Let $r=\\sqrt{k+1}$, so $x=r$, $y=-r$ or $x=-r$, $y=r$, with $x^{2}=y^{2}=r^{2}=k+1$. Then\n$$\nJ(r,-r) \\;=\\; \\begin{pmatrix} -1 & k - 3 r^{2} \\\\ k - 3 r^{2} & -1 \\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix} -1 & -\\,2k - 3 \\\\ -\\,2k - 3 & -1 \\end{pmatrix},\n$$\nbecause $k - 3 r^{2} = k - 3(k+1) = -2k - 3$. The eigenvalues are\n$$\n\\lambda_{1,2}(r,-r) \\;=\\; -1 \\pm (-2k - 3) \\;=\\; -2(k+2),\\;\\; 2(k+1).\n$$\nFor all $k>-1$, one eigenvalue is negative and one is positive, so these equilibria are saddles.\n\nTherefore, in the regime $1<k<2$, there are exactly two asymptotically stable nodes at $(\\sqrt{k-1},\\sqrt{k-1})$ and $(-\\sqrt{k-1},-\\sqrt{k-1})$, and three saddles at $(0,0)$ and $(\\pm \\sqrt{k+1}, \\mp \\sqrt{k+1})$.\n\nStep $3$: Biological interpretation. In a computational systems biology context, the asymptotically stable nodes represent robust phenotypic states of the two-gene module: the equilibrium $(\\sqrt{k-1},\\sqrt{k-1})$ corresponds to both proteins elevated above basal levels (positive deviations), and $(-\\sqrt{k-1},-\\sqrt{k-1})$ corresponds to both below basal levels (negative deviations). The saddles act as separatrices (thresholds) that partition the state space into basins of attraction of these phenotypes; small perturbations near a saddle can grow in one direction and decay in another, steering the system toward one of the stable phenotypes. The presence of two stable nodes for $1<k<2$ indicates bistability mediated by feedback. The loss of stability of the diagonal nodes when $k>2$ (one eigenvalue crossing zero at $k=2$) signals a change in qualitative dynamics consistent with a local bifurcation.\n\nStep $4$: Compute the requested observable at the positive diagonal stable equilibrium for $1<k<2$. The equilibrium with $x>0$ and $y>0$ is $(x^{\\star},y^{\\star})=(\\sqrt{k-1},\\sqrt{k-1})$. Therefore,\n$$\nz^{\\star} \\;=\\; x^{\\star} + 2\\,y^{\\star} \\;=\\; \\sqrt{k-1} + 2\\,\\sqrt{k-1} \\;=\\; 3\\,\\sqrt{k-1}.\n$$\nThis is a closed-form analytic expression in terms of $k$, as required. No rounding is necessary because the variables are dimensionless and the expression is exact.", "answer": "$$\\boxed{3\\sqrt{k-1}}$$", "id": "3310413"}]}