{"hands_on_practices": [{"introduction": "A fundamental step in developing reliable numerical codes is to verify that they achieve their designed order of accuracy. This exercise introduces the Method of Manufactured Solutions, a powerful technique for precisely measuring convergence rates by constructing a problem with a known analytic solution. By applying this method to a model constraint system, you will gain hands-on experience with the essential practice of code verification [@problem_id:3469183].", "problem": "You are to implement and verify the scaling of the discrete constraint residuals, modeled on the Hamiltonian constraint and momentum constraints used in numerical relativity, under uniform grid refinement and optional constraint damping. Use a manufactured-solution test in a three-dimensional periodic domain to ensure that the continuum constraints vanish identically so that the discrete residuals directly measure truncation error. Your task is to compute the observed order of accuracy and to verify the expected $\\mathcal{O}(\\Delta x^{p})$ behavior, where $\\Delta x$ is the grid spacing and $p$ is the formal order of the finite-difference stencil.\n\nFundamental base:\n- The discrete truncation error of a consistent, centered, order-$p$ finite-difference approximation to a smooth derivative scales as $\\mathcal{O}(\\Delta x^{p})$.\n- The $L^{2}$ norm of a function $f$ over a domain $\\Omega$ with volume $V$ is defined as $\\lVert f \\rVert_{2} = \\left( \\int_{\\Omega} f^{2} \\, dV \\right)^{1/2}$. On a uniform grid in three dimensions with spacing $\\Delta x$ and total volume $V = 1$, the discrete $L^{2}$ norm is computed as $\\left( \\sum f^{2} \\Delta x^{3} \\right)^{1/2}$, which equals $\\left( \\mathrm{mean}(f^{2}) \\right)^{1/2}$.\n- If a constraint field $C$ satisfies a homogeneous damping law $\\partial_{t} C = - \\kappa C$, its exact solution after a fixed physical time $T$ is $C \\mapsto e^{-\\kappa T} C$, which does not alter the asymptotic order in $\\Delta x$.\n\nSet-up:\n- Domain: the periodic cube $[0,1]^{3}$ with uniform Cartesian grid spacing $\\Delta x = 1/N$ for a given integer $N \\ge 8$.\n- Angles in the trigonometric functions must be in radians.\n- Manufactured smooth analytic fields:\n  1. A scalar field $\\phi(x,y,z) = \\sin(2\\pi x)\\cos(2\\pi y) + \\sin(2\\pi z)$.\n  2. A scalar field $\\pi(x,y,z) = \\exp\\!\\big(\\sin(2\\pi x) + \\cos(2\\pi y) + \\sin(2\\pi z)\\big)$.\n- Define exact source fields so that the continuum constraints vanish:\n  1. The exact Laplacian of $\\phi$ is $\\nabla^{2}\\phi = -2(2\\pi)^{2} \\sin(2\\pi x)\\cos(2\\pi y) - (2\\pi)^{2} \\sin(2\\pi z)$. Define $S(x,y,z)$ to equal this exact Laplacian so that the continuum Hamiltonian constraint $H \\equiv \\nabla^{2}\\phi - S$ is identically zero.\n  2. The exact gradient of $\\pi$ is $\\nabla \\pi = \\big(\\partial_{x}\\pi,\\partial_{y}\\pi,\\partial_{z}\\pi\\big)$ with $\\partial_{x}\\pi = (2\\pi)\\cos(2\\pi x)\\,\\pi$, $\\partial_{y}\\pi = -(2\\pi)\\sin(2\\pi y)\\,\\pi$, and $\\partial_{z}\\pi = (2\\pi)\\cos(2\\pi z)\\,\\pi$. Define the exact vector source $J_{i}$ to equal these components so that the continuum momentum constraint $M_{i} \\equiv \\partial_{i}\\pi - J_{i}$ is identically zero.\n- Discrete operators:\n  - Let $D^{(p)}_{i}$ denote a standard centered, order-$p$ accurate finite-difference approximation to the first derivative $\\partial_{i}$ on a periodic uniform grid.\n  - Let $\\Delta^{(p)}$ denote a standard centered, order-$p$ accurate finite-difference approximation to the Laplacian $\\nabla^{2}$ on a periodic uniform grid, constructed as the sum of the second derivatives along each axis, each approximated to order $p$.\n  - You must implement the usual centered stencils of order $p \\in \\{2,4\\}$ for both first and second derivatives on a periodic grid. Do not use one-sided stencils.\n- Discrete residuals and norms:\n  - The discrete Hamiltonian residual is $H_{h} = \\Delta^{(p)} \\phi - S$.\n  - The discrete momentum residuals are $M_{i,h} = D^{(p)}_{i}\\pi - J_{i}$ for $i \\in \\{x,y,z\\}$.\n  - Define the scalar $L^{2}$ norm for $H_{h}$ as $\\lVert H_{h}\\rVert_{2} = \\left( \\mathrm{mean}(H_{h}^{2}) \\right)^{1/2}$.\n  - Define the vector $L^{2}$ norm for $M_{i,h}$ as $\\lVert \\mathbf{M}_{h}\\rVert_{2} = \\left( \\mathrm{mean}\\big(M_{x,h}^{2} + M_{y,h}^{2} + M_{z,h}^{2}\\big) \\right)^{1/2}$.\n- Optional damping:\n  - After computing $H_{h}$ and $M_{i,h}$, optionally apply homogeneous constraint damping for a fixed physical time $T = 1$ with parameter $\\kappa \\ge 0$ by the exact multiplicative update $H_{h} \\mapsto e^{-\\kappa} H_{h}$ and $M_{i,h} \\mapsto e^{-\\kappa} M_{i,h}$.\n\nScaling measurement:\n- For a fixed order $p$ and damping parameter $\\kappa$, compute $\\lVert H_{h}\\rVert_{2}$ and $\\lVert \\mathbf{M}_{h}\\rVert_{2}$ for each grid resolution $N$ in a given list. Let $\\Delta x = 1/N$.\n- Fit the observed order $p_{\\mathrm{obs}}$ by linear regression of $\\log \\lVert H_{h}\\rVert_{2}$ versus $\\log \\Delta x$ and similarly for $\\log \\lVert \\mathbf{M}_{h}\\rVert_{2}$, so that $\\lVert \\cdot \\rVert_{2} \\approx C \\, (\\Delta x)^{p_{\\mathrm{obs}}}$.\n- Verification criterion: declare success if both observed orders, $p_{\\mathrm{obs}}(H)$ and $p_{\\mathrm{obs}}(M)$, satisfy $\\lvert p_{\\mathrm{obs}} - p \\rvert \\le \\varepsilon$ for a tolerance $\\varepsilon$.\n\nTest suite to implement:\n- Use the following four parameter sets to compute and verify the observed orders. For each set, angles are in radians, and the damping update uses $T = 1$ as described above.\n  1. Case $1$: $p = 2$, $\\kappa = 0$, $N \\in \\{16, 24, 32, 48\\}$.\n  2. Case $2$: $p = 4$, $\\kappa = 0$, $N \\in \\{16, 24, 32, 48\\}$.\n  3. Case $3$: $p = 2$, $\\kappa = 20$, $N \\in \\{16, 24, 32, 48\\}$.\n  4. Case $4$: $p = 4$, $\\kappa = 10$, $N \\in \\{16, 24, 32, 48\\}$.\n- Use tolerance $\\varepsilon = 0.2$ for all cases.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the four cases. Each entry is a boolean that is $True$ if and only if both constraints meet the verification criterion for that case, and $False$ otherwise. For example, a valid output line is of the form $[b_{1},b_{2},b_{3},b_{4}]$ where each $b_{i}$ is either $True$ or $False$.", "solution": "The problem statement is valid. It describes a well-posed numerical verification task using a manufactured solution, a standard and scientifically sound method in the study of partial differential equations and numerical analysis. All parameters, equations, and procedures are defined precisely and are mutually consistent.\n\nThe solution to this problem is founded on several key principles of numerical analysis:\n\n1.  **Method of Manufactured Solutions**: To test the convergence of a numerical scheme for a differential equation, we choose a smooth, analytic function as a \"manufactured\" solution. We substitute this solution into the differential operators to compute the corresponding analytic source terms. This creates a problem where the exact solution is known. The continuum constraints, $H \\equiv \\nabla^{2}\\phi - S$ and $M_{i} \\equiv \\partial_{i}\\pi - J_{i}$, are therefore satisfied identically (equal to zero) by construction.\n\n2.  **Truncation Error as the Residual**: When the discrete finite-difference operators are applied to the analytic solution on a grid, the result will not be exactly equal to the analytic source terms. This difference, known as the discrete residual (e.g., $H_{h} = \\Delta^{(p)} \\phi - S$), is precisely the truncation error of the finite-difference scheme. For a method of order $p$, this error is expected to scale as $\\mathcal{O}(\\Delta x^p)$, where $\\Delta x$ is the grid spacing.\n\n3.  **Convergence Analysis**: By computing the discrete residual for a sequence of decreasing grid spacings $\\Delta x$, we can measure the observed order of convergence, $p_{\\mathrm{obs}}$. A robust method for determining $p_{\\mathrm{obs}}$ is to perform a linear regression on the logarithmic data. The relationship $\\lVert \\text{Error} \\rVert \\approx C(\\Delta x)^p$ becomes linear in a log-log plot: $\\log(\\lVert \\text{Error} \\rVert) \\approx p \\log(\\Delta x) + \\log(C)$. The slope of this line is the order of convergence $p$.\n\n4.  **Finite-Difference Operators on Periodic Grids**: The differential operators $\\partial_i$ and $\\nabla^2$ are approximated using centered finite-difference stencils. For a periodic domain, points required by the stencil that lie outside the grid are \"wrapped around\" from the other side. This is implemented efficiently using array-rolling operations. The specific coefficients of the stencils are chosen to cancel lower-order error terms in the Taylor series expansion, achieving a desired order of accuracy $p$.\n\nThe algorithmic procedure to solve the problem is as follows:\n\nFor each of the four test cases defined by the order $p$, damping parameter $\\kappa$, and list of resolutions $N$:\n\n1.  Initialize two lists to store the computed $L^2$ norms for the Hamiltonian residual, $\\lVert H_h \\rVert_2$, and the momentum residual, $\\lVert \\mathbf{M}_h \\rVert_2$, for each resolution. Also, prepare a list of the corresponding grid spacings, $\\Delta x = 1/N$.\n\n2.  For each resolution $N$ in the specified list:\n    a. Construct a uniform 3D Cartesian grid for the domain $[0,1]^3$. The grid coordinates are $(x_i, y_j, z_k)$ where $x_i = i/N, y_j=j/N, z_k=k/N$ for $i,j,k \\in \\{0, \\dots, N-1\\}$.\n    b. Evaluate the analytic fields $\\phi$ and $\\pi$, and the corresponding source fields $S$ and $J_i$, on every point of this grid, storing them in 3D arrays.\n    c. Implement the centered finite-difference operators for the first derivative ($D_i^{(p)}$) and the Laplacian ($\\Delta^{(p)} = D_{xx}^{(p)} + D_{yy}^{(p)} + D_{zz}^{(p)}$) for the specified order $p \\in \\{2,4\\}$. The periodicity of the grid is handled by using circular shifts (rolls) of the data arrays.\n    \n    The stencils are:\n    - $p=2$:\n      - First derivative $D_i^{(2)} f$: $\\frac{f_{i+1} - f_{i-1}}{2\\Delta x}$\n      - Second derivative $D_{ii}^{(2)} f$: $\\frac{f_{i+1} - 2f_i + f_{i-1}}{(\\Delta x)^2}$\n    - $p=4$:\n      - First derivative $D_i^{(4)} f$: $\\frac{1}{12\\Delta x}(f_{i-2} - 8f_{i-1} + 8f_{i+1} - f_{i+2})$\n      - Second derivative $D_{ii}^{(4)} f$: $\\frac{1}{12(\\Delta x)^2}(-f_{i-2} + 16f_{i-1} - 30f_i + 16f_{i+1} - f_{i+2})$\n    \n    d. Compute the discrete residuals. The Hamiltonian residual is $H_h = \\Delta^{(p)}\\phi - S$. The momentum residuals are $M_{i,h} = D_i^{(p)}\\pi - J_i$ for $i \\in \\{x,y,z\\}$.\n    e. Calculate the $L^2$ norms of the residuals as defined by the problem: $\\lVert H_{h}\\rVert_{2} = \\left( \\mathrm{mean}(H_{h}^{2}) \\right)^{1/2}$ and $\\lVert \\mathbf{M}_{h}\\rVert_{2} = \\left( \\mathrm{mean}(M_{x,h}^{2} + M_{y,h}^{2} + M_{z,h}^{2}) \\right)^{1/2}$.\n    f. If $\\kappa > 0$, apply the damping factor by multiplying the computed norms by $e^{-\\kappa T}$ with $T=1$. Note that this constant multiplicative factor does not alter the slope of the log-log error plot, hence it does not affect the observed convergence order.\n    g. Append the final norms and the grid spacing $\\Delta x$ to their respective lists.\n\n3.  After iterating through all resolutions, perform a linear regression on the logarithm of the norms versus the logarithm of the grid spacings. The slope of the resulting line for the Hamiltonian residual provides $p_{\\mathrm{obs}}(H)$, and similarly for the momentum residual, $p_{\\mathrm{obs}}(M)$.\n\n4.  Finally, verify the success of the test case. The condition for success is that both observed orders are close to the theoretical order $p$, i.e., $| p_{\\mathrm{obs}}(H) - p | \\le \\varepsilon$ and $| p_{\\mathrm{obs}}(M) - p | \\le \\varepsilon$, with the given tolerance $\\varepsilon = 0.2$. The result for the case is a boolean value (True for success, False for failure).\n\nThis entire process is repeated for all four test cases, and the final output is a list of the four boolean results.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Implements and verifies the scaling of discrete constraint residuals\n    for a manufactured solution test in numerical relativity.\n    \"\"\"\n\n    # --- Finite Difference Operators ---\n\n    def diff_x_p2(f, dx):\n        \"\"\"Order-2 centered 1st derivative along axis 0.\"\"\"\n        return (np.roll(f, -1, axis=0) - np.roll(f, 1, axis=0)) / (2.0 * dx)\n\n    def diff_y_p2(f, dx):\n        \"\"\"Order-2 centered 1st derivative along axis 1.\"\"\"\n        return (np.roll(f, -1, axis=1) - np.roll(f, 1, axis=1)) / (2.0 * dx)\n\n    def diff_z_p2(f, dx):\n        \"\"\"Order-2 centered 1st derivative along axis 2.\"\"\"\n        return (np.roll(f, -1, axis=2) - np.roll(f, 1, axis=2)) / (2.0 * dx)\n\n    def diff_xx_p2(f, dx):\n        \"\"\"Order-2 centered 2nd derivative along axis 0.\"\"\"\n        return (np.roll(f, -1, axis=0) - 2.0 * f + np.roll(f, 1, axis=0)) / (dx**2)\n\n    def diff_yy_p2(f, dx):\n        \"\"\"Order-2 centered 2nd derivative along axis 1.\"\"\"\n        return (np.roll(f, -1, axis=1) - 2.0 * f + np.roll(f, 1, axis=1)) / (dx**2)\n\n    def diff_zz_p2(f, dx):\n        \"\"\"Order-2 centered 2nd derivative along axis 2.\"\"\"\n        return (np.roll(f, -1, axis=2) - 2.0 * f + np.roll(f, 1, axis=2)) / (dx**2)\n\n    def diff_x_p4(f, dx):\n        \"\"\"Order-4 centered 1st derivative along axis 0.\"\"\"\n        c = [1.0/12.0, -8.0/12.0, 8.0/12.0, -1.0/12.0]\n        return (c[0] * np.roll(f, 2, axis=0) + c[1] * np.roll(f, 1, axis=0) + \n                c[2] * np.roll(f, -1, axis=0) + c[3] * np.roll(f, -2, axis=0)) / dx\n\n    def diff_y_p4(f, dx):\n        \"\"\"Order-4 centered 1st derivative along axis 1.\"\"\"\n        c = [1.0/12.0, -8.0/12.0, 8.0/12.0, -1.0/12.0]\n        return (c[0] * np.roll(f, 2, axis=1) + c[1] * np.roll(f, 1, axis=1) + \n                c[2] * np.roll(f, -1, axis=1) + c[3] * np.roll(f, -2, axis=1)) / dx\n\n    def diff_z_p4(f, dx):\n        \"\"\"Order-4 centered 1st derivative along axis 2.\"\"\"\n        c = [1.0/12.0, -8.0/12.0, 8.0/12.0, -1.0/12.0]\n        return (c[0] * np.roll(f, 2, axis=2) + c[1] * np.roll(f, 1, axis=2) + \n                c[2] * np.roll(f, -1, axis=2) + c[3] * np.roll(f, -2, axis=2)) / dx\n\n    def diff_xx_p4(f, dx):\n        \"\"\"Order-4 centered 2nd derivative along axis 0.\"\"\"\n        c = [-1.0/12.0, 16.0/12.0, -30.0/12.0, 16.0/12.0, -1.0/12.0]\n        return (c[0] * np.roll(f, 2, axis=0) + c[1] * np.roll(f, 1, axis=0) + c[2] * f +\n                c[3] * np.roll(f, -1, axis=0) + c[4] * np.roll(f, -2, axis=0)) / (dx**2)\n\n    def diff_yy_p4(f, dx):\n        \"\"\"Order-4 centered 2nd derivative along axis 1.\"\"\"\n        c = [-1.0/12.0, 16.0/12.0, -30.0/12.0, 16.0/12.0, -1.0/12.0]\n        return (c[0] * np.roll(f, 2, axis=1) + c[1] * np.roll(f, 1, axis=1) + c[2] * f +\n                c[3] * np.roll(f, -1, axis=1) + c[4] * np.roll(f, -2, axis=1)) / (dx**2)\n\n    def diff_zz_p4(f, dx):\n        \"\"\"Order-4 centered 2nd derivative along axis 2.\"\"\"\n        c = [-1.0/12.0, 16.0/12.0, -30.0/12.0, 16.0/12.0, -1.0/12.0]\n        return (c[0] * np.roll(f, 2, axis=2) + c[1] * np.roll(f, 1, axis=2) + c[2] * f +\n                c[3] * np.roll(f, -1, axis=2) + c[4] * np.roll(f, -2, axis=2)) / (dx**2)\n\n    # --- Analytic Functions ---\n    \n    def get_analytic_fields(N):\n        dx = 1.0 / N\n        coords = np.arange(N) * dx\n        x, y, z = np.meshgrid(coords, coords, coords, indexing='ij')\n\n        pi2 = 2.0 * np.pi\n        \n        # Field phi and its Laplacian source S\n        phi = np.sin(pi2 * x) * np.cos(pi2 * y) + np.sin(pi2 * z)\n        S = -2.0 * (pi2**2) * np.sin(pi2 * x) * np.cos(pi2 * y) - (pi2**2) * np.sin(pi2 * z)\n\n        # Field pi and its gradient source J\n        pi_field = np.exp(np.sin(pi2 * x) + np.cos(pi2 * y) + np.sin(pi2 * z))\n        Jx = pi2 * np.cos(pi2 * x) * pi_field\n        Jy = -pi2 * np.sin(pi2 * y) * pi_field\n        Jz = pi2 * np.cos(pi2 * z) * pi_field\n\n        return phi, pi_field, S, Jx, Jy, Jz\n\n    def run_convergence_test(p, kappa, N_list):\n        dx_list = []\n        h_norms = []\n        m_norms = []\n\n        for N in N_list:\n            dx = 1.0 / N\n            dx_list.append(dx)\n\n            phi, pi_field, S, Jx, Jy, Jz = get_analytic_fields(N)\n\n            if p == 2:\n                # Hamiltonian residual\n                lap_phi = diff_xx_p2(phi, dx) + diff_yy_p2(phi, dx) + diff_zz_p2(phi, dx)\n                Hh = lap_phi - S\n                \n                # Momentum residuals\n                Mxh = diff_x_p2(pi_field, dx) - Jx\n                Myh = diff_y_p2(pi_field, dx) - Jy\n                Mzh = diff_z_p2(pi_field, dx) - Jz\n            elif p == 4:\n                # Hamiltonian residual\n                lap_phi = diff_xx_p4(phi, dx) + diff_yy_p4(phi, dx) + diff_zz_p4(phi, dx)\n                Hh = lap_phi - S\n\n                # Momentum residuals\n                Mxh = diff_x_p4(pi_field, dx) - Jx\n                Myh = diff_y_p4(pi_field, dx) - Jy\n                Mzh = diff_z_p4(pi_field, dx) - Jz\n            else:\n                raise ValueError(\"Unsupported order p.\")\n\n            # Calculate L2 norms\n            h_norm = np.sqrt(np.mean(Hh**2))\n            m_norm = np.sqrt(np.mean(Mxh**2 + Myh**2 + Mzh**2))\n            \n            # Apply damping\n            damping_factor = np.exp(-kappa * 1.0)\n            h_norms.append(h_norm * damping_factor)\n            m_norms.append(m_norm * damping_factor)\n\n        # Fit convergence order\n        log_dx = np.log(dx_list)\n        log_h_norm = np.log(h_norms)\n        log_m_norm = np.log(m_norms)\n\n        p_obs_h = stats.linregress(log_dx, log_h_norm).slope\n        p_obs_m = stats.linregress(log_dx, log_m_norm).slope\n        \n        return p_obs_h, p_obs_m\n\n    test_cases = [\n        {'p': 2, 'kappa': 0, 'N_list': [16, 24, 32, 48]},\n        {'p': 4, 'kappa': 0, 'N_list': [16, 24, 32, 48]},\n        {'p': 2, 'kappa': 20, 'N_list': [16, 24, 32, 48]},\n        {'p': 4, 'kappa': 10, 'N_list': [16, 24, 32, 48]},\n    ]\n    tolerance = 0.2\n    \n    final_results = []\n    for case in test_cases:\n        p_expected = case['p']\n        p_obs_h, p_obs_m = run_convergence_test(p_expected, case['kappa'], case['N_list'])\n        \n        h_success = abs(p_obs_h - p_expected) = tolerance\n        m_success = abs(p_obs_m - p_expected) = tolerance\n        \n        final_results.append(h_success and m_success)\n\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n\n```", "id": "3469183"}, {"introduction": "Many physical systems, including Einstein’s equations with constraint damping, exhibit stiffness, where different physical processes evolve on vastly different timescales. This exercise explores how stiffness poses a challenge for standard explicit time-stepping methods and motivates the use of Implicit-Explicit (IMEX) schemes. By analyzing the stability of different integrators, you will understand the critical trade-offs that guide the choice of numerical methods in production-level relativity codes [@problem_id:3469166].", "problem": "Consider the method-of-lines discretization of a constraint propagation subsystem in numerical relativity, where the dominant stiff term is a linear damping of the form $-\\kappa C$, with $C$ a constraint variable and $\\kappa > 0$ a damping coefficient. After spatial discretization, focus on the linear scalar ordinary differential equation (ODE) $dC/dt = -\\kappa C$ for a single Fourier mode of $C$. In binary black hole evolutions using generalized harmonic formulations, realistic choices often make the product $\\kappa \\Delta t$ non-negligible, where $\\Delta t$ is the timestep chosen to satisfy a Courant–Friedrichs–Lewy (CFL) bound for wave propagation speeds near the speed of light.\n\nYou will compare a purely explicit fourth-order explicit Runge–Kutta method (ERK4) to an implicit–explicit (IMEX) splitting where the stiff damping part is treated implicitly via backward Euler while nonstiff terms would be treated explicitly. To ground the discussion in first principles, start from the definition of a Runge–Kutta method applied to the linear test equation $y' = \\lambda y$ with $\\lambda \\in \\mathbb{C}$, and define the associated linear stability function $R(z)$, where $z = \\lambda \\Delta t$. For the ERK4 method applied to $y'=-\\kappa y$ (so $z=-\\kappa \\Delta t$ lies on the negative real axis), the stability requirement is $|R(z)| \\leq 1$. For the implicit part (backward Euler) of the IMEX scheme applied solely to the stiff term, the associated stability function is defined analogously.\n\nUsing this framework:\n- Derive the ERK4 stability function $R(z)$ for the linear test equation from the Runge–Kutta stage equations and update formula, without invoking pre-memorized stability polynomials.\n- Specialize to $z=-x$ with $x=\\kappa \\Delta t > 0$ and determine the largest $x$ such that the explicit ERK4 method remains linearly stable on the negative real axis, that is, the unique positive solution $x_{\\mathrm{crit}}$ of the boundary condition $|R(-x_{\\mathrm{crit}})| = 1$ with $x_{\\mathrm{crit}} \\neq 0$.\n- Briefly explain, using the backward Euler stability function derived from first principles, why the IMEX treatment of the stiff term $-\\kappa C$ is unconditionally stable for all $x>0$ on the negative real axis.\n\nAssume code units with total mass $M$ set to $M=1$ so that realistic parameters such as $M/64 \\le \\Delta x \\le M/8$, CFL number $0.3 \\le \\nu \\le 0.5$ so $\\Delta t = \\nu \\Delta x$, and damping parameters $10 \\le \\kappa \\le 100$ are plausible in different regions of the domain. Use these to interpret qualitatively where typical $\\kappa \\Delta t$ values fall relative to the explicit ERK4 stability interval you derive.\n\nCompute $x_{\\mathrm{crit}}$ and express your final answer as a dimensionless number, rounded to four significant figures.", "solution": "This problem is valid. It is scientifically grounded in the principles of numerical analysis for differential equations, specifically within the context of numerical relativity. The problem is well-posed, objective, and contains all necessary information to proceed to a unique solution.\n\nThe primary task is to analyze the stability of numerical methods for the stiff ordinary differential equation (ODE) $dC/dt = -\\kappa C$, which models a constraint damping term in numerical relativity simulations. We will compare a fully explicit method (ERK4) with an implicit-explicit (IMEX) approach.\n\nFirst, we derive the stability function for the classical fourth-order explicit Runge-Kutta (ERK4) method. A general Runge-Kutta method is defined by its stages. For the classical ERK4, these are:\n$$\nk_1 = f(t_n, y_n) \\\\\nk_2 = f(t_n + \\frac{1}{2}\\Delta t, y_n + \\frac{1}{2}\\Delta t k_1) \\\\\nk_3 = f(t_n + \\frac{1}{2}\\Delta t, y_n + \\frac{1}{2}\\Delta t k_2) \\\\\nk_4 = f(t_n + \\Delta t, y_n + \\Delta t k_3)\n$$\nThe solution is then updated via:\n$$\ny_{n+1} = y_n + \\frac{\\Delta t}{6}(k_1 + 2k_2 + 2k_3 + k_4)\n$$\nTo find the stability function $R(z)$, we apply this scheme to the linear test equation $y' = \\lambda y$, for which $f(t,y) = \\lambda y$. Let $z = \\lambda \\Delta t$. The stages become:\n$$\nk_1 = \\lambda y_n \\\\\nk_2 = \\lambda \\left(y_n + \\frac{\\Delta t}{2}(\\lambda y_n)\\right) = \\lambda y_n \\left(1 + \\frac{\\lambda \\Delta t}{2}\\right) = \\lambda y_n \\left(1 + \\frac{z}{2}\\right) \\\\\nk_3 = \\lambda \\left(y_n + \\frac{\\Delta t}{2}k_2\\right) = \\lambda \\left(y_n + \\frac{\\Delta t}{2} \\left[\\lambda y_n \\left(1 + \\frac{z}{2}\\right)\\right]\\right) = \\lambda y_n \\left(1 + \\frac{z}{2}\\left(1 + \\frac{z}{2}\\right)\\right) = \\lambda y_n \\left(1 + \\frac{z}{2} + \\frac{z^2}{4}\\right) \\\\\nk_4 = \\lambda (y_n + \\Delta t k_3) = \\lambda \\left(y_n + \\Delta t \\left[\\lambda y_n \\left(1 + \\frac{z}{2} + \\frac{z^2}{4}\\right)\\right]\\right) = \\lambda y_n \\left(1 + z\\left(1 + \\frac{z}{2} + \\frac{z^2}{4}\\right)\\right) = \\lambda y_n \\left(1 + z + \\frac{z^2}{2} + \\frac{z^3}{4}\\right)\n$$\nSubstituting these into the update formula $y_{n+1} = R(z) y_n$:\n$$\ny_{n+1} = y_n + \\frac{\\Delta t}{6} \\left[\\lambda y_n + 2\\lambda y_n \\left(1 + \\frac{z}{2}\\right) + 2\\lambda y_n \\left(1 + \\frac{z}{2} + \\frac{z^2}{4}\\right) + \\lambda y_n \\left(1 + z + \\frac{z^2}{2} + \\frac{z^3}{4}\\right)\\right]\n$$\nDividing by $y_n$ and recalling $z = \\lambda \\Delta t$:\n$$\nR(z) = 1 + \\frac{z}{6} \\left[1 + 2\\left(1 + \\frac{z}{2}\\right) + 2\\left(1 + \\frac{z}{2} + \\frac{z^2}{4}\\right) + \\left(1 + z + \\frac{z^2}{2} + \\frac{z^3}{4}\\right)\\right]\n$$\n$$\nR(z) = 1 + \\frac{z}{6} \\left[1 + 2 + z + 2 + z + \\frac{z^2}{2} + 1 + z + \\frac{z^2}{2} + \\frac{z^3}{4}\\right]\n$$\nCombining terms inside the bracket:\n$$\nR(z) = 1 + \\frac{z}{6} \\left[(1+2+2+1) + (z+z+z) + \\left(\\frac{z^2}{2}+\\frac{z^2}{2}\\right) + \\frac{z^3}{4}\\right]\n$$\n$$\nR(z) = 1 + \\frac{z}{6} \\left[6 + 3z + z^2 + \\frac{z^3}{4}\\right]\n$$\nDistributing the $z/6$ term gives the stability function for ERK4:\n$$\nR(z) = 1 + z + \\frac{z^2}{2} + \\frac{z^3}{6} + \\frac{z^4}{24}\n$$\nThis is, as expected, the fourth-order Taylor series expansion of $\\exp(z)$.\n\nNext, we determine the stability limit for this method on the negative real axis. Our ODE is $dC/dt = -\\kappa C$, so $\\lambda = -\\kappa$. We define $x = \\kappa \\Delta t > 0$, which means $z = \\lambda \\Delta t = -x$. The stability condition is $|R(-x)| \\le 1$.\nThe stability function is:\n$$\nR(-x) = 1 - x + \\frac{x^2}{2} - \\frac{x^3}{6} + \\frac{x^4}{24}\n$$\nThe stability interval on the negative real axis is $[-x_{\\mathrm{crit}}, 0]$, where $x_{\\mathrm{crit}}$ is the largest positive value of $x$ for which $|R(-x)| \\le 1$ for all $x \\in [0, x_{\\mathrm{crit}}]$. The boundary of the stability region is where $|R(-x)| = 1$. This yields two conditions: $R(-x) = 1$ or $R(-x) = -1$.\nCase 1: $R(-x) = 1$\n$$\n1 - x + \\frac{x^2}{2} - \\frac{x^3}{6} + \\frac{x^4}{24} = 1\n$$\n$$\n-x + \\frac{x^2}{2} - \\frac{x^3}{6} + \\frac{x^4}{24} = 0\n$$\nFactoring out $x$ (since we seek $x_{\\mathrm{crit}} \\neq 0$):\n$$\nx\\left(-1 + \\frac{x}{2} - \\frac{x^2}{6} + \\frac{x^3}{24}\\right) = 0\n$$\nWe must find the positive root of the polynomial in the parenthesis. Multiplying by $24$:\n$$\nx^3 - 4x^2 + 12x - 24 = 0\n$$\nCase 2: $R(-x) = -1$\n$$\n1 - x + \\frac{x^2}{2} - \\frac{x^3}{6} + \\frac{x^4}{24} = -1\n$$\n$$\n\\frac{x^4}{24} - \\frac{x^3}{6} + \\frac{x^2}{2} - x + 2 = 0\n$$\nThe function $R(-x)$ starts at $R(0)=1$ and initially decreases. A plot reveals that its minimum value is positive, so it never reaches $-1$. Therefore, the equation from Case 2 has no real roots, and the stability boundary is defined entirely by the non-zero root from Case 1.\nWe need to solve $x^3 - 4x^2 + 12x - 24 = 0$ for $x > 0$. Numerical methods (e.g., Newton-Raphson) yield a single real root.\n$$\nx_{\\mathrm{crit}} \\approx 2.78528178...\n$$\nRounding to four significant figures, $x_{\\mathrm{crit}} = 2.785$. The stability interval for ERK4 on the negative real axis is approximately $[-2.785, 0]$. This means that for stability, we must have $\\kappa \\Delta t \\le 2.785$.\n\nThird, we analyze the stability of the backward Euler method, proposed for the stiff term in an IMEX scheme. The backward Euler method for $y' = f(t,y)$ is $y_{n+1} = y_n + \\Delta t f(t_{n+1}, y_{n+1})$. Applying this to the test equation $y' = \\lambda y$:\n$$\ny_{n+1} = y_n + \\Delta t (\\lambda y_{n+1}) = y_n + z y_{n+1}\n$$\nSolving for $y_{n+1}$:\n$$\ny_{n+1}(1-z) = y_n \\implies y_{n+1} = \\frac{1}{1-z}y_n\n$$\nThe stability function for backward Euler is $R_{\\mathrm{BE}}(z) = \\frac{1}{1-z}$. For the damping term, $z = -x = -\\kappa \\Delta t$.\n$$\nR_{\\mathrm{BE}}(-x) = \\frac{1}{1 - (-x)} = \\frac{1}{1+x}\n$$\nThe stability requirement is $|R_{\\mathrm{BE}}(-x)| \\le 1$. Since $x = \\kappa \\Delta t > 0$, we have $1+x > 1$. Therefore:\n$$\n0  \\frac{1}{1+x}  1\n$$\nThis inequality holds for all $x > 0$. Thus, the backward Euler method is unconditionally stable for this type of damping term. This property, known as A-stability, makes it ideal for treating stiff terms within an IMEX framework, as it imposes no stability restriction on the timestep $\\Delta t$.\n\nFinally, we interpret these results using the provided realistic parameters in code units where $M=1$: $M/64 \\le \\Delta x \\le M/8$, $0.3 \\le \\nu \\le 0.5$, and $10 \\le \\kappa \\le 100$. The parameter of interest is $x = \\kappa \\Delta t = \\kappa \\nu \\Delta x$.\nLet's find the approximate range of $x$.\nThe minimum value occurs for the smallest $\\kappa, \\nu, \\Delta x$:\n$$\nx_{\\mathrm{min}} = 10 \\times 0.3 \\times \\frac{1}{64} = \\frac{3}{64} \\approx 0.047\n$$\nThe maximum value occurs for the largest $\\kappa, \\nu, \\Delta x$:\n$$\nx_{\\mathrm{max}} = 100 \\times 0.5 \\times \\frac{1}{8} = \\frac{50}{8} = 6.25\n$$\nThe range of plausible values for $x = \\kappa \\Delta t$ is approximately $[0.047, 6.25]$.\nComparing this range to the ERK4 stability limit $x_{\\mathrm{crit}} \\approx 2.785$:\n- At the low end of the parameter range (e.g., weak damping, fine resolution), $x$ is well within the stability region of ERK4 ($0.047  2.785$).\n- At the high end of the parameter range (e.g., strong damping, coarse resolution), $x$ can significantly exceed the stability limit of ERK4 ($6.25 > 2.785$).\nThis analysis demonstrates that for many realistic simulation setups in numerical relativity, a purely explicit method like ERK4 would be forced to take a timestep much smaller than what is required by the CFL condition for wave propagation, purely to satisfy the stability of the constraint damping term. This makes the explicit approach inefficient. The IMEX method, by treating the stiff damping term implicitly, circumvents this severe timestep restriction and allows the timestep to be chosen based on the physics of the non-stiff terms (like gravitational wave propagation), leading to much more efficient computations.\n\nThe calculated critical value for $x$ is $x_{\\mathrm{crit}} \\approx 2.785$.", "answer": "$$\n\\boxed{2.785}\n$$", "id": "3469166"}, {"introduction": "To gain deeper physical insight from numerical simulations, we need sophisticated diagnostic tools. This practice introduces spectral analysis, projecting constraint violation fields onto spherical harmonic modes to understand how they behave at different angular scales. By implementing this projection and comparing different mode-dependent damping strategies, you will learn how to design and analyze more targeted and physically motivated constraint control systems [@problem_id:3469145].", "problem": "Consider a linearized constraint field $C(\\theta,\\phi,t)$ defined on the unit sphere $\\mathbb{S}^2$ with colatitude $\\theta \\in [0,\\pi]$ and azimuth $\\phi \\in [0,2\\pi)$, where all angular measures are in radians and all quantities are dimensionless. Let $\\Delta_{\\mathbb{S}^2}$ denote the Laplace–Beltrami operator on $\\mathbb{S}^2$, and let $\\{Y_{\\ell m}(\\theta,\\phi)\\}$ denote the orthonormal complex spherical harmonics with the convention that\n$$\n\\int_{\\mathbb{S}^2} Y_{\\ell m}(\\theta,\\phi)\\,Y_{\\ell' m'}(\\theta,\\phi)^{*}\\,d\\Omega \\;=\\; \\delta_{\\ell\\ell'}\\,\\delta_{mm'},\n$$\nwhere $d\\Omega = \\sin\\theta\\,d\\theta\\,d\\phi$ and $(\\cdot)^{*}$ denotes complex conjugation. Assume a constraint propagation model driven by linear diffusion and explicit damping of the form\n$$\n\\partial_t C \\;=\\; \\nu\\,\\Delta_{\\mathbb{S}^2} C \\;-\\; \\kappa_{\\ell}\\,C,\n$$\nwhere $\\nu \\ge 0$ is a constant diffusivity and $\\kappa_{\\ell} \\ge 0$ is an angular-mode-dependent damping rate that depends only on $\\ell$. Use the well-tested facts that (i) the spherical harmonics are eigenfunctions of the Laplace–Beltrami operator with $\\Delta_{\\mathbb{S}^2} Y_{\\ell m} = -\\ell(\\ell+1) Y_{\\ell m}$, and (ii) orthonormality of $\\{Y_{\\ell m}\\}$ on $\\mathbb{S}^2$ as stated above.\n\nYour tasks are:\n- Derive, from the stated model and the orthonormality of the spherical harmonics, the evolution equation for the spectral coefficients $a_{\\ell m}(t)$ defined by the projection\n$$\na_{\\ell m}(t) \\;=\\; \\int_{\\mathbb{S}^2} C(\\theta,\\phi,t)\\,Y_{\\ell m}(\\theta,\\phi)^{*}\\,d\\Omega.\n$$\n- Based on your derivation, implement a diagnostic that:\n  1. Numerically projects a given initial field $C(\\theta,\\phi,0)$ onto the spherical harmonic modes up to a specified $L_{\\max}$, obtaining $a_{\\ell m}(0)$ for $0 \\le \\ell \\le L_{\\max}$ and $-\\ell \\le m \\le \\ell$.\n  2. Evolves the modal amplitudes to time $t=T$ under two damping strategies:\n     - Strategy A (uniform): $\\kappa_{\\ell} = \\kappa_0$ for all $\\ell$.\n     - Strategy B (mode-dependent): $\\kappa_{\\ell} = \\alpha\\,\\ell(\\ell+1)$ with $\\alpha$ chosen so that the multiplicity-weighted mean of $\\kappa_{\\ell}$ over all modes with $0 \\le \\ell \\le L_{\\max}$ and $-\\ell \\le m \\le \\ell$ equals $\\kappa_0$.\n  3. Computes the total squared norm at time $t$, defined spectrally by\n$$\n\\|C(\\cdot,\\cdot,t)\\|_2^2 \\;=\\; \\sum_{\\ell=0}^{L_{\\max}} \\sum_{m=-\\ell}^{\\ell} \\big|a_{\\ell m}(t)\\big|^2,\n$$\nfor each strategy, and returns the ratio $\\mathcal{R} = \\|C\\|_{2,\\mathrm{B}}(T) \\big/ \\|C\\|_{2,\\mathrm{A}}(T)$ along with a boolean indicating whether Strategy B improves overall decay, i.e., whether $\\mathcal{R}  1$.\n- The projection integral must be approximated numerically as follows:\n  - Use $N_{\\theta}$ Gauss–Legendre nodes in $x=\\cos\\theta$, with corresponding weights, and map to $\\theta=\\arccos x$ for the polar direction.\n  - Use $N_{\\phi}$ equispaced nodes in $\\phi$ with the rectangular rule.\n- Angles must be in radians. All computations are dimensionless.\n\nTest suite and initial data:\n- Use $N_{\\theta} = 64$ and $N_{\\phi} = 128$.\n- For each test, define the initial field as\n$$\nC(\\theta,\\phi,0) \\;=\\; \\Re\\left(\\sum_{(\\ell,m)\\in \\mathcal{S}} A_{\\ell m}\\,Y_{\\ell m}(\\theta,\\phi)\\right),\n$$\nwhere $\\Re(\\cdot)$ denotes the real part and $\\mathcal{S}$ with coefficients $A_{\\ell m}$ are listed below. In all tests, project and evolve using only modes with $0 \\le \\ell \\le L_{\\max}$.\n\nProvide results for the following parameter sets (each is one test case):\n- Test $1$ (happy path, mixed low and intermediate modes): $L_{\\max} = 6$, $\\nu = 0.05$, $\\kappa_0 = 0.1$, $T = 10.0$, with $\\mathcal{S}=\\{(0,0),(2,0),(4,2),(5,3)\\}$ and amplitudes $A_{0,0}=1.0$, $A_{2,0}=0.45$, $A_{4,2}=0.3$, $A_{5,3}=0.25$.\n- Test $2$ (edge case, zero diffusion, strong $\\ell=0$ content): $L_{\\max} = 6$, $\\nu = 0.0$, $\\kappa_0 = 0.08$, $T = 5.0$, with $\\mathcal{S}=\\{(0,0),(1,0),(5,0)\\}$ and amplitudes $A_{0,0}=2.0$, $A_{1,0}=0.2$, $A_{5,0}=0.1$.\n- Test $3$ (high diffusion, high-$\\ell$ content): $L_{\\max} = 8$, $\\nu = 0.5$, $\\kappa_0 = 0.05$, $T = 3.0$, with $\\mathcal{S}=\\{(7,6),(8,-7),(2,1),(3,0)\\}$ and amplitudes $A_{7,6}=0.4$, $A_{8,-7}=0.3$, $A_{2,1}=0.2$, $A_{3,0}=0.1$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a two-element list $[\\mathcal{R},\\mathrm{improved}]$ with $\\mathcal{R}$ rounded to six decimal places and $\\mathrm{improved}$ a boolean. For example, the output must look like\n$[[r_1,b_1],[r_2,b_2],[r_3,b_3]]$\nwith no extra text and where $r_i$ are decimal numbers and $b_i$ are booleans.", "solution": "The problem statement is valid. It presents a scientifically sound and well-posed numerical problem rooted in the spectral analysis of partial differential equations on a sphere, a common technique in physics and applied mathematics. All necessary equations, parameters, and procedures are clearly defined.\n\n**Derivation of the Modal Evolution Equation**\n\nWe start with the given partial differential equation (PDE) for the constraint field $C(\\theta,\\phi,t)$:\n$$\n\\partial_t C = \\nu\\,\\Delta_{\\mathbb{S}^2} C - \\kappa_{\\ell}\\,C\n$$\nTo find the evolution of the spectral coefficients $a_{\\ell m}(t)$, we project this equation onto the spherical harmonic basis. We multiply by the complex conjugate of a spherical harmonic, $Y_{\\ell m}^*(\\theta,\\phi)$, and integrate over the unit sphere $\\mathbb{S}^2$:\n$$\n\\int_{\\mathbb{S}^2} (\\partial_t C) Y_{\\ell m}^* \\,d\\Omega = \\int_{\\mathbb{S}^2} (\\nu\\,\\Delta_{\\mathbb{S}^2} C - \\kappa_{\\ell}\\,C) Y_{\\ell m}^* \\,d\\Omega\n$$\nUsing the linearity of the integral and the definition $a_{\\ell m}(t) = \\int C Y_{\\ell m}^* \\,d\\Omega$, the left-hand side becomes:\n$$\n\\int_{\\mathbb{S}^2} (\\partial_t C) Y_{\\ell m}^* \\,d\\Omega = \\partial_t \\int_{\\mathbb{S}^2} C Y_{\\ell m}^* \\,d\\Omega = \\frac{d}{dt} a_{\\ell m}(t)\n$$\nThe right-hand side can be split into two terms. For the first term, we expand $C$ in the spherical harmonic basis: $C = \\sum_{\\ell',m'} a_{\\ell'm'}(t)Y_{\\ell'm'}(\\theta,\\phi)$. Using the eigenfunction property $\\Delta_{\\mathbb{S}^2} Y_{\\ell'm'} = -\\ell'(\\ell'+1)Y_{\\ell'm'}$, we get:\n$$\n\\nu \\int_{\\mathbb{S}^2} (\\Delta_{\\mathbb{S}^2} C) Y_{\\ell m}^* \\,d\\Omega = \\nu \\int_{\\mathbb{S}^2} \\left(\\sum_{\\ell',m'} a_{\\ell'm'}(t) [-\\ell'(\\ell'+1)Y_{\\ell'm'}]\\right) Y_{\\ell m}^* \\,d\\Omega\n$$\nUsing the orthonormality relation $\\int Y_{\\ell'm'} Y_{\\ell m}^* \\,d\\Omega = \\delta_{\\ell\\ell'}\\delta_{mm'}$, the sum collapses to a single term:\n$$\n\\nu [-\\ell(\\ell+1) a_{\\ell m}(t)] = -\\nu\\ell(\\ell+1) a_{\\ell m}(t)\n$$\nFor the second term on the right-hand side, since $\\kappa_\\ell$ depends only on $\\ell$, it is a constant with respect to the integration:\n$$\n- \\int_{\\mathbb{S}^2} \\kappa_{\\ell} C Y_{\\ell m}^* \\,d\\Omega = -\\kappa_\\ell \\int_{\\mathbb{S}^2} C Y_{\\ell m}^* \\,d\\Omega = -\\kappa_\\ell a_{\\ell m}(t)\n$$\nCombining these results, we obtain a first-order ordinary differential equation (ODE) for each spectral coefficient $a_{\\ell m}(t)$:\n$$\n\\frac{d}{dt} a_{\\ell m}(t) = -[\\nu\\ell(\\ell+1) + \\kappa_\\ell] a_{\\ell m}(t)\n$$\nThis ODE has the straightforward solution:\n$$\na_{\\ell m}(t) = a_{\\ell m}(0) \\exp\\left(-[\\nu\\ell(\\ell+1) + \\kappa_\\ell]t\\right)\n$$\nThis equation governs the time evolution of each mode's amplitude.\n\n**Implementation Strategy**\n\nThe diagnostic tool is implemented by following these steps for each test case:\n\n1.  **Numerical Projection**: The initial coefficients $a_{\\ell m}(0)$ are computed by numerically integrating $a_{\\ell m}(0) = \\int_0^{2\\pi} \\int_0^\\pi C(\\theta,\\phi,0) Y_{\\ell m}^*(\\theta,\\phi) \\sin\\theta d\\theta d\\phi$. The integral is discretized using the specified quadrature rules:\n    *   The polar integral over $\\theta$ is performed using $N_\\theta$-point Gauss-Legendre quadrature over $x = \\cos\\theta \\in [-1, 1]$.\n    *   The azimuthal integral over $\\phi$ is performed using the rectangular rule with $N_\\phi$ equispaced points.\n    The discretized integral for each coefficient is a weighted sum over the grid points.\n\n2.  **Damping Strategies**:\n    *   **Strategy A (Uniform Damping)**: The damping rate is constant for all modes, $\\kappa_\\ell = \\kappa_0$. The decay of each mode is governed by the rate $\\lambda_\\ell^A = \\nu\\ell(\\ell+1) + \\kappa_0$.\n    *   **Strategy B (Mode-Dependent Damping)**: The damping rate is $\\kappa_\\ell = \\alpha\\ell(\\ell+1)$. The parameter $\\alpha$ is fixed by requiring that the multiplicity-weighted mean of $\\kappa_\\ell$ over all modes up to $L_{\\max}$ equals $\\kappa_0$. This leads to the formula $\\alpha = \\frac{\\kappa_0 (L_{\\max}+1)^2}{\\sum_{\\ell=0}^{L_{\\max}} (2\\ell+1) \\ell(\\ell+1)}$. The decay of each mode is then governed by the rate $\\lambda_\\ell^B = (\\nu+\\alpha)\\ell(\\ell+1)$.\n\n3.  **Time Evolution and Norm Calculation**: For each strategy, the amplitude of every mode $(\\ell, m)$ at time $T$ is computed using the ODE solution: $a_{\\ell m}(T) = a_{\\ell m}(0) e^{-\\lambda_\\ell T}$. The total squared norm is then found by summing the squared magnitudes of these evolved coefficients, as per Parseval's theorem: $\\|C(T)\\|_2^2 = \\sum_{\\ell=0}^{L_{\\max}}\\sum_{m=-\\ell}^{\\ell} |a_{\\ell m}(T)|^2$.\n\n4.  **Ratio and Comparison**: The final norms for Strategy A and Strategy B, $\\|C\\|_{2,\\mathrm{A}}(T)$ and $\\|C\\|_{2,\\mathrm{B}}(T)$, are computed by taking the square root of the squared norms. The ratio $\\mathcal{R} = \\|C\\|_{2,\\mathrm{B}}(T) / \\|C\\|_{2,\\mathrm{A}}(T)$ is calculated, and the boolean `improved` is set to `True` if and only if $\\mathcal{R}  1$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import sph_harm\nfrom numpy.polynomial.legendre import leggauss\n\ndef process_case(case_data):\n    \"\"\"\n    Processes a single test case according to the problem description.\n    \"\"\"\n    L_max, nu, kappa_0, T, S_dict = case_data\n    N_theta = 64\n    N_phi = 128\n\n    # 1. Setup numerical integration grid\n    # For the polar direction, use Gauss-Legendre quadrature in x = cos(theta)\n    x_nodes, w_theta = leggauss(N_theta)\n    theta_nodes = np.arccos(x_nodes)\n\n    # For the azimuthal direction, use equispaced nodes (rectangular rule)\n    phi_nodes = np.linspace(0, 2 * np.pi, N_phi, endpoint=False)\n    d_phi = 2 * np.pi / N_phi\n\n    # Create 2D grids for vectorized evaluation of spherical harmonics\n    phi_grid, theta_grid = np.meshgrid(phi_nodes, theta_nodes)\n\n    # 2. Evaluate the initial field C(theta, phi, 0) on the grid\n    Y_lm_sum = np.zeros_like(phi_grid, dtype=np.complex128)\n    for (l, m), A_lm in S_dict.items():\n        # scipy.special.sph_harm expects (m, l, azimuth, polar)\n        Y_lm_grid = sph_harm(m, l, phi_grid, theta_grid)\n        Y_lm_sum += A_lm * Y_lm_grid\n    \n    C_grid = np.real(Y_lm_sum)\n\n    # 3. Numerically project C to get the initial spectral coefficients a_lm(0)\n    a_lm_0 = {}\n    for l in range(L_max + 1):\n        for m in range(-l, l + 1):\n            y_lm_conj_grid = np.conj(sph_harm(m, l, phi_grid, theta_grid))\n            \n            integrand = C_grid * y_lm_conj_grid\n            \n            # Perform the integral over phi using the rectangular rule\n            phi_integral_res = np.sum(integrand, axis=1) * d_phi\n            \n            # Perform the integral over theta using Gauss-Legendre quadrature\n            # Note: The integral is over x=cos(theta) from -1 to 1, which the weights w_theta handle.\n            theta_integral_res = np.sum(phi_integral_res * w_theta)\n            \n            a_lm_0[(l, m)] = theta_integral_res\n\n    # 4. Determine the parameter alpha for Strategy B\n    # alpha is chosen so the multiplicity-weighted mean of kappa_l equals kappa_0\n    # Denominator sum: S = sum_{l=1}^{L_max} (2l+1)l(l+1)\n    denom_sum = sum((2 * l + 1) * l * (l + 1) for l in range(1, L_max + 1))\n    \n    if denom_sum == 0:\n        alpha = 0.0 # Avoid division by zero if L_max = 0\n    else:\n        alpha = (kappa_0 * (L_max + 1)**2) / denom_sum\n\n    # 5. Evolve coefficients to time T and compute norms\n    norm_sq_A = 0.0\n    norm_sq_B = 0.0\n    \n    for l in range(L_max + 1):\n        for m in range(-l, l + 1):\n            alm0 = a_lm_0[(l, m)]\n            \n            # Strategy A: kappa_l = kappa_0\n            decay_rate_A = nu * l * (l + 1) + kappa_0\n            alm_A_T = alm0 * np.exp(-decay_rate_A * T)\n            norm_sq_A += np.abs(alm_A_T)**2\n            \n            # Strategy B: kappa_l = alpha * l * (l + 1)\n            decay_rate_B = (nu + alpha) * l * (l + 1)\n            alm_B_T = alm0 * np.exp(-decay_rate_B * T)\n            norm_sq_B += np.abs(alm_B_T)**2\n            \n    norm_A = np.sqrt(norm_sq_A)\n    norm_B = np.sqrt(norm_sq_B)\n    \n    # 6. Compute the ratio R and the improvement flag\n    if norm_A == 0.0:\n        # If norm_A is zero, but norm_B is not, the ratio is infinite.\n        # If both are zero, the ratio is 1. Underflow is possible.\n        R = np.inf if norm_B > 1e-15 else 1.0\n    else:\n        R = norm_B / norm_A\n\n    improved = R  1.0\n    \n    return [round(R, 6), improved]\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (6, 0.05, 0.1, 10.0, {(0,0): 1.0, (2,0): 0.45, (4,2): 0.3, (5,3): 0.25}),\n        (6, 0.0, 0.08, 5.0, {(0,0): 2.0, (1,0): 0.2, (5,0): 0.1}),\n        (8, 0.5, 0.05, 3.0, {(7,6): 0.4, (8,-7): 0.3, (2,1): 0.2, (3,0): 0.1}),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = process_case(case)\n        results.append(result)\n\n    # Format the final output string exactly as required.\n    # Convert each inner list to its string representation and join them.\n    result_str = \",\".join(map(str, results)).replace(\" \", \"\") # Remove spaces for compactness\n    print(f\"[{result_str}]\")\n\nsolve()\n```", "id": "3469145"}]}