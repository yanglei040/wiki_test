{"hands_on_practices": [{"introduction": "We begin with an analytical exercise to understand how weak hyperbolicity can emerge within a system's structure. This problem [@problem_id:3497813] presents a toy model where a coupling parameter $\\epsilon$ mixes a physical mode with a gauge mode. By determining the critical value of this parameter where the system's characteristic speeds coalesce, you will see firsthand how a system can transition from being strongly hyperbolic to only weakly hyperbolic, a crucial concept for designing stable evolution formalisms.", "problem": "Consider a one-dimensional, first-order linear toy evolution system for a pair of fields $u = (h, g)^{\\top}$ representing a physical perturbation $h$ (e.g., a linearized gravitational-wave degree of freedom) and a gauge perturbation $g$ (e.g., a linearized lapse/shift degree of freedom). The system is\n$$\n\\partial_{t} u + A(\\epsilon,\\nu)\\,\\partial_{x} u = 0,\n$$\nwith principal matrix\n$$\nA(\\epsilon,\\nu) =\n\\begin{pmatrix}\n1 & \\epsilon \\\\\n-\\epsilon & \\nu\n\\end{pmatrix},\n$$\nwhere $1$ is the physical characteristic speed (in units where the speed of light is $1$), $\\nu \\in \\mathbb{R}$ is a prescribed gauge characteristic speed, and $\\epsilon \\in \\mathbb{R}$ is a coupling parameter that mixes physical and gauge sectors in the principal part. You may assume constant coefficients and analyze the symbol in the $x$ direction.\n\nUsing only the foundational definition that strong hyperbolicity of a first-order system requires a complete set of eigenvectors of the principal symbol with real characteristic speeds, while weak hyperbolicity requires real characteristic speeds but may lack a complete eigenvector set, determine the critical magnitude of the coupling parameter at which the system transitions from strongly hyperbolic to only weakly hyperbolic (i.e., the point at which eigenvectors cease to be complete while the characteristic speeds remain real). Express your final answer as a closed-form analytic expression for the critical value $\\epsilon_{*}$ in terms of $\\nu$. The final answer must be a single expression with no units.", "solution": "The problem requires the determination of the critical magnitude of the coupling parameter, denoted as $\\epsilon_{*}$, at which a given first-order linear evolution system transitions from being strongly hyperbolic to only weakly hyperbolic.\n\nThe system is given by:\n$$\n\\partial_{t} u + A(\\epsilon,\\nu)\\,\\partial_{x} u = 0\n$$\nwhere $u$ is a two-component vector field and the matrix of coefficients, which is the principal symbol of the system in the $x$-direction, is:\n$$\nA(\\epsilon,\\nu) =\n\\begin{pmatrix}\n1 & \\epsilon \\\\\n-\\epsilon & \\nu\n\\end{pmatrix}\n$$\nHere, $\\nu \\in \\mathbb{R}$ and $\\epsilon \\in \\mathbb{R}$ are parameters.\n\nAccording to the provided definitions, the hyperbolicity of the system is determined by the properties of the eigenvalues and eigenvectors of the principal matrix $A$. The eigenvalues, $\\lambda$, correspond to the characteristic speeds.\n- **Strong hyperbolicity** requires that the eigenvalues are all real and that there exists a complete set of eigenvectors. For a matrix of size $N \\times N$, this means there are $N$ linearly independent eigenvectors.\n- **Weak hyperbolicity** requires that the eigenvalues are all real, but the set of eigenvectors may be incomplete.\n\nThe transition from strong to weak hyperbolicity occurs at the boundary where the matrix $A$ ceases to be diagonalizable over the real numbers. For a general $N \\times N$ matrix, this occurs when an eigenvalue's geometric multiplicity (the dimension of its eigenspace) becomes less than its algebraic multiplicity (its multiplicity as a root of the characteristic polynomial). For a $2 \\times 2$ matrix that is not a scalar multiple of the identity, this happens precisely when the two eigenvalues become equal.\n\nWe begin by finding the eigenvalues of $A$ by solving the characteristic equation $\\det(A - \\lambda I) = 0$, where $I$ is the $2 \\times 2$ identity matrix.\n$$\n\\det\n\\begin{pmatrix}\n1 - \\lambda & \\epsilon \\\\\n-\\epsilon & \\nu - \\lambda\n\\end{pmatrix}\n= 0\n$$\nExpanding the determinant gives the characteristic polynomial for $\\lambda$:\n$$\n(1 - \\lambda)(\\nu - \\lambda) - (\\epsilon)(-\\epsilon) = 0\n$$\n$$\n\\nu - \\lambda - \\nu\\lambda + \\lambda^2 + \\epsilon^2 = 0\n$$\n$$\n\\lambda^2 - (1 + \\nu)\\lambda + (\\nu + \\epsilon^2) = 0\n$$\nWe solve this quadratic equation for the eigenvalues $\\lambda$ using the quadratic formula:\n$$\n\\lambda = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\n$$\nwith $a=1$, $b=-(1+\\nu)$, and $c=\\nu+\\epsilon^2$.\n$$\n\\lambda = \\frac{(1+\\nu) \\pm \\sqrt{(-(1+\\nu))^2 - 4(1)(\\nu + \\epsilon^2)}}{2}\n$$\n$$\n\\lambda = \\frac{(1+\\nu) \\pm \\sqrt{(1+\\nu)^2 - 4\\nu - 4\\epsilon^2}}{2}\n$$\n$$\n\\lambda = \\frac{(1+\\nu) \\pm \\sqrt{1 + 2\\nu + \\nu^2 - 4\\nu - 4\\epsilon^2}}{2}\n$$\n$$\n\\lambda = \\frac{(1+\\nu) \\pm \\sqrt{\\nu^2 - 2\\nu + 1 - 4\\epsilon^2}}{2}\n$$\nThe expression under the square root can be simplified by recognizing the perfect square:\n$$\n\\lambda = \\frac{(1+\\nu) \\pm \\sqrt{(\\nu-1)^2 - 4\\epsilon^2}}{2}\n$$\nFor the system to be hyperbolic (either weakly or strongly), the characteristic speeds $\\lambda$ must be real. This requires the discriminant of the quadratic formula, $\\Delta = (\\nu-1)^2 - 4\\epsilon^2$, to be non-negative.\n$$\n\\Delta \\ge 0 \\implies (\\nu-1)^2 \\ge 4\\epsilon^2\n$$\nThe system is strongly hyperbolic if the eigenvalues are real and distinct, which requires the discriminant to be strictly positive:\n$$\n\\Delta > 0 \\implies (\\nu-1)^2 > 4\\epsilon^2\n$$\nThis condition ensures the existence of two distinct eigenvalues, which for a $2 \\times 2$ matrix guarantees a complete set of two linearly independent eigenvectors.\n\nThe system transitions to being only weakly hyperbolic at the point where the eigenvalues become real and repeated, but the matrix is not diagonalizable. This occurs when the discriminant is exactly zero:\n$$\n\\Delta = (\\nu-1)^2 - 4\\epsilon^2 = 0\n$$\nAt this point, the two eigenvalues coalesce into a single value $\\lambda = \\frac{1+\\nu}{2}$. For the matrix $A$ to be non-diagonalizable, it must not be a scalar multiple of the identity matrix for this repeated eigenvalue. The matrix $A$ would be a scalar matrix only if $\\epsilon=0$ and $1=\\nu$. In this specific case, $A = I$, which is trivially diagonalizable and thus strongly hyperbolic. For any non-zero coupling $\\epsilon$, if $(\\nu-1)^2 = 4\\epsilon^2$, the matrix $A$ will not be a scalar matrix. The geometric multiplicity of the repeated eigenvalue will be $1$, which is less than the algebraic multiplicity of $2$, indicating an incomplete set of eigenvectors. This is the definition of the onset of weak hyperbolicity.\n\nTherefore, the critical condition marking the transition is given by the equation where the discriminant vanishes:\n$$\n(\\nu-1)^2 = 4\\epsilon^2\n$$\nThe problem asks for the critical magnitude of the coupling parameter, which we denote as $\\epsilon_{*}$. This implies we are solving for $|\\epsilon|$. Taking the square root of both sides of the equation yields:\n$$\n\\sqrt{(\\nu-1)^2} = \\sqrt{4\\epsilon^2}\n$$\n$$\n|\\nu-1| = 2|\\epsilon|\n$$\nSolving for the magnitude $|\\epsilon|$ gives the critical value $\\epsilon_{*}$:\n$$\n\\epsilon_{*} = |\\epsilon| = \\frac{|\\nu-1|}{2}\n$$\nFor any $|\\epsilon| < \\frac{|\\nu-1|}{2}$, the system is strongly hyperbolic. At $|\\epsilon| = \\frac{|\\nu-1|}{2}$, the system becomes weakly hyperbolic (unless $\\epsilon=0$ and $\\nu=1$). For $|\\epsilon| > \\frac{|\\nu-1|}{2}$, the eigenvalues become complex, and the system is no longer hyperbolic (it becomes elliptic), leading to an ill-posed initial value problem. The transition point is thus precisely at this critical value.", "answer": "$$\n\\boxed{\\frac{|\\nu-1|}{2}}\n$$", "id": "3497813"}, {"introduction": "Having explored the analytical conditions for weak hyperbolicity, we now turn to its practical consequences in numerical simulations. This hands-on coding exercise [@problem_id:3497807] challenges you to implement a numerical solver for both a strongly and a canonical weakly hyperbolic system. You will observe the classic pathology of weak hyperbolicity: a secular growth in high-frequency modes that leads to numerical solutions paradoxically deteriorating as grid resolution increases, a vital lesson in computational physics.", "problem": "Consider the linearized Arnowitt–Deser–Misner (ADM) formulation of general relativity around flat spacetime, restricted to one spatial dimension, and focus only on the principal part of an evolution system. In first-order form, write the system for a state vector $\\mathbf{u}(x,t)\\in\\mathbb{R}^2$ as\n$$\n\\partial_t \\mathbf{u} = A \\,\\partial_x \\mathbf{u},\n$$\nwhere $A$ is a constant $2\\times 2$ matrix capturing the principal symbol of the linearization. A fundamental base for analysis is the Fourier (normal mode) approach: insert the ansatz $\\mathbf{u}(x,t)=\\widehat{\\mathbf{u}}(k,t)e^{i k x}$ with spatial wavenumber $k\\in\\mathbb{R}$ to obtain\n$$\n\\partial_t \\widehat{\\mathbf{u}} = i k A \\,\\widehat{\\mathbf{u}}.\n$$\n\nHyperbolicity of this system is determined by the spectral properties of $A$. The system is strongly hyperbolic if, for each spatial direction, the principal symbol is diagonalizable with a complete set of eigenvectors and uniformly bounded condition number. It is only weakly hyperbolic if the eigenvalues are real but the principal symbol fails to be diagonalizable (has a nontrivial Jordan block). Weak hyperbolicity is known to lead to ill-posedness in the Hadamard sense, reflected in growth that is unbounded with respect to frequency $k$, which can manifest as resolution-dependent deterioration in numerical simulations of the ADM system.\n\nYou will implement and study a prototypical weakly hyperbolic test problem that models this behavior. Consider two matrices:\n$$\nA_{\\text{weak}} = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}, \\qquad\nA_{\\text{strong}} = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}.\n$$\nThe matrix $A_{\\text{weak}}$ has a repeated eigenvalue and a nontrivial Jordan block, hence represents a weakly hyperbolic principal part. In contrast, $A_{\\text{strong}}$ is diagonalizable with real eigenvalues, and represents a strongly hyperbolic principal part.\n\nYour program must numerically integrate the system on a periodic domain $[0,2\\pi]$ using the method of lines:\n- Use a uniform grid with $N$ points and grid spacing $h=2\\pi/N$.\n- Approximate $\\partial_x$ with the second-order centered difference operator\n$$\nD_h f_j = \\frac{f_{j+1}-f_{j-1}}{2h}, \\quad \\text{with periodic wrap-around}.\n$$\n- Advance in time to a final time $T$ with the classical fourth-order Runge–Kutta method (RK4).\n- Use a time step $\\Delta t = \\text{CFL}\\cdot h / a_{\\max}$ where $a_{\\max}$ is the maximum magnitude of the characteristic speeds implied by $A$ (for the above choices, take $a_{\\max}=1$). Ensure the final time integration spans exactly $T$ by taking an integer number of steps and resetting $\\Delta t = T / n_{\\text{steps}}$.\n\nFor an initial condition, take a single Fourier mode with wavenumber $m$ scaled to the grid:\n$$\n\\mathbf{u}(x,0) = \\begin{cases}\n\\big(\\sin(m x), \\sin(m x)\\big)^{\\top}, & \\text{generic two-component mode}, \\\\\n\\big(\\sin(m x), 0\\big)^{\\top}, & \\text{eigenvector-only mode for } A_{\\text{weak}}.\n\\end{cases}\n$$\nOn a grid of $N$ points, set $m=\\lfloor \\alpha N \\rfloor$ with a fixed fraction $\\alpha\\in(0,0.5)$ to probe resolution-dependent high-frequency behavior. Use the $L^2$ norm\n$$\n\\|\\mathbf{u}\\|_{L^2} = \\left( \\int_0^{2\\pi} \\left(u_1^2(x,t) + u_2^2(x,t)\\right) \\, dx \\right)^{1/2}\n$$\nand approximate it by the quadrature $\\left(h\\sum_j \\big(u_{1,j}^2+u_{2,j}^2\\big)\\right)^{1/2}$. Define the amplification factor\n$$\n\\mathcal{A} = \\frac{\\|\\mathbf{u}(\\cdot,T)\\|_{L^2}}{\\|\\mathbf{u}(\\cdot,0)\\|_{L^2}}.\n$$\n\nTask:\n- Implement the numerical integrator as described.\n- For each test case, compute the amplification factor $\\mathcal{A}$.\n\nScientific objective:\n- Explain, using the Fourier-symbol picture, why the weakly hyperbolic system with $A_{\\text{weak}}$ exhibits amplification that grows with resolution for high-frequency modes even when coarse grids appear stable for short times.\n- Demonstrate numerically that $\\mathcal{A}$ increases as $h\\to 0$ for the weakly hyperbolic generic mode, while remaining near unity for the eigenvector-only weak mode and for the strongly hyperbolic comparison.\n\nTest suite:\nProvide results for the following parameter sets $(\\text{system}, N, \\alpha, T, \\text{CFL})$:\n1. $(\\text{weak\\_generic}, 64, 0.25, 1.0, 0.5)$\n2. $(\\text{weak\\_generic}, 256, 0.25, 1.0, 0.5)$\n3. $(\\text{weak\\_generic}, 512, 0.25, 1.0, 0.5)$\n4. $(\\text{weak\\_eigen}, 256, 0.25, 1.0, 0.5)$\n5. $(\\text{strong\\_generic}, 256, 0.25, 1.0, 0.5)$\n\nAnswer specification:\n- For each test case, output the amplification factor $\\mathcal{A}$ as a float rounded to three decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4,\\text{result}_5]$).\n- No physical units are involved; all quantities are dimensionless.", "solution": "The problem is subjected to validation against the specified criteria.\n\n### Step 1: Extract Givens\n- **Governing Equation**: $\\partial_t \\mathbf{u} = A \\,\\partial_x \\mathbf{u}$ for a state vector $\\mathbf{u}(x,t)\\in\\mathbb{R}^2$.\n- **Matrices**:\n  - Weakly hyperbolic: $A_{\\text{weak}} = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}$.\n  - Strongly hyperbolic: $A_{\\text{strong}} = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}$.\n- **Domain**: Periodic, $x \\in [0, 2\\pi]$.\n- **Numerical Discretization (Method of Lines)**:\n  - **Spatial**: A uniform grid with $N$ points, spacing $h=2\\pi/N$, and a second-order centered difference operator $D_h f_j = \\frac{f_{j+1}-f_{j-1}}{2h}$ with periodic boundaries.\n  - **Temporal**: Classical fourth-order Runge–Kutta (RK4) integrator up to a final time $T$.\n- **Time Step**: $\\Delta t = \\text{CFL}\\cdot h / a_{\\max}$, with maximum characteristic speed $a_{\\max}=1$. The number of steps is fixed as $n_{\\text{steps}} = \\lceil T / \\Delta t_{\\text{initial}} \\rceil$ and the time step is adjusted to $\\Delta t = T / n_{\\text{steps}}$ to reach exactly time $T$.\n- **Initial Conditions**: A single Fourier mode with wavenumber $m=\\lfloor \\alpha N \\rfloor$ for $\\alpha\\in(0,0.5)$.\n  - Generic mode: $\\mathbf{u}(x,0) = (\\sin(m x), \\sin(m x))^{\\top}$.\n  - Eigenvector-only mode (for $A_{\\text{weak}}$): $\\mathbf{u}(x,0) = (\\sin(m x), 0)^{\\top}$.\n- **Analysis Metric**: The amplification factor $\\mathcal{A} = \\frac{\\|\\mathbf{u}(\\cdot,T)\\|_{L^2}}{\\|\\mathbf{u}(\\cdot,0)\\|_{L^2}}$, where the $L^2$ norm is approximated by the quadrature $\\|\\mathbf{u}\\|_{L^2} \\approx \\left(h\\sum_j \\big(u_{1,j}^2+u_{2,j}^2\\big)\\right)^{1/2}$.\n- **Test Suite**: Five cases are specified with parameters $(\\text{system}, N, \\alpha, T, \\text{CFL})$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientific Grounding**: The problem is scientifically sound. It addresses the well-established distinction between strong and weak hyperbolicity in the context of first-order partial differential equations, a cornerstone topic in numerical relativity and computational physics. The matrices $A_{\\text{weak}}$ and $A_{\\text{strong}}$ are canonical examples used to illustrate this concept. The predicted numerical pathology (resolution-dependent growth) for weakly hyperbolic systems is a known phenomenon.\n- **Well-Posedness**: The problem is well-posed. It specifies a complete initial-boundary value problem along with a fully determined numerical method for its solution. All parameters are provided.\n- **Objectivity**: The problem is stated in precise, objective, and formal mathematical language.\n- **Flaw Checklist**: The problem does not violate any of the specified criteria for invalidity. It is scientifically factual, formalizable, complete, feasible, well-structured, and non-trivial.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution is provided below.\n\n### Principle-Based Solution\n\nThe problem investigates the numerical consequences of weak hyperbolicity in systems of partial differential equations (PDEs). We analyze the behavior of the system $\\partial_t \\mathbf{u} = A \\,\\partial_x \\mathbf{u}$ by examining the properties of the evolution operator in Fourier space.\n\n**1. Hyperbolicity and the Fourier Symbol**\n\nFor a plane wave ansatz $\\mathbf{u}(x,t)=\\widehat{\\mathbf{u}}(k,t)e^{i k x}$ with spatial wavenumber $k$, the PDE system transforms into a system of ordinary differential equations (ODEs) for the Fourier amplitudes $\\widehat{\\mathbf{u}}$:\n$$\n\\partial_t \\widehat{\\mathbf{u}} = i k A \\,\\widehat{\\mathbf{u}}\n$$\nThe matrix $P(k) = ikA$ is the Fourier symbol of the differential operator. A system is defined as hyperbolic if the eigenvalues of the principal symbol matrix (in this 1D case, $A$) are all real. This ensures that the solutions $\\widehat{\\mathbf{u}}(k,t) = e^{ikAt}\\widehat{\\mathbf{u}}(k,0)$ are purely oscillatory for each mode $k$, not exponentially growing.\n\n**2. Strong vs. Weak Hyperbolicity**\n\nThe nature of the hyperbolicity depends on the eigensystem of $A$:\n- **Strongly Hyperbolic ($A_{\\text{strong}}$)**: The matrix $A_{\\text{strong}} = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}$ has distinct real eigenvalues $\\lambda = 1, -1$ and is diagonalizable. The evolution operator $e^{ikA_{\\text{strong}}t}$ is unitary (up to a coordinate transformation), so it preserves the norm of $\\widehat{\\mathbf{u}}(k,t)$ for all time. Consequently, the total $L^2$ norm of the solution is conserved, and the amplification factor $\\mathcal{A}$ is expected to be $1$.\n- **Weakly Hyperbolic ($A_{\\text{weak}}$)**: The matrix $A_{\\text{weak}} = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}$ has a repeated real eigenvalue $\\lambda = 1$ but is not diagonalizable; it possesses a non-trivial Jordan block. Its matrix exponential can be calculated as:\n$$\ne^{ikA_{\\text{weak}}t} = e^{ikt(I+N)} = e^{ikt}e^{ikNt} = e^{ikt}(I + ikNt + \\frac{(ikNt)^2}{2!} + \\dots)\n$$\nwhere $N = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}$. Since $N^2=0$, the series truncates:\n$$\ne^{ikA_{\\text{weak}}t} = e^{ikt} \\left( I + ikNt \\right) = e^{ikt} \\begin{pmatrix} 1 & ikt \\\\ 0 & 1 \\end{pmatrix}\n$$\nThe solution for a mode is $\\widehat{\\mathbf{u}}(k,t) = e^{ikt} \\begin{pmatrix} 1 & ikt \\\\ 0 & 1 \\end{pmatrix} \\widehat{\\mathbf{u}}(k,0)$. If the initial data $\\widehat{\\mathbf{u}}(k,0)$ has a component that is not in the true eigenspace (i.e., the second component is non-zero), the term $ikt$ causes the amplitude of the first component of $\\widehat{\\mathbf{u}}(k,t)$ to grow linearly with both time $t$ and wavenumber $k$. This unbounded growth with respect to $k$ signifies that the continuous problem is ill-posed in the sense of Hadamard.\n\n**3. Numerical Implications**\n\nThe method of lines discretizes the spatial domain, replacing the continuous derivative operator $\\partial_x$ with a discrete matrix operator. The symbol of the second-order centered difference operator $D_h$ is found by applying it to a grid function $e^{ikx_j}$:\n$$\nD_h e^{ikx_j} \\to i \\frac{\\sin(kh)}{h} e^{ikx_j}\n$$\nThe semi-discretized system for a Fourier mode behaves like $\\partial_t \\widehat{\\mathbf{u}} = i k_{\\text{eff}} A \\widehat{\\mathbf{u}}$, where $k_{\\text{eff}}(k) = \\frac{\\sin(kh)}{h}$ is the effective wavenumber.\n\nFor the weakly hyperbolic case, the growth is now proportional to $k_{\\text{eff}}t$. On a grid with $N$ points and spacing $h=2\\pi/N$, the highest wavenumbers that can be resolved are of order $k \\sim 1/h \\propto N$. The term $k_{\\text{eff}}$ is maximized for $kh=\\pi/2$, where $k_{\\text{eff}} = 1/h \\propto N$. The problem is designed with $\\alpha=0.25$, which sets the initial mode wavenumber $m = \\lfloor 0.25 N \\rfloor$. This corresponds to a grid wavenumber of $kh = m (2\\pi/N) \\approx 0.25 \\times 2\\pi = \\pi/2$. This choice precisely targets the frequency of maximum numerical growth.\n\nTherefore, for the weakly hyperbolic system with a generic initial condition:\n- The amplification is caused by the $ikt$ term in the evolution operator.\n- Higher resolution (larger $N$, smaller $h$) allows for the representation of modes with a larger effective wavenumber $k_{\\text{eff}} \\approx 1/h$.\n- This leads to a larger growth factor over a fixed time $T$, causing the amplification factor $\\mathcal{A}$ to increase with resolution. This is what the numerical tests are set up to demonstrate.\n\nIn contrast:\n- For the `weak_eigen` case, the initial condition $\\mathbf{u}(x,0) = (\\sin(mx), 0)^\\top$ lies entirely within the eigenspace of $A_{\\text{weak}}$. The evolution operator does not induce growth: $e^{ikt}\\begin{pmatrix} 1 & ikt \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} \\hat{u}_1 \\\\ 0 \\end{pmatrix} = e^{ikt}\\begin{pmatrix} \\hat{u}_1 \\\\ 0 \\end{pmatrix}$. The norm is preserved, and $\\mathcal{A} \\approx 1$.\n- For the `strong_generic` case, the system is norm-preserving. Numerical discretization will introduce small errors, but no systematic growth is expected, so $\\mathcal{A} \\approx 1$.\n\n**4. Implementation Details**\n\nThe solution is implemented using the Method of Lines. The state vector $\\mathbf{u}(x,t)$ is discretized onto a grid with $N$ points, yielding a large state vector of size $2N$. The spatial derivative $\\partial_x \\mathbf{u}$ is computed at each grid point using the centered difference formula with periodic wrap-around, which can be efficiently implemented using `np.roll`. This gives the right-hand side (RHS) of a large system of ODEs, $\\frac{d}{dt}\\mathbf{U} = F(\\mathbf{U})$. This ODE system is then integrated from $t=0$ to $t=T$ using the classical fourth-order Runge-Kutta (RK4) method. Finally, the $L^2$ norms of the initial and final states are computed via numerical quadrature to find the amplification factor $\\mathcal{A}$.", "answer": "[5.188,10.274,12.834,1.000,1.000]", "id": "3497807"}, {"introduction": "In practice, the evolution systems used in numerical relativity are too complex for simple analytical checks of hyperbolicity. This final exercise [@problem_id:3497814] introduces a powerful numerical technique to diagnose the hyperbolicity of a system based on its spectral properties, inspired by the Kreiss matrix theorem. By implementing a method to measure the scaling of a system's resolvent norm, you will build a practical tool to distinguish between well-posed (BSSN-like) and ill-posed (ADM-like) formulations, mirroring the kind of analysis that underpins modern numerical relativity.", "problem": "Consider a class of linear constant-coefficient first-order partial differential equation evolution systems arising in numerical relativity. For a unit spatial covector $n$ and a principal symbol matrix $P(n)$ (homogeneous of degree one in $n$), the resolvent of $P(n)$ at imaginary frequency $i\\omega$ is the matrix $\\left(i\\omega I - P(n)\\right)^{-1}$, and its operator $2$-norm is the spectral norm $\\left\\|\\left(i\\omega I - P(n)\\right)^{-1}\\right\\|_{2}$. A system is strongly hyperbolic if its principal symbol is diagonalizable with real eigenvalues for all $n \\neq 0$, which implies a uniform bound on the resolvent norm as $|n|$ increases for fixed $\\omega \\neq 0$ (in fact, for diagonalizable real-spectrum symbols with characteristic speeds proportional to $|n|$, the resolvent norm decays like $1/|n|$). A system is only weakly hyperbolic if the principal symbol is not diagonalizable, typically possessing Jordan blocks, which leads to growth of the resolvent norm with $|n|$ for fixed $\\omega \\neq 0$.\n\nYour task is to propose and implement a numerical method to detect weak hyperbolicity by examining the scaling of the resolvent norm $\\left\\|\\left(i\\omega I - P(n)\\right)^{-1}\\right\\|$ with $|n|$ via a rational approximation of the scalar function $f(x) = \\left\\|\\left(i\\omega I - P(n)\\right)^{-1}\\right\\|$ with $x = |n|$. Concretely:\n\n1. Base your derivation on the following principles and definitions:\n   - The principal symbol $P(n)$ is linear in $n$ and is obtained from the leading-order spatial derivative terms of the evolution system.\n   - Strong hyperbolicity implies diagonalizability of $P(n)$ with real eigenvalues; weak hyperbolicity implies non-diagonalizability (for example, nilpotent Jordan blocks).\n   - For diagonalizable real-spectrum matrices with entries scaling like $|n|$, the smallest singular value of $i\\omega I - P(n)$ scales like $|n|$ for fixed $\\omega \\neq 0$, implying $\\|\\left(i\\omega I - P(n)\\right)^{-1}\\| \\sim \\frac{1}{|n|}$.\n   - For a nilpotent Jordan block $J$ of size $m$, $\\left(i\\omega I - |n|J\\right)^{-1}$ is a finite polynomial in $\\frac{|n|}{\\omega}$ of degree $m-1$, implying $\\|\\left(i\\omega I - |n|J\\right)^{-1}\\|$ grows like $|n|^{m-1}$ for fixed $\\omega \\neq 0$.\n\n2. Define representative principal symbols for the linearized Arnowitt–Deser–Misner (ADM) system and the Baumgarte–Shapiro–Shibata–Nakamura (BSSN) system around Minkowski spacetime for plane waves with direction $n$:\n   - For the ADM-like weakly hyperbolic representative, use a block-diagonal principal symbol\n     $$\n     P_{\\mathrm{ADM}}(n) = \\begin{pmatrix}\n     |n|J_3 & 0 \\\\\n     0 & S(|n|)\n     \\end{pmatrix},\n     $$\n     where $J_3$ is the $3\\times 3$ nilpotent Jordan block with ones on the superdiagonal and zeros elsewhere, and $S(|n|)$ is a $2\\times 2$ symmetric matrix $S(|n|) = \\begin{pmatrix} 0 & |n| \\\\ |n| & 0 \\end{pmatrix}$ with eigenvalues $\\pm |n|$ modeling wave-like modes. This captures the known weak hyperbolicity of the standard linearized ADM formulation due to non-diagonalizable zero-speed modes.\n   - For the BSSN-like strongly hyperbolic representative, use a block-diagonal principal symbol\n     $$\n     P_{\\mathrm{BSSN}}(n) = \\begin{pmatrix}\n     S_1(|n|) & 0 \\\\\n     0 & S_2(|n|)\n     \\end{pmatrix},\n     $$\n     with $S_1(|n|) = \\begin{pmatrix} 0 & |n| \\\\ |n| & 0 \\end{pmatrix}$ and $S_2(|n|) = \\begin{pmatrix} 0 & 2|n| \\\\ 2|n| & 0 \\end{pmatrix}$, modeling two decoupled diagonalizable wave-like subsystems with characteristic speeds proportional to $|n|$.\n\n   These representatives are chosen to isolate the hyperbolicity features: a non-diagonalizable block in the ADM-like case and fully diagonalizable real-spectrum blocks in the BSSN-like case.\n\n3. For a fixed frequency $\\omega \\neq 0$, compute $f(x) = \\left\\|\\left(i\\omega I - P(n)\\right)^{-1}\\right\\|_{2}$ at a set of $x = |n|$ values. Approximate $f(x)$ with a rational function\n   $$\n   r(x) = \\frac{a_0 + a_1 x + a_2 x^2}{1 + b_1 x},\n   $$\n   by solving the linear least squares problem\n   $$\n   a_0 + a_1 x_i + a_2 x_i^2 - b_1 x_i y_i \\approx y_i,\n   $$\n   where $y_i = f(x_i)$. Use the fitted $r(x)$ to estimate the asymptotic scaling exponent at large $x$ by the logarithmic derivative at the largest $x$ in the sample,\n   $$\n   \\alpha(x) = \\frac{d\\log r(x)}{d\\log x} = \\frac{x r'(x)}{r(x)} = \\frac{x}{r(x)} \\cdot \\frac{N'(x)D(x) - N(x)D'(x)}{D(x)^2},\n   $$\n   where $N(x) = a_0 + a_1 x + a_2 x^2$ and $D(x) = 1 + b_1 x$. Classify the system as weakly hyperbolic if $\\alpha(x_{\\max}) > 0$ and strongly hyperbolic if $\\alpha(x_{\\max}) < 0$.\n\n4. All quantities are dimensionless; no physical units are required. Angles are not used.\n\n5. Implement the method and test it on the following parameter sets (test suite), using the exact resolvent norm computed by singular value decomposition to generate $y_i$, then performing the rational fit and classification:\n   - Test 1 (happy path, ADM-like): system type $\\mathrm{ADM}$, $\\omega = 1.0$, $x$ values $[1,2,4,8,16]$.\n   - Test 2 (happy path, BSSN-like): system type $\\mathrm{BSSN}$, $\\omega = 1.0$, $x$ values $[1,2,4,8,16]$.\n   - Test 3 (boundary, larger frequency): system type $\\mathrm{ADM}$, $\\omega = 10.0$, $x$ values $[1,2,4,8,16]$.\n   - Test 4 (edge, small frequency): system type $\\mathrm{BSSN}$, $\\omega = 0.1$, $x$ values $[1,2,4,8,16]$.\n\n6. Final output specification: Your program should produce a single line of output containing the classification results for the four tests as a comma-separated list enclosed in square brackets, where each entry is an integer $1$ for weakly hyperbolic and $0$ for strongly hyperbolic, in the same order as the test suite (for example, \"[1,0,1,0]\").\n\nYour solution should derive why the proposed rational approximation method captures the scaling distinction between weak and strong hyperbolicity and present a clear algorithmic path from the principles above to the implemented classification.", "solution": "The problem requires the development and implementation of a numerical method to classify linear first-order partial differential equation systems as either strongly or weakly hyperbolic. This classification is based on the asymptotic behavior of the operator $2$-norm of the resolvent of the system's principal symbol matrix.\n\n### 1. Theoretical Foundation: Hyperbolicity and the Resolvent Criterion\n\nAn evolution system of the form $\\partial_t u + \\sum_{j=1}^d A_j \\partial_{x_j} u + \\dots = 0$ is characterized by its principal symbol, a matrix-valued function $P(k) = \\sum_{j=1}^d k_j A_j$ of the spatial wavevector $k$. The type of hyperbolicity is determined by the properties of $P(k)$.\n\nA system is **strongly hyperbolic** if, for any non-zero spatial covector $n$, the matrix $P(n)$ is diagonalizable and has purely real eigenvalues. This property ensures that the initial value problem is well-posed, meaning solutions exist, are unique, and depend continuously on the initial data.\n\nA system is **weakly hyperbolic** if for some $n \\neq 0$, the eigenvalues of $P(n)$ are all real, but $P(n)$ is not diagonalizable. This typically occurs when $P(n)$ possesses one or more Jordan blocks of size greater than $1$ for certain zero-eigenvalues. Such systems can exhibit pathologies like instantaneous solution growth, making them unsuitable for stable numerical evolution.\n\nThe Kreiss matrix theorem and related results provide a powerful tool to distinguish these cases by examining the resolvent matrix $(i\\omega I - P(n))^{-1}$, where $\\omega$ is a real, non-zero frequency and $i = \\sqrt{-1}$. The key insight is that the asymptotic behavior of the resolvent's operator $2$-norm (spectral norm), $\\|(i\\omega I - P(n))^{-1}\\|_2$, for large wavenumbers $|n|$ reveals the system's hyperbolicity type. Let $x = |n|$.\n\n- For a **strongly hyperbolic** system, the eigenvalues $\\lambda_j(n)$ of $P(n)$ are real and typically scale linearly with $|n|$, i.e., $\\lambda_j(n) = c_j |n|$ for some constants $c_j$. The eigenvalues of the matrix $i\\omega I - P(n)$ are $i\\omega - \\lambda_j(n)$. The spectral norm of the inverse is the reciprocal of the smallest singular value of $i\\omega I - P(n)$. For a diagonalizable $P(n)$, this is bounded by a constant times the reciprocal of the minimum magnitude of its eigenvalues:\n$$\n\\left\\|\\left(i\\omega I - P(n)\\right)^{-1}\\right\\|_2 \\sim \\frac{1}{\\min_j |i\\omega - \\lambda_j(n)|} = \\frac{1}{\\min_j \\sqrt{\\omega^2 + \\lambda_j(n)^2}}\n$$\nFor large $x = |n|$, this behaves as:\n$$\nf(x) = \\left\\|\\left(i\\omega I - P(n)\\right)^{-1}\\right\\|_2 \\sim \\frac{1}{|n|} = x^{-1}\n$$\nThe norm decays as $x$ increases.\n\n- For a **weakly hyperbolic** system containing a nilpotent Jordan block of size $m>1$ associated with a zero-speed mode, the resolvent norm exhibits growth. For a principal symbol of the form $P(n) = |n| J_m$, where $J_m$ is an $m \\times m$ nilpotent Jordan block, the resolvent is $(i\\omega I - |n|J_m)^{-1}$. This can be expanded as a finite geometric series:\n$$\n\\left(i\\omega I - |n|J_m\\right)^{-1} = \\frac{1}{i\\omega} \\left(I - \\frac{|n|}{i\\omega}J_m\\right)^{-1} = \\frac{1}{i\\omega} \\sum_{k=0}^{m-1} \\left(\\frac{|n|}{i\\omega}J_m\\right)^k\n$$\nThe highest power of $|n|$ in this matrix polynomial is $|n|^{m-1}$. Consequently, for large $x = |n|$, the norm grows polynomially:\n$$\nf(x) = \\left\\|\\left(i\\omega I - P(n)\\right)^{-1}\\right\\|_2 \\sim |n|^{m-1} = x^{m-1}\n$$\n\nThe proposed method exploits this fundamental difference: decay for strong hyperbolicity versus growth for weak hyperbolicity.\n\n### 2. Representative Models and Their Scaling\n\nThe problem provides two representative principal symbols that isolate these behaviors. Let $x = |n|$.\n\n- **BSSN-like (Strongly Hyperbolic)**:\n$P_{\\mathrm{BSSN}}(x) = \\mathrm{diag}(S_1(x), S_2(x))$ where $S_1(x) = \\begin{pmatrix} 0 & x \\\\ x & 0 \\end{pmatrix}$ and $S_2(x) = \\begin{pmatrix} 0 & 2x \\\\ 2x & 0 \\end{pmatrix}$. This matrix is symmetric, hence diagonalizable, with real eigenvalues $\\pm x$ and $\\pm 2x$. All eigenvalues scale linearly with $x$. Following the analysis above, the resolvent norm for this system is expected to decay as $f(x) \\sim x^{-1}$.\n\n- **ADM-like (Weakly Hyperbolic)**:\n$P_{\\mathrm{ADM}}(x) = \\mathrm{diag}(x J_3, S(x))$ where $J_3$ is the $3 \\times 3$ nilpotent Jordan block and $S(x) = \\begin{pmatrix} 0 & x \\\\ x & 0 \\end{pmatrix}$. The matrix is block-diagonal, so the norm of its resolvent is the maximum of the norms of the resolvents of its blocks.\nThe block $(i\\omega I - x S(x))^{-1}$ corresponds to a strongly hyperbolic subsystem, so its norm decays as $x^{-1}$.\nThe block $(i\\omega I - x J_3)^{-1}$ corresponds to a weakly hyperbolic subsystem with $m=3$. Its norm grows as $x^{3-1} = x^2$.\nFor large $x$, the growth of the Jordan block term dominates the decay of the other block. Thus, the overall resolvent norm for the ADM-like system is expected to grow as $f(x) \\sim x^2$.\n\n### 3. Numerical Scheme for Scaling Detection\n\nThe core of the method is to fit the computed resolvent norm data $(x_i, y_i)$, where $y_i = f(x_i)$, to a model function and then examine the model's behavior to infer the scaling.\n\n**Rational Function Approximation**: The chosen model is the rational function\n$$\nr(x) = \\frac{N(x)}{D(x)} = \\frac{a_0 + a_1 x + a_2 x^2}{1 + b_1 x}\n$$\nTo find the coefficients $(a_0, a_1, a_2, b_1)$, we rearrange the approximation $y_i \\approx r(x_i)$ into a form suitable for linear least squares:\n$$\ny_i (1 + b_1 x_i) \\approx a_0 + a_1 x_i + a_2 x_i^2\n$$\n$$\ny_i \\approx a_0 + a_1 x_i + a_2 x_i^2 - b_1 x_i y_i\n$$\nThis defines an overdetermined linear system $M p \\approx Y$, where $p = [a_0, a_1, a_2, b_1]^T$, $Y = [y_1, y_2, \\dots]^T$, and the $i$-th row of matrix $M$ is $[1, x_i, x_i^2, -x_i y_i]$. The solution $p$ is found by minimizing the squared Euclidean norm $\\|Mp - Y\\|_2$.\n\n**Scaling Exponent Estimation**: The asymptotic behavior of a function $g(x)$ is often characterized by its logarithmic derivative, $\\alpha(x) = \\frac{d\\log g(x)}{d\\log x} = \\frac{x g'(x)}{g(x)}$. If $g(x) \\sim C x^k$, then $\\alpha(x) \\to k$ as $x \\to \\infty$. For our rational model $r(x)$, we calculate this quantity at the largest sampled point, $x_{\\max}$.\nWith $N(x) = a_0 + a_1 x + a_2 x^2$ and $D(x) = 1 + b_1 x$, the derivative is $r'(x) = \\frac{N'(x)D(x) - N(x)D'(x)}{D(x)^2}$. The logarithmic derivative is:\n$$\n\\alpha(x) = \\frac{x r'(x)}{r(x)} = \\frac{x (N'(x)D(x) - N(x)D'(x))}{N(x)D(x)}\n$$\nwhere $N'(x) = a_1 + 2a_2 x$ and $D'(x) = b_1$.\n\n**Classification**: The sign of $\\alpha(x_{\\max})$ serves as the classifier.\n- If $\\alpha(x_{\\max}) > 0$, the function is locally increasing, indicating growth. The system is classified as **weakly hyperbolic** (code $1$).\n- If $\\alpha(x_{\\max}) < 0$, the function is locally decreasing, indicating decay. The system is classified as **strongly hyperbolic** (code $0$).\n\nThis approach relies on the assumption that for the given range of $x_i$, the fitted model $r(x)$ will correctly capture the qualitative trend of growth or decay, even if its own asymptotic form ($r(x) \\sim x^1$) does not perfectly match the true behavior for the weakly hyperbolic case ($f(x) \\sim x^2$).\n\n### 4. Algorithmic Implementation\n\nThe procedure to classify a given system for a specific $\\omega$ over a set of $x$ values is as follows:\n\n1.  **Data Generation**: For each $x_i$ in the sample set:\n    a. Construct the principal symbol matrix $P(x_i)$ based on the system type (ADM or BSSN).\n    b. Form the complex matrix $A = i\\omega I - P(x_i)$.\n    c. Compute the singular values of $A$ using Singular Value Decomposition (SVD).\n    d. The resolvent norm is $y_i = \\|A^{-1}\\|_2 = 1/\\sigma_{\\min}(A)$, where $\\sigma_{\\min}(A)$ is the smallest singular value of $A$.\n2.  **Least Squares Fit**:\n    a. Assemble the matrix $M$ and vector $Y$ from the generated $(x_i, y_i)$ pairs as described above.\n    b. Solve the linear least squares problem $M p \\approx Y$ to obtain the coefficient vector $p = [a_0, a_1, a_2, b_1]^T$.\n3.  **Classification**:\n    a. Set $x = x_{\\max}$, the largest value in the sample set.\n    b. Using the fitted coefficients, calculate the value of the logarithmic derivative $\\alpha(x_{\\max})$.\n    c. If $\\alpha(x_{\\max}) > 0$, the classification is $1$ (weakly hyperbolic). Otherwise, it is $0$ (strongly hyperbolic).\n4.  **Output**: Collect the classification results for all test cases and format them as a comma-separated list within brackets.", "answer": "[1,0,1,0]", "id": "3497814"}]}