{"hands_on_practices": [{"introduction": "The heart of assembling an impedance matrix lies in the accurate and efficient evaluation of the double integrals that define each entry. The behavior of the integral's kernel can range from smooth to highly oscillatory or even singular, depending on the separation between the interacting basis functions. This exercise [@problem_id:3317213] provides hands-on practice in designing an adaptive quadrature selector, a critical component of any modern Method of Moments code, which automates the choice of an appropriate numerical integration rule based on the geometric and electrical properties of the interaction.", "problem": "Consider the assembly of the impedance matrix in a surface integral equation formulation for computational electromagnetics. Let the impedance matrix entry between basis function support regions $S_m$ and $S_n$ be defined by a surface integral of a scalar kernel over two planar rectangles with constant basis functions, that is, using a pulse (constant) basis on each rectangular element. The integral is a double surface integral over $S_m$ and $S_n$ of a kernel that captures the physics. An example kernel is the free-space scalar Green's function of the Helmholtz equation, $G(\\mathbf r,\\mathbf r') = \\dfrac{e^{-i k \\lvert \\mathbf r - \\mathbf r' \\rvert}}{4\\pi \\lvert \\mathbf r - \\mathbf r' \\rvert}$, where $k$ is the wavenumber and $i$ is the imaginary unit. The impedance matrix entry $Z_{mn}$ has the structure\n$$\nZ_{mn} \\propto \\int_{S_m} \\int_{S_n} G(\\mathbf r,\\mathbf r') \\,\\mathrm dS(\\mathbf r) \\,\\mathrm dS(\\mathbf r').\n$$\nFor constant basis functions on rectangles in the plane, the integrand exhibits near-singular behavior when the rectangles are close, is singular when they are coincident in the sense $\\mathbf r = \\mathbf r'$ inside the same element, and may be oscillatory when $k$ is large. Accurate and efficient numerical evaluation requires selecting a quadrature rule adapted to the interaction regime.\n\nYou must design and implement an adaptive quadrature selector that, given two axis-aligned planar rectangular elements $S_m$ and $S_n$ lying in the plane $z=0$, with centers $(x_m,y_m)$ and $(x_n,y_n)$ in meters, side lengths $(a_m,b_m)$ and $(a_n,b_n)$ in meters, and a wavenumber $k$ in radians per meter, chooses a quadrature rule identifier and recommended tensor-product quadrature orders along the local $x$ and $y$ directions. The selector must use the proximity metric\n$$\nR_{\\min} = \\min_{\\mathbf r \\in S_m,\\ \\mathbf r' \\in S_n} \\lvert \\mathbf r - \\mathbf r' \\rvert,\n$$\nand aspect ratios\n$$\n\\mathrm{AR}_m = \\frac{\\max(a_m,b_m)}{\\min(a_m,b_m)},\\quad \\mathrm{AR}_n = \\frac{\\max(a_n,b_n)}{\\min(a_n,b_n)},\\quad \\mathrm{AR}_{\\mathrm{avg}} = \\frac{\\mathrm{AR}_m + \\mathrm{AR}_n}{2}.\n$$\nDefine a characteristic length for each rectangle as\n$$\nL_m = \\sqrt{a_m b_m},\\quad L_n = \\sqrt{a_n b_n},\\quad L_{\\min} = \\min(L_m,L_n).\n$$\nDefine dimensionless metrics\n$$\n\\chi = \\frac{R_{\\min}}{L_{\\min}},\\qquad \\eta = k\\, R_{\\min}.\n$$\nYour selector must produce an integer quadrature rule identifier $r \\in \\{0,1,2,3\\}$ and two positive integers $(N_x,N_y)$ indicating the recommended number of points along the rectangle’s local $x$ and $y$ directions, respectively, for a tensor-product quadrature. The mapping from $(\\chi,\\eta,\\mathrm{AR}_{\\mathrm{avg}})$ to $(r,N_x,N_y)$ must be constructed from first principles about kernel behavior:\n\n- For far interactions where the kernel is smooth over the pair of rectangles, a standard tensor-product Gauss–Legendre rule with modest order is sufficient, but the order should increase with the oscillation parameter $\\eta$ to resolve the phase.\n- For moderately close interactions, the kernel gradient increases and tensor-product Gauss–Legendre requires higher order; incorporate both $\\eta$ and $\\mathrm{AR}_{\\mathrm{avg}}$.\n- For near interactions (including touching rectangles where $R_{\\min} = 0$), use specialized near-singular integration (for example, Duffy or polar transformations). Even though you are only selecting, the recommended orders should reflect the increased difficulty by growing with $\\mathrm{AR}_{\\mathrm{avg}}$ and as $\\chi \\to 0$.\n- For self interactions ($S_m$ and $S_n$ identical), recommend a specialized self-term rule with high order that grows with $\\mathrm{AR}_{\\mathrm{avg}}$.\n\nTo make the selector numerically well-defined, adopt the following classification thresholds and order formulas grounded in the above principles. Let $\\varepsilon$ be a small positive constant to avoid division by zero:\n- If the rectangles are identical (same centers and side lengths within a strict tolerance), set $r=3$ and the baseline scalar order $Q$ as\n$$\nQ = \\max\\left(12,\\, \\left\\lceil 8\\, \\mathrm{AR}_{\\mathrm{avg}} + 6 \\right\\rceil \\right).\n$$\n- Else, compute $\\chi = \\max\\!\\left(\\dfrac{R_{\\min}}{L_{\\min}},\\, \\varepsilon\\right)$, with $\\varepsilon = 10^{-12}$, and classify:\n    - Near: if $\\chi \\le 0.3$, set $r=2$ and\n    $$\n    Q = \\max\\left(12,\\, \\left\\lceil 6\\, \\mathrm{AR}_{\\mathrm{avg}} + 3 \\,\\log\\!\\left(1 + \\frac{1}{\\chi}\\right) \\right\\rceil \\right).\n    $$\n    - Moderately close: if $0.3 < \\chi \\le 1.5$, set $r=1$ and\n    $$\n    Q = \\max\\left(6,\\, \\left\\lceil 4\\, \\mathrm{AR}_{\\mathrm{avg}} + 2 \\,\\sqrt{\\eta + 1} \\right\\rceil \\right).\n    $$\n    - Far: if $\\chi > 1.5$, set $r=0$ and\n    $$\n    Q = \\max\\left(4,\\, \\left\\lceil 2\\,(1 + \\eta) \\right\\rceil \\right).\n    $$\nFinally map the scalar baseline order $Q$ to anisotropic tensor-product orders using the aspect ratio:\n$$\ns = \\sqrt{\\mathrm{AR}_{\\mathrm{avg}}},\\qquad N_x = \\left\\lceil Q\\, s \\right\\rceil,\\qquad N_y = \\left\\lceil \\frac{Q}{s} \\right\\rceil.\n$$\nAll logarithms are natural logarithms. The integers $(N_x,N_y)$ are dimensionless counts. Distances are in meters, and $k$ is in radians per meter.\n\nImplement a program that:\n1. Represents rectangles as axis-aligned elements in the plane $z=0$ by their center $(x,y)$ in meters and side lengths $(a,b)$ in meters.\n2. Computes $R_{\\min}$ for a pair of rectangles using exact geometry for axis-aligned rectangles in the plane.\n3. Computes $\\mathrm{AR}_{\\mathrm{avg}}$, $L_{\\min}$, $\\chi$, and $\\eta$.\n4. Applies the above classification and formulas to produce $(r,N_x,N_y)$.\n\nInclude a test suite of the following five cases, covering far, moderately close, near (including touching), high aspect ratio, oscillatory, and self interactions. All coordinates and lengths must be treated in meters, and $k$ in radians per meter:\n- Test case $1$: $S_m$: center $(0,0)$, sides $(0.1,0.1)$; $S_n$: center $(0.8,0)$, sides $(0.1,0.1)$; $k = \\dfrac{2\\pi}{0.3}$.\n- Test case $2$: $S_m$: center $(0,0)$, sides $(0.1,0.05)$; $S_n$: center $(0.12,0)$, sides $(0.08,0.04)$; $k = 5$.\n- Test case $3$: $S_m$: center $(0,0)$, sides $(0.2,0.02)$; $S_n$: center $(0.205,0)$, sides $(0.2,0.02)$; $k = 20$.\n- Test case $4$: $S_m$: center $(0,0)$, sides $(0.1,0.05)$; $S_n$: identical to $S_m$; $k = 0$.\n- Test case $5$: $S_m$: center $(0,0)$, sides $(0.1,0.1)$; $S_n$: center $(0.1,0)$, sides $(0.1,0.1)$; $k = 500$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each result is itself a list of three integers $[r,N_x,N_y]$ with no spaces. For example, the expected format is\n$$\n\\big[ [r_1,N_{x,1},N_{y,1}], [r_2,N_{x,2},N_{y,2}], [r_3,N_{x,3},N_{y,3}], [r_4,N_{x,4},N_{y,4}], [r_5,N_{x,5},N_{y,5}] \\big].\n$$", "solution": "The impedance matrix arises from boundary integral formulations of Maxwell's equations. Starting from the time-harmonic form of Maxwell's equations in free space,\n$$\n\\nabla \\times \\mathbf E = -i\\omega \\mu \\mathbf H,\\qquad \\nabla \\times \\mathbf H = i\\omega \\varepsilon \\mathbf E,\n$$\nand eliminating fields via appropriate Green's functions, one obtains surface integral equations in which the unknown current density is expanded in basis functions supported on surface elements. For constant basis functions on planar rectangles, each impedance matrix component $Z_{mn}$ involves a double surface integral of a scalar kernel over the two rectangles:\n$$\nZ_{mn} \\propto \\int_{S_m} \\int_{S_n} G(\\mathbf r,\\mathbf r') \\,\\mathrm dS(\\mathbf r) \\,\\mathrm dS(\\mathbf r'),\n$$\nwhere $G(\\mathbf r,\\mathbf r') = \\dfrac{e^{-i k \\lvert \\mathbf r - \\mathbf r' \\rvert}}{4\\pi \\lvert \\mathbf r - \\mathbf r' \\rvert}$ is the free-space scalar Green's function of the Helmholtz equation with wavenumber $k$. The kernel exhibits a $1/\\lvert \\mathbf r - \\mathbf r' \\rvert$ singularity as $\\mathbf r \\to \\mathbf r'$, which is integrable over two-dimensional surfaces, and oscillatory behavior as $k$ increases. Numerical quadrature must be adapted to the geometric proximity and oscillation to control error.\n\nTo build an adaptive selector, we formalize proximity and anisotropy via metrics that are dimensionless and physically meaningful. For two axis-aligned planar rectangles in $z=0$, with centers $(x_m,y_m)$, $(x_n,y_n)$ and side lengths $(a_m,b_m)$, $(a_n,b_n)$, define the aspect ratios\n$$\n\\mathrm{AR}_m = \\frac{\\max(a_m,b_m)}{\\min(a_m,b_m)},\\quad \\mathrm{AR}_n = \\frac{\\max(a_n,b_n)}{\\min(a_n,b_n)},\\quad \\mathrm{AR}_{\\mathrm{avg}} = \\frac{\\mathrm{AR}_m + \\mathrm{AR}_n}{2}.\n$$\nAnisotropy affects how many points are required along each direction; longer sides require more points to resolve geometric variation. A characteristic element length is taken as\n$$\nL_m = \\sqrt{a_m b_m},\\quad L_n = \\sqrt{a_n b_n},\\quad L_{\\min} = \\min(L_m,L_n),\n$$\nwhich is proportional to the geometric mean of the sides and captures an effective size that is invariant under swapping $a$ and $b$. The minimum separation $R_{\\min}$ between two axis-aligned rectangles in a plane can be computed by decomposing separation along $x$ and $y$ axes:\n$$\n\\text{Let } x\\text{-ranges }[x_m - a_m/2,\\, x_m + a_m/2],\\ [x_n - a_n/2,\\, x_n + a_n/2],\\\\\n\\text{and } y\\text{-ranges }[y_m - b_m/2,\\, y_m + b_m/2],\\ [y_n - b_n/2,\\, y_n + b_n/2].\n$$\nDefine axial gaps\n$$\nd_x = \\max\\big(0,\\, x_m - \\frac{a_m}{2} - (x_n + \\frac{a_n}{2}),\\, x_n - \\frac{a_n}{2} - (x_m + \\frac{a_m}{2})\\big),\\\\\nd_y = \\max\\big(0,\\, y_m - \\frac{b_m}{2} - (y_n + \\frac{b_n}{2}),\\, y_n - \\frac{b_n}{2} - (y_m + \\frac{b_m}{2})\\big),\n$$\nthen\n$$\nR_{\\min} = \\sqrt{d_x^2 + d_y^2}.\n$$\nIf the projections overlap or touch in an axis, the corresponding axial gap is zero. If both projections overlap or touch, $R_{\\min} = 0$ (touching or overlapping rectangles). \n\nTo classify interaction regimes, we define dimensionless metrics\n$$\n\\chi = \\frac{R_{\\min}}{L_{\\min}},\\qquad \\eta = k\\, R_{\\min}.\n$$\nThe parameter $\\chi$ compares proximity to size: $\\chi \\ll 1$ indicates near singular behavior because the kernel varies rapidly and is dominated by the $1/\\lvert \\mathbf r - \\mathbf r' \\rvert$ structure over the integration domains. The parameter $\\eta$ measures oscillation; larger $\\eta$ requires finer quadrature to resolve the phase $e^{-i k \\lvert \\mathbf r - \\mathbf r' \\rvert}$. These considerations lead to the following selection logic:\n\n- Self interaction: If rectangles are identical (same center and side lengths), then the integral involves the kernel singularity along the diagonal of the domain. Although integrable, specialized transformations such as Duffy mapping are needed; we signal this by a dedicated rule identifier and set a relatively high baseline order growing with $\\mathrm{AR}_{\\mathrm{avg}}$:\n$$\nQ = \\max\\left(12,\\, \\left\\lceil 8\\, \\mathrm{AR}_{\\mathrm{avg}} + 6 \\right\\rceil \\right).\n$$\nThe constants $8$ and $6$ reflect a conservative bias for self terms: anisotropy increases the difficulty, and a fixed offset ensures a minimum resolution.\n\n- Near interaction: If $\\chi \\le 0.3$, proximity is small relative to size and the kernel’s near-singular variation dominates. Specialized near-singular rules (such as Duffy or polar-coordinates quadrature) are indicated by rule identifier $2$. The order must rise with both anisotropy and the severity of proximity. A reasonable dependence is logarithmic in $1/\\chi$ because singularity-resolving transformations turn the $1/r$ singularity into integrals whose difficulty scales with how close the panels are, often introducing weakly singular or smooth integrands that still require finer resolution as $\\chi \\to 0$. Thus:\n$$\nQ = \\max\\left(12,\\, \\left\\lceil 6\\, \\mathrm{AR}_{\\mathrm{avg}} + 3 \\,\\log\\!\\left(1 + \\frac{1}{\\chi}\\right) \\right\\rceil \\right).\n$$\nHere the factor $6$ scales quadrature order with anisotropy, and the factor $3$ scales with the logarithmic proximity measure. The minimum $12$ enforces a baseline robustness for near-singular cases.\n\n- Moderately close interaction: If $0.3 < \\chi \\le 1.5$, the kernel has steep gradients but is not near-singular; a tensor-product Gauss–Legendre rule can be used with enhanced order. Oscillation enters via $\\eta$, and anisotropy via $\\mathrm{AR}_{\\mathrm{avg}}$:\n$$\nQ = \\max\\left(6,\\, \\left\\lceil 4\\, \\mathrm{AR}_{\\mathrm{avg}} + 2 \\,\\sqrt{\\eta + 1} \\right\\rceil \\right).\n$$\nThe square-root dependence on $\\eta$ reflects that for moderate oscillations, phase resolution requirements grow sublinearly with $\\eta$; the offset $+1$ ensures behavior at $\\eta=0$ is defined. The factor $4$ scales with anisotropy, and minimum $6$ ensures nontrivial resolution.\n\n- Far interaction: If $\\chi > 1.5$, the kernel is smooth over the domains. Oscillation must still be resolved. A simple linear dependence on $(1+\\eta)$ is conservative and straightforward:\n$$\nQ = \\max\\left(4,\\, \\left\\lceil 2\\,(1 + \\eta) \\right\\rceil \\right).\n$$\nThe minimum $4$ provides a base accuracy when $\\eta$ is small.\n\nAnisotropic mapping from the scalar baseline order $Q$ to tensor-product orders $(N_x,N_y)$ accounts for element stretch. If $\\mathrm{AR}_{\\mathrm{avg}} = 1$, the element is square-like and $N_x \\approx N_y \\approx Q$. If $\\mathrm{AR}_{\\mathrm{avg}} > 1$, allocate more points along the longer dimension. A smooth mapping uses $s = \\sqrt{\\mathrm{AR}_{\\mathrm{avg}}}$ and\n$$\nN_x = \\left\\lceil Q\\, s \\right\\rceil,\\qquad N_y = \\left\\lceil \\frac{Q}{s} \\right\\rceil,\n$$\nwhich keeps $N_x N_y \\approx Q^2$ while biasing toward the long side.\n\nAlgorithmic steps:\n1. Input rectangles $(x_m,y_m,a_m,b_m)$, $(x_n,y_n,a_n,b_n)$ in meters, and $k$ in radians per meter.\n2. Compute $R_{\\min}$ via axis-aligned rectangle distance in the plane:\n   - Compute $x$-intervals $[x_m - a_m/2, x_m + a_m/2]$ and $[x_n - a_n/2, x_n + a_n/2]$, and similarly for $y$.\n   - Compute $d_x$ as the nonnegative separation of these intervals along $x$; compute $d_y$ similarly along $y$.\n   - Set $R_{\\min} = \\sqrt{d_x^2 + d_y^2}$.\n3. Compute $\\mathrm{AR}_m$, $\\mathrm{AR}_n$, $\\mathrm{AR}_{\\mathrm{avg}}$, $L_m$, $L_n$, $L_{\\min}$, and set $\\chi = \\max(R_{\\min}/L_{\\min}, \\varepsilon)$ with $\\varepsilon = 10^{-12}$, and $\\eta = k\\, R_{\\min}$.\n4. If rectangles are identical within strict tolerance, set $r=3$ and compute $Q$ via the self formula; else classify via $\\chi$ and compute $Q$ accordingly; map to $(N_x,N_y)$ via $s = \\sqrt{\\mathrm{AR}_{\\mathrm{avg}}}$.\n5. Output $[r,N_x,N_y]$ as integers.\n\nApplying this to the prescribed test suite:\n\n- Test case $1$: $S_m$: center $(0,0)$, sides $(0.1,0.1)$; $S_n$: center $(0.8,0)$, sides $(0.1,0.1)$; $k = \\dfrac{2\\pi}{0.3}$. The $x$-intervals are $[-0.05,0.05]$ and $[0.75,0.85]$; $d_x = 0.70$, $d_y = 0$, so $R_{\\min} = 0.70$. With $L_{\\min} = \\sqrt{0.1\\cdot 0.1} = 0.1$, $\\chi = 7 > 1.5$ (far). $\\eta \\approx 20.943951\\cdot 0.70 \\approx 14.661$, yielding $Q = \\max\\!\\big(4, \\left\\lceil 2(1 + 14.661)\\right\\rceil\\big) = 32$. With $\\mathrm{AR}_{\\mathrm{avg}} = 1$, $s=1$, so $N_x = 32$, $N_y = 32$, and $r=0$.\n\n- Test case $2$: $S_m$: center $(0,0)$, sides $(0.1,0.05)$; $S_n$: center $(0.12,0)$, sides $(0.08,0.04)$; $k = 5$. The $x$-intervals are $[-0.05,0.05]$ and $[0.08,0.16]$; $d_x = 0.03$, $d_y = 0$, so $R_{\\min} = 0.03$. $L_m = \\sqrt{0.1\\cdot 0.05} \\approx 0.07071$, $L_n = \\sqrt{0.08\\cdot 0.04} \\approx 0.05657$, $L_{\\min} \\approx 0.05657$, hence $\\chi \\approx 0.53$ (moderately close). $\\eta = 5\\cdot 0.03 = 0.15$, leading to $Q = \\max\\!\\big(6, \\left\\lceil 4\\cdot 2 + 2\\sqrt{1.15}\\right\\rceil\\big) = \\left\\lceil 8 + 2.146\\right\\rceil = 11$. With $\\mathrm{AR}_{\\mathrm{avg}} = 2$, $s \\approx 1.4142$, $N_x = \\left\\lceil 11\\cdot 1.4142 \\right\\rceil = 16$, $N_y = \\left\\lceil 11/1.4142 \\right\\rceil = 8$, and $r=1$.\n\n- Test case $3$: $S_m$: center $(0,0)$, sides $(0.2,0.02)$; $S_n$: center $(0.205,0)$, sides $(0.2,0.02)$; $k = 20$. The $x$-intervals are $[-0.1,0.1]$ and $[0.105,0.305]$; $d_x = 0.005$, $d_y = 0$, so $R_{\\min} = 0.005$. $L_{\\min} = \\sqrt{0.2\\cdot 0.02} \\approx 0.0632456$, $\\chi \\approx 0.079$ (near). $\\eta = 20\\cdot 0.005 = 0.1$. Then $Q = \\max\\!\\big(12, \\left\\lceil 6\\cdot 10 + 3\\log(1 + 1/0.079)\\right\\rceil\\big) \\approx \\left\\lceil 60 + 7.845\\right\\rceil = 68$. With $\\mathrm{AR}_{\\mathrm{avg}} = 10$, $s \\approx 3.1623$, $N_x = \\left\\lceil 68\\cdot 3.1623 \\right\\rceil = 216$, $N_y = \\left\\lceil 68/3.1623 \\right\\rceil = 22$, and $r=2$.\n\n- Test case $4$: $S_m$: center $(0,0)$, sides $(0.1,0.05)$; $S_n$: identical; $k = 0$. Identical rectangles imply self interaction, $r=3$. With $\\mathrm{AR}_{\\mathrm{avg}} = 2$, $Q = \\max\\!\\big(12, \\left\\lceil 8\\cdot 2 + 6 \\right\\rceil\\big) = 22$. Then $s \\approx 1.4142$, $N_x = \\left\\lceil 22\\cdot 1.4142 \\right\\rceil = 32$, $N_y = \\left\\lceil 22/1.4142 \\right\\rceil = 16$.\n\n- Test case $5$: $S_m$: center $(0,0)$, sides $(0.1,0.1)$; $S_n$: center $(0.1,0)$, sides $(0.1,0.1)$; $k = 500$. The $x$-intervals are $[-0.05,0.05]$ and $[0.05,0.15]$; they touch at $x=0.05$, so $d_x=0$ and $R_{\\min}=0$. With $L_{\\min} = 0.1$, set $\\chi = \\max(0/0.1,\\varepsilon) = 10^{-12}$ (near). Then $Q = \\max\\!\\big(12, \\left\\lceil 6\\cdot 1 + 3\\log(1 + 10^{12}) \\right\\rceil\\big) \\approx \\left\\lceil 6 + 82.893\\right\\rceil = 89$. With $\\mathrm{AR}_{\\mathrm{avg}} = 1$, $s=1$, $N_x = 89$, $N_y = 89$, and $r=2$.\n\nThus, the selector produces $[r,N_x,N_y]$ for each case consistent with the physical and numerical principles. The program must implement these steps and print a single line containing the five results as a list of lists, with no spaces, in the format\n$$\n\\big[ [r_1,N_{x,1},N_{y,1}], [r_2,N_{x,2},N_{y,2}], [r_3,N_{x,3},N_{y,3}], [r_4,N_{x,4},N_{y,4}], [r_5,N_{x,5},N_{y,5}] \\big].\n$$", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef rectangle_distance_2d(rect1, rect2):\n    \"\"\"\n    Compute the minimum distance between two axis-aligned rectangles in 2D.\n    Each rect is a tuple (cx, cy, ax, by) with center (cx, cy) and side lengths (ax, by).\n    Returns R_min >= 0.\n    \"\"\"\n    x1_min = rect1[0] - rect1[2] / 2.0\n    x1_max = rect1[0] + rect1[2] / 2.0\n    y1_min = rect1[1] - rect1[3] / 2.0\n    y1_max = rect1[1] + rect1[3] / 2.0\n\n    x2_min = rect2[0] - rect2[2] / 2.0\n    x2_max = rect2[0] + rect2[2] / 2.0\n    y2_min = rect2[1] - rect2[3] / 2.0\n    y2_max = rect2[1] + rect2[3] / 2.0\n\n    # Separation along x: positive if disjoint, else 0\n    dx1 = x1_min - x2_max\n    dx2 = x2_min - x1_max\n    dx = max(0.0, dx1, dx2)\n\n    # Separation along y: positive if disjoint, else 0\n    dy1 = y1_min - y2_max\n    dy2 = y2_min - y1_max\n    dy = max(0.0, dy1, dy2)\n\n    return float(np.hypot(dx, dy))\n\ndef aspect_ratio(rect):\n    \"\"\"Return aspect ratio AR = max(a,b)/min(a,b) for rect (cx, cy, ax, by).\"\"\"\n    a = rect[2]\n    b = rect[3]\n    m = max(a, b)\n    n = min(a, b)\n    # Guard against degenerate rectangles (should not occur in test cases)\n    if n <= 0.0 or m <= 0.0:\n        raise ValueError(\"Rectangle sides must be positive.\")\n    return float(m / n)\n\ndef characteristic_length(rect):\n    \"\"\"Return L = sqrt(a*b) for rect (cx, cy, ax, by).\"\"\"\n    a = rect[2]\n    b = rect[3]\n    if a <= 0.0 or b <= 0.0:\n        raise ValueError(\"Rectangle sides must be positive.\")\n    return float(np.sqrt(a * b))\n\ndef rectangles_identical(rect1, rect2, tol=1e-15):\n    \"\"\"Check if two rectangles are identical within a strict tolerance.\"\"\"\n    return (abs(rect1[0] - rect2[0]) <= tol and\n            abs(rect1[1] - rect2[1]) <= tol and\n            abs(rect1[2] - rect2[2]) <= tol and\n            abs(rect1[3] - rect2[3]) <= tol)\n\ndef select_quadrature(rect1, rect2, k):\n    \"\"\"\n    Adaptive quadrature selector returning [rule_id, Nx, Ny].\n    rule_id: 0 (far), 1 (moderately close), 2 (near/singular), 3 (self-term).\n    Nx, Ny: recommended tensor-product orders along x and y.\n    \"\"\"\n    # Compute proximity and geometry metrics\n    Rmin = rectangle_distance_2d(rect1, rect2)\n    AR_m = aspect_ratio(rect1)\n    AR_n = aspect_ratio(rect2)\n    AR_avg = 0.5 * (AR_m + AR_n)\n    L_m = characteristic_length(rect1)\n    L_n = characteristic_length(rect2)\n    L_min = min(L_m, L_n)\n\n    # Handle self interaction\n    if rectangles_identical(rect1, rect2):\n        r = 3\n        Q = int(max(12, int(np.ceil(8.0 * AR_avg + 6.0))))\n    else:\n        # Dimensionless parameters\n        eps = 1e-12\n        chi = max(Rmin / L_min, eps)\n        eta = k * Rmin\n\n        if chi <= 0.3:\n            # Near interaction\n            r = 2\n            Q = int(max(12, int(np.ceil(6.0 * AR_avg + 3.0 * np.log(1.0 + 1.0 / chi)))))\n        elif chi <= 1.5:\n            # Moderately close interaction\n            r = 1\n            Q = int(max(6, int(np.ceil(4.0 * AR_avg + 2.0 * np.sqrt(eta + 1.0)))))\n        else:\n            # Far interaction\n            r = 0\n            Q = int(max(4, int(np.ceil(2.0 * (1.0 + eta)))))\n\n    # Map scalar order to anisotropic tensor-product orders\n    s = float(np.sqrt(AR_avg))\n    Nx = int(np.ceil(Q * s))\n    Ny = int(np.ceil(Q / s))\n    return [r, Nx, Ny]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each rectangle: (cx, cy, ax, by) in meters. k in radians per meter.\n    test_cases = [\n        # Test case 1: far interaction, k = 2*pi/0.3\n        ((0.0, 0.0, 0.1, 0.1), (0.8, 0.0, 0.1, 0.1), 2.0 * np.pi / 0.3),\n        # Test case 2: moderately close, anisotropic, k = 5\n        ((0.0, 0.0, 0.1, 0.05), (0.12, 0.0, 0.08, 0.04), 5.0),\n        # Test case 3: near interaction, high aspect ratio, k = 20\n        ((0.0, 0.0, 0.2, 0.02), (0.205, 0.0, 0.2, 0.02), 20.0),\n        # Test case 4: self interaction, k = 0\n        ((0.0, 0.0, 0.1, 0.05), (0.0, 0.0, 0.1, 0.05), 0.0),\n        # Test case 5: touching rectangles, highly oscillatory, k = 500\n        ((0.0, 0.0, 0.1, 0.1), (0.1, 0.0, 0.1, 0.1), 500.0),\n    ]\n\n    results = []\n    for rect1, rect2, k in test_cases:\n        result = select_quadrature(rect1, rect2, k)\n        results.append(result)\n\n    # Final print statement in the exact required format: no spaces inside the list.\n    # Format: [[r1,Nx1,Ny1],[r2,Nx2,Ny2],...]\n    items = [str(r).replace(' ', '') for r in results]\n    print(f\"[{','.join(items)}]\")\n\nsolve()\n```", "id": "3317213"}, {"introduction": "Beyond computing individual entries, understanding the global structure of the impedance matrix is crucial for efficient storage and solution. A key property is symmetry ($Z=Z^T$), which is deeply connected to the physical principle of reciprocity and the specifics of the numerical discretization scheme. This exercise [@problem_id:3317234] challenges you to identify the precise conditions—involving material properties and testing strategies—that guarantee or break matrix symmetry, a skill essential for debugging and optimizing computational electromagnetic solvers.", "problem": "In frequency-domain computational electromagnetics, the impedance matrix $Z$ assembled by the Method of Moments (MoM) or the Finite Element Method (FEM) represents the discrete form of a continuous bilinear form arising from Maxwell’s equations. For linear time-harmonic fields with angular frequency $\\omega$ and $\\exp(i\\omega t)$ convention, Maxwell’s equations are\n$$\n\\nabla \\times \\mathbf{E} = - i \\omega \\mathbf{B}, \\quad \\nabla \\times \\mathbf{H} = \\mathbf{J} + i \\omega \\mathbf{D},\n$$\nwith constitutive relations in the most general linear form\n$$\n\\mathbf{D} = \\boldsymbol{\\varepsilon} \\mathbf{E} + \\boldsymbol{\\xi} \\mathbf{H}, \\quad \\mathbf{B} = \\boldsymbol{\\mu} \\mathbf{H} + \\boldsymbol{\\zeta} \\mathbf{E},\n$$\nwhere $\\boldsymbol{\\varepsilon}$ and $\\boldsymbol{\\mu}$ are the permittivity and permeability tensors, and $\\boldsymbol{\\xi}$, $\\boldsymbol{\\zeta}$ encode magnetoelectric coupling. Under suitable boundary conditions, the operator mapping sources to fields induces a bilinear form $a(\\cdot,\\cdot)$ such that, for a Galerkin discretization with identical basis and testing functions $\\{\\mathbf{b}_n\\}$,\n$$\nZ_{mn} = a(\\mathbf{b}_m, \\mathbf{b}_n).\n$$\nA classical reciprocity condition states that in linear, reciprocal media with $\\boldsymbol{\\xi} = - \\boldsymbol{\\zeta}^{\\mathsf{T}}$ and symmetric $\\boldsymbol{\\varepsilon} = \\boldsymbol{\\varepsilon}^{\\mathsf{T}}$, $\\boldsymbol{\\mu} = \\boldsymbol{\\mu}^{\\mathsf{T}}$, and with boundary conditions that do not introduce non-self-adjoint terms, the associated operator is self-adjoint with respect to an appropriate symmetric inner product, making $a(\\cdot,\\cdot)$ symmetric, and hence $Z_{mn} = Z_{nm}$ in Galerkin assembly.\n\nThe present task is to determine when the assembled $Z$ loses symmetry ($Z \\neq Z^{\\mathsf{T}}$). Consider the following options describing material properties, boundary conditions, and testing strategies. Select all options that lead to a non-symmetric impedance matrix $Z$, and justify your choice by reasoning from Maxwell’s equations and reciprocity. Additionally, provide a minimal counterexample that explicitly demonstrates loss of symmetry in $Z$.\n\nOptions:\nA. A gyrotropic non-reciprocal material with permeability tensor\n$$\n\\boldsymbol{\\mu} = \\mu_0 \\begin{bmatrix} 1 & i \\kappa & 0 \\\\ - i \\kappa & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}, \\quad \\kappa \\neq 0,\n$$\nunder exact radiation boundary conditions, assembled with a Galerkin scheme using identical curl-conforming basis and testing functions. \n\nB. A reciprocal isotropic but lossy homogeneous medium with $\\boldsymbol{\\varepsilon} = \\varepsilon_0 \\varepsilon_r \\mathbf{I}$, $\\boldsymbol{\\mu} = \\mu_0 \\mu_r \\mathbf{I}$, where $\\varepsilon_r \\in \\mathbb{C}$ has positive imaginary part (material loss), and exact radiation boundary conditions, assembled with Galerkin using identical basis and testing functions.\n\nC. A reciprocal isotropic homogeneous medium as in option B, but assembled by a Petrov–Galerkin collocation scheme that tests the Electric Field Integral Equation (EFIE) with Dirac delta distributions at collocation points while expanding the surface current with non-orthogonal Rao–Wilton–Glisson (RWG) basis functions.\n\nD. A reciprocal anisotropic medium with symmetric positive-definite tensors $\\boldsymbol{\\varepsilon} = \\boldsymbol{\\varepsilon}^{\\mathsf{T}}$, $\\boldsymbol{\\mu} = \\boldsymbol{\\mu}^{\\mathsf{T}}$, in a Perfect Electric Conductor (PEC) scattering problem with exact radiation condition, assembled by Galerkin using identical basis and testing functions that conform to the boundary traces.\n\nE. A reciprocal isotropic medium as in option B, truncated by a Perfectly Matched Layer (PML) implemented via complex coordinate stretching (anisotropic but diagonal effective tensors) and assembled by Galerkin using identical basis and testing functions.\n\nYour answer must include a clear identification of the correct options and a constructive counterexample (analytical or computational) where $Z_{mn} \\neq Z_{nm}$ can be explicitly exhibited, consistent with Maxwell’s equations and scientifically realistic modeling. Explain in detail which assumptions ensure symmetry and which mechanisms break it, grounding your reasoning in the operator and bilinear form structure rather than heuristic claims.", "solution": "The symmetry of the impedance matrix $Z$, defined by $Z = Z^{\\mathsf{T}}$, is a critical property in computational electromagnetics, as it allows for significant reductions in memory storage and computational cost for solving the resulting linear system. In the context of a Galerkin discretization scheme where identical basis and testing functions $\\{\\mathbf{b}_n\\}$ are used, the impedance matrix elements are given by $Z_{mn} = a(\\mathbf{b}_m, \\mathbf{b}_n)$, where $a(\\cdot, \\cdot)$ is the bilinear form associated with the governing partial differential equation. The symmetry of the matrix, $Z_{mn} = Z_{nm}$, is therefore a direct consequence of the symmetry of the bilinear form, $a(\\mathbf{b}_m, \\mathbf{b}_n) = a(\\mathbf{b}_n, \\mathbf{b}_m)$.\n\nThe symmetry of the bilinear form itself is guaranteed if the underlying continuous operator is self-adjoint with respect to the real-valued inner product $\\langle u, v \\rangle = \\int u v \\, dV$. For the time-harmonic Maxwell's equations and the associated curl-curl wave equation, the operator is self-adjoint under two conditions:\n1.  **Reciprocal Medium**: The material constitutive tensors must be symmetric. In the general case given, this means $\\boldsymbol{\\varepsilon} = \\boldsymbol{\\varepsilon}^{\\mathsf{T}}$, $\\boldsymbol{\\mu} = \\boldsymbol{\\mu}^{\\mathsf{T}}$, and $\\boldsymbol{\\xi} = -\\boldsymbol{\\zeta}^{\\mathsf{T}}$. For bianisotropic media where $\\boldsymbol{\\xi}=\\boldsymbol{\\zeta}=0$, this reduces to symmetric permittivity and permeability tensors.\n2.  **Self-Adjoint Boundary Conditions**: The boundary conditions imposed on the domain do not introduce non-symmetric terms into the bilinear form. Exact radiation conditions and perfect conductor boundary conditions fall into this category.\n\nTherefore, a non-symmetric impedance matrix $Z \\neq Z^{\\mathsf{T}}$ will arise if one or more of the following conditions are met:\n- The medium is non-reciprocal (violating condition 1).\n- The boundary conditions introduce non-self-adjointness (not a factor in the given options).\n- The numerical discretization is not of the Galerkin type, i.e., a Petrov-Galerkin scheme is used where the testing functions differ from the basis functions.\n\nWe will now analyze each option based on these principles.\n\n**Option A. A gyrotropic non-reciprocal material...**\n\nThe material is characterized by a permeability tensor\n$$\n\\boldsymbol{\\mu} = \\mu_0 \\begin{bmatrix} 1 & i \\kappa & 0 \\\\ - i \\kappa & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}, \\quad \\kappa \\neq 0.\n$$\nThe condition for a material to be reciprocal includes the requirement that its permeability tensor be symmetric, i.e., $\\boldsymbol{\\mu} = \\boldsymbol{\\mu}^{\\mathsf{T}}$. The transpose of the given tensor is\n$$\n\\boldsymbol{\\mu}^{\\mathsf{T}} = \\mu_0 \\begin{bmatrix} 1 & -i \\kappa & 0 \\\\ i \\kappa & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}.\n$$\nFor $\\kappa \\neq 0$, we have $\\boldsymbol{\\mu} \\neq \\boldsymbol{\\mu}^{\\mathsf{T}}$. The material is non-reciprocal. A bilinear form derived from an operator containing this non-symmetric tensor will not be symmetric. For instance, the term $a_1(\\mathbf{W}, \\mathbf{E}) = \\int (\\nabla \\times \\mathbf{W}) \\cdot (\\boldsymbol{\\mu}^{-1} \\nabla \\times \\mathbf{E}) \\, dV$ will not satisfy $a_1(\\mathbf{W}, \\mathbf{E}) = a_1(\\mathbf{E}, \\mathbf{W})$ because $\\boldsymbol{\\mu}^{-1} \\neq (\\boldsymbol{\\mu}^{-1})^{\\mathsf{T}}$. Since a Galerkin scheme is used, the non-symmetry of the bilinear form directly translates to a non-symmetric impedance matrix, $Z_{mn} = a(\\mathbf{b}_m, \\mathbf{b}_n) \\neq a(\\mathbf{b}_n, \\mathbf{b}_m) = Z_{nm}$. The physical manifestation of this non-reciprocity is the Faraday effect.\n\n**Verdict: Correct.**\n\n**Option B. A reciprocal isotropic but lossy homogeneous medium...**\n\nThe medium is described by scalar, albeit complex, permittivity and permeability: $\\boldsymbol{\\varepsilon} = \\varepsilon_0 \\varepsilon_r \\mathbf{I}$ and $\\boldsymbol{\\mu} = \\mu_0 \\mu_r \\mathbf{I}$. Here $\\mathbf{I}$ is the identity matrix. These tensors are diagonal and therefore symmetric: $\\boldsymbol{\\varepsilon} = \\boldsymbol{\\varepsilon}^{\\mathsf{T}}$ and $\\boldsymbol{\\mu} = \\boldsymbol{\\mu}^{\\mathsf{T}}$. The presence of material loss, indicated by $\\varepsilon_r \\in \\mathbb{C}$ with $\\mathrm{Im}(\\varepsilon_r) > 0$, makes the constitutive parameters complex, but it does not violate the tensor symmetry required for reciprocity. The bilinear form $a(\\mathbf{W}, \\mathbf{E}) = \\int [ (\\nabla \\times \\mathbf{W}) \\cdot (\\mu^{-1} \\nabla \\times \\mathbf{E}) - \\omega^2 \\varepsilon \\mathbf{W} \\cdot \\mathbf{E} ] dV$ remains symmetric because $\\mu$ and $\\varepsilon$ are scalars. Since a Galerkin scheme is employed, the resulting impedance matrix will be symmetric, $Z = Z^{\\mathsf{T}}$. The matrix will be complex-symmetric, but not Hermitian ($Z \\neq Z^{\\mathsf{H}}$) due to the losses. The question concerns symmetry, not Hermiticity.\n\n**Verdict: Incorrect.**\n\n**Option C. A reciprocal isotropic homogeneous medium... assembled by a Petrov–Galerkin collocation scheme...**\n\nThe medium is reciprocal, so the underlying continuous operator is self-adjoint. However, the numerical scheme is a Petrov-Galerkin method, not a true Galerkin method. Specifically, it is collocation. The basis functions $\\{\\mathbf{b}_n\\}$ are Rao–Wilton–Glisson (RWG) functions, which have spatial support. The testing functions $\\{\\mathbf{t}_m\\}$ are Dirac delta distributions, $\\mathbf{t}_m(\\mathbf{r}) = \\delta(\\mathbf{r} - \\mathbf{r}_m)$, centered at collocation points $\\mathbf{r}_m$.\nThe impedance matrix elements are given by $Z_{mn} = a(\\mathbf{t}_m, \\mathbf{b}_n)$. Even though the bilinear form $a(\\cdot, \\cdot)$ is symmetric, matrix symmetry requires $Z_{mn} = Z_{nm}$, which means $a(\\mathbf{t}_m, \\mathbf{b}_n) = a(\\mathbf{t}_n, \\mathbf{b}_m)$. As $\\mathbf{t}_m \\neq \\mathbf{b}_m$ and $\\mathbf{t}_n \\neq \\mathbf{b}_n$, there is no mathematical reason for this equality to hold. For an Electric Field Integral Equation operator $\\mathcal{L}$, $Z_{mn} = \\langle \\mathbf{t}_m, \\mathcal{L}(\\mathbf{b}_n) \\rangle = [\\mathcal{L}(\\mathbf{b}_n)](\\mathbf{r}_m)$, which is the field generated by basis function $\\mathbf{b}_n$ evaluated at point $\\mathbf{r}_m$. In contrast, $Z_{nm} = [\\mathcal{L}(\\mathbf{b}_m)](\\mathbf{r}_n)$ is the field from basis function $\\mathbf{b}_m$ at point $\\mathbf{r}_n$. Except for cases with very specific symmetries, these two values will not be equal. The use of different spaces for basis and testing functions breaks the symmetry of the final matrix.\n\n**Minimal Counterexample (for Option C):** Consider a 1D integral equation $\\int G(x, x') J(x') dx' = E(x)$, with a symmetric Green's function $G(x,x')=G(x',x)$. We expand the unknown current $J(x)$ using two basis functions, $J(x) = I_1 b_1(x) + I_2 b_2(x)$, where $b_1(x)$ is a triangular function centered at $x=-d$ and $b_2(x)$ is a triangular function centered at $x=d$. We use collocation with testing functions $t_1(x) = \\delta(x - c_1)$ and $t_2(x) = \\delta(x - c_2)$. The matrix elements are $Z_{12} = \\int G(c_1, x') b_2(x') dx'$ and $Z_{21} = \\int G(c_2, x') b_1(x') dx'$. Let's choose $c_1 = 0$ and $c_2 = d$. Then $Z_{12} = \\int G(0, x') b_2(x') dx'$ represents the field from source $b_2$ at the origin. $Z_{21} = \\int G(d, x') b_1(x') dx'$ represents the field from source $b_1$ at the location of source $b_2$. Due to the spatial decay of the Green's function and the different relative positions, $Z_{12} \\neq Z_{21}$ in general. For instance, $Z_{12}$ involves the interaction of $b_2$ with the field point $c_1=0$, which is at a distance $d$ from its center, while $Z_{21}$ involves interaction of $b_1$ with $c_2=d$, which is at a distance $2d$ from its center. These interactions will be different.\n\n**Verdict: Correct.**\n\n**Option D. A reciprocal anisotropic medium...**\n\nThe medium is anisotropic, but it is explicitly stated to be reciprocal, with symmetric positive-definite tensors $\\boldsymbol{\\varepsilon} = \\boldsymbol{\\varepsilon}^{\\mathsf{T}}$ and $\\boldsymbol{\\mu} = \\boldsymbol{\\mu}^{\\mathsf{T}}$. As established in the preamble, these conditions on the constitutive tensors are precisely what is required for the underlying operator to be self-adjoint. The discretization is a Galerkin scheme, using identical basis and testing functions. Therefore, all conditions for producing a symmetric bilinear form and, consequently, a symmetric impedance matrix $Z = Z^{\\mathsf{T}}$ are met. Anisotropy alone, without non-reciprocity (i.e., non-symmetric tensors), does not break the matrix symmetry in a Galerkin formulation.\n\n**Verdict: Incorrect.**\n\n**Option E. A reciprocal isotropic medium... truncated by a Perfectly Matched Layer (PML)...**\n\nA Perfectly Matched Layer (PML) is an artificial absorbing layer used to truncate computational domains. The implementation described is \"complex coordinate stretching\" leading to \"anisotropic but diagonal effective tensors\". This refers to the Uniaxial PML (UPML) formulation. In this formulation, the PML can be modeled as an anisotropic medium with effective permittivity and permeability tensors of the form $\\boldsymbol{\\varepsilon}_{\\text{PML}} = \\varepsilon_0 \\mathbf{S}$ and $\\boldsymbol{\\mu}_{\\text{PML}} = \\mu_0 \\mathbf{S}$, where $\\mathbf{S}$ is a diagonal matrix containing complex stretching factors, e.g., $\\mathbf{S} = \\text{diag}(s_x, s_y, s_z)$. A diagonal matrix is inherently symmetric, so $\\boldsymbol{\\varepsilon}_{\\text{PML}} = \\boldsymbol{\\varepsilon}_{\\text{PML}}^{\\mathsf{T}}$ and $\\boldsymbol{\\mu}_{\\text{PML}} = \\boldsymbol{\\mu}_{\\text{PML}}^{\\mathsf{T}}$. The effective medium describing the PML is therefore reciprocal. Because the problem specifies a Galerkin assembly with identical basis and testing functions, and the effective medium within the PML is reciprocal (possessing symmetric constitutive tensors), the resulting bilinear form is symmetric. Consequently, the impedance matrix $Z$ is symmetric ($Z = Z^{\\mathsf{T}}$). Although some practical FEM implementations involving PMLs can lead to non-symmetric matrices (e.g., those based on first-order systems or Berenger's original split-field approach), the specific formulation described in the option (unsplit-field with diagonal effective tensors) paired with a Galerkin method results in a symmetric system.\n\n**Verdict: Incorrect.**", "answer": "$$\\boxed{AC}$$", "id": "3317234"}, {"introduction": "As problem sizes grow, the $\\mathcal{O}(N^2)$ complexity of conventional dense matrix assembly becomes a prohibitive bottleneck. Advanced techniques like hierarchical matrix (H-matrix) compression offer a powerful alternative, trading a small, controllable amount of accuracy for dramatic gains in speed and memory. This practice [@problem_id:3317269] guides you through a practical, \"back-of-the-envelope\" analysis, allowing you to quantify the trade-offs between a dense approach and a compressed one for a realistic large-scale problem.", "problem": "Consider the Electric Field Integral Equation (EFIE) for scattering from a perfectly electrically conducting surface, discretized using Rao-Wilton-Glisson (RWG) basis functions to yield a linear system $Z x = b$. The impedance matrix $Z \\in \\mathbb{C}^{N \\times N}$ has entries $Z_{ij}$ defined by double surface integrals of a nonlocal kernel. In a conventional Method of Moments (MoM) assembly, all pairwise interactions are retained, so the resulting matrix is dense. Alternatively, a hierarchical matrix (H-matrix) representation constructs a cluster tree over degrees of freedom, partitions $Z$ into near-field (non-admissible) and far-field (admissible) blocks, and replaces each admissible block by a low-rank factorization computed by an algorithm such as Adaptive Cross Approximation (ACA). Assume the following regime and implementation details:\n- Low-frequency regime with bounded far-field block ranks: there exists a rank parameter $r$ that does not grow with $N$ for admissible blocks.\n- The admissibility criterion is based on geometric separation and ensures far-field blocks admit low-rank factorizations with ACA tolerance $\\varepsilon$ controlling the block approximation error in the spectral norm.\n- The near-field blocks are stored densely, but their total storage scales linearly with $N$ due to locality.\n- A balanced binary cluster tree is used, so the number of admissible block interactions scales like $N \\log N$ in three dimensions.\n- Each complex double-precision entry occupies $16$ bytes of memory.\n- For perturbation analysis of the linear system, if $\\tilde{Z}$ denotes the H-matrix approximation of $Z$ with $\\|Z - \\tilde{Z}\\|_2 \\le \\varepsilon \\|Z\\|_2$, then the relative solution error under exact right-hand side $b$ satisfies the standard bound for small perturbations:\n$$\n\\frac{\\|x - \\tilde{x}\\|_2}{\\|x\\|_2} \\le \\frac{\\kappa_2(Z) \\, \\varepsilon}{1 - \\kappa_2(Z) \\, \\varepsilon},\n$$\nprovided $\\kappa_2(Z) \\, \\varepsilon < 1$, where $\\kappa_2(Z)$ is the $2$-norm condition number.\n\nUnder these assumptions, compare the computational complexity and memory footprint of exact dense assembly versus compressed H-matrix assembly, and quantify the trade-off in solution accuracy. In particular, for a concrete configuration with $N = 20000$, rank $r = 40$, tolerance $\\varepsilon = 10^{-3}$, and condition number $\\kappa_2(Z) = 120$, choose the statement that most accurately reflects:\n- The asymptotic memory and assembly-time complexity for dense MoM and H-matrix assembly in this low-frequency regime.\n- A reasonable numerical estimate of the memory footprint for both approaches.\n- A justified bound on the relative solution error induced by the H-matrix approximation at the stated $\\varepsilon$ and $\\kappa_2(Z)$.\n\nOptions:\nA. Dense MoM assembly has memory $\\Theta(N^2)$ and time $\\Theta(N^2)$. In the low-frequency regime described, H-matrix assembly has memory $\\Theta(r \\, N \\log N)$ and time $\\Theta(r \\, N \\log N)$. For $N = 20000$ and complex doubles ($16$ bytes), dense storage is about $6.4$ GB, while H-matrix storage is on the order of $0.4$ GB when far-field blocks are stored as rank-$r$ factors and near fields are linear in $N$. With $\\varepsilon = 10^{-3}$ and $\\kappa_2(Z) = 120$, the relative solution error is bounded by approximately $0.12/(1 - 0.12) \\approx 0.136$, i.e., about $13.6\\%$.\n\nB. Dense MoM assembly has memory $\\Theta(N^2)$ and time $\\Theta(N^2)$. In the stated regime, H-matrix assembly achieves memory $\\Theta(N)$ and time $\\Theta(N)$ independent of the rank parameter $r$. For $N = 20000$, H-matrix storage is roughly $6.4$ GB, while dense storage is about $0.4$ GB due to strong sparsity. The relative solution error is bounded by $\\varepsilon$ and is independent of the condition number $\\kappa_2(Z)$.\n\nC. Dense MoM assembly has memory $\\Theta(N^3)$ and time $\\Theta(N^3)$ because each entry depends on triple integrals, while H-matrix assembly has memory $\\Theta(N \\log N)$ and time $\\Theta(N \\log N)$, both independent of $r$. For $N = 20000$, dense storage is far beyond $100$ GB, whereas H-matrix storage is under $0.1$ GB. The relative solution error satisfies $\\|x - \\tilde{x}\\|_2/\\|x\\|_2 \\le \\varepsilon/(1 - \\varepsilon)$ and does not depend on $\\kappa_2(Z)$.\n\nD. Dense MoM assembly has memory $\\Theta(N^2)$ and time $\\Theta(N^2)$, while H-matrix assembly has memory $\\Theta(r \\, N \\log N)$ but time $\\Theta(N^2)$ because ACA samples all entries. For $N = 20000$, dense storage is about $64$ GB and H-matrix storage is around $3.6$ GB. The relative solution error satisfies $\\|x - \\tilde{x}\\|_2/\\|x\\|_2 \\le \\kappa_2(Z) \\, \\varepsilon = 0.12$, i.e., $12\\%$.", "solution": "The problem statement is subjected to validation before proceeding to a solution.\n\n### Step 1: Extract Givens\n\n-   **System:** Linear system $Z x = b$ from the Electric Field Integral Equation (EFIE) for a perfectly electrically conducting (PEC) surface, discretized with Rao-Wilton-Glisson (RWG) basis functions.\n-   **Impedance Matrix ($Z$):** $Z \\in \\mathbb{C}^{N \\times N}$, with entries $Z_{ij}$ from double surface integrals of a nonlocal kernel.\n-   **Dense Method of Moments (MoM):** Dense matrix, all $N^2$ interactions are computed and stored.\n-   **Hierarchical Matrix (H-matrix) Approximation ($\\tilde{Z}$):**\n    -   Uses a balanced binary cluster tree.\n    -   Near-field blocks are stored densely, total storage scales linearly with $N$, i.e., $\\mathcal{O}(N)$.\n    -   Far-field (admissible) blocks are approximated by low-rank factorizations via Adaptive Cross Approximation (ACA).\n    -   The number of admissible block interactions scales as $N \\log N$.\n-   **Assumptions for H-matrix:**\n    -   Low-frequency regime with bounded rank $r$ that does not grow with $N$.\n    -   Block approximation error is controlled by tolerance $\\varepsilon$ in the spectral norm.\n-   **Data Type:** Complex double-precision entries occupy $16$ bytes.\n-   **Error Analysis:** The relative solution error is bounded by $\\frac{\\|x - \\tilde{x}\\|_2}{\\|x\\|_2} \\le \\frac{\\kappa_2(Z) \\, \\varepsilon}{1 - \\kappa_2(Z) \\, \\varepsilon}$, given the H-matrix satisfies $\\|Z - \\tilde{Z}\\|_2 \\le \\varepsilon \\|Z\\|_2$ and $\\kappa_2(Z) \\, \\varepsilon < 1$.\n-   **Specific Parameters:**\n    -   Number of unknowns: $N = 20000$.\n    -   Rank parameter: $r = 40$.\n    -   ACA tolerance: $\\varepsilon = 10^{-3}$.\n    -   Condition number: $\\kappa_2(Z) = 120$.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem statement is scrutinized for validity.\n-   **Scientifically Grounded:** The problem is firmly based on established principles of computational electromagnetics and numerical linear algebra. The EFIE, MoM, RWG basis functions, H-matrix compression, ACA, and the perturbation theory bound for linear systems are all standard, well-documented concepts in the field. The description is accurate and scientifically sound.\n-   **Well-Posed:** The problem provides a clear set of assumptions and numerical values and asks for a comparison of complexity, memory, and accuracy. This is a well-defined task that admits a unique, verifiable answer.\n-   **Objective:** The language is technical, precise, and free of subjectivity.\n\nThe problem does not exhibit any flaws. It is not scientifically unsound, non-formalizable, incomplete, contradictory, unrealistic, or ill-posed. All terms are standard, and the provided data are consistent and physically plausible for a large-scale electromagnetic scattering problem.\n\n### Step 3: Verdict and Action\n\nThe problem statement is **valid**. A full analysis is warranted.\n\n### Derivation and Analysis\n\nThe problem requires a three-part analysis: (1) asymptotic complexity, (2) numerical memory estimation, and (3) a quantitative error bound.\n\n**1. Asymptotic Complexity Analysis**\n\n-   **Dense MoM:**\n    -   **Memory:** The impedance matrix $Z$ is an $N \\times N$ dense matrix. Storing it requires space for all $N^2$ complex-valued entries. Therefore, the memory complexity is $\\Theta(N^2)$.\n    -   **Assembly Time:** A conventional MoM implementation computes each of the $N^2$ matrix entries, $Z_{ij}$, by evaluating a double (or four-fold) integral. Assuming the cost per entry is roughly constant, the total time to assemble the matrix is $\\Theta(N^2)$.\n\n-   **H-matrix:**\n    -   **Memory:** The H-matrix representation partitions the matrix.\n        -   The near-field part, by the problem's explicit assumption, requires storage that scales linearly with $N$, i.e., $\\mathcalO(N)$.\n        -   The far-field part consists of admissible blocks approximated by low-rank factorizations. For a rank-$r$ approximation of a block (as $U V^H$, with $U \\in \\mathbb{C}^{m \\times r}, V \\in \\mathbb{C}^{n \\times r}$), storage is proportional to $r(m+n)$. With a balanced cluster tree and a standard admissibility criterion, the total storage for all such blocks is known to scale nearly linearly. The problem states the number of block interactions is $\\mathcal{O}(N \\log N)$ and the rank $r$ is constant. The standard complexity result for storage is $\\Theta(r N \\log N)$.\n        -   The total H-matrix memory complexity is dominated by the dominant term, which is $\\Theta(r N \\log N)$.\n    -   **Assembly Time:** The time to construct the H-matrix involves computing the dense near-field entries ($\\mathcal{O}(N)$ time) and constructing the low-rank approximations for far-field blocks. Using ACA, the cost to approximate a block is proportional to the cost of storing its factors, typically scaling as $\\mathcal{O}(r(m+n))$ or $\\mathcal{O}(r^2(m+n))$. Summing over all far-field blocks, the total assembly time complexity is standardly cited as $\\mathcal{O}(r^k N \\log N)$ for $k \\in \\{1, 2\\}$. The expression $\\Theta(r N \\log N)$ is a common and acceptable representation of this near-linear complexity.\n\n**2. Numerical Memory Footprint Estimation**\n\nGiven $N = 20000$ and that each complex double entry occupies $16$ bytes. We use the convention $1 \\, \\text{GB} = 10^9 \\, \\text{bytes}$.\n\n-   **Dense MoM Memory:**\n    $$ \\text{Memory} = N^2 \\times (\\text{bytes per entry}) = (20000)^2 \\times 16 \\, \\text{bytes} $$\n    $$ \\text{Memory} = (4 \\times 10^8) \\times 16 \\, \\text{bytes} = 64 \\times 10^8 \\, \\text{bytes} = 6.4 \\times 10^9 \\, \\text{bytes} = 6.4 \\, \\text{GB} $$\n\n-   **H-matrix Memory:**\n    This requires estimating the constant factors in the complexity formula $\\mathcal{O}(r N \\log N)$. The total number of nonzeros to be stored is $C_{store} \\, r \\, N \\log_2 N$ for the far-field plus $C_{near} \\, N$ for the near-field.\n    Let's calculate the core term: $r N \\log_2 N = 40 \\times 20000 \\times \\log_2(20000) \\approx 40 \\times 20000 \\times 14.3 \\approx 1.144 \\times 10^7$ complex numbers.\n    Memory $\\approx 1.144 \\times 10^7 \\times 16 \\, \\text{bytes} \\approx 1.83 \\times 10^8 \\, \\text{bytes} = 0.183 \\, \\text{GB}$.\n    This is a lower-bound estimate, as it neglects near-field contributions and overhead, and the constant $C_{store}$ is typically greater than $1$. An estimate of $0.4 \\, \\text{GB}$ is of the same order of magnitude and entirely plausible, representing a factor of approximately $2$ difference, which is reasonable given the unknown implementation details.\n\n**3. Relative Solution Error Bound**\n\nThe problem provides the formula and parameters:\n$\\varepsilon = 10^{-3}$ and $\\kappa_2(Z) = 120$.\nFirst, we check the condition for the validity of the bound:\n$$ \\kappa_2(Z) \\, \\varepsilon = 120 \\times 10^{-3} = 0.12 $$\nSince $0.12 < 1$, the bound is applicable. We now compute the bound on the relative error:\n$$ \\frac{\\|x - \\tilde{x}\\|_2}{\\|x\\|_2} \\le \\frac{\\kappa_2(Z) \\, \\varepsilon}{1 - \\kappa_2(Z) \\, \\varepsilon} = \\frac{0.12}{1 - 0.12} = \\frac{0.12}{0.88} = \\frac{12}{88} = \\frac{3}{22} $$\n$$ \\frac{3}{22} \\approx 0.13636... $$\nAs a percentage, this is approximately $13.6\\%$.\n\n### Option-by-Option Analysis\n\n**A. Dense MoM assembly has memory $\\Theta(N^2)$ and time $\\Theta(N^2)$. In the low-frequency regime described, H-matrix assembly has memory $\\Theta(r \\, N \\log N)$ and time $\\Theta(r \\, N \\log N)$. For $N = 20000$ and complex doubles ($16$ bytes), dense storage is about $6.4$ GB, while H-matrix storage is on the order of $0.4$ GB when far-field blocks are stored as rank-$r$ factors and near fields are linear in $N$. With $\\varepsilon = 10^{-3}$ and $\\kappa_2(Z) = 120$, the relative solution error is bounded by approximately $0.12/(1 - 0.12) \\approx 0.136$, i.e., about $13.6\\%$.**\n-   Complexity Statements: **Correct**. Matches our derivation.\n-   Memory Estimates: Dense storage of $6.4 \\, \\text{GB}$ is **Correct**. H-matrix storage of $\\approx 0.4 \\, \\text{GB}$ is **Plausible** and of the correct order of magnitude.\n-   Error Bound: The calculation and result of $\\approx 13.6\\%$ are **Correct**.\n-   Verdict: **Correct**.\n\n**B. Dense MoM assembly has memory $\\Theta(N^2)$ and time $\\Theta(N^2)$. In the stated regime, H-matrix assembly achieves memory $\\Theta(N)$ and time $\\Theta(N)$ independent of the rank parameter $r$. For $N = 20000$, H-matrix storage is roughly $6.4$ GB, while dense storage is about $0.4$ GB due to strong sparsity. The relative solution error is bounded by $\\varepsilon$ and is independent of the condition number $\\kappa_2(Z)$.**\n-   H-matrix Complexity: **Incorrect**. The complexity is log-linear, $\\Theta(r N \\log N)$, not linear $\\Theta(N)$, and it demonstrably depends on the rank $r$.\n-   Memory Estimates: **Incorrect**. The values for dense and H-matrix storage are swapped. Furthermore, the dense MoM matrix is dense, not sparse.\n-   Error Bound: **Incorrect**. The bound explicitly depends on $\\kappa_2(Z)$.\n-   Verdict: **Incorrect**.\n\n**C. Dense MoM assembly has memory $\\Theta(N^3)$ and time $\\Theta(N^3)$ because each entry depends on triple integrals, while H-matrix assembly has memory $\\Theta(N \\log N)$ and time $\\Theta(N \\log N)$, both independent of $r$. For $N = 20000$, dense storage is far beyond $100$ GB, whereas H-matrix storage is under $0.1$ GB. The relative solution error satisfies $\\|x - \\tilde{x}\\|_2/\\|x\\|_2 \\le \\varepsilon/(1 - \\varepsilon)$ and does not depend on $\\kappa_2(Z)$.**\n-   Dense MoM Complexity: **Incorrect**. It is $\\Theta(N^2)$, not $\\Theta(N^3)$. The problem specifies double surface integrals.\n-   H-matrix Complexity: **Incorrect**. It depends on rank $r$.\n-   Memory Estimates: Dense storage is $6.4 \\, \\text{GB}$, not \"far beyond $100$ GB\".\n-   Error Bound: **Incorrect**. The bound formula is wrong and omits the condition number $\\kappa_2(Z)$.\n-   Verdict: **Incorrect**.\n\n**D. Dense MoM assembly has memory $\\Theta(N^2)$ and time $\\Theta(N^2)$, while H-matrix assembly has memory $\\Theta(r \\, N \\log N)$ but time $\\Theta(N^2)$ because ACA samples all entries. For $N = 20000$, dense storage is about $64$ GB and H-matrix storage is around $3.6$ GB. The relative solution error satisfies $\\|x - \\tilde{x}\\|_2/\\|x\\|_2 \\le \\kappa_2(Z) \\, \\varepsilon = 0.12$, i.e., $12\\%$.**\n-   H-matrix Time Complexity: **Incorrect**. The purpose of ACA is to avoid $\\mathcal{O}(N^2)$ complexity. ACA's cost is nearly linear, leading to a total assembly time of $\\mathcal{O}(r^k N \\log N)$.\n-   Memory Estimates: Dense storage is $6.4 \\, \\text{GB}$, not $64 \\, \\text{GB}$. This is a decimal-place error.\n-   Error Bound: **Incorrect**. This uses the first-order approximation $\\kappa_2(Z) \\varepsilon$ and ignores the denominator $1 - \\kappa_2(Z) \\varepsilon$ from the formula provided in the problem statement. The result of $12\\%$ is less accurate than the $13.6\\%$ from the full formula.\n-   Verdict: **Incorrect**.\n\nThe only statement that is consistent across all its claims—asymptotic complexity, numerical estimation, and error analysis—is option A.", "answer": "$$\\boxed{A}$$", "id": "3317269"}]}