{"hands_on_practices": [{"introduction": "The primary achievement of Calderón preconditioning is its remarkable effect on the spectrum of boundary integral operators, transforming ill-conditioned first-kind equations into well-conditioned second-kind systems. This exercise provides a two-part practice to connect theory with numerical observation. You will first derive the theoretical locations of the eigenvalue clusters from the fundamental Calderón identities, and then use a synthetic numerical model to see how these clusters manifest in a discrete setting, confirming the power of the preconditioning to regularize the operator spectrum [@problem_id:3291128].", "problem": "Consider time-harmonic Maxwell equations in free space with angular frequency $\\omega$ and wavenumber $k = \\omega \\sqrt{\\mu_0 \\epsilon_0}$, where $\\mu_0$ and $\\epsilon_0$ are the permeability and permittivity of free space. For a perfectly electrically conducting sphere of radius $a$ (in meters), the boundary integral equation approach introduces trace operators and boundary integral operators on the sphere $\\Gamma$. Using the standard tangential field formulation on a smooth closed surface, one constructs boundary integral operators that satisfy the Calderón calculus. In particular, the jump relations of boundary potentials across $\\Gamma$ lead to Calderón projectors, and the Calderón preconditioning yields a second-kind operator whose spectrum is a compact perturbation of a constant multiple of the identity. As a consequence, the eigenvalues of the Calderón-preconditioned operator cluster at specific constants that can be derived from the fundamental jump relations and projector identities.\n\nPart A (continuous model on a sphere): Starting from the time-harmonic Maxwell equations and the boundary trace jump relations for smooth $\\Gamma$, use the Calderón calculus to determine the constants at which the eigenvalues of the continuous Calderón-preconditioned operator cluster. You must derive these constants from first principles (no shortcuts, no direct use of target formulas). Your derivation should rely on the jump relations for tangent and normal components implied by the integral representations, and the idempotent property of the Calderón projectors constructed from the boundary integral operators. Report these constants as the expected cluster centers. Do not use any units for these constants; they are dimensionless.\n\nPart B (discrete comparison with Rao–Wilton–Glisson–Buffa–Christiansen pairing): In computational electromagnetics, the Rao–Wilton–Glisson (RWG) basis and Buffa–Christiansen (BC) basis form a stable primal–dual pairing for mixed boundary integral discretizations on triangulated surfaces. On the unit sphere (take $a = 1$ meter), discrete Calderón-preconditioned operators formed using RWG–BC pairings exhibit eigenvalue clusters near the continuous cluster centers, with deviations that decrease with increasing resolution and mode index. For a model discrete operator that captures this behavior on the sphere, assume its eigenvalues are grouped into two families (representing transverse electric and transverse magnetic tangential modes), each given by a perturbation around the continuous cluster center derived in Part A. For mode index $\\ell \\in \\{1,2,\\dots,L_{\\max}\\}$, mesh resolution parameter $N$ (a positive integer proportional to the number of triangles), and wavenumber $k$ (in $\\mathrm{m}^{-1}$), define a synthetic discrete eigenvalue model by\n$$\n\\lambda_{\\ell}^{(\\pm)}(k,N) = c_{\\pm} + \\delta_{\\ell}(k,N),\n$$\nwhere $c_{+}$ and $c_{-}$ are the continuous cluster centers obtained in Part A, and $\\delta_{\\ell}(k,N)$ is a small, smooth perturbation that decays with $\\ell$ and $N$. For the purposes of this numerical model problem, take\n$$\n\\delta_{\\ell}(k,N) = \\alpha(k,a)\\,\\big(\\ell + \\beta N\\big)^{-1},\n$$\nwith $a=1$ meter, $\\beta$ a positive dimensionless constant, and $\\alpha(k,a)$ a dimensionless scaling factor depending on $k a$ that is bounded by a small number and reflects smooth, non-resonant frequency dependence. You must compute $\\alpha(k,a)$ using spherical Bessel functions of the first kind in a way that is consistent with a smooth dependence on $k a$ and ensures $\\alpha(k,a)$ is small. For this problem, you must implement\n$$\n\\alpha(k,a) = \\min\\left(0.1,\\ \\left|\\mathrm{j}_1(k a)\\right|\\right),\n$$\nwhere $\\mathrm{j}_1$ is the spherical Bessel function of the first kind of order $1$, and take $\\beta = \\sqrt{2}$.\n\nFor each parameter set $(k,N,L_{\\max})$ specified in the test suite below, generate the discrete eigenvalues $\\{\\lambda_{\\ell}^{(+)}(k,N)\\}_{\\ell=1}^{L_{\\max}}$ and $\\{\\lambda_{\\ell}^{(-)}(k,N)\\}_{\\ell=1}^{L_{\\max}}$, compute the empirical cluster centers for the “$+$” and “$-$” families by simple averaging,\n$$\n\\bar{\\lambda}^{(+)}(k,N) = \\frac{1}{L_{\\max}}\\sum_{\\ell=1}^{L_{\\max}} \\lambda_{\\ell}^{(+)}(k,N),\\qquad\n\\bar{\\lambda}^{(-)}(k,N) = \\frac{1}{L_{\\max}}\\sum_{\\ell=1}^{L_{\\max}} \\lambda_{\\ell}^{(-)}(k,N),\n$$\nand compare them to the continuous cluster centers $c_{+}$ and $c_{-}$ obtained in Part A by computing the absolute differences\n$$\n\\Delta^{(+)}(k,N) = \\left|\\bar{\\lambda}^{(+)}(k,N) - c_{+}\\right|,\\qquad\n\\Delta^{(-)}(k,N) = \\left|\\bar{\\lambda}^{(-)}(k,N) - c_{-}\\right|.\n$$\nThese differences are dimensionless floats.\n\nTest suite:\n- Case 1: $(k, N, L_{\\max}) = (0.01\\ \\mathrm{m}^{-1},\\ 24,\\ 8)$.\n- Case 2: $(k, N, L_{\\max}) = (1.0\\ \\mathrm{m}^{-1},\\ 48,\\ 12)$.\n- Case 3: $(k, N, L_{\\max}) = (5.0\\ \\mathrm{m}^{-1},\\ 96,\\ 20)$.\n- Case 4 (edge case, very low modal truncation): $(k, N, L_{\\max}) = (0.5\\ \\mathrm{m}^{-1},\\ 8,\\ 2)$.\n- Case 5 (finer mesh, moderate frequency): $(k, N, L_{\\max}) = (2.5\\ \\mathrm{m}^{-1},\\ 160,\\ 30)$.\n\nYour program must:\n- Derive and use the continuous cluster centers $c_{+}$ and $c_{-}$ from Part A.\n- Implement the synthetic discrete eigenvalue model from Part B with the specified $\\alpha(k,a)$ and $\\beta$, using $a=1$ meter.\n- For each test case, compute and record the two floats $\\Delta^{(+)}(k,N)$ and $\\Delta^{(-)}(k,N)$.\n- Produce a single line of output containing all results for the five test cases, aggregated in order, as a comma-separated list enclosed in square brackets (for example, $[\\text{case1\\_plus},\\text{case1\\_minus},\\dots,\\text{case5\\_plus},\\text{case5\\_minus}]$). These floats are dimensionless and should be printed in standard decimal notation.\n\nAngles, if any appear in your derivation, must be in radians; however, this problem’s required outputs are dimensionless floats, so no unit conversion for angles is needed. All physical quantities are to be used with the units specified above, and the final outputs must be dimensionless.", "solution": "The user-provided problem is valid as it is scientifically grounded in the established theory of boundary integral equations for Maxwell's equations, is well-posed, objective, and self-contained. The problem requires a two-part solution: a theoretical derivation of eigenvalue cluster centers for a continuous operator, followed by a numerical implementation of a discrete model based on these centers.\n\n### Part A: Derivation of Continuous Cluster Centers\n\nThe constants at which the eigenvalues of the Calderón-preconditioned operator cluster can be derived from the fundamental properties of the boundary integral operators for the time-harmonic Maxwell equations. The derivation hinges on the projector property of the Calderón operators.\n\nLet $\\Gamma$ be a smooth, closed, and bounded surface separating $\\mathbb{R}^3$ into an interior domain $\\Omega_-$ and an exterior domain $\\Omega_+$. A radiating solution $(\\mathbf{E}, \\mathbf{H})$ to the time-harmonic Maxwell equations in $\\Omega_+$ can be represented by the Stratton-Chu formula in terms of the tangential traces of the electric and magnetic fields on $\\Gamma$. These traces are known as the Cauchy data. Let us define the tangential trace operators for a vector field $\\mathbf{F}$ as $\\gamma_t \\mathbf{F} = \\mathbf{n} \\times \\mathbf{F} \\times \\mathbf{n}$ and $\\gamma_D\\mathbf{F} = \\mathbf{n} \\times \\mathbf{F}$, where $\\mathbf{n}$ is the outward-pointing unit normal to $\\Gamma$. We consider the pair of tangential traces $(\\mathbf{n} \\times \\mathbf{E}, \\mathbf{n} \\times \\mathbf{H})$ on $\\Gamma$.\n\nThe fields $(\\mathbf{E}, \\mathbf{H})$ are generated by electric and magnetic surface current densities, $\\mathbf{J}$ and $\\mathbf{M}$ respectively, residing on $\\Gamma$. The jump relations for the tangential traces across $\\Gamma$ are:\n$$\n\\mathbf{n} \\times \\mathbf{E}^+ - \\mathbf{n} \\times \\mathbf{E}^- = -\\mathbf{M}\n$$\n$$\n\\mathbf{n} \\times \\mathbf{H}^+ - \\mathbf{n} \\times \\mathbf{H}^- = \\mathbf{J}\n$$\nwhere the superscripts $+$ and $-$ denote the limits taken from $\\Omega_+$ and $\\Omega_-$, respectively.\n\nThe boundary integral operators map the surface currents $(\\mathbf{J}, \\mathbf{M})$ to the average tangential traces on $\\Gamma$. Let's define the Cauchy data pair $\\mathbf{v} = (\\mathbf{M}, \\mathbf{J})^T$. The associated trace operator, known as the Calderón operator, $\\mathcal{C}$, maps this pair to the principal value (average) of the traces $(\\mathbf{n} \\times \\mathbf{E}, \\mathbf{n} \\times \\mathbf{H})$ on $\\Gamma$. In matrix form, this is expressed as:\n$$\n\\begin{pmatrix} \\mathbf{n} \\times \\mathbf{E}_{\\text{avg}} \\\\ \\mathbf{n} \\times \\mathbf{H}_{\\text{avg}} \\end{pmatrix} = \\mathcal{C} \\begin{pmatrix} \\mathbf{M} \\\\ \\mathbf{J} \\end{pmatrix} = \\begin{pmatrix} -K  S \\\\ T  K' \\end{pmatrix} \\begin{pmatrix} \\mathbf{M} \\\\ \\mathbf{J} \\end{pmatrix}\n$$\nHere, $S$ is the electric-to-electric single-layer operator, $K$ is the magnetic-to-electric double-layer operator, $T$ is the magnetic-to-magnetic hypersingular operator, and $K'$ is the electric-to-magnetic double-layer operator.\n\nUsing the average traces and the jump relations, the exterior ($+$) and interior ($-$) traces can be written as:\n$$\n\\begin{pmatrix} \\mathbf{n} \\times \\mathbf{E}^+ \\\\ \\mathbf{n} \\times \\mathbf{H}^+ \\end{pmatrix} = (\\mathcal{C} + \\frac{1}{2}I) \\begin{pmatrix} \\mathbf{M} \\\\ \\mathbf{J} \\end{pmatrix}\n$$\n$$\n\\begin{pmatrix} \\mathbf{n} \\times \\mathbf{E}^- \\\\ \\mathbf{n} \\times \\mathbf{H}^- \\end{pmatrix} = (\\mathcal{C} - \\frac{1}{2}I) \\begin{pmatrix} \\mathbf{M} \\\\ \\mathbf{J} \\end{pmatrix}\n$$\nwhere $I$ is the identity operator.\n\nThe operators $P^+ = \\mathcal{C} + \\frac{1}{2}I$ and $P^- = \\mathcal{C} - \\frac{1}{2}I$ are the Calderón projectors onto the spaces of Cauchy data corresponding to radiating fields in $\\Omega_+$ and regular fields in $\\Omega_-$, respectively. A fundamental property of these projectors is that they are idempotent, i.e., $(P^\\pm)^2 = P^\\pm$. Let's use this property for $P^+$:\n$$\n(P^+)^2 = P^+ \\implies (\\mathcal{C} + \\frac{1}{2}I)^2 = \\mathcal{C} + \\frac{1}{2}I\n$$\n$$\n\\mathcal{C}^2 + \\mathcal{C} + \\frac{1}{4}I^2 = \\mathcal{C} + \\frac{1}{2}I\n$$\nSubtracting $\\mathcal{C}$ from both sides and simplifying yields the celebrated Calderón identity:\n$$\n\\mathcal{C}^2 = \\frac{1}{4}I\n$$\nThis relation holds exactly for smooth surfaces, while for non-smooth surfaces it holds up to a compact perturbation, i.e., $\\mathcal{C}^2 = \\frac{1}{4}I + \\mathcal{K}$ where $\\mathcal{K}$ is a compact operator.\n\nThe eigenvalues of the operator $\\mathcal{C}$ are directly related to this identity. Let $\\lambda$ be an eigenvalue of $\\mathcal{C}$ with a corresponding eigenvector $\\mathbf{v} \\neq \\mathbf{0}$, such that $\\mathcal{C}\\mathbf{v} = \\lambda\\mathbf{v}$. Applying $\\mathcal{C}$ again gives:\n$$\n\\mathcal{C}^2\\mathbf{v} = \\mathcal{C}(\\lambda\\mathbf{v}) = \\lambda(\\mathcal{C}\\mathbf{v}) = \\lambda^2\\mathbf{v}\n$$\nSubstituting the Calderón identity, we get:\n$$\n\\frac{1}{4}I\\mathbf{v} = \\lambda^2\\mathbf{v} \\implies \\frac{1}{4}\\mathbf{v} = \\lambda^2\\mathbf{v}\n$$\nSince $\\mathbf{v}$ is a non-zero eigenvector, we must have:\n$$\n\\lambda^2 = \\frac{1}{4} \\implies \\lambda = \\pm\\frac{1}{2}\n$$\nFor a general smooth surface, the spectrum of $\\mathcal{C}$ is not purely discrete, but its essential spectrum is $\\{ -1/2, 1/2 \\}$. This means that the eigenvalues of any conforming discretization of $\\mathcal{C}$ will cluster at these two values. The problem refers to the \"Calderón-preconditioned operator\", which in this context means an operator whose spectral properties are governed by the Calderón operator $\\mathcal{C}$. The two families of eigenvalues, often associated with transverse electric (TE) and transverse magnetic (TM) modes, cluster around these two derived constants.\n\nThus, the constants at which the eigenvalues cluster are:\n$$\nc_+ = \\frac{1}{2} \\quad \\text{and} \\quad c_- = -\\frac{1}{2}\n$$\nThese are the dimensionless constants required by the problem.\n\n### Part B: Discrete Eigenvalue Model and Comparison\n\nFor Part B, we implement the synthetic discrete eigenvalue model using the derived continuous cluster centers $c_+ = 0.5$ and $c_- = -0.5$. The model for the discrete eigenvalues is given by:\n$$\n\\lambda_{\\ell}^{(\\pm)}(k,N) = c_{\\pm} + \\delta_{\\ell}(k,N)\n$$\nwhere the perturbation $\\delta_{\\ell}(k,N)$ is identical for both the '+' and '$-$' families of eigenvalues. The empirical cluster centers are computed by averaging:\n$$\n\\bar{\\lambda}^{(\\pm)}(k,N) = \\frac{1}{L_{\\max}}\\sum_{\\ell=1}^{L_{\\max}} \\lambda_{\\ell}^{(\\pm)}(k,N) = c_{\\pm} + \\frac{1}{L_{\\max}}\\sum_{\\ell=1}^{L_{\\max}} \\delta_{\\ell}(k,N)\n$$\nThe absolute differences $\\Delta^{(\\pm)}$ between the empirical and continuous centers are:\n$$\n\\Delta^{(\\pm)}(k,N) = \\left|\\bar{\\lambda}^{(\\pm)}(k,N) - c_{\\pm}\\right| = \\left|\\frac{1}{L_{\\max}}\\sum_{\\ell=1}^{L_{\\max}} \\delta_{\\ell}(k,N)\\right|\n$$\nThe perturbation is defined as $\\delta_{\\ell}(k,N) = \\alpha(k,a)\\big(\\ell + \\beta N\\big)^{-1}$. The scaling factor $\\alpha(k,a) = \\min\\left(0.1, \\left|\\mathrm{j}_1(k a)\\right|\\right)$ is non-negative, and all other terms in $\\delta_{\\ell}$ are positive. Therefore, $\\delta_{\\ell}(k,N) \\geq 0$, and the absolute value can be removed. The differences for the '+' and '$-$' families are identical:\n$$\n\\Delta^{(+)}(k,N) = \\Delta^{(-)}(k,N) = \\frac{1}{L_{\\max}}\\sum_{\\ell=1}^{L_{\\max}} \\frac{\\alpha(k,a)}{\\ell + \\beta N} = \\frac{\\alpha(k,a)}{L_{\\max}} \\sum_{\\ell=1}^{L_{\\max}} \\frac{1}{\\ell + \\beta N}\n$$\nwhere $a=1\\,\\mathrm{m}$, $\\beta=\\sqrt{2}$, and $\\mathrm{j}_1$ is the spherical Bessel function of the first kind of order $1$.\n\nThe program will iterate through the five test cases. For each case $(k, N, L_{\\max})$, it calculates $\\alpha(k,a)$ using the `scipy.special.spherical_jn` function, then computes the sum, and finally determines the value of $\\Delta = \\Delta^{(+)} = \\Delta^{(-)}$. This value is then recorded twice for each test case in the final output list.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import spherical_jn\n\ndef solve():\n    \"\"\"\n    Computes differences between empirical and continuous eigenvalue cluster centers\n    for a synthetic model of a Calderón-preconditioned operator in computational electromagnetics.\n    \"\"\"\n    # Part A: The derivation from the Calderón calculus shows the continuous cluster centers are\n    # c_+ = 0.5 and c_- = -0.5. These are not explicitly needed in the final calculation\n    # as the difference Delta_pm = | mean(c_pm + delta) - c_pm | = |mean(delta)|.\n    \n    # Part B: Parameters for the discrete model\n    a = 1.0  # radius of the sphere in meters\n    beta = np.sqrt(2)  # dimensionless constant\n\n    # Test suite of parameters (k, N, L_max)\n    test_cases = [\n        (0.01, 24, 8),   # Case 1\n        (1.0, 48, 12),  # Case 2\n        (5.0, 96, 20),  # Case 3\n        (0.5, 8, 2),    # Case 4\n        (2.5, 160, 30), # Case 5\n    ]\n\n    results = []\n    for k, N, L_max in test_cases:\n        # Calculate the dimensionless scaling factor alpha(k,a)\n        # ka is dimensionless (in radians)\n        ka = k * a\n        \n        # spherical_jn(1, 0) correctly returns 0, so no special check for ka=0 is needed.\n        abs_j1_ka = np.abs(spherical_jn(1, ka))\n        alpha = min(0.1, abs_j1_ka)\n\n        # Calculate the perturbation sum.\n        # ell is a dimensionless mode index.\n        ell_values = np.arange(1, L_max + 1)\n        # The term (ell + beta*N) is dimensionless.\n        perturbation_sum = np.sum(1.0 / (ell_values + beta * N))\n\n        # Calculate the average perturbation, which is the absolute difference Delta.\n        # The perturbation delta_l is independent of the +/- family, so Delta^(+) = Delta^(-).\n        # The result delta_avg is dimensionless.\n        delta_avg = (alpha / L_max) * perturbation_sum\n\n        # For each case, we report two identical floats: Delta^(+) and Delta^(-).\n        results.append(delta_avg)\n        results.append(delta_avg)\n\n    # Final print statement in the exact required format.\n    # The output format is a single line, comma-separated list of floats in standard decimal notation.\n    # Using f-string with 'f' format specifier ensures decimal notation, not scientific.\n    print(f\"[{','.join(f'{r:.12f}' for r in results)}]\")\n\nsolve()\n```", "id": "3291128"}, {"introduction": "Beyond clustering eigenvalues, a properly formulated Calderón preconditioning scheme can transform the operator into one with highly desirable algebraic properties. This practice guides you through constructing a discrete energy norm in which the preconditioned operator becomes symmetric positive definite. By numerically verifying this property, you will understand the deep connection between the operator's coercivity and the ability to employ efficient and robust solvers like the Conjugate Gradient (CG) method, which are otherwise unavailable for the original EFIE system [@problem_id:3291131].", "problem": "You are tasked with constructing, analyzing, and numerically verifying a discrete energy norm under which a Calderón-preconditioned Electric Field Integral Equation (EFIE) becomes symmetric positive definite, thus enabling Conjugate Gradient (CG) iteration. The scientific basis is rooted in time-harmonic Maxwell equations and boundary integral formulations. In computational electromagnetics, the EFIE is known to be of the first kind and poorly conditioned in standard Euclidean norms. Calderón preconditioning composes the EFIE with operators derived from the Calderón projector to obtain a second-kind, coercive operator. Your goal is to demonstrate, in a controlled discrete setting, that an appropriate energy norm renders the preconditioned operator self-adjoint and positive definite.\n\nFundamental base:\n- The EFIE arises from the time-harmonic Maxwell equations and the associated boundary integral representation of the scattered fields. The underlying operators on a closed, smooth boundary map surface current densities to tangential electric or magnetic fields and involve the single-layer and hypersingular operators.\n- Calderón identities state that compositions of the boundary integral operators yield projectors that remove the first-kind ill-posedness and lead to second-kind, coercive operators (identity plus compact perturbations).\n- Coercivity means that the operator has a strictly positive lower bound on the associated energy norm, which guarantees stability and enables conjugate gradient methods when symmetry holds.\n\nDiscrete surrogate model to be implemented:\n1. Consider a family of symmetric positive definite matrices of dimension $n$, denoted by $S \\in \\mathbb{C}^{n \\times n}$, which model the discrete single-layer operator and induce the energy inner product. Construct $S$ via a unitary discrete Fourier transform basis as\n$$\nS = U^\\ast \\Lambda U,\n$$\nwhere $U \\in \\mathbb{C}^{n \\times n}$ is unitary with entries $U_{jk} = \\frac{1}{\\sqrt{n}} \\exp\\left(\\mathrm{i} \\frac{2\\pi jk}{n}\\right)$ for indices $j,k \\in \\{0,1,\\dots,n-1\\}$, and $\\Lambda = \\mathrm{diag}(\\lambda_0,\\dots,\\lambda_{n-1})$ has entries\n$$\n\\lambda_k = \\frac{1}{(1 + |m_k|)^p},\n$$\nwith $p  0$ and $m_k \\in \\mathbb{Z}$ given by the standard discrete Fourier frequencies mapped to integer mode indices satisfying $m_k \\in \\{-\\lfloor n/2 \\rfloor, \\dots, \\lfloor n/2 \\rfloor\\}$ and $|m_k|$ the absolute mode number. This construction enforces that $S$ is a smoothing operator of order $-p$, akin to a discrete $H^{-1/2}$ energy inner product in electromagnetics.\n\n2. Construct a compact, Hermitian positive semidefinite perturbation $K \\in \\mathbb{C}^{n \\times n}$ that commutes with $S$ by diagonalizing it in the same Fourier basis,\n$$\nK = U^\\ast \\mathrm{diag}(\\kappa_0,\\dots,\\kappa_{n-1}) U,\n$$\nwhere $\\kappa_k \\ge 0$ is nonzero only for $r$ indices corresponding to the $r$ smallest $|m_k|$ values (including $m=0$), and zero otherwise. For simplicity, let $\\kappa_k \\in \\{0,\\alpha\\}$ with a scalar strength parameter $\\alpha \\ge 0$. This models the compact part of the Calderón-preconditioned EFIE operator in the energy space, preserving the commuting structure.\n\n3. Form a discrete EFIE surrogate operator $A = S + K$ and apply the Calderón-like preconditioner $T = S^{-1}$ to obtain the preconditioned operator\n$$\nP = T A = S^{-1} (S + K) = I + S^{-1} K.\n$$\n\n4. Define the discrete energy inner product induced by $S$ as\n$$\n\\langle x, y \\rangle_M = x^\\ast M y, \\quad \\text{with} \\quad M = S,\n$$\nand verify the following properties numerically:\n- Symmetry with respect to $\\langle \\cdot, \\cdot \\rangle_M$: the operator $P$ is self-adjoint in the $M$-inner product if $P^\\ast M = M P$. Numerically, evaluate the Frobenius norm residual\n$$\n\\| P^\\ast M - M P \\|_F,\n$$\nand report this as a real-valued float.\n- Positive definiteness (coercivity): evaluate the smallest eigenvalue of the Hermitian matrix\n$$\nH = S^{1/2} P S^{1/2},\n$$\nwhere $S^{1/2} = U^\\ast \\mathrm{diag}(\\sqrt{\\lambda_0},\\dots,\\sqrt{\\lambda_{n-1}}) U$. The operator $P$ is symmetric positive definite in the $M$-inner product if and only if $H$ is symmetric positive definite in the Euclidean sense. Numerically, report:\n    - A boolean indicating whether all eigenvalues of $H$ are strictly positive within a numerical tolerance.\n    - The smallest eigenvalue of $H$ (the coercivity constant), as a float.\n\nImplementation requirements:\n- Use the above constructions with complex-valued matrices but return real floats for the residual and coercivity by taking real parts of the computed quantities as appropriate.\n- No physical units are required; all quantities are dimensionless.\n- Angles used in exponentials are measured in radians.\n\nTest suite:\nImplement your program to run the following test cases, each specified by a quadruple $(n, p, r, \\alpha)$:\n- Case 1 (general happy path): $(n, p, r, \\alpha) = (32, 1.0, 3, 0.1)$\n- Case 2 (edge case, identity): $(n, p, r, \\alpha) = (32, 1.0, 0, 0.0)$\n- Case 3 (strong compact term): $(n, p, r, \\alpha) = (64, 1.5, 1, 5.0)$\n- Case 4 (weak smoothing, larger rank): $(n, p, r, \\alpha) = (16, 0.5, 8, 0.01)$\n- Case 5 (near machine-precision perturbation): $(n, p, r, \\alpha) = (8, 2.0, 4, 10^{-12})$\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case must yield a list with three entries: the symmetry residual float, the boolean SPD flag, and the coercivity float. For example, the output must look like\n$$\n[\\,[\\text{res}_1,\\text{spd}_1,\\text{coer}_1],\\,[\\text{res}_2,\\text{spd}_2,\\text{coer}_2],\\,\\dots\\,]\n$$\nMake sure your implementation is self-contained, uses only the allowed libraries, and does not read any input.", "solution": "The problem requires the numerical construction and validation of a discrete surrogate model for a Calderón-preconditioned Electric Field Integral Equation (EFIE). The primary goal is to demonstrate that with an appropriate energy norm, the preconditioned discrete operator becomes symmetric and positive definite, which are the necessary conditions for utilizing the Conjugate Gradient (CG) method.\n\nThe methodology proceeds in four main steps:\n1.  **Construction of Discrete Operators**: We model the continuous integral operators using dense matrices whose properties are defined in the discrete Fourier domain. This is a standard technique for analyzing translation-invariant operators, as it diagonalizes them, making their properties (like spectrum, commutativity) transparent.\n    -   The discrete single-layer operator, denoted by $S \\in \\mathbb{C}^{n \\times n}$, provides the energy inner product. It is constructed to be a symmetric positive definite (SPD) smoothing operator. Its definition, $S = U^\\ast \\Lambda U$, where $U$ is the unitary Discrete Fourier Transform (DFT) matrix and $\\Lambda$ is a diagonal matrix of eigenvalues $\\lambda_k  0$, ensures these properties. The eigenvalues $\\lambda_k = (1 + |m_k|)^{-p}$ are defined based on integer mode indices $m_k$, with $p0$, causing $\\lambda_k$ to decay for higher frequencies. This models the behavior of a continuous Sobolev space mapping like $H^{1/2} \\to H^{-1/2}$.\n    -   The compact perturbation, $K \\in \\mathbb{C}^{n \\times n}$, is constructed in the same Fourier basis: $K = U^\\ast \\mathrm{diag}(\\kappa_0,\\dots,\\kappa_{n-1}) U$. The eigenvalues $\\kappa_k$ are non-negative and non-zero only for a small number, $r$, of low-frequency modes. This models a compact operator. A critical consequence of constructing both $S$ and $K$ in the same basis is that they commute: $[S, K] = SK - KS = 0$.\n\n2.  **Preconditioning**: The discrete EFIE surrogate is $A = S + K$. This represents a first-kind integral equation operator. The Calderón-like preconditioner is $T = S^{-1}$. Applying this from the left yields the preconditioned operator $P = T A = S^{-1}(S + K) = I + S^{-1}K$. This is a discrete analogue of a second-kind Fredholm operator ($I$ plus a compact term $S^{-1}K$).\n\n3.  **Symmetry Verification**: We must verify that $P$ is self-adjoint (symmetric) with respect to the energy inner product induced by $M=S$, which is defined as $\\langle x, y \\rangle_S = x^\\ast S y$. The condition for self-adjointness is $\\langle Px, y \\rangle_S = \\langle x, Py \\rangle_S$ for all $x, y \\in \\mathbb{C}^n$. This translates to the matrix identity $P^\\ast S = S P$.\n    We can verify this analytically. Since $S$ and $K$ are Hermitian and commute, $S^{-1}$ and $K$ also commute.\n    -   Left Hand Side: $P^\\ast S = (I + S^{-1}K)^\\ast S = (I + (S^{-1}K)^\\ast)S = (I + K^\\ast (S^{-1})^\\ast)S = (I + K S^{-1})S = S+K$.\n    -   Right Hand Side: $S P = S(I + S^{-1}K) = S+K$.\n    Since LHS = RHS, the property holds. The numerical task is to compute the Frobenius norm of the residual, $\\| P^\\ast S - S P \\|_F$, which should be zero up to floating-point precision.\n\n4.  **Positive Definiteness Verification**: We must verify that $P$ is positive definite in the $S$-inner product, meaning $\\langle Px, x \\rangle_S  0$ for all non-zero $x$. This is equivalent to the coercivity of the operator. The problem directs us to analyze the Hermitian matrix $H = S^{1/2} P S^{1/2}$.\n    -   We can simplify this expression: $H = S^{1/2} (I + S^{-1}K) S^{1/2} = S^{1/2}I S^{1/2} + S^{1/2}S^{-1}K S^{1/2} = S + S^{-1/2}K S^{1/2}$.\n    -   Because $S$ and $K$ commute, any function of $S$ (like $S^{-1/2}$) also commutes with $K$. Thus, $S^{-1/2}K S^{1/2} = K S^{-1/2} S^{1/2} = K$.\n    -   This yields the significant simplification $H = S+K = A$.\n    -   The problem of finding the eigenvalues of $H$ reduces to finding the eigenvalues of $A=S+K$. Since both $S$ and $K$ are diagonal in the Fourier basis, their sum is also diagonal in that basis. The eigenvalues of $H=A$ are therefore simply $\\lambda_k + \\kappa_k$.\n    -   The positive definiteness of $P$ in the $S$-inner product is equivalent to the standard positive definiteness of $H$. The eigenvalues of $H$, $\\lambda_k + \\kappa_k$, are all strictly positive because $\\lambda_k  0$ and $\\kappa_k \\ge 0$. This confirms $H$ is SPD. The smallest eigenvalue of $H$, $\\min_k(\\lambda_k + \\kappa_k)$, is the quantity to be reported.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs and analyzes a discrete surrogate model for a Calderón-preconditioned\n    Electric Field Integral Equation (EFIE).\n    \"\"\"\n\n    # Test cases defined by (n, p, r, alpha)\n    # n: matrix dimension\n    # p: smoothing order for S\n    # r: rank of compact perturbation K\n    # alpha: strength of perturbation K\n    test_cases = [\n        (32, 1.0, 3, 0.1),\n        (32, 1.0, 0, 0.0),\n        (64, 1.5, 1, 5.0),\n        (16, 0.5, 8, 0.01),\n        (8, 2.0, 4, 1e-12),\n    ]\n\n    results = []\n    # A small tolerance for numerically checking strict positivity of eigenvalues\n    positivity_tolerance = 1e-15\n\n    for n, p, r, alpha in test_cases:\n        # Step 1: Define discrete Fourier modes and operator eigenvalues in the Fourier domain.\n        \n        # Standard integer mode indices corresponding to numpy's FFT order.\n        m_k = np.fft.fftfreq(n) * n\n        abs_m_k = np.abs(m_k)\n        \n        # Eigenvalues of the discrete single-layer operator S.\n        lambda_k = 1.0 / np.power(1.0 + abs_m_k, p)\n        \n        # Eigenvalues of the compact perturbation K.\n        kappa_k = np.zeros(n, dtype=float)\n        if r > 0:\n            # The perturbation is non-zero only for r modes with the smallest |m_k|.\n            pert_indices = np.argsort(abs_m_k)[:r]\n            kappa_k[pert_indices] = alpha\n\n        # Step 2: Construct dense matrices S and P.\n        \n        # Construct the unitary Discrete Fourier Transform (DFT) matrix U.\n        # The entry U_jk is (1/sqrt(n)) * exp(i*2*pi*j*k/n). This matrix corresponds\n        # to the inverse DFT operation in numpy's convention.\n        j_indices, k_indices = np.meshgrid(np.arange(n), np.arange(n), sparse=True, indexing='ij')\n        U = (1.0 / np.sqrt(n)) * np.exp(2j * np.pi * j_indices * k_indices / n)\n\n        # Construct S = U^* Lambda U, where Lambda is diag(lambda_k).\n        # U is unitary, so U^* = U^-1. S is diagonal in the basis formed by columns of U^*.\n        S = U.conj().T @ np.diag(lambda_k) @ U\n        \n        # Construct P = I + S^-1 K. P is diagonal in the same basis with eigenvalues 1 + kappa_k/lambda_k.\n        p_eigvals = 1.0 + kappa_k / lambda_k\n        P = U.conj().T @ np.diag(p_eigvals) @ U\n        \n        # Step 3: Verify the symmetry property.\n        # Check if P is self-adjoint in the S-inner product by computing the residual\n        # norm || P^* S - S P ||_F. Analytically, this is zero because S and P commute.\n        # Numerically, it will be on the order of machine precision.\n        residual_matrix = P.conj().T @ S - S @ P\n        symmetry_residual = np.linalg.norm(residual_matrix, 'fro')\n\n        # Step 4: Verify the positive definiteness property.\n        # This involves analyzing the matrix H = S^(1/2) P S^(1/2). As derived, this simplifies\n        # to H = S + K because S and K commute. The eigenvalues of H are therefore lambda_k + kappa_k.\n        H_eigenvalues = lambda_k + kappa_k\n        \n        # The smallest eigenvalue of H is the quantity to be reported.\n        min_H_eigenvalue = np.min(H_eigenvalues)\n        \n        # P is positive definite in the S-inner product if and only if H is positive definite\n        # in the standard Euclidean sense. Since lambda_k > 0 and kappa_k >= 0,\n        # all eigenvalues of H are strictly positive.\n        is_spd = bool(min_H_eigenvalue > positivity_tolerance)\n        \n        results.append([float(symmetry_residual), is_spd, float(min_H_eigenvalue)])\n\n    # Format the final output string exactly as specified in the problem statement.\n    # The output is a list of lists, represented as a single-line string.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3291131"}, {"introduction": "The decision to use a preconditioner is ultimately a practical one, involving a trade-off between the cost per iteration and the total number of iterations required for convergence. This exercise formalizes this trade-off by analyzing the computational complexity of solving the EFIE with and without a matrix-free Calderón preconditioner. By deriving the asymptotic 'break-even' point, you will develop a quantitative understanding of when the overhead of the preconditioner is justified by the savings in iteration count, a crucial skill for designing efficient large-scale solvers [@problem_id:3291149].", "problem": "You are discretizing the Electric Field Integral Equation (EFIE) for a perfectly conducting scatterer using Rao–Wilton–Glisson (RWG) basis functions, leading to a boundary integral equation of size $N$. The resulting linear system is solved iteratively using the Generalized Minimal Residual (GMRES) method with restart parameter $m$. The system operator is applied in a matrix-free fashion using a Fast Multipole Method (FMM)-type acceleration.\n\nAdopt the following modeling assumptions, justified by standard practice in computational electromagnetics:\n- A single matrix-vector product with the EFIE operator using Fast Multipole Method (FMM) acceleration has leading-order complexity $a\\,N \\log N$ operations, where $a0$ is an implementation-dependent constant capturing kernel evaluation, translation, and near-field costs.\n- One iteration of restarted GMRES with restart $m$ uses modified Gram–Schmidt orthogonalization against $m$ basis vectors, incurring $4\\,m\\,N$ multiply-add operations at leading order for inner products and vector updates.\n- A matrix-free Calderón multiplicative preconditioner is applied on the right, formed by operator compositions that require $p$ additional FMM-accelerated operator applications per iteration (with the same asymptotic cost constant $a$), where $p \\in \\mathbb{N}$ is fixed and independent of $N$.\n- The preconditioner reduces the number of GMRES iterations required to reach a fixed tolerance by an $N$-independent factor $\\eta \\in (0,1)$ compared to the unpreconditioned case, in the asymptotic regime of large $N$.\n- The auxiliary memory used by the FMM scales linearly with $N$ and is reused by both the system operator and the preconditioner. The matrix-free preconditioner requires a constant number of additional work vectors of length $N$.\n\nTasks:\n1) Starting from the definitions of GMRES and modified Gram–Schmidt, and the stated asymptotic costs of FMM operator applications, derive the leading-order computational complexity per GMRES iteration for:\n   - the unpreconditioned solver,\n   - the right-preconditioned solver with a matrix-free Calderón preconditioner.\n\n2) Derive the leading-order asymptotic memory footprint for both solvers in terms of $N$ and $m$, explicitly identifying the dominant terms associated with the Krylov subspace storage and any additional work vectors required by the preconditioner.\n\n3) Using the per-iteration costs and the iteration reduction factor $\\eta$, define the asymptotic break-even problem size $N_{\\star}$ as the mesh size at which the total leading-order computational cost to reach the fixed tolerance is the same with and without the preconditioner. Solve for $N_{\\star}$ as a closed-form analytic expression in terms of $a$, $m$, $p$, and $\\eta$. Your final answer should be this expression for $N_{\\star}$. Do not include units. If logarithms appear, use the natural logarithm, and express $N_{\\star}$ as an explicit function (not implicitly via an equation).", "solution": "The problem asks for an analysis of the computational cost and memory footprint of an unpreconditioned and a preconditioned iterative solver for the Electric Field Integral Equation (EFIE), culminating in the derivation of the break-even problem size $N_{\\star}$. The solution is constructed by following the modeling assumptions provided.\n\nLet $N$ be the number of degrees of freedom (proportional to the number of RWG basis functions). Let $m$ be the restart parameter for GMRES. The constant $a  0$ characterizes the cost of the Fast Multipole Method (FMM) application, $p \\in \\mathbb{N}$ is the number of auxiliary operator applications for the preconditioner, and $\\eta \\in (0,1)$ is the iteration reduction factor.\n\n**1) Per-Iteration Computational Complexity**\n\nThe computational complexity per GMRES iteration is the sum of the cost of one matrix-vector product (or its preconditioned equivalent) and the cost of the orthogonalization procedure.\n\n**Unpreconditioned Solver:**\nA single iteration of the unpreconditioned GMRES solver for the system $A\\mathbf{x} = \\mathbf{b}$ involves:\n- One matrix-vector product, $\\mathbf{v} = A\\mathbf{u}$, accelerated by the FMM. The leading-order cost for this operation is given as $C_{FMM} = a N \\ln N$.\n- Orthogonalization of the new vector against the $m$ vectors in the Krylov basis using modified Gram-Schmidt, and subsequent vector updates. The leading-order cost is given as $C_{MGS} = 4 m N$.\n\nThe total leading-order computational complexity per iteration, $C_{\\text{iter,unprec}}$, is the sum of these costs:\n$$C_{\\text{iter,unprec}} = a N \\ln N + 4 m N$$\n\n**Right-Preconditioned Solver:**\nThe solver addresses the right-preconditioned system $(AP^{-1})\\mathbf{y} = \\mathbf{b}$, where $\\mathbf{x} = P^{-1}\\mathbf{y}$. A single iteration of GMRES applied to this system requires:\n- One application of the composite operator $AP^{-1}$ to a vector $\\mathbf{u}$. This is performed in two steps:\n    1.  Application of the inverse preconditioner: $\\mathbf{v} = P^{-1}\\mathbf{u}$. The cost of this step is given as $p$ additional FMM-accelerated operator applications. Thus, the cost is $C_{\\text{prec\\_app}} = p \\cdot (a N \\ln N) = p a N \\ln N$.\n    2.  Application of the system operator: $\\mathbf{w} = A\\mathbf{v}$. The cost is that of a single standard FMM-accelerated application, $C_{FMM} = a N \\ln N$.\nThe total cost for the effective matrix-vector product is the sum of these two, which is $(p a N \\ln N) + (a N \\ln N) = (p+1)a N \\ln N$.\n- The orthogonalization cost is identical to the unpreconditioned case, as it depends only on the restart parameter $m$ and problem size $N$. The cost is $C_{MGS} = 4 m N$.\n\nThe total leading-order computational complexity per iteration for the preconditioned solver, $C_{\\text{iter,prec}}$, is:\n$$C_{\\text{iter,prec}} = (p+1)a N \\ln N + 4 m N$$\n\n**2) Asymptotic Memory Footprint**\n\nThe memory footprint is determined by the storage required for the Krylov subspace basis vectors, FMM data structures, and any other work vectors. A vector of size $N$ is assumed to occupy $N$ units of storage.\n\n**Unpreconditioned Solver:**\n- Restarted GMRES(m) must store the orthonormal basis of the Krylov subspace. At any point during the $m$ iterations of a cycle, up to $m+1$ vectors are held in memory (the $m$ basis vectors and the new vector being generated and orthogonalized). The storage for these vectors is $(m+1)N$.\n- The FMM requires auxiliary data structures whose memory usage is stated to scale linearly with $N$. Let this be $M_{FMM} = c_1 N$ for some constant $c_1$.\n- Additional vectors for the right-hand side, solution, and temporary results require $c_2 N$ storage, where $c_2$ is a small constant.\nThe total memory footprint, $M_{\\text{unprec}}$, is the sum of these contributions. The dominant terms in $N$ and $m$ are:\n$$M_{\\text{unprec}}(N, m) = (m+1)N + c_{\\text{aux}}N = (m+1+c_{\\text{aux}})N$$\nwhere $c_{\\text{aux}}$ consolidates all linear-in-$N$ storage costs not related to the Krylov basis size. The term explicitly associated with the Krylov subspace is $(m+1)N$.\n\n**Right-Preconditioned Solver:**\n- The GMRES storage requirement remains $(m+1)N$ for the Krylov basis.\n- The FMM memory is reused by the preconditioner application.\n- The problem states that the preconditioner requires a constant number, let's call it $c_p$, of additional work vectors of length $N$. This adds $c_p N$ to the memory footprint.\nThe total memory footprint for the preconditioned solver, $M_{\\text{prec}}$, is:\n$$M_{\\text{prec}}(N, m) = (m+1)N + c_p N + c_{\\text{aux}}N = (m+1+c_p+c_{\\text{aux}})N$$\nThe storage is increased by $c_p N$ compared to the unpreconditioned solver.\n\n**3) Break-Even Problem Size $N_{\\star}$**\n\nThe break-even problem size $N_{\\star}$ is the size $N$ at which the total computational cost to reach a fixed tolerance is equal for both solvers.\n\nLet $K_{\\text{unprec}}$ be the number of iterations required for the unpreconditioned solver. The total cost is $T_{\\text{unprec}} = K_{\\text{unprec}} \\cdot C_{\\text{iter,unprec}}$.\n$$T_{\\text{unprec}} = K_{\\text{unprec}} (a N \\ln N + 4 m N)$$\n\nFor the preconditioned solver, the number of iterations is reduced to $K_{\\text{prec}} = \\eta K_{\\text{unprec}}$. The total cost is $T_{\\text{prec}} = K_{\\text{prec}} \\cdot C_{\\text{iter,prec}}$.\n$$T_{\\text{prec}} = (\\eta K_{\\text{unprec}}) ((p+1)a N \\ln N + 4 m N)$$\n\nThe break-even point $N_{\\star}$ is found by setting $T_{\\text{unprec}} = T_{\\text{prec}}$ at $N=N_{\\star}$.\n$$K_{\\text{unprec}} (a N_{\\star} \\ln N_{\\star} + 4 m N_{\\star}) = \\eta K_{\\text{unprec}} ((p+1)a N_{\\star} \\ln N_{\\star} + 4 m N_{\\star})$$\n\nSince $K_{\\text{unprec}}  0$ and we seek a solution for $N_{\\star}  0$, we can divide both sides by $K_{\\text{unprec}}N_{\\star}$:\n$$a \\ln N_{\\star} + 4 m = \\eta ((p+1)a \\ln N_{\\star} + 4 m)$$\n$$a \\ln N_{\\star} + 4 m = \\eta(p+1)a \\ln N_{\\star} + 4 m \\eta$$\n\nWe now solve for $\\ln N_{\\star}$ by rearranging the terms:\n$$4 m - 4 m \\eta = \\eta(p+1)a \\ln N_{\\star} - a \\ln N_{\\star}$$\n$$4 m (1 - \\eta) = a \\ln N_{\\star} (\\eta(p+1) - 1)$$\n\nSolving for $\\ln N_{\\star}$:\n$$\\ln N_{\\star} = \\frac{4 m (1 - \\eta)}{a (\\eta(p+1) - 1)}$$\nFor $N_{\\star}$ to be a meaningful break-even point greater than $1$, we must have $\\ln N_{\\star}  0$. Since $a0$, $m0$, and $1-\\eta0$, the numerator is positive. Thus, the denominator must also be positive:\n$$\\eta(p+1) - 1  0 \\implies \\eta(p+1)  1$$\nThis condition implies that the asymptotic cost per iteration for the preconditioned solver is higher, allowing for a crossover from the regime where the MGS cost dominates (and the preconditioner is effective due to $\\eta  1$) to the regime where the FMM cost dominates (and the preconditioner is less effective due to the factor $\\eta(p+1)1$).\n\nTo find $N_{\\star}$, we exponentiate the expression for $\\ln N_{\\star}$:\n$$N_{\\star} = \\exp\\left(\\frac{4 m (1 - \\eta)}{a (\\eta(p+1) - 1)}\\right)$$\nThis is the closed-form analytic expression for the break-even problem size.", "answer": "$$\\boxed{\\exp\\left(\\frac{4m(1-\\eta)}{a(\\eta(p+1) - 1)}\\right)}$$", "id": "3291149"}]}