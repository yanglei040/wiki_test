{"hands_on_practices": [{"introduction": "The multipole-to-local (M2L) operator is the computational engine at the heart of the Fast Multipole Method, yet a naive implementation is plagued by numerical instability for high expansion orders. This exercise delves into the root cause of this instability—the superexponential growth and decay of the underlying spherical basis functions—and guides you to the elegant solution of diagonal scaling. By analyzing how to renormalize the operator to preserve its structure and bound its norm, you will gain a deep appreciation for the numerical analysis required to build a robust and accurate FMM code [@problem_id:3357116].", "problem": "In the Fast Multipole Method (FMM) for time-harmonic electromagnetic scattering modeled via the scalar Helmholtz kernel in spherical-wave expansions, a common implementation for the multipole-to-local (M2L) interaction between a source box and a target box uses a rotation-translation-rotation composition: rotate the source multipole coefficients so that the source-to-target separation aligns with the $z$-axis, perform an axial translation, then rotate into the target frame. Let the wavenumber be $k$, the source and target box radii be $a$ and $b$, the center-to-center separation be $R$, and the truncation order be $p$. Assume a fixed separation ratio $\\rho=\\max(a,b)/R$ with $\\rho1$. The multipole and local bases are the spherical-harmonic expansions of degrees $n\\in\\{0,1,\\dots,p\\}$ and orders $m\\in\\{-n,\\dots,n\\}$.\n\nAs foundational facts, use the following well-tested properties:\n\n- The orthonormalized spherical harmonics $Y_n^m(\\theta,\\phi)$ form a unitary representation of the rotation group, so that when expansions are expressed in this basis (including a consistent phase convention), the rotation operator has unit $2$-norm and is unitary.\n- The spherical Bessel function $j_n(x)$ and the spherical Hankel function of the first kind $h_n^{(1)}(x)$ exhibit large-order, fixed-argument asymptotics of the form $j_n(x)\\sim x^n/(2n+1)!!$ and $h_n^{(1)}(x)\\sim -\\mathrm{i}(2n-1)!!/x^{n+1}$, which govern the magnitudes of multipole and local expansions at small arguments and large degrees.\n- The axial M2L translation couples degrees and orders according to the spherical addition theorem, with coefficients involving $h_\\ell^{(1)}(kR)$ and angular coupling factors, so that the dominant $n$-dependence in magnitudes follows from the $j_n$ and $h_n^{(1)}$ factors and the geometry via $a$, $b$, and $R$.\n\nConsider the numerical conditioning, as $p\\to\\infty$ with fixed $\\rho1$, of the rotation-translation-rotation block that maps source multipole coefficients to target local coefficients. Which strategy below yields a composition whose $2$-norm and condition number remain bounded with respect to $p$ for fixed $\\rho1$, by balancing the growth/decay due to spherical Bessel and Hankel functions and by preserving the unitary character of rotations? Select the best answer and justify it from first principles based on the above foundational facts (do not assume any unstated specialized formulas).\n\nA. Work in an orthonormal spherical harmonic basis and define degree-dependent diagonal rescalings of coefficients that absorb the factorial and power-law asymptotics: scale the multipole coefficients by $\\alpha_n=(2n+1)!!/(ka)^n$ and a phase $\\mathrm{i}^n$, and scale the local coefficients by $\\beta_n=(kb)^{n+1}/(2n-1)!!$ and a phase $\\mathrm{i}^{-(n+1)}$. Use these scaled coefficients consistently in aggregation, translation, and disaggregation. This makes rotations unitary and the axial translation uniformly bounded in $p$ for fixed $\\rho1$.\n\nB. Use real, unnormalized spherical harmonics and no coefficient scaling, but increase $p$ gradually; because the addition theorem is exact for all $p$, the composition will be well-conditioned for large $p$ when $\\rho1$.\n\nC. Pre- and post-multiply the axial translation by a single, $p$-independent scalar equal to the mean magnitude of $h_p^{(1)}(kR)$ over $R$ in a prescribed range, keeping the basis and coefficients unscaled; this mitigates the dominant growth and suffices to stabilize the composition for all $p$.\n\nD. Keep orthonormal spherical harmonics for rotation but scale all degrees by the same factors $\\gamma=(ka)^{-p}$ for all multipoles and $\\delta=(kb)^{p}$ for all locals; this equalizes magnitudes across degrees and yields $p$-independent conditioning.\n\nE. Use orthonormal spherical harmonics and include the $\\mathrm{i}^n$ phase in the basis so that rotations are precisely unitary, but do not scale multipole or local coefficients by degree; unitarity of rotations alone guarantees $p$-independent conditioning for fixed $\\rho1$.", "solution": "The core challenge is the numerical conditioning of the multipole-to-local (M2L) translation operator as the expansion order $p$ increases. The overall M2L operator is a composition $\\mathcal{T} = \\mathcal{R}_2 \\mathcal{T}_{axial} \\mathcal{R}_1$. The conditioning of this operator is determined by the axial translation part, $\\mathcal{T}_{axial}$, as the rotations $\\mathcal{R}_1, \\mathcal{R}_2$ are unitary when using an orthonormal spherical harmonic basis. The unscaled axial translation operator is severely ill-conditioned for large $p$. This instability arises from the dramatic difference in scaling between the multipole coefficients, which decay rapidly with degree $n$ (proportional to the spherical Bessel function $j_n(ka) \\sim (ka)^n / (2n+1)!!$), and the elements of the translation matrix, which grow rapidly with degree (proportional to the spherical Hankel function $h_l^{(1)}(kR) \\sim (2l-1)!! / (kR)^{l+1}$). The product of these terms in a finite-precision calculation leads to a massive loss of accuracy.\n\nStrategy A provides the correct solution by addressing both issues:\n1.  **Unitary Rotations:** It correctly specifies the use of an orthonormal spherical harmonic basis, which makes the rotation operators unitary (2-norm and condition number of 1), thus isolating the conditioning problem to the translation step.\n2.  **Diagonal Scaling:** It introduces degree-dependent scaling factors for both the multipole and local coefficients. The scaling for multipole coefficients, $\\alpha_n=(2n+1)!!/(ka)^n$, is designed to precisely counteract the asymptotic decay of $j_n(ka)$, making the scaled coefficients of order one. Similarly, the scaling for local coefficients and the overall transformation of the operator counteracts the growth from $h_n^{(1)}(kR)$. The resulting scaled axial translation operator has matrix elements that decay for large degrees under the standard FMM separation condition ($R > 2a$ where $a$ is the box radius), ensuring its norm and condition number remain bounded as $p \\to \\infty$. The phase factors are also crucial for ensuring the scaled operator has desirable properties (e.g., being real and symmetric).\n\nThe other options are incorrect:\n*   **B:** Fails because it does not use any scaling, which is the primary cause of the instability. The mathematical exactness of the addition theorem does not guarantee numerical stability.\n*   **C:** A single, degree-independent scalar scaling cannot normalize the operator, as the growth/decay is strongly degree-dependent. It would also not change the condition number.\n*   **D:** A single scaling factor dependent on the maximum order $p$ is insufficient. Degree-dependent scaling is required to normalize coefficients across all orders $n \\in \\{0, \\dots, p\\}$.\n*   **E:** Fails because unitary rotations are necessary but not sufficient. The ill-conditioning originates in the axial translation operator, which remains unscaled and unstable in this strategy.", "answer": "$$\\boxed{A}$$", "id": "3357116"}, {"introduction": "Before assembling the full FMM hierarchy, it is essential to ensure the correctness of the fundamental building blocks: the point-to-multipole (P2M) aggregation and local-to-point (L2P) disaggregation operators. This hands-on coding practice tasks you with creating a powerful self-consistency test based on physical reciprocity and basis orthogonality. By transforming a known local field to point values on a surface and then aggregating those values back into a multipole expansion, you will verify whether a power-like quantity is conserved, providing a crucial unit test for any FMM implementation [@problem_id:3357105]. This procedure also highlights the critical role of sampling theory in ensuring the accuracy of the discrete operators.", "problem": "Consider a two-dimensional time-harmonic field governed by the scalar Helmholtz equation in a homogeneous medium, expressed as $\\nabla^2 u + k^2 u = 0$, where $u$ is a complex-valued field and $k$ is the wavenumber. In the Fast Multipole Method (FMM), two fundamental operators are used: the Local-to-Point (L2P) operator, which evaluates a local expansion at specified target points, and the Point-to-Multipole (P2M) operator, which aggregates point data into a multipole expansion about a chosen center. You will construct a reciprocity-based self-test on a closed circular surface that assesses whether the composition of L2P followed by P2M approximately conserves a surface-averaged power-like quadratic quantity to within a specified tolerance $\\epsilon$.\n\nAssume a circular surface of radius $R_s$ centered at the origin. Work strictly in polar coordinates $(r,\\theta)$ with $\\theta$ measured in radians. Use separation of variables for the scalar Helmholtz equation and the standard cylindrical basis functions that arise from this separation. Assume a bandlimited local expansion of order $p$ about the origin inside the circle, and an outgoing multipole expansion of order $p$ about the origin outside the circle. Use $N$ equally spaced samples on the circular surface at angles $\\theta_m = \\frac{2\\pi m}{N}$ for integer $m \\in \\{0,1,\\dots,N-1\\}$.\n\nDefine the surface-averaged quadratic quantity as the angular average of the squared magnitude of the field sampled on the circle, namely $P_{\\text{surf}} = \\frac{1}{2\\pi} \\int_{0}^{2\\pi} |u(R_s,\\theta)|^2 \\, d\\theta$. Your program must implement the following test protocol:\n\n- Construct a local expansion at the origin with coefficients $b_n$ for integer indices $n$ such that $|n| \\leq p$. The coefficients are given deterministically by $b_n = \\exp(-\\alpha |n|) \\exp(i n \\delta)$ for real parameters $\\alpha  0$ and $\\delta$ in radians.\n- Apply the Local-to-Point (L2P) operator to evaluate the field on the circle of radius $R_s$ at the sampling angles $\\theta_m$, resulting in samples $u_m = u(R_s,\\theta_m)$.\n- From the sampled values $u_m$ on the circle, apply the Point-to-Multipole (P2M) operator to determine the outgoing multipole coefficients $a_n$ about the origin for the same bandlimit $|n| \\leq p$. Use separation-of-variables and orthogonality on the circle to perform this aggregation in a mathematically consistent manner.\n- Compute the discrete approximation to $P_{\\text{surf}}$ using the trapezoidal rule on the uniform angular grid, i.e., replace the angular integral by the uniform average of $|u_m|^2$ over the samples.\n- Using the outgoing multipole coefficients $a_n$, compute a corresponding reconstruction of the surface-averaged quadratic quantity in a way that is consistent with the separation-of-variables representation on the circle and the orthogonality of the angular basis. The exact formula must be derived from first principles; do not assume shortcut identities without justification.\n- Report whether the relative difference between the two computed quadratic quantities does not exceed the specified tolerance $\\epsilon$, i.e., whether $\\frac{|P_{\\text{out}} - P_{\\text{surf}}|}{\\max(P_{\\text{surf}},\\eta)} \\leq \\epsilon$, where $P_{\\text{out}}$ is the quantity computed from the outgoing multipole representation and $\\eta$ is a small positive constant introduced only to prevent division by zero if $P_{\\text{surf}}$ vanishes.\n\nAngles must be treated in radians, and all quantities are dimensionless. Use cylindrical functions appropriate to the scalar Helmholtz setting. The program must implement this test for each parameter set in the provided test suite and produce a single line of output containing the results as a comma-separated list enclosed in square brackets.\n\nTest suite:\n- Case 1 (happy path): $k = 3.0$, $R_s = 1.0$, $p = 6$, $N = 64$, $\\alpha = 0.4$, $\\delta = 0.3$, $\\epsilon = 10^{-10}$.\n- Case 2 (minimal sampling boundary): $k = 5.0$, $R_s = 0.7$, $p = 10$, $N = 21$, $\\alpha = 0.25$, $\\delta = 0.5$, $\\epsilon = 10^{-9}$.\n- Case 3 (under-resolved edge case): $k = 8.0$, $R_s = 1.2$, $p = 12$, $N = 16$, $\\alpha = 0.3$, $\\delta = 0.1$, $\\epsilon = 10^{-6}$.\n- Case 4 (zeroth-order sanity check): $k = 2.0$, $R_s = 0.5$, $p = 0$, $N = 8$, $\\alpha = 0.6$, $\\delta = 0.0$, $\\epsilon = 10^{-12}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,result_3,result_4]$), where each $result_i$ is a boolean indicating whether the reciprocity-based power conservation test passed for that case.", "solution": "This test validates the Local-to-Point (L2P) and Point-to-Multipole (P2M) operators by checking for conservation of a power-like quantity on a circular boundary. The method is based on the separation of variables for the two-dimensional scalar Helmholtz equation, $(\\nabla^2 + k^2)u = 0$, in polar coordinates $(r, \\theta)$.\n\nThe key steps and underlying principles are:\n1.  **Field Representation**: Fields are represented using cylindrical basis functions. A local expansion (regular at the origin) uses Bessel functions of the first kind, $J_n(kr)$, while an outgoing multipole expansion (radiating outwards) uses Hankel functions of the first kind, $H_n^{(1)}(kr)$.\n    *   Local expansion: $u_{\\text{loc}}(r, \\theta) = \\sum_{n=-p}^{p} b_n J_n(kr) e^{in\\theta}$\n    *   Outgoing expansion: $u_{\\text{out}}(r, \\theta) = \\sum_{n=-p}^{p} a_n H_n^{(1)}(kr) e^{in\\theta}$\n\n2.  **L2P Operation**: A known local expansion with coefficients $b_n$ is evaluated at $N$ equally spaced points on a circle of radius $R_s$. This produces field samples $u_m = u_{\\text{loc}}(R_s, \\theta_m)$.\n\n3.  **Surface Power Calculation ($P_{\\text{surf}}$)**: A surface-averaged quadratic quantity, analogous to power, is computed from the field samples using a numerical approximation of the integral $P_{\\text{surf}} = \\frac{1}{2\\pi} \\int_{0}^{2\\pi} |u(R_s,\\theta)|^2 \\, d\\theta$. Using the trapezoidal rule on the uniform grid, this becomes $P_{\\text{surf}} \\approx \\frac{1}{N} \\sum_{m=0}^{N-1} |u_m|^2$.\n\n4.  **P2M Operation**: The field samples $u_m$ are aggregated back into an outgoing multipole expansion with coefficients $a_n$. This is achieved by performing a Discrete Fourier Transform on the samples and dividing by the Hankel function values on the circle: $a_n \\approx \\frac{1}{N H_n^{(1)}(kR_s)} \\sum_{m=0}^{N-1} u_m e^{-in\\theta_m}$.\n\n5.  **Reconstructed Power ($P_{\\text{out}}$)**: The power is recalculated using the newly found multipole coefficients $a_n$ and Parseval's theorem for Fourier series: $P_{\\text{out}} = \\sum_{n=-p}^{p} |a_n H_n^{(1)}(kR_s)|^2$.\n\n6.  **Consistency Check**: The test passes if $P_{\\text{surf}}$ and $P_{\\text{out}}$ are approximately equal. This holds true if the number of samples $N$ is sufficient to prevent aliasing, i.e., if the Nyquist criterion $N \\ge 2p+1$ is met. When this condition holds, the discrete Fourier analysis is accurate, and the relationship $a_n = b_n \\frac{J_n(kR_s)}{H_n^{(1)}(kR_s)}$ is preserved, leading to the theoretical equality of the two power calculations. If $N  2p+1$, aliasing occurs, the test fails, and the operators would be considered incorrectly implemented or used.", "answer": "```python\nimport numpy as np\nfrom scipy.special import jv, hankel1\n\n# Set a small constant to prevent division by zero in the relative error calculation.\nETA = 1e-30\n\ndef reciprocity_test(k, Rs, p, N, alpha, delta, epsilon):\n    \"\"\"\n    Performs the reciprocity-based self-test for a given set of parameters.\n\n    The test follows these steps:\n    1.  Construct local expansion coefficients 'b_n'.\n    2.  Perform L2P: Evaluate the field 'u_m' on a circle from 'b_n'.\n    3.  Calculate the surface-averaged power 'P_surf' from 'u_m'.\n    4.  Perform P2M: Aggregate 'u_m' to get outgoing multipole coefficients 'a_n'.\n    5.  Calculate the reconstructed power 'P_out' from 'a_n'.\n    6.  Compare 'P_surf' and 'P_out' to check for conservation.\n    \"\"\"\n\n    # --- Step 1: Construct local expansion coefficients 'b_n' ---\n    # The modes/indices 'n' range from -p to p.\n    n_vals = np.arange(-p, p + 1)\n    b_n = np.exp(-alpha * np.abs(n_vals)) * np.exp(1j * n_vals * delta)\n\n    # --- Step 2: L2P (Local-to-Point) Operation ---\n    # Evaluate the local expansion on a circle of radius Rs.\n    # The field u(r, theta) is sum(b_n * J_n(kr) * exp(i*n*theta)).\n    \n    # Angular sample points\n    theta_m = (2 * np.pi / N) * np.arange(N)\n\n    # Calculate Bessel functions J_n(k*Rs). scipy.special.jv handles negative n.\n    jv_vals = jv(n_vals, k * Rs)\n    \n    # Coefficients of the Fourier series for the field on the circle\n    field_coeffs = b_n * jv_vals\n\n    # Evaluate the field samples u_m by synthesizing the Fourier series.\n    # This is an inverse discrete Fourier transform. A matrix-vector product is efficient.\n    # kernel[m, i] = exp(i * n_vals[i] * theta_m[m])\n    kernel_l2p = np.exp(1j * np.outer(theta_m, n_vals))\n    u_m = kernel_l2p @ field_coeffs\n\n    # --- Step 3: Calculate P_surf ---\n    # Approximate the surface-averaged power using the trapezoidal rule on the samples.\n    # P_surf = (1/N) * sum(|u_m|^2)\n    P_surf = np.mean(np.abs(u_m)**2)\n\n    # --- Step 4: P2M (Point-to-Multipole) Operation ---\n    # Aggregate point samples u_m into outgoing multipole coefficients a_n.\n    # a_n = (1 / (N * H_n(kRs))) * sum(u_m * exp(-i*n*theta_m))\n\n    # Calculate Hankel functions H_n^(1)(k*Rs). scipy.special.hankel1 handles negative n.\n    hankel1_vals = hankel1(n_vals, k * Rs)\n    \n    # The sum is a discrete Fourier transform analysis.\n    # kernel[i, m] = exp(-i * n_vals[i] * theta_m[m])\n    kernel_p2m = np.exp(-1j * np.outer(n_vals, theta_m))\n    fourier_sum = kernel_p2m @ u_m\n    \n    # Calculate a_n, handling potential division by zero for Hankel functions\n    # (though H_n^(1)(z) is zero only for z=0, which is not the case here).\n    a_n = fourier_sum / (N * hankel1_vals)\n\n    # --- Step 5: Calculate P_out ---\n    # Reconstruct the surface-averaged power from the multipole coefficients.\n    # P_out = sum(|a_n * H_n(kRs)|^2)\n    P_out = np.sum(np.abs(a_n * hankel1_vals)**2)\n    \n    # --- Step 6: Compare and return result ---\n    # Check if the relative difference is within the tolerance epsilon.\n    relative_diff = np.abs(P_out - P_surf) / max(P_surf, ETA)\n    \n    return relative_diff = epsilon\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        # (k, Rs, p, N, alpha, delta, epsilon)\n        (3.0, 1.0, 6, 64, 0.4, 0.3, 1e-10),  # Case 1: Well-resolved\n        (5.0, 0.7, 10, 21, 0.25, 0.5, 1e-9),   # Case 2: Nyquist boundary\n        (8.0, 1.2, 12, 16, 0.3, 0.1, 1e-6),   # Case 3: Under-resolved (aliased)\n        (2.0, 0.5, 0, 8, 0.6, 0.0, 1e-12)    # Case 4: Zeroth-order check\n    ]\n\n    results = []\n    for case in test_cases:\n        k, Rs, p, N, alpha, delta, epsilon = case\n        result = reciprocity_test(k, Rs, p, N, alpha, delta, epsilon)\n        results.append(str(result).lower())\n\n    # Print the final output in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3357105"}, {"introduction": "The efficiency of the FMM hinges on a critical decision: for any two groups of particles, should their interaction be computed directly or via the far-field multipole pathway? This practice challenges you to design and implement the very algorithm that makes this decision. You will develop a robust near-far switching criterion by calculating a rigorous error bound for the M2L translation operator and finding the precise separation distance at which this error meets a user-defined tolerance. This coding exercise transforms abstract error analysis into a concrete, practical tool that forms the logical backbone of the FMM algorithm, balancing computational cost against numerical accuracy [@problem_id:3357113].", "problem": "You are asked to design a robust near–far switching criterion for the Fast Multipole Method (FMM) in the context of the Helmholtz equation used in computational electromagnetics. The switching is between direct interactions and multipole/local expansions based on guaranteed cluster separation. The target is to ensure that multipole-to-local (M2L) translations are used only when the truncation error bound of the spherical Hankel expansion tail is below a user-specified tolerance. You must construct the criterion in a way that is valid for complex wavenumbers and then compute the minimal switching distances that achieve a specified error tolerance.\n\nStart from the fundamental base that the time-harmonic free-space Green’s function of the scalar Helmholtz equation is given by $G(\\mathbf{r},\\mathbf{r}')=\\dfrac{\\exp(i k \\|\\mathbf{r}-\\mathbf{r}'\\|)}{\\|\\mathbf{r}-\\mathbf{r}'\\|}$ where $k \\in \\mathbb{C}$ is the wavenumber with $\\operatorname{Im}(k) \\ge 0$ for passive media. Use the well-tested addition theorem expressing $G$ as a convergent spherical wave expansion involving the spherical Bessel function $j_n$ and the spherical Hankel function of the first kind $h_n^{(1)}$. For two disjoint balls (clusters) containing sources and targets, centered along a line with center-to-center separation $R$, with source ball radius $a_s$ and target ball radius $a_t$, guaranteed separation requires $R  a_s + a_t$. In this separated configuration, the addition theorem expansion converges absolutely and the tail for orders $n  p$ can be bounded using the triangle inequality applied to the spherical Bessel and Hankel terms evaluated at worst-case radii $r_ = a_s$ and $r_ = R - a_t$.\n\nDefine the truncation error proxy for the M2L translation at order $p$ by\n$$\nE_p(R;k,a_s,a_t) = \\sum_{n=p+1}^{\\infty} (2n+1)\\,\\big|j_n(k\\,r_)\\,h_n^{(1)}(k\\,r_)\\big|,\n$$\nwhich is a dimensionless bound derived from the addition theorem’s tail after summing over azimuthal degrees and applying the triangle inequality. In this problem, you will compute a numerically rigorous approximation of $E_p$ by summation until terms are sufficiently small, leveraging the known behavior of spherical Bessel and Hankel functions for complex arguments via their relationship to ordinary Bessel and Hankel functions.\n\nYour tasks:\n- Given $k \\in \\mathbb{C}$, $a_s \\in \\mathbb{R}_+$, $a_t \\in \\mathbb{R}_+$, an integer expansion order $p \\ge 0$, and an error tolerance $\\varepsilon \\in \\mathbb{R}_+$, design a near–far switching criterion that uses multipole/local expansions if and only if $E_p(R;k,a_s,a_t) \\le \\varepsilon$ with $R  a_s + a_t$, and otherwise uses direct interactions.\n- For each test case, compute the minimal switching distance $R_{\\text{switch}}$ (in meters) defined by the smallest $R$ strictly greater than $a_s + a_t$ such that $E_p(R;k,a_s,a_t) \\le \\varepsilon$. Use a numerically stable search procedure justified by the monotonic decay of the tail bound with increasing $R$ under guaranteed separation.\n- Your program must implement the spherical Hankel $h_n^{(1)}$ and spherical Bessel $j_n$ for complex arguments via their relationship to ordinary Bessel functions:\n$$\nj_n(z) = \\sqrt{\\frac{\\pi}{2z}} J_{n+\\tfrac{1}{2}}(z), \\quad\nh_n^{(1)}(z) = \\sqrt{\\frac{\\pi}{2z}} H_{n+\\tfrac{1}{2}}^{(1)}(z),\n$$\nand must numerically approximate the infinite tail sum to a stringent internal tolerance. You must ensure correctness by using worst-case radii $r_ = a_s$ and $r_ = R - a_t$, which correspond to the aggregation (source-to-multipole, S2M) and disaggregation (local-to-target, L2T) operators’ extremal geometric configuration within FMM’s translation chain. The translation operator (multipole-to-local, M2L) is the sole contributor to $E_p$ in this bound.\n\nUnits and output:\n- Use meters for distances and radians per meter for $k$.\n- Express all distances in meters.\n- Angles are not directly required; when present, they must be in radians.\n- For each test case, output the computed $R_{\\text{switch}}$ as a float rounded to five decimal places.\n\nTest suite:\n- Case $1$: $k = \\dfrac{2\\pi}{0.5}\\,\\text{rad/m}$, $a_s = 0.1\\,\\text{m}$, $a_t = 0.1\\,\\text{m}$, $p = 10$, $\\varepsilon = 10^{-6}$.\n- Case $2$ (boundary-sensitive): $k = 20\\,\\text{rad/m}$, $a_s = 0.2\\,\\text{m}$, $a_t = 0.2\\,\\text{m}$, $p = 6$, $\\varepsilon = 10^{-4}$.\n- Case $3$ (attenuative medium): $k = 30 + 5 i\\,\\text{rad/m}$, $a_s = 0.15\\,\\text{m}$, $a_t = 0.1\\,\\text{m}$, $p = 8$, $\\varepsilon = 10^{-8}$.\n- Case $4$ (high frequency, low order): $k = 100\\,\\text{rad/m}$, $a_s = 0.05\\,\\text{m}$, $a_t = 0.05\\,\\text{m}$, $p = 5$, $\\varepsilon = 10^{-5}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example $[r_1,r_2,r_3,r_4]$, where $r_i$ are the computed $R_{\\text{switch}}$ values for the test cases in meters, each rounded to five decimal places.", "solution": "The objective is to find the minimum separation distance, $R_{\\text{switch}}$, between two clusters (a source cluster of radius $a_s$ and a target cluster of radius $a_t$) at which the error from using a truncated multipole expansion is less than a specified tolerance $\\varepsilon$. This distance defines the switch-over point between direct near-field computations and efficient far-field FMM computations.\n\nThe solution is based on finding the root of the equation $E_p(R) - \\varepsilon = 0$, where $E_p(R)$ is the provided truncation error proxy for the multipole-to-local (M2L) operator.\n$$E_p(R;k,a_s,a_t) = \\sum_{n=p+1}^{\\infty} (2n+1)\\,\\big|j_n(k\\,a_s)\\,h_n^{(1)}(k(R-a_t))\\big|$$\nThe algorithmic approach is as follows:\n\n1.  **Error Function Implementation**: A function is created to compute $E_p(R)$. Since the formula involves an infinite sum, it is approximated numerically by summing terms from $n=p+1$ up to a sufficiently large limit $n_{\\text{max}}$ where the series has converged. The terms of the sum require the spherical Bessel function $j_n(z)$ and the spherical Hankel function $h_n^{(1)}(z)$ for complex arguments $z$. These are implemented using their standard definitions in terms of ordinary half-integer order Bessel ($J_{n+1/2}$) and Hankel ($H^{(1)}_{n+1/2}$) functions, which are available in scientific computing libraries like SciPy.\n\n2.  **Monotonicity and Root-Finding**: The error proxy $E_p(R)$ is a monotonically decreasing function of the separation distance $R$ for the valid range $R > a_s + a_t$. This is because the magnitude of the spherical Hankel function $|h_n^{(1)}(z)|$ decreases as $|z|$ increases. This monotonicity guarantees that a unique solution for $R_{\\text{switch}}$ exists and makes the problem suitable for efficient and robust numerical root-finding algorithms.\n\n3.  **Numerical Search**: A bracketing root-finding method, such as the Brent-Dekker algorithm (`brentq` in SciPy), is used to solve for $R$ in the equation $E_p(R) - \\varepsilon = 0$.\n    *   The search for the root $R_{\\text{switch}}$ is constrained to the valid domain $R > a_s + a_t$.\n    *   A search interval $[R_a, R_b]$ is established where the objective function $f(R) = E_p(R) - \\varepsilon$ changes sign. The lower bound $R_a$ is set slightly above the physical limit $a_s + a_t$. The upper bound $R_b$ is found by starting with a guess and iteratively increasing it until $f(R_b)$ becomes negative.\n    *   The root-finder then efficiently converges to the precise value of $R_{\\text{switch}}$ that satisfies the error tolerance.\n\nThis procedure provides a rigorous method to determine the near-far boundary, a critical component for balancing accuracy and efficiency in an FMM implementation.", "answer": "```python\nimport numpy as np\nfrom scipy.special import jv, hankel1\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Solves for the minimal switching distance R_switch for each test case.\n    \"\"\"\n\n    def spherical_jn(n, z):\n        \"\"\"\n        Computes the spherical Bessel function of the first kind j_n(z)\n        for integer order n and complex argument z.\n        \"\"\"\n        # For z=0, j_0(0) = 1 and j_n(0) = 0 for n > 0.\n        if z == 0:\n            return 1.0 if n == 0 else 0.0\n        return np.sqrt(np.pi / (2.0 * z)) * jv(n + 0.5, z)\n\n    def spherical_h1n(n, z):\n        \"\"\"\n        Computes the spherical Hankel function of the first kind h_n^(1)(z)\n        for integer order n and complex argument z.\n        \"\"\"\n        # h_n^(1)(z) has a singularity at z=0.\n        if z == 0:\n            return np.complex(np.inf, -np.inf)\n        return np.sqrt(np.pi / (2.0 * z)) * hankel1(n + 0.5, z)\n\n    def calculate_error_proxy(R, k, a_s, a_t, p):\n        \"\"\"\n        Calculates the truncation error proxy E_p for the M2L translation.\n        \"\"\"\n        # The separation must be guaranteed, R > a_s + a_t.\n        # If not, the expansion doesn't converge, error is infinite.\n        if R = a_s + a_t:\n            return np.inf\n\n        r_less = a_s\n        r_great = R - a_t\n\n        z_j = k * r_less\n        z_h = k * r_great\n\n        # Sum a sufficient number of terms in the tail of the series.\n        # p + 50 is a conservative choice that guarantees convergence\n        # to a high precision for the given test cases.\n        n_max = p + 50\n        \n        total_error = 0.0\n        # The sum starts from n = p + 1.\n        for n in range(p + 1, n_max + 1):\n            term = (2 * n + 1) * np.abs(spherical_jn(n, z_j) * spherical_h1n(n, z_h))\n            total_error += term\n            # A dynamic convergence check could be used for optimization,\n            # but a fixed large number of terms is robust.\n        \n        return total_error\n\n    def find_switching_distance(k, a_s, a_t, p, epsilon):\n        \"\"\"\n        Finds the minimal R > a_s + a_t such that E_p(R) = epsilon.\n        \"\"\"\n        R_min = a_s + a_t\n\n        def objective_func(R):\n            \"\"\"The function whose root we want to find: E_p(R) - epsilon = 0.\"\"\"\n            return calculate_error_proxy(R, k, a_s, a_t, p) - epsilon\n\n        # Check if the error is already below the tolerance at minimal separation.\n        # Use a small delta to ensure R > R_min.\n        try:\n            val_at_min_R = objective_func(R_min * (1.0 + 1e-12))\n        except (ValueError, TypeError): # Can happen if functions misbehave at boundary\n             val_at_min_R = np.inf\n\n        if val_at_min_R  0:\n            # If error is already low, the switching distance is the minimum possible.\n            return R_min\n\n        # Establish a search bracket [R_a, R_b] for the root-finder.\n        # R_a is the lower bound, slightly perturbed from R_min.\n        R_a = R_min * (1.0 + 1e-9)\n\n        # Find an upper bound R_b where the objective function is negative.\n        # Start with a reasonable guess and expand the interval if needed.\n        R_b = 2.0 * R_a if R_a > 1e-9 else 1.0 # Handle R_min=0 case\n        safety_counter = 0\n        while objective_func(R_b) > 0:\n            R_b *= 2.0\n            safety_counter += 1\n            if safety_counter > 50: # Avoid infinite loop\n                raise RuntimeError(\n                    f\"Could not find an upper bracket for root search for case \"\n                    f\"(k={k}, a_s={a_s}, a_t={a_t}, p={p}, eps={epsilon}).\"\n                )\n\n        # Use Brent's method to find the root with high tolerance.\n        R_switch = brentq(objective_func, R_a, R_b, xtol=1e-12, rtol=1e-12)\n        return R_switch\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (2.0 * np.pi / 0.5, 0.1, 0.1, 10, 1e-6),\n        (20.0, 0.2, 0.2, 6, 1e-4),\n        (30.0 + 5.0j, 0.15, 0.1, 8, 1e-8),\n        (100.0, 0.05, 0.05, 5, 1e-5),\n    ]\n\n    results = []\n    for case in test_cases:\n        k_val, a_s_val, a_t_val, p_val, eps_val = case\n        r_switch = find_switching_distance(k_val, a_s_val, a_t_val, p_val, eps_val)\n        # Round the final result to 5 decimal places as specified.\n        results.append(f\"{r_switch:.5f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3357113"}]}