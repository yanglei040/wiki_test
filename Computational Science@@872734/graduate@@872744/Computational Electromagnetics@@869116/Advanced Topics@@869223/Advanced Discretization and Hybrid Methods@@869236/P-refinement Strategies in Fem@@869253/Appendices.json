{"hands_on_practices": [{"introduction": "To fully appreciate the power of $p$-refinement, we must first understand its theoretical promise: exponential convergence for smooth solutions. This foundational exercise connects the abstract theory of polynomial approximation of analytic functions to a tangible calculation. By deriving the convergence rate constants for a model plane wave, you will gain a firm grasp of the remarkable efficiency of high-order methods and the source of their advantage over traditional, low-order approaches [@problem_id:3314615].", "problem": "Consider a one-dimensional proxy of a time-harmonic electromagnetic field in a homogeneous, lossless medium, where the exact complex electric field component is given by the analytic function $u(x) = \\exp(\\mathrm{i}\\kappa x)$ on the closed interval $\\Omega = [-1,1]$, with real wavenumber $\\kappa > 0$. The field is to be approximated by a single-element $hp$-finite element method (Finite Element Method (FEM)) on $\\Omega$ using a trial space of polynomials of degree at most $p$ defined on the reference element, i.e., a fixed $h$ and variable $p$ refinement strategy (a limiting case of $hp$-refinement). Assume the error is measured in the uniform norm $\\|\\cdot\\|_{L^{\\infty}(\\Omega)}$.\n\nUse as foundational facts the analyticity of $u$ together with standard approximation theory of analytic functions on the interval $[-1,1]$ via polynomial spaces and the Bernstein ellipse technique. In particular, recall that for a function analytic in and on a Bernstein ellipse $\\mathcal{E}_{\\rho}$ with parameter $\\rho > 1$ (the image of the circle $|w|=\\rho$ under the Joukowski map $z=\\frac{1}{2}(w+w^{-1})$), with maximum modulus $M_{\\rho} = \\max_{z\\in \\mathcal{E}_{\\rho}}|u(z)|$, the best degree-$p$ polynomial approximation error on $[-1,1]$ admits an upper bound of the form $\\frac{2M_{\\rho}}{\\rho - 1}\\rho^{-p}$ in the $L^{\\infty}$ norm.\n\nFor the specified analytic field $u(x) = \\exp(\\mathrm{i}\\kappa x)$ and the single-element discretization (which is a trivial mesh grading scheme with a single element of length $2$), set the Bernstein ellipse parameter to the explicit value $\\rho = 2$. Treat the discrete solution $u_{hp}$ as the best approximation in the polynomial trial space (which provides a rigorous upper bound for any Galerkin solution due to quasi-optimality in norms equivalent to $L^{\\infty}$ under analyticity).\n\nCompute explicit constants $C$ and $\\alpha$ such that the following bound holds for all polynomial degrees $p \\in \\mathbb{N}$:\n$$\n\\|u - u_{hp}\\|_{L^{\\infty}(\\Omega)} \\le C \\exp(-\\alpha p).\n$$\nExpress the final answer as a closed-form analytic expression in terms of $\\kappa$ only. No numerical rounding is required and no physical units are to be reported. The angle unit is radians.", "solution": "### Step 1: Extract Givens\n-   **Exact Solution:** The complex electric field component is given by $u(x) = \\exp(\\mathrm{i}\\kappa x)$ on the domain $\\Omega = [-1,1]$, where $\\kappa > 0$ is a real wavenumber. The function $u(x)$ is analytic.\n-   **Approximation Method:** A single-element $hp$-Finite Element Method (FEM) is used, which corresponds to a polynomial approximation on $\\Omega$ using polynomials of degree at most $p$.\n-   **Error Norm:** The error is measured in the uniform norm, $\\| \\cdot \\|_{L^{\\infty}(\\Omega)}$.\n-   **Approximation Theory Bound:** For a function $u(z)$ analytic in and on a Bernstein ellipse $\\mathcal{E}_{\\rho}$ with parameter $\\rho > 1$, the best degree-$p$ polynomial approximation error is bounded by:\n    $$ \\|u - u_p\\|_{L^{\\infty}([-1,1])} \\le \\frac{2M_{\\rho}}{\\rho - 1}\\rho^{-p} $$\n    where $M_{\\rho} = \\max_{z\\in \\mathcal{E}_{\\rho}}|u(z)|$.\n-   **Specific Parameters:** The Bernstein ellipse parameter is set to $\\rho = 2$.\n-   **Assumption:** The discrete FEM solution $u_{hp}$ is treated as the best polynomial approximation $u_p$.\n-   **Task:** Find explicit constants $C$ and $\\alpha$ in terms of $\\kappa$ such that the following bound holds for all $p \\in \\mathbb{N}$:\n    $$ \\|u - u_{hp}\\|_{L^{\\infty}(\\Omega)} \\le C \\exp(-\\alpha p) $$\n\n### Solution Derivation\n\nThe objective is to determine the constants $C$ and $\\alpha$ in the error bound $\\|u - u_{hp}\\|_{L^{\\infty}(\\Omega)} \\le C \\exp(-\\alpha p)$. The problem states that the discrete solution $u_{hp}$ can be treated as the best polynomial approximation of degree $p$, denoted $u_p$. We are given the theoretical bound for the error of the best approximation:\n$$ \\|u - u_p\\|_{L^{\\infty}([-1,1])} \\le \\frac{2M_{\\rho}}{\\rho - 1}\\rho^{-p} $$\nWe are given $\\rho = 2$. Substituting this value into the bound gives:\n$$ \\|u - u_p\\|_{L^{\\infty}([-1,1])} \\le \\frac{2M_{2}}{2 - 1}2^{-p} = 2 M_2 2^{-p} $$\nThe next step is to calculate $M_2$, which is the maximum modulus of the analytic continuation of $u(x)$ on the Bernstein ellipse $\\mathcal{E}_2$. The function is $u(x) = \\exp(\\mathrm{i}\\kappa x)$. Its analytic continuation into the complex plane is $u(z) = \\exp(\\mathrm{i}\\kappa z)$ for $z \\in \\mathbb{C}$.\n\nWe need to compute $M_2 = \\max_{z \\in \\mathcal{E}_2} |u(z)|$. Let $z = x + \\mathrm{i}y$. The modulus of $u(z)$ is:\n$$ |u(z)| = |\\exp(\\mathrm{i}\\kappa(x + \\mathrm{i}y))| = |\\exp(\\mathrm{i}\\kappa x - \\kappa y)| = |\\exp(\\mathrm{i}\\kappa x)| \\cdot |\\exp(-\\kappa y)| = 1 \\cdot \\exp(-\\kappa y) = \\exp(-\\kappa y) $$\nSince the wavenumber $\\kappa$ is given as positive ($\\kappa > 0$), the function $\\exp(-\\kappa y)$ is a strictly decreasing function of $y$. Therefore, its maximum value on the ellipse $\\mathcal{E}_2$ will occur at the point where the imaginary part $y$ is minimum.\n\nA Bernstein ellipse $\\mathcal{E}_{\\rho}$ is defined by the Joukowski map $z = \\frac{1}{2}(w + w^{-1})$ applied to the circle $|w| = \\rho$ in the complex $w$-plane. Let $w = \\rho \\exp(\\mathrm{i}\\theta)$ for $\\theta \\in [0, 2\\pi)$. Then $z$ is given by:\n$$ z(\\theta) = \\frac{1}{2} \\left(\\rho \\exp(\\mathrm{i}\\theta) + \\frac{1}{\\rho} \\exp(-\\mathrm{i}\\theta) \\right) $$\nExpanding the complex exponentials:\n$$ z(\\theta) = \\frac{1}{2} \\left( \\rho(\\cos\\theta + \\mathrm{i}\\sin\\theta) + \\frac{1}{\\rho}(\\cos\\theta - \\mathrm{i}\\sin\\theta) \\right) $$\n$$ z(\\theta) = \\frac{1}{2} \\left(\\rho + \\frac{1}{\\rho}\\right)\\cos\\theta + \\mathrm{i} \\frac{1}{2}\\left(\\rho - \\frac{1}{\\rho}\\right)\\sin\\theta $$\nThe imaginary part of $z$ is $y(\\theta) = \\frac{1}{2}(\\rho - \\frac{1}{\\rho})\\sin\\theta$. Since $\\rho > 1$, the term $(\\rho - \\frac{1}{\\rho})$ is positive. The minimum value of $y(\\theta)$ occurs when $\\sin\\theta = -1$, which gives:\n$$ y_{\\min} = -\\frac{1}{2}\\left(\\rho - \\frac{1}{\\rho}\\right) $$\nNow we can evaluate $M_{\\rho}$:\n$$ M_{\\rho} = \\max_{z \\in \\mathcal{E}_{\\rho}} \\exp(-\\kappa y) = \\exp(-\\kappa y_{\\min}) = \\exp\\left(\\kappa \\frac{1}{2}\\left(\\rho - \\frac{1}{\\rho}\\right)\\right) $$\nFor the specific case $\\rho = 2$, the minimum value of $y$ is:\n$$ y_{\\min} = -\\frac{1}{2}\\left(2 - \\frac{1}{2}\\right) = -\\frac{1}{2}\\left(\\frac{3}{2}\\right) = -\\frac{3}{4} $$\nAnd the maximum modulus $M_2$ is:\n$$ M_2 = \\exp(-\\kappa y_{\\min}) = \\exp\\left(-\\kappa \\left(-\\frac{3}{4}\\right)\\right) = \\exp\\left(\\frac{3\\kappa}{4}\\right) $$\nSubstituting this expression for $M_2$ into our error bound:\n$$ \\|u - u_p\\|_{L^{\\infty}([-1,1])} \\le 2 \\exp\\left(\\frac{3\\kappa}{4}\\right) 2^{-p} $$\nTo match the target form $C \\exp(-\\alpha p)$, we rewrite the term $2^{-p}$ using the natural exponential function:\n$$ 2^{-p} = (e^{\\ln 2})^{-p} = \\exp(-p \\ln 2) $$\nThe error bound thus becomes:\n$$ \\|u - u_p\\|_{L^{\\infty}([-1,1])} \\le 2 \\exp\\left(\\frac{3\\kappa}{4}\\right) \\exp(-(\\ln 2)p) $$\nComparing this to the form $C \\exp(-\\alpha p)$, we can identify the constants $C$ and $\\alpha$:\n$$ C = 2 \\exp\\left(\\frac{3\\kappa}{4}\\right) $$\n$$ \\alpha = \\ln 2 $$\nThese constants are expressed in terms of $\\kappa$ as required.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2 \\exp\\left(\\frac{3\\kappa}{4}\\right)  \\ln(2)\n\\end{pmatrix}\n}\n$$", "id": "3314615"}, {"introduction": "The promise of exponential convergence is only realized if we apply high polynomial degrees where they are needed most. This practice delves into the core mechanism of adaptivity: a posteriori error estimation, which acts as a \"sensor\" to detect regions of high error. You will derive and implement a residual-based indicator, learning how to use element and inter-element flux-jump residuals to guide $p$-refinement, a crucial skill for creating efficient and robust FEM solvers for problems with complex features like material discontinuities [@problem_id:3336608].", "problem": "You are to derive, implement, and test a residual-based polynomial-refinement ($p$-refinement) indicator for a finite element method applied to the frequency-domain curl-curl equation in computational electromagnetics. The governing equation is the time-harmonic Maxwell curl-curl equation for the electric field,\n$$\n\\nabla \\times \\left(\\mu^{-1} \\nabla \\times \\mathbf{E}\\right) - \\omega^{2} \\epsilon \\, \\mathbf{E} = i \\, \\omega \\, \\mathbf{J},\n$$\nposed on a bounded Lipschitz domain with perfect electric conductor boundary conditions. The electric permittivity $\\epsilon$ is piecewise constant and may be discontinuous across material interfaces, the magnetic permeability $\\mu$ is uniformly positive and may be taken as constant within each element, the angular frequency is $\\omega \\in \\mathbb{R}_{+}$, the electric field is $\\mathbf{E}$, and the impressed current density is $\\mathbf{J}$. The associated finite element approximation uses curl-conforming spaces with elementwise polynomial degree $p_K$ on each element $K$.\n\nStarting from the standard weak (variational) formulation of the curl-curl equation in the Hilbert space of square-integrable vector fields with square-integrable curl, derive a residual-based a posteriori error indicator that is suitable for guiding $p$-refinement. Your derivation must:\n- Begin from the fundamental weak form obtained from Maxwell’s equations with time-harmonic fields and perfect electric conductor boundary conditions, and employ elementwise integration by parts on a mesh partition of the domain into elements $K$ with interelement faces $F$.\n- Identify the element residual defined by the strong form applied to the discrete field, and the interelement face jump residual of the appropriate flux quantity (the tangential component of $\\mu^{-1}\\nabla \\times \\mathbf{E}_h$).\n- Justify and present scale-invariant weights that depend on the element size $h_K$, the face size $h_F$, and the local polynomial degrees $p_K$ and $p_F$, so that the indicator is robust with respect to the local polynomial degree. The face terms must be explicitly weighted by a function of the local polynomial degree $p$.\n\nTo enable a concrete, verifiable implementation while remaining faithful to the curl-curl structure, consider the two-dimensional transverse-electric scalar reduction in which the out-of-plane component satisfies a scalar Helmholtz-type equation of the form\n$$\n- \\nabla \\cdot \\left(\\mu^{-1} \\nabla u \\right) - \\omega^{2} \\epsilon \\, u = i \\, \\omega \\, j,\n$$\nwith homogeneous Dirichlet data $u=0$ on the boundary. Use this scalar reduction only for the purpose of testing the indicator you derive; your derivation must remain in the vectorial curl-curl framework, but your implementation and tests should follow the scalar model by analogy. In this scalar model, the interelement face-jump term corresponds to the jump of the normal flux $\\left(\\mu^{-1}\\nabla u\\right)\\cdot \\mathbf{n}$ across faces.\n\nImplementation requirements:\n- Domain and mesh: Use the square domain $[0,1]^2$ with a uniform Cartesian mesh of $N_x \\times N_y$ rectangles, with $N_x=N_y=8$. Let $h_x=1/N_x$, $h_y=1/N_y$, element diameter $h_K = \\sqrt{h_x^2 + h_y^2}$, and face length $h_F = h_x$ or $h_y$ as appropriate.\n- Material parameters: Take $\\mu \\equiv 1$. Let $\\epsilon$ be piecewise constant. You must include both constant and discontinuous $\\epsilon$ cases in the test suite.\n- Exact field and load: Choose the exact scalar field $u_{\\text{exact}}(x,y) = \\sin(\\pi x)\\sin(\\pi y)$ so that $u_{\\text{exact}}=0$ on the boundary. Define the impressed source $j(x,y)$ by substituting $u_{\\text{exact}}$ into the scalar equation,\n$$\nj(x,y) = \\frac{-\\nabla \\cdot \\left(\\mu^{-1} \\nabla u_{\\text{exact}} \\right) - \\omega^2 \\epsilon(x,y) u_{\\text{exact}}(x,y)}{i \\, \\omega},\n$$\nwhere for $\\mu=1$, $-\\nabla \\cdot (\\nabla u_{\\text{exact}}) = -\\Delta u_{\\text{exact}} = 2\\pi^2 \\sin(\\pi x)\\sin(\\pi y)$.\n- Discrete field model: On each element, construct a local polynomial approximation $u_h$ of degree $p_K$ by least-squares fitting of $u_{\\text{exact}}$ to the complete polynomial space of total degree $\\le p_K$ using at least $(p_K+2)^2$ interior sample points per element. Use this $u_h$ to compute element and face residuals.\n- Residual indicator: For each element $K$, compute\n  - the element residual $R_K(x,y) = -\\nabla \\cdot \\left(\\mu^{-1} \\nabla u_h \\right) - \\omega^2 \\epsilon(x,y) u_h(x,y) - i \\, \\omega \\, j(x,y)$, and its squared $L^2$-seminorm on $K$,\n  - the jump across each interior face $F \\subset \\partial K$ of the normal flux $\\llbracket \\mu^{-1}\\nabla u_h \\cdot \\mathbf{n}\\rrbracket$ (with outward normals on each neighbor), and its squared $L^2$-seminorm on $F$,\n  - assemble the elementwise indicator with degree-dependent weights,\n$$\n\\eta_K^2 = \\frac{h_K^2}{(p_K+1)^2} \\,\\lVert R_K \\rVert_{0,K}^2 \\;+\\; \\frac{1}{2} \\sum_{F \\subset \\partial K \\cap \\mathcal{F}_{\\text{int}}} \\frac{h_F}{(p_F+1)} \\, \\lVert \\llbracket \\mu^{-1}\\nabla u_h \\cdot \\mathbf{n} \\rrbracket \\rVert_{0,F}^2,\n$$\n  where $p_F = \\max(p_{K^-}, p_{K^+})$ for the two elements sharing $F$, and the sum is over interior faces only. Use the magnitude for complex quantities when forming norms.\n- Marking strategy: Given a global set of indicators $\\{\\eta_K\\}$, flag element $K$ for $p$-refinement if $\\eta_K$ is strictly larger than $\\theta$ times the average indicator, i.e., $\\eta_K > \\theta \\, \\overline{\\eta}$ with $\\overline{\\eta} = \\frac{1}{\\#\\mathcal{T}_h}\\sum_{K}\\eta_K$ and $\\theta=2$.\n\nDesign a test suite that exercises the indicator in multiple regimes:\n- Test 1 (baseline, smooth and matched): $\\epsilon(x,y)\\equiv 2.0$, $\\omega=8.0$ (in radians per second), uniform $p_K \\equiv 2$ on all elements.\n- Test 2 (material interface): $\\epsilon(x,y)=2.0$ for $x0.5$, and $\\epsilon(x,y)=5.0$ for $x\\ge 0.5$, $\\omega=8.0$, uniform $p_K \\equiv 2$.\n- Test 3 (nonuniform degree near interface): the same $\\epsilon(x,y)$ and $\\omega$ as Test 2, but set $p_K=1$ on elements whose centers satisfy $|x-0.5|0.15$ and $|y-0.5|0.15$, and $p_K=3$ elsewhere.\n\nYour program must:\n- Construct the mesh and elementwise polynomial fits as specified.\n- Compute the element and interior face residual terms using numerical quadrature of sufficient order to accurately integrate the squared residuals for the local degrees used.\n- Form $\\eta_K$ for each element, apply the marking strategy, and report the number of flagged elements for each test case.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[r1,r2,r3]\"), where each entry is an integer equal to the number of elements flagged for $p$-refinement in the corresponding test case.\n- There are no physical units in the final reported integers.", "solution": "### Derivation of the Residual-Based Error Indicator\n\nThe starting point is the time-harmonic curl-curl equation for the electric field $\\mathbf{E}$:\n$$\n\\nabla \\times \\left(\\mu^{-1} \\nabla \\times \\mathbf{E}\\right) - \\omega^{2} \\epsilon \\, \\mathbf{E} = i \\, \\omega \\, \\mathbf{J} \\quad \\text{in } \\Omega.\n$$\nThe domain $\\Omega$ is a bounded Lipschitz domain. We impose perfect electric conductor (PEC) boundary conditions, $\\mathbf{E} \\times \\mathbf{n} = \\mathbf{0}$, on the boundary $\\partial\\Omega$.\n\nThe problem is formulated in the Hilbert space $H_0(\\text{curl}, \\Omega) = \\{ \\mathbf{v} \\in (L^2(\\Omega))^3 : \\nabla \\times \\mathbf{v} \\in (L^2(\\Omega))^3, \\mathbf{v} \\times \\mathbf{n} = \\mathbf{0} \\text{ on } \\partial\\Omega \\}$. The weak (variational) formulation is: Find $\\mathbf{E} \\in H_0(\\text{curl}, \\Omega)$ such that for all test functions $\\mathbf{v} \\in H_0(\\text{curl}, \\Omega)$,\n$$\n\\int_{\\Omega} \\left( \\mu^{-1} (\\nabla \\times \\mathbf{E}) \\cdot (\\nabla \\times \\mathbf{v}) - \\omega^2 \\epsilon \\, \\mathbf{E} \\cdot \\mathbf{v} \\right) d\\Omega = \\int_{\\Omega} i \\omega \\mathbf{J} \\cdot \\mathbf{v} \\, d\\Omega.\n$$\nWe denote the bilinear form on the left by $B(\\mathbf{E}, \\mathbf{v})$. Let $\\mathbf{E}_h \\in V_h \\subset H_0(\\text{curl}, \\Omega)$ be the finite element approximation to $\\mathbf{E}$, where $V_h$ is a finite-dimensional space of curl-conforming vector polynomials of degree $p_K$ on each element $K$ of a mesh $\\mathcal{T}_h$. The error is $\\mathbf{e} = \\mathbf{E} - \\mathbf{E}_h$. The error equation for any $\\mathbf{v} \\in H_0(\\text{curl}, \\Omega)$ is found by substituting $\\mathbf{E} = \\mathbf{e} + \\mathbf{E}_h$ into the weak form:\n$$\nB(\\mathbf{e}, \\mathbf{v}) = \\int_{\\Omega} i \\omega \\mathbf{J} \\cdot \\mathbf{v} \\, d\\Omega - B(\\mathbf{E}_h, \\mathbf{v}).\n$$\nWe now perform integration by parts on the term involving $\\nabla \\times \\mathbf{E}_h$, element by element:\n$$\n\\int_{\\Omega} \\mu^{-1} (\\nabla \\times \\mathbf{E}_h) \\cdot (\\nabla \\times \\mathbf{v}) \\, d\\Omega = \\sum_{K \\in \\mathcal{T}_h} \\int_K \\mu^{-1} (\\nabla \\times \\mathbf{E}_h) \\cdot (\\nabla \\times \\mathbf{v}) \\, dK.\n$$\nUsing the vector identity $\\nabla \\cdot (\\mathbf{A} \\times \\mathbf{B}) = (\\nabla \\times \\mathbf{A}) \\cdot \\mathbf{B} - \\mathbf{A} \\cdot (\\nabla \\times \\mathbf{B})$ and the divergence theorem, we get the element-wise integration by parts formula:\n$$\n\\int_K (\\nabla \\times \\mathbf{A}) \\cdot \\mathbf{B} \\, dK = \\int_K \\mathbf{A} \\cdot (\\nabla \\times \\mathbf{B}) \\, dK + \\int_{\\partial K} (\\mathbf{A} \\times \\mathbf{n}_K) \\cdot \\mathbf{B} \\, dS.\n$$\nApplying this with $\\mathbf{A} = \\mu^{-1} \\nabla \\times \\mathbf{E}_h$ and $\\mathbf{B} = \\mathbf{v}$, we obtain:\n$$\n\\sum_{K \\in \\mathcal{T}_h} \\int_K \\mu^{-1} (\\nabla \\times \\mathbf{E}_h) \\cdot (\\nabla \\times \\mathbf{v}) \\, dK = \\sum_{K \\in \\mathcal{T}_h} \\left( \\int_K (\\nabla \\times (\\mu^{-1} \\nabla \\times \\mathbf{E}_h)) \\cdot \\mathbf{v} \\, dK + \\int_{\\partial K} ((\\mu^{-1} \\nabla \\times \\mathbf{E}_h) \\times \\mathbf{n}_K) \\cdot \\mathbf{v} \\, dS \\right).\n$$\nSubstituting this back into the error equation:\n$$\nB(\\mathbf{e}, \\mathbf{v}) = \\sum_{K \\in \\mathcal{T}_h} \\int_K \\left( i \\omega \\mathbf{J} - \\left( \\nabla \\times (\\mu^{-1} \\nabla \\times \\mathbf{E}_h) - \\omega^2 \\epsilon \\mathbf{E}_h \\right) \\right) \\cdot \\mathbf{v} \\, dK - \\sum_{K \\in \\mathcal{T}_h} \\int_{\\partial K} ((\\mu^{-1} \\nabla \\times \\mathbf{E}_h) \\times \\mathbf{n}_K) \\cdot \\mathbf{v} \\, dS.\n$$\nThe first term is the element residual, $\\mathbf{R}_K = i \\omega \\mathbf{J} - (\\nabla \\times (\\mu^{-1} \\nabla \\times \\mathbf{E}_h) - \\omega^2 \\epsilon \\mathbf{E}_h)$. The second term involves a sum of integrals over element boundaries. An interior face $F$ is shared by two elements, $K^+$ and $K^-$, with outward normals $\\mathbf{n}^+ = -\\mathbf{n}^-$. Summing their contributions gives rise to a jump term $\\llbracket \\cdot \\rrbracket$:\n$$\n\\int_F ((\\mu^{-1} \\nabla \\times \\mathbf{E}_h)|_{K^+} \\times \\mathbf{n}^+) \\cdot \\mathbf{v} \\, dS + \\int_F ((\\mu^{-1} \\nabla \\times \\mathbf{E}_h)|_{K^-} \\times \\mathbf{n}^-) \\cdot \\mathbf{v} \\, dS = \\int_F \\llbracket (\\mu^{-1} \\nabla \\times \\mathbf{E}_h) \\times \\mathbf{n} \\rrbracket \\cdot \\mathbf{v} \\, dS.\n$$\nThe term $\\llbracket (\\mu^{-1} \\nabla \\times \\mathbf{E}_h) \\times \\mathbf{n} \\rrbracket$ represents the jump in the tangential component of the magnetic field intensity $\\mathbf{H}_h = \\mu^{-1} \\nabla \\times \\mathbf{E}_h$. For faces on the domain boundary $\\partial\\Omega$, the term vanishes because $\\mathbf{v} \\in H_0(\\text{curl}, \\Omega)$ implies $\\mathbf{v} \\times \\mathbf{n} = \\mathbf{0}$, hence $\\mathbf{v}$ has no tangential component there. The error equation becomes:\n$$\nB(\\mathbf{e}, \\mathbf{v}) = \\sum_{K \\in \\mathcal{T}_h} \\int_K \\mathbf{R}_K \\cdot \\mathbf{v} \\, dK - \\sum_{F \\in \\mathcal{F}_{\\text{int}}} \\int_F \\mathbf{J}_F \\cdot \\mathbf{v} \\, dS,\n$$\nwhere $\\mathcal{F}_{\\text{int}}$ is the set of interior faces and $\\mathbf{J}_F = \\llbracket \\mu^{-1} \\nabla \\times \\mathbf{E}_h \\times \\mathbf{n} \\rrbracket$. The energy norm of the error, $\\Vert \\mathbf{e} \\Vert_{B} = \\sqrt{|B(\\mathbf{e}, \\mathbf{e})|}$, can be bounded above by the norms of these residuals weighted by constants derived from local interpolation error estimates. For $p$-refinement, these constants must depend on the polynomial degree $p_K$. This leads to an a posteriori error indicator $\\eta$ such that $\\Vert \\mathbf{e} \\Vert_{B}^2 \\lesssim \\eta^2 = \\sum_K \\eta_K^2$, where the local indicator $\\eta_K^2$ is of the form:\n$$\n\\eta_K^2 = C_K^2 \\lVert \\mathbf{R}_K \\rVert_{0,K}^2 + \\sum_{F \\subset \\partial K \\cap \\mathcal{F}_{\\text{int}}} C_F^2 \\lVert \\mathbf{J}_F \\rVert_{0,F}^2.\n$$\nThe weights $C_K$ and $C_F$ are chosen to make the estimator robust with respect to the polynomial degree. Standard choices, as specified in the problem, are $C_K^2 \\sim h_K^2/p_K^2$ and $C_F^2 \\sim h_F/p_F$. Using $p_K+1$ and $p_F+1$ is a common and valid variant.\n\n### Analogy to the Scalar Problem\n\nFor the 2D scalar problem $- \\nabla \\cdot \\left(\\mu^{-1} \\nabla u \\right) - \\omega^{2} \\epsilon u = i \\omega j$, the derivation is analogous:\n-   The strong operator $\\mathcal{L}u = - \\nabla \\cdot (\\mu^{-1} \\nabla u) - \\omega^{2} \\epsilon u$ is analogous to $\\nabla \\times (\\mu^{-1} \\nabla \\times \\mathbf{E}) - \\omega^2 \\epsilon \\mathbf{E}$.\n-   The flux term $\\mu^{-1} \\nabla \\times \\mathbf{E}_h$ is analogous to the scalar flux $\\mu^{-1} \\nabla u_h$.\n-   The tangential component $(\\mu^{-1} \\nabla \\times \\mathbf{E}_h) \\times \\mathbf{n}$ is analogous to the normal component of the scalar flux, $\\mu^{-1}(\\nabla u_h) \\cdot \\mathbf{n}$.\n-   The element residual becomes $R_K = i \\omega j - \\mathcal{L}u_h$.\n-   The face jump residual becomes $J_F = \\llbracket \\mu^{-1} (\\nabla u_h) \\cdot \\mathbf{n} \\rrbracket$.\nWith $\\mu \\equiv 1$, this simplifies to $R_K = -\\Delta u_h - \\omega^2 \\epsilon u_h - i \\omega j$ and $J_F = \\llbracket (\\nabla u_h) \\cdot \\mathbf{n} \\rrbracket$. This matches the setup for the implementation. The provided formula for $\\eta_K^2$ is therefore a direct and correct application of these principles to the scalar model.\n\n### Implementation Methodology\n\nThe implementation proceeds as specified. A key detail is the calculation of the discrete field $u_h$. For each element $K$, a unique polynomial is found by least-squares fitting to the exact solution $u_{\\text{exact}}$. This means $u_h$ is discontinuous across element boundaries, which is a simplification but allows for direct testing of the error indicator formula. The integrals for the residual norms are computed using high-order Gauss-Legendre quadrature to handle the non-polynomial nature of the integrands involving $u_{\\text{exact}}$. The marking strategy is then applied to the computed indicator values $\\{\\eta_K\\}$.", "answer": "```python\nimport numpy as np\nfrom scipy.special import roots_legendre\n\n# Problem constants and setup\nNX, NY = 8, 8\nHX, HY = 1.0 / NX, 1.0 / NY\nHK_VAL = np.sqrt(HX**2 + HY**2)\nTHETA = 2.0\n\n# --- Exact Solution and Source Term ---\ndef u_exact(x, y):\n    return np.sin(np.pi * x) * np.sin(np.pi * y)\n\ndef laplacian_u_exact(x, y):\n    return -2.0 * np.pi**2 * np.sin(np.pi * x) * np.sin(np.pi * y)\n\ndef grad_u_exact(x, y):\n    dx = np.pi * np.cos(np.pi * x) * np.sin(np.pi * y)\n    dy = np.pi * np.sin(np.pi * x) * np.cos(np.pi * y)\n    return np.array([dx, dy])\n\ndef source_component(x, y, eps_val, omega):\n    \"\"\"Computes -laplacian(u_exact) - omega^2*eps*u_exact, which equals i*omega*j\"\"\"\n    return -laplacian_u_exact(x, y) - omega**2 * eps_val * u_exact(x, y)\n\n# --- Polynomial Basis and Evaluation ---\nclass Polynomial2D:\n    def __init__(self, p, coeffs, hx, hy):\n        self.p = p\n        self.coeffs = coeffs\n        self.hx = hx\n        self.hy = hy\n        self.basis_size = (p + 1) * (p + 2) // 2\n        \n        self.basis_map = []\n        for total_degree in range(p + 1):\n            for i in range(total_degree + 1):\n                self.basis_map.append((i, total_degree - i))\n\n    def evaluate(self, xi, eta):\n        val = 0.0 + 0.0j\n        grad_val = np.zeros(2, dtype=np.complex128)\n        lap_val = 0.0 + 0.0j\n\n        for i in range(self.basis_size):\n            k, l = self.basis_map[i]\n            \n            xi_k = xi**k\n            eta_l = eta**l\n            \n            # Value\n            val += self.coeffs[i] * xi_k * eta_l\n            \n            # Gradient\n            if k > 0:\n                grad_val[0] += self.coeffs[i] * k * xi**(k - 1) * eta_l\n            if l > 0:\n                grad_val[1] += self.coeffs[i] * l * xi**k * eta**(l - 1)\n            \n            # Laplacian\n            if k > 1:\n                lap_val += self.coeffs[i] * k * (k - 1) * xi**(k - 2) * eta_l * (4.0 / self.hx**2)\n            if l > 1:\n                lap_val += self.coeffs[i] * l * (l - 1) * xi**k * eta**(l - 2) * (4.0 / self.hy**2)\n\n        grad_val[0] *= (2.0 / self.hx)\n        grad_val[1] *= (2.0 / self.hy)\n        \n        return val, grad_val, lap_val\n\ndef get_poly_coeffs(p, x_min, y_min, hx, hy):\n    basis_size = (p + 1) * (p + 2) // 2\n    basis_map = []\n    for total_degree in range(p + 1):\n        for i in range(total_degree + 1):\n            basis_map.append((i, total_degree - i))\n            \n    num_samples_1d = p + 2\n    num_samples = num_samples_1d**2\n    \n    sample_xi = np.linspace(-1.0, 1.0, num_samples_1d + 2)[1:-1]\n    sample_eta = np.linspace(-1.0, 1.0, num_samples_1d + 2)[1:-1]\n    \n    xi_grid, eta_grid = np.meshgrid(sample_xi, sample_eta)\n    xi_pts, eta_pts = xi_grid.flatten(), eta_grid.flatten()\n\n    A = np.zeros((num_samples, basis_size))\n    b = np.zeros(num_samples)\n\n    for i in range(num_samples):\n        for j in range(basis_size):\n            k, l = basis_map[j]\n            A[i, j] = xi_pts[i]**k * eta_pts[i]**l\n        \n        x = x_min + hx * (xi_pts[i] + 1.0) / 2.0\n        y = y_min + hy * (eta_pts[i] + 1.0) / 2.0\n        b[i] = u_exact(x, y)\n        \n    coeffs, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n    return coeffs\n\n# --- Main Calculation ---\ndef run_test_case(eps_func, omega, p_func):\n    elements = {}\n    for i in range(NX):\n        for j in range(NY):\n            x_min, y_min = i * HX, j * HY\n            p = p_func(x_min + HX/2, y_min + HY/2)\n            coeffs = get_poly_coeffs(p, x_min, y_min, HX, HY)\n            elements[(i, j)] = {\n                'poly': Polynomial2D(p, coeffs, HX, HY),\n                'p': p,\n                'x_min': x_min,\n                'y_min': y_min,\n            }\n\n    indicators = np.zeros((NX, NY))\n    \n    for i in range(NX):\n        for j in range(NY):\n            elem = elements[(i, j)]\n            p_k = elem['p']\n            x_min, y_min = elem['x_min'], elem['y_min']\n\n            # Element residual term\n            quad_order_elem = 2 * p_k + 4\n            xi_q, w_q = roots_legendre(quad_order_elem)\n            \n            elem_res_sq = 0.0\n            for qi in range(quad_order_elem):\n                for qj in range(quad_order_elem):\n                    xi, eta = xi_q[qi], xi_q[qj]\n                    x = x_min + HX * (xi + 1.0) / 2.0\n                    y = y_min + HY * (eta + 1.0) / 2.0\n                    \n                    eps_val = eps_func(x, y)\n                    u_h, _, lap_u_h = elem['poly'].evaluate(xi, eta)\n                    \n                    # R_k = -lap(u_h) - w^2*eps*u_h - i*w*j\n                    # i*w*j = -lap(u_exact) - w^2*eps*u_exact\n                    # R_k = -lap(u_h) - w^2*eps*u_h - (-lap(u_exact) - w^2*eps*u_exact)\n                    # NOTE: mu=1, so we drop it.\n                    residual = -lap_u_h - omega**2 * eps_val * u_h - source_component(x, y, eps_val, omega)\n                    \n                    elem_res_sq += np.abs(residual)**2 * w_q[qi] * w_q[qj]\n\n            elem_res_sq *= (HX * HY / 4.0)\n            eta_k_sq = (HK_VAL**2 / (p_k + 1)**2) * elem_res_sq\n\n            # Face jump terms\n            face_res_sq_sum = 0.0\n            neighbors = [((i, j+1), HY, np.array([0, 1]), 1.0),  # North\n                         ((i+1, j), HX, np.array([1, 0]), 1.0),  # East\n                         ((i, j-1), HY, np.array([0, -1]), -1.0), # South\n                         ((i-1, j), HX, np.array([-1, 0]), -1.0)] # West\n            \n            for neighbor_idx, h_f, n, xi_eta_val in neighbors:\n                if neighbor_idx in elements:\n                    neighbor = elements[neighbor_idx]\n                    p_neighbor = neighbor['p']\n                    p_f = max(p_k, p_neighbor)\n                    \n                    quad_order_face = 2 * p_f + 2 # Sufficient quadrature for polynomial of degree 2*p_f\n                    tau_q, w_face_q = roots_legendre(quad_order_face)\n                    \n                    face_jump_sq = 0.0\n                    for q_idx in range(quad_order_face):\n                        tau = tau_q[q_idx]\n                        if n[0] == 0: # Vertical face (North/South)\n                            xi_k, eta_k = tau, xi_eta_val\n                            xi_n, eta_n = tau, -xi_eta_val\n                        else: # Horizontal face (East/West)\n                            xi_k, eta_k = xi_eta_val, tau\n                            xi_n, eta_n = -xi_eta_val, tau\n                        \n                        _, grad_u_h_k, _ = elem['poly'].evaluate(xi_k, eta_k)\n                        _, grad_u_h_n, _ = neighbor['poly'].evaluate(xi_n, eta_n)\n                        \n                        # Note: mu=1\n                        jump = np.dot(grad_u_h_k - grad_u_h_n, n)\n                        face_jump_sq += np.abs(jump)**2 * w_face_q[q_idx]\n\n                    face_jump_sq *= (h_f / 2.0)\n                    face_res_sq_sum += (h_f / (p_f + 1)) * face_jump_sq\n            \n            eta_k_sq += 0.5 * face_res_sq_sum\n            indicators[i, j] = np.sqrt(eta_k_sq)\n            \n    avg_indicator = np.mean(indicators)\n    num_flagged = np.sum(indicators > THETA * avg_indicator)\n    return num_flagged\n\ndef solve():\n    test_cases = [\n        {\n            \"eps_func\": lambda x, y: 2.0,\n            \"omega\": 8.0,\n            \"p_func\": lambda x, y: 2,\n        },\n        {\n            \"eps_func\": lambda x, y: 2.0 if x  0.5 else 5.0,\n            \"omega\": 8.0,\n            \"p_func\": lambda x, y: 2,\n        },\n        {\n            \"eps_func\": lambda x, y: 2.0 if x  0.5 else 5.0,\n            \"omega\": 8.0,\n            \"p_func\": lambda x, y: 1 if (np.abs(x - 0.5)  0.15 and np.abs(y - 0.5)  0.15) else 3,\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_test_case(case[\"eps_func\"], case[\"omega\"], case[\"p_func\"])\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3336608"}, {"introduction": "A truly effective $p$-refinement strategy must balance multiple competing objectives, moving beyond pure error estimation to a complete decision-making algorithm. This capstone exercise challenges you to implement a practical $p$-selection routine that synthesizes three key aspects: limiting polynomial degree near singularities, aiming for high accuracy in smooth regions, and satisfying wave resolution constraints to control dispersion. By coding this logic, you will gain insight into how robust, industrial-strength adaptive solvers are architected [@problem_id:3314596].", "problem": "You are tasked with implementing a principled polynomial-degree selection algorithm for two-dimensional time-harmonic Computational Electromagnetics (CEM) using the Finite Element Method (FEM) with hybrid mesh-size and polynomial-degree refinement (hp-refinement). The goal is to decide the polynomial degree per element for a given mesh over a domain that includes both smooth regions and re-entrant corners that induce field singularities.\n\nFundamental base. Time-harmonic Maxwell equations reduce in two dimensions, for a single polarized component, to a curl-curl Helmholtz-type equation for the field component, with wavenumber $k$. It is a well-tested fact that in polygonal domains, a re-entrant corner with interior angle $\\theta$ greater than $\\pi$ induces a local singularity in the form of a corner singular exponent $\\lambda = \\pi/\\theta$, which implies reduced regularity near such corners. In contrast, away from re-entrant corners and material discontinuities, the field is smooth and often analytic, allowing superior convergence under polynomial enrichment. Additionally, to control wave dispersion error in FEM, a commonly used resolution guideline is that the nondimensional ratio $k h / p$ should be bounded by a prescribed constant, where $h$ is the element size and $p$ is the polynomial degree on the element.\n\nDecision problem. You must implement a decision algorithm that, given the element size and positions relative to specified re-entrant corners, a wavenumber $k$, and a target elementwise tolerance, classifies elements as either locally influenced by a corner singularity or smooth. It must then select a polynomial degree $p$ on each element by combining:\n- a corner-regularity-aware cap in singular neighborhoods,\n- an analyticity-driven choice in smooth regions to meet a target tolerance,\n- and a wave-resolution constraint to control dispersion.\n\nFor this exercise, adopt the following concrete and conservative numerical constants and modeling primitives, which are standardized solely to make the task well-posed and testable:\n- A corner is considered re-entrant and thus singular if $\\theta > \\pi$. For such a corner at position $(x_c,y_c)$ with angle $\\theta$, define its singularity exponent $\\lambda = \\pi/\\theta$.\n- For an element with centroid $(x_e,y_e)$ and size $h_e$, define the minimum Euclidean distance to any re-entrant corner as $d_e$, and declare the element to be in a singular neighborhood if $d_e \\le \\alpha h_e$ with $\\alpha = 1.5$. If there are no re-entrant corners, all elements are deemed smooth.\n- In a singular neighborhood, set a regularity-informed cap $p_{\\text{cap}} = \\lfloor \\lambda + 0.5 \\rfloor$, and then define a singular-neighborhood base choice $p_{\\text{sing}} = \\max(p_{\\min}, \\min(p_{\\text{cap}}, p_{\\text{max,sing}}))$ with $p_{\\min} = 1$ and $p_{\\text{max,sing}} = 3$.\n- In a smooth region, use an analytic error model with elementwise exponential decay in $p$ of the form $\\text{error} \\approx A_e \\exp(-b p)$ and select $p$ as the smallest integer meeting a target tolerance $\\tau$. For this exercise, use $A_e = k h_e$, $b = 0.6$, and a given $\\tau$ per test case. That is, choose $p_{\\text{smooth}}$ as the minimal integer satisfying $A_e \\exp(-b p) \\le \\tau$.\n- Impose a wave-resolution constraint $k h_e / p \\le \\chi$ with $\\chi = 0.5$ by enforcing $p \\ge p_{\\text{disp}} = \\lceil k h_e / \\chi \\rceil$.\n- Finally, enforce global bounds $p_{\\min} \\le p \\le p_{\\max}$ with $p_{\\max} = 8$, and set\n$$\np_e = \\min\\left(p_{\\max}, \\max\\left(p_{\\text{disp}}, \\begin{cases}\np_{\\text{sing}}  \\text{if in singular neighborhood},\\\\\np_{\\text{smooth}}  \\text{otherwise.}\n\\end{cases}\\right)\\right).\n$$\n\nInput specification is embedded in the test suite below. All geometric coordinates are in a consistent Cartesian coordinate system with distances measured in the same unit as $h_e$, and the wavenumber $k$ is in reciprocal length units. The final answers are unitless integers per element.\n\nTest suite. Implement the algorithm on the following five cases. In each case, you are given:\n- a list of elements, each with centroid $(x_e,y_e)$ and size $h_e$,\n- a wavenumber $k$,\n- a set of re-entrant corners specified by $(x_c,y_c,\\theta)$ with $\\theta$ in radians,\n- and a target tolerance $\\tau$ to be enforced in smooth regions.\n\nUse the constants $\\alpha = 1.5$, $p_{\\min} = 1$, $p_{\\max} = 8$, $p_{\\text{max,sing}} = 3$, $\\chi = 0.5$, $A_e = k h_e$, and $b = 0.6$ exactly as specified above.\n\n- Case $1$ (smooth unit square surrogate):\n    - Elements: $[(0.25, 0.25, h=0.5), (0.75, 0.25, h=0.5), (0.25, 0.75, h=0.5), (0.75, 0.75, h=0.5)]$.\n    - Re-entrant corners: $[]$ (none).\n    - Wavenumber: $k = 5$.\n    - Tolerance: $\\tau = 10^{-3}$.\n\n- Case $2$ (single re-entrant corner, mixed proximity):\n    - Elements: $[(0.05, 0.05, h=0.08), (0.20, 0.05, h=0.08), (0.40, 0.40, h=0.20), (0.80, 0.80, h=0.30)]$.\n    - Re-entrant corners: $[(0.0, 0.0, \\theta = 3\\pi/2)]$.\n    - Wavenumber: $k = 5$.\n    - Tolerance: $\\tau = 10^{-3}$.\n\n- Case $3$ (two re-entrant corners, mixed smoothness):\n    - Elements: $[(0.10, 0.10, h=0.10), (0.90, 0.50, h=0.08), (0.50, 0.50, h=0.20), (0.50, 0.10, h=0.15)]$.\n    - Re-entrant corners: $[(0.0, 0.0, \\theta = 3\\pi/2), (1.0, 0.5, \\theta = 3\\pi/2)]$.\n    - Wavenumber: $k = 1$.\n    - Tolerance: $\\tau = 10^{-4}$.\n\n- Case $4$ (high-frequency smooth domain):\n    - Elements: $[(0.10, 0.10, h=0.10), (0.30, 0.20, h=0.08), (0.60, 0.40, h=0.05), (0.80, 0.70, h=0.20), (0.50, 0.90, h=0.12)]$.\n    - Re-entrant corners: $[]$.\n    - Wavenumber: $k = 80$.\n    - Tolerance: $\\tau = 10^{-2}$.\n\n- Case $5$ (threshold classification near singular neighborhood boundary):\n    - Elements: $[(0.65, 0.50, h=0.10)]$.\n    - Re-entrant corners: $[(0.50, 0.50, \\theta = 3\\pi/2)]$.\n    - Wavenumber: $k = 10$.\n    - Tolerance: $\\tau = 10^{-3}$.\n\nRequired output. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each case’s result is itself a list of integers (the selected polynomial degrees per element, in the same order as listed). For example, the output must have the form\n$[ [p_{1,1}, p_{1,2}, \\dots], [p_{2,1}, \\dots], \\dots ]$\nwith no additional text. The final answers are plain integers without any unit.", "solution": "The task is to implement a polynomial-degree selection algorithm for a two-dimensional hp-FEM (hybrid mesh-size and polynomial-degree refinement) simulation of time-harmonic electromagnetic waves. The algorithm intelligently assigns a polynomial degree $p_e$ to each element of a finite element mesh based on local field characteristics, a target accuracy, and numerical stability criteria. The core idea of hp-FEM is to adaptively use a combination of mesh refinement ($h$-refinement, reducing element size $h_e$) and polynomial enrichment ($p$-refinement, increasing basis function degree $p_e$) to achieve optimal convergence. This problem focuses solely on the p-selection part for a given mesh.\n\nThe algorithm synthesizes three fundamental considerations in modern FEM for wave problems:\n\n1.  **Local Regularity of the Solution:** The smoothness of the electromagnetic field dictates the effectiveness of high-order polynomial approximations.\n    -   In regions where the solution is smooth (analytic), the approximation error decreases exponentially with the polynomial degree $p$. The provided error model, $\\text{error} \\approx (k h_e) \\exp(-b p)$, reflects this, and inverting it to find the minimum $p$ to meet a tolerance $\\tau$ is an efficient strategy for p-refinement.\n    -   Near geometric singularities, such as re-entrant corners in the domain boundary, the solution is not smooth. For a corner with angle $\\theta > \\pi$, the field exhibits a power-law singularity of the form $r^{\\lambda}$ where $r$ is the distance from the corner and $\\lambda = \\pi/\\theta$ is the singularity exponent. The solution's regularity is limited to the Sobolev space $H^{\\lambda+1-\\epsilon}$ for any $\\epsilon > 0$. Approximation theory for FEM indicates that the convergence rate with respect to $p$ is limited by $\\lambda$. Consequently, using very high polynomial degrees in these regions yields diminishing returns. The algorithm prudently caps the polynomial degree at $p_{\\text{cap}} = \\lfloor \\lambda + 0.5 \\rfloor$ in such singular neighborhoods, focusing computational resources where they are most effective.\n\n2.  **Dispersion Error Control:** Numerical schemes for wave equations, including FEM, can introduce a non-physical, frequency-dependent phase velocity for propagating waves. This \"numerical dispersion\" leads to phase errors that accumulate over distance. To control this, the numerical resolution must be sufficient to represent the wave. A standard rule of thumb is to maintain a certain number of degrees of freedom per wavelength. This is captured by the wave-resolution constraint $k h_e / p_e \\le \\chi$, where $k=2\\pi/\\text{wavelength}$ is the wavenumber. This constraint establishes a minimum required polynomial degree, $p_{\\text{disp}}$, for a given element size $h_e$ and wavenumber $k$ to ensure simulation fidelity.\n\n3.  **Algorithmic Synthesis:** The final polynomial degree $p_e$ for an element is determined by a clear hierarchy of these criteria. The choice is based on whether the element is in a \"singular\" or \"smooth\" region, but this base choice is then required to satisfy the dispersion constraint and global bounds. The final formula,\n    $$\n    p_e = \\min\\left(p_{\\max}, \\max\\left(p_{\\text{disp}}, \\begin{cases}\n    p_{\\text{sing}}  \\text{if in singular neighborhood},\\\\\n    p_{\\text{smooth}}  \\text{otherwise.}\n    \\end{cases}\\right)\\right)\n    $$\n    encapsulates this logic. It takes the appropriate base choice ($p_{\\text{sing}}$ or $p_{\\text{smooth}}$), ensures it is at least high enough to control dispersion (by taking the maximum with $p_{\\text{disp}}$), and finally caps it by a global maximum $p_{\\max}$ to limit computational cost.\n\nLet us now apply this algorithm to a representative test case, Case 2, which involves both singular and smooth regions.\n\n**Case 2: Detailed Walkthrough**\n-   **Givens:** Wavenumber $k=5$, tolerance $\\tau = 10^{-3}$.\n-   **Re-entrant Corner:** One corner at $(0.0, 0.0)$ with angle $\\theta = 3\\pi/2$. Since $\\theta > \\pi$, it is re-entrant. The singularity exponent is $\\lambda = \\pi / (3\\pi/2) = 2/3$.\n-   **Constants:** $\\alpha = 1.5, p_{\\min} = 1, p_{\\max} = 8, p_{\\text{max,sing}} = 3, \\chi = 0.5, b = 0.6$.\n\n**Element 1:** Centroid $(0.05, 0.05)$, size $h_e=0.08$.\n1.  **Region Classification:**\n    -   Distance to corner: $d_e = \\sqrt{(0.05-0)^2 + (0.05-0)^2} = \\sqrt{0.005} \\approx 0.0707$.\n    -   Neighborhood threshold: $\\alpha h_e = 1.5 \\times 0.08 = 0.12$.\n    -   Since $d_e \\approx 0.0707 \\le 0.12$, the element is in a **singular neighborhood**.\n2.  **Base Polynomial Degree ($p_{\\text{sing}}$):**\n    -   $p_{\\text{cap}} = \\lfloor \\lambda + 0.5 \\rfloor = \\lfloor 2/3 + 0.5 \\rfloor = \\lfloor 1.166... \\rfloor = 1$.\n    -   $p_{\\text{sing}} = \\max(p_{\\min}, \\min(p_{\\text{cap}}, p_{\\text{max,sing}})) = \\max(1, \\min(1, 3)) = 1$. So, $p_{\\text{base}} = 1$.\n3.  **Dispersion Constraint ($p_{\\text{disp}}$):**\n    -   $p_{\\text{disp}} = \\lceil k h_e / \\chi \\rceil = \\lceil (5 \\times 0.08) / 0.5 \\rceil = \\lceil 0.4 / 0.5 \\rceil = \\lceil 0.8 \\rceil = 1$.\n4.  **Final Degree ($p_e$):**\n    -   $p_e = \\min(p_{\\max}, \\max(p_{\\text{disp}}, p_{\\text{base}})) = \\min(8, \\max(1, 1)) = 1$.\n\n**Element 2:** Centroid $(0.20, 0.05)$, size $h_e=0.08$.\n1.  **Region Classification:**\n    -   Distance to corner: $d_e = \\sqrt{(0.20-0)^2 + (0.05-0)^2} = \\sqrt{0.0425} \\approx 0.2062$.\n    -   Neighborhood threshold: $\\alpha h_e = 1.5 \\times 0.08 = 0.12$.\n    -   Since $d_e \\approx 0.2062 > 0.12$, the element is in a **smooth region**.\n2.  **Base Polynomial Degree ($p_{\\text{smooth}}$):**\n    -   We require $(k h_e) \\exp(-b p) \\le \\tau$. This gives $p \\ge \\ln(k h_e / \\tau)/b$.\n    -   $k h_e = 5 \\times 0.08 = 0.4$.\n    -   $p_{\\text{smooth}} = \\lceil \\frac{\\ln(0.4 / 10^{-3})}{0.6} \\rceil = \\lceil \\frac{\\ln(400)}{0.6} \\rceil \\approx \\lceil 5.991 / 0.6 \\rceil = \\lceil 9.985 \\rceil = 10$. So, $p_{\\text{base}} = 10$.\n3.  **Dispersion Constraint ($p_{\\text{disp}}$):**\n    -   $p_{\\text{disp}} = \\lceil (5 \\times 0.08) / 0.5 \\rceil = \\lceil 0.8 \\rceil = 1$.\n4.  **Final Degree ($p_e$):**\n    -   $p_e = \\min(p_{\\max}, \\max(p_{\\text{disp}}, p_{\\text{base}})) = \\min(8, \\max(1, 10)) = \\min(8, 10) = 8$.\n\nThe remaining elements in Case 2 are also in smooth regions and yield $p_e=8$. This demonstrates how the algorithm assigns a low degree ($p_e=1$) to the element affected by the singularity and a high degree ($p_e=8$, capped by $p_{\\max}$) to elements in smooth regions where high-order approximation is effective.\n\nApplying this procedure to all test cases yields the following results:\n\n-   **Case 1:** All elements are smooth, requiring a high degree to meet the tolerance. The dispersion constraint is not dominant. The final degrees are all capped by $p_{\\max}$.\n    -   Result: $[8, 8, 8, 8]$\n-   **Case 2:** The first element is near a corner and assigned $p_e=1$. The other elements are smooth and are assigned $p_e=8$.\n    -   Result: $[1, 8, 8, 8]$\n-   **Case 3:** Two elements are near corners and assigned low degrees ($p_e=1$). The other two are in smooth regions and are assigned high degrees ($p_e=8$).\n    -   Result: $[1, 1, 8, 8]$\n-   **Case 4:** A high-frequency case ($k=80$) where all elements are smooth. The dispersion constraint ($p_{\\text{disp}}$) becomes the dominant factor, requiring very high degrees which are all ultimately capped by $p_{\\max}=8$.\n    -   Result: $[8, 8, 8, 8, 8]$\n-   **Case 5:** An element lies exactly on the boundary of a singular neighborhood ($d_e = 0.15 = \\alpha h_e = 1.5 \\times 0.1$). It is classified as singular. The dispersion constraint ($p_{\\text{disp}}=2$) is more demanding than the singularity-based choice ($p_{\\text{sing}}=1$), so the final degree is $p_e=2$.\n    -   Result: $[2]$\n\nThe complete set of results is: $[[8, 8, 8, 8], [1, 8, 8, 8], [1, 1, 8, 8], [8, 8, 8, 8, 8], [2]]$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the hp-refinement polynomial degree selection algorithm\n    and runs it on the specified test cases.\n    \"\"\"\n\n    # --- Fixed constants for the algorithm ---\n    ALPHA = 1.5\n    P_MIN = 1\n    P_MAX = 8\n    P_MAX_SING = 3\n    CHI = 0.5\n    B_COEFF = 0.6\n\n    # --- Test suite definition ---\n    test_cases = [\n        # Case 1 (smooth unit square surrogate)\n        {\n            \"elements\": [(0.25, 0.25, 0.5), (0.75, 0.25, 0.5), (0.25, 0.75, 0.5), (0.75, 0.75, 0.5)],\n            \"corners\": [],\n            \"k\": 5.0,\n            \"tau\": 1e-3\n        },\n        # Case 2 (single re-entrant corner, mixed proximity)\n        {\n            \"elements\": [(0.05, 0.05, 0.08), (0.20, 0.05, 0.08), (0.40, 0.40, 0.20), (0.80, 0.80, 0.30)],\n            \"corners\": [(0.0, 0.0, 3 * np.pi / 2)],\n            \"k\": 5.0,\n            \"tau\": 1e-3\n        },\n        # Case 3 (two re-entrant corners, mixed smoothness)\n        {\n            \"elements\": [(0.10, 0.10, 0.10), (0.90, 0.50, 0.08), (0.50, 0.50, 0.20), (0.50, 0.10, 0.15)],\n            \"corners\": [(0.0, 0.0, 3 * np.pi / 2), (1.0, 0.5, 3 * np.pi / 2)],\n            \"k\": 1.0,\n            \"tau\": 1e-4\n        },\n        # Case 4 (high-frequency smooth domain)\n        {\n            \"elements\": [(0.10, 0.10, 0.10), (0.30, 0.20, 0.08), (0.60, 0.40, 0.05), (0.80, 0.70, 0.20), (0.50, 0.90, 0.12)],\n            \"corners\": [],\n            \"k\": 80.0,\n            \"tau\": 1e-2\n        },\n        # Case 5 (threshold classification near singular neighborhood boundary)\n        {\n            \"elements\": [(0.65, 0.50, 0.10)],\n            \"corners\": [(0.50, 0.50, 3 * np.pi / 2)],\n            \"k\": 10.0,\n            \"tau\": 1e-3\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        case_results = []\n        elements = case[\"elements\"]\n        corners = case[\"corners\"]\n        k = case[\"k\"]\n        tau = case[\"tau\"]\n\n        re_entrant_corners = [(xc, yc, theta) for xc, yc, theta in corners if theta > np.pi]\n\n        for xe, ye, he in elements:\n            # Step 1: Calculate minimum distance to a re-entrant corner\n            min_dist = float('inf')\n            closest_corner_theta = None\n            if re_entrant_corners:\n                for xc, yc, theta in re_entrant_corners:\n                    dist = np.sqrt((xe - xc)**2 + (ye - yc)**2)\n                    if dist  min_dist:\n                        min_dist = dist\n                        closest_corner_theta = theta\n            \n            # Step 2: Classify element and calculate base p\n            is_singular = (min_dist = ALPHA * he) if re_entrant_corners else False\n            \n            if is_singular:\n                # In singular neighborhood\n                lambda_exp = np.pi / closest_corner_theta\n                p_cap = int(np.floor(lambda_exp + 0.5))\n                p_sing = max(P_MIN, min(p_cap, P_MAX_SING))\n                p_base = p_sing\n            else:\n                # In smooth region\n                kh = k * he\n                # Ae * exp(-b*p) = tau  =>  p >= ln(Ae/tau)/b\n                # Ae = kh\n                if kh = 0 or tau = 0 or kh/tau = 1:\n                    # To avoid math domain error with log or if tolerance met with p=0.\n                    p_smooth_raw = 0\n                else:\n                    p_smooth_raw = np.log(kh / tau) / B_COEFF\n                \n                p_smooth = int(np.ceil(p_smooth_raw))\n                p_base = max(P_MIN, p_smooth)\n\n            # Step 3: Calculate dispersion-constrained p\n            p_disp = int(np.ceil((k * he) / CHI))\n            \n            # Step 4: Combine and finalize p_e\n            p_intermediate = max(p_disp, p_base)\n            p_element = min(P_MAX, p_intermediate)\n            \n            case_results.append(p_element)\n            \n        all_results.append(case_results)\n\n    # Format output as a string representation of a list of lists.\n    # Using str(list) automatically adds spaces after commas, which matches the example format.\n    output_str = \"[\" + \", \".join(map(str, all_results)) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "3314596"}]}