{"hands_on_practices": [{"introduction": "This first practice is designed to build the foundational data transfer operators from first principles. You will implement and compare a conservative scheme based on geometric cell overlaps with a simple non-conservative nearest-neighbor sampling scheme [@problem_id:3501827]. This exercise is crucial for understanding how the mathematical construction of an operator directly determines its ability to conserve a quantity and maintain the physical bounds of the source data.", "problem": "You are given two one-dimensional meshes on the closed interval $[0,1]$. A mesh is specified by a strictly increasing list of cell-edge coordinates, and the associated data are cell averages of a scalar field over each cell. Let the source mesh have $N_{\\mathrm{s}}$ cells with edges $\\{x^{\\mathrm{s}}_{0},x^{\\mathrm{s}}_{1},\\dots,x^{\\mathrm{s}}_{N_{\\mathrm{s}}}\\}$ and cell lengths $L^{\\mathrm{s}}_{i}=x^{\\mathrm{s}}_{i+1}-x^{\\mathrm{s}}_{i}$ for $i=0,\\dots,N_{\\mathrm{s}}-1$. Let the target mesh have $N_{\\mathrm{t}}$ cells with edges $\\{x^{\\mathrm{t}}_{0},x^{\\mathrm{t}}_{1},\\dots,x^{\\mathrm{t}}_{N_{\\mathrm{t}}}\\}$ and cell lengths $L^{\\mathrm{t}}_{j}=x^{\\mathrm{t}}_{j+1}-x^{\\mathrm{t}}_{j}$ for $j=0,\\dots,N_{\\mathrm{t}}-1$. The source data are cell averages $\\bar{q}^{\\mathrm{s}}_{i}$, defined by $\\bar{q}^{\\mathrm{s}}_{i}=\\frac{1}{L^{\\mathrm{s}}_{i}}\\int_{x^{\\mathrm{s}}_{i}}^{x^{\\mathrm{s}}_{i+1}}u(x)\\,\\mathrm{d}x$ for some unknown integrable $u(x)$.\n\nYour task is to derive from first principles and implement two linear transfer operators that map the source cell-average vector to a target cell-average vector on a non-matching mesh:\n\n- A conservative operator, assembled from the geometric overlap between source and target cells, which preserves the total integral exactly when the target domain equals the source domain. Starting only from the definition of cell averages and the requirement that total integral be preserved, derive how to assemble this operator using geometric information.\n\n- A non-conservative operator based on nearest cell-center sampling, which assigns to each target cell the value of the source cell average corresponding to the source cell containing the target cell center.\n\nFor both operators, apply them to given source cell-average vectors and assess two properties:\n\n- Conservation: whether $\\sum_{i=0}^{N_{\\mathrm{s}}-1}\\bar{q}^{\\mathrm{s}}_{i}L^{\\mathrm{s}}_{i}$ equals $\\sum_{j=0}^{N_{\\mathrm{t}}-1}\\bar{q}^{\\mathrm{t}}_{j}L^{\\mathrm{t}}_{j}$ within a specified tolerance.\n\n- Boundedness: whether $\\min_{j}\\bar{q}^{\\mathrm{t}}_{j}\\ge \\min_{i}\\bar{q}^{\\mathrm{s}}_{i}$ and $\\max_{j}\\bar{q}^{\\mathrm{t}}_{j}\\le \\max_{i}\\bar{q}^{\\mathrm{s}}_{i}$ within a specified tolerance.\n\nAssume the target domain equals the source domain, and do not use any units; treat all quantities as dimensionless.\n\nImplement a program that:\n\n- Assembles the conservative operator solely from cell-edge coordinates and the cell-length normalization implied by the definition of cell averages.\n\n- Assembles the non-conservative operator by mapping each target cell center $c^{\\mathrm{t}}_{j}=\\frac{1}{2}(x^{\\mathrm{t}}_{j}+x^{\\mathrm{t}}_{j+1})$ to the unique source cell that contains it.\n\n- Applies both operators to the provided source cell-average vectors, and for each case returns booleans for conservation and boundedness.\n\nUse the following test suite of meshes and data:\n\n- Case A (general non-matching, smooth-to-mixed data):\n    - Source edges: $[0.0,\\,0.2,\\,0.5,\\,0.7,\\,1.0]$.\n    - Target edges: $[0.0,\\,0.1,\\,0.4,\\,0.6,\\,0.85,\\,1.0]$.\n    - Source cell averages: $[0.0,\\,1.0,\\,-0.5,\\,2.0]$.\n\n- Case B (boundary alignment, constant data):\n    - Source edges: $[0.0,\\,0.3,\\,0.6,\\,1.0]$.\n    - Target edges: $[0.0,\\,0.3,\\,0.8,\\,1.0]$.\n    - Source cell averages: $[1.0,\\,1.0,\\,1.0]$.\n\n- Case C (extreme size ratios, oscillatory data):\n    - Source edges: $[0.0,\\,0.01,\\,0.02,\\,0.5,\\,1.0]$.\n    - Target edges: $[0.0,\\,0.9,\\,0.95,\\,0.975,\\,1.0]$.\n    - Source cell averages: $[10.0,\\,-10.0,\\,0.0,\\,1.0]$.\n\nFor each case, compute and return in order the following four booleans:\n\n- Conservative operator: conservation check.\n- Conservative operator: boundedness check.\n- Non-conservative operator: conservation check.\n- Non-conservative operator: boundedness check.\n\nUse an absolute tolerance of $\\varepsilon=10^{-12}$ for both conservation and boundedness checks.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain the booleans for Case A followed by Case B followed by Case C, each case contributing four booleans in the order above. For example, a valid output format is $[{\\mathrm{True}},{\\mathrm{False}},{\\mathrm{True}},{\\mathrm{True}},\\dots]$.", "solution": "The problem requires the derivation and implementation of two data transfer operators between non-matching one-dimensional meshes: a conservative operator and a non-conservative nearest-neighbor operator. We will first derive the mathematical formulation of each operator from first principles and analyze their properties regarding conservation and boundedness.\n\nLet the source mesh be defined by a set of $N_{\\mathrm{s}}+1$ strictly increasing edge coordinates $\\{x^{\\mathrm{s}}_{0}, x^{\\mathrm{s}}_{1}, \\dots, x^{\\mathrm{s}}_{N_{\\mathrm{s}}}\\}$ on the interval $[0, 1]$, such that $x^{\\mathrm{s}}_{0}=0$ and $x^{\\mathrm{s}}_{N_{\\mathrm{s}}}=1$. The $i$-th source cell is the interval $[x^{\\mathrm{s}}_{i}, x^{\\mathrm{s}}_{i+1}]$ for $i=0, \\dots, N_{\\mathrm{s}}-1$, with length $L^{\\mathrm{s}}_{i} = x^{\\mathrm{s}}_{i+1} - x^{\\mathrm{s}}_{i}$. The source data are cell averages $\\bar{q}^{\\mathrm{s}}_{i}$ of an unknown integrable function $u(x)$, given by $\\bar{q}^{\\mathrm{s}}_{i} = \\frac{1}{L^{\\mathrm{s}}_{i}} \\int_{x^{\\mathrm{s}}_{i}}^{x^{\\mathrm{s}}_{i+1}} u(x) \\, \\mathrm{d}x$.\n\nSimilarly, the target mesh consists of $N_{\\mathrm{t}}$ cells defined by edges $\\{x^{\\mathrm{t}}_{0}, x^{\\mathrm{t}}_{1}, \\dots, x^{\\mathrm{t}}_{N_{\\mathrm{t}}}\\}$ on $[0, 1]$, with $x^{\\mathrm{t}}_{0}=0$ and $x^{\\mathrm{t}}_{N_{\\mathrm{t}}}=1$. The $j$-th target cell is $[x^{\\mathrm{t}}_{j}, x^{\\mathrm{t}}_{j+1}]$ with length $L^{\\mathrm{t}}_{j} = x^{\\mathrm{t}}_{j+1} - x^{\\mathrm{t}}_{j}$. Our goal is to compute the target cell averages $\\bar{q}^{\\mathrm{t}}_{j} = \\frac{1}{L^{\\mathrm{t}}_{j}} \\int_{x^{\\mathrm{t}}_{j}}^{x^{\\mathrm{t}}_{j+1}} u(x) \\, \\mathrm{d}x$.\n\n**1. Conservative Operator**\n\nThe derivation of the conservative operator begins with the fundamental definition of the target cell average $\\bar{q}^{\\mathrm{t}}_{j}$:\n$$ \\bar{q}^{\\mathrm{t}}_{j} = \\frac{1}{L^{\\mathrm{t}}_{j}} \\int_{x^{\\mathrm{t}}_{j}}^{x^{\\mathrm{t}}_{j+1}} u(x) \\, \\mathrm{d}x $$\nSince $u(x)$ is unknown, we must approximate it using the available source data. A common choice in finite volume methods, which naturally leads to a conservative scheme, is to reconstruct $u(x)$ as a piecewise-constant function, where the constant value in each source cell $i$ is its cell average, $\\bar{q}^{\\mathrm{s}}_{i}$. Let this reconstructed function be $\\tilde{u}(x)$:\n$$ \\tilde{u}(x) = \\sum_{i=0}^{N_{\\mathrm{s}}-1} \\bar{q}^{\\mathrm{s}}_{i} \\cdot \\mathbf{1}_{[x^{\\mathrm{s}}_{i}, x^{\\mathrm{s}}_{i+1}]}(x) $$\nwhere $\\mathbf{1}_{A}(x)$ is the indicator function, equal to $1$ if $x \\in A$ and $0$ otherwise.\n\nSubstituting $\\tilde{u}(x)$ for $u(x)$ in the integral for $\\bar{q}^{\\mathrm{t}}_{j}$:\n$$ \\bar{q}^{\\mathrm{t}}_{j} \\approx \\frac{1}{L^{\\mathrm{t}}_{j}} \\int_{x^{\\mathrm{t}}_{j}}^{x^{\\mathrm{t}}_{j+1}} \\left( \\sum_{i=0}^{N_{\\mathrm{s}}-1} \\bar{q}^{\\mathrm{s}}_{i} \\cdot \\mathbf{1}_{[x^{\\mathrm{s}}_{i}, x^{\\mathrm{s}}_{i+1}]}(x) \\right) \\mathrm{d}x $$\nBy linearity of the integral, we can swap the summation and integration:\n$$ \\bar{q}^{\\mathrm{t}}_{j} = \\frac{1}{L^{\\mathrm{t}}_{j}} \\sum_{i=0}^{N_{\\mathrm{s}}-1} \\bar{q}^{\\mathrm{s}}_{i} \\int_{x^{\\mathrm{t}}_{j}}^{x^{\\mathrm{t}}_{j+1}} \\mathbf{1}_{[x^{\\mathrm{s}}_{i}, x^{\\mathrm{s}}_{i+1}]}(x) \\, \\mathrm{d}x $$\nThe integral term represents the length of the intersection between source cell $i$ and target cell $j$. Let this intersection length be $\\Delta L_{ij}$:\n$$ \\Delta L_{ij} = \\text{length}([x^{\\mathrm{s}}_{i}, x^{\\mathrm{s}}_{i+1}] \\cap [x^{\\mathrm{t}}_{j}, x^{\\mathrm{t}}_{j+1}]) = \\max(0, \\min(x^{\\mathrm{s}}_{i+1}, x^{\\mathrm{t}}_{j+1}) - \\max(x^{\\mathrm{s}}_{i}, x^{\\mathrm{t}}_{j})) $$\nThe formula for the target cell average becomes:\n$$ \\bar{q}^{\\mathrm{t}}_{j} = \\sum_{i=0}^{N_{\\mathrm{s}}-1} \\left( \\frac{\\Delta L_{ij}}{L^{\\mathrm{t}}_{j}} \\right) \\bar{q}^{\\mathrm{s}}_{i} $$\nThis is a linear transformation from the source vector $\\bar{\\mathbf{q}}^{\\mathrm{s}}$ to the target vector $\\bar{\\mathbf{q}}^{\\mathrm{t}}$, $\\bar{\\mathbf{q}}^{\\mathrm{t}} = M \\bar{\\mathbf{q}}^{\\mathrm{s}}$, where the transfer matrix $M$ has entries $M_{ji} = \\frac{\\Delta L_{ij}}{L^{\\mathrm{t}}_{j}}$.\n\n**Conservation Analysis**: Conservation requires that the total integral of the quantity is preserved, i.e., $\\sum_{j=0}^{N_{\\mathrm{t}}-1} \\bar{q}^{\\mathrm{t}}_{j} L^{\\mathrm{t}}_{j} = \\sum_{i=0}^{N_{\\mathrm{s}}-1} \\bar{q}^{\\mathrm{s}}_{i} L^{\\mathrm{s}}_{i}$.\nStarting with the left-hand side:\n$$ \\sum_{j=0}^{N_{\\mathrm{t}}-1} \\bar{q}^{\\mathrm{t}}_{j} L^{\\mathrm{t}}_{j} = \\sum_{j=0}^{N_{\\mathrm{t}}-1} L^{\\mathrm{t}}_{j} \\left( \\frac{1}{L^{\\mathrm{t}}_{j}} \\sum_{i=0}^{N_{\\mathrm{s}}-1} \\bar{q}^{\\mathrm{s}}_{i} \\Delta L_{ij} \\right) = \\sum_{j=0}^{N_{\\mathrm{t}}-1} \\sum_{i=0}^{N_{\\mathrm{s}}-1} \\bar{q}^{\\mathrm{s}}_{i} \\Delta L_{ij} $$\nSwapping the order of summation:\n$$ \\sum_{i=0}^{N_{\\mathrm{s}}-1} \\bar{q}^{\\mathrm{s}}_{i} \\left( \\sum_{j=0}^{N_{\\mathrm{t}}-1} \\Delta L_{ij} \\right) $$\nThe inner sum, $\\sum_{j=0}^{N_{\\mathrm{t}}-1} \\Delta L_{ij}$, is the sum of lengths of intersections of source cell $i$ with all target cells. Since the target mesh covers the entire domain $[0, 1]$, this sum is precisely the length of the source cell $i$, i.e., $\\sum_{j=0}^{N_{\\mathrm{t}}-1} \\Delta L_{ij} = L^{\\mathrm{s}}_{i}$. Thus:\n$$ \\sum_{j=0}^{N_{\\mathrm{t}}-1} \\bar{q}^{\\mathrm{t}}_{j} L^{\\mathrm{t}}_{j} = \\sum_{i=0}^{N_{\\mathrm{s}}-1} \\bar{q}^{\\mathrm{s}}_{i} L^{\\mathrm{s}}_{i} $$\nThe operator is therefore conservative by construction.\n\n**Boundedness Analysis**: Boundedness requires $\\min_{j} \\bar{q}^{\\mathrm{t}}_{j} \\ge \\min_{i} \\bar{q}^{\\mathrm{s}}_{i}$ and $\\max_{j} \\bar{q}^{\\mathrm{t}}_{j} \\le \\max_{i} \\bar{q}^{\\mathrm{s}}_{i}$.\nThe formula $\\bar{q}^{\\mathrm{t}}_{j} = \\sum_{i=0}^{N_{\\mathrm{s}}-1} (\\frac{\\Delta L_{ij}}{L^{\\mathrm{t}}_{j}}) \\bar{q}^{\\mathrm{s}}_{i}$ expresses $\\bar{q}^{\\mathrm{t}}_{j}$ as a weighted average of the source values $\\bar{q}^{\\mathrm{s}}_{i}$. The weights are $w_{i} = \\frac{\\Delta L_{ij}}{L^{\\mathrm{t}}_{j}}$.\nThese weights are non-negative, since $\\Delta L_{ij} \\ge 0$ and $L^{\\mathrm{t}}_{j} > 0$.\nThe sum of the weights for a given target cell $j$ is:\n$$ \\sum_{i=0}^{N_{\\mathrm{s}}-1} \\frac{\\Delta L_{ij}}{L^{\\mathrm{t}}_{j}} = \\frac{1}{L^{\\mathrm{t}}_{j}} \\sum_{i=0}^{N_{\\mathrm{s}}-1} \\Delta L_{ij} $$\nThe sum $\\sum_{i} \\Delta L_{ij}$ is the sum of lengths of intersections of target cell $j$ with all source cells, which equals the length of target cell $j$, $L^{\\mathrm{t}}_{j}$. So, $\\sum_{i=0}^{N_{\\mathrm{s}}-1} w_{i} = \\frac{L^{\\mathrm{t}}_{j}}{L^{\\mathrm{t}}_{j}} = 1$.\nSince $\\bar{q}^{\\mathrm{t}}_{j}$ is a convex combination of the values $\\bar{q}^{\\mathrm{s}}_{i}$ (non-negative weights summing to unity), its value must be bounded by the minimum and maximum of the $\\bar{q}^{\\mathrm{s}}_{i}$ values. This property guarantees that the operator is bounded.\n\n**2. Non-Conservative Operator (Nearest Cell-Center Sampling)**\n\nThis operator is defined by a direct value assignment. For each target cell $j$, we first compute its center coordinate $c^{\\mathrm{t}}_{j} = \\frac{1}{2}(x^{\\mathrm{t}}_{j} + x^{\\mathrm{t}}_{j+1})$. We then find the unique source cell $i$ that contains this point, i.e., $x^{\\mathrm{s}}_{i} \\le c^{\\mathrm{t}}_{j} < x^{\\mathrm{s}}_{i+1}$ (or $x^{\\mathrm{s}}_{i} \\le c^{\\mathrm{t}}_{j} \\le x^{\\mathrm{s}}_{i+1}$ for the rightmost cell). The target cell average is then set to the average of that source cell:\n$$ \\bar{q}^{\\mathrm{t}}_{j} = \\bar{q}^{\\mathrm{s}}_{i} \\quad \\text{where } c^{\\mathrm{t}}_{j} \\in [x^{\\mathrm{s}}_{i}, x^{\\mathrm{s}}_{i+1}] $$\n\n**Conservation Analysis**: The total integral on the target mesh is:\n$$ \\sum_{j=0}^{N_{\\mathrm{t}}-1} \\bar{q}^{\\mathrm{t}}_{j} L^{\\mathrm{t}}_{j} = \\sum_{j=0}^{N_{\\mathrm{t}}-1} \\bar{q}^{\\mathrm{s}}_{\\text{map}(j)} L^{\\mathrm{t}}_{j} $$\nwhere $\\text{map}(j)$ is the index of the source cell containing the center of target cell $j$. We can group terms by the source cell index $i$:\n$$ \\sum_{i=0}^{N_{\\mathrm{s}}-1} \\bar{q}^{\\mathrm{s}}_{i} \\left( \\sum_{j \\text{ s.t. } \\text{map}(j)=i} L^{\\mathrm{t}}_{j} \\right) $$\nThe term in the parenthesis is the sum of the lengths of all target cells whose centers fall within source cell $i$. This sum is not, in general, equal to the length of the source cell $i$, $L^{\\mathrm{s}}_{i}$. Therefore, the total integral is not preserved, and the operator is non-conservative.\n\n**Boundedness Analysis**: For any target cell $j$, the value $\\bar{q}^{\\mathrm{t}}_{j}$ is simply a copy of one of the source values $\\bar{q}^{\\mathrm{s}}_{i}$. This means the set of all target values $\\{\\bar{q}^{\\mathrm{t}}_{j}\\}_{j=0}^{N_{\\mathrm{t}}-1}$ is a subset of the set of all source values $\\{\\bar{q}^{\\mathrm{s}}_{i}\\}_{i=0}^{N_{\\mathrm{s}}-1}$. Consequently, the minimum of the target values cannot be less than the minimum of the source values, and the maximum of the target values cannot be greater than the maximum of the source values. The operator is therefore inherently bounded.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives, implements, and tests conservative and non-conservative\n    interpolation operators between non-matching 1D meshes.\n    \"\"\"\n    test_cases = [\n        # Case A (general non-matching, smooth-to-mixed data)\n        {\n            \"s_edges\": [0.0, 0.2, 0.5, 0.7, 1.0],\n            \"t_edges\": [0.0, 0.1, 0.4, 0.6, 0.85, 1.0],\n            \"s_data\": [0.0, 1.0, -0.5, 2.0],\n        },\n        # Case B (boundary alignment, constant data)\n        {\n            \"s_edges\": [0.0, 0.3, 0.6, 1.0],\n            \"t_edges\": [0.0, 0.3, 0.8, 1.0],\n            \"s_data\": [1.0, 1.0, 1.0],\n        },\n        # Case C (extreme size ratios, oscillatory data)\n        {\n            \"s_edges\": [0.0, 0.01, 0.02, 0.5, 1.0],\n            \"t_edges\": [0.0, 0.9, 0.95, 0.975, 1.0],\n            \"s_data\": [10.0, -10.0, 0.0, 1.0],\n        }\n    ]\n\n    tolerance = 1e-12\n    all_results = []\n\n    for case in test_cases:\n        s_edges = np.array(case[\"s_edges\"], dtype=float)\n        t_edges = np.array(case[\"t_edges\"], dtype=float)\n        s_data = np.array(case[\"s_data\"], dtype=float)\n\n        s_lens = np.diff(s_edges)\n        t_lens = np.diff(t_edges)\n        \n        num_s_cells = len(s_data)\n        num_t_cells = len(t_lens)\n\n        s_integral = np.sum(s_data * s_lens)\n        s_min, s_max = np.min(s_data), np.max(s_data)\n        \n        # 1. Conservative Operator\n        \n        # Assemble transfer matrix M_ji = overlap(s_i, t_j) / L_t_j\n        transfer_matrix_cons = np.zeros((num_t_cells, num_s_cells))\n        for j in range(num_t_cells):\n            t_start, t_end = t_edges[j], t_edges[j+1]\n            for i in range(num_s_cells):\n                s_start, s_end = s_edges[i], s_edges[i+1]\n                \n                # Calculate intersection length\n                overlap = max(0.0, min(s_end, t_end) - max(s_start, t_start))\n                \n                if t_lens[j] > 0:\n                    transfer_matrix_cons[j, i] = overlap / t_lens[j]\n\n        # Apply operator\n        t_data_cons = transfer_matrix_cons @ s_data\n        \n        # Check properties for conservative operator\n        t_integral_cons = np.sum(t_data_cons * t_lens)\n        cons_is_conserved = abs(s_integral - t_integral_cons) <= tolerance\n        \n        t_min_cons = np.min(t_data_cons) if t_data_cons.size > 0 else 0\n        t_max_cons = np.max(t_data_cons) if t_data_cons.size > 0 else 0\n        \n        cons_is_bounded = (t_min_cons >= s_min - tolerance) and \\\n                          (t_max_cons <= s_max + tolerance)\n\n        all_results.extend([cons_is_conserved, cons_is_bounded])\n\n        # 2. Non-Conservative Operator (Nearest Cell-Center)\n        \n        t_centers = (t_edges[:-1] + t_edges[1:]) / 2.0\n        \n        # Find the index of the source cell containing each target center\n        # np.searchsorted with side='right' finds insertion points to maintain order.\n        # For a value v and array a, it finds i such that a[:i] <= v < a[i:].\n        # Subtracting 1 gives the index of the interval.\n        s_indices = np.searchsorted(s_edges, t_centers, side='right') - 1\n        \n        # The above can yield -1 or num_s_cells if t_centers are outside s_edges range.\n        # Although problem states domains match, clip for robustness.\n        s_indices = np.clip(s_indices, 0, num_s_cells - 1)\n        \n        # Apply operator\n        t_data_noncons = s_data[s_indices]\n        \n        # Check properties for non-conservative operator\n        t_integral_noncons = np.sum(t_data_noncons * t_lens)\n        noncons_is_conserved = abs(s_integral - t_integral_noncons) <= tolerance\n        \n        t_min_noncons = np.min(t_data_noncons) if t_data_noncons.size > 0 else 0\n        t_max_noncons = np.max(t_data_noncons) if t_data_noncons.size > 0 else 0\n        \n        noncons_is_bounded = (t_min_noncons >= s_min - tolerance) and \\\n                             (t_max_noncons <= s_max + tolerance)\n                             \n        all_results.extend([noncons_is_conserved, noncons_is_bounded])\n        \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "3501827"}, {"introduction": "Building on the fundamentals, this practice situates the concept of conservation within a concrete physical application: radiative heat transfer [@problem_id:3501781]. You will map view factor data between two different discretizations and evaluate how well each method preserves the fundamental energy balance condition, which requires that the sum of view factors from an emitter must equal one. This exercise highlights the direct impact of numerical transfer schemes on the physical consistency of a multiphysics simulation.", "problem": "Consider a parameterized radiative exchange over a one-dimensional, dimensionless arc-length domain $x \\in [0,1]$ that represents the receiving part of an enclosure. For each emitting patch $i$, the directional view factor density $f_i(x) \\ge 0$ is defined as a nonnegative function satisfying the normalization condition\n$$\n\\int_0^1 f_i(x)\\,dx = 1.\n$$\nFor a donor partition of the receiving domain into intervals $\\{I^{(d)}_\\alpha\\}_{\\alpha=1}^{N_d}$ and a receiver partition $\\{I^{(r)}_\\beta\\}_{\\beta=1}^{N_r}$, the donor view factors are defined by\n$$\nF^{(d)}_{i\\alpha} = \\int_{I^{(d)}_\\alpha} f_i(x)\\,dx,\n$$\nso that the net balance condition holds for each emitter $i$,\n$$\n\\sum_{\\alpha=1}^{N_d} F^{(d)}_{i\\alpha} = 1.\n$$\nThe task is to map the donor view factors $\\{F^{(d)}_{i\\alpha}\\}$ to the receiver partition to obtain $\\{F^{(r)}_{i\\beta}\\}$ using two methods:\n- Non-conservative nearest-element sampling: Construct a piecewise-constant approximation $g_i(x)$ to $f_i(x)$ on the donor mesh by setting $g_i(x) = F^{(d)}_{i\\alpha}/|I^{(d)}_\\alpha|$ for $x \\in I^{(d)}_\\alpha$. For each receiver interval $I^{(r)}_\\beta$, let $c_\\beta$ be its center. Find the donor interval $I^{(d)}_{\\alpha^\\ast}$ whose center is closest to $c_\\beta$, then set\n$$\nF^{(r,\\mathrm{NC})}_{i\\beta} = g_i(c_\\beta)\\,|I^{(r)}_\\beta|.\n$$\n- Conservative overlap integration: Using the same $g_i(x)$, set\n$$\nF^{(r,\\mathrm{C})}_{i\\beta} = \\int_{I^{(r)}_\\beta} g_i(x)\\,dx = \\sum_{\\alpha=1}^{N_d} \\left(\\frac{F^{(d)}_{i\\alpha}}{|I^{(d)}_\\alpha|}\\right)\\,\\left|I^{(r)}_\\beta \\cap I^{(d)}_\\alpha\\right|.\n$$\nDefine the net radiative balance error for emitter $i$ under each method by\n$$\ne^{(\\mathrm{NC})}_i = \\left|\\sum_{\\beta=1}^{N_r} F^{(r,\\mathrm{NC})}_{i\\beta} - 1\\right|,\\quad e^{(\\mathrm{C})}_i = \\left|\\sum_{\\beta=1}^{N_r} F^{(r,\\mathrm{C})}_{i\\beta} - 1\\right|.\n$$\nYour program must:\n- For each test case below, build $\\{F^{(d)}_{i\\alpha}\\}_{\\alpha}$ by numerically integrating the given $f_i(x)$ over donor intervals, ensuring the normalization condition $\\int_0^1 f_i(x)\\,dx = 1$ holds for each $i$.\n- Map $\\{F^{(d)}_{i\\alpha}\\}$ to $\\{F^{(r)}_{i\\beta}\\}$ using both the non-conservative and conservative methods defined above.\n- Compute $e^{(\\mathrm{NC})}_i$ and $e^{(\\mathrm{C})}_i$ for all emitters $i$ in the case, then report the maximum error over emitters for each method, i.e., $\\max_i e^{(\\mathrm{NC})}_i$ and $\\max_i e^{(\\mathrm{C})}_i$.\n\nUse dimensionless units throughout and express all outputs as floating-point numbers. No angles are involved. The following test suite must be implemented:\n\n- Test Case $1$:\n  - Donor interval edges: $[0,\\,0.4,\\,1.0]$.\n  - Receiver interval edges: $[0,\\,0.3,\\,0.6,\\,1.0]$.\n  - Emitters with densities:\n    - $f_1(x) = \\exp\\!\\left(-\\dfrac{(x-0.7)^2}{2\\cdot 0.1^2}\\right)$,\n    - $f_2(x) = 1$,\n    - $f_3(x) = x + 0.1$.\n\n- Test Case $2$:\n  - Donor interval edges: $[0,\\,0.2,\\,0.4,\\,0.6,\\,0.8,\\,1.0]$.\n  - Receiver interval edges: $[0,\\,0.55,\\,1.0]$.\n  - Emitters with densities:\n    - $f_1(x) = \\sin^2(8\\pi x)$,\n    - $f_2(x) = \\exp\\!\\left(-\\dfrac{(x-0.1)^2}{2\\cdot 0.05^2}\\right)$.\n\n- Test Case $3$:\n  - Donor interval edges: $[0,\\,0.15,\\,0.22,\\,0.5,\\,0.51,\\,0.9,\\,1.0]$.\n  - Receiver interval edges: $[0,\\,0.02,\\,0.25,\\,0.49,\\,0.76,\\,1.0]$.\n  - Emitters with densities:\n    - $f_1(x) = 0.5 + 2x(1-x)$,\n    - $f_2(x) = \\exp\\!\\left(-\\dfrac{(x-0.95)^2}{2\\cdot 0.02^2}\\right)$.\n\n- Test Case $4$:\n  - Donor interval edges: $[0,\\,0.31,\\,0.32,\\,0.7,\\,1.0]$.\n  - Receiver interval edges: $[0,\\,0.29,\\,0.33,\\,0.68,\\,1.0]$.\n  - Emitters with densities:\n    - $f_1(x) = 1$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case result must be a two-element list containing the maximum error for the non-conservative method and the maximum error for the conservative method in that order. For example, your output should look like $[[a_1,b_1],[a_2,b_2],[a_3,b_3],[a_4,b_4]]$ where $a_k$ and $b_k$ are floating-point numbers for Test Case $k$.", "solution": "The problem requires the comparison of two distinct numerical schemes for transferring data—specifically, view factors representing radiative exchange—between two non-matching one-dimensional meshes. The core task is to evaluate the conservation property of each scheme. A scheme is considered conservative if the total quantity transferred to the receiver mesh equals the total quantity from the donor mesh.\n\nThe fundamental principle being examined is the conservation of a physical quantity during its numerical transport across discretized domains. In this context, the quantity is the total view factor from a given emitter $i$, which is normalized to unity according to the condition $\\int_0^1 f_i(x)\\,dx = 1$. The total view factor on the donor mesh, $\\sum_{\\alpha=1}^{N_d} F^{(d)}_{i\\alpha}$, and the total view factor on the receiver mesh, $\\sum_{\\beta=1}^{N_r} F^{(r)}_{i\\beta}$, must both equal $1$ for the energy balance to be maintained. The error metrics, $e^{(\\mathrm{NC})}_i$ and $e^{(\\mathrm{C})}_i$, quantify the deviation from this required balance for each mapping method.\n\nThe procedural steps to solve this problem for each emitter $i$ are as follows:\n\n1.  **Normalization of the Density Function**: The provided functions, which we may denote as $f_{i,\\text{given}}(x)$, are proportional to the view factor density. To serve as a valid density, each must be normalized over the domain $x \\in [0,1]$. We compute the normalization constant $C_i = \\int_0^1 f_{i,\\text{given}}(x)\\,dx$. The correct, normalized view factor density is then $f_i(x) = f_{i,\\text{given}}(x) / C_i$. This ensures that $\\int_0^1 f_i(x)\\,dx = 1$, a foundational requirement. This integration is performed numerically using a high-precision quadrature method.\n\n2.  **Discretization on the Donor Mesh**: The continuous density $f_i(x)$ is discretized onto the donor partition $\\{I^{(d)}_\\alpha\\}_{\\alpha=1}^{N_d}$. The donor view factor for each interval $I^{(d)}_\\alpha$ is calculated by integrating the normalized density over that interval: $F^{(d)}_{i\\alpha} = \\int_{I^{(d)}_\\alpha} f_i(x)\\,dx$. By construction, the sum of these discrete view factors over the entire donor mesh is $\\sum_{\\alpha=1}^{N_d} F^{(d)}_{i\\alpha} = \\sum_{\\alpha=1}^{N_d} \\int_{I^{(d)}_\\alpha} f_i(x)\\,dx = \\int_0^1 f_i(x)\\,dx = 1$.\n\n3.  **Piecewise-Constant Reconstruction**: Both mapping methods are based on a piecewise-constant approximation, $g_i(x)$, of the original density function $f_i(x)$. This approximation is constructed from the discrete donor view factors. On each donor interval $I^{(d)}_\\alpha$, the function $g_i(x)$ is assigned a constant value equal to the average density over that interval: $g_i(x) = F^{(d)}_{i\\alpha} / |I^{(d)}_\\alpha|$ for $x \\in I^{(d)}_\\alpha$.\n\n4.  **Mapping to the Receiver Mesh**: The discrete data is then transferred from the donor mesh to the receiver mesh $\\{I^{(r)}_\\beta\\}_{\\beta=1}^{N_r}$ using the two specified methods.\n\n    a.  **Non-Conservative Nearest-Element Sampling**: This method is a form of point sampling. For each receiver interval $I^{(r)}_\\beta$, its center $c_\\beta$ is located. We then identify the donor interval $I^{(d)}_{\\alpha^\\ast}$ whose center $c_{\\alpha^\\ast}$ is closest to $c_\\beta$. The value of the reconstructed function $g_i(x)$ is sampled at the location corresponding to the center of this donor interval, which is $g_i(c_{\\alpha^\\ast}) = F^{(d)}_{i\\alpha^\\ast}/|I^{(d)}_{\\alpha^\\ast}|$. This sampled value is then treated as constant over the entire receiver interval $I^{(r)}_\\beta$, yielding the receiver view factor $F^{(r,\\mathrm{NC})}_{i\\beta} = \\left(F^{(d)}_{i\\alpha^\\ast}/|I^{(d)}_{\\alpha^\\ast}|\\right) \\cdot |I^{(r)}_\\beta|$. This method is computationally efficient but generally non-conservative because the sum $\\sum_{\\beta=1}^{N_r} F^{(r,\\mathrm{NC})}_{i\\beta}$ is not guaranteed to equal $1$. A minor ambiguity exists in the problem statement regarding tie-breaking if a receiver center is equidistant from two or more donor centers; a deterministic rule, such as selecting the one with the smallest index, is adopted.\n\n    b.  **Conservative Overlap Integration**: This method computes the receiver view factor $F^{(r,\\mathrm{C})}_{i\\beta}$ by integrating the piecewise-constant function $g_i(x)$ over the receiver interval $I^{(r)}_\\beta$. The integral is calculated as a sum of contributions from each donor interval $I^{(d)}_\\alpha$ that overlaps with $I^{(r)}_\\beta$:\n    $$ F^{(r,\\mathrm{C})}_{i\\beta} = \\int_{I^{(r)}_\\beta} g_i(x)\\,dx = \\sum_{\\alpha=1}^{N_d} \\left(\\frac{F^{(d)}_{i\\alpha}}{|I^{(d)}_\\alpha|}\\right)\\,\\left|I^{(r)}_\\beta \\cap I^{(d)}_\\alpha\\right| $$\n    where $|I^{(r)}_\\beta \\cap I^{(d)}_\\alpha|$ is the length of the intersection of the two intervals. This method is inherently conservative, as can be demonstrated by summing the receiver view factors:\n    $$ \\sum_{\\beta=1}^{N_r} F^{(r,\\mathrm{C})}_{i\\beta} = \\sum_{\\beta=1}^{N_r} \\sum_{\\alpha=1}^{N_d} \\left(\\frac{F^{(d)}_{i\\alpha}}{|I^{(d)}_\\alpha|}\\right)\\,\\left|I^{(r)}_\\beta \\cap I^{(d)}_\\alpha\\right| $$\n    By swapping the order of summation:\n    $$ = \\sum_{\\alpha=1}^{N_d} \\frac{F^{(d)}_{i\\alpha}}{|I^{(d)}_\\alpha|} \\sum_{\\beta=1}^{N_r} \\left|I^{(r)}_\\beta \\cap I^{(d)}_\\alpha\\right| $$\n    Since $\\{I^{(r)}_\\beta\\}$ forms a partition of the domain $[0,1]$, the sum of the intersection lengths with any given donor interval $I^{(d)}_\\alpha$ equals the length of the donor interval itself: $\\sum_{\\beta=1}^{N_r} |I^{(r)}_\\beta \\cap I^{(d)}_\\alpha| = |I^{(d)}_\\alpha|$. Substituting this gives:\n    $$ = \\sum_{\\alpha=1}^{N_d} \\frac{F^{(d)}_{i\\alpha}}{|I^{(d)}_\\alpha|} |I^{(d)}_\\alpha| = \\sum_{\\alpha=1}^{N_d} F^{(d)}_{i\\alpha} = 1 $$\n    Thus, the total view factor is preserved, and the conservation error $e^{(\\mathrm{C})}_i$ is expected to be zero, within the limits of floating-point precision.\n\n5.  **Error Calculation**: Finally, for each emitter $i$ and each method, the total mapped view factor is summed, and its absolute difference from $1$ is computed to find the net radiative balance errors $e^{(\\mathrm{NC})}_i$ and $e^{(\\mathrm{C})}_i$. The maximum error across all emitters in a test case is reported for each method.\n\nThe implementation will utilize numerical quadrature from the `scipy.integrate` library for accurate integration and array manipulation capabilities from `numpy` to handle the mesh data structures and calculations efficiently.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import integrate\n\ndef solve():\n    \"\"\"\n    Solves the problem of comparing non-conservative and conservative data transfer\n    methods between non-matching meshes.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"d_edges\": [0.0, 0.4, 1.0],\n            \"r_edges\": [0.0, 0.3, 0.6, 1.0],\n            \"funcs\": [\n                lambda x: np.exp(-(x - 0.7)**2 / (2 * 0.1**2)),\n                lambda x: 1.0,\n                lambda x: x + 0.1,\n            ]\n        },\n        {\n            \"d_edges\": [0.0, 0.2, 0.4, 0.6, 0.8, 1.0],\n            \"r_edges\": [0.0, 0.55, 1.0],\n            \"funcs\": [\n                lambda x: np.sin(8 * np.pi * x)**2,\n                lambda x: np.exp(-(x - 0.1)**2 / (2 * 0.05**2)),\n            ]\n        },\n        {\n            \"d_edges\": [0.0, 0.15, 0.22, 0.5, 0.51, 0.9, 1.0],\n            \"r_edges\": [0.0, 0.02, 0.25, 0.49, 0.76, 1.0],\n            \"funcs\": [\n                lambda x: 0.5 + 2 * x * (1 - x),\n                lambda x: np.exp(-(x - 0.95)**2 / (2 * 0.02**2)),\n            ]\n        },\n        {\n            \"d_edges\": [0.0, 0.31, 0.32, 0.7, 1.0],\n            \"r_edges\": [0.0, 0.29, 0.33, 0.68, 1.0],\n            \"funcs\": [\n                lambda x: 1.0,\n            ]\n        },\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        d_edges = np.array(case[\"d_edges\"])\n        r_edges = np.array(case[\"r_edges\"])\n        funcs = case[\"funcs\"]\n\n        d_intervals = list(zip(d_edges[:-1], d_edges[1:]))\n        d_lengths = np.diff(d_edges)\n        d_centers = (d_edges[:-1] + d_edges[1:]) / 2.0\n\n        r_intervals = list(zip(r_edges[:-1], r_edges[1:]))\n        r_lengths = np.diff(r_edges)\n        r_centers = (r_edges[:-1] + r_edges[1:]) / 2.0\n\n        max_err_nc = 0.0\n        max_err_c = 0.0\n\n        for f_unnormalized in funcs:\n            # 1. Normalize the density function\n            norm_const, _ = integrate.quad(f_unnormalized, 0, 1)\n            f_normalized = lambda x: f_unnormalized(x) / norm_const\n\n            # 2. Calculate donor view factors F_i_alpha\n            F_d = np.array([integrate.quad(f_normalized, start, end)[0] for start, end in d_intervals])\n\n            # 3. Construct piecewise-constant approximation g_i(x)\n            g_i_vals = F_d / d_lengths\n\n            # 4a. Non-conservative mapping\n            total_F_r_nc = 0.0\n            for r_center, r_len in zip(r_centers, r_lengths):\n                # Find the closest donor center\n                dists = np.abs(d_centers - r_center)\n                alpha_star = np.argmin(dists)\n                \n                F_r_nc_beta = g_i_vals[alpha_star] * r_len\n                total_F_r_nc += F_r_nc_beta\n            \n            err_nc = abs(total_F_r_nc - 1.0)\n            if err_nc > max_err_nc:\n                max_err_nc = err_nc\n\n            # 4b. Conservative mapping\n            total_F_r_c = 0.0\n            for r_int_start, r_int_end in r_intervals:\n                F_r_c_beta = 0.0\n                for alpha_idx, (d_int_start, d_int_end) in enumerate(d_intervals):\n                    # Calculate intersection length\n                    overlap_start = max(r_int_start, d_int_start)\n                    overlap_end = min(r_int_end, d_int_end)\n                    intersection_len = max(0, overlap_end - overlap_start)\n                    \n                    if intersection_len > 0:\n                        F_r_c_beta += g_i_vals[alpha_idx] * intersection_len\n                \n                total_F_r_c += F_r_c_beta\n                \n            err_c = abs(total_F_r_c - 1.0)\n            if err_c > max_err_c:\n                max_err_c = err_c\n        \n        all_results.append([max_err_nc, max_err_c])\n\n    # Final print statement in the exact required format.\n    # The replace(' ', '') is to match the no-space format in the problem example.\n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n\n```", "id": "3501781"}, {"introduction": "This final practice addresses a common and challenging scenario in numerical simulation: transferring data with sharp gradients or discontinuities. You will contrast a high-order interpolation method, which can introduce unphysical oscillations (Gibbs phenomenon), with a sophisticated conservative scheme that employs a slope limiter to ensure monotonicity [@problem_id:3501733]. This exercise demonstrates how to build robust transfer operators that not only conserve quantities but also preserve the qualitative features of the data, a critical requirement for stability and accuracy in many multiphysics problems.", "problem": "Consider one-dimensional data transfer across a non-matching interface between two computational meshes in a multiphysics coupled simulation. Let the physical domain be the closed interval $[0,1]$. A source mesh partitions $[0,1]$ into $N_s$ cells with edges $\\{x^s_0, x^s_1, \\dots, x^s_{N_s}\\}$, $x^s_0 = 0$, $x^s_{N_s} = 1$, and a target mesh partitions $[0,1]$ into $N_t$ cells with edges $\\{x^t_0, x^t_1, \\dots, x^t_{N_t}\\}$, $x^t_0 = 0$, $x^t_{N_t} = 1$. Denote source cell $i$ by $[x^s_i, x^s_{i+1}]$ and target cell $j$ by $[x^t_j, x^t_{j+1}]$. Define source cell centers $c^s_i = \\frac{1}{2}(x^s_i + x^s_{i+1})$ and target cell centers $c^t_j = \\frac{1}{2}(x^t_j + x^t_{j+1})$, and cell lengths $\\Delta x^s_i = x^s_{i+1} - x^s_i$, $\\Delta x^t_j = x^t_{j+1} - x^t_j$.\n\nThe known source field is specified as cell averages $\\bar{u}^s_i$, interpreted as the average of an underlying scalar field $u(x)$ over each source cell:\n$$\n\\bar{u}^s_i = \\frac{1}{\\Delta x^s_i} \\int_{x^s_i}^{x^s_{i+1}} u(x)\\,dx.\n$$\nFor this problem, let $u(x)$ be a unit Heaviside step located at position $x_\\star \\in (0,1)$, that is, $u(x) = 0$ for $x < x_\\star$ and $u(x) = 1$ for $x \\ge x_\\star$.\n\nTwo distinct data transfer methods must be implemented:\n\n1. A non-conservative high-order interpolation method that maps $\\bar{u}^s_i$ defined at the source centers $c^s_i$ to pointwise values $v^t_j$ at the target centers $c^t_j$ using a natural cubic spline $S(x)$ fit to the data $\\{(c^s_i, \\bar{u}^s_i)\\}$. The mapped target values are $v^t_j = S(c^t_j)$. Treat $v^t_j$ as the target cell averages for the purpose of diagnostics. This method is expected to produce Gibbs-type oscillations near the discontinuity at $x_\\star$ and is not integral-conservative.\n\n2. A conservative monotonicity-preserving remap using piecewise linear reconstruction with the minimum-modulus (minmod) slope limiter. Define limited slopes $s_i$ at each source cell center by\n$$\ns_i = \\operatorname{minmod}\\left(\\frac{\\bar{u}^s_i - \\bar{u}^s_{i-1}}{c^s_i - c^s_{i-1}},\\; \\frac{\\bar{u}^s_{i+1} - \\bar{u}^s_i}{c^s_{i+1} - c^s_i}\\right),\n$$\nwith boundary slopes $s_0 = 0$ and $s_{N_s-1} = 0$, and where the minimum-modulus function is\n$$\n\\operatorname{minmod}(a,b) = \\begin{cases}\n\\operatorname{sign}(a)\\,\\min(|a|,|b|), & \\text{if } a\\,b > 0,\\\\\n0, & \\text{otherwise}.\n\\end{cases}\n$$\nReconstruct in each source cell $i$ a linear profile\n$$\nu_i(x) = \\bar{u}^s_i + s_i \\left(x - c^s_i\\right), \\quad x \\in [x^s_i, x^s_{i+1}],\n$$\nand define the target cell averages by exact overlap integration of the reconstructed source profiles:\n$$\n\\bar{u}^t_j = \\frac{1}{\\Delta x^t_j} \\sum_{i=0}^{N_s-1} \\int_{\\max(x^t_j, x^s_i)}^{\\min(x^t_{j+1}, x^s_{i+1})} u_i(x)\\,dx,\n$$\nwith the convention that the integral over an empty interval is zero. This method is integral-conservative by construction and, due to the minmod limiter, does not create new extrema and thus avoids Gibbs-type oscillations.\n\nDiagnostics to quantify interface oscillations and conservation must be computed for both methods:\n\n- Discrete integral (total mass) on the source mesh:\n$$\nM_s = \\sum_{i=0}^{N_s-1} \\bar{u}^s_i \\,\\Delta x^s_i.\n$$\n- Discrete integral on the target mesh for the non-conservative method:\n$$\nM_t^{\\mathrm{nc}} = \\sum_{j=0}^{N_t-1} v^t_j \\,\\Delta x^t_j,\n$$\nand for the conservative method:\n$$\nM_t^{\\mathrm{c}} = \\sum_{j=0}^{N_t-1} \\bar{u}^t_j \\,\\Delta x^t_j.\n$$\nReport the absolute conservation errors $E^{\\mathrm{nc}} = |M_t^{\\mathrm{nc}} - M_s|$ and $E^{\\mathrm{c}} = |M_t^{\\mathrm{c}} - M_s|$.\n\n- Oscillation amplitude (overshoot violation) near the interface quantified as follows. For each target center $c^t_j$, find the index $i^\\star$ of the nearest source center, and define the local source envelope\n$$\nm_j^- = \\min\\{\\bar{u}^s_{i^\\star-1}, \\bar{u}^s_{i^\\star}, \\bar{u}^s_{i^\\star+1}\\}, \\quad m_j^+ = \\max\\{\\bar{u}^s_{i^\\star-1}, \\bar{u}^s_{i^\\star}, \\bar{u}^s_{i^\\star+1}\\},\n$$\nwith indices clamped to the valid range. For the non-conservative method, the local violation is\n$$\n\\delta^{\\mathrm{nc}}_j = \\max\\left(0,\\; v^t_j - m_j^+,\\; m_j^- - v^t_j\\right),\n$$\nand for the conservative method, replace $v^t_j$ by $\\bar{u}^t_j$ to obtain $\\delta^{\\mathrm{c}}_j$. Report the oscillation amplitudes $A^{\\mathrm{nc}} = \\max_j \\delta^{\\mathrm{nc}}_j$ and $A^{\\mathrm{c}} = \\max_j \\delta^{\\mathrm{c}}_j$.\n\n- Discrete Total Variation (TV) defined for a sequence $\\{w_k\\}$ by\n$$\n\\operatorname{TV}(\\{w_k\\}) = \\sum_{k=1}^{K-1} |w_k - w_{k-1}|.\n$$\nCompute $\\operatorname{TV}_s = \\operatorname{TV}(\\{\\bar{u}^s_i\\}_{i=0}^{N_s-1})$, $\\operatorname{TV}_t^{\\mathrm{nc}} = \\operatorname{TV}(\\{v^t_j\\}_{j=0}^{N_t-1})$, and $\\operatorname{TV}_t^{\\mathrm{c}} = \\operatorname{TV}(\\{\\bar{u}^t_j\\}_{j=0}^{N_t-1})$. Report TV increases $\\Delta \\operatorname{TV}^{\\mathrm{nc}} = \\operatorname{TV}_t^{\\mathrm{nc}} - \\operatorname{TV}_s$ and $\\Delta \\operatorname{TV}^{\\mathrm{c}} = \\operatorname{TV}_t^{\\mathrm{c}} - \\operatorname{TV}_s$.\n\n- Monotonicity preservation booleans $B^{\\mathrm{nc}}$ and $B^{\\mathrm{c}}$ indicating whether $A^{\\mathrm{nc}} = 0$ and $A^{\\mathrm{c}} = 0$, respectively, within a numerical tolerance.\n\nImplement the above for the following test suite (each case specifies source mesh, target mesh, and $x_\\star$):\n\n- Case $1$ (uniform non-matching meshes, interface at mid-domain): Source mesh uniform with $N_s = 16$; target mesh uniform with $N_t = 21$; step location $x_\\star = 0.5$.\n\n- Case $2$ (nearly checkerboard non-matching meshes, off-center interface): Source mesh with alternating cell lengths pattern $[0.03, 0.07]$ repeated to fill $[0,1]$, trimming the final cell to end exactly at $1$; target mesh with alternating pattern $[0.07, 0.03]$ repeated and trimmed similarly; step location $x_\\star = 0.31$.\n\n- Case $3$ (uniform meshes, interface near boundary): Source mesh uniform with $N_s = 10$; target mesh uniform with $N_t = 12$; step location $x_\\star = 0.05$.\n\nFor each case, compute and return the list\n$$\n\\left[ A^{\\mathrm{nc}},\\; E^{\\mathrm{nc}},\\; \\Delta \\operatorname{TV}^{\\mathrm{nc}},\\; B^{\\mathrm{nc}},\\; A^{\\mathrm{c}},\\; E^{\\mathrm{c}},\\; \\Delta \\operatorname{TV}^{\\mathrm{c}},\\; B^{\\mathrm{c}} \\right].\n$$\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case result is itself a comma-separated list enclosed in square brackets (for example, \"[[c1_result1,c1_result2,...],[c2_result1,c2_result2,...],[c3_result1,c3_result2,...]]\"). All reported quantities are dimensionless real numbers or booleans; no physical units are required. No user input is needed; all parameters are predetermined as above.", "solution": "The problem requires the implementation and comparison of two data transfer methods between non-matching one-dimensional meshes: a non-conservative cubic spline interpolation and a conservative, monotonicity-preserving piecewise linear remap. The performance of these methods will be evaluated on a discontinuous test case (a Heaviside step function) using a suite of diagnostics measuring conservation error, spurious oscillations, and total variation.\n\nFirst, we establish the computational framework. The domain is the interval $[0, 1]$. A source mesh is defined by $N_s+1$ edges $\\{x^s_i\\}_{i=0}^{N_s}$ with $x^s_0=0$ and $x^s_{N_s}=1$, forming $N_s$ cells. Similarly, a target mesh is defined by $N_t+1$ edges $\\{x^t_j\\}_{j=0}^{N_t}$. The source cell $i$ is $[x^s_i, x^s_{i+1}]$ with length $\\Delta x^s_i = x^s_{i+1} - x^s_i$ and center $c^s_i = (x^s_i + x^s_{i+1}) / 2$. Correspondingly, target cell $j$ is $[x^t_j, x^t_{j+1}]$ with length $\\Delta x^t_j$ and center $c^t_j$.\n\nThe underlying data field is a unit Heaviside step function located at $x_\\star \\in (0,1)$:\n$$\nU(x) = \\begin{cases} 0 & x < x_\\star \\\\ 1 & x \\ge x_\\star \\end{cases}\n$$\nThe input to our mapping algorithms is not the continuous function $U(x)$, but its cell-average values over the source mesh, $\\bar{u}^s_i$. These are calculated by integrating $U(x)$ over each source cell:\n$$\n\\bar{u}^s_i = \\frac{1}{\\Delta x^s_i} \\int_{x^s_i}^{x^s_{i+1}} U(x)\\,dx = \\frac{\\max(0, x^s_{i+1} - \\max(x^s_i, x_\\star))}{\\Delta x^s_i}\n$$\nFor any cell $[x^s_i, x^s_{i+1}]$ entirely to the left of $x_\\star$ (i.e., $x^s_{i+1} \\le x_\\star$), $\\bar{u}^s_i=0$. For any cell entirely to the right (i.e., $x^s_i \\ge x_\\star$), $\\bar{u}^s_i=1$. For the single cell that contains $x_\\star$, so that $x^s_i < x_\\star < x^s_{i+1}$, the average value is $\\bar{u}^s_i = (x^s_{i+1}-x_\\star)/\\Delta x^s_i$, which lies strictly between $0$ and $1$.\n\nThe first transfer method is a **non-conservative, high-order interpolation**. We construct a natural cubic spline, denoted $S(x)$, that interpolates the source data pairs $\\{(c^s_i, \\bar{u}^s_i)\\}_{i=0}^{N_s-1}$. A natural spline is defined by the condition that its second derivatives at the endpoints are zero, i.e., $S''(c^s_0)=0$ and $S''(c^s_{N_s-1})=0$. This choice is standard when no other boundary information is known. The data are then transferred to the target mesh by evaluating the spline at the target cell centers:\n$$\nv^t_j = S(c^t_j)\n$$\nFor diagnostic purposes, these pointwise values $v^t_j$ are treated as cell averages for the target mesh. High-order interpolation is known to capture smooth functions accurately but often introduces spurious oscillations (Gibbs phenomenon) near discontinuities, and it does not typically conserve integral quantities.\n\nThe second method is a **conservative, monotonicity-preserving remap**. This method is constructed to conserve the total integral of the quantity and to prevent the creation of new oscillations. It consists of three steps: reconstruction, integration, and averaging. First, a piecewise linear representation of the data, $u_i(x)$, is reconstructed in each source cell $i$:\n$$\nu_i(x) = \\bar{u}^s_i + s_i (x - c^s_i) \\quad \\text{for } x \\in [x^s_i, x^s_{i+1}]\n$$\nTo ensure monotonicity, the slope $s_i$ is calculated using the minimum-modulus (minmod) limiter, which selects the slope of smallest magnitude between the centered-difference slopes to the left and right, or zero if they have opposite signs.\n$$\ns_i = \\operatorname{minmod}\\left(\\frac{\\bar{u}^s_i - \\bar{u}^s_{i-1}}{c^s_i - c^s_{i-1}}, \\frac{\\bar{u}^s_{i+1} - \\bar{u}^s_i}{c^s_{i+1} - c^s_i}\\right) \\quad \\text{for } i \\in [1, N_s-2]\n$$\nwith boundary slopes $s_0 = 0$ and $s_{N_s-1} = 0$. The minmod function is defined as $\\operatorname{minmod}(a,b) = \\operatorname{sign}(a)\\min(|a|, |b|)$ if $ab>0$, and $0$ otherwise. This reconstruction ensures that no new local extrema are created.\n\nNext, the target cell averages $\\bar{u}^t_j$ are obtained by integrating this piecewise linear source reconstruction over each target cell. This is achieved through exact integration over the intersection of each source cell $i$ and target cell $j$:\n$$\n\\bar{u}^t_j = \\frac{1}{\\Delta x^t_j} \\sum_{i=0}^{N_s-1} \\int_{x_\\text{start}}^{x_\\text{end}} u_i(x)\\,dx, \\quad \\text{where } [x_\\text{start}, x_\\text{end}] = [x^t_j, x^t_{j+1}] \\cap [x^s_i, x^s_{i+1}]\n$$\nThe integral of the linear function $u_i(x)$ over an interval $[a,b]$ is given by $[(\\bar{u}^s_i - s_i c^s_i)x + \\frac{1}{2}s_i x^2]_a^b$. Summing these integral contributions over all source cells $i$ for a given target cell $j$ and dividing by the target cell length $\\Delta x^t_j$ completes the conservative transfer. By construction, this method ensures $\\sum_j \\bar{u}^t_j \\Delta x^t_j = \\sum_i \\bar{u}^s_i \\Delta x^s_i$ up to machine precision.\n\nFinally, we compute several diagnostics to quantify the performance.\n- The **absolute conservation errors**, $E^{\\mathrm{nc}} = |M_t^{\\mathrm{nc}} - M_s|$ and $E^{\\mathrm{c}} = |M_t^{\\mathrm{c}} - M_s|$, measure the change in the total integrated quantity, where $M_s = \\sum_i \\bar{u}^s_i \\Delta x^s_i$ and $M_t = \\sum_j \\bar{u}^t_j \\Delta x^t_j$ (using $v^t_j$ for the non-conservative case). We expect $E^{\\mathrm{c}} \\approx 0$.\n- The **oscillation amplitudes**, $A^{\\mathrm{nc}}$ and $A^{\\mathrm{c}}$, measure the degree to which the mapped values violate the local bounds of the source data. For each target cell $j$, a local source envelope $[m_j^-, m_j^+]$ is determined from the minimum and maximum of the source data in the neighborhood of the target cell center. The violation is the amount by which a target value exceeds this envelope. $A$ is the maximum violation across all target cells. We expect $A^{\\mathrm{c}} = 0$, indicating monotonicity, while $A^{\\mathrm{nc}} > 0$. The corresponding booleans $B^{\\mathrm{c}}$ and $B^{\\mathrm{nc}}$ formalize this check.\n- The **change in total variation (TV)**, $\\Delta\\operatorname{TV} = \\operatorname{TV}(\\text{target data}) - \\operatorname{TV}(\\text{source data})$, where $\\operatorname{TV}(\\{w_k\\}) = \\sum_{k} |w_{k+1} - w_k|$. Monotonicity-preserving schemes are expected to be non-increasing in total variation, so we expect $\\Delta\\operatorname{TV}^{\\mathrm{c}} \\le 0$, while the oscillatory spline method will likely increase TV, so $\\Delta\\operatorname{TV}^{\\mathrm{nc}} > 0$.\n\nBy applying these methods and diagnostics to the specified test cases, we can quantitatively demonstrate the fundamental trade-offs between high-order accuracy and the preservation of physical principles like conservation and monotonicity.", "answer": "```python\nimport numpy as np\nfrom scipy.interpolate import CubicSpline\n\ndef generate_mesh(N=None, pattern=None):\n    \"\"\"Generates a mesh on [0,1] either uniformly or from a pattern.\"\"\"\n    if N is not None:  # Uniform mesh\n        edges = np.linspace(0, 1, N + 1)\n    elif pattern is not None:  # Pattern-based mesh\n        edges = [0.0]\n        current_x = 0.0\n        i = 0\n        while current_x < 1.0 - 1e-9: # Loop until we are at or past 1.0\n            current_x += pattern[i % len(pattern)]\n            edges.append(current_x)\n            i += 1\n        edges[-1] = 1.0  # Trim the last edge to be exactly 1.0\n        edges = np.array(edges)\n    else:\n        raise ValueError(\"Either N or pattern must be provided.\")\n    \n    centers = 0.5 * (edges[:-1] + edges[1:])\n    lengths = edges[1:] - edges[:-1]\n    return edges, centers, lengths\n\ndef minmod(a, b):\n    \"\"\"The minmod slope limiter function.\"\"\"\n    return np.sign(a) * np.minimum(np.abs(a), np.abs(b)) * (np.sign(a) == np.sign(b))\n\ndef calculate_tv(data):\n    \"\"\"Computes the total variation of a 1D array.\"\"\"\n    return np.sum(np.abs(np.diff(data)))\n\ndef run_case(case_params):\n    \"\"\"\n    Runs a single test case for data transfer between non-matching meshes.\n    \"\"\"\n    source_mesh_def, target_mesh_def, x_star = case_params\n    \n    # 1. Generate meshes and source data\n    x_s, c_s, dx_s = generate_mesh(**source_mesh_def)\n    x_t, c_t, dx_t = generate_mesh(**target_mesh_def)\n    N_s = len(c_s)\n    N_t = len(c_t)\n\n    # Calculate source cell-average data from Heaviside step function\n    u_s_bar = np.maximum(0, x_s[1:] - np.maximum(x_s[:-1], x_star)) / dx_s\n\n    # 2. Method 1: Non-conservative spline interpolation\n    spline = CubicSpline(c_s, u_s_bar, bc_type='natural')\n    v_t = spline(c_t)\n\n    # 3. Method 2: Conservative piecewise linear remap\n    # 3.1. Calculate limited slopes\n    s = np.zeros(N_s)\n    # Slopes are zero for cells not adjacent to the discontinuity\n    disc_idx = np.where( (u_s_bar > 0) & (u_s_bar < 1) )[0]\n    if len(disc_idx) > 0:\n        idx = disc_idx[0]\n        # Calculate slopes only around the discontinuity.\n        for i in range(max(1, idx - 1), min(N_s - 1, idx + 2)):\n            slope_L = (u_s_bar[i] - u_s_bar[i-1]) / (c_s[i] - c_s[i-1])\n            slope_R = (u_s_bar[i+1] - u_s_bar[i]) / (c_s[i+1] - c_s[i])\n            s[i] = minmod(slope_L, slope_R)\n\n    # 3.2. Overlap integration\n    u_t_bar = np.zeros(N_t)\n    for j in range(N_t):\n        total_integral = 0.0\n        for i in range(N_s):\n            # Find intersection of source cell i and target cell j\n            x_start = np.maximum(x_t[j], x_s[i])\n            x_end = np.minimum(x_t[j+1], x_s[i+1])\n\n            if x_start < x_end:\n                # Indefinite integral: I(x) = (u_bar - s*c)*x + 0.5*s*x^2\n                const_term = u_s_bar[i] - s[i] * c_s[i]\n                integral_val = (const_term * (x_end - x_start) + \n                                0.5 * s[i] * (x_end**2 - x_start**2))\n                total_integral += integral_val\n        u_t_bar[j] = total_integral / dx_t[j]\n\n    # 4. Diagnostics\n    tol = 1e-12\n    \n    # 4.1. Conservation Error\n    M_s = np.sum(u_s_bar * dx_s)\n    M_t_nc = np.sum(v_t * dx_t)\n    M_t_c = np.sum(u_t_bar * dx_t)\n    \n    E_nc = np.abs(M_t_nc - M_s)\n    E_c = np.abs(M_t_c - M_s)\n\n    # 4.2. Oscillation Amplitude\n    # Find nearest source center for each target center\n    dist_matrix = np.abs(c_s.reshape(-1, 1) - c_t.reshape(1, -1))\n    i_star_indices = np.argmin(dist_matrix, axis=0)\n    \n    delta_nc, delta_c = np.zeros(N_t), np.zeros(N_t)\n    for j in range(N_t):\n        i_star = i_star_indices[j]\n        # Clamp indices to valid range\n        idx_min = max(0, i_star - 1)\n        idx_max = min(N_s - 1, i_star + 1)\n        local_u_s = u_s_bar[idx_min : idx_max + 1]\n        \n        m_j_minus = np.min(local_u_s)\n        m_j_plus = np.max(local_u_s)\n        \n        delta_nc[j] = np.max([0, v_t[j] - m_j_plus, m_j_minus - v_t[j]])\n        delta_c[j] = np.max([0, u_t_bar[j] - m_j_plus, m_j_minus - u_t_bar[j]])\n        \n    A_nc = np.max(delta_nc)\n    A_c = np.max(delta_c)\n\n    # 4.3. Total Variation\n    TV_s = calculate_tv(u_s_bar)\n    TV_t_nc = calculate_tv(v_t)\n    TV_t_c = calculate_tv(u_t_bar)\n    \n    dTV_nc = TV_t_nc - TV_s\n    dTV_c = TV_t_c - TV_s\n\n    # 4.4. Monotonicity Booleans\n    B_nc = (A_nc < tol)\n    B_c = (A_c < tol)\n    \n    return [A_nc, E_nc, dTV_nc, B_nc, A_c, E_c, dTV_c, B_c]\n\n\ndef solve():\n    \"\"\"Main function to run all test cases and print results.\"\"\"\n    test_cases = [\n        # Case 1: Uniform non-matching, mid-domain interface\n        ({'N': 16}, {'N': 21}, 0.5),\n        # Case 2: Checkerboard non-matching, off-center interface\n        ({'pattern': [0.03, 0.07]}, {'pattern': [0.07, 0.03]}, 0.31),\n        # Case 3: Uniform, interface near boundary\n        ({'N': 10}, {'N': 12}, 0.05),\n    ]\n\n    results = []\n    for case in test_cases:\n        results.append(run_case(case))\n    \n    # Format the output as specified: [[r1,r2,...],[r1,r2,...],...]\n    str_results = []\n    for res_list in results:\n        # Format each item in the sublist to string\n        # The problem does not specify float precision, so use default str representation\n        # Booleans will be 'True' or 'False'\n        str_items = [str(item) for item in res_list]\n        str_results.append(f\"[{','.join(str_items)}]\")\n        \n    print(f\"[{','.join(str_results)}]\")\n\nsolve()\n\n```", "id": "3501733"}]}