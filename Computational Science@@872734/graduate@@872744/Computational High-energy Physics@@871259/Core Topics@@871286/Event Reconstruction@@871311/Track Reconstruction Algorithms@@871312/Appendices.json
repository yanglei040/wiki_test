{"hands_on_practices": [{"introduction": "The starting point for any track reconstruction is \"seeding,\" which involves identifying small combinations of hits that could form the beginning of a particle's trajectory. In the high-occupancy environments of modern colliders, the combinatorial background of random hit combinations is immense, posing a significant computational challenge. This exercise [@problem_id:3539679] explores a modern technique to suppress this background by incorporating high-precision timing information, guiding you to derive and quantify the powerful constraints offered by the fourth dimension of spacetime.", "problem": "You are designing a three-layer seed-making stage for a charged-particle track reconstruction algorithm in a uniform magnetic field. A seed is a triplet of hits, one from each of three layers indexed by $1$, $2$, and $3$. Each hit carries a space-time coordinate $(x,y,z,t)$, where $t$ is the hit time. Your task is to develop and analyze a timing-aware seeding strategy that uses $t$ as a fourth coordinate to suppress combinatorics from random, spatially compatible hits in high pileup environments, and to derive an analytic scaling of fake seeds versus the timing resolution.\n\nFundamental base and assumptions:\n- Charged particles are ultra-relativistic with speed $v \\approx c$, where $c$ is the speed of light.\n- The time-of-flight difference between layers $i$ and $j$ for a genuine track is approximated by $\\Delta t_{ij} \\approx \\ell_{ij}/c$, where $\\ell_{ij}$ is the geometric path length between the two layers along the track trajectory.\n- Measured hit times are Gaussian distributed around their true values with standard deviation $\\sigma_t$, independent across hits.\n- The predicted time-of-flight difference $\\Delta t_{ij}^{\\mathrm{pred}}$ used in seeding has a modeling uncertainty represented by a Gaussian with standard deviation $\\sigma_{\\mathrm{TOF}}$ (for example due to unknown transverse momentum, path length, or residual alignment).\n- For random, spatially compatible hits from pileup, hit times are independent and uniformly distributed over the bunch-crossing interval of duration $T_{\\mathrm{bx}}$.\n- A timing-aware seed acceptance requires both pairwise residuals to be simultaneously consistent:\n  $$\\left|(t_2 - t_1) - \\Delta t_{12}^{\\mathrm{pred}}\\right| \\le k\\,S \\quad \\text{and} \\quad \\left|(t_3 - t_2) - \\Delta t_{23}^{\\mathrm{pred}}\\right| \\le k\\,S,$$\n  where $k$ is a chosen consistency multiplier (for example, $k=3$ for a three-standard-deviation gate), and\n  $$S = \\sqrt{2\\,\\sigma_t^2 + \\sigma_{\\mathrm{TOF}}^2}.$$\n- The effective number of spatially compatible hits per layer within the geometric seeding windows are $N_1$, $N_2$, and $N_3$. Without timing, the number of candidate triplets scales as $N_1 N_2 N_3$.\n\nProblem requirements:\n1. Starting from the above base, derive an analytic expression for the probability that a triplet of random, spatially compatible hits passes the two timing gates, expressed in terms of $\\sigma_t$, $\\sigma_{\\mathrm{TOF}}$, $T_{\\mathrm{bx}}$, and $k$. For small gates relative to $T_{\\mathrm{bx}}$, use the leading-order approximation for the difference of two independent uniform random variables and justify it. Then give the expected number of fake triplets per event:\n   $$N_{\\mathrm{fake}} \\approx N_1 N_2 N_3 \\, p_{\\mathrm{fake}}(\\sigma_t,\\sigma_{\\mathrm{TOF}},T_{\\mathrm{bx}},k),$$\n   with $p_{\\mathrm{fake}}$ clipped to the interval $[0,1]$ for physical realism.\n2. Using your expression, implement a program that computes $N_{\\mathrm{fake}}$ for the following test suite. All times must be treated in seconds in the computation. Counts are unitless. Use $c$ only in the rationale; it is not needed numerically in the program because $\\Delta t_{ij}^{\\mathrm{pred}}$ is only represented through $\\sigma_{\\mathrm{TOF}}$.\n   - Test case A (happy path): $N_1 = 60$, $N_2 = 80$, $N_3 = 70$, $\\sigma_t = 50\\,\\mathrm{ps}$, $\\sigma_{\\mathrm{TOF}} = 30\\,\\mathrm{ps}$, $T_{\\mathrm{bx}} = 25\\,\\mathrm{ns}$, $k = 3$.\n   - Test case B (high occupancy, good timing): $N_1 = 200$, $N_2 = 220$, $N_3 = 180$, $\\sigma_t = 30\\,\\mathrm{ps}$, $\\sigma_{\\mathrm{TOF}} = 50\\,\\mathrm{ps}$, $T_{\\mathrm{bx}} = 25\\,\\mathrm{ns}$, $k = 3$.\n   - Test case C (poor timing): $N_1 = 60$, $N_2 = 80$, $N_3 = 70$, $\\sigma_t = 300\\,\\mathrm{ps}$, $\\sigma_{\\mathrm{TOF}} = 30\\,\\mathrm{ps}$, $T_{\\mathrm{bx}} = 25\\,\\mathrm{ns}$, $k = 3$.\n   - Test case D (near-ideal timing limited by modeling): $N_1 = 60$, $N_2 = 80$, $N_3 = 70$, $\\sigma_t = 5\\,\\mathrm{ps}$, $\\sigma_{\\mathrm{TOF}} = 30\\,\\mathrm{ps}$, $T_{\\mathrm{bx}} = 25\\,\\mathrm{ns}$, $k = 3$.\n   - Test case E (saturation edge): $N_1 = 60$, $N_2 = 80$, $N_3 = 70$, $\\sigma_t = 10\\,\\mathrm{ns}$, $\\sigma_{\\mathrm{TOF}} = 30\\,\\mathrm{ps}$, $T_{\\mathrm{bx}} = 25\\,\\mathrm{ns}$, $k = 3$.\n3. Your program should produce a single line of output containing the results for cases A–E as a comma-separated list enclosed in square brackets (for example, $[r_A,r_B,r_C,r_D,r_E]$), where each $r_\\cdot$ is the expected number of fake triplets (a float).\n\nAnswer format:\n- Provide a complete derivation and solution.\n- Provide the final answer as a complete, runnable program.", "solution": "The problem statement is evaluated as scientifically sound, well-posed, and objective. It presents a realistic scenario in high-energy physics track reconstruction and requests a standard, albeit non-trivial, probabilistic derivation followed by a numerical implementation. All necessary definitions and parameters are provided, and there are no internal contradictions or violations of physical principles. The problem is therefore deemed **valid**.\n\nThe task is to derive an analytic expression for the probability that a triplet of random, spatially compatible hits forms a \"fake seed\" by passing a set of timing-based cuts. We are then asked to compute the expected number of such fake seeds for several parameter sets.\n\nLet the times of the three hits in layers $1$, $2$, and $3$ be $t_1$, $t_2$, and $t_3$. For a fake seed originating from random pileup interactions, these times are independent and identically distributed random variables, drawn from a uniform distribution over the bunch-crossing interval of duration $T_{\\mathrm{bx}}$. We can model this as $t_i \\sim U(0, T_{\\mathrm{bx}})$ for $i=1, 2, 3$.\n\nThe timing-aware seeding conditions are given as two simultaneous requirements on the pairwise time-of-flight residuals:\n$$\nC_1: \\quad |(t_2 - t_1) - \\Delta t_{12}^{\\mathrm{pred}}| \\le kS\n$$\n$$\nC_2: \\quad |(t_3 - t_2) - \\Delta t_{23}^{\\mathrm{pred}}| \\le kS\n$$\nwhere $k$ is a multiplier, $\\Delta t_{ij}^{\\mathrm{pred}}$ are the predicted time-of-flight differences for a hypothesized track, and $S = \\sqrt{2\\sigma_t^2 + \\sigma_{\\mathrm{TOF}}^2}$ is the total uncertainty on a single time-of-flight residual measurement. For notational convenience, let $W = kS$ be the half-width of the acceptance window. The conditions become:\n$$\nC_1: \\quad |(t_2 - t_1) - \\Delta t_{12}^{\\mathrm{pred}}| \\le W\n$$\n$$\nC_2: \\quad |(t_3 - t_2) - \\Delta t_{23}^{\\mathrm{pred}}| \\le W\n$$\n\nWe need to find the probability, $p_{\\mathrm{fake}}$, that a random triplet of hits satisfies both conditions, i.e., $p_{\\mathrm{fake}} = P(C_1 \\cap C_2)$. Since the hit times $t_1, t_2, t_3$ are independent, their joint probability density function (PDF) is $f(t_1, t_2, t_3) = (1/T_{\\mathrm{bx}})^3$ for $(t_1, t_2, t_3) \\in [0, T_{\\mathrm{bx}}]^3$, and $0$ otherwise. The probability $p_{\\mathrm{fake}}$ is the integral of this joint PDF over the volume in $(t_1, t_2, t_3)$ space defined by the conditions $C_1$ and $C_2$ and the bounds $0 \\le t_i \\le T_{\\mathrm{bx}}$.\n\nLet us define new variables for the time differences: $u_1 = t_2 - t_1$ and $u_2 = t_3 - t_2$. The conditions $C_1$ and $C_2$ are defined on these variables. The time differences $u_1$ and $u_2$ are not independent, as they both depend on $t_2$. To correctly calculate the joint probability, we perform a change of variables from $(t_1, t_2, t_3)$ to $(u_1, u_2, u_3)$, where we can choose $u_3 = t_2$ for simplicity. The inverse transformation is:\n$$\nt_1 = t_2 - (t_2 - t_1) = u_3 - u_1\n$$\n$$\nt_2 = u_3\n$$\n$$\nt_3 = (t_3 - t_2) + t_2 = u_2 + u_3\n$$\nThe Jacobian determinant of this transformation is:\n$$\nJ = \\det \\begin{pmatrix} \\frac{\\partial t_1}{\\partial u_1} & \\frac{\\partial t_1}{\\partial u_2} & \\frac{\\partial t_1}{\\partial u_3} \\\\ \\frac{\\partial t_2}{\\partial u_1} & \\frac{\\partial t_2}{\\partial u_2} & \\frac{\\partial t_2}{\\partial u_3} \\\\ \\frac{\\partial t_3}{\\partial u_1} & \\frac{\\partial t_3}{\\partial u_2} & \\frac{\\partial t_3}{\\partial u_3} \\end{pmatrix} = \\det \\begin{pmatrix} -1 & 0 & 1 \\\\ 0 & 0 & 1 \\\\ 0 & 1 & 1 \\end{pmatrix} = -1(0-1) = 1\n$$\nThe absolute value of the Jacobian is $|J|=1$. The joint PDF in the new coordinates is $f(u_1, u_2, u_3) = (1/T_{\\mathrm{bx}})^3 |J| = 1/T_{\\mathrm{bx}}^3$.\n\nThe probability is the integral over the transformed volume:\n$$\np_{\\mathrm{fake}} = \\iiint \\frac{1}{T_{\\mathrm{bx}}^3} \\, du_1 \\, du_2 \\, du_3\n$$\nThe integration limits are given by the conditions:\n1.  From $C_1$: $\\Delta t_{12}^{\\mathrm{pred}} - W \\le u_1 \\le \\Delta t_{12}^{\\mathrm{pred}} + W$\n2.  From $C_2$: $\\Delta t_{23}^{\\mathrm{pred}} - W \\le u_2 \\le \\Delta t_{23}^{\\mathrm{pred}} + W$\n3.  From $0 \\le t_i \\le T_{\\mathrm{bx}}$:\n    - $0 \\le u_3 - u_1 \\le T_{\\mathrm{bx}} \\implies u_1 \\le u_3 \\le T_{\\mathrm{bx}} + u_1$\n    - $0 \\le u_3 \\le T_{\\mathrm{bx}}$\n    - $0 \\le u_2 + u_3 \\le T_{\\mathrm{bx}} \\implies -u_2 \\le u_3 \\le T_{\\mathrm{bx}} - u_2$\n\nThe problem specifies to use a leading-order approximation for small gates relative to $T_{\\mathrm{bx}}$. This implies $W \\ll T_{\\mathrm{bx}}$. Also, for ultra-relativistic particles crossing a detector, the physical time-of-flight $\\Delta t^{\\mathrm{pred}}$ is very small compared to the bunch crossing interval $T_{\\mathrm{bx}}$. Therefore, the integration variables $u_1$ and $u_2$ are confined to small intervals near zero. This means $|u_1| \\ll T_{\\mathrm{bx}}$ and $|u_2| \\ll T_{\\mathrm{bx}}$.\n\nUnder this approximation, the bounds for $u_3$ simplify. The lower bound becomes $\\max(0, u_1, -u_2) \\approx 0$, and the upper bound becomes $\\min(T_{\\mathrm{bx}}, T_{\\mathrm{bx}}+u_1, T_{\\mathrm{bx}}-u_2) \\approx T_{\\mathrm{bx}}$. The length of the integration interval for $u_3$ is approximately $T_{\\mathrm{bx}}$.\n\nThe integral for $p_{\\mathrm{fake}}$ thus simplifies to:\n$$\np_{\\mathrm{fake}} \\approx \\frac{1}{T_{\\mathrm{bx}}^3} \\int_{\\Delta t_{12}^{\\mathrm{pred}} - W}^{\\Delta t_{12}^{\\mathrm{pred}} + W} du_1 \\int_{\\Delta t_{23}^{\\mathrm{pred}} - W}^{\\Delta t_{23}^{\\mathrm{pred}} + W} du_2 \\int_{0}^{T_{\\mathrm{bx}}} du_3\n$$\n$$\np_{\\mathrm{fake}} \\approx \\frac{1}{T_{\\mathrm{bx}}^3} \\left[ ((\\Delta t_{12}^{\\mathrm{pred}} + W) - (\\Delta t_{12}^{\\mathrm{pred}} - W)) \\times ((\\Delta t_{23}^{\\mathrm{pred}} + W) - (\\Delta t_{23}^{\\mathrm{pred}} - W)) \\times T_{\\mathrm{bx}} \\right]\n$$\n$$\np_{\\mathrm{fake}} \\approx \\frac{1}{T_{\\mathrm{bx}}^3} [ (2W) \\times (2W) \\times T_{\\mathrm{bx}} ] = \\frac{(2W)^2}{T_{\\mathrm{bx}}^2}\n$$\nThis derivation confirms that, in the small-window approximation, the probability of passing the two cuts is equivalent to the product of probabilities of passing each cut independently. The probability of passing a single cut $|(t_i - t_j) - \\Delta t_{ij}^{\\mathrm{pred}}| \\le W$ is the area of a window of width $2W$ under the PDF of the difference of two uniform random variables. This PDF is a triangular distribution on $[-T_{\\mathrm{bx}}, T_{\\mathrm{bx}}]$ with maximum height $1/T_{\\mathrm{bx}}$ at the center. For a small window near the center, the probability is approximately $(2W)/T_{\\mathrm{bx}}$.\n\nSubstituting $W = kS$ and $S^2 = 2\\sigma_t^2 + \\sigma_{\\mathrm{TOF}}^2$, we get:\n$$\np_{\\mathrm{fake}} = \\frac{(2kS)^2}{T_{\\mathrm{bx}}^2} = \\frac{4k^2S^2}{T_{\\mathrm{bx}}^2} = \\frac{4k^2(2\\sigma_t^2 + \\sigma_{\\mathrm{TOF}}^2)}{T_{\\mathrm{bx}}^2}\n$$\nThis approximation is valid as long as $2kS \\ll T_{\\mathrm{bx}}$. If the timing window becomes very large (comparable to or larger than $T_{\\mathrm{bx}}$), the probability of finding a random time difference within it approaches $1$. Therefore, for physical realism, we must clip the calculated probability to the interval $[0, 1]$.\n$$\np_{\\mathrm{fake}}(\\sigma_t, \\sigma_{\\mathrm{TOF}}, T_{\\mathrm{bx}}, k) = \\min\\left(1, \\frac{4k^2(2\\sigma_t^2 + \\sigma_{\\mathrm{TOF}}^2)}{T_{\\mathrm{bx}}^2}\\right)\n$$\nThe expected number of fake triplets, $N_{\\mathrm{fake}}$, is the total number of spatially compatible random triplets, $N_1 N_2 N_3$, multiplied by the probability $p_{\\mathrm{fake}}$ that any one of them passes the timing cuts.\n$$\nN_{\\mathrm{fake}} \\approx N_1 N_2 N_3 \\cdot p_{\\mathrm{fake}}\n$$\n\nWe will now implement this formula to compute $N_{\\mathrm{fake}}$ for the given test cases, ensuring all time units are consistently converted to seconds.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the track reconstruction problem by calculating the expected number of fake seeds.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Format: (N1, N2, N3, sigma_t_ps, sigma_tof_ps, T_bx_ns, k)\n    # Note: sigma_t and sigma_tof are given in ps or ns in the test cases,\n    # and T_bx is in ns. We will convert them to seconds in the calculation.\n    test_cases = [\n        # A: (N1, N2, N3, sigma_t, sigma_tof, T_bx, k)\n        (60, 80, 70, 50, 30, 25, 3),\n        # B:\n        (200, 220, 180, 30, 50, 25, 3),\n        # C:\n        (60, 80, 70, 300, 30, 25, 3),\n        # D:\n        (60, 80, 70, 5, 30, 25, 3),\n        # E: (sigma_t is 10 ns, which is 10000 ps)\n        (60, 80, 70, 10e3, 30, 25, 3),\n    ]\n\n    results = []\n    \n    # Unit conversion factors\n    PS_TO_S = 1e-12  # picoseconds to seconds\n    NS_TO_S = 1e-9   # nanoseconds to seconds\n\n    for case in test_cases:\n        N1, N2, N3, sigma_t_ps, sigma_tof_ps, T_bx_ns, k = case\n\n        # Convert all time values to seconds for consistent calculation\n        sigma_t = sigma_t_ps * PS_TO_S\n        sigma_tof = sigma_tof_ps * PS_TO_S\n        T_bx = T_bx_ns * NS_TO_S\n\n        # Total number of spatially compatible triplets without timing\n        N_cand = N1 * N2 * N3\n\n        # Calculate S^2 = 2*sigma_t^2 + sigma_TOF^2\n        S_squared = 2 * sigma_t**2 + sigma_tof**2\n\n        # Calculate the raw probability based on the derived formula\n        # p_raw = (4 * k^2 * S^2) / T_bx^2\n        p_raw = (4 * k**2 * S_squared) / T_bx**2\n        \n        # The probability must be clipped to the interval [0, 1] for physical realism.\n        # This handles cases where the timing window is larger than the bunch crossing interval.\n        p_fake = min(1.0, p_raw)\n\n        # Calculate the expected number of fake triplets\n        N_fake = N_cand * p_fake\n        \n        results.append(N_fake)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3539679"}, {"introduction": "Once a track candidate exists, we must extend it by associating it with new measurements in subsequent detector layers. This \"data association\" step is rarely a simple one-to-one mapping; a single hit might be a candidate for multiple tracks, a track might be missed by a detector, and many hits are often just spurious noise. This practice [@problem_id:3539732] introduces a rigorous probabilistic approach to resolve these ambiguities by formulating the task as a Maximum a Posteriori (MAP) assignment problem, which can be solved computationally to find the most likely set of track-hit associations.", "problem": "You are given a set of candidate particle tracks extrapolated to a single detector layer and a set of measured hits in the same layer. For each candidate track, you have a predicted two-dimensional position and a covariance that represents the extrapolation uncertainty. The detector provides two-dimensional hit positions, and the measurement noise covariance is known. There is also a uniform clutter model for spurious hits described by a Poisson Point Process (PPP). Your task is to compute association probabilities between tracks and hits based on a principled probabilistic model and then select a one-to-one assignment of hits to tracks under a Maximum a Posteriori (MAP) rule.\n\nFundamental base and physical modeling:\n- Assume the measurement model is a Multivariate Normal (MVN): conditional on a track with predicted position $\\mathbf{x}_i \\in \\mathbb{R}^2$ and extrapolation covariance $\\mathbf{S}_i \\in \\mathbb{R}^{2 \\times 2}$, a true associated hit $\\mathbf{z}_j \\in \\mathbb{R}^2$ is distributed as $\\mathcal{N}(\\mathbf{x}_i, \\mathbf{C}_i)$ where $\\mathbf{C}_i = \\mathbf{S}_i + \\mathbf{R}$ and $\\mathbf{R} \\in \\mathbb{R}^{2 \\times 2}$ is the measurement noise covariance. All positions are expressed in millimeters (mm), and covariances are expressed in square millimeters ($\\mathrm{mm}^2$).\n- Assume a uniform clutter density $\\lambda$ over a known sensor area $A$ (in $\\mathrm{mm}^2$) with an expected number of clutter hits $\\Lambda$ per readout. Then $\\lambda = \\Lambda / A$ has units $\\mathrm{mm}^{-2}$.\n- Each track $i$ has a Probability of Detection (PoD) $P_D^{(i)} \\in (0,1)$ and a prior Probability of Existence $P_T^{(i)} \\in (0,1)$.\n- Use a standard gating rule with a squared Mahalanobis distance $d_{ij}^2 = (\\mathbf{z}_j - \\mathbf{x}_i)^\\top \\mathbf{C}_i^{-1} (\\mathbf{z}_j - \\mathbf{x}_i)$ and a gate threshold $\\gamma > 0$. An association $(i,j)$ is admissible only if $d_{ij}^2 \\le \\gamma$.\n\nAssociation probabilities:\n- For an admissible pair $(i,j)$, define the local likelihood ratio $L_{ij} = \\frac{P_D^{(i)} \\cdot \\mathcal{N}(\\mathbf{z}_j; \\mathbf{x}_i, \\mathbf{C}_i)}{\\lambda}$, where $\\mathcal{N}(\\mathbf{z}_j; \\mathbf{x}_i, \\mathbf{C}_i)$ is the MVN probability density function evaluated at $\\mathbf{z}_j$. For inadmissible pairs, set $L_{ij} = 0$.\n- For a missed detection hypothesis of track $i$, define $L_{i0} = 1 - P_D^{(i)}$.\n- The normalized per-track association probabilities are then $p_{ij} = \\frac{L_{ij}}{L_{i0} + \\sum_k L_{ik}}$ for each admissible hit $j$, and $p_{i0} = \\frac{L_{i0}}{L_{i0} + \\sum_k L_{ik}}$ for the missed detection.\n\nMaximum a Posteriori (MAP) assignment:\n- Consider the joint assignment where each track is assigned either to one hit or to a missed detection, with the constraint that no hit is assigned to more than one track. The MAP assignment maximizes the joint posterior under independence assumptions and the PPP clutter model. Up to additive constants independent of the assignment, this reduces to maximizing $\\sum_i \\left[ \\log P_T^{(i)} + \\log L_{i,a(i)} \\right]$, where $a(i)$ is the chosen hypothesis for track $i$ (either a specific hit $j$ or $0$ for missed detection), subject to one-to-one constraints among hits.\n- Implement this selection by solving a linear assignment problem that minimizes the sum of negative log posterior contributions. Use a cost matrix with entries $c_{ij} = -\\left(\\log P_T^{(i)} + \\log P_D^{(i)} + \\log \\mathcal{N}(\\mathbf{z}_j; \\mathbf{x}_i, \\mathbf{C}_i) - \\log \\lambda\\right)$ for admissible pairs, a very large cost for inadmissible pairs, and $c_{i,\\text{miss}} = -\\left(\\log P_T^{(i)} + \\log(1 - P_D^{(i)})\\right)$ for missed detection. Enforce one-to-one constraints by giving each track a unique missed-detection column.\n\nNumerical and unit requirements:\n- Positions must be treated in millimeters (mm), covariances in square millimeters ($\\mathrm{mm}^2$). Angles are not involved in this problem.\n- The final output consists of assignment indices, which are dimensionless integers in zero-based indexing. Use $-1$ to denote a missed detection for a track.\n\nTest suite:\nProvide four test cases with scientifically plausible parameters. For each case, you must compute the MAP assignment as described.\n\n- Test Case $1$ (two tracks, three hits, broad gate):\n  - Sensor area: $A = 10000\\,\\mathrm{mm}^2$, expected clutter: $\\Lambda = 0.5$, so $\\lambda = 0.00005\\,\\mathrm{mm}^{-2}$.\n  - Measurement covariance: $\\mathbf{R} = \\begin{pmatrix} 1.0 & 0 \\\\ 0 & 1.0 \\end{pmatrix}\\,\\mathrm{mm}^2$.\n  - Gate threshold: $\\gamma = 9.0$.\n  - Tracks:\n    - Track $1$: $\\mathbf{x}_1 = [10.0, 10.0]\\,\\mathrm{mm}$, $\\mathbf{S}_1 = \\begin{pmatrix} 0.5 & 0 \\\\ 0 & 0.5 \\end{pmatrix}\\,\\mathrm{mm}^2$, $P_D^{(1)} = 0.9$, $P_T^{(1)} = 0.95$.\n    - Track $2$: $\\mathbf{x}_2 = [20.0, 20.0]\\,\\mathrm{mm}$, $\\mathbf{S}_2 = \\begin{pmatrix} 0.7 & 0 \\\\ 0 & 0.7 \\end{pmatrix}\\,\\mathrm{mm}^2$, $P_D^{(2)} = 0.85$, $P_T^{(2)} = 0.9$.\n  - Hits: $\\mathbf{z}_1 = [9.6, 10.4]\\,\\mathrm{mm}$, $\\mathbf{z}_2 = [20.2, 19.7]\\,\\mathrm{mm}$, $\\mathbf{z}_3 = [50.0, 50.0]\\,\\mathrm{mm}$.\n\n- Test Case $2$ (three tracks, three hits, competition for a hit):\n  - Sensor area: $A = 400\\,\\mathrm{mm}^2$, expected clutter: $\\Lambda = 0.2$, so $\\lambda = 0.0005\\,\\mathrm{mm}^{-2}$.\n  - Measurement covariance: $\\mathbf{R} = \\begin{pmatrix} 0.2 & 0 \\\\ 0 & 0.2 \\end{pmatrix}\\,\\mathrm{mm}^2$.\n  - Gate threshold: $\\gamma = 4.0$.\n  - Tracks:\n    - Track $1$: $\\mathbf{x}_1 = [0.0, 0.0]\\,\\mathrm{mm}$, $\\mathbf{S}_1 = \\begin{pmatrix} 0.3 & 0 \\\\ 0 & 0.3 \\end{pmatrix}\\,\\mathrm{mm}^2$, $P_D^{(1)} = 0.95$, $P_T^{(1)} = 0.99$.\n    - Track $2$: $\\mathbf{x}_2 = [0.5, 0.0]\\,\\mathrm{mm}$, $\\mathbf{S}_2 = \\begin{pmatrix} 0.3 & 0 \\\\ 0 & 0.3 \\end{pmatrix}\\,\\mathrm{mm}^2$, $P_D^{(2)} = 0.95$, $P_T^{(2)} = 0.99$.\n    - Track $3$: $\\mathbf{x}_3 = [5.0, 5.0]\\,\\mathrm{mm}$, $\\mathbf{S}_3 = \\begin{pmatrix} 0.3 & 0 \\\\ 0 & 0.3 \\end{pmatrix}\\,\\mathrm{mm}^2$, $P_D^{(3)} = 0.9$, $P_T^{(3)} = 0.9$.\n  - Hits: $\\mathbf{z}_1 = [0.2, -0.1]\\,\\mathrm{mm}$, $\\mathbf{z}_2 = [0.6, 0.1]\\,\\mathrm{mm}$, $\\mathbf{z}_3 = [5.1, 4.9]\\,\\mathrm{mm}$.\n\n- Test Case $3$ (one track, hits out of gate, low detection probability):\n  - Sensor area: $A = 10000\\,\\mathrm{mm}^2$, expected clutter: $\\Lambda = 1.0$, so $\\lambda = 0.0001\\,\\mathrm{mm}^{-2}$.\n  - Measurement covariance: $\\mathbf{R} = \\begin{pmatrix} 1.0 & 0 \\\\ 0 & 1.0 \\end{pmatrix}\\,\\mathrm{mm}^2$.\n  - Gate threshold: $\\gamma = 9.0$.\n  - Track $1$: $\\mathbf{x}_1 = [100.0, 100.0]\\,\\mathrm{mm}$, $\\mathbf{S}_1 = \\begin{pmatrix} 1.0 & 0 \\\\ 0 & 1.0 \\end{pmatrix}\\,\\mathrm{mm}^2$, $P_D^{(1)} = 0.2$, $P_T^{(1)} = 0.8$.\n  - Hits: $\\mathbf{z}_1 = [110.0, 110.0]\\,\\mathrm{mm}$, $\\mathbf{z}_2 = [90.0, 90.0]\\,\\mathrm{mm}$.\n\n- Test Case $4$ (boundary gating at threshold):\n  - Sensor area: $A = 100\\,\\mathrm{mm}^2$, expected clutter: $\\Lambda = 0.1$, so $\\lambda = 0.001\\,\\mathrm{mm}^{-2}$.\n  - Measurement covariance: $\\mathbf{R} = \\begin{pmatrix} 10^{-8} & 0 \\\\ 0 & 10^{-8} \\end{pmatrix}\\,\\mathrm{mm}^2$.\n  - Gate threshold: $\\gamma = 4.0$.\n  - Track $1$: $\\mathbf{x}_1 = [0.0, 0.0]\\,\\mathrm{mm}$, $\\mathbf{S}_1 = \\begin{pmatrix} 1.0 & 0 \\\\ 0 & 1.0 \\end{pmatrix}\\,\\mathrm{mm}^2$, $P_D^{(1)} = 0.7$, $P_T^{(1)} = 0.9$.\n  - Hits: $\\mathbf{z}_1 = [2.0, 0.0]\\,\\mathrm{mm}$, $\\mathbf{z}_2 = [10.0, 0.0]\\,\\mathrm{mm}$.\n\nProgram output specification:\n- For each test case, compute the MAP assignment and produce a list of integers of length equal to the number of tracks, using zero-based indexing for hit indices and $-1$ to indicate missed detection.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the per-test-case assignment list. For example, the output should look like $[\\,[a_{1,1}, a_{1,2}, \\dots], [a_{2,1}, \\dots], \\dots\\,]$ with zero-based indexing and $-1$ representing missed detection.", "solution": "We begin from probability theory and a physically realistic measurement model. A candidate track $i$ extrapolated to a detector layer is represented by a predicted position $\\mathbf{x}_i \\in \\mathbb{R}^2$ and an extrapolation covariance $\\mathbf{S}_i \\in \\mathbb{R}^{2 \\times 2}$. A measured hit $\\mathbf{z}_j \\in \\mathbb{R}^2$ is modeled as the true position corrupted by detector noise with covariance $\\mathbf{R} \\in \\mathbb{R}^{2 \\times 2}$. Under standard assumptions, the conditional distribution of an associated hit is a Multivariate Normal (MVN), $\\mathbf{z}_j \\mid \\text{track } i \\sim \\mathcal{N}(\\mathbf{x}_i, \\mathbf{C}_i)$ where $\\mathbf{C}_i = \\mathbf{S}_i + \\mathbf{R}$. All positions are measured in millimeters (mm), and the covariances are in square millimeters ($\\mathrm{mm}^2$).\n\nTo ensure physical and numerical realism, we apply a gate based on the squared Mahalanobis distance\n$$\nd_{ij}^2 = (\\mathbf{z}_j - \\mathbf{x}_i)^\\top \\mathbf{C}_i^{-1} (\\mathbf{z}_j - \\mathbf{x}_i),\n$$\nand only consider associations $(i,j)$ for which $d_{ij}^2 \\le \\gamma$, where $\\gamma > 0$ is a specified threshold (e.g., corresponding to a confidence region under the MVN).\n\nWe model spurious hits as a uniform Poisson Point Process (PPP) over the sensor area $A$ with expected count $\\Lambda$, yielding a spatial clutter density $\\lambda = \\Lambda / A$ in $\\mathrm{mm}^{-2}$. This density provides a reference for evaluating how likely a hit is to be clutter as opposed to originating from a particular track.\n\nEach track $i$ has a Probability of Detection (PoD) $P_D^{(i)} \\in (0,1)$ and a prior Probability of Existence $P_T^{(i)} \\in (0,1)$. Given a hit $\\mathbf{z}_j$, the local likelihood ratio for an admissible association $(i,j)$ follows from Bayes rule and the PPP clutter model:\n$$\nL_{ij} = \\frac{P_D^{(i)} \\, \\mathcal{N}(\\mathbf{z}_j; \\mathbf{x}_i, \\mathbf{C}_i)}{\\lambda}.\n$$\nFor inadmissible $(i,j)$ (outside the gate), we set $L_{ij} = 0$. The missed detection hypothesis for track $i$ has likelihood ratio\n$$\nL_{i0} = 1 - P_D^{(i)}.\n$$\nThese quantities are dimensionless because $\\mathcal{N}(\\cdot)$ and $\\lambda$ are both densities, and $P_D^{(i)}$ is dimensionless.\n\nFor per-track association probabilities, we normalize using\n$$\np_{ij} = \\frac{L_{ij}}{L_{i0} + \\sum_{k} L_{ik}}, \\quad p_{i0} = \\frac{L_{i0}}{L_{i0} + \\sum_{k} L_{ik}},\n$$\nwhich follows from Bayes rule under mutually exclusive hypotheses for track $i$.\n\nThe global Maximum a Posteriori (MAP) assignment problem considers assigning each track to a single hypothesis $a(i)$ (either a specific hit index $j$ or $0$ for missed detection) while enforcing that no hit is assigned to more than one track. Under independence assumptions and ignoring constants independent of the assignment, the joint posterior is proportional to\n$$\n\\prod_i \\left( P_T^{(i)} \\cdot L_{i,a(i)} \\right),\n$$\nand we therefore seek to maximize\n$$\n\\sum_i \\left[ \\log P_T^{(i)} + \\log L_{i,a(i)} \\right].\n$$\nThis is a linear assignment problem if we construct an appropriate cost matrix. For admissible associations $(i,j)$, define the cost\n$$\nc_{ij} = -\\left(\\log P_T^{(i)} + \\log P_D^{(i)} + \\log \\mathcal{N}(\\mathbf{z}_j; \\mathbf{x}_i, \\mathbf{C}_i) - \\log \\lambda \\right),\n$$\nand for inadmissible associations set $c_{ij}$ to a very large value to effectively disallow the pairing. For missed detection, we define a unique dummy column per track with cost\n$$\nc_{i,\\text{miss}} = -\\left(\\log P_T^{(i)} + \\log(1 - P_D^{(i)})\\right).\n$$\nHaving $N$ tracks and $M$ hits, we build a cost matrix of size $N \\times (M + N)$ by appending $N$ missed-detection columns, one for each track. This ensures the algorithm assigns exactly one hypothesis to each track and enforces that each hit can be assigned at most once. The Hungarian algorithm (also known as the Kuhn–Munkres algorithm) can then be used to find the assignment that minimizes the total cost, which corresponds to the MAP solution.\n\nImplementation details:\n- Compute $\\mathbf{C}_i = \\mathbf{S}_i + \\mathbf{R}$ for each track.\n- Compute $d_{ij}^2$ using a numerically stable method such as solving $\\mathbf{C}_i \\mathbf{y} = \\mathbf{z}_j - \\mathbf{x}_i$ for $\\mathbf{y}$ and then $d_{ij}^2 = (\\mathbf{z}_j - \\mathbf{x}_i)^\\top \\mathbf{y}$.\n- Compute the MVN density\n$$\n\\mathcal{N}(\\mathbf{z}_j; \\mathbf{x}_i, \\mathbf{C}_i) = \\frac{1}{2\\pi \\sqrt{\\det \\mathbf{C}_i}} \\exp\\left( -\\frac{1}{2} d_{ij}^2 \\right).\n$$\n- Use a large finite cost (for example, $10^9$) to represent disallowed assignments. Avoid taking $\\log 0$ by not computing log densities for gated-out pairs.\n- For each test case, construct the cost matrix, solve the assignment, and decode the result: if a track is assigned to a hit column $j < M$, output $j$; if it is assigned to its unique missed-detection column, output $-1$.\n\nEdge cases:\n- If all pairs for a track are outside the gate, it will be assigned to missed detection because the admissible hit costs are effectively infinite while $c_{i,\\text{miss}}$ is finite.\n- If the squared Mahalanobis distance equals the gate threshold ($d_{ij}^2 = \\gamma$), the association is admissible by definition ($\\le \\gamma$), and the density contributes accordingly.\n- With low $P_D^{(i)}$, $c_{i,\\text{miss}}$ may become competitive relative to hit associations even if some hits are within the gate, reflecting the underlying physics of low detection probability.\n\nThe program will compute the assignments for the four provided test cases and print a single line containing a list of assignment lists, each of which is a list of integers using zero-based hit indices and $-1$ for missed detection. This output is unitless as it represents discrete indices.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import linear_sum_assignment\n\ndef mvn_density(diff: np.ndarray, C: np.ndarray) -> float:\n    \"\"\"\n    Compute the multivariate normal density N(z; x, C) at diff = z - x\n    where C is the covariance matrix.\n    \"\"\"\n    # Solve C y = diff to avoid explicit inverse for Mahalanobis distance\n    try:\n        y = np.linalg.solve(C, diff)\n    except np.linalg.LinAlgError:\n        # In case C is ill-conditioned, fall back to pseudo-inverse\n        y = np.linalg.pinv(C).dot(diff)\n    d2 = float(diff.T.dot(y))\n    detC = float(np.linalg.det(C))\n    if detC <= 0:\n        # Numerical safeguard: if covariance is near-singular, use pseudo-det via SVD\n        s = np.linalg.svd(C, compute_uv=False)\n        detC = float(np.prod(s))\n        # If still zero, return an extremely small density\n        if detC == 0:\n            return 0.0\n    norm_const = 1.0 / (2.0 * np.pi * np.sqrt(detC))\n    return norm_const * np.exp(-0.5 * d2), d2\n\ndef compute_cost_matrix(tracks, hits, R, gamma, lam):\n    \"\"\"\n    Build the cost matrix for MAP assignment.\n    tracks: list of dicts with keys x (2,), S (2x2), P_D, P_T\n    hits: list of 2D arrays\n    R: 2x2 measurement covariance\n    gamma: gating threshold\n    lam: clutter density (Lambda / A)\n    Returns:\n        cost_matrix: shape (N_tracks, N_hits + N_tracks)\n    \"\"\"\n    n_tracks = len(tracks)\n    n_hits = len(hits)\n    big_M = 1e9  # large cost for disallowed\n    cost = np.full((n_tracks, n_hits + n_tracks), big_M, dtype=float)\n    for i, trk in enumerate(tracks):\n        x = np.array(trk[\"x\"], dtype=float)\n        S = np.array(trk[\"S\"], dtype=float)\n        P_D = float(trk[\"P_D\"])\n        P_T = float(trk[\"P_T\"])\n        C = S + R\n        # Missed detection column for track i\n        miss_col = n_hits + i\n        # c_{i,miss} = - [ log P_T + log(1 - P_D) ]\n        miss_cost = - (np.log(P_T) + np.log(max(1e-12, 1.0 - P_D)))\n        cost[i, miss_col] = miss_cost\n        # Hit costs\n        for j, z in enumerate(hits):\n            z = np.array(z, dtype=float)\n            diff = z - x\n            density, d2 = mvn_density(diff, C)\n            if d2 <= gamma and density > 0.0:\n                # c_{ij} = - [ log P_T + log P_D + log N - log lam ]\n                cij = - (np.log(P_T) + np.log(P_D) + np.log(density) - np.log(lam))\n                cost[i, j] = cij\n            else:\n                # inadmissible or negligible density\n                cost[i, j] = big_M\n    return cost\n\ndef map_assignment(tracks, hits, R, gamma, A, Lambda):\n    \"\"\"\n    Compute MAP assignment given tracks and hits.\n    Returns a list of ints per track: hit index (0-based) or -1 for missed detection.\n    \"\"\"\n    lam = Lambda / A\n    cost = compute_cost_matrix(tracks, hits, R, gamma, lam)\n    row_ind, col_ind = linear_sum_assignment(cost)\n    n_hits = len(hits)\n    assignment = [-1] * len(tracks)\n    for i, j in zip(row_ind, col_ind):\n        if j < n_hits:\n            # Assigned to hit j\n            assignment[i] = j\n        else:\n            # Assigned to missed detection (unique column per track)\n            assignment[i] = -1\n    return assignment\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1\n        {\n            \"A\": 10000.0,\n            \"Lambda\": 0.5,\n            \"R\": np.array([[1.0, 0.0], [0.0, 1.0]], dtype=float),\n            \"gamma\": 9.0,\n            \"tracks\": [\n                {\"x\": [10.0, 10.0], \"S\": np.array([[0.5, 0.0], [0.0, 0.5]], dtype=float), \"P_D\": 0.9, \"P_T\": 0.95},\n                {\"x\": [20.0, 20.0], \"S\": np.array([[0.7, 0.0], [0.0, 0.7]], dtype=float), \"P_D\": 0.85, \"P_T\": 0.9},\n            ],\n            \"hits\": [\n                [9.6, 10.4],\n                [20.2, 19.7],\n                [50.0, 50.0],\n            ],\n        },\n        # Test Case 2\n        {\n            \"A\": 400.0,\n            \"Lambda\": 0.2,\n            \"R\": np.array([[0.2, 0.0], [0.0, 0.2]], dtype=float),\n            \"gamma\": 4.0,\n            \"tracks\": [\n                {\"x\": [0.0, 0.0], \"S\": np.array([[0.3, 0.0], [0.0, 0.3]], dtype=float), \"P_D\": 0.95, \"P_T\": 0.99},\n                {\"x\": [0.5, 0.0], \"S\": np.array([[0.3, 0.0], [0.0, 0.3]], dtype=float), \"P_D\": 0.95, \"P_T\": 0.99},\n                {\"x\": [5.0, 5.0], \"S\": np.array([[0.3, 0.0], [0.0, 0.3]], dtype=float), \"P_D\": 0.9, \"P_T\": 0.9},\n            ],\n            \"hits\": [\n                [0.2, -0.1],\n                [0.6, 0.1],\n                [5.1, 4.9],\n            ],\n        },\n        # Test Case 3\n        {\n            \"A\": 10000.0,\n            \"Lambda\": 1.0,\n            \"R\": np.array([[1.0, 0.0], [0.0, 1.0]], dtype=float),\n            \"gamma\": 9.0,\n            \"tracks\": [\n                {\"x\": [100.0, 100.0], \"S\": np.array([[1.0, 0.0], [0.0, 1.0]], dtype=float), \"P_D\": 0.2, \"P_T\": 0.8},\n            ],\n            \"hits\": [\n                [110.0, 110.0],\n                [90.0, 90.0],\n            ],\n        },\n        # Test Case 4\n        {\n            \"A\": 100.0,\n            \"Lambda\": 0.1,\n            \"R\": np.array([[1e-8, 0.0], [0.0, 1e-8]], dtype=float),\n            \"gamma\": 4.0,\n            \"tracks\": [\n                {\"x\": [0.0, 0.0], \"S\": np.array([[1.0, 0.0], [0.0, 1.0]], dtype=float), \"P_D\": 0.7, \"P_T\": 0.9},\n            ],\n            \"hits\": [\n                [2.0, 0.0],\n                [10.0, 0.0],\n            ],\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        A = case[\"A\"]\n        Lambda = case[\"Lambda\"]\n        R = case[\"R\"]\n        gamma = case[\"gamma\"]\n        tracks = case[\"tracks\"]\n        hits = case[\"hits\"]\n        assignment = map_assignment(tracks, hits, R, gamma, A, Lambda)\n        results.append(assignment)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3539732"}, {"introduction": "After a hit has been associated with a track, we must incorporate its information to refine the track's state parameters—such as its position and direction—and reduce their uncertainty. The Kalman filter provides the optimal mathematical framework for this iterative process of prediction and updating. In this fundamental exercise [@problem_id:3539735], you will perform one complete prediction-update cycle with concrete numerical values, providing a tangible understanding of the filter's mechanics at the very heart of track fitting.", "problem": "A charged-particle track is reconstructed across two silicon detector layers in a collider experiment. Within a small step from a previous surface to the current measurement plane, adopt the linearized state-space track model with state vector $\\mathbf{x} = (u, t)^{\\mathsf{T}}$, where $u$ is the local transverse position in $\\mathrm{cm}$ and $t = \\mathrm{d}u/\\mathrm{d}z$ is the local slope (dimensionless). The process model is linear with a transport matrix $F$ and process noise covariance $Q$ representing small multiple-scattering fluctuations. The measurement at the current plane is a single hit coordinate $y$ related linearly to the state through a measurement matrix $H$, with measurement noise covariance $R$. All noises are assumed zero-mean Gaussian, independent, and with the stated covariances. You are to perform one prediction-update cycle from the previous filtered state to incorporate the hit.\n\nUse the following numerical inputs:\n- Previous filtered state and covariance: $\\mathbf{x}_{0} = \\begin{pmatrix} 0.05 \\\\ 0.002 \\end{pmatrix}$, $P_{0} = \\begin{pmatrix} 1.0 \\times 10^{-4} & 0 \\\\ 0 & 1.0 \\times 10^{-6} \\end{pmatrix}$.\n- Transport matrix and process noise covariance: $F = \\begin{pmatrix} 1 & 20 \\\\ 0 & 1 \\end{pmatrix}$, $Q = \\begin{pmatrix} 1.0 \\times 10^{-5} & 0 \\\\ 0 & 1.0 \\times 10^{-6} \\end{pmatrix}$.\n- Measurement model and noise covariance: $H = \\begin{pmatrix} 1 & 0 \\end{pmatrix}$, $R = 4.0 \\times 10^{-4}$.\n- Measured hit coordinate: $y = 0.115$ (in $\\mathrm{cm}$).\n\nStarting from first principles of the Bayesian linear-Gaussian model for state propagation and measurement, derive and compute:\n1. The predicted state $\\mathbf{x}^{-}$ and predicted covariance $P^{-}$.\n2. The measurement residual $r$, the innovation covariance $S$, and the optimal linear gain (Kalman gain) $K$ for the update.\n3. The updated state $\\mathbf{x}^{+}$ and updated covariance $P^{+}$ after incorporating the hit.\n4. The incremental chi-squared $\\Delta \\chi^{2}$ contributed by this hit.\n\nReport the incremental chi-squared $\\Delta \\chi^{2}$ as your final numerical answer. Round your answer to four significant figures. Since $\\Delta \\chi^{2}$ is dimensionless, no unit should be reported for the final answer.", "solution": "The problem requires performing a single prediction-update cycle of a linear Kalman filter to incorporate a new measurement into a charged-particle track's state estimate. The process is grounded in the principles of Bayesian inference for linear-Gaussian systems. We will proceed by first validating the problem statement and then systematically deriving and computing the requested quantities.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- Previous filtered state vector: $\\mathbf{x}_{0} = \\begin{pmatrix} 0.05 \\\\ 0.002 \\end{pmatrix}$\n- Previous filtered covariance matrix: $P_{0} = \\begin{pmatrix} 1.0 \\times 10^{-4} & 0 \\\\ 0 & 1.0 \\times 10^{-6} \\end{pmatrix}$\n- Transport matrix: $F = \\begin{pmatrix} 1 & 20 \\\\ 0 & 1 \\end{pmatrix}$\n- Process noise covariance matrix: $Q = \\begin{pmatrix} 1.0 \\times 10^{-5} & 0 \\\\ 0 & 1.0 \\times 10^{-6} \\end{pmatrix}$\n- Measurement matrix: $H = \\begin{pmatrix} 1 & 0 \\end{pmatrix}$\n- Measurement noise covariance (scalar): $R = 4.0 \\times 10^{-4}$\n- Measured hit coordinate (scalar): $y = 0.115$\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem describes a standard application of the Kalman filter for track reconstruction in high-energy physics. The linear state-space model is a common and valid approximation for small propagation steps. The physical interpretation of the state vector components ($u$ for position, $t$ for slope) and the matrices ($F$ for linear transport, $Q$ for multiple scattering, $H$ for a position measurement, $R$ for sensor resolution) are all standard in the field. The numerical values are physically plausible for a silicon detector system.\n- **Well-Posed:** The problem provides a complete set of initial conditions and model parameters required to execute one cycle of the Kalman filter. The calculations lead to a unique and stable solution.\n- **Objective:** The problem is stated using precise mathematical and physical terminology, free of ambiguity or subjective claims.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is a well-posed, scientifically grounded exercise in applying the Kalman filter algorithm. We will proceed with the solution.\n\n### Derivation and Computation\n\nThe Kalman filter cycle consists of two main steps: a prediction step (propagating the state to the new measurement surface) and an update step (correcting the state using the new measurement).\n\n**1. Predicted State and Covariance**\n\nThe state is propagated from the previous surface to the current measurement plane using the transport matrix $F$. The process noise $Q$ accounts for uncertainties added during this transport, such as from multiple scattering.\n\nThe predicted (a priori) state $\\mathbf{x}^{-}$ is the expectation of the propagated state:\n$$\n\\mathbf{x}^{-} = F \\mathbf{x}_{0}\n$$\nThe predicted (a priori) covariance $P^{-}$ is the sum of the propagated previous covariance and the process noise covariance:\n$$\nP^{-} = F P_{0} F^{\\mathsf{T}} + Q\n$$\nSubstituting the given values:\n$$\n\\mathbf{x}^{-} = \\begin{pmatrix} 1 & 20 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0.05 \\\\ 0.002 \\end{pmatrix} = \\begin{pmatrix} 1 \\cdot (0.05) + 20 \\cdot (0.002) \\\\ 0 \\cdot (0.05) + 1 \\cdot (0.002) \\end{pmatrix} = \\begin{pmatrix} 0.05 + 0.04 \\\\ 0.002 \\end{pmatrix} = \\begin{pmatrix} 0.09 \\\\ 0.002 \\end{pmatrix}\n$$\nFor the covariance:\n$$\nF P_{0} F^{\\mathsf{T}} = \\begin{pmatrix} 1 & 20 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 1.0 \\times 10^{-4} & 0 \\\\ 0 & 1.0 \\times 10^{-6} \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 20 & 1 \\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} 1.0 \\times 10^{-4} & 2.0 \\times 10^{-5} \\\\ 0 & 1.0 \\times 10^{-6} \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 20 & 1 \\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} (1.0 \\times 10^{-4}) + (2.0 \\times 10^{-5})(20) & 2.0 \\times 10^{-5} \\\\ 1.0 \\times 10^{-6}(20) & 1.0 \\times 10^{-6} \\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} 1.0 \\times 10^{-4} + 4.0 \\times 10^{-4} & 2.0 \\times 10^{-5} \\\\ 2.0 \\times 10^{-5} & 1.0 \\times 10^{-6} \\end{pmatrix} = \\begin{pmatrix} 5.0 \\times 10^{-4} & 2.0 \\times 10^{-5} \\\\ 2.0 \\times 10^{-5} & 1.0 \\times 10^{-6} \\end{pmatrix}\n$$\nNow, adding the process noise covariance $Q$:\n$$\nP^{-} = \\begin{pmatrix} 5.0 \\times 10^{-4} & 2.0 \\times 10^{-5} \\\\ 2.0 \\times 10^{-5} & 1.0 \\times 10^{-6} \\end{pmatrix} + \\begin{pmatrix} 1.0 \\times 10^{-5} & 0 \\\\ 0 & 1.0 \\times 10^{-6} \\end{pmatrix}\n$$\n$$\nP^{-} = \\begin{pmatrix} 5.1 \\times 10^{-4} & 2.0 \\times 10^{-5} \\\\ 2.0 \\times 10^{-5} & 2.0 \\times 10^{-6} \\end{pmatrix}\n$$\n\n**2. Measurement Residual, Innovation Covariance, and Kalman Gain**\n\nThe measurement residual $r$ (or innovation) is the difference between the actual measurement $y$ and the predicted measurement $H \\mathbf{x}^{-}$. The innovation covariance $S$ is the variance of this residual. The Kalman gain $K$ is the optimal weight for combining the prediction with the residual.\n\nThe residual $r$ is:\n$$\nr = y - H \\mathbf{x}^{-}\n$$\nThe innovation covariance $S$ is:\n$$\nS = H P^{-} H^{\\mathsf{T}} + R\n$$\nThe Kalman gain $K$ is:\n$$\nK = P^{-} H^{\\mathsf{T}} S^{-1}\n$$\nSubstituting values:\n$$\nr = 0.115 - \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0.09 \\\\ 0.002 \\end{pmatrix} = 0.115 - 0.09 = 0.025\n$$\nFor the innovation covariance $S$ (which is a scalar in this case):\n$$\nH P^{-} H^{\\mathsf{T}} = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} 5.1 \\times 10^{-4} & 2.0 \\times 10^{-5} \\\\ 2.0 \\times 10^{-5} & 2.0 \\times 10^{-6} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 5.1 \\times 10^{-4} & 2.0 \\times 10^{-5} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = 5.1 \\times 10^{-4}\n$$\n$$\nS = H P^{-} H^{\\mathsf{T}} + R = (5.1 \\times 10^{-4}) + (4.0 \\times 10^{-4}) = 9.1 \\times 10^{-4}\n$$\nFor the Kalman gain $K$ (which is a $2 \\times 1$ vector):\n$$\nP^{-} H^{\\mathsf{T}} = \\begin{pmatrix} 5.1 \\times 10^{-4} & 2.0 \\times 10^{-5} \\\\ 2.0 \\times 10^{-5} & 2.0 \\times 10^{-6} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 5.1 \\times 10^{-4} \\\\ 2.0 \\times 10^{-5} \\end{pmatrix}\n$$\n$$\nK = P^{-} H^{\\mathsf{T}} S^{-1} = \\begin{pmatrix} 5.1 \\times 10^{-4} \\\\ 2.0 \\times 10^{-5} \\end{pmatrix} (9.1 \\times 10^{-4})^{-1} = \\frac{1}{9.1 \\times 10^{-4}} \\begin{pmatrix} 5.1 \\times 10^{-4} \\\\ 2.0 \\times 10^{-5} \\end{pmatrix} = \\frac{1}{9.1} \\begin{pmatrix} 5.1 \\\\ 0.2 \\end{pmatrix}\n$$\n\n**3. Updated State and Covariance**\n\nThe updated (a posteriori) state $\\mathbf{x}^{+}$ is the predicted state corrected by the weighted residual. The updated covariance $P^{+}$ is the predicted covariance reduced by the information gained from the measurement.\n\nThe updated state $\\mathbf{x}^{+}$ is:\n$$\n\\mathbf{x}^{+} = \\mathbf{x}^{-} + K r\n$$\nThe updated covariance $P^{+}$ is:\n$$\nP^{+} = (I - K H) P^{-}\n$$\nSubstituting values:\n$$\n\\mathbf{x}^{+} = \\begin{pmatrix} 0.09 \\\\ 0.002 \\end{pmatrix} + \\frac{1}{9.1} \\begin{pmatrix} 5.1 \\\\ 0.2 \\end{pmatrix} (0.025) = \\begin{pmatrix} 0.09 \\\\ 0.002 \\end{pmatrix} + \\begin{pmatrix} \\frac{0.1275}{9.1} \\\\ \\frac{0.005}{9.1} \\end{pmatrix} \\approx \\begin{pmatrix} 0.09 + 0.01401 \\\\ 0.002 + 0.000549 \\end{pmatrix} = \\begin{pmatrix} 0.10401 \\\\ 0.002549 \\end{pmatrix}\n$$\nAnd for the covariance:\n$$\nK H = \\frac{1}{9.1} \\begin{pmatrix} 5.1 \\\\ 0.2 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\end{pmatrix} = \\frac{1}{9.1} \\begin{pmatrix} 5.1 & 0 \\\\ 0.2 & 0 \\end{pmatrix}\n$$\n$$\nI - K H = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} - \\frac{1}{9.1} \\begin{pmatrix} 5.1 & 0 \\\\ 0.2 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 - \\frac{5.1}{9.1} & 0 \\\\ -\\frac{0.2}{9.1} & 1 \\end{pmatrix} = \\begin{pmatrix} \\frac{4.0}{9.1} & 0 \\\\ -\\frac{0.2}{9.1} & 1 \\end{pmatrix}\n$$\n$$\nP^{+} = \\begin{pmatrix} \\frac{4.0}{9.1} & 0 \\\\ -\\frac{0.2}{9.1} & 1 \\end{pmatrix} \\begin{pmatrix} 5.1 \\times 10^{-4} & 2.0 \\times 10^{-5} \\\\ 2.0 \\times 10^{-5} & 2.0 \\times 10^{-6} \\end{pmatrix} \\approx \\begin{pmatrix} 2.24 \\times 10^{-4} & 8.79 \\times 10^{-6} \\\\ 8.79 \\times 10^{-6} & 1.56 \\times 10^{-6} \\end{pmatrix}\n$$\n\n**4. Incremental Chi-Squared**\n\nThe incremental chi-squared, $\\Delta \\chi^2$, quantifies the compatibility of the measurement with the predicted state. It is the squared Mahalanobis distance of the residual, normalized by its covariance. For a scalar measurement, this is:\n$$\n\\Delta \\chi^{2} = r^{\\mathsf{T}} S^{-1} r = \\frac{r^2}{S}\n$$\nUsing the previously computed values:\n$$\nr = 0.025\n$$\n$$\nS = 9.1 \\times 10^{-4}\n$$\n$$\n\\Delta \\chi^{2} = \\frac{(0.025)^2}{9.1 \\times 10^{-4}} = \\frac{6.25 \\times 10^{-4}}{9.1 \\times 10^{-4}} = \\frac{6.25}{9.1} \\approx 0.6868131868...\n$$\nRounding to four significant figures, the incremental chi-squared contributed by this hit is $0.6868$.", "answer": "$$\n\\boxed{0.6868}\n$$", "id": "3539735"}]}