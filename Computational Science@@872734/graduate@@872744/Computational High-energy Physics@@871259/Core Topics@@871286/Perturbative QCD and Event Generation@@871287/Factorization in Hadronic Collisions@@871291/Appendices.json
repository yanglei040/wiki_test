{"hands_on_practices": [{"introduction": "The cornerstone of predictive power in hadron collider physics is the Quantum Chromodynamics (QCD) factorization theorem. This powerful principle separates short-distance partonic interactions, which are calculable in perturbation theory, from long-distance, non-perturbative dynamics encapsulated in Parton Distribution Functions (PDFs). This first exercise [@problem_id:3514288] provides direct, hands-on experience implementing the fundamental convolution integral that connects these two regimes, allowing you to compute a hadronic cross section from its constituent parts and understand the numerical challenges posed by the structure of PDFs.", "problem": "Implement a complete program that numerically evaluates the hadronic cross section based on the factorization theorem in Quantum Chromodynamics (QCD). The cross section for a hadronic process is defined by the convolution of Parton Distribution Functions (PDFs) with partonic cross sections. Starting from the factorization principle, the hadronic cross section is given by the double integral over the longitudinal momentum fractions. You must design numerical quadrature that is robust under sharply peaked PDFs and verify convergence.\n\nYou must use the following modeling assumptions, which are scientifically plausible approximations suitable for computational testing:\n\n1. The factorization formula is defined as\n$$\n\\sigma(s,\\mu) = \\sum_{i,j} \\int_0^1 dx_1 \\int_0^1 dx_2 \\, f_i(x_1,\\mu)\\, f_j(x_2,\\mu) \\, \\hat{\\sigma}_{ij}(x_1 x_2 s, \\mu),\n$$\nwhere $s$ is the hadronic center-of-mass energy squared, $\\mu$ is the factorization scale, $f_i$ and $f_j$ are the PDFs for partons $i$ and $j$, and $\\hat{\\sigma}_{ij}$ is the partonic cross section for the subprocess $i j \\to X$.\n\n2. Model two effective parton species $i \\in \\{q, g\\}$ (quark and gluon). Each species $i$ has a PDF parameterized by a normalized Beta-like shape:\n$$\nf_i(x;\\lambda_i,\\eta_i) = \\mathcal{N}_i(\\lambda_i,\\eta_i)\\, x^{-\\lambda_i}\\, (1-x)^{\\eta_i}, \\quad x \\in (0,1),\n$$\nwith normalization constant $\\mathcal{N}_i(\\lambda_i,\\eta_i)$ chosen so that\n$$\n\\int_0^1 f_i(x;\\lambda_i,\\eta_i)\\,dx = 1.\n$$\nFor integrability and scientific realism, enforce $\\lambda_i  1$ and $\\eta_i  -1$.\n\n3. Use the following partonic cross sections:\n   - Quark-quark channel $(q,q)$ (Breit-Wigner resonance-like shape):\n     $$\n     \\hat{\\sigma}_{qq}(s_{\\mathrm{hat}}; M, \\Gamma, K_{qq}) = K_{qq}\\, \\frac{M \\Gamma}{\\left(s_{\\mathrm{hat}} - M^2\\right)^2 + M^2 \\Gamma^2},\n     $$\n     which is non-negative and sharply peaked near $s_{\\mathrm{hat}} \\approx M^2$.\n   - Gluon-gluon channel $(g,g)$ (threshold-like continuum):\n     $$ \n     \\hat{\\sigma}_{gg}(s_{\\mathrm{hat}}; s_{\\mathrm{thr}}, p, \\sigma_{0,gg}) = \n     \\begin{cases}\n     \\sigma_{0,gg}\\, \\dfrac{\\left(1 - s_{\\mathrm{thr}}/s_{\\mathrm{hat}}\\right)^p}{s_{\\mathrm{hat}}},  s_{\\mathrm{hat}} \\ge s_{\\mathrm{thr}}, \\\\\n     0,  s_{\\mathrm{hat}}  s_{\\mathrm{thr}},\n     \\end{cases}\n     $$\n     which is non-zero only above a physical threshold $s_{\\mathrm{thr}}$ and decreases at large $s_{\\mathrm{hat}}$.\n\nAll partonic cross sections are expressed in picobarn (pb), and the hadronic cross section must be returned and printed in picobarn (pb). You must use radians for any angular quantity if it were to appear (none appear here). No percentages are to be used anywhere; express fractional tolerances as decimals.\n\nYour program must:\n- Implement the double integral using tensor-product Gauss-Legendre quadrature on $[0,1]\\times[0,1]$ with adjustable number of points $N$ per dimension.\n- Verify convergence by comparing results between a coarse quadrature ($N_{\\mathrm{coarse}}$) and a fine quadrature ($N_{\\mathrm{fine}}$) using the relative difference criterion\n$$\n\\delta = \\frac{\\left|\\sigma_{N_{\\mathrm{fine}}} - \\sigma_{N_{\\mathrm{coarse}}}\\right|}{\\left|\\sigma_{N_{\\mathrm{fine}}}\\right|} \\le \\text{tol},\n$$\nwhere $\\text{tol}$ is a specified decimal tolerance. Return a boolean indicating whether the convergence criterion is met.\n\nTest Suite:\nEvaluate the following four test cases. For each case, compute the hadronic cross section with the fine quadrature and report the convergence boolean obtained by comparing coarse versus fine. Use the exact parameter values below. All energies must be treated in $\\mathrm{GeV}$ and cross sections in $\\mathrm{pb}$, and you must print the final cross sections in $\\mathrm{pb}$.\n\n- Case 1 (happy path, moderately peaked PDFs):\n  - $s = (13000\\,\\mathrm{GeV})^2$\n  - $\\mu = 91\\,\\mathrm{GeV}$\n  - Quark PDF: $\\lambda_q = 0.6$, $\\eta_q = 3.0$\n  - Gluon PDF: $\\lambda_g = 0.3$, $\\eta_g = 5.0$\n  - Quark-quark channel: $M = 91\\,\\mathrm{GeV}$, $\\Gamma = 2.5\\,\\mathrm{GeV}$, $K_{qq} = 1.0\\times 10^4\\,\\mathrm{pb}\\cdot\\mathrm{GeV}^2$\n  - Gluon-gluon channel: $s_{\\mathrm{thr}} = (350\\,\\mathrm{GeV})^2$, $p = 2$, $\\sigma_{0,gg} = 1.0\\times 10^5\\,\\mathrm{pb}\\cdot\\mathrm{GeV}^2$\n  - Convergence settings: $N_{\\mathrm{coarse}} = 64$, $N_{\\mathrm{fine}} = 128$, $\\text{tol} = 1.0\\times 10^{-3}$\n\n- Case 2 (sharply peaked PDFs near $x \\to 0$):\n  - $s = (13000\\,\\mathrm{GeV})^2$\n  - $\\mu = 50\\,\\mathrm{GeV}$\n  - Quark PDF: $\\lambda_q = 0.95$, $\\eta_q = 4.0$\n  - Gluon PDF: $\\lambda_g = 0.9$, $\\eta_g = 6.0$\n  - Quark-quark channel: $M = 91\\,\\mathrm{GeV}$, $\\Gamma = 2.5\\,\\mathrm{GeV}$, $K_{qq} = 1.0\\times 10^4\\,\\mathrm{pb}\\cdot\\mathrm{GeV}^2$\n  - Gluon-gluon channel: $s_{\\mathrm{thr}} = (350\\,\\mathrm{GeV})^2$, $p = 2$, $\\sigma_{0,gg} = 1.0\\times 10^5\\,\\mathrm{pb}\\cdot\\mathrm{GeV}^2$\n  - Convergence settings: $N_{\\mathrm{coarse}} = 64$, $N_{\\mathrm{fine}} = 128$, $\\text{tol} = 2.0\\times 10^{-3}$\n\n- Case 3 (very sharp PDFs and narrow resonance):\n  - $s = (13000\\,\\mathrm{GeV})^2$\n  - $\\mu = 20\\,\\mathrm{GeV}$\n  - Quark PDF: $\\lambda_q = 0.99$, $\\eta_q = 5.0$\n  - Gluon PDF: $\\lambda_g = 0.95$, $\\eta_g = 7.0$\n  - Quark-quark channel: $M = 91\\,\\mathrm{GeV}$, $\\Gamma = 0.5\\,\\mathrm{GeV}$, $K_{qq} = 1.0\\times 10^4\\,\\mathrm{pb}\\cdot\\mathrm{GeV}^2$\n  - Gluon-gluon channel: $s_{\\mathrm{thr}} = (350\\,\\mathrm{GeV})^2$, $p = 3$, $\\sigma_{0,gg} = 1.0\\times 10^5\\,\\mathrm{pb}\\cdot\\mathrm{GeV}^2$\n  - Convergence settings: $N_{\\mathrm{coarse}} = 64$, $N_{\\mathrm{fine}} = 128$, $\\text{tol} = 3.0\\times 10^{-3}$\n\n- Case 4 (high-mass resonance near phase-space boundary):\n  - $s = (13000\\,\\mathrm{GeV})^2$\n  - $\\mu = 200\\,\\mathrm{GeV}$\n  - Quark PDF: $\\lambda_q = 0.7$, $\\eta_q = 3.0$\n  - Gluon PDF: $\\lambda_g = 0.5$, $\\eta_g = 5.0$\n  - Quark-quark channel: $M = 6000\\,\\mathrm{GeV}$, $\\Gamma = 100\\,\\mathrm{GeV}$, $K_{qq} = 5.0\\times 10^4\\,\\mathrm{pb}\\cdot\\mathrm{GeV}^2$\n  - Gluon-gluon channel: $s_{\\mathrm{thr}} = (2000\\,\\mathrm{GeV})^2$, $p = 2$, $\\sigma_{0,gg} = 2.0\\times 10^5\\,\\mathrm{pb}\\cdot\\mathrm{GeV}^2$\n  - Convergence settings: $N_{\\mathrm{coarse}} = 64$, $N_{\\mathrm{fine}} = 128$, $\\text{tol} = 1.0\\times 10^{-3}$\n\nOutput specification:\nYour program must produce a single line of output containing a list of pairs, one per test case. Each pair must be of the form $[\\sigma_{\\mathrm{fine}}, \\mathrm{conv\\_ok}]$, where $\\sigma_{\\mathrm{fine}}$ is the cross section computed with $N_{\\mathrm{fine}}$ in $\\mathrm{pb}$ as a float, and $\\mathrm{conv\\_ok}$ is a boolean indicating whether the convergence criterion is satisfied. The final line must be printed exactly as a Python list of lists, for example:\n$$\n[\\,[\\sigma_1,\\mathrm{True}],[\\sigma_2,\\mathrm{False}],\\ldots\\,].\n$$", "solution": "The user-supplied problem is deemed valid. It is scientifically grounded in the principles of Quantum Chromodynamics (QCD), well-posed, objective, and computationally feasible. The problem asks for the numerical evaluation of a hadronic cross section, a central task in computational high-energy physics. The provided model, while a simplification of full QCD, uses standard parameterizations and is internally consistent.\n\nThe objective is to compute the hadronic cross section $\\sigma$ for a two-parton model, given by the QCD factorization theorem. The formula for the total cross section $\\sigma$ at a hadronic center-of-mass energy squared $s$ is a sum over contributions from all possible initial parton types $i, j$. For the specified model with two effective parton species, a quark ($q$) and a gluon ($g$), the set of partons is $\\{q, g\\}$. The governing expression is:\n$$\n\\sigma(s) = \\sum_{i,j \\in \\{q,g\\}} \\int_0^1 dx_1 \\int_0^1 dx_2 \\, f_i(x_1)\\, f_j(x_2) \\, \\hat{\\sigma}_{ij}(x_1 x_2 s, \\mu)\n$$\nThe problem provides models for the quark-quark $(q,q)$ and gluon-gluon $(g,g)$ channels. The omission of definitions for the mixed channels, quark-gluon $(q,g)$ and gluon-quark $(g,q)$, implies that their contributions are to be considered zero, i.e., $\\hat{\\sigma}_{qg} = \\hat{\\sigma}_{gq} = 0$. This is a common and acceptable simplification in pedagogical models. With this assumption, the total cross section is the sum of two terms:\n$$\n\\sigma(s) = \\int_0^1 dx_1 \\int_0^1 dx_2 \\, f_q(x_1) f_q(x_2) \\hat{\\sigma}_{qq}(x_1 x_2 s) + \\int_0^1 dx_1 \\int_0^1 dx_2 \\, f_g(x_1) f_g(x_2) \\hat{\\sigma}_{gg}(x_1 x_2 s)\n$$\nIt is noted that the factorization scale $\\mu$, though provided in each test case, does not explicitly appear in the simplified, scale-independent forms of the Parton Distribution Functions (PDFs) $f_i(x)$ or the partonic cross sections $\\hat{\\sigma}_{ij}$ as they are defined in the problem. Consequently, $\\mu$ is not an active parameter in the calculation according to the provided model.\n\nThe PDFs, $f_i(x; \\lambda_i, \\eta_i)$, which describe the probability density of finding a parton $i$ carrying a momentum fraction $x$ of the parent hadron, are parameterized as:\n$$\nf_i(x;\\lambda_i,\\eta_i) = \\mathcal{N}_i(\\lambda_i,\\eta_i)\\, x^{-\\lambda_i}\\, (1-x)^{\\eta_i}\n$$\nfor $x \\in (0,1)$. The normalization constant $\\mathcal{N}_i$ is fixed by the condition that the total probability of finding the parton with any momentum fraction is unity:\n$$\n\\int_0^1 f_i(x;\\lambda_i,\\eta_i)\\,dx = 1\n$$\nThis requires $\\mathcal{N}_i$ to be the reciprocal of the integral of the unnormalized function. This integral is a representation of the Euler Beta function, $B(a,b)$:\n$$\n\\int_0^1 x^{-\\lambda_i}\\, (1-x)^{\\eta_i} dx = \\int_0^1 x^{(1-\\lambda_i)-1}\\, (1-x)^{(\\eta_i+1)-1} dx = B(1-\\lambda_i, \\eta_i+1)\n$$\nThe constraints $\\lambda_i  1$ and $\\eta_i  -1$ ensure that this integral converges. The normalization constant is thus given by:\n$$\n\\mathcal{N}_i(\\lambda_i,\\eta_i) = \\frac{1}{B(1-\\lambda_i, \\eta_i+1)}\n$$\nThis constant is calculated using the `scipy.special.beta` function.\n\nThe partonic cross sections $\\hat{\\sigma}_{ij}(s_{\\mathrm{hat}})$ describe the fundamental interaction between partons $i$ and $j$ at a partonic center-of-mass energy squared $s_{\\mathrm{hat}} = x_1 x_2 s$. The specified models are:\n$1$. Quark-quark channel: This is modeled by a Breit-Wigner resonance shape, characteristic of the production of an unstable particle.\n$$\n\\hat{\\sigma}_{qq}(s_{\\mathrm{hat}}; M, \\Gamma, K_{qq}) = K_{qq}\\, \\frac{M \\Gamma}{\\left(s_{\\mathrm{hat}} - M^2\\right)^2 + M^2 \\Gamma^2}\n$$\n$2$. Gluon-gluon channel: This is modeled as continuum production above a kinematic threshold $s_{\\mathrm{thr}}$.\n$$\n\\hat{\\sigma}_{gg}(s_{\\mathrm{hat}}; s_{\\mathrm{thr}}, p, \\sigma_{0,gg}) =\n\\begin{cases}\n\\sigma_{0,gg}\\, \\dfrac{\\left(1 - s_{\\mathrm{thr}}/s_{\\mathrm{hat}}\\right)^p}{s_{\\mathrm{hat}}},  s_{\\mathrm{hat}} \\ge s_{\\mathrm{thr}} \\\\\n0,  s_{\\mathrm{hat}}  s_{\\mathrm{thr}}\n\\end{cases}\n$$\n\nThe numerical evaluation of the double integrals is performed using a tensor-product Gauss-Legendre quadrature rule. For a generic two-dimensional integral over the unit square, this method gives the approximation:\n$$\n\\int_0^1 \\int_0^1 G(x_1, x_2) \\,dx_1 dx_2 \\approx \\sum_{k=1}^{N} \\sum_{l=1}^{N} w_k w_l \\, G(p_k, p_l)\n$$\nHere, $\\{p_k\\}_{k=1}^N$ and $\\{w_k\\}_{k=1}^N$ are the quadrature points (nodes) and weights, respectively, for a single dimension over the interval $[0,1]$. These are obtained by a linear transformation of the standard Gauss-Legendre quadrature elements defined on $[-1,1]$. If $\\{z_k, w'_k\\}$ are the standard nodes and weights on $[-1,1]$, the transformation $x = (z+1)/2$ maps them to $[0,1]$, yielding nodes $p_k = (z_k+1)/2$ and weights $w_k = w'_k/2$. The `numpy.polynomial.legendre.leggauss` function is used to generate the standard nodes and weights.\n\nThe algorithm is as follows:\n$1$. For a given number of quadrature points $N$, generate the nodes $\\{p_k\\}$ and weights $\\{w_k\\}$ on the interval $[0,1]$.\n$2$. For each parton type ($q$ and $g$), construct the PDF functions $f_q(x)$ and $f_g(x)$ using the specified parameters and the pre-calculated normalization constants.\n$3$. Construct the partonic cross section functions $\\hat{\\sigma}_{qq}(s_{\\mathrm{hat}})$ and $\\hat{\\sigma}_{gg}(s_{\\mathrm{hat}})$.\n$4$. The integral for each channel, e.g., $(q,q)$, is computed by evaluating the full integrand $I_{qq}(x_1, x_2) = f_q(x_1) f_q(x_2) \\hat{\\sigma}_{qq}(x_1 x_2 s)$ at all pairs of nodes $(p_k, p_l)$ and performing the weighted sum. This calculation is implemented efficiently using vectorized `numpy` operations. We form a matrix of partonic energies $S_{\\mathrm{hat}, kl} = p_k p_l s$, and evaluate all functions on matrices constructed from the vectors of nodes using outer products.\n$5$. The same procedure is applied to the $(g,g)$ channel.\n$6$. The total hadronic cross section $\\sigma$ is the sum of the results from the $(q,q)$ and $(g,g)$ channels.\n\nConvergence is verified by computing the cross section with two different quadrature point counts, $N_{\\mathrm{coarse}}$ and $N_{\\mathrm{fine}}$. The relative difference $\\delta = |\\sigma_{N_{\\mathrm{fine}}} - \\sigma_{N_{\\mathrm{coarse}}}| / |\\sigma_{N_{\\mathrm{fine}}}|$ is then compared to a specified tolerance $\\text{tol}$. The outcome is a boolean variable, denoted $\\text{conv\\_ok}$, which is true if $\\delta \\le \\text{tol}$. This procedure is carried out for each of the four test cases. The final result is a list of pairs, $[\\sigma_{N_{\\mathrm{fine}}}, \\text{conv\\_ok}]$, one for each case. The strong peaking of the PDFs as $x \\to 0$ (for $\\lambda_i > 0$) necessitates a robust quadrature scheme. Gauss-Legendre quadrature is appropriate as its nodes are strictly within the integration interval, thereby avoiding direct evaluation at the endpoints where singularities may exist.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import beta\n\ndef pdf_factory(lambda_i, eta_i):\n    \"\"\"\n    Creates a normalized Parton Distribution Function (PDF).\n\n    Args:\n        lambda_i (float): The 'x - 0' behavior parameter.\n        eta_i (float): The 'x - 1' behavior parameter.\n\n    Returns:\n        A function that computes the PDF f_i(x).\n    \"\"\"\n    if not (lambda_i  1.0 and eta_i  -1.0):\n        # This check is for correctness, but test cases are valid.\n        raise ValueError(\"PDF parameters must satisfy lambda_i  1 and eta_i  -1\")\n    \n    # Normalization constant derived from the Beta function\n    try:\n        norm = 1.0 / beta(1.0 - lambda_i, eta_i + 1.0)\n    except (ValueError, TypeError):\n        # Fallback for invalid beta function arguments, though problem constraints prevent this.\n        norm = 0.0\n\n    def pdf(x):\n        \"\"\"\n        Computes the PDF value at x.\n        x can be a float or a numpy array.\n        \"\"\"\n        # Gauss-Legendre nodes are in (0, 1), so no division by zero at x=0.\n        # Add a small epsilon to 1-x to avoid log(0) if x=1 node ever appears.\n        x_safe = np.asarray(x)\n        return norm * (x_safe**(-lambda_i)) * ((1.0 - x_safe)**eta_i)\n        \n    return pdf\n\ndef hat_sigma_qq_factory(M, Gamma, K_qq):\n    \"\"\"\n    Creates the quark-quark partonic cross section function.\n    \"\"\"\n    M2 = M**2\n    MGamma = M * Gamma\n    \n    def hat_sigma_qq(s_hat):\n        \"\"\"Computes the Breit-Wigner cross section.\"\"\"\n        return K_qq * MGamma / ((s_hat - M2)**2 + M2 * Gamma**2)\n        \n    return hat_sigma_qq\n\ndef hat_sigma_gg_factory(s_thr, p, sigma0_gg):\n    \"\"\"\n    Creates the gluon-gluon partonic cross section function.\n    \"\"\"\n    def hat_sigma_gg(s_hat):\n        \"\"\"Computes the threshold-like cross section.\"\"\"\n        # Use np.where for vectorized conditional logic.\n        # Ensure s_hat is not zero to avoid division by zero warnings,\n        # although s_hat will always be positive in this problem.\n        s_hat_safe = np.where(s_hat  0, s_hat, 1.0)\n        ratio = s_thr / s_hat_safe\n        value = sigma0_gg * ((1.0 - ratio)**p) / s_hat_safe\n        return np.where(s_hat = s_thr, value, 0.0)\n        \n    return hat_sigma_gg\n\ndef calculate_cross_section(N_points, s, f_q, f_g, hat_sigma_qq, hat_sigma_gg):\n    \"\"\"\n    Calculates the total hadronic cross section using Gauss-Legendre quadrature.\n    \"\"\"\n    if N_points = 0:\n        return 0.0\n\n    # Get standard Gauss-Legendre points and weights on [-1, 1]\n    z, w_hat = np.polynomial.legendre.leggauss(N_points)\n    \n    # Transform nodes and weights to the integration interval [0, 1]\n    x_nodes = (z + 1.0) / 2.0\n    w_nodes = w_hat / 2.0\n    \n    # Evaluate PDFs at the quadrature nodes\n    fq_vals = f_q(x_nodes)\n    fg_vals = f_g(x_nodes)\n    \n    # Vectorized calculation using outer products\n    w_matrix = np.outer(w_nodes, w_nodes)\n    x1x2_matrix = np.outer(x_nodes, x_nodes)\n    shat_matrix = x1x2_matrix * s\n    \n    # Quark-quark channel contribution\n    fqfq_matrix = np.outer(fq_vals, fq_vals)\n    sigma_qq_integrand_matrix = fqfq_matrix * hat_sigma_qq(shat_matrix)\n    sigma_qq = np.sum(w_matrix * sigma_qq_integrand_matrix)\n    \n    # Gluon-gluon channel contribution\n    fgfg_matrix = np.outer(fg_vals, fg_vals)\n    sigma_gg_integrand_matrix = fgfg_matrix * hat_sigma_gg(shat_matrix)\n    sigma_gg = np.sum(w_matrix * sigma_gg_integrand_matrix)\n    \n    # Total cross section is sum of channels (qg, gq assumed zero)\n    total_sigma = sigma_qq + sigma_gg\n    return total_sigma\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        {'s': 13000.0**2, 'lambda_q': 0.6, 'eta_q': 3.0, 'lambda_g': 0.3, 'eta_g': 5.0,\n         'M': 91.0, 'Gamma': 2.5, 'K_qq': 1.0e4, 's_thr': 350.0**2, 'p': 2.0, 'sigma0_gg': 1.0e5,\n         'N_coarse': 64, 'N_fine': 128, 'tol': 1.0e-3},\n        # Case 2\n        {'s': 13000.0**2, 'lambda_q': 0.95, 'eta_q': 4.0, 'lambda_g': 0.9, 'eta_g': 6.0,\n         'M': 91.0, 'Gamma': 2.5, 'K_qq': 1.0e4, 's_thr': 350.0**2, 'p': 2.0, 'sigma0_gg': 1.0e5,\n         'N_coarse': 64, 'N_fine': 128, 'tol': 2.0e-3},\n        # Case 3\n        {'s': 13000.0**2, 'lambda_q': 0.99, 'eta_q': 5.0, 'lambda_g': 0.95, 'eta_g': 7.0,\n         'M': 91.0, 'Gamma': 0.5, 'K_qq': 1.0e4, 's_thr': 350.0**2, 'p': 3.0, 'sigma0_gg': 1.0e5,\n         'N_coarse': 64, 'N_fine': 128, 'tol': 3.0e-3},\n        # Case 4\n        {'s': 13000.0**2, 'lambda_q': 0.7, 'eta_q': 3.0, 'lambda_g': 0.5, 'eta_g': 5.0,\n         'M': 6000.0, 'Gamma': 100.0, 'K_qq': 5.0e4, 's_thr': 2000.0**2, 'p': 2.0, 'sigma0_gg': 2.0e5,\n         'N_coarse': 64, 'N_fine': 128, 'tol': 1.0e-3}\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        # Create function objects for the current case's parameters\n        f_q = pdf_factory(case['lambda_q'], case['eta_q'])\n        f_g = pdf_factory(case['lambda_g'], case['eta_g'])\n        hat_sigma_qq = hat_sigma_qq_factory(case['M'], case['Gamma'], case['K_qq'])\n        hat_sigma_gg = hat_sigma_gg_factory(case['s_thr'], case['p'], case['sigma0_gg'])\n        \n        # Calculate cross sections for coarse and fine quadrature\n        sigma_coarse = calculate_cross_section(\n            case['N_coarse'], case['s'], f_q, f_g, hat_sigma_qq, hat_sigma_gg\n        )\n        sigma_fine = calculate_cross_section(\n            case['N_fine'], case['s'], f_q, f_g, hat_sigma_qq, hat_sigma_gg\n        )\n        \n        # Check convergence criterion\n        if sigma_fine != 0.0:\n            rel_diff = np.abs(sigma_fine - sigma_coarse) / np.abs(sigma_fine)\n        # Handle the case where sigma_fine is zero to avoid division by zero\n        elif sigma_coarse != 0.0:\n            rel_diff = np.inf \n        else: # Both are zero\n            rel_diff = 0.0\n            \n        conv_ok = bool(rel_diff = case['tol'])\n        \n        results.append([float(sigma_fine), conv_ok])\n\n    # Final print statement in the exact required format.\n    print(f\"{results}\")\n\nsolve()\n```", "id": "3514288"}, {"introduction": "While leading-order (LO) calculations provide a first estimate, precision physics requires moving to next-to-leading order (NLO) and beyond. This step introduces apparent infinities from infrared (soft and collinear) divergences in the theory, which must cancel in any physical observable. This practice [@problem_id:3514222] guides you through a toy model of the Catani-Seymour dipole subtraction method, a universal and powerful algorithm for managing these divergences, demonstrating numerically how the sum of real and virtual contributions yields a finite, meaningful result.", "problem": "You are tasked with implementing, in code, a subtraction framework that captures the universal factorization structure of Quantum Chromodynamics (QCD) infrared singularities for the partonic channel of Drell-Yan production at Next-to-Leading Order (NLO): the process $q\\bar{q}\\to \\gamma^* g$. Your goal is to numerically verify that the sum of the real-emission contribution with Catani-Seymour dipole subtraction and the sum of virtual plus mass-factorization counterterms is finite for a set of test inputs.\n\nFundamental base and scope:\n- Start from the factorization theorem for hadronic cross sections and the universal infrared structure of Quantum Chromodynamics (QCD). Use the leading-order Altarelli-Parisi splitting function for quark-to-quark gluon splitting, defined by\n  $$\n  P_{qq}(z) = C_F \\frac{1+z^2}{1-z},\n  $$\n  where $z \\in (0,1)$ is the momentum fraction carried by the quark after collinear emission, and $C_F$ is the quadratic Casimir in the fundamental representation. In the toy model below, set $C_F = 1$ and an overall normalization constant equal to $1$ to keep the observable dimensionless.\n- Use the Catani-Seymour subtraction idea at the partonic level for initial-state singularities. Consider the incoming quark along the $+z$ direction and the incoming antiquark along the $-z$ direction in the partonic center-of-mass frame. Denote by $\\theta$ the scattering angle of the emitted gluon relative to the incoming quark, and define $c \\equiv \\cos\\theta \\in [-1,1]$. The soft region corresponds to $z \\to 1$, while the two collinear regions correspond to $c \\to +1$ (collinear to the incoming quark) and $c \\to -1$ (collinear to the incoming antiquark).\n- Define a toy Catani-Seymour dipole kernel that reproduces the correct soft and collinear singular behavior of the real-emission squared matrix element:\n  $$\n  \\mathcal{D}(z,c) \\equiv \\frac{1+z^2}{1-z}\\left(\\frac{1}{1-c} + \\frac{1}{1+c}\\right).\n  $$\n  This contains the correct $z\\to 1$ and $c\\to \\pm 1$ singularities up to overall factors.\n- Define a toy real-emission differential density that contains the same singularities as the physical matrix element and a finite remainder:\n  $$\n  \\mathcal{R}(z,c) \\equiv \\mathcal{D}(z,c) + f_{\\mathrm{fin}}(z), \\quad f_{\\mathrm{fin}}(z) \\equiv 1 - z.\n  $$\n  This construction is consistent with the factorization of singularities: the difference $\\mathcal{R}-\\mathcal{D}$ is integrable in four dimensions and finite everywhere in the phase space.\n- In the subtraction formalism, the NLO partonic cross section can be represented schematically as\n  $$\n  \\sigma^{\\mathrm{NLO}} = \\underbrace{\\int_{z_{\\min}}^{1}\\int_{-1}^{1}\\left[\\mathcal{R}(z,c) - \\mathcal{D}(z,c)\\right]\\mathrm{d}c\\,\\mathrm{d}z}_{\\sigma_{\\mathrm{real}}^{\\mathrm{sub}}}\n  + \\underbrace{\\left(\\sigma_{\\mathrm{virt}} + \\sigma_{\\mathrm{int.\\,dipole}} + \\sigma_{\\mathrm{mf}}\\right)}_{\\sigma_{\\mathrm{counter}}}.\n  $$\n  Here $\\sigma_{\\mathrm{virt}}$ denotes virtual corrections, $\\sigma_{\\mathrm{int.\\,dipole}}$ denotes the integrated dipole contribution, and $\\sigma_{\\mathrm{mf}}$ denotes the mass-factorization counterterms that absorb initial-state collinear singularities into the Parton Distribution Functions (PDFs). In this toy model, you are to assume a finite renormalization scheme such that the sum of virtual and mass-factorization counterterms plus the integrated dipole is finite and vanishes:\n  $$\n  \\sigma_{\\mathrm{counter}} = 0.\n  $$\n  This choice reflects that all infrared singularities are removed after summing those pieces, leaving only a finite contribution from $\\sigma_{\\mathrm{real}}^{\\mathrm{sub}}$.\n\nNumerical implementation mandates:\n- Implement a stable numerical integrator for $\\sigma_{\\mathrm{real}}^{\\mathrm{sub}}$ using Gauss-Legendre quadrature for both $z$ and $c$. You must evaluate\n  $$\n  \\sigma_{\\mathrm{real}}^{\\mathrm{sub}}(z_{\\min}) = \\int_{z_{\\min}}^{1}\\int_{-1}^{1}\\left[\\mathcal{R}(z,c) - \\mathcal{D}(z,c)\\right]\\mathrm{d}c\\,\\mathrm{d}z.\n  $$\n- To emulate numerical stability safeguards common in Monte Carlo event generators, when evaluating denominators of the form $1-c$, $1+c$, or $1-z$, you must regulate them as $1-c \\to 1-c+\\varepsilon_c$, $1+c\\to 1+c+\\varepsilon_c$, and $1-z\\to 1-z+\\varepsilon_z$ with user-specified small positive parameters $\\varepsilon_c$ and $\\varepsilon_z$. The physics of subtraction guarantees that the final subtracted integrand is finite and the integral does not depend on these regulators in the limit of small $\\varepsilon_c$ and $\\varepsilon_z$.\n- Because $\\mathcal{R}(z,c) - \\mathcal{D}(z,c) = f_{\\mathrm{fin}}(z) = 1-z$ is finite and independent of $c$, the exact value of the integrated subtracted real-emission piece is\n  $$\n  \\sigma_{\\mathrm{real}}^{\\mathrm{sub}}(z_{\\min}) = \\int_{z_{\\min}}^{1}\\int_{-1}^{1}(1-z)\\,\\mathrm{d}c\\,\\mathrm{d}z = 2\\int_{z_{\\min}}^{1}(1-z)\\,\\mathrm{d}z = 1 - 2 z_{\\min} + z_{\\min}^2,\n  $$\n  which is a useful cross-check but should not be hard-coded as the result. Your code must compute the integral numerically by integrating $\\mathcal{R}-\\mathcal{D}$.\n- For this problem, you must take the sum of real, virtual, and mass-factorization counterterms to be\n  $$\n  \\sigma_{\\mathrm{total}}(z_{\\min};\\varepsilon_c,\\varepsilon_z) \\equiv \\sigma_{\\mathrm{real}}^{\\mathrm{sub}}(z_{\\min}) + \\sigma_{\\mathrm{counter}} = \\sigma_{\\mathrm{real}}^{\\mathrm{sub}}(z_{\\min}),\n  $$\n  and demonstrate numerically that it is finite and regulator-independent.\n\nAngle and unit conventions:\n- All angles are to be treated in radians. The output observable is dimensionless.\n\nTest suite:\n- Use the following four test cases, which probe typical and boundary regimes as well as regulator-independence:\n  1. $z_{\\min} = 0.2$, $\\varepsilon_c = 10^{-6}$, $\\varepsilon_z = 10^{-9}$.\n  2. $z_{\\min} = 0.95$, $\\varepsilon_c = 10^{-6}$, $\\varepsilon_z = 10^{-12}$.\n  3. $z_{\\min} = 0.2$, $\\varepsilon_c = 10^{-12}$, $\\varepsilon_z = 10^{-6}$.\n  4. $z_{\\min} = 0.5$, $\\varepsilon_c = 10^{-9}$, $\\varepsilon_z = 10^{-9}$.\n\nRequired outputs:\n- For each test case, compute the single floating-point number\n  $$\n  \\sigma_{\\mathrm{total}}(z_{\\min};\\varepsilon_c,\\varepsilon_z).\n  $$\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, \"[result1,result2,result3,result4]\"). The results must be in the same order as the test suite listed above.\n\nImplementation constraints:\n- You must implement Gauss-Legendre quadrature over both $z$ and $c$ with at least $32$ nodes in each integral to ensure numerical stability and accuracy.\n- Your implementation must be fully deterministic, use no randomness, and should not require any user input.", "solution": "The problem statement has been critically validated and is deemed valid. It is scientifically grounded in the principles of Quantum Chromodynamics (QCD), specifically the factorization of infrared singularities and the Catani-Seymour dipole subtraction method. It presents a well-posed, self-contained numerical problem with clear definitions, constraints, and objectives. The toy model, while simplified, is conceptually sound and provides a rigorous test of the numerical implementation of the subtraction formalism.\n\nThe task is to numerically compute the subtracted real-emission contribution to the Next-to-Leading Order (NLO) partonic cross section for a toy model of Drell-Yan production, $q\\bar{q}\\to \\gamma^* g$. This observable is denoted $\\sigma_{\\mathrm{real}}^{\\mathrm{sub}}(z_{\\min})$ and its sum with the other NLO contributions, $\\sigma_{\\mathrm{total}}$, is to be calculated. The problem simplifies the calculation by positing that the sum of virtual corrections and counterterms vanishes, $\\sigma_{\\mathrm{counter}} = 0$, a valid assumption within a toy model. Therefore, the quantity to be computed is\n$$\n\\sigma_{\\mathrm{total}}(z_{\\min};\\varepsilon_c,\\varepsilon_z) = \\sigma_{\\mathrm{real}}^{\\mathrm{sub}}(z_{\\min}) = \\int_{z_{\\min}}^{1}\\int_{-1}^{1}\\left[\\mathcal{R}(z,c) - \\mathcal{D}(z,c)\\right]\\mathrm{d}c\\,\\mathrm{d}z.\n$$\nThe functions $\\mathcal{R}(z,c)$ and $\\mathcal{D}(z,c)$ are defined as:\n$$\n\\mathcal{D}(z,c) \\equiv \\frac{1+z^2}{1-z}\\left(\\frac{1}{1-c} + \\frac{1}{1+c}\\right)\n$$\n$$\n\\mathcal{R}(z,c) \\equiv \\mathcal{D}(z,c) + f_{\\mathrm{fin}}(z), \\quad \\text{with } f_{\\mathrm{fin}}(z) = 1 - z.\n$$\nA key feature of the subtraction method is that while $\\mathcal{R}(z,c)$ and $\\mathcal{D}(z,c)$ are individually singular in the soft ($z \\to 1$) and collinear ($c \\to \\pm 1$) limits, their difference is finite everywhere:\n$$\n\\mathcal{R}(z,c) - \\mathcal{D}(z,c) = 1 - z.\n$$\nThe problem requires a numerical demonstration of this cancellation. We must numerically evaluate the regulated expressions, where denominators are protected by small positive parameters $\\varepsilon_z$ and $\\varepsilon_c$. The regulated dipole term is\n$$\n\\mathcal{D}_{\\mathrm{reg}}(z,c; \\varepsilon_c, \\varepsilon_z) = \\frac{1+z^2}{1-z+\\varepsilon_z}\\left(\\frac{1}{1-c+\\varepsilon_c} + \\frac{1}{1+c+\\varepsilon_c}\\right).\n$$\nThe regulated real-emission term is $\\mathcal{R}_{\\mathrm{reg}}(z,c; \\varepsilon_c, \\varepsilon_z) = \\mathcal{D}_{\\mathrm{reg}}(z,c; \\varepsilon_c, \\varepsilon_z) + (1 - z)$. The numerical integration must be performed on the difference $\\mathcal{R}_{\\mathrm{reg}} - \\mathcal{D}_{\\mathrm{reg}}$ at each evaluation point. This procedure tests the numerical stability of the subtraction, as the individual regulated terms can become very large near the singular regions, and their difference must still yield the correct finite result.\n\nThe numerical integration will be performed using Gauss-Legendre quadrature for both the $z$ and $c$ integrals, as specified. A double integral of a function $F(z,c)$ over the domain $[z_{\\min}, 1] \\times [-1, 1]$ is approximated as:\n$$\n\\int_{z_{\\min}}^{1}\\int_{-1}^{1} F(z,c) \\,\\mathrm{d}c\\,\\mathrm{d}z \\approx \\frac{1-z_{\\min}}{2} \\sum_{i=1}^{N_z} w_i^z \\left( \\frac{1-(-1)}{2} \\sum_{j=1}^{N_c} w_j^c F(z_i, c_j) \\right)\n$$\nwhere $(x_k, w_k)$ are the $N$-point Gauss-Legendre nodes and weights on the interval $[-1, 1]$. The integration variables $z_i$ and $c_j$ are obtained by mapping the standard nodes $x_k$ to the respective integration intervals:\n$$\nz_i = \\frac{1-z_{\\min}}{2}x_i^z + \\frac{1+z_{\\min}}{2} \\quad \\text{and} \\quad c_j = x_j^c.\n$$\nThe problem specifies using at least $N_z = N_c = 32$ nodes. The implementation will use $N=32$ nodes for both dimensions. The required nodes and weights will be obtained from `scipy.special.roots_legendre`. The calculation will be performed for each test case, and the results should be consistent with the analytical value of the integral, which serves as a crucial cross-check:\n$$\n\\sigma_{\\mathrm{real}}^{\\mathrm{sub}}(z_{\\min}) = \\int_{z_{\\min}}^{1}\\int_{-1}^{1}(1-z)\\,\\mathrm{d}c\\,\\mathrm{d}z = 2 \\int_{z_{\\min}}^{1}(1-z)\\,\\mathrm{d}z = 2\\left[z - \\frac{z^2}{2}\\right]_{z_{\\min}}^1 = (1-z_{\\min})^2.\n$$\nThe numerical results are expected to be very close to this analytical formula, demonstrating that the subtraction scheme is correctly implemented and numerically stable, and that the result is independent of the specific small values chosen for the regulators $\\varepsilon_c$ and $\\varepsilon_z$.", "answer": "```python\nimport numpy as np\nfrom scipy.special import roots_legendre\n\ndef solve():\n    \"\"\"\n    Calculates the total cross section for a toy QCD process\n    using the Catani-Seymour dipole subtraction method.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (z_min, eps_c, eps_z)\n        (0.2, 1e-6, 1e-9),\n        (0.95, 1e-6, 1e-12),\n        (0.2, 1e-12, 1e-6),\n        (0.5, 1e-9, 1e-9),\n    ]\n\n    # Set the number of nodes for Gauss-Legendre quadrature.\n    # The problem requires at least 32 nodes.\n    NUM_NODES = 32\n    nodes, weights = roots_legendre(NUM_NODES)\n\n    def D_regulated(z, c, eps_z, eps_c):\n        \"\"\"\n        Calculates the regulated toy Catani-Seymour dipole kernel D(z,c).\n        \"\"\"\n        term_z = (1.0 + z**2) / (1.0 - z + eps_z)\n        term_c = 1.0 / (1.0 - c + eps_c) + 1.0 / (1.0 + c + eps_c)\n        return term_z * term_c\n\n    def R_regulated(z, c, eps_z, eps_c):\n        \"\"\"\n        Calculates the regulated toy real-emission differential density R(z,c).\n        \"\"\"\n        return D_regulated(z, c, eps_z, eps_c) + (1.0 - z)\n\n    def calculate_sigma_total(z_min, eps_c, eps_z):\n        \"\"\"\n        Performs the 2D numerical integration of (R - D) using\n        Gauss-Legendre quadrature.\n        \"\"\"\n        # Map the standard [-1, 1] nodes to the integration intervals.\n        # For c, the interval is [-1, 1], so c_coords = nodes.\n        c_coords = nodes\n        # For z, the interval is [z_min, 1].\n        z_map_factor = 0.5 * (1.0 - z_min)\n        z_map_offset = 0.5 * (1.0 + z_min)\n        z_coords = z_map_factor * nodes + z_map_offset\n\n        # Create 2D grids for coordinates and weights for vectorized evaluation.\n        z_grid, c_grid = np.meshgrid(z_coords, c_coords, indexing='ij')\n        w_z_grid, w_c_grid = np.meshgrid(weights, weights, indexing='ij')\n\n        # Evaluate the regulated R and D functions on the grid.\n        # The core of the subtraction method is to compute the difference of the\n        # full expressions numerically at each point.\n        r_vals = R_regulated(z_grid, c_grid, eps_z, eps_c)\n        d_vals = D_regulated(z_grid, c_grid, eps_z, eps_c)\n\n        # The integrand is the difference, which should be finite.\n        integrand = r_vals - d_vals\n\n        # Perform the weighted sum over the 2D grid.\n        # The integration weight for the c-integral is (1 - (-1))/2 = 1.\n        # The integration weight for the z-integral is (1 - z_min)/2.\n        integral = np.sum(w_z_grid * w_c_grid * integrand) * z_map_factor\n\n        return integral\n\n    results = []\n    for case in test_cases:\n        z_min_val, eps_c_val, eps_z_val = case\n        # According to the problem, sigma_total = sigma_real_sub, as sigma_counter = 0.\n        sigma_total = calculate_sigma_total(z_min_val, eps_c_val, eps_z_val)\n        results.append(sigma_total)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3514222"}, {"introduction": "Collinear factorization provides the total cross section but integrates over the transverse momentum ($q_T$) of the final state. To describe more exclusive observables, such as the $q_T$ spectrum of a produced Z boson, a more sophisticated framework is needed. This practice [@problem_id:3514286] introduces you to Transverse-Momentum Dependent (TMD) factorization, which systematically accounts for the intrinsic transverse motion of partons inside the proton, providing predictive power in the crucial low-$q_T$ region where most events occur.", "problem": "You are to derive and implement a computational model of Transverse-Momentum Dependent (TMD) factorization for low transverse momentum production in hadronic collisions, focusing on the process of proton-proton production of a neutral boson with accompanying radiation. Work within the setting of the partonic picture of Quantum Chromodynamics (QCD), specifically the factorization of soft and collinear dynamics at low transverse momentum derived from the separate roles of beam functions and the soft function. Your derivation must start from foundational definitions: the two-dimensional Fourier transform between impact parameter space and transverse-momentum space, rotational invariance in the transverse plane, and the convolution properties that arise from multiplicative structures in impact parameter space. Use these facts to establish the form of the transverse-momentum spectrum as a transform of an isotropic model in impact parameter space, without invoking any shortcut formulas beyond these base definitions.\n\nYou will model Transverse-Momentum Dependent (TMD) beam functions $B_i(x,b,\\mu,\\zeta)$ and the soft function $S(b,\\mu,\\zeta)$ using Gaussian ans√§tze that are consistent with the expectation of Sudakov suppression at large impact parameter $b$. You will restrict attention to the dominant light quark flavors for neutral boson production and use a toy but scientifically consistent parameterization of the parton distribution function (PDF) shapes and electroweak couplings. Your computational task is to assemble a mixture model across two quark flavors and to compare the normalized TMD prediction against a pseudo parton-shower model that produces transverse-momentum smearing via Gaussian broadening. The output metric for each test case is the root-mean-square error between the TMD prediction and the pseudo-shower across a prescribed grid of transverse momenta.\n\nYour program must adhere to the following modeling assumptions:\n\n- Beam functions are flavor dependent. For flavor $i \\in \\{u,d\\}$,\n  $$\n  B_i(x,b,\\mu,\\zeta) = f_i(x)\\,\\exp\\!\\big(-\\beta_{B,i}(\\mu,\\zeta)\\,b^2\\big),\n  $$\n  where $f_i(x)$ is a toy Parton Distribution Function (PDF) shape, and $\\beta_{B,i}(\\mu,\\zeta)$ encodes scale and rapidity dependence. The toy PDF is given for $i \\in \\{u,d\\}$ by\n  $$\n  f_u(x) = C_u\\,x^{-a_u}(1-x)^{b_u}, \\quad f_d(x) = C_d\\,x^{-a_d}(1-x)^{b_d},\n  $$\n  with fixed constants $C_u$, $C_d$, $a_u$, $a_d$, $b_u$, $b_d$ provided in the test suite below.\n- The soft function is isotropic and modeled as\n  $$\n  S(b,\\mu,\\zeta) = \\exp\\!\\big(-\\beta_S(\\mu,\\zeta)\\,b^2\\big).\n  $$\n- The total broadening parameter for flavor $i$ is\n  $$\n  \\beta_i(\\mu,\\zeta_1,\\zeta_2) = \\beta_{B,i}(\\mu,\\zeta_1) + \\beta_{B,i}(\\mu,\\zeta_2) + \\beta_S(\\mu,\\sqrt{\\zeta_1\\zeta_2}),\n  $$\n  ensuring positivity of the exponent for all scales.\n- The mixture weight for flavor $i$ entering neutral boson production is\n  $$\n  W_i = w_i\\,f_i(x_1)\\,f_i(x_2),\n  $$\n  where $w_i = v_i^2 + a_i^2$ uses Standard Model neutral-current couplings with $v_u = \\tfrac{1}{2} - \\tfrac{4}{3}\\sin^2\\theta_W$, $a_u = \\tfrac{1}{2}$, $v_d = -\\tfrac{1}{2} + \\tfrac{2}{3}\\sin^2\\theta_W$, $a_d = -\\tfrac{1}{2}$, and $\\sin^2\\theta_W$ provided in the test suite below.\n- The hard factor $H(Q,\\mu)$ multiplies the spectrum but will be normalized out by comparing shapes. You may use a one-loop running for the strong coupling to maintain scientific realism:\n  $$\n  \\alpha_s(\\mu) = \\frac{4\\pi}{\\beta_0 \\ln(\\mu^2/\\Lambda_{\\text{QCD}}^2)}, \\quad \\beta_0 = 11 - \\frac{2}{3}n_f,\n  $$\n  with $n_f$ and $\\Lambda_{\\text{QCD}}$ specified below.\n\nDerivation target from the base:\n- Starting from the two-dimensional Fourier transform definition\n  $$\n  \\tilde{F}(\\mathbf{q}_T) = \\int d^2\\mathbf{b}\\,e^{i\\mathbf{q}_T\\cdot\\mathbf{b}}\\,F(b),\n  $$\n  and using rotational symmetry of $F(b)$, derive the radial representation in terms of the zeroth-order Bessel function of the first kind $J_0$,\n  $$\n  \\tilde{F}(q_T) = 2\\pi\\int_0^\\infty db\\,b\\,J_0(q_T b)\\,F(b).\n  $$\n  Then, for the Gaussian model $F(b) = \\sum_i W_i\\exp(-\\beta_i b^2)$, deduce the corresponding mixture shape in transverse momentum and construct the normalized spectrum\n  $$\n  \\mathcal{S}_{\\text{TMD}}(q_T) = \\frac{\\sum_i W_i\\,\\mathcal{K}(q_T;\\beta_i)}{\\sum_i W_i\\,\\mathcal{K}(0;\\beta_i)},\n  $$\n  where $\\mathcal{K}(q_T;\\beta_i)$ is the radial transform of a Gaussian with width parameter $\\beta_i$.\n\nPseudo parton-shower comparison:\n- Build a pseudo-shower model with flavor-dependent Gaussian smearing widths\n  $$\n  \\sigma_i^2 = \\kappa\\cdot 2\\beta_i(\\mu,\\zeta_1,\\zeta_2),\n  $$\n  where $\\kappa$ is a dimensionless scale factor per test case. Define a normalized pseudo-shower mixture\n  $$\n  \\mathcal{S}_{\\text{PS}}(q_T) = \\frac{\\sum_i W_i\\,G(q_T;\\sigma_i)}{\\sum_i W_i\\,G(0;\\sigma_i)},\n  $$\n  where $G(q_T;\\sigma) = \\exp\\!\\big(-q_T^2/(2\\sigma^2)\\big)$ is the isotropic Gaussian shape in two dimensions evaluated at magnitude $q_T$ (normalization factors cancel after dividing by its value at $q_T = 0$).\n\nValidation metric:\n- For each test case, evaluate the root-mean-square error (RMSE)\n  $$\n  \\text{RMSE} = \\sqrt{\\frac{1}{N}\\sum_{n=1}^N \\left(\\mathcal{S}_{\\text{TMD}}(q_{T,n}) - \\mathcal{S}_{\\text{PS}}(q_{T,n})\\right)^2},\n  $$\n  across a specified grid $\\{q_{T,n}\\}_{n=1}^N$.\n\nUse the following fixed constants for all test cases:\n- The boson invariant mass $Q = $ $91.1876$.\n- The sine squared of the weak mixing angle $\\sin^2\\theta_W = $ $0.2312$.\n- The number of active flavors $n_f = $ $5$.\n- The Quantum Chromodynamics (QCD) scale $\\Lambda_{\\text{QCD}} = $ $0.2$.\n- The reference scale $Q_0 = $ $1.0$.\n- Toy PDF parameters: $C_u = $ $1.0$, $a_u = $ $0.3$, $b_u = $ $3.0$; $C_d = $ $1.0$, $a_d = $ $0.5$, $b_d = $ $4.0$.\n\nParameterization of $\\beta_{B,i}$ and $\\beta_S$ to ensure scale dependence and positivity:\n- For $i \\in \\{u,d\\}$,\n  $$\n  \\beta_{B,i}(\\mu,\\zeta) = \\lambda_{B,i}\\left[1 + c_B\\ln\\!\\left(\\frac{\\mu}{Q_0}\\right) + c_\\zeta\\ln\\!\\left(\\frac{\\sqrt{\\zeta}}{Q_0}\\right)\\right].\n  $$\n- Soft function parameterization,\n  $$\n  \\beta_S(\\mu,\\zeta) = \\lambda_S\\left[1 + c_S\\ln\\!\\left(\\frac{\\mu}{Q_0}\\right) + c_{S\\zeta}\\ln\\!\\left(\\frac{\\sqrt{\\zeta}}{Q_0}\\right)\\right].\n  $$\n\nTest suite:\n- Case $1$ (happy path, matched pseudo-shower width):\n  - $(\\mu, x_1, x_2, \\zeta_1, \\zeta_2) = ($ $91.1876$, $0.1$, $0.1$, $91.1876^2$, $91.1876^2$ $)$,\n  - $(\\lambda_{B,u}, \\lambda_{B,d}, c_B, c_\\zeta) = ($ $0.20$, $0.25$, $0.10$, $0.05$ $)$,\n  - $(\\lambda_S, c_S, c_{S\\zeta}) = ($ $0.15$, $0.08$, $0.04$ $)$,\n  - $q_T$ grid: $[$ $0.0$, $0.5$, $1.0$, $2.0$, $5.0$ $]$,\n  - pseudo-shower scale $\\kappa = $ $1.0$.\n- Case $2$ (boundary, very small $q_T$ values, matched widths):\n  - $(\\mu, x_1, x_2, \\zeta_1, \\zeta_2) = ($ $91.1876$, $0.1$, $0.1$, $91.1876^2$, $91.1876^2$ $)$,\n  - $(\\lambda_{B,u}, \\lambda_{B,d}, c_B, c_\\zeta) = ($ $0.20$, $0.25$, $0.10$, $0.05$ $)$,\n  - $(\\lambda_S, c_S, c_{S\\zeta}) = ($ $0.15$, $0.08$, $0.04$ $)$,\n  - $q_T$ grid: $[$ $0.0$, $0.05$, $0.1$, $0.2$, $0.5$ $]$,\n  - pseudo-shower scale $\\kappa = $ $1.0$.\n- Case $3$ (mismatched scales, narrower pseudo-shower):\n  - $(\\mu, x_1, x_2, \\zeta_1, \\zeta_2) = ($ $2\\times 91.1876$, $0.1$, $0.1$, $91.1876^2$, $91.1876^2$ $)$,\n  - $(\\lambda_{B,u}, \\lambda_{B,d}, c_B, c_\\zeta) = ($ $0.20$, $0.25$, $0.10$, $0.05$ $)$,\n  - $(\\lambda_S, c_S, c_{S\\zeta}) = ($ $0.15$, $0.08$, $0.04$ $)$,\n  - $q_T$ grid: $[$ $0.0$, $1.0$, $2.0$, $5.0$, $10.0$ $]$,\n  - pseudo-shower scale $\\kappa = $ $0.8$.\n- Case $4$ (high-$q_T$ boundary of TMD validity, broader pseudo-shower):\n  - $(\\mu, x_1, x_2, \\zeta_1, \\zeta_2) = ($ $91.1876$, $0.1$, $0.1$, $91.1876^2$, $91.1876^2$ $)$,\n  - $(\\lambda_{B,u}, \\lambda_{B,d}, c_B, c_\\zeta) = ($ $0.20$, $0.25$, $0.10$, $0.05$ $)$,\n  - $(\\lambda_S, c_S, c_{S\\zeta}) = ($ $0.15$, $0.08$, $0.04$ $)$,\n  - $q_T$ grid: $[$ $0.0$, $5.0$, $10.0$, $20.0$, $30.0$ $]$,\n  - pseudo-shower scale $\\kappa = $ $1.2$.\n\nYour program must implement the derivation-based model, compute the normalized TMD spectrum $\\mathcal{S}_{\\text{TMD}}(q_T)$ and the normalized pseudo-shower spectrum $\\mathcal{S}_{\\text{PS}}(q_T)$ on the specified grids, and output the RMSE for each case. Use natural units so that all computed outputs are dimensionless; no physical unit conversion is required. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[$$r_1$,$r_2$,$r_3$,$r_4$$]$), where $r_k$ are floating-point values of the RMSE for each test case in the order above.", "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the principles of Quantum Chromodynamics (QCD) and Transverse-Momentum Dependent (TMD) factorization, is well-posed with all necessary information provided, and is expressed in objective, formal language. We may therefore proceed with the derivation and solution.\n\nThe primary task is to derive and implement a model for the transverse momentum ($q_T$) spectrum of a neutral boson produced in a proton-proton collision. The model is based on TMD factorization, which separates the dynamics into contributions from incoming partons (beam functions) and their soft gluon interactions (soft function).\n\n### Part 1: Derivation of the Transverse Momentum Spectrum\n\nThe TMD factorization theorem for the differential cross section in the low-$q_T$ region, for a process like $p+p \\to V+X$ where $V$ is a neutral boson, can be expressed in impact parameter ($b$) space. The impact parameter $\\mathbf{b}$ is the two-dimensional Fourier conjugate to the transverse momentum $\\mathbf{q}_T$. The cross section in $b$-space has a multiplicative structure:\n$$\n\\frac{d\\sigma}{d^2\\mathbf{b}} \\propto \\sum_i H_i(Q,\\mu) \\times \\left[ B_i(x_1, b, \\mu, \\zeta_1) B_i(x_2, b, \\mu, \\zeta_2) \\right] \\times S(b, \\mu, \\sqrt{\\zeta_1 \\zeta_2}).\n$$\nHere, $i$ sums over quark flavors (in our case, $u$ and $d$), $H_i$ is the hard-scattering factor, $B_i$ are the TMD beam functions, and $S$ is the soft function. The variables are the boson invariant mass $Q$, the partonic momentum fractions $x_1, x_2$, the factorization scale $\\mu$, and the rapidity scales $\\zeta_1, \\zeta_2$. The hard factor $H_i(Q,\\mu)$ includes the quark electroweak couplings and is independent of $b$. Since we are only interested in the normalized $q_T$ shape, this factor will cancel.\n\nThe problem provides Gaussian models for the $b$-dependence of the beam and soft functions:\n$$\nB_i(x,b,\\mu,\\zeta) = f_i(x)\\,\\exp\\!\\big(-\\beta_{B,i}(\\mu,\\zeta)\\,b^2\\big)\n$$\n$$\nS(b,\\mu,\\zeta) = \\exp\\!\\big(-\\beta_S(\\mu,\\zeta)\\,b^2\\big)\n$$\nSubstituting these into the factorization formula, the transverse-part of the cross section in $b$-space for a given flavor $i$ becomes:\n$$\nF_i(b) = w_i f_i(x_1)f_i(x_2) \\exp(-\\beta_{B,i}(\\mu,\\zeta_1)b^2) \\exp(-\\beta_{B,i}(\\mu,\\zeta_2)b^2) \\exp(-\\beta_S(\\mu,\\sqrt{\\zeta_1\\zeta_2})b^2)\n$$\nwhere we have replaced the hard factor with the electroweak weight $w_i = v_i^2+a_i^2$. This simplifies to:\n$$\nF_i(b) = W_i \\exp(-\\beta_i b^2)\n$$\nwith the mixture weight $W_i = w_i f_i(x_1) f_i(x_2)$ and the total broadening parameter $\\beta_i = \\beta_{B,i}(\\mu,\\zeta_1) + \\beta_{B,i}(\\mu,\\zeta_2) + \\beta_S(\\mu,\\sqrt{\\zeta_1\\zeta_2})$. The total un-normalized cross section in $b$-space is the sum over flavors, $F(b) = \\sum_i F_i(b)$.\n\nThe transverse momentum spectrum is obtained by performing a two-dimensional Fourier transform:\n$$\n\\frac{d\\sigma}{d^2\\mathbf{q}_T} = \\tilde{F}(\\mathbf{q}_T) = \\int d^2\\mathbf{b}\\,e^{i\\mathbf{q}_T\\cdot\\mathbf{b}}\\,F(b)\n$$\nSince $F(b)$ depends only on the magnitude $b=|\\mathbf{b}|$, it is rotationally symmetric. We can evaluate the integral in polar coordinates. Let $\\mathbf{b} = (b\\cos\\phi_b, b\\sin\\phi_b)$ and $\\mathbf{q}_T = (q_T\\cos\\phi_q, q_T\\sin\\phi_q)$. The integration measure is $d^2\\mathbf{b} = b\\,db\\,d\\phi_b$. The dot product is $\\mathbf{q}_T \\cdot \\mathbf{b} = q_T b \\cos(\\phi_b - \\phi_q)$. The integral becomes:\n$$\n\\tilde{F}(\\mathbf{q}_T) = \\int_0^\\infty db\\,b\\,F(b) \\int_0^{2\\pi} d\\phi_b\\,e^{i q_T b \\cos(\\phi_b - \\phi_q)}\n$$\nThe inner integral over the angle $\\phi_b$ is an integral representation of the zeroth-order Bessel function of the first kind, $J_0(z) = \\frac{1}{2\\pi}\\int_0^{2\\pi}d\\theta\\,e^{iz\\cos\\theta}$. The integral evaluates to $2\\pi J_0(q_T b)$. This result is independent of $\\phi_q$, so the transform $\\tilde{F}(q_T)$ is also rotationally symmetric, as expected. Thus, we arrive at the radial representation:\n$$\n\\tilde{F}(q_T) = 2\\pi \\int_0^\\infty db\\,b\\,J_0(q_T b)\\,F(b)\n$$\nThis completes the first part of the derivation. Now, we apply this to our Gaussian model. The linearity of the Fourier transform allows us to transform each flavor component separately. Let $\\mathcal{K}(q_T; \\beta_i)$ be the transform of $\\exp(-\\beta_i b^2)$:\n$$\n\\mathcal{K}(q_T; \\beta_i) = 2\\pi \\int_0^\\infty db\\,b\\,J_0(q_T b)\\,\\exp(-\\beta_i b^2)\n$$\nThis is a standard Hankel transform of a Gaussian. The integral is known to be $\\int_0^\\infty dx\\,x\\,J_0(kx)\\exp(-ax^2) = \\frac{1}{2a}\\exp(-\\frac{k^2}{4a})$. With $x=b$, $k=q_T$, and $a=\\beta_i$, we get:\n$$\n\\mathcal{K}(q_T; \\beta_i) = 2\\pi \\left( \\frac{1}{2\\beta_i}\\exp\\left(-\\frac{q_T^2}{4\\beta_i}\\right) \\right) = \\frac{\\pi}{\\beta_i}\\exp\\left(-\\frac{q_T^2}{4\\beta_i}\\right)\n$$\nThe total un-normalized $q_T$ spectrum is $\\tilde{F}(q_T) = \\sum_i W_i \\mathcal{K}(q_T; \\beta_i)$.\n\n### Part 2: Normalized Spectra and RMSE\n\nTo compare shapes, we define the normalized TMD spectrum $\\mathcal{S}_{\\text{TMD}}(q_T)$ by dividing by the total spectrum at $q_T=0$.\n$$\n\\mathcal{K}(0; \\beta_i) = \\frac{\\pi}{\\beta_i}\n$$\n$$\n\\mathcal{S}_{\\text{TMD}}(q_T) = \\frac{\\sum_i W_i \\mathcal{K}(q_T; \\beta_i)}{\\sum_j W_j \\mathcal{K}(0; \\beta_j)} = \\frac{\\sum_i W_i \\frac{\\pi}{\\beta_i}\\exp(-\\frac{q_T^2}{4\\beta_i})}{\\sum_j W_j \\frac{\\pi}{\\beta_j}} = \\frac{\\sum_i \\frac{W_i}{\\beta_i}\\exp(-\\frac{q_T^2}{4\\beta_i})}{\\sum_j \\frac{W_j}{\\beta_j}}\n$$\nThe pseudo parton-shower (PS) model is defined directly in $q_T$ space as a mixture of Gaussians, $G(q_T;\\sigma) = \\exp(-q_T^2/(2\\sigma^2))$, with variance $\\sigma_i^2 = 2\\kappa\\beta_i$.\nThe exponential term is $\\exp(-q_T^2/(4\\kappa\\beta_i))$. The value at $q_T=0$ is $G(0;\\sigma_i)=1$.\nThe normalized PS spectrum is:\n$$\n\\mathcal{S}_{\\text{PS}}(q_T) = \\frac{\\sum_i W_i G(q_T; \\sigma_i)}{\\sum_j W_j G(0; \\sigma_j)} = \\frac{\\sum_i W_i \\exp(-\\frac{q_T^2}{4\\kappa\\beta_i})}{\\sum_j W_j}\n$$\nThe TMD and PS models differ in their mixture weights. The TMD model weights flavor $i$ by $W_i/\\beta_i$, which arises from the Fourier transform of the $b$-space distribution, whereas the PS model weights by $W_i$.\n\nFinally, the root-mean-square error (RMSE) between the two models on a grid of $N$ points $\\{q_{T,n}\\}$ is:\n$$\n\\text{RMSE} = \\sqrt{\\frac{1}{N}\\sum_{n=1}^N \\left(\\mathcal{S}_{\\text{TMD}}(q_{T,n}) - \\mathcal{S}_{\\text{PS}}(q_{T,n})\\right)^2}\n$$\n\n### Part 3: Algorithmic Implementation\n\nThe computational procedure for each test case is as follows:\n1.  **Calculate Mixture Weights**: Using the given parameters for $x_1, x_2$, and the toy PDF forms, compute $f_u(x_1)$, $f_u(x_2)$, $f_d(x_1)$, and $f_d(x_2)$. Using the value for $\\sin^2\\theta_W$, compute the electroweak factors $w_u$ and $w_d$. Combine these to get the final mixture weights $W_u = w_u f_u(x_1)f_u(x_2)$ and $W_d = w_d f_d(x_1)f_d(x_2)$.\n2.  **Calculate Broadening Parameters**: For the given scales $\\mu, \\zeta_1, \\zeta_2$ and model parameters $(\\lambda, c)$, compute the beam function widths $\\beta_{B,i}(\\mu,\\zeta_1)$ and $\\beta_{B,i}(\\mu,\\zeta_2)$ for each flavor $i \\in \\{u,d\\}$. Compute the soft function width $\\beta_S(\\mu, \\sqrt{\\zeta_1\\zeta_2})$. Sum these to get the total broadening parameters $\\beta_u$ and $\\beta_d$.\n3.  **Evaluate Spectra**: For each $q_T$ value in the specified grid, calculate $\\mathcal{S}_{\\text{TMD}}(q_T)$ and $\\mathcal{S}_{\\text{PS}}(q_T)$ using the derived formulas. This involves evaluating the weighted sums of Gaussians for both models.\n4.  **Compute RMSE**: Using the arrays of predicted values from both models, compute the RMSE. This final value is the result for the test case.\n\nThis procedure will be repeated for all four test cases provided.", "answer": "```python\nimport numpy as np\nimport scipy.special # Imported to adhere to specified execution environment.\n\ndef solve():\n    \"\"\"\n    Derives and implements a computational model of TMD factorization for\n    low-qT boson production and computes a comparison metric against\n    a pseudo-parton shower model.\n    \"\"\"\n    # --- Fixed Constants specified in the problem ---\n    Q = 91.1876\n    SIN2_THETA_W = 0.2312\n    Q0 = 1.0\n    # Toy PDF parameters\n    C_U, A_U, B_U = 1.0, 0.3, 3.0\n    C_D, A_D, B_D = 1.0, 0.5, 4.0\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: Happy path, matched pseudo-shower width\n        {\n            \"params\": (91.1876, 0.1, 0.1, 91.1876**2, 91.1876**2),\n            \"beam_params\": (0.20, 0.25, 0.10, 0.05),\n            \"soft_params\": (0.15, 0.08, 0.04),\n            \"qT_grid\": np.array([0.0, 0.5, 1.0, 2.0, 5.0]),\n            \"kappa\": 1.0\n        },\n        # Case 2: Boundary, very small qT values, matched widths\n        {\n            \"params\": (91.1876, 0.1, 0.1, 91.1876**2, 91.1876**2),\n            \"beam_params\": (0.20, 0.25, 0.10, 0.05),\n            \"soft_params\": (0.15, 0.08, 0.04),\n            \"qT_grid\": np.array([0.0, 0.05, 0.1, 0.2, 0.5]),\n            \"kappa\": 1.0\n        },\n        # Case 3: Mismatched scales, narrower pseudo-shower\n        {\n            \"params\": (2 * 91.1876, 0.1, 0.1, 91.1876**2, 91.1876**2),\n            \"beam_params\": (0.20, 0.25, 0.10, 0.05),\n            \"soft_params\": (0.15, 0.08, 0.04),\n            \"qT_grid\": np.array([0.0, 1.0, 2.0, 5.0, 10.0]),\n            \"kappa\": 0.8\n        },\n        # Case 4: High-qT boundary, broader pseudo-shower\n        {\n            \"params\": (91.1876, 0.1, 0.1, 91.1876**2, 91.1876**2),\n            \"beam_params\": (0.20, 0.25, 0.10, 0.05),\n            \"soft_params\": (0.15, 0.08, 0.04),\n            \"qT_grid\": np.array([0.0, 5.0, 10.0, 20.0, 30.0]),\n            \"kappa\": 1.2\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        mu, x1, x2, zeta1, zeta2 = case[\"params\"]\n        lambda_Bu, lambda_Bd, c_B, c_zeta = case[\"beam_params\"]\n        lambda_S, c_S, c_S_zeta = case[\"soft_params\"]\n        qT_grid = case[\"qT_grid\"]\n        kappa = case[\"kappa\"]\n\n        # --- Step 1: Calculate Mixture Weights (W_i) ---\n        def f_i(x, C, a, b):\n            return C * x**(-a) * (1 - x)**b\n\n        f_u_x1 = f_i(x1, C_U, A_U, B_U)\n        f_u_x2 = f_i(x2, C_U, A_U, B_U)\n        f_d_x1 = f_i(x1, C_D, A_D, B_D)\n        f_d_x2 = f_i(x2, C_D, A_D, B_D)\n        \n        # Electroweak couplings\n        v_u = 0.5 - (4.0/3.0) * SIN2_THETA_W\n        a_u = 0.5\n        w_u = v_u**2 + a_u**2\n        \n        v_d = -0.5 + (2.0/3.0) * SIN2_THETA_W\n        a_d = -0.5\n        w_d = v_d**2 + a_d**2\n        \n        W_u = w_u * f_u_x1 * f_u_x2\n        W_d = w_d * f_d_x1 * f_d_x2\n\n        # --- Step 2: Calculate Broadening Parameters (beta_i) ---\n        def beta_B_i(mu_val, zeta_val, lambda_B, c_B_val, c_zeta_val):\n            term_mu = c_B_val * np.log(mu_val / Q0)\n            term_zeta = c_zeta_val * np.log(np.sqrt(zeta_val) / Q0)\n            return lambda_B * (1.0 + term_mu + term_zeta)\n\n        def beta_S(mu_val, zeta_val, lambda_S_val, c_S_val, c_S_zeta_val):\n            term_mu = c_S_val * np.log(mu_val / Q0)\n            term_zeta = c_S_zeta_val * np.log(np.sqrt(zeta_val) / Q0)\n            return lambda_S_val * (1.0 + term_mu + term_zeta)\n        \n        beta_B_u1 = beta_B_i(mu, zeta1, lambda_Bu, c_B, c_zeta)\n        beta_B_u2 = beta_B_i(mu, zeta2, lambda_Bu, c_B, c_zeta)\n        \n        beta_B_d1 = beta_B_i(mu, zeta1, lambda_Bd, c_B, c_zeta)\n        beta_B_d2 = beta_B_i(mu, zeta2, lambda_Bd, c_B, c_zeta)\n        \n        zeta_eff_S = np.sqrt(zeta1 * zeta2)\n        beta_S_val = beta_S(mu, zeta_eff_S, lambda_S, c_S, c_S_zeta)\n        \n        beta_u = beta_B_u1 + beta_B_u2 + beta_S_val\n        beta_d = beta_B_d1 + beta_B_d2 + beta_S_val\n        \n        # --- Step 3  4: Calculate Spectra on the grid ---\n        # TMD Spectrum\n        comp_u_tmd = (W_u / beta_u) * np.exp(-qT_grid**2 / (4 * beta_u))\n        comp_d_tmd = (W_d / beta_d) * np.exp(-qT_grid**2 / (4 * beta_d))\n        norm_tmd = (W_u / beta_u) + (W_d / beta_d)\n        s_tmd_vals = (comp_u_tmd + comp_d_tmd) / norm_tmd\n\n        # Pseudo-Shower Spectrum\n        comp_u_ps = W_u * np.exp(-qT_grid**2 / (4 * kappa * beta_u))\n        comp_d_ps = W_d * np.exp(-qT_grid**2 / (4 * kappa * beta_d))\n        norm_ps = W_u + W_d\n        s_ps_vals = (comp_u_ps + comp_d_ps) / norm_ps\n        \n        # --- Step 5: Calculate RMSE ---\n        rmse = np.sqrt(np.mean((s_tmd_vals - s_ps_vals)**2))\n        results.append(rmse)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3514286"}]}