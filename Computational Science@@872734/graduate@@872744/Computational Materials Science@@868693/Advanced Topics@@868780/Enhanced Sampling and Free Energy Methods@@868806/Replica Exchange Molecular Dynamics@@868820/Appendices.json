{"hands_on_practices": [{"introduction": "The power of Replica Exchange Molecular Dynamics (REMD) stems from its ability to allow configurations to explore different temperatures, but this process is governed by strict statistical rules. The exchange of temperatures between two replicas must satisfy the principle of detailed balance to ensure the simulation correctly samples the desired extended canonical ensemble. This foundational exercise guides you through the derivation of the Metropolis–Hastings acceptance probability for a temperature swap, starting from first principles [@problem_id:3442046]. Mastering this derivation is the first step toward a deep understanding of how and why REMD is a powerful tool for enhanced sampling.", "problem": "Consider two independent replicas of a molecular system, each governed by the same Hamiltonian and coupled to a thermostat so that the system in each replica is in the canonical ensemble at temperature $T$. In Replica Exchange Molecular Dynamics (REMD) and Parallel Tempering (PT), one constructs a joint ensemble for two replicas at temperatures $T_1$ and $T_2$ with the joint equilibrium density proportional to the product of the Boltzmann factors. A temperature-swap move is proposed that exchanges the temperatures of the two replicas while leaving their microscopic configurations unchanged. Assume the proposal mechanism for the swap is symmetric. Starting from the definition of the canonical distribution and the principle of detailed balance, derive the Metropolis–Hastings acceptance probability for this temperature-swap move as a function of the instantaneous potential energies $E_1$ and $E_2$ associated with the two configurations at the moment of the proposed swap.\n\nThen, evaluate this acceptance probability for the following specific case: $T_1 = 300\\,\\mathrm{K}$, $T_2 = 450\\,\\mathrm{K}$, $E_1 = -25.0\\,\\mathrm{kJ\\,mol^{-1}}$, and $E_2 = -20.0\\,\\mathrm{kJ\\,mol^{-1}}$. Use the molar gas constant $R = 8.314462618\\,\\mathrm{J\\,mol^{-1}\\,K^{-1}}$ and the inverse temperature definition $\\beta_i = 1/(R T_i)$ appropriate for energies expressed per mole. Express the final acceptance probability as a dimensionless number. Round your final numerical answer to four significant figures.", "solution": "The canonical equilibrium distribution for a single replica with configuration $x$ and potential energy $E(x)$ at inverse temperature $\\beta$ is proportional to $\\exp(-\\beta E(x))$. For two independent replicas at inverse temperatures $\\beta_1$ and $\\beta_2$, with configurations $x_1$ and $x_2$ and corresponding energies $E_1 = E(x_1)$ and $E_2 = E(x_2)$, the joint equilibrium density is\n$$\n\\pi_{\\mathrm{old}}(x_1, x_2 \\mid \\beta_1, \\beta_2) \\propto \\exp(-\\beta_1 E_1)\\,\\exp(-\\beta_2 E_2).\n$$\nA proposed temperature-swap move produces the new state $(x_1, x_2 \\mid \\beta_2, \\beta_1)$, i.e., the temperatures are exchanged while the configurations are unchanged. The corresponding joint equilibrium density of the swapped state is\n$$\n\\pi_{\\mathrm{new}}(x_1, x_2 \\mid \\beta_2, \\beta_1) \\propto \\exp(-\\beta_2 E_1)\\,\\exp(-\\beta_1 E_2).\n$$\nBy the Metropolis–Hastings construction with a symmetric proposal, the acceptance probability $a$ is\n$$\na = \\min\\left(1, \\frac{\\pi_{\\mathrm{new}}}{\\pi_{\\mathrm{old}}}\\right) = \\min\\left(1, \\exp\\big[-\\beta_2 E_1 - \\beta_1 E_2 + \\beta_1 E_1 + \\beta_2 E_2\\big]\\right).\n$$\nCollecting terms yields\n$$\na = \\min\\left(1, \\exp\\big[(\\beta_1 - \\beta_2)(E_1 - E_2)\\big]\\right).\n$$\nThis is the acceptance criterion consistent with detailed balance in the joint canonical ensemble.\n\nWe now evaluate this expression for the specified values. The inverse temperatures are defined for molar energies by\n$$\n\\beta_1 = \\frac{1}{R T_1}, \\qquad \\beta_2 = \\frac{1}{R T_2}.\n$$\nThe energy difference is\n$$\n\\Delta E \\equiv E_1 - E_2 = -25.0\\,\\mathrm{kJ\\,mol^{-1}} - \\left(-20.0\\,\\mathrm{kJ\\,mol^{-1}}\\right) = -5.0\\,\\mathrm{kJ\\,mol^{-1}} = -5000\\,\\mathrm{J\\,mol^{-1}}.\n$$\nHence the exponent in the acceptance factor is\n$$\n(\\beta_1 - \\beta_2)\\,\\Delta E = \\left(\\frac{1}{R T_1} - \\frac{1}{R T_2}\\right)(-5000).\n$$\nWith $T_1 = 300\\,\\mathrm{K}$, $T_2 = 450\\,\\mathrm{K}$, and $R = 8.314462618\\,\\mathrm{J\\,mol^{-1}\\,K^{-1}}$,\n$$\n\\beta_1 = \\frac{1}{8.314462618 \\times 300}, \\qquad \\beta_2 = \\frac{1}{8.314462618 \\times 450},\n$$\nso that\n$$\n\\beta_1 - \\beta_2 = \\frac{1}{8.314462618 \\times 300} - \\frac{1}{8.314462618 \\times 450} = \\frac{T_2 - T_1}{R T_1 T_2}.\n$$\nNumerically,\n$$\n\\beta_1 - \\beta_2 = \\frac{150}{8.314462618 \\times 300 \\times 450} \\approx 1.33636 \\times 10^{-4},\n$$\nand therefore\n$$\n(\\beta_1 - \\beta_2)\\,\\Delta E \\approx (1.33636 \\times 10^{-4}) \\times (-5000) \\approx -0.66818.\n$$\nThe acceptance probability is then\n$$\na = \\min\\left(1, \\exp(-0.66818)\\right) \\approx \\exp(-0.66818).\n$$\nUsing $\\exp(-0.66818) = \\exp(-0.69314718 + 0.02496743) = \\exp(-0.69314718)\\,\\exp(0.02496743) = \\frac{1}{2}\\,\\exp(0.02496743)$ and $\\exp(0.02496743) \\approx 1.02528$, we obtain\n$$\na \\approx \\frac{1}{2} \\times 1.02528 \\approx 0.51264.\n$$\nRounded to four significant figures, the acceptance probability is\n$$\n0.5126.\n$$", "answer": "$$\\boxed{0.5126}$$", "id": "3442046"}, {"introduction": "A well-designed REMD simulation requires sufficient overlap between the potential energy distributions of adjacent replicas to ensure a reasonable swap acceptance rate. If the temperatures are too far apart, swaps will rarely be accepted, and the replicas will not efficiently traverse the temperature ladder. This practical coding exercise translates the theoretical acceptance criterion into a quantitative diagnostic tool [@problem_id:3485799]. By numerically estimating the expected swap acceptance from modeled energy histograms, you will learn a crucial skill for setting up and optimizing the temperature schedule for a simulation, ensuring efficient sampling.", "problem": "You are tasked with building a program that, starting from first principles of the canonical ensemble and the Metropolis–Hastings criterion, estimates the expected replica-exchange swap acceptance between two canonical replicas and diagnoses whether the temperature ladder spacing is adequate for a metallic glass. Consider two replicas that independently sample potential energies from empirical histograms at temperatures $T_i$ and $T_j$. The acceptance of a proposed swap should be derived from the requirement of detailed balance for the joint canonical distribution of the two replicas. The expected acceptance is defined as the joint expectation of the Metropolis–Hastings acceptance over the product measure formed by the two energy histograms. Your derivation must start from the canonical ensemble probability measure and the principle of detailed balance, without stating the target acceptance formula.\n\nGiven discretized energy histograms on a uniform energy grid, you must numerically estimate the expected acceptance using discrete summation that correctly accounts for bin widths, and then diagnose temperature ladder adequacy for a metallic glass using a scientifically justified criterion that is explicitly stated in terms of a numerical range. All quantities must be expressed in consistent physical units. Use energy in electronvolts (eV) and temperature in Kelvin (K). The Boltzmann constant $k_{\\mathrm{B}}$ must be used in electronvolt per Kelvin, where $k_{\\mathrm{B}} = 8.617333262 \\times 10^{-5}\\,\\mathrm{eV/K}$. Angles are not involved in this task.\n\nThe test suite below provides parameterized synthetic but scientifically plausible histogram specifications that emulate empirical potential energy histograms of a metallic glass. For each test case, you must construct the histogram $p_i(U)$ and $p_j(U)$ on the specified uniform energy grid, normalize them so that the integral over energy is $1$ using numerical integration consistent with the grid, and then compute the expected swap acceptance. You must output, for each case, a list consisting of the acceptance value and a boolean indicating whether the ladder spacing is adequate for a metallic glass according to the criterion that the acceptance should be within the window $[\\alpha_{\\min}, \\alpha_{\\max}]$, with $\\alpha_{\\min} = 0.2$ and $\\alpha_{\\max} = 0.4$. The temperature ladder is deemed adequate if and only if the acceptance lies within this closed interval.\n\nHistogram construction rules:\n- For a single Gaussian component, define the probability density function on energy $U$ by $f(U; \\mu, \\sigma) = \\dfrac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\!\\left(-\\dfrac{(U - \\mu)^2}{2\\sigma^2}\\right)$.\n- For a mixture of $M$ Gaussian components, define $p(U) = \\sum_{m=1}^{M} w_m f(U; \\mu_m, \\sigma_m)$, where the nonnegative weights $\\{w_m\\}$ sum to $1$.\n- Discretize $U$ on a uniform grid $U_k$ with $k = 0, 1, \\dots, N-1$, where $U_k$ spans the specified range using $N$ points.\n- Normalize the discrete histogram so that $\\sum_{k=0}^{N-1} p(U_k) \\,\\Delta U = 1$, where $\\Delta U$ is the uniform bin width.\n\nExpected acceptance estimation requirement:\n- Compute the expected acceptance as the discrete double sum over the joint product of the two normalized histograms, using the Metropolis–Hastings acceptance implied by detailed balance for swapping two independently sampled energies at inverse temperatures $\\beta_i$ and $\\beta_j$, where $\\beta = 1/(k_{\\mathrm{B}} T)$.\n\nAdequacy criterion:\n- Use $\\alpha_{\\min} = 0.2$ and $\\alpha_{\\max} = 0.4$. If the expected acceptance is within $[\\alpha_{\\min}, \\alpha_{\\max}]$, return the boolean $true$; otherwise return $false$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, where each item is a two-element list of the form $[\\text{acceptance}, \\text{adequate}]$. For example: $[[a_1,b_1],[a_2,b_2],\\dots]$. Each acceptance must be a floating-point number, and each adequacy must be a boolean.\n\nTest suite (construct the histograms and compute the results for these cases):\n- Case $1$ (moderate ladder spacing, unimodal):\n  - Temperatures: $T_i = 600\\,\\mathrm{K}$, $T_j = 660\\,\\mathrm{K}$.\n  - Energy grid: $U \\in [-3100\\,\\mathrm{eV}, -2900\\,\\mathrm{eV}]$ with $N = 801$ points.\n  - Replica $i$: unimodal Gaussian with $\\mu_i = -3000\\,\\mathrm{eV}$, $\\sigma_i = 18\\,\\mathrm{eV}$.\n  - Replica $j$: unimodal Gaussian with $\\mu_j = -2990\\,\\mathrm{eV}$, $\\sigma_j = 22\\,\\mathrm{eV}$.\n- Case $2$ (near-adjacent temperatures, unimodal):\n  - Temperatures: $T_i = 600\\,\\mathrm{K}$, $T_j = 602\\,\\mathrm{K}$.\n  - Energy grid: $U \\in [-3100\\,\\mathrm{eV}, -2900\\,\\mathrm{eV}]$ with $N = 801$ points.\n  - Replica $i$: unimodal Gaussian with $\\mu_i = -3000\\,\\mathrm{eV}$, $\\sigma_i = 18\\,\\mathrm{eV}$.\n  - Replica $j$: unimodal Gaussian with $\\mu_j = -2999.7\\,\\mathrm{eV}$, $\\sigma_j = 18.7\\,\\mathrm{eV}$.\n- Case $3$ (widely spaced temperatures, unimodal):\n  - Temperatures: $T_i = 600\\,\\mathrm{K}$, $T_j = 900\\,\\mathrm{K}$.\n  - Energy grid: $U \\in [-3100\\,\\mathrm{eV}, -2900\\,\\mathrm{eV}]$ with $N = 801$ points.\n  - Replica $i$: unimodal Gaussian with $\\mu_i = -3000\\,\\mathrm{eV}$, $\\sigma_i = 18\\,\\mathrm{eV}$.\n  - Replica $j$: unimodal Gaussian with $\\mu_j = -2950\\,\\mathrm{eV}$, $\\sigma_j = 35\\,\\mathrm{eV}$.\n- Case $4$ (bimodal mixture representing glassy heterogeneity):\n  - Temperatures: $T_i = 700\\,\\mathrm{K}$, $T_j = 770\\,\\mathrm{K}$.\n  - Energy grid: $U \\in [-3040\\,\\mathrm{eV}, -2920\\,\\mathrm{eV}]$ with $N = 601$ points.\n  - Replica $i$: mixture with two components:\n    - Weights: $w_{i,1} = 0.6$, $w_{i,2} = 0.4$.\n    - Means: $\\mu_{i,1} = -2995\\,\\mathrm{eV}$, $\\mu_{i,2} = -2970\\,\\mathrm{eV}$.\n    - Standard deviations: $\\sigma_{i,1} = 18\\,\\mathrm{eV}$, $\\sigma_{i,2} = 12\\,\\mathrm{eV}$.\n  - Replica $j$: mixture with two components:\n    - Weights: $w_{j,1} = 0.5$, $w_{j,2} = 0.5$.\n    - Means: $\\mu_{j,1} = -2988\\,\\mathrm{eV}$, $\\mu_{j,2} = -2960\\,\\mathrm{eV}$.\n    - Standard deviations: $\\sigma_{j,1} = 22\\,\\mathrm{eV}$, $\\sigma_{j,2} = 15\\,\\mathrm{eV}$.\n- Case $5$ (identical temperatures, unimodal; boundary condition):\n  - Temperatures: $T_i = 650\\,\\mathrm{K}$, $T_j = 650\\,\\mathrm{K}$.\n  - Energy grid: $U \\in [-3050\\,\\mathrm{eV}, -2930\\,\\mathrm{eV}]$ with $N = 601$ points.\n  - Replica $i$: unimodal Gaussian with $\\mu_i = -2995\\,\\mathrm{eV}$, $\\sigma_i = 20\\,\\mathrm{eV}$.\n  - Replica $j$: unimodal Gaussian with $\\mu_j = -2995\\,\\mathrm{eV}$, $\\sigma_j = 20\\,\\mathrm{eV}$.\n\nYour program must implement the above, compute the expected acceptance for each case, and output a single line in the exact format $[[a_1,b_1],[a_2,b_2],[a_3,b_3],[a_4,b_4],[a_5,b_5]]$, where each $a_k$ is a floating-point value and each $b_k$ is a boolean.", "solution": "The problem requires the estimation of the expected replica-exchange swap acceptance probability between two canonical replicas, $i$ and $j$, at temperatures $T_i$ and $T_j$, whose potential energies are sampled from given distributions. The derivation must originate from the first principles of statistical mechanics.\n\nLet the state of the two-replica system be defined by the potential energies of their respective configurations, $(U_i, U_j)$. In the extended canonical ensemble used for replica-exchange simulations, the joint probability density for this state is the product of the individual canonical probabilities. Assuming the density of states $\\Omega(U)$ is the same for both systems (as they represent the same physical system), the probability is proportional to the Boltzmann factors:\n$$\nP(U_i, U_j) \\propto \\Omega(U_i) e^{-\\beta_i U_i} \\cdot \\Omega(U_j) e^{-\\beta_j U_j}\n$$\nwhere $\\beta_k = 1/(k_{\\mathrm{B}} T_k)$ is the inverse temperature for replica $k$, and $k_{\\mathrm{B}}$ is the Boltzmann constant.\n\nA swap move between replicas $i$ and $j$ proposes a transition from state $(U_i, U_j)$ to $(U_j, U_i)$, where the configurations are exchanged. The replica at temperature $T_i$ now has energy $U_j$, and the one at $T_j$ has energy $U_i$. The probability of this new state is:\n$$\nP(U_j, U_i) \\propto \\Omega(U_j) e^{-\\beta_i U_j} \\cdot \\Omega(U_i) e^{-\\beta_j U_i}\n$$\n\nThe principle of detailed balance must be satisfied for the swap moves to maintain the equilibrium of the extended ensemble. This principle states:\n$$\nP(U_i, U_j) W((U_i, U_j) \\to (U_j, U_i)) = P(U_j, U_i) W((U_j, U_i) \\to (U_i, U_j))\n$$\nwhere $W(A \\to B)$ is the total transition probability from state $A$ to state $B$. This is a product of the proposal probability $g(A \\to B)$ and the acceptance probability $\\alpha(A \\to B)$. Since the proposal to swap is symmetric, $g((U_i, U_j) \\to (U_j, U_i)) = g((U_j, U_i) \\to (U_i, U_j))$, the detailed balance condition simplifies to a ratio of the acceptance probabilities:\n$$\n\\frac{\\alpha(U_i \\leftrightarrow U_j)}{\\alpha(U_j \\leftrightarrow U_i)} = \\frac{P(U_j, U_i)}{P(U_i, U_j)} = \\frac{\\Omega(U_j) e^{-\\beta_i U_j} \\Omega(U_i) e^{-\\beta_j U_i}}{\\Omega(U_i) e^{-\\beta_i U_i} \\Omega(U_j) e^{-\\beta_j U_j}} = \\frac{e^{-\\beta_i U_j - \\beta_j U_i}}{e^{-\\beta_i U_i - \\beta_j U_j}}\n$$\nNotice that the density of states terms $\\Omega(U)$ cancel. Simplifying the exponential term yields:\n$$\n\\frac{\\alpha(U_i \\leftrightarrow U_j)}{\\alpha(U_j \\leftrightarrow U_i)} = e^{-(\\beta_i U_j + \\beta_j U_i) + (\\beta_i U_i + \\beta_j U_j)} = e^{(\\beta_i - \\beta_j)U_i - (\\beta_i - \\beta_j)U_j} = e^{-(\\beta_j - \\beta_i)(U_j - U_i)}\n$$\nThe Metropolis-Hastings criterion provides a common and valid choice for the acceptance probability that satisfies this relation:\n$$\n\\alpha(U_i \\leftrightarrow U_j) = \\min\\left(1, \\frac{P(U_j, U_i)}{P(U_i, U_j)}\\right) = \\min\\left(1, e^{-(\\beta_j - \\beta_i)(U_j - U_i)}\\right)\n$$\nThis is the acceptance probability for a single proposed swap involving energies $U_i$ and $U_j$.\n\nThe problem states that replicas $i$ and $j$ independently sample potential energies from empirical histograms, which we represent as continuous probability density functions $p_i(U)$ and $p_j(U)$. The expected acceptance probability, $\\langle \\alpha \\rangle$, is the average of $\\alpha(U_i \\leftrightarrow U_j)$ over all possible pairs of energies $(U_i, U_j)$, weighted by the joint probability density $p_i(U_i)p_j(U_j)$:\n$$\n\\langle \\alpha \\rangle = \\int_{-\\infty}^{\\infty} dU_i \\int_{-\\infty}^{\\infty} dU_j \\, p_i(U_i) p_j(U_j) \\, \\alpha(U_i \\leftrightarrow U_j)\n$$\nSubstituting the derived expression for $\\alpha(U_i \\leftrightarrow U_j)$:\n$$\n\\langle \\alpha \\rangle = \\int_{-\\infty}^{\\infty} dU_i \\int_{-\\infty}^{\\infty} dU_j \\, p_i(U_i) p_j(U_j) \\, \\min\\left(1, e^{-(\\beta_j - \\beta_i)(U_j - U_i)}\\right)\n$$\n\nFor numerical computation, this double integral is discretized over a uniform energy grid. Let the grid consist of $N$ points $\\{U_k\\}_{k=0}^{N-1}$ with a uniform spacing of $\\Delta U$. The integral is approximated by a double Riemann sum. The probability of finding replica $i$ in the energy bin centered at $U_k$ is $P_i(k) = p_i(U_k) \\Delta U$. The sum is:\n$$\n\\langle \\alpha \\rangle \\approx \\sum_{k=0}^{N-1} \\sum_{l=0}^{N-1} (p_i(U_k) \\Delta U) (p_j(U_l) \\Delta U) \\min\\left(1, e^{-(\\beta_j - \\beta_i)(U_l - U_k)}\\right)\n$$\nThe problem specifies that the histograms are constructed from (mixtures of) Gaussian distributions. Let $h_i(U_k)$ be the value of the unnormalized Gaussian mixture function evaluated at grid point $U_k$. The normalization condition is $\\sum_{k=0}^{N-1} p_i(U_k) \\Delta U = 1$. This means the normalized density $p_i(U_k)$ is related to the unnormalized values $h_i(U_k)$ by $p_i(U_k) = h_i(U_k) / C_i$, where the normalization constant is $C_i = \\sum_{k=0}^{N-1} h_i(U_k) \\Delta U$. Substituting this into the expression for $\\langle \\alpha \\rangle$ and simplifying demonstrates that the bin width $\\Delta U$ cancels:\n$$\n\\langle \\alpha \\rangle \\approx \\frac{\\sum_{k=0}^{N-1} \\sum_{l=0}^{N-1} h_i(U_k) h_j(U_l) \\min\\left(1, e^{-(\\beta_j - \\beta_i)(U_l - U_k)}\\right)}{\\left(\\sum_{k=0}^{N-1} h_i(U_k)\\right) \\left(\\sum_{l=0}^{N-1} h_j(U_l)\\right)}\n$$\nThis expression is robust and is used for the implementation. The algorithm proceeds by:\n$1$. Constructing the uniform energy grid $\\{U_k\\}$.\n$2$. Evaluating the unnormalized histogram functions $h_i(U_k)$ and $h_j(U_k)$ on this grid based on the provided Gaussian parameters.\n$3$. Computing the double summation in the numerator and the product of sums in the denominator. Vectorized array operations are used for efficiency.\n$4$. Dividing the two results to obtain the estimated expected acceptance $\\langle \\alpha \\rangle$.\n\nFinally, the temperature ladder spacing is diagnosed. The criterion for an adequate ladder spacing for a metallic glass simulation is given as an acceptance rate within the closed interval $[\\alpha_{\\min}, \\alpha_{\\max}]$, where $\\alpha_{\\min} = 0.2$ and $\\alpha_{\\max} = 0.4$. The computed $\\langle \\alpha \\rangle$ is checked against this range, and a boolean value is returned accordingly.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the replica exchange problem for all test cases.\n    \"\"\"\n    \n    # Constants\n    KB_EV_K = 8.617333262e-5  # Boltzmann constant in eV/K\n    ALPHA_MIN = 0.2\n    ALPHA_MAX = 0.4\n\n    test_cases = [\n        # Case 1\n        {\n            \"temps\": (600, 660), \"N\": 801, \"U_range\": (-3100, -2900),\n            \"h_i\": [{\"w\": 1.0, \"mu\": -3000, \"sigma\": 18}],\n            \"h_j\": [{\"w\": 1.0, \"mu\": -2990, \"sigma\": 22}],\n        },\n        # Case 2\n        {\n            \"temps\": (600, 602), \"N\": 801, \"U_range\": (-3100, -2900),\n            \"h_i\": [{\"w\": 1.0, \"mu\": -3000, \"sigma\": 18}],\n            \"h_j\": [{\"w\": 1.0, \"mu\": -2999.7, \"sigma\": 18.7}],\n        },\n        # Case 3\n        {\n            \"temps\": (600, 900), \"N\": 801, \"U_range\": (-3100, -2900),\n            \"h_i\": [{\"w\": 1.0, \"mu\": -3000, \"sigma\": 18}],\n            \"h_j\": [{\"w\": 1.0, \"mu\": -2950, \"sigma\": 35}],\n        },\n        # Case 4\n        {\n            \"temps\": (700, 770), \"N\": 601, \"U_range\": (-3040, -2920),\n            \"h_i\": [\n                {\"w\": 0.6, \"mu\": -2995, \"sigma\": 18},\n                {\"w\": 0.4, \"mu\": -2970, \"sigma\": 12},\n            ],\n            \"h_j\": [\n                {\"w\": 0.5, \"mu\": -2988, \"sigma\": 22},\n                {\"w\": 0.5, \"mu\": -2960, \"sigma\": 15},\n            ],\n        },\n        # Case 5\n        {\n            \"temps\": (650, 650), \"N\": 601, \"U_range\": (-3050, -2930),\n            \"h_i\": [{\"w\": 1.0, \"mu\": -2995, \"sigma\": 20}],\n            \"h_j\": [{\"w\": 1.0, \"mu\": -2995, \"sigma\": 20}],\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        acceptance, is_adequate = compute_case(case, KB_EV_K, ALPHA_MIN, ALPHA_MAX)\n        results.append(f\"[{acceptance},{str(is_adequate).lower()}]\")\n        \n    print(f\"[{','.join(results)}]\")\n\n\ndef gaussian_pdf(x, mu, sigma):\n    \"\"\"\n    Computes the value of a Gaussian probability density function.\n    No scipy dependency used as per strict interpretation.\n    \"\"\"\n    return (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma) ** 2)\n\ndef build_histogram(U, components):\n    \"\"\"\n    Builds an unnormalized histogram from a Gaussian mixture model.\n    \"\"\"\n    h = np.zeros_like(U)\n    for comp in components:\n        h += comp[\"w\"] * gaussian_pdf(U, comp[\"mu\"], comp[\"sigma\"])\n    return h\n\ndef compute_case(case, kb, alpha_min, alpha_max):\n    \"\"\"\n    Computes the expected acceptance and adequacy for a single test case.\n    \"\"\"\n    T_i, T_j = case[\"temps\"]\n    N = case[\"N\"]\n    U_min, U_max = case[\"U_range\"]\n    \n    # 1. Construct the energy grid\n    U = np.linspace(U_min, U_max, N)\n    \n    # 2. Build unnormalized histograms\n    h_i = build_histogram(U, case[\"h_i\"])\n    h_j = build_histogram(U, case[\"h_j\"])\n    \n    # 3. Calculate inverse temperatures\n    # Use a small epsilon to avoid division by zero if T=0, though not expected here.\n    beta_i = 1.0 / (kb * (T_i + 1e-12))\n    beta_j = 1.0 / (kb * (T_j + 1e-12))\n    delta_beta = beta_j - beta_i\n\n    # Handle the trivial case of identical temperatures\n    if np.isclose(delta_beta, 0.0):\n        acceptance = 1.0\n        is_adequate = alpha_min = acceptance = alpha_max\n        return acceptance, is_adequate\n\n    # 4. Compute the double summation using vectorized operations\n    \n    # Denominator computation\n    sum_h_i = np.sum(h_i)\n    sum_h_j = np.sum(h_j)\n    denominator = sum_h_i * sum_h_j\n\n    if denominator == 0:\n        return 0.0, False\n\n    # Numerator computation\n    # Create matrices for broadcasting\n    U_k = U[:, np.newaxis]  # Column vector for U_i\n    U_l = U[np.newaxis, :]  # Row vector for U_j\n\n    h_i_col = h_i[:, np.newaxis]\n    h_j_row = h_j[np.newaxis, :]\n    \n    # Calculate matrix of energy differences\n    delta_U_matrix = U_l - U_k\n    \n    # Calculate acceptance probability for each pair (U_k, U_l)\n    exponent_matrix = -delta_beta * delta_U_matrix\n    alpha_matrix = np.minimum(1.0, np.exp(exponent_matrix))\n    \n    # Calculate the joint unnormalized probability matrix\n    joint_h_matrix = h_i_col * h_j_row\n    \n    # Compute the numerator sum\n    numerator = np.sum(joint_h_matrix * alpha_matrix)\n    \n    # 5. Calculate final expected acceptance\n    acceptance = numerator / denominator\n    \n    # 6. Diagnose adequacy\n    is_adequate = alpha_min = acceptance = alpha_max\n    \n    return acceptance, is_adequate\n\nsolve()\n\n```", "id": "3485799"}, {"introduction": "While a static, pre-determined temperature ladder is a common starting point, its efficiency can be suboptimal, especially for systems exhibiting complex phase behavior or temperature-dependent heat capacity. Modern REMD methods overcome this by using adaptive algorithms that adjust the temperature ladder on-the-fly. This advanced practice challenges you to design and test an adaptive controller that dynamically updates temperature spacings to maintain a constant, optimal overlap between replicas [@problem_id:3485795]. Engaging with this problem will provide you with hands-on experience in cutting-edge algorithmic design, moving beyond the static application of REMD to its intelligent and efficient implementation.", "problem": "You are asked to design and test an adaptive controller for the temperature ladder in Replica Exchange Molecular Dynamics (REMD) that updates the inverse temperatures $\\,\\beta_k\\,$ online to achieve a target pairwise overlap metric between adjacent replicas. The overlap metric must be the Bhattacharyya coefficient computed from running estimates of the potential energy variance as a function of temperature. Work in reduced units with Boltzmann constant $\\,k_{\\mathrm{B}} = 1\\,$ so that all quantities are dimensionless.\n\nFundamental base and modeling assumptions to be used:\n- Canonical ensemble: for a replica at temperature $\\,T\\,$, the potential energy $\\,U\\,$ is a random variable with mean $\\,\\mu_U(T)\\,$ and variance $\\,\\sigma_U^2(T)\\,$ determined by the equilibrium distribution $\\,\\propto \\exp(-U/T)\\,$.\n- Large-degrees-of-freedom approximation: for a material with constant heat capacity $\\,C_V\\,$, the potential energy distribution is well-approximated by a Gaussian with mean $\\,\\mu_U(T) \\approx C_V T\\,$ and variance $\\,\\sigma_U^2(T) \\approx C_V T^2\\,$. You must use this as the generative model for synthetic streaming data $\\,U\\,$ but the controller must rely only on running estimates of $\\,\\sigma_U(T)\\,$ when computing the overlap metric.\n- Bhattacharyya coefficient between two Gaussian energy distributions with means $\\,\\mu_1, \\mu_2\\,$ and standard deviations $\\,\\sigma_1, \\sigma_2\\,$ is defined as the integral $\\,\\mathrm{BC} = \\int_{-\\infty}^{\\infty} \\sqrt{p_1(u)\\,p_2(u)}\\,\\mathrm{d}u\\,$, where $\\,p_i\\,$ are the Gaussian probability density functions. You must derive and implement the expression of $\\,\\mathrm{BC}\\,$ in terms of $\\,\\mu_1, \\mu_2, \\sigma_1, \\sigma_2\\,$ from first principles in your solution, and then specialize it using running estimates of $\\,\\sigma_U(T)\\,$ and the relation between $\\,\\sigma_U(T)\\,$ and $\\,T\\,$ implied by the model.\n- The REMD ladder is parameterized by inverse temperatures $\\,\\beta_k = 1/T_k\\,$ with $\\,k \\in \\{0,1,\\dots,K-1\\}\\,$, and must remain ordered as $\\,\\beta_0  \\beta_1  \\dots  \\beta_{K-1}\\,$. The endpoints $\\,\\beta_0\\,$ and $\\,\\beta_{K-1}\\,$ are fixed.\n\nController design requirements:\n- Define nearest-neighbor spacings $\\,d_k = \\beta_k - \\beta_{k+1}\\,$ for $\\,k \\in \\{0,\\dots,K-2\\}\\,$. Design a multiplicative adaptive control law that updates $\\,d_k\\,$ online using streaming estimates of $\\,\\sigma_U(T)\\,$ to drive the pairwise Bhattacharyya coefficients $\\,\\mathrm{BC}_k\\,$ between adjacent replicas toward a target setpoint $\\,B^\\star\\,$. The multiplicative update must preserve positivity of the spacings. After each update, renormalize $\\,\\{d_k\\}\\,$ so that $\\,\\sum_{k=0}^{K-2} d_k = \\beta_0 - \\beta_{K-1}\\,$, ensuring fixed endpoints and monotonic ordering for the ladder.\n- Use a running estimator for $\\,\\sigma_U^2(T)\\,$ based on the streaming synthetic data $\\,U\\,$ at each replica. You must maintain and update online estimates $\\,\\widehat{\\sigma}_U^2(T_k)\\,$ and use them to derive an online estimate $\\,\\widehat{C}_V\\,$ via $\\,\\widehat{C}_V \\approx \\mathrm{mean}_k\\left(\\widehat{\\sigma}_U^2(T_k) / T_k^2\\right)\\,$ at each control step. The overlap metric calculation must use this estimated relationship to link $\\,\\sigma_U(T)\\,$ to $\\,T\\,$.\n- Stability analysis: linearize the closed-loop error dynamics around the equilibrium $\\,\\mathrm{BC}_k = B^\\star\\,$ and state a sufficient condition on the controller gain for local stability, expressed in terms of the sensitivity of the Bhattacharyya coefficient with respect to the spacings $\\,d_k\\,$. Your program must empirically test stability by verifying convergence characteristics of a Lyapunov-like function $\\,V = \\frac{1}{2}\\sum_{k} e_k^2\\,$ with $\\,e_k = B^\\star - \\mathrm{BC}_k\\,$.\n\nSynthetic data and estimator protocol:\n- At each control step, for each replica temperature $\\,T_k\\,$, draw $\\,m\\,$ independent synthetic samples $\\,U\\,$ from the Gaussian model with the true but unknown $\\,C_V^{\\mathrm{true}}\\,$, that is $\\,U \\sim \\mathcal{N}(C_V^{\\mathrm{true}} T_k,\\; C_V^{\\mathrm{true}} T_k^2)\\,$. Use these samples to update running estimates of $\\,\\sigma_U^2(T_k)\\,$ via an exponential moving average with smoothing factor $\\,\\rho\\,$.\n- From the current $\\,\\{\\widehat{\\sigma}_U^2(T_k)\\}\\,$ and $\\,\\{T_k\\}\\,$, compute $\\,\\widehat{C}_V\\,$ and then evaluate the current $\\,\\mathrm{BC}_k\\,$ between adjacent replicas using the Bhattacharyya formula specialized to Gaussian energies parameterized by $\\,T_k\\,$ and $\\,\\widehat{C}_V\\,$.\n\nQuantities, units, and numerical values:\n- All quantities are dimensionless because you must use reduced units $\\,k_{\\mathrm{B}} = 1\\,$.\n- Use $\\,K = 6\\,$ replicas, fixed endpoints $\\,T_{\\min} = 0.5\\,$, $\\,T_{\\max} = 2.0\\,$ (equivalently $\\,\\beta_0 = 1/T_{\\min}\\,$ and $\\,\\beta_{K-1} = 1/T_{\\max}\\,$), and the true heat capacity $\\,C_V^{\\mathrm{true}} = 100\\,$.\n- Use $\\,m = 64\\,$ samples per replica and control step, exponential smoothing factor $\\,\\rho = 0.05\\,$ for the variance estimator, and target overlap $\\,B^\\star = 0.80\\,$.\n\nStability test definition and pass criteria:\n- Let $\\,N_{\\mathrm{steps}}\\,$ be the number of control steps. Define the Lyapunov-like sequence $\\,V_t = \\frac{1}{2}\\sum_{k=0}^{K-2} \\left(B^\\star - \\mathrm{BC}_k(t)\\right)^2\\,$.\n- A run is declared stable if, by the final time, the following hold simultaneously:\n  1. Final root-mean-square tracking error $\\,\\sqrt{\\frac{1}{K-1}\\sum_{k} e_k^2}\\,$ is below $\\,\\varepsilon = 0.05\\,$.\n  2. The ladder remains ordered and within the fixed endpoints at all times.\n  3. Over the last $\\,\\lfloor N_{\\mathrm{steps}}/2 \\rfloor\\,$ steps, the fraction of steps for which $\\,V_{t+1} \\le V_t\\,$ is at least $\\,0.7\\,$.\n  4. Over the last $\\,\\lfloor N_{\\mathrm{steps}}/4 \\rfloor\\,$ steps, the coefficient of variation of the spacing vector $\\,\\{d_k\\}\\,$ is at most $\\,0.2\\,$.\n\nProgramming tasks:\n- Implement the streaming estimator, the overlap computation using the running $\\,\\widehat{C}_V\\,$, the multiplicative spacing update with renormalization, and the stability checks as defined above.\n- For numerical differentiation or sensitivity, you must not use any external automatic differentiation; the control law must be the multiplicative spacing update that does not require explicit gradients.\n- Use $\\,N_{\\mathrm{steps}} = 1000\\,$.\n\nTest suite:\nYour program must evaluate the following three test cases, each defined by a controller gain $\\,\\alpha\\,$ and a random seed for the synthetic data generator:\n1. Case A (happy path): $\\,\\alpha = 0.02\\,$, seed $\\,= 7\\,$.\n2. Case B (moderate gain): $\\,\\alpha = 0.06\\,$, seed $\\,= 11\\,$.\n3. Case C (aggressive gain): $\\,\\alpha = 0.20\\,$, seed $\\,= 13\\,$.\n\nFor each case, output a boolean indicating whether the run is stable under the above criteria.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[true_caseA,true_caseB,true_caseC]\" but using Python-style booleans), in the order of the test suite cases.", "solution": "The problem requires the design, implementation, and testing of an adaptive controller for the temperature ladder in Replica Exchange Molecular Dynamics (REMD). The controller must dynamically adjust the inverse temperatures, $\\beta_k = 1/T_k$, to maintain a target pairwise overlap, quantified by the Bhattacharyya coefficient, between adjacent replicas. The solution will proceed by first deriving the necessary theoretical expressions, then formulating the control strategy, and finally detailing the implementation and verification protocol. All quantities are dimensionless as per the problem statement, with Boltzmann constant $k_{\\mathrm{B}} = 1$.\n\n### 1. Theoretical Foundation: Bhattacharyya Coefficient for Gaussian Distributions\n\nThe overlap between the potential energy distributions of two adjacent replicas is the core metric. The problem models these distributions as Gaussian. The Bhattacharyya coefficient, $\\mathrm{BC}$, between two Gaussian probability density functions, $p_1(u) = \\mathcal{N}(u; \\mu_1, \\sigma_1^2)$ and $p_2(u) = \\mathcal{N}(u; \\mu_2, \\sigma_2^2)$, is defined as:\n$$\n\\mathrm{BC} = \\int_{-\\infty}^{\\infty} \\sqrt{p_1(u) p_2(u)} \\, \\mathrm{d}u\n$$\nThe product of the two PDFs is:\n$$\np_1(u) p_2(u) = \\frac{1}{2\\pi \\sigma_1 \\sigma_2} \\exp\\left( -\\frac{1}{2} \\left[ \\frac{(u-\\mu_1)^2}{\\sigma_1^2} + \\frac{(u-\\mu_2)^2}{\\sigma_2^2} \\right] \\right)\n$$\nThe term in the exponent is a quadratic in $u$. By completing the square, it can be shown that the integral evaluates to a closed-form expression. The argument of the exponential can be rearranged into the form of a new Gaussian-like term plus a constant independent of $u$:\n$$\n-\\frac{1}{2} \\left[ \\frac{(u-\\mu_1)^2}{\\sigma_1^2} + \\frac{(u-\\mu_2)^2}{\\sigma_2^2} \\right] = -\\frac{(u-\\mu_{new})^2}{2\\sigma_{new}^2} - \\frac{(\\mu_1-\\mu_2)^2}{2(\\sigma_1^2+\\sigma_2^2)}\n$$\nwhere $\\mu_{new}$ and $\\sigma_{new}^2$ are the mean and variance of a new Gaussian resulting from the product. The integral of the term $\\exp\\left( - (u-\\mu_{new})^2 / (2\\sigma_{new}^2) \\right)$ is proportional to $\\sigma_{new}$, while the constant term can be factored out. This derivation yields the final expression for the Bhattacharyya coefficient:\n$$\n\\mathrm{BC} = \\sqrt{\\frac{2\\sigma_1\\sigma_2}{\\sigma_1^2+\\sigma_2^2}} \\exp\\left( -\\frac{(\\mu_1-\\mu_2)^2}{4(\\sigma_1^2+\\sigma_2^2)} \\right)\n$$\n\n### 2. System Modeling: Overlap in Replica Exchange Molecular Dynamics\n\nThe problem provides a model for the potential energy $U$ of a replica at temperature $T$ based on a large-system approximation with constant heat capacity $C_V$:\n- Mean potential energy: $\\mu_U(T) \\approx C_V T$\n- Variance of potential energy: $\\sigma_U^2(T) \\approx C_V T^2$\n\nFor two adjacent replicas $k$ and $k+1$ at temperatures $T_k$ and $T_{k+1}$, we substitute this model into the general $\\mathrm{BC}$ formula:\n- $\\mu_1 = C_V T_k$, $\\sigma_1^2 = C_V T_k^2$\n- $\\mu_2 = C_V T_{k+1}$, $\\sigma_2^2 = C_V T_{k+1}^2$\n\nThis gives the terms:\n- $\\mu_1 - \\mu_2 = C_V (T_k - T_{k+1})$\n- $\\sigma_1^2 + \\sigma_2^2 = C_V (T_k^2 + T_{k+1}^2)$\n- $\\sigma_1 \\sigma_2 = C_V T_k T_{k+1}$\n\nSubstituting these into the $\\mathrm{BC}$ formula yields the specialized expression for the overlap between replicas $k$ and $k+1$, denoted $\\mathrm{BC}_k$:\n$$\n\\mathrm{BC}_k = \\sqrt{\\frac{2 T_k T_{k+1}}{T_k^2+T_{k+1}^2}} \\exp\\left( -\\frac{C_V(T_k-T_{k+1})^2}{4(T_k^2+T_{k+1}^2)} \\right)\n$$\nThe controller will not know the true $C_V^{\\mathrm{true}}$, but will use a running estimate $\\widehat{C}_V$ derived from streaming data.\n\n### 3. Controller Design and Analysis\n\nThe goal is to design a controller that updates the inverse temperature spacings, $d_k = \\beta_k - \\beta_{k+1}$, to drive the estimated overlap $\\widehat{\\mathrm{BC}}_k$ to a target setpoint $B^\\star$. The controller must be multiplicative to preserve positivity of the spacings.\n\nFrom the expression for $\\mathrm{BC}_k$, we observe that for a fixed level of overlap, a larger heat capacity $C_V$ requires smaller temperature differences $(T_k-T_{k+1})$, which translates to smaller inverse temperature spacings $d_k$. An increase in $d_k$ leads to a larger separation between temperatures, thus decreasing the overlap $\\mathrm{BC}_k$.\n\nA suitable proportional multiplicative control law is:\n$$\nd_k(t+1) = d_k(t) \\left( \\frac{\\widehat{\\mathrm{BC}}_k(t)}{B^\\star} \\right)^\\alpha\n$$\nwhere $\\alpha  0$ is the controller gain. If the current overlap $\\widehat{\\mathrm{BC}}_k(t)$ is less than the target $B^\\star$, the ratio is less than $1$, causing $d_k$ to decrease. This reduces the temperature gap, increasing the overlap towards the target. Conversely, if the overlap is too high, $d_k$ increases.\n\nAfter this update, the new set of spacings $\\{d'_k\\}$ will not necessarily sum to the total inverse temperature range $\\beta_0 - \\beta_{K-1}$. A renormalization step is required to enforce the fixed endpoints:\n$$\nd_k(t+1)_{renorm} = d'_k(t+1) \\frac{\\beta_0 - \\beta_{K-1}}{\\sum_{j=0}^{K-2} d'_j(t+1)}\n$$\n\nFor local stability analysis, we linearize the un-normalized control law around the equilibrium point where $\\mathrm{BC}_k = B^\\star$ and $d_k = d_k^\\star$. The error dynamics for $e_k = B^\\star - \\mathrm{BC}_k$ can be approximated as $e_{k,t+1} \\approx (\\alpha \\frac{d_k^\\star S_k}{B^\\star}) e_{k,t}$, where $S_k = \\frac{\\partial \\mathrm{BC}_k}{\\partial d_k}$ is the sensitivity, which is negative. For stability, the magnitude of the multiplier must be less than $1$, which gives the condition:\n$$\n\\alpha  \\frac{B^\\star}{d_k^\\star \\left| \\frac{\\partial \\mathrm{BC}_k}{\\partial d_k} \\right|_{d_k^\\star}}\n$$\nThis provides a sufficient condition on the gain $\\alpha$ for local stability, ignoring the coupling effect of renormalization.\n\n### 4. Implementation and Verification Protocol\n\nThe simulation proceeds in discrete time steps.\n1.  **Initialization**: The temperature ladder is initialized with linearly spaced inverse temperatures $\\{\\beta_k\\}$ between the fixed endpoints $\\beta_0=1/T_{\\min}$ and $\\beta_{K-1}=1/T_{\\max}$. The running variance estimates $\\widehat{\\sigma}_U^2(T_k)$ are initialized.\n2.  **Streaming Data Generation**: At each step $t$, for each replica $k$, $m$ synthetic potential energy samples are drawn from the true generative model $U \\sim \\mathcal{N}(C_V^{\\mathrm{true}} T_k, C_V^{\\mathrm{true}} T_k^2)$.\n3.  **State Estimation**: The sample variance of the $m$ data points is computed for each replica. This sample variance is used to update the running estimate $\\widehat{\\sigma}_U^2(T_k)$ via an exponential moving average (EMA) with smoothing factor $\\rho$.\n4.  **Parameter Estimation**: A running estimate of the heat capacity, $\\widehat{C}_V$, is computed by averaging the quantity $\\widehat{\\sigma}_U^2(T_k) / T_k^2$ over all $K$ replicas.\n5.  **Control and Update**: The current overlaps $\\widehat{\\mathrm{BC}}_k$ are calculated using the current temperatures $\\{T_k\\}$ and the estimated $\\widehat{C}_V$. The spacings $\\{d_k\\}$ are updated using the multiplicative control law and then renormalized. The ladder $\\{\\beta_k\\}$ is reconstructed from the new spacings.\n6.  **Verification**: The stability of each run is assessed based on four criteria evaluated at the end of $N_{\\mathrm{steps}}$ iterations:\n    i.  The final root-mean-square tracking error must be below a threshold $\\varepsilon$.\n    ii. The ladder must remain correctly ordered ($\\beta_k  \\beta_{k+1}$) throughout the simulation.\n    iii. The Lyapunov-like function $V_t = \\frac{1}{2}\\sum_k (B^\\star - \\widehat{\\mathrm{BC}}_k(t))^2$ must demonstrate convergence by decreasing in a high fraction of the steps in the latter half of the simulation.\n    iv. The relative dispersion of the spacings $\\{d_k\\}$, measured by their coefficient of variation, must remain small in the final quarter of the simulation, indicating that the controller has settled.\n\nThe provided Python code implements this entire protocol to test the stability of the controller for different gain values.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_simulation(alpha: float, seed: int) - bool:\n    \"\"\"\n    Runs a single simulation of the adaptive REMD temperature ladder controller.\n\n    Args:\n        alpha: The controller gain.\n        seed: The seed for the random number generator.\n\n    Returns:\n        A boolean indicating whether the run is stable according to the defined criteria.\n    \"\"\"\n    # Problem parameters\n    K = 6\n    T_min = 0.5\n    T_max = 2.0\n    C_V_true = 100.0\n    B_star = 0.80\n    m = 64\n    rho = 0.05\n    N_steps = 1000\n\n    # Stability criteria thresholds from the problem description\n    eps_err = 0.05\n    lyapunov_frac_threshold = 0.7\n    cv_spacing_threshold = 0.2\n\n    # Initialize a random number generator for reproducibility\n    rng = np.random.default_rng(seed)\n\n    # 1. Initialization\n    beta_0 = 1.0 / T_min\n    beta_K_minus_1 = 1.0 / T_max\n    \n    num_spacings = K - 1\n    # Initialize spacings to be uniform\n    d_k = np.full(num_spacings, (beta_0 - beta_K_minus_1) / num_spacings)\n\n    # Initialize inverse temperatures from spacings\n    betas = np.zeros(K)\n    betas[0] = beta_0\n    for k in range(1, K):\n        betas[k] = betas[k-1] - d_k[k-1]\n\n    # Initialize running estimates for potential energy variance\n    sigma_sq_U_hat = np.zeros(K)\n\n    # Data logging for stability checks\n    V_history = []\n    d_k_history = []\n    ladder_ordered = True\n    \n    # -------- Main Simulation Loop --------\n    for t in range(N_steps):\n        # Current temperatures of the replicas\n        temps = 1.0 / betas\n\n        # 2. Data Generation  State Estimation\n        sample_variances = np.zeros(K)\n        for k in range(K):\n            # Draw m samples from the true generative model\n            mu_U_true = C_V_true * temps[k]\n            # Variance is C_V * T^2, so stdev is sqrt(C_V) * T\n            sigma_U_true = np.sqrt(C_V_true) * temps[k]\n            \n            samples = rng.normal(loc=mu_U_true, scale=sigma_U_true, size=m)\n            # Calculate sample variance (unbiased estimator)\n            sample_variances[k] = np.var(samples, ddof=1)\n        \n        # Update running variance estimates via EMA.\n        # Bootstrap with the first measurement to avoid initial bias from zero.\n        if t == 0:\n             sigma_sq_U_hat = sample_variances\n        else:\n             sigma_sq_U_hat = (1 - rho) * sigma_sq_U_hat + rho * sample_variances\n\n        # 3. Model Parameter Estimation\n        # Avoid division by zero if temps are unstable, though unlikely\n        valid_indices = (temps  1e-9)  (sigma_sq_U_hat  0)\n        if np.any(valid_indices):\n            C_V_hat = np.mean(sigma_sq_U_hat[valid_indices] / (temps[valid_indices]**2))\n        else:\n            C_V_hat = C_V_true # Fallback, should not happen\n\n        # 4. Control Action\n        d_k_unnormalized = np.zeros(num_spacings)\n        current_bcs = np.zeros(num_spacings)\n\n        for k in range(num_spacings):\n            T_k, T_k_plus_1 = temps[k], temps[k+1]\n            \n            # Calculate current estimated Bhattacharyya Coefficient\n            prefactor_term_sq = (2 * T_k * T_k_plus_1) / (T_k**2 + T_k_plus_1**2)\n            exponent_term = (C_V_hat * (T_k - T_k_plus_1)**2) / (4 * (T_k**2 + T_k_plus_1**2))\n            \n            bc_hat_k = np.sqrt(prefactor_term_sq) * np.exp(-exponent_term)\n            current_bcs[k] = bc_hat_k\n\n            # Multiplicative update rule for the spacing\n            d_k_unnormalized[k] = d_k[k] * (bc_hat_k / B_star)**alpha\n\n        # Renormalization step to enforce fixed endpoints\n        S_target = beta_0 - beta_K_minus_1\n        S_current = np.sum(d_k_unnormalized)\n        d_k = d_k_unnormalized * (S_target / S_current)\n        \n        # Update beta ladder from the new spacings\n        betas[0] = beta_0\n        for k in range(1, K):\n            betas[k] = betas[k-1] - d_k[k-1]\n\n        # 5. Logging and Checks for Stability Analysis\n        # Check for ordering violation\n        if not np.all(np.diff(betas)  0):\n            ladder_ordered = False\n        \n        # Log Lyapunov-like function V_t and spacings d_k\n        error_k = B_star - current_bcs\n        V_t = 0.5 * np.sum(error_k**2)\n        V_history.append(V_t)\n        d_k_history.append(d_k.copy())\n\n    # -------- Post-Loop Stability Analysis --------\n    # Condition 1: Final root-mean-square tracking error\n    final_rms_error = np.sqrt(np.mean((B_star - current_bcs)**2))\n    cond1 = final_rms_error  eps_err\n    \n    # Condition 2: Ladder ordering maintained throughout\n    cond2 = ladder_ordered\n    \n    # Condition 3: Lyapunov-like function convergence\n    # Fraction of steps with V_{t+1} = V_t over the last N/2 steps\n    n_half = N_steps // 2\n    if n_half  0:\n        V_last_half = np.array(V_history[-n_half-1:])\n        v_decreases = np.sum(V_last_half[1:] = V_last_half[:-1])\n        frac_decreases = v_decreases / n_half\n        cond3 = frac_decreases = lyapunov_frac_threshold\n    else:\n        cond3 = False\n\n    # Condition 4: Spacing stability\n    # Mean coefficient of variation of the spacing vector over the last N/4 steps\n    n_quarter = N_steps // 4\n    if n_quarter  0:\n        d_k_last_quarter = np.array(d_k_history[-n_quarter:])\n        # axis=1 operates on each row (each time step's d_k vector)\n        cvs = np.std(d_k_last_quarter, axis=1) / np.mean(d_k_last_quarter, axis=1)\n        mean_cv = np.mean(cvs)\n        cond4 = mean_cv = cv_spacing_threshold\n    else:\n        cond4 = False\n    \n    is_stable = cond1 and cond2 and cond3 and cond4\n    return is_stable\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0.02, 7),   # Case A (happy path)\n        (0.06, 11),  # Case B (moderate gain)\n        (0.20, 13),  # Case C (aggressive gain)\n    ]\n\n    results = []\n    for case in test_cases:\n        alpha, seed = case\n        result = run_simulation(alpha, seed)\n        results.append(str(result).lower()) # convert Python bool to lowercase string\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3485795"}]}