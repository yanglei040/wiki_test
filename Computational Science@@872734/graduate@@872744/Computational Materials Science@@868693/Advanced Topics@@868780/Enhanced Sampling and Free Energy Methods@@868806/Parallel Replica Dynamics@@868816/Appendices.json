{"hands_on_practices": [{"introduction": "The primary motivation for using Parallel Replica Dynamics (ParRep) is to achieve significant computational speedup over direct simulation. This first exercise provides a quantitative foundation for understanding the performance of the ParRep method. By modeling the trade-off between the acceleration gained from parallelization and the inherent costs of dephasing and synchronization, you will derive the expected speedup and determine the optimal number of replicas to use, a crucial consideration for efficient resource allocation in any parallel computation [@problem_id:3473181].", "problem": "Consider a metastable state in an atomistic model where the exit (escape) time from the state in a single-replica serial simulation is modeled as an exponential random variable with rate parameter $\\lambda > 0$. Parallel Replica Dynamics (ParRep) is used to accelerate the sampling of exit events by running $N \\in \\mathbb{N}$ independent replicas after a dephasing stage. In ParRep, the workflow is as follows: a dephasing stage of duration $\\tau_{d} > 0$ produces $N$ decorrelated and quasi-stationary initial conditions inside the metastable state; then a parallel stage runs $N$ independent replicas until the first exit event is detected; finally, the algorithm performs a synchronization and selection stage with overhead that scales linearly in $N$ with coefficient $\\tau_{s} > 0$, representing per-replica communication and coordination costs.\n\nAssume the following:\n- The serial exit time is exponential with rate $\\lambda$, with mean $1/\\lambda$.\n- The $N$ parallel replicas have independent and identically distributed exponential exit times with the same rate $\\lambda$, and the detection/selection stage stops all replicas upon the first exit.\n- The total expected ParRep wall-clock time for one statistically correct exit event is the sum of the dephasing time, the expected time until the first exit among the $N$ replicas, and the synchronization overhead that scales linearly with $N$ with coefficient $\\tau_{s}$.\n\nUsing only first principles of exponential waiting-time processes and independence, derive a closed-form expression for the expected speedup $\\mathbb{E}[S(N)]$, defined as the ratio of the expected serial time to the expected ParRep wall-clock time for a single exit event. Then, determine the value $N^{\\star}$ (treated as a positive real for the purpose of optimization) that maximizes $\\mathbb{E}[S(N)]$ under the given linear synchronization overhead model. Express your final answers as closed-form analytic expressions. No numerical values are required. The speedup is dimensionless, and no units should be used in the answer.", "solution": "The problem statement is critically validated before proceeding to a solution.\n\n### Step 1: Extract Givens\n- The serial exit time, $T_{serial}$, is an exponential random variable with rate parameter $\\lambda > 0$.\n- The number of replicas is $N \\in \\mathbb{N}$.\n- The replicas are independent.\n- The dephasing stage duration is $\\tau_{d} > 0$.\n- The parallel stage runs $N$ independent replicas until the first exit.\n- The synchronization overhead per replica is $\\tau_{s} > 0$, for a total overhead of $N\\tau_s$.\n- The exit time for each of the $N$ replicas, $T_i$ for $i=1, 2, ..., N$, is an exponential random variable with rate $\\lambda$. They are independent and identically distributed (i.i.d.).\n- The total expected ParRep wall-clock time for one exit event is $\\mathbb{E}[T_{ParRep}(N)] = \\tau_{d} + \\mathbb{E}[\\text{time until first exit}] + N\\tau_{s}$.\n- The expected speedup is defined as $\\mathbb{E}[S(N)] = \\frac{\\mathbb{E}[T_{serial}]}{\\mathbb{E}[T_{ParRep}(N)]}$.\n- The task is to derive a closed-form expression for $\\mathbb{E}[S(N)]$ and to find the value $N^{\\star}$ (as a positive real number) that maximizes it.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded (Critical):** The problem is based on the well-established Parallel Replica Dynamics (ParRep) method used in computational science to study rare events. The modeling of exit times as exponential random variables is a standard and fundamental assumption rooted in transition state theory and the properties of Poisson processes. The linear overhead model is a basic and valid representation of communication costs in parallel algorithms. The problem is scientifically sound.\n- **Well-Posed:** The problem is clearly defined with all necessary parameters ($\\lambda, \\tau_d, \\tau_s$) and variables ($N$). The objective functions (speedup and its maximization) are explicitly stated. The mathematical framework provides a clear path to a unique and meaningful solution.\n- **Objective (Critical):** The problem is stated in precise, formal, and unbiased language. No subjective or opinion-based claims are present.\n\n### Step 3: Verdict and Action\nThe problem is scientifically grounded, well-posed, objective, and internally consistent. It is deemed **valid**. A solution will be derived.\n\n### Derivation of the Solution\n\nThe solution is derived in two parts: first, the expression for the expected speedup $\\mathbb{E}[S(N)]$, and second, the optimal number of replicas $N^{\\star}$ that maximizes this speedup.\n\n**Part 1: Expected Speedup $\\mathbb{E}[S(N)]$**\n\nThe expected speedup is the ratio of the expected time for a single-replica simulation to observe an exit event to the expected wall-clock time for the ParRep algorithm to observe one statistically correct exit event.\n\n1.  **Expected Serial Time:** The serial exit time $T_{serial}$ is stated to be an exponential random variable with rate $\\lambda$. The expected value of such a variable is the reciprocal of its rate.\n    $$\n    \\mathbb{E}[T_{serial}] = \\frac{1}{\\lambda}\n    $$\n\n2.  **Expected ParRep Wall-Clock Time:** The total expected ParRep time, $\\mathbb{E}[T_{ParRep}(N)]$, is the sum of three components:\n    - The dephasing time, given as the constant $\\tau_d$.\n    - The expected time until the first exit event in the parallel stage. Let $T_1, T_2, \\ldots, T_N$ be the i.i.d. exit times for the $N$ replicas, each following an exponential distribution with rate $\\lambda$. The time for the parallel stage is $T_{parallel} = \\min(T_1, T_2, \\ldots, T_N)$. The minimum of $N$ i.i.d. exponential random variables with rate $\\lambda$ is itself an exponential random variable with a rate equal to the sum of the individual rates, which is $N\\lambda$.\n    The probability that a single replica $T_i$ has not exited by time $t$ is $P(T_i > t) = \\exp(-\\lambda t)$. Since the replicas are independent, the probability that none of them have exited by time $t$ is:\n    $$\n    P(T_{parallel} > t) = P(T_1 > t, \\ldots, T_N > t) = \\prod_{i=1}^{N} P(T_i > t) = (\\exp(-\\lambda t))^N = \\exp(-N\\lambda t)\n    $$\n    This is the survival function of an exponential distribution with rate $N\\lambda$. The expected value of this distribution is:\n    $$\n    \\mathbb{E}[T_{parallel}] = \\frac{1}{N\\lambda}\n    $$\n    - The synchronization overhead, given as a linear function of $N$: $N\\tau_s$.\n\n    Combining these three components gives the total expected ParRep wall-clock time:\n    $$\n    \\mathbb{E}[T_{ParRep}(N)] = \\tau_d + \\mathbb{E}[T_{parallel}] + N\\tau_s = \\tau_d + \\frac{1}{N\\lambda} + N\\tau_s\n    $$\n\n3.  **Expected Speedup Expression:** The expected speedup $\\mathbb{E}[S(N)]$ is the ratio of the expected serial time to the expected ParRep time.\n    $$\n    \\mathbb{E}[S(N)] = \\frac{\\mathbb{E}[T_{serial}]}{\\mathbb{E}[T_{ParRep}(N)]} = \\frac{1/\\lambda}{\\tau_d + \\frac{1}{N\\lambda} + N\\tau_s}\n    $$\n    To simplify this expression, we can multiply the numerator and the denominator by $N\\lambda$:\n    $$\n    \\mathbb{E}[S(N)] = \\frac{N\\lambda(1/\\lambda)}{N\\lambda(\\tau_d + \\frac{1}{N\\lambda} + N\\tau_s)} = \\frac{N}{N\\lambda\\tau_d + 1 + N^2\\lambda\\tau_s}\n    $$\n    This can be rearranged into a standard polynomial form in the denominator:\n    $$\n    \\mathbb{E}[S(N)] = \\frac{N}{N^2\\lambda\\tau_s + N\\lambda\\tau_d + 1}\n    $$\n    This is the first required result.\n\n**Part 2: Optimal Number of Replicas $N^{\\star}$**\n\nTo find the number of replicas $N^{\\star}$ that maximizes the speedup $\\mathbb{E}[S(N)]$, we treat $N$ as a continuous positive real variable and find the maximum of the function $\\mathbb{E}[S(N)]$. Maximizing $\\mathbb{E}[S(N)]$ is equivalent to minimizing its reciprocal multiplied by a constant, which simplifies to minimizing the denominator of the original fraction, $\\mathbb{E}[T_{ParRep}(N)]$. Let us define this function to be minimized as $f(N)$:\n$$\nf(N) = \\mathbb{E}[T_{ParRep}(N)] = \\tau_d + \\frac{1}{N\\lambda} + N\\tau_s\n$$\nWe find the critical points by taking the first derivative of $f(N)$ with respect to $N$ and setting it to zero.\n$$\n\\frac{df}{dN} = \\frac{d}{dN} \\left( \\tau_d + \\frac{1}{N\\lambda} + N\\tau_s \\right) = 0 - \\frac{1}{N^2\\lambda} + \\tau_s\n$$\nSetting the derivative to zero:\n$$\n\\tau_s - \\frac{1}{N^2\\lambda} = 0 \\implies \\tau_s = \\frac{1}{N^2\\lambda}\n$$\nSolving for $N^2$:\n$$\nN^2 = \\frac{1}{\\lambda\\tau_s}\n$$\nSince $N$ must be positive, we take the positive square root:\n$$\nN^{\\star} = \\sqrt{\\frac{1}{\\lambda\\tau_s}} = \\frac{1}{\\sqrt{\\lambda\\tau_s}}\n$$\nTo confirm that this value corresponds to a maximum for the speedup (i.e., a minimum for the time $f(N)$), we examine the second derivative of $f(N)$:\n$$\n\\frac{d^2f}{dN^2} = \\frac{d}{dN} \\left( -\\frac{1}{N^2\\lambda} + \\tau_s \\right) = - \\left( \\frac{-2}{N^3\\lambda} \\right) = \\frac{2}{N^3\\lambda}\n$$\nSince $\\lambda > 0$, $\\tau_s > 0$, the optimal $N^{\\star}$ is positive. Therefore, for any $N > 0$, we have $\\frac{d^2f}{dN^2} > 0$. This positive second derivative indicates that $f(N)$ is a convex function for $N>0$ and that $N^{\\star}$ corresponds to a local and global minimum for $f(N)$. Consequently, $N^{\\star}$ yields the maximum value for the speedup $\\mathbb{E}[S(N)]$. This is the second required result.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{N}{N^2\\lambda\\tau_s + N\\lambda\\tau_d + 1}  \\frac{1}{\\sqrt{\\lambda\\tau_s}} \\end{pmatrix}}\n$$", "id": "3473181"}, {"introduction": "Beyond just accelerating the observation of a rare event, a successful ParRep simulation must provide statistically sound data to quantify the event's kinetics. This practice bridges the gap between simulation output and physical measurement by exploring the statistical properties of the accelerated times generated by ParRep. You will use the principles of maximum likelihood estimation to derive an estimator for the underlying escape rate, demonstrating how ParRep generates unbiased samples and how to compute the uncertainty in the resulting rate constant [@problem_id:3473198].", "problem": "Consider a metastable basin in a potential energy landscape at fixed temperature, where the exit event from the basin is rare on the timescale of local equilibration. Assume the exit time of the original, unaccelerated dynamics is a positive, continuous random variable $T$ with a constant hazard rate $k0$, meaning $h(t)=k$ for all $t\\geq 0$, where $h(t)$ is the instantaneous rate of exit conditional on survival up to time $t$. Under ideal Parallel Replica Dynamics (ParRep), after a decorrelation and dephasing stage, $N$ independent replicas are launched from the local equilibrium within the basin. Let $T^{(1)},\\dots,T^{(N)}$ denote the independent exit times of the replicas, and let $T_{\\min}=\\min\\{T^{(1)},\\dots,T^{(N)}\\}$ denote the earliest exit among the replicas. The ParRep accelerated time reported for that cycle is $T_{\\mathrm{acc}}=N\\,T_{\\min}$. Under ideal assumptions, $T_{\\mathrm{acc}}$ is used to represent one effective sample of the original exit time.\n\nYou perform $m$ independent ParRep cycles, each after successful decorrelation and dephasing, yielding independent accelerated times $\\{T_{\\mathrm{acc},i}\\}_{i=1}^{m}$. Starting from the constant hazard rate model and the independence assumptions above, derive the maximum likelihood estimator for the exit rate $k$ based on $\\{T_{\\mathrm{acc},i}\\}_{i=1}^{m}$. Then, compute the asymptotic variance of this estimator via the Fisher information.\n\nProvide your final answer as two closed-form analytic expressions: first, the maximum likelihood estimator $\\hat{k}$ in terms of the observed accelerated times, and second, the asymptotic variance of $\\hat{k}$ as a function of $k$ and $m$. No rounding is required. Do not include any units in your final answer.", "solution": "The problem is subjected to validation before a solution is attempted.\n\n### Step 1: Extract Givens\n- The unaccelerated exit time, $T$, is a positive, continuous random variable.\n- The hazard rate for $T$ is constant, $h(t) = k$ for $k  0$ and $t \\ge 0$.\n- Parallel Replica Dynamics (ParRep) is performed with $N$ independent replicas.\n- The exit times for the replicas are $T^{(1)}, \\dots, T^{(N)}$, which are independent and identically distributed (i.i.d.) random variables.\n- The earliest exit time among the replicas is $T_{\\min} = \\min\\{T^{(1)}, \\dots, T^{(N)}\\}$.\n- The ParRep accelerated time is defined as $T_{\\mathrm{acc}} = N T_{\\min}$.\n- There are $m$ independent observations of the accelerated time, denoted as $\\{T_{\\mathrm{acc},i}\\}_{i=1}^{m}$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is well-grounded in statistical mechanics and computational science. The assumption of a constant hazard rate corresponds to an exponential distribution of waiting times for a rare event, a cornerstone of transition state theory. The description of Parallel Replica Dynamics is consistent with the established literature on accelerated molecular dynamics methods.\n- **Well-Posed**: The problem is well-posed. It asks for the derivation of a maximum likelihood estimator (MLE) and its asymptotic variance, which are standard procedures in statistical inference. The provided information is sufficient and self-contained for these derivations.\n- **Objective**: The problem statement is written in precise, objective language, free from ambiguity or subjective claims.\n\nThe problem does not exhibit any flaws such as scientific unsoundness, incompleteness, or ambiguity. It is a formal, solvable problem in mathematical statistics applied to a recognized physical model.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be provided.\n\n### Solution Derivation\n\nThe solution requires a multi-step derivation, beginning with the probability distribution of the exit times and culminating in the calculation of the estimator's variance.\n\n**1. Distribution of the Unaccelerated Exit Time $T$**\nThe hazard rate function $h(t)$ is related to the probability density function (PDF) $f_T(t)$ and the survivor function $S_T(t) = P(T > t)$ by $h(t) = f_T(t) / S_T(t)$. The survivor function can be derived from the hazard rate:\n$$S_T(t) = \\exp\\left(-\\int_0^t h(u) \\, du\\right)$$\nGiven $h(t) = k$, a constant, we have:\n$$S_T(t) = \\exp\\left(-\\int_0^t k \\, du\\right) = \\exp(-kt)$$\nThe cumulative distribution function (CDF) is $F_T(t) = 1 - S_T(t) = 1 - \\exp(-kt)$. The PDF is the derivative of the CDF:\n$$f_T(t) = \\frac{d}{dt} F_T(t) = \\frac{d}{dt} (1 - \\exp(-kt)) = k \\exp(-kt)$$\nThis is the PDF for an exponential distribution with rate parameter $k$, denoted as $T \\sim \\text{Exp}(k)$. The mean of this distribution is $E[T] = 1/k$.\n\n**2. Distribution of the Minimum Exit Time $T_{\\min}$**\nThe variable $T_{\\min}$ is the minimum of $N$ i.i.d. random variables $T^{(j)}$, each distributed as $\\text{Exp}(k)$. The survivor function of $T_{\\min}$ is:\n$$S_{T_{\\min}}(t) = P(T_{\\min} > t) = P(T^{(1)} > t, T^{(2)} > t, \\ldots, T^{(N)} > t)$$\nDue to independence, this becomes:\n$$S_{T_{\\min}}(t) = \\prod_{j=1}^{N} P(T^{(j)} > t) = (S_T(t))^N = (\\exp(-kt))^N = \\exp(-Nkt)$$\nThe PDF of $T_{\\min}$ is found by first obtaining its CDF, $F_{T_{\\min}}(t) = 1 - S_{T_{\\min}}(t) = 1 - \\exp(-Nkt)$, and then differentiating:\n$$f_{T_{\\min}}(t) = \\frac{d}{dt} (1 - \\exp(-Nkt)) = Nk \\exp(-Nkt)$$\nThus, $T_{\\min}$ follows an exponential distribution with rate parameter $Nk$, i.e., $T_{\\min} \\sim \\text{Exp}(Nk)$.\n\n**3. Distribution of the Accelerated Time $T_{\\mathrm{acc}}$**\nThe accelerated time is defined as $T_{\\mathrm{acc}} = N T_{\\min}$. To find its distribution, we use the method of transformations. Let $Y = T_{\\mathrm{acc}}$ and $X = T_{\\min}$. We have $Y = NX$. The CDF of $Y$ is:\n$$F_Y(y) = P(Y \\le y) = P(NX \\le y) = P(X \\le y/N) = F_{T_{\\min}}(y/N)$$\nSubstituting the CDF of $T_{\\min}$:\n$$F_Y(y) = 1 - \\exp(-Nk(y/N)) = 1 - \\exp(-ky)$$\nThe PDF of $T_{\\mathrm{acc}}$ is the derivative of its CDF:\n$$f_{T_{\\mathrm{acc}}}(y) = \\frac{d}{dy} (1 - \\exp(-ky)) = k \\exp(-ky)$$\nThis demonstrates that $T_{\\mathrm{acc}}$ follows the same distribution as the original, unaccelerated exit time $T$, i.e., $T_{\\mathrm{acc}} \\sim \\text{Exp}(k)$. The problem data consist of $m$ i.i.d. samples $\\{T_{\\mathrm{acc},i}\\}_{i=1}^{m}$ from this distribution.\n\n**4. Maximum Likelihood Estimator (MLE) for $k$**\nLet the observed data be $\\{t_i\\}_{i=1}^{m}$, where $t_i = T_{\\mathrm{acc},i}$. The likelihood function $L(k)$ for these data is the product of the individual probability densities:\n$$L(k \\mid \\{t_i\\}) = \\prod_{i=1}^{m} f_{T_{\\mathrm{acc}}}(t_i; k) = \\prod_{i=1}^{m} k \\exp(-kt_i) = k^m \\exp\\left(-k \\sum_{i=1}^{m} t_i\\right)$$\nIt is more convenient to work with the log-likelihood function, $\\ell(k) = \\ln L(k)$:\n$$\\ell(k) = \\ln\\left(k^m \\exp\\left(-k \\sum_{i=1}^{m} t_i\\right)\\right) = m \\ln(k) - k \\sum_{i=1}^{m} t_i$$\nTo find the MLE, $\\hat{k}$, we differentiate $\\ell(k)$ with respect to $k$ and set the result to zero:\n$$\\frac{d\\ell(k)}{dk} = \\frac{m}{k} - \\sum_{i=1}^{m} t_i = 0$$\nSolving for $k$ gives the estimator $\\hat{k}$:\n$$\\frac{m}{\\hat{k}} = \\sum_{i=1}^{m} t_i \\implies \\hat{k} = \\frac{m}{\\sum_{i=1}^{m} t_i}$$\nRe-substituting $T_{\\mathrm{acc},i}$ for $t_i$, the MLE is:\n$$\\hat{k} = \\frac{m}{\\sum_{i=1}^{m} T_{\\mathrm{acc},i}}$$\nTo confirm this is a maximum, we check the second derivative:\n$$\\frac{d^2\\ell(k)}{dk^2} = -\\frac{m}{k^2}$$\nSince $m > 0$ and $k^2 > 0$, the second derivative is always negative, confirming that $\\hat{k}$ maximizes the likelihood.\n\n**5. Asymptotic Variance of $\\hat{k}$**\nThe asymptotic variance of an MLE is given by the inverse of the Fisher information. The Fisher information for $m$ i.i.d. samples, $I_m(k)$, is $m$ times the Fisher information for a single sample, $I_1(k)$.\n$$I_1(k) = -E\\left[\\frac{d^2}{dk^2} \\ln f(t; k)\\right]$$\nThe log-likelihood for a single observation $t$ from $\\text{Exp}(k)$ is $\\ln(k) - kt$.\nThe second derivative with respect to $k$ is:\n$$\\frac{d^2}{dk^2} (\\ln(k) - kt) = -\\frac{1}{k^2}$$\nThis expression is a constant with respect to the random variable $t$, so its expectation is the value itself:\n$$I_1(k) = -E\\left[-\\frac{1}{k^2}\\right] = \\frac{1}{k^2}$$\nThe total Fisher information for $m$ samples is:\n$$I_m(k) = m \\cdot I_1(k) = \\frac{m}{k^2}$$\nThe asymptotic variance of the MLE $\\hat{k}$ is the reciprocal of the total Fisher information (the CramÃ©r-Rao lower bound, which is achieved by the MLE asymptotically):\n$$\\text{Var}(\\hat{k}) \\approx \\frac{1}{I_m(k)} = \\frac{1}{m/k^2} = \\frac{k^2}{m}$$\nThis is the asymptotic variance of the estimator.\n\nThe two requested quantities are the MLE $\\hat{k}$ and its asymptotic variance.\n- MLE: $\\hat{k} = \\frac{m}{\\sum_{i=1}^{m} T_{\\mathrm{acc},i}}$\n- Asymptotic Variance: $\\frac{k^2}{m}$", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{m}{\\sum_{i=1}^{m} T_{\\mathrm{acc},i}}  \\frac{k^2}{m} \\end{pmatrix}}$$", "id": "3473198"}, {"introduction": "The validity of Parallel Replica Dynamics rests on a crucial physical assumption: a clear separation of timescales between fast relaxation within a metastable state and the slow, rare process of escaping it. This hands-on computational exercise allows you to rigorously test this assumption using the concept of the committor function. By calculating committor probabilities for a model multi-well system, you will gain a deep, practical understanding of what defines a \"good\" metastable state for ParRep analysis and how to validate the applicability of the method to a given system [@problem_id:3473222].", "problem": "Consider overdamped Langevin dynamics in one spatial dimension for a particle evolving under a confining triple-well potential. The dynamics are described by the stochastic differential equation:\n$$dx_t = -D \\beta U'(x_t) \\, dt + \\sqrt{2D} \\, dW_t$$\nwhere $x_t$ is the position as a function of time $t$, $D$ is the constant diffusion coefficient, $\\beta$ is the inverse temperature, $U(x)$ is the potential energy function, $U'(x)$ is the spatial derivative of $U(x)$, and $W_t$ is a standard Wiener process. In nondimensional units, take $D = 1$. The potential is specified as $U(x) = a x^6 - b x^4 + c x^2$, with parameters $a > 0$, $b > 0$, $c > 0$ chosen so that $U(x)$ has three local minima separated by two local maxima. This occurs when $b^2 > 3 a c$. Define the computational domain as the interval $\\left[-L, L\\right]$, with $L > 0$ sufficiently large to capture the outer basins.\n\nA key assumption underlying Parallel Replica Dynamics (PRD) is the existence of a timescale separation between intra-basin mixing and inter-basin crossing: once the system enters a basin, it quickly relaxes to the quasi-stationary distribution before a rare transition event occurs to leave the basin. One way to validate this assumption is through committor functions. For a pair of disjoint boundaries $x_\\ell  x_r$, the committor function $q(x)$ is defined as the probability that a trajectory starting at position $x$ hits the boundary at $x_r$ before the boundary at $x_\\ell$.\n\nYour tasks are:\n\n1. Construct the partition of the domain into basins using the local minima and local maxima of $U(x)$. Specifically:\n   - Compute all critical points of $U(x)$ by solving $U'(x) = 0$ and classify them by the sign of $U''(x)$ to identify local minima and local maxima.\n   - Let $x = 0$ be the central minimum (for $c > 0$). Using the remaining critical points, identify the left and right local minima at $x = -x_{\\min}$ and $x = +x_{\\min}$ and the left and right local maxima (saddles in one dimension) at $x = -x_{\\mathrm{sad}}$ and $x = +x_{\\mathrm{sad}}$, with $x_{\\mathrm{sad}}  x_{\\min}$.\n   - Define three basins as intervals: the left basin $\\left[-L, -x_{\\mathrm{sad}}\\right]$, the central basin $\\left[-x_{\\mathrm{sad}}, +x_{\\mathrm{sad}}\\right]$, and the right basin $\\left[+x_{\\mathrm{sad}}, +L\\right]$.\n\n2. For each basin, define an appropriate committor function consistent with the direction of an inter-basin crossing event:\n   - In the left basin, define $q_{\\mathrm{left}}(x)$ as the probability to hit $-x_{\\mathrm{sad}}$ before $-L$.\n   - In the central basin, define $q_{\\mathrm{center}}(x)$ as the probability to hit $+x_{\\mathrm{sad}}$ before $-x_{\\mathrm{sad}}$.\n   - In the right basin, define $p_{\\mathrm{right}}(x)$ as the probability to hit $+x_{\\mathrm{sad}}$ before $+L$.\n   In all cases, use the backward equation associated with the Langevin dynamics to compute these committor functions, with absorbing boundary conditions $q(x_\\ell) = 0$ and $q(x_r) = 1$ for the pair $\\left(x_\\ell, x_r\\right)$ relevant to the basin. Answer in nondimensional units.\n\n3. To validate that intra-basin mixing is fast relative to crossing events, quantify the sharpness of the committor transition layer within each basin by computing the width of the region in which the committor lies between the thresholds $0.1$ and $0.9$. Specifically, for each basin, compute the positions $x_{0.1}$ and $x_{0.9}$ at which the committor equals $0.1$ and $0.9$, respectively, and define the transition width as $w = |x_{0.9} - x_{0.1}|$. Define the basin width as $W = x_r - x_\\ell$. For the right basin, apply this to $p_{\\mathrm{right}}(x)$ rather than $q_{\\mathrm{right}}(x)$ so that the threshold interpretation is consistent with crossing toward the center. Report the ratio $r = w / W$ for each basin, and finally report, for each parameter set, the maximum of these three ratios across the basins. Small values of $r$ indicate a narrow transition region relative to basin size and hence fast intra-basin mixing relative to crossing.\n\n4. Implement a complete program that carries out the above steps and produces results for the following test suite. Use nondimensional units throughout. For each test case, output a single float equal to the maximum transition ratio across the three basins:\n   - Test case $1$: $a = 1.0$, $b = 3.0$, $c = 2.0$, $\\beta = 10.0$, $L = 3.0$.\n   - Test case $2$: $a = 1.0$, $b = 2.8$, $c = 2.0$, $\\beta = 5.0$, $L = 3.0$.\n   - Test case $3$: $a = 1.0$, $b = 3.5$, $c = 2.0$, $\\beta = 25.0$, $L = 3.5$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $\\left[\\text{result}_1,\\text{result}_2,\\text{result}_3\\right]$). Each result must be a float. No other text should be printed.", "solution": "### Principle-Based Design\n\nThe solution proceeds through a sequence of logical steps derived from the theory of stochastic processes.\n\n**1. Basin Identification**\n\nThe potential is given by $U(x) = a x^6 - b x^4 + c x^2$. The basins of attraction are separated by local maxima of the potential (saddle points in 1D). To find these, we first compute the critical points by solving $U'(x) = 0$:\n$$ U'(x) = 6ax^5 - 4bx^3 + 2cx = 2x(3ax^4 - 2bx^2 + c) = 0 $$\nOne critical point is $x=0$. The others are found by solving the quadratic equation in $x^2$: $3a(x^2)^2 - 2b(x^2) + c = 0$. The solutions for $x^2$ are:\n$$ x^2 = \\frac{2b \\pm \\sqrt{4b^2 - 12ac}}{6a} = \\frac{b \\pm \\sqrt{b^2 - 3ac}}{3a} $$\nThe condition $b^2 > 3ac$ ensures two distinct, positive solutions for $x^2$. The smaller value of $x^2$ corresponds to the local maxima (saddles) at $\\pm x_{\\mathrm{sad}}$, and the larger value corresponds to the side-well local minima at $\\pm x_{\\min}$. The point $x=0$ is the central minimum. The basins are then defined by the saddle points: Left: $\\left[-L, -x_{\\mathrm{sad}}\\right]$, Central: $\\left[-x_{\\mathrm{sad}}, +x_{\\mathrm{sad}}\\right]$, and Right: $\\left[+x_{\\mathrm{sad}}, L\\right]$.\n\n**2. Committor Function Solution**\n\nThe committor function $q(x)$ for a process on an interval $[x_\\ell, x_r]$ is governed by the backward equation, which for the given overdamped Langevin dynamics with $D=1$ is:\n$$ \\frac{d^2q}{dx^2} - \\beta U'(x) \\frac{dq}{dx} = 0 $$\nwith boundary conditions $q(x_\\ell) = 0$ and $q(x_r) = 1$. This is a second-order linear ODE. Letting $v(x) = q'(x)$, we get a first-order separable equation $v'(x) = \\beta U'(x) v(x)$, which solves to $v(x) = C_1 e^{\\beta U(x)}$. Integrating $q'(x)$ from $x_\\ell$ to $x$ and applying the boundary conditions yields the well-known solution:\n$$ q(x) = \\frac{\\displaystyle \\int_{x_\\ell}^{x} e^{\\beta U(y)} \\,dy}{\\displaystyle \\int_{x_\\ell}^{x_r} e^{\\beta U(y)} \\,dy} $$\nThis formula is used for all basins, with the appropriate definitions of $x_\\ell$ and $x_r$ for each committor ($q_{\\mathrm{left}}$, $q_{\\mathrm{center}}$, $p_{\\mathrm{right}}$).\n\n**3. Numerical Implementation**\n\nThe core of the problem is to compute the ratio $r = w/W$ for each basin. This requires finding the positions $x_{0.1}$ and $x_{0.9}$ where the relevant committor is $0.1$ and $0.9$. This is equivalent to solving for $x$ in:\n$$ \\int_{x_\\ell}^{x} e^{\\beta U(y)} \\,dy = C \\cdot \\int_{x_\\ell}^{x_r} e^{\\beta U(y)} \\,dy $$\nwhere $C$ is $0.1$ or $0.9$. This is a root-finding problem for $x$.\n\nA significant numerical challenge arises from the term $e^{\\beta U(y)}$, which can cause floating-point overflow for large $\\beta$. We circumvent this by shifting the potential by a constant $U_0$ (the minimum value in the integration interval), which does not change the ratio of integrals:\n$$ q(x) = \\frac{\\displaystyle \\int_{x_\\ell}^{x} e^{\\beta (U(y)-U_0)} \\,dy}{\\displaystyle \\int_{x_\\ell}^{x_r} e^{\\beta (U(y)-U_0)} \\,dy} $$\nThe overall algorithm for each basin is:\n1. Define the basin boundaries $(x_\\ell, x_r)$.\n2. Numerically find the minimum of the potential $U_0 = \\min_{y \\in [x_\\ell, x_r]} U(y)$ for stabilization.\n3. Define the stabilized integrand $f(y) = e^{\\beta(U(y)-U_0)}$.\n4. Compute the total integral $I_{\\mathrm{tot}} = \\int_{x_\\ell}^{x_r} f(y) \\,dy$ using numerical quadrature.\n5. Solve for $x_{0.1}$ and $x_{0.9}$ by finding the roots of the equations $\\int_{x_\\ell}^{x} f(y) \\,dy - C \\cdot I_{\\mathrm{tot}} = 0$ for $C=0.1$ and $C=0.9$ using a numerical root-finder.\n6. The transition width is the positive distance $w = |x_{0.9}-x_{0.1}|$.\n7. Compute the ratio $r = w / (x_r - x_\\ell)$.\nFinally, the maximum ratio among the three basins is selected as the result for the given parameter set. This procedure is implemented in the provided code.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import quad\nfrom scipy.optimize import brentq, minimize_scalar\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all specified test cases.\n    \"\"\"\n\n    test_cases = [\n        # (a, b, c, beta, L)\n        (1.0, 3.0, 2.0, 10.0, 3.0),\n        (1.0, 2.8, 2.0, 5.0, 3.0),\n        (1.0, 3.5, 2.0, 25.0, 3.5),\n    ]\n\n    results = []\n    for case in test_cases:\n        a, b, c, beta, L = case\n        max_ratio = calculate_max_transition_ratio(a, b, c, beta, L)\n        results.append(max_ratio)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef calculate_max_transition_ratio(a, b, c, beta, L):\n    \"\"\"\n    Calculates the maximum transition ratio across the three basins for a given set of parameters.\n    \"\"\"\n    \n    # Define the potential energy function U(x)\n    U = lambda x: a * x**6 - b * x**4 + c * x**2\n    \n    # 1. Find critical points to define basins\n    # The saddles are roots of 3a*z^2 - 2b*z + c = 0 where z = x^2.\n    # We only need the smaller positive root for x^2, which corresponds to the saddle points.\n    discriminant = (2 * b)**2 - 4 * (3 * a) * c\n    # The x^2 value for the saddle point\n    x_sad_sq = (2 * b - np.sqrt(discriminant)) / (2 * 3 * a)\n    x_sad = np.sqrt(x_sad_sq)\n    \n    # Define the three basins based on the saddle points\n    basins = [\n        (-L, -x_sad),       # Left basin\n        (-x_sad, x_sad),    # Central basin\n        (x_sad, L),         # Right basin\n    ]\n    \n    ratios = []\n    for xl, xr in basins:\n        # Note: The committor for the right basin from x_sad to L is p(x), prob to hit x_sad before L.\n        # This is equivalent to q(x) on [L, x_sad]. The integral formulation is symmetric\n        # and our implementation finds the width of the 0.1->0.9 transition layer, which is what's required.\n        ratio = compute_ratio_for_basin(xl, xr, U, beta)\n        ratios.append(ratio)\n        \n    return max(ratios)\n\ndef compute_ratio_for_basin(xl, xr, U_func, beta):\n    \"\"\"\n    Computes the transition width to basin width ratio for a single basin.\n\n    This function calculates the width of the region where the normalized integral\n    of exp(beta*U(x)) is between 0.1 and 0.9. This corresponds to the physical\n    transition width of the committor function.\n    \"\"\"\n    \n    # 1. Numerical stabilization by shifting the potential\n    # Find the minimum of the potential U(x) in the interval [xl, xr]\n    res = minimize_scalar(U_func, bounds=(xl, xr), method='bounded')\n    U_min = res.fun\n    \n    # Define the numerically stable integrand\n    stable_integrand = lambda y: np.exp(beta * (U_func(y) - U_min))\n    \n    # 2. Compute the total integral for normalization\n    total_integral, _ = quad(stable_integrand, xl, xr, epsabs=1e-12, epsrel=1e-12)\n    \n    # 3. Define functions for the root-finder\n    # The root of this function gives the position x where the partial integral\n    # is 0.1 of the total integral.\n    def root_func_01(x):\n        integral_part, _ = quad(stable_integrand, xl, x, epsabs=1e-12, epsrel=1e-12)\n        return integral_part - 0.1 * total_integral\n    \n    # The root of this function gives the position x for the 0.9 threshold.\n    def root_func_09(x):\n        integral_part, _ = quad(stable_integrand, xl, x, epsabs=1e-12, epsrel=1e-12)\n        return integral_part - 0.9 * total_integral\n        \n    # 4. Find the positions x_0.1 and x_0.9 by finding the roots\n    # The brentq algorithm requires an interval where the function changes sign.\n    # The functions are monotonic, so [xl, xr] is a valid bracket.\n    try:\n        x_sol_01 = brentq(root_func_01, xl, xr)\n        x_sol_09 = brentq(root_func_09, xl, xr)\n    except ValueError:\n        # This may happen if the function does not change sign,\n        # e.g., if the integral is numerically zero. Return a default value.\n        return 0.0\n\n    # 5. Calculate widths and the final ratio\n    # W_basin is the total width of the basin\n    W_basin = xr - xl\n    \n    # w_transition is the width of the transition region (0.1 to 0.9)\n    # The width is a positive quantity, |x_0.9 - x_0.1|.\n    # Since the integral is monotonically increasing, x_sol_09 > x_sol_01.\n    w_transition = x_sol_09 - x_sol_01\n    \n    if W_basin == 0:\n        return 0.0\n\n    return w_transition / W_basin\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3473222"}]}