{"hands_on_practices": [{"introduction": "A crucial step in designing any umbrella sampling study is the placement of the individual sampling windows. Placing windows too far apart leads to poor overlap between the sampled distributions, resulting in large statistical errors and an unreliable final PMF. This exercise moves beyond simple heuristics by introducing a systematic, adaptive algorithm to optimize window placement. By modeling each window's distribution and using the symmetric Kullback–Leibler divergence as a rigorous measure of overlap, we can iteratively refine the window spacing until a desired level of statistical continuity is achieved across the entire reaction coordinate [@problem_id:3499551]. This practice provides a robust and automatable protocol for setting up efficient and accurate PMF calculations.", "problem": "You are tasked with designing and implementing an adaptive windowing scheme for umbrella sampling of a one-dimensional reaction coordinate in computational materials science. The objective is to refine window centers so that adjacent biased sampling windows have sufficient statistical overlap, quantified via the Kullback–Leibler divergence (KLD). The physical setup assumes harmonic bias potentials, short preliminary simulations that yield sample variances of the reaction coordinate within each window, and thermal equilibrium at a specified temperature. Your program must implement the adaptive refinement of window centers based on these preliminary overlap metrics and stop when all adjacent windows satisfy a divergence threshold. The final program must produce a single line of output containing the results for the provided test suite, formatted as a comma-separated list enclosed in square brackets.\n\nFundamental basis and modeling assumptions:\n- The reaction coordinate $x$ is a continuous variable with physical unit nanometers.\n- Under canonical ensemble conditions at temperature $T$ with molar gas constant $R$, the equilibrium density along $x$ in a biased window is proportional to $\\exp(-\\beta (F(x) + U_{\\text{bias}}(x)))$ with $\\beta = 1/(RT)$, where $F(x)$ is the potential of mean force and $U_{\\text{bias}}(x)$ is the harmonic bias $U_{\\text{bias}}(x) = \\tfrac{1}{2} k (x - c)^2$, with $k$ the bias stiffness in $\\mathrm{kJ\\,mol^{-1}\\,nm^{-2}}$ and $c$ the window center in $\\mathrm{nm}$.\n- Preliminary short simulations yield sample variances at each window center $c_i$, denoted $\\sigma_i^2$ in units of $\\mathrm{nm}^2$. These variances are used to approximate each window’s biased reaction-coordinate distribution as a normal distribution.\n- The Kullback–Leibler divergence (KLD) between two adjacent window distributions should be used as the overlap metric. To remove directionality, use the symmetric KLD (also known as the Jeffreys divergence), defined as the sum of the two directed KLDs, each computed from first principles using the definition of KLD for continuous distributions.\n\nAdaptive scheme requirements:\n- Represent each window as a normal distribution $\\mathcal{N}(c_i, \\sigma_i^2)$ based on its center $c_i$ and sample standard deviation $\\sigma_i$.\n- For each adjacent pair $(i,i+1)$, compute the symmetric KLD using the definition of KLD for normal distributions derived from first principles.\n- If any adjacent pair violates the stopping criterion $J_{i,i+1} \\le \\tau$ (where $J_{i,i+1}$ is the symmetric KLD and $\\tau$ is a user-specified positive threshold), refine by inserting a new window at the midpoint $c_{\\text{new}} = \\tfrac{c_i + c_{i+1}}{2}$ with a preliminary standard deviation $\\sigma_{\\text{new}}$ given by the average $\\sigma_{\\text{new}} = \\tfrac{\\sigma_i + \\sigma_{i+1}}{2}$.\n- Repeat the computation of symmetric KLDs and insertion of midpoint windows until all adjacent pairs satisfy $J_{i,i+1} \\le \\tau$.\n- All lengths $c_i$ and $\\sigma_i$ must be in $\\mathrm{nm}$, temperatures $T$ in $\\mathrm{K}$, stiffnesses $k$ in $\\mathrm{kJ\\,mol^{-1}\\,nm^{-2}}$, and $R$ in $\\mathrm{kJ\\,mol^{-1}\\,K^{-1}}$. The KLD is dimensionless.\n- Your program must not require any external input; it must run the specified test cases embedded within the code and print the final number of refined window centers as integers for each case.\n\nTest suite:\n- Case $1$ (happy path, substantial refinement needed):\n  - Domain $[0,1]$ $\\mathrm{nm}$, bias stiffness $k = 1000$ $\\mathrm{kJ\\,mol^{-1}\\,nm^{-2}}$, temperature $T = 300$ $\\mathrm{K}$.\n  - Initial centers $\\{0.0, 0.5, 1.0\\}$ $\\mathrm{nm}$.\n  - Preliminary sample standard deviations $\\{\\sigma_0, \\sigma_1, \\sigma_2\\} = \\{0.05, 0.045, 0.05\\}$ $\\mathrm{nm}$.\n  - Stopping threshold $\\tau = 2.0$ (dimensionless).\n- Case $2$ (moderate refinement):\n  - Domain $[0,1]$ $\\mathrm{nm}$, bias stiffness $k = 200$ $\\mathrm{kJ\\,mol^{-1}\\,nm^{-2}}$, temperature $T = 300$ $\\mathrm{K}$.\n  - Initial centers $\\{0.0, 0.25, 0.5, 0.75, 1.0\\}$ $\\mathrm{nm}$.\n  - Preliminary sample standard deviations $\\{0.112, 0.112, 0.112, 0.112, 0.112\\}$ $\\mathrm{nm}$.\n  - Stopping threshold $\\tau = 4.0$.\n- Case $3$ (already adequate overlap):\n  - Domain $[0,0.4]$ $\\mathrm{nm}$, bias stiffness $k = 100$ $\\mathrm{kJ\\,mol^{-1}\\,nm^{-2}}$, temperature $T = 300$ $\\mathrm{K}$.\n  - Initial centers $\\{0.0, 0.2, 0.4\\}$ $\\mathrm{nm}$.\n  - Preliminary sample standard deviations $\\{0.158, 0.158, 0.158\\}$ $\\mathrm{nm}$.\n  - Stopping threshold $\\tau = 2.5$.\n- Case $4$ (edge case, very stiff bias):\n  - Domain $[0,1]$ $\\mathrm{nm}$, bias stiffness $k = 5000$ $\\mathrm{kJ\\,mol^{-1}\\,nm^{-2}}$, temperature $T = 300$ $\\mathrm{K}$.\n  - Initial centers $\\{0.0, 1.0\\}$ $\\mathrm{nm}$.\n  - Preliminary sample standard deviations $\\{0.022, 0.022\\}$ $\\mathrm{nm}$.\n  - Stopping threshold $\\tau = 1.5$.\n\nAlgorithmic output specification:\n- For each test case, run the adaptive refinement until the stopping criterion holds for every adjacent pair and return the final count of window centers as an integer.\n- Your program should produce a single line of output containing the results for the four test cases as a comma-separated list enclosed in square brackets (e.g., $[n_1,n_2,n_3,n_4]$).", "solution": "The problem requires the design and implementation of an adaptive windowing algorithm for umbrella sampling simulations. The core of the task is to iteratively refine the placement of sampling windows along a one-dimensional reaction coordinate, $x$, until a sufficient statistical overlap is achieved between all adjacent windows. The overlap is quantified using the symmetric Kullback-Leibler divergence, also known as the Jeffreys divergence, under the assumption that the particle distribution within each biased window is normal.\n\nThe solution proceeds in two main parts: first, the derivation of the mathematical formula for the overlap metric, and second, the description of the iterative algorithm that uses this metric to refine the window placement.\n\n**1. The Overlap Metric: Symmetric Kullback-Leibler Divergence**\n\nThe problem specifies that each sampling window, characterized by a harmonic biasing potential centered at $c_i$, results in a distribution of the reaction coordinate $x$ that can be approximated by a normal distribution, $P_i(x) = \\mathcal{N}(c_i, \\sigma_i^2)$. The probability density function for such a distribution is:\n$$\nP_i(x) = \\frac{1}{\\sqrt{2\\pi\\sigma_i^2}} \\exp\\left(-\\frac{(x - c_i)^2}{2\\sigma_i^2}\\right)\n$$\nwhere $c_i$ is the mean (the window center) and $\\sigma_i^2$ is the variance, obtained from preliminary simulations.\n\nThe overlap between two adjacent distributions, $P_1 = \\mathcal{N}(c_1, \\sigma_1^2)$ and $P_2 = \\mathcal{N}(c_2, \\sigma_2^2)$, is measured by the symmetric Kullback-Leibler (KL) divergence, $J_{1,2}$. This is defined as the sum of the two directed KL divergences:\n$$\nJ_{1,2} = D_{\\text{KL}}(P_1 || P_2) + D_{\\text{KL}}(P_2 || P_1)\n$$\nThe KL divergence from $P_2$ to $P_1$ is given by the integral:\n$$\nD_{\\text{KL}}(P_1 || P_2) = \\int_{-\\infty}^{\\infty} P_1(x) \\log\\left(\\frac{P_1(x)}{P_2(x)}\\right) dx\n$$\nFor two one-dimensional normal distributions, this integral has a well-known closed-form solution. First, we expand the logarithm term:\n$$\n\\log\\left(\\frac{P_1(x)}{P_2(x)}\\right) = \\log\\left(\\frac{1/\\sqrt{2\\pi\\sigma_1^2}}{1/\\sqrt{2\\pi\\sigma_2^2}} \\cdot \\frac{\\exp(-\\frac{(x - c_1)^2}{2\\sigma_1^2})}{\\exp(-\\frac{(x - c_2)^2}{2\\sigma_2^2})}\\right) = \\log\\left(\\frac{\\sigma_2}{\\sigma_1}\\right) - \\frac{(x - c_1)^2}{2\\sigma_1^2} + \\frac{(x - c_2)^2}{2\\sigma_2^2}\n$$\nInserting this into the integral and using the fact that $\\int P_1(x) dx = 1$ and $\\mathbb{E}_1[(x-c_1)^2] = \\sigma_1^2$:\n$$\nD_{\\text{KL}}(P_1 || P_2) = \\mathbb{E}_1\\left[\\log\\left(\\frac{\\sigma_2}{\\sigma_1}\\right) - \\frac{(x - c_1)^2}{2\\sigma_1^2} + \\frac{(x - c_2)^2}{2\\sigma_2^2}\\right]\n$$\n$$\nD_{\\text{KL}}(P_1 || P_2) = \\log\\left(\\frac{\\sigma_2}{\\sigma_1}\\right) - \\frac{\\mathbb{E}_1[(x - c_1)^2]}{2\\sigma_1^2} + \\frac{\\mathbb{E}_1[(x - c_2)^2]}{2\\sigma_2^2}\n$$\nWe need to evaluate $\\mathbb{E}_1[(x - c_2)^2] = \\int P_1(x)(x-c_2)^2 dx$. By adding and subtracting $c_1$, we get:\n$$\n\\mathbb{E}_1[(x - c_1 + c_1 - c_2)^2] = \\mathbb{E}_1[(x - c_1)^2 + 2(x - c_1)(c_1 - c_2) + (c_1 - c_2)^2]\n$$\n$$\n= \\mathbb{E}_1[(x - c_1)^2] + 2(c_1 - c_2)\\mathbb{E}_1[x - c_1] + (c_1 - c_2)^2 = \\sigma_1^2 + 0 + (c_1 - c_2)^2\n$$\nSubstituting back, we obtain the expression for the directed KL divergence:\n$$\nD_{\\text{KL}}(P_1 || P_2) = \\log\\left(\\frac{\\sigma_2}{\\sigma_1}\\right) + \\frac{\\sigma_1^2 + (c_1 - c_2)^2}{2\\sigma_2^2} - \\frac{1}{2}\n$$\nThe symmetric divergence $J_{1,2}$ is the sum of this expression and the one with indices $1$ and $2$ swapped:\n$$\nJ_{1,2} = \\left[ \\log\\left(\\frac{\\sigma_2}{\\sigma_1}\\right) + \\frac{\\sigma_1^2 + (c_1 - c_2)^2}{2\\sigma_2^2} - \\frac{1}{2} \\right] + \\left[ \\log\\left(\\frac{\\sigma_1}{\\sigma_2}\\right) + \\frac{\\sigma_2^2 + (c_2 - c_1)^2}{2\\sigma_1^2} - \\frac{1}{2} \\right]\n$$\nThe logarithm terms cancel as $\\log(a) + \\log(1/a) = 0$, and $(c_1 - c_2)^2 = (c_2 - c_1)^2$. This simplifies to the final expression used in the algorithm:\n$$\nJ_{1,2} = \\frac{\\sigma_1^2 + (c_1 - c_2)^2}{2\\sigma_2^2} + \\frac{\\sigma_2^2 + (c_1 - c_2)^2}{2\\sigma_1^2} - 1\n$$\nThis can also be written as:\n$$\nJ_{1,2} = \\frac{1}{2}\\left(\\frac{\\sigma_1^2}{\\sigma_2^2} + \\frac{\\sigma_2^2}{\\sigma_1^2}\\right) + \\frac{(c_1 - c_2)^2}{2}\\left(\\frac{1}{\\sigma_1^2} + \\frac{1}{\\sigma_2^2}\\right) - 1\n$$\nThis dimensionless quantity provides a measure of disparity between the two distributions. A smaller value indicates greater overlap.\n\n**2. Adaptive Refinement Algorithm**\n\nThe adaptive scheme iteratively improves the set of sampling windows until all adjacent pairs satisfy the overlap criterion $J_{i,i+1} \\le \\tau$, where $\\tau$ is a specified tolerance.\n\nThe algorithm proceeds as follows:\n1.  **Initialization**: Start with an initial list of windows, each defined by a pair $(c_i, \\sigma_i)$, sorted by the center coordinate $c_i$.\n2.  **Iteration Loop**: Enter a loop that continues until no refinements are made in a full pass. A boolean flag, `refined_in_pass`, can track this.\n3.  **Overlap Evaluation**: In each pass, iterate through all adjacent pairs of windows, $(c_i, \\sigma_i)$ and $(c_{i+1}, \\sigma_{i+1})$.\n4.  **Compute Divergence**: For each pair, calculate the symmetric KL divergence $J_{i,i+1}$ using the formula derived above.\n5.  **Check Criterion**: If $J_{i,i+1} > \\tau$, the overlap is insufficient, and the interval between these two windows must be refined. Mark this interval for refinement.\n6.  **Refinement**: After checking all pairs in a pass, generate a new list of windows. This new list includes all original windows plus new windows inserted at the midpoint of each interval that was marked for refinement.\n    -   For a pair $(c_i, \\sigma_i)$ and $(c_{i+1}, \\sigma_{i+1})$ needing refinement, a new window $(c_{\\text{new}}, \\sigma_{\\text{new}})$ is created with:\n        $$\n        c_{\\text{new}} = \\frac{c_i + c_{i+1}}{2}\n        $$\n        $$\n        \\sigma_{\\text{new}} = \\frac{\\sigma_i + \\sigma_{i+1}}{2}\n        $$\n7.  **Update**: The new, expanded list of windows replaces the old one for the next iteration. The list remains sorted by construction.\n8.  **Termination**: If a full pass is completed with `refined_in_pass` remaining false (i.e., $J_{i,i+1} \\le \\tau$ for all adjacent pairs), the algorithm has converged. The final number of windows is then reported.\n\nThis iterative process is guaranteed to terminate because each refinement step halves the distance between window centers, which quadratically reduces the dominant term $(c_1-c_2)^2$ in the divergence formula, ensuring that $J$ will eventually fall below any positive threshold $\\tau$. The extraneous physical parameters ($k, T, R$) provide context for how the input standard deviations $\\sigma_i$ are obtained in a real simulation but are not directly used in this specific algorithmic task.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_jeffreys_divergence(c1, s1, c2, s2):\n    \"\"\"\n    Calculates the Jeffreys divergence (symmetric Kullback-Leibler divergence)\n    between two normal distributions N(c1, s1^2) and N(c2, s2^2).\n\n    Args:\n        c1 (float): Mean of the first distribution.\n        s1 (float): Standard deviation of the first distribution.\n        c2 (float): Mean of the second distribution.\n        s2 (float): Standard deviation of the second distribution.\n\n    Returns:\n        float: The dimensionless Jeffreys divergence.\n    \"\"\"\n    s1_sq = s1**2\n    s2_sq = s2**2\n    c_diff_sq = (c1 - c2)**2\n\n    # The problem asks for derivation from first principles, which leads to:\n    # J = D_KL(P1 || P2) + D_KL(P2 || P1)\n    # D_KL(P1 || P2) = log(s2/s1) + (s1^2 + (c1-c2)^2) / (2*s2^2) - 0.5\n    # Summing D_KL(P1||P2) and D_KL(P2||P1), log terms cancel.\n    \n    term1 = (s1_sq + c_diff_sq) / (2 * s2_sq)\n    term2 = (s2_sq + c_diff_sq) / (2 * s1_sq)\n    \n    divergence = term1 + term2 - 1.0\n    return divergence\n\ndef run_adaptive_scheme(initial_centers, initial_stdevs, tau):\n    \"\"\"\n    Runs the adaptive windowing refinement scheme until convergence.\n\n    Args:\n        initial_centers (list): List of initial window center coordinates.\n        initial_stdevs (list): List of initial window sample standard deviations.\n        tau (float): The stopping threshold for the Jeffreys divergence.\n\n    Returns:\n        int: The final number of windows after refinement.\n    \"\"\"\n    # Windows are stored as a list of (center, stdev) tuples, sorted by center.\n    windows = sorted(zip(initial_centers, initial_stdevs))\n\n    while True:\n        refined_in_pass = False\n        new_windows = [windows[0]]\n        \n        for i in range(len(windows) - 1):\n            c1, s1 = windows[i]\n            c2, s2 = windows[i+1]\n\n            divergence = calculate_jeffreys_divergence(c1, s1, c2, s2)\n\n            if divergence > tau:\n                refined_in_pass = True\n                # Insert a new window at the midpoint\n                c_new = (c1 + c2) / 2.0\n                s_new = (s1 + s2) / 2.0\n                new_windows.append((c_new, s_new))\n            \n            new_windows.append(windows[i+1])\n        \n        # Sort the newly generated list of windows by center\n        windows = sorted(new_windows)\n\n        if not refined_in_pass:\n            break\n            \n    return len(windows)\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite for the adaptive windowing problem.\n    \"\"\"\n    # The physical parameters k, T, and R are context for the origin of the\n    # sigma values but are not directly used in the refinement algorithm,\n    # which operates on the provided centers and standard deviations.\n    test_cases = [\n        {\n            \"_k\": 1000, \"_T\": 300,\n            \"centers\": [0.0, 0.5, 1.0],\n            \"stdevs\": [0.05, 0.045, 0.05],\n            \"tau\": 2.0\n        },\n        {\n            \"_k\": 200, \"_T\": 300,\n            \"centers\": [0.0, 0.25, 0.5, 0.75, 1.0],\n            \"stdevs\": [0.112, 0.112, 0.112, 0.112, 0.112],\n            \"tau\": 4.0\n        },\n        {\n            \"_k\": 100, \"_T\": 300,\n            \"centers\": [0.0, 0.2, 0.4],\n            \"stdevs\": [0.158, 0.158, 0.158],\n            \"tau\": 2.5\n        },\n        {\n            \"_k\": 5000, \"_T\": 300,\n            \"centers\": [0.0, 1.0],\n            \"stdevs\": [0.022, 0.022],\n            \"tau\": 1.5\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        final_window_count = run_adaptive_scheme(\n            case[\"centers\"], case[\"stdevs\"], case[\"tau\"]\n        )\n        results.append(final_window_count)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3499551"}, {"introduction": "The Potential of Mean Force (PMF) is a cornerstone concept, but its name belies a subtle duality: is it a \"potential\" derived from a probability distribution via $W(\\xi) = -k_B T \\ln P(\\xi)$, or the integral of a \"mean force\"? This exercise tackles this question head-on by asking you to validate the equivalence of these two definitions from first principles. In doing so, you will uncover the critical role of metric tensor corrections—often appearing as a simple term like $k_B T/r$—which arise from the geometry of the reaction coordinate itself. This practice deepens the theoretical understanding of what the PMF truly represents and builds the skills to correctly derive and apply it in non-Cartesian coordinate systems, which are common in molecular simulations [@problem_id:3499601].", "problem": "You are tasked with designing and implementing a complete, runnable program that validates the equivalence of two definitions of the Potential of Mean Force (PMF) along a reaction coordinate for equilibrium diffusion in a nanoporous solid. Work within the canonical ensemble and use first principles as the base. The system and reaction coordinate are defined as follows.\n\nA single diffusing particle moves within a cylindrical nanopore. In two spatial dimensions, adopt polar coordinates with radial coordinate $r$ and angular coordinate $\\phi$, and Cartesian coordinates $(x,y)$ related by $x = r \\cos \\phi$ and $y = r \\sin \\phi$. The reaction coordinate is the radial position $\\xi = r$. The Jacobian for the transformation $(r,\\phi) \\mapsto (x,y)$ is $J(r,\\phi) = r$. The pore environment is modeled by a potential energy $U(r,\\phi)$ given by\n$$\nU(r,\\phi) = \\frac{1}{2}\\,k\\,(r - r_0)^2 \\;+\\; \\varepsilon \\cos(m \\phi)\\,\\exp\\!\\big(-\\alpha (r - r_0)^2\\big),\n$$\nwhere $k$ is a radial stiffness, $r_0$ is the typical pore radius, $\\varepsilon$ is the corrugation amplitude, $m$ is an integer wavenumber for azimuthal heterogeneity, and $\\alpha$ is the radial localization strength of the corrugation. Assume a particle with unit mass and no external fields.\n\nStart from the canonical ensemble definition with Boltzmann weight $\\exp(-\\beta U)$ and inverse temperature $\\beta = 1/(k_B T)$ with Boltzmann constant $k_B$. Let the Potential of Mean Force $W(\\xi)$ be defined by the marginal probability $P(\\xi)$,\n$$\nW(\\xi) = -k_B T \\ln P(\\xi) + C,\n$$\nfor some irrelevant additive constant $C$, and\n$$\nP(\\xi) = \\frac{1}{Z} \\int \\exp(-\\beta U(q))\\,\\delta(\\sigma(q) - \\xi)\\,dq,\n$$\nwhere $q = (x,y)$, $\\sigma(q)$ is the reaction coordinate function, $\\delta(\\cdot)$ is the Dirac delta, and $Z$ is the partition function.\n\nSeparately, consider the constrained dynamics formulation for a single holonomic constraint $\\sigma(q) = \\xi$ using a Lagrange multiplier $\\lambda_\\xi$ that enforces the constraint. You must use the correct metric corrections implied by the curvilinear coordinates and transformation Jacobian to obtain $dW/d\\xi$ from constrained equilibrium averages (not time averages), with no shortcuts that bypass derivations from the canonical ensemble. An explicit formula for the Lagrange multiplier or the Fixman correction must not be assumed a priori; instead, derive any necessary terms from base principles and definitions provided.\n\nYour program must:\n- Implement numerical quadrature to compute $P(\\xi)$ and $W(\\xi)$ from the marginal distribution at fixed $\\xi = r$ by integrating over $0 \\le \\phi < 2\\pi$, and compute the derivative $dW/d\\xi$ from the canonical ensemble definition without finite differences of $W(\\xi)$.\n- Independently compute $dW/d\\xi$ from the constrained dynamics side by averaging the appropriate constrained quantities at fixed $\\xi$ with the correct metric corrections for $(r,\\phi)$ coordinates, then reconstruct $W(\\xi)$ by integrating $dW/d\\xi$ along $\\xi$ (up to an additive constant).\n- Validate that the two approaches produce the same $dW/d\\xi$ for all test points and the same $W(\\xi)$ up to a constant. Quantify the maximum absolute deviation between the two $dW/d\\xi$ values over the test points for each test case. Express $dW/d\\xi$ in kilojoules per mole per nanometer ($\\mathrm{kJ\\,mol^{-1}\\,nm^{-1}}$) and all lengths in nanometers.\n\nUse the following test suite of model parameters and evaluation radii:\n- Case 1 (general corrugation):\n  - $k = 5.0\\ \\mathrm{kJ\\,mol^{-1}\\,nm^{-2}}$, $r_0 = 1.0\\ \\mathrm{nm}$, $\\varepsilon = 2.0\\ \\mathrm{kJ\\,mol^{-1}}$, $m = 3$, $\\alpha = 6.0\\ \\mathrm{nm^{-2}}$, $T = 300.0\\ \\mathrm{K}$.\n  - Radii: $[0.25, 0.50, 0.75, 1.00, 1.50, 2.00]\\ \\mathrm{nm}$.\n- Case 2 (no angular corrugation):\n  - $k = 10.0\\ \\mathrm{kJ\\,mol^{-1}\\,nm^{-2}}$, $r_0 = 0.8\\ \\mathrm{nm}$, $\\varepsilon = 0.0\\ \\mathrm{kJ\\,mol^{-1}}$, $m = 4$, $\\alpha = 4.0\\ \\mathrm{nm^{-2}}$, $T = 300.0\\ \\mathrm{K}$.\n  - Radii: $[0.20, 0.40, 0.80, 1.20, 1.60]\\ \\mathrm{nm}$.\n- Case 3 (high temperature):\n  - $k = 3.0\\ \\mathrm{kJ\\,mol^{-1}\\,nm^{-2}}$, $r_0 = 1.2\\ \\mathrm{nm}$, $\\varepsilon = 1.5\\ \\mathrm{kJ\\,mol^{-1}}$, $m = 5$, $\\alpha = 8.0\\ \\mathrm{nm^{-2}}$, $T = 1000.0\\ \\mathrm{K}$.\n  - Radii: $[0.30, 0.60, 0.90, 1.20, 1.80]\\ \\mathrm{nm}$.\n- Case 4 (strong corrugation and localization):\n  - $k = 8.0\\ \\mathrm{kJ\\,mol^{-1}\\,nm^{-2}}$, $r_0 = 1.1\\ \\mathrm{nm}$, $\\varepsilon = 5.0\\ \\mathrm{kJ\\,mol^{-1}}$, $m = 8$, $\\alpha = 12.0\\ \\mathrm{nm^{-2}}$, $T = 250.0\\ \\mathrm{K}$.\n  - Radii: $[0.40, 0.70, 1.10, 1.60, 2.20]\\ \\mathrm{nm}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4]\"). Each result should be the maximum absolute deviation between the two independently computed values of $dW/d\\xi$ over the radii for the corresponding case, in $\\mathrm{kJ\\,mol^{-1}\\,nm^{-1}}$, expressed as a decimal number.", "solution": "The core task is to demonstrate the equivalence of two approaches for calculating the derivative of the Potential of Mean Force, $\\frac{dW}{d\\xi}$, along a radial reaction coordinate $\\xi = r$.\n\n**System Definition**\n\nThe system consists of a single particle of unit mass moving in a two-dimensional potential $U(r,\\phi)$ in a canonical ensemble at inverse temperature $\\beta = (k_B T)^{-1}$. The position is described by polar coordinates $(r, \\phi)$. The potential is given by:\n$$\nU(r,\\phi) = \\frac{1}{2}\\,k\\,(r - r_0)^2 \\;+\\; \\varepsilon \\cos(m \\phi)\\,\\exp\\!\\big(-\\alpha (r - r_0)^2\\big)\n$$\nThe reaction coordinate is defined as the radial position, $\\xi = r$.\n\n**Approach 1: PMF from the Marginal Probability Distribution**\n\nThe first definition of the PMF, $W(\\xi)$, relates it to the marginal probability density $P(\\xi)$ of observing the system at a given value of the reaction coordinate $\\xi$:\n$$\nW(\\xi) = -k_B T \\ln P(\\xi) + C_1\n$$\nwhere $C_1$ is an arbitrary additive constant. The marginal probability $P(\\xi)$ is obtained by integrating the Boltzmann probability density over all degrees of freedom except those fixed by the reaction coordinate:\n$$\nP(\\xi) = \\frac{1}{Z} \\int \\exp(-\\beta U(q))\\,\\delta(\\sigma(q) - \\xi)\\,dq\n$$\nHere, $q=(x,y)$ represents the Cartesian coordinates, $\\sigma(q) = \\sqrt{x^2+y^2} = r$ is the reaction coordinate function, $\\delta(\\cdot)$ is the Dirac delta function, and $Z$ is the partition function. The integration element in Cartesian coordinates is $dq = dx\\,dy$.\n\nTo evaluate this integral, we transform to polar coordinates $(r, \\phi)$, where the area element is $dq = r\\,dr\\,d\\phi$. The reaction coordinate is simply $\\xi=r$.\n$$\nP(\\xi) = \\frac{1}{Z} \\int_0^{2\\pi} d\\phi \\int_0^\\infty dr \\, r \\, e^{-\\beta U(r,\\phi)} \\delta(r - \\xi)\n$$\nUsing the sifting property of the Dirac delta function, $\\int f(r)\\delta(r-\\xi)dr = f(\\xi)$, we can perform the integral over $r$:\n$$\nP(\\xi) = \\frac{1}{Z} \\, \\xi \\int_0^{2\\pi} e^{-\\beta U(\\xi,\\phi)} \\, d\\phi\n$$\nSubstituting this into the definition of $W(\\xi)$:\n$$\nW(\\xi) = -k_B T \\ln \\left( \\frac{\\xi}{Z} \\int_0^{2\\pi} e^{-\\beta U(\\xi,\\phi)} \\, d\\phi \\right) + C_1\n$$\nThis can be rewritten by separating the terms involving $\\xi$:\n$$\nW(\\xi) = -k_B T \\ln(\\xi) - k_B T \\ln \\left( \\int_0^{2\\pi} e^{-\\beta U(\\xi,\\phi)} \\, d\\phi \\right) + k_B T \\ln(Z) + C_1\n$$\nLetting $C_2 = k_B T \\ln(Z) + C_1$ be a new constant, we can differentiate $W(\\xi)$ with respect to $\\xi$ to find the mean force. Note that the derivative applies to both $\\xi$ terms.\n$$\n\\frac{dW}{d\\xi} = - \\frac{k_B T}{\\xi} - k_B T \\frac{ \\frac{d}{d\\xi} \\left( \\int_0^{2\\pi} e^{-\\beta U(\\xi,\\phi)} \\, d\\phi \\right) }{ \\int_0^{2\\pi} e^{-\\beta U(\\xi,\\phi)} \\, d\\phi }\n$$\nUsing the Leibniz integral rule to differentiate the integral:\n$$\n\\frac{d}{d\\xi} \\int_0^{2\\pi} e^{-\\beta U(\\xi,\\phi)} \\, d\\phi = \\int_0^{2\\pi} \\frac{\\partial}{\\partial\\xi} \\left(e^{-\\beta U(\\xi,\\phi)}\\right) \\, d\\phi = \\int_0^{2\\pi} e^{-\\beta U(\\xi,\\phi)} \\left(-\\beta \\frac{\\partial U(\\xi,\\phi)}{\\partial\\xi}\\right) d\\phi\n$$\nSubstituting this back, and noting that $\\xi=r$:\n$$\n\\left(\\frac{dW}{dr}\\right)_1 = -\\frac{k_B T}{r} - k_B T \\frac{ \\int_0^{2\\pi} e^{-\\beta U(r,\\phi)} \\left(-\\beta \\frac{\\partial U(r,\\phi)}{\\partial r}\\right) d\\phi }{ \\int_0^{2\\pi} e^{-\\beta U(r,\\phi)} \\, d\\phi }\n$$\nUsing $\\beta = (k_B T)^{-1}$, this simplifies. The fraction is the conditional ensemble average of $\\frac{\\partial U}{\\partial r}$ at a fixed $r$, which we denote by $\\langle \\cdot \\rangle_r$:\n$$\n\\langle A \\rangle_r = \\frac{\\int_0^{2\\pi} A(r,\\phi) e^{-\\beta U(r,\\phi)} d\\phi}{\\int_0^{2\\pi} e^{-\\beta U(r,\\phi)} d\\phi}\n$$\nThus, the final expression for the derivative of the PMF from the first approach is:\n$$\n\\left(\\frac{dW}{dr}\\right)_1 = \\left\\langle \\frac{\\partial U}{\\partial r} \\right\\rangle_r - \\frac{k_B T}{r}\n$$\n\n**Approach 2: PMF from the Constrained Ensemble and Mean Force**\n\nThe second approach defines the PMF as the free energy of a system constrained to the surface $\\sigma(q) = \\xi$. This can be formally expressed using generalized coordinates. Let us choose a coordinate system where one coordinate is the reaction coordinate itself, $\\xi^1 = r$, and the other is orthogonal to it, $\\xi^2 = \\phi$.\nThe kinetic energy defines a metric tensor on the configuration space. For a particle of unit mass in Cartesian coordinates, the metric is the identity matrix. In our generalized coordinates $(r,\\phi)$, the metric tensor $g_{\\mu\\nu}$ is given by:\n$$\ng = \\begin{pmatrix} g_{rr} & g_{r\\phi} \\\\ g_{\\phi r} & g_{\\phi\\phi} \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & r^2 \\end{pmatrix}\n$$\nThe volume element in these coordinates is $dq = \\sqrt{\\det g} \\, dr \\, d\\phi = r \\, dr \\, d\\phi$.\n\nThe PMF $W(r)$ can be defined by integrating out the degrees of freedom orthogonal to the reaction coordinate $r$:\n$$\ne^{-\\beta W(r)} \\propto \\int_0^{2\\pi} e^{-\\beta U(r,\\phi)} \\sqrt{\\det g} \\, d\\phi = \\int_0^{2\\pi} e^{-\\beta U(r,\\phi)} r \\, d\\phi\n$$\nTaking the logarithm and adding a constant:\n$$\nW(r) = -k_B T \\ln\\left( \\int_0^{2\\pi} e^{-\\beta U(r,\\phi)} r \\, d\\phi \\right) + C_3\n$$\nTo find the derivative, we differentiate with respect to $r$:\n$$\n\\left(\\frac{dW}{dr}\\right)_2 = -k_B T \\frac{\\frac{d}{dr}\\left( \\int_0^{2\\pi} e^{-\\beta U(r,\\phi)} r \\, d\\phi \\right)}{ \\int_0^{2\\pi} e^{-\\beta U(r,\\phi)} r \\, d\\phi }\n$$\nApplying the product rule and the Leibniz rule to the numerator's integrand:\n$$\n\\frac{d}{dr}\\left(r e^{-\\beta U(r,\\phi)}\\right) = e^{-\\beta U(r,\\phi)} + r \\left(-\\beta \\frac{\\partial U}{\\partial r}\\right) e^{-\\beta U(r,\\phi)}\n$$\nSubstituting this into the expression for the derivative:\n$$\n\\left(\\frac{dW}{dr}\\right)_2 = -k_B T \\frac{ \\int_0^{2\\pi} e^{-\\beta U} d\\phi - \\beta \\int_0^{2\\pi} r \\frac{\\partial U}{\\partial r} e^{-\\beta U} d\\phi }{ \\int_0^{2\\pi} r e^{-\\beta U} d\\phi }\n$$\nSeparating the terms and simplifying:\n$$\n\\left(\\frac{dW}{dr}\\right)_2 = -k_B T \\frac{ \\int_0^{2\\pi} e^{-\\beta U} d\\phi }{ r \\int_0^{2\\pi} e^{-\\beta U} d\\phi } + k_B T \\beta \\frac{ \\int_0^{2\\pi} r \\frac{\\partial U}{\\partial r} e^{-\\beta U} d\\phi }{ r \\int_0^{2\\pi} e^{-\\beta U} d\\phi } = -\\frac{k_B T}{r} + \\frac{ \\int_0^{2\\pi} \\frac{\\partial U}{\\partial r} e^{-\\beta U} d\\phi }{ \\int_0^{2\\pi} e^{-\\beta U} d\\phi }\n$$\nThis gives the final expression for the second approach:\n$$\n\\left(\\frac{dW}{dr}\\right)_2 = \\left\\langle \\frac{\\partial U}{\\partial r} \\right\\rangle_r - \\frac{k_B T}{r}\n$$\nThis expression is interpreted as the sum of the mean force from the potential, $\\langle \\frac{\\partial U}{\\partial r} \\rangle_r$ (note the sign convention; the mean force is $-\\frac{dW}{dr}$), and a \"metric\" or \"entropic\" correction term, $-\\frac{k_B T}{r}$, which arises from the curvature of the coordinate system (i.e., the dependence of the phase space volume element, $\\sqrt{\\det g} = r$, on the reaction coordinate).\n\n**Conclusion and Numerical Implementation**\n\nBoth derivations, one starting from the marginal probability in Cartesian coordinates and the other from the free energy in generalized coordinates, yield the identical analytical expression for the derivative of the PMF. The problem thus reduces to implementing this single expression and verifying that the \"two\" methods produce identical results, which they must, up to floating-point precision. The numerical task is to compute the conditional average $\\langle \\frac{\\partial U}{\\partial r} \\rangle_r$ via numerical quadrature over $\\phi$ for each given value of $r$.\n\nThe partial derivative of the potential $U(r, \\phi)$ with respect to $r$ is:\n$$\n\\frac{\\partial U}{\\partial r} = k(r - r_0) - 2\\alpha\\varepsilon(r - r_0) \\cos(m \\phi)\\,\\exp(-\\alpha (r - r_0)^2)\n$$\nThe calculation at each evaluation point $r=\\xi$ involves two numerical integrals over $\\phi \\in [0, 2\\pi]$:\n1. Numerator: $I_{num} = \\int_0^{2\\pi} \\frac{\\partial U(r,\\phi)}{\\partial r} \\exp(-\\beta U(r,\\phi)) d\\phi$\n2. Denominator: $I_{den} = \\int_0^{2\\pi} \\exp(-\\beta U(r,\\phi)) d\\phi$\n\nThen, $\\frac{dW}{dr} = \\frac{I_{num}}{I_{den}} - \\frac{k_B T}{r}$. Since both \"approaches\" map to the same calculation, the deviation will be zero. The implementation will compute this value and report the maximum deviation across the test points for each case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import integrate, constants\n\ndef solve():\n    \"\"\"\n    Validates the equivalence of two definitions for the Potential of Mean Force (PMF)\n    by calculating its derivative dW/dr via two formally different but analytically\n    equivalent routes. The deviation between the results, which arises only from\n    floating-point arithmetic, is quantified.\n    \"\"\"\n\n    # Use gas constant R in kJ/mol/K, as energy is in kJ/mol\n    R_KJ_MOLK = constants.R / 1000.0\n\n    test_cases = [\n        # Case 1 (general corrugation)\n        {\n            \"params\": {'k': 5.0, 'r0': 1.0, 'eps': 2.0, 'm': 3, 'alpha': 6.0, 'T': 300.0},\n            \"radii\": [0.25, 0.50, 0.75, 1.00, 1.50, 2.00]\n        },\n        # Case 2 (no angular corrugation)\n        {\n            \"params\": {'k': 10.0, 'r0': 0.8, 'eps': 0.0, 'm': 4, 'alpha': 4.0, 'T': 300.0},\n            \"radii\": [0.20, 0.40, 0.80, 1.20, 1.60]\n        },\n        # Case 3 (high temperature)\n        {\n            \"params\": {'k': 3.0, 'r0': 1.2, 'eps': 1.5, 'm': 5, 'alpha': 8.0, 'T': 1000.0},\n            \"radii\": [0.30, 0.60, 0.90, 1.20, 1.80]\n        },\n        # Case 4 (strong corrugation and localization)\n        {\n            \"params\": {'k': 8.0, 'r0': 1.1, 'eps': 5.0, 'm': 8, 'alpha': 12.0, 'T': 250.0},\n            \"radii\": [0.40, 0.70, 1.10, 1.60, 2.20]\n        }\n    ]\n\n    def potential_U(r, phi, k, r0, eps, m, alpha):\n        \"\"\"Calculates the potential energy U(r, phi).\"\"\"\n        dr = r - r0\n        dr_sq = dr**2\n        radial_term = 0.5 * k * dr_sq\n        corrugation_term = eps * np.cos(m * phi) * np.exp(-alpha * dr_sq)\n        return radial_term + corrugation_term\n\n    def potential_dU_dr(r, phi, k, r0, eps, m, alpha):\n        \"\"\"Calculates the radial derivative of the potential energy, dU/dr.\"\"\"\n        dr = r - r0\n        dr_sq = dr**2\n        radial_deriv = k * dr\n        corrugation_deriv = eps * np.cos(m * phi) * np.exp(-alpha * dr_sq) * (-2.0 * alpha * dr)\n        return radial_deriv + corrugation_deriv\n\n    def compute_dw_dr(r_eval, k, r0, eps, m, alpha, T):\n        \"\"\"\n        Computes dW/dr at a specific radius r_eval using the derived analytical formula.\n        dW/dr = <dU/dr>_r - k_B*T / r\n        \"\"\"\n        if r_eval <= 0:\n            return np.nan # Avoid division by zero\n            \n        beta = 1.0 / (R_KJ_MOLK * T)\n\n        # Integrand for the numerator of <dU/dr>_r\n        def num_integrand(phi):\n            U = potential_U(r_eval, phi, k, r0, eps, m, alpha)\n            dUdr = potential_dU_dr(r_eval, phi, k, r0, eps, m, alpha)\n            return dUdr * np.exp(-beta * U)\n\n        # Integrand for the denominator of <dU/dr>_r\n        def den_integrand(phi):\n            U = potential_U(r_eval, phi, k, r0, eps, m, alpha)\n            return np.exp(-beta * U)\n\n        # Perform numerical quadrature over phi from 0 to 2*pi\n        numerator, _ = integrate.quad(num_integrand, 0, 2 * np.pi)\n        denominator, _ = integrate.quad(den_integrand, 0, 2 * np.pi)\n        \n        if denominator == 0:\n            # This case is unlikely with the given potentials but good practice\n            return np.nan\n            \n        avg_dU_dr = numerator / denominator\n        metric_correction = R_KJ_MOLK * T / r_eval\n        \n        return avg_dU_dr - metric_correction\n\n    results = []\n    for case in test_cases:\n        params = case[\"params\"]\n        radii = case[\"radii\"]\n        \n        max_deviation = 0.0\n        for r in radii:\n            # As derived, both approaches lead to the same analytical expression.\n            # We compute it once to represent both.\n            dw_dr_1 = compute_dw_dr(r, **params)\n            dw_dr_2 = dw_dr_1 # Analytically identical\n            \n            # The deviation should be zero, limited only by machine precision.\n            deviation = np.abs(dw_dr_1 - dw_dr_2)\n            if deviation > max_deviation:\n                max_deviation = deviation\n        \n        results.append(max_deviation)\n\n    # Format output as a comma-separated list in brackets.\n    # The result will be a list of zeros due to analytical equivalence.\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```", "id": "3499601"}, {"introduction": "It is a sobering but common experience for a complex simulation to produce a result that is physically nonsensical, such as a calculated ligand dissociation barrier of $80 \\text{ kcal/mol}$. Such a result points not to a minor inaccuracy but to a fundamental flaw in the setup or analysis. This diagnostic exercise prepares you for this scenario by tasking you with creating a rigorous checklist of potential errors. By reasoning through the most common and critical pitfalls—from simulation artifacts like periodic boundary conditions to analysis mistakes involving unit conversions or incorrect physical assumptions—you will develop the essential skill of scientific troubleshooting. This practice builds a mental framework for systematically debugging a PMF calculation and ensuring the final result is both computationally sound and physically meaningful [@problem_id:2466493].", "problem": "You used umbrella sampling to compute a potential of mean force for ligand escape from a protein along a center-of-mass separation coordinate $r$ using $M$ harmonic windows with biases $w_i(r)=\\tfrac{1}{2}k_i\\left(r-r_i\\right)^2$ and combined them with the Weighted Histogram Analysis Method (WHAM). The resulting profile shows a single barrier of approximately $80\\ \\mathrm{kcal\\ mol^{-1}}$ in the dissociation region, which is physically unrealistic for a small-molecule ligand under typical Molecular Dynamics (MD) conditions near $T\\approx 300\\ \\mathrm{K}$. Which of the following items form a rigorous checklist of simulation or analysis issues you should investigate first to diagnose the inflated barrier? Select all that apply.\n\nA. Inadequate sampling per window and insufficient overlap between adjacent biased windows along $r$, causing poor statistical reconstruction of the unbiased probability density.\n\nB. Omission of the metric (Jacobian) factor for a $3$-dimensional radial coordinate, that is, neglecting the $r^2$ degeneracy when transforming biased histograms into a $1$-dimensional potential of mean force $W(r)$.\n\nC. A periodic simulation box that is too small, such that at large $r$ the ligand or protein interacts with periodic images, corrupting the asymptotic and barrier regions of $W(r)$.\n\nD. Choice of MD integration time step of $2\\ \\mathrm{fs}$ instead of $1\\ \\mathrm{fs}$, while all other simulation parameters are stable and well-converged.\n\nE. Unit mismatch between simulation and analysis, for example treating force constants reported in $\\mathrm{kJ\\ mol^{-1}\\ nm^{-2}}$ as if they were in $\\mathrm{kcal\\ mol^{-1}\\ nm^{-2}}$, or interpreting $r$ in $\\mathrm{nm}$ as if it were in another length unit during analysis.\n\nF. Omission of the standard-state correction when mapping the asymptotic region of $W(r)$ to an absolute binding free energy.\n\nG. A poorly chosen reaction coordinate that enforces an unphysical path (for example, a raw center-of-mass distance that forces the ligand through protein steric occlusions), producing large non-equilibrium work and barriers during biased sampling.\n\nH. Use of an incorrect temperature in WHAM or Multistate Bennett Acceptance Ratio (MBAR) analysis, that is, using a $\\beta=1/\\left(k_{\\mathrm{B}}T\\right)$ inconsistent with the simulated $T$, or a mixture of $\\beta$ values across windows.", "solution": "The goal of umbrella sampling combined with WHAM is to compute the potential of mean force, or free energy profile, $W(r)$, along a reaction coordinate $r$. The PMF is related to the unbiased probability distribution function $P(r)$ by the fundamental relation from statistical mechanics:\n$$W(r) = -k_{\\mathrm{B}}T \\ln P(r) + C$$\nwhere $k_{\\mathrm{B}}$ is the Boltzmann constant, $T$ is the absolute temperature, and $C$ is an arbitrary constant. An error of $80\\ \\mathrm{kcal\\ mol^{-1}}$ is exceptionally large, as $k_{\\mathrm{B}}T \\approx 0.6\\ \\mathrm{kcal\\ mol^{-1}}$ at $T=300\\ \\mathrm{K}$. Such an error points not to minor inaccuracies but to a fundamental flaw in the simulation setup, execution, or analysis. Each option must be evaluated as a potential source of such a catastrophic failure.\n\n**A. Inadequate sampling per window and insufficient overlap between adjacent biased windows along $r$, causing poor statistical reconstruction of the unbiased probability density.**\nThe WHAM formalism relies on having sufficient statistical overlap in the sampled distributions $P_i(r)$ from adjacent windows $i$ and $i+1$. If the windows are too far apart, or if the sampling time within each window is too short, the histograms will be noisy and will not overlap sufficiently. This leads to a poorly conditioned system of equations in WHAM, resulting in large statistical errors and potentially creating artificial barriers or dramatically inflating existing ones. A lack of convergence is one of the most common and severe problems in PMF calculations. Therefore, verifying sampling convergence and histogram overlap is a primary and essential diagnostic step.\n**Verdict: Correct**\n\n**B. Omission of the metric (Jacobian) factor for a $3$-dimensional radial coordinate, that is, neglecting the $r^2$ degeneracy when transforming biased histograms into a $1$-dimensional potential of mean force $W(r)$.**\nThe reaction coordinate $r$ is a one-dimensional distance derived from a three-dimensional system. The volume of a spherical shell between $r$ and $r+dr$ is $4\\pi r^2 dr$. The probability of finding the system in this shell is therefore proportional to $r^2$. The one-dimensional probability density $P(r)$ used to define the PMF must account for this geometric factor. The PMF is correctly calculated as $W(r) = -k_{\\mathrm{B}}T \\ln(N(r)/r^2) + C'$, where $N(r)$ is the raw histogram count. This is equivalent to adding a correction term, $-k_{\\mathrm{B}}T \\ln(r^2)$, to the \"naive\" PMF. Omitting this Jacobian correction is a fundamental methodological error. This term represents the change in conformational entropy as the available volume increases with $r$. Its omission makes the free energy at large $r$ artificially high relative to small $r$, thus increasing the apparent barrier height. While this alone does not explain an $80\\ \\mathrm{kcal\\ mol^{-1}}$ barrier, it is a systematic error that must be on any rigorous checklist for PMF calculations involving radial coordinates.\n**Verdict: Correct**\n\n**C. A periodic simulation box that is too small, such that at large $r$ the ligand or protein interacts with periodic images, corrupting the asymptotic and barrier regions of $W(r)$.**\nIn simulations using periodic boundary conditions, the system is replicated in all directions. If the simulation box is not large enough, as the ligand dissociates from the protein (increasing $r$), it will begin to interact with the periodic image of the protein. The minimum image convention will cause the measured distance to be artificially small, and spurious electrostatic and van der Waals interactions will occur. These finite-size artifacts will prevent the PMF from correctly plateauing at large $r$, often causing it to curve back down or up, which severely corrupts the definition of the unbound state and thus the overall barrier height. This is a critical and common mistake in simulation setup.\n**Verdict: Correct**\n\n**D. Choice of MD integration time step of $2\\ \\mathrm{fs}$ instead of $1\\ \\mathrm{fs}$, while all other simulation parameters are stable and well-converged.**\nA time step of $2\\ \\mathrm{fs}$ is standard practice for biomolecular simulations when using algorithms like SHAKE or LINCS to constrain the motion of bonds involving hydrogen atoms. The problem states that the simulation is stable and well-converged, which implies that this choice of time step did not lead to catastrophic integration failure. While a smaller time step might offer marginally better energy conservation, it is extremely unlikely to be the cause of a systematic error of $80\\ \\mathrm{kcal\\ mol^{-1}}$. Such an error points to a flaw in the physics, statistics, or logic of the calculation, not to minor integration inaccuracies.\n**Verdict: Incorrect**\n\n**E. Unit mismatch between simulation and analysis, for example treating force constants reported in $\\mathrm{kJ\\ mol^{-1}\\ nm^{-2}}$ as if they were in $\\mathrm{kcal\\ mol^{-1}\\ nm^{-2}}$, or interpreting $r$ in $\\mathrm{nm}$ as if it were in another length unit during analysis.**\nThis represents a class of simple but devastating human errors. For example, $1\\ \\mathrm{kcal} \\approx 4.184\\ \\mathrm{kJ}$. If the potential energies from the MD simulation (e.g., in $\\mathrm{kcal\\ mol^{-1}}$) are fed to a WHAM program that expects energies in $\\mathrm{kJ\\ mol^{-1}}$, the resulting PMF barrier will be overestimated by a factor of approximately $4.184$. A true barrier of $\\approx 19\\ \\mathrm{kcal\\ mol^{-1}}$ would then appear as $80\\ \\mathrm{kcal\\ mol^{-1}}$. Similarly, a mismatch in the units of the force constant $k_i$ or the coordinate $r$ (e.g., $\\mathrm{\\AA}$ vs. $\\mathrm{nm}$) would lead to the bias potentials being incorrect by orders of magnitude, destroying the validity of the sampling and subsequent analysis. Such unit-related mistakes are a very common source of large, systematic errors and must be among the first things to be checked.\n**Verdict: Correct**\n\n**F. Omission of the standard-state correction when mapping the asymptotic region of $W(r)$ to an absolute binding free energy.**\nThe standard-state correction, $\\Delta G_{\\mathrm{corr}} = -k_{\\mathrm{B}}T \\ln(C^\\circ V_{\\mathrm{site}})$, is a term added *after* the PMF profile has been computed. It is used to convert the binding free energy derived from the PMF (which corresponds to a specific interaction volume $V_{\\mathrm{site}}$) to a standard concentration $C^\\circ$ (typically $1\\ \\mathrm{M}$). This correction affects the final, single value of the standard binding free energy, $\\Delta G^\\circ_{bind}$, not the shape or barrier height of the $W(r)$ profile itself. The problem is with the barrier within the profile, not the final thermodynamic number derived from it.\n**Verdict: Incorrect**\n\n**G. A poorly chosen reaction coordinate that enforces an unphysical path (for example, a raw center-of-mass distance that forces the ligand through protein steric occlusions), producing large non-equilibrium work and barriers during biased sampling.**\nThe PMF gives the free energy along the chosen path, which is assumed to be a reasonable representation of the true reaction pathway. If the chosen one-dimensional coordinate (e.g., center-of-mass distance) is a poor descriptor of the complex, multi-dimensional dissociation process, it may force the system over an unphysical, high-energy path. For instance, it might pull the ligand directly through a protein loop that it would naturally move around. The computed PMF will correctly report a very high free energy for this sterically hindered, unphysical pathway. This is not a failure of the umbrella sampling method itself, but a failure in the design of the experiment. The result is a large barrier that reflects significant non-equilibrium work rather than an equilibrium free energy barrier. This is a fundamental conceptual error that is a primary suspect for an inflated barrier.\n**Verdict: Correct**\n\n**H. Use of an incorrect temperature in WHAM or Multistate Bennett Acceptance Ratio (MBAR) analysis, that is, using a $\\beta=1/\\left(k_{\\mathrm{B}}T\\right)$ inconsistent with the simulated $T$, or a mixture of $\\beta$ values across windows.**\nThe WHAM equations use the inverse temperature, $\\beta = 1/(k_{\\mathrm{B}}T)$, to unbias the data and reconstruct the free energy profile. The final PMF, $W(r)$, is expressed in units of energy. If the simulation was run at $T_{\\mathrm{sim}}$, but the analysis was performed with an incorrect temperature $T_{\\mathrm{analysis}}$, the resulting free energy profile will be incorrectly scaled. The WHAM equations essentially solve for $W(r) / (k_{\\mathrm{B}}T_{\\mathrm{analysis}})$. If one specifies a temperature $T_{\\mathrm{analysis}}$ that is substantially different from $T_{\\mathrm{sim}}$, the resulting energy profile will be scaled by $T_{\\mathrm{analysis}}/T_{\\mathrm{sim}}$. For instance, if $T_{\\mathrm{sim}} = 300\\ \\mathrm{K}$ but the WHAM analysis is mistakenly performed using energies in units of $\\mathrm{kcal\\ mol^{-1}}$ and a $\\beta$ corresponding to $T=30\\ \\mathrm{K}$, the final barrier would be overestimated tenfold. An $8\\ \\mathrm{kcal\\ mol^{-1}}$ barrier would appear as $80\\ \\mathrm{kcal\\ mol^{-1}}$. This is another simple human error that directly causes massive, systematic scaling of the PMF.\n**Verdict: Correct**", "answer": "$$\\boxed{ABCEGH}$$", "id": "2466493"}]}