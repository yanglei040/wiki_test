{"hands_on_practices": [{"introduction": "A core task in any electronic structure simulation is to find the chemical potential $\\mu$ that satisfies the system's electron-counting rule at a given temperature $T$. This is achieved by solving the fundamental equation $N_e = \\int N(E) f(E, \\mu, T) dE$, where the integral is approximated by a discrete sum over $k$-points. This practice provides hands-on experience implementing a robust numerical root-finder to solve for $\\mu$ in a tight-binding model, illuminating a critical procedure used in all major simulation packages and highlighting the sensitivity of the result to $k$-point sampling. [@problem_id:3443117]", "problem": "Implement a finite-temperature chemical potential solver that adjusts the chemical potential $\\,\\mu\\,$ to satisfy the electron number constraint\n$$\nN_e(\\mu,T) \\;=\\; \\int_{-\\infty}^{+\\infty} N(E)\\, f(E,\\mu,T)\\, dE \\,,\n$$\nwhere $\\,N(E)\\,$ is the electronic density of states and $\\,f(E,\\mu,T)\\,$ is the Fermi–Dirac distribution. Your implementation must be grounded in a tight-binding model and use discrete $\\,k$-point sampling to approximate the integral in a computationally realistic manner.\n\nUse the following physically realistic and self-consistent setup, which is standard in computational materials science electronic-structure workflows:\n- One-dimensional monatomic chain with one $\\,s\\,$-like orbital per unit cell and nearest-neighbor hopping parameter $\\,t = 1.0\\,\\mathrm{eV}\\,$, lattice constant $\\,a = 1.0\\,\\mathrm{\\AA}\\,$, and spin degeneracy $\\,g_s = 2$.\n- The single-band tight-binding dispersion is\n$$\nE(k) \\;=\\; -2t \\cos(ka)\\,,\n$$\nwith the Brillouin zone $k \\in [-\\pi/a,\\pi/a)$. This produces a single band with energy range $E \\in [-2t,2t]$.\n- The Fermi–Dirac distribution at finite temperature $\\,T\\,$ is\n$$\nf(E,\\mu,T) \\;=\\; \\frac{1}{1 + \\exp\\!\\big( \\frac{E-\\mu}{k_B T} \\big)}\\,,\n$$\nwhere $\\,k_B\\,$ is the Boltzmann constant in electronvolts per kelvin.\n- The discrete $\\,k$-point approximation to the electron number per unit cell is\n$$\nN_e(\\mu,T;N_k) \\;=\\; \\frac{g_s}{N_k}\\,\\sum_{j=1}^{N_k} f\\!\\big(E(k_j),\\mu,T\\big)\\,,\n$$\nwhere $\\,\\{k_j\\}\\,$ are $\\,N_k\\,$ uniformly spaced $\\,k$ points over the Brillouin zone. This replaces the continuum density-of-states integral by a Riemann sum over sampled band energies, consistent with modern density functional theory (DFT) implementations.\n\nYour task:\n1. Implement a robust, monotonic root-finding procedure for $\\,\\mu\\,$ at given $\\,T\\,$ and target electron number $\\,N_e^{\\mathrm{target}}\\,$ that solves\n$$\nF(\\mu) \\;=\\; N_e(\\mu,T;N_k) - N_e^{\\mathrm{target}} \\;=\\; 0\\,.\n$$\nUse the fact that $\\,F(\\mu)\\,$ is strictly increasing in $\\,\\mu\\,$ at finite $\\,T\\,$ to design a bracketed solver. Your method must be numerically stable for temperatures as low as $\\,10\\,\\mathrm{K}\\,$ and as high as $\\,1500\\,\\mathrm{K}\\,$ and must handle occupancies near band edges. The Boltzmann constant must be $\\,k_B = 8.617333262\\times 10^{-5}\\,\\mathrm{eV/K}\\,$.\n2. Analyze convergence with respect to $\\,k$-point sampling by comparing each computed chemical potential to a high-resolution reference computed for the same temperature and target electron number using a dense grid $\\,N_k^{\\mathrm{ref}}\\,$. In all calculations, express energies (including $\\,\\mu\\,$) in $\\mathrm{eV}$ and temperatures in $\\mathrm{K}$. Your program must internally compute the dense-grid reference with $\\,N_k^{\\mathrm{ref}} = 20001\\,$ for the same model.\n\nInput specification:\n- There is no external input. You must hard-code the model and the test suite below.\n\nTest suite:\nCompute, for each case, the converged chemical potential $\\,\\mu\\,$ (in $\\,\\mathrm{eV}\\,$) using the specified $\\,N_k\\,$, temperature $\\,T\\,$, and target electron number $\\,N_e^{\\mathrm{target}}\\,$, and also compute the absolute deviation from the dense-grid reference $\\,\\mu_{\\mathrm{ref}}\\,$ (in $\\,\\mathrm{eV}\\,$):\n- Case $\\,1\\,$ (general, symmetric band, half-filling): $\\,N_k = 31\\,$, $\\,T = 300\\,\\mathrm{K}\\,$, $\\,N_e^{\\mathrm{target}} = 1.0\\,$.\n- Case $\\,2\\,$ (coarse grid impact): $\\,N_k = 11\\,$, $\\,T = 300\\,\\mathrm{K}\\,$, $\\,N_e^{\\mathrm{target}} = 1.0\\,$.\n- Case $\\,3\\,$ (finer grid): $\\,N_k = 201\\,$, $\\,T = 300\\,\\mathrm{K}\\,$, $\\,N_e^{\\mathrm{target}} = 1.0\\,$.\n- Case $\\,4\\,$ (band-edge, low $\\,T\\,$, low filling): $\\,N_k = 401\\,$, $\\,T = 10\\,\\mathrm{K}\\,$, $\\,N_e^{\\mathrm{target}} = 0.1\\,$.\n- Case $\\,5\\,$ (high $\\,T\\,$, near top of band): $\\,N_k = 201\\,$, $\\,T = 1500\\,\\mathrm{K}\\,$, $\\,N_e^{\\mathrm{target}} = 1.9\\,$.\n\nFinal output specification:\n- Your program should produce a single line of output containing a comma-separated list enclosed in square brackets with, for each case in order, two floating-point numbers: $\\mu$ in $\\mathrm{eV}$ and the absolute deviation $\\lvert \\mu - \\mu_{\\mathrm{ref}} \\rvert$ in $\\mathrm{eV}$. Thus the final output must be a flat list with $\\,10\\,$ numbers:\n$$\n[\\mu_1, \\Delta\\mu_1, \\mu_2, \\Delta\\mu_2, \\mu_3, \\Delta\\mu_3, \\mu_4, \\Delta\\mu_4, \\mu_5, \\Delta\\mu_5]\\,,\n$$\nwhere $\\,\\Delta\\mu_i = \\lvert \\mu_i - \\mu_{\\mathrm{ref},i} \\rvert\\,$. All energies must be in $\\,\\mathrm{eV}\\,$ and temperatures in $\\,\\mathrm{K}\\,$. Angles in $\\,k$-space are dimensionless because $\\,a = 1.0\\,\\mathrm{\\AA}\\,$ is used to nondimensionalize $\\,ka\\,$. All numerical values in the output must be floating-point numbers.", "solution": "The user's request is to implement a finite-temperature chemical potential solver for a one-dimensional tight-binding model. This is a standard problem in computational materials science. I will first validate the problem statement and then provide a detailed solution.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n- **Governing Equation**: The target electron number per unit cell, $N_e^{\\mathrm{target}}$, must satisfy the relation:\n  $$N_e(\\mu,T) \\;=\\; \\int_{-\\infty}^{+\\infty} N(E)\\, f(E,\\mu,T)\\, dE$$\n- **Model System**: A one-dimensional monatomic chain with one $s$-like orbital.\n  - Hopping parameter: $t = 1.0\\,\\mathrm{eV}$.\n  - Lattice constant: $a = 1.0\\,\\mathrm{\\AA}$.\n  - Spin degeneracy: $g_s = 2$.\n- **Dispersion Relation**: The single-band energy dispersion is given by:\n  $$E(k) \\;=\\; -2t \\cos(ka)$$\n  over the Brillouin zone $k \\in [-\\pi/a, \\pi/a)$, yielding a band energy range of $E \\in [-2t, 2t]$.\n- **Statistical Mechanics**: The occupation is described by the Fermi–Dirac distribution:\n  $$f(E,\\mu,T) \\;=\\; \\frac{1}{1 + \\exp\\!\\big( \\frac{E-\\mu}{k_B T} \\big)}$$\n- **Physical Constant**: The Boltzmann constant is $k_B = 8.617333262\\times 10^{-5}\\,\\mathrm{eV/K}$.\n- **Numerical Approximation**: The integral for the electron number is replaced by a sum over a discrete, uniform $k$-point mesh:\n  $$N_e(\\mu,T;N_k) \\;=\\; \\frac{g_s}{N_k}\\,\\sum_{j=1}^{N_k} f\\!\\big(E(k_j),\\mu,T\\big)$$\n- **Computational Task**: Solve for the chemical potential $\\mu$ from the equation $F(\\mu) = N_e(\\mu,T;N_k) - N_e^{\\mathrm{target}} = 0$ using a robust, bracketed root-finding method.\n- **Convergence Analysis**: A high-resolution reference chemical potential, $\\mu_{\\mathrm{ref}}$, must be computed using $N_k^{\\mathrm{ref}} = 20001$ $k$-points to assess the convergence of the primary calculations.\n- **Test Suite**:\n  - Case 1: $N_k = 31$, $T = 300\\,\\mathrm{K}$, $N_e^{\\mathrm{target}} = 1.0$.\n  - Case 2: $N_k = 11$, $T = 300\\,\\mathrm{K}$, $N_e^{\\mathrm{target}} = 1.0$.\n  - Case 3: $N_k = 201$, $T = 300\\,\\mathrm{K}$, $N_e^{\\mathrm{target}} = 1.0$.\n  - Case 4: $N_k = 401$, $T = 10\\,\\mathrm{K}$, $N_e^{\\mathrm{target}} = 0.1$.\n  - Case 5: $N_k = 201$, $T = 1500\\,\\mathrm{K}$, $N_e^{\\mathrm{target}} = 1.9$.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientific Grounding**: The problem is fundamentally sound. It describes a canonical model in solid-state physics—the 1D tight-binding chain—and poses a standard computational task: determining the chemical potential required to achieve a target carrier concentration at a finite temperature. The use of $k$-point sampling to approximate Brillouin zone integrals is a cornerstone technique in modern electronic structure calculations (e.g., density functional theory). All parameters are physically realistic.\n- **Well-Posedness**: The problem is well-posed. The function to be solved, $F(\\mu) = N_e(\\mu,T;N_k) - N_e^{\\mathrm{target}}$, is a continuous and strictly monotonically increasing function of $\\mu$ for any finite temperature $T  0$. This is because the Fermi-Dirac function $f(E,\\mu,T)$ is strictly increasing with $\\mu$. The range of $N_e(\\mu,T;N_k)$ spans from $0$ (for $\\mu \\to -\\infty$) to $g_s=2$ (for $\\mu \\to +\\infty$). Since all specified target occupations $N_e^{\\mathrm{target}}$ lie within the interval $(0, 2)$, the Intermediate Value Theorem guarantees the existence of a unique solution for $\\mu$.\n- **Objectivity**: The problem statement is expressed in precise, objective mathematical and physical terms, free from ambiguity or subjective interpretation.\n\n**Step 3: Verdict and Action**\nThe problem is scientifically valid, well-posed, and self-contained. I will proceed with formulating and implementing the solution.\n\n### Principle-Based Design of the Solution\n\nThe solution to this problem involves the numerical implementation of fundamental concepts from solid-state physics and statistical mechanics. The core task is to find the chemical potential $\\mu$ that self-consistently yields a specified number of electrons per unit cell, $N_e^{\\mathrm{target}}$, at a given temperature $T$.\n\n**1. Electronic Structure: The Tight-Binding Model**\n\nWe begin with the electronic structure of the system, defined by the single-particle energy eigenvalues $E(k)$. For the one-dimensional chain with nearest-neighbor hopping $t$, the dispersion is $E(k) = -2t \\cos(ka)$. Since this is a periodic system, the physically distinct states are defined by the wavevector $k$ within the first Brillouin Zone (BZ), $k \\in [-\\pi/a, \\pi/a)$. The energy band spans continuously from $E_{min} = E(k=0) = -2t$ to $E_{max} = E(k=\\pm\\pi/a) = +2t$. With $t = 1.0\\,\\mathrm{eV}$, the band ranges from $-2.0\\,\\mathrm{eV}$ to $2.0\\,\\mathrm{eV}$.\n\n**2. From Continuum Integral to Discrete Sum: k-Point Sampling**\n\nIn a computational setting, integrals over the continuous BZ are approximated by sums over a discrete grid of $k$-points. The problem specifies a uniform grid of $N_k$ points. This transforms the integral for the total electron number into a Riemann sum. The number of electrons per unit cell, $N_e$, which is a function of $\\mu$ and $T$, is then given by:\n$$N_e(\\mu,T;N_k) \\;=\\; \\frac{g_s}{N_k}\\,\\sum_{j=1}^{N_k} f\\!\\big(E(k_j),\\mu,T\\big)$$\nHere, $\\{k_j\\}$ is the set of $N_k$ sampling points in the BZ, $E(k_j)$ are the corresponding energy eigenvalues, $g_s=2$ is the spin degeneracy, and $f$ is the Fermi-Dirac distribution. This discrete formulation is the function we will implement.\n\n**3. Root Finding for the Chemical Potential**\n\nThe problem now becomes finding the root of the function:\n$$F(\\mu) \\;=\\; N_e(\\mu,T;N_k) - N_e^{\\mathrm{target}} \\;=\\; 0$$\nAs established, $F(\\mu)$ is a continuous and strictly monotonic function of $\\mu$ for $T0$. This property is ideal for a bracketed root-finding algorithm, which is guaranteed to converge if an interval $[\\mu_a, \\mu_b]$ can be found such that $F(\\mu_a)$ and $F(\\mu_b)$ have opposite signs. Brent's method is an excellent choice as it combines the robustness of the bisection method with the speed of the secant method and inverse quadratic interpolation. It is available in the `scipy.optimize` library as `brentq`.\n\nTo bracket the root, we observe that the chemical potential $\\mu$ will typically lie near the energy band of the material. A safe and robust bracketing interval can be constructed by taking the minimum and maximum energies of the discrete band, $[E_{min}, E_{max}]$, and extending this interval by a thermal margin, e.g., several units of $k_B T$. This ensures that for any valid $N_e^{\\mathrm{target}}$, the function values at the bracket endpoints will have opposite signs.\n\n**4. Algorithmic Implementation**\n\nThe implementation will be structured as follows:\n\n- A helper function, `calculate_energies(Nk)`, will generate the set of $N_k$ energy eigenvalues $\\{E(k_j)\\}$ by first creating a uniform grid of $k$-points in the interval $[-\\pi/a, \\pi/a)$ and then applying the dispersion relation.\n- A second function, `calculate_Ne(mu, T, energies)`, will compute $N_e(\\mu,T;N_k)$ for a given $\\mu$, $T$, and a pre-computed set of energies. This function will be the core of our objective function for the root solver.\n- A solver function, `find_chemical_potential(T, Ne_target, energies)`, will define the objective function $F(\\mu)$ and use `scipy.optimize.root_scalar` with the `brentq` method to find its root, $\\mu$.\n- The main script will iterate through the provided test suite. For each case, it will:\n    1.  Compute the reference chemical potential, $\\mu_{\\mathrm{ref}}$, using a dense $k$-point grid ($N_k^{\\mathrm{ref}} = 20001$).\n    2.  Compute the case-specific chemical potential, $\\mu$, using the specified $N_k$.\n    3.  Calculate the absolute deviation $\\Delta\\mu = |\\mu - \\mu_{\\mathrm{ref}}|$.\n    4.  Append both $\\mu$ and $\\Delta\\mu$ to a results list.\n- Finally, the program will print the collected results in the specified format. This process directly addresses the problem's requirement to analyze convergence with respect to $k$-point sampling.\n\nThis systematic approach guarantees a robust and correct solution that is firmly grounded in the principles of condensed matter physics.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import root_scalar\n\ndef solve():\n    \"\"\"\n    Solves for the chemical potential in a 1D tight-binding model for various test cases\n    and computes the deviation from a high-resolution reference calculation.\n    \"\"\"\n    # Model and physical constants\n    T_PARAM = 1.0  # Hopping parameter in eV\n    A_PARAM = 1.0  # Lattice constant in Angstrom\n    GS = 2.0       # Spin degeneracy\n    KB = 8.617333262e-5  # Boltzmann constant in eV/K\n    NK_REF = 20001 # Number of k-points for reference calculation\n\n    # Test suite from the problem statement\n    test_cases = [\n        # (Nk, T in K, Ne_target)\n        (31, 300.0, 1.0),\n        (11, 300.0, 1.0),\n        (201, 300.0, 1.0),\n        (401, 10.0, 0.1),\n        (201, 1500.0, 1.9),\n    ]\n\n    results = []\n\n    def calculate_energies(Nk, t, a):\n        \"\"\"\n        Calculates the single-particle energy eigenvalues for a given k-point grid.\n        The grid is uniform in the 1st Brillouin Zone k in [-pi/a, pi/a).\n        \"\"\"\n        k_points = np.linspace(-np.pi / a, np.pi / a, Nk, endpoint=False)\n        energies = -2.0 * t * np.cos(k_points * a)\n        return energies\n\n    def calculate_Ne(mu, T, energies, gs, kB):\n        \"\"\"\n        Calculates the number of electrons per unit cell for a given chemical potential and temperature\n        using the discrete k-point summation.\n        \"\"\"\n        if T = 1e-9: # Treat very low T as T=0 to avoid numerical issues\n            return gs * np.sum(energies  mu) / len(energies)\n        \n        kBT = kB * T\n        # The argument of the exponential can be large, but numpy handles it robustly.\n        # np.exp will overflow to `inf` for large positive arguments, which correctly\n        # yields a Fermi-Dirac value of 0.\n        arg = (energies - mu) / kBT\n        fermi_dirac = 1.0 / (1.0 + np.exp(arg))\n        \n        # Total electron number is the mean occupancy multiplied by spin degeneracy\n        return gs * np.mean(fermi_dirac)\n        \n    def find_chemical_potential(T, Ne_target, energies, gs, kB):\n        \"\"\"\n        Solves for the chemical potential mu using a robust root-finding algorithm.\n        \"\"\"\n        # Define the objective function F(mu) = N_e(mu) - N_e_target, whose root we seek.\n        objective_func = lambda mu: calculate_Ne(mu, T, energies, gs, kB) - Ne_target\n        \n        # Establish a safe bracket for the root search. The energy band is [-2t, 2t].\n        # A wider bracket, extended by a thermal margin, ensures robustness.\n        E_min, E_max = np.min(energies), np.max(energies)\n        margin = max(2.0, 20.0 * kB * T) # Generous margin\n        bracket = [E_min - margin, E_max + margin]\n        \n        # Use scipy's `root_scalar` with the brentq method for robust and efficient\n        # bracketed root-finding.\n        try:\n            solution = root_scalar(objective_func, bracket=bracket, method='brentq')\n            return solution.root\n        except ValueError:\n            # This should not happen for this well-posed problem, but is good practice.\n            return np.nan # Error indicator\n            \n    # --- Main processing loop ---\n    for Nk, T, Ne_target in test_cases:\n        \n        # --- 1. Reference Calculation ---\n        energies_ref = calculate_energies(NK_REF, T_PARAM, A_PARAM)\n        mu_ref = find_chemical_potential(T, Ne_target, energies_ref, GS, KB)\n        \n        # --- 2. Test Case Calculation ---\n        energies_case = calculate_energies(Nk, T_PARAM, A_PARAM)\n        mu_case = find_chemical_potential(T, Ne_target, energies_case, GS, KB)\n        \n        # --- 3. Compute Deviation ---\n        # The deviation measures the error due to the coarser k-point grid.\n        delta_mu = abs(mu_case - mu_ref)\n        \n        # --- 4. Store Results ---\n        results.extend([mu_case, delta_mu])\n\n    # Final print statement in the exact required format.\n    # Format to 12 decimal places for sufficient precision.\n    print(f\"[{','.join(f'{x:.12f}' for x in results)}]\")\n\nsolve()\n```", "id": "3443117"}, {"introduction": "While uniform $k$-point grids are a straightforward way to perform Brillouin zone integrations, their inefficiency becomes apparent when the integrand has sharp features, demanding a very high density of points for accuracy. This exercise introduces a more sophisticated approach: adaptive mesh refinement. You will implement an algorithm that intelligently concentrates $k$-points in crucial regions, such as near the Fermi surface and at van Hove singularities, providing a practical lesson in how to achieve high-accuracy results with significantly reduced computational cost. [@problem_id:3443129]", "problem": "You are to implement an adaptive $k$-point mesh refinement strategy for a two-dimensional square-lattice, single-band, nearest-neighbor tight-binding model to reduce the integrated band occupancy error. The integrated occupancy is defined by the fundamental density-of-states relation\n$$\nn = \\int N(E)\\,f(E;\\mu,T)\\,dE,\n$$\nwhere $n$ is the number of electrons per unit cell, $N(E)$ is the density of states, $f(E;\\mu,T)$ is the Fermi-Dirac distribution, $\\mu$ is the chemical potential, and $T$ is the absolute temperature. The convergence metric is the integrated occupancy error\n$$\n\\epsilon_n = \\left| \\int N(E)\\,f(E;\\mu,T)\\,dE - n_{\\text{ref}} \\right|,\n$$\nwhere $n_{\\text{ref}}$ is a high-resolution numerical reference occupancy. Your program must compute $\\epsilon_n$ and use it to guide an adaptive refinement focused on sharp density-of-states features.\n\nFundamental base and model:\n- Use the two-dimensional square Brillouin zone defined by $k_x \\in [-\\pi,\\pi]$ and $k_y \\in [-\\pi,\\pi]$.\n- Use the tight-binding dispersion\n$$\nE(\\mathbf{k}) = -2t \\left[\\cos(k_x) + \\cos(k_y)\\right],\n$$\nwith hopping parameter $t$ expressed in electron-volts (eV).\n- Use the Fermi-Dirac distribution\n$$\nf(E;\\mu,T) = \\frac{1}{1+\\exp\\!\\left(\\frac{E-\\mu}{k_{\\mathrm{B}}\\,T}\\right)},\n$$\nwith Boltzmann constant $k_{\\mathrm{B}}$ expressed in electron-volts per Kelvin (eV/K).\n- Assume spin degeneracy $g_s = 2$ and one orbital per unit cell. The occupancy per unit cell is computed by\n$$\nn = \\frac{g_s}{\\Omega_{\\mathrm{BZ}}}\\int_{\\mathrm{BZ}} f(E(\\mathbf{k});\\mu,T)\\,d^2k,\n$$\nwhere $\\Omega_{\\mathrm{BZ}} = (2\\pi)^2$ is the Brillouin zone area. In discrete form, a uniform mesh with $N_k$ points approximates this integral by\n$$\nn \\approx \\frac{g_s}{N_k}\\sum_{i=1}^{N_k} f\\!\\left(E(\\mathbf{k}_i);\\mu,T\\right).\n$$\n\nAdaptive refinement requirements:\n- Start from an initial uniform grid of $N_0 \\times N_0$ rectangular $k$-space cells covering the Brillouin zone. Use the cell centers for integration with rectangular quadrature, so the occupancy estimate is\n$$\nn_{\\text{est}} = \\frac{g_s}{\\Omega_{\\mathrm{BZ}}} \\sum_{c \\in \\mathcal{C}} f\\!\\left(E(\\mathbf{k}_c);\\mu,T\\right)\\,A_c,\n$$\nwhere $\\mathcal{C}$ is the set of leaf cells after refinement, $\\mathbf{k}_c$ is the center of cell $c$, and $A_c$ is the area of cell $c$ in $k$-space.\n- At each refinement level, subdivide any cell into $2 \\times 2$ subcells if any of the following criteria are met:\n    1. The cell’s energy range intersects the thermal transition window around the chemical potential, i.e., if the minimum corner energy $E_{\\min}$ and maximum corner energy $E_{\\max}$ of the cell satisfy\n    $$\n    [E_{\\min},E_{\\max}] \\cap [\\mu - \\beta k_{\\mathrm{B}}T,\\ \\mu + \\beta k_{\\mathrm{B}}T] \\neq \\varnothing,\n    $$\n    where $\\beta$ is a positive dimensionless parameter.\n    2. The cell center is near a stationary point (where the gradient magnitude is small), indicating a potential sharp density-of-states feature (van Hove singularity). For the given dispersion, the gradient is\n    $$\n    \\nabla_{\\mathbf{k}} E = \\left(2t\\sin(k_x),\\ 2t\\sin(k_y)\\right).\n    $$\n    Refine if\n    $$\n    \\left|\\sin(k_{x,c})\\right|\\cdot\\left|\\sin(k_{y,c})\\right|  s_{\\mathrm{thr}},\n    $$\n    where $k_{x,c}$ and $k_{y,c}$ are the center coordinates and $s_{\\mathrm{thr}}$ is a small positive threshold.\n    3. The Fermi-Dirac factor varies significantly across the cell corners (indicating large local quadrature error). Let $f_{\\max}$ and $f_{\\min}$ be the maximum and minimum of $f$ evaluated at the four corners’ energies; refine if\n    $$\n    f_{\\max} - f_{\\min}  f_{\\mathrm{thr}},\n    $$\n    where $f_{\\mathrm{thr}}$ is a positive threshold.\n- Stop refining when no cell meets the criteria or when the maximum refinement level $L_{\\max}$ is reached.\n\nReference occupancy:\n- Compute $n_{\\text{ref}}$ using a uniform $N_{\\text{ref}} \\times N_{\\text{ref}}$ grid over the Brillouin zone, via the discrete average\n$$\nn_{\\text{ref}} = \\frac{g_s}{N_{\\text{ref}}^2}\\sum_{i=1}^{N_{\\text{ref}}^2} f\\!\\left(E(\\mathbf{k}_i);\\mu,T\\right).\n$$\n\nError metric and output:\n- Compute the final integrated occupancy error\n$$\n\\epsilon_n = \\left|n_{\\text{est}} - n_{\\text{ref}}\\right|.\n$$\n- Express $t$ and $\\mu$ in electron-volts (eV), $T$ in Kelvin (K), and $\\epsilon_n$ in electrons per unit cell, rounded to six decimal places.\n- For each test case, output a list containing the rounded $\\epsilon_n$ and the final number of $k$-points used in the adaptive integration, $N_k$, as $[\\epsilon_n, N_k]$ where $N_k$ is an integer.\n\nTest suite:\n- Use Boltzmann constant $k_{\\mathrm{B}} = 8.617333262145\\times 10^{-5}$ eV/K.\n- Provide the following test cases, each specified as $(t,\\ \\mu,\\ T,\\ N_0,\\ L_{\\max},\\ N_{\\text{ref}},\\ \\beta,\\ f_{\\mathrm{thr}},\\ s_{\\mathrm{thr}})$:\n    1. $(1.0,\\ 0.0,\\ 300,\\ 8,\\ 5,\\ 1024,\\ 4.0,\\ 0.25,\\ 0.02)$\n    2. $(1.0,\\ 3.5,\\ 50,\\ 8,\\ 6,\\ 1024,\\ 4.0,\\ 0.25,\\ 0.02)$\n    3. $(1.0,\\ 0.0,\\ 2000,\\ 6,\\ 4,\\ 1024,\\ 4.0,\\ 0.20,\\ 0.02)$\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of lists, enclosed in square brackets. For example,\n$$\n[\\,[\\epsilon_1,N_{k,1}],\\ [\\epsilon_2,N_{k,2}],\\ [\\epsilon_3,N_{k,3}]\\,].\n$$\nNo other text should be printed.", "solution": "The problem requires the implementation of an adaptive $k$-point mesh refinement strategy to calculate the integrated band occupancy for a two-dimensional tight-binding model. The accuracy of this adaptive method is evaluated against a high-resolution reference calculation. The process involves validating the problem statement and then providing a full computational solution.\n\n### Problem Formulation and Model\nThe core task is to compute the integrated band occupancy, $n$, defined as:\n$$\nn = \\int N(E)\\,f(E;\\mu,T)\\,dE\n$$\nwhere $N(E)$ is the density of states, and $f(E;\\mu,T)$ is the Fermi-Dirac distribution. This is equivalent to integrating the Fermi-Dirac distribution over the first Brillouin Zone (BZ):\n$$\nn = \\frac{g_s}{\\Omega_{\\mathrm{BZ}}}\\int_{\\mathrm{BZ}} f(E(\\mathbf{k});\\mu,T)\\,d^2k\n$$\nHere, $g_s=2$ is the spin degeneracy, and $\\Omega_{\\mathrm{BZ}}=(2\\pi)^2$ is the area of the two-dimensional BZ defined by $k_x \\in [-\\pi,\\pi]$ and $k_y \\in [-\\pi,\\pi]$.\n\nThe electronic band structure is described by a single-band, nearest-neighbor tight-binding model on a square lattice, with the dispersion relation:\n$$\nE(\\mathbf{k}) = -2t \\left[\\cos(k_x) + \\cos(k_y)\\right]\n$$\nwhere $t$ is the hopping parameter in electron-volts (eV).\n\nThe probability of state occupancy is given by the Fermi-Dirac distribution:\n$$\nf(E;\\mu,T) = \\frac{1}{1+\\exp\\!\\left(\\frac{E-\\mu}{k_{\\mathrm{B}}\\,T}\\right)}\n$$\nwhere $\\mu$ is the chemical potential (eV), $T$ is the absolute temperature (K), and $k_{\\mathrm{B}}$ is the Boltzmann constant ($8.617333262145\\times 10^{-5}$ eV/K).\n\n### Numerical Integration Strategy\n\n#### Reference Calculation\nA reference occupancy, $n_{\\text{ref}}$, is computed using a high-resolution, uniform $k$-point mesh. For an $N_{\\text{ref}} \\times N_{\\text{ref}}$ grid, the integral is approximated by a sum:\n$$\nn_{\\text{ref}} = \\frac{g_s}{N_{\\text{ref}}^2}\\sum_{i=1}^{N_{\\text{ref}}^2} f\\!\\left(E(\\mathbf{k}_i);\\mu,T\\right)\n$$\nwhere the $\\mathbf{k}_i$ points are chosen as the centers of the grid cells partitioning the BZ.\n\n#### Adaptive Mesh Refinement\nThe adaptive strategy aims to improve computational efficiency by concentrating $k$-points in regions where the integrand $f(E(\\mathbf{k}))$ varies rapidly. This is achieved through a quadtree-like refinement of the $k$-space grid.\n\nThe process starts with an initial uniform grid of $N_0 \\times N_0$ cells. These cells are then recursively subdivided based on a set of physical criteria. A cell at any level of refinement is a candidate for subdivision into $2 \\times 2 = 4$ smaller, equal-area cells.\n\nThe refinement is guided by three criteria. A cell is marked for refinement if it meets any of the following conditions:\n\n1.  **Energy Window Intersection**: The cell's energy range, $[E_{\\min}, E_{\\max}]$ (determined by the energies at its four corners), overlaps with the thermal transition window $[\\mu - \\beta k_{\\mathrm{B}}T, \\mu + \\beta k_{\\mathrm{B}}T]$. This criterion focuses computational effort on the Fermi surface, where the occupancy function transitions from $1$ to $0$.\n\n2.  **Proximity to van Hove Singularities**: The density of states $N(E)$ exhibits singularities (van Hove singularities) where the band velocity $\\nabla_{\\mathbf{k}} E$ is zero. For the given dispersion, this gradient is $\\nabla_{\\mathbf{k}} E = (2t\\sin(k_x), 2t\\sin(k_y))$. The condition given, $|\\sin(k_{x,c})| \\cdot |\\sin(k_{y,c})|  s_{\\mathrm{thr}}$ (where $\\mathbf{k}_c=(k_{x,c}, k_{y,c})$ is the cell center), serves as a proxy to identify cells near these singularities, which occur at $k_x, k_y \\in \\{0, \\pm\\pi\\}$.\n\n3.  **Fermi Factor Variation**: A large variation in the Fermi-Dirac factor across a cell indicates that a single-point quadrature rule (like the midpoint rule) will incur a large error. The condition $f_{\\max} - f_{\\min}  f_{\\mathrm{thr}}$, where $f_{\\max}$ and $f_{\\min}$ are the maximum and minimum values of the Fermi factor at the cell's four corners, triggers refinement to reduce this local quadrature error.\n\nThe refinement process terminates for a given branch of the quadtree when a cell no longer meets any refinement criteria, or when a maximum refinement level, $L_{\\max}$, is reached.\n\n#### Estimated Occupancy and Error\nThe final set of non-subdivided cells (leaf cells) forms the adaptive integration grid. The estimated occupancy, $n_{\\text{est}}$, is computed using a rectangular quadrature rule over these leaf cells:\n$$\nn_{\\text{est}} = \\frac{g_s}{\\Omega_{\\mathrm{BZ}}} \\sum_{c \\in \\mathcal{C}} f\\!\\left(E(\\mathbf{k}_c);\\mu,T\\right)\\,A_c\n$$\nwhere $\\mathcal{C}$ is the set of all leaf cells, $\\mathbf{k}_c$ is the center of a cell $c$, and $A_c$ is its area. The total number of points used is $N_k = |\\mathcal{C}|$.\n\nThe final convergence metric is the integrated occupancy error:\n$$\n\\epsilon_n = |n_{\\text{est}} - n_{\\text{ref}}|\n$$\n\n### Algorithm and Implementation\nThe overall algorithm is implemented as follows:\n1.  Loop through each test case provided.\n2.  For each case, first, calculate the reference occupancy $n_{\\text{ref}}$ on a fine, uniform $N_{\\text{ref}} \\times N_{\\text{ref}}$ grid. Vectorized `NumPy` operations are used for efficiency.\n3.  Next, perform the adaptive integration:\n    a.  Initialize a list of \"active\" cells with the base $N_0 \\times N_0$ grid covering the BZ from $[-\\pi, \\pi] \\times [-\\pi, \\pi]$.\n    b.  Iterate from a refinement level of $0$ to $L_{\\max}-1$. In each iteration:\n        i.  Create an empty list for the next level of active cells.\n        ii. For each cell in the current active list, check the three refinement criteria.\n        iii. If any criterion is met, subdivide the cell into four children and add them to the next-level list.\n        iv. If no criteria are met, the cell becomes a leaf cell and is stored separately.\n    c.  After the loop, any cells remaining in the active list (which have reached $L_{\\max}$) are also added to the list of leaf cells.\n    d.  The total number of $k$-points, $N_k$, is the total count of leaf cells.\n4.  Calculate $n_{\\text{est}}$ by summing the contributions from all leaf cells, using the formula for $n_{\\text{est}}$. Each cell's contribution is weighted by its area $A_c$.\n5.  Compute the error $\\epsilon_n = |n_{\\text{est}} - n_{\\text{ref}}|$.\n6.  Store the result for the test case as a pair: $[\\epsilon_n, N_k]$, with $\\epsilon_n$ rounded to six decimal places.\n7.  After processing all test cases, format the collected results into a single string as specified and print it.\n\nA custom class, `Cell`, holds the geometric attributes of each $k$-space cell (boundaries, center, area) and its refinement level, simplifying the subdivision logic and the final quadrature sum.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the adaptive k-point mesh refinement for all test cases.\n    \"\"\"\n    KB = 8.617333262145e-5  # Boltzmann constant in eV/K\n    G_S = 2.0  # Spin degeneracy\n    OMEGA_BZ = (2 * np.pi)**2  # Area of the 2D Brillouin Zone\n\n    test_cases = [\n        (1.0, 0.0, 300, 8, 5, 1024, 4.0, 0.25, 0.02),\n        (1.0, 3.5, 50, 8, 6, 1024, 4.0, 0.25, 0.02),\n        (1.0, 0.0, 2000, 6, 4, 1024, 4.0, 0.20, 0.02)\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        t, mu, T, N0, L_max, N_ref, beta, f_thr, s_thr = case\n        \n        # Calculate reference occupancy\n        n_ref = calculate_n_ref(t, mu, T, N_ref, KB, G_S)\n        \n        # Perform adaptive integration\n        n_est, Nk = adaptive_integration(t, mu, T, N0, L_max, beta, f_thr, s_thr, KB, G_S, OMEGA_BZ)\n        \n        # Calculate error\n        error = abs(n_est - n_ref)\n        \n        results.append([round(error, 6), Nk])\n\n    # Format and print the final output\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef energy(kx, ky, t):\n    \"\"\"Calculates the tight-binding energy.\"\"\"\n    return -2.0 * t * (np.cos(kx) + np.cos(ky))\n\ndef fermi_dirac(E, mu, T, kB):\n    \"\"\"Calculates the Fermi-Dirac distribution factor.\"\"\"\n    kBT = kB * T\n    if kBT == 0:\n        return 1.0 if E  mu else 0.0\n    # Use np.clip to avoid overflow in exp for large positive arguments\n    arg = np.clip((E - mu) / kBT, -700, 700)\n    return 1.0 / (1.0 + np.exp(arg))\n\ndef calculate_n_ref(t, mu, T, N_ref, kB, g_s):\n    \"\"\"Calculates the reference occupancy on a uniform grid.\"\"\"\n    dk = 2.0 * np.pi / N_ref\n    k_vals = np.linspace(-np.pi + dk / 2.0, np.pi - dk / 2.0, N_ref)\n    kx_grid, ky_grid = np.meshgrid(k_vals, k_vals)\n    \n    E_grid = energy(kx_grid, ky_grid, t)\n    f_grid = fermi_dirac(E_grid, mu, T, kB)\n    \n    n_ref = g_s * np.mean(f_grid)\n    return n_ref\n\n\nclass Cell:\n    \"\"\"Represents a cell in k-space for the adaptive grid.\"\"\"\n    def __init__(self, kx_min, kx_max, ky_min, ky_max, level):\n        self.kx_min = kx_min\n        self.kx_max = kx_max\n        self.ky_min = ky_min\n        self.ky_max = ky_max\n        self.level = level\n\n        self.k_center = (\n            (kx_min + kx_max) / 2.0,\n            (ky_min + ky_max) / 2.0\n        )\n        self.area = (kx_max - kx_min) * (ky_max - ky_min)\n        self.corners = [\n            (kx_min, ky_min), (kx_max, ky_min),\n            (kx_min, ky_max), (kx_max, ky_max)\n        ]\n\n    def subdivide(self):\n        \"\"\"Subdivides the cell into four children.\"\"\"\n        kx_mid, ky_mid = self.k_center\n        new_level = self.level + 1\n        return [\n            Cell(self.kx_min, kx_mid, self.ky_min, ky_mid, new_level),\n            Cell(kx_mid, self.kx_max, self.ky_min, ky_mid, new_level),\n            Cell(self.kx_min, kx_mid, ky_mid, self.ky_max, new_level),\n            Cell(kx_mid, self.kx_max, ky_mid, self.ky_max, new_level)\n        ]\n\ndef adaptive_integration(t, mu, T, N0, L_max, beta, f_thr, s_thr, kB, g_s, omega_bz):\n    \"\"\"Performs the adaptive k-space integration.\"\"\"\n    kBT = kB * T\n    thermal_window_min = mu - beta * kBT\n    thermal_window_max = mu + beta * kBT\n\n    # Initialize grid\n    initial_cells = []\n    dkx = 2 * np.pi / N0\n    dky = 2 * np.pi / N0\n    for i in range(N0):\n        kx_min = -np.pi + i * dkx\n        for j in range(N0):\n            ky_min = -np.pi + j * dky\n            initial_cells.append(Cell(kx_min, kx_min + dkx, ky_min, ky_min + dky, 0))\n\n    active_cells = initial_cells\n    leaf_cells = []\n\n    for level in range(L_max):\n        if not active_cells:\n            break\n        \n        next_active_cells = []\n        for cell in active_cells:\n            # Check refinement criteria\n            refine = False\n            \n            # Criterion 1: Energy window\n            corner_energies = [energy(kx, ky, t) for kx, ky in cell.corners]\n            E_min, E_max = min(corner_energies), max(corner_energies)\n            if E_max = thermal_window_min and E_min = thermal_window_max:\n                refine = True\n\n            # Criterion 2: van Hove singularity\n            if not refine:\n                kx_c, ky_c = cell.k_center\n                if abs(np.sin(kx_c) * np.sin(ky_c))  s_thr:\n                    refine = True\n            \n            # Criterion 3: Fermi factor variation\n            if not refine:\n                corner_f = [fermi_dirac(E, mu, T, kB) for E in corner_energies]\n                f_min, f_max = min(corner_f), max(corner_f)\n                if f_max - f_min  f_thr:\n                    refine = True\n            \n            # Subdivide or add to leaves\n            if refine:\n                next_active_cells.extend(cell.subdivide())\n            else:\n                leaf_cells.append(cell)\n        \n        active_cells = next_active_cells\n\n    leaf_cells.extend(active_cells) # Add cells that reached L_max\n\n    # Calculate estimated occupancy\n    n_est = 0.0\n    for cell in leaf_cells:\n        kx_c, ky_c = cell.k_center\n        E_c = energy(kx_c, ky_c, t)\n        f_c = fermi_dirac(E_c, mu, T, kB)\n        n_est += f_c * cell.area\n\n    n_est *= (g_s / omega_bz)\n    Nk = len(leaf_cells)\n    \n    return n_est, Nk\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3443129"}, {"introduction": "Often, we wish to move beyond total properties and analyze the electronic character of specific atoms or orbitals by computing a Projected Density of States (PDOS). In the common framework of non-orthogonal basis sets, this decomposition is fraught with peril, as a naive projection can yield unphysical results like negative electron populations. This practice confronts this issue directly, guiding you to compare a flawed projection scheme with the mathematically rigorous Löwdin orthogonalization method, thereby ensuring you can correctly interpret orbital-resolved data from your calculations. [@problem_id:3443144]", "problem": "Consider a finite-basis electronic structure model of a crystalline solid in the non-relativistic, single-particle approximation where the system is represented by a Hermitian Hamiltonian matrix $H$ expressed in a set of localized atomic orbitals and a symmetric positive definite overlap matrix $S$ that encodes the non-orthogonality of the basis. The generalized eigenvalue problem is\n$$\nH \\mathbf{c}_n = E_n\\, S \\mathbf{c}_n,\n$$\nwith eigenvalues $E_n$ and eigenvectors $\\mathbf{c}_n$. In a non-orthogonal basis, the naive projection of a state onto a particular orbital index $\\alpha$ by using the Euclidean component $|c_{n,\\alpha}|^2$ does not define a proper projector and can produce unphysical partial densities of states (Partial Density of States (PDOS)), including violations of sum rules for integrated occupancies. A mathematically consistent way to construct orbital projections is to form a symmetric orthonormalized basis using the Löwdin transformation, defined by the matrix square root $S^{1/2}$ and its inverse $S^{-1/2}$, and then project in the orthonormalized basis.\n\nFundamental definitions and facts to use:\n- The total density of states is defined spectrally by delta distributions at the eigenvalues: $D(E) = \\sum_n \\delta(E - E_n)$.\n- The Fermi–Dirac distribution is $f(E) = \\frac{1}{1 + \\exp\\!\\left(\\frac{E - E_F}{k_{\\mathrm{B}} T}\\right)}$, with Boltzmann constant $k_{\\mathrm{B}}$ expressed in electronvolts per Kelvin.\n- The total band occupancy (number of electrons in this spin channel) at temperature $T$ and Fermi level $E_F$ is $N_{\\mathrm{e}} = \\sum_n f(E_n)$.\n- In an orthonormal basis, projecting a normalized state onto orbital $\\alpha$ by $|u_{n,\\alpha}|^2$ gives a proper resolution of identity over orbitals and satisfies $\\sum_{\\alpha} |u_{n,\\alpha}|^2 = 1$ for each $n$.\n\nYour task is to implement two PDOS-based occupancy integrals for each orbital index $\\alpha$:\n1. A naive non-orthogonal PDOS integral using the raw coefficients $c_{n,\\alpha}$ from the generalized eigenvectors:\n$$\nN_{\\alpha}^{\\mathrm{naive}} = \\sum_{n} \\left| c_{n,\\alpha} \\right|^2\\, f(E_n).\n$$\n2. A Löwdin-orthogonalized PDOS integral using projections in the symmetric orthonormalized basis:\n$$\nN_{\\alpha}^{\\mathrm{L}} = \\sum_{n} \\left| d_{n,\\alpha} \\right|^2\\, f(E_n),\n\\quad \\text{where} \\quad \\mathbf{d}_n = S^{1/2} \\mathbf{c}_n.\n$$\nThen, for each test case, compute two diagnostics to quantify the physicality of the PDOS projections:\n- The occupancy sum rule error for the naive projection, defined by\n$$\n\\Delta_{\\mathrm{naive}} = \\left(\\sum_{\\alpha} N_{\\alpha}^{\\mathrm{naive}}\\right) - N_{\\mathrm{e}} \\quad \\text{(in electrons)}.\n$$\n- The occupancy sum rule error for the Löwdin-orthogonalized projection, defined by\n$$\n\\Delta_{\\mathrm{L}} = \\left(\\sum_{\\alpha} N_{\\alpha}^{\\mathrm{L}}\\right) - N_{\\mathrm{e}} \\quad \\text{(in electrons)}.\n$$\nAlso compute, for each test case, the maximum absolute orbital-wise deviation between the naive and Löwdin occupancies:\n$$\n\\Delta_{\\max} = \\max_{\\alpha} \\left| N_{\\alpha}^{\\mathrm{naive}} - N_{\\alpha}^{\\mathrm{L}} \\right| \\quad \\text{(in electrons)}.\n$$\n\nUse the following constants and units:\n- Energies $E$, $E_F$ and matrix elements of $H$ are in electronvolts (eV).\n- Temperature $T$ is in Kelvin (K).\n- The Boltzmann constant $k_{\\mathrm{B}} = 8.617333262145 \\times 10^{-5} \\mathrm{eV/K}$.\n- Occupancies and errors must be reported in electrons (dimensionless count), as floats.\n\nNumerical implementation requirements:\n- Obtain $(E_n, \\mathbf{c}_n)$ by solving the generalized Hermitian eigenproblem $H \\mathbf{c}_n = E_n S \\mathbf{c}_n$ with $S$ symmetric positive definite. Choose the eigenvectors such that they satisfy the $S$-metric normalization $\\mathbf{c}_n^{\\dagger} S \\mathbf{c}_m = \\delta_{nm}$.\n- Construct $S^{1/2}$ via the spectral decomposition $S = U \\Lambda U^{\\top}$ with $\\Lambda$ positive diagonal, and set $S^{1/2} = U \\Lambda^{1/2} U^{\\top}$.\n- Evaluate $f(E_n)$ using the Fermi–Dirac distribution. Carefully handle extreme arguments to avoid floating-point overflow by using a numerically stable implementation of the logistic function.\n- For each orbital index $\\alpha$, compute $N_{\\alpha}^{\\mathrm{naive}}$ and $N_{\\alpha}^{\\mathrm{L}}$, then compute $\\Delta_{\\mathrm{naive}}$, $\\Delta_{\\mathrm{L}}$, and $\\Delta_{\\max}$.\n\nTest suite:\n- Case 1 (identity overlap, baseline consistency): \n  $$\n  H = \\begin{bmatrix} 0.0  -1.0 \\\\ -1.0  0.5 \\end{bmatrix} \\mathrm{eV},\\quad\n  S = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  1.0 \\end{bmatrix},\\quad\n  E_F = 0.0 \\mathrm{eV},\\quad T = 300 \\mathrm{K}.\n  $$\n- Case 2 (moderate non-orthogonality): \n  $$\n  H = \\begin{bmatrix} 0.0  -1.0 \\\\ -1.0  0.5 \\end{bmatrix} \\mathrm{eV},\\quad\n  S = \\begin{bmatrix} 1.0  0.3 \\\\ 0.3  1.0 \\end{bmatrix},\\quad\n  E_F = 0.0 \\mathrm{eV},\\quad T = 300 \\mathrm{K}.\n  $$\n- Case 3 (three-orbital chain with strong nearest-neighbor overlap): \n  $$\n  H = \\begin{bmatrix}\n  0.0  -1.0  0.0 \\\\\n  -1.0  0.3  -1.0 \\\\\n  0.0  -1.0  0.6\n  \\end{bmatrix} \\mathrm{eV},\\quad\n  S = \\begin{bmatrix}\n  1.0  0.6  0.0 \\\\\n  0.6  1.0  0.6 \\\\\n  0.0  0.6  1.0\n  \\end{bmatrix},\\quad\n  E_F = 0.2 \\mathrm{eV},\\quad T = 1000 \\mathrm{K}.\n  $$\n- Case 4 (near-singular two-orbital overlap): \n  $$\n  H = \\begin{bmatrix} 0.2  -0.4 \\\\ -0.4  -0.1 \\end{bmatrix} \\mathrm{eV},\\quad\n  S = \\begin{bmatrix} 1.0  0.9 \\\\ 0.9  1.0 \\end{bmatrix},\\quad\n  E_F = 0.1 \\mathrm{eV},\\quad T = 1 \\mathrm{K}.\n  $$\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, output three floats in this order: $\\Delta_{\\mathrm{naive}}$, $\\Delta_{\\mathrm{L}}$, and $\\Delta_{\\max}$. Concatenate the results for all four test cases into a single flat list. For example, the output must have the form\n$$\n[\\Delta_{\\mathrm{naive}}^{(1)},\\Delta_{\\mathrm{L}}^{(1)},\\Delta_{\\max}^{(1)},\\Delta_{\\mathrm{naive}}^{(2)},\\Delta_{\\mathrm{L}}^{(2)},\\Delta_{\\max}^{(2)},\\Delta_{\\mathrm{naive}}^{(3)},\\Delta_{\\mathrm{L}}^{(3)},\\Delta_{\\max}^{(3)},\\Delta_{\\mathrm{naive}}^{(4)},\\Delta_{\\mathrm{L}}^{(4)},\\Delta_{\\max}^{(4)}].\n$$\nAll entries must be floats representing electrons.", "solution": "The problem requires an analysis and comparison of two distinct methods for computing orbital-projected electronic occupancies within a finite, non-orthogonal basis set model of a crystalline solid. This task is fundamental in computational materials science for interpreting the results of electronic structure calculations, for example, by assigning a number of electrons to a specific atom or orbital. The core of the problem lies in the mathematical subtlety of defining projections in a non-orthogonal vector space.\n\nWe begin with the generalized eigenvalue problem which describes the stationary states of a single-particle system in a basis of localized atomic orbitals $|\\phi_{\\alpha}\\rangle$:\n$$\nH \\mathbf{c}_n = E_n S \\mathbf{c}_n\n$$\nHere, $H$ is the Hamiltonian matrix with elements $H_{\\alpha\\beta} = \\langle \\phi_{\\alpha} | \\hat{H} | \\phi_{\\beta} \\rangle$, $S$ is the overlap matrix with elements $S_{\\alpha\\beta} = \\langle \\phi_{\\alpha} | \\phi_{\\beta} \\rangle$, $E_n$ are the energy eigenvalues, and $\\mathbf{c}_n$ are the eigenvectors containing the coefficients that express the $n$-th eigenstate $|\\psi_n\\rangle$ as a linear combination of the basis orbitals: $|\\psi_n\\rangle = \\sum_{\\alpha} c_{n,\\alpha} |\\phi_{\\alpha}\\rangle$. The matrices $H$ and $S$ are Hermitian; since they are given as real, they are symmetric. The basis set non-orthogonality implies that $S_{\\alpha\\beta}$ is not generally a Kronecker delta $\\delta_{\\alpha\\beta}$, and $S$ is not the identity matrix $I$. $S$ is, however, symmetric and positive definite. The eigenvectors are chosen to be normalized with respect to the $S$-metric, meaning $\\mathbf{c}_n^\\dagger S \\mathbf{c}_m = \\delta_{nm}$.\n\nThe total number of electrons in the system (for a single spin channel) at a finite temperature $T$ and a given Fermi level $E_F$ is determined by summing the occupation of each energy level $E_n$. The occupation is given by the Fermi-Dirac distribution, $f(E}$:\n$$\nf(E) = \\frac{1}{1 + \\exp\\!\\left(\\frac{E - E_F}{k_{\\mathrm{B}} T}\\right)}\n$$\nwhere $k_{\\mathrm{B}}$ is the Boltzmann constant. The total number of electrons is thus:\n$$\nN_{\\mathrm{e}} = \\sum_n f(E_n)\n$$\nA physically meaningful decomposition of $N_{\\mathrm{e}}$ into contributions from each orbital $\\alpha$, denoted $N_{\\alpha}$, must satisfy the sum rule $\\sum_{\\alpha} N_{\\alpha} = N_{\\mathrm{e}}$.\n\nThe problem presents two ways to calculate these orbital occupancies, $N_{\\alpha}$.\n\n1.  The **\"naive\" projection**: This approach incorrectly treats the coefficients $c_{n,\\alpha}$ as if they belonged to an orthonormal basis. The projected occupancy is defined as:\n    $$\n    N_{\\alpha}^{\\mathrm{naive}} = \\sum_{n} \\left| c_{n,\\alpha} \\right|^2\\, f(E_n)\n    $$\n    The sum of these naive occupancies over all orbitals is $\\sum_{\\alpha} N_{\\alpha}^{\\mathrm{naive}} = \\sum_n f(E_n) (\\mathbf{c}_n^\\dagger \\mathbf{c}_n)$. Since $\\mathbf{c}_n^\\dagger S \\mathbf{c}_n = 1$, and $S \\neq I$, it is generally true that $\\mathbf{c}_n^\\dagger \\mathbf{c}_n \\neq 1$. Consequently, the sum rule is violated: $\\sum_{\\alpha} N_{\\alpha}^{\\mathrm{naive}} \\neq N_{\\mathrm{e}}$.\n\n2.  The **Löwdin-orthogonalized projection**: This is a mathematically rigorous method. It begins by transforming the non-orthogonal basis $\\{|\\phi_{\\alpha}\\rangle\\}$ into an orthonormal basis $\\{|\\chi_{\\alpha}\\rangle\\}$ via the Löwdin symmetric orthogonalization procedure. The transformation matrix is the inverse square root of the overlap matrix, $S^{-1/2}$. An eigenstate $|\\psi_n\\rangle$ can be expressed in this new basis as $|\\psi_n\\rangle = \\sum_\\alpha d_{n,\\alpha} |\\chi_\\alpha\\rangle$. The new coefficients $\\mathbf{d}_n$ are related to the original coefficients $\\mathbf{c}_n$ by the transformation $\\mathbf{d}_n = S^{1/2} \\mathbf{c}_n$. Because the $\\{|\\chi_\\alpha\\rangle\\}$ basis is orthonormal, a projection onto orbital $\\alpha$ is given by $|d_{n,\\alpha}|^2$, and these projections correctly sum to unity: $\\sum_\\alpha |d_{n,\\alpha}|^2 = 1$ for each eigenstate $n$. The proof is direct:\n    $$\n    \\sum_{\\alpha} |d_{n,\\alpha}|^2 = \\mathbf{d}_n^\\dagger \\mathbf{d}_n = (S^{1/2}\\mathbf{c}_n)^\\dagger(S^{1/2}\\mathbf{c}_n) = \\mathbf{c}_n^\\dagger (S^{1/2})^\\dagger S^{1/2} \\mathbf{c}_n = \\mathbf{c}_n^\\dagger S \\mathbf{c}_n = 1\n    $$\n    where the last step uses the $S$-normalization of the eigenvectors $\\mathbf{c}_n$. The Löwdin occupancy is therefore defined as:\n    $$\n    N_{\\alpha}^{\\mathrm{L}} = \\sum_{n} \\left| d_{n,\\alpha} \\right|^2\\, f(E_n)\n    $$\n    Summing this over all orbitals yields:\n    $$\n    \\sum_{\\alpha} N_{\\alpha}^{\\mathrm{L}} = \\sum_{\\alpha} \\sum_n |d_{n,\\alpha}|^2 f(E_n) = \\sum_n f(E_n) \\left(\\sum_{\\alpha} |d_{n,\\alpha}|^2\\right) = \\sum_n f(E_n) \\cdot 1 = N_{\\mathrm{e}}\n    $$\n    Thus, the Löwdin projection method rigorously satisfies the electron number sum rule. The error $\\Delta_{\\mathrm{L}} = (\\sum_{\\alpha} N_{\\alpha}^{\\mathrm{L}}) - N_{\\mathrm{e}}$ should be zero, up to numerical floating-point precision. The naive error, $\\Delta_{\\mathrm{naive}}$, is expected to be non-zero when $S \\neq I$.\n\nThe numerical implementation will proceed as follows for each test case:\n1.  **Solve the generalized eigenproblem**: Given matrices $H$ and $S$, solve $H \\mathbf{c}_n = E_n S \\mathbf{c}_n$ to obtain eigenvalues $E_n$ and $S$-normalized eigenvectors $\\mathbf{c}_n$. This will be accomplished using `scipy.linalg.eigh`.\n2.  **Compute the matrix square root $S^{1/2}$**: This is done via spectral decomposition of $S$. First, diagonalize $S$ as $S = U \\Lambda U^{\\top}$, where $U$ is the orthogonal matrix of eigenvectors and $\\Lambda$ is the diagonal matrix of eigenvalues. Then, $S^{1/2}$ is constructed as $S^{1/2} = U \\Lambda^{1/2} U^{\\top}$, where $\\Lambda^{1/2}$ is a diagonal matrix whose entries are the square roots of the eigenvalues of $S$.\n3.  **Evaluate the Fermi-Dirac distribution**: For each eigenvalue $E_n$, compute the occupation factor $f(E_n)$ using the given $E_F$, $T$, and $k_B$. A numerically stable implementation is essential to avoid floating-point overflow when the exponent $(E_n - E_F)/(k_B T)$ is large.\n4.  **Compute occupancies**:\n    -   Calculate the total electron number $N_{\\mathrm{e}} = \\sum_n f(E_n)$.\n    -   Compute the matrix of naive projection weights, $W^{\\mathrm{naive}}_{n\\alpha} = |c_{n,\\alpha}|^2$. The naive orbital occupancies are then $N_{\\alpha}^{\\mathrm{naive}} = \\sum_n W^{\\mathrm{naive}}_{n\\alpha} f(E_n)$.\n    -   Transform the eigenvectors: $\\mathbf{d}_n = S^{1/2} \\mathbf{c}_n$.\n    -   Compute the matrix of Löwdin projection weights, $W^{\\mathrm{L}}_{n\\alpha} = |d_{n,\\alpha}|^2$. The Löwdin occupancies are $N_{\\alpha}^{\\mathrm{L}} = \\sum_n W^{\\mathrm{L}}_{n\\alpha} f(E_n)$.\n5.  **Calculate diagnostics**:\n    -   $\\Delta_{\\mathrm{naive}} = \\left(\\sum_{\\alpha} N_{\\alpha}^{\\mathrm{naive}}\\right) - N_{\\mathrm{e}}$.\n    -   $\\Delta_{\\mathrm{L}} = \\left(\\sum_{\\alpha} N_{\\alpha}^{\\mathrm{L}}\\right) - N_{\\mathrm{e}}$.\n    -   $\\Delta_{\\max} = \\max_{\\alpha} \\left| N_{\\alpha}^{\\mathrm{naive}} - N_{\\alpha}^{\\mathrm{L}} \\right|$.\n\nThis procedure will be applied to each test case to quantify the error of the naive projection and the difference between the two schemes, which is expected to grow as the non-orthogonality (i.e., the off-diagonal elements of $S$) increases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import eigh\nfrom scipy.special import expit\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases and prints the results.\n    \"\"\"\n    \n    # Define the Boltzmann constant in eV/K.\n    k_B = 8.617333262145e-5\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (identity overlap)\n        {\n            \"H\": np.array([[0.0, -1.0], [-1.0, 0.5]]),\n            \"S\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"E_F\": 0.0,\n            \"T\": 300.0\n        },\n        # Case 2 (moderate non-orthogonality)\n        {\n            \"H\": np.array([[0.0, -1.0], [-1.0, 0.5]]),\n            \"S\": np.array([[1.0, 0.3], [0.3, 1.0]]),\n            \"E_F\": 0.0,\n            \"T\": 300.0\n        },\n        # Case 3 (three-orbital chain with strong overlap)\n        {\n            \"H\": np.array([[0.0, -1.0, 0.0], [-1.0, 0.3, -1.0], [0.0, -1.0, 0.6]]),\n            \"S\": np.array([[1.0, 0.6, 0.0], [0.6, 1.0, 0.6], [0.0, 0.6, 1.0]]),\n            \"E_F\": 0.2,\n            \"T\": 1000.0\n        },\n        # Case 4 (near-singular two-orbital overlap)\n        {\n            \"H\": np.array([[0.2, -0.4], [-0.4, -0.1]]),\n            \"S\": np.array([[1.0, 0.9], [0.9, 1.0]]),\n            \"E_F\": 0.1,\n            \"T\": 1.0\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        H = case[\"H\"]\n        S = case[\"S\"]\n        E_F = case[\"E_F\"]\n        T = case[\"T\"]\n\n        # Step 1: Solve the generalized eigenvalue problem Hc = ESc\n        # scipy.linalg.eigh returns S-normalized eigenvectors.\n        # Eigenvectors are returned as columns of C.\n        E_n, C = eigh(H, S)\n\n        # Step 2: Construct the matrix square root S^(1/2)\n        # S is real symmetric, so its eigenvectors are real and U.T = U_inv.\n        s_eigvals, U = np.linalg.eigh(S)\n        # Check for positive definiteness\n        if np.any(s_eigvals = 0):\n            # This should not happen for the given valid problem cases.\n            raise ValueError(\"Overlap matrix S is not positive definite.\")\n        s_sqrt_eigvals = np.sqrt(s_eigvals)\n        S_sqrt = U @ np.diag(s_sqrt_eigvals) @ U.T\n\n        # Step 3: Evaluate the Fermi-Dirac distribution for each energy level\n        # f(E) = 1 / (1 + exp((E - E_F) / (k_B * T)))\n        # We use scipy.special.expit(x) = 1 / (1 + exp(-x))\n        # So f(E) corresponds to expit(-x) where x = (E - E_F) / (k_B * T)\n        if T  0:\n            beta = 1.0 / (k_B * T)\n            x = beta * (E_n - E_F)\n            f_E_n = expit(-x)\n        else: # Zero temperature limit (step function)\n            f_E_n = np.where(E_n  E_F, 1.0, 0.0)\n            f_E_n[E_n == E_F] = 0.5 # Convention for equality\n\n        # Step 4: Compute occupancies\n        \n        # Total electron count\n        N_e = np.sum(f_E_n)\n\n        # The eigenvectors C are arranged column-wise.\n        # c_{n,alpha} is C[alpha, n].\n        # The sum is over n (axis=1 for row-wise operations).\n        c_n_alpha_sq = np.abs(C)**2\n        N_alpha_naive = np.sum(c_n_alpha_sq * f_E_n, axis=1)\n\n        # Transform coefficients to the Löwdin basis: d = S^(1/2) * c\n        D = S_sqrt @ C\n        d_n_alpha_sq = np.abs(D)**2\n        N_alpha_L = np.sum(d_n_alpha_sq * f_E_n, axis=1)\n\n        # Step 5: Calculate diagnostics\n\n        # Sum of naive projected occupancies\n        sum_N_alpha_naive = np.sum(N_alpha_naive)\n        \n        # Sum of Löwdin projected occupancies\n        sum_N_alpha_L = np.sum(N_alpha_L)\n\n        # Occupancy sum rule errors\n        delta_naive = sum_N_alpha_naive - N_e\n        delta_L = sum_N_alpha_L - N_e\n\n        # Maximum absolute orbital-wise deviation\n        delta_max = np.max(np.abs(N_alpha_naive - N_alpha_L))\n\n        results.extend([delta_naive, delta_L, delta_max])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3443144"}]}