{"hands_on_practices": [{"introduction": "A cornerstone of computational materials science is the ability to predict how atoms in a material will vibrate. These vibrational modes, or phonons, govern a material's thermal conductivity, heat capacity, and stability. This exercise [@problem_id:3446833] provides a hands-on implementation of lattice dynamics for a finite cluster of atoms, starting from first principles. You will construct the stiffness and mass matrices and solve the generalized eigenvalue problem $K u = \\lambda M u$ to find the vibrational frequencies, learning the crucial step of projecting out non-physical rigid-body modes.", "problem": "Consider a finite cluster of $N$ atoms in three-dimensional space ($\\mathrm{3D}$) with $3N$ displacement Degrees of Freedom (DOF). Let $M \\in \\mathbb{R}^{3N \\times 3N}$ be the diagonal mass matrix with $3 \\times 3$ blocks $m_i I_3$ for atom index $i \\in \\{1,\\dots,N\\}$ and mass $m_i$, and let $K \\in \\mathbb{R}^{3N \\times 3N}$ be the symmetric stiffness (Hessian) matrix arising from linearization of pairwise central spring interactions at mechanical equilibrium. The total potential energy in the small-displacement regime is given by the quadratic form\n$$\n\\Pi(u) = \\frac{1}{2} u^\\top K u,\n$$\nwhere $u \\in \\mathbb{R}^{3N}$ collects Cartesian displacements of all atoms. The generalized eigenvalue problem for undamped free vibrations is\n$$\nK u = \\lambda M u,\n$$\nwhere $\\lambda = \\omega^2$ with $\\omega$ the angular frequency. In the absence of external constraints, the rigid-body subspace is spanned by three translations and three rotations about the center of mass, and $K$ is positive semidefinite with nullspace containing those rigid-body modes.\n\nYour task is to implement, in a self-contained program, a mass-weighted projection that removes rigid-body modes and to compute the generalized spectrum of the projected operator on the non-rigid subspace. From first principles and well-tested facts in linear elasticity and classical mechanics, the rigid-body translation modes are displacements $u_i = t$ at each atom $i$, for $t \\in \\mathbb{R}^3$, and the rigid-body rotation modes about the center of mass position $r_{\\mathrm{cm}}$ are displacements $u_i = \\omega \\times (r_i - r_{\\mathrm{cm}})$ at atom $i$, for angular velocity vector $\\omega \\in \\mathbb{R}^3$. The mass-weighted inner product is defined as\n$$\n\\langle x, y \\rangle_M = x^\\top M y,\n$$\nand the orthogonal projection onto the $M$-orthogonal complement of the rigid-body subspace should be constructed and used to restrict the generalized eigenvalue problem.\n\nImplement the stiffness matrix $K$ for central springs that only resist extension along the interatomic line, using the well-tested per-spring contribution for a spring between atoms $i$ and $j$ with spring constant $k_{ij}$ and unit direction $n_{ij} = \\frac{r_j - r_i}{\\|r_j - r_i\\|}$:\n- The $3 \\times 3$ block contribution is $B_{ij} = k_{ij} \\, n_{ij} n_{ij}^\\top$.\n- Assemble $K$ by adding $B_{ij}$ to diagonal blocks $(i,i)$ and $(j,j)$, and subtracting $B_{ij}$ from off-diagonal blocks $(i,j)$ and $(j,i)$.\n\nUse the following test suite. In all cases, the edges are the complete graph on the atom indices (all pairs $i  j$), the center of mass is computed with the given $m_i$, and rotations are about $r_{\\mathrm{cm}}$. All quantities are dimensionless and should be treated in consistent arbitrary units.\n\n- Test case $1$ (happy path): $N = 4$ atoms at positions\n$$\nr_1 = (1,1,1), \\quad r_2 = (-1,-1,1), \\quad r_3 = (-1,1,-1), \\quad r_4 = (1,-1,-1),\n$$\nwith masses $m = [1,1,1,1]$ and uniform spring constants $k_{ij} = k_0$ with $k_0 = 50$.\n\n- Test case $2$ (heterogeneous masses): same positions as test case $1$, masses $m = [1.0,\\,2.0,\\,3.5,\\,0.8]$ and uniform spring constants $k_{ij} = k_0$ with $k_0 = 10$.\n\n- Test case $3$ (general geometry, heterogeneous parameters): $N = 5$ atoms at positions\n$$\nr_1 = (0.0,\\,0.0,\\,0.0), \\quad r_2 = (1.2,\\,-0.7,\\,0.3), \\quad r_3 = (-0.9,\\,1.1,\\,0.8), \\quad r_4 = (0.5,\\,0.4,\\,-1.5), \\quad r_5 = (-1.3,\\,-0.2,\\,0.9),\n$$\nwith masses $m = [1.0,\\,0.8,\\,1.5,\\,1.2,\\,0.9]$ and spring constants defined by\n$$\nk_{ij} = k_0 \\left(1 + 0.1 (i + j)\\right), \\quad \\text{with } k_0 = 5.0,\n$$\nfor each pair $(i,j)$ with $i  j$.\n\n- Test case $4$ (boundary case with near-singular stiffness): same positions and masses as test case $1$, and uniform spring constants $k_{ij} = k_0$ with $k_0 = 10^{-6}$.\n\nFor each test case, perform the following computational steps:\n1. Assemble $K$ and $M$.\n2. Construct a basis for the rigid-body subspace using three linearly independent translations and three linearly independent rotations about $r_{\\mathrm{cm}}$.\n3. Build the $M$-orthogonal projection onto the complement of the rigid-body subspace and extract an $M$-orthonormal basis for this complement.\n4. Restrict the generalized eigenvalue problem to this complement and compute all eigenvalues $\\lambda$.\n5. Report, for each test case, the smallest eigenvalue and a boolean indicating whether all eigenvalues are strictly positive within a numerical tolerance $\\epsilon = 10^{-10}$; that is, whether $\\lambda  \\epsilon$ for all eigenvalues in the complement.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each entry corresponds to a test case and is itself a two-element list of the form $[\\text{min\\_eigenvalue}, \\text{all\\_positive}]$. For example, the output format should be\n$$\n[[\\lambda_{\\min}^{(1)}, \\text{True}],[\\lambda_{\\min}^{(2)}, \\text{True}],[\\lambda_{\\min}^{(3)}, \\text{True}],[\\lambda_{\\min}^{(4)}, \\text{True}]]\n$$\nwith the actual numerical values replacing the placeholders.", "solution": "The provided problem is a well-posed and scientifically sound exercise in computational materials science, specifically in the area of lattice dynamics for a finite atomic cluster. It is grounded in the principles of classical mechanics and linear algebra. The task is to compute the vibrational spectrum of an atomic cluster after removing the non-vibrational, zero-frequency rigid-body modes. All provided data and definitions are standard, consistent, and sufficient to obtain a unique, meaningful solution. Therefore, the problem is valid, and we proceed with a detailed solution.\n\nThe fundamental physical model is the harmonic approximation of the interatomic potential energy, which is valid for small displacements $u \\in \\mathbb{R}^{3N}$ from a mechanical equilibrium configuration. The potential energy is given by the quadratic form $\\Pi(u) = \\frac{1}{2} u^\\top K u$, where $K \\in \\mathbb{R}^{3N \\times 3N}$ is the symmetric, positive semidefinite stiffness matrix (or Hessian). The kinetic energy is $T(\\dot{u}) = \\frac{1}{2} \\dot{u}^\\top M \\dot{u}$, where $M \\in \\mathbb{R}^{3N \\times 3N}$ is the diagonal, positive definite mass matrix. Applying Lagrange's equations of motion leads to the system of second-order ordinary differential equations $M \\ddot{u} + K u = 0$. Assuming harmonic solutions of the form $u(t) = u_0 e^{i\\omega t}$, we arrive at the generalized eigenvalue problem:\n$$\nK u = \\omega^2 M u\n$$\nLetting $\\lambda = \\omega^2$, we have the standard form $K u = \\lambda M u$. The eigenvalues $\\lambda$ are the squared angular frequencies of the normal modes of vibration, and the eigenvectors $u$ are the corresponding displacement patterns.\n\nThe mass matrix $M$ is a diagonal matrix comprising $N$ blocks of the form $m_i I_3$, where $m_i$ is the mass of the $i$-th atom and $I_3$ is the $3 \\times 3$ identity matrix.\n$$\nM = \\begin{pmatrix} m_1 I_3   \\\\  m_2 I_3   \\\\   \\ddots  \\\\    m_N I_3 \\end{pmatrix}\n$$\nThe stiffness matrix $K$ is assembled from contributions of pairwise central spring interactions. For a spring with constant $k_{ij}$ connecting atoms $i$ and $j$ at positions $r_i$ and $r_j$, the energy stored is proportional to the square of the change in length. This leads to a $3 \\times 3$ block contribution $B_{ij} = k_{ij} n_{ij} n_{ij}^\\top$, where $n_{ij} = \\frac{r_j - r_i}{\\|r_j - r_i\\|}$ is the unit vector along the line connecting the atoms. The full stiffness matrix $K$ is assembled by adding these blocks to the diagonal submatrices and subtracting them from the off-diagonal submatrices, reflecting the forces on the atoms:\n$$\nK_{ii} = \\sum_{j \\neq i} B_{ij}, \\quad K_{ij} = -B_{ij} \\text{ for } i \\neq j\n$$\n\nFor a finite, unconstrained cluster, there exist modes of motion that do not distort interatomic distances and thus do not store potential energy. These are the rigid-body modes: three translations and three rotations. These modes span the nullspace of the stiffness matrix $K$, meaning $Ku=0$ for any rigid-body mode $u$. Consequently, the generalized eigenvalue problem yields six zero eigenvalues ($\\lambda=0$). To study the internal vibrations of the cluster, these non-vibrational modes must be projected out.\n\nThis projection is performed in the space endowed with the mass-weighted inner product, $\\langle x, y \\rangle_M = x^\\top M y$. This inner product is physically motivated, as the kinetic energy is $\\frac{1}{2} \\langle \\dot{u}, \\dot{u} \\rangle_M$. The procedure to solve the eigenvalue problem on the subspace $M$-orthogonal to the rigid-body modes is as follows:\n\n1.  **Transformation to a Standard Eigenvalue Problem**: The generalized eigenvalue problem $K u = \\lambda M u$ can be converted to a standard eigenvalue problem. Since $M$ is positive definite, its Cholesky decomposition exists. For a diagonal $M$, we can simply define a diagonal matrix $L = M^{1/2}$ such that $M = LL^\\top = L^2$. Substituting $u = L^{-1} \\tilde{u}$ into the equation gives:\n    $$\n    K L^{-1} \\tilde{u} = \\lambda L L^{-1} \\tilde{u}\n    $$\n    Multiplying from the left by $L^{-1}$ (which is $(L^{-1})^\\top$ as $L$ is diagonal) yields:\n    $$\n    (L^{-1} K L^{-1}) \\tilde{u} = \\lambda \\tilde{u}\n    $$\n    This is a standard eigenvalue problem $\\tilde{K} \\tilde{u} = \\lambda \\tilde{u}$ for the transformed stiffness matrix $\\tilde{K} = L^{-1} K L^{-1}$.\n\n2.  **Identification of the Rigid-Body Subspace**: The six rigid-body modes must be constructed.\n    -   **Translations**: Three basis vectors are formed by setting the displacement of every atom to $(1,0,0)$, $(0,1,0)$, and $(0,0,1)$, respectively.\n    -   **Rotations**: First, the center of mass is computed: $r_{\\mathrm{cm}} = \\frac{\\sum_{i=1}^N m_i r_i}{\\sum_{i=1}^N m_i}$. The rotational modes correspond to infinitesimal rotations about $r_{\\mathrm{cm}}$. The displacement of atom $i$ for a rotation by an angular velocity vector $\\omega$ is $u_i = \\omega \\times (r_i - r_{\\mathrm{cm}})$. Three basis vectors are formed by choosing $\\omega$ to be $(1,0,0)$, $(0,1,0)$, and $(0,0,1)$.\n    These six vectors, each of size $3N$, form a basis for the rigid-body subspace. Let's collect them as columns of a matrix $V_{\\mathrm{rigid}} \\in \\mathbb{R}^{3N \\times 6}$.\n\n3.  **Construction of the Projection**: In the transformed coordinates, the rigid-body modes are given by the columns of $\\tilde{V}_{\\mathrm{rigid}} = L V_{\\mathrm{rigid}}$. We need to find the eigenvalues of $\\tilde{K}$ on the subspace orthogonal to the one spanned by the columns of $\\tilde{V}_{\\mathrm{rigid}}$.\n    A numerically robust way to find an orthonormal basis for this orthogonal complement is via Singular Value Decomposition (SVD). Let the SVD of $\\tilde{V}_{\\mathrm{rigid}}$ be $U \\Sigma W^\\top$. The matrix $U \\in \\mathbb{R}^{3N \\times 3N}$ is unitary, and its columns form a complete orthonormal basis for $\\mathbb{R}^{3N}$. If the rank of $\\tilde{V}_{\\mathrm{rigid}}$ is $d$ (which is $6$ for a non-collinear system), the first $d$ columns of $U$ span the same subspace as $\\tilde{V}_{\\mathrm{rigid}}$. The remaining $3N-d$ columns of $U$ form an orthonormal basis for its orthogonal complement. Let this basis be $\\tilde{Q}_{\\mathrm{comp}} = U[:, d:]$.\n\n4.  **Solving the Projected Problem**: Any vector $\\tilde{u}$ in the complement subspace can be written as a linear combination of the basis vectors: $\\tilde{u} = \\tilde{Q}_{\\mathrm{comp}} c$, where $c \\in \\mathbb{R}^{3N-d}$ is a vector of coefficients. Substituting this into the standard eigenvalue problem:\n    $$\n    \\tilde{K} (\\tilde{Q}_{\\mathrm{comp}} c) = \\lambda (\\tilde{Q}_{\\mathrm{comp}} c)\n    $$\n    Projecting onto the basis by multiplying from the left by $\\tilde{Q}_{\\mathrm{comp}}^\\top$:\n    $$\n    (\\tilde{Q}_{\\mathrm{comp}}^\\top \\tilde{K} \\tilde{Q}_{\\mathrm{comp}}) c = \\lambda (\\tilde{Q}_{\\mathrm{comp}}^\\top \\tilde{Q}_{\\mathrm{comp}}) c\n    $$\n    Since the columns of $\\tilde{Q}_{\\mathrm{comp}}$ are orthonormal, $\\tilde{Q}_{\\mathrm{comp}}^\\top \\tilde{Q}_{\\mathrm{comp}} = I_{3N-d}$. The problem reduces to a smaller, standard eigenvalue problem for a $(3N-d) \\times (3N-d)$ matrix $K_{\\mathrm{proj}} = \\tilde{Q}_{\\mathrm{comp}}^\\top \\tilde{K} \\tilde{Q}_{\\mathrm{comp}}$:\n    $$\n    K_{\\mathrm{proj}} c = \\lambda c\n    $$\n    The eigenvalues $\\lambda$ of $K_{\\mathrm{proj}}$ are the squared frequencies of the internal vibrational modes. For a stable cluster, all these eigenvalues must be strictly positive. The numerical implementation will compute these eigenvalues for each test case and report the minimum eigenvalue and whether all are positive within a given tolerance.", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import svd, eigh\n\ndef solve_vibrational_problem(positions, masses, k_func, N):\n    \"\"\"\n    Solves the vibrational problem for a cluster of N atoms.\n\n    Args:\n        positions (np.ndarray): (N, 3) array of atom positions.\n        masses (np.ndarray): (N,) array of atom masses.\n        k_func (callable): Function k_func(i, j) that returns the spring constant \n                           between atoms i and j (0-indexed).\n        N (int): Number of atoms.\n\n    Returns:\n        tuple: A tuple containing (min_eigenvalue, all_positive_flag).\n    \"\"\"\n    dim = 3\n    total_dof = dim * N\n    tol = 1e-10\n\n    # Step 1: Assemble Stiffness (K) and Mass (M) matrices\n    M_diag = np.repeat(masses, dim)\n    M = np.diag(M_diag)\n    L_inv = np.diag(1.0 / np.sqrt(M_diag))\n    L = np.diag(np.sqrt(M_diag))\n\n    K = np.zeros((total_dof, total_dof))\n    for i in range(N):\n        for j in range(i + 1, N):\n            r_i = positions[i]\n            r_j = positions[j]\n            d_ij = r_j - r_i\n            dist = np.linalg.norm(d_ij)\n            if dist  tol:\n                continue\n            n_ij = d_ij / dist\n            \n            k_ij = k_func(i, j)\n            B_ij = k_ij * np.outer(n_ij, n_ij)\n            \n            s_i, s_j = dim * i, dim * j\n            K[s_i:s_i+dim, s_i:s_i+dim] += B_ij\n            K[s_j:s_j+dim, s_j:s_j+dim] += B_ij\n            K[s_i:s_i+dim, s_j:s_j+dim] -= B_ij\n            K[s_j:s_j+dim, s_i:s_i+dim] -= B_ij\n\n    # Step 2: Construct a basis for the rigid-body subspace\n    # Center of mass calculation\n    total_mass = np.sum(masses)\n    r_cm = np.sum(masses[:, np.newaxis] * positions, axis=0) / total_mass\n    rel_pos = positions - r_cm\n\n    V_rigid = np.zeros((total_dof, dim * 2))\n\n    # 3 translation modes\n    for k in range(dim):\n        V_rigid[k::dim, k] = 1.0\n\n    # 3 rotation modes\n    for k in range(dim):\n        omega = np.zeros(dim)\n        omega[k] = 1.0\n        # rot_disp_k = cross(omega, rel_pos)\n        rot_disp_k = np.cross(omega, rel_pos, axisa=0, axisb=1)\n        V_rigid[:, dim + k] = rot_disp_k.flatten()\n\n    # Step 3: Build an M-orthonormal basis for the complement of the rigid-body subspace\n    # Transform rigid modes to the mass-weighted coordinate system\n    V_rigid_tilde = L @ V_rigid\n    \n    # Use SVD to find an orthonormal basis for the complement space\n    U, s, _ = svd(V_rigid_tilde, full_matrices=True)\n    \n    # The rank of V_rigid_tilde determines the dimension of the rigid subspace\n    rank = np.sum(s > tol)\n    \n    Q_comp_tilde = U[:, rank:]\n\n    # Step 4: Restrict the generalized eigenvalue problem and compute eigenvalues\n    # Transform K to the mass-weighted coordinate system\n    K_tilde = L_inv @ K @ L_inv\n\n    # Project K_tilde onto the complement subspace\n    K_proj = Q_comp_tilde.T @ K_tilde @ Q_comp_tilde\n    \n    # The projected matrix must be symmetric. Enforce it to handle small numerical errors.\n    K_proj = 0.5 * (K_proj + K_proj.T)\n\n    # Compute eigenvalues of the projected problem\n    eigenvalues = eigh(K_proj, eigvals_only=True)\n\n    # Step 5: Report results\n    if len(eigenvalues) == 0:\n        min_eigenvalue = 0.0\n        all_positive = True\n    else:\n        min_eigenvalue = np.min(eigenvalues)\n        all_positive = bool(np.all(eigenvalues > tol))\n\n    return [min_eigenvalue, all_positive]\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the solver for each case.\n    \"\"\"\n    r_case1 = np.array([\n        [1.0, 1.0, 1.0],\n        [-1.0, -1.0, 1.0],\n        [-1.0, 1.0, -1.0],\n        [1.0, -1.0, -1.0]\n    ])\n    \n    r_case3 = np.array([\n        [0.0, 0.0, 0.0],\n        [1.2, -0.7, 0.3],\n        [-0.9, 1.1, 0.8],\n        [0.5, 0.4, -1.5],\n        [-1.3, -0.2, 0.9]\n    ])\n\n    test_cases = [\n        {\n            \"N\": 4,\n            \"positions\": r_case1,\n            \"masses\": np.array([1.0, 1.0, 1.0, 1.0]),\n            \"k_func\": lambda i, j: 50.0\n        },\n        {\n            \"N\": 4,\n            \"positions\": r_case1,\n            \"masses\": np.array([1.0, 2.0, 3.5, 0.8]),\n            \"k_func\": lambda i, j: 10.0\n        },\n        {\n            \"N\": 5,\n            \"positions\": r_case3,\n            \"masses\": np.array([1.0, 0.8, 1.5, 1.2, 0.9]),\n            \"k_func\": lambda i, j: 5.0 * (1.0 + 0.1 * ((i + 1) + (j + 1)))\n        },\n        {\n            \"N\": 4,\n            \"positions\": r_case1,\n            \"masses\": np.array([1.0, 1.0, 1.0, 1.0]),\n            \"k_func\": lambda i, j: 1e-6\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_vibrational_problem(case[\"positions\"], case[\"masses\"], case[\"k_func\"], case[\"N\"])\n        results.append(result)\n\n    # Format the results into the required string representation without extra spaces\n    result_strings = []\n    for res in results:\n        # Custom string formatting to match problem specification\n        min_eig_str = f\"{res[0]:.8e}\" if isinstance(res[0], float) else str(res[0])\n        bool_str = 'True' if res[1] else 'False'\n        result_strings.append(f\"[{min_eig_str},{bool_str}]\")\n\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```", "id": "3446833"}, {"introduction": "The eigenvalues of a Hamiltonian give us the allowed energies, but the corresponding eigenvectors hold the key to understanding the spatial nature of quantum states. This practice [@problem_id:3446844] delves into this by exploring the fascinating phenomenon of localization in the Aubry–André model, a canonical model for quasiperiodic systems. By diagonalizing the Hamiltonian and analyzing the resulting eigenstates, you will learn to compute and interpret metrics like the participation ratio and level spacing statistics to distinguish between spatially extended and localized electronic states.", "problem": "Consider the one-dimensional tight-binding Hamiltonian with a quasiperiodic on-site modulation known as the Aubry–André (also called the almost Mathieu) model. In computational materials science, this model is a standard setting to study localization transitions in quasiperiodic lattices using matrix diagonalization and eigenvalue analysis. The model is defined on a chain of length $N$ with open boundary conditions, hopping amplitude $t$ between nearest neighbors, and an on-site modulation of strength $\\lambda$ with an incommensurate frequency approximated by a rational number. The Hamiltonian matrix $\\mathbf{H} \\in \\mathbb{R}^{N \\times N}$ in the site basis $\\{|i\\rangle\\}_{i=0}^{N-1}$ is specified by\n$$\nH_{i,j} = t \\, (\\delta_{i,j+1} + \\delta_{i,j-1}) + \\lambda \\cos\\!\\big(2\\pi \\alpha \\, i + \\phi \\big) \\, \\delta_{i,j},\n$$\nwhere $i \\in \\{0,1,\\dots,N-1\\}$, $t \\in \\mathbb{R}$, $\\lambda \\in \\mathbb{R}$, $\\alpha \\in \\mathbb{R}$ is an irrational number approximated by a rational $p/q$, and $\\phi \\in \\mathbb{R}$ is a phase. Open boundary conditions are enforced by the fact that $H_{-1,0}=H_{N,N-1}=0$, which in practice means only the nearest-neighbor off-diagonal elements within the chain are nonzero. The fundamental base for the computation is the matrix eigenvalue problem,\n$$\n\\mathbf{H} \\, \\psi_n = E_n \\, \\psi_n,\n$$\nwhere $E_n \\in \\mathbb{R}$ are the eigenvalues and $\\psi_n \\in \\mathbb{R}^N$ are the corresponding normalized eigenvectors satisfying $\\sum_{i=0}^{N-1} |\\psi_n(i)|^2 = 1$. To quantify spatial extension versus localization of eigenstates, use the participation ratio defined for a normalized eigenvector by\n$$\nP_n = \\frac{\\Big(\\sum_{i=0}^{N-1} |\\psi_n(i)|^2 \\Big)^2}{\\sum_{i=0}^{N-1} |\\psi_n(i)|^4} = \\frac{1}{\\sum_{i=0}^{N-1} |\\psi_n(i)|^4},\n$$\nand the normalized participation ratio $p_n = P_n/N \\in (0,1]$. To quantify eigenvalue statistics without unfolding, use the ratio of consecutive level spacings defined for the ordered spectrum $E_0 \\le E_1 \\le \\dots \\le E_{N-1}$. Denoting spacings by $\\delta_k = E_{k+1} - E_k$ for $k \\in \\{0,1,\\dots,N-2\\}$, define for $k \\in \\{0,1,\\dots,N-3\\}$ the ratio\n$$\nr_k = \\frac{\\min(\\delta_k,\\delta_{k+1})}{\\max(\\delta_k,\\delta_{k+1})},\n$$\nand its average $r = \\frac{1}{N-2} \\sum_{k=0}^{N-3} r_k$ after excluding any undefined cases where a denominator would vanish.\n\nYour task is to implement a program that, for each test case below, constructs $\\mathbf{H}$, diagonalizes it numerically to obtain $\\{E_n,\\psi_n\\}$, computes the average normalized participation ratio\n$$\n\\overline{p} = \\frac{1}{N} \\sum_{n=0}^{N-1} \\frac{1}{N \\sum_{i=0}^{N-1} |\\psi_n(i)|^4},\n$$\nand the mean ratio of consecutive level spacings $r$ as defined above. Use $t=1$ in all cases. Angles are dimensionless and measured in radians. There are no physical units in this problem; all quantities are dimensionless.\n\nTest suite parameters are specified as tuples $(N,\\alpha,\\lambda,\\phi)$ with $t=1$ fixed:\n\n- Case A (extended regime candidate): $(N,\\alpha,\\lambda,\\phi) = (144,\\, 89/144,\\, 1.5,\\, 0.0)$.\n- Case B (critical regime candidate): $(N,\\alpha,\\lambda,\\phi) = (144,\\, 89/144,\\, 2.0,\\, 0.0)$.\n- Case C (localized regime candidate): $(N,\\alpha,\\lambda,\\phi) = (144,\\, 89/144,\\, 3.0,\\, 0.0)$.\n- Case D (no modulation baseline): $(N,\\alpha,\\lambda,\\phi) = (144,\\, 89/144,\\, 0.0,\\, 0.0)$.\n- Case E (different approximant and phase, localized): $(N,\\alpha,\\lambda,\\phi) = (89,\\, 55/89,\\, 3.0,\\, 0.3)$.\n\nYour program must output a single line containing a list of results, one per case, in the same order as listed. Each result must be the list $[\\lambda, \\overline{p}, r]$ with all three entries given as decimal numbers rounded to six digits after the decimal point. The entire output must be a single line in the form\n$$\n\\big[\\,[\\lambda_1,\\overline{p}_1,r_1],\\,[\\lambda_2,\\overline{p}_2,r_2],\\,\\dots\\,\\big].\n$$\nNo additional text should be printed.", "solution": "We start from the matrix eigenvalue problem for a real symmetric Hamiltonian $\\mathbf{H} \\in \\mathbb{R}^{N \\times N}$, which guarantees a complete set of orthonormal eigenvectors and real eigenvalues. The Aubry–André Hamiltonian on a one-dimensional chain with open boundary conditions is defined by hopping of amplitude $t$ between nearest neighbors and an on-site modulation $\\lambda \\cos(2\\pi \\alpha i + \\phi)$ with a frequency $\\alpha$ that is irrational in the infinite-size limit and approximated by rationals in finite systems. The indices $i$ are taken from $0$ to $N-1$, and $\\delta_{i,j}$ denotes the Kronecker delta.\n\nThe computational workflow is as follows:\n\n1. Matrix construction. For each test case $(N,\\alpha,\\lambda,\\phi)$ with $t=1$, construct $\\mathbf{H}$ by setting:\n   - For $i \\in \\{0,1,\\dots,N-1\\}$, the diagonal element\n     $$\n     H_{i,i} = \\lambda \\cos(2\\pi \\alpha i + \\phi).\n     $$\n   - For $i \\in \\{0,1,\\dots,N-2\\}$, the off-diagonal nearest-neighbor elements\n     $$\n     H_{i,i+1} = H_{i+1,i} = t = 1.\n     $$\n   All other elements are zero, which enforces open boundary conditions.\n\n2. Diagonalization. Solve\n   $$\n   \\mathbf{H}\\,\\psi_n = E_n \\,\\psi_n,\n   $$\n   using a routine for real symmetric matrices, which yields eigenvalues $\\{E_n\\}_{n=0}^{N-1}$ in nondecreasing order and orthonormal eigenvectors $\\{\\psi_n\\}_{n=0}^{N-1}$ satisfying\n   $$\n   \\sum_{i=0}^{N-1} |\\psi_n(i)|^2 = 1.\n   $$\n   The orthonormality ensures numerical stability and allows direct use of the definition of the participation ratio.\n\n3. Participation ratio. For each normalized eigenvector $\\psi_n$, compute the participation ratio using the definition\n   $$\n   P_n = \\frac{\\left(\\sum_{i=0}^{N-1} |\\psi_n(i)|^2\\right)^2}{\\sum_{i=0}^{N-1} |\\psi_n(i)|^4} = \\frac{1}{\\sum_{i=0}^{N-1} |\\psi_n(i)|^4}.\n   $$\n   The equality on the right follows from the normalization $\\sum_i |\\psi_n(i)|^2 = 1$. The normalized participation ratio $p_n = P_n/N \\in (0,1]$ measures the fraction of the system effectively occupied by the eigenstate, with $p_n \\approx 1$ indicating a spatially extended state and $p_n \\ll 1$ indicating localization over a small number of sites. Compute the mean normalized participation ratio\n   $$\n   \\overline{p} = \\frac{1}{N} \\sum_{n=0}^{N-1} \\frac{1}{N \\sum_{i=0}^{N-1} |\\psi_n(i)|^4 }.\n   $$\n\n4. Eigenvalue spacing statistics. Sort the eigenvalues in ascending order (the diagonalization routine for symmetric matrices provides them already sorted). Compute spacings $\\delta_k = E_{k+1} - E_k$ for $k \\in \\{0,1,\\dots,N-2\\}$. Then compute the ratio of consecutive gaps\n   $$\n   r_k = \\frac{\\min(\\delta_k, \\delta_{k+1})}{\\max(\\delta_k, \\delta_{k+1})}\n   $$\n   for $k \\in \\{0,1,\\dots,N-3\\}$, excluding any terms where the denominator would be zero to avoid division by zero. The mean ratio\n   $$\n   r = \\frac{1}{M} \\sum_{k} r_k,\n   $$\n   where $M$ is the number of valid $r_k$, is a dimensionless measure of level repulsion: for strongly localized spectra akin to uncorrelated levels, $r$ tends to values characteristic of Poisson statistics, while for extended states with level repulsion, $r$ is typically larger. The use of ratios avoids the need for spectral unfolding.\n\n5. Test suite and output. For each of the provided test cases, perform steps $1$–$4$ to obtain $(\\lambda, \\overline{p}, r)$. Assemble the results in the specified order into a list of lists $[\\,[\\lambda_1,\\overline{p}_1,r_1],\\dots]$ and print as a single line. Round each floating-point number to six digits after the decimal point to produce a concise, testable output.\n\nAlgorithmic design details and numerical considerations:\n- The Hamiltonian is tridiagonal with a cosine diagonal; the dimension $N$ in the test suite is small enough for dense diagonalization with a symmetric solver to be computationally trivial.\n- Because $\\mathbf{H}$ is real symmetric, $\\psi_n$ can be taken real, which simplifies absolute value operations to squares of real entries.\n- The normalization of eigenvectors from the solver guarantees that $P_n$ can be computed robustly as $1/\\sum_i |\\psi_n(i)|^4$, but for numerical safety one can compute the numerator $(\\sum_i |\\psi_n(i)|^2)^2$ and divide by $\\sum_i |\\psi_n(i)|^4$. Both yield the same value within floating-point tolerance.\n- The ratio $r_k$ is bounded in $[0,1]$, providing a well-conditioned statistic without rescaling.\n- The quasiperiodic frequency $\\alpha$ is approximated by Fibonacci ratios $89/144$ and $55/89$, which are standard rational approximants to the inverse golden ratio and provide high-quality incommensurability for finite chains.\n\nThe final program implements this pipeline deterministically and prints the results in the exact required single-line format.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef build_hamiltonian(N: int, alpha: float, lam: float, phi: float, t: float = 1.0) - np.ndarray:\n    \"\"\"\n    Construct the Aubry–André Hamiltonian matrix for a 1D chain with open boundary conditions.\n\n    H_{i,i}   = lam * cos(2*pi*alpha*i + phi)\n    H_{i,i+1} = H_{i+1,i} = t\n\n    Parameters\n    ----------\n    N : int\n        System size (number of lattice sites).\n    alpha : float\n        Quasiperiodic frequency (rational approximant of an irrational).\n    lam : float\n        Modulation strength lambda.\n    phi : float\n        Phase offset in radians.\n    t : float\n        Nearest-neighbor hopping amplitude (default 1.0).\n\n    Returns\n    -------\n    H : np.ndarray\n        Real symmetric Hamiltonian matrix of shape (N, N).\n    \"\"\"\n    H = np.zeros((N, N), dtype=np.float64)\n    i = np.arange(N, dtype=np.float64)\n    H[np.arange(N), np.arange(N)] = lam * np.cos(2.0 * np.pi * alpha * i + phi)\n    offdiag_indices = np.arange(N - 1)\n    H[offdiag_indices, offdiag_indices + 1] = t\n    H[offdiag_indices + 1, offdiag_indices] = t\n    return H\n\ndef participation_ratio(evecs: np.ndarray) - float:\n    \"\"\"\n    Compute the mean normalized participation ratio over all eigenvectors.\n\n    Parameters\n    ----------\n    evecs : np.ndarray\n        Eigenvectors as columns, shape (N, N), assumed normalized.\n\n    Returns\n    -------\n    pbar : float\n        Mean of P_n / N over n, where P_n = 1 / sum_i |psi_n(i)|^4.\n    \"\"\"\n    # evecs are real for a real symmetric matrix, but compute generically\n    psi2 = evecs**2  # since real; otherwise use np.abs(evecs)**2\n    denom = np.sum(psi2**2, axis=0)  # sum_i |psi_n(i)|^4 for each n\n    # Avoid division by zero (should not happen for normalized, nonzero vectors)\n    denom = np.where(denom == 0.0, np.finfo(np.float64).tiny, denom)\n    Pn = 1.0 / denom  # since sum_i |psi|^2 = 1 by normalization\n    N = evecs.shape[0]\n    pn_norm = Pn / N\n    return float(np.mean(pn_norm))\n\ndef mean_spacing_ratio(evals: np.ndarray) - float:\n    \"\"\"\n    Compute the mean ratio of consecutive level spacings, r = min(delta_k, delta_{k+1}) / max(...).\n\n    Parameters\n    ----------\n    evals : np.ndarray\n        Sorted eigenvalues in ascending order.\n\n    Returns\n    -------\n    r_mean : float\n        Mean ratio r over valid k.\n    \"\"\"\n    # Ensure sorted ascending\n    E = np.sort(evals)\n    s = np.diff(E)\n    if s.size  2:\n        return float('nan')\n    s_left = s[:-1]\n    s_right = s[1:]\n    denom = np.maximum(s_left, s_right)\n    # Exclude zeros to avoid division by zero\n    valid = denom  0.0\n    if not np.any(valid):\n        return 0.0\n    r_vals = np.minimum(s_left[valid], s_right[valid]) / denom[valid]\n    return float(np.mean(r_vals))\n\ndef analyze_case(N: int, alpha: float, lam: float, phi: float, t: float = 1.0):\n    \"\"\"\n    Build H, diagonalize, and compute average normalized participation ratio and mean spacing ratio.\n    \"\"\"\n    H = build_hamiltonian(N, alpha, lam, phi, t)\n    # eigh returns eigenvalues in ascending order and corresponding eigenvectors as columns\n    evals, evecs = np.linalg.eigh(H)\n    pbar = participation_ratio(evecs)\n    rmean = mean_spacing_ratio(evals)\n    return pbar, rmean\n\ndef solve():\n    # Define the test cases from the problem statement: (N, alpha, lambda, phi)\n    test_cases = [\n        (144, 89/144, 1.5, 0.0),  # Case A\n        (144, 89/144, 2.0, 0.0),  # Case B\n        (144, 89/144, 3.0, 0.0),  # Case C\n        (144, 89/144, 0.0, 0.0),  # Case D\n        (89,  55/89,  3.0, 0.3),  # Case E\n    ]\n\n    results = []\n    for N, alpha, lam, phi in test_cases:\n        pbar, rmean = analyze_case(N, alpha, lam, phi, t=1.0)\n        # Round to 6 decimals as specified\n        lam_s = f\"{lam:.6f}\"\n        pbar_s = f\"{pbar:.6f}\"\n        rmean_s = f\"{rmean:.6f}\"\n        results.append(f\"[{lam_s},{pbar_s},{rmean_s}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3446844"}, {"introduction": "In solid-state physics, plotting energy eigenvalues as a function of crystal momentum gives us the electronic band structure, a fingerprint of a material's electronic properties. A subtle but critical challenge arises because standard numerical eigensolvers sort eigenvalues by magnitude, which can incorrectly swap band identities at crossings or avoided crossings. This practice [@problem_id:3446748] addresses this head-on by guiding you to implement a robust protocol based on maximizing eigenvector overlap, ensuring the continuous and physically correct tracking of electronic bands across the Brillouin zone.", "problem": "Consider a family of finite-dimensional Hermitian eigenvalue problems arising in model Hamiltonians for crystalline solids and their deformations: for each value of a scalar parameter $t \\in \\mathbb{R}$ (for example, a crystal momentum component $k$ within a Brillouin zone, or a scalar strain), one has a Hermitian matrix $H(t) \\in \\mathbb{C}^{n \\times n}$ and seeks eigenpairs $\\{(\\lambda_a(t), \\mathbf{u}_a(t))\\}_{a=1}^n$ defined by $H(t)\\,\\mathbf{u}_a(t) = \\lambda_a(t)\\,\\mathbf{u}_a(t)$ with $\\{\\mathbf{u}_a(t)\\}_{a=1}^n$ forming an orthonormal basis of $\\mathbb{C}^n$. In computational materials science, band indexing must remain continuous as $t$ varies, even through near-degeneracies and crossings, so that the $a$-th tracked band represents a continuous band function rather than a locally sorted-by-value label.\n\nFundamental base:\n- For a Hermitian matrix $H(t)$, there exists a unitary matrix $U(t)$ such that $U(t)^\\dagger H(t) U(t) = \\Lambda(t)$ with $\\Lambda(t)$ diagonal and $U(t)$ whose columns are the orthonormal eigenvectors $\\mathbf{u}_a(t)$. The columns are defined up to multiplication by complex phases, and any orthonormal basis of a degenerate eigenspace is valid.\n- When eigenvalues are isolated (no degeneracy), eigenvectors can be chosen to vary continuously with $t$, up to a phase. When eigenvalues are degenerate, only the degenerate subspace is continuous; any orthonormal basis within that subspace represents the same physical subspace.\n\nTask:\n- Derive, from these principles, a parameter-continuous protocol to assign, at discrete parameter values $t_0,\\dots,t_m$, a consistent ordering of eigenpairs $\\{(\\lambda_a(t_i), \\mathbf{u}_a(t_i))\\}_{a=1}^n$ such that band labels $a$ are transported from $t_i$ to $t_{i+1}$ in a way that optimizes continuity. Your protocol must be formulated in terms of first principles of Hermitian eigenproblems and orthonormality, without relying on ad hoc heuristics based on eigenvalue magnitudes. It must produce a one-to-one assignment between the eigenvectors at $t_i$ and those at $t_{i+1}$ that is stable under near-degeneracy and exact degeneracy.\n- Implement your protocol as a program that, for each test case below, computes a scalar continuity score defined as follows. For each consecutive pair $(t_i,t_{i+1})$, use your protocol to establish a one-to-one matching between the $n$ eigenvectors at $t_i$ and those at $t_{i+1}$. For each matched pair $(\\mathbf{u}_a(t_i), \\mathbf{u}_a(t_{i+1}))$, compute the squared inner product $|\\langle \\mathbf{u}_a(t_i), \\mathbf{u}_a(t_{i+1}) \\rangle|^2$ using the standard complex Euclidean inner product. Define the per-step normalized continuity at $(t_i,t_{i+1})$ as\n$$\nC(t_i,t_{i+1}) \\equiv \\frac{1}{n} \\sum_{a=1}^n \\left|\\langle \\mathbf{u}_a(t_i), \\mathbf{u}_a(t_{i+1}) \\rangle\\right|^2.\n$$\nDefine the overall continuity score for a test as the arithmetic mean of $C(t_i,t_{i+1})$ over all $i$ from $0$ to $m-1$:\n$$\n\\overline{C} \\equiv \\frac{1}{m}\\sum_{i=0}^{m-1} C(t_i,t_{i+1}).\n$$\n- Your implementation should diagonalize each $H(t_i)$ using a numerically stable method for Hermitian matrices and perform the matching step robustly.\n\nTest suite:\n- Test case $1$ (exact crossing, two bands): $n=2$, $H(k) = \\begin{pmatrix} k  0 \\\\ 0  -k \\end{pmatrix}$, with $k \\in \\{-1.0,-0.5,0.0,0.5,1.0\\}$.\n- Test case $2$ (avoided crossing, two bands): $n=2$, $H(k) = \\begin{pmatrix} k  \\delta \\\\ \\delta  -k \\end{pmatrix}$ with $\\delta = 0.05$, with $k \\in \\{-1.0,-0.5,0.0,0.5,1.0\\}$.\n- Test case $3$ (three bands, nontrivial coupling reminiscent of a simple tight-binding model): $n=3$, $H(k) = \\begin{pmatrix} 2\\cos k  1  0 \\\\ 1  -\\cos k  1 \\\\ 0  1  0.5 \\cos k \\end{pmatrix}$, with $k \\in \\{-\\pi, -\\tfrac{3\\pi}{4}, -\\tfrac{\\pi}{2}, -\\tfrac{\\pi}{4}, 0, \\tfrac{\\pi}{4}, \\tfrac{\\pi}{2}, \\tfrac{3\\pi}{4}, \\pi\\}$.\n- Test case $4$ (exact degeneracy in a rotating subspace): $n=3$, $H(k) = R(\\theta(k)) \\,\\mathrm{diag}(0,0,\\sin k)\\, R(\\theta(k))^\\top$ with $R(\\theta) = \\begin{pmatrix} \\cos\\theta  -\\sin\\theta  0 \\\\ \\sin\\theta  \\cos\\theta  0 \\\\ 0  0  1 \\end{pmatrix}$ and $\\theta(k) = 0.2\\,k$, with $k \\in \\{-0.8,-0.4,0.0,0.4,0.8\\}$. Note that the first two eigenvalues are exactly degenerate for all $k$, while the corresponding eigenvectors rotate within the degenerate subspace as $k$ varies.\n\nAngle units are in radians wherever trigonometric functions are used. No physical units apply to the matrices or the results.\n\nOutput specification:\n- For each of the $4$ test cases, compute the scalar $\\overline{C}$ as defined above.\n- Your program should produce a single line of output containing the four results as a comma-separated list enclosed in square brackets, with each value rounded to six decimal places. For example, an output could look like $[0.999999,0.987654,0.954321,1.000000]$.", "solution": "The problem presented requires the development and implementation of a rigorous protocol for maintaining the continuous identity of eigenstates (bands) of a parameter-dependent Hermitian Hamiltonian, $H(t)$. Standard numerical diagonalization routines typically return eigenvalues sorted by magnitude, which leads to discontinuous and physically incorrect band indexing when eigenvalue crossings or avoided crossings occur. A robust protocol must be founded on first principles of quantum mechanics and linear algebra, rather than on eigenvalue sorting, which is merely a convention.\n\nThe fundamental principle guiding our derivation is that for a sufficiently small change in the parameter $t$, from $t_i$ to $t_{i+1}$, the physical eigenstates themselves must evolve continuously. The eigenvector $\\mathbf{u}_a(t_{i+1})$ associated with band $a$ must be the one that is \"closest\" to the eigenvector $\\mathbf{u}_a(t_i)$ from the previous step. In the Hilbert space of states, the measure of \"closeness\" or alignment between two normalized state vectors, $\\mathbf{u}$ and $\\mathbf{v}$, is given by the magnitude of their inner product, $|\\langle \\mathbf{u}, \\mathbf{v} \\rangle|$. Therefore, the core of our protocol will be to match eigenvectors between consecutive steps by maximizing this overlap.\n\nLet us formalize the protocol. Assume at step $t_i$, we have an ordered set of orthonormal eigenvectors $\\{\\mathbf{u}_a(t_i)\\}_{a=1}^n$. For the initial step $t_0$, this ordering can be arbitrarily chosen, for instance, by sorting the corresponding eigenvalues. At the next step, $t_{i+1}$, we compute the eigenpairs of $H(t_{i+1})$ using a standard numerical eigensolver. This yields a set of eigenvalues and a corresponding set of orthonormal eigenvectors, which we shall denote as $\\{\\mathbf{v}_b(t_{i+1})\\}_{b=1}^n$. This new set is unordered with respect to the continuous band indices we seek to preserve.\n\nTo establish the correct one-to-one correspondence between the reference set $\\{\\mathbf{u}_a(t_i)\\}$ and the new set $\\{\\mathbf{v}_b(t_{i+1})\\}$, we construct an $n \\times n$ overlap matrix, $S$, whose elements are defined as the squared magnitudes of the inner products between the eigenvectors from the two steps:\n$$\nS_{ab} = \\left|\\langle \\mathbf{u}_a(t_i), \\mathbf{v}_b(t_{i+1}) \\rangle\\right|^2 = \\left|\\mathbf{u}_a(t_i)^\\dagger \\mathbf{v}_b(t_{i+1})\\right|^2\n$$\nThe value $S_{ab}$ quantifies the projection of the new eigenvector $\\mathbf{v}_b(t_{i+1})$ onto the old eigenvector $\\mathbf{u}_a(t_i)$. Our objective is to find a permutation $\\pi$ of the indices $\\{1, 2, \\dots, n\\}$ that maximizes the total overlap of the matched pairs. Mathematically, we seek to find the permutation $\\pi \\in S_n$ that maximizes the sum:\n$$\n\\sum_{a=1}^n S_{a, \\pi(a)}\n$$\nThis is a classic problem in combinatorial optimization known as the assignment problem or maximum weight bipartite matching. It can be solved efficiently using algorithms such as the Hungarian algorithm or other linear programming techniques. By solving this problem, we find the optimal mapping that associates each reference eigenvector $\\mathbf{u}_a(t_i)$ with a unique new eigenvector $\\mathbf{v}_{\\pi(a)}(t_{i+1})$.\n\nThis procedure is robust in all scenarios, including degeneracies. If two or more eigenvalues are degenerate, the numerical solver returns an arbitrary orthonormal basis for the corresponding eigenspace. The assignment protocol naturally handles this by finding the basis for the new eigenspace that has the maximum possible overlap with the basis of the old eigenspace, thus ensuring the continuity of the tracked subspace as a whole. The use of the squared magnitude $|\\cdot|^2$ makes the procedure independent of the arbitrary complex phase of the eigenvectors.\n\nOnce the optimal permutation $\\pi$ is determined, the correctly ordered eigenvectors for step $t_{i+1}$ are given by $\\mathbf{u}_a(t_{i+1}) = \\mathbf{v}_{\\pi(a)}(t_{i+1})$ for $a=1, \\dots, n$. The corresponding eigenvalues are reordered accordingly. This new ordered set $\\{\\mathbf{u}_a(t_{i+1})\\}$ serves as the reference for the subsequent step, $t_{i+2}$.\n\nThe problem then requires the calculation of a continuity score. The per-step normalized continuity, $C(t_i, t_{i+1})$, is defined as the average of the maximized squared overlaps:\n$$\nC(t_i,t_{i+1}) = \\frac{1}{n} \\sum_{a=1}^n \\left|\\langle \\mathbf{u}_a(t_i), \\mathbf{u}_a(t_{i+1}) \\rangle\\right|^2 = \\frac{1}{n} \\sum_{a=1}^n S_{a, \\pi(a)}\n$$\nwhere $\\mathbf{u}_a(t_{i+1})$ now refers to the correctly reordered eigenvector. A value of $C=1$ indicates perfect continuity, where each eigenvector at $t_i$ evolves into its counterpart at $t_{i+1}$ with no projection onto other orthogonal states. The overall continuity score, $\\overline{C}$, is the arithmetic mean of these per-step scores over all intervals $(t_i, t_{i+1})$.\n\nThe implementation will proceed as follows:\n$1$. For each test case, generate the sequence of matrices $\\{H(t_i)\\}_{i=0}^m$.\n$2$. Diagonalize $H(t_0)$ to obtain the initial reference eigenvectors $U_0 = [\\mathbf{u}_1(t_0), \\dots, \\mathbf{u}_n(t_0)]$.\n$3$. Iterate from $i=0$ to $m-1$:\n    a. Let the reference eigenvectors be $U_{prev} = U_i$.\n    b. Diagonalize $H(t_{i+1})$ to get the raw new eigenvectors `U_curr,raw`.\n    c. Compute the overlap matrix $S_{ab} = |\\left(U_{prev}^\\dagger U_{curr,raw}\\right)_{ab}|^2$.\n    d. Solve the assignment problem for the cost matrix $-S$ to find the column indices `col_ind` that maximize the overlap sum.\n    e. Calculate the per-step continuity $C(t_i,t_{i+1}) = \\frac{1}{n} \\sum_a S_{a, \\text{col\\_ind}[a]}$.\n    f. Reorder the columns of `U_curr,raw` using `col_ind` to get the new reference eigenvectors `U_{i+1}`.\n$4$. Compute the average of the stored per-step continuity scores to obtain $\\overline{C}$.\nThis procedure is applied to each of the four specified test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import linear_sum_assignment\n\ndef get_case1_matrices():\n    \"\"\"Generates matrices for Test Case 1.\"\"\"\n    ks = np.array([-1.0, -0.5, 0.0, 0.5, 1.0])\n    matrices = []\n    for k in ks:\n        H = np.array([[k, 0.0], [0.0, -k]], dtype=complex)\n        matrices.append(H)\n    return matrices\n\ndef get_case2_matrices():\n    \"\"\"Generates matrices for Test Case 2.\"\"\"\n    ks = np.array([-1.0, -0.5, 0.0, 0.5, 1.0])\n    delta = 0.05\n    matrices = []\n    for k in ks:\n        H = np.array([[k, delta], [delta, -k]], dtype=complex)\n        matrices.append(H)\n    return matrices\n\ndef get_case3_matrices():\n    \"\"\"Generates matrices for Test Case 3.\"\"\"\n    ks = np.array([-np.pi, -3*np.pi/4, -np.pi/2, -np.pi/4, 0,\n                   np.pi/4, np.pi/2, 3*np.pi/4, np.pi])\n    matrices = []\n    for k in ks:\n        cos_k = np.cos(k)\n        H = np.array([[2 * cos_k, 1.0, 0.0],\n                      [1.0, -cos_k, 1.0],\n                      [0.0, 1.0, 0.5 * cos_k]], dtype=complex)\n        matrices.append(H)\n    return matrices\n\ndef get_case4_matrices():\n    \"\"\"Generates matrices for Test Case 4.\"\"\"\n    ks = np.array([-0.8, -0.4, 0.0, 0.4, 0.8])\n    matrices = []\n    for k in ks:\n        theta = 0.2 * k\n        cos_t, sin_t = np.cos(theta), np.sin(theta)\n        R = np.array([[cos_t, -sin_t, 0.0],\n                      [sin_t,  cos_t, 0.0],\n                      [0.0,    0.0,   1.0]])\n        D = np.diag([0.0, 0.0, np.sin(k)])\n        H = R @ D @ R.T\n        matrices.append(H.astype(complex))\n    return matrices\n\ndef calculate_continuity_score(matrices):\n    \"\"\"\n    Calculates the overall continuity score for a sequence of Hermitian matrices.\n    \"\"\"\n    if not matrices:\n        return 0.0\n\n    n = matrices[0].shape[0]\n    num_steps = len(matrices) - 1\n    if num_steps == 0:\n        return 1.0\n\n    # Initial step: diagonalize H(t_0)\n    # eigh returns eigenvalues in ascending order, and eigenvectors as columns.\n    _, u_prev = np.linalg.eigh(matrices[0])\n\n    step_continuities = []\n\n    for i in range(num_steps):\n        # Current step: diagonalize H(t_{i+1})\n        _, u_curr_raw = np.linalg.eigh(matrices[i+1])\n\n        # Construct the overlap matrix S_{ab} = |u_a(t_i)|v_b(t_{i+1})|^2\n        overlap_matrix = np.abs(u_prev.T.conj() @ u_curr_raw)**2\n\n        # Solve the assignment problem to find the optimal permutation.\n        # linear_sum_assignment minimizes the cost, so we use the negative of the overlap matrix.\n        row_ind, col_ind = linear_sum_assignment(-overlap_matrix)\n\n        # The sum of overlaps for the optimal assignment\n        max_overlap_sum = overlap_matrix[row_ind, col_ind].sum()\n\n        # Calculate per-step normalized continuity\n        C = max_overlap_sum / n\n        step_continuities.append(C)\n\n        # Reorder the current eigenvectors to match the previous step's order\n        # This becomes the reference for the next iteration.\n        u_prev = u_curr_raw[:, col_ind]\n\n    # Overall continuity score is the arithmetic mean of per-step scores\n    overline_C = np.mean(step_continuities)\n    return overline_C\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        get_case1_matrices(),\n        get_case2_matrices(),\n        get_case3_matrices(),\n        get_case4_matrices()\n    ]\n\n    results = []\n    for case_matrices in test_cases:\n        score = calculate_continuity_score(case_matrices)\n        results.append(score)\n\n    # Format the final output string\n    output_str = f\"[{','.join(f'{r:.6f}' for r in results)}]\"\n    print(output_str)\n\nsolve()\n```", "id": "3446748"}]}