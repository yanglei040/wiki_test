{"hands_on_practices": [{"introduction": "Numerical methods like spectral and discontinuous Galerkin methods perform calculations on a standardized reference element, such as the interval $[-1, 1]$, for simplicity and efficiency. This practice focuses on the essential task of applying these reference calculations to a real-world, physical element through an affine mapping [@problem_id:3388861]. By deriving the transformation of quadrature nodes and weights, you will solidify your understanding of how high-order accuracy is maintained across different parts of a computational domain.", "problem": "In the construction of high-order numerical fluxes and stiffness/mass matrices for Spectral and Discontinuous Galerkin (DG) methods, element-wise integrals on a physical interval element $E=[a,b]$ are evaluated by mapping to a reference interval $[-1,1]$. Consider an affine mapping $\\phi:[-1,1]\\to [a,b]$ given by $\\phi(\\xi)=\\alpha+\\beta\\,\\xi$ with constant Jacobian $J=\\phi'(\\xi)=\\beta>0$. A Gauss-type quadrature on the reference interval $[-1,1]$ with nodes $\\{\\xi_i\\}_{i=1}^{n}$ and weights $\\{w_i\\}_{i=1}^{n}$ approximates $\\int_{-1}^{1} g(\\xi)\\,d\\xi$ by $\\sum_{i=1}^{n} w_i\\,g(\\xi_i)$, and is exact for polynomials up to a degree that depends on the chosen rule (Gauss-Legendre, Gauss-Lobatto, or Gauss-Radau).\n\nStarting from the change-of-variables formula for integrals and the defining property of the reference quadrature, derive the quadrature rule on the physical element $E=[a,b]$ obtained by transporting the Gauss-type reference rule through $\\phi$. Your derivation must:\n- Express the mapped nodes and mapped weights in terms of $a$, $b$, $\\{\\xi_i\\}$, and $\\{w_i\\}$.\n- Justify that the degree of polynomial exactness is preserved under this affine mapping for Gauss-Legendre, Gauss-Lobatto, and Gauss-Radau rules.\n\nProvide your final result as a single closed-form analytic expression for the mapped quadrature approximation of $\\int_{a}^{b} f(x)\\,dx$ in terms of $a$, $b$, $\\{\\xi_i\\}$, and $\\{w_i\\}$, where $f$ is a sufficiently smooth function. Do not include any derivation or explanation in your final answer. The final answer must be a single analytic expression and must not include units.", "solution": "The problem is to derive the quadrature rule on a physical element $E=[a,b]$ by transporting a reference Gauss-type quadrature rule from the reference interval $[-1,1]$ via an affine mapping. We must also justify that the degree of polynomial exactness is preserved.\n\nFirst, we determine the parameters of the affine mapping $\\phi(\\xi) = \\alpha + \\beta\\xi$ that maps the reference interval $[-1,1]$ to the physical interval $[a,b]$. The endpoints must map to each other, so we require $\\phi(-1) = a$ and $\\phi(1) = b$. This gives a system of two linear equations for $\\alpha$ and $\\beta$:\n$$\n\\begin{cases}\n\\alpha - \\beta = a \\\\\n\\alpha + \\beta = b\n\\end{cases}\n$$\nAdding the two equations yields $2\\alpha = a+b$, so $\\alpha = \\frac{a+b}{2}$. Subtracting the first equation from the second yields $2\\beta = b-a$, so $\\beta = \\frac{b-a}{2}$. The condition $\\beta > 0$ implies $b>a$, which is consistent with the standard definition of an interval $[a,b]$.\nThe mapping is therefore:\n$$\nx = \\phi(\\xi) = \\frac{a+b}{2} + \\frac{b-a}{2}\\xi\n$$\nThe Jacobian of this transformation, $J$, is the derivative of $\\phi$ with respect to $\\xi$:\n$$\nJ = \\frac{d\\phi}{d\\xi} = \\beta = \\frac{b-a}{2}\n$$\nSince $a$ and $b$ are constants, the Jacobian $J$ is also a constant.\n\nNext, we apply the change-of-variables formula to the integral of a function $f(x)$ over the physical element $[a,b]$:\n$$\n\\int_{a}^{b} f(x)\\,dx = \\int_{\\phi^{-1}(a)}^{\\phi^{-1}(b)} f(\\phi(\\xi)) \\frac{d\\phi}{d\\xi}\\,d\\xi = \\int_{-1}^{1} f(\\phi(\\xi)) J\\,d\\xi\n$$\nSubstituting the expressions for $\\phi(\\xi)$ and $J$, we get:\n$$\n\\int_{a}^{b} f(x)\\,dx = \\int_{-1}^{1} f\\left( \\frac{a+b}{2} + \\frac{b-a}{2}\\xi \\right) \\left( \\frac{b-a}{2} \\right) d\\xi\n$$\nSince the Jacobian $J$ is a constant, we can move it outside the integral:\n$$\n\\int_{a}^{b} f(x)\\,dx = \\frac{b-a}{2} \\int_{-1}^{1} f\\left( \\frac{a+b}{2} + \\frac{b-a}{2}\\xi \\right) d\\xi\n$$\nNow, we approximate the integral on the reference interval $[-1,1]$ using the given Gauss-type quadrature rule. Let $g(\\xi) = f(\\phi(\\xi)) = f\\left( \\frac{a+b}{2} + \\frac{b-a}{2}\\xi \\right)$. The reference quadrature rule states:\n$$\n\\int_{-1}^{1} g(\\xi)\\,d\\xi \\approx \\sum_{i=1}^{n} w_i g(\\xi_i)\n$$\nwhere $\\{\\xi_i\\}_{i=1}^{n}$ are the reference nodes and $\\{w_i\\}_{i=1}^{n}$ are the reference weights.\nSubstituting this approximation into our transformed integral gives:\n$$\n\\int_{a}^{b} f(x)\\,dx \\approx \\frac{b-a}{2} \\sum_{i=1}^{n} w_i g(\\xi_i) = \\frac{b-a}{2} \\sum_{i=1}^{n} w_i f\\left( \\frac{a+b}{2} + \\frac{b-a}{2}\\xi_i \\right)\n$$\nThis expression is the quadrature rule on the physical element $[a,b]$. We can identify the mapped quadrature nodes, $x_i$, and the mapped quadrature weights, $W_i$. The quadrature rule on $[a,b]$ is of the form $\\sum_{i=1}^{n} W_i f(x_i)$. By comparing forms, we deduce:\nThe mapped nodes are $x_i = \\phi(\\xi_i) = \\frac{a+b}{2} + \\frac{b-a}{2}\\xi_i$.\nThe mapped weights are $W_i = J \\cdot w_i = \\frac{b-a}{2}w_i$.\n\nFinally, we must justify that the degree of polynomial exactness is preserved. Let the reference quadrature rule be exact for all polynomials in $\\xi$ up to degree $k$. The specific value of $k$ depends on the quadrature type (e.g., for $n$-point Gauss-Legendre, $k=2n-1$). This means for any polynomial $p(\\xi)$ of degree at most $k$, the quadrature is exact:\n$$\n\\int_{-1}^{1} p(\\xi)\\,d\\xi = \\sum_{i=1}^{n} w_i p(\\xi_i)\n$$\nNow, consider an arbitrary polynomial $P(x)$ of degree at most $k$ on the physical interval $[a,b]$. We want to show that the mapped quadrature rule is exact for $P(x)$.\nThe integral of $P(x)$ is:\n$$\n\\int_{a}^{b} P(x)\\,dx = \\frac{b-a}{2} \\int_{-1}^{1} P\\left(\\phi(\\xi)\\right) d\\xi\n$$\nThe quadrature approximation for this integral is:\n$$\n\\sum_{i=1}^{n} W_i P(x_i) = \\sum_{i=1}^{n} \\left(\\frac{b-a}{2}w_i\\right) P(\\phi(\\xi_i)) = \\frac{b-a}{2} \\sum_{i=1}^{n} w_i P(\\phi(\\xi_i))\n$$\nLet's analyze the composite function $p(\\xi) = P(\\phi(\\xi))$. Since $P(x)$ is a polynomial of degree at most $k$ and $\\phi(\\xi) = \\alpha + \\beta\\xi$ is a polynomial of degree $1$ in $\\xi$ (with $\\beta \\neq 0$), the composition $P(\\phi(\\xi))$ is also a polynomial in $\\xi$ of the same degree as $P(x)$, i.e., at most $k$.\nSince $p(\\xi) = P(\\phi(\\xi))$ is a polynomial of degree at most $k$, the reference quadrature rule is exact for it:\n$$\n\\int_{-1}^{1} P(\\phi(\\xi))\\,d\\xi = \\sum_{i=1}^{n} w_i P(\\phi(\\xi_i))\n$$\nMultiplying both sides by the constant Jacobian $J = \\frac{b-a}{2}$, we get:\n$$\n\\frac{b-a}{2} \\int_{-1}^{1} P(\\phi(\\xi))\\,d\\xi = \\frac{b-a}{2} \\sum_{i=1}^{n} w_i P(\\phi(\\xi_i))\n$$\nThe left side is the exact value of $\\int_{a}^{b} P(x)\\,dx$, and the right side is the value computed by the mapped quadrature rule. Since they are equal, the mapped rule is exact for any polynomial $P(x)$ of degree up to $k$. Thus, the degree of polynomial exactness is preserved under the affine mapping. This holds for Gauss-Legendre, Gauss-Lobatto, and Gauss-Radau rules, as the argument only relies on the properties of the affine map and the definition of quadrature exactness, not on the specific nodes and weights.\n\nThe final expression for the mapped quadrature approximation of $\\int_{a}^{b} f(x)\\,dx$ is:\n$$\n\\int_{a}^{b} f(x)\\,dx \\approx \\frac{b-a}{2} \\sum_{i=1}^{n} w_i f\\left( \\frac{a+b}{2} + \\frac{b-a}{2}\\xi_i \\right)\n$$", "answer": "$$\n\\boxed{\n\\frac{b-a}{2} \\sum_{i=1}^{n} w_i f\\left( \\frac{a+b}{2} + \\frac{b-a}{2}\\xi_i \\right)\n}\n$$", "id": "3388861"}, {"introduction": "While we often use pre-computed tables of Gaussian quadrature nodes and weights, understanding their origin is crucial for appreciating the numerical stability of spectral methods. This hands-on exercise guides you through the process of building a robust algorithm to compute Gauss-Legendre quadrature rules from first principles, using the recurrence relations of Legendre polynomials [@problem_id:3388881]. This practice demystifies a core component of numerical libraries and highlights the elegant mathematics that ensures high precision even for very high-order rules.", "problem": "You are asked to design, derive, and implement a numerically stable algorithm to compute the nodes and weights for Gauss-Legendre quadrature on the interval $[-1,1]$ that is appropriate for Spectral Element Methods and Discontinuous Galerkin (DG) methods. The goal is to avoid catastrophic cancellation in the evaluation of the derivative of the Legendre polynomial at its roots by expressing $P_n'(x)$ in terms of quantities that can be computed stably via recurrence. Your derivation must begin from the fundamental properties of Legendre polynomials and their three-term recurrence relation, together with basic facts about Gaussian quadrature exactness. You must not assume access to prepackaged special function node or weight generators. Construct the algorithm solely from these fundamentals.\n\nRequired derivations and algorithmic steps:\n1. Begin with the three-term recurrence for the Legendre polynomials $P_n(x)$ on $[-1,1]$ and their orthogonality, and derive a relation expressing $P_n'(x)$ in terms of $P_n(x)$ and $P_{n-1}(x)$ that does not suffer catastrophic cancellation at or near the Gauss-Legendre nodes $\\{\\xi_i\\}_{i=1}^n$.\n2. Derive a Newton iteration update formula for refining initial approximations to the roots $\\xi_i$ of $P_n(x)=0$, expressed only in terms of $P_n(\\xi)$, $P_{n-1}(\\xi)$, and $P_n'(\\xi)$.\n3. Using the exactness of Gaussian quadrature and the norm properties of Legendre polynomials, derive the Gauss-Legendre weight expression $w_i$ in terms of $P_n'(\\xi_i)$ and $\\xi_i$.\n4. Explain why this algorithm avoids catastrophic cancellation and is numerically stable for large $n$ in double precision.\n\nImplementation requirements:\n- Implement a program that, given a positive integer $n$, computes the Gauss-Legendre nodes $\\{\\xi_i\\}_{i=1}^n$ and weights $\\{w_i\\}_{i=1}^n$ on $[-1,1]$ using:\n  - Stable evaluation of $P_n(x)$ and $P_{n-1}(x)$ via the three-term recurrence.\n  - The stable derivative identity from your derivation for $P_n'(x)$ at the nodes.\n  - Newton iterations to refine the nodes starting from asymptotic initial guesses.\n- Do not use any library’s built-in Gauss-Legendre node/weight routines.\n- Your program must compute and report diagnostic metrics for each $n$ in the test suite below.\n\nTest suite:\n- Consider the following values of $n$: $n \\in \\{1,2,10,64\\}$.\n- For each $n$, compute the following three diagnostics:\n  1. $E_{\\mathrm{sum}}(n)$: the absolute error in the weight sum, defined as $E_{\\mathrm{sum}}(n) = \\left|\\sum_{i=1}^n w_i - 2\\right|$.\n  2. $E_{\\mathrm{poly}}(n)$: the absolute quadrature error for the even polynomial of degree $2n-2$, defined as $E_{\\mathrm{poly}}(n) = \\left|\\sum_{i=1}^n w_i \\, \\xi_i^{2n-2} - \\int_{-1}^1 x^{2n-2} \\, dx\\right|$, where $\\int_{-1}^1 x^{2n-2} \\, dx = \\frac{2}{2n-1}$.\n  3. $\\mathrm{PosOk}(n)$: a boolean that is true if and only if all weights are strictly positive and all nodes satisfy $-1 < \\xi_i < 1$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets.\n- The list must contain the diagnostics for the test cases in the following order: for $n=1$, output $E_{\\mathrm{sum}}(1)$, $E_{\\mathrm{poly}}(1)$, $\\mathrm{PosOk}(1)$; for $n=2$, output $E_{\\mathrm{sum}}(2)$, $E_{\\mathrm{poly}}(2)$, $\\mathrm{PosOk}(2)$; similarly for $n=10$ and $n=64$.\n- For example, your output must look like $[E_{\\mathrm{sum}}(1),E_{\\mathrm{poly}}(1),\\mathrm{PosOk}(1),E_{\\mathrm{sum}}(2),E_{\\mathrm{poly}}(2),\\mathrm{PosOk}(2),E_{\\mathrm{sum}}(10),E_{\\mathrm{poly}}(10),\\mathrm{PosOk}(10),E_{\\mathrm{sum}}(64),E_{\\mathrm{poly}}(64),\\mathrm{PosOk}(64)]$.\n- The numbers must be printed in decimal form. The booleans must be printed as either $True$ or $False$.\n\nNotes:\n- The implementation and derivation focus on Gauss-Legendre quadrature. You may briefly discuss how similar stability considerations arise for Gauss-Lobatto and Gauss-Radau rules used in Spectral Element and Discontinuous Galerkin methods, but you do not need to implement those variants in code for this task.", "solution": "The problem requires the derivation and implementation of a numerically stable algorithm to compute the nodes and weights for Gauss-Legendre quadrature. This is a fundamental task in numerical analysis, especially for high-order spectral and discontinuous Galerkin methods, where quadrature rules for large orders $n$ are needed and stability is paramount.\n\nThe procedure will be based on the fundamental properties of Legendre polynomials, $P_n(x)$. We will derive stable formulas for the derivative $P_n'(x)$ at the quadrature nodes, a Newton-Raphson root-finding iteration, and the quadrature weights $\\{w_i\\}$. The algorithm will be constructed from first principles, avoiding pre-packaged library functions for generating these quantities.\n\n### 1. Fundamental Properties of Legendre Polynomials\n\nLegendre polynomials, $P_n(x)$, for $n \\in \\{0, 1, 2, \\dots\\}$, are a sequence of orthogonal polynomials on the interval $[-1, 1]$ with respect to the weight function $w(x) = 1$.\n\n**Orthogonality:**\nThe orthogonality property is given by:\n$$\n\\int_{-1}^{1} P_m(x) P_n(x) dx = \\frac{2}{2n+1}\\delta_{mn}\n$$\nwhere $\\delta_{mn}$ is the Kronecker delta.\n\n**Three-Term Recurrence Relation (Bonnet's Recurrence):**\nLegendre polynomials can be generated using a stable three-term recurrence relation:\n$$\n(n+1)P_{n+1}(x) = (2n+1)xP_n(x) - nP_{n-1}(x)\n$$\nwith the starting polynomials $P_0(x) = 1$ and $P_1(x) = x$. This relation is the cornerstone of our stable algorithm for evaluating the polynomials.\n\n### 2. Derivation of the Numerically Stable Algorithm\n\nThe Gauss-Legendre quadrature nodes $\\{\\xi_i\\}_{i=1}^n$ are the roots of the Legendre polynomial $P_n(x)$. We will use Newton's method to find these roots with high precision. This requires the evaluation of both $P_n(x)$ and its derivative $P_n'(x)$.\n\n#### 2.1. Stable Formula for $P_n'(x)$ at a Node\n\nA standard identity for Legendre polynomials relates $P_n(x)$, $P_{n-1}(x)$, and $P_n'(x)$:\n$$\n(1-x^2)P_n'(x) = n(P_{n-1}(x) - xP_n(x))\n$$\nLet $\\xi_i$ be a Gauss-Legendre node, which is a root of $P_n(x)$. By definition, $P_n(\\xi_i)=0$. Substituting this into the identity yields:\n$$\n(1-\\xi_i^2)P_n'(\\xi_i) = n(P_{n-1}(\\xi_i) - \\xi_i \\cdot 0) = n P_{n-1}(\\xi_i)\n$$\nThis gives us a direct and stable formula for the derivative of $P_n(x)$ at its roots:\n$$\nP_n'(\\xi_i) = \\frac{n P_{n-1}(\\xi_i)}{1-\\xi_i^2}\n$$\nThis formula is numerically stable because the roots $\\xi_i$ of $P_n(x)$ are known to lie strictly in the interval $(-1, 1)$, so the denominator $(1-\\xi_i^2)$ is never zero. The term $P_{n-1}(\\xi_i)$ can be computed robustly using the three-term recurrence. This avoids potential catastrophic cancellation that might occur in other formulations of the derivative.\n\n#### 2.2. Newton's Method for Root Finding\n\nNewton's method provides an iterative scheme to find a root of a function $f(x)$:\n$$\nx_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}\n$$\nTo find the roots of $P_n(x)$, we set $f(x) = P_n(x)$. The iteration update is:\n$$\n\\xi^{(k+1)} = \\xi^{(k)} - \\frac{P_n(\\xi^{(k)})}{P_n'(\\xi^{(k)})}\n$$\nTo evaluate the derivative $P_n'(x)$ at an arbitrary point $x$ (not necessarily a root) during the iteration, we use a slight rearrangement of the identity from the previous section:\n$$\nP_n'(x) = \\frac{n(xP_n(x) - P_{n-1}(x))}{x^2-1}\n$$\nThe Newton update step, $\\Delta\\xi^{(k)} = \\xi^{(k+1)} - \\xi^{(k)}$, can then be written as:\n$$\n\\Delta\\xi^{(k)} = - \\frac{P_n(\\xi^{(k)})}{P_n'(\\xi^{(k)})} = - \\frac{P_n(\\xi^{(k)}) ((\\xi^{(k)})^2-1)}{n(\\xi^{(k)}P_n(\\xi^{(k)}) - P_{n-1}(\\xi^{(k)}))}\n$$\nThis expression is used in each step of the root-finding algorithm. The values $P_n(\\xi^{(k)})$ and $P_{n-1}(\\xi^{(k)})$ are computed efficiently and stably via the Bonnet recurrence relation.\n\n#### 2.3. Derivation of the Quadrature Weights\n\nThe weights $w_i$ for Gauss-Legendre quadrature can be expressed in terms of the nodes $\\xi_i$ and the derivative $P_n'(\\xi_i)$:\n$$\nw_i = \\frac{2}{(1-\\xi_i^2)[P_n'(\\xi_i)]^2}\n$$\nSubstituting the stable expression for $P_n'(\\xi_i)$ derived in Section 2.1 into this formula, we get:\n$$\nw_i = \\frac{2}{(1-\\xi_i^2)\\left[ \\frac{n P_{n-1}(\\xi_i)}{1-\\xi_i^2} \\right]^2} = \\frac{2 (1-\\xi_i^2)^2}{(1-\\xi_i^2) n^2 [P_{n-1}(\\xi_i)]^2}\n$$\nThis simplifies to the final, numerically stable formula for the weights:\n$$\nw_i = \\frac{2(1-\\xi_i^2)}{n^2 [P_{n-1}(\\xi_i)]^2}\n$$\nThis formula is exceptionally stable. It involves only squares and products of well-behaved quantities. The roots $\\xi_i$ lie in $(-1, 1)$, ensuring $1-\\xi_i^2 > 0$. The roots of $P_{n-1}(x)$ interlace the roots of $P_n(x)$, so $P_{n-1}(\\xi_i) \\neq 0$.\n\n### 3. Algorithm Summary and Stability Analysis\n\nThe complete algorithm proceeds as follows:\n1.  **Initial Guesses:** For a given order $n$, we require initial guesses for the roots of $P_n(x)$. The roots are symmetric about $x=0$. We only need to compute the non-negative roots. An excellent initial guess for the $k$-th root (ordered from largest to smallest) is given by the asymptotic formula:\n    $$ \\xi_k^{(0)} = \\cos\\left(\\pi \\frac{4k-1}{4n+2}\\right), \\quad k=1, 2, \\dots, \\lceil n/2 \\rceil $$\n2.  **Root Refinement:** Each initial guess is refined using the Newton-Raphson iteration described in Section 2.2 until convergence to machine precision.\n3.  **Weight Calculation:** Once a root $\\xi_i$ is found, the corresponding weight $w_i$ is calculated using the stable formula from Section 2.3.\n4.  **Symmetry:** The full set of nodes and weights is constructed by exploiting symmetry: if $\\xi_i$ is a node with weight $w_i$, then $-\\xi_i$ is also a node with the same weight $w_i$. If $n$ is odd, $\\xi=0$ is a node.\n\nThis algorithm is numerically stable for large $n$ for several reasons:\n- **Evaluation:** The use of the three-term recurrence to evaluate $P_k(x)$ is numerically stable for $x \\in [-1, 1]$, as the magnitudes of the polynomials are bounded by $1$.\n- **Root Finding:** The Newton iteration is based on a ratio involving $P_n(x)$ and $P_{n-1}(x)$, which are computed stably. Near a root, behavior is robust.\n- **Weight Calculation:** The final weight formula involves only positive quantities ($1-\\xi_i^2$, $n^2$, $[P_{n-1}(\\xi_i)]^2$) and avoids subtractions of nearly equal numbers, thus preventing catastrophic cancellation.\n\nThese principles of leveraging recurrence relations for stable evaluation are not limited to Gauss-Legendre quadrature. They are essential for computing nodes and weights for other quadrature rules like Gauss-Lobatto and Gauss-Radau, which are critical in Spectral Element and Discontinuous Galerkin methods for constructing diagonal mass matrices and ensuring robust numerical schemes.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_gauss_legendre(n):\n    \"\"\"\n    Computes Gauss-Legendre nodes and weights on [-1, 1] using a stable\n    Newton-Raphson method based on the three-term recurrence relation.\n\n    Args:\n        n (int): The order of the quadrature rule. Must be a positive integer.\n\n    Returns:\n        tuple[np.ndarray, np.ndarray]: A tuple containing the sorted nodes\n        and corresponding weights.\n    \"\"\"\n    if not isinstance(n, int) or n < 1:\n        raise ValueError(\"n must be a positive integer.\")\n\n    if n == 1:\n        return np.array([0.0]), np.array([2.0])\n\n    nodes = np.zeros(n, dtype=float)\n    weights = np.zeros(n, dtype=float)\n    \n    # We find the non-negative roots using symmetry.\n    # The number of roots to find is ceil(n/2).\n    n_roots_to_find = (n + 1) // 2\n    \n    for i in range(n_roots_to_find):\n        # Initial guess for the k-th root, where roots are ordered from largest to smallest.\n        # k is 1-indexed, loop i is 0-indexed.\n        k = i + 1\n        x = np.cos(np.pi * (k - 0.25) / (n + 0.5))\n\n        # Newton-Raphson iteration to refine the root.\n        # A tolerance based on machine epsilon is appropriate for high precision.\n        tol = np.finfo(float).eps\n        \n        for _ in range(20):  # A max iteration count prevents infinite loops.\n            # Evaluate P_n(x) and P_{n-1}(x) using Bonnet's three-term recurrence.\n            p_n_minus_1 = 1.0  # P_0(x)\n            p_n = x            # P_1(x)\n            \n            for j in range(1, n):\n                # (j+1)P_{j+1} = (2j+1)xP_j - jP_{j-1}\n                p_n_plus_1 = ((2 * j + 1) * x * p_n - j * p_n_minus_1) / (j + 1)\n                p_n_minus_1 = p_n\n                p_n = p_n_plus_1\n            # After the loop, p_n is P_n(x) and p_n_minus_1 is P_{n-1}(x).\n            \n            # Derivative P_n'(x) for the Newton step.\n            # (x^2 - 1) * P_n'(x) = n * (x*P_n(x) - P_{n-1}(x))\n            p_n_prime = n * (x * p_n - p_n_minus_1) / (x**2 - 1.0)\n            \n            # Newton update step.\n            dx = p_n / p_n_prime\n            x = x - dx\n            \n            # Check for convergence.\n            if np.abs(dx) <= tol * (1.0 + np.abs(x)):\n                break\n        \n        # Store the converged root and its symmetric counterpart.\n        # This scheme finds positive roots in descending order.\n        nodes[i] = x\n        nodes[n - 1 - i] = -x\n        \n        # Re-evaluate P_{n-1}(x) at the converged root for the weight calculation.\n        p_prev = 1.0 # P_0(x)\n        p_curr = x   # P_1(x)\n        if n > 1:\n            for j in range(1, n - 1): # Recurrence up to P_{n-1}\n                p_next = ((2 * j + 1) * x * p_curr - j * p_prev) / (j + 1)\n                p_prev = p_curr\n                p_curr = p_next\n        p_n_minus_1_at_root = p_curr\n        \n        # Calculate the weight using the stable formula:\n        # w_k = 2(1-x_k^2) / (n^2 * [P_{n-1}(x_k)]^2)\n        w = 2.0 * (1 - x**2) / ((n * p_n_minus_1_at_root)**2)\n        weights[i] = w\n        weights[n - 1 - i] = w\n        \n    # The nodes are constructed symmetrically, but for convention let's sort them.\n    # The construction order already results in a sorted descending array, so\n    # an explicit sort is for formal correctness according to convention.\n    sort_indices = np.argsort(nodes)\n    nodes = nodes[sort_indices]\n    weights = weights[sort_indices]\n\n    return nodes, weights\n\ndef solve():\n    test_cases = [1, 2, 10, 64]\n    results = []\n    \n    for n in test_cases:\n        nodes, weights = compute_gauss_legendre(n)\n\n        # Diagnostic 1: Absolute error in the sum of weights. Should be 2.\n        e_sum = np.abs(np.sum(weights) - 2.0)\n\n        # Diagnostic 2: Absolute quadrature error for f(x) = x^(2n-2).\n        # Integral of x^(2n-2) from -1 to 1 is 2/(2n-1).\n        exact_integral = 2.0 / (2 * n - 1)\n        # The term x^(2n-2) requires special handling for n=1, where x=0 and exponent is 0.\n        # np.power(0.0, 0.0) correctly evaluates to 1.0.\n        quad_sum = np.sum(weights * np.power(nodes, 2 * n - 2))\n        e_poly = np.abs(quad_sum - exact_integral)\n\n        # Diagnostic 3: Check if all weights are positive and nodes are in (-1, 1).\n        # The roots of Legendre polynomials are guaranteed to be in (-1, 1).\n        pos_ok = np.all(weights > 0) and np.all(np.abs(nodes) < 1.0)\n        \n        results.extend([e_sum, e_poly, pos_ok])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3388881"}, {"introduction": "In the design of a spectral or DG method, the choice of quadrature rule is not merely a technical detail—it is a critical decision that influences both accuracy and computational cost. This practice delves into the classic trade-off between using Gauss-Legendre (GL) and Gauss-Lobatto-Legendre (GLL) nodes and weights [@problem_id:3388916]. You will implement and analyze how the GLL rule facilitates an efficient diagonal mass matrix (a technique known as mass lumping) and quantify the resulting impact on the numerical dispersion of wave propagation.", "problem": "Consider the reference interval $[-1,1]$ and a polynomial space of degree $N \\ge 1$. Let $\\{x_i\\}_{i=0}^N$ be nodal points and $\\{w_i\\}_{i=0}^N$ be nonnegative weights defining a quadrature rule on $[-1,1]$. Define the Lagrange nodal basis $\\{\\ell_j(x)\\}_{j=0}^N$ by $\\ell_j(x_i)=\\delta_{ij}$, where $\\delta_{ij}$ is the Kronecker delta. The nodal Spectral Element Method (SEM) uses these basis functions to approximate functions and their derivatives. This problem focuses on two choices of quadrature and nodes: Gauss-Legendre (GL) and Gauss-Lobatto-Legendre (GLL), and on quantifying the trade-off between diagonal mass matrices and dispersion error in the context of spectral and Discontinuous Galerkin (DG) methods.\n\nYou must start from the following foundational facts and definitions:\n\n- An $(N+1)$-point Gauss-Legendre quadrature integrates exactly all polynomials up to degree $2(N+1)-1=2N+1$ on $[-1,1]$. The nodes are the zeros of the Legendre polynomial $P_{N+1}(x)$, and the weights are strictly positive.\n- The $(N+1)$-point Gauss-Lobatto-Legendre quadrature includes the endpoints $\\pm 1$, and the interior nodes are the zeros of $P_N'(x)$. Its degree of exactness is $2N-1$. The weights are strictly positive and can be written in terms of $P_N(x)$ evaluated at the nodes.\n- For nodal Lagrange basis functions $\\ell_j(x)$ at the quadrature nodes $\\{x_i\\}$, the quadrature-based mass matrix $M_{\\text{quad}}$ is diagonal with entries $M_{ii}^{\\text{quad}} = w_i$. For Gauss-Legendre quadrature with $N+1$ nodes, the quadrature-based mass matrix is also the exact consistent mass matrix. For Gauss-Lobatto-Legendre quadrature with $N+1$ nodes, the quadrature-based mass matrix differs from the exact consistent mass matrix, an effect commonly termed as mass lumping.\n\nYour tasks are:\n\n- Derive from first principles, using only the above facts and the definition of Lagrange interpolation, a numerically stable procedure to construct the differentiation matrix $D \\in \\mathbb{R}^{(N+1)\\times(N+1)}$ with entries $D_{ij} = \\ell_j'(x_i)$. You must do this without relying on any pre-derived closed-form differentiation formula in the problem statement, and you must justify stability in terms of conditioning.\n- For a complex-valued plane wave $u(x) = \\exp(\\mathrm{i}\\,\\kappa x)$ with real wavenumber $\\kappa$, define the mass-weighted least-squares residual $r(\\kappa) = \\| D\\,u - \\mathrm{i}\\,\\kappa\\,u \\|_{M}$, where $u \\in \\mathbb{C}^{N+1}$ is the vector of nodal samples $u_i = u(x_i)$ and $\\|v\\|_M^2 = v^* M v$ with $M$ the quadrature-based mass matrix and ${}^*$ denoting the conjugate transpose. Derive the expression for the discrete wavenumber $\\kappa_d$ that minimizes $r(\\kappa)$ over $\\kappa \\in \\mathbb{R}$, and express it in terms of $D$, $M$, and $u$ only.\n- For each scheme (GL and GLL), compute the relative dispersion error $E(N,\\kappa) = |\\kappa_d - \\kappa|/|\\kappa|$ for specified $(N,\\kappa)$.\n- Quantify the deviation between the diagonal mass-lumped matrix and the exact consistent mass matrix. Let $M_{\\text{true}}$ denote the exact consistent mass matrix with entries $M_{ij}^{\\text{true}} = \\int_{-1}^1 \\ell_i(x)\\,\\ell_j(x)\\,\\mathrm{d}x$. Using a sufficiently high-order Gauss-Legendre quadrature with $Q$ points, approximate $M_{\\text{true}}$ and compute the normalized off-diagonal Frobenius norm\n$$\n\\rho(N) = \\frac{\\| M_{\\text{true}} - \\operatorname{diag}(\\operatorname{diag}(M_{\\text{true}})) \\|_F}{\\| M_{\\text{true}} \\|_F}.\n$$\nReport $\\rho(N)$ for both GL and GLL nodes to contrast exact diagonalization (GL) and mass lumping (GLL).\n\nImplementation and numerical details you must follow:\n\n- Construct GL nodes and weights with $N+1$ points.\n- Construct GLL nodes and weights with $N+1$ points. The interior nodes must be the zeros of $P_N'(x)$, and the weights must use the standard positive GLL formula in terms of $P_N(x)$ evaluated at the nodes. Endpoints are included at $x=\\pm 1$.\n- Build the Lagrange basis via barycentric data and assemble the differentiation matrix $D$ by differentiating the interpolant. Use the barycentric representation to control numerical conditioning.\n- Approximate $M_{\\text{true}}$ using Gauss-Legendre quadrature with $Q=200$ points, and evaluate $\\ell_j(x)$ robustly at quadrature abscissae via the barycentric formula. You must adhere to a purely mathematical definition of all entities; no physical units are involved.\n\nTest suite:\n\nCompute and aggregate results for the following inputs:\n\n- Dispersion error tests:\n  - Case $\\#1$: $(N,\\kappa) = (2, 1.0)$.\n  - Case $\\#2$: $(N,\\kappa) = (4, 2.5)$.\n  - Case $\\#3$: $(N,\\kappa) = (8, 7.0)$.\n  - Case $\\#4$: $(N,\\kappa) = (6, 10^{-6})$.\n  For each case, output two floating-point numbers: $E_{\\text{GL}}$ and $E_{\\text{GLL}}$.\n- Mass matrix diagonality test:\n  - Case $\\#5$: $N=6$. Output two floating-point numbers: $\\rho_{\\text{GL}}$ and $\\rho_{\\text{GLL}}$.\n\nFinal output format:\n\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as\n$$\n[E_{\\text{GL}}^{(1)}, E_{\\text{GLL}}^{(1)}, E_{\\text{GL}}^{(2)}, E_{\\text{GLL}}^{(2)}, E_{\\text{GL}}^{(3)}, E_{\\text{GLL}}^{(3)}, E_{\\text{GL}}^{(4)}, E_{\\text{GLL}}^{(4)}, \\rho_{\\text{GL}}, \\rho_{\\text{GLL}}].\n$$\nAll floating-point outputs must be plain decimals. No other text should be printed. Angles and physical units do not apply in this problem.", "solution": "The user-provided problem is assessed to be valid. It is scientifically grounded in the principles of numerical analysis and spectral methods, well-posed, and expressed in objective mathematical language. It is self-contained and free of contradictions or ambiguities. The tasks require substantive, non-trivial derivations and computations based on established theory. We may, therefore, proceed with the solution.\n\nThe solution is presented in four parts: derivation of the differentiation matrix, derivation of the discrete wavenumber, procedure for computing dispersion error, and procedure for quantifying mass matrix diagonality.\n\n### 1. Construction of the Differentiation Matrix $D$\n\nLet $\\{x_i\\}_{i=0}^N$ be a set of $N+1$ distinct nodal points on the interval $[-1, 1]$. The Lagrange interpolating polynomial $p(x)$ of degree at most $N$ that passes through the points $(x_j, u_j)$ is given by $p(x) = \\sum_{j=0}^N u_j \\ell_j(x)$, where $\\{\\ell_j(x)\\}_{j=0}^N$ is the basis of Lagrange polynomials satisfying $\\ell_j(x_i) = \\delta_{ij}$.\n\nThe derivative of the interpolant is $p'(x) = \\sum_{j=0}^N u_j \\ell_j'(x)$. Evaluating this derivative at the nodal points $x_i$ gives the vector of derivative values, $p'(x_i) = \\sum_{j=0}^N u_j \\ell_j'(x_i)$. This can be expressed as a matrix-vector product $\\mathbf{u}' = D \\mathbf{u}$, where $\\mathbf{u} = [u_0, \\dots, u_N]^T$, $\\mathbf{u}' = [p'(x_0), \\dots, p'(x_N)]^T$, and $D$ is the $(N+1) \\times (N+1)$ differentiation matrix with entries $D_{ij} = \\ell_j'(x_i)$.\n\nA numerically stable procedure to compute $D_{ij}$ is derived from the barycentric form of the Lagrange polynomial, avoiding direct evaluation of $\\ell_j(x)$ and its derivative, which can be ill-conditioned.\n\nThe Lagrange basis polynomial $\\ell_j(x)$ is defined as:\n$$\n\\ell_j(x) = \\prod_{k=0, k \\neq j}^{N} \\frac{x-x_k}{x_j-x_k}\n$$\nFor the off-diagonal entries $D_{ij}$ with $i \\neq j$, we differentiate $\\ell_j(x)$ and evaluate at $x=x_i$:\n$$\n\\ell_j'(x_i) = \\left. \\frac{d}{dx} \\left( \\prod_{k=0, k \\neq j}^{N} \\frac{x-x_k}{x_j-x_k} \\right) \\right|_{x=x_i}\n$$\nUsing the product rule, the only non-zero term in the sum at $x=x_i$ is the one where the factor $(x-x_i)$ is differentiated. This yields:\n$$\n\\ell_j'(x_i) = \\frac{1}{\\prod_{k \\neq j}(x_j-x_k)} \\prod_{k \\neq j, k \\neq i} (x_i-x_k)\n$$\nWe introduce the barycentric weights $\\beta_j = 1 / \\prod_{k \\neq j} (x_j - x_k)$. The expression for $\\ell_j'(x_i)$ can be rewritten in terms of these weights:\n$$\nD_{ij} = \\ell_j'(x_i) = \\frac{\\beta_j}{\\beta_i} \\frac{1}{x_i - x_j} \\quad \\text{for } i \\neq j\n$$\nThis formula is known to be numerically stable for reasonable distributions of nodes.\n\nFor the diagonal entries $D_{ii}$, we use the property that the derivative of a constant function is zero. Let $u(x)=1$, so $u_j=1$ for all $j$. Its polynomial interpolant is exactly $p(x)=1$, and its derivative is $p'(x)=0$. At any node $x_i$, we must have:\n$$\np'(x_i) = \\sum_{j=0}^{N} D_{ij} u_j = \\sum_{j=0}^{N} D_{ij} (1) = 0\n$$\nThis implies that the sum of each row of the differentiation matrix is zero. We can, therefore, compute the diagonal entries as:\n$$\nD_{ii} = - \\sum_{j=0, j \\neq i}^{N} D_{ij}\n$$\nThis procedure avoids catastrophic cancellation that can occur when differentiating the formula for $\\ell_i(x)$ directly and provides a stable algorithm for constructing $D$.\n\n### 2. Derivation of the Discrete Wavenumber $\\kappa_d$\n\nWe are tasked to find the real wavenumber $\\kappa_d$ that minimizes the mass-weighted least-squares residual $r(\\kappa) = \\| D\\mathbf{u} - \\mathrm{i}\\kappa\\mathbf{u} \\|_M$ for a given nodal vector $\\mathbf{u} \\in \\mathbb{C}^{N+1}$ corresponding to the plane wave $u(x) = \\exp(\\mathrm{i}\\kappa x)$. The norm is defined as $\\|\\mathbf{v}\\|_M^2 = \\mathbf{v}^* M \\mathbf{v}$, where $M$ is the diagonal mass matrix with entries $M_{ii}=w_i > 0$ and $\\mathbf{v}^*$ is the conjugate transpose of $\\mathbf{v}$.\n\nMinimizing $r(\\kappa)$ is equivalent to minimizing its square, $r(\\kappa)^2$:\n$$\nr(\\kappa)^2 = \\| D\\mathbf{u} - \\mathrm{i}\\kappa\\mathbf{u} \\|_M^2 = (D\\mathbf{u} - \\mathrm{i}\\kappa\\mathbf{u})^* M (D\\mathbf{u} - \\mathrm{i}\\kappa\\mathbf{u})\n$$\nExpanding this expression, and using the fact that $\\kappa$ is real:\n$$\nr(\\kappa)^2 = ((D\\mathbf{u})^* + \\mathrm{i}\\kappa\\mathbf{u}^*) M (D\\mathbf{u} - \\mathrm{i}\\kappa\\mathbf{u})\n$$\n$$\nr(\\kappa)^2 = (D\\mathbf{u})^*M(D\\mathbf{u}) - \\mathrm{i}\\kappa(D\\mathbf{u})^*M\\mathbf{u} + \\mathrm{i}\\kappa\\mathbf{u}^*M(D\\mathbf{u}) + \\kappa^2\\mathbf{u}^*M\\mathbf{u}\n$$\nThis is a quadratic function of $\\kappa$ of the form $f(\\kappa) = a\\kappa^2 + b\\kappa + c$, where:\n$a = \\mathbf{u}^*M\\mathbf{u}$\n$b = \\mathrm{i}(\\mathbf{u}^*M(D\\mathbf{u}) - (D\\mathbf{u})^*M\\mathbf{u})$\n$c = (D\\mathbf{u})^*M(D\\mathbf{u})$\n\nLet $z = \\mathbf{u}^*M(D\\mathbf{u})$. Then $(D\\mathbf{u})^*M\\mathbf{u} = ((D\\mathbf{u})^*M\\mathbf{u})^* = \\mathbf{u}^*M^*(D\\mathbf{u})^{**} = \\mathbf{u}^*M(D\\mathbf{u}) = z^*$, since $M$ is real and diagonal, thus Hermitian ($M^*=M$).\nThe coefficient $b$ becomes $b = \\mathrm{i}(z - z^*) = \\mathrm{i}(2\\mathrm{i}\\operatorname{Im}(z)) = -2\\operatorname{Im}(z)$.\nThe quadratic is $r(\\kappa)^2 = (\\mathbf{u}^*M\\mathbf{u})\\kappa^2 - 2\\operatorname{Im}(\\mathbf{u}^*M(D\\mathbf{u}))\\kappa + (D\\mathbf{u})^*M(D\\mathbf{u})$.\nTo find the minimum, we take the derivative with respect to $\\kappa$ and set it to zero:\n$$\n\\frac{d}{d\\kappa} r(\\kappa)^2 = 2(\\mathbf{u}^*M\\mathbf{u})\\kappa - 2\\operatorname{Im}(\\mathbf{u}^*M(D\\mathbf{u})) = 0\n$$\nSince the mass matrix $M$ is positive definite, $\\mathbf{u}^*M\\mathbf{u} > 0$ for any non-zero $\\mathbf{u}$. Solving for $\\kappa$, we obtain the discrete wavenumber $\\kappa_d$:\n$$\n\\kappa_d = \\frac{\\operatorname{Im}(\\mathbf{u}^* M D \\mathbf{u})}{\\mathbf{u}^* M \\mathbf{u}}\n$$\nThis expression provides $\\kappa_d$ purely in terms of the differentiation matrix $D$, the mass matrix $M$, and the nodal vector $\\mathbf{u}$.\n\n### 3. Computation of Relative Dispersion Error $E(N,\\kappa)$\n\nFor each scheme (Gauss-Legendre, GL, and Gauss-Lobatto-Legendre, GLL) and each given pair $(N, \\kappa)$, the relative dispersion error $E = |\\kappa_d - \\kappa|/|\\kappa|$ is computed as follows:\n1.  For the specified degree $N$, determine the $N+1$ quadrature nodes $\\{x_i\\}_{i=0}^N$ and weights $\\{w_i\\}_{i=0}^N$ for the chosen scheme (GL or GLL).\n2.  Construct the $(N+1) \\times (N+1)$ differentiation matrix $D$ using the stable barycentric procedure described in Part 1.\n3.  Construct the diagonal mass matrix $M$ with entries $M_{ii} = w_i$.\n4.  Sample the plane wave $u(x) = \\exp(\\mathrm{i}\\kappa x)$ at the nodes to form the vector $\\mathbf{u}$ with entries $u_i = \\exp(\\mathrm{i}\\kappa x_i)$.\n5.  Compute the discrete wavenumber $\\kappa_d$ using the formula derived in Part 2.\n6.  Calculate the relative dispersion error $E(N,\\kappa) = |\\kappa_d - \\kappa| / |\\kappa|$.\n\n### 4. Computation of Mass Matrix Diagonality $\\rho(N)$\n\nThis task quantifies the deviation of the exact consistent mass matrix $M_{\\text{true}}$ from a purely diagonal form. The entries of $M_{\\text{true}}$ are $M_{ij}^{\\text{true}} = \\int_{-1}^1 \\ell_i(x)\\ell_j(x)\\,\\mathrm{d}x$.\n\nFor the Gauss-Legendre (GL) scheme with $N+1$ nodes, the quadrature rule is exact for polynomials of degree up to $2(N+1)-1=2N+1$. Since $\\ell_i(x)\\ell_j(x)$ is a polynomial of degree $2N$, and $2N \\le 2N+1$ for $N \\ge 0$, the integral is computed exactly by the quadrature rule itself:\n$$\nM_{ij}^{\\text{true}} = \\int_{-1}^1 \\ell_i(x)\\ell_j(x)\\,\\mathrm{d}x = \\sum_{k=0}^N w_k \\ell_i(x_k)\\ell_j(x_k) = \\sum_{k=0}^N w_k \\delta_{ik}\\delta_{jk} = w_i\\delta_{ij}\n$$\nThus, for the GL scheme, the true mass matrix $M_{\\text{true}}$ is identical to the diagonal quadrature-based mass matrix $M_{\\text{quad}}$. Consequently, $M_{\\text{true}} - \\operatorname{diag}(\\operatorname{diag}(M_{\\text{true}}))$ is a zero matrix, and the normalized off-diagonal Frobenius norm $\\rho_{\\text{GL}}(N)$ is theoretically zero. Any non-zero result would be due to finite-precision arithmetic.\n\nFor the Gauss-Lobatto-Legendre (GLL) scheme with $N+1$ nodes, the degree of exactness is $2N-1$. Since $2N > 2N-1$ for $N \\ge 1$, the GLL quadrature does not exactly integrate $\\ell_i(x)\\ell_j(x)$, and $M_{\\text{true}}$ is not diagonal. This effect is known as mass lumping.\n\nTo compute $\\rho(N)$ for a given $N$, we perform the following steps for both GL and GLL node sets:\n1.  Determine the $N+1$ nodes $\\{x_j\\}$ for the scheme.\n2.  Approximate the integral for $M_{ij}^{\\text{true}}$ using a high-order Gauss-Legendre quadrature with $Q=200$ points, denoted $\\{y_q, w'_q\\}_{q=0}^{Q-1}$.\n$$\nM_{ij}^{\\text{true}} \\approx \\sum_{q=0}^{Q-1} w'_q \\ell_i(y_q) \\ell_j(y_q)\n$$\n3.  The values $\\ell_j(y_q)$ are computed robustly using the second barycentric formula. Let $\\beta_j$ be the barycentric weights for the nodes $\\{x_j\\}$. Then:\n$$\n\\ell_j(y_q) = \\frac{ \\frac{\\beta_j}{y_q - x_j} }{ \\sum_{k=0}^N \\frac{\\beta_k}{y_q - x_k} }\n$$\nThis allows evaluation of the basis functions at the quadrature points $\\{y_q\\}$.\n4.  Assemble the matrix $M_{\\text{true}}$ using the high-order quadrature sum. In matrix notation, if $V$ is the $Q \\times (N+1)$ matrix with entries $V_{qj} = \\ell_j(y_q)$ and $W'$ is the diagonal $Q \\times Q$ matrix of weights $w'_q$, then $M_{\\text{true}} \\approx V^T W' V$.\n5.  Compute the normalized off-diagonal Frobenius norm:\n$$\n\\rho(N) = \\frac{\\| M_{\\text{true}} - \\operatorname{diag}(\\operatorname{diag}(M_{\\text{true}})) \\|_F}{\\| M_{\\text{true}} \\|_F}\n$$", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import roots_legendre, legendre, eval_legendre\n\ndef solve():\n    \"\"\"\n    Main solver function that computes and prints the results for the given test cases.\n    \"\"\"\n\n    def get_gl_nodes_weights(n_points):\n        \"\"\"\n        Computes n-point Gauss-Legendre nodes and weights.\n        \"\"\"\n        nodes, weights = roots_legendre(n_points)\n        return nodes, weights\n\n    def get_gll_nodes_weights(n_points):\n        \"\"\"\n        Computes n-point Gauss-Lobatto-Legendre nodes and weights.\n        n_points = N + 1, where N is the polynomial degree.\n        \"\"\"\n        if n_points < 2:\n            raise ValueError(\"GLL quadrature requires at least 2 points.\")\n        \n        N = n_points - 1\n        \n        if N > 0:\n            p_n_prime_roots = legendre(N).deriv(1).roots\n        else:\n            p_n_prime_roots = np.array([])\n            \n        nodes = np.concatenate(([-1.0], np.real(p_n_prime_roots), [1.0]))\n        nodes.sort()\n        \n        weights = 2 / (N * (N + 1) * eval_legendre(N, nodes)**2)\n        \n        return nodes, weights\n\n    def barycentric_weights(nodes):\n        \"\"\"\n        Computes barycentric weights for a given set of nodes.\n        \"\"\"\n        n = len(nodes)\n        weights = np.ones(n, dtype=np.float64)\n        for j in range(n):\n            prod = 1.0\n            for k in range(n):\n                if k != j:\n                    prod *= (nodes[j] - nodes[k])\n            weights[j] = 1.0 / prod\n        return weights\n\n    def differentiation_matrix(nodes):\n        \"\"\"\n        Constructs the differentiation matrix using the barycentric formula.\n        \"\"\"\n        n = len(nodes)\n        b_weights = barycentric_weights(nodes)\n        D = np.zeros((n, n), dtype=np.float64)\n        \n        for i in range(n):\n            row_sum = 0.0\n            for j in range(n):\n                if i == j:\n                    continue\n                term = (b_weights[j] / b_weights[i]) / (nodes[i] - nodes[j])\n                D[i, j] = term\n                row_sum += term\n            D[i, i] = -row_sum\n        return D\n\n    def compute_dispersion_error(N, kappa, scheme):\n        \"\"\"\n        Computes the relative dispersion error E(N, kappa).\n        \"\"\"\n        n_points = N + 1\n        \n        if scheme == 'GL':\n            nodes, weights = get_gl_nodes_weights(n_points)\n        elif scheme == 'GLL':\n            nodes, weights = get_gll_nodes_weights(n_points)\n        else:\n            raise ValueError(\"Unknown scheme\")\n\n        D = differentiation_matrix(nodes)\n        M = np.diag(weights)\n        u = np.exp(1j * kappa * nodes)\n        \n        u_H = u.conj().T\n        \n        numerator = np.imag(u_H @ M @ D @ u)\n        denominator = u_H @ M @ u\n        \n        kappa_d = numerator / denominator.real\n        \n        if np.abs(kappa) == 0:\n            return np.abs(kappa_d)\n            \n        return np.abs(kappa_d - kappa) / np.abs(kappa)\n\n    def compute_mass_matrix_diagonality(N, scheme, Q=200):\n        \"\"\"\n        Computes the normalized off-diagonal Frobenius norm rho(N).\n        \"\"\"\n        n_points = N + 1\n        \n        if scheme == 'GL':\n            x_nodes, _ = get_gl_nodes_weights(n_points)\n        elif scheme == 'GLL':\n            x_nodes, _ = get_gll_nodes_weights(n_points)\n        else:\n            raise ValueError(\"Unknown scheme\")\n\n        b_weights = barycentric_weights(x_nodes)\n        y_q, w_q = get_gl_nodes_weights(Q)\n        \n        V_mat = np.zeros((Q, n_points), dtype=np.float64)\n        \n        # Denominator for second barycentric formula\n        bary_denom = np.zeros(Q, dtype=np.float64)\n        for k in range(n_points):\n            bary_denom += b_weights[k] / (y_q - x_nodes[k])\n\n        for j in range(n_points):\n            # Numerator for second barycentric formula\n            bary_num = b_weights[j] / (y_q - x_nodes[j])\n            V_mat[:, j] = bary_num / bary_denom\n            \n            # Handle cases where y_q is very close to a node x_j\n            # This is unlikely for roots of different Legendre polynomials\n            # but good practice for robustness.\n            exact_indices = np.where(np.isclose(y_q, x_nodes[j]))\n            if len(exact_indices[0]) > 0:\n                V_mat[exact_indices, :] = 0.0\n                V_mat[exact_indices, j] = 1.0\n\n        M_true = V_mat.T @ np.diag(w_q) @ V_mat\n        \n        # For GL, M_true is theoretically diagonal. rho should be near zero.\n        # This implementation computes it explicitly for both cases as a validation.\n\n        M_diag_only = np.diag(np.diag(M_true))\n        \n        num_norm = np.linalg.norm(M_true - M_diag_only, 'fro')\n        den_norm = np.linalg.norm(M_true, 'fro')\n        \n        if den_norm == 0:\n            return 0.0\n            \n        return num_norm / den_norm\n\n    # Test suite from the problem statement\n    dispersion_tests = [\n        (2, 1.0),\n        (4, 2.5),\n        (8, 7.0),\n        (6, 1e-6)\n    ]\n    mass_matrix_test_N = 6\n\n    results = []\n\n    # Run dispersion error tests\n    for N, kappa in dispersion_tests:\n        E_GL = compute_dispersion_error(N, kappa, 'GL')\n        E_GLL = compute_dispersion_error(N, kappa, 'GLL')\n        results.extend([E_GL, E_GLL])\n\n    # Run mass matrix diagonality test\n    rho_GL = compute_mass_matrix_diagonality(mass_matrix_test_N, 'GL')\n    rho_GLL = compute_mass_matrix_diagonality(mass_matrix_test_N, 'GLL')\n    results.extend([rho_GL, rho_GLL])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.15f}' for r in results)}]\")\n\nsolve()\n```", "id": "3388916"}]}