{"hands_on_practices": [{"introduction": "The effectiveness of a quadrature rule is fundamentally measured by its degree of precision—the highest degree of polynomial it can integrate exactly. This first practice invites you to derive this crucial property for the family of closed Newton-Cotes rules from first principles [@problem_id:3401945]. By analyzing the structure of the polynomial interpolation error, you will uncover how the symmetry of the equispaced nodes leads to a surprising bonus in accuracy for even-ordered rules, a key theoretical result in numerical integration.", "problem": "Consider a reference element $[0,1]$ in a Spectral Discontinuous Galerkin (DG) method where inner products of polynomial basis functions are evaluated by quadrature. Define the closed Newton–Cotes (NC) rule of index $n$ on $[0,1]$ as follows: let $x_j = \\frac{j}{n}$ for $j=0,1,\\dots,n$, and let $\\ell_j(x)$ be the Lagrange interpolation basis polynomials of degree at most $n$ associated with these nodes. The quadrature is the linear functional\n$$\nQ_n(f) = \\sum_{j=0}^{n} w_j f(x_j), \\quad \\text{with} \\quad w_j = \\int_{0}^{1} \\ell_j(x)\\,dx,\n$$\nwhich, by construction, integrates the degree-$n$ interpolant of $f$ exactly over $[0,1]$.\n\nIn the context of assembling DG mass matrices with a monomial basis $x^k$, test the exactness of $Q_n$ on monomials $x^k$ for $k=0,1,\\dots,n+1$. Starting only from the definitions above and fundamental properties of polynomial interpolation and symmetry, determine the maximal integer $k$ in $\\{0,1,\\dots,n+1\\}$ such that $Q_n(x^k) = \\int_{0}^{1} x^k\\,dx$ holds. Express your final answer as a single closed-form analytic expression in terms of $n$. No rounding is required, and no physical units are involved.", "solution": "The problem asks for the maximal integer $k$ in the set $\\{0, 1, \\dots, n+1\\}$ such that the closed Newton-Cotes quadrature rule $Q_n$ on the interval $[0,1]$ is exact for the monomial $x^k$. That is, we seek the maximal $k \\in \\{0, 1, \\dots, n+1\\}$ for which $Q_n(x^k) = \\int_{0}^{1} x^k \\,dx$.\n\nThe quadrature rule is defined as\n$$\nQ_n(f) = \\sum_{j=0}^{n} w_j f(x_j)\n$$\nwith nodes $x_j = \\frac{j}{n}$ for $j=0, 1, \\dots, n$, and weights $w_j = \\int_{0}^{1} \\ell_j(x) \\,dx$, where $\\ell_j(x)$ are the Lagrange basis polynomials of degree at most $n$ associated with the nodes $\\{x_j\\}$.\n\nBy definition of the weights, we can write the quadrature rule as\n$$\nQ_n(f) = \\sum_{j=0}^{n} \\left(\\int_{0}^{1} \\ell_j(x) \\,dx\\right) f(x_j) = \\int_{0}^{1} \\left(\\sum_{j=0}^{n} f(x_j) \\ell_j(x)\\right) \\,dx\n$$\nThe sum inside the integral, $\\sum_{j=0}^{n} f(x_j) \\ell_j(x)$, is the unique polynomial of degree at most $n$ that interpolates the function $f(x)$ at the $n+1$ nodes $\\{x_j\\}_{j=0}^n$. Let us denote this interpolating polynomial as $I_n(f)(x)$. The quadrature rule is therefore constructed to be the exact integral of the interpolant:\n$$\nQ_n(f) = \\int_{0}^{1} I_n(f)(x) \\,dx\n$$\n\nFirst, we establish the exactness of the rule for polynomials of degree up to $n$. Let $P(x)$ be any polynomial of degree at most $n$. A fundamental property of Lagrange interpolation is that the interpolating polynomial of degree at most $n$ for $P(x)$ passing through $n+1$ points on the graph of $P(x)$ is $P(x)$ itself. Therefore, $I_n(P)(x) = P(x)$.\n\nApplying this to the quadrature rule, we have:\n$$\nQ_n(P) = \\int_{0}^{1} I_n(P)(x) \\,dx = \\int_{0}^{1} P(x) \\,dx\n$$\nThis demonstrates that the closed Newton-Cotes rule of index $n$ is exact for all polynomials of degree up to $n$. The monomials $x^k$ for $k=0, 1, \\dots, n$ are all polynomials of degree at most $n$. Consequently, the rule is exact for these monomials:\n$$\nQ_n(x^k) = \\int_{0}^{1} x^k \\,dx \\quad \\text{for } k=0, 1, \\dots, n\n$$\nThis establishes that the maximal integer $k$ we seek is at least $n$.\n\nNow, we must investigate the case $k=n+1$. The exactness condition is $Q_n(x^{n+1}) = \\int_{0}^{1} x^{n+1} \\,dx$. The error of the quadrature rule for the function $f(x) = x^{n+1}$ is given by:\n$$\nE_n(x^{n+1}) = \\int_{0}^{1} x^{n+1} \\,dx - Q_n(x^{n+1})\n$$\nUsing the definition of $Q_n$, the error can be expressed as:\n$$\nE_n(x^{n+1}) = \\int_{0}^{1} x^{n+1} \\,dx - \\int_{0}^{1} I_n(x^{n+1})(x) \\,dx = \\int_{0}^{1} \\left( x^{n+1} - I_n(x^{n+1})(x) \\right) \\,dx\n$$\nThe term inside the integral is the error of polynomial interpolation for the function $f(x)=x^{n+1}$. The standard formula for the interpolation error is\n$$\nf(x) - I_n(f)(x) = \\frac{f^{(n+1)}(\\xi_x)}{(n+1)!} \\prod_{j=0}^{n} (x-x_j)\n$$\nfor some $\\xi_x$ in the interval spanned by $x$ and the nodes. For $f(x) = x^{n+1}$, the $(n+1)$-th derivative is a constant: $f^{(n+1)}(x) = (n+1)!$. Thus, the interpolation error simplifies to:\n$$\nx^{n+1} - I_n(x^{n+1})(x) = \\frac{(n+1)!}{(n+1)!} \\prod_{j=0}^{n} (x-x_j) = \\prod_{j=0}^{n} (x-x_j)\n$$\nLet's define the node polynomial $\\pi_{n+1}(x) = \\prod_{j=0}^{n} (x-x_j) = \\prod_{j=0}^{n} (x - \\frac{j}{n})$. The quadrature error for $x^{n+1}$ is the integral of this polynomial:\n$$\nE_n(x^{n+1}) = \\int_{0}^{1} \\pi_{n+1}(x) \\,dx\n$$\nThe quadrature rule is exact for $k=n+1$ if and only if this integral is zero. To evaluate this, we analyze the symmetry of the integrand. The nodes $x_j = j/n$ are symmetric about the midpoint of the integration interval $[0,1]$, which is $x=1/2$. Specifically, for any $j \\in \\{0, 1, \\dots, n\\}$, the node $x_j$ and the node $x_{n-j}$ are equidistant from the midpoint:\n$$\nx_j - \\frac{1}{2} = \\frac{j}{n} - \\frac{1}{2} = \\frac{2j-n}{2n}\n$$\n$$\nx_{n-j} - \\frac{1}{2} = \\frac{n-j}{n} - \\frac{1}{2} = \\frac{2(n-j)-n}{2n} = \\frac{n-2j}{2n} = -\\left(\\frac{2j-n}{2n}\\right) = -(x_j - \\frac{1}{2})\n$$\nLet us perform a change of variables $u = x - 1/2$, so $x = u + 1/2$. The interval of integration $[0,1]$ becomes $[-1/2, 1/2]$. The function $\\pi_{n+1}(x)$ becomes $\\tilde{\\pi}_{n+1}(u) = \\pi_{n+1}(u+1/2)$.\n$$\n\\tilde{\\pi}_{n+1}(u) = \\prod_{j=0}^{n} \\left(u + \\frac{1}{2} - x_j\\right) = \\prod_{j=0}^{n} \\left(u - \\left(x_j - \\frac{1}{2}\\right)\\right)\n$$\nWe examine the parity of $\\tilde{\\pi}_{n+1}(u)$.\n$$\n\\tilde{\\pi}_{n+1}(-u) = \\prod_{j=0}^{n} \\left(-u - (x_j - \\frac{1}{2})\\right) = (-1)^{n+1} \\prod_{j=0}^{n} \\left(u + (x_j - \\frac{1}{2})\\right)\n$$\nUsing the symmetry property $x_j - 1/2 = -(x_{n-j} - 1/2)$, the set of node-offsets $\\{x_j-1/2\\}_{j=0}^n$ is symmetric about $0$. Therefore, $\\prod_{j=0}^{n} (u + (x_j - 1/2)) = \\prod_{j=0}^{n} (u - (x_{n-j} - 1/2)) = \\prod_{k=0}^{n} (u - (x_k - 1/2)) = \\tilde{\\pi}_{n+1}(u)$.\nThus, we have the symmetry relation:\n$$\n\\tilde{\\pi}_{n+1}(-u) = (-1)^{n+1} \\tilde{\\pi}_{n+1}(u)\n$$\nThis means that $\\tilde{\\pi}_{n+1}(u)$ is an odd function if $n+1$ is odd (i.e., if $n$ is even), and an even function if $n+1$ is even (i.e., if $n$ is odd).\n\nThe error integral is $E_n(x^{n+1}) = \\int_{-1/2}^{1/2} \\tilde{\\pi}_{n+1}(u) \\,du$.\n\nCase 1: $n$ is even.\nIn this case, $n+1$ is odd, and $\\tilde{\\pi}_{n+1}(u)$ is an odd function. The integral of an odd function over a symmetric interval $[-1/2, 1/2]$ is zero.\n$$\nE_n(x^{n+1}) = \\int_{-1/2}^{1/2} \\tilde{\\pi}_{n+1}(u) \\,du = 0\n$$\nTherefore, for even $n$, the quadrature rule is exact for $k=n+1$.\n\nCase 2: $n$ is odd.\nIn this case, $n+1$ is even, and $\\tilde{\\pi}_{n+1}(u)$ is an even function. An even polynomial that is not identically zero will not integrate to zero over a symmetric interval $[-a,a]$ unless it is identically zero. $\\tilde{\\pi}_{n+1}(u)$ is a non-zero polynomial of degree $n+1$, so its integral is non-zero. For example, for $n=1$, we get the trapezoidal rule, and the error integral is $\\int_0^1 x(x-1)dx = [x^3/3 - x^2/2]_0^1 = 1/3 - 1/2 = -1/6 \\neq 0$.\nThus, for odd $n$, the quadrature rule is not exact for $k=n+1$.\n\nSummary of results:\n- For any $n$, $Q_n(x^k)$ is exact for $k=0, 1, \\dots, n$.\n- If $n$ is even, $Q_n(x^{n+1})$ is also exact. It can be shown that $Q_n(x^{n+2})$ is not exact.\n- If $n$ is odd, $Q_n(x^{n+1})$ is not exact.\n\nThe problem asks for the maximal integer $k$ in the set $\\{0, 1, \\dots, n+1\\}$ for which the rule is exact.\n- If $n$ is even, the rule is exact for $k=0, \\dots, n, n+1$. The maximum such $k$ is $n+1$.\n- If $n$ is odd, the rule is exact for $k=0, \\dots, n$, but not for $k=n+1$. The maximum such $k$ is $n$.\n\nWe need to find a single closed-form expression for this result. The value is $n+1$ for even $n$ and $n$ for odd $n$. This can be written as:\n$$\nk_{\\text{max}} = n + \\begin{cases} 1  \\text{if } n \\text{ is even} \\\\ 0  \\text{if } n \\text{ is odd} \\end{cases}\n$$\nThe case distinction can be represented using $(-1)^n$, which is $1$ for even $n$ and $-1$ for odd $n$. The expression for the additional term is $\\frac{1+(-1)^n}{2}$. This is $1$ if $n$ is even and $0$ if $n$ is odd.\nTherefore, the maximal integer $k$ is given by the expression $n + \\frac{1+(-1)^n}{2}$.", "answer": "$$\n\\boxed{n + \\frac{1+(-1)^{n}}{2}}\n$$", "id": "3401945"}, {"introduction": "While Newton-Cotes formulas are exact for polynomials, their performance degrades significantly when faced with non-polynomial behavior, such as endpoint singularities. This exercise demonstrates this critical limitation by applying an open Newton-Cotes rule to an integrable but singular function, a scenario commonly encountered in spectral and Discontinuous Galerkin methods [@problem_id:3401936]. Completing this problem will highlight the inadequacy of standard rules for such integrands and motivate the need for more robust strategies like variable transformations or specialized weighted quadrature.", "problem": "In the context of high-order Discontinuous Galerkin (DG) and spectral element discretizations, boundary-adjacent integrals can exhibit algebraic endpoint singularities that challenge standard closed Newton–Cotes quadrature formulas. Consider the integral\n$$\n\\int_{0}^{1} x^{-1/2}\\,dx,\n$$\nwhich is integrable but has a square-root singularity at the left endpoint. To emulate a common practice of excluding endpoints in DG flux integrals, derive from first principles the three-point open Newton–Cotes quadrature rule on the interval $[0,1]$ with equally spaced interior nodes, and use it to produce a single exact analytic expression that approximates the integral above.\n\nYour derivation must start from fundamental definitions: construct the degree-$2$ Lagrange interpolating polynomial on the three equally spaced interior nodes and integrate it exactly over $[0,1]$ to obtain the quadrature weights. Then evaluate the resulting quadrature applied to $f(x)=x^{-1/2}$ at the specified nodes to obtain the requested exact analytic expression.\n\nFinally, explain, without invoking any pretabulated quadrature formulas, why either a change of variables that regularizes the endpoint singularity or a weighted orthogonal polynomial quadrature aligned with the singular weight can substantially improve accuracy in spectral and Discontinuous Galerkin (DG) methods. You may refer to Gauss–Jacobi quadrature, fully spelled out on first use as Gauss–Jacobi Quadrature (GJQ), to illustrate the weighted approach conceptually, but do not compute any alternative numerical approximations.\n\nDo not round; provide the open Newton–Cotes approximation as a single closed-form analytic expression.", "solution": "First, we derive the three-point open Newton–Cotes quadrature rule on the interval $[0, 1]$. This rule uses three equally spaced interior nodes. For an interval $[a, b]$ and $n=3$ interior nodes, the step size $h$ is given by $h = (b-a)/(n+1)$. With $a=0$ and $b=1$, we have $h = (1-0)/(3+1) = 1/4$. The nodes $x_j$ for $j=1, 2, 3$ are located at $x_j = a + j h$.\nThe quadrature nodes are:\n$$\nx_1 = 0 + 1 \\cdot \\frac{1}{4} = \\frac{1}{4} \\\\\nx_2 = 0 + 2 \\cdot \\frac{1}{4} = \\frac{1}{2} \\\\\nx_3 = 0 + 3 \\cdot \\frac{1}{4} = \\frac{3}{4}\n$$\nThe quadrature rule approximates the integral of a function $f(x)$ by integrating its degree-$2$ Lagrange interpolating polynomial $P_2(x)$ through these nodes. The polynomial is given by $P_2(x) = \\sum_{j=1}^{3} f(x_j) L_j(x)$, where $L_j(x)$ are the Lagrange basis polynomials.\nThe quadrature approximation is $\\int_0^1 f(x) dx \\approx \\int_0^1 P_2(x) dx = \\sum_{j=1}^{3} f(x_j) \\left(\\int_0^1 L_j(x) dx\\right) = \\sum_{j=1}^{3} w_j f(x_j)$. The weights $w_j$ are the integrals of the basis polynomials $L_j(x)$ over $[0, 1]$.\n\nThe Lagrange basis polynomials for nodes $x_1=1/4$, $x_2=1/2$, and $x_3=3/4$ are:\n$$\nL_1(x) = \\frac{(x-x_2)(x-x_3)}{(x_1-x_2)(x_1-x_3)} = \\frac{(x-1/2)(x-3/4)}{(1/4-1/2)(1/4-3/4)} = \\frac{x^2 - \\frac{5}{4}x + \\frac{3}{8}}{(-\\frac{1}{4})(-\\frac{2}{4})} = \\frac{x^2 - \\frac{5}{4}x + \\frac{3}{8}}{1/8} = 8x^2 - 10x + 3\n$$\n$$\nL_2(x) = \\frac{(x-x_1)(x-x_3)}{(x_2-x_1)(x_2-x_3)} = \\frac{(x-1/4)(x-3/4)}{(1/2-1/4)(1/2-3/4)} = \\frac{x^2 - x + \\frac{3}{16}}{(\\frac{1}{4})(-\\frac{1}{4})} = \\frac{x^2 - x + \\frac{3}{16}}{-1/16} = -16x^2 + 16x - 3\n$$\n$$\nL_3(x) = \\frac{(x-x_1)(x-x_2)}{(x_3-x_1)(x_3-x_2)} = \\frac{(x-1/4)(x-1/2)}{(3/4-1/4)(3/4-1/2)} = \\frac{x^2 - \\frac{3}{4}x + \\frac{1}{8}}{(\\frac{2}{4})(\\frac{1}{4})} = \\frac{x^2 - \\frac{3}{4}x + \\frac{1}{8}}{1/8} = 8x^2 - 6x + 1\n$$\nNext, we compute the weights $w_j$ by integrating these polynomials from $0$ to $1$:\n$$\nw_1 = \\int_{0}^{1} (8x^2 - 10x + 3) dx = \\left[ \\frac{8}{3}x^3 - 5x^2 + 3x \\right]_{0}^{1} = \\frac{8}{3} - 5 + 3 = \\frac{2}{3}\n$$\n$$\nw_2 = \\int_{0}^{1} (-16x^2 + 16x - 3) dx = \\left[ -\\frac{16}{3}x^3 + 8x^2 - 3x \\right]_{0}^{1} = -\\frac{16}{3} + 8 - 3 = -\\frac{1}{3}\n$$\n$$\nw_3 = \\int_{0}^{1} (8x^2 - 6x + 1) dx = \\left[ \\frac{8}{3}x^3 - 3x^2 + x \\right]_{0}^{1} = \\frac{8}{3} - 3 + 1 = \\frac{2}{3}\n$$\nThe three-point open Newton–Cotes rule on $[0, 1]$ is therefore:\n$$\n\\int_0^1 f(x) dx \\approx \\frac{2}{3}f\\left(\\frac{1}{4}\\right) - \\frac{1}{3}f\\left(\\frac{1}{2}\\right) + \\frac{2}{3}f\\left(\\frac{3}{4}\\right)\n$$\nNow, we apply this rule to the function $f(x) = x^{-1/2}$. The open nature of the quadrature rule is crucial as it avoids evaluating the function at the singularity $x=0$.\nWe evaluate $f(x)$ at the nodes:\n$$\nf(x_1) = f\\left(\\frac{1}{4}\\right) = \\left(\\frac{1}{4}\\right)^{-1/2} = 4^{1/2} = 2\n$$\n$$\nf(x_2) = f\\left(\\frac{1}{2}\\right) = \\left(\\frac{1}{2}\\right)^{-1/2} = 2^{1/2} = \\sqrt{2}\n$$\n$$\nf(x_3) = f\\left(\\frac{3}{4}\\right) = \\left(\\frac{3}{4}\\right)^{-1/2} = \\left(\\frac{4}{3}\\right)^{1/2} = \\frac{2}{\\sqrt{3}} = \\frac{2\\sqrt{3}}{3}\n$$\nSubstituting these values into the quadrature formula gives the approximation of the integral:\n$$\n\\int_{0}^{1} x^{-1/2}\\,dx \\approx \\frac{2}{3}(2) - \\frac{1}{3}(\\sqrt{2}) + \\frac{2}{3}\\left(\\frac{2\\sqrt{3}}{3}\\right) = \\frac{4}{3} - \\frac{\\sqrt{2}}{3} + \\frac{4\\sqrt{3}}{9}\n$$\nTo express this as a single fraction, we find a common denominator, which is $9$:\n$$\n\\frac{4 \\cdot 3}{9} - \\frac{\\sqrt{2} \\cdot 3}{9} + \\frac{4\\sqrt{3}}{9} = \\frac{12 - 3\\sqrt{2} + 4\\sqrt{3}}{9}\n$$\n\nFinally, we explain why alternative approaches are superior for this type of problem. The core issue is that Newton–Cotes rules approximate the integrand $f(x)$ with a single, globally smooth polynomial. The function $f(x) = x^{-1/2}$ has a vertical asymptote at $x=0$, and its derivatives are also singular at that point. No single low-degree polynomial can accurately capture this behavior over the entire interval $[0, 1]$. This mismatch between the smooth polynomial approximant and the singular function leads to large errors and slow convergence, a significant problem in high-order methods like DG and spectral elements where rapid (exponential) convergence is desired for smooth problems.\n\nTwo superior strategies are:\n1.  **Change of Variables (Regularization)**: This technique transforms the integral to one with a regular (smooth) integrand. For $\\int_0^1 x^{-1/2} dx$, the substitution $x = u^2$ with $dx = 2u\\,du$ transforms the integral to $\\int_0^1 (u^2)^{-1/2} (2u\\,du) = \\int_0^1 u^{-1} (2u\\,du) = \\int_0^1 2\\,du$. The new integrand is a constant, $g(u)=2$, which is infinitely smooth. Any standard quadrature rule can now integrate it with very high, often exact, accuracy. This removes the singularity, restoring the rapid convergence of high-order methods.\n\n2.  **Weighted Orthogonal Polynomial Quadrature**: This approach modifies the quadrature rule to be optimal for a specific class of singular functions. The integral is viewed as $\\int_0^1 w(x)g(x)dx$, where $w(x)=x^{-1/2}$ is a weight function and $g(x)=1$. Gaussian quadrature rules provide optimal accuracy for a given number of points against a specific weight function. For weight functions of the form $(1-z)^\\alpha (1+z)^\\beta$ on the interval $[-1, 1]$, the corresponding optimal rule is Gauss–Jacobi Quadrature (GJQ). The singularity $x^{-1/2}$ on $[0, 1]$ can be mapped to a Jacobi-type weight on $[-1, 1]$. A GJQ rule's nodes and weights are specifically chosen to exactly integrate products of the weight function and polynomials up to a high degree. By \"building\" the singular behavior into the quadrature rule itself, GJQ achieves very high accuracy even with few points, as it only needs to approximate the non-singular part of the integrand ($g(x)=1$ in this case), which is trivial. In spectral and DG methods, this corresponds to using basis functions (e.g., Jacobi polynomials) that are orthogonal with respect to the singular weight, which again restores exponential convergence.\n\nIn contrast, the Newton-Cotes formula, which is designed for an unweighted integral (i.e., $w(x)=1$), is fundamentally ill-suited for the task and its accuracy cannot be substantially improved merely by increasing the number of points.", "answer": "$$\n\\boxed{\\frac{12 - 3\\sqrt{2} + 4\\sqrt{3}}{9}}\n$$", "id": "3401936"}, {"introduction": "The choice of quadrature can have profound consequences that extend beyond simple integration error, impacting the stability of the entire numerical scheme. This practice explores one such critical link: how the negative weights of high-order Newton-Cotes rules can destroy the symmetric positive definiteness of the discrete diffusion operator in a Discontinuous Galerkin (DG) method [@problem_id:3401958]. By constructing the discrete operator and analyzing its eigenvalues, you will gain direct insight into how an seemingly abstract property of a quadrature rule can lead to a catastrophic failure of stability in a PDE solver.", "problem": "Consider the one-dimensional diffusion operator in Discontinuous Galerkin (DG) form, restricted to a single element mapped to the reference interval $\\left[-1,1\\right]$. The elemental volume contribution to the bilinear form for diffusion is defined by\n$$\na(u,v) \\;=\\; \\int_{-1}^{1} \\partial_x u(x)\\,\\partial_x v(x)\\,\\mathrm{d}x,\n$$\nwhere $u$ and $v$ belong to a polynomial space on the reference element. In spectral DG practice, a common choice is to represent functions using Legendre polynomials $\\{P_n(x)\\}_{n\\ge 0}$ on $\\left[-1,1\\right]$. To avoid the null mode in the diffusion energy, we consider the subspace spanned by $\\{P_n(x)\\}_{n=1}^{p}$, i.e., we exclude the constant mode $P_0$.\n\nNumerical integration is performed by a Newton–Cotes quadrature formula. Let a closed Newton–Cotes rule be defined over $\\left[-1,1\\right]$ by $N$ equispaced nodes including the endpoints:\n$$\nx_k \\;=\\; -1 + \\frac{2k}{N-1}, \\quad k=0,1,\\dots,N-1,\n$$\nwith associated weights $\\{w_k\\}_{k=0}^{N-1}$. The quadrature approximates integrals of the form $\\int_{-1}^{1} g(x)\\,\\mathrm{d}x$ by the weighted sum $\\sum_{k=0}^{N-1} w_k\\,g(x_k)$. The closed Newton–Cotes weights are defined by exactness on algebraic monomials up to degree $N-1$:\n$$\n\\sum_{k=0}^{N-1} w_k\\,x_k^m \\;=\\; \\int_{-1}^{1} x^m\\,\\mathrm{d}x, \\quad m=0,1,\\dots,N-1.\n$$\nIt is well known that for sufficiently large $N$, some closed Newton–Cotes weights become negative. Underintegration refers to using a quadrature whose exactness degree is lower than the degree required to integrate the bilinear form exactly on the chosen polynomial space.\n\nThe discrete elemental operator (Gram matrix of the bilinear form) is constructed as follows. Let $D(x)$ denote the column vector of derivatives of the Legendre basis functions,\n$$\nD(x) \\;=\\; \\begin{bmatrix} P_1'(x) \\\\ P_2'(x) \\\\ \\vdots \\\\ P_p'(x) \\end{bmatrix},\n$$\nand define the discrete Gram matrix $G\\in\\mathbb{R}^{p\\times p}$ by\n$$\nG \\;=\\; \\sum_{k=0}^{N-1} w_k\\, D(x_k)\\,D(x_k)^\\top.\n$$\nThis construction corresponds to applying the closed Newton–Cotes quadrature to the integrand $\\partial_x P_i(x)\\,\\partial_x P_j(x)$ for all basis indices $i,j$. The symmetric positive definiteness of the bilinear form is lost if the smallest eigenvalue of $G$ is non-positive, which may result either from rank deficiency (e.g., underintegration leading to zero eigenvalues) or from indefiniteness (e.g., negative weights causing negative eigenvalues).\n\nYour task is to implement a program that, for a prescribed set of polynomial degrees $p$ and numbers of quadrature points $N$, constructs $G$ via the procedure above, computes its spectrum, and determines whether symmetric positive definiteness is lost. Use the following test suite:\n- Case $1$: $p=3$, $N=5$.\n- Case $2$: $p=5$, $N=4$ (underintegration with fewer quadrature points than basis dimension).\n- Case $3$: $p=9$, $N=11$ (high-order closed Newton–Cotes with known negative weights).\n- Case $4$: $p=1$, $N=2$ (baseline trapezoidal rule).\n- Case $5$: $p=8$, $N=9$ (closed Newton–Cotes with negative weights).\n\nFor each case:\n1. Construct the closed Newton–Cotes weights $\\{w_k\\}_{k=0}^{N-1}$ by enforcing polynomial exactness up to degree $N-1$ on the equispaced nodes on $\\left[-1,1\\right]$.\n2. Evaluate $P_n'(x_k)$ for $n=1,\\dots,p$ at all quadrature nodes $x_k$.\n3. Assemble $G$ as above and symmetrize it by taking $\\frac{1}{2}\\left(G+G^\\top\\right)$.\n4. Compute the sorted eigenvalues of $G$ in ascending order.\n5. Determine whether symmetric positive definiteness is lost by checking if the smallest eigenvalue is less than or equal to a tolerance $\\varepsilon=10^{-10}$.\n\nYour program must output a single line containing a list of length equal to the number of test cases. Each entry in this list must itself be a list consisting of the sorted eigenvalues (floats) followed by a boolean indicating loss of symmetric positive definiteness (use $True$ if the smallest eigenvalue is $\\le \\varepsilon$, and $False$ otherwise). For example, the output format must look like\n$$\n\\big[ \\,[\\lambda_1,\\lambda_2,\\dots,\\lambda_p,\\text{flag}],\\; \\dots \\,\\big],\n$$\nwith no spaces in the printed string.\n\nNo physical units or angle units are involved. All numerical values must be expressed as floating-point numbers, and all logical decisions must be expressed as booleans. The final line produced by your program should be exactly the list described above, printed as a single line with comma-separated entries enclosed in square brackets.", "solution": "The problem requires an analysis of the symmetric positive definiteness of a discrete one-dimensional diffusion operator constructed using a spectral basis of Legendre polynomials within the Discontinuous Galerkin (DG) framework. The integration is performed numerically using closed Newton-Cotes quadrature rules. For specified polynomial degrees $p$ and numbers of quadrature points $N$, we are to construct the discrete Gram matrix $G$, compute its eigenvalues, and determine if positive definiteness is lost. Loss of positive definiteness is defined as the smallest eigenvalue being less than or equal to a tolerance $\\varepsilon = 10^{-10}$.\n\nThe procedure involves several distinct mathematical and computational steps, which are detailed below.\n\nFirst, we define the computational environment. The analysis is performed on the reference element, the interval $\\left[-1, 1\\right]$. The polynomial basis for the DG space is chosen to be $\\{P_n(x)\\}_{n=1}^p$, where $P_n(x)$ is the Legendre polynomial of degree $n$. The constant mode $P_0(x)$ is excluded to eliminate the trivial null mode of the diffusion operator.\n\nThe core of the problem lies in the construction and analysis of the discrete Gram matrix $G$, whose entries are given by the numerical quadrature of the bilinear form $a(u,v) = \\int_{-1}^{1} (\\partial_x u)(\\partial_x v) \\mathrm{d}x$ with $u=P_i(x)$ and $v=P_j(x)$. The discrete matrix $G \\in \\mathbb{R}^{p\\times p}$ is defined as:\n$$\nG_{ij} = \\sum_{k=0}^{N-1} w_k P_i'(x_k) P_j'(x_k).\n$$\n\nThe overall algorithm proceeds as follows for each test case $(p, N)$:\n\n1.  **Construct the Closed Newton-Cotes Quadrature Rule**\n\n    A closed Newton-Cotes quadrature rule on the interval $\\left[-1, 1\\right]$ with $N$ points is defined by a set of $N$ equispaced nodes $\\{x_k\\}_{k=0}^{N-1}$ and corresponding weights $\\{w_k\\}_{k=0}^{N-1}$.\n\n    The nodes are given by the formula:\n    $$\n    x_k = -1 + \\frac{2k}{N-1}, \\quad \\text{for } k=0, 1, \\dots, N-1.\n    $$\n    The weights are determined by enforcing that the quadrature rule exactly integrates polynomials up to degree $N-1$. This leads to a system of $N$ linear equations for the $N$ weights:\n    $$\n    \\sum_{k=0}^{N-1} w_k x_k^m = \\int_{-1}^{1} x^m \\mathrm{d}x, \\quad \\text{for } m=0, 1, \\dots, N-1.\n    $$\n    The integral on the right-hand side evaluates to:\n    $$\n    \\int_{-1}^{1} x^m \\mathrm{d}x = \\frac{1 - (-1)^{m+1}}{m+1} = \\begin{cases} \\frac{2}{m+1}  \\text{if } m \\text{ is even} \\\\ 0  \\text{if } m \\text{ is odd} \\end{cases}.\n    $$\n    This linear system can be written in matrix form as $V \\mathbf{w} = \\mathbf{b}$, where $V$ is a Vandermonde matrix with entries $V_{mk} = x_k^m$, $\\mathbf{w}$ is the column vector of weights $[w_0, \\dots, w_{N-1}]^\\top$, and $\\mathbf{b}$ is the column vector of the monomial integrals. Solving this system yields the required weights. For $N \\ge 9$ (and some other values like $N=8$), some of these weights become negative, which can compromise the positive definiteness of the resulting discrete operator.\n\n2.  **Evaluate Derivatives of Legendre Polynomials**\n\n    The basis functions are the Legendre polynomials $\\{P_n(x)\\}_{n=1}^p$. We require their first derivatives, $\\{P_n'(x)\\}_{n=1}^p$. These derivatives are themselves polynomials. For each basis function $P_n'(x)$, we must evaluate it at all the quadrature nodes $\\{x_k\\}$. This yields a set of values $P_n'(x_k)$ for $n \\in \\{1, \\dots, p\\}$ and $k \\in \\{0, \\dots, N-1\\}$. These evaluations can be organized into a matrix $D_{\\text{eval}} \\in \\mathbb{R}^{p \\times N}$ where $(D_{\\text{eval}})_{nk} = P_{n+1}'(x_k)$ (using $0$-based indexing for rows).\n\n3.  **Assemble the Discrete Gram Matrix $G$**\n\n    The Gram matrix $G$ is defined by the sum:\n    $$\n    G = \\sum_{k=0}^{N-1} w_k D(x_k) D(x_k)^\\top,\n    $$\n    where $D(x_k)$ is the column vector of basis function derivatives evaluated at node $x_k$:\n    $$\n    D(x_k) = \\begin{bmatrix} P_1'(x_k) \\\\ P_2'(x_k) \\\\ \\vdots \\\\ P_p'(x_k) \\end{bmatrix}.\n    $$\n    Using the matrix of evaluations $D_{\\text{eval}}$ from the previous step and a diagonal matrix $W = \\text{diag}(w_0, \\dots, w_{N-1})$, the matrix $G$ can be computed efficiently as:\n    $$\n    G = D_{\\text{eval}} W D_{\\text{eval}}^\\top.\n    $$\n    From this construction, we can infer potential sources of rank deficiency. The rank of $G$ is at most the rank of $W$ (which is $N$ if all weights are non-zero) and at most the rank of $D_{\\text{eval}}$ (which is at most $\\min(p, N)$). If $N  p$, the rank of $G$ is at most $N$, meaning $G$ will be a $p \\times p$ matrix with rank less than $p$. It will therefore have at least $p-N$ zero eigenvalues, leading to a loss of positive definiteness. This situation is referred to as underintegration.\n\n4.  **Analyze Symmetric Positive Definiteness**\n\n    Theoretically, the matrix $G$ as constructed is symmetric. However, due to floating-point arithmetic, small asymmetries may arise. To ensure a valid eigenvalue decomposition for a symmetric matrix, we first explicitly symmetrize $G$:\n    $$\n    G_{\\text{sym}} = \\frac{1}{2} (G + G^\\top).\n    $$\n    Next, we compute the eigenvalues of $G_{\\text{sym}}$. Since $G_{\\text{sym}}$ is a real symmetric matrix, all its eigenvalues are real. We sort these eigenvalues in ascending order: $\\lambda_1 \\le \\lambda_2 \\le \\dots \\le \\lambda_p$.\n\n    A matrix is symmetric positive definite if and only if all its eigenvalues are strictly positive. The problem defines loss of symmetric positive definiteness as the condition where the smallest eigenvalue, $\\lambda_1$, is non-positive. We check this condition using the given tolerance $\\varepsilon = 10^{-10}$:\n    $$\n    \\text{Loss of SPD} \\iff \\lambda_1 \\le \\varepsilon.\n    $$\n    A boolean flag is set based on this outcome ($True$ for loss, $False$ for preservation). The final result for each case comprises the sorted list of eigenvalues and this boolean flag.\n\nThis procedure is applied to each of the specified test cases, and the results are aggregated into the final output format. The chosen test cases are designed to highlight different numerical phenomena: stable integration ($p=3, N=5$), rank deficiency from underintegration ($p=5, N=4$), and indefiniteness from negative quadrature weights ($p=9, N=11$ and $p=8, N=9$). The case $p=1, N=2$ serves as a simple, stable baseline corresponding to the trapezoidal rule.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import legendre\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test cases, analyzing the symmetric positive\n    definiteness of a DG diffusion operator matrix.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (3, 5),   # Case 1\n        (5, 4),   # Case 2\n        (9, 11),  # Case 3\n        (1, 2),   # Case 4\n        (8, 9),   # Case 5\n    ]\n    \n    epsilon = 1e-10\n    all_results = []\n\n    for p, N in test_cases:\n        # Step 1: Construct the Closed Newton-Cotes Quadrature Rule\n        # Generate N equispaced nodes on [-1, 1]\n        nodes = np.linspace(-1.0, 1.0, N)\n\n        # Determine weights by solving the linear system for polynomial exactness\n        # The system is V.T @ w = b, where V is a Vandermonde matrix\n        V = np.vander(nodes, N, increasing=True).T\n        \n        # Right-hand side: integrals of x^m from -1 to 1\n        b = np.zeros(N)\n        for m in range(N):\n            if (m + 1) % 2 != 0:\n                b[m] = 2.0 / (m + 1)\n        \n        weights = np.linalg.solve(V, b)\n\n        # Step 2: Evaluate Derivatives of Legendre Polynomials\n        # D_eval is a p x N matrix where D_eval[i, j] = P_{i+1}'(nodes[j])\n        D_eval = np.zeros((p, N))\n        for n_poly in range(1, p + 1):\n            P_n = legendre(n_poly)\n            P_n_prime = P_n.deriv()\n            D_eval[n_poly - 1, :] = P_n_prime(nodes)\n\n        # Step 3: Assemble the Discrete Gram Matrix G\n        # G = D_eval @ diag(weights) @ D_eval.T\n        G = D_eval @ np.diag(weights) @ D_eval.T\n        \n        # Step 4: Analyze Symmetric Positive Definiteness\n        # Symmetrize the matrix to correct for potential floating point inaccuracies\n        G_sym = 0.5 * (G + G.T)\n        \n        # Compute eigenvalues. eigvalsh returns them sorted in ascending order.\n        eigenvalues = np.linalg.eigvalsh(G_sym)\n        \n        # Check if the smallest eigenvalue is non-positive within the tolerance\n        is_lost = eigenvalues[0] = epsilon\n        \n        # Format the result for this test case\n        result_case = eigenvalues.tolist() + [is_lost]\n        all_results.append(result_case)\n\n    # Final print statement in the exact required format.\n    results_str_list = []\n    for res in all_results:\n        # The last element is a boolean, the rest are floats.\n        # str() on a boolean gives 'True' or 'False' with a capital letter, as required.\n        str_vals = [f\"{v}\" for v in res]\n        results_str_list.append(f\"[{','.join(str_vals)}]\")\n    \n    print(f\"[{','.join(results_str_list)}]\")\n\nsolve()\n```", "id": "3401958"}]}