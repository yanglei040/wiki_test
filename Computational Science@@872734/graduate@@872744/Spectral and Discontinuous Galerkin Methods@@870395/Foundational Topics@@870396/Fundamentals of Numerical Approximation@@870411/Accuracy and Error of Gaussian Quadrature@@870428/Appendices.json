{"hands_on_practices": [{"introduction": "The remarkable efficiency of Gaussian quadrature is predicated on the integrand being well-approximated by a polynomial. This practice explores what happens when this core assumption is violated, specifically for a function with an essential singularity. By analyzing the behavior of Gauss-Legendre quadrature for the integral of $\\sin(1/x)$, you will confront the limitations of standard error bounds and learn to recognize when a numerical method is being pushed beyond its domain of applicability [@problem_id:2419556]. This exercise hones the critical skill of diagnosing numerical failures and considering robust alternatives, such as coordinate transformations, for handling challenging integrals.", "problem": "Consider the integral $I=\\int_{0}^{1}\\sin\\!\\left(\\tfrac{1}{x}\\right)\\,dx$ and the application of a standard $n$-point Gauss–Legendre quadrature rule on the interval $[0,1]$ with weight function $w(x)=1$. The integrand is bounded but exhibits an essential singularity at $x=0$ in the sense that it oscillates infinitely often as $x\\to 0^{+}$ and does not admit a continuous extension at the endpoint. Select all statements that are correct about the behavior of Gauss–Legendre quadrature for this problem and about viable remedies.\n\nA. The textbook remainder expression for Gauss–Legendre quadrature, which involves a bound on $f^{(2n)}(\\xi)$ for some $\\xi\\in(0,1)$, does not yield a finite a priori bound here because $f^{(k)}(x)$ is unbounded as $x\\to 0^{+}$ for every integer $k\\ge 1$.\n\nB. The substitution $t=\\tfrac{1}{x}$ converts $I$ into $\\int_{1}^{\\infty}\\sin t\\;t^{-2}\\,dt$, which is absolutely convergent; evaluating the truncated integral $\\int_{1}^{T}\\sin t\\;t^{-2}\\,dt$ numerically on $[1,T]$ and bounding the tail $\\int_{T}^{\\infty}\\sin t\\;t^{-2}\\,dt$ provides a reliable computational strategy.\n\nC. Because $|\\sin(1/x)|\\le 1$ on $[0,1]$, the error of any fixed $n$-point Gauss–Legendre quadrature on $[0,1]$ is bounded uniformly by a constant times $n^{-2n}$, independent of the oscillations near $x=0$.\n\nD. Gauss–Legendre quadrature converges exponentially fast in $n$ for $I$ because $f(x)=\\sin(1/x)$ is infinitely differentiable on $(0,1]$.\n\nE. Using a composite quadrature or a change of variables that clusters nodes near $x=0$ (for example, a double-exponential mapping) can overcome the poor performance of plain Gauss–Legendre by resolving the rapid oscillations near the endpoint, yielding substantially improved convergence at comparable total node counts.", "solution": "We analyze the integral $I=\\int_{0}^{1}\\sin\\!\\left(\\tfrac{1}{x}\\right)\\,dx$ and the behavior of Gauss–Legendre quadrature from basic principles.\n\nFirst, note that the integrand $f(x)=\\sin\\!\\left(\\tfrac{1}{x}\\right)$ is bounded on $(0,1]$ and integrable on $[0,1]$ because the oscillations near $x=0$ cancel sufficiently rapidly when measured against the measure $dx$; however, $f$ does not admit a continuous extension at $x=0$ and oscillates infinitely often as $x\\to 0^{+}$. Moreover, the derivatives of $f$ exhibit blow-up as $x\\to 0^{+}$. For example, by the chain rule,\n$$\nf'(x)=\\frac{d}{dx}\\sin\\!\\left(\\tfrac{1}{x}\\right)=-\\cos\\!\\left(\\tfrac{1}{x}\\right)\\,\\frac{1}{x^{2}},\n$$\nwhich is unbounded in any neighborhood of $x=0$. Higher derivatives contain successively higher powers of $\\tfrac{1}{x}$ multiplied by $\\sin\\!\\left(\\tfrac{1}{x}\\right)$ or $\\cos\\!\\left(\\tfrac{1}{x}\\right)$, and are therefore also unbounded as $x\\to 0^{+}$. This immediately impacts any error analysis for Gaussian quadrature that relies on bounded higher derivatives of the integrand.\n\nNext, consider the variable transformation $t=\\tfrac{1}{x}$, which yields $x=\\tfrac{1}{t}$ and $dx=-t^{-2}\\,dt$. Changing variables gives\n$$\nI=\\int_{0}^{1}\\sin\\!\\left(\\tfrac{1}{x}\\right)\\,dx=\\int_{\\infty}^{1}\\sin t\\;(-t^{-2})\\,dt=\\int_{1}^{\\infty}\\frac{\\sin t}{t^{2}}\\,dt.\n$$\nThe absolute integrability follows from the comparison $|\\sin t|/t^{2}\\le 1/t^{2}$ and the convergence of $\\int_{1}^{\\infty}t^{-2}\\,dt$. Moreover, for any $T>1$,\n$$\n\\left|\\int_{T}^{\\infty}\\frac{\\sin t}{t^{2}}\\,dt\\right|\\le \\int_{T}^{\\infty}\\frac{|\\sin t|}{t^{2}}\\,dt\\le \\int_{T}^{\\infty}\\frac{dt}{t^{2}}=\\frac{1}{T},\n$$\nso truncation at a finite $T$ introduces a tail error that admits a simple and rigorous bound. The truncated integral on $[1,T]$ can be computed with standard quadrature for smooth functions on a finite interval.\n\nFinally, regarding node placement, Gauss–Legendre quadrature on $[0,1]$ uses nodes strictly inside the interval and does not include the endpoint $x=0$. The nodes do not adapt to the integrand’s infinitely rapid oscillations near $x=0$ unless $n$ is made sufficiently large so that the smallest spacing near the endpoint resolves the local oscillation scale in $x$. Methods that deliberately cluster nodes near $x=0$, such as composite rules with geometrically refined panels or coordinate mappings with double-exponential clustering, can significantly improve resolution of the oscillations and thus improve convergence.\n\nWe now evaluate each option.\n\nOption A: The standard Gauss–Legendre remainder formula involves a term proportional to $f^{(2n)}(\\xi)$ for some $\\xi\\in(0,1)$, together with a known constant depending on $n$. Since $f^{(k)}(x)$ is unbounded as $x\\to 0^{+}$ for all integers $k\\ge 1$, one cannot establish a finite a priori bound on the error via this route; the hypothesis required for the textbook bound fails. Verdict — Correct.\n\nOption B: With $t=\\tfrac{1}{x}$, the integral becomes $\\int_{1}^{\\infty}\\sin t\\;t^{-2}\\,dt$. This integral is absolutely convergent by comparison to $\\int_{1}^{\\infty}t^{-2}\\,dt$. A numerical strategy that evaluates $\\int_{1}^{T}\\sin t\\;t^{-2}\\,dt$ (for sufficiently large $T$) and bounds the tail by $\\left|\\int_{T}^{\\infty}\\sin t\\;t^{-2}\\,dt\\right|\\le 1/T$ is sound and practical. Verdict — Correct.\n\nOption C: The bound $|\\sin(1/x)|\\le 1$ alone does not imply any uniform, rapidly decaying error bound for Gauss–Legendre quadrature that is independent of the oscillations near $x=0$. In particular, a claim of an error bounded by a constant times $n^{-2n}$ is unfounded here; such “spectral” or superalgebraic rates require analyticity of the integrand on and around the closed interval, which fails due to the essential singularity at $x=0$. Verdict — Incorrect.\n\nOption D: Infinite differentiability on the open interval $(0,1]$ is insufficient to guarantee exponential convergence of Gauss–Legendre quadrature. The lack of smooth extension to the endpoint $x=0$ (in fact, the presence of an essential singularity) destroys the analyticity assumptions behind exponential convergence results. Thus one cannot expect exponential convergence in $n$ here just from $C^{\\infty}$ smoothness on $(0,1]$. Verdict — Incorrect.\n\nOption E: Composite quadrature with refined panels toward $x=0$, or a coordinate transformation that clusters abscissae near $x=0$ (such as a double-exponential mapping), directly addresses the resolution issue caused by the rapid oscillations as $x\\to 0^{+}$. By placing more nodes where the integrand oscillates fastest, these approaches substantially improve accuracy for a given total number of function evaluations compared to a single-panel Gauss–Legendre rule on $[0,1]$. While precise rates depend on the specific scheme, the qualitative improvement is well founded. Verdict — Correct.", "answer": "$$\\boxed{ABE}$$", "id": "2419556"}, {"introduction": "In practical scientific computing, we not only need to approximate an integral but also to estimate the error of our approximation. This exercise guides you through the elegant construction of Gauss-Kronrod quadrature rules, a cornerstone of modern adaptive integration algorithms. Starting from fundamental moment-matching principles, you will derive an embedded rule that reuses existing node points to create a higher-order estimate, providing a highly efficient way to compute an error indicator [@problem_id:3361974]. Understanding this construction is key to appreciating how automated numerical integrators can deliver results with a specified tolerance.", "problem": "Consider volume integrals over the reference element $E=[-1,1]$ with unit weight in the numerical assembly of a one-dimensional Discontinuous Galerkin (DG) method. Let $P_{n}(x)$ denote the Legendre polynomial of degree $n$ and recall that the $n$-point Gauss-Legendre quadrature uses the $n$ distinct zeros of $P_{n}(x)$ as nodes and achieves exactness for polynomials up to degree $2n-1$.\n\n1) Starting from the orthogonality of Legendre polynomials with respect to the weight $w(x)=1$ on $[-1,1]$ and the definition of Gaussian quadrature exactness, derive the construction principles of a Kronrod extension that augments an $n$-point Gauss-Legendre rule to a $(2n+1)$-point rule by adding $n+1$ new nodes while retaining the original $n$ Gauss nodes. Your derivation must be based on the following fundamentals only: (i) exactness of quadrature as a moment-matching condition, (ii) symmetry of the rule for $w(x)=1$, and (iii) interlacing of nodes implied by orthogonality. Explain how the exactness conditions determine both the new nodes and all weights, and why the resulting rule can achieve an exactness degree strictly greater than $2n-1$.\n\n2) Specialize your derivation to the case $n=1$ on $E=[-1,1]$. Determine explicitly the $(2n+1)=3$ nodes and weights of the Kronrod-augmented rule by solving the moment equations implied by exactness for even monomials. Show that the augmented rule contains the original Gauss node and is symmetric.\n\n3) In adaptive DG integration, an embedded a posteriori error estimator on each element can be constructed as the absolute difference between a higher-order rule and its embedded lower-order subrule applied to the same integrand. Define the embedded estimator $\\varepsilon(f)$ on $E$ as $\\varepsilon(f)=\\left|Q_{K}(f)-Q_{G}(f)\\right|$, where $Q_{K}$ is the Kronrod-augmented $(2n+1)$-point rule from part 2 and $Q_{G}$ is the original $n$-point Gauss rule. Evaluate this estimator for the integrand $f(x)=x^{4}$ on $E=[-1,1]$. Express your final answer as an exact number. Do not include any units. The final answer to submit is the value of $\\varepsilon(x^{4})$ on $[-1,1]$.", "solution": "The problem is addressed in three parts: first, a derivation of the principles of Gauss-Kronrod quadrature; second, the explicit construction of the 3-point Gauss-Kronrod rule; and third, the evaluation of an error estimator using this rule.\n\n**1) Construction Principles of the Kronrod Extension**\n\nThe goal is to augment an $n$-point Gauss-Legendre rule, $Q_G(f)$, into a higher-order $(2n+1)$-point rule, $Q_K(f)$, by adding $n+1$ new nodes while reusing the original $n$ nodes. The original Gauss nodes, denoted $\\{x_i\\}_{i=1}^n$, are the roots of the Legendre polynomial $P_n(x)$. The original rule, $Q_G(f) = \\sum_{i=1}^n w_i f(x_i)$, is exact for all polynomials of degree up to $2n-1$.\n\nThe new $(2n+1)$-point Kronrod rule, $Q_K(f)$, is defined as:\n$$\nQ_K(f) = \\sum_{i=1}^n a_i f(x_i) + \\sum_{j=1}^{n+1} b_j f(y_j)\n$$\nwhere $\\{x_i\\}_{i=1}^n$ are the fixed Gauss nodes, $\\{y_j\\}_{j=1}^{n+1}$ are the new Kronrod nodes, and $\\{a_i\\}_{i=1}^n$ and $\\{b_j\\}_{j=1}^{n+1}$ are the corresponding weights. The total number of parameters to be determined is $(n+1)$ nodes $y_j$, $n$ weights $a_i$, and $(n+1)$ weights $b_j$, for a total of $3n+2$ free parameters.\n\n(i) **Exactness as a Moment-Matching Condition**: The principle of Gaussian quadrature construction is to use the available degrees of freedom to enforce exactness for polynomials of the highest possible degree. With $3n+2$ parameters, we can impose $3n+2$ constraints. These constraints are that the quadrature rule exactly integrates the monomials $x^k$ for $k=0, 1, \\dots, 3n+1$. This establishes a system of $3n+2$ equations:\n$$\n\\int_{-1}^1 x^k \\, dx = \\sum_{i=1}^n a_i x_i^k + \\sum_{j=1}^{n+1} b_j y_j^k, \\quad \\text{for } k = 0, 1, \\dots, 3n+1\n$$\nThis is a non-linear system of equations for the unknowns $\\{y_j\\}$, $\\{a_i\\}$, and $\\{b_j\\}$.\n\n(ii) **Symmetry for $w(x)=1$**: For the weight function $w(x)=1$ on the symmetric interval $E=[-1,1]$, the quadrature rule must also be symmetric. This implies that if $z$ is a node, then $-z$ is also a node, and their weights are equal. The original Gauss nodes $\\{x_i\\}$ are roots of $P_n(x)$ and are symmetric about $x=0$. We enforce that the new nodes $\\{y_j\\}$ are also symmetric about $x=0$. This symmetry property automatically satisfies the moment equations for all odd powers of $k$, since for odd $k$, $\\int_{-1}^1 x^k dx = 0$, and the sum on the right-hand side is also zero due to cancellation between pairs of nodes $(\\pm z, \\pm z, ...)$. This significantly simplifies the system, leaving only the equations for even values of $k$ to be solved. The number of unique unknowns (non-negative nodes and their weights) matches the number of even-moment equations, yielding a solvable (though still non-linear) system.\n\n(iii) **Interlacing of Nodes**: Solving the system of moment equations reveals a deeper structure. The new nodes $\\{y_j\\}$ are the roots of a polynomial of degree $n+1$, often denoted $E_{n+1}(x)$. This polynomial is found to be orthogonal to $P_n(x)$ on $[-1,1]$, i.e., $\\int_{-1}^1 E_{n+1}(x) P_n(x) dx = 0$. A fundamental theorem concerning the roots of orthogonal polynomials states that the roots of two consecutive polynomials in an orthogonal sequence interlace. While $\\{P_n(x), E_{n+1}(x)\\}$ do not form a standard orthogonal sequence, their orthogonality property ensures that their roots interlace. Thus, each interval between two consecutive Gauss nodes $(x_i, x_{i+1})$ contains exactly one Kronrod node $y_j$, and the intervals $(-\\infty, x_{\\min})$ and $(x_{\\max}, \\infty)$ also each contain one Kronrod node.\n\n**Degree of Exactness**: The original $n$-point rule is exact for polynomials up to degree $2n-1$. By introducing $n+1$ new nodes and having $3n+2$ total parameters, we can enforce exactness for polynomials up to degree $3n+1$. Since $n \\ge 1$, we have $3n+1 > 2n-1$, which means the Kronrod extension achieves a degree of exactness strictly greater than the original Gauss rule. In fact, due to symmetry, the rule is often exact for degree $3n+2$ when $n$ is odd.\n\n**2) Specialization to $n=1$**\n\nFor $n=1$, the Gauss-Legendre rule has one point. The node is the root of $P_1(x)=x$, so $x_1=0$. The weight $w_1$ is found by integrating $f(x)=1$: $\\int_{-1}^1 1 dx = 2 = w_1 \\cdot 1$, so $w_1=2$. The 1-point Gauss rule is $Q_G(f) = 2f(0)$. It is exact for polynomials of degree up to $2(1)-1=1$.\n\nWe seek to augment this to a $(2n+1)=3$-point Kronrod rule by adding $n+1=2$ nodes. Let the rule be $Q_K(f) = a_1 f(x_1) + b_1 f(y_1) + b_2 f(y_2)$.\nWith $x_1=0$, we have $Q_K(f) = a_1 f(0) + b_1 f(y_1) + b_2 f(y_2)$.\nBy symmetry, we must have $y_2 = -y_1$ and $b_2=b_1$. Let $y_1=y$ and $b_1=b_2=b$. The rule becomes:\n$$\nQ_K(f) = a_1 f(0) + b f(y) + b f(-y)\n$$\nThere are 3 unknowns: $a_1$, $b$, and $y$. We enforce exactness for polynomials of degree up to at least $3n+1=4$. Due to symmetry, we only need to consider the moment equations for even powers $k=0, 2, 4$.\n\nFor $k=0$ ($f(x)=1$):\n$\\int_{-1}^1 1 dx = 2$.\n$Q_K(1) = a_1(1) + b(1) + b(1) = a_1+2b$.\nEquation (1): $a_1+2b=2$.\n\nFor $k=2$ ($f(x)=x^2$):\n$\\int_{-1}^1 x^2 dx = \\frac{2}{3}$.\n$Q_K(x^2) = a_1(0)^2 + b(y)^2 + b(-y)^2 = 2by^2$.\nEquation (2): $2by^2 = \\frac{2}{3} \\implies by^2 = \\frac{1}{3}$.\n\nFor $k=4$ ($f(x)=x^4$):\n$\\int_{-1}^1 x^4 dx = \\frac{2}{5}$.\n$Q_K(x^4) = a_1(0)^4 + b(y)^4 + b(-y)^4 = 2by^4$.\nEquation (3): $2by^4 = \\frac{2}{5} \\implies by^4 = \\frac{1}{5}$.\n\nWe solve this system. Divide Equation (3) by Equation (2):\n$\\frac{by^4}{by^2} = \\frac{1/5}{1/3} \\implies y^2 = \\frac{3}{5}$.\nSo, the new nodes are $y = \\pm\\sqrt{\\frac{3}{5}}$.\nSubstitute $y^2 = 3/5$ into Equation (2):\n$b \\left(\\frac{3}{5}\\right) = \\frac{1}{3} \\implies b = \\frac{5}{9}$.\nSubstitute $b=5/9$ into Equation (1):\n$a_1 + 2\\left(\\frac{5}{9}\\right) = 2 \\implies a_1 = 2 - \\frac{10}{9} = \\frac{8}{9}$.\n\nThe resulting 3-point Gauss-Kronrod rule has:\n- Nodes: $-\\sqrt{\\frac{3}{5}}, 0, \\sqrt{\\frac{3}{5}}$\n- Weights: $\\frac{5}{9}, \\frac{8}{9}, \\frac{5}{9}$\nThis rule contains the original Gauss node ($0$) and is symmetric, as required.\n\n**3) Evaluation of the Error Estimator**\n\nThe embedded error estimator is defined as $\\varepsilon(f) = |Q_K(f) - Q_G(f)|$. We evaluate this for the integrand $f(x)=x^4$ on $E=[-1,1]$.\n\nFirst, apply the lower-order 1-point Gauss rule $Q_G(f) = 2f(0)$:\n$$\nQ_G(x^4) = 2 \\cdot (0)^4 = 0\n$$\n\nNext, apply the higher-order 3-point Kronrod rule $Q_K(f) = \\frac{8}{9}f(0) + \\frac{5}{9}f(-\\sqrt{3/5}) + \\frac{5}{9}f(\\sqrt{3/5})$:\n$$\nQ_K(x^4) = \\frac{8}{9}(0)^4 + \\frac{5}{9}\\left(-\\sqrt{\\frac{3}{5}}\\right)^4 + \\frac{5}{9}\\left(\\sqrt{\\frac{3}{5}}\\right)^4\n$$\n$$\nQ_K(x^4) = 0 + \\frac{5}{9}\\left(\\frac{3}{5}\\right)^2 + \\frac{5}{9}\\left(\\frac{3}{5}\\right)^2 = 2 \\cdot \\frac{5}{9} \\cdot \\frac{9}{25} = 2 \\cdot \\frac{5}{25} = \\frac{10}{25} = \\frac{2}{5}\n$$\nNote that this matches the exact integral $\\int_{-1}^{1} x^4 dx = \\frac{2}{5}$, as expected from our construction.\n\nFinally, compute the estimator's value:\n$$\n\\varepsilon(x^4) = |Q_K(x^4) - Q_G(x^4)| = \\left|\\frac{2}{5} - 0\\right| = \\frac{2}{5}\n$$", "answer": "$$\n\\boxed{\\frac{2}{5}}\n$$", "id": "3361974"}, {"introduction": "In the context of Discontinuous Galerkin (DG) and other spectral methods, quadrature rules do more than just approximate integrals; they build the very structure of the discrete operators that govern the simulation. This practice demonstrates the profound impact of quadrature accuracy on the algebraic properties of the mass matrix and the discrete derivative operator. You will verify how a sufficiently accurate Gauss-Lobatto quadrature rule preserves the coveted Summation-By-Parts (SBP) property—a discrete analogue of integration-by-parts that is crucial for proving the stability of a numerical scheme [@problem_id:3361955]. Calculating the \"defect\" that arises from under-integration provides a tangible lesson in how seemingly small quadrature errors can compromise the fundamental structure of the discrete system.", "problem": "Consider the reference element $[-1,1]$ and the modal Legendre polynomial basis $\\{P_{i}(x)\\}_{i=0}^{p}$, where $P_{i}(x)$ denotes the degree-$i$ Legendre polynomial normalized so that $\\int_{-1}^{1} P_{i}(x) P_{j}(x) \\,\\mathrm{d}x = \\frac{2}{2i+1} \\delta_{ij}$ and $P_{i}(1)=1$, $P_{i}(-1)=(-1)^{i}$. Let $p=4$. Define the Gauss–Lobatto–Legendre quadrature on $[-1,1]$ with $n$ nodes as the unique symmetric quadrature rule including the endpoints $x=\\pm 1$ and placing the interior nodes at the zeros of $P_{n-1}'(x)$, with positive weights $\\{w_{k}\\}_{k=1}^{n}$ chosen so that the rule is exact for every polynomial on $[-1,1]$ of degree at most $2n-3$.\n\nFor a given $n$, define the discrete mass matrix and the discrete derivative inner-product matrix by\n$$\n\\widetilde{M}_{ij} := \\sum_{k=1}^{n} w_{k}\\, P_{i}(x_{k}) P_{j}(x_{k}), \n\\qquad\n\\widetilde{S}_{ij} := \\sum_{k=1}^{n} w_{k}\\, P_{i}'(x_{k}) P_{j}(x_{k}),\n$$\nand define the boundary matrix\n$$\nB_{ij} := P_{i}(1) P_{j}(1) - P_{i}(-1) P_{j}(-1) = 1 - (-1)^{i+j}.\n$$\nThe Summation-By-Parts (SBP) identity states the discrete analogue of integration by parts,\n$$\n\\widetilde{S} + \\widetilde{S}^{\\top} = B,\n$$\nwhere the superscript ${\\top}$ denotes transpose. \n\nTasks:\n- Using only the Legendre polynomial properties and the Gauss–Lobatto–Legendre quadrature exactness, verify for $p=4$ that with $n=p+1=5$ nodes the discrete mass matrix $\\widetilde{M}$ is diagonal and the SBP identity $\\widetilde{S}+\\widetilde{S}^{\\top}=B$ is exact.\n- Now take $n=4<p+1$. Quantify the defect of the SBP identity by computing the single scalar\n$$\n\\Delta_{34} := \\big(\\widetilde{S}+\\widetilde{S}^{\\top} - B\\big)_{34},\n$$\ni.e., the $(3,4)$-entry of the difference between the left-hand side and right-hand side of the SBP identity. Your final answer must be this single real number, expressed exactly (no rounding).", "solution": "The problem consists of two parts. The first is a verification of properties for a fully-integrated case, and the second is a computation of an error term for an under-integrated case.\n\nFirst, we verify the claims for the case with polynomial degree $p=4$ and a Gauss-Lobatto-Legendre (GLL) quadrature rule with $n=p+1=5$ nodes. A GLL quadrature rule with $n$ nodes is exact for any polynomial on $[-1,1]$ of degree at most $2n-3$. For $n=5$, the rule is exact for polynomials of degree up to $2(5)-3=7$.\n\nThe discrete mass matrix is given by $\\widetilde{M}_{ij} = \\sum_{k=1}^{5} w_k P_i(x_k) P_j(x_k)$. This is the quadrature approximation of the integral $M_{ij} = \\int_{-1}^{1} P_i(x) P_j(x) dx$. The integrand is the polynomial $P_i(x) P_j(x)$, which has degree $i+j$. For the basis functions up to $p=4$, we consider indices $0 \\le i, j \\le 4$. For an off-diagonal entry, $i \\ne j$, the maximum degree of the integrand is for $(i,j)=(3,4)$, which is degree $3+4=7$. Since the GLL rule is exact for polynomials of degree up to $7$, for any $i \\ne j$ with $i+j \\le 7$, we have $\\widetilde{M}_{ij} = \\int_{-1}^{1} P_i(x) P_j(x) dx$. By the orthogonality of Legendre polynomials, this integral is zero. This condition $i+j \\le 7$ covers all off-diagonal elements of the $5 \\times 5$ matrix $\\widetilde{M}$ (for indices from $0$ to $4$). Therefore, $\\widetilde{M}$ is a diagonal matrix.\n\nThe SBP identity is $\\widetilde{S} + \\widetilde{S}^{\\top} = B$. The $(i,j)$-entry of the left-hand side is $\\widetilde{S}_{ij} + \\widetilde{S}_{ji} = \\sum_{k=1}^{5} w_k (P_i'(x_k) P_j(x_k) + P_j'(x_k) P_i(x_k))$. The term in the sum is the derivative of the product, $(P_i(x)P_j(x))'$. This is a polynomial of degree $i+j-1$. For $0 \\le i, j \\le 4$, the maximum degree is $4+4-1=7$. The GLL rule with $n=5$ is exact for these polynomials. Thus,\n$$ \\widetilde{S}_{ij} + \\widetilde{S}_{ji} = \\int_{-1}^{1} \\frac{d}{dx} (P_i(x)P_j(x)) dx $$\nBy the Fundamental Theorem of Calculus, this integral evaluates to\n$$ [P_i(x)P_j(x)]_{x=-1}^{x=1} = P_i(1)P_j(1) - P_i(-1)P_j(-1). $$\nUsing the given properties $P_k(1)=1$ and $P_k(-1)=(-1)^k$, this becomes $1 \\cdot 1 - (-1)^i (-1)^j = 1 - (-1)^{i+j}$, which is the definition of $B_{ij}$. Thus, for $n=p+1=5$, the SBP identity $\\widetilde{S}+\\widetilde{S}^{\\top}=B$ holds exactly.\n\nNow, we address the second task: to compute the defect $\\Delta_{34}$ for the under-integrated case with $n=4$ nodes, where $p=4$. The quantity to compute is\n$$ \\Delta_{34} = (\\widetilde{S}+\\widetilde{S}^{\\top} - B)_{34} = (\\widetilde{S}_{34} + \\widetilde{S}_{43}) - B_{34}. $$\nThe GLL quadrature with $n=4$ nodes is exact for polynomials of degree at most $2n-3 = 2(4)-3=5$. The term $\\widetilde{S}_{34} + \\widetilde{S}_{43}$ is the quadrature approximation of $\\int_{-1}^1 (P_3(x)P_4(x))' dx$. The integrand $(P_3P_4)'$ is a polynomial of degree $3+4-1=6$. Since the degree $6$ is greater than $5$, the quadrature is not exact and we expect a non-zero defect $\\Delta_{34}$.\n\nFirst, we determine the GLL nodes and weights for $n=4$. The nodes are the endpoints $\\{-1, 1\\}$ and the zeros of $P'_{n-1}(x) = P'_3(x)$. The Legendre polynomials with normalization $P_i(1)=1$ are:\n$P_3(x) = \\frac{1}{2}(5x^3-3x)$\n$P_4(x) = \\frac{1}{8}(35x^4-30x^2+3)$\nThe derivative of $P_3(x)$ is $P'_3(x) = \\frac{1}{2}(15x^2-3)$. Setting $P'_3(x)=0$ gives $15x^2=3$, so $x^2=1/5$. The interior nodes are $x = \\pm 1/\\sqrt{5}$.\nThe four GLL nodes are $x_1=-1$, $x_2=-1/\\sqrt{5}$, $x_3=1/\\sqrt{5}$, $x_4=1$.\nThe GLL weights are given by $w_k = \\frac{2}{n(n-1)[P_{n-1}(x_k)]^2} = \\frac{2}{4(3)[P_3(x_k)]^2} = \\frac{1}{6[P_3(x_k)]^2}$.\nFor the endpoints $x=\\pm 1$, we have $P_3(1)=1$ and $P_3(-1)=-1$, so $[P_3(\\pm 1)]^2=1$. The endpoint weights are $w_1=w_4=\\frac{1}{6}$.\nFor the interior nodes $x=\\pm 1/\\sqrt{5}$:\n$P_3(1/\\sqrt{5}) = \\frac{1}{2}(5(1/\\sqrt{5})^3-3(1/\\sqrt{5})) = \\frac{1}{2\\sqrt{5}}(1-3) = -1/\\sqrt{5}$.\n$P_3(-1/\\sqrt{5}) = 1/\\sqrt{5}$.\nSo, $[P_3(\\pm 1/\\sqrt{5})]^2 = 1/5$. The interior weights are $w_2=w_3=\\frac{1}{6(1/5)} = \\frac{5}{6}$.\n\nNext, we calculate the term $\\widetilde{S}_{34} + \\widetilde{S}_{43} = \\sum_{k=1}^{4} w_{k} (P_{3}'(x_{k}) P_{4}(x_{k}) + P_{4}'(x_{k}) P_{3}(x_{k}))$. Let $g(x) = P_3'(x)P_4(x) + P_4'(x)P_3(x)$. The required derivatives are:\n$P'_3(x) = \\frac{3}{2}(5x^2-1)$\n$P'_4(x) = \\frac{1}{8}(140x^3-60x) = \\frac{5}{2}(7x^3-3x)$\nThe function $g(x)$ is even, since $P_3$ is odd, $P_4$ is even, $P_3'$ is even, and $P_4'$ is odd, making $P_3'P_4$ even and $P_4'P_3$ even. So $g(-x)=g(x)$. The sum is $\\sum_{k=1}^4 w_k g(x_k) = 2w_1 g(1) + 2w_2 g(1/\\sqrt{5})$.\n\nWe evaluate $g(x)$ at the positive nodes:\nAt $x=1$:\n$P_3(1)=1$, $P_4(1)=1$\n$P'_3(1) = \\frac{3}{2}(5-1) = 6$\n$P'_4(1) = \\frac{5}{2}(7-3) = 10$\n$g(1) = P'_3(1)P_4(1) + P'_4(1)P_3(1) = 6(1) + 10(1) = 16$.\n\nAt $x=1/\\sqrt{5}$:\n$P_3(1/\\sqrt{5}) = -1/\\sqrt{5}$\n$P_4(1/\\sqrt{5}) = \\frac{1}{8}(35(1/25) - 30(1/5) + 3) = \\frac{1}{8}(7/5 - 6 + 3) = \\frac{1}{8}(7/5 - 15/5) = -1/5$.\n$P'_3(1/\\sqrt{5}) = \\frac{3}{2}(5(1/5)-1) = 0$ (as expected, since it is a node).\n$P'_4(1/\\sqrt{5}) = \\frac{5}{2}(7(1/5\\sqrt{5}) - 3(1/\\sqrt{5})) = \\frac{5}{2\\sqrt{5}}(7/5 - 3) = \\frac{5}{2\\sqrt{5}}(-8/5) = -4/\\sqrt{5}$.\n$g(1/\\sqrt{5}) = P'_3 P_4 + P'_4 P_3 = 0 \\cdot (-1/5) + (-4/\\sqrt{5})(-1/\\sqrt{5}) = 4/5$.\n\nNow we compute the sum:\n$\\widetilde{S}_{34} + \\widetilde{S}_{43} = 2w_1 g(1) + 2w_2 g(1/\\sqrt{5}) = 2(\\frac{1}{6})(16) + 2(\\frac{5}{6})(\\frac{4}{5}) = \\frac{16}{3} + \\frac{10}{6}\\frac{4}{5} = \\frac{16}{3} + \\frac{40}{30} = \\frac{16}{3} + \\frac{4}{3} = \\frac{20}{3}$.\n\nFinally, we compute the boundary term $B_{34}$:\n$B_{34} = P_3(1)P_4(1) - P_3(-1)P_4(-1) = 1 \\cdot 1 - (-1)^3 (-1)^4 = 1 - (-1)(1) = 2$.\n\nThe defect is the difference:\n$\\Delta_{34} = (\\widetilde{S}_{34} + \\widetilde{S}_{43}) - B_{34} = \\frac{20}{3} - 2 = \\frac{20-6}{3} = \\frac{14}{3}$.", "answer": "$$\\boxed{\\frac{14}{3}}$$", "id": "3361955"}]}