{"hands_on_practices": [{"introduction": "The concept of best approximation is best understood by direct application. This first practice provides a foundational exercise in computing the orthogonal projection of a function onto a finite-dimensional subspace within the standard $L^2([-1,1])$ Hilbert space [@problem_id:2395859]. By approximating the non-smooth function $f(x) = |x|$ with a quadratic polynomial, you will engage with the core mechanics of setting up and solving the Gram system, which lies at the heart of least-squares approximations.", "problem": "In computational engineering, one often replaces a non-smooth function by a low-degree polynomial that is optimal in a least-squares sense over a given interval. Consider the function $f(x)=|x|$ on the interval $[-1,1]$. Let $\\mathbb{P}_2$ denote the space of all real polynomials of degree at most $2$. Equip the space of square-integrable functions on $[-1,1]$, denoted the Lebesgue $L^2([-1,1])$ space, with the standard inner product $\\langle g,h\\rangle=\\int_{-1}^{1} g(x)\\,h(x)\\,dx$ and associated norm $\\|g\\|_{2}=\\sqrt{\\langle g,g\\rangle}$.\n\nUsing only the foundational definitions of inner product, norm, and the characterization of best approximation in a Hilbert space as an orthogonal projection onto a finite-dimensional subspace, determine the unique polynomial $p^{\\star}(x)\\in \\mathbb{P}_2$ that minimizes $\\|f-p\\|_{2}$ over all $p\\in \\mathbb{P}_2$. Express your final result as a single explicit polynomial in the monomial basis, $p^{\\star}(x)=a x^{2}+b x+c$, with exact rational coefficients. Do not round.", "solution": "The space $L^2([-1,1])$ is a Hilbert space with the inner product defined as $\\langle g,h\\rangle=\\int_{-1}^{1} g(x)\\,h(x)\\,dx$. We seek the polynomial $p^{\\star}(x) \\in \\mathbb{P}_2$ that minimizes the norm of the error, $\\|f - p\\|_{2}$, for the function $f(x)=|x|$ over all polynomials $p(x) \\in \\mathbb{P}_2$. According to the projection theorem in Hilbert spaces, this unique best approximation $p^{\\star}(x)$ is the orthogonal projection of $f(x)$ onto the finite-dimensional subspace $\\mathbb{P}_2$.\n\nThe defining property of the orthogonal projection is that the error vector, $f - p^{\\star}$, is orthogonal to the subspace $\\mathbb{P}_2$. This means that for any polynomial $q(x) \\in \\mathbb{P}_2$, the inner product must be zero:\n$$\n\\langle f - p^{\\star}, q \\rangle = 0\n$$\nIt is sufficient to enforce this orthogonality condition for a set of basis vectors of the subspace $\\mathbb{P}_2$. We shall use the standard monomial basis for $\\mathbb{P}_2$, the space of polynomials of degree at most $2$: $\\{\\phi_0(x), \\phi_1(x), \\phi_2(x)\\} = \\{1, x, x^2\\}$.\nLet the desired polynomial be written in this basis as $p^{\\star}(x) = a x^2 + b x + c$. The coefficients $a, b, c$ are the real-valued unknowns to be determined. The orthogonality conditions are:\n$$\n\\langle f - p^{\\star}, \\phi_j \\rangle = 0 \\quad \\text{for } j = 0, 1, 2\n$$\nBy the linearity of the inner product, this is equivalent to $\\langle f, \\phi_j \\rangle = \\langle p^{\\star}, \\phi_j \\rangle$. Substituting the form of $p^{\\star}(x)$ gives:\n$$\n\\langle f, \\phi_j \\rangle = \\langle a x^2 + b x + c, \\phi_j \\rangle = a \\langle x^2, \\phi_j \\rangle + b \\langle x, \\phi_j \\rangle + c \\langle 1, \\phi_j \\rangle\n$$\nThis gives a system of $3$ linear equations for the $3$ unknown coefficients $a, b, c$. Rearranging the terms to match the form $p^{\\star}(x)=a x^2 + b x + c$, the system is:\n$$\nc \\langle 1, \\phi_j \\rangle + b \\langle x, \\phi_j \\rangle + a \\langle x^2, \\phi_j \\rangle = \\langle f, \\phi_j \\rangle \\quad \\text{for } j = 0, 1, 2\n$$\nIn matrix form, this is the Gram system, where the matrix entries are the inner products of the basis functions. We now compute these inner products. The interval of integration $[-1, 1]$ is symmetric about the origin, so the integral of any odd function over this interval is $0$. For an even function $g(x)$, $\\int_{-1}^1 g(x) dx = 2 \\int_0^1 g(x) dx$.\n\nFirst, we compute the elements of the Gram matrix $G$, where $G_{ij} = \\langle \\phi_i, \\phi_j \\rangle$ with the basis ordered as $\\{1, x, x^2\\}$.\n$$\n\\langle 1, 1 \\rangle = \\int_{-1}^1 1 dx = [x]_{-1}^1 = 2\n$$\n$$\n\\langle 1, x \\rangle = \\int_{-1}^1 x dx = 0 \\quad (\\text{odd integrand})\n$$\n$$\n\\langle 1, x^2 \\rangle = \\int_{-1}^1 x^2 dx = 2 \\int_0^1 x^2 dx = 2\\left[\\frac{x^3}{3}\\right]_0^1 = \\frac{2}{3}\n$$\n$$\n\\langle x, x \\rangle = \\int_{-1}^1 x^2 dx = \\frac{2}{3}\n$$\n$$\n\\langle x, x^2 \\rangle = \\int_{-1}^1 x^3 dx = 0 \\quad (\\text{odd integrand})\n$$\n$$\n\\langle x^2, x^2 \\rangle = \\int_{-1}^1 x^4 dx = 2 \\int_0^1 x^4 dx = 2\\left[\\frac{x^5}{5}\\right]_0^1 = \\frac{2}{5}\n$$\nThe system of equations is structured as follows, with the coefficient vector $[c, b, a]^T$:\n$$\n\\begin{pmatrix}\n\\langle 1, 1 \\rangle & \\langle x, 1 \\rangle & \\langle x^2, 1 \\rangle \\\\\n\\langle 1, x \\rangle & \\langle x, x \\rangle & \\langle x^2, x \\rangle \\\\\n\\langle 1, x^2 \\rangle & \\langle x, x^2 \\rangle & \\langle x^2, x^2 \\rangle\n\\end{pmatrix}\n\\begin{pmatrix} c \\\\ b \\\\ a \\end{pmatrix}\n=\n\\begin{pmatrix}\n\\langle f, 1 \\rangle \\\\\n\\langle f, x \\rangle \\\\\n\\langle f, x^2 \\rangle\n\\end{pmatrix}\n$$\nNext, we compute the components of the right-hand side vector. The function is $f(x)=|x|$, which is an even function.\n$$\n\\langle f, 1 \\rangle = \\int_{-1}^1 |x| dx = 2 \\int_0^1 x dx = 2\\left[\\frac{x^2}{2}\\right]_0^1 = 1\n$$\n$$\n\\langle f, x \\rangle = \\int_{-1}^1 |x|x dx = 0 \\quad (\\text{odd integrand, } |x| \\text{ is even, } x \\text{ is odd})\n$$\n$$\n\\langle f, x^2 \\rangle = \\int_{-1}^1 |x|x^2 dx = 2 \\int_0^1 x \\cdot x^2 dx = 2 \\int_0^1 x^3 dx = 2\\left[\\frac{x^4}{4}\\right]_0^1 = \\frac{1}{2}\n$$\nAssembling the system:\n$$\n\\begin{pmatrix}\n2 & 0 & \\frac{2}{3} \\\\\n0 & \\frac{2}{3} & 0 \\\\\n\\frac{2}{3} & 0 & \\frac{2}{5}\n\\end{pmatrix}\n\\begin{pmatrix} c \\\\ b \\\\ a \\end{pmatrix}\n=\n\\begin{pmatrix}\n1 \\\\\n0 \\\\\n\\frac{1}{2}\n\\end{pmatrix}\n$$\nFrom the second row, we deduce $\\frac{2}{3}b = 0$, which implies $b=0$. This is expected, as the best polynomial approximation of an even function on a symmetric interval must also be even.\nThe system for $a$ and $c$ reduces to:\n$$\n\\begin{cases}\n2c + \\frac{2}{3}a = 1 \\\\\n\\frac{2}{3}c + \\frac{2}{5}a = \\frac{1}{2}\n\\end{cases}\n$$\nTo clear the denominators, we multiply the first equation by $3$ and the second by $30$:\n$$\n\\begin{cases}\n6c + 2a = 3 \\\\\n20c + 12a = 15\n\\end{cases}\n$$\nFrom the first of these new equations, we have $2a = 3 - 6c$, or $a = \\frac{3-6c}{2}$. Substituting this expression for $a$ into the second equation:\n$$\n20c + 12\\left(\\frac{3-6c}{2}\\right) = 15\n$$\n$$\n20c + 6(3-6c) = 15\n$$\n$$\n20c + 18 - 36c = 15\n$$\n$$\n-16c = -3\n$$\n$$\nc = \\frac{3}{16}\n$$\nNow, we substitute the value of $c$ back to find $a$:\n$$\na = \\frac{3 - 6(\\frac{3}{16})}{2} = \\frac{3 - \\frac{9}{8}}{2} = \\frac{\\frac{24 - 9}{8}}{2} = \\frac{\\frac{15}{8}}{2} = \\frac{15}{16}\n$$\nThe coefficients are $a=\\frac{15}{16}$, $b=0$, and $c=\\frac{3}{16}$.\nTherefore, the unique polynomial $p^{\\star}(x) \\in \\mathbb{P}_2$ that minimizes $\\|f-p\\|_{2}$ is:\n$$\np^{\\star}(x) = \\frac{15}{16}x^2 + \\frac{3}{16}\n$$", "answer": "$$\n\\boxed{\\frac{15}{16}x^{2} + \\frac{3}{16}}\n$$", "id": "2395859"}, {"introduction": "Building upon the basic projection, this exercise explores the critical idea that the notion of a \"best\" approximation is entirely dependent on the choice of inner product and its associated norm. You will compare approximations derived from two different weighted Hilbert spaces, one naturally associated with Legendre polynomials and the other with Chebyshev polynomials [@problem_id:3366993]. This comparison illuminates why different families of orthogonal polynomials are fundamental tools in spectral methods and how the selection of a weighted inner product directly influences the approximation's characteristics.", "problem": "Consider the Hilbert spaces of square-integrable functions on the interval $[-1,1]$ with inner products defined by weights. Specifically, for a weight function $w(x)$, define the space $L^{2}([-1,1],w)$ with inner product $\\langle f,g\\rangle_{w}=\\int_{-1}^{1} f(x)\\,g(x)\\,w(x)\\,dx$ and associated norm $\\|f\\|_{w}=\\big(\\int_{-1}^{1}|f(x)|^{2}w(x)\\,dx\\big)^{1/2}$. The best approximation of an element $f$ by a finite-dimensional subspace is the orthogonal projection of $f$ onto that subspace with respect to the inner product of the Hilbert space.\n\nThe Chebyshev polynomials of the first kind $\\{T_{n}(x)\\}_{n\\geq 0}$ are orthogonal on $[-1,1]$ with respect to the weight $w_{C}(x)=(1-x^{2})^{-1/2}$, and the Legendre polynomials $\\{P_{n}(x)\\}_{n\\geq 0}$ are orthogonal on $[-1,1]$ with respect to the unit weight $w_{L}(x)=1$. In spectral and discontinuous Galerkin methods, truncated orthogonal expansions realize best approximations in these weighted $L^{2}$ spaces.\n\nLet $f(x)=T_{3}(x)=4x^{3}-3x$. Consider the polynomial subspaces of degree at most one:\n- The Chebyshev subspace $\\mathcal{C}_{1}=\\operatorname{span}\\{T_{0},T_{1}\\}$ with inner product $\\langle\\cdot,\\cdot\\rangle_{w_{C}}$.\n- The Legendre subspace $\\mathcal{L}_{1}=\\operatorname{span}\\{P_{0},P_{1}\\}$ with inner product $\\langle\\cdot,\\cdot\\rangle_{w_{L}}$.\n\nUsing only the definitions of orthogonal projection in Hilbert spaces and the orthogonality of $\\{T_{n}\\}$ in $L^{2}([-1,1],w_{C})$ and $\\{P_{n}\\}$ in $L^{2}([-1,1],1)$, determine:\n1. The best approximation to $f$ from $\\mathcal{C}_{1}$ in $L^{2}([-1,1],w_{C})$ (the truncated Chebyshev expansion of degree at most one).\n2. The best approximation to $f$ from $\\mathcal{L}_{1}$ in $L^{2}([-1,1],1)$ (the truncated Legendre expansion of degree at most one).\n\nThen, quantify the difference between these two best approximations by computing the unweighted $L^{2}([-1,1])$ norm of their difference, that is, compute $\\|p_{L}-p_{C}\\|_{L^{2}([-1,1])}$ where $p_{C}\\in\\mathcal{C}_{1}$ and $p_{L}\\in\\mathcal{L}_{1}$ are the respective best approximants. Express your final answer as a single exact analytical expression. No rounding is required.", "solution": "The problem asks for the best approximations of the function $f(x)=T_{3}(x)=4x^{3}-3x$ from two different polynomial subspaces of degree at most one, each with respect to a different weighted inner product. Subsequently, it requires the calculation of the unweighted $L^{2}$ norm of the difference between these two approximations.\n\nThe fundamental principle being applied is that the best approximation of a function $f$ from a finite-dimensional subspace $V$ of a Hilbert space $H$ is the orthogonal projection of $f$ onto $V$. If $\\{v_{k}\\}_{k=0}^{N}$ is an orthogonal basis for $V$, the orthogonal projection of $f$ onto $V$, denoted $\\operatorname{proj}_{V}f$, is given by:\n$$\n\\operatorname{proj}_{V}f = \\sum_{k=0}^{N} \\frac{\\langle f, v_{k} \\rangle}{\\langle v_{k}, v_{k} \\rangle} v_{k}\n$$\nwhere $\\langle \\cdot, \\cdot \\rangle$ is the inner product of the Hilbert space $H$.\n\n1.  **Best approximation from the Chebyshev subspace $\\mathcal{C}_{1}$**\n\nThe first task is to find the best approximation of $f(x)=T_{3}(x)$ from the subspace $\\mathcal{C}_{1}=\\operatorname{span}\\{T_{0}, T_{1}\\}$ in the Hilbert space $L^{2}([-1,1], w_{C})$ with weight $w_{C}(x)=(1-x^{2})^{-1/2}$. The inner product is $\\langle f,g\\rangle_{w_{C}}=\\int_{-1}^{1} f(x)g(x)(1-x^{2})^{-1/2}dx$. Let the best approximation be $p_{C}(x)$.\n\nThe basis for $\\mathcal{C}_{1}$ is $\\{T_{0}(x), T_{1}(x)\\}$. The set of Chebyshev polynomials $\\{T_{n}(x)\\}_{n\\geq 0}$ is orthogonal with respect to the inner product $\\langle\\cdot,\\cdot\\rangle_{w_{C}}$. The approximation $p_{C}(x)$ is the orthogonal projection of $f(x)$ onto $\\mathcal{C}_{1}$:\n$$\np_{C}(x) = \\frac{\\langle f, T_{0} \\rangle_{w_{C}}}{\\langle T_{0}, T_{0} \\rangle_{w_{C}}} T_{0}(x) + \\frac{\\langle f, T_{1} \\rangle_{w_{C}}}{\\langle T_{1}, T_{1} \\rangle_{w_{C}}} T_{1}(x)\n$$\nThe function to be approximated is $f(x)=T_{3}(x)$. We use the orthogonality property of the Chebyshev polynomials: $\\langle T_{m}, T_{n} \\rangle_{w_{C}} = 0$ for $m \\neq n$.\n\nFor the first coefficient, the inner product in the numerator is $\\langle f, T_{0} \\rangle_{w_{C}} = \\langle T_{3}, T_{0} \\rangle_{w_{C}}$. Since $3 \\neq 0$, this inner product is $0$.\nFor the second coefficient, the inner product in the numerator is $\\langle f, T_{1} \\rangle_{w_{C}} = \\langle T_{3}, T_{1} \\rangle_{w_{C}}$. Since $3 \\neq 1$, this inner product is also $0$.\n\nTherefore, the coefficients of the expansion are both zero. The best approximation to $f(x)$ from $\\mathcal{C}_{1}$ is:\n$$\np_{C}(x) = 0 \\cdot T_{0}(x) + 0 \\cdot T_{1}(x) = 0\n$$\n\n2.  **Best approximation from the Legendre subspace $\\mathcal{L}_{1}$**\n\nThe second task is to find the best approximation of $f(x) = 4x^{3}-3x$ from the subspace $\\mathcal{L}_{1}=\\operatorname{span}\\{P_{0}, P_{1}\\}$ in the Hilbert space $L^{2}([-1,1], 1)$ with weight $w_{L}(x)=1$. The inner product is the standard unweighted inner product $\\langle f,g\\rangle_{w_{L}}=\\int_{-1}^{1} f(x)g(x)dx$. Let the best approximation be $p_{L}(x)$.\n\nThe basis for $\\mathcal{L}_{1}$ is $\\{P_{0}(x), P_{1}(x)\\}$. The set of Legendre polynomials $\\{P_{n}(x)\\}_{n\\geq 0}$ is orthogonal with respect to the inner product $\\langle\\cdot,\\cdot\\rangle_{w_{L}}$. The standard first two Legendre polynomials are $P_{0}(x)=1$ and $P_{1}(x)=x$.\n\nThe approximation $p_{L}(x)$ is the orthogonal projection of $f(x)$ onto $\\mathcal{L}_{1}$:\n$$\np_{L}(x) = \\frac{\\langle f, P_{0} \\rangle_{w_{L}}}{\\langle P_{0}, P_{0} \\rangle_{w_{L}}} P_{0}(x) + \\frac{\\langle f, P_{1} \\rangle_{w_{L}}}{\\langle P_{1}, P_{1} \\rangle_{w_{L}}} P_{1}(x)\n$$\nFirst, we compute the squared norms of the basis vectors:\n$$\n\\langle P_{0}, P_{0} \\rangle_{w_{L}} = \\int_{-1}^{1} (1)^{2} dx = [x]_{-1}^{1} = 1 - (-1) = 2\n$$\n$$\n\\langle P_{1}, P_{1} \\rangle_{w_{L}} = \\int_{-1}^{1} (x)^{2} dx = \\left[\\frac{x^{3}}{3}\\right]_{-1}^{1} = \\frac{1}{3} - \\frac{-1}{3} = \\frac{2}{3}\n$$\nNext, we compute the inner products of $f(x)$ with the basis vectors:\n$$\n\\langle f, P_{0} \\rangle_{w_{L}} = \\int_{-1}^{1} (4x^{3}-3x)(1) dx\n$$\nThe integrand $4x^{3}-3x$ is an odd function, so its integral over the symmetric interval $[-1,1]$ is $0$. Thus, $\\langle f, P_{0} \\rangle_{w_{L}} = 0$.\n\n$$\n\\langle f, P_{1} \\rangle_{w_{L}} = \\int_{-1}^{1} (4x^{3}-3x)(x) dx = \\int_{-1}^{1} (4x^{4}-3x^{2}) dx\n$$\nThe integrand $4x^{4}-3x^{2}$ is an even function.\n$$\n\\int_{-1}^{1} (4x^{4}-3x^{2}) dx = \\left[\\frac{4x^{5}}{5} - x^{3}\\right]_{-1}^{1} = \\left(\\frac{4}{5} - 1\\right) - \\left(-\\frac{4}{5} - (-1)\\right) = -\\frac{1}{5} - \\frac{1}{5} = -\\frac{2}{5}\n$$\nNow we can compute the coefficients for $p_{L}(x)$:\nThe coefficient for $P_{0}(x)$ is $\\frac{0}{2}=0$.\nThe coefficient for $P_{1}(x)$ is $\\frac{-2/5}{2/3} = -\\frac{2}{5} \\cdot \\frac{3}{2} = -\\frac{3}{5}$.\n\nThe best approximation to $f(x)$ from $\\mathcal{L}_{1}$ is:\n$$\np_{L}(x) = 0 \\cdot P_{0}(x) + \\left(-\\frac{3}{5}\\right) \\cdot P_{1}(x) = -\\frac{3}{5}x\n$$\n\n3.  **Norm of the difference**\n\nThe final task is to compute the unweighted $L^{2}([-1,1])$ norm of the difference between the two approximations, $\\|p_{L}-p_{C}\\|_{L^{2}([-1,1])}$.\nWe have $p_{C}(x)=0$ and $p_{L}(x)=-\\frac{3}{5}x$. The difference is $p_{L}(x)-p_{C}(x) = -\\frac{3}{5}x$.\nThe norm is defined as $\\|g\\|_{L^{2}([-1,1])} = \\left(\\int_{-1}^{1} |g(x)|^{2} dx\\right)^{1/2}$.\n$$\n\\|p_{L}-p_{C}\\|_{L^{2}([-1,1])} = \\left(\\int_{-1}^{1} \\left|-\\frac{3}{5}x\\right|^{2} dx\\right)^{1/2} = \\left(\\int_{-1}^{1} \\frac{9}{25}x^{2} dx\\right)^{1/2}\n$$\nWe evaluate the integral:\n$$\n\\int_{-1}^{1} \\frac{9}{25}x^{2} dx = \\frac{9}{25} \\int_{-1}^{1} x^{2} dx = \\frac{9}{25} \\left[\\frac{x^{3}}{3}\\right]_{-1}^{1} = \\frac{9}{25} \\left(\\frac{1}{3} - \\frac{-1}{3}\\right) = \\frac{9}{25} \\cdot \\frac{2}{3} = \\frac{3 \\cdot 2}{25} = \\frac{6}{25}\n$$\nThe norm is the square root of this value:\n$$\n\\|p_{L}-p_{C}\\|_{L^{2}([-1,1])} = \\sqrt{\\frac{6}{25}} = \\frac{\\sqrt{6}}{5}\n$$", "answer": "$$\n\\boxed{\\frac{\\sqrt{6}}{5}}\n$$", "id": "3366993"}, {"introduction": "This final practice bridges the gap between abstract theory and the practical challenges encountered in implementing high-order methods like spectral element and discontinuous Galerkin methods. You will investigate the effect of using curved, isoparametric elements on the best approximation process, where a geometric mapping introduces a non-constant Jacobian into the integrals [@problem_id:3367015]. By quantifying the error between a projection that accounts for this geometric distortion and one that does not, you will appreciate the importance of correctly handling the geometry to ensure the accuracy and optimality of the numerical solution.", "problem": "Consider a single isoparametric curved element used in a Spectral Element Method and a Discontinuous Galerkin (DG) method. Let the reference element be the interval $[-1,1]$ with coordinate $\\xi$, and define the isoparametric mapping to the physical element by $F(\\xi) = \\xi + \\epsilon \\xi^{3}$, where the distortion parameter satisfies $\\epsilon > -\\frac{1}{3}$ so that the Jacobian determinant $J(\\xi) = \\frac{dF}{d\\xi} = 1 + 3 \\epsilon \\xi^{2}$ is strictly positive. Let the Hilbert space be $L^{2}(K)$ on the physical element $K = F([-1,1])$, equipped with the curved-element $L^{2}$ inner product $(u,v)_{L^{2}(K)} = \\int_{K} u(x) v(x) \\, dx$, which under pullback to $[-1,1]$ becomes $(\\hat{u},\\hat{v})_{J} = \\int_{-1}^{1} \\hat{u}(\\xi) \\hat{v}(\\xi) J(\\xi) \\, d\\xi$, where $\\hat{u}(\\xi) = u(F(\\xi))$ and $\\hat{v}(\\xi) = v(F(\\xi))$. For comparison, consider the unweighted pullback reference inner product $(\\hat{u},\\hat{v})_{\\text{ref}} = \\int_{-1}^{1} \\hat{u}(\\xi) \\hat{v}(\\xi) \\, d\\xi$.\n\nLet the local isoparametric approximation space be the span of reference polynomials $\\mathbb{P}_{1}$ given by $V_{h} = \\operatorname{span}\\{ \\phi_{1}(\\xi), \\phi_{2}(\\xi) \\}$ with $\\phi_{1}(\\xi) = 1$ and $\\phi_{2}(\\xi) = \\xi$. Consider the target function on the physical element defined by the pullback $\\hat{f}(\\xi) = \\xi + \\xi^{2}$.\n\nDefine two best approximations (orthogonal projections) of $f$ onto $V_{h}$:\n1. The curved-element $L^{2}$ projection $P_{J} f \\in V_{h}$ that minimizes the error in the $L^{2}(K)$ norm, equivalently satisfies orthogonality in the weighted inner product $(\\cdot,\\cdot)_{J}$.\n2. The pullback reference inner-product projection $P_{\\text{ref}} f \\in V_{h}$ that satisfies orthogonality in $(\\cdot,\\cdot)_{\\text{ref}}$.\n\nBoth projections are computed in the reference coordinate as $P_{J} f(\\xi) = c_{1}^{(J)} + c_{2}^{(J)} \\xi$ and $P_{\\text{ref}} f(\\xi) = c_{1}^{(\\text{ref})} + c_{2}^{(\\text{ref})} \\xi$ for coefficients determined by the respective inner products.\n\nStarting from the foundational definition of best approximation in a Hilbert space as the orthogonal projection with respect to the chosen inner product, derive the explicit closed-form analytic expression for the physical $L^{2}$-norm squared of the difference between these two projections, namely\n$$\nE(\\epsilon) = \\int_{K} \\big| P_{J} f(x) - P_{\\text{ref}} f(x) \\big|^{2} \\, dx = \\int_{-1}^{1} \\big| P_{J} f(\\xi) - P_{\\text{ref}} f(\\xi) \\big|^{2} J(\\xi) \\, d\\xi,\n$$\nas a function of $\\epsilon$. Your final answer must be a single closed-form analytic expression in $\\epsilon$ with no units. Do not round.", "solution": "The problem requires the derivation of the squared $L^2$-norm of the difference between two best approximations, or orthogonal projections, of a function $f$ onto a polynomial subspace $V_h$. The two projections are defined with respect to two different inner products: one corresponding to the true curved geometry, $(\\cdot, \\cdot)_J$, and one corresponding to a simplified reference geometry, $(\\cdot, \\cdot)_{\\text{ref}}$.\n\nThe quantity to be computed is\n$$ E(\\epsilon) = \\int_{K} \\big| P_{J} f(x) - P_{\\text{ref}} f(x) \\big|^{2} \\, dx $$\nBy changing variables using the isoparametric map $x=F(\\xi)$, this becomes\n$$ E(\\epsilon) = \\int_{-1}^{1} \\big| P_{J} f(\\xi) - P_{\\text{ref}} f(\\xi) \\big|^{2} J(\\xi) \\, d\\xi = \\left( P_{J} f - P_{\\text{ref}} f, P_{J} f - P_{\\text{ref}} f \\right)_J $$\nwhere $J(\\xi) = 1 + 3 \\epsilon \\xi^{2}$. The projections $P_{J} f$ and $P_{\\text{ref}} f$ are functions in the space $V_h = \\operatorname{span}\\{\\phi_1(\\xi), \\phi_2(\\xi)\\}$ where $\\phi_1(\\xi) = 1$ and $\\phi_2(\\xi) = \\xi$. Let the pullback of the target function be $\\hat{f}(\\xi) = \\xi + \\xi^2$.\n\nThe derivation proceeds in three main steps:\n1.  Compute the coefficients of the projection $P_{\\text{ref}} f$.\n2.  Compute the coefficients of the projection $P_{J} f$.\n3.  Calculate the difference between the projections and evaluate the integral for $E(\\epsilon)$.\n\n**Step 1: Computation of $P_{\\text{ref}} f(\\xi) = c_{1}^{(\\text{ref})} + c_{2}^{(\\text{ref})} \\xi$**\n\nThe projection $P_{\\text{ref}} f$ is defined by the orthogonality condition\n$$ (\\hat{f} - P_{\\text{ref}} f, v)_{\\text{ref}} = 0 \\quad \\forall v \\in V_h $$\nwhere $(\\hat{u},\\hat{v})_{\\text{ref}} = \\int_{-1}^{1} \\hat{u}(\\xi) \\hat{v}(\\xi) \\, d\\xi$. This is equivalent to testing against the basis functions:\n$$ (\\hat{f}, \\phi_i)_{\\text{ref}} = (P_{\\text{ref}} f, \\phi_i)_{\\text{ref}} \\quad \\text{for } i \\in \\{1, 2\\} $$\nThe basis functions $\\phi_1(\\xi) = 1$ and $\\phi_2(\\xi) = \\xi$ are orthogonal with respect to the $(\\cdot, \\cdot)_{\\text{ref}}$ inner product on $[-1,1]$, since $\\int_{-1}^{1} \\phi_1(\\xi) \\phi_2(\\xi) \\, d\\xi = \\int_{-1}^1 \\xi \\, d\\xi = 0$.\nThus, the coefficients are given by:\n$$ c_{1}^{(\\text{ref})} = \\frac{(\\hat{f}, \\phi_1)_{\\text{ref}}}{(\\phi_1, \\phi_1)_{\\text{ref}}}, \\quad c_{2}^{(\\text{ref})} = \\frac{(\\hat{f}, \\phi_2)_{\\text{ref}}}{(\\phi_2, \\phi_2)_{\\text{ref}}} $$\nWe compute the necessary integrals:\n$$ (\\phi_1, \\phi_1)_{\\text{ref}} = \\int_{-1}^{1} 1^2 \\, d\\xi = 2 $$\n$$ (\\phi_2, \\phi_2)_{\\text{ref}} = \\int_{-1}^{1} \\xi^2 \\, d\\xi = \\left[ \\frac{\\xi^3}{3} \\right]_{-1}^{1} = \\frac{2}{3} $$\n$$ (\\hat{f}, \\phi_1)_{\\text{ref}} = \\int_{-1}^{1} (\\xi + \\xi^2) \\cdot 1 \\, d\\xi = \\left[ \\frac{\\xi^2}{2} + \\frac{\\xi^3}{3} \\right]_{-1}^{1} = \\frac{2}{3} $$\n$$ (\\hat{f}, \\phi_2)_{\\text{ref}} = \\int_{-1}^{1} (\\xi + \\xi^2) \\cdot \\xi \\, d\\xi = \\int_{-1}^{1} (\\xi^2 + \\xi^3) \\, d\\xi = \\left[ \\frac{\\xi^3}{3} + \\frac{\\xi^4}{4} \\right]_{-1}^{1} = \\frac{2}{3} $$\nThe coefficients are:\n$$ c_{1}^{(\\text{ref})} = \\frac{2/3}{2} = \\frac{1}{3} $$\n$$ c_{2}^{(\\text{ref})} = \\frac{2/3}{2/3} = 1 $$\nTherefore, the reference projection is $P_{\\text{ref}} f(\\xi) = \\frac{1}{3} + \\xi$.\n\n**Step 2: Computation of $P_{J} f(\\xi) = c_{1}^{(J)} + c_{2}^{(J)} \\xi$**\n\nThe projection $P_{J} f$ is defined by the orthogonality condition using the weighted inner product $(\\hat{u},\\hat{v})_{J} = \\int_{-1}^{1} \\hat{u}(\\xi) \\hat{v}(\\xi) J(\\xi) \\, d\\xi$:\n$$ (\\hat{f} - P_{J} f, v)_J = 0 \\quad \\forall v \\in V_h $$\nThis yields the $2 \\times 2$ Galerkin system for the coefficients $(c_1^{(J)}, c_2^{(J)})$:\n$$ \\begin{pmatrix} (\\phi_1, \\phi_1)_J & (\\phi_2, \\phi_1)_J \\\\ (\\phi_1, \\phi_2)_J & (\\phi_2, \\phi_2)_J \\end{pmatrix} \\begin{pmatrix} c_1^{(J)} \\\\ c_2^{(J)} \\end{pmatrix} = \\begin{pmatrix} (\\hat{f}, \\phi_1)_J \\\\ (\\hat{f}, \\phi_2)_J \\end{pmatrix} $$\nThe Jacobian $J(\\xi)=1+3\\epsilon\\xi^2$ is an even function. Since $\\phi_1$ is even and $\\phi_2$ is odd, the off-diagonal terms of the mass matrix are integrals of odd functions over a symmetric domain, and are thus zero:\n$$ (\\phi_1, \\phi_2)_J = (\\phi_2, \\phi_1)_J = \\int_{-1}^{1} \\xi (1+3\\epsilon\\xi^2) \\, d\\xi = 0 $$\nThe diagonal terms are:\n$$ M_{11} = (\\phi_1, \\phi_1)_J = \\int_{-1}^{1} 1^2 (1+3\\epsilon\\xi^2) \\, d\\xi = \\left[ \\xi + \\epsilon\\xi^3 \\right]_{-1}^{1} = 2 + 2\\epsilon $$\n$$ M_{22} = (\\phi_2, \\phi_2)_J = \\int_{-1}^{1} \\xi^2 (1+3\\epsilon\\xi^2) \\, d\\xi = \\int_{-1}^{1} (\\xi^2+3\\epsilon\\xi^4) \\, d\\xi = \\left[ \\frac{\\xi^3}{3} + \\frac{3\\epsilon\\xi^5}{5} \\right]_{-1}^{1} = \\frac{2}{3} + \\frac{6\\epsilon}{5} $$\nThe right-hand side vector components are:\n$$ b_1 = (\\hat{f}, \\phi_1)_J = \\int_{-1}^{1} (\\xi+\\xi^2)(1+3\\epsilon\\xi^2) \\, d\\xi = \\int_{-1}^{1} (\\xi^2 + 3\\epsilon\\xi^4 + \\text{odd terms}) \\, d\\xi = \\frac{2}{3} + \\frac{6\\epsilon}{5} $$\n$$ b_2 = (\\hat{f}, \\phi_2)_J = \\int_{-1}^{1} (\\xi+\\xi^2)\\xi(1+3\\epsilon\\xi^2) \\, d\\xi = \\int_{-1}^{1} (\\xi^2 + 3\\epsilon\\xi^4 + \\text{odd terms}) \\, d\\xi = \\frac{2}{3} + \\frac{6\\epsilon}{5} $$\nWith a diagonal mass matrix, the solution is straightforward:\n$$ c_1^{(J)} = \\frac{b_1}{M_{11}} = \\frac{\\frac{2}{3} + \\frac{6\\epsilon}{5}}{2+2\\epsilon} = \\frac{\\frac{10+18\\epsilon}{15}}{2(1+\\epsilon)} = \\frac{10+18\\epsilon}{30(1+\\epsilon)} = \\frac{5+9\\epsilon}{15(1+\\epsilon)} $$\n$$ c_2^{(J)} = \\frac{b_2}{M_{22}} = \\frac{\\frac{2}{3} + \\frac{6\\epsilon}{5}}{\\frac{2}{3} + \\frac{6\\epsilon}{5}} = 1 $$\nThus, the curved-element projection is $P_{J} f(\\xi) = \\frac{5+9\\epsilon}{15(1+\\epsilon)} + \\xi$.\n\n**Step 3: Calculation of $E(\\epsilon)$**\n\nThe difference between the two projections is:\n$$ P_{J} f(\\xi) - P_{\\text{ref}} f(\\xi) = \\left(\\frac{5+9\\epsilon}{15(1+\\epsilon)} + \\xi\\right) - \\left(\\frac{1}{3} + \\xi\\right) = \\frac{5+9\\epsilon}{15(1+\\epsilon)} - \\frac{5(1+\\epsilon)}{15(1+\\epsilon)} = \\frac{4\\epsilon}{15(1+\\epsilon)} $$\nThe difference is a constant function of $\\xi$. Let $\\Delta P(\\xi) = \\frac{4\\epsilon}{15(1+\\epsilon)}$.\nNow we can compute $E(\\epsilon)$:\n$$ E(\\epsilon) = \\int_{-1}^{1} \\big| \\Delta P(\\xi) \\big|^{2} J(\\xi) \\, d\\xi = \\int_{-1}^{1} \\left( \\frac{4\\epsilon}{15(1+\\epsilon)} \\right)^2 (1+3\\epsilon\\xi^2) \\, d\\xi $$\nThe constant term can be factored out of the integral:\n$$ E(\\epsilon) = \\left( \\frac{4\\epsilon}{15(1+\\epsilon)} \\right)^2 \\int_{-1}^{1} (1+3\\epsilon\\xi^2) \\, d\\xi $$\nThe integral is precisely the mass matrix element $M_{11} = (\\phi_1, \\phi_1)_J = 2+2\\epsilon$.\nSubstituting this value:\n$$ E(\\epsilon) = \\frac{16\\epsilon^2}{225(1+\\epsilon)^2} \\cdot (2+2\\epsilon) = \\frac{16\\epsilon^2}{225(1+\\epsilon)^2} \\cdot 2(1+\\epsilon) $$\nSimplifying the expression by canceling one factor of $(1+\\epsilon)$ yields the final result:\n$$ E(\\epsilon) = \\frac{32\\epsilon^2}{225(1+\\epsilon)} $$\nThis expression quantifies the squared-error, measured in the physical element's $L^2$-norm, incurred by using a projection based on the unweighted reference inner product instead of the correct, geometry-aware weighted inner product.", "answer": "$$\n\\boxed{\\frac{32\\epsilon^2}{225(1+\\epsilon)}}\n$$", "id": "3367015"}]}