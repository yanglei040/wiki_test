{"hands_on_practices": [{"introduction": "The Lax-Milgram theorem's power hinges on two key properties: coercivity and boundedness. This first exercise tackles coercivity, the condition that guarantees stability. You will move beyond the abstract definition to calculate the precise coercivity constant $\\alpha$ for a reaction-diffusion problem, discovering its dependence on physical coefficients and the domain's Poincaré constant [@problem_id:3395434]. This is a foundational skill for proving the well-posedness of variational formulations.", "problem": "Let $\\Omega \\subset \\mathbb{R}^{d}$ be a bounded Lipschitz domain, and let $H^{1}_{0}(\\Omega)$ denote the Sobolev space of functions with square-integrable first derivatives and vanishing trace on $\\partial \\Omega$. Assume the Poincaré inequality holds with the optimal Poincaré constant $C_{P} > 0$, meaning that for all $u \\in H^{1}_{0}(\\Omega)$ one has $\\|u\\|_{L^{2}(\\Omega)} \\leq C_{P}\\,\\|\\nabla u\\|_{L^{2}(\\Omega)}$. Consider the symmetric bilinear form $a : H^{1}_{0}(\\Omega) \\times H^{1}_{0}(\\Omega) \\to \\mathbb{R}$ defined by\n$$\na(u,v) \\;=\\; \\int_{\\Omega} \\nabla u \\cdot \\nabla v \\, dx \\;+\\; c \\int_{\\Omega} u\\,v \\, dx,\n$$\nwith a fixed reaction coefficient $c \\geq 0$. In the context of well-posedness for spectral Galerkin and discontinuous Galerkin formulations of linear elliptic Partial Differential Equations (PDEs) via the Lax–Milgram theorem, one fundamental requirement is coercivity of $a(\\cdot,\\cdot)$ with respect to a norm on $H^{1}_{0}(\\Omega)$. Here, take the $H^{1}$-norm\n$$\n\\|u\\|_{H^{1}(\\Omega)}^{2} \\;=\\; \\|\\nabla u\\|_{L^{2}(\\Omega)}^{2} \\;+\\; \\|u\\|_{L^{2}(\\Omega)}^{2}.\n$$\nDetermine, in closed form, the largest coercivity constant $\\alpha = \\alpha(c, C_{P})$ such that the inequality\n$$\na(u,u) \\;\\ge\\; \\alpha \\,\\|u\\|_{H^{1}(\\Omega)}^{2} \\quad \\text{for all } u \\in H^{1}_{0}(\\Omega)\n$$\nholds, expressed purely in terms of $c$ and $C_{P}$. Your final answer must be a single closed-form analytic expression in $c$ and $C_{P}$.", "solution": "The problem requires finding the largest coercivity constant $\\alpha$, which is a function of the reaction coefficient $c$ and the Poincaré constant $C_{P}$, for the bilinear form $a(\\cdot,\\cdot)$ with respect to the $H^{1}$-norm.\n\nThe problem provides the following definitions:\nThe bilinear form is $a(u,v) = \\int_{\\Omega} \\nabla u \\cdot \\nabla v \\, dx + c \\int_{\\Omega} u\\,v \\, dx$ for $u, v \\in H^{1}_{0}(\\Omega)$ and a constant $c \\ge 0$.\nThe squared $L^2$-norm of the gradient is $\\|\\nabla u\\|_{L^{2}(\\Omega)}^{2} = \\int_{\\Omega} |\\nabla u|^{2} \\, dx$.\nThe squared $L^2$-norm is $\\|u\\|_{L^{2}(\\Omega)}^{2} = \\int_{\\Omega} u^{2} \\, dx$.\nThus, the bilinear form evaluated at $(u,u)$ is $a(u,u) = \\|\\nabla u\\|_{L^{2}(\\Omega)}^{2} + c \\|u\\|_{L^{2}(\\Omega)}^{2}$.\n\nThe norm on the space $H^{1}_{0}(\\Omega)$ is the $H^{1}$-norm, with its square defined as $\\|u\\|_{H^{1}(\\Omega)}^{2} = \\|\\nabla u\\|_{L^{2}(\\Omega)}^{2} + \\|u\\|_{L^{2}(\\Omega)}^{2}$.\n\nThe coercivity condition is $a(u,u) \\ge \\alpha \\|u\\|_{H^{1}(\\Omega)}^{2}$ for all $u \\in H^{1}_{0}(\\Omega)$.\n\nTo find the largest possible value of $\\alpha$, we must find the infimum of the ratio $\\frac{a(u,u)}{\\|u\\|_{H^{1}(\\Omega)}^{2}}$ over all non-zero functions in the space $H^{1}_{0}(\\Omega)$.\n$$\n\\alpha = \\inf_{u \\in H^{1}_{0}(\\Omega) \\setminus \\{0\\}} \\frac{a(u,u)}{\\|u\\|_{H^{1}(\\Omega)}^{2}}\n$$\nSubstituting the expressions for $a(u,u)$ and $\\|u\\|_{H^{1}(\\Omega)}^{2}$:\n$$\n\\alpha = \\inf_{u \\in H^{1}_{0}(\\Omega) \\setminus \\{0\\}} \\frac{\\|\\nabla u\\|_{L^{2}(\\Omega)}^{2} + c \\|u\\|_{L^{2}(\\Omega)}^{2}}{\\|\\nabla u\\|_{L^{2}(\\Omega)}^{2} + \\|u\\|_{L^{2}(\\Omega)}^{2}}\n$$\nFor any $u \\in H^{1}_{0}(\\Omega)$ such that $u \\not\\equiv 0$, it must be that $\\|\\nabla u\\|_{L^{2}(\\Omega)} > 0$. If $\\|\\nabla u\\|_{L^{2}(\\Omega)} = 0$, then $u$ is a constant function. Since $u \\in H^{1}_{0}(\\Omega)$, its trace on the boundary $\\partial\\Omega$ is zero, which implies the constant must be zero, so $u \\equiv 0$. Therefore, for any non-zero $u$, we can divide both the numerator and the denominator by $\\|\\nabla u\\|_{L^{2}(\\Omega)}^{2}$:\n$$\n\\alpha = \\inf_{u \\in H^{1}_{0}(\\Omega) \\setminus \\{0\\}} \\frac{1 + c \\frac{\\|u\\|_{L^{2}(\\Omega)}^{2}}{\\|\\nabla u\\|_{L^{2}(\\Omega)}^{2}}}{1 + \\frac{\\|u\\|_{L^{2}(\\Omega)}^{2}}{\\|\\nabla u\\|_{L^{2}(\\Omega)}^{2}}}\n$$\nLet us define a variable $z = \\frac{\\|u\\|_{L^{2}(\\Omega)}^{2}}{\\|\\nabla u\\|_{L^{2}(\\Omega)}^{2}}$. The problem is now reduced to finding the infimum of a function of $z$, where the domain of $z$ is determined by the properties of the space $H^{1}_{0}(\\Omega)$.\n\nThe Poincaré inequality is given as $\\|u\\|_{L^{2}(\\Omega)} \\le C_{P} \\|\\nabla u\\|_{L^{2}(\\Omega)}$ for all $u \\in H^{1}_{0}(\\Omega)$, with $C_{P}$ being the optimal constant. Squaring this inequality gives $\\|u\\|_{L^{2}(\\Omega)}^{2} \\le C_{P}^{2} \\|\\nabla u\\|_{L^{2}(\\Omega)}^{2}$, which implies $z = \\frac{\\|u\\|_{L^{2}(\\Omega)}^{2}}{\\|\\nabla u\\|_{L^{2}(\\Omega)}^{2}} \\le C_{P}^{2}$.\nThe set of all possible values for the ratio $z$ for $u \\in H^{1}_{0}(\\Omega) \\setminus \\{0\\}$ is the interval $[0, C_P^2]$. The value $z=C_P^2$ is achieved for the eigenfunction corresponding to the first eigenvalue of the negative Laplacian with homogeneous Dirichlet boundary conditions. Values of $z$ arbitrarily close to $0$ can be achieved by functions that are highly oscillatory (corresponding to eigenfunctions of the Laplacian with large eigenvalues).\n\nWe must therefore find the infimum of the function $f(z) = \\frac{1+cz}{1+z}$ over the interval $z \\in [0, C_{P}^{2}]$. To do this, we analyze the derivative of $f(z)$:\n$$\nf'(z) = \\frac{d}{dz}\\left(\\frac{1+cz}{1+z}\\right) = \\frac{c(1+z) - (1+cz)(1)}{(1+z)^{2}} = \\frac{c-1}{(1+z)^{2}}\n$$\nThe sign of the derivative depends on the value of $c$, and the problem states $c \\ge 0$. We consider two cases.\n\nCase 1: $c \\ge 1$.\nIn this case, $c-1 \\ge 0$, so $f'(z) \\ge 0$. This implies that $f(z)$ is a non-decreasing function on its domain. The infimum of $f(z)$ on the interval $[0, C_{P}^{2}]$ is thus attained at the left endpoint, $z=0$.\n$$\n\\alpha = f(0) = \\frac{1+c(0)}{1+0} = 1\n$$\n\nCase 2: $0 \\le c < 1$.\nIn this case, $c-1 < 0$, so $f'(z) < 0$. This implies that $f(z)$ is a strictly decreasing function on its domain. The infimum of $f(z)$ on the interval $[0, C_{P}^{2}]$ is thus attained at the right endpoint, $z=C_{P}^{2}$.\n$$\n\\alpha = f(C_{P}^{2}) = \\frac{1+cC_{P}^{2}}{1+C_{P}^{2}}\n$$\n\nWe can combine these two results into a single analytical expression.\nIf $c \\ge 1$, then $c-1 \\ge 0$, which means $cC_P^2 \\ge C_P^2$, so $1+cC_P^2 \\ge 1+C_P^2$. This gives $\\frac{1+cC_{P}^{2}}{1+C_{P}^{2}} \\ge 1$. Thus, for $c \\ge 1$, the result $\\alpha=1$ can be written as $\\min\\left(1, \\frac{1+cC_P^2}{1+C_P^2}\\right)$.\nIf $0 \\le c < 1$, then $c-1 < 0$, which means $cC_P^2 < C_P^2$, so $1+cC_P^2 < 1+C_P^2$. This gives $\\frac{1+cC_{P}^{2}}{1+C_{P}^{2}} < 1$. Thus, for $0 \\le c < 1$, the result $\\alpha=\\frac{1+cC_{P}^{2}}{1+C_{P}^{2}}$ can be written as $\\min\\left(1, \\frac{1+cC_P^2}{1+C_P^2}\\right)$.\n\nTherefore, for all $c \\ge 0$, the largest coercivity constant $\\alpha$ can be expressed in the single closed form:\n$$\n\\alpha(c, C_{P}) = \\min\\left(1, \\frac{1+cC_{P}^{2}}{1+C_{P}^{2}}\\right)\n$$", "answer": "$$\n\\boxed{\\min\\left(1, \\frac{1+c C_{P}^{2}}{1+C_{P}^{2}}\\right)}\n$$", "id": "3395434"}, {"introduction": "Next, we address boundedness, the property ensuring the problem's energy is well-defined and finite. This practice complements the first by tasking you with finding the sharp boundedness constant $M$ for a similar variational form [@problem_id:3395454]. You will connect this abstract constant to the material coefficients of the PDE and explore its uniformity across nested approximation spaces, a key concept for analyzing numerical methods.", "problem": "Let $\\Omega = (-1,1)$ and consider the Sobolev space $H_{0}^{1}(\\Omega)$ of functions with square-integrable weak derivatives that vanish at the boundary in the trace sense. Equip $H_{0}^{1}(\\Omega)$ with the norm $\\|u\\|_{H_{0}^{1}(\\Omega)} = \\|u'\\|_{L^{2}(\\Omega)}$. Define the bilinear form $a : H_{0}^{1}(\\Omega) \\times H_{0}^{1}(\\Omega) \\to \\mathbb{R}$ by\n$$\na(u,v) = \\int_{-1}^{1} (1+x)\\, u'(x)\\, v'(x)\\, dx.\n$$\nStarting from the fundamental definitions of $L^{2}$-integrability, the Cauchy–Schwarz inequality, and the definition of norm-bounded bilinear forms used in the Lax–Milgram theorem, derive the smallest boundedness constant $M$ such that\n$$\n|a(u,v)| \\le M \\, \\|u\\|_{H_{0}^{1}(\\Omega)} \\, \\|v\\|_{H_{0}^{1}(\\Omega)} \\quad \\text{for all } u,v \\in H_{0}^{1}(\\Omega).\n$$\nExpress $M$ in terms of bounds of the coefficient $(1+x)$ on $\\Omega$ and compute its exact value. Then, using first principles of norm definition and basis-independent continuity, discuss whether the same boundedness constant $M$ can be chosen uniformly with respect to the polynomial degree $p$ for spectral Galerkin spaces consisting of polynomials of degree at most $p$ satisfying homogeneous Dirichlet boundary conditions on $\\Omega$. Your final answer must be the exact value of $M$ as a single number with no units. No rounding is required.", "solution": "The problem is deemed valid as it is scientifically grounded in functional analysis, well-posed with a unique answer, objective, and contains all necessary information without contradictions.\n\nThe task is to find the smallest constant $M$ such that the inequality $|a(u,v)| \\le M \\|u\\|_{H_{0}^{1}(\\Omega)} \\|v\\|_{H_{0}^{1}(\\Omega)}$ holds for all $u,v \\in H_{0}^{1}(\\Omega)$. This constant $M$ is the operator norm of the bilinear form $a$.\n\nBy definition, the norm of the bilinear form $a$ is given by:\n$$\nM = \\sup_{u,v \\in H_{0}^{1}(\\Omega) \\setminus \\{0\\}} \\frac{|a(u,v)|}{\\|u\\|_{H_{0}^{1}(\\Omega)} \\|v\\|_{H_{0}^{1}(\\Omega)}}\n$$\nThe space $H_{0}^{1}(\\Omega)$ is equipped with the norm $\\|u\\|_{H_{0}^{1}(\\Omega)} = \\|u'\\|_{L^{2}(\\Omega)} = \\left(\\int_{-1}^{1} (u'(x))^2 dx\\right)^{1/2}$. The bilinear form is $a(u,v) = \\int_{-1}^{1} (1+x)\\, u'(x)\\, v'(x)\\, dx$.\n\nFirst, we establish an upper bound for $|a(u,v)|$.\n$$\n|a(u,v)| = \\left| \\int_{-1}^{1} (1+x)\\, u'(x)\\, v'(x)\\, dx \\right|\n$$\nUsing the triangle inequality for integrals, this becomes:\n$$\n|a(u,v)| \\le \\int_{-1}^{1} |(1+x)\\, u'(x)\\, v'(x)|\\, dx\n$$\nOn the domain $\\Omega = (-1,1)$, the coefficient function $c(x) = 1+x$ is strictly positive, so $|1+x| = 1+x$. The coefficient is bounded above:\n$$\n1+x \\le \\sup_{y \\in (-1,1)} (1+y) = 2\n$$\nSubstituting this upper bound into the integral:\n$$\n|a(u,v)| \\le \\int_{-1}^{1} 2\\, |u'(x)|\\, |v'(x)|\\, dx = 2 \\int_{-1}^{1} |u'(x)v'(x)|\\, dx\n$$\nNow, we apply the Cauchy–Schwarz inequality for integrals to the term $\\int_{-1}^{1} |u'(x)v'(x)|\\, dx$:\n$$\n\\int_{-1}^{1} |u'(x)v'(x)|\\, dx \\le \\left( \\int_{-1}^{1} (u'(x))^2 dx \\right)^{1/2} \\left( \\int_{-1}^{1} (v'(x))^2 dx \\right)^{1/2}\n$$\nThis is precisely the product of the norms:\n$$\n\\int_{-1}^{1} |u'(x)v'(x)|\\, dx \\le \\|u'\\|_{L^{2}(\\Omega)} \\|v'\\|_{L^{2}(\\Omega)} = \\|u\\|_{H_{0}^{1}(\\Omega)} \\|v\\|_{H_{0}^{1}(\\Omega)}\n$$\nCombining these inequalities, we have:\n$$\n|a(u,v)| \\le 2 \\, \\|u\\|_{H_{0}^{1}(\\Omega)} \\, \\|v\\|_{H_{0}^{1}(\\Omega)}\n$$\nThis demonstrates that a boundedness constant exists and is at most $2$. Thus, $M \\le 2$.\n\nTo find the smallest such constant, we need to determine if this bound is sharp. Since the bilinear form $a(u,v)$ is symmetric ($a(u,v) = a(v,u)$), its norm can be computed as:\n$$\nM = \\sup_{u \\in H_{0}^{1}(\\Omega) \\setminus \\{0\\}} \\frac{|a(u,u)|}{\\|u\\|_{H_{0}^{1}(\\Omega)}^2} = \\sup_{u \\in H_{0}^{1}(\\Omega) \\setminus \\{0\\}} \\frac{\\left| \\int_{-1}^{1} (1+x) (u'(x))^2 dx \\right|}{\\int_{-1}^{1} (u'(x))^2 dx}\n$$\nSince $1+x > 0$ and $(u'(x))^2 \\ge 0$, the integral in the numerator is non-negative, so the absolute value can be dropped. Let $w(x) = u'(x)$. For any $u \\in H_{0}^{1}(\\Omega)$, we have $\\int_{-1}^{1} u'(x) dx = u(1) - u(-1) = 0 - 0 = 0$. So, $w$ is any function in $L^2(\\Omega)$ with a zero integral. The problem reduces to finding:\n$$\nM = \\sup_{w \\in L^2(\\Omega), \\int w \\ne 0, \\int w dx = 0} \\frac{\\int_{-1}^{1} (1+x) w(x)^2 dx}{\\int_{-1}^{1} w(x)^2 dx}\n$$\nThis is the supremum of the Rayleigh quotient for the multiplication operator $L(w) = (1+x)w$ on the subspace of $L^2(\\Omega)$ functions with zero mean. The supremum of this Rayleigh quotient is the essential supremum of the multiplier function, $\\operatorname{ess sup}_{x \\in \\Omega} (1+x)$.\n\nThe essential supremum of $c(x) = 1+x$ on $\\Omega = (-1,1)$ is:\n$$\n\\operatorname{ess sup}_{x \\in (-1,1)} (1+x) = 2\n$$\nThis suggests that $M = 2$. To prove this rigorously, we must show that we can construct a sequence of functions $u_n \\in H_0^1(\\Omega)$ such that the quotient approaches $2$. This involves choosing functions $u_n'$ that have zero mean and whose $L^2$ mass becomes increasingly concentrated near $x=1$, where $1+x$ is maximal.\n\nFor any small $\\epsilon > 0$, consider a sequence of functions $w_\\epsilon(x) = u_\\epsilon'(x)$ that are non-zero only near $x=1$ but maintain the zero-mean property. For instance, let $w_\\epsilon(x)$ be large and positive on an interval $[1-\\delta, 1)$ and small and negative on a wider interval to balance the integral to zero. As shown in detailed constructions, the limit of the Rayleigh quotient as the support of the positive part of $w_\\epsilon$ shrinks towards $x=1$ (i.e., $\\delta \\to 0$) is indeed $2$. For example, consider a sequence of functions $u_n'$ that are highly peaked near $x=1$ and have a small negative part elsewhere to satisfy $\\int u_n' dx = 0$. The ratio $\\frac{\\int (1+x)(u_n')^2 dx}{\\int (u_n')^2 dx}$ will be dominated by the integral over the peak, where $1+x \\approx 2$. In the limit as $n \\to \\infty$, the ratio approaches $2$.\n\nThus, the supremum is $2$. The smallest boundedness constant is $M=2$. This constant is expressed in terms of the coefficient $c(x) = 1+x$ as $M = \\sup_{x \\in \\Omega} c(x)$.\n\nFor the second part of the problem, we consider the spectral Galerkin spaces $V_p = \\{ P \\in \\mathbb{P}_p(\\Omega) \\mid P(-1) = P(1) = 0 \\}$, where $\\mathbb{P}_p$ is the space of polynomials of degree at most $p$. Each $V_p$ is a finite-dimensional subspace of $H_0^1(\\Omega)$.\n\nThe question is whether the boundedness constant $M$ can be chosen uniformly with respect to the polynomial degree $p$.\nThe principle of norm definition states that the operator norm (and thus the boundedness constant) is the supremum of a ratio over a given space. The continuity of the bilinear form is its boundedness. A key property of the supremum is that for any subset $S \\subset T$, we have $\\sup_{x \\in S} f(x) \\le \\sup_{x \\in T} f(x)$.\n\nIn our case, for each $p$, the space $V_p$ is a subspace of $H_0^1(\\Omega)$. The boundedness constant for the bilinear form restricted to $V_p$ is\n$$\nM_p = \\sup_{u,v \\in V_p \\setminus \\{0\\}} \\frac{|a(u,v)|}{\\|u\\|_{H_0^1} \\|v\\|_{H_0^1}}\n$$\nSince $V_p \\subset H_0^1(\\Omega)$, the set over which the supremum is taken for $M_p$ is a subset of the set for $M$. Therefore, for any $p$, it must be that $M_p \\le M = 2$.\n\nThis means that the constant $M=2$, which was derived for the entire space $H_0^1(\\Omega)$, serves as a valid boundedness constant for the bilinear form on any subspace $V_p$. Since this constant $M=2$ does not depend on $p$, it is, by definition, a uniform boundedness constant with respect to the polynomial degree $p$.\n\nFurthermore, the set of all polynomials is dense in $H_0^1(\\Omega)$. This implies that the union of all Galerkin spaces $\\cup_{p=1}^{\\infty} V_p$ is a dense subset of $H_0^1(\\Omega)$. Due to this density, the supremum over the union of the subspaces equals the supremum over the whole space:\n$$\n\\sup_{p} M_p = \\sup_{p} \\left( \\sup_{u \\in V_p \\setminus \\{0\\}} \\frac{a(u,u)}{\\|u\\|_{H_0^1}^2} \\right) = \\sup_{u \\in \\cup V_p \\setminus \\{0\\}} \\frac{a(u,u)}{\\|u\\|_{H_0^1}^2} = \\sup_{u \\in H_0^1(\\Omega) \\setminus \\{0\\}} \\frac{a(u,u)}{\\|u\\|_{H_0^1}^2} = M = 2\n$$\nTherefore, not only can $M=2$ be chosen as a uniform constant, it is the smallest such uniform constant. This conclusion relies only on the definition of the norm of a bilinear form (a basis-independent concept) and the relationship between a space and its subspaces.", "answer": "$$\\boxed{2}$$", "id": "3395454"}, {"introduction": "This final practice synthesizes theory with computation, bringing the abstract machinery of Hilbert spaces to life. You will implement a spectral Galerkin method to numerically verify the profound link between the Lax-Milgram and Riesz representation theorems [@problem_id:3395440]. By coding the solution as a Riesz representer in an energy-orthonormal basis, you will gain a tangible, computational intuition for the concepts of coercivity, boundedness, and the very structure of the solution space.", "problem": "Consider the variational problem on the real interval $[-1,1]$ with the Hilbert space $V = H_0^1(-1,1)$, equipped with a bilinear form $a(\\cdot,\\cdot)$ defined by\n$$\na(u,v) = \\int_{-1}^1 \\left( \\alpha(x)\\, u'(x)\\, v'(x) + \\beta(x)\\, u(x)\\, v(x) \\right)\\, dx,\n$$\nwhere $\\alpha(x)$ and $\\beta(x)$ are given real-valued functions with $\\alpha(x) \\ge \\alpha_0 > 0$ and $\\beta(x) \\ge 0$ for all $x \\in [-1,1]$. Let $f \\in V^\\ast$ be a bounded linear functional, specified by a function $g(x)$ through\n$$\nf(v) = \\int_{-1}^1 g(x)\\, v(x)\\, dx.\n$$\nBy the Lax–Milgram theorem and the Riesz representation theorem, for symmetric and coercive $a(\\cdot,\\cdot)$ the unique solution $u \\in V$ to\n$$\na(u,v) = f(v) \\quad \\text{for all } v \\in V\n$$\ncan be identified as the Riesz representer of $f$ in the energy inner product $a(\\cdot,\\cdot)$, that is, $u = R^{-1} f$ where $R: V \\to V^\\ast$ is the Riesz isomorphism induced by $a(\\cdot,\\cdot)$.\n\nYour task is to implement a numerical probe of this viewpoint within a spectral and discontinuous Galerkin methods setting using the following finite-dimensional subspaces. Let $\\{L_n(x)\\}_{n\\ge 0}$ denote the Legendre polynomials on $[-1,1]$. Define the polynomial basis that enforces homogeneous Dirichlet boundary conditions by\n$$\n\\phi_n(x) = L_{n+1}(x) - L_{n-1}(x), \\quad n = 1,2,\\dots,N,\n$$\nwhich satisfies $\\phi_n(\\pm 1) = 0$, and take $V_N = \\operatorname{span}\\{\\phi_1,\\dots,\\phi_N\\} \\subset V$. You will discretize the bilinear form $a(\\cdot,\\cdot)$ and the linear functional $f(\\cdot)$ on $V_N$, and you will construct an $a(\\cdot,\\cdot)$-orthonormal spectral basis to test the Riesz representer structure.\n\nFundamental base you may assume:\n- Definitions of Hilbert spaces, bilinear forms, and inner products.\n- The Lax–Milgram theorem for symmetric, bounded, coercive bilinear forms on Hilbert spaces.\n- The Riesz representation theorem and the notion of the Riesz isomorphism.\n\nYou must implement the following numerical steps for each test case:\n1. Assemble the Gram matrix $G \\in \\mathbb{R}^{N \\times N}$ with entries $G_{ij} = a(\\phi_i,\\phi_j)$.\n2. Assemble the Hilbert space Gram matrix $S \\in \\mathbb{R}^{N \\times N}$ for the $H^1$ inner product $(u,v)_V = \\int_{-1}^1 \\left(u'(x) v'(x) + u(x) v(x)\\right)\\, dx$, with entries $S_{ij} = (\\phi_i,\\phi_j)_V$.\n3. Assemble the load vector $F \\in \\mathbb{R}^N$ with entries $F_i = f(\\phi_i) = \\int_{-1}^1 g(x)\\, \\phi_i(x)\\, dx$.\n4. Form an $a(\\cdot,\\cdot)$-orthonormal spectral basis $\\{\\psi_j\\}_{j=1}^N$ by computing a linear transformation $U \\in \\mathbb{R}^{N \\times N}$ such that\n$$\n\\psi_j = \\sum_{i=1}^N U_{ij}\\, \\phi_i, \\quad \\text{and} \\quad a(\\psi_i,\\psi_j) = \\delta_{ij}.\n$$\n5. Compute the following diagnostics:\n   - The orthonormality defect in the energy inner product,\n     $$\n     \\delta = \\|U^\\top G U - I\\|_2,\n     $$\n     where $\\|\\cdot\\|_2$ is the spectral norm and $I$ is the identity matrix of size $N$.\n   - The Riesz-representer coefficient consistency defect. Let $c^{(1)} \\in \\mathbb{R}^N$ solve the discrete variational problem $G c^{(1)} = F$ in the basis $\\{\\phi_i\\}$. Let $c^{(2)} = U \\left(U^\\top F\\right)$. Report\n     $$\n     \\varepsilon = \\frac{\\|c^{(1)} - c^{(2)}\\|_2}{\\|c^{(1)}\\|_2}.\n     $$\n   - The variational residual in the energy-orthonormal basis,\n     $$\n     \\rho = \\|U^\\top (G c^{(1)} - F)\\|_2.\n     $$\n   - The discrete coercivity and continuity constants of $a(\\cdot,\\cdot)$ with respect to the $H^1$-inner-product norm on $V_N$, estimated as the extreme generalized eigenvalues of the pair $(G,S)$:\n     $$\n     \\alpha_N = \\min_{\\mathbf{c}\\neq 0} \\frac{\\mathbf{c}^\\top G \\mathbf{c}}{\\mathbf{c}^\\top S \\mathbf{c}}, \\qquad\n     L_N = \\max_{\\mathbf{c}\\neq 0} \\frac{\\mathbf{c}^\\top G \\mathbf{c}}{\\mathbf{c}^\\top S \\mathbf{c}}.\n     $$\n6. Use Gauss–Legendre quadrature of sufficiently high order to approximate all integrals on $[-1,1]$. All trigonometric functions must use angles in radians.\n\nTest Suite:\nImplement the above for the following four test cases, each specified by $(N,\\alpha(x),\\beta(x),g(x))$:\n- Case A (happy path): $N=8$, $\\alpha(x) = 1 + \\tfrac{1}{2} x^2$, $\\beta(x) = 1$, $g(x) = \\sin(\\pi x) + x$.\n- Case B (small dimension; stiffness-dominated): $N=2$, $\\alpha(x) = 1$, $\\beta(x) = 0$, $g(x) = 1 - x^2$.\n- Case C (high contrast coefficients): $N=12$, $\\alpha(x) = 2 + 10 x^2$, $\\beta(x) = 0.1 + 0.5 x^2$, $g(x) = e^{x}$.\n- Case D (oscillatory coefficients and data): $N=10$, $\\alpha(x) = 1 + 0.2 \\cos(3\\pi x)$, $\\beta(x) = 0.5$, $g(x) = \\cos(2\\pi x)$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of four lists, one per test case, in the order A, B, C, D. Each inner list must contain five floating-point numbers in the order $[\\delta,\\varepsilon,\\rho,\\alpha_N,L_N]$.\n- For example, the printed string must look like\n$$\n\\texttt{[[dA,eA,rA,aA,LA],[dB,eB,rB,aB,LB],[dC,eC,rC,aC,LC],[dD,eD,rD,aD,LD]]}\n$$\nwith actual numerical values substituted. No physical units are involved in this problem, and all angles are in radians.", "solution": "The problem statement is a valid, well-posed exercise in numerical analysis, specifically within the field of spectral Galerkin methods for solving elliptic partial differential equations. It asks for a numerical implementation to explore the connection between the solution of a variational problem and the Riesz representation theorem. All provided data and definitions are mathematically and scientifically sound. We proceed with the solution.\n\nThe core of the problem is to find a numerical approximation to the solution $u \\in V = H_0^1(-1,1)$ of the variational equation\n$$\na(u,v) = f(v) \\quad \\text{for all } v \\in V,\n$$\nwhere the bilinear form $a(\\cdot,\\cdot)$ and the linear functional $f(\\cdot)$ are given by\n$$\na(u,v) = \\int_{-1}^1 \\left( \\alpha(x)\\, u'(x)\\, v'(x) + \\beta(x)\\, u(x)\\, v(x) \\right)\\, dx,\n$$\n$$\nf(v) = \\int_{-1}^1 g(x)\\, v(x)\\, dx.\n$$\nThe conditions $\\alpha(x) \\ge \\alpha_0 > 0$ and $\\beta(x) \\ge 0$ ensure that $a(\\cdot,\\cdot)$ is a symmetric, coercive, and bounded bilinear form on $V$. Coercivity follows from the Poincaré inequality on $H_0^1(-1,1)$, making $a(\\cdot,\\cdot)$ an inner product, referred to as the energy inner product. The existence and uniqueness of the solution $u$ are guaranteed by the Lax–Milgram theorem.\n\nWe employ a spectral Galerkin method by seeking an approximate solution $u_N$ in a finite-dimensional subspace $V_N \\subset V$. The subspace $V_N$ is spanned by a set of $N$ basis functions $\\{\\phi_n\\}_{n=1}^N$ that satisfy the homogeneous Dirichlet boundary conditions. The chosen basis is\n$$\n\\phi_n(x) = L_{n+1}(x) - L_{n-1}(x), \\quad n=1, \\dots, N,\n$$\nwhere $L_k(x)$ is the Legendre polynomial of degree $k$. The property $L_k(\\pm 1) = (\\pm 1)^k$ ensures that $\\phi_n(\\pm 1) = 0$ for all $n \\ge 1$, so $V_N \\subset H_0^1(-1,1)$. A crucial property for computation is the simple form of the derivative of these basis functions, which follows from a standard recurrence relation for Legendre polynomials:\n$$\n\\phi_n'(x) = \\frac{d}{dx}\\left(L_{n+1}(x) - L_{n-1}(x)\\right) = (2n+1)L_n(x).\n$$\nThis simplification is valid for $n \\ge 1$. For $n=1$, it relies on interpreting the basis function as $\\phi_1(x) = L_2(x)-L_0(x)$, which is consistent with the derivative formula.\n\nThe approximate solution is written as a linear combination of basis functions, $u_N(x) = \\sum_{j=1}^N c_j \\phi_j(x)$. Substituting this into the variational problem and choosing the test functions to be the basis functions themselves, $v = \\phi_i(x)$ for $i=1,\\dots,N$, we obtain the Galerkin system of linear equations:\n$$\n\\sum_{j=1}^N a(\\phi_j, \\phi_i) c_j = f(\\phi_i), \\quad i=1,\\dots,N.\n$$\nThis is a matrix system $G \\mathbf{c}^{(1)} = F$, where $\\mathbf{c}^{(1)} \\in \\mathbb{R}^N$ is the vector of unknown coefficients, $G \\in \\mathbb{R}^{N \\times N}$ is the Gram matrix (or stiffness matrix), and $F \\in \\mathbb{R}^N$ is the load vector. Their entries are given by:\n$$\nG_{ij} = a(\\phi_i, \\phi_j) = \\int_{-1}^1 \\left( \\alpha(x) \\phi_i'(x) \\phi_j'(x) + \\beta(x) \\phi_i(x) \\phi_j(x) \\right) dx,\n$$\n$$\nF_i = f(\\phi_i) = \\int_{-1}^1 g(x) \\phi_i(x) dx.\n$$\nThe problem uses $1$-based indexing for basis functions and matrix entries. In the implementation, we use $0$-based indexing for arrays, so matrix entry $(i,j)$ will correspond to basis functions $\\phi_{i+1}$ and $\\phi_{j+1}$.\n\nThe integrals defining $G$ and $F$ involve non-polynomial functions $\\alpha(x)$, $\\beta(x)$, and $g(x)$, and are computed numerically using Gauss-Legendre quadrature. A quadrature rule with $Q$ points and weights $\\{w_k, x_k\\}_{k=1}^Q$ approximates an integral as $\\int_{-1}^1 h(x) dx \\approx \\sum_{k=1}^Q h(x_k) w_k$. To ensure high accuracy, the number of points $Q$ is chosen to be sufficiently large, e.g., $Q > 2(N+1)$, to handle the polynomial part of the integrands exactly.\n\nThe central task is to relate the direct solution of $G \\mathbf{c}^{(1)} = F$ to the Riesz representation viewpoint. According to the Riesz representation theorem, the solution $u$ is the unique element in $V$ such that $a(u,v) = f(v)$ for all $v \\in V$. This means $u$ is the Riesz representer of the functional $f$ with respect to the energy inner product $a(\\cdot,\\cdot)$. To see this numerically, we construct an $a(\\cdot,\\cdot)$-orthonormal basis $\\{\\psi_j\\}_{j=1}^N$ for $V_N$. Let each new basis function be a linear combination of the old ones: $\\psi_j = \\sum_{i=1}^N U_{ij} \\phi_i$. The orthonormality condition $a(\\psi_i, \\psi_j) = \\delta_{ij}$ imposes the matrix condition $U^\\top G U = I$, where $U$ is the change-of-basis matrix. Since $G$ is symmetric and positive definite, such a matrix $U$ can be constructed from the eigenvalue decomposition of $G = Q \\Lambda Q^\\top$, where $Q$ is orthogonal and $\\Lambda$ is diagonal with positive eigenvalues. The transformation matrix is $U = Q \\Lambda^{-1/2}$.\n\nWith this orthonormal basis, the solution $u_N$ can be expressed as $u_N = \\sum_{j=1}^N d_j \\psi_j$. The coefficients $d_j$ are simply the evaluation of the functional $f$ on the new basis vectors: $d_j = f(\\psi_j)$. In vector form, $\\mathbf{d} = U^\\top F$. To obtain the coefficients in the original basis $\\{\\phi_i\\}$, we transform back: $\\mathbf{c}^{(2)} = U \\mathbf{d} = U(U^\\top F)$. Mathematically, $G^{-1} = UU^\\top$, so $\\mathbf{c}^{(1)} = G^{-1}F$ and $\\mathbf{c}^{(2)} = UU^\\top F$ must be identical. The numerical diagnostics assess the fidelity of this equivalence.\n\nThe required calculations are as follows:\n1.  **Gram Matrices and Load Vector**: Assemble the matrices $G, S$ and vector $F$ using numerical quadrature. $S$ is the Gram matrix for the standard $H^1$ inner product, i.e., with $\\alpha(x)=1, \\beta(x)=1$.\n2.  **Orthonormal Basis**: Compute $U$ from the eigendecomposition of $G$.\n3.  **Diagnostics**:\n    - $\\delta = \\|U^\\top G U - I\\|_2$: This measures the numerical error in constructing the orthonormalizing transformation $U$. It should be close to machine precision.\n    - $\\varepsilon = \\frac{\\|\\mathbf{c}^{(1)} - \\mathbf{c}^{(2)}\\|_2}{\\|\\mathbf{c}^{(1)}\\|_2}$: This compares the coefficient vector from directly solving the linear system, $\\mathbf{c}^{(1)} = G^{-1}F$, with the one obtained via the Riesz representation procedure, $\\mathbf{c}^{(2)} = U U^\\top F$. This demonstrates the numerical equivalence of the two approaches.\n    - $\\rho = \\|U^\\top (G \\mathbf{c}^{(1)} - F)\\|_2$: This is the norm of the residual of the linear system, projected into the energy-orthonormal basis. Since $G \\mathbf{c}^{(1)} - F$ is ideally zero (up to numerical precision of the linear solve), $\\rho$ should be very small.\n    - $\\alpha_N, L_N$: These are the discrete coercivity and continuity constants of the bilinear form $a(\\cdot,\\cdot)$ on the subspace $V_N$ with respect to the $H^1$-norm. They are computed as the minimum and maximum generalized eigenvalues of the matrix pair $(G,S)$, corresponding to the extrema of the Rayleigh quotient $\\frac{\\mathbf{v}^\\top G \\mathbf{v}}{\\mathbf{v}^\\top S \\mathbf{v}} = \\frac{a(v_N, v_N)}{\\|v_N\\|_{H^1}^2}$ for $v_N \\in V_N$. These constants are crucial in the a priori error analysis of the Galerkin method.", "answer": "```python\nimport numpy as np\nimport scipy.special\nimport scipy.linalg\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n\n    def compute_diagnostics(N, alpha_func, beta_func, g_func):\n        \"\"\"\n        Performs the numerical tasks for a single test case.\n        \n        Args:\n            N (int): The dimension of the polynomial subspace.\n            alpha_func (callable): The function alpha(x).\n            beta_func (callable): The function beta(x).\n            g_func (callable): The function g(x).\n            \n        Returns:\n            list: A list of five floats: [delta, epsilon, rho, alpha_N, L_N].\n        \"\"\"\n        # 1. Setup Quadrature\n        # A quadrature rule of degree Q is exact for polynomials of degree 2Q-1.\n        # The highest polynomial degree in integrands is roughly 2(N+1).\n        # We need 2Q-1 >= 2N+2, so Q >= N+1.5. A much safer choice is used.\n        Q = 3 * N + 1\n        x_q, w_q = np.polynomial.legendre.leggauss(Q)\n\n        # 2. Evaluate Basis Functions and derivatives at quadrature points\n        L_vals = np.zeros((Q, N + 2))\n        for k in range(N + 2):\n            L_vals[:, k] = scipy.special.eval_legendre(k, x_q)\n\n        PHI = np.zeros((Q, N))\n        DPHI = np.zeros((Q, N))\n        for i in range(N):\n            n = i + 1  # Basis functions are indexed from n=1 to N\n            # phi_n(x) = L_{n+1}(x) - L_{n-1}(x)\n            # For n=1, phi_1(x) = L_2(x) - L_0(x)\n            PHI[:, i] = L_vals[:, n + 1] - L_vals[:, n - 1]\n            \n            # phi'_n(x) = (2n+1)L_n(x)\n            DPHI[:, i] = (2 * n + 1) * L_vals[:, n]\n\n        # Evaluate coefficient functions at quadrature points\n        alpha_vals = alpha_func(x_q)\n        beta_vals = beta_func(x_q)\n        g_vals = g_func(x_q)\n\n        # 3. Assemble G, S, and F using vectorized operations\n        G = DPHI.T @ np.diag(w_q * alpha_vals) @ DPHI + PHI.T @ np.diag(w_q * beta_vals) @ PHI\n        S = DPHI.T @ np.diag(w_q) @ DPHI + PHI.T @ np.diag(w_q) @ PHI\n        F = PHI.T @ (w_q * g_vals)\n\n        # 4. Form the a-orthonormal basis transformation U\n        eigvals_G, eigvecs_G = scipy.linalg.eigh(G)\n        \n        # Guard against non-positive eigenvalues from numerical error\n        if np.any(eigvals_G <= 0):\n             eigvals_G[eigvals_G <= 0] = np.finfo(float).eps\n\n        Lambda_inv_sqrt = np.diag(1.0 / np.sqrt(eigvals_G))\n        U = eigvecs_G @ Lambda_inv_sqrt\n\n        # 5. Compute diagnostics\n        # Orthonormality defect delta\n        I = np.identity(N)\n        delta = np.linalg.norm((U.T @ G @ U) - I, ord=2)\n\n        # Riesz-representer consistency defect epsilon\n        c1 = scipy.linalg.solve(G, F, assume_a='pos')\n        c2 = U @ (U.T @ F)\n        norm_c1 = np.linalg.norm(c1, ord=2)\n        if norm_c1 < 1e-15:\n            epsilon = np.linalg.norm(c1 - c2, ord=2)\n        else:\n            epsilon = np.linalg.norm(c1 - c2, ord=2) / norm_c1\n        \n        # Variational residual rho\n        residual = G @ c1 - F\n        rho = np.linalg.norm(U.T @ residual, ord=2)\n\n        # Discrete coercivity and continuity constants alpha_N, L_N\n        gen_eigvals = scipy.linalg.eigh(G, S, eigvals_only=True)\n        alpha_N = gen_eigvals[0]\n        L_N = gen_eigvals[-1]\n\n        return [delta, epsilon, rho, alpha_N, L_N]\n\n    test_cases = [\n        # Case A: N=8, alpha(x)=1+0.5x^2, beta(x)=1, g(x)=sin(pi*x)+x\n        {'N': 8, 'alpha': lambda x: 1 + 0.5 * x**2, 'beta': lambda x: 1.0, 'g': lambda x: np.sin(np.pi * x) + x},\n        # Case B: N=2, alpha(x)=1, beta(x)=0, g(x)=1-x^2\n        {'N': 2, 'alpha': lambda x: 1.0, 'beta': lambda x: 0.0, 'g': lambda x: 1 - x**2},\n        # Case C: N=12, alpha(x)=2+10x^2, beta(x)=0.1+0.5x^2, g(x)=e^x\n        {'N': 12, 'alpha': lambda x: 2 + 10 * x**2, 'beta': lambda x: 0.1 + 0.5 * x**2, 'g': lambda x: np.exp(x)},\n        # Case D: N=10, alpha(x)=1+0.2cos(3pi*x), beta(x)=0.5, g(x)=cos(2pi*x)\n        {'N': 10, 'alpha': lambda x: 1 + 0.2 * np.cos(3 * np.pi * x), 'beta': lambda x: 0.5, 'g': lambda x: np.cos(2 * np.pi * x)}\n    ]\n    \n    results = []\n    for case in test_cases:\n        res = compute_diagnostics(case['N'], case['alpha'], case['beta'], case['g'])\n        results.append(res)\n    \n    # Format the final output string as specified: [[...],[...],...]\n    print(str(results).replace(' ', ''))\n\nsolve()\n```", "id": "3395440"}]}