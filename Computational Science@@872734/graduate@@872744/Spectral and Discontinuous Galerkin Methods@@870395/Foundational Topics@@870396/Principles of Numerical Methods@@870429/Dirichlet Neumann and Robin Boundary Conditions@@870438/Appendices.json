{"hands_on_practices": [{"introduction": "Spectral methods rely on representing solutions as series of basis functions that are themselves solutions to a related eigenvalue problem. This practice explores the cornerstone of this idea: the Sturm-Liouville problem for the one-dimensional Laplacian with homogeneous Dirichlet boundary conditions. By explicitly calculating the eigenvalues and eigenfunctions, you will directly verify the fundamental properties of orthogonality and completeness, which guarantee that any well-behaved function can be uniquely represented by a Fourier-type series in this eigenbasis. This exercise reinforces the theoretical foundation that makes spectral methods so powerful. [@problem_id:3379345]", "problem": "Consider the one-dimensional Laplacian eigenvalue problem on the interval $(0,1)$ given by the ordinary differential equation $-u''(x) = \\lambda u(x)$, subject to homogeneous Dirichlet boundary conditions $u(0) = 0$ and $u(1) = 0$. In the framework of spectral methods and discontinuous Galerkin methods, this is a prototypical Sturm–Liouville problem whose eigenstructure underpins orthogonal expansions, stability, and convergence of numerical schemes. Starting from the foundational facts that the Dirichlet Laplacian is a self-adjoint operator on $L^{2}(0,1)$ with domain $H^{2}(0,1) \\cap H_{0}^{1}(0,1)$, and that self-adjoint Sturm–Liouville operators have real eigenvalues with orthogonal eigenfunctions forming a complete set in $L^{2}(0,1)$, carry out the following steps:\n\n1. Solve the boundary value problem $-u''(x) = \\lambda u(x)$ with $u(0) = 0$ and $u(1) = 0$ to determine all eigenpairs $(\\lambda_{n}, u_{n})$. Justify that the eigenvalues are real and the eigenfunctions corresponding to distinct eigenvalues are orthogonal in $L^{2}(0,1)$, and explain why the eigenfunctions form a complete set in $L^{2}(0,1)$.\n2. For the function $f(x) = x$ on $(0,1)$, form its Fourier sine expansion in the eigenfunction basis $\\{u_{n}\\}_{n \\ge 1}$, using the $L^{2}(0,1)$ inner product $\\langle v, w \\rangle = \\int_{0}^{1} v(x) w(x) \\,\\mathrm{d}x$. Define the expansion coefficients $b_{n}$ by the projection formula $b_{n} = \\langle f, u_{n} \\rangle / \\langle u_{n}, u_{n} \\rangle$, and determine $b_{n}$ explicitly for all $n \\ge 1$.\n3. Using orthogonality and completeness, apply Parseval’s identity for this expansion to compute the exact value of the infinite sum\n$$\nS \\;=\\; \\sum_{n=1}^{\\infty} \\frac{1}{2}\\,b_{n}^{2}.\n$$\nProvide the final result for $S$ as a single exact number. No rounding is required. The final answer must be a single real number without any units.", "solution": "The problem as stated is a standard, well-posed Sturm-Liouville eigenvalue problem which is fundamental to the theory of partial differential equations and numerical methods. All provided information is consistent and sufficient to determine a unique solution. The problem is valid.\n\nWe proceed with the solution in three parts as requested.\n\nPart 1: Determination of Eigenpairs and Justification of Properties\n\nThe eigenvalue problem is given by the ordinary differential equation\n$$\n-u''(x) = \\lambda u(x), \\quad x \\in (0,1)\n$$\nwith homogeneous Dirichlet boundary conditions $u(0) = 0$ and $u(1) = 0$. The equation can be rewritten as $u''(x) + \\lambda u(x) = 0$. We analyze the nature of the eigenvalues $\\lambda$.\n\nCase 1: $\\lambda  0$. Let $\\lambda = -\\mu^2$ for some $\\mu > 0$. The equation becomes $u''(x) - \\mu^2 u(x) = 0$, with the general solution $u(x) = A \\cosh(\\mu x) + B \\sinh(\\mu x)$. Applying the boundary conditions:\n$u(0) = A \\cosh(0) + B \\sinh(0) = A = 0$.\nThe solution reduces to $u(x) = B \\sinh(\\mu x)$. The second boundary condition gives $u(1) = B \\sinh(\\mu) = 0$. Since $\\mu > 0$, $\\sinh(\\mu) \\neq 0$, which implies $B=0$. This yields only the trivial solution $u(x) = 0$, so there are no negative eigenvalues.\n\nCase 2: $\\lambda = 0$. The equation is $u''(x) = 0$, with the general solution $u(x) = Ax + B$. Applying the boundary conditions:\n$u(0) = B = 0$.\n$u(1) = A \\cdot 1 = A = 0$.\nThis again yields only the trivial solution, so $\\lambda=0$ is not an eigenvalue.\n\nCase 3: $\\lambda > 0$. Let $\\lambda = k^2$ for some $k > 0$. The equation becomes $u''(x) + k^2 u(x) = 0$, with the general solution $u(x) = A \\cos(k x) + B \\sin(k x)$. Applying the boundary conditions:\n$u(0) = A \\cos(0) + B \\sin(0) = A = 0$.\nThe solution is now $u(x) = B \\sin(k x)$. The second boundary condition gives $u(1) = B \\sin(k) = 0$. To obtain a non-trivial solution, we must have $B \\neq 0$, which requires $\\sin(k) = 0$. The solutions for $k>0$ are $k = n\\pi$ for $n = 1, 2, 3, \\ldots$.\nThe eigenvalues are therefore $\\lambda_n = k_n^2 = (n\\pi)^2$ for $n \\in \\{1, 2, 3, \\ldots\\}$.\nThe corresponding eigenfunctions are $u_n(x) = B_n \\sin(n\\pi x)$. We may choose the constant $B_n=1$ for simplicity, yielding the eigenpairs:\n$$\n(\\lambda_n, u_n(x)) = ((n\\pi)^2, \\sin(n\\pi x)) \\quad \\text{for } n=1, 2, 3, \\dots\n$$\n\nJustification of properties:\nThe problem is a regular Sturm-Liouville problem for the operator $L[u] = -u''$ on the interval $[0,1]$ with the specified boundary conditions. The properties of such systems are well-established.\n1.  Real Eigenvalues: The operator $L$ with the given boundary conditions is self-adjoint on $L^2(0,1)$. Let $(\\lambda, u)$ be an eigenpair. Then $\\langle Lu, u \\rangle = \\langle \\lambda u, u \\rangle = \\lambda \\langle u, u \\rangle$. Using integration by parts and the boundary conditions $u(0)=u(1)=0$:\n    $$\n    \\langle Lu, u \\rangle = \\int_{0}^{1} -u''(x) \\overline{u(x)} \\, \\mathrm{d}x = \\left[-u'(x)\\overline{u(x)}\\right]_{0}^{1} + \\int_{0}^{1} u'(x) \\overline{u'(x)} \\, \\mathrm{d}x = \\int_{0}^{1} |u'(x)|^2 \\, \\mathrm{d}x\n    $$\n    This is a real, non-negative quantity. Since $\\langle u, u \\rangle = \\int_{0}^{1} |u(x)|^2 \\, \\mathrm{d}x > 0$ for a non-trivial eigenfunction $u$, it follows that $\\lambda = \\frac{\\int_{0}^{1} |u'(x)|^2 \\, \\mathrm{d}x}{\\int_{0}^{1} |u(x)|^2 \\, \\mathrm{d}x}$ must be real and non-negative. Our direct calculation confirms this.\n2.  Orthogonality of Eigenfunctions: Let $(\\lambda_n, u_n)$ and $(\\lambda_m, u_m)$ be two eigenpairs with $\\lambda_n \\neq \\lambda_m$. We have $Lu_n = \\lambda_n u_n$ and $Lu_m = \\lambda_m u_m$. Due to the self-adjointness of $L$:\n    $$\n    \\langle Lu_n, u_m \\rangle = \\langle u_n, Lu_m \\rangle\n    $$\n    Substituting the eigenvalue relations and using the fact that eigenvalues are real:\n    $$\n    \\langle \\lambda_n u_n, u_m \\rangle = \\langle u_n, \\lambda_m u_m \\rangle \\implies \\lambda_n \\langle u_n, u_m \\rangle = \\lambda_m \\langle u_n, u_m \\rangle\n    $$\n    This gives $(\\lambda_n - \\lambda_m) \\langle u_n, u_m \\rangle = 0$. Since $\\lambda_n \\neq \\lambda_m$, we must have $\\langle u_n, u_m \\rangle = 0$. The eigenfunctions are thus orthogonal in $L^2(0,1)$.\n3.  Completeness: A central theorem of Sturm-Liouville theory states that the set of eigenfunctions of a regular Sturm-Liouville problem forms a complete orthogonal basis for the Hilbert space $L^2$ on the interval. Since our problem is a regular Sturm-Liouville problem, the set of eigenfunctions $\\{u_n(x) = \\sin(n\\pi x)\\}_{n \\ge 1}$ is a complete basis for $L^2(0,1)$.\n\nPart 2: Fourier Sine Expansion Coefficients\n\nWe wish to find the coefficients $b_n$ for the expansion of $f(x) = x$ in the eigenfunction basis $\\{u_n\\}_{n \\ge 1}$. The formula provided is $b_n = \\frac{\\langle f, u_n \\rangle}{\\langle u_n, u_n \\rangle}$.\n\nFirst, we compute the denominator, which is the squared $L^2$-norm of the eigenfunction $u_n(x) = \\sin(n\\pi x)$:\n$$\n\\langle u_n, u_n \\rangle = \\int_{0}^{1} \\sin^2(n\\pi x) \\, \\mathrm{d}x = \\int_{0}^{1} \\frac{1 - \\cos(2n\\pi x)}{2} \\, \\mathrm{d}x = \\frac{1}{2} \\left[ x - \\frac{\\sin(2n\\pi x)}{2n\\pi} \\right]_{0}^{1} = \\frac{1}{2} (1 - 0) = \\frac{1}{2}\n$$\n\nNext, we compute the numerator, which is the projection of $f(x)=x$ onto $u_n(x)$:\n$$\n\\langle f, u_n \\rangle = \\int_{0}^{1} x \\sin(n\\pi x) \\, \\mathrm{d}x\n$$\nUsing integration by parts with $u=x$ and $dv = \\sin(n\\pi x)dx$:\n$$\n\\int_{0}^{1} x \\sin(n\\pi x) \\, \\mathrm{d}x = \\left[ x \\left(-\\frac{\\cos(n\\pi x)}{n\\pi}\\right) \\right]_{0}^{1} - \\int_{0}^{1} \\left(-\\frac{\\cos(n\\pi x)}{n\\pi}\\right) \\, \\mathrm{d}x\n$$\n$$\n= \\left( -\\frac{1 \\cdot \\cos(n\\pi)}{n\\pi} - 0 \\right) + \\frac{1}{n\\pi} \\int_{0}^{1} \\cos(n\\pi x) \\, \\mathrm{d}x\n$$\n$$\n= -\\frac{(-1)^n}{n\\pi} + \\frac{1}{n\\pi} \\left[ \\frac{\\sin(n\\pi x)}{n\\pi} \\right]_{0}^{1} = \\frac{(-1)^{n+1}}{n\\pi} + \\frac{1}{(n\\pi)^2}(\\sin(n\\pi) - \\sin(0)) = \\frac{(-1)^{n+1}}{n\\pi}\n$$\n\nNow we combine the numerator and denominator to find $b_n$:\n$$\nb_n = \\frac{\\frac{(-1)^{n+1}}{n\\pi}}{\\frac{1}{2}} = \\frac{2(-1)^{n+1}}{n\\pi}\n$$\n\nPart 3: Computation of the Sum using Parseval's Identity\n\nThe problem asks for the value of the sum $S = \\sum_{n=1}^{\\infty} \\frac{1}{2}\\,b_{n}^{2}$. We are to use Parseval's identity. For a function $f$ expanded in a complete orthogonal basis $\\{u_n\\}$ as $f(x) = \\sum_{n=1}^{\\infty} c_n u_n(x)$ with $c_n = \\frac{\\langle f, u_n \\rangle}{\\langle u_n, u_n \\rangle}$, Parseval's identity states:\n$$\n\\langle f, f \\rangle = \\sum_{n=1}^{\\infty} |c_n|^2 \\langle u_n, u_n \\rangle\n$$\nIn our case, $f(x)=x$, the coefficients are $b_n=c_n$, and the eigenfunctions are real. The identity becomes:\n$$\n\\int_{0}^{1} (f(x))^2 \\, \\mathrm{d}x = \\sum_{n=1}^{\\infty} b_n^2 \\langle u_n, u_n \\rangle\n$$\nSubstituting the known values $f(x)=x$ and $\\langle u_n, u_n \\rangle = 1/2$:\n$$\n\\int_{0}^{1} x^2 \\, \\mathrm{d}x = \\sum_{n=1}^{\\infty} b_n^2 \\left(\\frac{1}{2}\\right)\n$$\nThe right-hand side is precisely the sum $S$ that we need to compute. Therefore, the value of $S$ is given by the integral on the left-hand side.\n$$\nS = \\int_{0}^{1} x^2 \\, \\mathrm{d}x = \\left[ \\frac{x^3}{3} \\right]_{0}^{1} = \\frac{1^3}{3} - \\frac{0^3}{3} = \\frac{1}{3}\n$$\nThe exact value of the infinite sum is $1/3$.", "answer": "$$\n\\boxed{\\frac{1}{3}}\n$$", "id": "3379345"}, {"introduction": "While eigenfunction expansions are powerful, the general foundation for Galerkin methods is the weak formulation, which recasts a differential equation into an integral form. This practice guides you through deriving the weak formulation for a Poisson problem with more complex Neumann and Robin boundary conditions, demonstrating how they are naturally incorporated into the problem. You will use this framework to derive the essential compatibility condition for a pure Neumann problem and prove the uniqueness of the solution for the Robin case by establishing coercivity, linking abstract functional analysis to the practical question of whether a boundary value problem is well-posed. [@problem_id:3379401]", "problem": "Consider the one-dimensional Poisson boundary value problem on the interval $\\Omega = (-1,1)$,\n$$\n-\\frac{\\mathrm{d}^2 u}{\\mathrm{d}x^2} = f(x),\n$$\nwith mixed Neumann–Robin boundary conditions\n$$\n\\frac{\\mathrm{d}u}{\\mathrm{d}x}(-1) = g_{N}, \\qquad \\frac{\\mathrm{d}u}{\\mathrm{d}x}(1) + \\beta\\, u(1) = g_{R},\n$$\nwhere $\\beta>0$ is a given constant, and $f$, $g_{N}$, $g_{R}$ are given data. Develop the weak formulation suitable for a Legendre spectral Galerkin method and for a Discontinuous Galerkin (DG) method by starting from the fundamental definition of the weak solution based on integration by parts. Then:\n\n1. By testing with constant functions, rigorously derive the compatibility condition that ensures solvability when the Robin boundary condition is turned off (that is, when $\\beta=0$ so that the right boundary condition is Neumann), and justify uniqueness in the mixed Neumann–Robin case ($\\beta>0$) by establishing coercivity of the bilinear form with a trace term.\n\n2. For the specific data $f(x) = p\\,x + q$ with constants $p,q \\in \\mathbb{R}$, compute the exact solution and determine the mean value $\\overline{u} = \\frac{1}{2}\\int_{-1}^{1} u(x)\\,\\mathrm{d}x$ as a closed-form expression in terms of $p$, $q$, $g_{N}$, $g_{R}$, and $\\beta$. Express your final answer for $\\overline{u}$ as a single analytic expression. No rounding is required.", "solution": "### Derivation of the Weak Formulation\n\nTo derive the weak formulation, we start with the strong form of the problem. We seek a solution $u$ in a suitable function space, which for this problem is the Sobolev space $H^1(\\Omega)$. We multiply the PDE by an arbitrary test function $v \\in H^1(\\Omega)$ and integrate over the domain $\\Omega = (-1, 1)$:\n$$\n-\\int_{-1}^{1} \\frac{\\mathrm{d}^2 u}{\\mathrm{d}x^2} v(x) \\,\\mathrm{d}x = \\int_{-1}^{1} f(x) v(x) \\,\\mathrm{d}x\n$$\nWe apply integration by parts to the left-hand side:\n$$\n\\int_{-1}^{1} \\frac{\\mathrm{d}u}{\\mathrm{d}x} \\frac{\\mathrm{d}v}{\\mathrm{d}x} \\,\\mathrm{d}x - \\left[ \\frac{\\mathrm{d}u}{\\mathrm{d}x}(x) v(x) \\right]_{-1}^{1} = \\int_{-1}^{1} f(x) v(x) \\,\\mathrm{d}x\n$$\nExpanding the boundary terms, we get:\n$$\n\\int_{-1}^{1} \\frac{\\mathrm{d}u}{\\mathrm{d}x} \\frac{\\mathrm{d}v}{\\mathrm{d}x} \\,\\mathrm{d}x - \\frac{\\mathrm{d}u}{\\mathrm{d}x}(1)v(1) + \\frac{\\mathrm{d}u}{\\mathrm{d}x}(-1)v(-1) = \\int_{-1}^{1} f(x) v(x) \\,\\mathrm{d}x\n$$\nNow, we incorporate the boundary conditions. The Neumann condition $\\frac{\\mathrm{d}u}{\\mathrm{d}x}(-1) = g_N$ is a natural boundary condition and can be substituted directly. The Robin condition gives $\\frac{\\mathrm{d}u}{\\mathrm{d}x}(1) = g_R - \\beta u(1)$, which is also substituted.\n$$\n\\int_{-1}^{1} \\frac{\\mathrm{d}u}{\\mathrm{d}x} \\frac{\\mathrm{d}v}{\\mathrm{d}x} \\,\\mathrm{d}x - (g_R - \\beta u(1))v(1) + g_N v(-1) = \\int_{-1}^{1} f(x) v(x) \\,\\mathrm{d}x\n$$\nRearranging the terms to group those involving the unknown solution $u$ on the left and known data on the right gives:\n$$\n\\int_{-1}^{1} \\frac{\\mathrm{d}u}{\\mathrm{d}x} \\frac{\\mathrm{d}v}{\\mathrm{d}x} \\,\\mathrm{d}x + \\beta u(1) v(1) = \\int_{-1}^{1} f(x) v(x) \\,\\mathrm{d}x + g_R v(1) - g_N v(-1)\n$$\nThis is the weak formulation of the problem. We define a bilinear form $a(u,v)$ and a linear functional $L(v)$ as:\n-   Bilinear form: $a(u,v) = \\int_{-1}^{1} \\frac{\\mathrm{d}u}{\\mathrm{d}x} \\frac{\\mathrm{d}v}{\\mathrm{d}x} \\,\\mathrm{d}x + \\beta u(1) v(1)$\n-   Linear functional: $L(v) = \\int_{-1}^{1} f(x) v(x) \\,\\mathrm{d}x + g_R v(1) - g_N v(-1)$\n\nThe weak problem is to find $u \\in H^1(\\Omega)$ such that $a(u,v) = L(v)$ for all $v \\in H^1(\\Omega)$. This formulation is suitable for approximation by spectral Galerkin or continuous Galerkin finite element methods. A Discontinuous Galerkin (DG) method would require a slight modification involving numerical fluxes at the element boundary (which in this case is the domain boundary), but this formulation is the fundamental starting point.\n\n### Part 1: Compatibility and Uniqueness Analysis\n\n**Compatibility Condition for $\\beta = 0$ (Pure Neumann BCs)**\n\nWhen $\\beta=0$, the Robin condition becomes a Neumann condition: $\\frac{\\mathrm{d}u}{\\mathrm{d}x}(1) = g_R$. The weak formulation simplifies to: Find $u \\in H^1(\\Omega)$ such that for all $v \\in H^1(\\Omega)$,\n$$\n\\int_{-1}^{1} \\frac{\\mathrm{d}u}{\\mathrm{d}x} \\frac{\\mathrm{d}v}{\\mathrm{d}x} \\,\\mathrm{d}x = \\int_{-1}^{1} f(x) v(x) \\,\\mathrm{d}x + g_R v(1) - g_N v(-1)\n$$\nThe problem states to test with constant functions. Let's choose the test function $v(x) = 1$. For this choice, $\\frac{\\mathrm{d}v}{\\mathrmd{x}} = 0$, $v(1)=1$, and $v(-1)=1$. Substituting this into the weak formulation gives:\n$$\n\\int_{-1}^{1} \\frac{\\mathrm{d}u}{\\mathrm{d}x} (0) \\,\\mathrm{d}x = \\int_{-1}^{1} f(x) (1) \\,\\mathrm{d}x + g_R (1) - g_N (1)\n$$\n$$\n0 = \\int_{-1}^{1} f(x) \\,\\mathrm{d}x + g_R - g_N\n$$\nThis yields the compatibility condition for solvability:\n$$\n\\int_{-1}^{1} f(x) \\,\\mathrm{d}x = g_N - g_R\n$$\nThis condition is necessary for a solution to exist. If it holds, a solution exists but is only unique up to an additive constant, since if $u(x)$ is a solution, so is $u(x)+C$ for any constant $C$. This is because the kernel of the bilinear form $a(u,v)=\\int u'v' dx$ consists of all constant functions.\n\n**Uniqueness for $\\beta>0$ (Mixed Neumann-Robin BCs)**\n\nFor $\\beta>0$, we can establish existence and uniqueness of the solution via the Lax-Milgram theorem. This requires the bilinear form $a(u,v)$ to be continuous and coercive on $H^1(\\Omega)$. Continuity is straightforward. We focus on proving coercivity, i.e., there exists a constant $C > 0$ such that $a(u,u) \\ge C \\|u\\|_{H^1}^2$ for all $u \\in H^1(\\Omega)$. The $H^1$ norm is defined as $\\|u\\|_{H^1}^2 = \\|u\\|_{L^2}^2 + \\|u'\\|_{L^2}^2 = \\int_{-1}^1 u^2 dx + \\int_{-1}^1 (u')^2 dx$.\n\nThe bilinear form evaluated for $v=u$ is:\n$$\na(u,u) = \\int_{-1}^{1} \\left(\\frac{\\mathrm{d}u}{\\mathrm{d}x}\\right)^2 \\,\\mathrm{d}x + \\beta (u(1))^2 = \\|u'\\|_{L^2}^2 + \\beta (u(1))^2\n$$\nSince $\\beta>0$, both terms are non-negative. We use a proof by contradiction to show coercivity. Assume $a(u,u)$ is not coercive. Then there exists a sequence $\\{u_n\\}_{n=1}^{\\infty} \\subset H^1(\\Omega)$ such that $\\|u_n\\|_{H^1} = 1$ for all $n$, and $a(u_n, u_n) \\to 0$ as $n \\to \\infty$.\n\nThe condition $a(u_n, u_n) \\to 0$ implies that $\\|u_n'\\|_{L^2}^2 \\to 0$ and $\\beta (u_n(1))^2 \\to 0$. Since $\\beta>0$, this means $\\|u_n'\\|_{L^2} \\to 0$ and $u_n(1) \\to 0$.\nThe condition $\\|u_n\\|_{H^1} = 1$ means $\\|u_n\\|_{L^2}^2 + \\|u_n'\\|_{L^2}^2 = 1$. Since $\\|u_n'\\|_{L^2} \\to 0$, we must have $\\|u_n\\|_{L^2} \\to 1$.\n\nNow, for any $u_n \\in H^1(\\Omega)$, we can use the Fundamental Theorem of Calculus:\n$u_n(x) = u_n(1) - \\int_x^1 u_n'(t) \\,\\mathrm{d}t$.\nTaking the absolute value and applying the Cauchy-Schwarz inequality to the integral:\n$|u_n(x)| \\le |u_n(1)| + \\left|\\int_x^1 u_n'(t) \\,\\mathrm{d}t\\right| \\le |u_n(1)| + \\left(\\int_x^1 1^2 \\,\\mathrm{d}t\\right)^{1/2} \\left(\\int_x^1 (u_n'(t))^2 \\,\\mathrm{d}t\\right)^{1/2}$\n$|u_n(x)| \\le |u_n(1)| + \\sqrt{1-x} \\left(\\int_x^1 (u_n')^2 \\,\\mathrm{d}t\\right)^{1/2} \\le |u_n(1)| + \\sqrt{2} \\|u_n'\\|_{L^2}$.\nAs $n \\to \\infty$, we know $u_n(1) \\to 0$ and $\\|u_n'\\|_{L^2} \\to 0$. Thus, for any $x \\in [-1,1]$, $|u_n(x)| \\to 0$. The convergence is uniform in $x$, which implies $L^2$ convergence. Therefore, $\\|u_n\\|_{L^2} \\to 0$.\nThis result, $\\|u_n\\|_{L^2} \\to 0$, directly contradicts our earlier finding that $\\|u_n\\|_{L^2} \\to 1$. The contradiction implies our initial assumption was false, so $a(u,u)$ is coercive. By the Lax-Milgram theorem, a unique solution exists.\n\n### Part 2: Exact Solution and Mean Value\n\nGiven $f(x) = px+q$, the PDE is $-\\frac{\\mathrm{d}^2 u}{\\mathrm{d}x^2} = px+q$. We find the general solution by integrating twice with respect to $x$:\n$$\n\\frac{\\mathrm{d}u}{\\mathrm{d}x} = -\\int (px+q) \\,\\mathrm{d}x = -\\frac{p}{2}x^2 - qx + C_1\n$$\n$$\nu(x) = \\int \\left(-\\frac{p}{2}x^2 - qx + C_1\\right) \\,\\mathrm{d}x = -\\frac{p}{6}x^3 - \\frac{q}{2}x^2 + C_1x + C_2\n$$\nThe constants of integration $C_1$ and $C_2$ are determined by the boundary conditions.\n\n1.  From the Neumann condition at $x=-1$: $\\frac{\\mathrm{d}u}{\\mathrm{d}x}(-1) = g_N$.\n    $$\n    -\\frac{p}{2}(-1)^2 - q(-1) + C_1 = g_N \\implies -\\frac{p}{2} + q + C_1 = g_N\n    $$\n    $$\n    C_1 = g_N + \\frac{p}{2} - q\n    $$\n\n2.  From the Robin condition at $x=1$: $\\frac{\\mathrm{d}u}{\\mathrm{d}x}(1) + \\beta u(1) = g_R$.\n    $$\n    \\frac{\\mathrm{d}u}{\\mathrm{d}x}(1) = -\\frac{p}{2}(1)^2 - q(1) + C_1 = -\\frac{p}{2} - q + C_1\n    $$\n    $$\n    u(1) = -\\frac{p}{6}(1)^3 - \\frac{q}{2}(1)^2 + C_1(1) + C_2 = -\\frac{p}{6} - \\frac{q}{2} + C_1 + C_2\n    $$\n    Substituting these into the Robin condition and solving for $C_2$:\n    $$\n    \\left(-\\frac{p}{2} - q + C_1\\right) + \\beta\\left(-\\frac{p}{6} - \\frac{q}{2} + C_1 + C_2\\right) = g_R\n    $$\n    Substitute the expression for $C_1$:\n    $$\n    \\left(g_N - 2q\\right) + \\beta\\left(\\frac{p}{3} - \\frac{3q}{2} + g_N + C_2\\right) = g_R\n    $$\n    $$\n    C_2 = \\frac{g_R - g_N + 2q}{\\beta} - \\left(\\frac{p}{3} - \\frac{3q}{2} + g_N\\right)\n    $$\n\nFinally, we compute the mean value $\\overline{u}$:\n$$\n\\overline{u} = \\frac{1}{2}\\int_{-1}^{1} u(x)\\,\\mathrm{d}x = \\frac{1}{2}\\int_{-1}^{1} \\left(-\\frac{p}{6}x^3 - \\frac{q}{2}x^2 + C_1x + C_2\\right) \\,\\mathrm{d}x\n$$\nThe integrals of odd powers ($x^3$, $x$) over the symmetric interval $(-1,1)$ are zero.\n$$\n\\overline{u} = \\frac{1}{2} \\left[ -\\frac{q}{2} \\int_{-1}^{1} x^2 \\,\\mathrm{d}x + C_2 \\int_{-1}^{1} 1 \\,\\mathrm{d}x \\right] = \\frac{1}{2} \\left[ -\\frac{q}{2} \\left(\\frac{2}{3}\\right) + 2C_2 \\right] = -\\frac{q}{6} + C_2\n$$\nSubstituting the expression for $C_2$ and simplifying:\n$$\n\\overline{u} = -\\frac{q}{6} + \\frac{g_R - g_N + 2q}{\\beta} - \\frac{p}{3} + \\frac{3q}{2} - g_N = -\\frac{p}{3} + q\\left(-\\frac{1}{6} + \\frac{3}{2} + \\frac{2}{\\beta}\\right) + g_N\\left(-1 - \\frac{1}{\\beta}\\right) + \\frac{g_R}{\\beta}\n$$\n$$\n\\overline{u} = -\\frac{p}{3} + q\\left(\\frac{4}{3} + \\frac{2}{\\beta}\\right) - g_N\\left(\\frac{\\beta+1}{\\beta}\\right) + \\frac{g_R}{\\beta}\n$$\nCombining terms over a common denominator of $3\\beta$ gives the final expression.\n$$\n\\overline{u} = \\frac{-p\\beta + q(4\\beta+6) - 3g_N(\\beta+1) + 3g_R}{3\\beta}\n$$", "answer": "$$\n\\boxed{\\frac{3g_R - (3\\beta+3)g_N - \\beta p + (4\\beta+6)q}{3\\beta}}\n$$", "id": "3379401"}, {"introduction": "Theoretical knowledge gains its full power when applied to build working numerical solvers. This hands-on coding practice challenges you to implement a Chebyshev collocation method, a high-order technique for solving differential equations, for a problem featuring mixed Dirichlet and Neumann boundary conditions. By using the method of manufactured solutions, you will not only verify the correctness of your implementation but also witness the hallmark of spectral methods: exponential convergence. This exercise provides critical experience in translating the strong form of a boundary value problem into a discrete linear system and verifying its accuracy. [@problem_id:3379366]", "problem": "Consider the one-dimensional Poisson equation $-\\Delta u = f$ on the interval $(0,1)$, where $\\Delta$ denotes the second derivative operator with respect to $x$, subject to a mixed boundary condition: a Dirichlet boundary condition at $x=0$ and a Neumann boundary condition at $x=1$. Specifically, enforce $u(0) = g_D$ and $\\partial_x u(1) = g_N$. The objective is to construct manufactured analytic solutions $u$ and associated right-hand sides $f$, discretize the problem using a Chebyshev collocation method on Chebyshev–Gauss–Lobatto points, and numerically verify spectral (exponential) convergence.\n\nBase definitions for the spectral collocation method must be followed. Use the Chebyshev–Gauss–Lobatto points $\\{\\xi_j\\}_{j=0}^N$ on $[-1,1]$ given by $\\xi_j = \\cos\\left(\\frac{\\pi j}{N}\\right)$, and the standard Chebyshev differentiation matrix $D$ on $[-1,1]$ defined by the well-tested explicit formula with entries\n$$D_{ij} = \\begin{cases}\n\\frac{c_i}{c_j}\\frac{(-1)^{i+j}}{\\xi_i - \\xi_j},  i \\neq j,\\\\\n-\\sum_{k \\neq i} D_{ik},  i=j,\n\\end{cases}$$\nwith $c_0 = 2$, $c_N = 2$, and $c_j = 1$ for $j=1,\\dots,N-1$. Map the computational domain using $x = \\frac{\\xi+1}{2}$ so that $\\xi = -1$ corresponds to $x=0$ and $\\xi=1$ corresponds to $x=1$. Under this mapping, $d/dx = 2\\,d/d\\xi$ and $d^2/dx^2 = 4\\,d^2/d\\xi^2$. Construct the discrete second derivative operator with respect to $x$ as $D^{(2)}_x = 4 D^2$.\n\nFormulate the collocation linear system as follows. For interior collocation points ($j=1,\\dots,N-1$), enforce the strong form $-u''(x_j) = f(x_j)$ using $-D^{(2)}_x u = f$. At the right endpoint ($j=0$, corresponding to $x=1$), enforce the Neumann boundary condition $\\partial_x u(1) = g_N$ using the discrete operator $2 D u = g_N$. At the left endpoint ($j=N$, corresponding to $x=0$), enforce the Dirichlet boundary condition $u(0) = g_D$ by replacing the corresponding row with an identity constraint.\n\nAngles for all trigonometric functions must be specified in radians.\n\nManufactured analytic solutions:\n- Choose $u_1(x) = e^{x} \\sin(2\\pi x)$ with $f_1(x) = -u_1''(x)$, and boundary data $g_{D,1} = u_1(0)$ and $g_{N,1} = u_1'(1)$.\n- Choose $u_2(x) = \\cosh(3x) + \\cos(5x)$ with $f_2(x) = -u_2''(x)$, and boundary data $g_{D,2} = u_2(0)$ and $g_{N,2} = u_2'(1)$.\n\nVerification target:\n- For analytic $u$, Chebyshev collocation is expected to produce errors that decay exponentially with respect to $N$. Quantify this by computing the least-squares slope $b$ and coefficient of determination $R^2$ of $\\log_{10}(\\text{error})$ versus $N$ for a sequence of $N$ values. Exponential convergence is numerically evidenced by a strongly negative slope $b0$ and a high $R^2$ close to $1$.\n\nError definition:\n- Use the pointwise maximum norm on the collocation grid: $\\|e\\|_{\\infty} = \\max_j |u_{\\text{num}}(x_j) - u_{\\text{exact}}(x_j)|$.\n\nTest suite and required outputs:\n- Test case $\\mathsf{A}$ (happy path): Use $u_1$ with $N \\in \\{8,16,32,64\\}$. Compute the least-squares slope $b_{\\mathsf{A}}$ and $R^2_{\\mathsf{A}}$ of $y = \\log_{10}(\\|e\\|_{\\infty})$ versus $N$, and also report the $\\|e\\|_{\\infty}$ at the largest $N=64$.\n- Test case $\\mathsf{B}$ (alternate analytic solution): Use $u_2$ with $N \\in \\{6,12,24,48\\}$. Compute $b_{\\mathsf{B}}$, $R^2_{\\mathsf{B}}$.\n- Test case $\\mathsf{C}$ (boundary condition verification): For $u_1$ with $N=32$, compute the absolute residuals at the boundaries using the discrete operators, namely $r_D = |u_{\\text{num}}(0) - g_{D,1}|$ and $r_N = |\\partial_x u_{\\text{num}}(1) - g_{N,1}|$, where $\\partial_x u_{\\text{num}}(1)$ is computed as $2\\,D u$ at the right endpoint row.\n- Test case $\\mathsf{D}$ (edge case small $N$): For $u_1$ with $N=4$, compute the maximum norm error $\\|e\\|_{\\infty}$.\n\nYour program must numerically assemble and solve the collocation linear systems and produce, in this exact order, a single line output containing a comma-separated list enclosed in square brackets with the following eight results:\n$$[b_{\\mathsf{A}}, R^2_{\\mathsf{A}}, \\|e\\|_{\\infty}\\text{ at }N=64, b_{\\mathsf{B}}, R^2_{\\mathsf{B}}, r_D, r_N, \\|e\\|_{\\infty}\\text{ at }N=4].$$\nAll values must be real numbers. Angles in $\\sin$ and $\\cos$ must be in radians. No units are required since all quantities are non-dimensional. The final output must be a single line in the exact required format.", "solution": "The problem describes a complete and scientifically sound numerical experiment: solving a 1D Poisson equation with mixed boundary conditions using a Chebyshev collocation method. The solution requires implementing the method and verifying its correctness and convergence properties using the method of manufactured solutions.\n\nThe core of the method is to discretize the differential equation and boundary conditions on a set of collocation points, transforming the problem into a system of linear algebraic equations. The solution is then obtained by solving this system.\n\nFirst, we define the computational domain and the physical domain. The problem specifies the physical domain as the interval $x \\in [0, 1]$. We use a standard affine mapping to relate this to the canonical Chebyshev domain $\\xi \\in [-1, 1]$:\n$$x(\\xi) = \\frac{\\xi + 1}{2}$$\nThe collocation points are the Chebyshev-Gauss-Lobatto (CGL) points, given by $\\xi_j = \\cos\\left(\\frac{\\pi j}{N}\\right)$ for $j=0, 1, \\dots, N$. Note that under this standard indexing, $\\xi_0=1$ corresponds to $x=1$, and $\\xi_N=-1$ corresponds to $x=0$.\n\nThe derivatives with respect to $x$ are related to derivatives with respect to $\\xi$ via the chain rule:\n$$ \\frac{d}{dx} = \\frac{d\\xi}{dx} \\frac{d}{d\\xi} = 2 \\frac{d}{d\\xi} $$\n$$ \\frac{d^2}{dx^2} = 4 \\frac{d^2}{d\\xi^2} $$\nIn the spectral collocation method, differentiation is performed by matrix-vector multiplication. We construct the $(N+1) \\times (N+1)$ Chebyshev differentiation matrix $D$ on the CGL grid $\\{\\xi_j\\}$. The problem provides the explicit formula for its entries $D_{ij}$. The discrete first and second derivative operators in the physical domain, $D^{(1)}_x$ and $D^{(2)}_x$, are then given by:\n$$ D^{(1)}_x = 2D $$\n$$ D^{(2)}_x = 4D^2 $$\n\nThe task is to find a vector $U$ of approximate solution values $U_j \\approx u(x_j)$ at the collocation points $x_j = x(\\xi_j)$. This vector is the solution to a linear system $A U = b$, where the matrix $A$ and vector $b$ enforce the governing equation and boundary conditions at the collocation points.\n\nThe system is constructed as follows:\n1.  **Interior Points ($j=1, \\dots, N-1$):** At these points, we enforce the Poisson equation, $-\\Delta u = f$, which becomes $-u''(x_j) = f(x_j)$. In discrete form, this is $-[D^{(2)}_x U]_j = f(x_j)$. These equations populate rows $1$ through $N-1$ of the system $A U = b$.\n\n2.  **Neumann Boundary at $x=1$ ($j=0$):** At this point, we enforce the condition $\\partial_x u(1) = g_N$. In discrete form, $[D^{(1)}_x U]_0 = g_N$. This equation populates row $0$ of the system.\n\n3.  **Dirichlet Boundary at $x=0$ ($j=N$):** At this point, we enforce $u(0) = g_D$. This is done by directly setting the value of the unknown, $U_N = g_D$. This is imposed by replacing row $N$ of the matrix $A$ with an identity row (all zeros except for a $1$ in column $N$) and setting the corresponding element of the right-hand side vector $b$ to $g_D$.\n\nAfter assembling the $(N+1) \\times (N+1)$ matrix $A$ and the right-hand side vector $b$, the system $A U = b$ is solved for the unknown vector $U$ using a standard linear solver.\n\nTo verify the method, we use the method of manufactured solutions. We choose a smooth function $u(x)$, then derive the corresponding source term $f(x) = -u''(x)$ and boundary data $g_D = u(0)$ and $g_N=u'(1)$. The numerical solution $U$ can then be compared to the known exact solution $u(x)$ evaluated at the collocation points. For an analytic solution $u(x)$, spectral methods are expected to exhibit exponential convergence, meaning the error $\\|e\\|_\\infty = \\max_j |U_j - u(x_j)|$ decays exponentially with $N$. This is verified by observing that $\\log_{10}(\\|e\\|_\\infty)$ is approximately a linear function of $N$. We quantify this relationship by performing a least-squares linear regression to find the slope $b$ and coefficient of determination $R^2$. A large negative slope and an $R^2$ value close to $1$ confirm exponential convergence.\n\nThe specified test cases involve two different manufactured solutions, calculation of convergence metrics, checking boundary condition residuals, and evaluating the error for a small $N$. The boundary residuals $r_D = |u_{\\text{num}}(0) - g_D|$ and $r_N = |\\partial_x u_{\\text{num}}(1) - g_N|$ serve as a sanity check that the linear system correctly enforces the boundary conditions. Given the method of enforcement, these residuals are expected to be close to machine precision.", "answer": "```python\nimport numpy as np\n\ndef linear_regression(x_data, y_data):\n    \"\"\"\n    Performs a linear regression y = a + b*x and calculates R^2.\n    \"\"\"\n    x_data = np.asarray(x_data)\n    y_data = np.asarray(y_data)\n\n    # Use numpy.polyfit to get slope and intercept\n    slope, intercept = np.polyfit(x_data, y_data, 1)\n    \n    # Calculate R-squared value\n    y_mean = np.mean(y_data)\n    y_predicted = slope * x_data + intercept\n    ss_total = np.sum((y_data - y_mean)**2)\n    ss_residual = np.sum((y_data - y_predicted)**2)\n    \n    if ss_total == 0:\n        # Handle case where all y_data points are the same\n        r_squared = 1.0 if ss_residual == 0 else 0.0\n    else:\n        r_squared = 1.0 - (ss_residual / ss_total)\n        \n    return slope, r_squared\n\ndef chebyshev_diff_matrix(N):\n    \"\"\"\n    Constructs the Chebyshev differentiation matrix D on N+1 CGL points.\n    \"\"\"\n    if N == 0:\n        return np.zeros((1, 1))\n    \n    j = np.arange(N + 1)\n    xi = np.cos(np.pi * j / N)\n    \n    c = np.ones(N + 1)\n    c[0] = 2.\n    c[N] = 2.\n    \n    # Off-diagonal entries\n    c_i = c[:, np.newaxis]\n    c_j = c[np.newaxis, :]\n    xi_i = xi[:, np.newaxis]\n    xi_j = xi[np.newaxis, :]\n    d_xi = xi_i - xi_j\n    \n    signs = (-1)**(np.arange(N + 1)[:, np.newaxis] + np.arange(N + 1)[np.newaxis, :])\n    \n    D = (c_i / c_j) * signs / (d_xi + np.eye(N + 1))\n    np.fill_diagonal(D, 0.)\n    \n    # Diagonal entries\n    np.fill_diagonal(D, -np.sum(D, axis=1))\n    \n    return D\n\ndef solve_poisson_1d(N, u_func, f_func, g_D_val, g_N_val):\n    \"\"\"\n    Solves the 1D Poisson BVP using Chebyshev collocation.\n    \"\"\"\n    j = np.arange(N + 1)\n    xi = np.cos(np.pi * j / N)\n    x = (xi + 1.0) / 2.0\n    \n    D = chebyshev_diff_matrix(N)\n    D1x = 2.0 * D\n    D2x = 4.0 * np.dot(D, D)\n\n    A = np.zeros((N + 1, N + 1))\n    b = np.zeros(N + 1)\n    \n    # Interior points: -u'' = f\n    A[1:N, :] = -D2x[1:N, :]\n    b[1:N] = f_func(x[1:N])\n    \n    # Neumann BC at x=1 (j=0)\n    A[0, :] = D1x[0, :]\n    b[0] = g_N_val\n    \n    # Dirichlet BC at x=0 (j=N)\n    A[N, :] = 0.0\n    A[N, N] = 1.0\n    b[N] = g_D_val\n    \n    U_num = np.linalg.solve(A, b)\n    U_exact = u_func(x)\n    \n    error = np.max(np.abs(U_num - U_exact))\n    \n    return {\n        \"error\": error,\n        \"U_num\": U_num,\n        \"D1x\": D1x,\n    }\n\ndef solve():\n    \"\"\"\n    Main function to execute all test cases and print results.\n    \"\"\"\n    # Manufactured solution 1\n    u1 = lambda x: np.exp(x) * np.sin(2. * np.pi * x)\n    u1_prime = lambda x: np.exp(x) * (np.sin(2. * np.pi * x) + 2. * np.pi * np.cos(2. * np.pi * x))\n    f1 = lambda x: -np.exp(x) * ( (1. - 4. * np.pi**2) * np.sin(2. * np.pi * x) + 4. * np.pi * np.cos(2. * np.pi * x) )\n    g_D1 = u1(0.0)\n    g_N1 = u1_prime(1.0)\n\n    # Manufactured solution 2\n    u2 = lambda x: np.cosh(3. * x) + np.cos(5. * x)\n    u2_prime = lambda x: 3. * np.sinh(3. * x) - 5. * np.sin(5. * x)\n    f2 = lambda x: -(9. * np.cosh(3. * x) - 25. * np.cos(5. * x))\n    g_D2 = u2(0.0)\n    g_N2 = u2_prime(1.0)\n    \n    # Test case A: u1, N = {8, 16, 32, 64}\n    Ns_A = np.array([8, 16, 32, 64])\n    errors_A = []\n    for N in Ns_A:\n        result = solve_poisson_1d(N, u1, f1, g_D1, g_N1)\n        errors_A.append(result[\"error\"])\n    log_errors_A = np.log10(np.array(errors_A))\n    b_A, R2_A = linear_regression(Ns_A, log_errors_A)\n    error_N64_A = errors_A[-1]\n\n    # Test case B: u2, N = {6, 12, 24, 48}\n    Ns_B = np.array([6, 12, 24, 48])\n    errors_B = []\n    for N in Ns_B:\n        result = solve_poisson_1d(N, u2, f2, g_D2, g_N2)\n        errors_B.append(result[\"error\"])\n    log_errors_B = np.log10(np.array(errors_B))\n    b_B, R2_B = linear_regression(Ns_B, log_errors_B)\n    \n    # Test case C: u1, N=32, boundary residuals\n    N_C = 32\n    result_C = solve_poisson_1d(N_C, u1, f1, g_D1, g_N1)\n    U_num_C = result_C[\"U_num\"]\n    D1x_C = result_C[\"D1x\"]\n    # Dirichlet residual at x=0 (index N)\n    r_D = np.abs(U_num_C[-1] - g_D1)\n    # Neumann residual at x=1 (index 0)\n    du_dx_at_1_num = (D1x_C @ U_num_C)[0]\n    r_N = np.abs(du_dx_at_1_num - g_N1)\n    \n    # Test case D: u1, N=4, error\n    N_D = 4\n    result_D = solve_poisson_1d(N_D, u1, f1, g_D1, g_N1)\n    error_N4_D = result_D[\"error\"]\n    \n    final_results = [b_A, R2_A, error_N64_A, b_B, R2_B, r_D, r_N, error_N4_D]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```", "id": "3379366"}]}