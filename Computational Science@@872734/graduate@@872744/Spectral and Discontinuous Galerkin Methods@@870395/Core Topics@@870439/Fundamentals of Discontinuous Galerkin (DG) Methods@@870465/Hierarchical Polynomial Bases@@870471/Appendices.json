{"hands_on_practices": [{"introduction": "To effectively use hierarchical bases in solving differential equations, we must first understand how fundamental operations like differentiation are represented. This practice explores the construction of the \"weak\" differentiation matrix, whose entries are inner products involving the derivative of one basis function and another basis function. By deriving its structure from the properties of Legendre polynomials [@problem_id:3390228], you will uncover a remarkable sparsity pattern that is critical for the computational efficiency of spectral and discontinuous Galerkin methods.", "problem": "Consider the one-dimensional reference element $[-1,1]$ used in Spectral methods and Discontinuous Galerkin (DG) methods. Let $\\{\\phi_{n}\\}_{n=0}^{\\infty}$ denote the hierarchical polynomial basis formed by the Legendre polynomials, where $\\phi_{n}(x) = P_{n}(x)$ is the Legendre polynomial of degree $n$, defined on $[-1,1]$ and normalized by $P_{n}(1) = 1$. Define the differentiation matrix entries\n$$\nD_{mn} = \\int_{-1}^{1} \\phi_{m}'(x)\\,\\phi_{n}(x)\\,dx,\n$$\nfor nonnegative integers $m,n$.\n\nStarting from fundamental properties of Legendre polynomials—namely orthogonality on $[-1,1]$, parity $P_{n}(-x) = (-1)^{n} P_{n}(x)$, and the three-term relations and derivative relations that are standard in the theory of orthogonal polynomials—derive a closed-form expression for $D_{mn}$ that reveals its sparsity pattern in the Legendre hierarchical basis. Using this expression, explicitly compute the matrix $\\left(D_{mn}\\right)_{m,n=0}^{3}$ up to degree $3$.\n\nYour final answer must be the explicit $4\\times 4$ matrix with exact integer entries (no rounding). No units are required.", "solution": "The user wants to derive a closed-form expression for the entries of a differentiation matrix in the Legendre polynomial basis and then compute a specific submatrix.\n\n### Step 1: Extract Givens\n- **Domain:** The one-dimensional reference element is $I = [-1, 1]$.\n- **Basis:** A hierarchical polynomial basis $\\{\\phi_n\\}_{n=0}^{\\infty}$ where $\\phi_n(x) = P_n(x)$, the Legendre polynomial of degree $n$.\n- **Normalization:** The Legendre polynomials are normalized such that $P_n(1) = 1$ for all $n \\geq 0$.\n- **Matrix Definition:** The entries of the differentiation matrix are given by the integral $D_{mn} = \\int_{-1}^{1} \\phi_{m}'(x)\\,\\phi_{n}(x)\\,dx$ for non-negative integers $m$ and $n$.\n- **Assumed Properties:** Standard properties of Legendre polynomials, including orthogonality, parity, and derivative relations.\n- **Task 1:** Derive a closed-form expression for $D_{mn}$.\n- **Task 2:** Explicitly compute the $4\\times 4$ matrix $(D_{mn})_{m,n=0}^{3}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, and objective. It is a standard problem in the field of numerical analysis, specifically concerning spectral and discontinuous Galerkin methods. The given information is self-contained and consistent. The problem asks for a derivation based on fundamental properties of Legendre polynomials, which are well-established in mathematics. No flaws are detected.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. Proceed with the solution.\n\n### Derivation of the Closed-Form Expression for $D_{mn}$\n\nThe entries of the differentiation matrix are defined as:\n$$\nD_{mn} = \\int_{-1}^{1} P_{m}'(x)\\,P_{n}(x)\\,dx\n$$\nTo evaluate this integral, we will use two fundamental properties of the Legendre polynomials $P_k(x)$ on the interval $[-1, 1]$.\n\n1.  **Orthogonality:** The Legendre polynomials form an orthogonal set with respect to the $L^2$ inner product on $[-1, 1]$. The standard normalization (distinct from the one specified for the problem's context but used in the orthogonality relation) leads to:\n    $$\n    \\int_{-1}^{1} P_k(x)P_j(x)\\,dx = \\frac{2}{2k+1}\\delta_{kj}\n    $$\n    where $\\delta_{kj}$ is the Kronecker delta.\n\n2.  **Derivative Expansion:** The derivative of a Legendre polynomial can be expressed as a series of lower-degree Legendre polynomials. A standard identity is:\n    $$\n    P_{m}'(x) = \\sum_{k=0, \\, m-k \\text{ is odd}}^{m-1} (2k+1)P_k(x)\n    $$\n    This formula expresses the derivative of $P_m(x)$, a polynomial of degree $m-1$, in the Legendre basis. The sum runs over indices $k$ from $0$ to $m-1$ such that the difference in degree, $m-k$, is an odd number. This reflects the parity of the derivative: if $P_m(x)$ has parity $(-1)^m$, its derivative $P_m'(x)$ has parity $(-1)^{m-1}$. Thus, its expansion can only contain polynomials $P_k(x)$ with parity $(-1)^k = (-1)^{m-1}$, which requires $k$ and $m-1$ to have the same parity, implying $m-k$ is odd.\n\nWe substitute the derivative expansion into the definition of $D_{mn}$:\n$$\nD_{mn} = \\int_{-1}^{1} \\left( \\sum_{k=0, \\, m-k \\text{ is odd}}^{m-1} (2k+1)P_k(x) \\right) P_n(x)\\,dx\n$$\nSince the sum is finite, we can interchange the summation and integration:\n$$\nD_{mn} = \\sum_{k=0, \\, m-k \\text{ is odd}}^{m-1} (2k+1) \\int_{-1}^{1} P_k(x)P_n(x)\\,dx\n$$\nNow, we apply the orthogonality property. The integral $\\int_{-1}^{1} P_k(x)P_n(x)\\,dx$ is non-zero only when $k=n$, in which case it equals $\\frac{2}{2n+1}$. For the sum to be non-zero, the index $n$ must be one of the indices $k$ present in the summation. This imposes two conditions on $n$:\n\n1.  $n$ must be in the range of the sum, i.e., $0 \\le n \\le m-1$. This means $n  m$. If $n \\ge m$, every term in the sum is zero, and thus $D_{mn} = 0$. This shows that the matrix $\\mathbf{D} = (D_{mn})$ is strictly lower triangular.\n2.  The difference $m-n$ must be odd, as required by the summation indices. If $m-n$ is even, $n$ will not be an index in the sum, and $D_{mn} = 0$.\n\nIf both conditions ($n  m$ and $m-n$ is odd) are satisfied, then there is exactly one non-zero term in the sum, which occurs when $k=n$. The expression for $D_{mn}$ simplifies to:\n$$\nD_{mn} = (2n+1) \\cdot \\left( \\frac{2}{2n+1} \\right) = 2\n$$\nCombining these results, we obtain the closed-form expression for the matrix entries:\n$$\nD_{mn} =\n\\begin{cases}\n2  \\text{if } n  m \\text{ and } (m-n) \\text{ is odd} \\\\\n0  \\text{otherwise}\n\\end{cases}\n$$\nThis expression reveals the sparsity pattern of the differentiation matrix in the hierarchical Legendre basis. It is a strictly lower triangular matrix with non-zero entries equal to $2$ only where the row and column indices differ by an odd number.\n\n### Computation of the Matrix $(D_{mn})_{m,n=0}^{3}$\n\nWe need to compute the $4 \\times 4$ matrix for $m, n \\in \\{0, 1, 2, 3\\}$. The matrix is:\n$$\n\\mathbf{D} = \\begin{pmatrix}\nD_{00}  D_{01}  D_{02}  D_{03} \\\\\nD_{10}  D_{11}  D_{12}  D_{13} \\\\\nD_{20}  D_{21}  D_{22}  D_{23} \\\\\nD_{30}  D_{31}  D_{32}  D_{33}\n\\end{pmatrix}\n$$\nWe apply the derived rule for $D_{mn}$:\n\n-   For the diagonal and upper triangular part ($n \\ge m$), all entries are $0$:\n    $D_{00} = D_{11} = D_{22} = D_{33} = 0$.\n    $D_{01} = D_{02} = D_{03} = 0$.\n    $D_{12} = D_{13} = 0$.\n    $D_{23} = 0$.\n\n-   For the strictly lower triangular part ($n  m$):\n    -   $D_{10}$: $m=1$, $n=0$. $nm$ is true. $m-n=1$ (odd). So, $D_{10} = 2$.\n    -   $D_{20}$: $m=2$, $n=0$. $nm$ is true. $m-n=2$ (even). So, $D_{20} = 0$.\n    -   $D_{21}$: $m=2$, $n=1$. $nm$ is true. $m-n=1$ (odd). So, $D_{21} = 2$.\n    -   $D_{30}$: $m=3$, $n=0$. $nm$ is true. $m-n=3$ (odd). So, $D_{30} = 2$.\n    -   $D_{31}$: $m=3$, n=1. $nm$ is true. $m-n=2$ (even). So, $D_{31} = 0$.\n    -   $D_{32}$: $m=3$, n=2. $nm$ is true. $m-n=1$ (odd). So, $D_{32} = 2$.\n\nAssembling these values gives the final matrix:\n$$\n\\mathbf{D} = \\begin{pmatrix}\n0  0  0  0 \\\\\n2  0  0  0 \\\\\n0  2  0  0 \\\\\n2  0  2  0\n\\end{pmatrix}\n$$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0  0  0  0 \\\\\n2  0  0  0 \\\\\n0  2  0  0 \\\\\n2  0  2  0\n\\end{pmatrix}\n}\n$$", "id": "3390228"}, {"introduction": "While analytical derivations are foundational, practical scientific computing requires us to approximate functions that are not simple polynomials. This hands-on coding exercise guides you through the process of computing the $L^2$-projection of a general function, such as $u(x) = \\exp(x)$, onto a Legendre basis [@problem_id:3390285]. You will implement the projection by replacing exact integrals with highly accurate Gauss-Legendre numerical quadrature, a cornerstone of spectral methods, and investigate how the choice of quadrature rule impacts the accuracy of the result.", "problem": "Consider the reference interval $[-1,1]$ and the space of polynomials up to degree $3$, denoted by $\\mathbb{P}_3$. Use the Legendre polynomials $\\{P_0(x),P_1(x),P_2(x),P_3(x)\\}$ as a hierarchical basis, where $P_n(x)$ is the $n$th Legendre polynomial. The Legendre polynomials satisfy the orthogonality relation on $[-1,1]$ with the standard $L^2$ inner product $\\langle f,g\\rangle = \\int_{-1}^{1} f(x) g(x)\\,dx$, namely $\\int_{-1}^{1} P_n(x) P_m(x)\\,dx = \\frac{2}{2n+1}\\,\\delta_{nm}$. Define the $L^2$-projection of a function $u(x)$ onto $\\mathbb{P}_3$ as $u_3(x) = \\sum_{n=0}^{3} c_n P_n(x)$, with coefficients determined by orthogonality.\n\nThe task is to derive, implement, and test the computation of the projection coefficients $c_n$ using Gauss–Legendre quadrature. The Gauss–Legendre quadrature with $N_q$ nodes on $[-1,1]$ integrates exactly all polynomials of degree up to $2N_q-1$. For a general non-polynomial $u(x)$, the inner products $\\int_{-1}^{1} u(x) P_n(x)\\,dx$ must be approximated numerically, and the quadrature order $N_q$ affects the accuracy.\n\nYou must:\n\n- Derive from first principles the formula for the $L^2$-projection coefficients $c_n$ with respect to the Legendre basis using orthogonality, starting from the definition of the projection and the inner product.\n- Use Gauss–Legendre quadrature with $N_q=3$ nodes to approximate $\\int_{-1}^{1} u(x) P_n(x)\\,dx$ for $n=0,1,2,3$, where $u(x)=e^x$.\n- Implement the Legendre polynomials via the three-term recurrence $P_0(x)=1$, $P_1(x)=x$, and $(n+1)P_{n+1}(x)=(2n+1)xP_n(x)-nP_{n-1}(x)$ for $n\\ge 1$.\n- Form the projection $u_3(x)$ by computing the coefficients $c_n$.\n- Estimate the quadrature error in the coefficients by comparing the coefficients computed with $N_q=3$ to a high-accuracy reference computed with $N_q^{\\text{ref}}=200$ Gauss–Legendre nodes.\n\nTo make the implementation testable, use the following test suite, each specifying the integrand $u(x)$ and the quadrature order $N_q$:\n\n- Test case 1 (general non-polynomial, \"happy path\"): $u(x)=e^x$, $N_q=3$.\n- Test case 2 (boundary of exactness for inner products with $\\mathbb{P}_3$): $u(x)=x^2$, $N_q=3$.\n- Test case 3 (edge case, minimal quadrature): $u(x)=e^x$, $N_q=1$.\n\nFor each test case, compute the four Legendre coefficients $c_n$ for $n=0,1,2,3$ using $N_q$ nodes and compute the reference coefficients using $N_q^{\\text{ref}}=200$. Report, for each test case, a single float equal to the maximum absolute difference across the four coefficients, that is, $\\max_{n=0,\\dots,3} |c_n^{(N_q)} - c_n^{\\text{ref}}|$.\n\nYour program should produce a single line of output containing the three results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3]\"). No physical units or angles apply in this problem, and all reported values must be plain decimal floats.", "solution": "The present problem requires the computation of $L^2$-projection coefficients of a function onto a polynomial space spanned by a hierarchical Legendre basis. This is a fundamental task in the development of spectral and discontinuous Galerkin methods. The solution involves deriving the analytical formula for the coefficients from first principles, discretizing the resulting integrals using Gauss-Legendre quadrature, and implementing the entire procedure to assess the numerical error for specific test cases.\n\nLet the space of polynomials of degree at most $k$ be denoted by $\\mathbb{P}_k$. We are working on the reference interval $I = [-1, 1]$ with the polynomial space $\\mathbb{P}_3$. The basis for this space is given by the first four Legendre polynomials, $\\{P_0(x), P_1(x), P_2(x), P_3(x)\\}$. These polynomials are orthogonal with respect to the standard $L^2$ inner product, defined as $\\langle f, g \\rangle = \\int_{-1}^{1} f(x)g(x) \\, dx$. The orthogonality relation is given by:\n$$\n\\langle P_n, P_m \\rangle = \\int_{-1}^{1} P_n(x) P_m(x) \\, dx = \\frac{2}{2n+1} \\delta_{nm}\n$$\nwhere $\\delta_{nm}$ is the Kronecker delta.\n\nThe $L^2$-projection of a function $u(x) \\in L^2(I)$ onto the subspace $\\mathbb{P}_3$ is a polynomial $u_3(x) \\in \\mathbb{P}_3$ such that the projection error, $e(x) = u(x) - u_3(x)$, is orthogonal to every function in $\\mathbb{P}_3$. It is sufficient to enforce orthogonality to each basis function:\n$$\n\\langle u(x) - u_3(x), P_m(x) \\rangle = 0 \\quad \\text{for } m = 0, 1, 2, 3\n$$\nThe projection $u_3(x)$ can be written as a linear combination of the basis functions:\n$$\nu_3(x) = \\sum_{n=0}^{3} c_n P_n(x)\n$$\nSubstituting this expansion into the orthogonality condition and using the linearity of the inner product, we obtain:\n$$\n\\langle u(x), P_m(x) \\rangle - \\left\\langle \\sum_{n=0}^{3} c_n P_n(x), P_m(x) \\right\\rangle = 0\n$$\n$$\n\\langle u(x), P_m(x) \\rangle - \\sum_{n=0}^{3} c_n \\langle P_n(x), P_m(x) \\rangle = 0\n$$\nDue to the orthogonality of the Legendre polynomials, the sum collapses to a single term where $n=m$:\n$$\n\\langle u(x), P_m(x) \\rangle - c_m \\langle P_m(x), P_m(x) \\rangle = 0\n$$\nSolving for the coefficient $c_m$ yields:\n$$\nc_m = \\frac{\\langle u(x), P_m(x) \\rangle}{\\langle P_m(x), P_m(x) \\rangle} = \\frac{\\int_{-1}^{1} u(x) P_m(x) \\, dx}{\\frac{2}{2m+1}}\n$$\nThus, the exact formula for the $m$-th projection coefficient is:\n$$\nc_m = \\frac{2m+1}{2} \\int_{-1}^{1} u(x) P_m(x) \\, dx\n$$\n\nFor a general function $u(x)$, the integral in the expression for $c_m$ may not be analytically solvable. We must resort to numerical quadrature. Gauss-Legendre quadrature is the optimal choice for integration over $[-1, 1]$ as a rule with $N_q$ nodes (points) integrates polynomials of degree up to $2N_q-1$ exactly. The quadrature approximation of an integral is given by:\n$$\n\\int_{-1}^{1} f(x) \\, dx \\approx \\sum_{j=1}^{N_q} w_j f(x_j)\n$$\nwhere $x_j$ are the quadrature nodes and $w_j$ are the corresponding weights. Applying this to the formula for $c_m$, we obtain the numerically approximated coefficient $c_m^{(N_q)}$:\n$$\nc_m^{(N_q)} = \\frac{2m+1}{2} \\sum_{j=1}^{N_q} w_j u(x_j) P_m(x_j)\n$$\n\nThe implementation will proceed as follows:\n1.  A function to evaluate the Legendre polynomials $P_n(x)$ for $n=0, \\dots, 3$ at a given set of points $x_j$. This is achieved efficiently using the three-term recurrence relation:\n    $P_0(x) = 1$\n    $P_1(x) = x$\n    $(n+1)P_{n+1}(x) = (2n+1)xP_n(x) - nP_{n-1}(x)$ for $n \\ge 1$.\n2.  A function to compute the coefficients $c_n^{(N_q)}$ for a given function $u(x)$, polynomial degree $3$, and quadrature order $N_q$. This function will:\n    a. Obtain the $N_q$ Gauss-Legendre nodes $x_j$ and weights $w_j$.\n    b. Evaluate $u(x_j)$ at the nodes.\n    c. Evaluate $P_n(x_j)$ for $n \\in \\{0, 1, 2, 3\\}$ at the nodes.\n    d. For each $n$, compute the sum $\\sum_{j=1}^{N_q} w_j u(x_j) P_n(x_j)$ and apply the scaling factor $\\frac{2n+1}{2}$.\n3.  The main routine will execute the three specified test cases. For each case, it will compute the coefficients using the specified $N_q$ and a high-accuracy reference quadrature with $N_q^{\\text{ref}} = 200$. The error is then calculated as the maximum absolute difference between the approximated and reference coefficients: $\\max_{n=0,\\dots,3} |c_n^{(N_q)} - c_n^{(N_q^{\\text{ref}})}|$.\n\nFor Test Case 2, where $u(x) = x^2$ and $N_q=3$, we analyze the integrand $f_n(x) = u(x)P_n(x) = x^2P_n(x)$. The degree of $P_n(x)$ is $n$. Thus, the degrees of the integrands for $n=0, 1, 2, 3$ are $2, 3, 4, 5$, respectively. Gauss-Legendre quadrature with $N_q=3$ nodes is exact for polynomials of degree up to $2N_q-1 = 5$. Consequently, the integrals for all four coefficients will be computed exactly by both the $N_q=3$ rule and the $N_q^{\\text{ref}}=200$ rule. The computed error is therefore expected to be zero, up to machine precision.\n\nFor the other test cases involving $u(x)=e^x$, the integrand is not a polynomial, and quadrature error is expected. The error will be larger for the lower-order quadrature rule, $N_q=1$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import roots_legendre\n\ndef legendre_poly_values(n_max, x):\n    \"\"\"\n    Evaluates Legendre polynomials P_0, ..., P_{n_max} at points x.\n\n    Args:\n        n_max (int): The maximum degree of the polynomial.\n        x (np.ndarray): A 1D array of points to evaluate the polynomials at.\n\n    Returns:\n        np.ndarray: A (n_max + 1) x len(x) array where P[n, j] = P_n(x[j]).\n    \"\"\"\n    if not isinstance(x, np.ndarray):\n        x = np.array(x)\n    \n    num_points = x.shape[0]\n    P = np.zeros((n_max + 1, num_points))\n\n    if n_max = 0:\n        P[0, :] = 1.0  # P_0(x) = 1\n    if n_max = 1:\n        P[1, :] = x    # P_1(x) = x\n    \n    # Use the three-term recurrence relation for n = 1\n    for n in range(1, n_max):\n        # (n+1)P_{n+1}(x) = (2n+1)xP_n(x) - nP_{n-1}(x)\n        P[n + 1, :] = ((2 * n + 1) * x * P[n, :] - n * P[n - 1, :]) / (n + 1)\n        \n    return P\n\ndef compute_coefficients(u_func, n_poly, N_q):\n    \"\"\"\n    Computes the L2-projection coefficients using Gauss-Legendre quadrature.\n\n    Args:\n        u_func (callable): The function u(x) to project.\n        n_poly (int): The maximum polynomial degree for projection (e.g., 3 for P_3).\n        N_q (int): The number of quadrature nodes.\n\n    Returns:\n        np.ndarray: A 1D array of coefficients [c_0, c_1, ..., c_{n_poly}].\n    \"\"\"\n    # 1. Get Gauss-Legendre quadrature nodes and weights\n    nodes, weights = roots_legendre(N_q)\n\n    # 2. Evaluate the function u(x) at the quadrature nodes\n    u_vals = u_func(nodes)\n\n    # 3. Evaluate Legendre polynomials P_n(x) at the nodes\n    # P_vals is a (n_poly+1) x N_q matrix where P_vals[n, j] = P_n(nodes[j])\n    P_vals = legendre_poly_values(n_poly, nodes)\n\n    # 4. Compute the coefficients\n    coeffs = np.zeros(n_poly + 1)\n    for n in range(n_poly + 1):\n        # Numerically integrate u, P_n\n        integrand_vals = u_vals * P_vals[n, :]\n        integral = np.sum(weights * integrand_vals)\n        \n        # Apply the normalization factor c_n = (2n+1)/2 * u, P_n\n        coeffs[n] = (2 * n + 1) / 2.0 * integral\n        \n    return coeffs\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and produce the final output.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (function u(x), number of quadrature nodes N_q)\n        (lambda x: np.exp(x), 3),  # Test case 1\n        (lambda x: x**2, 3),        # Test case 2\n        (lambda x: np.exp(x), 1)   # Test case 3\n    ]\n\n    # Parameters for the projection\n    n_poly = 3\n    N_q_ref = 200\n\n    results = []\n    for u_func, N_q in test_cases:\n        # Compute coefficients with the specified quadrature order\n        c_approx = compute_coefficients(u_func, n_poly, N_q)\n\n        # Compute high-accuracy reference coefficients\n        c_ref = compute_coefficients(u_func, n_poly, N_q_ref)\n\n        # Calculate the maximum absolute difference between the sets of coefficients\n        max_abs_diff = np.max(np.abs(c_approx - c_ref))\n        results.append(max_abs_diff)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3390285"}, {"introduction": "Legendre polynomials are a special case of the more general Jacobi polynomials, which provide the flexibility to work with weighted inner products. This advanced computational exercise demonstrates how to construct and use a hierarchical Jacobi basis tailored for specific applications, such as the discontinuous Galerkin (DG) method for advection problems [@problem_id:3390295]. By modeling an upwind numerical flux, you will quantitatively explore how the first few \"boundary-aware\" modes of the Jacobi expansion control the solution's accuracy at the element endpoints, a critical aspect of high-order numerical methods.", "problem": "You are to write a complete, runnable program that constructs and uses hierarchical Jacobi polynomial bases tailored to boundary-weighted norms for Discontinuous Galerkin (DG) advection on the interval $[-1,1]$, and quantitatively assesses how the first two boundary modes $n=0$ and $n=1$ affect the accuracy of the upwind numerical flux at the endpoints $x=\\pm 1$.\n\nThe fundamental mathematical base is as follows:\n- Let the Jacobi weight be $w^{(\\alpha,\\beta)}(x) = (1-x)^{\\alpha}(1+x)^{\\beta}$ on $[-1,1]$ with $\\alpha > -1$ and $\\beta > -1$. The weighted inner product is\n$$\n\\langle f,g \\rangle_{(\\alpha,\\beta)} = \\int_{-1}^{1} f(x)\\,g(x)\\,w^{(\\alpha,\\beta)}(x)\\,dx.\n$$\n- The Jacobi polynomials $P_n^{(\\alpha,\\beta)}(x)$ are orthogonal on $[-1,1]$ with respect to $w^{(\\alpha,\\beta)}(x)$. Define a hierarchical orthonormal basis $\\{\\phi_n^{(\\alpha,\\beta)}\\}_{n=0}^{N}$ by normalizing $P_n^{(\\alpha,\\beta)}(x)$ so that $\\langle \\phi_n^{(\\alpha,\\beta)},\\phi_m^{(\\alpha,\\beta)} \\rangle_{(\\alpha,\\beta)} = \\delta_{nm}$ and $\\deg(\\phi_n^{(\\alpha,\\beta)})=n$.\n- For the linear advection equation $u_t + a\\,u_x = 0$ on a single element $[-1,1]$ with constant advection speed $a \\in \\mathbb{R}$, the upwind numerical flux at the inflow boundary is $F_{\\text{up}} = a\\,u(b)$, where $b=-1$ if $a0$ and $b=+1$ if $a0$.\n- For a given analytic function $f$, define its truncated weighted $L^2$ projection onto the span of $\\{\\phi_n^{(\\alpha,\\beta)}\\}_{n=0}^{N}$ by\n$$\nf_N(x) = \\sum_{n=0}^{N} c_n \\,\\phi_n^{(\\alpha,\\beta)}(x),\n\\quad\nc_n = \\langle f, \\phi_n^{(\\alpha,\\beta)} \\rangle_{(\\alpha,\\beta)}.\n$$\n- To quantify the impact of boundary modes $n=0,1$ on upwind flux accuracy, define for $k \\in \\{0,1\\}$ the partial boundary reconstruction\n$$\ns_k(b) = \\sum_{n=0}^{k} c_n \\,\\phi_n^{(\\alpha,\\beta)}(b),\n$$\nand the corresponding upwind flux absolute error\n$$\nE_k = \\big| a \\,\\big(f(b) - s_k(b)\\big) \\big|.\n$$\n\nYour program must:\n1. Construct the hierarchical orthonormal Jacobi basis $\\{\\phi_n^{(\\alpha,\\beta)}\\}_{n=0}^{N}$ from $P_n^{(\\alpha,\\beta)}(x)$ and the weight $w^{(\\alpha,\\beta)}(x)$ using first principles (orthogonality and normalization). Numerical quadrature must be used to evaluate inner products for non-polynomial functions. Use Gauss–Jacobi quadrature that is consistent with the weight $w^{(\\alpha,\\beta)}(x)$ to approximate the inner products accurately.\n2. For each test case, compute the modal coefficients $\\{c_n\\}_{n=0}^{N}$ by numerical quadrature and then compute $E_0$ and $E_1$ as defined above. Angles, when present, must be interpreted in radians.\n3. Use the inflow boundary $b=-1$ if $a0$ and $b=1$ if $a0$.\n\nTest suite:\n- Case $1$: $\\alpha=0$, $\\beta=0$, $a=1$, $N=8$, $f(x)=\\exp(x)$, boundary $b=-1$.\n- Case $2$: $\\alpha=0$, $\\beta=3$, $a=1$, $N=8$, $f(x)=\\exp(5x)$, boundary $b=-1$.\n- Case $3$: $\\alpha=3$, $\\beta=0$, $a=-1$, $N=8$, $f(x)=\\cos(2\\pi x)$, boundary $b=+1$; use radians for the cosine argument.\n- Case $4$: $\\alpha=\\frac{1}{2}$, $\\beta=\\frac{1}{2}$, $a=1$, $N=10$, $f(x)=\\frac{1}{1+25x^2}$, boundary $b=-1$.\n\nProgram output requirements:\n- For each test case, compute and return the pair $[E_0,E_1]$ as real numbers rounded to $12$ decimal places in fixed-point decimal notation.\n- Your program should produce a single line of output containing the results for the four test cases as a comma-separated list of these pairs, enclosed in square brackets. The exact format must be:\n$$\n\"[[E0_1,E1_1],[E0_2,E1_2],[E0_3,E1_3],[E0_4,E1_4]]\"\n$$\nwhere each $E$ is a decimal number with $12$ digits after the decimal point.\n\nAll computations are dimensionless; no physical units are involved. Angles are in radians. You must not require any user input; the program must run and print the single required output line.", "solution": "The problem is valid. It is a well-posed problem in numerical analysis, grounded in the established theory of orthogonal polynomials and their application in spectral and Discontinuous Galerkin (DG) methods. All terms are clearly defined, the test cases are complete, and the objective is quantitative and verifiable.\n\nThe solution to this problem involves constructing and utilizing a hierarchical orthonormal polynomial basis to approximate a given function and then evaluating the accuracy of this approximation at a specific boundary point. The context is the approximation of an upwind numerical flux for the linear advection equation, $u_t + a\\,u_x = 0$. The core of the methodology rests on the properties of Jacobi polynomials.\n\nFirst, we establish the mathematical framework. The Jacobi polynomials, denoted $P_n^{(\\alpha,\\beta)}(x)$, are a sequence of polynomials orthogonal on the interval $[-1,1]$ with respect to the weight function $w^{(\\alpha,\\beta)}(x) = (1-x)^{\\alpha}(1+x)^{\\beta}$. The orthogonality is defined via the weighted inner product:\n$$\n\\langle f,g \\rangle_{(\\alpha,\\beta)} = \\int_{-1}^{1} f(x)\\,g(x)\\,w^{(\\alpha,\\beta)}(x)\\,dx\n$$\nSuch that $\\langle P_n^{(\\alpha,\\beta)}, P_m^{(\\alpha,\\beta)} \\rangle_{(\\alpha,\\beta)} = 0$ for $n \\neq m$.\n\nThe problem requires a hierarchical orthonormal basis $\\{\\phi_n^{(\\alpha,\\beta)}\\}_{n=0}^{N}$. A basis is hierarchical if the span of the first $k+1$ basis functions, $\\{\\phi_n\\}_{n=0}^{k}$, forms the space of all polynomials of degree at most $k$. Since we define $\\phi_n^{(\\alpha,\\beta)}$ to be a polynomial of degree $n$, this property is satisfied. To make the basis orthonormal, i.e., $\\langle \\phi_n^{(\\alpha,\\beta)}, \\phi_m^{(\\alpha,\\beta)} \\rangle_{(\\alpha,\\beta)} = \\delta_{nm}$, we normalize each Jacobi polynomial $P_n^{(\\alpha,\\beta)}(x)$. The normalization constant is the square root of the weighted inner product of the polynomial with itself, which is its squared norm $h_n^2$:\n$$\nh_n^2 = \\|P_n^{(\\alpha,\\beta)}\\|_{(\\alpha,\\beta)}^2 = \\int_{-1}^{1} \\left[P_n^{(\\alpha,\\beta)}(x)\\right]^2 w^{(\\alpha,\\beta)}(x)\\,dx = \\frac{2^{\\alpha+\\beta+1}}{2n+\\alpha+\\beta+1} \\frac{\\Gamma(n+\\alpha+1)\\Gamma(n+\\beta+1)}{n!\\Gamma(n+\\alpha+\\beta+1)}\n$$\nThe orthonormal basis functions are thus given by $\\phi_n^{(\\alpha,\\beta)}(x) = P_n^{(\\alpha,\\beta)}(x) / h_n$.\n\nNext, we project an analytic function $f(x)$ onto the space spanned by the first $N+1$ basis functions. This projection, $f_N(x)$, is a finite series expansion:\n$$\nf_N(x) = \\sum_{n=0}^{N} c_n \\,\\phi_n^{(\\alpha,\\beta)}(x)\n$$\nThe modal coefficients $c_n$ are computed by taking the inner product of $f(x)$ with each basis function:\n$$\nc_n = \\langle f, \\phi_n^{(\\alpha,\\beta)} \\rangle_{(\\alpha,\\beta)} = \\int_{-1}^{1} f(x)\\,\\phi_n^{(\\alpha,\\beta)}(x)\\,w^{(\\alpha,\\beta)}(x)\\,dx\n$$\nFor a general function $f(x)$, this integral must be computed numerically. The problem specifies the use of Gauss-Jacobi quadrature, which is the optimal choice for integrals of this form. A quadrature rule with $M$ points approximates the integral as:\n$$\n\\int_{-1}^{1} g(x)\\,w^{(\\alpha,\\beta)}(x)\\,dx \\approx \\sum_{i=1}^{M} w_i\\,g(x_i)\n$$\nwhere $x_i$ and $w_i$ are the quadrature nodes and weights. Applying this, the coefficients are calculated as $c_n \\approx \\sum_{i=1}^{M} w_i f(x_i) \\phi_n^{(\\alpha,\\beta)}(x_i)$. A sufficiently large value of $M$ is chosen to ensure high accuracy.\n\nThe final step is to assess the accuracy of the upwind numerical flux. For the advection equation, the inflow boundary $b$ is where information enters the domain. This is $b=-1$ if the advection speed $a$ is positive, and $b=+1$ if $a$ is negative. The upwind flux is based on the value of the solution at this boundary. We approximate the true value $f(b)$ using partial sums of the series expansion, $s_k(b)$, which represent the projection's value at the boundary using modes up to degree $k$:\n$$\ns_k(b) = \\sum_{n=0}^{k} c_n \\,\\phi_n^{(\\alpha,\\beta)}(b)\n$$\nTo evaluate $\\phi_n^{(\\alpha,\\beta)}(b)$ accurately, we use the analytical formulas for Jacobi polynomials at the endpoints $x=\\pm 1$:\n$$\nP_n^{(\\alpha,\\beta)}(1) = \\frac{\\Gamma(n+\\alpha+1)}{n! \\Gamma(\\alpha+1)}, \\quad \\quad P_n^{(\\alpha,\\beta)}(-1) = (-1)^n \\frac{\\Gamma(n+\\beta+1)}{n! \\Gamma(\\beta+1)}\n$$\nThe absolute error in the upwind flux approximation is then defined as $E_k = \\big| a \\,\\big(f(b) - s_k(b)\\big) \\big|$. We compute this for $k=0$ (constant approximation) and $k=1$ (linear approximation) to see how the inclusion of the linear mode improves the boundary representation.\n\nThe algorithm proceeds by iterating through each test case. For each case, it determines the parameters $\\alpha, \\beta, a, N$ and the function $f(x)$. It calculates the necessary components: Gauss-Jacobi quadrature nodes and weights, normalization constants $h_n$, modal coefficients $c_n$, and the values of the basis functions $\\phi_n^{(\\alpha,\\beta)}$ at the inflow boundary $b$. Finally, it assembles the partial sums $s_0(b)$ and $s_1(b)$ to compute the errors $E_0$ and $E_1$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import jacobi, roots_jacobi, gamma, gammaln\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0.0, 0.0, 1.0, 8, lambda x: np.exp(x)),\n        (0.0, 3.0, 1.0, 8, lambda x: np.exp(5.0 * x)),\n        (3.0, 0.0, -1.0, 8, lambda x: np.cos(2.0 * np.pi * x)),\n        (0.5, 0.5, 1.0, 10, lambda x: 1.0 / (1.0 + 25.0 * x**2))\n    ]\n\n    results = []\n    for case in test_cases:\n        alpha, beta, a, N, f = case\n        \n        # Determine inflow boundary based on advection speed 'a'\n        b = -1.0 if a  0 else 1.0\n\n        # Set up Gauss-Jacobi Quadrature. A high number of quadrature points\n        # is used for accuracy with the given analytic functions.\n        M = 100 \n        quad_x, quad_w = roots_jacobi(M, alpha, beta)\n\n        # Pre-compute values for efficiency\n        h_n = np.zeros(N + 1)      # Norms ||P_n||\n        c_n = np.zeros(N + 1)      # Modal coefficients\n        f_at_quad_x = f(quad_x)\n\n        for n in range(N + 1):\n            # Calculate the squared norm of P_n^(alpha, beta) using log-gamma for stability\n            log_h_n_sq = ((alpha + beta + 1.0) * np.log(2.0)\n                          - np.log(2.0 * n + alpha + beta + 1.0)\n                          + gammaln(n + alpha + 1.0)\n                          + gammaln(n + beta + 1.0)\n                          - gammaln(n + 1.0)\n                          - gammaln(n + alpha + beta + 1.0))\n            h_n[n] = np.exp(0.5 * log_h_n_sq)\n\n            # Get the standard Jacobi polynomial P_n\n            p_n_poly = jacobi(n, alpha, beta)\n            \n            # Evaluate the orthonormal basis function phi_n at quadrature points\n            phi_n_at_quad_x = p_n_poly(quad_x) / h_n[n]\n            \n            # Compute modal coefficient c_n using numerical quadrature\n            integrand = f_at_quad_x * phi_n_at_quad_x\n            c_n[n] = np.sum(quad_w * integrand)\n\n        # Evaluate orthonormal basis functions phi_n for n=0,1 at the boundary 'b'\n        phi_n_at_b = np.zeros(2)\n        for n in range(2):\n            # Use stable analytical formulas for P_n(b)\n            if b == 1.0:\n                log_p_n_at_b = gammaln(n + alpha + 1.0) - gammaln(n + 1.0) - gammaln(alpha + 1.0)\n                p_n_at_b = np.exp(log_p_n_at_b)\n            else:  # b == -1.0\n                log_p_n_at_b = gammaln(n + beta + 1.0) - gammaln(n + 1.0) - gammaln(beta + 1.0)\n                p_n_at_b = ((-1.0)**n) * np.exp(log_p_n_at_b)\n            \n            phi_n_at_b[n] = p_n_at_b / h_n[n]\n\n        # Compute partial boundary reconstructions s_k(b) for k=0, 1\n        s0_b = c_n[0] * phi_n_at_b[0]\n        s1_b = s0_b + c_n[1] * phi_n_at_b[1]\n\n        # Compute absolute upwind flux errors E_k\n        f_at_b = f(np.array([b]))[0]\n        E0 = np.abs(a * (f_at_b - s0_b))\n        E1 = np.abs(a * (f_at_b - s1_b))\n        \n        results.append((E0, E1))\n\n    # Format the results into the required string format\n    formatted_pairs = []\n    for E0, E1 in results:\n        formatted_pairs.append(f\"[{E0:.12f},{E1:.12f}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_pairs)}]\")\n\nsolve()\n```", "id": "3390295"}]}