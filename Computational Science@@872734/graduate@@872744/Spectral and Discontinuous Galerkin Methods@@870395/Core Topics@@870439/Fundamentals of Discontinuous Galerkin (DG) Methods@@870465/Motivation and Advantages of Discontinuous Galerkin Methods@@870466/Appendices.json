{"hands_on_practices": [{"introduction": "The power of Discontinuous Galerkin methods often begins with computations on a simple, standardized 'reference' element. This first exercise guides you through the crucial process of mapping from this reference element to a 'physical' element in your mesh, and reveals how this geometric transformation directly influences the structure of the mass matrix [@problem_id:3401227]. Understanding this connection is key to appreciating the computational efficiency that DG methods can offer, particularly for time-dependent problems.", "problem": "Consider a Discontinuous Galerkin (DG) method on a single quadrilateral element with nondimensional coordinates. Let the reference element be the square $\\widehat{K} = [-1,1] \\times [-1,1]$ with local coordinates $(r,s)$. The physical element $K$ has vertices ordered counterclockwise corresponding to the reference corners $(-1,-1)$, $(1,-1)$, $(1,1)$, $(-1,1)$, and is given by the points $(0,0)$, $(2,0)$, $(2,3)$, $(0,3)$ in the physical coordinate system $(x,y)$. Use the standard bilinear isoparametric mapping constructed from the four bilinear Lagrange shape functions on $\\widehat{K}$:\n$$\nN_{1}(r,s) = \\frac{1}{4}(1-r)(1-s),\\quad\nN_{2}(r,s) = \\frac{1}{4}(1+r)(1-s),\\quad\nN_{3}(r,s) = \\frac{1}{4}(1+r)(1+s),\\quad\nN_{4}(r,s) = \\frac{1}{4}(1-r)(1+s),\n$$\nand define the mapping to the physical element by\n$$\nx(r,s) = \\sum_{i=1}^{4} N_{i}(r,s)\\,x_{i},\\qquad\ny(r,s) = \\sum_{i=1}^{4} N_{i}(r,s)\\,y_{i},\n$$\nwhere $(x_{i},y_{i})$ are the physical vertex coordinates in the order above. Let the approximation space on $\\widehat{K}$ be the tensor-product $L^{2}$-orthonormal polynomial basis\n$$\n\\psi_{p,q}(r,s) = \\varphi_{p}(r)\\,\\varphi_{q}(s),\\qquad p,q \\in \\{0,1,\\dots,P\\},\n$$\nwith $\\varphi_{p}(r) = \\sqrt{\\frac{2p+1}{2}}\\,P_{p}(r)$, where $P_{p}$ is the Legendre polynomial of degree $p$ on $[-1,1]$, so that\n$$\n\\int_{-1}^{1}\\int_{-1}^{1} \\psi_{p,q}(r,s)\\,\\psi_{p',q'}(r,s)\\,dr\\,ds = \\delta_{p,p'}\\,\\delta_{q,q'}.\n$$\nThe local mass matrix entry for the DG method is defined by\n$$\nM_{(p,q),(p',q')} = \\int_{K} \\psi_{p,q}(x,y)\\,\\psi_{p',q'}(x,y)\\,dA,\n$$\nwhere $dA$ is the physical area element, and $\\delta_{i,j}$ denotes the Kronecker delta.\n\nStarting from these definitions:\n- Compute the explicit reference-to-physical mapping $(x(r,s),y(r,s))$ and the Jacobian determinant $J(r,s) = \\det\\left(\\frac{\\partial(x,y)}{\\partial(r,s)}\\right)$.\n- Use the change-of-variables formula to write $M_{(p,q),(p',q')}$ as an integral over $\\widehat{K}$ including the Jacobian determinant.\n- Evaluate this integral in closed form.\n\nExplain briefly, based on your derivation, how the resulting structure of the local mass matrix illustrates a core computational motivation and advantage of Discontinuous Galerkin methods (DG), focusing on locality and efficiency. Express your final answer as a single closed-form analytic expression for $M_{(p,q),(p',q')}$; no rounding is required.", "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\n-   Reference element: The square $\\widehat{K} = [-1,1] \\times [-1,1]$ with local coordinates $(r,s)$.\n-   Physical element vertices: Ordered counterclockwise, corresponding to reference corners $(-1,-1)$, $(1,-1)$, $(1,1)$, $(-1,1)$, are $(x_1,y_1)=(0,0)$, $(x_2,y_2)=(2,0)$, $(x_3,y_3)=(2,3)$, $(x_4,y_4)=(0,3)$.\n-   Bilinear Lagrange shape functions:\n    $N_{1}(r,s) = \\frac{1}{4}(1-r)(1-s)$\n    $N_{2}(r,s) = \\frac{1}{4}(1+r)(1-s)$\n    $N_{3}(r,s) = \\frac{1}{4}(1+r)(1+s)$\n    $N_{4}(r,s) = \\frac{1}{4}(1-r)(1+s)$\n-   Isoparametric mapping: $x(r,s) = \\sum_{i=1}^{4} N_{i}(r,s)\\,x_{i}$, $y(r,s) = \\sum_{i=1}^{4} N_{i}(r,s)\\,y_{i}$.\n-   Approximation basis on $\\widehat{K}$: $\\psi_{p,q}(r,s) = \\varphi_{p}(r)\\,\\varphi_{q}(s)$ for $p,q \\in \\{0,1,\\dots,P\\}$.\n-   One-dimensional basis functions: $\\varphi_{p}(r) = \\sqrt{\\frac{2p+1}{2}}\\,P_{p}(r)$, where $P_{p}$ is the Legendre polynomial of degree $p$.\n-   Orthonormality condition: $\\int_{-1}^{1}\\int_{-1}^{1} \\psi_{p,q}(r,s)\\,\\psi_{p',q'}(r,s)\\,dr\\,ds = \\delta_{p,p'}\\,\\delta_{q,q'}$.\n-   Local mass matrix definition: $M_{(p,q),(p',q')} = \\int_{K} \\psi_{p,q}(x,y)\\,\\psi_{p',q'}(x,y)\\,dA$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is a standard exercise in the computational theory of Discontinuous Galerkin (DG) methods. All provided definitions, including the shape functions, isoparametric mapping, and Legendre polynomial basis, are standard in the field of spectral and finite element methods. The problem is self-contained, with all necessary data and definitions provided. The vertices define a simple rectangle, which simplifies the Jacobian calculation, a common technique for illustrating fundamental principles. The question is objective, mathematically formalizable, and directly pertains to the specified topic. There are no scientific or factual unsoundness, contradictions, or ambiguities.\n\n### Step 3: Verdict and Action\nThe problem is deemed valid. A complete solution will be provided.\n\n### Solution Derivation\n\nThe solution proceeds in three parts as requested: computation of the mapping and Jacobian, transformation of the mass matrix integral, and evaluation of the integral, followed by an explanation of the result's significance.\n\n**1. Reference-to-Physical Mapping and Jacobian Determinant**\n\nThe isoparametric mapping from the reference coordinates $(r,s) \\in \\widehat{K}$ to the physical coordinates $(x,y) \\in K$ is constructed using the given shape functions and vertex coordinates.\n\nThe $x$-coordinate mapping is:\n$$\nx(r,s) = N_{1}(r,s)x_{1} + N_{2}(r,s)x_{2} + N_{3}(r,s)x_{3} + N_{4}(r,s)x_{4}\n$$\nSubstituting the vertex coordinates $(x_1, x_2, x_3, x_4) = (0, 2, 2, 0)$:\n$$\nx(r,s) = \\frac{1}{4}(1-r)(1-s)(0) + \\frac{1}{4}(1+r)(1-s)(2) + \\frac{1}{4}(1+r)(1+s)(2) + \\frac{1}{4}(1-r)(1+s)(0)\n$$\n$$\nx(r,s) = \\frac{1}{2}(1+r)(1-s) + \\frac{1}{2}(1+r)(1+s) = \\frac{1}{2}(1+r)[(1-s)+(1+s)] = \\frac{1}{2}(1+r)(2) = 1+r\n$$\n\nThe $y$-coordinate mapping is:\n$$\ny(r,s) = N_{1}(r,s)y_{1} + N_{2}(r,s)y_{2} + N_{3}(r,s)y_{3} + N_{4}(r,s)y_{4}\n$$\nSubstituting the vertex coordinates $(y_1, y_2, y_3, y_4) = (0, 0, 3, 3)$:\n$$\ny(r,s) = \\frac{1}{4}(1-r)(1-s)(0) + \\frac{1}{4}(1+r)(1-s)(0) + \\frac{1}{4}(1+r)(1+s)(3) + \\frac{1}{4}(1-r)(1+s)(3)\n$$\n$$\ny(r,s) = \\frac{3}{4}(1+r)(1+s) + \\frac{3}{4}(1-r)(1+s) = \\frac{3}{4}(1+s)[(1+r)+(1-r)] = \\frac{3}{4}(1+s)(2) = \\frac{3}{2}(1+s)\n$$\nThe explicit mapping is $(x(r,s), y(r,s)) = \\left(1+r, \\frac{3}{2}(1+s)\\right)$. This is an affine mapping.\n\nNext, we compute the Jacobian matrix of the transformation, $\\frac{\\partial(x,y)}{\\partial(r,s)}$:\n$$\n\\mathbf{J} =\n\\begin{pmatrix}\n\\frac{\\partial x}{\\partial r} & \\frac{\\partial x}{\\partial s} \\\\\n\\frac{\\partial y}{\\partial r} & \\frac{\\partial y}{\\partial s}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\frac{\\partial}{\\partial r}(1+r) & \\frac{\\partial}{\\partial s}(1+r) \\\\\n\\frac{\\partial}{\\partial r}\\left(\\frac{3}{2}(1+s)\\right) & \\frac{\\partial}{\\partial s}\\left(\\frac{3}{2}(1+s)\\right)\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 & 0 \\\\\n0 & \\frac{3}{2}\n\\end{pmatrix}\n$$\nThe Jacobian determinant, $J(r,s)$, is the determinant of this matrix:\n$$\nJ(r,s) = \\det(\\mathbf{J}) = (1)\\left(\\frac{3}{2}\\right) - (0)(0) = \\frac{3}{2}\n$$\nThe Jacobian determinant is constant because the mapping is affine (mapping a square to a rectangle). This constant represents the ratio of the physical element area to the reference element area: $\\text{Area}(K) / \\text{Area}(\\widehat{K}) = (2 \\times 3) / (2 \\times 2) = 6/4 = 3/2$.\n\n**2. Mass Matrix Integral Transformation**\n\nThe local mass matrix entry is defined as an integral over the physical element $K$:\n$$\nM_{(p,q),(p',q')} = \\int_{K} \\psi_{p,q}(x,y)\\,\\psi_{p',q'}(x,y)\\,dA\n$$\nThe basis functions $\\psi_{p,q}$ are defined on the reference element $\\widehat{K}$ in terms of $(r,s)$. We use the change of variables formula for integration, where the physical area element $dA$ is replaced by $J(r,s)\\,dr\\,ds$.\n$$\nM_{(p,q),(p',q')} = \\int_{\\widehat{K}} \\psi_{p,q}(r,s)\\,\\psi_{p',q'}(r,s)\\,J(r,s)\\,dr\\,ds\n$$\nSubstituting the calculated Jacobian determinant $J(r,s) = \\frac{3}{2}$:\n$$\nM_{(p,q),(p',q')} = \\int_{-1}^{1}\\int_{-1}^{1} \\psi_{p,q}(r,s)\\,\\psi_{p',q'}(r,s)\\,\\left(\\frac{3}{2}\\right)\\,dr\\,ds\n$$\n\n**3. Closed-Form Evaluation and Interpretation**\n\nSince the Jacobian determinant is a constant, it can be factored out of the integral:\n$$\nM_{(p,q),(p',q')} = \\frac{3}{2} \\int_{-1}^{1}\\int_{-1}^{1} \\psi_{p,q}(r,s)\\,\\psi_{p',q'}(r,s)\\,dr\\,ds\n$$\nThe problem statement provides the orthonormality property of the basis functions $\\psi_{p,q}$:\n$$\n\\int_{-1}^{1}\\int_{-1}^{1} \\psi_{p,q}(r,s)\\,\\psi_{p',q'}(r,s)\\,dr\\,ds = \\delta_{p,p'}\\,\\delta_{q,q'}\n$$\nwhere $\\delta_{i,j}$ is the Kronecker delta. Substituting this into the expression for the mass matrix entry yields the final closed-form result:\n$$\nM_{(p,q),(p',q')} = \\frac{3}{2}\\,\\delta_{p,p'}\\,\\delta_{q,q'}\n$$\nThis result indicates that the local mass matrix is a diagonal matrix. Specifically, it is $\\frac{3}{2}$ times the identity matrix.\n\n**Explanation of Computational Motivation and Advantage:**\n\nThis derivation illustrates a core computational advantage of the Discontinuous Galerkin method, particularly when using an orthogonal basis.\n\n1.  **Locality and Block-Diagonal Structure:** The mass matrix is computed on an element-by-element basis. In a global system assembled from many elements, the global mass matrix becomes block-diagonal, where each block is the local mass matrix of an element. There is no coupling between basis functions on different elements, hence the \"discontinuous\" nature of the approximation.\n\n2.  **Efficiency through Diagonalization:** The pivotal result here is that the local mass matrix is diagonal. For time-dependent problems, which are often solved with explicit time-stepping schemes (e.g., Runge-Kutta methods), a crucial step involves solving a linear system of the form $M\\dot{u} = F(u)$, which requires computing $M^{-1}F(u)$.\n    -   Because the global mass matrix $M$ is block-diagonal, its inverse $M^{-1}$ is also block-diagonal, where each block is the inverse of the corresponding local mass matrix. The inversion can be done locally on each element.\n    -   Crucially, since the local mass matrix itself is diagonal ($M_{\\text{local}} = cI$), its inverse is trivial to compute: $(M_{\\text{local}})^{-1} = (1/c)I$. In this specific problem, the inverse of any local mass matrix block is simply multiplication by $2/3$.\n    -   This avoids the need for a computationally expensive global linear solve at each time step, which would be necessary in continuous Galerkin methods where the global mass matrix is sparse but not block-diagonal. The DG method's mass matrix is thus \"explicit-friendly,\" leading to highly efficient and parallelizable algorithms.\n\nWhile the perfectly diagonal mass matrix occurs for affine elements and orthogonal bases, the block-diagonal global structure is a general feature of DG methods. For more complex, non-affine (curved) elements, the Jacobian is no longer constant, and the local mass matrix becomes dense. However, it is still a small matrix that can be inverted far more efficiently than a large global system matrix, preserving a significant computational advantage over continuous methods.", "answer": "$$\n\\boxed{\\frac{3}{2}\\delta_{p,p'}\\delta_{q,q'}}\n$$", "id": "3401227"}, {"introduction": "Moving beyond a single element, the essence of any Galerkin method is its weak formulation, which dictates how elements communicate. This practice challenges you to derive the complete bilinear form for the Symmetric Interior Penalty Galerkin (SIPG) method, a cornerstone of DG for diffusion problems [@problem_id:3401258]. By constructing the consistency and penalty terms, you will gain firsthand experience in the art of designing numerical fluxes that ensure both stability and accuracy.", "problem": "Consider the one-dimensional diffusion model problem on the open interval $\\Omega=(0,1)$,\n$$-u''=f \\quad \\text{in } \\Omega,$$\nwith Dirichlet boundary data $u(0)=g_{0}$ and $u(1)=g_{1}$. Let $\\mathcal{T}_{h}$ be a partition $0=x_{0}<x_{1}<\\dots<x_{N}=1$ of $\\Omega$ into $N$ open subintervals $K_{i}=(x_{i-1},x_{i})$ of lengths $h_{i}=x_{i}-x_{i-1}$. Let $V_{h}$ be a discontinuous finite-dimensional space of piecewise polynomials of degree at least $1$, defined elementwise on $\\mathcal{T}_{h}$. For any function $w$ that is piecewise smooth on $\\mathcal{T}_{h}$, define at each interior node $x_{i}$, $i=1,\\dots,N-1$, the trace values $w_{-}(x_{i})$ from the left element $K_{i}$ and $w_{+}(x_{i})$ from the right element $K_{i+1}$, and similarly $w'_{-}(x_{i})$ and $w'_{+}(x_{i})$. Define the jump and average operators\n$$[w]_{i} := w_{-}(x_{i}) - w_{+}(x_{i}), \\qquad \\{w'\\}_{i} := \\frac{1}{2}\\big(w'_{-}(x_{i}) + w'_{+}(x_{i})\\big), \\quad i=1,\\dots,N-1.$$\nLet the outward unit normal at the boundary be $n(0)=-1$ at $x=0$ and $n(1)=+1$ at $x=1$. Introduce face-based positive penalty parameters $\\gamma_{i}>0$ for each interior node $x_{i}$, $i=1,\\dots,N-1$, and boundary penalty parameters $\\gamma_{0}>0$ and $\\gamma_{1}>0$ at $x=0$ and $x=1$, respectively. Let the characteristic face length be defined by $h_{i}:=\\tfrac{1}{2}\\big(h_{i}+h_{i+1}\\big)$ at interior nodes $x_{i}$, $i=1,\\dots,N-1$, and by $h_{0}:=h_{1}$ and $h_{1}:=h_{N}$ at the boundary points.\n\nStarting from the elementwise Green’s identity and the requirement of symmetry and consistency in the Symmetric Interior Penalty Galerkin (SIPG) method, derive the bilinear form $a_{h}(\\cdot,\\cdot)$ on $V_{h}\\times V_{h}$ that weakly enforces the Dirichlet boundary conditions via consistency and penalty terms. Your derivation should make explicit the volume term, the interior face consistency and penalty terms involving jumps and averages, and the boundary consistency and penalty terms involving the outward normals. Express your final answer as a single closed-form analytic expression for $a_{h}(u_{h},v_{h})$ in terms of $u_{h}$, $v_{h}$, their broken derivatives, the jumps $[\\,\\cdot\\,]_{i}$, averages $\\{\\,\\cdot\\,\\}_{i}$, the outward normals $n(0)$ and $n(1)$, and the penalty parameters $\\gamma_{i}$, $\\gamma_{0}$, $\\gamma_{1}$ and face lengths $h_{i}$, $h_{0}$, $h_{1}$.\n\nThe final answer must be the bilinear form $a_{h}(u_{h},v_{h})$ as a single closed-form expression. No numerical evaluation is required.", "solution": "The problem asks for the derivation of the symmetric interior penalty Galerkin (SIPG) bilinear form $a_{h}(u_{h},v_{h})$ for a one-dimensional diffusion problem with Dirichlet boundary conditions. The derivation must be based on the elementwise Green’s identity and the principles of symmetry and consistency.\n\nFirst, we validate the problem statement.\n\n### Step 1: Extract Givens\n- **Differential Equation:** $-u''=f$ on $\\Omega=(0,1)$.\n- **Boundary Conditions:** $u(0)=g_{0}$, $u(1)=g_{1}$.\n- **Mesh:** A partition $\\mathcal{T}_{h}$ of $\\Omega$ into $N$ open subintervals $K_{i}=(x_{i-1},x_{i})$ with $0=x_{0}<x_{1}<\\dots<x_{N}=1$. The length of element $K_i$ is $h_i=x_i-x_{i-1}$.\n- **Finite Element Space:** $V_{h}$, a space of discontinuous piecewise polynomials of degree at least $1$.\n- **Trace Notation:** For a function $w$ piecewise smooth on $\\mathcal{T}_{h}$, at an interior node $x_i$, $w_{-}(x_{i})$ and $w_{+}(x_{i})$ are the left and right limits, respectively. Similarly for the derivative $w'$.\n- **Jump and Average Operators (at interior nodes $x_i, i=1,\\dots,N-1$):**\n  - Jump: $[w]_{i} := w_{-}(x_{i}) - w_{+}(x_{i})$\n  - Average of derivative: $\\{w'\\}_{i} := \\frac{1}{2}\\big(w'_{-}(x_{i}) + w'_{+}(x_{i})\\big)$\n- **Outward Normals:** $n(0)=-1$ at $x=0$ and $n(1)=+1$ at $x=1$.\n- **Penalty Parameters:** $\\gamma_{i}>0$ for interior nodes $x_{i}$ ($i=1,\\dots,N-1$), and $\\gamma_{0}>0$, $\\gamma_{1}>0$ for boundary points $x=0$ and $x=1$.\n- **Characteristic Face Lengths:** $h_{i}:=\\tfrac{1}{2}\\big(h_{i}+h_{i+1}\\big)$ at $x_{i}$ ($i=1,\\dots,N-1$), $h_{0}:=h_{1}$ at $x=0$, and $h_{1}:=h_{N}$ at $x=1$. The problem statement uses $h_i$ to denote both element length and face length, a notational ambiguity. We interpret the latter as a re-definition for face-associated quantities.\n\n### Step 2: Validate Using Extracted Givens\nThe problem describes the standard setup for deriving the SIPG method, a well-established numerical method for partial differential equations. All components are standard in the literature of Discontinuous Galerkin (DG) methods.\n- **Scientifically Grounded:** The problem is based on the mathematical theory of finite element methods, which is a rigorous and well-established field. No scientific flaws are present.\n- **Well-Posed:** The task is to derive a specific mathematical expression based on given principles. A unique form for the SIPG bilinear form exists and the derivation is a standard procedure.\n- **Objective:** The language is formal and precise.\n\nThe notational choice of using $h_i$ for both element length and a newly defined \"face length\" is potentially confusing but does not constitute a fatal flaw, as the context distinguishes their use. The problem is deemed valid.\n\n### Derivation of the Bilinear Form\n\nThe derivation begins by formulating a weak form of the equation $-u''=f$. We multiply by a test function $v_h \\in V_h$ and integrate over each element $K_i=(x_{i-1}, x_i)$:\n$$ -\\int_{K_i} u'' v_h \\,dx = \\int_{K_i} f v_h \\,dx $$\n\nApplying Green's identity (integration by parts) to the left-hand side on each element $K_i$ yields:\n$$ \\int_{K_i} u' v_h' \\,dx - \\left[ u' v_h \\right]_{x_{i-1}}^{x_i} = \\int_{K_i} f v_h \\,dx $$\nwhere $\\left[ u' v_h \\right]_{x_{i-1}}^{x_i} = u'(x_i)v_h(x_i) - u'(x_{i-1})v_h(x_{i-1})$. Here, the values are the interior traces from within $K_i$, i.e., $u'_-(x_i)v_{h,-}(x_i) - u'_+(x_{i-1})v_{h,+}(x_{i-1})$.\n\nSumming over all elements $i=1, \\dots, N$:\n$$ \\sum_{i=1}^N \\int_{K_i} u' v_h' \\,dx - \\sum_{i=1}^N \\left( u'_-(x_i)v_{h,-}(x_i) - u'_+(x_{i-1})v_{h,+}(x_{i-1}) \\right) = \\sum_{i=1}^N \\int_{K_i} f v_h \\,dx $$\nThe right-hand side is simply the $L^2$ inner product $(f, v_h)_{\\mathcal{T}_h}$. The sum of boundary terms can be rearranged into a sum over interior faces and a term on the boundary $\\partial\\Omega$:\n$$ \\sum_{i=1}^N \\left( u'_-(x_i)v_{h,-}(x_i) - u'_+(x_{i-1})v_{h,+}(x_{i-1}) \\right) = \\sum_{i=1}^{N-1} \\left( u'_-(x_i)v_{h,-}(x_i) - u'_+(x_i)v_{h,+}(x_i) \\right) + u'_-(x_N)v_{h,-}(x_N) - u'_+(x_0)v_{h,+}(x_0) $$\nUsing the jump and average definitions given, and the identity $a_- b_- - a_+ b_+ = \\{a\\}[b] + [a]\\{b\\}$, the sum over interior faces ($x_i$ for $i=1,\\dots,N-1$) becomes:\n$$ \\sum_{i=1}^{N-1} \\left( \\{u'\\}_i [v_h]_i + [u']_i \\{v_h\\}_i \\right) $$\nThe boundary terms are at $x_N=1$ and $x_0=0$. Using the outward normals $n(1)=1$ and $n(0)=-1$, we can write $u'_-(1)v_{h,-}(1) - u'_+(0)v_{h,+}(0)$ as $(u'v_h n)(1) + (u'v_h n)(0)$.\n\nThus, for the exact solution $u$, we have the identity:\n$$ \\sum_{i=1}^N \\int_{K_i} u' v_h' \\,dx - \\sum_{i=1}^{N-1} \\left( \\{u'\\}_i [v_h]_i + [u']_i \\{v_h\\}_i \\right) - \\big( (u' v_h n)(1) + (u' v_h n)(0) \\big) = (f, v_h)_{\\mathcal{T}_h} $$\n\nThe SIPG bilinear form $a_h(u_h, v_h)$ is constructed for discrete functions $u_h, v_h \\in V_h$ based on this identity, with modifications to ensure symmetry and to weakly enforce boundary conditions.\n\n1.  **Volume Term:** The volume integral is naturally symmetric.\n    $$ \\sum_{i=1}^N \\int_{K_i} u_h' v_h' \\,dx $$\n\n2.  **Interior Face Terms:** The interior face term from the identity, $- (\\{u_h'\\}_i [v_h]_i + [u_h']_i \\{v_h\\}_i)$, is not symmetric. To enforce symmetry, we construct a symmetric consistency term:\n    $$ -\\sum_{i=1}^{N-1} \\left( \\{u_h'\\}_i [v_h]_i + \\{v_h'\\}_i [u_h]_i \\right) $$\n    For consistency, if $u$ is the smooth solution, $[u]_i = 0$, and this term reduces to $-\\sum \\{u'\\}_i [v_h]_i$, which matches the identity (since $[u']_i=0$).\n    To ensure stability (coercivity), a symmetric and positive-definite penalty term is added, which penalizes the jump in the solution:\n    $$ +\\sum_{i=1}^{N-1} \\gamma_i [u_h]_i [v_h]_i $$\n\n3.  **Boundary Face Terms:** The boundary conditions $u(0)=g_0$ and $u(1)=g_1$ are enforced weakly. Following the same principle as for interior faces, we introduce consistency and penalty terms. The boundary term from the identity is $- ((u_h'v_h n)(1) + (u_h'v_h n)(0))$. To make this symmetric and incorporate the solution value $u_h$, we define the consistency terms as:\n    $$ - \\left( (u_h' v_h n)(1) + (v_h' u_h n)(1) \\right) - \\left( (u_h' v_h n)(0) + (v_h' u_h n)(0) \\right) $$\n    Expanding with $n(1)=1$ and $n(0)=-1$:\n    $$ - (u_h'v_h + v_h'u_h)\\big|_{x=1} + (u_h'v_h + v_h'u_h)\\big|_{x=0} $$\n    The boundary penalty term is added to enforce the Dirichlet data:\n    $$ +\\gamma_1 u_h(1) v_h(1) + \\gamma_0 u_h(0) v_h(0) $$\n    The data $g_0, g_1$ appear in the linear form $L_h(v_h)$, not the bilinear form $a_h(u_h, v_h)$.\n\nCombining all these terms gives the full expression for the bilinear form $a_h(u_h, v_h)$. All trace values $u_h(x)$, $u_h'(x)$ at boundaries are single-sided (e.g., $u_h(1) = u_{h,-}(1)$ and $u_h(0) = u_{h,+}(0)$).\n\nIt is noted that the characteristic face lengths $h_{i}$, $h_{0}$, $h_{1}$ do not explicitly appear in the derived bilinear form. In the theory of DG methods, these lengths are typically used to define the magnitude of the penalty parameters $\\gamma_{i}$, $\\gamma_{0}$, $\\gamma_{1}$ to ensure stability, usually with $\\gamma \\propto 1/h$. Since the problem defines $\\gamma$ as the penalty parameter itself, the face lengths are implicitly encapsulated within these parameters and do not appear as separate terms in the general expression for $a_h(\\cdot, \\cdot)$.\n\nThe final bilinear form is the sum of the volume, interior face, and boundary face contributions.\n$$ a_{h}(u_{h},v_{h}) = \\sum_{i=1}^{N} \\int_{K_{i}} u'_{h} v'_{h} \\,dx - \\sum_{i=1}^{N-1} \\left( \\{u'_{h}\\}_{i} [v_{h}]_{i} + \\{v'_{h}\\}_{i} [u_{h}]_{i} \\right) + \\sum_{i=1}^{N-1} \\gamma_{i} [u_{h}]_{i} [v_{h}]_{i} \\\\ - \\Big( u'_{h} v_{h} + v'_{h} u_{h} \\Big)\\Big|_{x=1} + \\Big( u'_{h} v_{h} + v'_{h} u_{h} \\Big)\\Big|_{x=0} + \\gamma_{1} u_h(1) v_h(1) + \\gamma_{0} u_h(0) v_h(0) $$\nThis can be written more compactly using the given outward normals $n(1)=1$ and $n(0)=-1$.\n$$ \\Big( u'_{h} v_{h} + v'_{h} u_{h} \\Big)\\Big|_{x=1} = \\Big( u'_{h} v_{h} + v'_{h} u_{h} \\Big)\\Big|_{x=1} n(1) $$\n$$ -\\Big( u'_{h} v_{h} + v'_{h} u_{h} \\Big)\\Big|_{x=0} = \\Big( u'_{h} v_{h} + v'_{h} u_{h} \\Big)\\Big|_{x=0} n(0) $$\nWhich gives the final closed-form expression.", "answer": "$$\n\\boxed{\na_{h}(u_{h},v_{h}) = \\sum_{i=1}^{N} \\int_{K_{i}} u'_{h} v'_{h} \\,dx - \\sum_{i=1}^{N-1} \\left( \\{u'_{h}\\}_{i} [v_{h}]_{i} + \\{v'_{h}\\}_{i} [u_{h}]_{i} \\right) + \\sum_{i=1}^{N-1} \\gamma_{i} [u_{h}]_{i} [v_{h}]_{i} - \\sum_{x \\in \\{0,1\\}} \\left( u'_{h}v_{h}n + v'_{h}u_{h}n \\right) + \\gamma_{1} u_h(1)v_h(1) + \\gamma_{0} u_h(0)v_h(0)\n}\n$$", "id": "3401258"}, {"introduction": "One of the most remarkable advantages of DG methods is the hidden accuracy within their numerical solutions, which can be unlocked through post-processing. This exercise explores the concept of Smoothness-Increasing Accuracy-Conserving (SIAC) filtering, a technique that can dramatically improve the solution's precision [@problem_id:3401253]. By analyzing the theoretical underpinnings of this method, you will see how a simple convolution can elevate the convergence rate, showcasing the deep structure of the DG approximation error.", "problem": "Consider the linear advection equation $u_{t} + a\\,u_{x} = 0$ on the one-dimensional torus $\\mathbb{T} = \\mathbb{R}/\\mathbb{Z}$, with smooth $1$-periodic initial data $u(x,0) = u_{0}(x)$ and constant advection speed $a > 0$. Let $u_{h}$ denote the semi-discrete Discontinuous Galerkin (DG) approximation using degree-$p$ piecewise polynomials on a uniform mesh of size $h$, with an upwind numerical flux. You are told that $p=1$ and that the solution remains smooth for $t \\in [0,T]$. After computing $u_{h}(\\cdot,T)$, you perform a Smoothness-Increasing Accuracy-Conserving (SIAC) postprocessing defined as follows.\n\nDefine a compactly supported kernel $K:\\mathbb{R}\\to\\mathbb{R}$ as a linear combination of integer translates of the univariate B-spline of order $p+1$, chosen so that $K$ exactly reproduces polynomials up to degree $2p$ in the sense of the Strang–Fix conditions: for every polynomial $q$ with $\\deg(q)\\le 2p$, one has $\\int_{\\mathbb{R}} K(x)\\,q(x)\\,dx = q(0)$. For $h>0$, define the scaled kernel $K_{h}(x) = h^{-1}K(x/h)$ and the postprocessed solution $\\widetilde{u}_{h}(\\cdot,T)$ by the convolution $\\widetilde{u}_{h}(x,T) = \\int_{\\mathbb{T}} K_{h}(x-y)\\,u_{h}(y,T)\\,dy$, where the integral is interpreted periodically. Assume that the mesh is uniform, the coefficients in the kernel are symmetric so that $K$ is even, and that the convolution is implemented exactly on the piecewise polynomial $u_{h}$.\n\nStarting from fundamental approximation principles for convolution with reproduction kernels and the structure of DG discretizations on uniform meshes, outline the steps required to apply the SIAC filter in this setting and derive the asymptotic order of convergence in the $L^{2}(\\mathbb{T})$-norm of the postprocessed error $\\|\\widetilde{u}_{h}(\\cdot,T) - u(\\cdot,T)\\|_{L^{2}(\\mathbb{T})}$ as a function of $p$. Then, specialize your result to the given case $p=1$ and provide the predicted convergence rate as a single number. No rounding is required. Your final answer must be the numerical value of this predicted rate.", "solution": "The problem requires an analysis of the convergence properties of a Smoothness-Increasing Accuracy-Conserving (SIAC) post-processing method applied to a Discontinuous Galerkin (DG) numerical solution of the linear advection equation. We must first outline the theoretical basis for the enhanced accuracy and then derive the specific convergence rate for the given parameters.\n\nThe problem statement has been validated and is deemed to be scientifically sound, well-posed, and internally consistent. It describes a standard scenario in the numerical analysis of DG methods. We may proceed with the solution.\n\nLet $u(x,t)$ be the exact solution to the linear advection equation $u_{t} + a\\,u_{x} = 0$ on the one-dimensional torus $\\mathbb{T}$, with $a > 0$ and smooth initial data $u_0(x)$. Let $u_{h}(x,t)$ be the semi-discrete DG approximation using piecewise polynomials of degree $p$ on a uniform mesh of size $h$. The problem states that the solution remains smooth for $t \\in [0,T]$. The standard optimal error estimate for this DG approximation in the $L^{2}(\\mathbb{T})$-norm is\n$$\n\\|u(\\cdot,T) - u_{h}(\\cdot,T)\\|_{L^{2}(\\mathbb{T})} = O(h^{p+1})\n$$\nThe post-processed solution $\\widetilde{u}_{h}$ at time $T$ is defined by the periodic convolution with a scaled kernel $K_{h}(x) = h^{-1}K(x/h)$:\n$$\n\\widetilde{u}_{h}(x,T) = (K_{h} \\star u_{h})(x,T) = \\int_{\\mathbb{T}} K_{h}(x-y)\\,u_{h}(y,T)\\,dy\n$$\nOur goal is to determine the asymptotic order of convergence of the post-processed error, $\\|\\widetilde{u}_{h}(\\cdot,T) - u(\\cdot,T)\\|_{L^{2}(\\mathbb{T})}$, as $h \\to 0$.\n\nWe begin by decomposing the error using the triangle inequality:\n$$\n\\|\\widetilde{u}_{h} - u\\|_{L^{2}} = \\|K_{h} \\star u_{h} - u\\|_{L^{2}} \\le \\|K_{h} \\star u_{h} - K_{h} \\star u\\|_{L^{2}} + \\|K_{h} \\star u - u\\|_{L^{2}}\n$$\nLet us analyze the two terms on the right-hand side separately.\n\nThe second term, $\\|K_{h} \\star u - u\\|_{L^{2}}$, represents the approximation error of the convolution operator itself when applied to the exact solution $u$. The properties of the kernel $K$ are crucial here. The problem states that $K$ reproduces polynomials up to degree $2p$, meaning it satisfies the Strang-Fix conditions of order $2p+1$. That is, for any polynomial $q(x)$ with $\\deg(q) \\le 2p$, we have $\\int_{\\mathbb{R}} K(x)\\,q(x)\\,dx = q(0)$. A standard result in approximation theory states that for a sufficiently smooth function $u$ (which is given), the error of convolution with such a scaled kernel is determined by the order of the Strang-Fix conditions. Specifically, the error is of order $2p+1$.\n$$\n\\|K_{h} \\star u - u\\|_{L^{2}(\\mathbb{T})} = O(h^{2p+1})\n$$\nThis high order of accuracy is expected, as the kernel is explicitly designed for this purpose.\n\nThe first term, $\\|K_{h} \\star u_{h} - K_{h} \\star u\\|_{L^{2}}$, can be written as $\\|K_{h} \\star (u_{h} - u)\\|_{L^{2}}$. This term represents the effect of the convolution filter on the DG error $e_{h} = u_{h} - u$. By Young's inequality for convolutions, we know that $\\|K_{h} \\star e_{h}\\|_{L^{2}} \\le \\|K_{h}\\|_{L^{1}} \\|e_{h}\\|_{L^{2}}$. Since $\\|K_{h}\\|_{L^{1}} = \\|K\\|_{L^{1}} = \\text{const}$ (and is typically normalized to $1$), this bound would only give $\\|K_{h} \\star e_{h}\\|_{L^{2}} = O(h^{p+1})$, which shows no improvement.\n\nHowever, this is where the special structure of the DG error on uniform meshes for linear hyperbolic problems becomes critical. This is the cornerstone of SIAC post-processing for DG methods. The error $e_{h} = u_{h} - u$ is not a generic function of size $O(h^{p+1})$. Instead, it exhibits a form of structured oscillation and superconvergence properties. For a translation-invariant problem set up on a uniform grid, the DG error, while large in the $L^2$-norm, is nearly orthogonal to low-degree polynomials on each element in a specific sense.\n\nThe theory of SIAC post-processing, originally developed by Bramble and Schatz and later adapted to DG methods by Cockburn, Shu, and others, demonstrates that the convolution with a suitably chosen kernel $K$ effectively filters out the dominant, oscillatory components of the DG error. The kernel is designed not only to approximate smooth functions well but also to annihilate the leading-order error terms of the DG solution. The result of this analysis, which can be rigorously proven using Fourier analysis on the periodic domain or via properties of quasi-interpolants, is that the convolved DG error is also of high order.\n$$\n\\|K_{h} \\star (u_{h} - u)\\|_{L^{2}(\\mathbb{T})} = O(h^{2p+1})\n$$\nThis phenomenon, where the convolved error has a higher convergence rate than the original error, is precisely why the method is \"accuracy-conserving\" (or, more accurately, accuracy-enhancing). This result relies on all the assumptions given: a linear, constant-coefficient PDE, a uniform mesh, a properly designed kernel $K$, and a sufficiently smooth exact solution.\n\nCombining the two error bounds, we have:\n$$\n\\|\\widetilde{u}_{h} - u\\|_{L^{2}(\\mathbb{T})} \\le O(h^{2p+1}) + O(h^{2p+1}) = O(h^{2p+1})\n$$\nThus, the asymptotic order of convergence for the post-processed solution is $2p+1$. This is a significant improvement over the underlying DG scheme's convergence rate of $p+1$.\n\nThe problem specifies the use of degree-$p$ piecewise polynomials with $p=1$. To find the predicted convergence rate, we substitute $p=1$ into our derived formula for the order of convergence.\nThe convergence rate is $2p+1$.\nFor $p=1$, the rate is $2(1)+1 = 3$.\nSo, we predict that the $L^{2}$-norm of the post-processed error will converge to zero as $O(h^3)$, meaning the convergence rate is $3$.", "answer": "$$\\boxed{3}$$", "id": "3401253"}]}