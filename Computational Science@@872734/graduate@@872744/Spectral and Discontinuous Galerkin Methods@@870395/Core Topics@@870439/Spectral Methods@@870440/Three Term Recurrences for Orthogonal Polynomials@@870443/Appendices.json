{"hands_on_practices": [{"introduction": "The theory of orthogonal polynomials is not limited to continuous weight functions on an interval; it is just as powerful when applied to discrete data sets. This practice demonstrates how to numerically construct orthogonal polynomials and their recurrence coefficients with respect to a discrete inner product defined by a finite set of points, a common scenario in experimental science and numerical methods. By working through this example [@problem_id:2192741], you will build a solid, tangible intuition for how the abstract formulas for the recurrence coefficients, $\\alpha_k$ and $\\beta_k$, translate into a direct computational algorithm.", "problem": "In the numerical analysis of experimental data, it is often advantageous to work with a basis of functions that are orthogonal with respect to the data points. Consider a set of four experimental measurements at coordinates $\\{x_i\\} = \\{0, 1, 3, 6\\}$. We are interested in generating a sequence of monic polynomials $\\{p_k(x)\\}_{k=0}^\\infty$ that are orthogonal with respect to a discrete inner product.\n\nThe inner product of two real-valued functions, $f(x)$ and $g(x)$, over this set of points is defined as:\n$$ \\langle f, g \\rangle = \\sum_{i=1}^{4} f(x_i) g(x_i) $$\nThe sequence of orthogonal monic polynomials is generated by the three-term recurrence relation:\n$$ p_{k+1}(x) = (x - \\alpha_k) p_k(x) - \\beta_k p_{k-1}(x) $$\nfor $k \\ge 0$, with the initial conditions defined as $p_0(x) = 1$ and $p_{-1}(x) = 0$.\n\nYour task is to determine the exact value of the recurrence coefficient $\\alpha_1$. Express your final answer as a fraction in simplest form.", "solution": "We use the given discrete inner product\n$$\\langle f, g \\rangle = \\sum_{i=1}^{4} f(x_{i}) g(x_{i}), \\quad \\{x_{i}\\}=\\{0,1,3,6\\},$$\nand the monic three-term recurrence\n$$p_{k+1}(x)=(x-\\alpha_{k})p_{k}(x)-\\beta_{k}p_{k-1}(x), \\quad p_{0}(x)=1,\\; p_{-1}(x)=0.$$\n\nFor monic orthogonal polynomials, taking the inner product of the recurrence with $p_{k}$ yields\n$$\\langle p_{k+1},p_{k}\\rangle=\\langle (x-\\alpha_{k})p_{k},p_{k}\\rangle-\\beta_{k}\\langle p_{k-1},p_{k}\\rangle.$$\nBy orthogonality, $\\langle p_{k+1},p_{k}\\rangle=0$ and $\\langle p_{k-1},p_{k}\\rangle=0$, hence\n$$0=\\langle x p_{k},p_{k}\\rangle-\\alpha_{k}\\langle p_{k},p_{k}\\rangle,$$\nso\n$$\\alpha_{k}=\\frac{\\langle x p_{k},p_{k}\\rangle}{\\langle p_{k},p_{k}\\rangle}.$$\n\nFirst, compute $\\alpha_{0}$:\n$$\\alpha_{0}=\\frac{\\langle x p_{0},p_{0}\\rangle}{\\langle p_{0},p_{0}\\rangle}\n=\\frac{\\sum_{i=1}^{4} x_{i}}{\\sum_{i=1}^{4} 1}\n=\\frac{0+1+3+6}{4}\n=\\frac{10}{4}\n=\\frac{5}{2}.$$\nThus\n$$p_{1}(x)=x-\\alpha_{0}=x-\\frac{5}{2}.$$\n\nNow compute $\\alpha_{1}$ using\n$$\\alpha_{1}=\\frac{\\langle x p_{1},p_{1}\\rangle}{\\langle p_{1},p_{1}\\rangle}\n=\\frac{\\sum_{i=1}^{4} x_{i}\\,p_{1}(x_{i})^{2}}{\\sum_{i=1}^{4} p_{1}(x_{i})^{2}}.$$\nEvaluate $p_{1}(x)$ at the data points:\n$$p_{1}(0)=-\\frac{5}{2},\\quad p_{1}(1)=-\\frac{3}{2},\\quad p_{1}(3)=\\frac{1}{2},\\quad p_{1}(6)=\\frac{7}{2}.$$\nSquares:\n$$p_{1}(0)^{2}=\\frac{25}{4},\\quad p_{1}(1)^{2}=\\frac{9}{4},\\quad p_{1}(3)^{2}=\\frac{1}{4},\\quad p_{1}(6)^{2}=\\frac{49}{4}.$$\nDenominator:\n$$\\langle p_{1},p_{1}\\rangle=\\frac{25}{4}+\\frac{9}{4}+\\frac{1}{4}+\\frac{49}{4}=\\frac{84}{4}=21.$$\nNumerator:\n$$\\langle x p_{1},p_{1}\\rangle=0\\cdot\\frac{25}{4}+1\\cdot\\frac{9}{4}+3\\cdot\\frac{1}{4}+6\\cdot\\frac{49}{4}\n=\\frac{9}{4}+\\frac{3}{4}+\\frac{294}{4}=\\frac{306}{4}=\\frac{153}{2}.$$\nTherefore\n$$\\alpha_{1}=\\frac{\\frac{153}{2}}{21}=\\frac{153}{42}=\\frac{51}{14}.$$\nThis fraction is already in simplest form.", "answer": "$$\\boxed{\\frac{51}{14}}$$", "id": "2192741"}, {"introduction": "After building recurrence coefficients from discrete data, we now turn to one of the most important continuous cases: the Legendre polynomials. This exercise [@problem_id:3423659] challenges you to derive their famous three-term recurrence relation from first principles, starting with the Rodrigues formula and the definition of orthogonality. Mastering this derivation provides a deep understanding of the theoretical machinery behind classical orthogonal polynomials and demonstrates the process of converting them to the monic form used in constructing Jacobi matrices.", "problem": "Consider the family of Legendre polynomials $\\{P_n(x)\\}_{n=0}^{\\infty}$ on the interval $[-1,1]$ with weight function $w(x)=1$. Use only fundamental definitions and properties of orthogonal polynomials to complete the following tasks.\n\n1. Starting from the Rodrigues formula $P_n(x)=\\dfrac{1}{2^n n!}\\dfrac{d^n}{dx^n}\\left(x^2-1\\right)^n$ and the fact that $\\{P_n\\}$ is orthogonal with respect to the inner product $\\langle f,g\\rangle=\\int_{-1}^{1}f(x)g(x)\\,dx$, derive the three-term recurrence relation that expresses $P_{n+1}(x)$ as a linear combination of $xP_n(x)$ and $P_{n-1}(x)$ for all integers $n\\geq 1$. Do not use any pre-established recurrence; your derivation must proceed from the Rodrigues formula and the stated orthogonality structure.\n\n2. Define the monic Legendre polynomials $\\{p_n(x)\\}_{n=0}^{\\infty}$ by $p_n(x)=\\kappa_n P_n(x)$, where $\\kappa_n$ is chosen so that the leading coefficient of $p_n(x)$ is $1$. Determine $\\kappa_n$ explicitly.\n\n3. Rewrite the recurrence from part 1 in the monic form $p_{n+1}(x)=\\left(x-\\alpha_n\\right)p_n(x)-\\beta_n p_{n-1}(x)$ and identify the recurrence coefficients $\\alpha_n$ and $\\beta_n$ as closed-form analytic expressions in $n$.\n\nExpress your final answer for the ordered pair $(\\alpha_n,\\beta_n)$ as a single row matrix. No numerical approximation is required.", "solution": "The problem is found to be valid as it is scientifically grounded, well-posed, and objective. It concerns fundamental properties of Legendre polynomials, and the derivation requested is a standard, albeit non-trivial, exercise in mathematical physics. All necessary information is provided.\n\nThe solution is presented in three parts as requested by the problem statement.\n\n**Part 1: Derivation of the three-term recurrence relation**\n\nLet $\\{P_n(x)\\}_{n=0}^{\\infty}$ be the family of Legendre polynomials, orthogonal on the interval $[-1, 1]$ with respect to the weight function $w(x)=1$. The inner product is $\\langle f, g \\rangle = \\int_{-1}^{1} f(x)g(x) \\, dx$.\nThe polynomial $xP_n(x)$ has degree $n+1$, so it can be expressed as a linear combination of the basis polynomials $\\{P_k(x)\\}$:\n$$xP_n(x) = \\sum_{k=0}^{n+1} c_k P_k(x)$$\nwhere the coefficients are given by $c_k = \\frac{\\langle xP_n, P_k \\rangle}{\\langle P_k, P_k \\rangle}$.\nBy the property of the inner product, $\\langle xP_n, P_k \\rangle = \\langle P_n, xP_k \\rangle$. Since $xP_k(x)$ is a polynomial of degree $k+1$, by the orthogonality of Legendre polynomials, this inner product is zero if $k+1  n$, i.e., $k  n-1$.\nThus, only the coefficients $c_{n+1}$, $c_n$, and $c_{n-1}$ can be non-zero. The expansion simplifies to:\n$$xP_n(x) = c_{n+1}P_{n+1}(x) + c_n P_n(x) + c_{n-1}P_{n-1}(x)$$\nThe coefficient $c_n$ is given by $c_n = \\frac{\\langle xP_n, P_n \\rangle}{\\langle P_n, P_n \\rangle}$. The integral in the numerator is $\\int_{-1}^{1} x [P_n(x)]^2 \\, dx$. The parity of a Legendre polynomial is $P_n(-x) = (-1)^n P_n(x)$. Therefore, $[P_n(-x)]^2 = ((-1)^n P_n(x))^2 = [P_n(x)]^2$, which means $[P_n(x)]^2$ is an even function for all $n$. The term $x$ is an odd function. The product $x[P_n(x)]^2$ is an odd function. The integral of an odd function over the symmetric interval $[-1, 1]$ is zero. Thus, $\\langle xP_n, P_n \\rangle = 0$, which implies $c_n=0$.\nThe recurrence becomes:\n$$xP_n(x) = c_{n+1} P_{n+1}(x) + c_{n-1} P_{n-1}(x)$$\nTo find the coefficients $c_{n+1}$ and $c_{n-1}$, we first determine the leading coefficient of $P_n(x)$ from the Rodrigues formula, $P_n(x) = \\frac{1}{2^n n!} \\frac{d^n}{dx^n} (x^2-1)^n$.\nThe term $(x^2-1)^n$ is a polynomial whose term of highest degree is $x^{2n}$.\nThe $n$-th derivative of $x^{2n}$ is $\\frac{d^n}{dx^n}x^{2n} = (2n)(2n-1)\\cdots(n+1)x^n = \\frac{(2n)!}{n!}x^n$.\nThe leading coefficient of $P_n(x)$, which we denote by $k_n$, is therefore:\n$$k_n = \\frac{1}{2^n n!} \\frac{(2n)!}{n!} = \\frac{(2n)!}{2^n (n!)^2}$$\nBy comparing the leading coefficients in the recurrence $xP_n(x) = c_{n+1}P_{n+1}(x) + c_{n-1}P_{n-1}(x)$:\n$k_n = c_{n+1} k_{n+1}$. This gives $c_{n+1} = \\frac{k_n}{k_{n+1}}$.\n$$ \\frac{k_n}{k_{n+1}} = \\frac{(2n)!}{2^n (n!)^2} \\left/ \\frac{(2(n+1))!}{2^{n+1} ((n+1)!)^2} \\right. = \\frac{(2n)!}{2^n (n!)^2} \\frac{2^{n+1} (n+1)^2 (n!)^2}{(2n+2)!} = \\frac{2(n+1)^2}{(2n+2)(2n+1)} = \\frac{n+1}{2n+1} $$\nSo, $c_{n+1} = \\frac{n+1}{2n+1}$.\n\nNext, we find $c_{n-1} = \\frac{\\langle xP_n, P_{n-1} \\rangle}{\\langle P_{n-1}, P_{n-1} \\rangle} = \\frac{\\langle P_n, xP_{n-1} \\rangle}{\\langle P_{n-1}, P_{n-1} \\rangle}$.\nThe polynomial $xP_{n-1}(x)$ is of degree $n$, and its leading coefficient is $k_{n-1}$. We can write $xP_{n-1}(x) = \\frac{k_{n-1}}{k_n}P_n(x) + (\\text{terms of degree }n)$.\nTherefore, $\\langle P_n, xP_{n-1} \\rangle = \\frac{k_{n-1}}{k_n} \\langle P_n, P_n \\rangle$.\nThe coefficient $c_{n-1}$ is then $c_{n-1} = \\frac{k_{n-1}}{k_n} \\frac{\\langle P_n, P_n \\rangle}{\\langle P_{n-1}, P_{n-1} \\rangle}$.\nTo proceed, we must derive the squared norm $\\langle P_n, P_n \\rangle = \\int_{-1}^{1} [P_n(x)]^2 \\, dx$.\n$\\langle P_n, P_n \\rangle = \\langle P_n, k_n x^n + \\dots \\rangle = k_n \\langle P_n, x^n \\rangle$, since $P_n$ is orthogonal to all polynomials of degree less than $n$.\nWe evaluate $\\langle P_n, x^n \\rangle = \\int_{-1}^1 x^n P_n(x) \\, dx$ using the Rodrigues formula and integration by parts $n$ times.\n$$ \\langle P_n, x^n \\rangle = \\frac{1}{2^n n!} \\int_{-1}^1 x^n \\left(\\frac{d^n}{dx^n} (x^2-1)^n\\right) dx $$\nEach integration by parts introduces a minus sign and reduces the order of the derivative on $(x^2-1)^n$, while differentiating $x^n$. The boundary terms vanish at each step because derivatives of $(x^2-1)^n$ up to order $n-1$ are zero at $x=\\pm 1$. After $n$ steps:\n$$ \\langle P_n, x^n \\rangle = \\frac{(-1)^n}{2^n n!} \\int_{-1}^1 \\left(\\frac{d^n}{dx^n} x^n\\right) (x^2-1)^n dx = \\frac{(-1)^n n!}{2^n n!} \\int_{-1}^1 (x^2-1)^n dx = \\frac{1}{2^n} \\int_{-1}^1 (1-x^2)^n dx $$\nThe integral is evaluated by substitution $x=\\sin\\theta$, $dx=\\cos\\theta d\\theta$:\n$$ \\int_{-1}^1 (1-x^2)^n dx = \\int_{-\\pi/2}^{\\pi/2} (\\cos^2\\theta)^n \\cos\\theta d\\theta = 2 \\int_0^{\\pi/2} \\cos^{2n+1}\\theta d\\theta $$\nThis is a standard Wallis integral, whose value is $2\\frac{(2n)!!}{(2n+1)!!} = 2 \\frac{2^n n!}{(2n+1)!!} = \\frac{2^{2n+1}(n!)^2}{(2n+1)!}$.\nSo, $\\langle P_n, x^n \\rangle = \\frac{1}{2^n} \\frac{2^{2n+1}(n!)^2}{(2n+1)!} = \\frac{2^{n+1}(n!)^2}{(2n+1)!}$.\nNow, we find the norm:\n$$ \\langle P_n, P_n \\rangle = k_n \\langle P_n, x^n \\rangle = \\frac{(2n)!}{2^n (n!)^2} \\frac{2^{n+1}(n!)^2}{(2n+1)!} = \\frac{2}{2n+1} $$\nUsing this, $\\frac{\\langle P_n, P_n \\rangle}{\\langle P_{n-1}, P_{n-1} \\rangle} = \\frac{2/(2n+1)}{2/(2(n-1)+1)} = \\frac{2n-1}{2n+1}$.\nThe ratio of leading coefficients $k_{n-1}/k_n$ can be found from $k_n/k_{n+1} = (n+1)/(2n+1)$. Replacing $n$ with $n-1$ gives $k_{n-1}/k_n=n/(2n-1)$.\nSubstituting into the expression for $c_{n-1}$:\n$$ c_{n-1} = \\frac{k_{n-1}}{k_n} \\frac{\\langle P_n, P_n \\rangle}{\\langle P_{n-1}, P_{n-1} \\rangle} = \\frac{n}{2n-1} \\frac{2n-1}{2n+1} = \\frac{n}{2n+1} $$\nThe recurrence relation is $xP_n(x) = \\frac{n+1}{2n+1} P_{n+1}(x) + \\frac{n}{2n+1} P_{n-1}(x)$.\nSolving for $P_{n+1}(x)$:\n$$ (n+1)P_{n+1}(x) = (2n+1)xP_n(x) - nP_{n-1}(x) $$\n$$ P_{n+1}(x) = \\frac{2n+1}{n+1}xP_n(x) - \\frac{n}{n+1}P_{n-1}(x) $$\nThis relation holds for all integers $n \\geq 1$.\n\n**Part 2: Determination of the monic scaling factor $\\kappa_n$**\n\nMonic polynomials $\\{p_n(x)\\}$ are defined by $p_n(x) = \\kappa_n P_n(x)$, where the leading coefficient of $p_n(x)$ is $1$. The leading coefficient of $p_n(x)$ is $\\kappa_n k_n$.\nSetting $\\kappa_n k_n = 1$ gives $\\kappa_n = \\frac{1}{k_n}$.\n$$ \\kappa_n = \\frac{2^n (n!)^2}{(2n)!} $$\n\n**Part 3: Monic recurrence relation and coefficients $\\alpha_n, \\beta_n$**\n\nWe rewrite the recurrence from Part 1 using $P_k(x) = \\frac{1}{\\kappa_k}p_k(x)$:\n$$ \\frac{1}{\\kappa_{n+1}}p_{n+1}(x) = \\frac{2n+1}{n+1}x \\frac{1}{\\kappa_n}p_n(x) - \\frac{n}{n+1}\\frac{1}{\\kappa_{n-1}}p_{n-1}(x) $$\nMultiplying by $\\kappa_{n+1}$ gives:\n$$ p_{n+1}(x) = \\frac{\\kappa_{n+1}}{\\kappa_n}\\frac{2n+1}{n+1}x p_n(x) - \\frac{\\kappa_{n+1}}{\\kappa_{n-1}}\\frac{n}{n+1}p_{n-1}(x) $$\nWe evaluate the coefficient of the $x p_n(x)$ term. We need the ratio $\\kappa_{n+1}/\\kappa_n$:\n$$ \\frac{\\kappa_{n+1}}{\\kappa_n} = \\frac{2^{n+1}((n+1)!)^2}{(2n+2)!} \\left/ \\frac{2^n (n!)^2}{(2n)!} \\right. = \\frac{2(n+1)^2}{(2n+2)(2n+1)} = \\frac{n+1}{2n+1} $$\nThe coefficient of $x p_n(x)$ is $\\frac{n+1}{2n+1} \\frac{2n+1}{n+1} = 1$.\nThe recurrence takes the form $p_{n+1}(x) = x p_n(x) - \\beta_n p_{n-1}(x)$.\nComparing this with the target form $p_{n+1}(x) = (x-\\alpha_n)p_n(x) - \\beta_n p_{n-1}(x)$, we immediately identify $\\alpha_n = 0$.\nThe coefficient $\\beta_n$ is given by:\n$$ \\beta_n = \\frac{\\kappa_{n+1}}{\\kappa_{n-1}}\\frac{n}{n+1} $$\nWe compute the ratio $\\kappa_{n+1}/\\kappa_{n-1}$:\n$$ \\frac{\\kappa_{n+1}}{\\kappa_{n-1}} = \\frac{2^{n+1}((n+1)!)^2}{(2n+2)!} \\left/ \\frac{2^{n-1}((n-1)!)^2}{(2n-2)!} \\right. = \\frac{2^2 (n+1)^2 n^2}{(2n+2)(2n+1)(2n)(2n-1)} = \\frac{4n^2(n+1)^2}{4n(n+1)(2n+1)(2n-1)} = \\frac{n(n+1)}{(2n+1)(2n-1)} $$\nSubstituting this into the expression for $\\beta_n$:\n$$ \\beta_n = \\frac{n(n+1)}{(2n+1)(2n-1)} \\frac{n}{n+1} = \\frac{n^2}{(2n+1)(2n-1)} = \\frac{n^2}{4n^2-1} $$\nThis expression for $\\beta_n$ is valid for $n \\geq 1$.\nThe recurrence coefficients for the monic Legendre polynomials are $\\alpha_n=0$ and $\\beta_n = \\frac{n^2}{4n^2-1}$.", "answer": "$$ \\boxed{ \\begin{pmatrix} 0  \\frac{n^2}{4n^2-1} \\end{pmatrix} } $$", "id": "3423659"}, {"introduction": "A recurrence relation is not just a mathematical identity; it is also a computational algorithm, and its reliability is paramount. This problem [@problem_id:3423673] delves into the crucial topic of numerical stability, forcing an analysis of how floating-point errors behave when using the recurrence. By distinguishing between minimal and dominant solutions, you will understand why a naive forward iteration can fail dramatically and why backward recurrence, known as Miller's algorithm, is often the only stable method for computing certain solutions, a fundamental piece of wisdom for any computational scientist.", "problem": "Consider a family of real orthogonal polynomials $\\{p_n\\}_{n \\ge 0}$ on a compact interval with respect to a positive weight, normalized so that they satisfy the three-term recurrence relation\n$$\nx\\,p_n(x) \\;=\\; a_{n+1}\\,p_{n+1}(x) \\;+\\; b_n\\,p_n(x) \\;+\\; a_n\\,p_{n-1}(x), \\qquad n \\ge 0,\n$$\nwith $a_n > 0$ and $b_n \\in \\mathbb{R}$, and initial seeds $p_{-1}(x) \\equiv 0$, $p_0(x) \\equiv 1$. Assume the recurrence coefficients converge, in the sense that $a_n \\to a  0$ and $b_n \\to 0$ as $n \\to \\infty$, which holds for the classical Jacobi families after suitable normalization. Define the associated polynomials of the second kind $\\{q_n(x)\\}_{n \\ge 0}$ as the unique solution of the same homogeneous three-term recurrence with different initial seeds chosen so that, for any fixed $x$ with $|x|  2a$, the solution is minimal in the sense that $q_n(x) \\to 0$ relative to any other linearly independent solution as $n \\to \\infty$. These associated polynomials arise in boundary operator evaluations in high-order Spectral Element and Discontinuous Galerkin (DG) methods, where one often needs $\\{q_n(x)\\}_{n=0}^N$ for a fixed $x$ with $x  2a$ and large $N$.\n\nStarting only from the convergence of $(a_n,b_n)$ and the definition of minimal and dominant solutions for second-order linear difference equations, analyze the asymptotic growth factors that govern the error amplification in the forward direction (increasing $n$) and in the backward direction (decreasing $n$, as in Miller’s algorithm) when evaluating $\\{q_n(x)\\}$ for a fixed $x  2a$. Based on this analysis, which of the following statements most accurately justifies the numerically stable choice between forward and backward recurrence for computing $\\{q_n(x)\\}_{n=0}^N$ with minimal round-off amplification?\n\nA. Use forward recurrence, because $q_n(x)$ decays with $n$ for $x > 2a$, so round-off errors are damped by the minimal root $|r_-|  1$; the decay of the target solution guarantees stability.\n\nB. Neither direction is generally stable when $a_n$ varies with $n$; only if $a_n$ is exactly constant can backward recurrence be stable. Otherwise one must reorthogonalize at each step.\n\nC. Use backward recurrence (Miller’s algorithm), because generic perturbations contain a component in the dominant solution, which grows by the factor $|r_+|  1$ under forward iteration; reversing the direction multiplies this unwanted component by $|r_+|^{-1}  1$ at each step, thereby damping it so that the minimal solution is recovered up to a normalization.\n\nD. Either direction is equally stable for $x  2a$, because the characteristic roots satisfy $r_+ r_- = 1$, so the growth of one solution is exactly canceled by the decay of the other in floating-point arithmetic.", "solution": "The analysis concerns the numerical stability of computing a specific solution to the second-order linear homogeneous difference equation:\n$$\na_{n+1}\\,y_{n+1}(x) + (b_n - x)\\,y_n(x) + a_n\\,y_{n-1}(x) = 0\n$$\nThe problem specifies that the coefficients have the limits $a_n \\to a  0$ and $b_n \\to 0$ as $n \\to \\infty$. The recurrence relation asymptotically approaches the constant-coefficient form:\n$$\na\\,y_{n+1} - x\\,y_n + a\\,y_{n-1} \\approx 0\n$$\nWe analyze this limiting equation by seeking solutions of the form $y_n = r^n$. Substituting this ansatz yields the characteristic equation:\n$$\na\\,r^2 - x\\,r + a = 0 \\quad \\implies \\quad r^2 - \\frac{x}{a}\\,r + 1 = 0\n$$\nThe roots of this quadratic equation are:\n$$\nr_{\\pm} = \\frac{\\frac{x}{a} \\pm \\sqrt{(\\frac{x}{a})^2 - 4}}{2} = \\frac{x \\pm \\sqrt{x^2 - 4a^2}}{2a}\n$$\nThe problem considers a fixed $x  2a$, which implies $x^2  4a^2$. Consequently, the discriminant is positive, and the two characteristic roots $r_+$ and $r_-$ are real and distinct.\n\nFrom Vieta's formulas, the product of the roots is $r_+ r_- = 1$. Since $x  2a  0$ and $\\sqrt{x^2 - 4a^2}  0$, we can identify the magnitudes of the roots:\n- $r_+ = \\frac{x + \\sqrt{x^2 - 4a^2}}{2a}  \\frac{2a + 0}{2a} = 1$. Thus, $|r_+|  1$.\n- $r_- = \\frac{1}{r_+}$. Thus, $0  |r_-|  1$.\n\nAccording to the theory of linear difference equations (Perron-Kreuser theorem), the general solution to the original variable-coefficient recurrence is a linear combination of two fundamental solutions whose asymptotic behaviors are governed by these roots.\n- One solution, the **dominant solution**, grows asymptotically like $r_+^n$. The polynomial solution $\\{p_n(x)\\}$ is an example of a dominant solution.\n- The other solution, the **minimal solution**, decays asymptotically like $r_-^n$. The problem states that $\\{q_n(x)\\}$ is this minimal solution for $x  2a$.\n\nTo compute $\\{q_n(x)\\}_{n=0}^N$ using forward recurrence, one would start with $q_0(x)$ and $q_1(x)$ and iterate. Let $\\hat{q}_n$ be the value computed in floating-point arithmetic. At each step, a small round-off error is introduced. This means the computed sequence is not the pure minimal solution, but a perturbed one. A general solution can be expressed as $\\hat{q}_n = C_1 p_n(x) + C_2 q_n(x)$. Even if we start with exact initial values for $q_n(x)$, meaning the initial $\\hat{q}_0, \\hat{q}_1$ have $C_1=0$, subsequent floating-point operations will introduce errors that are equivalent to adding a small component of the dominant solution $p_n(x)$. Let this error component be $\\epsilon p_n(x)$. The total computed solution is $\\hat{q}_n(x) = q_n(x) + \\epsilon p_n(x)$. The relative error is:\n$$\n\\frac{|\\hat{q}_n(x) - q_n(x)|}{|q_n(x)|} = \\frac{|\\epsilon p_n(x)|}{|q_n(x)|} \\sim \\frac{|\\epsilon| |A r_+^n|}{|B r_-^n|} = \\frac{|\\epsilon A|}{|B|} |r_+|^{2n}\n$$\nSince $|r_+|  1$, the relative error grows exponentially. The computation is numerically unstable because the desired decaying solution is swamped by the unavoidable, growing error component.\n\nTo compute using backward recurrence (Miller's algorithm), one rearranges the formula to solve for $y_{n-1}$. In this direction, the roles of the solutions are reversed. A component that behaves like $y_n \\sim r^n$ is transformed into $y_{n-1} \\sim r^{n-1} = y_n/r$. The dominant solution component $p_n(x) \\sim r_+^n$ is damped at each step by a factor of $|r_+|^{-1}  1$. The minimal solution component $q_n(x) \\sim r_-^n$ is amplified at each step by a factor of $|r_-|^{-1} = |r_+|  1$. One starts the backward recurrence at an index $M \\gg N$ with arbitrary values, for instance $\\tilde{q}_{M+1} = 0$ and $\\tilde{q}_{M} = 1$. As one iterates backwards from $n=M-1$ down to $0$, the component corresponding to the original dominant solution $p_n(x)$ is exponentially damped. The component corresponding to the minimal solution $q_n(x)$ is exponentially amplified, quickly dominating the sequence. Therefore, the computed sequence $\\{\\tilde{q}_n\\}_{n=0}^N$ becomes proportional to the true minimal solution $\\{q_n(x)\\}_{n=0}^N$. This method is numerically stable because it systematically eliminates the unwanted growing solution.\n\nBased on this analysis:\n- **A** is incorrect. The decay of the target solution makes the forward recurrence *less* stable, not more.\n- **B** is incorrect. The stability of backward recurrence depends on the asymptotic behavior of coefficients, not them being constant.\n- **C** correctly describes the instability of forward iteration due to the amplification of the dominant error component, and the stability of backward iteration (Miller's algorithm) due to the damping of this same component.\n- **D** is incorrect. Floating-point arithmetic does not cause cancellation in this manner; the large growing error component overwhelms the small decaying solution.\n\nTherefore, the correct choice is to use backward recurrence.", "answer": "$$\\boxed{C}$$", "id": "3423673"}]}