{"hands_on_practices": [{"introduction": "The Chebyshev differentiation matrix is the fundamental building block of spectral collocation methods, enabling the approximation of derivatives with exceptional accuracy. This first practice [@problem_id:3369023] guides you through the process of constructing this matrix from first principles, with a crucial emphasis on the numerical stability of the formulas used. By implementing and testing a vectorized version, you will gain hands-on experience with the techniques that ensure robustness and efficiency in practical scientific computing.", "problem": "You are asked to derive and implement a numerically stable, fully vectorized Chebyshev–Gauss–Lobatto differentiation matrix for use in spectral and discontinuous Galerkin methods. Begin from foundational principles: Chebyshev polynomials of the first kind are defined by $T_n(x) = \\cos(n \\arccos(x))$, and the Chebyshev–Gauss–Lobatto points are generated from the extrema of $T_n(x)$ on the interval $[-1,1]$. Use the fundamental fact that interpolants at distinct nodes can be differentiated via barycentric Lagrange interpolation with weights and that the derivative of the interpolant at each node yields a differentiation matrix applied to nodal values. Your derivation must construct vectorized formulas for the off-diagonal and diagonal entries of the differentiation matrix and must emphasize avoidance of catastrophic cancellation when $x_i \\approx x_j$. You must justify all numerical safeguards employed.\n\nImplement the following in a single program:\n- Use the Chebyshev–Gauss–Lobatto nodes $x_k = \\cos(\\theta_k)$ where $\\theta_k = \\pi k / N$ for $k=0,1,\\dots,N$, with angles measured in radians.\n- Derive and implement a barycentric-based differentiation matrix $D \\in \\mathbb{R}^{(N+1)\\times(N+1)}$ whose action $y = D f$ approximates the derivative of the degree-$N$ interpolant of a function $f$ at the nodes $x_k$. Your implementation must be fully vectorized and must include explicit safeguards to avoid division by zero on the diagonal and subtraction-induced loss of significance for diagonal entries.\n- Provide a numerically stable routine to evaluate the Chebyshev polynomial of the first kind $T_m(x)$ and the Chebyshev polynomial of the second kind $U_{m-1}(x)$ at the Chebyshev–Gauss–Lobatto nodes in order to test exactness of differentiation for polynomials, taking care to handle the endpoints $x=\\pm 1$ without introducing undefined operations. Angles must be handled in radians.\n\nTest Suite. For each test case below, compute the maximum absolute error (supremum norm on the nodes) between the numerical derivative $D f$ and the corresponding analytic derivative when available.\n- Test A (boundary case): $N=1$, $f(x)=1$. Output the value $\\max\\limits_{k} |(Df)_k|$ as a float.\n- Test B (polynomial exactness, general case): $N=8$, $m=3$, $f(x)=T_m(x)$. Use the exact derivative $f'(x)=m\\,U_{m-1}(x)$. Output $\\max\\limits_{k} |(Df)_k - m\\,U_{m-1}(x_k)|$ as a float.\n- Test C (highest degree on the grid): $N=32$, $m=32$, $f(x)=T_m(x)$. Use the exact derivative $f'(x)=m\\,U_{m-1}(x)$. Output $\\max\\limits_{k} |(Df)_k - m\\,U_{m-1}(x_k)|$ as a float.\n- Test D (linear function property): $N=16$, $f(x)=x$. The exact derivative is $f'(x)=1$. Output $\\max\\limits_{k} |(Df)_k - 1|$ as a float.\n- Test E (analytic non-polynomial): $N=128$, $f(x)=e^x$. The exact derivative is $f'(x)=e^x$. Output $\\max\\limits_{k} |(Df)_k - e^{x_k}|$ as a float.\n\nFinal Output Format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[resultA,resultB,resultC,resultD,resultE]\"). Each result must be a floating-point number in standard decimal or scientific notation. All angles must be handled in radians.", "solution": "The problem of constructing a Chebyshev differentiation matrix is a cornerstone of spectral methods for solving differential equations. The process begins with the choice of nodes, followed by polynomial interpolation and differentiation. Herein, we derive the entries of the differentiation matrix for Chebyshev–Gauss–Lobatto (CGL) nodes from first principles, emphasizing numerical stability.\n\n**1. Chebyshev Polynomials and CGL Nodes**\n\nChebyshev polynomials of the first kind, $T_N(x)$, are defined on the interval $x \\in [-1, 1]$ by the relation $T_N(x) = \\cos(N \\arccos(x))$. The Chebyshev–Gauss–Lobatto (CGL) nodes are the set of $N+1$ points corresponding to the extrema of $T_N(x)$. These nodes are given by the formula:\n$$\nx_k = \\cos\\left(\\frac{\\pi k}{N}\\right) \\quad \\text{for } k = 0, 1, \\dots, N\n$$\nLet a function $f(x)$ be sampled at these nodes, yielding the vector of values $\\mathbf{f} = [f(x_0), f(x_1), \\dots, f(x_N)]^T$. We seek a differentiation matrix $D \\in \\mathbb{R}^{(N+1)\\times(N+1)}$ such that the vector $\\mathbf{f}' = D\\mathbf{f}$ provides a high-order approximation to the derivative of $f(x)$ at the nodes, i.e., $f'_k \\approx f'(x_k)$. This is achieved by differentiating the degree-$N$ polynomial interpolant $p(x)$ that passes through the points $(x_k, f(x_k))$.\n\n**2. Barycentric Lagrange Interpolation**\n\nThe unique polynomial interpolant $p(x)$ of degree at most $N$ is given in the Lagrange form as $p(x) = \\sum_{j=0}^{N} f_j \\ell_j(x)$, where $f_j = f(x_j)$ and $\\ell_j(x)$ are the Lagrange basis polynomials:\n$$\n\\ell_j(x) = \\prod_{\\substack{k=0 \\\\ k \\neq j}}^{N} \\frac{x-x_k}{x_j-x_k}\n$$\nDifferentiating this form directly is numerically unstable. A superior approach is the barycentric formulation. The first barycentric formula rewrites $\\ell_j(x)$ using barycentric weights $w_j$:\n$$\n\\ell_j(x) = \\frac{w_j}{x-x_j} \\left/ \\sum_{k=0}^N \\frac{w_k}{x-x_k} \\right.\n$$\nThe weights $w_j$ for the CGL nodes are known to have a simple form:\n$$\nw_j = \\frac{(-1)^j}{c_j}, \\quad \\text{where } c_j = \\begin{cases} 2 & j=0 \\text{ or } j=N \\\\ 1 & 1 \\le j \\le N-1 \\end{cases}\n$$\nThe derivative of the interpolant at a node $x_i$ is $p'(x_i) = \\sum_{j=0}^{N} f_j \\ell'_j(x_i)$. The entries of the differentiation matrix $D$ are therefore given by $D_{ij} = \\ell'_j(x_i)$.\n\n**3. Derivation of Differentiation Matrix Entries**\n\nWe derive the entries of $D$ by differentiating the Lagrange basis polynomials $\\ell_j(x)$.\n\n**Off-diagonal entries ($i \\neq j$):**\nFor $i \\neq j$, the evaluation of $\\ell'_j(x_i)$ is straightforward. Using the product rule is cumbersome; a more elegant method relies on the relationship between Lagrange polynomials and barycentric weights. The formula relating two basis polynomials at a node is $\\ell_j(x_i) = \\delta_{ij}$. Using a different form of Lagrange polynomials, $\\ell_j(x)=L(x)/((x-x_j)L'(x_j))$ where $L(x) = \\prod_k (x-x_k)$, we can show that for $i \\neq j$:\n$$\nD_{ij} = \\ell'_j(x_i) = \\frac{L'(x_i)}{(x_i-x_j)L'(x_j)} = \\frac{w_j/w_i}{x_i - x_j}\n$$\nSubstituting the specific weights for CGL nodes:\n$$\n\\frac{w_j}{w_i} = \\frac{(-1)^j/c_j}{(-1)^i/c_i} = \\frac{c_i}{c_j}(-1)^{j-i}\n$$\nSince $(-1)^{j-i} = (-1)^{i-j} = (-1)^{i+j}$, we can write the off-diagonal entries as:\n$$\nD_{ij} = \\frac{c_i}{c_j} \\frac{(-1)^{i+j}}{x_i - x_j} \\quad \\text{for } i \\neq j\n$$\nThis formula is well-behaved. Although the denominator $x_i - x_j$ can be small, it is not the result of a subtractive cancellation of nearly-equal floating-point numbers, as the nodes $x_i$ and $x_j$ are defined precisely via the cosine function.\n\n**Diagonal entries ($i = j$):**\nThe diagonal entries $D_{ii} = \\ell'_i(x_i)$ cannot be computed using the above formula, as it would lead to a $0/0$ indeterminacy. Two stable methods are available.\n\nMethod 1: Summation Property. The sum of the Lagrange basis polynomials is $\\sum_{j=0}^N \\ell_j(x) = 1$. Differentiating with respect to $x$ yields $\\sum_{j=0}^N \\ell'_j(x) = 0$. Evaluating at a node $x_i$ gives $\\sum_{j=0}^N \\ell'_j(x_i) = 0$, which implies:\n$$\nD_{ii} = \\ell'_i(x_i) = -\\sum_{\\substack{j=0 \\\\ j \\neq i}}^{N} \\ell'_j(x_i) = -\\sum_{\\substack{j=0 \\\\ j \\neq i}}^{N} D_{ij}\n$$\nThis means each diagonal element is the negative of the sum of the other elements in its row. This approach is numerically stable as it avoids differentiation of complex expressions and only involves a sum.\n\nMethod 2: Explicit Formula. Through a more detailed analysis involving the properties of Chebyshev polynomials, explicit formulas for the diagonal entries can be derived. These are computationally efficient and numerically robust:\n$$\nD_{ii} = \\begin{cases} \\frac{2N^2+1}{6} & i=0 \\\\ -\\frac{x_i}{2(1-x_i^2)} & 1 \\le i \\le N-1 \\\\ -\\frac{2N^2+1}{6} & i=N \\end{cases}\n$$\nFor implementation, this explicit formula is preferable due to its directness and efficiency, avoiding the need for a loop or sum over each row. The denominator $1-x_i^2 = 1-\\cos^2(\\pi i/N) = \\sin^2(\\pi i/N)$ is non-zero for the interior points ($1 \\le i \\le N-1$).\n\n**4. Numerically Stable Evaluation of Test Functions**\n\nThe test suite requires evaluating $T_m(x)$ and its derivative, $T'_m(x) = m U_{m-1}(x)$, at the CGL nodes $x_k = \\cos(\\theta_k)$ where $\\theta_k = \\pi k/N$.\n\nEvaluation of $T_m(x_k)$: The most stable method is to use the angle-space definition directly. For $\\theta_k \\in [0, \\pi]$, $\\arccos(\\cos(\\theta_k)) = \\theta_k$.\n$$\nT_m(x_k) = T_m(\\cos(\\theta_k)) = \\cos(m \\arccos(\\cos(\\theta_k))) = \\cos(m \\theta_k) = \\cos\\left(\\frac{m \\pi k}{N}\\right)\n$$\n\nEvaluation of $U_{m-1}(x_k)$: The Chebyshev polynomial of the second kind is defined by $U_n(\\cos\\theta) = \\frac{\\sin((n+1)\\theta)}{\\sin\\theta}$. Thus,\n$$\nU_{m-1}(x_k) = U_{m-1}(\\cos\\theta_k) = \\frac{\\sin(m\\theta_k)}{\\sin\\theta_k}\n$$\nThis formula becomes indeterminate ($0/0$) at the endpoints $k=0$ ($\\theta_0=0$) and $k=N$ ($\\theta_N=\\pi$). We must use L'Hôpital's rule at these points:\n- For $k=0$ ($\\theta_k \\to 0$):\n$$ \\lim_{\\theta \\to 0} \\frac{\\sin(m\\theta)}{\\sin\\theta} = \\lim_{\\theta \\to 0} \\frac{m\\cos(m\\theta)}{\\cos\\theta} = m $$\n- For $k=N$ ($\\theta_k \\to \\pi$): Let $\\phi = \\pi - \\theta \\to 0$.\n$$ \\lim_{\\theta \\to \\pi} \\frac{\\sin(m\\theta)}{\\sin\\theta} = \\lim_{\\phi \\to 0} \\frac{\\sin(m(\\pi-\\phi))}{\\sin(\\pi-\\phi)} = \\lim_{\\phi \\to 0} \\frac{-\\cos(m\\pi)\\sin(m\\phi)}{\\sin\\phi} = -(-1)^m \\cdot m = (-1)^{m+1}m = m(-1)^{m-1} $$\nTherefore, a stable evaluation of $U_{m-1}(x_k)$ is:\n$$\nU_{m-1}(x_k) = \\begin{cases} m & k=0 \\\\ \\frac{\\sin(m \\pi k/N)}{\\sin(\\pi k/N)} & 1 \\le k \\le N-1 \\\\ m(-1)^{m-1} & k=N \\end{cases}\n$$\nThese stable evaluation routines, combined with the robust differentiation matrix formulation, provide the necessary tools to perform the required tests with high accuracy.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives, implements, and tests a Chebyshev differentiation matrix.\n    \"\"\"\n\n    def chebyshev_diff_matrix(N):\n        \"\"\"\n        Constructs the (N+1)x(N+1) Chebyshev differentiation matrix.\n        Uses numerically stable, vectorized formulas.\n        \"\"\"\n        if not isinstance(N, int) or N < 0:\n            raise ValueError(\"N must be a non-negative integer.\")\n        if N == 0:\n            return np.array([[0.0]])\n\n        # Generate Chebyshev-Gauss-Lobatto nodes\n        k = np.arange(N + 1)\n        theta = np.pi * k / N\n        x = np.cos(theta)\n\n        # Vectorized computation of off-diagonal entries\n        c = np.ones(N + 1)\n        c[0] = 2.0\n        c[N] = 2.0\n\n        # Create column and row vectors for broadcasting\n        x_i = x[:, np.newaxis]\n        x_j = x[np.newaxis, :]\n        c_i = c[:, np.newaxis]\n        c_j = c[np.newaxis, :]\n        \n        # Matrix of i and j indices for sign\n        i = np.arange(N + 1)[:, np.newaxis]\n        j = np.arange(N + 1)[np.newaxis, :]\n        sign_matrix = (-1.0)**(i + j)\n        \n        # Difference matrix\n        dX = x_i - x_j\n        \n        # Fill diagonal to avoid division by zero; these values are overwritten later.\n        np.fill_diagonal(dX, 1e-30)\n\n        # Compute off-diagonal entries D_ij = (c_i/c_j) * (-1)^(i+j) / (x_i - x_j)\n        D = (c_i / c_j) * sign_matrix / dX\n\n        # Compute diagonal entries using the explicit, stable formula\n        diag = np.zeros(N + 1)\n        # Interior points\n        diag[1:N] = -x[1:N] / (2.0 * (1.0 - x[1:N]**2))\n        # Endpoints\n        diag[0] = (2.0 * N**2 + 1.0) / 6.0\n        diag[N] = -(2.0 * N**2 + 1.0) / 6.0\n        \n        np.fill_diagonal(D, diag)\n        \n        return D\n\n    def eval_Tm(m, N):\n        \"\"\"\n        Evaluates Chebyshev polynomial T_m at (N+1) CGL nodes.\n        Uses the stable formula T_m(x_k) = cos(m*theta_k).\n        \"\"\"\n        if N == 0:\n            return np.array([1.0])\n        k = np.arange(N + 1)\n        theta = np.pi * k / N\n        return np.cos(m * theta)\n\n    def eval_Um_minus_1(m, N):\n        \"\"\"\n        Evaluates Chebyshev polynomial U_{m-1} at (N+1) CGL nodes.\n        Uses stable formulas for endpoints.\n        \"\"\"\n        if m == 0:\n            # T'_0(x) = 0. So 0 * U_{-1} is 0.\n            return np.zeros(N + 1)\n        \n        if N == 0: # U_{m-1}(x_0=1) = m.\n            return np.array([float(m)])\n            \n        k = np.arange(N + 1)\n        theta = np.pi * k / N\n        \n        u_vals = np.zeros(N + 1)\n        \n        # Interior points k = 1, ..., N-1 where sin(theta) is non-zero\n        interior_indices = (k > 0) & (k < N)\n        u_vals[interior_indices] = np.sin(m * theta[interior_indices]) / np.sin(theta[interior_indices])\n        \n        # Endpoint k=0 (theta=0, x=1) using L'Hopital's rule\n        u_vals[0] = m\n        \n        # Endpoint k=N (theta=pi, x=-1) using L'Hopital's rule\n        u_vals[N] = m * (-1.0)**(m - 1)\n        \n        return u_vals\n\n    test_cases = [\n        {'id': 'A', 'N': 1, 'm': 0, 'f_name': 'const'},\n        {'id': 'B', 'N': 8, 'm': 3, 'f_name': 'poly'},\n        {'id': 'C', 'N': 32, 'm': 32, 'f_name': 'poly'},\n        {'id': 'D', 'N': 16, 'm': 1, 'f_name': 'poly'},\n        {'id': 'E', 'N': 128, 'm': None, 'f_name': 'exp'}\n    ]\n\n    results = []\n\n    for case in test_cases:\n        N = case['N']\n        m = case['m']\n        \n        # Generate nodes and differentiation matrix\n        k = np.arange(N + 1)\n        theta = np.pi * k / N\n        x = np.cos(theta)\n        D = chebyshev_diff_matrix(N)\n        \n        f_vec = None\n        df_analytical = None\n\n        if case['f_name'] == 'const':\n            # f(x) = 1 = T_0(x)\n            f_vec = np.ones(N + 1)\n            df_analytical = np.zeros(N + 1)\n        elif case['f_name'] == 'poly':\n            # f(x) = T_m(x)\n            f_vec = eval_Tm(m, N)\n            # f'(x) = m * U_{m-1}(x)\n            df_analytical = m * eval_Um_minus_1(m, N)\n        elif case['f_name'] == 'exp':\n            # f(x) = exp(x)\n            f_vec = np.exp(x)\n            df_analytical = np.exp(x)\n        \n        # Compute numerical derivative\n        df_numerical = D @ f_vec\n\n        # For Test A, the problem asks for max|(Df)_k|\n        if case['id'] == 'A':\n            error = np.max(np.abs(df_numerical))\n        else:\n            error = np.max(np.abs(df_numerical - df_analytical))\n\n        results.append(error)\n\n    # Format output as a comma-separated list in brackets.\n    output_str = \",\".join(f\"{res:.15e}\" for res in results)\n    print(f\"[{output_str}]\")\n\nsolve()\n```", "id": "3369023"}, {"introduction": "Once the differentiation matrix is built, we can deploy it to solve differential equations. This practice [@problem_id:3368981] applies the tool to a canonical Sturm-Liouville eigenvalue problem, which models phenomena from quantum wavefunctions to mechanical vibrations. You will implement and contrast two key techniques for enforcing boundary conditions—matrix restriction and the penalty method—and learn to distinguish between accurate physical solutions and numerical artifacts known as spurious modes.", "problem": "Consider the Sturm–Liouville eigenvalue problem on the interval $[-1,1]$,\n$$(p(x)\\,u'(x))' + q(x)\\,u(x) = \\lambda\\,w(x)\\,u(x),$$\nwith $p(x) = 1$, $q(x)=0$, and $w(x)=1$, subject to homogeneous Dirichlet boundary conditions $u(-1)=0$ and $u(1)=0$. You will discretize the operator using Chebyshev collocation based on Chebyshev–Gauss–Lobatto points and analyze the resulting discrete spectrum.\n\nYour tasks are:\n\n1. Starting from the fundamental definition of the Chebyshev–Gauss–Lobatto points $x_j = \\cos(\\pi j/N)$ for $j=0,1,\\dots,N$, and the requirement that a differentiation matrix $D \\in \\mathbb{R}^{(N+1)\\times(N+1)}$ approximates the first derivative at these nodes, derive the Chebyshev first differentiation matrix $D$. From this, derive the discrete second derivative matrix $D^{(2)} = D^2$.\n\n2. Using the interior collocation approach to enforce the Dirichlet boundary conditions exactly (i.e., eliminate the equations at $x_N=-1$ and $x_0=1$ and solve the eigenproblem on the $N-1$ interior nodes), form the discrete eigenvalue problem\n$$\nD^{(2)}_{\\text{int}}\\,v = \\lambda\\,v,\n$$\nwhere $D^{(2)}_{\\text{int}}$ is the interior submatrix of $D^{(2)}$ obtained by restricting to indices $1,\\dots,N-1$. Compute the first $K$ discrete eigenvalues ordered by decreasing real part.\n\n3. Independently, derive in closed form the exact eigenpairs for the continuous problem with $p(x)=1$, $q(x)=0$, $w(x)=1$ and homogeneous Dirichlet boundary conditions on $[-1,1]$. From this derivation, obtain the large-index asymptotic behavior of the continuous eigenvalues $\\lambda_m$ as a function of the mode index $m \\in \\mathbb{N}$. Use this analytical result to compare with the discrete eigenvalues obtained in Task $2$.\n\n4. Analyze the effect of a penalty-type boundary enforcement by modifying the full $(N+1)\\times(N+1)$ matrix $D^{(2)}$ with a diagonal penalty of magnitude $\\tau$ applied only at the boundary nodes $j=0$ and $j=N$. That is, consider\n$$\nL_{\\tau} \\equiv D^{(2)} + \\tau\\,\\mathrm{diag}(1,0,\\dots,0,1).\n$$\nSolve the discrete eigenproblem\n$$\nL_{\\tau}\\,u = \\lambda\\,u\n$$\non all $N+1$ nodes. Define a discrete mode $u$ to be boundary-localized if its normalized endpoint mass ratio\n$$\n\\rho(u) \\equiv \\frac{|u_0|^2 + |u_N|^2}{\\sum_{j=0}^N |u_j|^2}\n$$\nexceeds a threshold $\\theta$ with $0<\\theta<1$. Using a principled choice of large $\\tau$ and threshold $\\theta$, identify and count the number of boundary-localized spurious eigenmodes, i.e., eigenpairs whose eigenvalues are dominated by the penalty and whose eigenvectors localize at the boundaries.\n\n5. Report your findings via a small test suite that exercises accuracy, stability, and spurious-mode identification. For each test, produce a single number or a boolean as specified below.\n\nTest suite specification:\n\n- Test A (accuracy, interior enforcement): Use $N=48$ and $K=6$. Compute the first $K$ discrete eigenvalues from $D^{(2)}_{\\text{int}}$ ordered by decreasing real part. Compare them to the exact continuous eigenvalues derived in Task $3$ indexed by $m=1,2,\\dots,K$ and compute the maximum relative error over these $K$ modes,\n$$\n\\varepsilon_{\\max} \\equiv \\max_{1\\le m\\le K} \\frac{|\\lambda^{\\text{disc}}_m - \\lambda^{\\text{cont}}_m|}{|\\lambda^{\\text{cont}}_m|}.\n$$\nReport this as a floating-point number rounded to $8$ decimal places.\n\n- Test B (spurious-mode count, penalty enforcement): Use $N=48$, penalty magnitude $\\tau = 10^6$, and boundary-localization threshold $\\theta=0.9$. Solve the full $(N+1)$-dimensional eigenproblem for $L_{\\tau}$ and count the number of eigenpairs whose eigenvalue satisfies $\\mathrm{Re}(\\lambda) > 0.1\\,\\tau$ and whose eigenvector satisfies $\\rho(u) \\ge \\theta$. Report this count as an integer.\n\n- Test C (reality of spectrum under interior enforcement): Use $N=16$. Compute all eigenvalues of $D^{(2)}_{\\text{int}}$ and test whether the largest absolute value of their imaginary parts is less than $10^{-10}$. Report the boolean value $\\mathrm{True}$ if this holds and $\\mathrm{False}$ otherwise.\n\nFinal output format:\n\nYour program should produce a single line of output containing the results of Tests A, B, and C as a comma-separated list enclosed in square brackets, in the order [TestA,TestB,TestC]. For example, the output must be of the form\n$$\n[\\varepsilon_{\\max},\\; \\text{spurious\\_count},\\; \\text{all\\_real}],\n$$\nwhere $\\varepsilon_{\\max}$ is a floating-point number rounded to $8$ decimal places, $\\text{spurious\\_count}$ is an integer, and $\\text{all\\_real}$ is a boolean literal.", "solution": "The posed problem is a comprehensive exercise in the application of Chebyshev spectral collocation methods to a canonical Sturm–Liouville eigenvalue problem. It requires the derivation and implementation of Chebyshev differentiation matrices, the comparison of two distinct methods for enforcing boundary conditions (interior collocation versus penalty method), and the analytical solution of the underlying continuous problem for verification.\n\nWe begin by noting a minor inconsistency in the problem statement. The Chebyshev–Gauss–Lobatto (CGL) points are defined by the formula $x_j = \\cos(\\pi j/N)$ for $j=0,1,\\dots,N$. This explicitly sets $x_0 = \\cos(0) = 1$ and $x_N = \\cos(\\pi) = -1$. The problem text later refers to boundary nodes as \"$x_0=-1$ and $x_N=1$\". This appears to be a textual error. We shall proceed by adhering to the explicit and standard formula for the CGL points, such that the homogeneous Dirichlet boundary conditions $u(-1)=0$ and $u(1)=0$ are enforced at nodes $x_N$ and $x_0$, respectively.\n\n### Task 1: Derivation of Chebyshev Differentiation Matrices\n\nA spectral differentiation matrix $D$ for a set of nodes $\\{x_j\\}_{j=0}^N$ provides a linear transformation from the vector of function values $\\mathbf{u} = (u_0, \\dots, u_N)^T$ to the vector of approximate derivative values $\\mathbf{u}' = (u'_0, \\dots, u'_N)^T$ at these nodes. That is, $\\mathbf{u}' = D\\mathbf{u}$. The entries $D_{jk}$ of this matrix are given by $D_{jk} = \\ell'_k(x_j)$, where $\\ell_k(x)$ is the Lagrange cardinal polynomial associated with node $x_k$, which has the property $\\ell_k(x_j) = \\delta_{jk}$.\n\nFor the specific case of Chebyshev–Gauss–Lobatto points, $x_j = \\cos(\\pi j/N)$, there exist well-established, explicit formulas for the entries of $D \\in \\mathbb{R}^{(N+1)\\times(N+1)}$.\n\nThe off-diagonal entries are given by:\n$$\nD_{jk} = \\frac{c_j}{c_k} \\frac{(-1)^{j+k}}{x_j - x_k}, \\quad j \\ne k\n$$\nwhere the coefficients $c_j$ are defined as:\n$$\nc_j = \\begin{cases} 2 & j=0 \\text{ or } j=N \\\\ 1 & 1 \\le j \\le N-1 \\end{cases}\n$$\n\nThe diagonal entries $D_{jj}$ can be derived using different approaches. A direct formula is:\n$$\nD_{jj} = -\\frac{x_j}{2(1-x_j^2)}, \\quad 1 \\le j \\le N-1\n$$\nwith special formulas for the endpoints:\n$$\nD_{00} = \\frac{2N^2+1}{6}, \\quad D_{NN} = -\\frac{2N^2+1}{6}\n$$\nHowever, a more robust and numerically stable method relies on the fact that the derivative of a constant function must be zero. If $u(x)=1$ for all $x$, then its derivative is $0$. In matrix form, this means $D \\mathbf{1} = \\mathbf{0}$, where $\\mathbf{1}$ is the vector of all ones. This implies that the sum of each row of $D$ must be zero:\n$$\n\\sum_{k=0}^{N} D_{jk} = 0, \\quad \\text{for each } j=0, \\dots, N\n$$\nThis allows the diagonal entries to be calculated from the off-diagonal entries:\n$$\nD_{jj} = -\\sum_{k=0, k \\ne j}^{N} D_{jk}\n$$\nThis approach avoids the evaluation of indeterminate forms at the boundaries and improves numerical stability.\n\nThe second-order Chebyshev differentiation matrix, $D^{(2)}$, is then simply obtained by squaring the first-order matrix:\n$$\nD^{(2)} = D^2 = D D\n$$\n\n### Task 3: Exact Solution of the Continuous Problem\n\nBefore analyzing the discrete systems, we derive the exact solution for the continuous problem. The problem is the Helmholtz equation on the interval $[-1,1]$:\n$$\nu''(x) = \\lambda u(x)\n$$\nsubject to homogeneous Dirichlet boundary conditions $u(-1)=0$ and $u(1)=0$.\nFor a non-trivial solution, we must have $\\lambda < 0$. Let $\\lambda = -k^2$ for some $k > 0$. The differential equation becomes $u''(x) + k^2 u(x) = 0$, which has the general solution:\n$$\nu(x) = A \\sin(kx) + B \\cos(kx)\n$$\nApplying the boundary conditions:\n1. $u(1) = A \\sin(k) + B \\cos(k) = 0$\n2. $u(-1) = A \\sin(-k) + B \\cos(-k) = -A \\sin(k) + B \\cos(k) = 0$\n\nAdding these two equations gives $2B\\cos(k) = 0$. Subtracting the second from the first gives $2A\\sin(k) = 0$. For a non-trivial solution, we cannot have both $A=0$ and $B=0$. This leads to two families of solutions:\n- **Odd Solutions ($B=0, A\\ne 0$):** We require $\\sin(k) = 0$, which implies $k = n\\pi$ for $n \\in \\mathbb{N}$ (positive integers). The eigenfunctions are $u_n(x) \\propto \\sin(n\\pi x)$.\n- **Even Solutions ($A=0, B\\ne 0$):** We require $\\cos(k) = 0$, which implies $k = (n - 1/2)\\pi$ for $n \\in \\mathbb{N}$. The eigenfunctions are $u_n(x) \\propto \\cos((n - 1/2)\\pi x)$.\n\nTo obtain a single, ordered sequence of eigenvalues, we combine these possibilities for $k$:\n$$\nk_m = \\frac{m\\pi}{2}, \\quad m=1, 2, 3, \\ldots\n$$\nThe corresponding eigenvalues are:\n$$\n\\lambda^{\\text{cont}}_m = -k_m^2 = -\\left(\\frac{m\\pi}{2}\\right)^2, \\quad m=1, 2, 3, \\ldots\n$$\nThe eigenvalues, ordered by decreasing real part (i.e., from least negative to most negative), are $\\lambda^{\\text{cont}}_1 = -(\\pi/2)^2$, $\\lambda^{\\text{cont}}_2 = -(\\pi)^2$, $\\lambda^{\\text{cont}}_3 = -(3\\pi/2)^2$, and so on. This exact formula also describes the large-index asymptotic behavior.\n\n### Task 2: Discretization via Interior Collocation\n\nThe interior collocation method, also known as the matrix restriction or submatrix method, enforces the Dirichlet boundary conditions exactly. The full discrete system is $D^{(2)}\\mathbf{u} = \\lambda\\mathbf{u}$. The boundary conditions $u(1)=0$ and $u(-1)=0$ translate to $u_0=0$ and $u_N=0$ on the CGL grid.\n\nThe $j$-th equation of the system is $\\sum_{k=0}^{N} D^{(2)}_{jk} u_k = \\lambda u_j$. For an interior node $j \\in \\{1, \\dots, N-1\\}$, this is:\n$$\nD^{(2)}_{j,0}u_0 + \\sum_{k=1}^{N-1} D^{(2)}_{jk} u_k + D^{(2)}_{j,N}u_N = \\lambda u_j\n$$\nSubstituting $u_0=0$ and $u_N=0$, the system reduces to:\n$$\n\\sum_{k=1}^{N-1} D^{(2)}_{jk} u_k = \\lambda u_j, \\quad j=1, \\dots, N-1\n$$\nThis is a reduced eigenvalue problem for the interior degrees of freedom $\\mathbf{v} = (u_1, \\dots, u_{N-1})^T$:\n$$\nD^{(2)}_{\\text{int}}\\mathbf{v} = \\lambda\\mathbf{v}\n$$\nwhere $D^{(2)}_{\\text{int}}$ is the $(N-1) \\times (N-1)$ submatrix of $D^{(2)}$ obtained by taking rows and columns indexed from $1$ to $N-1$. The eigenvalues of $D^{(2)}_{\\text{int}}$ approximate the exact continuous eigenvalues $\\lambda^{\\text{cont}}_m$.\n\n### Task 4: Discretization via Penalty Method\n\nThe penalty method is an alternative for handling boundary conditions. Instead of reducing the system size, it modifies the full $(N+1) \\times (N+1)$ operator. For Dirichlet conditions, a large penalty term is added to the diagonal entries corresponding to the boundary nodes.\nThe modified operator is:\n$$\nL_{\\tau} = D^{(2)} + \\tau \\cdot \\mathrm{diag}(1, 0, \\dots, 0, 1)\n$$\nwhere $\\tau > 0$ is a large penalty parameter.\nThe eigenproblem to solve is $L_{\\tau}\\mathbf{u} = \\lambda\\mathbf{u}$. The rationale is that if an eigenmode $\\mathbf{u}$ happens to satisfy the boundary condition (i.e., $u_0 \\approx 0, u_N \\approx 0$), the penalty term has little effect, and its eigenvalue $\\lambda$ should approximate a true eigenvalue of the original operator.\nConversely, if a mode violates the boundary conditions (e.g., $u_0$ or $u_N$ is large), the term $\\tau u_j$ (for $j=0$ or $j=N$) will dominate the equation, yielding a large eigenvalue on the order of $\\tau$. These eigenpairs do not correspond to solutions of the continuous problem and are termed \"spurious modes.\" They are typically characterized by large eigenvalues and eigenvectors localized at the boundaries.\nTo identify them, we use the boundary-localized mass ratio:\n$$\n\\rho(u) \\equiv \\frac{|u_0|^2 + |u_N|^2}{\\sum_{j=0}^N |u_j|^2}\n$$\nA mode is flagged as spurious if its eigenvalue is large (e.g., $\\mathrm{Re}(\\lambda) > c\\tau$ for some constant $c<1$) and its eigenvector is boundary-localized (e.g., $\\rho(u) > \\theta$ for some threshold $\\theta$ close to $1$).\n\n### Task 5: Test Suite Realization\n\nThe logic developed above is now applied to the specified computational tests.\n- **Test A** evaluates the accuracy of the interior collocation method. It compares the first $K=6$ eigenvalues of $D^{(2)}_{\\text{int}}$ for $N=48$ against the exact analytical eigenvalues $\\lambda^{\\text{cont}}_m = -(m\\pi/2)^2$ and computes the maximum relative error. This demonstrates the high accuracy (\"spectral accuracy\") of the method for well-resolved modes.\n- **Test B** quantifies the number of spurious modes generated by the penalty method for $N=48$. It uses the specified criteria ($\\mathrm{Re}(\\lambda) > 0.1\\tau$ with $\\tau=10^6$ and $\\rho(u) \\ge 0.9$) to filter and count these non-physical solutions.\n- **Test C** verifies a fundamental property of the discrete operator. For this self-adjoint continuous problem, the eigenvalues of $D^{(2)}_{\\text{int}}$ should be real. This test checks for $N=16$ that the imaginary parts of the computed eigenvalues are negligible (less than $10^{-10}$), confirming the correctness of the matrix construction and the stability of the numerical eigensolver.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef cheb_diff_mat(N):\n    \"\"\"\n    Computes the Chebyshev differentiation matrix D on N+1 Gauss-Lobatto points.\n    \"\"\"\n    if N == 0:\n        return np.array([[0.0]])\n    \n    x = np.cos(np.pi * np.arange(N + 1) / N)\n    c = np.ones(N + 1)\n    c[0] = 2.0\n    c[N] = 2.0\n    \n    D = np.zeros((N + 1, N + 1))\n    \n    # Off-diagonal entries\n    for j in range(N + 1):\n        for k in range(N + 1):\n            if j != k:\n                D[j, k] = (c[j] / c[k]) * ((-1)**(j + k)) / (x[j] - x[k])\n\n    # Diagonal entries using the row-sum property for stability\n    for j in range(N + 1):\n        D[j, j] = -np.sum(D[j, :])\n        \n    return D\n\ndef solve():\n    \"\"\"\n    Executes the specified test suite for Chebyshev spectral methods.\n    \"\"\"\n    results = []\n\n    # === Test A: Accuracy, Interior Enforcement ===\n    N_A = 48\n    K_A = 6\n    \n    D_A = cheb_diff_mat(N_A)\n    D2_A = D_A @ D_A\n    D2_int_A = D2_A[1:N_A, 1:N_A]\n    \n    eigvals_disc_A = np.linalg.eigvals(D2_int_A)\n    # Sort by decreasing real part (e.g., from -2.5 to -9.8)\n    sorted_eigvals_disc_A = np.sort(np.real(eigvals_disc_A))[::-1]\n    \n    # Get top K discrete eigenvalues\n    lambda_disc = sorted_eigvals_disc_A[:K_A]\n    \n    # Get exact continuous eigenvalues\n    m_vals = np.arange(1, K_A + 1)\n    lambda_cont = -((m_vals * np.pi) / 2.0)**2\n    \n    # Compute maximum relative error\n    rel_errors = np.abs(lambda_disc - lambda_cont) / np.abs(lambda_cont)\n    eps_max = np.max(rel_errors)\n    \n    results.append(round(eps_max, 8))\n\n    # === Test B: Spurious-mode Count, Penalty Enforcement ===\n    N_B = 48\n    tau_B = 1.0e6\n    theta_B = 0.9\n    \n    D_B = cheb_diff_mat(N_B)\n    D2_B = D_B @ D_B\n    \n    L_tau = D2_B.copy()\n    L_tau[0, 0] += tau_B\n    L_tau[N_B, N_B] += tau_B\n    \n    eigvals_B, eigvecs_B = np.linalg.eig(L_tau)\n    \n    spurious_count = 0\n    for i in range(N_B + 1):\n        lam = eigvals_B[i]\n        u = eigvecs_B[:, i]\n        \n        # Condition 1: Eigenvalue dominated by penalty\n        if np.real(lam) > 0.1 * tau_B:\n            # Condition 2: Eigenvector localized at boundaries\n            # Eigenvectors from np.linalg.eig are L2-normalized to 1\n            rho_u_num = np.abs(u[0])**2 + np.abs(u[N_B])**2\n            rho_u_den = np.sum(np.abs(u)**2) # Should be 1.0, but compute for robustness\n            rho_u = rho_u_num / rho_u_den\n            \n            if rho_u >= theta_B:\n                spurious_count += 1\n                \n    results.append(spurious_count)\n\n    # === Test C: Reality of Spectrum, Interior Enforcement ===\n    N_C = 16\n    \n    D_C = cheb_diff_mat(N_C)\n    D2_C = D_C @ D_C\n    D2_int_C = D2_C[1:N_C, 1:N_C]\n    \n    eigvals_C = np.linalg.eigvals(D2_int_C)\n    \n    max_imag_part = np.max(np.abs(np.imag(eigvals_C)))\n    all_real = max_imag_part < 1e-10\n    \n    results.append(all_real)\n\n    # Final print statement in the exact required format.\n    print(f\"[{results[0]},{results[1]},{results[2]}]\")\n\nsolve()\n\n```", "id": "3368981"}, {"introduction": "The reliability of simulations for time-dependent physical processes often hinges on whether the numerical method preserves fundamental quantities like energy. This advanced practice [@problem_id:3368959] delves into this concept for a diffusion problem with a non-uniform coefficient $\\nu(x)$. You will investigate how two different discretizations, a \"conservative\" flux-form and a \"skew-symmetric\" energy-form, behave with respect to discrete energy dissipation, revealing why the algebraic structure of the operator is as important as its consistency with the continuous equation.", "problem": "Consider the variable-coefficient diffusion equation $u_t = (\\nu(x) u_x)_x$ on the interval $[-1,1]$ with homogeneous Dirichlet boundary conditions $u(-1)=0$ and $u(1)=0$. The continuous energy method, for the standard $L^2$ inner product, shows via integration by parts that the energy $E(t) = \\tfrac{1}{2} \\int_{-1}^1 u(x,t)^2 \\, dx$ satisfies $\\tfrac{d}{dt} E(t) = - \\int_{-1}^1 \\nu(x) u_x(x,t)^2 \\, dx \\le 0$ for any $\\nu(x) \\ge 0$. In spectral collocation, we discretize $x \\in [-1,1]$ using Chebyshev–Gauss–Lobatto nodes $x_j = \\cos\\!\\left(\\frac{\\pi j}{n}\\right)$ for $j=0,1,\\dots,n$. The entries of the Chebyshev first-derivative differentiation matrix $D \\in \\mathbb{R}^{(n+1)\\times(n+1)}$ associated with these nodes are given for $i \\neq j$ by $D_{ij} = \\frac{c_i}{c_j} \\frac{(-1)^{i+j}}{x_i - x_j}$, where $c_0 = c_n = 2$ and $c_k = 1$ for $1 \\le k \\le n-1$. The diagonal entries are $D_{ii} = -\\sum_{j\\ne i} D_{ij}$. Let $I = \\{1,2,\\dots,n-1\\}$ denote the set of indices of the interior nodes, and let $v \\in \\mathbb{R}^{n-1}$ be the vector of unknowns corresponding to the interior degrees of freedom, with $u_0 = u_n = 0$ enforced. Denote by $A = D(:,I) \\in \\mathbb{R}^{(n+1)\\times(n-1)}$ the matrix that maps interior values $v$ to nodal derivatives $D u$ under the convention $u_0 = u_n = 0$, and by $B = D(I,:) \\in \\mathbb{R}^{(n-1)\\times(n+1)}$ the restriction of $D$ to interior rows.\n\nTwo semi-discrete operators are considered:\n\n- A conservative flux-form collocation operator $L_{\\mathrm{cons}} \\in \\mathbb{R}^{(n-1)\\times(n-1)}$ defined by $L_{\\mathrm{cons}} = B \\, \\mathrm{diag}(\\nu(x)) \\, A$, which corresponds to $v_t = L_{\\mathrm{cons}} v$ and implements the discrete analogue of $u_t = ( \\nu u_x )_x$ as $D(\\nu \\, D u)$ restricted to the interior.\n\n- A skew-symmetric (split) energy-form operator $L_{\\mathrm{skew}} \\in \\mathbb{R}^{(n-1)\\times(n-1)}$ defined by $L_{\\mathrm{skew}} = - A^\\top \\, \\mathrm{diag}(\\nu(x)) \\, A$, which corresponds to $v_t = L_{\\mathrm{skew}} v$ and mimics the energy identity obtained by integration by parts with homogeneous Dirichlet boundary conditions.\n\nFor a fixed discrete energy $E_h(v) = \\tfrac{1}{2} v^\\top v$ based on the Euclidean inner product on the interior degrees of freedom, the instantaneous discrete energy variation associated with an operator $L \\in \\mathbb{R}^{(n-1)\\times(n-1)}$ is determined by the symmetric part $S(L) = \\tfrac{1}{2}(L + L^\\top)$ via $\\tfrac{d}{dt} E_h(v) = v^\\top S(L) v$. A necessary and sufficient condition for monotone non-increasing discrete energy for all $v$ is that the largest eigenvalue of $S(L)$ be less than or equal to $0$. In the continuous limit and under suitable summation-by-parts structure, the skew-symmetric form should yield non-positive discrete energy rates, whereas the naive conservative collocation $D(\\nu D u)$ may fail to be energy dissipative under the Euclidean inner product when $\\nu(x)$ is non-uniform.\n\nYour task is to implement a program that, for a set of prescribed test cases, constructs $D$, $A$, $B$, assembles $L_{\\mathrm{cons}}$ and $L_{\\mathrm{skew}}$ for each viscosity profile $\\nu(x)$, forms the symmetric parts $S(L_{\\mathrm{cons}})$ and $S(L_{\\mathrm{skew}})$, and computes the largest eigenvalue of each symmetric part. All trigonometric function arguments are in radians. The final outputs must be real-valued floats.\n\nStarting only from the definitions above and from properties of the Chebyshev–Gauss–Lobatto grid and differentiation matrix, derive the operators and design an algorithm that robustly computes the largest eigenvalues of the symmetric parts. Explain why the skew-symmetric (energy-form) operator enforces non-positivity of the discrete energy variation for any nonnegative $\\nu(x)$ when measured in the Euclidean inner product, and why the conservative flux-form need not. Do not use or assume any external formulas beyond these core definitions.\n\nTest Suite. For each case, set $n$ and $\\nu(x)$ as follows, where $\\cos$ denotes the cosine function with arguments in radians:\n\n- Case $1$: $n = 16$, $\\nu(x) = 1 + 0.5\\,x$.\n- Case $2$: $n = 32$, $\\nu(x) = 1 + 0.9 \\cos(3 \\pi x)$.\n- Case $3$: $n = 24$, $\\nu(x) = \\exp(5 x)$.\n- Case $4$: $n = 28$, $\\nu(x) = 0.01 + \\tfrac{1}{2}(x+1)$.\n- Case $5$: $n = 30$, $\\nu(x) = \\begin{cases}1, & x < 0,\\\\ 3, & x \\ge 0.\\end{cases}$\n\nFor each case, compute two floats:\n\n- $\\lambda_{\\max}^{\\mathrm{cons}}$, the largest eigenvalue of $S(L_{\\mathrm{cons}})$.\n- $\\lambda_{\\max}^{\\mathrm{skew}}$, the largest eigenvalue of $S(L_{\\mathrm{skew}})$.\n\nFinal Output Format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as $[\\lambda_{\\max,1}^{\\mathrm{cons}}, \\lambda_{\\max,1}^{\\mathrm{skew}}, \\lambda_{\\max,2}^{\\mathrm{cons}}, \\lambda_{\\max,2}^{\\mathrm{skew}}, \\dots, \\lambda_{\\max,5}^{\\mathrm{cons}}, \\lambda_{\\max,5}^{\\mathrm{skew}}]$. Round each float to six decimal places before printing.\n\nThere are no physical units in this problem. Angles in trigonometric functions are measured in radians. Ensure all operations are numerically stable for the given values of $n$ and that $\\nu(x) \\ge 0$ for all nodes $x$ in each test case.", "solution": "The problem statement has been validated and is deemed sound. It is well-posed, scientifically grounded in the theory of numerical methods for partial differential equations, and contains all necessary information to proceed with a solution.\n\nThe problem asks for an analysis and computation related to two different spectral collocation discretizations of the variable-coefficient diffusion equation $u_t = (\\nu(x) u_x)_x$ on the domain $x \\in [-1,1]$ with homogeneous Dirichlet boundary conditions $u(-1,t)=u(1,t)=0$. The analysis revolves around the concept of discrete energy stability.\n\n**1. Discrete Energy Analysis**\n\nThe evolution of the solution in the semi-discretized system is given by the ordinary differential equation (ODE) system $\\frac{d v}{dt} = L v$, where $v(t) \\in \\mathbb{R}^{n-1}$ is the vector of solution values at the interior Chebyshev nodes, and $L \\in \\mathbb{R}^{(n-1)\\times(n-1)}$ is the discrete spatial operator.\n\nThe problem defines a discrete energy based on the Euclidean inner product on the interior degrees of freedom:\n$$E_h(v) = \\frac{1}{2} v^\\top v$$\nThe time rate of change of this discrete energy is:\n$$ \\frac{d}{dt} E_h(v) = \\frac{1}{2} \\frac{d}{dt} (v^\\top v) = \\frac{1}{2} \\left( \\frac{dv^\\top}{dt} v + v^\\top \\frac{dv}{dt} \\right) $$\nSubstituting $\\frac{dv}{dt} = L v$, we get:\n$$ \\frac{d}{dt} E_h(v) = \\frac{1}{2} \\left( (Lv)^\\top v + v^\\top (Lv) \\right) = \\frac{1}{2} \\left( v^\\top L^\\top v + v^\\top L v \\right) = v^\\top \\left( \\frac{L + L^\\top}{2} \\right) v $$\nLet $S(L) = \\frac{1}{2} (L + L^\\top)$ be the symmetric part of the operator $L$. The energy rate is then expressed as the quadratic form $v^\\top S(L) v$.\n\nFor the numerical scheme to be energy-dissipative (or more precisely, non-energy-increasing), this rate must be non-positive for any state vector $v$. This means the matrix $S(L)$ must be negative semi-definite. A necessary and sufficient condition for a symmetric matrix to be negative semi-definite is that all of its eigenvalues are non-positive. Consequently, the scheme is guaranteed to be energy-dissipative if and only if the largest eigenvalue of $S(L)$ satisfies $\\lambda_{\\max}(S(L)) \\le 0$.\n\n**2. Analysis of the Skew-Symmetric (Energy-Form) Operator $L_{\\mathrm{skew}}$**\n\nThe energy-form operator is defined as $L_{\\mathrm{skew}} = -A^\\top N A$, where $N = \\mathrm{diag}(\\nu(x_j))$ is the diagonal matrix of viscosity values at the nodes, and $A=D(:,I)$ is the submatrix of the Chebyshev differentiation matrix $D$ corresponding to interior node columns. The vector $w = Av$ represents the discrete derivative of the function (with zero boundary values) evaluated at all grid points.\n\nLet us find the symmetric part of $L_{\\mathrm{skew}}$:\n$$ S(L_{\\mathrm{skew}}) = \\frac{1}{2} (L_{\\mathrm{skew}} + L_{\\mathrm{skew}}^\\top) = \\frac{1}{2} \\left( -A^\\top N A + (-A^\\top N A)^\\top \\right) $$\nUsing the property $(XYZ)^\\top = Z^\\top Y^\\top X^\\top$ and noting that $N$ is a diagonal matrix (hence symmetric, $N^\\top = N$), we have:\n$$ S(L_{\\mathrm{skew}}) = \\frac{1}{2} \\left( -A^\\top N A - A^\\top N^\\top (A^\\top)^\\top \\right) = \\frac{1}{2} \\left( -A^\\top N A - A^\\top N A \\right) = -A^\\top N A = L_{\\mathrm{skew}} $$\nThis shows that $L_{\\mathrm{skew}}$ is itself a symmetric matrix.\n\nThe energy variation is given by the quadratic form:\n$$ v^\\top S(L_{\\mathrm{skew}}) v = v^\\top (-A^\\top N A) v = -(Av)^\\top N (Av) $$\nLetting $w = Av \\in \\mathbb{R}^{n+1}$, the expression becomes:\n$$ -w^\\top N w = - \\sum_{j=0}^{n} w_j^2 N_{jj} = - \\sum_{j=0}^{n} \\nu(x_j) w_j^2 $$\nGiven that the problem specifies $\\nu(x) \\ge 0$, it follows that $\\nu(x_j) \\ge 0$ for all nodes $x_j$. Since $w_j^2 \\ge 0$, each term in the sum is non-negative. Therefore, the total sum is non-negative, and the quadratic form is non-positive:\n$$ \\frac{d}{dt} E_h(v) = - \\sum_{j=0}^{n} \\nu(x_j) w_j^2 \\le 0 $$\nThis holds for any vector $v$. Thus, $S(L_{\\mathrm{skew}})$ is negative semi-definite, and its largest eigenvalue must be less than or equal to zero, $\\lambda_{\\max}(S(L_{\\mathrm{skew}})) \\le 0$. This formulation guarantees discrete energy stability for any non-negative viscosity function $\\nu(x)$.\n\n**3. Analysis of the Conservative Flux-Form Operator $L_{\\mathrm{cons}}$**\n\nThe conservative-form operator is defined as $L_{\\mathrm{cons}} = B N A$, where $B=D(I,:)$ is the restriction of $D$ to its interior rows. This form directly discretizes the equation in flux form, $u_t = (\\nu u_x)_x$, by consecutively applying the differentiation operator: first to get $u_x$, then multiplying by $\\nu$, and finally differentiating the product $\\nu u_x$.\n\nThe symmetric part of this operator is:\n$$ S(L_{\\mathrm{cons}}) = \\frac{1}{2} (L_{\\mathrm{cons}} + L_{\\mathrm{cons}}^\\top) = \\frac{1}{2} (B N A + (B N A)^\\top) = \\frac{1}{2} (B N A + A^\\top N^\\top B^\\top) = \\frac{1}{2} (B N A + A^\\top N B^\\top) $$\nIn the continuous setting, stability is proven using integration by parts, which effectively relates the operator $(\\cdot)_x$ to its negative adjoint $-(\\cdot)_x$ under an appropriate inner product and boundary conditions. In the discrete setting, a similar property, known as summation-by-parts (SBP), is needed for $D$ to ensure stability. The Chebyshev differentiation matrix $D$ does not satisfy the SBP property with respect to the standard Euclidean inner product (where the quadrature matrix is the identity). Instead, it satisfies a SBP property with respect to a non-identity diagonal matrix of Clenshaw-Curtis quadrature weights.\n\nBecause the discrete energy $E_h(v) = \\frac{1}{2} v^\\top v$ is defined with the unweighted Euclidean inner product, there is a mismatch. There is no general algebraic property linking $B$ and $A^\\top$ (which are sub-blocks of $D$ and $D^\\top$) that would ensure the matrix $S(L_{\\mathrm{cons}})$ is negative semi-definite for any non-negative diagonal matrix $N$. While for constant $\\nu(x)$ this form is typically stable, for a general non-constant $\\nu(x)$, the quadratic form $v^\\top S(L_{\\mathrm{cons}}) v$ has no guaranteed sign. It is possible for $S(L_{\\mathrm{cons}})$ to have positive eigenvalues, leading to a spurious growth in discrete energy.\n\n**4. Algorithm Implementation**\n\nThe algorithm to compute the required eigenvalues proceeds as follows for each test case $(n, \\nu(x))$:\n1.  **Generate Grid**: Compute the $n+1$ Chebyshev–Gauss–Lobatto nodes $x_j = \\cos(\\frac{\\pi j}{n})$ for $j=0, \\dots, n$.\n2.  **Construct Differentiation Matrix $D$**: An $(n+1) \\times (n+1)$ matrix $D$ is constructed using the standard explicit formulas for its entries. The diagonal entries are computed via the sum-of-rows condition: $D_{ii} = -\\sum_{j\\ne i} D_{ij}$ for numerical stability.\n3.  **Form Boundary-Condition Matrices**: The matrices for handling homogeneous Dirichlet boundary conditions are extracted from $D$:\n    - $A = D(:, I)$ consists of columns $1, \\dots, n-1$ of $D$. This maps the $(n-1)$ interior values to derivatives at all $n+1$ nodes.\n    - $B = D(I, :)$ consists of rows $1, \\dots, n-1$ of $D$. This represents the differentiation operator restricted to interior points.\n4.  **Assemble Operators**:\n    - The diagonal viscosity matrix $N = \\mathrm{diag}(\\nu(x_j))$ is formed.\n    - The operators are assembled via matrix multiplication: $L_{\\mathrm{cons}} = B N A$ and $L_{\\mathrm{skew}} = -A^\\top N A$.\n5.  **Compute Eigenvalues**:\n    - The symmetric parts, $S(L_{\\mathrm{cons}}) = \\frac{1}{2}(L_{\\mathrm{cons}} + L_{\\mathrm{cons}}^\\top)$ and $S(L_{\\mathrm{skew}}) = \\frac{1}{2}(L_{\\mathrm{skew}} + L_{\\mathrm{skew}}^\\top)$, are formed.\n    - The eigenvalues of these real symmetric matrices are computed. The largest eigenvalue, $\\lambda_{\\max}$, is identified for each. `numpy.linalg.eigvalsh` is ideal for this task as it is optimized for symmetric matrices and returns sorted eigenvalues.\n\nThis procedure is systematically applied to each test case to generate the final results.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef build_chebyshev_diff_matrix(n):\n    \"\"\"\n    Constructs the Chebyshev differentiation matrix for n+1 Chebyshev-Gauss-Lobatto nodes.\n\n    Args:\n        n (int): The degree of the polynomial, corresponding to n+1 grid points.\n\n    Returns:\n        tuple[np.ndarray, np.ndarray]: A tuple containing:\n            - D (np.ndarray): The (n+1)x(n+1) Chebyshev differentiation matrix.\n            - x (np.ndarray): The n+1 Chebyshev-Gauss-Lobatto nodes.\n    \"\"\"\n    if n == 0:\n        return np.array([[0.0]]), np.array([1.0])\n    N_plus_1 = n + 1\n    # Generate Chebyshev-Gauss-Lobatto nodes\n    x = np.cos(np.pi * np.arange(N_plus_1) / n)\n\n    # Weights c_j (not c_j*(-1)^j)\n    c = np.ones(N_plus_1)\n    c[0] = 2.0\n    c[n] = 2.0\n\n    # Vectorized computation of off-diagonal entries\n    # D_ij = (c_i / c_j) * (-1)^(i+j) / (x_i - x_j) for i != j\n    x_col = x.reshape(-1, 1)\n    x_row = x.reshape(1, -1)\n    dX = x_col - x_row\n    \n    indices = np.arange(N_plus_1)\n    i_col = indices.reshape(-1, 1)\n    j_row = indices.reshape(1, -1)\n    sign_matrix = (-1.0)**(i_col + j_row)\n    \n    # Add identity to dX to avoid division by zero on the diagonal\n    D = (c.reshape(-1, 1) / c.reshape(1, -1)) * sign_matrix / (dX + np.eye(N_plus_1))\n    \n    # Set diagonal to zero before summing rows\n    np.fill_diagonal(D, 0.0)\n\n    # Compute diagonal entries: D_ii = -sum(D_ij for j!=i)\n    row_sums = np.sum(D, axis=1)\n    np.fill_diagonal(D, -row_sums)\n    \n    return D, x\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test suite.\n    For each case, it constructs the conservative and skew-symmetric operators,\n    forms their symmetric parts, and computes the largest eigenvalue of each.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (16, lambda x: 1 + 0.5 * x),\n        (32, lambda x: 1 + 0.9 * np.cos(3 * np.pi * x)),\n        (24, lambda x: np.exp(5 * x)),\n        (28, lambda x: 0.01 + 0.5 * (x + 1)),\n        (30, lambda x: np.where(x < 0, 1.0, 3.0)),\n    ]\n\n    results = []\n    for n, nu_func in test_cases:\n        # Step 1 & 2: Build differentiation matrix and grid\n        D, x_nodes = build_chebyshev_diff_matrix(n)\n        \n        # Step 3: Build submatrices A and B for boundary conditions\n        # Interior indices are 1, ..., n-1. In Python slicing, this is 1:n.\n        A = D[:, 1:n]  # D maps interior values to derivatives at all nodes\n        B = D[1:n, :]  # D restricts to interior rows\n        \n        # Step 4: Assemble operators\n        # Evaluate viscosity function at the nodes\n        nu_vals = nu_func(x_nodes)\n        Nu = np.diag(nu_vals)\n        \n        # Conservative flux-form operator\n        L_cons = B @ Nu @ A\n        \n        # Skew-symmetric (energy-form) operator\n        L_skew = -A.T @ Nu @ A\n        \n        # Step 5: Form symmetric parts\n        S_cons = 0.5 * (L_cons + L_cons.T)\n        S_skew = 0.5 * (L_skew + L_skew.T)\n        \n        # Step 6: Compute largest eigenvalue of each symmetric part\n        # eigvalsh returns sorted eigenvalues, so the largest is the last one.\n        lambda_max_cons = np.linalg.eigvalsh(S_cons)[-1]\n        lambda_max_skew = np.linalg.eigvalsh(S_skew)[-1]\n        \n        results.append(lambda_max_cons)\n        results.append(lambda_max_skew)\n\n    # Final print statement in the exact required format.\n    formatted_results = ','.join([f\"{r:.6f}\" for r in results])\n    print(f\"[{formatted_results}]\")\n\nsolve()\n```", "id": "3368959"}]}