{"hands_on_practices": [{"introduction": "Mastering the fundamentals of positivity-preserving limiters begins with understanding their core mechanism in a simplified setting. This practice guides you through the application of a Zhang-Shu type scaling limiter to a one-dimensional, high-degree polynomial. By computing subcell averages and deriving the necessary scaling factor, you will gain direct experience with how these limiters conservatively adjust a solution to enforce a minimum value, providing a foundational skill for more complex applications. [@problem_id:3409657]", "problem": "Consider the one-dimensional reference element $K=[-1,1]$ in a Discontinuous Galerkin (DG) discretization with polynomial degree $p=3$. Let the scalar field be represented by the polynomial\n$$\nu(x)=\\alpha_{0}+\\alpha_{1}x+\\alpha_{2}x^{2}+\\alpha_{3}x^{3},\n$$\nwith coefficients $\\alpha_{0}=\\frac{1}{5}$, $\\alpha_{1}=\\frac{1}{2}$, $\\alpha_{2}=-\\frac{2}{5}$, and $\\alpha_{3}=-\\frac{1}{10}$. Assume the positivity floor is specified as $\\epsilon=0.05$, and that positivity is to be enforced on the four equal subcells $K_{1}=[-1,-\\tfrac{1}{2}]$, $K_{2}=[-\\tfrac{1}{2},0]$, $K_{3}=[0,\\tfrac{1}{2}]$, and $K_{4}=[\\tfrac{1}{2},1]$ via a conservative Zhang–Shu-type scaling limiter:\n$$\nu^{+}(x)=\\theta\\big(u(x)-\\bar{u}\\big)+\\bar{u},\n$$\nwhere $\\bar{u}$ is the cell average over $K$ and the scaling factor $\\theta\\in[0,1]$ is chosen minimally so that every subcell average of $u^{+}$ is at least $\\epsilon$.\n\nTasks:\n- Starting from the definition of the cell average and subcell averages as exact integrals of $u(x)$, compute the subcell averages $U_{j}$ of $u(x)$ for $j=1,2,3,4$, and the cell average $\\bar{u}$ over $K$.\n- Derive the admissible range for $\\theta$ required to enforce $U_{j}^{+} \\ge \\epsilon$ for all $j$, where $U_{j}^{+}=\\theta\\big(U_{j}-\\bar{u}\\big)+\\bar{u}$, and determine the minimal such $\\theta$.\n- Using the Legendre–Gauss–Lobatto (LGL) nodes for $p=3$, namely $x_{0}=-1$, $x_{1}=-1/\\sqrt{5}$, $x_{2}=1/\\sqrt{5}$, and $x_{3}=1$, verify that the corrected nodal values $u^{+}(x_{i})$ are bounded by the convexity bounds\n$$\nu^{+}(x_{i})\\in\\big[\\min\\{u(x_{i}),\\bar{u}\\},\\,\\max\\{u(x_{i}),\\bar{u}\\}\\big],\\quad i=0,1,2,3.\n$$\n\nReport the scaling factor $\\theta$ that minimally enforces the subcell positivity. Round your final answer to four significant figures.", "solution": "The problem statement is found to be valid as it is scientifically grounded, well-posed, and objective. It presents a standard problem in the field of numerical methods for conservation laws, specifically concerning positivity-preserving limiters for the Discontinuous Galerkin method. All provided data and definitions are consistent and sufficient for a unique solution.\n\nThe solution process consists of three main parts:\n1.  Computing the cell and subcell averages of the given polynomial.\n2.  Determining the minimal scaling factor $\\theta$ that enforces the positivity constraint on all subcell averages.\n3.  Verifying a convexity property for the limited solution at specified nodes.\n\nThe scalar field is given by the polynomial $u(x)=\\alpha_{0}+\\alpha_{1}x+\\alpha_{2}x^{2}+\\alpha_{3}x^{3}$ on the reference element $K=[-1,1]$. The coefficients are $\\alpha_{0}=\\frac{1}{5}$, $\\alpha_{1}=\\frac{1}{2}$, $\\alpha_{2}=-\\frac{2}{5}$, and $\\alpha_{3}=-\\frac{1}{10}$. The positivity floor is $\\epsilon=0.05$.\n\n**Part 1: Computation of Cell and Subcell Averages**\n\nThe cell average $\\bar{u}$ over the element $K=[-1,1]$ is defined as:\n$$\n\\bar{u} = \\frac{1}{|K|} \\int_{-1}^{1} u(x) \\,dx = \\frac{1}{2} \\int_{-1}^{1} \\left(\\frac{1}{5} + \\frac{1}{2}x - \\frac{2}{5}x^2 - \\frac{1}{10}x^3\\right) \\,dx\n$$\nDue to the symmetry of the integration interval, the integrals of the odd-powered terms ($x$ and $x^3$) are zero.\n$$\n\\bar{u} = \\frac{1}{2} \\int_{-1}^{1} \\left(\\frac{1}{5} - \\frac{2}{5}x^2\\right) \\,dx = \\frac{1}{2} \\left[\\frac{1}{5}x - \\frac{2}{15}x^3\\right]_{-1}^{1} = \\frac{1}{2} \\left( \\left(\\frac{1}{5} - \\frac{2}{15}\\right) - \\left(-\\frac{1}{5} + \\frac{2}{15}\\right) \\right) = \\frac{1}{5} - \\frac{2}{15} = \\frac{3-2}{15} = \\frac{1}{15}\n$$\n\nThe subcell averages $U_j$ for $j=1,2,3,4$ are computed over the subcells $K_1=[-1, -\\frac{1}{2}]$, $K_2=[-\\frac{1}{2}, 0]$, $K_3=[0, \\frac{1}{2}]$, and $K_4=[\\frac{1}{2}, 1]$. Each subcell has length $|K_j| = \\frac{1}{2}$. The average is $U_j = \\frac{1}{|K_j|} \\int_{K_j} u(x) \\,dx = 2 \\int_{K_j} u(x) \\,dx$.\nLet's first find the indefinite integral of $u(x)$:\n$$\nI(x) = \\int \\left(\\frac{1}{5} + \\frac{1}{2}x - \\frac{2}{5}x^2 - \\frac{1}{10}x^3\\right) \\,dx = \\frac{1}{5}x + \\frac{1}{4}x^2 - \\frac{2}{15}x^3 - \\frac{1}{40}x^4 + C\n$$\nNow we compute the definite integrals for each subcell.\nFor $K_1=[-1, -\\frac{1}{2}]$:\n$I(-1) = -\\frac{1}{5} + \\frac{1}{4} + \\frac{2}{15} - \\frac{1}{40} = \\frac{-24+30+16-3}{120} = \\frac{19}{120}$.\n$I(-\\frac{1}{2}) = -\\frac{1}{10} + \\frac{1}{16} + \\frac{2}{120} - \\frac{1}{640} = \\frac{-192+120+32-3}{1920} = -\\frac{43}{1920}$.\n$U_1 = 2 \\left(I(-\\frac{1}{2}) - I(-1)\\right) = 2 \\left(-\\frac{43}{1920} - \\frac{19}{120}\\right) = 2 \\left(-\\frac{43}{1920} - \\frac{304}{1920}\\right) = 2 \\left(-\\frac{347}{1920}\\right) = -\\frac{347}{960}$.\n\nFor $K_2=[-\\frac{1}{2}, 0]$:\n$I(0) = 0$.\n$U_2 = 2 \\left(I(0) - I(-\\frac{1}{2})\\right) = 2 \\left(0 - (-\\frac{43}{1920})\\right) = \\frac{43}{960}$.\n\nFor $K_3=[0, \\frac{1}{2}]$:\n$I(\\frac{1}{2}) = \\frac{1}{10} + \\frac{1}{16} - \\frac{2}{120} - \\frac{1}{640} = \\frac{192+120-32-3}{1920} = \\frac{277}{1920}$.\n$U_3 = 2 \\left(I(\\frac{1}{2}) - I(0)\\right) = 2 \\left(\\frac{277}{1920}\\right) = \\frac{277}{960}$.\n\nFor $K_4=[\\frac{1}{2}, 1]$:\n$I(1) = \\frac{1}{5} + \\frac{1}{4} - \\frac{2}{15} - \\frac{1}{40} = \\frac{24+30-16-3}{120} = \\frac{35}{120} = \\frac{7}{24}$.\n$U_4 = 2 \\left(I(1) - I(\\frac{1}{2})\\right) = 2 \\left(\\frac{7}{24} - \\frac{277}{1920}\\right) = 2 \\left(\\frac{560}{1920} - \\frac{277}{1920}\\right) = 2 \\left(\\frac{283}{1920}\\right) = \\frac{283}{960}$.\n\nSummary of averages:\n$\\bar{u} = \\frac{1}{15} = \\frac{64}{960}$.\n$U_1 = -\\frac{347}{960}$.\n$U_2 = \\frac{43}{960}$.\n$U_3 = \\frac{277}{960}$.\n$U_4 = \\frac{283}{960}$.\n\nSanity check: The average of the subcell averages must equal the cell average.\n$\\frac{1}{4}(U_1+U_2+U_3+U_4) = \\frac{1}{4} \\frac{-347+43+277+283}{960} = \\frac{1}{4} \\frac{256}{960} = \\frac{64}{960} = \\frac{1}{15} = \\bar{u}$. The averages are correct.\n\n**Part 2: Determination of the Scaling Factor $\\theta$**\n\nThe positivity constraint requires that the limited subcell averages, $U_j^+$, satisfy $U_j^+ \\ge \\epsilon$ for all $j=1,2,3,4$.\nThe limiter is defined as $u^+(x) = \\theta(u(x)-\\bar{u}) + \\bar{u}$. Applying this to the subcell averages gives $U_j^+ = \\theta(U_j-\\bar{u}) + \\bar{u}$.\nThe constraint is $\\theta(U_j - \\bar{u}) + \\bar{u} \\ge \\epsilon$, which can be rewritten as $\\theta(U_j - \\bar{u}) \\ge \\epsilon - \\bar{u}$.\n\nLet's evaluate the quantities involved using the common denominator $960$.\n$\\epsilon = 0.05 = \\frac{1}{20} = \\frac{48}{960}$.\n$\\bar{u} = \\frac{64}{960}$.\nThe term $\\epsilon - \\bar{u} = \\frac{48-64}{960} = -\\frac{16}{960}$.\nThe differences $U_j - \\bar{u}$ are:\n$U_1 - \\bar{u} = -\\frac{347}{960} - \\frac{64}{960} = -\\frac{411}{960}$.\n$U_2 - \\bar{u} = \\frac{43}{960} - \\frac{64}{960} = -\\frac{21}{960}$.\n$U_3 - \\bar{u} = \\frac{277}{960} - \\frac{64}{960} = \\frac{213}{960}$.\n$U_4 - \\bar{u} = \\frac{283}{960} - \\frac{64}{960} = \\frac{219}{960}$.\n\nWe must find $\\theta \\in [0,1]$ that satisfies the constraints. The phrase \"chosen minimally\" can be ambiguous. In the context of limiters, this standardly refers to the minimal modification of the solution, which means choosing the largest possible $\\theta \\in [0,1]$ that satisfies the constraints. Any smaller $\\theta$ would represent a more aggressive (less minimal) limiting.\n\nLet's analyze the inequality $\\theta(U_j - \\bar{u}) \\ge \\epsilon - \\bar{u}$ for each $j$:\n- For $j=3, 4$: $U_j - \\bar{u} > 0$. The inequality is $\\theta \\ge \\frac{\\epsilon-\\bar{u}}{U_j-\\bar{u}}$. Since $\\epsilon - \\bar{u} < 0$, this yields a negative lower bound for $\\theta$. As $\\theta \\in [0,1]$, this constraint is non-binding.\n- For $j=1, 2$: $U_j - \\bar{u} < 0$. Dividing by a negative number reverses the inequality sign: $\\theta \\le \\frac{\\epsilon-\\bar{u}}{U_j-\\bar{u}}$.\nFor $j=1$: $\\theta \\le \\frac{-16/960}{-411/960} = \\frac{16}{411}$.\nFor $j=2$: $\\theta \\le \\frac{-16/960}{-21/960} = \\frac{16}{21}$.\nTo satisfy both constraints simultaneously, $\\theta$ must be less than or equal to the minimum of these upper bounds:\n$\\theta \\le \\min\\left(\\frac{16}{411}, \\frac{16}{21}\\right)$. since $411 > 21$, we have $\\frac{16}{411} < \\frac{16}{21}$.\nThe constraint on $\\theta$ is $\\theta \\le \\frac{16}{411}$.\n\nTo minimally modify the solution, we choose the largest possible $\\theta$, which is the upper bound itself.\n$$\n\\theta = \\frac{16}{411}\n$$\nThis corresponds to the standard Zhang--Shu limiter formula for the case $\\bar{u} > \\epsilon$: $\\theta = \\min\\left(1, \\frac{\\bar{u}-\\epsilon}{\\bar{u}-m}\\right)$, where $m=\\min_j U_j = U_1$.\n$\\theta = \\frac{1/15 - 1/20}{1/15 - (-347/960)} = \\frac{(4-3)/60}{(64+347)/960} = \\frac{1/60}{411/960} = \\frac{1}{60} \\frac{960}{411} = \\frac{16}{411}$.\n\n**Part 3: Verification of Convexity Bounds**\n\nThe task is to verify that for the Legendre-Gauss-Lobatto (LGL) nodes $x_i$, the corrected nodal values satisfy $u^{+}(x_{i})\\in\\big[\\min\\{u(x_{i}),\\bar{u}\\},\\,\\max\\{u(x_{i}),\\bar{u}\\}\\big]$.\nThe corrected solution is given by:\n$$\nu^{+}(x_i) = \\theta u(x_i) + (1-\\theta)\\bar{u}\n$$\nWe found $\\theta = \\frac{16}{411}$, which is in the interval $[0,1]$. Therefore, $u^+(x_i)$ is a convex combination of the values $u(x_i)$ and $\\bar{u}$.\nBy the definition of a convex combination, the resulting value $u^+(x_i)$ must lie in the closed interval between $u(x_i)$ and $\\bar{u}$. This interval is precisely $[\\min\\{u(x_i), \\bar{u}\\}, \\max\\{u(x_i), \\bar{u}\\}]$.\nThis property holds for any $\\theta \\in [0,1]$ and thus is verified for our calculated $\\theta$ without needing to compute the numerical values of $u(x_i)$ and $u^+(x_i)$ at the LGL nodes. The verification is a direct consequence of the limiter's mathematical form.\n\n**Final Answer Calculation**\nThe scaling factor is $\\theta = \\frac{16}{411}$. To provide the numerical answer rounded to four significant figures:\n$\\theta = \\frac{16}{411} \\approx 0.03892944...$\nThe first four significant figures are $3$, $8$, $9$, $2$. The next digit is $9$, which is $\\ge 5$, so we round up the last significant digit.\n$\\theta \\approx 0.03893$.", "answer": "$$\\boxed{0.03893}$$", "id": "3409657"}, {"introduction": "Building on the one-dimensional case, this exercise extends the concept of a scaling limiter to a two-dimensional triangular element, a common building block in many Discontinuous Galerkin simulations. You will apply the same principles of rescaling the solution around its mean, but now the positivity constraint must be enforced at a set of specific quadrature points within the triangle. This practice highlights how the core idea of limiting remains consistent across dimensions, while demonstrating a practical method for ensuring positivity in more complex geometries. [@problem_id:3409716]", "problem": "Consider a single triangular element in a Discontinuous Galerkin (DG) method for a hyperbolic conservation law, where the elementwise approximation represents a nonnegative scalar field (e.g., a density). The element is the reference triangle with vertices at $(0,0)$, $(1,0)$, and $(0,1)$. The polynomial degree is $p=2$. The elementwise approximation is\n$$\nu_h(x,y) \\;=\\; 1 \\;-\\; \\frac{5}{2}\\,x^2.\n$$\nA linear scaling positivity-preserving limiter is applied in the canonical form of rescaling around the cell average so that for a chosen parameter $\\theta \\in [0,1]$ the limited field is\n$$\nu^{\\theta}(x,y) \\;=\\; \\bar{u} \\;+\\; \\theta\\,\\big(u_h(x,y) - \\bar{u}\\big).\n$$\nHere $\\bar{u}$ is the exact cell average of $u_h$ over the element. The limiter is required to enforce nonnegativity at the volumetric check points given by the degree-$2$ Dunavant quadrature nodes, i.e., the three barycentric permutations of $(2/3,1/6,1/6)$, which in Cartesian coordinates for this reference triangle are\n$$\n(x_1,y_1)=\\Big(\\frac{1}{6},\\frac{1}{6}\\Big),\\quad (x_2,y_2)=\\Big(\\frac{2}{3},\\frac{1}{6}\\Big),\\quad (x_3,y_3)=\\Big(\\frac{1}{6},\\frac{2}{3}\\Big).\n$$\nStarting from first principles of the linear scaling limiter, determine the largest $\\theta \\in [0,1]$ such that $u^{\\theta}(x_q,y_q) \\ge 0$ at all three Dunavant nodes $(x_q,y_q)$ listed above. Compute $\\bar{u}$ exactly from its definition as the element average and carry out all evaluations exactly. Provide your final $\\theta$ as an exact rational number. No rounding is required and no units are involved.", "solution": "The problem requires finding the largest parameter $\\theta \\in [0,1]$ for a linear scaling positivity-preserving limiter such that the limited approximation $u^{\\theta}(x,y)$ remains non-negative at a specified set of check points.\n\nThe given element is the reference triangle $K$ with vertices at $(0,0)$, $(1,0)$, and $(0,1)$. Its area is $|K| = \\frac{1}{2} \\times \\text{base} \\times \\text{height} = \\frac{1}{2}(1)(1) = \\frac{1}{2}$.\n\nThe unlimited approximation is given by the quadratic polynomial:\n$$\nu_h(x,y) = 1 - \\frac{5}{2}x^2\n$$\n\nThe limited approximation is defined as:\n$$\nu^{\\theta}(x,y) = \\bar{u} + \\theta \\left( u_h(x,y) - \\bar{u} \\right)\n$$\nwhere $\\bar{u}$ is the cell average of $u_h$ over the element $K$.\n\nThe constraint to be enforced is $u^{\\theta}(x_q,y_q) \\ge 0$ at the three specified Dunavant quadrature nodes $(x_q, y_q)$. This translates to:\n$$\n\\bar{u} + \\theta \\left( u_h(x_q, y_q) - \\bar{u} \\right) \\ge 0\n$$\nfor each check point $q \\in \\{1,2,3\\}$. This inequality can be rearranged to find a constraint on $\\theta$. The nature of the constraint depends on the sign of the term $u_h(x_q, y_q) - \\bar{u}$.\n\nLet's analyze the inequality:\n1.  If $u_h(x_q, y_q) - \\bar{u} > 0$, the inequality is $\\theta \\ge \\frac{-\\bar{u}}{u_h(x_q, y_q) - \\bar{u}}$. If we find that $\\bar{u} > 0$, this provides a non-positive lower bound for $\\theta$. Since $\\theta \\in [0,1]$, this condition is trivially satisfied and imposes no upper bound on $\\theta$.\n2.  If $u_h(x_q, y_q) - \\bar{u} < 0$, we must divide by a negative number, which reverses the inequality sign:\n    $$\n    \\theta \\le \\frac{-\\bar{u}}{u_h(x_q, y_q) - \\bar{u}} = \\frac{\\bar{u}}{\\bar{u} - u_h(x_q, y_q)}\n    $$\n    This imposes an upper bound on $\\theta$.\n\nTo satisfy the non-negativity at all check points, $\\theta$ must be less than or equal to the minimum of all such upper bounds over all relevant points. The largest permissible $\\theta\n$ is therefore:\n$$\n\\theta_{\\text{max}} = \\min\\left(1, \\min_{q \\text{ s.t. } u_h(x_q,y_q) < \\bar{u}} \\left\\{ \\frac{\\bar{u}}{\\bar{u} - u_h(x_q,y_q)} \\right\\} \\right)\n$$\n\nThe solution proceeds in three steps:\n1.  Compute the exact cell average $\\bar{u}$.\n2.  Evaluate $u_h(x,y)$ at the three check points.\n3.  Use these values to determine the constraints on $\\theta$ and find the largest possible value.\n\n**Step 1: Compute the cell average $\\bar{u}$**\nThe cell average is defined as $\\bar{u} = \\frac{1}{|K|} \\int_K u_h(x,y) \\,dA$.\n$$\n\\bar{u} = \\frac{1}{1/2} \\int_0^1 \\int_0^{1-x} \\left(1 - \\frac{5}{2}x^2\\right) \\,dy\\,dx\n$$\n$$\n\\bar{u} = 2 \\int_0^1 \\left[ \\left(1 - \\frac{5}{2}x^2\\right)y \\right]_{y=0}^{y=1-x} \\,dx = 2 \\int_0^1 \\left(1 - \\frac{5}{2}x^2\\right)(1-x) \\,dx\n$$\nExpanding the integrand:\n$$\n\\bar{u} = 2 \\int_0^1 \\left(1 - x - \\frac{5}{2}x^2 + \\frac{5}{2}x^3\\right) \\,dx\n$$\nIntegrating term by term:\n$$\n\\bar{u} = 2 \\left[ x - \\frac{x^2}{2} - \\frac{5}{2}\\frac{x^3}{3} + \\frac{5}{2}\\frac{x^4}{4} \\right]_0^1 = 2 \\left( 1 - \\frac{1}{2} - \\frac{5}{6} + \\frac{5}{8} \\right)\n$$\n$$\n\\bar{u} = 2 \\left( \\frac{1}{2} - \\frac{5}{6} + \\frac{5}{8} \\right) = 2 \\left( \\frac{12}{24} - \\frac{20}{24} + \\frac{15}{24} \\right) = 2 \\left( \\frac{12 - 20 + 15}{24} \\right) = 2 \\left( \\frac{7}{24} \\right)\n$$\n$$\n\\bar{u} = \\frac{14}{24} = \\frac{7}{12}\n$$\nSince $\\bar{u} = 7/12 > 0$, our analysis of the inequality is correct.\n\n**Step 2: Evaluate $u_h(x,y)$ at the check points**\nThe check points are $(x_1,y_1)=(1/6,1/6)$, $(x_2,y_2)=(2/3,1/6)$, and $(x_3,y_3)=(1/6,2/3)$.\nThe function is $u_h(x,y) = 1 - \\frac{5}{2}x^2$. Note that $u_h$ is independent of $y$.\n\nFor $(x_1,y_1) = (1/6, 1/6)$:\n$$\nu_{h,1} = u_h\\left(\\frac{1}{6}, \\frac{1}{6}\\right) = 1 - \\frac{5}{2}\\left(\\frac{1}{6}\\right)^2 = 1 - \\frac{5}{2}\\left(\\frac{1}{36}\\right) = 1 - \\frac{5}{72} = \\frac{67}{72}\n$$\n\nFor $(x_2,y_2) = (2/3, 1/6)$:\n$$\nu_{h,2} = u_h\\left(\\frac{2}{3}, \\frac{1}{6}\\right) = 1 - \\frac{5}{2}\\left(\\frac{2}{3}\\right)^2 = 1 - \\frac{5}{2}\\left(\\frac{4}{9}\\right) = 1 - \\frac{10}{9} = -\\frac{1}{9}\n$$\n\nFor $(x_3,y_3) = (1/6, 2/3)$:\n$$\nu_{h,3} = u_h\\left(\\frac{1}{6}, \\frac{2}{3}\\right) = 1 - \\frac{5}{2}\\left(\\frac{1}{6}\\right)^2 = 1 - \\frac{5}{72} = \\frac{67}{72}\n$$\n\n**Step 3: Determine the constraints on $\\theta$**\nWe must find the points where $u_h(x_q, y_q) < \\bar{u}$.\nWe have $\\bar{u} = \\frac{7}{12} = \\frac{42}{72}$.\nThe values at the check points are $u_{h,1} = \\frac{67}{72}$, $u_{h,2} = -\\frac{1}{9} = -\\frac{8}{72}$, and $u_{h,3} = \\frac{67}{72}$.\n\n- For points $1$ and $3$: $u_h = \\frac{67}{72} > \\frac{42}{72} = \\bar{u}$. As determined earlier, these points do not impose an upper bound on $\\theta$.\n\n- For point $2$: $u_{h,2} = -\\frac{8}{72} < \\frac{42}{72} = \\bar{u}$. This point imposes an upper bound on $\\theta$:\n$$\n\\theta \\le \\frac{\\bar{u}}{\\bar{u} - u_{h,2}}\n$$\nSubstituting the values:\n$$\n\\theta \\le \\frac{\\frac{7}{12}}{\\frac{7}{12} - \\left(-\\frac{1}{9}\\right)} = \\frac{\\frac{7}{12}}{\\frac{7}{12} + \\frac{1}{9}}\n$$\nTo evaluate the denominator, we find a common multiple of $12$ and $9$, which is $36$:\n$$\n\\frac{7}{12} + \\frac{1}{9} = \\frac{7 \\times 3}{36} + \\frac{1 \\times 4}{36} = \\frac{21+4}{36} = \\frac{25}{36}\n$$\nSubstituting this back into the inequality for $\\theta$:\n$$\n\\theta \\le \\frac{\\frac{7}{12}}{\\frac{25}{36}} = \\frac{7}{12} \\times \\frac{36}{25} = \\frac{7 \\times 3}{25} = \\frac{21}{25}\n$$\n\nThe only upper bound from the non-negativity constraints is $\\theta \\le \\frac{21}{25}$. We also have the definitional constraint $\\theta \\in [0,1]$.\nThe final condition is $\\theta \\le \\min\\left(1, \\frac{21}{25}\\right)$. Since $\\frac{21}{25} < 1$, the minimum is $\\frac{21}{25}$.\nTherefore, the largest permissible value for $\\theta$ is $\\frac{21}{25}$.", "answer": "$$ \\boxed{\\frac{21}{25}} $$", "id": "3409716"}, {"introduction": "While scaling limiters are effective, an alternative and often more robust approach involves a change of basis. This computational exercise explores the unique properties of the Bernstein polynomial basis, whose coefficients directly control the bounds of the polynomial. You will implement a change-of-basis transform from a standard modal basis (like Legendre) to the Bernstein basis, apply simple clipping to the Bernstein coefficients to enforce positivity and boundedness, and transform back. This powerful technique offers a guaranteed method for preserving bounds and provides insight into the deep connection between the choice of basis and the physical properties of the numerical solution. [@problem_id:3409697]", "problem": "Consider a one-dimensional reference element with coordinate $x \\in [-1,1]$ and its affine mapping to the unit interval $t \\in [0,1]$ given by $t = (x+1)/2$. In a Discontinuous Galerkin (DG) method, an approximate solution $u_h$ on an element is represented as a degree-$n$ polynomial in a chosen basis. Three classical bases are: the Legendre polynomial basis $\\{P_k(x)\\}_{k=0}^n$, the Chebyshev polynomial basis of the first kind $\\{T_k(x)\\}_{k=0}^n$, and the Bernstein polynomial basis $\\{B_k^n(t)\\}_{k=0}^n$, where $B_k^n(t) = \\binom{n}{k} t^k (1-t)^{n-k}$. It is known that the Bernstein basis functions are nonnegative on $t \\in [0,1]$ and form a partition of unity, while Legendre and Chebyshev modal functions change sign on $x \\in [-1,1]$. A positivity preserving limiter ensures $u_h \\ge 0$, and a boundedness preserving limiter ensures $0 \\le u_h \\le U$ for a given bound $U$. Coefficient-wise constraints that enforce nonnegativity in modal bases such as Legendre or Chebyshev do not suffice to guarantee pointwise nonnegativity of $u_h$, whereas coefficient-wise constraints in the Bernstein basis do.\n\nStarting from the following fundamental bases and properties:\n- The three-term recurrence for Legendre polynomials: $P_0(x)=1$, $P_1(x)=x$, and $P_{k+1}(x) = \\frac{(2k+1)x P_k(x) - k P_{k-1}(x)}{k+1}$ for $k \\ge 1$.\n- The three-term recurrence for Chebyshev polynomials of the first kind: $T_0(x)=1$, $T_1(x)=x$, and $T_{k+1}(x)=2x T_k(x) - T_{k-1}(x)$ for $k \\ge 1$.\n- The Bernstein basis definition $B_k^n(t) = \\binom{n}{k} t^k (1-t)^{n-k}$ with $B_k^n(t) \\ge 0$ on $t \\in [0,1]$ and $\\sum_{k=0}^n B_k^n(t) = 1$.\n- The fact that evaluating a polynomial at $n+1$ distinct points uniquely determines its coefficients in any degree-$n$ basis via a change-of-basis linear system.\n\nImplement a fast change-of-basis transform to the Bernstein basis for limiting and a transform back to the original modal basis. Use the following approach:\n- Choose the $n+1$ Bernstein nodes $t_j = j/n$ for $j=0,1,\\dots,n$ (all in $[0,1]$), and map them to $x_j = 2t_j - 1 \\in [-1,1]$.\n- Build the evaluation matrix $E^{\\text{L}} \\in \\mathbb{R}^{(n+1)\\times(n+1)}$ for Legendre polynomials evaluated at $\\{x_j\\}$, and similarly $E^{\\text{C}}$ for Chebyshev polynomials at $\\{x_j\\}$, using the stated three-term recurrences.\n- Build the evaluation matrix $E^{\\text{B}} \\in \\mathbb{R}^{(n+1)\\times(n+1)}$ for Bernstein polynomials evaluated at $\\{t_j\\}$.\n- For any coefficient vector in a modal basis, compute the polynomial values at the chosen nodes by multiplying with the corresponding evaluation matrix, then solve the linear system with $E^{\\text{B}}$ to obtain Bernstein coefficients. Similarly, to transform back from Bernstein to a modal basis, multiply by $E^{\\text{B}}$ and solve with the modal evaluation matrix.\n\nUse these transforms to:\n- Demonstrate that nonnegative modal coefficients in the Legendre or Chebyshev basis do not imply $u_h \\ge 0$ on $x \\in [-1,1]$ by constructing counterexamples.\n- Demonstrate that nonnegative coefficients in the Bernstein basis do imply $u_h \\ge 0$ on $t \\in [0,1]$ (equivalently on $x \\in [-1,1]$ via the affine map).\n- Implement a positivity limiter that transforms a modal representation to Bernstein coefficients, clips all Bernstein coefficients below $0$ to $0$, and transforms back.\n- Implement a boundedness limiter that clips Bernstein coefficients to $[0,U]$ for a given bound $U$ and transforms back.\n\nConstruct the following test suite, where each test requires evaluating the resulting polynomial on a dense grid of $x$ values with $1001$ equally spaced points in $[-1,1]$:\n- Test $1$ (degree $n=1$):\n  - Legendre case: coefficients $[0,1]$ (that is, $u_h(x) = P_1(x)$). Report a boolean indicating whether $u_h(x) \\ge 0$ on $[-1,1]$.\n  - Chebyshev case: coefficients $[0,1]$ (that is, $u_h(x) = T_1(x)$). Report a boolean indicating whether $u_h(x) \\ge 0$ on $[-1,1]$.\n  - Bernstein case: coefficients $[0,1]$ (that is, $u_h(t) = B_1^1(t)$). Report a boolean indicating whether $u_h(t) \\ge 0$ on $[0,1]$.\n- Test $2$ (degree $n=3$):\n  - Legendre case: coefficients $[0,0,1,0]$ (that is, $u_h(x) = P_2(x)$). Report a boolean indicating whether $u_h(x) \\ge 0$ on $[-1,1]$.\n  - Chebyshev case: coefficients $[0,0,1,0]$ (that is, $u_h(x) = T_2(x)$). Report a boolean indicating whether $u_h(x) \\ge 0$ on $[-1,1]$.\n  - Bernstein case: coefficients $[0.2,0.3,0.4,0.5]$. Report a boolean indicating whether $u_h(t) \\ge 0$ on $[0,1]$.\n- Test $3$ (degree $n=5$): Legendre case with coefficients $[0.1,1.0,0.0,0.0,0.0,0.0]$. Compute two floats: the minimum value of $u_h(x)$ over $[-1,1]$ before limiting and the minimum value after applying the positivity limiter via Bernstein clipping. Report both floats rounded to six decimal places.\n- Test $4$ (degree $n=4$): Legendre case with coefficients $[0.3,0.9,-0.2,0.1,0.5]$ and bound $U=0.8$. Apply the boundedness limiter via Bernstein clipping to $[0,U]$, transform back, and evaluate on $x \\in [-1,1]$. Report two booleans: whether the limited polynomial satisfies $u_h(x) \\ge 0$ on $[-1,1]$, and whether it satisfies $u_h(x) \\le U$ on $[-1,1]$.\n- Test $5$ (degree $n=0$): Legendre case with coefficients $[-0.2]$. Apply the positivity limiter. Report one float: the minimum value over $[-1,1]$ after limiting, rounded to six decimal places.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the following order:\n$[$Test $1$ Legendre boolean, Test $1$ Chebyshev boolean, Test $1$ Bernstein boolean, Test $2$ Legendre boolean, Test $2$ Chebyshev boolean, Test $2$ Bernstein boolean, Test $3$ minimum before limiting (float rounded to six decimal places), Test $3$ minimum after limiting (float rounded to six decimal places), Test $4$ nonnegativity boolean, Test $4$ boundedness boolean, Test $5$ minimum after limiting (float rounded to six decimal places)$]$.", "solution": "The problem statement is a valid computational exercise in the field of numerical analysis, specifically concerning Discontinuous Galerkin (DG) methods for hyperbolic partial differential equations. It is scientifically grounded, well-posed, objective, and contains all necessary information to construct a unique, verifiable solution. The underlying principles—the properties of Legendre, Chebyshev, and Bernstein polynomial bases, and the use of basis transformations for implementing property-preserving limiters—are fundamental concepts in advanced numerical methods.\n\nThe core of the problem is to implement and utilize a change-of-basis transformation between modal polynomial bases (Legendre, Chebyshev) and the Bernstein polynomial basis. This transformation is pivotal for enforcing physical constraints like positivity or boundedness on the numerical solution $u_h$.\n\nA polynomial $u_h$ of degree $n$ can be expressed in various bases. In a modal basis $\\{\\phi_k(x)\\}_{k=0}^n$ on the reference element $x \\in [-1,1]$, the representation is:\n$$\nu_h(x) = \\sum_{k=0}^n \\hat{u}_k^{\\text{M}} \\phi_k(x)\n$$\nwhere $\\hat{u}_k^{\\text{M}}$ are the modal coefficients (e.g., Legendre or Chebyshev coefficients).\n\nThe same polynomial can be expressed in the Bernstein basis $\\{B_k^n(t)\\}_{k=0}^n$ on the unit interval $t \\in [0,1]$, where $t=(x+1)/2$ is the affine mapping from $x \\in [-1,1]$. The representation is:\n$$\nu_h(t) = \\sum_{k=0}^n \\hat{u}_k^{\\text{B}} B_k^n(t)\n$$\nwhere $B_k^n(t) = \\binom{n}{k} t^k (1-t)^{n-k}$ and $\\hat{u}_k^{\\text{B}}$ are the Bernstein coefficients.\n\nThe transformation between these representations is achieved by collocating the polynomial values at a set of $n+1$ distinct points. The problem specifies using the Bernstein nodes $t_j = j/n$ for $j=0, 1, \\dots, n$, which map to $x_j = 2t_j - 1$. At these nodes, the two representations must be equal:\n$$\n\\sum_{k=0}^n \\hat{u}_k^{\\text{M}} \\phi_k(x_j) = \\sum_{k=0}^n \\hat{u}_k^{\\text{B}} B_k^n(t_j) \\quad \\text{for } j=0, \\dots, n\n$$\nThis equality for all $j$ forms a linear system of equations:\n$$\n\\mathbf{E}^{\\text{M}} \\mathbf{\\hat{u}}^{\\text{M}} = \\mathbf{E}^{\\text{B}} \\mathbf{\\hat{u}}^{\\text{B}}\n$$\nHere, $\\mathbf{\\hat{u}}^{\\text{M}}$ and $\\mathbf{\\hat{u}}^{\\text{B}}$ are the column vectors of modal and Bernstein coefficients, respectively. $\\mathbf{E}^{\\text{M}}$ and $\\mathbf{E}^{\\text{B}}$ are the $(n+1) \\times (n+1)$ evaluation matrices with entries $(\\mathbf{E}^{\\text{M}})_{jk} = \\phi_k(x_j)$ and $(\\mathbf{E}^{\\text{B}})_{jk} = B_k^n(t_j)$. These matrices are invertible. The transformations are therefore given by solving these linear systems:\n-   **Modal to Bernstein**: $\\mathbf{\\hat{u}}^{\\text{B}} = (\\mathbf{E}^{\\text{B}})^{-1} \\mathbf{E}^{\\text{M}} \\mathbf{\\hat{u}}^{\\text{M}}$\n-   **Bernstein to Modal**: $\\mathbf{\\hat{u}}^{\\text{M}} = (\\mathbf{E}^{\\text{M}})^{-1} \\mathbf{E}^{\\text{B}} \\mathbf{\\hat{u}}^{\\text{B}}$\n\nThe utility of the Bernstein basis stems from two key properties:\n$1$. **Non-negativity**: $B_k^n(t) \\ge 0$ for all $k$ and for all $t \\in [0,1]$.\n$2$. **Partition of Unity**: $\\sum_{k=0}^n B_k^n(t) = 1$ for all $t \\in [0,1]$.\n\nThese properties imply that the polynomial $u_h(t)$ is contained within the convex hull of its Bernstein coefficients $\\hat{u}_k^{\\text{B}}$. Specifically, $\\min_k(\\hat{u}_k^{\\text{B}}) \\le u_h(t) \\le \\max_k(\\hat{u}_k^{\\text{B}})$. This provides a direct way to enforce bounds on the polynomial by manipulating its Bernstein coefficients.\n\n-   **Positivity-Preserving Limiter**: To ensure $u_h(x) \\ge 0$, we transform the modal coefficients $\\mathbf{\\hat{u}}^{\\text{M}}$ to Bernstein coefficients $\\mathbf{\\hat{u}}^{\\text{B}}$. We then clip any negative coefficients to zero, creating a new set of coefficients $\\hat{u}_k^{\\text{B}'} = \\max(0, \\hat{u}_k^{\\text{B}})$. The resulting polynomial $u_h'(t) = \\sum_k \\hat{u}_k^{\\text{B}'} B_k^n(t)$ is guaranteed to be non-negative, as it is a non-negative weighted sum of non-negative basis functions. This new set of Bernstein coefficients is then transformed back to the original modal basis to obtain the limited modal coefficients $\\mathbf{\\hat{u}}^{\\text{M}'}$.\n\n-   **Boundedness-Preserving Limiter**: To ensure $0 \\le u_h(x) \\le U$ for some upper bound $U$, a similar procedure is followed. The Bernstein coefficients are clipped to the range $[0, U]$, i.e., $\\hat{u}_k^{\\text{B}'} = \\min(U, \\max(0, \\hat{u}_k^{\\text{B}}))$. The non-negativity $u_h'(t) \\ge 0$ follows as before. The upper bound is guaranteed by the partition of unity property:\n$$\nu_h'(t) = \\sum_{k=0}^n \\hat{u}_k^{\\text{B}'} B_k^n(t) \\le \\sum_{k=0}^n U \\cdot B_k^n(t) = U \\sum_{k=0}^n B_k^n(t) = U \\cdot 1 = U\n$$\n\nThe implementation will proceed by first constructing functions to evaluate the polynomials from their coefficients and generate the necessary evaluation matrices using the specified three-term recurrences. Then, for each test case, the appropriate transformations and limiting procedures will be applied, and the results evaluated on a dense grid of $1001$ points on $x \\in [-1,1]$.\n\nThe test cases are designed to systematically demonstrate these principles:\n-   **Tests $1$ and $2$**: Show that non-negative modal coefficients for Legendre and Chebyshev polynomials can produce polynomials with negative values, while non-negative Bernstein coefficients guarantee a non-negative polynomial.\n-   **Test $3$**: Quantifies the effect of the positivity limiter on a polynomial that violates the non-negativity constraint.\n-   **Test $4$**: Demonstrates that the boundedness limiter correctly enforces both the lower ($0$) and upper ($U$) bounds.\n-   **Test $5$**: A simple case for $n=0$ (a constant function) to verify the limiter's behavior in the most basic scenario.\n\nThe following Python code implements this entire procedure to solve the problem as stated.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import comb\n\ndef eval_legendre(coeffs, x):\n    \"\"\"Evaluates a polynomial in the Legendre basis.\"\"\"\n    n = len(coeffs) - 1\n    if n < 0:\n        return np.zeros_like(x)\n    \n    p_prev = np.ones_like(x)\n    val = coeffs[0] * p_prev\n    \n    if n > 0:\n        p_curr = np.copy(x)\n        val += coeffs[1] * p_curr\n    \n    for k in range(1, n):\n        # P_{k+1}(x) = ((2k+1)x P_k(x) - k P_{k-1}(x)) / (k+1)\n        p_next = ((2 * k + 1) * x * p_curr - k * p_prev) / (k + 1)\n        val += coeffs[k + 1] * p_next\n        p_prev = p_curr\n        p_curr = p_next\n        \n    return val\n\ndef eval_chebyshev(coeffs, x):\n    \"\"\"Evaluates a polynomial in the Chebyshev basis.\"\"\"\n    n = len(coeffs) - 1\n    if n < 0:\n        return np.zeros_like(x)\n    \n    t_prev = np.ones_like(x)\n    val = coeffs[0] * t_prev\n    \n    if n > 0:\n        t_curr = np.copy(x)\n        val += coeffs[1] * t_curr\n        \n    for k in range(1, n):\n        # T_{k+1}(x) = 2x T_k(x) - T_{k-1}(x)\n        t_next = 2 * x * t_curr - t_prev\n        val += coeffs[k + 1] * t_next\n        t_prev = t_curr\n        t_curr = t_next\n        \n    return val\n\ndef eval_bernstein(coeffs, t, n):\n    \"\"\"Evaluates a polynomial in the Bernstein basis.\"\"\"\n    if n < 0:\n        return np.zeros_like(t)\n    \n    val = np.zeros_like(t, dtype=float)\n    for k in range(n + 1):\n        # B_k^n(t) = comb(n, k) * t^k * (1-t)^(n-k)\n        basis_func = comb(n, k) * (t**k) * ((1 - t)**(n - k))\n        val += coeffs[k] * basis_func\n        \n    return val\n\ndef get_eval_matrix(n, basis, nodes):\n    \"\"\"Generates the evaluation matrix for a given basis at specified nodes.\"\"\"\n    num_nodes = len(nodes)\n    num_coeffs = n + 1\n    E = np.zeros((num_nodes, num_coeffs))\n    \n    if basis == 'legendre':\n        p_prev = np.ones(num_nodes)\n        E[:, 0] = p_prev\n        if n > 0:\n            p_curr = np.copy(nodes)\n            E[:, 1] = p_curr\n        for k in range(1, n):\n            p_next = ((2 * k + 1) * nodes * p_curr - k * p_prev) / (k + 1)\n            E[:, k + 1] = p_next\n            p_prev = p_curr\n            p_curr = p_next\n    elif basis == 'chebyshev':\n        t_prev = np.ones(num_nodes)\n        E[:, 0] = t_prev\n        if n > 0:\n            t_curr = np.copy(nodes)\n            E[:, 1] = t_curr\n        for k in range(1, n):\n            t_next = 2 * nodes * t_curr - t_prev\n            E[:, k + 1] = t_next\n            t_prev = t_curr\n            t_curr = t_next\n    elif basis == 'bernstein':\n        for k in range(num_coeffs):\n            E[:, k] = comb(n, k) * (nodes**k) * ((1 - nodes)**(n - k))\n            \n    return E\n\ndef solve():\n    results = []\n    x_eval = np.linspace(-1, 1, 1001)\n    t_eval = (x_eval + 1) / 2\n\n    # --- Test 1 (n=1) ---\n    n1 = 1\n    # Legendre case\n    coeffs_l1 = np.array([0.0, 1.0])\n    u_h_l1 = eval_legendre(coeffs_l1, x_eval)\n    results.append(np.all(u_h_l1 >= -1e-9))\n    # Chebyshev case\n    coeffs_c1 = np.array([0.0, 1.0])\n    u_h_c1 = eval_chebyshev(coeffs_c1, x_eval)\n    results.append(np.all(u_h_c1 >= -1e-9))\n    # Bernstein case\n    coeffs_b1 = np.array([0.0, 1.0])\n    u_h_b1 = eval_bernstein(coeffs_b1, t_eval, n1)\n    results.append(np.all(u_h_b1 >= -1e-9))\n\n    # --- Test 2 (n=3) ---\n    n2 = 3\n    # Legendre case\n    coeffs_l2 = np.array([0.0, 0.0, 1.0, 0.0])\n    u_h_l2 = eval_legendre(coeffs_l2, x_eval)\n    results.append(np.all(u_h_l2 >= -1e-9))\n    # Chebyshev case\n    coeffs_c2 = np.array([0.0, 0.0, 1.0, 0.0])\n    u_h_c2 = eval_chebyshev(coeffs_c2, x_eval)\n    results.append(np.all(u_h_c2 >= -1e-9))\n    # Bernstein case\n    coeffs_b2 = np.array([0.2, 0.3, 0.4, 0.5])\n    u_h_b2 = eval_bernstein(coeffs_b2, t_eval, n2)\n    results.append(np.all(u_h_b2 >= -1e-9))\n\n    # --- Test 3 (n=5) ---\n    n3 = 5\n    coeffs_l3 = np.array([0.1, 1.0, 0.0, 0.0, 0.0, 0.0])\n    u_h_l3_before = eval_legendre(coeffs_l3, x_eval)\n    min_before = np.min(u_h_l3_before)\n    results.append(f\"{min_before:.6f}\")\n    \n    # Limiter\n    t_nodes3 = np.linspace(0, 1, n3 + 1)\n    x_nodes3 = 2 * t_nodes3 - 1\n    E_L3 = get_eval_matrix(n3, 'legendre', x_nodes3)\n    E_B3 = get_eval_matrix(n3, 'bernstein', t_nodes3)\n    \n    u_hat_B3 = np.linalg.solve(E_B3, E_L3 @ coeffs_l3)\n    u_hat_B3_limited = np.maximum(0, u_hat_B3)\n    coeffs_l3_limited = np.linalg.solve(E_L3, E_B3 @ u_hat_B3_limited)\n    \n    u_h_l3_after = eval_legendre(coeffs_l3_limited, x_eval)\n    min_after = np.min(u_h_l3_after)\n    results.append(f\"{min_after:.6f}\")\n\n    # --- Test 4 (n=4) ---\n    n4 = 4\n    U4 = 0.8\n    coeffs_l4 = np.array([0.3, 0.9, -0.2, 0.1, 0.5])\n    \n    t_nodes4 = np.linspace(0, 1, n4 + 1)\n    x_nodes4 = 2 * t_nodes4 - 1\n    E_L4 = get_eval_matrix(n4, 'legendre', x_nodes4)\n    E_B4 = get_eval_matrix(n4, 'bernstein', t_nodes4)\n    \n    u_hat_B4 = np.linalg.solve(E_B4, E_L4 @ coeffs_l4)\n    u_hat_B4_limited = np.clip(u_hat_B4, 0, U4)\n    coeffs_l4_limited = np.linalg.solve(E_L4, E_B4 @ u_hat_B4_limited)\n    \n    u_h_l4_limited = eval_legendre(coeffs_l4_limited, x_eval)\n    is_nonnegative = np.all(u_h_l4_limited >= -1e-9)\n    is_bounded = np.all(u_h_l4_limited <= U4 + 1e-9)\n    results.append(is_nonnegative)\n    results.append(is_bounded)\n    \n    # --- Test 5 (n=0) ---\n    n5 = 0\n    coeffs_l5 = np.array([-0.2])\n    \n    # For n=0, the transformation is trivial. u_hat_B = u_hat_L\n    u_hat_B5_limited = np.maximum(0, coeffs_l5)\n    coeffs_l5_limited = u_hat_B5_limited\n\n    u_h_l5_limited = eval_legendre(coeffs_l5_limited, x_eval)\n    min_after_5 = np.min(u_h_l5_limited)\n    results.append(f\"{min_after_5:.6f}\")\n\n    # Final print statement\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3409697"}]}