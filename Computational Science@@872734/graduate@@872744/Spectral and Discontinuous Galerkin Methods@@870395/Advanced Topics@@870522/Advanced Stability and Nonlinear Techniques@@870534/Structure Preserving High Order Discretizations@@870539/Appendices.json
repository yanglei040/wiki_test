{"hands_on_practices": [{"introduction": "Our first hands-on practice establishes the fundamental principles of structure-preserving discretizations in a clear and accessible context. We will use the Summation-By-Parts (SBP) finite difference method to discretize the linear advection equation, demonstrating how the combination of an SBP operator for the interior and a Simultaneous Approximation Term (SAT) for the boundary provably guarantees stability. This exercise provides a concrete implementation of a discrete energy analysis, allowing you to numerically verify that the chosen scheme dissipates energy correctly and maintains stability [@problem_id:3421651].", "problem": "Consider the linear advection equation $u_t + a\\,u_x = 0$ on the spatial domain $[0,1]$ with constant advection speed $a=1$ and homogeneous inflow boundary condition $u(0,t)=0$. Discretize the domain using a uniform grid of $N$ points $x_i = i h$ for $i=0,1,\\ldots,N-1$ where $h = 1/(N-1)$. Implement a second-order diagonal-norm Summation-By-Parts (SBP) operator, and use a Simultaneous Approximation Term (SAT) to impose the inflow boundary in a stable, energy-consistent manner. Then compute the semidiscrete energy growth rate and verify that it is non-increasing for all provided test cases.\n\nDefinitions and requirements:\n- The Summation-By-Parts (SBP) property is defined by a diagonal norm matrix $H \\in \\mathbb{R}^{N \\times N}$ and a differentiation operator $D \\in \\mathbb{R}^{N \\times N}$ satisfying $D = H^{-1} Q$ for some matrix $Q \\in \\mathbb{R}^{N \\times N}$ such that\n$$\nQ + Q^\\top = B,\n$$\nwhere $B = \\mathrm{diag}(-1, 0, \\ldots, 0, 1)$ corresponds to discrete boundary fluxes.\n- For a second-order diagonal-norm operator on a uniform grid, choose $H$ to be diagonal with entries\n$$\nH_{ii} = \\begin{cases}\n\\frac{h}{2}, & i=0 \\text{ or } i=N-1,\\\\\nh, & \\text{otherwise},\n\\end{cases}\n$$\nand choose $Q$ so that $D = H^{-1} Q$ reproduces the standard centered difference in the interior and one-sided boundary closures consistent with second-order accuracy. The simplest choice is\n$$\nQ_{i,i+1} = \\frac{1}{2},\\quad Q_{i+1,i} = -\\frac{1}{2}\\quad \\text{for } i=0,1,\\ldots,N-2,\n$$\nand boundary diagonal entries $Q_{00} = -\\frac{1}{2}$, $Q_{N-1,N-1} = \\frac{1}{2}$, with all unspecified entries being zero. This choice satisfies $Q + Q^\\top = B$.\n- Impose the homogeneous inflow boundary condition $u(0,t)=0$ using a Simultaneous Approximation Term (SAT) of the form\n$$\n\\text{SAT} = -a\\,H^{-1} e_1 (u_0 - g),\n$$\nwith $e_1$ the first canonical basis vector, $g=0$, and $a=1$. The semidiscrete system is then\n$$\nu_t = -a D u - a H^{-1} e_1 u_0,\n$$\nwhere $u \\in \\mathbb{R}^N$ denotes the grid values of the solution.\n- Define the discrete energy norm\n$$\n\\|u\\|_H^2 = u^\\top H u,\n$$\nand compute its time derivative for the semidiscrete system:\n$$\n\\frac{d}{dt}\\|u\\|_H^2 = 2\\,u^\\top H\\,u_t.\n$$\n\nTask:\n- Implement the above second-order diagonal-norm SBP operator on a uniform grid and the SAT boundary treatment for $a=1$ and $g=0$.\n- For each test case specified below, compute the semidiscrete energy growth rate $\\frac{d}{dt}\\|u\\|_H^2$ and return whether it is non-increasing, defined as being less than or equal to $10^{-12}$ (to account for floating-point roundoff).\n\nTest suite:\n- Case 1: $N=2$, $u = [1.0, 0.0]$.\n- Case 2: $N=2$, $u = [0.0, 2.0]$.\n- Case 3: $N=5$, $u = [0,0,0,0,0]$.\n- Case 4: $N=5$, $u$ with homogeneous inflow only, $u_0=1.0$, $u_i=0$ for $i \\neq 0$.\n- Case 5: $N=5$, $u$ with outflow value only, $u_{N-1}=1.0$, $u_i=0$ for $i \\neq N-1$.\n- Case 6: $N=10$, $u$ drawn deterministically from a uniform distribution on $[-1,1]$ using a fixed random seed.\n- Case 7: $N=10$, $u_i = x_i$ where $x_i = i h$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, \"[True,False,True,False]\". Each entry corresponds to one test case in the above order, indicating whether $\\frac{d}{dt}\\|u\\|_H^2 \\le 10^{-12}$ for that case.\n- No physical units or angles are involved; all computations are in pure numerical terms.", "solution": "The problem requires the implementation and verification of a stable semi-discretization for the linear advection equation, $u_t + a\\,u_x = 0$, using a second-order diagonal-norm Summation-By-Parts (SBP) operator for the spatial derivative and a Simultaneous Approximation Term (SAT) to enforce the boundary condition. The goal is to compute the time rate of change of a discrete energy norm and confirm that it is non-increasing for a suite of test cases.\n\nThe semi-discrete system for the solution vector $u(t) \\in \\mathbb{R}^N$, representing the solution at the grid points $x_i$, is given by:\n$$\n\\frac{du}{dt} = -a D u + \\text{SAT}\n$$\nHere, $D$ is the SBP differentiation matrix, $a=1$ is the advection speed, and the SAT term enforces the homogeneous inflow boundary condition $u(0,t)=0$. The specified SAT is:\n$$\n\\text{SAT} = -a\\,H^{-1} e_1 (u_0 - g)\n$$\nWith $a=1$ and the boundary data $g=0$, the system becomes:\n$$\n\\frac{du}{dt} = -D u - H^{-1} e_1 u_0\n$$\nwhere $u_0$ is the first component of the vector $u$, corresponding to the solution at the inflow boundary $x=0$, and $e_1 = [1, 0, \\ldots, 0]^\\top$ is the first canonical basis vector.\n\nThe stability of this scheme is analyzed using a discrete energy norm defined by the matrix $H$:\n$$\n\\|u\\|_H^2 = u^\\top H u\n$$\nThe matrix $H$ is a positive-definite diagonal matrix that defines a discrete inner product and quadrature rule. Its time derivative gives the energy growth rate:\n$$\n\\frac{d}{dt}\\|u(t)\\|_H^2 = \\frac{d}{dt}(u^\\top H u) = \\left(\\frac{du}{dt}\\right)^\\top H u + u^\\top H \\left(\\frac{du}{dt}\\right)\n$$\nSince the result is a scalar, the two terms are equal, and we have:\n$$\n\\frac{d}{dt}\\|u\\|_H^2 = 2 u^\\top H \\frac{du}{dt}\n$$\nSubstituting the semi-discrete equation for $\\frac{du}{dt}$:\n$$\n\\frac{d}{dt}\\|u\\|_H^2 = 2 u^\\top H (-D u - H^{-1} e_1 u_0) = -2 u^\\top H D u - 2 u^\\top H H^{-1} e_1 u_0\n$$\nWe analyze the two terms on the right-hand side separately.\n\nFor the first term, we use the SBP property. The differentiation operator $D$ is defined as $D = H^{-1}Q$, where the matrix $Q$ satisfies $Q+Q^\\top=B=\\mathrm{diag}(-1, 0, \\ldots, 0, 1)$.\n$$\n-2 u^\\top H D u = -2 u^\\top H (H^{-1}Q) u = -2 u^\\top Q u\n$$\nUsing the property that a scalar is its own transpose ($u^\\top Q u = (u^\\top Q u)^\\top = u^\\top Q^\\top u$), we can write:\n$$\n-2 u^\\top Q u = - (u^\\top Q u + u^\\top Q^\\top u) = -u^\\top(Q+Q^\\top)u = -u^\\top B u\n$$\nSubstituting the definition of $B$:\n$$\n-u^\\top B u = -\\begin{pmatrix} u_0 & \\dots & u_{N-1} \\end{pmatrix} \\begin{pmatrix} -1 & & \\\\ & 0 & \\\\ & & \\ddots & \\\\ & & & 1 \\end{pmatrix} \\begin{pmatrix} u_0 \\\\ \\vdots \\\\ u_{N-1} \\end{pmatrix} = -(-u_0^2 + u_{N-1}^2) = u_0^2 - u_{N-1}^2\n$$\nThis term represents the net energy flux across the boundaries.\n\nFor the second term, originating from the SAT, we have:\n$$\n-2 u^\\top H H^{-1} e_1 u_0 = -2 u^\\top I e_1 u_0 = -2 u^\\top e_1 u_0\n$$\nThe product $u^\\top e_1$ extracts the first component of $u$, which is $u_0$. So, the term becomes:\n$$\n-2 (u_0) u_0 = -2 u_0^2\n$$\nThis term represents the energy dissipation introduced by the SAT to enforce the boundary condition.\n\nCombining both results, the total energy growth rate is:\n$$\n\\frac{d}{dt}\\|u\\|_H^2 = (u_0^2 - u_{N-1}^2) - 2 u_0^2 = -u_0^2 - u_{N-1}^2\n$$\nSince $u_0^2 \\ge 0$ and $u_{N-1}^2 \\ge 0$, the energy growth rate is always non-positive ($\\le 0$). This proves that the SBP-SAT semi-discretization is energy-stable (or, more precisely, dissipative).\n\nThe implementation will construct the specified matrices $H$ and $Q$ for a given number of grid points $N$. It will then compute the vector $\\frac{du}{dt}$ according to the semi-discrete equation and finally evaluate the energy growth rate expression $2 u^\\top H \\frac{du}{dt}$ numerically for each test case. The result will be compared against a tolerance of $10^{-12}$ to account for floating-point arithmetic errors.", "answer": "```python\nimport numpy as np\n\ndef calculate_energy_rate(N, u_vec):\n    \"\"\"\n    Computes the semidiscrete energy growth rate for the linear advection equation\n    using a second-order SBP-SAT scheme.\n\n    Args:\n        N (int): The number of grid points.\n        u_vec (np.ndarray): The solution vector of size N.\n\n    Returns:\n        float: The computed energy growth rate, d/dt ||u||_H^2.\n    \"\"\"\n    if N < 2:\n        # The SBP operator definition is for N>=2.\n        # For N<2, h is undefined. A trivial case.\n        return 0.0\n\n    a = 1.0\n    h = 1.0 / (N - 1)\n\n    # 1. Construct the diagonal norm matrix H as a 1D array of its diagonal entries.\n    H_diag = np.full(N, h, dtype=float)\n    H_diag[0] = h / 2.0\n    H_diag[-1] = h / 2.0\n\n    # 2. Construct the matrix Q.\n    Q = np.zeros((N, N), dtype=float)\n    # Diagonal entries\n    Q[0, 0] = -0.5\n    Q[-1, -1] = 0.5\n    # Off-diagonal entries\n    idx = np.arange(N - 1)\n    Q[idx, idx + 1] = 0.5\n    Q[idx + 1, idx] = -0.5\n\n    # 3. Construct the differentiation matrix D = H^-1 * Q.\n    # We do this without explicitly forming the inverse of H.\n    H_inv_diag = 1.0 / H_diag\n    D = H_inv_diag[:, np.newaxis] * Q\n\n    # 4. Compute the time derivative of the solution vector, u_t.\n    # u_t = -a * D * u + SAT\n    Du = D @ u_vec\n    u_t = -a * Du\n\n    # The SAT term for u_t = -a*D*u - a*H^-1*e1*(u0-g) with g=0.\n    # This term simplifies to a vector with only the first component being non-zero.\n    # SAT_vector = -a * H_inv_diag[0] * u_vec[0]\n    sat_penalty = a * H_inv_diag[0] * u_vec[0]\n    u_t[0] -= sat_penalty\n\n    # 5. Compute the energy growth rate: d/dt ||u||^2_H = 2 * u^T * H * u_t.\n    # Since H is diagonal, H*u_t is an element-wise product.\n    H_u_t = H_diag * u_t\n    energy_rate = 2.0 * u_vec.T @ H_u_t\n    \n    return energy_rate\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        (2, np.array([1.0, 0.0])),\n        # Case 2\n        (2, np.array([0.0, 2.0])),\n        # Case 3\n        (5, np.array([0.0, 0.0, 0.0, 0.0, 0.0])),\n        # Case 4\n        (5, np.array([1.0, 0.0, 0.0, 0.0, 0.0])),\n        # Case 5\n        (5, np.array([0.0, 0.0, 0.0, 0.0, 1.0])),\n    ]\n\n    # Case 6: Deterministic \"random\" vector\n    N6 = 10\n    rng = np.random.default_rng(seed=12345)\n    u6 = rng.uniform(-1, 1, size=N6)\n    test_cases.append((N6, u6))\n\n    # Case 7: Linear profile\n    N7 = 10\n    h7 = 1.0 / (N7 - 1)\n    u7 = np.arange(N7) * h7\n    test_cases.append((N7, u7))\n\n    results = []\n    # Tolerance for floating-point comparison\n    tolerance = 1e-12\n\n    for N, u_vec in test_cases:\n        rate = calculate_energy_rate(N, u_vec)\n        is_non_increasing = rate <= tolerance\n        results.append(is_non_increasing)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3421651"}, {"introduction": "Building on the foundational SBP concept, this practice transitions to the more advanced Discontinuous Galerkin Spectral Element Method (DGSEM) for nonlinear conservation laws. You will implement an entropy-stable scheme for the inviscid Burgers' equation, a canonical model for shock formation, using a special two-point numerical flux that guarantees the discrete preservation of a chosen entropy. The core task is to verify that the resulting semi-discrete operator is skew-symmetric with respect to a physical mass matrix, a key property that ensures the conservation of discrete energy for smooth solutions [@problem_id:3421735]. This exercise illuminates the mechanism by which modern high-order methods achieve robustness for complex nonlinear problems.", "problem": "Consider the scalar conservation law given by inviscid Burgers’ equation on a periodic one-dimensional domain,\n$$\n\\partial_t u(x,t) + \\partial_x\\left(\\tfrac{1}{2}u(x,t)^2\\right) = 0 \\quad \\text{for} \\quad x \\in [0,1],\n$$\nwith periodic boundary conditions and smooth solutions. Let the interval be partitioned into $K$ uniform elements of size $h = 1/K$, and map each physical element to the reference interval $[-1,1]$ with Jacobian $J = h/2$. On each element, approximate $u$ by polynomials of degree $N=3$ using a Discontinuous Galerkin Spectral Element Method (DGSEM) collocated at the Legendre-Gauss nodes. Denote the $N+1$ reference nodes by $\\{\\xi_i\\}_{i=1}^{N+1}$ and the positive quadrature weights by $\\{w_i\\}_{i=1}^{N+1}$.\n\nConstruct the generalized Summation-By-Parts (SBP) operators on the reference element as follows:\n- The diagonal mass matrix $M \\in \\mathbb{R}^{(N+1)\\times(N+1)}$ has entries $M_{ii} = w_i$.\n- The nodal differentiation matrix $D \\in \\mathbb{R}^{(N+1)\\times(N+1)}$ is obtained from the derivatives of the Lagrange basis at the nodes $\\{\\xi_i\\}$.\n- Define $Q = M D$.\n- Let $R \\in \\mathbb{R}^{2\\times(N+1)}$ be the interpolation matrix to the boundaries $\\xi=-1$ and $\\xi=1$, i.e., $R = \\begin{bmatrix} \\ell_1(-1) & \\cdots & \\ell_{N+1}(-1) \\\\ \\ell_1(1) & \\cdots & \\ell_{N+1}(1)\\end{bmatrix}$ where $\\{\\ell_j\\}$ are the nodal Lagrange basis polynomials.\n- Let $B = \\operatorname{diag}(-1,1)$.\n\nThese operators satisfy the generalized SBP identity\n$$\nQ + Q^\\top = R^\\top B R.\n$$\n\nDiscretize the advective term using a two-point symmetric and consistent entropy-conserving volume flux for Burgers’ equation. Define the two-point flux\n$$\nf_S(a,b) = \\tfrac{1}{6}\\left(a^2 + a\\,b + b^2\\right),\n$$\nwhich is symmetric in its arguments and consistent with the physical flux $f(u) = \\tfrac{1}{2}u^2$ in the sense that $f_S(u,u) = f(u)$. Use the same two-point flux to define the numerical flux at inter-element interfaces (central/entropy-conserving interface flux). For an element with nodal solution vector $u \\in \\mathbb{R}^{N+1}$, define the matrix of pairwise fluxes $F \\in \\mathbb{R}^{(N+1)\\times(N+1)}$ by $F_{ij} = f_S(u_i,u_j)$ and the volume contribution by the row-wise sum\n$$\nG(u) = (Q \\circ F)\\,\\mathbf{1},\n$$\nwhere $\\circ$ denotes the Hadamard (element-wise) product and $\\mathbf{1} \\in \\mathbb{R}^{N+1}$ is the vector of ones. Let $\\widehat{f}\\in\\mathbb{R}^2$ collect the interface numerical fluxes for the left and right boundaries of the element, obtained by evaluating $f_S$ on the interpolated boundary traces using $R$ and periodic neighbor coupling.\n\nThe semi-discrete strong-form DGSEM on each element is\n$$\n\\frac{d u}{dt} \\;=\\; -\\frac{2}{J}\\, M^{-1}\\left(G(u) - R^\\top B\\, \\widehat{f}\\right),\n$$\nand the global semi-discrete system is obtained by assembling all elements with periodic boundary conditions at the domain endpoints.\n\nFor a global state vector $u \\in \\mathbb{R}^{K(N+1)}$, define the global right-hand side $\\mathcal{R}(u)$ by assembling all element contributions as above. For a constant state $u \\equiv c$, define the semi-discrete operator matrix $A(c) \\in \\mathbb{R}^{K(N+1)\\times K(N+1)}$ as the Jacobian of the right-hand side evaluated at $u=c\\,\\mathbf{1}$,\n$$\nA(c) \\;=\\; \\left.\\frac{\\partial \\mathcal{R}(u)}{\\partial u}\\right|_{u = c\\,\\mathbf{1}}.\n$$\nDefine the global physical mass matrix $M_{\\text{phys}}$ as the block-diagonal matrix with one block $J M$ per element, i.e., $M_{\\text{phys}} = \\operatorname{blkdiag}(J M,\\dots,J M) \\in \\mathbb{R}^{K(N+1)\\times K(N+1)}$.\n\nThe structure-preserving property to verify is the weighted skew-symmetry of the advective part in the $M_{\\text{phys}}$ inner product for periodic boundary conditions:\n$$\nM_{\\text{phys}}\\,A(c) + A(c)^\\top\\,M_{\\text{phys}} \\;=\\; 0.\n$$\n\nProgram requirements:\n- Implement the degree $N=3$ Discontinuous Galerkin Spectral Element Method (DGSEM) on Legendre-Gauss points on the domain $[0,1]$ with periodic boundary conditions and the two-point flux $f_S$ as specified.\n- Assemble the global right-hand side $\\mathcal{R}(u)$ and compute the Jacobian $A(c)$ at constant states $u \\equiv c$ by centered finite differences with a small perturbation $ \\varepsilon $, i.e.,\n$$\nA(c)\\,e_k \\;\\approx\\; \\frac{\\mathcal{R}(c\\,\\mathbf{1} + \\varepsilon\\, e_k) - \\mathcal{R}(c\\,\\mathbf{1} - \\varepsilon\\, e_k)}{2\\varepsilon},\n$$\nfor each canonical basis vector $e_k$.\n- Verify the weighted skew-symmetry by computing the infinity norm of the defect matrix $S(c) = M_{\\text{phys}}A(c) + A(c)^\\top M_{\\text{phys}}$, and comparing it to a tolerance.\n\nTest suite:\n- Use the following $(K,c)$ cases with $N=3$ fixed and periodic boundary conditions:\n    1. $(K,c) = (1, 0.8)$\n    2. $(K,c) = (3, 0.0)$\n    3. $(K,c) = (4, -1.0)$\n- For each test case, compute the boolean result of the predicate\n$$\n\\|S(c)\\|_{\\infty} \\leq 10^{-9},\n$$\nwhere $\\|\\cdot\\|_{\\infty}$ denotes the entrywise maximum absolute value.\n\nFinal output format:\n- Your program should produce a single line of output containing the three boolean results for the test suite, as a comma-separated Python-style list, for example, \"[True,False,True]\". No additional text should be printed.", "solution": "We begin with the scalar conservation law for inviscid Burgers’ equation,\n$$\n\\partial_t u(x,t) + \\partial_x f(u(x,t)) = 0,\\quad f(u) = \\tfrac{1}{2}u^2,\n$$\non a periodic domain $x \\in [0,1]$ with a partition into $K$ uniform elements of size $h=1/K$. The mapping from the reference coordinate $\\xi \\in [-1,1]$ to the physical coordinate $x$ on each element is affine with Jacobian $J = h/2$, so that $\\partial_x = (1/J)\\partial_\\xi$ and the equation on the reference element reads\n$$\n\\partial_t u(\\xi,t) + \\frac{1}{J}\\,\\partial_\\xi f(u(\\xi,t)) = 0.\n$$\n\nOn the reference element, we choose Discontinuous Galerkin Spectral Element Method (DGSEM) collocation with degree $N=3$ at Legendre-Gauss nodes $\\{\\xi_i\\}_{i=1}^{N+1}$ and quadrature weights $\\{w_i\\}_{i=1}^{N+1}$. Let $\\{\\ell_j(\\xi)\\}_{j=1}^{N+1}$ be the Lagrange interpolating polynomials at these nodes. We define the diagonal mass matrix $M \\in \\mathbb{R}^{(N+1)\\times(N+1)}$ with entries $M_{ii} = w_i$ and the nodal differentiation matrix $D \\in \\mathbb{R}^{(N+1)\\times(N+1)}$ with entries $D_{ij} = \\ell_j'(\\xi_i)$. The matrix $Q = M D$ together with the boundary interpolation matrix $R \\in \\mathbb{R}^{2\\times(N+1)}$, given by\n$$\nR = \\begin{bmatrix}\n\\ell_1(-1) & \\cdots & \\ell_{N+1}(-1)\\\\\n\\ell_1(1) & \\cdots & \\ell_{N+1}(1)\n\\end{bmatrix},\n$$\nand $B = \\operatorname{diag}(-1,1)$ satisfy the generalized Summation-By-Parts (SBP) identity\n$$\nQ + Q^\\top = R^\\top B R.\n$$\nThis identity ensures that discrete integration-by-parts holds when coupling elements through appropriate Simultaneous Approximation Terms (SATs).\n\nFor a stable and structure-preserving discretization of the nonlinear flux, we employ a symmetric and consistent two-point volume flux $f_S$ that is entropy-conserving for Burgers’ equation:\n$$\nf_S(a,b) = \\tfrac{1}{6}\\left(a^2 + a\\,b + b^2\\right) = f_S(b,a), \\quad f_S(u,u) = f(u).\n$$\nUsing the flux differencing form, the volume contribution on one element with nodal state vector $u \\in \\mathbb{R}^{N+1}$ is computed by forming the matrix $F \\in \\mathbb{R}^{(N+1)\\times(N+1)}$ with entries $F_{ij} = f_S(u_i,u_j)$ and then taking the row-wise sum\n$$\nG(u) = (Q \\circ F)\\,\\mathbf{1},\n$$\nwhere $\\circ$ denotes the Hadamard product and $\\mathbf{1}$ is the vector of ones. The numerical flux at element boundaries is also taken as $f_S$ evaluated on the left and right traces $u^-, u^+$, yielding the interface vector $\\widehat{f} \\in \\mathbb{R}^2$. The semi-discrete strong-form DGSEM within an element is\n$$\n\\frac{d u}{dt} \\;=\\; -\\frac{2}{J}\\, M^{-1}\\left(G(u) - R^\\top B\\, \\widehat{f}\\right).\n$$\nGluing elements with periodic boundary conditions is achieved by coupling traces between neighboring elements cyclically to define $\\widehat{f}$ at each face.\n\nEnergy analysis uses the physical inner product induced by the block-diagonal global mass matrix $M_{\\text{phys}} = \\operatorname{blkdiag}(J M,\\dots,J M)$, which is the quadrature representation of the physical $L^2$ inner product over the mesh. The generalized SBP identity implies a discrete energy balance. In particular, for periodic boundaries and with symmetric two-point fluxes, the discrete energy\n$$\nE(u) = \\tfrac{1}{2} u^\\top M_{\\text{phys}} u\n$$\nsatisfies\n$$\n\\frac{dE}{dt} = u^\\top M_{\\text{phys}} \\frac{du}{dt} = 0,\n$$\nso that the advective operator is skew-symmetric in the $M_{\\text{phys}}$ inner product. When linearizing the semi-discrete right-hand side $\\mathcal{R}(u)$ around a constant state $u \\equiv c$, the Jacobian $A(c) = \\left.\\frac{\\partial \\mathcal{R}}{\\partial u}\\right|_{u=c\\mathbf{1}}$ represents the semi-discrete advective operator at that state, and the structure-preserving property becomes\n$$\nM_{\\text{phys}}\\,A(c) + A(c)^\\top\\,M_{\\text{phys}} = 0.\n$$\nThis identity reflects exact skew-symmetry in the $M_{\\text{phys}}$ inner product and implies conservation of discrete energy for periodic boundary conditions.\n\nAlgorithmic construction:\n- Compute $\\{\\xi_i,w_i\\}_{i=1}^{N+1}$ as the Legendre-Gauss nodes and weights for $N=3$.\n- Build barycentric weights to evaluate Lagrange basis functions and their derivatives at nodes, yielding $D$ and the interpolation matrix $R$.\n- Form $M = \\operatorname{diag}(w)$ and $Q = M D$ and verify that $Q+Q^\\top \\approx R^\\top B R$.\n- Assemble the global right-hand side $\\mathcal{R}(u)$ by looping over elements, computing $G(u)$ via flux differencing and interface fluxes $\\widehat{f}$ via $f_S$ and $R$, and coupling elements periodically.\n- Approximate the Jacobian $A(c)$ at constant states $u \\equiv c$ by centered finite differences using a small perturbation $\\varepsilon$:\n$$\nA(c)\\,e_k \\approx \\frac{\\mathcal{R}(c\\,\\mathbf{1} + \\varepsilon\\, e_k) - \\mathcal{R}(c\\,\\mathbf{1} - \\varepsilon\\, e_k)}{2\\varepsilon}.\n$$\n- Form $M_{\\text{phys}}$ as a block-diagonal matrix with $J M$ on each block and evaluate the skew-symmetry defect\n$$\nS(c) = M_{\\text{phys}}A(c) + A(c)^\\top M_{\\text{phys}}.\n$$\n- Compute $\\|S(c)\\|_{\\infty}$ and compare with the tolerance $10^{-9}$ to obtain a boolean result for each test case.\n\nTest suite and output:\n- Use $(K,c)=(1,0.8)$, $(K,c)=(3,0.0)$, and $(K,c)=(4,-1.0)$ with $N=3$ fixed.\n- For each case, output whether $\\|S(c)\\|_{\\infty} \\le 10^{-9}$ holds.\n- The program must print a single line with the three boolean results as a Python-style list, e.g., \"[True,False,True]\".\n\nThis construction starts from the fundamental discrete SBP property and the symmetric, consistent two-point flux for Burgers’ equation, which are the core design principles ensuring structure preservation. The verification through the weighted skew-symmetry of $A(c)$ in the $M_{\\text{phys}}$ inner product demonstrates that the DGSEM discretization preserves the discrete energy structure for periodic boundary conditions.", "answer": "```python\nimport numpy as np\n\n# DGSEM on Gauss points for Burgers' equation, N=3, periodic domain [0,1]\n# Verify weighted skew-symmetry of the advective operator Jacobian at constant states.\n\ndef legendre_gauss_nodes_weights(n):\n    # Returns nodes and weights for Legendre-Gauss quadrature on [-1,1]\n    from numpy.polynomial.legendre import leggauss\n    x, w = leggauss(n)\n    return x, w\n\ndef barycentric_weights(nodes):\n    # Compute first-form barycentric weights for distinct nodes\n    n = len(nodes)\n    w = np.ones(n)\n    for j in range(n):\n        prod = 1.0\n        xj = nodes[j]\n        for k in range(n):\n            if k != j:\n                prod *= (xj - nodes[k])\n        w[j] = 1.0 / prod\n    return w\n\ndef lagrange_interp_row(t, nodes, bary_w):\n    # Returns the row vector [l_1(t),...,l_n(t)] for Lagrange basis at t\n    n = len(nodes)\n    # Check if t coincides with a node\n    for j in range(n):\n        if np.isclose(t, nodes[j], atol=1e-14, rtol=0.0):\n            row = np.zeros(n)\n            row[j] = 1.0\n            return row\n    diff = t - nodes\n    alpha = bary_w / diff\n    denom = np.sum(alpha)\n    row = alpha / denom\n    return row\n\ndef differentiation_matrix(nodes, bary_w):\n    # Build the nodal differentiation matrix using barycentric weights\n    n = len(nodes)\n    D = np.zeros((n, n))\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                D[i, j] = (bary_w[j] / bary_w[i]) / (nodes[i] - nodes[j])\n    D[np.diag_indices(n)] = -np.sum(D, axis=1)\n    return D\n\ndef burgers_two_point_flux(a, b):\n    # Entropy-conserving symmetric two-point flux: (a^2 + a b + b^2)/6\n    return (a*a + a*b + b*b) / 6.0\n\ndef build_reference_operators(N):\n    # Build reference element operators for degree N using Gauss nodes\n    n = N + 1\n    xi, wq = legendre_gauss_nodes_weights(n)\n    bw = barycentric_weights(xi)\n    D = differentiation_matrix(xi, bw)\n    M = np.diag(wq)\n    Q = M @ D\n    # Interpolation to boundaries -1 and 1\n    R = np.vstack([\n        lagrange_interp_row(-1.0, xi, bw),\n        lagrange_interp_row( 1.0, xi, bw)\n    ])\n    B = np.diag(np.array([-1.0, 1.0]))\n    return xi, wq, M, D, Q, R, B\n\ndef assemble_rhs(u, K, N, M, Q, R, B, J):\n    # Assemble the global RHS for Burgers' equation with periodic BCs using flux differencing on Gauss DGSEM\n    nloc = N + 1\n    total = K * nloc\n    rhs = np.zeros(total)\n    ones_loc = np.ones(nloc)\n\n    # Helper to extract element dofs\n    def elem_slice(e):\n        return slice(e*nloc, (e+1)*nloc)\n\n    # Compute boundary trace values per element\n    # left trace is at xi=-1 from inside element, right trace at xi=+1\n    u_left = np.zeros(K)\n    u_right = np.zeros(K)\n    for e in range(K):\n        ue = u[elem_slice(e)]\n        u_left[e] = R[0, :] @ ue\n        u_right[e] = R[1, :] @ ue\n\n    # Interface fluxes: for element e, left interface between e-1 (right) and e (left), right interface between e (right) and e+1 (left)\n    fhat_left = np.zeros(K)\n    fhat_right = np.zeros(K)\n    for e in range(K):\n        eL = (e - 1) % K\n        eR = (e + 1) % K\n        # left interface of element e: left neighbor right trace, current left trace\n        fhat_left[e] = burgers_two_point_flux(u_right[eL], u_left[e])\n        # right interface of element e: current right trace, right neighbor left trace\n        fhat_right[e] = burgers_two_point_flux(u_right[e], u_left[eR])\n\n    # Element contributions\n    Minv = np.linalg.inv(M)\n    for e in range(K):\n        ue = u[elem_slice(e)]\n        # Volume flux differencing\n        # Build matrix F with F_ij = f_S(u_i, u_j)\n        ui = ue[:, None]\n        uj = ue[None, :]\n        F = burgers_two_point_flux(ui, uj)\n        G = (Q * F) @ ones_loc  # row-wise sum\n        # Surface term\n        fhat = np.array([fhat_left[e], fhat_right[e]])\n        surf = R.T @ (B @ fhat)\n        # RHS local\n        rhs_e = -(2.0 / J) * (Minv @ (G - surf))\n        rhs[elem_slice(e)] = rhs_e\n\n    return rhs\n\ndef compute_jacobian_at_constant(K, N, c, M, Q, R, B, J, eps=1e-8):\n    # Compute Jacobian A at u=c via centered finite differences\n    nloc = N + 1\n    total = K * nloc\n    u0 = np.full(total, c)\n    rhs0 = assemble_rhs(u0, K, N, M, Q, R, B, J)  # not used directly but ensures any caches warm\n    A = np.zeros((total, total))\n    for k in range(total):\n        ek = np.zeros(total)\n        ek[k] = 1.0\n        up = u0 + eps * ek\n        um = u0 - eps * ek\n        rp = assemble_rhs(up, K, N, M, Q, R, B, J)\n        rm = assemble_rhs(um, K, N, M, Q, R, B, J)\n        A[:, k] = (rp - rm) / (2.0 * eps)\n    return A\n\ndef build_global_mass(K, M, J):\n    # Global physical mass matrix block diagonal with J * M per element\n    nloc = M.shape[0]\n    total = K * nloc\n    Mphys = np.zeros((total, total))\n    block = J * M\n    for e in range(K):\n        s = slice(e*nloc, (e+1)*nloc)\n        Mphys[s, s] = block\n    return Mphys\n\ndef skew_symmetry_defect_norm(Mphys, A):\n    # Compute infinity norm (max abs entry) of Mphys A + A^T Mphys\n    S = Mphys @ A + A.T @ Mphys\n    return np.max(np.abs(S))\n\ndef solve():\n    # Fixed degree N=3\n    N = 3\n    xi, wq, M, D, Q, R, B = build_reference_operators(N)\n\n    # Optional: check SBP property residual (not printed)\n    # sbp_res = np.max(np.abs(Q + Q.T - R.T @ B @ R))\n\n    # Test suite: (K, c)\n    test_cases = [\n        (1, 0.8),\n        (3, 0.0),\n        (4, -1.0),\n    ]\n\n    results = []\n    for K, c in test_cases:\n        h = 1.0 / K\n        J = 0.5 * h\n        # Build Jacobian at constant state\n        A = compute_jacobian_at_constant(K, N, c, M, Q, R, B, J, eps=1e-8)\n        Mphys = build_global_mass(K, M, J)\n        defect = skew_symmetry_defect_norm(Mphys, A)\n        results.append(defect <= 1e-9)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3421735"}, {"introduction": "Having addressed how to preserve structure in the spatial discretization, we now turn our attention to the temporal domain. A structure-preserving semi-discretization can be ruined by an inappropriate time integrator. This final practice delves into the world of geometric integration by applying several advanced time-stepping schemes to a Hamiltonian system derived from the nonlinear wave equation [@problem_id:3421719]. By implementing and comparing a symplectic Runge-Kutta method with energy-preserving integrators like the Average Vector Field (AVF) and Hamiltonian Boundary Value Methods (HBVM), you will gain firsthand experience with their remarkable long-time fidelity and their ability to conserve system invariants like energy.", "problem": "Consider the semidiscrete Hamiltonian system obtained from a periodic spectral discretization of the one-dimensional cubic nonlinear wave equation on the domain $[0,1]$. Let $N$ be the number of equally spaced grid points, $c>0$ be a propagation speed constant, and $\\lambda \\ge 0$ be a nonlinear coupling constant. Define the canonical variables $q \\in \\mathbb{R}^N$ and $p \\in \\mathbb{R}^N$ and the Hamiltonian\n$$\nH(q,p) = \\frac{1}{2} \\, p^\\top p + \\frac{1}{2} \\, q^\\top L q + \\frac{\\lambda}{4} \\sum_{i=1}^N q_i^4,\n$$\nwhere $L$ is the discrete positive semidefinite operator associated with minus the second derivative on the periodic grid, constructed spectrally as follows: for any $q \\in \\mathbb{R}^N$, let $\\widehat{q} = \\mathcal{F}(q)$ be the discrete Fourier transform, and define\n$$\nL q = c^2 \\, \\mathcal{F}^{-1}\\big( k^2 \\widehat{q} \\big),\n$$\nwith $k$ the vector of angular frequencies $k_j = \\tfrac{2\\pi}{\\Delta x} \\, \\xi_j$, $\\Delta x = 1/N$, and $\\xi_j$ the standard discrete frequencies produced by the discrete Fourier transform. The canonical ordinary differential equation is\n$$\n\\frac{d}{dt}\n\\begin{bmatrix}\nq \\\\ p\n\\end{bmatrix}\n=\nJ \\nabla H(q,p)\n=\n\\begin{bmatrix}\np \\\\ - (L q + \\lambda \\, q^{\\circ 3})\n\\end{bmatrix},\n$$\nwhere $J = \\begin{bmatrix} 0 & I \\\\ -I & 0 \\end{bmatrix}$ is the symplectic structure, $I$ is the $N \\times N$ identity matrix, $\\nabla H$ is the gradient of $H$, and $q^{\\circ 3}$ denotes the elementwise cube of $q$.\n\nYour task is to implement and compare three time integration schemes for this semidiscrete Hamiltonian system:\n1. A symplectic Runge–Kutta method based on two-stage Gauss–Legendre collocation. This method can be written as an implicit Runge–Kutta scheme with $s=2$ stages, nodes $c_1 = \\tfrac{1}{2} - \\tfrac{\\sqrt{3}}{6}$, $c_2 = \\tfrac{1}{2} + \\tfrac{\\sqrt{3}}{6}$, weights $b_1 = \\tfrac{1}{2}$, $b_2 = \\tfrac{1}{2}$, and Butcher matrix\n$$\nA =\n\\begin{bmatrix}\n\\frac{1}{4} & \\frac{1}{4} - \\frac{\\sqrt{3}}{6} \\\\\n\\frac{1}{4} + \\frac{\\sqrt{3}}{6} & \\frac{1}{4}\n\\end{bmatrix}.\n$$\nThe internal stages $\\{Y_i\\}_{i=1}^2$ solve\n$$\nY_i = y_n + h \\sum_{j=1}^2 a_{ij} f(Y_j), \\quad f(y) = J \\nabla H(y), \\quad y_n = \\begin{bmatrix} q_n \\\\ p_n \\end{bmatrix},\n$$\nand the update is $y_{n+1} = y_n + h \\sum_{j=1}^2 b_j f(Y_j)$.\n\n2. The Average Vector Field (AVF) method (energy-preserving for canonical Hamiltonian systems). For a time step $h>0$, the AVF method advances $y_n$ to $y_{n+1}$ by solving\n$$\ny_{n+1} = y_n + h \\int_0^1 f\\left( (1-\\sigma) y_n + \\sigma y_{n+1} \\right) \\, d\\sigma,\n$$\nwhich you shall implement using two-point Gauss–Legendre quadrature on $[0,1]$ with nodes $\\sigma_{1,2} = \\tfrac{1}{2} \\pm \\tfrac{1}{2\\sqrt{3}}$ and weights $\\omega_{1,2} = \\tfrac{1}{2}$.\n\n3. A Hamiltonian Boundary Value Method (HBVM) with $k=4$ quadrature nodes and $s=2$ basis polynomials (denoted HBVM(4,2)). Use the orthonormal shifted Legendre polynomials on $[0,1]$ of degrees $0$ and $1$,\n$$\nP_0(\\tau) = 1, \\qquad P_1(\\tau) = \\sqrt{3} \\, (2\\tau - 1),\n$$\nand Gauss–Legendre quadrature with $k=4$ nodes $\\{c_\\ell\\}_{\\ell=1}^4$ and weights $\\{\\omega_\\ell\\}_{\\ell=1}^4$ mapped to $[0,1]$. Define the stage values by\n$$\nY_\\ell = y_n + h \\left( \\alpha_{\\ell 0} \\, \\gamma_0 + \\alpha_{\\ell 1} \\, \\gamma_1 \\right), \\qquad \\alpha_{\\ell 0} = \\int_0^{c_\\ell} P_0(\\tau) \\, d\\tau = c_\\ell, \\quad \\alpha_{\\ell 1} = \\int_0^{c_\\ell} P_1(\\tau) \\, d\\tau = \\sqrt{3} \\, (c_\\ell^2 - c_\\ell),\n$$\nand compute $\\gamma_0, \\gamma_1 \\in \\mathbb{R}^{2N}$ by solving the nonlinear system\n$$\n\\gamma_0 = \\sum_{\\ell=1}^4 \\omega_\\ell \\, f(Y_\\ell), \\qquad\n\\gamma_1 = \\sum_{\\ell=1}^4 \\omega_\\ell \\, P_1(c_\\ell) \\, f(Y_\\ell).\n$$\nThen update $y_{n+1}$ using\n$$\ny_{n+1} = y_n + h \\int_0^1 \\left( \\gamma_0 P_0(\\tau) + \\gamma_1 P_1(\\tau) \\right) d\\tau = y_n + h \\, \\gamma_0,\n$$\nsince $\\int_0^1 P_0(\\tau)\\,d\\tau = 1$ and $\\int_0^1 P_1(\\tau)\\,d\\tau = 0$.\n\nAll implicit equations must be solved using a Newton iteration with the exact Jacobian built from the analytic expression of the Jacobian of $f(y)$. For the system above,\n$$\nf(y) =\n\\begin{bmatrix}\np \\\\ - (L q + \\lambda \\, q^{\\circ 3})\n\\end{bmatrix},\n\\qquad\nDf(y) =\n\\begin{bmatrix}\n0 & I \\\\\n- \\big(L + 3\\lambda \\, \\mathrm{diag}(q^{\\circ 2}) \\big) & 0\n\\end{bmatrix}.\n$$\nUse a consistent initial guess for the Newton iterations and terminate when the Euclidean norm of the Newton update is less than $10^{-10}$ or after $20$ iterations, whichever comes first.\n\nFor each of the three methods, simulate the dynamics for each of the following test cases, starting from the specified initial data:\n- Test case A (happy path): $N=32$, $c=1.0$, $\\lambda=0.1$, time step $h=0.05$, final time $T=10$. Initial condition $q_i(0) = 0.2 \\cos(2\\pi x_i)$, $p_i(0) = 0.2 \\sin(2\\pi x_i)$, where $x_i = \\tfrac{i}{N}$ for $i=0,\\dots,N-1$.\n- Test case B (strong nonlinearity): $N=64$, $c=1.0$, $\\lambda=1.0$, time step $h=0.02$, final time $T=4$. Initial condition $q_i(0) = 0.5 \\cos(2\\pi x_i)$, $p_i(0) = 0$.\n- Test case C (linear boundary case): $N=16$, $c=1.0$, $\\lambda=0.0$, time step $h=0.1$, final time $T=50$. Initial condition $q_i(0) = 0.3 \\cos(4\\pi x_i)$, $p_i(0) = 0.3 \\sin(4\\pi x_i)$.\n\nFor each simulation, compute the maximum absolute energy deviation\n$$\n\\Delta H_{\\max} = \\max_{0 \\le n \\le T/h} \\left| H(q_n,p_n) - H(q_0,p_0) \\right|.\n$$\nProduce as final output a single line containing a list of three lists, one per test case, and within each list the three floating-point values $\\Delta H_{\\max}$ for the symplectic Runge–Kutta method, the Average Vector Field method, and the Hamiltonian Boundary Value Method, respectively. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[[a1,a2,a3],[b1,b2,b3],[c1,c2,c3]]\"). No physical units are required; all values are dimensionless.", "solution": "## Problem Validation\n\n### Step 1: Extract Givens\n\nThe problem provides the following information:\n-   **System**: A semidiscrete Hamiltonian system derived from a periodic spectral discretization of the 1D cubic nonlinear wave equation on the domain $[0,1]$.\n-   **Parameters**:\n    -   $N$: The number of equally spaced grid points.\n    -   $c > 0$: A propagation speed constant.\n    -   $\\lambda \\ge 0$: A nonlinear coupling constant.\n-   **Variables**: Canonical variables $\\mathbf{q} \\in \\mathbb{R}^N$ and $\\mathbf{p} \\in \\mathbb{R}^N$.\n-   **Hamiltonian**: $H(\\mathbf{q},\\mathbf{p}) = \\frac{1}{2} \\, \\mathbf{p}^\\top \\mathbf{p} + \\frac{1}{2} \\, \\mathbf{q}^\\top L \\mathbf{q} + \\frac{\\lambda}{4} \\sum_{i=1}^N q_i^4$.\n-   **Operator L**: The discrete positive semidefinite operator for minus the second derivative, defined spectrally as $L \\mathbf{q} = c^2 \\, \\mathcal{F}^{-1}\\big( k^2 \\widehat{\\mathbf{q}} \\big)$, where $\\widehat{\\mathbf{q}} = \\mathcal{F}(\\mathbf{q})$ is the discrete Fourier transform, $k$ is the vector of angular frequencies $k_j = \\tfrac{2\\pi}{\\Delta x} \\, \\xi_j$, with $\\Delta x = 1/N$ and $\\xi_j$ being standard discrete frequencies.\n-   **Equations of Motion**: $\\frac{d}{dt} \\begin{bmatrix} \\mathbf{q} \\\\ \\mathbf{p} \\end{bmatrix} = J \\nabla H(\\mathbf{q},\\mathbf{p}) = \\begin{bmatrix} \\mathbf{p} \\\\ - (L \\mathbf{q} + \\lambda \\, \\mathbf{q}^{\\circ 3}) \\end{bmatrix}$, where $J = \\begin{bmatrix} 0 & I \\\\ -I & 0 \\end{bmatrix}$ and $\\mathbf{q}^{\\circ 3}$ is the elementwise cube.\n-   **Vector Field & Jacobian**: $f(\\mathbf{y}) = \\begin{bmatrix} \\mathbf{p} \\\\ - (L \\mathbf{q} + \\lambda \\, \\mathbf{q}^{\\circ 3}) \\end{bmatrix}$, $Df(\\mathbf{y}) = \\begin{bmatrix} 0 & I \\\\ - \\big(L + 3\\lambda \\, \\mathrm{diag}(\\mathbf{q}^{\\circ 2}) \\big) & 0 \\end{bmatrix}$.\n\n-   **Integrator 1: Symplectic Runge-Kutta (Gauss-Legendre, 2-stage)**\n    -   $s=2$ stages, nodes $c_1 = \\tfrac{1}{2} - \\tfrac{\\sqrt{3}}{6}$, $c_2 = \\tfrac{1}{2} + \\tfrac{\\sqrt{3}}{6}$, weights $b_1 = b_2 = \\tfrac{1}{2}$.\n    -   Butcher matrix $A = \\begin{bmatrix} \\frac{1}{4} & \\frac{1}{4} - \\frac{\\sqrt{3}}{6} \\\\ \\frac{1}{4} + \\frac{\\sqrt{3}}{6} & \\frac{1}{4} \\end{bmatrix}$.\n    -   Stage equations: $Y_i = \\mathbf{y}_n + h \\sum_{j=1}^2 a_{ij} f(Y_j)$.\n    -   Update: $\\mathbf{y}_{n+1} = \\mathbf{y}_n + h \\sum_{j=1}^2 b_j f(Y_j)$.\n\n-   **Integrator 2: Average Vector Field (AVF)**\n    -   Update equation: $\\mathbf{y}_{n+1} = \\mathbf{y}_n + h \\int_0^1 f\\left( (1-\\sigma) \\mathbf{y}_n + \\sigma \\mathbf{y}_{n+1} \\right) \\, d\\sigma$.\n    -   Quadrature: 2-point Gauss-Legendre on $[0,1]$ with nodes $\\sigma_{1,2} = \\tfrac{1}{2} \\pm \\tfrac{1}{2\\sqrt{3}}$ and weights $\\omega_{1,2} = \\tfrac{1}{2}$.\n\n-   **Integrator 3: Hamiltonian Boundary Value Method (HBVM(4,2))**\n    -   Basis polynomials on $[0,1]$: $P_0(\\tau) = 1$, $P_1(\\tau) = \\sqrt{3} \\, (2\\tau - 1)$.\n    -   Quadrature: $k=4$ Gauss-Legendre nodes $\\{c_\\ell\\}$ and weights $\\{\\omega_\\ell\\}$ on $[0,1]$.\n    -   Stage values: $Y_\\ell = \\mathbf{y}_n + h \\left( \\alpha_{\\ell 0} \\, \\gamma_0 + \\alpha_{\\ell 1} \\, \\gamma_1 \\right)$ with $\\alpha_{\\ell 0} = c_\\ell$, $\\alpha_{\\ell 1} = \\sqrt{3} \\, (c_\\ell^2 - c_\\ell)$.\n    -   Coefficient equations: $\\gamma_0 = \\sum_{\\ell=1}^4 \\omega_\\ell \\, f(Y_\\ell)$, $\\gamma_1 = \\sum_{\\ell=1}^4 \\omega_\\ell \\, P_1(c_\\ell) \\, f(Y_\\ell)$.\n    -   Update: $\\mathbf{y}_{n+1} = \\mathbf{y}_n + h \\, \\gamma_0$.\n\n-   **Numerical Method**: Implicit equations to be solved with Newton's method using the exact Jacobian. Tolerance is $10^{-10}$ on the update norm, max iterations is $20$.\n\n-   **Test Cases**:\n    -   A: $N=32$, $c=1.0$, $\\lambda=0.1$, $h=0.05$, $T=10$. IC: $q_i(0) = 0.2 \\cos(2\\pi x_i)$, $p_i(0) = 0.2 \\sin(2\\pi x_i)$.\n    -   B: $N=64$, $c=1.0$, $\\lambda=1.0$, $h=0.02$, $T=4$. IC: $q_i(0) = 0.5 \\cos(2\\pi x_i)$, $p_i(0) = 0$.\n    -   C: $N=16$, $c=1.0$, $\\lambda=0.0$, $h=0.1$, $T=50$. IC: $q_i(0) = 0.3 \\cos(4\\pi x_i)$, $p_i(0) = 0.3 \\sin(4\\pi x_i)$.\n    -   Grid points: $x_i = \\tfrac{i}{N}$ for $i=0,\\dots,N-1$.\n\n-   **Task**: For each test case and method, compute $\\Delta H_{\\max} = \\max_{n} | H(\\mathbf{q}_n,\\mathbf{p}_n) - H(\\mathbf{q}_0,\\mathbf{p}_0) |$.\n\n-   **Output Format**: A single line: `[[a1,a2,a3],[b1,b2,b3],[c1,c2,c3]]`.\n\n### Step 2: Validate Using Extracted Givens\n\n1.  **Scientifically Grounded**: The problem describes the numerical time integration of a semidiscrete system arising from the nonlinear wave equation. This is a standard topic in numerical analysis and computational physics. The Hamiltonian formulation, spectral discretization, and the specified geometric integrators (Gauss-Legendre, AVF, HBVM) are all well-established and mathematically sound concepts.\n2.  **Well-Posed**: The problem is well-posed. The system of ordinary differential equations is well-defined. The numerical methods are specified with sufficient detail (Butcher tableau, quadrature rules, basis functions) to ensure a unique implementation. The initial conditions are provided, leading to a unique solution for the time evolution.\n3.  **Objective**: The problem is stated in precise, objective, and mathematical language. It requires the implementation of specific algorithms and the calculation of a quantitative metric ($\\Delta H_{\\max}$). It is free of subjective or ambiguous terminology.\n4.  **Self-Contained and Consistent**: All necessary parameters, equations, initial conditions, and definitions are provided. The definitions of the methods are consistent with the literature on geometric integration. The provided Jacobian of the vector field is correct. The problem is self-contained.\n\n### Step 3: Verdict and Action\n\nThe problem is valid. It is a well-defined, scientifically sound task in the field of numerical analysis for partial differential equations. The instructions are clear and complete. Proceeding to solution.\n\n## Solution\n\nThe problem requires the implementation and comparison of three advanced numerical integrators for a Hamiltonian system. The system originates from the spatial discretization of the cubic nonlinear wave equation. The core of the task is to solve a system of implicit equations at each time step for each method, using Newton's method with the exact Jacobian.\n\n### 1. System Discretization and Core Functions\n\nFirst, we establish the components of the semidiscrete system. The state of the system is given by the vector $\\mathbf{y} = [\\mathbf{q}^\\top, \\mathbf{p}^\\top]^\\top \\in \\mathbb{R}^{2N}$.\n\n**Discrete Laplacian Operator ($L$)**: The operator $L$ represents minus the second spatial derivative on a periodic domain. It is defined using the discrete Fourier transform (DFT). For a vector $\\mathbf{q} \\in \\mathbb{R}^N$, $L\\mathbf{q}$ is computed as $L\\mathbf{q} = c^2 \\mathcal{F}^{-1}(k^2 \\mathcal{F}(\\mathbf{q}))$, where $\\mathcal{F}$ is the DFT and $k$ is the vector of angular frequencies. For a grid with $N$ points over $[0,1)$, the grid spacing is $\\Delta x=1/N$. The corresponding angular wavenumbers are $k_j = 2\\pi \\nu_j$, where $\\nu_j$ are the spatial frequencies given by `numpy.fft.fftfreq(N, d=1.0/N)`. The operator $L$ can be represented by a dense $N \\times N$ matrix, $L_{\\text{mat}}$, which is constructed by applying the operator to the canonical basis vectors of $\\mathbb{R}^N$. This matrix is pre-computed for use in the Jacobian of the vector field.\n\n**Hamiltonian and Vector Field**: The Hamiltonian $H(\\mathbf{q},\\mathbf{p})$ and the vector field $f(\\mathbf{y}) = J \\nabla H(\\mathbf{y})$ are implemented directly from their definitions. The vector field $f(\\mathbf{y})$ defines the right-hand side of the ODE system $\\dot{\\mathbf{y}} = f(\\mathbf{y})$.\n\n**Jacobian of the Vector Field ($Df(\\mathbf{y})$)**: The Jacobian of $f(\\mathbf{y})$ is a $2N \\times 2N$ block matrix given in the problem statement. Its lower-left block, $\\frac{\\partial f_p}{\\partial q} = -(L + 3\\lambda \\, \\mathrm{diag}(\\mathbf{q}^{\\circ 2}))$, depends on the state variable $\\mathbf{q}$. This state dependency makes the overall system nonlinear (for $\\lambda \\neq 0$) and requires re-evaluation of the Jacobian within the Newton iteration.\n\n**Newton's Method**: A generic Newton solver is implemented to find the root of a residual function $F(x)=0$. It iteratively computes $x_{k+1} = x_k - [J_F(x_k)]^{-1} F(x_k)$, where $J_F$ is the Jacobian of $F$. The linear system for the update is solved at each iteration.\n\n### 2. Time Integrators\n\nFor each integrator, we formulate the nonlinear system that must be solved at each time step and derive its corresponding residual and Jacobian for the Newton solver.\n\n#### Method 1: 2-stage Gauss–Legendre Runge-Kutta Method (GL2)\nThis is a fourth-order symplectic implicit Runge-Kutta method. The unknowns at each step are the two stage vectors, $Y_1, Y_2 \\in \\mathbb{R}^{2N}$. The total dimension of the unknown for the Newton solver is $4N$.\n-   **Residual**: The system to solve is $Y_i = \\mathbf{y}_n + h \\sum_{j=1}^2 a_{ij} f(Y_j)$ for $i=1,2$. The residual is constructed by bringing all terms to one side.\n-   **Jacobian**: The Jacobian of this $4N \\times 4N$ system with respect to the concatenated vector $[Y_1^\\top, Y_2^\\top]^\\top$ is a $2 \\times 2$ block matrix, where each block is a $2N \\times 2N$ matrix. The block $(i,j)$ is given by $\\delta_{ij}I_{2N} - h a_{ij} Df(Y_j)$, where $\\delta_{ij}$ is the Kronecker delta and $I_{2N}$ is the identity matrix.\n-   **Update**: After solving for $Y_1$ and $Y_2$, the state is advanced to $\\mathbf{y}_{n+1} = \\mathbf{y}_n + h (b_1 f(Y_1) + b_2 f(Y_2))$.\n\n#### Method 2: Average Vector Field Method (AVF)\nThe AVF method is designed to be exactly energy-preserving for any canonical Hamiltonian system. It defines the update $\\mathbf{y}_{n+1}$ implicitly.\n-   **Residual**: The integral in the update formula is approximated with 2-point Gauss-Legendre quadrature, yielding a nonlinear equation for $\\mathbf{y}_{n+1}$: $\\mathbf{y}_{n+1} - \\mathbf{y}_n - h \\sum_{j=1}^2 \\omega_j f((1-\\sigma_j)\\mathbf{y}_n + \\sigma_j \\mathbf{y}_{n+1}) = 0$. The left-hand side serves as the residual for the Newton method. The unknown is $\\mathbf{y}_{n+1} \\in \\mathbb{R}^{2N}$.\n-   **Jacobian**: The Jacobian of the residual with respect to $\\mathbf{y}_{n+1}$ is derived using the chain rule: $I_{2N} - h \\sum_{j=1}^2 \\omega_j \\sigma_j Df((1-\\sigma_j)\\mathbf{y}_n + \\sigma_j \\mathbf{y}_{n+1})$.\n\n#### Method 3: Hamiltonian Boundary Value Method (HBVM(4,2))\nHBVMs are a class of energy-preserving methods based on approximating the integral form of the solution using a polynomial expansion. Here, we use $s=2$ orthonormal Legendre polynomials on $[0,1]$, $P_0(\\tau)$ and $P_1(\\tau)$, and $k=4$ Gauss-Legendre quadrature points. The unknowns are the coefficients $\\gamma_0, \\gamma_1 \\in \\mathbb{R}^{2N}$ of the polynomial expansion.\n-   **Residual**: The unknowns $\\gamma_0, \\gamma_1$ are defined implicitly by the system:\n    $\\gamma_0 = \\sum_{\\ell=1}^4 \\omega_\\ell f(Y_\\ell)$\n    $\\gamma_1 = \\sum_{\\ell=1}^4 \\omega_\\ell P_1(c_\\ell) f(Y_\\ell)$\n    where the stage values $Y_\\ell$ depend linearly on $\\gamma_0$ and $\\gamma_1$. This $4N \\times 4N$ system defines the residual.\n-   **Jacobian**: The Jacobian of the residual system with respect to the concatenated vector $[\\gamma_0^\\top, \\gamma_1^\\top]^\\top$ is derived using the chain rule. It forms a $2 \\times 2$ block matrix of $2N \\times 2N$ blocks, where each block involves a weighted sum of the Jacobians $Df(Y_\\ell)$ at the quadrature points.\n-   **Update**: Once $\\gamma_0$ and $\\gamma_1$ are found, the state is updated by $\\mathbf{y}_{n+1} = \\mathbf{y}_n + h\\gamma_0$, which follows from integrating the polynomial approximation over the time step.\n\n### 3. Simulation and Analysis\nFor each of the three test cases, a simulation is run using each of the three methods. The initial condition $(\\mathbf{q}_0, \\mathbf{p}_0)$ is set, and the initial energy $H_0 = H(\\mathbf{q}_0, \\mathbf{p}_0)$ is calculated. The system is evolved up to the final time $T$. At each time step $t_n$, the energy $H_n = H(\\mathbf{q}_n, \\mathbf{p}_n)$ is computed. The maximum absolute deviation from the initial energy, $\\Delta H_{\\max} = \\max_n |H_n - H_0|$, is recorded as the performance metric for each simulation run. The results are then collated and formatted as specified.", "answer": "```python\nimport numpy as np\nfrom numpy.fft import fft, ifft\n\ndef solve():\n    \"\"\"\n    Implements and compares three geometric integrators for a semidiscrete\n    nonlinear wave equation.\n    \"\"\"\n\n    # --- Core Physics and Discretization ---\n    def setup_laplacian(N, c):\n        \"\"\"\n        Sets up the spectral Laplacian operator and its matrix form.\n        \"\"\"\n        k_wave_numbers = np.fft.fftfreq(N, d=1.0/N)\n        k = 2 * np.pi * k_wave_numbers\n        k_squared = k**2\n        \n        def apply_L(q):\n            return (c**2 * ifft(k_squared * fft(q))).real\n        \n        L_mat = np.zeros((N, N), dtype=float)\n        for i in range(N):\n            e_i = np.zeros(N)\n            e_i[i] = 1.0\n            L_mat[:, i] = apply_L(e_i)\n            \n        return apply_L, L_mat\n\n    def hamiltonian(y, apply_L, lam):\n        \"\"\"\n        Computes the Hamiltonian (total energy) of the system.\n        \"\"\"\n        N = len(y) // 2\n        q, p = y[:N], y[N:]\n        Lq = apply_L(q)\n        H_linear_q = 0.5 * np.dot(q, Lq)\n        H_p = 0.5 * np.dot(p, p)\n        H_nonlinear = (lam / 4.0) * np.sum(q**4)\n        return H_p + H_linear_q + H_nonlinear\n\n    def vector_field(y, apply_L, lam):\n        \"\"\"\n        Computes the vector field f(y) for the ODE y' = f(y).\n        \"\"\"\n        N = len(y) // 2\n        q, p = y[:N], y[N:]\n        fq = p\n        fp = -(apply_L(q) + lam * q**3)\n        return np.concatenate([fq, fp])\n\n    def jacobian_vector_field(y, L_mat, lam):\n        \"\"\"\n        Computes the Jacobian of the vector field, Df(y).\n        \"\"\"\n        N = len(y) // 2\n        q = y[:N]\n        I_N = np.eye(N)\n        Z_NN = np.zeros((N, N))\n        J_qq = -(L_mat + 3 * lam * np.diag(q**2))\n        return np.block([[Z_NN, I_N], [J_qq, Z_NN]])\n    \n    # --- Newton Solver ---\n    def newton_solver(F_func, J_func, y0, tol, max_iter):\n        \"\"\"\n        Solves F(y) = 0 using Newton's method.\n        \"\"\"\n        y = y0.copy()\n        for _ in range(max_iter):\n            F = F_func(y)\n            try:\n                J = J_func(y)\n                dy = np.linalg.solve(J, -F)\n            except np.linalg.LinAlgError:\n                J_pinv = np.linalg.pinv(J, rcond=1e-15)\n                dy = -J_pinv @ F\n            \n            y += dy\n            if np.linalg.norm(dy) < tol:\n                break\n        return y\n\n    # --- Integrators ---\n    def solve_gl2(y0, h, T, apply_L, L_mat, lam):\n        \"\"\"\n        Integrator 1: 2-stage Gauss-Legendre Runge-Kutta method.\n        \"\"\"\n        dim_y = len(y0)\n        s3 = np.sqrt(3)\n        A = np.array([[1/4, 1/4 - s3/6], [1/4 + s3/6, 1/4]])\n        b = np.array([1/2, 1/2])\n        \n        num_steps = int(round(T / h))\n        y_n = y0.copy()\n        H_initial = hamiltonian(y_n, apply_L, lam)\n        max_H_dev = 0.0\n\n        for _ in range(num_steps):\n            Y_guess = np.concatenate([y_n, y_n])\n            \n            def residual_gl2(Y_flat):\n                Y1, Y2 = Y_flat[:dim_y], Y_flat[dim_y:]\n                f_Y1 = vector_field(Y1, apply_L, lam)\n                f_Y2 = vector_field(Y2, apply_L, lam)\n                res1 = Y1 - y_n - h * (A[0,0] * f_Y1 + A[0,1] * f_Y2)\n                res2 = Y2 - y_n - h * (A[1,0] * f_Y1 + A[1,1] * f_Y2)\n                return np.concatenate([res1, res2])\n\n            def jacobian_gl2(Y_flat):\n                Y1, Y2 = Y_flat[:dim_y], Y_flat[dim_y:]\n                Df_Y1 = jacobian_vector_field(Y1, L_mat, lam)\n                Df_Y2 = jacobian_vector_field(Y2, L_mat, lam)\n                I = np.eye(dim_y)\n                J11 = I - h * A[0,0] * Df_Y1\n                J12 = -h * A[0,1] * Df_Y2\n                J21 = -h * A[1,0] * Df_Y1\n                J22 = I - h * A[1,1] * Df_Y2\n                return np.block([[J11, J12], [J21, J22]])\n\n            Y_sol_flat = newton_solver(residual_gl2, jacobian_gl2, Y_guess, 1e-10, 20)\n            Y1_sol, Y2_sol = Y_sol_flat[:dim_y], Y_sol_flat[dim_y:]\n            f_Y1_sol = vector_field(Y1_sol, apply_L, lam)\n            f_Y2_sol = vector_field(Y2_sol, apply_L, lam)\n            y_n += h * (b[0] * f_Y1_sol + b[1] * f_Y2_sol)\n            H_current = hamiltonian(y_n, apply_L, lam)\n            max_H_dev = max(max_H_dev, abs(H_current - H_initial))\n        return max_H_dev\n\n    def solve_avf(y0, h, T, apply_L, L_mat, lam):\n        \"\"\"\n        Integrator 2: Average Vector Field (AVF) method.\n        \"\"\"\n        dim_y = len(y0)\n        s1 = 0.5 - 1.0 / (2.0 * np.sqrt(3.0))\n        s2 = 0.5 + 1.0 / (2.0 * np.sqrt(3.0))\n        \n        num_steps = int(round(T / h))\n        y_n = y0.copy()\n        H_initial = hamiltonian(y_n, apply_L, lam)\n        max_H_dev = 0.0\n\n        for _ in range(num_steps):\n            y_guess = y_n.copy()\n            def residual_avf(y_np1):\n                y_s1 = (1 - s1) * y_n + s1 * y_np1\n                y_s2 = (1 - s2) * y_n + s2 * y_np1\n                f_s1 = vector_field(y_s1, apply_L, lam)\n                f_s2 = vector_field(y_s2, apply_L, lam)\n                return y_np1 - y_n - h * 0.5 * (f_s1 + f_s2)\n            \n            def jacobian_avf(y_np1):\n                y_s1 = (1 - s1) * y_n + s1 * y_np1\n                y_s2 = (1 - s2) * y_n + s2 * y_np1\n                Df_s1 = jacobian_vector_field(y_s1, L_mat, lam)\n                Df_s2 = jacobian_vector_field(y_s2, L_mat, lam)\n                return np.eye(dim_y) - (h / 2.0) * (s1 * Df_s1 + s2 * Df_s2)\n\n            y_n = newton_solver(residual_avf, jacobian_avf, y_guess, 1e-10, 20)\n            H_current = hamiltonian(y_n, apply_L, lam)\n            max_H_dev = max(max_H_dev, abs(H_current - H_initial))\n        return max_H_dev\n\n    def solve_hbvm(y0, h, T, apply_L, L_mat, lam):\n        \"\"\"\n        Integrator 3: Hamiltonian Boundary Value Method (HBVM(4,2)).\n        \"\"\"\n        dim_y = len(y0)\n        s3 = np.sqrt(3.0)\n        nodes_m11, weights_m11 = np.polynomial.legendre.leggauss(4)\n        c_nodes = (nodes_m11 + 1.0) / 2.0\n        w_weights = weights_m11 / 2.0\n        alpha_l0 = c_nodes\n        alpha_l1 = s3 * (c_nodes**2 - c_nodes)\n        P1_c = s3 * (2 * c_nodes - 1)\n        \n        num_steps = int(round(T / h))\n        y_n = y0.copy()\n        H_initial = hamiltonian(y_n, apply_L, lam)\n        max_H_dev = 0.0\n\n        for _ in range(num_steps):\n            gamma_guess = np.zeros(2*dim_y)\n            gamma_guess[:dim_y] = vector_field(y_n, apply_L, lam)\n\n            def residual_hbvm(Gamma_flat):\n                g0, g1 = Gamma_flat[:dim_y], Gamma_flat[dim_y:]\n                f_sum0 = np.zeros(dim_y)\n                f_sum1 = np.zeros(dim_y)\n                for l in range(4):\n                    Y_l = y_n + h * (alpha_l0[l] * g0 + alpha_l1[l] * g1)\n                    f_Y_l = vector_field(Y_l, apply_L, lam)\n                    f_sum0 += w_weights[l] * f_Y_l\n                    f_sum1 += w_weights[l] * P1_c[l] * f_Y_l\n                return np.concatenate([g0 - f_sum0, g1 - f_sum1])\n\n            def jacobian_hbvm(Gamma_flat):\n                g0, g1 = Gamma_flat[:dim_y], Gamma_flat[dim_y:]\n                I, Z_ = np.eye(dim_y), np.zeros((dim_y, dim_y))\n                J00, J01, J10, J11 = I.copy(), Z_.copy(), Z_.copy(), I.copy()\n                for l in range(4):\n                    Y_l = y_n + h * (alpha_l0[l] * g0 + alpha_l1[l] * g1)\n                    Df_l = jacobian_vector_field(Y_l, L_mat, lam)\n                    w_l = w_weights[l]\n                    J00 -= h * w_l * alpha_l0[l] * Df_l\n                    J01 -= h * w_l * alpha_l1[l] * Df_l\n                    J10 -= h * w_l * P1_c[l] * alpha_l0[l] * Df_l\n                    J11 -= h * w_l * P1_c[l] * alpha_l1[l] * Df_l\n                return np.block([[J00, J01], [J10, J11]])\n\n            Gamma_sol = newton_solver(residual_hbvm, jacobian_hbvm, gamma_guess, 1e-10, 20)\n            g0_sol = Gamma_sol[:dim_y]\n            y_n += h * g0_sol\n            H_current = hamiltonian(y_n, apply_L, lam)\n            max_H_dev = max(max_H_dev, abs(H_current - H_initial))\n        return max_H_dev\n\n    # --- Main Simulation Runner ---\n    test_cases_defs = [\n        {'N': 32, 'c': 1.0, 'lam': 0.1, 'h': 0.05, 'T': 10, \n         'q0_func': lambda x: 0.2 * np.cos(2*np.pi*x), \n         'p0_func': lambda x: 0.2 * np.sin(2*np.pi*x)},\n        {'N': 64, 'c': 1.0, 'lam': 1.0, 'h': 0.02, 'T': 4,\n         'q0_func': lambda x: 0.5 * np.cos(2*np.pi*x),\n         'p0_func': lambda x: np.zeros_like(x)},\n        {'N': 16, 'c': 1.0, 'lam': 0.0, 'h': 0.1, 'T': 50,\n         'q0_func': lambda x: 0.3 * np.cos(4*np.pi*x),\n         'p0_func': lambda x: 0.3 * np.sin(4*np.pi*x)}\n    ]\n    \n    methods = [solve_gl2, solve_avf, solve_hbvm]\n    all_results = []\n    \n    for case_params in test_cases_defs:\n        N = case_params['N']\n        x = np.arange(N) / N\n        y0 = np.concatenate([case_params['q0_func'](x), case_params['p0_func'](x)])\n        apply_L, L_mat = setup_laplacian(N, case_params['c'])\n        \n        case_results = []\n        for method in methods:\n            val = method(y0.copy(), case_params['h'], case_params['T'], apply_L, L_mat, case_params['lam'])\n            case_results.append(val)\n        all_results.append(case_results)\n        \n    output_str = \"[\" + \",\".join([f\"[{','.join(f'{v:.6e}' for v in r)}]\" for r in all_results]) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "3421719"}]}