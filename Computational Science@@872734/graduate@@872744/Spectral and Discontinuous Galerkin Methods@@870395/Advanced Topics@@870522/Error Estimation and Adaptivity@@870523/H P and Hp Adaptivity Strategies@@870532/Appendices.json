{"hands_on_practices": [{"introduction": "The foundation of any adaptive method is the ability to estimate where the numerical error is largest. This exercise provides concrete practice in calculating the components of a standard residual-based a posteriori error indicator for a Discontinuous Galerkin method. By working with given numerical values for residuals and jumps, you will gain an intuition for how different sources of error contribute to the local indicator and how these contributions are weighted by the mesh size $h$ and polynomial degree $p$ [@problem_id:3389838].", "problem": "Consider the scalar Poisson problem on a two-dimensional domain discretized by the Symmetric Interior Penalty Discontinuous Galerkin method (SIPDG). Let a single interior quadrilateral element $T$ be a square of side length $h=10^{-1}$ with polynomial degree $p=3$. Denote the interior residual by $r_{T}=f+\\Delta u_{h}$, the jump of the normal component of the gradient across face $F$ by $j_{F}=[\\nabla u_{h}\\cdot n_{F}]$, and the solution jump across face $F$ by $s_{F}=[u_{h}]$. Assume the penalty parameter has the canonical SIPDG scaling $\\sigma=\\kappa p^{2}/h$, and set the shape-regular constants and $\\kappa$ equal to $1$.\n\nYou are given the following $L^{2}$-norms:\n- The interior residual norm on $T$: $\\|r_{T}\\|_{T}=2.0$.\n- The flux-jump norms on the four faces $F_{1},F_{2},F_{3},F_{4}$: $\\|j_{F_{1}}\\|_{F_{1}}=1.5$, $\\|j_{F_{2}}\\|_{F_{2}}=0.6$, $\\|j_{F_{3}}\\|_{F_{3}}=1.0$, $\\|j_{F_{4}}\\|_{F_{4}}=0.2$.\n- The solution-jump norms on the four faces: $\\|s_{F_{1}}\\|_{F_{1}}=2\\times 10^{-2}$, $\\|s_{F_{2}}\\|_{F_{2}}=8\\times 10^{-2}$, $\\|s_{F_{3}}\\|_{F_{3}}=4\\times 10^{-2}$, $\\|s_{F_{4}}\\|_{F_{4}}=10^{-1}$.\n\nThe local error indicator $\\eta_T$ is defined by its square, $\\eta_T^2$, which is a sum of contributions from the element interior and its faces. The face contribution for a single face $F$ is denoted $\\eta_F^2$ and is composed of a flux-jump term and a solution-jump term. Using the canonical $h$-$p$ scalings consistent with the main text, the squared face contribution is:\n$$\n\\eta_F^2 = \\frac{h}{p} \\|j_F\\|_F^2 + \\frac{p^2}{h} \\|s_F\\|_F^2\n$$\nCompute the squared face contribution $\\eta_{F_i}^2$ for each of the four faces $i \\in \\{1,2,3,4\\}$.\n\nFinally, determine which face $F_{i}$ has the largest face contribution (i.e., dominates the face-based error) and report, as the final answer, the index $i\\in\\{1,2,3,4\\}$ of that dominating face. No rounding is required and the final answer must be the single integer index $i$ without any units.", "solution": "The problem asks to identify the face of a quadrilateral element that provides the largest contribution to the local a posteriori error indicator in a Symmetric Interior Penalty Discontinuous Galerkin (SIPDG) method. The local indicator $\\eta_T$ is defined by its square, $\\eta_T^2$, which is composed of contributions from the element's interior and its faces. We are interested in the face contributions, $\\eta_{F_i}^2$.\n\nThe squared contribution from a face $F$ is the sum of a flux-jump term and a solution-jump term, each weighted by factors dependent on the element size $h$ and polynomial degree $p$. Based on standard theory for $hp$-DG methods, these weights are chosen to balance the terms and ensure the estimator is reliable and efficient. The formula given is:\n$$\n\\eta_F^2 = \\frac{h}{p} \\|j_F\\|_F^2 + \\frac{p^2}{h} \\|s_F\\|_F^2\n$$\nwhere $j_F$ is the flux jump and $s_F$ is the solution jump across face $F$.\n\nWe are given the following parameters and data:\n- Element size: $h = 10^{-1}$\n- Polynomial degree: $p = 3$\n- Face jump norms: $\\|j_{F_{1}}\\|=1.5$, $\\|j_{F_{2}}\\|=0.6$, $\\|j_{F_{3}}\\|=1.0$, $\\|j_{F_{4}}\\|=0.2$\n- Solution jump norms: $\\|s_{F_{1}}\\|=2\\times 10^{-2}$, $\\|s_{F_{2}}\\|=8\\times 10^{-2}$, $\\|s_{F_{3}}\\|=4\\times 10^{-2}$, $\\|s_{F_{4}}\\|=10^{-1}$\n\nFirst, we compute the scaling factors:\n$$\n\\frac{h}{p} = \\frac{10^{-1}}{3} = \\frac{1}{30}\n$$\n$$\n\\frac{p^2}{h} = \\frac{3^2}{10^{-1}} = \\frac{9}{0.1} = 90\n$$\n\nNow, we compute the squared contribution $\\eta_{F_i}^2$ for each of the four faces:\n\n- **Face $F_1$**:\n$$\n\\eta_{F_1}^2 = \\frac{1}{30}(1.5)^2 + 90(2\\times 10^{-2})^2 = \\frac{2.25}{30} + 90(4\\times 10^{-4}) = 0.075 + 0.036 = 0.111\n$$\n\n- **Face $F_2$**:\n$$\n\\eta_{F_2}^2 = \\frac{1}{30}(0.6)^2 + 90(8\\times 10^{-2})^2 = \\frac{0.36}{30} + 90(64\\times 10^{-4}) = 0.012 + 0.576 = 0.588\n$$\n\n- **Face $F_3$**:\n$$\n\\eta_{F_3}^2 = \\frac{1}{30}(1.0)^2 + 90(4\\times 10^{-2})^2 = \\frac{1}{30} + 90(16\\times 10^{-4}) \\approx 0.0333 + 0.144 = 0.1773\n$$\n\n- **Face $F_4$**:\n$$\n\\eta_{F_4}^2 = \\frac{1}{30}(0.2)^2 + 90(10^{-1})^2 = \\frac{0.04}{30} + 90(10^{-2}) \\approx 0.0013 + 0.9 = 0.9013\n$$\n\nTo determine the dominating face, we compare the squared contributions:\n$$\n\\eta_{F_1}^2 = 0.111, \\quad \\eta_{F_2}^2 = 0.588, \\quad \\eta_{F_3}^2 \\approx 0.1773, \\quad \\eta_{F_4}^2 \\approx 0.9013\n$$\nThe largest value is $\\eta_{F_4}^2$, which means the error contribution from face $F_4$ is the largest. Therefore, the dominating face is $F_4$. The index is 4.", "answer": "$$\\boxed{4}$$", "id": "3389838"}, {"introduction": "Once local error indicators are computed for all elements, the next step is to decide which elements to refine. The Dörfler (or bulk) marking strategy provides a simple, effective, and theoretically sound method for making this selection. This practice focuses on the core algorithmic step of marking, where you will apply the Dörfler criterion to a given set of indicators to identify the minimal set of elements for refinement, thereby ensuring that the computational effort is directed where it is most needed [@problem_id:3389874].", "problem": "Consider a one-dimensional Discontinuous Galerkin (DG) discretization of a scalar elliptic boundary value problem on a mesh with $10$ elements. A reliable and efficient residual-based estimator provides nonnegative local indicators $\\{\\eta_{K}\\}_{K=1}^{10}$ for the current mesh, listed below with element indices $K=1,2,\\dots,10$:\n- $K=1$: $\\eta_{1}=0.90$,\n- $K=2$: $\\eta_{2}=0.85$,\n- $K=3$: $\\eta_{3}=0.75$,\n- $K=4$: $\\eta_{4}=0.60$,\n- $K=5$: $\\eta_{5}=0.58$,\n- $K=6$: $\\eta_{6}=0.40$,\n- $K=7$: $\\eta_{7}=0.35$,\n- $K=8$: $\\eta_{8}=0.30$,\n- $K=9$: $\\eta_{9}=0.25$,\n- $K=10$: $\\eta_{10}=0.20$.\n\nUsing the Dörfler bulk marking strategy with parameter $\\theta=0.50$, determine the smallest number of elements that must be marked. The standard Dörfler criterion states that the sum of the **squared** marked indicators must be at least $\\theta$ times the total sum of all **squared** indicators. Within your reasoning, justify why the procedure you use minimizes the number of marked elements.\n\nReport your final answer as the minimal cardinality $m$ of the marked set. No rounding is required.", "solution": "The problem requires applying the Dörfler bulk marking strategy to a set of local error indicators $\\{\\eta_K\\}_{K=1}^{10}$. The goal is to find the minimum number of elements to mark for refinement.\n\nThe Dörfler marking criterion identifies a set of marked elements $\\mathcal{M}$ from the total set of elements $\\mathcal{T}$. For a given bulk parameter $\\theta$, the condition is that the sum of the squared local error indicators of the marked elements must be at least a fraction $\\theta$ of the total sum of all squared indicators. Mathematically:\n$$\n\\sum_{K \\in \\mathcal{M}} \\eta_K^2 \\ge \\theta \\sum_{K \\in \\mathcal{T}} \\eta_K^2\n$$\nThe problem asks for the smallest cardinality, $m = |\\mathcal{M}|$, of a set $\\mathcal{M}$ satisfying this.\n\nFirst, we list the given data:\n- The local error indicators:\n  $\\eta_{1}=0.90$, $\\eta_{2}=0.85$, $\\eta_{3}=0.75$, $\\eta_{4}=0.60$, $\\eta_{5}=0.58$, $\\eta_{6}=0.40$, $\\eta_{7}=0.35$, $\\eta_{8}=0.30$, $\\eta_{9}=0.25$, $\\eta_{10}=0.20$.\n- The Dörfler marking parameter: $\\theta = 0.50$.\n\nThe first step is to compute the square of each indicator and their total sum, $E^2_{\\text{total}}$.\n- $\\eta_1^2 = 0.81$\n- $\\eta_2^2 = 0.7225$\n- $\\eta_3^2 = 0.5625$\n- $\\eta_4^2 = 0.36$\n- $\\eta_5^2 = 0.3364$\n- $\\eta_6^2 = 0.16$\n- $\\eta_7^2 = 0.1225$\n- $\\eta_8^2 = 0.09$\n- $\\eta_9^2 = 0.0625$\n- $\\eta_{10}^2 = 0.04$\n\n$$\nE^2_{\\text{total}} = \\sum_{K=1}^{10} \\eta_K^2 = 0.81 + 0.7225 + 0.5625 + 0.36 + 0.3364 + 0.16 + 0.1225 + 0.09 + 0.0625 + 0.04 = 3.2664\n$$\nNext, we calculate the target sum required by the Dörfler criterion, $E^2_{\\text{target}}$.\n$$\nE^2_{\\text{target}} = \\theta \\cdot E^2_{\\text{total}} = 0.50 \\times 3.2664 = 1.6332\n$$\nTo find the set $\\mathcal{M}$ with the minimum number of elements, we should greedily select elements with the largest squared indicators until their cumulative sum meets or exceeds the target. The indicators are already sorted in descending order, so their squares are also sorted.\n\nLet's compute the cumulative sum of the squared indicators, starting from the largest:\n1.  Mark element $K=1$: Cumulative sum = $\\eta_1^2 = 0.81$. This is less than $1.6332$.\n2.  Mark element $K=2$: Cumulative sum = $0.81 + \\eta_2^2 = 0.81 + 0.7225 = 1.5325$. This is less than $1.6332$.\n3.  Mark element $K=3$: Cumulative sum = $1.5325 + \\eta_3^2 = 1.5325 + 0.5625 = 2.095$. This is greater than or equal to $1.6332$.\n\nThe condition is met after marking 3 elements. The set of marked elements is $\\mathcal{M} = \\{K=1, K=2, K=3\\}$. The minimal cardinality is $m=3$.\n\nThis greedy procedure is guaranteed to find the minimal set. To satisfy the criterion with the fewest elements, one must always choose the elements that contribute the most to the sum. Since all $\\eta_K^2$ are non-negative, the largest contributions come from the elements with the largest $\\eta_K^2$ values. Any other set of 3 elements would have a sum of squared indicators less than or equal to the sum for $\\{K=1, K=2, K=3\\}$. Any set with fewer than 3 elements (i.e., 1 or 2 elements) would have a sum less than the target, as shown by our cumulative sum calculation. Therefore, 3 is the minimum number of elements that must be marked.", "answer": "$$\n\\boxed{3}\n$$", "id": "3389874"}, {"introduction": "A truly sophisticated $hp$-adaptive strategy goes beyond simply marking elements; it must also decide *how* to refine them ($h$-refinement, $p$-refinement, or both) while respecting computational constraints. This capstone exercise simulates a complete $hp$-decision step, where you will balance the predicted error reduction (benefit) against the increase in degrees of freedom (cost) for each potential refinement. By framing the final selection as an optimization problem, this practice integrates the concepts of error estimation, cost modeling, and resource allocation that are central to modern adaptive algorithms [@problem_id:3389819].", "problem": "Consider a mesh of elements used in a Spectral Element Method (SEM) with a Discontinuous Galerkin (DG) formulation. Each element $K$ is characterized by its current mesh size $h_K$, local polynomial degree $p_K$, and a non-negative local error indicator $\\eta_K$. The domain dimension is $d \\in \\{1,2,3\\}$, and the basis functions per element are tensor-product polynomials. The number of scalar degrees of freedom (DOFs) per element is modeled as $(p_K+1)^d$. You will simulate a single global decision step of an $hp$-adaptivity algorithm under a fixed budget of additional DOFs, deciding for each element whether to perform an $h$-refinement (split the element) or a $p$-refinement (increase the local polynomial degree), and then selecting a subset of these candidate actions to fit the budget while maximizing predicted error decrease.\n\nUse the following foundational principles and well-tested facts as the base of your model:\n\n- In DG and spectral element methods, the number of local basis functions per element for tensor-product polynomials of degree $p_K$ in $d$ dimensions is $(p_K+1)^d$.\n- A uniform $h$-refinement in $d$ dimensions splits one parent element into $2^d$ child elements, thereby increasing the global DOFs. The additional DOF cost of performing this $h$-refinement on a single element $K$ with degree $p_K$ is $\\Delta\\mathrm{dof}_h(K) = \\big(2^d-1\\big)\\,(p_K+1)^d$.\n- A $p$-refinement increases the local polynomial degree by $1$, from $p_K$ to $p_K+1$, with additional DOF cost $\\Delta\\mathrm{dof}_p(K) = \\big((p_K+2)^d-(p_K+1)^d\\big)$, provided $p_K < p_{\\max}$.\n- For smooth solutions, the $h$-convergence rate of DG methods is algebraic of order $p_K+1$; under limited regularity, the effective rate is capped. Model the predicted error indicator after one $h$-refinement on element $K$ as $\\eta'_h(K) = \\eta_K\\,2^{-\\mu_K}$ with $\\mu_K = \\min(p_K+1, r_{\\max})$, where $r_{\\max}$ is a regularity cap supplied as a global constant.\n- For analytic/sufficiently smooth solutions, $p$-refinement typically exhibits exponential convergence. Model the predicted error indicator after one $p$-refinement on element $K$ as $\\eta'_p(K) = \\eta_K\\,e^{-b}$, where $b>0$ is a global saturation constant.\n\nDefine the local benefit of an action on element $K$ as the predicted reduction in the local error indicator:\n- $B_h(K) = \\eta_K - \\eta'_h(K)$ for $h$-refinement,\n- $B_p(K) = \\eta_K - \\eta'_p(K)$ for $p$-refinement (only if $p_K < p_{\\max}$).\n\nDefine the local efficiency ratio of an action as benefit divided by additional DOF cost:\n- $R_h(K) = \\dfrac{B_h(K)}{\\Delta\\mathrm{dof}_h(K)}$,\n- $R_p(K) = \\dfrac{B_p(K)}{\\Delta\\mathrm{dof}_p(K)}$ (only if $p_K < p_{\\max}$).\n\nFor each element $K$, select a single proposed action as follows:\n- If $p_K < p_{\\max}$, compare $R_h(K)$ and $R_p(K)$; propose the action with larger ratio (if equal, choose $p$-refinement).\n- If $p_K \\ge p_{\\max}$, propose $h$-refinement.\nIf the proposed action’s additional DOF cost exceeds the budget, it may still be proposed but will only be taken if the global selection under the budget allows it.\n\nGiven a total additional DOF budget $B$, choose a subset of the proposed element actions that maximizes the sum of their benefits $\\sum B(\\cdot)$ subject to the sum of their costs $\\sum \\Delta\\mathrm{dof}(\\cdot) \\le B$. This is a $0$-$1$ knapsack selection.\n\nUpon selecting the subset, update the element states:\n- For a selected $h$-refinement on element $K$, set $h_K \\leftarrow h_K/2$ and keep $p_K$ unchanged.\n- For a selected $p$-refinement on element $K$, set $p_K \\leftarrow p_K+1$ and keep $h_K$ unchanged.\nElements not selected remain unchanged. Do not create or delete elements; the $h$-refinement is recorded by halving $h_K$ of the existing element.\n\nAll quantities are dimensionless in this problem. You must implement the above decision and selection logic and return the updated states and summary metrics for each test case.\n\nTest Suite:\nUse the following four test cases. For each case, the inputs are $(d, p_{\\max}, r_{\\max}, b, B)$ and a list of elements with triples $(h_K, p_K, \\eta_K)$:\n\n- Case $1$ (general case):\n  - $d=2$, $p_{\\max}=6$, $r_{\\max}=3$, $b=0.7$, $B=60$.\n  - Elements:\n    - $K_1$: $(h_{K_1}, p_{K_1}, \\eta_{K_1}) = (0.25, 2, 0.08)$,\n    - $K_2$: $(h_{K_2}, p_{K_2}, \\eta_{K_2}) = (0.10, 3, 0.02)$,\n    - $K_3$: $(h_{K_3}, p_{K_3}, \\eta_{K_3}) = (0.20, 1, 0.15)$,\n    - $K_4$: $(h_{K_4}, p_{K_4}, \\eta_{K_4}) = (0.05, 4, 0.01)$,\n    - $K_5$: $(h_{K_5}, p_{K_5}, \\eta_{K_5}) = (0.30, 0, 0.25)$.\n- Case $2$ (zero budget boundary):\n  - $d=1$, $p_{\\max}=5$, $r_{\\max}=4$, $b=0.5$, $B=0$.\n  - Elements:\n    - $K_1$: $(h_{K_1}, p_{K_1}, \\eta_{K_1}) = (0.50, 2, 0.12)$,\n    - $K_2$: $(h_{K_2}, p_{K_2}, \\eta_{K_2}) = (0.30, 0, 0.06)$,\n    - $K_3$: $(h_{K_3}, p_{K_3}, \\eta_{K_3}) = (0.25, 4, 0.02)$.\n- Case $3$ (high dimension with $p$ capped):\n  - $d=3$, $p_{\\max}=2$, $r_{\\max}=2$, $b=1.0$, $B=100$.\n  - Elements:\n    - $K_1$: $(h_{K_1}, p_{K_1}, \\eta_{K_1}) = (0.20, 2, 0.20)$,\n    - $K_2$: $(h_{K_2}, p_{K_2}, \\eta_{K_2}) = (0.10, 2, 0.05)$,\n    - $K_3$: $(h_{K_3}, p_{K_3}, \\eta_{K_3}) = (0.15, 1, 0.10)$.\n- Case $4$ (mixed actions under tight budget):\n  - $d=2$, $p_{\\max}=5$, $r_{\\max}=2$, $b=0.3$, $B=20$.\n  - Elements:\n    - $K_1$: $(h_{K_1}, p_{K_1}, \\eta_{K_1}) = (0.40, 0, 0.50)$,\n    - $K_2$: $(h_{K_2}, p_{K_2}, \\eta_{K_2}) = (0.10, 5, 0.04)$,\n    - $K_3$: $(h_{K_3}, p_{K_3}, \\eta_{K_3}) = (0.20, 2, 0.12)$,\n    - $K_4$: $(h_{K_4}, p_{K_4}, \\eta_{K_4}) = (0.30, 1, 0.08)$.\n\nFinal Output Format:\nYour solution should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, output a list with three entries:\n- the flattened list of updated states in the form $[h_{K_1}, p_{K_1}, h_{K_2}, p_{K_2}, \\dots]$,\n- the integer total of used additional DOFs,\n- the float total predicted error reduction (sum of selected benefits).\n\nTherefore, the overall output is a list of these per-case lists, e.g., $[[[\\dots], \\mathrm{used\\_dofs}_1, \\mathrm{total\\_reduction}_1], [[\\dots], \\mathrm{used\\_dofs}_2, \\mathrm{total\\_reduction}_2], \\dots]$ printed on one line. All numeric values should be represented as Python numbers in the output.", "solution": "We base the design on standard modeling for Discontinuous Galerkin (DG) spectral element methods, combining the degrees of freedom (DOFs) scaling with $h$- and $p$-convergence properties to formulate an $hp$-decision under a DOF budget.\n\nFundamental base:\n- The number of local basis functions (and thus local scalar DOFs) for tensor-product polynomials of degree $p_K$ in $d$ dimensions is $(p_K+1)^d$.\n- Uniform $h$-refinement of one element in $d$ dimensions creates $2^d$ children. The global increment in DOFs attributable to refining this one element is $\\Delta\\mathrm{dof}_h(K)=\\big(2^d-1\\big)\\,(p_K+1)^d$.\n- A $p$-refinement of one element increases its local degree from $p_K$ to $p_K+1$. The incremental DOFs are $\\Delta\\mathrm{dof}_p(K)=\\big((p_K+2)^d-(p_K+1)^d\\big)$, provided $p_K < p_{\\max}$.\n\nError indicator models:\n- For $h$-refinement, the error contracts multiplicatively by a factor $2^{-\\mu_K}$ with $\\mu_K=\\min(p_K+1,r_{\\max})$. Thus, the benefit is $B_h(K)=\\eta_K\\big(1-2^{-\\mu_K}\\big)$.\n- For $p$-refinement, we adopt the saturation model $\\eta'_p(K)=\\eta_K\\,e^{-b}$. The benefit is $B_p(K)=\\eta_K\\big(1-e^{-b}\\big)$.\n\nEfficiency and local proposal:\n- Define the efficiency ratios $R_h(K)=\\dfrac{B_h(K)}{\\Delta\\mathrm{dof}_h(K)}$ and $R_p(K)=\\dfrac{B_p(K)}{\\Delta\\mathrm{dof}_p(K)}$ if $p_K<p_{\\max}$. For each element, propose the action (either $h$ or $p$) with the larger ratio; if $p_K\\ge p_{\\max}$ then only $h$ is eligible. In ties, prefer $p$.\n\nGlobal selection under budget:\n- With a total budget $B$ of additional DOFs, we choose a subset of proposed actions that maximizes the total predicted benefit subject to the sum of costs not exceeding $B$. This is the classical $0$-$1$ knapsack problem, which can be solved optimally using dynamic programming.\n\nState update rules:\n- If an element’s selected action is $h$-refinement, set $h_K\\leftarrow h_K/2$. If the action is $p$-refinement, set $p_K\\leftarrow p_K+1$. Elements not selected remain unchanged.\n\nThe final implementation involves executing these steps for each test case:\n1. For each element, compute the cost, benefit, and efficiency ratio for both $h$- and $p$-refinement (if eligible).\n2. Based on the efficiency ratios, determine the single best proposed action for each element.\n3. Formulate a list of items for the knapsack problem, where each item is a proposed action with its associated cost (DOFs) and value (benefit).\n4. Solve the knapsack problem to find the optimal set of actions that fit within the DOF budget.\n5. Update the state of each element ($h_K, p_K$) based on the selected actions.\n6. Collate the results (updated states, total used DOFs, and total benefit) for all test cases into the specified output format.", "answer": "[[[0.25, 3, 0.1, 4, 0.2, 2, 0.05, 5, 0.3, 1], 35, 0.2530188081196426], [[0.5, 2, 0.3, 0, 0.25, 4], 0, 0.0], [[0.2, 2, 0.1, 2, 0.15, 2], 19, 0.06321205588285577], [[0.2, 0, 0.1, 5, 0.2, 2, 0.15, 1], 15, 0.31]]", "id": "3389819"}]}