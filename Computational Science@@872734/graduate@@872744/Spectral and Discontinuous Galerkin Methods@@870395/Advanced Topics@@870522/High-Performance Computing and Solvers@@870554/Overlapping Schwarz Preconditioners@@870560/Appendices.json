{"hands_on_practices": [{"introduction": "This exercise ([@problem_id:3407367]) will guide you through the explicit construction of an overlapping additive Schwarz preconditioner from first principles. By working with a small-scale, one-dimensional discontinuous Galerkin (DG) system, you will demystify the abstract components of the method, assembling the global stiffness matrix, the local subdomain matrices, and the final preconditioned operator by hand. This foundational practice is crucial for building a concrete understanding of how the different parts of the machinery fit together.", "problem": "Consider the one-dimensional diffusion operator with homogeneous Dirichlet boundary conditions on the interval $[0,3]$, discretized by a symmetric interior penalty discontinuous Galerkin (SIPG) method with piecewise constants (polynomial degree $p=0$) on a uniform mesh of three elements of unit length $h=1$. Let the piecewise constant diffusion coefficient be $\\kappa(x)=\\kappa_{i}$ on element $i$, with $\\kappa_{1}=1$, $\\kappa_{2}=2$, and $\\kappa_{3}=1$. Use the symmetric interior penalty formulation, where the only nonzero contributions for $p=0$ arise from face penalty terms. Define the penalty coefficient on an interior face between elements $i$ and $i+1$ as\n$$\n\\sigma_{i+\\frac{1}{2}}=\\frac{2\\,\\kappa_{i}\\,\\kappa_{i+1}}{\\kappa_{i}+\\kappa_{i+1}},\n$$\nand on a boundary face adjacent to element $i$ as\n$$\n\\sigma_{\\text{bdy}}=\\kappa_{i}.\n$$\nAssemble the global stiffness matrix $A \\in \\mathbb{R}^{3 \\times 3}$ using the SIPG bilinear form and the basis of indicator functions, one per element.\n\nNow define two overlapping subdomains with unit-weight additive Schwarz:\n- Subdomain $\\Omega_{1}$ contains elements $\\{1,2\\}$ (degrees of freedom $1$ and $2$).\n- Subdomain $\\Omega_{2}$ contains elements $\\{2,3\\}$ (degrees of freedom $2$ and $3$).\n\nLet the restriction operators be the canonical injections\n$$\nR_{1}=\\begin{pmatrix}1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{pmatrix}, \\qquad R_{2}=\\begin{pmatrix}0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}.\n$$\nDefine the local subdomain operators by principal submatrices, $A_{1}=R_{1} A R_{1}^{\\top}$ and $A_{2}=R_{2} A R_{2}^{\\top}$, corresponding to homogeneous Dirichlet conditions on artificial subdomain boundaries. Construct the unit-weight overlapping additive Schwarz preconditioner\n$$\nM^{-1}=R_{1}^{\\top} A_{1}^{-1} R_{1}+R_{2}^{\\top} A_{2}^{-1} R_{2}.\n$$\nCompute the preconditioned matrix $M^{-1} A$ explicitly. Finally, determine the spectral condition number, defined here as the ratio of the largest to the smallest eigenvalue of $M^{-1} A$. Provide your final answer as a single exact number (no units).", "solution": "The problem asks for the spectral condition number of an overlapping additive Schwarz preconditioned system. The system matrix $A$ arises from a symmetric interior penalty discontinuous Galerkin (SIPG) discretization of a one-dimensional diffusion problem. The solution process will be conducted in the following steps:\n1.  Construction of the global stiffness matrix $A$.\n2.  Definition of the subdomain matrices $A_1$ and $A_2$ and their inverses.\n3.  Construction of the additive Schwarz preconditioner $M^{-1}$.\n4.  Computation of the preconditioned matrix $M^{-1} A$.\n5.  Determination of the eigenvalues of $M^{-1} A$.\n6.  Calculation of the spectral condition number.\n\n**Step 1: Construction of the Global Stiffness Matrix $A$**\n\nThe problem is defined on the domain $[0,3]$, discretized into three elements of unit length $h=1$: $K_1 = [0,1]$, $K_2 = [1,2]$, and $K_3 = [2,3]$. The polynomial degree is $p=0$, so the basis functions are piecewise constant indicator functions $\\phi_i(x) = 1$ for $x \\in K_i$ and $0$ otherwise, for $i \\in \\{1, 2, 3\\}$.\n\nFor $p=0$, the gradient of any basis function is zero within each element. As stated in the problem, the SIPG bilinear form $a(u,v)$ simplifies, and the matrix entries $A_{ij} = a(\\phi_j, \\phi_i)$ are determined solely by the sum of contributions from the penalty terms on the element faces. The contribution from a single face $F$ is given by $\\sigma_F [\\phi_j]_F [\\phi_i]_F$, where $[\\cdot]_F$ is the jump operator at face $F$ and $\\sigma_F$ is the penalty parameter.\n\nThe faces are located at $x=0$, $x=1$, $x=2$, and $x=3$.\n-   Face at $x=0$ (boundary): Adjacent to $K_1$. Penalty $\\sigma_0 = \\kappa_1 = 1$. The jump is defined as the interior value minus the exterior (boundary) value, which is $0$. Thus, $[\\phi_1]_0 = 1-0 = 1$.\n-   Face at $x=1$ (interior): Between $K_1$ and $K_2$. Penalty $\\sigma_1 = \\frac{2\\kappa_1\\kappa_2}{\\kappa_1+\\kappa_2} = \\frac{2(1)(2)}{1+2} = \\frac{4}{3}$. The jumps are $[\\phi_1]_1 = 1-0 = 1$ and $[\\phi_2]_1 = 0-1 = -1$.\n-   Face at $x=2$ (interior): Between $K_2$ and $K_3$. Penalty $\\sigma_2 = \\frac{2\\kappa_2\\kappa_3}{\\kappa_2+\\kappa_3} = \\frac{2(2)(1)}{2+1} = \\frac{4}{3}$. The jumps are $[\\phi_2]_2 = 1-0 = 1$ and $[\\phi_3]_2 = 0-1 = -1$.\n-   Face at $x=3$ (boundary): Adjacent to $K_3$. Penalty $\\sigma_3 = \\kappa_3 = 1$. The jump is $[\\phi_3]_3 = 1-0 = 1$.\n\nThe matrix entries $A_{ij} = \\sum_{F} \\sigma_F [\\phi_j]_F [\\phi_i]_F$ are calculated as:\n-   Diagonal entries:\n    $A_{11} = \\sigma_0 [\\phi_1]_0^2 + \\sigma_1 [\\phi_1]_1^2 = (1)(1)^2 + (\\frac{4}{3})(1)^2 = 1 + \\frac{4}{3} = \\frac{7}{3}$.\n    $A_{22} = \\sigma_1 [\\phi_2]_1^2 + \\sigma_2 [\\phi_2]_2^2 = (\\frac{4}{3})(-1)^2 + (\\frac{4}{3})(1)^2 = \\frac{4}{3} + \\frac{4}{3} = \\frac{8}{3}$.\n    $A_{33} = \\sigma_2 [\\phi_3]_2^2 + \\sigma_3 [\\phi_3]_3^2 = (\\frac{4}{3})(-1)^2 + (1)(1)^2 = \\frac{4}{3} + 1 = \\frac{7}{3}$.\n\n-   Off-diagonal entries:\n    $A_{12} = A_{21} = \\sigma_1 [\\phi_1]_1 [\\phi_2]_1 = (\\frac{4}{3})(1)(-1) = -\\frac{4}{3}$.\n    $A_{23} = A_{32} = \\sigma_2 [\\phi_2]_2 [\\phi_3]_2 = (\\frac{4}{3})(1)(-1) = -\\frac{4}{3}$.\n    $A_{13} = A_{31} = 0$, as $\\phi_1$ and $\\phi_3$ do not share a common face.\n\nThe global stiffness matrix is:\n$$\nA = \\begin{pmatrix}\n\\frac{7}{3} & -\\frac{4}{3} & 0 \\\\\n-\\frac{4}{3} & \\frac{8}{3} & -\\frac{4}{3} \\\\\n0 & -\\frac{4}{3} & \\frac{7}{3}\n\\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix}\n7 & -4 & 0 \\\\\n-4 & 8 & -4 \\\\\n0 & -4 & 7\n\\end{pmatrix}\n$$\n\n**Step 2: Subdomain Matrices and Their Inverses**\n\nThe subdomain operators are $A_k = R_k A R_k^\\top$.\nFor subdomain $\\Omega_1$ (elements $\\{1,2\\}$):\n$$\nA_1 = R_1 A R_1^\\top = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{pmatrix} A \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{7}{3} & -\\frac{4}{3} \\\\ -\\frac{4}{3} & \\frac{8}{3} \\end{pmatrix}\n$$\nThe determinant is $\\det(A_1) = (\\frac{7}{3})(\\frac{8}{3}) - (-\\frac{4}{3})(-\\frac{4}{3}) = \\frac{56}{9} - \\frac{16}{9} = \\frac{40}{9}$.\nThe inverse is $A_1^{-1} = \\frac{1}{\\det(A_1)} \\begin{pmatrix} \\frac{8}{3} & \\frac{4}{3} \\\\ \\frac{4}{3} & \\frac{7}{3} \\end{pmatrix} = \\frac{9}{40} \\begin{pmatrix} \\frac{8}{3} & \\frac{4}{3} \\\\ \\frac{4}{3} & \\frac{7}{3} \\end{pmatrix} = \\frac{3}{40} \\begin{pmatrix} 8 & 4 \\\\ 4 & 7 \\end{pmatrix}$.\n\nFor subdomain $\\Omega_2$ (elements $\\{2,3\\}$):\n$$\nA_2 = R_2 A R_2^\\top = \\begin{pmatrix} 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} A \\begin{pmatrix} 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}^\\top = \\begin{pmatrix} \\frac{8}{3} & -\\frac{4}{3} \\\\ -\\frac{4}{3} & \\frac{7}{3} \\end{pmatrix}\n$$\nThe determinant is $\\det(A_2) = (\\frac{8}{3})(\\frac{7}{3}) - (-\\frac{4}{3})(-\\frac{4}{3}) = \\frac{40}{9}$.\nThe inverse is $A_2^{-1} = \\frac{9}{40} \\begin{pmatrix} \\frac{7}{3} & \\frac{4}{3} \\\\ \\frac{4}{3} & \\frac{8}{3} \\end{pmatrix} = \\frac{3}{40} \\begin{pmatrix} 7 & 4 \\\\ 4 & 8 \\end{pmatrix}$.\n\n**Step 3: Construction of the Additive Schwarz Preconditioner $M^{-1}$**\n\nThe preconditioner is $M^{-1} = R_1^\\top A_1^{-1} R_1 + R_2^\\top A_2^{-1} R_2$. We embed the local inverse matrices into the global $3 \\times 3$ space.\n$$\nR_1^\\top A_1^{-1} R_1 = \\frac{3}{40} \\begin{pmatrix} 8 & 4 & 0 \\\\ 4 & 7 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}\n$$\n$$\nR_2^\\top A_2^{-1} R_2 = \\frac{3}{40} \\begin{pmatrix} 0 & 0 & 0 \\\\ 0 & 7 & 4 \\\\ 0 & 4 & 8 \\end{pmatrix}\n$$\nAdding these two matrices gives the preconditioner inverse:\n$$\nM^{-1} = \\frac{3}{40} \\left( \\begin{pmatrix} 8 & 4 & 0 \\\\ 4 & 7 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} + \\begin{pmatrix} 0 & 0 & 0 \\\\ 0 & 7 & 4 \\\\ 0 & 4 & 8 \\end{pmatrix} \\right) = \\frac{3}{40} \\begin{pmatrix} 8 & 4 & 0 \\\\ 4 & 14 & 4 \\\\ 0 & 4 & 8 \\end{pmatrix} = \\frac{3}{20} \\begin{pmatrix} 4 & 2 & 0 \\\\ 2 & 7 & 2 \\\\ 0 & 2 & 4 \\end{pmatrix}\n$$\n\n**Step 4: Computation of the Preconditioned Matrix $M^{-1}A$**\n$$\nM^{-1}A = \\left( \\frac{3}{20} \\begin{pmatrix} 4 & 2 & 0 \\\\ 2 & 7 & 2 \\\\ 0 & 2 & 4 \\end{pmatrix} \\right) \\left( \\frac{1}{3} \\begin{pmatrix} 7 & -4 & 0 \\\\ -4 & 8 & -4 \\\\ 0 & -4 & 7 \\end{pmatrix} \\right)\n$$\n$$\nM^{-1}A = \\frac{1}{20} \\begin{pmatrix} 4 & 2 & 0 \\\\ 2 & 7 & 2 \\\\ 0 & 2 & 4 \\end{pmatrix} \\begin{pmatrix} 7 & -4 & 0 \\\\ -4 & 8 & -4 \\\\ 0 & -4 & 7 \\end{pmatrix}\n$$\nPerforming the matrix multiplication:\n$$\n\\begin{pmatrix} 4(7)+2(-4) & 4(-4)+2(8) & 4(0)+2(-4) \\\\ 2(7)+7(-4) & 2(-4)+7(8)+2(-4) & 2(0)+7(-4)+2(7) \\\\ 0(7)+2(-4) & 0(-4)+2(8)+4(-4) & 0(0)+2(-4)+4(7) \\end{pmatrix}\n= \\begin{pmatrix} 20 & 0 & -8 \\\\ -14 & 40 & -14 \\\\ -8 & 0 & 20 \\end{pmatrix}\n$$\nSo, the preconditioned matrix is:\n$$\nM^{-1}A = \\frac{1}{20} \\begin{pmatrix} 20 & 0 & -8 \\\\ -14 & 40 & -14 \\\\ -8 & 0 & 20 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 & -\\frac{2}{5} \\\\ -\\frac{7}{10} & 2 & -\\frac{7}{10} \\\\ -\\frac{2}{5} & 0 & 1 \\end{pmatrix}\n$$\n\n**Step 5: Determination of the Eigenvalues**\n\nWe find the eigenvalues $\\lambda$ by solving the characteristic equation $\\det(M^{-1}A - \\lambda I) = 0$.\n$$\n\\det \\begin{pmatrix} 1-\\lambda & 0 & -\\frac{2}{5} \\\\ -\\frac{7}{10} & 2-\\lambda & -\\frac{7}{10} \\\\ -\\frac{2}{5} & 0 & 1-\\lambda \\end{pmatrix} = 0\n$$\nUsing cofactor expansion along the second column:\n$$\n(2-\\lambda) \\det \\begin{pmatrix} 1-\\lambda & -\\frac{2}{5} \\\\ -\\frac{2}{5} & 1-\\lambda \\end{pmatrix} = 0\n$$\n$$\n(2-\\lambda) \\left[ (1-\\lambda)^2 - \\left(-\\frac{2}{5}\\right)^2 \\right] = 0\n$$\n$$\n(2-\\lambda) \\left[ (1-\\lambda)^2 - \\frac{4}{25} \\right] = 0\n$$\nThis equation yields three eigenvalues.\nOne eigenvalue is clearly $\\lambda_1 = 2$.\nThe other two are found from $(1-\\lambda)^2 = \\frac{4}{25}$, which means $1-\\lambda = \\pm\\sqrt{\\frac{4}{25}} = \\pm\\frac{2}{5}$.\n-   $1 - \\lambda = \\frac{2}{5} \\implies \\lambda_2 = 1 - \\frac{2}{5} = \\frac{3}{5}$.\n-   $1 - \\lambda = -\\frac{2}{5} \\implies \\lambda_3 = 1 + \\frac{2}{5} = \\frac{7}{5}$.\nThe eigenvalues of $M^{-1}A$ are $\\{ \\frac{3}{5}, \\frac{7}{5}, 2 \\}$.\n\n**Step 6: Calculation of the Spectral Condition Number**\n\nThe spectral condition number is the ratio of the largest eigenvalue to the smallest eigenvalue.\n$$\n\\lambda_{\\max} = 2\n$$\n$$\n\\lambda_{\\min} = \\frac{3}{5}\n$$\nThe condition number $\\kappa(M^{-1}A)$ is:\n$$\n\\kappa(M^{-1}A) = \\frac{\\lambda_{\\max}}{\\lambda_{\\min}} = \\frac{2}{\\frac{3}{5}} = 2 \\times \\frac{5}{3} = \\frac{10}{3}\n$$\nThis is the final exact value.", "answer": "$$\\boxed{\\frac{10}{3}}$$", "id": "3407367"}, {"introduction": "Moving from theory to practice, this coding exercise ([@problem_id:3407447]) tackles a classic challenge: solving a 2D Poisson equation on an anisotropic mesh, where the grid spacing is much finer in one direction. You will implement a one-level Schwarz preconditioner and run numerical tests to investigate how performance, measured by iteration count, is affected by the amount of overlap. This hands-on experiment provides direct insight into a key principle of domain decomposition: for anisotropic problems, convergence critically depends on providing sufficient overlap in the direction of strongest coupling.", "problem": "Consider the homogeneous Dirichlet boundary value problem for the elliptic operator on the unit square,\n$$\n-\\nabla \\cdot \\left(\\nabla u\\right) = f \\quad \\text{in } \\Omega = (0,1)\\times(0,1),\\qquad u=0 \\quad \\text{on } \\partial\\Omega,\n$$\nand its discretization on a uniform Cartesian grid of interior points with $N_x$ points in the $x$-direction and $N_y$ points in the $y$-direction, resulting in a Symmetric Positive Definite (SPD) linear system\n$$\nA \\, \\mathbf{u} = \\mathbf{b}.\n$$\nAssume a second-order, tensor-product, spectrally-consistent element discretization of polynomial order $p=1$ on rectangles, which for a uniform grid coincides with the standard five-point finite-difference stencil. Let the grid spacings be $h_x = 1/(N_x+1)$ and $h_y = 1/(N_y+1)$, and the operator be assembled as\n$$\nA = I_{N_y} \\otimes T_x + T_y \\otimes I_{N_x},\n$$\nwhere $I_{n}$ is the identity matrix of size $n$, $\\otimes$ denotes the Kronecker product, and $T_x \\in \\mathbb{R}^{N_x \\times N_x}$, $T_y \\in \\mathbb{R}^{N_y \\times N_y}$ are the one-dimensional second-difference matrices with homogeneous Dirichlet boundary conditions,\n$$\nT_x = \\frac{1}{h_x^2}\\,\\text{tridiag}\\left(-1, 2, -1\\right),\\qquad\nT_y = \\frac{1}{h_y^2}\\,\\text{tridiag}\\left(-1, 2, -1\\right).\n$$\nLet $\\mathbf{b}$ be the vector obtained by sampling a constant source term $f \\equiv 1$ at interior grid points, which is a standard, well-posed forcing for this model problem.\n\nWe aim to demonstrate the benefit of increased overlap along the thin direction (the direction with smaller element size, here taken to be the $x$-direction when $N_x \\gg N_y$) in an overlapping Schwarz preconditioner applied within the Preconditioned Conjugate Gradient (PCG) method. Consider the one-level additive Schwarz preconditioner\n$$\nM^{-1} = \\sum_{i=1}^S R_i^\\top A_i^{-1} R_i,\n$$\nwhere each $R_i \\in \\mathbb{R}^{n_i \\times N}$ restricts global vectors to the $i$-th overlapping subdomain of indices, $A_i \\in \\mathbb{R}^{n_i \\times n_i}$ is the principal submatrix of $A$ corresponding to those indices (interpreted as the local Dirichlet subproblem on the subdomain boundary), and $N = N_x N_y$ is the global number of unknowns. Subdomains are constructed as contiguous rectangular strips that tile the domain in a chosen orientation and are extended by an integer number of layers of overlap. Two orientations are relevant:\n- Vertical strips oriented along the $y$-direction (partitioning in $x$), used to increase overlap along the thin $x$-direction.\n- Horizontal strips oriented along the $x$-direction (partitioning in $y$), used to increase overlap along the thick $y$-direction.\n\nFor PCG, use the standard algorithm for SPD operators, halting when the relative residual norm satisfies\n$$\n\\frac{\\left\\| \\mathbf{r}_k \\right\\|_2}{\\left\\| \\mathbf{b} \\right\\|_2} \\leq 10^{-8}\n$$\nor a maximum iteration cap is reached.\n\nYour task is to implement:\n- Assembly of $A$ for given $N_x$ and $N_y$.\n- Construction of overlapping strip subdomains as described, for both vertical and horizontal orientations, parameterized by a strip width (in grid points) and an overlap (in grid points).\n- The one-level additive Schwarz preconditioner $M^{-1}$ built from local Dirichlet subproblems on each overlapping subdomain.\n- The Preconditioned Conjugate Gradient (PCG) method with the above $M^{-1}$, measuring the iteration count required to achieve the specified tolerance.\n\nUse the following test suite of parameter values, designed to target anisotropic rectangles with $h_x \\ll h_y$ (thin in $x$) and to compare increased overlap along thin versus thick directions. For each case, report the integer iteration count taken by PCG to reach the tolerance.\n\nTest cases:\n1. $N_x=60$, $N_y=12$, vertical strips, strip width $w_x=10$, overlap $o_x=0$.\n2. $N_x=60$, $N_y=12$, vertical strips, strip width $w_x=10$, overlap $o_x=2$.\n3. $N_x=60$, $N_y=12$, vertical strips, strip width $w_x=10$, overlap $o_x=4$.\n4. $N_x=60$, $N_y=12$, horizontal strips, strip width $w_y=3$, overlap $o_y=0$.\n5. $N_x=60$, $N_y=12$, horizontal strips, strip width $w_y=3$, overlap $o_y=4$.\n6. Boundary-strength anisotropy case: $N_x=96$, $N_y=8$, vertical strips, strip width $w_x=12$, overlap $o_x=0$.\n7. Boundary-strength anisotropy case: $N_x=96$, $N_y=8$, vertical strips, strip width $w_x=12$, overlap $o_x=4$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $\\left[\\text{result1},\\text{result2},\\dots\\right]$). The outputs must be integers corresponding to the iteration counts for the seven test cases listed above, in the same order as presented.", "solution": "The problem presented is a well-posed and standard exercise in the field of numerical analysis, specifically concerning the use of domain decomposition methods for solving large sparse linear systems arising from the discretization of elliptic partial differential equations. The problem is scientifically grounded, formally specified, and requires the implementation of established numerical algorithms. All parameters and conditions are provided, and there are no internal contradictions or ambiguities. Therefore, the problem is valid and a solution will be provided.\n\nThe core of the problem is to solve the linear system $A \\mathbf{u} = \\mathbf{b}$ using the Preconditioned Conjugate Gradient (PCG) method. We will detail the construction of the matrix $A$, the design of the one-level additive Schwarz preconditioner $M^{-1}$, and the steps of the PCG algorithm.\n\n### 1. Discretization and System Matrix Assembly\n\nThe problem addresses the Poisson equation with homogeneous Dirichlet boundary conditions on the unit square $\\Omega = (0,1) \\times (0,1)$:\n$$\n-\\Delta u = f \\quad \\text{in } \\Omega, \\qquad u = 0 \\quad \\text{on } \\partial\\Omega.\n$$\nThis equation is discretized on a uniform Cartesian grid with $N_x$ interior points in the $x$-direction and $N_y$ in the $y$-direction. The grid spacings are $h_x = 1/(N_x+1)$ and $h_y = 1/(N_y+1)$. The total number of unknowns is $N = N_x N_y$. We adopt a row-major ordering for the grid points $(i, j)$, where $i \\in \\{0, \\dots, N_x-1\\}$ and $j \\in \\{0, \\dots, N_y-1\\}$. The corresponding global index $k$ for a vector $\\mathbf{u} \\in \\mathbb{R}^N$ is given by $k = j \\cdot N_x + i$.\n\nThe discretization, described as a second-order finite difference or spectrally-consistent $p=1$ finite element method, leads to the well-known five-point stencil. The resulting system matrix $A$ has a block-tridiagonal structure that can be elegantly expressed using the Kronecker product $\\otimes$:\n$$\nA = I_{N_y} \\otimes T_x + T_y \\otimes I_{N_x}.\n$$\nHere, $I_n$ is the identity matrix of size $n$, and $T_x \\in \\mathbb{R}^{N_x \\times N_x}$ and $T_y \\in \\mathbb{R}^{N_y \\times N_y}$ are the one-dimensional second-difference matrices:\n$$\nT_x = \\frac{1}{h_x^2} \\begin{pmatrix}\n2 & -1 & & \\\\\n-1 & 2 & -1 & \\\\\n& \\ddots & \\ddots & \\ddots \\\\\n& & -1 & 2 & -1 \\\\\n& & & -1 & 2\n\\end{pmatrix},\n\\qquad\nT_y = \\frac{1}{h_y^2} \\begin{pmatrix}\n2 & -1 & & \\\\\n-1 & 2 & -1 & \\\\\n& \\ddots & \\ddots & \\ddots \\\\\n& & -1 & 2 & -1 \\\\\n& & & -1 & 2\n\\end{pmatrix}.\n$$\nThe first term, $I_{N_y} \\otimes T_x$, represents the coupling of grid points within the same row (constant $j$), corresponding to the second partial derivative with respect to $x$. The second term, $T_y \\otimes I_{N_x}$, represents the coupling between adjacent rows, corresponding to the second partial derivative with respect to $y$. The resulting matrix $A$ is symmetric and positive definite (SPD). The right-hand side vector $\\mathbf{b}$ is formed by sampling the constant function $f \\equiv 1$ at each of the $N$ interior grid points.\n\n### 2. One-Level Additive Schwarz Preconditioner\n\nThe additive Schwarz method is a domain decomposition technique that acts as a preconditioner for iterative solvers like PCG. The core idea is to decompose the global problem domain $\\Omega$ into a set of $S$ smaller, overlapping subdomains $\\{\\Omega_i\\}_{i=1}^S$. The global solution is approximated by solving smaller problems on these subdomains and adding the results.\n\nThe one-level additive Schwarz preconditioner $M^{-1}$ is defined as:\n$$\nM^{-1} = \\sum_{i=1}^S R_i^\\top A_i^{-1} R_i.\n$$\nThe components are:\n- $\\Omega_i$: The $i$-th subdomain, represented by a set of global indices of the grid points it contains.\n- $R_i \\in \\mathbb{R}^{n_i \\times N}$: A restriction operator that selects the components of a global vector corresponding to the $n_i$ unknowns in subdomain $\\Omega_i$. In matrix form, it is a matrix of zeros and ones.\n- $R_i^\\top \\in \\mathbb{R}^{N \\times n_i}$: The transpose of $R_i$, which acts as an extension-by-zero operator, embedding a local vector from $\\Omega_i$ into a global vector.\n- $A_i = R_i A R_i^\\top \\in \\mathbb{R}^{n_i \\times n_i}$: The principal submatrix of $A$ corresponding to the indices in $\\Omega_i$. This matrix represents the original PDE discretized on the subdomain $\\Omega_i$ with homogeneous Dirichlet boundary conditions on the artificial boundaries of $\\Omega_i$.\n- $A_i^{-1}$: The inverse of the local subproblem matrix. The action of $A_i^{-1}$ on a local vector is computed via a direct solve (e.g., LU factorization), which is efficient since the subdomains are small.\n\nThe application of the preconditioner to a residual vector $\\mathbf{r}$, $\\mathbf{z} = M^{-1}\\mathbf{r}$, is performed algorithmically:\n1. Initialize the output vector $\\mathbf{z} = \\mathbf{0} \\in \\mathbb{R}^N$.\n2. For each subdomain $\\Omega_i$ from $i=1$ to $S$:\n   a. Restrict the residual to the subdomain: $\\mathbf{r}_i = R_i \\mathbf{r}$.\n   b. Solve the local problem for the local correction: $\\mathbf{w}_i = A_i^{-1} \\mathbf{r}_i$.\n   c. Extend the local correction and add it to the global vector: $\\mathbf{z} \\leftarrow \\mathbf{z} + R_i^\\top \\mathbf{w}_i$.\n\nThe subdomains are constructed as contiguous rectangular strips that partition the domain along one axis and are then extended to create overlap.\n- **Vertical Strips**: The $N_x$ columns of grid points are partitioned into $S = N_x/w_x$ non-overlapping base strips of width $w_x$ grid points. Each base strip $s \\in \\{0, \\dots, S-1\\}$ is then extended by $o_x$ grid points on its left and right sides (where possible) to form the overlapping subdomain a $\\Omega_s$.\n- **Horizontal Strips**: A similar procedure partitions the $N_y$ rows of grid points into $S = N_y/w_y$ strips of width $w_y$ and extends them by $o_y$ grid points above and below.\n\nThe effectiveness of Schwarz preconditioners, particularly in anisotropic problems where $h_x \\ll h_y$ or vice-versa, is highly dependent on the amount of overlap. Theory suggests that providing generous overlap in the \"thin\" direction (the direction of smaller mesh spacing) is crucial for robust performance.\n\n### 3. Preconditioned Conjugate Gradient (PCG) Algorithm\n\nThe PCG method is an iterative algorithm for solving SPD linear systems $A\\mathbf{x}=\\mathbf{b}$ with an SPD preconditioner $M$. The algorithm for determining the solution $\\mathbf{x}$ is as follows:\n\n1. Initialize:\n   - Solution guess: $\\mathbf{x}_0 = \\mathbf{0}$\n   - Residual: $\\mathbf{r}_0 = \\mathbf{b} - A\\mathbf{x}_0 = \\mathbf{b}$\n   - Iteration counter: $k = 0$\n2. Precondition:\n   - Solve $M\\mathbf{z}_0 = \\mathbf{r}_0$ to get $\\mathbf{z}_0 = M^{-1}\\mathbf{r}_0$.\n3. Initialize search direction:\n   - $\\mathbf{p}_0 = \\mathbf{z}_0$\n4. Compute initial products:\n   - $\\rho_0 = \\mathbf{r}_0^\\top \\mathbf{z}_0$\n   - $\\|\\mathbf{b}\\|_2 = \\sqrt{\\mathbf{b}^\\top \\mathbf{b}}$\n5. Iterate until convergence: For $k=0, 1, 2, \\dots$ until termination:\n   a. Compute matrix-vector product: $\\mathbf{q}_k = A\\mathbf{p}_k$.\n   b. Compute step size: $\\alpha_k = \\rho_k / (\\mathbf{p}_k^\\top \\mathbf{q}_k)$.\n   c. Update solution: $\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{p}_k$.\n   d. Update residual: $\\mathbf{r}_{k+1} = \\mathbf{r}_k - \\alpha_k \\mathbf{q}_k$.\n   e. Check for convergence: If $\\|\\mathbf{r}_{k+1}\\|_2 / \\|\\mathbf{b}\\|_2 \\leq 10^{-8}$, terminate and return $\\mathbf{x}_{k+1}$ and iteration count $k+1$.\n   f. Apply preconditioner: Solve $M\\mathbf{z}_{k+1} = \\mathbf{r}_{k+1}$ to get $\\mathbf{z}_{k+1} = M^{-1}\\mathbf{r}_{k+1}$.\n   g. Compute new product for $\\beta$: $\\rho_{k+1} = \\mathbf{r}_{k+1}^\\top \\mathbf{z}_{k+1}$.\n   h. Compute search direction update factor: $\\beta_k = \\rho_{k+1} / \\rho_k$.\n   i. Update search direction: $\\mathbf{p}_{k+1} = \\mathbf{z}_{k+1} + \\beta_k \\mathbf{p}_k$.\n   j. Update $\\rho$: $\\rho_k \\leftarrow \\rho_{k+1}$.\n\nThe implementation will execute this algorithm for each of the seven test cases, a process that involves assembling the corresponding matrix $A$, constructing the specified subdomains, setting up the preconditioner solvers, and running the PCG iteration. The final output is the integer number of iterations required for convergence in each case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse import diags, identity, kron\nfrom scipy.sparse.linalg import splu\n\ndef assemble_A(Nx, Ny):\n    \"\"\"Assembles the 2D Poisson matrix A using Kronecker products.\"\"\"\n    hx = 1.0 / (Nx + 1)\n    hy = 1.0 / (Ny + 1)\n\n    # 1D Laplacian matrices\n    diag_vals_x = [-1.0, 2.0, -1.0]\n    diag_pos = [-1, 0, 1]\n    Tx = diags(diag_vals_x, diag_pos, shape=(Nx, Nx), format='csc') / (hx**2)\n\n    diag_vals_y = [-1.0, 2.0, -1.0]\n    Ty = diags(diag_vals_y, diag_pos, shape=(Ny, Ny), format='csc') / (hy**2)\n\n    # Identity matrices\n    Ix = identity(Nx, format='csc')\n    Iy = identity(Ny, format='csc')\n\n    # 2D Laplacian using Kronecker product for row-major ordering\n    A = kron(Iy, Tx) + kron(Ty, Ix)\n    return A.asformat('csc')\n\ndef get_subdomains(Nx, Ny, strip_dir, width, overlap):\n    \"\"\"\n    Constructs the index sets for overlapping strip subdomains.\n    Indices correspond to row-major ordering.\n    \"\"\"\n    subdomains = []\n    if strip_dir == 'vertical':\n        num_strips = Nx // width\n        for s in range(num_strips):\n            x_start_no_overlap = s * width\n            x_end_no_overlap = (s + 1) * width - 1\n\n            x_start_overlap = max(0, x_start_no_overlap - overlap)\n            x_end_overlap = min(Nx - 1, x_end_no_overlap + overlap)\n\n            x_indices = np.arange(x_start_overlap, x_end_overlap + 1)\n            y_indices = np.arange(Ny)\n            \n            # Create a meshgrid and flatten to get global indices\n            I_grid, J_grid = np.meshgrid(x_indices, y_indices)\n            global_indices = (J_grid * Nx + I_grid).flatten()\n            subdomains.append(global_indices)\n    else: # horizontal\n        num_strips = Ny // width\n        for s in range(num_strips):\n            y_start_no_overlap = s * width\n            y_end_no_overlap = (s + 1) * width - 1\n            \n            y_start_overlap = max(0, y_start_no_overlap - overlap)\n            y_end_overlap = min(Ny - 1, y_end_no_overlap + overlap)\n\n            y_indices = np.arange(y_start_overlap, y_end_overlap + 1)\n            x_indices = np.arange(Nx)\n\n            I_grid, J_grid = np.meshgrid(x_indices, y_indices)\n            global_indices = (J_grid * Nx + I_grid).flatten()\n            subdomains.append(global_indices)\n            \n    return subdomains\n\ndef pcg(A, b, apply_preconditioner, tol=1e-8, maxiter=2000):\n    \"\"\"\n    Preconditioned Conjugate Gradient algorithm for solving Ax=b.\n    \"\"\"\n    N = A.shape[0]\n    x = np.zeros(N)\n    r = b - A @ x\n    \n    norm_b = np.linalg.norm(b)\n    if norm_b == 0:\n        return x, 0\n    \n    if np.linalg.norm(r) / norm_b < tol:\n        return x, 0\n        \n    z = apply_preconditioner(r)\n    p = z.copy()\n    rho_old = np.dot(r, z)\n\n    for k in range(maxiter):\n        Ap = A @ p\n        alpha = rho_old / np.dot(p, Ap)\n        x += alpha * p\n        r -= alpha * Ap\n\n        if np.linalg.norm(r) / norm_b < tol:\n            return x, k + 1\n\n        z = apply_preconditioner(r)\n        rho_new = np.dot(r, z)\n        beta = rho_new / rho_old\n        p = z + beta * p\n        rho_old = rho_new\n        \n    return x, maxiter\n\ndef solve():\n    test_cases = [\n        # Nx, Ny, strip_dir, width, overlap\n        (60, 12, 'vertical', 10, 0),\n        (60, 12, 'vertical', 10, 2),\n        (60, 12, 'vertical', 10, 4),\n        (60, 12, 'horizontal', 3, 0),\n        (60, 12, 'horizontal', 3, 4),\n        (96, 8, 'vertical', 12, 0),\n        (96, 8, 'vertical', 12, 4),\n    ]\n\n    results = []\n    \n    for Nx, Ny, strip_dir, width, overlap in test_cases:\n        # 1. Assemble the global system matrix A and RHS vector b\n        A = assemble_A(Nx, Ny)\n        b = np.ones(Nx * Ny)\n\n        # 2. Define subdomains\n        subdomains = get_subdomains(Nx, Ny, strip_dir, width, overlap)\n\n        # 3. Set up the preconditioner components\n        preconditioner_solvers = []\n        for sub_indices in subdomains:\n            # Extract submatrix Ai = R_i A R_i^T\n            # SciPy handles this indexing efficiently\n            A_i = A[sub_indices, :][:, sub_indices]\n            # Pre-factorize for efficient application of A_i^{-1}\n            preconditioner_solvers.append(splu(A_i))\n\n        # 4. Define the preconditioner application function M_inv * r\n        def apply_M_inv(r):\n            z = np.zeros_like(r)\n            for i, sub_indices in enumerate(subdomains):\n                # Restrict to subdomain: r_i = R_i * r\n                r_i = r[sub_indices]\n                # Solve local problem: w_i = A_i^{-1} * r_i\n                w_i = preconditioner_solvers[i].solve(r_i)\n                # Extend and add: z += R_i^T * w_i\n                # In numpy, this is adding the local solution to the correct global indices\n                z[sub_indices] += w_i\n            return z\n\n        # 5. Run PCG and get iteration count\n        _, iterations = pcg(A, b, apply_M_inv)\n        results.append(iterations)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3407447"}, {"introduction": "This final practice ([@problem_id:3407345]) challenges you to engage with an advanced topic: the robustness of domain decomposition methods for problems with large jumps in material coefficients. Using the abstract Schwarz framework, you will analyze why a standard, \"unweighted\" preconditioner fails for a discontinuous Galerkin discretization of a high-contrast diffusion problem. This theoretical investigation illuminates the interplay between the PDE's physics and the algorithm's design, highlighting the need for \"coefficient-aware\" components to achieve a truly robust solver.", "problem": "Consider the scalar diffusion problem $-\\nabla \\cdot (K \\nabla u) = f$ on a bounded polygonal domain $\\Omega \\subset \\mathbb{R}^d$ with homogeneous Dirichlet boundary conditions, where $K(x)$ is a piecewise constant scalar field with jumps across interior faces of a mesh $\\mathcal{T}_h$. The symmetric interior penalty discontinuous Galerkin (SIPDG) method discretizes the bilinear form on the discontinuous finite element space $V_h$ of piecewise polynomials of degree $p \\geq 1$ as\n$$\na_h(u,v) \\coloneqq \\sum_{T \\in \\mathcal{T}_h} \\int_T K \\nabla u \\cdot \\nabla v \\, dx - \\sum_{F \\in \\mathcal{F}_h^{\\text{int}}} \\int_F \\left( \\{\\!\\{ K \\nabla u \\cdot n \\}\\!\\} [v] + \\{\\!\\{ K \\nabla v \\cdot n \\}\\!\\} [u] \\right) \\, ds + \\sum_{F \\in \\mathcal{F}_h} \\int_F \\sigma_F [u][v] \\, ds,\n$$\nwhere $\\mathcal{F}_h^{\\text{int}}$ denotes interior faces, $[\\cdot]$ denotes the jump, $\\{\\!\\{\\cdot\\}\\!\\}$ denotes a chosen average, $n$ is a unit normal to the face, and $\\sigma_F > 0$ is a sufficiently large penalty depending on the local mesh size and polynomial degree. Assume the face average is the simple arithmetic average and the penalty does not depend on $K$. Let $A \\in \\mathbb{R}^{N \\times N}$ be the symmetric positive definite linear system arising from $a_h(\\cdot,\\cdot)$.\n\nLet $\\{\\Omega_i\\}_{i=1}^N$ be an overlapping subdomain cover of $\\Omega$ obtained by aggregating elements into patches of diameter $H$ with overlap $\\delta > 0$ independent of the coefficient contrast, and let $R_i : \\mathbb{R}^N \\to \\mathbb{R}^{n_i}$ be restriction operators to local degrees of freedom; the local operators are $A_i \\coloneqq R_i A R_i^\\top$. Consider the one-level additive Schwarz preconditioner\n$$\nM^{-1}_{\\text{loc}} \\coloneqq \\sum_{i=1}^N R_i^\\top A_i^{-1} R_i,\n$$\nand its two-level variant\n$$\nM^{-1} \\coloneqq R_0^\\top A_0^{-1} R_0 + \\sum_{i=1}^N R_i^\\top A_i^{-1} R_i,\n$$\nwith coarse operator $A_0 \\coloneqq R_0 A R_0^\\top$ built from aggregates of diameter $\\mathcal{O}(H)$ using an unweighted partition-of-unity extension of coarse basis functions. Assume $R_0$ is constructed without any dependence on $K$ and that face constraints use equal weights across all faces irrespective of coefficient jumps.\n\nSuppose that across a particular interior face $F \\in \\mathcal{F}_h^{\\text{int}}$ shared by elements $T_+$ and $T_-$, the diffusion coefficients satisfy $K_{+} \\gg K_{-}$ with contrast $\\eta \\coloneqq K_{+}/K_{-} \\to \\infty$. Assume further that high-conductivity regions percolate across many subdomains so that subdomain interfaces frequently intersect faces with $K_{+} \\gg K_{-}$, and that $\\delta$ and $H$ are independent of $\\eta$.\n\nUsing the definitions of the SIPDG energy norm induced by $a_h(\\cdot,\\cdot)$, the additive Schwarz framework based on a stable decomposition and strengthened Cauchy–Schwarz inequalities, and standard Poincaré and trace inequalities, analyze how the condition number $\\kappa(M^{-1}A)$ depends on $\\eta$ for the above unweighted construction. Identify which of the following statements are correct and justify your choices by deriving the dependence of the stable decomposition constant on $\\eta$ and explaining the mechanisms at DG faces.\n\nA. In the absence of a coefficient-aware coarse space and coefficient-aware interface scaling, there exist configurations with $K_{+} \\gg K_{-}$ for which the stable decomposition constant grows at least proportionally to $\\eta$, implying that $\\kappa(M^{-1}A)$ becomes unbounded as $\\eta \\to \\infty$.\n\nB. A robust remedy is to build the coarse space by weighted aggregation that incorporates $K$ through a coefficient-weighted partition of unity or energy-minimizing/$K$-harmonic coarse basis functions, which yields a bound on $\\kappa(M^{-1}A)$ independent of $\\eta$ under standard geometric assumptions on $(H,\\delta)$.\n\nC. Simply increasing the overlap $\\delta$ while keeping an unweighted coarse space and equal face averaging is sufficient to eliminate the $\\eta$-dependence, i.e., for fixed $H$ and sufficiently large $\\delta$ independent of $\\eta$, one can obtain a uniform bound on $\\kappa(M^{-1}A)$ with respect to $\\eta$.\n\nD. Using coefficient-aware interface scalings at DG faces (for example, deluxe or $\\rho$-scaling with weights proportional to $K/h$ in the averaging operators) can remove the contrast dependence originating from face terms and, together with a coefficient-aware coarse correction, yields robustness with respect to $\\eta$.\n\nE. Choosing the SIPDG penalty parameter $\\sigma_F$ to be very large but independent of $K$ restores robustness with respect to coefficient contrast, even if the coarse space and face averages remain unweighted.\n\nSelect all that apply. Your reasoning must start from the definitions above and standard inequalities; do not assume any pre-existing robust bounds without justification. Your answer should identify failure mechanisms and articulate the role of coefficient-aware weighted aggregations in the remedy.", "solution": "### Step 1: Extract Givens\nThe problem statement provides the following information:\n-   **Problem**: Scalar diffusion equation $-\\nabla \\cdot (K \\nabla u) = f$ on a bounded polygonal domain $\\Omega \\subset \\mathbb{R}^d$ with homogeneous Dirichlet boundary conditions.\n-   **Coefficient**: $K(x)$ is a piecewise constant scalar field with jumps across interior faces of a mesh $\\mathcal{T}_h$.\n-   **Discretization**: Symmetric interior penalty discontinuous Galerkin (SIPDG) method on a space $V_h$ of piecewise polynomials of degree $p \\geq 1$.\n-   **Bilinear Form**:\n    $$\n    a_h(u,v) \\coloneqq \\sum_{T \\in \\mathcal{T}_h} \\int_T K \\nabla u \\cdot \\nabla v \\, dx - \\sum_{F \\in \\mathcal{F}_h^{\\text{int}}} \\int_F \\left( \\{\\!\\{ K \\nabla u \\cdot n \\}\\!\\} [v] + \\{\\!\\{ K \\nabla v \\cdot n \\}\\!\\} [u] \\right) \\, ds + \\sum_{F \\in \\mathcal{F}_h} \\int_F \\sigma_F [u][v] \\, ds\n    $$\n-   **Definitions**: $[\\cdot]$ is the jump operator, $\\{\\!\\{\\cdot\\}\\!\\}$ is the arithmetic average, $n$ is a unit normal, $\\sigma_F > 0$ is a sufficiently large penalty.\n-   **Assumptions on SIPDG**: The face average is the simple arithmetic average. The penalty $\\sigma_F$ does not depend on $K$. The resulting linear system matrix $A$ is symmetric positive definite (SPD).\n-   **Domain Decomposition**: An overlapping subdomain cover $\\{\\Omega_i\\}_{i=1}^N$ of $\\Omega$ is used, with patch diameter $H$ and overlap $\\delta > 0$. $H$ and $\\delta$ are independent of coefficient contrast.\n-   **Preconditioner (Two-Level Additive Schwarz)**:\n    $$\n    M^{-1} \\coloneqq R_0^\\top A_0^{-1} R_0 + \\sum_{i=1}^N R_i^\\top A_i^{-1} R_i\n    $$\n    where $A_i = R_i A R_i^\\top$ are local operators and $A_0 = R_0 A R_0^\\top$ is the coarse operator.\n-   **Assumptions on Preconditioner Construction**: The coarse space (defined by $R_0$) is constructed using an unweighted partition-of-unity extension of coarse basis functions, without any dependence on $K$. Face constraints use equal weights.\n-   **Coefficient Contrast Scenario**: On some faces, $K_+ \\gg K_-$, with contrast $\\eta \\coloneqq K_+/K_- \\to \\infty$. High-conductivity regions ($K=K_+$) percolate across many subdomains.\n-   **Question**: Analyze the dependence of the condition number $\\kappa(M^{-1}A)$ on $\\eta$ for this unweighted construction.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded**: The problem is firmly located within the well-established fields of numerical analysis for partial differential equations, specifically focusing on discontinuous Galerkin methods and domain decomposition preconditioners. All concepts used (SIPDG, Schwarz preconditioners, coefficient contrast) are standard.\n2.  **Well-Posed**: The problem asks for an analysis of the condition number's dependence on a specific parameter ($\\eta$). The setup provides a clear framework for applying the standard abstract theory of additive Schwarz methods. A meaningful analysis is possible.\n3.  **Objective**: The language is technical, precise, and free of subjectivity. All mathematical objects and assumptions are clearly defined.\n\nThe problem statement does not violate any of the invalidity criteria. It is a well-posed, scientifically grounded problem from numerical analysis.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. We may proceed to the solution.\n\n### Derivation and Analysis\n\nThe analysis of the two-level additive Schwarz preconditioner is based on the abstract Schwarz framework. The condition number $\\kappa(M^{-1}A)$ of the preconditioned operator is bounded as:\n$$\n\\kappa(M^{-1}A) \\le C_0^2 (\\omega + 1) \\rho(E)\n$$\nwhere $\\rho(E)$ relates to the number of subdomains that overlap, $\\omega$ is a constant from a strengthened Cauchy-Schwarz inequality (typically bounded for overlapping methods), and $C_0^2$ is the constant from the stable decomposition property. The key to analyzing robustness with respect to the coefficient contrast $\\eta$ is to determine the dependence of $C_0$ on $\\eta$.\n\nThe stable decomposition property states that for any function $u \\in V_h$, there must exist a decomposition $u = u_0 + \\sum_{i=1}^N u_i$, with $u_i$ supported in the local space corresponding to subdomain $\\Omega_i$ and $u_0$ in the coarse space, such that:\n$$\na_h(u_0, u_0) + \\sum_{i=1}^N a_h(u_i, u_i) \\leq C_0^2 a_h(u, u)\n$$\nThe local functions $u_i$ for $i=1, \\dots, N$ are typically constructed using a partition of unity (PoU) $\\{\\theta_i\\}_{i=1}^N$ subordinate to the cover $\\{\\Omega_i\\}$. Let $u_i = I_h(\\theta_i(u - u_0))$, where $I_h$ is a suitable interpolation operator into $V_h$. For simplicity in analysis, we approximate $u_i \\approx \\theta_i u$ (ignoring the coarse correction and interpolation for a moment, as the primary pathology already appears at the one-level decomposition). The functions $\\theta_i$ are constructed based on the geometry of the overlap, with properties $|\\nabla \\theta_i| \\le C/\\delta$, where $\\delta$ is the overlap width.\n\nLet's analyze the energy of a local component $u_i = I_h(\\theta_i u)$. The energy is given by the bilinear form $a_h(u_i, u_i)$. A key contribution to this energy comes from the element-wise gradient terms:\n$$\n\\sum_{T \\in \\mathcal{T}_h, T \\subset \\Omega_i} \\int_T K |\\nabla u_i|^2 \\, dx\n$$\nAssuming $I_h$ is a stable interpolation operator, $\\nabla u_i \\approx \\nabla(\\theta_i u) = u\\nabla\\theta_i + \\theta_i\\nabla u$. Using the inequality $(a+b)^2 \\le 2a^2 + 2b^2$, the energy of $u_i$ contains a term of the form:\n$$\n\\int_{\\Omega_i} K|u \\nabla \\theta_i|^2 \\, dx \\le \\frac{C}{\\delta^2} \\int_{\\text{supp}(\\nabla \\theta_i)} K u^2 \\, dx\n$$\nThe support of $\\nabla \\theta_i$ lies within the overlap region of $\\Omega_i$ with its neighbors. To bound this term by the global energy $a_h(u,u)$, we would need a $K$-weighted Poincaré-type inequality of the form $\\int_{\\omega} K u^2 dx \\le C_K \\int_{\\omega} K |\\nabla u|^2 dx$.\n\nThis is where the unweighted construction fails. Consider a scenario, permitted by the problem statement, where a high-conductivity path ($K=\\eta \\gg 1$) exists, and a function $u$ is constructed to be nearly constant (e.g., $u \\approx 1$) on this path, with its gradient concentrated in a narrow low-conductivity region ($K=1$) that acts as a \"bridge\".\n-   The global energy $a_h(u,u) \\approx \\int_{\\Omega} K |\\nabla u|^2 dx$ will be small, as the gradient is non-zero only where $K=1$. The energy is $\\mathcal{O}(1)$ with respect to $\\eta$.\n-   Now consider a local function $u_i = \\theta_i u$ for a subdomain $\\Omega_i$ that is crossed by this high-conductivity path. The term $\\int_{\\Omega_i} K u^2 dx$ will be large because $u \\approx 1$ where $K=\\eta$. This integral will be $\\mathcal{O}(\\eta)$.\n-   As a result, the local energy $a_h(u_i, u_i)$, containing the term $\\frac{C}{\\delta^2} \\int_{\\text{supp}(\\nabla \\theta_i)} K u^2 \\, dx$, can be of order $\\mathcal{O}(\\eta)$.\n\nWe have found a function $u$ for which $a_h(u,u) = \\mathcal{O}(1)$ but for which at least one local component $u_i$ has energy $a_h(u_i,u_i) = \\mathcal{O}(\\eta)$. Therefore, the stability constant $C_0^2$ must satisfy $C_0^2 \\ge C \\eta$, meaning it grows with the coefficient contrast. This implies that the condition number $\\kappa(M^{-1}A)$ is not bounded independently of $\\eta$. The same reasoning applies to an unweighted coarse space, which cannot approximate such problematic functions $u$ effectively, leaving a large residual for the local solvers.\n\nFurthermore, the SIPDG formulation itself introduces challenges. The use of a simple arithmetic average for the flux, $\\{\\!\\{K\\nabla u \\cdot n \\}\\!\\}$, combined with a penalty $\\sigma_F$ that is independent of $K$, leads to a bilinear form whose properties (continuity and coercivity constants) can degenerate as $\\eta \\to \\infty$. This is a separate, but related, failure mechanism inherent to the DG discretization itself when not designed for high contrast.\n\n### Option-by-Option Analysis\n\n**A. In the absence of a coefficient-aware coarse space and coefficient-aware interface scaling, there exist configurations with $K_{+} \\gg K_{-}$ for which the stable decomposition constant grows at least proportionally to $\\eta$, implying that $\\kappa(M^{-1}A)$ becomes unbounded as $\\eta \\to \\infty$.**\n\nThis statement is **Correct**. As derived above, the use of a standard, unweighted partition of unity for the decomposition fails to be stable in the energy norm $a_h(\\cdot,\\cdot)$ which is weighted by $K$. There exist \"problematic\" functions with low global energy but whose decomposition into local functions yields components with high energy, proportional to the contrast $\\eta$. This directly causes the stability constant $C_0^2$ to grow with $\\eta$, leading to a lack of robustness for the preconditioner.\n\n**B. A robust remedy is to build the coarse space by weighted aggregation that incorporates $K$ through a coefficient-weighted partition of unity or energy-minimizing/$K$-harmonic coarse basis functions, which yields a bound on $\\kappa(M^{-1}A)$ independent of $\\eta$ under standard geometric assumptions on $(H,\\delta)$.**\n\nThis statement is **Correct**. It accurately describes the state-of-the-art solution to the problem identified in A. By constructing coarse basis functions that are \"aware\" of the coefficient field $K$ (e.g., by ensuring they have low energy, making them nearly constant along high-conductivity paths), the coarse space can effectively approximate the problematic modes responsible for the non-robustness. This leads to a stable two-level method with a condition number bound independent of $\\eta$.\n\n**C. Simply increasing the overlap $\\delta$ while keeping an unweighted coarse space and equal face averaging is sufficient to eliminate the $\\eta$-dependence, i.e., for fixed $H$ and sufficiently large $\\delta$ independent of $\\eta$, one can obtain a uniform bound on $\\kappa(M^{-1}A)$ with respect to $\\eta$.**\n\nThis statement is **Incorrect**. Increasing the overlap $\\delta$ can improve the constant in the condition number bound that depends on the geometry (typically a factor of $(1+H/\\delta)$ for one-level methods), but it does not resolve the issue created by the coefficient heterogeneity. The failure of the weighted Poincaré inequality, which underpins the $\\eta$-dependence, is a physical, not geometric, problem. The factor of $\\eta$ in the stability constant $C_0^2$ will remain, regardless of the size of the overlap $\\delta$.\n\n**D. Using coefficient-aware interface scalings at DG faces (for example, deluxe or $\\rho$-scaling with weights proportional to $K/h$ in the averaging operators) can remove the contrast dependence originating from face terms and, together with a coefficient-aware coarse correction, yields robustness with respect to $\\eta$.**\n\nThis statement is **Correct**. For discontinuous Galerkin methods, robustness requires more than just a robust coarse space. The inter-element coupling terms in the bilinear form $a_h(\\cdot,\\cdot)$ must also be designed to handle coefficient jumps. The simple arithmetic average for fluxes is known to not be robust. Using a weighted average (e.g., harmonic average) for the flux term $\\{\\!\\{ K \\nabla u \\}\\!\\}$ is crucial for ensuring the face terms in the energy norm behave correctly across coefficient jumps. This, combined with the robust coarse-space correction mentioned in B, constitutes a fully robust domain decomposition strategy for high-contrast problems discretized with DG methods.\n\n**E. Choosing the SIPDG penalty parameter $\\sigma_F$ to be very large but independent of $K$ restores robustness with respect to coefficient contrast, even if the coarse space and face averages remain unweighted.**\n\nThis statement is **Incorrect**. A very large penalty parameter $\\sigma_F$ forces the discontinuous solution to become nearly continuous, making the method behave like a conforming finite element method. However, this does not solve the fundamental problem. The failure of the stable decomposition, as analyzed for statement A, stems primarily from the volume integral term $\\int K |u \\nabla \\theta_i|^2 dx$. The magnitude of the penalty term $\\int \\sigma_F [u]^2 ds$ does not affect the existence or the $\\eta$-dependence of this problematic volume term in the energy of the local functions $u_i$. Therefore, increasing $\\sigma_F$ cannot fix the $\\eta$-dependence of the stability constant $C_0$.", "answer": "$$\\boxed{ABD}$$", "id": "3407345"}]}