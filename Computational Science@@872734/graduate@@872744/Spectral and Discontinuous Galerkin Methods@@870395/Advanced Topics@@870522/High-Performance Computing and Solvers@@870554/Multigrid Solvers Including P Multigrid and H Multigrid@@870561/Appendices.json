{"hands_on_practices": [{"introduction": "This practice explores a crucial aspect of constructing multigrid solvers: the impact of numerical quadrature on the accuracy of coarse-grid operators. You will investigate how different quadrature strategies can introduce \"aliasing\" errors into the coarse-grid residual, $r = f - K u_h$, a key quantity for driving the multigrid correction. This exercise highlights the principle that the fidelity of the coarse-grid problem is fundamental to the overall efficiency of the multigrid method [@problem_id:3401628].", "problem": "You are asked to investigate how polynomial-degree coarsening in a one-dimensional spectral element method interacts with quadrature aliasing when constructing coarse-grid residuals for multigrid. Work entirely in one dimension on the interval $[-1,1]$, using a single spectral element with Lagrange basis functions at Gauss–Lobatto–Legendre (GLL) nodes. Consider the diffusion model problem in weak form with homogeneous natural (Neumann) boundary conditions: find a sufficiently smooth function $u$ such that for all test functions $v$,\n$$\n\\int_{-1}^{1} a(x)\\, u'(x)\\, v'(x)\\, dx = \\int_{-1}^{1} f(x)\\, v(x)\\, dx.\n$$\nUse the coefficient and exact solution\n$$\na(x) = 1 + 0.3\\cos(7x), \\quad u(x) = \\bigl(1-x^2\\bigr)^2,\n$$\nso that $u'(x) = -4x\\bigl(1-x^2\\bigr)$ and $u''(x) = -4 + 12x^2$. The source term is defined by substituting into the strong form $- \\bigl(a(x) u'(x)\\bigr)' = f(x)$, namely\n$$\nf(x) = -\\Big(a'(x)\\, u'(x) + a(x)\\, u''(x)\\Big), \\quad a'(x) = -2.1\\sin(7x).\n$$\nFor a chosen polynomial degree $p$ with $N=p+1$ GLL nodes $\\{x_i\\}_{i=0}^{N-1}$ and associated Lagrange basis $\\{\\phi_i(x)\\}_{i=0}^{N-1}$, define the discrete stiffness matrix and load vector via quadrature as\n$$\nK_{ij} \\approx \\sum_{q=1}^{Q} w_q\\, a(x_q)\\, \\phi_i'(x_q)\\, \\phi_j'(x_q), \\qquad\nf_i \\approx \\sum_{q=1}^{Q} w_q\\, f(x_q)\\, \\phi_i(x_q),\n$$\nwith quadrature nodes $\\{x_q\\}$ and weights $\\{w_q\\}$. The coarse-grid residual for a fixed coefficient and a fixed function $u$ interpolated at the GLL nodes is\n$$\nr = f - K\\, u_h, \\quad \\text{where} \\quad u_h = \\bigl(u(x_0),\\dots,u(x_{N-1})\\bigr)^{\\top}.\n$$\nYou must implement three quadrature strategies for constructing $K$ and $f$:\n- GLL collocation on a single element (coarse $p$): take $Q=N$, nodes equal to the GLL nodes $\\{x_i\\}$, and weights equal to the GLL quadrature weights. This exhibits quadrature aliasing because GLL with $N$ nodes integrates exactly only up to degree $2N-3=2p-1$.\n- Composite subpartitioning with GLL: partition $[-1,1]$ into $s$ equal subintervals and apply $N$-point GLL quadrature on each subinterval, mapping via an affine transform and summing contributions. This keeps the same GLL node set for the coarse finite-dimensional space but uses a composite quadrature to mitigate aliasing.\n- Over-integration reference: use $Q_{\\mathrm{ref}}=200$-point Gauss–Legendre quadrature on $[-1,1]$ to approximate the exact integrals in $K$ and $f$; denote the resulting residual by $r_{\\mathrm{ref}}$. This serves as the near-exact benchmark.\n\nTo isolate quadrature aliasing, use the same trial vector $u_h$ in all three constructions and compare the residuals. Measure the coarse residual accuracy for the two coarse constructions by the Euclidean norms\n$$\nE_{\\mathrm{GLL}} = \\lVert r_{\\mathrm{GLL}} - r_{\\mathrm{ref}} \\rVert_2, \\qquad\nE_{\\mathrm{comp}} = \\lVert r_{\\mathrm{comp}} - r_{\\mathrm{ref}} \\rVert_2,\n$$\nwhere $r_{\\mathrm{GLL}}$ is from single-element GLL quadrature and $r_{\\mathrm{comp}}$ is from composite GLL on $s$ subintervals.\n\nImplementation requirements:\n- Use the standard GLL nodes and weights for a given $N=p+1$. The $N$ GLL nodes are the endpoints $\\pm 1$ and the $(N-2)$ interior roots of the derivative of the Legendre polynomial of degree $(N-1)$. The GLL weights are given by\n$$\nw_i = \\frac{2}{N(N-1)\\,\\bigl(P_{N-1}(x_i)\\bigr)^2},\n$$\nwhere $P_{N-1}$ is the Legendre polynomial of degree $(N-1)$.\n- Use barycentric Lagrange interpolation to evaluate basis functions $\\phi_i(x)$ and their derivatives $\\phi_i'(x)$ at arbitrary quadrature points $x$, with careful handling of the limit when a quadrature point coincides with a node.\n- Assemble $K$ and $f$ via the above quadrature rules. No boundary condition elimination is required because the weak form uses natural boundary conditions, and the chosen $u$ satisfies $u'(\\pm 1)=0$.\n\nTest suite:\nEvaluate the pair $(E_{\\mathrm{GLL}}, E_{\\mathrm{comp}})$ for the following $(p,s)$ parameter sets:\n- $(p,s)=(2,1)$,\n- $(p,s)=(2,4)$,\n- $(p,s)=(4,1)$,\n- $(p,s)=(4,4)$,\n- $(p,s)=(8,1)$,\n- $(p,s)=(8,4)$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list of pairs, with no spaces, where each pair corresponds to a test case in the order listed above and contains the two floating-point values $E_{\\mathrm{GLL}}$ and $E_{\\mathrm{comp}}$ in scientific notation with eight digits after the decimal point. For example, a valid output line with two hypothetical test cases would look like\n$$\n[\\,[1.23456789\\mathrm{e}{-04},9.87654321\\mathrm{e}{-06}],[2.46800000\\mathrm{e}{-03},1.23500000\\mathrm{e}{-04}]\\,].\n$$\nAngles are in radians. No physical units are involved.", "solution": "The problem is valid. It is a well-posed, scientifically grounded problem in the field of numerical analysis for partial differential equations, specifically concerning spectral element methods and multigrid techniques. All necessary data and definitions are provided, and there are no internal contradictions or violations of scientific principles.\n\nThe core of the problem is to investigate the effect of quadrature aliasing on the coarse-grid residual in a one-dimensional spectral element method. The residual, $r = f - K u_h$, is a crucial component in multigrid methods for transferring information from a fine grid to a coarse grid. Its accuracy directly impacts the convergence of the multigrid solver. Aliasing errors arise when the quadrature rule used to compute the discrete stiffness matrix $K$ and load vector $f$ is not sufficiently accurate to integrate the products of basis functions (and their derivatives) with problem coefficients exactly.\n\nWe will implement a solution based on the principles of the spectral element method on a single element occupying the domain $[-1, 1]$.\n\n### 1. Spectral Discretization and Basis Functions\n\nThe solution $u(x)$ is approximated by a polynomial $u_p(x)$ of degree $p$. This approximation is represented in a basis of $N=p+1$ Lagrange polynomials $\\{\\phi_j(x)\\}_{j=0}^p$ defined with respect to the $N$ Gauss-Lobatto-Legendre (GLL) nodes $\\{x_j\\}_{j=0}^p$. These nodes are the zeros of $(1-x^2)P_p'(x)$, where $P_p(x)$ is the Legendre polynomial of degree $p$. The Lagrange basis has the property that $\\phi_j(x_i) = \\delta_{ij}$, where $\\delta_{ij}$ is the Kronecker delta.\n\nThe discrete solution is represented by the vector of its values at the GLL nodes, $u_h = [u(x_0), u(x_1), \\dots, u(x_p)]^\\top$. For this problem, the exact solution $u(x) = (1-x^2)^2$ is used to construct this vector.\n\n### 2. Weak Form and Quadrature\n\nThe weak form of the model problem is given by:\n$$\n\\int_{-1}^{1} a(x)\\, u'(x)\\, v'(x)\\, dx = \\int_{-1}^{1} f(x)\\, v(x)\\, dx\n$$\nSubstituting the spectral approximations $u(x) \\approx \\sum_j u_j \\phi_j(x)$ and using test functions $v(x) = \\phi_i(x)$, we obtain the discrete system $K u_h = f$. The entries of the stiffness matrix $K$ and load vector $f$ are:\n$$\nK_{ij} = \\int_{-1}^{1} a(x)\\, \\phi_i'(x)\\, \\phi_j'(x)\\, dx\n$$\n$$\nf_i = \\int_{-1}^{1} f(x)\\, \\phi_i(x)\\, dx\n$$\nThese integrals are computed numerically using a quadrature rule with $Q$ points $\\{x_q\\}$ and weights $\\{w_q\\}$:\n$$\nK_{ij} \\approx \\sum_{q=1}^{Q} w_q\\, a(x_q)\\, \\phi_i'(x_q)\\, \\phi_j'(x_q)\n$$\n$$\nf_i \\approx \\sum_{q=1}^{Q} w_q\\, f(x_q)\\, \\phi_i(x_q)\n$$\n\n### 3. Quadrature Strategies and Aliasing\n\nThe accuracy of $K$ and $f$ depends on the chosen quadrature rule. The integrand for $K_{ij}$ involves the product of basis function derivatives, $\\phi_i'(x)\\phi_j'(x)$, which is a polynomial of degree $2p-2$, multiplied by the non-polynomial coefficient $a(x)$.\n\nThree quadrature strategies are compared:\n\n1.  **Reference Quadrature ($r_{\\mathrm{ref}}$)**: A high-order $Q_{\\mathrm{ref}}=200$-point Gauss-Legendre rule is used. This quadrature is sufficiently accurate to be considered a \"near-exact\" evaluation of the integrals, providing a benchmark residual $r_{\\mathrm{ref}}$.\n\n2.  **GLL Collocation ($r_{\\mathrm{GLL}}$)**: The $N=p+1$ GLL nodes themselves are used as quadrature points. This rule integrates polynomials of degree up to $2N-3 = 2p-1$ exactly. Since the integrands for $K$ and $f$ involve the non-polynomial functions $a(x)$ and $f(x)$, this quadrature is inexact and introduces aliasing errors. For this specific quadrature, the load vector simplifies to $f_i = w_i f(x_i)$ due to the property $\\phi_i(x_j) = \\delta_{ij}$. The stiffness matrix is assembled using the GLL differentiation matrix $D$, where $D_{ij} = \\phi'_j(x_i)$, as $K_{\\mathrm{GLL}} = D^\\top W A D$, with $W$ and $A$ being diagonal matrices of the GLL weights and the coefficient $a(x)$ evaluated at the GLL nodes, respectively.\n\n3.  **Composite GLL Quadrature ($r_{\\mathrm{comp}}$)**: To mitigate aliasing while using the same GLL points locally, the domain $[-1,1]$ is divided into $s$ subintervals. On each subinterval, an $N$-point GLL quadrature rule is applied via an affine transformation. This results in a composite rule with $s \\times N$ total quadrature points, significantly increasing accuracy and reducing aliasing.\n\nThe error due to aliasing for the latter two methods is measured by the Euclidean norm of the difference between their computed residuals and the reference residual: $E_{\\mathrm{GLL}} = \\lVert r_{\\mathrm{GLL}} - r_{\\mathrm{ref}} \\rVert_2$ and $E_{\\mathrm{comp}} = \\lVert r_{\\mathrm{comp}} - r_{\\mathrm{ref}} \\rVert_2$.\n\n### 4. Implementation of Basis Functions and Derivatives\n\nA key implementation detail is the stable and accurate evaluation of basis functions $\\phi_j(x)$ and their derivatives $\\phi_j'(x)$ at arbitrary quadrature points $x_q$.\n\n-   **GLL Nodes and Weights**: For a given degree $p$, the $p+1$ nodes are found as the roots of $(1-x^2)P'_p(x)$, and the weights are computed from the standard formula involving $P_p(x)$.\n-   **Derivatives at Nodes**: For the GLL quadrature case, where quadrature points coincide with the basis nodes, derivatives are obtained from the entries of the GLL differentiation matrix $D$, which is constructed using established formulas for stability and accuracy.\n-   **Derivatives at Arbitrary Points**: For the reference and composite quadratures, the quadrature points $x_q$ do not generally coincide with the GLL nodes $\\{x_j\\}$. In these cases, we employ a formula for the derivative of a Lagrange polynomial $\\phi_j(x)$ at an arbitrary point $x \\ne x_j$:\n    $$\n    \\phi_j'(x) = \\frac{l'(x)}{l'(x_j)(x-x_j)} - \\frac{\\phi_j(x)}{x-x_j}\n    $$\n    where $l(x) = C(1-x^2)P_p'(x)$ is the polynomial whose roots are the GLL nodes. This requires computing $P_p(x)$ and its derivatives up to second order, which can be done efficiently using their three-term recurrence relations. This approach circumvents the potential instabilities of the naive product-rule definition of $\\phi_j'(x)$.\n\nBy following this procedure, we can systematically assemble the required matrices and vectors for each quadrature strategy, compute the residuals, and evaluate the specified error norms for each test case.", "answer": "```python\nimport numpy as np\nfrom numpy.polynomial.legendre import Legendre\n\ndef solve():\n    \"\"\"\n    Solves the problem of evaluating quadrature aliasing effects on coarse-grid residuals\n    in a 1D spectral element method.\n    \"\"\"\n    \n    test_cases = [\n        (2, 1),\n        (2, 4),\n        (4, 1),\n        (4, 4),\n        (8, 1),\n        (8, 4),\n    ]\n\n    _gll_cache = {}\n    def get_gll_nodes_weights(p):\n        \"\"\"\n        Computes Gauss-Lobatto-Legendre nodes and weights for a given polynomial degree p.\n        Nodes are roots of (1-x^2)P'_p(x).\n        \"\"\"\n        if p in _gll_cache:\n            return _gll_cache[p]\n\n        N = p + 1\n        if p == 0:\n            nodes = np.array([-1.0])\n            weights = np.array([2.0])\n            _gll_cache[p] = (nodes, weights)\n            return nodes, weights\n        if p == 1:\n            nodes = np.array([-1.0, 1.0])\n            weights = np.array([1.0, 1.0])\n            _gll_cache[p] = (nodes, weights)\n            return nodes, weights\n\n        # Interior nodes are roots of P'_p(x)\n        leg_poly = Legendre.basis(p)\n        leg_poly_deriv = leg_poly.deriv(1)\n        interior_nodes = leg_poly_deriv.roots()\n        \n        nodes = np.concatenate(([-1.0], np.sort(interior_nodes), [1.0]))\n        \n        # Weights formula: w_i = 2 / (p*(p+1) * (P_p(x_i))^2)\n        P_p_at_nodes = leg_poly(nodes)\n        weights = 2.0 / (p * (p + 1) * P_p_at_nodes**2)\n        \n        _gll_cache[p] = (nodes, weights)\n        return nodes, weights\n\n    def get_diff_matrix(p, nodes):\n        \"\"\"\n        Computes the GLL differentiation matrix D, where D_ij = phi'_j(x_i).\n        \"\"\"\n        N = p + 1\n        D = np.zeros((N, N))\n        leg_poly = Legendre.basis(p)\n        P_p_at_nodes = leg_poly(nodes)\n\n        for i in range(N):\n            for j in range(N):\n                if i != j:\n                    D[i, j] = (P_p_at_nodes[i] / P_p_at_nodes[j]) * (1.0 / (nodes[i] - nodes[j]))\n        \n        D[0, 0] = -p * (p + 1) / 4.0\n        D[N - 1, N - 1] = p * (p + 1) / 4.0\n        # for i > 0 and i  N-1, D[i,i] is 0 based on Hesthaven text,\n        # but summing off-diagonals is more general.\n        for i in range(1, N - 1):\n             D[i,i] = 0.0 # Standard formula for interior nodes\n        \n        return D\n\n    def legendre_poly_and_derivs(p, x):\n        \"\"\"\n        Computes P_p(x), P'_p(x), P''_p(x) using recurrence relations.\n        \"\"\"\n        if p == 0:\n            return 1.0, 0.0, 0.0\n        \n        p_k_minus_2, p_k_minus_1 = 1.0, x\n        pp_k_minus_2, pp_k_minus_1 = 0.0, 1.0\n        ppp_k_minus_2, ppp_k_minus_1 = 0.0, 0.0\n\n        for k in range(1, p):\n            p_k = ((2 * k + 1) * x * p_k_minus_1 - k * p_k_minus_2) / (k + 1)\n            pp_k = ((2 * k + 1) * (p_k_minus_1 + x * pp_k_minus_1) - k * pp_k_minus_2) / (k + 1)\n            ppp_k = ((2 * k + 1) * (2 * pp_k_minus_1 + x * ppp_k_minus_1) - k * ppp_k_minus_2) / (k + 1)\n            \n            p_k_minus_2, p_k_minus_1 = p_k_minus_1, p_k\n            pp_k_minus_2, pp_k_minus_1 = pp_k_minus_1, pp_k\n            ppp_k_minus_2, ppp_k_minus_1 = ppp_k_minus_1, ppp_k\n\n        return p_k_minus_1, pp_k_minus_1, ppp_k_minus_1\n\n    # Problem-specific functions\n    a = lambda x: 1.0 + 0.3 * np.cos(7.0 * x)\n    a_prime = lambda x: -2.1 * np.sin(7.0 * x)\n    u_exact = lambda x: (1.0 - x**2)**2\n    u_prime = lambda x: -4.0 * x * (1.0 - x**2)\n    u_double_prime = lambda x: -4.0 + 12.0 * x**2\n    f_source = lambda x: -(a_prime(x) * u_prime(x) + a(x) * u_double_prime(x))\n\n    results = []\n    \n    for p, s in test_cases:\n        N = p + 1\n        \n        gll_nodes, gll_weights = get_gll_nodes_weights(p)\n        D = get_diff_matrix(p, gll_nodes)\n        \n        u_h = u_exact(gll_nodes)\n        \n        # Precompute l'(x_j) for arbitrary point derivative evaluation\n        l_prime_at_nodes = np.zeros(N)\n        for j in range(N):\n            xj = gll_nodes[j]\n            _, Pp_prime, Pp_double_prime = legendre_poly_and_derivs(p, xj)\n            l_prime_at_nodes[j] = (1 - xj**2) * Pp_double_prime - 2 * xj * Pp_prime\n            \n        def eval_basis_functions(xq, p_deg, base_nodes, diff_matrix):\n            # Check if xq is one of the base_nodes\n            match_indices = np.where(np.isclose(xq, base_nodes))[0]\n            if len(match_indices) > 0:\n                k = match_indices[0]\n                phis = np.zeros(p_deg + 1)\n                phis[k] = 1.0\n                phi_primes = diff_matrix[k, :]\n                return phis, phi_primes\n            \n            # If xq is not a node, use arbitrary point evaluation formulas\n            phis = np.zeros(p_deg + 1)\n            phi_primes = np.zeros(p_deg + 1)\n\n            _, Pp_prime_xq, Pp_double_prime_xq = legendre_poly_and_derivs(p_deg, xq)\n            l_xq = (1 - xq**2) * Pp_prime_xq\n            l_prime_xq = (1 - xq**2) * Pp_double_prime_xq - 2 * xq * Pp_prime_xq\n\n            for j in range(p_deg + 1):\n                xj = base_nodes[j]\n                phis[j] = l_xq / ((xq - xj) * l_prime_at_nodes[j])\n                phi_primes[j] = (l_prime_xq / (l_prime_at_nodes[j] * (xq - xj))) - (phis[j] / (xq - xj))\n\n            return phis, phi_primes\n\n        # 1. Reference residual (Over-integration)\n        Q_ref = 200\n        xq_ref, wq_ref = np.polynomial.legendre.leggauss(Q_ref)\n        K_ref = np.zeros((N, N))\n        f_ref = np.zeros(N)\n        for xq, wq in zip(xq_ref, wq_ref):\n            phis, phi_primes = eval_basis_functions(xq, p, gll_nodes, D)\n            K_ref += wq * a(xq) * np.outer(phi_primes, phi_primes)\n            f_ref += wq * f_source(xq) * phis\n        r_ref = f_ref - K_ref @ u_h\n\n        # 2. GLL residual (Collocation)\n        K_gll = D.T @ np.diag(gll_weights * a(gll_nodes)) @ D\n        f_gll = gll_weights * f_source(gll_nodes)\n        r_gll = f_gll - K_gll @ u_h\n\n        # 3. Composite GLL residual\n        K_comp = np.zeros((N, N))\n        f_comp = np.zeros(N)\n        sub_interval_bps = np.linspace(-1, 1, s + 1)\n        for i in range(s):\n            a_sub, b_sub = sub_interval_bps[i], sub_interval_bps[i+1]\n            jacobian = (b_sub - a_sub) / 2.0\n            xq_sub = jacobian * gll_nodes + (a_sub + b_sub) / 2.0\n            wq_sub = jacobian * gll_weights\n            \n            for k in range(N):\n                xk = xq_sub[k]\n                wk = wq_sub[k]\n                phis, phi_primes = eval_basis_functions(xk, p, gll_nodes, D)\n                K_comp += wk * a(xk) * np.outer(phi_primes, phi_primes)\n                f_comp += wk * f_source(xk) * phis\n        r_comp = f_comp - K_comp @ u_h\n        \n        e_gll = np.linalg.norm(r_gll - r_ref)\n        e_comp = np.linalg.norm(r_comp - r_ref)\n        results.append([e_gll, e_comp])\n\n    formatted_pairs = [f\"[{e[0]:1.8e},{e[1]:1.8e}]\" for e in results]\n    print(f\"[{','.join(formatted_pairs)}]\")\n\nsolve()\n```", "id": "3401628"}, {"introduction": "Having explored operator construction, we now turn to the inter-grid transfer operators that form the bridge between fine and coarse levels. This practice focuses on a common performance trade-off in $p$-multigrid methods: using a computationally efficient \"mass-lumped\" coarse space versus a theoretically optimal \"consistent\" coarse space. By quantifying the effect of this choice on the convergence of the two-grid correction step, you will gain practical insight into designing efficient and robust prolongation and restriction operators [@problem_id:3401559].", "problem": "Consider a one-dimensional symmetric positive definite elliptic model problem on the reference interval $[-1,1]$, equipped with homogeneous Dirichlet boundary conditions. Let $p$ denote the polynomial degree and let the trial space be the nodal Lagrange basis at the Legendre–Gauss–Lobatto (LGL) points. The Spectral Element Method (SEM) stiffness operator $A$ is defined by the bilinear form $a(u,v) = \\int_{-1}^{1} u'(x) v'(x) \\, dx$ evaluated exactly by the LGL quadrature with weights and the differentiation matrix induced by the LGL nodes. Let $M$ denote the consistent mass operator defined by the bilinear form $m(u,v) = \\int_{-1}^{1} u(x) v(x) \\, dx$ evaluated exactly by Gauss–Legendre quadrature with sufficiently many points to integrate polynomials of degree $2p$ exactly. The Discontinuous Galerkin (DG) and Spectral Element Method (SEM) contexts share this Galerkin foundation for elementwise operators; for clarity, the present problem uses a single spectral element with homogeneous Dirichlet boundary conditions.\n\nIn $p$-multigrid, let the fine space be of degree $p_f$ and the coarse space be of degree $p_c  p_f$. Define the prolongation operator $P$ as the nodal interpolation mapping from the coarse interior degrees of freedom to the fine interior degrees of freedom, induced by the coarse Lagrange basis evaluated at the fine interior LGL nodes. Consider two definitions of restriction, corresponding to two coarse-space inner products:\n- The consistent $L^2$ restriction $R_{\\mathrm{cons}}$ is defined by the $L^2$ projection, $R_{\\mathrm{cons}} = M_c^{-1} P^{\\top} M_f$, where $M_f$ and $M_c$ are the consistent fine and coarse mass operators restricted to interior degrees of freedom.\n- The mass-lumped coarse-space restriction $R_{\\mathrm{lump}}$ uses a Euclidean inner product in which the coarse mass matrix is approximated by the identity, $M_c \\approx I$, yielding $R_{\\mathrm{lump}} = P^{\\top}$.\n\nFor each restriction choice, define the coarse operator by the standard Galerkin construction $A_c = R A_f P$, where $A_f$ is the fine stiffness operator restricted to interior degrees of freedom, and $A_c$ is the corresponding coarse operator. Define the two-grid coarse correction error-propagation operator\n$$\nE = I - P A_c^{-1} R A_f,\n$$\nwhere $I$ is the identity on the fine interior degrees of freedom. Quantify the effectiveness of the coarse correction by the contraction factor in the energy norm induced by $A_f$, defined by\n$$\n\\| E \\|_{A_f} = \\sup_{x \\neq 0} \\sqrt{\\frac{x^{\\top} E^{\\top} A_f E x}{x^{\\top} A_f x}}.\n$$\nThis quantity is the square root of the largest generalized eigenvalue of the pair $\\left(E^{\\top} A_f E, A_f\\right)$.\n\nTask: Propose and realize the mass-lumped coarse space by setting $M_c \\approx I$ so that $R_{\\mathrm{lump}} = P^{\\top}$, and quantify the loss of accuracy in the coarse correction relative to the consistent coarse mass $M_c$ by computing, for each test case, the ratio\n$$\n\\rho = \\frac{\\| E_{\\mathrm{lump}} \\|_{A_f}}{\\| E_{\\mathrm{cons}} \\|_{A_f}},\n$$\nwhere $E_{\\mathrm{lump}}$ and $E_{\\mathrm{cons}}$ are the error-propagation operators built from $R_{\\mathrm{lump}}$ and $R_{\\mathrm{cons}}$, respectively. Values $\\rho \\geq 1$ indicate a deterioration in coarse-correction effectiveness due to mass-lumping.\n\nUse the following test suite of polynomial degree pairs $(p_f, p_c)$:\n- Case 1 (general): $(8, 4)$.\n- Case 2 (near-minimal coarse space): $(3, 2)$.\n- Case 3 (aggressive coarsening): $(10, 2)$.\n- Case 4 (near-identity coarsening): $(12, 11)$.\n\nFor all computations:\n- Work on the reference interval $[-1,1]$.\n- Enforce homogeneous Dirichlet boundary conditions by restricting to interior degrees of freedom (i.e., omit the boundary LGL nodes from the algebraic operators).\n- Use Legendre–Gauss–Lobatto nodes for building the differentiation matrix and stiffness operator via exact quadrature under this collocation setting.\n- Use Gauss–Legendre quadrature with $p+1$ points to assemble the consistent mass operator exactly.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4]\"), where each entry is the floating-point value of $\\rho$ for the corresponding test case in the order listed above. No physical units or angles are involved in this computation, so no unit specification is required.", "solution": "## Problem Validation\n\n### Step 1: Extract Givens\n- **Model Problem**: One-dimensional symmetric positive definite elliptic model problem on the interval $[-1,1]$ with homogeneous Dirichlet boundary conditions.\n- **Discretization Method**: Spectral Element Method (SEM) using a single element.\n- **Trial Space**: Nodal Lagrange basis at the Legendre–Gauss–Lobatto (LGL) points for a given polynomial degree $p$.\n- **Stiffness Operator $A$**: Defined by $a(u,v) = \\int_{-1}^{1} u'(x) v'(x) \\, dx$, evaluated exactly using LGL quadrature.\n- **Consistent Mass Operator $M$**: Defined by $m(u,v) = \\int_{-1}^{1} u(x) v(x) \\, dx$, evaluated exactly using Gauss-Legendre quadrature with $p+1$ points.\n- **Boundary Conditions**: Homogeneous Dirichlet, enforced by restricting all operators to interior degrees of freedom.\n- **$p$-Multigrid Spaces**: A fine space of polynomial degree $p_f$ and a coarse space of degree $p_c  p_f$.\n- **Prolongation Operator $P$**: Nodal interpolation from coarse interior degrees of freedom to fine interior degrees of freedom.\n- **Restriction Operators**:\n    - Consistent Restriction $R_{\\mathrm{cons}} = M_c^{-1} P^{\\top} M_f$, where $M_f$ and $M_c$ are the fine and coarse consistent mass operators on interior degrees of freedom.\n    - Mass-Lumped Restriction $R_{\\mathrm{lump}} = P^{\\top}$, corresponding to approximating the coarse mass matrix $M_c$ as the identity $I$.\n- **Coarse Operator $A_c$**: Defined by the Galerkin projection $A_c = R A_f P$, where $A_f$ is the fine stiffness operator on interior degrees of freedom.\n- **Two-Grid Error-Propagation Operator $E$**: $E = I - P A_c^{-1} R A_f$, where $I$ is the identity on the fine interior space.\n- **Contraction Factor $\\|E\\|_{A_f}$**: The energy norm of the error-propagation operator, defined as $\\| E \\|_{A_f} = \\sup_{x \\neq 0} \\sqrt{\\frac{x^{\\top} E^{\\top} A_f E x}{x^{\\top} A_f x}}$. This is the square root of the largest generalized eigenvalue of the pair $(E^{\\top} A_f E, A_f)$.\n- **Task**: Compute the ratio $\\rho = \\frac{\\| E_{\\mathrm{lump}} \\|_{A_f}}{\\| E_{\\mathrm{cons}} \\|_{A_f}}$ for given test cases.\n- **Test Cases**: $(p_f, p_c)$ pairs: $(8, 4)$, $(3, 2)$, $(10, 2)$, and $(12, 11)$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the validation criteria:\n- **Scientifically Grounded**: The problem is firmly rooted in the established theory of numerical analysis for partial differential equations, specifically $p$-multigrid methods for spectral element discretizations. All definitions—operators, norms, and inter-grid transfers—are standard in this field.\n- **Well-Posed**: The problem is mathematically well-defined. It asks for a specific, computable quantity, $\\rho$, derived from standard matrix operations and a generalized eigenvalue problem. The underlying stiffness matrices for the elliptic problem are symmetric positive definite, ensuring that their inverses and the subsequent calculations are well-defined.\n- **Objective**: The problem statement is precise, quantitative, and free of any subjective or ambiguous language.\n- **Completeness and Consistency**: All necessary definitions, equations, and parameters are provided. The matrix dimensions for the defined operators are consistent, ensuring the validity of compositions like $A_c = R A_f P$.\n\nThere are no violations of scientific principles, no missing information, no contradictions, and no ambiguities. The problem is a standard, albeit complex, numerical experiment in computational mathematics.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be provided.\n\n---\n\n## Principle-Based Design\n\nThe solution requires implementing the components of a $p$-type two-grid solver for a one-dimensional spectral element method and then analyzing the convergence properties of two different coarse-grid formulations. The core of the task is to construct the specified matrices and operators and then compute the energy norm of the resulting two-grid error propagation operators.\n\n### 1. Nodal Basis and Quadrature Rules\nThe foundation of the spectral element method is the choice of basis functions and quadrature rules.\n- **Legendre-Gauss-Lobatto (LGL) Points**: For a polynomial degree $p$, we use $p+1$ LGL points on $[-1,1]$. These points are the roots of $(1-x^2)P_p'(x)$, where $P_p(x)$ is the Legendre polynomial of degree $p$. The interior LGL nodes are the roots of the Jacobi polynomial $P_{p-1}^{(1,1)}(x)$. The basis functions are the Lagrange polynomials $\\{l_j(x)\\}_{j=0}^p$ associated with these nodes.\n- **LGL Quadrature**: This quadrature rule uses the LGL nodes as abscissas and has associated weights $w_j = \\frac{2}{p(p+1)[P_p(x_j)]^2}$. It integrates polynomials of degree up to $2p-1$ exactly.\n- **Gauss-Legendre (GL) Quadrature**: This rule, with $k$ points, integrates polynomials of degree up to $2k-1$ exactly.\n\n### 2. Operator Assembly\nThe stiffness and mass operators are constructed using the appropriate quadrature rules. All operators are initially assembled for the full set of $p+1$ degrees of freedom.\n- **Stiffness Operator $A_p$**: The bilinear form is $a(l_j, l_i) = \\int_{-1}^1 l_i'(x) l_j'(x) dx$. This is evaluated using LGL quadrature. Using the differentiation matrix $D$, where $D_{ij} = l_j'(x_i)$, the stiffness matrix is given by $A_p = D^T W D$, where $W$ is the diagonal matrix of LGL weights. This quadrature is exact since the integrand $l_i'(x)l_j'(x)$ is a polynomial of degree $2(p-1)$, and LGL quadrature is exact for degrees up to $2p-1$.\n- **Consistent Mass Operator $M_p$**: The bilinear form is $m(l_j, l_i) = \\int_{-1}^1 l_i(x) l_j(x) dx$. The integrand is a polynomial of degree $2p$. To integrate this exactly, we need a quadrature rule exact for degree $2p$. Gauss-Legendre quadrature with $k$ points is exact for degree $2k-1$, so we require $2k-1 \\geq 2p$, which implies $k \\geq p+1/2$. The choice of $k=p+1$ GL points, as specified, is sufficient. The mass matrix is assembled as $M_p = V^T \\Omega V$, where $\\Omega$ is the diagonal matrix of GL weights and $V$ is a \"Vandermonde-like\" matrix with entries $V_{ki} = l_i(y_k)$, evaluating the LGL Lagrange basis function $l_i$ at the $k$-th GL node $y_k$.\n\n### 3. Boundary Conditions and Interior Subspaces\nHomogeneous Dirichlet boundary conditions ($u(-1)=u(1)=0$) are imposed by restricting the problem to the subspace spanned by interior basis functions. Algebraically, this is achieved by taking the submatrices of $A_p$ and $M_p$ corresponding to the interior nodes (i.e., excluding the first and last rows and columns). The resulting matrices $A_f$, $M_f$, and $M_c$ operate on vectors of interior degrees of freedom.\n\n### 4. Inter-Grid Transfer Operators\n- **Prolongation $P$**: This operator maps vectors from the coarse interior space to the fine interior space. It is constructed by evaluating the coarse-space basis functions at the fine-space interior nodes. The basis for the coarse interior space consists of the Lagrange polynomials $\\{l_{c,j}\\}_{j=1}^{p_c-1}$ associated with the coarse *interior* nodes. These basis functions are themselves defined using the full set of $p_c+1$ coarse LGL nodes. The matrix entry $P_{ij}$ is thus the value of the $j$-th coarse interior basis function evaluated at the $i$-th fine interior node. Barycentric interpolation is an effective method for this evaluation.\n- **Restriction $R$**: The restriction operator maps from the fine space to the coarse space.\n    - $R_{\\mathrm{lump}} = P^T$: This is the transpose of the prolongation operator, which corresponds to a simple injection of values and is equivalent to using a trivial (identity) inner product on the coarse space.\n    - $R_{\\mathrm{cons}} = M_c^{-1} P^T M_f$: This is the adjoint of $P$ with respect to the $L^2$ inner product, represented by the mass matrices $M_f$ and $M_c$. It is the theoretically optimal choice for an $L^2$-orthogonal projection.\n\n### 5. Two-Grid Analysis\nFor each choice of restriction ($R_{\\mathrm{cons}}$ and $R_{\\mathrm{lump}}$), the following steps are performed:\n1.  **Coarse Grid Operator $A_c$**: Form the Galerkin coarse operator $A_c = R A_f P$.\n2.  **Error Propagation Operator $E$**: Construct the two-grid error propagation operator $E = I - P A_c^{-1} R A_f$. This operator describes how the error is transformed by one cycle of coarse-grid correction (pre-smoothing is omitted in this definition, as is common for analyzing only the coarse correction step).\n3.  **Energy Norm Calculation**: The effectiveness of the coarse correction is measured by the $A_f$-norm of $E$. This norm is computed as the square root of the largest generalized eigenvalue $\\lambda_{\\max}$ of the matrix pair $(E^T A_f E, A_f)$. This eigenvalue problem is solved using a numerically stable algorithm for symmetric-definite pairs.\n4.  **Ratio $\\rho$**: The final step is to compute the ratio $\\rho = \\|E_{\\mathrm{lump}}\\|_{A_f} / \\|E_{\\mathrm{cons}}\\|_{A_f}$ to quantify the degradation in performance due to mass lumping in the coarse-space inner product.\n\nThis structured procedure is executed for each $(p_f, p_c)$ pair specified in the test suite.", "answer": "```python\nimport numpy as np\nfrom scipy.special import roots_jacobi, eval_legendre\nfrom scipy.linalg import eigh, inv\nfrom scipy.interpolate import BarycentricInterpolator\nfrom numpy.polynomial.legendre import leggauss\n\ndef lgl_nodes_weights(p):\n    \"\"\"\n    Computes Legendre-Gauss-Lobatto (LGL) nodes and weights for a given\n    polynomial degree p. Total number of points is p+1.\n    \"\"\"\n    if p == 0:\n        return np.array([-1.0]), np.array([2.0])\n    if p == 1:\n        return np.array([-1.0, 1.0]), np.array([1.0, 1.0])\n    \n    # Interior nodes are roots of the Jacobi polynomial P_{p-1}^{(1,1)}(x)\n    interior_nodes, _ = roots_jacobi(p - 1, 1, 1)\n    nodes = np.concatenate(([-1.0], interior_nodes, [1.0]))\n    \n    # Weights are computed using the formula involving P_p(x_j)\n    P_p_at_nodes = eval_legendre(p, nodes)\n    weights = 2.0 / (p * (p + 1) * P_p_at_nodes**2)\n    \n    return nodes, weights\n\ndef lgl_diff_matrix(p, nodes):\n    \"\"\"\n    Computes the (p+1)x(p+1) differentiation matrix for LGL nodes.\n    \"\"\"\n    N = p\n    N_plus_1 = N + 1\n    D = np.zeros((N_plus_1, N_plus_1))\n    \n    if p == 0:\n        return np.array([[0.0]])\n        \n    P_N_at_nodes = eval_legendre(N, nodes)\n    \n    # Off-diagonal entries\n    for i in range(N_plus_1):\n        for j in range(N_plus_1):\n            if i != j:\n                D[i, j] = P_N_at_nodes[i] / (P_N_at_nodes[j] * (nodes[i] - nodes[j]))\n    \n    # Diagonal entries\n    D[0, 0] = -N * (N + 1) / 4.0\n    D[N, N] = N * (N + 1) / 4.0\n    \n    return D\n\ndef stiffness_matrix(weights, diff_matrix):\n    \"\"\"\n    Computes the stiffness matrix A = D^T W D.\n    \"\"\"\n    W = np.diag(weights)\n    return diff_matrix.T @ W @ diff_matrix\n\ndef mass_matrix(p, lgl_nodes):\n    \"\"\"\n    Computes the consistent mass matrix M using Gauss-Legendre quadrature\n    with p+1 points for exactness.\n    \"\"\"\n    p_lgl = p\n    num_lgl_nodes = p_lgl + 1\n    \n    # Use k=p+1 GL points for exactness of degree 2p polynomial integration\n    k = p_lgl + 1\n    gl_nodes, gl_weights = leggauss(k)\n    \n    # Create Vandermonde-like matrix V_{ij} = l_j(gl_node_i) where l_j is the\n    # Lagrange polynomial for the j-th LGL node.\n    V = np.zeros((k, num_lgl_nodes))\n    interp = BarycentricInterpolator(lgl_nodes)\n    \n    for j in range(num_lgl_nodes):\n        y = np.zeros(num_lgl_nodes)\n        y[j] = 1.0\n        interp.set_yi(y)\n        V[:, j] = interp(gl_nodes)\n        \n    Omega = np.diag(gl_weights)\n    M = V.T @ Omega @ V\n    return M\n\ndef prolongation_matrix(p_c, nodes_c, nodes_f_int):\n    \"\"\"\n    Computes the prolongation matrix P, which interpolates from coarse\n    interior DoFs to fine interior DoFs.\n    \"\"\"\n    num_fine_int = len(nodes_f_int)\n    num_coarse_int = p_c - 1\n    \n    if num_coarse_int = 0:\n        return np.zeros((num_fine_int, 0))\n\n    P = np.zeros((num_fine_int, num_coarse_int))\n    # Interpolation is based on the full set of coarse nodes\n    interp = BarycentricInterpolator(nodes_c)\n    \n    # Iterate through coarse interior basis functions\n    for j in range(num_coarse_int):\n        coarse_node_idx_full = j + 1\n        y = np.zeros(p_c + 1)\n        y[coarse_node_idx_full] = 1.0\n        interp.set_yi(y)\n        P[:, j] = interp(nodes_f_int)\n\n    return P\n\ndef calculate_energy_norm(E, A_f):\n    \"\"\"\n    Calculates the energy norm ||E||_Af.\n    \"\"\"\n    # We need to solve the generalized eigenvalue problem (E^T A_f E) v = lambda A_f v\n    op = E.T @ A_f @ E\n    # Use eigh for symmetric-definite generalized eigenvalue problems\n    eigvals, _ = eigh(op, A_f)\n    # The norm squared is the largest eigenvalue. Eigenvalues are real.\n    return np.sqrt(np.max(eigvals))\n\n\ndef calculate_rho(p_f, p_c):\n    \"\"\"\n    Calculates the performance ratio rho for a given (p_f, p_c) pair.\n    \"\"\"\n    # 1. Fine grid setup\n    nodes_f, weights_f = lgl_nodes_weights(p_f)\n    D_f = lgl_diff_matrix(p_f, nodes_f)\n    A_f_full = stiffness_matrix(weights_f, D_f)\n    if p_f > 0:\n        M_f_full = mass_matrix(p_f, nodes_f)\n    else: # Should not happen based on problem constraints\n        M_f_full = np.array([[]])\n\n    \n    # 2. Coarse grid setup\n    nodes_c, _ = lgl_nodes_weights(p_c)\n    if p_c > 0:\n        M_c_full = mass_matrix(p_c, nodes_c)\n    else: # Should not happen\n        M_c_full = np.array([[]])\n    \n    # 3. Apply BCs by restricting to interior DoFs\n    nodes_f_int = nodes_f[1:-1]\n    A_f = A_f_full[1:-1, 1:-1]\n    M_f = M_f_full[1:-1, 1:-1]\n    M_c = M_c_full[1:-1, 1:-1]\n    \n    # 4. Prolongation operator\n    P = prolongation_matrix(p_c, nodes_c, nodes_f_int)\n    \n    num_fine_int = p_f - 1\n    if num_fine_int = 0: return 1.0 # Trivial case\n    I_f = np.eye(num_fine_int)\n\n    num_coarse_int = p_c - 1\n    if num_coarse_int = 0:\n        norm_cons = 1.0\n        norm_lump = 1.0\n        return 1.0\n    \n    # 5. Consistent case\n    R_cons = inv(M_c) @ P.T @ M_f\n    A_c_cons = R_cons @ A_f @ P\n    E_cons = I_f - P @ inv(A_c_cons) @ R_cons @ A_f\n    norm_cons = calculate_energy_norm(E_cons, A_f)\n\n    # 6. Mass-lumped case\n    R_lump = P.T\n    A_c_lump = R_lump @ A_f @ P\n    E_lump = I_f - P @ inv(A_c_lump) @ R_lump @ A_f\n    norm_lump = calculate_energy_norm(E_lump, A_f)\n    \n    # 7. Ratio\n    if norm_cons == 0:\n        # If consistent correction is exact, ratio is 1 if lumped is also exact, else inf.\n        return 1.0 if norm_lump == 0 else np.inf\n      \n    return norm_lump / norm_cons\n\ndef solve():\n    \"\"\"\n    Main solver function to execute the computation for all test cases.\n    \"\"\"\n    test_cases = [\n        (8, 4),    # general\n        (3, 2),    # near-minimal coarse space\n        (10, 2),   # aggressive coarsening\n        (12, 11),  # near-identity coarsening\n    ]\n\n    results = []\n    for p_f, p_c in test_cases:\n        rho = calculate_rho(p_f, p_c)\n        results.append(rho)\n\n    print(f\"[{','.join(f'{r:.15f}' for r in results)}]\")\n\nsolve()\n```", "id": "3401559"}, {"introduction": "With an understanding of operator construction and inter-grid transfers, we can analyze the performance of the complete multigrid algorithm. This exercise utilizes a simplified modal error model to compare the efficiency of different multigrid cycle types, such as the $V$-cycle, $W$-cycle, and $F$-cycle. By modeling how each cycle type addresses different error components, you will learn to predict the optimal cycle strategy based on problem characteristics and the coarsening strategy, moving from implementation details to algorithmic analysis [@problem_id:3401572].", "problem": "You are asked to design and implement a predictive comparison of multigrid cycle types for polynomial-degree multigrid (also called $p$-multigrid) within a spectral or Discontinuous Galerkin method. The comparison must be driven by a simplified, yet principled, modal error-propagation model that captures the essential features: smoothing dampens high-degree modal components more strongly, and coarse-grid correction reduces the error components representable on the coarse polynomial space but does so inexactly unless the coarsest system is solved exactly.\n\nYour program must implement the following components, derived from core definitions of modal representations and linear multigrid cycles for symmetric positive definite problems:\n\n- Represent the error on a single element at polynomial degree $p$ as a vector of modal coefficients $\\{e_m\\}_{m=0}^{p}$ in a hierarchical orthogonal polynomial basis, where $m$ is the modal index. The initial error spectrum is specified by a power-law amplitude shape $e_m \\propto (m+1)^{-\\beta}$, where $\\beta \\ge 0$ is given. This is consistent with expanding the error in the modal basis of the spectral or Discontinuous Galerkin operator and reflects common smoothness-weighted spectra for elliptic problems.\n\n- Define a smoothing operator $S_p$ that acts diagonally on modal components. For a single smoothing sweep at degree $p$, the reduction factor on mode $m$ is\n$$\n\\rho_s(m;p) \\;=\\; \\exp\\!\\big(-\\sigma\\,\\theta_m^{\\kappa}\\big), \\qquad \\theta_m \\;=\\; \\frac{m}{p},\n$$\nwith fixed parameters $\\sigma0$ and $\\kappa0$. With $ \\nu_{\\text{pre}} $ pre-smoothing sweeps and $ \\nu_{\\text{post}} $ post-smoothing sweeps, the total smoothing factors before and after coarse correction at degree $p$ are\n$$\n\\rho_{\\text{pre}}(m;p) \\;=\\; \\exp\\!\\big(-\\sigma\\,\\nu_{\\text{pre}}\\,\\theta_m^{\\kappa}\\big), \\qquad\n\\rho_{\\text{post}}(m;p) \\;=\\; \\exp\\!\\big(-\\sigma\\,\\nu_{\\text{post}}\\,\\theta_m^{\\kappa}\\big).\n$$\n\n- Define the restriction operator for $p$-multigrid as truncation of modes to degree $p_c$ (the coarse degree) and prolongation as injection into the low-order modal subspace on the fine grid. Let the polynomial degree reduction strategy be one of the following:\n    - Halving: $p \\mapsto p_c = \\max(1,\\lfloor p/2 \\rfloor)$.\n    - Decrement: $p \\mapsto p_c = \\max(1,p-1)$.\n  The coarse-grid correction is computed by recursively applying one multigrid cycle on the coarse level, which is inexact except on the coarsest recursion termination. The coarse-grid correction replaces the low-order modal components on the fine grid by their post-cycle value computed on the coarse grid.\n\n- Define the recursion termination at the coarsest degree $p_{\\min}=1$ as an inexact solve that reduces all modes by a uniform factor $\\rho_0$ with $0\\rho_01$, i.e., on the coarsest level the error update is $e \\leftarrow \\rho_0 e$. This models a practical inexact coarse solve and ensures that the choice of cycle type is meaningful.\n\n- Define three multigrid cycle types in terms of the number of recursive coarse calls per level, $\\gamma_{\\ell}$, at recursion depth $\\ell$:\n    - $V$-cycle: $\\gamma_{\\ell}=1$ for all $\\ell$.\n    - $W$-cycle: $\\gamma_{\\ell}=2$ for all $\\ell$.\n    - Nested $F$-cycle: $\\gamma_{0}=1$ at the finest level (depth $\\ell=0$) and $\\gamma_{\\ell}=2$ for all deeper levels $\\ell \\ge 1$.\n  For a level with degree $pp_{\\min}$, the one-cycle error update at that level is:\n  1. Pre-smoothing: $e_m \\leftarrow \\rho_{\\text{pre}}(m;p)\\, e_m$ for all $m$.\n  2. Coarse correction: let $p_c$ be the coarse degree. For $i=1,\\dots,\\gamma_{\\ell}$, restrict the current low modes to the coarse grid, apply one full cycle on the coarse grid to obtain updated coarse error, and prolong the updated coarse low-order modes back by replacing the low-order entries on the fine level.\n  3. Post-smoothing: $e_m \\leftarrow \\rho_{\\text{post}}(m;p)\\, e_m$.\n\n- Define a work model per cycle to compare efficiency across cycles. Let the cost units be proportional to the number of modal coefficients $(p+1)$ at a level. The cost model at degree $p$ and recursion depth $\\ell$ is\n$$\nW(p,\\ell) \\;=\\; c_s\\,(\\nu_{\\text{pre}}+\\nu_{\\text{post}})\\,(p+1) \\;+\\; c_{\\text{corr}}\\,(p+1) \\;+\\; \\gamma_{\\ell}\\, W(p_c,\\ell+1),\n$$\nwith base cost on the coarsest degree\n$$\nW(p_{\\min},\\ell) \\;=\\; c_{\\text{coarse}}\\,(p_{\\min}+1).\n$$\nThis models that each cycle at degree $p$ performs pre/post smoothing, a coarse-correction stage, and a number of recursive coarse cycles equal to $\\gamma_{\\ell}$.\n\n- For a given $(p,\\beta)$ and a chosen degree-reduction strategy, define the initial modal amplitudes at degree $p$ by\n$$\ne_m^{(0)} \\;=\\; (m+1)^{-\\beta}, \\quad m=0,\\dots,p.\n$$\nLet $e^{(1)}$ denote the error vector after one multigrid cycle at the finest level. Define the energy reduction factor per cycle as\n$$\nr \\;=\\; \\frac{\\sum_{m=0}^{p} \\left(e_m^{(1)}\\right)^2}{\\sum_{m=0}^{p} \\left(e_m^{(0)}\\right)^2}.\n$$\nDefine the work per decade (base-$10$) of error reduction as\n$$\n\\text{WPD} \\;=\\; \\frac{W(p,0)}{-\\log_{10}(r)},\n$$\nwith the convention that if $r \\ge 1$ then $\\text{WPD}=+\\infty$.\n\n- For each test case below, your program must compute the predicted $\\text{WPD}$ for each of the three cycle types and return the index of the optimal cycle type that minimizes $\\text{WPD}$. Use the index encoding: $0$ for $V$-cycle, $1$ for $W$-cycle, and $2$ for nested $F$-cycle. In the case of a numerical tie within a tolerance of $10^{-8}$, choose the cycle type with the smaller total work $W(p,0)$; if still tied within the same tolerance, choose the smallest index.\n\nUse the following fixed parameters for the model:\n- Smoother parameters: $\\nu_{\\text{pre}}=\\nu_{\\text{post}}=2$, $\\sigma=2.5$, $\\kappa=2$.\n- Coarsest-level reduction: $\\rho_0=0.2$.\n- Work model coefficients: $c_s=1.0$, $c_{\\text{corr}}=0.5$, $c_{\\text{coarse}}=2.0$.\n- Minimum degree: $p_{\\min}=1$.\n\nYour program must evaluate the following test suite of inputs. Each test is a tuple $(p,\\beta,\\text{strategy})$, where the strategy is either halving or decrement as defined above:\n- Test A: $(8, 2.0, \\text{halving})$.\n- Test B: $(8, 0.0, \\text{halving})$.\n- Test C: $(7, 1.5, \\text{decrement})$.\n- Test D: $(3, 1.0, \\text{decrement})$.\n- Test E: $(16, 3.0, \\text{decrement})$.\n- Test F: $(12, 0.5, \\text{halving})$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[resultA,resultB,resultC,resultD,resultE,resultF]\"), where each result is the integer index corresponding to the optimal cycle type for the respective test case. No additional text should be printed. No physical units or angle units are involved in this problem; all outputs are dimensionless integers as specified.", "solution": "The problem requires a comparison of three multigrid cycle types—$V$-cycle, $W$-cycle, and nested $F$-cycle—for a polynomial-degree multigrid ($p$-multigrid) method. The comparison is based on a simplified modal error propagation model, where the objective is to find the cycle type that minimizes the computational work required to reduce the error by a factor of ten, a metric known as Work-Per-Decade (WPD).\n\nThe solution is implemented by constructing a computational model that simulates the behavior of each cycle type according to the provided specifications. The overall approach is encapsulated within a Python class, `MultigridModel`, which allows for a clean separation of concerns and efficient computation through memoization. The main components of the model are the recursive calculation of computational work and the recursive construction of the error propagation operator.\n\nFirst, we define functions to handle the recursive structure of the multigrid hierarchy. The polynomial degree on a coarser level, $p_c$, is determined from the fine-level degree $p$ using one of two strategies: halving, $p_c = \\max(1, \\lfloor p/2 \\rfloor)$, or decrement, $p_c = \\max(1, p-1)$. The number of coarse-grid corrections at a given recursion level $\\ell$, denoted by $\\gamma_\\ell$, is determined by the cycle type: $\\gamma_\\ell=1$ for a $V$-cycle, $\\gamma_\\ell=2$ for a $W$-cycle, and $\\gamma_0=1, \\gamma_{\\ell0}=2$ for an $F$-cycle.\n\nThe computational work, $W(p, \\ell)$, for a single cycle at degree $p$ and recursion depth $\\ell$, is calculated recursively. The total work is the sum of the work for local operations (smoothing and coarse-grid setup) and the work from the recursive calls to the coarser grid. The formula is:\n$$\nW(p,\\ell) = c_s(\\nu_{\\text{pre}}+\\nu_{\\text{post}})(p+1) + c_{\\text{corr}}(p+1) + \\gamma_{\\ell} W(p_c,\\ell+1)\n$$\nThe recursion terminates at the minimum polynomial degree $p_{\\min}=1$, where the work is given by a fixed base cost, $W(p_{\\min},\\ell) = c_{\\text{coarse}}(p_{\\min}+1)$. This recursive calculation is implemented in a memoized function, `calculate_work`, to avoid redundant computations.\n\nNext, we model the error propagation. The error is represented as a vector of coefficients $\\{e_m\\}_{m=0}^{p}$ in a modal basis. A single multigrid cycle acts as a linear operator on this error vector. We can therefore construct the matrix representation of this one-cycle error propagation operator, let's call it $M(p, \\ell)$. This operator is also computed recursively.\n\nA cycle at degree $p  p_{\\min}$ consists of three stages:\n1.  **Pre-smoothing**: The error is multiplied by the pre-smoothing operator, $S_{\\text{pre}}(p)$, which is a diagonal matrix. The diagonal entry for mode $m$ is $(\\rho_s(m;p))^{\\nu_{\\text{pre}}}$, where $\\rho_s(m;p) = \\exp(-\\sigma (m/p)^{\\kappa})$.\n2.  **Coarse-Grid Correction**: This stage corrects the low-degree modes ($m=0, \\dots, p_c$). It involves applying the recursively-obtained coarse-grid cycle operator, $M(p_c, \\ell+1)$, $\\gamma_{\\ell}$ times.\n3.  **Post-smoothing**: The error is multiplied by the post-smoothing operator, $S_{\\text{post}}(p)$, which is structurally identical to $S_{\\text{pre}}(p)$ (since $\\nu_{\\text{pre}}=\\nu_{\\text{post}}$).\n\nThe resulting one-cycle operator for degree $p$ can be expressed as a matrix product: $M(p, \\ell) = S_{\\text{post}}(p) \\cdot C(p, \\ell) \\cdot S_{\\text{pre}}(p)$, where $C(p, \\ell)$ is the coarse-grid correction operator. $C(p, \\ell)$ is a block-diagonal matrix that applies $(M(p_c, \\ell+1))^{\\gamma_\\ell}$ to the low-degree modes and acts as the identity on the high-degree modes. The base case for this recursion is at $p=p_{\\min}=1$, where the operator is a simple diagonal matrix $M(1, \\ell) = \\rho_0 I$, with $\\rho_0=0.2$ being the uniform error reduction factor of the inexact coarse solve. This recursive construction is implemented in a memoized function, `get_cycle_operator`.\n\nWith the work $W(p,0)$ and the operator $M(p,0)$ for the finest level, we can calculate the WPD. The initial error vector $e^{(0)}$ is generated with modal amplitudes $e_m^{(0)} = (m+1)^{-\\beta}$. The error after one cycle is $e^{(1)} = M(p,0) e^{(0)}$. The energy reduction factor is the ratio of the squared $L^2$-norms of the error vectors:\n$$\nr = \\frac{\\|e^{(1)}\\|_2^2}{\\|e^{(0)}\\|_2^2} = \\frac{\\sum_{m=0}^{p} (e_m^{(1)})^2}{\\sum_{m=0}^{p} (e_m^{(0)})^2}\n$$\nThe Work-Per-Decade is then computed as:\n$$\n\\text{WPD} = \\frac{W(p,0)}{-\\log_{10}(r)}\n$$\nFor each test case, this procedure is performed for all three cycle types ($V$, $W$, $F$). The optimal cycle is determined by finding the minimum WPD. In case of ties (within a tolerance of $10^{-8}$), the cycle with the lower total work $W(p,0)$ is chosen. If the work is also tied, the cycle with the smallest index ($0$ for $V$, $1$ for $W$, $2$ for $F$) is selected. The program proceeds through the specified list of test cases and reports the index of the optimal cycle for each.", "answer": "```python\nimport numpy as np\nfrom functools import lru_cache\n\n# Define global constants as specified in the problem\nNU_PRE = 2\nNU_POST = 2\nSIGMA = 2.5\nKAPPA = 2.0\nRHO_0 = 0.2\nC_S = 1.0\nC_CORR = 0.5\nC_COARSE = 2.0\nP_MIN = 1\n\nclass MultigridModel:\n    \"\"\"\n    Encapsulates the logic for the p-multigrid model for a specific\n    coarsening strategy, using memoization for efficiency.\n    \"\"\"\n    def __init__(self, strategy):\n        if strategy not in ['halving', 'decrement']:\n            raise ValueError(\"Strategy must be 'halving' or 'decrement'.\")\n        self.strategy = strategy\n\n    @lru_cache(maxsize=None)\n    def get_coarse_p(self, p):\n        \"\"\"Computes the coarse-grid polynomial degree.\"\"\"\n        if self.strategy == 'halving':\n            return max(P_MIN, p // 2)\n        else:  # 'decrement'\n            return max(P_MIN, p - 1)\n\n    @staticmethod\n    @lru_cache(maxsize=None)\n    def get_gamma(level, cycle_type):\n        \"\"\"Determines the number of coarse-grid calls per cycle.\"\"\"\n        if cycle_type == 'V':\n            return 1\n        elif cycle_type == 'W':\n            return 2\n        elif cycle_type == 'F':\n            return 1 if level == 0 else 2\n        else:\n            raise ValueError(\"Unknown cycle type.\")\n\n    @lru_cache(maxsize=None)\n    def calculate_work(self, p, level, cycle_type):\n        \"\"\"Recursively calculates the total work for one multigrid cycle.\"\"\"\n        if p == P_MIN:\n            return C_COARSE * (P_MIN + 1)\n        \n        p_c = self.get_coarse_p(p)\n        gamma = self.get_gamma(level, cycle_type)\n        \n        local_work = (C_S * (NU_PRE + NU_POST) + C_CORR) * (p + 1)\n        recursive_work = gamma * self.calculate_work(p_c, level + 1, cycle_type)\n        \n        return local_work + recursive_work\n\n    @lru_cache(maxsize=None)\n    def get_cycle_operator(self, p, level, cycle_type):\n        \"\"\"\n        Recursively computes the matrix representation of the one-cycle\n        error propagation operator.\n        \"\"\"\n        if p == P_MIN:\n            return RHO_0 * np.identity(p + 1)\n\n        p_c = self.get_coarse_p(p)\n        gamma = self.get_gamma(level, cycle_type)\n\n        # 1. Smoothing operators (diagonal matrices)\n        m_vals = np.arange(p + 1, dtype=float)\n        theta_m = m_vals / p\n        \n        rho_s_vals = np.exp(-SIGMA * (theta_m ** KAPPA))\n        \n        S_pre = np.diag(rho_s_vals ** NU_PRE)\n        S_post = np.diag(rho_s_vals ** NU_POST)\n\n        # 2. Coarse-grid correction operator\n        M_coarse = self.get_cycle_operator(p_c, level + 1, cycle_type)\n        M_coarse_gamma = np.linalg.matrix_power(M_coarse, gamma)\n        \n        C_op = np.identity(p + 1)\n        C_op[0:p_c + 1, 0:p_c + 1] = M_coarse_gamma\n\n        # 3. Combine operators to form the full cycle operator: M = S_post * C * S_pre\n        M = S_post @ C_op @ S_pre\n        \n        return M\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    test_cases = [\n        (8, 2.0, 'halving'),   # Test A\n        (8, 0.0, 'halving'),   # Test B\n        (7, 1.5, 'decrement'), # Test C\n        (3, 1.0, 'decrement'), # Test D\n        (16, 3.0, 'decrement'),# Test E\n        (12, 0.5, 'halving'),  # Test F\n    ]\n\n    final_results = []\n    cycle_types = ['V', 'W', 'F']\n    TOL = 1e-8\n\n    for p, beta, strategy in test_cases:\n        model = MultigridModel(strategy)\n        \n        wpds = np.zeros(len(cycle_types))\n        works = np.zeros(len(cycle_types))\n\n        # Initial error vector\n        m_vals = np.arange(p + 1, dtype=float)\n        e0 = (m_vals + 1) ** (-beta)\n        E0 = np.dot(e0, e0)\n\n        if E0 == 0:\n            final_results.append(0) # Default to V-cycle if no initial error\n            continue\n            \n        for i, cycle_type in enumerate(cycle_types):\n            W = model.calculate_work(p, 0, cycle_type)\n            works[i] = W\n\n            M = model.get_cycle_operator(p, 0, cycle_type)\n            e1 = M @ e0\n            E1 = np.dot(e1, e1)\n\n            r = E1 / E0\n\n            if r >= 1.0:\n                wpds[i] = np.inf\n            elif r = 0.0: # r can be numerically slightly negative due to precision\n                wpds[i] = 0.0\n            else:\n                wpds[i] = W / (-np.log10(r))\n        \n        # Determine the optimal cycle using specified tie-breaking rules\n        min_wpd = np.min(wpds)\n        candidate_indices = np.where(np.abs(wpds - min_wpd) = TOL)[0]\n\n        if len(candidate_indices) == 1:\n            best_idx = candidate_indices[0]\n        else:\n            candidate_works = works[candidate_indices]\n            min_work = np.min(candidate_works)\n            \n            sub_candidate_indices_local = np.where(np.abs(candidate_works - min_work) = TOL)[0]\n            \n            # Map local indices back to original cycle indices\n            final_candidates = candidate_indices[sub_candidate_indices_local]\n\n            # Final tie-break: choose the smallest index\n            best_idx = np.min(final_candidates)\n\n        final_results.append(int(best_idx))\n\n    # Format output string as specified\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```", "id": "3401572"}]}