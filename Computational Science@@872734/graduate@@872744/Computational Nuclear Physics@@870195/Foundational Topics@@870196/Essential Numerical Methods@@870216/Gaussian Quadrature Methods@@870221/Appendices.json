{"hands_on_practices": [{"introduction": "A common question in applying Discrete Variable Representation (DVR) methods is choosing the right quadrature grid. This first practice explores the fundamental choice between a grid that includes its endpoints (Gauss-Lobatto) and one that does not (Gauss-Legendre). By evaluating a representative Hartree-Fock-Bogoliubov (HFB) pairing integral, you will directly quantify how this seemingly small decision impacts convergence and accuracy for a smooth, physically relevant integrand [@problem_id:3561526].", "problem": "Consider the evaluation of the Hartree–Fock–Bogoliubov (HFB) pairing matrix element integral for spherically symmetric fields, given by the radial expression\n$$\nI \\equiv \\int_{0}^{\\infty} r^{2} \\, dr \\, u(r) \\, v(r) \\, \\Delta(r),\n$$\nwhere $u(r)$ and $v(r)$ are quasiparticle radial amplitudes and $\\Delta(r)$ is the pairing field. In many computational nuclear physics algorithms based on the Discrete Variable Representation (DVR), Gaussian quadrature methods are used to approximate such integrals on finite domains. Your task is to implement a program that compares the convergence of Gauss–Legendre versus Gauss–Lobatto DVR grids for this integral under a model that remains analytically tractable and physically plausible.\n\nUse the following model functions:\n- Define the quasiparticle amplitudes and pairing field by\n$$\nu(r) = r \\, \\exp\\!\\left(-\\frac{r^{2}}{2 b_{u}^{2}}\\right), \\quad\nv(r) = \\exp\\!\\left(-\\frac{r^{2}}{2 b_{v}^{2}}\\right), \\quad\n\\Delta(r) = \\Delta_{0} \\, \\exp\\!\\left(-\\frac{r^{2}}{2 a^{2}}\\right),\n$$\nwith parameters $a$, $b_{u}$, $b_{v}$ in femtometers and $\\Delta_{0}$ in mega-electron-volts. This choice yields an integrand that decays rapidly with $r$ and is smooth at $r=0$.\n\nYou will approximate the semi-infinite integral by truncating to a finite interval $[0,R]$ and applying Gaussian quadrature on the reference interval $[-1,1]$ via the affine mapping $r(x) = \\frac{R}{2} (x+1)$ and the Jacobian $dr = \\frac{R}{2} dx$. Two quadrature families must be implemented:\n- Gauss–Legendre (with $N$ nodes inside $(-1,1)$), which is exact for polynomials up to degree $2N-1$ with unit weight on $[-1,1]$.\n- Gauss–Lobatto (with $N$ nodes including endpoints $\\{-1,1\\}$ and $N-2$ interior nodes given by the zeros of $P_{N-1}'(x)$, where $P_{n}(x)$ is the Legendre polynomial of degree $n$), which is exact for polynomials up to degree $2N-3$ with unit weight on $[-1,1]$.\n\nStart from fundamental, well-tested bases:\n- Properties of Legendre polynomials, Gaussian quadrature exactness for polynomials with unit weight, and affine mappings of quadrature rules between intervals.\n- The integral identity for Laplace-type Gaussian integrals,\n$$\n\\int_{0}^{\\infty} r^{2n+1} e^{-\\alpha r^{2}} \\, dr = \\frac{n!}{2 \\alpha^{n+1}} \\quad \\text{for} \\quad \\alpha > 0 \\quad \\text{and integer} \\quad n \\ge 0,\n$$\nwhich follows from the definition of the Gamma function and a change of variables.\n\nTasks:\n1. Derive from first principles an exact analytic expression for $I$ in terms of $a$, $b_{u}$, $b_{v}$, and $\\Delta_{0}$, without invoking any specialized nuclear structure formulas.\n2. Implement two quadrature routines on $[-1,1]$: Gauss–Legendre and Gauss–Lobatto, both with unit weight. For Gauss–Lobatto with $N$ nodes, use the $N-2$ interior nodes given by the zeros of $P_{N-1}'(x)$ and the weights\n$$\nw_{i} = \\frac{2}{N(N-1)\\left[P_{N-1}(x_{i})\\right]^{2}} \\quad \\text{for interior nodes}, \\quad\nw_{\\text{end}} = \\frac{2}{N(N-1)} \\quad \\text{for} \\quad x=\\pm 1.\n$$\n3. Using the mapping $r = \\frac{R}{2}(x+1)$ and $dr = \\frac{R}{2} dx$, approximate\n$$\nI \\approx \\sum_{i=1}^{N} w_{i} \\, \\frac{R}{2} \\, \\left[r(x_{i})\\right]^{2} \\, u\\!\\left(r(x_{i})\\right) \\, v\\!\\left(r(x_{i})\\right) \\, \\Delta\\!\\left(r(x_{i})\\right).\n$$\nChoose $R$ large enough that the truncation error relative to the exact semi-infinite integral is negligible on the provided test suite.\n\nTest suite and parameters:\n- The program must evaluate the absolute relative errors for both quadrature families, defined by\n$$\n\\varepsilon_{\\mathrm{GL}}(N) = \\frac{\\left| I_{\\mathrm{GL}}^{(N)} - I_{\\text{exact}} \\right|}{\\left| I_{\\text{exact}} \\right|}, \\quad\n\\varepsilon_{\\mathrm{GLL}}(N) = \\frac{\\left| I_{\\mathrm{GLL}}^{(N)} - I_{\\text{exact}} \\right|}{\\left| I_{\\text{exact}} \\right|}.\n$$\n- Use the following three parameter sets $(a, b_{u}, b_{v}, \\Delta_{0}, R)$, with $a$, $b_{u}$, $b_{v}$, $R$ in femtometers and $\\Delta_{0}$ in mega-electron-volts:\n  1. $(a, b_{u}, b_{v}, \\Delta_{0}, R) = (2.5, 2.0, 2.0, 1.2, 12.0)$.\n  2. $(a, b_{u}, b_{v}, \\Delta_{0}, R) = (1.8, 1.2, 2.8, 0.8, 12.0)$.\n  3. $(a, b_{u}, b_{v}, \\Delta_{0}, R) = (0.8, 0.8, 0.8, 2.0, 8.0)$.\n- For each parameter set, compute errors for $N \\in \\{8, 16, 24, 32\\}$.\n\nFinal output format:\n- Your program should produce a single line of output containing a flat, comma-separated list of floats enclosed in square brackets. The order must be, for each parameter set in the order of listing and for each $N$ in ascending order, first the Gauss–Legendre error and then the Gauss–Lobatto error:\n$$\n\\left[ \\varepsilon_{\\mathrm{GL}}^{(1)}(8), \\varepsilon_{\\mathrm{GLL}}^{(1)}(8), \\varepsilon_{\\mathrm{GL}}^{(1)}(16), \\varepsilon_{\\mathrm{GLL}}^{(1)}(16), \\ldots, \\varepsilon_{\\mathrm{GL}}^{(1)}(32), \\varepsilon_{\\mathrm{GLL}}^{(1)}(32), \\varepsilon_{\\mathrm{GL}}^{(2)}(8), \\ldots, \\varepsilon_{\\mathrm{GLL}}^{(3)}(32) \\right].\n$$\n- Each entry is a dimensionless decimal. The list must contain exactly $24$ numbers.\n\nScientific realism and constraints:\n- All scenarios are smooth, rapidly decaying, and numerically stable for the given $R$. Use double-precision floating point arithmetic.\n- Angles do not appear; thus no angle unit is required. Since the required outputs are relative errors, no physical units appear in the final output.", "solution": "We begin from the definitions of the model functions\n$$\nu(r) = r \\, \\exp\\!\\left(-\\frac{r^{2}}{2 b_{u}^{2}}\\right), \\quad\nv(r) = \\exp\\!\\left(-\\frac{r^{2}}{2 b_{v}^{2}}\\right), \\quad\n\\Delta(r) = \\Delta_{0} \\, \\exp\\!\\left(-\\frac{r^{2}}{2 a^{2}}\\right),\n$$\nand the HFB pairing matrix element integral\n$$\nI = \\int_{0}^{\\infty} r^{2} \\, dr \\, u(r) \\, v(r) \\, \\Delta(r).\n$$\nSubstituting $u(r)$, $v(r)$, and $\\Delta(r)$ gives\n$$\nI = \\int_{0}^{\\infty} r^{2} \\, dr \\, \\left[r \\, e^{-r^{2}/(2 b_{u}^{2})}\\right] \\, \\left[e^{-r^{2}/(2 b_{v}^{2})}\\right] \\, \\left[\\Delta_{0} \\, e^{-r^{2}/(2 a^{2})}\\right]\n= \\Delta_{0} \\int_{0}^{\\infty} r^{3} \\, \\exp\\!\\left[-\\left(\\frac{1}{2 b_{u}^{2}} + \\frac{1}{2 b_{v}^{2}} + \\frac{1}{2 a^{2}}\\right) r^{2}\\right] dr.\n$$\nDefine\n$$\n\\alpha \\equiv \\frac{1}{2} \\left( \\frac{1}{b_{u}^{2}} + \\frac{1}{b_{v}^{2}} + \\frac{1}{a^{2}} \\right),\n$$\nwith $\\alpha > 0$ for positive $a$, $b_{u}$, $b_{v}$. Then\n$$\nI = \\Delta_{0} \\int_{0}^{\\infty} r^{3} e^{-\\alpha r^{2}} dr.\n$$\nTo compute this exactly, start from the well-tested identity for Gaussian moments,\n$$\n\\int_{0}^{\\infty} r^{2n+1} e^{-\\alpha r^{2}} dr = \\frac{n!}{2 \\alpha^{n+1}}, \\quad \\alpha > 0, \\quad n \\in \\mathbb{Z}_{\\ge 0}.\n$$\nThis is derived by substituting $t = \\alpha r^{2}$, $dt = 2 \\alpha r \\, dr$, so that $r^{2n+1} dr = \\frac{1}{2 \\alpha^{n+1}} t^{n} dt$, hence\n$$\n\\int_{0}^{\\infty} r^{2n+1} e^{-\\alpha r^{2}} dr = \\frac{1}{2 \\alpha^{n+1}} \\int_{0}^{\\infty} t^{n} e^{-t} dt = \\frac{\\Gamma(n+1)}{2 \\alpha^{n+1}} = \\frac{n!}{2 \\alpha^{n+1}}.\n$$\nFor $n=1$ we obtain\n$$\n\\int_{0}^{\\infty} r^{3} e^{-\\alpha r^{2}} dr = \\frac{1}{2 \\alpha^{2}}.\n$$\nTherefore, the exact analytic value is\n$$\nI_{\\text{exact}} = \\Delta_{0} \\cdot \\frac{1}{2 \\alpha^{2}} = \\frac{\\Delta_{0}}{2 \\alpha^{2}}.\n$$\n\nNext, we design the quadrature algorithms. Gaussian quadrature on $[-1,1]$ with unit weight approximates\n$$\n\\int_{-1}^{1} g(x) \\, dx \\approx \\sum_{i=1}^{N} w_{i} \\, g(x_{i}).\n$$\n- For Gauss–Legendre, nodes $\\{x_{i}\\}$ are the $N$ zeros of $P_{N}(x)$, and weights $\\{w_{i}\\}$ are chosen to achieve exactness for polynomials up to degree $2N-1$.\n- For Gauss–Lobatto, nodes include endpoints $x=\\pm 1$, with the $N-2$ interior nodes being the zeros of $P_{N-1}'(x)$. The weights are\n$$\nw_{\\text{end}} = \\frac{2}{N(N-1)}, \\quad\nw_{i} = \\frac{2}{N(N-1)\\left[P_{N-1}(x_{i})\\right]^{2}} \\quad \\text{for interior nodes}.\n$$\nThis rule is exact for polynomials up to degree $2N-3$.\n\nWe wish to approximate\n$$\nI = \\int_{0}^{\\infty} r^{2} dr \\, u(r) v(r) \\Delta(r).\n$$\nWe truncate to $[0,R]$ and use the affine mapping $r(x) = \\frac{R}{2}(x+1)$, $dr = \\frac{R}{2} dx$, so that\n$$\nI \\approx \\int_{-1}^{1} \\left[ \\left( r(x) \\right)^{2} u(r(x)) v(r(x)) \\Delta(r(x)) \\right] \\left( \\frac{R}{2} \\right) dx.\n$$\nThus the quadrature approximation reads\n$$\nI^{(N)} \\approx \\sum_{i=1}^{N} w_{i} \\left( \\frac{R}{2} \\right) \\left[ r(x_{i}) \\right]^{2} u\\!\\left(r(x_{i})\\right) v\\!\\left(r(x_{i})\\right) \\Delta\\!\\left(r(x_{i})\\right).\n$$\nWith our Gaussian model, choosing $R$ such that $R \\gg a$, $b_{u}$, $b_{v}$ ensures negligible truncation error because the integrand behaves as $r^{3} e^{-\\alpha r^{2}}$ with $\\alpha > 0$, making the tail $\\int_{R}^{\\infty}$ exponentially small.\n\nAlgorithmic steps:\n1. For given $(a, b_{u}, b_{v}, \\Delta_{0})$, compute $\\alpha = \\frac{1}{2}\\left( b_{u}^{-2} + b_{v}^{-2} + a^{-2} \\right)$ and then $I_{\\text{exact}} = \\Delta_{0}/(2 \\alpha^{2})$.\n2. For each $N$ and each quadrature family, compute nodes $\\{x_{i}\\}$ and weights $\\{w_{i}\\}$ on $[-1,1]$. For Gauss–Legendre, use a standard routine constructing zeros of $P_{N}$ and weights. For Gauss–Lobatto, construct $P_{N-1}(x)$, find the roots of $P_{N-1}'(x)$ for interior nodes, and use the stated formula for weights including the endpoints $x=\\pm 1$.\n3. Map to $r_{i} = \\frac{R}{2}(x_{i}+1)$ and evaluate the integrand\n$$\nf(r) = r^{2} \\, u(r) \\, v(r) \\, \\Delta(r) = \\Delta_{0} \\, r^{3} \\, \\exp\\!\\left[-\\left(\\frac{1}{2 b_{u}^{2}} + \\frac{1}{2 b_{v}^{2}} + \\frac{1}{2 a^{2}}\\right) r^{2}\\right].\n$$\n4. Form the quadrature sum\n$$\nI_{\\mathrm{GL}}^{(N)} = \\sum_{i=1}^{N} w_{i}^{\\mathrm{GL}} \\left( \\frac{R}{2} \\right) f\\!\\left( r(x_{i}^{\\mathrm{GL}}) \\right), \\quad\nI_{\\mathrm{GLL}}^{(N)} = \\sum_{i=1}^{N} w_{i}^{\\mathrm{GLL}} \\left( \\frac{R}{2} \\right) f\\!\\left( r(x_{i}^{\\mathrm{GLL}}) \\right).\n$$\n5. Compute the absolute relative errors\n$$\n\\varepsilon_{\\mathrm{GL}}(N) = \\frac{| I_{\\mathrm{GL}}^{(N)} - I_{\\text{exact}} |}{| I_{\\text{exact}} |}, \\quad\n\\varepsilon_{\\mathrm{GLL}}(N) = \\frac{| I_{\\mathrm{GLL}}^{(N)} - I_{\\text{exact}} |}{| I_{\\text{exact}} |}.\n$$\n\nConvergence discussion:\n- Both Gauss–Legendre and Gauss–Lobatto are spectrally accurate for analytic integrands on $[-1,1]$, meaning errors decrease faster than any power of $N$. However, Gauss–Legendre achieves a higher exactness degree ($2N-1$) than Gauss–Lobatto ($2N-3$) for polynomials, and its interior nodes avoid endpoints, which often leads to smaller constants in the asymptotic error for smooth integrands without endpoint singularities. In this model, the mapped integrand is smooth and vanishes at the left endpoint because $f(r) \\sim r^{3}$ as $r \\to 0$, and is exponentially small at $r=R$. Consequently, Gauss–Legendre is expected to converge slightly faster at fixed $N$, though Gauss–Lobatto remains highly accurate. The numerical results across the test suite quantify this impact through the reported $\\varepsilon_{\\mathrm{GL}}(N)$ and $\\varepsilon_{\\mathrm{GLL}}(N)$ values.\n\nTest suite implementation details:\n- Parameter sets:\n  1. $(a, b_{u}, b_{v}, \\Delta_{0}, R) = (2.5, 2.0, 2.0, 1.2, 12.0)$.\n  2. $(a, b_{u}, b_{v}, \\Delta_{0}, R) = (1.8, 1.2, 2.8, 0.8, 12.0)$.\n  3. $(a, b_{u}, b_{v}, \\Delta_{0}, R) = (0.8, 0.8, 0.8, 2.0, 8.0)$.\n- Node counts per case: $N \\in \\{8, 16, 24, 32\\}$.\n- Output: a flat list of $24$ floats, ordered for each case and each $N$ as $\\varepsilon_{\\mathrm{GL}}(N)$, then $\\varepsilon_{\\mathrm{GLL}}(N)$.\n\nThis approach fully isolates the effect of Gauss–Lobatto versus Gauss–Legendre DVR grids on the convergence behavior for a smooth, nuclear-physics-motivated pairing matrix element, while maintaining an analytic reference for quantitative error assessment.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef gauss_legendre(n: int):\n    \"\"\"\n    Return nodes and weights for Gauss–Legendre quadrature on [-1, 1].\n    \"\"\"\n    x, w = np.polynomial.legendre.leggauss(n)\n    return x, w\n\ndef gauss_lobatto(n: int):\n    \"\"\"\n    Return nodes and weights for Gauss–Lobatto quadrature on [-1, 1] with unit weight.\n    Nodes include endpoints -1 and 1; interior nodes are roots of P_{n-1}'(x).\n    Weights:\n        w_end = 2/(n*(n-1)),\n        w_i = 2/(n*(n-1)*[P_{n-1}(x_i)]^2) for interior nodes.\n    \"\"\"\n    if n < 2:\n        raise ValueError(\"Gauss–Lobatto requires n >= 2.\")\n    # Construct Legendre polynomial P_{n-1}\n    P = np.polynomial.legendre.Legendre.basis(n - 1)\n    dP = P.deriv()\n    # Interior nodes are roots of derivative\n    if n == 2:\n        interior = np.array([], dtype=float)\n    else:\n        interior = dP.roots()\n        interior.sort()\n    nodes = np.concatenate((np.array([-1.0]), interior, np.array([1.0])))\n    weights = np.empty_like(nodes)\n    w_end = 2.0 / (n * (n - 1))\n    weights[0] = w_end\n    weights[-1] = w_end\n    # Interior weights\n    for i in range(1, len(nodes) - 1):\n        xi = nodes[i]\n        Pi = P(xi)\n        weights[i] = 2.0 / (n * (n - 1) * (Pi * Pi))\n    return nodes, weights\n\ndef map_to_radius(x, R):\n    \"\"\"\n    Affine map from x in [-1,1] to r in [0, R].\n    r = (R/2)*(x + 1)\n    \"\"\"\n    return 0.5 * R * (x + 1.0)\n\ndef integrand_r(r, a, bu, bv, Delta0):\n    \"\"\"\n    f(r) = r^2 * u(r) * v(r) * Delta(r)\n         = Delta0 * r^3 * exp(-r^2/2 * (1/bu^2 + 1/bv^2 + 1/a^2))\n    \"\"\"\n    inv_bu2 = 1.0 / (bu * bu)\n    inv_bv2 = 1.0 / (bv * bv)\n    inv_a2 = 1.0 / (a * a)\n    expo = -0.5 * (inv_bu2 + inv_bv2 + inv_a2) * (r * r)\n    return Delta0 * (r ** 3) * np.exp(expo)\n\ndef exact_integral(a, bu, bv, Delta0):\n    \"\"\"\n    I_exact = Delta0 * integral_0^inf r^3 exp(-alpha * r^2) dr\n            = Delta0 * (1 / (2 * alpha^2))\n    where alpha = 0.5 * (1/bu^2 + 1/bv^2 + 1/a^2).\n    \"\"\"\n    inv_bu2 = 1.0 / (bu * bu)\n    inv_bv2 = 1.0 / (bv * bv)\n    inv_a2 = 1.0 / (a * a)\n    alpha = 0.5 * (inv_bu2 + inv_bv2 + inv_a2)\n    return Delta0 / (2.0 * alpha * alpha)\n\ndef quadrature_integral(method, N, a, bu, bv, Delta0, R):\n    \"\"\"\n    Compute the quadrature approximation on [0, R] via mapping from [-1,1].\n    method: 'GL' or 'GLL'\n    \"\"\"\n    if method == 'GL':\n        x, w = gauss_legendre(N)\n    elif method == 'GLL':\n        x, w = gauss_lobatto(N)\n    else:\n        raise ValueError(\"Unknown method\")\n    r = map_to_radius(x, R)\n    drdx = 0.5 * R\n    f = integrand_r(r, a, bu, bv, Delta0)\n    return np.sum(w * drdx * f)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case: (a, bu, bv, Delta0, R)\n    test_cases = [\n        (2.5, 2.0, 2.0, 1.2, 12.0),\n        (1.8, 1.2, 2.8, 0.8, 12.0),\n        (0.8, 0.8, 0.8, 2.0, 8.0),\n    ]\n    Ns = [8, 16, 24, 32]\n\n    results = []\n    for (a, bu, bv, Delta0, R) in test_cases:\n        I_exact = exact_integral(a, bu, bv, Delta0)\n        for N in Ns:\n            I_GL = quadrature_integral('GL', N, a, bu, bv, Delta0, R)\n            I_GLL = quadrature_integral('GLL', N, a, bu, bv, Delta0, R)\n            err_GL = abs(I_GL - I_exact) / abs(I_exact)\n            err_GLL = abs(I_GLL - I_exact) / abs(I_exact)\n            results.append(err_GL)\n            results.append(err_GLL)\n\n    # Final print statement in the exact required format.\n    # Format with scientific notation for clarity and reproducibility.\n    formatted = \",\".join(f\"{x:.12e}\" for x in results)\n    print(f\"[{formatted}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3561526"}, {"introduction": "Nuclear physics calculations often involve momentum-space integrals spanning many orders of magnitude, a classic multi-scale challenge. This exercise demonstrates a powerful technique for adapting Gaussian quadrature to such problems by using a logarithmic change of variables, which distributes nodes efficiently across all momentum decades. You will not only compare the accuracy of this log-mapped quadrature to a standard linear grid but also analyze its superior numerical stability for stiff integrands [@problem_id:3561470].", "problem": "Consider momentum-space integrals that arise in computational nuclear physics, where a typical Three-Dimensional (3D) radial momentum integral reduces to a one-dimensional integral of the form $\\int f(p)\\,dp$ over a wide dynamic range of momenta. To resolve stiffness across decades, a logarithmic mapping $x=\\log p$ is used so that the quadrature proceeds in the variable $x$. Starting from the change-of-variables theorem and the core definition of Gaussian quadrature (without assuming any specialized formula beyond the mapping and the linear interval transformation for Gaussian quadrature on $[-1,1]$), derive the transformation of Gaussian nodes and weights when passing from the $p$-domain with $p\\in[10^{-3}\\Lambda,10^{3}\\Lambda]$ to the $x$-domain with $x\\in[\\log(10^{-3}\\Lambda),\\log(10^{3}\\Lambda)]$ under the mapping $x=\\log p$. The argument of the logarithm must be dimensionless; therefore, work in units where momenta are scaled by a fixed reference scale $\\Lambda$ and define the dimensionless momentum $q=p/\\Lambda$, so that $q\\in[10^{-3},10^{3}]$ and $x=\\log q$.\n\nYour task is to implement Gaussian quadrature with and without the logarithmic mapping for a set of stiff test integrands representative of momentum kernels, and to assess stability. Use the following foundational base:\n- The change-of-variables theorem for integrals: if $q=\\phi(x)$ is a differentiable bijection on $[a,b]$ then $\\int_{q(a)}^{q(b)} f(q)\\,dq=\\int_{a}^{b} f(\\phi(x))\\,\\phi'(x)\\,dx$.\n- The definition of Gauss-Legendre quadrature on $[-1,1]$: for a sufficiently smooth function $g(x)$, $\\int_{-1}^{1} g(x)\\,dx\\approx\\sum_{i=1}^{N} w_i\\,g(t_i)$, where $t_i$ and $w_i$ are the Gauss-Legendre nodes and weights, and the linear mapping transfers this quadrature to any finite interval.\n\nFormulate the quadrature after mapping $x=\\log q$ for integrals of the form $\\int_{10^{-3}}^{10^{3}} f(q)\\,dq$ and discuss how the transformed weights depend on $x$. Define a numerical stability metric for a given quadrature evaluation as the ratio\n$$\nR=\\frac{\\max_i \\left|c_i\\right|}{\\sum_{j} \\left|c_j\\right|},\n$$\nwhere $c_i$ are the individual weighted contributions of each node to the quadrature sum. Explain how $R$ reflects dominance by a small number of nodes and how this relates to stiffness. Design and implement a numerically stable summation strategy.\n\nImplement two quadrature schemes:\n- Direct Gauss-Legendre on $q\\in[10^{-3},10^{3}]$.\n- Log-mapped Gauss-Legendre via $x=\\log q$ on $x\\in[\\log 10^{-3},\\log 10^{3}]$.\n\nUse $N=64$ nodes for both schemes. For a high-accuracy reference, use an adaptive integrator to compute $\\int_{10^{-3}}^{10^{3}} f(q)\\,dq$ with tight tolerances.\n\nTest Suite:\nWork with the following dimensionless integrands $f(q)$ on $q\\in[10^{-3},10^{3}]$, chosen to exercise a variety of stiffness characteristics. All results are dimensionless, so no physical units are required.\n1. Happy path (regulated bulk): $f_1(q)=q^2\\,e^{-q^2}$.\n2. Narrow localized peak near $q=1$: with $\\gamma=10^{-3}$, $f_2(q)=\\dfrac{q^2\\,e^{-q^2}}{(q-1)^2+\\gamma^2}$.\n3. Heavy-tail suppression: $f_3(q)=\\dfrac{q^2}{1+q^8}$.\n4. Edge-localized near the lower boundary: with $\\gamma=10^{-4}$, $f_4(q)=\\dfrac{q^2}{(q-10^{-3})^2+\\gamma^2}$.\n5. Edge-localized near the upper boundary: with $\\gamma=1$, $f_5(q)=\\dfrac{q^2}{(q-10^{3})^2+\\gamma^2}$.\n\nFor each $f_k$, compute:\n- The relative error of the log-mapped quadrature, $E^{\\mathrm{log}}_k=\\left|\\dfrac{I^{\\mathrm{log}}_k-I^{\\mathrm{ref}}_k}{I^{\\mathrm{ref}}_k}\\right|$, where $I^{\\mathrm{log}}_k$ is the $N=64$ log-mapped Gauss-Legendre estimate and $I^{\\mathrm{ref}}_k$ is the high-accuracy reference.\n- The relative error of the direct quadrature on $q$, $E^{\\mathrm{dir}}_k=\\left|\\dfrac{I^{\\mathrm{dir}}_k-I^{\\mathrm{ref}}_k}{I^{\\mathrm{ref}}_k}\\right|$.\n- The stability metric $R^{\\mathrm{log}}_k$ using the log-mapped contributions.\n- The stability metric $R^{\\mathrm{dir}}_k$ using the direct contributions.\n\nNumerical summations must employ a compensation method to reduce round-off error. Express all angles, if any occur, in radians; none of the test functions involve angles. All outputs are dimensionless real numbers. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as\n$$\n\\left[ E^{\\mathrm{log}}_1,E^{\\mathrm{dir}}_1,R^{\\mathrm{log}}_1,R^{\\mathrm{dir}}_1,\\;E^{\\mathrm{log}}_2,E^{\\mathrm{dir}}_2,R^{\\mathrm{log}}_2,R^{\\mathrm{dir}}_2,\\;\\dots,\\;E^{\\mathrm{log}}_5,E^{\\mathrm{dir}}_5,R^{\\mathrm{log}}_5,R^{\\mathrm{dir}}_5\\right].\n$$\nEach entry must be printed as a decimal floating-point number. Use at least $N=64$ Gauss-Legendre nodes for both quadrature schemes and tight absolute and relative tolerances for the reference integration.\n\nYour derivation and implementation must be grounded in the change-of-variables theorem and the definition of Gaussian quadrature. Do not provide shortcut formulas; show how the transformed weights and nodes arise from first principles, and analyze how the stability metric captures stiffness in the quadrature sum.", "solution": "The problem requires the derivation and implementation of two Gaussian quadrature schemes for momentum-space integrals on a wide logarithmic scale, and an analysis of their numerical stability. We begin by deriving the quadrature formulas from first principles, as stipulated.\n\nLet the integral of interest be $I = \\int_{q_a}^{q_b} f(q) dq$, where the integration domain is $[q_a, q_b] = [10^{-3}, 10^{3}]$ for the dimensionless momentum $q$. The foundation for both schemes is the $N$-point Gauss-Legendre quadrature rule on the canonical interval $[-1, 1]$:\n$$\n\\int_{-1}^{1} g(t)\\,dt \\approx \\sum_{i=1}^{N} w_i^{\\text{std}} g(t_i^{\\text{std}})\n$$\nwhere $t_i^{\\text{std}}$ are the nodes (zeros of the $N$-th Legendre polynomial) and $w_i^{\\text{std}}$ are the corresponding weights.\n\n**1. Direct Gauss-Legendre Quadrature on $q \\in [q_a, q_b]$**\n\nTo apply Gaussian quadrature to the interval $[q_a, q_b]$, we introduce a linear transformation that maps the canonical variable $t \\in [-1, 1]$ to the physical variable $q \\in [q_a, q_b]$. Let this mapping be $q(t) = c_1 t + c_0$. The boundary conditions $q(-1) = q_a$ and $q(1) = q_b$ determine the constants:\n$$\n-c_1 + c_0 = q_a \\quad \\text{and} \\quad c_1 + c_0 = q_b\n$$\nSolving this system yields $c_1 = \\frac{q_b - q_a}{2}$ and $c_0 = \\frac{q_b + q_a}{2}$. The transformation is:\n$$\nq(t) = \\frac{q_b - q_a}{2}t + \\frac{q_b + q_a}{2}\n$$\nThe differential element transforms as $dq = \\frac{dq}{dt}dt = \\frac{q_b - q_a}{2}dt$. Substituting this into the original integral, we obtain an integral over the canonical interval $[-1, 1]$:\n$$\nI = \\int_{q_a}^{q_b} f(q)\\,dq = \\int_{-1}^{1} f(q(t)) \\frac{dq}{dt}\\,dt = \\int_{-1}^{1} f\\left(\\frac{q_b - q_a}{2}t + \\frac{q_b + q_a}{2}\\right) \\frac{q_b - q_a}{2}\\,dt\n$$\nApplying the Gauss-Legendre rule, the integral is approximated by the sum:\n$$\nI^{\\text{dir}} \\approx \\sum_{i=1}^{N} w_i^{\\text{std}} \\left[ f\\left(\\frac{q_b - q_a}{2}t_i^{\\text{std}} + \\frac{q_b + q_a}{2}\\right) \\right] \\left( \\frac{q_b - q_a}{2} \\right)\n$$\nThis can be expressed as a standard quadrature sum $I^{\\text{dir}} = \\sum_{i=1}^{N} w_i^{\\text{dir}}f(q_i)$, where the nodes $q_i$ and weights $w_i^{\\text{dir}}$ in the $q$-domain are:\n$$\nq_i = \\frac{q_b - q_a}{2}t_i^{\\text{std}} + \\frac{q_b + q_a}{2}\n$$\n$$\nw_i^{\\text{dir}} = w_i^{\\text{std}} \\left( \\frac{q_b - q_a}{2} \\right)\n$$\nThe individual contributions to the sum are $c_i^{\\text{dir}} = w_i^{\\text{dir}}f(q_i)$.\n\n**2. Log-Mapped Gauss-Legendre Quadrature**\n\nFor integrals over a wide dynamic range, a logarithmic change of variables is often advantageous. We apply the mapping $x = \\log q$, which implies $q = e^x$. The differential transforms as $dq = e^x dx$. The integration limits in the new variable $x$ become $x_a = \\log q_a$ and $x_b = \\log q_b$.\nThe integral transforms according to the change-of-variables theorem:\n$$\nI = \\int_{q_a}^{q_b} f(q)\\,dq = \\int_{x_a}^{x_b} f(e^x)e^x\\,dx\n$$\nLet us define the transformed integrand as $G(x) = f(e^x)e^x$. The problem is now to evaluate $I = \\int_{x_a}^{x_b} G(x)\\,dx$. We again use a linear mapping from the canonical interval $t \\in [-1, 1]$ to the $x$-domain interval $[x_a, x_b]$:\n$$\nx(t) = \\frac{x_b - x_a}{2}t + \\frac{x_b + x_a}{2}\n$$\nThe differential is $dx = \\frac{x_b - x_a}{2}dt$. The integral becomes:\n$$\nI = \\int_{-1}^{1} G(x(t)) \\frac{dx}{dt}\\,dt = \\int_{-1}^{1} G\\left(\\frac{x_b - x_a}{2}t + \\frac{x_b + x_a}{2}\\right) \\frac{x_b - x_a}{2}\\,dt\n$$\nApplying the Gauss-Legendre rule yields the approximation:\n$$\nI^{\\text{log}} \\approx \\sum_{i=1}^{N} w_i^{\\text{std}} \\left[ G\\left(\\frac{x_b - x_a}{2}t_i^{\\text{std}} + \\frac{x_b + x_a}{2}\\right) \\right] \\left( \\frac{x_b - x_a}{2} \\right)\n$$\nTo interpret this in terms of the original integrand $f(q)$, we substitute back $G(x) = f(e^x)e^x$. The nodes in the $x$-domain are $x_i = \\frac{x_b - x_a}{2}t_i^{\\text{std}} + \\frac{x_b + x_a}{2}$. The corresponding nodes in the original $q$-domain are $q_i = e^{x_i}$. The quadrature sum is:\n$$\nI^{\\text{log}} = \\sum_{i=1}^{N} w_i^{\\text{std}} \\left[ f(e^{x_i})e^{x_i} \\right] \\left( \\frac{x_b - x_a}{2} \\right) = \\sum_{i=1}^{N} w_i^{\\text{std}} \\left[ f(q_i) q_i \\right] \\left( \\frac{\\log q_b - \\log q_a}{2} \\right)\n$$\nThis can be written as a sum of the form $I^{\\text{log}} = \\sum_{i=1}^{N} w_i^{\\text{log}}f(q_i)$, where the effective weights $w_i^{\\text{log}}$ in the $q$-domain are:\n$$\nw_i^{\\text{log}} = w_i^{\\text{std}} \\cdot q_i \\cdot \\left( \\frac{\\log q_b - \\log q_a}{2} \\right)\n$$\nThe individual contributions are $c_i^{\\text{log}} = w_i^{\\log}f(q_i)$. Unlike the direct method, these effective weights are not constant; they are proportional to the node location $q_i$. This means that nodes at larger momenta are given more weight, which counteracts the $1/q$ density with which the nodes $q_i=e^{x_i}$ are distributed.\n\n**3. Numerical Stability Metric and Stiffness**\n\nThe stability metric is defined as $R = \\frac{\\max_i |c_i|}{\\sum_j |c_j|}$, where $c_i$ are the weighted contributions $w_i f(q_i)$ from each node. This metric quantifies the uniformity of the contributions to the integral's total value.\n- A small value of $R$ (approaching the ideal value of $1/N$) indicates that many nodes contribute significantly to the sum. The quadrature is stable, as the result is an average over many points, making it robust against small errors in function evaluation or node placement.\n- A large value of $R$ (approaching $1$) signifies that the sum is dominated by a single contribution. The integral is effectively approximated by one point, $I \\approx c_k = w_k f(q_k)$. This signals a \"stiff\" problem for the chosen quadrature scheme. The result is numerically unstable: it is highly sensitive to the precise location of the dominant node $q_k$ and prone to large truncation error because the quadrature grid fails to resolve the structure of the integrand. Such dominance often occurs when the integrand has a sharp, narrow peak that is missed by most nodes.\n\nThe direct quadrature distributes nodes with a density that is approximately uniform near the center of $[q_a, q_b]$ and increases towards the endpoints. If the integrand has features localized on a logarithmic scale (e.g., a sharp peak at small $q$ or a heavy tail over many decades), this linear node placement is inefficient. It may allocate too few nodes to the region of interest, leading to a large stability metric $R^{\\text{dir}}$ and poor accuracy.\n\nThe log-mapped quadrature distributes nodes $q_i=e^{x_i}$ such that the number of nodes per decade of momentum is constant. This is highly effective for integrands with multi-scale behavior, sharp features at low momentum, or power-law tails. By changing variables, the integrand is often transformed into a smoother function in the new coordinate $x$, for which standard Gauss-Legendre quadrature is very efficient. This results in more evenly distributed contributions $|c_i^{\\text{log}}|$ and hence a smaller, more desirable stability metric $R^{\\text{log}}$.\n\nTo ensure accurate summation, especially when contributions $c_i$ vary over many orders of magnitude, a compensated summation algorithm (like Kahan summation) is required to mitigate the loss of precision from floating-point round-off errors.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import quad\n\ndef solve():\n    \"\"\"\n    Derives, implements, and compares direct and log-mapped Gaussian quadrature\n    for stiff integrands in computational physics.\n    \"\"\"\n\n    def kahan_sum(arr):\n        \"\"\"Numerically stable summation using the Kahan algorithm.\"\"\"\n        s = 0.0\n        c = 0.0\n        for x in arr:\n            y = x - c\n            t = s + y\n            c = (t - s) - y\n            s = t\n        return s\n\n    # Problem Parameters\n    N = 64\n    q_min, q_max = 1e-3, 1e3\n    \n    # Test suite of integrands\n    gamma2 = 1e-3\n    gamma4 = 1e-4\n    gamma5 = 1.0\n\n    functions = [\n        (\"f1\", lambda q: q**2 * np.exp(-q**2)),\n        (\"f2\", lambda q: (q**2 * np.exp(-q**2)) / ((q - 1.0)**2 + gamma2**2)),\n        (\"f3\", lambda q: q**2 / (1.0 + q**8)),\n        (\"f4\", lambda q: q**2 / ((q - q_min)**2 + gamma4**2)),\n        (\"f5\", lambda q: q**2 / ((q - q_max)**2 + gamma5**2)),\n    ]\n\n    # Standard Gauss-Legendre nodes and weights on [-1, 1]\n    t_std, w_std = np.polynomial.legendre.leggauss(N)\n\n    # --- Direct Gauss-Legendre Quadrature Setup ---\n    # Linear mapping t -> q\n    # q(t) = a*t + b, where a = (q_max-q_min)/2, b = (q_max+q_min)/2\n    a_q = 0.5 * (q_max - q_min)\n    b_q = 0.5 * (q_max + q_min)\n    q_nodes_dir = a_q * t_std + b_q\n    w_dir = a_q * w_std\n\n    # --- Log-Mapped Gauss-Legendre Quadrature Setup ---\n    x_min, x_max = np.log(q_min), np.log(q_max)\n    # Linear mapping t -> x\n    # x(t) = a*t + b, where a = (x_max-x_min)/2, b = (x_max+x_min)/2\n    a_x = 0.5 * (x_max - x_min)\n    b_x = 0.5 * (x_max + x_min)\n    x_nodes = a_x * t_std + b_x\n    q_nodes_log = np.exp(x_nodes)\n    \n    # Effective weights in q-space for log mapping\n    # w_log_i = w_std_i * q_i * (x_max - x_min) / 2\n    w_log_factor = a_x\n    w_log = w_std * q_nodes_log * w_log_factor\n\n    results = []\n\n    for name, f in functions:\n        # 1. High-accuracy reference integral\n        i_ref, _ = quad(f, q_min, q_max, epsabs=1e-15, epsrel=1e-15, limit=200)\n\n        # 2. Direct Quadrature\n        f_vals_dir = f(q_nodes_dir)\n        contributions_dir = w_dir * f_vals_dir\n        i_dir = kahan_sum(contributions_dir)\n        \n        abs_contributions_dir = np.abs(contributions_dir)\n        r_dir = np.max(abs_contributions_dir) / kahan_sum(abs_contributions_dir)\n        e_dir = np.abs((i_dir - i_ref) / i_ref) if i_ref != 0 else 0.0\n\n        # 3. Log-Mapped Quadrature\n        f_vals_log = f(q_nodes_log)\n        contributions_log = w_log * f_vals_log\n        i_log = kahan_sum(contributions_log)\n\n        abs_contributions_log = np.abs(contributions_log)\n        r_log = np.max(abs_contributions_log) / kahan_sum(abs_contributions_log)\n        e_log = np.abs((i_log - i_ref) / i_ref) if i_ref != 0 else 0.0\n\n        results.extend([e_log, e_dir, r_log, r_dir])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3561470"}, {"introduction": "The ultimate power of Gaussian quadrature lies in its customizability to the unique structure of a problem. In this advanced practice, you will engineer a bespoke quadrature rule to handle the sharp, non-analytic behavior of cross-sections near a reaction threshold. By implementing a carefully chosen exponential change of variables, you will learn to concentrate quadrature points precisely where they are needed most, a method that dramatically boosts accuracy beyond what standard rules can offer [@problem_id:3561465].", "problem": "You are tasked with constructing and testing a Gaussian quadrature rule that exponentially clusters nodes near $x=1$ to resolve threshold behavior typical of breakup cross sections in computational nuclear physics. Near threshold, the cross section often behaves as $\\sigma(E) \\sim (E - E_{\\text{th}})^{\\nu}$ with exponent $\\nu$, where $E_{\\text{th}}$ is the threshold energy and $\\nu > -1$ ensures integrability. After linear rescaling of energy to a dimensionless variable $x \\in [0,1]$ such that $x=1$ corresponds to $E=E_{\\text{th}}$, the threshold behavior becomes $\\sigma(x) \\propto (1-x)^{\\nu}$. Your task is to design a Gaussian quadrature on $[0,1]$ that clusters nodes near $x=1$ using an exponential change of variables, and to quantify the accuracy of extracting $\\nu$ from integral representations of the form of moments.\n\nFundamental base: Use the definition of Gaussian quadrature on $[-1,1]$, the change-of-variables theorem for integrals, and the Beta function identity for exact moments. Specifically, for any sufficiently smooth $f(x)$ on $[a,b]$, a Gaussian quadrature with $N$ nodes $\\{x_i\\}_{i=1}^N$ and weights $\\{w_i\\}_{i=1}^N$ approximates\n$$\n\\int_a^b f(x)\\,dx \\approx \\sum_{i=1}^N w_i f(x_i).\n$$\nA change of variables $x = \\varphi(s)$ with Jacobian $dx/ds$ transforms\n$$\n\\int_0^1 f(x)\\,dx = \\int_0^1 f(\\varphi(s)) \\frac{d\\varphi}{ds}(s) \\, ds.\n$$\nFor the model cross section $\\sigma(x) = (1-x)^{\\nu}$, define moments with integer $m \\ge 1$,\n$$\nI_m(\\nu) \\equiv \\int_0^1 x^m (1-x)^{\\nu} \\, dx = B(m+1,\\nu+1) = \\frac{\\Gamma(m+1)\\Gamma(\\nu+1)}{\\Gamma(m+\\nu+2)}.\n$$\nThen the ratio\n$$\nR_m(\\nu) \\equiv \\frac{I_m(\\nu)}{I_{m-1}(\\nu)} = \\frac{m}{m+\\nu+1},\n$$\nimplies an estimator for $\\nu$ given a numerical estimate $\\widehat{R}_m$,\n$$\n\\widehat{\\nu} = \\frac{m}{\\widehat{R}_m} - m - 1.\n$$\n\nDesign the exponentially clustered quadrature on $[0,1]$ as follows. Start from the Gauss–Legendre quadrature on $[-1,1]$ with nodes $\\{u_i\\}$ and weights $\\{\\omega_i\\}$ for $i=1,\\dots,N$. Map to $s \\in [0,1]$ by $s_i = (u_i+1)/2$ and $\\tilde{\\omega}_i = \\omega_i/2$. Then apply the exponential clustering map $\\varphi_{\\alpha}(s)$ controlled by a parameter $\\alpha > 0$,\n$$\nx = \\varphi_{\\alpha}(s) \\equiv \\frac{1 - e^{-\\alpha s}}{1 - e^{-\\alpha}},\n$$\nwhich satisfies $\\varphi_{\\alpha}(0)=0$, $\\varphi_{\\alpha}(1)=1$, and clusters more nodes near $x=1$ as $\\alpha$ increases. The Jacobian is\n$$\n\\frac{d\\varphi_{\\alpha}}{ds}(s) = \\frac{\\alpha e^{-\\alpha s}}{1 - e^{-\\alpha}}.\n$$\nThe exponentially clustered quadrature approximation is then\n$$\n\\int_0^1 f(x)\\,dx \\approx \\sum_{i=1}^N \\tilde{\\omega}_i \\, f(\\varphi_{\\alpha}(s_i)) \\, \\frac{d\\varphi_{\\alpha}}{ds}(s_i).\n$$\n\nTask:\n- Implement two numerical quadratures to approximate $I_{m-1}(\\nu)$ and $I_m(\\nu)$:\n  1. A standard Gauss–Legendre quadrature on $[0,1]$ with $N$ nodes.\n  2. An exponentially clustered quadrature on $[0,1]$ with $N$ nodes and clustering parameter $\\alpha$ as defined above.\n- Use the moment ratio estimator to compute $\\widehat{\\nu}$ for both quadratures, and quantify the absolute error $|\\widehat{\\nu} - \\nu|$.\n- No physical units are involved; all quantities are dimensionless.\n- Angles are not involved.\n- Any fractions or decimals should be represented as decimals in the final outputs.\n\nTest suite:\nEvaluate the absolute errors for the following parameter sets $(\\nu, N, \\alpha, m)$:\n1. $(\\nu, N, \\alpha, m) = (0.5, 8, 4.0, 3)$, a typical near-threshold half-integer case.\n2. $(\\nu, N, \\alpha, m) = (1.5, 8, 4.0, 3)$, steeper threshold behavior.\n3. $(\\nu, N, \\alpha, m) = (0.5, 4, 4.0, 2)$, few nodes to test low-resolution behavior.\n4. $(\\nu, N, \\alpha, m) = (0.1, 8, 2.0, 3)$, weak threshold.\n5. $(\\nu, N, \\alpha, m) = (-0.4, 12, 6.0, 3)$, integrable divergence near threshold (edge case with $\\nu > -1$).\n\nFor each test case, compute three floats:\n- The absolute error for the exponentially clustered quadrature, $|\\widehat{\\nu}_{\\text{cluster}} - \\nu|$.\n- The absolute error for the plain Gauss–Legendre quadrature, $|\\widehat{\\nu}_{\\text{plain}} - \\nu|$.\n- The improvement ratio defined as $|\\widehat{\\nu}_{\\text{plain}} - \\nu| / \\max(|\\widehat{\\nu}_{\\text{cluster}} - \\nu|, 10^{-18})$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered by test case, and within each test case ordered as described above. That is, the output must be\n$$\n\\big[ \\; \\text{err}_{\\text{cluster},1}, \\text{err}_{\\text{plain},1}, \\text{improv}_1, \\dots, \\text{err}_{\\text{cluster},5}, \\text{err}_{\\text{plain},5}, \\text{improv}_5 \\; \\big].\n$$", "solution": "The core task is to estimate the exponent $\\nu$ from the ratio of numerically computed moments, $I_m(\\nu) = \\int_0^1 x^m (1-x)^{\\nu} dx$. We will implement and compare two different quadrature methods for this purpose. Both methods are based on the $N$-point Gauss-Legendre quadrature rule on the canonical interval $[-1,1]$, with nodes $\\{u_i\\}$ and weights $\\{\\omega_i\\}$.\n\n**1. Standard Gauss–Legendre Quadrature on $[0,1]$ ('Plain' Method)**\nThis approach uses a simple linear mapping to transform the canonical interval $[-1,1]$ to the target interval $[0,1]$. The transformation is $x(u) = (u+1)/2$, with a constant Jacobian of $1/2$. The quadrature rule becomes:\n$$ \\int_0^1 f(x) dx \\approx \\sum_{i=1}^N \\frac{\\omega_i}{2} f\\left(\\frac{u_i+1}{2}\\right) $$\nThe nodes $x_i = (u_i+1)/2$ are distributed symmetrically. This is generally inefficient for integrands like $(1-x)^{\\nu}$, which have a non-analytic behavior concentrated at the endpoint $x=1$.\n\n**2. Exponentially Clustered Quadrature on $[0,1]$**\nThis method uses a non-linear change of variables to cluster the quadrature nodes near $x=1$. The procedure involves two steps:\na. A linear map from the canonical variable $u \\in [-1,1]$ to an intermediate variable $s \\in [0,1]$, given by $s(u)=(u+1)/2$. The nodes are $s_i=(u_i+1)/2$ and weights are $\\tilde{\\omega}_i = \\omega_i/2$.\nb. An exponential map from $s$ to the final integration variable $x \\in [0,1]$:\n$$ x = \\varphi_{\\alpha}(s) = \\frac{1 - e^{-\\alpha s}}{1 - e^{-\\alpha}} $$\nThe integral is transformed using the change of variables theorem:\n$$ \\int_0^1 f(x) dx = \\int_0^1 f(\\varphi_{\\alpha}(s)) \\frac{d\\varphi_{\\alpha}}{ds}(s) ds $$\nwhere the Jacobian is $\\frac{d\\varphi_{\\alpha}}{ds}(s) = \\frac{\\alpha e^{-\\alpha s}}{1 - e^{-\\alpha}}$. The integral over $s$ is then approximated using the standard quadrature for $[0,1]$:\n$$ \\int_0^1 f(x) dx \\approx \\sum_{i=1}^N \\tilde{\\omega}_i \\left[ f(\\varphi_{\\alpha}(s_i)) \\frac{d\\varphi_{\\alpha}}{ds}(s_i) \\right] $$\nThis creates a new quadrature rule on $[0,1]$ with nodes $x_i = \\varphi_{\\alpha}(s_i)$ that are densely clustered near $x=1$ for larger $\\alpha$, providing better resolution of the threshold behavior.\n\n**3. Estimation Procedure**\nFor each quadrature method, we compute the numerical approximations for the moments $I_{m-1}(\\nu)$ and $I_m(\\nu)$ by setting $f(x)=x^{m-1}(1-x)^{\\nu}$ and $f(x)=x^m(1-x)^{\\nu}$ respectively. Let the numerical estimates be $\\widehat{I}_{m-1}$ and $\\widehat{I}_m$. We then calculate the ratio $\\widehat{R}_m = \\widehat{I}_m / \\widehat{I}_{m-1}$. Finally, the exponent $\\nu$ is estimated using the given formula:\n$$ \\widehat{\\nu} = \\frac{m}{\\widehat{R}_m} - m - 1 $$\nThe absolute error $|\\widehat{\\nu} - \\nu|$ is then computed for each method to quantify its accuracy. The ratio of the errors will demonstrate the effectiveness of the node clustering technique.", "answer": "```python\nimport numpy as np\nfrom scipy.special import roots_legendre\n\n# Ensure floating point precision in calculations and output\nnp.set_printoptions(precision=16)\n\ndef compute_nu_hat_plain(nu, N, m):\n    \"\"\"\n    Computes the estimated exponent nu_hat using standard Gauss-Legendre quadrature on [0,1].\n    \"\"\"\n    # Get base Gauss-Legendre nodes and weights on [-1, 1]\n    u, omega = roots_legendre(N)\n    \n    # Linearly transform nodes and weights to [0, 1]\n    x_nodes = (u + 1.0) / 2.0\n    w_nodes = omega / 2.0\n    \n    # Define the integrands for moments m-1 and m\n    # f(x) = x^k * (1-x)^nu\n    integrand_m_minus_1 = np.power(x_nodes, m - 1) * np.power(1.0 - x_nodes, nu)\n    integrand_m = np.power(x_nodes, m) * np.power(1.0 - x_nodes, nu)\n    \n    # Compute the moments via quadrature sum\n    I_hat_m_minus_1 = np.sum(w_nodes * integrand_m_minus_1)\n    I_hat_m = np.sum(w_nodes * integrand_m)\n    \n    # Compute the ratio and estimate nu\n    if I_hat_m_minus_1 == 0:\n        # Avoid division by zero, return NaN to indicate failure\n        return np.nan\n        \n    R_hat_m = I_hat_m / I_hat_m_minus_1\n    nu_hat = m / R_hat_m - m - 1.0\n    \n    return nu_hat\n\ndef compute_nu_hat_clustered(nu, N, alpha, m):\n    \"\"\"\n    Computes the estimated exponent nu_hat using exponentially clustered quadrature on [0,1].\n    \"\"\"\n    # Get base Gauss-Legendre nodes and weights on [-1, 1]\n    u, omega = roots_legendre(N)\n    \n    # Linearly transform to intermediate variable s on [0, 1]\n    s_nodes = (u + 1.0) / 2.0\n    w_tilde = omega / 2.0\n    \n    # Apply the exponential clustering map: x = phi(s)\n    common_denom = 1.0 - np.exp(-alpha)\n    x_nodes = (1.0 - np.exp(-alpha * s_nodes)) / common_denom\n    \n    # Calculate the Jacobian of the map at each node\n    jacobian = (alpha * np.exp(-alpha * s_nodes)) / common_denom\n    \n    # The effective weights for the integral over x are w_tilde * jacobian\n    w_effective = w_tilde * jacobian\n    \n    # Define the integrands at the new clustered nodes\n    # Note: (1-x_nodes) is guaranteed to be > 0 because u_i are in (-1,1)\n    integrand_m_minus_1 = np.power(x_nodes, m - 1) * np.power(1.0 - x_nodes, nu)\n    integrand_m = np.power(x_nodes, m) * np.power(1.0 - x_nodes, nu)\n    \n    # Compute the moments via quadrature sum\n    I_hat_m_minus_1 = np.sum(w_effective * integrand_m_minus_1)\n    I_hat_m = np.sum(w_effective * integrand_m)\n    \n    # Compute the ratio and estimate nu\n    if I_hat_m_minus_1 == 0:\n        return np.nan\n        \n    R_hat_m = I_hat_m / I_hat_m_minus_1\n    nu_hat = m / R_hat_m - m - 1.0\n    \n    return nu_hat\n\ndef solve():\n    \"\"\"\n    Main solver function to run through test cases and print results.\n    \"\"\"\n    test_cases = [\n        (0.5, 8, 4.0, 3),\n        (1.5, 8, 4.0, 3),\n        (0.5, 4, 4.0, 2),\n        (0.1, 8, 2.0, 3),\n        (-0.4, 12, 6.0, 3),\n    ]\n\n    results = []\n    for nu, N, alpha, m in test_cases:\n        # Calculate nu_hat for both methods\n        nu_hat_cluster = compute_nu_hat_clustered(nu, N, alpha, m)\n        nu_hat_plain = compute_nu_hat_plain(nu, N, m)\n        \n        # Calculate absolute errors\n        err_cluster = abs(nu_hat_cluster - nu)\n        err_plain = abs(nu_hat_plain - nu)\n        \n        # Calculate improvement ratio with a small number to prevent division by zero\n        improvement = err_plain / max(err_cluster, 1e-18)\n        \n        results.extend([err_cluster, err_plain, improvement])\n\n    # Format the final output string as required\n    output_str = f\"[{','.join(f'{r:.15f}' for r in results)}]\"\n    print(output_str)\n\nsolve()\n```", "id": "3561465"}]}