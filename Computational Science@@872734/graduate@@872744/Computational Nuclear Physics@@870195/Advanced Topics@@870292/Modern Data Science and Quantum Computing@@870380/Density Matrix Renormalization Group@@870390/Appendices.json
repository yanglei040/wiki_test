{"hands_on_practices": [{"introduction": "The power of the Density Matrix Renormalization Group (DMRG) algorithm lies in its ability to intelligently truncate the vast Hilbert space of a many-body system. This is not a random or arbitrary reduction; it is guided by the entanglement structure of the quantum state itself. This practice provides a direct, hands-on look at this core principle by asking you to apply the truncation criterion to a given entanglement spectrum, bridging the gap between the abstract concept of discarded weight and the practical choice of bond dimension [@problem_id:3554768].", "problem": "Consider a one-dimensional orbital ordering for a valence-space nuclear shell-model Hamiltonian, where the ground state is approximated using the Matrix Product State (MPS) ansatz within the Density Matrix Renormalization Group (DMRG). At a given bipartition (bond) along the chain, the bipartite entanglement spectrum is the set of eigenvalues of the reduced density matrix obtained from the Schmidt decomposition of the many-body state. Let the entanglement spectrum be ordered nonincreasingly as $\\{\\lambda_{\\alpha}\\}_{\\alpha=1}^{\\chi}$ with $\\sum_{\\alpha=1}^{\\chi} \\lambda_{\\alpha} = 1$ and $\\lambda_{1} \\ge \\lambda_{2} \\ge \\cdots \\ge \\lambda_{\\chi} \\ge 0$. The truncation at bond dimension $m$ retains the $m$ largest eigenvalues and discards the rest. The discarded weight is defined as $\\epsilon_{\\text{disc}}(m) = \\sum_{\\alpha=m+1}^{\\chi} \\lambda_{\\alpha}$.\n\nIn a two-site DMRG sweep, one aims to choose the smallest bond dimension $m$ at each bond such that the local truncation error is controlled by a target tolerance $\\varepsilon$. Starting from the foundational definition of the Schmidt decomposition and reduced density matrix for a pure state bipartition, use the entanglement spectrum\n$$\n\\{\\lambda_{\\alpha}\\}_{\\alpha=1}^{10} = \\{0.36,\\;0.24,\\;0.12,\\;0.08,\\;0.06,\\;0.05,\\;0.04,\\;0.025,\\;0.015,\\;0.01\\}\n$$\nand the tolerance $\\varepsilon = 2 \\times 10^{-2}$ to determine the minimal integer $m$ such that $\\epsilon_{\\text{disc}}(m) \\le \\varepsilon$. Then, based on the same foundational principles, explain how this criterion informs adaptive bond-dimension control during DMRG sweeps in computational nuclear physics, particularly in terms of computational efficiency and error control for strongly and weakly entangled cuts.\n\nProvide the final $m$ as a single integer. No rounding is required.", "solution": "The problem requires us to determine the minimal bond dimension $m$ required to satisfy a given truncation error tolerance and to explain the role of this criterion in adaptive Density Matrix Renormalization Group (DMRG) calculations.\n\nFirst, we validate the problem statement. The givens are an entanglement spectrum (a set of 10 non-increasing, normalized eigenvalues of a reduced density matrix), a definition for the discarded weight $\\epsilon_{\\text{disc}}(m)$, and a target tolerance $\\varepsilon$. The problem is scientifically grounded, mathematically well-posed, and contains all necessary information.\n\nWe proceed to find the minimal integer $m$ such that $\\epsilon_{\\text{disc}}(m) \\le \\varepsilon = 0.02$. The discarded weight is the sum of the eigenvalues not kept: $\\epsilon_{\\text{disc}}(m) = \\sum_{\\alpha=m+1}^{10} \\lambda_{\\alpha}$. An equivalent way to calculate this is $\\epsilon_{\\text{disc}}(m) = 1 - \\sum_{\\alpha=1}^{m} \\lambda_{\\alpha}$. We test integer values for $m$ starting from 1.\n\nThe eigenvalues are:\n$\\lambda_1=0.36, \\lambda_2=0.24, \\lambda_3=0.12, \\lambda_4=0.08, \\lambda_5=0.06, \\lambda_6=0.05, \\lambda_7=0.04, \\lambda_8=0.025, \\lambda_9=0.015, \\lambda_{10}=0.01$.\n\n- For $m=1$: $\\epsilon_{\\text{disc}}(1) = 1 - 0.36 = 0.64 > 0.02$.\n- For $m=2$: $\\epsilon_{\\text{disc}}(2) = 1 - (0.36 + 0.24) = 0.40 > 0.02$.\n- For $m=3$: $\\epsilon_{\\text{disc}}(3) = 1 - (0.60 + 0.12) = 0.28 > 0.02$.\n- For $m=4$: $\\epsilon_{\\text{disc}}(4) = 1 - (0.72 + 0.08) = 0.20 > 0.02$.\n- For $m=5$: $\\epsilon_{\\text{disc}}(5) = 1 - (0.80 + 0.06) = 0.14 > 0.02$.\n- For $m=6$: $\\epsilon_{\\text{disc}}(6) = 1 - (0.86 + 0.05) = 0.09 > 0.02$.\n- For $m=7$: $\\epsilon_{\\text{disc}}(7) = 1 - (0.91 + 0.04) = 0.05 > 0.02$.\n- For $m=8$: $\\epsilon_{\\text{disc}}(8) = \\lambda_9 + \\lambda_{10} = 0.015 + 0.01 = 0.025 > 0.02$.\n- For $m=9$: $\\epsilon_{\\text{disc}}(9) = \\lambda_{10} = 0.01 \\le 0.02$.\n\nThe condition is met for $m=9$. Therefore, the minimal integer bond dimension is 9.\n\nFor the second part, this criterion is the basis for adaptive bond-dimension control in DMRG. During a sweep, the algorithm performs a local optimization at each bond (bipartition) of the 1D orbital chain. This step involves a singular value decomposition (SVD), which is equivalent to a Schmidt decomposition of the state across that bond. The squares of the singular values are the eigenvalues of the reduced density matrix, $\\{\\lambda_{\\alpha}\\}$.\n\nInstead of using a fixed bond dimension $m$ for the entire chain, an adaptive scheme uses a fixed target discarded weight $\\varepsilon$. At each bond, the algorithm calculates the entanglement spectrum and determines the smallest $m$ needed to satisfy $\\epsilon_{\\text{disc}}(m) \\le \\varepsilon$. This value of $m$ is then used for that specific bond.\n\nThis adaptive strategy is crucial for computational efficiency:\n1.  **Weakly Entangled Cuts:** At bipartitions with weak entanglement (e.g., across a large shell gap), the entanglement spectrum decays rapidly. Only a few eigenvalues are significant. The adaptive algorithm will automatically choose a small $m$, reducing the size of the MPS tensors and the computational cost (which scales polynomially, often as $m^3$).\n2.  **Strongly Entangled Cuts:** At bipartitions with strong entanglement (e.g., in regions of strong configuration mixing), the spectrum decays slowly. To meet the tolerance $\\varepsilon$, a much larger $m$ is required. The algorithm automatically increases the bond dimension at these \"difficult\" bonds, allocating more computational resources to ensure the physics is accurately captured.\n\nIn summary, adaptive bond-dimension control based on discarded weight allows DMRG to dynamically allocate resources where they are most needed, making it a powerful and efficient method for complex systems like nuclei.", "answer": "$$\n\\boxed{9}\n$$", "id": "3554768"}, {"introduction": "While DMRG is natively formulated for one-dimensional systems, many problems in nuclear physics involve particles in three-dimensional potential wells. A critical step in applying DMRG is therefore to map these higher-dimensional orbital spaces onto a one-dimensional chain. This exercise guides you through a practical coding task to investigate how different ordering schemes impact the locality of interactions along the chain, a key factor determining DMRG's efficiency and accuracy [@problem_id:3554798].", "problem": "Consider a mapping of three-dimensional harmonic oscillator single-particle orbitals used in nuclear shell-model calculations onto a one-dimensional chain for a Density Matrix Renormalization Group (DMRG) algorithm. The goal is to design an ordering that minimizes effective coupling range along the chain by exploiting spatial locality. Starting from core definitions of the harmonic oscillator basis and a physically motivated short-range interaction, construct a program that quantifies how coupling magnitudes decay with chain distance for two distinct orderings: a spatially local ordering and an energy-ordered chain. Use the following specifications.\n\nFundamental base and definitions:\n- The three-dimensional harmonic oscillator has single-particle orbitals labeled by radial quantum number $n \\in \\{0,1,2,\\dots\\}$ and orbital angular momentum $l \\in \\{0,1,2,\\dots\\}$, with magnetic projection $m \\in \\{-l,-l+1,\\dots,l\\}$. The major shell quantum number is $N=2n+l$.\n- The harmonic oscillator energy is $E_{nl} = \\hbar \\omega \\left(2n + l + \\tfrac{3}{2}\\right)$, which is equivalently $E_{N} = \\hbar \\omega \\left(N + \\tfrac{3}{2}\\right)$.\n- The harmonic oscillator length parameter is $b$ (in femtometers), and the root-mean-square radius for a state in shell $N$ is approximated as $\\sqrt{\\langle r^{2}\\rangle_{N}} = b \\sqrt{N + \\tfrac{3}{2}}$.\n- Truncate the basis to $N \\leq N_{\\max}$ with the parity constraint that $n$ must be integer, i.e., $n = (N-l)/2$ must satisfy $N-l$ even.\n- The coupling between two orbitals $(n,l,m)$ and $(n',l',m')$ is modeled by a short-range central interaction of finite range $s$ (in femtometers), with an additional angular mismatch suppression. Define the centroid radii $R = b \\sqrt{N + \\tfrac{3}{2}}$ and $R' = b \\sqrt{N' + \\tfrac{3}{2}}$. The effective pairwise coupling weight is\n$$\nw_{ij} = \\exp\\!\\left(-\\frac{(R - R')^{2}}{2 s^{2}}\\right) \\exp\\!\\left(-\\alpha \\, |l - l'|\\right) \\exp\\!\\left(-\\beta \\, |m - m'|\\right),\n$$\nwhere $\\alpha$ and $\\beta$ are nonnegative dimensionless parameters that penalize angular momentum and magnetic projection mismatch, respectively. This form captures the physically motivated decay of overlap for finite-range interactions and reduced coupling for large angular mismatches.\n\nOrdering and chain distance:\n- Define a one-dimensional chain by assigning each orbital a position index according to an ordering rule.\n- The spatially local ordering sorts orbitals by ascending centroid radius $R$, then by ascending $l$, then by ascending $m$.\n- The energy ordering sorts orbitals by ascending energy $E_{N}$, then by descending $m$, then by descending $l$.\n- The chain distance between orbitals $i$ and $j$ in an ordering is $d_{ij} = |p(i) - p(j)|$, where $p(i)$ is the position index of orbital $i$ in the chain.\n\nQuantities to compute for each ordering:\n- The total coupling weight $W_{\\mathrm{tot}} = \\sum_{i<j} w_{ij}$ over unordered distinct pairs.\n- The weighted effective coupling range\n$$\n\\overline{d} = \\frac{\\sum_{i<j} w_{ij} \\, d_{ij}}{\\sum_{i<j} w_{ij}}.\n$$\n- The nearest-neighbor coupling fraction\n$$\nf_{\\mathrm{NN}} = \\frac{\\sum_{i<j,\\, d_{ij} \\leq 1} w_{ij}}{\\sum_{i<j} w_{ij}}.\n$$\n- The Pearson correlation coefficient between coupling magnitude and chain distance, defined as\n$$\n\\rho = \\frac{\\operatorname{Cov}(d,w)}{\\sigma_{d} \\sigma_{w}},\n$$\nwhere $\\operatorname{Cov}(d,w)$ is the covariance of $\\{d_{ij}\\}$ and $\\{w_{ij}\\}$, and $\\sigma_{d}$ and $\\sigma_{w}$ are their standard deviations. If either variance vanishes, define $\\rho = 0$.\n\nComparison metrics for each test case:\n- The improvement ratio in weighted coupling range $I_{\\mathrm{range}} = \\overline{d}_{\\mathrm{spatial}} / \\overline{d}_{\\mathrm{energy}}$.\n- The correlation improvement $\\Delta \\rho = \\rho_{\\mathrm{spatial}} - \\rho_{\\mathrm{energy}}$.\n- The nearest-neighbor gain $G_{\\mathrm{NN}} = f_{\\mathrm{NN,\\, spatial}} / f_{\\mathrm{NN,\\, energy}}$.\n\nUnits and constants:\n- Use $b$ and $s$ in femtometers. The outputs are dimensionless floats. You may set $\\hbar \\omega = 1$ (arbitrary units) for the purpose of energy ordering.\n\nTest suite:\nImplement your program to evaluate the three metrics $(I_{\\mathrm{range}}, \\Delta \\rho, G_{\\mathrm{NN}})$ for the following parameter sets:\n- Case $1$: $N_{\\max} = 4$, $b = 1.7$ fm, $s = 1.7$ fm, $\\alpha = 0.6$, $\\beta = 0.2$.\n- Case $2$: $N_{\\max} = 2$, $b = 1.7$ fm, $s = 0.6$ fm, $\\alpha = 0.8$, $\\beta = 0.3$.\n- Case $3$: $N_{\\max} = 6$, $b = 1.7$ fm, $s = 3.4$ fm, $\\alpha = 0.5$, $\\beta = 0.1$.\n- Case $4$ (edge case coverage): $N_{\\max} = 1$, $b = 1.7$ fm, $s = 0.4$ fm, $\\alpha = 0.7$, $\\beta = 0.2$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each case, output the three floats in the order $(I_{\\mathrm{range}}, \\Delta \\rho, G_{\\mathrm{NN}})$, and aggregate them for all four cases into a flat list. For example, the final output should be of the form $[I_{1}, \\Delta \\rho_{1}, G_{\\mathrm{NN},1}, I_{2}, \\Delta \\rho_{2}, G_{\\mathrm{NN},2}, I_{3}, \\Delta \\rho_{3}, G_{\\mathrm{NN},3}, I_{4}, \\Delta \\rho_{4}, G_{\\mathrm{NN},4}]$.", "solution": "The design of a Density Matrix Renormalization Group (DMRG) mapping for nuclear shell-model orbitals onto a one-dimensional chain should begin from fundamental properties of the single-particle basis and the physics of inter-orbital couplings. The three-dimensional harmonic oscillator is the standard basis for nuclear mean-field calculations, characterized by discrete major shells indexed by $N = 2n + l$, where $n$ is the radial quantum number and $l$ is the orbital angular momentum. The harmonic oscillator energy spacings are given by $E_{nl} = \\hbar \\omega (2n + l + \\tfrac{3}{2})$, and the spatial extent of orbitals increases with $N$ through the root-mean-square (rms) radius $\\sqrt{\\langle r^{2}\\rangle_{N}} = b \\sqrt{N + \\tfrac{3}{2}}$, where $b$ is the oscillator length.\n\nThe Density Matrix Renormalization Group works most efficiently when the Hamiltonian couplings are short range along the chain index because truncation errors are reduced with locality, leading to lower entanglement across cuts. In a nuclear context, realistic residual interactions are finite range; a widely used approximation is to model them as central finite-range potentials, for which coupling magnitudes between two orbitals are governed by spatial overlap. For harmonic oscillator orbitals, whose densities can be approximated by Gaussians spread over a characteristic radius tied to $b$ and $N$, the overlap of two such localized distributions decays as a Gaussian in the separation of their centroids. Therefore, an idealized effective coupling weight between orbitals $(n,l,m)$ and $(n',l',m')$ can be modeled as\n$$\nw_{ij} = \\exp\\!\\left(-\\frac{(R - R')^{2}}{2 s^{2}}\\right),\n$$\nwhere $R = b \\sqrt{N + \\tfrac{3}{2}}$ and $R' = b \\sqrt{N' + \\tfrac{3}{2}}$ approximate the rms spatial extents, and $s$ is a finite interaction range parameter. This captures the fundamental physical principle that finite-range forces preferentially couple states with similar spatial extent.\n\nA more refined coupling should also account for angular momentum mismatches. The spherical central interactions tend to conserve orbital angular momentum in dominant channels, implying reduced coupling when $|l - l'|$ is large. Additionally, tensor and spin-orbit components introduce dependence on angular projections, which we crudely encode via a penalty on $|m - m'|$. A simple, dimensionless suppression is\n$$\nw_{ij} \\leftarrow w_{ij} \\times \\exp\\!\\left(-\\alpha\\,|l-l'|\\right) \\times \\exp\\!\\left(-\\beta\\,|m-m'|\\right),\n$$\nwith $\\alpha \\geq 0$ and $\\beta \\geq 0$. This parametric form enforces that states with similar $l$ and $m$ couple more strongly, consistent with physically motivated selection patterns, while maintaining the primary finite-range character via the Gaussian factor.\n\nTo evaluate the impact of ordering on DMRG locality, we map the set of orbitals to a one-dimensional chain by assigning positions $p(i)$ according to an ordering rule. Two reasonable orderings are:\n- Spatially local ordering: sort by ascending $R$, then by ascending $l$, then by ascending $m$. This seeks local adjacency in real space and in angular quantum numbers.\n- Energy ordering: sort by ascending $E_{N}$, then by descending $m$, then by descending $l$. This represents a conventional energy-first fill, but the tie-breaking intentionally disrupts spatial locality, creating a useful contrast.\n\nFor a given ordering, define the chain distance\n$$\nd_{ij} = |p(i) - p(j)|.\n$$\nWith pair weights $w_{ij}$, define the total weight\n$$\nW_{\\mathrm{tot}} = \\sum_{i<j} w_{ij}.\n$$\nThree quantitative indicators of locality are computed:\n1. The weighted effective coupling range\n$$\n\\overline{d} = \\frac{\\sum_{i<j} w_{ij} \\, d_{ij}}{\\sum_{i<j} w_{ij}},\n$$\nwhich penalizes long-range couplings and is minimized by local orderings.\n2. The nearest-neighbor fraction\n$$\nf_{\\mathrm{NN}} = \\frac{\\sum_{i<j,\\, d_{ij} \\leq 1} w_{ij}}{\\sum_{i<j} w_{ij}},\n$$\nwhich emphasizes how much of the interaction weight is captured by adjacent orbitals.\n3. The coupling-distance Pearson correlation coefficient\n$$\n\\rho = \\frac{\\operatorname{Cov}(d,w)}{\\sigma_{d} \\sigma_{w}},\n$$\nwhere $\\operatorname{Cov}(d,w)$ is the covariance of the sample $\\{(d_{ij}, w_{ij})\\}$ and $\\sigma_{d}$, $\\sigma_{w}$ are their standard deviations. A more negative $\\rho$ indicates that larger distances are more strongly associated with smaller couplings, which is desired.\n\nFor comparison between the spatially local and energy orderings, we compute:\n- The improvement ratio in effective range $I_{\\mathrm{range}} = \\overline{d}_{\\mathrm{spatial}} / \\overline{d}_{\\mathrm{energy}}$, with $I_{\\mathrm{range}} < 1$ showing that spatial ordering reduces coupling range.\n- The correlation improvement $\\Delta \\rho = \\rho_{\\mathrm{spatial}} - \\rho_{\\mathrm{energy}}$, which should be negative when spatial ordering enhances locality (stronger negative correlation).\n- The nearest-neighbor gain $G_{\\mathrm{NN}} = f_{\\mathrm{NN,\\, spatial}} / f_{\\mathrm{NN,\\, energy}}$, with $G_{\\mathrm{NN}} > 1$ indicating that more weight lies in nearest-neighbor couplings for the spatial chain.\n\nAlgorithmic design steps for implementation:\n- Generate all orbitals with $N \\leq N_{\\max}$ obeying $n = (N-l)/2 \\in \\mathbb{Z}$, and include all $m \\in \\{-l,\\dots,l\\}$ to capture magnetic degeneracy. For each orbital, compute $R = b \\sqrt{N + \\tfrac{3}{2}}$ and $E_{N} = (N + \\tfrac{3}{2})$ after setting $\\hbar \\omega = 1$.\n- Create two orderings as specified. Map each orbital to its position $p(i)$ in the chain for each ordering.\n- For each unordered pair $(i,j)$ with $i<j$, compute $w_{ij}$ using the defined formula with the given $b$, $s$, $\\alpha$, and $\\beta$. Compute $d_{ij}$ per ordering.\n- Accumulate $\\sum w_{ij}$, $\\sum w_{ij} d_{ij}$, $\\sum_{d_{ij} \\leq 1} w_{ij}$, and the sample vectors of $d_{ij}$ and $w_{ij}$ for correlation evaluation. If $\\sigma_{d} = 0$ or $\\sigma_{w} = 0$, set $\\rho = 0$ to avoid undefined behavior.\n- For each ordering, compute $\\overline{d}$, $f_{\\mathrm{NN}}$, and $\\rho$. Then compute the three comparison metrics $(I_{\\mathrm{range}}, \\Delta \\rho, G_{\\mathrm{NN}})$.\n- Repeat for the specified test suite.\n\nThe outputs are dimensionless floats. Finally, aggregate the results into a single flat list ordered by test case and metric and print a single line in the exact required format $[I_{1}, \\Delta \\rho_{1}, G_{\\mathrm{NN},1}, I_{2}, \\Delta \\rho_{2}, G_{\\mathrm{NN},2}, I_{3}, \\Delta \\rho_{3}, G_{\\mathrm{NN},3}, I_{4}, \\Delta \\rho_{4}, G_{\\mathrm{NN},4}]$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef generate_orbitals(Nmax: int, b: float):\n    \"\"\"\n    Generate all 3D harmonic oscillator orbitals up to Nmax with parity constraint,\n    including magnetic degeneracy m in [-l, ..., l].\n    Each orbital is represented as a dict with keys: n, l, m, N, R, E.\n    \"\"\"\n    orbitals = []\n    for N in range(Nmax + 1):\n        # l can be 0..N, with the constraint that n = (N - l)/2 must be integer >= 0\n        for l in range(N + 1):\n            if (N - l) % 2 != 0:\n                continue\n            n = (N - l) // 2\n            if n  0:\n                continue\n            # magnetic degeneracy\n            for m in range(-l, l + 1):\n                R = b * np.sqrt(N + 1.5)  # rms radius\n                E = (N + 1.5)            # set ħω = 1 for ordering\n                orbitals.append({\"n\": n, \"l\": l, \"m\": m, \"N\": N, \"R\": R, \"E\": E})\n    return orbitals\n\ndef order_orbitals(orbitals, mode: str):\n    \"\"\"\n    Return an ordering mapping: orbital index -> position in chain.\n    mode: 'spatial' or 'energy'\n    spatial: sort by R asc, l asc, m asc\n    energy: sort by E asc, m desc, l desc\n    \"\"\"\n    indices = list(range(len(orbitals)))\n    if mode == \"spatial\":\n        sorted_idx = sorted(indices, key=lambda i: (orbitals[i][\"R\"], orbitals[i][\"l\"], orbitals[i][\"m\"]))\n    elif mode == \"energy\":\n        sorted_idx = sorted(indices, key=lambda i: (orbitals[i][\"E\"], -orbitals[i][\"m\"], -orbitals[i][\"l\"]))\n    else:\n        raise ValueError(\"Unknown mode\")\n    pos = {idx: p for p, idx in enumerate(sorted_idx)}\n    return pos\n\ndef pair_weight(o_i, o_j, s: float, alpha: float, beta: float):\n    \"\"\"\n    Compute the coupling weight between two orbitals based on Gaussian spatial decay and\n    exponential penalties for angular mismatches.\n    \"\"\"\n    dR = abs(o_i[\"R\"] - o_j[\"R\"])\n    # Gaussian in centroid separation with width s\n    w = np.exp(-(dR ** 2) / (2.0 * s ** 2))\n    # Angular momentum mismatch penalty\n    w *= np.exp(-alpha * abs(o_i[\"l\"] - o_j[\"l\"]))\n    # Magnetic projection mismatch penalty\n    w *= np.exp(-beta * abs(o_i[\"m\"] - o_j[\"m\"]))\n    return w\n\ndef compute_metrics(orbitals, pos_map, s: float, alpha: float, beta: float):\n    \"\"\"\n    Compute total weight, weighted effective coupling range, nearest-neighbor fraction,\n    and Pearson correlation between chain distance and weight for a given ordering.\n    \"\"\"\n    L = len(orbitals)\n    if L  2:\n        # No pairs; define zero metrics\n        return 0.0, 0.0, 0.0\n\n    w_tot = 0.0\n    w_d_sum = 0.0\n    w_nn = 0.0\n    d_list = []\n    w_list = []\n\n    for i in range(L):\n        for j in range(i + 1, L):\n            w = pair_weight(orbitals[i], orbitals[j], s, alpha, beta)\n            d = abs(pos_map[i] - pos_map[j])\n            w_tot += w\n            w_d_sum += w * d\n            if d = 1:\n                w_nn += w\n            d_list.append(float(d))\n            w_list.append(float(w))\n\n    if w_tot == 0.0:\n        # Avoid division by zero; define neutral metrics\n        avg_range = 0.0\n        nn_frac = 0.0\n    else:\n        avg_range = w_d_sum / w_tot\n        nn_frac = w_nn / w_tot\n\n    # Pearson correlation between d and w\n    d_arr = np.array(d_list)\n    w_arr = np.array(w_list)\n    sd_d = np.std(d_arr)\n    sd_w = np.std(w_arr)\n    if sd_d > 0 and sd_w > 0:\n        cov = float(np.mean((d_arr - np.mean(d_arr)) * (w_arr - np.mean(w_arr))))\n        rho = cov / (sd_d * sd_w)\n    else:\n        rho = 0.0\n\n    return avg_range, nn_frac, rho\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (Nmax, b [fm], s [fm], alpha, beta)\n    test_cases = [\n        (4, 1.7, 1.7, 0.6, 0.2),  # Case 1\n        (2, 1.7, 0.6, 0.8, 0.3),  # Case 2\n        (6, 1.7, 3.4, 0.5, 0.1),  # Case 3\n        (1, 1.7, 0.4, 0.7, 0.2),  # Case 4 (edge coverage)\n    ]\n\n    results = []\n    for Nmax, b, s, alpha, beta in test_cases:\n        orbitals = generate_orbitals(Nmax, b)\n        pos_spatial = order_orbitals(orbitals, mode=\"spatial\")\n        pos_energy = order_orbitals(orbitals, mode=\"energy\")\n\n        avg_range_sp, nn_frac_sp, rho_sp = compute_metrics(orbitals, pos_spatial, s, alpha, beta)\n        avg_range_en, nn_frac_en, rho_en = compute_metrics(orbitals, pos_energy, s, alpha, beta)\n\n        # Improvement ratio in weighted effective coupling range\n        if avg_range_en != 0.0:\n            I_range = avg_range_sp / avg_range_en\n        else:\n            # If energy range is zero (degenerate), set neutral comparison\n            I_range = 1.0\n\n        # Correlation improvement\n        delta_rho = rho_sp - rho_en\n\n        # Nearest-neighbor gain\n        if nn_frac_en != 0.0:\n            G_nn = nn_frac_sp / nn_frac_en\n        else:\n            # If energy NN fraction is zero, define gain as 1 if both zero else large; choose neutral 1.0\n            G_nn = 1.0\n\n        results.extend([I_range, delta_rho, G_nn])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3554798"}, {"introduction": "A deep understanding of any computational algorithm requires analyzing its performance and resource requirements. After grasping the logic of truncation and problem setup, it is essential to quantify the computational cost. This advanced exercise has you derive the memory and time complexity of a DMRG sweep from the fundamental tensor contractions, providing the analytical tools needed to estimate the resources for large-scale nuclear structure calculations [@problem_id:3554825].", "problem": "Consider a valence-space nuclear shell-model Hamiltonian encoded as a Matrix Product Operator (MPO) acting on a Matrix Product State (MPS) within a one-dimensional orbital ordering of length $L$. Each orbital has local Hilbert-space dimension $d$ (e.g., occupation-number and spin-isospin degrees of freedom consistent with fermionic antisymmetry), and the MPS is kept at a uniform bond dimension $m$ along the chain by Density Matrix Renormalization Group (DMRG; Density Matrix Renormalization Group). The Hamiltonian MPO has a uniform bond dimension $w$ arising from the finite range and operator structure of the nuclear interactions.\n\nAdopt the single-site variational DMRG update with an iterative Krylov eigensolver (e.g., Davidson), where the dominant kernel in each local update is the application of the effective Hamiltonian to the local state vector. Use the following canonical tensor shapes:\n- The site MPS tensor $A^{[i]}$ has indices $(\\alpha, s, \\beta)$ with $\\alpha \\in \\{1,\\dots,m\\}$, $s \\in \\{1,\\dots,d\\}$, and $\\beta \\in \\{1,\\dots,m\\}$, so its storage per site scales as $m^{2} d$.\n- The site MPO tensor $W^{[i]}$ has indices $(\\ell, r, s', s)$ with $\\ell \\in \\{1,\\dots,w\\}$, $r \\in \\{1,\\dots,w\\}$, and $s', s \\in \\{1,\\dots,d\\}$, so its storage per site scales as $w^{2} d^{2}$.\n- The left and right environments $E_{L}^{[i]}$ and $E_{R}^{[i]}$ entering the effective Hamiltonian application have indices $(\\alpha', \\alpha, \\ell)$ and $(\\beta, \\beta', r)$, respectively, so each environment per site scales as $m^{2} w$ in storage.\n\nFor a single-site local optimization, represent the local vector $x$ as a rank-$3$ tensor $x_{\\alpha s \\beta}$ of dimension $m \\times d \\times m$, which has flattened length $m^{2} d$. The effective Hamiltonian application yielding $y_{\\alpha' s' \\beta'}$ can be written schematically as the contraction\n$$\ny_{\\alpha' s' \\beta'} \\;=\\; \\sum_{\\alpha, s, \\beta} \\sum_{\\ell, r} \\; E_{L,\\alpha' \\alpha \\ell} \\; W_{\\ell r s' s} \\; E_{R,\\beta \\beta' r} \\; x_{\\alpha s \\beta}.\n$$\nDerive, from first principles of tensor contractions and index counting without using any shortcut formulas, the leading-order memory footprint over the full chain when both left and right environments are cached for all sites simultaneously during a bidirectional sweep, and the leading-order total time-complexity for one full sweep when counting one effective-Hamiltonian application per site and ignoring constant iteration counts in the Krylov method. Express both quantities as closed-form analytic expressions in terms of $m$, $w$, $L$, and $d$.\n\nAdditionally, based on the block structure induced by conserved quantum numbers (e.g., particle number $U(1)$ and total angular momentum $SU(2)$) and on the MPO bond index structure, propose a scientifically sound parallelization strategy that partitions work either across symmetry sectors or across MPO bonds. Your proposal should explain how the contraction above factorizes, how partial results are accumulated, and what the expected scaling of computation and communication would be, but your final numerical expressions for memory and time-complexity must remain functions only of $m$, $w$, $L$, and $d$.\n\nYour final answer must be a single row matrix containing the memory and time-complexity expressions in that order. No units are required. Do not include big-$\\mathcal{O}$ notation in the final expressions; provide the leading-order closed forms.", "solution": "The problem requires the derivation of the memory and time complexity for a single-site DMRG sweep and a proposal for a parallelization strategy. The provided tensor definitions and contraction formula are standard and well-posed, forming a valid basis for analysis.\n\n### Derivation of Memory Footprint\nThe total memory footprint is the sum of storage costs for the Matrix Product State (MPS), the Matrix Product Operator (MPO), and the cached left and right environment tensors for all $L$ sites.\n- **MPS Storage:** Each of the $L$ MPS tensors ($A^{[i]}$) has dimensions $(m, d, m)$, requiring $m^2 d$ elements. Total MPS storage is $L m^2 d$.\n- **MPO Storage:** Each of the $L$ MPO tensors ($W^{[i]}$) has dimensions $(w, w, d, d)$, requiring $w^2 d^2$ elements. Total MPO storage is $L w^2 d^2$.\n- **Environment Storage:** Caching both left ($E_L^{[i]}$) and right ($E_R^{[i]}$) environment tensors for all $L$ sites is specified. Each environment tensor has dimensions $(m, m, w)$, requiring $m^2 w$ elements. The total for both is $2 \\times L \\times m^2 w = 2 L m^2 w$.\n\nSumming these contributions gives the total leading-order memory footprint:\n$$ \\text{Memory} = L m^2 d + L w^2 d^2 + 2 L m^2 w $$\nThis can be factored as $L(m^2 d + w^2 d^2 + 2 m^2 w)$.\n\n### Derivation of Time Complexity\nThe total time complexity for one full sweep is $L$ times the cost of a single effective-Hamiltonian application. The cost of this application is determined by the number of floating-point operations in the tensor contraction:\n$$ y_{\\alpha' s' \\beta'} = \\sum_{\\alpha, s, \\beta, \\ell, r} E_{L,\\alpha' \\alpha \\ell} \\; W_{\\ell r s' s} \\; E_{R,\\beta \\beta' r} \\; x_{\\alpha s \\beta} $$\nTo minimize computational cost, we choose an optimal contraction order. A standard approach is to contract the local vector $x$ from right to left through the environment and MPO tensors.\n\n1.  **Contract local vector with right environment:** Let $T_1(\\alpha, s, \\beta', r) = \\sum_{\\beta} x_{\\alpha s \\beta} E_{R,\\beta \\beta' r}$. The cost is the product of the dimensions of the involved indices ($\\alpha, s, \\beta', r, \\beta$), which is $m \\times d \\times m \\times w \\times m = m^3 d w$. The resulting intermediate tensor $T_1$ has dimensions $(m, d, m, w)$.\n2.  **Contract intermediate with MPO:** Let $T_2(\\alpha, \\beta', \\ell, s') = \\sum_{s, r} T_1(\\alpha, s, \\beta', r) W_{\\ell r s' s}$. The cost is the product of the resultant tensor dimensions and the summed-over dimensions: $(m \\times m \\times w \\times d) \\times (d \\times w) = m^2 d^2 w^2$.\n3.  **Contract with left environment:** The final result is $y_{\\alpha' s' \\beta'} = \\sum_{\\alpha, \\ell} E_{L, \\alpha' \\alpha \\ell} T_2(\\alpha, \\beta', \\ell, s')$. The cost is $(m \\times d \\times m) \\times (m \\times w) = m^3 d w$.\n\nThe total cost per site is the sum of these steps: $m^3 d w + m^2 d^2 w^2 + m^3 d w = 2 m^3 d w + m^2 d^2 w^2$.\nThe total time complexity for a full sweep over $L$ sites is:\n$$ \\text{Time} = L (2 m^3 d w + m^2 d^2 w^2) $$\n\n### Parallelization Strategy\nThe structure of the effective Hamiltonian contraction naturally lends itself to parallelization. The summation over the MPO bond indices $(\\ell, r)$ can be partitioned. The total operation can be expressed as a sum over $w^2$ independent terms:\n$$ y_{\\alpha' s' \\beta'} = \\sum_{\\ell=1}^{w} \\sum_{r=1}^{w} \\left( \\sum_{\\alpha, s, \\beta} E_{L,\\alpha' \\alpha \\ell} \\; W_{\\ell r s' s} \\; E_{R,\\beta \\beta' r} \\; x_{\\alpha s \\beta} \\right) $$\n- **Work Partitioning:** The $w^2$ tasks, each corresponding to a specific $(\\ell, r)$ pair, can be distributed among available processors. Each processor computes a partial sum of the final tensor $y$ over its assigned set of $(\\ell, r)$ pairs.\n- **Data Distribution and Accumulation:** The environment tensors ($E_L, E_R$) and the local vector ($x$) must be available to all processors, while the MPO tensor $W$ can be distributed according to the task assignment. After parallel computation, a final reduction (summation) operation across all processors is required to obtain the complete result $y$.\n- **Scaling:** This strategy parallelizes the most computationally intensive part of the calculation. The computational workload scales down by the number of processors, while the main communication overhead is the final reduction of the result tensor, which has size $m^2d$. This approach is highly effective when the MPO bond dimension $w$ is large. The derived complexity expressions remain the same as they represent the total work.", "answer": "$$\n\\boxed{\n\\begin{pmatrix} L m^{2} d + 2 L m^{2} w + L w^{2} d^{2}  2 L m^{3} d w + L m^{2} d^{2} w^{2} \\end{pmatrix}\n}\n$$", "id": "3554825"}]}