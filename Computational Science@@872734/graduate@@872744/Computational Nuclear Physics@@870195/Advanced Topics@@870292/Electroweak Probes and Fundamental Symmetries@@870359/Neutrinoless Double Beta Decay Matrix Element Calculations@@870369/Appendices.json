{"hands_on_practices": [{"introduction": "The foundation of any neutrinoless double beta decay matrix element calculation lies in the accurate evaluation of the neutrino potential, which describes the interaction between the two decaying neutrons. These potentials are typically expressed as momentum-space integrals involving spherical Bessel functions. This exercise, [@problem_id:3572950], provides essential practice in implementing robust numerical quadrature methods, such as Gauss-Laguerre and Gauss-Legendre quadrature, which are workhorse techniques for handling the types of integrals encountered in realistic calculations. By benchmarking your implementation against known analytic results, you will build and verify a critical component of the computational toolkit required for this field.", "problem": "You are tasked with implementing numerical quadrature for momentum-space integrals that appear in the neutrino potentials used in neutrinoless double beta decay matrix element calculations. The neutrino potentials can be expressed as radial transforms that involve the spherical Bessel function and momentum-transfer kernels. Your program must implement Gauss–Legendre Quadrature (GLQ) and Gauss–Laguerre Quadrature (GLagQ) for specific test integrals and benchmark their accuracy against analytic results and against a high-resolution grid integration.\n\nFundamental base:\n- The radial neutrino potentials in the closure approximation are generated by Fourier–Bessel transforms that map momentum-space kernels to coordinate space, yielding integrals of the general type\n$$\nH_K(r) = \\int_0^\\infty dq\\, \\mathcal{K}_K(q)\\, j_0(q r),\n$$\nwhere $j_0(x)$ is the spherical Bessel function of order $0$ and $\\mathcal{K}_K(q)$ is a momentum-space kernel stemming from the neutrino propagator and nuclear form factors. This representation follows from the isotropic Fourier transform in three dimensions combined with angular integration.\n- Gauss–Legendre Quadrature integrates functions over finite intervals and is based on the orthogonality of Legendre polynomials on $[-1,1]$.\n- Gauss–Laguerre Quadrature integrates functions over $[0,\\infty)$ with an exponential weight, exploiting the orthogonality of Laguerre polynomials with weight $e^{-x}$.\n\nYou will implement and test the following integrals, each framed in purely mathematical terms to ensure universal applicability. All quantities in this problem are dimensionless; no physical units are required.\n\n1. Laguerre-weighted spherical Bessel transform:\nCompute\n$$\nI_L(r) = \\int_0^\\infty dq\\, e^{-q}\\, j_0(q r),\n$$\nfor specified values of $r$. This integral admits an analytic evaluation that you must use for benchmarking:\n$$\nI_L(r) = \\frac{\\arctan(r)}{r}.\n$$\nImplement Gauss–Laguerre Quadrature with $N_L$ nodes to approximate $I_L(r)$ and report the absolute error against the analytic result.\n\n2. Legendre-based finite-interval transform:\nCompute\n$$\nI_G(r, Q) = \\int_0^{Q} dq\\, q^2\\, j_0(q r),\n$$\nfor specified pairs $(r,Q)$. This integral admits an analytic evaluation that you must use for benchmarking:\n$$\nI_G(r, Q) = \\frac{\\sin(Q r) - Q r \\cos(Q r)}{r^3}.\n$$\nImplement Gauss–Legendre Quadrature with $N_G$ nodes on $[0,Q]$ to approximate $I_G(r,Q)$ and report the absolute error against the analytic result.\n\n3. Neutrino-potential-like regulated integral:\nCompute\n$$\nH(r;\\bar{E},\\Lambda) = \\int_0^\\infty dq\\, e^{-q/\\Lambda}\\, \\frac{q}{q+\\bar{E}}\\, j_0(q r),\n$$\nfor specified triplets $(r,\\bar{E},\\Lambda)$, where $\\bar{E}$ is a closure energy scale and $\\Lambda$ is a regulator scale. This integral does not have a closed-form analytic solution in general. Evaluate it with Gauss–Laguerre Quadrature by performing the change of variables $q = \\Lambda x$ to match the Laguerre weight $e^{-x}$, and benchmark it against a high-resolution grid integration using a composite Simpson rule over a truncated interval $[0,q_{\\max}]$ with $q_{\\max} = \\alpha \\Lambda$, where $\\alpha$ is a large positive number. Report the absolute difference between the Gauss–Laguerre result and the grid result.\n\nAlgorithmic and mathematical requirements:\n- In Gauss–Laguerre Quadrature for an integral of the form $\\int_0^\\infty dx\\, e^{-x}\\, f(x)$, use nodes $x_i$ and weights $w_i$ to approximate the integral by $\\sum_i w_i f(x_i)$.\n- In Gauss–Legendre Quadrature for an integral over $[a,b]$, use nodes $t_i \\in [-1,1]$ and weights $w_i$ and transform by $q_i = \\frac{b-a}{2} t_i + \\frac{b+a}{2}$, $W_i = \\frac{b-a}{2} w_i$, so that $\\int_a^b f(q)\\, dq \\approx \\sum_i W_i f(q_i)$.\n- For the regulated integral $H(r;\\bar{E},\\Lambda)$, use the substitution $q=\\Lambda x$ to write\n$$\nH(r;\\bar{E},\\Lambda) = \\Lambda \\int_0^\\infty dx\\, e^{-x}\\, \\frac{\\Lambda x}{\\Lambda x + \\bar{E}}\\, j_0(\\Lambda x\\, r),\n$$\nwhich is suitable for Gauss–Laguerre Quadrature.\n\nTest suite and parameters:\n- Use $N_L = 64$ nodes for Gauss–Laguerre Quadrature and $N_G = 128$ nodes for Gauss–Legendre Quadrature.\n- For the Laguerre-weighted transform $I_L(r)$, evaluate at $r \\in \\{10^{-3}, 0.5, 1.0, 5.0, 10.0\\}$.\n- For the finite-interval transform $I_G(r,Q)$, evaluate at $(r,Q) \\in \\{(10^{-3},10^{-2}), (0.1,1.0), (1.0,10.0), (3.0,50.0)\\}$.\n- For the regulated integral $H(r;\\bar{E},\\Lambda)$, evaluate at $(r,\\bar{E},\\Lambda) \\in \\{(0.5,1.0,1.0), (2.0,0.1,1.0), (5.0,10.0,0.5), (0.1,0.01,2.0)\\}$. Use $\\alpha = 40$ and a uniform high-resolution grid of $N_{\\text{grid}} = 20001$ points for the Simpson rule over $[0,q_{\\max}]$.\n- All results are dimensionless real numbers.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets.\n- The list must contain $13$ floating-point numbers in the following order:\n    1. The five absolute errors for $I_L(r)$ at the specified $r$ values, in the order given.\n    2. The four absolute errors for $I_G(r,Q)$ at the specified $(r,Q)$ pairs, in the order given.\n    3. The four absolute differences for $H(r;\\bar{E},\\Lambda)$ between Gauss–Laguerre and high-resolution grid evaluations at the specified triplets, in the order given.", "solution": "The problem of computing momentum-space integrals for neutrino potentials is addressed by implementing and benchmarking established numerical quadrature techniques. The solution is structured into three parts, each corresponding to one of the specified integrals. The core of the solution relies on Gaussian quadrature, a powerful method for numerical integration that provides high accuracy with a relatively small number of function evaluations.\n\nThe foundational principle of Gaussian quadrature is to approximate an integral by a weighted sum of the integrand's values at specific points, known as nodes. For an integral of the form $\\int_a^b W(x) f(x) dx$, where $W(x)$ is a weight function, the approximation is given by:\n$$\n\\int_a^b W(x) f(x) dx \\approx \\sum_{i=1}^{N} w_i f(x_i)\n$$\nThe nodes $x_i$ and weights $w_i$ are chosen to yield an exact result for polynomials of degree up to $2N-1$. The specific choice of nodes and weights depends on the weight function $W(x)$ and the integration interval $[a,b]$, which define a family of orthogonal polynomials. This implementation utilizes the `numpy` library for numerical array operations and the `scipy` library for its special functions and high-precision quadrature routines.\n\n1.  **Laguerre-weighted spherical Bessel transform: $I_L(r)$**\n\n    The first integral to be computed is\n    $$\n    I_L(r) = \\int_0^\\infty dq\\, e^{-q}\\, j_0(q r)\n    $$\n    This integral matches the canonical form for Gauss–Laguerre Quadrature (GLagQ), $\\int_0^\\infty e^{-x} f(x) dx$, where the integration variable is $q=x$ and the function is $f(q) = j_0(q r)$. The quadrature rule is therefore a direct application of the GLagQ formula:\n    $$\n    I_L(r) \\approx \\sum_{i=1}^{N_L} w_i j_0(q_i r)\n    $$\n    Here, $\\{q_i\\}$ and $\\{w_i\\}$ are the $N_L = 64$ nodes and weights for GLagQ, which are obtained using the `scipy.special.roots_laguerre` function. The spherical Bessel function of order zero, $j_0(x) = \\sin(x)/x$, is computed using the numerically stable `scipy.special.spherical_jn` function. The accuracy of the numerical result is benchmarked by calculating the absolute error against the provided analytic solution, $I_L(r) = \\frac{\\arctan(r)}{r}$.\n\n2.  **Legendre-based finite-interval transform: $I_G(r, Q)$**\n\n    The second integral is defined over a finite interval $[0, Q]$:\n    $$\n    I_G(r, Q) = \\int_0^{Q} dq\\, q^2\\, j_0(q r)\n    $$\n    This form is suited for Gauss–Legendre Quadrature (GLQ), which is defined on the standard interval $[-1,1]$. A linear change of variables is required to map the standard nodes $t_i \\in [-1,1]$ and weights $w_i$ to the interval $[0, Q]$. The transformation is:\n    $$\n    q_i = \\frac{Q}{2}(t_i + 1), \\quad W_i = \\frac{Q}{2}w_i\n    $$\n    The integral is then approximated as a sum over the transformed nodes and weights:\n    $$\n    I_G(r, Q) \\approx \\sum_{i=1}^{N_G} W_i q_i^2 j_0(q_i r)\n    $$\n    The standard nodes $\\{t_i\\}$ and weights $\\{w_i\\}$ for $N_G = 128$ points are obtained from `scipy.special.roots_legendre`. For benchmarking, the numerical result is compared to the analytic formula $I_G(r, Q) = \\frac{\\sin(Q r) - Q r \\cos(Q r)}{r^3}$. A crucial implementation detail is the handling of the analytic formula for small values of the argument $x = Qr$. Direct computation can suffer from catastrophic cancellation. To ensure high accuracy, a Taylor series expansion, $\\frac{\\sin(x) - x\\cos(x)}{x^3} = \\frac{1}{3} - \\frac{x^2}{30} + O(x^4)$, is used when $|Qr|$ is small.\n\n3.  **Neutrino-potential-like regulated integral: $H(r;\\bar{E},\\Lambda)$**\n\n    The third integral is more complex and lacks a simple analytic solution:\n    $$\n    H(r;\\bar{E},\\Lambda) = \\int_0^\\infty dq\\, e^{-q/\\Lambda}\\, \\frac{q}{q+\\bar{E}}\\, j_0(q r)\n    $$\n    This integral is evaluated using two different methods, and their results are compared.\n\n    **a) Gauss–Laguerre Quadrature:**\n    To apply GLagQ, the exponential term $e^{-q/\\Lambda}$ must be converted to the canonical weight $e^{-x}$. This is achieved via the substitution $q = \\Lambda x$, which gives $dq = \\Lambda dx$. The integral transforms to:\n    $$\n    H(r;\\bar{E},\\Lambda) = \\Lambda \\int_0^\\infty dx\\, e^{-x}\\, \\left(\\frac{\\Lambda x}{\\Lambda x + \\bar{E}}\\right)\\, j_0(\\Lambda x\\, r)\n    $$\n    This is now in the standard GLagQ form with integrand $f(x) = \\left(\\frac{\\Lambda x}{\\Lambda x + \\bar{E}}\\right)\\, j_0(\\Lambda x\\, r)$. The integral is approximated as $\\Lambda \\sum_i w_i f(x_i)$, using $N_L=64$ GLagQ nodes and weights.\n\n    **b) High-Resolution Grid Integration (Benchmark):**\n    As a benchmark, the integral is computed using a composite Simpson's rule, a robust method for numerical integration over a grid. The infinite integration interval is truncated to a finite one, $[0, q_{\\max}]$, where $q_{\\max} = \\alpha \\Lambda$ with $\\alpha=40$ chosen to be large enough to make the contribution from the tail negligible due to the exponential factor $e^{-q/\\Lambda}$. A uniform grid of $N_{\\text{grid}} = 20001$ points is constructed over this interval. The original integrand is evaluated at each grid point, and the `scipy.integrate.simpson` function is used to compute the integral from these discrete values.\n\n    The final reported value for this part is the absolute difference between the result from the GLagQ method and the Simpson's rule benchmark, providing a measure of the accuracy of the GLagQ approach for this type of regulated integral.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import special, integrate\n\ndef solve():\n    \"\"\"\n    Main function to perform all calculations and print the final result.\n    \"\"\"\n\n    # --- Helper Functions ---\n\n    def j0(x):\n        \"\"\"Numerically stable spherical Bessel function of order 0, j_0(x) = sin(x)/x.\"\"\"\n        return special.spherical_jn(0, x)\n\n    # --- Part 1: Laguerre-weighted spherical Bessel transform ---\n\n    def calculate_IL(r, N_L):\n        \"\"\"\n        Computes I_L(r) = integral(0, inf) dq exp(-q) j_0(q*r) using Gauss-Laguerre quadrature\n        and compares it to the analytic result arctan(r)/r.\n        \"\"\"\n        # Get Gauss-Laguerre nodes and weights for N_L points\n        nodes, weights = special.roots_laguerre(N_L)\n        \n        # The integrand for GLagQ is f(q) = j_0(q*r).\n        # The approximation is sum(w_i * f(q_i)).\n        integrand_values = j0(nodes * r)\n        numerical_result = np.sum(weights * integrand_values)\n        \n        # Analytic result: arctan(r)/r. For r=0, the limit is 1.\n        if r == 0.0:\n            analytic_result = 1.0\n        else:\n            analytic_result = np.arctan(r) / r\n            \n        return np.abs(numerical_result - analytic_result)\n\n    # --- Part 2: Legendre-based finite-interval transform ---\n\n    def calculate_IG(r, Q, N_G):\n        \"\"\"\n        Computes I_G(r, Q) = integral(0, Q) dq q^2 j_0(q*r) using Gauss-Legendre quadrature\n        and compares it to the analytic result (sin(Qr)-Qr*cos(Qr))/r^3.\n        \"\"\"\n        # Get standard Gauss-Legendre nodes and weights on [-1, 1]\n        t_nodes, t_weights = special.roots_legendre(N_G)\n        \n        # Transform nodes and weights for the interval [0, Q]\n        q_nodes = 0.5 * Q * (t_nodes + 1.0)\n        W_weights = 0.5 * Q * t_weights\n        \n        # Integrand f(q) = q^2 * j_0(q*r)\n        integrand_values = q_nodes**2 * j0(q_nodes * r)\n        numerical_result = np.sum(W_weights * integrand_values)\n        \n        # Analytic result. A Taylor expansion is used for small |Qr| to avoid catastrophic cancellation.\n        # f(x) = (sin(x)-x*cos(x))/x^3 = 1/3 - x^2/30 + O(x^4)\n        x = Q * r\n        if np.abs(x)  1e-4:\n            analytic_result = (Q**3 / 3.0) * (1.0 - x**2 / 10.0) # This is (Q^3/3 - Q^5 r^2 / 30)\n        else:\n            analytic_result = (np.sin(x) - x * np.cos(x)) / r**3\n            \n        return np.abs(numerical_result - analytic_result)\n\n    #--- Part 3: Neutrino-potential-like regulated integral comparison ---\n\n    def calculate_H_glag(r, E_bar, Lambda, N_L):\n        \"\"\"\n        Computes H(r; E_bar, Lambda) with Gauss-Laguerre quadrature after a change of variables q = Lambda*x.\n        \"\"\"\n        # Get Gauss-Laguerre nodes and weights\n        x_nodes, weights = special.roots_laguerre(N_L)\n        \n        # Integrand for GLagQ f(x) = (Lambda*x)/(Lambda*x + E_bar) * j_0(Lambda*x*r)\n        # Total integral is Lambda * sum(w_i * f(x_i))\n        numerator = Lambda * x_nodes\n        denominator = Lambda * x_nodes + E_bar\n        j0_arg = Lambda * x_nodes * r\n        \n        integrand_values = (numerator / denominator) * j0(j0_arg)\n        \n        numerical_result = Lambda * np.sum(weights * integrand_values)\n        return numerical_result\n\n    def calculate_H_simpson(r, E_bar, Lambda, alpha, N_grid):\n        \"\"\"\n        Computes H(r; E_bar, Lambda) using Simpson's rule on a high-resolution grid as a benchmark.\n        \"\"\"\n        # Define integration range [0, q_max] and grid\n        q_max = alpha * Lambda\n        q_grid = np.linspace(0, q_max, N_grid)\n        \n        # The original integrand g(q) = exp(-q/Lambda) * (q/(q+E_bar)) * j_0(q*r)\n        # Since E_bar > 0 in test cases, direct evaluation is safe. The term with q is 0 at q=0.\n        integrand_values = np.exp(-q_grid / Lambda) * (q_grid / (q_grid + E_bar)) * j0(q_grid * r)\n\n        # Compute integral using Simpson's rule\n        numerical_result = integrate.simpson(integrand_values, q_grid)\n        return numerical_result\n\n    # --- Main Execution Logic ---\n\n    # Define parameters from problem statement\n    N_L = 64\n    N_G = 128\n    alpha = 40.0\n    N_grid = 20001\n    \n    # Define test cases\n    test_cases_L = [1e-3, 0.5, 1.0, 5.0, 10.0]\n    test_cases_G = [(1e-3, 1e-2), (0.1, 1.0), (1.0, 10.0), (3.0, 50.0)]\n    test_cases_H = [(0.5, 1.0, 1.0), (2.0, 0.1, 1.0), (5.0, 10.0, 0.5), (0.1, 0.01, 2.0)]\n    \n    results = []\n    \n    # Run Part 1\n    for r_val in test_cases_L:\n        error = calculate_IL(r_val, N_L)\n        results.append(error)\n        \n    # Run Part 2\n    for r_val, Q_val in test_cases_G:\n        error = calculate_IG(r_val, Q_val, N_G)\n        results.append(error)\n        \n    # Run Part 3\n    for r_val, E_bar_val, Lambda_val in test_cases_H:\n        res_glag = calculate_H_glag(r_val, E_bar_val, Lambda_val, N_L)\n        res_simpson = calculate_H_simpson(r_val, E_bar_val, Lambda_val, alpha, N_grid)\n        diff = np.abs(res_glag - res_simpson)\n        results.append(diff)\n        \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3572950"}, {"introduction": "A full calculation of the nuclear matrix element would require summing over a vast, often infinite, set of virtual intermediate nuclear states, each with a unique energy denominator. This is computationally intractable, leading to the near-universal adoption of the closure approximation, where the energy of every intermediate state is replaced by a single average value, $\\bar{E}$. This practice, [@problem_id:3572951], guides you through a direct, quantitative comparison of the full nonclosure summation and the closure approximation within a simplified but physically faithful model. Completing this exercise will provide invaluable insight into the consequences of this pivotal approximation and the conditions under which it is most reliable.", "problem": "Consider a simplified but scientifically faithful model of neutrinoless double beta decay (NDBD) nuclear matrix element calculations that isolates the contribution of intermediate states with total angular momentum and parity $J^\\pi = 0^+$ and $J^\\pi = 1^+$ in a nonclosure scheme and compares them with a closure approximation. The goal is to design and implement a program that computes and compares these contributions based on first principles: linearity of amplitudes, additivity over intermediate states, and the dependence on intermediate-state excitation energies via an energy denominator.\n\nFundamental base and model setup:\n- In second-order weak processes, summation over intermediate states arises from time-ordered perturbation theory, and energy denominators encode the propagation of virtual states. In the nonclosure scheme, each intermediate state with excitation energy contributes with its own energy denominator. In the closure approximation (CA), the energy denominator is approximated by a single effective closure energy, which removes explicit dependence on individual intermediate state energies while preserving additivity over states.\n- We factorize the many-body structure into reduced dimensionless strengths $s_k^{(J)}$ that encode the radial and spin-isospin overlaps to intermediate state $k$ of multipole $J$. The momentum transfer dependence is encoded through a neutrino potential integral, approximated here in a dimensionless form to eliminate unit dependencies while retaining the qualitative functional dependence on the energy denominator.\n\nDefinitions:\n- Let $x$ denote a dimensionless momentum variable and let $d$ denote a dimensionless energy denominator. Both are defined by scaling physical momentum $q$ and energy denominator $\\Delta$ by a common positive scale $\\Lambda$, i.e., $x = q/\\Lambda$ and $d = \\Delta/\\Lambda$. The upper limit $x_{\\max} = q_{\\max}/\\Lambda$ controls the numerical range of the integral.\n- Define a dipole-like regulator $F(x) = \\left(1 + x^2\\right)^{-2}$ to mimic finite-size and form-factor effects. Define the dimensionless neutrino potential integral\n$$\nI(d) = \\int_{0}^{x_{\\max}} \\frac{x^2}{x + d}\\,F(x)\\,dx = \\int_{0}^{x_{\\max}} \\frac{x^2}{(x+d)\\left(1+x^2\\right)^2}\\,dx,\n$$\nwith $d  0$ and $x_{\\max}  0$. This integral is finite for any positive $d$ and $x_{\\max}$.\n- The reduced nonclosure contributions for the two multipoles are defined as\n$$\nM_{0^+}^{\\mathrm{non}} = g_V^2 \\sum_{k=1}^{N_{0^+}} s_k^{(0^+)}\\,I\\!\\left(d_k^{(0^+)}\\right),\\quad\nM_{1^+}^{\\mathrm{non}} = g_A^2 \\sum_{k=1}^{N_{1^+}} s_k^{(1^+)}\\,I\\!\\left(d_k^{(1^+)}\\right),\n$$\nwhere $g_V$ and $g_A$ are the vector and axial-vector couplings, respectively, and $d_k^{(J)}$ are the dimensionless denominators corresponding to the $k$-th intermediate state in multipole $J$.\n- In the closure approximation,\n$$\nM_{0^+}^{\\mathrm{cl}} = g_V^2\\left(\\sum_{k=1}^{N_{0^+}} s_k^{(0^+)}\\right) I\\!\\left(\\bar{d}_{0^+}\\right),\\quad\nM_{1^+}^{\\mathrm{cl}} = g_A^2\\left(\\sum_{k=1}^{N_{1^+}} s_k^{(1^+)}\\right) I\\!\\left(\\bar{d}_{1^+}\\right),\n$$\nwith $\\bar{d}_{J}$ a chosen effective closure denominator for multipole $J$.\n\nConstruction of denominators:\n- For each intermediate state $k$ of multipole $J$, define the dimensionless denominator by $d_k^{(J)} = \\left(E_0 + \\epsilon_k^{(J)}\\right)/\\Lambda$, where $E_0$ is an offset accounting for average kinematics and $\\epsilon_k^{(J)}$ is the excitation energy of the intermediate state. The closure denominators are defined by $\\bar{d}_{J} = \\bar{E}_J/\\Lambda$.\n\nTask:\n- Implement a program that evaluates $I(d)$ numerically and computes $M_{0^+}^{\\mathrm{non}}$, $M_{1^+}^{\\mathrm{non}}$, $M_{0^+}^{\\mathrm{cl}}$, and $M_{1^+}^{\\mathrm{cl}}$ for each test case listed below.\n- For each test case, produce the three floats:\n  - $\\Delta M_{0^+} = M_{0^+}^{\\mathrm{non}} - M_{0^+}^{\\mathrm{cl}}$,\n  - $\\Delta M_{1^+} = M_{1^+}^{\\mathrm{non}} - M_{1^+}^{\\mathrm{cl}}$,\n  - $\\Delta M_{\\mathrm{tot}} = \\left(M_{0^+}^{\\mathrm{non}} + M_{1^+}^{\\mathrm{non}}\\right) - \\left(M_{0^+}^{\\mathrm{cl}} + M_{1^+}^{\\mathrm{cl}}\\right)$.\n- All outputs are to be reported as dimensionless numbers.\n\nNumerical integration requirements:\n- Use a reliable numerical quadrature to evaluate $I(d)$ for each needed $d  0$ to at least modest absolute tolerance. The integrand has no singularity on the integration interval since $d  0$ and $x \\in [0,x_{\\max}]$ with $x_{\\max}  0$.\n\nConstants used in all tests:\n- Vector coupling $g_V = 1.0$ (dimensionless).\n- Axial-vector coupling $g_A = 1.27$ (dimensionless).\n- Scale $\\Lambda = 850.0$ (same unit as energies).\n- Maximum momentum $q_{\\max} = 2000.0$ (same unit as energies), hence $x_{\\max} = q_{\\max}/\\Lambda$.\n- The outputs are dimensionless.\n\nTest suite:\n- Test case $1$ (general case with mixed signs and nondegenerate denominators):\n  - Offset $E_0 = 10.0$.\n  - For $J^\\pi = 0^+$: three states with strengths $s^{(0^+)} = \\{0.6,\\,0.3,\\,-0.1\\}$ and excitations $\\epsilon^{(0^+)} = \\{2.0,\\,5.0,\\,8.0\\}$. Closure energy $\\bar{E}_{0^+} = 12.0$.\n  - For $J^\\pi = 1^+$: four states with strengths $s^{(1^+)} = \\{0.5,\\,-0.2,\\,0.4,\\,0.1\\}$ and excitations $\\epsilon^{(1^+)} = \\{1.0,\\,3.0,\\,6.0,\\,9.0\\}$. Closure energy $\\bar{E}_{1^+} = 13.0$.\n- Test case $2$ (degenerate denominators yield exact closure equivalence if the same closure is used):\n  - Offset $E_0 = 10.0$.\n  - For $J^\\pi = 0^+$: four states with strengths $s^{(0^+)} = \\{0.3,\\,0.4,\\,-0.1,\\,0.2\\}$ and excitations $\\epsilon^{(0^+)} = \\{4.0,\\,4.0,\\,4.0,\\,4.0\\}$. Closure energy $\\bar{E}_{0^+} = 14.0$.\n  - For $J^\\pi = 1^+$: five states with strengths $s^{(1^+)} = \\{0.5,\\,-0.2,\\,0.2,\\,0.1,\\,0.3\\}$ and excitations $\\epsilon^{(1^+)} = \\{4.0,\\,4.0,\\,4.0,\\,4.0,\\,4.0\\}$. Closure energy $\\bar{E}_{1^+} = 14.0$.\n- Test case $3$ (zero-sum strengths make the closure value vanish, but the nonclosure generally does not):\n  - Offset $E_0 = 10.0$.\n  - For $J^\\pi = 0^+$: two states with strengths $s^{(0^+)} = \\{1.0,\\,-1.0\\}$ and excitations $\\epsilon^{(0^+)} = \\{2.0,\\,10.0\\}$. Closure energy $\\bar{E}_{0^+} = 12.0$.\n  - For $J^\\pi = 1^+$: four states with strengths $s^{(1^+)} = \\{0.8,\\,-0.8,\\,0.5,\\,-0.5\\}$ and excitations $\\epsilon^{(1^+)} = \\{1.0,\\,4.0,\\,7.0,\\,10.0\\}$. Closure energy $\\bar{E}_{1^+} = 11.0$.\n\nAngle units do not apply, and no physical unit is to be reported in the outputs since the model is constructed to be dimensionless.\n\nFinal output format:\n- Your program should produce a single line of output containing all results for the test suite as a single comma-separated list enclosed in square brackets. The order is:\n  - First test case: $\\Delta M_{0^+}$, $\\Delta M_{1^+}$, $\\Delta M_{\\mathrm{tot}}$,\n  - Second test case: $\\Delta M_{0^+}$, $\\Delta M_{1^+}$, $\\Delta M_{\\mathrm{tot}}$,\n  - Third test case: $\\Delta M_{0^+}$, $\\Delta M_{1^+}$, $\\Delta M_{\\mathrm{tot}}$.\n- For example, the program must print a line of the form $[\\text{v}_1,\\text{v}_2,\\text{v}_3,\\text{v}_4,\\text{v}_5,\\text{v}_6,\\text{v}_7,\\text{v}_8,\\text{v}_9]$, where each $\\text{v}_i$ is a float.", "solution": "The problem statement has been validated and is deemed scientifically grounded, well-posed, and self-contained. It presents a simplified but faithful computational model for evaluating and comparing non-closure and closure-approximation-based nuclear matrix elements for neutrinoless double beta decay. All parameters and definitions are provided, and the task is a clear, formalizable computational procedure.\n\nThe solution proceeds by first implementing the core mathematical objects and then assembling them into a complete algorithm that processes the specified test cases.\n\nThe fundamental computational kernel is the dimensionless neutrino potential integral, defined as:\n$$\nI(d) = \\int_{0}^{x_{\\max}} \\frac{x^2}{(x+d)\\left(1+x^2\\right)^2}\\,dx\n$$\nwhere $d  0$ is the dimensionless energy denominator and $x_{\\max}  0$ is the dimensionless momentum cutoff. The integrand is a smooth, non-singular rational function for $x \\in [0, x_{\\max}]$ and $d  0$. This integral will be evaluated numerically using a robust quadrature algorithm. The `scipy.integrate.quad` function, which implements an adaptive quadrature scheme, is an excellent choice for this purpose, providing high accuracy. The constants defining the integration range are $q_{\\max} = 2000.0$ and $\\Lambda = 850.0$, yielding an upper integration limit of $x_{\\max} = q_{\\max}/\\Lambda \\approx 2.3529$.\n\nThe overall algorithm is structured to handle each test case by calculating the required matrix elements for the $J^\\pi=0^+$ and $J^\\pi=1^+$ multipoles. For a generic multipole $J$, the non-closure matrix element, $M_J^{\\mathrm{non}}$, is computed by summing the contributions from each intermediate state $k$:\n$$\nM_{J}^{\\mathrm{non}} = g_J^2 \\sum_{k=1}^{N_J} s_k^{(J)}\\,I\\!\\left(d_k^{(J)}\\right)\n$$\nHere, $g_J$ is the coupling constant ($g_V=1.0$ for $J=0^+$, $g_A=1.27$ for $J=1^+$), $s_k^{(J)}$ is the reduced strength of the $k$-th state, and $d_k^{(J)}$ is its dimensionless energy denominator. The denominator for each state is calculated from the provided offset $E_0$ and excitation energy $\\epsilon_k^{(J)}$ as:\n$$\nd_k^{(J)} = \\frac{E_0 + \\epsilon_k^{(J)}}{\\Lambda}\n$$\nThe calculation involves iterating through the list of intermediate states for a given multipole, computing $d_k^{(J)}$ for each, evaluating $I(d_k^{(J)})$ numerically, multiplying by the corresponding strength $s_k^{(J)}$, and accumulating the sum. This sum is then scaled by the square of the appropriate coupling constant.\n\nThe corresponding closure-approximation matrix element, $M_J^{\\mathrm{cl}}$, is computed by first summing all strengths and then multiplying by the potential integral evaluated at a single effective closure denominator $\\bar{d}_J$:\n$$\nM_{J}^{\\mathrm{cl}} = g_J^2\\left(\\sum_{k=1}^{N_J} s_k^{(J)}\\right) I\\!\\left(\\bar{d}_{J}\\right)\n$$\nThe closure denominator $\\bar{d}_J$ is determined by the given effective closure energy $\\bar{E}_J$ as:\n$$\n\\bar{d}_{J} = \\frac{\\bar{E}_J}{\\Lambda}\n$$\nThe implementation will first calculate the total sum of strengths $\\sum_k s_k^{(J)}$. If this sum is non-zero, it will compute $\\bar{d}_J$, evaluate $I(\\bar{d}_J)$, and then compute $M_J^{\\mathrm{cl}}$. If the sum of strengths is zero, $M_J^{\\mathrm{cl}}$ is necessarily zero.\n\nFor each test case and for each multipole ($J=0^+, 1^+$), we compute the difference $\\Delta M_J = M_J^{\\mathrm{non}} - M_J^{\\mathrm{cl}}$. Finally, the total difference is computed as the sum of the individual differences: $\\Delta M_{\\mathrm{tot}} = \\Delta M_{0^+} + \\Delta M_{1^+}$.\n\nThe program will be structured to process a list of test cases, each containing the parameters ($E_0$, lists of strengths $s_k$ and excitations $\\epsilon_k$, and closure energies $\\bar{E}_J$). For each case, it will execute the above logic to find $(\\Delta M_{0^+}, \\Delta M_{1^+}, \\Delta M_{\\mathrm{tot}})$, and collect these triplets from all test cases into a single flat list. This list will be formatted into the required string output. The implementation will use `NumPy` for efficient array operations and `SciPy` for numerical integration, adhering to the specified execution environment.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import quad\n\ndef solve():\n    \"\"\"\n    Main function to solve the neutrinoless double beta decay matrix element problem.\n    \"\"\"\n    # Define global constants given in the problem statement.\n    G_V = 1.0\n    G_A = 1.27\n    LAMBDA = 850.0\n    Q_MAX = 2000.0\n    X_MAX = Q_MAX / LAMBDA\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            # Test case 1 (general case)\n            \"E0\": 10.0,\n            \"0+\": {\n                \"s\": [0.6, 0.3, -0.1],\n                \"eps\": [2.0, 5.0, 8.0],\n                \"E_bar\": 12.0\n            },\n            \"1+\": {\n                \"s\": [0.5, -0.2, 0.4, 0.1],\n                \"eps\": [1.0, 3.0, 6.0, 9.0],\n                \"E_bar\": 13.0\n            }\n        },\n        {\n            # Test case 2 (degenerate denominators)\n            \"E0\": 10.0,\n            \"0+\": {\n                \"s\": [0.3, 0.4, -0.1, 0.2],\n                \"eps\": [4.0, 4.0, 4.0, 4.0],\n                \"E_bar\": 14.0\n            },\n            \"1+\": {\n                \"s\": [0.5, -0.2, 0.2, 0.1, 0.3],\n                \"eps\": [4.0, 4.0, 4.0, 4.0, 4.0],\n                \"E_bar\": 14.0\n            }\n        },\n        {\n            # Test case 3 (zero-sum strengths)\n            \"E0\": 10.0,\n            \"0+\": {\n                \"s\": [1.0, -1.0],\n                \"eps\": [2.0, 10.0],\n                \"E_bar\": 12.0\n            },\n            \"1+\": {\n                \"s\": [0.8, -0.8, 0.5, -0.5],\n                \"eps\": [1.0, 4.0, 7.0, 10.0],\n                \"E_bar\": 11.0\n            }\n        }\n    ]\n\n    # Memoization cache for the integral function to avoid re-computation.\n    integral_cache = {}\n\n    def integrand(x, d):\n        \"\"\"The integrand for the neutrino potential integral I(d).\"\"\"\n        return (x**2) / ((x + d) * (1 + x**2)**2)\n\n    def I(d):\n        \"\"\"Numerically evaluates the neutrino potential integral I(d).\"\"\"\n        if d in integral_cache:\n            return integral_cache[d]\n        \n        # Using quad for high-precision numerical integration.\n        # The absolute error tolerance ensures sufficient accuracy.\n        result, _ = quad(integrand, 0, X_MAX, args=(d,), epsabs=1e-12)\n        integral_cache[d] = result\n        return result\n\n    def calculate_matrix_elements(E0, multipole_data, g_coupling):\n        \"\"\"\n        Calculates non-closure and closure matrix elements for a single multipole.\n        \"\"\"\n        strengths = np.array(multipole_data[\"s\"])\n        excitations = np.array(multipole_data[\"eps\"])\n        closure_energy = multipole_data[\"E_bar\"]\n\n        # Non-closure calculation\n        m_non = 0.0\n        for s_k, eps_k in zip(strengths, excitations):\n            d_k = (E0 + eps_k) / LAMBDA\n            m_non += s_k * I(d_k)\n        \n        m_non *= g_coupling**2\n\n        # Closure calculation\n        sum_s = np.sum(strengths)\n        d_bar = closure_energy / LAMBDA\n        m_cl = sum_s * I(d_bar)\n        m_cl *= g_coupling**2\n        \n        return m_non, m_cl\n\n    results = []\n    for case in test_cases:\n        # Process J^pi = 0+ multipole\n        m_non_0, m_cl_0 = calculate_matrix_elements(case[\"E0\"], case[\"0+\"], G_V)\n        delta_m_0 = m_non_0 - m_cl_0\n        \n        # Process J^pi = 1+ multipole\n        m_non_1, m_cl_1 = calculate_matrix_elements(case[\"E0\"], case[\"1+\"], G_A)\n        delta_m_1 = m_non_1 - m_cl_1\n        \n        # Total difference\n        delta_m_tot = delta_m_0 + delta_m_1\n        \n        results.extend([delta_m_0, delta_m_1, delta_m_tot])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```", "id": "3572951"}, {"introduction": "A theoretical prediction is only as valuable as its uncertainty quantification. In large-scale nuclear structure calculations, the final matrix element is sensitive to several numerical and model-based choices, such as the size of the single-particle basis ($N_{\\max}$), the parameters of that basis (like the harmonic oscillator frequency $\\hbar\\omega$), and the precision of numerical integrations. This capstone exercise, [@problem_id:3572952], challenges you to perform a systematic convergence study and construct a complete error budget for a model calculation. This practice develops the essential skill of assessing the robustness of a computational result, a critical step for producing reliable and publishable scientific work.", "problem": "You are tasked with implementing a self-contained numerical study of the neutrinoless double beta decay nuclear matrix element, denoted by $M^{0\\nu}$, to assess systematic convergence with respect to three independent numerical controls and to report an error budget. The study must be conducted using first-principles, physically motivated definitions under a simplified, but scientifically plausible, model.\n\nStart from the following fundamental and well-tested bases in computational nuclear physics:\n\n- Under the closure approximation, the dimensionless nuclear matrix element $M^{0\\nu}$ can be constructed from radial integrals of a neutrino-exchange potential coupled to single-particle radial densities. For a Spherical Harmonic Oscillator (HO) basis, the single-particle radial wave functions are\n$$\nR_{nl}(r) = \\mathcal{N}_{nl} \\left(\\frac{r}{b}\\right)^l e^{-\\frac{r^2}{2b^2}} L_{n}^{l+\\frac{1}{2}}\\!\\left(\\frac{r^2}{b^2}\\right),\n$$\nwhere $n$ is the radial quantum number, $l$ is the orbital angular momentum, $b$ is the HO length, $L_{n}^{\\alpha}(x)$ is the generalized Laguerre polynomial, and $\\mathcal{N}_{nl}$ is the normalization factor chosen such that $\\int_{0}^{\\infty} r^2 \\left|R_{nl}(r)\\right|^2 dr = 1$. The normalization is\n$$\n\\mathcal{N}_{nl} = \\sqrt{\\frac{2\\,\\Gamma(n+1)}{b^3\\,\\Gamma\\!\\left(n + l + \\frac{3}{2}\\right)}},\n$$\nwith $\\Gamma(\\cdot)$ the gamma function. The HO length is\n$$\nb = \\frac{\\hbar}{\\sqrt{m_N \\hbar\\omega}},\n$$\nexpressed in natural nuclear units with $\\hbar$ in $\\mathrm{MeV}\\cdot\\mathrm{fm}$, $m_N$ in $\\mathrm{MeV}$, and $\\hbar\\omega$ in $\\mathrm{MeV}$.\n\n- A widely used screened neutrino potential approximation that yields a dimensionless matrix element is\n$$\nH(r) = \\frac{R\\,e^{-\\mu r}}{r},\n$$\nwhere $R = r_0 A^{1/3}$ is the nuclear radius with $r_0$ a constant and $A$ the mass number, and $\\mu$ is an inverse-length screening parameter. When multiplied by the dimensionless density factor $r^2 \\left|R_{nl}(r)\\right|^2$, the integrand is integrable at $r=0$.\n\n- Define a model-space truncation by the HO major-shell quantum number $K = 2n + l$, and include states up to $K \\leq N_{\\max}$. To mimic pairing-driven occupation and degeneracy, weight each state by\n$$\nw_{nl} = D_l\\,g_{nl}, \\quad D_l = 2l + 1, \\quad g_{nl} = g_0\\,e^{-\\alpha (2n + l)},\n$$\nwhere $D_l$ is the magnetic degeneracy, and $g_0$ and $\\alpha$ are positive constants.\n\nUnder these definitions, construct\n$$\nI_{nl} = \\int_{0}^{r_{\\max}} r^2 \\left[R_{nl}(r)\\right]^2 H(r)\\,dr,\n$$\nand\n$$\nM^{0\\nu}(N_{\\max}, \\hbar\\omega, N_r) = \\sum_{\\substack{l \\ge 0 \\\\ 2n + l \\le N_{\\max}}} \\sum_{n \\ge 0} w_{nl}\\,I_{nl},\n$$\nwhere the radial integral is to be evaluated numerically on a uniform mesh of $N_r$ points over $[0, r_{\\max}]$ using the Simpson rule, and $r_{\\max} = \\beta b$ with $\\beta$ a dimensionless factor set per test case. All lengths must be handled in femtometers ($\\mathrm{fm}$), all energies in megaelectronvolts ($\\mathrm{MeV}$), and the final $M^{0\\nu}$ is dimensionless. Use $\\hbar = 197.326\\,\\mathrm{MeV}\\cdot\\mathrm{fm}$, $m_N = 939.0\\,\\mathrm{MeV}$, and $r_0 = 1.2\\,\\mathrm{fm}$.\n\nPerform systematic convergence tests as follows:\n\n1. Model-space size sensitivity: vary $N_{\\max}$ across a provided set and define the model-space truncation error as the absolute difference between $M^{0\\nu}$ at the largest two $N_{\\max}$ values, computed at the central oscillator frequency and the finest mesh.\n2. Oscillator frequency sensitivity: vary $\\hbar\\omega$ across a provided set and define the frequency error as one-half the range of $M^{0\\nu}$ across that set, computed at the largest $N_{\\max}$ and the finest mesh.\n3. Radial mesh sensitivity: vary $N_r$ across a provided set and define the mesh error as the absolute difference between $M^{0\\nu}$ at the largest two $N_r$ values, computed at the largest $N_{\\max}$ and the central $\\hbar\\omega$.\n\nDefine the central value as $M^{0\\nu}$ at the largest $N_{\\max}$, the central $\\hbar\\omega$ (the median of the provided set; if only one value is given, use that), and the finest mesh $N_r$. The total error must be the quadrature combination of the three components.\n\nImplement the above using the following fixed constants: $g_0 = 1$ and $\\alpha = 0.4$, and use the screened neutrino parameter $\\mu$ provided per test case. If the Simpson rule requires an odd number of sample points, adjust $N_r$ to the nearest higher odd integer internally while preserving the intent of the test case. At $r=0$, evaluate the integrand via its limiting behavior and ensure numerical stability by taking the integrand to be $0$ at the mesh origin.\n\nYour program must execute the study for the following test suite:\n\n- Test case $1$: $A = 76$, $\\mu = 0.5\\,\\mathrm{fm}^{-1}$, $N_{\\max} \\in \\{4, 6, 8\\}$, $\\hbar\\omega \\in \\{10, 12, 14\\}\\,\\mathrm{MeV}$, $N_r \\in \\{200, 400\\}$, $\\beta = 8.0$.\n- Test case $2$: $A = 136$, $\\mu = 0.45\\,\\mathrm{fm}^{-1}$, $N_{\\max} \\in \\{6, 8, 10\\}$, $\\hbar\\omega \\in \\{8, 10, 12\\}\\,\\mathrm{MeV}$, $N_r \\in \\{300, 600\\}$, $\\beta = 9.0$.\n- Test case $3$: $A = 48$, $\\mu = 0.5\\,\\mathrm{fm}^{-1}$, $N_{\\max} \\in \\{2, 4\\}$, $\\hbar\\omega \\in \\{12\\}\\,\\mathrm{MeV}$, $N_r \\in \\{50, 100\\}$, $\\beta = 6.0$.\n\nFor each test case, compute and return a list $[M_{\\mathrm{central}}, \\Delta_{\\mathrm{model}}, \\Delta_{\\omega}, \\Delta_{\\mathrm{mesh}}, \\Delta_{\\mathrm{total}}]$, where all entries are dimensionless decimal floats with no units. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with one such list per test case, preserving order. For example, the output must look like $[[x_1,x_2,x_3,x_4,x_5],[y_1,y_2,y_3,y_4,y_5],[z_1,z_2,z_3,z_4,z_5]]$, where $x_i$, $y_i$, and $z_i$ are the computed floats for the three test cases.", "solution": "The problem requires the implementation of a numerical study to calculate the neutrinoless double beta decay nuclear matrix element, denoted $M^{0\\nu}$, within a simplified but physically grounded model. The study involves assessing the convergence of $M^{0\\nu}$ with respect to three key numerical parameters: the model-space size ($N_{\\max}$), the harmonic oscillator frequency ($\\hbar\\omega$), and the radial integration mesh size ($N_r$).\n\nThe methodological approach is broken down into two main components: first, the core algorithm to compute $M^{0\\nu}$ for a given set of physical and numerical parameters; second, a framework to systematically vary these parameters to compute a central value and an error budget.\n\n**1. Core Calculation of the Nuclear Matrix Element $M^{0\\nu}$**\n\nThe calculation of $M^{0\\nu}(N_{\\max}, \\hbar\\omega, N_r)$ is implemented in a single, reusable function. This function encapsulates the physics and numerical methods prescribed in the problem statement. The process for a given set of inputs ($A, \\mu, N_{\\max}, \\hbar\\omega, N_r, \\beta$) is as follows:\n\n- **Parameter Derivation**: First, dependent physical parameters are calculated from the inputs. The harmonic oscillator length $b$ is determined from the oscillator energy $\\hbar\\omega$ and the nucleon mass $m_N$ using the formula $b = \\hbar/\\sqrt{m_N \\hbar\\omega}$. The nuclear radius $R$ is computed as $R = r_0 A^{1/3}$. The upper limit for the radial integration is then set to $r_{\\max} = \\beta b$.\n\n- **Numerical Grid Setup**: A uniform radial grid is established for the numerical integration, spanning from $r=0$ to $r=r_{\\max}$. The grid consists of $N_r'$ points, where $N_r'$ is adjusted to be the smallest odd integer greater than or equal to the input $N_r$. This adjustment ensures the validity of the Simpson's rule for numerical integration, which requires an even number of intervals.\n\n- **Summation over States**: The total matrix element $M^{0\\nu}$ is a sum over contributions from all allowed single-particle states $(n,l)$, where $n$ is the radial quantum number and $l$ is the orbital angular momentum. The model space is truncated by the major-shell quantum number $K = 2n+l$, such that only states with $2n+l \\le N_{\\max}$ are included. The algorithm iterates through all valid $(n,l)$ pairs satisfying this condition.\n\n- **State Contribution**: For each state $(n,l)$, its contribution to the total matrix element is the product of a weight factor $w_{nl}$ and a radial integral $I_{nl}$.\n    - The weight $w_{nl}$ is calculated as $w_{nl} = (2l+1) g_0 e^{-\\alpha(2n+l)}$, combining the magnetic substate degeneracy $D_l = 2l+1$ with a phenomenological occupation factor $g_{nl}$.\n    - The radial integral $I_{nl}$ is given by $I_{nl} = \\int_{0}^{r_{\\max}} r^2 \\left[R_{nl}(r)\\right]^2 H(r)\\,dr$. The integrand is constructed as follows:\n        - The harmonic oscillator radial wave function $R_{nl}(r)$ is constructed using its definition: $R_{nl}(r) = \\mathcal{N}_{nl} (r/b)^l e^{-r^2/(2b^2)} L_{n}^{l+1/2}(r^2/b^2)$. The normalization factor $\\mathcal{N}_{nl} = \\sqrt{2\\,\\Gamma(n+1) / (b^3\\,\\Gamma(n + l + 3/2))}$ is computed using the gamma function $\\Gamma(\\cdot)$ from `scipy.special`. The generalized Laguerre polynomial $L_{n}^{l+1/2}(x)$ is evaluated using `scipy.special.genlaguerre`.\n        - The neutrino potential is $H(r) = R e^{-\\mu r} / r$.\n        - The full integrand simplifies to $r \\cdot |R_{nl}(r)|^2 \\cdot R e^{-\\mu r}$. This form is numerically advantageous as it is well-defined at $r=0$, where its limit is $0$. The calculation is vectorized over the entire radial grid, with the value at $r=0$ correctly evaluating to $0$.\n    - The integral $I_{nl}$ is then computed numerically using the Simpson's rule implementation from `scipy.integrate.simpson` over the constructed integrand values on the radial grid.\n\n- **Accumulation**: The weighted contributions $w_{nl}I_{nl}$ are summed over all $(n,l)$ pairs to yield the final value of $M^{0\\nu}$.\n\n**2. Convergence Analysis and Error Estimation**\n\nThe second part of the implementation orchestrates calls to the core calculation function to perform the specified convergence study for each test case.\n\n- **Central Value ($M_{\\mathrm{central}}$)**: The central value of the matrix element is defined as the result obtained using the largest model-space size ($N_{\\max}^{\\text{largest}}$), the central oscillator frequency ($\\hbar\\omega_{\\text{central}}$, taken as the median of the provided set), and the finest radial mesh ($N_r^{\\text{largest}}$).\n\n- **Error Components**: Three sources of numerical error are quantified:\n    1.  **Model-Space Error ($\\Delta_{\\mathrm{model}}$)**: This is calculated as the absolute difference $|M^{0\\nu}(N_{\\max}^{\\text{largest}}, \\dots) - M^{0\\nu}(N_{\\max}^{\\text{second-largest}}, \\dots)|$, with $\\hbar\\omega$ and $N_r$ fixed at their central and finest values, respectively.\n    2.  **Frequency Error ($\\Delta_{\\omega}$)**: This is computed as one-half of the range (maximum minus minimum) of $M^{0\\nu}$ values obtained by varying $\\hbar\\omega$ across its provided set, while keeping $N_{\\max}$ and $N_r$ at their largest values. If only one $\\hbar\\omega$ value is provided, this error is zero.\n    3.  **Mesh Error ($\\Delta_{\\mathrm{mesh}}$)**: This is the absolute difference $|M^{0\\nu}(\\dots, N_r^{\\text{largest}}) - M^{0\\nu}(\\dots, N_r^{\\text{second-largest}})|$, with $N_{\\max}$ and $\\hbar\\omega$ fixed at their largest and central values, respectively.\n\n- **Total Error ($\\Delta_{\\mathrm{total}}$)**: The individual error components are combined in quadrature to estimate the total numerical uncertainty: $\\Delta_{\\mathrm{total}} = \\sqrt{\\Delta_{\\mathrm{model}}^2 + \\Delta_{\\omega}^2 + \\Delta_{\\mathrm{mesh}}^2}$.\n\n**3. Implementation Strategy**\n\nTo optimize the numerous repeated calculations inherent in a convergence study, the core function `calculate_M0nu` is decorated with a memoization cache (`functools.lru_cache`). This ensures that any call with an identical set of parameters is not re-computed, but rather its result is retrieved instantly from memory, significantly improving performance. The final program iterates through the predefined test cases, performs the full analysis for each, and formats the resulting list of five values ($M_{\\mathrm{central}}, \\Delta_{\\mathrm{model}}, \\Delta_{\\omega}, \\Delta_{\\mathrm{mesh}}, \\Delta_{\\mathrm{total}}$) into the exact string format required.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import gamma, genlaguerre\nfrom scipy.integrate import simpson\nfrom functools import lru_cache\n\n# Physical constants in specified units\nHBAR_C = 197.326  # MeV*fm\nM_N = 939.0       # MeV\nR0 = 1.2          # fm\nG0 = 1.0\nALPHA = 0.4\n\n@lru_cache(maxsize=None)\ndef calculate_M0nu(A, mu, N_max, hw, Nr, beta):\n    \"\"\"\n    Calculates the neutrinoless double beta decay nuclear matrix element M^0nu\n    for a given set of model parameters.\n\n    Args:\n        A (int): Mass number.\n        mu (float): Screening parameter (fm^-1).\n        N_max (int): HO major-shell truncation.\n        hw (float): HO frequency (MeV).\n        Nr (int): Number of radial mesh points.\n        beta (float): Dimensionless factor for r_max.\n\n    Returns:\n        float: The dimensionless nuclear matrix element M^0nu.\n    \"\"\"\n    # 1. Derived physical and numerical parameters\n    R_nuc = R0 * A**(1.0/3.0)\n    b = HBAR_C / np.sqrt(M_N * hw)\n    r_max = beta * b\n\n    # Adjust Nr to be odd for Simpson's rule\n    Nr_adj = Nr if Nr % 2 != 0 else Nr + 1\n    r_mesh = np.linspace(0, r_max, Nr_adj)\n\n    M0nu_total = 0.0\n\n    # 2. Iterate over all allowed (n, l) quantum states\n    for K in range(N_max + 1):\n        for l in range(K + 1):\n            if (K - l) % 2 == 0:\n                n = (K - l) // 2\n                # Valid state (n,l) with 2n+l = K\n\n                # a. Calculate state weight w_nl\n                w_nl = (2 * l + 1) * G0 * np.exp(-ALPHA * K)\n\n                # b. Calculate radial integral I_nl\n                # Normalization factor for the HO wave function\n                norm_factor_sq = (2.0 * gamma(n + 1)) / (b**3 * gamma(n + l + 1.5))\n                \n                # Generalized Laguerre polynomial L_n^(l+0.5)\n                laguerre_poly = genlaguerre(n, l + 0.5)\n\n                # Vectorized calculation of the integrand on the mesh\n                # Integrand is r * |R_nl(r)|^2 * R_nuc * exp(-mu*r)\n                r_over_b = r_mesh / b\n                r_over_b_sq = r_over_b**2\n                \n                # np.power(0, 0) is 1, which is correct for l=0 at r=0\n                r_term = np.power(r_over_b, 2 * l)\n                exp_term = np.exp(-r_over_b_sq)\n                laguerre_term_sq = np.power(laguerre_poly(r_over_b_sq), 2)\n\n                R_nl_sq = norm_factor_sq * r_term * exp_term * laguerre_term_sq\n                \n                # The leading r_mesh factor ensures the integrand is 0 at r=0\n                integrand = r_mesh * R_nl_sq * R_nuc * np.exp(-mu * r_mesh)\n\n                # Numerical integration using Simpson's rule\n                I_nl = simpson(integrand, x=r_mesh)\n                \n                # c. Accumulate weighted contribution\n                M0nu_total += w_nl * I_nl\n\n    return M0nu_total\n\ndef solve():\n    \"\"\"\n    Main function to run the convergence study for all test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (A, mu, N_max_set, hw_set, Nr_set, beta)\n        {'A': 76, 'mu': 0.5, 'N_max_set': [4, 6, 8], 'hw_set': [10, 12, 14], 'Nr_set': [200, 400], 'beta': 8.0},\n        {'A': 136, 'mu': 0.45, 'N_max_set': [6, 8, 10], 'hw_set': [8, 10, 12], 'Nr_set': [300, 600], 'beta': 9.0},\n        {'A': 48, 'mu': 0.5, 'N_max_set': [2, 4], 'hw_set': [12], 'Nr_set': [50, 100], 'beta': 6.0},\n    ]\n\n    all_results = []\n    for case in test_cases:\n        A, mu, beta = case['A'], case['mu'], case['beta']\n        N_max_set = sorted(case['N_max_set'])\n        hw_set = sorted(case['hw_set'])\n        Nr_set = sorted(case['Nr_set'])\n\n        # Identify key parameter points for the study\n        N_max_large = N_max_set[-1]\n        N_max_second_large = N_max_set[-2] if len(N_max_set) > 1 else N_max_large\n        \n        hw_central = float(np.median(hw_set))\n        \n        Nr_large = Nr_set[-1]\n        Nr_second_large = Nr_set[-2] if len(Nr_set) > 1 else Nr_large\n\n        # 1. Central value calculation\n        M_central = calculate_M0nu(A, mu, N_max_large, hw_central, Nr_large, beta)\n\n        # 2. Model-space truncation error\n        M_at_Nmax_second = calculate_M0nu(A, mu, N_max_second_large, hw_central, Nr_large, beta)\n        delta_model = abs(M_central - M_at_Nmax_second)\n\n        # 3. Oscillator frequency error\n        if len(hw_set) > 1:\n            m_values_hw = [calculate_M0nu(A, mu, N_max_large, hw, Nr_large, beta) for hw in hw_set]\n            delta_hw = 0.5 * (max(m_values_hw) - min(m_values_hw))\n        else:\n            delta_hw = 0.0\n\n        # 4. Radial mesh error\n        M_at_Nr_second = calculate_M0nu(A, mu, N_max_large, hw_central, Nr_second_large, beta)\n        delta_mesh = abs(M_central - M_at_Nr_second)\n\n        # 5. Total error\n        delta_total = np.sqrt(delta_model**2 + delta_hw**2 + delta_mesh**2)\n\n        all_results.append([M_central, delta_model, delta_hw, delta_mesh, delta_total])\n\n    # Format the output as a string representing a list of lists.\n    formatted_results = [f\"[{','.join(map(str, res_list))}]\" for res_list in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3572952"}]}