{"hands_on_practices": [{"introduction": "At the heart of Relativistic Mean-Field (RMF) calculations lies the task of solving the field equations for the mesons, which are sourced by the nucleon densities. In the static limit, these take the form of inhomogeneous Klein-Gordon (or Yukawa) equations. This foundational exercise [@problem_id:3589493] guides you through the implementation of a robust solver for this type of equation on a discrete grid. You will master the use of the Yukawa Green's function and the convolution theorem to build an efficient solver based on Fast Fourier Transforms (FFTs), a core technique in modern computational nuclear physics codes.", "problem": "Consider the linear elliptic field equation in three spatial dimensions that arises in Relativistic Mean Field (RMF) theory for meson fields, namely the inhomogeneous Klein–Gordon (Yukawa) equation\n$$\n\\left(-\\Delta + m^2\\right)\\,\\phi(\\mathbf{r}) = s(\\mathbf{r}),\n$$\nwhere $\\Delta$ is the Laplacian, $m$ is a positive mass parameter, $\\phi(\\mathbf{r})$ is the field, and $s(\\mathbf{r})$ is a given source. The fundamental solution (Green’s function) for this operator in infinite space is the Yukawa kernel\n$$\nG(\\mathbf{r}) = \\frac{e^{-m r}}{4\\pi r},\\quad r = \\|\\mathbf{r}\\|.\n$$\nBy the Green’s function representation, a formal solution is the convolution\n$$\n\\phi(\\mathbf{r}) = \\int_{\\mathbb{R}^3} G(\\mathbf{r}-\\mathbf{r}')\\,s(\\mathbf{r}')\\,\\mathrm{d}^3\\mathbf{r}'.\n$$\nIn a computational setting, one typically discretizes a periodic cubic domain of side length $L$ with $N$ points per dimension, yielding a uniform grid spacing $a = L/N$ and a cell volume $\\Delta V = a^3$. On such a grid with periodic boundary conditions, the discrete convolution approximation is\n$$\n\\phi_{i,j,k} \\approx \\Delta V \\sum_{i',j',k'} G^{\\mathrm{per}}_{(i-i'),(j-j'),(k-k')} \\, s_{i',j',k'},\n$$\nwhere $G^{\\mathrm{per}}$ is the periodic implementation of the Yukawa kernel on the discrete torus, constructed using the minimal-image convention for the grid-index differences so that the kernel depends on the wrapped distance\n$$\nr_{i,j,k} = a\\,\\sqrt{(\\min(i,N-i))^2 + (\\min(j,N-j))^2 + (\\min(k,N-k))^2}.\n$$\nThe value of the Yukawa kernel is singular at $r=0$. To produce a numerically stable quadrature on the grid, the value of the kernel at the origin should be replaced by the average of $G$ over a voxel surrounding the origin. A simple and effective approximation is the spherical average over a sphere of radius $R$ chosen so that its volume equals the cube’s cell volume,\n$$\n\\frac{4}{3}\\pi R^3 = \\Delta V,\\quad R = \\left(\\frac{3\\Delta V}{4\\pi}\\right)^{1/3}.\n$$\nWith this choice, the voxel-averaged kernel value at the origin becomes\n$$\nG_0 = \\frac{1}{\\Delta V}\\int_{0}^{R} \\frac{e^{-m r}}{4\\pi r} \\, 4\\pi r^2 \\,\\mathrm{d}r = \\frac{1}{\\Delta V}\\int_{0}^{R} r e^{-m r}\\,\\mathrm{d}r = \\frac{1}{m^2 \\Delta V}\\left[1 - \\left(1 + m R\\right)e^{-m R}\\right],\n$$\nwith the $m \\to 0$ limit reducing to $G_0 = \\frac{R^2}{2\\,\\Delta V}$.\n\nAlternatively, the same periodic problem admits a spectral solution via the discrete Fourier transform that leverages the identity\n$$\n\\widehat{\\phi}(\\mathbf{k}) = \\frac{\\widehat{s}(\\mathbf{k})}{k^2 + m^2},\\quad k^2 = k_x^2 + k_y^2 + k_z^2,\n$$\nwhere $\\mathbf{k}$ are the discrete wave numbers associated with the periodic domain. This provides a consistent reference solution against which the convolution-based quadrature can be assessed.\n\nYour tasks are:\n- Derive, from first principles, the Green’s function convolution representation and the discrete periodic convolution consistent with the minimal-image convention and voxel-averaged origin correction.\n- Design and implement a solver that computes $\\phi$ on the grid via fast convolution using the discrete Fourier transform of $G^{\\mathrm{per}}$ and $s$ with the proper quadrature scaling by $\\Delta V$.\n- Implement a spectral solver that computes $\\phi$ via $\\widehat{\\phi}(\\mathbf{k}) = \\widehat{s}(\\mathbf{k})/(k^2+m^2)$ on the same grid, using the discrete wave numbers $k_x = 2\\pi\\,\\mathrm{fftfreq}(N,a)$ and similarly for $k_y$ and $k_z$.\n- Construct physically plausible discrete sources for testing: a point-like source approximating the Dirac delta using a single cell with amplitude $1/\\Delta V$ at the origin, and a normalized periodic Gaussian $s(\\mathbf{r}) = A \\exp\\left(-r^2/(2\\sigma^2)\\right)$ with $A$ chosen so that the discrete integral $\\sum s\\,\\Delta V$ equals $1$.\n\nAll quantities in this problem are dimensionless.\n\nDefine error metrics as follows:\n- For the point-like source, along the positive $x$-axis, compare the convolution solution against the analytical Yukawa kernel values for the first $M$ nonzero grid points, $i=1,\\dots,M$, where $r_i = i\\,a$. Report the mean absolute relative error,\n$$\n\\varepsilon_{\\mathrm{pt}} = \\frac{1}{M}\\sum_{i=1}^{M} \\left|\\frac{\\phi_{i,0,0} - G(r_i)}{G(r_i)}\\right|.\n$$\n- For Gaussian sources, report the relative $\\ell^2$ error between the convolution solution and the spectral solution over the full grid,\n$$\n\\varepsilon_{\\mathrm{gauss}} = \\frac{\\left\\|\\phi_{\\mathrm{conv}} - \\phi_{\\mathrm{spec}}\\right\\|_2}{\\left\\|\\phi_{\\mathrm{spec}}\\right\\|_2},\n$$\nwith the discrete norm defined by\n$$\n\\left\\|f\\right\\|_2 = \\left(\\sum_{i,j,k} |f_{i,j,k}|^2\\,\\Delta V\\right)^{1/2}.\n$$\n\nTest suite specification:\n- Test $1$ (happy path, point source): $N=48$, $L=24$, $m=1.0$, $M=12$.\n- Test $2$ (happy path, Gaussian): $N=48$, $L=24$, $m=1.0$, $\\sigma=1.5$.\n- Test $3$ (edge case, long range): $N=48$, $L=24$, $m=0.1$, $\\sigma=2.0$.\n- Test $4$ (edge case, short range): $N=48$, $L=24$, $m=5.0$, $\\sigma=0.5$.\n\nYour program must:\n- Build the periodic Yukawa kernel $G^{\\mathrm{per}}$ on the discrete grid with voxel-averaged origin value $G_0$ and perform fast convolution via the discrete Fourier transform with proper scaling by $\\Delta V$.\n- Build the spectral solution via the discrete wave numbers and compare as specified.\n- Produce four floating-point results corresponding to the error metrics for Tests $1$–$4$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $\\left[\\mathrm{result}_1,\\mathrm{result}_2,\\mathrm{result}_3,\\mathrm{result}_4\\right]$). Each result must be a floating-point number. No other text should be printed.", "solution": "The problem requires the numerical solution of the inhomogeneous Klein-Gordon equation on a periodic cubic domain using two distinct but related Fourier-based methods, and a quantitative comparison of their accuracy.\n\n### Principles and Derivations\n\n#### 1. Green's Function and Convolution Solution\nThe governing equation is the linear elliptic partial differential equation (PDE):\n$$\n\\left(-\\Delta + m^2\\right)\\,\\phi(\\mathbf{r}) = s(\\mathbf{r})\n$$\nwhere $\\Delta = \\nabla^2$ is the Laplacian operator, $m$ is a constant positive mass, $\\phi(\\mathbf{r})$ is the field to be solved for, and $s(\\mathbf{r})$ is a specified source term.\n\nThe fundamental solution, or Green's function, $G(\\mathbf{r}, \\mathbf{r}')$ of the operator $L_{\\mathbf{r}} = -\\Delta_{\\mathbf{r}} + m^2$ is defined by the equation:\n$$\nL_{\\mathbf{r}} G(\\mathbf{r}, \\mathbf{r}') = \\delta(\\mathbf{r} - \\mathbf{r}')\n$$\nwhere $\\delta(\\mathbf{r} - \\mathbf{r}')$ is the Dirac delta function. For an infinite, translationally-invariant domain, the Green's function depends only on the displacement vector, i.e., $G(\\mathbf{r}, \\mathbf{r}') = G(\\mathbf{r}-\\mathbf{r}')$. The solution in this case is the well-known Yukawa potential:\n$$\nG(\\mathbf{r}) = \\frac{e^{-m r}}{4\\pi r}, \\quad r = \\|\\mathbf{r}\\|\n$$\nThe solution $\\phi(\\mathbf{r})$ to the original PDE can be formally expressed using the Green's function. Let $L_{\\mathbf{r}'}$ be the operator acting on the $\\mathbf{r}'$ coordinate. By applying Green's second identity and assuming that the fields vanish at infinity, one can show:\n$$\n\\phi(\\mathbf{r}) = \\int_{\\mathbb{R}^3} G(\\mathbf{r}-\\mathbf{r}') \\left(L_{\\mathbf{r}'} \\phi(\\mathbf{r}')\\right) \\mathrm{d}^3\\mathbf{r}'\n$$\nSubstituting $L_{\\mathbf{r}'} \\phi(\\mathbf{r}') = s(\\mathbf{r}')$, we arrive at the convolution representation of the solution:\n$$\n\\phi(\\mathbf{r}) = \\int_{\\mathbb{R}^3} G(\\mathbf{r}-\\mathbf{r}')\\,s(\\mathbf{r}')\\,\\mathrm{d}^3\\mathbf{r}' = (G * s)(\\mathbf{r})\n$$\n\n#### 2. Discretization on a Periodic Grid\nFor a numerical solution, we discretize a cubic domain of side length $L$ into a grid of $N \\times N \\times N$ points. The grid spacing is $a = L/N$, and the volume of a single grid cell (voxel) is $\\Delta V = a^3$. The continuous fields $\\phi(\\mathbf{r})$ and $s(\\mathbf{r})$ are represented by their values on the grid points, $\\phi_{i,j,k}$ and $s_{i,j,k}$.\n\nThe convolution integral is approximated by a discrete sum:\n$$\n\\phi_{i,j,k} \\approx \\sum_{i',j',k'} G(\\mathbf{r}_{i,j,k}-\\mathbf{r}_{i',j',k'}) s_{i',j',k'} \\Delta V\n$$\nFor periodic boundary conditions, the interaction between points must account for the wrap-around nature of the domain. The distance between two points should be the shortest path on the discrete torus. This is achieved using the **minimal-image convention**. For grid indices $i \\in [0, N-1]$, the wrapped one-dimensional distance is $\\min(i, N-i)$. Extending to three dimensions, the periodic distance from the origin $(0,0,0)$ to a point $(i,j,k)$ is:\n$$\nr_{i,j,k} = a\\,\\sqrt{(\\min(i,N-i))^2 + (\\min(j,N-j))^2 + (\\min(k,N-k))^2}\n$$\nThis defines the periodic kernel $G^{\\mathrm{per}}$ used in the discrete periodic convolution:\n$$\n\\phi_{i,j,k} = \\Delta V \\sum_{i',j',k'} G^{\\mathrm{per}}_{(i-i'),(j-j'),(k-k')} \\, s_{i',j',k'}\n$$\nwhere indices are taken modulo $N$.\n\n#### 3. Singularity Regularization at the Origin\nThe Yukawa kernel $G(r) \\propto 1/r$ is singular at $r=0$. A naive evaluation on the grid would result in a division by zero. To obtain a stable and accurate numerical quadrature, the value $G^{\\mathrm{per}}_{0,0,0}$ is replaced by its average over the central voxel. We approximate the cubic voxel of volume $\\Delta V$ by a sphere of equivalent volume, which has radius $R = (3\\Delta V / 4\\pi)^{1/3}$. The averaged kernel value $G_0$ is:\n$$\nG_0 = \\frac{1}{\\Delta V} \\int_{\\|\\mathbf{r}\\| \\le R} G(\\mathbf{r}) \\,\\mathrm{d}^3\\mathbf{r} = \\frac{1}{\\Delta V} \\int_0^R \\frac{e^{-m r}}{4\\pi r} 4\\pi r^2 \\,\\mathrm{d}r = \\frac{1}{\\Delta V} \\int_0^R r e^{-m r} \\,\\mathrm{d}r\n$$\nPerforming this integral by parts yields the regularized value at the origin:\n$$\nG_0 = \\frac{1}{m^2 \\Delta V}\\left[1 - \\left(1 + m R\\right)e^{-m R}\\right]\n$$\n\n#### 4. Fast Convolution using Fourier Transforms\nDirect evaluation of the discrete convolution sum is computationally expensive, costing $O(N^6)$ operations for an $N \\times N \\times N$ grid. The Convolution Theorem provides a much more efficient path. The theorem states that the Fourier transform of a convolution of two functions is the element-wise product of their individual Fourier transforms:\n$$\n\\mathcal{F}\\{f * g\\} = \\mathcal{F}\\{f\\} \\cdot \\mathcal{F}\\{g\\}\n$$\nApplying this to our discrete periodic convolution, the solution $\\phi$ can be computed via:\n$$\n\\phi = \\Delta V \\cdot \\mathrm{IFFT}\\left( \\mathrm{FFT}(G^{\\mathrm{per}}) \\cdot \\mathrm{FFT}(s) \\right)\n$$\nwhere $\\mathrm{FFT}$ and $\\mathrm{IFFT}$ denote the Fast Fourier Transform and its inverse. This reduces the computational complexity to $O(N^3 \\log N)$.\n\n#### 5. Spectral Solution Method\nAn alternative approach is to solve the PDE directly in Fourier space. Applying the Fourier transform to the original equation $(-\\Delta + m^2)\\,\\phi = s$ and using the property that Fourier transforming the Laplacian corresponds to multiplication by $k^2 = \\|\\mathbf{k}\\|^2$, we get:\n$$\n(k^2 + m^2)\\,\\widehat{\\phi}(\\mathbf{k}) = \\widehat{s}(\\mathbf{k})\n$$\nwhere $\\widehat{\\phi}$ and $\\widehat{s}$ are the Fourier transforms of $\\phi$ and $s$, and $\\mathbf{k}$ is the wave vector. This gives an algebraic solution for the Fourier coefficients of the field:\n$$\n\\widehat{\\phi}(\\mathbf{k}) = \\frac{\\widehat{s}(\\mathbf{k})}{k^2 + m^2}\n$$\nThe solution in real space is then found by applying the inverse Fourier transform: $\\phi = \\mathcal{F}^{-1}\\{\\widehat{\\phi}\\}$. On our discrete grid, the wave numbers $\\mathbf{k} = (k_x, k_y, k_z)$ are given by $k_x = 2\\pi f_x$, where $f_x$ are the discrete frequencies from `numpy.fft.fftfreq(N, a)`. Since $m > 0$, the denominator $k^2 + m^2$ is always non-zero, ensuring a well-defined solution. This spectral method is mathematically equivalent to the periodic convolution and serves as a robust reference for verifying the implementation.\n\n#### 6. Source and Error Definitions\nThe problem specifies two source types for testing:\n1.  **Point Source**: A discrete approximation of the Dirac delta function, $s_{i,j,k} = \\delta_{i0}\\delta_{j0}\\delta_{k0} / \\Delta V$. The integral $\\sum s \\Delta V = 1$.\n2.  **Gaussian Source**: A periodic Gaussian $s(\\mathbf{r}) = A \\exp(-r^2/(2\\sigma^2))$, where $r$ is the periodic distance and $A$ is a normalization constant ensuring $\\sum s \\Delta V = 1$.\n\nThe error metrics are:\n1.  $\\varepsilon_{\\mathrm{pt}}$: For the point source, the solution is compared to the analytical infinite-space Green's function $G(r)$ along one axis. This tests the accuracy of the discretization and the impact of periodic boundary conditions.\n2.  $\\varepsilon_{\\mathrm{gauss}}$: For Gaussian sources, the convolution solution $\\phi_{\\mathrm{conv}}$ is compared to the spectral solution $\\phi_{\\mathrm{spec}}$ using a relative $\\ell^2$ norm. This verifies the consistency of the two implemented numerical methods.\n\nThe following implementation systematically carries out these calculations for the specified test suite.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_error(source_type, N, L, m, M, sigma):\n    \"\"\"\n    Computes the solution to the Klein-Gordon equation and the specified error metric.\n    \n    Args:\n        source_type (str): 'point' or 'gauss'.\n        N (int): Number of grid points per dimension.\n        L (float): Side length of the cubic domain.\n        m (float): Mass parameter.\n        M (int): Number of points for point-source error calculation.\n        sigma (float): Width of the Gaussian source.\n\n    Returns:\n        float: The calculated error.\n    \"\"\"\n    # Grid parameters\n    a = L / N\n    dV = a**3\n\n    # Create grid indices and distances using minimal image convention\n    i, j, k = np.ogrid[0:N, 0:N, 0:N]\n    ix = np.minimum(i, N - i)\n    iy = np.minimum(j, N - j)\n    ik = np.minimum(k, N - k)\n    r_grid = a * np.sqrt(ix**2 + iy**2 + ik**2)\n    \n    # 1. Construct the periodic Yukawa kernel G_per\n    # Voxel-averaged value at the origin\n    R = (3 * dV / (4 * np.pi))**(1/3)\n    if m > 1e-9:\n        G0 = (1 - (1 + m * R) * np.exp(-m * R)) / (m**2 * dV)\n    else: # Handle m -> 0 limit\n        G0 = R**2 / (2 * dV)\n\n    # Kernel on the grid\n    G_per = np.divide(np.exp(-m * r_grid), 4 * np.pi * r_grid, where=(r_grid != 0))\n    G_per[0, 0, 0] = G0\n\n    # 2. Construct the source term s\n    s = np.zeros((N, N, N), dtype=float)\n    if source_type == 'point':\n        s[0, 0, 0] = 1.0 / dV\n    elif source_type == 'gauss':\n        s_unnormalized = np.exp(-r_grid**2 / (2 * sigma**2))\n        integral_s = np.sum(s_unnormalized) * dV\n        s = s_unnormalized / integral_s\n\n    # 3. Compute solution via fast convolution (Method 1)\n    s_hat = np.fft.fftn(s)\n    G_per_hat = np.fft.fftn(G_per)\n    \n    phi_conv = dV * np.fft.ifftn(G_per_hat * s_hat)\n    phi_conv = np.real(phi_conv)\n\n    # 4. Calculate error based on source type\n    if source_type == 'point':\n        # Compare with analytical Yukawa kernel on x-axis\n        r_vals = a * np.arange(1, M + 1)\n        G_analytical = np.exp(-m * r_vals) / (4 * np.pi * r_vals)\n        phi_on_axis = phi_conv[1:M+1, 0, 0]\n        \n        relative_errors = np.abs((phi_on_axis - G_analytical) / G_analytical)\n        error = np.mean(relative_errors)\n        return error\n        \n    elif source_type == 'gauss':\n        # Compare with spectral solution (Method 2)\n        # Wave numbers\n        k_vals = 2 * np.pi * np.fft.fftfreq(N, a)\n        kx, ky, kz = np.meshgrid(k_vals, k_vals, k_vals, indexing='ij')\n        k2 = kx**2 + ky**2 + kz**2\n\n        phi_spec_hat = np.divide(s_hat, k2 + m**2, where=(k2 + m**2 != 0))\n        \n        phi_spec = np.fft.ifftn(phi_spec_hat)\n        phi_spec = np.real(phi_spec)\n\n        # Relative L2 error\n        norm_spec_sq = np.sum(phi_spec**2) * dV\n        norm_diff_sq = np.sum((phi_conv - phi_spec)**2) * dV\n        \n        if norm_spec_sq == 0:\n            return 0.0 if norm_diff_sq == 0 else 1.0\n\n        error = np.sqrt(norm_diff_sq / norm_spec_sq)\n        return error\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'type': 'point', 'N': 48, 'L': 24, 'm': 1.0, 'sigma': None,  'M': 12},\n        {'type': 'gauss', 'N': 48, 'L': 24, 'm': 1.0, 'sigma': 1.5,   'M': None},\n        {'type': 'gauss', 'N': 48, 'L': 24, 'm': 0.1, 'sigma': 2.0,   'M': None},\n        {'type': 'gauss', 'N': 48, 'L': 24, 'm': 5.0, 'sigma': 0.5,   'M': None},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = compute_error(\n            source_type=case['type'],\n            N=case['N'],\n            L=case['L'],\n            m=case['m'],\n            M=case['M'],\n            sigma=case['sigma']\n        )\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.12e}' for r in results)}]\")\n\nsolve()\n```", "id": "3589493"}, {"introduction": "Having learned to solve for the meson fields given a static source, the next step is to address the full self-consistency of the RMF problem, where the nucleon densities themselves depend on the fields they generate. This practice [@problem_id:3589504] walks you through building this essential non-linear feedback loop within a simplified but powerful model. You will implement a self-consistent solver that iterates between the density and potential, introducing two critical concepts for practical success: linear mixing to stabilize the iterations and spectral filtering to mitigate aliasing errors inherent in FFT-based non-linear calculations.", "problem": "Consider a simplified Relativistic Mean-Field (RMF) model for symmetric nuclear matter in a cubic periodic domain, where the time-like component of the vector meson field is treated as a convolution with a Yukawa kernel. Work in natural units with $\\hbar = c = 1$, and express lengths in femtometers (fm) and momenta in inverse femtometers (fm$^{-1}$). The baryon density is denoted by $\\rho(\\mathbf{r})$, the nucleon rest mass by $M$, the vector meson mass by $m_\\omega$, and the vector coupling by $g_\\omega$. The time-like vector potential seen by nucleons is $V(\\mathbf{r})$, and the chemical potential (a constant) is $\\mu$.\n\nStarting from the RMF field equation for the vector meson in the static limit, the Helmholtz-type equation\n$$\n\\left(-\\nabla^2 + m_\\omega^2\\right)\\,\\omega^0(\\mathbf{r}) = g_\\omega\\,\\rho(\\mathbf{r}),\n$$\ndefine the toy vector potential as $V(\\mathbf{r}) = g_\\omega\\,\\omega^0(\\mathbf{r})$. Show that $V(\\mathbf{r})$ is given by a convolution with the Yukawa kernel $K(\\mathbf{r})$,\n$$\nV(\\mathbf{r}) = \\int \\mathrm{d}^3 r'\\,K(\\mathbf{r}-\\mathbf{r}')\\,\\rho(\\mathbf{r}'), \\quad K(\\mathbf{r}) = \\frac{g_\\omega^2}{4\\pi}\\frac{e^{-m_\\omega r}}{r},\n$$\nand equivalently in Fourier space by\n$$\n\\tilde{V}(\\mathbf{k}) = \\tilde{K}(\\mathbf{k})\\,\\tilde{\\rho}(\\mathbf{k}), \\quad \\tilde{K}(\\mathbf{k}) = \\frac{g_\\omega^2}{\\mathbf{k}^2 + m_\\omega^2},\n$$\nwhere tildes denote Fourier transforms and $\\mathbf{k}$ is the wavevector.\n\nAssume the nucleon single-particle energies are given by a relativistic dispersion shifted by $V(\\mathbf{r})$,\n$$\nE(\\mathbf{k},\\mathbf{r}) = \\sqrt{\\mathbf{k}^2 + M^2} + V(\\mathbf{r}),\n$$\nand that the chemical potential satisfies the local relation\n$$\n\\mu = \\sqrt{k_F(\\mathbf{r})^2 + M^2} + V(\\mathbf{r}),\n$$\nso the local Fermi momentum $k_F(\\mathbf{r})$ equals\n$$\nk_F(\\mathbf{r}) = \\sqrt{\\max\\left(0, \\left[\\mu - V(\\mathbf{r})\\right]^2 - M^2\\right)}.\n$$\nWith spin-isospin degeneracy factor $\\gamma = 4$ for symmetric nuclear matter, the local baryon density is\n$$\n\\rho(\\mathbf{r}) = \\frac{\\gamma}{6\\pi^2}\\,k_F(\\mathbf{r})^3.\n$$\n\nYour task is to implement a self-consistent solver in a periodic cubic box of side $L$ with a uniform grid of $N^3$ points. The solver must:\n\n1. Initialize the density as a uniform background computed from $\\mu$ with an added Gaussian bump centered at the box center,\n$$\n\\rho_{\\mathrm{init}}(\\mathbf{r}) = \\rho_{\\mathrm{bg}} + A\\exp\\left(-\\frac{|\\mathbf{r}|^2}{2\\sigma^2}\\right), \\quad \\rho_{\\mathrm{bg}} = \\frac{\\gamma}{6\\pi^2}\\left[\\max\\left(0,\\sqrt{\\mu^2 - M^2}\\right)\\right]^3,\n$$\nwhere $A$ is the bump amplitude and $\\sigma$ is its width.\n\n2. Iterate the self-consistent loop:\n   - Compute $V(\\mathbf{r})$ from $\\rho(\\mathbf{r})$ via Fast Fourier Transform (FFT) using the spectral form $\\tilde{V}(\\mathbf{k}) = \\tilde{K}(\\mathbf{k})\\tilde{\\rho}(\\mathbf{k})$ with periodic boundary conditions.\n   - Update the density using the local Fermi momentum expression above.\n   - Apply linear mixing with parameter $\\alpha$:\n     $$\n     \\rho^{(n+1)}(\\mathbf{r}) = (1 - \\alpha)\\,\\rho^{(n)}(\\mathbf{r}) + \\alpha\\,\\rho_{\\mathrm{new}}(\\mathbf{r}).\n     $$\n   - Stop when the maximum absolute change in density satisfies\n     $$\n     \\|\\rho_{\\mathrm{new}} - \\rho^{(n)}\\|_{\\infty}  \\varepsilon,\n     $$\n     or after a maximum number of iterations.\n\n3. Implement two variants of the solver to study aliasing:\n   - A \"direct\" FFT-based solver with no spectral filtering.\n   - A \"dealiased\" solver that uses the two-thirds rule: after constructing $\\rho_{\\mathrm{new}}(\\mathbf{r})$, transform it to Fourier space and set to zero all modes with any component satisfying $|k_i|  \\frac{2}{3}k_{\\mathrm{Ny}}$, where $k_{\\mathrm{Ny}} = \\frac{\\pi N}{L}$ is the Nyquist wavenumber, then transform back to real space before mixing.\n\nUse the momentum grid spacing\n$$\n\\Delta k = \\frac{2\\pi}{L},\n$$\nwhich must be reported for each test case in units of fm$^{-1}$.\n\nQuantify aliasing effects and self-consistency by computing, for each test case: \n- The value of $\\Delta k$ in fm$^{-1}$.\n- The relative difference between the converged direct and dealiased vector potentials,\n$$\n\\mathrm{err} = \\frac{\\|\\ V_{\\mathrm{direct}} - V_{\\mathrm{dealiased}}\\ \\|_2}{\\|\\ V_{\\mathrm{dealiased}}\\ \\|_2},\n$$\nwhere $\\|\\cdot\\|_2$ is the Euclidean norm over the grid.\n- A boolean indicating whether the direct solver reached the fixed point tolerance, and a boolean indicating whether the dealiased solver reached the fixed point tolerance.\n\nImplement the program for the following test suite (all lengths in fm, all momenta in fm$^{-1}$):\n\n- Case 1 (happy path, mild features): $N = 32$, $L = 30$, $\\sigma = 4$, $A = 0.05$, $M = 4.759$, $m_\\omega = 3.97$, $g_\\omega = 1.0$, $\\mu = 5.0$, $\\alpha = 0.4$, $\\varepsilon = 10^{-6}$, maximum iterations $= 200$.\n- Case 2 (moderate resolution, sharper bump): $N = 24$, $L = 18$, $\\sigma = 2$, $A = 0.08$, $M = 4.759$, $m_\\omega = 3.97$, $g_\\omega = 1.0$, $\\mu = 5.0$, $\\alpha = 0.4$, $\\varepsilon = 10^{-6}$, maximum iterations $= 200$.\n- Case 3 (boundary/edge aliasing, coarse grid, sharp bump): $N = 16$, $L = 10$, $\\sigma = 1$, $A = 0.10$, $M = 4.759$, $m_\\omega = 3.97$, $g_\\omega = 1.0$, $\\mu = 5.0$, $\\alpha = 0.4$, $\\varepsilon = 10^{-6}$, maximum iterations $= 200$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element corresponds to one test case and is itself a list containing four entries in the order specified above:\n$$\n\\left[\\left[\\Delta k_1, \\mathrm{err}_1, \\mathrm{success}_{\\mathrm{direct},1}, \\mathrm{success}_{\\mathrm{dealiased},1}\\right], \\left[\\Delta k_2, \\mathrm{err}_2, \\mathrm{success}_{\\mathrm{direct},2}, \\mathrm{success}_{\\mathrm{dealiased},2}\\right], \\left[\\Delta k_3, \\mathrm{err}_3, \\mathrm{success}_{\\mathrm{direct},3}, \\mathrm{success}_{\\mathrm{dealiased},3}\\right]\\right].\n$$\nAll reported $\\Delta k$ must be in fm$^{-1}$, and all errors are unitless floats. Booleans must be literal true/false values. No other text may be printed.", "solution": "The RMF description for the vector meson in the static limit follows from the Euler-Lagrange equations applied to the linearized vector sector of the RMF Lagrangian density. In the absence of time dependence for the mean fields, the field equation reduces to a screened Poisson or Helmholtz-type equation,\n$$\n\\left(-\\nabla^2 + m_\\omega^2\\right)\\,\\omega^0(\\mathbf{r}) = g_\\omega\\,\\rho(\\mathbf{r}),\n$$\nwhere $\\omega^0(\\mathbf{r})$ is the time-like component of the vector field, $m_\\omega$ is the vector meson mass, $g_\\omega$ is the vector coupling, and $\\rho(\\mathbf{r})$ is the baryon density. The solution in free space is a Yukawa convolution,\n$$\n\\omega^0(\\mathbf{r}) = \\int \\mathrm{d}^3 r'\\,\\frac{g_\\omega}{4\\pi}\\frac{e^{-m_\\omega |\\mathbf{r} - \\mathbf{r}'|}}{|\\mathbf{r} - \\mathbf{r}'|}\\,\\rho(\\mathbf{r}').\n$$\nSince the nucleon vector potential is $V(\\mathbf{r}) = g_\\omega \\omega^0(\\mathbf{r})$, it becomes\n$$\nV(\\mathbf{r}) = \\int \\mathrm{d}^3 r'\\,K(\\mathbf{r}-\\mathbf{r}')\\,\\rho(\\mathbf{r}'), \\quad K(\\mathbf{r}) = \\frac{g_\\omega^2}{4\\pi}\\frac{e^{-m_\\omega r}}{r}.\n$$\nIn a periodic domain of side $L$ with a uniform grid of $N^3$ points, convolution is efficiently computed by the Fast Fourier Transform (FFT) using the convolution theorem. Denoting Fourier transforms by tildes,\n$$\n\\tilde{V}(\\mathbf{k}) = \\tilde{K}(\\mathbf{k})\\,\\tilde{\\rho}(\\mathbf{k}), \\quad \\tilde{K}(\\mathbf{k}) = \\frac{g_\\omega^2}{\\mathbf{k}^2 + m_\\omega^2}.\n$$\nHere $\\mathbf{k}$ runs over the discrete wavevectors consistent with the periodic boundary conditions, with components\n$$\nk_i = \\frac{2\\pi}{L}\\,n_i, \\quad n_i \\in \\left\\{-\\frac{N}{2},\\ldots,\\frac{N}{2}-1\\right\\}.\n$$\nIn floating-point FFT implementations, these are conveniently obtained from the function that returns discrete frequencies, scaled by $2\\pi$ to convert cycles per unit length to radians per unit length.\n\nFor the baryon density and self-consistent update, we use the relativistic Fermi gas expression with spin-isospin degeneracy $\\gamma = 4$ appropriate for symmetric nuclear matter. The nucleon single-particle energy at position $\\mathbf{r}$ is\n$$\nE(\\mathbf{k},\\mathbf{r}) = \\sqrt{\\mathbf{k}^2 + M^2} + V(\\mathbf{r}),\n$$\nwith $M$ the nucleon mass. Defining the local Fermi momentum by the chemical potential condition\n$$\n\\mu = \\sqrt{k_F(\\mathbf{r})^2 + M^2} + V(\\mathbf{r}),\n$$\nwe obtain\n$$\nk_F(\\mathbf{r}) = \\sqrt{\\max\\left(0, \\left[\\mu - V(\\mathbf{r})\\right]^2 - M^2\\right)}.\n$$\nThe local density follows as\n$$\n\\rho(\\mathbf{r}) = \\frac{\\gamma}{6\\pi^2}\\,k_F(\\mathbf{r})^3.\n$$\nThis mapping $\\rho(\\mathbf{r}) \\mapsto V(\\mathbf{r}) \\mapsto \\rho(\\mathbf{r})$ defines a non-linear fixed-point problem. We solve it by fixed-point iteration with linear mixing:\n$$\n\\rho^{(n+1)}(\\mathbf{r}) = (1 - \\alpha)\\,\\rho^{(n)}(\\mathbf{r}) + \\alpha\\,\\rho_{\\mathrm{new}}(\\mathbf{r}),\n$$\nwhere $\\rho_{\\mathrm{new}}$ is the density obtained from $V$ through the local Fermi momentum relation, $\\alpha \\in (0,1)$ controls stability, and $n$ indexes the iteration. Convergence is monitored using the infinity norm difference between successive densities,\n$$\n\\|\\rho_{\\mathrm{new}} - \\rho^{(n)}\\|_{\\infty}  \\varepsilon.\n$$\n\nAliasing arises when non-linear operations generate spectral content beyond the Nyquist wavenumber, $k_{\\mathrm{Ny}} = \\frac{\\pi N}{L}$, which then folds back into lower modes in a discrete representation. The momentum spacing is $\\Delta k = \\frac{2\\pi}{L}$, and finer resolution (smaller $\\Delta k$ and larger $k_{\\mathrm{Ny}}$) reduces aliasing. To characterize aliasing effects on self-consistency, we implement two solver variants: a \"direct\" solver with no spectral filtering and a \"dealiased\" solver that applies the two-thirds rule to the updated density $\\rho_{\\mathrm{new}}$. The two-thirds rule sets to zero all Fourier modes with any component satisfying\n$$\n|k_i|  \\frac{2}{3}k_{\\mathrm{Ny}},\n$$\nthus removing the highest one-third of modes in each direction and mitigating aliasing from non-linear generation of high-frequency components. The filter is applied to $\\rho_{\\mathrm{new}}$ before mixing, and the rest of the iteration proceeds accordingly.\n\nWe quantify aliasing by computing the relative difference in the converged vector potentials:\n$$\n\\mathrm{err} = \\frac{\\|\\ V_{\\mathrm{direct}} - V_{\\mathrm{dealiased}}\\ \\|_2}{\\|\\ V_{\\mathrm{dealiased}}\\ \\|_2},\n$$\nwhere a small value indicates minimal aliasing influence. We also report whether each solver meets the fixed-point tolerance $\\varepsilon$ within the iteration budget. The initial density is constructed from the chemical potential $\\mu$ as a uniform background\n$$\n\\rho_{\\mathrm{bg}} = \\frac{\\gamma}{6\\pi^2}\\left(\\max\\left[0,\\sqrt{\\mu^2 - M^2}\\right]\\right)^3,\n$$\nwith a Gaussian bump of amplitude $A$ and width $\\sigma$ centered at the box center:\n$$\n\\rho_{\\mathrm{init}}(\\mathbf{r}) = \\rho_{\\mathrm{bg}} + A\\exp\\left(-\\frac{|\\mathbf{r}|^2}{2\\sigma^2}\\right).\n$$\n\nAlgorithmic steps for each test case are:\n- Construct the uniform cubic grid with $N$ points per side over $[-L/2, L/2)$.\n- Build the discrete wavevector components using the FFT frequency convention and compute $\\tilde{K}(\\mathbf{k}) = \\frac{g_\\omega^2}{\\mathbf{k}^2 + m_\\omega^2}$.\n- Initialize $\\rho$ to $\\rho_{\\mathrm{init}}$.\n- Iterate: compute $V$ via spectral multiplication; compute $\\rho_{\\mathrm{new}}$ using the local Fermi momentum; optionally apply the two-thirds spectral filter to $\\rho_{\\mathrm{new}}$; mix to update $\\rho$; check convergence.\n- After convergence or reaching the maximum iterations, record whether the tolerance was achieved and compute the relative difference between the direct and dealiased converged $V$ fields.\n- Report $\\Delta k = \\frac{2\\pi}{L}$ and the metrics.\n\nThe provided test suite spans three regimes: a well-resolved case, a moderately resolved case with sharper features, and a coarse-grid case with sharp features to expose aliasing. The final program outputs a single line with the results aggregated as a list of lists:\n$$\n\\left[\\left[\\Delta k_1, \\mathrm{err}_1, \\mathrm{success}_{\\mathrm{direct},1}, \\mathrm{success}_{\\mathrm{dealiased},1}\\right], \\left[\\Delta k_2, \\mathrm{err}_2, \\mathrm{success}_{\\mathrm{direct},2}, \\mathrm{success}_{\\mathrm{dealiased},2}\\right], \\left[\\Delta k_3, \\mathrm{err}_3, \\mathrm{success}_{\\mathrm{direct},3}, \\mathrm{success}_{\\mathrm{dealiased},3}\\right]\\right].\n$$\nAll $\\Delta k$ values must be in fm$^{-1}$, while errors are dimensionless floats. The booleans are literal true/false values indicating solver convergence.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef k_grid_components(N, L):\n    # FFT frequencies in cycles per unit length, convert to radians per unit length\n    freqs = np.fft.fftfreq(N, d=L/N) * 2.0 * np.pi\n    kx = freqs\n    ky = freqs\n    kz = freqs\n    return kx, ky, kz\n\ndef yukawa_kernel_k(kx, ky, kz, g_omega, m_omega):\n    # Construct k^2 on the 3D grid using broadcasting\n    KX, KY, KZ = np.meshgrid(kx, ky, kz, indexing='ij')\n    k2 = KX**2 + KY**2 + KZ**2\n    # Spectral Yukawa kernel: g^2 / (k^2 + m^2)\n    return (g_omega**2) / (k2 + m_omega**2)\n\ndef fft_convolution(rho, kernel_k):\n    # Convolution via FFT: V_k = K_k * rho_k, V = ifft(V_k)\n    rho_k = np.fft.fftn(rho)\n    V_k = kernel_k * rho_k\n    V = np.fft.ifftn(V_k).real\n    return V\n\ndef two_thirds_filter(field, kx, ky, kz):\n    # Apply 2/3 de-aliasing rule in Fourier space (per-component cutoff)\n    field_k = np.fft.fftn(field)\n    kx_abs = np.abs(kx)\n    ky_abs = np.abs(ky)\n    kz_abs = np.abs(kz)\n    kx_ny = np.max(kx_abs) if len(kx_abs) > 0 else 0\n    ky_ny = np.max(ky_abs) if len(ky_abs) > 0 else 0\n    kz_ny = np.max(kz_abs) if len(kz_abs) > 0 else 0\n    kx_cut = (2.0/3.0) * kx_ny\n    ky_cut = (2.0/3.0) * ky_ny\n    kz_cut = (2.0/3.0) * kz_ny\n    mask_x = (kx_abs = kx_cut)\n    mask_y = (ky_abs = ky_cut)\n    mask_z = (kz_abs = kz_cut)\n    mask = (mask_x[:, None, None]  mask_y[None, :, None]  mask_z[None, None, :])\n    field_k_filtered = field_k * mask\n    return np.fft.ifftn(field_k_filtered).real\n\ndef local_density_from_potential(V, mu, M, gamma=4.0):\n    # k_F(r) = sqrt( max(0, (mu - V)^2 - M^2) )\n    term = (mu - V)**2 - M**2\n    kF = np.sqrt(np.maximum(0.0, term))\n    rho_new = (gamma / (6.0 * np.pi**2)) * (kF**3)\n    return rho_new\n\ndef initialize_density(N, L, mu, M, A, sigma, gamma=4.0):\n    # Background density from uniform Fermi momentum\n    kF_bg = np.sqrt(max(0.0, mu**2 - M**2))\n    rho_bg = (gamma / (6.0 * np.pi**2)) * (kF_bg**3)\n    # Coordinates centered at 0\n    x = np.linspace(-L/2.0, L/2.0, N, endpoint=False)\n    y = np.linspace(-L/2.0, L/2.0, N, endpoint=False)\n    z = np.linspace(-L/2.0, L/2.0, N, endpoint=False)\n    X, Y, Z = np.meshgrid(x, y, z, indexing='ij')\n    r2 = X**2 + Y**2 + Z**2\n    bump = A * np.exp(-r2 / (2.0 * sigma**2))\n    rho_init = rho_bg + bump\n    return rho_init\n\ndef self_consistent_solver(N, L, sigma, A, M, m_omega, g_omega, mu, alpha, tol, max_iter, dealiased):\n    # Prepare k-space components and kernel\n    kx, ky, kz = k_grid_components(N, L)\n    kernel_k = yukawa_kernel_k(kx, ky, kz, g_omega, m_omega)\n    # Initialize density\n    rho = initialize_density(N, L, mu, M, A, sigma)\n    success = False\n    for _ in range(max_iter):\n        # Compute vector potential via FFT convolution\n        V = fft_convolution(rho, kernel_k)\n        # Local density update\n        rho_new = local_density_from_potential(V, mu, M)\n        # Optional de-aliasing filter on the updated density\n        if dealiased:\n            rho_new = two_thirds_filter(rho_new, kx, ky, kz)\n        # Mixing\n        rho_mixed = (1.0 - alpha) * rho + alpha * rho_new\n        # Convergence check\n        res = np.max(np.abs(rho_new - rho))\n        rho = rho_mixed\n        if res  tol:\n            success = True\n            break\n    # Final potential from converged density\n    V_final = fft_convolution(rho, kernel_k)\n    return rho, V_final, success\n\ndef run_case(N, L, sigma, A, M, m_omega, g_omega, mu, alpha, tol, max_iter):\n    # Direct solver\n    rho_d, V_d, succ_d = self_consistent_solver(N, L, sigma, A, M, m_omega, g_omega, mu, alpha, tol, max_iter, dealiased=False)\n    # Dealiased solver\n    rho_f, V_f, succ_f = self_consistent_solver(N, L, sigma, A, M, m_omega, g_omega, mu, alpha, tol, max_iter, dealiased=True)\n    # Relative error between direct and dealiased potentials\n    num = np.linalg.norm((V_d - V_f).ravel())\n    den = np.linalg.norm(V_f.ravel())\n    rel_err = float(num / den) if den != 0.0 else 0.0\n    # Delta k\n    dk = 2.0 * np.pi / L\n    return [dk, rel_err, succ_d, succ_f]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N, L, sigma, A, M, m_omega, g_omega, mu, alpha, tol, max_iter)\n        (32, 30.0, 4.0, 0.05, 4.759, 3.97, 1.0, 5.0, 0.4, 1e-6, 200),\n        (24, 18.0, 2.0, 0.08, 4.759, 3.97, 1.0, 5.0, 0.4, 1e-6, 200),\n        (16, 10.0, 1.0, 0.10, 4.759, 3.97, 1.0, 5.0, 0.4, 1e-6, 200),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, L, sigma, A, M, m_omega, g_omega, mu, alpha, tol, max_iter = case\n        result = run_case(N, L, sigma, A, M, m_omega, g_omega, mu, alpha, tol, max_iter)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'[{r[0]},{r[1]},{str(r[2]).lower()},{str(r[3]).lower()}]' for r in results])}]\")\n\nsolve()\n```", "id": "3589504"}, {"introduction": "While simple linear mixing can achieve self-consistency, it often suffers from slow convergence or may fail entirely for realistic systems with strong correlations. This advanced practice [@problem_id:3589498] delves into the methods required to build robust and efficient solvers. Using a carefully constructed matrix model that mimics the structure of deformed nuclei, you will investigate the system's linear response by computing the Jacobian of the self-consistency map. This information is then used to construct a block-structured quasi-Newton preconditioner, a powerful technique that dramatically accelerates convergence and provides insight into the physics of coupled mean fields.", "problem": "Consider a reduced, finite-dimensional Relativistic Mean-Field (RMF) model for axially deformed nuclei that allows controlled breaking of axial symmetry and coupling between different projections of the total angular momentum on the symmetry axis. Start from the Dirac equation with a local Lorentz scalar field and a time-like Lorentz vector field, and the standard RMF definition of self-consistency: the scalar field equals the scalar density times a coupling constant, and the vector field equals the baryon (time-like) density times another coupling constant. In this problem, you will construct a two-sector model corresponding to two $K$-components, $K=\\frac{1}{2}$ and $K=\\frac{3}{2}$, and investigate how the coupling between these $K$-components changes the self-consistent field update map. You will also derive and implement a block-structured quasi-Newton preconditioner based on the sector structure of the fields.\n\nModeling assumptions and definitions:\n\n- The state space is a direct sum of two $K$-sectors, each with the two-component Dirac structure (large and small components). The resulting Hamiltonian is a $4\\times 4$ Hermitian matrix acting on spinors $\\psi=\\left(u_{1/2},\\ell_{1/2},u_{3/2},\\ell_{3/2}\\right)^{\\mathsf{T}}$. The free-kinetic Dirac block for sector $K$ is approximated by a $2\\times 2$ matrix with constant effective off-diagonal coupling, and constant rest mass. Denote the rest mass by $m$, and the kinetic couplings in the $K=\\frac{1}{2}$ and $K=\\frac{3}{2}$ sectors by $p_{1/2}$ and $p_{3/2}$, respectively.\n\n- A Lorentz scalar field $S_{K}$ and a time-like Lorentz vector field $V_{K}$ act within each $K$-sector. The block Hamiltonians are\n$$\nH_{K}=\\begin{pmatrix}\nm+V_{K}  p_{K} \\\\\np_{K}  -m+S_{K}\n\\end{pmatrix},\n$$\nfor $K\\in\\left\\{\\tfrac{1}{2},\\tfrac{3}{2}\\right\\}$.\n\n- Symmetry breaking couples the two $K$-sectors through a diagonal inter-sector block $B$ that connects like Dirac components. Let $\\beta$ denote a dimensionless deformation amplitude and $\\eta$ a dimensionless symmetry-breaking strength. The inter-sector block is modeled as\n$$\nB=\\eta\\,\\beta\\,\\begin{pmatrix}\nc_{uu}  0 \\\\\n0  c_{\\ell\\ell}\n\\end{pmatrix},\n$$\nwhere $c_{uu}$ and $c_{\\ell\\ell}$ are fixed, dimensionless constants representing how strongly the upper and lower components couple between sectors under symmetry breaking. The full Hamiltonian is the $4\\times 4$ matrix\n$$\nH=\\begin{pmatrix}\nH_{1/2}  B \\\\\nB  H_{3/2}\n\\end{pmatrix}.\n$$\n\n- The model uses standard RMF self-consistency: the fields are determined by the occupied spinors’ densities. For a normalized eigenvector $\\psi$ of $H$, define the sector-resolved baryon (time-like vector) density and scalar density by\n$$\nn_{v,K}=\\sum_{\\text{occ}}\\left(|u_{K}|^{2}+|\\ell_{K}|^{2}\\right),\\quad\nn_{s,K}=\\sum_{\\text{occ}}\\left(|u_{K}|^{2}-|\\ell_{K}|^{2}\\right),\n$$\nwhere the sum runs over the occupied positive-energy eigenstates. The self-consistency equations are\n$$\nS_{K}=g_{s}\\,n_{s,K},\\quad V_{K}=g_{v}\\,n_{v,K},\n$$\nwith scalar and vector coupling constants $g_{s}$ and $g_{v}$.\n\n- The self-consistent field update map $g:\\mathbb{R}^{4}\\to\\mathbb{R}^{4}$ takes a field vector $x=\\left(S_{1/2},V_{1/2},S_{3/2},V_{3/2}\\right)$ to $x_{\\text{new}}=g(x)$ obtained by:\n  1. Building $H$ from $x$,\n  2. Diagonalizing $H$,\n  3. Selecting the lowest positive-energy eigenstates up to a fixed occupation number $N_{\\text{occ}}$,\n  4. Computing $n_{s,K}$ and $n_{v,K}$,\n  5. Setting $S_{K}=g_{s}\\,n_{s,K}$ and $V_{K}=g_{v}\\,n_{v,K}$.\n\n- The fixed-point equation for self-consistency is $x=g(x)$. Define the residual $F(x)=x-g(x)$; a solution satisfies $F(x^{\\star})=0$.\n\nYour tasks:\n\n1. Implement the above model, with parameters $m$, $p_{1/2}$, $p_{3/2}$, $g_{s}$, $g_{v}$, $c_{uu}$, $c_{\\ell\\ell}$, deformation $\\beta$, symmetry-breaking strength $\\eta$, and occupation number $N_{\\text{occ}}$. Use a dimensionless formulation and do not introduce any physical units.\n\n2. For a given $x$, compute $g(x)$ and the Jacobian $\\mathrm{D}g(x)$ numerically by symmetric finite differences. From this, compute the spectral radius $\\rho\\left(\\mathrm{D}g(x)\\right)$ and the Frobenius-norm ratio\n$$\nr_{\\text{off}}=\\frac{\\left\\|\\begin{pmatrix}0  J_{12}\\\\ J_{21}  0\\end{pmatrix}\\right\\|_{F}}{\\|J\\|_{F}},\n$$\nwhere $J=\\mathrm{D}g(x)$ partitioned into $2\\times 2$ blocks $J_{ij}$ corresponding to the variables $\\left(S_{1/2},V_{1/2}\\right)$ and $\\left(S_{3/2},V_{3/2}\\right)$. This $r_{\\text{off}}$ quantifies how inter-sector coupling of $K$-components enters the self-consistent update map: larger $r_{\\text{off}}$ indicates stronger cross-coupling.\n\n3. Implement two solvers for $F(x)=0$:\n   - A linearly mixed fixed-point iteration $x_{k+1}=x_{k}-\\alpha\\,F(x_{k})$ with a fixed damping $\\alpha\\in(0,1]$.\n   - A quasi-Newton preconditioned iteration $x_{k+1}=x_{k}-M(x_{k})\\,F(x_{k})$, where $M(x)$ is a block-structured preconditioner approximating $\\left(\\mathrm{D}F(x)\\right)^{-1}$ by inverting only the $2\\times 2$ diagonal blocks of $\\mathrm{D}F(x)$. Here, $\\mathrm{D}F(x)=I-\\mathrm{D}g(x)$, so your $M(x)$ is the block-diagonal matrix with blocks $\\left(I-\\mathrm{D}g(x)\\big|_{\\text{sector }K}\\right)^{-1}$, computed numerically; regularize any nearly singular block by adding a small positive multiple of the identity if needed to ensure invertibility.\n\n4. For each test case, start from $x_{0}=0$ and iterate each solver until $\\|F(x_{k})\\|_{2}\\varepsilon$ or a maximum number of iterations is reached. Use the same stopping criteria for both solvers, and record the number of iterations required by each method.\n\n5. At the converged solution $x^{\\star}$ (or the last iterate if convergence fails), compute $\\rho\\left(\\mathrm{D}g\\left(x^{\\star}\\right)\\right)$ and $r_{\\text{off}}\\left(x^{\\star}\\right)$ as defined above.\n\nTest suite and required constants:\n\n- Use $m=1.0$, $p_{1/2}=0.8$, $p_{3/2}=1.2$, $g_{s}=-0.6$, $g_{v}=0.7$, $c_{uu}=0.5$, $c_{\\ell\\ell}=0.3$, $N_{\\text{occ}}=2$, $\\alpha=0.2$, $\\varepsilon=1.0\\times 10^{-8}$, and $\\text{max\\_iter}=500$.\n\n- Define the following four test cases as tuples $(\\beta,\\eta)$:\n  1. $(0.0,0.0)$,\n  2. $(0.2,0.05)$,\n  3. $(0.2,0.2)$,\n  4. $(0.2,0.4)$.\n\nFinal output specification:\n\n- For each test case, your program must produce a list with four entries: the spectral radius $\\rho\\left(\\mathrm{D}g\\left(x^{\\star}\\right)\\right)$ as a float, the off-block ratio $r_{\\text{off}}\\left(x^{\\star}\\right)$ as a float, the iteration count for the linear mixing solver as an integer, and the iteration count for the block-structured quasi-Newton preconditioned solver as an integer.\n\n- Your program should produce a single line of output containing the results for all test cases as a comma-separated list of these four-entry lists, enclosed in square brackets (e.g., $[\\,[\\rho_{1},r_{1},n_{1}^{\\text{lin}},n_{1}^{\\text{qN}}],\\ldots,[\\rho_{4},r_{4},n_{4}^{\\text{lin}},n_{4}^{\\text{qN}}]\\,]$).\n\nAll computations are dimensionless; do not use any physical units. Angles are not involved. Express all numbers internally in double-precision floating point; the final output is the list structure described above.", "solution": "The user-provided problem has been validated and is determined to be sound, well-posed, and scientifically grounded within the context of a simplified computational physics model. I will now provide a complete, reasoned solution.\n\n### 1. Theoretical and Algorithmic Framework\n\nThe problem requires the implementation and analysis of a self-consistent solution for a simplified Relativistic Mean-Field (RMF) model. The core task is to find a fixed point of an iterative map, which represents the self-consistent state of a nuclear system. We will develop the necessary components: the self-consistent map, its Jacobian, and two iterative solvers, and then apply them to the specified test cases.\n\n#### 1.1. Model Hamiltonian and State Space\n\nThe system is described by a $4 \\times 4$ Hamiltonian matrix acting on a four-component spinor $\\psi=\\left(u_{1/2},\\ell_{1/2},u_{3/2},\\ell_{3/2}\\right)^{\\mathsf{T}}$. The state space is a direct sum of two sectors, identified by the quantum number $K$, with $K \\in \\left\\{\\frac{1}{2}, \\frac{3}{2}\\right\\}$.\n\nThe full Hamiltonian $H$ is constructed from intra-sector blocks $H_K$ and an inter-sector coupling block $B$:\n$$\nH=\\begin{pmatrix}\nH_{1/2}  B \\\\\nB  H_{3/2}\n\\end{pmatrix}\n$$\nThe intra-sector blocks $H_K$ for $K \\in \\left\\{\\frac{1}{2}, \\frac{3}{2}\\right\\}$ are given by:\n$$\nH_{K}=\\begin{pmatrix}\nm+V_{K}  p_{K} \\\\\np_{K}  -m+S_{K}\n\\end{pmatrix}\n$$\nwhere $m$ is the nucleon rest mass, $p_K$ is the effective kinetic coupling for sector $K$, and $S_K$ and $V_K$ are the Lorentz scalar and time-like vector mean fields, respectively.\n\nThe inter-sector coupling block $B$ models symmetry-breaking effects:\n$$\nB=\\eta\\,\\beta\\,\\begin{pmatrix}\nc_{uu}  0 \\\\\n0  c_{\\ell\\ell}\n\\end{pmatrix}\n$$\nHere, $\\beta$ is a deformation parameter, $\\eta$ is the symmetry-breaking strength, and $c_{uu}$ and $c_{\\ell\\ell}$ are dimensionless coupling constants. The case $\\eta=0$ or $\\beta=0$ restores block-diagonality, decoupling the $K$-sectors.\n\n#### 1.2. The Self-Consistent Map $g(x)$\n\nSelf-consistency in RMF theory dictates that the mean fields are generated by the nucleons themselves. This feedback loop is formulated as a fixed-point problem. Let the vector of fields be $x = \\left(S_{1/2}, V_{1/2}, S_{3/2}, V_{3/2}\\right)^{\\mathsf{T}} \\in \\mathbb{R}^4$. The self-consistent map $g:\\mathbb{R}^{4}\\to\\mathbb{R}^{4}$ computes an updated field vector $x_{\\text{new}} = g(x)$ from an input vector $x$. The algorithm for computing $g(x)$ is as follows:\n\n1.  **Construct Hamiltonian**: Given an input field vector $x = (S_{1/2}, V_{1/2}, S_{3/2}, V_{3/2})$, the $4 \\times 4$ real symmetric Hamiltonian matrix $H$ is assembled using the definitions above.\n2.  **Diagonalize Hamiltonian**: The eigensystem of $H$ is solved: $H\\psi_i = E_i\\psi_i$. Since $H$ is Hermitian (real symmetric in our case), its eigenvalues $E_i$ are real and eigenvectors $\\psi_i$ can be chosen to be orthonormal. We obtain $4$ eigenpairs.\n3.  **Identify Occupied States**: The physical ground state is formed by filling the lowest-energy single-particle states. Following the model's specification, we select the $N_{\\text{occ}}$ eigenstates with the lowest positive eigenvalues.\n4.  **Compute Densities**: From the set of occupied eigenvectors $\\{\\psi_{\\text{occ}}\\}$, we compute the sector-resolved scalar and vector densities:\n    $$\n    n_{s,K}=\\sum_{\\text{occ}}\\left(|u_{K}|^{2}-|\\ell_{K}|^{2}\\right) \\quad \\text{and} \\quad n_{v,K}=\\sum_{\\text{occ}}\\left(|u_{K}|^{2}+|\\ell_{K}|^{2}\\right)\n    $$\n    where $u_K$ and $\\ell_K$ are the upper and lower components of the spinor within the $K$-sector.\n5.  **Compute New Fields**: The new field vector $x_{\\text{new}}$ is calculated using the source equations:\n    $$\n    S_{K,\\text{new}} = g_{s}\\,n_{s,K} \\quad \\text{and} \\quad V_{K,\\text{new}} = g_{v}\\,n_{v,K}\n    $$\n    with given coupling constants $g_s$ and $g_v$. The resulting vector is $x_{\\text{new}} = (S_{1/2,\\text{new}}, V_{1/2,\\text{new}}, S_{3/2,\\text{new}}, V_{3/2,\\text{new}})^{\\mathsf{T}}$. A self-consistent solution $x^\\star$ satisfies the fixed-point condition $x^\\star = g(x^\\star)$.\n\n#### 1.3. Iterative Solvers\n\nFinding the fixed point $x^\\star$ is equivalent to finding a root of the residual function $F(x) = x - g(x) = 0$. We implement two iterative methods to solve this equation.\n\n##### a) Linear Mixing\nThis is a damped fixed-point iteration. Starting from an initial guess $x_0$, the sequence of iterates is generated by:\n$$\nx_{k+1} = (1-\\alpha)x_k + \\alpha g(x_k) = x_k - \\alpha (x_k - g(x_k)) = x_k - \\alpha F(x_k)\n$$\nwhere $\\alpha \\in (0, 1]$ is a fixed damping factor that helps stabilize the iteration. Convergence is typically achieved if the spectral radius of the iteration matrix, $\\rho(I - \\alpha \\mathrm{D}F) = \\rho((1-\\alpha)I + \\alpha \\mathrm{D}g)$, is less than $1$. For simple mixing ($\\alpha=1$), this condition is $\\rho(\\mathrm{D}g(x^\\star))  1$.\n\n##### b) Block-Structured Quasi-Newton Method\nA full Newton's method for $F(x)=0$ would be $x_{k+1} = x_k - [\\mathrm{D}F(x_k)]^{-1} F(x_k)$, where $\\mathrm{D}F(x) = I - \\mathrm{D}g(x)$ is the Jacobian of the residual. This method is computationally expensive as it requires computing and inverting the full $4 \\times 4$ Jacobian at each step.\n\nThe specified quasi-Newton method simplifies this by approximating the inverse of the Jacobian. We partition the Jacobian $\\mathrm{D}F(x)$ into $2 \\times 2$ blocks corresponding to the two $K$-sectors:\n$$\n\\mathrm{D}F(x) = \\begin{pmatrix} \\mathrm{D}F_{11}  \\mathrm{D}F_{12} \\\\ \\mathrm{D}F_{21}  \\mathrm{D}F_{22} \\end{pmatrix}\n$$\nThe preconditioner $M(x)$ is constructed by inverting only the diagonal blocks and ignoring the off-diagonal blocks, thus approximating $(\\mathrm{D}F)^{-1}$:\n$$\nM(x) = \\begin{pmatrix} (\\mathrm{D}F_{11})^{-1}  0 \\\\ 0  (\\mathrm{D}F_{22})^{-1} \\end{pmatrix}\n$$\nThe iteration is then given by:\n$$\nx_{k+1} = x_{k} - M(x_k) F(x_k)\n$$\nThis method effectively treats the self-consistency problem within each sector independently at the level of the linear response, while the full non-linear coupling is retained in $F(x_k)$. It is expected to be more efficient than linear mixing, especially when the inter-sector coupling (the off-diagonal blocks of $\\mathrm{D}g$) is weak. To handle potential singularities in the diagonal blocks, a small regularization term $\\epsilon I$ is added before inversion.\n\n#### 1.4. Numerical Jacobian and Analysis Metrics\n\nThe Jacobian of the map, $J(x) = \\mathrm{D}g(x)$, is crucial for both the quasi-Newton solver and the analysis of the solution. It is computed numerically using a symmetric finite difference scheme for accuracy:\n$$\n\\frac{\\partial g_i}{\\partial x_j}(x) \\approx \\frac{g_i(x + h e_j) - g_i(x - h e_j)}{2h}\n$$\nwhere $h$ is a small step size and $e_j$ is the $j$-th standard basis vector.\n\nAt the converged solution $x^\\star$, two quantities are computed:\n1.  **Spectral Radius $\\rho(\\mathrm{D}g(x^\\star))$**: This is the maximum absolute eigenvalue of the Jacobian at the fixed point. It governs the local convergence rate of the simple fixed-point iteration ($x_{k+1}=g(x_k)$). If $\\rho  1$, the iteration converges locally.\n2.  **Off-Block Ratio $r_{\\text{off}}(x^\\star)$**: This metric quantifies the strength of the inter-sector coupling in the system's linear response. It is defined as the ratio of the Frobenius norm of the off-diagonal blocks of the Jacobian $J = \\mathrm{D}g(x^\\star)$ to the Frobenius norm of the entire Jacobian:\n    $$\n    r_{\\text{off}}=\\frac{\\left\\|\\begin{pmatrix}0  J_{12}\\\\ J_{21}  0\\end{pmatrix}\\right\\|_{F}}{\\|J\\|_{F}} = \\frac{\\sqrt{\\|J_{12}\\|_F^2 + \\|J_{21}\\|_F^2}}{\\|J\\|_F}\n    $$\n    A value of $r_{\\text{off}}=0$ indicates that the sectors are totally decoupled at the linear response level, while a larger value indicates stronger cross-talk between the sectors, which can slow down simple mixing schemes and justifies more sophisticated solvers like the quasi-Newton method.\n\n### 2. Implementation Strategy\n\nThe implementation proceeds by first defining a function for the map $g(x)$. Then, wrapper functions for the solvers and analysis are built upon it.\n- A central function `g_map` implements the five steps described in section 1.2.\n- A function `get_jacobian_Dg` computes the Jacobian of `g_map` using finite differences.\n- Two solver functions, `linear_solver` and `qn_solver`, implement the iterative schemes. They loop until the $L_2$ norm of the residual $F(x)$ falls below a tolerance $\\varepsilon$ or a maximum number of iterations is reached, returning the final solution and the iteration count.\n- An `analyze_solution` function computes $\\rho$ and $r_{\\text{off}}$ from the converged Jacobian.\n- The main script iterates through the four test cases defined by $(\\beta, \\eta)$, calls both solvers for each case starting from $x_0=0$, and collects the required metrics for the final formatted output. The converged solution from the more robust quasi-Newton solver is used for the final analysis.", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import block_diag\n\n# Set a fixed seed for reproducibility of numerical results\nnp.random.seed(42)\n\ndef g_map(x, beta, eta, params):\n    \"\"\"\n    Computes the self-consistent field update map x_new = g(x).\n\n    Args:\n        x (np.ndarray): Current field vector [S_1/2, V_1/2, S_3/2, V_3/2].\n        beta (float): Deformation amplitude.\n        eta (float): Symmetry-breaking strength.\n        params (dict): Dictionary of model parameters.\n\n    Returns:\n        np.ndarray: The new field vector x_new.\n    \"\"\"\n    # Unpack fields and parameters\n    S_12, V_12, S_32, V_32 = x\n    m, p_12, p_32 = params['m'], params['p_12'], params['p_32']\n    c_uu, c_ll = params['c_uu'], params['c_ll']\n    N_occ = params['N_occ']\n    gs, gv = params['g_s'], params['g_v']\n\n    # 1. Build Hamiltonian\n    H_12 = np.array([[m + V_12, p_12], [p_12, -m + S_12]])\n    H_32 = np.array([[m + V_32, p_32], [p_32, -m + S_32]])\n    B = eta * beta * np.array([[c_uu, 0.0], [0.0, c_ll]])\n    H = np.block([[H_12, B], [B, H_32]])\n\n    # 2. Diagonalize Hamiltonian\n    # H is real symmetric, eigh is efficient and returns sorted eigenvalues\n    eigvals, eigvecs = np.linalg.eigh(H)\n\n    # 3. Identify Occupied States\n    pos_eig_indices = np.where(eigvals > 0)[0]\n    \n    # Ensure there are enough positive energy states\n    if len(pos_eig_indices)  N_occ:\n        # This case should not happen for the given parameters but is good practice\n        # to handle. We return the input vector to indicate a failure in the map.\n        return x\n\n    occupied_indices = pos_eig_indices[:N_occ]\n    occupied_vecs = eigvecs[:, occupied_indices]\n\n    # 4. Compute Densities\n    # occupied_vecs is (4, N_occ).\n    u_12 = occupied_vecs[0, :]\n    l_12 = occupied_vecs[1, :]\n    u_32 = occupied_vecs[2, :]\n    l_32 = occupied_vecs[3, :]\n\n    n_v_12 = np.sum(np.abs(u_12)**2 + np.abs(l_12)**2)\n    n_s_12 = np.sum(np.abs(u_12)**2 - np.abs(l_12)**2)\n    n_v_32 = np.sum(np.abs(u_32)**2 + np.abs(l_32)**2)\n    n_s_32 = np.sum(np.abs(u_32)**2 - np.abs(l_32)**2)\n\n    # 5. Compute New Fields\n    S_12_new = gs * n_s_12\n    V_12_new = gv * n_v_12\n    S_32_new = gs * n_s_32\n    V_32_new = gv * n_v_32\n\n    return np.array([S_12_new, V_12_new, S_32_new, V_32_new])\n\ndef get_jacobian_Dg(x, beta, eta, params):\n    \"\"\"\n    Computes the Jacobian of the g_map numerically using symmetric finite differences.\n    \"\"\"\n    n_dim = len(x)\n    J = np.zeros((n_dim, n_dim))\n    h = params.get('h_fd', 1e-7)\n    \n    for j in range(n_dim):\n        dx = np.zeros(n_dim)\n        dx[j] = h\n        g_plus = g_map(x + dx, beta, eta, params)\n        g_minus = g_map(x - dx, beta, eta, params)\n        J[:, j] = (g_plus - g_minus) / (2 * h)\n        \n    return J\n\ndef linear_solver(x0, beta, eta, params):\n    \"\"\"\n    Solves the fixed-point equation using linear mixing.\n    \"\"\"\n    x = x0.copy()\n    alpha = params['alpha']\n    max_iter = params['max_iter']\n    epsilon = params['epsilon']\n    \n    for i in range(max_iter):\n        g_x = g_map(x, beta, eta, params)\n        F_x = x - g_x\n        if np.linalg.norm(F_x)  epsilon:\n            return x, i + 1\n        x -= alpha * F_x\n        \n    return x, max_iter\n\ndef qn_solver(x0, beta, eta, params):\n    \"\"\"\n    Solves the fixed-point equation using the block-structured quasi-Newton method.\n    \"\"\"\n    x = x0.copy()\n    max_iter = params['max_iter']\n    epsilon = params['epsilon']\n    reg = params.get('reg', 1e-12)\n\n    for i in range(max_iter):\n        g_x = g_map(x, beta, eta, params)\n        F_x = x - g_x\n        \n        if np.linalg.norm(F_x)  epsilon:\n            return x, i + 1\n            \n        J_g = get_jacobian_Dg(x, beta, eta, params)\n        DF = np.eye(4) - J_g\n        \n        DF11 = DF[0:2, 0:2]\n        DF22 = DF[2:4, 2:4]\n        \n        try:\n            DF11_inv = np.linalg.inv(DF11 + reg * np.eye(2))\n            DF22_inv = np.linalg.inv(DF22 + reg * np.eye(2))\n        except np.linalg.LinAlgError:\n            # If inversion fails, fall back to a simple mixing step for this iteration\n            x -= params['alpha'] * F_x\n            continue\n\n        M = block_diag(DF11_inv, DF22_inv)\n        step = M @ F_x\n        x -= step\n        \n    return x, max_iter\n\ndef analyze_solution(x_star, beta, eta, params):\n    \"\"\"\n    Computes spectral radius and off-block ratio at the solution.\n    \"\"\"\n    J = get_jacobian_Dg(x_star, beta, eta, params)\n    \n    # Spectral radius\n    eigvals = np.linalg.eigvals(J)\n    rho = np.max(np.abs(eigvals))\n    \n    # Off-block ratio\n    J12 = J[0:2, 2:4]\n    J21 = J[2:4, 0:2]\n    \n    norm_off = np.sqrt(np.linalg.norm(J12, 'fro')**2 + np.linalg.norm(J21, 'fro')**2)\n    norm_full = np.linalg.norm(J, 'fro')\n    \n    r_off = norm_off / norm_full if norm_full > 0 else 0.0\n    \n    return rho, r_off\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    params = {\n        'm': 1.0, 'p_12': 0.8, 'p_32': 1.2,\n        'g_s': -0.6, 'g_v': 0.7,\n        'c_uu': 0.5, 'c_ll': 0.3,\n        'N_occ': 2, 'alpha': 0.2,\n        'epsilon': 1.0e-8, 'max_iter': 500,\n    }\n    \n    test_cases = [\n        (0.0, 0.0),    # case 1\n        (0.2, 0.05),   # case 2\n        (0.2, 0.2),    # case 3\n        (0.2, 0.4),    # case 4\n    ]\n\n    all_results = []\n    \n    for beta, eta in test_cases:\n        x0 = np.zeros(4)\n        \n        # Run both solvers\n        x_lin, n_lin = linear_solver(x0, beta, eta, params)\n        x_qn, n_qN = qn_solver(x0, beta, eta, params)\n        \n        # Use the converged solution for analysis. If both converge, they should be\n        # effectively identical. If one fails, use the one that converged.\n        # Here we use the result from the QN solver as it's generally more robust.\n        x_star = x_qn\n        \n        rho, r_off = analyze_solution(x_star, beta, eta, params)\n        \n        all_results.append([rho, r_off, n_lin, n_qN])\n\n    # Format the output string as required\n    result_str = \",\".join([\n        f\"[{res[0]:.8f}, {res[1]:.8f}, {res[2]}, {res[3]}]\" for res in all_results\n    ])\n    \n    print(f\"[{result_str}]\")\n\nsolve()\n```", "id": "3589498"}]}