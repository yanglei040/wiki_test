{"hands_on_practices": [{"introduction": "The foundation of any trust-region method lies in constructing a local quadratic model of the objective function and using it to find a trial step. This first practice grounds these abstract concepts in a concrete calculation for a simple nonlinear system. By working through the process of defining the residual, computing the Jacobian, and forming the Gauss-Newton model, you will calculate the Cauchy step—the optimal step along the steepest-descent direction within the trust region—which guarantees a sufficient decrease in the model and is a cornerstone of global convergence proofs [@problem_id:3608055].", "problem": "Consider a two-degree-of-freedom nonlinear spring system with displacement vector $u=\\begin{pmatrix}u_1 \\\\ u_2\\end{pmatrix}$, internal force $R(u)=\\begin{pmatrix}k(u_1)u_1 \\\\ \\alpha u_2^{3}\\end{pmatrix}$, and external load $P=\\begin{pmatrix}P_1 \\\\ P_2\\end{pmatrix}$. The scalar stiffness function is $k(u_1)=k_0+\\beta u_1^{2}$ with positive parameters $k_0$ and $\\beta$, and the cubic parameter $\\alpha0$. The residual is defined by $F(u)=R(u)-P$, and the trust-region globalization method is applied to reduce the least-squares objective $\\phi(u)=\\tfrac{1}{2}\\|F(u)\\|_{2}^{2}$.\n\nStarting from the equilibrium principle $R(u)=P$ as the target equation, the least-squares objective $\\phi(u)$, and the definition of the Jacobian $J(u)=\\partial F/\\partial u$, proceed as follows:\n- Write the residual $F(u)$ and the objective $\\phi(u)$ explicitly in terms of $u_1$ and $u_2$.\n- At the iterate $u^{(0)}=\\begin{pmatrix}0.5 \\\\ 0.4\\end{pmatrix}$ with parameters $k_0=12$, $\\beta=4$, $\\alpha=3$, and load $P=\\begin{pmatrix}6.0 \\\\ 0.10\\end{pmatrix}$, form the Gauss–Newton quadratic model $m_0(s)=\\tfrac{1}{2}\\|F(u^{(0)})+J(u^{(0)})s\\|_2^{2}$ for the step $s\\in\\mathbb{R}^2$.\n- For the trust-region of radius $\\Delta=1$ in the Euclidean norm, determine the Cauchy step $s_c$ that minimizes $m_0(s)$ along the steepest-descent direction subject to $\\|s\\|_2\\le \\Delta$.\n\nExpress your final answer as the row vector $\\begin{pmatrix}s_{c,1}  s_{c,2}\\end{pmatrix}$, rounding each component to six significant figures. No units are required for the final answer.", "solution": "The target equation in static equilibrium is $R(u)=P$, which motivates minimizing the least-squares objective $\\phi(u)=\\tfrac{1}{2}\\|F(u)\\|_2^2$ where the residual $F(u)=R(u)-P$. For the given system,\n$$\nR(u)=\\begin{pmatrix}k(u_1)u_1 \\\\ \\alpha u_2^3\\end{pmatrix},\\quad k(u_1)=k_0+\\beta u_1^2,\n$$\nso the residual is\n$$\nF(u)=\\begin{pmatrix}k(u_1)u_1-P_1 \\\\ \\alpha u_2^3-P_2\\end{pmatrix}\n=\\begin{pmatrix}\\big(k_0+\\beta u_1^2\\big)u_1-P_1 \\\\ \\alpha u_2^3-P_2\\end{pmatrix}.\n$$\nThe objective to be reduced by the trust-region method is therefore\n$$\n\\phi(u)=\\tfrac{1}{2}\\left(\\big(\\big(k_0+\\beta u_1^2\\big)u_1-P_1\\big)^2+\\big(\\alpha u_2^3-P_2\\big)^2\\right).\n$$\nTo construct the Gauss–Newton model, we need the residual at the iterate and the Jacobian. At $u^{(0)}=\\begin{pmatrix}0.5 \\\\ 0.4\\end{pmatrix}$ with $k_0=12$, $\\beta=4$, $\\alpha=3$, and $P=\\begin{pmatrix}6.0 \\\\ 0.10\\end{pmatrix}$, compute\n$$\nk(u_1^{(0)})=k_0+\\beta (u_1^{(0)})^2=12+4(0.5)^2=12+1=13.\n$$\nHence\n$$\nR(u^{(0)})=\\begin{pmatrix}13\\cdot 0.5 \\\\ 3\\cdot (0.4)^3\\end{pmatrix}=\\begin{pmatrix}6.5 \\\\ 0.192\\end{pmatrix},\\quad\nF(u^{(0)})=R(u^{(0)})-P=\\begin{pmatrix}6.5-6.0 \\\\ 0.192-0.10\\end{pmatrix}=\\begin{pmatrix}0.5 \\\\ 0.092\\end{pmatrix}.\n$$\nThe Jacobian $J(u)=\\partial F/\\partial u=\\partial R/\\partial u$ for this diagonal system is\n$$\nJ(u)=\\begin{pmatrix}\\dfrac{\\partial}{\\partial u_1}\\big((k_0+\\beta u_1^2)u_1\\big)  0 \\\\ 0  \\dfrac{\\partial}{\\partial u_2}\\big(\\alpha u_2^3\\big)\\end{pmatrix}\n=\\begin{pmatrix}k_0+3\\beta u_1^2  0 \\\\ 0  3\\alpha u_2^2\\end{pmatrix}.\n$$\nEvaluated at $u^{(0)}$,\n$$\nJ(u^{(0)})=\\begin{pmatrix}12+3\\cdot 4\\cdot (0.5)^2  0 \\\\ 0  3\\cdot 3\\cdot (0.4)^2\\end{pmatrix}\n=\\begin{pmatrix}15  0 \\\\ 0  1.44\\end{pmatrix}.\n$$\nThe Gauss–Newton quadratic model around $u^{(0)}$ is\n$$\nm_0(s)=\\tfrac{1}{2}\\|F(u^{(0)})+J(u^{(0)})s\\|_2^2=\\phi(u^{(0)})+g^{\\top}s+\\tfrac{1}{2}s^{\\top}Bs,\n$$\nwhere the gradient and approximate Hessian are\n$$\ng=J(u^{(0)})^{\\top}F(u^{(0)}),\\quad B=J(u^{(0)})^{\\top}J(u^{(0)}).\n$$\nBecause $J(u^{(0)})$ is diagonal,\n$$\ng=\\begin{pmatrix}15  0 \\\\ 0  1.44\\end{pmatrix}\\begin{pmatrix}0.5 \\\\ 0.092\\end{pmatrix}=\\begin{pmatrix}7.5 \\\\ 0.13248\\end{pmatrix},\\quad\nB=\\begin{pmatrix}15^2  0 \\\\ 0  1.44^2\\end{pmatrix}=\\begin{pmatrix}225  0 \\\\ 0  2.0736\\end{pmatrix}.\n$$\nThe trust-region Cauchy step minimizes $m_0(s)$ along the steepest-descent direction $-g$ subject to $\\|s\\|_2\\le \\Delta$. Parametrize $s=-\\tau g$ with $\\tau\\ge 0$. Along this ray,\n$$\nm_0(-\\tau g)=\\phi(u^{(0)})-\\tau \\|g\\|_2^2+\\tfrac{1}{2}\\tau^2 g^{\\top}Bg.\n$$\nThe unconstrained minimizer occurs at\n$$\n\\tau_{\\ast}=\\frac{\\|g\\|_2^2}{g^{\\top}Bg}.\n$$\nIf $\\tau_{\\ast}\\|g\\|_2\\le \\Delta$, then the Cauchy step is $s_c=-\\tau_{\\ast}g$; otherwise it is truncated at the boundary $s_c=-\\frac{\\Delta}{\\|g\\|_2}g$.\n\nCompute the needed quantities:\n$$\n\\|g\\|_2^2=7.5^2+0.13248^2=56.25+0.0175509504=56.2675509504,\n$$\n$$\ng^{\\top}Bg=225\\cdot 7.5^2+2.0736\\cdot 0.13248^2=225\\cdot 56.25+2.0736\\cdot 0.0175509504=12656.25+0.03639365074944=12656.28639365075.\n$$\nThus\n$$\n\\tau_{\\ast}=\\frac{56.2675509504}{12656.28639365075}\\approx 0.0044458184.\n$$\nCheck the trust-region constraint with $\\Delta=1$:\n$$\n\\tau_{\\ast}\\|g\\|_2 \\approx 0.0044458184\\cdot \\sqrt{56.2675509504}\\approx 0.0044458184\\cdot 7.50117\\approx 0.033351,\n$$\nso the unconstrained minimizer is feasible. Therefore,\n$$\ns_c=-\\tau_{\\ast}g=-0.0044458184\\begin{pmatrix}7.5 \\\\ 0.13248\\end{pmatrix}=\\begin{pmatrix}-0.033343638 \\\\ -0.000588982021632\\end{pmatrix}.\n$$\nRounded to six significant figures for each component, the Cauchy step is\n$$\n\\begin{pmatrix}-0.0333436  -0.000588982\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}-0.0333436  -0.000588982\\end{pmatrix}}$$", "id": "3608055"}, {"introduction": "After computing a trial step, the \"globalization\" aspect of the trust-region method comes into play through a critical feedback mechanism. This exercise focuses on the core logic of step evaluation and acceptance. You will calculate the ratio $\\rho$, which compares the actual reduction achieved in the objective function to the reduction predicted by the quadratic model, and then apply a standard policy to update the trust-region radius $\\Delta$. This process is the \"brain\" of the algorithm, allowing it to adapt its ambition by shrinking the trust region when the model is poor and expanding it when the model proves accurate [@problem_id:3608057].", "problem": "In a nonlinear finite element equilibrium solve for hyperelasticity, consider minimizing the discrete total potential energy $\\phi(u)$ at the current Newton iterate $u$ using a trust-region globalization method. The trust-region method employs the quadratic model $m(p)$ built from the first and second derivatives of $\\phi$ at $u$, defined by\n$$\nm(p) \\equiv \\phi(u) + g^{\\top} p + \\tfrac{1}{2} p^{\\top} B p,\n$$\nwhere $g = \\nabla \\phi(u)$ and $B \\approx \\nabla^{2} \\phi(u)$ is a symmetric positive definite approximation of the Hessian.\n\nAt the current iterate, suppose the following data are available:\n- Objective values: $\\phi(u) = 10.5$ and $\\phi(u+p) = 9.62$.\n- Gradient: $g = \\begin{pmatrix} 6 \\\\ -2 \\end{pmatrix}$.\n- Hessian approximation: $B = \\begin{pmatrix} 8  1 \\\\ 1  2 \\end{pmatrix}$.\n- Proposed step: $p = \\begin{pmatrix} -0.1 \\\\ 0.2 \\end{pmatrix}$.\n- Current trust-region radius: $\\Delta_k = 0.25$.\n\nUsing the fundamental definition that the ratio $\\rho$ equals the actual reduction divided by the predicted reduction, with the actual reduction given by $\\phi(u) - \\phi(u+p)$ and the predicted reduction defined by $m(0) - m(p)$, compute $\\rho$.\n\nThen, determine the next trust-region radius $\\Delta_{k+1}$ according to the following fully specified acceptance and update policy with parameters $(\\eta_1,\\eta_2,\\gamma_{\\text{dec}},\\gamma_{\\text{inc}}) = (0.1, 0.9, 0.5, 2.0)$ and a boundary proximity factor $\\tau_b = 0.8$:\n- Accept the step if $\\rho \\ge \\eta_1$; otherwise reject it.\n- If $\\rho  \\eta_1$, set $\\Delta_{k+1} = \\gamma_{\\text{dec}} \\Delta_k$.\n- Else if $\\rho \\ge \\eta_2$ and $\\|p\\|_2 \\ge \\tau_b \\Delta_k$, set $\\Delta_{k+1} = \\gamma_{\\text{inc}} \\Delta_k$.\n- Else set $\\Delta_{k+1} = \\Delta_k$.\n\nReport the final answer as a row vector containing $\\rho$ and $\\Delta_{k+1}$, rounded to four significant figures, with no units.", "solution": "The problem requires the computation of two quantities related to a trust-region method for numerical optimization: the quality ratio $\\rho$ and the updated trust-region radius $\\Delta_{k+1}$.\n\nFirst, we calculate the ratio $\\rho$, which is defined as the actual reduction in the objective function divided by the predicted reduction from the quadratic model.\n\nThe actual reduction, denoted as $\\text{ared}$, is the change in the potential energy function $\\phi$:\n$$\n\\text{ared} = \\phi(u) - \\phi(u+p)\n$$\nUsing the given values, $\\phi(u) = 10.5$ and $\\phi(u+p) = 9.62$:\n$$\n\\text{ared} = 10.5 - 9.62 = 0.88\n$$\n\nThe predicted reduction, denoted as $\\text{pred}$, is the change in the quadratic model $m(p)$:\n$$\n\\text{pred} = m(0) - m(p)\n$$\nThe quadratic model is defined as $m(p) = \\phi(u) + g^{\\top} p + \\tfrac{1}{2} p^{\\top} B p$. At $p=0$, the model value is $m(0) = \\phi(u)$. Therefore, the predicted reduction is:\n$$\n\\text{pred} = \\phi(u) - \\left( \\phi(u) + g^{\\top} p + \\tfrac{1}{2} p^{\\top} B p \\right) = -g^{\\top} p - \\tfrac{1}{2} p^{\\top} B p\n$$\nWe compute the two terms in this expression using the provided data:\n$g = \\begin{pmatrix} 6 \\\\ -2 \\end{pmatrix}$, $p = \\begin{pmatrix} -0.1 \\\\ 0.2 \\end{pmatrix}$, and $B = \\begin{pmatrix} 8  1 \\\\ 1  2 \\end{pmatrix}$.\n\nThe linear term is $g^{\\top} p$:\n$$\ng^{\\top} p = \\begin{pmatrix} 6  -2 \\end{pmatrix} \\begin{pmatrix} -0.1 \\\\ 0.2 \\end{pmatrix} = (6)(-0.1) + (-2)(0.2) = -0.6 - 0.4 = -1.0\n$$\n\nThe quadratic term is $p^{\\top} B p$. First, we compute the product $B p$:\n$$\nB p = \\begin{pmatrix} 8  1 \\\\ 1  2 \\end{pmatrix} \\begin{pmatrix} -0.1 \\\\ 0.2 \\end{pmatrix} = \\begin{pmatrix} (8)(-0.1) + (1)(0.2) \\\\ (1)(-0.1) + (2)(0.2) \\end{pmatrix} = \\begin{pmatrix} -0.8 + 0.2 \\\\ -0.1 + 0.4 \\end{pmatrix} = \\begin{pmatrix} -0.6 \\\\ 0.3 \\end{pmatrix}\n$$\nNow, we compute $p^{\\top} (B p)$:\n$$\np^{\\top} B p = \\begin{pmatrix} -0.1  0.2 \\end{pmatrix} \\begin{pmatrix} -0.6 \\\\ 0.3 \\end{pmatrix} = (-0.1)(-0.6) + (0.2)(0.3) = 0.06 + 0.06 = 0.12\n$$\nSubstituting these back into the expression for the predicted reduction:\n$$\n\\text{pred} = -(-1.0) - \\tfrac{1}{2}(0.12) = 1.0 - 0.06 = 0.94\n$$\n\nNow we can compute the ratio $\\rho$:\n$$\n\\rho = \\frac{\\text{ared}}{\\text{pred}} = \\frac{0.88}{0.94} = \\frac{44}{47} \\approx 0.9361702...\n$$\nRounding to four significant figures, we get $\\rho \\approx 0.9362$.\n\nNext, we determine the next trust-region radius $\\Delta_{k+1}$ using the provided update policy and parameters $(\\eta_1, \\eta_2, \\gamma_{\\text{dec}}, \\gamma_{\\text{inc}}) = (0.1, 0.9, 0.5, 2.0)$ and $\\tau_b = 0.8$. The current radius is $\\Delta_k = 0.25$.\n\nThe update rules are:\n1. Accept the step if $\\rho \\ge \\eta_1$; otherwise reject.\n2. If $\\rho  \\eta_1$, set $\\Delta_{k+1} = \\gamma_{\\text{dec}} \\Delta_k$.\n3. Else if $\\rho \\ge \\eta_2$ and $\\|p\\|_2 \\ge \\tau_b \\Delta_k$, set $\\Delta_{k+1} = \\gamma_{\\text{inc}} \\Delta_k$.\n4. Else, set $\\Delta_{k+1} = \\Delta_k$.\n\nFirst, we check for step acceptance. We have $\\rho \\approx 0.9362$ and $\\eta_1 = 0.1$. Since $0.9362 \\ge 0.1$, the step is accepted. This means the first update rule (rule 2) for $\\rho  \\eta_1$ does not apply.\n\nWe proceed to the next condition (rule 3): $\\rho \\ge \\eta_2$ and $\\|p\\|_2 \\ge \\tau_b \\Delta_k$.\nThe first part of this condition is $\\rho \\ge \\eta_2$. With $\\eta_2 = 0.9$, we have $0.9362 \\ge 0.9$, which is true.\nThe second part is $\\|p\\|_2 \\ge \\tau_b \\Delta_k$. We need to compute both sides of this inequality.\nThe Euclidean norm of the step $p$ is:\n$$\n\\|p\\|_2 = \\sqrt{(-0.1)^2 + (0.2)^2} = \\sqrt{0.01 + 0.04} = \\sqrt{0.05} \\approx 0.2236\n$$\nThe boundary proximity threshold is:\n$$\n\\tau_b \\Delta_k = (0.8)(0.25) = 0.2\n$$\nComparing the two values, we check if $0.2236 \\ge 0.2$. This is true.\n\nSince both parts of the condition in rule 3 are true, we apply this rule to update the trust-region radius:\n$$\n\\Delta_{k+1} = \\gamma_{\\text{inc}} \\Delta_k\n$$\nUsing the given values $\\gamma_{\\text{inc}} = 2.0$ and $\\Delta_k = 0.25$:\n$$\n\\Delta_{k+1} = 2.0 \\times 0.25 = 0.5\n$$\nThe \"else\" condition (rule 4) is not reached.\n\nThe final values are $\\rho \\approx 0.9362$ and $\\Delta_{k+1} = 0.5$. The problem requests the answer to be rounded to four significant figures. Thus, $\\rho$ is $0.9362$ and $\\Delta_{k+1}$ is expressed as $0.5000$.\n\nThe final answer is the row vector containing these two values.", "answer": "$$\n\\boxed{\\begin{pmatrix} 0.9362  0.5000 \\end{pmatrix}}\n$$", "id": "3608057"}, {"introduction": "While the Cauchy step provides a safe and reliable descent direction, it can be overly conservative, leading to slow convergence. The dogleg method offers a more sophisticated and often more efficient way to approximate the solution to the trust-region subproblem. This conceptual exercise challenges you to understand the logic behind the dogleg path, which cleverly interpolates between the safe Cauchy step and the aggressive Newton step. By analyzing the different geometric cases, you will master the decision-making process that allows the algorithm to take the full Newton step when appropriate, or fall back to a constrained step on the dogleg path otherwise [@problem_id:3608044].", "problem": "Consider a nonlinear, quasi-static finite element equilibrium problem in computational solid mechanics, where the discrete equilibrium at the current iterate $u_k$ is enforced by driving the residual vector $r(u_k)$ to zero. To globalize the Newton method, a trust-region framework is used with the quadratic model $$m_k(p) = f(u_k) + g_k^\\top p + \\tfrac{1}{2}\\, p^\\top B_k\\, p,$$ where $f$ is a differentiable merit function (for example, a potential energy or a squared-residual merit), $g_k = \\nabla f(u_k)$ is the gradient of the merit function, and $B_k$ is a symmetric positive definite (SPD) approximation to the Hessian of $f$ (for example, the consistent tangent stiffness or a Gauss–Newton Hessian). The trust-region subproblem seeks $$\\min_{p \\in \\mathbb{R}^n} \\; m_k(p) \\quad \\text{subject to} \\quad \\|p\\|_2 \\le \\Delta_k,$$ where $\\|\\cdot\\|_2$ is the Euclidean norm and $\\Delta_k  0$ is the trust-region radius at iteration $k$.\n\nThe dogleg method constructs a piecewise-linear path from the origin to the Newton step $p_N$ via the Cauchy step $p_C$. The Newton step $p_N$ is defined by the solution of the linear system $$B_k\\, p_N = -\\, g_k,$$ and the Cauchy step $p_C$ is defined as the minimizer of $m_k(p)$ along the steepest descent ray $p(\\tau) = -\\, \\tau\\, g_k$ subject to $\\|p\\|_2 \\le \\Delta_k$, that is, $$p_C = -\\, \\tau^\\star\\, g_k, \\quad \\tau^\\star \\in \\arg\\min_{\\tau \\ge 0,\\; \\tau \\|g_k\\|_2 \\le \\Delta_k}\\; m_k(-\\,\\tau\\, g_k).$$ The dogleg path is the union of the segment from $0$ to $p_C$ and the segment from $p_C$ to $p_N$, and the dogleg step $p_{\\text{DL}}$ is chosen along this path to satisfy the trust-region constraint.\n\nStarting from these definitions and the fundamental facts that (i) an SPD $B_k$ implies that $m_k(\\cdot)$ is strictly convex and its unconstrained minimizer is $p_N$, and (ii) the Cauchy step $p_C$ lies on the ray $-g_k$ and either coincides with the unconstrained line minimizer or its truncation at the trust-region boundary, derive the decision logic for the dogleg step and identify the conditions under which the dogleg step equals $p_N$, equals $p_C$, or lies on the second segment of the dogleg path scaled to satisfy $\\|p\\|_2 = \\Delta_k$.\n\nSelect all statements that are correct.\n\nA. If $\\|p_N\\|_2 \\le \\Delta_k$, then $p_{\\text{DL}} = p_N$.\n\nB. If $\\|p_N\\|_2  \\Delta_k$ and $\\|p_C\\|_2 = \\Delta_k$, then $p_{\\text{DL}} = p_C$.\n\nC. If $\\|p_N\\|_2  \\Delta_k$ and $\\|p_C\\|_2  \\Delta_k$, then $p_{\\text{DL}}$ lies on the segment $\\{\\, p_C + \\theta\\, (p_N - p_C) : \\theta \\in (0,1)\\,\\}$ at the unique $\\theta$ for which $\\|p_C + \\theta\\, (p_N - p_C)\\|_2 = \\Delta_k$.\n\nD. If $\\|p_N\\|_2 \\le \\Delta_k$ but $g_k^\\top p_N  0$, then $p_{\\text{DL}} = p_C$ because the Newton step is ascent for $m_k(\\cdot)$.\n\nE. If $B_k$ is indefinite, then $p_{\\text{DL}} = p_C$ for all $\\Delta_k  0$ because the dogleg method avoids Newton steps in nonconvex settings in solid mechanics.\n\nChoose the option(s) that correctly characterize the dogleg step classification in this trust-region globalization setting for computational solid mechanics.", "solution": "The problem statement describes a standard dogleg trust-region method for globalizing a Newton-like iteration in the context of computational solid mechanics. The problem is well-posed, scientifically grounded, and internally consistent. The definitions provided for the quadratic model $m_k(p)$, the Newton step $p_N$, and the Cauchy step $p_C$ are standard in the field of numerical optimization. The key assumption that the Hessian approximation $B_k$ is symmetric positive definite (SPD) is crucial and will be used throughout the derivation. Let us proceed with the analysis.\n\nThe dogleg method seeks an approximate solution to the trust-region subproblem:\n$$ \\min_{p \\in \\mathbb{R}^n} \\; m_k(p) \\quad \\text{subject to} \\quad \\|p\\|_2 \\le \\Delta_k $$\nby constraining the search for the step $p$ to a piecewise-linear \"dogleg\" path. This path, denoted $\\mathcal{P}_{DL}$, is constructed from the origin to the Cauchy point $p_C$, and then from the Cauchy point to the Newton point $p_N$.\n\nThe Newton step $p_N = -B_k^{-1} g_k$ is the unconstrained minimizer of the quadratic model $m_k(p)$, as the gradient of the model, $\\nabla m_k(p) = g_k + B_k p$, is zero at $p=p_N$. Since $B_k$ is SPD, $m_k(p)$ is a strictly convex quadratic function, and $p_N$ is its unique global minimum.\n\nThe Cauchy step $p_C = -\\tau^\\star g_k$ is the minimizer of $m_k(p)$ along the steepest descent direction $-g_k$, constrained by the trust region. The unconstrained minimizer along this line is $p_{C,uc} = -\\tau_{uc} g_k$ where $\\tau_{uc} = \\frac{g_k^\\top g_k}{g_k^\\top B_k g_k} = \\frac{\\|g_k\\|_2^2}{g_k^\\top B_k g_k}$. Since $B_k$ is SPD, $g_k^\\top B_k g_k  0$ (for $g_k \\ne 0$), so $\\tau_{uc}  0$. The Cauchy step $p_C$ is then the shorter of $p_{C,uc}$ and the step that reaches the trust-region boundary: $\\|p_C\\|_2 = \\min(\\|p_{C,uc}\\|_2, \\Delta_k)$. By its definition, the Cauchy step always satisfies the trust-region constraint, i.e., $\\|p_C\\|_2 \\le \\Delta_k$.\n\nA key property of the dogleg path is that the model function value $m_k(p)$ decreases monotonically as one moves along the path from the origin towards the Newton step $p_N$. This is because the first segment is along the steepest descent direction, and the second segment moves from the Cauchy point (the constrained minimizer along the steepest-descent line) towards the global minimizer $p_N$. Therefore, the optimal dogleg step $p_{\\text{DL}}$ is the point on the path $\\mathcal{P}_{DL}$ that is furthest from the origin, yet still satisfies the trust-region constraint $\\|p\\|_2 \\le \\Delta_k$.\n\nWe can now derive the decision logic by considering the position of $p_N$ relative to the trust region.\n\n**Case 1: The Newton step is inside the trust region.**\nThis corresponds to the condition $\\|p_N\\|_2 \\le \\Delta_k$. In this case, the entire dogleg path from the origin to $p_N$ lies within the trust region. Since $p_N$ is the global minimizer of $m_k(p)$, and it is attainable (i.e., it lies on the path and satisfies the constraint), it is the optimal choice for the step.\nThus, if $\\|p_N\\|_2 \\le \\Delta_k$, then $p_{\\text{DL}} = p_N$.\n\n**Case 2: The Newton step is outside the trust region.**\nThis corresponds to the condition $\\|p_N\\|_2  \\Delta_k$. In this situation, the full Newton step is not a feasible solution. Since the model value improves as we move along the dogleg path towards $p_N$, the optimal step $p_{\\text{DL}}$ must lie on the boundary of the trust region, i.e., $\\|p_{\\text{DL}}\\|_2 = \\Delta_k$. We must determine where the dogleg path intersects this boundary. This depends on the length of the Cauchy step, $\\|p_C\\|_2$.\n\n*   **Subcase 2a: The Cauchy step lies on the trust-region boundary.**\n    This occurs when the minimum along the steepest descent direction is reached at or beyond the boundary, meaning $\\|p_{C,uc}\\|_2 \\ge \\Delta_k$. By definition, this gives $\\|p_C\\|_2 = \\Delta_k$. The first segment of the dogleg path, from the origin to $p_C$, ends on the boundary. Any point on the second segment, from $p_C$ to $p_N$, must lie outside the open trust region $\\|p\\|_2  \\Delta_k$. Since the best step on the path inside or on the boundary is sought, and the path only re-enters the trust region by going backwards towards the origin, the furthest point along the path that is feasible is $p_C$.\n    Thus, if $\\|p_N\\|_2  \\Delta_k$ and $\\|p_C\\|_2 = \\Delta_k$, then $p_{\\text{DL}} = p_C$.\n\n*   **Subcase 2b: The Cauchy step lies strictly inside the trust region.**\n    This occurs when the minimum along the steepest descent direction is reached before the boundary, meaning $\\|p_{C,uc}\\|_2  \\Delta_k$. This gives $p_C = p_{C,uc}$ and thus $\\|p_C\\|_2  \\Delta_k$. The dogleg path starts at the origin, passes through $p_C$ (strictly inside the trust region), and proceeds towards $p_N$ (outside the trust region). Since the path is continuous, it must intersect the trust-region boundary $\\|p\\|_2 = \\Delta_k$. This intersection must occur on the second segment of the path, connecting $p_C$ and $p_N$. The dogleg step $p_{\\text{DL}}$ is this intersection point. It can be written as $p_{\\text{DL}} = p_C + \\theta(p_N - p_C)$ for some $\\theta \\in (0, 1)$, where $\\theta$ is chosen to satisfy $\\|p_C + \\theta(p_N - p_C)\\|_2 = \\Delta_k$. Solving this quadratic equation for $\\theta$ yields the desired step. Because the path starts inside the circle at $p_C$ and ends outside at $p_N$, a unique intersection point in the direction of $p_N$ exists.\n    Thus, if $\\|p_N\\|_2  \\Delta_k$ and $\\|p_C\\|_2  \\Delta_k$, then $p_{\\text{DL}}$ is the unique point on the line segment connecting $p_C$ and $p_N$ that lies on the trust-region boundary.\n\nNow we evaluate each option.\n\n**A. If $\\|p_N\\|_2 \\le \\Delta_k$, then $p_{\\text{DL}} = p_N$.**\nThis matches our derivation for Case 1. The full Newton step is the unconstrained minimizer of the model, and since it is feasible, it is the best possible step.\n**Verdict: Correct.**\n\n**B. If $\\|p_N\\|_2  \\Delta_k$ and $\\|p_C\\|_2 = \\Delta_k$, then $p_{\\text{DL}} = p_C$.**\nThis matches our derivation for Subcase 2a. The Cauchy step is already on the boundary, and is the furthest point along the path that remains in the feasible region.\n**Verdict: Correct.**\n\n**C. If $\\|p_N\\|_2  \\Delta_k$ and $\\|p_C\\|_2  \\Delta_k$, then $p_{\\text{DL}}$ lies on the segment $\\{\\, p_C + \\theta\\, (p_N - p_C) : \\theta \\in (0,1)\\,\\}$ at the unique $\\theta$ for which $\\|p_C + \\theta\\, (p_N - p_C)\\|_2 = \\Delta_k$.**\nThis matches our derivation for Subcase 2b. The path crosses the trust-region boundary between $p_C$ and $p_N$, and this intersection point is the step.\n**Verdict: Correct.**\n\n**D. If $\\|p_N\\|_2 \\le \\Delta_k$ but $g_k^\\top p_N  0$, then $p_{\\text{DL}} = p_C$ because the Newton step is ascent for $m_k(\\cdot)$.**\nThis statement contains a premise that contradicts the problem setup. The problem assumes $B_k$ is SPD. The Newton step is $p_N = -B_k^{-1} g_k$. We examine the quantity $g_k^\\top p_N$:\n$$ g_k^\\top p_N = g_k^\\top (-B_k^{-1} g_k) = - g_k^\\top B_k^{-1} g_k $$\nSince $B_k$ is SPD, its inverse $B_k^{-1}$ is also SPD. For any non-zero gradient $g_k$ (which we assume, otherwise the iteration has converged), the quadratic form $g_k^\\top B_k^{-1} g_k$ is strictly positive. Therefore, $g_k^\\top p_N  0$. The condition $g_k^\\top p_N  0$ is mathematically impossible under the given assumptions. The directional derivative of $m_k(p)$ at $p=0$ along the direction $p_N$ is $g_k^\\top p_N$, which is negative, meaning $p_N$ is a descent direction, not an ascent direction. The option is based on a false premise.\n**Verdict: Incorrect.**\n\n**E. If $B_k$ is indefinite, then $p_{\\text{DL}} = p_C$ for all $\\Delta_k  0$ because the dogleg method avoids Newton steps in nonconvex settings in solid mechanics.**\nThis statement's premise, \"$B_k$ is indefinite,\" directly contradicts a central assumption of the problem statement: \"$B_k$ is a symmetric positive definite (SPD) approximation\". The entire derivation of the dogleg method as described, including the definition and properties of $p_N$ as the unique minimizer of a convex model, relies on $B_k$ being SPD. The question is to \"derive the decision logic for the dogleg step\" based on the provided definitions. Introducing a condition that violates these definitions renders the analysis outside the scope of the problem. While other trust-region methods are designed to handle indefinite Hessians, this specific formulation is not.\n**Verdict: Incorrect.**\n\nSummary: Options A, B, and C correctly describe the three possible outcomes for the choice of the dogleg step based on the standard algorithm under the assumption of an SPD Hessian approximation.", "answer": "$$\\boxed{ABC}$$", "id": "3608044"}]}