{"hands_on_practices": [{"introduction": "Understanding advanced domain decomposition methods begins with building the core components from the ground up. This practice guides you through the process of deriving and implementing a FETI-style dual problem for a model elliptic equation, starting from a standard finite element discretization. By constructing the local Schur complements, the dual operator $F$, and a block-diagonal preconditioner, you will gain concrete insight into the machinery of these powerful solvers and explore the critical trade-off between computational cost and preconditioner quality [@problem_id:3565959].", "problem": "Consider the scalar linearized mechanics model posed as the homogeneous Dirichlet boundary value problem for the Laplace operator on the unit square. Let $u$ denote the displacement-like scalar field, and let $\\Omega = (0,1)\\times(0,1) \\subset \\mathbb{R}^2$ with boundary $\\partial \\Omega$. The continuous problem is to find $u \\in H_0^1(\\Omega)$ such that for all admissible test functions $v \\in H_0^1(\\Omega)$,\n$$\n\\int_{\\Omega} \\nabla u \\cdot \\nabla v \\, d\\Omega \\;=\\; \\int_{\\Omega} f v \\, d\\Omega,\n$$\nwith $f \\equiv 0$. This is a standard model in computational solid mechanics for scalar diffusion or antiplane shear, and it provides a clean setting to study domain decomposition.\n\nYou will discretize the weak form using bilinear $Q_1$ finite elements on a structured grid of $N_x \\times N_y$ rectangular elements, so the grid has $(N_x+1)\\times(N_y+1)$ nodes. Dirichlet boundary conditions are enforced by eliminating the boundary degrees of freedom, leaving only interior unknowns. Partition the domain into $s_x$ nonoverlapping subdomains by cutting only along the $x$-direction into $s_x$ strips of equal element width. Assume that $N_x$ is divisible by $s_x$ so that subdomain interfaces align with element edges.\n\nStarting from the fundamental definitions above, you must derive and implement the following construction entirely from first principles:\n\n- Use the standard finite element assembly to form the global stiffness matrix $K$ on the unknown (interior) nodes. Restrict $K$ to each subdomain to obtain local stiffness matrices $K^{(i)}$ for subdomain index $i \\in \\{0,\\dots,s_x-1\\}$, using the subdomain’s local interior and boundary node sets relative to the global outer boundary. For each subdomain $i$, partition its local matrix as\n$$\nK^{(i)} \\;=\\; \\begin{bmatrix}\nK^{(i)}_{bb} & K^{(i)}_{bi} \\\\\nK^{(i)}_{ib} & K^{(i)}_{ii}\n\\end{bmatrix},\n$$\nwhere the index set $b$ contains the subdomain’s interface boundary unknowns that lie on interior subdomain cuts (not on $\\partial \\Omega$), and $i$ contains the subdomain’s strictly interior unknowns. Use the Schur complement\n$$\nS^{(i)} \\;=\\; K^{(i)}_{bb} \\;-\\; K^{(i)}_{bi}\\,\\big(K^{(i)}_{ii}\\big)^{-1}\\,K^{(i)}_{ib}\n$$\nto define the local Dirichlet-to-Neumann map on the subdomain interface unknowns.\n\n- Introduce Lagrange multipliers to enforce continuity across subdomain interfaces. For each interior cut index $k \\in \\{1,\\dots,s_x-1\\}$ and each interior grid line index $j \\in \\{1,\\dots,N_y-1\\}$ along $y$, introduce one dual variable corresponding to the interface node at the cut $k$ and vertical position $j$. Order the dual variables first by cut $k$ and then by vertical index $j$, yielding a dual vector $\\lambda \\in \\mathbb{R}^{n_\\lambda}$ of length $n_\\lambda = (s_x-1)\\,(N_y-1)$. Define, for each subdomain $i$, a signed boolean incidence operator $C^{(i)} \\in \\mathbb{R}^{n_\\lambda \\times n_b^{(i)}}$ mapping subdomain interface boundary displacements to interface jump constraints, where $n_b^{(i)}$ is the number of interface boundary unknowns in subdomain $i$, and the signs are chosen consistently so that the continuity condition at each interface node reads $u^{(i)}_{\\text{right}} - u^{(i+1)}_{\\text{left}} = 0$.\n\n- Using only these constructions, derive the dual operator $F \\in \\mathbb{R}^{n_\\lambda \\times n_\\lambda}$ that maps Lagrange multipliers to interface jumps. Express $F$ in terms of the local Schur complements and the boolean maps $\\{C^{(i)}\\}$. Do not invoke or assume any formula beyond what can be derived from the weak form, finite element assembly, and static condensation.\n\n- Propose a block-diagonal preconditioner $M$ for the dual operator $F$ built from the local interface Schur complements. Specifically, define\n$$\nM \\;=\\; \\sum_{i=0}^{s_x-1} C^{(i)} D^{(i)} \\big(C^{(i)}\\big)^{\\top},\n$$\nwhere $D^{(i)}$ approximates $\\big(S^{(i)}\\big)^{-1}$. Construct and compare two choices:\n  1. Exact local solves where $D^{(i)} = \\big(S^{(i)}\\big)^{-1}$ via a sparse direct factorization.\n  2. Approximate local solves where $D^{(i)} \\approx \\big(S^{(i)}\\big)^{-1}$ computed by a sparse incomplete factorization with controlled drop tolerance.\n\n- Quantitatively analyze the trade-offs between the exact and approximate local solves by computing, for each choice of $D^{(i)}$, the spectral condition number estimate of the left-preconditioned operator $M^{-1} F$, defined as the ratio of the largest to the smallest eigenvalue (taking the real parts if necessary). This number quantifies the expected convergence behavior of Krylov methods and reveals the benefit or degradation due to approximation.\n\nImplementation requirements:\n\n- Discretize the bilinear form using standard bilinear $Q_1$ elements and $2\\times 2$ Gauss integration on each element. Use the uniform mesh with element sizes $h_x = 1/N_x$ and $h_y = 1/N_y$. Use homogeneous Dirichlet boundary conditions on all of $\\partial \\Omega$. Assemble $K$ only on the interior nodes (unknowns).\n- Build each subdomain’s local matrix by extracting rows and columns of $K$ corresponding to the subdomain’s nodes. Identify $b$ and $i$ within each subdomain, and form $S^{(i)}$ exactly by static condensation using a sparse direct factorization of $K^{(i)}_{ii}$.\n- Assemble the exact dual operator $F$ from the local contributions and boolean maps. Construct $M$ in two variants: exact (with $D^{(i)} = \\big(S^{(i)}\\big)^{-1}$) and approximate (with $D^{(i)}$ obtained by applying a sparse incomplete factorization to $S^{(i)}$).\n- For each variant, form $M^{-1} F$ as a dense matrix via columnwise solves with $M$, and compute its eigenvalues to estimate the condition number as $\\kappa = \\lambda_{\\max}/\\lambda_{\\min}$ using the real parts of the eigenvalues and ignoring values smaller than a small positive threshold.\n\nTest suite and required output:\n\nUse the following three test cases, each specified by $(N_x,N_y,s_x,\\tau)$ where $\\tau$ is the drop tolerance for the incomplete factorization:\n\n- Case $1$: $(N_x,N_y,s_x,\\tau) = (12,8,3,10^{-4})$.\n- Case $2$: $(N_x,N_y,s_x,\\tau) = (8,8,2,10^{-2})$.\n- Case $3$: $(N_x,N_y,s_x,\\tau) = (20,12,4,5\\times 10^{-2})$.\n\nFor each case, compute and return a pair of floating-point numbers $[\\kappa_{\\text{exact}}, \\kappa_{\\text{approx}}]$, where $\\kappa_{\\text{exact}}$ is the condition number estimate obtained with exact local solves and $\\kappa_{\\text{approx}}$ is the estimate obtained with the incomplete factorization of the local Schur complements using the given drop tolerance $\\tau$.\n\nFinal output format:\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each entry is the two-element list for a test case in the same order as listed above. For example, a valid output looks like\n$$\n[\\,[\\kappa_{\\text{exact}}^{(1)},\\kappa_{\\text{approx}}^{(1)}],\\,[\\kappa_{\\text{exact}}^{(2)},\\kappa_{\\text{approx}}^{(2)}],\\,[\\kappa_{\\text{exact}}^{(3)},\\kappa_{\\text{approx}}^{(3)}]\\,].\n$$\nAll quantities are unitless; no physical units are required. Angles are not involved. Express numerical answers as decimal floating-point values. Your program must not read any input and must print exactly one line in the format above.", "solution": "## Problem Validation\n\n### Step 1: Extract Givens\n- **Continuous Problem:** Find $u \\in H_0^1(\\Omega)$ such that $\\int_{\\Omega} \\nabla u \\cdot \\nabla v \\, d\\Omega = \\int_{\\Omega} f v \\, d\\Omega$, with domain $\\Omega = (0,1)\\times(0,1)$ and forcing term $f \\equiv 0$.\n- **Discretization:** Bilinear $Q_1$ finite elements on a structured $N_x \\times N_y$ grid. Homogeneous Dirichlet boundary conditions on $\\partial \\Omega$ enforced by eliminating boundary degrees of freedom.\n- **Domain Decomposition:** The domain is partitioned into $s_x$ non-overlapping vertical strips of equal width. $N_x$ is assumed to be divisible by $s_x$.\n- **Local Stiffness Matrix Partition:** For each subdomain $i$, the local matrix $K^{(i)}$ is partitioned as $K^{(i)} = \\begin{bmatrix} K^{(i)}_{bb} & K^{(i)}_{bi} \\\\ K^{(i)}_{ib} & K^{(i)}_{ii} \\end{bmatrix}$, where '$b$' denotes interface boundary unknowns and '$i$' denotes strictly interior unknowns for the subdomain.\n- **Local Schur Complement:** $S^{(i)} = K^{(i)}_{bb} - K^{(i)}_{bi}(K^{(i)}_{ii})^{-1}K^{(i)}_{ib}$.\n- **Continuity Enforcement:** Lagrange multipliers $\\lambda \\in \\mathbb{R}^{n_\\lambda}$ with $n_\\lambda = (s_x-1)(N_y-1)$. A signed boolean incidence operator $C^{(i)}$ maps local interface displacements to global interface jump constraints, according to the rule $u^{(i)}_{\\text{right}} - u^{(i+1)}_{\\text{left}} = 0$.\n- **Dual Operator:** Derive the operator $F$ that maps Lagrange multipliers to interface jumps.\n- **Preconditioner:** Construct a block-diagonal preconditioner $M = \\sum_{i=0}^{s_x-1} C^{(i)} D^{(i)} (C^{(i)})^{\\top}$.\n- **Preconditioner Variants:**\n  1. **Exact:** $D^{(i)} = (S^{(i)})^{-1}$ via sparse direct factorization.\n  2. **Approximate:** $D^{(i)} \\approx (S^{(i)})^{-1}$ via sparse incomplete factorization of $S^{(i)}$ with drop tolerance $\\tau$.\n- **Analysis Task:** Compute the spectral condition number estimate $\\kappa = \\lambda_{\\max}/\\lambda_{\\min}$ of the preconditioned operator $M^{-1}F$ for both variants, using the real parts of eigenvalues and a small positive threshold.\n- **Implementation Details:** Use $2\\times2$ Gauss integration for element stiffness matrices.\n- **Test Cases:**\n  1. $(N_x,N_y,s_x,\\tau) = (12,8,3,10^{-4})$\n  2. $(N_x,N_y,s_x,\\tau) = (8,8,2,10^{-2})$\n  3. $(N_x,N_y,s_x,\\tau) = (20,12,4,5\\times 10^{-2})$\n- **Output Format:** A single line `[ [k_exact1, k_approx1], [k_exact2, k_approx2], [k_exact3, k_approx3] ]`.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is evaluated against the validation criteria.\n- **Scientifically Grounded:** The problem describes a standard Finite Element Tearing and Interconnecting (FETI) or Balancing Domain Decomposition (BDD) method for solving an elliptic partial differential equation. The use of finite elements, static condensation (Schur complements), Lagrange multipliers, and preconditioning are all standard, well-established techniques in computational science and engineering. The formulation is mathematically and scientifically sound.\n- **Well-Posed:** The underlying Poisson problem with homogeneous Dirichlet conditions is well-posed. The discrete formulation via finite elements results in a symmetric positive-definite stiffness matrix, ensuring a unique solution. The dual problem formulation is also well-posed. All required parameters and definitions are provided, making the problem self-contained and unambiguous.\n- **Objective:** The language is precise, formal, and free of subjectivity. All terms are defined within the standard lexicon of numerical analysis and computational mechanics.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. It is a clear, self-contained, and scientifically sound problem in the field of computational mechanics. I will now provide a complete solution.\n\n## Solution Methodology\n\nThe solution requires the implementation of a one-level FETI-type domain decomposition method. The methodology proceeds as follows:\n\n1.  **Finite Element Discretization:** The weak form of the Laplace equation is discretized using bilinear ($Q_1$) quadrilateral elements on a uniform rectangular mesh. The element stiffness matrix $K^e$ for an element of size $h_x \\times h_y$ is computed using $2\\times2$ Gauss quadrature. These element matrices are assembled into a global stiffness matrix $K$ corresponding to the $(N_x-1)(N_y-1)$ interior degrees of freedom (DoFs).\n\n2.  **Domain Decomposition and Matrix Partitioning:** The global set of DoFs is partitioned among $s_x$ subdomains. For each subdomain $i$, its DoFs are further classified into two sets: those strictly in its interior ($i$-nodes) and those on its interface with other subdomains ($b$-nodes). This induces a block partitioning of the subdomain stiffness matrix $K^{(i)}$:\n    $$\n    K^{(i)} = \\begin{bmatrix} K^{(i)}_{bb} & K^{(i)}_{bi} \\\\ K^{(i)}_{ib} & K^{(i)}_{ii} \\end{bmatrix}\n    $$\n\n3.  **Static Condensation:** The interior DoFs of each subdomain are eliminated via static condensation. This yields the local Schur complement matrix $S^{(i)}$, which acts as the effective stiffness matrix on the interface DoFs of subdomain $i$. It is derived as:\n    $$\n    S^{(i)} = K^{(i)}_{bb} - K^{(i)}_{bi} \\left(K^{(i)}_{ii}\\right)^{-1} K^{(i)}_{ib}\n    $$\n    Computationally, the term $(K^{(i)}_{ii})^{-1} K^{(i)}_{ib}$ is found by solving a linear system with the sparse matrix $K^{(i)}_{ii}$, not by explicit inversion.\n\n4.  **Dual Problem Formulation:** Continuity of the displacement field across subdomain interfaces is enforced using Lagrange multipliers, $\\lambda$. One multiplier is introduced for each DoF along each of the $s_x-1$ interfaces. The continuity condition is expressed as $\\sum_i C^{(i)} u_b^{(i)} = 0$, where $u_b^{(i)}$ is the vector of interface displacements for subdomain $i$, and $C^{(i)}$ is a signed boolean matrix that maps these local displacements to the global set of constraints. The problem statement gives the sign convention $u^{(i)}_{\\text{right}} - u^{(i+1)}_{\\text{left}} = 0$, which defines the entries of $C^{(i)}$ as $+1$ or $-1$.\n    Solving the local problems in terms of $\\lambda$ and substituting into the continuity equation leads to the dual system $F\\lambda = d$. The dual operator, or FETI matrix, $F$ is given by the sum of contributions from each subdomain:\n    $$\n    F = \\sum_{i=0}^{s_x-1} C^{(i)} \\left(S^{(i)}\\right)^{-1} \\left(C^{(i)}\\right)^{\\top}\n    $$\n    This operator maps the Lagrange multipliers to the residual of the continuity constraints (the interface 'jumps').\n\n5.  **Preconditioner Construction:** An effective preconditioner $M$ for $F$ is crucial for efficient iterative solution. The problem specifies a block-diagonal preconditioner of the form:\n    $$\n    M = \\sum_{i=0}^{s_x-1} C^{(i)} D^{(i)} \\left(C^{(i)}\\right)^{\\top}\n    $$\n    where $D^{(i)}$ is an approximation to $\\left(S^{(i)}\\right)^{-1}$.\n    - For the **exact** variant, we set $D^{(i)} = \\left(S^{(i)}\\right)^{-1}$. In this case, $M$ becomes identical to $F$, and the preconditioned operator $M^{-1}F$ is the identity matrix. Its condition number is theoretically $\\kappa_{\\text{exact}} = 1$.\n    - For the **approximate** variant, $D^{(i)}$ is constructed using a sparse incomplete LU factorization (ILU) of $S^{(i)}$ with a specified drop tolerance $\\tau$. The action of $D^{(i)}$ is computed by solving with the ILU factors. This yields a preconditioner $M_{\\text{approx}}$ which is cheaper to apply than $F^{-1}$ but less effective, leading to a condition number $\\kappa_{\\text{approx}} > 1$.\n\n6.  **Spectral Analysis:** For both the exact and approximate cases, the preconditioned operator $A = M^{-1}F$ is formed explicitly as a dense matrix. Its eigenvalues are computed numerically. The spectral condition number is then estimated as the ratio of the largest to the smallest positive real part of the eigenvalues, $\\kappa = \\frac{\\max(\\text{Re}(\\lambda_i))}{\\min(\\text{Re}(\\lambda_i))}$, providing a quantitative measure of the preconditioning quality. A value closer to $1$ indicates better preconditioning and faster convergence for Krylov subspace methods.", "answer": "```python\nimport numpy as np\nfrom scipy.sparse import lil_matrix, csc_matrix, csr_matrix\nfrom scipy.sparse.linalg import spsolve, spilu\n\ndef get_element_stiffness_matrix(hx, hy):\n    \"\"\"\n    Computes the 4x4 element stiffness matrix for a bilinear Q1 element\n    of size hx x hy using 2x2 Gauss quadrature.\n    Node ordering: (0,0), (1,0), (0,1), (1,1) in local coordinates.\n    \"\"\"\n    gp_val = 1.0 / np.sqrt(3)\n    gauss_points = [(-gp_val, -gp_val), (gp_val, -gp_val), (-gp_val, gp_val), (gp_val, gp_val)]\n    weights = [1.0, 1.0, 1.0, 1.0]\n    \n    Ke = np.zeros((4, 4))\n    \n    for w, (xi, eta) in zip(weights, gauss_points):\n        # Derivatives of shape functions w.r.t. reference coordinates (xi, eta)\n        dNdxi = 0.25 * np.array([-(1 - eta), (1 - eta), -(1 + eta), (1 + eta)])\n        dNdeta = 0.25 * np.array([-(1 - xi), -(1 + xi), (1 - xi), (1 + xi)])\n        \n        # Jacobian determinant for a rectangular element\n        detJ = hx * hy / 4.0\n        \n        # Derivatives w.r.t. physical coordinates (x,y)\n        dNdx = dNdxi * (2.0 / hx)\n        dNdy = dNdeta * (2.0 / hy)\n        \n        B = np.array([dNdx, dNdy])  # Shape (2, 4)\n        \n        # Add contribution to stiffness matrix\n        Ke += (B.T @ B) * w * detJ\n        \n    return Ke\n\ndef solve_case(Nx, Ny, sx, tau):\n    \"\"\"\n    Solves one test case for the given parameters.\n    \"\"\"\n    # 1. Grid and DoF numbering for interior nodes\n    n_dof = (Nx - 1) * (Ny - 1)\n    dof_map = np.full((Nx + 1, Ny + 1), -1, dtype=int)\n    dof_idx = 0\n    inv_dof_map = {}\n    for j in range(1, Ny):\n        for i in range(1, Nx):\n            dof_map[i, j] = dof_idx\n            inv_dof_map[dof_idx] = (i,j)\n            dof_idx += 1\n            \n    # 2. Element stiffness matrix\n    hx = 1.0 / Nx\n    hy = 1.0 / Ny\n    Ke = get_element_stiffness_matrix(hx, hy)\n    \n    # 3. Global stiffness matrix assembly\n    K = lil_matrix((n_dof, n_dof))\n    for ey in range(Ny):\n        for ex in range(Nx):\n            nodes = [(ex, ey), (ex + 1, ey), (ex, ey + 1), (ex + 1, ey + 1)]\n            element_dofs = [dof_map[i, j] for i, j in nodes]\n            \n            for i_local in range(4):\n                if element_dofs[i_local] == -1: continue\n                for j_local in range(4):\n                    if element_dofs[j_local] == -1: continue\n                    K[element_dofs[i_local], element_dofs[j_local]] += Ke[i_local, j_local]\n    \n    K = K.tocsc()\n    \n    # 4. Subdomain and Interface Definitions\n    nodes_per_sub_x = Nx // sx\n    subdomain_data = {}\n    \n    for i_sub in range(sx):\n        i_dofs, b_dofs = [], []\n        x_min_node = i_sub * nodes_per_sub_x\n        x_max_node = (i_sub + 1) * nodes_per_sub_x\n        \n        for j in range(1, Ny):\n            for i in range(x_min_node, x_max_node + 1):\n                if i in (0, Nx): continue\n                \n                dof = dof_map[i, j]\n                is_interface = (i > 0 and i % nodes_per_sub_x == 0 and i < Nx)\n\n                if is_interface:\n                    if dof not in b_dofs: b_dofs.append(dof)\n                elif dof not in i_dofs: i_dofs.append(dof)\n\n        subdomain_data[i_sub] = {'i_dofs': sorted(i_dofs), 'b_dofs': sorted(b_dofs)}\n\n    # 5. Schur Complements and C matrices\n    lambda_dofs = (sx - 1) * (Ny - 1)\n    lm_map = {} # (cut_idx, y_idx) -> lm_idx\n    lm_idx = 0\n    for k in range(1, sx):\n        for j in range(1, Ny):\n            lm_map[(k, j)] = lm_idx\n            lm_idx += 1\n            \n    local_S, local_C = {}, {}\n    \n    for i_sub in range(sx):\n        i_dofs = subdomain_data[i_sub]['i_dofs']\n        b_dofs = subdomain_data[i_sub]['b_dofs']\n        all_dofs = i_dofs + b_dofs\n        n_i, n_b = len(i_dofs), len(b_dofs)\n\n        if not all_dofs: continue\n\n        K_sub = K[all_dofs, :][:, all_dofs]\n        K_ii, K_ib = K_sub[:n_i, :n_i], K_sub[:n_i, n_i:]\n        K_bi, K_bb = K_sub[n_i:, :n_i], K_sub[n_i:, n_i:]\n        \n        if n_i > 0:\n            invKii_Kib = spsolve(K_ii, K_ib)\n            S_i = K_bb - K_bi @ invKii_Kib\n        else:\n            S_i = K_bb\n        \n        local_S[i_sub] = S_i.toarray() if hasattr(S_i, 'toarray') else S_i\n\n        C_i = lil_matrix((lambda_dofs, n_b))\n        for b_local_idx, b_dof in enumerate(b_dofs):\n            i_node, j_node = inv_dof_map[b_dof]\n            cut_idx = i_node // nodes_per_sub_x\n            l_idx = lm_map[(cut_idx, j_node)]\n            \n            if i_sub == cut_idx: C_i[l_idx, b_local_idx] = -1\n            elif i_sub == cut_idx - 1: C_i[l_idx, b_local_idx] = 1\n        \n        local_C[i_sub] = C_i.tocsc()\n        \n    # 6. Dual Operator F and Preconditioner M\n    F = np.zeros((lambda_dofs, lambda_dofs))\n    M_approx = np.zeros((lambda_dofs, lambda_dofs))\n    \n    for i_sub in range(sx):\n        if i_sub not in local_S or local_S[i_sub].shape[0] == 0: continue\n        \n        S_i = local_S[i_sub]\n        C_i = local_C[i_sub]\n        n_b = S_i.shape[0]\n\n        invS_i = np.linalg.inv(S_i)\n        F += C_i @ invS_i @ C_i.T\n        \n        S_i_sparse = csr_matrix(S_i)\n        try:\n            ilu = spilu(S_i_sparse, drop_tol=tau, fill_factor=10)\n            invS_approx_i = ilu.solve(np.eye(n_b))\n        except RuntimeError:\n            invS_approx_i = invS_i\n\n        M_approx += C_i @ invS_approx_i @ C_i.T\n    \n    M_exact = F.copy()\n    \n    # 7. Condition Number Calculation\n    def cond_est(A):\n        eigvals = np.linalg.eigvals(A)\n        real_eigvals = np.real(eigvals)\n        pos_eigs = real_eigvals[real_eigvals > 1e-10]\n        return np.max(pos_eigs) / np.min(pos_eigs) if len(pos_eigs) > 0 else 1.0\n\n    k_exact = cond_est(np.linalg.solve(M_exact, F)) if M_exact.shape[0] > 0 else 1.0\n    k_approx = cond_est(np.linalg.solve(M_approx, F)) if M_approx.shape[0] > 0 else 1.0\n    \n    return [k_exact, k_approx]\n\ndef solve():\n    test_cases = [\n        (12, 8, 3, 1e-4),\n        (8, 8, 2, 1e-2),\n        (20, 12, 4, 5e-2),\n    ]\n\n    results = []\n    for case in test_cases:\n        Nx, Ny, sx, tau = case\n        result = solve_case(Nx, Ny, sx, tau)\n        results.append(result)\n        \n    # Final print statement in the exact required format.\n    # The string representation of a list of lists is standard and machine-readable.\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "3565959"}, {"introduction": "A key challenge in dual-primal methods like FETI is managing the null space of the floating subdomains, which renders the dual operator singular. This is resolved by introducing a coarse problem and a corresponding projector that enforces solvability. This exercise focuses on the mathematical heart of this mechanism, asking you to derive the explicit form of the $F$-orthogonal projector and analyze its properties, providing a fundamental understanding of how coarse-scale constraints are imposed in the dual space [@problem_id:3565928].", "problem": "Consider a nonoverlapping finite element domain decomposition of a linear elastic body, where interface compatibility is enforced in the dual space by Lagrange multipliers. In the dual formulation of Finite Element Tearing and Interconnecting (FETI) and Balancing Domain Decomposition (BDD), the interface operator is the dual Schur complement $F \\in \\mathbb{R}^{n \\times n}$, which is symmetric positive semidefinite, and positive definite on the subspace orthogonal (in the sense of the $F$-inner product) to the coarse space. Let $Z \\in \\mathbb{R}^{n \\times m}$ be a full column rank basis for the coarse space of interface modes (e.g., rigid body modes), such that $Z^{T} F Z \\in \\mathbb{R}^{m \\times m}$ is invertible. The goal is to construct a linear projector $P \\in \\mathbb{R}^{n \\times n}$ acting on the dual variables that eliminates coarse components and enforces orthogonality to the coarse modes in the $F$-inner product.\n\nStarting from the first principles of energy orthogonality and the defining properties of oblique projections in an inner-product space determined by $F$, derive an explicit algebraic expression for the projector $P$ onto the $F$-orthogonal complement of $\\mathrm{Range}(Z)$. Prove that this $P$ enforces coarse mode orthogonality in the sense that for every dual vector $\\lambda \\in \\mathbb{R}^{n}$, the coarse component is annihilated and the projected vector is $F$-orthogonal to the coarse space. Then, assess numerical stability under roundoff by analyzing the sensitivity of the $F$-orthogonality condition to finite-precision computation of the inverse of $Z^{T} F Z$.\n\nFor a concrete test, use\n$$\nF \\;=\\; \\begin{pmatrix}\n4 & 1 & 0 \\\\\n1 & 3 & 1 \\\\\n0 & 1 & 2\n\\end{pmatrix},\n\\qquad\nZ \\;=\\; \\begin{pmatrix}\n1 \\\\ -1 \\\\ 2\n\\end{pmatrix}.\n$$\nCompute the exact projector $P$ and verify its annihilation and orthogonality properties with respect to the coarse space defined by $Z$. Next, define an approximate projector $P_{r}$ by replacing $(Z^{T} F Z)^{-1}$ with its rounded value $a_{r}$ obtained from the exact scalar $(Z^{T} F Z)^{-1}$ rounded to three significant figures in standard scientific notation, and set\n$$\nP_{r} \\;=\\; I \\;-\\; Z \\, a_{r} \\, Z^{T} F.\n$$\nQuantify the violation of coarse orthogonality introduced by this rounding by evaluating the scalar\n$$\n\\epsilon \\;=\\; \\left\\| Z^{T} F P_{r} \\right\\|_{2}.\n$$\nReport the value of $\\epsilon$ as your final answer. Round your final numerical answer to four significant figures. No physical units are required.", "solution": "The problem asks for the derivation of a projector $P$ that enforces orthogonality to a coarse space in a specific inner product, followed by an analysis of its numerical stability and a concrete numerical calculation.\n\nThe problem is first validated.\n**Step 1: Extract Givens**\n- Interface operator: $F \\in \\mathbb{R}^{n \\times n}$, symmetric positive semidefinite, and positive definite on the subspace $F$-orthogonal to the coarse space.\n- Coarse space basis: $Z \\in \\mathbb{R}^{n \\times m}$ with full column rank.\n- Coarse problem matrix: $Z^{T} F Z$ is invertible.\n- Projector: $P \\in \\mathbb{R}^{n \\times n}$ projects onto the $F$-orthogonal complement of $\\mathrm{Range}(Z)$.\n- Concrete test case:\n  $$\n  F \\;=\\; \\begin{pmatrix}\n  4 & 1 & 0 \\\\\n  1 & 3 & 1 \\\\\n  0 & 1 & 2\n  \\end{pmatrix},\n  \\qquad\n  Z \\;=\\; \\begin{pmatrix}\n  1 \\\\ -1 \\\\ 2\n  \\end{pmatrix}.\n  $$\n- Approximate projector: $P_{r} = I - Z a_{r} Z^{T} F$, where $a_{r}$ is $(Z^{T} F Z)^{-1}$ rounded to three significant figures.\n- Error metric: $\\epsilon = \\| Z^{T} F P_{r} \\|_{2}$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, situated within the well-established field of numerical methods for partial differential equations (domain decomposition). It is well-posed, with all necessary information provided for both the theoretical derivation and the numerical computation. The given matrix $F$ is symmetric. Its eigenvalues can be shown to be positive, so it is positive definite, which is consistent with the given properties. The matrix $Z$ has full column rank. The product $Z^T F Z$ for the given data is the scalar $9$, which is invertible. The problem is objective, complete, consistent, and mathematically verifiable.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\n**Part 1: Derivation of the Projector $P$**\nLet $\\mathbb{R}^n$ be the space of dual variables. The problem defines an inner product (or semi-inner product, since $F$ is positive semidefinite) on this space as $\\langle u, v \\rangle_F = u^T F v$ for any $u, v \\in \\mathbb{R}^n$. The coarse space is the subspace $\\mathcal{Z} = \\mathrm{Range}(Z) = \\{ Z\\alpha \\mid \\alpha \\in \\mathbb{R}^m \\}$.\n\nWe seek a projector $P$ onto the $F$-orthogonal complement of $\\mathcal{Z}$, which we denote $\\mathcal{Z}^{\\perp_F}$. Any vector $\\lambda \\in \\mathbb{R}^n$ can be decomposed into a component in $\\mathcal{Z}$ and a component in $\\mathcal{Z}^{\\perp_F}$:\n$$ \\lambda = \\lambda_{\\mathcal{Z}} + \\lambda_{\\perp_F} $$\nwhere $\\lambda_{\\mathcal{Z}} \\in \\mathcal{Z}$ and $\\lambda_{\\perp_F} \\in \\mathcal{Z}^{\\perp_F}$. The projector $P$ acts on $\\lambda$ to yield the component in the $F$-orthogonal complement: $P\\lambda = \\lambda_{\\perp_F}$.\n\nSince $\\lambda_{\\mathcal{Z}} \\in \\mathcal{Z}$, it can be written as $\\lambda_{\\mathcal{Z}} = Z\\alpha$ for some coefficient vector $\\alpha \\in \\mathbb{R}^m$. The projected vector is then $\\lambda_{\\perp_F} = \\lambda - \\lambda_{\\mathcal{Z}} = \\lambda - Z\\alpha$.\n\nThe defining property of $\\lambda_{\\perp_F}$ is its $F$-orthogonality to every vector in the coarse space $\\mathcal{Z}$. This is satisfied if $\\lambda_{\\perp_F}$ is $F$-orthogonal to all basis vectors of $\\mathcal{Z}$, i.e., the columns of $Z$. This condition is expressed as:\n$$ \\langle Z\\beta, \\lambda - Z\\alpha \\rangle_F = 0, \\quad \\forall \\beta \\in \\mathbb{R}^m $$\nWriting this out using the definition of the inner product:\n$$ (Z\\beta)^T F (\\lambda - Z\\alpha) = 0 $$\n$$ \\beta^T Z^T F (\\lambda - Z\\alpha) = 0 $$\nSince this must hold for all $\\beta \\in \\mathbb{R}^m$, the vector term must be zero:\n$$ Z^T F (\\lambda - Z\\alpha) = 0 $$\n$$ Z^T F \\lambda - Z^T F Z \\alpha = 0 $$\n$$ Z^T F Z \\alpha = Z^T F \\lambda $$\nThe problem states that the matrix $Z^T F Z$ is invertible. We can therefore solve for $\\alpha$:\n$$ \\alpha = (Z^T F Z)^{-1} Z^T F \\lambda $$\nSubstituting this expression for $\\alpha$ back into the formula for $\\lambda_{\\mathcal{Z}}$ gives the projection of $\\lambda$ onto the coarse space:\n$$ \\lambda_{\\mathcal{Z}} = Z\\alpha = Z (Z^T F Z)^{-1} Z^T F \\lambda $$\nThe projector onto the coarse space, let's call it $P_{\\mathcal{Z}}$, is thus $P_{\\mathcal{Z}} = Z (Z^T F Z)^{-1} Z^T F$. This is an oblique projector.\n\nThe desired projector $P$ projects onto the complement, so it is given by $P = I - P_{\\mathcal{Z}}$.\n$$ P = I - Z (Z^T F Z)^{-1} Z^T F $$\n\n**Part 2: Proof of Properties**\nWe must prove that for any $\\lambda \\in \\mathbb{R}^{n}$:\n1. The coarse component is annihilated. Any vector in the coarse space, $v = Z\\gamma$, is projected to zero.\n   $$\n   P v = P (Z\\gamma) = \\left(I - Z (Z^T F Z)^{-1} Z^T F\\right) (Z\\gamma) = Z\\gamma - Z (Z^T F Z)^{-1} (Z^T F Z) \\gamma = Z\\gamma - Z I_m \\gamma = Z\\gamma - Z\\gamma = 0\n   $$\n   The property is proven.\n\n2. The projected vector $P\\lambda$ is $F$-orthogonal to the coarse space $\\mathcal{Z}$. We check if $\\langle Z\\gamma, P\\lambda \\rangle_F = 0$ for any $\\gamma \\in \\mathbb{R}^m$. This is equivalent to checking if $Z^T F (P\\lambda) = 0$.\n   $$\n   Z^T F (P\\lambda) = Z^T F \\left(I - Z (Z^T F Z)^{-1} Z^T F\\right) \\lambda = \\left(Z^T F - (Z^T F Z) (Z^T F Z)^{-1} Z^T F\\right) \\lambda = (Z^T F - I_m Z^T F) \\lambda = (Z^T F - Z^T F) \\lambda = 0\n   $$\n   The property is proven.\n\n**Part 3: Assessment of Numerical Stability**\nThe $F$-orthogonality of the projected result depends on the exact cancellation $Z^T F - (Z^T F Z) (Z^T F Z)^{-1} Z^T F = 0$. In finite-precision arithmetic, we compute an approximate inverse, say $\\tilde{G} \\approx G = (Z^T F Z)^{-1}$. The approximate projector is $\\tilde{P} = I - Z \\tilde{G} Z^T F$. The residual of the orthogonality condition is:\n$$ Z^T F \\tilde{P} = Z^T F - (Z^T F Z) \\tilde{G} Z^T F = (Z^T F Z)G Z^T F - (Z^T F Z) \\tilde{G} Z^T F = (Z^T F Z) (G - \\tilde{G}) Z^T F = - (Z^T F Z) (\\delta G) Z^T F $$\nwhere $\\delta G = \\tilde{G} - G$ is the error in the inverse. This shows that the loss of orthogonality is proportional to the error in the inverse of the coarse matrix $Z^T F Z$, pre-multiplied by $Z^T F Z$ itself. The magnitude of this violation will be sensitive to the condition number of the coarse matrix, $\\kappa(Z^T F Z)$. A large condition number can amplify small rounding errors in the inverse computation, leading to a significant loss of $F$-orthogonality.\n\n**Part 4: Concrete Numerical Calculation**\nWe are given the matrices:\n$$\nF \\;=\\; \\begin{pmatrix}\n4 & 1 & 0 \\\\\n1 & 3 & 1 \\\\\n0 & 1 & 2\n\\end{pmatrix},\n\\qquad\nZ \\;=\\; \\begin{pmatrix}\n1 \\\\ -1 \\\\ 2\n\\end{pmatrix}.\n$$\nFirst, we compute the components for the projector.\n$$\nF Z = \\begin{pmatrix} 4 & 1 & 0 \\\\ 1 & 3 & 1 \\\\ 0 & 1 & 2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 4(1) + 1(-1) + 0(2) \\\\ 1(1) + 3(-1) + 1(2) \\\\ 0(1) + 1(-1) + 2(2) \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 0 \\\\ 3 \\end{pmatrix}\n$$\n$$\nZ^T F = (FZ)^T = \\begin{pmatrix} 3 & 0 & 3 \\end{pmatrix}\n$$\nNext, we compute the scalar coarse problem matrix $Z^T F Z$:\n$$\nZ^T F Z = \\begin{pmatrix} 3 & 0 & 3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\\\ 2 \\end{pmatrix} = 3(1) + 0(-1) + 3(2) = 9\n$$\nThe exact inverse is $(Z^T F Z)^{-1} = \\frac{1}{9}$.\nThe exact projector is $P = I - \\frac{1}{9} Z Z^T F$.\n\nThe problem requires using a rounded value for the inverse. The exact value is $a = \\frac{1}{9} = 0.1111... = 1.111... \\times 10^{-1}$.\nRounding this to three significant figures gives the approximate value $a_r$:\n$$\na_r = 1.11 \\times 10^{-1} = 0.111\n$$\nThe approximate projector is $P_r = I - Z a_r Z^T F$.\n\nWe need to quantify the violation of orthogonality by evaluating $\\epsilon = \\| Z^T F P_r \\|_{2}$.\nLet's first compute the row vector $Z^T F P_r$:\n$$\nZ^T F P_r = Z^T F (I - Z a_r Z^T F) = Z^T F - (Z^T F Z) a_r Z^T F\n$$\nSubstituting the known values:\n$$\nZ^T F P_r = Z^T F - (9) a_r Z^T F = (1 - 9 a_r) Z^T F\n$$\nThe scalar pre-factor is:\n$$\n1 - 9 a_r = 1 - 9(0.111) = 1 - 0.999 = 0.001\n$$\nSo, the row vector is:\n$$\nZ^T F P_r = 0.001 \\times \\begin{pmatrix} 3 & 0 & 3 \\end{pmatrix} = \\begin{pmatrix} 0.003 & 0 & 0.003 \\end{pmatrix}\n$$\nFinally, we compute its Euclidean ($L_2$) norm:\n$$\n\\epsilon = \\| \\begin{pmatrix} 0.003 & 0 & 0.003 \\end{pmatrix} \\|_2 = \\sqrt{0.003^2 + 0^2 + 0.003^2}\n$$\n$$\n\\epsilon = \\sqrt{2 \\times (0.003)^2} = \\sqrt{2} \\times 0.003\n$$\nUsing the value $\\sqrt{2} \\approx 1.41421356...$:\n$$\n\\epsilon \\approx 1.41421356 \\times 0.003 = 0.0042426408...\n$$\nRounding the final answer to four significant figures gives:\n$$\n\\epsilon \\approx 0.004243\n$$", "answer": "$$\\boxed{0.004243}$$", "id": "3565928"}, {"introduction": "The performance of BDDC and FETI methods hinges on the quality of the coarse space, especially for problems with challenging features like strong material heterogeneity. This practice introduces the powerful concept of adaptive coarse space enrichment, where local eigenproblems are used to diagnose and constrain problematic interface modes. By implementing a predictive model based on material contrast, you will learn how to design a more robust solver that automatically adapts to the physics of the problem, ensuring scalability and efficiency [@problem_id:3565891].", "problem": "You are to implement and analyze an adaptive Balanced Domain Decomposition by Constraints (BDDC) coarse space based on local generalized eigenproblems on edges and faces, with a prescribed threshold $ \\tau $, for a three-dimensional ($3$D) channel exhibiting layered stiffness. The goal is to predict the minimal number of added primal constraints needed so that the preconditioned operator’s condition number $ \\kappa $ is guaranteed to satisfy $ \\kappa \\le \\tau $. The final program must compute this number for a given set of test cases that specify the subdomain stiffness distribution and the baseline spectral content on each interface component.\n\nStart from the variational formulation of linear elasticity and the classical substructuring framework: the global finite element equilibrium reads $ \\mathbf{K} \\mathbf{u} = \\mathbf{f} $, where $ \\mathbf{K} $ is the symmetric positive definite stiffness matrix assembled from subdomains. After eliminating interior subdomain degrees of freedom, the interface Schur complement system is posed in terms of the interface trace $ \\mathbf{u}_{\\Gamma} $. In a BDDC preconditioner, one introduces a coarse (primal) space by enforcing continuity constraints across selected interface functionals. In adaptive BDDC, additional constraints are chosen by solving, on each interface component $ c $ (edge or face), a local generalized eigenproblem that compares “jump” and “continuous” energies, typically expressible in the Schur complement energy inner product. Specifically, for each component $ c $, one solves a generalized eigenproblem of the form\n$$\n\\mathbf{S}_c^{\\Delta} \\boldsymbol{\\psi} = \\lambda \\, \\mathbf{S}_c^{\\Pi} \\boldsymbol{\\psi},\n$$\nwhere $ \\mathbf{S}_c^{\\Delta} $ measures the energetic penalty of discontinuous modes and $ \\mathbf{S}_c^{\\Pi} $ measures the energetic contribution of the corresponding continuous counterpart. Modes with eigenvalues $ \\lambda $ larger than a threshold $ \\tau $ are targeted for addition as primal constraints, yielding a guarantee that the global preconditioned operator has a condition number bounded by a constant times $ \\tau $; in the simplified model specified below, this constant is treated as $ 1 $. Therefore, a selection rule “add constraints for all local modes with $ \\lambda > \\tau $” ensures $ \\kappa \\le \\tau $.\n\nTo make the computation concrete and self-contained while retaining scientific realism, adopt the following simplified but widely used spectral scaling model: for a three-dimensional layered channel where each subdomain $ i $ has a homogeneous Young’s modulus $ E_i $ (in Pascals), the local generalized eigenvalues on an interface component $ c $ between adjacent subdomains $ i $ and $ j $ can be approximated as\n$$\n\\lambda_{c,k} \\approx \\rho_c \\, \\mu_{c,k}, \\quad \\text{with} \\quad \\rho_c = \\frac{\\max(E_i,E_j)}{\\min(E_i,E_j)},\n$$\nwhere $ \\{ \\mu_{c,k} \\}_k $ are the baseline eigenvalues for a unit-contrast homogeneous medium on the same geometric interface (that is, $ E_i = E_j $), and $ \\rho_c $ is the stiffness contrast ratio associated with $ c $. This model captures the amplification of problematic interface modes by material contrast in layered configurations and is consistent with established adaptive BDDC/FETI theory in which the local Rayleigh quotients scale with coefficient jumps. You are to assume that each provided $ \\mu_{c,k} $ already excludes the always-present corner constraints; thus, “added constraints” refers solely to the adaptive constraints beyond the standard corner set.\n\nTask. For each test case below:\n- Compute, for every interface component $ c $ with adjacent subdomains $ (i,j) $, the contrast ratio $ \\rho_c $ using the provided subdomain Young’s moduli $ \\{ E_i \\} $.\n- Form the approximate local eigenvalues $ \\lambda_{c,k} = \\rho_c \\, \\mu_{c,k} $ using the given baseline spectra $ \\{ \\mu_{c,k} \\}_k $.\n- Determine the minimal number of added constraints as the total count of all $ \\lambda_{c,k} $ that strictly exceed the threshold $ \\tau $. Eigenvalues equal to $ \\tau $ do not require adding a constraint.\n- Return, for each test case, a single integer: the total number of added constraints across all interface components.\n\nPhysical units. Young’s modulus values $ E_i $ are given in Pascals. No quantity with physical units is requested in the output; only integer counts of constraints are to be returned.\n\nAngle units. No angles are involved.\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list of integers enclosed in square brackets, for the test cases in the order presented below. For example, if there are three test cases and the computed counts are $ a $, $ b $, and $ c $, respectively, the output must be exactly $ [a,b,c] $.\n\nTest suite. Implement your program to solve the following five test cases:\n\n- Test Case $ 1 $ (homogeneous channel, no contrast):\n  - Subdomains and moduli (Pascals): $ E = [10^9, 10^9, 10^9] $.\n  - Interface components $ c $ (adjacent pairs) and baseline spectra:\n    - Pair $ (0,1) $: $ \\{ \\mu_{c,k} \\} = \\{ 0.5, 0.2 \\} $.\n    - Pair $ (1,2) $: $ \\{ \\mu_{c,k} \\} = \\{ 0.4, 0.1 \\} $.\n  - Threshold: $ \\tau = 0.6 $.\n\n- Test Case $ 2 $ (three-layer channel with high middle-layer stiffness):\n  - Subdomains and moduli (Pascals): $ E = [10^9, 10^{12}, 10^9] $.\n  - Interface components and baseline spectra as in Test Case $ 1 $.\n  - Threshold: $ \\tau = 300 $.\n\n- Test Case $ 3 $ (same as Test Case $ 2 $, edge threshold):\n  - Subdomains and moduli (Pascals): $ E = [10^9, 10^{12}, 10^9] $.\n  - Interface components and baseline spectra as in Test Case $ 1 $.\n  - Threshold: $ \\tau = 400 $.\n\n- Test Case $ 4 $ (two-by-one-by-two arrangement with top/bottom layers of contrasting stiffness):\n  - Subdomains and moduli (Pascals): $ E = [10^6, 10^6, 10^9, 10^9] $.\n  - Interface components and baseline spectra:\n    - Pair $ (0,2) $: $ \\{ \\mu_{c,k} \\} = \\{ 0.3, 0.25, 0.1 \\} $.\n    - Pair $ (1,3) $: $ \\{ \\mu_{c,k} \\} = \\{ 0.3, 0.25, 0.1 \\} $.\n    - Pair $ (0,1) $: $ \\{ \\mu_{c,k} \\} = \\{ 0.6, 0.55, 0.4 \\} $.\n    - Pair $ (2,3) $: $ \\{ \\mu_{c,k} \\} = \\{ 0.6, 0.55, 0.4 \\} $.\n  - Threshold: $ \\tau = 0.5 $.\n\n- Test Case $ 5 $ (same as Test Case $ 4 $, very permissive threshold):\n  - Subdomains and moduli (Pascals): $ E = [10^6, 10^6, 10^9, 10^9] $.\n  - Interface components and baseline spectra as in Test Case $ 4 $.\n  - Threshold: $ \\tau = 10^4 $.\n\nYour program must hard-code the above test suite, apply the described model and selection rule, and print the final results as a single line in the specified format.", "solution": "We begin with linear elasticity in the small-strain regime with homogeneous, isotropic material properties per subdomain. The finite element semi-discrete system can be written as $ \\mathbf{K} \\mathbf{u} = \\mathbf{f} $, where $ \\mathbf{K} $ is symmetric positive definite. In a substructured formulation, each subdomain’s interior degrees of freedom are statically condensed, producing the Schur complement system on the global interface trace $ \\mathbf{u}_{\\Gamma} $,\n$$\n\\mathbf{S} \\, \\mathbf{u}_{\\Gamma} = \\mathbf{g},\n$$\nwith $ \\mathbf{S} $ symmetric positive definite in the energy inner product induced by $ \\mathbf{K} $. Balanced Domain Decomposition by Constraints (BDDC) constructs a preconditioner by enforcing primal continuity on a subset of interface functionals (e.g., corners, averages on edges/faces), and splitting the remainder into dual parts solved locally. The efficiency of the preconditioner is measured by the condition number $ \\kappa $ of the preconditioned operator. \n\nAdaptive BDDC enriches the primal space by identifying “bad” interface modes through local generalized eigenproblems that compare discontinuous and continuous energy measures. On each interface component $ c $ (edge or face), one defines operators $ \\mathbf{S}_c^{\\Delta} $ and $ \\mathbf{S}_c^{\\Pi} $ representing, respectively, the energy of the jump mode and the energy of its corresponding continuous mode, and solves\n$$\n\\mathbf{S}_c^{\\Delta} \\boldsymbol{\\psi} = \\lambda \\, \\mathbf{S}_c^{\\Pi} \\boldsymbol{\\psi}.\n$$\nThe local Rayleigh quotient associated with a mode $ \\boldsymbol{\\psi} $ is $ \\lambda = \\dfrac{\\langle \\boldsymbol{\\psi}, \\mathbf{S}_c^{\\Delta} \\boldsymbol{\\psi} \\rangle}{\\langle \\boldsymbol{\\psi}, \\mathbf{S}_c^{\\Pi} \\boldsymbol{\\psi} \\rangle} $. Established theory for adaptive BDDC and Finite Element Tearing and Interconnecting (FETI) methods shows that, when one augments the primal space with constraints associated to all eigenvectors whose eigenvalues exceed a threshold $ \\tau $, the condition number of the preconditioned global operator satisfies a bound of the form $ \\kappa \\le C \\, \\tau $, where $ C $ is a benign constant depending weakly on shape regularity and scaling choices. In our model and for the purposes of this prediction task, we set $ C = 1 $, so selecting all local modes with $ \\lambda > \\tau $ guarantees $ \\kappa \\le \\tau $.\n\nTo relate the local spectra to material heterogeneity in a layered three-dimensional channel, consider a pair of adjacent subdomains $ (i,j) $ with homogeneous Young’s moduli $ E_i $ and $ E_j $, respectively. For a homogeneous medium ($ E_i = E_j $), the interface generalized eigenvalues for a fixed geometric interface are denoted by $ \\{ \\mu_{c,k} \\}_k $. When a jump in stiffness is present, the local energy of jump modes is amplified in proportion to the contrast ratio. A widely used and well-tested approximation is\n$$\n\\lambda_{c,k} \\approx \\rho_c \\, \\mu_{c,k}, \\quad \\text{with} \\quad \\rho_c = \\frac{\\max(E_i,E_j)}{\\min(E_i,E_j)}.\n$$\nThis follows from the scaling behavior of the Schur complement entries with respect to piecewise constant coefficients and from the observation that the Rayleigh quotient scales linearly with the dominant coefficient in the jump energy while the denominator scales with a representative continuous energy, yielding a factor of the ratio of coefficients across the interface. This model preserves ordering of modes because multiplication by a positive scalar $ \\rho_c $ does not alter relative magnitudes among the $ \\mu_{c,k} $.\n\nAdaptive selection rule. With the above approximation, the minimal number of added constraints on interface $ c $ required to achieve $ \\lambda_{c,k} \\le \\tau $ for all remaining unconstrained modes equals the count of $ k $ for which $ \\lambda_{c,k} > \\tau $, i.e., the cardinality of $ \\{ k : \\rho_c \\, \\mu_{c,k} > \\tau \\} $. Summing over all interface components $ c $ gives the total number of added constraints. Modes with $ \\lambda_{c,k} = \\tau $ are not added because they already satisfy the inequality $ \\lambda \\le \\tau $. The minimality follows because the maximum remaining eigenvalue decreases monotonically as the largest $ \\lambda $ modes are removed, and, under the multiplicative scaling, removing precisely those with $ \\rho_c \\mu_{c,k} > \\tau $ is both necessary and sufficient to enforce that all remaining $ \\lambda \\le \\tau $.\n\nAlgorithm. For each test case:\n1. For each interface component $ c $ connecting subdomains $ (i,j) $, compute $ \\rho_c = \\dfrac{\\max(E_i,E_j)}{\\min(E_i,E_j)} $.\n2. For each baseline eigenvalue $ \\mu_{c,k} $ on $ c $, compute $ \\lambda_{c,k} = \\rho_c \\, \\mu_{c,k} $.\n3. Count those with $ \\lambda_{c,k} > \\tau $. Sum over all $ c $ to obtain the total number of added constraints.\n4. Return this total as the test case’s result.\n\nNow we apply this to each provided test case.\n\n- Test Case $ 1 $:\n  - $ E = [10^9, 10^9, 10^9] $. For both pairs $ (0,1) $ and $ (1,2) $, $ \\rho_c = 1 $.\n  - Pair $ (0,1) $: $ \\lambda = \\{ 1 \\cdot 0.5, 1 \\cdot 0.2 \\} = \\{ 0.5, 0.2 \\} $. With $ \\tau = 0.6 $, none exceed $ \\tau $. Count $ 0 $.\n  - Pair $ (1,2) $: $ \\lambda = \\{ 0.4, 0.1 \\} $, none exceed $ \\tau $. Count $ 0 $.\n  - Total added constraints: $ 0 $.\n\n- Test Case $ 2 $:\n  - $ E = [10^9, 10^{12}, 10^9] $. For both pairs $ (0,1) $ and $ (1,2) $, $ \\rho_c = \\dfrac{10^{12}}{10^9} = 10^3 $.\n  - Pair $ (0,1) $: $ \\lambda = \\{ 10^3 \\cdot 0.5, 10^3 \\cdot 0.2 \\} = \\{ 500, 200 \\} $. With $ \\tau = 300 $, only $ 500 > 300 $. Count $ 1 $.\n  - Pair $ (1,2) $: $ \\lambda = \\{ 10^3 \\cdot 0.4, 10^3 \\cdot 0.1 \\} = \\{ 400, 100 \\} $. Only $ 400 > 300 $. Count $ 1 $.\n  - Total added constraints: $ 2 $.\n\n- Test Case $ 3 $:\n  - Same $ E $ and $ \\rho_c = 10^3 $ as Test Case $ 2 $.\n  - Pair $ (0,1) $: $ \\lambda = \\{ 500, 200 \\} $. With $ \\tau = 400 $, only $ 500 > 400 $. Count $ 1 $.\n  - Pair $ (1,2) $: $ \\lambda = \\{ 400, 100 \\} $. Here $ 400 = \\tau $ does not count, $ 100 < \\tau $. Count $ 0 $.\n  - Total added constraints: $ 1 $.\n\n- Test Case $ 4 $:\n  - $ E = [10^6, 10^6, 10^9, 10^9] $.\n  - Pair $ (0,2) $: $ \\rho = \\dfrac{10^9}{10^6} = 10^3 $. $ \\lambda = \\{ 300, 250, 100 \\} $. With $ \\tau = 0.5 $, all three exceed. Count $ 3 $.\n  - Pair $ (1,3) $: same as above. Count $ 3 $.\n  - Pair $ (0,1) $: $ \\rho = 1 $, $ \\lambda = \\{ 0.6, 0.55, 0.4 \\} $. Exceeding $ 0.5 $ are $ 0.6 $ and $ 0.55 $. Count $ 2 $.\n  - Pair $ (2,3) $: same as previous. Count $ 2 $.\n  - Total added constraints: $ 3 + 3 + 2 + 2 = 10 $.\n\n- Test Case $ 5 $:\n  - Same $ E $ and interfaces as Test Case $ 4 $.\n  - Threshold $ \\tau = 10^4 $. All $ \\lambda $ values from Test Case $ 4 $ are at most $ 300 $, so none exceed $ 10^4 $. Total added constraints: $ 0 $.\n\nTherefore, the expected outputs, in order, are the integer list $ [0, 2, 1, 10, 0] $. The program should compute these using the described algorithm and print them as a single line exactly in the format $ [0,2,1,10,0] $.\n\nThis principle-based design ties the computational procedure directly to the energy-based generalized eigenproblems governing adaptive BDDC, uses a contrast-driven scaling consistent with coefficient-jump sensitivity, and yields a quantifiable and verifiable integer output per test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef count_added_constraints(E, interfaces, tau):\n    \"\"\"\n    Count the minimal number of added adaptive BDDC constraints to ensure kappa <= tau,\n    under the spectral scaling model lambda = rho * mu for each interface component.\n    \n    Parameters:\n        E : list of floats\n            Young's modulus per subdomain (Pa).\n        interfaces : list of dicts\n            Each dict has:\n                'pair': (i, j) subdomain indices adjacent at the interface component.\n                'mu': list of baseline eigenvalues for the component in a homogeneous medium.\n        tau : float\n            Eigenvalue threshold.\n    Returns:\n        int : total number of added constraints across all interface components.\n    \"\"\"\n    total = 0\n    for comp in interfaces:\n        i, j = comp['pair']\n        Ei, Ej = E[i], E[j]\n        # Contrast ratio\n        rho = max(Ei, Ej) / min(Ei, Ej)\n        # Count modes that exceed tau after scaling\n        for mu in comp['mu']:\n            lam = rho * mu\n            if lam > tau:\n                total += 1\n    return total\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1\n        {\n            'E': [1e9, 1e9, 1e9],\n            'interfaces': [\n                {'pair': (0, 1), 'mu': [0.5, 0.2]},\n                {'pair': (1, 2), 'mu': [0.4, 0.1]},\n            ],\n            'tau': 0.6\n        },\n        # Test Case 2\n        {\n            'E': [1e9, 1e12, 1e9],\n            'interfaces': [\n                {'pair': (0, 1), 'mu': [0.5, 0.2]},\n                {'pair': (1, 2), 'mu': [0.4, 0.1]},\n            ],\n            'tau': 300.0\n        },\n        # Test Case 3\n        {\n            'E': [1e9, 1e12, 1e9],\n            'interfaces': [\n                {'pair': (0, 1), 'mu': [0.5, 0.2]},\n                {'pair': (1, 2), 'mu': [0.4, 0.1]},\n            ],\n            'tau': 400.0\n        },\n        # Test Case 4\n        {\n            'E': [1e6, 1e6, 1e9, 1e9],\n            'interfaces': [\n                {'pair': (0, 2), 'mu': [0.3, 0.25, 0.1]},\n                {'pair': (1, 3), 'mu': [0.3, 0.25, 0.1]},\n                {'pair': (0, 1), 'mu': [0.6, 0.55, 0.4]},\n                {'pair': (2, 3), 'mu': [0.6, 0.55, 0.4]},\n            ],\n            'tau': 0.5\n        },\n        # Test Case 5\n        {\n            'E': [1e6, 1e6, 1e9, 1e9],\n            'interfaces': [\n                {'pair': (0, 2), 'mu': [0.3, 0.25, 0.1]},\n                {'pair': (1, 3), 'mu': [0.3, 0.25, 0.1]},\n                {'pair': (0, 1), 'mu': [0.6, 0.55, 0.4]},\n                {'pair': (2, 3), 'mu': [0.6, 0.55, 0.4]},\n            ],\n            'tau': 1e4\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        E = case['E']\n        interfaces = case['interfaces']\n        tau = case['tau']\n        result = count_added_constraints(E, interfaces, tau)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3565891"}]}