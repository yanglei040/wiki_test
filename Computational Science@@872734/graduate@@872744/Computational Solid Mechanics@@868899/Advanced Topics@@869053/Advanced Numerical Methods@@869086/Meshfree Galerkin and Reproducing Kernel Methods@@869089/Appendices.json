{"hands_on_practices": [{"introduction": "This first exercise takes you back to the fundamentals of the Moving Least Squares (MLS) approximation. By deriving the shape functions and their gradients from first principles in a simple one-dimensional setting, you will gain a concrete understanding of the core machinery, including the moment matrix and the role of the weight function. This practice [@problem_id:3581248] illuminates why MLS shape functions are inherently smooth and why, unlike standard finite element shape functions, they do not possess the Kronecker delta property.", "problem": "Consider a one-dimensional meshfree Galerkin approximation constructed via the Moving Least Squares (MLS) method, which is a standard realization of the Reproducing Kernel Particle Method (RKPM). Let the trial space be generated from the quadratic polynomial basis $p(x) = [1, x, x^2]^T$. Assume a nodal set located at positions $x_{i} \\in \\{-2,\\,-1,\\,0,\\,1,\\,2\\}$ on the real line, with nodal parameters (pseudo-values) $u_{i}$. The MLS approximation at a point $x$ takes the form $u^{h}(x) = p(x)^T a(x)$, where $a(x)$ is determined by minimizing the weighted least-squares functional built from a Gaussian weight function. Specifically, use the Gaussian weights\n$$\nw_{i}(x) \\;=\\; \\exp\\!\\Big(-\\,\\frac{(x - x_{i})^{2}}{2}\\Big),\n$$\nwhich are $C^{\\infty}$ functions of $x$. Starting from the least-squares minimization and its normal equations, derive the MLS shape functions $N_{i}(x)$ such that $u^{h}(x) = \\sum_{i} N_{i}(x)\\,u_{i}$, and their spatial gradients in one dimension, $\\partial_{x} N_{i}(x)$. Then, using only the given nodal set, basis, and weights:\n\n1) Compute the exact closed-form expressions of the MLS shape functions $N_{i}(x)$ in a neighborhood of $x=0$ by explicitly forming the moment matrix $\\mathbf{A}(x)$, inverting it, and evaluating $N_{i}(x) = p(x)^T \\mathbf{A}^{-1}(x)\\,w_{i}(x)\\,p(x_{i})$ at $x=0$.\n\n2) Compute the exact expressions of the gradients $\\partial_{x} N_{i}(x)$ at $x=0$ by differentiating the MLS shape functions with respect to $x$, carefully accounting for the $x$-dependence of both the weights and the inverse moment matrix.\n\n3) Using your formulas from items $1)$ and $2)$, verify:\n- Smoothness: argue from first principles why the functions $N_{i}(x)$ and $\\partial_{x}N_{i}(x)$ are continuous (indeed $C^{\\infty}$) at $x=0$.\n- Absence of the Kronecker delta property at nodes: demonstrate explicitly that $N_{0}(0) \\neq 1$ and $N_{j}(0) \\neq 0$ for at least one $j \\neq 0$.\n\nFor the final answer, report only the exact closed-form analytic expression (in terms of $\\exp(\\cdot)$) for the central-node MLS shape function evaluated at the central node, $N_{0}(0)$. Do not provide a numerical approximation. Express your final answer as a single simplified expression in terms of $\\exp(-\\tfrac{1}{2})$ and $\\exp(-2)$. No units are required.", "solution": "The problem is well-posed, scientifically grounded, and contains all necessary information to derive a unique solution. We proceed with the solution.\n\nThe Moving Least Squares (MLS) approximation $u^{h}(x)$ of a function $u(x)$ is constructed by finding the best local polynomial fit. At any point $x$, we seek a vector of coefficients $\\mathbf{a}(x)$ that minimizes a weighted discrete $L_2$ norm of the error between the polynomial approximation and the nodal values $u_i = u(x_i)$. The functional to be minimized is:\n$$\nJ(\\mathbf{a}(x)) = \\sum_{i} w_{i}(x) \\left( \\mathbf{p}(x_i)^T \\mathbf{a}(x) - u_i \\right)^2\n$$\nwhere $p(x) = [1, x, x^2]^T$ is the quadratic basis, $x_i \\in \\{-2, -1, 0, 1, 2\\}$ is the set of nodes, and $w_{i}(x) = \\exp(-\\frac{(x - x_i)^2}{2})$ is the Gaussian weight function.\n\nThe minimum is found by setting the gradient of $J$ with respect to $\\mathbf{a}(x)$ to zero, $\\nabla_a J(\\mathbf{a}(x)) = 0$. This leads to the normal equations:\n$$\n\\left( \\sum_{i} w_{i}(x) \\mathbf{p}(x_i) \\mathbf{p}(x_i)^T \\right) \\mathbf{a}(x) = \\sum_{i} w_{i}(x) \\mathbf{p}(x_i) u_i\n$$\nThe matrix in the parentheses is the moment matrix, $\\mathbf{A}(x) = \\sum_{i} w_{i}(x) \\mathbf{p}(x_i) \\mathbf{p}(x_i)^T$. The normal equations are thus $\\mathbf{A}(x) \\mathbf{a}(x) = \\mathbf{B}(x) \\mathbf{u}$, where $\\mathbf{B}(x)$ is a matrix whose $i$-th column is $w_{i}(x)\\mathbf{p}(x_i)$ and $\\mathbf{u}$ is the vector of nodal values $u_i$.\nSolving for $\\mathbf{a}(x)$ yields $\\mathbf{a}(x) = \\mathbf{A}^{-1}(x) \\sum_{i} w_{i}(x) \\mathbf{p}(x_i) u_i$.\nThe MLS approximation is then $u^{h}(x) = \\mathbf{p}(x)^T \\mathbf{a}(x)$. Substituting the expression for $\\mathbf{a}(x)$:\n$$\nu^{h}(x) = \\mathbf{p}(x)^T \\mathbf{A}^{-1}(x) \\sum_{i} w_{i}(x) \\mathbf{p}(x_i) u_i = \\sum_{i} \\left( \\mathbf{p}(x)^T \\mathbf{A}^{-1}(x) w_{i}(x) \\mathbf{p}(x_i) \\right) u_i\n$$\nBy definition, $u^{h}(x) = \\sum_{i} N_i(x) u_i$, so the MLS shape function for node $i$ is:\n$$\nN_i(x) = \\mathbf{p}(x)^T \\mathbf{A}^{-1}(x) w_{i}(x) \\mathbf{p}(x_i)\n$$\n\n### Part 1: Computation of $N_i(0)$\n\nWe need to evaluate the shape functions at $x=0$. This requires computing the moment matrix $\\mathbf{A}(0)$ and its inverse.\nThe nodes are $x_i \\in \\{-2, -1, 0, 1, 2\\}$. Let us denote them $x_{-2}, x_{-1}, x_0, x_1, x_2$.\nThe weights at $x=0$ are $w_i(0) = \\exp(-\\frac{x_i^2}{2})$.\n$w_0(0) = \\exp(0) = 1$.\n$w_1(0) = w_{-1}(0) = \\exp(-\\frac{1^2}{2}) = \\exp(-\\frac{1}{2})$.\n$w_2(0) = w_{-2}(0) = \\exp(-\\frac{(-2)^2}{2}) = \\exp(-2)$.\n\nThe moment matrix is $\\mathbf{A}(x) = \\sum_{i} w_i(x) \\begin{pmatrix} 1 & x_i & x_i^2 \\\\ x_i & x_i^2 & x_i^3 \\\\ x_i^2 & x_i^3 & x_i^4 \\end{pmatrix}$.\nAt $x=0$, due to the symmetry of the nodes and weights ($w_i(0)=w_{-i}(0)$), any summation $\\sum_i w_i(0) x_i^k$ for odd $k$ will be zero.\n$$\n\\mathbf{A}(0) = \\begin{pmatrix} \\sum_i w_i(0) & 0 & \\sum_i w_i(0) x_i^2 \\\\ 0 & \\sum_i w_i(0) x_i^2 & 0 \\\\ \\sum_i w_i(0) x_i^2 & 0 & \\sum_i w_i(0) x_i^4 \\end{pmatrix}\n$$\nLet's compute the sums (moments):\n$S_0 = \\sum_i w_i(0) = w_0(0) + 2w_1(0) + 2w_2(0) = 1 + 2\\exp(-\\frac{1}{2}) + 2\\exp(-2)$.\n$S_2 = \\sum_i w_i(0) x_i^2 = w_0(0)(0)^2 + 2w_1(0)(1)^2 + 2w_2(0)(2)^2 = 2\\exp(-\\frac{1}{2}) + 8\\exp(-2)$.\n$S_4 = \\sum_i w_i(0) x_i^4 = w_0(0)(0)^4 + 2w_1(0)(1)^4 + 2w_2(0)(2)^4 = 2\\exp(-\\frac{1}{2}) + 32\\exp(-2)$.\n\nSo the moment matrix at $x=0$ is:\n$$\n\\mathbf{A}(0) = \\begin{pmatrix} S_0 & 0 & S_2 \\\\ 0 & S_2 & 0 \\\\ S_2 & 0 & S_4 \\end{pmatrix}\n$$\nThe matrix is block-diagonal, which simplifies inversion. The inverse is:\n$$\n\\mathbf{A}^{-1}(0) = \\begin{pmatrix} \\frac{S_4}{S_0 S_4 - S_2^2} & 0 & \\frac{-S_2}{S_0 S_4 - S_2^2} \\\\ 0 & \\frac{1}{S_2} & 0 \\\\ \\frac{-S_2}{S_0 S_4 - S_2^2} & 0 & \\frac{S_0}{S_0 S_4 - S_2^2} \\end{pmatrix}\n$$\nThe determinant of the $2 \\times 2$ block is $\\det_{sub} = S_0 S_4 - S_2^2$. Let's compute this term. Let $E_1 = \\exp(-\\frac{1}{2})$ and $E_2 = \\exp(-2)$.\n$S_0 = 1 + 2E_1 + 2E_2$\n$S_2 = 2E_1 + 8E_2$\n$S_4 = 2E_1 + 32E_2$\n$\\det_{sub} = (1 + 2E_1 + 2E_2)(2E_1 + 32E_2) - (2E_1 + 8E_2)^2$\n$= (2E_1+32E_2) + (4E_1^2+64E_1E_2) + (4E_1E_2+64E_2^2) - (4E_1^2 + 32E_1E_2 + 64E_2^2)$\n$= 2E_1+32E_2 + 4E_1^2 + 68E_1E_2 + 64E_2^2 - 4E_1^2 - 32E_1E_2 - 64E_2^2$\n$= 2E_1 + 32E_2 + 36E_1E_2$.\nSubstituting back the exponential forms and using $E_1E_2 = \\exp(-\\frac{5}{2})$:\n$\\det_{sub} = 2\\exp(-\\frac{1}{2}) + 32\\exp(-2) + 36\\exp(-\\frac{5}{2})$.\n\nNow we compute $N_i(0) = \\mathbf{p}(0)^T \\mathbf{A}^{-1}(0) w_i(0) \\mathbf{p}(x_i)$.\nSince $\\mathbf{p}(0)^T = [1, 0, 0]$, it picks the first row of $\\mathbf{A}^{-1}(0)$:\n$\\mathbf{p}(0)^T \\mathbf{A}^{-1}(0) = [(\\mathbf{A}^{-1})_{11}, 0, (\\mathbf{A}^{-1})_{13}] = [\\frac{S_4}{\\det_{sub}}, 0, \\frac{-S_2}{\\det_{sub}}]$.\nThen, $N_i(0) = [\\frac{S_4}{\\det_{sub}}, 0, \\frac{-S_2}{\\det_{sub}}] \\begin{pmatrix} 1 \\\\ x_i \\\\ x_i^2 \\end{pmatrix} w_i(0) = \\frac{w_i(0)}{\\det_{sub}} (S_4 - S_2 x_i^2)$.\n\nFor the central node $i=0$: $x_0=0$, $w_0(0)=1$.\n$N_0(0) = \\frac{1}{\\det_{sub}}(S_4 - S_2(0)^2) = \\frac{S_4}{\\det_{sub}}$.\n$N_0(0) = \\frac{2\\exp(-\\frac{1}{2}) + 32\\exp(-2)}{2\\exp(-\\frac{1}{2}) + 32\\exp(-2) + 36\\exp(-\\frac{5}{2})}$.\nDividing the numerator and denominator by $2$:\n$N_0(0) = \\frac{\\exp(-\\frac{1}{2}) + 16\\exp(-2)}{\\exp(-\\frac{1}{2}) + 16\\exp(-2) + 18\\exp(-\\frac{5}{2})}$. This is the value requested for the final answer.\n\n### Part 2: Computation of $\\partial_x N_i(0)$\n\nThe gradient of the shape function is found by differentiating $N_i(x)$:\n$\\partial_x N_i(x) = (\\partial_x \\mathbf{p}(x)^T) \\mathbf{A}^{-1}(x) w_i(x) \\mathbf{p}(x_i) + \\mathbf{p}(x)^T (\\partial_x \\mathbf{A}^{-1}(x)) w_i(x) \\mathbf{p}(x_i) + \\mathbf{p}(x)^T \\mathbf{A}^{-1}(x) (\\partial_x w_i(x)) \\mathbf{p}(x_i)$.\nWe evaluate each term at $x=0$.\n$\\partial_x \\mathbf{p}(x) = [0, 1, 2x]^T$, so $\\partial_x \\mathbf{p}(0) = [0, 1, 0]^T$.\n$\\partial_x w_i(x) = -(x-x_i)w_i(x)$, so $\\partial_x w_i(0) = x_i w_i(0)$.\n$\\partial_x \\mathbf{A}^{-1}(x) = -\\mathbf{A}^{-1}(x) (\\partial_x \\mathbf{A}(x)) \\mathbf{A}^{-1}(x)$.\n$\\partial_x \\mathbf{A}(x) = \\sum_j (\\partial_x w_j(x)) \\mathbf{p}(x_j)\\mathbf{p}(x_j)^T$, so $\\partial_x \\mathbf{A}(0) = \\sum_j x_j w_j(0) \\mathbf{p}(x_j)\\mathbf{p}(x_j)^T$.\nThis matrix, let's call it $\\mathbf{A}'(0)$, has entries $\\mathbf{A}'_{kl}(0) = \\sum_j w_j(0) x_j^{k+l-1}$. Due to symmetry, entries are non-zero only if $k+l-1$ is even.\n$\\mathbf{A}'_{11} = \\sum w_j x_j = 0$. $\\mathbf{A}'_{12} = \\sum w_j x_j^2 = S_2$. $\\mathbf{A}'_{13} = 0$. $\\mathbf{A}'_{22} = 0$. $\\mathbf{A}'_{23} = \\sum w_j x_j^4 = S_4$. $\\mathbf{A}'_{33}=0$.\n$$\n\\mathbf{A}'(0) = \\begin{pmatrix} 0 & S_2 & 0 \\\\ S_2 & 0 & S_4 \\\\ 0 & S_4 & 0 \\end{pmatrix}\n$$\nNow we evaluate the three terms of $\\partial_x N_i(0)$.\n- Term 1: $\\partial_x \\mathbf{p}(0)^T \\mathbf{A}^{-1}(0) w_i(0) \\mathbf{p}(x_i) = [0,1,0]\\mathbf{A}^{-1}(0) w_i(0) \\mathbf{p}(x_i) = (\\mathbf{A}^{-1})_{22} w_i(0) x_i = \\frac{1}{S_2} w_i(0) x_i$.\n- Term 2: $-\\mathbf{p}(0)^T\\mathbf{A}^{-1}(0)\\mathbf{A}'(0)\\mathbf{A}^{-1}(0)w_i(0)\\mathbf{p}(x_i)$.\nThe vector $\\mathbf{v}^T = \\mathbf{p}(0)^T\\mathbf{A}^{-1}(0)\\mathbf{A}'(0) = [\\frac{S_4}{\\det_{sub}}, 0, \\frac{-S_2}{\\det_{sub}}] \\begin{pmatrix} 0 & S_2 & 0 \\\\ S_2 & 0 & S_4 \\\\ 0 & S_4 & 0 \\end{pmatrix} = [0, \\frac{S_4 S_2}{\\det_{sub}} - \\frac{S_2 S_4}{\\det_{sub}}, 0] = [0, 0, 0]$.\nSo, Term 2 is zero for all $i$. This is a consequence of symmetry.\n- Term 3: $\\mathbf{p}(0)^T \\mathbf{A}^{-1}(0) (\\partial_x w_i(0)) \\mathbf{p}(x_i) = \\mathbf{p}(0)^T \\mathbf{A}^{-1}(0) (x_i w_i(0)) \\mathbf{p}(x_i) = x_i N_i(0)$.\n\nCombining terms:\n$$\n\\partial_x N_i(0) = \\frac{x_i w_i(0)}{S_2} + x_i N_i(0) = x_i w_i(0) \\left( \\frac{1}{S_2} + \\frac{S_4 - S_2 x_i^2}{\\det_{sub}} \\right)\n$$\nFor $i=0$, $x_0=0$, so $\\partial_x N_0(0) = 0$. This is expected for an even shape function $N_0(x)$ centered at a point of symmetry.\n\n### Part 3: Verification of Properties\n\n- **Smoothness**: The shape function is $N_i(x) = \\mathbf{p}(x)^T \\mathbf{A}^{-1}(x) w_i(x) \\mathbf{p}(x_i)$. The basis functions $p_k(x)$ are polynomials and hence $C^{\\infty}$. The weight functions $w_i(x)$ are Gaussian and are $C^{\\infty}$. The moment matrix $\\mathbf{A}(x)$ has entries that are linear combinations of $w_j(x)$, so they are also $C^{\\infty}$. The inverse $\\mathbf{A}^{-1}(x)$ exists and its entries are $C^{\\infty}$ as long as $\\det(\\mathbf{A}(x)) \\neq 0$. We computed $\\det(\\mathbf{A}(0)) = S_2 \\cdot \\det_{sub}$. Since $S_2 > 0$ and $\\det_{sub} > 0$, the determinant is non-zero at $x=0$. By continuity, it is non-zero in a neighborhood of $x=0$. Therefore, $\\mathbf{A}^{-1}(x)$ is $C^{\\infty}$ near $x=0$. As $N_i(x)$ is formed from products and sums of $C^{\\infty}$ functions, it is $C^{\\infty}$. Its derivative $\\partial_x N_i(x)$ is consequently also $C^{\\infty}$.\n\n- **Absence of Kronecker Delta Property**:\nWe need to show $N_0(0) \\neq 1$ and $N_j(0) \\neq 0$ for some $j \\neq 0$.\nThe expression for $N_0(0)$ is $\\frac{S_4}{\\det_{sub}} = \\frac{S_4}{S_4 + 36\\exp(-\\frac{5}{2})}$, which is clearly positive and less than $1$. So $N_0(0) \\neq 1$.\nFor $j=1$, $x_1=1$:\n$N_1(0) = \\frac{w_1(0)}{\\det_{sub}}(S_4 - S_2 x_1^2) = \\frac{\\exp(-\\frac{1}{2})}{\\det_{sub}}(S_4 - S_2)$.\n$S_4 - S_2 = (2E_1 + 32E_2) - (2E_1 + 8E_2) = 24E_2 = 24\\exp(-2)$.\n$N_1(0) = \\frac{\\exp(-\\frac{1}{2}) \\cdot 24\\exp(-2)}{\\det_{sub}} = \\frac{24\\exp(-\\frac{5}{2})}{\\det_{sub}}$.\nSince $\\det_{sub}>0$, we have $N_1(0) > 0$. By symmetry, $N_{-1}(0) = N_1(0) \\neq 0$.\nSimilarly, for $j=2$, $x_2=2$:\n$N_2(0) = \\frac{w_2(0)}{\\det_{sub}}(S_4 - S_2 x_2^2) = \\frac{\\exp(-2)}{\\det_{sub}}(S_4 - 4S_2)$.\n$S_4 - 4S_2 = (2E_1 + 32E_2) - 4(2E_1 + 8E_2) = -6E_1 = -6\\exp(-\\frac{1}{2})$.\n$N_2(0) = \\frac{\\exp(-2) \\cdot (-6\\exp(-\\frac{1}{2}))}{\\det_{sub}} = \\frac{-6\\exp(-\\frac{5}{2})}{\\det_{sub}} \\neq 0$.\nThis explicitly demonstrates that the MLS shape functions do not possess the Kronecker delta property at the nodes.\n\nThe final answer required is the expression for $N_0(0)$.\n$N_0(0) = \\frac{\\exp(-\\frac{1}{2}) + 16\\exp(-2)}{\\exp(-\\frac{1}{2}) + 16\\exp(-2) + 18\\exp(-\\frac{5}{2})}$.\nFactoring out the numerator from the denominator visually demonstrates this:\n$N_0(0) = \\frac{\\exp(-\\frac{1}{2}) + 16\\exp(-2)}{(\\exp(-\\frac{1}{2}) + 16\\exp(-2)) + 18\\exp(-\\frac{5}{2})}$.", "answer": "$$\n\\boxed{\\frac{\\exp(-\\frac{1}{2}) + 16\\exp(-2)}{18\\exp(-\\frac{5}{2}) + \\exp(-\\frac{1}{2}) + 16\\exp(-2)}}\n$$", "id": "3581248"}, {"introduction": "Moving from analytical derivation to numerical implementation, this practice focuses on verifying one of the most critical properties of a numerical approximation: polynomial reproduction. This exercise [@problem_id:3581266] guides you through the implementation of a \"patch test,\" a fundamental benchmark in computational mechanics that confirms whether the approximation can exactly represent specific polynomial fields. Successfully passing the patch test is a necessary condition for convergence, and this practice demonstrates its direct link to the completeness of the chosen polynomial basis.", "problem": "Consider a two-dimensional meshfree Element-Free Galerkin (EFG) patch test formulated via Moving Least Squares (MLS) within the framework of Reproducing Kernel (RK) approximation. The goal is to verify the reproduction properties under rigid body motion and uniform strain for a square particle cloud, and to quantify the effect of support size and basis degree on the numerical reproduction error.\n\nYou are to implement an MLS-based shape function construction over a uniform set of nodes in the square domain $[0,1] \\times [0,1]$, with node coordinates given by a regular grid of size $N_x \\times N_y$, where $N_x = N_y = 11$. The grid spacing is $h = 1/(N_x - 1)$. Use a compactly supported, positive weight function defined by\n$$\nw(q) = \\begin{cases}\n1 - 6 q^2 + 8 q^3 - 3 q^4, & 0 \\le q \\le 1, \\\\\n0, & q > 1,\n\\end{cases}\n$$\nwhere $q = r/d$, $r$ is the Euclidean distance from the evaluation point to a node, and $d$ is the nodal support radius. The MLS basis must be either degree $0$ (constant basis $p(\\mathbf{x}) = [1]$) or degree $1$ (linear basis $p(\\mathbf{x}) = [1, x, y]$). The MLS approximation must be constructed directly from first principles: start from the variational definition of MLS coefficients that minimize the weighted least-squares error over the local neighborhood, and derive the algebraic expressions needed for numerical evaluation of the shape functions and the approximate field.\n\nDefine three displacement fields in the plane:\n- Rigid translation: $\\mathbf{u}(\\mathbf{x}) = \\mathbf{c}$, with $\\mathbf{c} \\in \\mathbb{R}^2$.\n- Infinitesimal rigid rotation about the origin by angle $\\theta$ (in radians): $\\mathbf{u}(\\mathbf{x}) = \\theta\\,[-y,\\,x]^T$.\n- Uniform strain: $\\mathbf{u}(\\mathbf{x}) = \\mathbf{E}\\,\\mathbf{x}$, with $\\mathbf{E} \\in \\mathbb{R}^{2 \\times 2}$ constant.\n\nThe reproduction test requires that the MLS approximation $\\mathbf{u}^h(\\mathbf{x})$ exactly matches the target field $\\mathbf{u}(\\mathbf{x})$ for all $\\mathbf{x}$ whenever the field belongs to the polynomial space spanned by the chosen basis and the moment matrix is invertible. In particular, with the degree $0$ basis, constant fields are reproducible; with the degree $1$ basis, all linear vector fields, including rigid body rotation and uniform strain, are reproducible.\n\nNumerically verify these reproduction properties by constructing the MLS approximant $\\mathbf{u}^h(\\mathbf{x})$ from nodal samples $\\{\\mathbf{u}_i\\}$ at the grid nodes $\\{\\mathbf{x}_i\\}$ and evaluating the maximum absolute error\n$$\n\\varepsilon_{\\max} = \\max_{\\mathbf{x} \\in \\mathcal{S}} \\|\\mathbf{u}^h(\\mathbf{x}) - \\mathbf{u}(\\mathbf{x})\\|_{\\infty},\n$$\nover a set $\\mathcal{S}$ of evaluation points. Use the infinity norm on $\\mathbb{R}^2$ defined by $\\|[a,b]^T\\|_{\\infty} = \\max\\{|a|,|b|\\}$.\n\nAngles must be in radians. No physical units are involved in the outputs. Your program must implement the MLS shape functions and compute $\\varepsilon_{\\max}$ for each test case below. The final output must be a single line containing a list of floating-point errors for each test case, in the specified order.\n\nTest suite:\n- Test $\\mathbf{T1}$ (happy path, constant reproduction): basis degree $0$; support factor $s = 2.5$ so $d = s\\,h$; rigid translation with $\\mathbf{c} = [0.3,-0.2]^T$; evaluation set $\\mathcal{S}$ is the Cartesian product of coordinates $\\{0.1,0.3,0.5,0.7,0.9\\} \\times \\{0.1,0.3,0.5,0.7,0.9\\}$, totaling $25$ points.\n- Test $\\mathbf{T2}$ (non-reproducible with constant basis): basis degree $0$; support factor $s = 2.5$; rigid rotation with $\\theta = 0.1$; evaluation set $\\mathcal{S}$ as in $\\mathbf{T1}$.\n- Test $\\mathbf{T3}$ (rigid rotation reproduction): basis degree $1$; support factor $s = 2.5$; rigid rotation with $\\theta = 0.1$; evaluation set $\\mathcal{S}$ as in $\\mathbf{T1}$.\n- Test $\\mathbf{T4}$ (uniform strain reproduction): basis degree $1$; support factor $s = 2.5$; uniform strain with\n$$\n\\mathbf{E} = \\begin{bmatrix} 0.01 & 0.02 \\\\ 0.00 & -0.005 \\end{bmatrix};\n$$\nevaluation set $\\mathcal{S}$ as in $\\mathbf{T1}$.\n- Test $\\mathbf{T5}$ (edge case near boundary with small support): basis degree $1$; support factor $s = 1.05$; uniform strain with the same $\\mathbf{E}$ as in $\\mathbf{T4}$; evaluation set $\\mathcal{S}$ consists of a single point $\\mathbf{x} = [0.02, 0.02]^T$.\n\nFor each test, compute and return the value of $\\varepsilon_{\\max}$ as a float. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[$r_1,r_2,r_3,r_4,r_5$]\"), where $r_k$ is the result for test $\\mathbf{Tk}$ in the above order. Angles must be interpreted in radians, and there are no physical units for the outputs.\n\nYour derivations and implementation must start from the foundational definitions of the MLS approximation and the concept of reproduction in reproducing kernel methods, without assuming specialized formulas beyond these definitions.", "solution": "The problem requires the numerical verification of the reproduction properties of the Moving Least Squares (MLS) approximation, a cornerstone of meshfree methods like the Element-Free Galerkin (EFG) method. We will first derive the MLS shape functions from foundational principles and then outline the numerical procedure to conduct the patch tests.\n\n### 1. Moving Least Squares (MLS) Approximation\n\nThe MLS method constructs a continuous approximation of a field from a set of discrete nodal values. Let $u(\\mathbf{x})$ be a scalar field defined over a domain $\\Omega \\subset \\mathbb{R}^2$. Given a set of $N$ nodes $\\{\\mathbf{x}_i\\}_{i=1}^N$ with corresponding nodal values $\\{u_i = u(\\mathbf{x}_i)\\}_{i=1}^N$, the MLS approximation $u^h(\\mathbf{x})$ at an evaluation point $\\mathbf{x}$ is defined as a polynomial of a certain degree whose coefficients are determined locally.\n\nLet $\\mathbf{p}(\\mathbf{x}) = [p_1(\\mathbf{x}), p_2(\\mathbf{x}), \\dots, p_m(\\mathbf{x})]^T$ be a basis of $m$ polynomial functions. For a linear approximation in two dimensions, a suitable basis is $\\mathbf{p}(\\mathbf{x}) = [1, x, y]^T$, corresponding to a basis degree of $1$ and $m=3$. For a constant approximation, the basis is $\\mathbf{p}(\\mathbf{x}) = [1]$, with degree $0$ and $m=1$.\n\nThe approximation at a point $\\mathbf{x}$ is given by:\n$$\nu^h(\\mathbf{x}) = \\mathbf{p}(\\mathbf{x})^T \\mathbf{a}(\\mathbf{x})\n$$\nwhere $\\mathbf{a}(\\mathbf{x}) \\in \\mathbb{R}^m$ is a vector of coefficients that depends on the position $\\mathbf{x}$. These coefficients are determined by minimizing a weighted, discrete least-squares error functional $J(\\mathbf{a})$ over the nodal values in a local neighborhood of $\\mathbf{x}$:\n$$\nJ(\\mathbf{a}) = \\sum_{i=1}^{N} w(\\mathbf{x} - \\mathbf{x}_i) \\left[ \\mathbf{p}(\\mathbf{x}_i)^T \\mathbf{a}(\\mathbf{x}) - u_i \\right]^2\n$$\nThe function $w(\\mathbf{x} - \\mathbf{x}_i)$ is a weight function with compact support, which is non-zero only for nodes $\\mathbf{x}_i$ \"close\" to $\\mathbf{x}$. The problem specifies the weight function as:\n$$\nw(q) = \\begin{cases}\n1 - 6 q^2 + 8 q^3 - 3 q^4, & 0 \\le q \\le 1, \\\\\n0, & q > 1,\n\\end{cases}\n$$\nwhere $q = \\|\\mathbf{x} - \\mathbf{x}_i\\|_2 / d$, $d$ being the radius of the support domain. For brevity, we denote $w_i(\\mathbf{x}) = w(\\mathbf{x} - \\mathbf{x}_i)$.\n\nTo find the coefficients $\\mathbf{a}(\\mathbf{x})$ that minimize $J$, we take the derivative of $J$ with respect to $\\mathbf{a}$ and set it to zero:\n$$\n\\frac{\\partial J}{\\partial \\mathbf{a}} = 2 \\sum_{i=1}^{N} w_i(\\mathbf{x}) \\mathbf{p}(\\mathbf{x}_i) \\left[ \\mathbf{p}(\\mathbf{x}_i)^T \\mathbf{a}(\\mathbf{x}) - u_i \\right] = \\mathbf{0}\n$$\nThis leads to the following system of linear equations for $\\mathbf{a}(\\mathbf{x})$:\n$$\n\\left( \\sum_{i=1}^{N} w_i(\\mathbf{x}) \\mathbf{p}(\\mathbf{x}_i) \\mathbf{p}(\\mathbf{x}_i)^T \\right) \\mathbf{a}(\\mathbf{x}) = \\sum_{i=1}^{N} w_i(\\mathbf{x}) \\mathbf{p}(\\mathbf{x}_i) u_i\n$$\nWe define the moment matrix $\\mathbf{M}(\\mathbf{x})$, an $m \\times m$ matrix, as:\n$$\n\\mathbf{M}(\\mathbf{x}) = \\sum_{i=1}^{N} w_i(\\mathbf{x}) \\mathbf{p}(\\mathbf{x}_i) \\mathbf{p}(\\mathbf{x}_i)^T\n$$\nThe system can now be written as $\\mathbf{M}(\\mathbf{x}) \\mathbf{a}(\\mathbf{x}) = \\sum_{i=1}^{N} w_i(\\mathbf{x}) \\mathbf{p}(\\mathbf{x}_i) u_i$.\nAssuming $\\mathbf{M}(\\mathbf{x})$ is invertible, which requires a sufficient number of nodes within the support domain of $\\mathbf{x}$ that are not in a degenerate configuration, we can solve for $\\mathbf{a}(\\mathbf{x})$:\n$$\n\\mathbf{a}(\\mathbf{x}) = \\mathbf{M}^{-1}(\\mathbf{x}) \\sum_{i=1}^{N} w_i(\\mathbf{x}) \\mathbf{p}(\\mathbf{x}_i) u_i\n$$\n\n### 2. Derivation of MLS Shape Functions\n\nSubstituting the expression for $\\mathbf{a}(\\mathbf{x})$ back into the definition of $u^h(\\mathbf{x})$, we get:\n$$\nu^h(\\mathbf{x}) = \\mathbf{p}(\\mathbf{x})^T \\mathbf{M}^{-1}(\\mathbf{x}) \\sum_{i=1}^{N} w_i(\\mathbf{x}) \\mathbf{p}(\\mathbf{x}_i) u_i\n$$\nBy rearranging the expression to match the standard finite element form $u^h(\\mathbf{x}) = \\sum_{i=1}^{N} \\phi_i(\\mathbf{x}) u_i$, we can identify the MLS shape function $\\phi_i(\\mathbf{x})$ associated with node $i$:\n$$\n\\phi_i(\\mathbf{x}) = \\mathbf{p}(\\mathbf{x})^T \\mathbf{M}^{-1}(\\mathbf{x}) \\mathbf{p}(\\mathbf{x}_i) w_i(\\mathbf{x})\n$$\nNote that $\\phi_i(\\mathbf{x}) = 0$ if node $\\mathbf{x}_i$ is outside the support of $\\mathbf{x}$, because $w_i(\\mathbf{x})=0$.\n\nFor a vector field, such as a displacement field $\\mathbf{u}(\\mathbf{x}) \\in \\mathbb{R}^2$, the MLS approximation is applied to each component independently using the same scalar shape functions:\n$$\n\\mathbf{u}^h(\\mathbf{x}) = \\sum_{i=1}^{N} \\phi_i(\\mathbf{x}) \\mathbf{u}_i\n$$\nwhere $\\mathbf{u}_i = \\mathbf{u}(\\mathbf{x}_i)$ are the nodal displacement vectors.\n\n### 3. Reproduction Property\n\nThe MLS approximation possesses the \"reproducing kernel\" property. If the basis $\\mathbf{p}(\\mathbf{x})$ includes all polynomial terms up to degree $k$, then the MLS approximation can exactly reproduce any polynomial field of degree up to $k$.\nLet the field to be approximated, $u(\\mathbf{x})$, be a polynomial from the span of the basis, i.e., $u(\\mathbf{x}) = \\mathbf{p}(\\mathbf{x})^T\\mathbf{c}$ for some constant coefficient vector $\\mathbf{c}$. The nodal values are $u_i = u(\\mathbf{x}_i) = \\mathbf{p}(\\mathbf{x}_i)^T\\mathbf{c}$.\nSubstituting these nodal values into the expression for $u^h(\\mathbf{x})$:\n$$\nu^h(\\mathbf{x}) = \\sum_{i=1}^{N} \\phi_i(\\mathbf{x}) u_i = \\sum_{i=1}^{N} \\phi_i(\\mathbf{x}) (\\mathbf{p}(\\mathbf{x}_i)^T\\mathbf{c})\n$$\nSubstituting the formula for $\\phi_i(\\mathbf{x})$:\n$$\nu^h(\\mathbf{x}) = \\sum_{i=1}^{N} \\left[ \\mathbf{p}(\\mathbf{x})^T \\mathbf{M}^{-1}(\\mathbf{x}) \\mathbf{p}(\\mathbf{x}_i) w_i(\\mathbf{x}) \\right] (\\mathbf{p}(\\mathbf{x}_i)^T\\mathbf{c})\n$$\nSince $\\mathbf{c}$ is constant, we can pull it out of the summation:\n$$\nu^h(\\mathbf{x}) = \\mathbf{p}(\\mathbf{x})^T \\mathbf{M}^{-1}(\\mathbf{x}) \\left( \\sum_{i=1}^{N} w_i(\\mathbf{x}) \\mathbf{p}(\\mathbf{x}_i)\\mathbf{p}(\\mathbf{x}_i)^T \\right) \\mathbf{c}\n$$\nThe term in the parenthesis is the definition of the moment matrix $\\mathbf{M}(\\mathbf{x})$. Therefore:\n$$\nu^h(\\mathbf{x}) = \\mathbf{p}(\\mathbf{x})^T \\mathbf{M}^{-1}(\\mathbf{x}) \\mathbf{M}(\\mathbf{x}) \\mathbf{c} = \\mathbf{p}(\\mathbf{x})^T \\mathbf{c} = u(\\mathbf{x})\n$$\nThis proves that $u^h(\\mathbf{x}) = u(\\mathbf{x})$ for any point $\\mathbf{x}$ where $\\mathbf{M}(\\mathbf{x})$ is invertible, provided $u(\\mathbf{x})$ is in the space spanned by the basis $\\mathbf{p}(\\mathbf{x})$.\n\n### 4. Numerical Implementation for Patch Tests\n\nThe algorithm to perform the numerical verification for each test case is as follows:\n1.  **Node Generation**: Generate a grid of $N_x \\times N_y = 11 \\times 11$ nodes in the domain $[0,1] \\times [0,1]$. The grid spacing is $h = 1 / (N_x - 1) = 1/10 = 0.1$.\n2.  **Test Case Setup**: For each test case ($\\mathbf{T1}$ to $\\mathbf{T5}$), set the basis degree, support factor $s$, the analytical displacement field $\\mathbf{u}(\\mathbf{x})$, and the set of evaluation points $\\mathcal{S}$. The support radius is $d = s \\cdot h$.\n3.  **Nodal Displacements**: Evaluate the analytical displacement field $\\mathbf{u}(\\mathbf{x})$ at each node $\\mathbf{x}_i$ to obtain the nodal values $\\mathbf{u}_i$.\n4.  **Error Calculation**:\n    a. Initialize maximum error $\\varepsilon_{\\max} = 0$.\n    b. For each evaluation point $\\mathbf{x} \\in \\mathcal{S}$:\n        i.   Identify all nodes $\\{\\mathbf{x}_i\\}$ within the support, i.e., for which $\\|\\mathbf{x} - \\mathbf{x}_i\\|_2 \\le d$.\n        ii.  Construct the moment matrix $\\mathbf{M}(\\mathbf{x})$ using the basis polynomials $\\mathbf{p}(\\mathbf{x}_i)$ and weights $w_i(\\mathbf{x})$ for the nodes in the support.\n        iii. If $\\mathbf{M}(\\mathbf{x})$ is invertible, compute its inverse $\\mathbf{M}^{-1}(\\mathbf{x})$.\n        iv.  Initialize the approximated displacement $\\mathbf{u}^h(\\mathbf{x}) = [0, 0]^T$.\n        v.   For each node $\\mathbf{x}_i$ in the support, compute its shape function value $\\phi_i(\\mathbf{x}) = \\mathbf{p}(\\mathbf{x})^T \\mathbf{M}^{-1}(\\mathbf{x}) \\mathbf{p}(\\mathbf{x}_i) w_i(\\mathbf{x})$.\n        vi.  Accumulate the approximation: $\\mathbf{u}^h(\\mathbf{x}) += \\phi_i(\\mathbf{x}) \\mathbf{u}_i$.\n        vii. Calculate the analytical displacement $\\mathbf{u}(\\mathbf{x})$ at the evaluation point.\n        viii.Compute the error $\\varepsilon = \\|\\mathbf{u}^h(\\mathbf{x}) - \\mathbf{u}(\\mathbf{x})\\|_{\\infty} = \\max(|u_x^h - u_x|, |u_y^h - u_y|)$.\n        ix.  Update $\\varepsilon_{\\max} = \\max(\\varepsilon_{\\max}, \\varepsilon)$.\n5.  **Return Result**: The final $\\varepsilon_{\\max}$ is the result for the test case.\n\nThe test cases are designed to verify the reproduction property:\n-   **T1**: Degree $0$ basis on a constant field. Expected $\\varepsilon_{\\max} \\approx 0$.\n-   **T2**: Degree $0$ basis on a linear field. Not reproducible. Expected $\\varepsilon_{\\max} > 0$.\n-   **T3**: Degree $1$ basis on a linear field (rotation). Expected $\\varepsilon_{\\max} \\approx 0$.\n-   **T4**: Degree $1$ basis on a linear field (strain). Expected $\\varepsilon_{\\max} \\approx 0$.\n-   **T5**: Degree $1$ basis on a linear field, with minimal support near a boundary. This tests the robustness of the method. Expected $\\varepsilon_{\\max} \\approx 0$, possibly slightly larger than T3/T4 due to poorer conditioning of $\\mathbf{M}(\\mathbf{x})$.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and runs the Element-Free Galerkin (EFG) patch tests \n    using Moving Least Squares (MLS) approximation.\n    \"\"\"\n\n    # --- Problem Setup ---\n    Nx = 11\n    Ny = 11\n    h = 1.0 / (Nx - 1)\n    \n    # Generate node coordinates\n    x_coords = np.linspace(0.0, 1.0, Nx)\n    y_coords = np.linspace(0.0, 1.0, Ny)\n    nodes = np.array(np.meshgrid(x_coords, y_coords)).T.reshape(-1, 2)\n\n    # --- Weight Function ---\n    def weight_function(q):\n        \"\"\"\n        C1 continuous quartic spline weight function.\n        w(q) = 1 - 6q^2 + 8q^3 - 3q^4 for 0 <= q <= 1.\n        \"\"\"\n        if 0.0 <= q <= 1.0:\n            return 1.0 - 6.0*q**2 + 8.0*q**3 - 3.0*q**4\n        return 0.0\n\n    # --- MLS Core Logic ---\n    def compute_mls_error(nodes, basis_degree, support_factor, u_field_func, eval_points):\n        \"\"\"\n        Computes the maximum error of the MLS approximation for a given setup.\n        \"\"\"\n        s = support_factor\n        d = s * h\n        \n        # Get nodal values from the analytical field\n        u_nodal = np.array([u_field_func(node) for node in nodes])\n        \n        max_error = 0.0\n        \n        for x_eval in eval_points:\n            # Find nodes within the support domain of x_eval\n            support_nodes_indices = []\n            distances = []\n            for i, node in enumerate(nodes):\n                dist = np.linalg.norm(x_eval - node)\n                if dist <= d:\n                    support_nodes_indices.append(i)\n                    distances.append(dist)\n\n            if not support_nodes_indices:\n                # Should not happen with the given parameters\n                # If it does, the approximation is zero, error is the field value\n                u_true = u_field_func(x_eval)\n                error = np.max(np.abs(u_true))\n                max_error = max(max_error, error)\n                continue\n\n            # Basis setup\n            if basis_degree == 0:\n                m = 1\n                get_p = lambda x: np.array([1.0])\n            elif basis_degree == 1:\n                m = 3\n                get_p = lambda x: np.array([1.0, x[0], x[1]])\n            else:\n                raise ValueError(\"Unsupported basis degree\")\n\n            if len(support_nodes_indices) < m:\n                # Insufficient nodes for a stable approximation\n                # This indicates a potential issue, e.g., in T5\n                u_true = u_field_func(x_eval)\n                # Approximation is ill-defined, cannot compute error robustly.\n                # A robust implementation might switch to a lower order basis.\n                # Here we assume the error is large or skip. Let's compute best effort.\n                u_h = np.zeros(2) # Fallback\n                error = np.max(np.abs(u_h - u_true))\n                max_error = max(max_error, error)\n                continue\n\n            # Construct Moment Matrix M(x)\n            M = np.zeros((m, m))\n            support_nodes = nodes[support_nodes_indices]\n            \n            w_vals = [weight_function(dist / d) for dist in distances]\n\n            for i in range(len(support_nodes)):\n                node = support_nodes[i]\n                p_i = get_p(node)\n                w_i = w_vals[i]\n                M += w_i * np.outer(p_i, p_i)\n\n            # Invert Moment Matrix\n            try:\n                M_inv = np.linalg.inv(M)\n            except np.linalg.LinAlgError:\n                # Singular matrix, approximation fails\n                u_true = u_field_func(x_eval)\n                u_h = np.zeros(2) # Fallback\n                error = np.max(np.abs(u_h - u_true))\n                max_error = max(max_error, error)\n                continue\n\n            # Calculate shape functions and approximated field u_h(x)\n            p_eval = get_p(x_eval)\n            u_h = np.zeros(2)\n            \n            for i in range(len(support_nodes)):\n                node_idx = support_nodes_indices[i]\n                node = support_nodes[i]\n                p_i = get_p(node)\n                w_i = w_vals[i]\n                \n                # Shape function value phi_i(x_eval)\n                phi_i = p_eval.T @ M_inv @ p_i * w_i\n                \n                u_h += phi_i * u_nodal[node_idx]\n\n            # Calculate error at the evaluation point\n            u_true = u_field_func(x_eval)\n            error = np.max(np.abs(u_h - u_true))\n            max_error = max(max_error, error)\n            \n        return max_error\n\n    # --- Test Cases Definition ---\n    eval_grid_coords = [0.1, 0.3, 0.5, 0.7, 0.9]\n    eval_set_T1_T4 = np.array(np.meshgrid(eval_grid_coords, eval_grid_coords)).T.reshape(-1, 2)\n    \n    # T1: Rigid Translation\n    c = np.array([0.3, -0.2])\n    u_trans = lambda x: c\n\n    # T2/T3: Rigid Rotation\n    theta = 0.1\n    u_rot = lambda x: theta * np.array([-x[1], x[0]])\n\n    # T4/T5: Uniform Strain\n    E = np.array([[0.01, 0.02], [0.00, -0.005]])\n    u_strain = lambda x: E @ x\n\n    test_cases = [\n        {'name': 'T1', 'basis_degree': 0, 'support_factor': 2.5, 'u_field_func': u_trans, 'eval_points': eval_set_T1_T4},\n        {'name': 'T2', 'basis_degree': 0, 'support_factor': 2.5, 'u_field_func': u_rot, 'eval_points': eval_set_T1_T4},\n        {'name': 'T3', 'basis_degree': 1, 'support_factor': 2.5, 'u_field_func': u_rot, 'eval_points': eval_set_T1_T4},\n        {'name': 'T4', 'basis_degree': 1, 'support_factor': 2.5, 'u_field_func': u_strain, 'eval_points': eval_set_T1_T4},\n        {'name': 'T5', 'basis_degree': 1, 'support_factor': 1.05, 'u_field_func': u_strain, 'eval_points': np.array([[0.02, 0.02]])},\n    ]\n\n    results = []\n    for case in test_cases:\n        error = compute_mls_error(nodes, case['basis_degree'], case['support_factor'], case['u_field_func'], case['eval_points'])\n        results.append(error)\n\n    # --- Final Output ---\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3581266"}, {"introduction": "Building on the foundational concepts of reproduction, this final practice explores the robustness of meshfree methods in geometrically complex scenarios. Real-world problems, particularly in fracture mechanics, often involve non-convex domains where standard MLS approximations can fail. This exercise [@problem_id:3581244] introduces the concept of visibility constraints to handle such cases and challenges you to develop diagnostic tools to pinpoint different failure modes, from insufficient nodal support to ill-conditioning caused by poor node distribution.", "problem": "Consider a two-dimensional L-shaped domain defined by the set of points $\\mathcal{D} = \\{(x,y) \\in \\mathbb{R}^2 \\mid -1 \\le x \\le 1, -1 \\le y \\le 1, x \\le 0 \\text{ or } y \\le 0\\}$, which has a reentrant corner at $(0,0)$. Nodes are placed on a uniform Cartesian grid with spacing $h$ over $[-1,1] \\times [-1,1]$ and restricted to $\\mathcal{D}$. For a given evaluation point $\\mathbf{x} \\in \\mathcal{D}$, define the Moving Least Squares (MLS) approximation with a linear polynomial basis $p(\\mathbf{X}) = [1, X, Y]^T$. Let the compactly supported weight function be $w(r) = (1 - r)^4(4r + 1)$ for $0 \\le r \\le 1$ and $w(r) = 0$ otherwise, where $r = \\|\\mathbf{x} - \\mathbf{X}_I\\|/R$ is the normalized distance with support radius $R$ and $\\mathbf{X}_I$ denotes the coordinates of node $I$. The MLS moment matrix is defined as\n$$\n\\mathbf{A}(\\mathbf{x}) = \\sum_{I} w_I(\\mathbf{x})\\, p(\\mathbf{X}_I)\\, p(\\mathbf{X}_I)^T,\n$$\nand the corresponding MLS shape functions are\n$$\n\\phi_I(\\mathbf{x}) = p(\\mathbf{x})^T \\mathbf{A}(\\mathbf{x})^{-1} w_I(\\mathbf{x}) p(\\mathbf{X}_I).\n$$\nWhen visibility constraints are enforced, a node $I$ is considered visible from $\\mathbf{x}$ if the straight line segment connecting $\\mathbf{x}$ and $\\mathbf{X}_I$ lies entirely within $\\mathcal{D}$; otherwise, set $w_I(\\mathbf{x}) = 0$ for that $I$. Assume that $p(\\mathbf{x}) = [1, x, y]^T$ with $(x,y)$ the coordinates of $\\mathbf{x}$.\n\nYour task is to implement a program that, for each provided test case, constructs the MLS shape functions $\\phi_I(\\mathbf{x})$ under the specified support and visibility conditions, and then evaluates:\n\n1. The partition of unity error\n$$\ne_{\\mathrm{PU}}(\\mathbf{x}) = \\left| \\sum_I \\phi_I(\\mathbf{x}) - 1 \\right|.\n$$\n\n2. The linear reproduction error\n$$\ne_{\\mathrm{LIN}}(\\mathbf{x}) = \\left\\| \\sum_I \\phi_I(\\mathbf{x})\\, \\mathbf{X}_I - \\mathbf{x} \\right\\|_2.\n$$\n\nUse the following diagnostic logic to classify failure modes:\n- Return a diagnostic integer $d$ defined by:\n  - $d = 0$ if both tests pass within the specified tolerance.\n  - $d = 1$ if there is insufficient support, defined as fewer than $3$ contributing nodes (with $w_I(\\mathbf{x}) > 0$ after applying visibility).\n  - $d = 2$ if the MLS moment matrix $\\mathbf{A}(\\mathbf{x})$ is singular or ill-conditioned (use a condition number threshold of $10^{12}$).\n  - $d = 3$ if tests fail despite sufficient support and a well-conditioned moment matrix, indicating a failure attributable to visibility constraints or geometric distribution.\n\nFor numerical tolerance, use $10^{-8}$ for both $e_{\\mathrm{PU}}$ and $e_{\\mathrm{LIN}}$. No physical units are involved; treat all quantities as dimensionless.\n\nImplement the following test suite, where each case is given as $(\\mathbf{x}, R, h, \\mathrm{visibility})$:\n- Test case 1: $\\mathbf{x} = (-0.5,-0.5)$, $R = 0.45$, $h = 0.2$, $\\mathrm{visibility} = \\text{False}$.\n- Test case 2: $\\mathbf{x} = (-0.05,-0.05)$, $R = 0.15$, $h = 0.2$, $\\mathrm{visibility} = \\text{False}$.\n- Test case 3: $\\mathbf{x} = (-0.05,-0.05)$, $R = 0.35$, $h = 0.2$, $\\mathrm{visibility} = \\text{True}$.\n- Test case 4: $\\mathbf{x} = (0.2,-0.2)$, $R = 0.3$, $h = 0.2$, $\\mathrm{visibility} = \\text{True}$.\n- Test case 5: $\\mathbf{x} = (-0.05,-0.05)$, $R = 0.25$, $h = 0.2$, $\\mathrm{visibility} = \\text{True}$.\n\nFor each test case, compute the boolean indicators\n$$\nb_{\\mathrm{PU}} = \\left( e_{\\mathrm{PU}} \\le 10^{-8} \\right), \\quad b_{\\mathrm{LIN}} = \\left( e_{\\mathrm{LIN}} \\le 10^{-8} \\right),\n$$\nand the diagnostic integer $d$ defined above.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is a list of the form $[b_{\\mathrm{PU}}, b_{\\mathrm{LIN}}, d]$. For example:\n$$\n[ [True, True, 0], [False, False, 1], \\ldots ].\n$$", "solution": "The problem poses a well-defined exercise in computational mechanics, specifically focusing on the properties of Moving Least Squares (MLS) shape functions in a non-convex domain. All provided definitions, including the L-shaped domain $\\mathcal{D}$, the polynomial basis $p(\\mathbf{X})$, the weight function $w(r)$, the moment matrix $\\mathbf{A}(\\mathbf{x})$, the shape functions $\\phi_I(\\mathbf{x})$, and the error metrics $e_{\\mathrm{PU}}$ and $e_{\\mathrm{LIN}}$, are standard within the theory of meshfree methods. The problem is scientifically grounded, objective, and contains all necessary information to proceed with a unique computational solution for each test case. The inclusion of diagnostic criteria for failure modes such as insufficient nodal support, matrix conditioning, and visibility effects makes the problem a comprehensive test of understanding MLS principles. The problem is therefore deemed **valid**.\n\nThe solution proceeds by implementing the MLS approximation scheme for each specified test case. The core steps are as follows:\n\n1.  **Nodal Discretization**: For a given grid spacing $h$, a uniform Cartesian grid of nodes is generated over the square domain $[-1, 1] \\times [-1, 1]$. These nodes are then filtered to retain only those that lie within the specified L-shaped domain $\\mathcal{D}$. A node at coordinates $(X_I, Y_I)$ is retained if it satisfies the condition $X_I \\le 0$ or $Y_I \\le 0$. A small numerical tolerance is used in practice to handle floating-point arithmetic precisely at the boundaries (e.g., $X_I \\le 10^{-9}$).\n\n2.  **Support Domain and Weight Calculation**: For a given evaluation point $\\mathbf{x}$ and a support radius $R$, we identify all nodes $\\mathbf{X}_I$ within the circular support domain, i.e., nodes for which the Euclidean distance $\\|\\mathbf{x} - \\mathbf{X}_I\\|$ is less than or equal to $R$. For each such node, the normalized distance $r_I = \\|\\mathbf{x} - \\mathbf{X}_I\\| / R$ is computed. The corresponding weight $w_I(\\mathbf{x})$ is then evaluated using the provided quartic spline function, $w(r_I) = (1 - r_I)^4(4r_I + 1)$.\n\n3.  **Visibility Constraint**: If the visibility constraint is active, an additional check is performed for each node $\\mathbf{X}_I$ within the support radius. A node is deemed \"not visible\" if the straight line segment connecting it to the evaluation point $\\mathbf{x}$ intersects the void region of the domain, which is the open first quadrant $\\{(u,v) \\in \\mathbb{R}^2 \\mid u > 0, v > 0\\}$. This geometric condition occurs if and only if one of the points ($\\mathbf{x}$ or $\\mathbf{X}_I$) lies in the open second quadrant ($\\{ u < 0, v > 0 \\}$) and the other lies in the open fourth quadrant ($\\{ u > 0, v < 0 \\}$). If a node is not visible, its weight is set to zero, $w_I(\\mathbf{x})=0$, effectively removing it from the approximation.\n\n4.  **Diagnostic Check for Sufficient Support**: The MLS approximation with a linear basis $p(\\mathbf{x}) = [1, x, y]^T$ requires a minimum of $3$ nodes to ensure the moment matrix can be non-singular. The number of contributing nodes (those with $w_I(\\mathbf{x}) > 0$ after applying distance and visibility criteria) is counted. If this number is less than $3$, the support is insufficient. The diagnostic code is set to $d=1$, and no further calculations for this case are performed.\n\n5.  **Moment Matrix Construction and Conditioning**: If support is sufficient, the $3 \\times 3$ moment matrix $\\mathbf{A}(\\mathbf{x})$ is assembled:\n    $$\n    \\mathbf{A}(\\mathbf{x}) = \\sum_{I} w_I(\\mathbf{x})\\, p(\\mathbf{X}_I)\\, p(\\mathbf{X}_I)^T\n    $$\n    where the sum is over all contributing nodes. The basis vector for a node $I$ is $p(\\mathbf{X}_I) = [1, X_I, Y_I]^T$. The condition number of $\\mathbf{A}(\\mathbf{x})$ is then computed. If it exceeds the threshold of $10^{12}$, the matrix is considered ill-conditioned, and the diagnostic code is set to $d=2$.\n\n6.  **Shape Function Evaluation and Property Verification**: If the moment matrix is well-conditioned, its inverse $\\mathbf{A}(\\mathbf{x})^{-1}$ is used to determine the shape functions. For computational efficiency, we first compute the vector $\\mathbf{b}(\\mathbf{x})^T = p(\\mathbf{x})^T \\mathbf{A}(\\mathbf{x})^{-1}$. The shape function for each contributing node $I$ is then $\\phi_I(\\mathbf{x}) = \\mathbf{b}(\\mathbf{x})^T w_I(\\mathbf{x}) p(\\mathbf{X}_I)$.\n    With the shape functions computed, we verify the partition of unity and linear reproduction properties:\n    - Partition of Unity (PU): We compute the sum $\\sum_I \\phi_I(\\mathbf{x})$ and its absolute deviation from $1$, which gives $e_{\\mathrm{PU}}$.\n    - Linear Reproduction (LIN): We compute the vector sum $\\sum_I \\phi_I(\\mathbf{x})\\, \\mathbf{X}_I$ and its Euclidean distance to the evaluation point $\\mathbf{x}$, which gives $e_{\\mathrm{LIN}}$.\n\n7.  **Final Diagnostics**: Based on the error calculations, the boolean indicators $b_{\\mathrm{PU}} = (e_{\\mathrm{PU}} \\le 10^{-8})$ and $b_{\\mathrm{LIN}} = (e_{\\mathrm{LIN}} \\le 10^{-8})$ are determined. The final diagnostic code $d$ is assigned:\n    - If $b_{\\mathrm{PU}}$ and $b_{\\mathrm{LIN}}$ are both true, $d=0$ (success).\n    - Otherwise (if either test fails despite sufficient support and a well-conditioned matrix), $d=3$ (reproduction failure).\n\nThis procedure is systematically applied to each test case to generate the required output.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Moving Least Squares problem for a set of test cases.\n    \"\"\"\n    test_cases = [\n        # (x_eval, R, h, visibility_flag)\n        ((-0.5, -0.5), 0.45, 0.2, False),\n        ((-0.05, -0.05), 0.15, 0.2, False),\n        ((-0.05, -0.05), 0.35, 0.2, True),\n        ((0.2, -0.2), 0.3, 0.2, True),\n        ((-0.05, -0.05), 0.25, 0.2, True),\n    ]\n\n    results = []\n    \n    TOL = 1e-8\n    COND_THRESH = 1e12\n\n    def weight_function(r):\n        if 0 <= r <= 1:\n            return (1 - r)**4 * (4 * r + 1)\n        return 0.0\n\n    def is_visible(p1, p2):\n        x1, y1 = p1\n        x2, y2 = p2\n        eps = 1e-9\n        \n        # Obstructed if one point is in the open 2nd quadrant and the other in the open 4th.\n        # Q2: x < 0, y > 0\n        # Q4: x > 0, y < 0\n        case1 = (x1 < -eps and y1 > eps) and (x2 > eps and y2 < -eps)\n        case2 = (x1 > eps and y1 < -eps) and (x2 < -eps and y2 > eps)\n        \n        return not (case1 or case2)\n\n    for x_eval, R, h, visibility_flag in test_cases:\n        # Step 1: Nodal Discretization\n        n_points = int(round(2.0 / h)) + 1\n        coords = np.linspace(-1.0, 1.0, n_points)\n        all_nodes = []\n        for x_node in coords:\n            for y_node in coords:\n                # Domain D: x <= 0 or y <= 0\n                if x_node <= TOL or y_node <= TOL:\n                    all_nodes.append(np.array([x_node, y_node]))\n        \n        x_eval = np.array(x_eval)\n        \n        # Step 2 & 3: Find contributing nodes (support + visibility)\n        contributing_nodes = []\n        for X_I in all_nodes:\n            dist = np.linalg.norm(x_eval - X_I)\n            if dist <= R:\n                if visibility_flag and not is_visible(x_eval, X_I):\n                    continue\n                \n                r = dist / R\n                w_I = weight_function(r)\n                if w_I > 0:\n                    contributing_nodes.append({'pos': X_I, 'w': w_I})\n                    \n        # Step 4: Diagnostic Check for Sufficient Support\n        if len(contributing_nodes) < 3:\n            results.append([False, False, 1])\n            continue\n\n        # Step 5: Moment Matrix Construction and Conditioning\n        A = np.zeros((3, 3))\n        for node in contributing_nodes:\n            p_I = np.array([1.0, node['pos'][0], node['pos'][1]])\n            A += node['w'] * np.outer(p_I, p_I)\n        \n        if np.linalg.cond(A) > COND_THRESH:\n            results.append([False, False, 2])\n            continue\n            \n        # Step 6: Shape Function and Property Verification\n        p_eval = np.array([1.0, x_eval[0], x_eval[1]])\n        try:\n            b = np.linalg.solve(A, p_eval)\n        except np.linalg.LinAlgError:\n            results.append([False, False, 2]) # Should be caught by cond, but as a safeguard\n            continue\n\n        phi_sum = 0.0\n        phi_X_sum = np.zeros(2)\n\n        for node in contributing_nodes:\n            p_I = np.array([1.0, node['pos'][0], node['pos'][1]])\n            phi_I = np.dot(b, p_I) * node['w']\n            phi_sum += phi_I\n            phi_X_sum += phi_I * node['pos']\n            \n        e_PU = abs(phi_sum - 1.0)\n        e_LIN = np.linalg.norm(phi_X_sum - x_eval)\n        \n        b_PU = e_PU <= TOL\n        b_LIN = e_LIN <= TOL\n\n        # Step 7: Final Diagnostics\n        if b_PU and b_LIN:\n            d = 0\n        else:\n            d = 3\n        \n        results.append([b_PU, b_LIN, d])\n\n    # Format the final output string\n    # E.g., [[True, True, 0], [False, False, 1]]\n    output_str = \"[\" + \",\".join(map(str, results)) + \"]\"\n    print(output_str.replace(\"'\", \"\")) # Remove quotes from strings for exact format\n\nsolve()\n```", "id": "3581244"}]}