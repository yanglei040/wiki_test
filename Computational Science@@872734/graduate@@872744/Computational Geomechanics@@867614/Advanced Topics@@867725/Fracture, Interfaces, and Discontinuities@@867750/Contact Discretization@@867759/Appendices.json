{"hands_on_practices": [{"introduction": "Before any physical laws can be applied, a contact algorithm must first solve a purely geometric problem: identifying which parts of opposing bodies are interacting. This \"contact search\" is the backbone of any node-to-segment (NTS) formulation, and its robustness is critical for the convergence and stability of the entire simulation. This exercise challenges you to implement the detailed decision logic for a 2D contact search, paying close attention to the deterministic resolution of ambiguous cases near corners, which are a common source of error in naive implementations [@problem_id:3509961]. Mastering this geometric foundation is an essential first step toward building a reliable contact model.", "problem": "You are given a two-dimensional polyline interface defined by an ordered list of vertices and the corresponding straight segments between consecutive vertices. In computational geomechanics contact detection using node-to-segment discretization, a node is mapped to exactly one segment of the polyline by orthogonal projection. Your task is to implement a robust and deterministic decision logic that, for any node position, selects the segment onto which the projection is taken, and resolves ties consistently at corners.\n\nStart from fundamental geometric definitions. Let the polyline vertices be $v_0,\\dots,v_m \\in \\mathbb{R}^2$, where segment $S_i$ connects $v_i$ to $v_{i+1}$ for $i \\in \\{0,\\dots,m-1\\}$. For a node $x \\in \\mathbb{R}^2$ and a segment $S_i$, denote the segment vector by $e_i = v_{i+1} - v_i$, the tangent unit vector by $t_i = e_i / \\|e_i\\|$, and the left-hand unit normal by $n_i = R(t_i)$, where $R$ rotates a vector by $+90^\\circ$ in the plane so that $R[(a,b)] = (-b,a)$. For the infinite line supporting $S_i$, the orthogonal projection of $x$ onto that line can be written as $p_i = v_i + \\tau_i e_i$, where the projection parameter is $\\tau_i = \\frac{(x - v_i) \\cdot e_i}{\\|e_i\\|^2}$, and the Euclidean distance from $x$ to the line is $d_i = \\|x - p_i\\|$. The closest point from $x$ to the segment $S_i$ lies at $p_i$ if $\\tau_i \\in [0,1]$, otherwise it lies at the nearest endpoint.\n\nImplement the following segment selection logic, using these fundamental definitions and a numerical tolerance $\\varepsilon = 10^{-12}$ to compare real numbers:\n\n1. Interior projection preference: Among all segments for which $\\tau_i \\in (0,1)$, select the segment that minimizes $d_i$. If there is a tie within the tolerance, break the tie by selecting the segment that maximizes the facing measure $s_i = n_i \\cdot r_i$, where $r_i = \\frac{x - p_i}{\\|x - p_i\\|}$ if $\\|x - p_i\\| > \\varepsilon$ and $r_i = (0,0)$ otherwise. If there is still a tie, select the segment that maximizes $t_i \\cdot r_i$, and if a tie remains, select the smallest segment index.\n\n2. Corner tie resolution when no interior projection exists: If no $\\tau_i \\in (0,1)$, determine the nearest vertex $v_k$ to $x$. Let $\\mathcal{A}(k)$ be the set of adjacent segments that share $v_k$. If $|\\mathcal{A}(k)| = 1$, select that single adjacent segment. If $|\\mathcal{A}(k)| = 2$, let $u_j$ be the unit tangent of segment $S_j$ oriented away from $v_k$ along the segment interior, i.e., $u_j = \\frac{v_{\\text{other}} - v_k}{\\|v_{\\text{other}} - v_k\\|}$ where $v_{\\text{other}}$ is the endpoint of $S_j$ not equal to $v_k$, and define $n_j = R(u_j)$. Let $r = \\frac{x - v_k}{\\|x - v_k\\|}$ if $\\|x - v_k\\| > \\varepsilon$ and $r = (0,0)$ otherwise. Choose the segment that maximizes $s_j = n_j \\cdot r$. If there is a tie within the tolerance, choose the segment that maximizes $u_j \\cdot r$. If the node lies exactly at the vertex, i.e., $\\|x - v_k\\| \\le \\varepsilon$, select the smallest index among the adjacent segments to ensure determinism.\n\n3. Fallback: If neither interior projections nor corner adjacency logic applies (which should not happen for valid polylines and nodes), select the segment that minimizes $d_i$ and break ties as in step $1$.\n\nUse the following fixed polyline and test suite. The polyline has $m = 4$ segments and vertices\n$v_0 = (0,0)$, $v_1 = (2,0)$, $v_2 = (2,1)$, $v_3 = (2,3)$, $v_4 = (0,3)$.\nThe ordered segments are $S_0 = [v_0,v_1]$, $S_1 = [v_1,v_2]$, $S_2 = [v_2,v_3]$, $S_3 = [v_3,v_4]$.\n\nEvaluate the segment selection for the following nodes (each node is given as $(x_1,x_2)$ in $\\mathbb{R}^2$):\n- Test $1$: $(1.0,-0.2)$.\n- Test $2$: $(2.0,-0.5)$.\n- Test $3$: $(3.0,3.4)$.\n- Test $4$: $(2.0,1.0)$.\n- Test $5$: $(1.0,3.1)$.\n- Test $6$: $(-0.2,0.1)$.\n- Test $7$: $(1.5,0.5)$.\n\nYour program should compute, for each test node, the selected segment index $i \\in \\{0,1,2,3\\}$ using the logic above, and produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3]\"). All calculations are purely geometric; no physical units are required, and angles are handled implicitly through vector dot products in radians-free form.", "solution": "The user has provided a problem that is **valid** based on the specified criteria. It is scientifically grounded in Euclidean geometry, well-posed with a deterministic set of rules ensuring a unique solution, and formally complete. The problem asks for the implementation of a specific hierarchical algorithm for node-to-segment mapping, a task relevant to computational mechanics.\n\nThe solution requires a direct and meticulous implementation of the prescribed geometric logic. The core of the problem is to develop a function that, given the coordinates of a node $x \\in \\mathbb{R}^2$ and a polyline defined by an ordered set of vertices $\\{v_0, v_1, \\dots, v_m\\}$, selects a single segment $S_i = [v_i, v_{i+1}]$ according to a three-tiered decision process.\n\nFirst, for each segment $S_i$ of the polyline, we must compute a set of geometric quantities relative to the node $x$. These quantities are derived from fundamental vector algebra. The segment is defined by its start and end vertices, $v_i$ and $v_{i+1}$. The segment vector is $e_i = v_{i+1} - v_i$. The squared length of the segment is $\\|e_i\\|^2 = e_i \\cdot e_i$. A key parameter is the normalized projection parameter $\\tau_i$, which determines the position of the orthogonal projection of $x$ onto the infinite line containing $S_i$. It is calculated as:\n$$\n\\tau_i = \\frac{(x - v_i) \\cdot e_i}{\\|e_i\\|^2}\n$$\nThis parameter $\\tau_i$ indicates that the projection point $p_i = v_i + \\tau_i e_i$ lies on the segment $S_i$ if and only if $\\tau_i \\in [0,1]$.\nThe orthogonal distance from the node $x$ to the line is $d_i = \\|x - p_i\\|$.\nThe other required quantities for tie-breaking are the tangent unit vector $t_i = e_i / \\|e_i\\|$, the left-hand normal unit vector $n_i = R(t_i)$ where $R[(a,b)] = (-b,a)$, and a normalized direction vector $r_i$ from the projection point to the node, defined as $r_i = (x-p_i)/d_i$ if $d_i > \\varepsilon$ and $r_i=(0,0)$ otherwise, where $\\varepsilon=10^{-12}$ is the specified numerical tolerance. These vectors are used to compute the tie-breaking measures $s_i = n_i \\cdot r_i$ and $t_i \\cdot r_i$.\n\nThe implemented algorithm follows the prescribed hierarchical logic:\n\n1.  **Interior Projection Preference:** The primary selection criterion is based on identifying segments for which the node's orthogonal projection falls strictly within the segment's interior. This corresponds to the condition $\\tau_i \\in (0,1)$. To handle floating-point arithmetic, this condition is implemented as $\\tau_i > \\varepsilon$ and $1 - \\tau_i > \\varepsilon$. If one or more segments satisfy this condition, a unique segment is chosen from this candidate set by a lexicographical comparison. The candidates are ordered first by minimizing the orthogonal distance $d_i$, then by maximizing the \"facing measure\" $s_i$, then by maximizing the tangential alignment measure $t_i \\cdot r_i$, and finally, by the smallest segment index $i$. This multi-level sorting ensures a deterministic outcome. A computationally efficient way to implement this is through a multi-key stable sort or, equivalently, a single pass sort using a tuple of keys `(d_i, -s_i, -t_i \\cdot r_i, i)`.\n\n2.  **Corner Tie Resolution:** If no segment has an interior projection (i.e., the candidate set from the first step is empty), the logic proceeds to the corner resolution rule. This rule assumes the node is geometrically closest to one of the polyline's vertices. The first step is to identify the nearest vertex $v_k$ to the node $x$ by minimizing the Euclidean distance $\\|x - v_j\\|$ over all vertices $v_j$.\n    The segments adjacent to $v_k$ are then considered. The polyline structure dictates that an endpoint vertex (like $v_0$ or $v_m$) has one adjacent segment, while an interior vertex $v_k$ (for $0 < k < m$) has two ($S_{k-1}$ and $S_k$).\n    - If only one segment is adjacent to $v_k$, it is unequivocally selected.\n    - If two segments are adjacent, a tie-breaking procedure is required. A special case is when the node $x$ is located exactly at the vertex $v_k$ (i.e., $\\|x-v_k\\| \\le \\varepsilon$). In this situation, determinism is achieved by selecting the adjacent segment with the smaller index.\n    - If the node is near, but not at, the vertex, the choice is based on which segment \"faces\" the node more directly. For each adjacent segment $S_j$, a unit tangent vector $u_j$ is defined pointing away from the corner $v_k$ into the segment's interior. The associated normal is $n_j=R(u_j)$. A relative position vector $r = (x-v_k)/\\|x-v_k\\|$ is computed. The segment that maximizes the dot product $s_j = n_j \\cdot r$ is chosen. If this results in a tie (i.e., the values are within $\\varepsilon$ of each other), a secondary tie-breaker is used: the segment that maximizes the dot product $u_j \\cdot r$ is selected. A final tie-breaker on the segment index is implemented for robustness, though ties at this level are geometrically unlikely for distinct segments.\n\n3.  **Fallback Mechanism:** The problem statement suggests that the first two rules should be sufficient to resolve any case for a valid polyline and node. However, for programmatic completeness, a fallback is included. Should the corner resolution logic fail to yield a selection, the algorithm reverts to a global search across all segments, applying the same selection criteria as in the first rule (minimize $d_i$, etc.) to all segments, not just those with interior projections. This ensures that a segment is always selected.\n\nThe final implementation encapsulates this logic in a Python function. It uses the `numpy` library for efficient and clean vector operations. The function processes each test node, computes the required geometric data for all four segments, and applies the ordered rules to determine the index of the selected segment. The results for all test cases are then aggregated and formatted into the required output string.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the node-to-segment mapping problem.\n    It defines the polyline and test nodes, then computes the selected\n    segment for each node using the specified hierarchical logic.\n    \"\"\"\n    \n    # Define the polyline vertices and test cases from the problem statement.\n    vertices = np.array([\n        [0.0, 0.0],  # v0\n        [2.0, 0.0],  # v1\n        [2.0, 1.0],  # v2\n        [2.0, 3.0],  # v3\n        [0.0, 3.0],  # v4\n    ])\n    \n    # Segments are defined by indices of the vertices array\n    segments = [(0, 1), (1, 2), (2, 3), (3, 4)]\n    \n    test_nodes = [\n        (1.0, -0.2),\n        (2.0, -0.5),\n        (3.0, 3.4),\n        (2.0, 1.0),\n        (1.0, 3.1),\n        (-0.2, 0.1),\n        (1.5, 0.5),\n    ]\n\n    epsilon = 1e-12\n\n    def rotate_90(v):\n        \"\"\"Rotates a 2D vector by +90 degrees.\"\"\"\n        return np.array([-v[1], v[0]])\n\n    def select_segment(node, vertices, segments, epsilon):\n        \"\"\"\n        Implements the specified hierarchical logic to select a segment for a given node.\n        \"\"\"\n        \n        # 1. Pre-computation for all segments\n        segment_data = []\n        for i, (v_start_idx, v_end_idx) in enumerate(segments):\n            v_i = vertices[v_start_idx]\n            v_i_plus_1 = vertices[v_end_idx]\n            \n            e_i = v_i_plus_1 - v_i\n            e_len_sq = np.dot(e_i, e_i)\n            \n            if e_len_sq < epsilon**2: # Segment has zero length\n                tau_i = 0.0\n                p_i = v_i\n                t_i = np.array([0.0, 0.0])\n            else:\n                tau_i = np.dot(node - v_i, e_i) / e_len_sq\n                p_i = v_i + tau_i * e_i\n                t_i = e_i / np.sqrt(e_len_sq)\n\n            n_i = rotate_90(t_i)\n            x_minus_pi = node - p_i\n            d_i = np.linalg.norm(x_minus_pi)\n            \n            if d_i > epsilon:\n                r_i = x_minus_pi / d_i\n            else:\n                r_i = np.array([0.0, 0.0])\n                \n            s_i = np.dot(n_i, r_i)\n            t_dot_r_i = np.dot(t_i, r_i)\n            \n            segment_data.append({\n                'index': i, 'tau': tau_i, 'd': d_i, 's': s_i, 't_dot_r': t_dot_r_i,\n            })\n\n        # 2. Rule 1: Interior projection preference\n        interior_candidates = [\n            d for d in segment_data \n            if (d['tau'] > epsilon) and (1.0 - d['tau'] > epsilon)\n        ]\n        \n        if interior_candidates:\n            # Sort by d_i (asc), s_i (desc), t_dot_r_i (desc), index (asc)\n            # Python's sort is stable, so we can sort by keys in reverse order of precedence.\n            interior_candidates.sort(key=lambda d: d['index'])\n            interior_candidates.sort(key=lambda d: d['t_dot_r'], reverse=True)\n            interior_candidates.sort(key=lambda d: d['s'], reverse=True)\n            interior_candidates.sort(key=lambda d: d['d'])\n            return interior_candidates[0]['index']\n\n        # 3. Rule 2: Corner tie resolution\n        dists_to_vertices = [np.linalg.norm(node - v) for v in vertices]\n        k = np.argmin(dists_to_vertices)\n        \n        adj_indices = []\n        if k > 0:\n            adj_indices.append(k - 1)\n        if k < len(vertices) - 1:\n            adj_indices.append(k)\n        \n        if not adj_indices:\n             # Fallback, should not happen for this problem\n             pass\n        elif len(adj_indices) == 1:\n            return adj_indices[0]\n        else: # len == 2\n            v_k = vertices[k]\n            if np.linalg.norm(node - v_k) <= epsilon:\n                return min(adj_indices)\n            else:\n                r = (node - v_k) / np.linalg.norm(node - v_k)\n                corner_candidates = []\n                for seg_idx in adj_indices:\n                    v_start_idx, v_end_idx = segments[seg_idx]\n                    \n                    if v_start_idx == k:\n                        v_other = vertices[v_end_idx]\n                        u_vec = v_other - v_k\n                    else:\n                        v_other = vertices[v_start_idx]\n                        u_vec = v_other - v_k\n                    \n                    u_j = u_vec / np.linalg.norm(u_vec)\n                    n_j = rotate_90(u_j)\n                    \n                    s_j = np.dot(n_j, r)\n                    u_dot_r = np.dot(u_j, r)\n                    \n                    corner_candidates.append({\n                        'index': seg_idx, 's': s_j, 'u_dot_r': u_dot_r\n                    })\n\n                # Perform comparison with tolerance\n                cand1, cand2 = corner_candidates[0], corner_candidates[1]\n                \n                s_diff = cand1['s'] - cand2['s']\n                if s_diff > epsilon:\n                    return cand1['index']\n                if -s_diff > epsilon:\n                    return cand2['index']\n                \n                # Tie in s_j, check u_dot_r\n                u_dot_r_diff = cand1['u_dot_r'] - cand2['u_dot_r']\n                if u_dot_r_diff > epsilon:\n                    return cand1['index']\n                if -u_dot_r_diff > epsilon:\n                    return cand2['index']\n\n                # Final tie-break with index\n                return min(cand1['index'], cand2['index'])\n\n        # 4. Fallback: should not be reached but included for robustness\n        segment_data.sort(key=lambda d: d['index'])\n        segment_data.sort(key=lambda d: d['t_dot_r'], reverse=True)\n        segment_data.sort(key=lambda d: d['s'], reverse=True)\n        segment_data.sort(key=lambda d: d['d'])\n        return segment_data[0]['index']\n\n    results = []\n    for node_coords in test_nodes:\n        node_np = np.array(node_coords, dtype=float)\n        selected_index = select_segment(node_np, vertices, segments, epsilon)\n        results.append(selected_index)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3509961"}, {"introduction": "Once a contact pair—such as a slave node and a master segment—has been identified, the next step is to quantify their mechanical interaction. In the Finite Element Method (FEM), this is achieved by deriving the pair's contribution to the global residual vector, which represents the system's out-of-balance forces. This practice guides you through the fundamental derivation of this contact residual using the widely-used penalty method [@problem_id:3510014]. By starting from the principle of virtual work and a defined gap function $g_{n}$, you will see precisely how continuum mechanical principles are translated into the discrete algebraic equations that a computer solves.", "problem": "Consider a frictionless unilateral contact interaction in two-dimensional small-strain kinematics between a single slave node and a straight two-node master segment in the context of computational geomechanics. The master segment has end nodes labeled $m_{1}$ and $m_{2}$ with reference positions $\\boldsymbol{X}_{m_{1}}$ and $\\boldsymbol{X}_{m_{2}}$, and current displacements $\\boldsymbol{u}_{m_{1}}$ and $\\boldsymbol{u}_{m_{2}}$. The slave node $s$ has reference position $\\boldsymbol{X}_{s}$ and current displacement $\\boldsymbol{u}_{s}$. Let the master segment be parameterized by a local coordinate $\\xi \\in [-1,1]$ with standard linear shape functions $N_{1}(\\xi) = \\frac{1-\\xi}{2}$ and $N_{2}(\\xi) = \\frac{1+\\xi}{2}$. Assume the outward unit normal of the master segment at the closest projection point is the constant vector $\\boldsymbol{n} = (n_{x}, n_{y})^{\\mathsf{T}}$, and that the closest-point projection coordinate $\\xi$ lies strictly in the open interval $(-1,1)$ and is held fixed during the current residual evaluation.\n\nStarting from the principle of virtual work and the definition of a quadratic penalty potential for the normal contact gap, derive the discrete residual contribution associated with this single slave-to-segment contact pair. Use the normal gap defined by the kinematics\n$$\ng_{n} = \\boldsymbol{n}^{\\mathsf{T}}\\left[\\left(\\boldsymbol{X}_{s} + \\boldsymbol{u}_{s}\\right) - \\sum_{a=1}^{2} N_{a}(\\xi)\\left(\\boldsymbol{X}_{m_{a}} + \\boldsymbol{u}_{m_{a}}\\right)\\right],\n$$\nand a scalar penalty stiffness $k_{p} > 0$. Neglect the dependence of $\\xi$ and $\\boldsymbol{n}$ on the nodal degrees of freedom for this residual construction.\n\n- Identify clearly the nodal degrees of freedom that receive nonzero contributions from this contact pair, and adopt the degree-of-freedom ordering\n$$\n\\left[u_{s,x},\\, u_{s,y},\\, u_{m_{1},x},\\, u_{m_{1},y},\\, u_{m_{2},x},\\, u_{m_{2},y}\\right]^{\\mathsf{T}}.\n$$\n- Express your final result as a single vector-valued analytical expression for the discrete residual contribution $\\boldsymbol{R}_{c}$ in terms of $k_{p}$, $g_{n}$, $n_{x}$, $n_{y}$, $N_{1}(\\xi)$, and $N_{2}(\\xi)$, together with the above ordering. You may leave $g_{n}$ in symbolic form or substitute its explicit dependence on the reference positions and displacements.\n\nYour final answer must be a single closed-form analytical expression. Do not include units. No numerical rounding is required.", "solution": "The derivation begins from the principle of virtual work for contact in a penalty formulation. For a frictionless unilateral contact penalty, one introduces a penalty potential that penalizes interpenetration ($g_n < 0$). A standard quadratic penalty potential at the slave node is\n$$\n\\Pi_{c} = \\frac{1}{2}\\,k_{p}\\,(\\min(0, g_{n}))^{2},\n$$\nwith $k_{p} > 0$ the penalty stiffness. The corresponding virtual work of contact is the first variation of this potential,\n$$\n\\delta \\Pi_{c} = k_{p}\\,\\min(0, g_{n})\\,\\delta g_{n}.\n$$\nIn the small-strain, small-displacement setting with a fixed closest-point parameter $\\xi$ and fixed unit normal $\\boldsymbol{n}$, the variation of the gap, $\\delta g_n$, follows by linearity from its kinematic definition:\n$$\n\\delta g_{n} = \\boldsymbol{n}^{\\mathsf{T}}\\left[\\delta \\boldsymbol{u}_{s} - \\sum_{a=1}^{2} N_{a}(\\xi)\\,\\delta \\boldsymbol{u}_{m_{a}}\\right]\n= \\boldsymbol{n}^{\\mathsf{T}}\\delta \\boldsymbol{u}_{s} - N_{1}(\\xi)\\,\\boldsymbol{n}^{\\mathsf{T}}\\delta \\boldsymbol{u}_{m_{1}} - N_{2}(\\xi)\\,\\boldsymbol{n}^{\\mathsf{T}}\\delta \\boldsymbol{u}_{m_{2}}.\n$$\nThe contact residual contribution $\\boldsymbol{R}_c$ is defined through the relation $\\delta \\Pi_c = \\delta\\mathbf{u}^T \\boldsymbol{R}_c$. By substituting the expression for $\\delta g_n$ into the virtual work and identifying the terms that multiply the virtual displacements, we can construct the residual vector.\nThe scalar term $k_p \\min(0, g_n)$ represents the penalty force magnitude, which is non-zero only for penetration. This force is distributed to the nodes:\n- The slave node receives a contribution $k_{p} \\min(0, g_{n})\\,\\boldsymbol{n}$.\n- The master node $m_{1}$ receives a contribution $-k_{p} \\min(0, g_{n}) N_{1}(\\xi)\\,\\boldsymbol{n}$.\n- The master node $m_{2}$ receives a contribution $-k_{p} \\min(0, g_{n}) N_{2}(\\xi)\\,\\boldsymbol{n}$.\nCollecting these into the prescribed degree-of-freedom ordering $[u_{s,x},\\, u_{s,y},\\, u_{m_{1},x},\\, u_{m_{1},y},\\, u_{m_{2},x},\\, u_{m_{2},y}]^{\\mathsf{T}}$ yields the final expression. The degrees of freedom involved are precisely the translational components of the slave node and the two master segment end nodes.", "answer": "$$\\boxed{k_{p}\\,\\min(0, g_{n})\\,\\begin{bmatrix}\nn_{x} \\\\\nn_{y} \\\\\n-\\,N_{1}(\\xi)\\,n_{x} \\\\\n-\\,N_{1}(\\xi)\\,n_{y} \\\\\n-\\,N_{2}(\\xi)\\,n_{x} \\\\\n-\\,N_{2}(\\xi)\\,n_{y}\n\\end{bmatrix}}$$", "id": "3510014"}, {"introduction": "A working algorithm is not necessarily a correct one. In computational mechanics, we use verification benchmarks called \"patch tests\" to ensure a numerical method can accurately reproduce fundamental physical states. This practice explores the vital constant-pressure patch test, which reveals critical differences between various contact discretization schemes [@problem_id:3509997]. By comparing the performance of a simple Node-to-Segment (NTS) approach with a more sophisticated Segment-to-Segment (STS) mortar method, you will gain insight into why certain formulations are prone to spurious oscillations while others provide stable, accurate results, a behavior governed by the crucial Ladyzhenskaya–Babuška–Brezzi (LBB) stability condition.", "problem": "Consider a frictionless unilateral contact patch test in two-dimensional small-strain linear elasticity between two identical rectangular elastic continua, labeled body $1$ and body $2$, occupying domains $\\Omega^{(1)}$ and $\\Omega^{(2)}$ with a perfectly flat interface $\\Gamma_{c}$ of length $L$ aligned with the horizontal axis. Let $\\Gamma_{c}$ be the bottom boundary of $\\Omega^{(1)}$ and the top boundary of $\\Omega^{(2)}$. The outward unit normal on $\\Gamma_{c}$ for $\\Omega^{(1)}$ is $\\mathbf{n}$, and for $\\Omega^{(2)}$ is $-\\mathbf{n}$. Both bodies have the same elastic moduli, Young’s modulus $E$ and Poisson’s ratio $\\nu$, and equal thickness in plane strain. The non-contact boundaries are loaded by uniform compressive tractions of magnitude $p_{0}>0$ such that the exact solution, if contact is enforced without interpenetration, yields a constant contact pressure $p(\\mathbf{x})=p_{0}$ on $\\Gamma_{c}$, zero normal gap $g_{n}(\\mathbf{x})=0$, and zero tangential traction on $\\Gamma_{c}$.\n\nThe governing weak form couples the standard linear momentum balance with the contact constraints. For displacement fields $\\mathbf{u}^{(1)}$ and $\\mathbf{u}^{(2)}$ and test functions $\\mathbf{w}^{(1)}$ and $\\mathbf{w}^{(2)}$, the elastic part on each body is\n$$\n\\int_{\\Omega^{(k)}} \\boldsymbol{\\sigma}(\\mathbf{u}^{(k)}):\\boldsymbol{\\varepsilon}(\\mathbf{w}^{(k)})\\,\\mathrm{d}\\Omega = \\int_{\\Omega^{(k)}} \\mathbf{b}^{(k)}\\cdot \\mathbf{w}^{(k)}\\,\\mathrm{d}\\Omega + \\int_{\\Gamma_{N}^{(k)}} \\bar{\\mathbf{t}}^{(k)}\\cdot \\mathbf{w}^{(k)}\\,\\mathrm{d}\\Gamma, \\quad k\\in\\{1,2\\},\n$$\nwith $\\boldsymbol{\\sigma}(\\mathbf{u}) = \\lambda\\,\\mathrm{tr}(\\boldsymbol{\\varepsilon}(\\mathbf{u}))\\,\\mathbf{I} + 2\\mu\\,\\boldsymbol{\\varepsilon}(\\mathbf{u})$ and Lamé parameters $\\lambda,\\mu$ related to $E,\\nu$. On $\\Gamma_{c}$, the frictionless unilateral contact conditions are expressed in terms of the normal gap $g_{n}(\\mathbf{x})$ and the normal contact pressure $p(\\mathbf{x})$ as $p(\\mathbf{x})\\ge 0$, $g_{n}(\\mathbf{x})\\ge 0$, and $p(\\mathbf{x})\\,g_{n}(\\mathbf{x})=0$, with the weak contact contribution\n$$\n-\\int_{\\Gamma_{c}} p(\\mathbf{x})\\,\\mathbf{n}\\cdot \\left(\\mathbf{w}^{(1)} - \\mathbf{w}^{(2)}\\right)\\,\\mathrm{d}\\Gamma.\n$$\n\nA Finite Element Method (FEM) discretization is constructed with identical meshes for $\\Omega^{(1)}$ and $\\Omega^{(2)}$, each having a straight interface mesh composed of $m$ equal-length line segments on $\\Gamma_{c}$ with nodes $\\{\\mathbf{x}_{a}\\}_{a=1}^{m+1}$; the displacement field is interpolated by standard interface trace shape functions $\\{N_{a}(\\xi)\\}$ on the slave side, where $\\xi$ is the local interface coordinate.\n\nTwo alternative contact discretizations are considered:\n\n- Node-to-segment (N2S): The normal gap is evaluated at the slave nodes, and the normal contact pressure is discretized by nodal Lagrange multipliers $\\{\\lambda_{a}\\}$ collocated at the same slave nodes, using the same interpolation order as the displacement trace. The discrete contact bilinear form reduces to a nodal sum consistent with mass-lumped quadrature on $\\Gamma_{c}$.\n\n- Segment-to-segment (S2S): A mortar-type formulation with a Lagrange multiplier field $p_{h}(\\xi)$ interpolated by dual (biorthogonal) interface shape functions $\\{\\widehat{M}_{a}(\\xi)\\}$ defined on the slave mesh, satisfying the biorthogonality condition\n$$\n\\int_{\\Gamma_{c}} \\widehat{M}_{a}(\\xi)\\,N_{b}(\\xi)\\,\\mathrm{d}\\Gamma = \\delta_{ab}\\,w_{a},\n$$\nfor all $a,b$, where $w_{a}>0$ are scalar weights and $\\delta_{ab}$ is the Kronecker delta. The contact coupling then involves segment-wise integration, distributing reactions over segments rather than concentrating them at nodes.\n\nThe patch test requires that under the uniform external compression, the discrete model reproduces the exact interface solution $p(\\mathbf{x})\\equiv p_{0}$, $g_{n}(\\mathbf{x})\\equiv 0$ without spurious oscillations in the computed contact pressure. The following statements are proposed about this patch test:\n\nA. In S2S with biorthogonal dual shape functions for the multiplier field, the discrete contact operator reproduces a constant pressure $p_{h}(\\xi)\\equiv p_{0}$ exactly on $\\Gamma_{c}$, and the segment reactions are equal to $p_{0}$ times the segment length; thus the patch test is passed.\n\nB. In N2S with equal-order nodal Lagrange multipliers collocated at slave nodes, the discrete system satisfies a stable discrete Ladyzhenskaya–Babuška–Brezzi (LBB) condition, guaranteeing a uniform multiplier field and no oscillations; thus the patch test is passed.\n\nC. In N2S with penalty enforcement of the normal gap at slave nodes, the interface reaction field is concentrated at nodes, producing spurious oscillations in the reconstructed contact pressure even with identical meshes, unless a consistent projection or smoothing is introduced; thus the patch test is not passed in its strict sense.\n\nD. S2S mortar formulations only pass the constant-pressure patch test when slave and master meshes are identical and node-aligned; if the meshes are non-matching, constant pressure cannot be reproduced.\n\nWhich of the above statements are correct?", "solution": "The problem statement describes a classical patch test for contact discretizations in computational mechanics. The test verifies whether a numerical method can exactly reproduce a state of constant contact pressure on a flat interface, which is a fundamental consistency requirement. The problem is well-posed and scientifically sound, allowing for a rigorous analysis of the proposed numerical schemes.\n\nThe analysis hinges on the properties of the discrete function spaces used for the displacement field and the Lagrange multiplier (contact pressure) field. A stable and accurate contact formulation requires that the chosen spaces satisfy the discrete inf-sup or Ladyzhenskaya–Babuška–Brezzi (LBB) condition. Formulations that fail this condition are prone to spurious oscillations in the computed pressure field, while those that satisfy it can provide stable and convergent solutions.\n\nLet $\\mathcal{V}_h$ be the discrete space for the trace of the displacement field on the contact boundary $\\Gamma_c$, and let $\\mathcal{M}_h$ be the discrete space for the Lagrange multiplier (pressure) field. For linear elements, the displacement trace is piecewise linear and continuous, so $u_h|_ {\\Gamma_c} \\in \\mathcal{V}_h = \\{v \\in C^0(\\Gamma_c) \\mid v|_e \\in P_1(e) \\}$, where $P_1(e)$ is the space of linear polynomials on an element $e$.\n\nLet's analyze the two proposed discretization schemes.\n\n**1. Segment-to-Segment (S2S) Mortar Formulation**\nThis method employs a Lagrange multiplier space $\\mathcal{M}_h$ spanned by dual or biorthogonal basis functions $\\{\\widehat{M}_a(\\xi)\\}$. These are defined with respect to the displacement trace basis functions $\\{N_b(\\xi)\\}$ (which are standard tent-like $P_1$ shape functions) by the condition:\n$$ \\int_{\\Gamma_{c}} \\widehat{M}_{a}(\\xi)\\,N_{b}(\\xi)\\,\\mathrm{d}\\Gamma = \\delta_{ab}\\,w_{a} $$\nwhere $\\delta_{ab}$ is the Kronecker delta and $w_a > 0$ are weights. This construction is specifically designed to satisfy the LBB condition.\n\nTo pass the patch test, the method must be able to exactly represent the constant pressure solution, $p(\\mathbf{x}) = p_0$. This means that there must exist a discrete pressure field $p_h(\\xi) \\in \\mathcal{M}_h$ such that $p_h(\\xi) = p_0$. We can write $p_h(\\xi) = \\sum_a \\lambda_a \\widehat{M}_a(\\xi)$, where $\\lambda_a$ are the unknown multiplier coefficients. For this to be equal to $p_0$, the following must hold:\n$$ \\sum_a \\lambda_a \\widehat{M}_a(\\xi) = p_0 $$\nTo find the coefficients $\\lambda_a$, we can project this equation onto the displacement basis functions $\\{N_b(\\xi)\\}$:\n$$ \\int_{\\Gamma_c} \\left( \\sum_a \\lambda_a \\widehat{M}_a(\\xi) \\right) N_b(\\xi) \\, \\mathrm{d}\\Gamma = \\int_{\\Gamma_c} p_0 N_b(\\xi) \\, \\mathrm{d}\\Gamma $$\nUsing the biorthogonality property, the left side simplifies:\n$$ \\sum_a \\lambda_a (\\delta_{ab} w_a) = \\lambda_b w_b $$\nThus, the required coefficients are:\n$$ \\lambda_b = \\frac{p_0}{w_b} \\int_{\\Gamma_c} N_b(\\xi) \\, \\mathrm{d}\\Gamma $$\nSince this equation yields a unique set of coefficients $\\{\\lambda_b\\}$, the constant pressure state is exactly representable in the multiplier space $\\mathcal{M}_h$. The resulting discrete nodal forces are $F_{c,b} = \\lambda_b w_b = p_0 \\int_{\\Gamma_c} N_b(\\xi) \\, \\mathrm{d}\\Gamma$, which are precisely the consistent nodal forces corresponding to a uniform pressure $p_0$. Because the exact solution is contained within the finite element approximation spaces for both displacement and pressure, the Galerkin procedure will recover it exactly. Hence, the S2S mortar method with a dual basis passes the patch test.\n\n**2. Node-to-Segment (N2S) with Collocated Lagrange Multipliers**\nThis method uses a \"node-on-segment\" or slave-point collocation approach. The problem states that the Lagrange multipliers $\\{\\lambda_a\\}$ are collocated at the slave nodes and use the same interpolation order as the displacement trace. This corresponds to choosing the multiplier space $\\mathcal{M}_h$ to be the same as the displacement trace space $\\mathcal{V}_h$. For linear elements, this is the P1-P1 (piecewise linear for displacement, piecewise linear for pressure) pairing. It is a classical result in the theory of mixed finite element methods that this equal-order pairing for velocity-pressure in Stokes flow, or displacement-pressure in contact/incompressibility, violates the LBB condition.\n\nThe failure to satisfy the LBB condition leads to an unstable formulation. The pressure (or Lagrange multiplier) field is not uniquely defined and is susceptible to spurious, non-physical oscillations. Even in this simple patch test where the exact solution is a constant pressure, a collocated N2S method will compute nodal multiplier values that oscillate around the true value $p_0$. Therefore, the constant pressure is not reproduced, and the patch test is failed.\n\n**3. N2S with Penalty Enforcement**\nThis is an alternative N2S method where the contact constraint is enforced not by Lagrange multipliers but by adding a penalty term to the potential energy, of the form $\\frac{1}{2} \\epsilon_N g_n^2$, where $\\epsilon_N$ is a large penalty parameter. In the discrete form, this is applied at the slave nodes, leading to nodal reaction forces $F_{c,a} = \\epsilon_N g_{n,a}$ (for penetration $g_{n,a} > 0$, or a suitable redefinition of gap). Like the collocated LM method, this approach enforces the constraint at discrete points. The resulting nodal reaction forces are also known to be oscillatory and do not accurately represent a constant pressure distribution. To obtain a continuous pressure field, a reconstruction or smoothing procedure is needed, but the underlying nodal data is oscillatory. Therefore, this method also fails the constant-pressure patch test in its strict sense.\n\nNow, we evaluate each statement:\n\n**A. In S2S with biorthogonal dual shape functions for the multiplier field, the discrete contact operator reproduces a constant pressure $p_{h}(\\xi)\\equiv p_{0}$ exactly on $\\Gamma_{c}$, and the segment reactions are equal to $p_{0}$ times the segment length; thus the patch test is passed.**\nAs derived above, the S2S mortar method with a dual basis is constructed specifically to allow for the exact representation of a constant pressure field. The coefficients of the Lagrange multipliers can be uniquely determined to match $p_0$. The resulting distribution of forces is consistent with the constant pressure field. The integral of the constant pressure $p_0$ over a segment of length $L_s$ is indeed $p_0 L_s$. This statement is a correct description of the properties of a well-formulated mortar method.\n**Verdict: Correct.**\n\n**B. In N2S with equal-order nodal Lagrange multipliers collocated at slave nodes, the discrete system satisfies a stable discrete Ladyzhenskaya–Babuška–Brezzi (LBB) condition, guaranteeing a uniform multiplier field and no oscillations; thus the patch test is passed.**\nThis statement is fundamentally flawed. The premise that an N2S scheme with equal-order interpolation for displacements and Lagrange multipliers satisfies the LBB condition is false. This choice of spaces is known to be LBB-unstable. Consequently, it does not guarantee a uniform multiplier field and is, in fact, prone to spurious oscillations. The patch test is not passed.\n**Verdict: Incorrect.**\n\n**C. In N2S with penalty enforcement of the normal gap at slave nodes, the interface reaction field is concentrated at nodes, producing spurious oscillations in the reconstructed contact pressure even with identical meshes, unless a consistent projection or smoothing is introduced; thus the patch test is not passed in its strict sense.**\nThis statement correctly describes the behavior of N2S penalty methods. The enforcement of constraints at discrete points leads to a set of nodal reaction forces. For a constant pressure patch test, these nodal forces are known to exhibit oscillations (e.g., they are often smaller at the ends of the contact patch than in the interior). Any direct reconstruction of a continuous pressure field from these forces will inherit these oscillations. The conclusion that the patch test is not passed in its strict sense is accurate. This behavior is symptomatic of point-collocated contact schemes in general, including the unstable Lagrange multiplier variant described in the problem.\n**Verdict: Correct.**\n\n**D. S2S mortar formulations only pass the constant-pressure patch test when slave and master meshes are identical and node-aligned; if the meshes are non-matching, constant pressure cannot be reproduced.**\nThis statement is false. A primary motivation and a key advantage of mortar (S2S) methods is their ability to handle non-matching, non-conforming meshes at the interface. A properly formulated mortar method, such as one with a dual Lagrange multiplier basis, is designed to pass patch tests (including the constant pressure test) even when the meshes are not identical. The claim that it *only* passes for identical meshes negates the very purpose of the method.\n**Verdict: Incorrect.**\n\nBased on the analysis, statements A and C are correct.", "answer": "$$\\boxed{\\text{AC}}$$", "id": "3509997"}]}