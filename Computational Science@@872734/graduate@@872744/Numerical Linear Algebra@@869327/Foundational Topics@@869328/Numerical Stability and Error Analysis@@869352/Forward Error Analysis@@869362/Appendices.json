{"hands_on_practices": [{"introduction": "The relationship between backward error and forward error is a cornerstone of numerical analysis. A backward stable algorithm guarantees that the computed solution is the exact solution to a nearby problem, but this does not automatically mean the computed solution is near the true solution. This exercise [@problem_id:3546754] provides a striking, hands-on demonstration of how the condition number, $\\kappa(A)$, acts as an amplification factor, capable of turning a tiny backward error into a large and significant forward error.", "problem": "Let $\\|\\cdot\\|$ denote the spectral norm (the Euclidean $2$-norm for vectors and the induced operator $2$-norm for matrices). Consider the $2 \\times 2$ diagonal matrix\n$$\nA \\;=\\; \\begin{pmatrix} 1  0 \\\\ 0  \\varepsilon \\end{pmatrix},\n\\quad \\text{with } \\varepsilon \\;=\\; 10^{-14},\n$$\nthe exact solution\n$$\nx \\;=\\; \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix},\n$$\nand the corresponding right-hand side\n$$\nb \\;=\\; A x \\;=\\; \\begin{pmatrix} 1 \\\\ \\varepsilon \\end{pmatrix}.\n$$\nSuppose a computed solution is reported as\n$$\n\\hat{x} \\;=\\; \\begin{pmatrix} 1 \\\\ 1 - \\alpha \\end{pmatrix},\n\\quad \\text{with } \\alpha \\;=\\; 10^{-2}.\n$$\nYou will verify that the normwise backward error is no larger than $10^{-16}$ while the normwise forward error is approximately $10^{-2}$, and then justify this discrepancy using the condition number of $A$.\n\nTasks:\n1. Using the normwise backward error definition (the minimal $\\eta$ for which there exist perturbations $\\Delta A$ and $\\Delta b$ satisfying $(A + \\Delta A)\\hat{x} = b + \\Delta b$, with $\\|\\Delta A\\| \\le \\eta \\|A\\|$ and $\\|\\Delta b\\| \\le \\eta \\|b\\|$), exhibit specific $\\Delta A$ and $\\Delta b$ showing that the backward error for $\\hat{x}$ does not exceed $10^{-16}$.\n2. Compute the normwise forward error ratio $\\|x - \\hat{x}\\| / \\|x\\|$.\n3. Starting from the definitions of the condition number $\\kappa_{2}(A) = \\|A\\| \\,\\|A^{-1}\\|$, the backward error, and the forward error, derive a bound that explains why the forward error can be much larger than the backward error for ill-conditioned $A$, and evaluate this bound for the given data to interpret your result.\n\nReport, as your final answer, the numerical value of the forward error ratio $\\|x - \\hat{x}\\| / \\|x\\|$ rounded to four significant figures.", "solution": "The problem asks for a three-part analysis of a computed solution to a linear system, focusing on the concepts of backward error, forward error, and the condition number.\n\nThe given quantities are:\n- The matrix $A = \\begin{pmatrix} 1  0 \\\\ 0  \\varepsilon \\end{pmatrix}$ with $\\varepsilon = 10^{-14}$.\n- The exact solution $x = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$.\n- The right-hand side $b = Ax = \\begin{pmatrix} 1 \\\\ \\varepsilon \\end{pmatrix}$.\n- The computed solution $\\hat{x} = \\begin{pmatrix} 1 \\\\ 1 - \\alpha \\end{pmatrix}$ with $\\alpha = 10^{-2}$.\n- The norm $\\|\\cdot\\|$ is the spectral norm ($2$-norm for vectors, induced $2$-norm for matrices).\n\n### Task 1: Backward Error Verification\n\nThe normwise backward error $\\eta$ is the smallest non-negative number for which there exist perturbations $\\Delta A$ and $\\Delta b$ satisfying $(A + \\Delta A)\\hat{x} = b + \\Delta b$, with $\\|\\Delta A\\| \\le \\eta \\|A\\|$ and $\\|\\Delta b\\| \\le \\eta \\|b\\|$. This condition can be rewritten by defining the residual vector $r = b - A\\hat{x}$. The equation becomes:\n$$\n\\Delta b - \\Delta A \\hat{x} = A\\hat{x} - b = -r\n$$\nFirst, let's compute the residual $r$:\n$$\nA\\hat{x} = \\begin{pmatrix} 1  0 \\\\ 0  \\varepsilon \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1-\\alpha \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ \\varepsilon(1-\\alpha) \\end{pmatrix}\n$$\n$$\nr = b - A\\hat{x} = \\begin{pmatrix} 1 \\\\ \\varepsilon \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ \\varepsilon(1-\\alpha) \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\varepsilon\\alpha \\end{pmatrix}\n$$\nTo show that the backward error does not exceed $10^{-16}$, we need to exhibit specific perturbations $\\Delta A$ and $\\Delta b$ that satisfy the error equation and the norm bounds for an $\\eta \\le 10^{-16}$. A simple choice is to attribute the entire residual to a perturbation in $b$ by setting $\\Delta A = 0$.\nLet $\\Delta A$ be the $2 \\times 2$ zero matrix, $\\Delta A = \\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix}$. The error equation simplifies to $\\Delta b = -r$.\n$$\n\\Delta b = -r = \\begin{pmatrix} 0 \\\\ -\\varepsilon\\alpha \\end{pmatrix}\n$$\nNow we must verify the norm conditions for some $\\eta \\le 10^{-16}$. The first condition, $\\|\\Delta A\\| \\le \\eta \\|A\\|$, becomes $0 \\le \\eta \\|A\\|$, which is true for any $\\eta \\ge 0$.\nFor the second condition, we need to find the smallest $\\eta$ that satisfies $\\|\\Delta b\\| \\le \\eta \\|b\\|$. This gives $\\eta \\ge \\frac{\\|\\Delta b\\|}{\\|b\\|}$. Let's calculate the norms:\n$$\n\\|\\Delta b\\| = \\left\\| \\begin{pmatrix} 0 \\\\ -\\varepsilon\\alpha \\end{pmatrix} \\right\\|_2 = \\sqrt{0^2 + (-\\varepsilon\\alpha)^2} = \\varepsilon\\alpha = (10^{-14})(10^{-2}) = 10^{-16}\n$$\n$$\n\\|b\\| = \\left\\| \\begin{pmatrix} 1 \\\\ \\varepsilon \\end{pmatrix} \\right\\|_2 = \\sqrt{1^2 + \\varepsilon^2} = \\sqrt{1 + (10^{-14})^2} = \\sqrt{1 + 10^{-28}}\n$$\nFor our choice of $\\Delta A$ and $\\Delta b$, the backward error measure is $\\eta = \\frac{\\|\\Delta b\\|}{\\|b\\|} = \\frac{10^{-16}}{\\sqrt{1 + 10^{-28}}}$.\nSince $\\sqrt{1 + 10^{-28}} > 1$, we have $\\eta  10^{-16}$. The true normwise backward error is the minimum over all possible perturbations, so it must be less than or equal to this value. Thus, we have shown that the backward error for $\\hat{x}$ does not exceed $10^{-16}$.\n\n### Task 2: Forward Error Computation\n\nThe normwise forward error ratio is given by $\\frac{\\|x - \\hat{x}\\|}{\\|x\\|}$.\nFirst, we compute the error vector $x - \\hat{x}$:\n$$\nx - \\hat{x} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 1-\\alpha \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\alpha \\end{pmatrix}\n$$\nNext, we compute the required norms:\n$$\n\\|x - \\hat{x}\\| = \\left\\| \\begin{pmatrix} 0 \\\\ \\alpha \\end{pmatrix} \\right\\|_2 = \\sqrt{0^2 + \\alpha^2} = \\alpha = 10^{-2}\n$$\n$$\n\\|x\\| = \\left\\| \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\right\\|_2 = \\sqrt{1^2 + 1^2} = \\sqrt{2}\n$$\nThe forward error ratio is:\n$$\n\\frac{\\|x - \\hat{x}\\|}{\\|x\\|} = \\frac{10^{-2}}{\\sqrt{2}}\n$$\nTo provide the numerical value rounded to four significant figures:\n$$\n\\frac{10^{-2}}{\\sqrt{2}} \\approx \\frac{10^{-2}}{1.41421356} \\approx 0.0070710678 \\approx 7.071 \\times 10^{-3}\n$$\nThe value is approximately $0.007071$.\n\n### Task 3: Justification using the Condition Number\n\nThe discrepancy between the small backward error (approx. $10^{-16}$) and the much larger forward error (approx. $10^{-2}$) is explained by the condition number of the matrix $A$.\n\nFirst, we derive a general bound relating forward error and backward error. From $(A + \\Delta A)\\hat{x} = b + \\Delta b$ and $Ax = b$, we can write:\n$$\n(A+\\Delta A)\\hat{x} = Ax + \\Delta b \\implies \\hat{x} = (A+\\Delta A)^{-1}(Ax + \\Delta b)\n$$\nThe error is $\\hat{x}-x = (A+\\Delta A)^{-1}(Ax+\\Delta b) - x = (A+\\Delta A)^{-1}[Ax+\\Delta b - (A+\\Delta A)x] = (A+\\Delta A)^{-1}(\\Delta b - \\Delta A x)$.\nTaking norms, we get $\\|\\hat{x}-x\\| \\le \\|(A+\\Delta A)^{-1}\\| (\\|\\Delta b\\| + \\|\\Delta A\\|\\|x\\|)$.\nUsing the Banach Lemma, if $\\|\\Delta A\\|\\|A^{-1}\\|  1$, then $\\|(A+\\Delta A)^{-1}\\| \\le \\frac{\\|A^{-1}\\|}{1-\\|A^{-1}\\|\\|\\Delta A\\|}$.\nSubstituting this in, we get:\n$$\n\\|\\hat{x}-x\\| \\le \\frac{\\|A^{-1}\\|}{1-\\|A^{-1}\\|\\|\\Delta A\\|} (\\|\\Delta b\\| + \\|\\Delta A\\|\\|x\\|)\n$$\nDividing by $\\|x\\|$ to get the relative error:\n$$\n\\frac{\\|\\hat{x}-x\\|}{\\|x\\|} \\le \\frac{\\|A^{-1}\\|}{1-\\|A^{-1}\\|\\|\\Delta A\\|} \\left(\\frac{\\|\\Delta b\\|}{\\|x\\|} + \\|\\Delta A\\|\\right)\n$$\nUsing the inequality $\\|b\\|=\\|Ax\\| \\le \\|A\\|\\|x\\| \\implies \\frac{1}{\\|x\\|} \\le \\frac{\\|A\\|}{\\|b\\|}$:\n$$\n\\frac{\\|\\hat{x}-x\\|}{\\|x\\|} \\le \\frac{\\|A^{-1}\\|}{1-\\|A^{-1}\\|\\|\\Delta A\\|} \\left(\\frac{\\|\\Delta b\\|\\|A\\|}{\\|b\\|} + \\|\\Delta A\\|\\right) = \\frac{\\|A\\|\\|A^{-1}\\|}{1-\\|A\\|\\|A^{-1}\\|\\frac{\\|\\Delta A\\|}{\\|A\\|}} \\left(\\frac{\\|\\Delta b\\|}{\\|b\\|} + \\frac{\\|\\Delta A\\|}{\\|A\\|}\\right)\n$$\nLetting $\\kappa_2(A) = \\|A\\|\\|A^{-1}\\|$ be the condition number, and using the definition of backward error $\\eta$ which bounds $\\frac{\\|\\Delta A\\|}{\\|A\\|}$ and $\\frac{\\|\\Delta b\\|}{\\|b\\|}$, we arrive at the standard bound:\n$$\n\\frac{\\|\\hat{x}-x\\|}{\\|x\\|} \\le \\frac{\\kappa_2(A)}{1-\\kappa_2(A)\\frac{\\|\\Delta A\\|}{\\|A\\|}} \\left(\\frac{\\|\\Delta A\\|}{\\|A\\|} + \\frac{\\|\\Delta b\\|}{\\|b\\|}\\right)\n$$\nFor small backward error, the term $1-\\kappa_2(A)\\frac{\\|\\Delta A\\|}{\\|A\\|}$ is close to $1$. The bound illustrates that the forward error can be amplified by a factor of the condition number $\\kappa_2(A)$ relative to the backward error.\n\nNow, we evaluate this for the given data. First, we compute the condition number $\\kappa_2(A)$. The spectral norm of a diagonal matrix is the maximum absolute value of its diagonal entries.\n$$\n\\|A\\|_2 = \\max(1, |\\varepsilon|) = \\max(1, 10^{-14}) = 1\n$$\nThe inverse of $A$ is $A^{-1} = \\begin{pmatrix} 1  0 \\\\ 0  1/\\varepsilon \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  10^{14} \\end{pmatrix}$.\n$$\n\\|A^{-1}\\|_2 = \\max(1, |1/\\varepsilon|) = \\max(1, 10^{14}) = 10^{14}\n$$\nThe condition number is:\n$$\n\\kappa_2(A) = \\|A\\|_2 \\|A^{-1}\\|_2 = 1 \\cdot 10^{14} = 10^{14}\n$$\nThis is an extremely large condition number, indicating that the matrix $A$ is very ill-conditioned.\n\nThe derived inequality shows that the forward error is bounded by a quantity proportional to the product of the condition number and the backward error:\n$$\n\\text{Forward Error} \\lesssim \\kappa_2(A) \\times (\\text{Backward Error})\n$$\nIn our case, the backward error $\\eta$ is of the order $10^{-16}$, while the condition number $\\kappa_2(A)$ is $10^{14}$. Their product is approximately $10^{14} \\times 10^{-16} = 10^{-2}$. This theoretical estimate aligns perfectly with the forward error ratio we computed, which is $\\frac{10^{-2}}{\\sqrt{2}} \\approx 7.071 \\times 10^{-3}$. The large condition number acts as an amplification factor, transforming a very small backward error (meaning $\\hat{x}$ is the exact solution to a nearby problem) into a large forward error (meaning $\\hat{x}$ is far from the true solution $x$).", "answer": "$$\\boxed{0.007071}$$", "id": "3546754"}, {"introduction": "Often, our assessment of error is based on a vector norm, which provides a single number to quantify the overall discrepancy. However, this normwise perspective can obscure critical inaccuracies in individual components of a solution, which may be of primary interest in an application. This practice [@problem_id:3546786] delves into this crucial distinction by constructing a scenario where catastrophic cancellation in floating-point arithmetic leads to a very large *componentwise* relative error, even while the *normwise* relative error remains deceptively small.", "problem": "Consider a linear system $A x = b$ with $A \\in \\mathbb{R}^{3 \\times 3}$ and $b \\in \\mathbb{R}^{3}$. In exact arithmetic, set $A = I_{3}$, and define the right-hand side by\n$$\nb^{\\ast} = \\begin{pmatrix}\n\\left(10^{8} + 1\\right) - 10^{8} \\\\\n10^{8} \\\\\n-10^{8}\n\\end{pmatrix}.\n$$\nAssume that $b^{\\ast}$ is formed by first computing $\\left(10^{8} + 1\\right)$ using decimal floating-point arithmetic with precision $t = 8$ significant digits and rounding to nearest at each operation, and then subtracting $10^{8}$, again in the same arithmetic. Let $\\widehat{b}$ denote the floating-point result of these two operations in the first component and exact assignments in the second and third components, and let $\\widehat{x}$ denote the computed solution to $A x = \\widehat{b}$ in the same arithmetic. Because $A = I_{3}$, we have $x^{\\ast} = b^{\\ast}$ and $\\widehat{x} = \\widehat{b}$.\n\nUsing the standard definitions of forward error in numerical linear algebra, where the normwise relative forward error is $\\left\\|\\widehat{x} - x^{\\ast}\\right\\|_{2} / \\left\\|x^{\\ast}\\right\\|_{2}$ and the componentwise relative forward error is $\\max_{i} \\left|\\widehat{x}_{i} - x^{\\ast}_{i}\\right| / \\left|x^{\\ast}_{i}\\right|$, construct the explicit vectors $x^{\\ast}$ and $\\widehat{x}$ induced by the above arithmetic and cancellation, and explain why the componentwise forward error is large while the normwise forward error is small. Then compute the ratio\n$$\n\\rho = \\frac{\\displaystyle \\max_{i} \\frac{\\left|\\widehat{x}_{i} - x^{\\ast}_{i}\\right|}{\\left|x^{\\ast}_{i}\\right|}}{\\displaystyle \\frac{\\left\\|\\widehat{x} - x^{\\ast}\\right\\|_{2}}{\\left\\|x^{\\ast}\\right\\|_{2}}}.\n$$\nExpress your final answer for $\\rho$ as a single closed-form analytic expression. No rounding is required.", "solution": "This problem illustrates the crucial difference between normwise and componentwise relative forward error by analyzing a case of catastrophic cancellation in floating-point arithmetic.\n\n### Step 1: Construct the exact solution $x^*$\nSince $A = I_3$, the exact solution is $x^* = b^*$. We compute the components of $b^*$ in exact arithmetic:\n- $b^*_1 = (10^8 + 1) - 10^8 = 1$.\n- $b^*_2 = 10^8$.\n- $b^*_3 = -10^8$.\nTherefore, the exact solution is\n$$\nx^* = \\begin{pmatrix} 1 \\\\ 10^8 \\\\ -10^8 \\end{pmatrix}.\n$$\n\n### Step 2: Construct the computed solution $\\widehat{x}$\nSince $A=I_3$, the computed solution is $\\widehat{x} = \\widehat{b}$. We must compute the first component of $\\widehat{b}$ using decimal floating-point arithmetic with $t=8$ significant digits and rounding to the nearest.\nThe operation is $\\widehat{b}_1 = \\text{fl}(\\text{fl}(10^8 + 1) - 10^8)$.\n1.  **First, compute the inner operation:** $\\text{fl}(10^8 + 1)$.\n    The exact value is $100,000,001$. In scientific notation, this is $1.00000001 \\times 10^8$. This representation has 9 significant digits.\n    To round this to $t=8$ significant digits, we look at the 9th digit, which is '1'. Since $1  5$, we round down (truncate).\n    $$\\text{fl}(10^8 + 1) = 1.0000000 \\times 10^8 = 10^8.$$\n    The information contained in the '+1' is lost at this stage.\n2.  **Next, compute the subtraction:** $\\text{fl}(10^8 - 10^8)$.\n    This results in $0$.\nSo, the first component of the computed vector is $\\widehat{b}_1 = 0$. The other components are exact assignments. The computed solution is\n$$\n\\widehat{x} = \\begin{pmatrix} 0 \\\\ 10^8 \\\\ -10^8 \\end{pmatrix}.\n$$\n\n### Step 3: Compute Errors and Explain the Discrepancy\nThe absolute error vector is $\\widehat{x} - x^* = \\begin{pmatrix} 0 \\\\ 10^8 \\\\ -10^8 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 10^8 \\\\ -10^8 \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ 0 \\\\ 0 \\end{pmatrix}$.\n\n**Componentwise Relative Forward Error:**\nThe formula is $\\max_{i} \\frac{|\\widehat{x}_i - x^*_i|}{|x^*_i|}$. We check each component:\n- For $i=1$: $\\frac{|\\widehat{x}_1 - x^*_1|}{|x^*_1|} = \\frac{|0-1|}{|1|} = 1$. This is a $100\\%$ relative error.\n- For $i=2$: $\\frac{|\\widehat{x}_2 - x^*_2|}{|x^*_2|} = \\frac{|10^8 - 10^8|}{|10^8|} = 0$.\n- For $i=3$: $\\frac{|\\widehat{x}_3 - x^*_3|}{|x^*_3|} = \\frac{|-10^8 - (-10^8)|}{|-10^8|} = 0$.\nThe componentwise relative forward error is the maximum of these values, which is $1$.\n\n**Normwise Relative Forward Error:**\nThe formula is $\\frac{\\|\\widehat{x} - x^*\\|_2}{\\|x^*\\|_2}$.\n- $\\|\\widehat{x} - x^*\\|_2 = \\left\\| \\begin{pmatrix} -1 \\\\ 0 \\\\ 0 \\end{pmatrix} \\right\\|_2 = \\sqrt{(-1)^2 + 0^2 + 0^2} = 1$.\n- $\\|x^*\\|_2 = \\left\\| \\begin{pmatrix} 1 \\\\ 10^8 \\\\ -10^8 \\end{pmatrix} \\right\\|_2 = \\sqrt{1^2 + (10^8)^2 + (-10^8)^2} = \\sqrt{1 + 2 \\times 10^{16}}$.\nThe normwise relative forward error is $\\frac{1}{\\sqrt{1 + 2 \\times 10^{16}}}$. This value is very small, approximately $\\frac{1}{\\sqrt{2} \\times 10^8} \\approx 7.07 \\times 10^{-9}$.\n\n**Explanation:**\nThe componentwise error is large because catastrophic cancellation during the floating-point computation completely erased the small first component of the solution. A relative error of $1$ indicates a total loss of accuracy for that component.\nIn contrast, the normwise error is small because the Euclidean norm is dominated by the large components of the vector. The absolute error of magnitude $1$ is tiny compared to the overall magnitude of the solution vector $\\|x^*\\|_2 \\approx \\sqrt{2} \\times 10^8$. This demonstrates how a normwise error metric can conceal severe inaccuracies in smaller components of a solution vector.\n\n### Step 4: Compute the Ratio $\\rho$\nThe ratio is defined as\n$$\n\\rho = \\frac{\\text{Componentwise Relative Error}}{\\text{Normwise Relative Error}} = \\frac{1}{\\frac{1}{\\sqrt{1 + 2 \\times 10^{16}}}} = \\sqrt{1 + 2 \\times 10^{16}}.\n$$\nThis is the required closed-form analytic expression.", "answer": "$$ \\boxed{\\sqrt{1 + 2 \\times 10^{16}}} $$", "id": "3546786"}, {"introduction": "Having seen how a large condition number can amplify errors, a natural question arises: can we actively improve the conditioning of a problem before solving it? This practice [@problem_id:3546820] explores a powerful preconditioning technique known as equilibration. By applying simple diagonal scaling matrices to the rows and columns of a poorly scaled system, you will see firsthand how it is possible to dramatically reduce a matrix's condition number, thereby tightening the bound on the forward error and improving the potential accuracy of the computed solution.", "problem": "Consider the linear system $A x = b$ with\n$$\nA \\;=\\; \\begin{pmatrix} 10^{-3}  0 \\\\ 0  1 \\end{pmatrix}, \n\\qquad \nx_{\\star} \\;=\\; \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix},\n\\qquad \nb \\;=\\; A x_{\\star} \\;=\\; \\begin{pmatrix} 10^{-3} \\\\ 1 \\end{pmatrix}.\n$$\nWe solve for $x$ using a naive direct solver in base-$10$ floating-point arithmetic with $t=3$ significant digits rounded to nearest. Assume the solver is normwise backward stable in the following sense: the computed solution $\\widehat{x}$ is the exact solution to a perturbed system $(A + \\Delta A)\\widehat{x} = b + \\Delta b$ with\n$$\n\\max\\!\\left\\{\\frac{\\|\\Delta A\\|_{2}}{\\|A\\|_{2}},\\,\\frac{\\|\\Delta b\\|_{2}}{\\|b\\|_{2}}\\right\\} \\;\\le\\; u,\n\\qquad\nu \\;=\\; 5\\times 10^{-4}.\n$$\nYou will examine the forward error before and after an equilibration step that uses both row and column scalings. Define the diagonal scalings\n$$\nD_{r} \\;=\\; \\operatorname{diag}\\!\\big(10^{3/2},\\,1\\big),\n\\qquad\nD_{c} \\;=\\; \\operatorname{diag}\\!\\big(10^{3/2},\\,1\\big),\n$$\nand consider the equilibrated system\n$$\n\\big(D_{r} A D_{c}\\big)\\,y \\;=\\; D_{r} b,\n\\qquad\nx \\;=\\; D_{c}\\,y.\n$$\n\nUsing normwise forward error analysis in the spectral norm (also called the $2$-norm), proceed as follows:\n\n1. Start from the defining relations of backward stability and the basic perturbation identity to derive the standard bound that, provided $\\kappa_{2}(M)\\,\\eta  1$,\n$$\n\\frac{\\|\\widehat{z}-z\\|_{2}}{\\|z\\|_{2}} \\;\\le\\; \\frac{\\kappa_{2}(M)\\,\\eta}{\\,1 - \\kappa_{2}(M)\\,\\eta\\,},\n$$\nwhere $M$ is a nonsingular coefficient matrix, $z$ the exact solution to $M z = f$, $\\widehat{z}$ the computed solution, and $\\eta$ the normwise relative backward error.\n2. Compute the $2$-norm condition numbers $\\kappa_{2}(A)$ and $\\kappa_{2}(D_{r} A D_{c})$.\n3. Using $u$ in place of $\\eta$ as justified by the backward stability assumption, form the worst-case relative forward error bounds for the original and for the equilibrated systems, and then compute the ratio\n$$\nR \\;=\\; \\frac{\\text{bound before equilibration}}{\\text{bound after equilibration}}.\n$$\n\nWhat is the numerical value of $R$? Round your answer to four significant figures. The final answer must be reported as a pure number without units.", "solution": "The problem requires a three-part analysis of forward error for a linear system, both before and after an equilibration step. We now proceed with the solution, following the three specified steps.\n\n### Part 1: Derivation of the Forward Error Bound\n\nWe are asked to derive the standard forward error bound for a linear system $Mz=f$. Let $M$ be a nonsingular matrix. The exact solution is $z = M^{-1}f$. Let $\\widehat{z}$ be the computed solution, which is assumed to be the exact solution to a perturbed system. For the purpose of deriving the target formula, we consider the perturbation to be only in the matrix, i.e.,\n$$(M + \\Delta M) \\widehat{z} = f$$\nwhere the backward error is bounded by $\\|\\Delta M\\|_2 \\le \\eta \\|M\\|_2$ for some backward error measure $\\eta$.\n\nSubtracting the original equation $Mz=f$ from the perturbed one gives:\n$$(M + \\Delta M) \\widehat{z} - Mz = 0$$\n$$M\\widehat{z} + \\Delta M \\widehat{z} - Mz = 0$$\nRearranging the terms to find an expression for the error vector $\\widehat{z}-z$:\n$$M(\\widehat{z} - z) = -\\Delta M \\widehat{z}$$\nProvided $M$ is nonsingular, we can multiply by $M^{-1}$:\n$$\\widehat{z} - z = -M^{-1} \\Delta M \\widehat{z}$$\nTaking the $2$-norm of both sides and applying the sub-multiplicativity of matrix norms:\n$$\\|\\widehat{z} - z\\|_{2} = \\|-M^{-1} \\Delta M \\widehat{z}\\|_{2} \\le \\|M^{-1}\\|_{2} \\|\\Delta M\\|_{2} \\|\\widehat{z}\\|_{2}$$\nTo obtain the relative forward error, we divide by $\\|z\\|_2$ (assuming $z \\ne 0$):\n$$\\frac{\\|\\widehat{z} - z\\|_{2}}{\\|z\\|_{2}} \\le \\|M^{-1}\\|_{2} \\|\\Delta M\\|_{2} \\frac{\\|\\widehat{z}\\|_{2}}{\\|z\\|_{2}}$$\nNow, we use the backward error bound $\\|\\Delta M\\|_2 \\le \\eta \\|M\\|_2$:\n$$\\frac{\\|\\widehat{z} - z\\|_{2}}{\\|z\\|_{2}} \\le \\eta \\|M\\|_2 \\|M^{-1}\\|_{2} \\frac{\\|\\widehat{z}\\|_{2}}{\\|z\\|_{2}}$$\nRecognizing the $2$-norm condition number $\\kappa_2(M) = \\|M\\|_2 \\|M^{-1}\\|_2$:\n$$\\frac{\\|\\widehat{z} - z\\|_{2}}{\\|z\\|_{2}} \\le \\kappa_2(M) \\eta \\frac{\\|\\widehat{z}\\|_{2}}{\\|z\\|_{2}}$$\nThis bound depends on the unknown computed solution $\\widehat{z}$. We can eliminate this dependency by noting that $\\widehat{z} = z + (\\widehat{z}-z)$. Using the triangle inequality:\n$$\\|\\widehat{z}\\|_2 = \\|z + (\\widehat{z}-z)\\|_2 \\le \\|z\\|_2 + \\|\\widehat{z}-z\\|_2$$\nDividing by $\\|z\\|_2$ gives:\n$$\\frac{\\|\\widehat{z}\\|_2}{\\|z\\|_2} \\le 1 + \\frac{\\|\\widehat{z}-z\\|_2}{\\|z\\|_2}$$\nLet $e_{rel} = \\frac{\\|\\widehat{z} - z\\|_{2}}{\\|z\\|_{2}}$. The inequality becomes $e_{rel} \\le \\kappa_2(M) \\eta (1 + e_{rel})$.\n$$e_{rel} \\le \\kappa_2(M)\\eta + \\kappa_2(M)\\eta\\,e_{rel}$$\n$$e_{rel}(1 - \\kappa_2(M)\\eta) \\le \\kappa_2(M)\\eta$$\nProvided that $\\kappa_2(M)\\eta  1$, the term $(1 - \\kappa_2(M)\\eta)$ is positive, and we can divide by it without changing the inequality direction:\n$$\\frac{\\|\\widehat{z}-z\\|_{2}}{\\|z\\|_{2}} \\le \\frac{\\kappa_{2}(M)\\,\\eta}{\\,1 - \\kappa_{2}(M)\\,\\eta\\,}$$\nThis completes the derivation of the specified bound.\n\n### Part 2: Computation of Condition Numbers\n\nFirst, we compute the condition number of the original matrix $A$.\n$$A = \\begin{pmatrix} 10^{-3}  0 \\\\ 0  1 \\end{pmatrix}$$\nSince $A$ is a diagonal matrix, its singular values are the absolute values of its diagonal entries: $\\sigma_1 = 1$ and $\\sigma_2 = 10^{-3}$.\nThe $2$-norm of $A$ is its largest singular value, $\\|A\\|_2 = \\sigma_{max}(A) = 1$.\nThe inverse of $A$ is $A^{-1} = \\begin{pmatrix} 10^{3}  0 \\\\ 0  1 \\end{pmatrix}$.\nThe $2$-norm of $A^{-1}$ is its largest singular value, $\\|A^{-1}\\|_2 = 10^3$.\nThe $2$-norm condition number is $\\kappa_2(A) = \\|A\\|_2 \\|A^{-1}\\|_2$.\n$$\\kappa_2(A) = 1 \\times 10^3 = 1000$$\nAlternatively, for a diagonal matrix, $\\kappa_2(A) = \\frac{\\sigma_{max}}{\\sigma_{min}} = \\frac{1}{10^{-3}} = 1000$.\n\nNext, we compute the condition number of the equilibrated matrix $\\tilde{A} = D_r A D_c$.\nThe scaling matrices are $D_r = \\operatorname{diag}(10^{3/2}, 1)$ and $D_c = \\operatorname{diag}(10^{3/2}, 1)$.\n$$\\tilde{A} = D_r A D_c = \\begin{pmatrix} 10^{3/2}  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 10^{-3}  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 10^{3/2}  0 \\\\ 0  1 \\end{pmatrix}$$\n$$\\tilde{A} = \\begin{pmatrix} 10^{3/2} \\cdot 10^{-3} \\cdot 10^{3/2}  0 \\\\ 0  1 \\cdot 1 \\cdot 1 \\end{pmatrix} = \\begin{pmatrix} 10^{3/2 - 3 + 3/2}  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 10^{0}  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}$$\nThe equilibrated matrix is the $2 \\times 2$ identity matrix, $\\tilde{A}=I$.\nThe condition number of the identity matrix is:\n$$\\kappa_2(D_r A D_c) = \\kappa_2(I) = 1$$\n\n### Part 3: Ratio of Forward Error Bounds\n\nWe are instructed to use the formula derived in Part 1 to form the worst-case relative forward error bounds. We use $\\eta = u = 5 \\times 10^{-4}$.\n\nThe bound for the original system $Ax=b$ is:\n$$\\text{Bound}_{before} = \\frac{\\kappa_2(A) u}{1 - \\kappa_2(A) u}$$\nWe have $\\kappa_2(A) = 1000$ and $u = 5 \\times 10^{-4}$. The product is $\\kappa_2(A)u = 1000 \\times 5 \\times 10^{-4} = 0.5$. Since $0.5  1$, the bound is well-defined.\n$$\\text{Bound}_{before} = \\frac{0.5}{1 - 0.5} = \\frac{0.5}{0.5} = 1$$\n\nThe bound for the equilibrated system $\\tilde{A}y=\\tilde{b}$ is:\n$$\\text{Bound}_{after} = \\frac{\\kappa_2(\\tilde{A}) u}{1 - \\kappa_2(\\tilde{A}) u}$$\nWe have $\\kappa_2(\\tilde{A}) = 1$. The product is $\\kappa_2(\\tilde{A})u = 1 \\times 5 \\times 10^{-4} = 0.0005$. Since $0.0005  1$, the bound is well-defined.\n$$\\text{Bound}_{after} = \\frac{5 \\times 10^{-4}}{1 - 5 \\times 10^{-4}} = \\frac{5 \\times 10^{-4}}{0.9995}$$\nThis bound applies to the relative error in the solution $y$ of the equilibrated system. The problem asks for the ratio of the bounds \"for the original and for the equilibrated systems\", which compares the conditioning of the problem solved by the direct method in each case.\n\nThe ratio $R$ is:\n$$R = \\frac{\\text{Bound}_{before}}{\\text{Bound}_{after}} = \\frac{1}{\\frac{5 \\times 10^{-4}}{0.9995}} = \\frac{0.9995}{5 \\times 10^{-4}}$$\n$$R = \\frac{9995 \\times 10^{-4}}{5 \\times 10^{-4}} = \\frac{9995}{5} = 1999$$\nThe result $R=1999$ is an exact integer. The problem asks for the answer to be rounded to four significant figures. As $1999$ has four significant figures, no rounding is necessary.", "answer": "$$\\boxed{1999}$$", "id": "3546820"}]}