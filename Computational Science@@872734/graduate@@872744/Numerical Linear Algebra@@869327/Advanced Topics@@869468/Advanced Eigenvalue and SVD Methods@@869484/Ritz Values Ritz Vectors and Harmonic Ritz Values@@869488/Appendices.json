{"hands_on_practices": [{"introduction": "This first practice serves as a crucial conceptual cornerstone. We will construct a simple, analytically tractable scenario to demonstrate a fundamental limitation of the standard Rayleigh-Ritz method, particularly its difficulty in approximating interior eigenvalues. Through this guided example [@problem_id:3574738], you will see firsthand why the method can fail and then discover how the harmonic Ritz projection elegantly overcomes this very challenge by reformulating the underlying orthogonality condition.", "problem": "Let $A \\in \\mathbb{R}^{3 \\times 3}$ be the symmetric matrix $A = \\operatorname{diag}(1, 2, 100)$. Consider the two-dimensional trial subspace $\\mathcal{K} = \\operatorname{span}\\{u_{1}, u_{2}\\}$ where $u_{1} = \\frac{1}{\\sqrt{1+\\varepsilon^{2}}}(e_{1} + \\varepsilon e_{2})$ and $u_{2} = e_{3}$, with $e_{1}, e_{2}, e_{3}$ the standard basis vectors in $\\mathbb{R}^{3}$ and $\\varepsilon > 0$ a fixed, but otherwise arbitrary, real parameter. Denote by $W \\in \\mathbb{R}^{3 \\times 2}$ the matrix with columns $u_{1}$ and $u_{2}$ so that $\\mathcal{K} = \\operatorname{range}(W)$ and $W^{\\mathsf{T}}W = I$. \n\nUsing only fundamental definitions, do the following.\n\n1. Using the Rayleigh–Ritz projection principle, derive the Ritz values by forming the $2 \\times 2$ projected matrix $T = W^{\\mathsf{T}} A W$ and computing its eigenvalues. Explain, in terms of the geometry of the subspace and the Rayleigh quotient characterization for symmetric matrices, why this procedure fails to approximate the interior eigenvalue $2$ for small $\\varepsilon$, even if one were to repeatedly reuse the same subspace $\\mathcal{K}$ (as in restarted projection methods with fixed subspace dimension).\n\n2. Using the harmonic projection principle with shift $s \\in \\mathbb{R}$, defined by enforcing the Petrov–Galerkin condition that the residual $r(\\lambda, y) = A(Wy) - \\lambda (Wy)$ be orthogonal to $(A - s I)\\mathcal{K}$, derive the reduced generalized eigenvalue problem in the basis $W$ and solve it explicitly to obtain the harmonic Ritz values as functions of $s$ and $\\varepsilon$.\n\n3. Specialize your expression to the shift $s = 1$. Determine the harmonic Ritz value that approximates the interior eigenvalue and state its exact value. Then, mechanistically explain why the harmonic projection succeeds here while the standard Rayleigh–Ritz projection stagnates on the interior eigenvalue for this subspace.\n\nYour final reported answer must be the single harmonic Ritz value that approximates the interior eigenvalue when $s = 1$. No rounding is required and no units are involved. Express your final answer exactly.", "solution": "The problem asks for an analysis of the Rayleigh-Ritz and harmonic Ritz methods for approximating eigenvalues of a given $3 \\times 3$ symmetric matrix $A$ in a specific two-dimensional subspace $\\mathcal{K}$.\n\nThe given matrix is $A = \\operatorname{diag}(1, 2, 100)$, which is an element of $\\mathbb{R}^{3 \\times 3}$. Its eigenvalues are $\\lambda_1 = 1$, $\\lambda_2 = 2$, and $\\lambda_3 = 100$, with corresponding eigenvectors $e_1$, $e_2$, and $e_3$, the standard basis vectors.\n\nThe trial subspace is $\\mathcal{K} = \\operatorname{span}\\{u_1, u_2\\}$, where the basis vectors are $u_1 = \\frac{1}{\\sqrt{1+\\varepsilon^2}}(e_1 + \\varepsilon e_2)$ and $u_2 = e_3$. The parameter $\\varepsilon$ is a fixed positive real number. The matrix $W \\in \\mathbb{R}^{3 \\times 2}$ has $u_1$ and $u_2$ as its columns, and it is given that $W^{\\mathsf{T}}W = I$, which is readily verified.\n$W = \\begin{pmatrix} \\frac{1}{\\sqrt{1+\\varepsilon^2}} & 0 \\\\ \\frac{\\varepsilon}{\\sqrt{1+\\varepsilon^2}} & 0 \\\\ 0 & 1 \\end{pmatrix}$.\n\n**1. Rayleigh–Ritz Projection and its Failure for the Interior Eigenvalue**\n\nThe Rayleigh-Ritz method seeks approximate eigenvalues of $A$ from the subspace $\\mathcal{K}$ by finding the eigenvalues of the projected matrix $T = W^{\\mathsf{T}}AW$. These eigenvalues are called the Ritz values.\n\nFirst, we compute the matrix $AW$:\n$$ AW = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 100 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{\\sqrt{1+\\varepsilon^2}} & 0 \\\\ \\frac{\\varepsilon}{\\sqrt{1+\\varepsilon^2}} & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{\\sqrt{1+\\varepsilon^2}} & 0 \\\\ \\frac{2\\varepsilon}{\\sqrt{1+\\varepsilon^2}} & 0 \\\\ 0 & 100 \\end{pmatrix} $$\nNext, we compute $T = W^{\\mathsf{T}}AW$:\n$$ T = \\begin{pmatrix} \\frac{1}{\\sqrt{1+\\varepsilon^2}} & \\frac{\\varepsilon}{\\sqrt{1+\\varepsilon^2}} & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{\\sqrt{1+\\varepsilon^2}} & 0 \\\\ \\frac{2\\varepsilon}{\\sqrt{1+\\varepsilon^2}} & 0 \\\\ 0 & 100 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{1+\\varepsilon^2} + \\frac{2\\varepsilon^2}{1+\\varepsilon^2} & 0 \\\\ 0 & 100 \\end{pmatrix} = \\begin{pmatrix} \\frac{1+2\\varepsilon^2}{1+\\varepsilon^2} & 0 \\\\ 0 & 100 \\end{pmatrix} $$\nThe projected matrix $T$ is diagonal. Its eigenvalues, the Ritz values, are therefore the diagonal entries:\n$\\theta_1 = \\frac{1+2\\varepsilon^2}{1+\\varepsilon^2}$ and $\\theta_2 = 100$.\n\nFor small $\\varepsilon > 0$, the first Ritz value can be analyzed as $\\theta_1 = \\frac{1+\\varepsilon^2+\\varepsilon^2}{1+\\varepsilon^2} = 1 + \\frac{\\varepsilon^2}{1+\\varepsilon^2}$. As $\\varepsilon \\to 0$, $\\theta_1 \\to 1$. The second Ritz value is exactly $\\theta_2 = 100$.\nThus, the Ritz values approximate the extremal eigenvalues $\\lambda_1 = 1$ and $\\lambda_3 = 100$ of $A$. Neither approximates the interior eigenvalue $\\lambda_2 = 2$.\n\nThe reason for this failure lies in the geometry of the subspace $\\mathcal{K}$ and the nature of the Rayleigh quotient. The Ritz values are the stationary values of the Rayleigh quotient $R_A(x) = \\frac{x^{\\mathsf{T}}Ax}{x^{\\mathsf{T}}x}$ for $x \\in \\mathcal{K}$. The Rayleigh-Ritz method provides good approximations for eigenvalues whose corresponding eigenvectors are well-represented in the trial subspace $\\mathcal{K}$.\nFor small $\\varepsilon$, the basis vector $u_1$ is a small perturbation of the eigenvector $e_1$: $u_1 \\approx e_1$. The other basis vector $u_2$ is exactly the eigenvector $e_3$. Therefore, the subspace $\\mathcal{K} = \\operatorname{span}\\{u_1, u_2\\}$ is closely aligned with the eigenspace $\\operatorname{span}\\{e_1, e_3\\}$ corresponding to the extremal eigenvalues.\nConversely, the eigenvector $e_2$ corresponding to the interior eigenvalue $\\lambda_2=2$ is nearly orthogonal to $\\mathcal{K}$. Specifically, the angle $\\alpha$ between $e_2$ and any unit vector $x = c_1 u_1 + c_2 u_2$ in $\\mathcal{K}$ is bounded below. The projection of $e_2$ onto $\\mathcal{K}$ has a norm of $\\sqrt{(e_2^{\\mathsf{T}}u_1)^2 + (e_2^{\\mathsf{T}}u_2)^2} = \\sqrt{(\\frac{\\varepsilon}{\\sqrt{1+\\varepsilon^2}})^2 + 0} = \\frac{\\varepsilon}{\\sqrt{1+\\varepsilon^2}}$, which is small for small $\\varepsilon$. Since $\\mathcal{K}$ lacks a significant component in the direction of $e_2$, the Rayleigh quotient $R_A(x)$ for $x \\in \\mathcal{K}$ cannot approximate $\\lambda_2 = R_A(e_2) = 2$. Consequently, the standard Ritz procedure fails to find the interior eigenvalue.\n\n**2. Harmonic Ritz Projection**\n\nThe harmonic Ritz method uses a Petrov-Galerkin condition on a different test subspace. Given a shift $s \\in \\mathbb{R}$, the residual $r(\\lambda, y) = A(Wy) - \\lambda (Wy)$ is made orthogonal to the test subspace $(A-sI)\\mathcal{K}$. This gives the condition:\n$((A-sI)W)^{\\mathsf{T}} (A-\\lambda I)Wy = 0$ for all $y \\in \\mathbb{R}^2$.\nSince $A$ is symmetric, this leads to the $2 \\times 2$ generalized eigenvalue problem:\n$$ (W^{\\mathsf{T}}(A-sI)AW)y = \\lambda (W^{\\mathsf{T}}(A-sI)W)y $$\nLet $T_{std} = W^{\\mathsf{T}}AW$ and $S_{std} = W^{\\mathsf{T}}A^2W$. The problem can be written as $(S_{std} - s T_{std})y = \\lambda (T_{std} - sI)y$.\nWe have already computed $T_{std} = \\begin{pmatrix} \\frac{1+2\\varepsilon^2}{1+\\varepsilon^2} & 0 \\\\ 0 & 100 \\end{pmatrix}$.\nNow we compute $S_{std} = W^{\\mathsf{T}}A^2W$. Since $A^2 = \\operatorname{diag}(1, 4, 10000)$:\n$$ A^2W = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 4 & 0 \\\\ 0 & 0 & 10000 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{\\sqrt{1+\\varepsilon^2}} & 0 \\\\ \\frac{\\varepsilon}{\\sqrt{1+\\varepsilon^2}} & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{\\sqrt{1+\\varepsilon^2}} & 0 \\\\ \\frac{4\\varepsilon}{\\sqrt{1+\\varepsilon^2}} & 0 \\\\ 0 & 10000 \\end{pmatrix} $$\n$$ S_{std} = W^{\\mathsf{T}}A^2W = \\begin{pmatrix} \\frac{1}{\\sqrt{1+\\varepsilon^2}} & \\frac{\\varepsilon}{\\sqrt{1+\\varepsilon^2}} & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{\\sqrt{1+\\varepsilon^2}} & 0 \\\\ \\frac{4\\varepsilon}{\\sqrt{1+\\varepsilon^2}} & 0 \\\\ 0 & 10000 \\end{pmatrix} = \\begin{pmatrix} \\frac{1+4\\varepsilon^2}{1+\\varepsilon^2} & 0 \\\\ 0 & 10000 \\end{pmatrix} $$\nSince both matrices are diagonal, the generalized eigenvalue problem decouples. Let the harmonic Ritz values be $\\lambda^{(H)}$.\nFor the first eigenvalue:\n$$ \\lambda_1^{(H)} = \\frac{(S_{std})_{11} - s(T_{std})_{11}}{(T_{std})_{11} - s} = \\frac{\\frac{1+4\\varepsilon^2}{1+\\varepsilon^2} - s\\frac{1+2\\varepsilon^2}{1+\\varepsilon^2}}{\\frac{1+2\\varepsilon^2}{1+\\varepsilon^2} - s} = \\frac{1+4\\varepsilon^2 - s(1+2\\varepsilon^2)}{1+2\\varepsilon^2 - s(1+\\varepsilon^2)} $$\nFor the second eigenvalue (assuming $s \\neq 100$):\n$$ \\lambda_2^{(H)} = \\frac{(S_{std})_{22} - s(T_{std})_{22}}{(T_{std})_{22} - s} = \\frac{10000 - s(100)}{100 - s} = \\frac{100(100 - s)}{100 - s} = 100 $$\nThe harmonic Ritz values are $\\lambda_1^{(H)} = \\frac{1+4\\varepsilon^2 - s - 2s\\varepsilon^2}{1+2\\varepsilon^2 - s - s\\varepsilon^2}$ and $\\lambda_2^{(H)} = 100$.\n\n**3. Specialization to $s=1$ and Explanation**\n\nWe now specialize the result to the shift $s=1$.\nThe second harmonic Ritz value remains $\\lambda_2^{(H)} = 100$.\nThe first harmonic Ritz value becomes:\n$$ \\lambda_1^{(H)} = \\frac{1+4\\varepsilon^2 - 1(1+2\\varepsilon^2)}{1+2\\varepsilon^2 - 1(1+\\varepsilon^2)} = \\frac{1+4\\varepsilon^2 - 1 - 2\\varepsilon^2}{1+2\\varepsilon^2 - 1 - \\varepsilon^2} = \\frac{2\\varepsilon^2}{\\varepsilon^2} = 2 $$\nFor any $\\varepsilon > 0$, this harmonic Ritz value is exactly $2$, which is the interior eigenvalue of $A$.\n\nThe success of the harmonic projection with $s=1$ is due to the choice of the test subspace $(A-sI)\\mathcal{K}$. With $s=1$, the test subspace becomes $(A-I)\\mathcal{K}$. Let's find a basis for this space. The basis vectors of $\\mathcal{K}$ are $u_1$ and $u_2$. The basis for the test space is $\\{(A-I)u_1, (A-I)u_2\\}$.\n$$ (A-I)u_1 = (A-I)\\frac{1}{\\sqrt{1+\\varepsilon^2}}(e_1 + \\varepsilon e_2) = \\frac{1}{\\sqrt{1+\\varepsilon^2}}((A-I)e_1 + \\varepsilon(A-I)e_2) $$\nSince $Ae_1 = 1e_1$ and $Ae_2 = 2e_2$, we have $(A-I)e_1 = 0$ and $(A-I)e_2 = e_2$. Thus:\n$$ (A-I)u_1 = \\frac{1}{\\sqrt{1+\\varepsilon^2}}(0 + \\varepsilon e_2) = \\frac{\\varepsilon}{\\sqrt{1+\\varepsilon^2}} e_2 $$\nFor the second basis vector:\n$$ (A-I)u_2 = (A-I)e_3 = Ae_3 - e_3 = 100e_3 - e_3 = 99e_3 $$\nThe test space is $(A-I)\\mathcal{K} = \\operatorname{span}\\{e_2, e_3\\}$.\n\nThe harmonic Ritz condition for an approximate eigenpair $(\\theta, x)$ with $x \\in \\mathcal{K}$ is that the residual $Ax-\\theta x$ must be orthogonal to this test space. This means the residual must be orthogonal to both $e_2$ and $e_3$.\nConsider the vector $u_1 \\in \\mathcal{K}$. Let's find the value $\\theta$ such that $(Au_1 - \\theta u_1) \\perp \\operatorname{span}\\{e_2, e_3\\}$. The residual is:\n$$ Au_1 - \\theta u_1 = \\frac{1}{\\sqrt{1+\\varepsilon^2}}(e_1 + 2\\varepsilon e_2) - \\frac{\\theta}{\\sqrt{1+\\varepsilon^2}}(e_1 + \\varepsilon e_2) = \\frac{1}{\\sqrt{1+\\varepsilon^2}} \\left[ (1-\\theta)e_1 + (2-\\theta)\\varepsilon e_2 \\right] $$\nFor this residual to be orthogonal to $e_2$, its $e_2$ component must be zero. This requires $(2-\\theta)\\varepsilon = 0$. Since $\\varepsilon > 0$, we must have $\\theta = 2$. With $\\theta=2$, the residual becomes $\\frac{-1}{\\sqrt{1+\\varepsilon^2}}e_1$, which is indeed orthogonal to both $e_2$ and $e_3$.\nTherefore, $(\\theta=2, x=u_1)$ is a harmonic Ritz pair. The choice of shift $s=1=\\lambda_1$ filtered out the $e_1$ direction from the test space, forcing the method to use the available information in the $e_2$ direction. In contrast, the standard Rayleigh-Ritz method uses a test space $\\mathcal{K} \\approx \\operatorname{span}\\{e_1, e_3\\}$ which is almost blind to the $e_2$ direction, leading to its failure.\n\nThe harmonic Ritz value that approximates the interior eigenvalue for $s=1$ is exactly $2$.", "answer": "$$\\boxed{2}$$", "id": "3574738"}, {"introduction": "Moving from conceptual understanding to practical implementation, this exercise focuses on efficiency. A naive implementation of the harmonic Ritz method might involve explicitly forming and working with large, shifted matrices. This practice [@problem_id:3574726] guides you through deriving and implementing a technique that completely avoids this pitfall by leveraging the structure of the Arnoldi decomposition, allowing computation of harmonic Ritz values using only small, projected Hessenberg matrices.", "problem": "Let $A \\in \\mathbb{C}^{n \\times n}$ be a general matrix and let $m \\ll n$. Construct an orthonormal basis $V_{m} \\in \\mathbb{C}^{n \\times m}$ for the Krylov subspace generated by a nonzero vector $b \\in \\mathbb{C}^{n}$ using $m$ steps of the Arnoldi process, and let $V_{m+1} \\in \\mathbb{C}^{n \\times (m+1)}$ denote the same basis extended by one additional Arnoldi vector. The Arnoldi relation is the fundamental identity\n$$\nA V_{m} \\;=\\; V_{m+1} \\,\\widehat{H}_{m},\n$$\nwhere $\\widehat{H}_{m} \\in \\mathbb{C}^{(m+1) \\times m}$ is upper Hessenberg and its top $m \\times m$ block is denoted by $H_{m} \\in \\mathbb{C}^{m \\times m}$. A Ritz pair $(\\lambda, u)$ with respect to the subspace $\\mathrm{range}(V_{m})$ satisfies $u = V_{m} y$ for some $y \\in \\mathbb{C}^{m}$ and the Galerkin condition that the residual $A u - \\lambda u$ is orthogonal to $\\mathrm{range}(V_{m})$. A harmonic Ritz pair $(\\theta, u)$ with respect to a complex shift $\\sigma \\in \\mathbb{C}$ satisfies $u = V_{m} y$ for some $y \\in \\mathbb{C}^{m}$ and the Petrov-Galerkin condition that the residual $A u - \\theta u$ is orthogonal to $(A - \\sigma I)\\mathrm{range}(V_{m})$.\n\nStarting from only the Arnoldi relation and these definitions, derive a reduced, $m \\times m$ generalized eigenvalue problem that produces harmonic Ritz values and vectors relative to the shift $\\sigma$ without explicitly forming $(A - \\sigma I) V_{m}$. Your derivation must depend solely on the small matrices $H_{m}$, $\\widehat{H}_{m}$, and the selector $E^{*} \\in \\mathbb{C}^{m \\times (m+1)}$ that extracts the first $m$ rows, i.e., $E^{*} = [\\,I_{m} \\;\\; 0\\,]$ so that $E^{*} \\widehat{H}_{m} = H_{m}$. Then, design and implement an algorithm that:\n- Computes $V_{m+1}$ and $\\widehat{H}_{m}$ by $m$ steps of Arnoldi for each test case.\n- Computes the Ritz values and vectors by solving the projected eigenproblem on $H_{m}$.\n- Computes the harmonic Ritz values and vectors by solving your derived reduced generalized eigenproblem that uses only $H_{m}$ and $\\widehat{H}_{m}$ (and not $(A - \\sigma I) V_{m}$).\n- For each test case, selects the Ritz and harmonic Ritz values closest to $\\sigma$ (in absolute difference), forms the corresponding approximate eigenvectors $u_{\\mathrm{ritz}}$ and $u_{\\mathrm{harm}}$, and reports their residual norms $\\lVert A u - \\lambda u \\rVert_{2}$ for the selected pairs.\n\nYour program must implement the full pipeline above and produce the requested outputs for the following test suite. All matrices, vectors, and scalars are given explicitly:\n- Test case $1$ (real symmetric, interior shift near the smallest eigenvalue):\n  - $n = 6$, \n  $$\n  A_{1} = \\begin{bmatrix}\n  2 & -1 & 0 & 0 & 0 & 0 \\\\\n  -1 & 2 & -1 & 0 & 0 & 0 \\\\\n  0 & -1 & 2 & -1 & 0 & 0 \\\\\n  0 & 0 & -1 & 2 & -1 & 0 \\\\\n  0 & 0 & 0 & -1 & 2 & -1 \\\\\n  0 & 0 & 0 & 0 & -1 & 2\n  \\end{bmatrix},\n  \\quad\n  b_{1} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix},\n  \\quad\n  m_{1} = 4,\n  \\quad\n  \\sigma_{1} = 0.1.\n  $$\n- Test case $2$ (real, non-Hermitian upper Hessenberg, shift near an interior eigenvalue):\n  - $n = 5$,\n  $$\n  A_{2} = \\begin{bmatrix}\n  4 & 1 & 0 & 0 & 0 \\\\\n  2 & 3 & 1 & 0 & 0 \\\\\n  0 & 2 & 3 & 1 & 0 \\\\\n  0 & 0 & 2 & 3 & 1 \\\\\n  0 & 0 & 0 & 2 & 3\n  \\end{bmatrix},\n  \\quad\n  b_{2} = \\frac{1}{\\sqrt{5}} \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix},\n  \\quad\n  m_{2} = 4,\n  \\quad\n  \\sigma_{2} = 2.9.\n  $$\n- Test case $3$ (complex, mildly non-normal, shift at a targeted eigenvalue):\n  - $n = 5$,\n  $$\n  A_{3} = \\begin{bmatrix}\n  1 + 2\\mathrm{i} & 0.1 & 0 & 0 & 0 \\\\\n  0 & 2 + \\mathrm{i} & 0.1 & 0 & 0 \\\\\n  0 & 0 & 3 + 0.5\\mathrm{i} & 0.1 & 0 \\\\\n  0 & 0 & 0 & 4 & 0.1 \\\\\n  0 & 0 & 0 & 0 & 5 - \\mathrm{i}\n  \\end{bmatrix},\n  \\quad\n  b_{3} = \\frac{1}{\\sqrt{5}} \\begin{bmatrix} 1 \\\\ \\mathrm{i} \\\\ 1 \\\\ -\\mathrm{i} \\\\ 1 \\end{bmatrix},\n  \\quad\n  m_{3} = 3,\n  \\quad\n  \\sigma_{3} = 3 + 0.5\\mathrm{i}.\n  $$\n\nFor each test case $j \\in \\{1,2,3\\}$, your program must:\n- Select the harmonic Ritz value $\\theta_{j}$ closest to $\\sigma_{j}$ and its vector $u_{\\mathrm{harm},j} = V_{m_{j}} y_{\\mathrm{harm},j}$, and compute the residual norm $r_{\\mathrm{harm},j} = \\lVert A_{j} u_{\\mathrm{harm},j} - \\theta_{j} u_{\\mathrm{harm},j} \\rVert_{2}$.\n- Select the Ritz value $\\lambda_{j}$ closest to $\\sigma_{j}$ and its vector $u_{\\mathrm{ritz},j} = V_{m_{j}} y_{\\mathrm{ritz},j}$, and compute the residual norm $r_{\\mathrm{ritz},j} = \\lVert A_{j} u_{\\mathrm{ritz},j} - \\lambda_{j} u_{\\mathrm{ritz},j} \\rVert_{2}$.\n\nFinal output format requirement:\n- Your program should produce a single line of output containing a Python-style list of length $3$, where each element is itself a list of length $4$ for a test case $j$, formatted as\n  $$\n  [ \\,\\mathrm{Re}(\\theta_{j}),\\ \\mathrm{Im}(\\theta_{j}),\\ r_{\\mathrm{harm},j},\\ r_{\\mathrm{ritz},j} - r_{\\mathrm{harm},j} \\,],\n  $$\n  with each number rounded to $8$ decimal places. The entire output should be one line, with no spaces, for example\n  $$\n  [[a_{11},a_{12},a_{13},a_{14}],[a_{21},a_{22},a_{23},a_{24}],[a_{31},a_{32},a_{33},a_{34}]].\n  $$\n\nScientific realism constraint:\n- You must derive the reduced generalized eigenproblem entirely from the Arnoldi relation and the stated orthogonality conditions. You must not use any prepackaged formulas for harmonic Ritz extraction that already encode the target conclusion, and you must not form $(A - \\sigma I)\\,V_{m}$ explicitly at any point. Your implementation must carry out the computation using only the small projected matrices available from Arnoldi.\n\nAll answers are in pure numbers (unitless). Angles and physical units are not involved in this problem. The final printed output must follow the exact format described above.", "solution": "The problem is valid. It is a well-posed problem in numerical linear algebra, based on established scientific principles and definitions of Krylov subspace methods. All data and conditions are provided and are consistent.\n\nThe solution involves two main parts: first, a derivation of the reduced eigenvalue problems for Ritz and harmonic Ritz pairs, and second, the implementation of an algorithm to compute these quantities and their corresponding residual norms for the given test cases.\n\n### Derivation of the Reduced Eigenvalue Problems\n\nLet $A \\in \\mathbb{C}^{n \\times n}$ be a matrix, and let $\\mathrm{range}(V_m)$ be an $m$-dimensional subspace spanned by the orthonormal columns of $V_m \\in \\mathbb{C}^{n \\times m}$. These columns form a basis for the Krylov subspace $\\mathcal{K}_m(A, b)$ generated by $m$ steps of the Arnoldi process starting with a vector $b$. The Arnoldi process produces the relation $A V_m = V_{m+1} \\widehat{H}_m$, where $V_{m+1} \\in \\mathbb{C}^{n \\times (m+1)}$ is an orthonormal basis and $\\widehat{H}_m \\in \\mathbb{C}^{(m+1) \\times m}$ is an upper Hessenberg matrix. The matrix $H_m \\in \\mathbb{C}^{m \\times m}$ consists of the first $m$ rows of $\\widehat{H}_m$.\n\n**1. Ritz Pairs**\n\nA Ritz pair $(\\lambda, u)$ with respect to the subspace $\\mathrm{range}(V_m)$ is defined by an approximate eigenvector $u = V_m y$ for some non-zero vector $y \\in \\mathbb{C}^m$ and the Galerkin condition, which states that the residual $r = A u - \\lambda u$ is orthogonal to the subspace $\\mathrm{range}(V_m)$. This condition is expressed as:\n$$ V_m^* (A u - \\lambda u) = 0 $$\nSubstituting $u = V_m y$:\n$$ V_m^* (A V_m y - \\lambda V_m y) = 0 $$\nDistributing $V_m^*$ and using the orthonormality of $V_m$'s columns ($V_m^* V_m = I_m$):\n$$ (V_m^* A V_m) y - \\lambda (V_m^* V_m) y = 0 $$\n$$ (V_m^* A V_m) y = \\lambda y $$\nTo simplify $V_m^* A V_m$, we use the Arnoldi relation. Let $E^* = [I_m \\;\\; 0] \\in \\mathbb{C}^{m \\times (m+1)}$ be the selector that extracts the first $m$ rows, such that $H_m = E^* \\widehat{H}_m$. We can also write $V_m = V_{m+1} E$, where $E = [I_m^T \\;\\; 0^T]^T$.\n$$ V_m^* A V_m = (V_{m+1} E)^* (V_{m+1} \\widehat{H}_m) = E^* V_{m+1}^* V_{m+1} \\widehat{H}_m $$\nSince $V_{m+1}$ is orthonormal, $V_{m+1}^* V_{m+1} = I_{m+1}$.\n$$ V_m^* A V_m = E^* \\widehat{H}_m = H_m $$\nThus, the Galerkin condition leads to the reduced standard eigenvalue problem of size $m \\times m$:\n$$ H_m y = \\lambda y $$\nThe eigenvalues $\\lambda$ of $H_m$ are the Ritz values, and the corresponding approximate eigenvectors are $u = V_m y$, where $y$ is an eigenvector of $H_m$.\n\n**2. Harmonic Ritz Pairs**\n\nA harmonic Ritz pair $(\\theta, u)$ with respect to a shift $\\sigma \\in \\mathbb{C}$ is defined by an approximate eigenvector $u = V_m y$ and the Petrov-Galerkin condition. This condition requires the residual $r = A u - \\theta u$ to be orthogonal to the test subspace $(A - \\sigma I)\\mathrm{range}(V_m)$. This is expressed as:\n$$ ((A - \\sigma I)V_m)^* (A u - \\theta u) = 0 $$\nSubstituting $u = V_m y$:\n$$ ((A - \\sigma I)V_m)^* (A V_m y - \\theta V_m y) = 0 $$\nThis equation must hold for any choice of basis in the test space, which leads to the matrix equation:\n$$ V_m^* (A^* - \\bar{\\sigma}I) (A - \\theta I) V_m y = 0 $$\nwhere $\\bar{\\sigma}$ is the complex conjugate of $\\sigma$. We expand the terms:\n$$ \\left( V_m^* A^* A V_m - \\theta V_m^* A^* V_m - \\bar{\\sigma} V_m^* A V_m + \\theta\\bar{\\sigma} V_m^* V_m \\right) y = 0 $$\nWe evaluate each projected matrix term using the Arnoldi relation:\n- $V_m^* V_m = I_m$ (by orthonormality).\n- $V_m^* A V_m = H_m$ (as shown for Ritz pairs).\n- $V_m^* A^* V_m = (V_m^* A V_m)^* = H_m^*$.\n- For the term $V_m^* A^* A V_m$, we use the full Arnoldi relation:\n$$ V_m^* A^* A V_m = (A V_m)^* (A V_m) = (V_{m+1} \\widehat{H}_m)^* (V_{m+1} \\widehat{H}_m) = \\widehat{H}_m^* V_{m+1}^* V_{m+1} \\widehat{H}_m = \\widehat{H}_m^* I_{m+1} \\widehat{H}_m = \\widehat{H}_m^* \\widehat{H}_m $$\nSubstituting these into the expanded equation yields:\n$$ \\left( \\widehat{H}_m^* \\widehat{H}_m - \\theta H_m^* - \\bar{\\sigma} H_m + \\theta\\bar{\\sigma} I_m \\right) y = 0 $$\nTo formulate this as a generalized eigenvalue problem for $\\theta$, we group the terms involving $\\theta$:\n$$ (\\widehat{H}_m^* \\widehat{H}_m - \\bar{\\sigma} H_m) y = \\theta (H_m^* - \\bar{\\sigma} I_m) y $$\nThis is the required $m \\times m$ generalized eigenvalue problem $K y = \\theta M y$, where the matrices $K$ and $M$ are:\n$$ K = \\widehat{H}_m^* \\widehat{H}_m - \\bar{\\sigma} H_m $$\n$$ M = H_m^* - \\bar{\\sigma} I_m $$\nThese matrices depend only on the products of the Arnoldi process, $\\widehat{H}_m$ and its submatrix $H_m$, and the shift $\\sigma$. This derivation successfully avoids the explicit formation or use of $(A - \\sigma I)V_m$.\n\n### Algorithm Implementation\n\nThe algorithm proceeds as follows for each test case $(A_j, b_j, m_j, \\sigma_j)$:\n1.  **Arnoldi Process**:\n    - An orthonormal basis $V_{m_j+1} \\in \\mathbb{C}^{n_j \\times (m_j+1)}$ for the Krylov subspace $\\mathcal{K}_{m_j+1}(A_j, b_j)$ and the upper Hessenberg matrix $\\widehat{H}_{m_j} \\in \\mathbb{C}^{(m_j+1) \\times m_j}$ are computed using $m_j$ steps of the Arnoldi iteration with modified Gram-Schmidt orthogonalization for numerical stability.\n2.  **Ritz Pair Calculation**:\n    - The matrix $H_{m_j}$ is extracted from the first $m_j$ rows of $\\widehat{H}_{m_j}$.\n    - The standard eigenproblem $H_{m_j} y = \\lambda y$ is solved to find the Ritz values $\\lambda$ and corresponding eigenvectors $y$.\n    - The Ritz value $\\lambda_j$ closest to the shift $\\sigma_j$ is selected.\n    - The full approximate eigenvector is reconstructed as $u_{\\mathrm{ritz},j} = V_{m_j} y_{\\mathrm{ritz},j}$, where $V_{m_j}$ contains the first $m_j$ columns of $V_{m_j+1}$. The vector $u_{\\mathrm{ritz},j}$ has unit norm.\n    - The residual norm $r_{\\mathrm{ritz},j} = \\lVert A_j u_{\\mathrm{ritz},j} - \\lambda_j u_{\\mathrm{ritz},j} \\rVert_{2}$ is computed.\n3.  **Harmonic Ritz Pair Calculation**:\n    - The matrices $K = \\widehat{H}_{m_j}^* \\widehat{H}_{m_j} - \\bar{\\sigma}_j H_{m_j}$ and $M = H_{m_j}^* - \\bar{\\sigma}_j I_{m_j}$ are formed.\n    - The generalized eigenproblem $K y = \\theta M y$ is solved for the harmonic Ritz values $\\theta$ and eigenvectors $y$.\n    - The harmonic Ritz value $\\theta_j$ closest to the shift $\\sigma_j$ is selected from the set of finite solutions.\n    - The full approximate eigenvector is reconstructed as $u_{\\mathrm{harm},j} = V_{m_j} y_{\\mathrm{harm},j}$. Since eigenvectors from a generalized eigenproblem are not necessarily of unit norm, $u_{\\mathrm{harm},j}$ is normalized to have unit norm for a fair comparison of residuals.\n    - The residual norm $r_{\\mathrm{harm},j} = \\lVert A_j u_{\\mathrm{harm},j} - \\theta_j u_{\\mathrm{harm},j} \\rVert_{2}$ is computed.\n4.  **Output Formatting**:\n    - For each test case, a list containing $[\\mathrm{Re}(\\theta_j), \\mathrm{Im}(\\theta_j), r_{\\mathrm{harm},j}, r_{\\mathrm{ritz},j} - r_{\\mathrm{harm},j}]$ is created, with each value rounded to $8$ decimal places.\n\nThe provided Python code implements this complete pipeline.", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import eig\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases, including Arnoldi iteration,\n    Ritz and Harmonic Ritz analysis, and residual norm computation.\n    \"\"\"\n    # Test case 1 data\n    A1 = np.array([\n        [2., -1., 0., 0., 0., 0.],\n        [-1., 2., -1., 0., 0., 0.],\n        [0., -1., 2., -1., 0., 0.],\n        [0., 0., -1., 2., -1., 0.],\n        [0., 0., 0., -1., 2., -1.],\n        [0., 0., 0., 0., -1., 2.]\n    ], dtype=np.float64)\n    b1 = np.array([1., 0., 0., 0., 0., 0.], dtype=np.float64)\n    m1 = 4\n    sigma1 = 0.1\n\n    # Test case 2 data\n    A2 = np.array([\n        [4., 1., 0., 0., 0.],\n        [2., 3., 1., 0., 0.],\n        [0., 2., 3., 1., 0.],\n        [0., 0., 2., 3., 1.],\n        [0., 0., 0., 2., 3.]\n    ], dtype=np.float64)\n    b2 = np.ones(5, dtype=np.float64) / np.sqrt(5)\n    m2 = 4\n    sigma2 = 2.9\n\n    # Test case 3 data\n    A3 = np.array([\n        [1. + 2.j, 0.1, 0., 0., 0.],\n        [0., 2. + 1.j, 0.1, 0., 0.],\n        [0., 0., 3. + 0.5j, 0.1, 0.],\n        [0., 0., 0., 4., 0.1],\n        [0., 0., 0., 0., 5. - 1.j]\n    ], dtype=np.complex128)\n    b3 = np.array([1., 1.j, 1., -1.j, 1.], dtype=np.complex128) / np.sqrt(5)\n    m3 = 3\n    sigma3 = 3. + 0.5j\n\n    test_cases = [ (A1, b1, m1, sigma1), (A2, b2, m2, sigma2), (A3, b3, m3, sigma3) ]\n    \n    final_results = []\n    \n    for A, b, m, sigma in test_cases:\n        n = A.shape[0]\n        dtype = A.dtype\n\n        # 1. Arnoldi Process using Modified Gram-Schmidt\n        V = np.zeros((n, m + 1), dtype=dtype)\n        H_hat = np.zeros((m + 1, m), dtype=dtype)\n        \n        V[:, 0] = b / np.linalg.norm(b)\n\n        for j in range(m):\n            w = A @ V[:, j]\n            for i in range(j + 1):\n                H_hat[i, j] = V[:, i].conj().T @ w\n                w = w - H_hat[i, j] * V[:, i]\n            \n            h_next = np.linalg.norm(w)\n            H_hat[j + 1, j] = h_next\n            \n            # Avoid division by zero in case of breakdown (unlikely for these tests)\n            if h_next > 1e-14:\n                V[:, j + 1] = w / h_next\n            # else: breakdown occurred, H_hat[j+1,j] is 0, V[:,j+1] is 0.\n\n        V_m = V[:, :m]\n        H_m = H_hat[:m, :m]\n\n        # 2. Ritz values and vectors\n        ritz_vals, ritz_vecs_y = eig(H_m)\n        idx_ritz = np.argmin(np.abs(ritz_vals - sigma))\n        lambda_ritz = ritz_vals[idx_ritz]\n        y_ritz = ritz_vecs_y[:, idx_ritz]\n        u_ritz = V_m @ y_ritz\n        # u_ritz is already unit norm as y_ritz is and V_m is orthonormal\n        r_ritz_norm = np.linalg.norm(A @ u_ritz - lambda_ritz * u_ritz)\n\n        # 3. Harmonic Ritz values and vectors\n        K = H_hat.conj().T @ H_hat - np.conj(sigma) * H_m\n        M = H_m.conj().T - np.conj(sigma) * np.eye(m, dtype=dtype)\n        \n        harm_vals, harm_vecs_y = eig(K, M)\n\n        # Filter out non-finite eigenvalues (e.g., inf) before finding the closest\n        finite_mask = np.isfinite(harm_vals)\n        finite_harm_vals = harm_vals[finite_mask]\n        finite_indices = np.where(finite_mask)[0]\n\n        if len(finite_harm_vals) == 0:\n             # Should not happen in this problem\n             raise ValueError(\"No finite harmonic Ritz values found.\")\n\n        idx_in_finite = np.argmin(np.abs(finite_harm_vals - sigma))\n        idx_harm = finite_indices[idx_in_finite]\n        \n        theta_harm = harm_vals[idx_harm]\n        y_harm = harm_vecs_y[:, idx_harm]\n\n        u_harm = V_m @ y_harm\n        # Normalize u_harm for fair residual comparison, as generalized eigenvectors are not unit-norm\n        u_harm = u_harm / np.linalg.norm(u_harm)\n        r_harm_norm = np.linalg.norm(A @ u_harm - theta_harm * u_harm)\n        \n        # 4. Store results with specified rounding\n        result_for_case = [\n            round(theta_harm.real, 8),\n            round(theta_harm.imag, 8),\n            round(r_harm_norm, 8),\n            round(r_ritz_norm - r_harm_norm, 8)\n        ]\n        final_results.append(result_for_case)\n\n    # Final print statement in the exact required format\n    print(str(final_results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "3574726"}, {"introduction": "Our final practice delves into the critical, real-world issue of numerical stability in Krylov subspace methods. While mathematical theory often assumes exact arithmetic, floating-point computations introduce subtle errors, such as a loss of orthogonality in the basis vectors. This exercise [@problem_id:3574756] explores the consequences of such numerical artifacts, demonstrating how they can degrade the quality of computed Ritz vectors even when the Ritz values themselves remain accurate, thereby highlighting the importance of robust implementation techniques like reorthogonalization.", "problem": "Let $A \\in \\mathbb{R}^{4 \\times 4}$ be the Hermitian matrix $A = \\operatorname{diag}(1,\\, 3,\\, 3 + \\delta,\\, 10^{3})$ with a small positive parameter $\\delta \\in \\mathbb{R}$, and let $b \\in \\mathbb{R}^{4}$ be the starting vector $b = \\frac{1}{2}[1,\\, 1,\\, 1,\\, 1]^{\\top}$. Consider the Krylov subspace of dimension $m = 3$, defined by $\\mathcal{K}_{3}(A, b) = \\operatorname{span}\\{b,\\, A b,\\, A^{2} b\\}$. Suppose the Arnoldi process is applied in exact arithmetic in two distinct computational regimes: (i) with full reorthogonalization, producing an orthonormal basis $Q \\in \\mathbb{R}^{4 \\times 3}$, and (ii) without reorthogonalization, which is modeled by a nearly orthonormal but not exactly orthonormal basis $U \\in \\mathbb{R}^{4 \\times 3}$ spanning the same subspace, with $U = Q T$, where\n$$\nT \\,=\\, \\begin{bmatrix}\n1 & \\varepsilon & 0 \\\\\n0 & 1 & \\varepsilon \\\\\n0 & 0 & 1\n\\end{bmatrix}, \\qquad \\varepsilon = 10^{-8}.\n$$\nIn both regimes, the same vector $b$ and matrix $A$ are used, so the trial subspace is identical, but the basis differs due to the presence or absence of reorthogonalization.\n\nRitz values are defined by the Rayleigh–Ritz condition $A u - \\theta u \\perp \\mathcal{K}_{3}(A, b)$, and harmonic Ritz values at zero shift are defined by the Petrov–Galerkin condition $A u - \\mu u \\perp A \\mathcal{K}_{3}(A, b)$, all in exact arithmetic. Assume that the numerical roundoff affects the basis but not the exact subspace, and that the modeling $U = Q T$ captures this effect for a small parameter $\\varepsilon$.\n\nTasks:\n1. Starting from the defining conditions of Rayleigh–Ritz and harmonic Rayleigh–Ritz for the trial subspace $\\mathcal{K}_{3}(A, b)$, derive the reduced problems that characterize:\n   - Ritz values as the generalized eigenvalues of the pencil $(U^{*} A U,\\, U^{*} U)$ when $U$ is an arbitrary basis of $\\mathcal{K}_{3}(A, b)$, and the standard eigenvalues of $Q^{*} A Q$ when $Q$ is an orthonormal basis.\n   - Harmonic Ritz values at zero shift as the generalized eigenvalues of $(U^{*} A^{2} U,\\, U^{*} A U)$ when $U$ is an arbitrary basis, and of $(Q^{*} A^{2} Q,\\, Q^{*} A Q)$ when $Q$ is an orthonormal basis.\n2. Using only the fact that $U = Q T$ with $T \\in \\mathbb{C}^{3 \\times 3}$ invertible and $Q^{*} Q = I$, prove that the sets of Ritz values and harmonic Ritz values are invariant under the change of basis within the same trial subspace. Your proof must proceed by analyzing the characteristic polynomials of the corresponding generalized eigenvalue problems and identifying a scalar constant multiplier that is independent of the spectral parameter.\n3. Explain, within this scenario, why the computed Ritz vectors $u = Q y$ and $u = U \\tilde{y}$ can differ significantly in quality (angle with a true eigenvector of $A$) between the two regimes, even though the computed Ritz values remain indistinguishable to within rounding errors. Your explanation must be tied to conditioning of the Gram matrix and the stability of the small projected problems.\n4. For the specific $T$ given above, compute the constant scalar ratio\n$$\nR(\\lambda) \\,=\\, \\frac{\\det\\!\\big(U^{*} A U - \\lambda\\, U^{*} U\\big)}{\\det\\!\\big(Q^{*} A Q - \\lambda\\, I\\big)}\n$$\nand report its value. No rounding is required.\n\nYour final answer must be the single value of $R(\\lambda)$, expressed exactly as a real number. No units are involved.", "solution": "The problem is validated as scientifically grounded, well-posed, objective, and self-contained. It is a standard problem in numerical linear algebra concerning Krylov subspace methods. We will proceed to solve the four tasks in order.\n\nLet $A \\in \\mathbb{R}^{4 \\times 4}$ be a Hermitian matrix, $\\mathcal{K}_{m}$ be a trial subspace of dimension $m=3$, and $u \\in \\mathcal{K}_{m}$ be a non-zero approximate eigenvector.\n\n**1. Derivation of the Reduced Problems**\n\nThis task requires deriving the eigenvalue problems that define the Ritz and harmonic Ritz values. Let $U \\in \\mathbb{C}^{n \\times m}$ be an arbitrary basis for the trial subspace $\\mathcal{K}_{m}$. Any vector $u \\in \\mathcal{K}_{m}$ can be written as $u = U y$ for some non-zero vector $y \\in \\mathbb{C}^{m}$.\n\n**Ritz Values:**\nThe Ritz values $\\theta$ and corresponding Ritz vectors $u$ are defined by the Rayleigh-Ritz condition, which is a Galerkin condition on the residual:\n$$\nA u - \\theta u \\perp \\mathcal{K}_{m}\n$$\nThis orthogonality condition means that for any vector $v \\in \\mathcal{K}_{m}$, the inner product $\\langle v, A u - \\theta u \\rangle = 0$. Since the columns of $U$ form a basis for $\\mathcal{K}_{m}$, this is equivalent to requiring that the residual be orthogonal to each basis vector:\n$$\nU^{*} (A u - \\theta u) = 0\n$$\nSubstituting $u = U y$, we obtain:\n$$\nU^{*} (A (U y) - \\theta (U y)) = 0\n$$\n$$\n(U^{*} A U) y - \\theta (U^{*} U) y = 0\n$$\nThis is a generalized eigenvalue problem for the matrix pencil $(U^{*} A U, U^{*} U)$. The Ritz values $\\theta$ are the generalized eigenvalues of this pencil.\n\nIf the basis is orthonormal, denoted by $Q$, then $Q^{*} Q = I_{m}$, where $I_{m}$ is the $m \\times m$ identity matrix. In this special case, the generalized eigenvalue problem simplifies to a standard eigenvalue problem:\n$$\n(Q^{*} A Q) y - \\theta (I_{m}) y = 0\n$$\n$$\n(Q^{*} A Q) y = \\theta y\n$$\nThus, for an orthonormal basis $Q$, the Ritz values are the standard eigenvalues of the projected matrix $H_{m} = Q^{*} A Q$.\n\n**Harmonic Ritz Values:**\nThe harmonic Ritz values $\\mu$ at zero shift and corresponding harmonic Ritz vectors $u$ are defined by the Petrov-Galerkin condition where the test subspace is $A \\mathcal{K}_{m}$:\n$$\nA u - \\mu u \\perp A \\mathcal{K}_{m}\n$$\nThe subspace $A \\mathcal{K}_{m}$ is spanned by the columns of the matrix $A U$. The orthogonality condition is thus equivalent to:\n$$\n(A U)^{*} (A u - \\mu u) = 0\n$$\nSince $A$ is Hermitian, $A^{*} = A$. The condition becomes:\n$$\nU^{*} A (A u - \\mu u) = 0\n$$\nSubstituting $u = U y$:\n$$\nU^{*} A (A (U y) - \\mu (U y)) = 0\n$$\n$$\n(U^{*} A^{2} U) y - \\mu (U^{*} A U) y = 0\n$$\nThis is a generalized eigenvalue problem for the matrix pencil $(U^{*} A^{2} U, U^{*} A U)$. The harmonic Ritz values $\\mu$ are the generalized eigenvalues of this pencil.\n\nIf the basis is orthonormal, $U = Q$, the problem becomes:\n$$\n(Q^{*} A^{2} Q) y = \\mu (Q^{*} A Q) y\n$$\nThis remains a generalized eigenvalue problem.\n\n**2. Invariance of Ritz and Harmonic Ritz Values Under Basis Change**\n\nLet $Q$ be an orthonormal basis for $\\mathcal{K}_{m}$, and let $U$ be any other basis for the same subspace. Then there exists an invertible matrix $T \\in \\mathbb{C}^{m \\times m}$ such that $U = Q T$.\n\n**Ritz Values Invariance:**\nThe Ritz values $\\theta$ are the roots of the characteristic polynomial of the respective eigenvalue problem.\nFor the orthonormal basis $Q$, the characteristic polynomial is:\n$$\np_{Q}(\\theta) = \\det(Q^{*} A Q - \\theta I)\n$$\nFor the arbitrary basis $U$, the characteristic polynomial is:\n$$\np_{U}(\\theta) = \\det(U^{*} A U - \\theta U^{*} U)\n$$\nSubstitute $U = Q T$ and $U^{*} = T^{*} Q^{*}$ into the expression for $p_{U}(\\theta)$:\n$$\np_{U}(\\theta) = \\det((T^{*} Q^{*}) A (Q T) - \\theta (T^{*} Q^{*}) (Q T))\n$$\nSince $Q^{*} Q = I$, this simplifies to:\n$$\np_{U}(\\theta) = \\det(T^{*} (Q^{*} A Q) T - \\theta T^{*} I T)\n$$\n$$\np_{U}(\\theta) = \\det(T^{*} (Q^{*} A Q) T - T^{*} (\\theta I) T)\n$$\nUsing the distributivity of matrix multiplication, we can factor out $T^{*}$ and $T$:\n$$\np_{U}(\\theta) = \\det(T^{*} (Q^{*} A Q - \\theta I) T)\n$$\nUsing the property $\\det(BCD) = \\det(B)\\det(C)\\det(D)$, we get:\n$$\np_{U}(\\theta) = \\det(T^{*}) \\det(Q^{*} A Q - \\theta I) \\det(T)\n$$\n$$\np_{U}(\\theta) = \\det(T^{*}) \\det(T) \\, p_{Q}(\\theta)\n$$\nSince $T$ is a complex matrix, $\\det(T^{*}) = \\overline{\\det(T)}$. Therefore, the scalar multiplier is $\\det(T^{*})\\det(T) = |\\det(T)|^{2}$. As $T$ is invertible, $\\det(T) \\neq 0$, so $|\\det(T)|^{2}$ is a non-zero constant independent of the spectral parameter $\\theta$.\nThe equation $p_{U}(\\theta) = |\\det(T)|^{2} p_{Q}(\\theta)$ shows that the polynomials $p_{U}(\\theta)$ and $p_{Q}(\\theta)$ have the exact same roots. Thus, the set of Ritz values is invariant under a change of basis of the trial subspace.\n\n**Harmonic Ritz Values Invariance:**\nA similar argument applies. For basis $Q$, the characteristic polynomial is $g_{Q}(\\mu) = \\det(Q^{*} A^{2} Q - \\mu Q^{*} A Q)$. For basis $U=QT$, it is $g_{U}(\\mu) = \\det(U^{*} A^{2} U - \\mu U^{*} A U)$.\nSubstituting $U=QT$:\n$$\ng_{U}(\\mu) = \\det(T^{*} (Q^{*} A^{2} Q) T - \\mu T^{*} (Q^{*} A Q) T)\n$$\n$$\ng_{U}(\\mu) = \\det(T^{*} (Q^{*} A^{2} Q - \\mu Q^{*} A Q) T)\n$$\n$$\ng_{U}(\\mu) = \\det(T^{*}) \\det(Q^{*} A^{2} Q - \\mu Q^{*} A Q) \\det(T)\n$$\n$$\ng_{U}(\\mu) = |\\det(T)|^{2} g_{Q}(\\mu)\n$$\nAgain, the roots of $g_{U}(\\mu)$ and $g_{Q}(\\mu)$ are identical. The set of harmonic Ritz values is also invariant under a change of basis.\n\n**3. Difference in Quality of Computed Ritz Vectors**\n\nThe invariance of Ritz values and vectors is a result of exact arithmetic. In finite precision, the quality of the computed Ritz vectors can differ substantially.\nThe Ritz vector $u$ is computed in two steps: first, solving a projected eigenvalue problem for the coordinate vector $y$ (or $\\tilde{y}$), and second, forming the linear combination $u=Qy$ (or $u=U\\tilde{y}$).\n\nIn the case of full reorthogonalization, the basis $Q$ is orthonormal ($Q^{*}Q = I$). The Ritz values and vectors are found by solving the standard eigenvalue problem $(Q^{*}AQ)y = \\theta y$. Since $A$ is Hermitian, the projected matrix $H = Q^{*}AQ$ is also Hermitian. The eigenvalue problem for a Hermitian matrix is well-conditioned with respect to the computation of its eigenvectors. Thus, the computed vector $y_{computed}$ will be very close to the exact eigenvector $y_{exact}$, and the resulting Ritz vector $u = Q y_{computed}$ will be a high-quality approximation to an eigenvector of $A$.\n\nIn the case without reorthogonalization, the basis $U$ is not orthonormal. The loss of orthogonality means that the basis vectors (columns of $U$) become nearly linearly dependent. The measure of this is the conditioning of the Gram matrix $N = U^{*}U$. If the columns of $U$ are nearly dependent, $N$ is ill-conditioned, i.e., its condition number $\\kappa(N) = \\|N\\|_{2}\\|N^{-1}\\|_{2}$ is very large.\nThe Ritz vectors are found by solving the generalized eigenvalue problem $(U^{*}AU)\\tilde{y} = \\theta (U^{*}U)\\tilde{y}$. Numerically solving a generalized eigenvalue problem $(M, N)\\tilde{y} = \\theta \\tilde{y}$ is known to be an unstable task when the matrix $N$ is ill-conditioned (close to singular). Small perturbations in $M=U^{*}AU$ and $N=U^{*}U$ from floating-point arithmetic can cause large errors in the computed eigenvector $\\tilde{y}_{computed}$.\nEven though in exact arithmetic $u = U \\tilde{y} = (QT)(T^{-1}y) = Qy$, the computational path is different and numerically unstable. The large error in $\\tilde{y}_{computed}$ propagates to the final computed Ritz vector $u_{computed} = U \\tilde{y}_{computed}$, making it a poor approximation of the true eigenvector of $A$. In contrast, the eigenvalues (Ritz values) are often much less sensitive to such perturbations and are computed with high relative accuracy, which explains why they can be indistinguishable between the two regimes while the vectors differ significantly in quality.\n\n**4. Computation of the Constant Scalar Ratio**\n\nThe task is to compute the value of the constant scalar ratio:\n$$\nR(\\lambda) \\,=\\, \\frac{\\det\\!\\big(U^{*} A U - \\lambda\\, U^{*} U\\big)}{\\det\\!\\big(Q^{*} A Q - \\lambda\\, I\\big)}\n$$\nFrom the proof in Task 2, we have already established the relationship between the numerator and the denominator. The numerator is the characteristic polynomial for the basis $U$, $p_{U}(\\lambda)$, and the denominator is the characteristic polynomial for the basis $Q$, $p_{Q}(\\lambda)$. The relationship is:\n$$\n\\det(U^{*} A U - \\lambda\\, U^{*} U) = \\det(T^{*}) \\det(T) \\det(Q^{*} A Q - \\lambda\\, I)\n$$\nTherefore, the ratio $R(\\lambda)$ is:\n$$\nR(\\lambda) = \\frac{\\det(T^{*}) \\det(T) \\det(Q^{*} A Q - \\lambda\\, I)}{\\det(Q^{*} A Q - \\lambda\\, I)} = \\det(T^{*}) \\det(T)\n$$\nThe problem specifies the matrix $T$ as:\n$$\nT \\,=\\, \\begin{bmatrix}\n1 & \\varepsilon & 0 \\\\\n0 & 1 & \\varepsilon \\\\\n0 & 0 & 1\n\\end{bmatrix}\n$$\nwhere $\\varepsilon = 10^{-8}$. Although the problem states $T \\in \\mathbb{C}^{3 \\times 3}$, the entries given are real, so $T$ is a real matrix. In this case, the conjugate transpose $T^{*}$ is the same as the transpose $T^{\\top}$.\n$$\n\\det(T^{*}) = \\det(T^{\\top}) = \\det(T)\n$$\nThus, the ratio is $R(\\lambda) = (\\det(T))^{2}$.\nThe matrix $T$ is an upper triangular matrix. Its determinant is the product of its diagonal elements:\n$$\n\\det(T) = 1 \\cdot 1 \\cdot 1 = 1\n$$\nTherefore, the constant scalar ratio is:\n$$\nR(\\lambda) = (1)^{2} = 1\n$$\nThis result is independent of the value of $\\varepsilon$, as long as $T$ is structured this way.", "answer": "$$\\boxed{1}$$", "id": "3574756"}]}