{"hands_on_practices": [{"introduction": "The efficiency of many iterative solvers for Toeplitz systems relies on performing the matrix-vector multiplication (MVM) quickly. The standard technique involves embedding the Toeplitz matrix into a larger circulant matrix, allowing the MVM to be computed as a convolution using the Fast Fourier Transform (FFT). This practice [@problem_id:3545696] guides you through optimizing this process, exploring the critical trade-off between computational cost and the approximation error that arises from the circulant embedding.", "problem": "Consider a family of symmetric Toeplitz matrices of size $n \\times n$ generated by a two-sided Fourier series symbol $g(\\theta)$ on $[0,2\\pi)$, defined via real, nonnegative Fourier coefficients $\\{t_k\\}_{k \\in \\mathbb{N}_0}$ satisfying $t_{-k} = t_k$. The Toeplitz matrix $T_n$ has entries $(T_n)_{ij} = t_{\\lvert i-j \\rvert}$ for $1 \\leq i,j \\leq n$. The task is to compute the matrix-vector product $y = T_n x$ efficiently using a circulant embedding and the Fast Fourier Transform (FFT), and to optimize the embedding size to minimize aliasing effects.\n\nFundamental base:\n- The Discrete Fourier Transform (DFT) diagonalizes circulant matrices. Circular convolution of a length-$m$ kernel with a length-$m$ vector is computable in $\\mathcal{O}(m \\log m)$ by FFT.\n- The Fourier series representation $g(\\theta) = \\sum_{k \\in \\mathbb{Z}} t_k \\mathrm{e}^{-\\mathrm{i} k \\theta}$ with $t_{-k}=t_k$ defines a translation-invariant kernel on the cyclic group of order $m$. Sampling $g(\\theta)$ on an $m$-point grid yields a circulant whose time-domain kernel equals the periodic summation of the Fourier coefficients.\n\nAliasing and periodic summation principle:\n- Sampling $g(\\theta)$ at $m$ equispaced points and applying the inverse DFT yields a time-domain sequence $c[r]$ ($0 \\leq r  m$) equal to the periodic summation of the Fourier coefficients:\n$$\nc[r] = \\sum_{\\ell \\in \\mathbb{Z}} t_{\\lvert r + \\ell m \\rvert}.\n$$\n- Computing the circular convolution of $c$ with a zero-padded $x$ approximates $T_n x$. The difference relative to the exact Toeplitz product can be bounded in terms of aliasing error arising from the periodic summation tail.\n\nSymbol smoothness models:\n- Exponential decay (analytic symbol): $t_k = C \\mathrm{e}^{-\\alpha k}$ for $k \\geq 0$, with parameters $C > 0$, $\\alpha > 0$.\n- Algebraic decay (finite smoothness): $t_k = C (1+k)^{-p}$ for $k \\geq 0$, with parameters $C > 0$, $p > 1$.\n\nAliasing error bounds for the periodic summation of $\\{t_k\\}$:\n- For exponential decay, the periodic aliasing tail for any fixed $r$ is bounded by\n$$\nE_{\\mathrm{alias}}^{\\mathrm{exp}}(m) \\leq 2 C \\frac{\\mathrm{e}^{-\\alpha m}}{1 - \\mathrm{e}^{-\\alpha m}}.\n$$\n- For algebraic decay, the periodic aliasing tail for any fixed $r$ is bounded by\n$$\nE_{\\mathrm{alias}}^{\\mathrm{alg}}(m) \\leq 2 C \\zeta(p) m^{-p},\n$$\nwhere $\\zeta(p)$ is the Riemann zeta function evaluated at $p$.\n\nOptimization objective:\n- Given $n$, a smoothness model with known parameters, and a tolerance $\\varepsilon$, choose the smallest power-of-two embedding size $m$ such that the aliasing bound for the chosen model is at most $\\varepsilon$, while ensuring $m \\geq 2n$ so that the circular convolution window covers the linear range without wrap-around of the input.\n\nImplementation details:\n- Construct the periodic kernel $c[r]$ using the identity $c[r] = \\sum_{\\ell \\in \\mathbb{Z}} t_{\\lvert r + \\ell m \\rvert}$, truncated by neglecting terms below a threshold $\\tau$. Because $t_k$ is monotone decreasing in $k$ under both models, a simple loop over $\\ell \\geq 1$ suffices, stopping when both $t_{r + \\ell m}$ and $t_{\\ell m - r}$ fall below $\\tau$. For $r=0$, use $c[0] = t_0 + 2\\sum_{\\ell \\geq 1} t_{\\ell m}$ truncated at $\\tau$.\n- Compute the approximate product $y_{\\mathrm{FFT}}$ by circular convolution of $c$ with $x$ zero-padded to length $m$ using FFT.\n- Compute the exact product $y_{\\mathrm{exact}}$ by direct summation $y_i = \\sum_{j=1}^n t_{\\lvert i-j \\rvert} x_j$.\n- Measure the relative error $\\|y_{\\mathrm{FFT}} - y_{\\mathrm{exact}}\\|_{\\infty}/\\|y_{\\mathrm{exact}}\\|_{\\infty}$.\n\nTest suite:\nFor each test case below, use tolerance $\\varepsilon = 10^{-8}$ and truncation threshold $\\tau = 10^{-12}$.\n\n1. Exponential decay (analytic symbol):\n   - $n = 64$, $C = 1$, $\\alpha = 0.5$.\n2. Algebraic decay (finite smoothness):\n   - $n = 64$, $C = 1$, $p = 2.2$.\n3. Exponential decay (analytic symbol, faster):\n   - $n = 128$, $C = 1$, $\\alpha = 1.0$.\n4. Algebraic decay (finite smoothness, smoother):\n   - $n = 128$, $C = 1$, $p = 3.0$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each result is the relative $\\ell_{\\infty}$ error (a float) for the corresponding test case, in the same order as listed above. For example: \"[e1,e2,e3,e4]\".", "solution": "The user has provided a problem in the domain of numerical linear algebra, specifically concerning the fast computation of a matrix-vector product for a symmetric Toeplitz matrix $T_n$. The proposed method involves embedding the $n \\times n$ Toeplitz matrix into a larger $m \\times m$ circulant matrix and using the Fast Fourier Transform (FFT) to perform the convolution efficiently in $\\mathcal{O}(m \\log m)$ time.\n\n### Step 1: Problem Validation\n\nThe problem is subjected to rigorous validation before a solution is attempted.\n\n-   **Extraction of Givens**:\n    -   **Matrix**: Symmetric Toeplitz matrix $T_n$ of size $n \\times n$, with entries $(T_n)_{ij} = t_{|i-j|}$.\n    -   **Coefficients**: The sequence $\\{t_k\\}_{k \\in \\mathbb{N}_0}$ is real, nonnegative, and even ($t_{-k} = t_k$).\n    -   **Task**: Compute $y = T_n x$ using a circulant embedding of size $m \\times m$ and FFT.\n    -   **Circulant Kernel**: The first column of the circulant matrix, $c$, is defined by the periodic summation $c[r] = \\sum_{\\ell \\in \\mathbb{Z}} t_{|r + \\ell m|}$.\n    -   **Coefficient Decay Models**:\n        1.  Exponential (analytic): $t_k = C \\mathrm{e}^{-\\alpha k}$ for $k \\geq 0$, with $C > 0, \\alpha > 0$.\n        2.  Algebraic (finite smoothness): $t_k = C (1+k)^{-p}$ for $k \\geq 0$, with $C > 0, p > 1$.\n    -   **Aliasing Error Bounds**: Explicit formulas are provided for the error in the circulant kernel due to periodic summation for each decay model.\n        -   Exponential: $E_{\\mathrm{alias}}^{\\mathrm{exp}}(m) \\leq 2 C \\frac{\\mathrm{e}^{-\\alpha m}}{1 - \\mathrm{e}^{-\\alpha m}}$.\n        -   Algebraic: $E_{\\mathrm{alias}}^{\\mathrm{alg}}(m) \\leq 2 C \\zeta(p) m^{-p}$.\n    -   **Optimization Goal**: For a given $n$, decay model, and tolerance $\\varepsilon$, find the smallest power-of-two integer $m$ such that $m \\geq 2n$ and the corresponding aliasing error bound is no more than $\\varepsilon$.\n    -   **Implementation Details**:\n        -   Kernel construction involves truncating the summation for $c[r]$ when terms fall below a threshold $\\tau$.\n        -   The final error is measured by the relative $\\ell_{\\infty}$ norm: $\\|y_{\\mathrm{FFT}} - y_{\\mathrm{exact}}\\|_{\\infty}/\\|y_{\\mathrm{exact}}\\|_{\\infty}$.\n    -   **Test Suite Parameters**: Four test cases are specified with values for $n$, $C$, $\\alpha$, $p$. Tolerances are given as $\\varepsilon = 10^{-8}$ and $\\tau = 10^{-12}$.\n\n-   **Validation Verdict**:\n    -   **Scientifically Grounded**: The problem is a classic application of Fourier analysis in numerical linear algebra. The use of circulant preconditioners and fast convolution for Toeplitz systems is a well-established, fundamental technique. The connection between the symbol's smoothness (decay of Fourier coefficients) and the convergence of the circulant approximation is a core concept in the field. The provided error bounds are standard results. The problem is scientifically and mathematically sound.\n    -   **Well-Posed and Complete**: The problem is clearly defined. All necessary parameters, models, and objectives are specified. The optimization goal for the embedding size $m$ is unambiguous. The only unspecified element is the input vector $x$. In the context of testing a numerical algorithm's accuracy, a standard practice is to use a fixed or random vector. Using a vector of pseudorandom numbers (generated from a fixed seed for reproducibility) is a valid and standard approach to complete the problem specification.\n    -   **Objective**: The language is precise and mathematical, free from any subjectivity or ambiguity.\n\nThe problem is deemed **valid**. It is a well-posed, scientifically grounded exercise in computational mathematics. The solution can proceed.\n\n### Step 2: Solution Derivation\n\nThe solution involves implementing the described algorithm for each of the four test cases. A random vector $x$ will be generated for each test case to perform the computations. For reproducibility, a single pseudorandom number generator with a fixed seed is used.\n\n**Algorithm Outline for Each Test Case:**\n\n1.  **Parameter Setup**: Isolate the parameters for the current test case: $n$, the model type ('exponential' or 'algebraic'), and the model parameters ($C, \\alpha$ or $C, p$). Set the tolerances $\\varepsilon = 10^{-8}$ and $\\tau = 10^{-12}$.\n\n2.  **Determine Embedding Size $m$**:\n    -   Initialize $m$ to be the smallest power of two that is greater than or equal to $2n$. This ensures that linear convolution is correctly computed without wrap-around effects.\n    -   Enter a loop:\n        -   Calculate the aliasing error bound based on the specified model for the current $m$. For the algebraic model, this requires the Riemann zeta function $\\zeta(p)$, available in `scipy.special`.\n        -   If the calculated bound is less than or equal to the tolerance $\\varepsilon$, exit the loop.\n        -   Otherwise, double the value of $m$ and continue the loop.\n\n3.  **Generate Test Data**:\n    -   Create the input vector $x$ of size $n$ with random entries drawn from a uniform distribution on $[0, 1)$.\n    -   Define a helper function, `t_k_func(k)`, which evaluates the coefficient $t_k$ according to the specified decay model.\n\n4.  **Compute Exact Product $y_{\\mathrm{exact}}$**:\n    -   Generate the first column of the Toeplitz matrix $T_n$, which consists of $[t_0, t_1, \\dots, t_{n-1}]$.\n    -   Construct the full $n \\times n$ symmetric Toeplitz matrix $T_n$ using the function `scipy.linalg.toeplitz`.\n    -   Compute the exact matrix-vector product $y_{\\mathrm{exact}} = T_n x$.\n\n5.  **Compute Approximate Product $y_{\\mathrm{FFT}}$**:\n    -   **Construct Circulant Kernel $c$**: Create a vector $c$ of length $m$. Based on the identity $c[r] = \\sum_{\\ell \\in \\mathbb{Z}} t_{|r+\\ell m|}$ and the evenness of $t_k$, $c$ is also even with respect to the midpoint $m/2$, i.e., $c[r] = c[m-r]$. This symmetry is exploited for efficiency.\n        -   Compute $c[r]$ for $r \\in [0, m/2]$ by summing the series $t_r + \\sum_{\\ell=1}^{\\infty} (t_{\\ell m - r} + t_{\\ell m + r})$ (with a special form for $r=0$). The summation over $\\ell$ is truncated when the term to be added falls below the threshold $\\tau$.\n        -   Populate the remaining entries $c[r]$ for $r \\in (m/2, m)$ using the symmetry $c[r] = c[m-r]$.\n    -   **Circular Convolution by FFT**:\n        -   Zero-pad the input vector $x$ to length $m$.\n        -   Compute the DFTs of the kernel $c$ and the padded vector $x$ using `numpy.fft.fft`.\n        -   Multiply the DFTs element-wise.\n        -   Compute the inverse DFT of the product using `numpy.fft.ifft`. The result is the circular convolution.\n        -   Extract the first $n$ components of the resulting vector and take its real part (to discard negligible imaginary components arising from floating-point inaccuracies). This is the approximate product $y_{\\mathrm{FFT}}$.\n\n6.  **Compute Relative Error**: Calculate the relative error using the $\\ell_{\\infty}$-norm:\n    $$\n    \\text{error} = \\frac{\\|y_{\\mathrm{FFT}} - y_{\\mathrm{exact}}\\|_{\\infty}}{\\|y_{\\mathrm{exact}}\\|_{\\infty}}\n    $$\n    A check is made to handle the case where $\\|y_{\\mathrm{exact}}\\|_{\\infty}$ might be zero.\n\n7.  **Store and Report**: The computed error is stored. After all test cases are processed, the results are formatted into a single string as specified.\n\nThis systematic procedure is implemented in the Python code provided in the final answer.", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import toeplitz\nfrom scipy.special import zeta\n\ndef solve():\n    \"\"\"\n    Computes the matrix-vector product y = T_n x for a symmetric Toeplitz\n    matrix T_n using a circulant embedding and FFT, and evaluates the\n    accuracy against a direct computation.\n    \"\"\"\n    # Define problem constants and test suite\n    TOL_EPS = 1e-8\n    TOL_TAU = 1e-12\n\n    test_cases = [\n        {'n': 64, 'model': 'exponential', 'params': {'C': 1.0, 'alpha': 0.5}},\n        {'n': 64, 'model': 'algebraic', 'params': {'C': 1.0, 'p': 2.2}},\n        {'n': 128, 'model': 'exponential', 'params': {'C': 1.0, 'alpha': 1.0}},\n        {'n': 128, 'model': 'algebraic', 'params': {'C': 1.0, 'p': 3.0}},\n    ]\n\n    results = []\n    # Use a seeded random number generator for reproducible results\n    rng = np.random.default_rng(12345)\n\n    for case in test_cases:\n        n = case['n']\n        model = case['model']\n        params = case['params']\n\n        # Define the tk generator function based on the model\n        if model == 'exponential':\n            C, alpha = params['C'], params['alpha']\n            t_k_func = lambda k: C * np.exp(-alpha * np.abs(k))\n        else: # algebraic\n            C, p = params['C'], params['p']\n            t_k_func = lambda k: C * (1 + np.abs(k))**(-p)\n\n        # 1. Determine the optimal embedding size m\n        # Smallest power of two >= 2n\n        m = 1  (2 * n - 1).bit_length()\n        while True:\n            if model == 'exponential':\n                bound = 2 * C * np.exp(-alpha * m) / (1 - np.exp(-alpha * m))\n            else: # algebraic\n                bound = 2 * C * zeta(p) * (m**(-p))\n            \n            if bound = TOL_EPS:\n                break\n            m *= 2\n            \n        # 2. Generate test vector x\n        x = rng.random(n)\n        \n        # 3. Compute the exact matrix-vector product\n        t_coeffs = t_k_func(np.arange(n))\n        T_n = toeplitz(t_coeffs)\n        y_exact = T_n @ x\n\n        # 4. Compute the approximate product using FFT\n        # 4.1 Construct the circulant kernel c\n        c = np.zeros(m)\n        \n        # Compute c[0] through c[m/2] by summing the periodic terms\n        for r in range(m // 2 + 1):\n            c[r] = t_k_func(r)\n            ell = 1\n            while True:\n                if r == 0:\n                    # For r=0, term is t(lm) + t(-lm) = 2*t(lm)\n                    term = 2 * t_k_func(ell * m)\n                else:\n                    # For r>0, term is t(lm+r) + t(lm-r)\n                    term = t_k_func(ell * m - r) + t_k_func(ell * m + r)\n                \n                if term  TOL_TAU:\n                    break\n                \n                c[r] += term\n                ell += 1\n        \n        # Exploit symmetry c[r] = c[m-r] for the other half of the kernel\n        for r in range(1, m // 2):\n            c[m - r] = c[r]\n\n        # 4.2 Perform circular convolution via FFT\n        x_pad = np.zeros(m)\n        x_pad[:n] = x\n        \n        y_pad = np.fft.ifft(np.fft.fft(c) * np.fft.fft(x_pad))\n        # Result should be real; take real part to discard numerical noise\n        y_fft = np.real(y_pad[:n])\n        \n        # 5. Calculate the relative l-infinity error\n        norm_y_exact = np.linalg.norm(y_exact, np.inf)\n        if norm_y_exact == 0:\n            error = 0.0\n        else:\n            error = np.linalg.norm(y_fft - y_exact, np.inf) / norm_y_exact\n            \n        results.append(error)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3545696"}, {"introduction": "While fast MVMs are building blocks for iterative methods, direct solvers for Toeplitz systems like the Levinson-Durbin recursion offer an alternative. However, their performance on ill-conditioned systems, which often arise from symbols with zeros on the unit circle, can be fragile. This experiment [@problem_id:3545692] pits the non-pivoted Levinson-Durbin algorithm against a robust, pivoted solver to practically investigate and quantify the crucial concepts of numerical stability and accuracy.", "problem": "Construct a family of Hermitian Toeplitz linear systems from a symbol with zeros on the unit circle and design a parameterized experiment to compare numerical stability and accuracy between the Levinson–Durbin recursion and the Gohberg–Kailath–Olshevsky (GKO) paradigm as the zero approaches $\\{e^{\\pm i\\theta_0}\\}$. Begin from the following foundational base.\n\nA Toeplitz matrix $T_n(f)$ of size $n\\times n$ is generated by a $2\\pi$-periodic symbol $f(\\theta)$ via its Fourier coefficients. For a function $f(\\theta)$, the Fourier coefficients are $c_k = \\frac{1}{2\\pi}\\int_0^{2\\pi} f(\\theta)e^{-ik\\theta}\\,d\\theta$ for integers $k$, and the Toeplitz matrix is defined by $[T_n(f)]_{ij} = c_{i-j}$ for $i,j \\in \\{1,2,\\dots,n\\}$ with the convention $c_{-k} = \\overline{c_k}$ to ensure Hermitian structure.\n\nConsider the family of symbols\n$$\nf_{\\delta,\\theta_0}(\\theta) = \\delta + 2 - 2\\cos(\\theta - \\theta_0),\n$$\nwhere $\\delta > 0$ is a small parameter and $\\theta_0 \\in (0,\\pi)$ is fixed. The function $f_{\\delta,\\theta_0}(\\theta)$ is nonnegative for all $\\theta$ and has a zero at $\\theta = \\theta_0$ when $\\delta = 0$, hence the associated Toeplitz matrices become increasingly ill-conditioned as $\\delta \\to 0^+$. Derive the Fourier coefficients of $f_{\\delta,\\theta_0}(\\theta)$ and use them to construct a Hermitian Toeplitz matrix $T_n(f_{\\delta,\\theta_0})$ with first column $c$ and first row $r$. Choose a deterministic nonzero target solution vector $x_{\\text{true}} \\in \\mathbb{C}^n$, form the right-hand side $b = T_n(f_{\\delta,\\theta_0}) x_{\\text{true}}$, and solve the system $T_n(f_{\\delta,\\theta_0}) x = b$ by two methods:\n- Levinson–Durbin recursion specialized for Hermitian Toeplitz matrices.\n- A Gohberg–Kailath–Olshevsky (GKO)-style pivoted approach. For this experiment, you must emulate the pivoting and robustness of GKO by applying classical Gaussian elimination with partial pivoting to the dense Toeplitz matrix, accepting the loss of fast complexity but focusing on stability and accuracy as the zero approaches the unit circle.\n\nFor each solution $\\hat{x}$ computed by a method, evaluate the following quantifiable metrics:\n1. The relative solution error $E = \\frac{\\| \\hat{x} - x_{\\text{true}} \\|_2}{\\| x_{\\text{true}} \\|_2}$.\n2. The relative residual norm $R = \\frac{\\| b - T_n(f_{\\delta,\\theta_0}) \\hat{x} \\|_2}{\\| b \\|_2}$.\n3. The $2$-norm condition number $\\kappa_2(T_n(f_{\\delta,\\theta_0})) = \\|T_n(f_{\\delta,\\theta_0})\\|_2 \\cdot \\|T_n(f_{\\delta,\\theta_0})^{-1}\\|_2$.\n\nDesign and run a parameterized experiment with the following test suite of $(n,\\theta_0,\\delta)$ values to probe stability and accuracy over a range of conditioning levels and angles:\n- Test case $1$: $(n,\\theta_0,\\delta) = (32,\\frac{\\pi}{4},10^{-2})$.\n- Test case $2$: $(n,\\theta_0,\\delta) = (64,\\frac{\\pi}{3},10^{-6})$.\n- Test case $3$: $(n,\\theta_0,\\delta) = (64,0.01,10^{-8})$.\n- Test case $4$: $(n,\\theta_0,\\delta) = (16,\\pi - 0.01,10^{-9})$.\n- Test case $5$: $(n,\\theta_0,\\delta) = (8,\\frac{\\pi}{6},10^{-12})$.\n\nFor reproducibility, select a deterministic nonzero $x_{\\text{true}}$ defined by\n$$\nx_{\\text{true}}[j] = \\sin\\left(\\frac{2\\pi j}{n}\\right) + \\frac{1}{2}\\cos\\left(\\frac{4\\pi j}{n}\\right), \\quad j=0,1,\\dots,n-1,\n$$\nand treat it as a real vector embedded in $\\mathbb{C}^n$.\n\nYour program must:\n- Construct $T_n(f_{\\delta,\\theta_0})$ exactly from the derived Fourier coefficients for each test case.\n- Compute $b$ from $x_{\\text{true}}$.\n- Solve the system by Levinson–Durbin recursion and by pivoted Gaussian elimination (as a GKO-style stability proxy).\n- Compute the three metrics $(E,R,\\kappa_2)$ for each method and matrix.\n- Produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, output five floating-point numbers in the order:\n$$\n\\left[E_{\\text{LD}},E_{\\text{GKO}},R_{\\text{LD}},R_{\\text{GKO}},\\kappa_2\\right],\n$$\nand concatenate these groups across the five test cases into a single flat list. For example, the final output format must be\n$$\n\\left[ E_{\\text{LD}}^{(1)}, E_{\\text{GKO}}^{(1)}, R_{\\text{LD}}^{(1)}, R_{\\text{GKO}}^{(1)}, \\kappa_2^{(1)}, \\dots, E_{\\text{LD}}^{(5)}, E_{\\text{GKO}}^{(5)}, R_{\\text{LD}}^{(5)}, R_{\\text{GKO}}^{(5)}, \\kappa_2^{(5)} \\right].\n$$\nNo physical units are involved, and all angles are in radians. The output must be exactly one line with the list format described and values represented as decimal floating-point numbers.", "solution": "The user-provided problem is valid. It is scientifically grounded in numerical linear algebra, specifically concerning structured linear systems. The setup is well-posed: for $\\delta > 0$, the symbol $f_{\\delta,\\theta_0}(\\theta)$ is strictly positive, guaranteeing that the Hermitian Toeplitz matrix $T_n(f)$ is positive definite and thus invertible. All definitions, parameters, and experimental goals are specified precisely and objectively, forming a complete and non-contradictory problem statement.\n\n### Step 1: Derivation of Fourier Coefficients and Matrix Structure\n\nThe problem requires constructing a family of Hermitian Toeplitz matrices $T_n(f_{\\delta,\\theta_0})$ from the symbol $f_{\\delta,\\theta_0}(\\theta) = \\delta + 2 - 2\\cos(\\theta - \\theta_0)$. The elements of the Toeplitz matrix, $[T_n(f)]_{ij} = c_{i-j}$, are the Fourier coefficients of the symbol $f$. The $k$-th Fourier coefficient $c_k$ is defined as:\n$$\nc_k = \\frac{1}{2\\pi}\\int_0^{2\\pi} f_{\\delta,\\theta_0}(\\theta)e^{-ik\\theta}\\,d\\theta\n$$\nWe substitute the expression for $f_{\\delta,\\theta_0}(\\theta)$:\n$$\nc_k = \\frac{1}{2\\pi}\\int_0^{2\\pi} (\\delta + 2 - 2\\cos(\\theta - \\theta_0))e^{-ik\\theta}\\,d\\theta\n$$\nWe can separate the integral into two parts:\n1.  The constant term: $\\frac{1}{2\\pi}\\int_0^{2\\pi} (\\delta + 2)e^{-ik\\theta}\\,d\\theta$. This integral evaluates to $\\delta + 2$ for $k=0$ and $0$ for $k \\ne 0$.\n2.  The cosine term: We use Euler's formula, $\\cos(x) = \\frac{e^{ix} + e^{-ix}}{2}$, to write $-2\\cos(\\theta - \\theta_0) = -e^{i(\\theta - \\theta_0)} - e^{-i(\\theta - \\theta_0)} = -e^{-i\\theta_0}e^{i\\theta} - e^{i\\theta_0}e^{-i\\theta}$.\n    The integral becomes:\n    $$\n    -\\frac{1}{2\\pi}\\int_0^{2\\pi} (e^{-i\\theta_0}e^{i\\theta} + e^{i\\theta_0}e^{-i\\theta})e^{-ik\\theta}\\,d\\theta = -\\frac{e^{-i\\theta_0}}{2\\pi}\\int_0^{2\\pi} e^{i(1-k)\\theta}\\,d\\theta - \\frac{e^{i\\theta_0}}{2\\pi}\\int_0^{2\\pi} e^{-i(1+k)\\theta}\\,d\\theta\n    $$\n    The first integral is non-zero only for $1-k=0$, i.e., $k=1$, where it evaluates to $-e^{-i\\theta_0}$. The second integral is non-zero only for $1+k=0$, i.e., $k=-1$, where it evaluates to $-e^{i\\theta_0}$.\n\nCombining these results, the Fourier coefficients are:\n-   For $k=0$: $c_0 = \\delta + 2$.\n-   For $k=1$: $c_1 = -e^{-i\\theta_0}$.\n-   For $k=-1$: $c_{-1} = -e^{i\\theta_0}$.\n-   For $|k| \\ge 2$: $c_k = 0$.\n\nThe Hermitian property $c_{-k} = \\overline{c_k}$ is satisfied, as $c_{-1} = -e^{i\\theta_0} = -(\\cos\\theta_0 + i\\sin\\theta_0)$ and $\\overline{c_1} = \\overline{-e^{-i\\theta_0}} = -\\overline{\\cos(-\\theta_0) + i\\sin(-\\theta_0)} = -(\\cos\\theta_0 - i\\sin\\theta_0)$, which equals $c_{-1}$. Because coefficients $c_k$ are zero for $|k| \\ge 2$, the resulting $n \\times n$ matrix $T_n(f_{\\delta,\\theta_0})$ is a Hermitian tridiagonal Toeplitz matrix:\n$$\nT_n = \\begin{pmatrix}\nc_0  c_{-1}  0  \\dots  0 \\\\\nc_1  c_0  c_{-1}  \\dots  0 \\\\\n0  c_1  c_0  \\ddots  \\vdots \\\\\n\\vdots   \\ddots  \\ddots  c_{-1} \\\\\n0  \\dots  0  c_1  c_0\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\delta+2  \\overline{c_1}  0  \\dots  0 \\\\\nc_1  \\delta+2  \\overline{c_1}  \\dots  0 \\\\\n0  c_1  \\delta+2  \\ddots  \\vdots \\\\\n\\vdots   \\ddots  \\ddots  \\overline{c_1} \\\\\n0  \\dots  0  c_1  \\delta+2\n\\end{pmatrix}\n$$\nwhere $c_1 = -e^{-i\\theta_0}$.\n\n### Step 2: Algorithmic Design and Experiment Setup\n\nThe experiment compares two algorithms for solving the linear system $T_n x = b$. The vector $x_{\\text{true}}$ is defined, and the right-hand side $b$ is computed as $b = T_n x_{\\text{true}}$ to establish a ground truth for accuracy analysis.\n\n1.  **Levinson–Durbin Recursion**: This is a fast algorithm, with complexity $O(n^2)$, for solving linear systems with a Toeplitz matrix structure. For a Hermitian Toeplitz matrix defined by its first column $c = [c_0, c_1, \\dots, c_{n-1}]^T$, the algorithm iteratively builds up the solution. It is known to be numerically stable for positive-definite matrices. However, as $\\delta \\to 0$, $T_n$ becomes ill-conditioned, and the algorithm's accuracy may degrade due to the propagation of rounding errors without a pivoting mechanism. A standard implementation, such as `scipy.linalg.solve_toeplitz`, will be used.\n\n2.  **GKO-Style Pivoted Approach (Proxy)**: The Gohberg–Kailath–Olshevsky (GKO) algorithm is a fast $O(n^2)$ solver for structured matrices that can incorporate pivoting for numerical stability. Pivoting disrupts the matrix structure, making the algorithm significantly more complex. As a proxy for a stable, pivoted fast solver, the problem specifies using classical Gaussian Elimination with Partial Pivoting (GEPP) on the dense matrix. While this has a higher complexity of $O(n^3)$, it serves as a baseline for numerical stability against which the non-pivoted Levinson-Durbin method can be compared. GEPP is the standard robust algorithm for general dense linear systems and is implemented in routines like `numpy.linalg.solve`.\n\n### Step 3: Evaluation Metrics\n\nThe performance of each method is quantified by three metrics:\n\n1.  **Relative Solution Error ($E$)**: Measures how close the computed solution $\\hat{x}$ is to the known true solution $x_{\\text{true}}$.\n    $$\n    E = \\frac{\\| \\hat{x} - x_{\\text{true}} \\|_2}{\\| x_{\\text{true}} \\|_2}\n    $$\n2.  **Relative Residual Norm ($R$)**: Measures how well the computed solution satisfies the original equation. A small residual indicates that $\\hat{x}$ is the exact solution to a nearby problem $T_n x = b + \\Delta b$.\n    $$\n    R = \\frac{\\| b - T_n \\hat{x} \\|_2}{\\| b \\|_2}\n    $$\n3.  **2-Norm Condition Number ($\\kappa_2$)**: An intrinsic property of the matrix $T_n$ that bounds the amplification of errors in the input data (both $T_n$ and $b$) to the output solution $x$. A large condition number indicates an ill-conditioned problem, where small input perturbations can lead to large changes in the solution.\n    $$\n    \\kappa_2(T_n) = \\|T_n\\|_2 \\cdot \\|T_n^{-1}\\|_2\n    $$\n    For a given method, we expect a relationship approximately like $E \\lesssim \\kappa_2(T_n) (R + \\epsilon_{\\text{mach}})$, where $\\epsilon_{\\text{mach}}$ is machine precision.\n\nThe experiment systematically varies the parameters $(n, \\theta_0, \\delta)$ to observe how matrix size, position of the symbol's near-zero, and the proximity to singularity affect stability and accuracy. As $\\delta$ approaches $0$, $\\kappa_2(T_n)$ is expected to grow large, challenging the numerical stability of the solvers. The expectation is that the GEPP proxy, due to its pivoting strategy, will maintain better accuracy (smaller $E$) than the non-pivoted Levinson-Durbin recursion in severely ill-conditioned cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import toeplitz, solve_toeplitz\n\ndef solve():\n    \"\"\"\n    Designs and runs a parameterized experiment to compare the numerical stability\n    of Levinson-Durbin recursion and a GKO-style pivoted approach (proxied by GEPP)\n    for solving ill-conditioned Hermitian Toeplitz linear systems.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (32, np.pi/4, 1e-2),\n        (64, np.pi/3, 1e-6),\n        (64, 0.01, 1e-8),\n        (16, np.pi - 0.01, 1e-9),\n        (8, np.pi/6, 1e-12),\n    ]\n\n    results = []\n    for n, theta0, delta in test_cases:\n        # Step 1: Construct the Hermitian Toeplitz matrix T_n\n        \n        # Derive the Fourier coefficients c_k from the symbol.\n        # c_0 = delta + 2\n        # c_1 = -exp(-i*theta0)\n        # c_k = 0 for |k| >= 2\n        c0 = delta + 2.0\n        c1 = -np.exp(-1j * theta0)\n        \n        # The first column of the Toeplitz matrix\n        c_col = np.zeros(n, dtype=np.complex128)\n        c_col[0] = c0\n        if n > 1:\n            c_col[1] = c1\n\n        # The first row of the Hermitian Toeplitz matrix.\n        # r_k = c_{-k} = conjugate(c_k)\n        r_row = np.conjugate(c_col)\n\n        # Construct the dense matrix T_n.\n        # This is a tridiagonal Hermitian Toeplitz matrix.\n        T = toeplitz(c_col, r_row)\n\n        # Step 2: Define the true solution x_true and compute the RHS b\n        j = np.arange(n)\n        x_true = np.sin(2 * np.pi * j / n) + 0.5 * np.cos(4 * np.pi * j / n)\n        x_true = x_true.astype(np.complex128) # Treat as complex vector\n        \n        b = T @ x_true\n        \n        # Step 3: Solve the system T*x = b using both methods.\n        \n        # Method 1: Levinson-Durbin recursion\n        # scipy.linalg.solve_toeplitz uses Levinson-Durbin for Hermitian matrices.\n        # It takes the first column `c_col` as input.\n        x_ld = solve_toeplitz(c_col, b)\n        \n        # Method 2: GKO-style proxy (Gaussian Elimination with Partial Pivoting)\n        # numpy.linalg.solve uses LAPACK's gesv, which implements GEPP.\n        x_gko = np.linalg.solve(T, b)\n\n        # Step 4: Compute the evaluation metrics\n        \n        # Norms for relative error and residual calculations\n        norm_xtrue = np.linalg.norm(x_true, 2)\n        norm_b = np.linalg.norm(b, 2)\n\n        # Relative solution error E\n        E_ld = np.linalg.norm(x_ld - x_true, 2) / norm_xtrue\n        E_gko = np.linalg.norm(x_gko - x_true, 2) / norm_xtrue\n\n        # Relative residual norm R\n        R_ld = np.linalg.norm(b - T @ x_ld, 2) / norm_b\n        R_gko = np.linalg.norm(b - T @ x_gko, 2) / norm_b\n\n        # 2-norm condition number kappa_2\n        kappa2 = np.linalg.cond(T, p=2)\n\n        results.extend([E_ld, E_gko, R_ld, R_gko, kappa2])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{v:.15e}' for v in results)}]\")\n\nsolve()\n```", "id": "3545692"}, {"introduction": "The label \"fast solver\" promises a significant speed advantage, but theoretical operation counts do not tell the whole story. Actual performance on modern CPUs is a complex interplay between computation, memory bandwidth, and the cache hierarchy. This modeling exercise [@problem_id:3545756] allows you to build and apply a roofline model to predict the end-to-end performance of a Toeplitz solver, quantifying how algorithmic choices and hardware limitations determine its true speed.", "problem": "You are given a performance-modeling task for fast solvers for Toeplitz systems that use Fast Fourier Transforms (FFT) to accelerate Toeplitz matrix-vector multiplications (MVMs) via circulant embedding. The goal is to quantify predicted end-to-end solver speedups when using a split-radix FFT versus a radix-$2$ Cooley–Tukey FFT, and to explicitly connect how cache-fit or cache-miss regimes alter these speedups on a modern Central Processing Unit (CPU) through a simple roofline-style model.\n\nYou must implement a program that computes the predicted end-to-end runtime of a Krylov subspace solver that uses $k$ iterations, where each iteration is dominated by one Toeplitz MVM evaluated using FFTs, plus standard vector operations. The Toeplitz matrix is assumed to be fixed across iterations and Hermitian positive-definite, so Conjugate Gradient is applicable. You will compare two implementations of the FFT within the same solver structure:\n- a radix-$2$ Cooley–Tukey FFT (denoted $\\mathrm{CT}$),\n- a split-radix FFT (denoted $\\mathrm{SR}$).\n\nYou must use the following fundamental and well-tested mathematical facts as your base:\n- A Toeplitz MVM of size $n$ can be performed by embedding into a circulant convolution of length $m \\ge 2n-1$ and evaluating the convolution via FFTs. For computational efficiency, use a power-of-two embedding length $L = 2^{\\lceil \\log_2(2n-1) \\rceil}$.\n- For one Toeplitz MVM with a fixed kernel, there is a one-time precomputation of the kernel’s FFT of length $L$. Each subsequent MVM requires one forward FFT of the padded input of length $L$, one elementwise complex multiplication of length $L$, and one inverse FFT of length $L$.\n- In double-precision complex arithmetic, each complex number occupies $16$ bytes.\n- Adopt a roofline-style performance model: for any operation with total floating-point operation (FLOP) count $F$ and total memory traffic $M$ bytes, on a CPU with peak floating-point rate $P$ FLOP/s and sustained memory bandwidth $B$ bytes/s, the time is modeled as the maximum of the compute time and the memory time:\n$$\nT \\;=\\; \\max\\!\\left(\\frac{F}{P}, \\frac{M}{B}\\right).\n$$\n\nModel the operation counts and memory traffic as follows.\n\n1) FFT arithmetic work. For a complex FFT of length $L$:\n- Radix-$2$ Cooley–Tukey model: FLOPs $F_{\\mathrm{CT}}(L) = c_{\\mathrm{CT}}\\, L \\log_2 L$ with $c_{\\mathrm{CT}} = 10$.\n- Split-radix model: FLOPs $F_{\\mathrm{SR}}(L) = c_{\\mathrm{SR}}\\, L \\log_2 L$ with $c_{\\mathrm{SR}} = 9$.\n\n2) FFT memory traffic. For a complex FFT of length $L$ on a cache of capacity $C$ bytes:\n- If the working set fits, i.e., $16L \\le C$, assume two full array sweeps per FFT, so $M_{\\mathrm{fit}}(L) = 2 \\cdot 16 L$ bytes.\n- If it does not fit, assume algorithm-dependent streaming passes per level:\n$$\nM_{\\mathrm{CT,miss}}(L) \\;=\\; \\rho_{\\mathrm{CT}} \\cdot 16 L \\log_2 L,\\quad \\rho_{\\mathrm{CT}} = 2.0,\n$$\n$$\nM_{\\mathrm{SR,miss}}(L) \\;=\\; \\rho_{\\mathrm{SR}} \\cdot 16 L \\log_2 L,\\quad \\rho_{\\mathrm{SR}} = 1.7.\n$$\nUse $M_{\\mathrm{FFT}}(L) = M_{\\mathrm{fit}}(L)$ if $16L \\le C$ and $M_{\\mathrm{FFT}}(L) = M_{\\mathrm{algo,miss}}(L)$ otherwise.\n\n3) Complex elementwise multiplication for the convolution. For length $L$, assume $F_{\\times}(L) = 6L$ FLOPs and memory $M_{\\times}(L) = 3 \\cdot 16 L$ bytes (read two inputs, write one output).\n\n4) Vector operations per Conjugate Gradient iteration on vectors of length $n$:\n- Two dot products, each modeled as $F_{\\mathrm{dot}}(n) = 8n$ FLOPs and $M_{\\mathrm{dot}}(n) = 2 \\cdot 16 n$ bytes.\n- Three AXPY operations $z \\leftarrow \\alpha x + y$ with complex $\\alpha$, each modeled as $F_{\\mathrm{axpy}}(n) = 8n$ FLOPs and $M_{\\mathrm{axpy}}(n) = 3 \\cdot 16 n$ bytes.\nFor vector operations, model memory traffic as stated regardless of $C$; these are streaming vector kernels.\n\nGiven $n$, $k$, $P$, $B$, and $C$:\n- Compute $L = 2^{\\lceil \\log_2(2n-1) \\rceil}$.\n- Precomputation time: one FFT of the kernel of length $L$.\n- Per-iteration time for the Toeplitz MVM: one forward FFT length $L$, the elementwise complex multiplication length $L$, and one inverse FFT length $L$.\n- Per-iteration time for vector ops: two dot products and three AXPYs on length $n$.\n- Total end-to-end time for algorithm $\\mathrm{algo} \\in \\{\\mathrm{CT}, \\mathrm{SR}\\}$:\n$$\nT_{\\mathrm{algo}} \\;=\\; T_{\\mathrm{FFT,pre}}^{(\\mathrm{algo})}(L) \\;+\\; k \\,\\Big( T_{\\mathrm{FFT,fwd}}^{(\\mathrm{algo})}(L) + T_{\\times}(L) + T_{\\mathrm{FFT,inv}}^{(\\mathrm{algo})}(L) + 2\\,T_{\\mathrm{dot}}(n) + 3\\,T_{\\mathrm{axpy}}(n) \\Big),\n$$\nwhere each component time is computed as $T=\\max(F/P,\\, M/B)$ with the corresponding $F$ and $M$ from the above models for that component and algorithm.\n\nYour program must output, for each test case, the predicted speedup factor\n$$\nS \\;=\\; \\frac{T_{\\mathrm{CT}}}{T_{\\mathrm{SR}}},\n$$\nexpressed as a floating-point number rounded to six digits after the decimal point, with no unit.\n\nTest suite. Use exactly the following four test cases, each a tuple $(n,k,P,B,C)$:\n- Case 1 (small, cache-fitting, moderate bandwidth): $(n,k,P,B,C) = (4096,\\,100,\\,3\\times 10^{11},\\,1\\times 10^{11},\\,32\\times 10^{6})$.\n- Case 2 (small, cache-fitting, high bandwidth): $(n,k,P,B,C) = (4096,\\,100,\\,3\\times 10^{11},\\,4\\times 10^{11},\\,32\\times 10^{6})$.\n- Case 3 (large, non-fitting, moderate bandwidth): $(n,k,P,B,C) = (10^{6},\\,30,\\,3\\times 10^{11},\\,1\\times 10^{11},\\,32\\times 10^{6})$.\n- Case 4 (boundary-scale, non-fitting under smaller cache): $(n,k,P,B,C) = (524288,\\,20,\\,3\\times 10^{11},\\,1\\times 10^{11},\\,16\\times 10^{6})$.\n\nFinal output format. Your program should produce a single line of output containing the four speedups in order of the test suite, as a comma-separated list enclosed in square brackets, with each speedup rounded to six digits after the decimal point. For example, the format must look like\n\"[1.000000,1.123456,1.234567,1.345678]\".", "solution": "The user-provided problem is assessed as valid. It is scientifically grounded in numerical linear algebra and high-performance computing principles, well-posed with a complete and consistent set of definitions and parameters, and objectively stated. Therefore, a solution is provided.\n\nThe objective is to compute the speedup factor $S = T_{\\mathrm{CT}} / T_{\\mathrm{SR}}$, where $T_{\\mathrm{CT}}$ and $T_{\\mathrm{SR}}$ are the total execution times for a Conjugate Gradient solver using radix-$2$ Cooley-Tukey (CT) and split-radix (SR) FFT algorithms, respectively. The solution is derived by systematically applying the provided performance models.\n\nFirst, for a given problem size $n$, the length $L$ of the FFT required for circulant embedding is determined. A Toeplitz MVM of size $n$ is embedded into a circulant convolution of length at least $2n-1$. For optimal FFT performance, this is padded to the next power of two:\n$$\nL = 2^{\\lceil \\log_2(2n-1) \\rceil}\n$$\nThe value $\\log_2 L$ is simply the exponent $\\lceil \\log_2(2n-1) \\rceil$.\n\nNext, we establish the time cost for each elementary operation using the specified roofline model: $T = \\max(F/P, M/B)$, where $F$ is the floating-point operation count, $M$ is the memory traffic in bytes, $P$ is the peak floating-point rate, and $B$ is the memory bandwidth.\n\nWe calculate the time for each of the five fundamental operations involved in the solver:\n\n1.  **FFT Time ($T_{\\mathrm{FFT}}$)**: The cost depends on the algorithm ($\\mathrm{CT}$ or $\\mathrm{SR}$). For an FFT of length $L$, the FLOP counts are:\n    - $F_{\\mathrm{CT}}(L) = c_{\\mathrm{CT}}\\, L \\log_2 L$, with $c_{\\mathrm{CT}} = 10$.\n    - $F_{\\mathrm{SR}}(L) = c_{\\mathrm{SR}}\\, L \\log_2 L$, with $c_{\\mathrm{SR}} = 9$.\n    The memory traffic $M_{\\mathrm{FFT}}(L)$ depends on whether the working set of size $16L$ bytes fits into the cache of capacity $C$.\n    - If $16L \\le C$ (cache-fit), $M_{\\mathrm{fit}}(L) = 2 \\cdot 16 L = 32L$ for both algorithms.\n    - If $16L > C$ (cache-miss), the traffic is algorithm-dependent:\n      - $M_{\\mathrm{CT,miss}}(L) = \\rho_{\\mathrm{CT}} \\cdot 16 L \\log_2 L$, with $\\rho_{\\mathrm{CT}} = 2.0$.\n      - $M_{\\mathrm{SR,miss}}(L) = \\rho_{\\mathrm{SR}} \\cdot 16 L \\log_2 L$, with $\\rho_{\\mathrm{SR}} = 1.7$.\n    For a given algorithm $\\mathrm{algo} \\in \\{\\mathrm{CT}, \\mathrm{SR}\\}$, the FFT time is:\n    $$\n    T_{\\mathrm{FFT}}^{(\\mathrm{algo})}(L) = \\max\\left(\\frac{F_{\\mathrm{algo}}(L)}{P}, \\frac{M_{\\mathrm{FFT}}^{(\\mathrm{algo})}(L)}{B}\\right)\n    $$\n\n2.  **Elementwise Multiplication Time ($T_{\\times}$)**: For the convolution step on vectors of length $L$, the FLOP count is $F_{\\times}(L) = 6L$ and memory traffic is $M_{\\times}(L) = 3 \\cdot 16 L = 48L$. The time is:\n    $$\n    T_{\\times}(L) = \\max\\left(\\frac{6L}{P}, \\frac{48L}{B}\\right)\n    $$\n\n3.  **Dot Product Time ($T_{\\mathrm{dot}}$)**: For vectors of length $n$, the FLOP count is $F_{\\mathrm{dot}}(n) = 8n$ and memory traffic is $M_{\\mathrm{dot}}(n) = 2 \\cdot 16 n = 32n$. The time is:\n    $$\n    T_{\\mathrm{dot}}(n) = \\max\\left(\\frac{8n}{P}, \\frac{32n}{B}\\right)\n    $$\n\n4.  **AXPY Time ($T_{\\mathrm{axpy}}$)**: For vectors of length $n$, the FLOP count is $F_{\\mathrm{axpy}}(n) = 8n$ and memory traffic is $M_{\\mathrm{axpy}}(n) = 3 \\cdot 16 n = 48n$. The time is:\n    $$\n    T_{\\mathrm{axpy}}(n) = \\max\\left(\\frac{8n}{P}, \\frac{48n}{B}\\right)\n    $$\n\nThe total end-to-end time for each algorithm is the sum of the precomputation time and the time for $k$ iterations. The precomputation consists of one FFT of the Toeplitz kernel. Each iteration involves one Toeplitz MVM (two FFTs and one elementwise multiplication) and the vector operations (two dot products and three AXPYs). The cost model for an inverse FFT is identical to that of a forward FFT.\n\nThe total time for an algorithm $\\mathrm{algo} \\in \\{\\mathrm{CT}, \\mathrm{SR}\\}$ is:\n$$\nT_{\\mathrm{algo}} = T_{\\mathrm{FFT,pre}}^{(\\mathrm{algo})}(L) + k \\cdot \\left( T_{\\mathrm{FFT,fwd}}^{(\\mathrm{algo})}(L) + T_{\\mathrm{FFT,inv}}^{(\\mathrm{algo})}(L) + T_{\\times}(L) + 2 \\cdot T_{\\mathrm{dot}}(n) + 3 \\cdot T_{\\mathrm{axpy}}(n) \\right)\n$$\nThis simplifies to:\n$$\nT_{\\mathrm{algo}} = (1 + 2k) \\cdot T_{\\mathrm{FFT}}^{(\\mathrm{algo})}(L) + k \\cdot \\left( T_{\\times}(L) + 2 \\cdot T_{\\mathrm{dot}}(n) + 3 \\cdot T_{\\mathrm{axpy}}(n) \\right)\n$$\n\nThe procedure for each test case $(n, k, P, B, C)$ is to first compute $T_{\\mathrm{CT}}$ and $T_{\\mathrm{SR}}$ using the above formula and the corresponding parameters. The final speedup is then calculated as the ratio $S = T_{\\mathrm{CT}} / T_{\\mathrm{SR}}$. The final result for each case is rounded to six decimal places.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to calculate and print the speedup factors for the given test cases.\n    \"\"\"\n    # Test suite: each element is a tuple (n, k, P, B, C)\n    test_cases = [\n        # Case 1 (small, cache-fitting, moderate bandwidth)\n        (4096, 100, 3e11, 1e11, 32e6),\n        # Case 2 (small, cache-fitting, high bandwidth)\n        (4096, 100, 3e11, 4e11, 32e6),\n        # Case 3 (large, non-fitting, moderate bandwidth)\n        (1e6, 30, 3e11, 1e11, 32e6),\n        # Case 4 (boundary-scale, non-fitting under smaller cache)\n        (524288, 20, 3e11, 1e11, 16e6),\n    ]\n\n    # Algorithm-specific parameters\n    # Radix-2 Cooley-Tukey (CT)\n    params_ct = {'c_fft': 10.0, 'rho_fft': 2.0}\n    # Split-Radix (SR)\n    params_sr = {'c_fft': 9.0, 'rho_fft': 1.7}\n\n    results = []\n\n    for n, k, P, B, C in test_cases:\n        # Cast n to int if it's float from scientific notation 1e6\n        n = int(n)\n        \n        # Calculate total time for CT algorithm\n        t_ct = calculate_total_time(n, k, P, B, C, params_ct)\n\n        # Calculate total time for SR algorithm\n        t_sr = calculate_total_time(n, k, P, B, C, params_sr)\n\n        # Compute speedup and round to 6 decimal places\n        speedup = t_ct / t_sr\n        results.append(f\"{speedup:.6f}\")\n\n    # Print the results in the required format\n    print(f\"[{','.join(results)}]\")\n\ndef get_op_time(F, M, P, B):\n    \"\"\"\n    Computes the time for an operation using the roofline model.\n    T = max(time_compute, time_memory)\n    \"\"\"\n    time_compute = F / P\n    time_memory = M / B\n    return max(time_compute, time_memory)\n\ndef calculate_total_time(n, k, P, B, C, algo_params):\n    \"\"\"\n    Calculates the total end-to-end time for a given algorithm configuration.\n    \"\"\"\n    # 1. Calculate FFT length L\n    log2_val = np.log2(2 * n - 1)\n    # Handle case n=1 where log2(1) = 0\n    if log2_val  0: log2_val = 0\n    \n    log2L = np.ceil(log2_val)\n    L = 1  int(log2L)\n\n    # Convert log2L to float for multiplication\n    log2L_float = float(log2L)\n\n    # 2. Calculate time for each elementary operation\n    \n    # FFT time T_fft\n    c_fft = algo_params['c_fft']\n    rho_fft = algo_params['rho_fft']\n    bytes_per_complex = 16\n\n    F_fft = c_fft * L * log2L_float\n    \n    # Check cache-fit condition\n    if bytes_per_complex * L = C:\n        # Cache-fit\n        M_fft = 2.0 * bytes_per_complex * L\n    else:\n        # Cache-miss\n        M_fft = rho_fft * bytes_per_complex * L * log2L_float\n        \n    T_fft = get_op_time(F_fft, M_fft, P, B)\n\n    # Elementwise multiplication time T_mul\n    F_mul = 6.0 * L\n    M_mul = 3.0 * bytes_per_complex * L\n    T_mul = get_op_time(F_mul, M_mul, P, B)\n\n    # Dot product time T_dot\n    F_dot = 8.0 * n\n    M_dot = 2.0 * bytes_per_complex * n\n    T_dot = get_op_time(F_dot, M_dot, P, B)\n    \n    # AXPY time T_axpy\n    F_axpy = 8.0 * n\n    M_axpy = 3.0 * bytes_per_complex * n\n    T_axpy = get_op_time(F_axpy, M_axpy, P, B)\n    \n    # 3. Aggregate total time\n    # T_total = T_precompute + k * T_iteration\n    # T_precompute = 1 * T_fft\n    # T_iteration = (2 * T_fft + T_mul) + (2 * T_dot + 3 * T_axpy)\n    total_time = (1 + 2 * k) * T_fft + k * (T_mul + 2 * T_dot + 3 * T_axpy)\n\n    return total_time\n\n# Execute the solver\nsolve()\n```", "id": "3545756"}]}