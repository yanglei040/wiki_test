{"hands_on_practices": [{"introduction": "The effectiveness of Algebraic Multigrid begins with its setup phase, where it analyzes the system matrix to build a hierarchy of coarser problems. This first exercise provides a concrete application of the classical Ruge-Stüben coarsening strategy, which forms the foundation of many AMG methods [@problem_id:3532927]. By identifying strong connections and performing a coarse-fine splitting on a matrix from an anisotropic problem, you will gain hands-on experience with how AMG automatically adapts to the underlying physics.", "problem": "Consider the linear system $\\mathbf{A}\\mathbf{u}=\\mathbf{f}$ arising from the standard five-point finite-difference discretization of the two-dimensional anisotropic Laplacian on a uniform $5\\times 5$ grid with periodic boundary conditions in both directions. The discrete operator uses the constant stencil\n$$\n\\begin{bmatrix}\n0  -\\epsilon  0\\\\\n-1  2(1+\\epsilon)  -1\\\\\n0  -\\epsilon  0\n\\end{bmatrix},\n$$\nwith $\\epsilon=0.1$, so that for each grid point $(i,j)$ the matrix $\\mathbf{A}$ has diagonal entry $a_{ii}=2(1+\\epsilon)$ and four off-diagonal entries $-1$ to its horizontal neighbors and $-\\epsilon$ to its vertical neighbors (with wrap-around at the boundaries). Assume the unknowns are indexed in row-major lexicographic order $(1,1),(1,2),\\ldots,(1,5),(2,1),\\ldots,(5,5)$.\n\nYou will use Algebraic Multigrid (AMG) as a right preconditioner for $\\mathbf{A}$. In classical AMG, a point $j$ is said to be a strong negative connection of point $i$ if $a_{ij}0$ and\n$$\n- a_{ij} \\geq \\theta \\max_{k\\neq i} \\left(-a_{ik}\\right),\n$$\nwith strength threshold $\\theta=0.25$. Build the undirected strong connection graph by placing an edge between $i$ and $j$ if either $i$ strongly depends on $j$ or $j$ strongly depends on $i$. Then, construct a coarse/fine (C/F) splitting by selecting a maximal independent set (MIS) of this undirected strong graph using the following deterministic greedy rule: traverse the nodes in the given lexicographic order, and mark a node as coarse if none of its already-visited neighbors in the strong graph are coarse; otherwise mark it as fine. This yields a well-defined C/F splitting.\n\nStarting from the above definitions and without assuming any unproven AMG heuristics beyond the given criterion for strong connections and the MIS rule, determine the total number of coarse points produced by this procedure on the $5\\times 5$ grid. Provide your final answer as a single integer. No rounding is required.", "solution": "The problem requires us to determine the total number of coarse points resulting from a specific algebraic multigrid (AMG) coarsening procedure applied to a linear system derived from a finite-difference discretization. The procedure is fully deterministic. The solution process consists of three main parts:\n1.  Determining the structure of the strong connection graph.\n2.  Applying the specified maximal independent set (MIS) algorithm to find the coarse points for a single row.\n3.  Extrapolating the result to the entire grid.\n\n**1. Determine the Strong Connection Graph**\n\nFor any grid point $i$, the matrix $\\mathbf{A}$ has four non-zero off-diagonal entries corresponding to its neighbors. Due to the periodic boundary conditions on the $5\\times 5$ grid, every point has exactly four neighbors: two horizontal and two vertical.\n- The off-diagonal entry for a horizontal connection is $a_{ij} = -1$.\n- The off-diagonal entry for a vertical connection is $a_{ij} = -\\epsilon = -0.1$.\n\nTo apply the strong connection criterion, we first need to compute the maximum magnitude of the off-diagonal entries for any row $i$:\n$$\n\\max_{k\\neq i} \\left(-a_{ik}\\right) = \\max\\left(1, 1, \\epsilon, \\epsilon\\right) = \\max\\left(1, 1, 0.1, 0.1\\right) = 1\n$$\nThe strength threshold is given as $\\theta=0.25$. A connection from $i$ to $j$ is strong if $-a_{ij} \\geq \\theta \\times 1$, which is $-a_{ij} \\geq 0.25$.\n\nLet's evaluate this condition for the two types of connections:\n- For a horizontal neighbor $j$, $-a_{ij} = -(-1) = 1$. Since $1 \\geq 0.25$, the horizontal connections are **strong**.\n- For a vertical neighbor $j$, $-a_{ij} = -(-\\epsilon) = -(-0.1) = 0.1$. Since $0.1  0.25$, the vertical connections are **weak**.\n\nThe problem states that the undirected strong connection graph has an edge between $i$ and $j$ if either $i$ strongly depends on $j$ or vice versa. The matrix $\\mathbf{A}$ is symmetric ($a_{ij} = a_{ji}$), so the condition is symmetric: $i$ strongly depends on $j$ if and only if $j$ strongly depends on $i$.\nTherefore, the strong connection graph consists of edges connecting only horizontal neighbors.\n\nFor a grid point $(r,c)$, where $r$ is the row index and $c$ is the column index ($r,c \\in \\{1, 2, 3, 4, 5\\}$), it is strongly connected to $(r, c-1)$ and $(r, c+1)$. Due to periodic boundary conditions, column $1$ is adjacent to column $5$. This means for each row $r$, the grid points $(r,1), (r,2), (r,3), (r,4), (r,5)$ form a cycle graph of length $5$: $(r,1) \\leftrightarrow (r,2) \\leftrightarrow (r,3) \\leftrightarrow (r,4) \\leftrightarrow (r,5) \\leftrightarrow (r,1)$.\nSince there are no strong vertical connections, the overall strong connection graph is the disjoint union of $5$ such cycle graphs, one for each row of the grid.\n\n**2. Apply the MIS Algorithm for a Single Row**\n\nThe C/F splitting is determined by finding an MIS of the strong graph using a greedy algorithm based on the lexicographic node ordering. The nodes are ordered $(1,1), \\dots, (1,5), (2,1), \\dots, (2,5), \\dots$. This means we process all nodes of row $1$, then all nodes of row $2$, and so on.\nSince the strong graph is disconnected row by row, the C/F splitting for each row is independent of the others. We can analyze the process for a single row, say row $r$, and the result will be identical for all other rows.\n\nLet's analyze the procedure for the $5$ nodes in row $r$. For simplicity, let's label the nodes within this row as $v_1, v_2, v_3, v_4, v_5$, corresponding to columns $1$ through $5$. The strong connections are $(v_1, v_2), (v_2, v_3), (v_3, v_4), (v_4, v_5), (v_5, v_1)$. The algorithm proceeds as follows, where $C_{set}$ is the set of coarse points:\n- **Node $v_1$ (e.g., point $(r,1)$):** This is the first node visited in this row. It has no previously-visited neighbors that are coarse (the set of such neighbors is empty). Therefore, $v_1$ is marked **Coarse (C)**. $C_{set} = \\{v_1\\}$.\n- **Node $v_2$ (point $(r,2)$):** Its neighbors in the strong graph are $v_1$ and $v_3$. The only already-visited neighbor is $v_1$. Since $v_1$ is in $C_{set}$, $v_2$ has a coarse neighbor. Therefore, $v_2$ is marked **Fine (F)**.\n- **Node $v_3$ (point $(r,3)$):** Its neighbors are $v_2$ and $v_4$. The only already-visited neighbor is $v_2$. Since $v_2$ is not coarse, $v_3$ has no coarse neighbors among the already-visited nodes. Therefore, $v_3$ is marked **Coarse (C)**. $C_{set} = \\{v_1, v_3\\}$.\n- **Node $v_4$ (point $(r,4)$):** Its neighbors are $v_3$ and $v_5$. Its already-visited neighbors are $v_2$ and $v_3$. Since $v_3$ is in $C_{set}$, $v_4$ has a coarse neighbor. Therefore, $v_4$ is marked **Fine (F)**.\n- **Node $v_5$ (point $(r,5)$):** Its neighbors are $v_4$ and $v_1$. Its already-visited neighbors are $v_1, v_2, v_3, v_4$. Since $v_1$ is in $C_{set}$, $v_5$ has a coarse neighbor. Therefore, $v_5$ is marked **Fine (F)**.\n\nFor a single row, the C/F splitting pattern is C-F-C-F-F. The number of coarse points in one row is $2$.\n\n**3. Calculate Total Number of Coarse Points**\n\nThe process described above is identical for each of the $5$ rows of the grid because the intra-row graph structure and ordering are the same for all rows.\n- Number of coarse points per row = $2$.\n- Number of rows = $5$.\n\nTotal number of coarse points = (Number of coarse points per row) $\\times$ (Number of rows)\n$$\n\\text{Total Coarse Points} = 2 \\times 5 = 10\n$$\n\nThe procedure yields a total of $10$ coarse points on the $5\\times 5$ grid.", "answer": "$$\n\\boxed{10}\n$$", "id": "3532927"}, {"introduction": "For a coarse-grid correction to be effective, algebraically smooth errors must be well-approximated by the coarse space—a requirement known as the approximation property. This exercise presents a carefully constructed counterexample where a poor choice of interpolation violates this property, rendering the coarse-grid correction useless for certain error modes [@problem_id:3532911]. By working through this failure, you will learn to use the nullspace of the operator $P^{\\top} A$ as a sharp algebraic tool to diagnose fundamental weaknesses in an AMG setup.", "problem": "Consider the task of designing an Algebraic Multigrid (AMG) preconditioner for a linear system with a Symmetric Positive Definite (SPD) matrix. Let the system matrix be the canonical one-dimensional discrete Laplacian with Dirichlet boundary conditions on four grid points,\n$$\nA \\;=\\;\n\\begin{pmatrix}\n2  -1  0  0 \\\\\n-1  2  -1  0 \\\\\n0  -1  2  -1 \\\\\n0  0  -1  2\n\\end{pmatrix},\n$$\nand suppose a coarse/fine (C/F) splitting is chosen with coarse variables at indices $\\{1,4\\}$ and fine variables at indices $\\{2,3\\}$. Define the prolongation operator $P$ by direct injection at coarse points and no interpolation to fine points, so that the columns of $P$ are the coordinate vectors at indices $1$ and $4$, namely\n$$\nP \\;=\\;\n\\begin{pmatrix}\n1  0 \\\\\n0  0 \\\\\n0  0 \\\\\n0  1\n\\end{pmatrix}.\n$$\nStarting only from the core definitions of Algebraic Multigrid (AMG) as a preconditioner, the role of the coarse space $\\operatorname{Range}(P)$, and the Galerkin construction $A_{\\mathrm{c}} = P^{\\top} A P$, explain why this choice of C/F splitting and interpolation violates the approximation property by identifying a nonzero algebraically smooth error that the coarse space cannot approximate. Then, diagnose this failure using the algebraic criterion involving the nullspace of $P^{\\top} A$ by computing the dimension of $\\operatorname{Null}(P^{\\top} A)$.\n\nYour final answer must be the dimension of $\\operatorname{Null}(P^{\\top} A)$, expressed as a single integer. No rounding is required.", "solution": "The core idea of a two-grid method, and by extension multigrid, is to use a relaxation method (like Jacobi or Gauss-Seidel) to damp high-frequency (oscillatory) components of the error, and a coarse-grid correction step to eliminate the low-frequency (algebraically smooth) components of the error that relaxation methods struggle with.\n\nFor the coarse-grid correction to be effective, two primary conditions must be met:\n$1$. The **approximation property**: The space of coarse-grid vectors, represented by the range of the prolongation operator $P$, denoted $\\operatorname{Range}(P)$, must be able to accurately approximate the algebraically smooth error components.\n$2$. The coarse-grid operator $A_{\\mathrm{c}} = P^{\\top} A P$ must be a good, stable representation of the fine-grid operator $A$ on the coarse space.\n\nThe problem asks us to show that the first property is violated and to diagnose this failure algebraically.\n\n### Part 1: Violation of the Approximation Property\n\nAn error vector $e$ is considered algebraically smooth if it is a linear combination of the eigenvectors of $A$ corresponding to small eigenvalues. In general, a vector $e$ is smooth if the Rayleigh quotient $R(e) = \\frac{e^{\\top}Ae}{e^{\\top}e}$ is small. For the discrete Laplacian matrix $A$, smooth vectors are those that do not oscillate much between adjacent grid points. A canonical example of a smooth vector is one whose components are nearly constant. Let us consider the vector $e_{\\mathrm{smooth}} = \\begin{pmatrix} 1  1  1  1 \\end{pmatrix}^{\\top}$. This vector represents a constant mode, which is the smoothest possible function on the grid. This vector is indeed algebraically smooth with respect to $A$, as its Rayleigh quotient is $R(e_{\\mathrm{smooth}}) = \\frac{\\begin{pmatrix} 1  1  1  1 \\end{pmatrix} A \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}}{\\begin{pmatrix} 1  1  1  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}} = \\frac{\\begin{pmatrix} 1  1  1  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 1 \\end{pmatrix}}{4} = \\frac{2}{4} = \\frac{1}{2}$. The smallest eigenvalue of $A$ is $\\lambda_1 = 2 - 2\\cos(\\frac{\\pi}{5}) \\approx 0.382$, so a Rayleigh quotient of $0.5$ indicates a very smooth vector.\n\nThe approximation property requires that this smooth vector $e_{\\mathrm{smooth}}$ can be well-approximated by a vector in the coarse space, $\\operatorname{Range}(P)$. The given prolongation operator is\n$$\nP \\;=\\;\n\\begin{pmatrix}\n1  0 \\\\\n0  0 \\\\\n0  0 \\\\\n0  1\n\\end{pmatrix}.\n$$\nThe columns of $P$ are the standard basis vectors $e_1$ and $e_4$. The coarse space $\\operatorname{Range}(P)$ is the set of all vectors of the form $v_c = \\alpha e_1 + \\beta e_4$, which can be written as\n$$\nv_c = \\begin{pmatrix} \\alpha \\\\ 0 \\\\ 0 \\\\ \\beta \\end{pmatrix}\n$$\nfor some scalars $\\alpha, \\beta \\in \\mathbb{R}$.\n\nTo approximate $e_{\\mathrm{smooth}} = \\begin{pmatrix} 1  1  1  1 \\end{pmatrix}^{\\top}$ with a vector in $\\operatorname{Range}(P)$, we would choose $\\alpha=1$ and $\\beta=1$ to match the values at the coarse points (indices $\\{1,4\\}$). The best approximation of $e_{\\mathrm{smooth}}$ in $\\operatorname{Range}(P)$ is thus\n$$\ne_{\\mathrm{approx}} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 1 \\end{pmatrix}.\n$$\nThe error of this approximation is\n$$\ne_{\\mathrm{err}} = e_{\\mathrm{smooth}} - e_{\\mathrm{approx}} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\\\ 0 \\end{pmatrix}.\n$$\nThe magnitude of this error is $\\|e_{\\mathrm{err}}\\|_2 = \\sqrt{0^2 + 1^2 + 1^2 + 0^2} = \\sqrt{2}$, which is significant compared to the magnitude of the original smooth vector $\\|e_{\\mathrm{smooth}}\\|_2 = \\sqrt{4} = 2$. The approximation completely fails to capture the behavior of the smooth error at the fine points (indices $\\{2,3\\}$). This is a direct consequence of the chosen $P$, which performs no interpolation; it simply injects the coarse-point values and sets the fine-point values to zero. Therefore, this choice of $P$ violates the approximation property. The vector $e_{\\mathrm{smooth}} = \\begin{pmatrix} 1  1  1  1 \\end{pmatrix}^{\\top}$ is a nonzero algebraically smooth error that the coarse space cannot approximate well.\n\n### Part 2: Diagnosis via $\\operatorname{Null}(P^{\\top} A)$\n\nA more formal algebraic criterion for a failing coarse-grid correction is the existence of a non-trivial nullspace for the operator $P^{\\top} A$. If there exists a nonzero vector $e$ such that $P^{\\top} A e = 0$, it implies that a smooth error component $e$ can generate a residual $r=Ae$ that is entirely \"invisible\" to the coarse grid. The restriction of the residual, $P^{\\top}r$, would be zero. Consequently, the coarse-grid problem $A_{\\mathrm{c}} e_{\\mathrm{c}} = P^{\\top} r$ would have a zero right-hand side, leading to a zero correction $e_{\\mathrm{c}}=0$. The error $e$ would remain uncorrected by the coarse-grid step. The dimension of this nullspace quantifies the number of independent \"bad\" modes that the coarse-grid correction cannot handle.\n\nWe compute the matrix product $P^{\\top} A$:\n$$\nP^{\\top} = \\begin{pmatrix} 1  0  0  0 \\\\ 0  0  0  1 \\end{pmatrix}.\n$$\n$$\nP^{\\top} A = \\begin{pmatrix} 1  0  0  0 \\\\ 0  0  0  1 \\end{pmatrix}\n\\begin{pmatrix}\n2  -1  0  0 \\\\\n-1  2  -1  0 \\\\\n0  -1  2  -1 \\\\\n0  0  -1  2\n\\end{pmatrix}\n= \\begin{pmatrix}\n2  -1  0  0 \\\\\n0  0  -1  2\n\\end{pmatrix}.\n$$\nNow, we must find the nullspace of this $2 \\times 4$ matrix. We seek all vectors $x = \\begin{pmatrix} x_1  x_2  x_3  x_4 \\end{pmatrix}^{\\top}$ such that $(P^{\\top} A) x = 0$:\n$$\n\\begin{pmatrix}\n2  -1  0  0 \\\\\n0  0  -1  2\n\\end{pmatrix}\n\\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{pmatrix}\n= \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}.\n$$\nThis matrix equation corresponds to the following system of two linear equations with four unknowns:\n\\begin{align*}\n2x_1 - x_2 = 0 \\\\\n-x_3 + 2x_4 = 0\n\\end{align*}\nFrom the first equation, we have $x_2 = 2x_1$. From the second equation, we have $x_3 = 2x_4$.\nThe variables $x_1$ and $x_4$ are free variables. Let us set $x_1 = s$ and $x_4 = t$ for arbitrary parameters $s, t \\in \\mathbb{R}$. The general solution is:\n$$\nx = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{pmatrix} = \\begin{pmatrix} s \\\\ 2s \\\\ 2t \\\\ t \\end{pmatrix} = s \\begin{pmatrix} 1 \\\\ 2 \\\\ 0 \\\\ 0 \\end{pmatrix} + t \\begin{pmatrix} 0 \\\\ 0 \\\\ 2 \\\\ 1 \\end{pmatrix}.\n$$\nThe nullspace $\\operatorname{Null}(P^{\\top} A)$ is spanned by the two linearly independent vectors\n$$\nv_1 = \\begin{pmatrix} 1 \\\\ 2 \\\\ 0 \\\\ 0 \\end{pmatrix} \\quad \\text{and} \\quad v_2 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 2 \\\\ 1 \\end{pmatrix}.\n$$\nSince the nullspace is spanned by two linearly independent vectors, its dimension is $2$.\nThis confirms the failure of the chosen AMG setup. There is a two-dimensional subspace of error vectors that are completely missed by the coarse-grid correction process defined by this $P$.\n\nThe final answer is the dimension of this nullspace.", "answer": "$$\n\\boxed{2}\n$$", "id": "3532911"}, {"introduction": "The ultimate goal of AMG is to achieve optimal, or near-optimal, performance, meaning the total work scales linearly with the problem size. This efficiency is not guaranteed and depends on the quality of the hierarchy. This exercise shifts our focus from the construction details to performance analysis, asking you to compute the standard metrics used to judge an AMG hierarchy: grid complexity ($C_g$), operator complexity ($C_o$), and the work per V-cycle [@problem_id:3532884]. Mastering these calculations is essential for predicting and understanding the practical cost of using AMG as a preconditioner.", "problem": "Consider solving a symmetric positive definite linear system with Conjugate Gradient preconditioned by Algebraic Multigrid (AMG). An AMG hierarchy has three levels $l \\in \\{0,1,2\\}$ with degrees of freedom $(n_0,n_1,n_2)=(4096,1024,256)$. The fine-level matrix $A_0$ has approximately $5$ nonzeros per row, the middle-level matrix $A_1$ has approximately $9$ nonzeros per row, and the coarse-level matrix $A_2$ has approximately $15$ nonzeros per row. Assume the following for work accounting:\n- One V-cycle uses one pre-smoothing sweep and one post-smoothing sweep on each non-coarsest level, with weighted Jacobi relaxation; count the cost of each smoothing sweep as the cost of one sparse matrix-vector multiplication (SpMV) with $A_l$.\n- On each non-coarsest level, computing the residual is counted as the cost of one SpMV with $A_l$.\n- On the coarsest level, the cost of the coarse-grid solve is neglected for this estimate, and costs of restriction and prolongation are neglected on all levels.\nDefine the grid complexity $C_g$ and operator complexity $C_o$ using standard AMG complexity definitions. Using the above work model, estimate the normalized work per V-cycle $W$ in units of fine-level SpMV equivalents, meaning total V-cycle work divided by the cost of one SpMV with $A_0$. Compute $C_g$, $C_o$, and $W$. Express your final answer as a single row matrix containing the three quantities $(C_g,C_o,W)$, and do not round.", "solution": "The AMG hierarchy consists of $3$ levels, indexed $l \\in \\{0, 1, 2\\}$, with the finest level being $l=0$ and the coarsest level being $l=2$. The number of degrees of freedom (DoFs) on each level is given as $n_0 = 4096$, $n_1 = 1024$, and $n_2 = 256$. The number of non-zero entries per row for the matrices $A_l$ on each level $l$ are given as approximately $nnz_r(A_0) \\approx 5$, $nnz_r(A_1) \\approx 9$, and $nnz_r(A_2) \\approx 15$. For the purpose of calculation, these approximate values will be treated as exact.\n\nFirst, we compute the grid complexity, $C_g$. This is defined as the ratio of the total number of degrees of freedom across all levels to the number of degrees of freedom on the finest level.\n$$C_g = \\frac{\\sum_{l=0}^{2} n_l}{n_0} = \\frac{n_0 + n_1 + n_2}{n_0}$$\nSubstituting the given values:\n$$C_g = \\frac{4096 + 1024 + 256}{4096} = \\frac{5376}{4096}$$\nTo simplify this fraction, we can express the numerator and denominator in terms of common factors. Noting that $1024 = 4096/4$ and $256 = 4096/16$:\n$$C_g = 1 + \\frac{1024}{4096} + \\frac{256}{4096} = 1 + \\frac{1}{4} + \\frac{1}{16} = \\frac{16}{16} + \\frac{4}{16} + \\frac{1}{16} = \\frac{21}{16}$$\n\nNext, we compute the operator complexity, $C_o$. This is defined as the ratio of the total number of non-zero entries in all system matrices to the number of non-zero entries in the fine-level matrix. The total number of non-zeros, $N_l$, in matrix $A_l$ is the product of the number of rows (DoFs) $n_l$ and the non-zeros per row $nnz_r(A_l)$.\n$$N_l = n_l \\times nnz_r(A_l)$$\nWe calculate $N_l$ for each level:\n$$N_0 = n_0 \\times nnz_r(A_0) = 4096 \\times 5 = 20480$$\n$$N_1 = n_1 \\times nnz_r(A_1) = 1024 \\times 9 = 9216$$\n$$N_2 = n_2 \\times nnz_r(A_2) = 256 \\times 15 = 3840$$\nThe operator complexity $C_o$ is then:\n$$C_o = \\frac{\\sum_{l=0}^{2} N_l}{N_0} = \\frac{N_0 + N_1 + N_2}{N_0} = \\frac{20480 + 9216 + 3840}{20480} = \\frac{33536}{20480}$$\nSimplifying the fraction:\n$$C_o = 1 + \\frac{9216}{20480} + \\frac{3840}{20480} = 1 + \\frac{1024 \\times 9}{4096 \\times 5} + \\frac{256 \\times 15}{4096 \\times 5} = 1 + \\frac{9}{4 \\times 5} + \\frac{15}{16 \\times 5} = 1 + \\frac{9}{20} + \\frac{3}{16}$$\nUsing a common denominator of $80$:\n$$C_o = \\frac{80}{80} + \\frac{9 \\times 4}{80} + \\frac{3 \\times 5}{80} = \\frac{80 + 36 + 15}{80} = \\frac{131}{80}$$\n\nFinally, we compute the normalized work per V-cycle, $W$. The work model specifies operations on each non-coarsest level ($l=0, 1$). On each such level $l$, the work comprises $1$ pre-smoothing sweep, $1$ post-smoothing sweep, and $1$ residual computation. Each of these $3$ operations is counted as having the cost of one sparse matrix-vector multiplication (SpMV) with the matrix $A_l$. The cost of an SpMV with $A_l$ can be taken as proportional to the number of non-zeros $N_l$. Let the cost of one SpMV with $A_l$ be denoted as $\\text{Work}(\\text{SpMV}_l) = N_l$.\nThe total work on a non-coarsest level $l$ is:\n$$\\text{Work}_l = (1_{\\text{pre}} + 1_{\\text{post}} + 1_{\\text{res}}) \\times \\text{Work}(\\text{SpMV}_l) = 3 \\times N_l$$\nThe cost of restriction, prolongation, and the coarse-grid solve ($l=2$) are neglected. Thus, the total work for one V-cycle is the sum of the work on levels $l=0$ and $l=1$:\n$$\\text{Work}_{V-cycle} = \\text{Work}_0 + \\text{Work}_1 = 3 N_0 + 3 N_1$$\nThe normalized work $W$ is this total work divided by the cost of one fine-level SpMV, which is $N_0$:\n$$W = \\frac{3 N_0 + 3 N_1}{N_0} = 3 + 3 \\frac{N_1}{N_0}$$\nSubstituting the previously calculated values for $N_0$ and $N_1$:\n$$W = 3 + 3 \\left(\\frac{9216}{20480}\\right)$$\nWe simplify the fraction $\\frac{N_1}{N_0}$:\n$$\\frac{N_1}{N_0} = \\frac{1024 \\times 9}{4096 \\times 5} = \\frac{1}{4} \\times \\frac{9}{5} = \\frac{9}{20}$$\nNow we compute $W$:\n$$W = 3 + 3 \\left(\\frac{9}{20}\\right) = 3 + \\frac{27}{20} = \\frac{60}{20} + \\frac{27}{20} = \\frac{87}{20}$$\n\nThe three computed quantities are $C_g = \\frac{21}{16}$, $C_o = \\frac{131}{80}$, and $W = \\frac{87}{20}$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{21}{16}  \\frac{131}{80}  \\frac{87}{20}\n\\end{pmatrix}\n}\n$$", "id": "3532884"}]}