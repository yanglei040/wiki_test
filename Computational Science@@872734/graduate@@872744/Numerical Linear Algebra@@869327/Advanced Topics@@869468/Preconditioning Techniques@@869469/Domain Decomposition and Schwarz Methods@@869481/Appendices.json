{"hands_on_practices": [{"introduction": "At the heart of any domain decomposition method lies the algebraic machinery for transferring information between a global problem and local subproblems. This is accomplished through restriction operators, which extract local data, and prolongation operators, which embed local contributions back into the global context. This exercise guides you through the construction of these fundamental operators and reveals a crucial concept: the partition of unity, which ensures that information from overlapping regions is combined correctly. Mastering these building blocks is the first step toward understanding and implementing any Schwarz method [@problem_id:3544213].", "problem": "Consider the canonical one-dimensional Poisson operator with homogeneous Dirichlet boundary conditions on a uniform grid with $7$ interior points. Its stiffness matrix is the $7 \\times 7$ Symmetric Positive Definite (SPD) tridiagonal matrix\n$$\nA \\;=\\;\n\\begin{pmatrix}\n2  -1  0  0  0  0  0 \\\\\n-1  2  -1  0  0  0  0 \\\\\n0  -1  2  -1  0  0  0 \\\\\n0  0  -1  2  -1  0  0 \\\\\n0  0  0  -1  2  -1  0 \\\\\n0  0  0  0  -1  2  -1 \\\\\n0  0  0  0  0  -1  2\n\\end{pmatrix}.\n$$\nPartition the global index set $\\{1,2,3,4,5,6,7\\}$ into two overlapping subdomains\n$$\n\\Omega_1 \\;=\\; \\{1,2,3,4\\}, \\qquad \\Omega_2 \\;=\\; \\{4,5,6,7\\},\n$$\nwith one-node overlap at index $4$. Let $R_i \\in \\mathbb{R}^{4 \\times 7}$ denote the restriction that extracts the components in $\\Omega_i$ from a global vector in $\\mathbb{R}^7$, and let $P_i \\in \\mathbb{R}^{7 \\times 4}$ be the corresponding natural injection (i.e., $P_i = R_i^{\\top}$). \n\nTasks:\n- Explicitly write $R_1$, $R_2$, $P_1$, and $P_2$ as $0$-$1$ matrices.\n- Using only the definitions of restriction and injection, verify that $\\sum_{i=1}^{2} P_i R_i \\neq I_7$.\n- Now introduce diagonal scalings $D_1 = \\mathrm{diag}(1,1,1,w) \\in \\mathbb{R}^{4 \\times 4}$ and $D_2 = \\mathrm{diag}(w,1,1,1) \\in \\mathbb{R}^{4 \\times 4}$, where $w \\in \\mathbb{R}$ is a single overlap weight applied symmetrically to the shared node in each subdomain and all non-overlapping nodes have weight $1$. Determine the unique real value of $w$ (under this symmetry assumption) such that the partition-of-unity identity\n$$\n\\sum_{i=1}^{2} P_i D_i R_i \\;=\\; I_7\n$$\nholds exactly.\n\nYour final answer must be the value of $w$ as an exact number. No rounding is required.", "solution": "The problem is well-posed and scientifically grounded within the field of numerical linear algebra, specifically concerning domain decomposition methods. All definitions and data are self-contained and consistent. The stiffness matrix $A$ provides context for the origin of such a problem, but its specific values are not required for the tasks, which focus on the geometric decomposition and the construction of a partition of unity. We may therefore proceed with a complete solution.\n\nThe problem requires us to perform three tasks related to a domain decomposition of a $7$-node grid. The global index set is $\\{1, 2, 3, 4, 5, 6, 7\\}$.\n\n**Task 1: Explicitly write $R_1$, $R_2$, $P_1$, and $P_2$**\n\nThe restriction operator $R_i \\in \\mathbb{R}^{m_i \\times n}$ for a subdomain $\\Omega_i$ with $m_i$ indices, drawn from a global domain with $n$ indices, is a matrix that extracts the components corresponding to $\\Omega_i$. Here, the global dimension is $n=7$ and the local dimension for both subdomains is $m_1=m_2=4$.\n\nFor the first subdomain $\\Omega_1 = \\{1, 2, 3, 4\\}$, the restriction operator $R_1 \\in \\mathbb{R}^{4 \\times 7}$ extracts the first four components of a global vector in $\\mathbb{R}^7$. Its rows are the standard basis vectors $e_1^{\\top}, e_2^{\\top}, e_3^{\\top}, e_4^{\\top}$ of $\\mathbb{R}^7$.\n$$\nR_1 \\;=\\;\n\\begin{pmatrix}\n1  0  0  0  0  0  0 \\\\\n0  1  0  0  0  0  0 \\\\\n0  0  1  0  0  0  0 \\\\\n0  0  0  1  0  0  0\n\\end{pmatrix}\n$$\nThe corresponding injection operator $P_1 \\in \\mathbb{R}^{7 \\times 4}$ is the transpose of $R_1$:\n$$\nP_1 = R_1^{\\top} \\;=\\;\n\\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  1 \\\\\n0  0  0  0 \\\\\n0  0  0  0 \\\\\n0  0  0  0\n\\end{pmatrix}\n$$\n\nFor the second subdomain $\\Omega_2 = \\{4, 5, 6, 7\\}$, the restriction operator $R_2 \\in \\mathbb{R}^{4 \\times 7}$ extracts components $4, 5, 6, 7$. Its rows are the standard basis vectors $e_4^{\\top}, e_5^{\\top}, e_6^{\\top}, e_7^{\\top}$ of $\\mathbb{R}^7$.\n$$\nR_2 \\;=\\;\n\\begin{pmatrix}\n0  0  0  1  0  0  0 \\\\\n0  0  0  0  1  0  0 \\\\\n0  0  0  0  0  1  0 \\\\\n0  0  0  0  0  0  1\n\\end{pmatrix}\n$$\nThe corresponding injection operator $P_2 \\in \\mathbb{R}^{7 \\times 4}$ is the transpose of $R_2$:\n$$\nP_2 = R_2^{\\top} \\;=\\;\n\\begin{pmatrix}\n0  0  0  0 \\\\\n0  0  0  0 \\\\\n0  0  0  0 \\\\\n1  0  0  0 \\\\\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  1\n\\end{pmatrix}\n$$\n\n**Task 2: Verify that $\\sum_{i=1}^{2} P_i R_i \\neq I_7$**\n\nWe compute the products $P_1 R_1$ and $P_2 R_2$ and sum them.\nThe product $P_1 R_1$ is a $7 \\times 7$ matrix:\n$$\nP_1 R_1 \\;=\\;\n\\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  1 \\\\\n0  0  0  0 \\\\\n0  0  0  0 \\\\\n0  0  0  0\n\\end{pmatrix}\n\\begin{pmatrix}\n1  0  0  0  0  0  0 \\\\\n0  1  0  0  0  0  0 \\\\\n0  0  1  0  0  0  0 \\\\\n0  0  0  1  0  0  0\n\\end{pmatrix} \\;=\\; \\mathrm{diag}(1, 1, 1, 1, 0, 0, 0)\n$$\nThe product $P_2 R_2$ is also a $7 \\times 7$ matrix:\n$$\nP_2 R_2 \\;=\\;\n\\begin{pmatrix}\n0  0  0  0 \\\\\n0  0  0  0 \\\\\n0  0  0  0 \\\\\n1  0  0  0 \\\\\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  1\n\\end{pmatrix}\n\\begin{pmatrix}\n0  0  0  1  0  0  0 \\\\\n0  0  0  0  1  0  0 \\\\\n0  0  0  0  0  1  0 \\\\\n0  0  0  0  0  0  1\n\\end{pmatrix} \\;=\\; \\mathrm{diag}(0, 0, 0, 1, 1, 1, 1)\n$$\nThe sum is:\n$$\n\\sum_{i=1}^{2} P_i R_i = P_1 R_1 + P_2 R_2 = \\mathrm{diag}(1, 1, 1, 1, 0, 0, 0) + \\mathrm{diag}(0, 0, 0, 1, 1, 1, 1) = \\mathrm{diag}(1, 1, 1, 2, 1, 1, 1)\n$$\nThis resulting matrix is not the $7 \\times 7$ identity matrix $I_7 = \\mathrm{diag}(1, 1, 1, 1, 1, 1, 1)$, because the fourth diagonal entry is $2$ instead of $1$. This is a direct consequence of the node with global index $4$ belonging to both subdomains. Thus, we have verified that $\\sum_{i=1}^{2} P_i R_i \\neq I_7$.\n\n**Task 3: Determine $w$ for the partition-of-unity identity**\n\nWe are asked to find the value of $w \\in \\mathbb{R}$ such that $\\sum_{i=1}^{2} P_i D_i R_i = I_7$, where $D_1 = \\mathrm{diag}(1, 1, 1, w)$ and $D_2 = \\mathrm{diag}(w, 1, 1, 1)$. We compute the terms $P_1 D_1 R_1$ and $P_2 D_2 R_2$.\n\nFor the first term:\n$$\nP_1 D_1 R_1 = P_1 \\left( \\begin{pmatrix} 1000 \\\\ 0100 \\\\ 0010 \\\\ 000w \\end{pmatrix} R_1 \\right) = P_1 \\begin{pmatrix}\n1  0  0  0  0  0  0 \\\\\n0  1  0  0  0  0  0 \\\\\n0  0  1  0  0  0  0 \\\\\n0  0  0  w  0  0  0\n\\end{pmatrix} = \\mathrm{diag}(1, 1, 1, w, 0, 0, 0)\n$$\nFor the second term:\n$$\nP_2 D_2 R_2 = P_2 \\left( \\begin{pmatrix} w000 \\\\ 0100 \\\\ 0010 \\\\ 0001 \\end{pmatrix} R_2 \\right) = P_2 \\begin{pmatrix}\n0  0  0  w  0  0  0 \\\\\n0  0  0  0  1  0  0 \\\\\n0  0  0  0  0  1  0 \\\\\n0  0  0  0  0  0  1\n\\end{pmatrix} = \\mathrm{diag}(0, 0, 0, w, 1, 1, 1)\n$$\nThe sum is:\n$$\n\\sum_{i=1}^{2} P_i D_i R_i = \\mathrm{diag}(1, 1, 1, w, 0, 0, 0) + \\mathrm{diag}(0, 0, 0, w, 1, 1, 1) = \\mathrm{diag}(1, 1, 1, w+w, 1, 1, 1)\n$$\n$$\n= \\mathrm{diag}(1, 1, 1, 2w, 1, 1, 1)\n$$\nFor this matrix to be equal to the identity matrix $I_7 = \\mathrm{diag}(1, 1, 1, 1, 1, 1, 1)$, their corresponding entries must be equal. The entries for indices $1, 2, 3, 5, 6, 7$ are already $1$. For the fourth diagonal entry, we must have:\n$$\n2w = 1\n$$\nSolving for $w$ yields:\n$$\nw = \\frac{1}{2}\n$$\nThis is the unique value of $w$ that satisfies the partition-of-unity condition. This weighting scheme ensures that the contribution of the overlapping node, which is counted twice, is scaled by one-half in each subdomain, so that its total contribution sums to unity.", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "3544213"}, {"introduction": "While Additive Schwarz methods are viewed as preconditioners, Multiplicative Schwarz methods are naturally understood as iterative solvers that apply corrections sequentially across subdomains. The convergence of such a stationary iterative process is entirely determined by the spectral properties of its error propagation operator. This practice challenges you to derive this operator from first principles for a simple 1D problem and compute its spectral radius, $\\rho(E)$. This provides a tangible analysis of the method's convergence speed and reveals the algebraic mechanism by which errors are annihilated iteration by iteration [@problem_id:3544255].", "problem": "Consider the one-dimensional Poisson boundary value problem $-u''(x)=f(x)$ on $[0,1]$ with homogeneous Dirichlet boundary conditions $u(0)=u(1)=0$. Discretize using the standard second-order centered finite difference with $N=5$ interior grid points. For the linear system $A u = b$, take the stiffness matrix $A \\in \\mathbb{R}^{5 \\times 5}$ to be the unscaled Dirichlet discrete Laplacian\n$$\nA \\;=\\; \\begin{pmatrix}\n2  -1  0  0  0 \\\\\n-1  2  -1  0  0 \\\\\n0  -1  2  -1  0 \\\\\n0  0  -1  2  -1 \\\\\n0  0  0  -1  2\n\\end{pmatrix}.\n$$\nPartition the index set $\\{1,2,3,4,5\\}$ into two overlapping subdomains $\\Omega_{1}=\\{1,2,3\\}$ and $\\Omega_{2}=\\{3,4,5\\}$. Define the restriction operators $R_{1},R_{2} \\in \\mathbb{R}^{3 \\times 5}$ to extract the components on $\\Omega_{1}$ and $\\Omega_{2}$, respectively, and set the prolongations to be $P_{i}=R_{i}^{\\top}$ for $i \\in \\{1,2\\}$. Define the local operators by $A_{i} = R_{i} A P_{i}$, which correspond to exact subdomain solves with homogeneous Dirichlet conditions on the artificial subdomain boundaries. Consider the multiplicative Alternating Schwarz Method (ASM), which applies an exact solve on $\\Omega_{1}$ followed by an exact solve on $\\Omega_{2}$ at each iteration, and view it as a stationary method acting linearly on the current error vector.\n\nStarting from these definitions only, first derive the one-step error-propagation operator of the two-subdomain multiplicative Schwarz iteration in terms of $A$, $R_{i}$, $P_{i}$, and $A_{i}^{-1}$, explaining each step of the derivation from first principles in numerical linear algebra and domain decomposition. Then, for the concrete data above, form the explicit $5 \\times 5$ iteration matrix and compute its spectral radius $\\rho(E)$.\n\nProvide the exact value of $\\rho(E)$ as your final answer. No rounding is required and no units are to be reported.", "solution": "The problem is valid as it is scientifically grounded, well-posed, objective, and complete. It presents a standard exercise in the numerical analysis of domain decomposition methods. I will proceed with the solution, which consists of two main parts as requested: first, the derivation of the error-propagation operator, and second, its explicit computation and the calculation of its spectral radius for the given data.\n\n**Part 1: Derivation of the Multiplicative Schwarz Error-Propagation Operator**\n\nLet the exact solution to the linear system be $u$, such that $A u = b$. Let $u^{(k)}$ be the approximate solution at iteration $k$. The error at this iteration is defined as $e^{(k)} = u - u^{(k)}$. The residual is $r^{(k)} = b - A u^{(k)} = A u - A u^{(k)} = A(u - u^{(k)}) = A e^{(k)}$.\n\nThe multiplicative Alternating Schwarz Method (ASM) consists of sequential corrections on the subdomains $\\Omega_1$ and $\\Omega_2$.\n\n**Step 1: Correction on Subdomain $\\Omega_1$**\n\nStarting with the approximation $u^{(k)}$, we compute a correction restricted to the degrees of freedom in $\\Omega_1$. The correction is determined by solving the local problem for the current residual. The residual on $\\Omega_1$ is $r_1^{(k)} = R_1 r^{(k)}$. The local correction $c_1$ in the coordinates of $\\Omega_1$ is found by solving the local system $A_1 c_1 = r_1^{(k)}$, which corresponds to an exact solve on the subdomain. Thus, $c_1 = A_1^{-1} r_1^{(k)} = A_1^{-1} R_1 r^{(k)}$.\n\nThis local correction is then prolonged back to the global grid and added to the current solution to produce an intermediate solution $u^{(k+1/2)}$:\n$$ u^{(k+1/2)} = u^{(k)} + P_1 c_1 = u^{(k)} + P_1 A_1^{-1} R_1 r^{(k)} $$\nTo find the error-propagation operator for this step, we analyze the transformation of the error. The new error is $e^{(k+1/2)} = u - u^{(k+1/2)}$.\n$$ e^{(k+1/2)} = u - \\left(u^{(k)} + P_1 A_1^{-1} R_1 r^{(k)}\\right) $$\nSubstituting $u-u^{(k)} = e^{(k)}$ and $r^{(k)}=A e^{(k)}$:\n$$ e^{(k+1/2)} = (u - u^{(k)}) - P_1 A_1^{-1} R_1 (A e^{(k)}) $$\n$$ e^{(k+1/2)} = e^{(k)} - P_1 A_1^{-1} R_1 A e^{(k)} = (I - P_1 A_1^{-1} R_1 A) e^{(k)} $$\nWe define the error-propagation operator for the first half-step as $E_1 = I - P_1 A_1^{-1} R_1 A$.\n\n**Step 2: Correction on Subdomain $\\Omega_2$**\n\nNext, we start with the intermediate approximation $u^{(k+1/2)}$ and apply a similar correction for subdomain $\\Omega_2$. The residual is now $r^{(k+1/2)} = b - A u^{(k+1/2)} = A e^{(k+1/2)}$. The local residual is $r_2^{(k+1/2)} = R_2 r^{(k+1/2)}$, and the local correction is $c_2 = A_2^{-1} r_2^{(k+1/2)}$. The final updated solution for iteration $k$ is:\n$$ u^{(k+1)} = u^{(k+1/2)} + P_2 c_2 = u^{(k+1/2)} + P_2 A_2^{-1} R_2 r^{(k+1/2)} $$\nThe corresponding error transformation is:\n$$ e^{(k+1)} = u - u^{(k+1)} = u - \\left(u^{(k+1/2)} + P_2 A_2^{-1} R_2 r^{(k+1/2)}\\right) $$\nSubstituting $u-u^{(k+1/2)} = e^{(k+1/2)}$ and $r^{(k+1/2)}=A e^{(k+1/2)}$:\n$$ e^{(k+1)} = e^{(k+1/2)} - P_2 A_2^{-1} R_2 A e^{(k+1/2)} = (I - P_2 A_2^{-1} R_2 A) e^{(k+1/2)} $$\nWe define the error-propagation operator for the second half-step as $E_2 = I - P_2 A_2^{-1} R_2 A$.\n\n**Step 3: Combined Operator**\n\nBy composing the two steps, we find the total error propagation for one full iteration:\n$$ e^{(k+1)} = E_2 e^{(k+1/2)} = E_2 (E_1 e^{(k)}) = (E_2 E_1) e^{(k)} $$\nTherefore, the one-step error-propagation operator for the multiplicative Schwarz method is $E = E_2 E_1$, which is:\n$$ E = (I - P_2 A_2^{-1} R_2 A) (I - P_1 A_1^{-1} R_1 A) $$\nThis completes the derivation.\n\n**Part 2: Computation for the Given Problem**\n\nThe global stiffness matrix is $A \\in \\mathbb{R}^{5 \\times 5}$:\n$$ A = \\begin{pmatrix} 2  -1  0  0  0 \\\\ -1  2  -1  0  0 \\\\ 0  -1  2  -1  0 \\\\ 0  0  -1  2  -1 \\\\ 0  0  0  -1  2 \\end{pmatrix} $$\nThe subdomains are $\\Omega_1=\\{1,2,3\\}$ and $\\Omega_2=\\{3,4,5\\}$. The restriction operators $R_1, R_2$ and prolongation operators $P_1=R_1^\\top, P_2=R_2^\\top$ are:\n$$ R_1 = \\begin{pmatrix} 1  0  0  0  0 \\\\ 0  1  0  0  0 \\\\ 0  0  1  0  0 \\end{pmatrix}, \\quad P_1 = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\\\ 0  0  0 \\\\ 0  0  0 \\end{pmatrix} $$\n$$ R_2 = \\begin{pmatrix} 0  0  1  0  0 \\\\ 0  0  0  1  0 \\\\ 0  0  0  0  1 \\end{pmatrix}, \\quad P_2 = \\begin{pmatrix} 0  0  0 \\\\ 0  0  0 \\\\ 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{pmatrix} $$\nThe local operators $A_i = R_i A P_i$ are the principal submatrices of $A$:\n$$ A_1 = R_1 A P_1 = \\begin{pmatrix} 2  -1  0 \\\\ -1  2  -1 \\\\ 0  -1  2 \\end{pmatrix}, \\quad A_2 = R_2 A P_2 = \\begin{pmatrix} 2  -1  0 \\\\ -1  2  -1 \\\\ 0  -1  2 \\end{pmatrix} $$\nThe inverse of this $3 \\times 3$ matrix is required. Let $B = A_1=A_2$. The determinant is $\\det(B) = 2(4-1) - (-1)(-2) = 4$.\n$$ B^{-1} = \\frac{1}{4} \\begin{pmatrix} 3  2  1 \\\\ 2  4  2 \\\\ 1  2  3 \\end{pmatrix} $$\nSo, $A_1^{-1} = A_2^{-1} = \\frac{1}{4} \\begin{pmatrix} 3  2  1 \\\\ 2  4  2 \\\\ 1  2  3 \\end{pmatrix}$.\n\nNow, we construct $E_1 = I - P_1 A_1^{-1} R_1 A$.\n$$ R_1 A = \\begin{pmatrix} 2  -1  0  0  0 \\\\ -1  2  -1  0  0 \\\\ 0  -1  2  -1  0 \\end{pmatrix} $$\n$$ A_1^{-1} (R_1 A) = \\frac{1}{4} \\begin{pmatrix} 3  2  1 \\\\ 2  4  2 \\\\ 1  2  3 \\end{pmatrix} \\begin{pmatrix} 2  -1  0  0  0 \\\\ -1  2  -1  0  0 \\\\ 0  -1  2  -1  0 \\end{pmatrix} = \\frac{1}{4} \\begin{pmatrix} 4  0  0  -1  0 \\\\ 0  4  0  -2  0 \\\\ 0  0  4  -3  0 \\end{pmatrix} = \\begin{pmatrix} 1  0  0  -1/4  0 \\\\ 0  1  0  -1/2  0 \\\\ 0  0  1  -3/4  0 \\end{pmatrix} $$\n$$ P_1 (A_1^{-1} R_1 A) = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\\\ 0  0  0 \\\\ 0  0  0 \\end{pmatrix} \\begin{pmatrix} 1  0  0  -1/4  0 \\\\ 0  1  0  -1/2  0 \\\\ 0  0  1  -3/4  0 \\end{pmatrix} = \\begin{pmatrix} 1  0  0  -1/4  0 \\\\ 0  1  0  -1/2  0 \\\\ 0  0  1  -3/4  0 \\\\ 0  0  0  0  0 \\\\ 0  0  0  0  0 \\end{pmatrix} $$\n$$ E_1 = I - P_1 A_1^{-1} R_1 A = \\begin{pmatrix} 0  0  0  1/4  0 \\\\ 0  0  0  1/2  0 \\\\ 0  0  0  3/4  0 \\\\ 0  0  0  1  0 \\\\ 0  0  0  0  1 \\end{pmatrix} $$\nNext, we construct $E_2 = I - P_2 A_2^{-1} R_2 A$.\n$$ R_2 A = \\begin{pmatrix} 0  -1  2  -1  0 \\\\ 0  0  -1  2  -1 \\\\ 0  0  0  -1  2 \\end{pmatrix} $$\n$$ A_2^{-1} (R_2 A) = \\frac{1}{4} \\begin{pmatrix} 3  2  1 \\\\ 2  4  2 \\\\ 1  2  3 \\end{pmatrix} \\begin{pmatrix} 0  -1  2  -1  0 \\\\ 0  0  -1  2  -1 \\\\ 0  0  0  -1  2 \\end{pmatrix} = \\frac{1}{4} \\begin{pmatrix} 0  -3  4  0  0 \\\\ 0  -2  0  4  0 \\\\ 0  -1  0  0  4 \\end{pmatrix} = \\begin{pmatrix} 0  -3/4  1  0  0 \\\\ 0  -1/2  0  1  0 \\\\ 0  -1/4  0  0  1 \\end{pmatrix} $$\n$$ P_2 (A_2^{-1} R_2 A) = \\begin{pmatrix} 0  0  0 \\\\ 0  0  0 \\\\ 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{pmatrix} \\begin{pmatrix} 0  -3/4  1  0  0 \\\\ 0  -1/2  0  1  0 \\\\ 0  -1/4  0  0  1 \\end{pmatrix} = \\begin{pmatrix} 0  0  0  0  0 \\\\ 0  0  0  0  0 \\\\ 0  -3/4  1  0  0 \\\\ 0  -1/2  0  1  0 \\\\ 0  -1/4  0  0  1 \\end{pmatrix} $$\n$$ E_2 = I - P_2 A_2^{-1} R_2 A = \\begin{pmatrix} 1  0  0  0  0 \\\\ 0  1  0  0  0 \\\\ 0  3/4  0  0  0 \\\\ 0  1/2  0  0  0 \\\\ 0  1/4  0  0  0 \\end{pmatrix} $$\nNow we compute the final iteration matrix $E = E_2 E_1$:\n$$ E = \\begin{pmatrix} 1  0  0  0  0 \\\\ 0  1  0  0  0 \\\\ 0  3/4  0  0  0 \\\\ 0  1/2  0  0  0 \\\\ 0  1/4  0  0  0 \\end{pmatrix} \\begin{pmatrix} 0  0  0  1/4  0 \\\\ 0  0  0  1/2  0 \\\\ 0  0  0  3/4  0 \\\\ 0  0  0  1  0 \\\\ 0  0  0  0  1 \\end{pmatrix} = \\begin{pmatrix} 0  0  0  1/4  0 \\\\ 0  0  0  1/2  0 \\\\ 0  0  0  (3/4)(1/2)  0 \\\\ 0  0  0  (1/2)(1/2)  0 \\\\ 0  0  0  (1/4)(1/2)  0 \\end{pmatrix} = \\begin{pmatrix} 0  0  0  1/4  0 \\\\ 0  0  0  1/2  0 \\\\ 0  0  0  3/8  0 \\\\ 0  0  0  1/4  0 \\\\ 0  0  0  1/8  0 \\end{pmatrix} $$\nFinally, we compute the spectral radius $\\rho(E)$, which is the maximum absolute value of the eigenvalues of $E$. The eigenvalues $\\lambda$ are the roots of the characteristic equation $\\det(E - \\lambda I) = 0$.\n$$ E - \\lambda I = \\begin{pmatrix} -\\lambda  0  0  1/4  0 \\\\ 0  -\\lambda  0  1/2  0 \\\\ 0  0  -\\lambda  3/8  0 \\\\ 0  0  0  1/4-\\lambda  0 \\\\ 0  0  0  1/8  -\\lambda \\end{pmatrix} $$\nThis is an upper triangular matrix. Its determinant is the product of its diagonal elements:\n$$ \\det(E - \\lambda I) = (-\\lambda)(-\\lambda)(-\\lambda)(1/4 - \\lambda)(-\\lambda) = \\lambda^4 (1/4 - \\lambda) $$\nThe roots of the characteristic equation $\\lambda^4 (1/4 - \\lambda)=0$ are $\\lambda_1=\\lambda_2=\\lambda_3=\\lambda_4=0$ and $\\lambda_5 = 1/4$.\nThe set of eigenvalues of $E$ is $\\sigma(E) = \\{0, 1/4\\}$.\nThe spectral radius is the maximum modulus of these eigenvalues:\n$$ \\rho(E) = \\max_{\\lambda \\in \\sigma(E)} |\\lambda| = \\max\\{|0|, |1/4|\\} = 1/4 $$\nThis is the exact value of the spectral radius of the iteration matrix.", "answer": "$$\\boxed{\\frac{1}{4}}$$", "id": "3544255"}, {"introduction": "The theoretical elegance of Schwarz methods must eventually confront the practical realities of implementation, especially when moving from one-dimensional models to more realistic 2D or 3D settings. In this context, the Additive Schwarz method's performance as a preconditioner, measured by the condition number $\\kappa(M^{-1} A)$, is highly sensitive to the geometric properties of the subdomains. This computational exercise asks you to investigate this relationship directly by exploring how subdomain shapes, from compact squares to elongated rectangles, affect the condition number. This practice bridges theory and high-performance computing by revealing how strategic decomposition is key to designing efficient parallel solvers [@problem_id:3544245].", "problem": "Consider the discrete Poisson problem with homogeneous Dirichlet boundary conditions on the unit square, discretized by a uniform grid of $N_x \\times N_y$ interior points, yielding a symmetric positive definite matrix $A \\in \\mathbb{R}^{n \\times n}$, where $n = N_x N_y$. The discrete operator $A$ is defined by the standard five-point stencil, which can be constructed from one-dimensional second-difference matrices using the Kronecker product. The Additive Schwarz preconditioner $M$ is defined by a covering of the global index set by overlapping subdomains. Each subdomain $S_i$ induces a local system $A_{S_i}$ formed by restricting $A$ to the indices in $S_i$, applying homogeneous Dirichlet boundary conditions at the subdomain boundary. The preconditioner is applied as $M^{-1} r = \\sum_i R_i^{\\top} A_{S_i}^{-1} R_i r$, where $R_i$ is the restriction operator onto subdomain $S_i$.\n\nYour task is to study how the shape of subdomains influences the conditioning of the preconditioned operator $M^{-1} A$ and to design computational geometry metrics that correlate with the condition number $\\kappa(M^{-1} A)$. You must:\n\n1. Construct the sparse matrix $A$ for the discrete Poisson operator on a grid with $N_x = 12$ and $N_y = 12$ interior points.\n2. Define coverings of the domain by overlapping subdomains of different geometric shapes. For each covering, build the corresponding Additive Schwarz preconditioner $M$ by precomputing local factorizations of the subdomain-restricted matrices $A_{S_i}$.\n3. For each covering, explicitly construct the dense matrix representation of the preconditioned operator $P = M^{-1} A$ by applying $M^{-1} A$ to each canonical basis vector of $\\mathbb{R}^n$ and assembling the columns. Symmetrize $P$ by replacing it with $\\tfrac{1}{2}(P + P^{\\top})$.\n4. Compute the eigenvalues of $P$ and report the condition number $\\kappa(M^{-1} A)$ defined as the ratio of the largest eigenvalue to the smallest eigenvalue.\n5. For each covering, compute the following computational geometry metrics over its subdomains and report their averages across subdomains:\n   - The average aspect ratio, defined for a subdomain as the ratio between the larger and smaller of its bounding-box side lengths measured in grid nodes.\n   - The average perimeter-to-area ratio, where the perimeter is the count of grid-adjacent boundary edges of the subdomain and the area is the number of interior grid nodes in the subdomain.\n   - The average normalized bottleneck width, defined as the minimum count of subdomain nodes along any fixed column or row within its bounding box, divided by the larger of the bounding-box side lengths.\n   - The average overlap multiplicity, defined as the average, over all global grid nodes, of the number of subdomains that contain that node.\n6. Compute the Pearson correlation coefficient between the list of condition numbers for the test suite and each of the four lists of metric averages.\n\nImplement the following test suite of subdomain coverings on the $12 \\times 12$ grid. Each covering must tile the domain without gaps when overlap is zero and cover the domain when overlap is positive. For dilation by an overlap width $g$, treat the grid as a four-neighbor graph and include all nodes within graph distance at most $g$ from the base subdomain shape.\n- Case 1: Square subdomains of size $4 \\times 4$ with overlap $g = 1$.\n- Case 2: Elongated horizontal rectangles of size $6 \\times 2$ with overlap $g = 1$.\n- Case 3: Elongated vertical rectangles of size $2 \\times 6$ with overlap $g = 1$.\n- Case 4: L-shaped subdomains: bounding boxes of size $4 \\times 4$ with a $2 \\times 2$ corner removed from the top-left of each bounding box; overlap $g = 2$ applied to the resulting L-shape.\n- Case 5: Square subdomains of size $4 \\times 4$ with overlap $g = 0$.\n- Case 6: Square subdomains of size $4 \\times 4$ with overlap $g = 2$.\n\nThe final output must be a single line consisting of a comma-separated list enclosed in square brackets, containing the six condition numbers in the order of the cases above, followed by the four correlation coefficients between the six condition numbers and, respectively, the average aspect ratio, the average perimeter-to-area ratio, the average normalized bottleneck width, and the average overlap multiplicity. All numerical outputs must be real numbers without any percentage signs or units.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,...]\"). No user input is required, and your program must be self-contained.", "solution": "The problem statement has been critically validated and is deemed valid. It presents a well-posed computational problem in the field of numerical linear algebra, specifically concerning domain decomposition methods. The problem is scientifically grounded, objective, and self-contained, with all necessary parameters and definitions provided for a unique numerical solution. While it contains a minor procedural deviation from standard theoretical analysis by instructing to symmetrize the generally non-symmetric preconditioned operator before eigenvalue computation, this is a clear and executable directive that does not invalidate the problem's integrity. The task is to investigate the relationship between subdomain geometry and the conditioning of an Additive Schwarz preconditioned system.\n\nThe solution proceeds as follows:\n1.  **System Matrix Construction**: The discrete Poisson operator on a uniform grid is constructed.\n2.  **Domain Decomposition and Preconditioner**: For each test case, the domain is partitioned, subdomains are defined with specified overlap, and the Additive Schwarz preconditioner is built.\n3.  **Preconditioned Operator Analysis**: The dense preconditioned operator matrix is explicitly constructed, symmetrized, and its condition number is computed from its eigenvalues.\n4.  **Geometric Metric Calculation**: For each decomposition, four distinct geometric metrics are computed and averaged over the subdomains.\n5.  **Correlation Analysis**: The Pearson correlation coefficient is calculated between the set of condition numbers and each set of averaged geometric metrics.\n\n**1. The Discrete Poisson Problem**\nWe consider the Poisson equation $-\\Delta u = f$ on the unit square $\\Omega = (0,1) \\times (0,1)$ with homogeneous Dirichlet boundary conditions $u|_{\\partial\\Omega}=0$. Discretizing this problem on a uniform grid with $N_x \\times N_y$ interior points using a centered finite difference scheme results in a linear system $A\\mathbf{u} = \\mathbf{f}$. The grid spacing is $h = 1/(N+1)$ where for simplicity we assume $N_x=N_y=N$. The vector $\\mathbf{u}$ contains the values of the solution at the interior grid points, ordered lexicographically. The matrix $A$ is a symmetric positive definite (SPD) block-tridiagonal matrix of size $n \\times n$, where $n = N_x N_y$.\n\nFor this problem, $N_x=12$ and $N_y=12$, so $n=144$. The matrix $A$ can be constructed using the Kronecker product of one-dimensional second-difference matrices. Let $T_k \\in \\mathbb{R}^{k \\times k}$ be the tridiagonal matrix with $2$ on the main diagonal and $-1$ on the first off-diagonals. Then, the two-dimensional discrete Laplacian matrix $A$ (scaled by $h^2$, which does not affect the condition number of $M^{-1}A$) is given by:\n$$\nA = I_{N_y} \\otimes T_{N_x} + T_{N_y} \\otimes I_{N_x}\n$$\nwhere $I_k$ is the $k \\times k$ identity matrix. This matrix represents the connectivity of the five-point stencil on the grid.\n\n**2. Additive Schwarz Preconditioner**\nThe Additive Schwarz Method is a domain decomposition technique for preconditioning the system $A\\mathbf{u}=\\mathbf{f}$. The domain (the set of grid indices $\\{0, \\dots, n-1\\}$) is covered by a set of $K$ overlapping subdomains $\\{S_i\\}_{i=1}^K$.\nFor each subdomain $S_i$, we define a restriction operator $R_i: \\mathbb{R}^n \\to \\mathbb{R}^{|S_i|}$ which is a matrix that extracts the components of a vector corresponding to the indices in $S_i$. Its transpose, $R_i^\\top$, is the extension-by-zero operator that embeds a local vector from the subdomain back into the global vector space.\nThe local system matrix for subdomain $S_i$ is $A_{S_i} = R_i A R_i^\\top$. This corresponds to the principal submatrix of $A$ associated with the indices in $S_i$. These local matrices inherit the SPD property from $A$.\nThe Additive Schwarz preconditioner $M$ is defined by its inverse action:\n$$\nM^{-1} = \\sum_{i=1}^K R_i^\\top A_{S_i}^{-1} R_i\n$$\nApplying the preconditioner involves restricting the residual to each subdomain, solving a local problem (with Dirichlet boundary conditions on the artificial subdomain boundaries), and adding the extended local solutions together. For this problem, we pre-compute the inverses $A_{S_i}^{-1}$ since the subdomains are small.\n\nThe subdomains for each test case are generated by first defining a set of non-overlapping \"base\" shapes that partition the $12 \\times 12$ grid. Then, an overlap of width $g$ is introduced by dilating each base shape. The dilation includes all grid nodes within a graph distance of $g$ from any node in the base shape, where distance is measured on the 4-neighbor grid graph.\n\n**3. Preconditioned Operator and Condition Number**\nThe preconditioned operator is $P_{op} = M^{-1}A$. The goal is to compute its condition number, $\\kappa(M^{-1}A) = \\| M^{-1}A \\| \\| (M^{-1}A)^{-1} \\|$. For an SPD matrix $A$ and SPD preconditioner $M$, the eigenvalues of $M^{-1}A$ are real and positive. The condition number is then $\\kappa = \\lambda_{\\max} / \\lambda_{\\min}$.\nThe problem specifies an explicit procedure for this computation:\n1. Construct the dense matrix representation $P$ of the operator $M^{-1}A$. The $j$-th column of $P$ is $P_j = M^{-1}A e_j$, where $e_j$ is the $j$-th canonical basis vector and $A e_j$ is the $j$-th column of $A$.\n2. The operator $M^{-1}A$ is generally not symmetric. The problem instructs to form a symmetric matrix $P_{sym} = \\frac{1}{2}(P + P^\\top)$.\n3. Compute the eigenvalues of $P_{sym}$. Since $P_{sym}$ is symmetric, its eigenvalues are real. We find the largest eigenvalue $\\lambda_{\\max}$ and the smallest positive eigenvalue $\\lambda_{\\min}$.\n4. The condition number is reported as $\\kappa = \\lambda_{\\max} / \\lambda_{\\min}$.\n\n**4. Geometric Metrics**\nTo correlate the conditioning with subdomain geometry, four metrics are computed for each subdomain covering and then averaged. For a given subdomain $S$, represented as a set of $(i,j)$ grid coordinates:\n- **Aspect Ratio**: Let the bounding box of $S$ be $[i_{\\min}, i_{\\max}] \\times [j_{\\min}, j_{\\max}]$. The side lengths are $L_x = i_{\\max} - i_{\\min} + 1$ and $L_y = j_{\\max} - j_{\\min} + 1$. The aspect ratio is $\\max(L_x, L_y) / \\min(L_x, L_y)$.\n- **Perimeter-to-Area Ratio**: The area is $|S|$, the number of nodes in the subdomain. The perimeter is the number of edges connecting a node in $S$ to a node not in $S$ on the 4-neighbor grid graph.\n- **Normalized Bottleneck Width**: This measures the \"thinness\" of a shape. We count the number of nodes in $S$ for each row and each column within its bounding box. The minimum of these counts is the bottleneck width. This is then normalized by $\\max(L_x, L_y)$.\n- **Average Overlap Multiplicity**: This is a global metric of the covering, not specific to a single subdomain, but averaged over all nodes. It is the average number of subdomains to which a grid node belongs, calculated as $(\\sum_{i=1}^K |S_i|) / n$.\n\n**5. Correlation Analysis**\nThe final step is to quantify the relationship between the computed condition numbers and the geometric metrics. This is done by calculating the Pearson correlation coefficient, $\\rho$, for the set of six data points (one for each test case). For a list of condition numbers $X = (\\kappa_1, \\dots, \\kappa_6)$ and a corresponding list of metric averages $Y = (m_1, \\dots, m_6)$, the coefficient is:\n$$\n\\rho(X, Y) = \\frac{\\sum_{i=1}^6 (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum_{i=1}^6 (X_i - \\bar{X})^2} \\sqrt{\\sum_{i=1}^6 (Y_i - \\bar{Y})^2}}\n$$\nThis value ranges from $-1$ to $1$, indicating the strength and direction of a linear relationship between the two variables. This analysis will be performed for each of the four geometric metrics against the condition number.", "answer": "```python\nimport numpy as np\nfrom scipy.sparse import diags, kron, eye, csc_matrix\nfrom scipy.linalg import inv\nfrom collections import deque\n\ndef solve():\n    \"\"\"\n    Main function to solve the entire problem as specified.\n    \"\"\"\n    Nx, Ny = 12, 12\n    n = Nx * Ny\n\n    # 1. Construct the sparse matrix A for the discrete Poisson operator.\n    def get_laplacian_matrix(nx, ny):\n        T_x = diags([-1, 2, -1], [-1, 0, 1], shape=(nx, nx))\n        T_y = diags([-1, 2, -1], [-1, 0, 1], shape=(ny, ny))\n        I_x = eye(nx)\n        I_y = eye(ny)\n        A = kron(I_y, T_x) + kron(T_y, I_x)\n        return A.tocsc()\n\n    A = get_laplacian_matrix(Nx, Ny)\n    A_dense = A.toarray()\n\n    # Helper for grid operations\n    def to_1d(i, j, nx):\n        return i + j * nx\n\n    def to_2d(k, nx):\n        return k % nx, k // nx\n\n    # 2. Define subdomain coverings and build preconditioners.\n    def get_base_subdomains(case_name, nx, ny):\n        subdomains = []\n        if case_name == \"4x4\":\n            for j in range(ny // 4):\n                for i in range(nx // 4):\n                    base = []\n                    for jj in range(4):\n                        for ii in range(4):\n                            base.append(to_1d(i * 4 + ii, j * 4 + jj, nx))\n                    subdomains.append(base)\n        elif case_name == \"6x2_horiz\":\n            for j in range(ny // 2):\n                for i in range(nx // 6):\n                    base = []\n                    for jj in range(2):\n                        for ii in range(6):\n                            base.append(to_1d(i * 6 + ii, j * 2 + jj, nx))\n                    subdomains.append(base)\n        elif case_name == \"2x6_vert\":\n            for j in range(ny // 6):\n                for i in range(nx // 2):\n                    base = []\n                    for jj in range(6):\n                        for ii in range(2):\n                            base.append(to_1d(i * 2 + ii, j * 6 + jj, nx))\n                    subdomains.append(base)\n        elif case_name == \"L_shape\":\n            for j in range(ny // 4):\n                for i in range(nx // 4):\n                    base = []\n                    i0, j0 = i * 4, j * 4\n                    for jj in range(4):\n                        for ii in range(4):\n                            if not (ii  2 and jj  2):\n                                base.append(to_1d(i0 + ii, j0 + jj, nx))\n                    subdomains.append(base)\n        return subdomains\n\n    def dilate_subdomains(base_subdomains, g, nx, ny):\n        dilated_subdomains = []\n        for base in base_subdomains:\n            q = deque([(k, 0) for k in base])\n            visited = set(base)\n            dilated = set(base)\n            while q:\n                k, dist = q.popleft()\n                if dist = g:\n                    continue\n                \n                i, j = to_2d(k, nx)\n                for di, dj in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                    ni, nj = i + di, j + dj\n                    if 0 = ni  nx and 0 = nj  ny:\n                        nk = to_1d(ni, nj, nx)\n                        if nk not in visited:\n                            visited.add(nk)\n                            dilated.add(nk)\n                            q.append((nk, dist + 1))\n            dilated_subdomains.append(sorted(list(dilated)))\n        return dilated_subdomains\n\n    # 3. For each covering, build P, compute kappa, and compute metrics.\n    test_cases = [\n        (\"4x4\", 1),         # Case 1\n        (\"6x2_horiz\", 1),   # Case 2\n        (\"2x6_vert\", 1),    # Case 3\n        (\"L_shape\", 2),     # Case 4\n        (\"4x4\", 0),         # Case 5\n        (\"4x4\", 2)          # Case 6\n    ]\n\n    all_conds = []\n    all_avg_aspect_ratios = []\n    all_avg_p2a_ratios = []\n    all_avg_bottlenecks = []\n    all_avg_overlaps = []\n    \n    for shape, g in test_cases:\n        base_subdomains = get_base_subdomains(shape, Nx, Ny)\n        subdomains = dilate_subdomains(base_subdomains, g, Nx, Ny)\n\n        # Build preconditioner M^-1 components\n        A_inv_locals = []\n        for S_indices in subdomains:\n            A_S = A[np.ix_(S_indices, S_indices)].toarray()\n            A_inv_locals.append(inv(A_S))\n\n        # Explicitly construct dense P = M^-1 * A\n        P = np.zeros((n, n))\n        for j_col in range(n):\n            a_j = A_dense[:, j_col]\n            v = np.zeros(n)\n            for i, S_indices in enumerate(subdomains):\n                a_j_local = a_j[S_indices]\n                sol_local = A_inv_locals[i] @ a_j_local\n                v[S_indices] += sol_local\n            P[:, j_col] = v\n        \n        # Symmetrize P\n        P_sym = 0.5 * (P + P.T)\n        \n        # Compute eigenvalues and condition number\n        eigenvalues = np.linalg.eigvalsh(P_sym)\n        # Filter out potential small negative values due to floating point error\n        positive_eigenvalues = eigenvalues[eigenvalues  1e-12]\n        lambda_max = np.max(positive_eigenvalues)\n        lambda_min = np.min(positive_eigenvalues)\n        cond_num = lambda_max / lambda_min\n        all_conds.append(cond_num)\n\n        # Compute geometric metrics\n        aspect_ratios = []\n        p2a_ratios = []\n        bottlenecks = []\n        \n        subdomain_coords = [[to_2d(k, Nx) for k in S] for S in subdomains]\n\n        for i, S_indices in enumerate(subdomains):\n            coords = np.array(subdomain_coords[i])\n            i_coords, j_coords = coords[:, 0], coords[:, 1]\n\n            # Aspect ratio\n            i_min, i_max = np.min(i_coords), np.max(i_coords)\n            j_min, j_max = np.min(j_coords), np.max(j_coords)\n            side_x = i_max - i_min + 1\n            side_y = j_max - j_min + 1\n            aspect_ratios.append(max(side_x, side_y) / min(side_x, side_y))\n\n            # Perimeter-to-area\n            area = len(S_indices)\n            perimeter = 0\n            S_set = set(S_indices)\n            for k in S_indices:\n                i_node, j_node = to_2d(k, Nx)\n                for di, dj in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                    ni, nj = i_node + di, j_node + dj\n                    if 0 = ni  Nx and 0 = nj  Ny:\n                        if to_1d(ni, nj, Nx) not in S_set:\n                            perimeter += 1\n            p2a_ratios.append(perimeter / area)\n\n            # Normalized bottleneck width\n            counts = []\n            if side_x  0:\n                for c in range(i_min, i_max + 1):\n                    counts.append(np.sum(i_coords == c))\n            if side_y  0:\n                for r in range(j_min, j_max + 1):\n                    counts.append(np.sum(j_coords == r))\n            \n            min_count = min(counts) if counts else 0\n            bottlenecks.append(min_count / max(side_x, side_y))\n\n        # Overlap multiplicity\n        overlap_counts = np.zeros(n)\n        for S_indices in subdomains:\n            overlap_counts[S_indices] += 1\n        \n        all_avg_aspect_ratios.append(np.mean(aspect_ratios))\n        all_avg_p2a_ratios.append(np.mean(p2a_ratios))\n        all_avg_bottlenecks.append(np.mean(bottlenecks))\n        all_avg_overlaps.append(np.mean(overlap_counts))\n\n    # 6. Compute correlation coefficients\n    corr_aspect = np.corrcoef(all_conds, all_avg_aspect_ratios)[0, 1]\n    corr_p2a = np.corrcoef(all_conds, all_avg_p2a_ratios)[0, 1]\n    corr_bottle = np.corrcoef(all_conds, all_avg_bottlenecks)[0, 1]\n    corr_overlap = np.corrcoef(all_conds, all_avg_overlaps)[0, 1]\n\n    # Final result assembly and output\n    results = all_conds + [corr_aspect, corr_p2a, corr_bottle, corr_overlap]\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3544245"}]}