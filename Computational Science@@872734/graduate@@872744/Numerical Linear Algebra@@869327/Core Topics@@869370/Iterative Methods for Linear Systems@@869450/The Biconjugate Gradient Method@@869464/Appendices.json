{"hands_on_practices": [{"introduction": "The Biconjugate Gradient method's stability hinges on a key relationship between the primal residual $r_k$ and the shadow residual $\\tilde{r}_k$. At initialization, this requires the biorthogonality product $\\tilde{r}_0^T r_0$ to be non-zero, a condition that prevents immediate breakdown. This first exercise provides practice in computing these initial residuals and verifying this essential starting condition for the algorithm [@problem_id:3585481].", "problem": "Consider a nonsymmetric linear system with coefficient matrix $A \\in \\mathbb{R}^{3 \\times 3}$, right-hand side $b \\in \\mathbb{R}^{3}$, and an initial guess $x_{0} \\in \\mathbb{R}^{3}$. The biconjugate gradient method (BiCG) for nonsymmetric systems couples two Krylov processes, one defined by $A$ and the other by $A^{\\top}$, and requires two initial residuals $r_{0}$ and $\\tilde{r}_{0}$ such that the coupling $\\tilde{r}_{0}^{\\top} r_{0}$ is nonzero. Starting from the fundamental definition of a residual for a linear system, the initial residual for the primal system is defined as $r_{0} = b - A x_{0}$. To initialize the shadow process, consider the transposed system $A^{\\top} y = \\tilde{b}$ together with an initial guess $y_{0}$, and define the shadow residual $\\tilde{r}_{0} = \\tilde{b} - A^{\\top} y_{0}$. Your task is to compute $r_{0}$ and $\\tilde{r}_{0}$ from the provided data and then evaluate the bilinear form $\\tilde{r}_{0}^{\\top} r_{0}$ to verify the nondegenerate biorthogonality condition required by BiCG. Use the following data:\n$$\nA = \\begin{pmatrix}\n2  -1  0 \\\\\n1  3  -2 \\\\\n0  -1  1\n\\end{pmatrix}, \\quad\nb = \\begin{pmatrix}\n1 \\\\ 0 \\\\ 2\n\\end{pmatrix}, \\quad\nx_{0} = \\begin{pmatrix}\n0 \\\\ 1 \\\\ -1\n\\end{pmatrix},\n$$\nand for the shadow system,\n$$\n\\tilde{b} = \\begin{pmatrix}\n0 \\\\ 1 \\\\ 1\n\\end{pmatrix}, \\quad\ny_{0} = \\begin{pmatrix}\n1 \\\\ 0 \\\\ 0\n\\end{pmatrix}.\n$$\nStarting from the definitions of $r_{0}$ and $\\tilde{r}_{0}$, compute $r_{0}$ and $\\tilde{r}_{0}$ exactly, and then evaluate $\\tilde{r}_{0}^{\\top} r_{0}$. Provide the value of $\\tilde{r}_{0}^{\\top} r_{0}$ as your final answer.", "solution": "The problem is valid as it is scientifically grounded in numerical linear algebra, well-posed with all necessary data provided, and objectively stated. We proceed with the solution.\n\nThe task is to compute the value of the bilinear form $\\tilde{r}_{0}^{\\top} r_{0}$, which is a crucial quantity for initiating the biconjugate gradient (BiCG) algorithm. This requires the computation of the initial primal residual, $r_{0}$, and the initial shadow residual, $\\tilde{r}_{0}$.\n\nThe given data includes the coefficient matrix $A$, the right-hand side vector $b$, and the initial guess $x_{0}$ for the primal system $A x = b$:\n$$\nA = \\begin{pmatrix}\n2  -1  0 \\\\\n1  3  -2 \\\\\n0  -1  1\n\\end{pmatrix}, \\quad\nb = \\begin{pmatrix}\n1 \\\\\n0 \\\\\n2\n\\end{pmatrix}, \\quad\nx_{0} = \\begin{pmatrix}\n0 \\\\\n1 \\\\\n-1\n\\end{pmatrix}\n$$\nFor the auxiliary shadow system, we are given the right-hand side vector $\\tilde{b}$ and the initial guess $y_{0}$:\n$$\n\\tilde{b} = \\begin{pmatrix}\n0 \\\\\n1 \\\\\n1\n\\end{pmatrix}, \\quad\ny_{0} = \\begin{pmatrix}\n1 \\\\\n0 \\\\\n0\n\\end{pmatrix}\n$$\n\nFirst, we compute the initial residual $r_{0}$ for the primal system using its definition, $r_{0} = b - A x_{0}$.\nWe begin by calculating the product $A x_{0}$:\n$$\nA x_{0} = \\begin{pmatrix}\n2  -1  0 \\\\\n1  3  -2 \\\\\n0  -1  1\n\\end{pmatrix}\n\\begin{pmatrix}\n0 \\\\\n1 \\\\\n-1\n\\end{pmatrix}\n= \\begin{pmatrix}\n(2)(0) + (-1)(1) + (0)(-1) \\\\\n(1)(0) + (3)(1) + (-2)(-1) \\\\\n(0)(0) + (-1)(1) + (1)(-1)\n\\end{pmatrix}\n= \\begin{pmatrix}\n0 - 1 + 0 \\\\\n0 + 3 + 2 \\\\\n0 - 1 - 1\n\\end{pmatrix}\n= \\begin{pmatrix}\n-1 \\\\\n5 \\\\\n-2\n\\end{pmatrix}\n$$\nNow we can find $r_0$ by subtracting this result from $b$:\n$$\nr_{0} = b - A x_{0} = \\begin{pmatrix}\n1 \\\\\n0 \\\\\n2\n\\end{pmatrix}\n-\n\\begin{pmatrix}\n-1 \\\\\n5 \\\\\n-2\n\\end{pmatrix}\n= \\begin{pmatrix}\n1 - (-1) \\\\\n0 - 5 \\\\\n2 - (-2)\n\\end{pmatrix}\n= \\begin{pmatrix}\n2 \\\\\n-5 \\\\\n4\n\\end{pmatrix}\n$$\n\nNext, we compute the initial residual $\\tilde{r}_{0}$ for the shadow system. The definition is $\\tilde{r}_{0} = \\tilde{b} - A^{\\top} y_{0}$.\nFirst, we determine the transpose of the matrix $A$, denoted by $A^{\\top}$:\n$$\nA^{\\top} = \\begin{pmatrix}\n2  1  0 \\\\\n-1  3  -1 \\\\\n0  -2  1\n\\end{pmatrix}\n$$\nWe then calculate the product $A^{\\top} y_{0}$:\n$$\nA^{\\top} y_{0} = \\begin{pmatrix}\n2  1  0 \\\\\n-1  3  -1 \\\\\n0  -2  1\n\\end{pmatrix}\n\\begin{pmatrix}\n1 \\\\\n0 \\\\\n0\n\\end{pmatrix}\n= \\begin{pmatrix}\n(2)(1) + (1)(0) + (0)(0) \\\\\n(-1)(1) + (3)(0) + (-1)(0) \\\\\n(0)(1) + (-2)(0) + (1)(0)\n\\end{pmatrix}\n= \\begin{pmatrix}\n2 \\\\\n-1 \\\\\n0\n\\end{pmatrix}\n$$\nNow we can find $\\tilde{r}_0$ by subtracting this result from $\\tilde{b}$:\n$$\n\\tilde{r}_{0} = \\tilde{b} - A^{\\top} y_{0} = \\begin{pmatrix}\n0 \\\\\n1 \\\\\n1\n\\end{pmatrix}\n-\n\\begin{pmatrix}\n2 \\\\\n-1 \\\\\n0\n\\end{pmatrix}\n= \\begin{pmatrix}\n0 - 2 \\\\\n1 - (-1) \\\\\n1 - 0\n\\end{pmatrix}\n= \\begin{pmatrix}\n-2 \\\\\n2 \\\\\n1\n\\end{pmatrix}\n$$\n\nFinally, we evaluate the bilinear form $\\tilde{r}_{0}^{\\top} r_{0}$, which is the dot product of the vectors $\\tilde{r}_{0}$ and $r_{0}$.\n$$\n\\tilde{r}_{0}^{\\top} r_{0} = \\begin{pmatrix}\n-2  2  1\n\\end{pmatrix}\n\\begin{pmatrix}\n2 \\\\\n-5 \\\\\n4\n\\end{pmatrix}\n$$\n$$\n\\tilde{r}_{0}^{\\top} r_{0} = (-2)(2) + (2)(-5) + (1)(4) = -4 - 10 + 4 = -10\n$$\nThe condition $\\tilde{r}_{0}^{\\top} r_{0} \\neq 0$ is satisfied, which ensures that the BiCG algorithm can be initiated without breakdown at the first step. The computed value is $-10$.", "answer": "$$\\boxed{-10}$$", "id": "3585481"}, {"introduction": "Once initiated, the BiCG algorithm proceeds through a series of elegant short-recurrence relations that update the solution, residual, and search directions. This exercise offers a complete walkthrough of two full iterations of the method, providing essential practice with the computational mechanics of the algorithm. By tracking every intermediate scalar and vector, you will gain a deep, procedural understanding of how the coupled recurrences work together to find the solution [@problem_id:3585465].", "problem": "Consider the task of solving the nonsymmetric linear system $A x = b$ by performing exactly two iterations of the Biconjugate Gradient (BiCG) method (without preconditioning) in exact arithmetic, starting from $x_{0} = 0$ and taking the shadow residual equal to the initial residual. The system data are\n$$\nA = \\begin{pmatrix}\n2  1  0 \\\\\n0  3  1 \\\\\n1  0  2\n\\end{pmatrix},\n\\qquad\nb = \\begin{pmatrix}\n1 \\\\\n1 \\\\\n0\n\\end{pmatrix}.\n$$\nLet the initial residual be $r_{0} = b - A x_{0}$ and take the shadow residual $\\tilde{r}_{0} = r_{0}$. Use the standard real-arithmetic Biconjugate Gradient (BiCG) method (Biconjugate Gradient (BiCG) is defined through bi-orthogonality of the residuals with respect to $A$ and $A^{\\mathsf{T}}$, and coupled short recurrences for search directions driven by three-term relations) to:\n- Construct and report all intermediate scalars and vectors generated during the first two iterations, including $r_{k}$, $\\tilde{r}_{k}$, $p_{k}$, $\\tilde{p}_{k}$, $v_{k} = A p_{k}$, $\\tilde{v}_{k} = A^{\\mathsf{T}} \\tilde{p}_{k}$, and the scalars $\\rho_{k}$, $\\alpha_{k}$, $\\beta_{k}$, together with $x_{1}$ and $x_{2}$.\n- Verify nonbreakdown at each step by confirming that all required inner products used as denominators are nonzero.\n\nFinally, provide the exact value of the Euclidean norm $\\|r_{2}\\|_{2}$ as a simplified analytic expression. Do not round; report the exact value.", "solution": "The problem is valid as it is a well-defined exercise in numerical linear algebra, based on the standard Biconjugate Gradient (BiCG) method, with all necessary data provided and no internal contradictions or scientific flaws. We proceed with the solution.\n\nThe Biconjugate Gradient (BiCG) method is an iterative algorithm for solving nonsymmetric linear systems $A x = b$. The algorithm generates sequences of residuals $r_k$ and shadow residuals $\\tilde{r}_k$, along with corresponding search directions $p_k$ and $\\tilde{p}_k$. The defining properties are the biorthogonality of the residuals, $\\tilde{r}_j^T r_k = 0$ for $j \\neq k$, and the A-biorthogonality (or biconjugacy) of the search directions, $\\tilde{p}_j^T A p_k = 0$ for $j \\neq k$.\n\nThe algorithm starts with an initial guess $x_0$ and proceeds as follows:\n1.  Initialize:\n    $r_0 = b - A x_0$\n    Choose $\\tilde{r}_0$ (here, $\\tilde{r}_0 = r_0$)\n    $p_0 = r_0$, $\\tilde{p}_0 = \\tilde{r}_0$\n2.  For $k = 0, 1, 2, \\dots$:\n    $\\rho_k = \\tilde{r}_k^T r_k$\n    $v_k = A p_k$\n    $\\alpha_k = \\rho_k / (\\tilde{p}_k^T v_k)$\n    $x_{k+1} = x_k + \\alpha_k p_k$\n    $r_{k+1} = r_k - \\alpha_k v_k$\n    $\\tilde{r}_{k+1} = \\tilde{r}_k - \\alpha_k A^T \\tilde{p}_k$\n    $\\rho_{k+1} = \\tilde{r}_{k+1}^T r_{k+1}$\n    $\\beta_k = \\rho_{k+1} / \\rho_k$\n    $p_{k+1} = r_{k+1} + \\beta_k p_k$\n    $\\tilde{p}_{k+1} = \\tilde{r}_{k+1} + \\beta_k \\tilde{p}_k$\n\nWe are given the system data:\n$$A = \\begin{pmatrix} 2  1  0 \\\\ 0  3  1 \\\\ 1  0  2 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}$$\nThe transpose of $A$ is:\n$$A^{\\mathsf{T}} = \\begin{pmatrix} 2  0  1 \\\\ 1  3  0 \\\\ 0  1  2 \\end{pmatrix}$$\n\n**Initialization ($k=0$)**\nThe initial guess is $x_0 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}$.\nThe initial residual is $r_0 = b - A x_0 = b = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}$.\nThe initial shadow residual is taken as $\\tilde{r}_0 = r_0 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}$.\nThe initial search directions are $p_0 = r_0 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}$ and $\\tilde{p}_0 = \\tilde{r}_0 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}$.\n\n**First Iteration ($k=0$)**\nWe compute the scalar $\\rho_0$:\n$$\\rho_0 = \\tilde{r}_0^T r_0 = \\begin{pmatrix} 1  1  0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} = 1 \\cdot 1 + 1 \\cdot 1 + 0 \\cdot 0 = 2$$\nThe vector $v_0 = A p_0$ is:\n$$v_0 = A p_0 = \\begin{pmatrix} 2  1  0 \\\\ 0  3  1 \\\\ 1  0  2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 3 \\\\ 1 \\end{pmatrix}$$\nThe vector $\\tilde{v}_0 = A^{\\mathsf{T}} \\tilde{p}_0$ is:\n$$\\tilde{v}_0 = A^{\\mathsf{T}} \\tilde{p}_0 = \\begin{pmatrix} 2  0  1 \\\\ 1  3  0 \\\\ 0  1  2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 4 \\\\ 1 \\end{pmatrix}$$\nThe denominator for $\\alpha_0$ is $\\tilde{p}_0^T v_0 = \\begin{pmatrix} 1  1  0 \\end{pmatrix} \\begin{pmatrix} 3 \\\\ 3 \\\\ 1 \\end{pmatrix} = 3+3 = 6$.\n*Non-breakdown check:* Both $\\rho_0 = 2 \\neq 0$ and $\\tilde{p}_0^T A p_0 = 6 \\neq 0$, so the method can proceed.\nThe step size $\\alpha_0$ is:\n$$\\alpha_0 = \\frac{\\rho_0}{\\tilde{p}_0^T v_0} = \\frac{2}{6} = \\frac{1}{3}$$\nWe update the solution vector to obtain $x_1$:\n$$x_1 = x_0 + \\alpha_0 p_0 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} + \\frac{1}{3} \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1/3 \\\\ 1/3 \\\\ 0 \\end{pmatrix}$$\nThe new residual $r_1$ is:\n$$r_1 = r_0 - \\alpha_0 v_0 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} - \\frac{1}{3} \\begin{pmatrix} 3 \\\\ 3 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1-1 \\\\ 1-1 \\\\ 0-1/3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ -1/3 \\end{pmatrix}$$\nThe new shadow residual $\\tilde{r}_1$ is:\n$$\\tilde{r}_1 = \\tilde{r}_0 - \\alpha_0 \\tilde{v}_0 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} - \\frac{1}{3} \\begin{pmatrix} 2 \\\\ 4 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1-2/3 \\\\ 1-4/3 \\\\ 0-1/3 \\end{pmatrix} = \\begin{pmatrix} 1/3 \\\\ -1/3 \\\\ -1/3 \\end{pmatrix}$$\nWe compute $\\rho_1$ for the next step:\n$$\\rho_1 = \\tilde{r}_1^T r_1 = \\begin{pmatrix} 1/3  -1/3  -1/3 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\\\ -1/3 \\end{pmatrix} = 0 + 0 + \\frac{1}{9} = \\frac{1}{9}$$\nThe scalar $\\beta_0$ is:\n$$\\beta_0 = \\frac{\\rho_1}{\\rho_0} = \\frac{1/9}{2} = \\frac{1}{18}$$\nThe new search directions $p_1$ and $\\tilde{p}_1$ are:\n$$p_1 = r_1 + \\beta_0 p_0 = \\begin{pmatrix} 0 \\\\ 0 \\\\ -1/3 \\end{pmatrix} + \\frac{1}{18} \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1/18 \\\\ 1/18 \\\\ -6/18 \\end{pmatrix} = \\frac{1}{18} \\begin{pmatrix} 1 \\\\ 1 \\\\ -6 \\end{pmatrix}$$\n$$\\tilde{p}_1 = \\tilde{r}_1 + \\beta_0 \\tilde{p}_0 = \\begin{pmatrix} 1/3 \\\\ -1/3 \\\\ -1/3 \\end{pmatrix} + \\frac{1}{18} \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 6/18 + 1/18 \\\\ -6/18 + 1/18 \\\\ -6/18 \\end{pmatrix} = \\begin{pmatrix} 7/18 \\\\ -5/18 \\\\ -6/18 \\end{pmatrix} = \\frac{1}{18} \\begin{pmatrix} 7 \\\\ -5 \\\\ -6 \\end{pmatrix}$$\n\n**Second Iteration ($k=1$)**\nWe start with $\\rho_1 = 1/9$.\nThe vector $v_1 = A p_1$ is:\n$$v_1 = A p_1 = \\begin{pmatrix} 2  1  0 \\\\ 0  3  1 \\\\ 1  0  2 \\end{pmatrix} \\frac{1}{18} \\begin{pmatrix} 1 \\\\ 1 \\\\ -6 \\end{pmatrix} = \\frac{1}{18} \\begin{pmatrix} 2(1)+1(1) \\\\ 3(1)+1(-6) \\\\ 1(1)+2(-6) \\end{pmatrix} = \\frac{1}{18} \\begin{pmatrix} 3 \\\\ -3 \\\\ -11 \\end{pmatrix}$$\nThe vector $\\tilde{v}_1 = A^{\\mathsf{T}} \\tilde{p}_1$ is:\n$$\\tilde{v}_1 = A^{\\mathsf{T}} \\tilde{p}_1 = \\begin{pmatrix} 2  0  1 \\\\ 1  3  0 \\\\ 0  1  2 \\end{pmatrix} \\frac{1}{18} \\begin{pmatrix} 7 \\\\ -5 \\\\ -6 \\end{pmatrix} = \\frac{1}{18} \\begin{pmatrix} 2(7)+1(-6) \\\\ 1(7)+3(-5) \\\\ 1(-5)+2(-6) \\end{pmatrix} = \\frac{1}{18} \\begin{pmatrix} 8 \\\\ -8 \\\\ -17 \\end{pmatrix}$$\nThe denominator for $\\alpha_1$ is $\\tilde{p}_1^T v_1 = \\left( \\frac{1}{18} \\begin{pmatrix} 7  -5  -6 \\end{pmatrix} \\right) \\left( \\frac{1}{18} \\begin{pmatrix} 3 \\\\ -3 \\\\ -11 \\end{pmatrix} \\right) = \\frac{1}{324} (21+15+66) = \\frac{102}{324} = \\frac{17}{54}$.\n*Non-breakdown check:* We have $\\rho_1 = 1/9 \\neq 0$ and $\\tilde{p}_1^T A p_1 = 17/54 \\neq 0$. The method proceeds without breakdown.\nThe step size $\\alpha_1$ is:\n$$\\alpha_1 = \\frac{\\rho_1}{\\tilde{p}_1^T v_1} = \\frac{1/9}{17/54} = \\frac{1}{9} \\cdot \\frac{54}{17} = \\frac{6}{17}$$\nWe update the solution vector to obtain $x_2$:\n$$x_2 = x_1 + \\alpha_1 p_1 = \\begin{pmatrix} 1/3 \\\\ 1/3 \\\\ 0 \\end{pmatrix} + \\frac{6}{17} \\left(\\frac{1}{18} \\begin{pmatrix} 1 \\\\ 1 \\\\ -6 \\end{pmatrix}\\right) = \\begin{pmatrix} 1/3 \\\\ 1/3 \\\\ 0 \\end{pmatrix} + \\frac{1}{51} \\begin{pmatrix} 1 \\\\ 1 \\\\ -6 \\end{pmatrix} = \\begin{pmatrix} 17/51+1/51 \\\\ 17/51+1/51 \\\\ -6/51 \\end{pmatrix} = \\begin{pmatrix} 18/51 \\\\ 18/51 \\\\ -6/51 \\end{pmatrix} = \\frac{1}{17} \\begin{pmatrix} 6 \\\\ 6 \\\\ -2 \\end{pmatrix}$$\nThe new residual $r_2$ is:\n$$r_2 = r_1 - \\alpha_1 v_1 = \\begin{pmatrix} 0 \\\\ 0 \\\\ -1/3 \\end{pmatrix} - \\frac{6}{17} \\left(\\frac{1}{18} \\begin{pmatrix} 3 \\\\ -3 \\\\ -11 \\end{pmatrix}\\right) = \\begin{pmatrix} 0 \\\\ 0 \\\\ -1/3 \\end{pmatrix} - \\frac{1}{51} \\begin{pmatrix} 3 \\\\ -3 \\\\ -11 \\end{pmatrix} = \\begin{pmatrix} -3/51 \\\\ 3/51 \\\\ -17/51+11/51 \\end{pmatrix} = \\begin{pmatrix} -3/51 \\\\ 3/51 \\\\ -6/51 \\end{pmatrix} = \\frac{1}{17} \\begin{pmatrix} -1 \\\\ 1 \\\\ -2 \\end{pmatrix}$$\nWe report the other quantities generated during this iteration as requested. The new shadow residual $\\tilde{r}_2$ is:\n$$\\tilde{r}_2 = \\tilde{r}_1 - \\alpha_1 \\tilde{v}_1 = \\begin{pmatrix} 1/3 \\\\ -1/3 \\\\ -1/3 \\end{pmatrix} - \\frac{6}{17} \\left(\\frac{1}{18} \\begin{pmatrix} 8 \\\\ -8 \\\\ -17 \\end{pmatrix}\\right) = \\begin{pmatrix} 1/3 \\\\ -1/3 \\\\ -1/3 \\end{pmatrix} - \\frac{1}{51} \\begin{pmatrix} 8 \\\\ -8 \\\\ -17 \\end{pmatrix} = \\begin{pmatrix} 17/51-8/51 \\\\ -17/51+8/51 \\\\ -17/51+17/51 \\end{pmatrix} = \\begin{pmatrix} 9/51 \\\\ -9/51 \\\\ 0 \\end{pmatrix} = \\frac{1}{17} \\begin{pmatrix} 3 \\\\ -3 \\\\ 0 \\end{pmatrix}$$\nFinally, we compute $\\rho_2$ and $\\beta_1$:\n$$\\rho_2 = \\tilde{r}_2^T r_2 = \\left( \\frac{1}{17} \\begin{pmatrix} 3  -3  0 \\end{pmatrix} \\right) \\left( \\frac{1}{17} \\begin{pmatrix} -1 \\\\ 1 \\\\ -2 \\end{pmatrix} \\right) = \\frac{1}{289}(-3-3+0) = -\\frac{6}{289}$$\n$$\\beta_1 = \\frac{\\rho_2}{\\rho_1} = \\frac{-6/289}{1/9} = -\\frac{54}{289}$$\n\nThe problem requires the exact value of the Euclidean norm of $r_2$.\n$$\\|r_2\\|_2 = \\left\\| \\frac{1}{17} \\begin{pmatrix} -1 \\\\ 1 \\\\ -2 \\end{pmatrix} \\right\\|_2 = \\frac{1}{17} \\left\\| \\begin{pmatrix} -1 \\\\ 1 \\\\ -2 \\end{pmatrix} \\right\\|_2 = \\frac{1}{17} \\sqrt{(-1)^2 + 1^2 + (-2)^2} = \\frac{1}{17} \\sqrt{1+1+4} = \\frac{\\sqrt{6}}{17}$$", "answer": "$$\n\\boxed{\\frac{\\sqrt{6}}{17}}\n$$", "id": "3585465"}, {"introduction": "While elegant, the standard BiCG algorithm is susceptible to breakdowns, particularly when the biorthogonality product $\\rho_k = \\tilde{r}_k^T r_k$ vanishes prematurely. This advanced exercise confronts such a \"true breakdown\" scenario, moving beyond the standard algorithm to explore a robust recovery technique. You will work through a look-ahead step, a strategy used in practical software to navigate these breakdowns and ensure the method can continue towards a solution [@problem_id:3585500].", "problem": "Consider the linear system $A x = b$ with\n$$\nA = \\begin{pmatrix}\n0  1  0 \\\\\n0  0  1 \\\\\n1  0  0\n\\end{pmatrix}, \n\\quad\nb = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix},\n\\quad\nx_0 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix},\n\\quad\n\\tilde{r}_0 = \\begin{pmatrix} 1 \\\\ 4 \\\\ 2 \\end{pmatrix}.\n$$\nWe work with the biconjugate gradient method (BiCG), using the standard definitions:\n- The residual $r_k = b - A x_k$ and the shadow residual $\\tilde{r}_k$.\n- The biorthogonality product $\\rho_k = \\tilde{r}_k^{\\top} r_k$.\n- The step size $\\alpha_k = \\rho_k / \\left(\\tilde{p}_k^{\\top} A p_k\\right)$, with $p_k$ and $\\tilde{p}_k$ the right and left search directions defined by the two-term BiCG recurrences.\n\nFor this toy problem, set $p_0 = r_0$ and $\\tilde{p}_0 = \\tilde{r}_0$, and carry out the first BiCG update to obtain $x_1 = x_0 + \\alpha_0 p_0$, $r_1 = r_0 - \\alpha_0 A p_0$, and $\\tilde{r}_1 = \\tilde{r}_0 - \\alpha_0 A^{\\top} \\tilde{p}_0$. You will find that the iteration encounters a breakdown in the sense that $\\rho_1 = \\tilde{r}_1^{\\top} r_1 = 0$ while both $r_1$ and $\\tilde{r}_1$ are nonzero.\n\nTo continue, perform a single look-ahead step of grade two at iteration $k=0$ by updating\n$$\nx_1^{\\mathrm{LA}} = x_0 + \\tau_1 p_0 + \\tau_2 A p_0,\n$$\nso that the corresponding residual becomes\n$$\nr_1^{\\mathrm{LA}} = r_0 - \\tau_1 A p_0 - \\tau_2 A^2 p_0.\n$$\nImpose the two biorthogonality conditions against the first two left Krylov basis vectors at $k=0$,\n$$\n\\tilde{r}_0^{\\top} r_1^{\\mathrm{LA}} = 0,\n\\qquad\n\\left(A^{\\top} \\tilde{r}_0\\right)^{\\top} r_1^{\\mathrm{LA}} = 1,\n$$\nwhich enforce that the look-ahead residual is orthogonal to $\\tilde{r}_0$ and normalized to have a nonzero coupling with $A^{\\top}\\tilde{r}_0$.\n\nDerive, from first principles and the given data, the resulting linear system for $\\tau_1$ and $\\tau_2$, solve it analytically, and report the scalar $\\tau_2$ as a single exact number (no rounding).", "solution": "We begin by recalling the baseline definitions in the biconjugate gradient method (BiCG). Given a nonsymmetric matrix $A$, BiCG maintains two coupled sequences:\n- The right residuals $r_k = b - A x_k$ and right search directions $p_k$,\n- The left residuals (shadow residuals) $\\tilde{r}_k$ and left search directions $\\tilde{p}_k$,\nwith the biorthogonality condition encoded by $\\rho_k = \\tilde{r}_k^{\\top} r_k$ and the scalar update\n$$\n\\alpha_k = \\frac{\\rho_k}{\\tilde{p}_k^{\\top} A p_k}.\n$$\nAt the first step we take $p_0 = r_0$ and $\\tilde{p}_0 = \\tilde{r}_0$, which is valid at initialization. The update formulas then read:\n$$\nx_1 = x_0 + \\alpha_0 p_0, \n\\qquad\nr_1 = r_0 - \\alpha_0 A p_0,\n\\qquad\n\\tilde{r}_1 = \\tilde{r}_0 - \\alpha_0 A^{\\top} \\tilde{p}_0.\n$$\n\nWe now compute the concrete quantities from the data. First, $x_0 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}$ implies $r_0 = b - A x_0 = b = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$. With $p_0 = r_0$, we have $A p_0 = A r_0 = A \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$, which is simply the first column of $A$:\n$$\nA r_0 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}.\n$$\nNext, we compute the initial biorthogonality product and its denominator:\n$$\n\\rho_0 = \\tilde{r}_0^{\\top} r_0 = \\begin{pmatrix} 1  4  2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = 1,\n$$\n$$\n\\tilde{p}_0^{\\top} A p_0 = \\tilde{r}_0^{\\top} A r_0 = \\begin{pmatrix} 1  4  2 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} = 2.\n$$\nThus the first step size is\n$$\n\\alpha_0 = \\frac{\\rho_0}{\\tilde{p}_0^{\\top} A p_0} = \\frac{1}{2}.\n$$\nTherefore\n$$\nx_1 = x_0 + \\alpha_0 p_0 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} + \\frac{1}{2} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{2} \\\\ 0 \\\\ 0 \\end{pmatrix},\n$$\n$$\nr_1 = r_0 - \\alpha_0 A p_0 = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} - \\frac{1}{2} \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\\\ -\\frac{1}{2} \\end{pmatrix}.\n$$\nFor the shadow residual, we compute $A^{\\top} \\tilde{p}_0 = A^{\\top} \\tilde{r}_0$. Since\n$$\nA^{\\top} = \\begin{pmatrix}\n0  0  1 \\\\\n1  0  0 \\\\\n0  1  0\n\\end{pmatrix},\n$$\nwe obtain\n$$\nA^{\\top} \\tilde{r}_0 = \n\\begin{pmatrix}\n0  0  1 \\\\\n1  0  0 \\\\\n0  1  0\n\\end{pmatrix}\n\\begin{pmatrix} 1 \\\\ 4 \\\\ 2 \\end{pmatrix}\n=\n\\begin{pmatrix} 2 \\\\ 1 \\\\ 4 \\end{pmatrix}.\n$$\nHence\n$$\n\\tilde{r}_1 = \\tilde{r}_0 - \\alpha_0 A^{\\top} \\tilde{p}_0 = \\begin{pmatrix} 1 \\\\ 4 \\\\ 2 \\end{pmatrix} - \\frac{1}{2} \\begin{pmatrix} 2 \\\\ 1 \\\\ 4 \\end{pmatrix}\n= \\begin{pmatrix} 0 \\\\ \\frac{7}{2} \\\\ 0 \\end{pmatrix}.\n$$\nThe next biorthogonality product is\n$$\n\\rho_1 = \\tilde{r}_1^{\\top} r_1 = \\begin{pmatrix} 0  \\frac{7}{2}  0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ -\\frac{1}{2} \\end{pmatrix} = 0,\n$$\nwhich is a breakdown (the scalar product vanishes) even though neither $r_1$ nor $\\tilde{r}_1$ is the zero vector.\n\nTo continue the process, we invoke a look-ahead step of grade two at iteration $k=0$. Define\n$$\nx_1^{\\mathrm{LA}} = x_0 + \\tau_1 p_0 + \\tau_2 A p_0,\n$$\nso the corresponding residual becomes\n$$\nr_1^{\\mathrm{LA}} = b - A x_1^{\\mathrm{LA}} = r_0 - \\tau_1 A p_0 - \\tau_2 A^2 p_0.\n$$\nWe can compute $A^2 p_0$ explicitly. We already have $A p_0 = A r_0 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}$. Therefore\n$$\nA^2 p_0 = A \\left(A r_0\\right) = A \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}\n= \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}.\n$$\nAs a result,\n$$\nr_1^{\\mathrm{LA}} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} - \\tau_1 \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} - \\tau_2 \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}\n= \\begin{pmatrix} 1 \\\\ -\\tau_2 \\\\ -\\tau_1 \\end{pmatrix}.\n$$\nWe impose the two biorthogonality conditions\n$$\n\\tilde{r}_0^{\\top} r_1^{\\mathrm{LA}} = 0,\n\\qquad\n\\left(A^{\\top} \\tilde{r}_0\\right)^{\\top} r_1^{\\mathrm{LA}} = 1.\n$$\nUsing $\\tilde{r}_0 = \\begin{pmatrix} 1 \\\\ 4 \\\\ 2 \\end{pmatrix}$ and $A^{\\top} \\tilde{r}_0 = \\begin{pmatrix} 2 \\\\ 1 \\\\ 4 \\end{pmatrix}$, these inner products become\n$$\n\\tilde{r}_0^{\\top} r_1^{\\mathrm{LA}} = 1 \\cdot 1 + 4 \\cdot (-\\tau_2) + 2 \\cdot (-\\tau_1) = 1 - 4 \\tau_2 - 2 \\tau_1,\n$$\n$$\n\\left(A^{\\top} \\tilde{r}_0\\right)^{\\top} r_1^{\\mathrm{LA}} = 2 \\cdot 1 + 1 \\cdot (-\\tau_2) + 4 \\cdot (-\\tau_1) = 2 - \\tau_2 - 4 \\tau_1.\n$$\nTherefore the conditions are the linear system\n$$\n1 - 4 \\tau_2 - 2 \\tau_1 = 0,\n\\qquad\n2 - \\tau_2 - 4 \\tau_1 = 1.\n$$\nEquivalently,\n$$\n2 \\tau_1 + 4 \\tau_2 = 1,\n\\qquad\n4 \\tau_1 + \\tau_2 = 1.\n$$\nSolving, multiply the first equation by $2$ to obtain $4 \\tau_1 + 8 \\tau_2 = 2$. Subtract the second equation to eliminate $\\tau_1$:\n$$\n(4 \\tau_1 + 8 \\tau_2) - (4 \\tau_1 + \\tau_2) = 2 - 1 \n\\;\\;\\Longrightarrow\\;\\;\n7 \\tau_2 = 1 \n\\;\\;\\Longrightarrow\\;\\;\n\\tau_2 = \\frac{1}{7}.\n$$\nBack-substitution into $4 \\tau_1 + \\tau_2 = 1$ yields $4 \\tau_1 + \\frac{1}{7} = 1$, hence $4 \\tau_1 = \\frac{6}{7}$ and $\\tau_1 = \\frac{3}{14}$. The look-ahead residual is therefore\n$$\nr_1^{\\mathrm{LA}} = \\begin{pmatrix} 1 \\\\ -\\frac{1}{7} \\\\ -\\frac{3}{14} \\end{pmatrix},\n$$\nand the enforced coupling satisfies\n$$\n\\left(A^{\\top} \\tilde{r}_0\\right)^{\\top} r_1^{\\mathrm{LA}} = 1.\n$$\nThis provides a viable continuation beyond the breakdown at $\\rho_1 = 0$.\n\nThe requested scalar is $\\tau_2 = \\frac{1}{7}$.", "answer": "$$\\boxed{\\frac{1}{7}}$$", "id": "3585500"}]}