{"hands_on_practices": [{"introduction": "The structure of a matrix's Jordan canonical form, specifically the number and sizes of its Jordan blocks, is not merely an abstract classification. It is deeply connected to tangible properties of the matrix, such as the ranks of the matrices $(A - \\lambda I)^j$. This exercise provides hands-on practice in constructing a matrix with a prescribed Jordan structure and then using this rank-based analysis to certify its properties from first principles. [@problem_id:3553184]", "problem": "Let $A \\in \\mathbb{R}^{4 \\times 4}$ be a real matrix. The characteristic polynomial of $A$ is defined by $p_{A}(x) = \\det(x I - A)$, where $I$ is the identity matrix. A Jordan block of size $m$ associated with an eigenvalue $\\lambda \\in \\mathbb{C}$ is the $m \\times m$ matrix $J_{m}(\\lambda)$ having $\\lambda$ on the diagonal, ones on the superdiagonal, and zeros elsewhere. A matrix is called defective if its geometric multiplicity (the dimension of the eigenspace) is strictly smaller than its algebraic multiplicity (the multiplicity of the eigenvalue in the characteristic polynomial). The rank-nullity theorem states that for any linear map on a finite-dimensional vector space, $\\operatorname{rank}(M) + \\operatorname{nullity}(M) = n$, where $n$ is the dimension.\n\nConstruct explicitly a matrix $A \\in \\mathbb{R}^{4 \\times 4}$ with characteristic polynomial $p_{A}(x) = (x-1)^{4}$ that has exactly two Jordan blocks. Using only the foundational definitions above and direct computation, determine the ranks $r_{j} = \\operatorname{rank}\\big((A - I)^{j}\\big)$ for $j \\in \\{1,2,3\\}$, and use these ranks to certify that $A$ is defective by interpreting the nullities of $(A-I)^{j}$ in terms of eigenspaces and generalized eigenspaces. Briefly explain, from first principles, why matrices with nontrivial Jordan blocks are numerically unstable under small perturbations in the sense that their eigen-structure is highly sensitive.\n\nProvide, as your final answer, the row matrix $\\big(r_{1}, r_{2}, r_{3}\\big)$. No rounding is required.", "solution": "The user wants me to solve a problem about the Jordan canonical form and its numerical properties.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   $A \\in \\mathbb{R}^{4 \\times 4}$ is a real matrix.\n-   The characteristic polynomial of $A$ is $p_{A}(x) = (x-1)^{4}$.\n-   $A$ must have exactly two Jordan blocks.\n-   Definitions are provided for: characteristic polynomial, Jordan block, defective matrix, and the rank-nullity theorem.\n-   Task 1: Construct a matrix $A$ satisfying these properties.\n-   Task 2: Determine the ranks $r_{j} = \\operatorname{rank}\\big((A - I)^{j}\\big)$ for $j \\in \\{1,2,3\\}$, where $I$ is the identity matrix.\n-   Task 3: Use these ranks to certify that $A$ is defective.\n-   Task 4: Explain why matrices with nontrivial Jordan blocks are numerically unstable.\n-   The final answer must be the row matrix $(r_1, r_2, r_3)$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is well-posed and scientifically grounded within the domain of linear algebra and numerical analysis.\n-   **Scientific Soundness**: All concepts (Jordan form, characteristic polynomial, rank, nullity, numerical stability) are standard and correct.\n-   **Well-Posedness**: The characteristic polynomial $p_{A}(x) = (x-1)^{4}$ implies that the only eigenvalue is $\\lambda = 1$ with algebraic multiplicity $4$. For a $4 \\times 4$ matrix, having two Jordan blocks means their sizes must sum to $4$. The possible partitions of $4$ into two integers are $3+1$ and $2+2$. The problem asks for the construction of *a* matrix, so selecting either partition is valid. The request to compute ranks for $j \\in \\{1,2,3\\}$ suggests that the maximal Jordan block size is at least $3$, making the $3+1$ partition a more illustrative choice. The tasks are specific and lead to a unique solution for the ranks once a matrix is constructed.\n-   **Objectivity**: The problem is stated using precise, unambiguous mathematical terminology.\n-   **Completeness**: The problem provides all necessary information and definitions to proceed. It is self-contained.\n\n**Step 3: Verdict and Action**\nThe problem is valid. I will proceed with the solution.\n\n### Solution\n\n**Part 1: Construction of Matrix A**\n\nThe characteristic polynomial is given as $p_{A}(x) = (x-1)^{4}$. This implies that the matrix $A$ has a single eigenvalue $\\lambda = 1$ with algebraic multiplicity $m_a = 4$.\nThe matrix $A$ is specified to have exactly two Jordan blocks. The sum of the sizes of the Jordan blocks must equal the dimension of the matrix, which is $4$. The possible partitions of the integer $4$ into two parts are $3+1$ and $2+2$.\nWe choose the partition $3+1$. This structure implies that the Jordan canonical form $J$ of $A$ consists of one Jordan block of size $3$ and one Jordan block of size $1$, both associated with the eigenvalue $\\lambda=1$.\nThe Jordan form is:\n$$ J = \\begin{pmatrix} J_{3}(1)  0 \\\\ 0  J_{1}(1) \\end{pmatrix} = \\begin{pmatrix} 1  1  0  0 \\\\ 0  1  1  0 \\\\ 0  0  1  0 \\\\ 0  0  0  1 \\end{pmatrix} $$\nTo construct the matrix $A$, we can choose $A$ to be its own Jordan form, as this is the simplest representative of the similarity class of matrices with this Jordan structure. Let $A = J$. This matrix is in $\\mathbb{R}^{4 \\times 4}$, its characteristic polynomial is indeed $(x-1)^4$ (since it is upper triangular with diagonal entries all equal to $1$), and it has two Jordan blocks by construction.\n\n**Part 2: Determination of Ranks**\n\nWe need to compute the ranks $r_j = \\operatorname{rank}((A-I)^j)$ for $j \\in \\{1, 2, 3\\}$. Let $N = A - I$.\n$$ N = A - I = \\begin{pmatrix} 1  1  0  0 \\\\ 0  1  1  0 \\\\ 0  0  1  0 \\\\ 0  0  0  1 \\end{pmatrix} - \\begin{pmatrix} 1  0  0  0 \\\\ 0  1  0  0 \\\\ 0  0  1  0 \\\\ 0  0  0  1 \\end{pmatrix} = \\begin{pmatrix} 0  1  0  0 \\\\ 0  0  1  0 \\\\ 0  0  0  0 \\\\ 0  0  0  0 \\end{pmatrix} $$\n-   For $j=1$: We compute $r_1 = \\operatorname{rank}(N)$. The matrix $N$ has two linearly independent column vectors (the second and third columns are $(1,0,0,0)^T$ and $(0,1,0,0)^T$ respectively). Thus, its rank is $2$.\n    $r_1 = 2$.\n-   For $j=2$: We compute $r_2 = \\operatorname{rank}(N^2)$.\n    $$ N^2 = \\begin{pmatrix} 0  1  0  0 \\\\ 0  0  1  0 \\\\ 0  0  0  0 \\\\ 0  0  0  0 \\end{pmatrix} \\begin{pmatrix} 0  1  0  0 \\\\ 0  0  1  0 \\\\ 0  0  0  0 \\\\ 0  0  0  0 \\end{pmatrix} = \\begin{pmatrix} 0  0  1  0 \\\\ 0  0  0  0 \\\\ 0  0  0  0 \\\\ 0  0  0  0 \\end{pmatrix} $$\n    The matrix $N^2$ has only one non-zero column. Its rank is $1$.\n    $r_2 = 1$.\n-   For $j=3$: We compute $r_3 = \\operatorname{rank}(N^3)$.\n    $$ N^3 = N^2 \\cdot N = \\begin{pmatrix} 0  0  1  0 \\\\ 0  0  0  0 \\\\ 0  0  0  0 \\\\ 0  0  0  0 \\end{pmatrix} \\begin{pmatrix} 0  1  0  0 \\\\ 0  0  1  0 \\\\ 0  0  0  0 \\\\ 0  0  0  0 \\end{pmatrix} = \\begin{pmatrix} 0  0  0  0 \\\\ 0  0  0  0 \\\\ 0  0  0  0 \\\\ 0  0  0  0 \\end{pmatrix} $$\n    The matrix $N^3$ is the zero matrix. Its rank is $0$.\n    $r_3 = 0$.\n\nThe sequence of ranks is $(r_1, r_2, r_3) = (2, 1, 0)$.\n\n**Part 3: Certification of Defectiveness**\n\nA matrix is defective if, for at least one eigenvalue, its geometric multiplicity is strictly less than its algebraic multiplicity.\nThe algebraic multiplicity of the eigenvalue $\\lambda=1$ is $m_a = 4$, as given by the characteristic polynomial $p_A(x)=(x-1)^4$.\nThe geometric multiplicity $m_g$ of $\\lambda=1$ is the dimension of the eigenspace $E_1 = \\ker(A - 1 \\cdot I)$. By the rank-nullity theorem applied to the matrix $A-I$ on $\\mathbb{R}^4$:\n$$ \\operatorname{rank}(A-I) + \\operatorname{nullity}(A-I) = 4 $$\nThe nullity is the geometric multiplicity: $m_g = \\operatorname{nullity}(A-I)$.\n$$ m_g = 4 - \\operatorname{rank}(A-I) = 4 - r_1 $$\nUsing our computed value $r_1=2$, we find the geometric multiplicity:\n$$ m_g = 4 - 2 = 2 $$\nComparing the multiplicities, we have $m_g = 2  m_a = 4$. Since the geometric multiplicity is strictly smaller than the algebraic multiplicity, the matrix $A$ is defective.\n\nThe nullities of the powers of $(A-I)$ relate to the structure of the generalized eigenspaces. Let $k_j = \\operatorname{nullity}((A-I)^j) = 4-r_j$.\n-   $k_1 = 4-r_1 = 4-2=2$. This is the dimension of the eigenspace, equal to the number of Jordan blocks.\n-   $k_2 = 4-r_2 = 4-1=3$. This is the dimension of the kernel of $(A-I)^2$.\n-   $k_3 = 4-r_3 = 4-0=4$. This is the dimension of the kernel of $(A-I)^3$.\nThe number of Jordan blocks of size at least $j$ is given by the difference $k_j - k_{j-1}$ (with $k_0 = 0$).\n-   Number of blocks $\\ge 1$: $k_1 - k_0 = 2-0=2$.\n-   Number of blocks $\\ge 2$: $k_2 - k_1 = 3-2=1$.\n-   Number of blocks $\\ge 3$: $k_3 - k_2 = 4-3=1$.\nThis confirms the existence of one block of size $3$ and one block of size $1$, consistent with our construction.\n\n**Part 4: Explanation of Numerical Instability**\n\nMatrices with nontrivial Jordan blocks (i.e., blocks of size $m1$) are defective, meaning they have repeated eigenvalues whose geometric multiplicity is less than their algebraic multiplicity. The calculation of eigenvalues for such matrices is an ill-conditioned problem. This means that small perturbations in the matrix entries can lead to large changes in the computed eigenvalues.\n\nFrom first principles, consider a simple $2 \\times 2$ Jordan block associated with an eigenvalue $\\lambda$:\n$$ J = \\begin{pmatrix} \\lambda  1 \\\\ 0  \\lambda \\end{pmatrix} $$\nIts characteristic polynomial is $(x-\\lambda)^2=0$, yielding one eigenvalue $x=\\lambda$ with algebraic multiplicity $2$ and geometric multiplicity $1$.\n\nNow, introduce a small perturbation $\\epsilon$ to the $(2,1)$ entry, creating the matrix $J'$:\n$$ J' = \\begin{pmatrix} \\lambda  1 \\\\ \\epsilon  \\lambda \\end{pmatrix} $$\nThe characteristic polynomial of $J'$ is $\\det(xI - J') = (x-\\lambda)^2 - \\epsilon = 0$. The roots are given by $x - \\lambda = \\pm\\sqrt{\\epsilon}$, which means the new eigenvalues are:\n$$ x_{1,2} = \\lambda \\pm \\sqrt{\\epsilon} $$\nA perturbation of size $|\\epsilon|$ in a matrix entry has caused a perturbation of size $|\\sqrt{\\epsilon}|$ in the eigenvalues. For small $\\epsilon$ (e.g., $\\epsilon = 10^{-16}$), the perturbation to the eigenvalues ($\\sqrt{\\epsilon} = 10^{-8}$) is many orders of magnitude larger. This disproportionate response signifies numerical instability.\n\nFurthermore, for any non-zero $\\epsilon$, the two eigenvalues $\\lambda + \\sqrt{\\epsilon}$ and $\\lambda - \\sqrt{\\epsilon}$ are distinct. This means the perturbed matrix $J'$ is no longer defective; it is diagonalizable and has a full set of two linearly independent eigenvectors. The fundamental eigen-structure of the matrix changes drastically from defective to diagonalizable due to an arbitrarily small perturbation. In floating-point arithmetic, distinguishing between a truly defective matrix and a diagonalizable matrix that is merely close to a defective one is impossible, making the Jordan form a numerically unstable representation.", "answer": "$$\n\\boxed{\\begin{pmatrix} 2  1  0 \\end{pmatrix}}\n$$", "id": "3553184"}, {"introduction": "The numerical instability of a defective matrix can be quantified by analyzing the sensitivity of its eigenvalues to perturbations. The condition number of an eigenvalue, $\\kappa(\\mu)$, provides this measure, and it diverges as a matrix approaches a defective state. This practice problem guides you through an explicit calculation for a simple $2 \\times 2$ case, revealing precisely how the condition number blows up and why the right and left eigenvectors becoming orthogonal is at the heart of this instability. [@problem_id:3553213]", "problem": "Let $A(\\epsilon) \\in \\mathbb{R}^{2 \\times 2}$ be given by\n$$\nA(\\epsilon) = \\begin{bmatrix} \\lambda  1 \\\\ \\epsilon  \\lambda \\end{bmatrix},\n$$\nwhere $\\lambda \\in \\mathbb{R}$ is fixed and $\\epsilon0$. Consider the right and left eigenvalue problems $A(\\epsilon)\\,x=\\mu\\,x$ and $y^{\\top}A(\\epsilon)=\\mu\\,y^{\\top}$, respectively, for a simple eigenvalue $\\mu$ of $A(\\epsilon)$. Work in the vector two-norm. Your tasks are:\n\n1. Starting from the characteristic polynomial definition and the eigenvector equations, determine the two eigenvalues and construct corresponding nonzero right and left eigenvectors for $A(\\epsilon)$.\n\n2. Using the definition of the eigenvalue condition number for a simple eigenvalue,\n$$\n\\kappa_{2}(\\mu) = \\frac{\\|x\\|_{2}\\,\\|y\\|_{2}}{|y^{\\top}x|},\n$$\nwhere $x$ and $y$ are the corresponding right and left eigenvectors (with arbitrary nonzero scaling), evaluate $\\kappa_{2}(\\mu)$ explicitly as a function of $\\epsilon$ for the eigenvalue $\\mu_{+}$ with the larger real part.\n\n3. Explain, from first principles, how the behavior of $\\kappa_{2}(\\mu_{+})$ as $\\epsilon \\to 0^{+}$ reflects the approach of $A(\\epsilon)$ to a defective matrix with a single Jordan block, and derive the precise scaling in $\\epsilon$.\n\nReport, as your final answer, the exact closed-form expression (in simplest form) of $\\kappa_{2}(\\mu_{+})$ as a function of $\\epsilon$. No numerical rounding is required, and no units are involved.", "solution": "The problem statement is scientifically grounded, well-posed, objective, and complete. It represents a standard analysis in numerical linear algebra concerning the sensitivity of eigenvalues near a defective matrix. We may therefore proceed with the solution.\n\nThe problem is divided into three parts. We will address them in sequence.\n\n**Part 1: Eigenvalues and Eigenvectors of $A(\\epsilon)$**\n\nThe matrix is given by\n$$\nA(\\epsilon) = \\begin{bmatrix} \\lambda  1 \\\\ \\epsilon  \\lambda \\end{bmatrix}\n$$\nwhere $\\lambda \\in \\mathbb{R}$ and $\\epsilon  0$.\n\nThe eigenvalues $\\mu$ are the roots of the characteristic polynomial, $\\det(A(\\epsilon) - \\mu I) = 0$, where $I$ is the $2 \\times 2$ identity matrix.\n$$\n\\det\\left(\\begin{bmatrix} \\lambda - \\mu  1 \\\\ \\epsilon  \\lambda - \\mu \\end{bmatrix}\\right) = (\\lambda - \\mu)^2 - \\epsilon = 0\n$$\nSolving for $\\mu$, we get $\\lambda - \\mu = \\pm\\sqrt{\\epsilon}$, which gives the two eigenvalues:\n$$\n\\mu_{\\pm} = \\lambda \\pm \\sqrt{\\epsilon}\n$$\nSince $\\epsilon  0$, the two eigenvalues $\\mu_+$ and $\\mu_-$ are real and distinct. Therefore, they are simple eigenvalues, as stated in the problem.\n\nNext, we find the corresponding right and left eigenvectors.\n\n**Right Eigenvectors:**\nA right eigenvector $x$ corresponding to an eigenvalue $\\mu$ satisfies the equation $(A(\\epsilon) - \\mu I)x = 0$.\n\nFor $\\mu_{+} = \\lambda + \\sqrt{\\epsilon}$:\nThe system to solve is $(A(\\epsilon) - \\mu_{+} I)x_{+} = 0$:\n$$\n\\begin{bmatrix} \\lambda - (\\lambda + \\sqrt{\\epsilon})  1 \\\\ \\epsilon  \\lambda - (\\lambda + \\sqrt{\\epsilon}) \\end{bmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \\begin{bmatrix} -\\sqrt{\\epsilon}  1 \\\\ \\epsilon  -\\sqrt{\\epsilon} \\end{bmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\nThis gives the equation $-\\sqrt{\\epsilon} x_1 + x_2 = 0$, or $x_2 = \\sqrt{\\epsilon} x_1$. We can choose a non-zero eigenvector by setting $x_1 = 1$, which yields $x_2 = \\sqrt{\\epsilon}$.\nThus, a right eigenvector for $\\mu_{+}$ is $x_{+} = \\begin{pmatrix} 1 \\\\ \\sqrt{\\epsilon} \\end{pmatrix}$.\n\n**Left Eigenvectors:**\nA left eigenvector $y$ corresponding to an eigenvalue $\\mu$ satisfies $y^{\\top}(A(\\epsilon) - \\mu I) = 0^{\\top}$, which is equivalent to $(A(\\epsilon)^{\\top} - \\mu I)y = 0$. The transpose of $A(\\epsilon)$ is $A(\\epsilon)^{\\top} = \\begin{bmatrix} \\lambda  \\epsilon \\\\ 1  \\lambda \\end{bmatrix}$.\n\nFor $\\mu_{+} = \\lambda + \\sqrt{\\epsilon}$:\nThe system to solve is $(A(\\epsilon)^{\\top} - \\mu_{+} I)y_{+} = 0$:\n$$\n\\begin{bmatrix} \\lambda - (\\lambda + \\sqrt{\\epsilon})  \\epsilon \\\\ 1  \\lambda - (\\lambda + \\sqrt{\\epsilon}) \\end{bmatrix} \\begin{pmatrix} y_1 \\\\ y_2 \\end{pmatrix} = \\begin{bmatrix} -\\sqrt{\\epsilon}  \\epsilon \\\\ 1  -\\sqrt{\\epsilon} \\end{bmatrix} \\begin{pmatrix} y_1 \\\\ y_2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\nThis gives the equation $y_1 - \\sqrt{\\epsilon} y_2 = 0$, or $y_1 = \\sqrt{\\epsilon} y_2$. We can choose a non-zero eigenvector by setting $y_2 = 1$, which yields $y_1 = \\sqrt{\\epsilon}$.\nThus, a left eigenvector for $\\mu_{+}$ is $y_{+} = \\begin{pmatrix} \\sqrt{\\epsilon} \\\\ 1 \\end{pmatrix}$.\n\n**Part 2: Eigenvalue Condition Number $\\kappa_{2}(\\mu_{+})$**\n\nThe eigenvalue with the larger real part is $\\mu_{+} = \\lambda + \\sqrt{\\epsilon}$. The condition number $\\kappa_{2}(\\mu_{+})$ is defined as:\n$$\n\\kappa_{2}(\\mu) = \\frac{\\|x\\|_{2}\\,\\|y\\|_{2}}{|y^{\\top}x|}\n$$\nWe use the right eigenvector $x_{+} = \\begin{pmatrix} 1 \\\\ \\sqrt{\\epsilon} \\end{pmatrix}$ and the left eigenvector $y_{+} = \\begin{pmatrix} \\sqrt{\\epsilon} \\\\ 1 \\end{pmatrix}$ corresponding to $\\mu_{+}$.\n\nFirst, we compute the required norms and the inner product. The norm used is the vector $2$-norm.\n$$\n\\|x_{+}\\|_{2} = \\sqrt{1^2 + (\\sqrt{\\epsilon})^2} = \\sqrt{1 + \\epsilon}\n$$\n$$\n\\|y_{+}\\|_{2} = \\sqrt{(\\sqrt{\\epsilon})^2 + 1^2} = \\sqrt{\\epsilon + 1}\n$$\nNext, we compute the inner product $y_{+}^{\\top}x_{+}$:\n$$\ny_{+}^{\\top}x_{+} = \\begin{pmatrix} \\sqrt{\\epsilon}  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ \\sqrt{\\epsilon} \\end{pmatrix} = (\\sqrt{\\epsilon})(1) + (1)(\\sqrt{\\epsilon}) = 2\\sqrt{\\epsilon}\n$$\nSince $\\epsilon  0$, we have $|y_{+}^{\\top}x_{+}| = |2\\sqrt{\\epsilon}| = 2\\sqrt{\\epsilon}$.\n\nSubstituting these into the formula for the condition number:\n$$\n\\kappa_{2}(\\mu_{+}) = \\frac{(\\sqrt{1 + \\epsilon})(\\sqrt{1 + \\epsilon})}{2\\sqrt{\\epsilon}} = \\frac{1 + \\epsilon}{2\\sqrt{\\epsilon}}\n$$\n\n**Part 3: Interpretation as $\\epsilon \\to 0^{+}$**\n\nAs $\\epsilon \\to 0^{+}$, the matrix $A(\\epsilon)$ approaches the matrix $A(0)$:\n$$\nA(0) = \\lim_{\\epsilon\\to 0^{+}} A(\\epsilon) = \\begin{bmatrix} \\lambda  1 \\\\ 0  \\lambda \\end{bmatrix}\n$$\nThe matrix $A(0)$ is in Jordan canonical form. It is an upper triangular matrix, so its eigenvalues are its diagonal entries. There is a single eigenvalue $\\mu = \\lambda$ with algebraic multiplicity $2$.\n\nTo find the geometric multiplicity, we find the dimension of the null space of $A(0) - \\lambda I$:\n$$\nA(0) - \\lambda I = \\begin{bmatrix} 0  1 \\\\ 0  0 \\end{bmatrix}\n$$\nThe rank of this matrix is $1$. By the rank-nullity theorem, the dimension of its null space is $2 - 1 = 1$. The geometric multiplicity is $1$. Since the geometric multiplicity ($1$) is less than the algebraic multiplicity ($2$), the matrix $A(0)$ is defective. It consists of a single $2 \\times 2$ Jordan block associated with the eigenvalue $\\lambda$.\n\nNow, let's examine the behavior of the condition number $\\kappa_{2}(\\mu_{+})$ as $\\epsilon \\to 0^{+}$:\n$$\n\\lim_{\\epsilon\\to 0^{+}} \\kappa_{2}(\\mu_{+}) = \\lim_{\\epsilon\\to 0^{+}} \\frac{1 + \\epsilon}{2\\sqrt{\\epsilon}}\n$$\nAs $\\epsilon \\to 0^{+}$, the numerator $1 + \\epsilon \\to 1$ while the denominator $2\\sqrt{\\epsilon} \\to 0^{+}$. Thus, the limit is:\n$$\n\\lim_{\\epsilon\\to 0^{+}} \\kappa_{2}(\\mu_{+}) = \\infty\n$$\nThe divergence of the condition number signifies that the eigenvalue problem for matrices near a defective one is ill-conditioned. For any small $\\epsilon  0$, the matrix $A(\\epsilon)$ has two distinct eigenvalues $\\lambda \\pm \\sqrt{\\epsilon}$, but as $\\epsilon$ becomes vanishingly small, these eigenvalues are extremely sensitive to the perturbation $\\epsilon$.\n\nThe precise scaling behavior as $\\epsilon \\to 0^{+}$ is determined by the dominant term in the expression for $\\kappa_{2}(\\mu_{+})$:\n$$\n\\kappa_{2}(\\mu_{+}) = \\frac{1}{2\\sqrt{\\epsilon}} + \\frac{\\epsilon}{2\\sqrt{\\epsilon}} = \\frac{1}{2}\\epsilon^{-1/2} + \\frac{1}{2}\\epsilon^{1/2}\n$$\nFor small $\\epsilon$, the term $\\epsilon^{-1/2}$ dominates. Therefore, the condition number scales as $O(\\epsilon^{-1/2})$.\n\nThis ill-conditioning has a geometric interpretation. The condition number is inversely proportional to $|y_{+}^{\\top}x_{+}|$. This term is related to the cosine of the angle $\\theta$ between the right and left eigenvectors:\n$$\n\\cos(\\theta) = \\frac{y_{+}^{\\top}x_{+}}{\\|x_{+}\\|_{2} \\|y_{+}\\|_{2}} = \\frac{2\\sqrt{\\epsilon}}{1+\\epsilon} = \\frac{1}{\\kappa_2(\\mu_{+})}\n$$\nAs $\\epsilon \\to 0^{+}$, we have $\\cos(\\theta) \\to 0$, which implies that $\\theta \\to \\frac{\\pi}{2}$. This means the right and left eigenvectors become orthogonal to each other.\nLet's check the limits of the eigenvectors themselves:\n$$\n\\lim_{\\epsilon\\to 0^{+}} x_{+} = \\lim_{\\epsilon\\to 0^{+}} \\begin{pmatrix} 1 \\\\ \\sqrt{\\epsilon} \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\n$$\n\\lim_{\\epsilon\\to 0^{+}} y_{+} = \\lim_{\\epsilon\\to 0^{+}} \\begin{pmatrix} \\sqrt{\\epsilon} \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\nThese limiting vectors are indeed the right and left eigenvectors, respectively, of the defective matrix $A(0)$, and they are orthogonal: $\\begin{pmatrix} 0  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = 0$. The vanishing of the inner product $y^{\\top}x$ as the matrix approaches a defective one is the fundamental reason for the blow-up of the eigenvalue condition number.", "answer": "$$\n\\boxed{\\frac{1 + \\epsilon}{2\\sqrt{\\epsilon}}}\n$$", "id": "3553213"}, {"introduction": "Theoretical analysis shows that small perturbations shatter the delicate structure of a Jordan block, and in practice, the finite precision of computer arithmetic provides exactly this kind of perturbation through roundoff error. This computational exercise allows you to observe this phenomenon directly by simulating how floating-point errors act as small, random perturbations. You will see that even with a matrix defined to be a perfect Jordan block, numerical eigenvalue solvers will almost surely compute a set of distinct eigenvalues, reflecting a diagonalizable structure rather than the true defective one. [@problem_id:3553193]", "problem": "Consider the Jordan canonical form (JCF), which expresses a matrix as a block-diagonal matrix composed of Jordan blocks. A single Jordan block of size $m$ associated with eigenvalue $\\lambda \\in \\mathbb{C}$ is defined as the $m \\times m$ matrix $J_m(\\lambda)$ with $\\lambda$ on the diagonal and ones on the superdiagonal, and zeros elsewhere. In finite precision arithmetic, any input matrix is subject to unavoidable roundoff modeled as an additive perturbation. For matrices with nontrivial Jordan structure, such perturbations are known to cause eigenvalue splitting and, with probability one under continuous random perturbations, yield a diagonalizable matrix.\n\nStart from the following foundational base:\n- The characteristic polynomial of $J_m(\\lambda)$ is $(x - \\lambda)^m$ and thus has a single eigenvalue $\\lambda$ of algebraic multiplicity $m$ and geometric multiplicity $1$ when $m \\geq 2$.\n- In floating-point arithmetic, a matrix $A$ is effectively $A + \\Delta A$, with $\\lVert \\Delta A \\rVert$ on the order of machine epsilon scaled by the magnitudes of the entries in $A$.\n- The eigenvalues of perturbed polynomials generically undergo root splitting governed by the sizes of the newly introduced lower-degree coefficients.\n\nYour task is to design and implement a complete program that conducts numerical experiments to demonstrate and quantify the numerical instability of the Jordan canonical form with respect to eigenvalue computation. For each test case, construct the perturbed matrix\n$$\nA_\\delta = J_m(\\lambda) + \\delta E,\n$$\nwhere $E$ is a real-valued random matrix with independent entries sampled from a standard normal distribution, and $\\delta \\ge 0$ is a scalar controlling the perturbation magnitude. Use a fixed pseudorandom seed to ensure reproducibility for each test case.\n\nFor each constructed matrix $A_\\delta$, perform the following steps:\n1. Compute all eigenvalues $\\mu_1,\\dots,\\mu_m \\in \\mathbb{C}$ of $A_\\delta$.\n2. Using an absolute tolerance $\\tau = 10^{-12}$, compute the integer $k$ equal to the number of distinct eigenvalues, where two eigenvalues are considered identical if their absolute difference is less than or equal to $\\tau$.\n3. Compute the observed eigenvalue spread\n$$\nr = \\max_{1 \\le i \\le m} \\left| \\mu_i - \\lambda \\right|.\n$$\n4. Estimate the effective perturbation size via the defect-sensitive scaling law by\n$$\n\\widehat{\\varepsilon} = r^m.\n$$\nReport $k$ to numerically support the claim that, under generic perturbations, the computed spectrum is almost surely simple (and thus diagonalizable), and report $\\widehat{\\varepsilon}$ as an estimate of the magnitude of the underlying perturbation inferred from the eigenvalue spread.\n\nTest suite:\n- Case $1$: $(m,\\lambda,\\delta,\\text{seed}) = (1, 2, 10^{-12}, 0)$.\n- Case $2$: $(m,\\lambda,\\delta,\\text{seed}) = (2, 0, 2^{-52}, 1)$, where $2^{-52}$ is double-precision machine epsilon.\n- Case $3$: $(m,\\lambda,\\delta,\\text{seed}) = (3, 1, 10^{-8}, 2)$.\n- Case $4$: $(m,\\lambda,\\delta,\\text{seed}) = (4, 0.5, 0, 3)$.\n- Case $5$: $(m,\\lambda,\\delta,\\text{seed}) = (5, -3.2, 10^{-30}, 4)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, output two values in order: first the integer $k$, then the float $\\widehat{\\varepsilon}$. The outputs from all test cases should be flattened into a single list in the same order as the test suite. For example, the final output should have the form\n$$\n[k_1,\\widehat{\\varepsilon}_1,k_2,\\widehat{\\varepsilon}_2,k_3,\\widehat{\\varepsilon}_3,k_4,\\widehat{\\varepsilon}_4,k_5,\\widehat{\\varepsilon}_5].\n$$\nNo physical units or angles are involved. All numerical quantities should be reported as raw numbers. Implement the program in any modern language, adhering to the specified runtime environment in the final answer.", "solution": "The problem is subjected to validation prior to any attempt at a solution.\n\n### Step 1: Extract Givens\nThe verbatim givens from the problem statement are:\n- **Task**: Design and implement a program to demonstrate and quantify the numerical instability of the Jordan canonical form (JCF) with respect to eigenvalue computation.\n- **Matrix construction**: $A_\\delta = J_m(\\lambda) + \\delta E$.\n- **$J_m(\\lambda)$**: A Jordan block of size $m \\times m$ with eigenvalue $\\lambda$. It has $\\lambda$ on the diagonal, ones on the superdiagonal, and zeros elsewhere.\n- **$E$**: A real-valued random matrix with independent entries sampled from a standard normal distribution.\n- **$\\delta$**: A scalar perturbation magnitude, with $\\delta \\ge 0$.\n- **Reproducibility**: A fixed pseudorandom seed is used for each test case.\n- **Computational Steps**:\n    1. Compute all eigenvalues $\\mu_1, \\dots, \\mu_m \\in \\mathbb{C}$ of $A_\\delta$.\n    2. Compute the number of distinct eigenvalues, $k$, using an absolute tolerance $\\tau = 10^{-12}$. Two eigenvalues are considered identical if their absolute difference is less than or equal to $\\tau$.\n    3. Compute the observed eigenvalue spread $r = \\max_{1 \\le i \\le m} |\\mu_i - \\lambda|$.\n    4. Estimate the effective perturbation size $\\widehat{\\varepsilon} = r^m$.\n- **Test Suite**:\n    - Case 1: $(m, \\lambda, \\delta, \\text{seed}) = (1, 2, 10^{-12}, 0)$.\n    - Case 2: $(m, \\lambda, \\delta, \\text{seed}) = (2, 0, 2^{-52}, 1)$.\n    - Case 3: $(m, \\lambda, \\delta, \\text{seed}) = (3, 1, 10^{-8}, 2)$.\n    - Case 4: $(m, \\lambda, \\delta, \\text{seed}) = (4, 0.5, 0, 3)$.\n    - Case 5: $(m, \\lambda, \\delta, \\text{seed}) = (5, -3.2, 10^{-30}, 4)$.\n- **Output Format**: A single line of text: $[k_1,\\widehat{\\varepsilon}_1,k_2,\\widehat{\\varepsilon}_2,k_3,\\widehat{\\varepsilon}_3,k_4,\\widehat{\\varepsilon}_4,k_5,\\widehat{\\varepsilon}_5]$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is evaluated against the established validation criteria.\n\n- **Scientific Grounding**: The problem is fundamentally sound. It addresses a canonical topic in numerical linear algebra: the sensitivity of eigenvalues of defective matrices. The characteristic polynomial of a Jordan block $J_m(\\lambda)$ is indeed $(x - \\lambda)^m$. A generic perturbation of such a matrix typically results in a diagonalizable matrix with $m$ distinct eigenvalues. The relationship between the perturbation magnitude $\\varepsilon$ and the resulting eigenvalue spread $r$ for a defective eigenvalue is given by the well-known result $r = O(\\varepsilon^{1/m})$. The proposed estimator $\\widehat{\\varepsilon} = r^m$ is a direct consequence of this scaling law, designed to recover an estimate of the perturbation magnitude from the observed spread. The entire premise is scientifically correct.\n- **Well-Posedness**: The problem is well-posed. For each test case, all necessary parameters ($m, \\lambda, \\delta, \\text{seed}$) are provided. The procedure for calculating the outputs ($k$ and $\\widehat{\\varepsilon}$) is explicitly defined, including the numerical tolerance $\\tau$ for distinguishing eigenvalues. The use of a fixed seed for the random number generator ensures that the experiment is deterministic and reproducible.\n- **Objectivity**: The problem is stated in precise, objective mathematical language, free from ambiguity or subjective claims.\n\nThe problem does not exhibit any of the listed invalidity flaws. It is scientifically sound, well-posed, objective, formalizable, complete, and non-trivial.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be provided.\n\n### Solution\nThe objective is to conduct a numerical experiment to investigate the instability of eigenvalues of a Jordan block under small perturbations. For each test case specified by $(m, \\lambda, \\delta, \\text{seed})$, we will construct a perturbed matrix $A_\\delta$ and analyze its computed spectrum.\n\n**Theoretical Background**\nA Jordan block $J_m(\\lambda)$ is a defective matrix for $m \\ge 2$, meaning it has fewer linearly independent eigenvectors than its dimension. It possesses a single eigenvalue $\\lambda$ with algebraic multiplicity $m$ but a geometric multiplicity of only $1$. The eigenvalues of such a matrix are highly sensitive to perturbations. It can be shown from perturbation theory that a generic perturbation of magnitude $\\delta$ will split the single eigenvalue into $m$ distinct eigenvalues, $\\mu_i$, which lie in a disk of radius $O(\\delta^{1/m})$ centered at $\\lambda$ in the complex plane.\nThe perturbed characteristic polynomial can be approximated as:\n$$ \\det(xI - A_\\delta) = \\det(xI - J_m(\\lambda) - \\delta E) \\approx (x-\\lambda)^m - c \\delta = 0 $$\nwhere the constant $c$ depends on the entries of the perturbation matrix $E$, specifically $c \\approx (-1)^{m+1} E_{m,1}$ for $J_m(0)$. The roots of this polynomial are approximately $\\mu_j \\approx \\lambda + (c\\delta)^{1/m}$. The maximum distance from $\\lambda$ is the spread $r = \\max_j |\\mu_j - \\lambda|$, which scales as $r \\propto \\delta^{1/m}$. Consequently, we can estimate the perturbation's effective magnitude by inverting this relationship: $\\widehat{\\varepsilon} = r^m$, which should be on the order of $\\delta$.\n\n**Algorithmic Procedure**\nFor each test case $(m, \\lambda, \\delta, \\text{seed})$, the following steps are executed:\n\n1.  **Set Seed for Reproducibility**: The pseudorandom number generator's seed is fixed to the value specified in the test case. This ensures that the random matrix $E$ is identical upon every execution of the experiment.\n\n2.  **Construct Matrices**:\n    - A Jordan block $J_m(\\lambda)$ of size $m \\times m$ is created. This matrix has the value $\\lambda$ on its main diagonal and the value $1$ on its first superdiagonal.\n    - An $m \\times m$ perturbation matrix $E$ is generated, where each entry is an independent sample from the standard normal distribution $\\mathcal{N}(0, 1)$.\n    - The final perturbed matrix is computed as $A_\\delta = J_m(\\lambda) + \\delta E$.\n\n3.  **Compute Eigenvalues**: The eigenvalues $\\mu_1, \\dots, \\mu_m$ of the matrix $A_\\delta$ are computed using a standard numerical library function. These eigenvalues may be complex numbers even if $A_\\delta$ is real.\n\n4.  **Count Distinct Eigenvalues ($k$)**: The number of distinct eigenvalues is determined based on the given tolerance $\\tau = 10^{-12}$. An iterative algorithm is employed:\n    - Initialize an empty list of distinct eigenvalues.\n    - For each computed eigenvalue $\\mu_i$:\n        - Check if it is \"close\" to any of the eigenvalues already in the distinct list, i.e., if $|\\mu_i - \\mu_j| \\le \\tau$ for any $\\mu_j$ already in the list.\n        - If it is not close to any existing distinct eigenvalue, add it to the list.\n    - The count $k$ is the final size of this list of distinct eigenvalues.\n    For $\\delta  0$ and $m  1$, we expect $k=m$ with very high probability. For $\\delta=0$ or $m=1$, we expect $k=1$.\n\n5.  **Calculate Eigenvalue Spread ($r$)**: The maximum absolute deviation of the computed eigenvalues from the original eigenvalue $\\lambda$ is calculated:\n    $$ r = \\max_{1 \\le i \\le m} |\\mu_i - \\lambda| $$\n    where $|\\cdot|$ denotes the modulus for complex numbers.\n\n6.  **Estimate Effective Perturbation ($\\widehat{\\varepsilon}$)**: The effective perturbation size is estimated using the scaling law derived from perturbation theory:\n    $$ \\widehat{\\varepsilon} = r^m $$\n    This value provides an estimate of the perturbation magnitude inferred from its effect on the spectrum. For $\\delta  0$, we expect $\\widehat{\\varepsilon}$ to be on the order of $\\delta$.\n\nThe results ($k$ and $\\widehat{\\varepsilon}$) from each test case are collected and formatted into the required output string.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Conducts numerical experiments to demonstrate the instability of the\n    Jordan canonical form's eigenvalues under perturbation.\n    \"\"\"\n    # Test suite: (m, lambda, delta, seed)\n    test_cases = [\n        (1, 2.0, 1e-12, 0),\n        (2, 0.0, 2**-52, 1),\n        (3, 1.0, 1e-8, 2),\n        (4, 0.5, 0.0, 3),\n        (5, -3.2, 1e-30, 4),\n    ]\n\n    # Tolerance for distinguishing eigenvalues\n    tau = 1e-12\n    \n    results = []\n    \n    for m, lam, delta, seed in test_cases:\n        # 1. Set seed for reproducibility\n        np.random.seed(seed)\n        \n        # 2. Construct matrices\n        # Construct the Jordan block J_m(lambda)\n        J = np.diag(np.full(m, lam)) + np.diag(np.ones(m - 1), k=1)\n        \n        # Construct the random perturbation matrix E\n        E = np.random.standard_normal(size=(m, m))\n        \n        # Construct the perturbed matrix A_delta\n        A_delta = J + delta * E\n        \n        # 3. Compute eigenvalues\n        eigenvalues = np.linalg.eigvals(A_delta)\n        \n        # 4. Count distinct eigenvalues (k)\n        distinct_eigenvalues = []\n        for eig_val in eigenvalues:\n            is_new = True\n            for distinct_eig in distinct_eigenvalues:\n                if np.abs(eig_val - distinct_eig) = tau:\n                    is_new = False\n                    break\n            if is_new:\n                distinct_eigenvalues.append(eig_val)\n        k = len(distinct_eigenvalues)\n        \n        # 5. Calculate eigenvalue spread (r)\n        # Handle the edge case of m=0 for an empty eigenvalues array\n        if m > 0:\n            r = np.max(np.abs(eigenvalues - lam))\n        else:\n            r = 0.0\n            \n        # 6. Estimate effective perturbation (widehat_epsilon)\n        widehat_epsilon = r**m\n        \n        results.append(k)\n        results.append(widehat_epsilon)\n        \n    # Format the final output as a single comma-separated string in brackets.\n    # Use a custom formatter to ensure sufficient precision for small numbers.\n    def format_number(n):\n        if isinstance(n, int):\n            return str(n)\n        # Use scientific notation for small floats to preserve precision.\n        return f\"{n:.16e}\"\n\n    print(f\"[{','.join(map(format_number, results))}]\")\n\nsolve()\n\n```", "id": "3553193"}]}