{"hands_on_practices": [{"introduction": "Before applying Givens rotations in complex algorithms, it is crucial to understand their fundamental construction. This exercise guides you through deriving the rotation parameters directly from the first principles of orthogonality. By doing so, you will solidify your understanding of why the standard formulas for the cosine ($c$) and sine ($s$) parameters are what they are, connecting the geometry of rotations to the algebraic goal of annihilating a specific matrix element [@problem_id:3548499].", "problem": "Consider the dense matrix\n$$\nA \\;=\\; \\begin{pmatrix}\n4 & -3 & 8 \\\\\n7 & 5 & -2 \\\\\n1 & -9 & 6\n\\end{pmatrix}.\n$$\nA Givens rotation is a planar orthogonal transformation that acts nontrivially on a selected pair of coordinates and preserves the Euclidean $2$-norm. Using only the fundamental definition of orthogonal matrices as norm-preserving linear isometries in $\\mathbb{R}^{n}$ and the characterization of planar rotations in $\\mathbb{R}^{2}$, derive the constraints on the two real parameters of a Givens rotation that acts on rows $1$ and $2$ by left multiplication and annihilates the entry below the diagonal in column $1$ of $A$, that is, the element $a_{21}$. Starting from these first principles, determine an analytic expression for these parameters in terms of $a_{11}$ and $a_{21}$, and then evaluate them for the specific matrix $A$ given above.\n\nReport as your final answer the cosine parameter $c$ of the Givens rotation that annihilates $a_{21}$ for the given matrix $A$. Express your final answer in exact closed form; no rounding is required.", "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It is a standard problem in numerical linear algebra that is self-contained and free of contradictions.\n\nThe task is to derive the parameters of a Givens rotation that annihilates a specific element of a matrix and then to compute one of these parameters for the given matrix $A$. The derivation must be based on first principles. A Givens rotation is an orthogonal transformation that acts on a two-dimensional subspace.\n\nLet the given matrix be $A \\in \\mathbb{R}^{3 \\times 3}$, with entries denoted by $a_{ij}$.\n$$\nA \\;=\\; \\begin{pmatrix}\n4 & -3 & 8 \\\\\n7 & 5 & -2 \\\\\n1 & -9 & 6\n\\end{pmatrix}\n$$\nWe seek a Givens rotation matrix $G$ that, when applied via left multiplication to $A$, annihilates the element $a_{21}=7$. This rotation must act on rows 1 and 2. The Givens rotation matrix $G$ is an orthogonal matrix that is identical to the identity matrix except for a $2 \\times 2$ submatrix that performs a planar rotation. For an action on rows 1 and 2, the matrix $G$ has the general form:\n$$\nG \\;=\\; \\begin{pmatrix}\nc & s & 0 \\\\\n-s & c & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix}\n$$\nwhere $c$ and $s$ are real parameters.\n\nThe first principle stated is that $G$ must be an orthogonal matrix. An orthogonal matrix $Q$ satisfies the condition $Q^T Q = I$, where $I$ is the identity matrix. This property ensures that the transformation is a linear isometry, i.e., it preserves the Euclidean $2$-norm. Applying this condition to $G$:\n$$\nG^T G = \\begin{pmatrix}\nc & -s & 0 \\\\\ns & c & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\nc & s & 0 \\\\\n-s & c & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix} = \\begin{pmatrix}\nc^2 + s^2 & cs - sc & 0 \\\\\nsc - cs & s^2 + c^2 & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix} = \\begin{pmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix}\n$$\nFrom the top-left entry of the resulting identity matrix, we derive the first constraint on the parameters $c$ and $s$:\n$$\nc^2 + s^2 = 1\n$$\nThis constraint confirms that $c$ and $s$ can be interpreted as the cosine and sine of some rotation angle $\\theta$, i.e., $c = \\cos(\\theta)$ and $s = \\sin(\\theta)$, for the rotation matrix convention used here (a clockwise rotation by $\\theta$).\n\nNext, we apply the transformation to the matrix $A$ to form a new matrix $A' = G A$.\n$$\nA' = \\begin{pmatrix}\nc & s & 0 \\\\\n-s & c & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\na_{11} & a_{12} & a_{13} \\\\\na_{21} & a_{22} & a_{23} \\\\\na_{31} & a_{32} & a_{33}\n\\end{pmatrix}\n$$\nThe problem requires that the element in the second row and first column of $A'$, denoted $a'_{21}$, be annihilated (i.e., set to $0$). The expression for $a'_{21}$ is obtained by computing the dot product of the second row of $G$ and the first column of $A$:\n$$\na'_{21} = (-s) \\cdot a_{11} + c \\cdot a_{21} + 0 \\cdot a_{31} = -s a_{11} + c a_{21}\n$$\nSetting $a'_{21} = 0$ gives us the second constraint:\n$$\n-s a_{11} + c a_{21} = 0 \\quad \\implies \\quad c a_{21} = s a_{11}\n$$\nWe now have a system of two equations for the two unknowns $c$ and $s$:\n1. $c^2 + s^2 = 1$\n2. $c a_{21} = s a_{11}$\n\nAssuming $a_{11} \\ne 0$, we can write $s = c \\frac{a_{21}}{a_{11}}$. Substituting this into the first equation:\n$$\nc^2 + \\left(c \\frac{a_{21}}{a_{11}}\\right)^2 = 1\n$$\n$$\nc^2 \\left(1 + \\frac{a_{21}^2}{a_{11}^2}\\right) = 1\n$$\n$$\nc^2 \\left(\\frac{a_{11}^2 + a_{21}^2}{a_{11}^2}\\right) = 1\n$$\n$$\nc^2 = \\frac{a_{11}^2}{a_{11}^2 + a_{21}^2}\n$$\nTaking the square root, we get $c = \\pm \\frac{|a_{11}|}{\\sqrt{a_{11}^2 + a_{21}^2}}$. A standard convention, which also ensures the new diagonal element $a'_{11}$ is positive, is to choose the positive root and let $c$ have the same sign as $a_{11}$. This leads to the general analytic expression for $c$:\n$$\nc = \\frac{a_{11}}{\\sqrt{a_{11}^2 + a_{21}^2}}\n$$\nSubstituting this back into $c a_{21} = s a_{11}$, we solve for $s$:\n$$\n\\left(\\frac{a_{11}}{\\sqrt{a_{11}^2 + a_{21}^2}}\\right) a_{21} = s a_{11}\n$$\nAssuming $a_{11} \\ne 0$, we find the expression for $s$:\n$$\ns = \\frac{a_{21}}{\\sqrt{a_{11}^2 + a_{21}^2}}\n$$\nIf $a_{11}=0$, the annihilation equation becomes $c a_{21} = 0$. If $a_{21} \\ne 0$, then $c=0$. From $c^2+s^2=1$, we get $s^2=1$, so $s=\\pm 1$. Our formulas yield $c=0$ and $s=a_{21}/|a_{21}| = \\pm 1$, which is consistent. If both $a_{11}=0$ and $a_{21}=0$, the element is already zero and no rotation is needed ($c=1, s=0$). Our formulas are thus robust.\n\nNow, we evaluate these parameters for the given matrix $A$. The relevant entries are $a_{11} = 4$ and $a_{21} = 7$.\nFirst, we compute the denominator, which corresponds to the Euclidean norm of the vector $(a_{11}, a_{21})^T$. Let this be $r$.\n$$\nr = \\sqrt{a_{11}^2 + a_{21}^2} = \\sqrt{4^2 + 7^2} = \\sqrt{16 + 49} = \\sqrt{65}\n$$\nUsing the derived analytic expression, the cosine parameter $c$ is:\n$$\nc = \\frac{a_{11}}{r} = \\frac{4}{\\sqrt{65}}\n$$\nFor completeness, the sine parameter $s$ is:\n$$\ns = \\frac{a_{21}}{r} = \\frac{7}{\\sqrt{65}}\n$$\nThe problem requests the value of the cosine parameter $c$, expressed in exact closed form.\nThe final answer is $c = \\frac{4}{\\sqrt{65}}$.", "answer": "$$\n\\boxed{\\frac{4}{\\sqrt{65}}}\n$$", "id": "3548499"}, {"introduction": "A correct algorithm is only the first step; an efficient one is the goal in high-performance computing. This practice moves from the abstract mathematics of Givens rotations to their concrete implementation, focusing on computational efficiency. You will explore how memory access patterns, dictated by data layout like row-major ordering, can dramatically impact performance and learn to implement a memory-efficient, in-place rotation [@problem_id:3548445].", "problem": "You are asked to design and analyze an in-place application of a Givens rotation to two rows of a row-major matrix within the field of numerical linear algebra. The program must implement the algorithm in a way that minimizes memory traffic. The fundamental base for your derivation should be the definition of an orthogonal rotation in the plane and the concept of row-major memory layout. No shortcut formulas may be used in the problem statement; the per-element update must be derived from first principles in your solution.\n\nDefinitions and context:\n- A Givens rotation is an orthogonal transformation in the plane that acts nontrivially on two coordinates while leaving all other coordinates unchanged. It can be represented as a matrix that is identical to the identity matrix except for a rotation acting on two selected coordinates.\n- A row-major matrix stores entries of each row in contiguous memory. In row-major layout, scanning across the column index within a fixed row accesses memory sequentially.\n- In-place operations must overwrite the given matrix without materializing a full copy of the matrix.\n\nTasks:\n1. Starting from the definition of an orthogonal rotation in the plane, derive the element-wise update required to apply a Givens rotation to two rows of a matrix without losing access to any original values during the update. The angle of rotation must be treated as a real number in radians. Express the update as algebraic relations among the original and new row elements. Explain how loop ordering over the column index interacts with row-major layout to minimize memory traffic.\n2. Implement two algorithms:\n   - A single-pass streaming in-place algorithm that sweeps the column index in increasing order and updates both affected rows per column using a constant number of temporaries. This algorithm must be designed to minimize memory traffic on the matrix by reading each affected entry exactly once and writing each affected entry exactly once.\n   - A two-pass in-place algorithm that first updates the first row across all columns using a saved copy of the original row, and then updates the second row across all columns using the same saved copy. This algorithm must correctly preserve the original values required for the second update but will incur extra memory traffic and use additional temporary storage proportional to the number of columns.\n3. Construct a baseline by left-multiplying the matrix with the appropriate Givens rotation matrix acting on the specified pair of rows. Use this baseline to quantify the numerical correctness of each implementation by reporting a maximum absolute difference between the in-place result and the baseline.\n4. Count the conceptual memory traffic of each implementation by tracking the number of matrix element loads and matrix element stores that your algorithm performs, as well as loads from and stores to any temporary buffer you explicitly allocate. In this counting, assume each scalar read or write to the matrix or the temporary buffer contributes one unit to the corresponding counter. You must not rely on any hardware performance counters.\n5. All angles must be expressed in radians. No physical units are involved in this problem.\n6. Your program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case must produce a list containing the following values in order:\n   - The maximum absolute difference (as a floating-point number) between the single-pass streaming algorithm’s result and the baseline.\n   - The number of matrix loads (as an integer) performed by the single-pass streaming algorithm.\n   - The number of matrix stores (as an integer) performed by the single-pass streaming algorithm.\n   - The maximum absolute difference (as a floating-point number) between the two-pass algorithm’s result and the baseline.\n   - The number of matrix loads (as an integer) performed by the two-pass algorithm.\n   - The number of matrix stores (as an integer) performed by the two-pass algorithm.\n   - The number of temporary buffer loads (as an integer) performed by the two-pass algorithm.\n   - The number of temporary buffer stores (as an integer) performed by the two-pass algorithm.\n   Aggregate the per-test-case lists into a single list in the specified output format.\n\nTest suite:\nUse the following set of parameter values to exercise different aspects of the solution. In each case, the matrix is real-valued and stored in row-major order. Angles are in radians.\n\n- Case $1$ (general happy path): $m=5$, $n=7$, rows $i=1$, $j=3$, angle $\\theta=0.7$. Initialize the entries of the $m \\times n$ matrix with reproducible pseudorandom values in double precision.\n- Case $2$ (boundary angle): $m=3$, $n=4$, rows $i=0$, $j=2$, angle $\\theta=0$. Initialize with reproducible pseudorandom values in double precision.\n- Case $3$ (right-angle rotation): $m=4$, $n=4$, rows $i=1$, $j=2$, angle $\\theta=\\pi/2$. Initialize with reproducible pseudorandom values in double precision.\n- Case $4$ (scaling of traffic with size): $m=128$, $n=256$, rows $i=5$, $j=9$, angle $\\theta=0.3$. Initialize with reproducible pseudorandom values in double precision.\n- Case $5$ (extreme magnitude values): $m=2$, $n=3$, rows $i=0$, $j=1$, angle $\\theta=0.3$. Initialize the matrix explicitly with entries of order $10^{300}$ and $10^{-300}$ such that arithmetic remains finite in double precision.\n\nYour program must produce a single line of output of the form\n$[r_1,r_2,r_3,r_4,r_5]$\nwhere each $r_k$ is the list of values described above for the corresponding case. The angle unit is radians, and all outputs must be numerical (booleans are not required here).", "solution": "### Step 1: Problem Validation\n\nThe problem is subjected to a rigorous validation process before a solution is attempted.\n\n#### Step 1.1: Extract Givens\n\n- **Topic**: In-place application of Givens rotations on a row-major matrix in numerical linear algebra.\n- **Definition (Givens rotation)**: An orthogonal transformation in the plane acting on two coordinates, represented by a matrix identical to the identity except for a $2 \\times 2$ rotation sub-block.\n- **Definition (Row-major layout)**: Matrix elements are stored row by row in contiguous memory.\n- **Definition (In-place operation)**: The operation must overwrite the input matrix without creating a full copy.\n- **Task 1 (Derivation and Analysis)**:\n    - Starting from the first principles of an orthogonal rotation, derive the element-wise update equations for applying a Givens rotation to two rows ($i$ and $j$) of a matrix.\n    - The derivation must not use shortcut formulas and must manage original values correctly during an in-place update.\n    - The angle $\\theta$ is a real number in radians.\n    - Explain the interaction between loop ordering (over columns) and row-major layout with respect to memory traffic minimization.\n- **Task 2 (Implementation)**:\n    - Implement a single-pass streaming in-place algorithm that updates both rows in one sweep over columns, using a constant number of temporary variables. This algorithm should read and write each affected element exactly once.\n    - Implement a two-pass in-place algorithm that uses a temporary buffer (proportional to the number of columns, $n$) to store one of the original rows.\n- **Task 3 (Verification)**:\n    - Establish a baseline by left-multiplying the original matrix with the full Givens rotation matrix.\n    - Quantify the numerical correctness of both implementations by reporting the maximum absolute difference against the baseline.\n- **Task 4 (Performance Counting)**:\n    - Count the conceptual memory traffic for each implementation: number of matrix element loads, matrix element stores, temporary buffer loads, and temporary buffer stores. Each scalar read/write to the matrix or temporary buffer is one unit.\n- **Task 5 (Units)**: All angles are in radians.\n- **Task 6 (Output Format)**:\n    - For each test case, produce a list of 8 values: `[diff_single_pass, loads_single_pass, stores_single_pass, diff_two_pass, loads_two_pass, stores_two_pass, temp_loads_two_pass, temp_stores_two_pass]`.\n    - The final output is a single line: a list of these lists for all test cases, e.g., `[[case1_results], [case2_results], ...]`.\n- **Test Suite**:\n    - Case 1: $m=5, n=7, i=1, j=3, \\theta=0.7$, pseudorandom matrix.\n    - Case 2: $m=3, n=4, i=0, j=2, \\theta=0.0$, pseudorandom matrix.\n    - Case 3: $m=4, n=4, i=1, j=2, \\theta=\\pi/2$, pseudorandom matrix.\n    - Case 4: $m=128, n=256, i=5, j=9, \\theta=0.3$, pseudorandom matrix.\n    - Case 5: $m=2, n=3, i=0, j=1, \\theta=0.3$, explicitly initialized matrix with extreme values.\n\n#### Step 1.2: Validate Using Extracted Givens\n\n- **Scientific Grounding**: The problem is firmly rooted in numerical linear algebra. Givens rotations, matrix memory layouts, in-place algorithms, and memory traffic analysis are standard, well-defined concepts. The problem is mathematically and computationally sound.\n- **Well-Posedness**: The problem is specified with precision. Inputs are defined for each test case, and the required outputs (numerical error and memory counts) are explicitly described. A unique solution exists for each sub-task. The baseline provides a clear criterion for correctness.\n- **Objectivity**: The problem is stated in precise, technical language, free from subjectivity or ambiguity.\n- **Flaw Checklist**: The problem does not exhibit any of the defined flaws. It is not unsound, irrelevant, incomplete, contradictory, unrealistic, ill-posed, or trivial. The requirement to derive the update equations from first principles and analyze memory traffic constitutes a substantive task in numerical computing.\n\n#### Step 1.3: Verdict and Action\n\nThe problem is **valid**. A full solution will be provided.\n\n### Step 2: Solution\n\n#### Part 1: Derivation of Element-wise Update and Memory Access Analysis\n\nA Givens rotation is an orthogonal transformation. In a two-dimensional plane, a vector $\\begin{pmatrix} x \\\\ y \\end{pmatrix}$ is rotated by an angle $\\theta$ to a new vector $\\begin{pmatrix} x' \\\\ y' \\end{pmatrix}$ according to the transformation:\n$$\n\\begin{pmatrix} x' \\\\ y' \\end{pmatrix} = \\begin{pmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix}\n$$\nThis gives the component-wise relations, letting $c = \\cos\\theta$ and $s = \\sin\\theta$:\n$$\nx' = c x - s y \\\\\ny' = s x + c y\n$$\nLeft-multiplying an $m \\times n$ matrix $A$ by an $m \\times m$ Givens rotation matrix $G$ applies this rotation to the rows of $A$. Let the rotation act on rows $i$ and $j$. The matrix $G$ is an identity matrix except for four elements: $G_{ii} = c$, $G_{ij} = -s$, $G_{ji} = s$, and $G_{jj} = c$.\n\nThe new matrix $A'$ is given by $A' = GA$. The elements of a row $p$ in the new matrix are given by $(A')_{pk} = \\sum_{l=0}^{m-1} G_{pl} A_{lk}$ for each column $k \\in \\{0, \\dots, n-1\\}$.\n\nFor row $i$, the sum only has non-zero terms for $l=i$ and $l=j$:\n$$\nA'_{ik} = G_{ii}A_{ik} + G_{ij}A_{jk} = c A_{ik} - s A_{jk}\n$$\nFor row $j$, the non-zero terms are also for $l=i$ and $l=j$:\n$$\nA'_{jk} = G_{ji}A_{ik} + G_{jj}A_{jk} = s A_{ik} + c A_{jk}\n$$\nFor any other row $p \\ne i, j$, the sum has only one non-zero term, $G_{pp}=1$:\n$$\nA'_{pk} = G_{pp}A_{pk} = A_{pk}\n$$\nThus, for each column $k$, the pair of elements $(A_{ik}, A_{jk})$ is transformed into $(A'_{ik}, A'_{jk})$ using the same 2D rotation formulas. To perform this update in-place, one must be careful. If we compute $A'_{ik}$ and overwrite $A_{ik}$, the original value of $A_{ik}$ is lost, but it is needed to compute $A'_{jk}$.\n\n**Single-Pass Streaming Algorithm**:\nTo resolve this dependency, for each column $k$, we use temporary scalar variables.\nLet $t_i = A_{ik}$ and $t_j = A_{jk}$. We then compute the new values using these temporaries:\n$$\nA_{ik} \\leftarrow c t_i - s t_j \\\\\nA_{jk} \\leftarrow s t_i + c t_j\n$$\nThis process is repeated for each column $k$ from $0$ to $n-1$. This algorithm uses a constant amount of temporary storage (two scalars, which would typically be held in CPU registers) regardless of the number of columns $n$.\n\n**Memory Traffic Analysis**:\nIn a row-major memory layout, elements $A_{p,k}$ and $A_{p,k+1}$ are adjacent. The single-pass algorithm iterates over $k$ and, in each iteration, accesses $A_{ik}$ and $A_{jk}$. These two elements are separated by $(j-i) \\times n$ memory locations. However, the sequence of accesses to row $i$ ($A_{i0}, A_{i1}, \\dots$) and row $j$ ($A_{j0}, A_{j1}, \\dots$) are both sequential (stride-1). Modern CPUs are optimized for such streaming access patterns via prefetching, making this loop efficient. The key benefit is that each required element is loaded from the matrix exactly once, and each updated element is stored exactly once. Total traffic for $n$ columns: $2n$ matrix loads and $2n$ matrix stores.\n\nThe **two-pass algorithm**, by contrast, first creates a full copy of one row, say row $i$, into a temporary buffer. This costs $n$ matrix loads and $n$ stores to the temporary buffer. Then, it performs a pass over all columns to update row $i$, using the temporary buffer and the original row $j$. This pass entails $n$ matrix loads (from row $j$), $n$ temporary buffer loads, and $n$ matrix stores (to row $i$). Finally, a second pass updates row $j$, again using the temporary buffer and the original row $j$. This pass requires an additional $n$ matrix loads (from row $j$), $n$ temporary buffer loads, and $n$ matrix stores (to row $j$). The total traffic is substantially higher: $3n$ matrix loads, $2n$ matrix stores, $2n$ temporary buffer loads, and $n$ temporary buffer stores. The repeated reads of row $j$ are particularly inefficient from a memory bandwidth perspective.\n\n#### Part 2: Implementation, Verification, and Counting\n\nThe provided Python code implements the two algorithms, the baseline calculation, and the memory traffic counters as described. The single-pass algorithm iterates once over the columns, using two temporary variables per column. The two-pass algorithm explicitly allocates a temporary array for one row and performs its updates in separate loops. The numerical error is calculated as the maximum absolute difference between the result of each algorithm and the baseline result obtained from direct matrix multiplication. Memory traffic is tallied by incrementing counters for each explicit scalar access to the matrix or the temporary buffer.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef apply_givens_rotation(m, n, i, j, theta, A_init):\n    \"\"\"\n    Applies a Givens rotation to a matrix and analyzes performance.\n    \n    Args:\n        m (int): Number of rows in the matrix.\n        n (int): Number of columns in the matrix.\n        i (int): First row index for rotation.\n        j (int): Second row index for rotation.\n        theta (float): Rotation angle in radians.\n        A_init (np.ndarray): The initial matrix.\n\n    Returns:\n        list: A list containing 8 statistics as specified in the problem.\n    \"\"\"\n    \n    # Ensure indices are ordered for consistency, though not required by the math\n    if i > j:\n        i, j = j, i\n        \n    c = np.cos(theta)\n    s = np.sin(theta)\n\n    # -------------------------------------------------------------\n    # 3. Baseline calculation using full Givens matrix multiplication\n    # -------------------------------------------------------------\n    A_orig = A_init.copy()\n    G = np.identity(m, dtype=np.float64)\n    # The problem description implies a counter-clockwise rotation convention\n    # x' = cx - sy, y' = sx + cy, which corresponds to G_ij = -s, G_ji = s\n    G[i, i], G[i, j] = c, -s\n    G[j, i], G[j, j] = s, c\n    A_baseline = G @ A_orig\n\n    # ----------------------------------------------------------------------------------\n    # 2a. Single-pass streaming in-place algorithm\n    # 4.  Memory traffic counting for single-pass\n    # ----------------------------------------------------------------------------------\n    A1 = A_orig.copy()\n    loads_1pass = 0\n    stores_1pass = 0\n\n    for k in range(n):\n        # Load original values for column k\n        val_i = A1[i, k]\n        val_j = A1[j, k]\n        loads_1pass += 2\n\n        # Compute new values and store back, following x' = cx - sy, y' = sx + cy\n        A1[i, k] = c * val_i - s * val_j\n        A1[j, k] = s * val_i + c * val_j\n        stores_1pass += 2\n\n    diff_1pass = np.max(np.abs(A1 - A_baseline))\n\n    # ----------------------------------------------------------------------------------\n    # 2b. Two-pass in-place algorithm\n    # 4.  Memory traffic counting for two-pass\n    # ----------------------------------------------------------------------------------\n    A2 = A_orig.copy()\n    loads_2pass = 0\n    stores_2pass = 0\n    temp_loads_2pass = 0\n    temp_stores_2pass = 0\n\n    temp_row = np.zeros(n, dtype=np.float64)\n\n    # First, save original row i to a temporary buffer\n    for k in range(n):\n        temp_row[k] = A2[i, k]\n        loads_2pass += 1\n        temp_stores_2pass += 1\n        \n    # First pass: update row i using temp_row and original row j\n    for k in range(n):\n        # A2[i, k] = c * temp_row[k] - s * A2[j,k]\n        val_temp = temp_row[k]\n        val_j = A2[j,k]\n        temp_loads_2pass += 1\n        loads_2pass += 1\n        A2[i, k] = c * val_temp - s * val_j\n        stores_2pass += 1\n        \n    # Second pass: update row j using temp_row and original row j.\n    # Note: original row j is now modified in A2. This is a common bug.\n    # A correct two-pass algo would save BOTH rows or be more clever.\n    # The provided solution has a subtle logic error in the two-pass algorithm.\n    # A correct implementation must use the *original* values of row j for the second pass.\n    # Let's re-read the prompt: \"updates the second row across all columns using the same saved copy.\"\n    # This implies the original values of row i are needed.\n    # `A2[j,k] = s * temp_row[k] + c * A2[j, k]` is wrong, because `A2[j,k]` is no longer the original value\n    # after the first pass if i=j. But i!=j is assumed. So the issue is that it's using the *original* A2[j,k]\n    # on the RHS of the update for A2[i,k] but the *updated* A2[i,k] is not used.\n    # Let's trace carefully:\n    # Pass 1: A2[i, k] = c * temp_row[k] - s * A2[j, k]. RHS uses original A2[j,k]. OK.\n    # Pass 2: A2[j, k] = s * temp_row[k] + c * A2[j, k]. RHS uses original A2[j,k]. OK.\n    # The code's counting is not consistent with this logic. Let's fix counting.\n    # A2[i,k] update: temp_load, A2_load, A2_store.\n    # A2[j,k] update: temp_load, A2_load, A2_store.\n    # So `loads_2pass` should be `n` (for temp store) + `n` (for A2[i] update) + `n` (for A2[j] update) = 3n\n    # The code has this. It seems my mental trace was wrong.\n    \n    # Let's re-implement the counting for clarity and correctness.\n    A2_recount = A_orig.copy()\n    l_2p, s_2p, tl_2p, ts_2p = 0, 0, 0, 0\n    temp_row_recount = np.zeros(n, dtype=np.float64)\n\n    for k in range(n):\n        temp_row_recount[k] = A2_recount[i, k]\n        l_2p += 1\n        ts_2p += 1\n    \n    for k in range(n):\n        val_i_orig = temp_row_recount[k]\n        tl_2p += 1\n        val_j_orig = A2_recount[j, k]\n        l_2p += 1\n        A2_recount[i, k] = c * val_i_orig - s * val_j_orig\n        s_2p += 1\n\n    for k in range(n):\n        val_i_orig = temp_row_recount[k]\n        tl_2p += 1\n        val_j_orig = A2_recount[j, k] # This is the bug. A2[j,k] was not saved.\n        # But wait, A2[j,k] was not modified in the first pass. So it's still original.\n        # The logic is correct, just the memory access pattern is inefficient.\n        l_2p += 1 \n        A2_recount[j, k] = s * val_i_orig + c * val_j_orig\n        s_2p += 1\n\n    diff_2pass = np.max(np.abs(A2_recount - A_baseline))\n    \n    return [\n        diff_1pass, loads_1pass, stores_1pass,\n        diff_2pass, l_2p, s_2p, tl_2p, ts_2p\n    ]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    # Test cases defined in the problem statement.\n    test_cases = [\n        {'m': 5, 'n': 7, 'i': 1, 'j': 3, 'theta': 0.7, 'type': 'rand'},\n        {'m': 3, 'n': 4, 'i': 0, 'j': 2, 'theta': 0.0, 'type': 'rand'},\n        {'m': 4, 'n': 4, 'i': 1, 'j': 2, 'theta': np.pi/2, 'type': 'rand'},\n        {'m': 128, 'n': 256, 'i': 5, 'j': 9, 'theta': 0.3, 'type': 'rand'},\n        {'m': 2, 'n': 3, 'i': 0, 'j': 1, 'theta': 0.3, 'type': 'extreme'},\n    ]\n\n    all_results_str = []\n    \n    # Use a fixed seed for reproducible random matrices\n    rng = np.random.default_rng(seed=42)\n\n    for case in test_cases:\n        m, n, i, j, theta = case['m'], case['n'], case['i'], case['j'], case['theta']\n        \n        if case['type'] == 'rand':\n            # Initialize with reproducible pseudorandom values\n            A_init = rng.random((m, n), dtype=np.float64) * 200 - 100\n        else: # 'extreme'\n            # Initialize with extreme magnitude values\n            A_init = np.array([\n                [1.2e300, -4.5e-300, 8.9e300],\n                [3.1e-300, -7.6e300, -2.4e-300]\n            ], dtype=np.float64)\n\n        result_list = apply_givens_rotation(m, n, i, j, theta, A_init)\n        \n        # Format the numbers: integers as is, floats in scientific notation\n        # for consistency.\n        formatted_results = []\n        for val in result_list:\n            if isinstance(val, (float, np.floating)):\n                formatted_results.append(f\"{val:.16e}\")\n            else:\n                formatted_results.append(str(val))\n\n        case_str = f\"[{','.join(formatted_results)}]\"\n        all_results_str.append(case_str)\n\n    # Format the final output as a single-line string\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n\n```", "id": "3548445"}, {"introduction": "Individual rotations are building blocks for powerful matrix factorizations. In this capstone exercise, you will construct a full QR factorization algorithm using a sequence of Givens rotations and compare it against the widely used Householder method. This practice emphasizes the importance of numerical verification, requiring you to implement cross-checks for correctness and address the non-uniqueness of QR factorization through sign alignment [@problem_id:3548524].", "problem": "Design and implement a complete program that, for a given finite set of real matrices, computes two orthogonal-triangular factorization (QR) decompositions: one via Householder reflectors and one via Givens rotations. The goal is to construct principled cross-checks to verify orthogonality, upper-trapezoidal structure of the triangular factor, reconstruction accuracy, and to propose and implement a mathematically sound method to align signs so that the two triangular factors are comparable under a consistent sign convention.\n\nYour derivation and implementation must start from the following fundamental base:\n- The definition of an orthogonal matrix: a real matrix $\\mathbf{Q} \\in \\mathbb{R}^{m \\times m}$ is orthogonal if $\\mathbf{Q}^{\\top} \\mathbf{Q} = \\mathbf{I}_m$.\n- The Euclidean norm induced by the inner product, and the Frobenius norm $\\|\\cdot\\|_F$ induced by the Euclidean inner product on matrices.\n- A Householder reflector is an orthogonal transformation of the form $\\mathbf{H} = \\mathbf{I} - 2 \\mathbf{u} \\mathbf{u}^{\\top}$ where $\\mathbf{u} \\in \\mathbb{R}^{k}$ with $\\|\\mathbf{u}\\|_2 = 1$, which reflects vectors across the hyperplane orthogonal to $\\mathbf{u}$.\n- A Givens rotation is an orthogonal transformation acting on a coordinate plane spanned by two standard basis vectors, parameterized by scalars $c$ and $s$ satisfying $c^2 + s^2 = 1$, used to annihilate selected entries.\n\nYou must:\n- Construct $\\mathbf{Q}_{\\mathrm{H}}$ and $\\mathbf{R}_{\\mathrm{H}}$ using Householder reflectors so that $\\mathbf{A} = \\mathbf{Q}_{\\mathrm{H}} \\mathbf{R}_{\\mathrm{H}}$ with $\\mathbf{Q}_{\\mathrm{H}}$ orthogonal and $\\mathbf{R}_{\\mathrm{H}}$ upper-trapezoidal.\n- Construct $\\mathbf{Q}_{\\mathrm{G}}$ and $\\mathbf{R}_{\\mathrm{G}}$ using Givens rotations so that $\\mathbf{A} = \\mathbf{Q}_{\\mathrm{G}} \\mathbf{R}_{\\mathrm{G}}$ with $\\mathbf{Q}_{\\mathrm{G}}$ orthogonal and $\\mathbf{R}_{\\mathrm{G}}$ upper-trapezoidal.\n- Propose and implement a sign-alignment method to make the diagonals of $\\mathbf{R}_{\\mathrm{H}}$ and $\\mathbf{R}_{\\mathrm{G}}$ comparable under a single sign convention. The method must preserve the equality $\\mathbf{A} = \\mathbf{Q} \\mathbf{R}$ for each factorization. A valid approach is to enforce a nonnegative diagonal in $\\mathbf{R}$ by multiplying row $k$ of $\\mathbf{R}$ and column $k$ of $\\mathbf{Q}$ by $-1$ whenever the diagonal element $\\mathbf{R}_{k k}$ is negative, for $k = 1, \\dots, \\min(m,n)$; when $\\mathbf{R}_{k k}$ is numerically zero, leave it unchanged.\n\nFor each matrix, design cross-checks that verify:\n- Upper-trapezoidal structure: the entries strictly below the main diagonal of $\\mathbf{R}_{\\mathrm{H}}$ and $\\mathbf{R}_{\\mathrm{G}}$ have small magnitude relative to the scale of $\\mathbf{A}$.\n- Orthogonality: $\\|\\mathbf{Q}^{\\top}\\mathbf{Q} - \\mathbf{I}\\|_F$ is small for both $\\mathbf{Q}_{\\mathrm{H}}$ and $\\mathbf{Q}_{\\mathrm{G}}$.\n- Reconstruction: $\\|\\mathbf{A} - \\mathbf{Q}\\mathbf{R}\\|_F$ is small for both decompositions.\n- Aligned triangular comparison: after applying the sign-alignment convention to both $\\mathbf{R}_{\\mathrm{H}}$ and $\\mathbf{R}_{\\mathrm{G}}$, the two triangular factors are close in Frobenius norm.\n\nAll comparisons must be performed using a numerically reasonable tolerance based on the Frobenius norm $\\|\\mathbf{A}\\|_F$ of the input and a scale-invariant threshold. Angles are implicit in the use of cosines and sines of Givens rotations and do not need explicit units. No physical units are involved.\n\nImplement the algorithms directly from the above principles; do not call any built-in orthogonal-triangular factorization (QR) routines. You may, however, use basic linear algebra operations.\n\nUse the following test suite of real matrices, given explicitly as arrays:\n- Test case $1$ (tall, full column rank):\n$$\n\\mathbf{A}_1 =\n\\begin{bmatrix}\n3 & -2 & 5 \\\\\n7 & 1 & -1 \\\\\n2 & 4 & 0 \\\\\n-3 & 5 & 2 \\\\\n1 & -6 & 3\n\\end{bmatrix}.\n$$\n- Test case $2$ (square, full rank):\n$$\n\\mathbf{A}_2 =\n\\begin{bmatrix}\n4 & 2 & -2 \\\\\n1 & 3 & 0 \\\\\n0 & -1 & 5\n\\end{bmatrix}.\n$$\n- Test case $3$ (square, rank deficient):\n$$\n\\mathbf{A}_3 =\n\\begin{bmatrix}\n1 & 0 & 1 & 2 \\\\\n0 & 1 & 2 & -1 \\\\\n2 & -3 & -4 & 1 \\\\\n-1 & 4 & 7 & 0\n\\end{bmatrix}.\n$$\n- Test case $4$ (wide, full row rank):\n$$\n\\mathbf{A}_4 =\n\\begin{bmatrix}\n1 & 0 & 2 & -1 & 3 \\\\\n0 & -2 & 1 & 4 & -1 \\\\\n3 & 5 & -2 & 0 & 1\n\\endbmatrix}.\n$$\n\nFor each $\\mathbf{A}_i$, aggregate all cross-checks into a single boolean result $b_i$ that is $ \\mathrm{True} $ if and only if all of the following hold simultaneously:\n- $\\mathbf{R}_{\\mathrm{H}}$ is upper-trapezoidal within tolerance.\n- $\\mathbf{R}_{\\mathrm{G}}$ is upper-trapezoidal within tolerance.\n- $\\mathbf{Q}_{\\mathrm{H}}$ is orthogonal within tolerance.\n- $\\mathbf{Q}_{\\mathrm{G}}$ is orthogonal within tolerance.\n- $\\mathbf{A}_i \\approx \\mathbf{Q}_{\\mathrm{H}} \\mathbf{R}_{\\mathrm{H}}$ and $\\mathbf{A}_i \\approx \\mathbf{Q}_{\\mathrm{G}} \\mathbf{R}_{\\mathrm{G}}$ within tolerance.\n- After sign alignment to enforce a nonnegative diagonal in both $\\mathbf{R}_{\\mathrm{H}}$ and $\\mathbf{R}_{\\mathrm{G}}$, the two triangular factors approximately match within tolerance.\n\nFinal Output Format:\n- Your program should produce a single line of output containing the boolean results as a comma-separated list enclosed in square brackets, in the order $[b_1,b_2,b_3,b_4]$. For example, an output could look like $[\\mathrm{True},\\mathrm{True},\\mathrm{True},\\mathrm{True}]$ if all test cases pass all cross-checks.", "solution": "The problem is well-posed, scientifically sound, and contains all necessary information for its resolution. It requests the implementation and verification of two fundamental numerical linear algebra algorithms—QR factorization via Householder reflectors and Givens rotations—and a subsequent comparison. This constitutes a standard and valuable exercise in computational science.\n\nThe core task is to find the QR factorization of a given real matrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$, which is a decomposition of the form $\\mathbf{A} = \\mathbf{Q}\\mathbf{R}$, where $\\mathbf{Q} \\in \\mathbb{R}^{m \\times m}$ is an orthogonal matrix ($\\mathbf{Q}^{\\top}\\mathbf{Q} = \\mathbf{I}_m$) and $\\mathbf{R} \\in \\mathbb{R}^{m \\times n}$ is an upper-trapezoidal matrix. An upper-trapezoidal matrix has zero entries below its main diagonal, i.e., $\\mathbf{R}_{ij} = 0$ for $i > j$.\n\nWe will construct two such factorizations, $(\\mathbf{Q}_{\\mathrm{H}}, \\mathbf{R}_{\\mathrm{H}})$ and $(\\mathbf{Q}_{\\mathrm{G}}, \\mathbf{R}_{\\mathrm{G}})$, using Householder reflectors and Givens rotations, respectively.\n\n### 1. QR Factorization via Householder Reflectors\n\nThe strategy is to apply a sequence of orthogonal transformations to the matrix $\\mathbf{A}$ to progressively introduce zeros below the main diagonal. Each transformation zeroes out the sub-diagonal elements of a single column. The Householder reflector is the tool for this task.\n\nFor each column $k$ (from $1$ to $\\min(m-1, n)$), we aim to transform the current matrix, which we will call $\\mathbf{A}^{(k-1)}$ (with $\\mathbf{A}^{(0)} = \\mathbf{A}$), into $\\mathbf{A}^{(k)} = \\mathbf{H}_k \\mathbf{A}^{(k-1)}$, where $\\mathbf{H}_k$ is a Householder reflector chosen to zero out the entries in column $k$ below the diagonal element $\\mathbf{A}^{(k)}_{kk}$.\n\nThe reflector $\\mathbf{H}_k$ acts on the vector $\\mathbf{x} \\in \\mathbb{R}^{m-k+1}$ which is the sub-column $\\mathbf{A}^{(k-1)}_{k:m,k}$. We require a reflector $\\hat{\\mathbf{H}}_k$ such that $\\hat{\\mathbf{H}}_k \\mathbf{x} = \\alpha \\mathbf{e}_1$, where $\\mathbf{e}_1 = [1, 0, \\dots, 0]^{\\top}$ and $\\alpha$ is a scalar. Since orthogonal transformations preserve the Euclidean norm, $|\\alpha| = \\|\\mathbf{x}\\|_2$. The reflector is defined by a vector $\\mathbf{v}$ normal to the reflection hyperplane. This vector is given by $\\mathbf{v} = \\mathbf{x} - \\alpha \\mathbf{e}_1$. To avoid numerical cancellation, a robust choice for $\\alpha$ is $\\alpha = -\\mathrm{sgn}(\\mathbf{x}_1) \\|\\mathbf{x}\\|_2$, where $\\mathbf{x}_1$ is the first component of $\\mathbf{x}$.\n\nThe Householder reflector is then given by $\\hat{\\mathbf{H}}_k = \\mathbf{I} - 2\\frac{\\mathbf{v}\\mathbf{v}^{\\top}}{\\mathbf{v}^{\\top}\\mathbf{v}}$. In practice, to avoid forming the matrix explicitly, we compute $\\beta = 2/(\\mathbf{v}^{\\top}\\mathbf{v})$ and apply the transformation to a matrix $\\mathbf{C}$ as $\\hat{\\mathbf{H}}_k\\mathbf{C} = \\mathbf{C} - \\beta \\mathbf{v}(\\mathbf{v}^{\\top}\\mathbf{C})$.\n\nThe full transformation matrix at step $k$ is $\\mathbf{H}_k = \\begin{pmatrix} \\mathbf{I}_{k-1} & \\mathbf{0} \\\\ \\mathbf{0} & \\hat{\\mathbf{H}}_k \\end{pmatrix}$. After $\\min(m-1, n)$ steps, we have $\\mathbf{H}_{\\min(m-1,n)} \\dots \\mathbf{H}_2 \\mathbf{H}_1 \\mathbf{A} = \\mathbf{R}_{\\mathrm{H}}$.\nSince each $\\mathbf{H}_k$ is orthogonal, their product is also orthogonal. Let $\\mathbf{Q}_{\\mathrm{H}}^{\\top} = \\mathbf{H}_{\\min(m-1,n)} \\dots \\mathbf{H}_1$. Then $\\mathbf{A} = \\mathbf{Q}_{\\mathrm{H}}\\mathbf{R}_{\\mathrm{H}}$, with $\\mathbf{Q}_{\\mathrm{H}} = \\mathbf{H}_1^{\\top} \\dots \\mathbf{H}_{\\min(m-1,n)}^{\\top} = \\mathbf{H}_1 \\dots \\mathbf{H}_{\\min(m-1,n)}$.\nThe matrix $\\mathbf{Q}_{\\mathrm{H}}$ is formed by starting with $\\mathbf{Q} = \\mathbf{I}_m$ and successively applying the reflectors: $\\mathbf{Q} \\leftarrow \\mathbf{Q} \\mathbf{H}_k$.\n\n### 2. QR Factorization via Givens Rotations\n\nGivens rotations offer a more fine-grained approach, introducing zeros one element at a time. A Givens rotation acts on a 2D plane spanned by two coordinate axes. To zero out the element at position $(i, j)$ (with $i > j$) using the pivot element at $(j, j)$, we apply a rotation in the $(j, i)$-plane.\n\nLet the values of the two elements be $a = \\mathbf{R}_{jj}$ and $b = \\mathbf{R}_{ij}$. We seek a rotation matrix that transforms the vector $[a, b]^{\\top}$ into $[r, 0]^{\\top}$. The rotation matrix is\n$$\n\\mathbf{G}_{ji}^{\\top} = \\begin{pmatrix} c & s \\\\ -s & c \\end{pmatrix}\n$$\nwhere $c^2 + s^2 = 1$. The transformation yields $\\begin{pmatrix} c & s \\\\ -s & c \\end{pmatrix} \\begin{pmatrix} a \\\\ b \\end{pmatrix} = \\begin{pmatrix} ca + sb \\\\ -sa + cb \\end{pmatrix}$. To make the second component zero, we choose $c = a/r$ and $s = b/r$, where $r = \\sqrt{a^2 + b^2}$. This results in the new vector $[r, 0]^{\\top}$.\n\nThe overall algorithm proceeds by iterating through columns $j$ from $1$ to $n$, and for each column, iterating through rows $i$ from $j+1$ to $m$. At each step $(i, j)$, a Givens rotation $\\mathbf{G}_{ji}^{\\top}$ is applied to the left of the current matrix to zero out the element $\\mathbf{R}_{ij}$.\nThe final upper-trapezoidal matrix is $\\mathbf{R}_{\\mathrm{G}} = (\\dots \\mathbf{G}_{m,n-1}^{\\top} \\dots \\mathbf{G}_{j+1,j}^{\\top} \\dots) \\mathbf{A}$.\nThe orthogonal matrix $\\mathbf{Q}_{\\mathrm{G}}$ is the product of all the Givens matrices: $\\mathbf{Q}_{\\mathrm{G}} = (\\dots \\mathbf{G}_{j+1,j} \\dots \\mathbf{G}_{m,n-1} \\dots)$. This is constructed by initializing $\\mathbf{Q} = \\mathbf{I}_m$ and successively post-multiplying by each Givens matrix $\\mathbf{G}_{ji}$. The update rule for two columns $\\mathbf{q}_j$ and $\\mathbf{q}_i$ of $\\mathbf{Q}$ becomes:\n$(\\mathbf{q}'_j, \\mathbf{q}'_i) = (\\mathbf{q}_j, \\mathbf{q}_i) \\begin{pmatrix} c & -s \\\\ s & c \\end{pmatrix}$.\n\n### 3. Sign Alignment and Uniqueness\n\nThe QR factorization of a full-rank matrix is unique up to the signs of the columns of $\\mathbf{Q}$ and rows of $\\mathbf{R}$. Specifically, if $\\mathbf{A} = \\mathbf{Q}\\mathbf{R}$, then for any diagonal matrix $\\mathbf{D}$ with $\\mathbf{D}_{kk} = \\pm 1$, the factorization $\\mathbf{A} = (\\mathbf{Q}\\mathbf{D})(\\mathbf{D}\\mathbf{R})$ is also a valid QR factorization. To enable a meaningful comparison between $\\mathbf{R}_{\\mathrm{H}}$ and $\\mathbf{R}_{\\mathrm{G}}$, we must enforce a consistent sign convention.\n\nThe problem specifies a canonical representation where all diagonal elements of $\\mathbf{R}$ are non-negative. For each $k \\in \\{1, \\dots, \\min(m,n)\\}$, if $\\mathbf{R}_{kk} < 0$, we multiply the $k$-th row of $\\mathbf{R}$ and the $k$-th column of $\\mathbf{Q}$ by $-1$. This corresponds to setting $\\mathbf{D}_{kk} = \\mathrm{sgn}(\\mathbf{R}_{kk})$ (with $\\mathrm{sgn}(0)$ defined as $1$). This operation preserves the equality $\\mathbf{A}=\\mathbf{Q}\\mathbf{R}$ and the orthogonality of $\\mathbf{Q}$.\n\n### 4. Verification and Cross-Checks\n\nTo validate the correctness and precision of the implemented algorithms, we perform four types of checks for each input matrix $\\mathbf{A}$, using a dynamically scaled tolerance $\\tau = \\|\\mathbf{A}\\|_F \\times \\epsilon$, where $\\epsilon$ is a small factor like $10^{-12}$.\n\n1.  **Upper-Trapezoidal Structure**: The Frobenius norm of the strictly lower-triangular part of $\\mathbf{R}$ must be close to zero. We check $\\|\\mathrm{tril}(\\mathbf{R}, -1)\\|_F < \\tau$.\n2.  **Orthogonality of Q**: The matrix $\\mathbf{Q}$ must be orthogonal. We verify this by checking if its deviation from orthogonality is small: $\\|\\mathbf{Q}^{\\top}\\mathbf{Q} - \\mathbf{I}_m\\|_F < \\tau$.\n3.  **Reconstruction Accuracy**: The product $\\mathbf{Q}\\mathbf{R}$ must reconstruct the original matrix $\\mathbf{A}$. We check the reconstruction error: $\\|\\mathbf{A} - \\mathbf{Q}\\mathbf{R}\\|_F < \\tau$.\n4.  **Aligned Triangular Comparison**: After applying the sign-alignment convention to both $(\\mathbf{Q}_{\\mathrm{H}}, \\mathbf{R}_{\\mathrm{H}})$ and $(\\mathbf{Q}_{\\mathrm{G}}, \\mathbf{R}_{\\mathrm{G}})$ to obtain $(\\mathbf{Q}_{\\mathrm{H}}', \\mathbf{R}_{\\mathrm{H}}')$ and $(\\mathbf{Q}_{\\mathrm{G}}', \\mathbf{R}_{\\mathrm{G}}')$, the resulting triangular factors should be identical (within tolerance). We check $\\|\\mathbf{R}_{\\mathrm{H}}' - \\mathbf{R}_{\\mathrm{G}}'\\|_F < \\tau$.\n\nA test case is considered successful only if all these checks pass for both the Householder and Givens-based factorizations.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef qr_householder(A):\n    \"\"\"\n    Computes QR factorization of a matrix A using Householder reflectors.\n    Returns Q, R where A = QR, Q is orthogonal, and R is upper-trapezoidal.\n    \"\"\"\n    m, n = A.shape\n    R = A.copy().astype(np.float64)\n    Q = np.identity(m, dtype=np.float64)\n\n    for k in range(min(m - 1, n)):\n        x = R[k:, k]\n        x_norm = np.linalg.norm(x)\n        if np.isclose(x_norm, 0.0):\n            continue\n\n        v = x.copy()\n        v[0] += np.copysign(x_norm, x[0])\n        \n        v_norm = np.linalg.norm(v)\n        if np.isclose(v_norm, 0.0):\n            continue\n        v /= v_norm\n\n        beta = 2.0\n        \n        R_sub = R[k:, k:]\n        R[k:, k:] -= beta * np.outer(v, v.T @ R_sub)\n\n        Q_sub = Q[:, k:]\n        Q[:, k:] -= beta * np.outer(Q_sub @ v, v)\n\n    return Q, R\n\n\ndef qr_givens(A):\n    \"\"\"\n    Computes QR factorization of a matrix A using Givens rotations.\n    Returns Q, R where A = QR, Q is orthogonal, and R is upper-trapezoidal.\n    \"\"\"\n    m, n = A.shape\n    R = A.copy().astype(np.float64)\n    Q = np.identity(m, dtype=np.float64)\n\n    for j in range(n):\n        for i in range(j + 1, m):\n            a = R[j, j]\n            b = R[i, j]\n\n            if np.isclose(b, 0.0):\n                continue\n            \n            r = np.hypot(a, b)\n            c = a / r\n            s = b / r\n\n            # Apply G.T to R (affecting rows j and i)\n            R_j_row, R_i_row = R[j, j:].copy(), R[i, j:].copy()\n            R[j, j:] = c * R_j_row + s * R_i_row\n            R[i, j:] = -s * R_j_row + c * R_i_row\n\n            # Apply G to Q (affecting columns j and i)\n            Q_j_col, Q_i_col = Q[:, j].copy(), Q[:, i].copy()\n            Q[:, j] = c * Q_j_col + s * Q_i_col\n            Q[:, i] = -s * Q_j_col + c * Q_i_col\n            \n    return Q, R\n\n\ndef align_signs(Q, R):\n    \"\"\"\n    Enforces a sign convention on QR factorization: diagonal of R is non-negative.\n    \"\"\"\n    m, n = R.shape\n    Q_aligned = Q.copy()\n    R_aligned = R.copy()\n\n    for k in range(min(m, n)):\n        if R_aligned[k, k]  0:\n            R_aligned[k, :] *= -1\n            Q_aligned[:, k] *= -1\n    \n    return Q_aligned, R_aligned\n\n\ndef run_checks_for_matrix(A):\n    \"\"\"\n    Performs all computations and cross-checks for a single matrix A.\n    Returns True if all checks pass, False otherwise.\n    \"\"\"\n    m, n = A.shape\n    \n    norm_A = np.linalg.norm(A, 'fro')\n    tol = norm_A * 1e-12 if not np.isclose(norm_A, 0.0) else 1e-10\n\n    Q_H, R_H = qr_householder(A)\n    Q_G, R_G = qr_givens(A)\n\n    checks = []\n\n    # 1. Upper-trapezoidal structure\n    checks.append(np.linalg.norm(np.tril(R_H, -1), 'fro')  tol)\n    checks.append(np.linalg.norm(np.tril(R_G, -1), 'fro')  tol)\n\n    # 2. Orthogonality of Q\n    I_m = np.identity(m)\n    checks.append(np.linalg.norm(Q_H.T @ Q_H - I_m, 'fro')  tol)\n    checks.append(np.linalg.norm(Q_G.T @ Q_G - I_m, 'fro')  tol)\n\n    # 3. Reconstruction accuracy\n    checks.append(np.linalg.norm(A - Q_H @ R_H, 'fro')  tol)\n    checks.append(np.linalg.norm(A - Q_G @ R_G, 'fro')  tol)\n\n    # 4. Aligned triangular comparison\n    Q_H_a, R_H_a = align_signs(Q_H, R_H)\n    Q_G_a, R_G_a = align_signs(Q_G, R_G)\n\n    # Sanity check: ensure alignment preserved factorization\n    checks.append(np.linalg.norm(A - Q_H_a @ R_H_a, 'fro')  tol)\n    checks.append(np.linalg.norm(A - Q_G_a @ R_G_a, 'fro')  tol)\n    \n    # Main comparison of aligned R factors\n    checks.append(np.linalg.norm(R_H_a - R_G_a, 'fro')  tol)\n\n    return all(checks)\n\n\ndef solve():\n    \"\"\"\n    Main function to run the process for the test suite and print results.\n    \"\"\"\n    test_cases = [\n        np.array([[3, -2, 5], [7, 1, -1], [2, 4, 0], [-3, 5, 2], [1, -6, 3]]),\n        np.array([[4, 2, -2], [1, 3, 0], [0, -1, 5]]),\n        np.array([[1, 0, 1, 2], [0, 1, 2, -1], [2, -3, -4, 1], [-1, 4, 7, 0]]),\n        np.array([[1, 0, 2, -1, 3], [0, -2, 1, 4, -1], [3, 5, -2, 0, 1]]),\n    ]\n    \n    results = [run_checks_for_matrix(A) for A in test_cases]\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3548524"}]}