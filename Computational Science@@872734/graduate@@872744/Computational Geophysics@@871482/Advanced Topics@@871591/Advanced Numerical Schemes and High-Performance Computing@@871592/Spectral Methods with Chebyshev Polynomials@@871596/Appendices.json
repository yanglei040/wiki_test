{"hands_on_practices": [{"introduction": "The cornerstone of spectral methods is the ability to represent a function $f(x)$ with exceptional accuracy using a truncated series of basis polynomials. This first practice focuses on the fundamental task of Chebyshev interpolation, the \"hello world\" of spectral approximations. You will learn the essential workflow of transforming function values $\\{f(x_j)\\}$ from a set of Chebyshev-Lobatto nodes into a corresponding set of spectral coefficients $\\{a_n\\}$, and then use these coefficients to demonstrate the hallmark exponential convergence that makes these methods so powerful for smooth problems. [@problem_id:3614946]", "problem": "Consider the task of constructing a spectral interpolant for the analytic function $f(x)=e^{x}$ on the interval $[-1,1]$ using Chebyshev polynomials of the first kind. This task is representative of a core step in spectral methods widely used in Computational Geophysics for high-accuracy approximation of smooth fields (for instance, stratified velocity profiles or temperature distributions), where Chebyshev expansions provide exponential convergence for analytic functions.\n\nYou must start from the following fundamental base:\n- The Chebyshev polynomials of the first kind $\\{T_n(x)\\}_{n \\ge 0}$ are defined by the relations $T_0(x)=1$, $T_1(x)=x$, and the recurrence $T_{n+1}(x)=2x\\,T_n(x)-T_{n-1}(x)$, and equivalently $T_n(x)=\\cos(n\\arccos x)$.\n- The Chebyshev–Lobatto nodes are $x_j=\\cos\\left(\\frac{\\pi j}{N}\\right)$ for $j=0,1,\\dots,N$, with $N\\in\\mathbb{N}$ and angles in radians.\n- The pointwise values $\\{f(x_j)\\}$ at Chebyshev–Lobatto nodes admit a discrete cosine representation that can be mapped to Chebyshev coefficients by the Discrete Cosine Transform of Type I (DCT-I), leveraging the discrete orthogonality of $\\{\\cos(k\\theta)\\}$ on the grid $\\theta_j=\\frac{\\pi j}{N}$ when endpoints are taken with half-weight.\n\nYour goal is to implement, from first principles, the mapping from gridded data to the Chebyshev interpolant and evaluate its accuracy. In particular:\n1. For a given integer $N\\geq 1$, form the $N+1$ Chebyshev–Lobatto nodes $x_j=\\cos\\left(\\frac{\\pi j}{N}\\right)$ and compute the samples $f_j=f(x_j)$ of $f(x)=e^x$.\n2. Compute the Chebyshev interpolant coefficients $\\{a_n\\}_{n=0}^{N}$ from $\\{f_j\\}_{j=0}^{N}$ using the Discrete Cosine Transform of Type I (DCT-I). You must correctly account for the endpoint half-weights implied by the discrete orthogonality on Chebyshev–Lobatto nodes when reconstructing the interpolant.\n3. Evaluate the interpolant $P_N(x)$ at $x=0.8$ using a numerically stable summation strategy consistent with the recurrence of Chebyshev polynomials. Carefully handle the endpoint contributions so that the interpolant evaluation matches the interpolation conditions at the nodes.\n4. Estimate the pointwise error at $x=0.8$ as $E_N=\\left|P_N(0.8)-e^{0.8}\\right|$.\n\nAngle measures in all trigonometric expressions must be in radians. No physical units are involved.\n\nTest Suite:\nCompute $E_N$ for the following values of $N$ to exercise different facets of the implementation:\n- Boundary case: $N=1$.\n- Small sizes: $N=2$, $N=4$.\n- Moderate sizes: $N=10$, $N=20$.\n- Larger sizes for high accuracy and non-power-of-two coverage: $N=64$, $N=127$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the seven error values $[E_{1},E_{2},E_{4},E_{10},E_{20},E_{64},E_{127}]$ as a comma-separated list enclosed in square brackets, in decimal form (floats). For example: \"[0.1,0.01,0.001,0.0001,0.00001,1e-6,1e-7]\". Your program must be fully self-contained, require no user input, and implement the computations as specified above using DCT-I to obtain the interpolant coefficients.", "solution": "The objective is to construct a Chebyshev polynomial interpolant for the analytic function $f(x) = e^x$ on the interval $[-1, 1]$ for various polynomial degrees $N$, and to evaluate the pointwise accuracy of this interpolant at $x=0.8$. The procedure involves four primary steps: sampling the function at Chebyshev-Lobatto nodes, computing the Chebyshev coefficients of the interpolant via the Discrete Cosine Transform (DCT-I), evaluating the resulting polynomial sum using a stable algorithm, and calculating the approximation error.\n\n**Step 1: Chebyshev-Lobatto Nodes and Function Sampling**\n\nFor a chosen polynomial degree $N \\in \\mathbb{N}$, the interpolant is constructed to match the function $f(x)$ at $N+1$ specific points. The Chebyshev-Lobatto nodes are an optimal choice for this purpose, minimizing the Runge phenomenon for polynomial interpolation. These nodes are the extrema of the Chebyshev polynomial $T_N(x)$ on the interval $[-1,1]$. They are defined as:\n$$\nx_j = \\cos\\left(\\frac{\\pi j}{N}\\right) \\quad \\text{for } j = 0, 1, \\dots, N\n$$\nThe angles are taken in radians. The function $f(x) = e^x$ is then sampled at these $N+1$ nodes to obtain the data points $\\{f_j\\}_{j=0}^N$, where $f_j = f(x_j) = e^{x_j}$.\n\n**Step 2: Computation of Chebyshev Coefficients**\n\nThe Chebyshev interpolating polynomial of degree $N$ is denoted by $P_N(x)$. It can be expressed as a linear combination of the first $N+1$ Chebyshev polynomials of the first kind, $\\{T_n(x)\\}_{n=0}^N$:\n$$\nP_N(x) = \\sum_{n=0}^{N} c_n T_n(x)\n$$\nThe interpolation conditions are $P_N(x_j) = f_j$ for $j=0, \\dots, N$. This leads to a system of linear equations for the coefficients $\\{c_n\\}$. A more direct and numerically efficient method to find these coefficients leverages the connection between Chebyshev polynomials and the cosine function, $T_n(\\cos\\theta) = \\cos(n\\theta)$. Substituting $x_j = \\cos(\\frac{\\pi j}{N})$ into the interpolation conditions yields:\n$$\nf_j = \\sum_{n=0}^{N} c_n T_n(x_j) = \\sum_{n=0}^{N} c_n \\cos\\left(\\frac{n \\pi j}{N}\\right)\n$$\nThis is a finite discrete cosine series. The coefficients can be found by exploiting the discrete orthogonality of the cosine functions on the grid points $\\theta_j = \\frac{\\pi j}{N}$. The standard formulation of the interpolant is often written with halved contributions from the first and last basis functions:\n$$\nP_N(x) = \\sum_{n=0}^{N} {}^{'} a_n T_n(x) \\equiv \\frac{1}{2}a_0 T_0(x) + \\sum_{n=1}^{N-1} a_n T_n(x) + \\frac{1}{2}a_N T_N(x)\n$$\nThe corresponding coefficients $\\{a_n\\}$ are given by a discrete transform:\n$$\na_n = \\frac{2}{N} \\sum_{j=0}^{N} {}^{''} f_j T_n(x_j) = \\frac{2}{N} \\sum_{j=0}^{N} {}^{''} f_j \\cos\\left(\\frac{n \\pi j}{N}\\right)\n$$\nwhere the double prime on the summation indicates that the terms for $j=0$ and $j=N$ are multiplied by $\\frac{1}{2}$. This summation is directly related to the Discrete Cosine Transform of Type I (DCT-I). For a data sequence $\\{f_j\\}_{j=0}^N$, the DCT-I is defined as:\n$$\nY_n = f_0 + (-1)^n f_N + 2 \\sum_{j=1}^{N-1} f_j \\cos\\left(\\frac{n \\pi j}{N}\\right)\n$$\nBy inspection, the sum in the formula for $a_n$ is equal to $\\frac{1}{2}Y_n$. Therefore, the coefficients are:\n$$\na_n = \\frac{2}{N} \\left(\\frac{1}{2} Y_n\\right) = \\frac{Y_n}{N}\n$$\nTo evaluate the polynomial sum in its standard form $\\sum_{n=0}^N c_n T_n(x)$, we set $c_n$ to be the coefficients of each basis function $T_n(x)$. From the formulation with the primed summation, we have:\n$$\nc_0 = \\frac{1}{2}a_0 = \\frac{Y_0}{2N}, \\quad c_N = \\frac{1}{2}a_N = \\frac{Y_N}{2N}, \\quad \\text{and} \\quad c_n = a_n = \\frac{Y_n}{N} \\quad \\text{for } 1 \\le n \\le N-1.\n$$\nThese coefficients $\\{c_n\\}_{n=0}^N$ will be used in the evaluation step.\n\n**Step 3: Stable Polynomial Evaluation via Clenshaw's Algorithm**\n\nTo evaluate $P_N(x) = \\sum_{n=0}^{N} c_n T_n(x)$ at the specified point $x = 0.8$, a naive summation would be inefficient and potentially numerically unstable. The prescribed stable method is Clenshaw's algorithm, which leverages the three-term recurrence relation of the Chebyshev polynomials: $T_{n+1}(x) = 2x T_n(x) - T_{n-1}(x)$ for $n \\ge 1$.\n\nThe algorithm proceeds as follows to compute the sum $S$:\n1. Initialize two variables, $u_{k+2} = 0$ and $u_{k+1} = 0$.\n2. Iterate downwards from $k=N$ to $k=0$:\n   $$ u_k = c_k + 2x u_{k+1} - u_{k+2} $$\n   In each step, the old $u_{k+1}$ becomes the new $u_{k+2}$ and the old $u_k$ becomes the new $u_{k+1}$.\n3. After the loop completes, the value of the sum is given by:\n   $$ P_N(x) = u_0 - x u_1 $$\nThis algorithm avoids explicit computation of $T_n(x)$ and is both efficient (requiring $O(N)$ operations) and numerically stable.\n\n**Step 4: Error Estimation**\n\nThe final step is to quantify the accuracy of the interpolation. The pointwise error $E_N$ at $x=0.8$ is calculated as the absolute difference between the interpolated value $P_N(0.8)$ and the true function value $f(0.8)$:\n$$\nE_N = |P_N(0.8) - e^{0.8}|\n$$\nThis entire procedure is repeated for each value of $N$ in the test suite: $N \\in \\{1, 2, 4, 10, 20, 64, 127\\}$. The exponential convergence characteristic of spectral methods for analytic functions should be observable as a rapid decrease in $E_N$ as $N$ increases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.fft import dct\n\ndef solve():\n    \"\"\"\n    Computes the error of Chebyshev interpolation for f(x)=e^x at x=0.8\n    for a suite of polynomial degrees N.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [1, 2, 4, 10, 20, 64, 127]\n    \n    # The point at which to evaluate the interpolant and its error.\n    eval_point = 0.8\n    true_value = np.exp(eval_point)\n\n    results = []\n    \n    for N in test_cases:\n        # Step 1: Form the N+1 Chebyshev–Lobatto nodes and compute function samples.\n        # j is an array [0, 1, ..., N]\n        j = np.arange(N + 1)\n        # x_j = cos(pi*j/N)\n        nodes = np.cos(np.pi * j / N)\n        # f_j = f(x_j) = e^(x_j)\n        f_values = np.exp(nodes)\n\n        # Step 2: Compute the Chebyshev interpolant coefficients using DCT-I.\n        # The DCT-I of the function values {f_j} gives {Y_n}.\n        # Y_n = f_0 + (-1)^n f_N + 2 * sum_{j=1}^{N-1} f_j * cos(n*pi*j/N)\n        # The scipy.fft.dct function with type=1 computes exactly this.\n        dct_vals = dct(f_values, type=1)\n\n        # The coefficients {a_n} of the interpolant form P_N(x)=sum'{a_n T_n(x)}\n        # are a_n = Y_n / N.\n        # For evaluation with a standard sum P_N(x)=sum{c_n T_n(x)}, the\n        # coefficients are c_0 = a_0/2, c_N = a_N/2, and c_n = a_n otherwise.\n        # This is equivalent to scaling Y_0 and Y_N by 1/(2N) and other Y_n by 1/N.\n        \n        # Guard against division by zero if N=0, though not in test cases.\n        if N == 0:\n            # For N=0, P_0(x) is a constant f(x_0)=f(1)=e.\n            # In this special case, c_0 = f_0 = e. Error is |e - e^0.8|.\n            # This logic block is for completeness and not required by the test suite.\n            p_N_at_point = f_values[0]\n            error = np.abs(p_N_at_point - true_value)\n            results.append(error)\n            continue\n            \n        cheb_coeffs = dct_vals / N\n        cheb_coeffs[0] /= 2.0\n        cheb_coeffs[N] /= 2.0\n        \n        # Step 3: Evaluate the interpolant P_N(x) at x=0.8 using Clenshaw's algorithm.\n        # This evaluates the sum sum_{n=0 to N} c_n T_n(x).\n        u_k_plus_2 = 0.0\n        u_k_plus_1 = 0.0\n        # Iterate downwards from k=N to 0\n        for k in range(N, -1, -1):\n            # Recurrence: u_k = c_k + 2*x*u_{k+1} - u_{k+2}\n            u_k = cheb_coeffs[k] + 2.0 * eval_point * u_k_plus_1 - u_k_plus_2\n            # Update for next iteration\n            u_k_plus_2 = u_k_plus_1\n            u_k_plus_1 = u_k\n        \n        # The final value of the sum is u_0 - x*u_1\n        # At the end of the loop, u_k_plus_1 holds u_0 and u_k_plus_2 holds u_1.\n        p_N_at_point = u_k_plus_1 - eval_point * u_k_plus_2\n\n        # Step 4: Estimate the pointwise error at x=0.8.\n        error = np.abs(p_N_at_point - true_value)\n        results.append(error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3614946"}, {"introduction": "While spectral methods provide exponential convergence for smooth functions, many geophysical phenomena involve sharp fronts where a naive spectral expansion $u_N(x) = \\sum_{k=0}^N a_k T_k(x)$ is plagued by non-physical Gibbs oscillations. This exercise tackles this critical issue by introducing spectral filtering, a practical technique for post-processing the spectral coefficients. [@problem_id:3614897] You will apply a high-order filter $\\sigma_k$ to the coefficients $a_k$ to produce a smoothed approximation, and in doing so, quantify the crucial trade-off between suppressing oscillations and preserving accuracy.", "problem": "Consider a one-dimensional, non-dimensionalized, sharp-front profile representative of a tracer concentration in a stratified fluid on the interval $[-1,1]$. Let the target field be the monotone transition\n$$\nf(x) = \\tfrac{1}{2}\\left(1 + \\tanh\\left(s\\,(x - x_0)\\right)\\right),\n$$\nwhere $s > 0$ controls the sharpness of the front and $x_0 \\in (-1,1)$ is the front location. You will construct a Chebyshev polynomial approximation on $[-1,1]$, apply an $8$th-order exponential filter to its Chebyshev coefficients, and quantify the trade-off between oscillation suppression and spectral accuracy loss.\n\nStarting from the following foundational elements:\n- The Chebyshev polynomials of the first kind $\\{T_k(x)\\}_{k=0}^\\infty$ satisfy $T_k(\\cos \\theta) = \\cos(k\\theta)$ and are orthogonal on $[-1,1]$ with respect to the weight $w(x) = (1-x^2)^{-1/2}$.\n- The Chebyshev-Lobatto grid is defined by the nodes $x_j = \\cos\\left(\\frac{\\pi j}{N}\\right)$ for $j=0,1,\\dots,N$.\n- The truncated Chebyshev expansion of degree $N$ is\n$$\nu_N(x) = \\sum_{k=0}^N a_k T_k(x),\n$$\nwhere the coefficients $\\{a_k\\}$ approximate the exact orthogonal projection coefficients of $f$ under the Chebyshev inner product.\n\nYou must:\n1. Sample $f(x)$ at the Chebyshev-Lobatto nodes $\\{x_j\\}_{j=0}^N$ to obtain nodal values $\\{v_j\\}$.\n2. Compute the Chebyshev coefficients $\\{a_k\\}_{k=0}^N$ of the interpolating polynomial that matches the nodal values $\\{v_j\\}$.\n3. Define and apply an $8$th-order exponential filter to the coefficients by\n$$\n\\sigma_k = \\exp\\!\\left(-\\alpha \\left(\\frac{k}{N}\\right)^p\\right), \\quad p=8,\\quad \\sigma_0 = 1,\n$$\nand let the filtered coefficients be $\\{\\tilde{a}_k\\}$ with $\\tilde{a}_k = \\sigma_k a_k$.\n4. Evaluate both $u_N(x)$ and the filtered approximation $\\tilde{u}_N(x) = \\sum_{k=0}^N \\tilde{a}_k T_k(x)$ on a uniform grid of $M$ points in $[-1,1]$.\n5. Quantify the oscillation suppression by the excess total variation,\n$$\n\\mathrm{ETV}(g) = \\sum_{i=0}^{M-2} \\left| g(x_{i+1}) - g(x_i) \\right| - \\left| g(x_{M-1}) - g(x_0) \\right|,\n$$\ncomputed for $g=u_N$ and $g=\\tilde{u}_N$ on the same uniform grid $\\{x_i\\}_{i=0}^{M-1}$.\n6. Quantify spectral accuracy loss via the relative discrete $L^2$ error on the uniform grid:\n$$\n\\varepsilon(g) = \\frac{\\left( \\frac{1}{M}\\sum_{i=0}^{M-1} \\left(g(x_i)-f(x_i)\\right)^2 \\right)^{1/2}}{\\left( \\frac{1}{M}\\sum_{i=0}^{M-1} f(x_i)^2 \\right)^{1/2}},\n$$\ncomputed for $g=u_N$ and $g=\\tilde{u}_N$.\n\nImplementation requirements:\n- Use $M=2001$ equispaced grid points in $[-1,1]$ for evaluation of the excess total variation and the relative $L^2$ error.\n- Use the Chebyshev-Lobatto nodes for coefficient computation, and evaluate $u_N$ and $\\tilde{u}_N$ from the Chebyshev coefficients.\n- Apply the $8$th-order filter as defined with exponent $p=8$ and parameter $\\alpha > 0$.\n\nTest suite:\nFor each parameter set $(N,\\alpha,s,x_0)$ below, compute and report the four floating-point quantities in the order $[\\mathrm{ETV}(u_N), \\mathrm{ETV}(\\tilde{u}_N), \\varepsilon(u_N), \\varepsilon(\\tilde{u}_N)]$.\n\n- Case A (general): $N=128$, $\\alpha=36.0$, $s=40.0$, $x_0=0.2$.\n- Case B (weak filter): $N=128$, $\\alpha=4.0$, $s=40.0$, $x_0=0.2$.\n- Case C (strong filter): $N=128$, $\\alpha=72.0$, $s=40.0$, $x_0=0.2$.\n- Case D (coarser resolution, sharper front): $N=64$, $\\alpha=36.0$, $s=80.0$, $x_0=0.2$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a sublist of four floating-point numbers in the order specified, for example:\n[[ETV_unf_A,ETV_flt_A,RelL2_unf_A,RelL2_flt_A],[ETV_unf_B,ETV_flt_B,RelL2_unf_B,RelL2_flt_B],...]\nEnsure the output is exactly one line, with no additional text or formatting. No physical units are involved; all quantities are non-dimensional real numbers. All angles are in radians by construction through $\\cos(\\cdot)$ in the Chebyshev nodes.", "solution": "The problem requires the construction and analysis of a Chebyshev polynomial approximation to a sharp front, specifically addressing the Gibbs phenomenon and its mitigation via spectral filtering. This is a canonical problem in the application of spectral methods to fields like computational geophysics and fluid dynamics, where sharp interfaces (e.g., thermoclines, tracer fronts) are common.\n\nThe solution proceeds systematically through the steps outlined in the problem statement.\n\n1.  **Discretization and Function Sampling**: The function to be approximated is $f(x) = \\tfrac{1}{2}\\left(1 + \\tanh\\left(s\\,(x - x_0)\\right)\\right)$ on the domain $x \\in [-1, 1]$. The parameter $s > 0$ controls the gradient sharpness, and $x_0$ is the center of the front. We construct a Chebyshev approximation of degree $N$ by interpolating the function $f(x)$ at the $N+1$ Chebyshev-Lobatto nodes, defined as $x_j = \\cos\\left(\\frac{\\pi j}{N}\\right)$ for $j=0, 1, \\dots, N$. These nodes are the extrema of the Chebyshev polynomial $T_N(x)$ and are a standard choice for high-order interpolation due to their clustering near the boundaries, which helps mitigate Runge's phenomenon for smooth functions. The sampled values are denoted $v_j = f(x_j)$.\n\n2.  **Computation of Chebyshev Coefficients**: The Chebyshev interpolant is a polynomial $u_N(x) = \\sum_{k=0}^N a_k T_k(x)$ that satisfies $u_N(x_j) = v_j$ for all $j=0, \\dots, N$. The coefficients $\\{a_k\\}_{k=0}^N$ are determined uniquely by this condition. They can be computed efficiently using the Discrete Cosine Transform of type I (DCT-I). The coefficients are given by the formula:\n    $$\n    a_k = \\frac{C_k}{N \\bar{c}_k}\n    $$\n    where $\\bar{c}_k = 2$ for $k=0$ or $k=N$, and $\\bar{c}_k = 1$ for $1 \\le k \\le N-1$. The term $C_k$ is the result of the DCT-I applied to the vector of nodal values $[v_0, v_1, \\dots, v_N]$:\n    $$\n    C_k = v_0 + (-1)^k v_N + 2 \\sum_{j=1}^{N-1} v_j \\cos\\left(\\frac{\\pi j k}{N}\\right)\n    $$\n    This computation is implemented using the `scipy.fft.dct` function with `type=1`.\n\n3.  **Spectral Filtering**: The sharp gradient in $f(x)$ causes the Chebyshev coefficients $a_k$ to decay slowly, and the abrupt truncation of the series at degree $N$ leads to Gibbs oscillations near the front. To suppress these non-physical oscillations, a spectral filter is applied to the coefficients. The specified $8$-th order exponential filter is defined by the filter function:\n    $$\n    \\sigma_k = \\exp\\!\\left(-\\alpha \\left(\\frac{k}{N}\\right)^p\\right)\n    $$\n    with the order $p=8$ and a tunable strength parameter $\\alpha > 0$. The filtered coefficients are computed as $\\tilde{a}_k = \\sigma_k a_k$ for $k=0, \\dots, N$. This filter smoothly attenuates the high-wavenumber coefficients (large $k$), which are primarily responsible for the Gibbs oscillations. The choice of $p=8$ makes the filter very flat near $k=0$ and steep near $k=N$, thereby preserving the low-wavenumber modes that capture the bulk of the function's structure while aggressively damping the high-wavenumber modes. The condition $\\sigma_0 = 1$ is naturally satisfied by the formula, ensuring the mean value of the approximation is preserved. The resulting filtered approximation is $\\tilde{u}_N(x) = \\sum_{k=0}^N \\tilde{a}_k T_k(x)$.\n\n4.  **Evaluation and Analysis**: Both the unfiltered approximation $u_N(x)$ and the filtered approximation $\\tilde{u}_N(x)$ are evaluated on a fine, uniform grid of $M=2001$ points spanning the interval $[-1, 1]$. The evaluation is efficiently performed using Clenshaw's algorithm, which is available in `numpy.polynomial.chebyshev.chebval`. The performance of each approximation is then quantified using two metrics:\n\n    a.  **Excess Total Variation (ETV)**: This metric quantifies the degree of oscillation. For a perfectly monotone function, the total variation equals the absolute difference between its values at the endpoints. The ETV is the difference between the computed total variation and this minimum possible variation:\n        $$\n        \\mathrm{ETV}(g) = \\left( \\sum_{i=0}^{M-2} \\left| g(x_{i+1}) - g(x_i) \\right| \\right) - \\left| g(x_{M-1}) - g(x_0) \\right|\n        $$\n        A lower ETV indicates better suppression of oscillations and a more monotonic profile, which is desirable for representing physical fronts.\n\n    b.  **Relative Discrete $L^2$ Error**: This metric measures the loss of accuracy due to both truncation and filtering. It is defined as the root-mean-square error between the approximation $g(x)$ and the true function $f(x)$, normalized by the root-mean-square value of $f(x)$ itself:\n        $$\n        \\varepsilon(g) = \\frac{\\left( \\frac{1}{M}\\sum_{i=0}^{M-1} \\left(g(x_i)-f(x_i)\\right)^2 \\right)^{1/2}}{\\left( \\frac{1}{M}\\sum_{i=0}^{M-1} f(x_i)^2 \\right)^{1/2}}\n        $$\n    The unfiltered approximation $u_N(x)$ generally has a lower $L^2$ error but higher ETV. The filtering aims to significantly reduce ETV at the cost of a modest increase in $\\varepsilon$. The parameter $\\alpha$ controls this trade-off: a larger $\\alpha$ leads to stronger filtering, more oscillation suppression (lower ETV), but greater loss of accuracy (higher $\\varepsilon$).\n\nThe provided Python code implements this entire procedure, iterating through the specified test cases to compute and report the four required quantities $[\\mathrm{ETV}(u_N), \\mathrm{ETV}(\\tilde{u}_N), \\varepsilon(u_N), \\varepsilon(\\tilde{u}_N)]$ for each parameter set.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.fft import dct\nfrom numpy.polynomial.chebyshev import chebval\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        # Case A (general): N=128, alpha=36.0, s=40.0, x_0=0.2.\n        (128, 36.0, 40.0, 0.2),\n        # Case B (weak filter): N=128, alpha=4.0, s=40.0, x_0=0.2.\n        (128, 4.0, 40.0, 0.2),\n        # Case C (strong filter): N=128, alpha=72.0, s=40.0, x_0=0.2.\n        (128, 72.0, 40.0, 0.2),\n        # Case D (coarser resolution, sharper front): N=64, alpha=36.0, s=80.0, x_0=0.2.\n        (64, 36.0, 80.0, 0.2),\n    ]\n\n    results = []\n    for case in test_cases:\n        result_case = analyze_approximation(*case)\n        results.append(result_case)\n\n    # Final print statement in the exact required format.\n    # Convert each sublist to its string representation and join with commas.\n    # Then enclose the whole thing in square brackets.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef analyze_approximation(N, alpha, s, x0):\n    \"\"\"\n    Performs the Chebyshev approximation, filtering, and analysis for one case.\n\n    Args:\n        N (int): Degree of the Chebyshev expansion.\n        alpha (float): Strength of the exponential filter.\n        s (float): Sharpness parameter of the tanh front.\n        x0 (float): Location of the tanh front.\n\n    Returns:\n        list: A list of four floats: [ETV(u_N), ETV(u_N_tilde), ε(u_N), ε(u_N_tilde)].\n    \"\"\"\n    M = 2001  # Number of points for evaluation grid\n    p = 8     # Order of the exponential filter\n\n    # 1. Define grids\n    # Chebyshev-Lobatto nodes for coefficient computation\n    j_nodes = np.arange(N + 1)\n    x_nodes = np.cos(np.pi * j_nodes / N)\n\n    # Uniform grid for evaluation\n    x_eval = np.linspace(-1.0, 1.0, M)\n\n    # 2. Define and sample the target function\n    def target_function(x, s_param, x0_param):\n        return 0.5 * (1.0 + np.tanh(s_param * (x - x0_param)))\n\n    v_nodal_values = target_function(x_nodes, s, x0)\n    f_eval_values = target_function(x_eval, s, x0)\n\n    # 3. Compute Chebyshev coefficients using DCT-I\n    # C_k = dct(v, type=1)\n    C_k = dct(v_nodal_values, type=1)\n    \n    # Normalization factors for coefficients of sum_k a_k T_k(x)\n    c_bar = np.ones(N + 1)\n    c_bar[0] = 2.0\n    c_bar[N] = 2.0\n    \n    a_k = C_k / (N * c_bar)\n\n    # 4. Define and apply the 8th-order exponential filter\n    k_vals = np.arange(N + 1)\n    sigma_k = np.exp(-alpha * (k_vals / N)**p)\n    a_k_tilde = sigma_k * a_k\n\n    # 5. Evaluate unfiltered and filtered approximations on the uniform grid\n    u_N_eval = chebval(x_eval, a_k)\n    u_N_tilde_eval = chebval(x_eval, a_k_tilde)\n\n    # 6. Quantify oscillation and accuracy\n    # Excess Total Variation (ETV)\n    def calculate_etv(g_vals):\n        total_var = np.sum(np.abs(np.diff(g_vals)))\n        monotonic_var = np.abs(g_vals[-1] - g_vals[0])\n        return total_var - monotonic_var\n\n    etv_uN = calculate_etv(u_N_eval)\n    etv_uN_tilde = calculate_etv(u_N_tilde_eval)\n\n    # Relative discrete L2 error\n    def calculate_rel_l2_error(g_vals, f_true_vals):\n        l2_error_numerator = np.sqrt(np.mean((g_vals - f_true_vals)**2))\n        l2_norm_denominator = np.sqrt(np.mean(f_true_vals**2))\n        # Handle case where denominator is zero to avoid division by zero.\n        if l2_norm_denominator == 0.0:\n            return 0.0 if l2_error_numerator == 0.0 else np.inf\n        return l2_error_numerator / l2_norm_denominator\n\n    eps_uN = calculate_rel_l2_error(u_N_eval, f_eval_values)\n    eps_uN_tilde = calculate_rel_l2_error(u_N_tilde_eval, f_eval_values)\n    \n    return [etv_uN, etv_uN_tilde, eps_uN, eps_uN_tilde]\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3614897"}, {"introduction": "Having explored function approximation, we now apply these tools to solve a physically meaningful differential equation from geophysical fluid dynamics. This final practice guides you through implementing a Chebyshev-Galerkin method to solve the Sturm-Liouville eigenvalue problem $-\\phi'' = \\lambda N^2(z) \\phi$, which governs the vertical structure of internal waves. [@problem_id:3614944] By projecting the weak form of the equation onto a basis of functions that satisfy the boundary conditions, you will translate the continuous differential operator into a generalized matrix eigenvalue problem $A \\mathbf{c} = \\lambda B \\mathbf{c}$, a core technique in computational science.", "problem": "Consider the one-dimensional vertical mode problem for a stratified Boussinesq fluid in the hydrostatic and long-wave limits, expressed on the nondimensional vertical interval $z\\in[-1,1]$. Starting from the standard linearized hydrostatic balance and buoyancy relation, one arrives at a Sturm–Liouville eigenproblem for the vertical structure that admits a self-adjoint formulation in the form\n$$\n-\\frac{d^2 \\phi}{dz^2} \\;=\\; \\lambda\\,N^2(z)\\,\\phi(z),\\qquad z\\in(-1,1),\n$$\nwith homogeneous Dirichlet boundary conditions\n$$\n\\phi(-1)=0,\\qquad \\phi(1)=0.\n$$\nHere $N^2(z)$ is the squared buoyancy frequency profile and $\\lambda$ is the (nonnegative) eigenvalue associated with a baroclinic normal mode. In this problem, use the profile\n$$\nN^2(z)=N_0^2\\,(1+z),\n$$\nwhere $N_0>0$ is a constant. The problem is well-posed in the weighted $L^2$ inner product induced by $N^2(z)$, and the operator is self-adjoint and positive definite on the subspace of functions satisfying the boundary conditions. Angles used in any trigonometric expressions must be in radians.\n\nYour task is to implement a Chebyshev polynomial Galerkin discretization to approximate the first few eigenvalues and eigenfunctions of this problem. Proceed as follows, without using any shortcut formulas beyond the fundamental properties listed below.\n\n- Use the Chebyshev polynomials of the first kind $\\{T_n(z)\\}_{n\\ge 0}$ as the starting basis, and enforce the homogeneous Dirichlet boundary conditions by adopting the admissible trial and test basis\n$$\n\\varphi_k(z) \\;=\\; T_k(z)\\;-\\;T_{k+2}(z),\\qquad k=0,1,\\dots,M-1,\n$$\nwhich satisfies $\\varphi_k(\\pm 1)=0$ because $T_n(1)=1$ and $T_n(-1)=(-1)^n$.\n- Use the weak (variational) form derived from integration by parts with the given boundary conditions:\n$$\n\\int_{-1}^{1}\\,\\varphi_i'(z)\\,\\varphi_j'(z)\\,dz \\;=\\; \\lambda\\;\\int_{-1}^{1} N^2(z)\\,\\varphi_i(z)\\,\\varphi_j(z)\\,dz,\\qquad i,j=0,\\dots,M-1.\n$$\n- Assemble the symmetric positive definite stiffness matrix $A\\in\\mathbb{R}^{M\\times M}$ and the symmetric positive definite mass matrix $B\\in\\mathbb{R}^{M\\times M}$ with entries\n$$\nA_{ij} \\;=\\; \\int_{-1}^{1}\\,\\varphi_i'(z)\\,\\varphi_j'(z)\\,dz,\\qquad\nB_{ij} \\;=\\; \\int_{-1}^{1} N^2(z)\\,\\varphi_i(z)\\,\\varphi_j(z)\\,dz.\n$$\n- Recover the lowest eigenpairs by solving the generalized symmetric eigenvalue problem\n$$\nA\\,\\mathbf{c} \\;=\\; \\lambda\\,B\\,\\mathbf{c}.\n$$\n- Use only the following fundamental polynomial identities: $T_n(\\cos\\theta)=\\cos(n\\theta)$ and $\\dfrac{d}{dz}T_n(z) = n\\,U_{n-1}(z)$ with $U_n(\\cos\\theta)=\\dfrac{\\sin((n+1)\\theta)}{\\sin\\theta}$, where $U_n$ denotes the Chebyshev polynomial of the second kind. Angles $\\theta$ are in radians.\n\nAlgorithmic requirements:\n- For numerical integration of the bilinear forms, use any high-order accurate quadrature on $[-1,1]$ that is appropriate for smooth integrands; a suitable choice is Gauss–Legendre quadrature with $Q$ points. Ensure $Q$ is sufficiently large relative to $M$ to avoid under-integration.\n- To evaluate $T_n(z)$ and $U_n(z)$ at quadrature nodes, use the cosine and sine representations above. Avoid any divisions by zero by using quadrature nodes that do not include the endpoints.\n- Normalize eigenfunctions in any consistent manner for internal use; the final reported quantities are the eigenvalues only.\n\nTest suite:\nCompute the three smallest eigenvalues for each of the following parameter sets $(N_0,M,Q)$:\n- Case $1$: $N_0=1.0$, $M=24$, $Q=200$.\n- Case $2$: $N_0=2.0$, $M=24$, $Q=200$.\n- Case $3$: $N_0=1.0$, $M=8$, $Q=120$.\n- Case $4$: $N_0=0.5$, $M=24$, $Q=200$.\n\nOutput specification:\n- For each case, sort the computed eigenvalues in ascending order and take the first three. Round each to $8$ decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list of lists in the order of the cases above. For example, it should look like:\n$[ [\\lambda_{1}^{(1)},\\lambda_{2}^{(1)},\\lambda_{3}^{(1)}], [\\lambda_{1}^{(2)},\\lambda_{2}^{(2)},\\lambda_{3}^{(2)}], [\\lambda_{1}^{(3)},\\lambda_{2}^{(3)},\\lambda_{3}^{(3)}], [\\lambda_{1}^{(4)},\\lambda_{2}^{(4)},\\lambda_{3}^{(4)}] ]$.\nOnly print this single line; do not print any additional text.\n\nNotes:\n- The formulation above is universally applicable as a self-adjoint weighted eigenproblem. It avoids any singular coefficients at $z=-1$ by working with the equivalent self-adjoint form $-\\,\\phi''=\\lambda\\,N^2\\phi$ and Dirichlet boundary conditions, which is consistent with a Liouville transformation of the standard hydrostatic baroclinic mode equation.\n- All angles used inside trigonometric functions must be in radians.", "solution": "The problem presented is a well-posed Sturm-Liouville eigenvalue problem, which is fundamental to the study of vertical modes in stratified fluids within geophysical fluid dynamics. It is scientifically sound, self-contained, and mathematically unambiguous. Therefore, I will proceed with a complete solution.\n\nThe governing equation for the vertical structure function $\\phi(z)$ is given by\n$$\n-\\frac{d^2 \\phi}{dz^2} = \\lambda\\,N^2(z)\\,\\phi(z),\n$$\non the domain $z \\in (-1, 1)$, subject to homogeneous Dirichlet boundary conditions $\\phi(-1) = 0$ and $\\phi(1) = 0$. The squared buoyancy frequency profile is a linear function of depth, $N^2(z) = N_0^2\\,(1+z)$.\n\nWe seek to find the smallest eigenvalues $\\lambda$ using the Chebyshev-Galerkin spectral method. The core of this method is to project the problem onto a finite-dimensional function space spanned by a set of basis functions that satisfy the problem's boundary conditions.\n\nFirst, the differential equation is converted into its weak or variational form. We multiply the equation by a test function $v(z)$ from a suitable space and integrate over the domain:\n$$\n-\\int_{-1}^{1} v(z) \\frac{d^2 \\phi}{dz^2} dz = \\lambda \\int_{-1}^{1} v(z) N^2(z) \\phi(z) dz.\n$$\nApplying integration by parts to the left-hand side yields:\n$$\n\\left[ -v(z) \\frac{d\\phi}{dz} \\right]_{-1}^{1} + \\int_{-1}^{1} \\frac{dv}{dz} \\frac{d\\phi}{dz} dz = \\lambda \\int_{-1}^{1} v(z) N^2(z) \\phi(z) dz.\n$$\nIn the Galerkin method, the test functions $v(z)$ are chosen from the same space as the trial (basis) functions for the solution $\\phi(z)$. The problem specifies trial functions that satisfy the boundary conditions, so we require $v(\\pm 1) = 0$. This makes the boundary term $\\left[ -v(z) \\frac{d\\phi}{dz} \\right]_{-1}^{1}$ vanish, leading to the weak form:\n$$\n\\int_{-1}^{1} v'(z) \\phi'(z) dz = \\lambda \\int_{-1}^{1} v(z) \\phi(z) N^2(z) dz.\n$$\n\nThe solution $\\phi(z)$ is approximated by a finite expansion in terms of $M$ basis functions $\\varphi_j(z)$:\n$$\n\\phi(z) \\approx \\phi_M(z) = \\sum_{j=0}^{M-1} c_j \\varphi_j(z),\n$$\nwhere $c_j$ are unknown coefficients. The specified basis functions, constructed from Chebyshev polynomials of the first kind $T_n(z)$, are\n$$\n\\varphi_k(z) = T_k(z) - T_{k+2}(z), \\quad k=0, 1, \\dots, M-1.\n$$\nThese functions satisfy $\\varphi_k(\\pm 1) = 0$ because $T_n(1)=1$ and $T_n(-1)=(-1)^n$, ensuring that $T_k(\\pm 1) = T_{k+2}(\\pm 1)$, and thus correctly incorporating the boundary conditions into the approximation space.\n\nSubstituting the expansion for $\\phi_M(z)$ into the weak form and choosing the test functions to be the basis functions themselves, $v(z) = \\varphi_i(z)$ for $i=0, 1, \\dots, M-1$, we obtain a system of $M$ linear equations:\n$$\n\\sum_{j=0}^{M-1} c_j \\left( \\int_{-1}^{1} \\varphi_i'(z) \\varphi_j'(z) dz \\right) = \\lambda \\sum_{j=0}^{M-1} c_j \\left( \\int_{-1}^{1} N^2(z) \\varphi_i(z) \\varphi_j(z) dz \\right).\n$$\nThis system is expressed as a generalized symmetric matrix eigenvalue problem:\n$$\nA \\mathbf{c} = \\lambda B \\mathbf{c},\n$$\nwhere $\\mathbf{c} = [c_0, c_1, \\dots, c_{M-1}]^T$ is the vector of coefficients, and the stiffness matrix $A$ and mass matrix $B$ have entries:\n$$\nA_{ij} = \\int_{-1}^{1} \\varphi_i'(z) \\varphi_j'(z) dz,\n$$\n$$\nB_{ij} = \\int_{-1}^{1} N^2(z) \\varphi_i(z) \\varphi_j(z) dz = N_0^2 \\int_{-1}^{1} (1+z) \\varphi_i(z) \\varphi_j(z) dz.\n$$\n\nThe entries of these matrices are computed via numerical quadrature. We employ Gauss-Legendre quadrature with $Q$ points $\\{z_q\\}_{q=0}^{Q-1}$ and corresponding weights $\\{w_q\\}_{q=0}^{Q-1}$ on the interval $[-1, 1]$. The matrix entries are thus approximated as:\n$$\nA_{ij} \\approx \\sum_{q=0}^{Q-1} w_q \\varphi_i'(z_q) \\varphi_j'(z_q),\n$$\n$$\nB_{ij} \\approx N_0^2 \\sum_{q=0}^{Q-1} w_q (1+z_q) \\varphi_i(z_q) \\varphi_j(z_q).\n$$\n\nTo evaluate the basis functions and their derivatives at the quadrature nodes, we use the specified trigonometric identities. With the substitution $z = \\cos\\theta$, we have $\\theta = \\arccos(z)$. The quadrature nodes $z_q$ are strictly within $(-1, 1)$, so $\\theta_q = \\arccos(z_q)$ is well-defined in $(0, \\pi)$.\nThe basis functions are evaluated using $T_n(\\cos\\theta) = \\cos(n\\theta)$:\n$$\n\\varphi_k(z_q) = T_k(\\cos\\theta_q) - T_{k+2}(\\cos\\theta_q) = \\cos(k\\theta_q) - \\cos((k+2)\\theta_q).\n$$\nThe derivatives are found using $\\frac{d}{dz}T_n(z) = n U_{n-1}(z)$ and $U_n(\\cos\\theta) = \\frac{\\sin((n+1)\\theta)}{\\sin\\theta}$:\n$$\n\\varphi_k'(z) = k U_{k-1}(z) - (k+2) U_{k+1}(z).\n$$\nEvaluated at the nodes $z_q=\\cos\\theta_q$, this becomes:\n$$\n\\varphi_k'(z_q) = k \\frac{\\sin(k\\theta_q)}{\\sin\\theta_q} - (k+2) \\frac{\\sin((k+2)\\theta_q)}{\\sin\\theta_q}.\n$$\nThe denominator $\\sin\\theta_q$ is non-zero as $\\theta_q \\in (0, \\pi)$.\n\nWith the matrices $A$ and $B$ assembled, the generalized eigenvalue problem $A \\mathbf{c} = \\lambda B \\mathbf{c}$ is solved numerically. Since $A$ and $B$ are symmetric and positive definite, specialized and stable algorithms are available. The resulting eigenvalues $\\lambda$ are approximations to the true eigenvalues of the continuous problem. We sort these in ascending order and select the smallest three as required.\n\nIt is worth noting the role of the constant $N_0$. The mass matrix $B$ is proportional to $N_0^2$. The eigenvalues $\\lambda$ are therefore inversely proportional to $N_0^2$. This means that if we compute the eigenvalues $\\lambda_{N_0=1}$ for $N_0=1.0$, the eigenvalues for any other $N_0$ are given by $\\lambda_{N_0} = \\lambda_{N_0=1} / N_0^2$. This physical scaling provides a valuable consistency check for the numerical results.\n\nThe implementation proceeds by first calculating Gauss-Legendre quadrature nodes and weights. Then, for a given $M$, the values of all basis functions and their derivatives are evaluated at these nodes and stored. These are used to assemble matrices $A$ and $B$ efficiently using vectorized operations. Finally, a generalized eigensolver from a standard scientific library (e.g., SciPy) is used to compute the eigenvalues. This process is repeated for each test case specified in the problem statement.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import eigh\n\ndef solve():\n    \"\"\"\n    Main function to solve the eigenvalue problem for the given test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N0, M, Q)\n        (1.0, 24, 200),\n        (2.0, 24, 200),\n        (1.0, 8, 120),\n        (0.5, 24, 200),\n    ]\n\n    all_results = []\n    for N0, M, Q in test_cases:\n        eigenvalues = compute_eigenvalues(N0, M, Q)\n        # Select the three smallest eigenvalues and round them.\n        smallest_three = np.round(eigenvalues[:3], 8).tolist()\n        all_results.append(smallest_three)\n\n    # Final print statement in the exact required format.\n    # The default string representation of a list of lists adds spaces inside inner lists,\n    # which matches the problem's symbolic example. The join operation specified in the\n    # template code produces a slightly different whitespace pattern. We construct the\n    # string carefully to match the template's specified join logic.\n    inner_list_strings = [str(res) for res in all_results]\n    print(f\"[{','.join(inner_list_strings)}]\")\n\n\ndef compute_eigenvalues(N0, M, Q):\n    \"\"\"\n    Computes the eigenvalues for a single case (N0, M, Q).\n    \n    Args:\n        N0 (float): Buoyancy frequency constant.\n        M (int): Number of basis functions (size of discretization).\n        Q (int): Number of Gauss-Legendre quadrature points.\n\n    Returns:\n        np.ndarray: An array of computed eigenvalues, sorted in ascending order.\n    \"\"\"\n    # Step 1: Get Gauss-Legendre quadrature nodes and weights for the interval [-1, 1].\n    z_nodes, w_weights = np.polynomial.legendre.leggauss(Q)\n\n    # Step 2: Evaluate basis functions phi_k and their derivatives dphi_k/dz at the nodes.\n    phi_vals, dphi_vals = evaluate_basis_functions(M, z_nodes)\n\n    # Step 3: Assemble the stiffness (A) and mass (B) matrices.\n    # A_ij = integral(phi'_i * phi'_j, dz)\n    # B_ij = integral(N^2 * phi_i * phi_j, dz)\n    \n    # Efficient assembly using vectorized operations.\n    # This is equivalent to dphi_vals @ np.diag(w_weights) @ dphi_vals.T\n    A = dphi_vals @ (dphi_vals * w_weights).T\n\n    # Buoyancy frequency squared N^2(z) = N0^2 * (1 + z) evaluated at nodes.\n    N2_on_nodes = N0**2 * (1 + z_nodes)\n    \n    # This is equivalent to phi_vals @ np.diag(w_weights * N2_on_nodes) @ phi_vals.T\n    B = phi_vals @ (phi_vals * (w_weights * N2_on_nodes)).T\n\n    # Step 4: Solve the generalized symmetric eigenvalue problem A c = lambda B c.\n    # eigh returns eigenvalues in ascending order, which is what we need.\n    eigenvalues = eigh(A, B, eigvals_only=True)\n    \n    return eigenvalues\n\n\ndef evaluate_basis_functions(M, z_nodes):\n    \"\"\"\n    Evaluates Chebyshev-based trial functions and their derivatives at quadrature nodes.\n    The basis functions are phi_k(z) = T_k(z) - T_{k+2}(z).\n    \n    Args:\n        M (int): Number of basis functions.\n        z_nodes (np.ndarray): Quadrature nodes in [-1, 1].\n\n    Returns:\n        tuple[np.ndarray, np.ndarray]: \n            - phi_vals (M x Q): Values of basis functions at nodes.\n            - dphi_vals (M x Q): Values of basis function derivatives at nodes.\n    \"\"\"\n    Q = len(z_nodes)\n    \n    # Use the transformation z = cos(theta)\n    # Note: z_nodes from leggauss are in (-1, 1), so arccos is well-defined in (0, pi).\n    theta_nodes = np.arccos(z_nodes)\n    sin_theta = np.sin(theta_nodes) # This will not be zero.\n    \n    # Array of basis indices: k = 0, 1, ..., M-1\n    k = np.arange(M).reshape(-1, 1)\n\n    # Evaluate phi_k(z) = T_k(z) - T_{k+2}(z) using T_n(cos(theta)) = cos(n*theta).\n    # Broadcasting k (M,1) with theta_nodes (Q,) -> (M,Q)\n    T_k = np.cos(k * theta_nodes)\n    T_k_plus_2 = np.cos((k + 2) * theta_nodes)\n    phi_vals = T_k - T_k_plus_2\n    \n    # Evaluate d(phi_k)/dz = k*U_{k-1}(z) - (k+2)*U_{k+1}(z)\n    # using U_{n-1}(cos(theta)) = sin(n*theta)/sin(theta).\n    \n    # Term 1: k*U_{k-1}(z) -> k*sin(k*theta)/sin(theta)\n    # For k=0, the numerator is sin(0)=0, so the term is 0, which is correct.\n    dphi_term1 = k * np.sin(k * theta_nodes) / sin_theta\n    \n    # Term 2: (k+2)*U_{k+1}(z) -> (k+2)*sin((k+2)*theta)/sin(theta)\n    dphi_term2 = (k + 2) * np.sin((k + 2) * theta_nodes) / sin_theta\n    \n    dphi_vals = dphi_term1 - dphi_term2\n    \n    return phi_vals, dphi_vals\n\n# The entry point of the script.\nif __name__ == \"__main__\":\n    solve()\n\n```", "id": "3614944"}]}