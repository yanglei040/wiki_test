## Introduction
Seismic inversion, particularly Full Waveform Inversion (FWI), is a cornerstone of modern geophysical exploration, but its application is often limited by the immense computational cost and acquisition time associated with traditional, sequential-source surveys. Source encoding strategies offer a powerful solution to this bottleneck by enabling the simultaneous firing of multiple sources, drastically accelerating [data acquisition](@entry_id:273490). However, this efficiency introduces a new challenge: separating the blended wavefields and mitigating the resulting '[crosstalk](@entry_id:136295)' interference. This article provides a rigorous exploration of how these challenges are overcome, establishing a comprehensive understanding of [source encoding](@entry_id:755072) from first principles to advanced applications.

In the following chapters, you will delve into the core tenets of this methodology. The first chapter, **Principles and Mechanisms**, lays the theoretical groundwork, explaining how the [principle of superposition](@entry_id:148082) and statistical frameworks allow for the separation of blended signals and the formulation of unbiased gradient estimators for inversion. The second chapter, **Applications and Interdisciplinary Connections**, broadens this perspective, showcasing how encoding paradigms are applied to complex physical models and how they draw upon powerful concepts from compressed sensing, optimization, and statistics. Finally, the **Hands-On Practices** section provides an opportunity to solidify this knowledge by tackling concrete problems in code design and analysis. Together, these sections will equip you with the expertise to design, analyze, and leverage [source encoding](@entry_id:755072) for state-of-the-art [seismic inversion](@entry_id:161114).

## Principles and Mechanisms

The efficacy of [source encoding](@entry_id:755072) in [seismic inversion](@entry_id:161114) is not fortuitous; it is rooted in fundamental physical and mathematical principles. This chapter delineates these principles, starting from the linear nature of [wave propagation](@entry_id:144063) that permits source superposition, to the statistical mechanisms that enable the separation of blended signals, and culminating in advanced frameworks for analysis and optimization. By dissecting the core mechanics, we establish a rigorous foundation for understanding, designing, and applying [source encoding](@entry_id:755072) strategies.

### The Superposition Principle in Seismic Forward Modeling

The fundamental prerequisite for any simultaneous-source method is the **[principle of superposition](@entry_id:148082)**. In the context of seismic acquisition, this principle asserts that the wavefield generated by multiple sources firing simultaneously is simply the sum of the wavefields that would have been generated by each source firing individually. To formalize this, we consider the abstract representation of seismic [forward modeling](@entry_id:749528).

Let the Earth's subsurface be described by a set of model parameters, denoted by the vector $m$. For a given source signature $s$, the resulting seismic wavefield $u$ is governed by a [partial differential equation](@entry_id:141332) (PDE), which can be written in operator form as:
$$
A(m)u = s
$$
Here, $A(m)$ is a [linear differential operator](@entry_id:174781) (e.g., the acoustic or elastic wave operator) that depends on the model parameters $m$. The data recorded at the receivers, $d$, is obtained by applying a linear sampling operator $R$ to the wavefield. The entire [forward modeling](@entry_id:749528) process, from source to data, can be expressed by a single linear operator $L(m)$:
$$
d = R u = R \left( A(m)^{-1} s \right) \equiv L(m)s
$$
The operator $A(m)^{-1}$ represents the Green's function or propagator for the medium. Crucially, while the relationship between the model $m$ and the data $d$ is highly non-linear, the relationship between the source $s$ and the data $d$ is linear for a fixed model $m$. This is because $A(m)$ is a linear operator with respect to the wavefield $u$, and consequently, its inverse $A(m)^{-1}$ and the composite operator $L(m)$ are linear with respect to the [source term](@entry_id:269111).

This linearity is the key that unlocks [source encoding](@entry_id:755072). If we consider two sources, $s_1$ and $s_2$, fired simultaneously, the combined source is $s = s_1 + s_2$. The resulting data $d$ is:
$$
d = L(m)(s_1 + s_2) = L(m)s_1 + L(m)s_2
$$
If we define $d_1 = L(m)s_1$ and $d_2 = L(m)s_2$ as the data from the individual sources, then the data from the simultaneous shot is simply $d = d_1 + d_2$. This demonstrates that the recorded data from a blended source experiment is the linear superposition of the data from each constituent source.

For this elegant superposition to hold in practice, several assumptions must be satisfied [@problem_id:3614683]:
1.  **Linear Wave Physics**: The governing PDE must be linear in the wavefield $u$. This is an excellent approximation for small-strain [seismic waves](@entry_id:164985), as described by linear acoustic or elastic theory.
2.  **Linear Acquisition System**: The entire measurement chain, from the geophones or hydrophones to the recording instruments, must exhibit a linear response. Phenomena such as sensor saturation, signal clipping, or non-linear amplification would violate this assumption.
3.  **Linear Source Superposition**: The physical act of firing multiple sources must not involve non-linear interactions. If sources are placed too closely, for instance, their interaction with the near-surface [geology](@entry_id:142210) might not be a simple sum, altering the effective combined source wavelet.

It is vital to recognize that this principle does not require any linearization with respect to the model parameters $m$, such as the Born approximation. Nor does it require the neglect of multiply scattered waves. The operator $L(m)$ represents the full, non-linear forward model, including all primaries and multiples. The linearity is exclusively with respect to the [source term](@entry_id:269111).

### A Framework for Categorizing Encoding Strategies

With the principle of superposition established, we can introduce a more detailed framework to classify the diverse array of encoding strategies. A discrete forward model can be factorized to distinguish the stages of source injection, propagation, and receiver sampling [@problem_id:3614622]:
$$
d = L(m)s = R G(m) P s
$$
Here, $s \in \mathbb{C}^{n_s}$ is a vector of abstract source coefficients, $P$ is the **source injection operator** that maps these coefficients to a physical [source term](@entry_id:269111) in spacetime, $G(m)$ is the **propagation operator** (Green's function) that maps the source term to the full wavefield, and $R$ is the **receiver sampling operator** that produces the discrete data vector $d$. Different encoding strategies can be understood by which component of this chain they modify.

*   **Encoding via Source Coefficients ($s$)**: This is the most common and flexible form of encoding. It involves designing the coefficient vector $s$ that weights a fixed basis of physical sources. Examples include:
    *   **Amplitude Encoding**: Applying random amplitude weights to each source, which corresponds to choosing the elements of $s$.
    *   **Time-Shift Encoding**: Introducing a per-source time delay $\tau_j$ is equivalent to multiplying the frequency-domain coefficient $s_j(\omega)$ by a phase factor $\exp(-i\omega\tau_j)$. This is a modification of the complex-valued vector $s(\omega)$.
    *   **Source Muting**: Randomly turning sources off is equivalent to setting the corresponding elements of $s$ to zero.

*   **Encoding via the Injection Operator ($P$)**: This involves changing the fundamental basis of the physical sources themselves. For example, changing the [radiation pattern](@entry_id:261777) of a source from a monopole to a dipole alters its spatial signature. This constitutes a change in the operator $P$, and therefore in the overall forward operator $L(m)$.

This framework clarifies that most encoding schemes operate "on the right" of the model operator, by manipulating the source vector $s$. This is computationally advantageous, as it does not require re-computing the (potentially large) [matrix operators](@entry_id:269557).

### The Statistical Mechanism: Separating Signal from Crosstalk

While sources can be linearly superposed, the resulting data is a complex blend of individual responses. The challenge is to either separate these responses ([deblending](@entry_id:748252)) or to use the blended data in a way that is statistically equivalent to using unblended data. The key lies in designing the encoding such that the "crosstalk"—the interference from other sources—has statistical properties that allow it to be suppressed.

#### Decoding and Code Correlation

One way to conceptualize the separation process is through **[matched filtering](@entry_id:144625)**. Consider an experiment where each source's unencoded data would be $f_i(t)$, and each is encoded by convolution with a code sequence $c_i(t)$. The blended data is $d(t) = \sum_{i} (f_i * c_i)(t)$. To estimate the data for a specific source $j$, we can correlate the blended data with the code $c_j(t)$. This matched-filter estimate, $\hat{d}_j(t)$, can be derived as [@problem_id:3614632]:
$$
\hat{d}_{j}(t) = \sum_{i=1}^{N_{s}} (f_i * r_{ji})(t)
$$
where $r_{ji}(t)$ is the time-domain cross-correlation between codes $c_j$ and $c_i$. If the codes are designed such that their cross-correlations are highly localized at zero lag, we can approximate $r_{ji}(\tau) \approx \langle c_j, c_i \rangle \delta(\tau)$, where $\langle \cdot, \cdot \rangle$ is the zero-lag inner product. The estimate then simplifies to:
$$
\hat{d}_{j}(t) \approx \langle c_{j},c_{j}\rangle f_{j}(t) + \sum_{i \neq j} \langle c_{i},c_{j}\rangle f_{i}(t)
$$
This expression beautifully decomposes the estimate into two parts: the desired signal $f_j(t)$, scaled by its code's energy, and the **residual [crosstalk](@entry_id:136295)**, which is a linear combination of all other source responses, weighted by their code cross-correlations. This immediately reveals the goal of code design: to make the cross-correlations $\langle c_i, c_j \rangle$ for $i \neq j$ as small as possible, ideally zero (orthogonality), to eliminate crosstalk.

#### The Power Spectrum of Blended Data

Another way to see the statistical separation is by analyzing the [power spectrum](@entry_id:159996) of the blended signal. Consider an encoding scheme using random, independent time shifts $\tau_i$ drawn uniformly from an interval $[0, T]$. The Fourier transform of the blended signal is $Y(\omega) = S(\omega) \sum_i \exp(-i\omega\tau_i)$, where $S(\omega)$ is the Fourier transform of the base source wavelet. The expected [power spectrum](@entry_id:159996), $\mathbb{E}[|Y(\omega)|^2]$, can be shown to be [@problem_id:3614627]:
$$
\mathbb{E}[|Y(\omega)|^2] = |S(\omega)|^2 \left( N_s + N_s(N_s-1) \frac{4\sin^2(\frac{\omega T}{2})}{\omega^2 T^2} \right)
$$
This result is highly instructive. The first term, $N_s |S(\omega)|^2$, represents the incoherent sum of power from all $N_s$ sources. This is the "signal" component. The second term, involving the [sinc-squared function](@entry_id:270853), represents the expected contribution from coherent interference, or crosstalk. As the time-shift range $T$ increases, this term decays, meaning the crosstalk is "smeared out" and becomes less significant at any given frequency. Random encoding, therefore, acts to transform structured coherent interference into more benign, broadband noise.

### Impact on Inversion: The Encoded Gradient Estimator

The primary motivation for [source encoding](@entry_id:755072) in FWI is the acceleration of gradient computations. In a standard approach, one gradient evaluation requires $N_s$ forward simulations and $N_s$ adjoint simulations. With [source encoding](@entry_id:755072), we aim to approximate the full gradient using only a single encoded forward simulation and a single encoded adjoint simulation.

Let the true gradient of a [least-squares](@entry_id:173916) [misfit functional](@entry_id:752011) be $g = \sum_{i=1}^{S} J_i^{\top} r_i$, where $r_i$ is the residual for source $i$ and $J_i$ is its corresponding Jacobian. In an encoded scheme, we form an encoded residual $\tilde{r} = \sum_{j} c_j r_j$ and an encoded Jacobian $\tilde{J} = \sum_{i} c_i J_i$, where $c_i$ are random codes. The encoded gradient estimator is then $\tilde{g} = \tilde{J}^{\top} \tilde{r}$.

#### Bias-Variance Analysis

A critical question is how this estimator $\tilde{g}$ relates to the true gradient $g$. This is answered through a bias-variance analysis. Let the codes $\{c_i\}$ be independent, identically distributed random variables with [zero mean](@entry_id:271600) ($\mathbb{E}[c_i]=0$) and unit variance ($\mathbb{E}[c_i^2]=1$).

First, we compute the expectation of the estimator [@problem_id:3614648]:
$$
\mathbb{E}[\tilde{g}] = \mathbb{E}\left[ \left(\sum_i c_i J_i\right)^{\top} \left(\sum_j c_j r_j\right) \right] = \sum_{i,j} \mathbb{E}[c_i c_j] J_i^{\top} r_j
$$
Since $\mathbb{E}[c_i c_j] = \delta_{ij}$ (the Kronecker delta), the off-diagonal terms ($i \neq j$) vanish in expectation:
$$
\mathbb{E}[\tilde{g}] = \sum_{i} J_i^{\top} r_i = g
$$
This is a powerful result: the encoded gradient estimator is **unbiased**. On average, it yields the exact true gradient. This property holds for a wide variety of zero-mean random encodings, including Rademacher (sign-flipping) codes and complex phase codes [@problem_id:3614656] [@problem_id:3614640].

However, any single realization of $\tilde{g}$ is not equal to $g$. The difference is the encoding noise, whose magnitude is quantified by the variance, $\operatorname{Var}[\tilde{g}] = \mathbb{E}[\tilde{g} \tilde{g}^{\top}] - g g^{\top}$. The derivation shows that the variance is non-zero and is composed of sums of cross-terms of the form $J_i^{\top} r_j$ and $J_j^{\top} r_i$ for $i \neq j$ [@problem_id:3614648]. This variance represents the "[crosstalk](@entry_id:136295) artifacts" in the gradient. While a single encoded gradient is noisy, these artifacts have [zero mean](@entry_id:271600) and can be averaged out over multiple iterations of a [stochastic optimization](@entry_id:178938) algorithm or by using multiple encoded shots per gradient evaluation.

### Advanced Frameworks and Applications

Building on these core principles, we can explore more advanced perspectives and practical applications of [source encoding](@entry_id:755072).

#### The Compressed Sensing Perspective

An alternative and powerful framework for analyzing source separation is **compressed sensing (CS)**. This framework is particularly relevant when the goal is to recover the complete set of individual shot records from a smaller number of encoded measurements. If the underlying data has a [sparse representation](@entry_id:755123) (e.g., in the shot domain, if only a few sources are active), CS theory provides guarantees for perfect recovery.

In this view, the [deblending](@entry_id:748252) problem is cast as $d = A x$, where $x$ is a sparse vector of shot coefficients and $A$ is the sensing matrix whose columns are the encoded responses of each possible shot. A key property of the sensing matrix is its **[mutual coherence](@entry_id:188177)** [@problem_id:3614700]:
$$
\mu(A) = \max_{i \neq j} \frac{|\langle a_i, a_j \rangle|}{\|a_i\|_2 \|a_j\|_2}
$$
This measures the maximum similarity between any two distinct columns. A fundamental result in CS states that if the number of active shots $s$ satisfies
$$
s  \frac{1}{2}\left(1 + \frac{1}{\mu(A)}\right)
$$
then the sparse vector $x$ can be perfectly recovered from the blended data $d$ via convex $\ell_1$-norm minimization. The role of random [source encoding](@entry_id:755072) in this context is precisely to design a sensing matrix $A$ with low [mutual coherence](@entry_id:188177), thereby allowing for the recovery of a larger number of simultaneous shots.

#### Preconditioning in Multi-Parameter Inversion

Source encoding also interacts with the challenges of multi-parameter FWI, such as the trade-offs between velocity ($v$) and density ($\rho$). The Gauss-Newton Hessian for a multi-parameter problem is a [block matrix](@entry_id:148435), and its off-diagonal blocks (e.g., $H_{v\rho}$) represent parameter [crosstalk](@entry_id:136295).

When using [source encoding](@entry_id:755072), the instantaneous Gauss-Newton Hessian, $H^e$, contains crosstalk from both parameter coupling *and* [source encoding](@entry_id:755072). However, as we have seen, the expectation of the encoded Hessian eliminates the source [crosstalk](@entry_id:136295), recovering the true Hessian: $\mathbb{E}[H^e] = H^{\text{true}}$. This insight allows for the design of sophisticated preconditioners. By computing the expected diagonal blocks, $\mathbb{E}[H_{vv}^e] = \sum_k J_{v,k}^\top W J_{v,k}$ and $\mathbb{E}[H_{\rho\rho}^e] = \sum_k J_{\rho,k}^\top W J_{\rho,k}$, we can form a [block-diagonal preconditioner](@entry_id:746868) [@problem_id:3614624]:
$$
P = \begin{pmatrix} (\mathbb{E}[H_{vv}^e] + \lambda I)^{-1}  0 \\ 0  (\mathbb{E}[H_{\rho\rho}^e] + \lambda I)^{-1} \end{pmatrix}
$$
This [preconditioner](@entry_id:137537) approximates the inverse of the true Hessian's diagonal, effectively addressing the velocity-density coupling while leveraging the [statistical power](@entry_id:197129) of [source encoding](@entry_id:755072) to make its construction computationally feasible.

#### Optimal Experimental Design

A practical question arises: given a fixed computational budget, what is the optimal number of sources to blend in a single simulation? Blending more sources ($N_s$) reduces the number of simulations required but increases the variance of the resulting gradient estimator. This suggests a trade-off.

Let's model the cost of a single encoded simulation as $C(N_s) = c_0 + c_1 N_s$, where $c_0$ is the fixed cost of a wave-equation solve and $c_1$ is the per-source overhead. Let the variance of the single-batch estimator be $V_{\text{batch}}(N_s) = a/N_s + b$, where $a$ captures variance that averages down and $b$ captures crosstalk variance. For a fixed total budget $B$, we can run $K = B/C(N_s)$ batches. The total variance of the final averaged gradient is $V_{\text{total}} = V_{\text{batch}}/K$. Minimizing this total variance with respect to $N_s$ yields an optimal number of simultaneous sources [@problem_id:3614639]:
$$
N_s^{\text{opt}} = \sqrt{\frac{ac_0}{bc_1}}
$$
This result provides a clear, quantitative guideline for experimental design. The optimal blending factor is not infinite; it is a balance between the costs ($c_0, c_1$) and the statistical properties of the noise ($a, b$). This highlights a mature stage of [source encoding](@entry_id:755072), moving from proof-of-concept to a quantitatively optimized methodology.