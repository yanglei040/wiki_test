{"hands_on_practices": [{"introduction": "The one-dimensional discrete Laplacian is the canonical matrix in the numerical analysis of partial differential equations, serving as a fundamental building block for more complex problems. A deep understanding of its spectral properties is essential for analyzing the stability, convergence, and efficiency of numerical schemes. This practice guides you through the explicit derivation of the eigenvalues and eigenvectors of this matrix, revealing their elegant connection to the discrete sine functions of Fourier analysis and providing a powerful tool for its diagonalization [@problem_id:3416297].", "problem": "Consider a uniform grid on the open interval $(0,1)$ with $N$ interior points located at $x_{j} = j h$ for $j \\in \\{1,2,\\dots,N\\}$ and $h = \\frac{1}{N+1}$. Impose homogeneous Dirichlet boundary conditions so that a grid function $v = (v_{1},\\dots,v_{N})^{\\top} \\in \\mathbb{R}^{N}$ satisfies $v_{0} = 0$ and $v_{N+1} = 0$ at the endpoints. Define the one-dimensional Dirichlet discrete Laplacian $A \\in \\mathbb{R}^{N \\times N}$ by its action\n$$\n(A v)_{j} = 2 v_{j} - v_{j-1} - v_{j+1}, \\quad j \\in \\{1,2,\\dots,N\\},\n$$\nwith the convention $v_{0} = 0$ and $v_{N+1} = 0$. Equivalently, $A$ is the symmetric tridiagonal Toeplitz matrix with $A_{j j} = 2$ and $A_{j, j\\pm 1} = -1$. This is the unscaled matrix representation of the centered second-order finite difference approximation of the negative second derivative with Dirichlet boundary conditions, factored by $h^{2}$ for simplicity.\n\nStarting from the fundamental definitions of eigenvalues and eigenvectors, and the finite difference model above, perform the following steps:\n\n1. Derive the eigenpairs $(\\lambda_{k}, v^{(k)})$ of $A$ by solving $A v = \\lambda v$. Use only the recurrence relations implied by the tridiagonal structure and the boundary conditions to determine the admissible discrete modes and the corresponding eigenvalues. Show that the eigenvectors are discrete sine modes and identify the allowed wavenumbers. Normalize the eigenvectors to form an orthonormal family.\n\n2. Assemble the orthonormal eigenvectors into a matrix $Q \\in \\mathbb{R}^{N \\times N}$ and form the diagonal matrix $\\Lambda = \\operatorname{diag}(\\lambda_{1},\\dots,\\lambda_{N})$. Using the properties of a symmetric matrix and orthonormal eigenvectors, use them to diagonalize $A$ explicitly as $A = Q \\Lambda Q^{\\top}$. Relate $Q$ to the Discrete Sine Transform (DST) by writing down its entries.\n\n3. Using the diagonalization and appropriate product identities for trigonometric functions, evaluate the exact determinant $\\det(A)$ as a closed-form analytic expression in terms of $N$.\n\nProvide the final answer as a single closed-form analytic expression for $\\det(A)$, with no units. Do not round; an exact expression is required.", "solution": "The problem requires the derivation of the eigenpairs of the discrete Laplacian matrix $A$, its diagonalization, and the subsequent calculation of its determinant. We will proceed by solving the recurrence relation that arises from the eigenvalue problem.\n\nThe matrix $A \\in \\mathbb{R}^{N \\times N}$ is defined by its action on a vector $v \\in \\mathbb{R}^{N}$ as $(A v)_{j} = 2 v_{j} - v_{j-1} - v_{j+1}$ for $j=1, \\dots, N$, with the boundary conditions $v_{0}=0$ and $v_{N+1}=0$.\n\n**1. Derivation of Eigenpairs $(\\lambda_{k}, v^{(k)})$}\n\nThe eigenvalue problem is $A v = \\lambda v$. For each component $j$, this translates to:\n$$\n2 v_{j} - v_{j-1} - v_{j+1} = \\lambda v_{j}\n$$\nRearranging the terms, we obtain a second-order linear homogeneous recurrence relation for the components $v_j$ of an eigenvector $v$:\n$$\nv_{j+1} - (2 - \\lambda) v_{j} + v_{j-1} = 0, \\quad \\text{for } j=1, \\dots, N\n$$\nwith boundary conditions $v_0 = 0$ and $v_{N+1} = 0$.\n\nWe seek a solution of the form $v_j = r^j$. Substituting this into the recurrence relation gives the characteristic equation:\n$$\nr^2 - (2-\\lambda)r + 1 = 0\n$$\nThe roots are given by the quadratic formula: $r_{1,2} = \\frac{(2-\\lambda) \\pm \\sqrt{(2-\\lambda)^2 - 4}}{2}$.\nSince $A$ is a real symmetric matrix, its eigenvalues $\\lambda$ must be real. We can analyze the nature of the roots based on the discriminant $\\Delta = (2-\\lambda)^2 - 4$.\nIf $\\Delta \\geq 0$, the roots $r_1, r_2$ are real. The general solution is $v_j = c_1 r_1^j + c_2 r_2^j$. The condition $v_0=0$ implies $c_1+c_2=0$, so $v_j = c_1(r_1^j - r_2^j)$. The condition $v_{N+1}=0$ implies $c_1(r_1^{N+1} - r_2^{N+1})=0$. Since $r_1r_2=1$, and for $\\Delta>0$ we have $|r_1| \\neq |r_2|$, this would lead to $c_1=0$, giving the trivial solution $v=0$. For $\\Delta=0$, $\\lambda=0$ or $\\lambda=4$, and $r_1=r_2=\\pm 1$, which also leads to the trivial solution under the given boundary conditions.\n\nThus, we must have $\\Delta  0$, which means $(2-\\lambda)^2  4$, or $0  \\lambda  4$. In this case, the roots are a complex conjugate pair. Let's define an angle $\\theta$ such that $2-\\lambda = 2\\cos(\\theta)$. This is always possible for $0  \\lambda  4$. The roots become:\n$$\nr_{1,2} = \\cos(\\theta) \\pm i \\sin(\\theta) = e^{\\pm i\\theta}\n$$\nThe general solution for $v_j$ is a linear combination of $(e^{i\\theta})^j$ and $(e^{-i\\theta})^j$:\n$$\nv_j = c_1 e^{ij\\theta} + c_2 e^{-ij\\theta}\n$$\nApplying the first boundary condition, $v_0 = 0$:\n$$\nv_0 = c_1 e^0 + c_2 e^0 = c_1 + c_2 = 0 \\implies c_2 = -c_1\n$$\nThis simplifies the solution to:\n$$\nv_j = c_1(e^{ij\\theta} - e^{-ij\\theta}) = 2i c_1 \\sin(j\\theta)\n$$\nThis demonstrates that the eigenvectors are discrete sine modes. Let $C = 2i c_1$ be an arbitrary constant. Then $v_j = C \\sin(j\\theta)$.\n\nNow, we apply the second boundary condition, $v_{N+1}=0$:\n$$\nv_{N+1} = C \\sin((N+1)\\theta) = 0\n$$\nFor a non-trivial eigenvector, we require $C \\neq 0$, which implies $\\sin((N+1)\\theta) = 0$. This condition quantizes the possible values of $\\theta$:\n$$\n(N+1)\\theta = k\\pi \\implies \\theta_k = \\frac{k\\pi}{N+1}\n$$\nfor some integer $k$. The values $k=1, 2, \\dots, N$ produce distinct, non-trivial eigenvectors. For $k=0$ or $k=N+1$, $\\sin(j\\theta_k)=0$ for all $j$, yielding the zero vector. Other integer values of $k$ produce eigenvectors that are either identical or scalar multiples of the eigenvectors for $k \\in \\{1, \\dots, N\\}$. Thus, we have $N$ distinct eigenvectors corresponding to $k=1, 2, \\dots, N$.\n\nThe eigenvalues $\\lambda_k$ are determined by the corresponding $\\theta_k$:\n$$\n\\lambda_k = 2 - 2\\cos(\\theta_k) = 2 - 2\\cos\\left(\\frac{k\\pi}{N+1}\\right)\n$$\nUsing the half-angle identity $1-\\cos(x) = 2\\sin^2(x/2)$, we get:\n$$\n\\lambda_k = 4\\sin^2\\left(\\frac{k\\pi}{2(N+1)}\\right), \\quad k=1, 2, \\dots, N\n$$\nThe components of the corresponding unnormalized eigenvector $v^{(k)}$ are:\n$$\nv_j^{(k)} = \\sin\\left(j\\theta_k\\right) = \\sin\\left(\\frac{jk\\pi}{N+1}\\right), \\quad j=1, 2, \\dots, N\n$$\n\nTo normalize these eigenvectors, we require their Euclidean norm to be $1$. We compute the squared norm:\n$$\n\\sum_{j=1}^{N} \\left(v_j^{(k)}\\right)^2 = \\sum_{j=1}^{N} \\sin^2\\left(\\frac{jk\\pi}{N+1}\\right)\n$$\nUsing the identity $\\sin^2(x) = \\frac{1}{2}(1-\\cos(2x))$, the sum becomes:\n$$\n\\sum_{j=1}^{N} \\frac{1}{2}\\left(1 - \\cos\\left(\\frac{2jk\\pi}{N+1}\\right)\\right) = \\frac{N}{2} - \\frac{1}{2} \\sum_{j=1}^{N} \\cos\\left(\\frac{2jk\\pi}{N+1}\\right)\n$$\nThe sum of cosines can be evaluated by considering the geometric series of complex exponentials $\\sum_{j=1}^{N} z^j$ with $z = \\exp\\left(i \\frac{2k\\pi}{N+1}\\right)$. Since $k \\in \\{1, \\dots, N\\}$, $z \\neq 1$. The sum is $\\sum_{j=1}^{N} z^j = z \\frac{1-z^N}{1-z}$. As $z^{N+1}=1$, we have $z^N = z^{-1}$. The sum is $z \\frac{1-z^{-1}}{1-z} = \\frac{z-1}{1-z}=-1$.\nThus, $\\sum_{j=1}^{N} \\cos\\left(\\frac{2jk\\pi}{N+1}\\right) = \\operatorname{Re}(-1) = -1$.\nThe squared norm is therefore $\\frac{N}{2} - \\frac{1}{2}(-1) = \\frac{N+1}{2}$.\nThe normalization constant is $\\sqrt{\\frac{2}{N+1}}$. The components of the orthonormal eigenvectors $v^{(k)}$ are:\n$$\nv_j^{(k)} = \\sqrt{\\frac{2}{N+1}} \\sin\\left(\\frac{jk\\pi}{N+1}\\right), \\quad j,k = 1, \\dots, N\n$$\n\n**2. Diagonalization of $A$**\n\nWe assemble the orthonormal eigenvectors $v^{(k)}$ as columns of a matrix $Q \\in \\mathbb{R}^{N \\times N}$:\n$$\nQ_{jk} = (v^{(k)})_j = \\sqrt{\\frac{2}{N+1}} \\sin\\left(\\frac{jk\\pi}{N+1}\\right)\n$$\nThe matrix of eigenvalues $\\Lambda$ is the diagonal matrix $\\Lambda = \\operatorname{diag}(\\lambda_1, \\dots, \\lambda_N)$, where\n$$\n\\Lambda_{kk} = \\lambda_k = 4\\sin^2\\left(\\frac{k\\pi}{2(N+1)}\\right)\n$$\nThe set of eigenvalue equations $A v^{(k)} = \\lambda_k v^{(k)}$ for $k=1, \\dots, N$ can be written in matrix form as $A Q = Q \\Lambda$.\nSince $A$ is a real symmetric matrix, its eigenvectors form an orthonormal basis. The matrix $Q$ whose columns are these orthonormal eigenvectors is therefore an orthogonal matrix, satisfying $Q^{\\top}Q = I$, which implies $Q^{-1}=Q^{\\top}$.\nMultiplying $A Q = Q \\Lambda$ on the right by $Q^{\\top}$, we get $A Q Q^{\\top} = Q \\Lambda Q^{\\top}$, which simplifies to $A = Q \\Lambda Q^{\\top}$. This is the spectral decomposition (diagonalization) of $A$.\n\nThe entries of $Q$ are $Q_{jk} = \\sqrt{\\frac{2}{N+1}} \\sin\\left(\\frac{jk\\pi}{N+1}\\right)$. This matrix is, by definition, the matrix of the Type-I Discrete Sine Transform (DST-I). The scaling factor ensures the transform is orthogonal (involutary). Note that $Q$ is a symmetric matrix, i.e., $Q = Q^{\\top}$.\n\n**3. Evaluation of $\\det(A)$**\n\nUsing the property $\\det(XY) = \\det(X)\\det(Y)$ and $\\det(X^{\\top}) = \\det(X)$, we can compute the determinant of $A$ from its diagonalization:\n$$\n\\det(A) = \\det(Q \\Lambda Q^{\\top}) = \\det(Q) \\det(\\Lambda) \\det(Q^{\\top}) = \\det(\\Lambda) (\\det(Q))^2\n$$\nSince $Q$ is orthogonal, $Q Q^{\\top}=I$, so $\\det(Q Q^{\\top})=\\det(Q)\\det(Q^{\\top})=(\\det(Q))^2 = \\det(I)=1$.\nTherefore, $\\det(A) = \\det(\\Lambda)$.\nThe determinant of the diagonal matrix $\\Lambda$ is the product of its diagonal entries:\n$$\n\\det(A) = \\prod_{k=1}^{N} \\lambda_k = \\prod_{k=1}^{N} 4\\sin^2\\left(\\frac{k\\pi}{2(N+1)}\\right)\n$$\nWe can factor out the $4$'s:\n$$\n\\det(A) = 4^N \\left( \\prod_{k=1}^{N} \\sin\\left(\\frac{k\\pi}{2(N+1)}\\right) \\right)^2\n$$\nTo evaluate the product of sines, we use the well-known identity:\n$$\n\\prod_{k=1}^{m-1} \\sin\\left(\\frac{k\\pi}{m}\\right) = \\frac{m}{2^{m-1}}\n$$\nLet's set $m = 2(N+1)$. The argument of the sines in our product is $\\frac{k\\pi}{m}$. Let $P = \\prod_{k=1}^{N} \\sin\\left(\\frac{k\\pi}{m}\\right)$. The identity involves a product up to $m-1 = 2N+1$. We relate our product to the identity:\n$$\n\\frac{m}{2^{m-1}} = \\prod_{k=1}^{2N+1} \\sin\\left(\\frac{k\\pi}{m}\\right) = \\left(\\prod_{k=1}^{N} \\sin\\left(\\frac{k\\pi}{m}\\right)\\right) \\cdot \\sin\\left(\\frac{(N+1)\\pi}{m}\\right) \\cdot \\left(\\prod_{k=N+2}^{2N+1} \\sin\\left(\\frac{k\\pi}{m}\\right)\\right)\n$$\nThe middle term is $\\sin\\left(\\frac{(N+1)\\pi}{2(N+1)}\\right) = \\sin(\\pi/2) = 1$.\nFor the last term, we use the identity $\\sin(\\pi-x)=\\sin(x)$. Let $j=m-k$. As $k$ runs from $N+2$ to $2N+1$, $j$ runs from $N$ down to $1$.\n$$\n\\sin\\left(\\frac{k\\pi}{m}\\right) = \\sin\\left(\\frac{(m-j)\\pi}{m}\\right) = \\sin\\left(\\pi - \\frac{j\\pi}{m}\\right) = \\sin\\left(\\frac{j\\pi}{m}\\right)\n$$\nThus, the last product is equal to the first: $\\prod_{k=N+2}^{2N+1} \\sin\\left(\\frac{k\\pi}{m}\\right) = P$.\nWe have $\\frac{m}{2^{m-1}} = P \\cdot 1 \\cdot P = P^2$.\nSubstituting $m=2(N+1)$:\n$$\nP^2 = \\frac{2(N+1)}{2^{2(N+1)-1}} = \\frac{2(N+1)}{2^{2N+1}} = \\frac{N+1}{2^{2N}}\n$$\nFinally, we substitute this back into the expression for the determinant:\n$$\n\\det(A) = 4^N \\cdot P^2 = (2^2)^N \\cdot \\frac{N+1}{2^{2N}} = 2^{2N} \\frac{N+1}{2^{2N}} = N+1\n$$\nThe determinant of the $N \\times N$ discrete Laplacian matrix is simply $N+1$.", "answer": "$$\\boxed{N+1}$$", "id": "3416297"}, {"introduction": "The theoretical elegance of the Finite Element Method (FEM) relies on the precise translation of a continuous variational problem into a discrete linear system that preserves its core properties, such as symmetry and positive-definiteness. In practice, however, approximations made during the assembly process, often called \"variational crimes,\" can compromise these properties. This exercise explores the consequences of using an inconsistent quadrature rule to assemble the stiffness matrix, providing a concrete example of how a seemingly minor implementation shortcut can break the symmetry of the underlying bilinear form and lead to a non-symmetric system [@problem_id:3416264].", "problem": "Consider the scalar diffusion problem on the interval $\\Omega = (0,1)$ with homogeneous Dirichlet boundary conditions: find $u \\in H_{0}^{1}(\\Omega)$ such that\n$$\n- \\frac{d}{dx}\\!\\left(\\beta(x)\\, \\frac{du}{dx}\\right) = f(x) \\quad \\text{in } \\Omega, \\quad u(0)=u(1)=0,\n$$\nwhere the diffusion coefficient is $\\beta(x) = 1 + \\rho\\, x$ with a fixed parameter $\\rho  0$. The variational formulation is: find $u \\in H_{0}^{1}(\\Omega)$ such that for all $v \\in H_{0}^{1}(\\Omega)$,\n$$\na(u,v) := \\int_{0}^{1} \\beta(x)\\, u'(x)\\, v'(x)\\, dx = \\ell(v),\n$$\nwith a given linear functional $\\ell$.\n\nDiscretize this variational problem with continuous, piecewise affine (linear) finite elements (FE) on the uniform mesh with nodes $x_{0}=0$, $x_{1}=\\frac{1}{3}$, $x_{2}=\\frac{2}{3}$, $x_{3}=1$. Impose the boundary conditions strongly, so the global system involves the two interior basis functions $\\{\\varphi_{1},\\varphi_{2}\\}$. With exact integration of $a(\\cdot,\\cdot)$, the stiffness matrix is symmetric positive definite.\n\nNow modify the assembly by injecting an inconsistent quadrature that breaks symmetry in the following precise way: for each pair of indices $(i,j)$ corresponding to the test function $\\varphi_{i}$ and the trial function $\\varphi_{j}$, approximate the elementwise integral by evaluating the coefficient at the test-function node and keeping the exact derivative-product integral. Concretely, define the assembled matrix entries by\n$$\nK_{ij} := \\sum_{K} \\beta(x_{i}) \\int_{K} \\varphi_{i}'(x)\\, \\varphi_{j}'(x)\\, dx,\n$$\nwhere the sum is over the two elements $K=[x_{0},x_{1}] \\cup [x_{1},x_{2}]$ that contribute to row $i=1$ and over $K=[x_{1},x_{2}] \\cup [x_{2},x_{3}]$ that contribute to row $i=2$, as dictated by FE support.\n\nStarting from first principles of the Galerkin method and FE basis functions:\n\n- Derive the exact (symmetric) stiffness matrix for $\\beta \\equiv 1$ on this mesh.\n- Show that, under the above inconsistent quadrature, the resulting matrix takes the form $K(\\rho) = D(\\rho)\\, S$, where $S$ is the exact stiffness matrix for $\\beta \\equiv 1$ and $D(\\rho)$ is a positive diagonal matrix depending on $\\rho$.\n- Explain algebraically why this left scaling by $D(\\rho)$ destroys symmetry and, hence, the symmetric positive definite (SPD) structure, even though each factor is positive definite in the appropriate sense.\n\nFinally, compute in closed form the smallest eigenvalue $\\lambda_{\\min}(\\rho)$ of the $2 \\times 2$ matrix $K(\\rho)$ as a function of $\\rho$. Provide your answer as a single analytic expression in $\\rho$ with no units. Do not approximate or round the result.", "solution": "We begin from the variational formulation $a(u,v) = \\int_{0}^{1} \\beta(x)\\, u'(x)\\, v'(x)\\, dx$ and the standard Galerkin discretization with continuous, piecewise affine finite element (FE) basis functions $\\{\\varphi_{i}\\}$ associated with the interior nodes $x_{1}=\\frac{1}{3}$ and $x_{2}=\\frac{2}{3}$. The mesh is uniform with spacing $h = \\frac{1}{3}$, and there are three elements: $[x_{0},x_{1}]$, $[x_{1},x_{2}]$, $[x_{2},x_{3}]$.\n\nFundamental facts for one-dimensional linear FE on a uniform mesh:\n\n- On an element $K=[x_{k},x_{k+1}]$ of length $h$, the local stiffness for the model coefficient $\\beta \\equiv 1$ is the $2 \\times 2$ matrix\n$$\n\\frac{1}{h} \\begin{pmatrix} 1  -1 \\\\ -1  1 \\end{pmatrix},\n$$\narising from the exact integral $\\int_{K} \\varphi_{k}' \\varphi_{k}'\\, dx = \\frac{1}{h}$, $\\int_{K} \\varphi_{k}' \\varphi_{k+1}'\\, dx = -\\frac{1}{h}$, and symmetry.\n\n- After assembling on the three-element mesh and imposing Dirichlet boundary conditions at $x_{0}$ and $x_{3}$, the global stiffness for $\\beta \\equiv 1$ in the interior degrees of freedom $(\\varphi_{1},\\varphi_{2})$ is\n$$\nS \\;=\\; \\frac{1}{h} \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix}\n\\;=\\; 3 \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix}\n\\;=\\; \\begin{pmatrix} 6  -3 \\\\ -3  6 \\end{pmatrix}.\n$$\nThis matrix $S$ is symmetric positive definite (SPD), as expected from the exact Galerkin method for a symmetric coercive bilinear form.\n\nNext, we incorporate the variable coefficient $\\beta(x) = 1 + \\rho x$ and define the inconsistent quadrature. For each row index $i \\in \\{1,2\\}$, corresponding to the test function $\\varphi_{i}$ supported on two neighboring elements, we approximate the elementwise contribution by pulling $\\beta$ out of the integral and evaluating it at the test-function node $x_{i}$:\n$$\nK_{ij} := \\sum_{K \\subset \\operatorname{supp}(\\varphi_{i})} \\beta(x_{i}) \\int_{K} \\varphi_{i}'(x)\\, \\varphi_{j}'(x)\\, dx.\n$$\nSince $\\beta(x_{i})$ is constant with respect to the element integral and does not depend on $K$, we can factor it out of the sum over the two elements touching node $i$:\n$$\nK_{ij} = \\beta(x_{i}) \\sum_{K \\subset \\operatorname{supp}(\\varphi_{i})} \\int_{K} \\varphi_{i}'(x)\\, \\varphi_{j}'(x)\\, dx.\n$$\nBut the sum over the two elements of the exact derivative-product integrals is precisely the corresponding entry of the global stiffness matrix for the constant coefficient problem $\\beta \\equiv 1$. Therefore,\n$$\nK_{ij} = \\beta(x_{i})\\, S_{ij}.\n$$\nIn matrix form, with the row index determining the multiplier, this reads\n$$\nK(\\rho) \\;=\\; D(\\rho)\\, S, \\quad \\text{where} \\quad D(\\rho) = \\operatorname{diag}\\big(\\beta(x_{1}),\\, \\beta(x_{2})\\big).\n$$\n\nWe now identify the diagonal entries of $D(\\rho)$. With $x_{1}=\\frac{1}{3}$ and $x_{2}=\\frac{2}{3}$, we have\n$$\n\\beta(x_{1}) = 1 + \\rho\\, \\frac{1}{3} =: a, \\qquad \\beta(x_{2}) = 1 + \\rho\\, \\frac{2}{3} =: b.\n$$\nThus\n$$\nD(\\rho) = \\begin{pmatrix} a  0 \\\\ 0  b \\end{pmatrix}, \\qquad S = \\begin{pmatrix} 6  -3 \\\\ -3  6 \\end{pmatrix}, \\qquad K(\\rho) = \\begin{pmatrix} 6a  -3a \\\\ -3b  6b \\end{pmatrix}.\n$$\n\nAlgebraic mechanism of failure of symmetry and SPD:\n\n- The exact Galerkin stiffness with exact integration for the variable coefficient is $S_{\\text{exact}}(\\rho) = \\big[\\int_{0}^{1} \\beta(x)\\, \\varphi_{i}' \\varphi_{j}'\\, dx\\big]$, which is symmetric because the integrand is symmetric in $(i,j)$. Moreover, by coercivity of $a(\\cdot,\\cdot)$, $S_{\\text{exact}}(\\rho)$ is SPD.\n\n- The inconsistent quadrature replaces the symmetric bilinear form with a Petrov-Galerkin-like left scaling $K(\\rho) = D(\\rho)\\, S$, where $S$ is SPD and $D(\\rho)$ is positive diagonal but appears only on the test side (rows). Unless $D(\\rho)$ commutes with $S$ (which it does only if $a=b$), the product $D(\\rho)\\, S$ is generally non-symmetric:\n$$\nK(\\rho)^{T} = S\\, D(\\rho) \\neq D(\\rho)\\, S = K(\\rho) \\quad \\text{if} \\quad a \\neq b.\n$$\nThus symmetry is lost because the left scaling by $D(\\rho)$ weights test functions differently from trial functions, breaking the adjointness that underpins symmetry in the Galerkin method. Although both $S$ and $D(\\rho)$ are positive definite in their respective senses, their product is not symmetric and therefore not SPD.\n\nWe now compute the eigenvalues of the $2 \\times 2$ matrix $K(\\rho) = \\begin{pmatrix} 6a  -3a \\\\ -3b  6b \\end{pmatrix}$. The characteristic polynomial is\n$$\n\\det\\!\\big(K(\\rho) - \\lambda I\\big) = \\det \\begin{pmatrix} 6a - \\lambda  -3a \\\\ -3b  6b - \\lambda \\end{pmatrix}\n= (6a - \\lambda)(6b - \\lambda) - 9ab.\n$$\nExpanding,\n$$\n(6a - \\lambda)(6b - \\lambda) - 9ab = 36ab - 6(a+b)\\lambda + \\lambda^{2} - 9ab = \\lambda^{2} - 6(a+b)\\lambda + 27ab.\n$$\nHence the eigenvalues are\n$$\n\\lambda_{\\pm}(\\rho) = \\frac{6(a+b) \\pm \\sqrt{36(a+b)^{2} - 108\\, ab}}{2}\n= 3(a+b) \\pm 3 \\sqrt{(a+b)^{2} - 3ab}.\n$$\nWe simplify the quantities $a+b$ and $(a+b)^{2} - 3ab$ using $a = 1 + \\frac{\\rho}{3}$ and $b = 1 + \\frac{2\\rho}{3}$:\n$$\na + b = \\left(1 + \\frac{\\rho}{3}\\right) + \\left(1 + \\frac{2\\rho}{3}\\right) = 2 + \\rho,\n$$\n$$\n(a+b)^{2} - 3ab = a^{2} - ab + b^{2}.\n$$\nCompute $a^{2} - ab + b^{2}$:\n$$\na^{2} = \\left(1 + \\frac{\\rho}{3}\\right)^{2} = 1 + \\frac{2\\rho}{3} + \\frac{\\rho^{2}}{9}, \\quad\nb^{2} = \\left(1 + \\frac{2\\rho}{3}\\right)^{2} = 1 + \\frac{4\\rho}{3} + \\frac{4\\rho^{2}}{9},\n$$\n$$\nab = \\left(1 + \\frac{\\rho}{3}\\right)\\left(1 + \\frac{2\\rho}{3}\\right) = 1 + \\rho + \\frac{2\\rho^{2}}{9}.\n$$\nTherefore,\n$$\na^{2} - ab + b^{2} = \\left(1 + \\frac{2\\rho}{3} + \\frac{\\rho^{2}}{9}\\right) - \\left(1 + \\rho + \\frac{2\\rho^{2}}{9}\\right) + \\left(1 + \\frac{4\\rho}{3} + \\frac{4\\rho^{2}}{9}\\right)\n= 1 + \\rho + \\frac{\\rho^{2}}{3}.\n$$\nThus the smallest eigenvalue is\n$$\n\\lambda_{\\min}(\\rho) = 3(a+b) - 3 \\sqrt{(a+b)^{2} - 3ab} = 3(2 + \\rho) - 3 \\sqrt{1 + \\rho + \\frac{\\rho^{2}}{3}}.\n$$\nEquivalently,\n$$\n\\lambda_{\\min}(\\rho) = 6 + 3\\rho - 3 \\sqrt{1 + \\rho + \\frac{\\rho^{2}}{3}}.\n$$\nThis is a closed-form analytic expression in $\\rho$. It is strictly positive for $\\rho \\geq 0$ because $K(\\rho)$, as the product of two positive definite matrices $D(\\rho)$ and $S$, is similar to the symmetric positive definite matrix $S^{1/2} D(\\rho) S^{1/2}$ via\n$$\nS^{1/2} \\, K(\\rho) \\, S^{-1/2} = S^{1/2} D(\\rho) S^{1/2},\n$$\nwhich guarantees a positive real spectrum even though $K(\\rho)$ is non-symmetric. The loss here is symmetry (and hence the SPD property), directly attributable to the inconsistent, row-weighted quadrature that breaks the symmetry of the bilinear form at the discrete level.", "answer": "$$\\boxed{6 + 3\\rho - 3\\sqrt{\\,1 + \\rho + \\frac{\\rho^{2}}{3}\\,}}$$", "id": "3416264"}, {"introduction": "A crucial link between the continuous PDE and its discrete counterpart is the preservation of qualitative properties, such as the maximum principle. Algebraically, this is often guaranteed if the stiffness matrix is a so-called $M$-matrix, a condition that depends delicately on the mesh geometry and material coefficients. This hands-on coding practice challenges you to implement a finite element assembly from first principles and investigate this connection directly, demonstrating through numerical experiments how acute-angled meshes can yield an $M$-matrix while obtuse triangles or strong anisotropy can destroy this critical property [@problem_id:3416313].", "problem": "Consider the two-dimensional scalar diffusion boundary value problem on a polygonal domain, modeled by the elliptic partial differential equation $-\\nabla \\cdot (K(x) \\nabla u(x)) = f(x)$ with homogeneous Dirichlet boundary conditions $u(x) = 0$ on the boundary, where $K(x)$ is either a scalar field or a symmetric positive definite tensor field. Use the conforming linear Lagrange finite element method on planar triangular meshes, with piecewise constant coefficients $K_T$ per triangle. Assemble the global stiffness matrix $A$ by summing element-wise bilinear forms of the type $\\int_T \\nabla \\varphi_i(x)^\\top K_T \\nabla \\varphi_j(x) \\, \\mathrm{d}x$ for each triangle $T$ and local basis functions $\\varphi_i$. Restrict attention to the submatrix $A_{\\mathcal{I}\\mathcal{I}}$ corresponding to the interior nodes $\\mathcal{I}$, defined as those mesh nodes that lie strictly inside the domain. In this setting, the property that the stiffness matrix is a so-called $M$-matrix is characterized by the following algebraic conditions: (i) $A_{\\mathcal{I}\\mathcal{I}}$ is symmetric positive definite, (ii) all off-diagonal entries of $A_{\\mathcal{I}\\mathcal{I}}$ are nonpositive, and (iii) each interior row of $A_{\\mathcal{I}\\mathcal{I}}$ is weakly diagonally dominant. This sign structure underpins a discrete maximum principle through an inverse-positivity mechanism. \n\nYour task is to implement, in a single self-contained program, the assembly of $A$ from first principles, the extraction of $A_{\\mathcal{I}\\mathcal{I}}$, and the verification of the above $M$-matrix conditions and the nonpositivity (also known as $Z$-matrix) sign pattern. You will construct three meshes and coefficient distributions to probe the relationship between mesh geometry, coefficients, and the sign pattern of $A$, including a counterexample with obtuse triangles that breaks monotonicity of the sign pattern. All numerical values are dimensionless. Angles, where relevant, are in radians.\n\nBase assumptions and definitions to be used in your derivation:\n- The conforming linear finite element space uses nodal basis functions that are affine on each triangle and globally continuous.\n- The element-level stiffness contribution is obtained via the standard Galerkin projection of the bilinear form $\\int_T \\nabla \\varphi_i(x)^\\top K_T \\nabla \\varphi_j(x) \\, \\mathrm{d}x$ onto the local basis, resulting in constant gradients of local basis functions on each triangle and a constant coefficient $K_T$ per triangle.\n- The global stiffness matrix $A$ is assembled by summing local contributions into the appropriate entries based on element connectivity, without any shortcut formula provided to you; you must derive and compute the necessary gradients and integrals explicitly.\n- Symmetric positive definiteness is to be verified numerically by checking that all eigenvalues of $A_{\\mathcal{I}\\mathcal{I}}$ are strictly positive to within a small numerical tolerance.\n- The $Z$-matrix sign pattern is to be verified by checking that all off-diagonal entries of $A_{\\mathcal{I}\\mathcal{I}}$ are nonpositive to within a small numerical tolerance.\n- Weak diagonal dominance for the interior rows is to be verified by checking $A_{ii} \\geq \\sum_{j \\neq i} |A_{ij}|$ for each $i \\in \\mathcal{I}$ to within a small numerical tolerance.\n\nConstruct the following three test cases:\n\n- Test case $1$ (acute, isotropic): Let the domain be the square $[0,1] \\times [0,1]$. Define a uniform grid of $5 \\times 5$ nodes at coordinates $(x_i, y_j)$ where $x_i = i/4$ and $y_j = j/4$ for integers $i,j \\in \\{0,1,2,3,4\\}$. Triangulate each of the $4 \\times 4$ squares by the northeast-southwest diagonal, forming two triangles per square: $(i,j)\\text{-}(i+1,j)\\text{-}(i+1,j+1)$ and $(i,j)\\text{-}(i+1,j+1)\\text{-}(i,j+1)$ in terms of grid indices. Set the scalar coefficient $K_T = \\kappa_T \\, I$ with $\\kappa_T = 1$ for all triangles.\n\n- Test case $2$ (obtuse perturbation, isotropic, heterogeneous): Start from test case $1$ but perturb the central interior node at $(0.5,0.5)$ to $(0.1,0.5)$ while keeping all other node coordinates fixed. Use the same triangulation connectivity based on the original grid indexing. Define piecewise constant scalar coefficients by $K_T = \\kappa_T \\, I$ with $\\kappa_T = 50$ on triangles that include the perturbed central node as a vertex and $\\kappa_T = 1$ otherwise.\n\n- Test case $3$ (acute, anisotropic): Use the unperturbed mesh and triangulation of test case $1$. Define a constant anisotropic symmetric positive definite coefficient tensor per triangle by $K_T = R^\\top \\operatorname{diag}(100, 1) R$, where $R$ is the rotation matrix\n$$\nR = \\begin{bmatrix}\n\\cos \\theta  -\\sin \\theta \\\\\n\\sin \\theta  \\cos \\theta\n\\end{bmatrix}\n$$\nwith $\\theta = \\pi/4$.\n\nIn all cases, define the set of interior nodes $\\mathcal{I}$ as the nodes strictly inside the square, i.e., those with coordinates $(x,y)$ satisfying $0  x  1$ and $0  y  1$. Assemble the full stiffness matrix $A$ and then extract $A_{\\mathcal{I}\\mathcal{I}}$.\n\nFor each test case, compute two boolean indicators:\n- $Z$: whether $A_{\\mathcal{I}\\mathcal{I}}$ has the $Z$-matrix sign pattern (all off-diagonals nonpositive).\n- $M$: whether $A_{\\mathcal{I}\\mathcal{I}}$ satisfies the $M$-matrix criteria (symmetric positive definite, nonpositive off-diagonals, and weak diagonal dominance of interior rows).\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order $[Z_1, M_1, Z_2, M_2, Z_3, M_3]$, where the subscript denotes the test case index. The outputs must be booleans.", "solution": "The task is to assemble the stiffness matrix for a two-dimensional scalar diffusion problem using the linear finite element method (FEM) on triangular meshes and to verify specific algebraic properties of the resulting matrix system. The properties of interest are those that characterize an $M$-matrix, which are linked to the discrete maximum principle.\n\nThe starting point is the elliptic partial differential equation on a domain $\\Omega$:\n$$-\\nabla \\cdot (K(x) \\nabla u(x)) = f(x) \\quad \\text{in } \\Omega$$\nwith homogeneous Dirichlet boundary conditions $u(x) = 0$ on $\\partial\\Omega$. Here, $u(x)$ is the scalar field, and $K(x)$ is a symmetric positive definite coefficient tensor, which is assumed to be piecewise constant on each triangle $T$ of the mesh, denoted as $K_T$.\n\nThe weak formulation of this problem leads to finding $u \\in H^1_0(\\Omega)$ such that for all $v \\in H^1_0(\\Omega)$:\n$$a(u,v) = \\int_\\Omega (\\nabla v)^\\top K (\\nabla u) \\, \\mathrm{d}x = \\int_\\Omega fv \\, \\mathrm{d}x$$\nWe discretize the space $H^1_0(\\Omega)$ using a conforming linear finite element space $V_h$. Let $\\{\\varphi_i\\}_{i \\in \\mathcal{N}}$ be the set of global nodal basis functions, where $\\mathcal{N}$ is the set of all node indices in the mesh. The approximate solution is $u_h = \\sum_{j \\in \\mathcal{N}} u_j \\varphi_j(x)$, where $u_j$ are the nodal values. The Galerkin method yields a linear system $AU = F$, where $U$ is the vector of nodal values $u_j$, and the stiffness matrix $A$ has entries $A_{ij} = a(\\varphi_j, \\varphi_i)$. Due to the homogeneous Dirichlet boundary conditions, we only solve for the nodal values at the interior nodes, indexed by the set $\\mathcal{I}$. This leads to a reduced system $A_{\\mathcal{I}\\mathcal{I}}U_{\\mathcal{I}} = F_{\\mathcal{I}}$, where $A_{\\mathcal{I}\\mathcal{I}}$ is the submatrix of $A$ corresponding to interior nodes.\n\nThe global stiffness matrix $A$ is assembled by summing up contributions from each element (triangle) $T$ in the mesh:\n$$A_{ij} = \\sum_{T} \\int_T (\\nabla \\varphi_i)^\\top K_T (\\nabla \\varphi_j) \\, \\mathrm{d}x$$\nThe integral contributes to $A_{ij}$ only if nodes $i$ and $j$ are vertices of triangle $T$. For a single triangle $T$ with vertices $p_1, p_2, p_3$, the local basis functions are affine, so their gradients are constant vectors within $T$. Let the vertices have coordinates $p_k = (x_k, y_k)$ for $k \\in \\{1,2,3\\}$. The gradient of the local basis function $\\varphi_k$ (associated with vertex $p_k$) is given by:\n$$\\nabla \\varphi_k = \\frac{1}{2|T|} \\mathbf{v}_k$$\nwhere $|T|$ is the area of the triangle and the vectors $\\mathbf{v}_k$ are determined by the vertex coordinates. Specifically:\n$$\\mathbf{v}_1 = \\begin{pmatrix} y_2 - y_3 \\\\ x_3 - x_2 \\end{pmatrix}, \\quad \\mathbf{v}_2 = \\begin{pmatrix} y_3 - y_1 \\\\ x_1 - x_3 \\end{pmatrix}, \\quad \\mathbf{v}_3 = \\begin{pmatrix} y_1 - y_2 \\\\ x_2 - x_1 \\end{pmatrix}$$\nThe area $|T|$ is calculated as $|T| = \\frac{1}{2} |x_1(y_2-y_3) + x_2(y_3-y_1) + x_3(y_1-y_2)|$.\n\nFor each triangle $T$, we compute a $3 \\times 3$ element stiffness matrix $A^T$. Since $\\nabla\\varphi_i$, $\\nabla\\varphi_j$, and $K_T$ are constant within the element, the integral simplifies to a product:\n$$A^T_{ij} = |T| (\\nabla \\varphi_i)^\\top K_T (\\nabla \\varphi_j)$$\nwhere $i,j \\in \\{1,2,3\\}$ are the local indices of the vertices. If we define a $2 \\times 3$ matrix $B_T = [\\nabla \\varphi_1, \\nabla \\varphi_2, \\nabla \\varphi_3]$, the element stiffness matrix can be expressed compactly as $A^T = |T| B_T^\\top K_T B_T$. These local entries are then added to the corresponding global positions in $A$. For a triangle with global node indices $(n_1, n_2, n_3)$, the local entry $A^T_{ij}$ is added to the global entry $A_{n_i, n_j}$.\n\nAfter assembling the global matrix $A$, we extract the submatrix $A_{\\mathcal{I}\\mathcal{I}}$ corresponding to the specified interior nodes. We then verify the following properties for $A_{\\mathcal{I}\\mathcal{I}}$ using a numerical tolerance $\\epsilon$ (e.g., $10^{-9}$):\n\n1.  **Z-matrix property**: All off-diagonal entries must be nonpositive. We check if $A_{ij} \\le \\epsilon$ for all $i \\ne j$ in the index set $\\mathcal{I}$. The boolean indicator for this is $Z$.\n\n2.  **M-matrix properties**: A matrix is an $M$-matrix if it is a Z-matrix with a positive inverse. For a symmetric matrix, this is equivalent to being a symmetric positive definite (SPD) Z-matrix. The problem adds the condition of weak diagonal dominance. Thus, we check for three conditions combined:\n    a. **Symmetric Positive Definiteness (SPD)**: We verify symmetry ($A_{\\mathcal{I}\\mathcal{I}} = A_{\\mathcal{I}\\mathcal{I}}^\\top$) and then compute the eigenvalues of $A_{\\mathcal{I}\\mathcal{I}}$. All eigenvalues must be strictly positive (greater than $\\epsilon$).\n    b. **Z-matrix property**: As defined above.\n    c. **Weak Diagonal Dominance (WDD)**: For each row $i \\in \\mathcal{I}$, we check if $A_{ii} \\ge \\sum_{j \\in \\mathcal{I}, j \\ne i} |A_{ij}|$. For a Z-matrix, where off-diagonals are nonpositive, this is equivalent to checking if the sum of each row is non-negative, $\\sum_{j \\in \\mathcal{I}} A_{ij} \\ge 0$.\n\nThe boolean indicator $M$ is true if and only if all three of these conditions (SPD, Z-matrix, and WDD) are met.\n\nThe test cases are designed to investigate the influence of mesh geometry and material coefficients on these properties.\n- **Test Case 1**: An isotropic coefficient ($K_T=I$) on a uniform mesh of acute right-angled triangles. This is the ideal case, where the Z-matrix and M-matrix properties are expected to hold.\n- **Test Case 2**: A node is perturbed, introducing obtuse angles into the mesh. This is a classic counterexample. The entry $A^T_{ij}$ is related to $-\\cot\\gamma_{ij}$ where $\\gamma_{ij}$ is the angle opposite the edge $(i, j)$. If an angle is obtuse, the cotangent is negative, leading to a positive off-diagonal contribution $A^T_{ij} > 0$. This can break the Z-matrix property for the global matrix $A_{\\mathcal{I}\\mathcal{I}}$.\n- **Test Case 3**: A strong, constant anisotropy is introduced on the acute mesh. The condition for non-positive off-diagonals becomes $(\\nabla \\varphi_i)^\\top K_T (\\nabla \\varphi_j) \\le 0$. If the directions of high conductivity in $K_T$ are not aligned with the mesh, this condition can be violated even on a geometrically acute mesh, leading to a loss of the Z-matrix property.\n\nThe implementation will proceed by generating the mesh data for each case, assembling the matrix $A$ from first principles as derived above, extracting $A_{\\mathcal{I}\\mathcal{I}}$, and then programmatically checking the $Z$- and $M$-matrix conditions to produce the required boolean flags.\n```python\nimport numpy as np\n\ndef evaluate_case(nodes, triangles, K_func, interior_node_indices, tol=1e-9):\n    \"\"\"\n    Assembles the FEM stiffness matrix and evaluates its properties.\n\n    Args:\n        nodes (np.ndarray): Array of node coordinates, shape (num_nodes, 2).\n        triangles (list[tuple]): List of triangles, each a tuple of 3 node indices.\n        K_func (callable): Function that takes triangle nodes and returns the 2x2 K_T matrix.\n        interior_node_indices (list[int]): List of indices for interior nodes.\n        tol (float): Numerical tolerance for comparisons.\n\n    Returns:\n        tuple[bool, bool]: A tuple (is_Z, is_M) indicating Z-matrix and M-matrix properties.\n    \"\"\"\n    num_nodes = nodes.shape[0]\n    A = np.zeros((num_nodes, num_nodes))\n\n    for tri_indices in triangles:\n        # 1. Get vertex coordinates\n        p1, p2, p3 = nodes[tri_indices[0]], nodes[tri_indices[1]], nodes[tri_indices[2]]\n\n        # 2. Calculate triangle area and basis function gradients\n        # The element stiffness matrix is invariant to vertex ordering, but its\n        # derivation is cleaner if we use the absolute area.\n        matrix_for_area = np.array([\n            [p2[0] - p1[0], p2[1] - p1[1]],\n            [p3[0] - p1[0], p3[1] - p1[1]]\n        ])\n        area = 0.5 * np.abs(np.linalg.det(matrix_for_area))\n\n        if area  1e-12:  # Skip degenerate triangles\n            continue\n\n        # Gradients of local basis functions (phi_1, phi_2, phi_3)\n        # grad(phi_k) = (1 / 2*|T|) * [y_next - y_prev, x_prev - x_next]\n        grad_phi = (1.0 / (2.0 * area)) * np.array([\n            [p2[1] - p3[1], p3[1] - p1[1], p1[1] - p2[1]],  # dy components\n            [p3[0] - p2[0], p1[0] - p3[0], p2[0] - p1[0]]   # dx components\n        ])\n\n        # 3. Get coefficient K_T for the current triangle\n        K_T = K_func(tri_indices)\n\n        # 4. Compute the 3x3 element stiffness matrix A_T\n        A_T = area * grad_phi.T @ K_T @ grad_phi\n\n        # 5. Assemble A_T into the global stiffness matrix A\n        for i in range(3):\n            for j in range(3):\n                A[tri_indices[i], tri_indices[j]] += A_T[i, j]\n\n    # Extract the submatrix corresponding to interior nodes\n    A_II = A[np.ix_(interior_node_indices, interior_node_indices)]\n\n    # --- Verify Matrix Properties ---\n\n    # 1. Z-matrix property: all off-diagonal entries are non-positive\n    off_diagonal_mask = ~np.eye(A_II.shape[0], dtype=bool)\n    is_Z = np.all(A_II[off_diagonal_mask] = tol)\n\n    # 2. M-matrix properties: is a Z-matrix, SPD, and WDD.\n    is_M = False\n    if is_Z:\n        # Check for Symmetric Positive Definiteness (SPD)\n        is_symmetric = np.allclose(A_II, A_II.T, atol=tol)\n        is_spd = False\n        if is_symmetric:\n            try:\n                eigenvalues = np.linalg.eigvalsh(A_II)\n                is_spd = np.all(eigenvalues > tol)\n            except np.linalg.LinAlgError:\n                is_spd = False\n        \n        if is_spd:\n            # Check for Weak Diagonal Dominance (WDD)\n            # For a Z-matrix, WDD is equivalent to non-negative row sums.\n            row_sums = np.sum(A_II, axis=1)\n            is_wdd = np.all(row_sums >= -tol)\n            \n            if is_wdd:\n                is_M = True # Only if Z, SPD, and WDD all hold\n\n    return is_Z, is_M\n\ndef solve():\n    \"\"\"\n    Sets up and runs the three test cases, then prints the results.\n    \"\"\"\n    N = 5\n    num_nodes = N * N\n    \n    # Identify interior node indices (nodes not on the boundary 0 or 1)\n    interior_node_indices = []\n    for j in range(1, N - 1):\n        for i in range(1, N - 1):\n            interior_node_indices.append(j * N + i)\n\n    # Define triangulation based on a uniform grid\n    # Each square is split by the NE-SW diagonal\n    triangles = []\n    for j in range(N - 1):\n        for i in range(N - 1):\n            p_bl = j * N + i        # Bottom-left\n            p_br = j * N + i + 1    # Bottom-right\n            p_tl = (j + 1) * N + i    # Top-left\n            p_tr = (j + 1) * N + i + 1# Top-right\n            triangles.append((p_bl, p_br, p_tr))\n            triangles.append((p_bl, p_tr, p_tl))\n    \n    results = []\n\n    # --- Test Case 1: Acute, Isotropic ---\n    nodes1 = np.array([[i / (N - 1), j / (N - 1)] for j in range(N) for i in range(N)])\n    def K_func1(tri_indices):\n        return np.identity(2)\n    \n    Z1, M1 = evaluate_case(nodes1, triangles, K_func1, interior_node_indices)\n    results.extend([Z1, M1])\n\n    # --- Test Case 2: Obtuse, Isotropic, Heterogeneous ---\n    nodes2 = np.copy(nodes1)\n    perturbed_node_idx = (N // 2) * N + (N // 2)  # Central node (2,2) -> index 12\n    nodes2[perturbed_node_idx] = [0.1, 0.5]\n    \n    def K_func2(tri_indices):\n        if perturbed_node_idx in tri_indices:\n            return 50.0 * np.identity(2)\n        return np.identity(2)\n\n    Z2, M2 = evaluate_case(nodes2, triangles, K_func2, interior_node_indices)\n    results.extend([Z2, M2])\n\n    # --- Test Case 3: Acute, Anisotropic ---\n    nodes3 = nodes1 # Unperturbed mesh\n    theta = np.pi / 4.0\n    c, s = np.cos(theta), np.sin(theta)\n    R = np.array([[c, -s], [s, c]])\n    D = np.diag([100.0, 1.0])\n    K_aniso = R.T @ D @ R\n\n    def K_func3(tri_indices):\n        return K_aniso\n\n    Z3, M3 = evaluate_case(nodes3, triangles, K_func3, interior_node_indices)\n    results.extend([Z3, M3])\n\n    # Print results in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\n# This part would be executed to generate the answer\n# solve()\n```", "answer": "[True,True,False,False,False,False]", "id": "3416313"}]}