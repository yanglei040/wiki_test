{"hands_on_practices": [{"introduction": "Mastering the theory of Sobolev spaces begins with a firm grasp of their fundamental building blocks: the norms and seminorms. This first practice provides a direct, hands-on opportunity to move beyond abstract definitions. By computing the $H^1$ norm and seminorm for a simple trigonometric function, you will solidify your understanding of how these measures quantify both the magnitude and the oscillatory behavior of a function. [@problem_id:3397294]", "problem": "Consider the Sobolev space $H^{1}(0,1)$ associated with the interval $(0,1)$, arising in the weak formulation of linear elliptic partial differential equations (PDEs). Let $u(x)=\\sin(\\pi x)$ for $x\\in(0,1)$. Using only the foundational definitions of the Lebesgue space $L^{2}(0,1)$ norm, the weak derivative, the $H^{1}(0,1)$ seminorm, and the $H^{1}(0,1)$ norm, compute the $H^{1}(0,1)$ seminorm and the $H^{1}(0,1)$ norm of $u$. Then compare their magnitudes by forming the ratio of the seminorm to the norm. Report your result as the row vector $\\big(|u|_{H^{1}(0,1)},\\ \\|u\\|_{H^{1}(0,1)},\\ |u|_{H^{1}(0,1)}/\\|u\\|_{H^{1}(0,1)}\\big)$. Express your answer in exact analytic form with no rounding.", "solution": "The problem is well-posed, scientifically grounded, and provides all necessary information for a unique solution. The concepts involved—Sobolev spaces, norms, and weak derivatives—are standard in the mathematical analysis of partial differential equations. We may therefore proceed with the solution.\n\nThe problem asks for the computation of the $H^{1}(0,1)$ seminorm, the $H^{1}(0,1)$ norm, and their ratio for the function $u(x) = \\sin(\\pi x)$ on the domain $\\Omega = (0,1)$. We will proceed by using the foundational definitions as stipulated.\n\nFirst, let us recall the definitions. The Sobolev space $H^{1}(\\Omega)$ is the space of functions $v$ in the Lebesgue space $L^{2}(\\Omega)$ whose weak first derivatives are also in $L^{2}(\\Omega)$. For our one-dimensional domain $\\Omega=(0,1)$, this is written as $H^{1}(0,1) = \\{v \\in L^{2}(0,1) \\mid v' \\in L^{2}(0,1)\\}$.\n\nThe $L^{2}(0,1)$ norm of a function $v$ is defined as:\n$$ \\|v\\|_{L^{2}(0,1)} = \\left( \\int_{0}^{1} |v(x)|^{2} \\,dx \\right)^{1/2} $$\n\nThe weak derivative $v'$ of a function $v \\in L^{2}(0,1)$ is a function that satisfies the relation:\n$$ \\int_{0}^{1} v'(x) \\phi(x) \\,dx = - \\int_{0}^{1} v(x) \\phi'(x) \\,dx $$\nfor all test functions $\\phi \\in C_{c}^{\\infty}(0,1)$ (infinitely differentiable functions with compact support in $(0,1)$).\nFor the given function $u(x) = \\sin(\\pi x)$, which is continuously differentiable on the entire real line, its weak derivative coincides with its classical derivative. The classical derivative is $u'(x) = \\pi \\cos(\\pi x)$. Since both $u(x)$ and $u'(x)$ are continuous and bounded functions on the closed interval $[0,1]$, they are square-integrable, i.e., $u \\in L^{2}(0,1)$ and $u' \\in L^{2}(0,1)$. Therefore, $u(x) = \\sin(\\pi x)$ is an element of the Sobolev space $H^{1}(0,1)$.\n\nThe $H^{1}(0,1)$ seminorm, denoted $|v|_{H^{1}(0,1)}$, is the $L^{2}$ norm of the weak derivative:\n$$ |v|_{H^{1}(0,1)} = \\|v'\\|_{L^{2}(0,1)} = \\left( \\int_{0}^{1} |v'(x)|^{2} \\,dx \\right)^{1/2} $$\nThe $H^{1}(0,1)$ norm, denoted $\\|v\\|_{H^{1}(0,1)}$, is defined by:\n$$ \\|v\\|_{H^{1}(0,1)} = \\left( \\|v\\|_{L^{2}(0,1)}^{2} + |v|_{H^{1}(0,1)}^{2} \\right)^{1/2} = \\left( \\int_{0}^{1} |v(x)|^{2} \\,dx + \\int_{0}^{1} |v'(x)|^{2} \\,dx \\right)^{1/2} $$\n\nNow, we compute these quantities for $u(x) = \\sin(\\pi x)$.\n\nFirst, we compute the squared $L^{2}$ norm of $u(x)$:\n$$ \\|u\\|_{L^{2}(0,1)}^{2} = \\int_{0}^{1} (\\sin(\\pi x))^{2} \\,dx $$\nUsing the trigonometric identity $\\sin^{2}(\\theta) = \\frac{1 - \\cos(2\\theta)}{2}$, we get:\n$$ \\|u\\|_{L^{2}(0,1)}^{2} = \\int_{0}^{1} \\frac{1 - \\cos(2\\pi x)}{2} \\,dx = \\frac{1}{2} \\left[ x - \\frac{\\sin(2\\pi x)}{2\\pi} \\right]_{0}^{1} $$\n$$ = \\frac{1}{2} \\left( \\left(1 - \\frac{\\sin(2\\pi)}{2\\pi}\\right) - \\left(0 - \\frac{\\sin(0)}{2\\pi}\\right) \\right) = \\frac{1}{2} ( (1 - 0) - (0 - 0) ) = \\frac{1}{2} $$\n\nNext, we compute the squared $H^{1}$ seminorm, which is the squared $L^{2}$ norm of the derivative $u'(x) = \\pi \\cos(\\pi x)$:\n$$ |u|_{H^{1}(0,1)}^{2} = \\|u'\\|_{L^{2}(0,1)}^{2} = \\int_{0}^{1} (\\pi \\cos(\\pi x))^{2} \\,dx = \\pi^{2} \\int_{0}^{1} \\cos^{2}(\\pi x) \\,dx $$\nUsing the trigonometric identity $\\cos^{2}(\\theta) = \\frac{1 + \\cos(2\\theta)}{2}$, we get:\n$$ |u|_{H^{1}(0,1)}^{2} = \\pi^{2} \\int_{0}^{1} \\frac{1 + \\cos(2\\pi x)}{2} \\,dx = \\frac{\\pi^{2}}{2} \\left[ x + \\frac{\\sin(2\\pi x)}{2\\pi} \\right]_{0}^{1} $$\n$$ = \\frac{\\pi^{2}}{2} \\left( \\left(1 + \\frac{\\sin(2\\pi)}{2\\pi}\\right) - \\left(0 + \\frac{\\sin(0)}{2\\pi}\\right) \\right) = \\frac{\\pi^{2}}{2} ( (1 + 0) - (0 + 0) ) = \\frac{\\pi^{2}}{2} $$\nFrom this, we find the seminorm:\n$$ |u|_{H^{1}(0,1)} = \\sqrt{\\frac{\\pi^{2}}{2}} = \\frac{\\pi}{\\sqrt{2}} $$\n\nNow, we compute the $H^{1}$ norm. We use the squared norms we have already calculated:\n$$ \\|u\\|_{H^{1}(0,1)}^{2} = \\|u\\|_{L^{2}(0,1)}^{2} + |u|_{H^{1}(0,1)}^{2} = \\frac{1}{2} + \\frac{\\pi^{2}}{2} = \\frac{1+\\pi^{2}}{2} $$\nTaking the square root gives the norm:\n$$ \\|u\\|_{H^{1}(0,1)} = \\sqrt{\\frac{1+\\pi^{2}}{2}} = \\frac{\\sqrt{1+\\pi^{2}}}{\\sqrt{2}} $$\n\nFinally, we compute the ratio of the seminorm to the norm:\n$$ \\frac{|u|_{H^{1}(0,1)}}{\\|u\\|_{H^{1}(0,1)}} = \\frac{\\left(\\frac{\\pi}{\\sqrt{2}}\\right)}{\\left(\\frac{\\sqrt{1+\\pi^{2}}}{\\sqrt{2}}\\right)} = \\frac{\\pi}{\\sqrt{1+\\pi^{2}}} $$\n\nThe problem requests the result as the row vector $\\big(|u|_{H^{1}(0,1)}, \\|u\\|_{H^{1}(0,1)}, |u|_{H^{1}(0,1)}/\\|u\\|_{H^{1}(0,1)}\\big)$. Substituting our computed values, we get:\n$$ \\left( \\frac{\\pi}{\\sqrt{2}}, \\frac{\\sqrt{1+\\pi^{2}}}{\\sqrt{2}}, \\frac{\\pi}{\\sqrt{1+\\pi^{2}}} \\right) $$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{\\pi}{\\sqrt{2}}  \\frac{\\sqrt{1+\\pi^{2}}}{\\sqrt{2}}  \\frac{\\pi}{\\sqrt{1+\\pi^{2}}}\n\\end{pmatrix}\n}\n$$", "id": "3397294"}, {"introduction": "Beyond computing norms for a single function, a deeper understanding comes from analyzing how these norms and related constants transform across different domains. This practice introduces the powerful technique of scaling arguments, which are indispensable in the analysis of PDEs. By investigating how the famous Poincaré inequality constant changes with the size of the domain, you will learn a fundamental method for relating solutions on different geometric scales. [@problem_id:3397255]", "problem": "Let $\\Omega \\subset \\mathbb{R}^{d}$ be a bounded Lipschitz domain and let $H_{0}^{1}(\\Omega)$ denote the Sobolev space of $L^{2}$ functions with $L^{2}$ weak gradient that vanish on $\\partial \\Omega$ in the sense of traces. The Poincaré inequality on $\\Omega$ states that there exists a minimal constant $C_{P}(\\Omega) \\in (0,\\infty)$ such that for all $u \\in H_{0}^{1}(\\Omega)$ one has\n$$\n\\|u\\|_{L^{2}(\\Omega)} \\leq C_{P}(\\Omega)\\,\\|\\nabla u\\|_{L^{2}(\\Omega)}.\n$$\nFor a given $h0$, define the scaled domain $\\Omega_{h} := h\\,\\Omega = \\{x \\in \\mathbb{R}^{d} : x = h y \\text{ for some } y \\in \\Omega\\}$. Let $C_{P}(\\Omega_{h})$ denote the minimal Poincaré constant on $\\Omega_{h}$ defined analogously.\n\nUsing only the change-of-variables formula for Lebesgue integrals and the chain rule for Sobolev functions under linear changes of variables, derive the exact scaling factor $S(h,d)$ defined by\n$$\nC_{P}(\\Omega_{h}) = S(h,d)\\,C_{P}(\\Omega).\n$$\n\nYour final answer should be a closed-form expression in $h$ and $d$. No rounding is required, and no units are involved. Provide only the expression for $S(h,d)$ as your final answer.", "solution": "The problem statement is valid. It is a well-posed mathematical problem grounded in the theory of Sobolev spaces and partial differential equations. All terms are standard and precisely defined, and the task is to perform a rigorous derivation using specified mathematical tools.\n\nLet $\\Omega_{h} = h\\,\\Omega = \\{x \\in \\mathbb{R}^{d} : x = hy \\text{ for some } y \\in \\Omega\\}$ for some given constant $h0$. The Poincaré constant on the domain $\\Omega_h$, denoted $C_{P}(\\Omega_{h})$, is the smallest constant such that the following inequality holds for all functions $v \\in H_{0}^{1}(\\Omega_{h})$:\n$$\n\\|v\\|_{L^{2}(\\Omega_{h})} \\leq C_{P}(\\Omega_{h})\\,\\|\\nabla_{x} v\\|_{L^{2}(\\Omega_{h})}\n$$\nThe minimality implies that $C_{P}(\\Omega_{h})$ is given by the supremum:\n$$\nC_{P}(\\Omega_{h}) = \\sup_{v \\in H_{0}^{1}(\\Omega_{h}), v \\neq 0} \\frac{\\|v\\|_{L^{2}(\\Omega_{h})}}{\\|\\nabla_{x} v\\|_{L^{2}(\\Omega_{h})}}\n$$\nwhere $\\nabla_{x}$ denotes the gradient with respect to the variable $x \\in \\Omega_h$. Our goal is to relate this expression to $C_{P}(\\Omega)$ by using a change of variables.\n\nConsider the linear transformation $T: \\Omega \\to \\Omega_{h}$ defined by $x = T(y) = hy$. For any function $v \\in H_{0}^{1}(\\Omega_{h})$, we can define a corresponding function $u$ on the domain $\\Omega$ by the composition $u(y) = v(T(y)) = v(hy)$. The mapping from $v$ to $u$ establishes an isomorphism between the spaces $H_{0}^{1}(\\Omega_{h})$ and $H_{0}^{1}(\\Omega)$. This means that for every $v \\in H_{0}^{1}(\\Omega_{h})$ there is a unique $u \\in H_{0}^{1}(\\Omega)$ related by this transformation, and vice-versa. Therefore, taking the supremum over all non-zero $v \\in H_{0}^{1}(\\Omega_{h})$ is equivalent to taking the supremum over all non-zero $u \\in H_{0}^{1}(\\Omega)$.\n\nWe now relate the norms of $v$ on $\\Omega_{h}$ to the norms of $u$ on $\\Omega$.\n\nFirst, we analyze the $L^{2}$-norm of the function. The definition of the norm is:\n$$\n\\|v\\|_{L^{2}(\\Omega_{h})}^{2} = \\int_{\\Omega_{h}} |v(x)|^{2} dx\n$$\nWe apply the change of variables $x=hy$. The differential volume element $dx$ is related to $dy$ by the determinant of the Jacobian of the transformation. The Jacobian matrix of the transformation $x=hy$ is $J = hI_{d}$, where $I_{d}$ is the $d \\times d$ identity matrix. The determinant is $|\\det(J)|=h^{d}$. Thus, $dx = h^{d}dy$. Substituting this and $v(x) = v(hy) = u(y)$ into the integral, we get:\n$$\n\\|v\\|_{L^{2}(\\Omega_{h})}^{2} = \\int_{\\Omega} |u(y)|^{2} (h^{d} dy) = h^{d} \\int_{\\Omega} |u(y)|^{2} dy = h^{d} \\|u\\|_{L^{2}(\\Omega)}^{2}\n$$\nTaking the square root of both sides gives the relationship between the norms:\n$$\n\\|v\\|_{L^{2}(\\Omega_{h})} = h^{d/2} \\|u\\|_{L^{2}(\\Omega)}\n$$\nSecond, we analyze the $L^{2}$-norm of the gradient. The norm is defined as:\n$$\n\\|\\nabla_{x} v\\|_{L^{2}(\\Omega_{h})}^{2} = \\int_{\\Omega_{h}} |\\nabla_{x} v(x)|^{2} dx\n$$\nWe need to relate the gradient of $v$ with respect to $x$ to the gradient of $u$ with respect to $y$. Using the chain rule on $u(y) = v(hy)$:\n$$\n\\nabla_{y} u(y) = \\nabla_{y} (v(hy)) = (J)^{T} (\\nabla_{x} v)(hy) = (hI_{d})^{T} (\\nabla_{x} v)(hy) = h (\\nabla_{x} v)(hy)\n$$\nwhere $\\nabla_{y}$ is the gradient with respect to $y$. Rearranging this equation gives:\n$$\n(\\nabla_{x} v)(hy) = \\frac{1}{h} \\nabla_{y} u(y)\n$$\nNow, we substitute this and the change of variables $x=hy$ into the integral for the gradient norm:\n$$\n\\|\\nabla_{x} v\\|_{L^{2}(\\Omega_{h})}^{2} = \\int_{\\Omega} |(\\nabla_{x} v)(hy)|^{2} (h^{d} dy) = \\int_{\\Omega} \\left|\\frac{1}{h} \\nabla_{y} u(y)\\right|^{2} h^{d} dy\n$$\n$$\n\\|\\nabla_{x} v\\|_{L^{2}(\\Omega_{h})}^{2} = \\frac{1}{h^{2}} \\int_{\\Omega} |\\nabla_{y} u(y)|^{2} h^{d} dy = h^{d-2} \\int_{\\Omega} |\\nabla_{y} u(y)|^{2} dy = h^{d-2} \\|\\nabla_{y} u\\|_{L^{2}(\\Omega)}^{2}\n$$\nTaking the square root, we find the relationship for the gradient norms:\n$$\n\\|\\nabla_{x} v\\|_{L^{2}(\\Omega_{h})} = h^{(d-2)/2} \\|\\nabla_{y} u\\|_{L^{2}(\\Omega)}\n$$\nNow we can express $C_{P}(\\Omega_{h})$ in terms of the norms of $u$ on $\\Omega$. Substituting the derived expressions into the definition of $C_{P}(\\Omega_{h})$:\n$$\nC_{P}(\\Omega_{h}) = \\sup_{u \\in H_{0}^{1}(\\Omega), u \\neq 0} \\frac{h^{d/2} \\|u\\|_{L^{2}(\\Omega)}}{h^{(d-2)/2} \\|\\nabla_{y} u\\|_{L^{2}(\\Omega)}}\n$$\nSince the factors involving $h$ are constant with respect to the function $u$, they can be pulled out of the supremum:\n$$\nC_{P}(\\Omega_{h}) = \\frac{h^{d/2}}{h^{(d-2)/2}} \\sup_{u \\in H_{0}^{1}(\\Omega), u \\neq 0} \\frac{\\|u\\|_{L^{2}(\\Omega)}}{\\|\\nabla_{y} u\\|_{L^{2}(\\Omega)}}\n$$\nThe supremum expression is, by definition, the Poincaré constant $C_{P}(\\Omega)$. We simplify the scaling prefactor:\n$$\n\\frac{h^{d/2}}{h^{(d-2)/2}} = h^{\\frac{d}{2} - \\frac{d-2}{2}} = h^{\\frac{d - (d-2)}{2}} = h^{\\frac{2}{2}} = h^{1} = h\n$$\nTherefore, we have the relation:\n$$\nC_{P}(\\Omega_{h}) = h \\, C_{P}(\\Omega)\n$$\nBy comparing this result with the given relation $C_{P}(\\Omega_{h}) = S(h,d)\\,C_{P}(\\Omega)$, we identify the scaling factor $S(h,d)$.\n$$\nS(h,d) = h\n$$\nThe scaling factor is independent of the spatial dimension $d$.", "answer": "$$ \\boxed{h} $$", "id": "3397255"}, {"introduction": "We now apply our understanding of scaling arguments to a cornerstone of modern numerical analysis: the finite element method. This method relies on mapping computations from a general 'physical' element to a fixed 'reference' element via an affine transformation. This exercise guides you through deriving how the $H^1$ seminorm scales under such a map, a result that is then used to establish a classic 'inverse inequality,' which is critical for analyzing the stability and accuracy of finite element solutions. [@problem_id:3397300]", "problem": "Let $\\hat K \\subset \\mathbb{R}^{d}$ be a fixed reference element with nonempty interior and unit diameter, and let $K \\subset \\mathbb{R}^{d}$ be a physical element obtained from $\\hat K$ by an affine map $F:\\hat K \\to K$ of the form $x = F(\\hat x) = B \\hat x + b$, where $B \\in \\mathbb{R}^{d \\times d}$ is invertible and $b \\in \\mathbb{R}^{d}$. Denote the diameter of $K$ by $h = \\operatorname{diam}(K) = \\sup_{x,y \\in K} |x - y|$. For $v \\in H^{1}(K)$ define $\\hat v \\in H^{1}(\\hat K)$ by $\\hat v(\\hat x) = v(F(\\hat x))$. Recall that for any measurable function $g$ and any invertible affine map $F$, the change-of-variables formula states $\\int_{K} g(x)\\,dx = \\int_{\\hat K} g(F(\\hat x))\\,|\\det B|\\,d\\hat x$, and the chain rule for gradients gives $\\nabla_{\\hat x} \\hat v(\\hat x) = B^{T} \\nabla_{x} v(F(\\hat x))$.\n\nAssume a shape-regular family of affine maps in the following sense: there exist positive constants $c_{\\min}$ and $c_{\\max}$, independent of $K$ and $h$, such that $c_{\\min}\\,h \\le \\|B\\| \\le c_{\\max}\\,h$ and $c_{\\min}\\,h^{d} \\le |\\det B| \\le c_{\\max}\\,h^{d}$, where $\\|\\cdot\\|$ is the operator norm induced by the Euclidean norm. Let $|\\cdot|_{H^{1}(D)}$ denote the $H^{1}$ seminorm on a domain $D$, i.e., $|w|_{H^{1}(D)} := \\|\\nabla w\\|_{L^{2}(D)}$.\n\nTask A. Starting only from the stated change-of-variables and chain-rule facts, derive the explicit $h$-dependence of the scaling of the $H^{1}$ seminorm under the affine map, in the sense that there exists a shape constant $C_{\\mathrm{sr}} \\ge 1$, independent of $h$, such that\n$$\nC_{\\mathrm{sr}}^{-1}\\,S(h,d)\\,|\\hat v|_{H^{1}(\\hat K)} \\le |v|_{H^{1}(K)} \\le C_{\\mathrm{sr}}\\,S(h,d)\\,|\\hat v|_{H^{1}(\\hat K)}.\n$$\nIdentify $S(h,d)$ as a single expression in terms of $h$ and $d$.\n\nTask B. Let $V_{h}(K)$ be the image under $F$ of a fixed polynomial space $V(\\hat K)$ consisting of all polynomials on $\\hat K$ of total degree at most $p$, with $p$ fixed independently of $h$. Using only the finite-dimensional norm equivalence on $V(\\hat K)$ and your result from Task A, deduce the inverse inequality\n$$\n\\|\\nabla v_{h}\\|_{L^{2}(K)} \\le C\\,h^{-1}\\,\\|v_{h}\\|_{L^{2}(K)} \\quad \\text{for all } v_{h} \\in V_{h}(K),\n$$\nwith a constant $C$ independent of $h$.\n\nAnswer specification: Your final answer must be the single closed-form expression you found for $S(h,d)$ in Task A. No units are required, and no rounding is necessary. Express your answer as a function of $h$ and $d$ only.", "solution": "The user has provided a problem asking for the derivation of a scaling law for the $H^{1}$ seminorm under an affine mapping and a subsequent deduction of a finite element inverse inequality.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n*   Reference element: $\\hat K \\subset \\mathbb{R}^{d}$, nonempty interior, $\\operatorname{diam}(\\hat K) = 1$.\n*   Physical element: $K \\subset \\mathbb{R}^{d}$, $\\operatorname{diam}(K) = h$.\n*   Affine map: $F:\\hat K \\to K$, $x = F(\\hat x) = B \\hat x + b$, with $B \\in \\mathbb{R}^{d \\times d}$ invertible and $b \\in \\mathbb{R}^{d}$.\n*   Function mapping: For $v \\in H^{1}(K)$, $\\hat v \\in H^{1}(\\hat K)$ is defined by $\\hat v(\\hat x) = v(F(\\hat x))$.\n*   Change of variables: $\\int_{K} g(x)\\,dx = \\int_{\\hat K} g(F(\\hat x))\\,|\\det B|\\,d\\hat x$.\n*   Chain rule: $\\nabla_{\\hat x} \\hat v(\\hat x) = B^{T} \\nabla_{x} v(F(\\hat x))$.\n*   Shape-regularity assumption: There exist positive constants $c_{\\min}$ and $c_{\\max}$ independent of $K$ and $h$ such that:\n    1.  $c_{\\min}\\,h \\le \\|B\\| \\le c_{\\max}\\,h$, where $\\|\\cdot\\|$ is the operator norm.\n    2.  $c_{\\min}\\,h^{d} \\le |\\det B| \\le c_{\\max}\\,h^{d}$.\n*   $H^1$ seminorm definition: $|w|_{H^{1}(D)} := \\|\\nabla w\\|_{L^{2}(D)} = \\left(\\int_{D} |\\nabla w(y)|^2 dy\\right)^{1/2}$.\n*   Task A goal: Find $S(h,d)$ in the relation $C_{\\mathrm{sr}}^{-1}\\,S(h,d)\\,|\\hat v|_{H^{1}(\\hat K)} \\le |v|_{H^{1}(K)} \\le C_{\\mathrm{sr}}\\,S(h,d)\\,|\\hat v|_{H^{1}(\\hat K)}$.\n*   Task B setup: $V(\\hat K)$ is the space of polynomials of total degree at most $p$. $V_{h}(K)$ is the image of $V(\\hat K)$ under the mapping $F$.\n*   Task B goal: Deduce the inverse inequality $\\|\\nabla v_{h}\\|_{L^{2}(K)} \\le C\\,h^{-1}\\,\\|v_{h}\\|_{L^{2}(K)}$ for all $v_{h} \\in V_{h}(K)$.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem statement is a standard exercise in the mathematical theory of the finite element method.\n*   **Scientifically Grounded**: The problem is based on fundamental principles of linear algebra, multivariate calculus (change of variables, chain rule), and functional analysis ($L^2$ and Sobolev spaces). The concept of shape-regularity and derivation of scaling laws are central to the convergence analysis of finite element methods. The problem is mathematically and scientifically sound.\n*   **Well-Posed**: The problem is clearly stated with all necessary definitions and assumptions. As shown in the solution derivation, the provided assumptions are sufficient to arrive at a unique scaling factor $S(h,d)$ and to prove the inverse inequality. The problem is not under- or over-specified.\n*   **Objective**: The language is precise and mathematical, free of any subjectivity or ambiguity.\n\nThe problem does not violate any of the invalidity criteria. All terms are standard or explicitly defined. The assumptions are self-consistent and sufficient for the tasks.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. I will proceed with the solution.\n\n### Solution\n\nThe solution is divided into two parts as requested by the problem statement.\n\n**Task A: Scaling of the $H^{1}$ Seminorm**\n\nThe goal is to find the scaling factor $S(h,d)$ that relates the $H^{1}$ seminorm of a function $v$ on the physical element $K$ to the seminorm of the corresponding function $\\hat{v}$ on the reference element $\\hat{K}$.\n\nThe square of the $H^{1}$ seminorm of $v$ on $K$ is defined as:\n$$\n|v|_{H^{1}(K)}^{2} = \\int_{K} |\\nabla_{x} v(x)|^{2} dx\n$$\nWe apply the given change-of-variables formula with $g(x) = |\\nabla_{x} v(x)|^{2}$.\n$$\n|v|_{H^{1}(K)}^{2} = \\int_{\\hat K} |\\nabla_{x} v(F(\\hat x))|^{2} |\\det B| \\,d\\hat x\n$$\nNext, we use the given chain rule $\\nabla_{\\hat x} \\hat v(\\hat x) = B^{T} \\nabla_{x} v(F(\\hat x))$. Since $B$ is invertible, so is $B^T$. We can write:\n$$\n\\nabla_{x} v(F(\\hat x)) = (B^{T})^{-1} \\nabla_{\\hat x} \\hat v(\\hat x)\n$$\nSubstituting this into the integral expression gives:\n$$\n|v|_{H^{1}(K)}^{2} = \\int_{\\hat K} |(B^{T})^{-1} \\nabla_{\\hat x} \\hat v(\\hat x)|^{2} |\\det B| \\,d\\hat x\n$$\nLet the vector field $\\hat w(\\hat x) = \\nabla_{\\hat x} \\hat v(\\hat x)$. The squared norm is the dot product:\n$$\n|(B^{T})^{-1} \\hat w|^{2} = ((B^{T})^{-1} \\hat w) \\cdot ((B^{T})^{-1} \\hat w) = \\hat w^{T} (B^{T})^{-T} (B^{T})^{-1} \\hat w = \\hat w^{T} (B^{-1}) (B^{T})^{-1} \\hat w = \\hat w^{T} (B B^{T})^{-1} \\hat w\n$$\nThe matrix $(B B^{T})^{-1}$ is symmetric and positive definite. The expression $\\hat w^{T} (B B^{T})^{-1} \\hat w$ can be bounded by the minimum and maximum eigenvalues of $(B B^{T})^{-1}$. The eigenvalues of $B B^{T}$ are the squares of the singular values of $B$, denoted by $\\sigma_i(B)^{2}$. Thus, the eigenvalues of $(B B^{T})^{-1}$ are $1/\\sigma_i(B)^{2}$.\nLet $\\sigma_{\\min}(B)$ and $\\sigma_{\\max}(B)$ be the minimum and maximum singular values of $B$. Then the minimum and maximum eigenvalues of $(B B^{T})^{-1}$ are $1/\\sigma_{\\max}(B)^{2}$ and $1/\\sigma_{\\min}(B)^{2}$, respectively.\nWe know that the operator norm is $\\|B\\| = \\sigma_{\\max}(B)$ and $\\|B^{-1}\\| = 1/\\sigma_{\\min}(B)$. Therefore, the Rayleigh quotient is bounded as:\n$$\n\\frac{1}{\\|B\\|^{2}} |\\hat w|^{2} \\le \\hat w^{T} (B B^{T})^{-1} \\hat w \\le \\|B^{-1}\\|^{2} |\\hat w|^{2}\n$$\nApplying these bounds to our integral expression, we get two inequalities.\n\nFor the upper bound:\n$$\n|v|_{H^{1}(K)}^{2} \\le \\int_{\\hat K} \\|B^{-1}\\|^{2} |\\nabla_{\\hat x} \\hat v(\\hat x)|^{2} |\\det B| \\,d\\hat x = \\|B^{-1}\\|^{2} |\\det B| \\int_{\\hat K} |\\nabla_{\\hat x} \\hat v(\\hat x)|^{2} \\,d\\hat x = \\|B^{-1}\\|^{2} |\\det B| |\\hat v|_{H^{1}(\\hat K)}^{2}\n$$\nFor the lower bound:\n$$\n|v|_{H^{1}(K)}^{2} \\ge \\int_{\\hat K} \\frac{1}{\\|B\\|^{2}} |\\nabla_{\\hat x} \\hat v(\\hat x)|^{2} |\\det B| \\,d\\hat x = \\frac{|\\det B|}{\\|B\\|^{2}} \\int_{\\hat K} |\\nabla_{\\hat x} \\hat v(\\hat x)|^{2} \\,d\\hat x = \\frac{|\\det B|}{\\|B\\|^{2}} |\\hat v|_{H^{1}(\\hat K)}^{2}\n$$\nNow, we use the shape-regularity assumptions. First, we must bound $\\|B^{-1}\\|$. From the properties of singular values, $\\|B^{-1}\\| = 1/\\sigma_{\\min}(B)$. The determinant is the product of singular values, $|\\det B| = \\prod_{i=1}^d \\sigma_i(B)$. Thus, $|\\det B| \\le \\sigma_{\\min}(B) (\\sigma_{\\max}(B))^{d-1} = \\sigma_{\\min}(B) \\|B\\|^{d-1}$. This yields $\\sigma_{\\min}(B) \\ge \\frac{|\\det B|}{\\|B\\|^{d-1}}$. Therefore:\n$$\n\\|B^{-1}\\| = \\frac{1}{\\sigma_{\\min}(B)} \\le \\frac{\\|B\\|^{d-1}}{|\\det B|}\n$$\nUsing the given assumptions $c_{\\min}\\,h \\le \\|B\\| \\le c_{\\max}\\,h$ and $c_{\\min}\\,h^{d} \\le |\\det B| \\le c_{\\max}\\,h^{d}$:\n$$\n\\|B^{-1}\\| \\le \\frac{(c_{\\max}h)^{d-1}}{c_{\\min}h^{d}} = \\frac{c_{\\max}^{d-1}}{c_{\\min}} h^{-1}\n$$\nNow we can bound the terms in our inequalities.\nFor the upper bound on $|v|_{H^{1}(K)}$:\n$$\n|v|_{H^{1}(K)}^{2} \\le \\|B^{-1}\\|^{2} |\\det B| |\\hat v|_{H^{1}(\\hat K)}^{2} \\le \\left(\\frac{c_{\\max}^{d-1}}{c_{\\min}} h^{-1}\\right)^{2} (c_{\\max}h^{d}) |\\hat v|_{H^{1}(\\hat K)}^{2} = \\frac{c_{\\max}^{2d-2+1}}{c_{\\min}^{2}} h^{-2+d} |\\hat v|_{H^{1}(\\hat K)}^{2} = \\frac{c_{\\max}^{2d-1}}{c_{\\min}^{2}} h^{d-2} |\\hat v|_{H^{1}(\\hat K)}^{2}\n$$\nFor the lower bound on $|v|_{H^{1}(K)}$:\n$$\n|v|_{H^{1}(K)}^{2} \\ge \\frac{|\\det B|}{\\|B\\|^{2}} |\\hat v|_{H^{1}(\\hat K)}^{2} \\ge \\frac{c_{\\min}h^{d}}{(c_{\\max}h)^{2}} |\\hat v|_{H^{1}(\\hat K)}^{2} = \\frac{c_{\\min}}{c_{\\max}^{2}} h^{d-2} |\\hat v|_{H^{1}(\\hat K)}^{2}\n$$\nTaking the square root of both inequalities, we obtain:\n$$\n\\sqrt{\\frac{c_{\\min}}{c_{\\max}^{2}}} h^{\\frac{d-2}{2}} |\\hat v|_{H^{1}(\\hat K)} \\le |v|_{H^{1}(K)} \\le \\sqrt{\\frac{c_{\\max}^{2d-1}}{c_{\\min}^{2}}} h^{\\frac{d-2}{2}} |\\hat v|_{H^{1}(\\hat K)}\n$$\nThis is of the form $C_{\\mathrm{sr}}^{-1}\\,S(h,d)\\,|\\hat v|_{H^{1}(\\hat K)} \\le |v|_{H^{1}(K)} \\le C_{\\mathrm{sr}}\\,S(h,d)\\,|\\hat v|_{H^{1}(\\hat K)}$ where the shape constant $C_{\\mathrm{sr}}$ depends on $c_{\\min}$, $c_{\\max}$, and $d$, but not on $h$. The scaling factor $S(h,d)$ is identified as:\n$$\nS(h,d) = h^{\\frac{d-2}{2}}\n$$\n\n**Task B: Inverse Inequality**\n\nWe want to derive the inverse inequality $\\|\\nabla v_{h}\\|_{L^{2}(K)} \\le C\\,h^{-1}\\,\\|v_{h}\\|_{L^{2}(K)}$ for $v_h \\in V_h(K)$. This is equivalent to $|v_h|_{H^1(K)} \\le C h^{-1} \\|v_h\\|_{L^2(K)}$.\nLet $v_h \\in V_h(K)$. Then there exists a polynomial $\\hat{v}_h \\in V(\\hat{K})$ of degree at most $p$ such that $v_h(x) = \\hat{v}_h(\\hat{x})$ for $x = F(\\hat{x})$.\n\n1.  **Relate $|v_h|_{H^1(K)}$ to $|\\hat{v}_h|_{H^1(\\hat K)}$**: From Task A, we have the upper bound:\n    $$\n    |v_h|_{H^1(K)} \\le C_1 h^{\\frac{d-2}{2}} |\\hat{v}_h|_{H^1(\\hat K)}\n    $$\n    where $C_1 = \\sqrt{c_{\\max}^{2d-1}/c_{\\min}^{2}}$ is a constant independent of $h$.\n\n2.  **Relate $\\|\\hat{v}_h\\|_{H^1(\\hat K)}$ to $\\|\\hat{v}_h\\|_{L^2(\\hat K)}$**: The space $V(\\hat{K})$ is a finite-dimensional vector space. On a finite-dimensional space, all norms are equivalent. The operator $\\nabla: V(\\hat K) \\to [V(\\hat K)]^{d}$ is a linear map between finite-dimensional spaces, and is therefore bounded. This implies the existence of a constant $C_{\\text{equiv}}$, depending only on the space $V(\\hat K)$ (i.e., on $p$ and the geometry of $\\hat K$), such that for any $\\hat{v}_h \\in V(\\hat K)$:\n    $$\n    |\\hat{v}_h|_{H^1(\\hat K)} = \\|\\nabla \\hat{v}_h\\|_{L^2(\\hat K)} \\le C_{\\text{equiv}} \\|\\hat{v}_h\\|_{L^2(\\hat K)}\n    $$\n\n3.  **Relate $\\|\\hat{v}_h\\|_{L^2(\\hat K)}$ to $\\|v_h\\|_{L^2(K)}$**: We analyze the scaling of the $L^2$ norm.\n    $$\n    \\|v_h\\|_{L^2(K)}^2 = \\int_K |v_h(x)|^2 dx = \\int_{\\hat K} |v_h(F(\\hat x))|^2 |\\det B| d\\hat x = \\int_{\\hat K} |\\hat{v}_h(\\hat x)|^2 |\\det B| d\\hat x\n    $$\n    Using the lower bound for the determinant, $|\\det B| \\ge c_{\\min}h^d$:\n    $$\n    \\|v_h\\|_{L^2(K)}^2 \\ge c_{\\min}h^d \\int_{\\hat K} |\\hat{v}_h(\\hat x)|^2 d\\hat x = c_{\\min}h^d \\|\\hat{v}_h\\|_{L^2(\\hat K)}^2\n    $$\n    Taking the square root and rearranging gives:\n    $$\n    \\|\\hat{v}_h\\|_{L^2(\\hat K)} \\le \\frac{1}{\\sqrt{c_{\\min}} h^{d/2}} \\|v_h\\|_{L^2(K)}\n    $$\n\n4.  **Combine the inequalities**:\n    Starting from the result of Step 1:\n    $$\n    |v_h|_{H^1(K)} \\le C_1 h^{\\frac{d-2}{2}} |\\hat{v}_h|_{H^1(\\hat K)}\n    $$\n    Using the norm equivalence from Step 2:\n    $$\n    |v_h|_{H^1(K)} \\le C_1 h^{\\frac{d-2}{2}} (C_{\\text{equiv}} \\|\\hat{v}_h\\|_{L^2(\\hat K)})\n    $$\n    Finally, using the scaling from Step 3:\n    $$\n    |v_h|_{H^1(K)} \\le C_1 C_{\\text{equiv}} h^{\\frac{d-2}{2}} \\left( \\frac{1}{\\sqrt{c_{\\min}} h^{d/2}} \\|v_h\\|_{L^2(K)} \\right)\n    $$\n    Simplifying the expression:\n    $$\n    |v_h|_{H^1(K)} \\le \\left(\\frac{C_1 C_{\\text{equiv}}}{\\sqrt{c_{\\min}}}\\right) h^{\\frac{d-2}{2} - \\frac{d}{2}} \\|v_h\\|_{L^2(K)} = \\left(\\frac{C_1 C_{\\text{equiv}}}{\\sqrt{c_{\\min}}}\\right) h^{-1} \\|v_h\\|_{L^2(K)}\n    $$\n    Letting $C = \\frac{C_1 C_{\\text{equiv}}}{\\sqrt{c_{\\min}}}$, we have a constant independent of $h$, and we obtain the desired inverse inequality:\n    $$\n    \\|\\nabla v_{h}\\|_{L^{2}(K)} \\le C\\,h^{-1}\\,\\|v_{h}\\|_{L^{2}(K)}\n    $$\nThe final answer required is the expression for $S(h,d)$ from Task A.", "answer": "$$\\boxed{h^{\\frac{d-2}{2}}}$$", "id": "3397300"}]}