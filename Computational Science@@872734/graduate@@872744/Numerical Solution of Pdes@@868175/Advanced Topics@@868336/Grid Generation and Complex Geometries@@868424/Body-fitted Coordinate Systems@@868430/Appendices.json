{"hands_on_practices": [{"introduction": "The first and most critical step in using a body-fitted coordinate system is to ensure the mapping from the simple computational domain to the complex physical domain is mathematically valid. The key to this validity check is the Jacobian determinant, $J$. This practice [@problem_id:3367212] challenges you to derive the Jacobian for a given transformation and determine the conditions on its parameters that guarantee its positivity, which prevents grid cells from folding over or inverting. Mastering this analysis is a foundational skill for anyone involved in grid generation, as it forms the basis of quality control for any curvilinear coordinate system.", "problem": "Consider a two-dimensional body-fitted mapping from a computational domain to a physical domain, as commonly used in the numerical solution of partial differential equations (PDEs) on curved geometries. Let the computational coordinates be $(\\xi,\\eta)\\in[0,1]^{2}$ and the physical coordinates be $(x,y)$ defined by the smooth transformation\n$$\nx(\\xi,\\eta)=\\xi+\\alpha\\,\\xi\\,\\eta,\\qquad y(\\xi,\\eta)=\\eta+\\beta\\,\\xi^{2},\n$$\nwhere $\\alpha$ and $\\beta$ are real constants. The Jacobian determinant $J(\\xi,\\eta)$ of the map is defined by the determinant of the $2\\times 2$ matrix of partial derivatives of $(x,y)$ with respect to $(\\xi,\\eta)$, and positivity of $J$ on $[0,1]^{2}$ is a necessary condition for the mapping to be orientation-preserving and nondegenerate (grid cells do not fold).\n\nStarting from the fundamental definition of the Jacobian determinant in coordinate transformations, derive $J(\\xi,\\eta)$ for the given map and determine the parameter ranges on $(\\alpha,\\beta)$ that ensure $J(\\xi,\\eta)>0$ for all $(\\xi,\\eta)\\in[0,1]^{2}$. Your derivation must proceed from first principles and justify all steps in the minimization needed to certify positivity on the entire square.\n\nAnswer specification:\n- Provide your final answer as a single closed-form analytic expression for the minimum value of $J(\\xi,\\eta)$ over $[0,1]^{2}$ in terms of $\\alpha$ and $\\beta$ only. This expression characterizes the positivity condition $J>0$ by requiring the minimum to be strictly positive.\n- Do not include inequalities or equations in the final answer.\n- No units are required. No rounding is required.", "solution": "The problem is to determine the range of parameters $(\\alpha, \\beta)$ for which the Jacobian determinant $J(\\xi, \\eta)$ of a given coordinate transformation is strictly positive over the computational domain $(\\xi, \\eta) \\in [0, 1]^2$. This is equivalent to finding the global minimum of $J(\\xi, \\eta)$ on this domain and requiring it to be greater than zero. The problem explicitly asks for the analytical expression for this minimum value.\n\nFirst, we define the Jacobian matrix of the transformation from computational coordinates $(\\xi, \\eta)$ to physical coordinates $(x, y)$. The transformation is given by:\n$$\nx(\\xi, \\eta) = \\xi + \\alpha \\xi \\eta \\\\\ny(\\xi, \\eta) = \\eta + \\beta \\xi^2\n$$\nThe Jacobian matrix $\\mathbf{J}$ is defined as:\n$$\n\\mathbf{J}(\\xi, \\eta) = \\begin{pmatrix} \\frac{\\partial x}{\\partial \\xi} & \\frac{\\partial x}{\\partial \\eta} \\\\ \\frac{\\partial y}{\\partial \\xi} & \\frac{\\partial y}{\\partial \\eta} \\end{pmatrix}\n$$\nWe compute the necessary partial derivatives:\n$$\n\\frac{\\partial x}{\\partial \\xi} = \\frac{\\partial}{\\partial \\xi} (\\xi + \\alpha \\xi \\eta) = 1 + \\alpha \\eta \\\\\n\\frac{\\partial x}{\\partial \\eta} = \\frac{\\partial}{\\partial \\eta} (\\xi + \\alpha \\xi \\eta) = \\alpha \\xi \\\\\n\\frac{\\partial y}{\\partial \\xi} = \\frac{\\partial}{\\partial \\xi} (\\eta + \\beta \\xi^2) = 2 \\beta \\xi \\\\\n\\frac{\\partial y}{\\partial \\eta} = \\frac{\\partial}{\\partial \\eta} (\\eta + \\beta \\xi^2) = 1\n$$\nThe Jacobian determinant, $J(\\xi, \\eta) = \\det(\\mathbf{J})$, is therefore:\n$$\nJ(\\xi, \\eta) = \\left(\\frac{\\partial x}{\\partial \\xi}\\right) \\left(\\frac{\\partial y}{\\partial \\eta}\\right) - \\left(\\frac{\\partial x}{\\partial \\eta}\\right) \\left(\\frac{\\partial y}{\\partial \\xi}\\right)\n$$\nSubstituting the partial derivatives, we obtain:\n$$\nJ(\\xi, \\eta) = (1 + \\alpha \\eta)(1) - (\\alpha \\xi)(2 \\beta \\xi) = 1 + \\alpha \\eta - 2 \\alpha \\beta \\xi^2\n$$\nOur task is to find the minimum value of this function, $J_{min}$, on the compact domain $[0,1]^2 = \\{(\\xi, \\eta) \\mid 0 \\le \\xi \\le 1, 0 \\le \\eta \\le 1\\}$.\n\nThe expression for $J(\\xi, \\eta)$ is a polynomial in $\\xi$ and $\\eta$ and is therefore continuous on the closed, bounded domain $[0,1]^2$. By the Extreme Value Theorem, a global minimum exists and must be attained either at a critical point in the interior of the domain, $(0,1)^2$, or on its boundary.\n\nThe partial derivatives of $J$ with respect to $\\xi$ and $\\eta$ are:\n$$\n\\frac{\\partial J}{\\partial \\xi} = -4 \\alpha \\beta \\xi \\\\\n\\frac{\\partial J}{\\partial \\eta} = \\alpha\n$$\nFor an interior critical point, we would need $\\frac{\\partial J}{\\partial \\eta} = 0$, which implies $\\alpha = 0$. If $\\alpha=0$, then $J(\\xi, \\eta) = 1$ for all $(\\xi, \\eta)$, and its minimum is $1$. In the case where $\\alpha \\neq 0$, there are no critical points in the interior of the domain. Therefore, the minimum value of $J(\\xi, \\eta)$ must be attained on the boundary of the square $[0,1]^2$.\n\nA more direct approach is to analyze the structure of $J(\\xi, \\eta) = 1 + \\alpha \\eta - 2 \\alpha \\beta \\xi^2$. Let us define new variables $u = \\eta$ and $v = \\xi^2$. As $(\\xi, \\eta)$ sweeps the domain $[0,1]^2$, the point $(u, v)$ also sweeps the unit square $[0,1]^2$. In terms of these new variables, the Jacobian becomes a linear function:\n$$\nL(u, v) = 1 + \\alpha u - 2 \\alpha \\beta v\n$$\nThe problem is transformed into finding the minimum of a linear function $L(u,v)$ over the unit square $(u,v) \\in [0,1]^2$. The minimum (and maximum) of a linear function over a convex polygon must occur at one of its vertices. The vertices of the unit square in the $(u,v)$-plane are $(0,0)$, $(1,0)$, $(0,1)$, and $(1,1)$.\n\nWe evaluate $L(u,v)$ at these four vertices:\n\\begin{enumerate}\n    \\item At $(u,v) = (0,0)$ (corresponding to $(\\xi,\\eta)=(0,0)$): $L(0,0) = 1$.\n    \\item At $(u,v) = (1,0)$ (corresponding to $(\\xi,\\eta)=(0,1)$): $L(1,0) = 1 + \\alpha$.\n    \\item At $(u,v) = (0,1)$ (corresponding to $(\\xi,\\eta)=(1,0)$): $L(0,1) = 1 - 2 \\alpha \\beta$.\n    \\item At $(u,v) = (1,1)$ (corresponding to $(\\xi,\\eta)=(1,1)$): $L(1,1) = 1 + \\alpha - 2 \\alpha \\beta$.\n\\end{enumerate}\nThe global minimum of $J(\\xi, \\eta)$ on $[0,1]^2$ is the minimum of these four values:\n$$\nJ_{min} = \\min \\{1, 1+\\alpha, 1-2\\alpha\\beta, 1+\\alpha-2\\alpha\\beta\\}\n$$\nThis expression can be simplified into a single closed-form analytic expression. We can group the terms:\n$$\nJ_{min} = \\min \\left( \\min\\{1, 1+\\alpha\\}, \\min\\{1-2\\alpha\\beta, 1+\\alpha-2\\alpha\\beta\\} \\right)\n$$\nThe first inner minimum is $\\min\\{1, 1+\\alpha\\} = 1 + \\min\\{0, \\alpha\\}$.\nThe second inner minimum is $\\min\\{1-2\\alpha\\beta, (1-2\\alpha\\beta)+\\alpha\\} = 1-2\\alpha\\beta + \\min\\{0, \\alpha\\}$.\nSo, the expression becomes:\n$$\nJ_{min} = \\min \\left( 1 + \\min\\{0, \\alpha\\}, 1-2\\alpha\\beta + \\min\\{0, \\alpha\\} \\right)\n$$\nFactoring out the common term $1 + \\min\\{0, \\alpha\\}$ gives:\n$$\nJ_{min} = 1 + \\min\\{0, \\alpha\\} + \\min\\{0, -2\\alpha\\beta\\}\n$$\nTo express this using elementary functions and absolute values, we use the identities $\\min\\{0, x\\} = \\frac{x - |x|}{2}$ and $|xy| = |x||y|$.\n$$\n\\min\\{0, \\alpha\\} = \\frac{\\alpha - |\\alpha|}{2}\n$$\n$$\n\\min\\{0, -2\\alpha\\beta\\} = \\frac{-2\\alpha\\beta - |-2\\alpha\\beta|}{2} = \\frac{-2\\alpha\\beta - 2|\\alpha\\beta|}{2} = - \\alpha\\beta - |\\alpha\\beta|\n$$\nSubstituting these into the expression for $J_{min}$:\n$$\nJ_{min} = 1 + \\frac{\\alpha - |\\alpha|}{2} - \\alpha\\beta - |\\alpha\\beta|\n$$\nThis is the single closed-form analytic expression for the minimum value of the Jacobian determinant over the specified domain. The condition for a valid, non-degenerate mapping is $J_{min} > 0$.", "answer": "$$\n\\boxed{1 + \\frac{\\alpha - |\\alpha|}{2} - \\alpha\\beta - |\\alpha\\beta|}\n$$", "id": "3367212"}, {"introduction": "With a valid grid, the next step is often to perform numerical integration, a cornerstone of methods like the Finite Element Method. When we transform an integral from a curved physical cell to a simple reference square, the integrand is multiplied by the Jacobian determinant, often resulting in a high-degree polynomial. This practice [@problem_id:3367230] guides you through determining the minimum number of Gauss quadrature points needed to integrate this new function exactly. This analysis is crucial for balancing computational efficiency and accuracy, providing direct insight into how grid curvature impacts the design of a numerical solver.", "problem": "Consider a two-dimensional curved quadrilateral cell $\\mathcal{K}$ obtained from the reference square $\\widehat{\\mathcal{K}}=[-1,1]^{2}$ by an isoparametric tensor-product polynomial mapping $\\boldsymbol{F}:\\widehat{\\mathcal{K}}\\to \\mathcal{K}$ of degree $k\\geq 1$ in each reference coordinate, that is, each component of $\\boldsymbol{F}(\\boldsymbol{\\xi})$ is a polynomial of degree at most $k$ in $\\xi_{1}$ and degree at most $k$ in $\\xi_{2}$, where $\\boldsymbol{\\xi}=(\\xi_{1},\\xi_{2})$. Let $f:\\mathbb{R}^{2}\\to\\mathbb{R}$ be any polynomial in the physical coordinates $(x,y)$ of total degree at most $p\\geq 0$. The exact cell integral is\n$$\nI=\\int_{\\mathcal{K}} f(x,y)\\,\\mathrm{d}x\\,\\mathrm{d}y.\n$$\nBy the change-of-variables theorem with $\\boldsymbol{x}=\\boldsymbol{F}(\\boldsymbol{\\xi})$ and Jacobian determinant $J(\\boldsymbol{\\xi})=\\det\\left(\\frac{\\partial(x,y)}{\\partial(\\xi_{1},\\xi_{2})}\\right)$, this integral can be expressed over $\\widehat{\\mathcal{K}}$ as\n$$\nI=\\int_{-1}^{1}\\int_{-1}^{1} \\big(f\\circ \\boldsymbol{F}\\big)(\\xi_{1},\\xi_{2})\\,J(\\xi_{1},\\xi_{2})\\,\\mathrm{d}\\xi_{2}\\,\\mathrm{d}\\xi_{1}.\n$$\nYou will approximate $I$ by a tensor-product Gauss–Legendre quadrature with $N$ points per reference direction:\n$$\nQ_{N}=\\sum_{i=1}^{N}\\sum_{j=1}^{N} w_{i}\\,w_{j}\\,\\big(f\\circ \\boldsymbol{F}\\big)(\\xi_{i},\\eta_{j})\\,J(\\xi_{i},\\eta_{j}),\n$$\nwhere $\\{(\\xi_{i},w_{i})\\}_{i=1}^{N}$ are the $N$-point Gauss–Legendre nodes and weights on $[-1,1]$ in the $\\xi_{1}$-direction and $\\{(\\eta_{j},w_{j})\\}_{j=1}^{N}$ are the corresponding nodes and weights in the $\\xi_{2}$-direction.\n\nStarting from the change-of-variables principle and well-established degree-exactness properties of Gauss–Legendre quadrature in one dimension and its tensor-product extension, determine the minimal number of quadrature points $N_{\\min}$ per direction (as an explicit analytic expression in $p$ and $k$) such that $Q_{N}$ is guaranteed to be exact, that is $Q_{N}=I$, for all polynomials $f(x,y)$ in the physical coordinates of total degree at most $p$ on $\\mathcal{K}$.\n\nState clearly any degree bounds you invoke for compositions and products of polynomials under the isoparametric mapping and its Jacobian determinant. Your final answer must be a single closed-form analytic expression for $N_{\\min}$ in terms of $p$ and $k$ (no numerical evaluation is required, and no units are involved).", "solution": "The task is to determine the minimum number of Gauss-Legendre quadrature points, $N_{\\min}$, required per direction on the reference square $\\widehat{\\mathcal{K}}=[-1,1]^{2}$ to guarantee the exact evaluation of the integral $I=\\int_{\\mathcal{K}} f(\\boldsymbol{x})\\,\\mathrm{d}\\boldsymbol{x}$.\n\nThe integral is transformed to the reference element $\\widehat{\\mathcal{K}}$ via the mapping $\\boldsymbol{x} = \\boldsymbol{F}(\\boldsymbol{\\xi})$, where $\\boldsymbol{x}=(x,y)$ and $\\boldsymbol{\\xi}=(\\xi_1, \\xi_2)$. The transformed integral is:\n$$\nI = \\int_{-1}^{1}\\int_{-1}^{1} \\big(f\\circ \\boldsymbol{F}\\big)(\\xi_{1},\\xi_{2})\\,J(\\xi_{1},\\xi_{2})\\,\\mathrm{d}\\xi_{2}\\,\\mathrm{d}\\xi_{1}\n$$\nThe numerical quadrature, $Q_N$, approximates this integral. For $Q_N$ to be exactly equal to $I$, the quadrature rule must be exact for the integrand function, which we denote as $g(\\xi_1, \\xi_2) = \\big(f\\circ \\boldsymbol{F}\\big)(\\xi_{1},\\xi_{2})\\,J(\\xi_{1},\\xi_{2})$.\n\nThe chosen quadrature is a tensor-product Gauss-Legendre rule. A one-dimensional $N$-point Gauss-Legendre quadrature on the interval $[-1,1]$ is exact for any polynomial of degree up to $2N-1$. For the two-dimensional tensor-product rule to be exact, the integrand $g(\\xi_1, \\xi_2)$ must be a polynomial in $\\xi_1$ of degree at most $2N-1$ for any fixed $\\xi_2$, and a polynomial in $\\xi_2$ of degree at most $2N-1$ for any fixed $\\xi_1$. Our goal is therefore to find the maximum possible polynomial degree of $g(\\xi_1, \\xi_2)$ in each of its variables.\n\nLet us analyze the polynomial degree of the two factors of the integrand, $(f\\circ \\boldsymbol{F})$ and $J$.\n\n1.  **Degree of the composite function $(f\\circ \\boldsymbol{F})(\\boldsymbol{\\xi})$**:\n    The mapping $\\boldsymbol{F}(\\boldsymbol{\\xi})=(x(\\xi_1, \\xi_2), y(\\xi_1, \\xi_2))$ is a tensor-product polynomial of degree $k$ in each reference coordinate. This means that $x(\\xi_1, \\xi_2)$ and $y(\\xi_1, \\xi_2)$ are polynomials with maximum degree $k$ in $\\xi_1$ and maximum degree $k$ in $\\xi_2$. We can write this as $\\text{deg}_{\\xi_1}(x) \\le k$, $\\text{deg}_{\\xi_2}(x) \\le k$, $\\text{deg}_{\\xi_1}(y) \\le k$, and $\\text{deg}_{\\xi_2}(y) \\le k$.\n    The function $f(x,y)$ is a polynomial in the physical coordinates $(x,y)$ of total degree at most $p$. A generic term in $f(x,y)$ is of the form $c_{ab} x^a y^b$ where $a+b \\le p$.\n    When we compose $f$ with $\\boldsymbol{F}$, this term becomes $c_{ab} (x(\\xi_1, \\xi_2))^a (y(\\xi_1, \\xi_2))^b$.\n    The degree of this composite term in the variable $\\xi_1$ is:\n    $$\n    \\text{deg}_{\\xi_1}\\left((x(\\xi_1, \\xi_2))^a (y(\\xi_1, \\xi_2))^b\\right) = a \\cdot \\text{deg}_{\\xi_1}(x) + b \\cdot \\text{deg}_{\\xi_1}(y)\n    $$\n    To find the maximum possible degree, we consider the upper bounds:\n    $$\n    \\text{deg}_{\\xi_1}\\left((x(\\xi_1, \\xi_2))^a (y(\\xi_1, \\xi_2))^b\\right) \\le a \\cdot k + b \\cdot k = (a+b)k\n    $$\n    Since the maximum value of $a+b$ is $p$, the maximum degree of any term in $(f\\circ \\boldsymbol{F})$ with respect to $\\xi_1$ is $pk$. The same logic applies to the variable $\\xi_2$. Thus, the maximum polynomial degrees are:\n    $$\n    \\text{deg}_{\\xi_1}(f\\circ \\boldsymbol{F}) \\le pk \\quad \\text{and} \\quad \\text{deg}_{\\xi_2}(f\\circ \\boldsymbol{F}) \\le pk\n    $$\n    These bounds are sharp, as can be seen by taking $f(x,y)=x^p$ and a mapping with $x(\\xi_1,\\xi_2)=\\xi_1^k$.\n\n2.  **Degree of the Jacobian determinant $J(\\boldsymbol{\\xi})$**:\n    The Jacobian determinant is defined as:\n    $$\n    J(\\boldsymbol{\\xi}) = \\det\\left(\\frac{\\partial(x,y)}{\\partial(\\xi_{1},\\xi_{2})}\\right) = \\frac{\\partial x}{\\partial \\xi_1}\\frac{\\partial y}{\\partial \\xi_2} - \\frac{\\partial x}{\\partial \\xi_2}\\frac{\\partial y}{\\partial \\xi_1}\n    $$\n    The degrees of the partial derivatives with respect to $\\xi_1$ are:\n    $\\text{deg}_{\\xi_1}\\left(\\frac{\\partial x}{\\partial \\xi_1}\\right) \\le k-1$, $\\text{deg}_{\\xi_1}\\left(\\frac{\\partial y}{\\partial \\xi_1}\\right) \\le k-1$.\n    $\\text{deg}_{\\xi_1}\\left(\\frac{\\partial x}{\\partial \\xi_2}\\right) \\le k$, $\\text{deg}_{\\xi_1}\\left(\\frac{\\partial y}{\\partial \\xi_2}\\right) \\le k$.\n    Now we find the degree of each term in the expression for $J$:\n    $$\n    \\text{deg}_{\\xi_1}\\left(\\frac{\\partial x}{\\partial \\xi_1}\\frac{\\partial y}{\\partial \\xi_2}\\right) = \\text{deg}_{\\xi_1}\\left(\\frac{\\partial x}{\\partial \\xi_1}\\right) + \\text{deg}_{\\xi_1}\\left(\\frac{\\partial y}{\\partial \\xi_2}\\right) \\le (k-1) + k = 2k-1\n    $$\n    $$\n    \\text{deg}_{\\xi_1}\\left(\\frac{\\partial x}{\\partial \\xi_2}\\frac{\\partial y}{\\partial \\xi_1}\\right) = \\text{deg}_{\\xi_1}\\left(\\frac{\\partial x}{\\partial \\xi_2}\\right) + \\text{deg}_{\\xi_1}\\left(\\frac{\\partial y}{\\partial \\xi_1}\\right) \\le k + (k-1) = 2k-1\n    $$\n    The degree of the sum (or difference) is at most the maximum of the degrees of the terms. Therefore, the maximum degree of $J$ with respect to $\\xi_1$ is $2k-1$. By symmetry, the same holds for $\\xi_2$:\n    $$\n    \\text{deg}_{\\xi_1}(J) \\le 2k-1 \\quad \\text{and} \\quad \\text{deg}_{\\xi_2}(J) \\le 2k-1\n    $$\n    This bound is also sharp.\n\n3.  **Degree of the complete integrand $g(\\boldsymbol{\\xi})$**:\n    The degree of the product $g = (f\\circ \\boldsymbol{F}) J$ is the sum of the degrees of its factors. The maximum degree of $g$ in $\\xi_1$ is:\n    $$\n    \\text{deg}_{\\xi_1}(g) = \\text{deg}_{\\xi_1}(f\\circ \\boldsymbol{F}) + \\text{deg}_{\\xi_1}(J) \\le pk + (2k-1)\n    $$\n    Let $D_{\\max} = pk + 2k - 1$. This is the maximum polynomial degree of the integrand in each variable $\\xi_1$ and $\\xi_2$.\n\n4.  **Determining the minimal number of quadrature points $N_{\\min}$**:\n    For the $N$-point Gauss-Legendre quadrature to be exact, the degree of the polynomial integrand must be no more than $2N-1$. We must therefore satisfy the condition:\n    $$\n    D_{\\max} \\le 2N - 1\n    $$\n    Substituting the expression for $D_{\\max}$:\n    $$\n    pk + 2k - 1 \\le 2N - 1\n    $$\n    Simplifying this inequality yields:\n    $$\n    pk + 2k \\le 2N\n    $$\n    $$\n    N \\ge \\frac{pk + 2k}{2} = \\frac{k(p+2)}{2}\n    $$\n    Since the number of quadrature points $N$ must be an integer, we must take the smallest integer that satisfies this condition. This is given by the ceiling function:\n    $$\n    N_{\\min} = \\left\\lceil \\frac{k(p+2)}{2} \\right\\rceil\n    $$\nThis expression provides the minimal number of quadrature points per direction needed to guarantee exact integration for any polynomial $f$ of total degree up to $p$ over a domain mapped by a degree-$k$ tensor-product polynomial.", "answer": "$$\n\\boxed{\\left\\lceil \\frac{k(p+2)}{2} \\right\\rceil}\n$$", "id": "3367230"}, {"introduction": "The transition from continuous equations to a discrete algorithm on a computer can introduce subtle errors if not handled carefully. A fundamental consistency requirement for any numerical scheme on a curvilinear grid is \"free-stream preservation\"—the ability to perfectly maintain a uniform flow without generating spurious artifacts. This property is directly linked to the careful discretization of the grid's geometric metrics to satisfy a discrete analogue of a continuous identity, known as the Geometric Conservation Law (GCL). In this hands-on coding exercise [@problem_id:3367290], you will implement a metric discretization that satisfies the GCL and verify its direct impact on achieving free-stream preservation, a vital step in developing reliable simulation codes.", "problem": "Consider a two-dimensional body-fitted coordinate transformation mapping computational coordinates $(\\xi,\\eta)\\in[0,1]\\times[0,1]$ (with periodic boundary conditions) to physical coordinates $(x,y)$ via smooth functions $x(\\xi,\\eta)$ and $y(\\xi,\\eta)$. Let the Jacobian determinant be defined by $J = \\det\\left(\\frac{\\partial(x,y)}{\\partial(\\xi,\\eta)}\\right)$, and let $\\boldsymbol{a}^{i}$ denote the contravariant basis vectors associated with the transformation. The conservative linear advection equation for a scalar field $q(x,y,t)$ with constant velocity $(u,v)$ in the physical domain can be written in the computational domain in a flux-divergence form using transformed fluxes and geometric metrics built from $J\\boldsymbol{a}^{i}$.\n\nYour task is to design and implement a discrete approximation for $J\\boldsymbol{a}^{i}$ on a structured, collocated, uniform grid in $(\\xi,\\eta)$ using second-order centered finite differences, such that the discrete metric identity $D_{\\xi}\\left(J\\boldsymbol{a}^{1}\\right) + D_{\\eta}\\left(J\\boldsymbol{a}^{2}\\right) = \\boldsymbol{0}$ is satisfied exactly under periodic boundary conditions, where $D_{\\xi}$ and $D_{\\eta}$ are the discrete partial derivative operators with respect to $\\xi$ and $\\eta$. Starting from the chain rule and the definition of the Jacobian determinant and contravariant basis, derive how to assemble $J\\boldsymbol{a}^{i}$ from discrete spatial derivatives in a manner that enforces the discrete metric identity. Then, using the resulting metrics, demonstrate free-stream preservation for the discrete conservative linear advection operator: for a constant field $q(\\xi,\\eta)=q_{0}$ and constant velocity $(u,v)$, show that the semi-discrete operator applied to $q$ produces a zero residual when constructed consistently with the same difference operators used in the metric approximation.\n\nUse the following test suite in your program. For each test, define the mapping by\n$$\nx(\\xi,\\eta) = \\xi + \\alpha \\sin(2\\pi \\xi)\\sin(2\\pi \\eta),\\qquad\ny(\\xi,\\eta) = \\eta + \\beta \\cos(2\\pi \\xi)\\sin(2\\pi \\eta),\n$$\nwith periodicity in both directions, and discretize the domain with a uniform, periodic grid of size $N_{\\xi}\\times N_{\\eta}$ and spacings $\\Delta \\xi = \\tfrac{1}{N_{\\xi}}$, $\\Delta \\eta = \\tfrac{1}{N_{\\eta}}$. Use a centered difference stencil with periodic wrapping for $D_{\\xi}$ and $D_{\\eta}$. For each case, set $q_{0} = 1$ (dimensionless), and compute:\n- The maximum absolute value of each component of $D_{\\xi}\\left(J\\boldsymbol{a}^{1}\\right) + D_{\\eta}\\left(J\\boldsymbol{a}^{2}\\right)$ over the grid.\n- The maximum absolute value of the discrete conservative advection residual $D_{\\xi}(F^{\\xi}) + D_{\\eta}(F^{\\eta})$, where the fluxes $F^{\\xi}$ and $F^{\\eta}$ are the transformed fluxes built consistently from $J\\boldsymbol{a}^{i}$ and the constant velocity $(u,v)$.\n\nDeclare success for the discrete metric identity if the maximum absolute value of both components is less than a tolerance $\\varepsilon = 10^{-12}$, and declare free-stream preservation success if the maximum absolute value of the residual is less than the same tolerance $\\varepsilon = 10^{-12}$.\n\nTest suite:\n- Case $1$: $N_{\\xi} = 64$, $N_{\\eta} = 64$, $\\alpha = 0.2$, $\\beta = 0.15$, $u = 0.8$, $v = -0.3$.\n- Case $2$: $N_{\\xi} = 32$, $N_{\\eta} = 48$, $\\alpha = 0.0$, $\\beta = 0.0$, $u = 1.0$, $v = 0.4$.\n- Case $3$: $N_{\\xi} = 33$, $N_{\\eta} = 33$, $\\alpha = 0.25$, $\\beta = 0.05$, $u = 0.0$, $v = 0.0$.\n- Case $4$: $N_{\\xi} = 5$, $N_{\\eta} = 7$, $\\alpha = 0.1$, $\\beta = -0.08$, $u = -0.5$, $v = 0.9$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as $[\\text{metric\\_ok\\_case1},\\text{free\\_ok\\_case1},\\text{metric\\_ok\\_case2},\\text{free\\_ok\\_case2},\\ldots]$, where each entry is a boolean indicating whether the corresponding check passed under the tolerance $\\varepsilon = 10^{-12}$. No physical units or angle units are involved, and all quantities are dimensionless.", "solution": "The problem requires the design of a discrete approximation for the geometric metrics of a curvilinear coordinate system, specifically the quantities $J\\boldsymbol{a}^{1}$ and $J\\boldsymbol{a}^{2}$, such that the discrete geometric identity is satisfied exactly. This property is then used to demonstrate free-stream preservation for a conservative advection scheme.\n\nLet the physical coordinates $(x, y)$ be functions of the computational coordinates $(\\xi, \\eta)$. The position vector is $\\boldsymbol{r}(\\xi, \\eta) = x(\\xi, \\eta)\\boldsymbol{i} + y(\\xi, \\eta)\\boldsymbol{j}$. The covariant basis vectors are defined as the partial derivatives of the position vector with respect to the computational coordinates:\n$$\n\\boldsymbol{e}_{1} = \\frac{\\partial \\boldsymbol{r}}{\\partial \\xi} = \\frac{\\partial x}{\\partial \\xi}\\boldsymbol{i} + \\frac{\\partial y}{\\partial \\xi}\\boldsymbol{j}\n$$\n$$\n\\boldsymbol{e}_{2} = \\frac{\\partial \\boldsymbol{r}}{\\partial \\eta} = \\frac{\\partial x}{\\partial \\eta}\\boldsymbol{i} + \\frac{\\partial y}{\\partial \\eta}\\boldsymbol{j}\n$$\nThe contravariant basis vectors, $\\boldsymbol{a}^{1}$ and $\\boldsymbol{a}^{2}$, are defined by the relation $\\boldsymbol{a}^{i} \\cdot \\boldsymbol{e}_{j} = \\delta^{i}_{j}$, where $\\delta^{i}_{j}$ is the Kronecker delta. The Jacobian determinant of the transformation is $J = x_{\\xi}y_{\\eta} - x_{\\eta}y_{\\xi}$.\nSolving for the contravariant basis vectors yields:\n$$\n\\boldsymbol{a}^{1} = \\frac{1}{J}\\left( y_{\\eta}\\boldsymbol{i} - x_{\\eta}\\boldsymbol{j} \\right)\n$$\n$$\n\\boldsymbol{a}^{2} = \\frac{1}{J}\\left( -y_{\\xi}\\boldsymbol{i} + x_{\\xi}\\boldsymbol{j} \\right)\n$$\nThe quantities of interest are the contravariant basis vectors scaled by the Jacobian, $J\\boldsymbol{a}^{i}$:\n$$\nJ\\boldsymbol{a}^{1} = y_{\\eta}\\boldsymbol{i} - x_{\\eta}\\boldsymbol{j} = \\begin{pmatrix} y_{\\eta} \\\\ -x_{\\eta} \\end{pmatrix}\n$$\n$$\nJ\\boldsymbol{a}^{2} = -y_{\\xi}\\boldsymbol{i} + x_{\\xi}\\boldsymbol{j} = \\begin{pmatrix} -y_{\\xi} \\\\ x_{\\xi} \\end{pmatrix}\n$$\nIn the continuous case, these metrics satisfy the identity $\\frac{\\partial}{\\partial \\xi}(J\\boldsymbol{a}^{1}) + \\frac{\\partial}{\\partial \\eta}(J\\boldsymbol{a}^{2}) = \\boldsymbol{0}$. This is a direct consequence of the equality of mixed partial derivatives for smooth functions (Clairaut's theorem):\n$$\n\\frac{\\partial}{\\partial \\xi}(J\\boldsymbol{a}^{1}) + \\frac{\\partial}{\\partial \\eta}(J\\boldsymbol{a}^{2}) = \\frac{\\partial}{\\partial \\xi}\\begin{pmatrix} y_{\\eta} \\\\ -x_{\\eta} \\end{pmatrix} + \\frac{\\partial}{\\partial \\eta}\\begin{pmatrix} -y_{\\xi} \\\\ x_{\\xi} \\end{pmatrix} = \\begin{pmatrix} y_{\\eta\\xi} - y_{\\xi\\eta} \\\\ -x_{\\eta\\xi} + x_{\\xi\\eta} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = \\boldsymbol{0}\n$$\n\nThe goal is to preserve this identity in the discrete sense. We discretize the computational domain $[0,1]\\times[0,1]$ with a uniform grid of $N_{\\xi} \\times N_{\\eta}$ points, with grid spacings $\\Delta\\xi = 1/N_{\\xi}$ and $\\Delta\\eta = 1/N_{\\eta}$. We define second-order centered difference operators, $D_{\\xi}$ and $D_{\\eta}$, for any grid function $f_{i,j} = f(i\\Delta\\xi, j\\Delta\\eta)$:\n$$\n(D_{\\xi} f)_{i,j} = \\frac{f_{i+1,j} - f_{i-1,j}}{2\\Delta\\xi}\n$$\n$$\n(D_{\\eta} f)_{i,j} = \\frac{f_{i,j+1} - f_{i,j-1}}{2\\Delta\\eta}\n$$\nwhere indices are handled periodically. The crucial insight is to construct the discrete metrics by directly replacing the partial derivatives in the expressions for $J\\boldsymbol{a}^{i}$ with these difference operators. Let $(\\tilde{G}^{1})_{i,j}$ and $(\\tilde{G}^{2})_{i,j}$ be the discrete approximations of $(J\\boldsymbol{a}^{1})_{i,j}$ and $(J\\boldsymbol{a}^{2})_{i,j}$.\n$$\n(\\tilde{G}^{1})_{i,j} = \\begin{pmatrix} (D_{\\eta} y)_{i,j} \\\\ -(D_{\\eta} x)_{i,j} \\end{pmatrix}\n$$\n$$\n(\\tilde{G}^{2})_{i,j} = \\begin{pmatrix} -(D_{\\xi} y)_{i,j} \\\\ (D_{\\xi} x)_{i,j} \\end{pmatrix}\n$$\nNow, we apply the discrete divergence operator to these discrete metrics:\n$$\nD_{\\xi}(\\tilde{G}^{1}) + D_{\\eta}(\\tilde{G}^{2}) = D_{\\xi}\\begin{pmatrix} D_{\\eta} y \\\\ -D_{\\eta} x \\end{pmatrix} + D_{\\eta}\\begin{pmatrix} -D_{\\xi} y \\\\ D_{\\xi} x \\end{pmatrix} = \\begin{pmatrix} D_{\\xi}D_{\\eta}y - D_{\\eta}D_{\\xi}y \\\\ -D_{\\xi}D_{\\eta}x + D_{\\eta}D_{\\xi}x \\end{pmatrix}\n$$\nThe standard second-order centered difference operators commute, meaning $D_{\\xi}D_{\\eta}f = D_{\\eta}D_{\\xi}f$ for any grid function $f$. This can be shown by writing out the stencils. Therefore, each component of the resulting vector is identically zero. This proves that this specific construction of the discrete metrics satisfies the metric identity $D_{\\xi}(\\tilde{G}^{1}) + D_{\\eta}(\\tilde{G}^{2}) = \\boldsymbol{0}$ exactly (up to machine precision).\n\nNext, we demonstrate free-stream preservation. The conservative linear advection equation for a scalar $q$ with constant velocity $\\boldsymbol{v} = (u,v)$ in physical space, $\\frac{\\partial q}{\\partial t} + \\nabla \\cdot (\\boldsymbol{v}q) = 0$, transforms to computational space as:\n$$\n\\frac{\\partial (Jq)}{\\partial t} + \\frac{\\partial F^{\\xi}}{\\partial \\xi} + \\frac{\\partial F^{\\eta}}{\\partial \\eta} = 0\n$$\nwhere the transformed fluxes are $F^{\\xi} = q (\\boldsymbol{v} \\cdot J\\boldsymbol{a}^{1})$ and $F^{\\eta} = q (\\boldsymbol{v} \\cdot J\\boldsymbol{a}^{2})$.\nIn semi-discrete form, the spatial operator (residual) at grid point $(i,j)$ is $R_{i,j} = D_{\\xi}(F^{\\xi})_{i,j} + D_{\\eta}(F^{\\eta})_{i,j}$. For the free-stream condition, the scalar field is constant, $q=q_0$, and the velocity $(u,v)$ is constant. The discrete fluxes are constructed consistently with the metrics:\n$$\n(F^{\\xi})_{i,j} = q_{0} \\left( u (\\tilde{G}^{1}_{x})_{i,j} + v (\\tilde{G}^{1}_{y})_{i,j} \\right) = q_0 \\left( u (D_{\\eta}y)_{i,j} - v (D_{\\eta}x)_{i,j} \\right)\n$$\n$$\n(F^{\\eta})_{i,j} = q_{0} \\left( u (\\tilde{G}^{2}_{x})_{i,j} + v (\\tilde{G}^{2}_{y})_{i,j} \\right) = q_0 \\left( -u (D_{\\xi}y)_{i,j} + v (D_{\\xi}x)_{i,j} \\right)\n$$\nThe discrete residual is the divergence of these fluxes:\n$$\nR_{i,j} = D_{\\xi} \\left( q_0 ( u D_{\\eta}y - v D_{\\eta}x ) \\right)_{i,j} + D_{\\eta} \\left( q_0 ( -u D_{\\xi}y + v D_{\\xi}x ) \\right)_{i,j}\n$$\nSince $q_0$, $u$, and $v$ are constants, they can be factored out of the difference operators:\n$$\nR_{i,j} = q_0 u \\left( D_{\\xi}D_{\\eta}y - D_{\\eta}D_{\\xi}y \\right)_{i,j} - q_0 v \\left( D_{\\xi}D_{\\eta}x - D_{\\eta}D_{\\xi}x \\right)_{i,j}\n$$\nAs established before, the operators commute, so $(D_{\\xi}D_{\\eta}y - D_{\\eta}D_{\\xi}y)_{i,j} = 0$ and $(D_{\\xi}D_{\\eta}x - D_{\\eta}D_{\\xi}x)_{i,j} = 0$. Consequently, the residual $R_{i,j}=0$ for all $(i,j)$. This demonstrates that a constant initial field remains constant, a property known as free-stream preservation. This is a crucial property for a numerical scheme to accurately simulate uniform flows on curvilinear grids without introducing artificial sources or sinks. The implementation below follows this derivation.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and implements discrete geometric metrics for a body-fitted coordinate system\n    that satisfy the discrete metric identity and demonstrates free-stream preservation for\n    a conservative linear advection operator.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N_xi, N_eta, alpha, beta, u, v)\n        (64, 64, 0.2, 0.15, 0.8, -0.3),\n        (32, 48, 0.0, 0.0, 1.0, 0.4),\n        (33, 33, 0.25, 0.05, 0.0, 0.0),\n        (5, 7, 0.1, -0.08, -0.5, 0.9),\n    ]\n\n    tolerance = 1e-12\n    results = []\n\n    for case in test_cases:\n        N_xi, N_eta, alpha, beta, u, v = case\n        \n        # 1. Grid Generation\n        d_xi = 1.0 / N_xi\n        d_eta = 1.0 / N_eta\n        \n        # Create computational coordinate grid\n        xi_vec = np.linspace(0.0, 1.0, N_xi, endpoint=False)\n        eta_vec = np.linspace(0.0, 1.0, N_eta, endpoint=False)\n        \n        # Use 'xy' indexing for (N_eta, N_xi) shaped arrays,\n        # where xi varies along axis 1 (columns) and eta along axis 0 (rows).\n        xi_grid, eta_grid = np.meshgrid(xi_vec, eta_vec, indexing='xy')\n        \n        # Compute physical coordinates using the mapping functions\n        x_grid = xi_grid + alpha * np.sin(2 * np.pi * xi_grid) * np.sin(2 * np.pi * eta_grid)\n        y_grid = eta_grid + beta * np.cos(2 * np.pi * xi_grid) * np.sin(2 * np.pi * eta_grid)\n        \n        # 2. Discrete Operators and Metric Calculation\n        def diff_xi(f):\n            \"\"\"Second-order centered difference in xi (axis=1) with periodic BC.\"\"\"\n            return (np.roll(f, -1, axis=1) - np.roll(f, 1, axis=1)) / (2 * d_xi)\n        \n        def diff_eta(f):\n            \"\"\"Second-order centered difference in eta (axis=0) with periodic BC.\"\"\"\n            return (np.roll(f, -1, axis=0) - np.roll(f, 1, axis=0)) / (2 * d_eta)\n        \n        # Calculate discrete partial derivatives of coordinates\n        dx_dxi = diff_xi(x_grid)\n        dx_deta = diff_eta(x_grid)\n        dy_dxi = diff_xi(y_grid)\n        dy_deta = diff_eta(y_grid)\n        \n        # Assemble the discrete metrics J*a^i\n        # G1 corresponds to the discrete metric for J*a^1\n        G1_x = dy_deta\n        G1_y = -dx_deta\n        \n        # G2 corresponds to the discrete metric for J*a^2\n        G2_x = -dy_dxi\n        G2_y = dx_dxi\n        \n        # 3. Check Metric Identity\n        # This is D_xi(J*a^1) + D_eta(J*a^2)\n        metric_identity_x = diff_xi(G1_x) + diff_eta(G2_x)\n        metric_identity_y = diff_xi(G1_y) + diff_eta(G2_y)\n        \n        # Find the maximum absolute error over the grid\n        max_err_x = np.max(np.abs(metric_identity_x))\n        max_err_y = np.max(np.abs(metric_identity_y))\n        \n        metric_ok = max_err_x  tolerance and max_err_y  tolerance\n        results.append(metric_ok)\n        \n        # 4. Check Free-Stream Preservation\n        q0 = 1.0  # Constant scalar field\n        \n        # Compute transformed fluxes F^xi and F^eta\n        flux_xi = q0 * (u * G1_x + v * G1_y)\n        flux_eta = q0 * (u * G2_x + v * G2_y)\n        \n        # Compute the discrete divergence of the fluxes (the residual)\n        residual = diff_xi(flux_xi) + diff_eta(flux_eta)\n        \n        # Find the maximum absolute residual over the grid\n        max_residual = np.max(np.abs(residual))\n        \n        free_ok = max_residual  tolerance\n        results.append(free_ok)\n\n    # Final print statement in the exact required format.\n    # The map to str converts booleans to 'True'/'False'.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3367290"}]}