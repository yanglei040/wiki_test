{"hands_on_practices": [{"introduction": "Before we can simulate the interaction between a fluid and a structure, we must first accurately represent the immersed boundary and its geometric properties on a discrete grid. This often involves approximating key quantities like the unit tangent, normal vector, and curvature from a set of Lagrangian marker points. This practice [@problem_id:3405640] guides you through the foundational process of deriving finite difference formulas for these geometric properties, paying special attention to the errors introduced by non-uniform point spacing.", "problem": "Consider a closed, smooth planar interface represented by a curve $\\boldsymbol{X}(s) \\in \\mathbb{R}^{2}$ parameterized by arclength $s$, so that $|\\boldsymbol{X}'(s)|=1$. In the Immersed Boundary (IB) and Immersed Interface Methods (IIM), the interface is discretized by Lagrangian points at parameters $s_j$ with generally nonuniform spacings $h_{j+\\frac{1}{2}} := s_{j+1}-s_j$. Let the local base step be $h>0$ and suppose the nonuniformity is small and smooth in the sense that\n$$\nh_{j+\\frac{1}{2}} = h\\bigl(1+\\epsilon\\,\\phi(s_{j+\\frac{1}{2}})\\bigr), \\qquad 0<|\\epsilon|\\ll 1,\n$$\nwith a bounded, smooth function $\\phi$. Denote $a:=h_{j-\\frac{1}{2}}$ and $b:=h_{j+\\frac{1}{2}}$.\n\nStarting from the geometric definitions of unit tangent $\\boldsymbol{t}(s)=\\boldsymbol{X}'(s)$, unit normal $\\boldsymbol{n}(s)=\\boldsymbol{R}\\,\\boldsymbol{t}(s)$, curvature $\\kappa(s)=\\boldsymbol{n}(s)\\cdot \\boldsymbol{X}''(s)$, where $\\boldsymbol{R}$ is the counterclockwise rotation by $\\pi/2$, and arclength increment $\\Delta s=\\int \\lvert \\boldsymbol{X}'(s)\\rvert\\,ds$, carry out the following.\n\n(1) Derive three-point, nonuniform, finite-difference formulas at $s_j$ for:\n- the first derivative $\\boldsymbol{X}'(s_j)$ (to approximate the tangent), using $\\boldsymbol{X}_{j-1},\\boldsymbol{X}_j,\\boldsymbol{X}_{j+1}$ with steps $a$ and $b$,\n- the second derivative $\\boldsymbol{X}''(s_j)$ (to be used in curvature),\n- the unit tangent $\\boldsymbol{t}_j$ by normalizing the discrete first derivative,\n- the unit normal $\\boldsymbol{n}_j=\\boldsymbol{R}\\,\\boldsymbol{t}_j$,\n- the local arclength increment $\\Delta s_{j+\\frac{1}{2}}\\approx \\lvert \\boldsymbol{X}_{j+1}-\\boldsymbol{X}_j\\rvert$.\n\nYour derivations must start from Taylor expansions of $\\boldsymbol{X}(s)$ and the defining geometric identities, and must yield truncation error expansions up to and including the leading nonvanishing term in powers of $h$ and $\\epsilon$.\n\n(2) Use your formulas to obtain an asymptotic expression, to the first nonvanishing order in $h$ and $\\epsilon$, for the curvature estimator\n$$\n\\kappa_j := \\boldsymbol{n}_j \\cdot \\boldsymbol{D}^{(2)}\\boldsymbol{X}_j,\n$$\nwhere $\\boldsymbol{D}^{(2)}$ is your nonuniform three-point second-derivative operator. Isolate the contribution of nonuniform spacing by expressing the leading curvature bias in terms of $a$, $b$, and derivatives of $\\boldsymbol{X}(s)$ evaluated at $s_j$, and then re-express the result in terms of $h$ and $\\epsilon\\,\\phi$.\n\n(3) Specialize to the circle of radius $R_0>0$, parameterized by arclength as $\\boldsymbol{X}(s)=\\bigl(R_0\\cos(s/R_0),\\,R_0\\sin(s/R_0)\\bigr)$, which has exact curvature $\\kappa\\equiv 1/R_0$. Assume the nonuniform pattern $\\phi(s)=\\cos(s/R_0)$. Using your asymptotics from (2), determine the leading-order expression for the maximum absolute relative error in $\\kappa_j$ over all $j$ as $h\\to 0$ and $|\\epsilon|\\ll 1$.\n\nFinally, evaluate this predicted maximum absolute relative error for $R_0=1.3$, $h=0.08$, and $\\epsilon=0.10$. Round your answer to four significant figures. Express the final answer as a pure number without units.", "solution": "The problem is a valid exercise in numerical analysis, specifically the derivation and analysis of finite difference formulas for geometric quantities on a smooth curve. It is mathematically well-posed, scientifically grounded, and free of any of the invalidating flaws outlined in the validation protocol. We proceed with the solution.\n\nThe solution is divided into three parts as requested. We denote derivatives of $\\boldsymbol{X}$ with respect to the arclength parameter $s$ as $\\boldsymbol{X}', \\boldsymbol{X}'', \\dots$ and their values at the point $s_j$ as $\\boldsymbol{X}'_j, \\boldsymbol{X}''_j, \\dots$. The discrete points are $\\boldsymbol{X}_j = \\boldsymbol{X}(s_j)$, $\\boldsymbol{X}_{j-1} = \\boldsymbol{X}(s_j-a)$, and $\\boldsymbol{X}_{j+1} = \\boldsymbol{X}(s_j+b)$, where $a=s_j-s_{j-1}$ and $b=s_{j+1}-s_j$.\n\n### Part (1): Finite-Difference Formulas and Truncation Errors\n\nWe start from the Taylor series expansions of $\\boldsymbol{X}(s)$ around $s_j$:\n$$ \\boldsymbol{X}_{j+1} = \\boldsymbol{X}(s_j+b) = \\boldsymbol{X}_j + b\\boldsymbol{X}'_j + \\frac{b^2}{2}\\boldsymbol{X}''_j + \\frac{b^3}{6}\\boldsymbol{X}'''_j + \\frac{b^4}{24}\\boldsymbol{X}^{(4)}_j + O(b^5) $$\n$$ \\boldsymbol{X}_{j-1} = \\boldsymbol{X}(s_j-a) = \\boldsymbol{X}_j - a\\boldsymbol{X}'_j + \\frac{a^2}{2}\\boldsymbol{X}''_j - \\frac{a^3}{6}\\boldsymbol{X}'''_j + \\frac{a^4}{24}\\boldsymbol{X}^{(4)}_j + O(a^5) $$\n\n**First Derivative $\\boldsymbol{X}'(s_j)$**\nTo find a second-order accurate formula for $\\boldsymbol{X}'_j$, we eliminate the $\\boldsymbol{X}''_j$ term. We multiply the first expansion by $a^2$ and the second by $b^2$ and subtract:\n$$ a^2\\boldsymbol{X}_{j+1} - b^2\\boldsymbol{X}_{j-1} = (a^2-b^2)\\boldsymbol{X}_j + (a^2b+ab^2)\\boldsymbol{X}'_j + \\frac{a^2b^3-b^2(-a^3)}{6}\\boldsymbol{X}'''_j + O(h^5) $$\n$$ a^2\\boldsymbol{X}_{j+1} - b^2\\boldsymbol{X}_{j-1} = (a^2-b^2)\\boldsymbol{X}_j + ab(a+b)\\boldsymbol{X}'_j + \\frac{a^2b^2(a+b)}{6}\\boldsymbol{X}'''_j + O(h^5) $$\nRearranging for $\\boldsymbol{X}'_j$ gives the three-point nonuniform formula $\\boldsymbol{D}^{(1)}\\boldsymbol{X}_j$:\n$$ \\boldsymbol{D}^{(1)}\\boldsymbol{X}_j := \\frac{a^2\\boldsymbol{X}_{j+1} + (b^2-a^2)\\boldsymbol{X}_j - b^2\\boldsymbol{X}_{j-1}}{ab(a+b)} $$\nThe truncation error is found by rearranging the expansion:\n$$ \\boldsymbol{D}^{(1)}\\boldsymbol{X}_j = \\boldsymbol{X}'_j + \\frac{ab}{6}\\boldsymbol{X}'''_j + O((a+b)^3) $$\nSince $a,b=O(h)$, the leading error term is $O(h^2)$.\n\n**Second Derivative $\\boldsymbol{X}''(s_j)$**\nTo find a formula for $\\boldsymbol{X}''_j$, we eliminate the $\\boldsymbol{X}'_j$ term. We multiply the first expansion by $a$ and the second by $b$ and add:\n$$ a\\boldsymbol{X}_{j+1} + b\\boldsymbol{X}_{j-1} = (a+b)\\boldsymbol{X}_j + \\frac{ab^2+ba^2}{2}\\boldsymbol{X}''_j + \\frac{ab^3-ba^3}{6}\\boldsymbol{X}'''_j + \\frac{ab^4+ba^4}{24}\\boldsymbol{X}^{(4)}_j + O(h^5) $$\n$$ a\\boldsymbol{X}_{j+1} + b\\boldsymbol{X}_{j-1} = (a+b)\\boldsymbol{X}_j + \\frac{ab(a+b)}{2}\\boldsymbol{X}''_j + \\frac{ab(b-a)}{6}\\boldsymbol{X}'''_j + \\frac{ab(a^3+b^3)}{24(a+b)}(a+b)\\boldsymbol{X}^{(4)}_j + \\dots $$\nThis gives the formula for the second derivative, $\\boldsymbol{D}^{(2)}\\boldsymbol{X}_j$:\n$$ \\boldsymbol{D}^{(2)}\\boldsymbol{X}_j := \\frac{2\\left(a\\boldsymbol{X}_{j+1} - (a+b)\\boldsymbol{X}_j + b\\boldsymbol{X}_{j-1}\\right)}{ab(a+b)} $$\nThe truncation error is:\n$$ \\boldsymbol{D}^{(2)}\\boldsymbol{X}_j = \\boldsymbol{X}''_j + \\frac{b-a}{3}\\boldsymbol{X}'''_j + \\frac{a^2-ab+b^2}{12}\\boldsymbol{X}^{(4)}_j + O((a,b)^3) $$\nThe leading error is typically $O(b-a)=O(h)$ for general non-uniform grids, but under the given smooth variation $b-a = O(\\epsilon h^2)$, making the leading error $O(h^2)$.\n\n**Unit Tangent $\\boldsymbol{t}_j$ and Normal $\\boldsymbol{n}_j$**\nThe unit tangent is approximated by normalizing the discrete first derivative: $\\boldsymbol{t}_j^{approx} = \\frac{\\boldsymbol{D}^{(1)}\\boldsymbol{X}_j}{|\\boldsymbol{D}^{(1)}\\boldsymbol{X}_j|}$. First, we find the magnitude of $\\boldsymbol{D}^{(1)}\\boldsymbol{X}_j$:\n$$ |\\boldsymbol{D}^{(1)}\\boldsymbol{X}_j|^2 = |\\boldsymbol{X}'_j + \\frac{ab}{6}\\boldsymbol{X}'''_j + O(h^3)|^2 = |\\boldsymbol{X}'_j|^2 + 2\\frac{ab}{6} \\boldsymbol{X}'_j \\cdot \\boldsymbol{X}'''_j + O(h^4) $$\nSince $s$ is arclength, $\\boldsymbol{X}'=\\boldsymbol{t}$ and $|\\boldsymbol{t}|=1$. The Frenet-Serret relations for a plane curve are $\\boldsymbol{t}'=\\kappa\\boldsymbol{n}$ and $\\boldsymbol{n}'=-\\kappa\\boldsymbol{t}$. Thus $\\boldsymbol{X}''=\\kappa\\boldsymbol{n}$ and $\\boldsymbol{X}''' = \\kappa'\\boldsymbol{n} - \\kappa^2\\boldsymbol{t}$. So, $\\boldsymbol{t}\\cdot\\boldsymbol{X}''' = -\\kappa^2$.\n$$ |\\boldsymbol{D}^{(1)}\\boldsymbol{X}_j|^2 = 1 - \\frac{ab}{3}\\kappa_j^2 + O(h^4) \\implies |\\boldsymbol{D}^{(1)}\\boldsymbol{X}_j| = 1 - \\frac{ab}{6}\\kappa_j^2 + O(h^4) $$\nThe approximate tangent is then:\n$$ \\boldsymbol{t}_j^{approx} = (\\boldsymbol{X}'_j + \\frac{ab}{6}\\boldsymbol{X}'''_j)(1 + \\frac{ab}{6}\\kappa_j^2 + O(h^4)) = \\boldsymbol{t}_j + \\frac{ab}{6}(\\boldsymbol{X}'''_j + \\kappa_j^2\\boldsymbol{t}_j) + O(h^4) $$\n$$ \\boldsymbol{t}_j^{approx} = \\boldsymbol{t}_j + \\frac{ab}{6}(\\kappa'_j\\boldsymbol{n}_j - \\kappa_j^2\\boldsymbol{t}_j + \\kappa_j^2\\boldsymbol{t}_j) + O(h^4) = \\boldsymbol{t}_j + \\frac{ab}{6}\\kappa'_j\\boldsymbol{n}_j + O(h^4) $$\nThe approximate normal $\\boldsymbol{n}_j^{approx} = \\boldsymbol{R}\\boldsymbol{t}_j^{approx}$ is:\n$$ \\boldsymbol{n}_j^{approx} = \\boldsymbol{R}(\\boldsymbol{t}_j + \\frac{ab}{6}\\kappa'_j\\boldsymbol{n}_j) + O(h^4) = \\boldsymbol{n}_j + \\frac{ab}{6}\\kappa'_j(-\\boldsymbol{t}_j) + O(h^4) = \\boldsymbol{n}_j - \\frac{ab}{6}\\kappa'_j\\boldsymbol{t}_j + O(h^4) $$\nThe leading error terms for both $\\boldsymbol{t}_j^{approx}$ and $\\boldsymbol{n}_j^{approx}$ are $O(h^2)$.\n\n**Arclength Increment $\\Delta s_{j+\\frac{1}{2}}$**\nThe exact arclength increment is $\\Delta s_{j+\\frac{1}{2}} = s_{j+1}-s_j=b$. The approximation is the chord length $|\\boldsymbol{X}_{j+1}-\\boldsymbol{X}_j|$.\n$$ \\boldsymbol{X}_{j+1}-\\boldsymbol{X}_j = b\\boldsymbol{X}'_j + \\frac{b^2}{2}\\boldsymbol{X}''_j + \\frac{b^3}{6}\\boldsymbol{X}'''_j + \\frac{b^4}{24}\\boldsymbol{X}^{(4)}_j + O(b^5) $$\nUsing the Frenet-Serret relations: $\\boldsymbol{X}'=\\boldsymbol{t}$, $\\boldsymbol{X}''=\\kappa\\boldsymbol{n}$, $\\boldsymbol{X}'''=-\\kappa^2\\boldsymbol{t}+\\kappa'\\boldsymbol{n}$, $\\boldsymbol{X}^{(4)}=-3\\kappa\\kappa'\\boldsymbol{t}+(\\kappa''-\\kappa^3)\\boldsymbol{n}$.\n$$ |\\boldsymbol{X}_{j+1}-\\boldsymbol{X}_j|^2 = \\left(b - \\frac{b^3\\kappa^2}{6}\\right)^2 + \\left(\\frac{b^2\\kappa}{2} + \\frac{b^3\\kappa'}{6}\\right)^2 + O(b^6) = b^2 - \\frac{b^4\\kappa^2}{3} + \\frac{b^4\\kappa^2}{4} + O(b^5) = b^2 - \\frac{b^4\\kappa^2}{12} + O(b^5) $$\n$$ |\\boldsymbol{X}_{j+1}-\\boldsymbol{X}_j| = b\\sqrt{1-\\frac{b^2\\kappa^2}{12}+O(b^3)} = b\\left(1-\\frac{b^2\\kappa^2}{24}+O(b^4)\\right) = b - \\frac{b^3\\kappa^2}{24} + O(b^5) $$\nThe error is $|\\boldsymbol{X}_{j+1}-\\boldsymbol{X}_j| - b = -\\frac{b^3\\kappa_j^2}{24} + O(b^5)$.\n\n### Part (2): Curvature Estimator Asymptotics\n\nThe curvature estimator is $\\kappa_j^{approx} := \\boldsymbol{n}_j^{approx} \\cdot \\boldsymbol{D}^{(2)}\\boldsymbol{X}_j$. We use the expressions from Part (1):\n$$ \\kappa_j^{approx} = \\left(\\boldsymbol{n}_j - \\frac{ab}{6}\\kappa'_j\\boldsymbol{t}_j + O(h^4)\\right) \\cdot \\left(\\boldsymbol{X}''_j + \\frac{b-a}{3}\\boldsymbol{X}'''_j + \\frac{a^2-ab+b^2}{12}\\boldsymbol{X}^{(4)}_j + O(h^3)\\right) $$\nExpanding and keeping the leading terms:\n$$ \\kappa_j^{approx} = \\boldsymbol{n}_j\\cdot\\boldsymbol{X}''_j + \\frac{b-a}{3}\\boldsymbol{n}_j\\cdot\\boldsymbol{X}'''_j + \\frac{a^2-ab+b^2}{12}\\boldsymbol{n}_j\\cdot\\boldsymbol{X}^{(4)}_j - \\frac{ab}{6}\\kappa'_j(\\boldsymbol{t}_j\\cdot\\boldsymbol{X}''_j) + \\dots $$\nWe evaluate the dot products:\n- $\\boldsymbol{n}_j\\cdot\\boldsymbol{X}''_j = \\boldsymbol{n}_j\\cdot(\\kappa_j\\boldsymbol{n}_j) = \\kappa_j$.\n- $\\boldsymbol{n}_j\\cdot\\boldsymbol{X}'''_j = \\boldsymbol{n}_j\\cdot(\\kappa'_j\\boldsymbol{n}_j-\\kappa_j^2\\boldsymbol{t}_j) = \\kappa'_j$.\n- $\\boldsymbol{n}_j\\cdot\\boldsymbol{X}^{(4)}_j = \\boldsymbol{n}_j\\cdot(-3\\kappa_j\\kappa'_j\\boldsymbol{t}_j + (\\kappa''_j-\\kappa_j^3)\\boldsymbol{n}_j) = \\kappa''_j-\\kappa_j^3$.\n- $\\boldsymbol{t}_j\\cdot\\boldsymbol{X}''_j = \\boldsymbol{t}_j\\cdot(\\kappa_j\\boldsymbol{n}_j) = 0$.\n\nSubstituting these back, we get the asymptotic expression for the estimated curvature:\n$$ \\kappa_j^{approx} = \\kappa_j + \\frac{b-a}{3}\\kappa'_j + \\frac{a^2-ab+b^2}{12}(\\kappa''_j - \\kappa_j^3) + O(\\epsilon h^3, h^3) $$\nThe error is $\\kappa_j^{approx} - \\kappa_j$. The contribution from the nonuniform spacing is the part of the error that vanishes if $a=b=h$. The total error is the expression above subtract $\\kappa_j$. The nonuniform contribution to the leading error is $\\frac{b-a}{3}\\kappa'_j$. This is the first requested expression, in terms of $a,b$ and derivatives.\n\nTo express this in terms of $h$ and $\\epsilon\\phi$, we use $b = h(1+\\epsilon\\phi(s_{j+1/2}))$ and $a=h(1+\\epsilon\\phi(s_{j-1/2}))$. Assuming $s_{j\\pm 1/2}$ are the arclength midpoints, $s_{j\\pm 1/2} \\approx s_j \\pm h/2$.\n$$ b-a \\approx h\\epsilon(\\phi(s_j+h/2)-\\phi(s_j-h/2)) \\approx h\\epsilon(h\\phi'(s_j)) = \\epsilon h^2 \\phi'(s_j) $$\nSo the leading curvature bias due to nonuniformity is $\\frac{\\epsilon h^2 \\phi'(s_j)}{3}\\kappa'_j$.\n\n### Part (3): Circle Example and Error Evaluation\n\nFor a circle of radius $R_0$, we have $\\boldsymbol{X}(s)=\\bigl(R_0\\cos(s/R_0),\\,R_0\\sin(s/R_0)\\bigr)$. The curvature is constant, $\\kappa \\equiv 1/R_0$. Consequently, its derivatives are zero: $\\kappa'=0$ and $\\kappa''=0$.\n\nUsing the error expression from Part (2):\n$$ \\kappa_j^{approx} - \\kappa_j = \\frac{b-a}{3}(0) + \\frac{a^2-ab+b^2}{12}(0 - \\kappa_j^3) = -\\frac{a^2-ab+b^2}{12}\\kappa^3 $$\nNow we expand $a^2-ab+b^2$ in terms of $h$ and $\\epsilon$. Let $\\phi_a = \\phi(s_{j-1/2})$ and $\\phi_b=\\phi(s_{j+1/2})$.\n$$ a^2-ab+b^2 = h^2\\left[(1+\\epsilon\\phi_a)^2 - (1+\\epsilon\\phi_a)(1+\\epsilon\\phi_b) + (1+\\epsilon\\phi_b)^2\\right] $$\n$$ = h^2\\left[1+\\epsilon(\\phi_a+\\phi_b) + \\epsilon^2(\\phi_a^2-\\phi_a\\phi_b+\\phi_b^2)\\right] $$\nTo leading order in $h$ and $\\epsilon$, we need $\\phi_a+\\phi_b$. With $\\phi(s)=\\cos(s/R_0)$ and $s_{j\\pm1/2}\\approx s_j\\pm h/2$:\n$$ \\phi_a+\\phi_b \\approx \\phi(s_j-h/2)+\\phi(s_j+h/2) = \\cos(\\frac{s_j-h/2}{R_0}) + \\cos(\\frac{s_j+h/2}{R_0}) $$\n$$ = 2\\cos(s_j/R_0)\\cos(h/2R_0) \\approx 2\\cos(s_j/R_0)(1-O(h^2)) \\approx 2\\phi(s_j) $$\nThus, $a^2-ab+b^2 \\approx h^2(1+2\\epsilon\\phi(s_j))$.\nThe error in curvature is:\n$$ \\kappa_j^{approx} - \\kappa \\approx -\\frac{h^2(1+2\\epsilon\\phi(s_j))}{12}\\kappa^3 = -\\frac{h^2(1+2\\epsilon\\cos(s_j/R_0))}{12 R_0^3} $$\nThe relative error is:\n$$ \\frac{\\kappa_j^{approx} - \\kappa}{\\kappa} \\approx -\\frac{h^2(1+2\\epsilon\\cos(s_j/R_0))}{12 R_0^2} $$\nTo find the maximum absolute relative error, we maximize the absolute value of this expression over all points $j$, which corresponds to maximizing over the angle $\\theta_j=s_j/R_0 \\in [0, 2\\pi)$. We need to maximize $|1+2\\epsilon\\cos(\\theta_j)|$. Since $\\epsilon=0.10$ is small and positive, the maximum is achieved when $\\cos(\\theta_j)=1$:\n$$ \\max |1+2\\epsilon\\cos(\\theta_j)| = 1+2\\epsilon $$\nThe maximum absolute relative error is therefore:\n$$ E_{max} = \\frac{h^2(1+2\\epsilon)}{12 R_0^2} $$\nFinally, we evaluate this expression for the given values: $R_0 = 1.3$, $h = 0.08$, and $\\epsilon = 0.10$.\n$$ E_{max} = \\frac{(0.08)^2(1+2 \\cdot 0.10)}{12 \\cdot (1.3)^2} = \\frac{0.0064 \\cdot (1.2)}{12 \\cdot 1.69} = \\frac{0.00768}{20.28} $$\n$$ E_{max} \\approx 0.000378703155... $$\nRounding to four significant figures, the predicted maximum absolute relative error is $0.0003787$.", "answer": "$$\\boxed{0.0003787}$$", "id": "3405640"}, {"introduction": "The core mechanism of the Immersed Boundary Method is the regularized delta function, a mathematical tool that smoothly communicates force and velocity between the sharp interface and the background fluid grid. The properties of this kernel directly control the accuracy and stability of the entire simulation. In this exercise [@problem_id:3405625], you will implement a procedure to construct these crucial kernels from first principles by enforcing a set of mathematical moment conditions, and then analyze how their design impacts key numerical error sources.", "problem": "You are asked to formalize and implement a construction of one-dimensional discrete regularized delta kernels for the Immersed Boundary Method (IBM), with tunable compact support and prescribed second moment, and then to quantify how the kernel’s first and second moments control two key immersed boundary errors: volume leakage and no-slip (slip velocity) error. Work in a dimensionless setting with grid spacing normalized to $h = 1$ and angles not required. All final numerical answers shall be reported as dimensionless real numbers.\n\nStart from the following foundational definitions and principles:\n\n- In the Immersed Boundary Method (IBM), coupling between Lagrangian and Eulerian variables is effected through a regularized Dirac delta kernel. In one dimension, for a point at location $X$, interpolation and spreading are defined via weights $w_k(s)$ associated with grid nodes $x_k = k$, where $s \\in [0,1)$ is the fractional shift locating $X$ between two grid nodes (for multi-dimensional problems, tensor products of one-dimensional kernels are used, but this problem is one-dimensional).\n- A discrete regularized delta kernel of support half-width $m \\in \\mathbb{N}$ is a set of weights $\\{w_k(s)\\}_{k=-m}^{m}$ depending on the shift $s \\in [0,1)$, such that the following discrete moment conditions up to order two about the local coordinate $r_k(s) = k - s$ are imposed:\n  1. Zeroth-moment (partition of unity): $\\sum_{k=-m}^{m} w_k(s) = 1$.\n  2. First-moment (linear consistency): $\\sum_{k=-m}^{m} r_k(s)\\, w_k(s) = 0$.\n  3. Second-moment (prescribed smoothing width): $\\sum_{k=-m}^{m} r_k(s)^2\\, w_k(s) = c_2$, where $c_2 > 0$ is a given parameter controlling the kernel’s second central moment (and hence its smoothing width).\n\nYour construction requirement is:\n\n- For any chosen support half-width $m$ and target second moment $c_2$, and for any shift $s \\in [0,1)$, construct the weight vector $w(s) \\in \\mathbb{R}^{2m+1}$ that has minimal Euclidean norm among all vectors that satisfy the three linear constraints above. In symbols, for each $s$, solve\n  $$\n  \\min_{w \\in \\mathbb{R}^{2m+1}} \\tfrac{1}{2}\\Vert w \\Vert_2^2 \\quad \\text{subject to} \\quad\n  \\sum_{k=-m}^{m} w_k = 1, \\;\n  \\sum_{k=-m}^{m} (k - s) w_k = 0, \\;\n  \\sum_{k=-m}^{m} (k - s)^2 w_k = c_2.\n  $$\n  This defines a family of kernels $\\{w_k(s; m, c_2)\\}$ parameterized by $(m, c_2)$.\n\nDefine diagnostics that quantify the two IBM errors using only the moment information of the constructed kernel:\n\n- Volume leakage proxy: For a discrete scheme that preserves incompressibility in the continuum, discrete volume leakage due to the kernel arises from violation of the first-moment condition under interpolation/spreading. Define the first-moment defect at shift $s$ by\n  $\n  M_1(s; m, c_2) = \\sum_{k=-m}^{m} (k - s)\\, w_k(s; m, c_2).\n  $\n  The leakage diagnostic is the shift-wise worst-case magnitude over a set of representative shifts $\\mathcal{S}$:\n  $\n  L(m, c_2) = \\max_{s \\in \\mathcal{S}} \\left| M_1(s; m, c_2) \\right|.\n  $\n\n- No-slip error proxy: For a smooth velocity field $u(x)$, the interpolation error at a Lagrangian point $X$ has a Taylor expansion whose leading nonvanishing term, under the zeroth- and first-moment conditions, is proportional to the second central moment of the kernel. Define\n  $\n  M_2(s; m, c_2) = \\sum_{k=-m}^{m} (k - s)^2\\, w_k(s; m, c_2),\n  $\n  and quantify the no-slip error amplitude by the shift-averaged second moment\n  $\n  E(m, c_2) = \\frac{1}{|\\mathcal{S}|} \\sum_{s \\in \\mathcal{S}} M_2(s; m, c_2).\n  $\n\nUse the following discrete set of representative shifts:\n$\n\\mathcal{S} = \\{ 0.0, \\; 0.25, \\; 0.5, \\; 0.75 \\}.\n$\n\nProgram requirements:\n\n1. Implement the minimal-norm construction per shift $s \\in \\mathcal{S}$ and per parameter pair $(m, c_2)$ using only linear algebra. There is no need to simulate a full fluid solver.\n2. For each test case listed below, compute the pair $\\big(L(m, c_2), E(m, c_2)\\big)$, as defined above, using the shifts in $\\mathcal{S}$.\n3. Aggregate and print the results for all test cases as a single line, a comma-separated list of Python literals, where each element is a two-element list $[L, E]$ in the same order as the test cases.\n\nTest suite (each case is a pair $(m, c_2)$):\n\n- Case 1: $(m, c_2) = (1, 0.3)$\n- Case 2: $(m, c_2) = (1, 1.0)$\n- Case 3: $(m, c_2) = (2, 0.5)$\n- Case 4: $(m, c_2) = (2, 1.5)$\n- Case 5: $(m, c_2) = (3, 2.0)$\n\nFinal output format:\n\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each result must be a two-element list $[L, E]$ for the corresponding test case, in the same order as above. For example, a valid output format for three cases would look like\n  $\n  [[L_1,E_1],[L_2,E_2],[L_3,E_3]].\n  $\n- All $L$ and $E$ values must be printed as decimal floating-point numbers.\n\nThere are no physical units in this problem; all quantities are dimensionless. Angles are not used. Answers must be real numbers. The problem is fully self-contained and requires only numerical linear algebra and summations as described above.", "solution": "The user has provided a problem that requires the construction of discrete regularized delta kernels for the Immersed Boundary Method (IBM) and the subsequent analysis of numerical errors associated with these kernels.\n\n### Step 1: Problem Validation\n\n**Extracted Givens:**\n- **Kernel Construction:** For a given support half-width $m \\in \\mathbb{N}$ and target second moment $c_2 > 0$, the kernel weights $w_k(s)$ for a fractional shift $s \\in [0,1)$ are determined by solving the constrained optimization problem:\n  $$\n  \\min_{w \\in \\mathbb{R}^{2m+1}} \\tfrac{1}{2}\\Vert w \\Vert_2^2\n  $$\n  subject to the linear constraints:\n  1.  Zeroth moment: $\\sum_{k=-m}^{m} w_k = 1$\n  2.  First moment: $\\sum_{k=-m}^{m} (k - s) w_k = 0$\n  3.  Second moment: $\\sum_{k=-m}^{m} (k - s)^2 w_k = c_2$\n\n- **Error Diagnostics:**\n  - **Volume Leakage Proxy, $L(m, c_2)$:** The maximum absolute value of the first moment defect, $M_1(s) = \\sum_{k=-m}^{m} (k - s)\\, w_k(s)$, over a set of shifts $\\mathcal{S}$.\n    $$\n    L(m, c_2) = \\max_{s \\in \\mathcal{S}} \\left| M_1(s; m, c_2) \\right|\n    $$\n  - **No-Slip Error Proxy, $E(m, c_2)$:** The average value of the second moment, $M_2(s) = \\sum_{k=-m}^{m} (k - s)^2\\, w_k(s)$, over the set of shifts $\\mathcal{S}$.\n    $$\n    E(m, c_2) = \\frac{1}{|\\mathcal{S}|} \\sum_{s \\in \\mathcal{S}} M_2(s; m, c_2)\n    $$\n\n- **Representative Shifts:** The set $\\mathcal{S} = \\{ 0.0, 0.25, 0.5, 0.75 \\}$.\n\n- **Test Cases $(m, c_2)$:**\n  1. $(1, 0.3)$\n  2. $(1, 1.0)$\n  3. $(2, 0.5)$\n  4. $(2, 1.5)$\n  5. $(3, 2.0)$\n\n- **Output Requirement:** A single-line printout of a list of lists, `[[L1,E1],[L2,E2],...]`.\n\n**Validation Verdict:**\n1.  **Scientifically Grounded:** The problem is based on established principles of the Immersed Boundary Method, a widely used technique in computational fluid dynamics. The concepts of regularized delta kernels, moment conditions, and error analysis are central to this field. The problem is scientifically sound.\n2.  **Well-Posed:** The core task is a convex quadratic programming problem with linear equality constraints. This problem has a unique solution, provided the constraint matrix has full row rank. The constraints are defined by polynomials of degree $0$, $1$, and $2$. For $m \\ge 1$, the number of grid points ($2m+1$) is at least $3$, which is sufficient to ensure the linear independence of the constraint vectors. Thus, the optimization problem is well-posed.\n3.  **Objective:** All terms, conditions, and parameters are defined with mathematical precision. There is no ambiguity.\n4.  **Incomplete or Contradictory Setup:** At first glance, there appears to be a contradiction in requiring the first moment to be zero by constraint, while also defining a non-trivial error metric $L(m, c_2)$ based on this same moment. However, this is resolved by interpreting the problem within the context of numerical computation. The solution for the weights $w_k$ will be found using floating-point arithmetic, which introduces small numerical errors. The diagnostics $L$ and $E$ are thus measures of how well the constraints are satisfied by the numerically computed solution. $L$ quantifies the numerical error in achieving the first-moment condition, and $E$ quantifies the average numerically-achieved second moment, which should be very close to the target $c_2$. This interpretation makes the problem consistent and meaningful from a numerical analysis perspective.\n\nThe problem is deemed **valid**.\n\n### Step 2: Principle-Based Solution Design\n\nThe problem requires solving a constrained minimization problem for the weight vector $w$. This is a classic application for the method of Lagrange multipliers.\n\n**1. Formulation of the Lagrangian**\nLet the local coordinate be $r_k(s) = k - s$. The objective is to minimize $J(w) = \\frac{1}{2} w^T w$ subject to three linear constraints. The Lagrangian $\\mathcal{L}$ is:\n$$\n\\mathcal{L}(w, \\lambda) = \\frac{1}{2} \\sum_{k=-m}^{m} w_k^2 - \\lambda_0 \\left( \\sum_{k=-m}^{m} w_k - 1 \\right) - \\lambda_1 \\left( \\sum_{k=-m}^{m} r_k w_k \\right) - \\lambda_2 \\left( \\sum_{k=-m}^{m} r_k^2 w_k - c_2 \\right)\n$$\nwhere $\\lambda_0, \\lambda_1, \\lambda_2$ are the Lagrange multipliers.\n\n**2. Deriving the Form of the Weights**\nTo find the optimal $w$, we set the partial derivative of $\\mathcal{L}$ with respect to each weight $w_j$ to zero:\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial w_j} = w_j - \\lambda_0 - \\lambda_1 r_j - \\lambda_2 r_j^2 = 0\n$$\nThis gives the functional form of the optimal weights in terms of the local coordinate $r_j$ and the unknown Lagrange multipliers:\n$$\nw_j = \\lambda_0 + \\lambda_1 r_j + \\lambda_2 r_j^2\n$$\nThe minimal-norm solution is a quadratic polynomial in the local coordinate.\n\n**3. Solving for the Lagrange Multipliers**\nWe substitute this expression for $w_k$ back into the three constraint equations:\n1.  $\\sum_{k=-m}^{m} (\\lambda_0 + \\lambda_1 r_k + \\lambda_2 r_k^2) = 1$\n2.  $\\sum_{k=-m}^{m} r_k (\\lambda_0 + \\lambda_1 r_k + \\lambda_2 r_k^2) = 0$\n3.  $\\sum_{k=-m}^{m} r_k^2 (\\lambda_0 + \\lambda_1 r_k + \\lambda_2 r_k^2) = c_2$\n\nLet $S_p = \\sum_{k=-m}^{m} r_k^p$ be the $p$-th moment of the grid locations relative to the shift $s$. The above equations form a $3 \\times 3$ linear system for the vector of Lagrange multipliers $\\lambda = [\\lambda_0, \\lambda_1, \\lambda_2]^T$:\n$$\n\\begin{pmatrix}\nS_0 & S_1 & S_2 \\\\\nS_1 & S_2 & S_3 \\\\\nS_2 & S_3 & S_4\n\\end{pmatrix}\n\\begin{pmatrix}\n\\lambda_0 \\\\\n\\lambda_1 \\\\\n\\lambda_2\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 \\\\\n0 \\\\\nc_2\n\\end{pmatrix}\n$$\nThis system can be solved for $\\lambda$ using standard numerical linear algebra libraries.\n\n**4. Algorithmic Implementation**\nFor each test case $(m, c_2)$:\n1.  Initialize empty lists to store the computed moments $M_1(s)$ and $M_2(s)$ for each shift.\n2.  Iterate through each shift $s \\in \\mathcal{S} = \\{0.0, 0.25, 0.5, 0.75\\}$.\n3.  For each $s$:\n    a. Define the integer grid indices $k$ from $-m$ to $m$.\n    b. Compute the local coordinates $r_k = k - s$.\n    c. Compute the power sums $S_p$ for $p = 0, 1, 2, 3, 4$.\n    d. Construct the $3 \\times 3$ moment matrix $M_S$ and the right-hand side vector $b = [1, 0, c_2]^T$.\n    e. Solve the linear system $M_S \\lambda = b$ to find the Lagrange multipliers $\\lambda_0, \\lambda_1, \\lambda_2$.\n    f. Construct the weight vector $w$ using the formula $w_k = \\lambda_0 + \\lambda_1 r_k + \\lambda_2 r_k^2$.\n    g. Using this numerically computed vector $w$, calculate the moments $M_1(s) = \\sum r_k w_k$ and $M_2(s) = \\sum r_k^2 w_k$.\n    h. Store the computed $M_1(s)$ and $M_2(s)$.\n4.  After iterating through all shifts, compute the final diagnostics:\n    - $L(m, c_2) = \\max_{s \\in \\mathcal{S}} |M_1(s)|$\n    - $E(m, c_2) = \\text{mean}(\\{M_2(s) \\mid s \\in \\mathcal{S}\\})$\n5.  Store the pair $[L, E]$ as the result for the current test case.\n6.  After all test cases are processed, format the list of results into the specified string format.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs discrete regularized delta kernels and computes error diagnostics.\n\n    This function iterates through a set of test cases, each defined by a\n    support half-width `m` and a target second moment `c2`. For each case,\n    it computes kernel weights for a series of fractional shifts `s` by solving\n    a constrained optimization problem (minimum norm solution satisfying three\n    moment conditions).\n\n    The solution is found using the method of Lagrange multipliers, which results\n    in a 3x3 linear system for the multipliers. Once the weights are found,\n    two diagnostic quantities, L (volume leakage proxy) and E (no-slip error\n    proxy), are computed based on the numerical fidelity of the first and\n    second moments of the constructed kernel. The results for all test cases\n    are then printed in the specified format.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1, 0.3),\n        (1, 1.0),\n        (2, 0.5),\n        (2, 1.5),\n        (3, 2.0),\n    ]\n\n    # Define the discrete set of representative shifts.\n    shifts = np.array([0.0, 0.25, 0.5, 0.75])\n\n    results = []\n    for m, c2 in test_cases:\n        m1_values_for_case = []\n        m2_values_for_case = []\n        \n        for s in shifts:\n            # Step 1: Define grid indices and local coordinates r_k = k - s\n            k = np.arange(-m, m + 1)\n            r = k - s\n\n            # Step 2: Compute power sums S_p = sum(r_k^p) for p=0..4\n            S = np.zeros(5)\n            for p in range(5):\n                S[p] = np.sum(r**p)\n\n            # Step 3: Construct and solve the 3x3 linear system for the Lagrange multipliers.\n            # The system is M_S * lambda = b, where M_S is the moment matrix.\n            M_S = np.array([\n                [S[0], S[1], S[2]],\n                [S[1], S[2], S[3]],\n                [S[2], S[3], S[4]]\n            ])\n            b = np.array([1.0, 0.0, c2])\n\n            lambdas = np.linalg.solve(M_S, b)\n\n            # Step 4: Construct the weights w_k using the solved multipliers.\n            # w_k = lambda_0 + lambda_1*r_k + lambda_2*r_k^2\n            w = lambdas[0] + lambdas[1] * r + lambdas[2] * r**2\n\n            # Step 5: Compute the actual moments M1 and M2 from the constructed weights `w`.\n            # This verifies the numerical satisfaction of the constraints.\n            m1 = np.sum(r * w)\n            m2 = np.sum(r**2 * w)\n\n            m1_values_for_case.append(m1)\n            m2_values_for_case.append(m2)\n\n        # Step 6: Compute the final diagnostics L and E for the current case.\n        # L: Volume leakage proxy (worst-case first-moment defect).\n        L = np.max(np.abs(m1_values_for_case))\n        # E: No-slip error proxy (shift-averaged second moment).\n        E = np.mean(m2_values_for_case)\n\n        results.append([L, E])\n\n    # Final print statement in the exact required format.\n    # The output is a string representation of a list of lists, with no spaces.\n    # e.g., [[L1,E1],[L2,E2],...]\n    print(str(results).replace(' ', ''))\n\nsolve()\n```", "id": "3405625"}, {"introduction": "Ultimately, the immersed boundary is not an isolated object but a component within a larger fluid dynamics system. This practice [@problem_id:3405586] focuses on the critical step of coupling the boundary constraints with the fluid solver, specifically within the framework of a projection method for incompressible flow. You will assemble the core linear system that links boundary forces to the divergence-free velocity update, providing insight into the solvability and conditioning of the fully coupled problem.", "problem": "Consider the incompressible Navier–Stokes equations on the periodic square domain $\\Omega = [0,1]^2$ with periodic boundary conditions in both spatial directions. Let the spatial grid be uniform with $N \\times N$ points, grid spacing $h = 1/N$, and let the velocity field be discretized on the Eulerian grid while the constraints are enforced at Lagrangian points $\\{\\mathbf{X}_\\ell\\}_{\\ell=1}^{N_b}$ representing an immersed boundary. The immersed boundary method enforces the no-slip constraints at the Lagrangian locations via Lagrange multipliers, which are spread to the Eulerian grid by a regularized Dirac delta. In a projection method, the pressure is determined by a Poisson equation solved efficiently using the Fast Fourier Transform (FFT), and the velocity is projected to a divergence-free field.\n\nYou must formulate a discrete projection-method immersed boundary solver that couples an FFT-based pressure solve with delta-mediated constraints. The discretization must be based on the following foundational ingredients:\n\n- Incompressible flow constraint: $\\nabla \\cdot \\mathbf{u}^{n+1} = 0$.\n- Projection method update (neglecting advection and viscosity to isolate the immersed boundary coupling and incompressibility): compute an intermediate velocity $\\mathbf{u}^* = \\mathbf{u}^n + \\Delta t\\, \\mathbf{f}_{\\text{IB}}$ where $\\mathbf{f}_{\\text{IB}}$ is the force density obtained by spreading Lagrange multipliers from the immersed boundary to the grid using a regularized Dirac delta, then solve the pressure Poisson equation $\\Delta p = \\frac{1}{\\Delta t}\\nabla \\cdot \\mathbf{u}^*$ subject to periodic boundary conditions and zero-mean pressure, and finally update $\\mathbf{u}^{n+1} = \\mathbf{u}^* - \\Delta t \\nabla p$.\n- Periodic-domain Fourier-space Helmholtz–Hodge decomposition: for Fourier mode wavevector $\\mathbf{k} = (k_x, k_y)$, the divergence-free projection operator is $\\mathbf{P}(\\mathbf{k}) = \\mathbf{I} - \\frac{\\mathbf{k}\\mathbf{k}^\\top}{\\|\\mathbf{k}\\|^2}$ for $\\mathbf{k} \\neq \\mathbf{0}$, and $\\mathbf{P}(\\mathbf{0}) = \\mathbf{I}$.\n- Regularized Dirac delta for the immersed boundary method: use the four-point Peskin kernel. For one-dimensional distance $r$ in grid units, define\n$$\n\\phi(r) =\n\\begin{cases}\n\\frac{1}{8}\\left(3 - 2r + \\sqrt{1 + 4r - 4r^2}\\right), & 0 \\le r < 1, \\\\\n\\frac{1}{8}\\left(5 - 2r - \\sqrt{-7 + 12r - 4r^2}\\right), & 1 \\le r < 2, \\\\\n0, & r \\ge 2,\n\\end{cases}\n$$\nand define the two-dimensional tensor-product kernel $\\delta_h(\\mathbf{x} - \\mathbf{X}) = \\phi\\!\\left(\\frac{x - X_x}{h}\\right)\\,\\phi\\!\\left(\\frac{y - X_y}{h}\\right)/h^2$ with periodic wrapping of indices. The spreading operator maps Lagrange multipliers at Lagrangian points to forces on the Eulerian grid by $\\mathbf{f}_{\\text{IB}}(\\mathbf{x}_{ij}) = \\sum_{\\ell=1}^{N_b} \\delta_h(\\mathbf{x}_{ij} - \\mathbf{X}_\\ell)\\,\\boldsymbol{\\lambda}_\\ell$, and the interpolation operator maps Eulerian velocities to Lagrangian velocities by $\\mathbf{U}_\\ell = \\sum_{i,j} \\mathbf{u}(\\mathbf{x}_{ij})\\,\\phi\\!\\left(\\frac{x_{i} - X_{\\ell,x}}{h}\\right)\\,\\phi\\!\\left(\\frac{y_{j} - X_{\\ell,y}}{h}\\right)$.\n\nLet the Lagrange multipliers $\\{\\boldsymbol{\\lambda}_\\ell\\}$ be determined such that the no-slip constraints at the immersed boundary are satisfied after projection, i.e., $\\mathbf{U}_\\ell^{n+1} = \\mathbf{U}_b(\\mathbf{X}_\\ell)$, where $\\mathbf{U}_b$ is a prescribed boundary velocity. In the linearized setting with $\\Delta t = 1$ and $\\mathbf{u}^n = \\mathbf{0}$, the coupling of spreading, projection, and interpolation leads to a linear system for $\\{\\boldsymbol{\\lambda}_\\ell\\}$ of the form $\\mathbf{M}\\,\\boldsymbol{\\lambda} = \\mathbf{g}$, where $\\mathbf{M} = \\mathbf{J}\\,\\mathbf{P}\\,\\mathbf{S}$, $\\mathbf{S}$ is the spreading operator, $\\mathbf{P}$ is the divergence-free projection, and $\\mathbf{J}$ is the interpolation operator. Here $\\boldsymbol{\\lambda} \\in \\mathbb{R}^{2N_b}$ stacks the Lagrange multiplier components, and $\\mathbf{g} \\in \\mathbb{R}^{2N_b}$ stacks the target boundary velocities.\n\nYour tasks:\n\n1. Construct the discretized operators $\\mathbf{S}$, $\\mathbf{P}$, and $\\mathbf{J}$ as defined above on a uniform periodic grid. Use the two-dimensional FFT to implement the Fourier-space projection $\\mathbf{P}$ mode-by-mode with wave numbers $k_x = 2\\pi \\cdot \\text{fftfreq}(N, d=h)$ and $k_y = 2\\pi \\cdot \\text{fftfreq}(N, d=h)$. Treat the zero mode by $\\mathbf{P}(\\mathbf{0}) = \\mathbf{I}$.\n2. Assemble the dense matrix $\\mathbf{M} \\in \\mathbb{R}^{2N_b \\times 2N_b}$ by applying $\\mathbf{S}$ to each standard basis vector in $\\mathbb{R}^{2N_b}$, projecting with $\\mathbf{P}$, and interpolating with $\\mathbf{J}$.\n3. Analyze solvability conditions for the divergence-free velocity update in this periodic setting. Specifically:\n   - The FFT-based pressure Poisson equation is solvable if and only if the right-hand side has zero mean. In the projection method formulation, this translates to the requirement that $\\frac{1}{|\\Omega|}\\int_{\\Omega} \\nabla \\cdot \\mathbf{u}^*\\,\\mathrm{d}\\mathbf{x} = 0$, which is a condition on the intermediate velocity $\\mathbf{u}^*$ and any applied forces. Implement a discrete check of the mean divergence of $\\mathbf{u}^*$ using periodic finite differences and report the absolute value of the mean.\n   - The no-slip constraints are solvable via Lagrange multipliers if and only if the operator $\\mathbf{M}$ is full rank. Compute the singular values of $\\mathbf{M}$ and report the smallest singular value together with a boolean indicating whether $\\mathbf{M}$ has full rank within a numerical tolerance.\n\nUse the following test suite, each with $N = 32$, $\\Delta t = 1$, and $\\mathbf{u}^n = \\mathbf{0}$:\n\n- Test case A (general position, single point): $N_b = 1$, Lagrangian positions $\\mathbf{X}_1 = (0.35, 0.72)$.\n- Test case B (coincident points, potential rank deficiency): $N_b = 2$, Lagrangian positions $\\mathbf{X}_1 = (0.10, 0.90)$, $\\mathbf{X}_2 = (0.10, 0.90)$.\n- Test case C (distinct points, periodic wrap): $N_b = 2$, Lagrangian positions $\\mathbf{X}_1 = (0.99, 0.02)$, $\\mathbf{X}_2 = (0.51, 0.49)$.\n\nFor each test case, construct $\\mathbf{M}$, compute its smallest singular value $\\sigma_{\\min}$, determine full-rank solvability by checking whether all singular values exceed a tolerance (use a fixed tolerance of $10^{-10}$), and compute the absolute mean divergence of the intermediate velocity $\\mathbf{u}^*$ resulting from spreading a unit Lagrange multiplier vector applied to each column assembly (you may equivalently use the $\\mathbf{u}^*$ obtained while assembling $\\mathbf{M}$). Report, for each test case, three outputs: $\\sigma_{\\min}$ (as a floating-point number), full-rank solvability (as a boolean), and the absolute value of the mean divergence (as a floating-point number).\n\nFinal output format: Your program should produce a single line of output containing the nine results as a comma-separated list enclosed in square brackets, in the order $[\\sigma_{\\min}^{A}, \\text{full\\_rank}^{A}, |\\overline{\\nabla \\cdot \\mathbf{u}^*}|^{A}, \\sigma_{\\min}^{B}, \\text{full\\_rank}^{B}, |\\overline{\\nabla \\cdot \\mathbf{u}^*}|^{B}, \\sigma_{\\min}^{C}, \\text{full\\_rank}^{C}, |\\overline{\\nabla \\cdot \\mathbf{u}^*}|^{C}]$.", "solution": "The user-provided problem is a valid and well-posed numerical analysis task. It requires the construction and analysis of a linear operator that arises in the context of the immersed boundary method for incompressible fluid flow. The problem is scientifically grounded in the principles of computational fluid dynamics, provides a complete set of definitions and parameters, and requests a verifiable numerical output. We may therefore proceed with a formal solution.\n\nThe core of the problem is to construct the matrix $\\mathbf{M} \\in \\mathbb{R}^{2N_b \\times 2N_b}$ representing the linear mapping from Lagrangian forces $\\boldsymbol{\\lambda}$ to the resulting velocities at the Lagrangian points after projection to a divergence-free field. This matrix is defined by the composition of three operators: spreading ($\\mathbf{S}$), projection ($\\mathbf{P}$), and interpolation ($\\mathbf{J}$), such that $\\mathbf{M} = \\mathbf{JPS}$. The setting is a simplified projection method step where the intermediate velocity is determined solely by the immersed boundary force.\n\nLet the computational domain be $\\Omega = [0,1]^2$ with periodic boundary conditions, discretized on a uniform grid of $N \\times N$ points. The grid spacing is $h=1/N$. The grid points are denoted by $\\mathbf{x}_{ij} = (ih, jh)$ for $i,j \\in \\{0, 1, \\dots, N-1\\}$. The immersed boundary is represented by a set of $N_b$ Lagrangian points $\\{\\mathbf{X}_\\ell\\}_{\\ell=1}^{N_b}$.\n\n### Discretized Operators\n\n**1. Spreading Operator ($\\mathbf{S}$)**\nThe spreading operator $\\mathbf{S}$ maps the vector of $N_b$ Lagrange multipliers $\\boldsymbol{\\lambda} \\in \\mathbb{R}^{2N_b}$ to an Eulerian force density field $\\mathbf{f}_{\\text{IB}}$ on the grid. This is achieved using a regularized Dirac delta function $\\delta_h$:\n$$\n\\mathbf{f}_{\\text{IB}}(\\mathbf{x}_{ij}) = (\\mathbf{S}\\boldsymbol{\\lambda})(\\mathbf{x}_{ij}) = \\sum_{\\ell=1}^{N_b} \\delta_h(\\mathbf{x}_{ij} - \\mathbf{X}_\\ell)\\,\\boldsymbol{\\lambda}_\\ell\n$$\nThe 2D delta function is a tensor product of a 1D kernel $\\phi(r)$:\n$$\n\\delta_h(\\mathbf{x} - \\mathbf{X}) = \\frac{1}{h^2} \\phi\\left(\\frac{|x - X_x|_{\\text{periodic}}}{h}\\right)\\,\\phi\\left(\\frac{|y - X_y|_{\\text{periodic}}}{h}\\right)\n$$\nwhere $|d|_{\\text{periodic}} = \\min(|d|, 1-|d|)$ accounts for the periodic domain of length $1$. The argument $r$ to $\\phi$ is the distance in grid units. The four-point Peskin kernel $\\phi(r)$ is given by:\n$$\n\\phi(r) =\n\\begin{cases}\n\\frac{1}{8}\\left(3 - 2r + \\sqrt{1 + 4r - 4r^2}\\right), & 0 \\le r < 1 \\\\\n\\frac{1}{8}\\left(5 - 2r - \\sqrt{-7 + 12r - 4r^2}\\right), & 1 \\le r < 2 \\\\\n0, & r \\ge 2\n\\end{cases}\n$$\nThe compact support of $\\phi(r)$ for $r < 2$ implies that for each Lagrangian point $\\mathbf{X}_\\ell$, the force is spread to a local $4 \\times 4$ stencil of grid points.\n\n**2. Projection Operator ($\\mathbf{P}$)**\nThe projection operator $\\mathbf{P}$ maps a vector field to its divergence-free component. In a periodic domain, this is most efficiently implemented in Fourier space. Let $\\hat{\\mathbf{u}}(\\mathbf{k})$ be the Fourier transform of a velocity field $\\mathbf{u}(\\mathbf{x})$ at wavevector $\\mathbf{k}=(k_x, k_y)$. The projection operator in Fourier space is:\n$$\n\\mathbf{P}(\\mathbf{k}) = \\mathbf{I} - \\frac{\\mathbf{k}\\mathbf{k}^\\top}{\\|\\mathbf{k}\\|^2} \\quad \\text{for } \\mathbf{k} \\neq \\mathbf{0}\n$$\nand $\\mathbf{P}(\\mathbf{0}) = \\mathbf{I}$, where $\\mathbf{I}$ is the $2 \\times 2$ identity matrix. The wavevectors are given by $k_x = 2\\pi \\cdot \\text{fftfreq}(N, d=h)$ and $k_y = 2\\pi \\cdot \\text{fftfreq}(N, d=h)$. The numerical implementation of $\\mathbf{P}$ involves:\n- A 2D Fast Fourier Transform (FFT) of the input vector field $\\mathbf{u}^*$.\n- Element-wise application of the projection matrix $\\mathbf{P}(\\mathbf{k})$ to each Fourier mode $\\hat{\\mathbf{u}}^*(\\mathbf{k})$.\n- An inverse 2D FFT to obtain the projected field $\\mathbf{u}^{n+1}$ in physical space.\n\n**3. Interpolation Operator ($\\mathbf{J}$)**\nThe interpolation operator $\\mathbf{J}$ maps an Eulerian velocity field $\\mathbf{u}$ to velocities $\\mathbf{U}$ at the Lagrangian points. It is the discrete adjoint of the spreading operator $\\mathbf{S}$. Its action is given by:\n$$\n\\mathbf{U}_\\ell = (\\mathbf{J}\\mathbf{u})_\\ell = \\sum_{i,j=0}^{N-1} \\mathbf{u}(\\mathbf{x}_{ij})\\,\\phi\\left(\\frac{|x_j - X_{\\ell,x}|_{\\text{periodic}}}{h}\\right)\\,\\phi\\left(\\frac{|y_i - X_{\\ell,y}|_{\\text{periodic}}}{h}\\right)\n$$\nAs with spreading, this sum is computationally restricted to the $4 \\times 4$ stencil around each $\\mathbf{X}_\\ell$.\n\n### Matrix Assembly and Solvability Analysis\nThe matrix $\\mathbf{M}$ is assembled column by column. The $k$-th column of $\\mathbf{M}$ is the result of applying the operator sequence $\\mathbf{JPS}$ to the $k$-th standard basis vector $\\mathbf{e}_k \\in \\mathbb{R}^{2N_b}$.\nFor each $k \\in \\{1, \\dots, 2N_b\\}$:\n1.  Set $\\boldsymbol{\\lambda} = \\mathbf{e}_k$.\n2.  Compute $\\mathbf{u}^* = \\mathbf{S}\\boldsymbol{\\lambda}$, which corresponds to the intermediate velocity since $\\mathbf{u}^n=\\mathbf{0}$ and $\\Delta t=1$.\n3.  Compute $\\mathbf{u}_{\\text{proj}} = \\mathbf{P}\\mathbf{u}^*$.\n4.  The $k$-th column is then $\\mathbf{m}_k = \\mathbf{J}\\mathbf{u}_{\\text{proj}}$.\n\nTwo solvability conditions are analyzed:\n1.  **Rank of $\\mathbf{M}$**: The linear system for the Lagrange multipliers, $\\mathbf{M}\\boldsymbol{\\lambda} = \\mathbf{g}$, has a unique solution if and only if $\\mathbf{M}$ is full rank. This is assessed by computing the singular values of $\\mathbf{M}$ using Singular Value Decomposition (SVD). The matrix is considered full rank if its smallest singular value, $\\sigma_{\\min}$, is greater than a numerical tolerance of $10^{-10}$. A value of $\\sigma_{\\min} \\approx 0$ indicates rank deficiency, which can occur, for instance, if Lagrangian points are coincident (Test Case B), leading to linearly dependent constraints.\n2.  **Mean Divergence**: The pressure Poisson equation $\\Delta p = \\frac{1}{\\Delta t}\\nabla \\cdot \\mathbf{u}^*$ with periodic boundary conditions is solvable if and only if the right-hand side has zero mean, i.e., $\\int_{\\Omega} \\nabla \\cdot \\mathbf{u}^* d\\mathbf{x} = 0$. By the divergence theorem, this is automatically satisfied for a periodic domain. Discretely, this property should hold up to numerical precision. We verify this by computing the mean of the discrete divergence of $\\mathbf{u}^*$ using a second-order central difference scheme on the periodic grid:\n   $$\n   (\\nabla_h \\cdot \\mathbf{u}^*)_{ij} = \\frac{u^*_x(x_{i,j+1}) - u^*_x(x_{i,j-1})}{2h} + \\frac{u^*_y(x_{i+1,j}) - u^*_y(x_{i-1,j})}{2h}\n   $$\n   (with indices taken modulo $N$). The absolute value of the mean of this quantity, $|\\overline{\\nabla_h \\cdot \\mathbf{u}^*}|$, is reported. We expect this value to be close to machine precision.\n\nThe implementation will proceed by constructing these operators and performing the analysis for each specified test case.", "answer": "```python\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Constructs and analyzes the immersed boundary operator M for three test cases.\n    \"\"\"\n\n    def phi(r_in):\n        \"\"\"\n        Computes the four-point Peskin kernel phi(r) for r in grid units.\n        r_in is expected to be a numpy array of non-negative distances.\n        \"\"\"\n        r = np.asarray(r_in)\n        result = np.zeros_like(r, dtype=float)\n\n        # Condition for 0 <= r < 1\n        cond1 = r < 1\n        r1 = r[cond1]\n        arg_sqrt1 = 1.0 + 4.0 * r1 - 4.0 * r1**2\n        arg_sqrt1[arg_sqrt1 < 0] = 0.0 # Guard against floating point error\n        result[cond1] = 0.125 * (3.0 - 2.0 * r1 + np.sqrt(arg_sqrt1))\n\n        # Condition for 1 <= r < 2\n        cond2 = (r >= 1) & (r < 2)\n        r2 = r[cond2]\n        arg_sqrt2 = -7.0 + 12.0 * r2 - 4.0 * r2**2\n        arg_sqrt2[arg_sqrt2 < 0] = 0.0 # Guard against floating point error\n        result[cond2] = 0.125 * (5.0 - 2.0 * r2 - np.sqrt(arg_sqrt2))\n\n        return result\n\n    # --- Problem setup ---\n    test_suite = [\n        {'name': 'A', 'X': [(0.35, 0.72)]},\n        {'name': 'B', 'X': [(0.10, 0.90), (0.10, 0.90)]},\n        {'name': 'C', 'X': [(0.99, 0.02), (0.51, 0.49)]},\n    ]\n\n    N = 32\n    h = 1.0 / N\n    \n    # --- Pre-compute FFT-related quantities ---\n    k_vals = 2 * np.pi * np.fft.fftfreq(N, d=h)\n    kx, ky = np.meshgrid(k_vals, k_vals)\n    k_norm_sq = kx**2 + ky**2\n    # Inverse of k_norm_sq, handling the k=0 singularity\n    k_norm_sq_inv = np.divide(1.0, k_norm_sq, out=np.zeros_like(k_norm_sq), where=k_norm_sq!=0)\n\n    all_results = []\n\n    for case in test_suite:\n        X_lagrangian = np.array(case['X'])\n        N_b = len(X_lagrangian)\n        dim = 2 * N_b\n\n        def spread(lambdas_flat):\n            lambdas_vec = lambdas_flat.reshape((N_b, 2))\n            f_field = np.zeros((2, N, N))\n            \n            for l_idx in range(N_b):\n                lambda_x, lambda_y = lambdas_vec[l_idx]\n                if lambda_x == 0 and lambda_y == 0:\n                    continue\n                \n                X_x, X_y = X_lagrangian[l_idx]\n                ix_center = int(np.floor(X_x / h))\n                iy_center = int(np.floor(X_y / h))\n\n                for i_offset in range(-1, 3):\n                    i = (iy_center + i_offset) % N\n                    for j_offset in range(-1, 3):\n                        j = (ix_center + j_offset) % N\n                        \n                        grid_pt_x, grid_pt_y = j * h, i * h\n                        \n                        dist_x = abs(grid_pt_x - X_x)\n                        rx = min(dist_x, 1.0 - dist_x) / h\n                        \n                        dist_y = abs(grid_pt_y - X_y)\n                        ry = min(dist_y, 1.0 - dist_y) / h\n\n                        if rx < 2.0 and ry < 2.0:\n                            delta_h_val = phi(rx) * phi(ry) / h**2\n                            f_field[0, i, j] += delta_h_val * lambda_x\n                            f_field[1, i, j] += delta_h_val * lambda_y\n            return f_field\n\n        def interpolate(u_field):\n            U_interp_list = []\n            for l_idx in range(N_b):\n                U_x, U_y = 0.0, 0.0\n                X_x, X_y = X_lagrangian[l_idx]\n                ix_center = int(np.floor(X_x / h))\n                iy_center = int(np.floor(X_y / h))\n\n                for i_offset in range(-1, 3):\n                    i = (iy_center + i_offset) % N\n                    for j_offset in range(-1, 3):\n                        j = (ix_center + j_offset) % N\n                        \n                        grid_pt_x, grid_pt_y = j * h, i * h\n                        \n                        dist_x = abs(grid_pt_x - X_x)\n                        rx = min(dist_x, 1.0 - dist_x) / h\n                        \n                        dist_y = abs(grid_pt_y - X_y)\n                        ry = min(dist_y, 1.0 - dist_y) / h\n                        \n                        if rx < 2.0 and ry < 2.0:\n                            phi_prod = phi(rx) * phi(ry)\n                            U_x += u_field[0, i, j] * phi_prod\n                            U_y += u_field[1, i, j] * phi_prod\n                            \n                U_interp_list.extend([U_x, U_y])\n            return np.array(U_interp_list)\n\n        def project(u_field):\n            u_hat = np.fft.fft2(u_field, axes=(1, 2))\n            \n            k_dot_u_hat = kx * u_hat[0] + ky * u_hat[1]\n            u_hat_proj_x = u_hat[0] - kx * k_dot_u_hat * k_norm_sq_inv\n            u_hat_proj_y = u_hat[1] - ky * k_dot_u_hat * k_norm_sq_inv\n            \n            u_hat_proj = np.array([u_hat_proj_x, u_hat_proj_y])\n            u_proj = np.fft.ifft2(u_hat_proj, axes=(1, 2)).real\n            return u_proj\n\n        # --- Assemble matrix M and perform analysis ---\n        M = np.zeros((dim, dim))\n        mean_div = 0.0\n\n        for k in range(dim):\n            lambda_k = np.zeros(dim)\n            lambda_k[k] = 1.0\n            \n            # S operator: u_star = S(lambda_k)\n            u_star = spread(lambda_k)\n            \n            # P operator\n            u_proj = project(u_star)\n            \n            # J operator\n            M[:, k] = interpolate(u_proj)\n            \n            # Compute mean divergence for the first basis vector's u_star\n            if k == 0:\n                dux_dx = (np.roll(u_star[0], shift=-1, axis=1) - np.roll(u_star[0], shift=1, axis=1)) / (2 * h)\n                duy_dy = (np.roll(u_star[1], shift=-1, axis=0) - np.roll(u_star[1], shift=1, axis=0)) / (2 * h)\n                div_u_star = dux_dx + duy_dy\n                mean_div = np.abs(np.mean(div_u_star))\n\n        if dim > 0:\n            singular_values = linalg.svd(M, compute_uv=False)\n            sigma_min = np.min(singular_values)\n            is_full_rank = np.all(singular_values > 1e-10)\n        else: # Should not be reached by test cases\n            sigma_min = np.nan\n            is_full_rank = True\n\n        all_results.extend([sigma_min, is_full_rank, mean_div])\n    \n    # --- Format and print output ---\n    output_str_parts = []\n    for item in all_results:\n        if isinstance(item, bool):\n            output_str_parts.append(str(item).lower())\n        else:\n            output_str_parts.append(f\"{item:.12g}\")\n    print(f\"[{','.join(output_str_parts)}]\")\n\nsolve()\n```", "id": "3405586"}]}