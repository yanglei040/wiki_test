{"hands_on_practices": [{"introduction": "The heart of the Fast Marching Method (FMM) is the local update rule, which solves a discretized version of the Eikonal equation using information from neighboring points that the front has already passed. This exercise grounds your understanding in the upwind principle by having you derive this rule and the critical decision logic that chooses between a one-dimensional and a two-dimensional update. Mastering this core calculation is the first step toward a full and correct implementation of the FMM.", "problem": "Consider the isotropic Eikonal equation $|\\nabla T(\\mathbf{x})| = 1/f(\\mathbf{x})$, where $T$ is the arrival time of a front propagating with speed $f(\\mathbf{x})$. In the Fast Marching Method (FMM), the tentative update at a grid node $(i,j)$ is computed using an upwind Godunov discretization with equal grid spacing $h$ in both directions, based on the already accepted neighboring arrival times along the coordinate axes. Let the minimum accepted arrival times along the $x$- and $y$-directions be $a$ and $b$, respectively. Assume the monotonicity constraint $T \\geq \\max\\{a,b\\}$ must hold at the tentative update.\n\nStarting from the Eikonal equation and using the upwind principle, derive the local discrete relation that $T$ must satisfy in terms of $a$, $b$, $h$, and $f$, and from this relation deduce the decision logic for whether the two-dimensional update or the one-dimensional update is admissible. Then, apply your logic to compute the tentative update $T$ at the node for the values $a=0.35$, $b=0.50$, $h=0.01$, and a constant speed $f=1.8$. Express your final answer as a single number. No rounding is required.", "solution": "The problem statement is evaluated as scientifically grounded, well-posed, and objective. It is a standard problem in the numerical solution of partial differential equations, specifically concerning the Fast Marching Method for the Eikonal equation. The provided data are sufficient and consistent for a unique solution. Therefore, the problem is deemed valid and a full solution is presented below.\n\nThe isotropic Eikonal equation is given by\n$$ |\\nabla T(\\mathbf{x})|^2 = \\frac{1}{f(\\mathbf{x})^2} $$\nwhere $T(\\mathbf{x})$ is the arrival time at position $\\mathbf{x}$ and $f(\\mathbf{x})$ is the propagation speed. In a two-dimensional Cartesian grid with uniform spacing $h$, this equation can be written as\n$$ \\left(\\frac{\\partial T}{\\partial x}\\right)^2 + \\left(\\frac{\\partial T}{\\partial y}\\right)^2 = \\frac{1}{f^2} $$\nThe Fast Marching Method (FMM) uses an upwind Godunov scheme to discretize the spatial derivatives. The upwind principle ensures that information propagates from smaller arrival times to larger ones. At a grid node $(i,j)$ where we wish to compute the tentative arrival time $T$, we use the already accepted arrival times of its neighbors. Let $a$ and $b$ be the minimum accepted arrival times along the $x$ and $y$ coordinate directions, respectively. The upwind discretization for the partial derivatives is based on the idea that for the front to advance, the new time $T$ must be greater than the time at the neighbors from which the front is propagating. The general form of the first-order upwind discretization is:\n$$ \\left(\\max\\left(0, \\frac{T-a}{h}\\right)\\right)^2 + \\left(\\max\\left(0, \\frac{T-b}{h}\\right)\\right)^2 = \\frac{1}{f^2} $$\nHere, we have simplified the notation by directly using $a$ and $b$ as the relevant upwind neighbor values. The problem states the monotonicity constraint $T \\ge \\max\\{a, b\\}$, which implies that both $(T-a)$ and $(T-b)$ should be non-negative.\n\nFirst, let's derive the local discrete relation assuming a two-dimensional (2D) update is admissible. This assumption means the front propagates to the node $(i,j)$ using information from both the $x$ and $y$ directions. In this case, both terms inside the $\\max$ functions are positive, and the equation simplifies to:\n$$ \\left(\\frac{T-a}{h}\\right)^2 + \\left(\\frac{T-b}{h}\\right)^2 = \\frac{1}{f^2} $$\nThis equation is the local discrete relation that $T$ must satisfy for a 2D update. We can solve this quadratic equation for $T$:\n$$ (T-a)^2 + (T-b)^2 = \\frac{h^2}{f^2} $$\n$$ T^2 - 2aT + a^2 + T^2 - 2bT + b^2 = \\frac{h^2}{f^2} $$\n$$ 2T^2 - 2(a+b)T + \\left(a^2 + b^2 - \\frac{h^2}{f^2}\\right) = 0 $$\nUsing the quadratic formula $T = \\frac{-B \\pm \\sqrt{B^2 - 4AC}}{2A}$ with $A=2$, $B=-2(a+b)$, and $C = a^2+b^2 - (h/f)^2$:\n$$ T = \\frac{2(a+b) \\pm \\sqrt{4(a+b)^2 - 8\\left(a^2+b^2 - \\frac{h^2}{f^2}\\right)}}{4} $$\n$$ T = \\frac{a+b \\pm \\sqrt{(a+b)^2 - 2(a^2+b^2) + \\frac{2h^2}{f^2}}}{2} $$\n$$ T = \\frac{a+b \\pm \\sqrt{a^2+2ab+b^2 - 2a^2-2b^2 + \\frac{2h^2}{f^2}}}{2} $$\n$$ T = \\frac{a+b \\pm \\sqrt{\\frac{2h^2}{f^2} - (a-b)^2}}{2} $$\nSince we require $T \\ge \\max\\{a, b\\}$, we must choose the larger root, corresponding to the `+` sign:\n$$ T_{2D} = \\frac{a+b + \\sqrt{\\frac{2h^2}{f^2} - (a-b)^2}}{2} $$\nThis is the candidate solution for a 2D update.\n\nNext, we deduce the decision logic. A real solution for $T_{2D}$ exists only if the discriminant is non-negative: $\\frac{2h^2}{f^2} - (a-b)^2 \\ge 0$, which implies $|a-b| \\le \\frac{\\sqrt{2}h}{f}$. More importantly, the assumption that this 2D update is valid depends on the result satisfying the monotonicity constraint $T \\ge \\max\\{a,b\\}$. Let's assume without loss of generality that $b \\ge a$, so $\\max\\{a,b\\}=b$. The condition for validity is $T_{2D} \\ge b$.\n$$ \\frac{a+b + \\sqrt{\\frac{2h^2}{f^2} - (a-b)^2}}{2} \\ge b $$\n$$ a+b + \\sqrt{\\frac{2h^2}{f^2} - (a-b)^2} \\ge 2b $$\n$$ \\sqrt{\\frac{2h^2}{f^2} - (a-b)^2} \\ge b-a $$\nSince $b-a \\ge 0$, we can square both sides:\n$$ \\frac{2h^2}{f^2} - (a-b)^2 \\ge (b-a)^2 $$\n$$ \\frac{2h^2}{f^2} \\ge 2(a-b)^2 $$\n$$ \\frac{h^2}{f^2} \\ge (a-b)^2 \\implies \\frac{h}{f} \\ge |a-b| $$\nThis provides the decision logic. The 2D update is admissible if and only if $|a-b| \\le \\frac{h}{f}$.\n\nIf this condition is not met, i.e., $|a-b|  \\frac{h}{f}$, then the 2D formula would yield $T_{2D}  \\max\\{a,b\\}$, violating the causality principle. This implies that our initial assumption was wrong; specifically, the update is not influenced by both neighbors. The general discrete equation must be used, where one of the $\\max$ terms becomes zero. If $b \\ge a$ and $|a-b|  h/f$, then $T  b$, so $\\max(0, (T-b)/h) = 0$. The governing equation reduces to a one-dimensional (1D) update determined by the neighbor with the smaller arrival time, in this case $a$:\n$$ \\left(\\frac{T-a}{h}\\right)^2 + 0 = \\frac{1}{f^2} $$\nSolving for $T$ yields:\n$$ T_{1D} = a + \\frac{h}{f} $$\nMore generally, the 1D update uses the minimum of the neighbor values: $T = \\min(a,b) + \\frac{h}{f}$.\n\nThe decision logic is as follows:\n1.  Calculate $|a-b|$ and $\\frac{h}{f}$.\n2.  If $|a-b| \\le \\frac{h}{f}$, the update is 2D and $T = \\frac{a+b + \\sqrt{2(h/f)^2 - (a-b)^2}}{2}$.\n3.  If $|a-b|  \\frac{h}{f}$, the update is 1D and $T = \\min(a,b) + \\frac{h}{f}$.\n\nNow, we apply this logic to the given values: $a=0.35$, $b=0.50$, $h=0.01$, and $f=1.8$.\nWe express these values as exact fractions to avoid rounding errors:\n$a = 0.35 = \\frac{35}{100} = \\frac{7}{20}$\n$b = 0.50 = \\frac{50}{100} = \\frac{1}{2}$\n$h = 0.01 = \\frac{1}{100}$\n$f = 1.8 = \\frac{18}{10} = \\frac{9}{5}$\n\nFirst, we check the condition for the decision logic:\n$$ |a-b| = \\left|\\frac{7}{20} - \\frac{1}{2}\\right| = \\left|\\frac{7}{20} - \\frac{10}{20}\\right| = \\left|-\\frac{3}{20}\\right| = \\frac{3}{20} $$\n$$ \\frac{h}{f} = \\frac{1/100}{9/5} = \\frac{1}{100} \\cdot \\frac{5}{9} = \\frac{5}{900} = \\frac{1}{180} $$\nNow we compare $|a-b|$ with $\\frac{h}{f}$:\n$$ \\frac{3}{20} \\quad \\text{vs.} \\quad \\frac{1}{180} $$\nTo compare, we can use a common denominator or cross-multiply:\n$$ 3 \\times 180 = 540 $$\n$$ 20 \\times 1 = 20 $$\nSince $540  20$, we have $\\frac{3}{20}  \\frac{1}{180}$.\nThe condition $|a-b| \\le \\frac{h}{f}$ is false.\n\nTherefore, the one-dimensional (1D) update is admissible. The tentative update $T$ is computed using the smaller of the two neighbor values, which is $T_{\\min} = \\min(a,b) = a = \\frac{7}{20}$.\n$$ T = T_{\\min} + \\frac{h}{f} $$\n$$ T = \\frac{7}{20} + \\frac{1}{180} $$\nTo add these fractions, we find a common denominator, which is $180$:\n$$ T = \\frac{7 \\times 9}{20 \\times 9} + \\frac{1}{180} = \\frac{63}{180} + \\frac{1}{180} = \\frac{64}{180} $$\nFinally, we simplify the fraction:\n$$ T = \\frac{64 \\div 4}{180 \\div 4} = \\frac{16}{45} $$\nThe tentative update for the arrival time $T$ at the node is $\\frac{16}{45}$.", "answer": "$$ \\boxed{\\frac{16}{45}} $$", "id": "3391176"}, {"introduction": "Building on the local update rule from the previous practice [@problem_id:3391176], this exercise guides you through assembling the complete FMM algorithm. You will combine the update logic with a priority queue data structure, which orchestrates the advancement of the wavefront in a causal, ordered manner. Implementing the method and verifying it against a known analytic solution by computing error norms like $L^1$, $L^2$, and $L^\\infty$ is a fundamental practice in developing reliable numerical software.", "problem": "Construct a fully specified analytic benchmark for the Eikonal Partial Differential Equation (PDE) arising in travel-time or distance computation, and design a program to quantify the convergence of the Fast Marching Method (FMM) as the grid size tends to zero.\n\nYou are to consider the Eikonal PDE\n$$\n\\|\\nabla T(x,y)\\| = \\frac{1}{f},\n$$\non the square domain $[0,1]^2$, with a single point-source boundary condition $T(x_0,y_0)=0$. Assume a constant positive speed $f0$, so that the viscosity solution is the travel-time function\n$$\nT(x,y) = \\frac{\\sqrt{(x-x_0)^2+(y-y_0)^2}}{f}.\n$$\nThis benchmark is entirely dimensionless; no physical units are to be reported.\n\nYour tasks are:\n\n- Derive, from first principles, how to discretize the Eikonal PDE with a monotone upwind finite difference scheme suitable for use within the Fast Marching Method (FMM), making explicit the local update formula that arises from the discrete form of the Hamilton–Jacobi equation when using the $4$-neighborhood.\n- Specify how to approximate the continuous $L^1$, $L^2$, and $L^\\infty$ norms of the error $e_h=T_h - T$ between the numerical solution $T_h$ on a uniform Cartesian grid of spacing $h$ and the analytic solution $T$:\n  - The grid consists of $N\\times N$ nodes with spacing $h=\\frac{1}{N-1}$ at coordinates $(x_i,y_j)=(ih,jh)$ for $i,j\\in\\{0,\\dots,N-1\\}$.\n  - The discrete approximations must be\n    $$\n    E_1(h) = h^2 \\sum_{i=0}^{N-1}\\sum_{j=0}^{N-1} |e_h(x_i,y_j)|,\\quad\n    E_2(h) = \\left(h^2 \\sum_{i=0}^{N-1}\\sum_{j=0}^{N-1} e_h(x_i,y_j)^2\\right)^{1/2},\\quad\n    E_\\infty(h) = \\max_{0\\le i,j\\le N-1}|e_h(x_i,y_j)|.\n    $$\n- Implement the FMM with the monotone upwind update for the case of constant $f$. Use a single point source where the boundary condition $T=0$ is enforced at a single grid node. Use the following analytic benchmarks:\n  - Center source: $(x_0,y_0)=(\\tfrac{1}{2},\\tfrac{1}{2})$. This is exactly a grid node when $N$ is odd.\n  - Corner source: $(x_0,y_0)=(0,0)$. This is always a grid node for any $N$.\n- For each case, compute the numerical solution $T_h$ and the analytic solution $T$, then evaluate $E_1(h)$, $E_2(h)$, and $E_\\infty(h)$.\n\nProgram requirements:\n\n- The program must be a single, complete, runnable script that produces the errors for a fixed test suite. There is no user input.\n- The discrete FMM must use the $4$-neighborhood and the monotone quadratic update that arises from the discrete Eikonal equation in two spatial dimensions with constant $f$.\n- Use the following test suite of parameter triples $(N,f,\\text{source})$:\n  - $(33,\\,1.0,\\,\\text{center})$\n  - $(65,\\,1.0,\\,\\text{center})$\n  - $(129,\\,1.0,\\,\\text{center})$\n  - $(33,\\,0.7,\\,\\text{center})$\n  - $(65,\\,0.7,\\,\\text{center})$\n  - $(65,\\,1.0,\\,\\text{corner})$\n- For each test case, output a list of three real numbers $[E_1(h),E_2(h),E_\\infty(h)]$.\n- Final output format: Your program should produce a single line of output containing the results as a comma-separated list of lists, in the order given above, enclosed in square brackets, for example\n  $$\n  [[E_1^{(1)},E_2^{(1)},E_\\infty^{(1)}],[E_1^{(2)},E_2^{(2)},E_\\infty^{(2)}],\\dots]\n  $$\n  where each $E$ is a real number. It is acceptable to round all real numbers to a fixed number of decimal places; do not include any units or additional text.\n\nScientific and algorithmic bases you must use:\n\n- The Eikonal PDE $\\|\\nabla T\\|=\\frac{1}{f}$ with constant $f$ and a single point-source Dirichlet condition has the viscosity solution $T(x,y)=\\frac{\\sqrt{(x-x_0)^2+(y-y_0)^2}}{f}$.\n- The monotone upwind finite difference approximation in two spatial dimensions using the $4$-neighborhood yields a local update that solves a quadratic equation consistent with the discrete form of the Eikonal PDE.\n- The Fast Marching Method (FMM) advances the accepted front in order of increasing $T_h$, using a min-heap or equivalent priority queue to maintain trial points.\n\nYour implementation must be general and based solely on these principles, without relying on any special-case formulas beyond the above foundational facts. The final program must compute and print the error norms as specified for the test suite. The output must be a single line in the exact format described above. No angles or percentages are involved in this problem; all quantities are dimensionless.", "solution": "The user-provided problem is a valid and well-posed benchmark for a numerical method. It requires the derivation, implementation, and verification of the Fast Marching Method (FMM) for the Eikonal equation. The problem is scientifically grounded in the theory of Hamilton-Jacobi equations and their numerical solution, provides a complete and consistent set of givens, and specifies a clear, objective task.\n\nThe solution proceeds in two parts: first, a principled derivation of the numerical scheme, and second, an implementation of the FMM algorithm to solve the benchmark problem.\n\n### 1. The Eikonal Equation and its Discretization\n\nThe problem concerns the Eikonal Partial Differential Equation (PDE) on a domain $\\Omega = [0,1]^2$:\n$$\n\\|\\nabla T(x,y)\\| = \\frac{1}{f}\n$$\nwhere $T(x,y)$ is the travel-time function, and $f  0$ is the constant speed of propagation. Let $s = 1/f$ be the slowness. The PDE can be written in Cartesian coordinates as:\n$$\n\\left(\\frac{\\partial T}{\\partial x}\\right)^2 + \\left(\\frac{\\partial T}{\\partial y}\\right)^2 = s^2\n$$\nThis is a non-linear, static Hamilton-Jacobi equation. The problem specifies a single point-source boundary condition, $T(x_0, y_0) = 0$, for which the unique viscosity solution is the Euclidean distance to the source scaled by the slowness:\n$$\nT(x,y) = s \\sqrt{(x-x_0)^2 + (y-y_0)^2}\n$$\nTo solve this numerically, we introduce a uniform Cartesian grid over the domain $\\Omega$ with $N \\times N$ nodes $(x_i, y_j) = (ih, jh)$, where $i,j \\in \\{0, 1, \\dots, N-1\\}$ and the grid spacing is $h = 1/(N-1)$. Let $T_{i,j}$ denote the numerical approximation of $T(x_i, y_j)$.\n\nThe Fast Marching Method requires a monotone, upwind finite difference scheme to approximate the spatial derivatives. The \"upwind\" nature reflects causality: the value of $T$ at a point is determined by points with smaller $T$ values, from which the \"wavefront\" has already passed. For a point $(i,j)$ being updated, the scheme selects from its neighbors which have already been finalized. The derivatives are approximated as:\n$$\n\\left(\\frac{\\partial T}{\\partial x}\\right)_{i,j}^2 \\approx \\left( \\max\\left( \\frac{T_{i,j} - T_{i-1,j}}{h}, \\frac{T_{i,j} - T_{i+1,j}}{h}, 0 \\right) \\right)^2 \\approx \\left( \\frac{T_{i,j} - T_x}{h} \\right)^2\n$$\n$$\n\\left(\\frac{\\partial T}{\\partial y}\\right)_{i,j}^2 \\approx \\left( \\max\\left( \\frac{T_{i,j} - T_{i,j-1}}{h}, \\frac{T_{i,j} - T_{i,j+1}}{h}, 0 \\right) \\right)^2 \\approx \\left( \\frac{T_{i,j} - T_y}{h} \\right)^2\n$$\nwhere $T_x = \\min(T_{i-1,j}, T_{i+1,j})$ and $T_y = \\min(T_{i,j-1}, T_{i,j+1})$, considering only neighbors that have been finalized. The $\\max(\\dots, 0)$ terms enforce the upwind condition, ensuring that $T_{i,j}$ is only influenced by neighbors with smaller travel times. Combining these gives the discretized Eikonal equation:\n$$\n\\left(\\frac{T_{i,j} - T_x}{h}\\right)^2 + \\left(\\frac{T_{i,j} - T_y}{h}\\right)^2 = s^2\n$$\n\n### 2. The Local Update Formula\n\nTo find a new value for $T_{i,j}$, which we denote by $u$, we must solve this equation. The values $T_x$ and $T_y$ are the minimum travel times among the already computed (\"frozen\") neighbors in the x and y directions, respectively. The equation is a quadratic equation for $u$:\n$$\n(u - T_x)^2 + (u - T_y)^2 = (hs)^2\n$$\nExpanding this gives:\n$$\nu^2 - 2uT_x + T_x^2 + u^2 - 2uT_y + T_y^2 - (hs)^2 = 0\n$$\n$$\n2u^2 - 2(T_x + T_y)u + (T_x^2 + T_y^2 - (hs)^2) = 0\n$$\nThis is of the form $au^2+bu+c=0$ with $a=2$, $b=-2(T_x+T_y)$, and $c=T_x^2+T_y^2-(hs)^2$. The solution for $u$ is given by the quadratic formula, where we take the larger root because the travel time $u$ must be greater than that of its upwind neighbors $T_x$ and $T_y$:\n$$\nu = \\frac{T_x + T_y + \\sqrt{(T_x+T_y)^2 - 2(T_x^2+T_y^2 - (hs)^2)}}{2}\n$$\nThe discriminant is $D = (T_x+T_y)^2 - 2(T_x^2+T_y^2 - (hs)^2) = 2(hs)^2 - (T_x-T_y)^2$. A real solution exists only if $D \\ge 0$, which implies $|T_x - T_y| \\le \\sqrt{2}hs$.\n\nIf this condition is not met ($D  0$), it implies that the characteristic providing the update path arrives from only one direction, not a combination of both. In this case, the update should be one-dimensional, using only the neighbor with the overall minimum travel time, say $T_1 = \\min(T_x, T_y)$. The update formula simplifies to solving $(\\frac{u-T_1}{h})^2 = s^2$, which yields $u = T_1 + hs$.\n\nThe complete update logic for a trial point based on its frozen neighbors is therefore:\n1.  Identify available frozen neighbor values, yielding $T_x$ and/or $T_y$. If only one direction provides a value (e.g., $T_x$), the update is one-dimensional: $u = T_x + hs$.\n2.  If both $T_x$ and $T_y$ are available, let $T_1 = \\min(T_x, T_y)$ and $T_2 = \\max(T_x, T_y)$.\n3.  Calculate the discriminant $D = 2(hs)^2 - (T_2 - T_1)^2$.\n4.  If $D  0$, the update is one-dimensional: $u = T_1 + hs$.\n5.  If $D \\ge 0$, the update is two-dimensional: $u = \\frac{T_1 + T_2 + \\sqrt{D}}{2}$.\n\n### 3. The Fast Marching Method (FMM)\n\nFMM is an efficient algorithm for solving the discretized Eikonal equation by systematically advancing a front in order of increasing travel time, mimicking the physics of wave propagation. It uses a priority queue to achieve its efficiency.\n\nThe algorithm classifies each grid point into one of three states:\n-   **FROZEN**: The travel time $T_{i,j}$ has been computed and is considered final.\n-   **NARROW_BAND** (or TRIAL): The point is a neighbor of at least one FROZEN point, and has a tentative travel time value. These are candidate points to be frozen next.\n-   **FAR_AWAY**: All other points, which have not yet been reached by the front. Their initial travel time is set to infinity.\n\nThe FMM algorithm proceeds as follows:\n1.  **Initialization**:\n    -   Initialize the travel time array $T$ with $\\infty$ for all points, and the state array with FAR_AWAY.\n    -   Set the travel time of the source point $(i_0, j_0)$ to $T_{i_0,j_0} = 0$.\n    -   Add the source's neighbors to a min-priority queue (implementing the NARROW_BAND). For each neighbor, calculate a tentative $T$ value using the one-dimensional update ($T_{neighbor} = 0 + hs = hs$) and update its state to NARROW_BAND.\n2.  **Marching Loop**:\n    -   While the priority queue is not empty:\n        a. Extract the point `(i,j)` with the smallest tentative travel time from the priority queue.\n        b. Change the state of `(i,j)` to FROZEN. This value is now final.\n        c. For each neighbor `(k,l)` of `(i,j)`:\n            i. If the state of `(k,l)` is FROZEN, do nothing.\n            ii. Otherwise, calculate a new tentative travel time $u_{new}$ for `(k,l)` using the local update formula, considering all its FROZEN neighbors.\n            iii. If $u_{new}$ is smaller than the current travel time $T_{k,l}$:\n                - Update $T_{k,l} = u_{new}$.\n                - Change the state of `(k,l)` to NARROW_BAND.\n                - Add `(u_new, (k,l))` to the priority queue.\n\n### 4. Error Norms\n\nAfter the FMM algorithm has converged, producing the numerical solution $T_h$ at all grid nodes, we quantify the error by comparing it to the known analytic solution $T$. The error at each node is $e_h(x_i, y_j) = T_h(x_i, y_j) - T(x_i, y_j)$. The problem specifies the computation of discrete approximations to the $L^1$, $L^2$, and $L^\\infty$ norms of the error function:\n$$\nE_1(h) = h^2 \\sum_{i=0}^{N-1}\\sum_{j=0}^{N-1} |T_{h}(x_i, y_j) - T(x_i, y_j)|\n$$\n$$\nE_2(h) = \\left(h^2 \\sum_{i=0}^{N-1}\\sum_{j=0}^{N-1} (T_{h}(x_i, y_j) - T(x_i, y_j))^2\\right)^{1/2}\n$$\n$$\nE_\\infty(h) = \\max_{0\\le i,j\\le N-1}|T_{h}(x_i, y_j) - T(x_i, y_j)|\n$$\nThese formulas correspond to a Riemann sum approximation of the continuous integrals over the domain, using the area element $\\Delta A = h^2$. The following program implements the FMM algorithm and computes these error norms for the specified test cases.", "answer": "```python\nimport numpy as np\nimport heapq\n# Scipy is specified in the requirements but not strictly needed for this implementation.\n# We import it to adhere to the specified execution environment.\nfrom scipy import version as scipy_version\n\n# Define states for FMM\n_FROZEN = 0\n_NARROW_BAND = 1\n_FAR_AWAY = 2\n\ndef solve_eikonal_fmm(N, f, source_coord):\n    \"\"\"\n    Solves the Eikonal equation using the Fast Marching Method.\n\n    Args:\n        N (int): Number of grid points along one dimension (N x N grid).\n        f (float): Constant speed.\n        source_coord (tuple): (row, col) indices of the source point.\n\n    Returns:\n        numpy.ndarray: The computed travel time map T_h.\n    \"\"\"\n    h = 1.0 / (N - 1)\n    s = 1.0 / f\n    hs = h * s\n\n    T = np.full((N, N), np.inf, dtype=np.float64)\n    states = np.full((N, N), _FAR_AWAY, dtype=np.int8)\n    \n    # Priority queue for the narrow band (min-heap)\n    # Items are (T_value, (row, col))\n    narrow_band = []\n\n    # Initialization\n    src_i, src_j = source_coord\n    T[src_i, src_j] = 0.0\n    states[src_i, src_j] = _FROZEN\n\n    # Initialize neighbors of the source\n    for i_offset, j_offset in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n        ni, nj = src_i + i_offset, src_j + j_offset\n        if 0 = ni  N and 0 = nj  N:\n            T[ni, nj] = hs\n            states[ni, nj] = _NARROW_BAND\n            heapq.heappush(narrow_band, (T[ni, nj], (ni, nj)))\n\n    # Main FMM loop\n    while narrow_band:\n        T_min, (i, j) = heapq.heappop(narrow_band)\n        \n        if states[i, j] == _FROZEN:\n            continue\n            \n        states[i, j] = _FROZEN\n\n        # Process neighbors\n        for i_offset, j_offset in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n            ni, nj = i + i_offset, j + j_offset\n\n            if 0 = ni  N and 0 = nj  N:\n                if states[ni, nj] == _FROZEN:\n                    continue\n\n                # Find minimum T values in x and y directions from frozen neighbors\n                T_x_neighbors = []\n                if ni  0 and states[ni - 1, nj] == _FROZEN:\n                    T_x_neighbors.append(T[ni - 1, nj])\n                if ni  N - 1 and states[ni + 1, nj] == _FROZEN:\n                    T_x_neighbors.append(T[ni + 1, nj])\n                \n                T_y_neighbors = []\n                if nj  0 and states[ni, nj - 1] == _FROZEN:\n                    T_y_neighbors.append(T[ni, nj - 1])\n                if nj  N - 1 and states[ni, nj + 1] == _FROZEN:\n                    T_y_neighbors.append(T[ni, nj + 1])\n\n                # Calculate new T value for the neighbor\n                T_x_min = min(T_x_neighbors) if T_x_neighbors else np.inf\n                T_y_min = min(T_y_neighbors) if T_y_neighbors else np.inf\n                \n                val = np.inf\n                if T_x_min != np.inf and T_y_min != np.inf:\n                    T1 = min(T_x_min, T_y_min)\n                    T2 = max(T_x_min, T_y_min)\n                    discriminant = 2 * hs**2 - (T2 - T1)**2\n                    if discriminant = 0:\n                        val = (T1 + T2 + np.sqrt(discriminant)) / 2.0\n                    else:\n                        val = T1 + hs\n                elif T_x_min != np.inf:\n                    val = T_x_min + hs\n                elif T_y_min != np.inf:\n                    val = T_y_min + hs\n\n                if val  T[ni, nj]:\n                    T[ni, nj] = val\n                    states[ni, nj] = _NARROW_BAND\n                    heapq.heappush(narrow_band, (val, (ni, nj)))\n    return T\n\ndef get_analytic_solution(N, f, source_pos):\n    \"\"\"\n    Computes the analytic solution on the grid.\n    \"\"\"\n    h = 1.0 / (N - 1)\n    x0, y0 = source_pos\n    x = np.linspace(0, 1, N)\n    y = np.linspace(0, 1, N)\n    xx, yy = np.meshgrid(x, y, indexing='ij')\n    \n    return np.sqrt((xx - x0)**2 + (yy - y0)**2) / f\n\ndef compute_errors(T_h, T_analytic, h):\n    \"\"\"\n    Computes E1, E2, and E_inf error norms.\n    \"\"\"\n    error = T_h - T_analytic\n    e1 = h**2 * np.sum(np.abs(error))\n    e2 = np.sqrt(h**2 * np.sum(error**2))\n    e_inf = np.max(np.abs(error))\n    return [e1, e2, e_inf]\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        (33, 1.0, 'center'),\n        (65, 1.0, 'center'),\n        (129, 1.0, 'center'),\n        (33, 0.7, 'center'),\n        (65, 0.7, 'center'),\n        (65, 1.0, 'corner'),\n    ]\n\n    results = []\n    \n    for N, f, source_type in test_cases:\n        h = 1.0 / (N - 1)\n        if source_type == 'center':\n            source_pos = (0.5, 0.5)\n            source_coord = ((N - 1) // 2, (N - 1) // 2)\n        elif source_type == 'corner':\n            source_pos = (0.0, 0.0)\n            source_coord = (0, 0)\n        else:\n            raise ValueError(\"Unknown source type\")\n\n        T_h = solve_eikonal_fmm(N, f, source_coord)\n        T_analytic = get_analytic_solution(N, f, source_pos)\n        \n        errors = compute_errors(T_h, T_analytic, h)\n        results.append(errors)\n\n    # Format output as specified: [[E1,E2,E_inf],[...],...]\n    output_str_parts = []\n    for res in results:\n        output_str_parts.append(f\"[{res[0]},{res[1]},{res[2]}]\")\n    \n    final_output = f\"[{','.join(output_str_parts)}]\"\n    print(final_output)\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3391154"}, {"introduction": "Once an implementation is verified, a more rigorous analysis of its accuracy is required. This practice introduces the grid refinement study, a standard procedure for experimentally measuring a numerical method's order of accuracy. By running your FMM code on a sequence of progressively finer grids and analyzing the trend in the error, you will confirm that the method's accuracy improves at the theoretically expected rate, a cornerstone skill in the field of numerical analysis.", "problem": "Consider the isotropic Eikonal equation, a Hamilton–Jacobi partial differential equation that models front propagation with spatially varying speed. The unknown arrival time field $T(x)$ satisfies the equation $|\\nabla T(x)| = \\frac{1}{f(x)}$, where $f(x)$ denotes the local front speed. For a constant speed $f(x) \\equiv f_0$ and a single point source at $x_s$, the solution is radially symmetric and determined by the geometry of the shortest path. For this setting, design and implement a grid refinement study to assess the numerical accuracy and observed order of accuracy of a Fast Marching Method (FMM) discretization of the Eikonal equation on uniform two-dimensional grids.\n\nYour task is to write a complete program that:\n- Implements a two-dimensional Fast Marching Method on a uniform Cartesian grid with spacing $h$ on the square domain $[0,1] \\times [0,1]$ using first-order upwind, monotone discretization. The discretization must be derived from the Eikonal equation and must respect causality via an acceptance mechanism that proceeds from smaller to larger arrival times.\n- Uses a constant speed $f(x) \\equiv f_0$ and a single point source with zero arrival time located exactly on a grid node to avoid subgrid projection error. The source location must be chosen so that it is present on all grid resolutions in the test suite.\n- Derives the analytic solution $T_{\\text{exact}}(x)$ from the governing equation and the geometry of shortest paths for the constant speed case with a point source, and uses it to compute grid-based error norms.\n\nThe grid refinement study must adhere to the following:\n- Grids: Use uniform grids with $N \\in \\{33,65,129,257\\}$ points per dimension, so the grid spacing is $h = \\frac{1}{N-1}$. This ensures that the coordinate $x = 0.5$ is always a grid node when $N$ is odd.\n- Error norms: For each $N$, compute the discrete $L_1$, $L_2$, and $L_\\infty$ error norms between the numerical solution $T_h$ and the analytic solution $T_{\\text{exact}}$ over all grid nodes. Use the discrete approximations consistent with integral norms:\n  - $L_1$ error: $E_{1}(h) = h^2 \\sum_{i,j} |T_h(x_{i,j}) - T_{\\text{exact}}(x_{i,j})|$.\n  - $L_2$ error: $E_{2}(h) = \\sqrt{h^2 \\sum_{i,j} (T_h(x_{i,j}) - T_{\\text{exact}}(x_{i,j}))^2}$.\n  - $L_\\infty$ error: $E_{\\infty}(h) = \\max_{i,j} |T_h(x_{i,j}) - T_{\\text{exact}}(x_{i,j})|$.\n- Observed order of accuracy: For a sequence of grid spacings $h_1  h_2  \\dots$, define the observed order $p$ for a given norm by the slope of the error trend in log–log space computed between successive grid levels:\n  $$p_{k} = \\frac{\\log\\left(\\frac{E(h_{k+1})}{E(h_{k})}\\right)}{\\log\\left(\\frac{h_{k+1}}{h_{k}}\\right)}.$$\n  Report a single robustness-enhanced estimate per norm by taking the median of $\\{p_{k}\\}$ across all successive pairs of grids in the test suite.\n\nTest suite specification:\n- Case A (happy path): $f_0 = 1$, source at the domain center $x_s = (0.5,0.5)$.\n- Case B (speed variation): $f_0 = 2$, source at the domain center $x_s = (0.5,0.5)$.\n- Case C (geometric edge case): $f_0 = 1$, source at the domain corner $x_s = (0,0)$.\n\nAnalytic solution requirement: You must determine $T_{\\text{exact}}(x)$ for constant $f_0$ and a single source $x_s$ from first principles using the Eikonal equation and the geometry of shortest paths. This analytic solution must be used for error computation.\n\nFinal output format:\n- For each case, compute the median observed orders for the three norms $L_1$, $L_2$, and $L_\\infty$ across the four grids. Aggregate the results for the three cases into a single list of nine floating-point numbers in the order $[p_{L_1}^{\\text{A}}, p_{L_2}^{\\text{A}}, p_{L_\\infty}^{\\text{A}}, p_{L_1}^{\\text{B}}, p_{L_2}^{\\text{B}}, p_{L_\\infty}^{\\text{B}}, p_{L_1}^{\\text{C}}, p_{L_2}^{\\text{C}}, p_{L_\\infty}^{\\text{C}}]$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,\\dots,result_9]$).\nAll quantities are dimensionless; no physical units are required. Angles are not involved. Express all final numeric outputs as floating-point numbers.", "solution": "The problem requires the implementation of a grid refinement study to determine the observed order of accuracy for a first-order Fast Marching Method (FMM) solving the Eikonal equation. The study will be conducted on a two-dimensional square domain for a constant wave speed and a single point source.\n\n### 1. Underlying Principles and Analytic Solution\n\nThe governing equation is the isotropic Eikonal equation:\n$$\n|\\nabla T(x)| = \\frac{1}{f(x)}\n$$\nwhere $T(x)$ is the arrival time field of a propagating front and $f(x)$ is the local speed of the front. In this problem, the speed is constant, $f(x) \\equiv f_0$. The equation describes the shortest travel time from a source region. With a constant speed $f_0$, the medium is homogeneous, and the shortest path between two points is a straight line. The time taken to travel this path is its Euclidean length divided by the speed.\n\nGiven a single point source at $x_s$ with an initial arrival time $T(x_s) = 0$, the arrival time at any other point $x$ is determined by the length of the shortest path from $x_s$ to $x$. For a constant speed, this path is the straight line segment connecting them. The analytic solution is therefore the Euclidean distance from the source, scaled by the slowness $S_0 = 1/f_0$:\n$$\nT_{\\text{exact}}(x) = \\frac{\\|x - x_s\\|_2}{f_0}\n$$\nFor a point $x = (x, y)$ and a source $x_s = (x_s, y_s)$, this is explicitly:\n$$\nT_{\\text{exact}}(x, y) = \\frac{\\sqrt{(x-x_s)^2 + (y-y_s)^2}}{f_0}\n$$\nThis exact solution will serve as the ground truth for computing numerical errors. It is smooth everywhere except for a conical singularity at the source $x=x_s$.\n\n### 2. Numerical Discretization and The Fast Marching Method\n\nWe discretize the domain $[0,1] \\times [0,1]$ using a uniform Cartesian grid with $N$ points in each dimension, giving a grid spacing of $h = 1/(N-1)$. Let $T_{i,j}$ be the numerical approximation of $T(ih, jh)$.\n\nThe Eikonal equation, when squared, is $(\\frac{\\partial T}{\\partial x})^2 + (\\frac{\\partial T}{\\partial y})^2 = S^2$, where $S = 1/f_0$ is the constant slowness. A first-order, upwind, monotone discretization must be used. This means the value $T_{i,j}$ is computed using only the values of its neighbors that have smaller arrival times. The FMM algorithm naturally enforces this causality. The upwind discretization for the partial derivatives is:\n$$\n\\left(\\max\\left(\\frac{T_{i,j}-T_{i-1,j}}{h}, -\\frac{T_{i+1,j}-T_{i,j}}{h}, 0\\right)\\right)^2 + \\left(\\max\\left(\\frac{T_{i,j}-T_{i,j-1}}{h}, -\\frac{T_{i,j+1}-T_{i,j}}{h}, 0\\right)\\right)^2 = S^2\n$$\nWithin the FMM framework, at the moment of updating $T_{i,j}$, its upwind neighbors have already been assigned their final, smaller arrival times. Let $T_x = \\min(T_{i-1,j}, T_{i+1,j})$ and $T_y = \\min(T_{i,j-1}, T_{i,j+1})$. The equation for $T_{i,j}$ simplifies based on two regimes:\n\n1.  **One-Dimensional Update**: If the front arrives at $(i,j)$ primarily from one direction (e.g., $x$), the update mimics a 1D problem. This occurs if $|T_x - T_y| \\ge hS$. In this case, the update is:\n    $$\n    T_{i,j} = \\min(T_x, T_y) + hS\n    $$\n\n2.  **Two-Dimensional Update**: If the front arrives from a direction incorporating both $x$ and $y$ components, a quadratic equation must be solved. This occurs if $|T_x - T_y|  hS$. The underlying equation is $(T_{i,j} - T_x)^2 + (T_{i,j} - T_y)^2 = (hS)^2$. Solving for $T_{i,j}$ and taking the larger root (which corresponds to the viscosity solution) yields:\n    $$\n    T_{i,j} = \\frac{T_x + T_y + \\sqrt{2(hS)^2 - (T_x - T_y)^2}}{2}\n    $$\n\nThe **Fast Marching Method (FMM)** is an efficient algorithm for solving the discretized Eikonal equation in the correct order. It uses a min-priority queue to systematically advance the front from smaller to larger arrival times.\n- **Node States**: Each grid node is in one of three states: `KNOWN` (final time computed), `TRIAL` (tentative time computed, on the propagation front), or `UNSEEN` (far from the front).\n- **Initialization**: All nodes are `UNSEEN` with $T=\\infty$, except the source node, which has $T=0$ and is marked as `TRIAL`.\n- **Algorithm**:\n    1. A min-priority queue stores all `TRIAL` nodes, ordered by their arrival times.\n    2. Repeatedly extract the `TRIAL` node $(i,j)$ with the minimum arrival time from the queue.\n    3. Mark this node as `KNOWN`.\n    4. For each `UNSEEN` or `TRIAL` neighbor of $(i,j)$, calculate a new arrival time using the upwind discretization scheme described above.\n    5. If the newly calculated time is smaller than the neighbor's current time, update the neighbor's time and add it to the priority queue.\n\n### 3. Grid Refinement Study and Error Analysis\n\nA grid refinement study is performed to assess the numerical accuracy. The theoretical order of accuracy $p$ relates the error $E$ to the grid spacing $h$ by $E(h) \\approx C h^p$. By computing the error on a sequence of successively finer grids, we can estimate $p$.\n\n- **Grids**: Uniform grids with $N \\in \\{33, 65, 129, 257\\}$ points per dimension, yielding grid spacings $h_k = 1/(N_k-1)$ that are successively halved.\n- **Error Norms**: For each grid, the discrete $L_1$, $L_2$, and $L_\\infty$ error norms are computed by comparing the numerical solution $T_h$ to the analytic solution $T_{\\text{exact}}$ evaluated at the grid nodes.\n    - $L_1$ error: $E_{1}(h) = h^2 \\sum_{i,j} |T_h(x_{i,j}) - T_{\\text{exact}}(x_{i,j})|$\n    - $L_2$ error: $E_{2}(h) = \\sqrt{h^2 \\sum_{i,j} (T_h(x_{i,j}) - T_{\\text{exact}}(x_{i,j}))^2}$\n    - $L_\\infty$ error: $E_{\\infty}(h) = \\max_{i,j} |T_h(x_{i,j}) - T_{\\text{exact}}(x_{i,j})|$\n- **Observed Order of Accuracy**: For each norm, the order $p_k$ is computed between successive grid levels $h_k$ and $h_{k+1}$:\n    $$\n    p_{k} = \\frac{\\log\\left(E(h_{k+1})/E(h_{k})\\right)}{\\log\\left(h_{k+1}/h_{k}\\right)}\n    $$\nSince $h_{k+1}/h_k = 1/2$, this simplifies to $p_k = -\\log_2(E(h_{k+1})/E(h_k))$. A single robust estimate for the order $p$ is obtained by taking the median of the sequence $\\{p_k\\}$. The procedure is executed for all three specified test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport heapq\n\ndef fast_marching(N, h, f0, source_idx):\n    \"\"\"\n    Implements the Fast Marching Method on a 2D uniform grid.\n\n    Args:\n        N (int): Number of grid points per dimension.\n        h (float): Grid spacing.\n        f0 (float): Constant wave speed.\n        source_idx (tuple): (row, col) indices of the source point.\n\n    Returns:\n        numpy.ndarray: A (N, N) array of arrival times.\n    \"\"\"\n    # 1. Initialization\n    T = np.full((N, N), np.inf, dtype=np.float64)\n    # States: 0=UNSEEN, 1=TRIAL, 2=KNOWN\n    states = np.zeros((N, N), dtype=np.uint8)\n    UNSEEN, TRIAL, KNOWN = 0, 1, 2\n    \n    pq = []  # Min-priority queue\n\n    slowness_h = h / f0\n\n    # Set source node\n    isrc, jsrc = source_idx\n    T[isrc, jsrc] = 0.0\n    states[isrc, jsrc] = TRIAL\n    heapq.heappush(pq, (0.0, isrc, jsrc))\n\n    # 2. Main loop\n    while pq:\n        time, i, j = heapq.heappop(pq)\n\n        # If a better time has been found since this entry was added, skip.\n        if time  T[i, j]:\n            continue\n\n        states[i, j] = KNOWN\n\n        # 3. Update neighbors\n        # Iterate over neighbors (_ni, _nj) of the current node (i, j)\n        for _ni, _nj in [(i - 1, j), (i + 1, j), (i, j - 1), (i, j + 1)]:\n            # Check if neighbor is within grid and not already finalized\n            if 0 = _ni  N and 0 = _nj  N and states[_ni, _nj] != KNOWN:\n                \n                # Calculate new tentative time for the neighbor (_ni, _nj)\n                # by solving its local Eikonal equation.\n                \n                # Get minimum arrival time from x-direction neighbors of (_ni, _nj)\n                t_x_min = np.inf\n                if _ni  0:\n                    t_x_min = min(t_x_min, T[_ni - 1, _nj])\n                if _ni  N - 1:\n                    t_x_min = min(t_x_min, T[_ni + 1, _nj])\n                \n                # Get minimum arrival time from y-direction neighbors of (_ni, _nj)\n                t_y_min = np.inf\n                if _nj  0:\n                    t_y_min = min(t_y_min, T[_ni, _nj - 1])\n                if _nj  N - 1:\n                    t_y_min = min(t_y_min, T[_ni, _nj + 1])\n                \n                # If neither neighbor has a finite time, we can't update yet.\n                if not (np.isfinite(t_x_min) or np.isfinite(t_y_min)):\n                    continue\n\n                # Determine whether to use 1D or 2D update\n                if abs(t_x_min - t_y_min) = slowness_h:\n                    t_new = min(t_x_min, t_y_min) + slowness_h\n                else:\n                    # Quadratic update\n                    discriminant = 2 * slowness_h**2 - (t_x_min - t_y_min)**2\n                    # Discriminant should be non-negative due to the condition above,\n                    # but floating point arithmetic may cause small negative values.\n                    discriminant = max(0, discriminant)\n                    t_new = (t_x_min + t_y_min + np.sqrt(discriminant)) / 2.0\n\n                # If the new time is an improvement, update and add to queue\n                if t_new  T[_ni, _nj]:\n                    T[_ni, _nj] = t_new\n                    if states[_ni, _nj] == UNSEEN:\n                        states[_ni, _nj] = TRIAL\n                    heapq.heappush(pq, (t_new, _ni, _nj))\n    \n    return T\n\ndef run_refinement_study(f0, source_coords):\n    \"\"\"\n    Performs a grid refinement study for a given case.\n\n    Args:\n        f0 (float): Constant wave speed.\n        source_coords (tuple): (x, y) coordinates of the source.\n\n    Returns:\n        list: A list of three median observed orders for L1, L2, Linf norms.\n    \"\"\"\n    grid_sizes = [33, 65, 129, 257]\n    errors = { \"l1\": [], \"l2\": [], \"linf\": [] }\n    h_values = []\n\n    for N in grid_sizes:\n        h = 1.0 / (N - 1)\n        h_values.append(h)\n\n        # Create grid\n        x = np.linspace(0.0, 1.0, N)\n        y = np.linspace(0.0, 1.0, N)\n        xx, yy = np.meshgrid(x, y, indexing='ij')\n\n        # Source index must be exactly on a node\n        isrc = int(round(source_coords[0] / h))\n        jsrc = int(round(source_coords[1] / h))\n\n        # Compute numerical solution\n        T_numerical = fast_marching(N, h, f0, (isrc, jsrc))\n        \n        # Compute analytic solution\n        T_analytic = np.sqrt((xx - source_coords[0])**2 + (yy - source_coords[1])**2) / f0\n        \n        # Compute errors\n        diff = np.abs(T_numerical - T_analytic)\n        \n        # L_infinity error\n        errors[\"linf\"].append(np.max(diff))\n        \n        # L1 error\n        errors[\"l1\"].append(h**2 * np.sum(diff))\n        \n        # L2 error\n        errors[\"l2\"].append(np.sqrt(h**2 * np.sum(diff**2)))\n\n    # Compute observed orders of accuracy\n    orders = []\n    log_h_ratio = np.log(0.5)\n    for norm in [\"l1\", \"l2\", \"linf\"]:\n        p_k = []\n        for i in range(len(grid_sizes) - 1):\n            # p_k = log(E_k+1 / E_k) / log(h_k+1 / h_k)\n            # handle cases where error is zero\n            if errors[norm][i+1]  0 and errors[norm][i]  0:\n                log_err_ratio = np.log(errors[norm][i+1] / errors[norm][i])\n                p_k.append(log_err_ratio / log_h_ratio)\n        \n        if not p_k:\n             # This can happen if error is consistently zero, implying perfect accuracy\n             # on the test grids. The theoretical order is then irrelevant.\n             # Or if there are not enough data points.\n             orders.append(np.nan)\n        else:\n             orders.append(np.median(p_k))\n\n    return orders\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Test suite specification\n    test_cases = [\n        {'f0': 1.0, 'source_coords': (0.5, 0.5)},  # Case A\n        {'f0': 2.0, 'source_coords': (0.5, 0.5)},  # Case B\n        {'f0': 1.0, 'source_coords': (0.0, 0.0)},  # Case C\n    ]\n\n    all_results = []\n    for case in test_cases:\n        orders = run_refinement_study(case['f0'], case['source_coords'])\n        all_results.extend(orders)\n    \n    # Format a string for the final output\n    result_str = \",\".join([f\"{r:.7f}\" for r in all_results])\n    print(f\"[{result_str}]\")\n\nsolve()\n```", "id": "3391181"}]}