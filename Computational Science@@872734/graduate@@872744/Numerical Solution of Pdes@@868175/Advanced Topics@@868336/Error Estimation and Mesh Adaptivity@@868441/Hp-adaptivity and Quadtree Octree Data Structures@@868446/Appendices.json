{"hands_on_practices": [{"introduction": "Efficient management of hierarchical meshes, such as quadtrees and octrees, is foundational to high-performance adaptive solvers. A key challenge is mapping multi-dimensional spatial data to a one-dimensional memory layout that preserves locality and simplifies neighbor-finding. This exercise explores the Morton order, or Z-order curve, a classic space-filling curve that accomplishes this by interleaving the bits of spatial coordinates, providing you with the tools to derive the essential mapping formulas from first principles [@problem_id:3404620].", "problem": "Consider an $hp$-adaptive discretization of a two-dimensional Partial Differential Equation (PDE) on the unit square using a quadtree mesh. At a fixed quadtree level $\\ell \\in \\mathbb{N}$, the leaf cells form a uniform dyadic partition of the domain into a grid of $2^{\\ell} \\times 2^{\\ell}$ axis-aligned squares. Index these leaf cells by integer coordinates $(i,j)$ with $i,j \\in \\{0,1,\\dots,2^{\\ell}-1\\}$, where $i$ increases along the $x$-axis and $j$ increases along the $y$-axis. In order to store per-cell polynomial degrees and associated Degrees of Freedom (DOF) contiguously for efficient matrix assembly in the Finite Element Method (FEM), a Morton (Z-order) indexing scheme is used to map the pair $(i,j)$ to a single integer key $m \\in \\{0,1,\\dots,2^{2\\ell}-1\\}$ by bit-interleaving the binary expansions of $i$ and $j$.\n\nStarting from first principles about binary expansions of integers and the definition of dyadic quadtree levels, derive explicit, closed-form expressions (not algorithms) for:\n- the forward mapping $m$ as a function of $(i,j,\\ell)$ obtained by interleaving the bits of $i$ and $j$ from least significant to most significant, placing the bits of $i$ at even positions and the bits of $j$ at odd positions in the binary expansion of $m$, and\n- the inverse mapping formulas $i$ and $j$ as functions of $(m,\\ell)$ that recover the original grid indices by de-interleaving.\n\nYou must express your final mappings entirely with well-defined arithmetic operations on integers and the functions $\\lfloor \\cdot \\rfloor$ and $\\bmod$, and you must use summation notation over bit positions. Use the convention that for an integer $x \\ge 0$, its bit $x_{k} \\in \\{0,1\\}$ at position $k$ (least significant bit is position $k=0$) is given by $x_{k} = \\left\\lfloor \\dfrac{x}{2^{k}} \\right\\rfloor \\bmod 2$. Assume zero-based indexing of bits throughout.\n\nProvide your final answer as three closed-form analytic expressions: $m(i,j,\\ell)$, $i(m,\\ell)$, and $j(m,\\ell)$. The final answer must be a single closed-form analytic expression or a collection of expressions formatted as a single row matrix. No rounding is required.", "solution": "The problem is found to be valid as it is scientifically grounded, well-posed, objective, and self-contained. It presents a standard, formalizable task from computational science and numerical analysis without any factual unsoundness, ambiguity, or contradiction.\n\nThe objective is to derive closed-form expressions for the forward and inverse Morton (Z-order) mappings between two-dimensional grid indices $(i,j)$ and a one-dimensional index $m$ for a quadtree at level $\\ell$.\n\nFirst, we establish the fundamental principle of binary representation. Any non-negative integer $x$ can be uniquely expressed as a sum of powers of $2$, weighted by its binary digits (bits). If $x$ can be represented by $N$ bits, its value is given by:\n$$x = \\sum_{k=0}^{N-1} x_k 2^k$$\nwhere $x_k \\in \\{0, 1\\}$ is the bit at position $k$ (with $k=0$ being the least significant bit). The problem provides the formula for extracting this bit:\n$$x_k = \\left\\lfloor \\frac{x}{2^k} \\right\\rfloor \\bmod 2$$\n\nThe grid indices $i$ and $j$ are in the range $\\{0, 1, \\dots, 2^{\\ell}-1\\}$, which means they can be represented by $\\ell$ bits. Their binary expansions are:\n$$i = \\sum_{k=0}^{\\ell-1} i_k 2^k$$\n$$j = \\sum_{k=0}^{\\ell-1} j_k 2^k$$\nThe Morton index $m$ is in the range $\\{0, 1, \\dots, 2^{2\\ell}-1\\}$, which means it can be represented by $2\\ell$ bits. Its binary expansion is:\n$$m = \\sum_{p=0}^{2\\ell-1} m_p 2^p$$\n\n**1. Derivation of the Forward Mapping $m(i, j, \\ell)$**\n\nThe problem defines the forward Morton mapping by interleaving the bits of $i$ and $j$. Specifically, the $k$-th bit of $i$, $i_k$, is placed at the even position $2k$ in $m$, and the $k$-th bit of $j$, $j_k$, is placed at the odd position $2k+1$ in $m$. Formally:\n$$m_{2k} = i_k, \\quad \\text{for } k \\in \\{0, 1, \\dots, \\ell-1\\}$$\n$$m_{2k+1} = j_k, \\quad \\text{for } k \\in \\{0, 1, \\dots, \\ell-1\\}$$\n\nTo find the expression for $m$, we substitute these bit definitions into its binary expansion. We can split the summation over the index $p$ into two separate sums for even and odd positions.\nLet $p=2k$ for the even positions and $p=2k+1$ for the odd positions. As $p$ goes from $0$ to $2\\ell-1$, the index $k$ for both cases goes from $0$ to $\\ell-1$.\n$$m = \\sum_{p \\text{ is even}} m_p 2^p + \\sum_{p \\text{ is odd}} m_p 2^p$$\nSubstituting $p=2k$ and $p=2k+1$:\n$$m = \\sum_{k=0}^{\\ell-1} m_{2k} 2^{2k} + \\sum_{k=0}^{\\ell-1} m_{2k+1} 2^{2k+1}$$\nNow, we replace the bits of $m$ with the corresponding bits of $i$ and $j$:\n$$m = \\sum_{k=0}^{\\ell-1} i_k 2^{2k} + \\sum_{k=0}^{\\ell-1} j_k 2^{2k+1}$$\nFinally, we substitute the provided formula for bit extraction for $i_k$ and $j_k$:\n$$i_k = \\left\\lfloor \\frac{i}{2^k} \\right\\rfloor \\bmod 2$$\n$$j_k = \\left\\lfloor \\frac{j}{2^k} \\right\\rfloor \\bmod 2$$\nThis yields the final closed-form expression for the forward mapping:\n$$m(i, j, \\ell) = \\sum_{k=0}^{\\ell-1} \\left( \\left( \\left\\lfloor \\frac{i}{2^k} \\right\\rfloor \\bmod 2 \\right) 2^{2k} + \\left( \\left\\lfloor \\frac{j}{2^k} \\right\\rfloor \\bmod 2 \\right) 2^{2k+1} \\right)$$\n\n**2. Derivation of the Inverse Mappings $i(m, \\ell)$ and $j(m, \\ell)$**\n\nThe inverse mapping, or de-interleaving, recovers the original grid indices $i$ and $j$ from the Morton index $m$. We start from the binary expansions of $i$ and $j$:\n$$i = \\sum_{k=0}^{\\ell-1} i_k 2^k$$\n$$j = \\sum_{k=0}^{\\ell-1} j_k 2^k$$\nFrom the definition of the forward mapping, we know that the bits of $i$ and $j$ are embedded in $m$ at specific positions:\n$$i_k = m_{2k}$$\n$$j_k = m_{2k+1}$$\nWe can substitute these into the binary expansions for $i$ and $j$:\n$$i = \\sum_{k=0}^{\\ell-1} m_{2k} 2^k$$\n$$j = \\sum_{k=0}^{\\ell-1} m_{2k+1} 2^k$$\nNow, we use the given formula to extract the bits $m_p$ from $m$:\n$$m_p = \\left\\lfloor \\frac{m}{2^p} \\right\\rfloor \\bmod 2$$\nReplacing $p$ with $2k$ and $2k+1$ respectively, we get:\n$$m_{2k} = \\left\\lfloor \\frac{m}{2^{2k}} \\right\\rfloor \\bmod 2$$\n$$m_{2k+1} = \\left\\lfloor \\frac{m}{2^{2k+1}} \\right\\rfloor \\bmod 2$$\nSubstituting these expressions back into the summations for $i$ and $j$ gives the final closed-form expressions for the inverse mappings:\n$$i(m, \\ell) = \\sum_{k=0}^{\\ell-1} \\left( \\left\\lfloor \\frac{m}{2^{2k}} \\right\\rfloor \\bmod 2 \\right) 2^k$$\n$$j(m, \\ell) = \\sum_{k=0}^{\\ell-1} \\left( \\left\\lfloor \\frac{m}{2^{2k+1}} \\right\\rfloor \\bmod 2 \\right) 2^k$$\nThese three expressions for $m(i, j, \\ell)$, $i(m, \\ell)$, and $j(m, \\ell)$ satisfy all the requirements of the problem statement.", "answer": "$$\\boxed{\\begin{pmatrix} m(i,j,\\ell) = \\sum_{k=0}^{\\ell-1} \\left( 2^{2k} \\left( \\left\\lfloor \\frac{i}{2^k} \\right\\rfloor \\bmod 2 \\right) + 2^{2k+1} \\left( \\left\\lfloor \\frac{j}{2^k} \\right\\rfloor \\bmod 2 \\right) \\right) & i(m,\\ell) = \\sum_{k=0}^{\\ell-1} 2^k \\left( \\left\\lfloor \\frac{m}{2^{2k}} \\right\\rfloor \\bmod 2 \\right) & j(m,\\ell) = \\sum_{k=0}^{\\ell-1} 2^k \\left( \\left\\lfloor \\frac{m}{2^{2k+1}} \\right\\rfloor \\bmod 2 \\right) \\end{pmatrix}}$$", "id": "3404620"}, {"introduction": "Adaptive mesh refinement naturally creates non-conforming interfaces where larger \"parent\" elements abut smaller \"child\" elements, leading to \"hanging nodes\" that are not shared by all adjacent elements. To maintain the global $C^0$ continuity required by the Finite Element Method, the degrees of freedom associated with these hanging nodes must be constrained. This practice guides you through the derivation of these constraints for quadratic elements, a critical step in ensuring the mathematical validity and accuracy of the numerical solution on an adaptive grid [@problem_id:3404633].", "problem": "Consider a two-dimensional quadtree mesh with a single level difference ($1{:}2$ refinement) across a straight interior edge. Let a coarse quadrilateral cell $\\Omega_{c}$ with tensor-product biquadratic $\\mathbb{Q}_2$ finite elements abut two refined child cells $\\Omega_{f}^{-}$ and $\\Omega_{f}^{+}$ along a shared edge $E$. Assume standard nodal Lagrange interpolation on the biunit square reference cell with nodes at $\\{-1,0,1\\}^2$. Parameterize the coarse edge $E$ by a coordinate $s \\in [-1,1]$ increasing from the bottom endpoint to the top endpoint. The refined neighbor splits $E$ at $s=0$ into two subedges $E^{-} = [-1,0]$ and $E^{+} = [0,1]$, each equipped with $\\mathbb{Q}_2$ edge nodes at their endpoints and midpoint, so that the unique fine edge nodes along $E$ are located at $s \\in \\{-1,-\\frac{1}{2},0,\\frac{1}{2},1\\}$.\n\nWork in the trace spaces along $E$. Let $\\ell_{0}(s)$ denote the one-dimensional quadratic Lagrange basis function on the coarse edge associated with the mid-edge node at $s=0$. Use only the foundational definition of Lagrange interpolation on intervals and the fact that a quadratic on a subinterval is uniquely determined by its values at its three interpolation nodes. Derive, from first principles, the constraint that enforces global $C^{0}$ continuity by expressing the coarse mid-edge degree of freedom on $\\Omega_{c}$ as a linear combination of the refined edge degrees of freedom of $\\Omega_{f}^{-}$ and $\\Omega_{f}^{+}$. In other words, determine the unique coefficient row vector $\\mathbf{c} \\in \\mathbb{R}^{5}$ such that the restriction of $\\ell_{0}(s)$ to the refined trace space on $E$ is represented exactly by the nodal basis associated with the fine edge nodes at $s \\in \\{-1,-\\frac{1}{2},0,\\frac{1}{2},1\\}$ with coefficients given by the entries of $\\mathbf{c}$.\n\nProvide the explicit $1 \\times 5$ constraint row vector $\\mathbf{c}$ in the node ordering $s=-1,-\\frac{1}{2},0,\\frac{1}{2},1$. Your final answer must be a single closed-form analytic expression. No rounding is required.", "solution": "The user-provided problem has been analyzed and is deemed valid. It is scientifically grounded in the principles of the finite element method, specifically concerning $C^0$ continuity on adaptively refined meshes. The problem is well-posed, objective, and contains all necessary information to derive a unique solution from first principles as requested.\n\nThe task is to determine the constraint vector that ensures $C^0$ continuity for a quadratic finite element across an interface where one quadrilateral cell is refined into two. This is achieved by representing a coarse-grid basis function in terms of the fine-grid basis functions on the shared edge.\n\nThe problem statement asks to \"determine the unique coefficient row vector $\\mathbf{c} \\in \\mathbb{R}^{5}$ such that the restriction of $\\ell_{0}(s)$ to the refined trace space on $E$ is represented exactly by the nodal basis associated with the fine edge nodes...\". This is a precise and well-defined mathematical problem. It requires finding the coefficients $c_j$ such that $\\ell_{0}(s) = \\sum_{j=1}^{5} c_j \\hat{\\ell}_j(s)$, where $\\ell_0(s)$ is the coarse-grid basis function and $\\hat{\\ell}_j(s)$ are the fine-grid basis functions.\n\nLet us begin by defining the coarse-grid basis function $\\ell_0(s)$. The coarse edge $E$ is parameterized by $s \\in [-1,1]$. The finite elements are specified as $\\mathbb{Q}_2$, which means the trace space on this edge is the space of quadratic polynomials, $P_2([-1,1])$. The nodal basis for this space is defined by the nodes at $s \\in \\{-1, 0, 1\\}$. The basis function $\\ell_0(s)$ is associated with the central node at $s=0$. By the definition of Lagrange basis functions, $\\ell_0(s)$ must satisfy:\n$$ \\ell_0(-1) = 0 $$\n$$ \\ell_0(0) = 1 $$\n$$ \\ell_0(1) = 0 $$\nThe unique quadratic polynomial satisfying these conditions is:\n$$ \\ell_0(s) = \\frac{(s - (-1))(s - 1)}{(0 - (-1))(0 - 1)} = \\frac{(s+1)(s-1)}{(1)(-1)} = -(s^2-1) = 1 - s^2 $$\n\nNext, we consider the refined trace space on the edge $E$. This space is composed of continuous functions that are quadratic on the sub-edge $E^-$, parameterized by $s \\in [-1,0]$, and quadratic on the sub-edge $E^+$, parameterized by $s \\in [0,1]$. The basis for this space is the set of nodal Lagrange basis functions, $\\{\\hat{\\ell}_j(s)\\}_{j=1}^{5}$, associated with the five unique fine-edge nodes. The problem specifies the ordered set of node locations as $s \\in \\{-1, -\\frac{1}{2}, 0, \\frac{1}{2}, 1\\}$. Let us denote these nodal coordinates as $\\hat{s}_j$ for $j=1, \\dots, 5$. By definition, the fine-grid basis functions satisfy $\\hat{\\ell}_j(\\hat{s}_k) = \\delta_{jk}$, where $\\delta_{jk}$ is the Kronecker delta.\n\nWe want to find the coefficients $c_j$ for the row vector $\\mathbf{c} = \\begin{pmatrix} c_1 & c_2 & c_3 & c_4 & c_5 \\end{pmatrix}$ in the exact representation:\n$$ \\ell_0(s) = \\sum_{j=1}^{5} c_j \\hat{\\ell}_j(s) $$\nThis equation represents the interpolation of the function $\\ell_0(s)$ onto the fine-grid trace space. The coefficients of an interpolation in a nodal basis are simply the values of the function being interpolated at the corresponding nodes. To see this, we can evaluate the expression at each fine node $\\hat{s}_k$:\n$$ \\ell_0(\\hat{s}_k) = \\sum_{j=1}^{5} c_j \\hat{\\ell}_j(\\hat{s}_k) = \\sum_{j=1}^{5} c_j \\delta_{jk} = c_k $$\nTherefore, the coefficients are given by $c_k = \\ell_0(\\hat{s}_k)$.\n\nThis guarantees that the representation is exact at the five fine-grid nodes. To confirm that the representation is exact for all $s \\in [-1,1]$, we rely on the property that a quadratic polynomial on an interval is uniquely determined by its values at three distinct points.\nOn the subinterval $s \\in [-1,0]$, the fine-grid representation $\\sum_{j=1}^{5} c_j \\hat{\\ell}_j(s)$ is a quadratic polynomial. Its values at the three nodes on this subinterval ($s=-1, -1/2, 0$) are, by construction, identical to the values of $\\ell_0(s)$ at those same points. Since $\\ell_0(s)$ is itself a quadratic polynomial, the two functions must be identical over the entire subinterval $[-1,0]$.\nA symmetric argument applies to the subinterval $s \\in [0,1]$. Thus, the equality holds for all $s \\in [-1,1]$.\n\nWe now calculate the five coefficients:\n1.  For the node at $\\hat{s}_1 = -1$:\n    $c_1 = \\ell_0(-1) = 1 - (-1)^2 = 1 - 1 = 0$.\n\n2.  For the node at $\\hat{s}_2 = -\\frac{1}{2}$:\n    $c_2 = \\ell_0(-\\frac{1}{2}) = 1 - (-\\frac{1}{2})^2 = 1 - \\frac{1}{4} = \\frac{3}{4}$.\n\n3.  For the node at $\\hat{s}_3 = 0$:\n    $c_3 = \\ell_0(0) = 1 - 0^2 = 1$.\n\n4.  For the node at $\\hat{s}_4 = \\frac{1}{2}$:\n    $c_4 = \\ell_0(\\frac{1}{2}) = 1 - (\\frac{1}{2})^2 = 1 - \\frac{1}{4} = \\frac{3}{4}$.\n\n5.  For the node at $\\hat{s}_5 = 1$:\n    $c_5 = \\ell_0(1) = 1 - 1^2 = 1 - 1 = 0$.\n\nThese coefficients form the desired constraint vector. This vector describes how the degree of freedom associated with the coarse mid-edge node must be distributed to the fine-edge degrees of freedom to maintain $C^0$ continuity of the finite element solution across the refined interface.\n\nThe resulting $1 \\times 5$ coefficient row vector $\\mathbf{c}$ for the node ordering $s=-1, -\\frac{1}{2}, 0, \\frac{1}{2}, 1$ is:\n$$ \\mathbf{c} = \\begin{pmatrix} 0 & \\frac{3}{4} & 1 & \\frac{3}{4} & 0 \\end{pmatrix} $$", "answer": "$$\n\\boxed{\\begin{pmatrix} 0 & \\frac{3}{4} & 1 & \\frac{3}{4} & 0 \\end{pmatrix}}\n$$", "id": "3404633"}, {"introduction": "The power of $hp$-adaptivity lies in its ability to optimally distribute computational resources by choosing the most effective type of refinement—either subdividing an element ($h$-refinement) or increasing its polynomial order ($p$-refinement). This decision process is guided by an adaptive strategy that aims to maximize the reduction in error for each new degree of freedom added to the system. This problem asks you to formulate and apply a sophisticated bulk-chasing criterion, giving you hands-on experience with the core logic that drives an efficient $hp$-adaptive simulation [@problem_id:3404627].", "problem": "Consider a stationary elliptic Partial Differential Equation (PDE) discretized by an $hp$-version Finite Element Method (FEM) on a two-dimensional quadtree mesh. Let the current mesh consist of three leaf elements $E_1$, $E_2$, and $E_3$ with polynomial orders $p_1$, $p_2$, and $p_3$, respectively. Suppose a residual-based a posteriori error estimator produces local indicators $\\eta_i$ that are equivalent to the local contributions to the energy-norm error, so that the total error surrogate is $\\sum_{i=1}^{3} \\eta_i$. You are to formulate a bulk-chasing selection criterion that maximizes predicted error decrease per added Degrees of Freedom (DOF) by ranking $h$- and $p$-refinement actions using local model estimators.\n\nStart from the following fundamental base:\n- The Dörfler bulk-chasing principle requires selecting a set of local modifications whose predicted error decrease reaches a target fraction $\\theta \\in (0,1)$ of the current total estimated error.\n- The local model estimator predicts, for each leaf element $E_i$, the post-action local indicator under either $h$-refinement (quadtree $4$-way split) or $p$-refinement (raise $p_i$ by one), as a multiplicative factor times the current indicator. Specifically, for element $E_i$, let $a_i \\in (0,1)$ be the predicted post-$h$ factor and $b_i \\in (0,1)$ the predicted post-$p$ factor. The predicted local decreases are $r_i^{h} = (1-a_i)\\eta_i$ and $r_i^{p} = (1-b_i)\\eta_i$.\n- The added DOF cost of a local action is defined by a local counting model consistent with $C^0$ tensor-product elements on quadrilaterals: increasing $p_i$ to $p_i+1$ changes the local interior DOFs by $\\Delta n_i^{p} = (p_i+2)^2 - (p_i+1)^2 = 2p_i+3$, and replacing one element by its $4$ children at the same $p_i$ changes the local interior DOFs by $\\Delta n_i^{h} = 4(p_i+1)^2 - (p_i+1)^2 = 3(p_i+1)^2$.\n\nDefine, from first principles, a bulk-chasing criterion that selects a set of at most one action per element so as to meet the target fraction while maximizing error decrease per added DOF. Show that the resulting selection can be characterized by a gain threshold $\\lambda_{\\star}$, where the gain of an action is the ratio of predicted decrease to DOF cost.\n\nThen, for the following quadtree leaf data,\n- $(\\eta_1,\\eta_2,\\eta_3) = (0.40, 0.35, 0.25)$ with $(p_1,p_2,p_3) = (2,1,3)$,\n- $h$-model factors $(a_1,a_2,a_3) = (0.52, 0.60, 0.55)$,\n- $p$-model factors $(b_1,b_2,b_3) = (0.35, 0.80, 0.50)$,\nand a bulk parameter $\\theta = 0.45$,\n\ncompute the numerical value of the gain threshold $\\lambda_{\\star}$ implied by your criterion. Express your final answer as an exact number without units. If you choose to present a rounded numerical value, round to four significant figures. The answer must be a single real number.", "solution": "The problem is valid as it is scientifically grounded in the theory of adaptive finite element methods, is well-posed with sufficient and consistent data, and is expressed in objective, formal language. We will proceed with a full solution.\n\nThe problem asks for two things: first, to formulate a general bulk-chasing criterion for $hp$-refinement that maximizes error decrease per added Degree of Freedom (DOF); second, to apply this criterion to a specific numerical case and compute the resulting gain threshold $\\lambda_{\\star}$.\n\nWe begin by formalizing the selection criterion. The goal is to select a set of refinement actions, at most one per element, that satisfies the Dörfler bulk-chasing condition while being maximally efficient. Efficiency is defined as maximizing the predicted error decrease per added DOF.\n\nFor each leaf element $E_i$ in the mesh, there are two possible refinement actions: $h$-refinement (type $h$) and $p$-refinement (type $p$).\nThe predicted error decrease for an action of type $k \\in \\{h, p\\}$ on element $E_i$ is denoted by $r_i^k$:\n$$r_i^{h} = (1-a_i)\\eta_i$$\n$$r_i^{p} = (1-b_i)\\eta_i$$\nThe corresponding cost in terms of added local interior DOFs is $\\Delta n_i^k$:\n$$\\Delta n_i^{h} = 3(p_i+1)^2$$\n$$\\Delta n_i^{p} = 2p_i+3$$\nThe efficiency or \"gain\" of an action $(i, k)$ is the ratio of predicted decrease to its cost:\n$$\\lambda_i^k = \\frac{r_i^k}{\\Delta n_i^k}$$\nThis gain $\\lambda_i^k$ represents the predicted error reduction per newly introduced DOF for a specific action. To maximize overall efficiency, we should prioritize actions with the highest gain. This leads to a greedy selection strategy.\n\nThe constraint that at most one action can be performed on any given element $E_i$ implies that for each element, we should first determine its most efficient potential refinement. We define the \"best\" action for element $E_i$ as the one with the higher gain. Let this action be $(i, k_i^*)$ where $k_i^* = \\arg\\max_{k \\in \\{h, p\\}} \\lambda_i^k$. The corresponding gain, decrease, and cost are denoted $\\lambda_i^*$, $r_i^*$, and $\\Delta n_i^*$, respectively.\n\nThe proposed bulk-chasing algorithm is as follows:\n1.  For each element $E_i$, $i \\in \\{1, \\dots, N\\}$, calculate the gains $\\lambda_i^h$ and $\\lambda_i^p$.\n2.  For each element $E_i$, identify the best candidate action $(i, k_i^*)$, which is the refinement type with the maximum gain $\\lambda_i^* = \\max(\\lambda_i^h, \\lambda_i^p)$. This gives a list of $N$ candidate actions, one for each element.\n3.  Sort these $N$ candidate actions in descending order of their gains $\\lambda_i^*$. Let the sorted list of indices be $(j_1, j_2, \\dots, j_N)$ such that $\\lambda_{j_1}^* \\ge \\lambda_{j_2}^* \\ge \\dots \\ge \\lambda_{j_N}^*$.\n4.  The Dörfler condition requires selecting a set of actions $S$ such that the total predicted decrease meets a target: $\\sum_{(i,k) \\in S} r_i^k \\ge \\theta \\mathcal{E}$, where $\\mathcal{E} = \\sum_{i=1}^N \\eta_i$ is the total estimated error.\n5.  Following the sorted list from step 3, greedily add candidate actions to the selection set $S$ until the Dörfler condition is met. That is, find the smallest integer $M$ such that $\\sum_{m=1}^M r_{j_m}^* \\ge \\theta \\mathcal{E}$. The selected set is $S = \\{(j_m, k_{j_m}^*) \\mid m=1, \\dots, M\\}$.\n6.  This greedy selection process can be characterized by a single gain threshold, $\\lambda_{\\star}$. The last action added to the set, $(j_M, k_{j_M}^*)$, has the smallest gain among all selected actions, $\\lambda_{j_M}^*$. Any candidate action $(i, k_i^*)$ with a gain $\\lambda_i^* > \\lambda_{j_M}^*$ is selected, and any with $\\lambda_i^* < \\lambda_{j_M}^*$ is not. Thus, the threshold is $\\lambda_{\\star} = \\lambda_{j_M}^*$, and the selection rule is to choose all best-per-element actions $(i, k_i^*)$ for which $\\lambda_i^* \\ge \\lambda_{\\star}$.\n\nNow, we apply this procedure to the given numerical data:\n-  Local indicators: $(\\eta_1, \\eta_2, \\eta_3) = (0.40, 0.35, 0.25)$\n-  Polynomial orders: $(p_1, p_2, p_3) = (2, 1, 3)$\n-  $h$-model factors: $(a_1, a_2, a_3) = (0.52, 0.60, 0.55)$\n-  $p$-model factors: $(b_1, b_2, b_3) = (0.35, 0.80, 0.50)$\n-  Bulk parameter: $\\theta = 0.45$\n\nFirst, calculate the total estimated error $\\mathcal{E}$ and the target error decrease:\n$$\\mathcal{E} = \\eta_1 + \\eta_2 + \\eta_3 = 0.40 + 0.35 + 0.25 = 1.00$$\n$$\\text{Target Decrease} = \\theta \\mathcal{E} = 0.45 \\times 1.00 = 0.45$$\n\nNext, we evaluate the two possible refinement actions for each of the three elements.\n\nFor Element $E_1$ ($p_1=2, \\eta_1=0.40, a_1=0.52, b_1=0.35$):\n-  $h$-refinement:\n    - Decrease: $r_1^h = (1-0.52) \\times 0.40 = 0.192$\n    - Cost: $\\Delta n_1^h = 3(2+1)^2 = 27$\n    - Gain: $\\lambda_1^h = \\frac{0.192}{27} \\approx 0.00711$\n-  $p$-refinement:\n    - Decrease: $r_1^p = (1-0.35) \\times 0.40 = 0.260$\n    - Cost: $\\Delta n_1^p = 2(2)+3 = 7$\n    - Gain: $\\lambda_1^p = \\frac{0.260}{7} \\approx 0.03714$\n-  Comparison: $\\lambda_1^p > \\lambda_1^h$. The best action for $E_1$ is $p$-refinement.\n-  Candidate 1: Action $(1, p)$, Gain $\\lambda_1^* = \\frac{0.26}{7}$, Decrease $r_1^* = 0.260$.\n\nFor Element $E_2$ ($p_2=1, \\eta_2=0.35, a_2=0.60, b_2=0.80$):\n-  $h$-refinement:\n    - Decrease: $r_2^h = (1-0.60) \\times 0.35 = 0.140$\n    - Cost: $\\Delta n_2^h = 3(1+1)^2 = 12$\n    - Gain: $\\lambda_2^h = \\frac{0.140}{12} = \\frac{7}{600} \\approx 0.01167$\n-  $p$-refinement:\n    - Decrease: $r_2^p = (1-0.80) \\times 0.35 = 0.070$\n    - Cost: $\\Delta n_2^p = 2(1)+3 = 5$\n    - Gain: $\\lambda_2^p = \\frac{0.070}{5} = 0.014$\n-  Comparison: $\\lambda_2^p > \\lambda_2^h$. The best action for $E_2$ is $p$-refinement.\n-  Candidate 2: Action $(2, p)$, Gain $\\lambda_2^* = 0.014$, Decrease $r_2^* = 0.070$.\n\nFor Element $E_3$ ($p_3=3, \\eta_3=0.25, a_3=0.55, b_3=0.50$):\n-  $h$-refinement:\n    - Decrease: $r_3^h = (1-0.55) \\times 0.25 = 0.1125$\n    - Cost: $\\Delta n_3^h = 3(3+1)^2 = 48$\n    - Gain: $\\lambda_3^h = \\frac{0.1125}{48} \\approx 0.00234$\n-  $p$-refinement:\n    - Decrease: $r_3^p = (1-0.50) \\times 0.25 = 0.125$\n    - Cost: $\\Delta n_3^p = 2(3)+3 = 9$\n    - Gain: $\\lambda_3^p = \\frac{0.125}{9} \\approx 0.01389$\n-  Comparison: $\\lambda_3^p > \\lambda_3^h$. The best action for $E_3$ is $p$-refinement.\n-  Candidate 3: Action $(3, p)$, Gain $\\lambda_3^* = \\frac{0.125}{9}$, Decrease $r_3^* = 0.125$.\n\nNow, we sort the three candidate actions by their gains:\n1.  Candidate 1 (on $E_1$): $\\lambda_1^* = \\frac{0.26}{7} \\approx 0.03714$\n2.  Candidate 2 (on $E_2$): $\\lambda_2^* = 0.014$\n3.  Candidate 3 (on $E_3$): $\\lambda_3^* = \\frac{0.125}{9} = \\frac{1}{72} \\approx 0.01389$\nThe sorted order of candidates is $(1,p)$, $(2,p)$, $(3,p)$.\n\nWe apply the greedy selection procedure, accumulating the decrease until we meet the target of $0.45$:\n1.  Select action $(1, p)$. Cumulative decrease = $r_1^* = 0.260$. This is less than $0.45$.\n2.  Select action $(2, p)$. Cumulative decrease = $r_1^* + r_2^* = 0.260 + 0.070 = 0.330$. This is less than $0.45$.\n3.  Select action $(3, p)$. Cumulative decrease = $r_1^* + r_2^* + r_3^* = 0.330 + 0.125 = 0.455$. This is greater than or equal to $0.45$.\n\nThe Dörfler criterion is met after selecting all three candidate actions. The last action added to the set was $(3, p)$. The gain of this action, the minimum gain in the selected set, is the gain threshold $\\lambda_{\\star}$.\n$$\\lambda_{\\star} = \\lambda_3^* = \\frac{0.125}{9} = \\frac{\\frac{1}{8}}{9} = \\frac{1}{72}$$\nThe value of the gain threshold is exactly $\\frac{1}{72}$.", "answer": "$$\\boxed{\\frac{1}{72}}$$", "id": "3404627"}]}