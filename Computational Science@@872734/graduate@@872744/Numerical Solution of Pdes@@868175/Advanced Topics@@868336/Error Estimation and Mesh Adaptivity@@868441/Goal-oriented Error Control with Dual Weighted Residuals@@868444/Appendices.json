{"hands_on_practices": [{"introduction": "To truly grasp the Dual Weighted Residual method, it's essential to build an error estimator from its foundational parts. This exercise guides you through a direct calculation on a simple one-dimensional problem, revealing how local residuals on mesh elements and jumps across element faces are weighted by the dual solution to form a global error estimate [@problem_id:3400751]. Completing this practice will solidify your understanding of the DWR error representation formula at its most fundamental level.", "problem": "Consider the second-order elliptic model problem in one spatial dimension. Let the domain be $\\Omega=(0,1)$ and consider the primal boundary value problem\n$$-u'' = f \\quad \\text{in } \\Omega,\\qquad u(0)=0,\\quad u(1)=0,$$\nwith load $f(x)=1$. Let $V:=H^{1}_{0}(\\Omega)$ and let $V_{h}\\subset V$ be the conforming piecewise-linear finite element space associated with the uniform partition $\\mathcal{T}_{h}=\\{[0,\\tfrac{1}{3}],[\\tfrac{1}{3},\\tfrac{2}{3}],[\\tfrac{2}{3},1]\\}$, having nodes at $x_{0}=0$, $x_{1}=\\tfrac{1}{3}$, $x_{2}=\\tfrac{2}{3}$, $x_{3}=1$. Denote by $\\mathcal{E}_{h}$ the set of interior faces (in one dimension, the interior nodes) $\\{\\tfrac{1}{3},\\tfrac{2}{3}\\}$. Let $u_{h}\\in V_{h}$ be the Galerkin finite element solution of the primal problem.\n\nDefine the goal functional $J:V\\to\\mathbb{R}$ by $J(v)=v(\\tfrac{1}{2})$. Consider the adjoint (dual) problem: find $z\\in V$ such that\n$$\\int_{0}^{1} w'(x)\\,z'(x)\\,dx=J(w)\\quad\\text{for all } w\\in V.$$\nThis adjoint admits the strong form $-z''=\\delta_{\\tfrac{1}{2}}$ in $\\Omega$ with $z(0)=0$ and $z(1)=0$, where $\\delta_{\\tfrac{1}{2}}$ is the Dirac distribution at $x=\\tfrac{1}{2}$.\n\nFrom first principles, using the residual and jump decomposition on the mesh $\\mathcal{T}_{h}$, define local dual weights $\\tilde{z}_{h}$ restricted to elements and faces as follows:\n- For each element $K\\in\\mathcal{T}_{h}$, take $\\tilde{z}_{h}|_{K}:=z|_{K}$.\n- For each interior face $E\\in\\mathcal{E}_{h}$, take $\\tilde{z}_{h}|_{E}:=z(E)$.\n\nConstruct local goal-oriented indicators for elements and faces using the Dual Weighted Residuals (DWR) principle:\n- For each element $K\\in\\mathcal{T}_{h}$, set $\\eta_{K}:=\\int_{K}\\left(f+u_{h}''\\right)\\,\\tilde{z}_{h}\\,dx$.\n- For each interior face $E\\in\\mathcal{E}_{h}$, set $\\eta_{E}:=-\\left[\\!\\left[u_{h}'\\right]\\!\\right]_{E}\\,\\tilde{z}_{h}|_{E}$, where $\\left[\\!\\left[u_{h}'\\right]\\!\\right]_{E}$ denotes the jump of the derivative across $E$ oriented by outward normals of adjacent elements.\n\nAssuming the exact dual $z$ is used to define the local dual weights as above, compute the global estimator\n$$\\eta:=\\sum_{K\\in\\mathcal{T}_{h}}\\eta_{K}+\\sum_{E\\in\\mathcal{E}_{h}}\\eta_{E},$$\nfully from the given data, and provide its exact value as a single real number. No rounding is required; provide the exact result.", "solution": "The user wants me to compute the value of a goal-oriented error estimator, $\\eta$, for a one-dimensional elliptic boundary value problem solved with the finite element method.\n\nThe problem is deemed valid as it is scientifically grounded in the theory of numerical analysis for PDEs, specifically a posteriori error estimation using Dual Weighted Residuals (DWR). It is well-posed, objective, and contains all necessary information to compute a unique solution.\n\nThe global estimator $\\eta$ is defined as the sum of local element indicators $\\eta_K$ and local face indicators $\\eta_E$:\n$$\n\\eta = \\sum_{K\\in\\mathcal{T}_{h}}\\eta_{K}+\\sum_{E\\in\\mathcal{E}_{h}}\\eta_{E}\n$$\nwhere\n$$\n\\eta_{K}:=\\int_{K}\\left(f+u_{h}''\\right)\\,\\tilde{z}_{h}\\,dx \\quad \\text{and} \\quad \\eta_{E}:=-\\left[\\!\\left[u_{h}'\\right]\\!\\right]_{E}\\,\\tilde{z}_{h}|_{E}\n$$\nThe calculation proceeds in several steps:\n1.  Find the exact dual solution $z(x)$.\n2.  Find the finite element solution $u_h(x)$.\n3.  Compute the element indicators $\\eta_K$.\n4.  Compute the face indicators $\\eta_E$.\n5.  Sum all indicators to find $\\eta$.\n\n**Step 1: Determine the exact dual solution $z(x)$**\nThe dual problem is given in strong form as:\n$$\n-z'' = \\delta_{\\frac{1}{2}} \\quad \\text{in } \\Omega=(0,1), \\qquad z(0)=0, \\quad z(1)=0\n$$\nwhere $\\delta_{\\frac{1}{2}}$ is the Dirac distribution centered at $x=\\frac{1}{2}$. This is the Green's function for the negative second derivative operator on $(0,1)$ with homogeneous Dirichlet boundary conditions. The solution is continuous and piecewise linear.\n\nFor $x \\neq \\frac{1}{2}$, we have $z''(x)=0$, so $z(x)$ is linear on each subinterval $(0, \\frac{1}{2})$ and $(\\frac{1}{2}, 1)$.\nApplying the boundary conditions:\n-   For $x \\in [0, \\frac{1}{2}]$, $z(x) = C_1 x$.\n-   For $x \\in [\\frac{1}{2}, 1]$, $z(x) = C_2(1-x)$.\n\nContinuity at $x=\\frac{1}{2}$ requires $C_1(\\frac{1}{2}) = C_2(1-\\frac{1}{2})$, which implies $C_1=C_2$.\n\nThe jump condition on the first derivative at $x=\\frac{1}{2}$ is obtained by integrating $-z''=\\delta_{\\frac{1}{2}}$ over a small interval $[\\frac{1}{2}-\\epsilon, \\frac{1}{2}+\\epsilon]$:\n$$\n\\int_{\\frac{1}{2}-\\epsilon}^{\\frac{1}{2}+\\epsilon} -z'' dx = 1 \\implies [-z']_{\\frac{1}{2}-\\epsilon}^{\\frac{1}{2}+\\epsilon} = 1 \\implies z'(\\tfrac{1}{2}^{-}) - z'(\\tfrac{1}{2}^{+}) = 1\n$$\nThe derivatives are $z'(x) = C_1$ for $x  \\frac{1}{2}$ and $z'(x) = -C_2$ for $x  \\frac{1}{2}$.\nThe jump condition becomes $C_1 - (-C_2) = 1$, so $C_1 + C_2 = 1$.\nWith $C_1=C_2$, we get $2C_1 = 1$, so $C_1=C_2=\\frac{1}{2}$.\nThe dual solution is:\n$$\nz(x) = \\begin{cases} \\frac{1}{2}x  \\text{if } 0 \\le x \\le \\frac{1}{2} \\\\ \\frac{1}{2}(1-x)  \\text{if } \\frac{1}{2} \\le x \\le 1 \\end{cases}\n$$\n\n**Step 2: Determine the finite element solution $u_h(x)$**\nThe space $V_h$ consists of continuous piecewise linear functions on the uniform mesh with nodes $x_0=0$, $x_1=\\frac{1}{3}$, $x_2=\\frac{2}{3}$, $x_3=1$. The solution is $u_h(x) = U_1\\phi_1(x) + U_2\\phi_2(x)$, where $\\phi_1, \\phi_2$ are the hat basis functions at the interior nodes $x_1, x_2$, and $U_i = u_h(x_i)$. The Galerkin system is $A\\mathbf{U}=\\mathbf{b}$, where $h = \\frac{1}{3}$ is the mesh size.\nThe stiffness matrix $A$ and load vector $\\mathbf{b}$ are:\n$$\nA = \\frac{1}{h}\\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix} = 3\\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix} = \\begin{pmatrix} 6  -3 \\\\ -3  6 \\end{pmatrix}\n$$\n$$\nb_i = \\int_0^1 f(x)\\phi_i(x) dx = \\int_0^1 \\phi_i(x) dx = \\text{Area}(\\phi_i) = h = \\frac{1}{3}\n$$\nThe system to solve is:\n$$\n\\begin{pmatrix} 6  -3 \\\\ -3  6 \\end{pmatrix} \\begin{pmatrix} U_1 \\\\ U_2 \\end{pmatrix} = \\begin{pmatrix} 1/3 \\\\ 1/3 \\end{pmatrix}\n$$\nBy symmetry, $U_1=U_2$. The first equation gives $6U_1 - 3U_1 = \\frac{1}{3}$, so $3U_1 = \\frac{1}{3}$, which yields $U_1 = \\frac{1}{9}$.\nThus, $u_h(\\frac{1}{3})=\\frac{1}{9}$ and $u_h(\\frac{2}{3})=\\frac{1}{9}$.\nThe finite element solution $u_h(x)$ is given by the points $(0,0), (\\frac{1}{3}, \\frac{1}{9}), (\\frac{2}{3}, \\frac{1}{9}), (1,0)$. The first derivative $u_h'(x)$ is piecewise constant:\n$$\nu_h'(x) = \\begin{cases} \\frac{1/9}{1/3} = \\frac{1}{3}  \\text{if } x \\in (0, 1/3) \\\\ \\frac{1/9 - 1/9}{1/3} = 0  \\text{if } x \\in (1/3, 2/3) \\\\ \\frac{0 - 1/9}{1/3} = -\\frac{1}{3}  \\text{if } x \\in (2/3, 1) \\end{cases}\n$$\n\n**Step 3: Compute the element indicators $\\eta_K$**\nThe local dual weight on an element is $\\tilde{z}_h|_K = z|_K$. Since $u_h$ is linear on each element $K$, $u_h''=0$ inside $K$. With $f=1$, the element indicator is:\n$$\n\\eta_{K} = \\int_{K} (1+0) z(x) dx = \\int_K z(x) dx\n$$\n-   For $K_1=[0, \\frac{1}{3}]$:\n    $\\eta_{K_1} = \\int_0^{1/3} \\frac{1}{2}x dx = \\left[\\frac{x^2}{4}\\right]_0^{1/3} = \\frac{1}{4}\\left(\\frac{1}{3}\\right)^2 = \\frac{1}{36}$.\n-   For $K_2=[\\frac{1}{3}, \\frac{2}{3}]$:\n    $\\eta_{K_2} = \\int_{1/3}^{2/3} z(x) dx = \\int_{1/3}^{1/2} \\frac{1}{2}x dx + \\int_{1/2}^{2/3} \\frac{1}{2}(1-x) dx$\n    $= \\left[\\frac{x^2}{4}\\right]_{1/3}^{1/2} + \\left[\\frac{x}{2}-\\frac{x^2}{4}\\right]_{1/2}^{2/3}$\n    $= \\left(\\frac{1}{16}-\\frac{1}{36}\\right) + \\left(\\left(\\frac{1}{3}-\\frac{1}{9}\\right) - \\left(\\frac{1}{4}-\\frac{1}{16}\\right)\\right)$\n    $= \\frac{5}{144} + \\left(\\frac{2}{9} - \\frac{3}{16}\\right) = \\frac{5}{144} + \\frac{32-27}{144} = \\frac{5}{144} + \\frac{5}{144} = \\frac{10}{144} = \\frac{5}{72}$.\n-   For $K_3=[\\frac{2}{3}, 1]$: By symmetry with $K_1$, $\\eta_{K_3}=\\eta_{K_1}=\\frac{1}{36}$.\n\nThe sum of element indicators is:\n$$\n\\sum_{K\\in\\mathcal{T}_{h}}\\eta_K = \\frac{1}{36} + \\frac{5}{72} + \\frac{1}{36} = \\frac{2}{72} + \\frac{5}{72} + \\frac{2}{72} = \\frac{9}{72} = \\frac{1}{8}\n$$\n\n**Step 4: Compute the face indicators $\\eta_E$**\nThe interior faces are $E_1=\\{\\frac{1}{3}\\}$ and $E_2=\\{\\frac{2}{3}\\}$. The local dual weight on a face is $\\tilde{z}_h|_E = z(E)$. The jump $\\left[\\!\\left[u_h'\\right]\\!\\right]_{E}$ is specified as \"oriented by outward normals\". For a face $E=x_i$ between elements $K_L$ and $K_R$, this defines the jump as $\\left[\\!\\left[v\\right]\\!\\right]_{x_i} = v(x_i^-)n_L + v(x_i^+)n_R = v(x_i^-)(+1) + v(x_i^+)(-1) = v(x_i^-) - v(x_i^+)$.\n\n-   For $E_1=\\{\\frac{1}{3}\\}$:\n    $z(\\frac{1}{3}) = \\frac{1}{2}(\\frac{1}{3}) = \\frac{1}{6}$.\n    $\\left[\\!\\left[u_h'\\right]\\!\\right]_{1/3} = u_h'(\\tfrac{1}{3}^-) - u_h'(\\tfrac{1}{3}^+) = \\frac{1}{3} - 0 = \\frac{1}{3}$.\n    $\\eta_{E_1} = - \\left[\\!\\left[u_h'\\right]\\!\\right]_{1/3} z(\\tfrac{1}{3}) = -\\left(\\frac{1}{3}\\right)\\left(\\frac{1}{6}\\right) = -\\frac{1}{18}$.\n-   For $E_2=\\{\\frac{2}{3}\\}$:\n    $z(\\frac{2}{3}) = \\frac{1}{2}(1-\\frac{2}{3}) = \\frac{1}{6}$.\n    $\\left[\\!\\left[u_h'\\right]\\!\\right]_{2/3} = u_h'(\\tfrac{2}{3}^-) - u_h'(\\tfrac{2}{3}^+) = 0 - (-\\frac{1}{3}) = \\frac{1}{3}$.\n    $\\eta_{E_2} = - \\left[\\!\\left[u_h'\\right]\\!\\right]_{2/3} z(\\tfrac{2}{3}) = -\\left(\\frac{1}{3}\\right)\\left(\\frac{1}{6}\\right) = -\\frac{1}{18}$.\n\nThe sum of face indicators is:\n$$\n\\sum_{E\\in\\mathcal{E}_{h}}\\eta_E = -\\frac{1}{18} - \\frac{1}{18} = -\\frac{2}{18} = -\\frac{1}{9}\n$$\n\n**Step 5: Compute the global estimator $\\eta$**\nThe global estimator is the sum of the element and face contributions:\n$$\n\\eta = \\sum_{K\\in\\mathcal{T}_{h}}\\eta_K + \\sum_{E\\in\\mathcal{E}_{h}}\\eta_E = \\frac{1}{8} + \\left(-\\frac{1}{9}\\right) = \\frac{1}{8} - \\frac{1}{9} = \\frac{9-8}{72} = \\frac{1}{72}\n$$\nThis result is consistent with the DWR identity, which states that for this choice of weights, the estimator $\\eta$ is equal to the error in the goal functional, $J(u) - J(u_h)$. The exact solution is $u(x)=\\frac{1}{2}x(1-x)$, so $J(u)=u(\\frac{1}{2})=\\frac{1}{8}$. The FE solution is $u_h(x)=\\frac{1}{9}$ on the middle element, so $J(u_h)=u_h(\\frac{1}{2})=\\frac{1}{9}$. The error is $J(u)-J(u_h) = \\frac{1}{8}-\\frac{1}{9}=\\frac{1}{72}$.", "answer": "$$\\boxed{\\frac{1}{72}}$$", "id": "3400751"}, {"introduction": "The adjoint method is not just a tool for estimating numerical error; it is a powerful framework for sensitivity analysis. This practice explores how the dual solution quantifies the influence of perturbations in the problem data—in this case, the source term—on a specific goal functional [@problem_id:3400748]. By working through this derivation, you will see firsthand how the adjoint solution acts as a 'weight' that maps input uncertainties to output variations, a cornerstone of uncertainty quantification and optimization.", "problem": "Consider the scalar diffusion model problem on the interval $\\Omega=(0,1)$ with homogeneous Dirichlet boundary conditions: find $u(f) \\in V := H_{0}^{1}(0,1)$ such that\n$$\n\\int_{0}^{1} u'(x)\\, v'(x)\\, dx \\;=\\; \\int_{0}^{1} f(x)\\, v(x)\\, dx\n\\quad \\text{for all } v \\in V.\n$$\nLet the goal functional be the spatial average of the state,\n$$\nJ(u) \\;=\\; \\int_{0}^{1} u(x)\\, dx,\n$$\nand suppose the right-hand side data $f$ is uncertain and can be written as $f = \\widehat{f} + \\delta f$, where $\\widehat{f}$ is a fixed reference and the data perturbation $\\delta f$ is given by\n$$\n\\delta f(x) \\;=\\; \\beta \\;+\\; \\eta \\, \\sin(\\pi x),\n$$\nwith $\\beta,\\eta \\in \\mathbb{R}$.\n\nUsing first principles of linearization, treat $J(u(f))$ as a functional of $f$ through the state equation, and derive the first-order variation of the goal, $\\delta J_{\\mathrm{data}}$, with respect to the data perturbation $\\delta f$. Introduce the adjoint $z \\in V$ through the variational identity\n$$\n\\int_{0}^{1} v'(x)\\, z'(x)\\, dx \\;=\\; J'(u(\\widehat{f}))[v]\n\\quad \\text{for all } v \\in V,\n$$\nand express $\\delta J_{\\mathrm{data}}$ in terms of $\\delta f$ and $z$ by systematically eliminating the state variation via the adjoint. Then, compute $\\delta J_{\\mathrm{data}}$ in closed form for the specified $\\delta f(x) = \\beta + \\eta \\sin(\\pi x)$ by solving the adjoint problem explicitly.\n\nProvide your final answer as a single closed-form analytic expression in terms of $\\beta$ and $\\eta$. Do not include units. No rounding is required.", "solution": "The user wants me to critically validate and then solve a problem from the field of numerical analysis of partial differential equations, specifically concerning goal-oriented error control with dual weighted residuals.\n\n### Step 1: Extract Givens\n- **Domain**: $\\Omega=(0,1)$.\n- **Function Space**: $V := H_{0}^{1}(0,1)$, the Sobolev space of functions with square-integrable first weak derivatives that are zero at the boundary.\n- **State Equation (Weak Form)**: Find $u(f) \\in V$ such that $\\int_{0}^{1} u'(x)\\, v'(x)\\, dx = \\int_{0}^{1} f(x)\\, v(x)\\, dx$ for all $v \\in V$.\n- **Goal Functional**: $J(u) = \\int_{0}^{1} u(x)\\, dx$.\n- **Data Perturbation**: The right-hand side data is $f = \\widehat{f} + \\delta f$, where $\\widehat{f}$ is a reference and $\\delta f(x) = \\beta + \\eta \\sin(\\pi x)$ with $\\beta, \\eta \\in \\mathbb{R}$.\n- **Adjoint Equation (Weak Form)**: Find $z \\in V$ such that $\\int_{0}^{1} v'(x)\\, z'(x)\\, dx = J'(u(\\widehat{f}))[v]$ for all $v \\in V$.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientific or Factual Unsoundness**: The problem is scientifically and mathematically sound. It describes a standard application of the adjoint method (specifically, the dual weighted residual method) to determine the sensitivity of a functional output (the goal) with respect to perturbations in the input data of a boundary value problem. The equations provided are the standard weak forms for the primal problem (Poisson's equation) and the corresponding dual (adjoint) problem.\n2.  **Non-Formalizable or Irrelevant**: The problem is highly formal and directly pertains to the topic *goal-oriented error control with dual weighted residuals* within the field *numerical solution of pdes*.\n3.  **Incomplete or Contradictory Setup**: The problem is self-contained. It provides the state equation, the goal functional, the specific form of the data perturbation, and the definition of the adjoint problem needed for the derivation. There are no contradictions.\n4.  **Unrealistic or Infeasible**: The problem is a standard model problem in the analysis of PDEs and is entirely feasible to solve.\n5.  **Ill-Posed or Poorly Structured**: The problem is well-posed. The Poisson problem with homogeneous Dirichlet conditions is well-posed, as is the adjoint problem. The derivation requested leads to a unique, meaningful result.\n6.  **Pseudo-Profound, Trivial, or Tautological**: The problem is not trivial. It requires a multi-step derivation involving concepts from functional analysis (Fréchet derivatives, weak formulations) and calculus of variations, followed by the solution of a differential equation and evaluation of definite integrals. These steps test a core understanding of the adjoint method.\n7.  **Outside Scientific Verifiability**: The derivation and final result are mathematically verifiable.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. I will proceed to provide a complete, reasoned solution.\n\nThe problem asks for the first-order variation of the goal functional, $\\delta J_{\\mathrm{data}}$, due to a perturbation $\\delta f$ in the a data. The solution process involves three main steps:\n1.  Derive a general expression for $\\delta J_{\\mathrm{data}}$ in terms of the adjoint state $z$ and the data perturbation $\\delta f$.\n2.  Solve the adjoint problem explicitly to find the adjoint state $z(x)$.\n3.  Substitute the solutions for $z(x)$ and the given $\\delta f(x)$ into the general expression and compute the result.\n\nLet us define the bilinear form $a: V \\times V \\to \\mathbb{R}$ and the linear functional $L_f: V \\to \\mathbb{R}$ corresponding to the weak formulation of the state equation:\n$$\na(w, v) := \\int_{0}^{1} w'(x)\\, v'(x)\\, dx\n$$\n$$\nL_f(v) := \\int_{0}^{1} f(x)\\, v(x)\\, dx\n$$\nThe state equation for a given source $f$ is to find $u(f) \\in V$ such that $a(u(f), v) = L_f(v)$ for all $v \\in V$.\n\nLet $\\widehat{u} = u(\\widehat{f})$ be the solution corresponding to the reference data $\\widehat{f}$, and $u = u(\\widehat{f} + \\delta f)$ be the solution for the perturbed data. The first-order variation of the state, $\\delta u$, is defined by the approximation $u \\approx \\widehat{u} + \\delta u$. We can find the equation governing $\\delta u$ by linearizing the state equation.\n$$\na(\\widehat{u} + \\delta u, v) = L_{\\widehat{f} + \\delta f}(v)\n$$\nBy the linearity of $a(\\cdot, \\cdot)$ in its first argument and the linearity of $L_{(\\cdot)}(v)$, we have:\n$$\na(\\widehat{u}, v) + a(\\delta u, v) = L_{\\widehat{f}}(v) + L_{\\delta f}(v)\n$$\nSince $\\widehat{u}$ satisfies the state equation for data $\\widehat{f}$, i.e., $a(\\widehat{u}, v) = L_{\\widehat{f}}(v)$, we can subtract this from the previous equation to obtain the linearized state equation for the state variation $\\delta u$:\n$$\na(\\delta u, v) = L_{\\delta f}(v) \\quad \\text{for all } v \\in V.\n$$\nThe first-order variation of the goal functional, $\\delta J_{\\mathrm{data}}$, is given by the linearization of $J(u)$ around $\\widehat{u}$:\n$$\n\\delta J_{\\mathrm{data}} = J(u) - J(\\widehat{u}) \\approx J'(\\widehat{u})[\\delta u]\n$$\nThe goal functional is $J(u) = \\int_{0}^{1} u(x) dx$. This is a linear functional, so its Fréchet derivative $J'(u)$ is independent of $u$ and is given by $J'(u)[v] = \\int_{0}^{1} v(x) dx = J(v)$. Thus, the variation of the goal is exactly:\n$$\n\\delta J_{\\mathrm{data}} = J(\\delta u) = \\int_{0}^{1} \\delta u(x) dx = J'(\\widehat{u})[\\delta u]\n$$\nThe adjoint problem is defined by seeking $z \\in V$ such that $a(v, z) = J'(\\widehat{u})[v]$ for all $v \\in V$. The bilinear form $a(\\cdot, \\cdot)$ is symmetric, i.e., $a(w,v) = a(v,w)$, so the adjoint equation can be written as $a(z, v) = J'(\\widehat{u})[v]$.\n\nNow, we use the adjoint solution $z$ to express $\\delta J_{\\mathrm{data}}$ in terms of the data perturbation $\\delta f$.\nWe start with the expression for the goal variation and set the test function $v$ in the adjoint equation to be the state variation $\\delta u \\in V$:\n$$\n\\delta J_{\\mathrm{data}} = J'(\\widehat{u})[\\delta u] = a(\\delta u, z)\n$$\nNext, we use the linearized state equation for $\\delta u$ and set its test function $v$ to be the adjoint solution $z \\in V$:\n$$\na(\\delta u, z) = L_{\\delta f}(z)\n$$\nCombining these two results gives the desired relationship:\n$$\n\\delta J_{\\mathrm{data}} = L_{\\delta f}(z) = \\int_{0}^{1} \\delta f(x) z(x) dx\n$$\nThis expression relates the variation in the output functional directly to the input data perturbation, mediated by the adjoint solution $z$, which acts as a sensitivity function.\n\nTo compute the value of $\\delta J_{\\mathrm{data}}$, we must find the explicit form of $z(x)$. The adjoint problem in weak form is:\n$$\n\\int_{0}^{1} z'(x)\\, v'(x)\\, dx = \\int_{0}^{1} v(x)\\, dx \\quad \\text{for all } v \\in V=H_0^1(0,1).\n$$\nThis is the weak formulation of the strong-form two-point boundary value problem:\n$$\n-z''(x) = 1, \\quad x \\in (0,1)\n$$\n$$\nz(0) = 0, \\quad z(1) = 0\n$$\nIntegrating the differential equation twice yields:\n$$\n-z'(x) = x + C_1\n$$\n$$\n-z(x) = \\frac{1}{2}x^2 + C_1 x + C_2\n$$\nApplying the boundary conditions to find the constants $C_1$ and $C_2$:\n$z(0) = 0 \\implies -(\\frac{1}{2}(0)^2 + C_1(0) + C_2) = 0 \\implies C_2=0$.\n$z(1) = 0 \\implies -(\\frac{1}{2}(1)^2 + C_1(1) + 0) = 0 \\implies -\\frac{1}{2} - C_1 = 0 \\implies C_1 = -\\frac{1}{2}$.\nSubstituting the constants back gives the adjoint solution:\n$$\nz(x) = -\\left(\\frac{1}{2}x^2 - \\frac{1}{2}x\\right) = \\frac{1}{2}(x - x^2)\n$$\nFinally, we compute $\\delta J_{\\mathrm{data}}$ by substituting $z(x) = \\frac{1}{2}(x - x^2)$ and $\\delta f(x) = \\beta + \\eta \\sin(\\pi x)$ into the integral expression:\n$$\n\\delta J_{\\mathrm{data}} = \\int_{0}^{1} \\left(\\beta + \\eta \\sin(\\pi x)\\right) \\left(\\frac{1}{2}(x - x^2)\\right) dx\n$$\nWe can split the integral into two parts:\n$$\n\\delta J_{\\mathrm{data}} = \\frac{\\beta}{2} \\int_{0}^{1} (x - x^2) dx + \\frac{\\eta}{2} \\int_{0}^{1} (x - x^2) \\sin(\\pi x) dx\n$$\nThe first integral is:\n$$\n\\int_{0}^{1} (x - x^2) dx = \\left[ \\frac{x^2}{2} - \\frac{x^3}{3} \\right]_{0}^{1} = \\frac{1}{2} - \\frac{1}{3} = \\frac{1}{6}\n$$\nThe second integral requires integration by parts twice. Let $I = \\int_{0}^{1} (x - x^2) \\sin(\\pi x) dx$.\nFirst integration by parts: let $u_1 = x - x^2$ and $dv_1 = \\sin(\\pi x) dx$. Then $du_1 = (1 - 2x) dx$ and $v_1 = -\\frac{1}{\\pi}\\cos(\\pi x)$.\n$$\nI = \\left[ -\\frac{1}{\\pi}(x - x^2)\\cos(\\pi x) \\right]_{0}^{1} - \\int_{0}^{1} \\left(-\\frac{1}{\\pi}\\cos(\\pi x)\\right)(1 - 2x) dx\n$$\nThe boundary term is zero at both $x=0$ and $x=1$.\n$$\nI = \\frac{1}{\\pi} \\int_{0}^{1} (1 - 2x)\\cos(\\pi x) dx\n$$\nSecond integration by parts: let $u_2 = 1 - 2x$ and $dv_2 = \\cos(\\pi x) dx$. Then $du_2 = -2 dx$ and $v_2 = \\frac{1}{\\pi}\\sin(\\pi x)$.\n$$\nI = \\frac{1}{\\pi} \\left( \\left[ \\frac{1}{\\pi}(1 - 2x)\\sin(\\pi x) \\right]_{0}^{1} - \\int_{0}^{1} \\frac{1}{\\pi}\\sin(\\pi x)(-2) dx \\right)\n$$\nThe boundary term is again zero at both limits, as $\\sin(0) = \\sin(\\pi) = 0$.\n$$\nI = \\frac{1}{\\pi} \\left( \\frac{2}{\\pi} \\int_{0}^{1} \\sin(\\pi x) dx \\right) = \\frac{2}{\\pi^2} \\left[ -\\frac{1}{\\pi}\\cos(\\pi x) \\right]_{0}^{1}\n$$\n$$\nI = -\\frac{2}{\\pi^3} [\\cos(\\pi x)]_{0}^{1} = -\\frac{2}{\\pi^3} (\\cos(\\pi) - \\cos(0)) = -\\frac{2}{\\pi^3} (-1 - 1) = \\frac{4}{\\pi^3}\n$$\nNow, we combine the results for the two parts of $\\delta J_{\\mathrm{data}}$:\n$$\n\\delta J_{\\mathrm{data}} = \\frac{\\beta}{2} \\left(\\frac{1}{6}\\right) + \\frac{\\eta}{2} \\left(\\frac{4}{\\pi^3}\\right) = \\frac{\\beta}{12} + \\frac{2\\eta}{\\pi^3}\n$$\nThis is the closed-form first-order variation of the goal with respect to the specified data perturbation.", "answer": "$$\\boxed{\\frac{\\beta}{12} + \\frac{2\\eta}{\\pi^3}}$$", "id": "3400748"}, {"introduction": "In real-world applications, especially in two or three dimensions, solving a global adjoint problem can be computationally prohibitive. This exercise introduces a crucial practical technique: the localization of the adjoint problem. You will implement and compare a full DWR estimator with one based on a localized adjoint solution, computed only in a small patch around the domain of interest, demonstrating how to achieve significant computational savings without sacrificing the accuracy of the error estimate [@problem_id:3400755].", "problem": "Consider the linear elliptic model problem on the unit square domain $\\Omega = (0,1)\\times(0,1)$ with homogeneous Dirichlet boundary conditions: find $u$ such that\n$$\n-\\Delta u = f \\quad \\text{in } \\Omega, \\qquad u = 0 \\quad \\text{on } \\partial\\Omega.\n$$\nLet the goal functional be the linear quantity of interest localized to a measurable subdomain $D \\subset \\Omega$,\n$$\nJ(u) = \\int_D u \\, \\mathrm{d}x\\,\\mathrm{d}y.\n$$\nYou will assess a Dual Weighted Residual (DWR) goal-oriented error estimator and its domain-decomposed approximation that localizes the adjoint computation to a neighborhood of $D$.\n\nThe task has three parts:\n\n1) Starting from the weak form of the primal problem, derive the adjoint (dual) problem associated with the Fréchet derivative of $J$ evaluated at $u$ in the direction of a generic perturbation. Specify the boundary value problem that the adjoint solution must satisfy. Do not assume any specific discretization at this stage.\n\n2) Specialize to the Poisson model with a manufactured exact solution\n$$\nu_{\\text{exact}}(x,y) = \\sin(\\pi x)\\sin(\\pi y),\n$$\nso that\n$$\nf(x,y) = 2\\pi^2 \\sin(\\pi x)\\sin(\\pi y).\n$$\nFrom first principles, deduce the adjoint source and verify that the exact goal can be computed analytically as a product of one-dimensional integrals. Explain how a consistent two-grid DWR estimator can be formed by evaluating the fine-grid residual of the coarse-grid primal solution, weighted by the fine-grid adjoint solution. Clearly articulate the assumptions under which such a two-grid estimator approximates the true goal error $J(u) - J(u_H)$, where $u_H$ denotes the coarse-grid discrete solution.\n\n3) Implement a program that:\n- Discretizes the primal and adjoint problems by the standard five-point second-order finite difference scheme on uniform interior grids. Use a coarse grid of $N_H \\times N_H$ interior points and a fine grid of $N_h \\times N_h$ interior points with $N_h = 2N_H + 1$ so that the fine grid has mesh size $h = \\tfrac{1}{2}H$.\n- Solves the coarse-grid primal problem for $u_H$ and evaluates the approximate discrete goal $J(u_H)$ by a rectangle rule on coarse interior nodes lying in $D$.\n- Constructs a two-grid DWR estimator as follows: prolongate $u_H$ to the fine grid by bilinear interpolation that respects homogeneous Dirichlet boundary conditions, compute the fine-grid residual vector $r_h = f_h - A_h \\mathcal{P}u_H$ (where $A_h$ is the fine-grid stiffness matrix and $\\mathcal{P}$ is the prolongation), solve the fine-grid adjoint problem for the full adjoint $z_h$ with the right-hand side being the nodal indicator $\\chi_D$ of $D$, and form\n$$\n\\eta_{\\text{full}} = \\sum_{i} r_{h,i}\\, z_{h,i}\\, h^2.\n$$\n- Implements a domain-decomposed localized adjoint: define a rectangular patch as the minimal fine-grid bounding box that contains all fine-grid interior nodes inside $D$, expanded by an integer radius $r$ measured in the number of fine-grid interior node layers in both $x$ and $y$ directions. Solve the adjoint restricted to this patch with homogeneous Dirichlet conditions on the artificial patch boundary; extend the localized adjoint by zero outside the patch to obtain $z_{h}^{\\text{loc}}$, and form\n$$\n\\eta_{\\text{loc}} = \\sum_{i} r_{h,i}\\, z^{\\text{loc}}_{h,i}\\, h^2.\n$$\n- Computes the exact goal $J(u_{\\text{exact}})$ analytically and the true goal error $E = J(u_{\\text{exact}}) - J(u_H)$.\n- Reports, for each test case, four floats:\n  1. $|E|$,\n  2. $|\\eta_{\\text{full}} - E|$,\n  3. $|\\eta_{\\text{loc}} - E|$,\n  4. the fraction $\\mathrm{dof}_{\\text{loc}}/\\mathrm{dof}_{\\text{full}}$, where $\\mathrm{dof}_{\\text{full}} = N_h^2$ and $\\mathrm{dof}_{\\text{loc}}$ is the number of interior fine-grid unknowns in the localized patch.\n\nImplementation details:\n- Use homogeneous Dirichlet boundary conditions for both primal and adjoint problems.\n- The prolongation to the fine grid must be bilinear in physical coordinates and must respect zero boundary values on $\\partial \\Omega$.\n- The adjoint right-hand side should use the fine-grid nodal indicator $\\chi_D$ defined as $\\chi_D(x_i,y_j) = 1$ if $(x_i,y_j)\\in D$ and $\\chi_D(x_i,y_j)=0$ otherwise.\n\nAnalytical reference for the exact goal:\n$$\nJ(u_{\\text{exact}}) = \\left(\\int_{a_x}^{b_x} \\sin(\\pi x)\\, \\mathrm{d}x\\right)\\left(\\int_{a_y}^{b_y} \\sin(\\pi y)\\, \\mathrm{d}y\\right) = \\frac{\\cos(\\pi a_x) - \\cos(\\pi b_x)}{\\pi}\\cdot \\frac{\\cos(\\pi a_y) - \\cos(\\pi b_y)}{\\pi},\n$$\nfor a rectangular $D = [a_x,b_x]\\times[a_y,b_y]$.\n\nTest suite:\n- Case A: $N_H = 31$, $D = [0.25, 0.50]\\times[0.25, 0.75]$, localized adjoint radius $r = 8$.\n- Case B: $N_H = 31$, $D = [0.00, 0.20]\\times[0.00, 0.20]$, localized adjoint radius $r = 6$.\n- Case C: $N_H = 15$, $D = [0.45, 0.55]\\times[0.45, 0.55]$, localized adjoint radius $r = 4$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The values must be ordered as\n$$\n[|E|_{\\text{A}},\\, |\\eta_{\\text{full}}-E|_{\\text{A}},\\, |\\eta_{\\text{loc}}-E|_{\\text{A}},\\, \\mathrm{dof\\_ratio}_{\\text{A}},\\, |E|_{\\text{B}},\\, |\\eta_{\\text{full}}-E|_{\\text{B}},\\, |\\eta_{\\text{loc}}-E|_{\\text{B}},\\, \\mathrm{dof\\_ratio}_{\\text{B}},\\, |E|_{\\text{C}},\\, |\\eta_{\\text{full}}-E|_{\\text{C}},\\, |\\eta_{\\text{loc}}-E|_{\\text{C}},\\, \\mathrm{dof\\_ratio}_{\\text{C}}].\n$$\nAll numbers must be printed as decimals rounded to eight digits after the decimal point. No physical units are involved. Angles, if any, must be interpreted in radians. Percentages, if any, must be expressed as decimals.", "solution": "The user has provided a multi-part problem concerning goal-oriented error estimation using the Dual Weighted Residual (DWR) method for a linear elliptic PDE. The problem is deemed valid as it is scientifically sound, well-posed, and contains all necessary information for a complete solution.\n\n### Part 1: Derivation of the Adjoint Problem\n\nThe primal problem is to find the solution $u$ in a suitable function space $V$ such that\n$$-\\Delta u = f \\quad \\text{in } \\Omega, \\qquad u = 0 \\quad \\text{on } \\partial\\Omega.$$\nHere, $\\Omega = (0,1) \\times (0,1)$ and we choose the solution space to be the Sobolev space $V = H_0^1(\\Omega)$, which consists of functions with square-integrable first derivatives that vanish on the boundary $\\partial\\Omega$.\n\nThe weak form of the primal problem is obtained by multiplying the PDE by an arbitrary test function $v \\in V$ and integrating over $\\Omega$. Using Green's first identity (integration by parts) and the fact that $v=0$ on $\\partial\\Omega$, we get:\n$$\n\\int_\\Omega \\nabla u \\cdot \\nabla v \\, \\mathrm{d}x\\mathrm{d}y = \\int_\\Omega f v \\, \\mathrm{d}x\\mathrm{d}y.\n$$\nThis can be written in abstract bilinear form as: Find $u \\in V$ such that\n$$a(u,v) = L(v) \\quad \\forall v \\in V,$$\nwhere the bilinear form $a(\\cdot,\\cdot): V \\times V \\to \\mathbb{R}$ and the linear functional $L(\\cdot): V \\to \\mathbb{R}$ are defined as:\n$$\na(w,v) = \\int_\\Omega \\nabla w \\cdot \\nabla v \\, \\mathrm{d}x\\mathrm{d}y, \\qquad L(v) = \\int_\\Omega f v \\, \\mathrm{d}x\\mathrm{d}y.\n$$\nThe goal functional is given by $J(u) = \\int_D u \\, \\mathrm{d}x\\mathrm{d}y$. This is a linear functional on $V$.\n\nTo derive the adjoint problem, we seek a representation for the error in the goal functional, $J(u) - J(u_H)$, where $u_H$ is some approximation to $u$. Let the error be $e = u - u_H$. Due to the linearity of $J$, the error in the functional is $J(e) = J(u) - J(u_H)$.\n\nThe adjoint problem is defined by seeking a function $z \\in V$, the adjoint solution, such that the bilinear form $a(w,z)$ represents the goal functional $J(w)$ for any function $w \\in V$. That is, find $z \\in V$ such that:\n$$\na(w,z) = J(w) \\quad \\forall w \\in V.\n$$\nSubstituting the definitions of $a(\\cdot,\\cdot)$ and $J(\\cdot)$, we have:\n$$\n\\int_\\Omega \\nabla w \\cdot \\nabla z \\, \\mathrm{d}x\\mathrm{d}y = \\int_D w \\, \\mathrm{d}x\\mathrm{d}y.\n$$\nThe integral over $D$ can be written as an integral over $\\Omega$ by using the characteristic (indicator) function $\\chi_D$ of the subdomain $D$:\n$$\n\\int_\\Omega \\nabla w \\cdot \\nabla z \\, \\mathrm{d}x\\mathrm{d}y = \\int_\\Omega \\chi_D w \\, \\mathrm{d}x\\mathrm{d}y.\n$$\nTo find the strong form of the adjoint problem, we integrate the left side by parts:\n$$\n\\int_\\Omega (-\\Delta z) w \\, \\mathrm{d}x\\mathrm{d}y + \\int_{\\partial\\Omega} w \\frac{\\partial z}{\\partial n} \\, \\mathrm{d}s = \\int_\\Omega \\chi_D w \\, \\mathrm{d}x\\mathrm{d}y.\n$$\nSince $w \\in H_0^1(\\Omega)$, $w=0$ on the boundary $\\partial\\Omega$, so the boundary integral vanishes. This leaves:\n$$\n\\int_\\Omega (-\\Delta z) w \\, \\mathrm{d}x\\mathrm{d}y = \\int_\\Omega \\chi_D w \\, \\mathrm{d}x\\mathrm{d}y.\n$$\nSince this equality must hold for all test functions $w \\in V$, the integrands must be equal almost everywhere. This gives the strong form of the PDE for the adjoint solution $z$:\n$$\n-\\Delta z = \\chi_D \\quad \\text{in } \\Omega.\n$$\nThe adjoint solution $z$ is sought in the space $V = H_0^1(\\Omega)$, which imposes the boundary condition:\n$$\nz = 0 \\quad \\text{on } \\partial\\Omega.\n$$\nThus, the adjoint problem is another Poisson problem, structurally identical to the primal problem but with a different source term, namely the indicator function of the goal domain $D$.\n\n### Part 2: Two-Grid DWR Estimator\n\nFor the given manufactured solution $u_{\\text{exact}}(x,y) = \\sin(\\pi x)\\sin(\\pi y)$, the source term is $f = -\\Delta u_{\\text{exact}} = -(-\\pi^2\\sin(\\pi x)\\sin(\\pi y) - \\pi^2\\sin(\\pi x)\\sin(\\pi y)) = 2\\pi^2 \\sin(\\pi x)\\sin(\\pi y)$, which matches the problem statement. The adjoint source, derived from first principles in Part 1, is $g = \\chi_D$.\n\nFor a rectangular domain $D = [a_x,b_x]\\times[a_y,b_y]$, the exact goal is\n$$\nJ(u_{\\text{exact}}) = \\int_{a_y}^{b_y} \\int_{a_x}^{b_x} \\sin(\\pi x)\\sin(\\pi y) \\, \\mathrm{d}x \\, \\mathrm{d}y = \\left(\\int_{a_x}^{b_x} \\sin(\\pi x) \\, \\mathrm{d}x\\right) \\left(\\int_{a_y}^{b_y} \\sin(\\pi y) \\, \\mathrm{d}y\\right).\n$$\nThe one-dimensional integral evaluates to $\\int_{a}^{b} \\sin(\\pi \\xi) \\, \\mathrm{d}\\xi = [-\\frac{1}{\\pi}\\cos(\\pi \\xi)]_{a}^{b} = \\frac{1}{\\pi}(\\cos(\\pi a) - \\cos(\\pi b))$. The product of these two results confirms the analytical formula provided.\n\nThe DWR method provides an exact representation for the error in the goal functional: $J(u) - J(u_H) = J(e) = a(e, z) = a(u-u_H, z) = a(u,z) - a(u_H,z) = L(z) - a(u_H, z)$. This expression represents the residual of the approximate solution $u_H$ evaluated on the adjoint solution $z$.\n\nThis exact representation is not directly computable because the exact adjoint solution $z$ is unknown. The DWR error estimator approximates this quantity. A two-grid DWR estimator works as follows:\n1.  Solve for the primal solution $u_H$ on a coarse grid with mesh size $H$.\n2.  Solve for an approximate adjoint solution $z_h$ on a fine grid with mesh size $h  H$.\n3.  Approximate the error by replacing $z$ with $z_h$: $J(u) - J(u_H) \\approx L(z_h) - a(u_H, z_h)$.\n\nThe problem specifies a particular algebraic form of this estimator. Let $A_H u_H = f_H$ be the coarse-grid discrete system and $A_h u_h = f_h$ be the fine-grid system. The error on the fine grid between the true fine-grid solution $u_h$ and the prolongation $\\mathcal{P}u_H$ of the coarse-grid solution is $e_h = u_h - \\mathcal{P}u_H$. This error satisfies the fine-grid system $A_h e_h = A_h u_h - A_h \\mathcal{P}u_H = f_h - A_h \\mathcal{P}u_H =: r_h$, where $r_h$ is the fine-grid residual of the prolongated coarse solution.\n\nThe error in the discrete goal functional is approximately $J_h(u_h) - J_h(u_H) \\approx J_h(u_h) - J_h(\\mathcal{P}u_H) = J_h(e_h)$. Let the discrete goal functional be represented by an inner product with a vector $g_h$, $J_h(v_h) = (g_h, v_h)_h = g_h^T v_h h^2$. The discrete adjoint problem is $A_h z_h = g_h$ (since $A_h$ is symmetric).\nThen, the error in the goal is:\n$$\nJ_h(e_h) = (g_h, e_h)_h = (A_h z_h, e_h)_h = (z_h, A_h e_h)_h = (z_h, r_h)_h.\n$$\nThis inner product $(z_h, r_h)_h = \\sum_i z_{h,i} r_{h,i} h^2$ is exactly the estimator $\\eta_{\\text{full}}$.\n\nThis two-grid estimator accurately approximates the true goal error $J(u) - J(u_H)$ under the key assumption that the fine grid provides a significantly more accurate representation of the problem. Specifically, we assume that the discretization error on the fine grid is negligible compared to the error on the coarse grid, i.e., $J(u) - J_h(u_h) \\ll J(u) - J_H(u_H)$. Under this assumption, $J(u) - J_H(u_H) \\approx J_h(u_h) - J_H(u_H) \\approx J_h(u_h) - J_h(\\mathcal{P}u_H) = \\eta$.\n\n### Part 3: Implementation\n\nThe program will implement the described finite difference discretization and error estimation procedure. It will solve the coarse-grid primal problem, the fine-grid full adjoint problem, and the fine-grid localized adjoint problem. It will then compute the true error $E$, the full DWR estimate $\\eta_{\\text{full}}$, the localized DWR estimate $\\eta_{\\text{loc}}$, and the ratio of degrees of freedom.\n\nThe steps are:\n1.  Define grid parameters $N_H, N_h, H, h$ for each test case.\n2.  Construct the coarse grid Poisson matrix $A_H$ and right-hand side $f_H$. Solve for $u_H$.\n3.  Compute the exact goal $J(u_{\\text{exact}})$ using the analytical formula and the approximate goal $J(u_H)$ by numerical quadrature. Compute the true error $E = J(u_{\\text{exact}}) - J(u_H)$.\n4.  Prolongate $u_H$ to the fine grid to get $\\mathcal{P}u_H$ via bilinear interpolation.\n5.  Construct the fine-grid matrix $A_h$ and right-hand side $f_h$. Compute the fine-grid residual vector $r_h = f_h - A_h \\mathcal{P}u_H$.\n6.  For the full estimator, construct the adjoint source vector $g_h$ (nodal indicator of $D$). Solve the full adjoint system $A_h z_h = g_h$. Compute $\\eta_{\\text{full}} = (r_h, z_h)_h$.\n7.  For the localized estimator, identify the patch of fine-grid nodes around $D$ with radius $r$. Construct and solve the smaller, local adjoint problem. Embed the solution into a zero vector of the full fine-grid size to get $z_h^{\\text{loc}}$. Compute $\\eta_{\\text{loc}} = (r_h, z_h^{\\text{loc}})_h$.\n8.  Calculate the required error metrics and the DOF ratio, format them, and print the final output.\nThe following code implements this procedure.", "answer": "```python\nimport numpy as np\nfrom scipy.sparse import diags\nfrom scipy.sparse.linalg import spsolve\n\ndef get_poisson_matrix(Nx, Ny, h):\n    \"\"\"\n    Constructs the 2D Poisson matrix for a Nx x Ny grid with mesh size h.\n    Represents the negative Laplacian operator, -Delta, assuming row-major\n    (C-style) flattening of the 2D grid, where the x-index is fastest.\n    \"\"\"\n    N = Nx * Ny\n    main_diag = np.ones(N) * 4\n    \n    # Off-diagonals for x-connections (fast index)\n    side_diag_x = np.ones(N - 1) * -1\n    # At block boundaries, no x-connection\n    for i in range(Nx - 1, N - 1, Nx):\n        side_diag_x[i] = 0\n        \n    # Off-diagonals for y-connections (slow index)\n    side_diag_y = np.ones(N - Nx) * -1\n    \n    # Use scipy.sparse.diags to build the matrix\n    A = diags([side_diag_y, side_diag_x, main_diag, side_diag_x, side_diag_y],\n              [-Nx, -1, 0, 1, Nx], shape=(N, N), format='csr')\n              \n    return A / (h**2)\n\ndef solve_poisson_system(N, f_func, h):\n    \"\"\"\n    Solves -Delta u = f on an N x N interior grid with mesh size h.\n    \"\"\"\n    x = np.linspace(h, 1-h, N)\n    y = np.linspace(h, 1-h, N)\n    xx, yy = np.meshgrid(x, y)\n    \n    f_grid = f_func(xx, yy)\n    f_vec = f_grid.flatten()\n    \n    A = get_poisson_matrix(N, N, h)\n    \n    u_vec = spsolve(A, f_vec)\n    \n    return u_vec.reshape((N, N))\n\ndef prolongate_bilinear(u_H, N_H):\n    \"\"\"Bilinear interpolation from N_H x N_H grid to N_h x N_h grid.\"\"\"\n    N_h = 2 * N_H + 1\n    H = 1.0 / (N_H + 1)\n    h = 1.0 / (N_h + 1)\n\n    # Pad coarse solution with zero boundaries\n    u_H_padded = np.zeros((N_H + 2, N_H + 2))\n    u_H_padded[1:-1, 1:-1] = u_H\n\n    u_h_interp = np.zeros((N_h, N_h))\n    \n    fine_x_coords = np.linspace(h, 1-h, N_h)\n    fine_y_coords = np.linspace(h, 1-h, N_h)\n\n    for k, y_val in enumerate(fine_y_coords):\n        for j, x_val in enumerate(fine_x_coords):\n            # Find surrounding coarse grid cell\n            I = int(x_val / H)\n            J = int(y_val / H)\n            \n            x_I = I * H\n            y_J = J * H\n\n            # Local coordinates for interpolation\n            s = (x_val - x_I) / H\n            t = (y_val - y_J) / H\n\n            # Get values at corners of the coarse cell\n            u00 = u_H_padded[J, I]\n            u10 = u_H_padded[J, I + 1]\n            u01 = u_H_padded[J + 1, I]\n            u11 = u_H_padded[J + 1, I + 1]\n\n            # Bilinear interpolation formula\n            val = (1 - s) * (1 - t) * u00 + s * (1 - t) * u10 + \\\n                  (1 - s) * t * u01 + s * t * u11\n            u_h_interp[k, j] = val\n            \n    return u_h_interp\n\ndef solve():\n    test_cases = [\n        (31, (0.25, 0.50, 0.25, 0.75), 8),\n        (31, (0.00, 0.20, 0.00, 0.20), 6),\n        (15, (0.45, 0.55, 0.45, 0.55), 4),\n    ]\n    results = []\n    f_primal = lambda x, y: 2 * np.pi**2 * np.sin(np.pi * x) * np.sin(np.pi * y)\n\n    for N_H, D_rect, r in test_cases:\n        ax, bx, ay, by = D_rect\n\n        # 1. Grid setup\n        N_h = 2 * N_H + 1\n        H = 1.0 / (N_H + 1)\n        h = 1.0 / (N_h + 1)\n\n        # 2. Primal problem on coarse grid\n        u_H = solve_poisson_system(N_H, f_primal, H)\n\n        # 3. Compute goal functional approximations and true error\n        J_exact = ( (np.cos(np.pi * ax) - np.cos(np.pi * bx)) / np.pi *\n                    (np.cos(np.pi * ay) - np.cos(np.pi * by)) / np.pi )\n\n        coarse_x = np.linspace(H, 1-H, N_H)\n        coarse_y = np.linspace(H, 1-H, N_H)\n        cxx, cyy = np.meshgrid(coarse_x, coarse_y)\n        nodes_in_D_mask_coarse = (cxx >= ax)  (cxx = bx)  (cyy >= ay)  (cyy = by)\n        J_uH = np.sum(u_H[nodes_in_D_mask_coarse]) * H**2\n        E = J_exact - J_uH\n\n        # 4. Two-grid estimator setup: residual calculation\n        u_h_interp = prolongate_bilinear(u_H, N_H)\n        u_h_interp_vec = u_h_interp.flatten()\n\n        A_h = get_poisson_matrix(N_h, N_h, h)\n\n        fine_x = np.linspace(h, 1-h, N_h)\n        fine_y = np.linspace(h, 1-h, N_h)\n        fxx, fyy = np.meshgrid(fine_x, fine_y)\n        f_h_grid = f_primal(fxx, fyy)\n        f_h_vec = f_h_grid.flatten()\n        \n        r_h_vec = f_h_vec - A_h @ u_h_interp_vec\n\n        # 5. Full DWR estimator\n        g_h_mask = (fxx >= ax)  (fxx = bx)  (fyy >= ay)  (fyy = by)\n        g_h_vec = g_h_mask.flatten().astype(float)\n        \n        z_h_vec = spsolve(A_h, g_h_vec)\n        eta_full = np.dot(r_h_vec, z_h_vec) * h**2\n\n        # 6. Localized DWR estimator\n        # Find bounding box of nodes in D\n        node_indices_in_D = np.where(g_h_mask.flatten())[0]\n        if len(node_indices_in_D) == 0:\n            eta_loc, dof_loc = 0.0, 0\n        else:\n            j_coords_D = node_indices_in_D % N_h\n            k_coords_D = node_indices_in_D // N_h\n            j_min_D, j_max_D = j_coords_D.min(), j_coords_D.max()\n            k_min_D, k_max_D = k_coords_D.min(), k_coords_D.max()\n\n            # Expand box by radius r\n            j_loc_min = max(0, j_min_D - r)\n            j_loc_max = min(N_h - 1, j_max_D + r)\n            k_loc_min = max(0, k_min_D - r)\n            k_loc_max = min(N_h - 1, k_max_D + r)\n            \n            Nx_loc = j_loc_max - j_loc_min + 1\n            Ny_loc = k_loc_max - k_loc_min + 1\n            dof_loc = Nx_loc * Ny_loc\n\n            A_loc = get_poisson_matrix(Nx_loc, Ny_loc, h)\n            g_loc_grid = g_h_mask[k_loc_min:k_loc_max+1, j_loc_min:j_loc_max+1]\n            g_loc_vec = g_loc_grid.flatten().astype(float)\n            \n            if np.any(g_loc_vec > 0):\n                z_loc_vec = spsolve(A_loc, g_loc_vec)\n                \n                z_h_loc_vec = np.zeros(N_h**2)\n                z_loc_grid = z_loc_vec.reshape(Ny_loc, Nx_loc)\n\n                for k_loc in range(Ny_loc):\n                    for j_loc in range(Nx_loc):\n                        glob_j = j_loc_min + j_loc\n                        glob_k = k_loc_min + k_loc\n                        glob_idx = glob_j + glob_k * N_h\n                        z_h_loc_vec[glob_idx] = z_loc_grid[k_loc, j_loc]\n            else: # Patch does not overlap with D\n                z_h_loc_vec = np.zeros(N_h**2)\n\n            eta_loc = np.dot(r_h_vec, z_h_loc_vec) * h**2\n\n        dof_full = N_h**2\n        dof_ratio = dof_loc / dof_full if dof_full > 0 else 0\n        \n        # 7. Collate and append results\n        results.extend([\n            f\"{abs(E):.8f}\",\n            f\"{abs(eta_full - E):.8f}\",\n            f\"{abs(eta_loc - E):.8f}\",\n            f\"{dof_ratio:.8f}\"\n        ])\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3400755"}]}