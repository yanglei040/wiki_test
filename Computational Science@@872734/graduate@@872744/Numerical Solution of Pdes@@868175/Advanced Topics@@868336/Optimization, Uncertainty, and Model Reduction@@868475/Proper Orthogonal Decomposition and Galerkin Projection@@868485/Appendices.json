{"hands_on_practices": [{"introduction": "We begin our practical exploration with a foundational thought experiment. This exercise examines one of the simplest non-trivial dynamical systems, a two-dimensional linear oscillator, to illustrate the core mechanics of Galerkin projection. By reducing this system to a single dimension, we will derive the resulting reduced-order model and uncover a crucial lesson: a formally correct projection can sometimes miss essential qualitative features of the original dynamics. This practice [@problem_id:2432084] serves as a valuable cautionary tale, emphasizing the need to critically assess the capabilities and limitations of a chosen reduced basis.", "problem": "Consider a two-dimensional linear Ordinary Differential Equation (ODE) of the form $\\dot{\\boldsymbol{x}}(t) = A \\boldsymbol{x}(t)$ with $A \\in \\mathbb{R}^{2 \\times 2}$ and the standard Euclidean inner product on $\\mathbb{R}^{2}$. Let $A$ be the skew-symmetric matrix\n$$\nA = \\begin{pmatrix} 0  -\\omega \\\\ \\omega  0 \\end{pmatrix},\n$$\nwhere $\\omega  0$ is a fixed real constant. Suppose we collect a continuous-time snapshot ensemble by evolving the system from the initial condition $\\boldsymbol{x}(0) = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ over the time interval $[0,\\, 2\\pi/\\omega]$ with uniform time weighting, and we build a one-dimensional basis using Proper Orthogonal Decomposition (POD), defined as the dominant eigenvector of the snapshot correlation operator computed with the Euclidean inner product.\n\nUsing only fundamental definitions of Proper Orthogonal Decomposition (POD) and Galerkin projection, and the standard properties of linear time-invariant systems, derive the one-dimensional Galerkin-reduced model $\\dot{a}(t) = a_r\\, a(t)$ obtained by projecting the full system onto the one-dimensional POD subspace. Then, compute the scalar coefficient $a_r$ as an explicit real number.\n\nYour final answer must be the value of $a_r$. No rounding is required, and no units are needed. Express the final answer as a single real number.", "solution": "The problem is first subjected to validation.\n\nStep 1: Extract Givens.\n- The system dynamics are described by the linear Ordinary Differential Equation (ODE) $\\dot{\\boldsymbol{x}}(t) = A \\boldsymbol{x}(t)$, where $\\boldsymbol{x}(t) \\in \\mathbb{R}^{2}$ and $t$ is time.\n- The system matrix $A$ is given as the skew-symmetric matrix $A = \\begin{pmatrix} 0  -\\omega \\\\ \\omega  0 \\end{pmatrix}$ for a constant $\\omega  0$.\n- The inner product is the standard Euclidean inner product on $\\mathbb{R}^{2}$.\n- A continuous-time snapshot ensemble is generated from the initial condition $\\boldsymbol{x}(0) = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ over the time interval $[0, 2\\pi/\\omega]$. The time weighting is uniform.\n- A one-dimensional basis is to be constructed using Proper Orthogonal Decomposition (POD). This basis is specified as the dominant eigenvector of the snapshot correlation operator.\n- The full system is to be projected onto this one-dimensional POD subspace using Galerkin projection to obtain a reduced-order model of the form $\\dot{a}(t) = a_r a(t)$.\n- The task is to derive this model and compute the scalar coefficient $a_r$.\n\nStep 2: Validate Using Extracted Givens.\nThe problem is scientifically grounded, dealing with standard methods in computational engineering (reduced-order modeling, POD, Galerkin projection) applied to a fundamental linear dynamical system (a harmonic oscillator). The problem is objective and well-defined, providing all necessary mathematical objects and parameters. A minor ambiguity exists in the term \"the dominant eigenvector\", as the symmetry of the problem's trajectory leads to a correlation operator with degenerate eigenvalues. However, as will be demonstrated, the final demanded result is independent of the choice of eigenvector from the resulting eigenspace. Thus, this ambiguity does not render the problem ill-posed or unsolvable. The problem is valid.\n\nStep 3: Proceed with Solution.\nThe objective is to find the scalar coefficient $a_r$ in the one-dimensional reduced-order model $\\dot{a}(t) = a_r a(t)$. This model is obtained by a Galerkin projection of the full system $\\dot{\\boldsymbol{x}} = A \\boldsymbol{x}$ onto a one-dimensional POD basis.\n\nLet the one-dimensional POD basis be denoted by the vector $\\boldsymbol{\\phi} \\in \\mathbb{R}^{2}$. By definition, POD basis vectors are orthonormal, so we have $\\boldsymbol{\\phi}^T \\boldsymbol{\\phi} = 1$.\n\nThe reduced-order model (ROM) seeks an approximation of the state $\\boldsymbol{x}(t)$ in the form $\\boldsymbol{\\hat{x}}(t) = a(t) \\boldsymbol{\\phi}$, where $a(t)$ is the time-varying coordinate in the reduced basis.\n\nThe Galerkin projection method requires the residual of the ODE, when evaluated with the approximation $\\boldsymbol{\\hat{x}}(t)$, to be orthogonal to the basis vector $\\boldsymbol{\\phi}$. The residual is $R(t) = \\dot{\\boldsymbol{\\hat{x}}}(t) - A \\boldsymbol{\\hat{x}}(t)$.\n\nThe orthogonality condition is expressed using the Euclidean inner product:\n$$\n\\boldsymbol{\\phi}^T R(t) = 0\n$$\nSubstituting the expressions for $\\boldsymbol{\\hat{x}}(t)$ and its time derivative $\\dot{\\boldsymbol{\\hat{x}}}(t) = \\dot{a}(t) \\boldsymbol{\\phi}$:\n$$\n\\boldsymbol{\\phi}^T (\\dot{a}(t) \\boldsymbol{\\phi} - A (a(t) \\boldsymbol{\\phi})) = 0\n$$\nBy linearity of the inner product, we can separate the terms:\n$$\n\\boldsymbol{\\phi}^T (\\dot{a}(t) \\boldsymbol{\\phi}) - \\boldsymbol{\\phi}^T (a(t) A \\boldsymbol{\\phi}) = 0\n$$\nThe scalar coefficients $\\dot{a}(t)$ and $a(t)$ can be factored out:\n$$\n\\dot{a}(t) (\\boldsymbol{\\phi}^T \\boldsymbol{\\phi}) - a(t) (\\boldsymbol{\\phi}^T A \\boldsymbol{\\phi}) = 0\n$$\nGiven that the basis vector $\\boldsymbol{\\phi}$ is normalized, $\\boldsymbol{\\phi}^T \\boldsymbol{\\phi} = 1$. The equation simplifies to:\n$$\n\\dot{a}(t) = (\\boldsymbol{\\phi}^T A \\boldsymbol{\\phi}) a(t)\n$$\nThis is the one-dimensional Galerkin-reduced model. By comparing this to the required form $\\dot{a}(t) = a_r a(t)$, we identify the coefficient $a_r$ as:\n$$\na_r = \\boldsymbol{\\phi}^T A \\boldsymbol{\\phi}\n$$\nThe value $a_r$ is a scalar, representing the Rayleigh quotient of the matrix $A$ with respect to the vector $\\boldsymbol{\\phi}$.\n\nWe can determine the value of $a_r$ by exploiting the properties of the matrix $A$, without needing to explicitly compute the POD basis vector $\\boldsymbol{\\phi}$. The problem states that $A$ is a skew-symmetric matrix. By definition, a matrix is skew-symmetric if its transpose is equal to its negative, i.e., $A^T = -A$.\n\nLet us consider the transpose of the scalar $a_r$. As a scalar, $a_r$ is equal to its own transpose: $a_r^T = a_r$.\nNow, let's compute the transpose of the expression for $a_r$:\n$$\na_r^T = (\\boldsymbol{\\phi}^T A \\boldsymbol{\\phi})^T\n$$\nUsing the property of matrix transpose $(BC)^T = C^T B^T$, and noting that $\\boldsymbol{\\phi}$ is a column vector so $\\boldsymbol{\\phi}^T$ is a row vector, we have:\n$$\na_r^T = \\boldsymbol{\\phi}^T A^T (\\boldsymbol{\\phi}^T)^T = \\boldsymbol{\\phi}^T A^T \\boldsymbol{\\phi}\n$$\nNow, we use the skew-symmetric property, $A^T = -A$:\n$$\na_r^T = \\boldsymbol{\\phi}^T (-A) \\boldsymbol{\\phi} = -(\\boldsymbol{\\phi}^T A \\boldsymbol{\\phi})\n$$\nBy the definition of $a_r$, this means:\n$$\na_r^T = -a_r\n$$\nWe have thus established two facts: $a_r = a_r^T$ and $a_r^T = -a_r$. Combining these gives:\n$$\na_r = -a_r\n$$\nThis equation implies $2 a_r = 0$, which has the unique solution for a real number $a_r$:\n$$\na_r = 0\n$$\nThis result is general for any one-dimensional Galerkin projection of a linear system governed by a real skew-symmetric matrix. It is independent of the specific basis vector $\\boldsymbol{\\phi}$ used for the projection. Therefore, despite the degeneracy of the POD problem for this specific circular trajectory (where the correlation matrix is proportional to the identity matrix, $C = \\frac{\\pi}{\\omega}I$, and any vector is an eigenvector), the resulting reduced model coefficient $a_r$ is unique and unambiguous. The reduced model is $\\dot{a}(t) = 0$, which correctly captures the energy-conserving nature of the full system, as the reduced \"energy\" $\\frac{1}{2}a(t)^2$ is constant.", "answer": "$$\\boxed{0}$$", "id": "2432084"}, {"introduction": "Moving from linear systems to the complexities of the real world often means confronting nonlinearity. A key to creating efficient reduced-order models is to handle nonlinear terms in a way that does not require expensive computations at every time step. This practice [@problem_id:3436025] demonstrates a fundamental technique for systems with quadratic nonlinearities, showing how the Galerkin projection leads to a third-order tensor whose entries can be pre-computed. Mastering this \"offline/online\" decomposition is essential for developing practical, fast-running nonlinear reduced-order models.", "problem": "Consider a spatially semi-discretized nonlinear partial differential equation with $N$ degrees of freedom that yields an ordinary differential equation of the form\n$$\n\\frac{d}{dt} x(t) = A\\,x(t) + B\\big(x(t)\\odot x(t)\\big),\n$$\nwhere $x(t)\\in\\mathbb{R}^N$, $A\\in\\mathbb{R}^{N\\times N}$ is a linear operator, $B\\in\\mathbb{R}^{N\\times N}$ is a linear mapping applied after the Hadamard (componentwise) product, and $\\odot$ denotes the Hadamard product. Suppose a Proper Orthogonal Decomposition (POD) basis $U=\\big[u_1,\\dots,u_r\\big]\\in\\mathbb{R}^{N\\times r}$ with orthonormal columns in the Euclidean inner product is obtained, and the Galerkin projection is performed with the ansatz $x(t)\\approx U\\,a(t)$, where $a(t)\\in\\mathbb{R}^r$ are reduced coordinates. The reduced model is formed by enforcing the Galerkin condition with the Euclidean inner product on $\\operatorname{span}\\{u_1,\\dots,u_r\\}$.\n\nPart $(i)$: Starting from the definition of the Galerkin projection, derive the reduced quadratic term in a form suitable for offline precomputation and fast online evaluation. Your derivation must begin from the substitution $x(t)\\approx U\\,a(t)$ into the full model and the orthogonality (Galerkin) condition. Clearly identify the third-order tensor entries governing the quadratic term, expressed purely in terms of $B$ and the POD basis vectors $\\{u_i\\}_{i=1}^r$. You may assume no special structure of $B$ beyond linearity.\n\nPart $(ii)$: Specialize to $N=4$ and $r=3$ with the following data:\n$$\nB =\n\\begin{pmatrix}\n2  -1  0  0\\\\\n1  \\phantom{-}3  2  0\\\\\n0  -2  1  4\\\\\n0  \\phantom{-}0  3  -1\n\\end{pmatrix},\\quad\nu_1 =\n\\begin{pmatrix}\n1\\\\ 0\\\\ 0\\\\ 0\n\\end{pmatrix},\\quad\nu_2 =\\frac{1}{\\sqrt{2}}\n\\begin{pmatrix}\n0\\\\ 1\\\\ 1\\\\ 0\n\\end{pmatrix},\\quad\nu_3 =\\frac{1}{\\sqrt{2}}\n\\begin{pmatrix}\n0\\\\ 1\\\\ -1\\\\ 0\n\\end{pmatrix}.\n$$\nUsing your result from Part $(i)$, compute the specific reduced tensor entry corresponding to the quadratic term coefficient $C_{1,2,3}$ in the reduced model. Provide your final answer as a single real number. No rounding is required, and no physical units are involved.", "solution": "The problem is valid as it is scientifically grounded in the theory of model order reduction, is well-posed with all necessary information provided and no contradictions, and is expressed in objective, formal language. We can proceed with the solution.\n\n### Part (i): Derivation of the Reduced Quadratic Term\n\nWe are given the full-order model, which is a system of ordinary differential equations (ODEs):\n$$\n\\frac{d}{dt} x(t) = A\\,x(t) + B\\big(x(t)\\odot x(t)\\big)\n$$\nwhere $x(t) \\in \\mathbb{R}^N$. We seek a reduced-order model (ROM) using a Galerkin projection onto the subspace spanned by the columns of the POD basis matrix $U = [u_1, \\dots, u_r] \\in \\mathbb{R}^{N\\times r}$. The columns of $U$ are orthonormal, satisfying $u_i^T u_j = \\delta_{ij}$ for $i,j \\in \\{1, \\dots, r\\}$.\n\nThe Galerkin ansatz approximates the high-dimensional state $x(t)$ as a linear combination of the basis vectors:\n$$\nx(t) \\approx x_r(t) = U\\,a(t) = \\sum_{j=1}^{r} a_j(t) u_j\n$$\nwhere $a(t) \\in \\mathbb{R}^r$ is the vector of reduced (or generalized) coordinates.\n\nWe substitute this ansatz into the full-order model. Since $U$ is a constant matrix, the time derivative of the approximation is $\\frac{d}{dt}x_r(t) = U \\frac{d}{dt}a(t) = U \\dot{a}(t)$. The full ODE is not exactly satisfied by the approximation, leaving a residual $R(t)$:\n$$\nR(t) = U \\dot{a}(t) - A(U a(t)) - B\\big((U a(t)) \\odot (U a(t))\\big)\n$$\nThe Galerkin condition requires the residual to be orthogonal to the basis of the projection subspace. This means the Euclidean inner product of the residual with each basis vector $u_i$ must be zero:\n$$\n\\langle R(t), u_i \\rangle = u_i^T R(t) = 0 \\quad \\text{for } i=1, \\dots, r\n$$\nApplying this condition, we have:\n$$\nu_i^T \\left( U \\dot{a}(t) - A U a(t) - B\\big((U a(t)) \\odot (U a(t))\\big) \\right) = 0\n$$\nRearranging the terms gives:\n$$\nu_i^T U \\dot{a}(t) = u_i^T A U a(t) + u_i^T B\\big((U a(t)) \\odot (U a(t))\\big)\n$$\nLet's analyze each term for the $i$-th equation of the reduced system.\n\nFor the left-hand side, we use the orthonormality of the basis vectors:\n$$\nu_i^T U \\dot{a}(t) = u_i^T \\left( \\sum_{k=1}^r \\dot{a}_k(t) u_k \\right) = \\sum_{k=1}^r \\dot{a}_k(t) (u_i^T u_k) = \\sum_{k=1}^r \\dot{a}_k(t) \\delta_{ik} = \\dot{a}_i(t)\n$$\nFor the linear term on the right-hand side:\n$$\nu_i^T A U a(t) = u_i^T A \\left( \\sum_{j=1}^r a_j(t) u_j \\right) = \\sum_{j=1}^r (u_i^T A u_j) a_j(t)\n$$\nThis represents the $i$-th component of the matrix-vector product $A_r a(t)$, where the reduced linear operator is $A_r = U^T A U \\in \\mathbb{R}^{r \\times r}$.\n\nFor the nonlinear term on the right-hand side, we first expand the term inside the operator $B$:\n$$\n(Ua(t)) \\odot (Ua(t)) = \\left(\\sum_{j=1}^r a_j(t) u_j\\right) \\odot \\left(\\sum_{k=1}^r a_k(t) u_k\\right) = \\sum_{j=1}^r \\sum_{k=1}^r a_j(t) a_k(t) (u_j \\odot u_k)\n$$\nNow, we apply the linear operator $B$ and the projection $u_i^T$:\n$$\nu_i^T B\\big((U a(t)) \\odot (U a(t))\\big) = u_i^T B \\left( \\sum_{j=1}^r \\sum_{k=1}^r a_j(t) a_k(t) (u_j \\odot u_k) \\right)\n$$\nBy linearity of $B$ and the projection $u_i^T$:\n$$\nu_i^T B\\big((U a(t)) \\odot (U a(t))\\big) = \\sum_{j=1}^r \\sum_{k=1}^r \\left(u_i^T B(u_j \\odot u_k)\\right) a_j(t) a_k(t)\n$$\nCombining all terms, the $i$-th equation of the reduced system is:\n$$\n\\dot{a}_i(t) = \\sum_{j=1}^r (u_i^T A u_j) a_j(t) + \\sum_{j=1}^r \\sum_{k=1}^r \\left(u_i^T B(u_j \\odot u_k)\\right) a_j(t) a_k(t)\n$$\nThe quadratic term is governed by a third-order tensor $C \\in \\mathbb{R}^{r \\times r \\times r}$, whose entries are given by:\n$$\nC_{i,j,k} = u_i^T B(u_j \\odot u_k)\n$$\nThese tensor entries are constant and depend only on the operator $B$ and the POD basis vectors $\\{u_i\\}_{i=1}^r$. They can be precomputed in an offline stage, allowing for fast online evaluation of the reduced model.\n\n### Part (ii): Computation of the Tensor Entry $C_{1,2,3}$\n\nWe are asked to compute the specific tensor entry $C_{1,2,3}$ for $N=4$ and $r=3$, using the provided data. The formula derived in Part (i) for the tensor entries is $C_{i,j,k} = u_i^T B(u_j \\odot u_k)$. For $(i,j,k) = (1,2,3)$, this becomes:\n$$\nC_{1,2,3} = u_1^T B(u_2 \\odot u_3)\n$$\nThe provided data are:\n$$\nB = \\begin{pmatrix} 2  -1  0  0\\\\ 1  3  2  0\\\\ 0  -2  1  4\\\\ 0  0  3  -1 \\end{pmatrix}, \\quad u_1 = \\begin{pmatrix} 1\\\\ 0\\\\ 0\\\\ 0 \\end{pmatrix}, \\quad u_2 = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 0\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix}, \\quad u_3 = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 0\\\\ 1\\\\ -1\\\\ 0 \\end{pmatrix}\n$$\nFirst, we compute the Hadamard product $u_2 \\odot u_3$:\n$$\nu_2 \\odot u_3 = \\left( \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 0\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix} \\right) \\odot \\left( \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 0\\\\ 1\\\\ -1\\\\ 0 \\end{pmatrix} \\right) = \\frac{1}{2} \\begin{pmatrix} 0 \\cdot 0 \\\\ 1 \\cdot 1 \\\\ 1 \\cdot (-1) \\\\ 0 \\cdot 0 \\end{pmatrix} = \\frac{1}{2} \\begin{pmatrix} 0 \\\\ 1 \\\\ -1 \\\\ 0 \\end{pmatrix}\n$$\nLet's denote this resulting vector as $v = u_2 \\odot u_3$. Next, we apply the operator $B$ to $v$:\n$$\nB v = B (u_2 \\odot u_3) = \\begin{pmatrix} 2  -1  0  0\\\\ 1  3  2  0\\\\ 0  -2  1  4\\\\ 0  0  3  -1 \\end{pmatrix} \\left( \\frac{1}{2} \\begin{pmatrix} 0 \\\\ 1 \\\\ -1 \\\\ 0 \\end{pmatrix} \\right)\n$$\n$$\nB v = \\frac{1}{2} \\begin{pmatrix} 2(0) + (-1)(1) + 0(-1) + 0(0) \\\\ 1(0) + 3(1) + 2(-1) + 0(0) \\\\ 0(0) + (-2)(1) + 1(-1) + 4(0) \\\\ 0(0) + 0(1) + 3(-1) + (-1)(0) \\end{pmatrix} = \\frac{1}{2} \\begin{pmatrix} -1 \\\\ 1 \\\\ -3 \\\\ -3 \\end{pmatrix}\n$$\nFinally, we compute the dot product of this result with $u_1^T$:\n$$\nC_{1,2,3} = u_1^T (B v) = \\begin{pmatrix} 1  0  0  0 \\end{pmatrix} \\left( \\frac{1}{2} \\begin{pmatrix} -1 \\\\ 1 \\\\ -3 \\\\ -3 \\end{pmatrix} \\right)\n$$\nThis operation simply extracts the first component of the vector $Bv$:\n$$\nC_{1,2,3} = \\frac{1}{2} \\times (-1) = -\\frac{1}{2}\n$$\nThus, the value of the specified tensor entry is $-\\frac{1}{2}$.", "answer": "$$\\boxed{-\\frac{1}{2}}$$", "id": "3436025"}, {"introduction": "The theoretical elegance of model reduction must eventually meet the practical realities of numerical implementation. When building a ROM for a time-dependent problem, a critical choice emerges: do we project the continuous equations first and then apply a time-stepping scheme (\"project-first\"), or do we discretize the full system first and then project the resulting algebraic update (\"discretize-first\")? This exercise [@problem_id:3435971] delves into this dilemma. Through a careful asymptotic analysis, we will quantify the \"commutation error\" between these two approaches, providing crucial insights into the sources of error in practical ROM simulations.", "problem": "Consider the linear parabolic partial differential equation $u_{t} = \\alpha u_{xx}$ on the spatial interval $[0,1]$ with homogeneous Dirichlet boundary conditions $u(0,t) = u(1,t) = 0$. Let a standard second-order centered finite-difference semi-discretization with $N=3$ interior points and uniform mesh be used, yielding the system of ordinary differential equations $\\frac{d}{dt} \\boldsymbol{u}(t) = A \\boldsymbol{u}(t)$, where $\\boldsymbol{u}(t) \\in \\mathbb{R}^{3}$ and\n$$\nA = \\begin{pmatrix}\n-2  1  0 \\\\\n1  -2  1 \\\\\n0  1  -2\n\\end{pmatrix}.\n$$\nSuppose a Proper Orthogonal Decomposition (POD) subspace of dimension $r=2$ is given by an orthonormal basis $V \\in \\mathbb{R}^{3 \\times 2}$ whose columns are $V = \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 0  0 \\end{pmatrix}$. Denote the orthogonal projector onto the POD subspace by $P = V V^{\\top}$ and the reduced operator by $\\widehat{A} = V^{\\top} A V \\in \\mathbb{R}^{2 \\times 2}$. Consider the implicit (backward) Euler one-step time discretization with time step $h  0$.\n\nTwo reduced modeling strategies are considered:\n- Project-first (Galerkin-before-discretization): The reduced state $\\boldsymbol{z}(t) \\in \\mathbb{R}^{2}$ satisfies $\\frac{d}{dt} \\boldsymbol{z}(t) = \\widehat{A} \\boldsymbol{z}(t)$, and the implicit Euler update is $\\boldsymbol{z}_{n+1}^{\\mathrm{pf}} = (I - h \\widehat{A})^{-1} \\boldsymbol{z}_{n}$.\n- Discretize-first (projection-after-discretization): The full implicit Euler step is $\\boldsymbol{u}_{n+1} = (I - h A)^{-1} \\boldsymbol{u}_{n}$, and projection yields $\\boldsymbol{z}_{n+1}^{\\mathrm{df}} = V^{\\top} \\boldsymbol{u}_{n+1} = V^{\\top} (I - h A)^{-1} V \\boldsymbol{z}_{n}$, assuming $\\boldsymbol{u}_{n} = V \\boldsymbol{z}_{n}$ lies in the POD subspace at step $n$.\n\nDefine the one-step discrepancy in reduced coordinates by $\\boldsymbol{e}(h; \\boldsymbol{z}_{n}) = \\boldsymbol{z}_{n+1}^{\\mathrm{df}} - \\boldsymbol{z}_{n+1}^{\\mathrm{pf}}$. Starting from the fundamental definitions above (Galerkin projection, implicit Euler scheme, and linear algebra identities), derive the leading-order asymptotic expression of $\\boldsymbol{e}(h; \\boldsymbol{z}_{n})$ as $h \\to 0$ and then specialize to the given $A$, $V$, and initial reduced state $\\boldsymbol{z}_{n} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$. Compute the coefficient $c \\in \\mathbb{R}$ such that the one-step error norm satisfies $\\|\\boldsymbol{e}(h; \\boldsymbol{z}_{n})\\|_{2} = c h^{2} + o(h^{2})$ as $h \\to 0$. Report only the numerical value of $c$ as your final answer.", "solution": "The problem is subjected to validation.\n\n### Step 1: Extract Givens\n- **PDE and Domain**: Linear parabolic PDE $u_{t} = \\alpha u_{xx}$ on $[0,1]$ with homogeneous Dirichlet boundary conditions $u(0,t) = u(1,t) = 0$.\n- **Semi-discretization**: A second-order centered finite-difference scheme with $N=3$ interior points results in the system of ODEs $\\frac{d}{dt} \\boldsymbol{u}(t) = A \\boldsymbol{u}(t)$, where $\\boldsymbol{u}(t) \\in \\mathbb{R}^{3}$.\n- **System Matrix**:\n$$\nA = \\begin{pmatrix}\n-2  1  0 \\\\\n1  -2  1 \\\\\n0  1  -2\n\\end{pmatrix}\n$$\n- **POD Subspace**: A POD subspace of dimension $r=2$ is defined by the orthonormal basis $V \\in \\mathbb{R}^{3 \\times 2}$ with columns given by:\n$$\nV = \\begin{pmatrix}\n1  0 \\\\\n0  1 \\\\\n0  0\n\\end{pmatrix}\n$$\n- **Projector and Reduced Operator**: The orthogonal projector is $P = V V^{\\top}$, and the reduced operator is $\\widehat{A} = V^{\\top} A V \\in \\mathbb{R}^{2 \\times 2}$.\n- **Time Discretization**: Implicit (backward) Euler with time step $h  0$.\n- **Project-First (Galerkin-before-discretization) Model**: The reduced state evolution is $\\frac{d}{dt} \\boldsymbol{z}(t) = \\widehat{A} \\boldsymbol{z}(t)$, with the update rule $\\boldsymbol{z}_{n+1}^{\\mathrm{pf}} = (I - h \\widehat{A})^{-1} \\boldsymbol{z}_{n}$.\n- **Discretize-First (Projection-after-discretization) Model**: The full state is updated via $\\boldsymbol{u}_{n+1} = (I - h A)^{-1} \\boldsymbol{u}_{n}$, followed by projection: $\\boldsymbol{z}_{n+1}^{\\mathrm{df}} = V^{\\top} \\boldsymbol{u}_{n+1}$. Assuming $\\boldsymbol{u}_{n} = V \\boldsymbol{z}_{n}$, this leads to $\\boldsymbol{z}_{n+1}^{\\mathrm{df}} = V^{\\top} (I - h A)^{-1} V \\boldsymbol{z}_{n}$.\n- **Discrepancy Definition**: $\\boldsymbol{e}(h; \\boldsymbol{z}_{n}) = \\boldsymbol{z}_{n+1}^{\\mathrm{df}} - \\boldsymbol{z}_{n+1}^{\\mathrm{pf}}$.\n- **Initial State**: The reduced state at step $n$ is $\\boldsymbol{z}_{n} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$.\n- **Objective**: Find the coefficient $c \\in \\mathbb{R}$ such that the one-step error norm satisfies $\\|\\boldsymbol{e}(h; \\boldsymbol{z}_{n})\\|_{2} = c h^{2} + o(h^{2})$ as $h \\to 0$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed for validity.\n- **Scientifically Grounded**: The problem is set in the context of numerical methods for partial differential equations, specifically model order reduction using Proper Orthogonal Decomposition (POD) and Galerkin projection. The comparison between \"project-first\" and \"discretize-first\" approaches is a standard and fundamental topic in this field. All mathematical constructs (matrices, time integration schemes, projectors) are standard. The problem is scientifically sound.\n- **Well-Posed**: All necessary data ($A$, $V$, $\\boldsymbol{z}_n$), definitions, and relationships are provided. The task is to perform a well-defined asymptotic analysis and calculation, for which a unique answer exists.\n- **Objective**: The problem is stated using precise mathematical language, free from ambiguity or subjective claims.\n\nThe problem does not exhibit any of the invalidity flaws. It is a well-defined, self-contained, and scientifically valid problem from the field of numerical analysis.\n\n### Step 3: Verdict and Action\nThe problem is valid. A detailed solution will be provided.\n\nThe one-step discrepancy in the reduced coordinates is defined as $\\boldsymbol{e}(h; \\boldsymbol{z}_{n}) = \\boldsymbol{z}_{n+1}^{\\mathrm{df}} - \\boldsymbol{z}_{n+1}^{\\mathrm{pf}}$.\nUsing the given definitions, we can write this as:\n$$\n\\boldsymbol{e}(h; \\boldsymbol{z}_{n}) = \\left( V^{\\top} (I - h A)^{-1} V - (I - h \\widehat{A})^{-1} \\right) \\boldsymbol{z}_{n}\n$$\nwhere $I$ represents identity matrices of appropriate sizes and $\\widehat{A} = V^{\\top} A V$.\n\nTo find the leading-order asymptotic expression as $h \\to 0$, we use the Neumann series expansion for the matrix inverse, $(I - X)^{-1} = I + X + X^2 + X^3 + \\dots$, which is valid for sufficiently small $h$ (such that $\\|hA\\|  1$ and $\\|h\\widehat{A}\\|  1$).\n\nFirst, we expand the \"discretize-first\" term, $V^{\\top} (I - h A)^{-1} V$:\n$$\nV^{\\top} (I - h A)^{-1} V = V^{\\top} (I + hA + h^2 A^2 + O(h^3)) V = V^{\\top}V + h V^{\\top}AV + h^2 V^{\\top}A^2V + O(h^3)\n$$\nThe basis $V$ is given as orthonormal, which means its columns are orthonormal vectors. This implies $V^{\\top}V = I$, where $I$ is the $2 \\times 2$ identity matrix.\nAlso, by definition, $\\widehat{A} = V^{\\top}AV$. Substituting these into the expansion gives:\n$$\nV^{\\top} (I - h A)^{-1} V = I + h \\widehat{A} + h^2 V^{\\top}A^2V + O(h^3)\n$$\n\nNext, we expand the \"project-first\" term, $(I - h \\widehat{A})^{-1}$:\n$$\n(I - h \\widehat{A})^{-1} = I + h\\widehat{A} + h^2\\widehat{A}^2 + O(h^3)\n$$\n\nNow, we compute the difference between the two operator expansions:\n$$\nV^{\\top} (I - h A)^{-1} V - (I - h \\widehat{A})^{-1} = (I + h \\widehat{A} + h^2 V^{\\top}A^2V) - (I + h\\widehat{A} + h^2\\widehat{A}^2) + O(h^3)\n$$\nThe terms of order $h^0$ and $h^1$ cancel out. The leading-order term is of order $h^2$:\n$$\nh^2(V^{\\top}A^2V - \\widehat{A}^2) + O(h^3)\n$$\nWe can rewrite the coefficient of $h^2$ using the projector $P=VV^{\\top}$. Note that $\\widehat{A}^2 = (V^{\\top}AV)(V^{\\top}AV) = V^{\\top}A(VV^{\\top})AV = V^{\\top}APAV$.\nThus, the difference is:\n$$\nV^{\\top}A^2V - V^{\\top}APAV = V^{\\top}A(I-P)AV\n$$\nThe asymptotic expression for the discrepancy is therefore:\n$$\n\\boldsymbol{e}(h; \\boldsymbol{z}_{n}) = h^2 V^{\\top}A(I-P)AV \\boldsymbol{z}_{n} + O(h^3)\n$$\nThe problem asks for the coefficient $c$ in the expansion of the norm $\\|\\boldsymbol{e}(h; \\boldsymbol{z}_{n})\\|_{2}$. Taking the $L_2$-norm gives:\n$$\n\\|\\boldsymbol{e}(h; \\boldsymbol{z}_{n})\\|_{2} = \\|h^2 V^{\\top}A(I-P)AV \\boldsymbol{z}_{n} + O(h^3)\\|_{2} = h^2 \\|V^{\\top}A(I-P)AV \\boldsymbol{z}_{n}\\|_{2} + O(h^3)\n$$\nComparing this with the required form $\\|\\boldsymbol{e}(h; \\boldsymbol{z}_{n})\\|_{2} = c h^{2} + o(h^{2})$, we identify the coefficient $c$ as:\n$$\nc = \\|V^{\\top}A(I-P)AV \\boldsymbol{z}_{n}\\|_{2}\n$$\nWe now compute this value using the given $A$, $V$, and $\\boldsymbol{z}_n$. For clarity, let $\\boldsymbol{u}_n = V \\boldsymbol{z}_n$. The expression for $c$ becomes $c = \\|V^{\\top}A(I-P)A\\boldsymbol{u}_{n}\\|_{2}$.\n\nThe given quantities are:\n$$\nA = \\begin{pmatrix} -2  1  0 \\\\ 1  -2  1 \\\\ 0  1  -2 \\end{pmatrix}, \\quad V = \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 0  0 \\end{pmatrix}, \\quad \\boldsymbol{z}_{n} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n$$\n1.  Compute the full-space state vector $\\boldsymbol{u}_n$:\n$$\n\\boldsymbol{u}_n = V \\boldsymbol{z}_n = \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 0  0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}\n$$\n2.  Compute the action of the dynamics on this state, $A\\boldsymbol{u}_n$:\n$$\nA\\boldsymbol{u}_n = \\begin{pmatrix} -2  1  0 \\\\ 1  -2  1 \\\\ 0  1  -2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -2(1) + 1(1) + 0(0) \\\\ 1(1) - 2(1) + 1(0) \\\\ 0(1) + 1(1) - 2(0) \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ -1 \\\\ 1 \\end{pmatrix}\n$$\n3.  Compute the orthogonal projector $P = VV^{\\top}$:\n$$\nP = \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 0  0 \\end{pmatrix} \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\end{pmatrix} = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  0 \\end{pmatrix}\n$$\n4.  Compute the projector onto the orthogonal complement, $I-P$:\n$$\nI-P = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{pmatrix} - \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  0 \\end{pmatrix} = \\begin{pmatrix} 0  0  0 \\\\ 0  0  0 \\\\ 0  0  1 \\end{pmatrix}\n$$\n5.  Compute the component of $A\\boldsymbol{u}_n$ that is orthogonal to the POD subspace:\n$$\n(I-P)A\\boldsymbol{u}_n = \\begin{pmatrix} 0  0  0 \\\\ 0  0  0 \\\\ 0  0  1 \\end{pmatrix} \\begin{pmatrix} -1 \\\\ -1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}\n$$\n6.  Apply the dynamics matrix $A$ to this orthogonal component:\n$$\nA((I-P)A\\boldsymbol{u}_n) = \\begin{pmatrix} -2  1  0 \\\\ 1  -2  1 \\\\ 0  1  -2 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\\\ -2 \\end{pmatrix}\n$$\n7.  Project this result back onto the POD subspace by applying $V^{\\top}$:\n$$\nV^{\\top}A((I-P)A\\boldsymbol{u}_n) = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ -2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\n8.  Finally, compute the $L_2$-norm of this vector to find $c$:\n$$\nc = \\left\\| \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\right\\|_{2} = \\sqrt{0^2 + 1^2} = \\sqrt{1} = 1\n$$\nThe coefficient is $c=1$.", "answer": "$$\\boxed{1}$$", "id": "3435971"}]}