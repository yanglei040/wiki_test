{"hands_on_practices": [{"introduction": "The first step in applying the Stochastic Galerkin (SG) method is to project the governing PDE onto the chosen polynomial chaos basis. This foundational exercise guides you through this process for a common scenario: a diffusion problem where uncertainty is described by a Karhunen–Loève expansion. By working through this problem, you will learn how to derive the core coupling matrices that form the building blocks of the final, deterministic SG linear system, a critical skill for tackling any new application. [@problem_id:3432950]", "problem": "Consider a linear elliptic partial differential equation with random diffusion coefficient, given by $-\\nabla \\cdot \\left(a(x,\\boldsymbol{\\xi}) \\nabla u(x,\\boldsymbol{\\xi})\\right) = f(x)$ on a bounded Lipschitz domain, where the randomness enters through a truncated Karhunen–Loève expansion (KLE). The Karhunen–Loève expansion is a representation of a second-order random field as a countable sum of orthogonal spatial modes modulated by uncorrelated random variables. Assume the truncation yields two independent, standard normal random variables $\\boldsymbol{\\xi} = (\\xi_{1},\\xi_{2})$ and an affine parametrization $a(x,\\boldsymbol{\\xi}) = a_{0}(x) + a_{1}(x)\\,\\xi_{1} + a_{2}(x)\\,\\xi_{2}$. In a stochastic Galerkin (sG) method, one seeks $u(x,\\boldsymbol{\\xi})$ in a finite-dimensional tensor space spanned by multivariate polynomial chaos (PC) basis functions.\n\nUse the following foundational facts:\n- The Karhunen–Loève expansion (KLE) produces mutually independent, standard normal variables when the underlying field is Gaussian and centered.\n- For the standard normal measure, the probabilists’ Hermite polynomials $\\mathrm{He}_{n}(\\xi)$ satisfy $\\mathbb{E}\\left[\\mathrm{He}_{m}(\\xi)\\,\\mathrm{He}_{n}(\\xi)\\right] = n!\\,\\delta_{mn}$, and the recurrence $\\,\\xi\\,\\mathrm{He}_{n}(\\xi) = \\mathrm{He}_{n+1}(\\xi) + n\\,\\mathrm{He}_{n-1}(\\xi)$.\n- The multivariate PC basis for Gaussian inputs is formed by tensor products of one-dimensional orthonormal Hermite polynomials with respect to the Gaussian measure.\n\nTask:\n1. Map the KLE variables $\\xi_{i}$ to a multivariate orthonormal polynomial chaos basis $\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})$ indexed by the multi-index $\\boldsymbol{\\alpha} = (\\alpha_{1},\\alpha_{2}) \\in \\mathbb{N}_{0}^{2}$, using only the core definitions above. Explicitly construct $\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})$ from one-dimensional components, and justify orthonormality with respect to the joint standard normal measure.\n2. Starting from the orthonormality of the basis and the Hermite recurrence, derive general closed-form expressions for the stochastic coupling matrices required in sG assembly for the affine coefficient:\n   - The gram matrix $G^{(0)}$ with entries $G^{(0)}_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}} = \\mathbb{E}\\left[\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})\\,\\Psi_{\\boldsymbol{\\beta}}(\\boldsymbol{\\xi})\\right]$.\n   - The affine coupling matrices $G^{(i)}$ with entries $G^{(i)}_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}} = \\mathbb{E}\\left[\\xi_{i}\\,\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})\\,\\Psi_{\\boldsymbol{\\beta}}(\\boldsymbol{\\xi})\\right]$ for $i \\in \\{1,2\\}$.\n3. Consider the total-degree-$2$ truncated multivariate PC space in two dimensions, with index set $\\mathcal{A} = \\{(0,0),(1,0),(0,1),(2,0),(1,1),(0,2)\\}$. Using your general expressions, evaluate the single coupling entry $G^{(1)}_{(2,0),(1,0)}$ exactly. Your final answer must be a single closed-form analytic expression. No rounding is required and no units are involved.", "solution": "The problem is valid as it is scientifically grounded in the theory of numerical methods for PDEs with random inputs, specifically stochastic Galerkin methods using polynomial chaos expansions. It is well-posed, objective, and provides all necessary definitions and relations to derive the requested quantities. We proceed with the solution.\n\nThe solution is structured into three parts as requested by the task.\n\n1.  **Construction of the Multivariate Orthonormal Polynomial Chaos Basis**\n\nThe problem provides the orthogonality relation for the probabilists' Hermite polynomials $\\mathrm{He}_{n}(\\xi)$ with respect to the standard normal measure, where $\\xi \\sim \\mathcal{N}(0,1)$:\n$$\n\\mathbb{E}\\left[\\mathrm{He}_{m}(\\xi)\\,\\mathrm{He}_{n}(\\xi)\\right] = n!\\,\\delta_{mn}\n$$\nHere, $\\mathbb{E}[\\cdot]$ denotes the expectation operator and $\\delta_{mn}$ is the Kronecker delta. The basis polynomials are orthogonal but not orthonormal, as their squared norm is $\\mathbb{E}\\left[\\mathrm{He}_{n}(\\xi)^{2}\\right] = n!$.\n\nTo construct a one-dimensional orthonormal basis, we normalize each polynomial. Let the one-dimensional orthonormal basis functions be denoted by $\\psi_{n}(\\xi)$. We define them as:\n$$\n\\psi_{n}(\\xi) = \\frac{1}{\\sqrt{n!}}\\,\\mathrm{He}_{n}(\\xi)\n$$\nThe orthonormality of this basis is verified by computing the expectation of their product:\n$$\n\\mathbb{E}\\left[\\psi_{m}(\\xi)\\,\\psi_{n}(\\xi)\\right] = \\mathbb{E}\\left[\\left(\\frac{1}{\\sqrt{m!}}\\,\\mathrm{He}_{m}(\\xi)\\right)\\left(\\frac{1}{\\sqrt{n!}}\\,\\mathrm{He}_{n}(\\xi)\\right)\\right] = \\frac{1}{\\sqrt{m!n!}}\\,\\mathbb{E}\\left[\\mathrm{He}_{m}(\\xi)\\,\\mathrm{He}_{n}(\\xi)\\right] = \\frac{1}{\\sqrt{m!n!}}\\,n!\\,\\delta_{mn} = \\delta_{mn}\n$$\nThis confirms that the set $\\{\\psi_{n}(\\xi)\\}_{n \\in \\mathbb{N}_{0}}$ is orthonormal with respect to the standard normal measure.\n\nThe problem specifies a two-dimensional random vector $\\boldsymbol{\\xi} = (\\xi_{1}, \\xi_{2})$ with independent, standard normal components. The multivariate polynomial chaos (PC) basis $\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})$ for a multi-index $\\boldsymbol{\\alpha} = (\\alpha_{1}, \\alpha_{2}) \\in \\mathbb{N}_{0}^{2}$ is formed by the tensor product of the one-dimensional orthonormal basis functions:\n$$\n\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi}) = \\Psi_{(\\alpha_{1}, \\alpha_{2})}(\\xi_{1}, \\xi_{2}) = \\psi_{\\alpha_{1}}(\\xi_{1})\\,\\psi_{\\alpha_{2}}(\\xi_{2})\n$$\nTo justify the orthonormality of this multivariate basis, we compute the expectation of the product of two basis functions, $\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})$ and $\\Psi_{\\boldsymbol{\\beta}}(\\boldsymbol{\\xi})$ for multi-indices $\\boldsymbol{\\alpha} = (\\alpha_{1}, \\alpha_{2})$ and $\\boldsymbol{\\beta} = (\\beta_{1}, \\beta_{2})$. The joint probability density function of $\\boldsymbol{\\xi}$ is the product of the individual standard normal densities due to independence. Thus, the expectation integral separates:\n$$\n\\mathbb{E}\\left[\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})\\,\\Psi_{\\boldsymbol{\\beta}}(\\boldsymbol{\\xi})\\right] = \\mathbb{E}\\left[\\left(\\psi_{\\alpha_{1}}(\\xi_{1})\\,\\psi_{\\alpha_{2}}(\\xi_{2})\\right)\\left(\\psi_{\\beta_{1}}(\\xi_{1})\\,\\psi_{\\beta_{2}}(\\xi_{2})\\right)\\right]\n$$\n$$\n= \\mathbb{E}\\left[\\psi_{\\alpha_{1}}(\\xi_{1})\\,\\psi_{\\beta_{1}}(\\xi_{1})\\,\\psi_{\\alpha_{2}}(\\xi_{2})\\,\\psi_{\\beta_{2}}(\\xi_{2})\\right]\n$$\nDue to the independence of $\\xi_{1}$ and $\\xi_{2}$, the expectation of the product is the product of the expectations:\n$$\n= \\mathbb{E}\\left[\\psi_{\\alpha_{1}}(\\xi_{1})\\,\\psi_{\\beta_{1}}(\\xi_{1})\\right] \\, \\mathbb{E}\\left[\\psi_{\\alpha_{2}}(\\xi_{2})\\,\\psi_{\\beta_{2}}(\\xi_{2})\\right]\n$$\nUsing the one-dimensional orthonormality property $\\mathbb{E}\\left[\\psi_{m}(\\xi)\\,\\psi_{n}(\\xi)\\right] = \\delta_{mn}$, we get:\n$$\n= \\delta_{\\alpha_{1}\\beta_{1}}\\,\\delta_{\\alpha_{2}\\beta_{2}} = \\delta_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}}\n$$\nwhere $\\delta_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}}$ is the multivariate Kronecker delta, which is $1$ if $\\boldsymbol{\\alpha} = \\boldsymbol{\\beta}$ (i.e., $\\alpha_{1}=\\beta_{1}$ and $\\alpha_{2}=\\beta_{2}$) and $0$ otherwise. This confirms the multivariate basis $\\{\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})\\}_{\\boldsymbol{\\alpha} \\in \\mathbb{N}_{0}^{2}}$ is orthonormal with respect to the joint standard normal measure on $\\mathbb{R}^{2}$.\n\n2.  **Derivation of the Stochastic Coupling Matrices**\n\nThe matrices $G^{(0)}$ and $G^{(i)}$ are essential for assembling the linear system in the stochastic Galerkin method.\n\nThe entries of the Gram matrix $G^{(0)}$ are given by $G^{(0)}_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}} = \\mathbb{E}\\left[\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})\\,\\Psi_{\\boldsymbol{\\beta}}(\\boldsymbol{\\xi})\\right]$. As shown in the previous section, this is precisely the orthonormality condition for the basis functions. Therefore, its entries are given by the multivariate Kronecker delta:\n$$\nG^{(0)}_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}} = \\delta_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}}\n$$\nThis means the Gram matrix $G^{(0)}$ is the identity matrix.\n\nThe entries of the affine coupling matrices $G^{(i)}$ are given by $G^{(i)}_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}} = \\mathbb{E}\\left[\\xi_{i}\\,\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})\\,\\Psi_{\\boldsymbol{\\beta}}(\\boldsymbol{\\xi})\\right]$ for $i \\in \\{1,2\\}$. Let us derive the expression for $G^{(1)}_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}}$:\n$$\nG^{(1)}_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}} = \\mathbb{E}\\left[\\xi_{1}\\,\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})\\,\\Psi_{\\boldsymbol{\\beta}}(\\boldsymbol{\\xi})\\right] = \\mathbb{E}\\left[\\xi_{1}\\,\\psi_{\\alpha_{1}}(\\xi_{1})\\psi_{\\alpha_{2}}(\\xi_{2})\\,\\psi_{\\beta_{1}}(\\xi_{1})\\psi_{\\beta_{2}}(\\xi_{2})\\right]\n$$\nGrouping terms by variable and using independence:\n$$\nG^{(1)}_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}} = \\mathbb{E}\\left[\\xi_{1}\\,\\psi_{\\alpha_{1}}(\\xi_{1})\\,\\psi_{\\beta_{1}}(\\xi_{1})\\right] \\, \\mathbb{E}\\left[\\psi_{\\alpha_{2}}(\\xi_{2})\\,\\psi_{\\beta_{2}}(\\xi_{2})\\right]\n$$\nThe second term is simply $\\delta_{\\alpha_{2}\\beta_{2}}$. For the first term, we substitute the definition of $\\psi_{n}$ and use the provided recurrence relation for $\\mathrm{He}_{n}$: $\\xi\\,\\mathrm{He}_{n}(\\xi) = \\mathrm{He}_{n+1}(\\xi) + n\\,\\mathrm{He}_{n-1}(\\xi)$.\n$$\n\\mathbb{E}\\left[\\xi_{1}\\,\\psi_{\\alpha_{1}}(\\xi_{1})\\,\\psi_{\\beta_{1}}(\\xi_{1})\\right] = \\frac{1}{\\sqrt{\\alpha_{1}!\\,\\beta_{1}!}}\\,\\mathbb{E}\\left[\\xi_{1}\\,\\mathrm{He}_{\\alpha_{1}}(\\xi_{1})\\,\\mathrm{He}_{\\beta_{1}}(\\xi_{1})\\right]\n$$\n$$\n= \\frac{1}{\\sqrt{\\alpha_{1}!\\,\\beta_{1}!}}\\,\\mathbb{E}\\left[\\left(\\mathrm{He}_{\\alpha_{1}+1}(\\xi_{1}) + \\alpha_{1}\\,\\mathrm{He}_{\\alpha_{1}-1}(\\xi_{1})\\right)\\,\\mathrm{He}_{\\beta_{1}}(\\xi_{1})\\right]\n$$\nBy linearity of expectation and the orthogonality of $\\mathrm{He}_n$:\n$$\n= \\frac{1}{\\sqrt{\\alpha_{1}!\\,\\beta_{1}!}}\\,\\left(\\mathbb{E}\\left[\\mathrm{He}_{\\alpha_{1}+1}(\\xi_{1})\\,\\mathrm{He}_{\\beta_{1}}(\\xi_{1})\\right] + \\alpha_{1}\\mathbb{E}\\left[\\mathrm{He}_{\\alpha_{1}-1}(\\xi_{1})\\,\\mathrm{He}_{\\beta_{1}}(\\xi_{1})\\right]\\right)\n$$\n$$\n= \\frac{1}{\\sqrt{\\alpha_{1}!\\,\\beta_{1}!}}\\,\\left((\\alpha_{1}+1)!\\,\\delta_{\\beta_{1}, \\alpha_{1}+1} + \\alpha_{1}\\,(\\alpha_{1}-1)!\\,\\delta_{\\beta_{1}, \\alpha_{1}-1}\\right)\n$$\nSince $\\alpha_{1}(\\alpha_{1}-1)! = \\alpha_{1}!$:\n$$\n= \\frac{(\\alpha_{1}+1)!}{\\sqrt{\\alpha_{1}!\\,\\beta_{1}!}}\\,\\delta_{\\beta_{1}, \\alpha_{1}+1} + \\frac{\\alpha_{1}!}{\\sqrt{\\alpha_{1}!\\,\\beta_{1}!}}\\,\\delta_{\\beta_{1}, \\alpha_{1}-1}\n$$\nThis expression is non-zero only if $\\beta_{1} = \\alpha_{1}+1$ or $\\beta_{1} = \\alpha_{1}-1$.\nIf $\\beta_{1} = \\alpha_{1}+1$: the expression becomes $\\frac{(\\alpha_{1}+1)!}{\\sqrt{\\alpha_{1}!\\,(\\alpha_{1}+1)!}} = \\sqrt{\\alpha_{1}+1}$.\nIf $\\beta_{1} = \\alpha_{1}-1$: the expression becomes $\\frac{\\alpha_{1}!}{\\sqrt{\\alpha_{1}!\\,(\\alpha_{1}-1)!}} = \\sqrt{\\alpha_{1}}$.\nThus, we can write the first term as:\n$$\n\\mathbb{E}\\left[\\xi_{1}\\,\\psi_{\\alpha_{1}}(\\xi_{1})\\,\\psi_{\\beta_{1}}(\\xi_{1})\\right] = \\sqrt{\\alpha_{1}+1}\\,\\delta_{\\beta_{1}, \\alpha_{1}+1} + \\sqrt{\\alpha_{1}}\\,\\delta_{\\beta_{1}, \\alpha_{1}-1}\n$$\nCombining this with the term $\\delta_{\\alpha_{2}\\beta_{2}}$, the general expression for $G^{(1)}_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}}$ is:\n$$\nG^{(1)}_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}} = \\left(\\sqrt{\\alpha_{1}+1}\\,\\delta_{\\beta_{1}, \\alpha_{1}+1} + \\sqrt{\\alpha_{1}}\\,\\delta_{\\beta_{1}, \\alpha_{1}-1}\\right)\\,\\delta_{\\alpha_{2}\\beta_{2}}\n$$\nBy symmetry, the expression for $G^{(2)}_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}}$ is obtained by swapping the roles of indices $1$ and $2$:\n$$\nG^{(2)}_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}} = \\left(\\sqrt{\\alpha_{2}+1}\\,\\delta_{\\beta_{2}, \\alpha_{2}+1} + \\sqrt{\\alpha_{2}}\\,\\delta_{\\beta_{2}, \\alpha_{2}-1}\\right)\\,\\delta_{\\alpha_{1}\\beta_{1}}\n$$\n\n3.  **Evaluation of a Specific Coupling Entry**\n\nWe are asked to evaluate the entry $G^{(1)}_{(2,0),(1,0)}$. This corresponds to setting the multi-indices as $\\boldsymbol{\\alpha} = (2,0)$ and $\\boldsymbol{\\beta} = (1,0)$. Thus, we have $\\alpha_{1}=2$, $\\alpha_{2}=0$, $\\beta_{1}=1$, and $\\beta_{2}=0$.\n\nWe use the derived expression for $G^{(1)}_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}}$:\n$$\nG^{(1)}_{(2,0),(1,0)} = \\left(\\sqrt{2+1}\\,\\delta_{1, 2+1} + \\sqrt{2}\\,\\delta_{1, 2-1}\\right)\\,\\delta_{0,0}\n$$\nNow we evaluate the Kronecker deltas:\n- $\\delta_{1, 2+1} = \\delta_{1,3} = 0$.\n- $\\delta_{1, 2-1} = \\delta_{1,1} = 1$.\n- $\\delta_{0,0} = 1$.\n\nSubstituting these values into the expression:\n$$\nG^{(1)}_{(2,0),(1,0)} = \\left(\\sqrt{3} \\cdot 0 + \\sqrt{2} \\cdot 1\\right) \\cdot 1\n$$\n$$\nG^{(1)}_{(2,0),(1,0)} = \\left(0 + \\sqrt{2}\\right) \\cdot 1 = \\sqrt{2}\n$$\nThe exact value of the coupling entry is $\\sqrt{2}$.", "answer": "$$\\boxed{\\sqrt{2}}$$", "id": "3432950"}, {"introduction": "Once the Stochastic Galerkin system is assembled, we face the practical challenge of solving a large, often ill-conditioned, linear system. This practice explores a crucial aspect of this process: preconditioning. You will analyze a simplified but representative problem to derive an exact expression for the condition number of a preconditioned SG operator, connecting the statistical properties of the random input directly to the numerical stability of the discrete system. [@problem_id:3432959]", "problem": "Consider the scalar elliptic Partial Differential Equation (PDE) $-\\nabla \\cdot \\left(a(\\xi)\\nabla u(x,\\xi)\\right)=f(x)$ on the domain $D=(0,1)$ with homogeneous Dirichlet boundary conditions. Assume a conforming finite element spatial discretization with a fixed basis yields the deterministic stiffness matrix $K_{1}$ for the unit-coefficient operator, so that for any spatially constant coefficient $a(\\xi)$, the stiffness matrix is $K(a(\\xi))=a(\\xi)\\,K_{1}$. Let the input coefficient be an affine random field that is constant in space, $a(\\xi)=a_{0}+a_{1}\\,\\xi$, where $\\xi$ is uniformly distributed on $\\left[-1,1\\right]$, and assume $a_{0}|a_{1}|$ so that $a(\\xi)0$ almost surely.\n\nAdopt a Polynomial Chaos Expansion (PCE) basis of total degree at most $1$ with respect to the uniform law, namely the orthonormal Legendre basis $\\{\\phi_{0}(\\xi),\\phi_{1}(\\xi)\\}$ defined by $\\phi_{0}(\\xi)=1$ and $\\phi_{1}(\\xi)=\\sqrt{3}\\,\\xi$, so that $\\mathbb{E}[\\phi_{i}\\phi_{j}]=\\delta_{ij}$. Form the Stochastic Galerkin (SG) system in this basis, which yields a $2\\times 2$ block system $A \\in \\mathbb{R}^{2n\\times 2n}$ of the form $A=G\\otimes K_{1}$, where $G\\in\\mathbb{R}^{2\\times 2}$ has entries $G_{ij}=\\mathbb{E}\\big[a(\\xi)\\,\\phi_{i}(\\xi)\\phi_{j}(\\xi)\\big]$. Consider the mean-based preconditioner $A_{0}=I\\otimes K(a_{0})=I\\otimes (a_{0}K_{1})$.\n\nLet the variance-to-mean ratio be defined by $r_{v}=\\mathrm{Var}[a]/\\big(\\mathbb{E}[a]\\big)^{2}$. Under the above assumptions, derive from first principles the exact spectral condition number of the preconditioned SG operator $A_{0}^{-1}A$ in closed form as a function of $r_{v}$. Your answer must be a single analytical expression in terms of $r_{v}$. No numerical approximation is required. State your final answer as that expression only, with no units.", "solution": "The problem is validated as self-contained, scientifically grounded, and well-posed. The objective is to derive the spectral condition number of the preconditioned Stochastic Galerkin (SG) operator, $\\kappa(A_{0}^{-1}A)$, as a function of the variance-to-mean ratio, $r_{v}$.\n\nThe SG system matrix is given by the Kronecker product $A = G \\otimes K_{1}$, where $K_{1} \\in \\mathbb{R}^{n \\times n}$ is the finite element stiffness matrix for a unit diffusion coefficient, and $G \\in \\mathbb{R}^{2 \\times 2}$ is the Galerkin matrix with entries $G_{ij} = \\mathbb{E}[a(\\xi)\\phi_{i}(\\xi)\\phi_{j}(\\xi)]$ for $i,j \\in \\{0, 1\\}$. The mean-based preconditioner is $A_{0} = I \\otimes K(a_{0})$. Since $K(a(\\xi)) = a(\\xi)K_{1}$, we have $K(a_{0}) = a_{0}K_{1}$. The preconditioner is thus $A_{0} = I \\otimes (a_{0}K_{1}) = a_{0}(I \\otimes K_{1})$.\n\nThe inverse of the preconditioner is $A_{0}^{-1} = (a_{0}(I \\otimes K_{1}))^{-1} = a_{0}^{-1}(I \\otimes K_{1}^{-1})$. The preconditioned operator is then:\n$$A_{0}^{-1}A = \\left(a_{0}^{-1}(I \\otimes K_{1}^{-1})\\right) (G \\otimes K_{1})$$\nUsing the mixed-product property of the Kronecker product, $(P \\otimes Q)(R \\otimes S) = (PR) \\otimes (QS)$, we have:\n$$A_{0}^{-1}A = (a_{0}^{-1}IG) \\otimes (K_{1}^{-1}K_{1}) = (a_{0}^{-1}G) \\otimes I_{n}$$\nwhere $I_{n}$ is the identity matrix of size $n \\times n$.\n\nThe eigenvalues of a Kronecker product $M \\otimes N$ are the products of the eigenvalues of $M$ and the eigenvalues of $N$. The eigenvalues of the identity matrix $I_{n}$ are all equal to $1$. Therefore, the spectrum of the preconditioned operator $A_{0}^{-1}A$ consists of the eigenvalues of the matrix $a_{0}^{-1}G$, each with algebraic multiplicity $n$. The problem thus reduces to finding the eigenvalues of $a_{0}^{-1}G$.\n\nFirst, we compute the entries of the matrix $G$. The random variable $\\xi$ is uniformly distributed on $[-1, 1]$, so the expectation operator is $\\mathbb{E}[f(\\xi)] = \\frac{1}{2}\\int_{-1}^{1} f(\\xi)\\,d\\xi$. We will need the moments $\\mathbb{E}[\\xi] = 0$, $\\mathbb{E}[\\xi^{2}] = \\frac{1}{3}$, and $\\mathbb{E}[\\xi^{3}] = 0$.\nThe random coefficient is $a(\\xi) = a_{0} + a_{1}\\xi$. The orthonormal Legendre basis functions are $\\phi_{0}(\\xi)=1$ and $\\phi_{1}(\\xi)=\\sqrt{3}\\xi$.\n\nThe entries $G_{ij}$ are:\n$$G_{00} = \\mathbb{E}[a(\\xi)\\phi_{0}(\\xi)\\phi_{0}(\\xi)] = \\mathbb{E}[(a_{0}+a_{1}\\xi)(1)^{2}] = \\mathbb{E}[a_{0}+a_{1}\\xi] = a_{0} + a_{1}\\mathbb{E}[\\xi] = a_{0}$$\n$$G_{01} = G_{10} = \\mathbb{E}[a(\\xi)\\phi_{0}(\\xi)\\phi_{1}(\\xi)] = \\mathbb{E}[(a_{0}+a_{1}\\xi)(1)(\\sqrt{3}\\xi)] = \\mathbb{E}[\\sqrt{3}a_{0}\\xi + \\sqrt{3}a_{1}\\xi^{2}] = \\sqrt{3}a_{0}\\mathbb{E}[\\xi] + \\sqrt{3}a_{1}\\mathbb{E}[\\xi^{2}] = \\sqrt{3}a_{1}\\left(\\frac{1}{3}\\right) = \\frac{a_{1}}{\\sqrt{3}}$$\n$$G_{11} = \\mathbb{E}[a(\\xi)\\phi_{1}(\\xi)\\phi_{1}(\\xi)] = \\mathbb{E}[(a_{0}+a_{1}\\xi)(\\sqrt{3}\\xi)^{2}] = \\mathbb{E}[(a_{0}+a_{1}\\xi)(3\\xi^{2})] = \\mathbb{E}[3a_{0}\\xi^{2} + 3a_{1}\\xi^{3}] = 3a_{0}\\mathbb{E}[\\xi^{2}] + 3a_{1}\\mathbb{E}[\\xi^{3}] = 3a_{0}\\left(\\frac{1}{3}\\right) = a_{0}$$\nSo, the matrix $G$ is:\n$$G = \\begin{pmatrix} a_{0}  \\frac{a_{1}}{\\sqrt{3}} \\\\ \\frac{a_{1}}{\\sqrt{3}}  a_{0} \\end{pmatrix}$$\nThe eigenvalues $\\lambda$ of $G$ are found from the characteristic equation $\\det(G-\\lambda I)=0$:\n$$(a_{0}-\\lambda)^{2} - \\left(\\frac{a_{1}}{\\sqrt{3}}\\right)^{2} = 0 \\implies a_{0}-\\lambda = \\pm \\frac{a_{1}}{\\sqrt{3}} \\implies \\lambda = a_{0} \\mp \\frac{a_{1}}{\\sqrt{3}}$$\nThe eigenvalues of $G$ are $\\lambda_{1} = a_{0} + \\frac{a_{1}}{\\sqrt{3}}$ and $\\lambda_{2} = a_{0} - \\frac{a_{1}}{\\sqrt{3}}$. Let $\\lambda_{\\max}(G)$ and $\\lambda_{\\min}(G)$ be the maximum and minimum eigenvalues. These are $\\lambda_{\\max}(G) = a_{0} + \\frac{|a_{1}|}{\\sqrt{3}}$ and $\\lambda_{\\min}(G) = a_{0} - \\frac{|a_{1}|}{\\sqrt{3}}$. The condition $a_{0}  |a_{1}|$ ensures $a_{0}  |a_{1}|/\\sqrt{3}$, so $\\lambda_{\\min}(G)  0$.\n\nThe eigenvalues of $A_{0}^{-1}A$ are the eigenvalues of $a_{0}^{-1}G$. Let these be $\\mu$.\n$$\\mu_{\\max} = a_{0}^{-1}\\lambda_{\\max}(G) = a_{0}^{-1}\\left(a_{0} + \\frac{|a_{1}|}{\\sqrt{3}}\\right) = 1 + \\frac{|a_{1}|}{a_{0}\\sqrt{3}}$$\n$$\\mu_{\\min} = a_{0}^{-1}\\lambda_{\\min}(G) = a_{0}^{-1}\\left(a_{0} - \\frac{|a_{1}|}{\\sqrt{3}}\\right) = 1 - \\frac{|a_{1}|}{a_{0}\\sqrt{3}}$$\nSince $\\lambda_{\\min}(G)0$ and $a_{0}0$, both $\\mu_{\\max}$ and $\\mu_{\\min}$ are positive. The spectral condition number is the ratio of the maximum to the minimum eigenvalue:\n$$\\kappa(A_{0}^{-1}A) = \\frac{\\mu_{\\max}}{\\mu_{\\min}} = \\frac{1 + \\frac{|a_{1}|}{a_{0}\\sqrt{3}}}{1 - \\frac{|a_{1}|}{a_{0}\\sqrt{3}}}$$\nNow, we express this result in terms of the variance-to-mean ratio $r_{v} = \\mathrm{Var}[a]/(\\mathbb{E}[a])^{2}$.\nThe mean of $a(\\xi)$ is $\\mathbb{E}[a] = \\mathbb{E}[a_{0} + a_{1}\\xi] = a_{0}$.\nThe variance of $a(\\xi)$ is $\\mathrm{Var}[a] = \\mathrm{Var}[a_{0} + a_{1}\\xi] = a_{1}^{2}\\mathrm{Var}[\\xi]$. For $\\xi \\sim U[-1, 1]$, $\\mathrm{Var}[\\xi] = \\mathbb{E}[\\xi^{2}] - (\\mathbb{E}[\\xi])^{2} = \\frac{1}{3} - 0^{2} = \\frac{1}{3}$.\nSo, $\\mathrm{Var}[a] = \\frac{a_{1}^{2}}{3}$.\nThe variance-to-mean ratio is:\n$$r_{v} = \\frac{\\mathrm{Var}[a]}{(\\mathbb{E}[a])^{2}} = \\frac{a_{1}^{2}/3}{a_{0}^{2}} = \\frac{a_{1}^{2}}{3a_{0}^{2}}$$\nTaking the square root gives $\\sqrt{r_{v}} = \\frac{|a_{1}|}{\\sqrt{3}|a_{0}|}$. Since $a_{0}|a_{1}| \\ge 0$, $a_{0}$ is positive, so $|a_{0}|=a_{0}$.\n$$\\sqrt{r_{v}} = \\frac{|a_{1}|}{a_{0}\\sqrt{3}}$$\nSubstituting this into the expression for the condition number:\n$$\\kappa(A_{0}^{-1}A) = \\frac{1 + \\sqrt{r_{v}}}{1 - \\sqrt{r_{v}}}$$\nThe condition $a_{0}  |a_{1}|$ implies $a_{0}\\sqrt{3}  |a_{1}|\\sqrt{3}  |a_{1}|$, which ensures $1  \\frac{|a_{1}|}{a_{0}\\sqrt{3}} = \\sqrt{r_{v}}$. Thus, the denominator is positive and the condition number is well-defined.", "answer": "$$\\boxed{\\frac{1+\\sqrt{r_v}}{1-\\sqrt{r_v}}}$$", "id": "3432959"}, {"introduction": "This capstone practice bridges the gap between theory and practical implementation by tasking you with building a complete adaptive SG-FEM solver. You will implement a residual-based a posteriori error estimator that automatically drives the refinement of the polynomial chaos degree, concentrating computational resources where they are most effective. Completing this exercise will provide you with a tangible understanding of how to construct efficient, modern algorithms for uncertainty quantification. [@problem_id:3432978]", "problem": "Consider the one-dimensional heterogeneous diffusion model on the spatial domain $[0,1]$ with homogeneous Dirichlet boundary conditions. Let the uncertain diffusion coefficient be defined by $a(x,\\xi) = a_0(x) + a_1(x)\\,\\xi$, where $\\xi$ is a single random variable uniformly distributed on $[-1,1]$ and $a_0(x) = 1 + 0.5\\sin(2\\pi x)$, $a_1(x) = \\epsilon\\cdot 0.3\\cos(2\\pi x)$ for a given amplitude parameter $\\epsilon \\in (0,1]$. The forcing is $f(x) \\equiv 1$ and the boundary conditions are $u(0,\\xi) = 0$ and $u(1,\\xi) = 0$.\n\nThe goal is to solve the random Partial Differential Equation (PDE) in the Stochastic Galerkin (SG) framework with a Polynomial Chaos Expansion (PCE) of the form\n$$\nu(x,\\xi) \\approx \\sum_{n=0}^{p} u_n(x)\\,\\Phi_n(\\xi),\n$$\nwhere $\\{\\Phi_n(\\xi)\\}_{n\\ge 0}$ are the orthonormal Legendre polynomials on $[-1,1]$ with respect to the weight $w(\\xi) = \\tfrac{1}{2}$. Define $\\Phi_n(\\xi) = \\sqrt{2n+1}\\,P_n(\\xi)$, where $P_n(\\xi)$ is the $n$-th (unnormalized) Legendre polynomial satisfying $\\int_{-1}^{1} P_n(\\xi)P_m(\\xi)\\,d\\xi = \\frac{2}{2n+1}\\delta_{nm}$. With this normalization, the orthonormality property is $\\int_{-1}^{1} \\Phi_n(\\xi)\\Phi_m(\\xi)\\,w(\\xi)\\,d\\xi = \\delta_{nm}$.\n\nThe SG weak formulation with test functions $v_m(x)\\Phi_m(\\xi)$ yields a block system for the coefficient functions $u_n(x)$:\n$$\n\\sum_{n=0}^{p} \\left( \\int_{-1}^{1} \\Phi_n(\\xi)\\Phi_m(\\xi)\\,w(\\xi)\\,d\\xi \\right) \\int_0^1 a_0(x)\\,u_n'(x)\\,v_m'(x)\\,dx\n+\n\\sum_{n=0}^{p} \\left( \\int_{-1}^{1} \\xi\\,\\Phi_n(\\xi)\\Phi_m(\\xi)\\,w(\\xi)\\,d\\xi \\right) \\int_0^1 a_1(x)\\,u_n'(x)\\,v_m'(x)\\,dx\n=\n\\delta_{m0}\\int_0^1 f(x)\\,v_m(x)\\,dx.\n$$\nLet $T$ be the coupling matrix induced by multiplication with $\\xi$ in the orthonormal basis, given by the well-known three-term recurrence\n$$\n\\xi\\,\\Phi_n(\\xi) = \\alpha_n\\,\\Phi_{n+1}(\\xi) + \\beta_n\\,\\Phi_{n-1}(\\xi),\n\\quad\n\\alpha_n = \\frac{n+1}{\\sqrt{(2n+1)(2n+3)}},\n\\quad\n\\beta_n = \\frac{n}{\\sqrt{(2n+1)(2n-1)}},\n$$\nwith the convention $\\Phi_{-1} \\equiv 0$. Then $T \\in \\mathbb{R}^{(p+1)\\times(p+1)}$ is tridiagonal with entries $T_{n,n+1} = \\alpha_n$, $T_{n,n-1} = \\beta_n$, and symmetric.\n\nSpatially, use a conforming first-order Finite Element (FE) method on a uniform mesh with $N$ equal elements, applying the usual piecewise linear basis. Let $K_0 \\in \\mathbb{R}^{(N-1)\\times(N-1)}$ and $K_1 \\in \\mathbb{R}^{(N-1)\\times(N-1)}$ denote the FE stiffness matrices assembled using $a_0(x)$ and $a_1(x)$, respectively, and let $F_0 \\in \\mathbb{R}^{(N-1)}$ be the FE load vector for $f(x) \\equiv 1$. The SG linear system for the coefficient vector $U = [u_0;u_1;\\dots;u_p] \\in \\mathbb{R}^{(p+1)(N-1)}$ is\n$$\n\\left( I_{p+1} \\otimes K_0 + T \\otimes K_1 \\right) U = \\left[ F_0; 0; \\dots; 0 \\right],\n$$\nwhere $\\otimes$ denotes the Kronecker product and $I_{p+1}$ is the identity matrix of size $p+1$.\n\nDevelop a residual-based a posteriori error estimator that targets the stochastic truncation error and drives adaptive polynomial degree refinement. Use the hierarchical residual equation for the first neglected mode $u_{p+1}$, obtained by testing the SG equation at level $m=p+1$ with the truncated PCE (where $u_{p+1} \\equiv 0$). The residual equation becomes\n$$\nK_0\\,u_{p+1} \\approx -\\,\\alpha_p\\,K_1\\,u_p,\n$$\nmotivating the hierarchical predictor for the neglected coefficient\n$$\n\\widehat{u}_{p+1} := -\\,K_0^{-1}\\,\\big(\\alpha_p\\,K_1\\,u_p\\big).\n$$\nDefine the energy norm with respect to the mean coefficient $a_0(x)$ by\n$$\n\\| v \\|_{E}^2 := v^\\top K_0\\,v,\n$$\nand the stochastic energy norm of the error relative to a higher-degree reference SG solution $U^{\\mathrm{ref}}$ by\n$$\n\\| e \\|_{E,\\mathrm{sto}}^2 := \\sum_{n=0}^{p_{\\mathrm{ref}}} \\| u_n^{\\mathrm{ref}} - u_n^{\\mathrm{approx}} \\|_E^2,\n$$\nwhere $u_n^{\\mathrm{approx}} = u_n$ for $n \\le p$ and $u_n^{\\mathrm{approx}} = 0$ for $n  p$. Use the hierarchical estimator\n$$\n\\eta_p := \\| \\widehat{u}_{p+1} \\|_E,\n$$\nto drive adaptive refinement $p \\to p+1$ while $\\eta_p$ exceeds a given tolerance. For reliability and efficiency assessment on the benchmark, compute the ratios\n$$\n\\mathrm{Rel} := \\frac{\\eta_p}{\\| e \\|_{E,\\mathrm{sto}}}, \\qquad \\mathrm{Eff} := \\frac{\\| e \\|_{E,\\mathrm{sto}}}{\\eta_p},\n$$\nusing a sufficiently enriched reference polynomial degree $p_{\\mathrm{ref}}  p$.\n\nImplement the following requirements:\n\n- Construct $K_0$ and $K_1$ using two-point Gaussian quadrature per element for $\\int a(x)\\,dx$, and assemble $F_0$ exactly for $f(x) \\equiv 1$ using first-order finite elements.\n- Solve the SG system for a given initial polynomial degree $p$ and mesh $N$, compute the hierarchical estimator $\\eta_p$, and adaptively increase $p$ until the estimator is below the specified tolerance or a maximum degree limit is reached. Use $p_{\\max} = 12$.\n- For reliability and efficiency analysis, compute a reference SG solution at polynomial degree $p_{\\mathrm{ref}} = \\min(p+3,12)$ and evaluate $\\| e \\|_{E,\\mathrm{sto}}$ with respect to the current approximation.\n- Report, for each test case, a list containing the final polynomial degree $p_{\\mathrm{final}}$, the total number of adaptive increments $\\mathsf{iters}$, the reliability ratio $\\mathrm{Rel}$, and the efficiency ratio $\\mathrm{Eff}$. Ratios must be returned as floating-point numbers.\n\nTest Suite:\n\n- Case 1 (happy path): $N = 64$, $\\epsilon = 1.0$, initial $p = 0$, tolerance $\\mathrm{tol} = 10^{-3}$.\n- Case 2 (tighter tolerance): $N = 64$, $\\epsilon = 1.0$, initial $p = 0$, tolerance $\\mathrm{tol} = 10^{-5}$.\n- Case 3 (edge case, weak heterogeneity): $N = 64$, $\\epsilon = 0.05$, initial $p = 0$, tolerance $\\mathrm{tol} = 10^{-6}$.\n\nFinal Output Format:\n\nYour program should produce a single line of output containing the results from the three test cases as a comma-separated list of lists enclosed in square brackets, in the order of the test suite. Each inner list must be of the form $[p_{\\mathrm{final}}, \\mathsf{iters}, \\mathrm{Rel}, \\mathrm{Eff}]$. For example, the output must look like:\n$$\n[[p_1,\\mathsf{iters}_1,\\mathrm{Rel}_1,\\mathrm{Eff}_1],[p_2,\\mathsf{iters}_2,\\mathrm{Rel}_2,\\mathrm{Eff}_2],[p_3,\\mathsf{iters}_3,\\mathrm{Rel}_3,\\mathrm{Eff}_3]].\n$$\nAll numerical values must be reported in decimal form. There are no physical units involved.", "solution": "The user has provided a well-defined problem in the field of numerical methods for partial differential equations with random inputs. The problem asks for the implementation of an adaptive Stochastic Galerkin (SG) method based on a Polynomial Chaos Expansion (PCE) to solve a one-dimensional diffusion equation with an uncertain coefficient. A posteriori error estimation is used to drive the adaptive refinement of the polynomial degree of the PCE.\n\n### Step 1: Problem Validation\n\nThe problem is validated against the required criteria.\n\n**Extracted Givens:**\n- **PDE Model**: One-dimensional heterogeneous diffusion equation on the spatial domain $[0,1]$: $-\\frac{d}{dx}\\left( a(x,\\xi) \\frac{du}{dx} \\right) = f(x)$.\n- **Boundary Conditions**: Homogeneous Dirichlet, $u(0,\\xi) = 0$ and $u(1,\\xi) = 0$.\n- **Forcing Term**: $f(x) \\equiv 1$.\n- **Uncertain Diffusion Coefficient**: $a(x,\\xi) = a_0(x) + a_1(x)\\,\\xi$, where $\\xi$ is a random variable uniformly distributed on $[-1,1]$.\n- **Coefficient Functions**: $a_0(x) = 1 + 0.5\\sin(2\\pi x)$ and $a_1(x) = \\epsilon\\cdot 0.3\\cos(2\\pi x)$ for $\\epsilon \\in (0,1]$.\n- **Stochastic Discretization (PCE)**: $u(x,\\xi) \\approx \\sum_{n=0}^{p} u_n(x)\\,\\Phi_n(\\xi)$, using orthonormal Legendre polynomials $\\{\\Phi_n(\\xi)\\}$ with respect to the weight $w(\\xi) = 1/2$.\n- **Spatial Discretization (FEM)**: Conforming first-order finite elements on a uniform mesh with $N$ elements.\n- **SG System**: The global linear system is given by $\\left( I_{p+1} \\otimes K_0 + T \\otimes K_1 \\right) U = \\left[ F_0; 0; \\dots; 0 \\right]$, where $K_0, K_1$ are FE stiffness matrices, $F_0$ is the load vector, and $T$ is the tridiagonal coupling matrix derived from the three-term recurrence relation of the Legendre polynomials.\n- **Error Estimator**: A hierarchical, residual-based a posteriori error estimator $\\eta_p = \\| \\widehat{u}_{p+1} \\|_E$, where $\\widehat{u}_{p+1} := -\\,K_0^{-1}\\,\\big(\\alpha_p\\,K_1\\,u_p\\big)$ and $\\| v \\|_{E}^2 := v^\\top K_0\\,v$. The coefficient $\\alpha_p$ is defined by the recurrence relation.\n- **Adaptive Strategy**: The polynomial degree $p$ is increased starting from an initial value if $\\eta_p \\ge \\mathrm{tol}$, up to a maximum degree $p_{\\max} = 12$.\n- **Error Analysis**: For analysis, a reference solution is computed at $p_{\\mathrm{ref}} = \\min(p+3, 12)$, and the reliability ($\\mathrm{Rel}$) and efficiency ($\\mathrm{Eff}$) ratios of the estimator are calculated with respect to the stochastic energy error norm $\\| e \\|_{E,\\mathrm{sto}}$.\n- **Implementation Details**: Two-point Gaussian quadrature is specified for assembling stiffness matrices. The load vector is to be assembled exactly.\n- **Test Cases**:\n    - Case 1: $N = 64$, $\\epsilon = 1.0$, initial $p = 0$, $\\mathrm{tol} = 10^{-3}$.\n    - Case 2: $N = 64$, $\\epsilon = 1.0$, initial $p = 0$, $\\mathrm{tol} = 10^{-5}$.\n    - Case 3: $N = 64$, $\\epsilon = 0.05$, initial $p = 0$, $\\mathrm{tol} = 10^{-6}$.\n\n**Validation Verdict:**\n1.  **Scientifically Grounded and Factual Soundness**: The problem is well-grounded in the theory of uncertainty quantification and numerical analysis for PDEs. The SG-FEM framework is a standard technique. The diffusion coefficient $a(x,\\xi)$ remains strictly positive for the given parameter range, ensuring the physical and mathematical validity of the diffusion model. Minimum of $a(x,\\xi)$ is $a(x, \\xi) \\ge \\min(a_0) - \\epsilon \\max|a_1| = (1-0.5) - 1.0 \\cdot 0.3 = 0.2  0$.\n2.  **Well-Posed**: The underlying PDE is a standard elliptic problem, which is well-posed. The resulting SG linear system is for a symmetric positive-definite matrix, guaranteeing a unique solution.\n3.  **Objective**: The problem is stated with precise mathematical definitions and free of subjectivity.\n4.  **Complete and Consistent**: All necessary information, including model equations, discretization methods, adaptive strategy, and test parameters, is provided. The setup is self-consistent.\n5.  **Not Trivial or Pseudo-Profound**: The problem requires a non-trivial implementation of an established numerical method, representing a genuine computational science task.\n\nThe problem is deemed **valid**. We may proceed with the solution.\n\n### Step 2: Solution Design\n\nThe solution will be implemented in Python using the `numpy` library. The overall structure will consist of a main function that iterates through the test cases. For each case, a dedicated function will execute the adaptive algorithm, compute the required quantities, and return the results.\n\n**1. Finite Element Assembly:**\nA helper function, `assemble_fem`, will construct the finite element matrices $K_0$, $K_1$, and the load vector $F_0$.\n- The spatial domain $[0,1]$ is discretized into $N$ uniform elements of size $h=1/N$. This gives $N-1$ internal degrees of freedom.\n- The stiffness matrices $K_0, K_1$ are of size $(N-1) \\times (N-1)$. An element stiffness matrix $k^e$ is computed for each element $[x_i, x_{i+1}]$. Its entry is proportional to $\\int_{x_i}^{x_{i+1}} a(x) \\, dx$, where $a(x)$ is either $a_0(x)$ or $a_1(x)$. This integral is approximated using two-point Gaussian quadrature as specified. The global matrices are assembled by summing the contributions from each element.\n- The load vector $F_0$ of size $N-1$ is for a constant forcing $f(x)=1$. For a P1 linear basis function $\\phi_j(x)$, the integral $\\int_0^1 f(x)\\phi_j(x)\\,dx = \\int_{x_{j-1}}^{x_{j+1}} 1 \\cdot \\phi_j(x)\\,dx$ is exactly the area under the hat function, which is $h$. Thus, all entries of $F_0$ are equal to $h$.\n\n**2. Stochastic Galerkin System Solver:**\nA function `get_sg_solution` will build and solve the full SG system for a given polynomial degree $p$.\n- The tridiagonal coupling matrix $T \\in \\mathbb{R}^{(p+1)\\times(p+1)}$ is constructed. Its non-zero entries are $T_{n,n+1} = T_{n+1,n} = \\alpha_n = (n+1)/\\sqrt{(2n+1)(2n+3)}$ for $n=0, \\dots, p-1$.\n- The global SG matrix $A_{SG} = I_{p+1} \\otimes K_0 + T \\otimes K_1$ is formed using Kronecker products.\n- The right-hand side vector is constructed as $[F_0; 0; \\dots; 0]$.\n- The system $A_{SG} U = RHS$ is solved using `numpy.linalg.solve` to find the coefficient vector $U$.\n\n**3. Adaptive Refinement Algorithm:**\nThe main logic is encapsulated in `run_case_logic`.\n- It initializes $p$ to the starting value and enters an adaptive loop.\n- Inside the loop, for the current degree $p$:\n    1.  The SG system is solved to obtain the solution vector $U$. The last block of this vector corresponds to the nodal values of the coefficient function $u_p(x)$.\n    2.  The hierarchical error estimator $\\eta_p$ is computed. This involves:\n        a.  Calculating the residual right-hand side $RHS_{res} = -\\alpha_p K_1 u_p$.\n        b.  Solving the linear system $K_0 \\widehat{u}_{p+1} = RHS_{res}$ for the error predictor $\\widehat{u}_{p+1}$.\n        c.  Computing the energy norm squared $\\eta_p^2 = \\|\\widehat{u}_{p+1}\\|_E^2 = \\widehat{u}_{p+1}^\\top K_0 \\widehat{u}_{p+1} = \\widehat{u}_{p+1}^\\top RHS_{res}$.\n    3.  The loop terminates if $\\eta_p$ is below the tolerance `tol` or if $p$ reaches the maximum degree $p_{\\max}$. Otherwise, $p$ is incremented.\n\n**4. Error and Ratio Calculation:**\n- After the adaptive loop terminates at $p_{final}$, a reference solution $U^{ref}$ is computed at a higher degree $p_{ref} = \\min(p_{final}+3, p_{max})$.\n- The stochastic energy error $\\|e\\|_{E,sto}$ is calculated by summing the energy norms of the differences between the reference coefficients and the approximated coefficients: $\\| e \\|_{E,\\mathrm{sto}}^2 = \\sum_{n=0}^{p_{\\mathrm{ref}}} \\| u_n^{\\mathrm{ref}} - u_n^{\\mathrm{approx}} \\|_E^2$. Note that $u_n^{\\mathrm{approx}}=0$ for $n  p_{final}$.\n- Finally, the reliability $\\mathrm{Rel} = \\eta_p / \\| e \\|_{E,\\mathrm{sto}}$ and efficiency $\\mathrm{Eff} = \\| e \\|_{E,\\mathrm{sto}} / \\eta_p$ are computed. Special care is taken for cases where the error or the estimator might be zero, to avoid division-by-zero errors. If both are zero, the ratios are defined as $1.0$.\n\nThe following code implements this design.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport scipy.linalg\n\ndef solve():\n    \"\"\"\n    Main driver function to run the test suite and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: N=64, epsilon=1.0, p_initial=0, tol=1e-3\n        (64, 1.0, 0, 1e-3),\n        # Case 2: N=64, epsilon=1.0, p_initial=0, tol=1e-5\n        (64, 1.0, 0, 1e-5),\n        # Case 3: N=64, epsilon=0.05, p_initial=0, tol=1e-6\n        (64, 0.05, 0, 1e-6),\n    ]\n\n    p_max = 12\n    results = []\n    for case in test_cases:\n        N, epsilon, p_initial, tol = case\n        result = run_case_logic(N, epsilon, p_initial, tol, p_max)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef get_alpha(n):\n    \"\"\"Computes the recurrence coefficient alpha_n for orthonormal Legendre polynomials.\"\"\"\n    return (n + 1) / np.sqrt((2 * n + 1) * (2 * n + 3))\n\ndef assemble_fem(N, epsilon):\n    \"\"\"\n    Assembles the finite element matrices K0, K1, and the load vector F0\n    for a uniform mesh with N elements.\n    \"\"\"\n    num_dofs = N - 1\n    h = 1.0 / N\n    x_nodes = np.linspace(0, 1, N + 1)\n\n    a0_func = lambda x: 1.0 + 0.5 * np.sin(2 * np.pi * x)\n    a1_func = lambda x: epsilon * 0.3 * np.cos(2 * np.pi * x)\n\n    gq_points = np.array([-1.0, 1.0]) / np.sqrt(3.0)\n    gq_weights = np.array([1.0, 1.0])\n\n    int_a0_elem = np.zeros(N)\n    int_a1_elem = np.zeros(N)\n\n    for i in range(N):\n        x_i, x_i_plus_1 = x_nodes[i], x_nodes[i+1]\n        jacobian = 0.5 * h\n        mapped_gq_points = jacobian * gq_points + 0.5 * (x_i + x_i_plus_1)\n        \n        a0_vals = a0_func(mapped_gq_points)\n        a1_vals = a1_func(mapped_gq_points)\n        \n        int_a0_elem[i] = jacobian * np.sum(gq_weights * a0_vals)\n        int_a1_elem[i] = jacobian * np.sum(gq_weights * a1_vals)\n\n    K0 = np.zeros((num_dofs, num_dofs))\n    K1 = np.zeros((num_dofs, num_dofs))\n    \n    # Fill diagonal and super-diagonal\n    diag0 = (int_a0_elem[:-1] + int_a0_elem[1:]) / h**2\n    diag1 = (int_a1_elem[:-1] + int_a1_elem[1:]) / h**2\n    np.fill_diagonal(K0, diag0)\n    np.fill_diagonal(K1, diag1)\n    \n    off_diag0 = -int_a0_elem[1:-1] / h**2\n    off_diag1 = -int_a1_elem[1:-1] / h**2\n    K0.flat[1::num_dofs+1] = off_diag0\n    K1.flat[1::num_dofs+1] = off_diag1\n\n    # Fill sub-diagonal (by symmetry)\n    K0.flat[num_dofs::num_dofs+1] = off_diag0\n    K1.flat[num_dofs::num_dofs+1] = off_diag1\n            \n    F0 = np.full(num_dofs, h)\n    \n    return K0, K1, F0\n\ndef get_sg_solution(p, K0, K1, F0):\n    \"\"\"\n    Constructs and solves the Stochastic Galerkin system for a given polynomial degree p.\n    \"\"\"\n    num_dofs = K0.shape[0]\n    T = np.zeros((p + 1, p + 1))\n    for i in range(p):\n        alpha_i = get_alpha(i)\n        T[i, i + 1] = alpha_i\n        T[i + 1, i] = alpha_i\n\n    I_p = np.eye(p + 1)\n    A_sg = np.kron(I_p, K0) + np.kron(T, K1)\n\n    RHS = np.zeros((p + 1) * num_dofs)\n    RHS[:num_dofs] = F0\n\n    U = scipy.linalg.solve(A_sg, RHS, assume_a='sym')\n    return U\n\ndef run_case_logic(N, epsilon, p_initial, tol, p_max):\n    \"\"\"\n    Main logic for a single test case: adaptive refinement, error computation, and ratio calculation.\n    \"\"\"\n    K0, K1, F0 = assemble_fem(N, epsilon)\n    num_dofs = K0.shape[0]\n\n    p = p_initial\n    iters = 0\n    U_final, eta_final = None, -1.0\n\n    while True:\n        U = get_sg_solution(p, K0, K1, F0)\n        \n        u_p = U[p * num_dofs:]\n        \n        alpha_p = get_alpha(p)\n        rhs_res = -alpha_p * (K1 @ u_p)\n        hat_u_p_plus_1 = scipy.linalg.solve(K0, rhs_res, assume_a='sym')\n        \n        eta_p_sq = hat_u_p_plus_1.T @ rhs_res\n        eta_p = np.sqrt(max(0, eta_p_sq))\n\n        if eta_p  tol or p = p_max:\n            p_final = p\n            U_final = U\n            eta_final = eta_p\n            break\n\n        p += 1\n        iters += 1\n    \n    p_ref = min(p_final + 3, p_max)\n    \n    if p_ref = p_final:\n        true_error = 0.0\n    else:\n        U_ref = get_sg_solution(p_ref, K0, K1, F0)\n        error_sq = 0.0\n        \n        for n in range(p_ref + 1):\n            u_n_ref = U_ref[n*num_dofs : (n+1)*num_dofs]\n            if n = p_final:\n                u_n_approx = U_final[n*num_dofs : (n+1)*num_dofs]\n            else:\n                u_n_approx = np.zeros(num_dofs)\n            \n            diff = u_n_ref - u_n_approx\n            error_sq += diff.T @ K0 @ diff\n            \n        true_error = np.sqrt(max(0, error_sq))\n\n    with np.errstate(divide='ignore', invalid='ignore'):\n        Rel = np.divide(eta_final, true_error)\n        Eff = np.divide(true_error, eta_final)\n    \n    if np.isnan(Rel) or np.isinf(Rel): Rel = 1.0\n    if np.isnan(Eff) or np.isinf(Eff): Eff = 1.0\n    \n    return [p_final, iters, Rel, Eff]\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3432978"}]}