{"hands_on_practices": [{"introduction": "The power of multigrid methods lies in the coarse-grid correction step, which efficiently addresses low-frequency error components. Before delving into more abstract Fourier analysis, it's essential to have a concrete grasp of the mechanics of this process. This first practice [@problem_id:3458899] guides you through a single coarse-grid correction for a very small, well-defined problem, allowing you to trace the flow of information from the fine-grid residual to the final corrected solution by hand.", "problem": "Consider the one-dimensional Dirichlet problem for a linear elliptic partial differential equation (PDE) discretized on a uniform fine grid with $n_h = 3$ interior points. Let the fine-grid stiffness matrix $A_h \\in \\mathbb{R}^{3 \\times 3}$ be the standard tridiagonal matrix\n$$\nA_h \\;=\\; \\begin{pmatrix}\n2  -1  0 \\\\\n-1  2  -1 \\\\\n0  -1  2\n\\end{pmatrix}.\n$$\nYou are given the current fine-grid iterate\n$$\nu_h^{(k)} \\;=\\; \\begin{pmatrix} 1 \\\\ 0 \\\\ -1 \\end{pmatrix},\n$$\nand the fine-grid right-hand side\n$$\nf_h \\;=\\; \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}.\n$$\nUse a two-grid correction with an exact coarse-grid solve, the full-weighting restriction operator $R \\in \\mathbb{R}^{1 \\times 3}$ defined by\n$$\nR \\;=\\; \\begin{pmatrix} \\tfrac{1}{4}  \\tfrac{1}{2}  \\tfrac{1}{4} \\end{pmatrix},\n$$\nand the linear interpolation prolongation operator $P \\in \\mathbb{R}^{3 \\times 1}$ defined by\n$$\nP \\;=\\; \\begin{pmatrix} \\tfrac{1}{2} \\\\ 1 \\\\ \\tfrac{1}{2} \\end{pmatrix}.\n$$\nForm the coarse-grid operator by the Galerkin definition $A_H \\;=\\; R\\,A_h\\,P \\in \\mathbb{R}^{1 \\times 1}$. Define the fine-grid residual $r_h \\;=\\; f_h - A_h u_h^{(k)}$, restrict it to the coarse grid $r_H \\;=\\; R\\,r_h$, compute the exact coarse-grid error $e_H \\in \\mathbb{R}$ by solving $A_H e_H \\;=\\; r_H$, and then compute the corrected fine-grid iterate $u_h^{(k+1)} \\;=\\; u_h^{(k)} + P e_H$.\n\nStarting from these definitions only, compute the explicit values of $e_H$ and $u_h^{(k+1)}$. Express your final answer as a single row matrix with two entries, where the first entry is the scalar $e_H$ and the second entry is the $3 \\times 1$ column vector $u_h^{(k+1)}$. No rounding is required, and your answer should be exact.", "solution": "We proceed from the fundamental definitions of the two-grid correction. The fine-grid residual is defined by\n$$\nr_h \\;=\\; f_h \\;-\\; A_h\\,u_h^{(k)}.\n$$\nWith the given $A_h$ and $u_h^{(k)}$, we first compute $A_h\\,u_h^{(k)}$. Let\n$$\nA_h \\;=\\; \\begin{pmatrix}\n2  -1  0 \\\\\n-1  2  -1 \\\\\n0  -1  2\n\\end{pmatrix}, \n\\quad \nu_h^{(k)} \\;=\\; \\begin{pmatrix} 1 \\\\ 0 \\\\ -1 \\end{pmatrix}.\n$$\nThen\n$$\nA_h\\,u_h^{(k)} \\;=\\; \n\\begin{pmatrix}\n2 \\cdot 1 + (-1) \\cdot 0 + 0 \\cdot (-1) \\\\\n(-1) \\cdot 1 + 2 \\cdot 0 + (-1) \\cdot (-1) \\\\\n0 \\cdot 1 + (-1) \\cdot 0 + 2 \\cdot (-1)\n\\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n2 \\\\\n-1 + 1 \\\\\n-2\n\\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n2 \\\\\n0 \\\\\n-2\n\\end{pmatrix}.\n$$\nHence the residual is\n$$\nr_h \\;=\\; f_h - A_h\\,u_h^{(k)} \n\\;=\\; \n\\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} \n- \n\\begin{pmatrix} 2 \\\\ 0 \\\\ -2 \\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix} -2 \\\\ 1 \\\\ 2 \\end{pmatrix}.\n$$\n\nNext, restrict the residual to the coarse grid using the full-weighting restriction $R$:\n$$\nR \\;=\\; \\begin{pmatrix} \\tfrac{1}{4}  \\tfrac{1}{2}  \\tfrac{1}{4} \\end{pmatrix},\n\\qquad\nr_H \\;=\\; R\\,r_h.\n$$\nThus\n$$\nr_H \\;=\\; \\begin{pmatrix} \\tfrac{1}{4}  \\tfrac{1}{2}  \\tfrac{1}{4} \\end{pmatrix}\n\\begin{pmatrix} -2 \\\\ 1 \\\\ 2 \\end{pmatrix}\n\\;=\\; \\tfrac{1}{4} \\cdot (-2) \\;+\\; \\tfrac{1}{2} \\cdot 1 \\;+\\; \\tfrac{1}{4} \\cdot 2\n\\;=\\; -\\tfrac{1}{2} \\;+\\; \\tfrac{1}{2} \\;+\\; \\tfrac{1}{2}\n\\;=\\; \\tfrac{1}{2}.\n$$\n\nForm the coarse-grid operator $A_H$ by the Galerkin definition $A_H \\;=\\; R\\,A_h\\,P$. With\n$$\nP \\;=\\; \\begin{pmatrix} \\tfrac{1}{2} \\\\ 1 \\\\ \\tfrac{1}{2} \\end{pmatrix},\n$$\nwe first compute $A_h\\,P$:\n$$\nA_h\\,P \\;=\\; \n\\begin{pmatrix}\n2  -1  0 \\\\\n-1  2  -1 \\\\\n0  -1  2\n\\end{pmatrix}\n\\begin{pmatrix} \\tfrac{1}{2} \\\\ 1 \\\\ \\tfrac{1}{2} \\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n2 \\cdot \\tfrac{1}{2} + (-1) \\cdot 1 + 0 \\cdot \\tfrac{1}{2} \\\\\n(-1) \\cdot \\tfrac{1}{2} + 2 \\cdot 1 + (-1) \\cdot \\tfrac{1}{2} \\\\\n0 \\cdot \\tfrac{1}{2} + (-1) \\cdot 1 + 2 \\cdot \\tfrac{1}{2}\n\\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n1 - 1 \\\\\n- \\tfrac{1}{2} + 2 - \\tfrac{1}{2} \\\\\n-1 + 1\n\\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n0 \\\\ 1 \\\\ 0\n\\end{pmatrix}.\n$$\nTherefore,\n$$\nA_H \\;=\\; R\\,(A_h\\,P) \\;=\\; \\begin{pmatrix} \\tfrac{1}{4}  \\tfrac{1}{2}  \\tfrac{1}{4} \\end{pmatrix}\n\\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}\n\\;=\\; \\tfrac{1}{2}.\n$$\n\nSolve the coarse problem $A_H e_H \\;=\\; r_H$ exactly:\n$$\n\\tfrac{1}{2}\\, e_H \\;=\\; \\tfrac{1}{2}\n\\;\\;\\Longrightarrow\\;\\;\ne_H \\;=\\; 1.\n$$\n\nProlong the coarse-grid error to the fine grid and correct the fine-grid iterate:\n$$\nP\\,e_H \\;=\\; \\begin{pmatrix} \\tfrac{1}{2} \\\\ 1 \\\\ \\tfrac{1}{2} \\end{pmatrix} \\cdot 1\n\\;=\\; \\begin{pmatrix} \\tfrac{1}{2} \\\\ 1 \\\\ \\tfrac{1}{2} \\end{pmatrix},\n\\qquad\nu_h^{(k+1)} \\;=\\; u_h^{(k)} + P\\,e_H \n\\;=\\; \n\\begin{pmatrix} 1 \\\\ 0 \\\\ -1 \\end{pmatrix}\n+\n\\begin{pmatrix} \\tfrac{1}{2} \\\\ 1 \\\\ \\tfrac{1}{2} \\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix} \\tfrac{3}{2} \\\\ 1 \\\\ -\\tfrac{1}{2} \\end{pmatrix}.\n$$\n\nThus the computed coarse-grid error is $e_H \\;=\\; 1$, and the corrected fine-grid iterate is $u_h^{(k+1)} \\;=\\; \\begin{pmatrix} \\tfrac{3}{2} \\\\ 1 \\\\ -\\tfrac{1}{2} \\end{pmatrix}$, as required.", "answer": "$$\\boxed{\\begin{pmatrix} 1  \\begin{pmatrix} \\tfrac{3}{2} \\\\ 1 \\\\ -\\tfrac{1}{2} \\end{pmatrix} \\end{pmatrix}}$$", "id": "3458899"}, {"introduction": "Coarse-grid correction, while powerful for smooth errors, is ineffective at eliminating high-frequency, oscillatory error components. This is where the smoother comes in, acting as a complementary process to damp these troublesome modes. In this exercise [@problem_id:3458866], we will employ Local Fourier Analysis (LFA) to quantify the smoother's effectiveness and find the optimal relaxation parameter for the weighted Jacobi method, a classic technique that illustrates the core principles of smoother design.", "problem": "Consider the boundary value problem for a partial differential equation (PDE), $-u''(x)=f(x)$ on $(0,1)$ with homogeneous Dirichlet boundary conditions $u(0)=u(1)=0$. Discretize the operator by the standard second-order centered finite difference scheme on a uniform grid with mesh size $h=\\frac{1}{n+1}$, $x_j=jh$, $j=1,\\dots,n$, leading to the linear system $A_h u_h = f_h$ where $A_h$ is the tridiagonal matrix with stencil $\\frac{1}{h^2}[-1,2,-1]$. Consider the weighted Jacobi relaxation $u_h^{(k+1)} = u_h^{(k)} + \\omega D_h^{-1}(f_h - A_h u_h^{(k)})$, where $D_h$ is the diagonal of $A_h$ and $\\omega > 0$ is the relaxation parameter.\n\nIn a two-grid method with coarse grid spacing $2h$, the purpose of the smoother is to damp the high-frequency error components that are not representable on the coarse grid. Using Local Fourier Analysis (LFA), which assumes an infinite uniform grid and analyzes the error evolution mode-by-mode, define the smoothing factor $\\mu_{\\text{smooth}}(\\omega)$ as the supremum of the magnitude of the Fourier symbol of the error-propagation operator over the high-frequency set complementary to the coarse-grid space. Take the high-frequency set to be $\\{\\theta\\in[\\pi/2,\\pi]\\}$ (angles measured in radians), corresponding to modes not representable on the coarse grid of spacing $2h$.\n\nStarting from first principles (the discrete operator stencil, the definition of the weighted Jacobi iteration, and the Fourier representation of translation-invariant operators), derive an analytic expression for $\\mu_{\\text{smooth}}(\\omega)$ and determine the value $\\omega^{\\star}$ that minimizes it over $\\omega > 0$. Then compute the resulting minimal smoothing factor $\\mu_{\\text{smooth}}(\\omega^{\\star})$.\n\nProvide your final answer as a single row matrix $\\begin{pmatrix}\\omega^{\\star}  \\mu_{\\text{smooth}}(\\omega^{\\star})\\end{pmatrix}$. No numerical rounding is required.", "solution": "We find the optimal relaxation parameter $\\omega^{\\star}$ and the corresponding minimal smoothing factor $\\mu_{\\text{smooth}}(\\omega^{\\star})$ for a weighted Jacobi smoother applied to the 1D Poisson equation using Local Fourier Analysis (LFA).\n\nFirst, we determine the error-propagation operator for the weighted Jacobi iteration. The error $e_h^{(k)} = u_h - u_h^{(k)}$ evolves according to:\n$$ e_h^{(k+1)} = (I - \\omega D_h^{-1} A_h) e_h^{(k)} $$\nThe error-propagation operator, or smoother, is $S_h(\\omega) = I - \\omega D_h^{-1} A_h$.\n\nNext, we apply LFA, which analyzes the action of the operator on Fourier modes of the form $v_\\theta(x_j) = \\exp(i \\theta j)$, where $\\theta \\in [-\\pi, \\pi]$ is the scaled frequency. The action of a linear, translation-invariant operator on such a mode is to multiply it by a scalar, called the Fourier symbol or amplification factor.\nThe operator $A_h$ is given by the stencil $\\frac{1}{h^2}[-1, 2, -1]$. Its symbol is $\\widehat{A_h}(\\theta) = \\frac{1}{h^2}(2 - 2\\cos(\\theta)) = \\frac{4}{h^2}\\sin^2(\\theta/2)$.\nThe operator $D_h$ is the diagonal of $A_h$, which is $\\frac{2}{h^2}I$. Its symbol is a constant, $\\widehat{D_h}(\\theta) = \\frac{2}{h^2}$, and the symbol of its inverse is $\\widehat{D_h^{-1}}(\\theta) = \\frac{h^2}{2}$.\n\nThe symbol of the smoother $S_h(\\omega)$ is:\n$$ \\widehat{S_h}(\\omega, \\theta) = \\widehat{I}(\\theta) - \\omega \\widehat{D_h^{-1}}(\\theta) \\widehat{A_h}(\\theta) = 1 - \\omega \\left(\\frac{h^2}{2}\\right) \\left(\\frac{4}{h^2}\\sin^2(\\theta/2)\\right) = 1 - 2\\omega \\sin^2(\\theta/2) $$\nThis expression is the amplification factor for an error mode with frequency $\\theta$.\n\nThe smoothing factor, $\\mu_{\\text{smooth}}(\\omega)$, is defined as the supremum of the magnitude of the amplification factor over the set of high frequencies, specified as $\\theta \\in [\\pi/2, \\pi]$.\n$$ \\mu_{\\text{smooth}}(\\omega) = \\sup_{\\theta \\in [\\pi/2, \\pi]} |1 - 2\\omega \\sin^2(\\theta/2)| $$\nTo evaluate this, let's analyze the range of $z = \\sin^2(\\theta/2)$ for $\\theta \\in [\\pi/2, \\pi]$. As $\\theta$ ranges from $\\pi/2$ to $\\pi$, the argument $\\theta/2$ ranges from $\\pi/4$ to $\\pi/2$. Thus, the range of $z$ is $[\\sin^2(\\pi/4), \\sin^2(\\pi/2)] = [1/2, 1]$.\nThe problem reduces to finding:\n$$ \\mu_{\\text{smooth}}(\\omega) = \\sup_{z \\in [1/2, 1]} |1 - 2\\omega z| $$\nThe function $g(z) = 1 - 2\\omega z$ is linear in $z$. The supremum of its absolute value over the interval $[1/2, 1]$ must be attained at one of the endpoints.\nAt $z = 1/2$: $|g(1/2)| = |1 - \\omega|$.\nAt $z = 1$: $|g(1)| = |1 - 2\\omega|$.\nThe smoothing factor is the maximum of these two values:\n$$ \\mu_{\\text{smooth}}(\\omega) = \\max(|1 - \\omega|, |1 - 2\\omega|) $$\n\nWe find the value $\\omega^{\\star}$ that minimizes $\\mu_{\\text{smooth}}(\\omega)$. The minimum of the maximum of two functions often occurs when the functions are equal in magnitude:\n$$ |1 - \\omega| = |1 - 2\\omega| $$\nThis equality holds if $1 - \\omega = -(1 - 2\\omega)$, which implies $1 - \\omega = -1 + 2\\omega$, leading to $2 = 3\\omega$, or $\\omega = \\frac{2}{3}$.\nThus, the optimal relaxation parameter is $\\omega^{\\star} = \\frac{2}{3}$.\n\nThe minimal smoothing factor is the value of $\\mu_{\\text{smooth}}(\\omega)$ at $\\omega^{\\star}$:\n$$ \\mu_{\\text{smooth}}(\\omega^{\\star}) = \\mu_{\\text{smooth}}(2/3) = \\max\\left(\\left|1 - \\frac{2}{3}\\right|, \\left|1 - 2\\left(\\frac{2}{3}\\right)\\right|\\right) $$\n$$ = \\max\\left(\\left|\\frac{1}{3}\\right|, \\left|1 - \\frac{4}{3}\\right|\\right) = \\max\\left(\\frac{1}{3}, \\left|-\\frac{1}{3}\\right|\\right) = \\frac{1}{3} $$\nThe minimal smoothing factor is $\\mu_{\\text{smooth}}(\\omega^{\\star}) = \\frac{1}{3}$.\n\nThe final answer is the pair $(\\omega^{\\star}, \\mu_{\\text{smooth}}(\\omega^{\\star}))$.", "answer": "$$ \\boxed{\\begin{pmatrix} \\frac{2}{3}  \\frac{1}{3} \\end{pmatrix}} $$", "id": "3458866"}, {"introduction": "Having analyzed the smoother and the coarse-grid correction process separately, we can now synthesize these concepts to predict the performance of a complete two-grid cycle. This final practice [@problem_id:3458872] represents a capstone analysis, using LFA to derive the theoretical convergence factor for a model problem. The result reveals the remarkable efficiency of the two-grid method, stemming from the elegant interplay between high-frequency smoothing and low-frequency coarse-grid correction.", "problem": "Consider the one-dimensional Poisson equation on a periodic domain with fine-grid spacing $h$, discretized by the standard second-order centered finite difference operator $A_h$ with stencil $\\{-1, 2, -1\\}$. A two-grid method is applied using one pre-smoothing and one post-smoothing step of weighted Jacobi relaxation, full-weighting restriction from the fine grid to the coarse grid, and linear interpolation from the coarse grid back to the fine grid. The coarse-grid operator is defined by the Galerkin choice $A_{2h} = R A_h P$, where $R$ is the restriction and $P$ is the prolongation.\n\nUsing Local Fourier Analysis (LFA), represent the two-grid error-propagation operator on the fine grid by its symbol $\\widehat{E}(\\theta)$ acting on the space spanned by the harmonic pair $\\{\\exp(\\mathrm{i} j \\theta), \\exp(\\mathrm{i} j (\\theta+\\pi))\\}$, with $\\theta \\in (-\\pi,\\pi]$ in radians. Choose the weighted Jacobi parameter $\\omega$ to be optimal in the sense of minimizing the maximum smoothing factor over the high-frequency range appropriate for two-grid analysis.\n\nStarting only from the definitions of the discrete operator symbol on the fine grid, the weighted Jacobi smoothing symbol, the full-weighting restriction symbol, and the linear interpolation symbol, derive the two-grid error symbol $\\widehat{E}(\\theta)$ and determine the LFA two-grid convergence factor as the spectral radius\n$$\n\\rho_{\\text{LFA}} \\;=\\; \\sup_{\\theta \\in (-\\pi,\\pi]} \\rho\\big(\\widehat{E}(\\theta)\\big).\n$$\nProvide your final answer as a single exact number. Then briefly compare this LFA prediction to the empirical convergence behavior one expects for large periodic grids under the stated components.", "solution": "To derive the two-grid convergence factor using Local Fourier Analysis (LFA), we analyze how the two-grid error propagation operator acts on Fourier modes. For a two-grid method with a coarsening factor of 2, a low-frequency mode $\\exp(\\mathrm{i} j \\theta)$ for $\\theta \\in [-\\pi/2, \\pi/2]$ is coupled with its high-frequency alias $\\exp(\\mathrm{i} j (\\theta+\\pi))$. LFA thus represents grid operators as $2 \\times 2$ matrices (symbols) acting on the vector of amplitudes of this harmonic pair. Let $s = \\sin(\\theta/2)$ and $c = \\cos(\\theta/2)$.\n\nFirst, we determine the symbols for each component of the two-grid cycle.\nThe fine-grid operator $A_h$ with stencil $\\frac{1}{h^2}\\{-1, 2, -1\\}$ has a diagonal symbol:\n$$\n\\widehat{A}_h(\\theta) = \\frac{4}{h^2} \\begin{pmatrix} s^2  0 \\\\ 0  c^2 \\end{pmatrix}\n$$\nThe weighted Jacobi smoother $S_h = I_h - \\omega D_h^{-1} A_h$ with $D_h = \\frac{2}{h^2}I$ has the symbol:\n$$\n\\widehat{S}_h(\\theta) = \\mathbf{I} - \\frac{\\omega h^2}{2} \\widehat{A}_h(\\theta) = \\begin{pmatrix} 1 - 2\\omega s^2  0 \\\\ 0  1 - 2\\omega c^2 \\end{pmatrix}\n$$\nThe optimal Jacobi parameter for smoothing high frequencies is $\\omega=2/3$. With this choice, $\\widehat{S}_h(\\theta) = \\begin{pmatrix} 1 - \\frac{4}{3} s^2  0 \\\\ 0  1 - \\frac{4}{3} c^2 \\end{pmatrix}$.\n\nThe full-weighting restriction operator $R$ and linear interpolation operator $P$ have symbols:\n$$\n\\widehat{R}(\\theta) = [c^2, s^2], \\qquad \\widehat{P}(\\theta) = \\begin{pmatrix} c^2 \\\\ s^2 \\end{pmatrix}\n$$\nThe coarse-grid operator is formed by the Galerkin choice, $\\widehat{A}_{2h}(2\\theta) = \\widehat{R}(\\theta) \\widehat{A}_h(\\theta) \\widehat{P}(\\theta)$, which evaluates to:\n$$\n\\widehat{A}_{2h}(2\\theta) = [c^2, s^2] \\frac{4}{h^2} \\begin{pmatrix} s^2  0 \\\\ 0  c^2 \\end{pmatrix} \\begin{pmatrix} c^2 \\\\ s^2 \\end{pmatrix} = \\frac{4}{h^2} (s^2 c^4 + s^4 c^2) = \\frac{4}{h^2} s^2 c^2 = \\frac{1}{h^2} \\sin^2(\\theta).\n$$\nThe symbol for the two-grid error propagation operator with one pre- and one post-smoothing step is $\\widehat{E}(\\theta) = \\widehat{S}_h(\\theta) \\left(\\mathbf{I} - \\widehat{P}(\\theta) \\widehat{A}_{2h}^{-1}(2\\theta) \\widehat{R}(\\theta) \\widehat{A}_h(\\theta)\\right) \\widehat{S}_h(\\theta)$. The coarse-grid correction symbol (the term in parentheses) is:\n$$\n\\widehat{CGC}(\\theta) = \\mathbf{I} - \\begin{pmatrix} c^2 \\\\ s^2 \\end{pmatrix} \\frac{h^2}{\\sin^2(\\theta)} [c^2, s^2] \\frac{4}{h^2} \\begin{pmatrix} s^2  0 \\\\ 0  c^2 \\end{pmatrix} = \\mathbf{I} - \\frac{1}{s^2c^2} \\begin{pmatrix} c^2 \\\\ s^2 \\end{pmatrix} [s^2c^2, s^2c^2] = \\begin{pmatrix} s^2  -c^2 \\\\ -s^2  c^2 \\end{pmatrix}\n$$\nCombining these, we get the full two-grid symbol $\\widehat{E}(\\theta) = \\widehat{S}_h(\\theta) \\widehat{CGC}(\\theta) \\widehat{S}_h(\\theta)$.\nTo find the convergence factor, we compute the spectral radius of this matrix. The determinant is $\\det(\\widehat{E}(\\theta)) = \\det(\\widehat{S}_h)^2 \\det(\\widehat{CGC}) = 0$, since $\\det(\\widehat{CGC})=0$. Therefore, one eigenvalue is 0, and the other is the trace, $\\text{Tr}(\\widehat{E}(\\theta))$. The spectral radius is $\\rho(\\widehat{E}(\\theta)) = |\\text{Tr}(\\widehat{E}(\\theta))|$.\nThe trace is $\\text{Tr}(\\widehat{E}(\\theta)) = \\text{Tr}(\\widehat{S}_h \\widehat{CGC} \\widehat{S}_h) = \\text{Tr}(\\widehat{CGC} \\widehat{S}_h^2)$.\n$$\n\\text{Tr}(\\widehat{E}(\\theta)) = \\text{Tr}\\left( \\begin{pmatrix} s^2  -c^2 \\\\ -s^2  c^2 \\end{pmatrix} \\begin{pmatrix} (1 - \\frac{4}{3} s^2)^2  0 \\\\ 0  (1 - \\frac{4}{3} c^2)^2 \\end{pmatrix} \\right) = s^2(1 - \\frac{4}{3} s^2)^2 + c^2(1 - \\frac{4}{3} c^2)^2\n$$\nLet $x = s^2 = \\sin^2(\\theta/2)$. Then $c^2=1-x$. The spectral radius becomes a function of $x$:\n$$\n\\rho(x) = \\left| x\\left(1-\\frac{4}{3}x\\right)^2 + (1-x)\\left(1-\\frac{4}{3}(1-x)\\right)^2 \\right| = \\left| \\frac{x(3-4x)^2}{9} + \\frac{(1-x)(4x-1)^2}{9} \\right|\n$$\nExpanding the numerator:\n$$\nx(9-24x+16x^2) + (1-x)(16x^2-8x+1) = (9x - 24x^2 + 16x^3) + (16x^2 - 16x^3 - 8x + 8x^2 + 1 - x) = 1\n$$\nThe terms in $x, x^2, x^3$ all cancel out. The spectral radius is therefore constant for all frequencies $\\theta$:\n$$\n\\rho(\\widehat{E}(\\theta)) = \\frac{1}{9}\n$$\nThe LFA two-grid convergence factor is the supremum of this value, which is $\\rho_{\\text{LFA}} = 1/9$.\n\n**Comparison to Empirical Behavior**\n\nLocal Fourier Analysis assumes an infinite, uniform grid (or a periodic domain, which is topologically equivalent). The LFA convergence factor of $1/9$ therefore represents an asymptotic convergence rate that would be observed on very large periodic grids, where boundary effects are negligible. For numerical experiments performed on the 1D Poisson problem with periodic boundary conditions, the empirically measured convergence factor (e.g., the ratio of successive residual norms) is expected to approach this theoretical value of $1/9$ very closely as the number of grid points increases. This particular combination of multigrid components (optimal weighted Jacobi, full weighting, linear interpolation, Galerkin coarse operator) is known to be highly efficient, and the LFA prediction is exceptionally accurate in this ideal setting.", "answer": "$$\\boxed{\\frac{1}{9}}$$", "id": "3458872"}]}