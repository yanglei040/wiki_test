{"hands_on_practices": [{"introduction": "The Grünwald-Letnikov (GL) formulas provide a direct and intuitive way to discretize fractional derivatives, but their basic forms often yield only first-order accuracy. This exercise guides you through the Fourier analysis of a shifted GL scheme for the Riesz fractional derivative, a cornerstone for modeling anomalous diffusion. By analyzing the symbol of the numerical operator, you will determine the optimal shift that cancels the leading error term, thereby enhancing the scheme's accuracy—a fundamental technique in the design of high-performance fractional derivative approximations. [@problem_id:3426237]", "problem": "Consider the one-dimensional space-fractional diffusion equation on a periodic domain with period $L$,\n$$\n\\frac{\\partial u}{\\partial t}(x,t) \\;=\\; \\kappa \\,\\mathcal{D}_{R}^{\\alpha} u(x,t),\n$$\nwhere $1  \\alpha  2$, $\\kappa0$, and $\\mathcal{D}_{R}^{\\alpha}$ denotes the Riesz fractional derivative of order $\\alpha$, defined via the Fourier transform by $\\mathcal{F}\\!\\left[\\,\\mathcal{D}_{R}^{\\alpha} u\\,\\right](\\xi) \\;=\\; -\\,|\\xi|^{\\alpha}\\,\\widehat{u}(\\xi)$. Let $x_{j} = j h$ be a uniform spatial grid with spacing $h0$, and consider the following shifted left and right Grünwald–Letnikov (GL) fractional difference operators of order $\\alpha$ with shift parameter $r \\in \\mathbb{R}$:\n$$\n\\delta_{h,+}^{\\alpha,r} u(x) \\;=\\; h^{-\\alpha} \\sum_{m=0}^{\\infty} (-1)^{m} \\binom{\\alpha}{m} \\, u\\!\\left(x - (m - r) h\\right),\n\\qquad\n\\delta_{h,-}^{\\alpha,r} u(x) \\;=\\; h^{-\\alpha} \\sum_{m=0}^{\\infty} (-1)^{m} \\binom{\\alpha}{m} \\, u\\!\\left(x + (m - r) h\\right),\n$$\nwhere the generalized binomial coefficient is $\\displaystyle \\binom{\\alpha}{m} = \\frac{\\Gamma(\\alpha+1)}{\\Gamma(m+1)\\,\\Gamma(\\alpha-m+1)}$ and $\\Gamma$ is the Gamma function. A common GL-based approximation to the Riesz derivative is\n$$\n\\mathcal{R}_{h}^{(\\alpha,r)} u(x) \\;=\\; -\\,\\frac{1}{2\\cos\\!\\left(\\frac{\\pi\\alpha}{2}\\right)}\\left( \\delta_{h,+}^{\\alpha,r} u(x) + \\delta_{h,-}^{\\alpha,r} u(x) \\right).\n$$\nLet $u(x)=\\exp(i\\xi x)$ be a single Fourier mode with wavenumber $\\xi$, and denote $\\theta = \\xi h$. Using only the Fourier definition of $\\mathcal{D}_{R}^{\\alpha}$ and the Grünwald–Letnikov construction above, derive the discrete Fourier symbol of $\\mathcal{R}_{h}^{(\\alpha,r)}$ acting on $u(x)$, and perform a small-$\\theta$ asymptotic expansion. Determine the value of the shift $r$ that eliminates the linear-in-$\\theta$ term in the low-wavenumber expansion of the symbol, so that $\\mathcal{R}_{h}^{(\\alpha,r)}$ is consistent with $\\mathcal{D}_{R}^{\\alpha}$ up to and including the $O(\\theta^{\\alpha+2})$ term (i.e., the first deviation from the exact $-|\\xi|^{\\alpha}$ symbol is $O(\\theta^{\\alpha+2})$). Provide your final answer as a single, closed-form analytical expression in terms of $\\alpha$. No numerical rounding is required.", "solution": "The user wants to find the value of the shift parameter $r$ that makes the given Grünwald–Letnikov (GL)-based approximation to the Riesz fractional derivative of order $\\alpha$ more accurate for low wavenumbers.\n\nTo do this, we must first determine the discrete Fourier symbol of the operator $\\mathcal{R}_{h}^{(\\alpha,r)}$. The symbol, which we will denote $\\Psi(\\xi h)$, is defined by the action of the operator on a single Fourier mode, $u(x) = \\exp(i\\xi x)$, such that $\\mathcal{R}_{h}^{(\\alpha,r)} u(x) = \\Psi(\\xi h) u(x)$. Here, $\\xi$ is the wavenumber. We define the dimensionless wavenumber as $\\theta = \\xi h$.\n\nThe operator $\\mathcal{R}_{h}^{(\\alpha,r)}$ is defined as:\n$$\n\\mathcal{R}_{h}^{(\\alpha,r)} u(x) = -\\frac{1}{2\\cos(\\frac{\\pi\\alpha}{2})}\\left( \\delta_{h,+}^{\\alpha,r} u(x) + \\delta_{h,-}^{\\alpha,r} u(x) \\right)\n$$\nWe begin by finding the symbol of the shifted left GL operator, $\\delta_{h,+}^{\\alpha,r}$. Applying it to $u(x)=\\exp(i\\xi x)$:\n$$\n\\begin{aligned}\n\\delta_{h,+}^{\\alpha,r} \\exp(i\\xi x) = h^{-\\alpha} \\sum_{m=0}^{\\infty} (-1)^{m} \\binom{\\alpha}{m} \\exp(i\\xi (x - (m - r) h)) \\\\\n= h^{-\\alpha} \\exp(i\\xi x) \\sum_{m=0}^{\\infty} (-1)^{m} \\binom{\\alpha}{m} \\exp(-i\\xi (m-r)h) \\\\\n= h^{-\\alpha} \\exp(i\\xi x) \\exp(i\\xi rh) \\sum_{m=0}^{\\infty} \\binom{\\alpha}{m} (-\\exp(-i\\xi h))^{m}\n\\end{aligned}\n$$\nThe sum is the generalized binomial series for $(1+z)^{\\alpha}$ with $z = -\\exp(-i\\xi h)$. Thus, the sum is equal to $(1 - \\exp(-i\\xi h))^{\\alpha}$. The symbol for $\\delta_{h,+}^{\\alpha,r}$ is therefore:\n$$\n\\widehat{\\delta}_{h,+}^{(\\alpha,r)}(\\xi) = h^{-\\alpha} \\exp(i\\theta r) (1 - \\exp(-i\\theta))^{\\alpha}\n$$\nSimilarly, for the shifted right GL operator, $\\delta_{h,-}^{\\alpha,r}$:\n$$\n\\begin{aligned}\n\\delta_{h,-}^{\\alpha,r} \\exp(i\\xi x) = h^{-\\alpha} \\sum_{m=0}^{\\infty} (-1)^{m} \\binom{\\alpha}{m} \\exp(i\\xi (x + (m - r) h)) \\\\\n= h^{-\\alpha} \\exp(i\\xi x) \\exp(-i\\xi rh) \\sum_{m=0}^{\\infty} \\binom{\\alpha}{m} (-\\exp(i\\xi h))^{m}\n\\end{aligned}\n$$\nThis gives the symbol:\n$$\n\\widehat{\\delta}_{h,-}^{(\\alpha,r)}(\\xi) = h^{-\\alpha} \\exp(-i\\theta r) (1 - \\exp(i\\theta))^{\\alpha}\n$$\nCombining these, the symbol $\\Psi(\\theta)$ for the Riesz operator approximation $\\mathcal{R}_{h}^{(\\alpha,r)}$ is:\n$$\n\\Psi(\\theta) = -\\frac{h^{-\\alpha}}{2\\cos(\\frac{\\pi\\alpha}{2})} \\left[ \\exp(i\\theta r) (1 - \\exp(-i\\theta))^{\\alpha} + \\exp(-i\\theta r) (1 - \\exp(i\\theta))^{\\alpha} \\right]\n$$\nThe exact Riesz derivative $\\mathcal{D}_{R}^{\\alpha}$ has the symbol $-|\\xi|^{\\alpha}$. Our goal is to choose $r$ such that $\\Psi(\\theta)$ provides the best possible approximation to $-|\\xi|^{\\alpha} = -h^{-\\alpha}|\\theta|^{\\alpha}$ for small $|\\theta|$. To analyze this, we perform an asymptotic expansion of $\\Psi(\\theta)$ for small $\\theta$.\n\nFirst, let's expand the term $(1 - \\exp(-i\\theta))^{\\alpha}$. For small $\\theta$:\n$$\n1 - \\exp(-i\\theta) = 1 - \\left(1 - i\\theta + \\frac{(-i\\theta)^2}{2!} + \\frac{(-i\\theta)^3}{3!} + \\dots\\right) = i\\theta + \\frac{\\theta^2}{2} - i\\frac{\\theta^3}{6} + O(\\theta^4)\n$$\nWe can factor out $i\\theta$:\n$$\n1 - \\exp(-i\\theta) = i\\theta \\left(1 - \\frac{i\\theta}{2} - \\frac{\\theta^2}{6} + O(\\theta^3)\\right)\n$$\nUsing the generalized binomial expansion $(1+z)^\\beta = 1 + \\beta z + \\frac{\\beta(\\beta-1)}{2}z^2 + \\dots$, we get:\n$$\n\\left(1 - \\frac{i\\theta}{2} - \\frac{\\theta^2}{6} + \\dots\\right)^{\\alpha} = 1 + \\alpha\\left(-\\frac{i\\theta}{2} - \\frac{\\theta^2}{6} + \\dots\\right) + \\frac{\\alpha(\\alpha-1)}{2}\\left(-\\frac{i\\theta}{2}+\\dots\\right)^2 + \\dots\n$$\n$$\n= 1 - i\\frac{\\alpha\\theta}{2} - \\frac{\\alpha\\theta^2}{6} - \\frac{\\alpha(\\alpha-1)\\theta^2}{8} + O(\\theta^3) = 1 - i\\frac{\\alpha\\theta}{2} - \\frac{3\\alpha^2+\\alpha}{24}\\theta^2 + O(\\theta^3)\n$$\nThe symbol for the shifted left GL operator is thus:\n$$\n\\widehat{\\delta}_{h,+}^{(\\alpha,r)}(\\xi) = h^{-\\alpha} \\left(1 + i\\theta r - \\frac{r^2\\theta^2}{2} + \\dots\\right) (i\\theta)^\\alpha \\left(1 - i\\frac{\\alpha\\theta}{2} - \\frac{3\\alpha^2+\\alpha}{24}\\theta^2 + \\dots\\right)\n$$\n$$\n= (i\\xi)^\\alpha \\left(1 + i\\theta\\left(r - \\frac{\\alpha}{2}\\right) + O(\\theta^2)\\right) = (i\\xi)^\\alpha - h\\left(r - \\frac{\\alpha}{2}\\right)(i\\xi)^{\\alpha+1} + O(h^2)\n$$\nThe symbol for the shifted right GL operator is obtained by replacing $i$ with $-i$ and $r$ with $-r$ in the unshifted part of the derivation, which corresponds to replacing $\\theta$ by $-\\theta$. So:\n$$\n\\widehat{\\delta}_{h,-}^{(\\alpha,r)}(\\xi) = (-i\\xi)^\\alpha \\left(1 - i\\theta\\left(r - \\frac{\\alpha}{2}\\right) + O(\\theta^2)\\right) = (-i\\xi)^\\alpha + h\\left(r - \\frac{\\alpha}{2}\\right)(-i\\xi)^{\\alpha+1} + O(h^2)\n$$\nNow we sum these two symbols. Let $\\xi  0$:\n$$\n\\widehat{\\delta}_{h,+}^{(\\alpha,r)}(\\xi) + \\widehat{\\delta}_{h,-}^{(\\alpha,r)}(\\xi) = \\xi^\\alpha(e^{i\\pi\\alpha/2} + e^{-i\\pi\\alpha/2}) - h\\left(r - \\frac{\\alpha}{2}\\right)\\xi^{\\alpha+1}( (i)^{\\alpha+1} + (-i)^{\\alpha+1} ) + O(h^2)\n$$\nUsing $e^{iz}+e^{-iz}=2\\cos(z)$:\n$$\n= \\xi^\\alpha(2\\cos(\\frac{\\pi\\alpha}{2})) - h\\left(r - \\frac{\\alpha}{2}\\right)\\xi^{\\alpha+1}(2\\cos(\\frac{\\pi(\\alpha+1)}{2})) + O(h^2)\n$$\nUsing $\\cos(A+\\pi/2)=-\\sin(A)$:\n$$\n= 2\\cos(\\frac{\\pi\\alpha}{2})\\xi^\\alpha - h\\left(r - \\frac{\\alpha}{2}\\right)\\xi^{\\alpha+1}(-2\\sin(\\frac{\\pi\\alpha}{2})) + O(h^2)\n$$\n$$\n= 2\\cos(\\frac{\\pi\\alpha}{2})\\xi^\\alpha + 2h\\sin(\\frac{\\pi\\alpha}{2})\\left(r - \\frac{\\alpha}{2}\\right)\\xi^{\\alpha+1} + O(h^2)\n$$\nNow we substitute this into the expression for $\\Psi(\\theta)$:\n$$\n\\Psi(\\theta) = -\\frac{1}{2\\cos(\\frac{\\pi\\alpha}{2})} \\left[ 2\\cos(\\frac{\\pi\\alpha}{2})\\xi^\\alpha + 2h\\sin(\\frac{\\pi\\alpha}{2})\\left(r - \\frac{\\alpha}{2}\\right)\\xi^{\\alpha+1} + O(h^2) \\right]\n$$\n$$\n\\Psi(\\theta) = -\\xi^\\alpha - h\\tan(\\frac{\\pi\\alpha}{2})\\left(r - \\frac{\\alpha}{2}\\right)\\xi^{\\alpha+1} + O(h^2)\n$$\nA similar derivation for $\\xi  0$ yields a factor of $|\\xi|$ instead of $\\xi$, confirming the leading error term is even. The symbol of the exact operator is $-|\\xi|^\\alpha$. The error of the approximation is:\n$$\n\\text{Error} = \\Psi(\\theta) - (-|\\xi|^\\alpha) = - h\\tan(\\frac{\\pi\\alpha}{2})\\left(r - \\frac{\\alpha}{2}\\right)|\\xi|^{\\alpha+1} + O(h^2)\n$$\nThis is the leading error term. The problem asks to choose $r$ to eliminate the \"linear-in-$\\theta$\" term in the expansion, which corresponds to this $O(h)$ term (since $\\theta = \\xi h$). To eliminate this term, we must set its coefficient to zero:\n$$\n- h\\tan(\\frac{\\pi\\alpha}{2})\\left(r - \\frac{\\alpha}{2}\\right) = 0\n$$\nFor the given range $1  \\alpha  2$, we have $\\pi/2  \\pi\\alpha/2  \\pi$, so $\\tan(\\pi\\alpha/2) \\neq 0$. Therefore, we must have:\n$$\nr - \\frac{\\alpha}{2} = 0\n$$\nThis gives the required value for the shift parameter $r$:\n$$\nr = \\frac{\\alpha}{2}\n$$\nWith this choice, the $O(h)$ error term vanishes, and the scheme becomes second-order accurate, with an error of $O(h^2)$. The leading deviation from the exact symbol becomes proportional to $h^2|\\xi|^{\\alpha+2}$, which is equivalent to $h^{-\\alpha}|\\theta|^{\\alpha+2}$ up to a constant factor, matching the problem's specification.", "answer": "$$\\boxed{\\frac{\\alpha}{2}}$$", "id": "3426237"}, {"introduction": "A common challenge in solving time-fractional differential equations is the presence of \"start-up singularities,\" where the solution is not smooth near $t=0$. These singularities can degrade the convergence rate of standard numerical schemes on uniform grids. This practice explores a powerful remedy: the use of a graded temporal mesh that clusters points near the initial time to resolve the singularity. You will derive the optimal grading exponent required to restore the full convergence order of the popular L1 scheme, illustrating a key strategy for handling the characteristic non-smooth solutions of fractional-order models. [@problem_id:3426227]", "problem": "Consider the time-fractional diffusion equation with the Caputo fractional derivative of order $\\alpha \\in (0,1)$ on the spatial interval $x \\in (0,1)$ with homogeneous Dirichlet boundary conditions and a source term chosen so that the exact solution is $u(x,t) = \\sin(\\pi x)\\,t^{\\sigma}$ for $t \\in [0,1]$, where $\\sigma \\in (0,1]$. By projecting onto the first eigenmode of the Laplacian, the temporal evolution reduces to a scalar equation for the amplitude $y(t)$ that has the exact solution $y(t) = t^{\\sigma}$. The Caputo fractional derivative of order $\\alpha$ is defined by\n$$\n{}^{\\mathrm{C}}D_{t}^{\\alpha} y(t) = \\frac{1}{\\Gamma(1-\\alpha)} \\int_{0}^{t} (t-s)^{-\\alpha}\\,y'(s)\\,\\mathrm{d}s.\n$$\nDiscretize the time interval $[0,1]$ using $N$ steps on a graded mesh $\\{t_{n}\\}_{n=0}^{N}$ defined by $t_{n} = \\left(\\frac{n}{N}\\right)^{\\gamma}$ with grading exponent $\\gamma \\geq 1$. Approximate the Caputo derivative at $t=t_{n}$ via the classical $L1$ scheme,\n$$\n\\mathcal{L}_{1}[y](t_{n}) = \\frac{1}{\\Gamma(1-\\alpha)} \\sum_{k=1}^{n} \\left(\\frac{y(t_{k}) - y(t_{k-1})}{t_{k} - t_{k-1}} \\right) \\int_{t_{k-1}}^{t_{k}} (t_{n}-s}^{-\\alpha}\\,\\mathrm{d}s.\n$$\nStarting only from the above definitions and well-tested facts about the smooth-solution accuracy of the $L1$ scheme, analyze the leading-order behavior as $N \\to \\infty$ of the global discretization error at $t=1$,\n$$\nE_{N} = \\left|{}^{\\mathrm{C}}D_{t}^{\\alpha} y(1) - \\mathcal{L}_{1}[y](1)\\right|,\n$$\nfor the start-up singular solution $y(t) = t^{\\sigma}$. Then determine the minimal grading exponent $\\gamma$ such that the overall error satisfies $E_{N} = \\mathcal{O}\\!\\left(N^{-(2-\\alpha)}\\right)$, i.e., the method achieves its smooth-solution accuracy order. Your final answer must be a single closed-form analytic expression in terms of $\\alpha$ and $\\sigma$ for the minimal $\\gamma$ required to ensure $E_{N} = \\mathcal{O}\\!\\left(N^{-(2-\\alpha)}\\right)$ as $N \\to \\infty$.", "solution": "The problem requires an analysis of the global discretization error, $E_{N}$, for the $L1$ approximation of the Caputo fractional derivative of order $\\alpha$ for the function $y(t) = t^{\\sigma}$ at $t=1$. The time domain $[0,1]$ is discretized using a graded mesh $t_{n} = (n/N)^{\\gamma}$ for $n=0, 1, \\dots, N$ with a grading exponent $\\gamma \\geq 1$. The goal is to find the minimal $\\gamma$ that ensures the error $E_N$ converges at the optimal rate of $\\mathcal{O}(N^{-(2-\\alpha)})$, which is the known rate for sufficiently smooth solutions.\n\nThe global error at $t=t_N=1$ is given by\n$$\nE_{N} = \\left|{}^{\\mathrm{C}}D_{t}^{\\alpha} y(1) - \\mathcal{L}_{1}[y](1)\\right|.\n$$\nBy substituting the definitions of the Caputo derivative and the $L1$ scheme, we can express the error as a sum of local errors over the subintervals $[t_{k-1}, t_k]$:\n$$\nE_{N} = \\frac{1}{\\Gamma(1-\\alpha)} \\left| \\sum_{k=1}^{N} \\int_{t_{k-1}}^{t_{k}} (1-s)^{-\\alpha} \\left( y'(s) - \\frac{y(t_k) - y(t_{k-1})}{t_k - t_{k-1}} \\right) \\mathrm{d}s \\right|.\n$$\nThe function is $y(t) = t^{\\sigma}$, for which the first derivative is $y'(t) = \\sigma t^{\\sigma-1}$ and the second derivative is $y''(t) = \\sigma(\\sigma-1)t^{\\sigma-2}$. For the given range $\\sigma \\in (0,1]$, the second derivative $y''(t)$ is singular at $t=0$ (unless $\\sigma=1$, in which case $y''(t)=0$, and the problem becomes trivial as the $L1$ scheme is exact for linear functions). This singularity at the origin is the source of the convergence-order reduction when using a uniform mesh. The graded mesh, by clustering points near $t=0$, is designed to mitigate the effect of this singularity.\n\nThe error analysis for the $L1$ scheme on a graded mesh for solutions with an initial algebraic singularity of the form $t^{\\sigma}$ reveals that the global error is determined by two competing factors:\n$1$. The error arising from the approximation of the non-smooth part of the function near $t=0$. This error is controlled by the grading exponent $\\gamma$ and the singularity strength $\\sigma$.\n$2$. The standard truncation error of the numerical method over the smoother part of the domain, which corresponds to the rate observed for regular solutions (e.g., $y \\in C^2[0,1]$).\n\nA standard result from the numerical analysis of fractional equations states that the convergence order of the $L1$ scheme on a graded mesh for a function with the regularity of $y(t)=t^\\sigma$ is given by the balance of these two error sources. The global error $E_N$ takes the form:\n$$\nE_N = \\mathcal{O}(N^{-\\min(\\gamma \\sigma, 2-\\alpha)}).\n$$\nThe term $\\mathcal{O}(N^{-\\gamma \\sigma})$ represents the error contribution from the initial singularity. A finer mesh near $t=0$ (larger $\\gamma$) or a smoother solution (larger $\\sigma$) results in a faster decay of this error component. The term $\\mathcal{O}(N^{-(2-\\alpha)})$ is the canonical convergence rate of the $L1$ scheme for smooth solutions, which the problem statement refers to as the \"smooth-solution accuracy\". The overall accuracy is limited by the slower of these two rates.\n\nOur objective is to determine the minimal grading exponent $\\gamma$ such that the method achieves its optimal smooth-solution accuracy. This means we require the overall error to be $E_N = \\mathcal{O}(N^{-(2-\\alpha)})$. For this to hold, the error component due to the singularity, $\\mathcal{O}(N^{-\\gamma \\sigma})$, must converge at a rate at least as fast as $\\mathcal{O}(N^{-(2-\\alpha)})$. This imposes the condition on the exponents:\n$$\n\\gamma \\sigma \\geq 2-\\alpha.\n$$\nTo find the minimal grading exponent $\\gamma$ that satisfies this condition, we take the equality, as any smaller $\\gamma$ would result in the $\\mathcal{O}(N^{-\\gamma \\sigma})$ term dominating and thus determining a suboptimal convergence rate.\n$$\n\\gamma \\sigma = 2-\\alpha.\n$$\nSolving for $\\gamma$, we obtain the minimal required grading exponent:\n$$\n\\gamma = \\frac{2-\\alpha}{\\sigma}.\n$$\nWe should verify that this value is consistent with the constraint $\\gamma \\geq 1$. Given that $\\alpha \\in (0,1)$ and $\\sigma \\in (0,1]$, the numerator $2-\\alpha$ is in the interval $(1,2)$, and the denominator $\\sigma$ is in $(0,1]$. Therefore, the ratio $\\frac{2-\\alpha}{\\sigma}$ is always greater than $1$. The condition is satisfied. This choice of $\\gamma$ precisely balances the error from the start-up singularity with the intrinsic error of the numerical scheme, thereby restoring the optimal convergence order.", "answer": "$$\n\\boxed{\\frac{2-\\alpha}{\\sigma}}\n$$", "id": "3426227"}, {"introduction": "Verifying the correctness of a numerical solver is a crucial step in scientific computing, and the method of manufactured solutions provides a rigorous framework for this task. This hands-on problem challenges you to implement a spectral method for the spatial fractional Laplacian, an operator central to non-local physics. You will construct an exact solution based on an eigenfunction of the Laplacian, use it to define a corresponding source term, and then numerically solve the problem to measure the convergence rate of your implementation, confirming its theoretical accuracy. [@problem_id:3426256]", "problem": "Consider the one-dimensional bounded domain $(0,1)$ with homogeneous Dirichlet boundary conditions. Let $-\\Delta$ denote the classical Laplacian operator associated with the second derivative, and let $(-\\Delta)^s$ for $s \\in (0,1)$ denote the spectral fractional Laplacian defined on $(0,1)$ by functional calculus with respect to the eigenbasis of $-\\Delta$ under Dirichlet boundary conditions. The manufactured solution approach constructs an exact solution with a known right-hand side to validate a numerical method. In this problem, choose the manufactured solution $u(x) = \\sin(m\\pi x)$ for a positive integer $m$ and define $f(x)$ so that the fractional Poisson problem\n$$\n(-\\Delta)^s u(x) = f(x), \\quad x \\in (0,1), \\quad u(0)=u(1)=0,\n$$\nis satisfied exactly. You may assume the spectral definition of $(-\\Delta)^s$ on $(0,1)$ with homogeneous Dirichlet boundary conditions, based on the eigenfunctions and eigenvalues of the classical Dirichlet Laplacian. Angles in trigonometric functions must be interpreted in radians.\n\nStarting from the following fundamental base: \n- The classical Dirichlet Laplacian $-\\Delta$ on $(0,1)$ has a complete orthonormal set of eigenfunctions with real, positive eigenvalues.\n- The spectral fractional Laplacian $(-\\Delta)^s$ is defined on $(0,1)$ by applying the fractional power $s$ to the eigenvalues of $-\\Delta$ in its spectral decomposition.\n- The Finite Difference Method (FDM) for the classical Dirichlet Laplacian on a uniform grid yields a symmetric positive definite matrix that approximates the operator.\n\nDesign a numerical method that:\n- Constructs the discrete Dirichlet Laplacian matrix on a uniform grid with $N$ interior points using a standard second-order centered FDM.\n- Computes the spectral fractional power of this matrix via its eigen-decomposition.\n- Solves the discrete fractional Poisson problem for the manufactured right-hand side $f(x)$ obtained from the chosen $u(x)$ and the spectral definition of $(-\\Delta)^s$.\n- Evaluates the numerical solution $u_h$ at the interior grid points and compares it against the exact solution samples $u(x_i)$ at the same grid points.\n- Uses the discrete $L^2$ error defined by\n$$\nE(N) = \\left( h \\sum_{i=1}^{N} \\left| u_h(x_i) - u(x_i) \\right|^2 \\right)^{1/2},\n$$\nwhere $h = \\frac{1}{N+1}$ and $x_i = i h$ are the interior grid points.\n\nEstimate the observed convergence rate under grid refinement by computing, for two successive refinements $N \\to 2N$, the quantity\n$$\n\\rho(N \\to 2N) = \\frac{\\log\\left(E(N)/E(2N)\\right)}{\\log(2)}.\n$$\nFor each test case, report a single float equal to the mean of the two successive refinement rates $\\rho(N_1 \\to N_2)$ and $\\rho(N_2 \\to N_3)$ over three grid sizes $N_1  N_2  N_3$.\n\nTest suite:\n- Case $1$: $s = 0.25$, $m = 1$, $N_1 = 50$, $N_2 = 100$, $N_3 = 200$.\n- Case $2$: $s = 0.50$, $m = 1$, $N_1 = 50$, $N_2 = 100$, $N_3 = 200$.\n- Case $3$: $s = 0.75$, $m = 3$, $N_1 = 50$, $N_2 = 100$, $N_3 = 200$.\n- Case $4$: $s = 0.99$, $m = 1$, $N_1 = 50$, $N_2 = 100$, $N_3 = 200$.\n\nAll angles in $\\sin$ are in radians. No physical units are involved. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $[r_1,r_2,r_3,r_4]$, where each $r_k$ is the mean of the two successive refinement rates for the $k$-th test case. Each list element must be a float.", "solution": "The user has provided a problem statement that requires the validation of a numerical method for the one-dimensional fractional Poisson problem using a manufactured solution. The problem is scientifically sound, well-posed, and contains all necessary information for a unique solution. We can therefore proceed with a full solution.\n\n### 1. Mathematical Formulation\n\nThe problem under consideration is the fractional Poisson equation on the domain $\\Omega = (0,1)$ with homogeneous Dirichlet boundary conditions:\n$$\n\\begin{cases}\n(-\\Delta)^s u(x) = f(x),  x \\in (0,1) \\\\\nu(0) = u(1) = 0\n\\end{cases}\n$$\nwhere $s \\in (0,1)$ is the fractional order. The operator $(-\\Delta)^s$ is the spectral fractional Laplacian.\n\nThe classical Laplacian operator $-\\Delta = -d^2/dx^2$ on $(0,1)$ with homogeneous Dirichlet boundary conditions has a set of known eigenvalues $\\lambda_k$ and corresponding orthonormal eigenfunctions $\\phi_k(x)$:\n$$\n\\lambda_k = (k\\pi)^2, \\quad \\phi_k(x) = \\sqrt{2}\\sin(k\\pi x), \\quad k = 1, 2, 3, \\dots\n$$\nAny function $g(x)$ in the appropriate functional space can be represented by its eigenfunction expansion $g(x) = \\sum_{k=1}^{\\infty} c_k \\phi_k(x)$, where $c_k = \\int_0^1 g(x) \\phi_k(x) dx$. The spectral fractional Laplacian is defined by its action on this expansion:\n$$\n(-\\Delta)^s g(x) = \\sum_{k=1}^{\\infty} c_k \\lambda_k^s \\phi_k(x)\n$$\nThe problem specifies a manufactured solution $u(x) = \\sin(m\\pi x)$ for some positive integer $m$. This choice is convenient because $u(x)$ is directly proportional to the $m$-th eigenfunction $\\phi_m(x)$: $u(x) = \\frac{1}{\\sqrt{2}}\\phi_m(x)$.\nApplying the fractional operator to $u(x)$, we find:\n$$\n(-\\Delta)^s u(x) = (-\\Delta)^s \\left( \\frac{1}{\\sqrt{2}}\\phi_m(x) \\right) = \\frac{1}{\\sqrt{2}} \\lambda_m^s \\phi_m(x)\n$$\nSubstituting the expressions for $\\lambda_m$ and $\\phi_m(x)$:\n$$\n(-\\Delta)^s u(x) = \\frac{1}{\\sqrt{2}} ((m\\pi)^2)^s (\\sqrt{2}\\sin(m\\pi x)) = (m\\pi)^{2s} \\sin(m\\pi x)\n$$\nThus, to satisfy the equation with the manufactured solution $u(x)$, the right-hand side function $f(x)$ must be:\n$$\nf(x) = (m\\pi)^{2s} \\sin(m\\pi x)\n$$\n\n### 2. Numerical Discretization\n\nThe continuous domain $(0,1)$ is discretized using a uniform grid with $N$ interior points. Let the grid spacing be $h = 1/(N+1)$. The grid points are $x_i = i h$ for $i = 0, 1, \\dots, N+1$. The interior points are $\\{x_i\\}_{i=1}^N$. Let $u_h$ be the vector of numerical approximations to $u(x)$ at these interior points, i.e., $u_h = [u(x_1), u(x_2), \\dots, u(x_N)]^T$.\n\nThe classical Laplacian $-\\Delta$ is approximated using a second-order centered finite difference scheme:\n$$\n-\\frac{d^2u}{dx^2}\\bigg|_{x=x_i} \\approx \\frac{-u(x_{i-1}) + 2u(x_i) - u(x_{i+1})}{h^2}\n$$\nIncorporating the boundary conditions $u(x_0)=u(0)=0$ and $u(x_{N+1})=u(1)=0$, this discretization leads to an $N \\times N$ matrix system. The discrete Laplacian operator, denoted $A_h$, is a symmetric positive definite matrix:\n$$\nA_h = \\frac{1}{h^2}\n\\begin{pmatrix}\n2  -1  0  \\dots  0 \\\\\n-1  2  -1  \\dots  0 \\\\\n0  \\ddots  \\ddots  \\ddots  0 \\\\\n\\vdots   -1  2  -1 \\\\\n0  \\dots  0  -1  2\n\\end{pmatrix}\n$$\n\n### 3. Solving the Discrete Fractional System\n\nThe numerical method is a discrete analogue of the spectral definition. The discrete fractional Laplacian $A_h^s$ is computed via the eigendecomposition of $A_h$. Let the eigendecomposition of $A_h$ be:\n$$\nA_h = V \\Lambda V^T\n$$\nwhere $\\Lambda$ is a diagonal matrix containing the eigenvalues $\\mu_k$ of $A_h$, and $V$ is an orthogonal matrix whose columns are the corresponding eigenvectors $v_k$. The matrix power $A_h^s$ is then defined as:\n$$\nA_h^s = V \\Lambda^s V^T\n$$\nwhere $\\Lambda^s$ is the diagonal matrix with entries $\\mu_k^s$.\n\nThe discrete form of the fractional Poisson problem is the linear system:\n$$\nA_h^s u_h = f_h\n$$\nwhere $f_h = [f(x_1), f(x_2), \\dots, f(x_N)]^T$ is the vector of the right-hand side function evaluated at the interior grid points. The solution for the numerical approximation $u_h$ is given by:\n$$\nu_h = (A_h^s)^{-1} f_h = V \\Lambda^{-s} V^T f_h\n$$\nThis provides a computationally stable and efficient algorithm:\n1.  Construct the matrix $A_h$.\n2.  Compute its eigenvalues $\\Lambda$ and eigenvectors $V$ using a reliable numerical library function (e.g., `scipy.linalg.eigh`).\n3.  Construct the vector $f_h$.\n4.  Transform $f_h$ into the eigenbasis of $A_h$: $\\hat{f}_h = V^T f_h$.\n5.  Scale the components in the eigenbasis: $\\hat{u}_h(k) = \\mu_k^{-s} \\hat{f}_h(k)$. This is a component-wise multiplication.\n6.  Transform the result back to the standard basis: $u_h = V \\hat{u}_h$.\n\n### 4. Error Analysis and Convergence Rate\n\nTo validate the method, we compare the numerical solution $u_h$ with the exact solution $u(x)$ sampled at the grid points. The vector of exact solution values is $u_{exact} = [u(x_1), u(x_2), \\dots, u(x_N)]^T$.\n\nThe error is quantified using the discrete $L^2$ norm:\n$$\nE(N) = \\left( h \\sum_{i=1}^{N} | u_h(x_i) - u(x_i) |^2 \\right)^{1/2} = \\sqrt{h} \\|u_h - u_{exact}\\|_2\n$$\nwhere $\\|\\cdot\\|_2$ denotes the standard Euclidean vector norm.\n\nThe order of convergence, $\\rho$, is estimated by refining the grid. If the error behaves as $E(N) \\approx C h^\\rho = C (N+1)^{-\\rho}$ for some constant $C$, then for two grid sizes $N$ and $2N$, the ratio of errors is approximately $E(N)/E(2N) \\approx ((N+1)^{-1} / (2N+1)^{-1})^\\rho \\approx 2^\\rho$. Taking the logarithm gives the formula for the observed rate of convergence:\n$$\n\\rho(N \\to 2N) = \\frac{\\log(E(N)/E(2N))}{\\log(2)}\n$$\nThe problem requires computing this rate for two successive refinements, $N_1 \\to N_2$ and $N_2 \\to N_3$ (where $N_2=2N_1$ and $N_3=2N_2$ is not assumed, but is true in the test cases), and reporting the mean of these two rates. This provides a more stable estimate of the asymptotic convergence rate. The expected convergence rate for this method with a smooth manufactured solution is $\\rho=2$, as the dominant error stems from the second-order finite difference approximation of the local Laplacian operator.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import eigh\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    test_cases = [\n        # (s, m, (N1, N2, N3))\n        {'s': 0.25, 'm': 1, 'N_grid': (50, 100, 200)},\n        {'s': 0.50, 'm': 1, 'N_grid': (50, 100, 200)},\n        {'s': 0.75, 'm': 3, 'N_grid': (50, 100, 200)},\n        {'s': 0.99, 'm': 1, 'N_grid': (50, 100, 200)},\n    ]\n\n    results = []\n    for case in test_cases:\n        mean_rate = compute_mean_convergence_rate(case['s'], case['m'], case['N_grid'])\n        results.append(mean_rate)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef compute_mean_convergence_rate(s, m, N_grid_sizes):\n    \"\"\"\n    Computes the mean convergence rate for a given set of parameters.\n\n    Args:\n        s (float): The fractional order of the Laplacian.\n        m (int): The mode number for the manufactured solution.\n        N_grid_sizes (tuple): A tuple of three integers (N1, N2, N3) for grid sizes.\n\n    Returns:\n        float: The mean of two successive convergence rates.\n    \"\"\"\n    errors = []\n    for N in N_grid_sizes:\n        h = 1.0 / (N + 1)\n        \n        # 1. Define interior grid points\n        x = np.linspace(h, 1.0 - h, N)\n        \n        # 2. Construct the discrete Laplacian matrix A_h\n        main_diag = np.full(N, 2.0)\n        off_diag = np.full(N - 1, -1.0)\n        A_h = (np.diag(main_diag) + np.diag(off_diag, k=1) + np.diag(off_diag, k=-1)) / (h**2)\n        \n        # 3. Compute the eigendecomposition of A_h.\n        # eigh is used for symmetric matrices.\n        eigenvalues, eigenvectors = eigh(A_h)\n        \n        # 4. Construct the right-hand side vector f_h\n        # f(x) = (m*pi)^(2s) * sin(m*pi*x)\n        f_h = (m * np.pi)**(2 * s) * np.sin(m * np.pi * x)\n        \n        # 5. Solve the linear system A_h^s * u_h = f_h using the spectral method\n        # u_h = V * Lambda^(-s) * V^T * f_h\n        # Step 5.1: Transform f_h to the eigenbasis\n        f_hat = eigenvectors.T @ f_h\n        # Step 5.2: Scale by Lambda^(-s)\n        u_hat = f_hat * (eigenvalues**(-s))\n        # Step 5.3: Transform back to the standard basis\n        u_h = eigenvectors @ u_hat\n        \n        # 6. Compute the exact solution vector u_exact\n        u_exact = np.sin(m * np.pi * x)\n        \n        # 7. Calculate the discrete L2 error E(N)\n        error_norm_sq = np.sum((u_h - u_exact)**2)\n        error_L2 = np.sqrt(h * error_norm_sq)\n        errors.append(error_L2)\n        \n    # 8. Calculate convergence rates\n    E1, E2, E3 = errors\n    \n    # Check for grid refinement ratio. Assume it is 2 for simplicity.\n    grid_ratio1 = N_grid_sizes[1] / N_grid_sizes[0]\n    grid_ratio2 = N_grid_sizes[2] / N_grid_sizes[1]\n\n    rate1 = np.log(E1 / E2) / np.log(grid_ratio1)\n    rate2 = np.log(E2 / E3) / np.log(grid_ratio2)\n    \n    mean_rate = (rate1 + rate2) / 2.0\n    \n    return mean_rate\n\nsolve()\n\n```", "id": "3426256"}]}