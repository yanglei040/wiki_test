{"hands_on_practices": [{"introduction": "A fundamental skill in the numerical analysis of time integrators is the ability to derive the stability function $R(z)$. This rational function of the complex step size $z$ encapsulates the method's behavior on the linear test problem and is the gateway to analyzing its stability. This exercise guides you through the derivation of $R(z)$ for a specific singly diagonally implicit Runge-Kutta (SDIRK) method and then uses it to assess A- and L-stability directly from their definitions, providing essential practice in these core analytical techniques. [@problem_id:3360286]", "problem": "Consider the one-dimensional heat equation with homogeneous Dirichlet boundary conditions,\n$$\nu_{t}(x,t) = \\nu\\,u_{xx}(x,t), \\quad x \\in (0,1), \\quad t \\geq 0, \\quad u(0,t) = u(1,t) = 0,\n$$\nwhere $\\nu  0$ is the thermal diffusivity. Let a standard second-order central difference semi-discretization in space on a uniform grid of $N$ interior points with mesh width $h = \\frac{1}{N+1}$ be used, yielding the system of ordinary differential equations\n$$\n\\frac{d}{dt}\\mathbf{u}(t) = A_{h}\\,\\mathbf{u}(t),\n$$\nwhere $\\mathbf{u}(t) \\in \\mathbb{R}^{N}$ collects the nodal values and $A_{h} = \\frac{\\nu}{h^{2}}L$ with $L \\in \\mathbb{R}^{N \\times N}$ the tridiagonal matrix with entries $L_{jj} = -2$, $L_{j,j+1} = L_{j+1,j} = 1$, and zeros otherwise. It is known that the spectrum of $A_{h}$ satisfies $\\sigma(A_{h}) \\subset (-\\infty,0)$ and, for each eigenvalue $\\lambda \\in \\sigma(A_{h})$, the corresponding mode satisfies the scalar test equation $\\frac{d}{dt}y(t) = \\lambda\\,y(t)$.\n\nTime-integrate this semi-discrete system with the following two-stage singly diagonally implicit Runge–Kutta (SDIRK) method (the Alexander second-order method), whose Butcher coefficients are\n$$\n\\begin{array}{c|cc}\n\\gamma  \\gamma  0 \\\\\n1  1-\\gamma  \\gamma \\\\\n\\hline\n  1-\\gamma  \\gamma\n\\end{array}\n\\quad \\text{with} \\quad \\gamma = 1 - \\frac{1}{\\sqrt{2}}.\n$$\nApply the method to the scalar test equation $\\frac{d}{dt}y(t) = \\lambda\\,y(t)$ and define $z = \\Delta t\\,\\lambda$, where $\\Delta t  0$ is the time step. Derive the stability function $R(z)$ of this method, expressed as a single closed-form analytic function of $z$ with $\\gamma$ substituted by $1 - \\frac{1}{\\sqrt{2}}$.\n\nThen, using only the spectral characterization of $A_{h}$ together with your derived $R(z)$, assess whether the method is $A$-stable and whether it is $L$-stable for this semi-discrete heat equation. Base your reasoning on fundamental definitions: $A$-stability means $|R(z)| \\leq 1$ for all $z$ with $\\operatorname{Re}(z) \\leq 0$, and $L$-stability means $A$-stability together with $\\lim_{z \\to -\\infty} R(z) = 0$. You must not invoke any canned stability theorems; reason directly from the definitions and the spectrum of $A_{h}$.\n\nYour final answer must be the derived closed-form expression for $R(z)$. No rounding is required.", "solution": "The problem statement is valid as it describes a standard, well-posed problem in numerical analysis concerning the stability of a time integration scheme for a partial differential equation. It is scientifically sound, objective, and contains all necessary information.\n\nThe task is to derive the stability function $R(z)$ for the given two-stage singly diagonally implicit Runge–Kutta (SDIRK) method and subsequently analyze its $A$-stability and $L$-stability properties.\n\nThe Butcher tableau for the method is:\n$$\n\\begin{array}{c|cc}\n\\gamma  \\gamma  0 \\\\\n1  1-\\gamma  \\gamma \\\\\n\\hline\n  1-\\gamma  \\gamma\n\\end{array}\n$$\nwith $\\gamma = 1 - \\frac{1}{\\sqrt{2}}$.\n\nWe apply this method to the scalar test equation $\\frac{d}{dt}y(t) = \\lambda y(t)$. A single step of the Runge-Kutta method from $y_n$ to $y_{n+1}$ is given by computing the stage values $Y_1, Y_2$ and then the final result.\n\nThe stage values $Y_i$ are approximations to $y(t_n + c_i \\Delta t)$. For an implicit method, they are defined by:\n$$\nY_i = y_n + \\Delta t \\sum_{j=1}^{2} a_{ij} f(Y_j)\n$$\nwhere $f(Y_j) = \\lambda Y_j$. Let $z = \\Delta t \\lambda$. The stage equations become:\n$$\nY_i = y_n + z \\sum_{j=1}^{2} a_{ij} Y_j\n$$\nFor the given method ($a_{11}=\\gamma$, $a_{12}=0$, $a_{21}=1-\\gamma$, $a_{22}=\\gamma$):\n\nStage $1$:\n$$\nY_1 = y_n + z a_{11} Y_1 = y_n + z \\gamma Y_1\n$$\nSolving for $Y_1$:\n$$\nY_1(1 - z\\gamma) = y_n \\implies Y_1 = \\frac{y_n}{1 - z\\gamma}\n$$\n\nStage $2$:\n$$\nY_2 = y_n + z(a_{21}Y_1 + a_{22}Y_2) = y_n + z(1-\\gamma)Y_1 + z\\gamma Y_2\n$$\nSolving for $Y_2$:\n$$\nY_2(1 - z\\gamma) = y_n + z(1-\\gamma)Y_1\n$$\nSubstitute the expression for $Y_1$:\n$$\nY_2(1 - z\\gamma) = y_n + z(1-\\gamma)\\frac{y_n}{1 - z\\gamma}\n$$\n$$\nY_2 = \\frac{y_n}{1 - z\\gamma} + \\frac{z(1-\\gamma)y_n}{(1 - z\\gamma)^2} = \\frac{y_n(1 - z\\gamma) + z(1-\\gamma)y_n}{(1 - z\\gamma)^2}\n$$\n$$\nY_2 = \\frac{y_n(1 - z\\gamma + z - z\\gamma)}{(1 - z\\gamma)^2} = y_n \\frac{1 + z(1-2\\gamma)}{(1 - z\\gamma)^2}\n$$\nThe Butcher tableau shows that the weights $b_i$ are identical to the last row of the matrix $A$, i.e., $b_1 = a_{21} = 1-\\gamma$ and $b_2 = a_{22} = \\gamma$. This property is known as \"stiffly accurate\", and it implies that the final solution update $y_{n+1}$ is identical to the last stage value, $Y_2$.\nTherefore, the stability function $R(z) = y_{n+1}/y_n$ is simply $Y_2/y_n$:\n$$\nR(z) = \\frac{1 + z(1-2\\gamma)}{(1 - z\\gamma)^2}\n$$\nNow we substitute the given value $\\gamma = 1 - \\frac{1}{\\sqrt{2}} = 1 - \\frac{\\sqrt{2}}{2}$:\n$$\n1-2\\gamma = 1 - 2\\left(1 - \\frac{\\sqrt{2}}{2}\\right) = 1 - 2 + \\sqrt{2} = \\sqrt{2}-1\n$$\nSo, the stability function is:\n$$\nR(z) = \\frac{1 + (\\sqrt{2}-1)z}{\\left(1 - \\left(1-\\frac{\\sqrt{2}}{2}\\right)z\\right)^2}\n$$\nThis is the required closed-form expression.\n\nNext, we assess the stability properties.\n**A-stability**: A method is $A$-stable if its region of absolute stability contains the entire left half of the complex plane, i.e., $|R(z)| \\le 1$ for all $z \\in \\mathbb{C}$ with $\\operatorname{Re}(z) \\le 0$.\nThe poles of $R(z)$ are given by the roots of the denominator, $1 - z\\gamma = 0$, which gives $z = 1/\\gamma$.\nSince $\\gamma = 1 - \\frac{1}{\\sqrt{2}} \\approx 1 - 0.707 = 0.293 > 0$, the pole $z = 1/\\gamma$ is in the right-half plane, $\\operatorname{Re}(z) > 0$.\nThus, $R(z)$ is analytic for all $z$ with $\\operatorname{Re}(z) \\le 0$.\nBy the Maximum Modulus Principle, if $|R(z)| \\le 1$ on the boundary of this region (i.e., the imaginary axis, $z=iy$ for $y \\in \\mathbb{R}$) and at infinity, then $|R(z)| \\le 1$ throughout the region.\nLet's check the imaginary axis, $z = iy$:\n$$\n|R(iy)|^2 = \\frac{|1 + iy(\\sqrt{2}-1)|^2}{|(1 - iy(1-\\frac{\\sqrt{2}}{2}))^2|^2} = \\frac{1^2 + y^2(\\sqrt{2}-1)^2}{\\left(1^2 + y^2\\left(1-\\frac{\\sqrt{2}}{2}\\right)^2\\right)^2}\n$$\nLet's simplify the coefficients. Note that $(\\sqrt{2}-1)^2 = 2-2\\sqrt{2}+1 = 3-2\\sqrt{2}$.\nAlso, $\\left(1-\\frac{\\sqrt{2}}{2}\\right)^2 = \\left(\\frac{2-\\sqrt{2}}{2}\\right)^2 = \\frac{4-4\\sqrt{2}+2}{4} = \\frac{3-2\\sqrt{2}}{2}$.\nLet $a = y^2(3-2\\sqrt{2})$. Since $3-2\\sqrt{2} > 0$, we have $a \\ge 0$. The inequality $|R(iy)|^2 \\le 1$ becomes:\n$$\n1 + a \\le \\left(1 + \\frac{a}{2}\\right)^2\n$$\n$$\n1 + a \\le 1 + a + \\frac{a^2}{4}\n$$\n$$\n0 \\le \\frac{a^2}{4}\n$$\nThis inequality is true for all real $a$, and therefore for all $y \\in \\mathbb{R}$. So, $|R(iy)| \\le 1$.\nNow we check the limit as $|z| \\to \\infty$ in the left-half plane:\n$$\n\\lim_{|z|\\to\\infty, \\operatorname{Re}(z)\\le 0} |R(z)| = \\lim_{|z|\\to\\infty} \\left|\\frac{1 + z(1-2\\gamma)}{1-2z\\gamma+z^2\\gamma^2}\\right| = \\lim_{|z|\\to\\infty} \\left|\\frac{z(1-2\\gamma)}{z^2\\gamma^2}\\right| = \\lim_{|z|\\to\\infty} \\left|\\frac{1-2\\gamma}{\\gamma^2 z}\\right| = 0\n$$\nSince $|R(z)| \\le 1$ on the boundary and goes to $0$ at infinity, by the Maximum Modulus Principle, $|R(z)| \\le 1$ for all $\\operatorname{Re}(z) \\le 0$. The method is $A$-stable.\n\n**L-stability**: A method is $L$-stable if it is $A$-stable and, in addition, $\\lim_{|z| \\to \\infty} |R(z)| = 0$ for $\\operatorname{Re}(z) \\le 0$. The problem concerns the semi-discrete heat equation, for which the eigenvalues $\\lambda$ are real and negative. Thus, the relevant limit is for $z$ approaching $-\\infty$ along the negative real axis.\nWe have already shown that the method is $A$-stable. We now check the limit:\n$$\n\\lim_{z \\to -\\infty} R(z) = \\lim_{z \\to -\\infty} \\frac{1 + z(1-2\\gamma)}{(1 - z\\gamma)^2}\n$$\nThis is a rational function where the degree of the numerator is $1$ and the degree of the denominator is $2$.\n$$\n\\lim_{z \\to -\\infty} \\frac{z(1-2\\gamma)}{z^2\\gamma^2} = \\lim_{z \\to -\\infty} \\frac{1-2\\gamma}{z\\gamma^2} = 0\n$$\nSince the method is $A$-stable and the limit of $|R(z)|$ at infinity in the left-half plane is 0, the method is $L$-stable. This property is highly desirable for stiff problems like the semi-discretized heat equation, as it ensures that very stiff modes are strongly damped by the numerical scheme.", "answer": "$$\\boxed{\\frac{1 + \\left(\\sqrt{2}-1\\right)z}{\\left(1 - \\left(1-\\frac{\\sqrt{2}}{2}\\right)z\\right)^2}}$$", "id": "3360286"}, {"introduction": "Theoretical stability properties have tangible consequences in simulations. A-stability guarantees stability but does not prevent non-physical oscillations when solving stiff problems, a shortcoming addressed by the stricter requirement of L-stability. This computational practice contrasts the L-stable Backward Euler scheme with the merely A-stable Crank-Nicolson method on a convection-diffusion problem, where stiff diffusive modes are prominent. By implementing these schemes in Fourier space, you will directly observe and quantify how the failure to damp high-frequency components (i.e., $|R(-\\infty)| \\neq 0$) leads to spurious oscillations. [@problem_id:3360288]", "problem": "Consider the one-dimensional linear convection–diffusion partial differential equation (PDE) on a periodic domain,\n$$\nu_t(x,t) + b\\,u_x(x,t) = \\kappa\\,u_{xx}(x,t),\n$$\nfor $x \\in [0,L]$, with period $L$, constant convection speed $b \\in \\mathbb{R}$, and diffusion coefficient $\\kappa  0$. Assume a spatial semi-discretization on a uniform grid with $N$ points and grid spacing $h = L/N$, periodic boundary conditions, and the following standard second-order central differences for the spatial operators:\n- For the first derivative, use $(u_{j+1} - u_{j-1})/(2h)$, which has discrete Fourier symbol $i\\,\\sin(\\theta)/h$.\n- For the second derivative, use $(u_{j+1} - 2u_j + u_{j-1})/h^2$, which has discrete Fourier symbol $-4\\,\\sin^2(\\theta/2)/h^2$.\nHere, $\\theta = 2\\pi m/N$ for Fourier mode index $m \\in \\{0,1,\\dots,N-1\\}$.\n\nThe semi-discrete system can therefore be written as $\\partial_t u = \\mathcal{L} u$, where $\\mathcal{L}$ is the discrete linear spatial operator whose action on the discrete Fourier mode corresponding to $\\theta$ has eigenvalue\n$$\n\\lambda(\\theta) = -i\\,b\\,\\frac{\\sin(\\theta)}{h} - \\kappa\\,\\frac{4\\sin^2(\\theta/2)}{h^2}.\n$$\n\nTwo implicit time integrators are to be contrasted:\n1. Backward Euler (implicit Euler), defined by $(I - \\Delta t\\,\\mathcal{L})\\,u^{n+1} = u^{n}$.\n2. Crank–Nicolson, defined by $\\left(I - \\frac{\\Delta t}{2}\\,\\mathcal{L}\\right) u^{n+1} = \\left(I + \\frac{\\Delta t}{2}\\,\\mathcal{L}\\right) u^{n}$.\n\nStarting from the widely used linear test equation $y'(t) = \\lambda\\,y(t)$ and the definitions of the schemes above, derive the corresponding scalar stability functions $R(z)$, where $z = \\Delta t\\,\\lambda$, for backward Euler and Crank–Nicolson. Then, using the discrete Fourier symbols for $\\lambda(\\theta)$ specified above, design a one-step Fourier-space propagator for each scheme so that $\\widehat{u}^{n+1}(\\theta) = R\\left(\\Delta t\\,\\lambda(\\theta)\\right)\\,\\widehat{u}^{n}(\\theta)$, where $\\widehat{u}$ denotes the discrete Fourier transform of $u$.\n\nDefine the measure of oscillations as follows, using the single-step update from $t=0$ to $t=\\Delta t$:\n- Consider the initial condition\n$$\nu(x,0) = \n\\begin{cases}\n1,  0 \\le x  L/2, \\\\\n0,  L/2 \\le x  L,\n\\end{cases}\n$$\ninterpreted on the periodic grid. This is a discontinuous step function that excites a wide spectrum of Fourier modes, including the stiffest high-frequency components.\n- For each scheme (backward Euler and Crank–Nicolson), compute $u(x,\\Delta t)$ via the Fourier-space one-step update.\n- Define the undershoot amplitude for a scheme as the minimum value of $u(x,\\Delta t)$, which quantifies oscillations producing values below $0$. Define the overshoot amplitude for a scheme as $\\max\\{u(x,\\Delta t)-1,\\,0\\}$, which quantifies values above $1$.\n\nAdditionally, to connect oscillations to non-L-stability, quantify the high-frequency stiff-mode amplification using the magnitude of the stability function evaluated at the Nyquist mode $\\theta_{\\mathrm{nyq}} = \\pi$ (i.e., $m = N/2$), namely\n$$\nG_{\\mathrm{nyq}}^{\\mathrm{scheme}} = \\left|R\\big(\\Delta t\\,\\lambda(\\pi)\\big)\\right|.\n$$\nRecall that for $L$-stability (stiff decay), one requires $R(\\infty) = 0$, meaning that infinitely stiff modes are completely damped; otherwise, nonzero $R(\\infty)$ implies persistent (or alternating-sign) high-frequency components that manifest as oscillations.\n\nYour task is to:\n- Derive the stability functions $R(z)$ for backward Euler and Crank–Nicolson from the scheme definitions applied to $y'=\\lambda y$.\n- Construct the one-step Fourier-space propagators using the given discrete symbols.\n- Implement a complete program that:\n  1. Sets $L = 2\\pi$, $N = 256$, and builds the step-function initial condition on the grid.\n  2. For each specified test case, computes the one-step update for both schemes by multiplying Fourier coefficients with $R\\left(\\Delta t\\,\\lambda(\\theta)\\right)$ and transforming back to physical space.\n  3. Measures the undershoot and overshoot amplitudes as defined above.\n  4. Computes $G_{\\mathrm{nyq}}^{\\mathrm{scheme}}$ for both schemes.\n  5. Outputs, for each test case, a list of six floats\n     $$\n     \\big[\\min(u_{\\mathrm{CN}}),\\,\\min(u_{\\mathrm{BE}}),\\,\\max\\{u_{\\mathrm{CN}}-1,0\\},\\,\\max\\{u_{\\mathrm{BE}}-1,0\\},\\,G_{\\mathrm{nyq}}^{\\mathrm{CN}},\\,G_{\\mathrm{nyq}}^{\\mathrm{BE}}\\big],\n     $$\n     in that order.\n\nAll quantities are dimensionless; no physical units are required.\n\nTest suite:\n- Case 1 (stiff diffusion, no convection): $b = 0.0$, $\\kappa = 100.0$, $\\Delta t = 0.5$.\n- Case 2 (stiff diffusion with convection): $b = 3.0$, $\\kappa = 100.0$, $\\Delta t = 0.5$.\n- Case 3 (moderately diffusive, small time step): $b = 0.0$, $\\kappa = 1.0$, $\\Delta t = 10^{-4}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a six-element list for one test case, with no spaces. For example: \n$$\n[\\,[a_1,b_1,c_1,d_1,e_1,f_1],[a_2,b_2,c_2,d_2,e_2,f_2],[a_3,b_3,c_3,d_3,e_3,f_3]\\,].\n$$", "solution": "The problem statement is a well-posed and scientifically grounded exercise in the numerical analysis of partial differential equations. It concerns the stability and oscillatory properties of two common time integration schemes, backward Euler and Crank-Nicolson, when applied to a semi-discretized convection-diffusion equation. All definitions, parameters, and objectives are stated clearly and are consistent with standard theory in the field. The problem is therefore valid.\n\nThe solution proceeds in two main parts: first, a theoretical derivation of the necessary components (stability functions and propagators), and second, a description of the numerical implementation to compute the required metrics.\n\n**1. Derivation of Stability Functions and Propagators**\n\nTo analyze the stability of time integration schemes, we apply them to the linear test equation $y'(t) = \\lambda y(t)$, where $\\lambda \\in \\mathbb{C}$ is a complex number with $\\text{Re}(\\lambda) \\le 0$. A single step of a numerical scheme updates the solution from time $t_n$ to $t_{n+1} = t_n + \\Delta t$ as $y^{n+1} = R(z) y^n$, where $z = \\lambda \\Delta t$. The function $R(z)$ is the scalar stability function of the scheme.\n\n**1.1. Backward Euler (BE)**\nThe backward Euler scheme is defined by the implicit relation:\n$$\n\\frac{u^{n+1} - u^n}{\\Delta t} = \\mathcal{L} u^{n+1}\n$$\nApplying this to the test equation, where $\\mathcal{L}$ corresponds to multiplication by $\\lambda$:\n$$\ny^{n+1} - y^n = \\Delta t \\lambda y^{n+1}\n$$\nSolving for $y^{n+1}$:\n$$\ny^{n+1} (1 - \\Delta t \\lambda) = y^n\n$$\n$$\ny^{n+1} = \\frac{1}{1 - \\Delta t \\lambda} y^n\n$$\nThus, the stability function for backward Euler is:\n$$\nR_{\\mathrm{BE}}(z) = \\frac{1}{1-z}\n$$\n\n**1.2. Crank-Nicolson (CN)**\nThe Crank-Nicolson scheme is defined by the implicit relation:\n$$\n\\frac{u^{n+1} - u^n}{\\Delta t} = \\frac{1}{2} (\\mathcal{L} u^n + \\mathcal{L} u^{n+1})\n$$\nApplying this to the test equation:\n$$\ny^{n+1} - y^n = \\frac{\\Delta t}{2} (\\lambda y^n + \\lambda y^{n+1})\n$$\nSolving for $y^{n+1}$:\n$$\ny^{n+1} \\left(1 - \\frac{\\Delta t \\lambda}{2}\\right) = y^n \\left(1 + \\frac{\\Delta t \\lambda}{2}\\right)\n$$\n$$\ny^{n+1} = \\frac{1 + \\Delta t \\lambda / 2}{1 - \\Delta t \\lambda / 2} y^n\n$$\nThus, the stability function for Crank-Nicolson is:\n$$\nR_{\\mathrm{CN}}(z) = \\frac{1 + z/2}{1 - z/2}\n$$\n\n**1.3. L-Stability and Connection to Oscillations**\nA scheme is $A$-stable if $|R(z)| \\le 1$ for all $z$ with $\\text{Re}(z) \\le 0$. A scheme is $L$-stable if it is $A$-stable and additionally satisfies $\\lim_{|z| \\to \\infty} |R(z)| = 0$ for $\\text{Re}(z) \\le 0$. This latter condition is critical for damping infinitely stiff modes, which correspond to high-frequency spatial components such as discontinuities.\n- For backward Euler: $\\lim_{|z| \\to \\infty} |R_{\\mathrm{BE}}(z)| = \\lim_{|z| \\to \\infty} \\left|\\frac{1}{1-z}\\right| = 0$. Backward Euler is $L$-stable. It effectively damps stiff components.\n- For Crank-Nicolson: $\\lim_{|z| \\to \\infty} |R_{\\mathrm{CN}}(z)| = \\lim_{|z| \\to \\infty} \\left|\\frac{1+z/2}{1-z/2}\\right| = \\lim_{|z| \\to \\infty} \\left|\\frac{1/z+1/2}{1/z-1/2}\\right| = \\left|\\frac{1/2}{-1/2}\\right| = 1$. Crank-Nicolson is $A$-stable but not $L$-stable. It fails to damp stiff components, which can manifest as persistent, non-physical oscillations in the numerical solution, particularly near sharp gradients.\n\n**1.4. Fourier-Space Propagator**\nThe semi-discrete system $\\partial_t u = \\mathcal{L}u$ is a system of coupled ordinary differential equations (ODEs) for the grid point values $u_j(t)$. By applying a discrete Fourier transform (DFT), this system is diagonalized. Each Fourier mode $\\widehat{u}(\\theta)$ evolves independently according to the ODE:\n$$\n\\frac{d}{dt}\\widehat{u}(\\theta, t) = \\lambda(\\theta)\\,\\widehat{u}(\\theta, t)\n$$\nwhere $\\lambda(\\theta)$ is the eigenvalue of the operator $\\mathcal{L}$ for the mode corresponding to $\\theta = 2\\pi m/N$. This is an instance of the scalar test equation. Therefore, a single time step from $t_n$ to $t_{n+1}$ updates each Fourier coefficient as:\n$$\n\\widehat{u}^{n+1}(\\theta) = R(\\Delta t\\,\\lambda(\\theta))\\,\\widehat{u}^{n}(\\theta)\n$$\nThe one-step Fourier propagator is the array of values $R(\\Delta t\\,\\lambda(\\theta))$ for all discrete modes $\\theta$.\n\n**2. Numerical Implementation and Metrics**\n\nThe algorithm to solve the problem is as follows:\n1.  Set the physical and numerical parameters: $L=2\\pi$, $N=256$. From these, calculate the grid spacing $h=L/N$.\n2.  Define the spatial grid $x_j = j h$ for $j=0, 1, \\dots, N-1$.\n3.  Construct the initial condition array $u_0$, representing the step function on the grid. $u_j(0) = 1$ for $j=0, \\dots, N/2-1$ and $u_j(0)=0$ otherwise.\n4.  Construct the array of dimensionless wavenumbers $\\theta_m = 2\\pi m/N$. For use with `numpy.fft`, the effective mode indices $m$ are ordered as $0, 1, \\dots, N/2-1, -N/2, \\dots, -1$. This is conveniently generated using `np.fft.fftfreq`.\n5.  For each test case $(b, \\kappa, \\Delta t)$:\n    a. Calculate the array of eigenvalues $\\lambda(\\theta)$ for all modes using the given formula:\n    $$\n    \\lambda(\\theta) = -i\\,b\\,\\frac{\\sin(\\theta)}{h} - \\kappa\\,\\frac{4\\sin^2(\\theta/2)}{h^2}\n    $$\n    b. Compute the array $z = \\Delta t\\,\\lambda(\\theta)$.\n    c. Compute the propagator arrays for both schemes: $R_{\\mathrm{BE}}(z)$ and $R_{\\mathrm{CN}}(z)$.\n    d. Compute the DFT of the initial condition: $\\widehat{u}^0 = \\text{DFT}(u_0)$.\n    e. Propagate for one step in Fourier space: $\\widehat{u}^1_{\\mathrm{BE}} = R_{\\mathrm{BE}}(z) \\odot \\widehat{u}^0$ and $\\widehat{u}^1_{\\mathrm{CN}} = R_{\\mathrm{CN}}(z) \\odot \\widehat{u}^0$, where $\\odot$ is element-wise multiplication.\n    f. Compute the solution at time $\\Delta t$ by applying the inverse DFT: $u^1_{\\mathrm{scheme}} = \\text{IDFT}(\\widehat{u}^1_{\\mathrm{scheme}})$. Since the initial data is real, we take the real part of the result to discard negligible imaginary components from numerical round-off.\n    g. Calculate the oscillation metrics:\n        - Undershoot: $\\min(u^1_{\\mathrm{scheme}})$.\n        - Overshoot: $\\max\\{0, \\max(u^1_{\\mathrm{scheme}}) - 1\\}$.\n    h. Calculate the stiff-mode amplification at the Nyquist frequency, $G_{\\mathrm{nyq}}$. The Nyquist mode corresponds to $\\theta = \\pi$. The eigenvalue is purely real and diffusive:\n    $$\n    \\lambda(\\pi) = -i\\,b\\,\\frac{\\sin(\\pi)}{h} - \\kappa\\,\\frac{4\\sin^2(\\pi/2)}{h^2} = - \\frac{4\\kappa}{h^2}\n    $$\n    Let $z_{\\mathrm{nyq}} = \\Delta t \\lambda(\\pi) = -4\\kappa\\Delta t/h^2$. Then:\n    $$\n    G_{\\mathrm{nyq}}^{\\mathrm{BE}} = |R_{\\mathrm{BE}}(z_{\\mathrm{nyq}})| = \\left|\\frac{1}{1 - z_{\\mathrm{nyq}}}\\right|\n    $$\n    $$\n    G_{\\mathrm{nyq}}^{\\mathrm{CN}} = |R_{\\mathrm{CN}}(z_{\\mathrm{nyq}})| = \\left|\\frac{1 + z_{\\mathrm{nyq}}/2}{1 - z_{\\mathrm{nyq}}/2}\\right|\n    $$\n6.  Collect the six specified floating-point numbers for each test case and format the final output as a list of lists.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of comparing backward Euler and Crank-Nicolson schemes\n    for a convection-diffusion equation, focusing on stability and oscillations.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (stiff diffusion, no convection)\n        (0.0, 100.0, 0.5),\n        # Case 2 (stiff diffusion with convection)\n        (3.0, 100.0, 0.5),\n        # Case 3 (moderately diffusive, small time step)\n        (0.0, 1.0, 1e-4),\n    ]\n\n    # Global parameters\n    L = 2.0 * np.pi\n    N = 256\n    h = L / N\n\n    # Spatial grid and initial condition\n    x = np.arange(N) * h\n    u0 = np.zeros(N)\n    # The condition is u(x,0)=1 for 0 = x  L/2.\n    # On the grid x_j = j*h, this means j*h  L/2 = j  L/(2*h) = N/2.\n    # Indices are 0, 1, ..., N/2 - 1.\n    u0[0:N//2] = 1.0\n\n    # Fourier space setup\n    # theta = 2*pi*m/N, where m are the DFT mode numbers\n    # np.fft.fftfreq(N) gives m/N for the standard FFT ordering\n    theta = 2.0 * np.pi * np.fft.fftfreq(N)\n    u0_hat = np.fft.fft(u0)\n    \n    results = []\n    for b, kappa, dt in test_cases:\n        # 1. Compute eigenvalues and stability function arguments\n        # Eigenvalue of the semi-discrete operator for each mode theta\n        # lambda(theta) = -i*b*sin(theta)/h - kappa*4*sin^2(theta/2)/h^2\n        # Use 2*(1-cos(theta)) for 4*sin^2(theta/2) to avoid creating theta/2 array\n        lambda_theta = (-1j * b * np.sin(theta) / h\n                        - kappa * 2.0 * (1.0 - np.cos(theta)) / h**2)\n        \n        # Stability function argument z = dt * lambda\n        z = dt * lambda_theta\n\n        # 2. Compute the one-step Fourier propagators (R(z))\n        # Backward Euler: R_BE(z) = 1 / (1 - z)\n        R_BE = 1.0 / (1.0 - z)\n        # Crank-Nicolson: R_CN(z) = (1 + z/2) / (1 - z/2)\n        R_CN = (1.0 + 0.5 * z) / (1.0 - 0.5 * z)\n\n        # 3. Propagate one step in Fourier space\n        u1_hat_BE = R_BE * u0_hat\n        u1_hat_CN = R_CN * u0_hat\n\n        # 4. Transform back to physical space and take the real part\n        u1_BE = np.real(np.fft.ifft(u1_hat_BE))\n        u1_CN = np.real(np.fft.ifft(u1_hat_CN))\n\n        # 5. Measure undershoot and overshoot amplitudes\n        # Undershoot is defined as the minimum value of u\n        min_u_cn = np.min(u1_CN)\n        min_u_be = np.min(u1_BE)\n        \n        # Overshoot is defined as max{u-1, 0}\n        overshoot_cn = np.max([np.max(u1_CN) - 1.0, 0.0])\n        overshoot_be = np.max([np.max(u1_BE) - 1.0, 0.0])\n\n        # 6. Compute stiff-mode amplification at Nyquist mode (theta=pi)\n        # lambda_nyq = -4*kappa/h^2, since sin(pi)=0 and sin(pi/2)=1\n        lambda_nyq = -4.0 * kappa / h**2\n        z_nyq = dt * lambda_nyq\n        \n        # G_nyq for BE\n        g_nyq_be = np.abs(1.0 / (1.0 - z_nyq))\n        \n        # G_nyq for CN\n        g_nyq_cn = np.abs((1.0 + 0.5 * z_nyq) / (1.0 - 0.5 * z_nyq))\n\n        # 7. Collect results for the current case\n        case_results = [\n            min_u_cn,\n            min_u_be,\n            overshoot_cn,\n            overshoot_be,\n            g_nyq_cn,\n            g_nyq_be\n        ]\n        results.append(case_results)\n\n    # Final print statement in the exact required format.\n    # Create '[a,b,c],[d,e,f]' string\n    formatted_results = [f\"[{','.join(map(str, res))}]\" for res in results]\n    # Enclose in outer '[]'\n    final_output = f\"[{','.join(formatted_results)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3360288"}, {"introduction": "The challenges of stiffness and the importance of L-stability are not confined to linear equations; they are often even more critical in nonlinear systems, such as those arising in chemical kinetics or reaction-diffusion problems. This exercise extends our investigation to a stiff nonlinear scalar ODE. You will discover that implicit methods necessitate the use of nonlinear solvers, such as Newton's method, and see firsthand how a method that is not L-stable (Implicit Midpoint) can produce non-physical overshoots, while an L-stable method (Backward Euler) provides a qualitatively correct, robust solution. [@problem_id:3360266]", "problem": "Consider the scalar initial value problem arising from a semidiscrete reaction term in a partial differential equation, posed abstractly as\n$$\n\\frac{du}{dt} = -p\\big(u + f(u)\\big), \\qquad f(u)=u^p, \\qquad p1,\\qquad u(0)=1,\n$$\nwhere $p$ is a dimensionless stiffness parameter as well as the nonlinearity exponent. The exact solution for $u(t)$ remains nonnegative and monotonically decaying to the stable equilibrium $u^\\star=0$. You will study the qualitative behavior of two implicit, one-step time integrators applied to this problem:\n- Backward Euler (an $L$-stable method),\n- Implicit Midpoint, also known as Crank–Nicolson for ordinary differential equations (an $A$-stable but not $L$-stable method).\n\nYou must start from the following foundational bases:\n- Definitions of $A$-stability and $L$-stability in terms of the linear test equation $\\frac{dy}{dt}=\\lambda y$ and the associated linear stability function for a time integrator, without assuming any specific formula beforehand.\n- The concept that for stiff problems, local linearization of a nonlinear right-hand side around the current state can faithfully capture stiff decay in the limit of large stiffness, and that this reduces analysis locally to the linear test equation with a large negative real parameter.\n\nYou will not be given any method-specific stability formula in the problem statement. Instead, you must reason from first principles and implement both methods directly on the nonlinear problem using their defining implicit update equations.\n\nFor a time step size $h0$ and a current value $u_n$, the two methods are defined by the implicit equations for $u_{n+1}$:\n- Backward Euler: find $u_{n+1}$ such that\n$$\nu_{n+1} = u_n + h\\Big(-p\\big(u_{n+1} + u_{n+1}^p\\big)\\Big).\n$$\n- Implicit Midpoint: find $u_{n+1}$ such that\n$$\nu_{n+1} = u_n + h\\Big(-p\\big(\\tfrac{1}{2}(u_n+u_{n+1}) + \\big(\\tfrac{1}{2}(u_n+u_{n+1})\\big)^p\\big)\\Big).\n$$\n\nDefine the overshoot indicator for a given method and parameter set as follows: simulate $N$ steps starting from $u_0=1$ and declare “overshoot” if at any step the numerical solution becomes negative, that is, if $\\min_{0\\leq n\\leq N} u_n  0$. This indicator is a boolean that you must report as an integer, where $1$ means “overshoot occurred” and $0$ means “no overshoot occurred.”\n\nDesign and implement a robust nonlinear solver for the above implicit equations per step that guarantees convergence to the physically relevant solution branch. Do not make any assumptions that bypass solving the nonlinear equations.\n\nTest Suite. Use the following parameter sets $(p, h, N)$:\n- Test $1$: $p=10$, $h=0.5$, $N=3$.\n- Test $2$: $p=10$, $h=0.05$, $N=20$.\n- Test $3$: $p=100$, $h=0.1$, $N=3$.\n- Test $4$: $p=2$, $h=0.9$, $N=3$.\n- Test $5$: $p=1000$, $h=0.01$, $N=3$.\n\nYour program must output a single line containing a comma-separated list enclosed in square brackets with the overshoot indicators, flattened in the order “Implicit Midpoint then Backward Euler” for each test, i.e.,\n$$\n[\\mathrm{IM}_1,\\mathrm{BE}_1,\\mathrm{IM}_2,\\mathrm{BE}_2,\\mathrm{IM}_3,\\mathrm{BE}_3,\\mathrm{IM}_4,\\mathrm{BE}_4,\\mathrm{IM}_5,\\mathrm{BE}_5],\n$$\nwhere each entry is either $0$ or $1$. No additional text should be printed. All quantities are dimensionless, so no physical units are required or permitted in the output. The angle unit is not applicable. Percentages are not used; any fractional quantities must be represented as decimal numbers in intermediate computations, but the final reported indicators are integers in $\\{0,1\\}$.\n\nYour solution must justify, from first principles, why an $L$-stable method avoids overshoot whereas a merely $A$-stable method can exhibit overshoot as $p\\to\\infty$, and how the provided numerical experiment operationalizes this distinction without relying on any shortcut formulas.", "solution": "The problem is scientifically valid and presents a well-posed numerical experiment to contrast the qualitative behavior of A-stable and L-stable methods on a stiff nonlinear ODE.\n\n**Theoretical Justification from First Principles**\n\nThe core of the problem lies in the distinction between A-stability and L-stability. These concepts are defined for the linear test equation $y' = \\lambda y$. A one-step method gives $y_{n+1} = R(z) y_n$ where $z=h\\lambda$.\n\n1.  **Backward Euler (BE)** is defined by $y_{n+1} = y_n + h \\lambda y_{n+1}$. Its stability function is $R_{\\text{BE}}(z) = \\frac{1}{1-z}$.\n    *   **A-stability**: For $\\text{Re}(z) \\le 0$, $|R_{\\text{BE}}(z)| \\le 1$. The method is A-stable.\n    *   **L-stability**: As $z \\to -\\infty$, $R_{\\text{BE}}(z) \\to 0$. The method is L-stable. This means for very stiff components (large negative $\\lambda$), the solution is damped to zero.\n\n2.  **Implicit Midpoint (IM)** is defined by $y_{n+1} = y_n + h \\lambda \\frac{y_n+y_{n+1}}{2}$. Its stability function is $R_{\\text{IM}}(z) = \\frac{1+z/2}{1-z/2}$.\n    *   **A-stability**: For $\\text{Re}(z) \\le 0$, $|R_{\\text{IM}}(z)| \\le 1$. The method is A-stable.\n    *   **L-stability**: As $z \\to -\\infty$, $R_{\\text{IM}}(z) \\to -1$. The method is **not** L-stable. For very stiff components, the solution flips its sign without decaying in magnitude, i.e., $y_{n+1} \\approx -y_n$.\n\nFor the nonlinear problem $\\frac{du}{dt} = F(u)$, where $F(u) = -p(u+u^p)$, stiffness arises for large $p$. The local behavior is approximated by linearizing around the current state, which connects to the test equation with $\\lambda \\approx F'(u)$. For large $p$ and non-infinitesimal $h$, the term $z=h\\lambda$ can be large and negative, activating the behavior seen in the L-stability analysis.\n\n-   The L-stable **Backward Euler** method damps the stiff dynamics, driving the solution smoothly towards the equilibrium at $u=0$.\n-   The A-stable but not L-stable **Implicit Midpoint** method responds to the stiff dynamics by flipping the solution's sign, causing a non-physical overshoot to negative values.\n\nWe can prove this rigorously for the given problem. At each step, we must solve a nonlinear equation $G(u_{n+1})=0$ for $u_{n+1}$. An overshoot occurs if $u_{n+1}  0$ when $u_n > 0$.\n\n-   **For BE**, the equation is $G_{\\text{BE}}(x) = x - u_n + hp(x+x^p) = 0$. For $x \\ge 0$, the function is monotonic increasing, and $G_{\\text{BE}}(0) = -u_n \\le 0$. Thus, the root must be non-negative. BE cannot overshoot.\n\n-   **For IM**, the equation is $G_{\\text{IM}}(x) = x - u_n + hp\\left(\\frac{u_n+x}{2} + \\left(\\frac{u_n+x}{2}\\right)^p\\right) = 0$. This function is also monotonic for $x$ in the region of interest. An overshoot in the first step ($u_0=1$) will happen if the root is negative, which occurs if $G_{\\text{IM}}(0) > 0$.\n    $$G_{\\text{IM}}(0) = -1 + hp\\left(\\frac{1}{2} + \\left(\\frac{1}{2}\\right)^p\\right)$$\n    The condition for overshoot is $hp\\left(1/2 + 2^{-p}\\right) > 1$. For large $p$, this approaches $hp > 2$. This condition is met for tests 1, 3, 4, and 5, but not for test 2.\n\n**Numerical Implementation**\n\nA robust nonlinear solver is required for the implicit equations at each step. Newton's method is a suitable choice. For a given method, we define the residual function $G(x)$ and its Jacobian $G'(x)$ and iterate to find the root $x=u_{n+1}$. The integer values of $p$ in the test suite ensure that terms like $x^p$ are well-defined even if $x$ becomes negative. The simulation for each test case checks at every step if the computed solution is negative to determine the overshoot indicator. The provided code implements this logic.", "answer": "```python\nimport numpy as np\n\ndef newton_solver(g, g_prime, x0, tol=1e-12, max_iter=50):\n    \"\"\"\n    Solves the scalar nonlinear equation g(x) = 0 using Newton's method.\n    \"\"\"\n    x = float(x0)\n    for _ in range(max_iter):\n        try:\n            gx = g(x)\n            if abs(gx)  tol:\n                return x\n            gpx = g_prime(x)\n        except (ValueError, OverflowError):\n            # Handles cases like non-integer power of a negative number or overflow\n            return float('nan')\n\n        if gpx == 0:\n            return float('nan')\n        \n        x = x - gx / gpx\n    return x\n\ndef run_simulation(method, p, h, N):\n    \"\"\"\n    Runs a time integration for N steps and reports if overshoot occurs.\n    \n    Returns:\n        1 if overshoot occurred, 0 otherwise.\n    \"\"\"\n    u = 1.0\n    for _ in range(N):\n        u_n = u\n        \n        # Define the residual and Jacobian functions for the nonlinear solver\n        if method == 'BE':\n            # Residual G(x) = x - u_n - h * F(x), where F(x) = -p*(x+x^p)\n            g = lambda x: x * (1.0 + h * p) + h * p * np.power(x, p) - u_n\n            # Jacobian G'(x) = 1 - h * F'(x), where F'(x) = -p*(1+p*x^(p-1))\n            g_prime = lambda x: 1.0 + h * p * (1.0 + p * np.power(x, p - 1))\n        \n        elif method == 'IM':\n            # Residual G(x) = x - u_n - h * F((u_n+x)/2)\n            def g(x):\n                mid = (u_n + x) / 2.0\n                return x - u_n + h * p * (mid + np.power(mid, p))\n            \n            # Jacobian G'(x) = 1 - (h/2) * F'((u_n+x)/2)\n            def g_prime(x):\n                mid = (u_n + x) / 2.0\n                return 1.0 + h * p * (0.5 + 0.5 * p * np.power(mid, p - 1))\n        \n        else:\n            raise ValueError(\"Unknown method specified.\")\n            \n        u_next = newton_solver(g, g_prime, u_n)\n        \n        # Check for overshoot or solver failure\n        if not np.isfinite(u_next) or u_next  0:\n            return 1\n        \n        u = u_next\n           \n    return 0\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results in the specified format.\n    \"\"\"\n    test_cases = [\n        (10, 0.5, 3),    # Test 1\n        (10, 0.05, 20),  # Test 2\n        (100, 0.1, 3),   # Test 3\n        (2, 0.9, 3),     # Test 4\n        (1000, 0.01, 3), # Test 5\n    ]\n\n    results = []\n    for p, h, N in test_cases:\n        # Implicit Midpoint simulation\n        im_res = run_simulation('IM', float(p), float(h), N)\n        results.append(im_res)\n        \n        # Backward Euler simulation\n        be_res = run_simulation('BE', float(p), float(h), N)\n        results.append(be_res)\n        \n    # Format and print the final output as a single comma-separated list\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3360266"}]}