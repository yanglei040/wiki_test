{"hands_on_practices": [{"introduction": "The definition of a symplectic map, $D\\Psi_h(y)^{\\top} J D\\Psi_h(y) = J$, is the mathematical foundation of this entire topic. This first exercise provides a direct, hands-on opportunity to work with this definition by applying it to the explicit Euler method for a simple harmonic oscillator. By calculating the \"symplecticity defect,\" you will see precisely why this common integrator fails to preserve the geometric structure of a Hamiltonian system. [@problem_id:3451935]", "problem": "Consider a canonical Hamiltonian system in two dimensions with phase vector $y = (q,p)^{\\top}$ and the standard symplectic matrix $J = \\begin{pmatrix} 0  1 \\\\ -1  0 \\end{pmatrix}$. A one-step method with step size $h$, denoted $\\Psi_h: \\mathbb{R}^2 \\to \\mathbb{R}^2$, is called symplectic if its Jacobian satisfies the Jacobian constraint $D\\Psi_h(y)^{\\top} J D\\Psi_h(y) = J$ for all $y$. Starting from Hamilton's canonical equations for the separable quadratic Hamiltonian $H(q,p) = \\tfrac{1}{2}(p^2 + q^2)$, derive the explicit Euler one-step map $\\Psi_h$ and its Jacobian. Then, using only the definition of symplecticity and basic linear algebra, show that there is a scalar factor $\\lambda(h)$ such that $D\\Psi_h(y)^{\\top} J D\\Psi_h(y) = \\lambda(h)\\, J$ for this method. Compute $\\lambda(h)$ in closed form as a symbolic expression in $h$, and use it to determine whether the explicit Euler method satisfies the symplecticity constraint for nonzero $h$. Provide your final answer as the single symbolic expression $\\lambda(h)$ with no units. No numerical rounding is required.", "solution": "The problem statement is critically evaluated for validity.\n\n**Step 1: Extract Givens**\n- **System:** A canonical Hamiltonian system in two dimensions.\n- **Phase Vector:** $y = (q,p)^{\\top}$.\n- **Symplectic Matrix:** $J = \\begin{pmatrix} 0  1 \\\\ -1  0 \\end{pmatrix}$.\n- **One-Step Method:** $\\Psi_h: \\mathbb{R}^2 \\to \\mathbb{R}^2$ with step size $h$.\n- **Symplecticity Condition:** A method is symplectic if its Jacobian $D\\Psi_h(y)$ satisfies $D\\Psi_h(y)^{\\top} J D\\Psi_h(y) = J$ for all $y$.\n- **Hamiltonian:** $H(q,p) = \\frac{1}{2}(p^2 + q^2)$.\n- **Method to Analyze:** The explicit Euler method.\n- **Tasks:**\n    1. Derive the explicit Euler one-step map $\\Psi_h$ and its Jacobian $D\\Psi_h(y)$.\n    2. Show that $D\\Psi_h(y)^{\\top} J D\\Psi_h(y) = \\lambda(h) J$ for some scalar $\\lambda(h)$.\n    3. Compute a closed-form expression for $\\lambda(h)$.\n    4. Use $\\lambda(h)$ to determine if the explicit Euler method is symplectic for $h \\neq 0$.\n- **Final Answer Requirement:** Provide the single symbolic expression for $\\lambda(h)$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding:** The problem is firmly grounded in the fields of classical mechanics (Hamiltonian systems) and numerical analysis (numerical solution of ordinary differential equations, specifically geometric integration). The Hamiltonian for a simple harmonic oscillator, the explicit Euler method, and the definition of a symplectic map are all standard and well-established concepts.\n- **Well-Posedness:** The problem is well-posed. It provides a specific Hamiltonian and a specific numerical integrator, and asks for a clear, derivable mathematical property (the value of $\\lambda(h)$). All necessary information is present to arrive at a unique solution.\n- **Objectivity:** The problem is stated in precise, objective mathematical language, free from any subjective claims.\n\n**Step 3: Verdict and Action**\nThe problem is scientifically sound, well-posed, objective, and self-contained. It is a valid exercise in numerical analysis. Therefore, a solution will be derived.\n\nThe first step is to derive the system of ordinary differential equations from the given Hamiltonian $H(q,p) = \\frac{1}{2}(p^2 + q^2)$ using Hamilton's canonical equations:\n$$\n\\dot{q} = \\frac{\\partial H}{\\partial p} \\\\\n\\dot{p} = -\\frac{\\partial H}{\\partial q}\n$$\nCalculating the partial derivatives of $H$:\n$$\n\\frac{\\partial H}{\\partial p} = p \\\\\n\\frac{\\partial H}{\\partial q} = q\n$$\nSubstituting these into Hamilton's equations yields the system:\n$$\n\\dot{q} = p \\\\\n\\dot{p} = -q\n$$\nIn vector form, with $y = (q,p)^{\\top}$, this system can be written as $\\dot{y} = f(y)$, where $f(y) = \\begin{pmatrix} p \\\\ -q \\end{pmatrix}$.\n\nNext, we apply the explicit Euler method to this system. The explicit Euler method for an initial value problem $\\dot{y} = f(y)$ is given by the recurrence relation $y_{n+1} = y_n + h f(y_n)$, where $h$ is the step size. The one-step map $\\Psi_h$ is defined by $y_{n+1} = \\Psi_h(y_n)$. Let $y = (q,p)^{\\top}$. The map $\\Psi_h$ is therefore:\n$$\n\\Psi_h(y) = y + h f(y) = \\begin{pmatrix} q \\\\ p \\end{pmatrix} + h \\begin{pmatrix} p \\\\ -q \\end{pmatrix} = \\begin{pmatrix} q + hp \\\\ p - hq \\end{pmatrix}\n$$\nThis is the explicit form of the one-step map for the explicit Euler method applied to the given Hamiltonian system.\n\nThe next step is to compute the Jacobian matrix of this map, $D\\Psi_h(y)$. The components of $\\Psi_h(y)$ are $\\Psi_{h,1}(q,p) = q + hp$ and $\\Psi_{h,2}(q,p) = p - hq$. The Jacobian is:\n$$\nD\\Psi_h(y) = \\begin{pmatrix} \\frac{\\partial \\Psi_{h,1}}{\\partial q}  \\frac{\\partial \\Psi_{h,1}}{\\partial p} \\\\ \\frac{\\partial \\Psi_{h,2}}{\\partial q}  \\frac{\\partial \\Psi_{h,2}}{\\partial p} \\end{pmatrix}\n$$\nComputing the partial derivatives:\n$$\n\\frac{\\partial}{\\partial q}(q + hp) = 1 \\\\\n\\frac{\\partial}{\\partial p}(q + hp) = h \\\\\n\\frac{\\partial}{\\partial q}(p - hq) = -h \\\\\n\\frac{\\partial}{\\partial p}(p - hq) = 1\n$$\nThus, the Jacobian matrix is constant and given by:\n$$\nD\\Psi_h(y) = M = \\begin{pmatrix} 1  h \\\\ -h  1 \\end{pmatrix}\n$$\nTo check for symplecticity, we must compute the product $M^{\\top} J M$. The transpose of $M$ is:\n$$\nM^{\\top} = \\begin{pmatrix} 1  -h \\\\ h  1 \\end{pmatrix}\n$$\nNow, we perform the matrix multiplication. First, we compute $M^{\\top}J$:\n$$\nM^{\\top}J = \\begin{pmatrix} 1  -h \\\\ h  1 \\end{pmatrix} \\begin{pmatrix} 0  1 \\\\ -1  0 \\end{pmatrix} = \\begin{pmatrix} (1)(0) + (-h)(-1)  (1)(1) + (-h)(0) \\\\ (h)(0) + (1)(-1)  (h)(1) + (1)(0) \\end{pmatrix} = \\begin{pmatrix} h  1 \\\\ -1  h \\end{pmatrix}\n$$\nNext, we multiply this result by $M$:\n$$\n(M^{\\top}J)M = \\begin{pmatrix} h  1 \\\\ -1  h \\end{pmatrix} \\begin{pmatrix} 1  h \\\\ -h  1 \\end{pmatrix} = \\begin{pmatrix} (h)(1) + (1)(-h)  (h)(h) + (1)(1) \\\\ (-1)(1) + (h)(-h)  (-1)(h) + (h)(1) \\end{pmatrix}\n$$\nSimplifying the entries gives:\n$$\nM^{\\top} J M = \\begin{pmatrix} h - h  h^2 + 1 \\\\ -1 - h^2  -h + h \\end{pmatrix} = \\begin{pmatrix} 0  1+h^2 \\\\ -(1+h^2)  0 \\end{pmatrix}\n$$\nWe can factor out the scalar term $(1+h^2)$:\n$$\n\\begin{pmatrix} 0  1+h^2 \\\\ -(1+h^2)  0 \\end{pmatrix} = (1+h^2) \\begin{pmatrix} 0  1 \\\\ -1  0 \\end{pmatrix} = (1+h^2)J\n$$\nThis result is of the form $\\lambda(h)J$, where the scalar factor is $\\lambda(h) = 1+h^2$.\n\nThe condition for a method to be symplectic is that its Jacobian $M$ must satisfy $M^{\\top} J M = J$. In our case, this requires $\\lambda(h) = 1$.\nSetting our derived expression for $\\lambda(h)$ equal to $1$:\n$$\n1+h^2 = 1\n$$\nThis implies $h^2 = 0$, which is only true for $h=0$. For any non-zero step size $h \\neq 0$, we have $h^2  0$, and thus $\\lambda(h) = 1+h^2  1$. Therefore, the explicit Euler method is not symplectic for this system for any non-zero step size. The problem asks for the closed-form symbolic expression for $\\lambda(h)$.\n\nThe derived expression is $\\lambda(h) = 1+h^2$.", "answer": "$$\n\\boxed{1+h^2}\n$$", "id": "3451935"}, {"introduction": "A key motivation for using symplectic integrators is their superior long-term stability, which is essential when simulating wave phenomena. This exercise connects the abstract concept of a symplectic integrator to the practical stability constraints familiar from numerical PDEs. You will perform a von Neumann stability analysis on the symplectic leapfrog (Störmer–Verlet) method applied to a semi-discretized wave equation to derive its Courant–Friedrichs–Lewy (CFL) condition. [@problem_id:3451899]", "problem": "Consider the semi-discrete wave equation obtained, for example, from a mass-lumped finite element spatial discretization of a linear wave model,\n$$\n\\frac{\\mathrm{d}^{2}}{\\mathrm{d}t^{2}} u(t) + A\\,u(t) = 0,\n$$\nwhere $u(t) \\in \\mathbb{R}^{N}$, $A \\in \\mathbb{R}^{N \\times N}$ is real symmetric positive semidefinite, and its spectral radius is $\\rho(A) = \\max\\{ \\lambda : \\lambda \\text{ is an eigenvalue of } A \\}$. Assume that the mass matrix is the identity so that the kinetic energy is given by the Euclidean norm. The Hamiltonian is\n$$\nH(u,v) = \\frac{1}{2}\\|v\\|^{2} + \\frac{1}{2} u^{\\top} A u,\n$$\nwith $v(t) = \\frac{\\mathrm{d}}{\\mathrm{d}t}u(t)$.\n\nApply the symplectic leapfrog (also called Störmer–Verlet) time integrator with a constant timestep $\\Delta t  0$ to this system, defined by\n$$\nv^{n+\\frac{1}{2}} = v^{n-\\frac{1}{2}} - \\Delta t\\,A\\,u^{n}, \\qquad\nu^{n+1} = u^{n} + \\Delta t\\,v^{n+\\frac{1}{2}},\n$$\nfor integer $n \\ge 0$. Using only fundamental principles of modal decomposition and linear stability analysis, derive a Courant–Friedrichs–Lewy (CFL) type stability condition on $\\Delta t$ ensuring that the method is linearly stable for all modes associated with $A$. Express the maximal allowable timestep as a single closed-form analytic expression in terms of $\\rho(A)$. The final answer must be a single analytic expression; do not include any units.", "solution": "The problem requires the derivation of a Courant–Friedrichs–Lewy (CFL) type stability condition for the symplectic leapfrog (Störmer–Verlet) method applied to the semi-discrete wave equation $\\frac{\\mathrm{d}^{2}}{\\mathrm{d}t^{2}} u(t) + A\\,u(t) = 0$. The analysis will be based on modal decomposition.\n\nThe leapfrog method is given by the pair of equations:\n$$\nv^{n+\\frac{1}{2}} = v^{n-\\frac{1}{2}} - \\Delta t\\,A\\,u^{n}\n$$\n$$\nu^{n+1} = u^{n} + \\Delta t\\,v^{n+\\frac{1}{2}}\n$$\nTo facilitate the stability analysis, we first combine these two equations into a single three-term recurrence relation for $u^{n}$. From the second equation, we can express $v^{n+\\frac{1}{2}}$ as:\n$$\nv^{n+\\frac{1}{2}} = \\frac{u^{n+1} - u^{n}}{\\Delta t}\n$$\nSimilarly, for the previous time step, we have:\n$$\nv^{n-\\frac{1}{2}} = \\frac{u^{n} - u^{n-1}}{\\Delta t}\n$$\nSubstituting these expressions for $v^{n+\\frac{1}{2}}$ and $v^{n-\\frac{1}{2}}$ into the first leapfrog equation yields:\n$$\n\\frac{u^{n+1} - u^{n}}{\\Delta t} = \\frac{u^{n} - u^{n-1}}{\\Delta t} - \\Delta t\\,A\\,u^{n}\n$$\nMultiplying by $\\Delta t$ and rearranging the terms, we obtain the explicit three-level scheme for $u$:\n$$\nu^{n+1} - 2u^{n} + u^{n-1} = -(\\Delta t)^{2} A u^{n}\n$$\nThis equation can be rewritten as:\n$$\nu^{n+1} = (2I - (\\Delta t)^{2} A)u^{n} - u^{n-1}\n$$\nwhere $I$ is the identity matrix in $\\mathbb{R}^{N \\times N}$.\n\nThe stability of this vector recurrence is determined by the stability of its independent modes. The matrix $A$ is given as real, symmetric, and positive semi-definite. Therefore, it admits a complete set of orthonormal eigenvectors. Let $Q$ be the orthogonal matrix whose columns are the eigenvectors of $A$, and let $\\Lambda$ be the diagonal matrix of the corresponding eigenvalues $\\lambda_k \\ge 0$ for $k=1, \\dots, N$. We can write the spectral decomposition of $A$ as $A = Q \\Lambda Q^{\\top}$.\n\nWe perform a change of basis to the modal coordinates by defining $\\hat{u}^{n} = Q^{\\top}u^{n}$. Substituting $u^{n} = Q\\hat{u}^{n}$ into the recurrence relation gives:\n$$\nQ\\hat{u}^{n+1} - 2Q\\hat{u}^{n} + Q\\hat{u}^{n-1} = -(\\Delta t)^{2} (Q \\Lambda Q^{\\top}) (Q\\hat{u}^{n})\n$$\nMultiplying from the left by $Q^{\\top}$ and using the property $Q^{\\top}Q=I$, we get:\n$$\n\\hat{u}^{n+1} - 2\\hat{u}^{n} + \\hat{u}^{n-1} = -(\\Delta t)^{2} \\Lambda \\hat{u}^{n}\n$$\nThis vector equation decouples into $N$ independent scalar equations, one for each modal component $\\hat{u}_{k}^{n}$ corresponding to the eigenvalue $\\lambda_k$:\n$$\n\\hat{u}_{k}^{n+1} - 2\\hat{u}_{k}^{n} + \\hat{u}_{k}^{n-1} = -(\\Delta t)^{2} \\lambda_k \\hat{u}_{k}^{n}\n$$\nTo analyze the stability of this scalar recurrence, we use the von Neumann method, seeking a solution of the form $\\hat{u}_{k}^{n} = g^{n} \\hat{u}_{k}^{0}$, where $g$ is the amplification factor. Substituting this ansatz into the equation, we obtain:\n$$\ng^{n+1}\\hat{u}_{k}^{0} - 2g^{n}\\hat{u}_{k}^{0} + g^{n-1}\\hat{u}_{k}^{0} = -(\\Delta t)^{2} \\lambda_k g^{n}\\hat{u}_{k}^{0}\n$$\nAssuming a non-trivial initial condition ($\\hat{u}_{k}^{0} \\ne 0$) and dividing by $g^{n-1}$, we arrive at the characteristic equation for the amplification factor $g$:\n$$\ng^2 - 2g + 1 = -(\\Delta t)^{2} \\lambda_k g\n$$\n$$\ng^2 - \\left(2 - (\\Delta t)^{2} \\lambda_k\\right) g + 1 = 0\n$$\nFor the numerical solution to remain bounded (i.e., for the method to be linearly stable), the magnitude of the roots $g$ of this quadratic equation must be less than or equal to one: $|g| \\le 1$. The product of the roots of a quadratic equation $ax^2+bx+c=0$ is $c/a$. In our case, the product of the two roots is $1$. If one root $g_1$ has magnitude $|g_1|  1$, then the other root $g_2 = 1/g_1$ must have magnitude $|g_2|  1$. The presence of a root with magnitude greater than one would lead to exponential growth of the corresponding mode, causing instability. Therefore, for stability, both roots must have a magnitude of exactly one, i.e., $|g|=1$.\n\nThe roots of a quadratic equation with real coefficients have magnitude one if and only if they are a complex conjugate pair lying on the unit circle. This occurs when the discriminant of the quadratic equation is non-positive. The discriminant $D$ is:\n$$\nD = \\left(2 - (\\Delta t)^{2} \\lambda_k\\right)^{2} - 4(1)(1)\n$$\nThe stability condition is $D \\le 0$:\n$$\n\\left(2 - (\\Delta t)^{2} \\lambda_k\\right)^{2} - 4 \\le 0\n$$\n$$\n\\left(2 - (\\Delta t)^{2} \\lambda_k\\right)^{2} \\le 4\n$$\nTaking the square root of both sides gives:\n$$\n|2 - (\\Delta t)^{2} \\lambda_k| \\le 2\n$$\nThis single inequality is equivalent to the pair of inequalities:\n$$\n-2 \\le 2 - (\\Delta t)^{2} \\lambda_k \\le 2\n$$\nLet us analyze each inequality separately.\n$1$. The right-hand inequality: $2 - (\\Delta t)^{2} \\lambda_k \\le 2 \\implies -(\\Delta t)^{2} \\lambda_k \\le 0$. Since $\\Delta t  0$ and $A$ is positive semi-definite, its eigenvalues are non-negative, $\\lambda_k \\ge 0$. Thus, $(\\Delta t)^{2} \\lambda_k \\ge 0$, and this inequality is always satisfied.\n$2$. The left-hand inequality: $-2 \\le 2 - (\\Delta t)^{2} \\lambda_k \\implies (\\Delta t)^{2} \\lambda_k \\le 4$.\n\nThis condition, $(\\Delta t)^{2} \\lambda_k \\le 4$, must hold for all modes, i.e., for all eigenvalues $\\lambda_k$ of $A$. To ensure stability for the entire system, the timestep $\\Delta t$ must satisfy the most restrictive of these conditions. The most restrictive case corresponds to the largest possible value of $\\lambda_k$. The largest eigenvalue of $A$ is its spectral radius, $\\rho(A) = \\max_k \\{ \\lambda_k \\}$.\nTherefore, the stability condition for the entire system is:\n$$\n(\\Delta t)^{2} \\rho(A) \\le 4\n$$\nIf $\\rho(A) = 0$, then $A$ must be the zero matrix (since it is positive semi-definite), and the condition is trivially satisfied for any $\\Delta t$. If $\\rho(A)  0$, we can solve for $\\Delta t$:\n$$\n(\\Delta t)^{2} \\le \\frac{4}{\\rho(A)}\n$$\nSince $\\Delta t  0$, we take the positive square root:\n$$\n\\Delta t \\le \\frac{2}{\\sqrt{\\rho(A)}}\n$$\nThe problem asks for the maximal allowable timestep, which corresponds to the equality in the above condition. This is the CFL-type stability limit for the leapfrog method applied to this system.\n$$\n\\Delta t_{\\text{max}} = \\frac{2}{\\sqrt{\\rho(A)}}\n$$", "answer": "$$\n\\boxed{\\frac{2}{\\sqrt{\\rho(A)}}}\n$$", "id": "3451899"}, {"introduction": "Analytical proofs establish the properties of an integrator, but computational verification is a crucial skill for numerical scientists to debug implementations and build confidence in their code. This practice guides you through the process of creating a numerical diagnostic test for symplecticity. By approximating the Jacobian matrix with finite differences, you will compute a quantitative measure of the \"symplecticity error\" for various schemes, empirically confirming the theoretical differences between symplectic and non-symplectic methods. [@problem_id:3451938]", "problem": "Consider a semi-discretization in space of a one-dimensional linear wave equation on a periodic grid with $N$ nodes, resulting in a finite-dimensional Hamiltonian system with state $y = (q, p) \\in \\mathbb{R}^{2N}$ governed by canonical equations $y'(t) = J \\nabla H(y(t))$, where $J = \\begin{bmatrix} 0  I \\\\ -I  0 \\end{bmatrix}$ is the canonical symplectic matrix of size $2N \\times 2N$, $I$ is the identity matrix of size $N \\times N$, and $H(q,p) = T(p) + V(q)$ with $T(p) = \\tfrac{1}{2} \\sum_{i=1}^{N} p_i^2$ and $V(q) = -\\tfrac{1}{2} c^2 q^\\top L q$. The matrix $L \\in \\mathbb{R}^{N \\times N}$ is the standard second-difference periodic Laplacian such that $(L q)_i = q_{i+1} - 2 q_i + q_{i-1}$ with indices interpreted modulo $N$, and $c \\in \\mathbb{R}$ is a positive wave speed parameter.\n\nA discrete one-step time integrator with step size $h \\in \\mathbb{R}$ defines a map $\\Psi_h : \\mathbb{R}^{2N} \\to \\mathbb{R}^{2N}$. A map $\\Psi_h$ is symplectic if $D\\Psi_h(y)^\\top J D\\Psi_h(y) = J$ for all states $y$, where $D\\Psi_h(y) \\in \\mathbb{R}^{2N \\times 2N}$ is the Jacobian matrix of $\\Psi_h$ at $y$. Your task is to empirically verify discrete symplecticity by approximating $D\\Psi_h(y)$ via finite differences on representative test states, and computing the Frobenius norm of the violation\n$$\n\\Delta(y; h) = D\\Psi_h(y)^\\top J D\\Psi_h(y) - J,\n$$\nreported as the relative quantity\n$$\nr(y; h) = \\frac{\\lVert \\Delta(y; h) \\rVert_F}{\\lVert J \\rVert_F}.\n$$\nUse central differences to approximate the columns of $D\\Psi_h(y)$: for the $i$-th canonical basis vector $e_i \\in \\mathbb{R}^{2N}$ and a finite difference scale $\\varepsilon \\in \\mathbb{R}$, approximate the $i$-th column by\n$$\n\\frac{\\Psi_h(y + \\varepsilon e_i) - \\Psi_h(y - \\varepsilon e_i)}{2 \\varepsilon}.\n$$\n\nImplement the following one-step time integrators $\\Psi_h$ on the semi-discrete system:\n- A separable Hamiltonian, symplectic method based on the kinetic-potential splitting with canonical variables (Störmer–Verlet).\n- A symplectic method defined by the midpoint rule applied to the canonical system (Implicit Midpoint).\n- A non-symplectic method based on the explicit Euler step.\n- A non-symplectic method that includes linear damping in the momentum update (Damped Explicit Euler), where damping strength $\\gamma \\in \\mathbb{R}$ modifies the semi-discrete dynamics to $p'(t) = c^2 L q(t) - \\gamma p(t)$.\n\nDerive each integrator from the governing equations and system structure, and implement $\\Psi_h$ so that it acts on an input state vector $y \\in \\mathbb{R}^{2N}$ and returns the next state. Construct the periodic Laplacian $L$ exactly as specified. Use representative test states consisting of:\n- A deterministic sinusoidal configuration with $q_i = \\sin(2\\pi i/N)$ and $p_i = 0$ for $i = 0, 1, \\dots, N-1$.\n- A reproducible random state drawn from a standard normal distribution with a fixed seed.\n\nFor all computations, use pure mathematical quantities with no physical units. Angles, where applicable to the sinusoid, are implicitly in radians.\n\nDesign and run a test suite comprising the following parameter sets $(\\text{method}, N, h, \\varepsilon, c, \\text{state}, \\gamma)$, producing $r(y; h)$ for each:\n- Case $1$: $(\\text{Verlet},\\, 6,\\, 0.2,\\, 10^{-6},\\, 1.0,\\, \\text{random},\\, 0.0)$.\n- Case $2$: $(\\text{ImplicitMidpoint},\\, 6,\\, 0.2,\\, 10^{-6},\\, 1.0,\\, \\text{random},\\, 0.0)$.\n- Case $3$: $(\\text{ExplicitEuler},\\, 6,\\, 0.2,\\, 10^{-6},\\, 1.0,\\, \\text{random},\\, 0.0)$.\n- Case $4$: $(\\text{Verlet},\\, 6,\\, 0.8,\\, 10^{-6},\\, 1.0,\\, \\text{sine},\\, 0.0)$.\n- Case $5$: $(\\text{DampedExplicitEuler},\\, 6,\\, 0.2,\\, 10^{-6},\\, 1.0,\\, \\text{sine},\\, 0.5)$.\n- Case $6$: $(\\text{ExplicitEuler},\\, 6,\\, 0.05,\\, 10^{-6},\\, 1.0,\\, \\text{random},\\, 0.0)$.\n\nYour program should produce a single line of output containing the six resulting relative violations $r(y; h)$ as a comma-separated list enclosed in square brackets (e.g., $[\\text{result}_1,\\text{result}_2,\\dots,\\text{result}_6]$). Each $\\text{result}_i$ must be a floating-point number.", "solution": "The problem requires an empirical verification of the symplecticity property for several numerical time integrators applied to a semi-discretized linear wave equation. The verification is performed by numerically approximating the Jacobian of the discrete flow and measuring its deviation from the symplecticity condition.\n\n### System Formulation\nThe physical system is modeled as a finite-dimensional Hamiltonian system. The state at time $t$ is given by the vector $y(t) = (q(t), p(t))^\\top \\in \\mathbb{R}^{2N}$, where $q \\in \\mathbb{R}^N$ represents grid point positions and $p \\in \\mathbb{R}^N$ their corresponding momenta. The system's evolution follows Hamilton's canonical equations:\n$$y'(t) = J \\nabla H(y(t))$$\nwhere $J \\in \\mathbb{R}^{2N \\times 2N}$ is the canonical symplectic matrix, and $H(y)$ is the system's Hamiltonian (total energy). The matrix $J$ is defined as:\n$$J = \\begin{bmatrix} 0  I \\\\ -I  0 \\end{bmatrix}$$\nwhere $I$ is the $N \\times N$ identity matrix. The Hamiltonian is separable, $H(q,p) = T(p) + V(q)$, with kinetic energy $T(p)$ and potential energy $V(q)$:\n$$\nT(p) = \\frac{1}{2} p^\\top p \\quad \\text{and} \\quad V(q) = -\\frac{1}{2} c^2 q^\\top L q\n$$\nHere, $c$ is a positive wave speed constant, and $L \\in \\mathbb{R}^{N \\times N}$ is the symmetric second-difference periodic Laplacian matrix. The action of $L$ on a vector $q$ is defined element-wise as $(Lq)_i = q_{i+1} - 2q_i + q_{i-1}$, with indices interpreted modulo $N$.\n\nThe gradients of the energy components are $\\nabla_p T(p) = p$ and, due to the symmetry of $L$, $\\nabla_q V(q) = -c^2 L q$. Hamilton's equations thus expand to:\n$$\nq'(t) = \\frac{\\partial H}{\\partial p} = p(t)\n$$\n$$\np'(t) = -\\frac{\\partial H}{\\partial q} = -(-c^2 L q(t)) = c^2 L q(t)\n$$\nThis system of $2N$ first-order ordinary differential equations (ODEs), which can be written compactly as $y' = Ay$ with $A = \\begin{pmatrix} 0  I \\\\ c^2 L  0 \\end{pmatrix}$, is the foundation for the numerical methods.\n\n### Numerical Integrators\nWe implement four one-step integrators, $\\Psi_h$, which map the state $y_n$ at time $t_n$ to the state $y_{n+1}$ at time $t_{n+1} = t_n + h$.\n\n1.  **Störmer–Verlet Integrator ($\\Psi_h^{\\text{Verlet}}$)**: This is a second-order, explicit, symplectic integrator, ideal for separable Hamiltonians. A common implementation, known as the position Verlet or leapfrog method, is given by a sequence of three explicit steps:\n    - Half-step update of momentum: $p_{n+1/2} = p_n + \\frac{h}{2} (c^2 L q_n)$.\n    - Full-step update of position: $q_{n+1} = q_n + h p_{n+1/2}$.\n    - Final half-step update of momentum: $p_{n+1} = p_{n+1/2} + \\frac{h}{2} (c^2 L q_{n+1})$.\n\n2.  **Implicit Midpoint Rule ($\\Psi_h^{\\text{IM}}$)**: This method is a one-step, second-order, implicit integrator that is symplectic for any Hamiltonian system. For an ODE $y' = f(y)$, the update is $y_{n+1} = y_n + h f(\\frac{y_n+y_{n+1}}{2})$. For our linear system $y' = Ay$, this yields:\n    $$y_{n+1} = y_n + h A \\frac{y_n + y_{n+1}}{2}$$\n    This can be rearranged into a linear system for $y_{n+1}$: $(I - \\frac{h}{2}A) y_{n+1} = (I + \\frac{h}{2}A) y_n$. For implementation, we decouple the equations for $q$ and $p$. By substitution, we obtain a linear system solely for $q_{n+1}$:\n    $$ \\left(I - \\frac{h^2 c^2}{4} L\\right) q_{n+1} = \\left(I + \\frac{h^2 c^2}{4} L\\right) q_n + h p_n $$\n    After solving this $N \\times N$ system for $q_{n+1}$, we can find $p_{n+1}$ via the explicit update $p_{n+1} = p_n + \\frac{h c^2}{2} L(q_n + q_{n+1})$.\n\n3.  **Explicit Euler Method ($\\Psi_h^{\\text{EE}}$)**: The simplest explicit method, defined by $y_{n+1} = y_n + h f(y_n)$. It is first-order and not symplectic. For our system:\n    - $q_{n+1} = q_n + h p_n$.\n    - $p_{n+1} = p_n + h c^2 L q_n$.\n\n4.  **Damped Explicit Euler Method ($\\Psi_h^{\\text{DEE}}$)**: Here, the underlying dynamics are modified to include a non-conservative damping term with strength $\\gamma \\ge 0$: $p'(t) = c^2 L q(t) - \\gamma p(t)$. The system is no longer Hamiltonian. The explicit Euler method applied to these modified dynamics gives:\n    - $q_{n+1} = q_n + h p_n$.\n    - $p_{n+1} = p_n + h (c^2 L q_n - \\gamma p_n) = (1-h\\gamma)p_n + h c^2 L q_n$.\n\n### Verification of Symplecticity\nA map $\\Psi_h$ from $\\mathbb{R}^{2N}$ to itself is symplectic if its Jacobian, $D\\Psi_h(y)$, satisfies the condition\n$$ D\\Psi_h(y)^\\top J D\\Psi_h(y) = J $$\nfor all states $y$. To verify this property empirically, we approximate the Jacobian matrix. The $j$-th column of $D\\Psi_h(y)$ is the partial derivative $\\frac{\\partial \\Psi_h}{\\partial y_j}(y)$, which we approximate using a second-order central finite difference formula with a small step $\\varepsilon$:\n$$ \\left[D\\Psi_h(y)\\right]_{\\cdot, j} \\approx \\frac{\\Psi_h(y + \\varepsilon e_j) - \\Psi_h(y - \\varepsilon e_j)}{2 \\varepsilon} $$\nwhere $e_j$ is the $j$-th canonical basis vector in $\\mathbb{R}^{2N}$. Once the approximate Jacobian $D\\Psi_h$ is constructed, we evaluate the symplecticity violation matrix $\\Delta(y; h) = D\\Psi_h(y)^\\top J D\\Psi_h(y) - J$. The magnitude of this violation is quantified by the relative Frobenius norm:\n$$ r(y; h) = \\frac{\\lVert \\Delta(y; h) \\rVert_F}{\\lVert J \\rVert_F} $$\nThe Frobenius norm of $J$ is $\\lVert J \\rVert_F = \\sqrt{\\text{Tr}(J^\\top J)} = \\sqrt{\\text{Tr}(\\text{diag}(I,I))} = \\sqrt{2N}$.\n\nFor the Störmer-Verlet and Implicit Midpoint methods, which are exactly symplectic, the theoretical violation is zero. The computed value $r(y;h)$ will be non-zero but small, dominated by floating-point rounding errors and the $O(\\varepsilon^2)$ error of the finite difference approximation. For non-symplectic methods like Explicit Euler, the violation is intrinsic, and $r(y;h)$ is expected to be of order $O(h)$. The damped system is non-Hamiltonian, so its discrete flow is also expected to be non-symplectic.\n\nThe computational procedure involves implementing the four integrator maps, constructing the necessary matrices for a given dimension $N$, generating the specified initial states, and then executing the test suite. For each case, the Jacobian is computed numerically, and the relative violation $r(y;h)$ is calculated and reported.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import linalg\n\ndef get_laplacian(N):\n    \"\"\"Constructs the 1D periodic Laplacian matrix L of size N x N.\"\"\"\n    L = np.zeros((N, N))\n    for i in range(N):\n        L[i, i] = -2\n        L[i, (i + 1) % N] = 1\n        L[i, (i - 1 + N) % N] = 1\n    return L\n\ndef get_J_matrix(N):\n    \"\"\"Constructs the canonical symplectic matrix J of size 2N x 2N.\"\"\"\n    J = np.zeros((2 * N, 2 * N))\n    I = np.eye(N)\n    J[0:N, N:2*N] = I\n    J[N:2*N, 0:N] = -I\n    return J\n    \ndef verlet_step(y, h, c, L):\n    \"\"\"Performs one step of the Störmer-Verlet integrator.\"\"\"\n    N = L.shape[0]\n    q_n = y[:N]\n    p_n = y[N:]\n    \n    # Half-step momentum\n    p_half = p_n + (h / 2.0) * (c**2) * (L @ q_n)\n    # Full-step position\n    q_next = q_n + h * p_half\n    # Half-step momentum\n    p_next = p_half + (h / 2.0) * (c**2) * (L @ q_next)\n    \n    return np.concatenate([q_next, p_next])\n\ndef implicit_midpoint_step(y, h, c, L):\n    \"\"\"Performs one step of the Implicit Midpoint integrator.\"\"\"\n    N = L.shape[0]\n    I_N = np.eye(N)\n    q_n = y[:N]\n    p_n = y[N:]\n\n    # System for q_{n+1}: M_imp * q_{n+1} = b_imp\n    M_imp = I_N - (h**2 * c**2 / 4.0) * L\n    b_imp = (I_N + (h**2 * c**2 / 4.0) * L) @ q_n + h * p_n\n    \n    q_next = np.linalg.solve(M_imp, b_imp)\n    \n    # Update p_{n+1}\n    p_next = p_n + (h * c**2 / 2.0) * (L @ (q_n + q_next))\n\n    return np.concatenate([q_next, p_next])\n\ndef explicit_euler_step(y, h, c, L):\n    \"\"\"Performs one step of the Explicit Euler integrator.\"\"\"\n    N = L.shape[0]\n    q_n = y[:N]\n    p_n = y[N:]\n\n    q_next = q_n + h * p_n\n    p_next = p_n + h * (c**2) * (L @ q_n)\n    \n    return np.concatenate([q_next, p_next])\n\ndef damped_explicit_euler_step(y, h, c, L, gamma):\n    \"\"\"Performs one step of the Damped Explicit Euler integrator.\"\"\"\n    N = L.shape[0]\n    q_n = y[:N]\n    p_n = y[N:]\n\n    q_next = q_n + h * p_n\n    p_next = p_n + h * ((c**2) * (L @ q_n) - gamma * p_n)\n\n    return np.concatenate([q_next, p_next])\n\ndef compute_jacobian(integrator_func, y, h, epsilon, **kwargs):\n    \"\"\"Computes the Jacobian of the integrator map using central differences.\"\"\"\n    dim = len(y)\n    D = np.zeros((dim, dim))\n    \n    for j in range(dim):\n        e_j = np.zeros(dim)\n        e_j[j] = 1.0\n        \n        y_plus = y + epsilon * e_j\n        y_minus = y - epsilon * e_j\n        \n        psi_plus = integrator_func(y_plus, h, **kwargs)\n        psi_minus = integrator_func(y_minus, h, **kwargs)\n        \n        D[:, j] = (psi_plus - psi_minus) / (2.0 * epsilon)\n        \n    return D\n\ndef calculate_violation(D, J):\n    \"\"\"Calculates the relative Frobenius norm of the symplecticity violation.\"\"\"\n    N = J.shape[0] // 2\n    delta = D.T @ J @ D - J\n    norm_delta = np.linalg.norm(delta, 'fro')\n    norm_J = np.sqrt(2.0 * N)\n    \n    return norm_delta / norm_J\n\ndef solve():\n    test_cases = [\n        {'method': 'Verlet', 'N': 6, 'h': 0.2, 'epsilon': 1e-6, 'c': 1.0, 'state': 'random', 'gamma': 0.0},\n        {'method': 'ImplicitMidpoint', 'N': 6, 'h': 0.2, 'epsilon': 1e-6, 'c': 1.0, 'state': 'random', 'gamma': 0.0},\n        {'method': 'ExplicitEuler', 'N': 6, 'h': 0.2, 'epsilon': 1e-6, 'c': 1.0, 'state': 'random', 'gamma': 0.0},\n        {'method': 'Verlet', 'N': 6, 'h': 0.8, 'epsilon': 1e-6, 'c': 1.0, 'state': 'sine', 'gamma': 0.0},\n        {'method': 'DampedExplicitEuler', 'N': 6, 'h': 0.2, 'epsilon': 1e-6, 'c': 1.0, 'state': 'sine', 'gamma': 0.5},\n        {'method': 'ExplicitEuler', 'N': 6, 'h': 0.05, 'epsilon': 1e-6, 'c': 1.0, 'state': 'random', 'gamma': 0.0},\n    ]\n\n    integrators = {\n        'Verlet': verlet_step,\n        'ImplicitMidpoint': implicit_midpoint_step,\n        'ExplicitEuler': explicit_euler_step,\n        'DampedExplicitEuler': damped_explicit_euler_step\n    }\n\n    results = []\n    \n    # Use a fixed seed for reproducibility of random states\n    np.random.seed(42)\n\n    for case in test_cases:\n        N = case['N']\n        h = case['h']\n        epsilon = case['epsilon']\n        c = case['c']\n        gamma = case['gamma']\n        \n        # Construct matrices\n        L = get_laplacian(N)\n        J = get_J_matrix(N)\n\n        # Generate initial state y = (q, p)\n        if case['state'] == 'sine':\n            i_vals = np.arange(N)\n            q0 = np.sin(2 * np.pi * i_vals / N)\n            p0 = np.zeros(N)\n            y0 = np.concatenate([q0, p0])\n        elif case['state'] == 'random':\n            y0 = np.random.randn(2 * N)\n        \n        # Select integrator\n        integrator = integrators[case['method']]\n        \n        # Prepare kwargs for the integrator and jacobian calculation\n        kwargs = {'c': c, 'L': L}\n        if case['method'] == 'DampedExplicitEuler':\n            kwargs['gamma'] = gamma\n        \n        # Compute Jacobian\n        D_psi_h = compute_jacobian(integrator, y0, h, epsilon, **kwargs)\n        \n        # Calculate violation\n        r = calculate_violation(D_psi_h, J)\n        results.append(r)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3451938"}]}