{"hands_on_practices": [{"introduction": "The discrete maximum principle is a cornerstone of stable numerical schemes for diffusion problems, ensuring that solutions remain physically plausible. This principle is guaranteed if the discretization matrix is an $M$-matrix, which requires non-positive off-diagonal entries. This exercise demonstrates how standard finite difference stencils for anisotropic diffusion can easily violate this condition, leading to spurious oscillations and overshoots. You will implement a scheme [@problem_id:3416731], observe this failure, and apply a practical algebraic \"lumping\" technique to restore the $M$-matrix property and improve the global accuracy of the solution.", "problem": "Consider the two-dimensional anisotropic diffusion model posed on the unit square domain $[0,1]\\times[0,1]$ with homogeneous Dirichlet boundary data given by the exact solution $u(x,y)=\\sin(\\pi x)\\sin(\\pi y)$. The governing elliptic partial differential equation is $-\\nabla\\cdot(\\boldsymbol{D}\\nabla u)=f$, where the diffusion tensor is $\\boldsymbol{D}=\\begin{pmatrix}1&\\beta\\\\ \\beta&1\\end{pmatrix}$ with a constant anisotropy parameter $\\beta\\in\\mathbb{R}$. The source term $f$ is defined so that $u$ is the exact solution, i.e., $f(x,y)=-\\nabla\\cdot(\\boldsymbol{D}\\nabla u(x,y))$. The discrete approximation uses a uniform Cartesian grid with $N$ interior points per coordinate direction, with mesh spacing $h=1/(N+1)$ and interior nodes at coordinates $(x_i,y_j)=(ih,jh)$ for $i=1,\\dots,N$ and $j=1,\\dots,N$, respectively.\n\nYou must assemble the discrete operator $\\boldsymbol{A}$ acting on the vector of interior nodal unknowns using the following stencil:\n- The second derivatives $u_{xx}$ and $u_{yy}$ are each approximated by central differences with the standard five-point stencil, giving weights $4/h^2$ on the diagonal and $-1/h^2$ on each of the four axis-aligned neighbors.\n- The mixed derivative $u_{xy}$ is approximated by the standard central-difference nine-point contribution\n$$u_{xy}(x_i,y_j)\\approx \\frac{u_{i+1,j+1}-u_{i+1,j-1}-u_{i-1,j+1}+u_{i-1,j-1}}{4h^2},$$\nwhich contributes to the cross terms in $-\\nabla\\cdot(\\boldsymbol{D}\\nabla u)$ via $-2\\beta\\,u_{xy}$. This yields corner weights $\\pm \\beta/(2h^2)$ with signs as implied by the above formula. The resulting $\\boldsymbol{A}$ is symmetric.\n\nThe fundamental base for your derivation and algorithmic design must begin with the continuous maximum principle for uniformly elliptic operators, the notion of an $M$-matrix for discrete operators, and the standard definitions of local truncation error and global discretization error:\n- A symmetric tensor $\\boldsymbol{D}$ with eigenvalues bounded below by a positive constant implies uniform ellipticity and a continuous maximum principle: if $f\\ge 0$ and boundary data is bounded, then interior maxima do not exceed boundary maxima.\n- A sparse matrix $\\boldsymbol{A}$ is an $M$-matrix if its off-diagonal entries are nonpositive and it is weakly diagonally dominant by rows with a positive diagonal; this suffices for a discrete maximum principle.\n- The local truncation error at a grid point is the residual obtained by inserting the exact solution into the discrete operator, and the global discretization error is the difference between the discrete solution and the exact solution measured in a norm, here the $L^{\\infty}$ norm.\n\nThe problem you must solve comprises three parts:\n1. Starting from these principles, explain clearly why the presence of locally sign-indefinite corner weights and overly large negative off-diagonals in the anisotropic nine-point stencil can violate the $M$-matrix property and hence the discrete maximum principle, thereby admitting global overshoots where the discrete solution exceeds the continuous maximum $1$ attained by $u(x,y)$ at $(x,y)=(\\tfrac{1}{2},\\tfrac{1}{2})$.\n2. Propose and implement a strictly local algebraic fix that restores the $M$-matrix property without changing the discrete operator beyond the immediate row and column associated to the violating entries: for any positive off-diagonal entry $A_{ij}$, with $i\\ne j$, set $A_{ij}\\leftarrow 0$ and $A_{ji}\\leftarrow 0$, and increase both diagonals $A_{ii}$ and $A_{jj}$ by the removed amount to strengthen diagonal dominance while preserving matrix symmetry.\n3. Quantify the change in the global $L^{\\infty}$ error due to this local fix. For each test case defined below, compute the $L^{\\infty}$ error $E_{\\infty}=\\max_{i,j}|u^{h}_{ij}-u(x_i,y_j)|$ for the original stencil and for the locally fixed stencil, and report the improvement $\\Delta E_{\\infty}=E_{\\infty,\\text{orig}}-E_{\\infty,\\text{fix}}$ as a float. Also compute the overshoot magnitude $O=\\max\\{0,\\max_{i,j}u^{h}_{ij}-1\\}$ before and after the fix, but only $\\Delta E_{\\infty}$ must be printed. No physical units are involved, and all angles, if any appear, must be in radians.\n\nUse the following test suite $(N,\\beta)$ values to exercise diverse regimes:\n- Case A (happy path, isotropic): $(N,\\beta)=(33,0)$.\n- Case B (moderate anisotropy): $(N,\\beta)=(33,0.6)$.\n- Case C (strong anisotropy, coarse grid): $(N,\\beta)=(17,0.95)$.\n- Case D (negative cross anisotropy): $(N,\\beta)=(33,-0.8)$.\n\nYour program must:\n- Assemble $\\boldsymbol{A}$ and the right-hand side vector $\\boldsymbol{b}$ with entries $b_{ij}=f(x_i,y_j)$ obtained analytically from $u$ and $\\boldsymbol{D}$, where $f(x,y)=-\\nabla\\cdot(\\boldsymbol{D}\\nabla u(x,y))$.\n- Solve $\\boldsymbol{A}\\boldsymbol{u}^{h}=\\boldsymbol{b}$ for the interior unknowns $\\boldsymbol{u}^{h}$ before and after applying the local fix.\n- Compute $E_{\\infty,\\text{orig}}$, $E_{\\infty,\\text{fix}}$, and the improvement $\\Delta E_{\\infty}$ for each case.\n\nFinal output format: Your program should produce a single line of output containing the four improvement values as a comma-separated list enclosed in square brackets (e.g., $[a,b,c,d]$). Each entry must be a float. No other text should be printed.", "solution": "The problem requires a three-part analysis of a finite difference discretization for an anisotropic diffusion equation. We must first validate the problem's formulation, then provide a theoretical explanation of a potential numerical artifact, propose and justify a fix, and finally implement a numerical experiment to quantify the fix's effect.\n\n### Problem Validation\n\nThe problem is deemed valid. It is scientifically grounded in the established theory of numerical analysis for partial differential equations, specifically concerning finite difference methods, matrix properties ($M$-matrices), and maximum principles. The setup is well-posed: it defines a linear elliptic PDE on a simple domain with a known smooth solution, specifies a consistent discretization scheme, and asks for a quantifiable analysis of a known numerical issue. The problem is objective, complete, and contains no contradictions. All parameters and test cases are physically and mathematically reasonable for the context of demonstrating the specified numerical behavior. We may therefore proceed with the solution.\n\n### Part 1: Violation of the Discrete Maximum Principle\n\nThe governing partial differential equation (PDE) is given by $-\\nabla\\cdot(\\boldsymbol{D}\\nabla u)=f$ on the domain $[0,1]\\times[0,1]$, where $\\boldsymbol{D}=\\begin{pmatrix}1&\\beta\\\\ \\beta&1\\end{pmatrix}$. Expanding the divergence operator, the PDE becomes:\n$$ -\\frac{\\partial}{\\partial x}\\left(1 \\cdot \\frac{\\partial u}{\\partial x} + \\beta \\frac{\\partial u}{\\partial y}\\right) - \\frac{\\partial}{\\partial y}\\left(\\beta \\frac{\\partial u}{\\partial x} + 1 \\cdot \\frac{\\partial u}{\\partial y}\\right) = f $$\n$$ - \\left( \\frac{\\partial^2 u}{\\partial x^2} + \\beta \\frac{\\partial^2 u}{\\partial y \\partial x} \\right) - \\left( \\beta \\frac{\\partial^2 u}{\\partial x \\partial y} + \\frac{\\partial^2 u}{\\partial y^2} \\right) = f $$\nAssuming sufficient smoothness of $u$ such that mixed partial derivatives are equal ($u_{xy} = u_{yx}$), the PDE is:\n$$ -u_{xx} - u_{yy} - 2\\beta u_{xy} = f $$\nThe problem specifies a finite-difference discretization on a uniform grid with spacing $h$. The second derivatives are approximated using standard central differences, and the mixed derivative is approximated as specified. For a generic interior node $(i,j)$, let $u_{i,j}$ denote the approximate solution at $(x_i, y_j)$. The discrete form of the operator at this node is:\n$$ - \\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} - \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} - 2\\beta \\frac{u_{i+1,j+1}-u_{i+1,j-1}-u_{i-1,j+1}+u_{i-1,j-1}}{4h^2} = f_{i,j} $$\nGrouping terms by their corresponding nodal values, we obtain the computational stencil:\n$$ \\frac{1}{h^2} \\left( 4u_{i,j} - u_{i+1,j} - u_{i-1,j} - u_{i,j+1} - u_{i,j-1} \\right) - \\frac{\\beta}{2h^2} \\left( u_{i+1,j+1}-u_{i+1,j-1}-u_{i-1,j+1}+u_{i-1,j-1} \\right) = f_{i,j} $$\nThis equation defines a row in the linear system $\\boldsymbol{A}\\boldsymbol{u}^h = \\boldsymbol{b}$. The coefficients of the neighboring $u$ values become the off-diagonal entries of the matrix $\\boldsymbol{A}$.\nThe stencil weights for the row corresponding to node $(i,j)$ are:\n- Center $(i,j)$: $\\frac{4}{h^2}$ (diagonal entry of $\\boldsymbol{A}$)\n- Axis-aligned neighbors $(i\\pm1,j)$, $(i,j\\pm1)$: $-\\frac{1}{h^2}$\n- Diagonal neighbors $(i+1,j+1)$, $(i-1,j-1)$: $-\\frac{\\beta}{2h^2}$\n- Anti-diagonal neighbors $(i-1,j+1)$, $(i+1,j-1)$: $+\\frac{\\beta}{2h^2}$\n\nA matrix $\\boldsymbol{A}$ is an $M$-matrix if it is nonsingular, its diagonal entries are positive ($A_{kk} > 0$), and all its off-diagonal entries are nonpositive ($A_{kl} \\le 0$ for $k \\ne l$). A sufficient condition for this is that $\\boldsymbol{A}$ is weakly diagonally dominant with nonpositive off-diagonals and positive diagonals. An $M$-matrix property guarantees a discrete maximum principle (DMP), ensuring that the numerical solution does not exhibit non-physical oscillations or extrema not present in the source term or boundary data.\n\nFrom the stencil weights, we observe that the off-diagonal entries of $\\boldsymbol{A}$ depend on the sign of $\\beta$:\n- If $\\beta > 0$, the weights corresponding to the anti-diagonal neighbors $(i-1,j+1)$ and $(i+1,j-1)$ are $+\\frac{\\beta}{2h^2} > 0$.\n- If $\\beta < 0$, let $\\beta = -|\\beta|$. The weights for the diagonal neighbors $(i+1,j+1)$ and $(i-1,j-1)$ become $-\\frac{-|\\beta|}{2h^2} = +\\frac{|\\beta|}{2h^2} > 0$.\n\nIn either case, for any $\\beta \\neq 0$, the matrix $\\boldsymbol{A}$ will have positive off-diagonal entries. This violates the definition of an $M$-matrix. The failure to satisfy the $M$-matrix property implies that the discrete operator does not satisfy a discrete maximum principle. The continuous solution $u(x,y)=\\sin(\\pi x)\\sin(\\pi y)$ has a maximum value of $1$ at $(0.5, 0.5)$ and is zero on the boundary. The loss of the DMP can lead to spurious \"overshoots\" in the numerical solution, where $\\max_{i,j} u^h_{i,j}$ can exceed the continuous maximum of $1$, a non-physical artifact.\n\n### Part 2: Restoring the $M$-Matrix Property\n\nTo restore the $M$-matrix property, we apply a local algebraic fix to the matrix $\\boldsymbol{A}$. The goal is to eliminate all positive off-diagonal entries. The proposed fix is as follows: For every pair of indices $(k,l)$ with $k \\ne l$ and $A_{kl} > 0$:\n1. Set the positive off-diagonal entry to zero: $A_{kl} \\leftarrow 0$. Since the original matrix $\\boldsymbol{A}$ is symmetric, we also set $A_{lk} \\leftarrow 0$.\n2. To preserve symmetry and strengthen diagonal dominance, the removed positive value is added to the corresponding diagonal entries. Specifically, we update $A_{kk} \\leftarrow A_{kk} + A_{kl, \\text{orig}}$ and $A_{ll} \\leftarrow A_{ll} + A_{lk, \\text{orig}}$.\n\nThis procedure transforms the original matrix $\\boldsymbol{A}_{\\text{orig}}$ into a new matrix $\\boldsymbol{A}_{\\text{fix}}$. Let's analyze why this fix is effective:\n- **Nonpositive Off-Diagonals:** The procedure systematically identifies and zeroes out every positive off-diagonal entry. Originally negative or zero off-diagonal entries are left unchanged. By construction, the resulting matrix $\\boldsymbol{A}_{\\text{fix}}$ has exclusively nonpositive off-diagonal entries.\n- **Diagonal Dominance:** The diagonal entries of $\\boldsymbol{A}_{\\text{orig}}$ are positive ($4/h^2 > 0$). The fix adds a non-negative value (the original positive off-diagonal element) to each diagonal entry involved in a modification. This strictly increases the magnitude of the diagonal entries relative to the off-diagonals, thereby strengthening the diagonal dominance of the matrix.\n- **$M$-Matrix and DMP:** The resulting matrix $\\boldsymbol{A}_{\\text{fix}}$ now has positive diagonals, nonpositive off-diagonals, and is at least as diagonally dominant as $\\boldsymbol{A}_{\\text{orig}}$. This ensures $\\boldsymbol{A}_{\\text{fix}}$ is an $M$-matrix. An invertible $M$-matrix has a non-negative inverse ($\\boldsymbol{A}_{\\text{fix}}^{-1} \\ge 0$), which is a sufficient condition for the discrete operator to satisfy a maximum principle. This restoration of the DMP suppresses the non-physical overshoots and is expected to yield a more stable and qualitatively correct numerical solution.\n\n### Part 3: Quantifying the Improvement\n\nThe theoretical benefit of restoring the DMP is the suppression of numerical overshoots and improved stability. We quantify the practical impact by measuring the change in the global discretization error. The error is measured in the infinity norm ($L^{\\infty}$), defined as the maximum absolute difference between the numerical solution $u^h$ and the exact solution $u$ at the grid nodes: $E_{\\infty} = \\max_{i,j}|u^{h}_{ij}-u(x_i,y_j)|$.\n\nBy solving the linear system for both the original matrix ($\\boldsymbol{A}_{\\text{orig}}\\boldsymbol{u}^h_{\\text{orig}} = \\boldsymbol{b}$) and the fixed matrix ($\\boldsymbol{A}_{\\text{fix}}\\boldsymbol{u}^h_{\\text{fix}} = \\boldsymbol{b}$), we obtain two numerical solutions. We can then compute their respective errors, $E_{\\infty,\\text{orig}}$ and $E_{\\infty,\\text{fix}}$. The improvement is defined as $\\Delta E_{\\infty} = E_{\\infty,\\text{orig}} - E_{\\infty,\\text{fix}}$. A positive value for $\\Delta E_{\\infty}$ indicates that the local algebraic fix has reduced a global error measure, yielding a more accurate solution in addition to being more qualitatively correct. The provided code implements this procedure for the specified test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse import csr_matrix, dok_matrix\nfrom scipy.sparse.linalg import spsolve\n\ndef assemble_system(N, beta):\n    \"\"\"\n    Assembles the sparse matrix A and the right-hand side vector b.\n    \"\"\"\n    h = 1.0 / (N + 1)\n    N2 = N * N\n    \n    # Create grid\n    x = np.linspace(h, 1.0 - h, N)\n    y = np.linspace(h, 1.0 - h, N)\n    X, Y = np.meshgrid(x, y, indexing='ij')\n\n    # Exact solution\n    u_exact = np.sin(np.pi * X) * np.sin(np.pi * Y)\n    \n    # Source term f(x,y)\n    f = (2.0 * np.pi**2 * np.sin(np.pi * X) * np.sin(np.pi * Y) -\n         2.0 * beta * np.pi**2 * np.cos(np.pi * X) * np.cos(np.pi * Y))\n    b = f.flatten()\n\n    # Stencil weights\n    h2 = h * h\n    w_center = 4.0 / h2\n    w_axis = -1.0 / h2\n    w_diag = -beta / (2.0 * h2)\n    w_anti = beta / (2.0 * h2)\n\n    # Assemble A using COO format\n    rows, cols, data = [], [], []\n\n    for i in range(N):\n        for j in range(N):\n            k = i * N + j\n            \n            # Center\n            rows.append(k)\n            cols.append(k)\n            data.append(w_center)\n            \n            # Axis-aligned neighbors\n            if i > 0:   # (i-1, j)\n                rows.append(k); cols.append(k - N); data.append(w_axis)\n            if i  N-1: # (i+1, j)\n                rows.append(k); cols.append(k + N); data.append(w_axis)\n            if j > 0:   # (i, j-1)\n                rows.append(k); cols.append(k - 1); data.append(w_axis)\n            if j  N-1: # (i, j+1)\n                rows.append(k); cols.append(k + 1); data.append(w_axis)\n                \n            # Mixed-derivative neighbors\n            # (i-1, j-1)\n            if i > 0 and j > 0:\n                rows.append(k); cols.append(k - N - 1); data.append(w_diag)\n            # (i+1, j+1)\n            if i  N-1 and j  N-1:\n                rows.append(k); cols.append(k + N + 1); data.append(w_diag)\n            # (i-1, j+1)\n            if i > 0 and j  N-1:\n                rows.append(k); cols.append(k - N + 1); data.append(w_anti)\n            # (i+1, j-1)\n            if i  N-1 and j > 0:\n                rows.append(k); cols.append(k + N - 1); data.append(w_anti)\n\n    A = csr_matrix((data, (rows, cols)), shape=(N2, N2))\n    return A, b, u_exact.flatten()\n\ndef apply_local_fix(A_orig):\n    \"\"\"\n    Applies the local algebraic fix to restore the M-matrix property.\n    \"\"\"\n    A_fix = A_orig.todok()\n    \n    # Find positive off-diagonal entries. Iterate over a copy of keys.\n    positive_off_diagonals = []\n    for (r, c), v in A_fix.items():\n        if r != c and v > 0:\n            positive_off_diagonals.append((r, c))\n\n    for r, c in positive_off_diagonals:\n        # Check if it hasn't been zeroed out by its symmetric partner\n        if A_fix[r, c] > 0:\n            val = A_fix[r, c]\n            A_fix[r, r] += val\n            A_fix[c, c] += val  # Using symmetry, A[c,r] was also positive\n            A_fix[r, c] = 0\n            A_fix[c, r] = 0\n            \n    return A_fix.tocsr()\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and compute error improvements.\n    \"\"\"\n    test_cases = [\n        (33, 0.0),      # Case A\n        (33, 0.6),      # Case B\n        (17, 0.95),     # Case C\n        (33, -0.8),     # Case D\n    ]\n\n    results = []\n    for N, beta in test_cases:\n        # 1. Assemble original system\n        A_orig, b, u_exact_flat = assemble_system(N, beta)\n        \n        # 2. Solve original system and compute error\n        u_h_orig = spsolve(A_orig, b)\n        e_inf_orig = np.max(np.abs(u_h_orig - u_exact_flat))\n        \n        # 3. Apply fix\n        A_fix = apply_local_fix(A_orig)\n        \n        # 4. Solve fixed system and compute error\n        u_h_fix = spsolve(A_fix, b)\n        e_inf_fix = np.max(np.abs(u_h_fix - u_exact_flat))\n\n        # 5. Calculate error improvement\n        delta_e_inf = e_inf_orig - e_inf_fix\n        results.append(delta_e_inf)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```", "id": "3416731"}, {"introduction": "Rather than patching a flawed discretization, a more robust approach is to build schemes that are correct by design. This practice explores a powerful, coordinate-free finite volume method that is naturally suited for arbitrary polygonal meshes. The central concept you will investigate [@problem_id:3379955] is linear exactnessâ€”the fundamental property that a scheme must perfectly reproduce a linear solution. By deriving this method from first principles and verifying its exactness numerically, you will gain insight into the design of high-quality, geometrically flexible discretization methods.", "problem": "Consider the anisotropic diffusion Partial Differential Equation (PDE) $-\\nabla \\cdot (A \\nabla u) = f$ on a domain in $\\mathbb{R}^d$, where $A \\in \\mathbb{R}^{d \\times d}$ is a symmetric positive definite constant tensor. Your task is to derive and implement a coordinate-free finite volume discretization of fluxes on arbitrary polytopal meshes using barycentric duals, and to verify the property of linear exactness for constant $A$ on skewed meshes with rotated anisotropy.\n\nBegin from the following fundamental base:\n- The Divergence Theorem: for any sufficiently smooth vector field $q$ and any polytope $K$ with outward unit normal $\\boldsymbol{n}$, one has $\\int_K \\nabla \\cdot q \\, dV = \\int_{\\partial K} q \\cdot \\boldsymbol{n} \\, dS$.\n- For any sufficiently smooth scalar field $u$, the average gradient over a cell $K$ satisfies $\\int_K \\nabla u \\, dV = \\int_{\\partial K} u \\boldsymbol{n} \\, dS$.\n- The barycentric dual construction on a polytopal mesh partitions a primal cell into subcells associated to lower-dimensional entities (such as faces and vertices), enabling control-volume balances built from face-based contributions without introducing a preferred coordinate system.\n- A constant symmetric positive definite matrix $A$ defines an inner product on $\\mathbb{R}^d$ and a rotated, scaled diffusion, without any dependence on a chosen coordinate basis.\n\nYour objectives:\n1) Derive a coordinate-free cellwise discrete gradient on an arbitrary convex polygonal cell $K \\subset \\mathbb{R}^2$ using the above fundamental statements and a barycentric-dual consistent evaluation of face (edge) integrals that does not depend on a particular coordinate system. From that, derive a cellwise flux and face fluxes. Justify that the method uses only geometric entities such as outward normals and edge lengths, and is independent of a specific component-wise coordinate representation.\n2) Prove linear exactness for constant $A$: if $u(\\boldsymbol{x}) = \\boldsymbol{p} \\cdot \\boldsymbol{x} + c$ for a constant vector $\\boldsymbol{p} \\in \\mathbb{R}^2$ and constant $c \\in \\mathbb{R}$, then your discrete gradient on each cell $K$ equals the exact gradient $\\nabla u = \\boldsymbol{p}$, and the discrete face fluxes computed with constant $A$ equal the exact face fluxes. Explain why this result holds on arbitrary convex polygons and how the barycentric dual construction ensures exactness for linear fields.\n3) Implement a program that:\n- Accepts no input and constructs the test meshes and parameters as prescribed below.\n- For each cell, uses vertex-based unknowns $u(\\boldsymbol{v}_i)$ placed at vertices $\\boldsymbol{v}_i$ to evaluate the cellwise discrete gradient in a coordinate-free manner via edge-based contributions associated with the barycentric dual. Use only geometric primitives: edge vectors, outward normals, edge measures, and cell area. For the value of $u$ at an edge midpoint, use the barycentric-dual consistent choice implied by linear interpolation from vertices.\n- Builds a constant anisotropy $A$ by rotating a diagonal matrix with eigenvalues $a_\\parallel$ and $a_\\perp$ by a given angle $\\theta$, i.e., $A = R(\\theta) \\operatorname{diag}(a_\\parallel, a_\\perp) R(\\theta)^\\top$, where $R(\\theta)$ is a rotation in $\\mathbb{R}^2$ by $\\theta$ radians.\n- For each test case, computes the maximum absolute error over all cell edges between the discrete face flux produced by your method and the exact face flux for the prescribed linear field. The exact flux is $q_{\\text{exact}} = -A \\boldsymbol{p}$, which is constant, and the exact face flux through an oriented edge with outward normal $\\boldsymbol{n}$ and edge length $\\lvert e \\rvert$ is $(q_{\\text{exact}} \\cdot \\boldsymbol{n}) \\lvert e \\rvert$.\n- Aggregates the maximum absolute error over all faces across all cells for that case into a single floating-point number.\n\nTest suite and parameters:\n- All meshes are polygonal in $\\mathbb{R}^2$ and must be constructed as described. You must ensure that each polygon is oriented counterclockwise.\n- All angles are in radians. No physical units are involved.\n\nConstruct the following three test cases.\n\nTest case $1$ (happy path, moderately skewed multi-cell mesh):\n- Base mesh: a Cartesian grid on $[0,1]^2$ with cell size $h = 1/2$, yielding $4$ quadrilateral cells with vertices $[(0,0),(1/2,0),(1/2,1/2),(0,1/2)]$, $[(1/2,0),(1,0),(1,1/2),(1/2,1/2)]$, $[(0,1/2),(1/2,1/2),(1/2,1),(0,1)]$, $[(1/2,1/2),(1,1/2),(1,1),(1/2,1)]$.\n- Apply the affine map $\\boldsymbol{x} \\mapsto M_1 \\boldsymbol{x} + \\boldsymbol{b}_1$ with\n$$\nM_1 = \\begin{pmatrix} 1  0.3 \\\\ 0  1 \\end{pmatrix}, \\quad \\boldsymbol{b}_1 = \\begin{pmatrix} 0.05 \\\\ -0.02 \\end{pmatrix}.\n$$\n- Anisotropy: $\\theta_1 = \\pi/6$, $a_{\\parallel,1} = 5$, $a_{\\perp,1} = 1$.\n- Linear field: $\\boldsymbol{p}_1 = (0.7,-1.1)$, $c_1 = 0.3$.\n\nTest case $2$ (single high-order polygon, global skew and rotation):\n- Base polygon: regular octagon with vertices\n$$\n\\boldsymbol{v}_k = \\boldsymbol{c}_0 + r \\begin{pmatrix} \\cos(2\\pi k/8) \\\\ \\sin(2\\pi k/8) \\end{pmatrix}, \\quad k=0,\\dots,7,\n$$\nwith $\\boldsymbol{c}_0 = (0.2,-0.1)$ and $r=0.6$.\n- Apply the affine map $\\boldsymbol{x} \\mapsto M_2 \\boldsymbol{x} + \\boldsymbol{b}_2$ with\n$$\nM_2 = \\begin{pmatrix} 1.2  0.5 \\\\ 0.2  0.9 \\end{pmatrix}, \\quad \\boldsymbol{b}_2 = \\begin{pmatrix} -0.3 \\\\ 0.15 \\end{pmatrix}.\n$$\n- Anisotropy: $\\theta_2 = \\pi/3$, $a_{\\parallel,2} = 10$, $a_{\\perp,2} = 1$.\n- Linear field: $\\boldsymbol{p}_2 = (1.0,0.4)$, $c_2 = -0.2$.\n\nTest case $3$ (edge case: highly skewed thin parallelogram and strongly rotated anisotropy):\n- Single cell: parallelogram with vertices $\\boldsymbol{v}_0=(0,0)$, $\\boldsymbol{v}_1=(1,0)$, $\\boldsymbol{v}_2=(1+0.8,0.05)$, $\\boldsymbol{v}_3=(0.8,0.05)$, in counterclockwise order.\n- Anisotropy: $\\theta_3 = 5\\pi/12$, $a_{\\parallel,3} = 100$, $a_{\\perp,3} = 1$.\n- Linear field: $\\boldsymbol{p}_3 = (-0.3,2.0)$, $c_3 = 0.1$.\n\nRequired numerical outputs:\n- For each test case $i \\in \\{1,2,3\\}$, compute the maximum absolute face-flux error over all faces across all cells:\n$$\nE_i \\equiv \\max_{\\text{cells }K} \\max_{\\text{edges }e \\subset \\partial K} \\left| (q_K \\cdot \\boldsymbol{n}_e) \\lvert e \\rvert - (q_{\\text{exact}} \\cdot \\boldsymbol{n}_e) \\lvert e \\rvert \\right|,\n$$\nwhere $q_K$ is your discrete cell flux based on the discrete gradient in $K$ and $q_{\\text{exact}} = -A \\boldsymbol{p}_i$.\n- Your program must output a single line with the results as a comma-separated list enclosed in square brackets, in the order $[E_1,E_2,E_3]$.\n\nFinal answer format:\n- Your program must produce exactly one line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[x_1,x_2,x_3]$), with each $x_i$ a floating-point number.", "solution": "The problem statement has been analyzed and is determined to be valid. It is scientifically grounded, well-posed, objective, and provides a complete and consistent set of requirements and data for a problem in the numerical analysis of partial differential equations. The task is to derive and implement a coordinate-free finite volume method and verify its linear exactness property.\n\n## Part 1: Derivation of the Discrete Gradient and Fluxes\n\nOur goal is to derive a discrete approximation to the gradient of a scalar field $u$ on a polygonal cell $K \\subset \\mathbb{R}^2$. The foundation for this derivation is the identity for the average gradient, which is a direct consequence of the Divergence Theorem:\n$$\n(\\nabla u)_K \\equiv \\frac{1}{|K|} \\int_K \\nabla u \\, dV = \\frac{1}{|K|} \\int_{\\partial K} u \\boldsymbol{n} \\, dS\n$$\nHere, $|K|$ is the area of the cell $K$, $\\partial K$ is its boundary, $\\boldsymbol{n}$ is the outward unit normal vector on the boundary, $dV$ is the differential area element, and $dS$ is the differential arc length element. In $\\mathbb{R}^2$, we use $|K|$ for the area and $dl$ for the arc length.\n\nThe boundary $\\partial K$ of a polygon consists of a finite number of straight edges, which we denote by $e_j$. The boundary integral can thus be written as a sum over these edges:\n$$\n\\int_{\\partial K} u \\boldsymbol{n} \\, dl = \\sum_{e_j \\subset \\partial K} \\int_{e_j} u \\boldsymbol{n}_{e_j} \\, dl\n$$\nSince each edge $e_j$ is a straight line segment, its outward unit normal $\\boldsymbol{n}_{e_j}$ is constant along the edge. We can therefore move it outside the integral:\n$$\n\\sum_{e_j \\subset \\partial K} \\int_{e_j} u \\boldsymbol{n}_{e_j} \\, dl = \\sum_{e_j \\subset \\partial K} \\boldsymbol{n}_{e_j} \\int_{e_j} u \\, dl\n$$\nTo proceed, we must approximate the integral $\\int_{e_j} u \\, dl$. A common and effective choice, consistent with second-order accuracy and the principles of barycentric dual methods, is the midpoint rule. This rule approximates the integral by the value of the integrand at the edge midpoint, $\\boldsymbol{x}_{e_j}$, multiplied by the edge length, $|e_j|$:\n$$\n\\int_{e_j} u \\, dl \\approx u(\\boldsymbol{x}_{e_j}) |e_j|\n$$\nThe problem specifies that the unknowns are the values of $u$ at the vertices of the mesh, $u(\\boldsymbol{v}_i)$, and that the value at an edge midpoint should be derived from linear interpolation. For an edge $e_j$ connecting vertices $\\boldsymbol{v}_i$ and $\\boldsymbol{v}_k$, its midpoint is $\\boldsymbol{x}_{e_j} = (\\boldsymbol{v}_i + \\boldsymbol{v}_k)/2$. The value of $u$ at this midpoint is approximated by the average of the values at the vertices:\n$$\nu(\\boldsymbol{x}_{e_j}) \\approx \\frac{u(\\boldsymbol{v}_i) + u(\\boldsymbol{v}_k)}{2}\n$$\nSubstituting these approximations into the gradient formula yields the discrete gradient for cell $K$:\n$$\n\\nabla_K u = \\frac{1}{|K|} \\sum_{e_{jk} \\subset \\partial K} \\frac{u(\\boldsymbol{v}_j) + u(\\boldsymbol{v}_k)}{2} |e_{jk}| \\boldsymbol{n}_{e_{jk}}\n$$\nwhere the sum is over all edges $e_{jk}$ of the cell, connecting vertices $\\boldsymbol{v}_j$ and $\\boldsymbol{v}_k$. For implementation, it is convenient to use the scaled outward normal vector $\\boldsymbol{N}_{e_{jk}} = |e_{jk}|\\boldsymbol{n}_{e_{jk}}$. If the vertices of the cell are ordered counter-clockwise, and edge $e_{jk}$ connects $\\boldsymbol{v}_j=(x_j, y_j)$ to $\\boldsymbol{v}_k=(x_k, y_k)$, then this scaled normal is simply $\\boldsymbol{N}_{e_{jk}} = (y_k - y_j, -(x_k - x_j))$. The formula becomes:\n$$\n\\nabla_K u = \\frac{1}{2|K|} \\sum_{e_{jk} \\subset \\partial K} (u(\\boldsymbol{v}_j) + u(\\boldsymbol{v}_k)) \\boldsymbol{N}_{e_{jk}}\n$$\nThis formula is coordinate-free because it is constructed exclusively from geometric invariants (cell area, vertex coordinates from which edge vectors and normals are derived) and nodal values of the field $u$. It does not depend on a specific choice of coordinate system axes.\n\nFrom the discrete gradient, the cell-wise constant discrete flux vector $q_K$ is defined as:\n$$\nq_K = -A \\nabla_K u\n$$\nwhere $A$ is the constant diffusion tensor. The total flux across an edge $e_j$ from cell $K$ is then given by:\n$$\nF_{e_j} = \\int_{e_j} q_K \\cdot \\boldsymbol{n}_{e_j} \\, dl = (q_K \\cdot \\boldsymbol{n}_{e_j}) |e_j| = q_K \\cdot \\boldsymbol{N}_{e_j}\n$$\n\n## Part 2: Proof of Linear Exactness\n\nA crucial property of a high-quality discretization scheme is linear exactness: the ability to exactly reproduce the gradient of a linear field. We now prove that the derived discrete gradient $\\nabla_K u$ satisfies this property.\n\nLet the scalar field $u$ be a linear function of position $\\boldsymbol{x}$:\n$$\nu(\\boldsymbol{x}) = \\boldsymbol{p} \\cdot \\boldsymbol{x} + c\n$$\nfor a constant vector $\\boldsymbol{p} \\in \\mathbb{R}^2$ and a constant scalar $c \\in \\mathbb{R}$. The exact gradient of this field is $\\nabla u = \\boldsymbol{p}$.\n\nThe value of $u$ at any vertex $\\boldsymbol{v}_i$ is $u(\\boldsymbol{v}_i) = \\boldsymbol{p} \\cdot \\boldsymbol{v}_i + c$. For an edge $e_{jk}$ connecting $\\boldsymbol{v}_j$ and $\\boldsymbol{v}_k$ with midpoint $\\boldsymbol{x}_{e_{jk}}$, the exact value of $u$ at the midpoint is:\n$$\nu(\\boldsymbol{x}_{e_{jk}}) = \\boldsymbol{p} \\cdot \\boldsymbol{x}_{e_{jk}} + c = \\boldsymbol{p} \\cdot \\left(\\frac{\\boldsymbol{v}_j + \\boldsymbol{v}_k}{2}\\right) + c = \\frac{(\\boldsymbol{p} \\cdot \\boldsymbol{v}_j + c) + (\\boldsymbol{p} \\cdot \\boldsymbol{v}_k + c)}{2} = \\frac{u(\\boldsymbol{v}_j) + u(\\boldsymbol{v}_k)}{2}\n$$\nThis shows that our approximation for the midpoint value is exact for any linear field.\n\nFurthermore, the midpoint quadrature rule is exact for integrating linear functions over an interval. Since $u(\\boldsymbol{x})$ varies linearly along any straight edge $e_j$, the integral of $u$ over the edge is exactly the midpoint value times the length:\n$$\n\\int_{e_j} u \\, dl = u(\\boldsymbol{x}_{e_j}) |e_j|\n$$\nTherefore, the sum in our discrete gradient formula is not an approximation but is identical to the continuous boundary integral for a linear field:\n$$\n\\nabla_K u = \\frac{1}{|K|} \\sum_{e_j \\subset \\partial K} u(\\boldsymbol{x}_{e_j}) |e_j| \\boldsymbol{n}_{e_j} = \\frac{1}{|K|} \\int_{\\partial K} u \\boldsymbol{n} \\, dl\n$$\nSubstituting $u(\\boldsymbol{x}) = \\boldsymbol{p} \\cdot \\boldsymbol{x} + c$:\n$$\n\\nabla_K u = \\frac{1}{|K|} \\int_{\\partial K} (\\boldsymbol{p} \\cdot \\boldsymbol{x} + c) \\boldsymbol{n} \\, dl = \\frac{1}{|K|} \\left( \\int_{\\partial K} (\\boldsymbol{p} \\cdot \\boldsymbol{x}) \\boldsymbol{n} \\, dl + c \\int_{\\partial K} \\boldsymbol{n} \\, dl \\right)\n$$\nWe use two standard geometric identities for any closed boundary $\\partial K$ in $\\mathbb{R}^2$:\n$1$. $\\int_{\\partial K} \\boldsymbol{n} \\, dl = \\int_K \\nabla(1) \\, dA = \\boldsymbol{0}$.\n$2$. For any constant vector $\\boldsymbol{p}$, $\\int_{\\partial K} (\\boldsymbol{p} \\cdot \\boldsymbol{x}) \\boldsymbol{n} \\, dl = |K| \\boldsymbol{p}$. This identity can be proven component-wise using the Divergence Theorem. The $i$-th component of the integral is $\\int_{\\partial K} (\\sum_j p_j x_j) n_i \\, dl = \\int_K \\nabla \\cdot ((\\sum_j p_j x_j) \\boldsymbol{e}_i) \\, dA = \\int_K \\frac{\\partial}{\\partial x_i}(\\sum_j p_j x_j) \\, dA = \\int_K p_i \\, dA = p_i |K|$. Summing over components gives $|K|\\boldsymbol{p}$.\n\nApplying these identities to our expression for $\\nabla_K u$:\n$$\n\\nabla_K u = \\frac{1}{|K|} ( |K| \\boldsymbol{p} + c \\cdot \\boldsymbol{0} ) = \\boldsymbol{p}\n$$\nThis proves that the discrete gradient $\\nabla_K u$ is exactly equal to the true gradient $\\nabla u = \\boldsymbol{p}$ for any linear field, on any convex polygon $K$. The property of linear exactness holds irrespective of the cell's shape or the orientation and magnitude of the anisotropy defined by tensor $A$.\n\nBecause $\\nabla_K u = \\boldsymbol{p}$, it immediately follows that the discrete flux $q_K = -A \\nabla_K u$ is equal to the exact flux $q_{\\text{exact}} = -A \\boldsymbol{p}$. Consequently, the discrete flux across any face, $(q_K \\cdot \\boldsymbol{n}_e)|e|$, is identical to the exact flux, $(q_{\\text{exact}} \\cdot \\boldsymbol{n}_e)|e|$. The error metric $E_i$ as defined in the problem statement must therefore be zero, up to the limits of floating-point precision. The following implementation will verify this numerically.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives, implements, and verifies a coordinate-free finite volume discretization\n    of fluxes for the anisotropic diffusion equation, focusing on linear exactness.\n    \"\"\"\n\n    def _calculate_discrete_gradient(cell_verts, vert_values):\n        \"\"\"\n        Calculates the discrete gradient for a single polygonal cell using the\n        coordinate-free formula derived from the Divergence Theorem.\n\n        Args:\n            cell_verts (list of np.ndarray): List of vertex coordinate vectors (CCW order).\n            vert_values (list of float): List of scalar field values at the vertices.\n\n        Returns:\n            np.ndarray: The computed discrete gradient vector for the cell.\n        \"\"\"\n        num_verts = len(cell_verts)\n        area = 0.0\n        grad_sum = np.zeros(2, dtype=np.float64)\n\n        for i in range(num_verts):\n            v_curr = cell_verts[i]\n            v_next = cell_verts[(i + 1) % num_verts]\n            u_curr = vert_values[i]\n            u_next = vert_values[(i + 1) % num_verts]\n\n            # Shoelace formula for signed area. Positive for CCW.\n            area += 0.5 * (v_curr[0] * v_next[1] - v_next[0] * v_curr[1])\n\n            # Edge midpoint value of the field u\n            u_mid = 0.5 * (u_curr + u_next)\n            \n            # Scaled outward normal vector: |e|*n_e = (dy, -dx) for CCW polygons\n            scaled_normal = np.array([v_next[1] - v_curr[1], -(v_next[0] - v_curr[0])], dtype=np.float64)\n            \n            grad_sum += u_mid * scaled_normal\n\n        if abs(area)  1e-15:\n            # Degenerate cell\n            return np.zeros(2, dtype=np.float64)\n            \n        return grad_sum / area\n\n    def _apply_affine_map(mesh, M, b):\n        \"\"\"Applies an affine map to all vertices of a mesh.\"\"\"\n        new_mesh = []\n        for cell in mesh:\n            new_cell = [(M @ v + b) for v in cell]\n            new_mesh.append(new_cell)\n        return new_mesh\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"name\": \"Test Case 1: Moderately skewed multi-cell mesh\",\n            \"mesh_generator\": lambda: _apply_affine_map(\n                [\n                    [np.array([0.0, 0.0]), np.array([0.5, 0.0]), np.array([0.5, 0.5]), np.array([0.0, 0.5])],\n                    [np.array([0.5, 0.0]), np.array([1.0, 0.0]), np.array([1.0, 0.5]), np.array([0.5, 0.5])],\n                    [np.array([0.0, 0.5]), np.array([0.5, 0.5]), np.array([0.5, 1.0]), np.array([0.0, 1.0])],\n                    [np.array([0.5, 0.5]), np.array([1.0, 0.5]), np.array([1.0, 1.0]), np.array([0.5, 1.0])]\n                ],\n                M=np.array([[1.0, 0.3], [0.0, 1.0]]),\n                b=np.array([0.05, -0.02])\n            ),\n            \"anisotropy\": {\"theta\": np.pi / 6, \"a_par\": 5.0, \"a_perp\": 1.0},\n            \"linear_field\": {\"p\": np.array([0.7, -1.1]), \"c\": 0.3},\n        },\n        {\n            \"name\": \"Test Case 2: Single high-order polygon, global skew and rotation\",\n            \"mesh_generator\": lambda: _apply_affine_map(\n                [\n                    [np.array([0.2 + 0.6 * np.cos(2 * np.pi * k / 8), -0.1 + 0.6 * np.sin(2 * np.pi * k / 8)]) for k in range(8)]\n                ],\n                M=np.array([[1.2, 0.5], [0.2, 0.9]]),\n                b=np.array([-0.3, 0.15])\n            ),\n            \"anisotropy\": {\"theta\": np.pi / 3, \"a_par\": 10.0, \"a_perp\": 1.0},\n            \"linear_field\": {\"p\": np.array([1.0, 0.4]), \"c\": -0.2},\n        },\n        {\n            \"name\": \"Test Case 3: Highly skewed thin parallelogram and strong anisotropy\",\n            \"mesh_generator\": lambda: [\n                [np.array([0.0, 0.0]), np.array([1.0, 0.0]), np.array([1.8, 0.05]), np.array([0.8, 0.05])]\n            ],\n            \"anisotropy\": {\"theta\": 5 * np.pi / 12, \"a_par\": 100.0, \"a_perp\": 1.0},\n            \"linear_field\": {\"p\": np.array([-0.3, 2.0]), \"c\": 0.1},\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # 1. Construct mesh for the current test case\n        mesh = case[\"mesh_generator\"]()\n\n        # 2. Construct anisotropy tensor A\n        theta = case[\"anisotropy\"][\"theta\"]\n        a_par = case[\"anisotropy\"][\"a_par\"]\n        a_perp = case[\"anisotropy\"][\"a_perp\"]\n        c, s = np.cos(theta), np.sin(theta)\n        R = np.array([[c, -s], [s, c]])\n        D = np.diag([a_par, a_perp])\n        A = R @ D @ R.T\n\n        # 3. Define linear field and exact flux\n        p = case[\"linear_field\"][\"p\"]\n        c_const = case[\"linear_field\"][\"c\"]\n        q_exact = -A @ p\n\n        max_flux_error = 0.0\n\n        # 4. Iterate over all cells in the mesh\n        for cell_verts in mesh:\n            # Evaluate linear field at vertices\n            vert_values = [(p @ v + c_const) for v in cell_verts]\n            \n            # Compute discrete gradient and flux\n            grad_K_u = _calculate_discrete_gradient(cell_verts, vert_values)\n            q_K = -A @ grad_K_u\n            \n            # 5. Iterate over all edges of the cell\n            num_verts = len(cell_verts)\n            for i in range(num_verts):\n                v_curr = cell_verts[i]\n                v_next = cell_verts[(i + 1) % num_verts]\n\n                # Scaled outward normal vector needed for integrated flux calculation\n                scaled_normal = np.array([v_next[1] - v_curr[1], -(v_next[0] - v_curr[0])])\n                \n                # Compute discrete and exact face fluxes\n                flux_discrete = q_K @ scaled_normal\n                flux_exact = q_exact @ scaled_normal\n                \n                # Update maximum absolute error over all faces\n                error = abs(flux_discrete - flux_exact)\n                if error > max_flux_error:\n                    max_flux_error = error\n        \n        results.append(max_flux_error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3379955"}, {"introduction": "In the Finite Element Method (FEM), the governing equations are expressed in an integral (or 'weak') form, which is then solved numerically. The accuracy of this process hinges on the numerical quadrature rules used to approximate these integrals. This exercise [@problem_id:3380005] bridges the gap between FEM theory and practical implementation by asking you to determine the minimal quadrature accuracy needed. By analyzing the polynomial degree of the terms in the weak form, including a spatially-varying diffusion tensor, you will see how theoretical properties of the PDE and the basis functions dictate concrete computational requirements.", "problem": "Consider the anisotropic diffusion model problem in a bounded Lipschitz domain $\\Omega \\subset \\mathbb{R}^{d}$ with $d \\in \\{2,3\\}$, where the diffusion tensor field $K(x)$ is symmetric positive definite (SPD) for all $x \\in \\Omega$. Let $\\mathcal{T}_{h}$ be a shape-regular simplicial mesh (triangles if $d=2$, tetrahedra if $d=3$) with affine element maps. Let $V_{h}$ be the conforming space of continuous, piecewise linear Lagrange finite elements. The Galerkin bilinear form for the weak formulation is\n$$\na(u_{h},v_{h}) \\;=\\; \\sum_{T \\in \\mathcal{T}_{h}} \\int_{T} \\left(\\nabla v_{h}(x)\\right)^{\\top} K(x)\\, \\nabla u_{h}(x)\\, \\mathrm{d}x,\n$$\nfor $u_{h},v_{h} \\in V_{h}$. Assume that on each element $T \\in \\mathcal{T}_{h}$, the tensor $K(x)$ is affine in $x$, i.e., for $x \\in T$ one has $K(x) = K_{0}^{(T)} + \\sum_{i=1}^{d} x_{i} K_{i}^{(T)}$ with constant matrices $K_{i}^{(T)}$.\n\nYou plan to compute $a(u_{h},v_{h})$ exactly by replacing each element integral by a single-element quadrature rule defined on $T$ (or equivalently on a reference simplex with an affine map), characterized by its algebraic degree of exactness: a rule is said to have algebraic degree $p$ if it integrates exactly every polynomial of total degree at most $p$ on $T$.\n\nDetermine the minimal algebraic degree of exactness required of the element quadrature rule so that, for arbitrary choices of $u_{h},v_{h} \\in V_{h}$ and any affine $K$ as specified above, the computed $a(u_{h},v_{h})$ is exact (i.e., has zero quadrature error). Give your answer as a single integer with no units. No rounding is required.", "solution": "The problem requires the determination of the minimal algebraic degree of exactness for a quadrature rule to exactly compute the element-wise integrals that constitute the Galerlin bilinear form $a(u_{h},v_{h})$. The bilinear form is given by\n$$\na(u_{h},v_{h}) \\;=\\; \\sum_{T \\in \\mathcal{T}_{h}} \\int_{T} \\left(\\nabla v_{h}(x)\\right)^{\\top} K(x)\\, \\nabla u_{h}(x)\\, \\mathrm{d}x\n$$\nwhere the integral is over an element $T$ (a simplex in $\\mathbb{R}^{d}$ for $d \\in \\{2,3\\}$). A quadrature rule is said to have an algebraic degree of exactness $p$ if it can integrate any polynomial of total degree up to $p$ with zero error. To find the minimal required degree $p$, we must determine the maximum possible polynomial degree of the integrand, $I(x) = (\\nabla v_{h}(x))^{\\top} K(x) \\nabla u_{h}(x)$, on any element $T \\in \\mathcal{T}_{h}$.\n\nLet us analyze the polynomial degree of each term in the integrand $I(x)$ on a single element $T$.\n\n1.  **The Finite Element Functions and Their Gradients**: The functions $u_{h}$ and $v_{h}$ belong to the space $V_{h}$ of continuous, piecewise linear Lagrange finite elements. By definition, on any given element $T \\in \\mathcal{T}_{h}$, the restrictions $u_{h}|_{T}$ and $v_{h}|_{T}$ are linear polynomials in the spatial coordinates $x = (x_{1}, \\dots, x_{d})^{\\top}$. A linear polynomial in $d$ variables is a function of the form $f(x) = c_{0} + \\sum_{i=1}^{d} c_{i}x_{i}$, where $c_{0}, \\dots, c_{d}$ are constants. Such a function has a total polynomial degree of $1$.\n\n    The gradient of a linear polynomial is a vector of constants. For example, for $u_{h}|_{T}(x) = c_{0} + \\sum_{i=1}^{d} c_{i}x_{i}$, its gradient is $\\nabla u_{h}(x) = (c_{1}, \\dots, c_{d})^{\\top}$. This is a constant vector for all $x \\in T$. A constant function or vector can be viewed as a polynomial of degree $0$. Therefore, on any element $T$, both $\\nabla u_{h}(x)$ and $\\nabla v_{h}(x)$ are polynomials of degree $0$.\n\n2.  **The Diffusion Tensor**: The problem states that on each element $T$, the diffusion tensor $K(x)$ is affine. This means each component $K_{ij}(x)$ of the tensor $K(x)$ is a linear polynomial in the coordinates $x_1, \\dots, x_d$. Specifically, $K(x) = K_{0}^{(T)} + \\sum_{i=1}^{d} x_{i} K_{i}^{(T)}$, where $K_{i}^{(T)}$ are constant matrices. Consequently, each entry of the matrix $K(x)$ is a polynomial of degree at most $1$. For a generic affine tensor, the degree is exactly $1$.\n\n3.  **The Integrand**: The integrand is the scalar-valued function $I(x) = (\\nabla v_{h})^{\\top} K(x) \\nabla u_{h}$. Let $\\mathbf{c}_{u} = \\nabla u_h$ and $\\mathbf{c}_{v} = \\nabla v_h$ be the constant gradient vectors on the element $T$. The integrand can be written in component form as:\n    $$\n    I(x) = \\sum_{i=1}^{d} \\sum_{j=1}^{d} (\\mathbf{c}_{v})_{i} \\, K_{ij}(x) \\, (\\mathbf{c}_{u})_{j}\n    $$\n    In this expression, $(\\mathbf{c}_{v})_{i}$ and $(\\mathbf{c}_{u})_{j}$ are the constant components of the gradient vectors, so they are polynomials of degree $0$. The term $K_{ij}(x)$ is a polynomial of degree at most $1$. The product of three terms with degrees $0$, $1$, and $0$ respectively results in a polynomial of degree $0+1+0=1$.\n    $$\n    \\text{degree}\\left((\\mathbf{c}_{v})_{i} \\, K_{ij}(x) \\, (\\mathbf{c}_{u})_{j}\\right) = \\text{degree}((\\mathbf{c}_{v})_{i}) + \\text{degree}(K_{ij}(x)) + \\text{degree}((\\mathbf{c}_{u})_{j}) \\le 0 + 1 + 0 = 1\n    $$\n    The integrand $I(x)$ is a finite sum of such terms. The sum of polynomials of degree at most $1$ is itself a polynomial of degree at most $1$. In the general case where $K(x)$ is truly affine (not constant) and the gradients are non-zero, the degree of the integrand will be exactly $1$.\n\nTo ensure that the integral $\\int_{T} I(x) \\, \\mathrm{d}x$ is computed exactly for any choice of $u_h, v_h \\in V_h$ and any valid affine tensor field $K(x)$, the quadrature rule must be exact for all possible integrands. Since the integrand is a polynomial of total degree at most $1$, the quadrature rule must have an algebraic degree of exactness of at least $1$. The question asks for the minimal such degree. Therefore, the minimal required algebraic degree of exactness is $p=1$.", "answer": "$$\\boxed{1}$$", "id": "3380005"}]}