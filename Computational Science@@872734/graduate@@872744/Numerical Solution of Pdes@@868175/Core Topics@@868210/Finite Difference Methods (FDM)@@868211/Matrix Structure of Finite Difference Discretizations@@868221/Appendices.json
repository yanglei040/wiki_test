{"hands_on_practices": [{"introduction": "Moving from theory to practice, our first exercise grounds us in the foundational process of discretization. While uniform grids provide a gentle introduction, real-world applications often demand the flexibility of non-uniform meshes to resolve complex geometries or sharp solution features. This practice guides you through the derivation of the second-derivative matrix on a non-uniform grid, not by rote memorization, but from the physically meaningful principle of conservation. Mastering this finite-volume-flavored derivation equips you with a robust technique to construct discrete operators for any grid, revealing how the local grid spacing directly shapes the entries of the resulting tridiagonal matrix.", "problem": "Consider the linear second-derivative operator $L u = \\frac{d^{2}u}{dx^{2}}$ acting on a sufficiently smooth scalar field $u(x)$ defined over a bounded interval $[a,b]$ with Dirichlet boundary conditions. Let $\\{x_{i}\\}_{i=0}^{n}$ be a strictly monotone nonuniform grid with $x_{0} = a$ and $x_{n} = b$, satisfying $x_{i-1} < x_{i} < x_{i+1}$ for all interior indices $i \\in \\{1,\\dots,n-1\\}$. Define the local spacings by $h_{i+\\frac{1}{2}} = x_{i+1} - x_{i} > 0$ and $h_{i-\\frac{1}{2}} = x_{i} - x_{i-1} > 0$. Using only fundamental definitions (limits and Taylor expansions) and the conservative interpretation of $\\frac{d^{2}u}{dx^{2}}$ as the divergence of the gradient, derive a $3$-point finite difference approximation of $L u$ at an interior node $x_{i}$ that depends solely on the nodal values $u_{i-1}$, $u_{i}$, and $u_{i+1}$, and is consistent to second order under smoothness assumptions on $u$. Then, write the corresponding tridiagonal matrix representation $A$ of the discrete operator mapping the vector of nodal values $(u_{0},u_{1},\\dots,u_{n})^{\\top}$ to the vector of discrete second derivatives $(L_{h}u)_{i}$ at interior nodes $\\{1,\\dots,n-1\\}$, and give explicit formulas for the diagonal entry $A_{i,i}$ and off-diagonal entries $A_{i,i-1}$ and $A_{i,i+1}$ in terms of $h_{i-\\frac{1}{2}}$ and $h_{i+\\frac{1}{2}}$. Your final answer must be the single row of these three entries ordered as $(A_{i,i-1}, A_{i,i}, A_{i,i+1})$, expressed as a closed-form analytic expression. No rounding is required.", "solution": "The problem requires the derivation of a $3$-point finite difference approximation for the second-derivative operator $L u = \\frac{d^{2}u}{dx^{2}}$ on a nonuniform grid. The derivation is to be based on the conservative interpretation of the operator, which is fundamental to the finite volume method and ensures conservation properties in numerical solutions to many physical laws expressed as Partial Differential Equations (PDEs).\n\nThe conservative form of the operator is $L u = \\frac{d}{dx} \\left( \\frac{du}{dx} \\right)$, which expresses the second derivative as the divergence of a flux, where the flux is the gradient $F(x) = \\frac{du}{dx}$.\n\nWe construct a control volume (or cell) $C_i$ around each interior node $x_i$. A natural choice for this control volume is the interval bounded by the midpoints between the nodes: $C_i = [x_{i-\\frac{1}{2}}, x_{i+\\frac{1}{2}}]$, where $x_{i-\\frac{1}{2}} = \\frac{x_{i-1} + x_i}{2}$ and $x_{i+\\frac{1}{2}} = \\frac{x_i + x_{i+1}}{2}$.\n\nThe length of this control volume is given by $\\Delta x_i = x_{i+\\frac{1}{2}} - x_{i-\\frac{1}{2}}$. Using the definitions of the local spacings, $h_{i+\\frac{1}{2}} = x_{i+1} - x_i$ and $h_{i-\\frac{1}{2}} = x_i - x_{i-1}$, we can express this length as:\n$$ \\Delta x_i = \\left(\\frac{x_i + x_{i+1}}{2}\\right) - \\left(\\frac{x_{i-1} + x_i}{2}\\right) = \\frac{x_{i+1} - x_{i-1}}{2} = \\frac{(x_{i+1} - x_i) + (x_i - x_{i-1})}{2} = \\frac{h_{i+\\frac{1}{2}} + h_{i-\\frac{1}{2}}}{2} $$\nThe finite difference approximation $(L_h u)_i$ at node $x_i$ is constructed by averaging the operator $L u$ over the control volume $C_i$ and then discretizing the resulting expression.\n$$ (L_h u)_i \\approx \\frac{1}{\\Delta x_i} \\int_{x_{i-\\frac{1}{2}}}^{x_{i+\\frac{1}{2}}} \\frac{d}{dx} \\left( \\frac{du}{dx} \\right) dx $$\nBy the Fundamental Theorem of Calculus, the integral simplifies to the difference of the flux at the boundaries of the control volume:\n$$ (L_h u)_i \\approx \\frac{1}{\\Delta x_i} \\left[ \\left( \\frac{du}{dx} \\right)_{x_{i+\\frac{1}{2}}} - \\left( \\frac{du}{dx} \\right)_{x_{i-\\frac{1}{2}}} \\right] $$\nNext, we approximate the flux (the first derivative) at the cell faces $x_{i+\\frac{1}{2}}$ and $x_{i-\\frac{1}{2}}$ using second-order accurate central difference approximations based on the adjacent nodal values:\n$$ \\left( \\frac{du}{dx} \\right)_{x_{i+\\frac{1}{2}}} \\approx \\frac{u(x_{i+1}) - u(x_i)}{x_{i+1} - x_i} = \\frac{u_{i+1} - u_i}{h_{i+\\frac{1}{2}}} $$\n$$ \\left( \\frac{du}{dx} \\right)_{x_{i-\\frac{1}{2}}} \\approx \\frac{u(x_i) - u(x_{i-1})}{x_i - x_{i-1}} = \\frac{u_i - u_{i-1}}{h_{i-\\frac{1}{2}}} $$\nSubstituting these flux approximations into the expression for $(L_h u)_i$ yields the discrete operator:\n$$ (L_h u)_i = \\frac{1}{\\frac{h_{i+\\frac{1}{2}} + h_{i-\\frac{1}{2}}}{2}} \\left( \\frac{u_{i+1} - u_i}{h_{i+\\frac{1}{2}}} - \\frac{u_i - u_{i-1}}{h_{i-\\frac{1}{2}}} \\right) $$\nTo determine the entries of the corresponding matrix $A$, we rearrange this expression to identify the coefficients of $u_{i-1}$, $u_i$, and $u_{i+1}$:\n$$ (L_h u)_i = \\frac{2}{h_{i+\\frac{1}{2}} + h_{i-\\frac{1}{2}}} \\left[ \\left(\\frac{1}{h_{i-\\frac{1}{2}}}\\right)u_{i-1} - \\left(\\frac{1}{h_{i-\\frac{1}{2}}} + \\frac{1}{h_{i+\\frac{1}{2}}}\\right)u_i + \\left(\\frac{1}{h_{i+\\frac{1}{2}}}\\right)u_{i+1} \\right] $$\nWe can simplify the coefficient of $u_i$:\n$$ -\\left(\\frac{1}{h_{i-\\frac{1}{2}}} + \\frac{1}{h_{i+\\frac{1}{2}}}\\right) = -\\frac{h_{i+\\frac{1}{2}} + h_{i-\\frac{1}{2}}}{h_{i-\\frac{1}{2}}h_{i+\\frac{1}{2}}} $$\nThe discrete operator is $(L_h u)_i = A_{i,i-1}u_{i-1} + A_{i,i}u_i + A_{i,i+1}u_{i+1}$. The coefficients, which form the $i$-th row of the matrix representation $A$, are:\n\nFor the sub-diagonal entry:\n$$ A_{i,i-1} = \\frac{2}{h_{i+\\frac{1}{2}} + h_{i-\\frac{1}{2}}} \\cdot \\frac{1}{h_{i-\\frac{1}{2}}} = \\frac{2}{h_{i-\\frac{1}{2}}(h_{i-\\frac{1}{2}} + h_{i+\\frac{1}{2}})} $$\nFor the super-diagonal entry:\n$$ A_{i,i+1} = \\frac{2}{h_{i+\\frac{1}{2}} + h_{i-\\frac{1}{2}}} \\cdot \\frac{1}{h_{i+\\frac{1}{2}}} = \\frac{2}{h_{i+\\frac{1}{2}}(h_{i-\\frac{1}{2}} + h_{i+\\frac{1}{2}})} $$\nFor the diagonal entry:\n$$ A_{i,i} = \\frac{2}{h_{i+\\frac{1}{2}} + h_{i-\\frac{1}{2}}} \\cdot \\left(-\\frac{h_{i+\\frac{1}{2}} + h_{i-\\frac{1}{2}}}{h_{i-\\frac{1}{2}}h_{i+\\frac{1}{2}}}\\right) = -\\frac{2}{h_{i-\\frac{1}{2}}h_{i+\\frac{1}{2}}} $$\nA Taylor series analysis shows that the local truncation error of this scheme is $T_i = (L_h u)_i - u''_i = \\frac{h_{i+\\frac{1}{2}} - h_{i-\\frac{1}{2}}}{3}u'''_i + O(h^2_{max})$. The scheme is first-order accurate on a general nonuniform grid. It achieves second-order consistency, as requested, under the condition that the grid spacing changes smoothly, i.e., $|h_{i+\\frac{1}{2}} - h_{i-\\frac{1}{2}}| = O(h^2_{max})$, or on a uniform grid where $h_{i+\\frac{1}{2}} = h_{i-\\frac{1}{2}}$. The derivation method itself is robust and leads to a unique $3$-point stencil.\n\nThe requested entries for the $i$-th row of the matrix $A$, ordered as $(A_{i,i-1}, A_{i,i}, A_{i,i+1})$, are therefore given by the expressions derived above.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{2}{h_{i-\\frac{1}{2}}(h_{i-\\frac{1}{2}} + h_{i+\\frac{1}{2}})} & -\\frac{2}{h_{i-\\frac{1}{2}}h_{i+\\frac{1}{2}}} & \\frac{2}{h_{i+\\frac{1}{2}}(h_{i-\\frac{1}{2}} + h_{i+\\frac{1}{2}})} \\end{pmatrix}}\n$$", "id": "3418706"}, {"introduction": "With a solid understanding of one-dimensional discretization, we now scale our analysis to higher dimensions. This practice explores the elegant structure of the discrete Laplacian matrix in two dimensions, revealing it to be a Kronecker sum of its one-dimensional counterparts. By constructing eigenvectors as tensor products of 1D eigenvectors, you will rigorously derive the full spectrum of the 2D operator. This powerful result is not merely an academic curiosity; it forms the bedrock of fast Fourier transform (FFT) based Poisson solvers and provides critical insight into the behavior and analysis of numerical schemes in multiple dimensions.", "problem": "Consider the two-dimensional Poisson equation with homogeneous Dirichlet boundary conditions on a rectangle,\n$$\n-\\frac{\\partial^{2} u}{\\partial x^{2}}(x,y) - \\frac{\\partial^{2} u}{\\partial y^{2}}(x,y) = f(x,y), \\quad (x,y) \\in (0,L_{x}) \\times (0,L_{y}), \\quad u(x,y) = 0 \\text{ on } \\partial\\big((0,L_{x}) \\times (0,L_{y})\\big).\n$$\nDiscretize the interior of the domain using a uniform grid with $n_{x}$ interior points in the $x$-direction and $n_{y}$ interior points in the $y$-direction, with spacings $h_{x} = \\frac{L_{x}}{n_{x}+1}$ and $h_{y} = \\frac{L_{y}}{n_{y}+1}$. Assemble the standard second-order centered finite difference (finite difference is defined here as a method that replaces derivatives by difference quotients on a grid) matrix $A \\in \\mathbb{R}^{n_{x} n_{y} \\times n_{x} n_{y}}$ approximating the negative Laplacian $-\\Delta$, by lexicographic ordering of interior grid points. Let $T_{n}$ denote the $n \\times n$ tridiagonal matrix with $2$ on the diagonal and $-1$ on the sub- and super-diagonals, which arises from the one-dimensional second-order centered finite difference discretization of the negative second derivative with homogeneous Dirichlet conditions. Then $A$ has the Kronecker sum structure\n$$\nA = \\frac{1}{h_{x}^{2}}\\, T_{n_{x}} \\otimes I_{n_{y}} \\;+\\; \\frac{1}{h_{y}^{2}}\\, I_{n_{x}} \\otimes T_{n_{y}},\n$$\nwhere $I_{m}$ denotes the $m \\times m$ identity matrix, and $\\otimes$ denotes the Kronecker product (the Kronecker product of matrices $X \\in \\mathbb{R}^{a \\times b}$ and $Y \\in \\mathbb{R}^{c \\times d}$ is the block matrix in $\\mathbb{R}^{ac \\times bd}$ defined by $X \\otimes Y = [x_{ij} Y]_{i,j}$).\n\nStarting from the definitions of the one-dimensional second-order centered finite difference operator with homogeneous Dirichlet boundary conditions, and standard properties of the Kronecker product—specifically $(X \\otimes I)(v \\otimes w) = (Xv) \\otimes w$ and $(I \\otimes Y)(v \\otimes w) = v \\otimes (Yw)$—derive the eigenpairs of the one-dimensional matrices $T_{n_{x}}$ and $T_{n_{y}}$, and then construct tensor-product eigenvectors for $A$ to rigorously show that the eigenvalues of $A$ are sums of one-dimensional eigenvalues scaled by $h_{x}$ and $h_{y}$.\n\nYour final task is to provide a single closed-form analytic expression for a generic eigenvalue $\\lambda_{p,q}$ of $A$ corresponding to mode indices $p \\in \\{1,\\dots,n_{x}\\}$ and $q \\in \\{1,\\dots,n_{y}\\}$, expressed only in terms of $p$, $q$, $n_{x}$, $n_{y}$, $h_{x}$, and $h_{y}$. No numerical approximation is required, and no units are to be used in the final expression.", "solution": "The problem statement is evaluated to be valid. It is scientifically grounded, well-posed, and objective. It presents a standard problem in numerical analysis for partial differential equations, with all necessary definitions and constraints provided for a rigorous derivation. The problem is self-contained, consistent, and does not violate any of the criteria for invalidity.\n\nThe derivation proceeds in two main stages as requested: first, determining the eigenpairs of the one-dimensional finite difference matrix $T_n$, and second, using these to construct the eigenpairs of the two-dimensional matrix $A$.\n\n**Part 1: Eigenpairs of the one-dimensional matrix $T_n$**\n\nThe matrix $T_n$ is an $n \\times n$ tridiagonal matrix with $2$ on the main diagonal and $-1$ on the first sub- and super-diagonals. An eigenvalue equation for $T_n$ is given by $T_n v = \\mu v$, where $\\mu$ is an eigenvalue and $v \\in \\mathbb{R}^n$ is the corresponding eigenvector with components $v_j$. The $j$-th row of this matrix-vector equation, for $j \\in \\{1, \\dots, n\\}$, is:\n$$\n-v_{j-1} + 2v_j - v_{j+1} = \\mu v_j.\n$$\nThese equations are complemented by boundary conditions derived from the homogeneous Dirichlet conditions on the continuous problem, which imply $v_0 = 0$ and $v_{n+1} = 0$. The equation can be rewritten as a homogeneous second-order linear difference equation:\n$$\nv_{j+1} + (\\mu - 2)v_j + v_{j-1} = 0.\n$$\nWe seek a solution of the form $v_j = \\sin(j\\theta)$ for some angle $\\theta$. This choice is motivated by the eigenfunctions of the continuous counterpart, the second derivative operator. The boundary condition $v_0 = \\sin(0 \\cdot \\theta) = 0$ is immediately satisfied. The condition at the other boundary, $v_{n+1}=0$, requires:\n$$\n\\sin((n+1)\\theta) = 0.\n$$\nThis implies that $(n+1)\\theta$ must be an integer multiple of $\\pi$. We write $(n+1)\\theta_p = p\\pi$ for an integer index $p$. To obtain $n$ linearly independent eigenvectors, we can choose $p \\in \\{1, 2, \\dots, n\\}$. This gives the angles:\n$$\n\\theta_p = \\frac{p\\pi}{n+1}, \\quad p \\in \\{1, 2, \\dots, n\\}.\n$$\nThus, the components of the $p$-th eigenvector, denoted $v_p^{(n)}$, are given by:\n$$\n(v_p^{(n)})_j = \\sin\\left(\\frac{jp\\pi}{n+1}\\right), \\quad j \\in \\{1, 2, \\dots, n\\}.\n$$\nTo find the corresponding eigenvalue $\\mu_p$, we substitute this solution back into the difference equation:\n$$\n-\\sin\\left(\\frac{(j-1)p\\pi}{n+1}\\right) + 2\\sin\\left(\\frac{jp\\pi}{n+1}\\right) - \\sin\\left(\\frac{(j+1)p\\pi}{n+1}\\right) = \\mu_p \\sin\\left(\\frac{jp\\pi}{n+1}\\right).\n$$\nUsing the trigonometric sum-to-product identity $\\sin(\\alpha-\\beta) + \\sin(\\alpha+\\beta) = 2\\sin(\\alpha)\\cos(\\beta)$, we can simplify the first and third terms on the left-hand side:\n$$\n\\sin\\left(\\frac{jp\\pi}{n+1} - \\frac{p\\pi}{n+1}\\right) + \\sin\\left(\\frac{jp\\pi}{n+1} + \\frac{p\\pi}{n+1}\\right) = 2\\sin\\left(\\frac{jp\\pi}{n+1}\\right)\\cos\\left(\\frac{p\\pi}{n+1}\\right).\n$$\nSubstituting this back, the equation becomes:\n$$\n2\\sin\\left(\\frac{jp\\pi}{n+1}\\right) - 2\\sin\\left(\\frac{jp\\pi}{n+1}\\right)\\cos\\left(\\frac{p\\pi}{n+1}\\right) = \\mu_p \\sin\\left(\\frac{jp\\pi}{n+1}\\right).\n$$\nFactoring out the sine term (which is not identically zero for the eigenvector):\n$$\n\\left[2 - 2\\cos\\left(\\frac{p\\pi}{n+1}\\right)\\right] \\sin\\left(\\frac{jp\\pi}{n+1}\\right) = \\mu_p \\sin\\left(\\frac{jp\\pi}{n+1}\\right).\n$$\nFrom this, we identify the eigenvalue $\\mu_p^{(n)}$ for the matrix $T_n$:\n$$\n\\mu_p^{(n)} = 2 - 2\\cos\\left(\\frac{p\\pi}{n+1}\\right).\n$$\nUsing the half-angle identity $1 - \\cos(2\\alpha) = 2\\sin^2(\\alpha)$, with $\\alpha = \\frac{p\\pi}{2(n+1)}$, we obtain the final form for the eigenvalues of $T_n$:\n$$\n\\mu_p^{(n)} = 4\\sin^2\\left(\\frac{p\\pi}{2(n+1)}\\right), \\quad p \\in \\{1, 2, \\dots, n\\}.\n$$\n\n**Part 2: Eigenpairs of the two-dimensional matrix $A$**\n\nThe matrix $A$ for the 2D problem is given by the Kronecker sum:\n$$\nA = \\frac{1}{h_{x}^{2}}\\, T_{n_{x}} \\otimes I_{n_{y}} \\;+\\; \\frac{1}{h_{y}^{2}}\\, I_{n_{x}} \\otimes T_{n_{y}}.\n$$\nLet $(\\mu_p^{(n_x)}, v_p^{(n_x)})$ be the eigenpairs for $T_{n_x}$ for $p \\in \\{1, \\dots, n_x\\}$ and $(\\mu_q^{(n_y)}, v_q^{(n_y)})$ be the eigenpairs for $T_{n_y}$ for $q \\in \\{1, \\dots, n_y\\}$, as derived in Part 1. We construct candidate eigenvectors for $A$ as tensor products of the one-dimensional eigenvectors:\n$$\nw_{p,q} = v_p^{(n_x)} \\otimes v_q^{(n_y)}.\n$$\nWe now apply the matrix $A$ to this vector $w_{p,q}$:\n$$\nA w_{p,q} = \\left( \\frac{1}{h_{x}^{2}}\\, T_{n_{x}} \\otimes I_{n_{y}} \\;+\\; \\frac{1}{h_{y}^{2}}\\, I_{n_{x}} \\otimes T_{n_{y}} \\right) ( v_p^{(n_x)} \\otimes v_q^{(n_y)} ).\n$$\nBy linearity, we can distribute the vector to each term in the sum:\n$$\nA w_{p,q} = \\frac{1}{h_{x}^{2}}\\, (T_{n_{x}} \\otimes I_{n_{y}}) ( v_p^{(n_x)} \\otimes v_q^{(n_y)} ) \\;+\\; \\frac{1}{h_{y}^{2}}\\, (I_{n_{x}} \\otimes T_{n_{y}}) ( v_p^{(n_x)} \\otimes v_q^{(n_y)} ).\n$$\nUsing the provided properties of the Kronecker product:\n\\begin{align*} (T_{n_{x}} \\otimes I_{n_{y}}) ( v_p^{(n_x)} \\otimes v_q^{(n_y)} ) &= (T_{n_{x}} v_p^{(n_x)}) \\otimes v_q^{(n_y)} \\\\ (I_{n_{x}} \\otimes T_{n_{y}}) ( v_p^{(n_x)} \\otimes v_q^{(n_y)} ) &= v_p^{(n_x)} \\otimes (T_{n_{y}} v_q^{(n_y)}) \\end{align*}\nSince $v_p^{(n_x)}$ and $v_q^{(n_y)}$ are eigenvectors of $T_{n_x}$ and $T_{n_y}$ respectively, we have $T_{n_{x}} v_p^{(n_x)} = \\mu_p^{(n_x)} v_p^{(n_x)}$ and $T_{n_{y}} v_q^{(n_y)} = \\mu_q^{(n_y)} v_q^{(n_y)}$. Substituting these into the expressions above:\n\\begin{align*} (T_{n_{x}} v_p^{(n_x)}) \\otimes v_q^{(n_y)} &= (\\mu_p^{(n_x)} v_p^{(n_x)}) \\otimes v_q^{(n_y)} = \\mu_p^{(n_x)} (v_p^{(n_x)} \\otimes v_q^{(n_y)}) = \\mu_p^{(n_x)} w_{p,q} \\\\ v_p^{(n_x)} \\otimes (T_{n_{y}} v_q^{(n_y)}) &= v_p^{(n_x)} \\otimes (\\mu_q^{(n_y)} v_q^{(n_y)}) = \\mu_q^{(n_y)} (v_p^{(n_x)} \\otimes v_q^{(n_y)}) = \\mu_q^{(n_y)} w_{p,q} \\end{align*}\nSubstituting these results back into the equation for $A w_{p,q}$:\n$$\nA w_{p,q} = \\frac{1}{h_{x}^{2}}\\, (\\mu_p^{(n_x)} w_{p,q}) \\;+\\; \\frac{1}{h_{y}^{2}}\\, (\\mu_q^{(n_y)} w_{p,q}).\n$$\nFactoring out $w_{p,q}$:\n$$\nA w_{p,q} = \\left( \\frac{\\mu_p^{(n_x)}}{h_x^2} + \\frac{\\mu_q^{(n_y)}}{h_y^2} \\right) w_{p,q}.\n$$\nThis is an eigenvalue equation for $A$. The vector $w_{p,q}$ is an eigenvector of $A$, and the corresponding eigenvalue, denoted $\\lambda_{p,q}$, is:\n$$\n\\lambda_{p,q} = \\frac{\\mu_p^{(n_x)}}{h_x^2} + \\frac{\\mu_q^{(n_y)}}{h_y^2}.\n$$\nThis shows that the eigenvalues of the 2D matrix $A$ are sums of the scaled 1D eigenvalues, for $p \\in \\{1, \\dots, n_x\\}$ and $q \\in \\{1, \\dots, n_y\\}$.\n\n**Part 3: Final Expression for the Eigenvalues of $A$**\n\nFinally, we substitute the expressions for the 1D eigenvalues derived in Part 1 into the formula for $\\lambda_{p,q}$:\n$$\n\\mu_p^{(n_x)} = 4\\sin^2\\left(\\frac{p\\pi}{2(n_x+1)}\\right)\n$$\n$$\n\\mu_q^{(n_y)} = 4\\sin^2\\left(\\frac{q\\pi}{2(n_y+1)}\\right)\n$$\nThe eigenvalue $\\lambda_{p,q}$ of $A$ is therefore:\n$$\n\\lambda_{p,q} = \\frac{1}{h_x^2} \\left[ 4\\sin^2\\left(\\frac{p\\pi}{2(n_x+1)}\\right) \\right] + \\frac{1}{h_y^2} \\left[ 4\\sin^2\\left(\\frac{q\\pi}{2(n_y+1)}\\right) \\right].\n$$\nThis is the required closed-form analytic expression for a generic eigenvalue of $A$ in terms of $p$, $q$, $n_{x}$, $n_{y}$, $h_{x}$, and $h_{y}$.\n$$\n\\lambda_{p,q} = \\frac{4}{h_x^2}\\sin^2\\left(\\frac{p\\pi}{2(n_x+1)}\\right) + \\frac{4}{h_y^2}\\sin^2\\left(\\frac{q\\pi}{2(n_y+1)}\\right).\n$$", "answer": "$$\\boxed{\\frac{4}{h_{x}^{2}}\\sin^{2}\\left(\\frac{p\\pi}{2(n_{x}+1)}\\right) + \\frac{4}{h_{y}^{2}}\\sin^{2}\\left(\\frac{q\\pi}{2(n_{y}+1)}\\right)}$$", "id": "3418648"}, {"introduction": "Our final practice introduces a new physical process: advection. Unlike pure diffusion, which gives rise to symmetric matrices, the presence of a first-derivative advection term breaks this symmetry, leading to a non-normal matrix with profoundly different properties. This exercise guides you in discretizing the advection-diffusion operator and analyzing the resulting non-normality by decomposing the matrix into its Hermitian (diffusive) and skew-Hermitian (advective) parts. Quantifying the size of the skew-Hermitian component is essential for understanding numerical stability and is a key factor in the analysis and selection of iterative methods, whose convergence can be highly sensitive to non-normality.", "problem": "Consider the one-dimensional linear operator acting on a sufficiently smooth function $u(x)$ on the interval $[0,1]$ given by $-\\nu\\,u_{xx} + b\\,u_{x}$, where $\\nu>0$ is the diffusion coefficient and $b>0$ is the advection speed. Discretize the interval $[0,1]$ with a uniform grid of $n$ interior points and mesh spacing $h = \\frac{1}{n+1}$, imposing homogeneous Dirichlet boundary conditions $u(0)=u(1)=0$. Use the standard second-order central difference approximation for the second derivative and the first-order upwind approximation for the first derivative appropriate for positive advection speed.\n\nStarting from the definitions of these finite difference approximations and the standard Euclidean inner product on $\\mathbb{C}^{n}$, assemble the $n\\times n$ matrix $A$ representing the discrete operator. Then analyze the nonnormality of $A$ through the field of values (also known as the numerical range) defined by $\\{x^{\\ast}A x / x^{\\ast} x : x \\in \\mathbb{C}^{n}, x \\neq 0\\}$ and the skew-Hermitian part $K = \\frac{1}{2}(A - A^{\\ast})$. In particular, determine the exact closed-form expression of the spectral norm of the skew-Hermitian part, $\\|K\\|_{2}$, in terms of $b$, $h$, and $n$.\n\nExpress your final answer as a single closed-form analytic expression. No rounding is required.", "solution": "The problem requires assembling the matrix for the discretized one-dimensional advection-diffusion operator and then finding the spectral norm of its skew-Hermitian part.\n\n**Step 1: Discretize the Operator and Assemble the Matrix**\nLet $U_j$ be the approximation to $u(x_j)$ on a uniform grid with spacing $h$. The operator is $L u = -\\nu u_{xx} + b u_x$.\nThe second derivative term is discretized using a second-order central difference:\n$$ -\\nu u_{xx}(x_j) \\approx -\\nu \\frac{U_{j+1} - 2U_j + U_{j-1}}{h^2} $$\nFor positive advection speed ($b>0$), the first derivative term is discretized using a first-order upwind (backward) difference:\n$$ b u_x(x_j) \\approx b \\frac{U_j - U_{j-1}}{h} $$\nCombining these at an interior node $j$ gives the discrete equation:\n$$ (AU)_j = -\\nu \\left( \\frac{U_{j+1} - 2U_j + U_{j-1}}{h^2} \\right) + b \\left( \\frac{U_j - U_{j-1}}{h} \\right) $$\nBy rearranging terms based on the nodal indices, we identify the entries for the $j$-th row of the system matrix $A$:\n$$ (AU)_j = \\left(-\\frac{\\nu}{h^2} - \\frac{b}{h}\\right) U_{j-1} + \\left(\\frac{2\\nu}{h^2} + \\frac{b}{h}\\right) U_j - \\frac{\\nu}{h^2} U_{j+1} $$\nThis defines a tridiagonal matrix $A$ where, for $j=1, \\dots, n$:\n-   Sub-diagonal ($A_{j,j-1}$): $-\\frac{\\nu}{h^2} - \\frac{b}{h}$\n-   Diagonal ($A_{j,j}$): $\\frac{2\\nu}{h^2} + \\frac{b}{h}$\n-   Super-diagonal ($A_{j,j+1}$): $-\\frac{\\nu}{h^2}$\nThe homogeneous Dirichlet boundary conditions $U_0 = 0$ and $U_{n+1}=0$ are incorporated in the first and last rows of this structure.\n\n**Step 2: Determine the Skew-Hermitian Part $K$**\nThe skew-Hermitian part of a real matrix $A$ is given by $K = \\frac{1}{2}(A - A^T)$. The symmetric part of $A$, arising from the diffusion term $-\\nu u_{xx}$, cancels out in this difference. The non-symmetric part, from the advection term $b u_x$, remains.\n-   Diagonal entries: $K_{j,j} = \\frac{1}{2}(A_{j,j} - A_{j,j}) = 0$.\n-   Super-diagonal entries: $K_{j,j+1} = \\frac{1}{2}(A_{j,j+1} - A_{j+1,j}) = \\frac{1}{2} \\left( -\\frac{\\nu}{h^2} - \\left(-\\frac{\\nu}{h^2} - \\frac{b}{h}\\right) \\right) = \\frac{b}{2h}$.\n-   Sub-diagonal entries: $K_{j,j-1} = \\frac{1}{2}(A_{j,j-1} - A_{j-1,j}) = \\frac{1}{2} \\left( \\left(-\\frac{\\nu}{h^2} - \\frac{b}{h}\\right) - \\left(-\\frac{\\nu}{h^2}\\right) \\right) = -\\frac{b}{2h}$.\nThe resulting matrix $K$ is a real, skew-symmetric tridiagonal matrix:\n$$ K = \\frac{b}{2h} \\begin{pmatrix}\n0 & 1 & 0 & \\dots & 0 \\\\\n-1 & 0 & 1 & \\dots & 0 \\\\\n0 & -1 & 0 & \\ddots & \\vdots \\\\\n\\vdots & & \\ddots & \\ddots & 1 \\\\\n0 & \\dots & & -1 & 0\n\\end{pmatrix}_{n \\times n} $$\n\n**Step 3: Calculate the Spectral Norm $\\|K\\|_2$**\nSince $K$ is a normal matrix ($K^T K = K K^T$), its spectral norm $\\|K\\|_2$ is equal to its spectral radius, $\\rho(K)$, which is the maximum absolute value of its eigenvalues.\nThe eigenvalues of the base matrix $S_n = \\text{tridiag}(-1, 0, 1)$ are known to be purely imaginary and are given by the formula $\\lambda_k(S_n) = 2i \\cos\\left(\\frac{k\\pi}{n+1}\\right)$ for $k = 1, \\dots, n$.\nThe eigenvalues of $K$ are therefore:\n$$ \\lambda_k(K) = \\frac{b}{2h} \\lambda_k(S_n) = \\frac{b}{h} i \\cos\\left(\\frac{k\\pi}{n+1}\\right) $$\nThe spectral norm is the maximum of the magnitudes of these eigenvalues:\n$$ \\|K\\|_2 = \\max_{k=1,\\dots,n} \\left| \\frac{b i}{h} \\cos\\left(\\frac{k\\pi}{n+1}\\right) \\right| = \\frac{b}{h} \\max_{k=1,\\dots,n} \\left| \\cos\\left(\\frac{k\\pi}{n+1}\\right) \\right| $$\nThe function $|\\cos(\\theta)|$ on the interval $(0, \\pi)$ reaches its maximum at the endpoints of the interval. For the discrete set of angles $\\theta_k = \\frac{k\\pi}{n+1}$, the maximum is achieved for $k=1$ and $k=n$.\n$$ \\max_{k=1,\\dots,n} \\left| \\cos\\left(\\frac{k\\pi}{n+1}\\right) \\right| = \\cos\\left(\\frac{\\pi}{n+1}\\right) $$\nTherefore, the spectral norm of the skew-Hermitian part is:\n$$ \\|K\\|_2 = \\frac{b}{h} \\cos\\left(\\frac{\\pi}{n+1}\\right) $$", "answer": "$$\\boxed{\\frac{b}{h} \\cos\\left(\\frac{\\pi}{n+1}\\right)}$$", "id": "3418668"}]}