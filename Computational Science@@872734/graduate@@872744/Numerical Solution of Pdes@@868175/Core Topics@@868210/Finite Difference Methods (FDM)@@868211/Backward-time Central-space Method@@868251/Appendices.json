{"hands_on_practices": [{"introduction": "The first step in developing any numerical solver is to verify its correctness against a known theoretical benchmark. This exercise guides you through a fundamental validation procedure: implementing the BTCS method for the classic 1D heat equation and performing a grid refinement study. By systematically isolating and measuring the error, you will empirically confirm the method's theoretical convergence rate of $\\mathcal{O}(\\Delta t + \\Delta x^2)$, an essential skill for building robust computational tools [@problem_id:3365331].", "problem": "Consider the one-dimensional heat equation with constant diffusivity on a finite interval with homogeneous Dirichlet boundary conditions. The governing partial differential equation is $u_t = \\alpha u_{xx}$ posed on $x \\in [0,1]$, $t \\in [0,T]$, with boundary conditions $u(0,t)=0$, $u(1,t)=0$, and initial condition $u(x,0)=\\sin(\\pi x)$. The exact solution consistent with these data is $u(x,t)=\\exp(-\\alpha \\pi^2 t)\\sin(\\pi x)$. You will use the backward-time central-space (BTCS) method, defined as backward Euler in time together with the standard second-order central difference stencil in space, to approximate the solution numerically. Begin from the fundamental definitions of consistent spatial finite differences and the backward Euler time discretization, and derive the linear system that must be solved at each time step under Dirichlet boundary conditions. Ensure the algebraic system you derive is dimensionally consistent and respects the boundary values.\n\nYour task is to design and implement a grid refinement experiment to empirically verify the $\\mathcal{O}(\\Delta t+\\Delta x^2)$ convergence behavior of the BTCS method and to demonstrate how to separate temporal and spatial error contributions. Use the discrete $L^2$ norm to quantify errors, defined for a grid function $e_i$ on interior nodes by $\\|e\\|_{L^2_h} = \\sqrt{\\Delta x}\\left(\\sum_i e_i^2\\right)^{1/2}$. The observed rate with respect to a refinement parameter $h$ is to be measured by the slope of the least-squares fit of $\\log(E)$ versus $\\log(h)$ over a refinement sequence, where $E$ denotes the error in $\\| \\cdot \\|_{L^2_h}$.\n\nImplement the following three experiments, each constructed to probe a different facet of the error:\n\n- Spatial-refinement-dominated experiment (to measure the $\\mathcal{O}(\\Delta x^2)$ contribution): fix a very small time step so the temporal error is negligible relative to spatial error. Use $\\alpha = 1$, $T=0.01$, and a target time step $\\Delta t_{\\mathrm{target}}=10^{-5}$. For each $N_x \\in \\{16,32,64,128\\}$, set $\\Delta x = 1/N_x$, set the number of time steps $N_t=\\lceil T/\\Delta t_{\\mathrm{target}} \\rceil$, and then set the actual time step to $\\Delta t = T/N_t$ so that the simulation lands exactly at $t=T$. Compute the discrete $L^2$ error at $t=T$ against the exact solution and estimate the observed spatial rate by fitting $\\log(E)$ against $\\log(\\Delta x)$.\n\n- Temporal-refinement-dominated experiment (to measure the $\\mathcal{O}(\\Delta t)$ contribution): fix a very fine spatial grid so the spatial error is negligible relative to temporal error. Use $\\alpha = 1$, $T=0.01$, fix $N_x=512$ so that $\\Delta x = 1/512$, and perform runs with $N_t \\in \\{4,8,16,32\\}$, i.e., $\\Delta t = T/N_t$. Compute the discrete $L^2$ error at $t=T$ and estimate the observed temporal rate by fitting $\\log(E)$ against $\\log(\\Delta t)$.\n\n- Coupled refinement experiment (to verify the combined $\\mathcal{O}(\\Delta t + \\Delta x^2)$ behavior where contributions are of the same order): use $\\alpha = 1$, $T=0.01$, choose $N_x \\in \\{16,32,64,128\\}$, and set a coupling constant $c=0.4$. For each $N_x$, first compute the nominal $\\Delta t_{\\mathrm{nom}} = c\\,\\Delta x^2$, then set $N_t=\\max\\{1,\\mathrm{round}(T/\\Delta t_{\\mathrm{nom}})\\}$ and use the actual $\\Delta t=T/N_t$. Compute the discrete $L^2$ error at $t=T$ and estimate the observed coupled rates by fitting $\\log(E)$ against $\\log(\\Delta x)$ and separately against $\\log(\\Delta t)$.\n\nIn all experiments, implement BTCS in fully discrete form for the interior points only, treating the Dirichlet boundaries exactly. Construct the linear system based on first principles, without using any pre-packaged partial differential equation solvers. Ensure that the linear algebra is performed consistently for each time step.\n\nTest suite and required outputs:\n\n- Use the three experiments specified above, with the stated parameter values. These three experiments collectively serve as the test suite. They cover a general case, isolate spatial and temporal errors, and include edge cases such as coarse grids ($N_x=16$) and very few time steps ($N_t=4$).\n\n- For the spatial-refinement-dominated experiment, report one float: the estimated spatial order $p_{\\mathrm{space}}$.\n\n- For the temporal-refinement-dominated experiment, report one float: the estimated temporal order $p_{\\mathrm{time}}$.\n\n- For the coupled refinement experiment, report two floats: the estimated order with respect to spatial refinement $p_{\\mathrm{coupled},x}$ and the estimated order with respect to temporal refinement $p_{\\mathrm{coupled},t}$.\n\nFinal output format:\n\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4]\"). The list must be ordered as $[p_{\\mathrm{space}},p_{\\mathrm{time}},p_{\\mathrm{coupled},x},p_{\\mathrm{coupled},t}]$. All outputs must be floats. No physical units are involved in this problem; all quantities are dimensionless.", "solution": "We begin with the fundamental formulation of the one-dimensional heat equation $u_t=\\alpha u_{xx}$ on $x\\in[0,1]$, subject to $u(0,t)=0$, $u(1,t)=0$, and $u(x,0)=\\sin(\\pi x)$. The exact solution for these data is $u(x,t)=\\exp(-\\alpha \\pi^2 t)\\sin(\\pi x)$, which provides a reliable reference to assess numerical error. The backward-time central-space method uses backward Euler in time and the standard second-order central finite difference for the Laplacian in space.\n\nDerivation of the fully discrete scheme follows from core definitions. Let the spatial grid have $N_x$ uniform subintervals with spacing $\\Delta x = 1/N_x$ and interior nodes $x_i=i\\Delta x$ for $i=1,2,\\dots,N_x-1$. Let the time grid have $N_t$ steps with $\\Delta t = T/N_t$ and times $t^n = n\\Delta t$ for $n=0,1,\\dots,N_t$. Define $u_i^n \\approx u(x_i,t^n)$. The backward Euler time discretization is $u_t(x_i,t^{n+1}) \\approx (u_i^{n+1} - u_i^n)/\\Delta t$. The second-order central difference for the second derivative is $u_{xx}(x_i,t^{n+1}) \\approx (u_{i-1}^{n+1} - 2u_i^{n+1} + u_{i+1}^{n+1})/\\Delta x^2$. Substituting these into $u_t=\\alpha u_{xx}$ yields\n$$(u_i^{n+1} - u_i^n)/\\Delta t = \\alpha \\frac{u_{i-1}^{n+1} - 2 u_i^{n+1} + u_{i+1}^{n+1}}{\\Delta x^2}.$$\nRearranging and defining $r = \\alpha \\Delta t / \\Delta x^2$, we obtain the linear system for interior indices $i=1,\\dots,N_x-1$,\n$$-r\\,u_{i-1}^{n+1} + (1+2r)\\,u_i^{n+1} - r\\,u_{i+1}^{n+1} = u_i^n.$$\nThe boundary conditions are $u_0^{n+1}=u_{N_x}^{n+1}=0$, so there are no additional terms on the right-hand side for homogeneous Dirichlet boundaries. In matrix form, for the interior unknown vector $u^{n+1}\\in\\mathbb{R}^{N_x-1}$, we solve\n$$(I - \\Delta t\\,\\alpha\\,L_h) u^{n+1} = u^n,$$\nwhere $L_h$ is the discrete Laplacian operator with second-order central differences scaled by $\\Delta x^{-2}$. The coefficient matrix is strictly diagonally dominant and symmetric positive definite for $\\alpha0$, so the system is uniquely solvable for any $\\Delta t0$. The method is unconditionally stable and exhibits a local truncation error that is first order in time and second order in space for sufficiently smooth solutions; thus the global error for smooth solutions behaves as $\\mathcal{O}(\\Delta t + \\Delta x^2)$.\n\nTo empirically verify this behavior and to separate temporal and spatial contributions, we design three experiments:\n\n1. Spatial-refinement-dominated experiment: fix a very small $\\Delta t$ so that the $\\mathcal{O}(\\Delta t)$ term becomes negligible compared to $\\mathcal{O}(\\Delta x^2)$ across spatial refinements. We use $\\alpha=1$, $T=0.01$, and a target $\\Delta t_{\\mathrm{target}}=10^{-5}$. For each $N_x\\in\\{16,32,64,128\\}$, set $N_t=\\lceil T/\\Delta t_{\\mathrm{target}}\\rceil$ and $\\Delta t=T/N_t$. For each grid we compute the error $E(\\Delta x)$ in the discrete $L^2$ norm at $t=T$ and estimate the spatial order by least-squares fitting of $\\log(E)$ against $\\log(\\Delta x)$. Because $\\Delta t$ is much smaller than $\\Delta x^2$ on the refined grids (for instance, for $N_x=128$, $\\Delta x^2 \\approx 6.10\\times 10^{-5}$ while $\\Delta t=10^{-5}$), the observed slope should be close to $2$.\n\n2. Temporal-refinement-dominated experiment: fix a very fine spatial grid so that the $\\mathcal{O}(\\Delta x^2)$ spatial error is negligible compared to the time discretization error. We use $\\alpha=1$, $T=0.01$, fix $N_x=512$ so that $\\Delta x^2 \\approx 3.81\\times 10^{-6}$, and vary $N_t\\in\\{4,8,16,32\\}$ so that $\\Delta t$ ranges from $2.5\\times 10^{-3}$ down to $3.125\\times 10^{-4}$, all much larger than $\\Delta x^2$. We compute the error $E(\\Delta t)$ and fit $\\log(E)$ against $\\log(\\Delta t)$. The slope should be close to $1$.\n\n3. Coupled refinement experiment: set $\\Delta t = c\\,\\Delta x^2$ (modulo rounding to align the final time), so that the temporal and spatial errors are of the same order. We use $\\alpha=1$, $T=0.01$, $c=0.4$, and $N_x\\in\\{16,32,64,128\\}$. For each $N_x$, compute $\\Delta t_{\\mathrm{nom}}=c\\,\\Delta x^2$, then choose $N_t=\\max\\{1,\\mathrm{round}(T/\\Delta t_{\\mathrm{nom}})\\}$ and $\\Delta t=T/N_t$. Compute the error at $t=T$; when fitting against $\\Delta x$, the error behaves like $\\mathcal{O}(\\Delta x^2)$, yielding an observed slope near $2$. When fitting against $\\Delta t$, use the relation $\\Delta t\\propto \\Delta x^2$ so that the error behaves like $\\mathcal{O}(\\Delta t)$, giving a slope near $1$.\n\nAlgorithmic design details are as follows:\n\n- Assemble the tridiagonal matrix with main diagonal entries $(1+2r)$ and off-diagonals $(-r)$, where $r=\\alpha \\Delta t/\\Delta x^2$. This corresponds to the operator $(I - \\Delta t\\,\\alpha\\,L_h)$ acting on the interior vector.\n\n- Pre-factor the sparse matrix once per choice of $(\\Delta x,\\Delta t)$ using a sparse direct solver to accelerate the repeated solves at each time step.\n\n- Advance in time for $N_t$ steps using the recurrence given by the linear system. The right-hand side at each step is the previous interior vector, since boundary values are zero and constant.\n\n- Evaluate the exact solution at interior grid points $x_i=i\\Delta x$ for $i=1,\\dots,N_x-1$ and $t=T$, compute the discrete $L^2$ norm of the error $e_i=u_i^{N_t}-u(x_i,T)$ as $\\|e\\|_{L^2_h}=\\sqrt{\\Delta x}\\left(\\sum_i e_i^2\\right)^{1/2}$.\n\n- Estimate observed convergence rates as slopes in a least-squares sense using a linear fit of $\\log(E)$ versus $\\log(h)$, where $h$ is $\\Delta x$ or $\\Delta t$ depending on the experiment.\n\nThe final program executes the three experiments, computes the four requested metrics $[p_{\\mathrm{space}},p_{\\mathrm{time}},p_{\\mathrm{coupled},x},p_{\\mathrm{coupled},t}]$, and prints them on a single line as a comma-separated list in square brackets. For a smooth exact solution, we expect values close to $[2,1,2,1]$, up to small deviations due to finite sample sizes, rounding of $N_t$, and the least-squares fit over a small number of refinement levels.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse import diags, csc_matrix\nfrom scipy.sparse.linalg import splu\n\ndef exact_solution(x, t, alpha):\n    # Exact solution: exp(-alpha*pi^2*t) * sin(pi*x)\n    return np.exp(-alpha * (np.pi**2) * t) * np.sin(np.pi * x)\n\ndef build_btcs_solver(alpha, dx, dt, nx_interior):\n    # Build (I - dt*alpha*L_h) where L_h is centered second-difference / dx^2\n    r = alpha * dt / (dx * dx)\n    main = (1.0 + 2.0 * r) * np.ones(nx_interior)\n    off = (-r) * np.ones(nx_interior - 1)\n    A = diags(diagonals=[off, main, off], offsets=[-1, 0, 1], format='csc')\n    # Factorize once for repeated solves\n    solver = splu(A)\n    return solver\n\ndef btcs_heat(alpha, T, Nx, Nt):\n    # Returns interior solution at final time T, and grid spacing dx\n    dx = 1.0 / Nx\n    dt = T / Nt\n    nx_interior = Nx - 1\n    # Interior grid points x_i = i*dx, i = 1..Nx-1\n    x_interior = np.linspace(dx, 1.0 - dx, nx_interior)\n\n    # Initial condition on interior: sin(pi x)\n    u = np.sin(np.pi * x_interior).copy()\n\n    # Pre-factorized solver for the linear system\n    solver = build_btcs_solver(alpha, dx, dt, nx_interior)\n\n    # Time stepping\n    for _ in range(Nt):\n        u = solver.solve(u)\n\n    return u, x_interior, dx, dt\n\ndef discrete_L2_error(u_num, x_interior, dx, T, alpha):\n    u_ex = exact_solution(x_interior, T, alpha)\n    e = u_num - u_ex\n    return np.sqrt(dx) * np.linalg.norm(e, ord=2)\n\ndef observed_order(h_list, E_list):\n    # Fit log(E) = p * log(h) + c\n    logh = np.log(np.array(h_list))\n    logE = np.log(np.array(E_list))\n    p, _ = np.polyfit(logh, logE, 1)\n    return p\n\ndef spatial_refinement_experiment():\n    alpha = 1.0\n    T = 0.01\n    Nx_list = [16, 32, 64, 128]\n    # Target very small dt to suppress temporal error; adjust Nt to land on T\n    dt_target = 1e-5\n    Nt = int(np.ceil(T / dt_target))\n    # Final actual dt used\n    dt_actual = T / Nt\n\n    dx_list = []\n    E_list = []\n    for Nx in Nx_list:\n        u_num, x_interior, dx, _ = btcs_heat(alpha, T, Nx, Nt)\n        E = discrete_L2_error(u_num, x_interior, dx, T, alpha)\n        dx_list.append(dx)\n        E_list.append(E)\n    p_space = observed_order(dx_list, E_list)\n    return p_space\n\ndef temporal_refinement_experiment():\n    alpha = 1.0\n    T = 0.01\n    Nx = 512  # very fine spatial grid to suppress spatial error\n    Nt_list = [4, 8, 16, 32]\n\n    dt_list = []\n    E_list = []\n    for Nt in Nt_list:\n        u_num, x_interior, dx, dt = btcs_heat(alpha, T, Nx, Nt)\n        E = discrete_L2_error(u_num, x_interior, dx, T, alpha)\n        dt_list.append(dt)\n        E_list.append(E)\n    p_time = observed_order(dt_list, E_list)\n    return p_time\n\ndef coupled_refinement_experiment():\n    alpha = 1.0\n    T = 0.01\n    Nx_list = [16, 32, 64, 128]\n    c = 0.4\n\n    dx_list = []\n    dt_list = []\n    E_list = []\n    for Nx in Nx_list:\n        dx = 1.0 / Nx\n        dt_nom = c * dx * dx\n        # Choose Nt so that dt ~ c*dx^2 and T is reached exactly\n        Nt = int(max(1, round(T / dt_nom)))\n        u_num, x_interior, dx_used, dt_used = btcs_heat(alpha, T, Nx, Nt)\n        E = discrete_L2_error(u_num, x_interior, dx_used, T, alpha)\n        dx_list.append(dx_used)\n        dt_list.append(dt_used)\n        E_list.append(E)\n    p_coupled_x = observed_order(dx_list, E_list)\n    p_coupled_t = observed_order(dt_list, E_list)\n    return p_coupled_x, p_coupled_t\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Three experiments: spatial-dominated, temporal-dominated, coupled refinement\n    results = []\n    p_space = spatial_refinement_experiment()\n    results.append(f\"{p_space:.6f}\")\n    p_time = temporal_refinement_experiment()\n    results.append(f\"{p_time:.6f}\")\n    p_cx, p_ct = coupled_refinement_experiment()\n    results.append(f\"{p_cx:.6f}\")\n    results.append(f\"{p_ct:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3365331"}, {"introduction": "While the BTCS method is unconditionally stable for the pure heat equation, its behavior can change when applied to more complex physical systems. This practice moves from computational verification to analytical derivation, challenging you to determine the stability constraints for a reaction-diffusion problem of the form $u_t = \\kappa u_{xx} + \\beta u$. By analyzing the underlying matrix properties, you will derive the sharp condition on the time step required to preserve the non-negativity of the solution, a critical property for many physical models [@problem_id:3365252].", "problem": "Consider the linear reaction–diffusion initial–boundary value problem on the unit interval,\n$$\nu_{t}(x,t) \\;=\\; \\kappa\\,u_{xx}(x,t) \\;+\\; \\beta\\,u(x,t), \\quad x\\in(0,1),\\; t0,\n$$\nwith fixed Dirichlet boundary data\n$$\nu(0,t) \\;=\\; g_{0}(t), \\qquad u(1,t) \\;=\\; g_{1}(t),\n$$\nand initial condition\n$$\nu(x,0) \\;=\\; u_{0}(x),\n$$\nwhere $\\kappa0$ and $\\beta0$ are constants. Assume nonnegativity of the data in the sense that $u_{0}(x)\\ge 0$ for all $x\\in[0,1]$ and $g_{0}(t)\\ge 0$, $g_{1}(t)\\ge 0$ for all $t\\ge 0$.\n\nDiscretize the spatial interval with a uniform grid $x_{i}=i h$, $i=0,1,\\dots,M$, $h=1/M$, and define the time grid $t^{n}=n\\,\\Delta t$, $n\\in\\mathbb{N}$. Let $u_{i}^{n}$ denote the approximation to $u(x_{i},t^{n})$ at interior nodes $i=1,\\dots,M-1$ and times $n\\ge 0$. Apply the backward-time central-space (BTCS) method (backward-time central-space) to obtain, for each time step $n\\to n+1$, a tridiagonal linear system for the interior values $u_{i}^{n+1}$, in which the diffusion ratio\n$$\n\\lambda \\;=\\; \\frac{\\kappa\\,\\Delta t}{h^{2}}\n$$\nappears.\n\nUsing only fundamental properties of monotone matrices and discrete maximum principles, derive from first principles the sharp condition on the time step $\\Delta t$ (expressed in terms of $\\beta$ only) that guarantees the following positivity preservation property for the BTCS update, uniformly for all spatial meshes (equivalently, for all $\\lambda\\ge 0$):\n\nIf $u_{i}^{n}\\ge 0$ for all interior indices $i$ and if the Dirichlet boundary values at the new time level satisfy $g_{0}(t^{n+1})\\ge 0$ and $g_{1}(t^{n+1})\\ge 0$, then the BTCS solution at the next time level satisfies $u_{i}^{n+1}\\ge 0$ for all interior indices $i$.\n\nYour final answer should be a single closed-form analytic expression giving the largest admissible $\\Delta t$ in terms of $\\beta$ only, valid for all $\\lambda\\ge 0$. Do not provide an inequality in your final answer; instead, provide the maximal allowable $\\Delta t$ as an explicit expression. No numerical rounding is required in your final answer. Express your answer in terms of $\\beta$ only.", "solution": "The problem requires the derivation of a sharp condition on the time step $\\Delta t$ that guarantees positivity preservation for the backward-time central-space (BTCS) method applied to the given reaction-diffusion equation, valid for all spatial mesh sizes.\n\nThe partial differential equation (PDE) is given by\n$$u_{t}(x,t) \\;=\\; \\kappa\\,u_{xx}(x,t) \\;+\\; \\beta\\,u(x,t), \\quad x\\in(0,1),\\; t0$$\nwith constants $\\kappa0$ and $\\beta0$. The boundary conditions are $u(0,t) = g_{0}(t)$ and $u(1,t) = g_{1}(t)$, and the initial condition is $u(x,0) = u_{0}(x)$. The data is assumed to be non-negative.\n\nWe first formulate the BTCS numerical scheme. The spatial domain is discretized with a uniform grid $x_{i}=i h$ for $i=0,1,\\dots,M$, where $h=1/M$. The time domain is discretized as $t^{n}=n\\,\\Delta t$. Let $u_{i}^{n}$ denote the numerical approximation of $u(x_{i},t^{n})$.\n\nThe BTCS method discretizes the equation at time level $t^{n+1}$. The time derivative $u_t$ is approximated by a backward difference, and the spatial derivative $u_{xx}$ is approximated by a central difference, both evaluated at $(x_i, t^{n+1})$.\n$$\n\\frac{u_{i}^{n+1} - u_{i}^{n}}{\\Delta t} \\;=\\; \\kappa\\,\\frac{u_{i+1}^{n+1} - 2u_{i}^{n+1} + u_{i-1}^{n+1}}{h^{2}} \\;+\\; \\beta\\,u_{i}^{n+1}\n$$\nThis equation holds for the interior grid points, $i=1, \\dots, M-1$.\n\nWe rearrange the equation to group terms at time level $n+1$ on the left-hand side and terms at time level $n$ on the right-hand side. Multiplying by $\\Delta t$ gives\n$$\nu_{i}^{n+1} - u_{i}^{n} \\;=\\; \\frac{\\kappa\\,\\Delta t}{h^{2}}(u_{i+1}^{n+1} - 2u_{i}^{n+1} + u_{i-1}^{n+1}) \\;+\\; \\beta\\,\\Delta t\\,u_{i}^{n+1}\n$$\nUsing the given diffusion ratio $\\lambda = \\frac{\\kappa\\,\\Delta t}{h^{2}}$, we have\n$$\nu_{i}^{n+1} - u_{i}^{n} \\;=\\; \\lambda(u_{i+1}^{n+1} - 2u_{i}^{n+1} + u_{i-1}^{n+1}) \\;+\\; \\beta\\,\\Delta t\\,u_{i}^{n+1}\n$$\nGrouping the terms with superscript $n+1$ on the left side yields\n$$\n-\\lambda u_{i-1}^{n+1} + (1 + 2\\lambda - \\beta\\Delta t)u_{i}^{n+1} - \\lambda u_{i+1}^{n+1} \\;=\\; u_{i}^{n}\n$$\nThis set of equations for $i=1, \\dots, M-1$ forms a linear system for the unknown vector of interior values $\\mathbf{u}^{n+1} = [u_{1}^{n+1}, u_{2}^{n+1}, \\dots, u_{M-1}^{n+1}]^T$. Let's write this system in matrix form as $A\\mathbf{u}^{n+1} = \\mathbf{b}$.\n\nAt the boundaries of the interior domain, for $i=1$ and $i=M-1$, we incorporate the Dirichlet boundary conditions: $u_{0}^{n+1} = g_{0}(t^{n+1})$ and $u_{M}^{n+1} = g_{1}(t^{n+1})$.\nFor $i=1$:\n$$\n-\\lambda u_{0}^{n+1} + (1 + 2\\lambda - \\beta\\Delta t)u_{1}^{n+1} - \\lambda u_{2}^{n+1} \\;=\\; u_{1}^{n}\n$$\n$$\n(1 + 2\\lambda - \\beta\\Delta t)u_{1}^{n+1} - \\lambda u_{2}^{n+1} \\;=\\; u_{1}^{n} + \\lambda g_{0}(t^{n+1})\n$$\nFor $i=M-1$:\n$$\n-\\lambda u_{M-2}^{n+1} + (1 + 2\\lambda - \\beta\\Delta t)u_{M-1}^{n+1} - \\lambda u_{M}^{n+1} \\;=\\; u_{M-1}^{n}\n$$\n$$\n-\\lambda u_{M-2}^{n+1} + (1 + 2\\lambda - \\beta\\Delta t)u_{M-1}^{n+1} \\;=\\; u_{M-1}^{n} + \\lambda g_{1}(t^{n+1})\n$$\nThe matrix $A$ is an $(M-1) \\times (M-1)$ tridiagonal matrix with entries:\n$$\na_{ii} = 1 + 2\\lambda - \\beta\\Delta t \\quad \\text{for } i=1, \\dots, M-1\n$$\n$$\na_{i,i-1} = a_{i,i+1} = -\\lambda \\quad \\text{for relevant } i\n$$\nThe right-hand side vector $\\mathbf{b}$ has components:\n$$\nb_{1} = u_{1}^{n} + \\lambda g_{0}(t^{n+1})\n$$\n$$\nb_{i} = u_{i}^{n} \\quad \\text{for } i=2, \\dots, M-2\n$$\n$$\nb_{M-1} = u_{M-1}^{n} + \\lambda g_{1}(t^{n+1})\n$$\nThe problem requires that if the solution at the previous time step is non-negative ($u_{i}^{n} \\ge 0$ for all $i$) and the boundary data is non-negative ($g_{0}(t^{n+1}) \\ge 0$, $g_{1}(t^{n+1}) \\ge 0$), then the solution at the new time step must also be non-negative ($u_{i}^{n+1} \\ge 0$ for all $i$).\nGiven that $\\kappa0$, $\\Delta t  0$, and $h0$, we have $\\lambda0$. The assumptions $u_{i}^{n} \\ge 0$, $g_0 \\ge 0$, $g_1 \\ge 0$ ensure that every component of the vector $\\mathbf{b}$ is non-negative, i.e., $\\mathbf{b} \\ge \\mathbf{0}$ (component-wise).\nThe positivity preservation property thus translates to the following matrix property: if $\\mathbf{b} \\ge \\mathbf{0}$, then the solution $\\mathbf{u}^{n+1} = A^{-1}\\mathbf{b}$ must satisfy $\\mathbf{u}^{n+1} \\ge \\mathbf{0}$. This holds if and only if all entries of the inverse matrix $A^{-1}$ are non-negative, i.e., $A^{-1} \\ge 0$. A matrix $A$ with this property is called a monotone matrix.\n\nA sufficient condition for a matrix to be monotone is that it is a non-singular M-matrix. A real square matrix $A=(a_{ij})$ is an M-matrix if it satisfies the following conditions:\n1. $a_{ii}  0$ for all $i$ (positive diagonal entries).\n2. $a_{ij} \\le 0$ for all $i \\ne j$ (a Z-matrix).\n3. $A$ is non-singular and $A^{-1}$'s entries are all non-negative. A common way to ensure this is to show that $A$ is strictly or irreducibly diagonally dominant.\n\nLet's check these conditions for our matrix $A$.\nCondition 2: The off-diagonal entries are $a_{i,j} = -\\lambda$. Since $\\lambda = \\frac{\\kappa \\Delta t}{h^2} \\ge 0$, this condition is satisfied. $A$ is a Z-matrix.\nCondition 1: The diagonal entries must be positive: $a_{ii} = 1 + 2\\lambda - \\beta\\Delta t  0$. This condition must hold for all possible choices of the spatial grid, which means it must hold for all $\\lambda \\ge 0$. The expression $1 + 2\\lambda - \\beta\\Delta t$ is a linear function of $\\lambda$. Its minimum value over the domain $\\lambda \\ge 0$ occurs at $\\lambda=0$. Thus, for the inequality to hold for all $\\lambda \\ge 0$, it must hold at this minimum:\n$$\n1 + 2(0) - \\beta\\Delta t  0 \\implies 1 - \\beta\\Delta t  0 \\implies \\Delta t  \\frac{1}{\\beta}\n$$\nLet's analyze diagonal dominance as an alternative path, which establishes non-singularity and monotonicity for an M-matrix candidate. A matrix $A$ is irreducibly diagonally dominant if it is irreducible, weakly diagonally dominant in all rows ($|a_{ii}| \\ge \\sum_{j\\ne i} |a_{ij}|$), and strictly diagonally dominant in at least one row ($|a_{ii}|  \\sum_{j\\ne i} |a_{ij}|$).\nFor our matrix $A$, which is a tridiagonal matrix with non-zero off-diagonals, it is irreducible.\nThe weak diagonal dominance condition for rows $i=2, \\dots, M-2$ is:\n$$\n|1 + 2\\lambda - \\beta\\Delta t| \\ge |-\\lambda| + |-\\lambda| = 2\\lambda\n$$\nAssuming the diagonal is positive, this is $1 + 2\\lambda - \\beta\\Delta t \\ge 2\\lambda$, which simplifies to $1 - \\beta\\Delta t \\ge 0$.\nFor the first and last rows ($i=1, M-1$), the condition is:\n$$\n|1 + 2\\lambda - \\beta\\Delta t| \\ge |-\\lambda| = \\lambda\n$$\nwhich simplifies to $1 + 2\\lambda - \\beta\\Delta t \\ge \\lambda$, or $1 + \\lambda - \\beta\\Delta t \\ge 0$.\nFor the condition to hold for all rows and all $\\lambda \\ge 0$, the most restrictive of these must be satisfied. This is clearly $1 - \\beta\\Delta t \\ge 0$, which implies $\\Delta t \\le 1/\\beta$.\n\nLet's verify that $\\Delta t \\le 1/\\beta$ is a sufficient condition. If $\\Delta t \\le 1/\\beta$, then $1 - \\beta\\Delta t \\ge 0$.\n- The diagonal entry is $a_{ii} = (1 - \\beta\\Delta t) + 2\\lambda \\ge 2\\lambda$. For any valid discretization ($\\Delta t0, h0$), we have $\\lambda  0$, so $a_{ii}  0$.\n- The off-diagonal entries are $-\\lambda \\le 0$.\n- We have established weak diagonal dominance for all rows: $a_{ii} \\ge 2\\lambda$ for interior rows and $a_{ii} \\ge 2\\lambda  \\lambda$ for boundary rows.\nThe matrix $A$ is irreducibly diagonally dominant. Such a matrix is a non-singular M-matrix, and its inverse $A^{-1}$ has all positive entries. Therefore, if $\\Delta t \\le 1/\\beta$, positivity is preserved for any choice of $h  0$.\n\nNow we must show this condition is sharp (necessary). Suppose we choose a time step $\\Delta t$ such that $\\Delta t  1/\\beta$. Let $\\Delta t = (1+\\epsilon)/\\beta$ for some $\\epsilon  0$. Then $1 - \\beta\\Delta t = -\\epsilon  0$.\nThe diagonal entries of $A$ become $a_{ii} = 1 + 2\\lambda - \\beta\\Delta t = 2\\lambda - \\epsilon$.\nThe condition on positivity preservation must hold for all spatial meshes, meaning for all values $\\lambda \\ge 0$. We are free to choose a mesh size $h$ that results in any $\\lambda$. If we choose a coarse mesh (large $h$) or a small $\\kappa$, we can make $\\lambda$ arbitrarily small. Specifically, we can choose $h$ such that $\\lambda = \\frac{\\kappa \\Delta t}{h^2}  \\frac{\\epsilon}{2}$.\nFor such a choice, the diagonal entries $a_{ii} = 2\\lambda - \\epsilon$ become negative. A matrix with negative diagonal entries cannot be an M-matrix, and positivity is not guaranteed.\nTo see this explicitly, consider the limit $\\lambda \\to 0$. The system matrix $A$ approaches $(1-\\beta\\Delta t)I = -\\epsilon I$, where $I$ is the identity matrix. The linear system becomes approximately $-\\epsilon \\mathbf{u}^{n+1} = \\mathbf{u}^n$. If we start with $\\mathbf{u}^n  \\mathbf{0}$, the next solution is $\\mathbf{u}^{n+1} \\approx -\\frac{1}{\\epsilon}\\mathbf{u}^n$, which is negative. This violates positivity.\nTherefore, the condition $\\Delta t \\le 1/\\beta$ is necessary.\n\nSince the condition $\\Delta t \\le 1/\\beta$ is both necessary and sufficient for positivity preservation for all $\\lambda \\ge 0$, the sharp condition is a boundary case of this inequality. The largest admissible value for $\\Delta t$ is the maximum value that satisfies this condition.\n\nThe largest admissible $\\Delta t$ is $\\frac{1}{\\beta}$.", "answer": "$$\\boxed{\\frac{1}{\\beta}}$$", "id": "3365252"}, {"introduction": "Beyond formal accuracy, the practical utility of a numerical scheme often depends on its qualitative behavior, such as its ability to handle stiffness and damp spurious oscillations. This hands-on experiment places the BTCS method in the context of a viscous substep in computational fluid dynamics, comparing its performance against the well-known Crank-Nicolson method [@problem_id:3365299]. You will numerically measure the damping of high-frequency modes, providing direct insight into why the L-stability of BTCS is a highly desirable feature for solving stiff problems.", "problem": "Consider the viscous substep that arises in semi-implicit treatments of the incompressible Navier–Stokes equations, where the convective term is handled explicitly and the viscous term is handled implicitly. In the absence of the convective contribution, the substep reduces to the linear diffusion equation for a single velocity component, which is the one-dimensional heat equation\n$$\n\\partial_t u(x,t) = \\nu \\,\\partial_{xx} u(x,t),\n$$\nposed on a periodic interval of length $1$, with kinematic viscosity $\\nu  0$. You must analyze and implement three time-integration strategies for the implicit diffusion substep on a uniform periodic grid.\n\nFundamental base and discretization framework:\n- Use a uniform grid with $N$ points and grid spacing $h = 1/N$. Let the unknown at grid point $j$ and time level $n$ be denoted by $u_j^n$, where $j \\in \\{0,1,\\dots,N-1\\}$.\n- Approximate the Laplacian using the standard second-order central difference with periodic wrap:\n$$\n(\\Delta_h u)_j = \\frac{u_{j+1} - 2 u_j + u_{j-1}}{h^2},\n$$\nwhere indices are taken modulo $N$.\n- Introduce the dimensionless step size parameter\n$$\nr = \\frac{\\nu\\,\\Delta t}{h^2},\n$$\nwhere $\\Delta t$ is the time step.\n\nTime discretizations to implement:\n- Backward-Time Central-Space (BTCS): the backward Euler time discretization with the above spatial discretization. This is the standard unconditionally stable implicit scheme for diffusion obtained by replacing $\\partial_t u$ by a backward difference and $\\partial_{xx} u$ by the central difference at the new time level.\n- Crank–Nicolson (CN): the trapezoidal (time-centered) method for the diffusion substep, obtained by the average of the spatial operator at time levels $n$ and $n+1$.\n- Crank–Nicolson with Rannacher startup: replace the first full $\\Delta t$ step by two backward Euler half-steps of size $\\Delta t/2$ (with the same spatial operator) to provide additional damping of high-frequency components. For the purpose of this problem, you will only consider the propagation over one total time step $\\Delta t$ implemented as two backward Euler solves of size $\\Delta t/2$; no subsequent steps are taken.\n\nAssessment task:\n- Consider the highest-resolvable spatial Fourier mode on the periodic grid, given by the grid function $v_j = (-1)^j$. This is an eigenvector of the discrete Laplacian on the uniform periodic grid. For each of the three schemes listed above, define the one-step amplification magnitude as follows: starting from $u^0 = v$, compute $u^1$ after one total time step $\\Delta t$ according to the scheme, and report the ratio\n$$\nG = \\frac{\\|u^1\\|_2}{\\|u^0\\|_2},\n$$\nwhere $\\|\\cdot\\|_2$ is the Euclidean norm. This quantity measures viscous damping for that highest-frequency mode. Because the grid operator is circulant, $v$ is an eigenvector and $G$ coincides with the magnitude of the corresponding scalar amplification factor.\n- Your program must construct the periodic discrete Laplacian matrix corresponding to the central difference, form the linear systems implied by each time discretization, and compute $G$ numerically via linear algebra for the specified parameter sets below. Do not use any pre-derived closed-form amplification formulas in your implementation; the result should follow from assembling and applying the linear systems.\n\nTest suite:\n- Use viscosity $\\nu = 0.01$ and grid size $N = 64$ (so $h = 1/64$).\n- Evaluate the one-step amplification magnitude $G$ for each of the following three time steps $\\Delta t$:\n  - Small step: $\\Delta t = 0.0005$.\n  - Moderate step: $\\Delta t = 0.005$.\n  - Large step: $\\Delta t = 0.05$.\n- For each $\\Delta t$, compute and report the triple of amplification magnitudes in the order: BTCS, CN, CN with Rannacher startup (two backward Euler half-steps).\n\nFinal output specification:\n- Your program should produce a single line of output containing all nine results as a comma-separated list enclosed in square brackets, ordered by increasing $\\Delta t$ and, for each $\\Delta t$, by the scheme order specified above. Explicitly, the output format must be\n$$\n[\\text{G\\_BTCS}(\\Delta t_1),\\text{G\\_CN}(\\Delta t_1),\\text{G\\_Rannacher}(\\Delta t_1),\\text{G\\_BTCS}(\\Delta t_2),\\text{G\\_CN}(\\Delta t_2),\\text{G\\_Rannacher}(\\Delta t_2),\\text{G\\_BTCS}(\\Delta t_3),\\text{G\\_CN}(\\Delta t_3),\\text{G\\_Rannacher}(\\Delta t_3)],\n$$\nwhere $\\Delta t_1 = 0.0005$, $\\Delta t_2 = 0.005$, and $\\Delta t_3 = 0.05$. Each number must be rounded to $6$ decimal places. No other text should be printed.", "solution": "The problem requires an analysis and numerical implementation of three implicit time-integration schemes for the one-dimensional diffusion equation, $\\partial_t u = \\nu \\partial_{xx} u$, on a periodic domain. The objective is to compute the one-step amplification magnitude for the highest-frequency Fourier mode on a discrete grid.\n\nThe governing partial differential equation (PDE) is the heat equation:\n$$\n\\partial_t u(x,t) = \\nu \\,\\partial_{xx} u(x,t)\n$$\nwhere $u(x,t)$ is the quantity of interest (e.g., a velocity component), $x \\in [0,1)$ is the spatial coordinate with periodic boundary conditions, $t$ is time, and $\\nu  0$ is the constant kinematic viscosity.\n\nWe first discretize the spatial domain. A uniform grid with $N$ points is used, with grid spacing $h = 1/N$. The grid points are $x_j = j h$ for $j \\in \\{0, 1, \\dots, N-1\\}$. Let $U(t)$ be the column vector of grid values at time $t$, $U(t) = [u(x_0,t), u(x_1,t), \\dots, u(x_{N-1},t)]^T$. The second spatial derivative $\\partial_{xx} u$ is approximated using the standard second-order central difference operator with periodic boundary conditions:\n$$\n(\\Delta_h u)_j = \\frac{u_{j+1} - 2u_j + u_{j-1}}{h^2}\n$$\nwhere indices are taken modulo $N$. This spatial discretization transforms the PDE into a system of ordinary differential equations (ODEs):\n$$\n\\frac{d U}{dt} = \\nu A U(t)\n$$\nHere, $A$ is the $N \\times N$ matrix representation of the discrete Laplacian operator $\\Delta_h$. It is a real, symmetric, circulant matrix given by:\n$$\nA = \\frac{1}{h^2}\n\\begin{pmatrix}\n-2  1  0  \\dots  0  1 \\\\\n1  -2  1  \\ddots   0 \\\\\n0  1  -2  \\ddots  \\ddots  \\vdots \\\\\n\\vdots  \\ddots  \\ddots  \\ddots  1  0 \\\\\n0   \\ddots  1  -2  1 \\\\\n1  0  \\dots  0  1  -2\n\\end{pmatrix}\n$$\nLet $U^n$ denote the numerical approximation of $U(t)$ at time $t_n = n \\Delta t$. We now introduce the three time-stepping schemes.\n\n1.  **Backward-Time Central-Space (BTCS)**: This scheme uses a first-order backward Euler method for the time derivative, evaluating the spatial term at the future time level $n+1$.\n    $$\n    \\frac{U^{n+1} - U^n}{\\Delta t} = \\nu A U^{n+1}\n    $$\n    Rearranging terms to solve for $U^{n+1}$ yields the linear system:\n    $$\n    (I - \\nu \\Delta t A) U^{n+1} = U^n\n    $$\n    where $I$ is the $N \\times N$ identity matrix.\n\n2.  **Crank–Nicolson (CN)**: This scheme is based on the second-order trapezoidal rule for time integration, averaging the spatial term at time levels $n$ and $n+1$.\n    $$\n    \\frac{U^{n+1} - U^n}{\\Delta t} = \\frac{\\nu A}{2} (U^n + U^{n+1})\n    $$\n    Grouping terms involving $U^{n+1}$ on the left-hand side and terms involving $U^n$ on the right-hand side, we obtain the linear system:\n    $$\n    \\left(I - \\frac{\\nu \\Delta t}{2} A\\right) U^{n+1} = \\left(I + \\frac{\\nu \\Delta t}{2} A\\right) U^n\n    $$\n\n3.  **Crank–Nicolson with Rannacher Startup**: This procedure damps high-frequency oscillations by taking two backward Euler steps, each with a half time step $\\Delta t/2$. For this problem, this two-step procedure constitutes the entire evolution over one full time step $\\Delta t$.\n    - Step 1 (from $t_n$ to $t_{n+1/2} = t_n + \\Delta t/2$):\n      $$\n      \\left(I - \\nu \\frac{\\Delta t}{2} A\\right) U^{n+1/2} = U^n\n      $$\n    - Step 2 (from $t_{n+1/2}$ to $t_{n+1} = t_n + \\Delta t$):\n      $$\n      \\left(I - \\nu \\frac{\\Delta t}{2} A\\right) U^{n+1} = U^{n+1/2}\n      $$\n    Solving the first equation for $U^{n+1/2}$ and substituting into the second gives the overall update:\n    $$\n    U^{n+1} = \\left(I - \\nu \\frac{\\Delta t}{2} A\\right)^{-1} \\left[ \\left(I - \\nu \\frac{\\Delta t}{2} A\\right)^{-1} U^n \\right] = \\left(I - \\nu \\frac{\\Delta t}{2} A\\right)^{-2} U^n\n    $$\n    Numerically, this is implemented by solving two sequential linear systems with the same system matrix.\n\nThe assessment task is to compute the one-step amplification magnitude, $G = \\|U^1\\|_2 / \\|U^0\\|_2$, for the specific initial condition $U^0$ corresponding to the grid function $v_j = (-1)^j$. This function represents the highest-resolvable spatial frequency on the periodic grid. Since $v_j$ is an eigenvector of the circulant matrix $A$, the resulting vector $U^1$ will be a scalar multiple of $U^0$, and $G$ will be the magnitude of this scalar multiplier (the amplification factor). The numerical procedure is as follows:\n- Construct the matrix $A$ for the given $N=64$ and $h=1/64$.\n- Construct the initial vector $U^0$ with elements $(U^0)_j = (-1)^j$.\n- For each scheme and each given $\\Delta t$:\n    - Assemble the corresponding matrix or matrices for the linear system(s).\n    - Solve for the solution vector $U^1$.\n    - Compute the Euclidean norms $\\|U^1\\|_2$ and $\\|U^0\\|_2$.\n    - Calculate the ratio $G = \\|U^1\\|_2 / \\|U^0\\|_2$.\nThe results are then reported for the specified set of parameters.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Analyzes three time-integration schemes for the 1D heat equation by\n    computing the amplification magnitude for the highest-frequency Fourier mode.\n    \"\"\"\n    # Define parameters from the problem statement\n    nu = 0.01\n    N = 64\n    h = 1.0 / N\n\n    # Define the test cases for the time step delta_t\n    test_cases = [0.0005, 0.005, 0.05]\n\n    # Construct the initial condition vector u0 for the highest-frequency mode\n    # u_j = (-1)^j\n    j_indices = np.arange(N)\n    u0 = (-1.0)**j_indices\n    norm_u0 = np.linalg.norm(u0)\n\n    # Construct the discrete Laplacian matrix A\n    # A = (1/h^2) * L, where L is circulant with (-2, 1, ..., 1) in the first row.\n    diag_val = -2.0\n    off_diag_val = 1.0\n    \n    A_unscaled = np.diag(diag_val * np.ones(N)) + \\\n                 np.diag(off_diag_val * np.ones(N - 1), k=1) + \\\n                 np.diag(off_diag_val * np.ones(N - 1), k=-1)\n    \n    # Apply periodic boundary conditions for the corners\n    A_unscaled[0, N - 1] = off_diag_val\n    A_unscaled[N - 1, 0] = off_diag_val\n\n    A = A_unscaled / (h**2)\n\n    all_results = []\n\n    # Iterate through each test case (each delta_t)\n    for delta_t in test_cases:\n        # 1. Backward-Time Central-Space (BTCS)\n        # (I - nu * dt * A) * u1 = u0\n        mat_btcs = np.identity(N) - nu * delta_t * A\n        u1_btcs = np.linalg.solve(mat_btcs, u0)\n        g_btcs = np.linalg.norm(u1_btcs) / norm_u0\n        all_results.append(g_btcs)\n\n        # 2. Crank-Nicolson (CN)\n        # (I - nu*dt/2 * A) * u1 = (I + nu*dt/2 * A) * u0\n        mat_cn_lhs = np.identity(N) - (nu * delta_t / 2.0) * A\n        mat_cn_rhs = np.identity(N) + (nu * delta_t / 2.0) * A\n        rhs_cn = mat_cn_rhs @ u0\n        u1_cn = np.linalg.solve(mat_cn_lhs, rhs_cn)\n        g_cn = np.linalg.norm(u1_cn) / norm_u0\n        all_results.append(g_cn)\n        \n        # 3. Rannacher Startup (two BTCS half-steps)\n        # (I - nu*dt/2 * A) * u_half = u0\n        # (I - nu*dt/2 * A) * u1 = u_half\n        # The matrix is the same as the CN left-hand side matrix.\n        mat_rannacher = mat_cn_lhs\n        u_half = np.linalg.solve(mat_rannacher, u0)\n        u1_rannacher = np.linalg.solve(mat_rannacher, u_half)\n        g_rannacher = np.linalg.norm(u1_rannacher) / norm_u0\n        all_results.append(g_rannacher)\n\n    # Format the final output string to 6 decimal places per number\n    # The format '{:.6f}'.format is used to ensure trailing zeros are printed.\n    print(f\"[{','.join(map('{:.6f}'.format, all_results))}]\")\n\nsolve()\n\n```", "id": "3365299"}]}