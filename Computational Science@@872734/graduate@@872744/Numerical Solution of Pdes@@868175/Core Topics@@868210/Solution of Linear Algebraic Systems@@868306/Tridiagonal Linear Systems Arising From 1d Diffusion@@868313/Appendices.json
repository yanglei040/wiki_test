{"hands_on_practices": [{"introduction": "Understanding the tridiagonal system begins with the steady-state case, which gives rise to the fundamental linear system $L_h \\mathbf{u} = \\mathbf{f}$. This practice explores the 1D Poisson equation, where you will derive the inverse of the discrete Laplacian matrix $L_h$, known as the discrete Green's function. By comparing the discrete solution with its continuous counterpart, you will precisely quantify the scheme's accuracy and gain insight into the nature of discretization error [@problem_id:3458571].", "problem": "Consider the steady one-dimensional diffusion boundary value problem for the scalar field $u(x)$ on the unit interval with homogeneous Dirichlet boundary conditions,\n$$\n-u''(x) = f(x), \\quad x \\in (0,1), \\qquad u(0)=0, \\quad u(1)=0,\n$$\nwhere $f(x)$ is a smooth forcing. The continuous solution can be represented using the Green’s function. Discretize the interval by $N$ interior points with uniform spacing $h = \\frac{1}{N+1}$, and let $x_i = i h$ for $i \\in \\{1,2,\\dots,N\\}$. Define the standard second-order centered finite difference discretization of the negative second derivative by the tridiagonal operator $L_h$,\n$$\n(L_h \\mathbf{u})_i := \\frac{-u_{i-1} + 2 u_i - u_{i+1}}{h^2}, \\quad i \\in \\{1,2,\\dots,N\\},\n$$\nwith boundary conditions enforced by $u_0 = 0$ and $u_{N+1}=0$. The discrete system is $L_h \\mathbf{u} = \\mathbf{f}$, where $\\mathbf{f}_i := f(x_i)$.\n\nLet the forcing be $f(x) = \\sin(\\pi x)$. Define the discrete Green’s function as the matrix $G^{(h)} := L_h^{-1} \\in \\mathbb{R}^{N \\times N}$ so that the discrete solution is the discrete convolution\n$$\nu_i^{(h)} = \\sum_{j=1}^{N} G^{(h)}_{ij} f(x_j), \\quad i \\in \\{1,2,\\dots,N\\}.\n$$\nSimilarly, the continuous solution admits the Green’s function representation\n$$\nu(x) = \\int_{0}^{1} G(x,\\xi)\\, f(\\xi)\\, d\\xi,\n$$\nwhere $G(x,\\xi)$ is the Green’s function for the operator $-d^2/dx^2$ with homogeneous Dirichlet boundary conditions on $(0,1)$.\n\nAssume $N$ is odd so that the midpoint $x_{i_*} = \\frac{1}{2}$ is a grid point with $i_* = \\frac{N+1}{2}$. Starting from fundamental definitions (the discrete operator, the definition of a Green’s function, and the continuous Green’s function for the Dirichlet problem on an interval), perform the following steps:\n\n(1) Derive the explicit entries of the discrete Green’s function $G^{(h)} = L_h^{-1}$ in terms of $i$, $j$, $N$, and $h$. Use this to express $u_{i_*}^{(h)}$ as a closed-form expression in $h$ and universal constants for the given forcing $f(x)=\\sin(\\pi x)$.\n\n(2) Write down the continuous Green’s function $G(x,\\xi)$ for the operator $-d^2/dx^2$ with homogeneous Dirichlet boundary conditions on $(0,1)$, and evaluate the continuous solution $u(x_{i_*})$ by carrying out the integral against $f(\\xi)=\\sin(\\pi \\xi)$.\n\n(3) Using your results from parts (1) and (2), determine the leading-order asymptotic consistency constant at the midpoint by computing\n$$\nC \\;=\\; \\lim_{h \\to 0} \\frac{u_{i_*}^{(h)} - u(x_{i_*})}{h^2}.\n$$\n\nProvide $C$ as a single exact number with no units. No numerical rounding is required; give your answer in exact form.", "solution": "The user wants to analyze the accuracy of a finite difference scheme for the 1D Poisson equation at the domain's midpoint. This involves three steps: deriving the discrete solution, finding the continuous solution, and then computing the limit of their normalized difference as the mesh spacing $h$ approaches zero.\n\n### Part (1): Discrete Green's Function and Solution\n\nThe problem is to solve the discrete system $L_h \\mathbf{u} = \\mathbf{f}$, where the operator $L_h$ is represented by the $N \\times N$ matrix\n$$\nL_h = \\frac{1}{h^2}\n\\begin{pmatrix}\n2 & -1 & & & \\\\\n-1 & 2 & -1 & & \\\\\n& \\ddots & \\ddots & \\ddots & \\\\\n& & -1 & 2 & -1 \\\\\n& & & -1 & 2\n\\end{pmatrix}.\n$$\nThe discrete Green's function $G^{(h)}$ is the inverse of this matrix, $G^{(h)} = L_h^{-1}$. We must first find the entries $G^{(h)}_{ij}$. The definition $L_h G^{(h)} = I$ (the identity matrix) implies that for each column $j$, we solve the system of equations:\n$$\n\\frac{1}{h^2} (-G^{(h)}_{i-1,j} + 2G^{(h)}_{i,j} - G^{(h)}_{i+1,j}) = \\delta_{ij}, \\quad \\text{for } i \\in \\{1, \\dots, N\\},\n$$\nwith boundary conditions $G^{(h)}_{0,j} = G^{(h)}_{N+1,j} = 0$. This is equivalent to solving the second-order difference equation:\n$$\n- G^{(h)}_{i-1,j} + 2G^{(h)}_{i,j} - G^{(h)}_{i+1,j} = h^2\\delta_{ij}.\n$$\nThe homogeneous equation has general solutions of the form $Ai+B$. Applying the boundary conditions and the jump condition at $i=j$, we can solve for the coefficients.\nFor $i<j$, the solution satisfying $G^{(h)}_{0,j}=0$ is $G^{(h)}_{i,j} = C_1 i$.\nFor $i>j$, the solution satisfying $G^{(h)}_{N+1,j}=0$ is $G^{(h)}_{i,j} = C_2(i-(N+1))$.\nContinuity at $i=j$ requires $C_1 j = C_2(j-(N+1))$. The jump condition from the equation at $i=j$ is $-G^{(h)}_{j-1,j} + 2G^{(h)}_{j,j} - G^{(h)}_{j+1,j} = h^2$. Solving for the constants $C_1$ and $C_2$ yields:\n$C_1 = h^2 \\frac{N+1-j}{N+1}$ and $C_2 = -h^2 \\frac{j}{N+1}$.\nSubstituting these back gives the entries of the discrete Green's function for $i,j \\in \\{1,\\dots,N\\}$:\n$$\nG^{(h)}_{ij} =\n\\begin{cases}\nh^2 \\frac{i(N+1-j)}{N+1} & i \\le j \\\\\nh^2 \\frac{j(N+1-i)}{N+1} & i \\ge j\n\\end{cases}\n$$\nThis is the explicit formula in terms of $i, j, N,$ and $h$.\n\nNext, we find the discrete solution $u_{i_*}^{(h)}$ for the forcing $f(x) = \\sin(\\pi x)$. The discrete forcing vector is $\\mathbf{f}_j = f(x_j) = \\sin(\\pi j h)$. The discrete solution $\\mathbf{u}^{(h)}$ is given by $\\mathbf{u}^{(h)} = L_h^{-1} \\mathbf{f} = G^{(h)} \\mathbf{f}$.\nA more direct method than performing the summation $\\sum_j G^{(h)}_{ij} f_j$ is to recognize that the forcing vector $\\mathbf{f}$ is an eigenvector of the operator $L_h$. The normalized eigenvectors of $L_h$ are $\\mathbf{v}_k$ with components $(\\mathbf{v}_k)_i = \\sqrt{2h}\\sin(k \\pi i h)$, and the corresponding eigenvalues are $\\mu_k = \\frac{4\\sin^2(k\\pi h/2)}{h^2}$.\nOur forcing vector $\\mathbf{f}$ with components $\\sin(\\pi j h)$ corresponds to the eigenvector for $k=1$. Thus, $L_h \\mathbf{f} = \\mu_1 \\mathbf{f}$.\nThe solution to $L_h \\mathbf{u}^{(h)} = \\mathbf{f}$ is then simply $\\mathbf{u}^{(h)} = \\frac{1}{\\mu_1}\\mathbf{f}$.\nThe components of the solution are:\n$$\nu_i^{(h)} = \\frac{1}{\\mu_1} \\sin(\\pi i h) = \\frac{h^2}{4\\sin^2(\\pi h/2)} \\sin(\\pi i h).\n$$\nWe need to evaluate this at the midpoint $i_* = (N+1)/2$. At this point, $x_{i_*} = i_*h = \\frac{N+1}{2}h = \\frac{N+1}{2}\\frac{1}{N+1} = \\frac{1}{2}$.\nThe term $\\sin(\\pi i_* h) = \\sin(\\pi/2) = 1$.\nTherefore, the discrete solution at the midpoint is a closed-form expression in $h$:\n$$\nu_{i_*}^{(h)} = \\frac{h^2}{4\\sin^2(\\pi h/2)}.\n$$\n\n### Part (2): Continuous Green's Function and Solution\n\nThe continuous Green's function $G(x,\\xi)$ for the operator $-d^2/dx^2$ with homogeneous Dirichlet boundary conditions $u(0)=u(1)=0$ is the solution to $-G_{xx}(x,\\xi) = \\delta(x-\\xi)$ with $G(0,\\xi)=G(1,\\xi)=0$. Following a standard derivation by integrating twice and applying boundary and interface conditions (continuity of $G$ and a unit jump in $G_x$ at $x=\\xi$), we find:\n$$\nG(x,\\xi) =\n\\begin{cases}\nx(1-\\xi) & x \\le \\xi \\\\\n\\xi(1-x) & x \\ge \\xi\n\\end{cases}\n$$\nThe continuous solution $u(x)$ is given by the integral $u(x) = \\int_0^1 G(x,\\xi) f(\\xi) d\\xi$.\nThe forcing function is $f(x) = \\sin(\\pi x)$. This function is an eigenfunction of the differential operator $-d^2/dx^2$ with the given boundary conditions:\n$$\n-\\frac{d^2}{dx^2} (\\sin(\\pi x)) = -(-\\pi^2 \\sin(\\pi x)) = \\pi^2 \\sin(\\pi x).\n$$\nThe eigenvalue is $\\lambda = \\pi^2$. To solve $-u''(x) = \\sin(\\pi x)$, we can assume a solution of the form $u(x) = C \\sin(\\pi x)$. Substituting this into the equation gives $C\\pi^2\\sin(\\pi x) = \\sin(\\pi x)$, which implies $C=1/\\pi^2$.\nSo, the continuous solution is:\n$$\nu(x) = \\frac{1}{\\pi^2} \\sin(\\pi x).\n$$\nAt the midpoint $x_{i_*} = 1/2$, the continuous solution is:\n$$\nu(x_{i_*}) = u(1/2) = \\frac{1}{\\pi^2} \\sin(\\pi/2) = \\frac{1}{\\pi^2}.\n$$\n\n### Part (3): Asymptotic Consistency Constant\n\nWe must compute the constant $C = \\lim_{h \\to 0} \\frac{u_{i_*}^{(h)} - u(x_{i_*})}{h^2}$.\nSubstituting the expressions from parts (1) and (2):\n$$\nC = \\lim_{h \\to 0} \\frac{1}{h^2} \\left(\\frac{h^2}{4\\sin^2(\\pi h/2)} - \\frac{1}{\\pi^2}\\right) = \\lim_{h \\to 0} \\left(\\frac{1}{4\\sin^2(\\pi h/2)} - \\frac{1}{\\pi^2 h^2}\\right).\n$$\nTo evaluate this limit, we use the Taylor series expansion for $\\sin(z)$ around $z=0$: $\\sin(z) = z - \\frac{z^3}{6} + \\mathcal{O}(z^5)$. Let $z = \\pi h/2$.\n$$\n\\sin(\\pi h/2) = \\frac{\\pi h}{2} - \\frac{1}{6}\\left(\\frac{\\pi h}{2}\\right)^3 + \\mathcal{O}(h^5) = \\frac{\\pi h}{2} - \\frac{\\pi^3 h^3}{48} + \\mathcal{O}(h^5).\n$$\nSquaring this gives:\n$$\n\\sin^2(\\pi h/2) = \\left(\\frac{\\pi h}{2}\\right)^2 - 2\\left(\\frac{\\pi h}{2}\\right)\\left(\\frac{\\pi^3 h^3}{48}\\right) + \\mathcal{O}(h^6) = \\frac{\\pi^2 h^2}{4} - \\frac{\\pi^4 h^4}{48} + \\mathcal{O}(h^6).\n$$\nNow we analyze the term $\\frac{1}{4\\sin^2(\\pi h/2)}$:\n$$\n\\frac{1}{4\\sin^2(\\pi h/2)} = \\frac{1}{4\\left(\\frac{\\pi^2 h^2}{4} - \\frac{\\pi^4 h^4}{48} + \\mathcal{O}(h^6)\\right)} = \\frac{1}{\\pi^2 h^2 - \\frac{\\pi^4 h^4}{12} + \\mathcal{O}(h^6)}.\n$$\nWe factor out $\\pi^2 h^2$ from the denominator and use the geometric series expansion $\\frac{1}{1-y} = 1+y+\\mathcal{O}(y^2)$:\n$$\n\\frac{1}{\\pi^2 h^2 \\left(1 - \\frac{\\pi^2 h^2}{12} + \\mathcal{O}(h^4)\\right)} = \\frac{1}{\\pi^2 h^2} \\left[1 + \\frac{\\pi^2 h^2}{12} + \\mathcal{O}(h^4)\\right] = \\frac{1}{\\pi^2 h^2} + \\frac{1}{12} + \\mathcal{O}(h^2).\n$$\nSubstituting this back into the expression for $C$:\n$$\nC = \\lim_{h \\to 0} \\left[ \\left(\\frac{1}{\\pi^2 h^2} + \\frac{1}{12} + \\mathcal{O}(h^2)\\right) - \\frac{1}{\\pi^2 h^2} \\right] = \\lim_{h \\to 0} \\left(\\frac{1}{12} + \\mathcal{O}(h^2)\\right).\n$$\nThe limit is therefore:\n$$\nC = \\frac{1}{12}.\n$$\nThis constant is related to the leading term of the local truncation error for the centered second-difference formula, which is $-\\frac{h^2}{12}u^{(4)}(x)$. The calculation confirms this relationship for the specific problem at the midpoint.", "answer": "$$\n\\boxed{\\frac{1}{12}}\n$$", "id": "3458571"}, {"introduction": "Moving to time-dependent diffusion, the choice of time-stepping scheme is critical for stability and accuracy. This exercise analyzes the popular Crank-Nicolson method and its amplification matrix $G$, revealing how the spectral properties of the tridiagonal operator govern the solution's evolution. You will investigate the amplification factor for different spatial modes to understand why this unconditionally stable method can still produce non-physical oscillations [@problem_id:3458532].", "problem": "Consider the one-dimensional diffusion (heat) equation $u_t = \\kappa u_{xx}$ posed on a bounded interval with homogeneous Dirichlet boundary conditions, where $\\kappa > 0$ is the diffusivity. Discretize space with a uniform grid of spacing $h$, and approximate $-u_{xx}$ by the standard second-order centered finite difference operator, leading to a symmetric positive definite tridiagonal matrix $T \\in \\mathbb{R}^{N \\times N}$ that represents the discrete operator for $-u_{xx}$. Let $\\lambda = \\kappa \\Delta t / h^2$, where $\\Delta t > 0$ is the time step. The $\\theta$-method in time with $\\theta = 1/2$ (Crank–Nicolson) yields the linear update\n$$(I + \\tfrac{\\lambda}{2} T) u^{n+1} = (I - \\tfrac{\\lambda}{2} T) u^n,$$\nso that the amplification matrix is\n$$G = (I + \\tfrac{\\lambda}{2} T)^{-1} (I - \\tfrac{\\lambda}{2} T).$$\nUsing only first principles about the spectral properties of symmetric positive definite matrices and linear time-stepping methods for Partial Differential Equations (PDE), derive how potential temporal oscillations are tied to the spectrum of $G$, and explain the damping properties of high-frequency spatial modes. Then select the statement that best captures the correct relationship between the spectral radius of $G$ and the behavior of high-frequency modes under the Crank–Nicolson scheme.\n\nA. For all $\\lambda > 0$ and any symmetric positive definite $T$, all eigenvalues of $G$ lie in $(0,1)$, the spectral radius $\\rho(G)$ is strictly less than $1$, and no temporal oscillations can occur.\n\nB. For all $\\lambda > 0$ and any symmetric positive definite $T$, the eigenvalues of $G$ are real and satisfy $\\lvert \\gamma \\rvert \\le 1$ for each eigenvalue $\\gamma$ of $G$; moreover, $\\gamma$ becomes negative precisely when $\\lambda \\mu > 2$ for an eigenvalue $\\mu$ of $T$, leading to alternating-in-time oscillations in those modal components. As $\\lambda$ increases, $\\rho(G)$ approaches $1$, implying weak damping of high-frequency modes.\n\nC. The amplification matrix $G$ has complex-conjugate eigenvalues with modulus exceeding $1$ for sufficiently large $\\lambda$, so the Crank–Nicolson method becomes unstable due to growth of high-frequency modes.\n\nD. Increasing $\\lambda$ strictly decreases the spectral radius $\\rho(G)$ toward $0$, so high-frequency modes are strongly damped and no oscillations occur for any $\\lambda$.", "solution": "The user wants me to validate the problem statement and, if valid, derive a solution based on first principles concerning the Crank-Nicolson method for the 1D diffusion equation.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n*   **PDE**: $u_t = \\kappa u_{xx}$ for $\\kappa > 0$.\n*   **Domain**: Bounded interval.\n*   **Boundary Conditions**: Homogeneous Dirichlet.\n*   **Spatial Discretization**: Uniform grid with spacing $h$.\n*   **Discrete Operator**: $-u_{xx}$ is approximated by a symmetric positive definite (SPD) tridiagonal matrix $T \\in \\mathbb{R}^{N \\times N}$.\n*   **Time Discretization**: The $\\theta$-method with $\\theta = 1/2$ (Crank-Nicolson).\n*   **Parameters**: Time step $\\Delta t > 0$; diffusion number $\\lambda = \\kappa \\Delta t / h^2 > 0$.\n*   **Update Equation**: $(I + \\tfrac{\\lambda}{2} T) u^{n+1} = (I - \\tfrac{\\lambda}{2} T) u^n$.\n*   **Amplification Matrix**: $G = (I + \\tfrac{\\lambda}{2} T)^{-1} (I - \\tfrac{\\lambda}{2} T)$.\n*   **Task**:\n    1.  Derive the relationship between temporal oscillations and the spectrum of $G$.\n    2.  Explain the damping properties for high-frequency spatial modes.\n    3.  Select the statement that best describes the relationship between the spectral radius of $G$ and high-frequency mode behavior.\n\n**Step 2: Validate Using Extracted Givens**\n\n1.  **Scientifically Grounded**: The problem describes the standard application of the Crank-Nicolson method to the diffusion equation. The use of a finite difference stencil leading to an SPD matrix for the discrete negative Laplacian with homogeneous Dirichlet boundary conditions is a cornerstone of numerical PDE analysis. All concepts are standard and scientifically sound.\n2.  **Well-Posed**: The problem is well-posed. Given the properties of the matrix $T$, the properties of the amplification matrix $G$ can be uniquely determined and analyzed. The question asks for a specific analysis of these properties.\n3.  **Objective**: The language is precise, mathematical, and free of subjective or ambiguous statements.\n4.  **Completeness and Consistency**: The problem is self-contained. The crucial property that $T$ is symmetric positive definite is explicitly stated, which is all that is required for the spectral analysis. The provided update equation and the definition of $G$ are correct for the Crank-Nicolson method.\n5.  **Other Flaws**: The problem is not metaphorical, trivial, unverifiable, or ill-posed. It is a standard and important analysis in the field.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is **valid**. I will proceed with the derivation and solution.\n\n### Derivation\n\nThe stability and accuracy properties of the time-stepping scheme are determined by the spectral properties of the amplification matrix $G$. The problem states that $T$ is a symmetric positive definite (SPD) matrix.\n\nSince $T$ is symmetric, it is diagonalizable by an orthonormal basis of eigenvectors. Let $\\{v_k\\}_{k=1}^N$ be the set of eigenvectors of $T$ with corresponding eigenvalues $\\{\\mu_k\\}_{k=1}^N$. From the properties of the finite difference approximation to $-u_{xx}$ on a bounded domain with homogeneous Dirichlet conditions, and the given fact that $T$ is positive definite, we know all its eigenvalues are real and strictly positive: $\\mu_k > 0$ for all $k=1, \\dots, N$.\n\nWe now analyze the action of the amplification matrix $G$ on an eigenvector $v_k$ of $T$:\n$$G v_k = (I + \\tfrac{\\lambda}{2} T)^{-1} (I - \\tfrac{\\lambda}{2} T) v_k$$\nFirst, we apply the rightmost part:\n$$(I - \\tfrac{\\lambda}{2} T) v_k = I v_k - \\tfrac{\\lambda}{2} T v_k = v_k - \\tfrac{\\lambda}{2} \\mu_k v_k = (1 - \\tfrac{\\lambda}{2} \\mu_k) v_k$$\nNow, we apply the inverse matrix $(I + \\tfrac{\\lambda}{2} T)^{-1}$ to this result. The eigenvectors of $T$ are also the eigenvectors of $(I + \\tfrac{\\lambda}{2} T)$:\n$$(I + \\tfrac{\\lambda}{2} T) v_k = v_k + \\tfrac{\\lambda}{2} \\mu_k v_k = (1 + \\tfrac{\\lambda}{2} \\mu_k) v_k$$\nSince $\\lambda > 0$ and $\\mu_k > 0$, the eigenvalue $(1 + \\tfrac{\\lambda}{2} \\mu_k)$ is always strictly greater than $1$, so the matrix $(I + \\tfrac{\\lambda}{2} T)$ is invertible. The eigenvalues of the inverse matrix $(I + \\tfrac{\\lambda}{2} T)^{-1}$ are simply the reciprocal of the eigenvalues of $(I + \\tfrac{\\lambda}{2} T)$. Therefore:\n$$(I + \\tfrac{\\lambda}{2} T)^{-1} v_k = \\frac{1}{1 + \\tfrac{\\lambda}{2} \\mu_k} v_k$$\nCombining these steps:\n$$G v_k = (I + \\tfrac{\\lambda}{2} T)^{-1} \\left( (1 - \\tfrac{\\lambda}{2} \\mu_k) v_k \\right) = (1 - \\tfrac{\\lambda}{2} \\mu_k) (I + \\tfrac{\\lambda}{2} T)^{-1} v_k$$\n$$G v_k = (1 - \\tfrac{\\lambda}{2} \\mu_k) \\left( \\frac{1}{1 + \\tfrac{\\lambda}{2} \\mu_k} \\right) v_k = \\left( \\frac{1 - \\tfrac{\\lambda}{2} \\mu_k}{1 + \\tfrac{\\lambda}{2} \\mu_k} \\right) v_k$$\nThis shows that the eigenvectors $v_k$ of $T$ are also the eigenvectors of $G$. The corresponding eigenvalues of $G$, which we denote by $\\gamma_k$, are given by the rational function:\n$$\\gamma_k = \\frac{1 - \\tfrac{\\lambda \\mu_k}{2}}{1 + \\tfrac{\\lambda \\mu_k}{2}}$$\nLet's analyze this amplification factor $\\gamma_k$. Since $\\lambda > 0$ and $\\mu_k > 0$, the product $\\lambda \\mu_k$ is a positive real number.\nThe magnitude of $\\gamma_k$ is:\n$$|\\gamma_k| = \\left| \\frac{1 - \\tfrac{\\lambda \\mu_k}{2}}{1 + \\tfrac{\\lambda \\mu_k}{2}} \\right| = \\frac{|1 - \\tfrac{\\lambda \\mu_k}{2}|}{1 + \\tfrac{\\lambda \\mu_k}{2}}$$\nBecause $x \\ge |y|$ implies $x \\ge y$ and $x \\ge -y$, we can check that $1 + \\tfrac{\\lambda \\mu_k}{2} \\ge |1 - \\tfrac{\\lambda \\mu_k}{2}|$ for all $\\lambda \\mu_k > 0$. This implies $|\\gamma_k| \\le 1$. The method is therefore unconditionally stable for any choice of $\\lambda > 0$. Equality $|\\gamma_k|=1$ holds in the limit $\\lambda\\mu_k \\to \\infty$, where $\\gamma_k \\to -1$. For any finite $\\lambda$ and $\\mu_k$, $|\\gamma_k| < 1$, as $\\lambda \\mu_k > 0$.\n\n**Temporal Oscillations**:\nA modal component of the solution undergoes temporal oscillations if its amplification factor $\\gamma_k$ is negative. This causes the sign of the component's amplitude to flip at each time step. The condition for $\\gamma_k$ to be negative is:\n$$\\gamma_k < 0 \\implies \\frac{1 - \\tfrac{\\lambda \\mu_k}{2}}{1 + \\tfrac{\\lambda \\mu_k}{2}} < 0$$\nSince the denominator $(1 + \\tfrac{\\lambda \\mu_k}{2})$ is always positive, the numerator must be negative:\n$$1 - \\tfrac{\\lambda \\mu_k}{2} < 0 \\implies 1 < \\tfrac{\\lambda \\mu_k}{2} \\implies \\lambda \\mu_k > 2$$\nThus, oscillations occur in modes for which the product of the diffusion number $\\lambda$ and the eigenvalue $\\mu_k$ exceeds $2$.\n\n**Damping of High-Frequency Modes**:\nThe eigenvectors $v_k$ of the discrete Laplacian $T$ correspond to discrete sinusoids of varying spatial frequencies. \"High-frequency\" modes correspond to the eigenvectors with the largest eigenvalues $\\mu_k$. The largest eigenvalue, $\\mu_{max}$, of the standard second-order centered difference matrix for $-u_{xx}$ scales as $O(h^{-2})$.\nDamping is determined by $|\\gamma_k|$. Strong damping means $|\\gamma_k| \\ll 1$, while weak damping means $|\\gamma_k| \\approx 1$. Let's examine the behavior of $\\gamma_k$ for high-frequency modes, i.e., large $\\mu_k$. As $\\mu_k \\to \\infty$ (or more practically, as $\\mu_k$ takes its largest values, which are proportional to $h^{-2}$), the product $\\lambda \\mu_k = (\\kappa \\Delta t/h^2)\\mu_k$ also becomes large.\nIn the limit of large $\\lambda \\mu_k$:\n$$\\lim_{\\lambda \\mu_k \\to \\infty} \\gamma_k = \\lim_{\\lambda \\mu_k \\to \\infty} \\frac{1 - \\tfrac{\\lambda \\mu_k}{2}}{1 + \\tfrac{\\lambda \\mu_k}{2}} = \\lim_{x \\to \\infty} \\frac{1/x - 1/2}{1/x + 1/2} = \\frac{-1/2}{1/2} = -1$$\nThis means for high-frequency modes, especially when $\\lambda$ is large, the amplification factor $\\gamma_k$ approaches $-1$. Consequently, the magnitude $|\\gamma_k|$ approaches $1$. This indicates that high-frequency modes are very **weakly damped** and simultaneously undergo strong temporal oscillations. This is a well-known deficiency of the Crank-Nicolson method.\n\n**Spectral Radius**:\nThe spectral radius of $G$ is $\\rho(G) = \\max_k |\\gamma_k|$. The behavior of $|\\gamma(\\lambda \\mu)|$ as a function of the positive variable $x = \\lambda \\mu$ is that it decreases from $1$ (at $x=0$) to $0$ (at $x=2$) and then increases from $0$ back toward $1$ as $x \\to \\infty$. Therefore, the spectral radius is given by $\\rho(G) = \\max(|\\gamma(\\lambda\\mu_{min})|, |\\gamma(\\lambda\\mu_{max})|)$. As $\\lambda$ increases, $\\lambda \\mu_{max}$ will become large and dominate, so $\\rho(G) \\approx |\\gamma(\\lambda \\mu_{max})|$. Since $\\lim_{x\\to\\infty} |\\gamma(x)| = 1$, we conclude that as $\\lambda$ increases, $\\rho(G)$ approaches $1$.\n\n### Option Analysis\n\n**A. For all $\\lambda > 0$ and any symmetric positive definite $T$, all eigenvalues of $G$ lie in $(0,1)$, the spectral radius $\\rho(G)$ is strictly less than $1$, and no temporal oscillations can occur.**\nThis is **Incorrect**. As derived, if $\\lambda \\mu_k > 2$ for any eigenvalue $\\mu_k$ of $T$, the corresponding eigenvalue $\\gamma_k$ of $G$ becomes negative. Since we can always choose $\\lambda$ large enough, there will be conditions under which eigenvalues of $G$ are negative, leading to oscillations.\n\n**B. For all $\\lambda > 0$ and any symmetric positive definite $T$, the eigenvalues of $G$ are real and satisfy $\\lvert \\gamma \\rvert \\le 1$ for each eigenvalue $\\gamma$ of $G$; moreover, $\\gamma$ becomes negative precisely when $\\lambda \\mu > 2$ for an eigenvalue $\\mu$ of $T$, leading to alternating-in-time oscillations in those modal components. As $\\lambda$ increases, $\\rho(G)$ approaches $1$, implying weak damping of high-frequency modes.**\nThis is **Correct**. Our derivation shows:\n1.  Eigenvalues $\\gamma_k$ are real.\n2.  Unconditional stability holds: $|\\gamma_k| \\le 1$.\n3.  Oscillations occur when $\\gamma_k < 0$, which is precisely when $\\lambda \\mu_k > 2$.\n4.  As $\\lambda$ increases, $\\rho(G)$ is dominated by the high-frequency modes and approaches $1$.\n5.  $|\\gamma_k| \\to 1$ for high-frequency modes implies weak damping.\nThis statement accurately summarizes all the key findings of the analysis.\n\n**C. The amplification matrix $G$ has complex-conjugate eigenvalues with modulus exceeding $1$ for sufficiently large $\\lambda$, so the Crank–Nicolson method becomes unstable due to growth of high-frequency modes.**\nThis is **Incorrect**. Since $T$ is SPD, its eigenvalues $\\mu_k$ are real. The formula for $\\gamma_k$ involves only real numbers, so $\\gamma_k$ must be real. Furthermore, we proved $|\\gamma_k| \\le 1$, so the method is unconditionally stable and the modulus never exceeds $1$.\n\n**D. Increasing $\\lambda$ strictly decreases the spectral radius $\\rho(G)$ toward $0$, so high-frequency modes are strongly damped and no oscillations occur for any $\\lambda$.**\nThis is **Incorrect**. Increasing $\\lambda$ causes $\\rho(G)$ to approach $1$, not $0$. This corresponds to weak damping of high-frequency modes, not strong damping. Oscillations can and do occur for large enough $\\lambda$.", "answer": "$$\\boxed{B}$$", "id": "3458532"}, {"introduction": "In practice, the linear system at each time step is often solved inexactly with an iterative method to a certain tolerance, $\\varepsilon$. This practice investigates the consequences, asking you to analyze how local algebraic errors accumulate and to derive a tolerance rule, such as $\\varepsilon = \\theta \\Delta t^2$. The goal is to ensure that the error from the inexact solve does not contaminate the temporal accuracy of the overall simulation [@problem_id:3458596].", "problem": "Consider the one-dimensional diffusion equation on the domain $[0,1]$ with homogeneous Dirichlet boundary conditions and normalized units so that the diffusion coefficient equals one. The partial differential equation is $u_t = u_{xx}$, with $u(0,t) = 0$, $u(1,t) = 0$, and $u(x,0) = \\sin(\\pi x)$ for $x \\in [0,1]$. Discretize space with $N$ interior points to obtain uniform grid spacing $h = \\frac{1}{N+1}$ and use the standard second-order centered finite difference approximation of the Laplacian. Discretize time with backward Euler (fully implicit) using time step $\\Delta t$ and final time $T$. The resulting linear system at each time step is $A u^{n+1} = u^{n}$, where $A = I - \\Delta t L_h$, and $L_h$ is the discrete Laplacian with Dirichlet boundary conditions, yielding the tridiagonal representation\n$$\nA = \\begin{bmatrix}\n1 + \\frac{2\\Delta t}{h^2} & -\\frac{\\Delta t}{h^2} & & \\\\\n-\\frac{\\Delta t}{h^2} & 1 + \\frac{2\\Delta t}{h^2} & -\\frac{\\Delta t}{h^2} & \\\\\n& \\ddots & \\ddots & \\ddots \\\\\n& & -\\frac{\\Delta t}{h^2} & 1 + \\frac{2\\Delta t}{h^2}\n\\end{bmatrix},\n$$\nwith dimension $N \\times N$ and zero Dirichlet boundaries incorporated via the interior unknowns. Because $A$ is symmetric positive definite, any linear solve can be performed by the Thomas algorithm (exact up to machine precision) or by an iterative method such as Conjugate Gradient (CG) or truncated Parallel Cyclic Reduction (PCR), which can be stopped early according to a relative residual tolerance $\\varepsilon$.\n\nYour task is to examine how using an inexact tridiagonal solve at each time step affects the global temporal error at time $T$, and to establish a tolerance selection rule that ensures the accumulated algebraic error remains below the time discretization error. Use the following fundamental base.\n- The backward Euler method is first-order accurate in time, so its global temporal discretization error behaves like $\\mathcal{O}(\\Delta t)$ for sufficiently smooth solutions.\n- For a linear solve $A x = b$ with an inexact solution $\\tilde{x}$ having residual $r = b - A \\tilde{x}$, the algebraic solution error satisfies $\\|x - \\tilde{x}\\| \\le \\|A^{-1}\\| \\, \\|r\\|$ in any subordinate norm.\n- For backward Euler applied to the semi-discrete diffusion operator, the matrix $A$ has eigenvalues $\\lambda_k(A) = 1 - \\Delta t \\lambda_k(L_h)$, where $\\lambda_k(L_h) = -\\frac{4}{h^2}\\sin^2\\left(\\frac{k\\pi}{2(N+1)}\\right)$ for $k = 1,\\dots,N$.\n\nFrom these principles, reason about the cumulative effect of per-step algebraic errors caused by inexact solves and derive a tolerance selection rule for the per-step relative residual $\\varepsilon$ so that the total algebraic error at time $T$ does not exceed the time discretization error.\n\nYour program must:\n1. Implement backward Euler time stepping for the semi-discrete system with the exact tridiagonal solve using the Thomas algorithm to produce a reference solution at time $T$.\n2. Implement an inexact solve at each time step using an iterative method that terminates when the relative residual drops below a prescribed tolerance $\\varepsilon$. You may use Conjugate Gradient as a practical surrogate for truncated Parallel Cyclic Reduction (PCR) to realize controlled inexactness through early stopping.\n3. Estimate the time discretization error $E_{\\text{time}}$ at time $T$ by computing the difference between the exact-solve backward Euler solution using step $\\Delta t$ and the exact-solve backward Euler solution using step $\\Delta t/2$, both starting from the same initial condition and using the same spatial grid. Use the Euclidean norm in $\\mathbb{R}^N$ for error measurement.\n4. Estimate the algebraic error $E_{\\text{alg}}$ at time $T$ by computing the difference between the exact-solve backward Euler solution using step $\\Delta t$ and the inexact-solve backward Euler solution using step $\\Delta t$ with the chosen tolerance $\\varepsilon$.\n5. Based on your derivation, implement the tolerance selection rule $\\varepsilon = \\theta \\Delta t^2$, where $\\theta$ is chosen using available quantities in the semi-discrete model to ensure $E_{\\text{alg}} \\le E_{\\text{time}}$; the specific formula for $\\theta$ must be justified in your solution and implemented in code.\n\nUse the following test suite of parameter values and report whether the rule achieves $E_{\\text{alg}} \\le E_{\\text{time}}$.\n- Test case $1$: $N=64$, $T=0.1$, $\\Delta t = 10^{-3}$, tolerance set by the rule.\n- Test case $2$: $N=64$, $T=0.1$, $\\Delta t = 2 \\times 10^{-3}$, tolerance set by the rule.\n- Test case $3$: $N=64$, $T=0.1$, $\\Delta t = 5 \\times 10^{-4}$, tolerance set by the rule.\n- Test case $4$ (edge case to test failure when the rule is violated): $N=64$, $T=0.1$, $\\Delta t = 10^{-3}$, tolerance set to a larger value proportional to $\\Delta t$ such that the cumulative algebraic error is expected to exceed the time error.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,result_3,result_4]$). Each $result_i$ must be a boolean indicating whether $E_{\\text{alg}} \\le E_{\\text{time}}$ for the corresponding test case. No physical units are required in the output since normalized units are used throughout.", "solution": "The problem is valid as it presents a well-posed, scientifically grounded task in the field of numerical analysis for partial differential equations. All provided information is consistent, complete, and aligns with established theory. We will now derive the required tolerance selection rule and then implement the numerical experiment.\n\n### Derivation of the Tolerance Selection Rule\n\nThe objective is to derive a rule for the per-step relative residual tolerance $\\varepsilon$ of the form $\\varepsilon = \\theta \\Delta t^2$, such that the total accumulated algebraic error $E_{alg}$ at the final time $T$ is on the same order as, or smaller than, the global temporal discretization error $E_{time}$.\n\nLet $u^n$ be the numerically exact solution vector at time $t_n = n \\Delta t$, obtained by solving the backward Euler system $A u^{n+1} = u^n$ exactly. Let $\\tilde{u}^n$ be the solution vector obtained when the linear system is solved inexactly. We start with the same initial condition, so $\\tilde{u}^0 = u^0$.\n\n**1. Bounding the Accumulated Algebraic Error ($E_{alg}$)**\n\nAt each time step $n+1$, we solve for $\\tilde{u}^{n+1}$ from the system $A x = \\tilde{u}^n$. The inexact solver produces a solution $\\tilde{u}^{n+1}$ such that the residual $r^{n+1} = \\tilde{u}^n - A \\tilde{u}^{n+1}$ satisfies the relative tolerance condition $\\|r^{n+1}\\| / \\|\\tilde{u}^n\\| \\le \\varepsilon$. All norms are the Euclidean $L_2$-norm. This implies $\\|r^{n+1}\\| \\le \\varepsilon \\|\\tilde{u}^n\\|$.\n\nThe local algebraic error introduced at this step, $\\delta^{n+1}$, is the difference between the exact solution of this system and the inexact one: $\\delta^{n+1} = A^{-1}\\tilde{u}^n - \\tilde{u}^{n+1}$. Using the provided error bound from the problem statement, we have:\n$$\n\\|\\delta^{n+1}\\| \\le \\|A^{-1}\\| \\|r^{n+1}\\| \\le \\|A^{-1}\\| \\varepsilon \\|\\tilde{u}^n\\|\n$$\nFor the backward Euler discretization of the diffusion equation, the matrix $A = I - \\Delta t L_h$ is symmetric positive definite and all its eigenvalues are greater than or equal to $1$. Therefore, its inverse $A^{-1}$ is also SPD and has eigenvalues less than or equal to $1$, which implies $\\|A^{-1}\\| \\le 1$. Further, the diffusion process is dissipative, meaning the norm of the solution does not grow in time: $\\|\\tilde{u}^n\\| \\le \\|\\tilde{u}^{n-1}\\| \\le \\dots \\le \\|\\tilde{u}^0\\| = \\|u^0\\|$.\nThis simplifies the bound on the local algebraic error:\n$$\n\\|\\delta^{n+1}\\| \\le \\varepsilon \\|u^0\\|\n$$\nThe global algebraic error at step $n+1$, $e_{alg}^{n+1} = u^{n+1} - \\tilde{u}^{n+1}$, accumulates from the previous step's global error and the new local error:\n$$\ne_{alg}^{n+1} = (A^{-1} u^n) - (A^{-1}\\tilde{u}^n - \\delta^{n+1}) = A^{-1}(u^n - \\tilde{u}^n) + \\delta^{n+1} = A^{-1}e_{alg}^n + \\delta^{n+1}\n$$\nTaking norms and using $\\|A^{-1}\\| \\le 1$: $\\|e_{alg}^{n+1}\\| \\le \\|e_{alg}^n\\| + \\|\\delta^{n+1}\\|$.\nBy induction from $e_{alg}^0 = 0$, the total algebraic error at the final time $T = N_T \\Delta t$ is bounded by the sum of the magnitudes of the local errors:\n$$\nE_{alg} = \\|e_{alg}^{N_T}\\| \\le \\sum_{n=1}^{N_T} \\|\\delta^n\\| \\le \\sum_{n=1}^{N_T} \\varepsilon \\|u^0\\| = N_T \\varepsilon \\|u^0\\| = \\frac{T}{\\Delta t} \\varepsilon \\|u^0\\|\n$$\nSo, the accumulated algebraic error scales as $E_{alg} \\propto \\varepsilon / \\Delta t$.\n\n**2. Bounding the Temporal Discretization Error ($E_{time}$)**\n\nThe backward Euler method is first-order accurate in time. The local truncation error (LTE) at step $n+1$ for the semi-discrete system $du/dt = L_h u$ is given by:\n$$\n\\tau^{n+1} \\approx \\frac{\\Delta t^2}{2} u_{tt}(t_{n+1})\n$$\nwhere $u_{tt} = \\frac{d^2u}{dt^2}$. Since $u_t = L_h u$, we have $u_{tt} = L_h u_t = L_h(L_h u) = L_h^2 u$. Thus, the LTE is:\n$$\n\\|\\tau^{n+1}\\| \\approx \\frac{\\Delta t^2}{2} \\|L_h^2 u(t_{n+1})\\|\n$$\nThe global time discretization error $E_{time}$ is, to leading order, the accumulation of these local errors. A heuristic argument suggests that the global error is bounded by the number of steps times the maximum LTE:\n$$\nE_{time} \\approx N_T \\times \\max_n \\|\\tau^n\\| = \\frac{T}{\\Delta t} \\left( \\frac{\\Delta t^2}{2} \\max_n \\|L_h^2 u(t_n)\\| \\right) = \\frac{T \\Delta t}{2} \\max_n \\|L_h^2 u(t_n)\\|\n$$\n\n**3. Balancing the Errors and Deriving the Rule**\n\nTo ensure the algebraic error does not pollute the temporal accuracy, we require $E_{alg} \\lesssim E_{time}$:\n$$\n\\frac{T}{\\Delta t} \\varepsilon \\|u^0\\| \\lesssim \\frac{T \\Delta t}{2} \\max_n \\|L_h^2 u(t_n)\\|\n$$\nSolving for $\\varepsilon$:\n$$\n\\varepsilon \\lesssim \\frac{\\Delta t^2}{2} \\frac{\\max_n \\|L_h^2 u(t_n)\\|}{\\|u^0\\|}\n$$\nThe problem specifies the initial condition $u(x,0) = \\sin(\\pi x)$. This is the first eigenfunction of the continuous operator $-\\partial^2/\\partial x^2$ with eigenvalue $\\pi^2$. The discrete initial condition is a close approximation to the first eigenvector of the discrete Laplacian $-L_h$, with corresponding eigenvalue $\\lambda_1(-L_h) = - \\lambda_1(L_h) = \\frac{4}{h^2}\\sin^2\\left(\\frac{\\pi}{2(N+1)}\\right) \\approx \\pi^2$.\nThe solution to the semi-discrete system is $u(t) \\approx e^{\\lambda_1(L_h)t} u^0$. Therefore, $L_h^2 u(t) \\approx (\\lambda_1(L_h))^2 u(t)$. The norm $\\|L_h^2 u(t_n)\\|$ will be maximal at $t=0$ because the solution decays exponentially.\n$$\n\\max_n \\|L_h^2 u(t_n)\\| \\approx \\|L_h^2 u(0)\\| \\approx \\|(\\lambda_1(L_h))^2 u^0\\| = (\\lambda_1(L_h))^2 \\|u^0\\|\n$$\nSubstituting this into the inequality for $\\varepsilon$:\n$$\n\\varepsilon \\lesssim \\frac{\\Delta t^2}{2} \\frac{(\\lambda_1(L_h))^2 \\|u^0\\|}{\\|u^0\\|} = \\frac{(\\lambda_1(L_h))^2}{2} \\Delta t^2\n$$\nThis provides the desired form $\\varepsilon = \\theta \\Delta t^2$. We select $\\theta = \\frac{(\\lambda_1(L_h))^2}{2}$, a parameter that can be computed directly from the spatial discretization.\nThe specific formula for the smallest (in magnitude) eigenvalue of $L_h$ is given as $\\lambda_1(L_h) = -\\frac{4}{h^2}\\sin^2\\left(\\frac{k\\pi}{2(N+1)}\\right)$ with $k=1$. We will use this to set the tolerance in our implementation.\n$$\n\\theta = \\frac{1}{2} \\left[ -\\frac{4}{h^2}\\sin^2\\left(\\frac{\\pi}{2(N+1)}\\right) \\right]^2 = \\frac{8}{h^4} \\sin^4\\left(\\frac{\\pi}{2(N+1)}\\right)\n$$\n\n### Implementation Strategy\n\nThe program will be structured as follows:\n1.  **`thomas_algorithm`**: An implementation of the Thomas algorithm for solving tridiagonal systems, used for the \"exact\" solves.\n2.  **`conjugate_gradient`**: An implementation of the Conjugate Gradient algorithm for solving SPD systems, used for the \"inexact\" solves. It terminates when the relative residual falls below the tolerance $\\varepsilon$.\n3.  **`solve_diffusion`**: A main driver function that performs the time-stepping using either the Thomas or CG solver. It takes grid and time parameters, solver type, and tolerance as input, and returns the solution at the final time $T$.\n4.  **`solve`**: The main function orchestrating the four test cases. For each case, it:\n    a. Calculates the rule-based coefficient $\\theta$.\n    b. Computes the reference solution $u_{\\Delta t}$ using the exact solver.\n    c. Computes a more accurate reference solution $u_{\\Delta t/2}$ using the exact solver and a halved time step.\n    d. Estimates the time error $E_{time} = \\|u_{\\Delta t} - u_{\\Delta t/2}\\|$.\n    e. Sets the tolerance $\\varepsilon$ according to the derived rule (or a faulty rule for case $4$).\n    f. Computes the inexact solution $\\tilde{u}_{\\Delta t}$ with tolerance $\\varepsilon$.\n    g. Calculates the algebraic error $E_{alg} = \\|u_{\\Delta t} - \\tilde{u}_{\\Delta t}\\|$.\n    h. Records whether $E_{alg} \\le E_{time}$.\nThe final output will be a list of these boolean results.", "answer": "```python\nimport numpy as np\n\ndef thomas_algorithm(l, m, u, d):\n    \"\"\"\n    Solves a tridiagonal system of equations Ax=d.\n    l: lower diagonal (length n-1)\n    m: main diagonal (length n)\n    u: upper diagonal (length n-1)\n    d: right-hand side vector (length n)\n    \"\"\"\n    n = len(d)\n    m_copy = np.copy(m) # Avoid modifying the original array\n    d_copy = np.copy(d) # Avoid modifying the original array\n    \n    # Forward elimination\n    for i in range(1, n):\n        factor = l[i-1] / m_copy[i-1]\n        m_copy[i] = m_copy[i] - factor * u[i-1]\n        d_copy[i] = d_copy[i] - factor * d_copy[i-1]\n\n    # Backward substitution\n    x = np.zeros(n)\n    x[n-1] = d_copy[n-1] / m_copy[n-1]\n    for i in range(n - 2, -1, -1):\n        x[i] = (d_copy[i] - u[i] * x[i+1]) / m_copy[i]\n        \n    return x\n\ndef conjugate_gradient(A, b, tolerance, initial_guess):\n    \"\"\"\n    Solves Ax=b for SPD matrix A using the Conjugate Gradient method.\n    Termination is based on relative residual norm.\n    \"\"\"\n    x = initial_guess\n    r = b - A @ x\n    p = r.copy()\n    rs_old = np.dot(r, r)\n    norm_b = np.linalg.norm(b)\n\n    if norm_b == 0:\n        return np.zeros_like(b)\n\n    # Set a reasonable maximum number of iterations\n    max_iter = len(b) * 2\n    for _ in range(max_iter):\n        Ap = A @ p\n        alpha = rs_old / np.dot(p, Ap)\n        x = x + alpha * p\n        r = r - alpha * Ap\n        rs_new = np.dot(r, r)\n        \n        current_rel_residual = np.sqrt(rs_new) / norm_b\n        if current_rel_residual < tolerance:\n            break\n            \n        p = r + (rs_new / rs_old) * p\n        rs_old = rs_new\n        \n    return x\n\ndef solve_diffusion(N, T, dt, solver_type, tolerance=None):\n    \"\"\"\n    Solves the 1D diffusion equation using backward Euler.\n    \"\"\"\n    h = 1.0 / (N + 1)\n    x_grid = np.linspace(h, 1.0 - h, N)\n    u = np.sin(np.pi * x_grid)\n\n    diag_val = 1.0 + 2.0 * dt / h**2\n    offdiag_val = -dt / h**2\n    \n    main_diag = np.full(N, diag_val)\n    off_diag = np.full(N - 1, offdiag_val)\n\n    num_steps = int(round(T / dt))\n\n    if solver_type == 'exact':\n        for _ in range(num_steps):\n            u = thomas_algorithm(off_diag, main_diag, off_diag, u)\n    elif solver_type == 'inexact':\n        # Build dense matrix for CG\n        A = np.diag(main_diag) + np.diag(off_diag, k=1) + np.diag(off_diag, k=-1)\n        for _ in range(num_steps):\n            # Use previous solution as a warm start for the CG solver\n            u = conjugate_gradient(A, u, tolerance, initial_guess=u.copy())\n            \n    return u\n\ndef solve():\n    test_cases = [\n        # N, T, dt, is_edge_case\n        (64, 0.1, 1e-3, False),\n        (64, 0.1, 2e-3, False),\n        (64, 0.1, 5e-4, False),\n        (64, 0.1, 1e-3, True), # Edge case to test failure\n    ]\n\n    results = []\n    \n    for N, T, dt, is_edge_case in test_cases:\n        # Calculate theta for the tolerance rule\n        h = 1.0 / (N + 1)\n        lambda_1_Lh = -4.0 / h**2 * np.sin(np.pi / (2.0 * (N + 1)))**2\n        theta = (lambda_1_Lh**2) / 2.0\n        \n        # 1. Compute reference solution with step dt\n        u_ref_dt = solve_diffusion(N, T, dt, 'exact')\n        \n        # 2. Compute reference solution with step dt/2 for error estimation\n        u_ref_dt_half = solve_diffusion(N, T, dt / 2.0, 'exact')\n        \n        # 3. Estimate time discretization error\n        E_time = np.linalg.norm(u_ref_dt - u_ref_dt_half)\n        \n        # 4. Set tolerance and compute inexact solution\n        if is_edge_case:\n            # Set a tolerance proportional to dt, which violates the rule\n            # and is expected to lead to larger algebraic error.\n            # 0.1 is an arbitrary constant chosen to make the tolerance large enough.\n            tolerance = 0.1 * dt\n        else:\n            # Use the derived rule\n            tolerance = theta * dt**2\n            \n        u_inexact = solve_diffusion(N, T, dt, 'inexact', tolerance=tolerance)\n        \n        # 5. Estimate algebraic error\n        E_alg = np.linalg.norm(u_ref_dt - u_inexact)\n        \n        # 6. Check if algebraic error is controlled\n        results.append(E_alg <= E_time)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3458596"}]}