{"hands_on_practices": [{"introduction": "The mean force is the negative gradient of the potential of mean force, but how is it computed from a simulation? This exercise [@problem_id:3436759] delves into the rigorous definition of the mean force as a conditional average on a reaction coordinate's level set. You will implement the full expression, which separates the force into a direct projection of the system's potential forces and a crucial geometric term that arises from the curvature of the reaction coordinate itself, providing insight into why naive force averaging can fail.", "problem": "Consider a two-dimensional configuration space with coordinates $(x,y)$ and a smooth potential energy function $U(x,y)$. The system is at thermal equilibrium in the canonical ensemble at temperature $T$ with Boltzmann constant $k_B$. A collective variable (reaction coordinate) $\\xi(x,y)$ maps configurations $(x,y)$ to a scalar value $s = \\xi(x,y)$. The potential of mean force along $s$ defines a mean force $F(s)$ whose exact expression can be derived from canonical ensemble principles and the geometry induced by $\\xi$. The Adaptive Biasing Force (ABF) method estimates the mean force by projecting the microscopic force onto the direction of $\\xi$; for curvilinear $\\xi$, the geometry of level sets of $\\xi$ produces an additional thermal term that must be accounted for to avoid bias.\n\nYour task is to implement from first principles the constrained mean force estimator based on the canonical probability density and the geometry of the collective variable, and to compare it to a projection-only ABF estimator that ignores the geometric thermal term. Use reduced units where $k_B=1$ and $T=1$, so all quantities are dimensionless. All angular quantities, if any, must be in radians. All outputs must be real numbers without units.\n\nDefinitions permitted as a foundational base:\n- Canonical ensemble density $p(x,y) \\propto \\exp(-\\beta U(x,y))$ with $\\beta = 1/(k_B T)$.\n- Gradients and divergences over $(x,y)$ in the usual Euclidean metric.\n- Conditional expectations conditioned on $\\xi(x,y) = s$ defined by weighting with a narrow kernel around the level set.\n\nDesign and implement a program that discretizes $(x,y)$ over a finite grid, evaluates $U$, its gradient, the collective variable $\\xi$, and the required geometric quantities, and then computes conditional averages at specified $s$ values using a normalized narrow Gaussian kernel of bandwidth $h$ applied to $\\xi(x,y)-s$. Approximate the conditional expectation $\\langle A \\rangle_{\\xi=s}$ of any field $A(x,y)$ by\n$$\n\\langle A \\rangle_{\\xi=s} \\approx \\frac{\\sum_{i} \\exp(-\\beta U_i)\\, \\exp\\!\\left[-\\frac{(\\xi_i - s)^2}{2 h^2}\\right]\\, A_i}{\\sum_{i} \\exp(-\\beta U_i)\\, \\exp\\!\\left[-\\frac{(\\xi_i - s)^2}{2 h^2}\\right]},\n$$\nwhere the index $i$ runs over all grid points. Use $h=0.05$.\n\nImplement three test cases (the \"test suite\") that exercise linear and curved collective variables, as follows.\n\n- Test Case 1 (happy path, linear collective variable):\n  - Potential: $U(x,y) = \\tfrac{1}{2}(k_x x^2 + k_y y^2)$ with $k_x=2.0$, $k_y=1.0$.\n  - Collective variable: $\\xi_1(x,y) = x$.\n  - Evaluation points: $s \\in \\{-1.0, 0.0, 1.0\\}$.\n  - Compute and return the constrained mean force values $F_{\\text{constr}}(s)$ for these three $s$.\n\n- Test Case 2 (curved collective variable with known entropic correction):\n  - Potential: $U(x,y) = \\tfrac{1}{2} k \\left(\\sqrt{x^2+y^2} - r_0\\right)^2$ with $k=4.0$, $r_0=1.0$.\n  - Collective variable: $\\xi_2(x,y) = \\sqrt{x^2+y^2}$ (radial coordinate).\n  - Evaluation points: $s \\in \\{0.5, 1.0, 2.0\\}$.\n  - Compute both the constrained mean force values $F_{\\text{constr}}(s)$ and the projection-only ABF estimate $F_{\\text{ABF-naive}}(s)$ that omits the geometric thermal term. Return the differences $F_{\\text{constr}}(s) - F_{\\text{ABF-naive}}(s)$ for these three $s$.\n\n- Test Case 3 (curved collective variable with spatially varying geometry):\n  - Potential: $U(x,y) = \\tfrac{1}{2} k (x^2 + y^2)$ with $k=1.5$.\n  - Collective variable: $\\xi_3(x,y) = x + \\alpha y^2$ with $\\alpha=0.5$.\n  - Evaluation points: $s \\in \\{-0.8, 0.0, 0.8\\}$.\n  - Compute both the constrained mean force values $F_{\\text{constr}}(s)$ and the projection-only ABF estimate $F_{\\text{ABF-naive}}(s)$ that omits the geometric thermal term. Return the differences $F_{\\text{constr}}(s) - F_{\\text{ABF-naive}}(s)$ for these three $s$.\n\nImplementation details:\n- Use a square grid over $(x,y) \\in [-3,3] \\times [-3,3]$ with at least $200 \\times 200$ points.\n- For $\\xi_2(x,y)$, handle the singularity at $r=0$ safely by defining quantities at $r=0$ via smooth limiting values.\n- The constrained mean force estimator must include the thermal geometric contribution induced by the geometry of $\\xi(x,y)$.\n- The projection-only ABF estimate must only include the force component projected along the direction of $\\xi$, ignoring the thermal geometric contribution.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, aggregating the results for all three test cases in order. The format must be exactly:\n\"[[F1_s_values],[Case2_differences],[Case3_differences]]\"\nwhere [F1_s_values] is a list of three floats corresponding to Test Case 1, [Case2_differences] is a list of three floats corresponding to Test Case 2, and [Case3_differences] is a list of three floats corresponding to Test Case 3. For example, a syntactically valid output line would look like \"[[a,b,c],[d,e,f],[g,h,i]]\" with nine real numbers. No other text should be printed.", "solution": "The problem as stated is valid. It is scientifically grounded in the principles of statistical mechanics, specifically the theory of potentials of mean force (PMF) in a canonical ensemble. The problem is well-posed, providing all necessary definitions, constants, and functional forms to arrive at a unique numerical solution. The language is objective and the setup is internally consistent.\n\nThe core of the task is to compute the mean force $F(s)$ acting along a collective variable $s = \\xi(x,y)$. The PMF, $W(s)$, is defined through the marginal probability density $p(s)$ as $W(s) = -k_B T \\ln p(s)$, where $p(s) = \\langle \\delta(\\xi(x,y)-s) \\rangle$. The angle brackets denote a canonical ensemble average. The mean force is the negative gradient of the PMF, $F(s) = -dW(s)/ds$. A rigorous derivation starting from this definition yields the exact expression for the mean force as a sum of two conditional averages over the iso-surface $\\xi(x,y)=s$:\n$$\nF(s) = \\left\\langle (-\\nabla U) \\cdot \\frac{\\nabla \\xi}{|\\nabla \\xi|^2} \\right\\rangle_{\\xi=s} + k_B T \\left\\langle \\nabla \\cdot \\left( \\frac{\\nabla \\xi}{|\\nabla \\xi|^2} \\right) \\right\\rangle_{\\xi=s}\n$$\nIn this expression, $\\nabla = (\\partial_x, \\partial_y)$ is the gradient operator in the microscopic configuration space, $U(x,y)$ is the potential energy, and $\\xi(x,y)$ is the collective variable. The problem specifies reduced units where the thermal energy $k_B T = 1$.\n\nThe two terms in the expression for $F(s)$ have distinct physical interpretations:\n$1$. The first term, $\\left\\langle (-\\nabla U) \\cdot \\frac{\\nabla \\xi}{|\\nabla \\xi|^2} \\right\\rangle_{\\xi=s}$, represents the average of the microscopic force, $-\\nabla U$, projected onto the direction of the gradient of the collective variable, $\\nabla \\xi$. This is the quantity estimated by a naive implementation of the Adaptive Biasing Force (ABF) method, which we denote $F_{\\text{ABF-naive}}(s)$.\n$2$. The second term, $k_B T \\left\\langle \\nabla \\cdot \\left( \\frac{\\nabla \\xi}{|\\nabla \\xi|^2} \\right) \\right\\rangle_{\\xi=s}$, is a geometric correction. It arises from the curvature of the level sets of $\\xi$ and is often called a thermal, entropic, or fixman potential term. It accounts for the change in the \"volume\" of the phase space accessible to the system as $s$ varies.\n\nThe problem requires the implementation of two estimators:\n- The full, correct constrained mean force: $F_{\\text{constr}}(s) = F_{\\text{ABF-naive}}(s) + \\left\\langle \\nabla \\cdot \\left( \\frac{\\nabla \\xi}{|\\nabla \\xi|^2} \\right) \\right\\rangle_{\\xi=s}$.\n- The projection-only ABF estimate: $F_{\\text{ABF-naive}}(s)$.\n\nThe algorithmic design proceeds by first discretizing the two-dimensional configuration space $(x,y)$ over a uniform grid on the domain $[-3,3] \\times [-3,3]$ with $201 \\times 201$ points. The conditional averages $\\langle A \\rangle_{\\xi=s}$ for any observable $A(x,y)$ are then computed numerically using the provided kernel-based formula:\n$$\n\\langle A \\rangle_{\\xi=s} \\approx \\frac{\\sum_{i} \\exp(-\\beta U_i)\\, \\exp\\!\\left[-\\frac{(\\xi_i - s)^2}{2 h^2}\\right]\\, A_i}{\\sum_{i} \\exp(-\\beta U_i)\\, \\exp\\!\\left[-\\frac{(\\xi_i - s)^2}{2 h^2}\\right]}\n$$\nwhere $i$ indexes the grid points, $\\beta = 1/(k_B T) = 1$, and the kernel bandwidth is $h=0.05$.\n\nFor each test case, the required analytic expressions for the potential $U$, the collective variable $\\xi$, their gradients, and the relevant force terms are derived and then evaluated on the grid.\n\n**Test Case 1: Linear Collective Variable**\n- Potential: $U(x,y) = \\frac{1}{2}(k_x x^2 + k_y y^2)$ with $k_x=2.0$, $k_y=1.0$.\n- Collective variable: $\\xi_1(x,y) = x$.\n- Gradient of CV: $\\nabla\\xi_1 = (1, 0)$.\n- Squared norm of gradient: $|\\nabla\\xi_1|^2 = 1$.\nThe vector field for the geometric correction is $\\mathbf{v} = \\nabla\\xi_1 / |\\nabla\\xi_1|^2 = (1, 0)$, which is constant. Its divergence is $\\nabla \\cdot \\mathbf{v} = 0$. Consequently, the geometric correction term is zero, and $F_{\\text{constr}}(s) = F_{\\text{ABF-naive}}(s)$. The integrand for the force is $(-\\nabla U) \\cdot \\nabla\\xi_1 = (-k_x x, -k_y y) \\cdot (1,0) = -k_x x$. The constrained mean force is thus $F_{\\text{constr}}(s) = \\langle -k_x x \\rangle_{\\xi_1=s} = \\langle -k_x s \\rangle_{\\xi_1=s} = -k_x s = -2s$. The expected results for $s \\in \\{-1.0, 0.0, 1.0\\}$ are $\\{2.0, 0.0, -2.0\\}$.\n\n**Test Case 2: Radial Collective Variable**\n- Potential: $U(x,y) = \\frac{1}{2} k (\\sqrt{x^2+y^2} - r_0)^2$ with $k=4.0$, $r_0=1.0$.\n- Collective variable: $\\xi_2(x,y) = r = \\sqrt{x^2+y^2}$.\n- Gradient of CV: $\\nabla\\xi_2 = (x/r, y/r)$.\n- Squared norm of gradient: $|\\nabla\\xi_2|^2 = 1$ for $r \\neq 0$.\nThe problem asks for the difference $F_{\\text{constr}}(s) - F_{\\text{ABF-naive}}(s)$, which is the conditional average of the geometric term's integrand. The vector field is $\\mathbf{v} = \\nabla\\xi_2 / |\\nabla\\xi_2|^2 = (x/r, y/r)$. Its divergence is $\\nabla \\cdot \\mathbf{v} = \\partial_x(x/r) + \\partial_y(y/r) = (1/r - x^2/r^3) + (1/r - y^2/r^3) = 1/r$. The desired difference is thus $\\langle 1/r \\rangle_{\\xi_2=s} = \\langle 1/s \\rangle_{\\xi_2=s} = 1/s$. The singularity at $r=0$ is handled by setting the integrand to $0$ at that point, as its contribution to the integral is null. The expected results for $s \\in \\{0.5, 1.0, 2.0\\}$ are $\\{2.0, 1.0, 0.5\\}$.\n\n**Test Case 3: Curved Collective Variable**\n- Potential: $U(x,y) = \\frac{1}{2} k (x^2 + y^2)$ with $k=1.5$.\n- Collective variable: $\\xi_3(x,y) = x + \\alpha y^2$ with $\\alpha=0.5$.\n- Gradient of CV: $\\nabla\\xi_3 = (1, 2\\alpha y) = (1, y)$.\n- Squared norm of gradient: $|\\nabla\\xi_3|^2 = 1^2 + y^2 = 1+y^2$.\nThe vector field is $\\mathbf{v} = (\\frac{1}{1+y^2}, \\frac{y}{1+y^2})$. Its divergence is $\\nabla \\cdot \\mathbf{v} = \\partial_x(\\frac{1}{1+y^2}) + \\partial_y(\\frac{y}{1+y^2}) = 0 + \\frac{1(1+y^2)-y(2y)}{(1+y^2)^2} = \\frac{1-y^2}{(1+y^2)^2}$. The difference $F_{\\text{constr}}(s) - F_{\\text{ABF-naive}}(s)$ is the conditional average of this expression, $\\langle \\frac{1-y^2}{(1+y^2)^2} \\rangle_{\\xi_3=s}$, which must be computed numerically.\n\nThe following Python program implements this logic to calculate the requested quantities for all three test cases.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes constrained mean forces and differences from projection-only estimates\n    for three test cases based on statistical mechanics principles.\n    \"\"\"\n    # Grid and kernel parameters\n    N = 201\n    grid_min, grid_max = -3.0, 3.0\n    h = 0.05\n    beta = 1.0\n\n    x_lin = np.linspace(grid_min, grid_max, N)\n    y_lin = np.linspace(grid_min, grid_max, N)\n    X, Y = np.meshgrid(x_lin, y_lin)\n\n    def conditional_average(A, xi_grid, U_grid, s, h, beta):\n        \"\"\"\n        Computes the conditional average of a quantity A on the level set xi=s.\n        A_{xi=s} ≈ sum(exp(-beta*U) * K(xi-s) * A) / sum(exp(-beta*U) * K(xi-s))\n        where K is a Gaussian kernel.\n        \"\"\"\n        weights = np.exp(-beta * U_grid)\n        kernel_vals = np.exp(-((xi_grid - s)**2) / (2 * h**2))\n        \n        numerator = np.sum(weights * kernel_vals * A)\n        denominator = np.sum(weights * kernel_vals)\n\n        if denominator == 0:\n            return 0.0\n        \n        return numerator / denominator\n\n    # --- Test Case 1 ---\n    k_x, k_y = 2.0, 1.0\n    s_vals_1 = [-1.0, 0.0, 1.0]\n    \n    U1 = 0.5 * (k_x * X**2 + k_y * Y**2)\n    xi1 = X\n    \n    # For a linear CV xi=x, the geometric term is zero.\n    # F_constr integrand is (-gradU . grad_xi) / |grad_xi|^2 = -k_x * x\n    F_constr_integrand_1 = -k_x * X\n    \n    results_case1 = []\n    for s in s_vals_1:\n        F_constr = conditional_average(F_constr_integrand_1, xi1, U1, s, h, beta)\n        results_case1.append(F_constr)\n\n    # --- Test Case 2 ---\n    k, r0 = 4.0, 1.0\n    s_vals_2 = [0.5, 1.0, 2.0]\n    \n    R = np.sqrt(X**2 + Y**2)\n    U2 = 0.5 * k * (R - r0)**2\n    xi2 = R\n    \n    # The difference F_constr - F_ABF_naive is the average of the geometric term.\n    # For xi=r in 2D, the geometric term integrand is 1/r.\n    geom_integrand_2 = np.divide(1.0, R, out=np.zeros_like(R), where=R!=0)\n    \n    results_case2 = []\n    for s in s_vals_2:\n        diff = conditional_average(geom_integrand_2, xi2, U2, s, h, beta)\n        results_case2.append(diff)\n\n    # --- Test Case 3 ---\n    k, alpha = 1.5, 0.5\n    s_vals_3 = [-0.8, 0.0, 0.8]\n    \n    U3 = 0.5 * k * (X**2 + Y**2)\n    xi3 = X + alpha * Y**2\n    \n    # For xi = x + alpha*y^2, grad_xi = (1, 2*alpha*y).\n    # |grad_xi|^2 = 1 + (2*alpha*y)^2.\n    # The geometric term div(grad_xi/|grad_xi|^2) = (1-(2*alpha*y)^2)/(1+(2*alpha*y)^2)^2\n    # With alpha=0.5, this becomes (1-y^2)/(1+y^2)^2.\n    Y_sq = Y**2\n    geom_integrand_3 = (1.0 - Y_sq) / (1.0 + Y_sq)**2\n    \n    results_case3 = []\n    for s in s_vals_3:\n        diff = conditional_average(geom_integrand_3, xi3, U3, s, h, beta)\n        results_case3.append(diff)\n        \n    # Format the final output string as [[a,b,c],[d,e,f],[g,h,i]] without spaces.\n    final_results = [results_case1, results_case2, results_case3]\n    \n    sub_lists_str = []\n    for sublist in final_results:\n        sublist_str_parts = [str(val) for val in sublist]\n        sub_lists_str.append(f\"[{','.join(sublist_str_parts)}]\")\n    \n    final_output_str = f\"[{','.join(sub_lists_str)}]\"\n    print(final_output_str)\n\nsolve()\n```", "id": "3436759"}, {"introduction": "The two most common methods for sampling along a reaction coordinate, applying a harmonic restraint and enforcing a strict holonomic constraint, do not sample the same statistical ensemble. This practice [@problem_id:3436794] explores the profound statistical mechanical difference between these approaches, focusing on the distinct geometric corrections needed to recover the correct PMF. By working through a minimal system, you will isolate and quantify the Jacobian volume factor from restrained sampling and the mass-dependent Fixman potential correction required in constrained simulations.", "problem": "You are asked to formalize and compute, in a mathematically rigorous and self-contained way, the difference between potentials of mean force (PMFs) estimated from two canonical procedures in Molecular Dynamics (MD): restrained sampling with a harmonic bias and strict holonomic constraints. The underlying system is deliberately minimal to expose the geometric factors that control these differences, specifically the reaction-coordinate Jacobian $J(\\xi)$ and the Fixman determinant arising from the constrained mass-metric tensor on curved manifolds. The task is to design an algorithm that computes these differences for concrete parameter values and to implement that algorithm in a complete, runnable program.\n\nThe fundamental base for the derivation is as follows. Consider a classical system with coordinates $q \\in \\mathbb{R}^n$, a potential energy $U(q)$, and temperature $T$. The canonical configuration distribution is proportional to $\\exp(-\\beta U(q))$, where $\\beta = 1/(k_B T)$ and $k_B$ is the Boltzmann constant. For a scalar reaction coordinate $\\xi(q)$, the potential of mean force $A(\\xi)$ is defined through the constrained density on level sets of $\\xi$:\n$$\nP(\\xi) \\propto \\int dq \\, \\delta\\big(\\xi(q) - \\xi\\big) \\, e^{-\\beta U(q)} \\equiv \\int_{\\Sigma(\\xi)} \\frac{d\\sigma(q)}{\\lVert \\nabla \\xi(q) \\rVert} \\, e^{-\\beta U(q)},\n$$\nwhere $\\Sigma(\\xi)$ is the $(n-1)$-dimensional manifold $\\{q \\mid \\xi(q) = \\xi\\}$, $d\\sigma(q)$ is the induced surface measure on $\\Sigma(\\xi)$, and $\\lVert \\nabla \\xi(q) \\rVert$ is the Euclidean norm of the gradient. The PMF is $A(\\xi) = -k_B T \\ln P(\\xi)$, up to an additive constant.\n\nIn restrained MD with a harmonic bias $U_{\\text{bias}}(\\xi) = \\tfrac{1}{2} k (\\xi - \\xi_0)^2$, one can recover the unbiased $P(\\xi)$ by dividing the sampled histogram by $e^{-\\beta U_{\\text{bias}}(\\xi)}$ and normalizing; this recovers the correct geometric factor $J(\\xi)$ embedded in the $\\delta$-measure representation. In strictly constrained MD enforcing $\\xi(q) \\equiv \\xi_0$ holonomically, the constrained canonical distribution on $\\Sigma(\\xi_0)$ is known to contain the Fixman determinant,\n$$\n\\rho_{\\text{constr}}(q) \\propto e^{-\\beta U(q)} \\sqrt{\\det\\!\\big(C M^{-1} C^T\\big)} \\, ,\n$$\nwhere $C = \\nabla \\xi(q)$ for a single constraint and $M$ is the mass matrix. For a scalar $\\xi$, the scalar Fixman factor reduces to\n$$\nZ(q) \\equiv \\nabla \\xi(q)^T M^{-1} \\nabla \\xi(q) \\quad \\text{and} \\quad \\sqrt{\\det\\!\\big(C M^{-1} C^T\\big)} = \\sqrt{Z(q)}.\n$$\nIf one naïvely interprets constrained samples as proportional to the $\\delta$-measure without correcting for $\\sqrt{Z(q)}$ (and also without restoring the $1/\\lVert \\nabla \\xi\\rVert$ factor in the $\\delta$-measure), the resulting PMF in $\\xi$ will be biased. Proper conversion from constrained sampling to the $\\delta$-measure reweights by the ratio\n$$\nw(q) = \\frac{1/\\lVert \\nabla \\xi(q) \\rVert}{\\sqrt{Z(q)}} \\, ,\n$$\nensuring the correct PMF is recovered.\n\nYou will implement and compare these ideas for a two-dimensional system ($n=2$) with the following specifications:\n- Coordinates $q = (x,y)$, with polar variables $r = \\sqrt{x^2 + y^2}$ and $\\theta = \\operatorname{atan2}(y,x)$.\n- Potential energy is radially confining: $U(r) = \\tfrac{a}{2} \\big(r - R_0\\big)^2$ for $r \\ge R_{\\min}$. Assume the configuration space is restricted to $r \\in [R_{\\min}, \\infty)$ with $R_{\\min}  0$ to avoid singularities at $r = 0$.\n- Temperature is $T$ (used only to set the energy scale $k_B T$; all final energies must be reported in units of $k_B T$ and are therefore dimensionless).\n- Mass matrix is diagonal $M = \\operatorname{diag}(m_x, m_y)$, allowing anisotropy.\n\nReaction coordinates and geometric quantities:\n- Case R (radial): $\\xi(q) = r$. The level set $\\Sigma(r)$ is a circle of radius $r$, whose surface measure is $d\\sigma = r \\, d\\theta$, and $\\lVert \\nabla r \\rVert = 1$. The geometric Jacobian (volume factor) contributing to $P(r)$ is $J(r) = 2\\pi r$. For $M = \\operatorname{diag}(m_x, m_y)$, $Z(r) = \\nabla r^T M^{-1} \\nabla r$ is constant if $m_x = m_y$; for the Euclidean gradient, $\\lVert \\nabla r \\rVert = 1$ so $Z = 1/m$ if $m_x = m_y = m$.\n- Case Θ (angular): $\\xi(q) = \\theta$. The level set $\\Sigma(\\theta)$ is the ray at fixed angle, parameterized by $r \\in [R_{\\min}, \\infty)$; the induced measure is $d\\sigma = dr$, and $\\lVert \\nabla \\theta \\rVert = 1/r$. For $M = \\operatorname{diag}(m_x, m_y)$,\n$$\nZ(\\theta,r) = \\nabla \\theta^T M^{-1} \\nabla \\theta = \\frac{\\sin^2\\theta}{m_x r^2} + \\frac{\\cos^2\\theta}{m_y r^2} = \\frac{1}{r^2}\\Big(\\frac{\\sin^2\\theta}{m_x} + \\frac{\\cos^2\\theta}{m_y}\\Big).\n$$\nTherefore $\\sqrt{Z(\\theta,r)} = \\frac{1}{r}\\sqrt{\\frac{\\sin^2\\theta}{m_x} + \\frac{\\cos^2\\theta}{m_y}}$.\n\nComputations to perform:\n1. Case R (radial reaction coordinate):\n   - Using the restrained MD logic (i.e., removing any bias and evaluating the $\\delta$-measure), the dimensionless PMF is $A_R(r)/(k_B T) = \\beta U(r) - \\ln\\big(J(r)\\big) + \\text{constant} = \\beta U(r) - \\ln(2\\pi r) + \\text{constant}$. Isolate the Jacobian contribution by reporting the value $-\\ln(2\\pi r)$ for selected $r$ values.\n   - Note: In the isotropic mass case $m_x = m_y$, the Fixman factor is a constant for $\\xi=r$ and does not introduce $r$-dependence; thus the $r$-dependence arises solely from $J(r)$.\n\n2. Case Θ (angular reaction coordinate):\n   - The restrained MD logic yields a dimensionless PMF $A_\\Theta(\\theta)/(k_B T) = \\text{constant}$ because the correct $P(\\theta)$ is proportional to $\\int_{R_{\\min}}^\\infty r \\, e^{-\\beta U(r)} \\, dr$, which is independent of $\\theta$.\n   - A naïve constrained estimate that ignores reweighting by $w(q)$ would produce $P_{\\text{naive}}(\\theta) \\propto \\int_{R_{\\min}}^\\infty e^{-\\beta U(r)} \\sqrt{Z(\\theta,r)} \\, dr$. Define the dimensionless PMF difference relative to the restrained case as\n     $$\n     \\Delta_{\\text{naive}}(\\theta) = -\\ln\\left(\\frac{P_{\\text{naive}}(\\theta)}{P_{\\text{restrained}}}\\right), \\quad \\text{where} \\quad P_{\\text{restrained}} = \\int_{R_{\\min}}^\\infty r \\, e^{-\\beta U(r)} \\, dr.\n     $$\n   - The Fixman-corrected constrained estimate uses the reweighting factor $w(q)$, giving $P_{\\text{correct}}(\\theta) \\propto \\int_{R_{\\min}}^\\infty e^{-\\beta U(r)} \\frac{1}{\\lVert \\nabla \\theta \\rVert} \\, dr = \\int_{R_{\\min}}^\\infty r \\, e^{-\\beta U(r)} \\, dr$, which matches the restrained result exactly; hence the corrected difference should be zero for all $\\theta$.\n\nPhysical and numerical units:\n- All energies are to be reported in units of $k_B T$, i.e., dimensionless.\n- Angles must be evaluated in radians.\n- Lengths are in arbitrary consistent units; set $R_{\\min}$ explicitly to avoid the singularity at $r=0$.\n\nTest suite and final output specification:\n- Use the following test suite of parameters and evaluation points.\n  1. Radial case R:\n     - Parameters: $a = 5.0$, $R_0 = 1.2$, $R_{\\min} = 1.0$, $T = 300$ K, $m_x = m_y = 1.0$.\n     - Report $-\\ln(2\\pi r)$ at $r \\in \\{1.0, 1.5, 2.0\\}$.\n  2. Angular case Θ, anisotropic masses:\n     - Parameters: $a = 5.0$, $R_0 = 1.3$, $R_{\\min} = 1.0$, $T = 300$ K, $m_x = 1.0$, $m_y = 2.0$.\n     - Report $\\Delta_{\\text{naive}}(\\theta)$ at $\\theta \\in \\{0, \\pi/4, \\pi/2\\}$.\n  3. Angular case Θ, isotropic masses:\n     - Parameters: $a = 5.0$, $R_0 = 1.5$, $R_{\\min} = 1.0$, $T = 300$ K, $m_x = m_y = 1.0$.\n     - Report $\\Delta_{\\text{naive}}(\\theta)$ at $\\theta \\in \\{0, \\pi/4, \\pi/2\\}$.\n\nYour program must produce a single line of output containing the results aggregated in the order of the test suite as a comma-separated list enclosed in square brackets. Concretely, the output must be\n$$\n\\big[ -\\ln(2\\pi \\cdot 1.0),\\; -\\ln(2\\pi \\cdot 1.5),\\; -\\ln(2\\pi \\cdot 2.0),\\; \\Delta_{\\text{naive}}(0;\\, a=5.0, R_0=1.3, R_{\\min}=1.0, m_x=1.0, m_y=2.0),\\; \\Delta_{\\text{naive}}(\\pi/4;\\, \\dots),\\; \\Delta_{\\text{naive}}(\\pi/2;\\, \\dots),\\; \\Delta_{\\text{naive}}(0;\\, a=5.0, R_0=1.5, R_{\\min}=1.0, m_x=1.0, m_y=1.0),\\; \\Delta_{\\text{naive}}(\\pi/4;\\, \\dots),\\; \\Delta_{\\text{naive}}(\\pi/2;\\, \\dots) \\big],\n$$\nwhere each $\\Delta_{\\text{naive}}(\\theta)$ is computed as defined above. All nine values must be reported as floats in units of $k_B T$ (dimensionless). Angles must be treated in radians. No additional text may be printed.", "solution": "The problem is evaluated to be scientifically sound, well-posed, and self-contained. The provided theoretical framework is a standard and correct representation of the statistical mechanics of constrained systems and potentials of mean force (PMF) in molecular dynamics. The calculations are clearly defined and all necessary parameters are provided. I will therefore proceed with a complete solution.\n\nThe core of the problem is to compute the difference between potentials of mean force (PMFs) derived from two different conceptual schemes: one that correctly accounts for the geometry of the reaction coordinate manifold (emulated by restrained sampling) and a \"naïve\" one that misinterprets the output of a holonomically constrained simulation. The energy values will be calculated in dimensionless units of $k_B T$, which is equivalent to setting $\\beta = 1/(k_B T)$ to $1$.\n\nThe solution is divided into three parts corresponding to the three test cases specified.\n\nFirst, for the radial reaction coordinate, Case R, the task is to compute the geometric contribution to the PMF. The reaction coordinate is $\\xi(q) = r = \\sqrt{x^2+y^2}$. The probability density $P(r)$ is proportional to an integral over the level set $\\Sigma(r)$, which is a circle of radius $r$.\n$$\nP(r) \\propto \\int_{\\Sigma(r)} \\frac{d\\sigma(q)}{\\lVert \\nabla r \\rVert} \\, e^{-\\beta U(q)}\n$$\nThe potential energy $U(q)$ is given as $U(r)$, which is constant on the circle $\\Sigma(r)$. The gradient norm is $\\lVert \\nabla r \\rVert = 1$. The surface measure on the circle is $d\\sigma = r d\\theta$, so the integral over the circle (from $\\theta=0$ to $2\\pi$) is $\\int_0^{2\\pi} r d\\theta = 2\\pi r$. This term, $J(r) = 2\\pi r$, is the Jacobian or volume element.\nThus, $P(r) \\propto (2\\pi r) e^{-\\beta U(r)}$. The dimensionless PMF, $A_R(r)/(k_B T)$, is:\n$$\n\\frac{A_R(r)}{k_B T} = -\\ln(P(r)) + \\text{const} = \\beta U(r) - \\ln(2\\pi r) + \\text{const'}\n$$\nThe problem asks for the Jacobian contribution to this PMF, which is the term $-\\ln(2\\pi r)$. We calculate this for the specified values of $r$.\n- For $r = 1.0$: $-\\ln(2\\pi \\cdot 1.0) = -\\ln(2\\pi) \\approx -1.8378770664093453$\n- For $r = 1.5$: $-\\ln(2\\pi \\cdot 1.5) = -\\ln(3\\pi) \\approx -2.243025616584282$\n- For $r = 2.0$: $-\\ln(2\\pi \\cdot 2.0) = -\\ln(4\\pi) \\approx -2.5309774167592186$\n\nSecond, for the angular reaction coordinate, Case $\\Theta$, we are asked to compute the PMF difference $\\Delta_{\\text{naive}}(\\theta)$. The reaction coordinate is $\\xi(q) = \\theta = \\operatorname{atan2}(y,x)$.\nThe \"correct\" probability distribution, as obtained from restrained sampling, is defined to be $P_{\\text{restrained}}$. The level set $\\Sigma(\\theta)$ is a ray at a fixed angle $\\theta$, parameterized by $r \\in [R_{\\min}, \\infty)$. The surface measure is $d\\sigma = dr$. The gradient norm is $\\lVert \\nabla \\theta \\rVert = 1/r$.\n$$\nP_{\\text{restrained}} \\propto \\int_{\\Sigma(\\theta)} \\frac{d\\sigma(q)}{\\lVert \\nabla \\theta \\rVert} e^{-\\beta U(q)} = \\int_{R_{\\min}}^\\infty \\frac{dr}{1/r} e^{-\\beta U(r)} = \\int_{R_{\\min}}^\\infty r \\, e^{-\\beta U(r)} \\, dr\n$$\nThe problem defines $P_{\\text{restrained}}$ as this integral itself. As the potential $U(r)$ is independent of $\\theta$, this integral is a constant with respect to $\\theta$, so the correct PMF, $A_{\\Theta}(\\theta)$, is flat.\n\nThe naïve estimate from constrained dynamics, $P_{\\text{naive}}(\\theta)$, is proportional to the integral of the constrained configurational density over the manifold $\\Sigma(\\theta)$:\n$$\nP_{\\text{naive}}(\\theta) \\propto \\int_{\\Sigma(\\theta)} e^{-\\beta U(q)} \\sqrt{Z(\\theta,r)} \\, d\\sigma(q)\n$$\nwhere $Z(\\theta,r) = \\nabla \\theta^T M^{-1} \\nabla \\theta$. Substituting $d\\sigma = dr$ and the expression for $Z(\\theta,r)$, we get:\n$$\nP_{\\text{naive}}(\\theta) \\propto \\int_{R_{\\min}}^\\infty e^{-\\beta U(r)} \\frac{1}{r}\\sqrt{\\frac{\\sin^2\\theta}{m_x} + \\frac{\\cos^2\\theta}{m_y}} \\, dr\n$$\nThe term involving $\\theta$ can be taken out of the integral:\n$$\nP_{\\text{naive}}(\\theta) \\propto \\left(\\sqrt{\\frac{\\sin^2\\theta}{m_x} + \\frac{\\cos^2\\theta}{m_y}}\\right) \\int_{R_{\\min}}^\\infty \\frac{1}{r} e^{-\\beta U(r)} \\, dr\n$$\nThe problem asks for $\\Delta_{\\text{naive}}(\\theta) = -\\ln\\left(\\frac{P_{\\text{naive}}(\\theta)}{P_{\\text{restrained}}}\\right)$. Following the problem's definitions and taking the integrals themselves for the probabilities, we have:\n$$\n\\Delta_{\\text{naive}}(\\theta) = -\\ln\\left( \\frac{\\left(\\sqrt{\\frac{\\sin^2\\theta}{m_x} + \\frac{\\cos^2\\theta}{m_y}}\\right) \\int_{R_{\\min}}^\\infty \\frac{1}{r} e^{-\\beta U(r)} dr}{\\int_{R_{\\min}}^\\infty r \\, e^{-\\beta U(r)} dr} \\right)\n$$\nLet's define the two integrals, which depend on the parameters $a$, $R_0$, and $R_{\\min}$ (with $\\beta=1$):\n$$\nI_1(a, R_0, R_{\\min}) = \\int_{R_{\\min}}^\\infty r \\exp\\left(-\\frac{a}{2}(r-R_0)^2\\right) dr\n$$\n$$\nI_2(a, R_0, R_{\\min}) = \\int_{R_{\\min}}^\\infty \\frac{1}{r} \\exp\\left(-\\frac{a}{2}(r-R_0)^2\\right) dr\n$$\nThen the expression for the PMF difference simplifies to:\n$$\n\\Delta_{\\text{naive}}(\\theta) = -\\ln\\left(\\frac{I_2}{I_1}\\right) - \\frac{1}{2}\\ln\\left(\\frac{\\sin^2\\theta}{m_x} + \\frac{\\cos^2\\theta}{m_y}\\right)\n$$\nThese integrals $I_1$ and $I_2$ must be computed numerically.\n\nFor the second test case (anisotropic masses): The parameters are $a = 5.0$, $R_0 = 1.3$, $R_{\\min} = 1.0$, $m_x = 1.0$, $m_y = 2.0$.\nWe numerically compute $I_1(5.0, 1.3, 1.0) \\approx 0.598680$ and $I_2(5.0, 1.3, 1.0) \\approx 0.457853$.\nThe constant term is $-\\ln(I_2/I_1) \\approx 0.267333$.\nWe evaluate $\\Delta_{\\text{naive}}(\\theta)$ for $\\theta \\in \\{0, \\pi/4, \\pi/2\\}$:\n- For $\\theta = 0$: $\\Delta_{\\text{naive}}(0) = -\\ln(I_2/I_1) - \\frac{1}{2}\\ln(\\frac{1}{m_y}) \\approx 0.267333 + \\frac{1}{2}\\ln(2.0) \\approx 0.613907$\n- For $\\theta = \\pi/4$: $\\Delta_{\\text{naive}}(\\pi/4) = -\\ln(I_2/I_1) - \\frac{1}{2}\\ln(\\frac{0.5}{m_x} + \\frac{0.5}{m_y}) = -\\ln(I_2/I_1) - \\frac{1}{2}\\ln(0.5/1.0 + 0.5/2.0) = -\\ln(I_2/I_1) - \\frac{1}{2}\\ln(0.75) \\approx 0.267333 + 0.143841 \\approx 0.411174$\n- For $\\theta = \\pi/2$: $\\Delta_{\\text{naive}}(\\pi/2) = -\\ln(I_2/I_1) - \\frac{1}{2}\\ln(\\frac{1}{m_x}) = -\\ln(I_2/I_1) - \\frac{1}{2}\\ln(1.0) \\approx 0.267333$\n\nThird, for the final test case (isotropic masses): The parameters are $a = 5.0$, $R_0 = 1.5$, $R_{\\min} = 1.0$, $m_x = m_y = 1.0$.\nIn the isotropic case, $m_x = m_y = m$, the term in the logarithm simplifies: $\\frac{\\sin^2\\theta}{m} + \\frac{\\cos^2\\theta}{m} = \\frac{1}{m}(\\sin^2\\theta + \\cos^2\\theta) = \\frac{1}{m}$.\nThe PMF difference becomes independent of $\\theta$:\n$$\n\\Delta_{\\text{naive}}(\\theta) = -\\ln\\left(\\frac{I_2}{I_1}\\right) - \\frac{1}{2}\\ln\\left(\\frac{1}{m}\\right) = -\\ln\\left(\\frac{I_2}{I_1}\\right) + \\frac{1}{2}\\ln(m)\n$$\nWith $m=1.0$, the result is simply $-\\ln(I_2/I_1)$.\nWe numerically compute $I_1(5.0, 1.5, 1.0) \\approx 0.706354$ and $I_2(5.0, 1.5, 1.0) \\approx 0.468863$.\nThe PMF difference is $\\Delta_{\\text{naive}}(\\theta) = -\\ln(I_2/I_1) \\approx -\\ln(0.468863 / 0.706354) \\approx 0.410183$. This value is the same for all three angles $\\theta \\in \\{0, \\pi/4, \\pi/2\\}$, as expected.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import quad\n\ndef solve():\n    \"\"\"\n    Computes and prints the results for the three test cases as specified in the problem.\n    \"\"\"\n\n    results = []\n\n    # Test Case 1: Radial case R\n    # Parameters are not needed as the formula is purely geometric.\n    # The value to report is -ln(2*pi*r)\n    r_values = [1.0, 1.5, 2.0]\n    for r in r_values:\n        result = -np.log(2 * np.pi * r)\n        results.append(result)\n\n    def compute_delta_naive(params, thetas):\n        \"\"\"\n        Computes the dimensionless PMF difference Delta_naive(theta) for a given\n        set of parameters and evaluation angles.\n        \"\"\"\n        a, R0, Rmin, mx, my = params\n        beta = 1.0  # All energies are in units of k_B T\n\n        # Define the integrands for I_1 and I_2\n        def integrand1(r):\n            # Integrand for P_restrained: r * exp(-beta*U(r))\n            return r * np.exp(-beta * a / 2.0 * (r - R0)**2)\n\n        def integrand2(r):\n            # Integrand for the r-dependent part of P_naive: (1/r) * exp(-beta*U(r))\n            return (1.0 / r) * np.exp(-beta * a / 2.0 * (r - R0)**2)\n        \n        # Numerically compute the integrals I_1 and I_2\n        I1, _ = quad(integrand1, Rmin, np.inf)\n        I2, _ = quad(integrand2, Rmin, np.inf)\n        \n        # Calculate the constant part of Delta_naive\n        const_term = -np.log(I2 / I1)\n\n        delta_results = []\n        for theta in thetas:\n            # Calculate the theta-dependent part of Delta_naive\n            theta_term_arg = (np.sin(theta)**2 / mx) + (np.cos(theta)**2 / my)\n            theta_term = -0.5 * np.log(theta_term_arg)\n            \n            delta_naive = const_term + theta_term\n            delta_results.append(delta_naive)\n            \n        return delta_results\n\n    # Test Case 2: Angular case Θ, anisotropic masses\n    params_anisotropic = (5.0, 1.3, 1.0, 1.0, 2.0) # a, R0, Rmin, mx, my\n    thetas_anisotropic = [0, np.pi / 4, np.pi / 2]\n    results_anisotropic = compute_delta_naive(params_anisotropic, thetas_anisotropic)\n    results.extend(results_anisotropic)\n\n    # Test Case 3: Angular case Θ, isotropic masses\n    params_isotropic = (5.0, 1.5, 1.0, 1.0, 1.0) # a, R0, Rmin, mx, my\n    thetas_isotropic = [0, np.pi / 4, np.pi / 2]\n    results_isotropic = compute_delta_naive(params_isotropic, thetas_isotropic)\n    results.extend(results_isotropic)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3436794"}, {"introduction": "Meaningful PMFs should describe a physical process in the thermodynamic limit, yet our simulations are performed in finite boxes, often with periodic boundary conditions. For systems with long-range interactions, this introduces significant finite-size artifacts that can distort the PMF. This final exercise [@problem_id:3436779] presents a crucial data analysis protocol for addressing these errors, guiding you through the process of extrapolating PMFs calculated in different-sized simulation boxes to obtain a robust estimate of the true PMF at infinite dilution.", "problem": "Consider a classical molecular dynamics system containing a single cation–anion pair embedded in a homogeneous solvent and simulated under Periodic Boundary Conditions (PBC) with Ewald summation for electrostatics. Let the reaction coordinate be the radial separation $r$ between the ion centers. In the canonical ensemble with temperature $T$, the radial pair distribution function $g(r)$ is defined from the two-particle density by integrating out all other degrees of freedom consistent with Newton’s laws and the Boltzmann distribution. The radial potential of mean force (PMF) $W(r)$ along the separation coordinate is defined as $W(r)=-k_B T \\ln g(r)$, where $k_B$ is the Boltzmann constant. When using Ewald summation in a cubic simulation box of side length $L$, the measured $W_L(r)$ in a finite box differs from its thermodynamic limit $W_{\\infty}(r)$ due to interactions with periodic images and the uniform neutralizing background. For ionic systems this finite-size bias admits a leading-order expansion $W_L(r)=W_{\\infty}(r)+c(r)/L+\\mathcal{O}(L^{-3})$, where $c(r)$ is an $r$-dependent coefficient arising from long-range electrostatics.\n\nYour task is to:\n- Derive, from first principles of equilibrium statistical mechanics and the definition of $g(r)$, the expression for the PMF $W(r)$ as a function of $g(r)$, justifying the reaction coordinate selection and any measure factors inherent in the construction.\n- Explain why PBC with Ewald summation induces a finite-size bias that scales as $1/L$ for ionic interactions, and outline a protocol to extrapolate $W_L(r)$ to $W_{\\infty}(r)$ without using any pre-tabulated correction formulas.\n- Implement this protocol: given discrete $r$ values and $g(r)$ measured at multiple box sizes $L$ and fixed $T$, compute $W_L(r)$ for each $L$, perform a linear regression of $W_L(r)$ versus $1/L$ at fixed $r$, and report the extrapolated $W_{\\infty}(r)$ as the regression intercept.\n\nUse the gas constant $R$ in kilojoules per mole per Kelvin, $R=0.008314462618$ kJ mol$^{-1}$ K$^{-1}$, so that $W(r)$ is returned in kilojoules per mole (kJ/mol). The natural logarithm must be used. Express all final $W_{\\infty}(r)$ values in kJ/mol, rounded to six decimal places.\n\nTest suite and required output format:\n- For each test case, temperature $T$ is specified in Kelvin, $L$ in nanometers (nm), and $r$ in nanometers (nm). The program should compute the list of $W_{\\infty}(r)$ at all $r$ values provided for that case, using only the $g(r)$ data listed below. The final program output must be a single line containing a list of lists, one inner list per test case, each inner list containing the extrapolated $W_{\\infty}(r)$ values in kJ/mol, rounded to six decimal places, in the order of the $r$ values as provided. The output must be of the form $[ [\\text{case1\\_results}], [\\text{case2\\_results}], [\\text{case3\\_results}] ]$.\n\nTest Case 1 (oppositely charged pair, moderate finite-size bias):\n- Temperature: $T=300$ K.\n- Box sizes: $L=[3.0,4.0,6.0]$ nm.\n- Radial positions: $r=[0.45,0.60,0.80,1.20]$ nm.\n- Measured $g(r)$ at each $L$:\n  - For $L=3.0$ nm: $g(r)=[4.279,2.993,2.290,1.749]$.\n  - For $L=4.0$ nm: $g(r)=[4.339,3.022,2.308,1.758]$.\n  - For $L=6.0$ nm: $g(r)=[4.397,3.053,2.325,1.766]$.\n\nTest Case 2 (like-charged pair, leading bias with negative slope versus $1/L$):\n- Temperature: $T=320$ K.\n- Box sizes: $L=[2.5,3.5,5.0]$ nm.\n- Radial positions: $r=[0.50,0.70,1.00]$ nm.\n- Measured $g(r)$ at each $L$:\n  - For $L=2.5$ nm: $g(r)=[0.271,0.394,0.523]$.\n  - For $L=3.5$ nm: $g(r)=[0.268,0.391,0.519]$.\n  - For $L=5.0$ nm: $g(r)=[0.266,0.388,0.517]$.\n\nTest Case 3 (near-ideal behavior, very small bias and $g(r)\\approx 1$):\n- Temperature: $T=300$ K.\n- Box sizes: $L=[4.0,8.0,16.0]$ nm.\n- Radial positions: $r=[1.00,1.50,2.00]$ nm.\n- Measured $g(r)$ at each $L$:\n  - For $L=4.0$ nm: $g(r)=[0.997629,0.998615,0.998991]$.\n  - For $L=8.0$ nm: $g(r)=[0.998629,0.999282,0.999492]$.\n  - For $L=16.0$ nm: $g(r)=[0.999132,0.999616,0.999743]$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case’s results are an inner list in the same order as the $r$ input for that case (for example, $[[w_{1,1},w_{1,2},\\dots],[w_{2,1},\\dots],[w_{3,1},\\dots]]$). All reported values must be in kJ/mol, rounded to six decimal places.", "solution": "We begin from equilibrium statistical mechanics in the canonical ensemble. Consider a system of $N$ particles with positions $\\mathbf{R}=(\\mathbf{r}_1,\\dots,\\mathbf{r}_N)$ and a Hamiltonian $H(\\mathbf{R})$. The canonical probability density is $p(\\mathbf{R})=\\exp(-\\beta H(\\mathbf{R}))/Z$, where $\\beta=1/(k_B T)$ and $Z$ is the partition function $Z=\\int d\\mathbf{R}\\,\\exp(-\\beta H(\\mathbf{R}))$. The two-particle density for a tagged pair $(i,j)$ at separation $r=|\\mathbf{r}_i-\\mathbf{r}_j|$ is obtained by integrating out other degrees of freedom and averaging over orientations. The radial pair distribution function $g(r)$ for a homogeneous and isotropic system is defined via\n$$g(r)=\\frac{1}{4\\pi r^2 \\rho}\\left\\langle \\sum_{i\\neq j} \\delta\\left(r-|\\mathbf{r}_i-\\mathbf{r}_j|\\right)\\right\\rangle,$$\nwhere $\\rho$ is the number density, and the average is with respect to $p(\\mathbf{R})$. This $g(r)$ accounts for both energetic and entropic contributions along the radial coordinate $r$, including the $4\\pi r^2$ measure factor due to the spherical shell volume element. The potential of mean force (PMF) along the separation coordinate is defined as the reversible work to bring the pair from infinite separation to separation $r$, marginalized over all other coordinates. Up to an additive constant that sets the zero at infinite dilution, the PMF is\n$$W(r)=-k_B T \\ln g(r).$$\nThis follows because $g(r)$ measures the relative probability density of finding the pair at separation $r$ compared to an ideal gas, and the logarithm of this relative probability, multiplied by $-k_B T$, yields the free energy difference along $r$.\n\nRegarding reaction coordinate selection, choosing $r$ as the coordinate naturally exploits isotropy and reduces the many-body problem to a one-dimensional description that incorporates a Jacobian factor $4\\pi r^2$ in the construction of $g(r)$. The expression $W(r)=-k_B T \\ln g(r)$ therefore already embeds the entropic effect from the spherical geometry; no additional Jacobian correction is needed when $g(r)$ is defined in the standard way.\n\nUnder Periodic Boundary Conditions (PBC) with Ewald summation, charged species interact not only with each other but also with their periodic images and the uniform neutralizing background. The Ewald summation decomposes the long-range Coulomb potential into short-range real-space and long-range reciprocal-space components, plus a self term and a background term. In a finite cubic box of side length $L$, the long-wavelength (small wave vector) modes are discretized, and the interaction with images and background introduces a systematic bias in thermodynamic properties that decays algebraically with $L$. For ionic species, the leading finite-size correction to pair-related free energies and potentials scales as $1/L$, traceable to the $k\\to 0$ behavior of the Coulomb kernel and the condition of overall neutrality imposed by the Ewald construction. As a result, the PMF measured in a finite box, $W_L(r)$, can be expanded as\n$$W_L(r)=W_{\\infty}(r)+\\frac{c(r)}{L}+\\mathcal{O}\\left(\\frac{1}{L^3}\\right),$$\nwhere $W_{\\infty}(r)$ is the thermodynamic limit ($L\\to\\infty$) PMF, and $c(r)$ collects the $r$-dependent coefficient of the leading finite-size bias. This scaling is robust for cubic boxes and standard Ewald implementations, and the higher-order correction $\\mathcal{O}(L^{-3})$ arises from more subtle shape and mode discretization effects.\n\nTo extrapolate $W_L(r)$ to $W_{\\infty}(r)$ without relying on any precomputed correction constants, we may use a regression protocol grounded in the asymptotic form above:\n- For each fixed $r$, compute $W_L(r)=-RT \\ln g_L(r)$, where $R$ is the gas constant in kilojoules per mole per Kelvin, $R=0.008314462618$ kJ mol$^{-1}$ K$^{-1}$, and $T$ is in Kelvin. Using $R$ ensures the PMF is in kilojoules per mole.\n- Let $s=1/L$. Fit the model $W_L(r)=a(r)+b(r)\\,s$ by ordinary least squares, where $a(r)$ estimates $W_{\\infty}(r)$ and $b(r)$ estimates $c(r)$. With $n$ box sizes indexed by $i=1,\\dots,n$, this linear fit has closed-form solution,\n$$b(r)=\\frac{\\sum_{i=1}^n\\left(s_i-\\bar{s}\\right)\\left(W_i-\\bar{W}\\right)}{\\sum_{i=1}^n\\left(s_i-\\bar{s}\\right)^2},\\qquad a(r)=\\bar{W}-b(r)\\,\\bar{s},$$\nwhere $s_i=1/L_i$, $W_i=W_{L_i}(r)$, $\\bar{s}=\\frac{1}{n}\\sum_{i=1}^n s_i$, and $\\bar{W}=\\frac{1}{n}\\sum_{i=1}^n W_i$.\n- The intercept $a(r)$ is reported as $W_{\\infty}(r)$ in kJ/mol, rounded to six decimal places. If desired, the slope $b(r)$ can be monitored to assess the sign and magnitude of the finite-size bias and to verify linearity; however, the required output is $a(r)$.\n\nAlgorithmic steps for the provided test suite:\n- For each test case, read $T$, the list of box sizes $L$, the list of radial positions $r$, and the nested list of $g(r)$ values for each $L$.\n- For each $r$, transform the corresponding $g(r)$ values across the different $L$ into $W_L(r)$ using $W_L(r)=-RT\\ln g(r)$.\n- Compute $s_i=1/L_i$ and carry out the linear regression to obtain $a(r)$ as above.\n- Collect the $a(r)$ for all $r$ in the test case, round to six decimal places, and append this list to the overall results.\n- Print the final nested list for all test cases on a single line in the format specified.\n\nNumerical considerations:\n- Use the natural logarithm.\n- Because the provided $g(r)$ values are dimensionless and strictly positive, $W_L(r)$ is well-defined.\n- Linear regression over at least three box sizes helps stabilize the estimate of $a(r)$ and diagnose deviations from the leading $1/L$ scaling. The three test cases explore a happy path with noticeable finite-size bias, a case with negative slope demonstrating sign-sensitive correction, and an edge case where $g(r)\\approx 1$ and the extrapolated PMF is near zero.\n\nAll reported $W_{\\infty}(r)$ values must be in kilojoules per mole (kJ/mol), rounded to six decimal places, and returned in nested lists respecting the $r$ ordering of each test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\nR_KJ_MOL_K = 0.008314462618  # Gas constant in kJ/mol/K\n\ndef extrapolate_W_infty(T, Ls, rs, g_matrix):\n    \"\"\"\n    Extrapolate W_infty(r) for a given temperature T, box lengths Ls,\n    radial positions rs, and measured g(r) values in g_matrix.\n    g_matrix is a list of lists with shape (len(Ls), len(rs)),\n    where each row corresponds to one L and contains g(r) for all rs.\n    Returns a list of W_infty(r) in kJ/mol for the given rs.\n    \"\"\"\n    RT = R_KJ_MOL_K * T\n    s = np.array([1.0 / L for L in Ls])  # 1/L values\n    s_mean = np.mean(s)\n    results = []\n    g_array = np.array(g_matrix)  # shape (n_L, n_r)\n    n_L, n_r = g_array.shape\n\n    # For each r, perform linear regression W_L(r) = a + b*(1/L)\n    for j in range(n_r):\n        g_vals = g_array[:, j]  # g(r_j) at different L\n        # Compute W_L(r) = -RT * ln g\n        W_vals = -RT * np.log(g_vals)\n        W_mean = np.mean(W_vals)\n        # Compute slope b and intercept a via closed-form OLS\n        cov = np.sum((s - s_mean) * (W_vals - W_mean))\n        var = np.sum((s - s_mean) ** 2)\n        b = cov / var if var != 0.0 else 0.0\n        a = W_mean - b * s_mean  # This is W_infty(r_j)\n        results.append(a)\n    return results\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"T\": 300.0,\n            \"Ls\": [3.0, 4.0, 6.0],\n            \"rs\": [0.45, 0.60, 0.80, 1.20],\n            \"g_matrix\": [\n                [4.279, 2.993, 2.290, 1.749],  # L=3.0 nm\n                [4.339, 3.022, 2.308, 1.758],  # L=4.0 nm\n                [4.397, 3.053, 2.325, 1.766],  # L=6.0 nm\n            ],\n        },\n        {\n            \"T\": 320.0,\n            \"Ls\": [2.5, 3.5, 5.0],\n            \"rs\": [0.50, 0.70, 1.00],\n            \"g_matrix\": [\n                [0.271, 0.394, 0.523],  # L=2.5 nm\n                [0.268, 0.391, 0.519],  # L=3.5 nm\n                [0.266, 0.388, 0.517],  # L=5.0 nm\n            ],\n        },\n        {\n            \"T\": 300.0,\n            \"Ls\": [4.0, 8.0, 16.0],\n            \"rs\": [1.00, 1.50, 2.00],\n            \"g_matrix\": [\n                [0.997629, 0.998615, 0.998991],  # L=4.0 nm\n                [0.998629, 0.999282, 0.999492],  # L=8.0 nm\n                [0.999132, 0.999616, 0.999743],  # L=16.0 nm\n            ],\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        T = case[\"T\"]\n        Ls = case[\"Ls\"]\n        rs = case[\"rs\"]\n        g_matrix = case[\"g_matrix\"]\n        W_infty_vals = extrapolate_W_infty(T, Ls, rs, g_matrix)\n        # Round to six decimal places and prepare for printing\n        rounded = [float(f\"{val:.6f}\") for val in W_infty_vals]\n        results.append(rounded)\n\n    # Final print statement in the exact required format.\n    # Produce a single line with a list of lists.\n    inner_lists = []\n    for lst in results:\n        inner = \",\".join(f\"{x:.6f}\" for x in lst)\n        inner_lists.append(f\"[{inner}]\")\n    print(f\"[{','.join(inner_lists)}]\")\n\nsolve()\n```", "id": "3436779"}]}