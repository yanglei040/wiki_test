{"hands_on_practices": [{"introduction": "A core concept in the Blue Moon ensemble is that the geometry of the constraint manifold is defined by the mass metric, not by a simple Euclidean metric. This foundational exercise [@problem_id:3398634] provides a rigorous analytical proof of this principle using a solvable model system. By completing this derivation, you will understand why using the correct mass-weighted metric, $g_M$, is essential to avoid spurious, mass-dependent forces in free energy calculations.", "problem": "Consider two independent one-dimensional particles with Cartesian coordinates $x$ and $y$, masses $m_{x}$ and $m_{y}$, and the same harmonic tether to the origin with potential $U(x,y) = \\tfrac{1}{2} k \\left(x^{2} + y^{2}\\right)$. The system is sampled in the canonical ensemble at temperature $T$ (Boltzmann constant $k_{B}$). Define the reaction coordinate $\\xi(x,y) = \\arctan\\!\\left(\\tfrac{y}{x}\\right)$ taking values in $(0,\\pi)$ and measure angles in radians.\n\nYour tasks are as follows.\n\n1. Starting from the canonical configurational distribution and a change of variables to polar-like coordinates $(r,\\xi)$ with $r = \\sqrt{x^{2} + y^{2}}$, derive the exact potential of mean force $A(\\xi)$ along $\\xi$ and its derivative $\\tfrac{dA}{d\\xi}$ by integrating out $r$. Do not assume any result specific to this coordinate a priori; begin from first principles for the canonical ensemble and the Jacobian of the coordinate transformation.\n\n2. Next, imagine computing $\\tfrac{dA}{d\\xi}$ from a constrained Molecular Dynamics (MD) simulation in which $\\xi$ is held fixed at a given value. Use the Blue Moon ensemble logic: the constrained equilibrium measure on the hypersurface $\\xi=\\text{const}$ is induced by the kinetic energy metric (the mass metric) $M = \\mathrm{diag}(m_{x}, m_{y})$, and the corresponding geometric factor is $g_{M}(x,y) = \\nabla \\xi(x,y)^{\\top} M^{-1} \\nabla \\xi(x,y)$. Explain why the identity\n$$\n\\frac{dA}{d\\xi} \\;=\\; \\left\\langle \\Lambda_{\\xi} \\right\\rangle_{\\xi} \\;-\\; \\frac{k_{B} T}{2} \\,\\frac{d}{d\\xi} \\ln g_{M}\n$$\nholds, where $\\Lambda_{\\xi}$ is the Lagrange multiplier enforcing the holonomic constraint $\\xi=\\text{const}$ in the constrained MD and $\\langle \\cdot \\rangle_{\\xi}$ denotes the canonical average on the constrained manifold. You may use as a well-tested fact that constrained MD samples the Blue Moon ensemble with density proportional to $\\exp(-\\beta U)\\sqrt{g_{M}}$ on $\\xi=\\text{const}$, with $\\beta = 1/(k_{B} T)$.\n\n3. Compute explicitly the gradient $\\nabla \\xi(x,y)$, the correct mass-metric factor $g_{M}(x,y)$, and the Euclidean-metric factor $g_{E}(x,y) = \\nabla \\xi(x,y)^{\\top} \\nabla \\xi(x,y)$ in terms of $(r,\\xi)$. Show that, for this isotropic potential, the correct mass-metric formula yields $\\tfrac{dA}{d\\xi}=0$ by an exact cancellation between $\\left\\langle \\Lambda_{\\xi} \\right\\rangle_{\\xi}$ and $\\tfrac{k_{B} T}{2} \\tfrac{d}{d\\xi}\\ln g_{M}$, while replacing $g_{M}$ by $g_{E}$ in the correction term generically produces a nonzero result.\n\nProvide, as your final answer, the closed-form analytic expression for the resulting spurious derivative\n$$\n\\Delta(\\xi;m_{x},m_{y}) \\;=\\; \\left.\\frac{dA}{d\\xi}\\right|_{\\text{Euclidean correction}} \\;-\\; \\left.\\frac{dA}{d\\xi}\\right|_{\\text{exact}}\n$$\nas a function of $\\xi$, $m_{x}$, and $m_{y}$, in radians. Do not insert numerical values. Express your final answer as a single simplified analytic expression.", "solution": "We begin from the canonical configurational ensemble. The canonical probability density in Cartesian coordinates is\n$$\n\\pi(x,y) \\;=\\; \\frac{1}{Z} \\exp\\!\\left(-\\beta U(x,y)\\right) \\;=\\; \\frac{1}{Z} \\exp\\!\\left(-\\frac{\\beta k}{2}(x^{2}+y^{2})\\right),\n$$\nwhere $Z$ is the configurational partition function and $\\beta = 1/(k_{B} T)$. Introduce polar-like coordinates $(r,\\xi)$ with $r=\\sqrt{x^{2}+y^{2}}$ and $\\xi = \\arctan(y/x)$ on $(0,\\pi)$; the Jacobian of the transformation is $J = r$, so the area element transforms as $dx\\,dy = r\\,dr\\,d\\xi$. The marginal density of $\\xi$ is\n$$\np(\\xi) \\;\\propto\\; \\int_{0}^{\\infty} r \\exp\\!\\left(-\\frac{\\beta k}{2} r^{2}\\right) dr,\n$$\nwhich is independent of $\\xi$ because the integrand does not depend on $\\xi$. Therefore $p(\\xi)$ is constant (uniform) and the potential of mean force (PMF) $A(\\xi)$ satisfies\n$$\nA(\\xi) \\;=\\; -k_{B} T \\ln p(\\xi) \\;=\\; \\text{const},\n$$\nso\n$$\n\\frac{dA}{d\\xi} \\;=\\; 0.\n$$\n\nWe now turn to the constrained Molecular Dynamics (MD) and the Blue Moon ensemble. For a holonomic constraint $\\xi(x,y)=\\xi_{0}$, the constrained equilibrium density sampled by constrained MD is proportional to $\\exp(-\\beta U)\\sqrt{g_{M}}$ on the constraint manifold, where the Blue Moon factor $g_{M}$ is defined by\n$$\ng_{M}(x,y) \\;=\\; \\nabla \\xi(x,y)^{\\top} M^{-1} \\nabla \\xi(x,y),\n$$\nwith $M = \\mathrm{diag}(m_{x}, m_{y})$ the mass metric appearing in the kinetic energy $T = \\tfrac{1}{2} \\dot{\\mathbf{q}}^{\\top} M \\dot{\\mathbf{q}}$. A well-tested identity of the Blue Moon ensemble relates the derivative of the PMF to constrained averages as\n$$\n\\frac{dA}{d\\xi} \\;=\\; \\left\\langle \\Lambda_{\\xi} \\right\\rangle_{\\xi} \\;-\\; \\frac{k_{B} T}{2} \\frac{d}{d\\xi} \\ln g_{M}.\n$$\nThis follows by differentiating the constrained partition function $Z_{\\mathrm{constr}}(\\xi) = \\int \\exp(-\\beta U) \\sqrt{g_{M}} \\,\\delta(\\xi(\\mathbf{q})-\\xi)\\, d\\mathbf{q}$ with respect to $\\xi$ and identifying the Lagrange multiplier contribution $\\Lambda_{\\xi}$ from virtual work along the constrained manifold, together with the derivative of the geometric factor $\\sqrt{g_{M}}$.\n\nWe compute the gradient of $\\xi(x,y) = \\arctan(y/x)$. Using standard derivatives,\n$$\n\\frac{\\partial \\xi}{\\partial x} \\;=\\; -\\frac{y}{x^{2}+y^{2}} \\;=\\; -\\frac{y}{r^{2}}, \n\\qquad\n\\frac{\\partial \\xi}{\\partial y} \\;=\\; \\frac{x}{x^{2}+y^{2}} \\;=\\; \\frac{x}{r^{2}},\n$$\nso\n$$\n\\nabla \\xi(x,y) \\;=\\; \\begin{pmatrix} -y/r^{2} \\\\[4pt] x/r^{2} \\end{pmatrix}.\n$$\nThe Euclidean-metric factor is\n$$\ng_{E}(x,y) \\;=\\; \\nabla \\xi^{\\top} \\nabla \\xi \\;=\\; \\frac{y^{2}}{r^{4}} + \\frac{x^{2}}{r^{4}} \\;=\\; \\frac{x^{2}+y^{2}}{r^{4}} \\;=\\; \\frac{1}{r^{2}}.\n$$\nThe mass-metric factor is\n$$\ng_{M}(x,y) \\;=\\; \\nabla \\xi^{\\top} M^{-1} \\nabla \\xi \\;=\\; \n\\begin{pmatrix} -y/r^{2} & x/r^{2} \\end{pmatrix}\n\\begin{pmatrix} 1/m_{x} & 0 \\\\ 0 & 1/m_{y} \\end{pmatrix}\n\\begin{pmatrix} -y/r^{2} \\\\ x/r^{2} \\end{pmatrix}\n\\;=\\; \\frac{y^{2}}{m_{x} r^{4}} + \\frac{x^{2}}{m_{y} r^{4}}.\n$$\nExpressed in $(r,\\xi)$ via $x=r\\cos\\xi$, $y=r\\sin\\xi$, this becomes\n$$\ng_{M}(r,\\xi) \\;=\\; \\frac{r^{2}\\sin^{2}\\xi}{m_{x} r^{4}} + \\frac{r^{2}\\cos^{2}\\xi}{m_{y} r^{4}} \\;=\\; \\frac{1}{r^{2}} \\left( \\frac{\\sin^{2}\\xi}{m_{x}} + \\frac{\\cos^{2}\\xi}{m_{y}} \\right).\n$$\nIt follows that\n$$\n\\ln g_{M}(r,\\xi) \\;=\\; -2 \\ln r \\;+\\; \\ln\\!\\left( \\frac{\\sin^{2}\\xi}{m_{x}} + \\frac{\\cos^{2}\\xi}{m_{y}} \\right).\n$$\nHence the derivative with respect to $\\xi$ at fixed $\\xi$ (i.e., along the constrained manifold) is\n$$\n\\frac{d}{d\\xi} \\ln g_{M} \\;=\\; \\frac{ \\dfrac{d}{d\\xi} \\left( \\dfrac{\\sin^{2}\\xi}{m_{x}} + \\dfrac{\\cos^{2}\\xi}{m_{y}} \\right) }{ \\dfrac{\\sin^{2}\\xi}{m_{x}} + \\dfrac{\\cos^{2}\\xi}{m_{y}} }\n\\;=\\; \\frac{ 2 \\sin\\xi \\cos\\xi \\left( \\dfrac{1}{m_{x}} - \\dfrac{1}{m_{y}} \\right) }{ \\dfrac{\\sin^{2}\\xi}{m_{x}} + \\dfrac{\\cos^{2}\\xi}{m_{y}} }.\n$$\nBy contrast, the Euclidean factor $g_{E} = 1/r^{2}$ yields $\\dfrac{d}{d\\xi} \\ln g_{E} = 0$.\n\nFor the isotropic harmonic potential $U=\\tfrac{1}{2}k r^{2}$, rotational symmetry implies that the exact PMF derivative vanishes, $\\tfrac{dA}{d\\xi} = 0$, as shown in the first part. Therefore, in the correct Blue Moon expression,\n$$\n0 \\;=\\; \\left\\langle \\Lambda_{\\xi} \\right\\rangle_{\\xi} \\;-\\; \\frac{k_{B} T}{2} \\frac{d}{d\\xi} \\ln g_{M},\n$$\nso the constrained average of the Lagrange multiplier must be\n$$\n\\left\\langle \\Lambda_{\\xi} \\right\\rangle_{\\xi} \\;=\\; \\frac{k_{B} T}{2} \\frac{d}{d\\xi} \\ln g_{M}.\n$$\nIf, however, one mistakenly replaces the mass-metric correction by the Euclidean-metric correction, one would compute\n$$\n\\left.\\frac{dA}{d\\xi}\\right|_{\\text{Euclidean correction}}\n\\;=\\; \\left\\langle \\Lambda_{\\xi} \\right\\rangle_{\\xi} \\;-\\; \\frac{k_{B} T}{2} \\frac{d}{d\\xi} \\ln g_{E}\n\\;=\\; \\left\\langle \\Lambda_{\\xi} \\right\\rangle_{\\xi} \\;-\\; 0\n\\;=\\; \\frac{k_{B} T}{2} \\frac{d}{d\\xi} \\ln g_{M}.\n$$\nSince the exact derivative is zero, the spurious derivative relative to the exact result is therefore\n$$\n\\Delta(\\xi;m_{x},m_{y}) \\;=\\; \\left.\\frac{dA}{d\\xi}\\right|_{\\text{Euclidean correction}} \\;-\\; \\left.\\frac{dA}{d\\xi}\\right|_{\\text{exact}}\n\\;=\\; \\frac{k_{B} T}{2} \\frac{d}{d\\xi} \\ln g_{M}.\n$$\nSubstituting the expression for $\\dfrac{d}{d\\xi} \\ln g_{M}$ found above and simplifying, we obtain the closed-form expression\n$$\n\\Delta(\\xi;m_{x},m_{y}) \\;=\\; k_{B} T \\,\\frac{ \\sin\\xi \\cos\\xi \\left( \\dfrac{1}{m_{x}} - \\dfrac{1}{m_{y}} \\right) }{ \\dfrac{\\sin^{2}\\xi}{m_{x}} + \\dfrac{\\cos^{2}\\xi}{m_{y}} }.\n$$\nThis is nonzero whenever $m_{x} \\neq m_{y}$ and $\\xi \\notin \\{0,\\tfrac{\\pi}{2},\\pi\\}$, demonstrating that using the Euclidean metric in place of the mass metric yields an artificial, mass-heterogeneity-dependent bias in $\\dfrac{dA}{d\\xi}$, whereas the correct mass-metric treatment recovers the exact uniform PMF with $\\dfrac{dA}{d\\xi} = 0$.", "answer": "$$\\boxed{k_{B} T\\,\\frac{\\left(\\frac{1}{m_{x}}-\\frac{1}{m_{y}}\\right)\\sin\\xi\\,\\cos\\xi}{\\frac{\\sin^{2}\\xi}{m_{x}}+\\frac{\\cos^{2}\\xi}{m_{y}}}}$$", "id": "3398634"}, {"introduction": "Having established the importance of the mass-weighted metric, a practical question arises: how do we compute the resulting geometric correction term, $\\partial_\\xi \\ln \\sqrt{\\det G(\\xi)}$, in a simulation? This exercise [@problem_id:3398624] tasks you with implementing and comparing two different estimators for this term, one derived from Lagrange multiplier fluctuations and another using finite differences. This practice will build your coding skills for constrained simulations and provide valuable insight into the statistical properties and variances of different estimators.", "problem": "Consider a classical system with two Cartesian coordinates $q_1$ and $q_2$, a diagonal mass matrix $M = \\mathrm{diag}(m_1,m_2)$, and a harmonic potential energy $U(q_1,q_2) = \\frac{k}{2}(q_1^2 + q_2^2)$. Impose a single holonomic constraint on the configuration,\n$$\n\\xi(q_1,q_2) = q_1 + \\gamma q_1 q_2^2 = c,\n$$\nwhere $\\gamma$ is a real parameter controlling curvature, and $c$ is the fixed reaction coordinate value. This defines a one-dimensional constraint manifold in the $(q_1,q_2)$ plane. Let $a(q) = \\nabla \\xi(q)$ denote the gradient of the constraint, and $H_\\xi(q)$ the Hessian matrix of the constraint. Define the scalar metric $g(q)$ associated with the single constraint by\n$$\ng(q) = a(q)^\\top M^{-1} a(q),\n$$\nso that the Fixman determinant for one constraint is $\\det G(\\xi) = g(q)$.\n\nYou will design and implement an estimator of the derivative $\\partial_\\xi \\ln \\sqrt{\\det G(\\xi)} = \\partial_\\xi \\left(\\frac{1}{2}\\ln g\\right)$ based on fluctuations of the Lagrange multiplier in the acceleration-level constrained dynamics and the Hessian of the constraint, and compare its variance against a direct finite-difference approximation along the reaction coordinate $\\xi$. All quantities in this problem are dimensionless; the temperature $T$ uses units where the Boltzmann constant is one (i.e., $k_{\\mathrm{B}}=1$).\n\nFundamental base for derivation and design:\n- Newton's second law with holonomic constraints: for position $q$ and velocity $v$, the equations of motion with a Lagrange multiplier $\\lambda$ enforcing $\\xi(q)=c$ are\n$$\nM \\ddot{q} = -\\nabla U(q) - a(q)\\,\\lambda,\n$$\ntogether with the kinematic constraint $\\dot{\\xi}(q,v) = a(q)^\\top v = 0$ for constrained dynamics and the acceleration-level constraint\n$$\n\\ddot{\\xi}(q,v) = a(q)^\\top \\ddot{q} + v^\\top H_\\xi(q) v = 0.\n$$\n- In the canonical ensemble at temperature $T$ with the velocity constraint $a(q)^\\top v = 0$, the velocity distribution is a Gaussian restricted to the tangent space, and its covariance is\n$$\n\\langle v v^\\top \\rangle_q = T\\left[M^{-1} - \\frac{M^{-1} a(q) a(q)^\\top M^{-1}}{g(q)}\\right],\n$$\nwhere the average is conditional on the configuration $q$ on the constraint manifold.\n- The Lagrange multiplier at fixed $q$ and $v$ is obtained by solving the acceleration-level constraint for $\\lambda$:\n$$\n\\lambda(q,v) = \\frac{a(q)^\\top M^{-1} F(q) + v^\\top H_\\xi(q)\\, v}{g(q)},\n$$\nwhere $F(q) = -\\nabla U(q)$ is the physical force.\n\nEstimator design:\n- The estimator for $\\partial_\\xi \\ln \\sqrt{\\det G(\\xi)}$ at fixed configuration $q$ is constructed by averaging the velocity-dependent term of $\\lambda(q,v)$ over the constrained canonical velocity distribution and eliminating the deterministic force projection $a(q)^\\top M^{-1} F(q)/g(q)$. This yields a configuration-dependent estimator\n$$\n\\mathcal{E}_\\lambda(q) = \\frac{1}{T}\\left\\langle \\frac{v^\\top H_\\xi(q)\\, v}{g(q)}\\right\\rangle_q = \\frac{1}{g(q)}\\left[\\mathrm{Tr}\\left(H_\\xi(q)\\, M^{-1}\\right) - \\frac{a(q)^\\top M^{-1} H_\\xi(q) M^{-1} a(q)}{g(q)}\\right],\n$$\nwhich depends only on $q$ via $a(q)$, $H_\\xi(q)$, and $g(q)$.\n- A direct finite-difference estimator at fixed $q_2$ perturbs the reaction coordinate by a small increment $\\delta$ and evaluates\n$$\n\\mathcal{E}_{\\mathrm{FD}}(q_2) = \\frac{1}{2}\\,\\frac{\\ln g\\left(q_1^+(q_2),q_2\\right) - \\ln g\\left(q_1^-(q_2),q_2\\right)}{\\delta},\n$$\nwhere $q_1^\\pm(q_2) = \\frac{c \\pm \\delta}{1 + \\gamma q_2^2}$ are the configuration points on the neighboring constraint manifolds $\\xi = c \\pm \\delta$ with the same $q_2$.\n\nEnsemble along the constraint manifold:\n- The constrained canonical distribution of configurations $(q_1,q_2)$ at temperature $T$ and potential $U(q)$, conditioned on $\\xi(q)=c$, induces a one-dimensional distribution over $q_2$ via the coarea formula. Using $f(q_1,q_2) = q_1 + \\gamma q_1 q_2^2 - c$ and solving $q_1(q_2) = \\frac{c}{1 + \\gamma q_2^2}$, the induced unnormalized density over $q_2$ is\n$$\nw(q_2) = \\exp\\!\\left(-\\frac{U\\left(q_1(q_2),q_2\\right)}{T}\\right)\\,\\frac{1}{\\left|\\frac{\\partial f}{\\partial q_1}(q_1(q_2),q_2)\\right|} = \\exp\\!\\left(-\\frac{k}{2T}\\left(q_1(q_2)^2 + q_2^2\\right)\\right)\\,\\frac{1}{1+\\gamma q_2^2}.\n$$\n- Expectations of any configuration-dependent quantity $\\Phi(q_2)$ over the constrained ensemble are computed by weighted averages over a symmetric grid $q_2 \\in [-Q,Q]$ with uniform spacing $\\Delta q_2$, using normalized weights $p_i = w(q_{2,i})/\\sum_j w(q_{2,j})$:\n$$\n\\langle \\Phi \\rangle_{\\xi=c} \\approx \\sum_i p_i\\,\\Phi(q_{2,i}),\n$$\nand the corresponding ensemble variance\n$$\n\\mathrm{Var}_{\\xi=c}[\\Phi] \\approx \\sum_i p_i\\left(\\Phi(q_{2,i}) - \\sum_j p_j \\Phi(q_{2,j})\\right)^2.\n$$\n\nYour tasks:\n1. Implement the configuration-dependent estimator $\\mathcal{E}_\\lambda(q)$ derived above by computing $a(q)$, $H_\\xi(q)$, and $g(q)$ on the grid of $q_2$ values, with $q_1(q_2) = \\frac{c}{1 + \\gamma q_2^2}$.\n2. Implement the finite-difference estimator $\\mathcal{E}_{\\mathrm{FD}}(q_2)$ using $q_1^\\pm(q_2) = \\frac{c \\pm \\delta}{1 + \\gamma q_2^2}$.\n3. For each specified test case, compute the ensemble variances $\\mathrm{Var}_{\\xi=c}[\\mathcal{E}_\\lambda]$ and $\\mathrm{Var}_{\\xi=c}[\\mathcal{E}_{\\mathrm{FD}}]$ over the constrained distribution of $q_2$ described above.\n\nUse the following test suite of parameter sets:\n- Test 1 (happy path): $(m_1,m_2,k,T,c,\\gamma,\\delta,Q,N) = (1.0,\\,2.0,\\,1.0,\\,0.5,\\,0.8,\\,0.6,\\,0.01,\\,3.0,\\,2001)$.\n- Test 2 (near-linear constraint): $(m_1,m_2,k,T,c,\\gamma,\\delta,Q,N) = (1.0,\\,2.0,\\,1.0,\\,0.5,\\,0.8,\\,0.05,\\,0.01,\\,3.0,\\,2001)$.\n- Test 3 (strong curvature): $(m_1,m_2,k,T,c,\\gamma,\\delta,Q,N) = (1.0,\\,2.0,\\,1.0,\\,0.5,\\,0.8,\\,1.5,\\,0.01,\\,3.0,\\,2001)$.\n\nFinal output format:\nYour program should produce a single line of output containing the six ensemble variances, ordered as\n$$\n\\left[\\mathrm{Var}_{\\xi=c}[\\mathcal{E}_\\lambda]_{\\text{Test 1}},\\,\\mathrm{Var}_{\\xi=c}[\\mathcal{E}_{\\mathrm{FD}}]_{\\text{Test 1}},\\,\\mathrm{Var}_{\\xi=c}[\\mathcal{E}_\\lambda]_{\\text{Test 2}},\\,\\mathrm{Var}_{\\xi=c}[\\mathcal{E}_{\\mathrm{FD}}]_{\\text{Test 2}},\\,\\mathrm{Var}_{\\xi=c}[\\mathcal{E}_\\lambda]_{\\text{Test 3}},\\,\\mathrm{Var}_{\\xi=c}[\\mathcal{E}_{\\mathrm{FD}}]_{\\text{Test 3}}\\right],\n$$\nprinted as a comma-separated list enclosed in square brackets, in dimensionless units.", "solution": "### Step 1: Extract Givens\n\nThe problem provides the following data, definitions, and equations:\n- **System Coordinates**: Cartesian coordinates $q_1$, $q_2$.\n- **Mass Matrix**: Diagonal matrix $M = \\mathrm{diag}(m_1,m_2)$.\n- **Potential Energy**: Harmonic potential $U(q_1,q_2) = \\frac{k}{2}(q_1^2 + q_2^2)$.\n- **Holonomic Constraint**: $\\xi(q_1,q_2) = q_1 + \\gamma q_1 q_2^2 = c$, where $\\gamma$ is a real parameter and $c$ is a fixed value.\n- **Constraint Gradient**: $a(q) = \\nabla \\xi(q)$.\n- **Constraint Hessian**: $H_\\xi(q)$.\n- **Metric Scalar**: $g(q) = a(q)^\\top M^{-1} a(q)$. The Fixman determinant is $\\det G(\\xi) = g(q)$.\n- **Target Quantity**: The derivative $\\partial_\\xi \\ln \\sqrt{\\det G(\\xi)} = \\partial_\\xi \\left(\\frac{1}{2}\\ln g\\right)$.\n- **Equations of Motion**: $M \\ddot{q} = -\\nabla U(q) - a(q)\\,\\lambda$.\n- **Acceleration-Level Constraint**: $a(q)^\\top \\ddot{q} + v^\\top H_\\xi(q) v = 0$.\n- **Constrained Velocity Covariance**: $\\langle v v^\\top \\rangle_q = T\\left[M^{-1} - \\frac{M^{-1} a(q) a(q)^\\top M^{-1}}{g(q)}\\right]$ at temperature $T$ where $k_B=1$.\n- **Lagrange Multiplier**: $\\lambda(q,v) = \\frac{a(q)^\\top M^{-1} F(q) + v^\\top H_\\xi(q)\\, v}{g(q)}$, where $F(q) = -\\nabla U(q)$.\n- **Estimator $\\mathcal{E}_\\lambda(q)$**: $\\mathcal{E}_\\lambda(q) = \\frac{1}{T}\\left\\langle \\frac{v^\\top H_\\xi(q)\\, v}{g(q)}\\right\\rangle_q = \\frac{1}{g(q)}\\left[\\mathrm{Tr}\\left(H_\\xi(q)\\, M^{-1}\\right) - \\frac{a(q)^\\top M^{-1} H_\\xi(q) M^{-1} a(q)}{g(q)}\\right]$.\n- **Estimator $\\mathcal{E}_{\\mathrm{FD}}(q_2)$**: $\\mathcal{E}_{\\mathrm{FD}}(q_2) = \\frac{1}{2}\\,\\frac{\\ln g\\left(q_1^+(q_2),q_2\\right) - \\ln g\\left(q_1^-(q_2),q_2\\right)}{\\delta}$, with $q_1^\\pm(q_2) = \\frac{c \\pm \\delta}{1 + \\gamma q_2^2}$.\n- **Induced Unnormalized Density on $q_2$**: $w(q_2) = \\exp\\!\\left(-\\frac{U\\left(q_1(q_2),q_2\\right)}{T}\\right)\\,\\frac{1}{1+\\gamma q_2^2}$, where $q_1(q_2) = \\frac{c}{1+\\gamma q_2^2}$.\n- **Ensemble Average and Variance**: Computed as a weighted sum over a grid of $q_2$ values using normalized weights $p_i = w(q_{2,i})/\\sum_j w(q_{2,j})$.\n- **Test Cases**: Three sets of parameters $(m_1,m_2,k,T,c,\\gamma,\\delta,Q,N)$:\n  1. $(1.0,\\,2.0,\\,1.0,\\,0.5,\\,0.8,\\,0.6,\\,0.01,\\,3.0,\\,2001)$\n  2. $(1.0,\\,2.0,\\,1.0,\\,0.5,\\,0.8,\\,0.05,\\,0.01,\\,3.0,\\,2001)$\n  3. $(1.0,\\,2.0,\\,1.0,\\,0.5,\\,0.8,\\,1.5,\\,0.01,\\,3.0,\\,2001)$\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem is subjected to rigorous validation.\n\n- **Scientific Grounding**: The problem is firmly rooted in the principles of classical statistical mechanics and Lagrangian mechanics with holonomic constraints. The concepts, such as the Lagrange multiplier, Fixman potential (via the metric determinant $g(q)$), and constrained canonical ensembles, are standard in advanced molecular dynamics simulations. All provided equations are consistent with established theory.\n- **Well-Posedness**: The problem is well-posed. It provides all necessary equations, parameters, and a clear computational objective. The tasks are specified without ambiguity, leading to a unique numerical result for each test case.\n- **Objectivity**: The problem is stated in precise, objective, and mathematical language. It is free of any subjectivity or opinion.\n\nThe problem does not exhibit any of the invalidity flags. The theoretical basis is sound, the problem is self-contained with no missing information or contradictions, and the tasks are computationally feasible and specific. The provided formula for the finite-difference estimator, while not a standard central-difference formula, is an explicit definition to be used in the implementation and does not render the problem invalid.\n\n### Step 3: Verdict and Action\n\nThe problem is **valid**. A complete, reasoned solution will be provided.\n\n### Solution\n\nThe objective is to compute and compare the ensemble variances of two estimators, $\\mathcal{E}_\\lambda$ and $\\mathcal{E}_{\\mathrm{FD}}$, for the geometric correction term $\\partial_\\xi \\ln \\sqrt{\\det G(\\xi)}$ that arises in constrained molecular dynamics. The calculation is performed on a one-dimensional manifold defined by the constraint $\\xi(q_1, q_2) = c$.\n\nFirst, we derive the necessary analytical expressions for the quantities defined in the problem. The coordinate $q_1$ is parameterized by $q_2$ via the constraint equation:\n$$\nq_1(q_2) = \\frac{c}{1 + \\gamma q_2^2}\n$$\n\nThe gradient of the constraint function $\\xi(q_1, q_2) = q_1(1 + \\gamma q_2^2) - c = 0$ is\n$$\na(q) = \\nabla \\xi(q) = \\begin{pmatrix} \\partial\\xi/\\partial q_1 \\\\ \\partial\\xi/\\partial q_2 \\end{pmatrix} = \\begin{pmatrix} 1 + \\gamma q_2^2 \\\\ 2 \\gamma q_1 q_2 \\end{pmatrix}\n$$\n\nThe Hessian matrix of the constraint function is\n$$\nH_\\xi(q) = \\begin{pmatrix} \\partial^2\\xi/\\partial q_1^2 & \\partial^2\\xi/\\partial q_1 \\partial q_2 \\\\ \\partial^2\\xi/\\partial q_2 \\partial q_1 & \\partial^2\\xi/\\partial q_2^2 \\end{pmatrix} = \\begin{pmatrix} 0 & 2 \\gamma q_2 \\\\ 2 \\gamma q_2 & 2 \\gamma q_1 \\end{pmatrix}\n$$\n\nThe inverse of the mass matrix $M = \\mathrm{diag}(m_1, m_2)$ is $M^{-1} = \\mathrm{diag}(1/m_1, 1/m_2)$.\n\nThe metric scalar $g(q)$ is computed as:\n$$\ng(q) = a(q)^\\top M^{-1} a(q) = \\frac{(1 + \\gamma q_2^2)^2}{m_1} + \\frac{(2 \\gamma q_1 q_2)^2}{m_2}\n$$\nThis function is required for both estimators.\n\nThe numerical procedure is as follows:\n1.  A uniform grid of $N$ points is generated for the coordinate $q_2$ in the symmetric interval $[-Q, Q]$.\n2.  For each point $q_{2,i}$ on this grid, the corresponding $q_{1,i}$ is calculated, defining a set of configurations $\\{q_i = (q_{1,i}, q_{2,i})\\}$ that lie on the constraint manifold $\\xi=c$.\n\n3.  At each configuration $q_i$, the estimator $\\mathcal{E}_\\lambda(q_i)$ is computed. Its formula is:\n    $$\n    \\mathcal{E}_\\lambda(q) = \\frac{1}{g(q)}\\left[\\mathrm{Tr}\\left(H_\\xi(q)\\, M^{-1}\\right) - \\frac{a(q)^\\top M^{-1} H_\\xi(q) M^{-1} a(q)}{g(q)}\\right]\n    $$\n    The implementation will compute the matrix and vector quantities $a(q_i)$, $H_\\xi(q_i)$, $M^{-1}$, and $g(q_i)$ and perform the specified matrix-vector operations. This approach is more robust than a direct symbolic expansion.\n\n4.  Similarly, at each point $q_{2,i}$, the finite-difference estimator $\\mathcal{E}_{\\mathrm{FD}}(q_{2,i})$ is computed. This requires evaluating the metric $g(q)$ at two neighboring points, $(q_1^+(q_{2,i}), q_{2,i})$ and $(q_1^-(q_{2,i}), q_{2,i})$, which lie on adjacent constraint manifolds $\\xi = c \\pm \\delta$.\n    $$\n    \\mathcal{E}_{\\mathrm{FD}}(q_2) = \\frac{1}{2\\delta}\\left[\\ln g\\left(\\frac{c + \\delta}{1 + \\gamma q_2^2}, q_2\\right) - \\ln g\\left(\\frac{c - \\delta}{1 + \\gamma q_2^2}, q_2\\right)\\right]\n    $$\n\n5.  The canonical ensemble average over the constraint manifold is calculated as a weighted sum over the $q_2$ grid. The unnormalized weights $w(q_{2,i})$ are given by the coarea formula:\n    $$\n    w(q_{2,i}) = \\exp\\left(-\\frac{U(q_{1,i}, q_{2,i})}{T}\\right) \\frac{1}{1 + \\gamma q_{2,i}^2}\n    $$\n    where $U(q_{1,i}, q_{2,i}) = \\frac{k}{2}(q_{1,i}^2 + q_{2,i}^2)$. These weights are then normalized to obtain probabilities $p_i = w_i / \\sum_j w_j$.\n\n6.  Finally, for each estimator $\\Phi \\in \\{\\mathcal{E}_\\lambda, \\mathcal{E}_{\\mathrm{FD}}\\}$, the ensemble average $\\langle \\Phi \\rangle = \\sum_i p_i \\Phi_i$ and the ensemble variance $\\mathrm{Var}[\\Phi] = \\sum_i p_i (\\Phi_i - \\langle \\Phi \\rangle)^2$ are computed.\n\nThis process is repeated for each of the three test cases provided, which vary the constraint curvature parameter $\\gamma$ to examine its effect on the fluctuations of the estimators. The implementation will be fully vectorized using `numpy` for efficiency.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It computes the ensemble variances for two different estimators of a\n    geometric correction term in constrained molecular dynamics.\n    \"\"\"\n\n    # Test cases as tuples of (m1, m2, k, T, c, gamma, delta, Q, N)\n    test_cases = [\n        (1.0, 2.0, 1.0, 0.5, 0.8, 0.6, 0.01, 3.0, 2001),\n        (1.0, 2.0, 1.0, 0.5, 0.8, 0.05, 0.01, 3.0, 2001),\n        (1.0, 2.0, 1.0, 0.5, 0.8, 1.5, 0.01, 3.0, 2001)\n    ]\n\n    def compute_variances(params):\n        \"\"\"\n        Computes the ensemble variances for both estimators for a single\n        set of parameters.\n        \"\"\"\n        m1, m2, k, T, c, gamma, delta, Q, N = params\n        \n        # 1. Create a uniform grid for the q2 coordinate.\n        q2_grid = np.linspace(-Q, Q, N)\n\n        # 2. Compute the corresponding q1 coordinate on the constraint manifold.\n        q1_denom = 1 + gamma * q2_grid**2\n        q1_grid = c / q1_denom\n\n        # Helper function to compute the metric scalar g(q)\n        def compute_g(q1_vals, q2_vals):\n            a1_vals = 1 + gamma * q2_vals**2\n            a2_vals = 2 * gamma * q1_vals * q2_vals\n            return a1_vals**2 / m1 + a2_vals**2 / m2\n\n        # 3. Compute the Lagrange multiplier-based estimator E_lambda.\n        # This is done using vectorized numpy operations for efficiency.\n        \n        # Components of the constraint gradient vector a(q)\n        a1 = 1 + gamma * q2_grid**2\n        a2 = 2 * gamma * q1_grid * q2_grid\n        \n        # The metric scalar g(q) on the grid\n        g_grid = a1**2 / m1 + a2**2 / m2\n\n        # Term 1 of E_lambda: Tr(H * M^-1)\n        # H_22 = 2 * gamma * q1\n        # Tr(H * M^-1) = H_11/m1 + H_22/m2 = 0 + (2*gamma*q1)/m2\n        term1_tr = 2 * gamma * q1_grid / m2\n        \n        # Term 2 of E_lambda numerator: a^T * M^-1 * H * M^-1 * a\n        # This is expanded and vectorized to avoid loops.\n        M_inv_a1 = a1 / m1\n        M_inv_a2 = a2 / m2\n        H_M_inv_a_1 = (2 * gamma * q2_grid) * M_inv_a2\n        H_M_inv_a_2 = (2 * gamma * q2_grid) * M_inv_a1 + (2 * gamma * q1_grid) * M_inv_a2\n        term2_num = M_inv_a1 * H_M_inv_a_1 + M_inv_a2 * H_M_inv_a_2\n\n        E_lambda_values = (1 / g_grid) * (term1_tr - term2_num / g_grid)\n\n        # 4. Compute the finite-difference estimator E_FD.\n        q1_plus = (c + delta) / q1_denom\n        q1_minus = (c - delta) / q1_denom\n        \n        g_plus = compute_g(q1_plus, q2_grid)\n        g_minus = compute_g(q1_minus, q2_grid)\n\n        E_fd_values = (0.5 / delta) * (np.log(g_plus) - np.log(g_minus))\n\n        # 5. Compute the canonical weights for the ensemble average.\n        potential_U = 0.5 * k * (q1_grid**2 + q2_grid**2)\n        weights_unnormalized = np.exp(-potential_U / T) / (1 + gamma * q2_grid**2.0)\n        \n        # Normalize weights to get probabilities p_i\n        p_weights = weights_unnormalized / np.sum(weights_unnormalized)\n\n        # 6. Compute the ensemble variances.\n        avg_E_lambda = np.sum(p_weights * E_lambda_values)\n        var_E_lambda = np.sum(p_weights * (E_lambda_values - avg_E_lambda)**2)\n\n        avg_E_fd = np.sum(p_weights * E_fd_values)\n        var_E_fd = np.sum(p_weights * (E_fd_values - avg_E_fd)**2)\n\n        return var_E_lambda, var_E_fd\n\n    results = []\n    for case in test_cases:\n        var_lam, var_fd = compute_variances(case)\n        results.append(var_lam)\n        results.append(var_fd)\n\n    # Print the final results in the specified format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3398624"}, {"introduction": "Beyond correct implementation, the efficiency of free energy calculations is paramount, as converging the mean force $\\langle \\Lambda_\\xi \\rangle_\\xi$ can be computationally demanding. This advanced practice [@problem_id:3398631] introduces a powerful variance reduction method based on control variates constructed from the generator of the system's dynamics. By analyzing an exactly solvable overdamped model, you will see how this technique can dramatically reduce the statistical error in the computed mean force, a crucial skill for tackling complex molecular simulations.", "problem": "You will design and analyze a variance-reduced estimator for the derivative of the constrained free energy in a simple, but nontrivial, molecular dynamics setting using the Blue Moon ensemble. The goal is to derive an estimator for the derivative of the free energy with respect to a reaction coordinate, construct control variates using local quadratic models, and quantify the asymptotic variance in terms of the spectral properties of the constrained dynamics generator. Then, implement a program to compute the resulting quantities for a specified test suite.\n\nConsider a two-dimensional configuration vector $q = (x,y) \\in \\mathbb{R}^2$ with a separable holonomic constraint defined by the reaction coordinate $\\xi(q) = x$. The constraint is imposed as $x = \\xi_0$, thereby restricting the dynamics to the one-dimensional manifold $M_{\\xi_0} = \\{(x,y) \\in \\mathbb{R}^2 : x = \\xi_0\\}$. The physical system is described by a potential energy function $V(q)$ that is twice differentiable and admits a local quadratic expansion. You will study the constrained free energy $A(\\xi)$ defined by the equilibrium marginal over $\\xi$ and its derivative $dA/d\\xi$ evaluated at $x = \\xi_0$.\n\nUse the following legitimate modeling framework:\n\n- Dynamics are overdamped and occur at constant temperature with Boltzmann constant $k_B$ and absolute temperature $T$, with friction coefficient $\\gamma > 0$.\n- The configuration is constrained to the manifold $M_{\\xi_0}$ where $x = \\xi_0$, and the dynamics evolve along the $y$ direction only.\n- The potential energy is specified as a quadratic model\n  $$V(x,y) = \\frac{1}{2} k_x x^2 + \\frac{1}{2} k_y y^2 + k_{xy} x y,$$\n  where $k_x > 0$, $k_y > 0$, and $k_{xy}$ is any real scalar coupling.\n\nStart from the following foundational bases, without using any pre-derived formulas for the target quantity or the variance:\n\n1. Newtonian mechanics in the overdamped limit, leading to the overdamped Langevin equation along the constrained manifold, with drift proportional to the negative gradient of the potential along the manifold and diffusion consistent with the fluctuation-dissipation theorem.\n2. The statistical mechanics definition of constrained free energy $A(\\xi)$ from the Boltzmann distribution marginalized at fixed $\\xi$.\n3. The definition of the infinitesimal generator of the constrained dynamics and its spectral properties, including the interpretation of stationarity and autocorrelation decay for linear systems.\n\nTasks:\n\n1. Derive an expression for the derivative of the constrained free energy $dA/d\\xi$ at $x = \\xi_0$ in this setting, expressed as an expectation with respect to the stationary constrained distribution on $M_{\\xi_0}$.\n2. Derive the constrained overdamped Langevin dynamics generator along $M_{\\xi_0}$ and identify its spectrum for the local quadratic potential model.\n3. Construct a variance-reduced estimator for $dA/d\\xi$ using a control variate obtained from applying the generator to a function $\\psi(y)$ selected from the family of local quadratic functions aligned with the local quadratic model of $V(q)$ and a quadratic model of the coarse-grained free energy $U_F(\\xi)$ near $\\xi_0$. Ensure the control variate has zero expectation under the stationary constrained distribution and determine the choice of coefficients that minimize the asymptotic variance.\n4. Express the asymptotic variance of the time-average estimator and the variance-reduced estimator in terms of the spectrum of the generator. Provide a closed-form quantification in this quadratic setting.\n\nImplementation requirements:\n\n- Use reduced units where $k_B T = 1$ and all physical quantities are expressed in these reduced units. Therefore, report all numerical outputs as unitless quantities.\n- For a given parameter set $(k_x,k_y,k_{xy},\\gamma,\\xi_0)$, compute and return:\n  - The exact value of $dA/d\\xi$ at $x = \\xi_0$.\n  - The asymptotic variance of the naive time-average estimator for $dA/d\\xi$ under the constrained dynamics.\n  - The asymptotic variance of the optimally variance-reduced estimator using the generator-based control variate with coefficients determined from the local quadratic model parameters.\n  - The asymptotic variance of a mis-specified variance-reduced estimator where the control variate uses perturbed local quadratic parameters $(\\widehat{k}_y,\\widehat{k}_{xy})$ (provided in the test suite).\n\nYour program must implement these computations deterministically without any simulation, using the derived analytical relationships, and produce the outputs for the following test suite of parameter values:\n\n- Test Case 1 (general case):\n  - $k_x = 2.0$, $k_y = 4.0$, $k_{xy} = 1.5$, $\\gamma = 1.0$, $\\xi_0 = 0.3$, $k_B T = 1.0$\n  - Mis-specification factors: $\\widehat{k}_y = 0.9\\,k_y$, $\\widehat{k}_{xy} = 1.1\\,k_{xy}$\n- Test Case 2 (decoupled boundary, zero coupling):\n  - $k_x = 3.5$, $k_y = 2.0$, $k_{xy} = 0.0$, $\\gamma = 1.25$, $\\xi_0 = -0.2$, $k_B T = 1.0$\n  - Mis-specification factors: $\\widehat{k}_y = 1.2\\,k_y$, $\\widehat{k}_{xy} = 0.8\\,k_{xy}$\n- Test Case 3 (stiff transverse mode):\n  - $k_x = 1.0$, $k_y = 100.0$, $k_{xy} = 2.0$, $\\gamma = 0.5$, $\\xi_0 = 0.1$, $k_B T = 1.0$\n  - Mis-specification factors: $\\widehat{k}_y = 1.1\\,k_y$, $\\widehat{k}_{xy} = 0.95\\,k_{xy}$\n- Test Case 4 (negative coupling and larger friction):\n  - $k_x = 0.7$, $k_y = 3.0$, $k_{xy} = -1.0$, $\\gamma = 2.0$, $\\xi_0 = -0.4$, $k_B T = 1.0$\n  - Mis-specification factors: $\\widehat{k}_y = 0.85\\,k_y$, $\\widehat{k}_{xy} = 1.05\\,k_{xy}$\n\nFor each test case, your program should output the four computed quantities in the order listed above. Your program should produce a single line of output containing all results from the four test cases, concatenated, as a comma-separated list enclosed in square brackets. For example, the final output format must be:\n\"[mu1,naive_var1,cv_opt_var1,cv_mis_var1,mu2,naive_var2,cv_opt_var2,cv_mis_var2,mu3,naive_var3,cv_opt_var3,cv_mis_var3,mu4,naive_var4,cv_opt_var4,cv_mis_var4]\".", "solution": "The problem is to derive and implement estimators for the derivative of a constrained free energy, $dA/d\\xi$, for a particle in a two-dimensional quadratic potential, $V(x,y)$, subject to a holonomic constraint, $x=\\xi_0$. The analysis is rooted in the Blue Moon ensemble framework and overdamped Langevin dynamics. We will use a generator-based control variate to reduce the variance of the estimator. We operate in reduced units where $k_B T = 1$.\n\nThe potential energy is given by:\n$$V(x,y) = \\frac{1}{2} k_x x^2 + \\frac{1}{2} k_y y^2 + k_{xy} x y$$\nThe reaction coordinate is $\\xi(q) = x$, and the system is constrained to the manifold $M_{\\xi_0}$ where $x = \\xi_0$.\n\n**1. Derivative of the Constrained Free Energy**\n\nThe constrained free energy $A(\\xi)$ is defined through the partition function on the constrained manifold, $Z(\\xi) = \\int e^{-\\beta V(\\xi, y)} dy$.\n$$A(\\xi) = -k_B T \\ln Z(\\xi) = -\\frac{1}{\\beta} \\ln \\int e^{-\\beta V(\\xi, y)} dy$$\nUsing $\\beta = 1/(k_B T) = 1$, the derivative with respect to $\\xi$ is found using the chain rule:\n$$\\frac{dA}{d\\xi} = -\\frac{d}{d\\xi} \\ln \\int e^{-V(\\xi, y)} dy = -\\frac{1}{Z(\\xi)} \\int \\left(-\\frac{\\partial V}{\\partial\\xi}\\right) e^{-V(\\xi, y)} dy$$\nThis simplifies to the ensemble average of the generalized force conjugate to $\\xi$:\n$$\\frac{dA}{d\\xi} = \\frac{\\int \\frac{\\partial V(\\xi, y)}{\\partial \\xi} e^{-V(\\xi, y)} dy}{\\int e^{-V(\\xi, y)} dy} = \\left\\langle \\frac{\\partial V}{\\partial \\xi} \\right\\rangle_\\xi$$\nwhere $\\langle \\cdot \\rangle_\\xi$ denotes the expectation with respect to the stationary (Boltzmann) distribution on the manifold $M_\\xi$.\nFor our system, $\\xi = x$, so $\\partial V/\\partial\\xi = \\partial V/\\partial x = k_x x + k_{xy} y$.\nOn the manifold $M_{\\xi_0}$, where $x=\\xi_0$, the expression for the free energy derivative is:\n$$\\mu \\equiv \\frac{dA}{d\\xi}\\bigg|_{\\xi_0} = \\langle k_x \\xi_0 + k_{xy} y \\rangle_{\\xi_0} = k_x \\xi_0 + k_{xy} \\langle y \\rangle_{\\xi_0}$$\nThe quantity to be estimated from a molecular dynamics simulation is the observable $f(y) = k_x \\xi_0 + k_{xy} y$.\n\nTo find the exact value of $\\mu$, we must compute $\\langle y \\rangle_{\\xi_0}$. The stationary probability distribution of $y$ on $M_{\\xi_0}$ is $p(y|\\xi_0) \\propto e^{-V(\\xi_0, y)}$. The potential restricted to the manifold is:\n$$V(\\xi_0, y) = \\frac{1}{2} k_y y^2 + k_{xy} \\xi_0 y + \\frac{1}{2} k_x \\xi_0^2$$\nThis is a quadratic in $y$, meaning $p(y|\\xi_0)$ is a Gaussian distribution. The mean $\\langle y \\rangle_{\\xi_0}$ corresponds to the minimum of $V(\\xi_0, y)$, which is found by setting $\\partial V(\\xi_0, y) / \\partial y = 0$.\n$$\\frac{\\partial V}{\\partial y} = k_y y + k_{xy} \\xi_0 = 0 \\implies \\langle y \\rangle_{\\xi_0} = -\\frac{k_{xy} \\xi_0}{k_y}$$\nSubstituting this into the expression for $\\mu$:\n$$\\mu = k_x \\xi_0 + k_{xy} \\left(-\\frac{k_{xy} \\xi_0}{k_y}\\right) = \\left(k_x - \\frac{k_{xy}^2}{k_y}\\right) \\xi_0$$\nThis is the exact analytical value for the free energy derivative at $\\xi_0$.\n\n**2. Constrained Dynamics and Generator**\n\nThe dynamics on $M_{\\xi_0}$ evolve only in the $y$ coordinate. The overdamped Langevin equation is:\n$$\\gamma \\dot{y} = F_y + \\sqrt{2\\gamma k_B T} R(t) = -\\frac{\\partial V(\\xi_0, y)}{\\partial y} + \\sqrt{2\\gamma} R(t)$$\n$$\\gamma \\dot{y} = -(k_y y + k_{xy} \\xi_0) + \\sqrt{2\\gamma} R(t)$$\nThis describes an Ornstein-Uhlenbeck process. The corresponding Fokker-Planck generator, $\\mathcal{L}$, acting on a test function $\\phi(y)$, is:\n$$\\mathcal{L}\\phi(y) = \\left[-\\frac{1}{\\gamma}(k_y y + k_{xy} \\xi_0)\\right] \\frac{d\\phi}{dy} + \\frac{1}{\\gamma} \\frac{d^2\\phi}{dy^2}$$\nThe dynamics of the centered coordinate $y_c = y - \\langle y \\rangle_{\\xi_0}$ are simpler: $\\gamma \\dot{y}_c = -k_y y_c + \\sqrt{2\\gamma} R(t)$. This process has a single relaxation rate, $\\lambda_1 = k_y/\\gamma$, which is the first non-zero eigenvalue of $-\\mathcal{L}$. The spectrum of $\\mathcal{L}$ is given by $\\{-n\\lambda_1\\}_{n=0}^\\infty = \\{-n \\frac{k_y}{\\gamma}\\}_{n=0}^\\infty$.\n\n**3. Asymptotic Variance of Estimators**\n\nThe asymptotic variance of a time-average estimator for an observable $A$ is given by the integral of its auto-correlation function: $\\sigma^2_{\\bar{A}} = 2 \\int_0^\\infty C_{AA}(\\tau) d\\tau$.\n\n**Naive Estimator:**\nThe observable is $f(y) = k_x \\xi_0 + k_{xy} y$. Its fluctuating part is $f(y) - \\mu = k_{xy}(y - \\langle y \\rangle_{\\xi_0}) = k_{xy} y_c$.\nThe auto-correlation function of $y_c$ for an Ornstein-Uhlenbeck process is $C_{y_c y_c}(\\tau) = \\langle y_c^2 \\rangle_{\\xi_0} e^{-\\lambda_1 |\\tau|}$. The variance of $y$ in the constrained ensemble is $\\langle y_c^2 \\rangle_{\\xi_0} = 1/k_y$.\n$$C_{ff}(\\tau) = \\langle (k_{xy} y_c(\\tau))(k_{xy} y_c(0)) \\rangle = k_{xy}^2 C_{y_c y_c}(\\tau) = \\frac{k_{xy}^2}{k_y} e^{-(k_y/\\gamma)|\\tau|}$$\nThe asymptotic variance of the naive estimator is:\n$$\\sigma^2_{\\text{naive}} = 2 \\int_0^\\infty \\frac{k_{xy}^2}{k_y} e^{-(k_y/\\gamma)\\tau} d\\tau = 2 \\frac{k_{xy}^2}{k_y} \\left(\\frac{\\gamma}{k_y}\\right) = \\frac{2\\gamma k_{xy}^2}{k_y^2}$$\n\n**Variance-Reduced Estimator:**\nA control variate $g(y)$ with $\\langle g(y) \\rangle=0$ can be constructed as $g = \\mathcal{L}\\psi$ for some function $\\psi(y)$. The variance-reduced observable is $f^* = f + g = f + \\mathcal{L}\\psi$. The goal is to choose $\\psi$ to make the variance of $f^*$ minimal, which is achieved by making $f+\\mathcal{L}\\psi$ as constant as possible. This leads to the Poisson equation for $\\psi$: $\\mathcal{L}\\psi \\approx -(f - \\mu)$.\n\nFor our problem, $f - \\mu = k_{xy} y_c$. We look for a solution $\\psi(y) = c y$.\n$$\\mathcal{L}(cy) = c \\mathcal{L}y = c \\left( -\\frac{1}{\\gamma}(k_y y + k_{xy}\\xi_0) \\cdot 1 + 0 \\right) = -\\frac{c k_y}{\\gamma} (y + \\frac{k_{xy}\\xi_0}{k_y}) = -\\frac{c k_y}{\\gamma} y_c$$\nTo solve $\\mathcal{L}(cy) = -k_{xy} y_c$, we set $-\\frac{c k_y}{\\gamma} y_c = -k_{xy} y_c$, which gives $c = \\frac{k_{xy}\\gamma}{k_y}$.\nThus, the optimal choice is $\\psi_{opt}(y) = \\frac{k_{xy}\\gamma}{k_y} y$.\nWith this $\\psi_{opt}$, the control variate is $g_{opt} = \\mathcal{L}\\psi_{opt} = -k_{xy} y_c = -(f-\\mu)$.\nThe new observable's fluctuating part is $(f-\\mu) + g_{opt} = (f-\\mu) - (f-\\mu) = 0$.\nThe variance of this new observable is zero. Consequently, the asymptotic variance is also zero. This perfect cancellation is a special feature of the quadratic potential and linear observable.\n$$\\sigma^2_{\\text{cv\\_opt}} = 0$$\n\n**Mis-specified Estimator:**\nThe control variate is now constructed based on a mis-specified model with parameters $\\widehat{k}_y$ and $\\widehat{k}_{xy}$. We construct a function $\\widehat{\\psi}$ that would be optimal for this 'hat' model, and then apply the true generator $\\mathcal{L}$ to it.\nBy analogy with the optimal case, $\\widehat{\\psi}(y) = \\frac{\\widehat{k}_{xy}\\gamma}{\\widehat{k}_y} y$.\nThe control variate is $g_{mis} = \\mathcal{L}\\widehat{\\psi} = \\mathcal{L}\\left(\\frac{\\widehat{k}_{xy}\\gamma}{\\widehat{k}_y} y\\right) = \\frac{\\widehat{k}_{xy}\\gamma}{\\widehat{k}_y} \\mathcal{L}y$.\nUsing $\\mathcal{L}y = -(k_y/\\gamma)y_c$, we get:\n$$g_{mis} = \\frac{\\widehat{k}_{xy}\\gamma}{\\widehat{k}_y} \\left(-\\frac{k_y}{\\gamma} y_c\\right) = -\\frac{\\widehat{k}_{xy} k_y}{\\widehat{k}_y} y_c$$\nThe residual fluctuation for the estimator $f_{mis}^* = f + g_{mis}$ is:\n$$R(y) = (f-\\mu) + g_{mis} = k_{xy} y_c - \\frac{\\widehat{k}_{xy} k_y}{\\widehat{k}_y} y_c = \\left( k_{xy} - \\frac{k_y \\widehat{k}_{xy}}{\\widehat{k}_y} \\right) y_c$$\nThe auto-correlation of this residual is $C_{RR}(\\tau) = \\langle R(y(t))R(y(0)) \\rangle = \\left( k_{xy} - \\frac{k_y \\widehat{k}_{xy}}{\\widehat{k}_y} \\right)^2 C_{y_c y_c}(\\tau)$.\nThe asymptotic variance is:\n$$\\sigma^2_{\\text{cv\\_mis}} = 2 \\int_0^\\infty C_{RR}(\\tau) d\\tau = \\left( k_{xy} - \\frac{k_y \\widehat{k}_{xy}}{\\widehat{k}_y} \\right)^2 \\left( 2\\int_0^\\infty C_{y_c y_c}(\\tau) d\\tau \\right)$$\nThe integral term is the asymptotic variance of $y_c$, which is $2 \\text{Var}(y_c) / \\lambda_1 = 2 (1/k_y) / (k_y/\\gamma) = 2\\gamma/k_y^2$.\nTherefore,\n$$\\sigma^2_{\\text{cv\\_mis}} = \\frac{2\\gamma}{k_y^2} \\left( k_{xy} - k_y \\frac{\\widehat{k}_{xy}}{\\widehat{k}_y} \\right)^2$$\nThis formula correctly recovers $\\sigma^2_{\\text{cv\\_mis}}=0$ when $\\widehat{k}_y=k_y$ and $\\widehat{k}_{xy}=k_{xy}$.\n\nWe now have all the necessary analytical expressions to compute the required quantities for the test suite.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# No other libraries are needed.\n\ndef solve():\n    \"\"\"\n    Computes analytical results for a Blue Moon ensemble problem.\n\n    For a 2D system with a quadratic potential and a linear constraint, this\n    function calculates:\n    1. The exact derivative of the constrained free energy (dA/dxi).\n    2. The asymptotic variance of the naive estimator for dA/dxi.\n    3. The asymptotic variance of the optimally-reduced control variate estimator.\n    4. The asymptotic variance of a mis-specified control variate estimator.\n\n    The calculations are based on derived analytical formulas, not simulations.\n    \"\"\"\n    # Test cases defined in the problem statement.\n    # Each tuple is: (k_x, k_y, k_xy, gamma, xi_0, k_y_hat_factor, k_xy_hat_factor)\n    test_cases = [\n        (2.0, 4.0, 1.5, 1.0, 0.3, 0.9, 1.1),\n        (3.5, 2.0, 0.0, 1.25, -0.2, 1.2, 0.8),\n        (1.0, 100.0, 2.0, 0.5, 0.1, 1.1, 0.95),\n        (0.7, 3.0, -1.0, 2.0, -0.4, 0.85, 1.05)\n    ]\n\n    results = []\n\n    for case in test_cases:\n        k_x, k_y, k_xy, gamma, xi_0, ky_hat_factor, kxy_hat_factor = case\n\n        # 1. Exact value of dA/dxi at xi_0\n        # Formula: mu = (k_x - k_xy^2 / k_y) * xi_0\n        mu = (k_x - k_xy**2 / k_y) * xi_0\n\n        # 2. Asymptotic variance of the naive time-average estimator\n        # Formula: sigma^2_naive = 2 * gamma * k_xy^2 / k_y^2\n        if k_y == 0:\n             # Should not happen based on problem constraints (k_y > 0)\n            naive_var = float('inf')\n        else:\n            naive_var = (2 * gamma * k_xy**2) / k_y**2\n\n        # 3. Asymptotic variance of the optimally variance-reduced estimator\n        # For the quadratic model, this is zero.\n        cv_opt_var = 0.0\n\n        # 4. Asymptotic variance of the mis-specified variance-reduced estimator\n        # Perturbed parameters\n        k_y_hat = ky_hat_factor * k_y\n        k_xy_hat = kxy_hat_factor * k_xy\n        \n        # Formula: sigma^2_mis = (2*gamma/k_y^2) * (k_xy - k_y * k_xy_hat / k_y_hat)^2\n        if k_y == 0 or k_y_hat == 0:\n            # Should not happen\n            cv_mis_var = float('inf')\n        else:\n            residual_coeff = k_xy - k_y * k_xy_hat / k_y_hat\n            cv_mis_var = (2 * gamma / k_y**2) * residual_coeff**2\n            \n        results.extend([mu, naive_var, cv_opt_var, cv_mis_var])\n\n    # Final print statement in the exact required format.\n    # Using np.format_float_positional to avoid scientific notation and trailing zeros.\n    formatted_results = [np.format_float_positional(r, trim='-') for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3398631"}]}