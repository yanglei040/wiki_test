{"hands_on_practices": [{"introduction": "Calculating the diffusion coefficient, $D$, is a foundational task in molecular dynamics, bridging microscopic motion to macroscopic transport. This exercise guides you through the two primary theoretical routes: the Einstein relation, based on the mean-squared displacement, and the Green-Kubo relation, which integrates the velocity autocorrelation function (VACF). By constructing synthetic data for a particle in a crowded environment, you will explore the practical challenges of these methods, including the crucial role of long-time correlation tails and the subtle differences between ensemble and time averaging [@problem_id:3453827].", "problem": "Consider a single diffusing particle evolving in continuous time with a velocity process subject to crowding-induced memory. The context is molecular dynamics and the focus is thermodynamic fluctuations and response. The goal is to estimate the diffusion coefficient using two routes, examine the discrepancy between time and ensemble averaging, and quantify how much of that discrepancy is attributable to long-time tails in the velocity autocorrelation function. The derivations must begin from fundamental definitions, without shortcut formulas.\n\nYou must implement a program that constructs synthetic trajectories in three spatial dimensions using a discretized microscopic dynamics model consistent with stationary Gaussian statistics and crowding-induced memory. The velocity of each trajectory must be composed of two statistically independent parts: a baseline, exponentially relaxing contribution and a crowding-induced correlated contribution generated by convolving a white-noise sequence with a power-law memory kernel. The positions must be obtained by integrating the velocities in time. All quantities must be expressed in International System of Units (SI), and the final diffusion coefficients must be reported in square meters per second. Angles are not involved. The results must be floats.\n\nFrom these trajectories, the program must compute the following for each test case:\n1. An estimate based on integrating the time correlation of one velocity component, truncated at a finite time. This estimates the coefficient connected to linear response using the standard equilibrium time-correlation definition, but the integral is truncated at the maximum lag used to avoid circular wrap-around artifacts.\n2. A tail-corrected version of the first estimate, obtained by fitting the long-time decay of the velocity autocorrelation to a power law and analytically extending the integral beyond the truncation time using the fitted tail.\n3. An estimate based on the slope of the ensemble-averaged mean squared displacement at long times, divided by twice the spatial dimensionality, as required to obtain a scalar diffusion coefficient from the growth of the displacement variance.\n4. An estimate based on the slope of the time-averaged mean squared displacement of a single trajectory at long times, divided by twice the spatial dimensionality.\n5. A scalar between zero and one that quantifies the fraction of the discrepancy between the ensemble-averaged and time-averaged estimates that can be accounted for by the missing contribution from the long-time tail beyond the truncation time used in the integral. This fraction is defined as the magnitude of the analytically continued tail contribution divided by the absolute difference between the ensemble- and time-averaged diffusion estimates, clipped to one if it would otherwise exceed one.\n\nYou must ensure scientific realism by using physically plausible parameters and by implementing numerically stable and unbiased estimators based on stationarity and ergodicity arguments. Specifically, compute correlation functions using the convolution theorem in the frequency domain and restrict all integrals and fits to lag times where circular convolution does not compromise the estimate. The simulation must be performed with no external files or inputs.\n\nUse the following test suite, where each test set is a tuple of parameters:\n- The number of trajectories $M$, the number of time steps $N$, the time step $dt$ in seconds, the spatial dimension $d$, the baseline relaxation rate $\\gamma$ in inverse seconds, the per-component stationary velocity variance $v_{\\mathrm{var}}$ in $(\\mathrm{m}/\\mathrm{s})^2$, the crowding strength $a_{\\mathrm{tail}}$ in $\\mathrm{m}/\\mathrm{s}$, the power-law kernel exponent parameter $\\beta$ (dimensionless), and the kernel length $L$ (integer):\n1. $(10,16384,10^{-12},3,10^{12},10^{3},0.5,1.25,2048)$\n2. $(10,16384,10^{-12},3,10^{12},10^{3},1.0,1.25,2048)$\n3. $(10,16384,10^{-12},3,10^{12},10^{3},0.0,1.25,2048)$\n\nYour program must:\n- Generate $M$ independent velocity trajectories in $d$ dimensions by summing an exponentially correlated baseline component and a crowding-induced component constructed by convolving white noise with a finite-length kernel whose coefficients scale as $(n+1)^{-\\beta}$ for $n=0,\\ldots,L-1$ and are normalized so that the convolution output has unit variance before scaling by $a_{\\mathrm{tail}}$.\n- Integrate velocities to positions via forward Euler in time.\n- Compute the ensemble-averaged mean squared displacement as the average over trajectories of the squared displacement norm from the origin, and compute the time-averaged mean squared displacement for a single trajectory by circularly averaging over time origins.\n- Compute the velocity autocorrelation function by the convolution theorem for each trajectory and component, average over trajectories and components, and integrate it up to half the total time to avoid circular artifacts.\n- Fit the positive long-time tail of the averaged velocity autocorrelation (beyond $10/\\gamma$) to a power law in time and analytically estimate the residual integral beyond the truncation time; add this residual to obtain the tail-corrected estimate.\n- Extract long-time slopes for both mean squared displacement variants via linear regression on the last half of the usable lag window and convert to diffusion coefficients by dividing by $2d$.\n- Return the five values specified above for each test case. All diffusion coefficients must be reported in $\\mathrm{m}^2/\\mathrm{s}$ as floats. The fraction must be reported as a float in $[0,1]$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a sublist of five floats in the order specified above, with no spaces. For example, the output must have the form `[[x1,x2,x3,x4,x5],[y1,y2,y3,y4,y5],[z1,z2,z3,z4,z5]]`, with all numbers in decimal or scientific notation. No other text may be printed.", "solution": "The fundamental base for diffusion in molecular dynamics is the definition of position as the time integral of velocity and the characterization of thermal fluctuations by stationary correlation functions. Let the particle position be $\\mathbf{r}(t)$ and velocity be $\\mathbf{v}(t)=\\dot{\\mathbf{r}}(t)$ in $d$ spatial dimensions. The ensemble mean squared displacement is defined by $\\mathrm{MSD}(t)=\\left\\langle\\lVert \\mathbf{r}(t)-\\mathbf{r}(0)\\rVert^2\\right\\rangle$, where angle brackets denote an ensemble average over realizations at equilibrium. For any stationary velocity process with zero mean and a component autocorrelation $C(t)=\\left\\langle v_x(0)v_x(t)\\right\\rangle$, one uses the convolution identity\n$$\n\\mathbf{r}(t)-\\mathbf{r}(0)=\\int_0^t \\mathbf{v}(\\tau)\\, \\mathrm{d}\\tau,\n$$\nso that\n$$\n\\mathrm{MSD}(t)=2d\\int_0^t (t-\\tau) C(\\tau)\\, \\mathrm{d}\\tau,\n$$\nwhich follows from stationarity and the definition of the autocorrelation. Differentiating with respect to time yields\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t}\\mathrm{MSD}(t)=2d\\int_0^t C(\\tau)\\, \\mathrm{d}\\tau.\n$$\nAt long times, if the integral of $C(t)$ converges, the derivative tends to a constant, and the growth of $\\mathrm{MSD}(t)$ becomes linear:\n$$\n\\mathrm{MSD}(t)\\sim 2d D\\, t \\quad \\text{as } t\\to\\infty,\n$$\nwhich defines the Einstein relation, where $D$ is the scalar diffusion coefficient.\n\nLinear response theory and the fluctuation-dissipation theorem connect transport coefficients to equilibrium time-correlation functions. For diffusion in an isotropic medium,\n$$\nD = \\int_0^\\infty C(t)\\, \\mathrm{d}t,\n$$\nwhere $C(t)$ is the autocorrelation of a single Cartesian component of the velocity; this is the Green–Kubo relation. Both relations are exact under equilibrium and ergodicity. In crowded systems with slow relaxation, the correlation function can exhibit long-time tails, often with a power-law decay of the form $C(t)\\sim A t^{-\\alpha}$ with $\\alpha1$, which implies that the integral converges but only slowly. For finite observation times $T$, truncating the integral at $T$ yields a bias relative to the infinite-time value, given by the residual tail contribution:\n$$\n\\Delta D_{\\mathrm{tail}}(T) = \\int_T^\\infty C(t)\\, \\mathrm{d}t \\approx \\int_T^\\infty A t^{-\\alpha}\\, \\mathrm{d}t = \\frac{A}{\\alpha-1} T^{1-\\alpha}.\n$$\nThis quantity measures how much of the diffusion coefficient is missed by cutting off the integral at $T$. Because the time-averaged mean squared displacement slope for a single finite trajectory suffers from incomplete sampling of long lags and persistent correlations, the discrepancy between time-averaged and ensemble-averaged estimates can be significantly influenced by the same long-time tail that biases the truncated integral. A principled way to quantify that contribution is to compute the fraction\n$$\nf_{\\mathrm{tail}} = \\min\\left\\{1, \\frac{\\left|\\Delta D_{\\mathrm{tail}}(T)\\right|}{\\left|D_{\\mathrm{Ein,ens}} - D_{\\mathrm{Ein,time}}\\right|} \\right\\},\n$$\nwhere $D_{\\mathrm{Ein,ens}}$ and $D_{\\mathrm{Ein,time}}$ are the diffusion coefficients obtained from the ensemble-averaged and time-averaged mean squared displacement slopes over the same lag window. This fraction estimates how much of the observed discrepancy is explained by the analytic extension of the long-time tail beyond the truncation time.\n\nAlgorithmic construction consistent with the above principles:\n1. Velocity model. We synthesize a stationary Gaussian velocity process in $d$ dimensions as a sum $\\mathbf{v}(t)=\\mathbf{v}^{\\mathrm{OU}}(t)+\\mathbf{w}(t)$, where $\\mathbf{v}^{\\mathrm{OU}}(t)$ is an Ornstein–Uhlenbeck process with per-component relaxation rate $\\gamma$ and stationary variance $v_{\\mathrm{var}}$, and $\\mathbf{w}(t)$ is a crowding-induced contribution obtained by convolving a unit-variance white-noise sequence with a finite-length memory kernel $k_n\\propto (n+1)^{-\\beta}$, normalized so that the convolution output has unit variance before scaling by $a_{\\mathrm{tail}}$. In discrete time with step $dt$, the exact-update Ornstein–Uhlenbeck recursion for each component is\n$$\nv_{n+1}^{\\mathrm{OU}} = a v_{n}^{\\mathrm{OU}} + \\sigma \\xi_n,\\quad a=e^{-\\gamma\\, dt},\\quad \\sigma=\\sqrt{v_{\\mathrm{var}}\\,(1-a^2)},\n$$\nwith $\\xi_n$ independent standard normal random numbers. The crowding contribution is $w_n = (k * z)_n$, the circular convolution of independent standard normal $z_n$ with a kernel $k_n$ normalized to unit convolution variance; we then scale by $a_{\\mathrm{tail}}$ to adjust the crowding strength. The sum is a stationary Gaussian process with correlation inherited from both parts, and for $\\beta1$ the induced correlations decay algebraically.\n\n2. Position integration. Positions are computed by forward Euler integration $\\mathbf{r}_{n+1}=\\mathbf{r}_n + \\mathbf{v}_n\\, dt$, starting from $\\mathbf{r}_0=\\mathbf{0}$.\n\n3. Velocity autocorrelation and Green–Kubo. For each trajectory and component, compute the autocorrelation by the convolution theorem (Wiener–Khinchin). For a length-$N$ sequence $v_n$, the circular autocorrelation estimate is\n$$\n\\widehat{C}_\\mathrm{circ}[\\ell] = \\frac{1}{N}\\,\\mathcal{F}^{-1}\\left\\{ \\mathcal{F}\\{v\\}\\cdot \\overline{\\mathcal{F}\\{v\\}} \\right\\}[\\ell],\n$$\nwhere $\\mathcal{F}$ denotes the discrete Fourier transform and overline complex conjugation. Average $\\widehat{C}$ across components and trajectories to obtain an ensemble estimate $C(\\ell\\, dt)$, and integrate by the trapezoid rule up to $\\ell_{\\max}=N/2$ to avoid circular wrap-around:\n$$\nD_{\\mathrm{GK,trunc}} \\approx \\sum_{\\ell=0}^{\\ell_{\\max}} C(\\ell\\, dt)\\, dt.\n$$\nTo correct for the tail, fit the region $\\ell\\ge\\ell_{\\mathrm{fit}}$ with $\\ell_{\\mathrm{fit}}\\approx \\lceil 10/(\\gamma\\, dt)\\rceil$ where the exponential part has decayed, using a log–log linear regression $\\log C(t)\\approx \\log A - \\alpha \\log t$ on points with $C(t)0$, and then add $\\Delta D_{\\mathrm{tail}}$ evaluated at $T=\\ell_{\\max}\\, dt$:\n$$\nD_{\\mathrm{GK,corr}} = D_{\\mathrm{GK,trunc}} + \\frac{A}{\\alpha-1}\\, T^{1-\\alpha},\\quad \\alpha1.\n$$\n\n4. Ensemble Einstein estimate. The ensemble-averaged mean squared displacement is $\\mathrm{MSD}_{\\mathrm{ens}}(n\\, dt)=\\frac{1}{M}\\sum_{m=1}^M \\lVert \\mathbf{r}^{(m)}_n - \\mathbf{r}^{(m)}_0\\rVert^2$. Fit a straight line to the last half of the usable lag window and compute the slope $s_{\\mathrm{ens}}$, yielding\n$$\nD_{\\mathrm{Ein,ens}} = \\frac{s_{\\mathrm{ens}}}{2d}.\n$$\n\n5. Time-averaged Einstein estimate. For a single trajectory, the time-averaged mean squared displacement at lag $\\ell$ is defined by averaging over time origins under the circular approximation,\n$$\n\\mathrm{MSD}_{\\mathrm{time}}(\\ell\\, dt) = \\frac{1}{N}\\sum_{n=0}^{N-1} \\lVert \\mathbf{r}_{n+\\ell}-\\mathbf{r}_n\\rVert^2.\n$$\nThis can be computed efficiently via the convolution theorem using the position autocorrelation $\\widehat{R}(\\ell)=\\frac{1}{N}\\sum_n \\mathbf{r}_n\\cdot \\mathbf{r}_{n+\\ell}$:\n$$\n\\mathrm{MSD}_{\\mathrm{time}}(\\ell\\, dt)=2\\sum_{i=1}^d\\left( \\frac{1}{N}\\sum_{n} x_{i,n}^2 - \\widehat{R}_i(\\ell)\\right).\n$$\nFit the last half of the accessible lags to obtain the slope $s_{\\mathrm{time}}$ and compute\n$$\nD_{\\mathrm{Ein,time}}=\\frac{s_{\\mathrm{time}}}{2d}.\n$$\n\n6. Tail contribution fraction. With $T=\\ell_{\\max}\\, dt$,\n$$\nf_{\\mathrm{tail}} = \\min\\left\\{1, \\frac{\\left|\\frac{A}{\\alpha-1} T^{1-\\alpha}\\right|}{\\left|D_{\\mathrm{Ein,ens}}-D_{\\mathrm{Ein,time}}\\right|}\\right\\}.\n$$\nThis fraction quantifies the extent to which the missing long-time tail beyond the truncation time explains the discrepancy between the time-averaged and ensemble-averaged diffusion estimates.\n\nNumerical details:\n- Use the exact-update form for the Ornstein–Uhlenbeck recursion to ensure the stationary target variance $v_{\\mathrm{var}}$ per component.\n- Construct the memory kernel as $k_n=(n+1)^{-\\beta}$ and normalize so that the circular convolution with white noise yields unit variance: if $z_n$ are independent standard normal random variables and $w_n=(k*z)_n$ is the circular convolution, then $\\mathrm{Var}(w_n)=\\sum_{n=0}^{L-1}k_n^2$; define $k_n\\leftarrow k_n/\\sqrt{\\sum k_n^2}$ to set this variance to one before scaling by $a_{\\mathrm{tail}}$.\n- Compute autocorrelations and circular time averages using the Discrete Fourier Transform via the convolution theorem. Restrict estimates to lags $\\ell\\le N/2$.\n- Perform log–log linear regression on positive values of the autocorrelation in the tail region. If fewer than a minimal number of points are available or the fitted exponent is not greater than one, set the tail correction to zero.\n- Use linear regression via least squares to fit slopes of the mean squared displacements over the last half of the usable window.\n\nTest suite coverage:\n- The first case sets moderate crowding strength $a_{\\mathrm{tail}}=0.5\\,\\mathrm{m}/\\mathrm{s}$, yielding discernible long-time tails and a modest discrepancy.\n- The second case sets strong crowding $a_{\\mathrm{tail}}=1.0\\,\\mathrm{m}/\\mathrm{s}$, accentuating long-time tails and increasing the discrepancy.\n- The third case sets $a_{\\mathrm{tail}}=0$, recovering a purely exponentially relaxing baseline with negligible long-time tail, serving as a boundary condition where the truncated integral and Einstein estimates agree within statistical error.\n\nThe program aggregates the five scalar results per test case into a single-line output of nested lists in the exact format specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef generate_velocities(M, N, dt, d, gamma, v_var, a_tail, beta, L, rng):\n    \"\"\"\n    Generate M velocity trajectories, each with d components and length N, as\n    the sum of an OU process and a crowding-induced correlated component\n    constructed by circular convolution of white noise with a power-law kernel.\n    \"\"\"\n    # Precompute OU parameters\n    a = np.exp(-gamma * dt)\n    sigma = np.sqrt(v_var * (1.0 - a * a))\n\n    # Build and normalize the memory kernel (length N, padding zeros beyond L)\n    k = np.zeros(N)\n    n = np.arange(L)\n    # Power-law kernel k_n ~ (n+1)^(-beta)\n    k_vals = (n + 1.0) ** (-beta)\n    k_norm = np.sqrt(np.sum(k_vals ** 2))\n    if k_norm == 0.0:\n        k_norm = 1.0\n    k[:L] = k_vals / k_norm  # normalized so that variance of convolution output ~ 1\n\n    K_fft = np.fft.rfft(k)  # FFT of kernel for circular convolution\n\n    # Storage for velocities: shape (M, d, N)\n    v = np.zeros((M, d, N), dtype=float)\n\n    # Generate trajectories\n    for m in range(M):\n        for comp in range(d):\n            # Ornstein-Uhlenbeck component\n            v_ou = np.empty(N, dtype=float)\n            v_ou[0] = rng.normal(0.0, np.sqrt(v_var))\n            # Exact-update recursion\n            xi = rng.normal(0.0, 1.0, size=N - 1)\n            for i in range(N - 1):\n                v_ou[i + 1] = a * v_ou[i] + sigma * xi[i]\n\n            if a_tail != 0.0:\n                # Crowding-induced correlated component via circular convolution\n                z = rng.normal(0.0, 1.0, size=N)\n                Z_fft = np.fft.rfft(z)\n                w = np.fft.irfft(Z_fft * K_fft, n=N)\n                # Scale by a_tail to set the strength in m/s\n                v[m, comp, :] = v_ou + a_tail * w\n            else:\n                v[m, comp, :] = v_ou\n\n    return v\n\ndef integrate_positions(v, dt):\n    \"\"\"\n    Integrate velocities to positions via forward Euler.\n    v: shape (M, d, N)\n    Returns positions r: shape (M, d, N)\n    \"\"\"\n    M, d, N = v.shape\n    r = np.zeros((M, d, N), dtype=float)\n    # Forward Euler integration\n    r[:, :, 1:] = np.cumsum(v[:, :, :-1] * dt, axis=2)\n    return r\n\ndef autocorr_fft(x):\n    \"\"\"\n    Circular autocorrelation via FFT, normalized by sequence length.\n    For input array x of length N, returns length-N autocorrelation estimate.\n    \"\"\"\n    N = x.shape[-1]\n    X = np.fft.rfft(x)\n    S = X * np.conj(X)\n    acf = np.fft.irfft(S, n=N) / N\n    return acf\n\ndef ensemble_velocity_acf(v, max_lag):\n    \"\"\"\n    Compute ensemble- and component-averaged velocity autocorrelation up to max_lag.\n    v: shape (M, d, N)\n    Returns acf_avg[0:max_lag+1]\n    \"\"\"\n    M, d, N = v.shape\n    acf_sum = np.zeros(N, dtype=float)\n    for m in range(M):\n        for comp in range(d):\n            acf = autocorr_fft(v[m, comp, :])\n            acf_sum += acf\n    acf_avg_full = acf_sum / (M * d)\n    return acf_avg_full[:max_lag + 1]\n\ndef fit_power_law_tail(times, values):\n    \"\"\"\n    Fit values ~ A * t^(-alpha) using log-log linear regression on positive values.\n    times: array of t0\n    values: array of corresponding C(t)\n    Returns (A, alpha, ok) where ok indicates fit validity with alpha1 and sufficient points.\n    \"\"\"\n    # Select positive times and positive values\n    mask = (times > 0)  (values > 0)\n    t_pos = times[mask]\n    v_pos = values[mask]\n    if t_pos.size  10:\n        return 0.0, 0.0, False\n    log_t = np.log(t_pos)\n    log_v = np.log(v_pos)\n    # Linear regression log_v = b + m * log_t\n    m, b = np.polyfit(log_t, log_v, deg=1)\n    alpha = -m\n    A = np.exp(b)\n    if alpha = 1.0 or not np.isfinite(alpha) or not np.isfinite(A):\n        return 0.0, 0.0, False\n    return A, alpha, True\n\ndef slope_linear_fit(times, values):\n    \"\"\"\n    Compute slope via linear regression of values vs times.\n    Returns slope (float).\n    \"\"\"\n    # Fit y = a * t + c\n    A = np.vstack([times, np.ones_like(times)]).T\n    # Least squares solution\n    coeffs, _, _, _ = np.linalg.lstsq(A, values, rcond=None)\n    slope = coeffs[0]\n    return slope\n\ndef compute_msd_ensemble(r):\n    \"\"\"\n    Compute ensemble-averaged MSD(t) = mean over trajectories of |r(t) - r(0)|^2.\n    r: shape (M, d, N)\n    Returns msd_ens of shape (N,)\n    \"\"\"\n    # r(0) = 0 by construction; displacement norm squared is sum over dimensions of r^2\n    disp2 = np.sum(r ** 2, axis=1)  # shape (M, N)\n    msd_ens = np.mean(disp2, axis=0)  # shape (N,)\n    return msd_ens\n\ndef compute_tamsd_single(r_single):\n    \"\"\"\n    Compute time-averaged MSD for a single trajectory via circular averaging.\n    r_single: shape (d, N)\n    Returns tamsd of shape (N,), derived up to N lags (circular).\n    \"\"\"\n    d, N = r_single.shape\n    # For each component, compute autocorrelation of x via FFT\n    acf_sum = np.zeros(N, dtype=float)\n    mean_x2_sum = 0.0\n    for comp in range(d):\n        x = r_single[comp, :]\n        mean_x2_sum += np.mean(x ** 2)\n        acf_x = autocorr_fft(x)  # circular autocorrelation\n        acf_sum += acf_x\n    # TAMSD(ell) = 2 * (sum_d mean(x^2) - sum_d acf_x(ell))\n    tamsd = 2.0 * (mean_x2_sum - acf_sum)\n    return tamsd\n\ndef run_case(params):\n    \"\"\"\n    Run a single test case and return results:\n    [D_GK_trunc, D_GK_tailcorr, D_Ein_ensemble, D_Ein_time, f_tail]\n    \"\"\"\n    (M, N, dt, d, gamma, v_var, a_tail, beta, L) = params\n    rng = np.random.default_rng(seed=12345)  # fixed seed for reproducibility per run_case\n\n    # Generate synthetic velocities and positions\n    v = generate_velocities(M, N, dt, d, gamma, v_var, a_tail, beta, L, rng)\n    r = integrate_positions(v, dt)\n\n    # Maximum lag to avoid wrap-around artifacts\n    max_lag = N // 2  # use half-length\n    times = np.arange(max_lag + 1) * dt\n\n    # Ensemble-averaged velocity autocorrelation and Green-Kubo integrals\n    acf_avg = ensemble_velocity_acf(v, max_lag)\n    # Truncated integral\n    D_GK_trunc = np.trapz(acf_avg, times)\n\n    # Fit tail beyond t_fit_start = 10/gamma\n    t_fit_start = 10.0 / gamma\n    fit_mask = times >= t_fit_start\n    A_tail, alpha_tail, ok_tail = fit_power_law_tail(times[fit_mask], acf_avg[fit_mask])\n    # Tail correction beyond truncation time T = times[-1]\n    if ok_tail:\n        T_trunc = times[-1]\n        delta_D_tail = (A_tail / (alpha_tail - 1.0)) * (T_trunc ** (1.0 - alpha_tail))\n    else:\n        delta_D_tail = 0.0\n    D_GK_tailcorr = D_GK_trunc + delta_D_tail\n\n    # Ensemble Einstein estimate from ensemble MSD\n    msd_ens = compute_msd_ensemble(r)\n    # Fit on the last half of usable lags\n    t_fit_ens = times[1:max_lag]  # exclude time zero\n    y_fit_ens = msd_ens[1:max_lag]\n    # Use latter half\n    start_idx = len(t_fit_ens) // 2\n    t_seg_ens = t_fit_ens[start_idx:]\n    y_seg_ens = y_fit_ens[start_idx:]\n    slope_ens = slope_linear_fit(t_seg_ens, y_seg_ens)\n    D_Ein_ensemble = slope_ens / (2.0 * d)\n\n    # Time-averaged MSD for first trajectory\n    tamsd = compute_tamsd_single(r[0, :, :])\n    # Fit on the last half of usable lags\n    y_fit_time = tamsd[1:max_lag]\n    t_seg_time = t_fit_ens[start_idx:]\n    y_seg_time = y_fit_time[start_idx:]\n    slope_time = slope_linear_fit(t_seg_time, y_seg_time)\n    D_Ein_time = slope_time / (2.0 * d)\n\n    # Fraction of discrepancy explained by tail\n    denom = abs(D_Ein_ensemble - D_Ein_time)\n    # Use absolute tail correction magnitude (per-component diffusion correction)\n    f_tail = min(1.0, abs(delta_D_tail) / (denom + 1e-30))\n\n    return [D_GK_trunc, D_GK_tailcorr, D_Ein_ensemble, D_Ein_time, f_tail]\n\ndef format_results(results):\n    \"\"\"\n    Format nested list of floats with no spaces, each float in scientific notation.\n    \"\"\"\n    def fmt_float(x):\n        return f\"{x:.6e}\"\n    inner_lists = []\n    for res in results:\n        inner = \",\".join(fmt_float(x) for x in res)\n        inner_lists.append(f\"[{inner}]\")\n    return \"[\" + \",\".join(inner_lists) + \"]\"\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (10, 16384, 1e-12, 3, 1e12, 1e3, 0.5, 1.25, 2048),\n        (10, 16384, 1e-12, 3, 1e12, 1e3, 1.0, 1.25, 2048),\n        (10, 16384, 1e-12, 3, 1e12, 1e3, 0.0, 1.25, 2048),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_case(case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(format_results(results))\n\nsolve()\n```", "id": "3453827"}, {"introduction": "A key challenge in molecular simulation is relating results from a finite, periodic system to the infinite system of the real world. This practice illuminates a critical finite-size effect: the systematic dependence of the diffusion coefficient on simulation box size $L$. You will derive how the long-range $t^{-3/2}$ hydrodynamic tail of the VACF is effectively cut off by the finite box, leading to a predictable, $1/L$ correction to the diffusion coefficient, and then validate this prediction numerically [@problem_id:3453864].", "problem": "Consider a three-dimensional equilibrium fluid simulated in a cubic periodic box of edge length $L$ using molecular dynamics. The self-diffusion coefficient $D$ is related to the velocity autocorrelation function (VACF) $C(t)=\\langle \\mathbf{v}(0)\\cdot \\mathbf{v}(t)\\rangle$ by the Green–Kubo relation $D=\\frac{1}{3}\\int_{0}^{\\infty} C(t)\\,dt$. In an infinite system, hydrodynamics predicts a long-time tail of the VACF with the asymptotic form $C(t)\\sim A\\,t^{-3/2}$ for large $t$, where $A$ is a positive amplitude that depends on thermodynamic and transport parameters. In a finite periodic domain, hydrodynamic long-wavelength modes are discretized: the smallest nonzero wave number is $k_{\\min}=2\\pi/L$, and shear modes decay diffusively with a decay rate $\\nu k^{2}$, where $\\nu$ is the kinematic viscosity. This introduces a hydrodynamic time scale $\\tau_{L}\\sim 1/(\\nu k_{\\min}^{2})$ beyond which the infinite-system asymptotic tail ceases to contribute.\n\nStarting only from the following base principles:\n- The Green–Kubo relation $D=\\frac{1}{3}\\int_{0}^{\\infty} C(t)\\,dt$.\n- The finite-size hydrodynamic mode discretization $k_{\\min}=2\\pi/L$ in a cubic periodic box.\n- The diffusive decay rate of shear modes $\\nu k^{2}$, hence a hydrodynamic time scale $\\tau_{L}=1/(\\nu k_{\\min}^{2})$.\n- The asymptotic VACF form $C(t)\\sim A\\,t^{-3/2}$ at long times in three dimensions.\n\nDerive how the finite system size $L$ modifies the measured diffusion coefficient $D(L)$ relative to its infinite-system value $D_{\\infty}$. Your derivation should proceed by identifying the contribution to $D$ from the long-time tail and explaining how the finite cutoff in time at $t\\sim \\tau_{L}$ removes part of this contribution in the finite system. From this, obtain the leading-order finite-size correction to $D(L)$ in terms of $A$, $\\nu$, and $L$, and state its scaling with $L$.\n\nThen implement the derived expression to predict $D(L)$ for given parameters and validate the predicted $1/L$ scaling by a linear least-squares fit of $D(L)$ versus $1/L$ to recover both the slope and the intercept. Compare the fitted slope magnitude against your analytic prediction and the fitted intercept against the input $D_{\\infty}$.\n\nNumerical and algorithmic requirements:\n- Use the expression you derived for the leading-order finite-size correction to compute, for each specified set of parameters $\\{D_{\\infty}, \\nu, A, \\{L_{i}\\}\\}$, the values $D(L_{i})$.\n- For each parameter set, perform a linear regression of $D(L)$ versus $1/L$ over the provided list $\\{L_{i}\\}$, reporting the absolute difference between:\n  1. The magnitude of the fitted slope and your analytic slope prediction, expressed in $\\mathrm{m^{3}/s}$.\n  2. The fitted intercept and the input $D_{\\infty}$, expressed in $\\mathrm{m^{2}/s}$.\n- All computed diffusion coefficients $D(L)$ must be reported in $\\mathrm{m^{2}/s}$.\n- All outputs must be rounded to $12$ significant figures.\n- Angles are not used in this problem; no angle unit specification is required.\n\nTest suite:\nUse the following three parameter sets to comprehensively test your implementation. All quantities are in the International System of Units (SI).\n- Case $1$ (happy path):\n  - $D_{\\infty}=2.3\\times 10^{-9}\\,\\mathrm{m^{2}/s}$,\n  - $\\nu=1.0\\times 10^{-6}\\,\\mathrm{m^{2}/s}$,\n  - $A=6.2\\times 10^{-17}\\,\\mathrm{m^{2}\\,s^{-1/2}}$,\n  - $L\\in\\{5.0\\times 10^{-8}\\,\\mathrm{m},\\,1.0\\times 10^{-7}\\,\\mathrm{m},\\,2.0\\times 10^{-7}\\,\\mathrm{m}\\}$.\n- Case $2$ (different transport regime):\n  - $D_{\\infty}=1.0\\times 10^{-9}\\,\\mathrm{m^{2}/s}$,\n  - $\\nu=5.0\\times 10^{-7}\\,\\mathrm{m^{2}/s}$,\n  - $A=1.0\\times 10^{-16}\\,\\mathrm{m^{2}\\,s^{-1/2}}$,\n  - $L\\in\\{1.0\\times 10^{-7}\\,\\mathrm{m},\\,3.0\\times 10^{-7}\\,\\mathrm{m},\\,1.0\\times 10^{-6}\\,\\mathrm{m}\\}$.\n- Case $3$ (edge case with no tail):\n  - $D_{\\infty}=1.0\\times 10^{-9}\\,\\mathrm{m^{2}/s}$,\n  - $\\nu=1.0\\times 10^{-6}\\,\\mathrm{m^{2}/s}$,\n  - $A=0.0\\,\\mathrm{m^{2}\\,s^{-1/2}}$,\n  - $L\\in\\{1.0\\times 10^{-7}\\,\\mathrm{m},\\,2.0\\times 10^{-7}\\,\\mathrm{m}\\}$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets.\n- For each case, append in order: the values $D(L_{i})$ for the listed $L_{i}$ (each in $\\mathrm{m^{2}/s}$, rounded to $12$ significant figures), followed by two validation metrics for that case:\n  1. The absolute error between the fitted slope magnitude and the analytic slope prediction (in $\\mathrm{m^{3}/s}$, rounded to $12$ significant figures).\n  2. The absolute error between the fitted intercept and $D_{\\infty}$ (in $\\mathrm{m^{2}/s}$, rounded to $12$ significant figures).\n- Concatenate the results for Case $1$, then Case $2$, then Case $3$ into a single flat list. For example, the output should have the form $[D(L_{1}^{(1)}),D(L_{2}^{(1)}),\\dots,\\text{slope\\_err}^{(1)},\\text{intercept\\_err}^{(1)},D(L_{1}^{(2)}),\\dots]$ where superscripts denote the case index.", "solution": "The diffusion coefficient $D$ is given by the Green-Kubo relation in three dimensions:\n$$D = \\frac{1}{3} \\int_{0}^{\\infty} C(t) \\, dt$$\nwhere $C(t) = \\langle \\mathbf{v}(0)\\cdot \\mathbf{v}(t)\\rangle$ is the velocity autocorrelation function (VACF). In an infinite system ($L \\to \\infty$), this integral yields the true diffusion coefficient, $D_{\\infty}$.\n\nThe VACF can be split into a short-time part and a long-time hydrodynamic tail:\n$$D_{\\infty} = \\frac{1}{3} \\int_{0}^{\\tau_0} C(t) \\, dt + \\frac{1}{3} \\int_{\\tau_0}^{\\infty} C(t) \\, dt$$\nwhere $\\tau_0$ is a microscopic time after which the asymptotic form $C(t) \\sim A t^{-3/2}$ becomes valid.\n\nIn a finite periodic system of size $L$, the continuous spectrum of hydrodynamic modes is replaced by a discrete set of wave vectors. The smallest non-zero wave number is $k_{\\min} = 2\\pi/L$. The long-time tail arises from the coupling of particle motion to slowly decaying shear modes of the fluid. In a finite box, the slowest-decaying mode corresponds to $k_{\\min}$. The decay rate of this mode is $\\gamma = \\nu k_{\\min}^2$, where $\\nu$ is the kinematic viscosity. This introduces a finite-system hydrodynamic time scale, $\\tau_L = 1/\\gamma$, beyond which the collective modes responsible for the $t^{-3/2}$ tail are effectively cut off.\n$$\\tau_L = \\frac{1}{\\nu k_{\\min}^2} = \\frac{1}{\\nu \\left(\\frac{2\\pi}{L}\\right)^2} = \\frac{L^2}{4\\pi^2\\nu}$$\nThe measured diffusion coefficient in the finite system, $D(L)$, is obtained by assuming the VACF is truncated at a time of order $\\tau_L$. The difference between $D_{\\infty}$ and $D(L)$ is primarily due to the \"missing\" portion of the integral from the long-time tail.\n$$\\Delta D = D(L) - D_{\\infty} \\approx -\\frac{1}{3} \\int_{\\tau_L}^{\\infty} C(t) \\, dt$$\nWe can approximate this difference by using the asymptotic form of $C(t)$:\n$$\\Delta D \\approx -\\frac{1}{3} \\int_{\\tau_L}^{\\infty} A t^{-3/2} \\, dt$$\nEvaluating the definite integral:\n$$ \\int_{\\tau_L}^{\\infty} A t^{-3/2} \\, dt = A \\left[ -2t^{-1/2} \\right]_{\\tau_L}^{\\infty} = A \\left( \\lim_{t\\to\\infty}(-2t^{-1/2}) - (-2\\tau_L^{-1/2}) \\right) = 2A\\tau_L^{-1/2} $$\nSubstituting this result back, we get the finite-size correction:\n$$\\Delta D = -\\frac{1}{3} (2A\\tau_L^{-1/2}) = -\\frac{2A}{3\\sqrt{\\tau_L}}$$\nNow, we substitute the expression for $\\tau_L$:\n$$\\Delta D = -\\frac{2A}{3\\sqrt{\\frac{L^2}{4\\pi^2\\nu}}} = -\\frac{2A}{3 \\left( \\frac{L}{2\\pi\\sqrt{\\nu}} \\right)} = -\\frac{4\\pi A \\sqrt{\\nu}}{3L}$$\nThis equation quantifies the leading-order finite-size effect. By rearranging it, we obtain the expression for $D(L)$:\n$$D(L) = D_{\\infty} + \\Delta D = D_{\\infty} - \\frac{4\\pi A \\sqrt{\\nu}}{3L}$$\nThis result shows that the leading-order correction to the diffusion coefficient scales as $1/L$. The relationship is linear when $D(L)$ is plotted against $1/L$:\n$$D(L) = D_{\\infty} + m \\cdot \\left(\\frac{1}{L}\\right)$$\nThe analytical prediction for the intercept is $D_{\\infty}$, and for the slope $m$ is:\n$$m = -\\frac{4\\pi A \\sqrt{\\nu}}{3}$$\nThe magnitude of the analytical slope is therefore $|m| = \\frac{4\\pi A \\sqrt{\\nu}}{3}$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import linregress\n\ndef solve():\n    \"\"\"\n    Derives and applies the finite-size correction for the self-diffusion coefficient\n    in molecular dynamics simulations, and validates the result via linear regression.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # All quantities are in SI units.\n    test_cases = [\n        {\n            \"D_inf\": 2.3e-9,  # m^2/s\n            \"nu\": 1.0e-6,   # m^2/s\n            \"A\": 6.2e-17,   # m^2*s^(-1/2)\n            \"L_values\": [5.0e-8, 1.0e-7, 2.0e-7],  # m\n        },\n        {\n            \"D_inf\": 1.0e-9,\n            \"nu\": 5.0e-7,\n            \"A\": 1.0e-16,\n            \"L_values\": [1.0e-7, 3.0e-7, 1.0e-6],\n        },\n        {\n            \"D_inf\": 1.0e-9,\n            \"nu\": 1.0e-6,\n            \"A\": 0.0,\n            \"L_values\": [1.0e-7, 2.0e-7],\n        },\n    ]\n\n    results = []\n    \n    # Custom formatter for 12 significant figures\n    def format_num(n):\n        return f\"{n:.12g}\"\n\n    for case in test_cases:\n        D_inf = case[\"D_inf\"]\n        nu = case[\"nu\"]\n        A = case[\"A\"]\n        L_values = case[\"L_values\"]\n\n        # 1. Calculate the magnitude of the analytic slope from the derived formula.\n        # The relationship is D(L) = D_inf - C/L, where C is the slope magnitude.\n        # C = (4 * pi * A * sqrt(nu)) / 3\n        analytic_slope_magnitude = (4 * np.pi * A * np.sqrt(nu)) / 3\n\n        x_reg = []  # will store 1/L values\n        y_reg = []  # will store D(L) values\n\n        # 2. Compute D(L) for each L and prepare data for regression\n        for L in L_values:\n            # The derived formula for D(L) is D_inf - (analytic_slope_magnitude) * (1/L)\n            d_l = D_inf - analytic_slope_magnitude / L\n            results.append(d_l)\n            \n            x_reg.append(1.0 / L)\n            y_reg.append(d_l)\n\n        # 3. Perform linear regression of D(L) vs 1/L\n        # Convert to numpy arrays for scipy\n        x_reg_np = np.array(x_reg)\n        y_reg_np = np.array(y_reg)\n        \n        # linregress will return a perfect fit since the data is generated from the model\n        fit_result = linregress(x_reg_np, y_reg_np)\n        fitted_slope = fit_result.slope\n        fitted_intercept = fit_result.intercept\n\n        # 4. Calculate the error metrics\n        # Abs difference between fitted slope magnitude and analytic slope magnitude\n        slope_error = abs(abs(fitted_slope) - analytic_slope_magnitude)\n        \n        # Abs difference between fitted intercept and D_inf\n        intercept_error = abs(fitted_intercept - D_inf)\n\n        results.append(slope_error)\n        results.append(intercept_error)\n\n    # 5. Final print statement in the exact required format.\n    formatted_results = [format_num(r) for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3453864"}, {"introduction": "The fluctuation-dissipation theorem offers a profound connection between equilibrium fluctuations and linear transport phenomena. This practice explores this connection for shear viscosity, $\\eta$, and thermal conductivity, $\\kappa$, by contrasting calculations from equilibrium time-correlation functions (the Green-Kubo method) with a model for non-equilibrium simulations where an external field is applied. This comparison allows you to identify the limits of linear response theory and understand when equilibrium fluctuations are sufficient to predict a system's response to perturbation [@problem_id:3453814].", "problem": "Consider a homogeneous Lennard–Jones fluid in reduced units where the characteristic energy $\\,\\epsilon\\,$, length $\\,\\sigma\\,$, mass $\\,m\\,$, and the Boltzmann constant $\\,k_{\\mathrm{B}}\\,$ are set to $\\,1\\,$. In these Lennard–Jones reduced units, all reported quantities are dimensionless. The equilibrium time autocorrelation functions of two microscopic fluxes are given: the off-diagonal shear component of the pressure tensor $\\,P_{xy}\\,$ and the heat current $\\,J_{Q}\\,$. Let $\\,C_{P}(t) = \\langle P_{xy}(0) P_{xy}(t)\\rangle/V\\,$ and $\\,C_{J}(t) = \\langle J_{Q}(0) J_{Q}(t)\\rangle/V\\,$ denote per-volume correlation functions, where $\\,V\\,$ is the volume and $\\,\\langle \\cdot \\rangle\\,$ denotes an equilibrium ensemble average. Assume linear response theory holds in the weak forcing limit, and consider nonequilibrium forcings that may induce nonlinear response at larger amplitudes.\n\nYour task is to write a complete, runnable program that, for each test case specified below, performs the following:\n\n- Starting from the fluctuation–dissipation framework and the Green–Kubo construction, compute the shear viscosity $\\,\\eta_{0}\\,$ and thermal conductivity $\\,\\kappa_{0}\\,$ in the linear regime by numerically integrating $\\,C_{P}(t)\\,$ and $\\,C_{J}(t)\\,$, respectively, over time using a convergent quadrature on a finite time window chosen to render the remainder negligible.\n- For nonequilibrium forcing amplitudes $\\,\\dot{\\gamma}\\,$ (shear rate) and $\\,|\\nabla T|\\,$ (magnitude of temperature gradient), model the effective transport coefficients $\\,\\eta(\\dot{\\gamma})\\,$ and $\\,\\kappa(|\\nabla T|)\\,$ via a weakly nonlinear expansion consistent with isotropy and parity:\n  $$ \\eta_{\\mathrm{eff}}(\\dot{\\gamma}) = \\eta_{0}\\left[1 - a\\left(\\frac{\\dot{\\gamma}}{\\dot{\\gamma}_{c}}\\right)^{2}\\right], \\qquad \\kappa_{\\mathrm{eff}}(|\\nabla T|) = \\kappa_{0}\\left[1 - b\\left(\\frac{|\\nabla T|}{G_{c}}\\right)^{2}\\right], $$\n  where $\\,a\\,$, $\\,b\\,$, $\\,\\dot{\\gamma}_{c}\\,$, and $\\,G_{c}\\,$ are case-dependent parameters.\n- Identify the onset of nonlinear response separately for $\\,\\eta(\\dot{\\gamma})\\,$ and $\\,\\kappa(|\\nabla T|)\\,$ by scanning the provided amplitude lists and finding the smallest amplitude at which the relative deviation from $\\,\\eta_{0}\\,$ or $\\,\\kappa_{0}\\,$ exceeds $\\,0.05\\,$ (i.e., a $\\,0.05\\,$ threshold expressed as a decimal). If no amplitude in the list exceeds the threshold, define the onset amplitude to be $\\,0.0\\,$.\n- Check fluctuation–dissipation consistency in the linear regime by verifying that, at the smallest amplitudes provided for $\\,\\dot{\\gamma}\\,$ and $\\,|\\nabla T|\\,$, the relative deviations $\\,\\left|\\eta_{\\mathrm{eff}}/\\eta_{0} - 1\\right|\\,$ and $\\,\\left|\\kappa_{\\mathrm{eff}}/\\kappa_{0} - 1\\right|\\,$ are both less than $\\,0.01\\,$. Report a boolean that is $\\,\\mathrm{True}\\,$ if both deviations satisfy this bound and $\\,\\mathrm{False}\\,$ otherwise.\n\nFundamental base to use:\n- Equilibrium time autocorrelation functions and the fluctuation–dissipation theorem relate transport coefficients to integrated equilibrium fluctuations in the linear response regime.\n- For per-volume correlation functions, the Green–Kubo expressions read\n  $$ \\eta_{0} = \\frac{1}{k_{\\mathrm{B}} T}\\int_{0}^{\\infty} C_{P}(t)\\,dt, \\qquad \\kappa_{0} = \\frac{1}{k_{\\mathrm{B}} T^{2}}\\int_{0}^{\\infty} C_{J}(t)\\,dt, $$\n  with $\\,k_{\\mathrm{B}}=1\\,$ in Lennard–Jones reduced units, and $\\,T\\,$ the temperature.\n- The nonequilibrium constitutive relations for the fluxes are $\\,\\langle P_{xy}\\rangle = -\\eta(\\dot{\\gamma})\\,\\dot{\\gamma}\\,$ and $\\,\\langle J_{Q}\\rangle = -\\kappa(|\\nabla T|)\\,|\\nabla T|\\,$, with effective coefficients modeled above.\n\nNumerical protocol:\n- Use a uniform time step $\\,\\Delta t = 10^{-3}\\,$ and integrate on $\\,t \\in [0, t_{\\max}]\\,$ with $\\,t_{\\max}\\,$ chosen as $\\,10\\,$ times the largest decay time parameter across $\\,C_{P}\\,$ and $\\,C_{J}\\,$ in each test case. Use a composite Simpson rule on an odd number of grid points to ensure accuracy.\n- All outputs must be expressed in Lennard–Jones reduced units.\n\nTest suite and model correlation functions:\nFor each test case $\\,i \\in \\{1,2,3\\}\\,$, the temperature $\\,T\\,$ and correlation functions are specified as follows, with parameters constrained to physically sensible decays and oscillations:\n\n- Case $\\,1\\,$:\n  - Temperature: $\\,T = 1.0\\,$.\n  - Shear stress correlation: \n    $$ C_{P}(t) = A_{P1}\\,e^{-t/\\tau_{P1}} + A_{P2}\\,e^{-t/\\tau_{P2}}\\cos(\\omega_{P}\\,t), $$\n    with $\\,A_{P1} = 0.5\\,$, $\\,\\tau_{P1} = 0.3\\,$, $\\,A_{P2} = 0.2\\,$, $\\,\\tau_{P2} = 1.5\\,$, $\\,\\omega_{P} = 2.0\\,$.\n  - Heat current correlation:\n    $$ C_{J}(t) = B_{J1}\\,e^{-t/\\theta_{J1}} + B_{J2}\\,e^{-t/\\theta_{J2}}, $$\n    with $\\,B_{J1} = 1.0\\,$, $\\,\\theta_{J1} = 0.2\\,$, $\\,B_{J2} = 0.3\\,$, $\\,\\theta_{J2} = 1.0\\,$.\n  - Nonequilibrium parameters: $\\,a = 1.0\\,$, $\\,\\dot{\\gamma}_{c} = 0.02\\,$, $\\,b = 1.0\\,$, $\\,G_{c} = 0.03\\,$.\n\n- Case $\\,2\\,$:\n  - Temperature: $\\,T = 0.7\\,$.\n  - Shear stress correlation: \n    $$ C_{P}(t) = A_{P1}\\,e^{-t/\\tau_{P1}} + A_{P2}\\,e^{-t/\\tau_{P2}}\\cos(\\omega_{P}\\,t), $$\n    with $\\,A_{P1} = 0.8\\,$, $\\,\\tau_{P1} = 0.5\\,$, $\\,A_{P2} = 0.25\\,$, $\\,\\tau_{P2} = 2.5\\,$, $\\,\\omega_{P} = 1.5\\,$.\n  - Heat current correlation:\n    $$ C_{J}(t) = B_{J1}\\,e^{-t/\\theta_{J1}} + B_{J2}\\,e^{-t/\\theta_{J2}}, $$\n    with $\\,B_{J1} = 0.9\\,$, $\\,\\theta_{J1} = 0.3\\,$, $\\,B_{J2} = 0.4\\,$, $\\,\\theta_{J2} = 1.5\\,$.\n  - Nonequilibrium parameters: $\\,a = 1.0\\,$, $\\,\\dot{\\gamma}_{c} = 0.015\\,$, $\\,b = 1.0\\,$, $\\,G_{c} = 0.02\\,$.\n\n- Case $\\,3\\,$:\n  - Temperature: $\\,T = 1.5\\,$.\n  - Shear stress correlation: \n    $$ C_{P}(t) = A_{P1}\\,e^{-t/\\tau_{P1}} + A_{P2}\\,e^{-t/\\tau_{P2}}\\cos(\\omega_{P}\\,t), $$\n    with $\\,A_{P1} = 0.4\\,$, $\\,\\tau_{P1} = 0.25\\,$, $\\,A_{P2} = 0.15\\,$, $\\,\\tau_{P2} = 1.0\\,$, $\\,\\omega_{P} = 3.0\\,$.\n  - Heat current correlation:\n    $$ C_{J}(t) = B_{J1}\\,e^{-t/\\theta_{J1}} + B_{J2}\\,e^{-t/\\theta_{J2}}, $$\n    with $\\,B_{J1} = 0.7\\,$, $\\,\\theta_{J1} = 0.15\\,$, $\\,B_{J2} = 0.2\\,$, $\\,\\theta_{J2} = 0.8\\,$.\n  - Nonequilibrium parameters: $\\,a = 1.0\\,$, $\\,\\dot{\\gamma}_{c} = 0.04\\,$, $\\,b = 1.0\\,$, $\\,G_{c} = 0.05\\,$.\n\nFor all cases, evaluate the effective coefficients at the following amplitude lists:\n- Shear rates $\\,\\dot{\\gamma}\\,$: $\\,\\{10^{-4}, 10^{-3}, 5\\times 10^{-3}, 10^{-2}, 5\\times 10^{-2}\\}\\,$.\n- Temperature gradients $\\,|\\nabla T|\\,$: $\\,\\{10^{-4}, 5\\times 10^{-4}, 10^{-3}, 5\\times 10^{-3}, 10^{-2}\\}\\,$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case result must be a list of five elements $\\,\\left[\\eta_{0},\\kappa_{0},\\dot{\\gamma}_{\\mathrm{onset}},G_{\\mathrm{onset}},\\mathrm{FDT}\\right]\\,$, where $\\,\\dot{\\gamma}_{\\mathrm{onset}}\\,$ and $\\,G_{\\mathrm{onset}}\\,$ are the identified onset amplitudes and $\\,\\mathrm{FDT}\\,$ is a boolean as defined above. For example, the overall printed structure should look like $\\,\\big[\\,[\\cdots], [\\cdots], [\\cdots]\\,\\big]\\,$.\n\nAll outputs must be expressed in Lennard–Jones reduced units (dimensionless) and the program must be self-contained, requiring no external input.", "solution": "The problem requires the calculation of transport coefficients for a Lennard-Jones fluid from model time autocorrelation functions, both in the linear response regime and for weakly nonlinear forcings. The solution is structured around the principles of linear response theory, specifically the Green-Kubo relations, and extends to a phenomenological model for nonlinear behavior. The tasks involve numerical integration, algebraic manipulation, and programmatic logic to test specific conditions.\n\nThe foundation of the solution lies in the fluctuation-dissipation theorem, which connects the response of a system to an external perturbation with the statistical fluctuations of the system in thermal equilibrium. For transport phenomena, this connection is expressed by the Green-Kubo relations. In the specified Lennard-Jones reduced units where the Boltzmann constant $k_{\\mathrm{B}}=1$, the shear viscosity $\\eta_{0}$ and thermal conductivity $\\kappa_{0}$ are given by the time integrals of the equilibrium autocorrelation functions of the corresponding microscopic fluxes. The pressure tensor component $P_{xy}$ is the flux associated with shear stress, and the heat current $J_Q$ is the flux for thermal transport. The per-volume correlation functions are denoted $C_{P}(t) = \\langle P_{xy}(0) P_{xy}(t)\\rangle/V$ and $C_{J}(t) = \\langle J_Q(0) J_Q(t)\\rangle/V$. The Green-Kubo relations are:\n$$ \\eta_{0} = \\frac{1}{T}\\int_{0}^{\\infty} C_{P}(t)\\,dt $$\n$$ \\kappa_{0} = \\frac{1}{T^{2}}\\int_{0}^{\\infty} C_{J}(t)\\,dt $$\nwhere $T$ is the equilibrium temperature of the fluid. The integrals are over all time, but for practical computation, we integrate over a finite interval $[0, t_{\\max}]$ chosen such that the correlation functions have decayed to negligible values. The problem specifies $t_{\\max}$ to be $10$ times the longest decay time constant among all exponential terms in $C_P(t)$ and $C_J(t)$ for each case. This ensures the truncation error is small. For the numerical integration, a composite Simpson's rule is employed over a uniform time grid with step size $\\Delta t = 10^{-3}$. The number of intervals $N = t_{\\max}/\\Delta t$ must be an even integer for this rule, which is equivalent to an odd number of grid points, $N+1$. This condition is met by the specified parameters for all test cases.\n\nFirst, for each test case, we define the model functions for $C_P(t)$ and $C_J(t)$ based on the provided parameters. For example, in Case $1$:\n$$ C_{P}(t) = 0.5\\,e^{-t/0.3} + 0.2\\,e^{-t/1.5}\\cos(2.0\\,t) $$\n$$ C_{J}(t) = 1.0\\,e^{-t/0.2} + 0.3\\,e^{-t/1.0} $$\nNext, we determine $t_{\\max}$. For Case $1$, the decay time constants are $\\tau_{P1}=0.3$, $\\tau_{P2}=1.5$, $\\theta_{J1}=0.2$, and $\\theta_{J2}=1.0$. The maximum is $1.5$, so $t_{\\max} = 10 \\times 1.5 = 15.0$. A time array $t$ is generated from $0$ to $t_{\\max}$ with spacing $\\Delta t=10^{-3}$. We evaluate $C_P(t)$ and $C_J(t)$ on this grid. The integrals $\\int_0^{t_{\\max}} C_P(t) dt$ and $\\int_0^{t_{\\max}} C_J(t) dt$ are then computed using the composite Simpson's rule. Finally, $\\eta_0$ and $\\kappa_0$ are calculated using the Green-Kubo formulas with the given temperature $T$.\n\nSecond, we analyze the nonlinear response. The effective transport coefficients, $\\eta_{\\mathrm{eff}}(\\dot{\\gamma})$ and $\\kappa_{\\mathrm{eff}}(|\\nabla T|)$, are modeled by a weakly nonlinear expansion:\n$$ \\eta_{\\mathrm{eff}}(\\dot{\\gamma}) = \\eta_{0}\\left[1 - a\\left(\\frac{\\dot{\\gamma}}{\\dot{\\gamma}_{c}}\\right)^{2}\\right] $$\n$$ \\kappa_{\\mathrm{eff}}(|\\nabla T|) = \\kappa_{0}\\left[1 - b\\left(\\frac{|\\nabla T|}{G_{c}}\\right)^{2}\\right] $$\nThe relative deviation from the linear response value is $|\\eta_{\\mathrm{eff}}/\\eta_0 - 1| = a(\\dot{\\gamma}/\\dot{\\gamma}_c)^2$ for viscosity and $|\\kappa_{\\mathrm{eff}}/\\kappa_0 - 1| = b(|\\nabla T|/G_c)^2$ for thermal conductivity. We iterate through the provided lists of forcing amplitudes ($\\dot{\\gamma}$ and $|\\nabla T|$), which are sorted in increasing order. The onset of nonlinearity, $\\dot{\\gamma}_{\\mathrm{onset}}$ or $G_{\\mathrm{onset}}$, is identified as the first amplitude in the list for which this relative deviation exceeds a threshold of $0.05$. If no amplitude in the list causes the deviation to exceed this threshold, the onset amplitude is defined as $0.0$.\n\nThird, we perform a consistency check. Linear response theory, from which the Green-Kubo relations are derived, is valid in the limit of vanishingly small external forces. The provided nonlinear models should converge to the linear response result as the forcing amplitudes $\\dot{\\gamma}$ and $|\\nabla T|$ approach zero. We verify this consistency by calculating the relative deviations at the smallest available amplitudes in the provided lists: $\\dot{\\gamma}_{\\min} = 10^{-4}$ and $|\\nabla T|_{\\min} = 10^{-4}$. We then check if both deviations, $|\\eta_{\\mathrm{eff}}(\\dot{\\gamma}_{\\min})/\\eta_0 - 1|$ and $|\\kappa_{\\mathrm{eff}}(|\\nabla T|_{\\min})/\\kappa_0 - 1|$, are less than a stricter tolerance of $0.01$. The result of this check is stored as a boolean value.\n\nThis entire procedure is repeated for all three test cases, and the five computed values for each case—$\\eta_0$, $\\kappa_0$, $\\dot{\\gamma}_{\\mathrm{onset}}$, $G_{\\mathrm{onset}}$, and the boolean FDT consistency check—are collected and formatted into the specified output structure.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import simpson\n\ndef solve():\n    \"\"\"\n    Solves the thermodynamic fluctuations and response problem for three test cases.\n    \"\"\"\n    \n    # Define parameters for the three test cases\n    test_cases = [\n        {\n            \"case_id\": 1,\n            \"T\": 1.0,\n            \"cp_params\": {\"A_P1\": 0.5, \"tau_P1\": 0.3, \"A_P2\": 0.2, \"tau_P2\": 1.5, \"omega_P\": 2.0},\n            \"cj_params\": {\"B_J1\": 1.0, \"theta_J1\": 0.2, \"B_J2\": 0.3, \"theta_J2\": 1.0},\n            \"nl_params\": {\"a\": 1.0, \"gammadot_c\": 0.02, \"b\": 1.0, \"G_c\": 0.03},\n        },\n        {\n            \"case_id\": 2,\n            \"T\": 0.7,\n            \"cp_params\": {\"A_P1\": 0.8, \"tau_P1\": 0.5, \"A_P2\": 0.25, \"tau_P2\": 2.5, \"omega_P\": 1.5},\n            \"cj_params\": {\"B_J1\": 0.9, \"theta_J1\": 0.3, \"B_J2\": 0.4, \"theta_J2\": 1.5},\n            \"nl_params\": {\"a\": 1.0, \"gammadot_c\": 0.015, \"b\": 1.0, \"G_c\": 0.02},\n        },\n        {\n            \"case_id\": 3,\n            \"T\": 1.5,\n            \"cp_params\": {\"A_P1\": 0.4, \"tau_P1\": 0.25, \"A_P2\": 0.15, \"tau_P2\": 1.0, \"omega_P\": 3.0},\n            \"cj_params\": {\"B_J1\": 0.7, \"theta_J1\": 0.15, \"B_J2\": 0.2, \"theta_J2\": 0.8},\n            \"nl_params\": {\"a\": 1.0, \"gammadot_c\": 0.04, \"b\": 1.0, \"G_c\": 0.05},\n        },\n    ]\n\n    # Amplitude lists for evaluation\n    gammadot_list = [1e-4, 1e-3, 5e-3, 1e-2, 5e-2]\n    gradT_list = [1e-4, 5e-4, 1e-3, 5e-3, 1e-2]\n    \n    dt = 1e-3\n    \n    all_results = []\n\n    for case in test_cases:\n        # Define correlation functions for the current case\n        def C_P(t, p):\n            return p[\"A_P1\"] * np.exp(-t / p[\"tau_P1\"]) + p[\"A_P2\"] * np.exp(-t / p[\"tau_P2\"]) * np.cos(p[\"omega_P\"] * t)\n\n        def C_J(t, p):\n            return p[\"B_J1\"] * np.exp(-t / p[\"theta_J1\"]) + p[\"B_J2\"] * np.exp(-t / p[\"theta_J2\"])\n\n        # Step 1: Compute linear transport coefficients\n        cp_p = case[\"cp_params\"]\n        cj_p = case[\"cj_params\"]\n        \n        # Determine integration limit t_max\n        max_decay_time = max(cp_p[\"tau_P1\"], cp_p[\"tau_P2\"], cj_p[\"theta_J1\"], cj_p[\"theta_J2\"])\n        t_max = 10.0 * max_decay_time\n        \n        # Create time grid for integration\n        num_points = int(t_max / dt) + 1\n        t_grid = np.linspace(0, t_max, num_points)\n        \n        # Evaluate functions on the grid\n        cp_values = C_P(t_grid, cp_p)\n        cj_values = C_J(t_grid, cj_p)\n        \n        # Integrate using composite Simpson's rule\n        integral_cp = simpson(cp_values, t_grid)\n        integral_cj = simpson(cj_values, t_grid)\n        \n        # Calculate eta_0 and kappa_0\n        T = case[\"T\"]\n        eta_0 = (1.0 / T) * integral_cp\n        kappa_0 = (1.0 / (T**2)) * integral_cj\n\n        # Step 2: Identify onset of nonlinear response\n        nl_p = case[\"nl_params\"]\n        \n        # Onset for shear viscosity\n        gammadot_onset = 0.0\n        for gdot in gammadot_list:\n            dev_eta = nl_p['a'] * (gdot / nl_p['gammadot_c'])**2\n            if dev_eta > 0.05:\n                gammadot_onset = gdot\n                break\n        \n        # Onset for thermal conductivity\n        G_onset = 0.0\n        for gT in gradT_list:\n            dev_kappa = nl_p['b'] * (gT / nl_p['G_c'])**2\n            if dev_kappa > 0.05:\n                G_onset = gT\n                break\n\n        # Step 3: Check fluctuation-dissipation consistency\n        gammadot_min = gammadot_list[0]\n        gradT_min = gradT_list[0]\n        \n        dev_eta_min = nl_p['a'] * (gammadot_min / nl_p['gammadot_c'])**2\n        dev_kappa_min = nl_p['b'] * (gradT_min / nl_p['G_c'])**2\n        \n        fdt_check = (dev_eta_min  0.01) and (dev_kappa_min  0.01)\n\n        # Collate results for the current case\n        case_results = [eta_0, kappa_0, gammadot_onset, G_onset, fdt_check]\n        all_results.append(case_results)\n\n    # Final print statement in the exact required format.\n    # We use str() and replace to match the no-space comma-separated format.\n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "3453814"}]}