{"hands_on_practices": [{"introduction": "Correctness is the bedrock of scientific computing. Before we can trust the results of a fast algorithm, we must prove it gives the right answer. This practice guides you through the essential process of validating a cell list implementation by comparing its output against a simple, brute-force neighbor search, which, while slow, is straightforward to verify. By creating a test suite that probes different scenarios, you will build confidence in your code's correctness under various conditions, such as systems in two or three dimensions, varying particle densities, and configurations designed to stress periodic boundary conditions [@problem_id:3400627].", "problem": "You are asked to write a complete, runnable program that validates the completeness of a neighbor search based on a uniform cell list (spatial hashing) by comparing it to a high-precision brute-force reference. The context is Molecular Dynamics (MD), where pairwise interactions depend on the Euclidean distance between particles. The domain is a periodic hypercube of side length $L$ with Periodic Boundary Conditions (PBC), and the neighbor relation is defined by the Minimum Image Convention (MIC). The program must work for dimension $d \\in \\{2,3\\}$.\n\nFundamental base and definitions:\n- Newtonian particle systems interact pairwise via distances; thus identifying all particle pairs within a cutoff radius $r_c$ is a prerequisite to compute forces consistently, from Newton's laws of motion and the definition of pairwise interactions.\n- The Euclidean norm in $\\mathbb{R}^d$ defines distances. Under PBC, the MIC defines the displacement between two positions $\\mathbf{x}_i$ and $\\mathbf{x}_j$ as $\\mathbf{r}_{ij} = \\mathbf{x}_j - \\mathbf{x}_i - L \\,\\mathrm{round}\\!\\left((\\mathbf{x}_j - \\mathbf{x}_i)/L\\right)$, where division and rounding are applied component-wise.\n- A cell list discretizes the domain into a uniform grid of cells with edge length $h$, hashing each particle to a cell by integer division, and then only inspecting particles in neighboring cells sufficient to guarantee that any two particles within $r_c$ are considered.\n\nYour program must, for each test case, do the following:\n1. Generate the particle positions either uniformly at random in $[0,L)^d$ or by a prescribed construction, using the provided random seed where applicable.\n2. Compute the set $S_{\\mathrm{BF}}$ of all unordered index pairs $\\{i,j\\}$ with $i  j$ such that $\\lVert \\mathbf{r}_{ij} \\rVert \\le r_c$ using a brute-force check with double precision. Use the MIC as defined above, and include a small nonnegative tolerance to handle floating-point comparisons.\n3. Compute the set $S_{\\mathrm{CL}}$ of all unordered index pairs $\\{i,j\\}$ found by a correct cell-list neighbor search that uses a uniform grid with nominal cell edge $h$, Periodic Boundary Conditions, and a search over all offset cells that are required by Euclidean geometry to ensure that any pair with separation at most $r_c$ must be enumerated. The implementation must not assume $h \\ge r_c$ and must remain correct for any $h > 0$.\n4. Return a boolean for the test case indicating whether $S_{\\mathrm{CL}} = S_{\\mathrm{BF}}$.\n\nAssumptions and constraints:\n- Positions are in reduced, dimensionless units; you must report dimensionless results. No physical units are required.\n- The cutoff relation is \"within $r_c$\" interpreted as $\\lVert \\mathbf{r}_{ij} \\rVert \\le r_c$.\n- The box is a $d$-dimensional cube of side length $L$ with PBC along each dimension.\n- All indices are zero-based integers.\n\nTest suite:\nProvide results for the following six test cases. For each, you are given dimension $d$, number of particles $N$, side length $L$, cutoff $r_c$, nominal cell size $h$, a random seed if needed, and the configuration type.\n\n- Case A (happy path, three dimensions, $h = r_c$): $d=3$, $N=256$, $L=10.0$, $r_c=1.1$, $h=1.1$, seed $=1234$, configuration: uniform random in $[0,L)^d$.\n- Case B (non-integer grid, $h  r_c$, stress the neighbor offset radius): $d=3$, $N=1000$, $L=20.0$, $r_c=1.9$, $h=1.71$, seed $=7$, configuration: uniform random in $[0,L)^d$.\n- Case C (two dimensions, $h = r_c$): $d=2$, $N=400$, $L=10.0$, $r_c=2.5$, $h=2.5$, seed $=2023$, configuration: uniform random in $[0,L)^d$.\n- Case D (boundary concentration to stress PBC): $d=3$, $N=200$, $L=6.0$, $r_c=2.9$, $h=2.9$, seed $=99$, configuration: half of the particles uniformly in $[0,w)^d$ and half in $[L-w,L)^d$ with $w=0.3$.\n- Case E (tiny system with analytic expectation under PBC): $d=3$, $N=3$, $L=1.0$, $r_c=0.25$, $h=0.25$, configuration: explicit positions $\\mathbf{x}_0=(0.02,0.02,0.02)$, $\\mathbf{x}_1=(0.21,0.02,0.02)$, $\\mathbf{x}_2=(0.85,0.02,0.02)$.\n- Case F (dense, many neighbors, $h$ smaller than $r_c$): $d=3$, $N=500$, $L=5.0$, $r_c=1.2$, $h=0.6$, seed $=555$, configuration: uniform random in $[0,L)^d$.\n\nOutput specification:\n- For each case, compute a boolean indicating whether the neighbor pairs found by the cell list exactly match the brute-force neighbor pairs.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[true,false,true]\"). Use the Python boolean literals \"True\" or \"False\" without additional whitespace.\n\nDeliverables:\n- A single, complete, runnable program that performs all computations and prints the specified final line. No user input is needed. All computations must be self-contained and reproducible from the parameters above.", "solution": "The problem statement is assessed to be valid. It presents a well-defined task from the field of computational physics, specifically the validation of a cell-list algorithm for neighbor finding in a molecular dynamics simulation. The problem is scientifically grounded, logically consistent, and all parameters are specified, allowing for a unique and verifiable solution. A minor ambiguity regarding the exact method for discretizing the simulation box into cells given a \"nominal\" cell edge length $h$ is resolved by adopting a standard and reasonable implementation choice, which will be detailed below. Similarly, the note on floating-point tolerance is addressed by ensuring bit-wise identical arithmetic in both the reference and test algorithms, which is the most stringent validation method.\n\nThe solution is implemented by performing two independent calculations for each test case and comparing their results. The first is a brute-force ($S_{\\mathrm{BF}}$) calculation that serves as a high-precision reference. The second is the cell-list ($S_{\\mathrm{CL}}$) algorithm, which is the method under test. The validation is successful if and only if $S_{\\mathrm{CL}} = S_{\\mathrm{BF}}$.\n\n**1. Brute-Force Reference Calculation ($S_{\\mathrm{BF}}$)**\nThe set of true neighbor pairs, $S_{\\mathrm{BF}}$, is computed by examining every possible unique pair of particles $\\{i,j\\}$ with particle indices $i  j$. For each pair, the displacement vector $\\Delta\\mathbf{x} = \\mathbf{x}_j - \\mathbf{x}_i$ is calculated. To account for the periodic boundary conditions (PBC), this vector is corrected using the minimum image convention (MIC). The MIC displacement vector $\\mathbf{r}_{ij}$ is given by the formula specified in the problem:\n$$\n\\mathbf{r}_{ij} = \\Delta\\mathbf{x} - L \\cdot \\mathrm{round}(\\Delta\\mathbf{x} / L)\n$$\nwhere $L$ is the side length of the cubic domain and the operations are performed component-wise. The squared Euclidean distance is then $\\lVert \\mathbf{r}_{ij} \\rVert^2$. A pair $\\{i,j\\}$ is added to the set $S_{\\mathrm{BF}}$ if this distance satisfies the cutoff criterion:\n$$\n\\lVert \\mathbf{r}_{ij} \\rVert^2 \\le r_c^2\n$$\nwhere $r_c$ is the cutoff radius. This process is performed for all $\\frac{N(N-1)}{2}$ unique pairs of $N$ particles. The resulting set of pairs, stored as sorted tuples $(i,j)$ with $ij$, constitutes the ground truth.\n\n**2. Cell-List Algorithm ($S_{\\mathrm{CL}}$)**\nThe cell-list algorithm accelerates the neighbor search by spatially sorting particles into a grid.\n\n**2.1. Grid Discretization**\nThe simulation domain, a hypercube of side length $L$, is divided into a uniform grid of smaller cells. Given the nominal cell edge length $h$, the number of cells along each dimension, $m_{\\text{dim}}$, is determined. We make the reasonable assumption that the grid should be as close as possible to the nominal size while fitting the domain perfectly. This is achieved by setting $m_{\\text{dim}} = \\max(1, \\mathrm{round}(L/h))$. The actual cell edge length is then $h_{\\text{actual}} = L / m_{\\text{dim}}$. This ensures the entire domain is covered by a uniform grid.\n\n**2.2. Particle Hashing**\nEach particle is assigned to a cell based on its position $\\mathbf{x} = (x_1, \\dots, x_d)$. The integer index vector of the cell is calculated as:\n$$\n\\mathbf{c} = \\lfloor \\mathbf{x} / h_{\\text{actual}} \\rfloor\n$$\nwhere the floor operation is component-wise. A hash map (dictionary in Python) is used to store lists of particle indices for each cell index tuple $\\mathbf{c}$.\n\n**2.3. Neighbor Search**\nThe core principle is that two particles can only be neighbors if their respective cells are sufficiently close. The maximum possible distance between particles requires us to check not just adjacent cells, but a larger stencil of cells, particularly when $h_{\\text{actual}}  r_c$. The search radius in terms of cells, $s_{\\text{rad}}$, is determined by:\n$$\ns_{\\text{rad}} = \\lceil r_c / h_{\\text{actual}} \\rceil\n$$\nFor each particle $i$, we must check for neighbors in a hypercubic block of $(2s_{\\text{rad}}+1)^d$ cells centered on the home cell of particle $i$.\n\nTo ensure each pair $\\{i,j\\}$ is checked exactly once, we iterate through all particles $i$ from $0$ to $N-1$. For each particle $i$, we identify its home cell and iterate through the $(2s_{\\text{rad}}+1)^d$ cell stencil (including the home cell itself). Periodic boundary conditions are applied to the cell indices using the modulo operator. For each particle $j$ found within this stencil of cells, we enforce the condition $j  i$ before proceeding. This simple condition correctly avoids both self-pairing ($i=j$) and double-counting pairs. For each valid candidate pair $(i,j)$, the MIC distance is computed and checked against $r_c$, identical to the brute-force method. If the criterion is met, the pair $(i,j)$ is added to the set $S_{\\mathrm{CL}}$.\n\n**3. Validation**\nFor each test case, the program computes both sets $S_{\\mathrm{BF}}$ and $S_{\\mathrm{CL}}$. The final result for the test case is the boolean value of the expression $S_{\\mathrm{CL}} == S_{\\mathrm{BF}}$. The implementation for all test cases is designed to be general for any valid dimension $d$, including the specified $d \\in \\{2,3\\}$. The provided test cases correctly probe various aspects of the algorithm, such as behavior when $hr_c$ (Case B, F), two-dimensional systems (Case C), and systems designed to stress the periodic boundary conditions (Case D, E).", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\nimport itertools\nfrom collections import defaultdict\n\ndef run_case(d, N, L, r_c, h, seed, config_type, config_params=None):\n    \"\"\"\n    Runs a single test case, comparing a brute-force neighbor search\n    with a cell-list-based search. Returns True if the results match.\n    \n    Args:\n        d (int): Dimension of the system.\n        N (int): Number of particles.\n        L (float): Side length of the periodic box.\n        r_c (float): Cutoff radius for neighbor search.\n        h (float): Nominal cell edge length.\n        seed (int or None): Random seed for particle generation.\n        config_type (str): Type of particle configuration ('uniform', 'boundary', 'explicit').\n        config_params (dict or None): Additional parameters for configuration.\n        \n    Returns:\n        bool: True if the set of pairs from cell list matches brute force, False otherwise.\n    \"\"\"\n    \n    # 1. Generate Particle Positions\n    if seed is not None:\n        rng = np.random.default_rng(seed)\n    \n    if config_type == \"uniform\":\n        positions = rng.uniform(0.0, L, size=(N, d))\n    elif config_type == \"boundary\":\n        w = config_params['w']\n        N_half = N // 2\n        pos1 = rng.uniform(0.0, w, size=(N_half, d))\n        pos2 = rng.uniform(L - w, L, size=(N - N_half, d))\n        positions = np.vstack((pos1, pos2))\n    elif config_type == \"explicit\":\n        positions = np.array(config_params['positions'], dtype=np.float64)\n    else:\n        raise ValueError(f\"Unknown configuration type: {config_type}\")\n\n    r_c_sq = r_c * r_c\n\n    # 2. Brute-Force Reference Calculation (S_BF)\n    s_bf = set()\n    for i in range(N):\n        for j in range(i + 1, N):\n            dr = positions[j] - positions[i]\n            # Apply Minimum Image Convention (MIC)\n            dr_mic = dr - L * np.round(dr / L)\n            dist_sq = np.sum(dr_mic**2)\n            \n            # The problem mentions a tolerance, but for validation of two computational\n            # methods on the same machine, bit-wise identical comparisons are the most\n            # stringent test. Both methods use the same floating-point arithmetic.\n            if dist_sq = r_c_sq:\n                s_bf.add((i, j))\n\n    # 3. Cell List Algorithm (S_CL)\n    s_cl = set()\n\n    # 3.1. Grid Discretization\n    m_per_dim = max(1, int(round(L / h)))\n    h_actual = L / m_per_dim\n    \n    # 3.2. Particle Hashing\n    cell_list = defaultdict(list)\n    for i in range(N):\n        # Particle coordinates are in [0, L), so floor(pos/h_actual) gives indices in [0, m_per_dim-1].\n        cell_idx = tuple(np.floor(positions[i] / h_actual).astype(int))\n        cell_list[cell_idx].append(i)\n\n    # 3.3. Neighbor Search\n    s_rad = math.ceil(r_c / h_actual)\n    offsets = list(itertools.product(range(-s_rad, s_rad + 1), repeat=d))\n    \n    for i in range(N):\n        pos_i = positions[i]\n        home_cell_idx = np.floor(pos_i / h_actual).astype(int)\n        \n        for offset in offsets:\n            np_offset = np.array(offset)\n            neighbor_cell_idx = tuple((home_cell_idx + np_offset) % m_per_dim)\n            \n            if neighbor_cell_idx in cell_list:\n                for j in cell_list[neighbor_cell_idx]:\n                    # Enforce j  i to check each pair only once and avoid self-pairs.\n                    if j = i:\n                        continue\n                    \n                    pos_j = positions[j]\n                    dr = pos_j - pos_i\n                    dr_mic = dr - L * np.round(dr / L)\n                    dist_sq = np.sum(dr_mic**2)\n                    \n                    if dist_sq = r_c_sq:\n                        s_cl.add((i, j))\n    \n    # 4. Validation: Compare the two sets of pairs\n    return s_bf == s_cl\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite, then prints the results.\n    \"\"\"\n    test_cases = [\n        # Case A: happy path, 3D, h = r_c\n        {'d': 3, 'N': 256, 'L': 10.0, 'r_c': 1.1, 'h': 1.1, 'seed': 1234, 'config_type': 'uniform', 'config_params': None},\n        # Case B: h  r_c, stress neighbor offset radius\n        {'d': 3, 'N': 1000, 'L': 20.0, 'r_c': 1.9, 'h': 1.71, 'seed': 7, 'config_type': 'uniform', 'config_params': None},\n        # Case C: 2D, h = r_c\n        {'d': 2, 'N': 400, 'L': 10.0, 'r_c': 2.5, 'h': 2.5, 'seed': 2023, 'config_type': 'uniform', 'config_params': None},\n        # Case D: boundary concentration to stress PBC\n        {'d': 3, 'N': 200, 'L': 6.0, 'r_c': 2.9, 'h': 2.9, 'seed': 99, 'config_type': 'boundary', 'config_params': {'w': 0.3}},\n        # Case E: tiny system with analytic expectation\n        {'d': 3, 'N': 3, 'L': 1.0, 'r_c': 0.25, 'h': 0.25, 'seed': None, 'config_type': 'explicit', 'config_params': {'positions': [[0.02, 0.02, 0.02], [0.21, 0.02, 0.02], [0.85, 0.02, 0.02]]}},\n        # Case F: dense, many neighbors, h  r_c\n        {'d': 3, 'N': 500, 'L': 5.0, 'r_c': 1.2, 'h': 0.6, 'seed': 555, 'config_type': 'uniform', 'config_params': None},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_case(**case)\n        results.append(str(result))\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3400627"}, {"introduction": "The key motivation for using cell lists is to reduce the computational complexity of neighbor searching from $O(N^2)$ to $O(N)$. This exercise provides a hands-on approach to understanding this performance gain quantitatively. By developing a simple linear cost model and fitting it to empirical runtime data, you will dissect the computational cost into its core components—per-particle binning and per-neighbor pair evaluation—and learn to predict performance [@problem_id:3400658].", "problem": "A Molecular Dynamics (MD) simulation of short-range interactions uses cell lists with spatial hashing to accelerate neighbor search. In each neighbor-list build, two dominant algorithmic phases occur: assigning each of $N$ particles to discrete spatial cells by hashing their positions into bins, and scanning nearby bins to evaluate candidate pairs within a fixed cutoff. Assume a homogeneous number density, a fixed cutoff, and an average number of candidate neighbors per particle denoted by $n$. Under these assumptions, model the total wall-clock runtime $T(N,n)$ of a single neighbor-list construction as the sum of two contributions: one that scales with $N$ due to per-particle binning, and a second that scales with the total number of candidate pairs $N n$ due to per-neighbor pair evaluation. The per-particle binning and per-neighbor evaluation incur unknown positive, constant average costs $c_b$ and $c_p$, respectively.\n\nYou are provided three empirical measurements from a single-threaded implementation on a fixed hardware platform, each reporting $(N, n, T)$ for a neighbor-list build:\n- Run $1$: $N = 1.0 \\times 10^{5}$, $n = 40$, $T = 0.241 \\ \\mathrm{s}$.\n- Run $2$: $N = 2.0 \\times 10^{5}$, $n = 60$, $T = 0.730 \\ \\mathrm{s}$.\n- Run $3$: $N = 4.0 \\times 10^{5}$, $n = 80$, $T = 1.93 \\ \\mathrm{s}$.\n\nStarting from first principles about the algorithmic steps just described and their scaling, first derive a linear-in-$N$ and linear-in-$Nn$ cost model for $T(N,n)$ that does not include an additive constant offset. Next, fit the parameters $c_b$ and $c_p$ by linear least squares using the provided data.\n\nFinally, using your fitted parameters, predict the runtime for a neighbor-list build at $N = 3.0 \\times 10^{5}$ and $n = 50$. Round your predicted runtime to four significant figures and express it in $\\mathrm{s}$.", "solution": "The user wants me to solve a problem related to Molecular Dynamics (MD) simulations.\n\nHere's my thinking process:\n\n1.  **Problem Validation:**\n    *   **Step 1: Extract Givens:**\n        *   The algorithm has two phases: per-particle binning and per-neighbor pair evaluation.\n        *   The total number of particles is $N$.\n        *   The average number of candidate neighbors per particle is $n$.\n        *   The total wall-clock runtime is $T(N,n)$.\n        *   A cost model is proposed: $T(N,n)$ is the sum of a term scaling with $N$ and a term scaling with the total number of candidate pairs, $Nn$. There is no additive constant offset.\n        *   The average cost for per-particle binning is $c_b$ (positive, constant).\n        *   The average cost for per-neighbor evaluation is $c_p$ (positive, constant).\n        *   Three empirical data points $(N, n, T)$ are provided:\n            *   Run $1$: $N_1 = 1.0 \\times 10^{5}$, $n_1 = 40$, $T_1 = 0.241 \\ \\mathrm{s}$.\n            *   Run $2$: $N_2 = 2.0 \\times 10^{5}$, $n_2 = 60$, $T_2 = 0.730 \\ \\mathrm{s}$.\n            *   Run $3$: $N_3 = 4.0 \\times 10^{5}$, $n_3 = 80$, $T_3 = 1.93 \\ \\mathrm{s}$.\n        *   Task 1: Derive the linear cost model for $T(N,n)$.\n        *   Task 2: Fit the parameters $c_b$ and $c_p$ using linear least squares.\n        *   Task 3: Predict the runtime for $N = 3.0 \\times 10^{5}$ and $n = 50$.\n        *   Task 4: Round the final prediction to four significant figures.\n\n    *   **Step 2: Validate Using Extracted Givens:**\n        *   **Scientifically Grounded:** The problem describes a simplified but standard model for the computational cost of neighbor list construction using cell lists in MD. The linear scaling assumptions for particle binning ($O(N)$) and pair evaluation ($O(Nn)$) are physically and algorithmically sound for this method under the stated assumption of homogeneous density.\n        *   **Well-Posed:** The problem provides a clear mathematical model form, sufficient data (3 points for 2 parameters) to perform a least-squares fit, and a specific prediction task. This constitutes a standard, well-posed problem in data fitting and model-based prediction.\n        *   **Objective:** The problem is stated in precise, quantitative terms. There are no subjective or ambiguous statements.\n\n    *   **Step 3: Verdict and Action:** The problem is valid. I will proceed with the solution.\n\n2.  **Solution Derivation:**\n\n    *   **Derive the Cost Model:**\n        *   The cost of binning all $N$ particles is proportional to $N$, with a proportionality constant $c_b$. This contribution is $T_{binning} = c_b N$.\n        *   The cost of evaluating all candidate pairs is proportional to the total number of pairs, which is $Nn$. The proportionality constant is $c_p$. This contribution is $T_{pairs} = c_p (Nn)$.\n        *   The total runtime $T(N,n)$ is the sum of these two contributions, with no constant offset as specified.\n        *   Thus, the model is $T(N,n) = c_b N + c_p Nn$.\n\n    *   **Fit Parameters via Linear Least Squares:**\n        *   The model $T = c_b N + c_p (Nn)$ is linear in the parameters $c_b$ and $c_p$.\n        *   We can construct a system of linear equations of the form $\\mathbf{X}\\mathbf{c} = \\mathbf{y}$, where $\\mathbf{c} = \\begin{pmatrix} c_b \\\\ c_p \\end{pmatrix}$.\n        *   The design matrix $\\mathbf{X}$ and the observation vector $\\mathbf{y}$ are constructed from the given data points:\n            *   Row 1: $T_1 = c_b N_1 + c_p (N_1 n_1) \\implies 0.241 = c_b(10^5) + c_p(10^5 \\cdot 40) = c_b(10^5) + c_p(4 \\times 10^6)$\n            *   Row 2: $T_2 = c_b N_2 + c_p (N_2 n_2) \\implies 0.730 = c_b(2 \\cdot 10^5) + c_p(2 \\cdot 10^5 \\cdot 60) = c_b(2 \\cdot 10^5) + c_p(12 \\times 10^6)$\n            *   Row 3: $T_3 = c_b N_3 + c_p (N_3 n_3) \\implies 1.93 = c_b(4 \\cdot 10^5) + c_p(4 \\cdot 10^5 \\cdot 80) = c_b(4 \\cdot 10^5) + c_p(32 \\times 10^6)$\n        *   So, $\\mathbf{X} = \\begin{pmatrix} 1 \\times 10^5  4 \\times 10^6 \\\\ 2 \\times 10^5  12 \\times 10^6 \\\\ 4 \\times 10^5  32 \\times 10^6 \\end{pmatrix}$ and $\\mathbf{y} = \\begin{pmatrix} 0.241 \\\\ 0.730 \\\\ 1.93 \\end{pmatrix}$.\n        *   The least-squares solution for $\\mathbf{c}$ is given by the normal equations: $\\mathbf{c} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}$.\n        *   To simplify calculations, let's redefine the basis vectors and parameters. Let $x_{1,i} = N_i/10^5$ and $x_{2,i} = (N_i n_i)/10^6$. The model becomes $T_i = c_b (10^5 x_{1,i}) + c_p (10^6 x_{2,i})$. Let $c'_b = 10^5 c_b$ and $c'_p = 10^6 c_p$. The model is now $T_i = c'_b x_{1,i} + c'_p x_{2,i}$, which is simpler to work with.\n        *   The new design matrix $\\mathbf{X}'$ and parameter vector $\\mathbf{c}'$ are:\n            *   $\\mathbf{X}' = \\begin{pmatrix} 1  4 \\\\ 2  12 \\\\ 4  32 \\end{pmatrix}$, $\\mathbf{c}' = \\begin{pmatrix} c'_b \\\\ c'_p \\end{pmatrix}$.\n        *   Solve $\\mathbf{c}' = (\\mathbf{X}'^T \\mathbf{X}')^{-1} \\mathbf{X}'^T \\mathbf{y}$.\n        *   Calculate $\\mathbf{X}'^T \\mathbf{X}'$:\n            *   $\\mathbf{X}'^T \\mathbf{X}' = \\begin{pmatrix} 1  2  4 \\\\ 4  12  32 \\end{pmatrix} \\begin{pmatrix} 1  4 \\\\ 2  12 \\\\ 4  32 \\end{pmatrix} = \\begin{pmatrix} 1+4+16  4+24+128 \\\\ 4+24+128  16+144+1024 \\end{pmatrix} = \\begin{pmatrix} 21  156 \\\\ 156  1184 \\end{pmatrix}$.\n        *   Calculate $\\mathbf{X}'^T \\mathbf{y}$:\n            *   $\\mathbf{X}'^T \\mathbf{y} = \\begin{pmatrix} 1  2  4 \\\\ 4  12  32 \\end{pmatrix} \\begin{pmatrix} 0.241 \\\\ 0.730 \\\\ 1.93 \\end{pmatrix} = \\begin{pmatrix} 1(0.241) + 2(0.730) + 4(1.93) \\\\ 4(0.241) + 12(0.730) + 32(1.93) \\end{pmatrix} = \\begin{pmatrix} 0.241 + 1.46 + 7.72 \\\\ 0.964 + 8.76 + 61.76 \\end{pmatrix} = \\begin{pmatrix} 9.421 \\\\ 71.484 \\end{pmatrix}$.\n        *   Now, we need the inverse of $\\mathbf{X}'^T \\mathbf{X}'$:\n            *   $\\det(\\mathbf{X}'^T \\mathbf{X}') = (21)(1184) - (156)(156) = 24864 - 24336 = 528$.\n            *   $(\\mathbf{X}'^T \\mathbf{X}')^{-1} = \\frac{1}{528} \\begin{pmatrix} 1184  -156 \\\\ -156  21 \\end{pmatrix}$.\n        *   Solve for $\\mathbf{c}'$:\n            *   $\\begin{pmatrix} c'_b \\\\ c'_p \\end{pmatrix} = \\frac{1}{528} \\begin{pmatrix} 1184  -156 \\\\ -156  21 \\end{pmatrix} \\begin{pmatrix} 9.421 \\\\ 71.484 \\end{pmatrix} = \\frac{1}{528} \\begin{pmatrix} (1184)(9.421) - (156)(71.484) \\\\ (-156)(9.421) + (21)(71.484) \\end{pmatrix}$\n            *   $= \\frac{1}{528} \\begin{pmatrix} 11154.464 - 11151.504 \\\\ -1469.676 + 1501.164 \\end{pmatrix} = \\frac{1}{528} \\begin{pmatrix} 2.96 \\\\ 31.488 \\end{pmatrix}$.\n        *   $c'_b = 2.96 / 528 = 37/6600$.\n        *   $c'_p = 31.488 / 528 = 82/1375$.\n\n    *   **Predict Runtime:**\n        *   We need to predict $T$ for $N_{new} = 3.0 \\times 10^5$ and $n_{new} = 50$.\n        *   Using our scaled variables:\n            *   $x_{1,new} = N_{new} / 10^5 = 3$.\n            *   $x_{2,new} = (N_{new} n_{new}) / 10^6 = (3.0 \\times 10^5 \\times 50) / 10^6 = 15 \\times 10^6 / 10^6 = 15$.\n        *   The predicted time $T_{pred}$ is:\n            *   $T_{pred} = c'_b x_{1,new} + c'_p x_{2,new} = (\\frac{37}{6600})(3) + (\\frac{82}{1375})(15)$.\n            *   $T_{pred} = \\frac{111}{6600} + \\frac{1230}{1375}$.\n            *   Simplify the fractions: $T_{pred} = \\frac{37}{2200} + \\frac{246}{275}$.\n            *   The least common multiple of $2200$ and $275$ is $2200$. We find $2200 / 275 = 8$.\n            *   $T_{pred} = \\frac{37}{2200} + \\frac{246 \\times 8}{275 \\times 8} = \\frac{37}{2200} + \\frac{1968}{2200} = \\frac{37 + 1968}{2200} = \\frac{2005}{2200}$.\n        *   Convert to a decimal: $T_{pred} = \\frac{2005}{2200} = \\frac{401}{440} \\approx 0.9113636... \\ \\mathrm{s}$.\n\n    *   **Rounding:**\n        *   The problem requires rounding to four significant figures.\n        *   $0.91136...$ rounded to four significant figures is $0.9114$.\n\nThis completes the solution path. I will now write the final output in the required format.", "answer": "$$\n\\boxed{0.9114}\n$$", "id": "3400658"}, {"introduction": "Real-world molecular simulations often employ non-orthorhombic (triclinic) periodic boxes to model crystalline or sheared systems efficiently. This advanced practice extends the cell list algorithm to these general geometries, introducing transformations between Cartesian and fractional coordinates via a lattice matrix $H$. You will also confront the important issue of numerical stability, learning how the shape of the simulation box, quantified by its condition number $\\kappa_2(H)$, can impact the precision of your calculations [@problem_id:3400609].", "problem": "Consider a periodic Molecular Dynamics domain represented by a lattice matrix $H \\in \\mathbb{R}^{3 \\times 3}$, where the Cartesian position vector $r \\in \\mathbb{R}^{3}$ is related to the fractional coordinates $s \\in \\mathbb{R}^{3}$ by the linear relation $r = H s$. The periodic boundary condition is enforced by identifying positions that differ by an integer combination of lattice vectors, that is, $s$ and $s + k$ represent equivalent points for any integer vector $k \\in \\mathbb{Z}^{3}$. A common requirement in constructing cell lists and spatial hashing is to wrap fractional coordinates back into the canonical unit cell using modulo arithmetic, and then map wrapped fractional coordinates to discrete cell indices.\n\nStarting from the foundational definitions of periodic boundaries and linear coordinate transforms, implement the following:\n\n1. Given $H$ and a set of Cartesian positions $\\{r_i\\}$, compute the fractional coordinates $s_i$ by solving $H s_i = r_i$ using a numerically stable linear solver that does not explicitly form $H^{-1}$.\n2. Wrap each component of $s_i$ into the half-open interval $[0, 1)$ using modulo-$1$ arithmetic to obtain $s_i^{\\mathrm{wrap}}$. Use a wrapping rule that is robust to floating-point roundoff near $0$ and $1$.\n3. Given a vector of per-dimension cell counts $m = (m_x, m_y, m_z) \\in \\mathbb{N}^3$, map each wrapped fractional coordinate $s_i^{\\mathrm{wrap}}$ to integer cell indices $(c_x, c_y, c_z)$ via uniform binning of $[0, 1)$ into $m_d$ bins along dimension $d \\in \\{x, y, z\\}$. Then compute a spatial hash $h_i \\in \\mathbb{N}$ by a collision-free linearization $h_i = c_x \\cdot m_y \\cdot m_z + c_y \\cdot m_z + c_z$.\n4. Quantify numerical stability by computing the spectral condition number $\\kappa_2(H)$ and the amplification factor $A(H, r_0, \\delta)$, where $A(H, r_0, \\delta) = \\frac{\\lVert s(r_0 + \\delta) - s(r_0) \\rVert_2}{\\lVert \\delta \\rVert_2}$ and $s(\\cdot)$ denotes the solution of $H s = r$. Discuss the expected relationship between $A$ and $\\kappa_2(H)$.\n5. Verify that the wrapping operation is consistent with the periodic identification by computing, for each test case, the maximum absolute deviation from integer of $k_i = s_i - s_i^{\\mathrm{wrap}}$ across all positions and dimensions, namely $\\max_{i,d} \\left| k_{i,d} - \\mathrm{round}(k_{i,d}) \\right|$.\n\nPhysical units: Express all entries of $H$ and $r_i$ in nanometers (nm). Angles do not appear in this problem. The program output is unitless because it comprises dimensionless indices, condition numbers, and ratios.\n\nTest suite: Use the following $3$ test cases. For each case, compute the quantities described above.\n\n- Case $1$ (orthorhombic box):\n  - $H = \\mathrm{diag}(3.0, 2.0, 1.5)$ (nm).\n  - Positions $r_1 = (3.1, -0.1, 1.6)$ (nm), $r_2 = (-0.01, 0.99, -1.5)$ (nm), $r_3 = (2.9999999999, 1.9999999999, 1.4999999999)$ (nm).\n  - Cells $m = (4, 5, 6)$.\n  - Perturbation for amplification: $\\delta = (10^{-9}, -2 \\cdot 10^{-9}, 10^{-9})$ (nm), applied to $r_1$.\n\n- Case $2$ (moderately skewed triclinic box):\n  - $H = \\begin{pmatrix} 2.0  0.5  0.2 \\\\ 0.0  2.5  0.3 \\\\ 0.0  0.0  3.0 \\end{pmatrix}$ (nm).\n  - Positions $r_1 = (2.3, 1.2, 3.1)$ (nm), $r_2 = (-0.2, 2.6, -0.1)$ (nm), $r_3 = (4.1, 0.0, 0.0)$ (nm).\n  - Cells $m = (5, 4, 3)$.\n  - Perturbation for amplification: $\\delta = (10^{-9}, -2 \\cdot 10^{-9}, 10^{-9})$ (nm), applied to $r_1$.\n\n- Case $3$ (highly skewed and nearly singular box):\n  - $H = \\begin{pmatrix} 1.0  0.999999  0.0 \\\\ 0.0  10^{-6}  0.0 \\\\ 0.0  0.0  2.0 \\end{pmatrix}$ (nm).\n  - Positions $r_1 = (1.0, 0.0, 0.0)$ (nm), $r_2 = (10^{-6}, 10^{-6}, 0.0)$ (nm), $r_3 = (0.0, 0.0, 0.1)$ (nm).\n  - Cells $m = (10, 10, 2)$.\n  - Perturbation for amplification: $\\delta = (10^{-9}, -2 \\cdot 10^{-9}, 10^{-9})$ (nm), applied to $r_1$.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element corresponds to one test case and is itself a list with four elements:\n- the condition number $\\kappa_2(H)$ as a float,\n- the amplification factor $A(H, r_0, \\delta)$ as a float,\n- the maximum absolute deviation from integer for $k_i = s_i - s_i^{\\mathrm{wrap}}$ as a float,\n- the list of spatial hash integers $[h_1, h_2, \\dots]$ for the provided positions.\n\nFor example, the structure of the output must be $[[\\kappa_2, A, \\mathrm{dev}, [h_1,h_2,h_3]], [\\kappa_2, A, \\mathrm{dev}, [h_1,h_2,h_3]], [\\kappa_2, A, \\mathrm{dev}, [h_1,h_2,h_3]]]$ for the three cases.", "solution": "The problem statement has been validated and is deemed sound. It is a well-posed, scientifically grounded problem in the domain of computational physics and numerical methods, with all necessary data and definitions provided.\n\nThe solution proceeds by implementing the five specified tasks for each test case. The underlying principles and implementation details for each task are outlined below.\n\n**1. Computation of Fractional Coordinates ($s_i$)**\n\nThe relationship between a Cartesian position vector $r$ and its corresponding fractional coordinate vector $s$ is given by the linear system $r = H s$, where $H$ is the $3 \\times 3$ lattice matrix. To find the fractional coordinates for a given set of Cartesian positions $\\{r_i\\}$, we must solve the system of linear equations $H s_i = r_i$ for each $s_i$.\n\nThe problem requires a numerically stable solver that does not explicitly compute the matrix inverse $H^{-1}$. The use of explicit inverses is generally discouraged in numerical linear algebra as it can be less accurate and computationally more expensive than direct solution methods. Standard numerical libraries provide solvers based on matrix decompositions (e.g., LU decomposition with partial pivoting) that satisfy these requirements. We will use `numpy.linalg.solve`, which implements such a stable algorithm. For a set of $N$ position vectors, we can assemble the vectors into a matrix and solve the system efficiently. If the Cartesian coordinates are stored as rows in a matrix $R \\in \\mathbb{R}^{N \\times 3}$, we solve for the fractional coordinates $S \\in \\mathbb{R}^{N \\times 3}$ by solving the system $H S^T = R^T$.\n\n**2. Wrapping Fractional Coordinates ($s_i^{\\mathrm{wrap}}$)**\n\nPeriodic boundary conditions in molecular simulations mean that a particle leaving the simulation box on one side re-enters from the opposite side. This is handled mathematically by identifying fractional coordinates $s$ and $s+k$ for any integer vector $k \\in \\mathbb{Z}^3$. A canonical representation is typically chosen by mapping all fractional coordinates into a unit cell, such as $[0, 1) \\times [0, 1) \\times [0, 1)$.\n\nThis wrapping operation is performed using modulo-$1$ arithmetic on each component of the fractional coordinate vector $s_i$. A numerically robust method to map a value $x$ to the half-open interval $[0, 1)$ is given by the formula $x^{\\mathrm{wrap}} = x - \\lfloor x \\rfloor$. This approach correctly handles positive, negative, and zero-valued coordinates and avoids floating-point issues near integer boundaries. For example, if $s_d = 2.1$, $s_d^{\\mathrm{wrap}} = 2.1 - 2.0 = 0.1$. If $s_d = -0.2$, $s_d^{\\mathrm{wrap}} = -0.2 - (-1.0) = 0.8$. If $s_d = 3.0$, $s_d^{\\mathrm{wrap}} = 3.0 - 3.0 = 0.0$.\n\n**3. Cell Indexing and Spatial Hashing ($c_i$, $h_i$)**\n\nTo accelerate the search for neighboring particles, the simulation domain is often partitioned into a grid of smaller cells. A particle's cell is determined by its position. Given the wrapped fractional coordinates $s_i^{\\mathrm{wrap}} \\in [0, 1)^3$ and a grid of $m = (m_x, m_y, m_z)$ cells, we can map $s_i^{\\mathrm{wrap}}$ to an integer cell index vector $c_i = (c_x, c_y, c_z)$ via uniform binning. The index $c_d$ for dimension $d \\in \\{x, y, z\\}$ is calculated as:\n$$c_d = \\lfloor s_{i,d}^{\\mathrm{wrap}} \\cdot m_d \\rfloor$$\nSince $s_{i,d}^{\\mathrm{wrap}} \\in [0, 1)$, the product $s_{i,d}^{\\mathrm{wrap}} \\cdot m_d$ is in $[0, m_d)$, and the floor function correctly maps it to one of the $m_d$ integer indices $\\{0, 1, \\dots, m_d - 1\\}$.\n\nThe $3$D cell index $c_i$ is then linearized into a single integer hash value $h_i$. The provided formula performs a row-major mapping:\n$$h_i = c_x \\cdot (m_y \\cdot m_z) + c_y \\cdot m_z + c_z$$\nThis mapping is unique and collision-free as long as the cell indices $(c_x, c_y, c_z)$ are within their valid ranges, i.e., $c_d \\in [0, m_d-1]$.\n\n**4. Numerical Stability Analysis ($\\kappa_2(H)$, $A$)**\n\nThe stability of the solution to $H s = r$ with respect to perturbations in $r$ is a critical concern, especially for highly skewed (non-orthorhombic) simulation cells.\n\nThe spectral condition number, $\\kappa_2(H) = \\lVert H \\rVert_2 \\lVert H^{-1} \\rVert_2$, provides a general measure of this sensitivity. A large $\\kappa_2(H)$ indicates that the matrix $H$ is close to singular (ill-conditioned), and small relative errors in the input $r$ can lead to large relative errors in the output $s$. We compute this using `numpy.linalg.cond`.\n\nThe amplification factor, $A(H, r_0, \\delta) = \\frac{\\lVert s(r_0 + \\delta) - s(r_0) \\rVert_2}{\\lVert \\delta \\rVert_2}$, quantifies the amplification for a specific perturbation $\\delta$ applied to a specific position $r_0$. Let $\\Delta r = \\delta$ and $\\Delta s = s(r_0 + \\delta) - s(r_0)$. From the linearity of the system, $H(s_0 + \\Delta s) = r_0 + \\Delta r$, which implies $H \\Delta s = \\Delta r$. Thus, $\\Delta s = H^{-1} \\Delta r$. The amplification factor is then:\n$$A = \\frac{\\lVert H^{-1} \\delta \\rVert_2}{\\lVert \\delta \\rVert_2}$$\nFrom the definition of the induced matrix $2$-norm, $\\lVert H^{-1} \\rVert_2 = \\sup_{\\delta \\neq 0} \\frac{\\lVert H^{-1} \\delta \\rVert_2}{\\lVert \\delta \\rVert_2}$. Therefore, the amplification factor $A$ is bounded by the norm of the inverse matrix: $A \\le \\lVert H^{-1} \\rVert_2$. The maximum possible amplification is achieved when $\\delta$ is aligned with the right singular vector of $H$ corresponding to its smallest singular value.\nThe expected relationship is that a large condition number $\\kappa_2(H)$ implies a large $\\lVert H^{-1} \\rVert_2$ (since $\\lVert H^{-1} \\rVert_2 = \\kappa_2(H) / \\lVert H \\rVert_2$), which in turn implies a high potential for amplification $A$. The test cases, particularly Case 3, are designed to demonstrate this relationship: an ill-conditioned matrix leads to a large amplification factor for a well-chosen perturbation.\n\n**5. Verification of Wrapping Consistency**\n\nThis task verifies that the integer vector $k_i = s_i - s_i^{\\mathrm{wrap}}$ is indeed integer-valued, as it should be from its definition. We define $k_i = s_i - s_i^{\\mathrm{wrap}}$. Substituting the definition of the wrapping operation, $s_i^{\\mathrm{wrap}} = s_i - \\lfloor s_i \\rfloor$, we find that $k_i = s_i - (s_i - \\lfloor s_i \\rfloor) = \\lfloor s_i \\rfloor$. In exact arithmetic, the components of $k_i$ are integers.\n\nIn floating-point arithmetic, the computed value of $\\lfloor s_i \\rfloor$ may have a minute representational error. The quantity $\\max_{i,d} \\left| k_{i,d} - \\mathrm{round}(k_{i,d}) \\right|$ measures the maximum deviation of the computed components of $k_i$ from their nearest integers. For a numerically sound implementation, this value should be on the order of machine epsilon, confirming the integrity of the wrapping procedure.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases, performing coordinate transformation,\n    wrapping, hashing, and numerical stability analysis.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"H\": np.diag([3.0, 2.0, 1.5]),\n            \"r\": np.array([\n                [3.1, -0.1, 1.6],\n                [-0.01, 0.99, -1.5],\n                [2.9999999999, 1.9999999999, 1.4999999999]\n            ]),\n            \"m\": np.array([4, 5, 6]),\n            \"delta\": np.array([1e-9, -2e-9, 1e-9]),\n            \"r0_idx\": 0  # Apply perturbation to r1\n        },\n        {\n            \"H\": np.array([\n                [2.0, 0.5, 0.2],\n                [0.0, 2.5, 0.3],\n                [0.0, 0.0, 3.0]\n            ]),\n            \"r\": np.array([\n                [2.3, 1.2, 3.1],\n                [-0.2, 2.6, -0.1],\n                [4.1, 0.0, 0.0]\n            ]),\n            \"m\": np.array([5, 4, 3]),\n            \"delta\": np.array([1e-9, -2e-9, 1e-9]),\n            \"r0_idx\": 0  # Apply perturbation to r1\n        },\n        {\n            \"H\": np.array([\n                [1.0, 0.999999, 0.0],\n                [0.0, 1e-6, 0.0],\n                [0.0, 0.0, 2.0]\n            ]),\n            \"r\": np.array([\n                [1.0, 0.0, 0.0],\n                [1e-6, 1e-6, 0.0],\n                [0.0, 0.0, 0.1]\n            ]),\n            \"m\": np.array([10, 10, 2]),\n            \"delta\": np.array([1e-9, -2e-9, 1e-9]),\n            \"r0_idx\": 0  # Apply perturbation to r1\n        }\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        H = case[\"H\"]\n        r_cartesian = case[\"r\"]\n        m = case[\"m\"]\n        delta = case[\"delta\"]\n        r0 = r_cartesian[case[\"r0_idx\"]]\n\n        # Task 1: Compute fractional coordinates s_i\n        # We solve H * s_T = r_T, where T denotes transpose.\n        # r_cartesian is (N, 3), so r_cartesian.T is (3, N).\n        # s_T will be (3, N), so s is (N, 3).\n        s_T = np.linalg.solve(H, r_cartesian.T)\n        s = s_T.T\n\n        # Task 2: Wrap fractional coordinates into [0, 1)\n        s_wrap = s - np.floor(s)\n\n        # Task 3: Map to cell indices and compute spatial hash\n        m_x, m_y, m_z = m\n        # Broadcasting s_wrap (N, 3) with m (3,) automatically works element-wise\n        cell_indices = np.floor(s_wrap * m).astype(np.int64)\n        c_x = cell_indices[:, 0]\n        c_y = cell_indices[:, 1]\n        c_z = cell_indices[:, 2]\n        hashes = (c_x * m_y * m_z + c_y * m_z + c_z).tolist()\n\n        # Task 4: Quantify numerical stability\n        # Condition number\n        kappa_2 = np.linalg.cond(H, 2)\n        \n        # Amplification factor\n        s0 = np.linalg.solve(H, r0)\n        s_pert = np.linalg.solve(H, r0 + delta)\n        delta_s = s_pert - s0\n        \n        norm_delta_s_2 = np.linalg.norm(delta_s, 2)\n        norm_delta_2 = np.linalg.norm(delta, 2)\n        \n        amplification_A = norm_delta_s_2 / norm_delta_2 if norm_delta_2 > 0 else 0.0\n\n        # Task 5: Verify wrapping consistency\n        k = s - s_wrap  # By definition, this is floor(s)\n        # The deviation from the nearest integer should be near machine epsilon\n        deviation = np.max(np.abs(k - np.round(k)))\n\n        # Compile results for this case\n        case_results = [kappa_2, amplification_A, deviation, hashes]\n        all_results.append(case_results)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "3400609"}]}