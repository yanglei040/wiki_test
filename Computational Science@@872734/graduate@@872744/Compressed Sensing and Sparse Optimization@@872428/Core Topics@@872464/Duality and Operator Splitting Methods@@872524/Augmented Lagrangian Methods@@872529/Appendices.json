{"hands_on_practices": [{"introduction": "To solve constrained optimization problems, a common strategy is to convert them into unconstrained ones using penalties. This exercise invites you to compare two such strategies: the straightforward quadratic penalty method and the more sophisticated augmented Lagrangian method. By working from first principles, you will uncover the fundamental reason why the augmented Lagrangian can achieve exact feasibility for a finite penalty parameter, a key advantage that underpins its widespread use [@problem_id:3432451].", "problem": "Let $A \\in \\mathbb{R}^{m \\times n}$ and $b \\in \\mathbb{R}^{m}$. Consider the convex compressed sensing model known as basis pursuit, which seeks to minimize $f(x) = \\|x\\|_{1}$ subject to the equality constraint $A x = b$. Two standard unconstrained surrogates for handling the equality constraint are:\n$$P_{\\rho}(x) = \\|x\\|_{1} + \\frac{\\rho}{2}\\|A x - b\\|_{2}^{2},$$\nand the augmented Lagrangian\n$$L_{\\rho}(x,\\lambda) = \\|x\\|_{1} + \\lambda^{\\top}(A x - b) + \\frac{\\rho}{2}\\|A x - b\\|_{2}^{2},$$\nwhere $\\rho > 0$ and $\\lambda \\in \\mathbb{R}^{m}$ are the penalty parameter and the Lagrange multiplier, respectively. From the fundamental definitions of convex optimization, Lagrangian duality, and augmented Lagrangian methods, analyze the relationship between minimizers of $P_{\\rho}$ and $L_{\\rho}$ for the function $f(x) = \\|x\\|_{1}$. In particular, reason from first principles about how feasibility $A x = b$ can be obtained by choosing an appropriate $\\lambda$ with bounded $\\rho$.\n\nSelect the option that is most accurate and universally valid in the convex setting described above:\n\nA. For any $\\rho > 0$, assuming existence of a primal-dual optimal pair and strong duality (which holds for $f(x) = \\|x\\|_{1}$ with equality constraints and $A x = b$ feasible), there exists $\\lambda^{\\star}$ such that every minimizer of $L_{\\rho}(x,\\lambda^{\\star})$ is primal feasible and primal optimal. In contrast, for $P_{\\rho}(x)$, exact feasibility at a minimizer for finite $\\rho$ is generally not guaranteed unless an unconstrained minimizer of $f$ happens to satisfy $A x = b$.\n\nB. Because $f(x) = \\|x\\|_{1}$ is the $\\ell_{1}$ norm, there is a finite threshold $\\bar{\\rho}$ such that, for all $\\rho \\ge \\bar{\\rho}$, every minimizer of $P_{\\rho}(x)$ is exactly feasible and primal optimal, irrespective of $A$ and $b$.\n\nC. Even with an optimal choice of $\\lambda$, bounded $\\rho$ cannot yield feasibility $A x = b$ at minimizers of $L_{\\rho}(x,\\lambda)$; one must take $\\rho \\to \\infty$ to enforce feasibility.\n\nD. Feasibility of minimizers of $L_{\\rho}(x,\\lambda)$ with bounded $\\rho$ requires that $A$ have full column rank; otherwise minimizers necessarily remain infeasible.\n\nE. For any $\\rho > 0$ and any $\\lambda \\in \\mathbb{R}^{m}$, minimizers of $L_{\\rho}(x,\\lambda)$ are always feasible because the linear term $\\lambda^{\\top}(A x - b)$ enforces the constraint exactly.", "solution": "The problem asks for an analysis of two common optimization formulations used to solve the basis pursuit problem, which is a constrained convex optimization problem. The core task is to compare the ability of the quadratic penalty method and the augmented Lagrangian method to enforce the primal feasibility constraint $A x = b$.\n\nLet the primal problem be denoted by $(P)$:\n$$ (P) \\quad \\min_{x \\in \\mathbb{R}^n} f(x) \\quad \\text{subject to} \\quad A x = b $$\nwhere $f(x) = \\|x\\|_{1}$, $A \\in \\mathbb{R}^{m \\times n}$, and $b \\in \\mathbb{R}^{m}$. This is a convex optimization problem. The problem statement assumes that a primal-dual optimal pair $(x^{\\star}, \\lambda^{\\star})$ exists and that strong duality holds. This is a reasonable assumption; for instance, if the feasible set $\\{x \\in \\mathbb{R}^n \\mid A x = b\\}$ is non-empty, Slater's condition holds, which guarantees strong duality.\n\nThe Karush-Kuhn-Tucker (KKT) conditions for optimality of a pair $(x^{\\star}, \\lambda^{\\star})$ are:\n1.  **Primal feasibility:** $A x^{\\star} = b$.\n2.  **Dual feasibility** (related to the dual problem $\\max_{\\lambda} \\inf_x (\\|x\\|_1 + \\lambda^\\top(Ax-b)) $, which is $\\max_{\\lambda} -b^\\top\\lambda$ s.t. $\\|A^\\top\\lambda\\|_\\infty \\le 1$): $\\|A^\\top \\lambda^\\star\\|_\\infty \\le 1$. While this condition is part of the full KKT system, the crucial part for analyzing the objective function is the stationarity condition.\n3.  **Stationarity:** $0 \\in \\partial_x L(x^{\\star}, \\lambda^{\\star})$, where $L(x,\\lambda) = \\|x\\|_1 + \\lambda^\\top(Ax-b)$ is the standard Lagrangian. This condition is $0 \\in \\partial f(x^{\\star}) + A^{\\top}\\lambda^{\\star}$, or equivalently, $-A^{\\top}\\lambda^{\\star} \\in \\partial \\|x^{\\star}\\|_{1}$.\n\nWith these first principles established, we analyze the two given surrogate functions.\n\n**1. Analysis of the Quadratic Penalty Method**\nThe quadratic penalty formulation seeks to minimize:\n$$ P_{\\rho}(x) = \\|x\\|_{1} + \\frac{\\rho}{2}\\|A x - b\\|_{2}^{2} $$\nLet $x_{\\rho}$ be a minimizer of $P_{\\rho}(x)$ for some penalty parameter $\\rho > 0$. The first-order necessary condition for optimality (from Fermat's rule for convex functions) is $0 \\in \\partial P_{\\rho}(x_{\\rho})$. This gives:\n$$ 0 \\in \\partial \\|x_{\\rho}\\|_{1} + \\rho A^{\\top}(A x_{\\rho} - b) $$\nThis can be rewritten as $- \\rho A^{\\top}(A x_{\\rho} - b) \\in \\partial \\|x_{\\rho}\\|_{1}$.\n\nNow, let us examine if $x_{\\rho}$ can be primal feasible, i.e., $A x_{\\rho} = b$, for a finite $\\rho > 0$. If $A x_{\\rho} = b$, the optimality condition simplifies to $0 \\in \\partial \\|x_{\\rho}\\|_{1}$. The subdifferential of the $\\ell_1$ norm is the set of vectors $v$ with $v_i = \\text{sgn}((x_{\\rho})_i)$ if $(x_{\\rho})_i \\neq 0$ and $v_i \\in [-1, 1]$ if $(x_{\\rho})_i=0$. The condition $0 \\in \\partial \\|x_{\\rho}\\|_{1}$ is satisfied only if $x_{\\rho} = 0$.\nSo, if a minimizer $x_{\\rho}$ were to be feasible, it must be $x_{\\rho}=0$. This would in turn require $A(0) = b$, which implies $b=0$. In this special case, the unconstrained minimizer of $\\|x\\|_1$ (which is $x=0$) is feasible and thus solves the original problem. For any $b \\neq 0$, a minimizer $x_\\rho$ of $P_\\rho(x)$ for a finite $\\rho$ will not satisfy $Ax_\\rho=b$. The minimizer $x_{\\rho}$ represents a compromise between minimizing $\\|x\\|_{1}$ and minimizing the feasibility violation $\\|A x - b\\|_{2}^{2}$. To enforce feasibility, one must increase the weight on the penalty term, which means taking the limit $\\rho \\to \\infty$. Therefore, the quadratic penalty method is generally not an exact penalty method; it does not achieve exact feasibility for a finite penalty parameter.\n\n**2. Analysis of the Augmented Lagrangian Method**\nThe augmented Lagrangian function is:\n$$ L_{\\rho}(x,\\lambda) = \\|x\\|_{1} + \\lambda^{\\top}(A x - b) + \\frac{\\rho}{2}\\|A x - b\\|_{2}^{2} $$\nThe core idea of the method of multipliers is that by choosing the correct Lagrange multiplier $\\lambda = \\lambda^{\\star}$, we can enforce feasibility even for a finite, bounded $\\rho$. Let's prove this.\n\nLet $(x^{\\star}, \\lambda^{\\star})$ be an optimal primal-dual pair. By strong duality, the optimal primal value $p^{\\star} = \\|x^{\\star}\\|_{1}$ is equal to the optimal dual value $d^{\\star} = \\inf_{x} L(x, \\lambda^{\\star})$. This means $\\|x\\|_{1} + (\\lambda^{\\star})^{\\top}(A x - b) \\ge \\|x^{\\star}\\|_{1}$ for all $x \\in \\mathbb{R}^n$.\n\nNow, consider the augmented Lagrangian $L_{\\rho}(x, \\lambda^{\\star})$ for any $\\rho>0$:\n$$ L_{\\rho}(x, \\lambda^{\\star}) = \\left( \\|x\\|_{1} + (\\lambda^{\\star})^{\\top}(A x - b) \\right) + \\frac{\\rho}{2}\\|A x - b\\|_{2}^{2} $$\nUsing the duality inequality, we have:\n$$ L_{\\rho}(x, \\lambda^{\\star}) \\ge \\|x^{\\star}\\|_{1} + \\frac{\\rho}{2}\\|A x - b\\|_{2}^{2} $$\nLet $\\tilde{x}$ be any minimizer of $L_{\\rho}(x, \\lambda^{\\star})$. By definition of a minimizer, $L_{\\rho}(\\tilde{x}, \\lambda^{\\star}) \\le L_{\\rho}(x, \\lambda^{\\star})$ for all $x$. Let's evaluate $L_{\\rho}$ at the primal solution $x^{\\star}$:\n$$ L_{\\rho}(x^{\\star}, \\lambda^{\\star}) = \\|x^{\\star}\\|_{1} + (\\lambda^{\\star})^{\\top}(A x^{\\star} - b) + \\frac{\\rho}{2}\\|A x^{\\star} - b\\|_{2}^{2} $$\nSince $x^{\\star}$ is feasible, $A x^{\\star} - b = 0$. Thus,\n$$ L_{\\rho}(x^{\\star}, \\lambda^{\\star}) = \\|x^{\\star}\\|_{1} = p^{\\star} $$\nBecause $\\tilde{x}$ is a minimizer, it must be that $L_{\\rho}(\\tilde{x}, \\lambda^{\\star}) \\le L_{\\rho}(x^{\\star}, \\lambda^{\\star}) = p^{\\star}$.\nCombining this with our earlier inequality:\n$$ p^{\\star} + \\frac{\\rho}{2}\\|A \\tilde{x} - b\\|_{2}^{2} \\le L_{\\rho}(\\tilde{x}, \\lambda^{\\star}) \\le p^{\\star} $$\nThis chain of inequalities can only hold if $\\frac{\\rho}{2}\\|A \\tilde{x} - b\\|_{2}^{2} \\le 0$. Since $\\rho > 0$ and the squared norm is non-negative, we must have $\\|A \\tilde{x} - b\\|_{2}^{2} = 0$, which implies $A \\tilde{x} = b$. This proves that any minimizer $\\tilde{x}$ of $L_{\\rho}(x, \\lambda^{\\star})$ is primal feasible.\n\nFurthermore, the inequalities must hold as equalities, so $L_{\\rho}(\\tilde{x}, \\lambda^{\\star}) = p^{\\star}$. Since $\\tilde{x}$ is feasible,\n$$ L_{\\rho}(\\tilde{x}, \\lambda^{\\star}) = \\|\\tilde{x}\\|_{1} + (\\lambda^{\\star})^{\\top}(A \\tilde{x} - b) + \\frac{\\rho}{2}\\|A \\tilde{x} - b\\|_{2}^{2} = \\|\\tilde{x}\\|_{1} + 0 + 0 = \\|\\tilde{x}\\|_{1} $$\nTherefore, $\\|\\tilde{x}\\|_{1} = p^{\\star}$. Since $\\tilde{x}$ is feasible and its objective value is the optimal value, $\\tilde{x}$ is a primal optimal solution. This holds for any $\\rho > 0$.\n\nNow we evaluate the given options.\n\n**A. For any $\\rho > 0$, assuming existence of a primal-dual optimal pair and strong duality (which holds for $f(x) = \\|x\\|_{1}$ with equality constraints and $A x = b$ feasible), there exists $\\lambda^{\\star}$ such that every minimizer of $L_{\\rho}(x,\\lambda^{\\star})$ is primal feasible and primal optimal. In contrast, for $P_{\\rho}(x)$, exact feasibility at a minimizer for finite $\\rho$ is generally not guaranteed unless an unconstrained minimizer of $f$ happens to satisfy $A x = b$.**\nOur derivation for the augmented Lagrangian shows that if one chooses the optimal Lagrange multiplier $\\lambda^{\\star}$, any minimizer of $L_{\\rho}(x, \\lambda^{\\star})$ is indeed primal feasible and optimal for any $\\rho > 0$. Our analysis of the quadratic penalty method showed that its minimizers are generally not feasible for finite $\\rho$, with the exception of the case where the unconstrained minimizer of $\\|x\\|_1$ (which is $x=0$) is feasible (i.e. $b=0$). This option provides a perfectly accurate summary of the theory.\nVerdict: **Correct**.\n\n**B. Because $f(x) = \\|x\\|_{1}$ is the $\\ell_{1}$ norm, there is a finite threshold $\\bar{\\rho}$ such that, for all $\\rho \\ge \\bar{\\rho}$, every minimizer of $P_{\\rho}(x)$ is exactly feasible and primal optimal, irrespective of $A$ and $b$.**\nThis statement claims that the quadratic penalty function is an exact penalty function for this problem. As demonstrated in our analysis of $P_{\\rho}(x)$, this is false. For $b \\neq 0$, a minimizer of $P_{\\rho}(x)$ for any finite $\\rho > 0$ cannot be feasible. The claim that this property holds \"irrespective of $A$ and $b$\" is particularly strong and incorrect. Exact penalty results typically require non-differentiable penalty functions (like an $\\ell_1$ penalty on the residuals, $\\|Ax-b\\|_1$) rather than the squared $\\ell_2$ penalty.\nVerdict: **Incorrect**.\n\n**C. Even with an optimal choice of $\\lambda$, bounded $\\rho$ cannot yield feasibility $A x = b$ at minimizers of $L_{\\rho}(x,\\lambda)$; one must take $\\rho \\to \\infty$ to enforce feasibility.**\nThis is the opposite of the main theoretical advantage of the augmented Lagrangian method. As proven above, an optimal choice $\\lambda = \\lambda^{\\star}$ guarantees feasibility of the minimizer for any $\\rho > 0$. The statement describes the behavior of the quadratic penalty method, not the augmented Lagrangian method.\nVerdict: **Incorrect**.\n\n**D. Feasibility of minimizers of $L_{\\rho}(x,\\lambda)$ with bounded $\\rho$ requires that $A$ have full column rank; otherwise minimizers necessarily remain infeasible.**\nOur derivation of the property of $L_{\\rho}(x, \\lambda^{\\star})$ did not rely on any assumptions about the matrix $A$, such as its rank. The result is general and holds for any $A \\in \\mathbb{R}^{m \\times n}$ provided strong duality holds. In the context of compressed sensing, one typically has an underdetermined system where $n > m$, so $A$ cannot have full column rank. The theory still applies.\nVerdict: **Incorrect**.\n\n**E. For any $\\rho > 0$ and any $\\lambda \\in \\mathbb{R}^{m}$, minimizers of $L_{\\rho}(x,\\lambda)$ are always feasible because the linear term $\\lambda^{\\top}(A x - b)$ enforces the constraint exactly.**\nThis is a gross overstatement. The feasibility property was shown to hold for the specific, optimal choice $\\lambda = \\lambda^{\\star}$. For an arbitrary $\\lambda \\neq \\lambda^{\\star}$, the minimizer of $L_{\\rho}(x, \\lambda)$ will generally be infeasible. Iterative augmented Lagrangian methods work by generating a sequence of multipliers $\\lambda_k$ that converges to $\\lambda^{\\star}$; the corresponding sequence of minimizers $x_k$ only converges to a feasible point in the limit. The linear term by itself does not enforce the constraint.\nVerdict: **Incorrect**.", "answer": "$$\\boxed{A}$$", "id": "3432451"}, {"introduction": "In any iterative optimization algorithm, knowing when to stop is critical. This practice moves from theory to application by tasking you with deriving a computable primal-dual gap for the Basis Pursuit Denoising problem. You will learn how to construct a valid dual-feasible point from an algorithm's iterates and use it to obtain a rigorous upper bound on the suboptimality of your current solution [@problem_id:3432463].", "problem": "Consider the constrained Basis Pursuit Denoising (BPDN) problem in compressed sensing: minimize the $\\ell_{1}$-norm subject to a Euclidean-residual constraint, that is, find $x \\in \\mathbb{R}^{n}$ solving\n$$\n\\min_{x \\in \\mathbb{R}^{n}} \\|x\\|_{1} \\quad \\text{subject to} \\quad \\|A x - b\\|_{2} \\leq \\tau,\n$$\nwhere $A \\in \\mathbb{R}^{m \\times n}$ is a sensing matrix, $b \\in \\mathbb{R}^{m}$ is the measurement vector, and $\\tau \\geq 0$ is the residual tolerance. In the Augmented Lagrangian Method (ALM), one iteratively updates primal variables and multipliers that approximate dual variables for the norm-constrained problem. Starting from the fundamental definitions of Lagrangian duality, Fenchel conjugates, and dual norms, derive a computable primal-dual gap expression that uses an ALM multiplier to form a dual-feasible certificate for the BPDN problem. Then, use this gap to construct a stopping rule that guarantees an absolute error bound on the constrained problem’s optimal value.\n\nWork with the following concrete instance:\n- The sensing matrix is\n$$\nA = \\begin{pmatrix}\n1 & 0 \\\\\n0 & 2\n\\end{pmatrix}.\n$$\n- The measurement vector is\n$$\nb = \\begin{pmatrix}\n1 \\\\\n0\n\\end{pmatrix}.\n$$\n- The residual tolerance is $\\tau = 0.5$.\n- An ALM primal iterate is\n$$\nx^{k} = \\begin{pmatrix}\n0.8 \\\\\n0\n\\end{pmatrix}.\n$$\n- The corresponding ALM multiplier is\n$$\ny^{k} = \\begin{pmatrix}\n-0.2 \\\\\n0\n\\end{pmatrix}.\n$$\n\nYour tasks are:\n1. Derive, from first principles, the dual problem associated with the constrained BPDN formulation above and identify its feasibility constraints on the dual variable.\n2. Show how to obtain a dual-feasible certificate $\\tilde{y}$ from the ALM multiplier $y^{k}$ using only computable operations, and justify why the resulting primal-dual gap $g(x^{k}, \\tilde{y})$ is an upper bound on the absolute error $|\\|x^{k}\\|_{1} - v^{\\star}|$, where $v^{\\star}$ is the optimal value of the constrained problem.\n3. Compute the primal-dual gap $g(x^{k}, \\tilde{y})$ for the provided instance using your derivation.\n\nExpress the final answer as a single real number. No rounding is necessary; provide the exact value.", "solution": "The problem asks for the derivation of the dual problem for Basis Pursuit Denoising (BPDN), the construction of a dual-feasible certificate from an Augmented Lagrangian Method (ALM) multiplier, the justification of the primal-dual gap as an error bound, and the computation of this gap for a specific instance.\n\nThe primal problem, which we will denote (P), is given by:\n$$\nv^{\\star} = \\min_{x \\in \\mathbb{R}^{n}} \\|x\\|_{1} \\quad \\text{subject to} \\quad \\|A x - b\\|_{2} \\leq \\tau\n$$\nwhere $v^{\\star}$ is the optimal value. Let $p(x) = \\|x\\|_{1}$ be the primal objective function.\n\n### Part 1: Derivation of the Dual Problem\n\nWe derive the dual problem using Lagrange duality. The problem can be reformulated by introducing a slack variable $r \\in \\mathbb{R}^m$:\n$$\n\\min_{x, r} \\|x\\|_{1} \\quad \\text{subject to} \\quad A x - b = r, \\quad \\|r\\|_{2} \\leq \\tau\n$$\nTo handle the norm constraint, we express it using an indicator function. Let $K = \\{z \\in \\mathbb{R}^{m} \\mid \\|z\\|_{2} \\leq \\tau\\}$ be the closed ball of radius $\\tau$. The indicator function for this set is $I_K(r)$, which is $0$ if $r \\in K$ and $+\\infty$ otherwise. The problem becomes:\n$$\n\\min_{x, r} \\|x\\|_{1} + I_K(r) \\quad \\text{subject to} \\quad Ax - r = b\n$$\nWe introduce a Lagrange multiplier vector $y \\in \\mathbb{R}^{m}$ for the equality constraint $Ax - r - b = 0$. The Lagrangian is:\n$$\n\\mathcal{L}(x, r, y) = \\|x\\|_{1} + I_K(r) + y^T (b - Ax + r)\n$$\nRearranging terms, we get:\n$$\n\\mathcal{L}(x, r, y) = (\\|x\\|_{1} - y^T A x) + (I_K(r) + y^T r) + y^T b\n$$\nThe Lagrange dual function $d(y)$ is the infimum of the Lagrangian over the primal variables $x$ and $r$:\n$$\nd(y) = \\inf_{x, r} \\mathcal{L}(x, r, y) = y^T b + \\inf_{x} (\\|x\\|_{1} - (A^T y)^T x) + \\inf_{r} (I_K(r) + y^T r)\n$$\nThe two infima can be evaluated separately using the definition of the Fenchel conjugate. The Fenchel conjugate of a function $f(z)$ is $f^{*}(w) = \\sup_z (w^T z - f(z))$. Thus, $\\inf_z (f(z) - w^T z) = -f^{*}(w)$.\n\nFor the first infimum, with $f(x) = \\|x\\|_{1}$:\n$$\n\\inf_{x} (\\|x\\|_{1} - (A^T y)^T x) = -(\\|\\cdot\\|_{1})^{*}(A^T y)\n$$\nThe conjugate of the $\\ell_1$-norm is the indicator function of the unit ball in the dual norm, which is the $\\ell_{\\infty}$-norm. Specifically, $(\\|\\cdot\\|_{1})^{*}(z) = 0$ if $\\|z\\|_{\\infty} \\leq 1$, and $+\\infty$ otherwise. For the infimum to be finite, we require $\\|A^T y\\|_{\\infty} \\leq 1$, in which case the infimum is $0$.\n\nFor the second infimum, with $f(r) = I_K(r)$:\n$$\n\\inf_{r} (I_K(r) + y^T r) = \\inf_{r} (I_K(r) - (-y)^T r) = -I_K^{*}(-y)\n$$\nThe conjugate of the indicator function of a set $K$ is the support function of that set, $\\sigma_K(z) = \\sup_{r \\in K} z^T r$. So, $I_K^{*}(z) = \\sigma_K(z)$.\nFor the set $K = \\{r \\mid \\|r\\|_{2} \\leq \\tau\\}$, the support function is $\\sigma_K(z) = \\tau \\|z\\|_{2}$.\nTherefore, the second infimum is $-\\sigma_K(-y) = -\\tau \\|-y\\|_{2} = -\\tau \\|y\\|_{2}$. This value is always finite.\n\nCombining these results, the dual function $d(y)$ is:\n$$\nd(y) = \\begin{cases} y^T b - \\tau \\|y\\|_{2} & \\text{if } \\|A^T y\\|_{\\infty} \\leq 1 \\\\ -\\infty & \\text{otherwise} \\end{cases}\n$$\nThe dual problem (D) is to maximize the dual function:\n$$\n\\max_{y \\in \\mathbb{R}^{m}} d(y) \\quad \\equiv \\quad \\max_{y \\in \\mathbb{R}^{m}} y^T b - \\tau \\|y\\|_{2} \\quad \\text{subject to} \\quad \\|A^T y\\|_{\\infty} \\leq 1\n$$\nLet $v(y) = y^T b - \\tau \\|y\\|_{2}$ be the dual objective. The feasibility constraint on the dual variable $y$ is $\\|A^T y\\|_{\\infty} \\leq 1$.\n\n### Part 2: Dual Certificate and Primal-Dual Gap\n\nGiven a primal iterate $x^{k}$ and an ALM multiplier $y^{k}$, we need to construct a dual-feasible point $\\tilde{y}$ and use it to form an error bound.\n\nThe ALM multiplier $y^{k}$ is an estimate of the true dual optimal variable, but it is not guaranteed to be dual-feasible, i.e., it might not satisfy $\\|A^T y^{k}\\|_{\\infty} \\leq 1$. We can construct a dual-feasible point $\\tilde{y}$ by projecting $y^{k}$ onto the feasible set. A simple way to do this is by scaling:\nLet $c = \\max(1, \\|A^T y^{k}\\|_{\\infty})$. We define the dual-feasible certificate $\\tilde{y}$ as:\n$$\n\\tilde{y} = \\frac{y^{k}}{c} = \\frac{y^{k}}{\\max(1, \\|A^T y^{k}\\|_{\\infty})}\n$$\nThis operation is always computable. To verify that $\\tilde{y}$ is dual-feasible, we check its satisfaction of the constraint:\n$$\n\\|A^T \\tilde{y}\\|_{\\infty} = \\left\\|A^T \\frac{y^{k}}{\\max(1, \\|A^T y^{k}\\|_{\\infty})}\\right\\|_{\\infty} = \\frac{\\|A^T y^{k}\\|_{\\infty}}{\\max(1, \\|A^T y^{k}\\|_{\\infty})}\n$$\nIf $\\|A^T y^{k}\\|_{\\infty} \\leq 1$, then $\\max(1, \\|A^T y^{k}\\|_{\\infty}) = 1$, and $\\|A^T \\tilde{y}\\|_{\\infty} = \\|A^T y^{k}\\|_{\\infty} \\leq 1$.\nIf $\\|A^T y^{k}\\|_{\\infty} > 1$, then $\\max(1, \\|A^T y^{k}\\|_{\\infty}) = \\|A^T y^{k}\\|_{\\infty}$, and $\\|A^T \\tilde{y}\\|_{\\infty} = \\frac{\\|A^T y^{k}\\|_{\\infty}}{\\|A^T y^{k}\\|_{\\infty}} = 1$.\nIn both cases, $\\|A^T \\tilde{y}\\|_{\\infty} \\leq 1$, so $\\tilde{y}$ is dual-feasible.\n\nFor the BPDN problem, Slater's condition holds if there exists a strictly feasible point, i.e., an $x$ such that $\\|Ax - b\\|_{2} < \\tau$. If this holds, strong duality is guaranteed, meaning the optimal primal value $v^{\\star}$ equals the optimal dual value. For any primal-feasible iterate $x^k$ (satisfying $\\|A x^{k} - b\\|_{2} \\leq \\tau$) and any dual-feasible point $\\tilde{y}$ (satisfying $\\|A^T \\tilde{y}\\|_{\\infty} \\leq 1$), weak duality states:\n$$\nv(\\tilde{y}) \\leq v^{\\star} \\leq p(x^{k})\n$$\nThe absolute error of the current iterate's objective value is $|p(x^{k}) - v^{\\star}| = p(x^{k}) - v^{\\star}$ (since $x^{k}$ is feasible, $p(x^k) \\geq v^\\star$). From the weak duality inequality, we have:\n$$\np(x^{k}) - v^{\\star} \\leq p(x^{k}) - v(\\tilde{y})\n$$\nThis difference, $g(x^{k}, \\tilde{y}) = p(x^{k}) - v(\\tilde{y})$, is known as the primal-dual gap. It is a computable upper bound on the suboptimality of the current iterate $x^k$:\n$$\ng(x^{k}, \\tilde{y}) = \\|x^{k}\\|_{1} - ( \\tilde{y}^T b - \\tau \\|\\tilde{y}\\|_{2} ) = \\|x^{k}\\|_{1} - \\tilde{y}^T b + \\tau \\|\\tilde{y}\\|_{2}\n$$\nA stopping rule can be designed based on this gap: the iterative algorithm terminates when $g(x^{k}, \\tilde{y}) \\leq \\epsilon$ for a user-defined tolerance $\\epsilon > 0$, guaranteeing that $\\|x^k\\|_1$ is at most $\\epsilon$ away from the true optimal value $v^\\star$.\n\n### Part 3: Computation for the Given Instance\n\nWe are given the following instance:\n- $A = \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix}$, $b = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$, $\\tau = 0.5$.\n- Primal iterate: $x^{k} = \\begin{pmatrix} 0.8 \\\\ 0 \\end{pmatrix}$.\n- ALM multiplier: $y^{k} = \\begin{pmatrix} -0.2 \\\\ 0 \\end{pmatrix}$.\n\nFirst, we check if $x^k$ is primal-feasible:\n$$\nA x^k - b = \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix} \\begin{pmatrix} 0.8 \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0.8 \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -0.2 \\\\ 0 \\end{pmatrix}\n$$\n$$\n\\|A x^k - b\\|_{2} = \\sqrt{(-0.2)^2 + 0^2} = \\sqrt{0.04} = 0.2\n$$\nSince $0.2 \\leq \\tau = 0.5$, the iterate $x^k$ is primal-feasible.\n\nNext, we construct the dual-feasible certificate $\\tilde{y}$ from $y^k$:\n$$\nA^T = \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix}\n$$\n$$\nA^T y^k = \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix} \\begin{pmatrix} -0.2 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -0.2 \\\\ 0 \\end{pmatrix}\n$$\nThe $\\ell_{\\infty}$-norm is $\\|A^T y^k\\|_{\\infty} = \\max(|-0.2|, |0|) = 0.2$.\nThe scaling factor is $c = \\max(1, \\|A^T y^k\\|_{\\infty}) = \\max(1, 0.2) = 1$.\nTherefore, $\\tilde{y} = \\frac{y^k}{1} = y^k = \\begin{pmatrix} -0.2 \\\\ 0 \\end{pmatrix}$. The multiplier was already dual-feasible.\n\nFinally, we compute the primal-dual gap $g(x^k, \\tilde{y}) = \\|x^k\\|_1 - \\tilde{y}^T b + \\tau \\|\\tilde{y}\\|_2$. We compute each term:\n- Primal objective value:\n$$\np(x^k) = \\|x^k\\|_1 = |0.8| + |0| = 0.8\n$$\n- Term from the dual objective:\n$$\n\\tilde{y}^T b = \\begin{pmatrix} -0.2 & 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = (-0.2)(1) + (0)(0) = -0.2\n$$\n- Norm of the dual certificate:\n$$\n\\|\\tilde{y}\\|_2 = \\left\\| \\begin{pmatrix} -0.2 \\\\ 0 \\end{pmatrix} \\right\\|_2 = \\sqrt{(-0.2)^2 + 0^2} = 0.2\n$$\nSubstituting these values into the gap formula with $\\tau = 0.5$:\n$$\ng(x^k, \\tilde{y}) = 0.8 - (-0.2) + (0.5)(0.2) = 0.8 + 0.2 + 0.1 = 1.1\n$$\nThe primal-dual gap is $1.1$. This value provides an upper bound on the suboptimality of the objective value of $x^k$.", "answer": "$$\\boxed{1.1}$$", "id": "3432463"}, {"introduction": "Standard algorithms often assume ideal conditions, such as perfectly consistent constraints, which may not hold in the presence of noise. This advanced practice explores how the standard augmented Lagrangian method can fail when constraints are inconsistent and introduces a principled modification to ensure robustness. By analyzing a projected multiplier update, you will understand how to prevent divergence and guide the algorithm to a sensible solution in more realistic settings [@problem_id:3432484].", "problem": "Consider the measurement model $A x = b$ within compressed sensing, where $A \\in \\mathbb{R}^{m \\times n}$ and $b \\in \\mathbb{R}^{m}$ are given data. In the presence of noise, $b$ may fail to lie in the range of $A$, i.e., $b \\notin \\mathrm{range}(A)$, which renders the equality constraint inconsistent and can cause divergence of the Lagrange multiplier sequence in classical augmented Lagrangian updates. To study the effect of a principled remedy, consider the proximal subproblem that arises in many sparse optimization schemes and is representative of the core mechanism of augmented Lagrangian methods: minimize the strictly convex quadratic objective subject to the linear measurement constraint,\n$$\n\\min_{x \\in \\mathbb{R}^{n}} \\ \\frac{1}{2}\\|x\\|_{2}^{2} \\quad \\text{subject to} \\quad A x = b,\n$$\nwith $A \\in \\mathbb{R}^{2 \\times 1}$ and $b \\in \\mathbb{R}^{2}$ specified by\n$$\nA = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\qquad b = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix},\n$$\nand penalty parameter $\\rho > 0$. The classical augmented Lagrangian uses the function\n$$\n\\mathcal{L}_{\\rho}(x,\\lambda) = \\frac{1}{2}\\|x\\|_{2}^{2} + \\langle \\lambda, A x - b \\rangle + \\frac{\\rho}{2}\\|A x - b\\|_{2}^{2},\n$$\nand the multiplier update $\\lambda^{k+1} = \\lambda^{k} + \\rho(A x^{k+1} - b)$. Because $b \\notin \\mathrm{range}(A)$, this unmodified update can drive $\\lambda^{k}$ to diverge.\n\nOne robust approach to prevent divergence due to the inconsistent component is to relax the constraint by updating the multiplier only along the measurement subspace via the orthogonal projector $P$ onto $\\mathrm{range}(A)$, defined by $P = A A^{\\dagger}$, where $A^{\\dagger}$ denotes the Moore–Penrose pseudoinverse of $A$. In this modified scheme, the primal update $x^{k+1}$ minimizes $\\mathcal{L}_{\\rho}(x,\\lambda^{k})$, and the multiplier update is\n$$\n\\lambda^{k+1} = \\lambda^{k} + \\rho \\, P\\,(A x^{k+1} - b),\n$$\ninitialized at $\\lambda^{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$.\n\nStarting from the foundational definitions above and without invoking any shortcut formulas, derive the exact scalar recursion that governs the first component of the multiplier $\\lambda_{1}^{k}$ in this projected-update scheme, and compute the limiting value of $\\lambda_{1}^{k}$ as $k \\to \\infty$. Express your final answer as a single real number. No rounding is required. Interpret your derivation to briefly explain why this modification prevents divergence in the present inconsistent setting.", "solution": "The problem asks for the derivation of the scalar recursion for the first component of the Lagrange multiplier, $\\lambda_1^k$, and its limiting value as $k \\to \\infty$. The optimization problem is:\n$$\n\\min_{x \\in \\mathbb{R}} \\ \\frac{1}{2}\\|x\\|_{2}^{2} \\quad \\text{subject to} \\quad A x = b\n$$\nHere, $x$ is a scalar since $A \\in \\mathbb{R}^{2 \\times 1}$. The given data are:\n$$\nA = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\qquad b = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n$$\nThe system $Ax=b$ is inconsistent because $\\mathrm{range}(A)$ consists of vectors of the form $\\begin{pmatrix} \\alpha \\\\ 0 \\end{pmatrix}$ for any scalar $\\alpha$, and $b = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ does not have this form.\n\nThe modified augmented Lagrangian scheme is defined by the iterative updates:\n1. Primal update: $x^{k+1} = \\arg\\min_{x} \\mathcal{L}_{\\rho}(x, \\lambda^{k})$\n2. Dual update: $\\lambda^{k+1} = \\lambda^{k} + \\rho P (A x^{k+1} - b)$\n\nwhere $\\mathcal{L}_{\\rho}(x,\\lambda) = \\frac{1}{2}\\|x\\|_{2}^{2} + \\langle \\lambda, A x - b \\rangle + \\frac{\\rho}{2}\\|A x - b\\|_{2}^{2}$, $P$ is the orthogonal projector onto $\\mathrm{range}(A)$, and the initialization is $\\lambda^0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$.\n\nFirst, we determine the projector matrix $P = AA^{\\dagger}$. For a matrix $A$ with full column rank, the Moore-Penrose pseudoinverse $A^{\\dagger}$ is given by $A^{\\dagger} = (A^T A)^{-1} A^T$.\nWe have $A^T = \\begin{pmatrix} 1 & 0 \\end{pmatrix}$.\n$$\nA^T A = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = 1\n$$\nSo, $(A^T A)^{-1} = 1$.\nThe pseudoinverse is:\n$$\nA^{\\dagger} = 1 \\cdot \\begin{pmatrix} 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\end{pmatrix}\n$$\nNow, we can compute the projector $P$:\n$$\nP = A A^{\\dagger} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}\n$$\nThis matrix projects any vector in $\\mathbb{R}^2$ onto the subspace spanned by $\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$, which is the range of $A$.\n\nNext, we find the primal update $x^{k+1}$ by minimizing the augmented Lagrangian $\\mathcal{L}_{\\rho}(x, \\lambda^k)$ with respect to $x$. Since $x$ is a scalar, $\\|x\\|_2^2 = x^2$.\n$$\n\\mathcal{L}_{\\rho}(x,\\lambda^k) = \\frac{1}{2}x^2 + (\\lambda^k)^T(Ax-b) + \\frac{\\rho}{2}\\|Ax-b\\|_2^2\n$$\nThis is a strictly convex function of $x$. The minimum is found by setting the derivative with respect to $x$ to zero.\n$$\n\\frac{d}{dx} \\mathcal{L}_{\\rho}(x,\\lambda^k) = x + A^T \\lambda^k + \\rho A^T (Ax - b) = 0\n$$\nSolving for $x$ at the $(k+1)$-th step, we get:\n$$\nx^{k+1} + \\rho A^T A x^{k+1} = -A^T \\lambda^k + \\rho A^T b\n$$\n$$\n(1 + \\rho A^T A) x^{k+1} = A^T(\\rho b - \\lambda^k)\n$$\nWe substitute the known values: $A^T A = 1$, $A^T = \\begin{pmatrix} 1 & 0 \\end{pmatrix}$, $b = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$. Let $\\lambda^k = \\begin{pmatrix} \\lambda_1^k \\\\ \\lambda_2^k \\end{pmatrix}$.\n$$\nA^T b = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = 1\n$$\n$$\nA^T \\lambda^k = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} \\lambda_1^k \\\\ \\lambda_2^k \\end{pmatrix} = \\lambda_1^k\n$$\nSubstituting these into the equation for $x^{k+1}$:\n$$\n(1 + \\rho) x^{k+1} = \\rho(1) - \\lambda_1^k\n$$\n$$\nx^{k+1} = \\frac{\\rho - \\lambda_1^k}{1+\\rho}\n$$\n\nNow, we analyze the dual update: $\\lambda^{k+1} = \\lambda^k + \\rho P (A x^{k+1} - b)$.\nFirst, compute the residual term $A x^{k+1} - b$:\n$$\nA x^{k+1} - b = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} x^{k+1} - \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} x^{k+1} - 1 \\\\ -1 \\end{pmatrix}\n$$\nNext, apply the projector $P$:\n$$\nP(A x^{k+1} - b) = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} x^{k+1} - 1 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} x^{k+1} - 1 \\\\ 0 \\end{pmatrix}\n$$\nThe dual update equation is then:\n$$\n\\begin{pmatrix} \\lambda_1^{k+1} \\\\ \\lambda_2^{k+1} \\end{pmatrix} = \\begin{pmatrix} \\lambda_1^k \\\\ \\lambda_2^k \\end{pmatrix} + \\rho \\begin{pmatrix} x^{k+1} - 1 \\\\ 0 \\end{pmatrix}\n$$\nThis vector equation yields two scalar recursions:\n1. $\\lambda_1^{k+1} = \\lambda_1^k + \\rho (x^{k+1} - 1)$\n2. $\\lambda_2^{k+1} = \\lambda_2^k + 0 = \\lambda_2^k$\n\nFrom the second recursion, we see that $\\lambda_2^k$ is constant. With the initial condition $\\lambda^0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$, we have $\\lambda_2^0 = 0$, so $\\lambda_2^k = 0$ for all $k \\ge 0$.\n\nNow we derive the requested scalar recursion for $\\lambda_1^k$. We substitute the expression for $x^{k+1}$ into the first recursion:\n$$\n\\lambda_1^{k+1} = \\lambda_1^k + \\rho \\left( \\frac{\\rho - \\lambda_1^k}{1+\\rho} - 1 \\right)\n$$\nSimplify the term in the parenthesis:\n$$\n\\frac{\\rho - \\lambda_1^k}{1+\\rho} - \\frac{1+\\rho}{1+\\rho} = \\frac{\\rho - \\lambda_1^k - 1 - \\rho}{1+\\rho} = \\frac{-1 - \\lambda_1^k}{1+\\rho}\n$$\nSo the recursion becomes:\n$$\n\\lambda_1^{k+1} = \\lambda_1^k + \\rho \\left( \\frac{-1 - \\lambda_1^k}{1+\\rho} \\right) = \\lambda_1^k - \\frac{\\rho}{1+\\rho} \\lambda_1^k - \\frac{\\rho}{1+\\rho}\n$$\n$$\n\\lambda_1^{k+1} = \\left( 1 - \\frac{\\rho}{1+\\rho} \\right) \\lambda_1^k - \\frac{\\rho}{1+\\rho}\n$$\n$$\n\\lambda_1^{k+1} = \\left( \\frac{1+\\rho-\\rho}{1+\\rho} \\right) \\lambda_1^k - \\frac{\\rho}{1+\\rho}\n$$\nThe exact scalar recursion is:\n$$\n\\lambda_1^{k+1} = \\frac{1}{1+\\rho} \\lambda_1^k - \\frac{\\rho}{1+\\rho}\n$$\nThis is a linear first-order recurrence relation. Since $\\rho > 0$, the coefficient $\\frac{1}{1+\\rho}$ is in the interval $(0, 1)$. Therefore, the sequence $\\{\\lambda_1^k\\}$ converges to a unique fixed point $\\lambda_1^*$. The fixed point satisfies:\n$$\n\\lambda_1^* = \\frac{1}{1+\\rho} \\lambda_1^* - \\frac{\\rho}{1+\\rho}\n$$\n$$\n\\lambda_1^* \\left( 1 - \\frac{1}{1+\\rho} \\right) = - \\frac{\\rho}{1+\\rho}\n$$\n$$\n\\lambda_1^* \\left( \\frac{1+\\rho-1}{1+\\rho} \\right) = - \\frac{\\rho}{1+\\rho}\n$$\n$$\n\\lambda_1^* \\left( \\frac{\\rho}{1+\\rho} \\right) = - \\frac{\\rho}{1+\\rho}\n$$\n$$\n\\lambda_1^* = -1\n$$\nThe limiting value of $\\lambda_1^k$ as $k \\to \\infty$ is $-1$.\n\nThe modification prevents divergence because the projector $P$ filters out the component of the residual $Ax-b$ that lies in the null space of $A^T$, which corresponds to the inconsistent part of the linear system. The standard multiplier update $\\lambda^{k+1} = \\lambda^k + \\rho(Ax^{k+1}-b)$ would yield a divergent sequence for $\\lambda_2^k$. Specifically, the update for the second component would be $\\lambda_2^{k+1} = \\lambda_2^k + \\rho(-1)$. Starting from $\\lambda_2^0 = 0$, this leads to $\\lambda_2^k = -k\\rho$, which diverges to $-\\infty$. By using the projected residual $P(Ax^{k+1}-b)$, the update vector is forced to lie in $\\mathrm{range}(A)$. In this case, the second component of the update vector is always zero, stabilizing the corresponding multiplier component $\\lambda_2^k$ at its initial value of $0$. The method effectively solves the projected (and consistent) problem $\\min \\frac{1}{2}\\|x\\|_2^2$ subject to $Ax=Pb$. The KKT conditions for this consistent problem give $x=1$ and a multiplier component of $-1$, matching our limit.", "answer": "$$\\boxed{-1}$$", "id": "3432484"}]}