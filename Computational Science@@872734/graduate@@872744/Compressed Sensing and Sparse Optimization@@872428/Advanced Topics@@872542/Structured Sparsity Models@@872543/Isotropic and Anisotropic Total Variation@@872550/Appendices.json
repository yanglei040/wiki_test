{"hands_on_practices": [{"introduction": "Understanding an abstract mathematical concept often begins with a concrete calculation. This exercise grounds the definitions of isotropic and anisotropic total variation (TV) in a direct, hands-on computation for a small image patch. By working through the arithmetic, you will develop a tangible intuition for how these two regularizers measure image variation and see precisely how their underlying vector norms, the $\\ell_1$-norm and $\\ell_2$-norm, lead to different results based on the local gradient structure [@problem_id:3491268].", "problem": "Consider a discrete image model on a Cartesian grid with unit spacing. Let the discrete gradient at pixel $(i,j)$ be defined by the forward-difference operator with homogeneous Neumann boundary conditions (i.e., any forward difference that would access an out-of-bounds pixel is set to zero). Specifically, the discrete gradient at $(i,j)$ is the two-vector consisting of the forward horizontal and vertical differences at $(i,j)$. The anisotropic total variation (TV) of a discrete image is the sum, over all pixels, of the $\\ell_{1}$ norm of the discrete gradient vector at each pixel. The isotropic total variation is the sum, over all pixels, of the $\\ell_{2}$ norm of the discrete gradient vector at each pixel.\n\nYou are given the $3\\times 3$ image patch with pixel values\n$$\nU \\;=\\;\n\\begin{pmatrix}\n1 & 2 & 2 \\\\\n1 & 3 & 5 \\\\\n2 & 3 & 6\n\\end{pmatrix}.\n$$\nUsing only the above fundamental definitions and the stated boundary model, do the following:\n- Compute explicitly the anisotropic total variation and the isotropic total variation of $U$.\n- Explain concisely, from first principles of vector norms, why these two values differ numerically for this patch and identify the structural source of the difference at the pixel level.\n\nLet $D$ denote the exact difference between the anisotropic and isotropic total variations,\n$$\nD \\;=\\; \\mathrm{TV}_{\\mathrm{anisotropic}}(U) \\;-\\; \\mathrm{TV}_{\\mathrm{isotropic}}(U).\n$$\nReport $D$ as a single closed-form analytic expression. Do not round your answer.", "solution": "The problem statement is internally consistent, scientifically grounded in the principles of numerical image analysis and vector norms, and provides all necessary information to compute a unique solution. Therefore, the problem is deemed valid. We proceed with the solution.\n\nLet the discrete image be represented by the matrix $U$, where $U_{i,j}$ is the pixel value at row $i$ and column $j$. The grid is a $3 \\times 3$ Cartesian grid, so the indices $(i,j)$ range from $(1,1)$ to $(3,3)$. The given image is:\n$$\nU =\n\\begin{pmatrix}\n1 & 2 & 2 \\\\\n1 & 3 & 5 \\\\\n2 & 3 & 6\n\\end{pmatrix}\n$$\nThe discrete gradient at a pixel $(i,j)$ is a vector $\\nabla U_{i,j} = \\begin{pmatrix} (\\nabla_x U)_{i,j} \\\\ (\\nabla_y U)_{i,j} \\end{pmatrix}$. The components are defined by forward differences:\n$$\n(\\nabla_x U)_{i,j} = U_{i,j+1} - U_{i,j}\n$$\n$$\n(\\nabla_y U)_{i,j} = U_{i+1,j} - U_{i,j}\n$$\nThe homogeneous Neumann boundary conditions imply that any difference that requires an out-of-bounds pixel is set to zero. For a $3 \\times 3$ image, this means $(\\nabla_x U)_{i,3} = 0$ for $i \\in \\{1,2,3\\}$ and $(\\nabla_y U)_{3,j} = 0$ for $j \\in \\{1,2,3\\}$.\n\nFirst, we compute the discrete gradient vector for each of the $9$ pixels:\n- At $(1,1)$: $\\nabla U_{1,1} = \\begin{pmatrix} U_{1,2} - U_{1,1} \\\\ U_{2,1} - U_{1,1} \\end{pmatrix} = \\begin{pmatrix} 2 - 1 \\\\ 1 - 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$\n- At $(1,2)$: $\\nabla U_{1,2} = \\begin{pmatrix} U_{1,3} - U_{1,2} \\\\ U_{2,2} - U_{1,2} \\end{pmatrix} = \\begin{pmatrix} 2 - 2 \\\\ 3 - 2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$\n- At $(1,3)$: $\\nabla U_{1,3} = \\begin{pmatrix} 0 \\\\ U_{2,3} - U_{1,3} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 5 - 2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 3 \\end{pmatrix}$\n- At $(2,1)$: $\\nabla U_{2,1} = \\begin{pmatrix} U_{2,2} - U_{2,1} \\\\ U_{3,1} - U_{2,1} \\end{pmatrix} = \\begin{pmatrix} 3 - 1 \\\\ 2 - 1 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$\n- At $(2,2)$: $\\nabla U_{2,2} = \\begin{pmatrix} U_{2,3} - U_{2,2} \\\\ U_{3,2} - U_{2,2} \\end{pmatrix} = \\begin{pmatrix} 5 - 3 \\\\ 3 - 3 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix}$\n- At $(2,3)$: $\\nabla U_{2,3} = \\begin{pmatrix} 0 \\\\ U_{3,3} - U_{2,3} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 6 - 5 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$\n- At $(3,1)$: $\\nabla U_{3,1} = \\begin{pmatrix} U_{3,2} - U_{3,1} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 3 - 2 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$\n- At $(3,2)$: $\\nabla U_{3,2} = \\begin{pmatrix} U_{3,3} - U_{3,2} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 6 - 3 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 0 \\end{pmatrix}$\n- At $(3,3)$: $\\nabla U_{3,3} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$\n\nNext, we compute the anisotropic total variation, $\\mathrm{TV}_{\\mathrm{anisotropic}}(U)$, which is the sum of the $\\ell_1$ norms of these gradient vectors. For a vector $v = \\begin{pmatrix} v_x \\\\ v_y \\end{pmatrix}$, its $\\ell_1$ norm is $\\|v\\|_1 = |v_x| + |v_y|$.\n$$\n\\mathrm{TV}_{\\mathrm{anisotropic}}(U) = \\sum_{i=1}^{3} \\sum_{j=1}^{3} \\|\\nabla U_{i,j}\\|_1\n$$\n$$\n\\mathrm{TV}_{\\mathrm{anisotropic}}(U) = (|1|+|0|) + (|0|+|1|) + (|0|+|3|) + (|2|+|1|) + (|2|+|0|) + (|0|+|1|) + (|1|+|0|) + (|3|+|0|) + (|0|+|0|)\n$$\n$$\n\\mathrm{TV}_{\\mathrm{anisotropic}}(U) = 1 + 1 + 3 + 3 + 2 + 1 + 1 + 3 + 0 = 15\n$$\n\nThen, we compute the isotropic total variation, $\\mathrm{TV}_{\\mathrm{isotropic}}(U)$, which is the sum of the $\\ell_2$ norms. For a vector $v = \\begin{pmatrix} v_x \\\\ v_y \\end{pmatrix}$, its $\\ell_2$ norm is $\\|v\\|_2 = \\sqrt{v_x^2 + v_y^2}$.\n$$\n\\mathrm{TV}_{\\mathrm{isotropic}}(U) = \\sum_{i=1}^{3} \\sum_{j=1}^{3} \\|\\nabla U_{i,j}\\|_2\n$$\n$$\n\\mathrm{TV}_{\\mathrm{isotropic}}(U) = \\sqrt{1^2+0^2} + \\sqrt{0^2+1^2} + \\sqrt{0^2+3^2} + \\sqrt{2^2+1^2} + \\sqrt{2^2+0^2} + \\sqrt{0^2+1^2} + \\sqrt{1^2+0^2} + \\sqrt{3^2+0^2} + \\sqrt{0^2+0^2}\n$$\n$$\n\\mathrm{TV}_{\\mathrm{isotropic}}(U) = 1 + 1 + 3 + \\sqrt{5} + 2 + 1 + 1 + 3 + 0 = 12 + \\sqrt{5}\n$$\n\nThe two values differ because of the fundamental properties of the $\\ell_1$ and $\\ell_2$ norms. For any vector $v$ in $\\mathbb{R}^n$, the inequality $\\|v\\|_1 \\ge \\|v\\|_2$ holds. In our case, for a $2$-dimensional gradient vector $v = \\begin{pmatrix} v_x \\\\ v_y \\end{pmatrix}$, we have $\\|v\\|_1 = |v_x|+|v_y|$ and $\\|v\\|_2 = \\sqrt{v_x^2+v_y^2}$. Equality, $|v_x|+|v_y| = \\sqrt{v_x^2+v_y^2}$, holds if and only if at least one component, $v_x$ or $v_y$, is zero. This corresponds to a gradient that is purely horizontal or purely vertical.\n\nThe numerical difference between $\\mathrm{TV}_{\\mathrm{anisotropic}}(U)$ and $\\mathrm{TV}_{\\mathrm{isotropic}}(U)$ arises from the sum of the differences $\\|\\nabla U_{i,j}\\|_1 - \\|\\nabla U_{i,j}\\|_2$ over all pixels. This difference is non-zero only at pixels where both components of the gradient vector are non-zero.\nExamining our computed gradients, only the pixel at $(2,1)$ has a gradient vector with two non-zero components: $\\nabla U_{2,1} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$. For all other pixels, the gradient vector has at least one zero component, meaning $\\|\\nabla U_{i,j}\\|_1 = \\|\\nabla U_{i,j}\\|_2$ for all $(i,j) \\neq (2,1)$.\nThe structural source of the difference is therefore located entirely at pixel $(2,1)$, which represents a corner or a point where the image intensity changes in both the horizontal and vertical directions simultaneously.\n\nFinally, we compute the exact difference $D$:\n$$\nD = \\mathrm{TV}_{\\mathrm{anisotropic}}(U) - \\mathrm{TV}_{\\mathrm{isotropic}}(U)\n$$\nThis difference is the sum of the term-by-term differences, which simplifies to the difference at the single contributing pixel:\n$$\nD = (\\|\\nabla U_{2,1}\\|_1 - \\|\\nabla U_{2,1}\\|_2) = (|2|+|1|) - \\sqrt{2^2+1^2} = 3 - \\sqrt{5}\n$$\nAlternatively, using the total computed values:\n$$\nD = 15 - (12 + \\sqrt{5}) = 3 - \\sqrt{5}\n$$\nThe result is consistent.", "answer": "$$\n\\boxed{3 - \\sqrt{5}}\n$$", "id": "3491268"}, {"introduction": "While the previous exercise explored the difference between TV measures at a single pixel, this problem generalizes that concept to the continuum, revealing the fundamental geometric nature of anisotropy. By analyzing a rotated checkerboard pattern, you will derive a closed-form expression showing how the ratio of anisotropic to isotropic TV changes with the orientation of image features. This powerful result, obtained by considering the limit as the grid spacing goes to zero, demonstrates that while continuous isotropic TV is rotationally invariant, its anisotropic counterpart systematically penalizes diagonal edges more than axis-aligned ones [@problem_id:3453907].", "problem": "Consider a bounded square domain $\\Omega = [0,L] \\times [0,L]$ with periodic boundary conditions, where $L > 0$. Let $a > 0$ be such that $L/a \\in \\mathbb{N}$, so that an unrotated checkerboard of square tiles of side length $a$ fits perfectly in $\\Omega$. Define a binary image $u_{\\theta} : \\Omega \\to \\{0,A\\}$ with contrast amplitude $A > 0$ as the characteristic function of a rotated checkerboard: $u_{\\theta}(x,y) = A$ on alternating squares of side $a$ whose boundaries form two orthogonal families of parallel lines, each family rotated by an angle $\\theta \\in [0,\\pi/2]$ with respect to the $x$-axis, and $u_{\\theta}(x,y) = 0$ on the complementary squares. The boundary of the set $\\{(x,y) \\in \\Omega : u_{\\theta}(x,y) = A\\}$ is thus a union of straight line segments at orientations $\\theta$ and $\\theta + \\pi/2$, periodically tiling $\\Omega$.\n\nFor a uniform Cartesian grid of spacing $h = L/N$ with $N \\in \\mathbb{N}$, sample $u_{\\theta}$ at grid nodes $(i h, j h)$ with $i,j \\in \\{0,1,\\dots,N-1\\}$, and define the discrete forward differences with periodic wrap-around. The discrete anisotropic total variation is\n$$\nTV_{\\mathrm{aniso}}^{h}(u_{\\theta}) \\;=\\; \\sum_{i=0}^{N-1}\\sum_{j=0}^{N-1} \\Big( \\big|u_{\\theta}((i+1)h,jh) - u_{\\theta}(ih,jh)\\big| \\;+\\; \\big|u_{\\theta}(ih,(j+1)h) - u_{\\theta}(ih,jh)\\big| \\Big),\n$$\nand the discrete isotropic total variation is\n$$\nTV_{\\mathrm{iso}}^{h}(u_{\\theta}) \\;=\\; \\sum_{i=0}^{N-1}\\sum_{j=0}^{N-1} \\sqrt{ \\big(u_{\\theta}((i+1)h,jh) - u_{\\theta}(ih,jh)\\big)^{2} \\;+\\; \\big(u_{\\theta}(ih,(j+1)h) - u_{\\theta}(ih,jh)\\big)^{2} }.\n$$\n\nUsing only fundamental definitions of total variation and well-tested facts about the convergence of discrete total variation functionals to their continuum counterparts as $h \\to 0$, derive the continuum limits of these functionals for the rotated checkerboard configuration and compute the exact closed-form expression of the limit ratio\n$$\nR(\\theta) \\;=\\; \\lim_{h \\to 0} \\frac{TV_{\\mathrm{aniso}}^{h}(u_{\\theta})}{TV_{\\mathrm{iso}}^{h}(u_{\\theta})}\n$$\nas an analytic function of $\\theta$ for $\\theta \\in [0,\\pi/2]$. Your final answer must be a single closed-form expression for $R(\\theta)$, simplified as much as possible. No numerical rounding is required.", "solution": "### Step 1: Extract Givens\n- Domain: A bounded square $\\Omega = [0,L] \\times [0,L]$ with periodic boundary conditions, where $L > 0$.\n- Checkerboard tile side length: $a > 0$, such that $L/a \\in \\mathbb{N}$.\n- Image function: $u_{\\theta} : \\Omega \\to \\{0,A\\}$, $A > 0$, representing a checkerboard pattern rotated by an angle $\\theta \\in [0,\\pi/2]$. The boundaries of the checkerboard squares are straight line segments with orientations $\\theta$ and $\\theta + \\pi/2$.\n- Grid: A uniform Cartesian grid with spacing $h = L/N$ for $N \\in \\mathbb{N}$.\n- Discrete anisotropic total variation:\n$$\nTV_{\\mathrm{aniso}}^{h}(u_{\\theta}) \\;=\\; \\sum_{i=0}^{N-1}\\sum_{j=0}^{N-1} \\Big( \\big|u_{\\theta}((i+1)h,jh) - u_{\\theta}(ih,jh)\\big| \\;+\\; \\big|u_{\\theta}(ih,(j+1)h) - u_{\\theta}(ih,jh)\\big| \\Big)\n$$\n- Discrete isotropic total variation:\n$$\nTV_{\\mathrm{iso}}^{h}(u_{\\theta}) \\;=\\; \\sum_{i=0}^{N-1}\\sum_{j=0}^{N-1} \\sqrt{ \\big(u_{\\theta}((i+1)h,jh) - u_{\\theta}(ih,jh)\\big)^{2} \\;+\\; \\big(u_{\\theta}(ih,(j+1)h) - u_{\\theta}(ih,jh)\\big)^{2} }\n$$\n- Objective: Compute the exact closed-form expression for the limit ratio\n$$\nR(\\theta) \\;=\\; \\lim_{h \\to 0} \\frac{TV_{\\mathrm{aniso}}^{h}(u_{\\theta})}{TV_{\\mathrm{iso}}^{h}(u_{\\theta})}\n$$\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, and objective. It is a standard problem in the analysis of variational methods for image processing, specifically investigating the anisotropy of different definitions of total variation. The provided definitions for discrete TV functionals are standard finite-difference approximations. The concept of a rotated checkerboard is a common test pattern. The question asks for the continuum limit of the ratio of these functionals, which relies on the well-established theory of $\\Gamma$-convergence, where discrete sums on a refining grid converge to continuous integrals. The problem is self-contained, with all necessary parameters and definitions provided. There are no contradictions, ambiguities, or scientifically unsound premises.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete, reasoned solution will be provided.\n\n### Solution\nThe problem requires the calculation of the limit ratio of two discrete total variation (TV) functionals as the grid spacing $h$ approaches $0$. The core principle to be used is the convergence of these discrete functionals to their continuous counterparts.\n\nFor a function $u \\in L^1(\\Omega)$, the discrete functionals $TV_{\\mathrm{aniso}}^{h}(u)$ and $TV_{\\mathrm{iso}}^{h}(u)$ (after proper scaling by $h$) converge to continuous total variation functionals in the limit $h \\to 0$. The limiting functionals are defined based on the distributional gradient $\\nabla u$.\n\nThe continuous isotropic total variation, commonly denoted as $TV(u)$, corresponds to the $L^2$-norm of the gradient. For a sufficiently smooth function $u$, it is given by $TV_{\\mathrm{iso}}(u) = \\int_{\\Omega} \\|\\nabla u\\|_2 \\,dx\\,dy = \\int_{\\Omega} \\sqrt{(\\frac{\\partial u}{\\partial x})^2 + (\\frac{\\partial u}{\\partial y})^2} \\,dx\\,dy$.\nThe continuous anisotropic total variation corresponds to the $L^1$-norm of the gradient components: $TV_{\\mathrm{aniso}}(u) = \\int_{\\Omega} \\|\\nabla u\\|_1 \\,dx\\,dy = \\int_{\\Omega} (|\\frac{\\partial u}{\\partial x}| + |\\frac{\\partial u}{\\partial y}|) \\,dx\\,dy$.\n\nThe ratio $R(\\theta)$ is the ratio of these continuum functionals evaluated for the function $u_\\theta$:\n$$ R(\\theta) = \\frac{TV_{\\mathrm{aniso}}(u_{\\theta})}{TV_{\\mathrm{iso}}(u_{\\theta})} $$\n\nThe function $u_{\\theta}$ is a piecewise constant function, taking values $0$ and $A$. For such functions, which are of bounded variation (BV), the gradient $\\nabla u_\\theta$ is a measure concentrated on the set of discontinuities, which we denote as $S$. The set $S$ is the union of all boundary segments between the black and white regions of the checkerboard.\nFor a piecewise constant function with jump set $S$, the continuous TV functionals can be expressed using the coarea formula for BV functions:\n$$ TV_{\\mathrm{iso}}(u_{\\theta}) = \\int_S |[u_{\\theta}]| \\,d\\mathcal{H}^1 $$\n$$ TV_{\\mathrm{aniso}}(u_{\\theta}) = \\int_S |[u_{\\theta}]| (|\\nu_x| + |\\nu_y|) \\,d\\mathcal{H}^1 $$\nHere, $[u_{\\theta}]$ is the jump in the function value across the interface $S$, $\\nu = (\\nu_x, \\nu_y)$ is the unit normal vector to the interface, and $\\mathcal{H}^1$ is the $1$-dimensional Hausdorff measure, which corresponds to the arc length of the interface $S$.\n\nFor the given checkerboard function $u_{\\theta}$, the jump is constant along the entire interface $S$: $|[u_{\\theta}]| = |A - 0| = A$.\n\nThe next step is to analyze the geometry of the interface $S$. The interface consists of a periodic grid of line segments. Within the domain $\\Omega = [0,L] \\times [0,L]$, this grid is formed by two orthogonal families of parallel lines. The density of lines for an unrotated grid of spacing $a$ is $1/a$ in the x-direction and $1/a$ in the y-direction, yielding a total line length per unit area of $2/a$. Rotation does not change the total length of the line segments within a large area. Therefore, the total length of the interface $S$ within the domain $\\Omega$ is:\n$$ \\mathcal{L}(S) = \\int_S d\\mathcal{H}^1 = \\frac{2}{a} \\times (\\text{Area of } \\Omega) = \\frac{2L^2}{a} $$\n\nNow, we can calculate the continuum isotropic TV:\n$$ TV_{\\mathrm{iso}}(u_{\\theta}) = \\int_S A \\,d\\mathcal{H}^1 = A \\int_S d\\mathcal{H}^1 = A \\cdot \\mathcal{L}(S) = \\frac{2AL^2}{a} $$\nNotably, this value is independent of the rotation angle $\\theta$, as it only depends on the total length of the interface.\n\nNext, we calculate the continuum anisotropic TV. The interface $S$ is composed of two sets of segments:\n$1$. $S_1$: Segments with orientation $\\theta$. The normal vector to these segments is oriented at $\\theta \\pm \\pi/2$. Let's take $\\nu_1 = (\\cos(\\theta+\\pi/2), \\sin(\\theta+\\pi/2)) = (-\\sin\\theta, \\cos\\theta)$. The magnitudes of its components are $|\\nu_{1,x}| = |\\sin\\theta|$ and $|\\nu_{1,y}| = |\\cos\\theta|$.\n$2$. $S_2$: Segments with orientation $\\theta+\\pi/2$. The normal vector to these segments is oriented at $(\\theta+\\pi/2) \\pm \\pi/2$, i.e., at $\\theta$ or $\\theta+\\pi$. Let's take $\\nu_2 = (\\cos\\theta, \\sin\\theta)$. The magnitudes of its components are $|\\nu_{2,x}| = |\\cos\\theta|$ and $|\\nu_{2,y}| = |\\sin\\theta|$.\n\nSince the checkerboard is made of squares, the total length of segments in family $S_1$ is equal to the total length of segments in family $S_2$.\n$$ \\mathcal{L}(S_1) = \\mathcal{L}(S_2) = \\frac{1}{2}\\mathcal{L}(S) = \\frac{L^2}{a} $$\nThe anisotropic TV can be split into integrals over $S_1$ and $S_2$:\n$$ TV_{\\mathrm{aniso}}(u_{\\theta}) = \\int_{S_1} A (|\\nu_{1,x}| + |\\nu_{1,y}|) \\,d\\mathcal{H}^1 + \\int_{S_2} A (|\\nu_{2,x}| + |\\nu_{2,y}|) \\,d\\mathcal{H}^1 $$\nSince the normal vector components are constant on each family of segments, we can pull the integrands out of the integrals:\n$$ TV_{\\mathrm{aniso}}(u_{\\theta}) = A (|\\sin\\theta| + |\\cos\\theta|) \\int_{S_1} d\\mathcal{H}^1 + A (|\\cos\\theta| + |\\sin\\theta|) \\int_{S_2} d\\mathcal{H}^1 $$\n$$ TV_{\\mathrm{aniso}}(u_{\\theta}) = A (|\\sin\\theta| + |\\cos\\theta|) \\mathcal{L}(S_1) + A (|\\cos\\theta| + |\\sin\\theta|) \\mathcal{L}(S_2) $$\nSubstituting the lengths $\\mathcal{L}(S_1) = \\mathcal{L}(S_2) = L^2/a$:\n$$ TV_{\\mathrm{aniso}}(u_{\\theta}) = A (|\\sin\\theta| + |\\cos\\theta|) \\frac{L^2}{a} + A (|\\cos\\theta| + |\\sin\\theta|) \\frac{L^2}{a} $$\n$$ TV_{\\mathrm{aniso}}(u_{\\theta}) = 2A (|\\sin\\theta| + |\\cos\\theta|) \\frac{L^2}{a} $$\nThe problem specifies that $\\theta \\in [0, \\pi/2]$. In this interval, both $\\sin\\theta \\ge 0$ and $\\cos\\theta \\ge 0$. Thus, the absolute value signs can be removed.\n$$ TV_{\\mathrm{aniso}}(u_{\\theta}) = \\frac{2AL^2}{a} (\\sin\\theta + \\cos\\theta) $$\n\nFinally, we compute the ratio $R(\\theta)$:\n$$ R(\\theta) = \\frac{TV_{\\mathrm{aniso}}(u_{\\theta})}{TV_{\\mathrm{iso}}(u_{\\theta})} = \\frac{\\frac{2AL^2}{a} (\\sin\\theta + \\cos\\theta)}{\\frac{2AL^2}{a}} $$\nAll the constants $A$, $L$, and $a$ cancel out, yielding the final expression:\n$$ R(\\theta) = \\sin\\theta + \\cos\\theta $$\nThis function quantifies the degree of anisotropy of the $TV_{\\mathrm{aniso}}$ functional. It has a minimum value of $1$ at $\\theta=0$ and $\\theta=\\pi/2$ (axis-aligned features) and a maximum value of $\\sqrt{2}$ at $\\theta=\\pi/4$ (diagonal features), reflecting the fact that the anisotropic TV penalizes diagonal edges more heavily than axis-aligned ones.", "answer": "$$\\boxed{\\sin(\\theta) + \\cos(\\theta)}$$", "id": "3453907"}, {"introduction": "Moving from theory to practice, this final exercise demonstrates the crucial role that TV operator analysis plays in designing efficient optimization algorithms for image reconstruction. The convergence of powerful methods like the Primal-Dual Hybrid Gradient (PDHG) algorithm depends critically on step-size parameters, which are bounded by the spectral norm of the underlying linear operator. This problem guides you through the process of calculating the precise spectral norm, $\\|K\\|^2$, for the discrete gradient operator with periodic boundary conditions, a result essential for guaranteeing and optimizing algorithm performance when solving TV-regularized problems [@problem_id:3453908].", "problem": "Consider a two-dimensional image domain discretized on a rectangular grid with $N_{x}$ points in the horizontal direction and $N_{y}$ points in the vertical direction. Let $u \\in \\mathbb{R}^{N_{x} N_{y}}$ denote the vectorized image. Define the forward finite-difference gradient operator with periodic boundary conditions as the linear map $K : \\mathbb{R}^{N_{x} N_{y}} \\to \\mathbb{R}^{2 N_{x} N_{y}}$ given by $K u = \\big(D_{x} u, D_{y} u\\big)$, where $D_{x}$ and $D_{y}$ compute unit-spaced forward differences along the horizontal and vertical directions, respectively, and wrap around at the boundaries. The isotropic total variation is defined as $\\mathrm{TV}_{\\mathrm{iso}}(u) = \\sum_{i} \\sqrt{\\big(D_{x} u\\big)_{i}^{2} + \\big(D_{y} u\\big)_{i}^{2}}$ and the anisotropic total variation is defined as $\\mathrm{TV}_{\\mathrm{aniso}}(u) = \\sum_{i} \\left| \\big(D_{x} u\\big)_{i} \\right| + \\left| \\big(D_{y} u\\big)_{i} \\right|$. Consider applying the Primal-Dual Hybrid Gradient (PDHG) method to a convex optimization model of the form $\\min_{u} f(u) + \\lambda \\,\\mathrm{TV}(u)$, where $f$ is a proper, closed, convex function. A standard step-size condition for PDHG requires primal and dual step sizes $\\tau > 0$ and $\\sigma > 0$ such that $\\tau \\sigma \\|K\\|^{2} < 1$, where $\\|K\\|$ denotes the operator norm induced by the Euclidean norm.\n\nUsing only the fundamental properties of the discrete Fourier transform on periodic grids and the definition of the operator norm as the square root of the largest eigenvalue of $K^{\\ast} K$, derive a closed-form expression for $\\|K\\|$ in terms of $N_{x}$ and $N_{y}$ by diagonalizing $K$ in the Fourier domain. Then, using this expression, determine the maximal admissible value of the product $\\tau \\sigma$ (i.e., the supremal product over all feasible $\\tau$ and $\\sigma$) that satisfies the PDHG step-size condition for both isotropic and anisotropic total variation. Provide your final answer as a single analytical expression depending only on $N_{x}$ and $N_{y}$. Do not approximate; no rounding is required.", "solution": "The problem requires the derivation of the operator norm for a discrete gradient operator and its use in determining a step-size parameter limit for the Primal-Dual Hybrid Gradient (PDHG) algorithm.\n\nFirst, we validate the problem statement.\n\n**Step 1: Extract Givens**\n- Domain: A $2$D rectangular grid with $N_{x} \\times N_{y}$ points.\n- Image vector: $u \\in \\mathbb{R}^{N_{x} N_{y}}$.\n- Gradient operator: $K : \\mathbb{R}^{N_{x} N_{y}} \\to \\mathbb{R}^{2 N_{x} N_{y}}$ defined by $K u = \\big(D_{x} u, D_{y} u\\big)$.\n- Difference operators: $D_{x}$ and $D_{y}$ are unit-spaced forward finite-difference operators with periodic boundary conditions.\n- Isotropic TV: $\\mathrm{TV}_{\\mathrm{iso}}(u) = \\sum_{i} \\sqrt{\\big(D_{x} u\\big)_{i}^{2} + \\big(D_{y} u\\big)_{i}^{2}}$.\n- Anisotropic TV: $\\mathrm{TV}_{\\mathrm{aniso}}(u) = \\sum_{i} \\left| \\big(D_{x} u\\big)_{i} \\right| + \\left| \\big(D_{y} u\\big)_{i} \\right|$.\n- Optimization model: $\\min_{u} f(u) + \\lambda \\,\\mathrm{TV}(u)$, with $f$ being a proper, closed, convex function.\n- PDHG step-size condition: $\\tau > 0$, $\\sigma > 0$ such that $\\tau \\sigma \\|K\\|^{2} < 1$.\n- Definition of operator norm: $\\|K\\|$ is the operator norm induced by the Euclidean norm, and $\\|K\\| = \\sqrt{\\lambda_{\\max}(K^{\\ast} K)}$, where $K^\\ast$ is the adjoint of $K$.\n- Task: Derive a closed-form expression for $\\|K\\|$ by diagonalizing $K^{\\ast} K$ in the Fourier domain. Then, find the maximal admissible value for the product $\\tau \\sigma$ for both TV definitions.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded in the fields of numerical linear algebra, convex optimization, and signal processing. The concepts of total variation, PDHG, operator norms, and the discrete Fourier transform are standard and well-defined. The problem is self-contained, providing all necessary definitions and constraints. The language is precise and objective. The use of the same operator norm based on Euclidean spaces for both isotropic and anisotropic TV contexts is a standard assumption in the basic convergence analysis of the PDHG algorithm. The problem is well-posed and solvable.\n\n**Step 3: Verdict and Action**\nThe problem is deemed valid. A detailed solution follows.\n\nThe core of the problem is to compute the squared operator norm $\\|K\\|^2$. By the definition provided, $\\|K\\|^2 = \\lambda_{\\max}(K^{\\ast} K)$, the largest eigenvalue of the operator $K^{\\ast} K$. The operator $K$ is defined on a periodic grid, which makes it a circulant-type operator. Such operators are diagonalized by the Discrete Fourier Transform (DFT).\n\nLet's represent an image as a $2$D array $u = \\{u_{i,j}\\}$ where $i \\in \\{0, 1, \\dots, N_x-1\\}$ and $j \\in \\{0, 1, \\dots, N_y-1\\}$. The forward difference operators with periodic boundary conditions are given by:\n$$ (D_x u)_{i,j} = u_{i+1, j} - u_{i,j} $$\n$$ (D_y u)_{i,j} = u_{i, j+1} - u_{i,j} $$\nwhere indices are taken modulo $N_x$ and $N_y$ respectively. The operator $K$ maps $u$ to the pair $(D_x u, D_y u)$.\n\nThe squared operator norm $\\|K\\|^2$ is the spectral radius of $K^\\ast K$. We will find the eigenvalues of $K^\\ast K$ by analyzing its action in the Fourier domain. The eigenvectors of any linear shift-invariant operator on a periodic grid are the discrete Fourier modes:\n$$ \\phi_{k,l}(i,j) = \\exp\\left(2\\pi \\mathrm{i} \\left(\\frac{ki}{N_x} + \\frac{lj}{N_y}\\right)\\right) $$\nfor frequency indices $k \\in \\{0, \\dots, N_x-1\\}$ and $l \\in \\{0, \\dots, N_y-1\\}$, where $\\mathrm{i} = \\sqrt{-1}$.\n\nThe action of the difference operators $D_x$ and $D_y$ on these Fourier modes is multiplicative. Let $\\mathcal{F}$ denote the 2D DFT. For any image $u$, we have:\n$$ \\mathcal{F}(D_x u)_{k,l} = \\left(\\exp\\left(\\frac{2\\pi \\mathrm{i} k}{N_x}\\right) - 1\\right) \\mathcal{F}(u)_{k,l} $$\n$$ \\mathcal{F}(D_y u)_{k,l} = \\left(\\exp\\left(\\frac{2\\pi \\mathrm{i} l}{N_y}\\right) - 1\\right) \\mathcal{F}(u)_{k,l} $$\nThe Fourier symbols for $D_x$ and $D_y$ are therefore $\\widehat{D_x}(k) = \\exp(2\\pi \\mathrm{i} k/N_x) - 1$ and $\\widehat{D_y}(l) = \\exp(2\\pi \\mathrm{i} l/N_y) - 1$.\n\nThe operator $K$ can be written as a block matrix $K = \\begin{pmatrix} D_x \\\\ D_y \\end{pmatrix}$. Its adjoint is $K^\\ast = \\begin{pmatrix} D_x^\\ast & D_y^\\ast \\end{pmatrix}$. The operator $K^\\ast K$ is then $K^\\ast K = D_x^\\ast D_x + D_y^\\ast D_y$. In the Fourier domain, the adjoint of an operator corresponds to the conjugate of its symbol. Thus, the symbol for $K^\\ast K$ is:\n$$ \\widehat{K^\\ast K}(k,l) = \\overline{\\widehat{D_x}(k)}\\widehat{D_x}(k) + \\overline{\\widehat{D_y}(l)}\\widehat{D_y}(l) = |\\widehat{D_x}(k)|^2 + |\\widehat{D_y}(l)|^2 $$\nThe eigenvalues of $K^\\ast K$ are given by these symbol values for all $(k,l)$. We compute the squared magnitudes:\n$$ |\\exp(\\mathrm{i}\\theta)-1|^2 = (\\cos\\theta-1)^2 + \\sin^2\\theta = \\cos^2\\theta - 2\\cos\\theta + 1 + \\sin^2\\theta = 2 - 2\\cos\\theta = 4\\sin^2(\\theta/2) $$\nApplying this identity, we get the eigenvalues of $K^\\ast K$:\n$$ \\lambda_{k,l}(K^\\ast K) = \\left|\\exp\\left(\\frac{2\\pi \\mathrm{i} k}{N_x}\\right) - 1\\right|^2 + \\left|\\exp\\left(\\frac{2\\pi \\mathrm{i} l}{N_y}\\right) - 1\\right|^2 = 4\\sin^2\\left(\\frac{\\pi k}{N_x}\\right) + 4\\sin^2\\left(\\frac{\\pi l}{N_y}\\right) $$\nThe squared operator norm $\\|K\\|^2$ is the maximum of these eigenvalues over all valid $k$ and $l$.\n$$ \\|K\\|^2 = \\max_{k,l} \\lambda_{k,l}(K^\\ast K) = \\max_{\\substack{k \\in \\{0, \\dots, N_x-1\\} \\\\ l \\in \\{0, \\dots, N_y-1\\}}} \\left[ 4\\sin^2\\left(\\frac{\\pi k}{N_x}\\right) + 4\\sin^2\\left(\\frac{\\pi l}{N_y}\\right) \\right] $$\nSince the variables $k$ and $l$ are independent, we can maximize the two terms in the sum separately:\n$$ \\|K\\|^2 = 4 \\left( \\max_{k \\in \\{0, \\dots, N_x-1\\}} \\sin^2\\left(\\frac{\\pi k}{N_x}\\right) + \\max_{l \\in \\{0, \\dots, N_y-1\\}} \\sin^2\\left(\\frac{\\pi l}{N_y}\\right) \\right) $$\nFor an integer $N$, the maximum value of $\\sin^2(\\pi k/N)$ for $k \\in \\{0, \\dots, N-1\\}$ is obtained when $k$ is chosen to make the argument $\\pi k/N$ as close as possible to $\\pi/2$. This occurs for $k = \\lfloor N/2 \\rfloor$. Therefore,\n$$ \\max_{k \\in \\{0, \\dots, N-1\\}} \\sin^2\\left(\\frac{\\pi k}{N}\\right) = \\sin^2\\left(\\frac{\\pi \\lfloor N/2 \\rfloor}{N}\\right) $$\nSubstituting this into our expression for $\\|K\\|^2$:\n$$ \\|K\\|^2 = 4 \\left( \\sin^2\\left(\\frac{\\pi \\lfloor N_x/2 \\rfloor}{N_x}\\right) + \\sin^2\\left(\\frac{\\pi \\lfloor N_y/2 \\rfloor}{N_y}\\right) \\right) $$\nThe PDHG step-size condition is $\\tau \\sigma \\|K\\|^2 < 1$, which is equivalent to $\\tau \\sigma < 1/\\|K\\|^2$. The maximal admissible value for the product $\\tau \\sigma$ is the supremum of the allowable range, which is $1/\\|K\\|^2$. This condition depends only on the operator $K$ and the Euclidean norms on its domain and codomain, not on the specific choice of the TV functional (isotropic or anisotropic). Thus, the result is the same for both cases.\n\nThe maximal admissible value for $\\tau \\sigma$ is:\n$$ \\sup\\{\\tau\\sigma\\} = \\frac{1}{\\|K\\|^2} = \\frac{1}{4 \\left( \\sin^2\\left(\\frac{\\pi \\lfloor N_x/2 \\rfloor}{N_x}\\right) + \\sin^2\\left(\\frac{\\pi \\lfloor N_y/2 \\rfloor}{N_y}\\right) \\right)} $$", "answer": "$$ \\boxed{\\frac{1}{4 \\left( \\sin^2\\left(\\frac{\\pi \\lfloor N_x/2 \\rfloor}{N_x}\\right) + \\sin^2\\left(\\frac{\\pi \\lfloor N_y/2 \\rfloor}{N_y}\\right) \\right)}} $$", "id": "3453908"}]}