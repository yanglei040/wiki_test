{"hands_on_practices": [{"introduction": "伪随机数生成器 (PRNG) 是确定性的机器，其内部状态是有限的。这个看似简单的特性带来了一个深刻的限制：如果一个问题的可能结果总数（例如一副牌的所有排列组合 $n!$）超过了生成器的内部状态数 $m$，那么该生成器从根本上就无法产生所有可能的结果。本练习将通过一个关于洗牌的经典问题，引导你探索和验证这个原理，这是一个在为科学计算选择合适工具时必须考虑的关键一课。[@problem_id:2433326]", "problem": "您将研究一个简单的伪随机数生成器在何种情况下原则上能生成由 Fisher–Yates 洗牌算法产生的所有排列。设伪随机数生成器（PRNG）为一个具有内部状态的确定性映射，其输出一个旨在模拟独立样本的整数序列。考虑线性同余生成器（LCG），其由以下递推关系定义：\n$$\nX_{k+1} \\equiv (a X_k + c) \\bmod m,\n$$\n其中 $a$、$c$ 和 $m$ 是整数，满足 $m \\ge 2$，且 $X_k \\in \\{0,1,\\dots,m-1\\}$。使用 Fisher–Yates 算法对一个长度为 $n$ 的列表进行洗牌，需要对从 $n-1$ 到 $1$ 的每个 $i$，生成一个均匀分布的整数 $J_i \\in \\{0,1,\\dots,i\\}$，然后交换位置 $i$ 和 $J_i$ 上的元素。\n\n基本原理。在您的推导和算法设计中，请使用以下原则作为基础：\n- 确定性状态演化：一个模为 $m$ 的 PRNG 最多有 $m$ 个不同的内部状态。因此，遍历所有可能的种子最多能探索 $m$ 个不同的输出序列。\n- 排列计数：对于 $n$ 个带标签的项，存在 $n!$ 种排列。\n- 使用拒绝采样从有限范围进行精确均匀选择：如果 $X$ 在 $\\{0,1,\\dots,m-1\\}$ 上均匀分布，那么对于任何正整数 $b$，整数\n$$\nJ = X \\bmod b \\quad \\text{在 } X  \\left\\lfloor \\frac{m}{b} \\right\\rfloor b \\text{ 的条件下}\n$$\n在 $\\{0,1,\\dots,b-1\\}$ 上是均匀分布的。这实现了在 $\\{0,1,\\dots,b-1\\}$ 上的精确均匀抽样，而仅使用在 $\\{0,1,\\dots,m-1\\}$ 上的均匀抽样。\n- 关于混合 LCG 满周期的 Hull–Dobell 定理：一个模为 $m$ 的 LCG 具有满周期 $m$ 的充要条件是：$\\gcd(c,m) = 1$，$a-1$ 能被 $m$ 的所有素因子整除，并且当 $m$ 能被 $4$ 整除时，$a-1$ 也能被 $4$ 整除。\n\n任务。您必须实现：\n1) 如上定义的 LCG。\n2) 对列表 $[0,1,\\dots,n-1]$ 进行 Fisher–Yates 洗牌，使用如上所述的拒绝采样方法从 LCG 状态中获得精确均匀的整数抽样 $J_i \\in \\{0,\\dots,i\\}$。第 $i$ 次抽样必须仅依赖于当前的 LCG 状态，并通过 LCG 递推关系确定性地更新状态。\n3) 对于给定的元组 $(n,a,c,m)$，枚举所有种子 $x_0 \\in \\{0,1,\\dots,m-1\\}$，每个种子运行一次 Fisher–Yates 洗牌，并统计所实现的不同排列的数量。将此计数记为 $R(n,a,c,m)$。\n4) 对于给定的 $(n,m)$，还需计算布尔值\n$$\nB(n,m) = \\begin{cases}\n1  \\text{若 } m \\ge n! \\\\\n0  \\text{若 } m  n!\n\\end{cases}\n$$\n这是一个模为 $m$ 的 LCG 在遍历所有种子时能够实现所有 $n!$ 种排列的必要（但不充分）条件。\n\n科学目标。从第一性原理出发，论证并检验必要条件 $R(n,a,c,m) \\le \\min\\{m,n!\\}$，并凭经验探索在精确均匀索引选择下，$R(n,a,c,m)$ 何时能达到该界限。\n\n测试套件。您的程序必须为以下四组参数计算 $R(n,a,c,m)$，并为 $n=52$ 的情况计算 $B(n,m)$：\n- 测试 1：$(n,a,c,m) = (5,\\,109,\\,1,\\,256)$。\n- 测试 2：$(n,a,c,m) = (6,\\,109,\\,1,\\,256)$。\n- 测试 3：$(n,a,c,m) = (7,\\,421,\\,1,\\,5040)$。\n- 测试 4：$(n,a,c,m) = (7,\\,109,\\,1,\\,4096)$。\n- 测试 5：$B(52,2^{32})$。\n\n根据定义，上述所有整数 $n$、$a$、$c$ 和 $m$ 均为无量纲。不涉及任何物理单位或角度。\n\n输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果的顺序必须完全如下：\n$$\n\\big[ R(5,109,1,256),\\; R(6,109,1,256),\\; R(7,421,1,5040),\\; R(7,109,1,4096),\\; B(52,2^{32}) \\big].\n$$\n每个条目都必须是整数。不应打印任何额外文本。计算过程必须是完全确定性的，不需要用户输入或外部文件。", "solution": "该问题要求分析 Fisher-Yates 洗牌算法生成的不同排列的数量，该算法从线性同余生成器（LCG）中抽取其随机索引。这涉及实现指定的算法，并探索生成器能够产生所有可能排列的一个必要条件。\n\n首先，我们将该系统形式化。LCG 是一种伪随机数生成器，由以下递推关系定义：\n$$\nX_{k+1} \\equiv (a X_k + c) \\bmod m\n$$\n其中 $X_k$ 是生成器的状态，$a$、$c$ 和 $m$ 是整数参数。对于一个给定的初始状态（或种子）$X_0 \\in \\{0, 1, \\dots, m-1\\}$，LCG 会产生一个确定性的整数序列。可能种子的数量为 $m$，因此最多可以生成 $m$ 个不同的输出序列。\n\nFisher-Yates 洗牌算法生成一个包含 $n$ 个元素的列表的随机排列。它通过从 $i = n-1$ 向下迭代到 $1$ 来进行。在每一步中，它从范围 $\\{0, 1, \\dots, i\\}$ 中均匀随机地选择一个整数 $J_i$，然后交换位置 $i$ 和 $J_i$ 上的元素。要生成一个单一的排列，需要一个包含 $n-1$ 个随机整数的序列 $\\{J_{n-1}, J_{n-2}, \\dots, J_1\\}$。\n\n问题的核心是将 LCG 与 Fisher-Yates 洗牌结合起来。采用 $J_i = X_k \\pmod{i+1}$ 的简单方法是有缺陷的，因为如果 $m$ 不是 $i+1$ 的倍数，它会引入偏差。问题要求使用拒绝采样来获得一个精确均匀的整数。要从 $\\{0, 1, \\dots, b-1\\}$（其中 $b = i+1$）中抽取一个均匀整数 $J_i$，我们使用 LCG 生成值 $X \\in \\{0, 1, \\dots, m-1\\}$。我们找到小于或等于 $m$ 的 $b$ 的最大倍数，即 $T = \\lfloor \\frac{m}{b} \\rfloor \\cdot b$。如果生成的 $X$ 值满足 $X  T$，则接受该值；否则，拒绝该值。接受后，所需的索引为 $J_i = X \\pmod b$。对于从 LCG 生成的每个值 $X$，无论其被接受还是拒绝，LCG 的内部状态都必须根据其递推关系向前推进。这确保了对于给定的种子，整个过程是确定性的。\n\nLCG 与带拒绝采样的 Fisher-Yates 洗牌相结合，定义了一个确定性函数 $\\pi(X_0)$，它将一个初始种子 $X_0$ 映射到 $\\{0, 1, \\dots, n-1\\}$ 的一个特定排列。我们的任务是计算 $R(n, a, c, m)$，即当种子 $X_0$ 遍历所有可能的值 $\\{0, 1, \\dots, m-1\\}$ 时，生成的不同排列的数量。这是函数 $\\pi$ 的像的基数：\n$$\nR(n, a, c, m) = \\left| \\{ \\pi(X_0) \\mid X_0 \\in \\{0, 1, \\dots, m-1\\} \\} \\right|\n$$\n$R(n,a,c,m)$ 的值有两个基本约束。首先， $n$ 个项的不同排列的总数是 $n!$。生成的排列集合是所有可能排列的子集，因此 $R(n,a,c,m) \\le n!$。其次，由于只有 $m$ 个可能的种子，并且每个种子映射到一个单一的排列，所以不同结果的数量不能超过 $m$。这意味着 $R(n,a,c,m) \\le m$。综合这些观察结果，我们得到以下必要条件：\n$$\nR(n,a,c,m) \\le \\min\\{m, n!\\}\n$$\n这个条件是鸽巢原理的直接推论。该界限的饱和，即 $R(n,a,c,m) = \\min\\{m, n!\\}$，取决于 LCG 的具体属性，特别是其周期和输出序列的统计质量。Hull-Dobell 定理指出，对于某些参数，LCG 可以具有 $m$ 的满周期，这意味着它会在重复之前遍历所有 $m$ 个状态。对于一个旨在覆盖广阔结果空间的生成器来说，这是一个理想的属性。\n\n函数 $B(n,m)$ 评估条件 $m \\ge n!$。这是一个简单但至关重要的必要条件。如果一个 LCG 的内部状态数（$m$）少于可能排列的总数（$n!$），那么无论其其他属性如何，它都不可能生成所有排列。对于 $B(52, 2^{32})$，我们必须比较 $52!$ 和 $2^{32}$。快速计算可知 $13! \\approx 6.2 \\times 10^9$，这已经大于 $2^{32} \\approx 4.3 \\times 10^9$。因此，$52!$ 远大于 $2^{32}$，所以 $B(52, 2^{32}) = 0$。\n\n为给定测试用例找到 $R(n, a, c, m)$ 的计算过程如下：\n1. 初始化一个空集，`permutations`，用于存储生成的唯一排列。\n2. 遍历从 $0$ 到 $m-1$ 的每个可能的种子 $X_0$。\n3. 为每个种子创建一个 LCG 实例。\n4. 对列表 $[0, 1, \\dots, n-1]$ 执行 Fisher-Yates 洗牌。对于从 $n-1$ 向下到 $1$ 的每一步 $i$：\n    a. 使用 LCG 和拒绝采样来抽取一个均匀索引 $J_i \\in \\{0, 1, \\dots, i\\}$。\n    b. 交换位置 $i$ 和 $J_i$ 上的元素。\n5. 将结果列表转换为不可变的元组，并将其添加到 `permutations` 集合中。\n6. $R(n, a, c, m)$ 的值是该集合的最终大小，即 `len(permutations)`。\n\n此程序被实现用于计算测试套件所需的值。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\n# No other libraries are permitted aside from the standard library.\n\nclass LCG:\n    \"\"\"\n    Implements a Linear Congruential Generator (LCG).\n    X_{k+1} = (a * X_k + c) mod m\n    \"\"\"\n    def __init__(self, a, c, m, seed):\n        self.a = np.uint64(a)\n        self.c = np.uint64(c)\n        self.m = np.uint64(m)\n        self.state = np.uint64(seed)\n\n    def next(self):\n        \"\"\"Generates the next number in the sequence.\"\"\"\n        self.state = (self.a * self.state + self.c) % self.m\n        return self.state\n\ndef draw_uniform(lcg_instance, b):\n    \"\"\"\n    Draws a uniform integer from {0, 1, ..., b-1} using the LCG\n    with rejection sampling.\n    \"\"\"\n    if b = 1:\n        return 0\n    \n    m = lcg_instance.m\n    threshold = (m // b) * b\n    \n    while True:\n        x = lcg_instance.next()\n        if x  threshold:\n            return int(x % b)\n\ndef fisher_yates_shuffle(n, lcg_instance):\n    \"\"\"\n    Performs a Fisher-Yates shuffle on the list [0, ..., n-1]\n    using the provided LCG instance for random number generation.\n    Returns the shuffled list as a tuple.\n    \"\"\"\n    arr = list(range(n))\n    for i in range(n - 1, 0, -1):\n        # Draw a uniform integer j from {0, ..., i}\n        # The range has size a_i = i + 1\n        j = draw_uniform(lcg_instance, i + 1)\n        arr[i], arr[j] = arr[j], arr[i]\n    return tuple(arr)\n\ndef compute_R(n, a, c, m):\n    \"\"\"\n    Enumerates all seeds for an LCG, performs a Fisher-Yates shuffle for each,\n    and counts the number of distinct permutations realized.\n    \"\"\"\n    permutations = set()\n    for seed in range(m):\n        lcg = LCG(a, c, m, seed)\n        perm = fisher_yates_shuffle(n, lcg)\n        permutations.add(perm)\n    return len(permutations)\n\ndef compute_B(n, m):\n    \"\"\"\n    Computes B(n, m) = 1 if m >= n!, 0 otherwise.\n    \"\"\"\n    if n > 20: # math.factorial(21) already exceeds 64-bit int max\n        # For large n, we must check if n! exceeds m.\n        # 13! > 2^32, so 52! is vastly larger than 2^32.\n        # Direct comparison is safe due to Python's arbitrary-precision integers.\n        return 1 if m >= math.factorial(n) else 0\n    \n    # For smaller n, this is safe and direct.\n    n_factorial = math.factorial(n)\n    return 1 if m >= n_factorial else 0\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, a, c, m)\n        (5, 109, 1, 256),\n        (6, 109, 1, 256),\n        (7, 421, 1, 5040),\n        (7, 109, 1, 4096),\n    ]\n\n    results = []\n    \n    # Run Test 1\n    n, a, c, m = test_cases[0]\n    results.append(compute_R(n, a, c, m))\n\n    # Run Test 2\n    n, a, c, m = test_cases[1]\n    results.append(compute_R(n, a, c, m))\n\n    # Run Test 3\n    n, a, c, m = test_cases[2]\n    results.append(compute_R(n, a, c, m))\n    \n    # Run Test 4\n    n, a, c, m = test_cases[3]\n    results.append(compute_R(n, a, c, m))\n\n    # Run Test 5\n    n_b, m_b = (52, 2**32)\n    results.append(compute_B(n_b, m_b))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "2433326"}, {"introduction": "在生成随机排列组合时，算法本身至关重要。本练习将深入探讨洗牌的*方法*，将经过数学证明的、正确的 Fisher–Yates 算法与一些故意设计的有缺陷版本进行对比。你将亲手实现这些算法，并学习如何使用统计检验（如卡方检验）来量化和检测出那些看似微小的算法错误所引入的显著偏差，从而验证随机化过程的质量。[@problem_id:2433283]", "problem": "要求您设计并实现一个程序，用于验证“无偏随机排列应使每个元素在任何位置出现的概率均等”这一原理。您的关注点是第一个位置。本练习与计算物理学中的蒙特卡洛方法直接相关，在蒙特卡洛方法中，伪随机数生成器 (PRNG) 的保真度决定了随机模拟结果的有效性。\n\n起始点和定义：\n- 伪随机数生成器 (PRNG) 在用种子初始化时，会产生一个确定性的数字序列，该序列近似于从指定概率分布中抽取的样本。\n- $N$ 个不同标签的一个排列是集合 $\\{0,1,\\dots,N-1\\}$ 上的一个双射。如果 $N!$ 种可能的排列中，每一种出现的概率都为 $1/N!$，则该排列是均匀的。\n- 如果排列是均匀的，那么对于任何固定位置（特别是第一个位置），每个标签出现的概率必须为 $1/N$。\n- 为了检验观测计数是否与一个假设的离散均匀分布一致，可以使用经典的卡方拟合优度检验：根据观测计数和期望计数形成卡方统计量，并将其与具有适当自由度的卡方分布进行比较以获得 $p$-值。在预先选定的显著性水平 $\\alpha$ 下，如果 $p$-值足够小，则拒绝原假设。\n\n您的任务：\n1) 对标签列表 $[0,1,\\dots,N-1]$ 实现三种排列生成器：\n   - 方法 U (无偏 Fisher–Yates)：迭代索引 $i$ 从 $N-1$ 向下到 $1$。对于每个 $i$，从 $\\{0,1,\\dots,i\\}$ 中均匀抽取一个整数 $j$，并交换索引 $i$ 和 $j$ 处的元素。已知这种方法可以产生均匀排列。\n   - 方法 P$(c)$ (部分 Fisher–Yates)：定义 $m=\\lfloor c\\,N\\rfloor$，其中 $0c1$。仅执行方法U的最后 $m$ 次交换，即对于 $k=0,1,\\dots,m-1$，设置 $i=N-1-k$，从 $\\{0,1,\\dots,i\\}$ 中均匀抽取 $j$，并交换索引 $i$ 和 $j$。这会故意让前导部分随机化不足。\n   - 方法 M$(b)$ (有偏模运算首选)：从 $\\{0,1,\\dots,2^b-1\\}$ 中均匀抽取一个整数 $x$，并设置 $f = x \\bmod N$。交换索引 $0$ 和 $f$。然后通过对索引 $i=N-1$ 到 $1$ 应用受限的 Fisher–Yates 过程来完成位置 $1$ 到 $N-1$ 的排列，即从 $\\{1,2,\\dots,i\\}$ 中均匀抽取 $j$ 并交换索引 $i$ 和 $j$。这会强制第一个元素的选择来自一个大小为 $2^b$ 的离散池，除非 $N$ 能整除 $2^b$，否则这通常会使第一个位置的选择产生偏差。\n\n2) 对于给定的方法、整数 $N \\ge 2$、试验次数 $T$、显著性水平 $\\alpha$（以小数表示）和种子 $s$，执行以下实验：\n   - 使用整数种子 $s$ 初始化 PRNG。\n   - 独立重复以下步骤 $T$ 次：\n     - 使用所选方法生成 $[0,1,\\dots,N-1]$ 的一个排列。\n     - 通过增加其计数来记录占据索引 $0$ 的标签。\n   - 令 $\\mathbf{O}=(O_0,\\dots,O_{N-1})$ 为观测计数，$\\mathbf{E}=(E,\\dots,E)$（其中 $E=T/N$）为原假设 $H_0$（即第一个位置的标签分布在 $\\{0,1,\\dots,N-1\\}$ 上是均匀的）下的期望计数。\n   - 基于 $\\mathbf{O}$ 和 $\\mathbf{E}$ 计算卡方检验统计量，并使用具有 $N-1$ 个自由度的卡方分布计算相应的 $p$-值。\n   - 报告四舍五入到六位小数的 $p$-值，以及一个指示符 $d$。如果在 $\\alpha$ 水平上拒绝原假设（即 $p\\alpha$），则 $d$ 等于 $1$，否则等于 $0$。\n\n3) 将您的解决方案实现为一个完整、可运行的程序，该程序不使用任何输入，并为以下测试套件打印结果。其中每个案例的形式为 $(\\text{方法}, N, T, \\alpha, s, \\text{参数})$，“参数”根据上述方法描述进行解释：\n   - 案例 1 (理想情况，无偏): $(\\text{\"U\"},\\, 10,\\, 100000,\\, 0.01,\\, 10101,\\, \\text{None})$。\n   - 案例 2 (前端的边缘随机化不足): $(\\text{\"P\"},\\, 20,\\, 80000,\\, 1\\times 10^{-12},\\, 20202,\\, c=0.2)$。\n   - 案例 3 (首次选择中的显式模偏差): $(\\text{\"M\"},\\, 10,\\, 120000,\\, 1\\times 10^{-6},\\, 30303,\\, b=8)$。\n   - 案例 4 (小 $N$ 边界情况，无偏): $(\\text{\"U\"},\\, 2,\\, 60000,\\, 0.01,\\, 40404,\\, \\text{None})$。\n   - 案例 5 (小取值空间下的强模偏差): $(\\text{\"M\"},\\, 7,\\, 120000,\\, 1\\times 10^{-6},\\, 50505,\\, b=3)$。\n\n输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。每个元素本身必须是一个形式为 $[p, d]$ 的双元素列表，其中 $p$ 是四舍五入到六位小数的 $p$-值，$d$ 是上文定义的整数决策指示符。例如，一个有效的输出行如下所示：\n  [[0.532114,0],[0.000000,1],[0.123456,0],[0.774321,0],[0.000000,1]]\n\n注意事项：\n- 不涉及物理单位，因此无需进行单位转换。\n- 不涉及角度。\n- 百分比（如显著性水平）已指定为小数，并且必须按此处理。", "solution": "该问题要求通过实验验证三种排列算法，测试它们是否在排列数组的第一个位置上产生均匀的标签分布。这是计算物理学和蒙特卡洛方法中的一个基本检查，在这些领域，伪随机性的质量对模拟结果的有效性至关重要。验证将使用卡方拟合优度检验进行。\n\n对于每个测试用例，总体过程包括固定次数的试验，即 $T$ 次。在每次试验中，使用指定方法之一对初始标签数组 $[0, 1, \\dots, N-1]$ 进行排列。记录最终位于索引 0 的标签。经过 $T$ 次试验后，我们获得每个标签在第一个位置出现的观测计数的频率分布 $\\mathbf{O} = (O_0, O_1, \\dots, O_{N-1})$。\n\n原假设 $H_0$ 指出，排列方法对于第一个位置是无偏的，即每个标签 $k \\in \\{0, \\dots, N-1\\}$ 出现在该位置的概率为 $1/N$。在 $H_0$ 下，每个标签的期望计数为 $E_k = T/N$。卡方检验统计量 $\\chi^2$ 计算如下：\n$$ \\chi^2 = \\sum_{k=0}^{N-1} \\frac{(O_k - E_k)^2}{E_k} $$\n将此统计量与具有 $df = N-1$ 个自由度的 $\\chi^2$ 分布进行比较。$p$-值表示如果 $H_0$ 为真，观测到至少与计算出的统计量一样极端的统计量的概率，它由该分布的生存函数确定：$p = P(\\chi^2_{df} \\ge \\chi^2_{\\text{observed}})$。在给定的显著性水平 $\\alpha$下，如果 $p  \\alpha$，则拒绝 $H_0$。\n\n以下是每种排列方法的分析。所有算法都使用以特定种子 $s$ 初始化的伪随机数生成器 (PRNG) 实现，以确保可复现性。\n\n方法 U（无偏 Fisher–Yates）：该算法将索引 $i$ 从 $N-1$ 迭代到 $1$。在每一步中，它从 $\\{0, 1, \\dots, i\\}$ 中均匀选择一个随机索引 $j$，并交换位置 $i$ 和 $j$ 的元素。这个经典算法被证明能以相等的概率 $1/N!$ 生成 $N$ 个元素的所有可能排列。因此，任何给定标签出现在任何给定位置的概率恰好为 $1/N$。此方法是我们无偏排列的基准，我们预计统计检验不会拒绝原假设（即，会产生较大的 $p$-值）。\n\n方法 P($c$)（部分 Fisher–Yates）：此方法被设计为有偏的。它只执行完整 Fisher-Yates 洗牌的一部分交换。给定参数 $c \\in (0, 1)$，它执行 $m = \\lfloor cN \\rfloor$ 次交换。问题的描述“对于 $k=0,1,\\dots,m-1$ 设置 $i=N-1-k$”规定了这些交换是针对最大的一些索引，即 $i=N-1, N-2, \\dots, N-m$。这使得数组的前缀（对应于小索引）随机化不足。起始于前缀的标签被移动的可能性较小。具体来说，标签 $0$（初始在索引 $0$）会留在其位置上，除非它在某次交换中被选为索引 $j$。它*不*被选中的概率是 $\\prod_{i=N-m}^{N-1} (1 - \\frac{1}{i+1}) = \\frac{N-m}{N} = 1-c$。这造成了显著的偏差：标签 $0$ 出现在索引 $0$ 的可能性远大于任何其他标签。我们预计检验会以接近 $0$ 的 $p$-值强烈拒绝 $H_0$。\n\n方法 M($b$)（有偏模运算首选）：此方法在第一步就引入了偏差。它从一个非均匀分布中为第一个位置选择元素。从 $\\{0, 1, \\dots, 2^b-1\\}$ 中均匀抽取一个整数 $x$，并计算一个索引 $f = x \\pmod N$。将索引 $f$ 处的元素（即标签 $f$）交换到索引 $0$。如描述所述，随后的洗牌步骤在索引 $1$ 到 $N-1$ 之间对元素进行洗牌，而索引 $0$ 处的元素保持不变。因此，最终在索引 $0$ 处的标签分布就是 $f$ 的分布。只有当 $N$ 整除 $2^b$ 时，这个分布才是均匀的。否则，设 $2^b = qN+r$。标签 $\\{0, \\dots, r-1\\}$ 被选择的概率为 $(q+1)/2^b$，而标签 $\\{r, \\dots, N-1\\}$ 被选择的概率为 $q/2^b$。这种差异，无论多么微小，都会引入一个偏差，当试验次数 $T$ 足够大时，这个偏差应该是可以检测到的。对于给定的测试用例，$N$ 都不整除 $2^b$，所以我们预计会拒绝 $H_0$。偏差的大小，以及由此产生的 $p$-值，取决于概率偏离 $1/N$ 的程度。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef permute_U(arr, rng):\n    \"\"\"\n    Generates a uniform permutation using the Fisher-Yates shuffle.\n    \"\"\"\n    n = len(arr)\n    for i in range(n - 1, 0, -1):\n        j = rng.integers(0, i, endpoint=True)\n        arr[i], arr[j] = arr[j], arr[i]\n    return arr\n\ndef permute_P(arr, rng, c):\n    \"\"\"\n    Generates a biased permutation using a partial Fisher-Yates shuffle.\n    \"\"\"\n    n = len(arr)\n    m = int(c * n)\n    for k in range(m):\n        i = n - 1 - k\n        # The swap is meaningful only for i > 0\n        if i > 0:\n            j = rng.integers(0, i, endpoint=True)\n            arr[i], arr[j] = arr[j], arr[i]\n    return arr\n\ndef permute_M(arr, rng, b):\n    \"\"\"\n    Generates a biased permutation using a modulo-biased first pick.\n    \"\"\"\n    n = len(arr)\n    # Draw x uniformly from {0, ..., 2^b - 1}\n    keyspace = 2**b\n    x = rng.integers(0, keyspace - 1, endpoint=True)\n    f = x % n\n    \n    # Swap element at index f into the first position\n    arr[0], arr[f] = arr[f], arr[0]\n    \n    # Shuffle the rest of the array (indices 1..N-1) among themselves\n    # The problem specifies j is drawn from {1, ..., i}\n    for i in range(n - 1, 0, -1):\n        j = rng.integers(1, i, endpoint=True)\n        arr[i], arr[j] = arr[j], arr[i]\n    return arr\n\ndef run_experiment(method, N, T, s, param):\n    \"\"\"\n    Runs the simulation to collect counts of labels at the first position.\n    \"\"\"\n    rng = np.random.default_rng(seed=s)\n    counts = np.zeros(N, dtype=np.int64)\n    \n    permute_func = None\n    if method == \"U\":\n        permute_func = lambda arr: permute_U(arr, rng)\n    elif method == \"P\":\n        permute_func = lambda arr: permute_P(arr, rng, c=param)\n    elif method == \"M\":\n        permute_func = lambda arr: permute_M(arr, rng, b=param)\n    else:\n        raise ValueError(f\"Unknown permutation method: {method}\")\n\n    for _ in range(T):\n        p = list(range(N))\n        permuted_p = permute_func(p)\n        first_element_label = permuted_p[0]\n        counts[first_element_label] += 1\n        \n    return counts\n\ndef perform_chi2_test(observed_counts, N, T, alpha):\n    \"\"\"\n    Performs the chi-squared goodness-of-fit test.\n    \"\"\"\n    # Under H0, expected count for each category is uniform.\n    expected_count = T / N\n    \n    # Calculate the chi-squared statistic\n    chisq_stat = np.sum((observed_counts - expected_count)**2 / expected_count)\n    \n    # Degrees of freedom for a GOF test is k-1.\n    df = N - 1\n    \n    # Calculate p-value using the survival function (1 - CDF).\n    p_value = chi2.sf(chisq_stat, df)\n    \n    # Decision: reject H0 if p  alpha\n    decision = 1 if p_value  alpha else 0\n    \n    return p_value, decision\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        # (method, N, T, alpha, seed, parameter)\n        (\"U\", 10, 100000, 0.01, 10101, None),\n        (\"P\", 20, 80000, 1e-12, 20202, 0.2),\n        (\"M\", 10, 120000, 1e-6, 30303, 8),\n        (\"U\", 2, 60000, 0.01, 40404, None),\n        (\"M\", 7, 120000, 1e-6, 50505, 3),\n    ]\n\n    results = []\n    for case in test_cases:\n        method, N, T, alpha, seed, param = case\n        \n        # 1. Run simulation to get observed counts\n        observed_counts = run_experiment(method, N, T, seed, param)\n        \n        # 2. Perform chi-squared test to get p-value and decision\n        p_value, decision = perform_chi2_test(observed_counts, N, T, alpha)\n        \n        results.append((p_value, decision))\n    \n    # 3. Format output string precisely as required\n    result_strings = [f\"[{p:.6f},{d}]\" for p, d in results]\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```", "id": "2433283"}, {"introduction": "许多科学模拟超越了简单的离散任务，要求我们从连续的、非均匀的分布中进行抽样。本练习将解决一个经典问题：如何在球面上均匀地生成点，这是模拟各向同性现象（如粒子辐射或分子方向）的关键步骤。你将应用逆变换采样法这一强大技术，并再次使用卡方检验来验证你生成的点集是否精确地遵循了预期的空间分布。[@problem_id:2433291]", "problem": "你需要编写一个完整、可运行的程序，用于在三维空间的单位球体表面上生成均匀分布的点，并使用基于球面坐标的二维直方图来评估其均匀性。所有角度必须以弧度为单位。单位球体的表面由球面坐标参数化，其中极角 $\\theta \\in [0,\\pi]$，方位角 $\\phi \\in [0,2\\pi)$。均匀表面测度的曲面面积元为 $\\mathrm{d}A = \\sin\\theta\\,\\mathrm{d}\\theta\\,\\mathrm{d}\\phi$，总表面积为 $4\\pi$。对于一组给定的生成点，通过将 $\\theta$ 划分到 $B_\\theta$ 个等宽区间，并将 $\\phi$ 划分到 $B_\\phi$ 个等宽区间，来构建一个二维直方图。$\\theta$ 区间的边界为 $\\theta_i = i\\,\\Delta\\theta$，其中 $\\Delta\\theta = \\pi/B_\\theta$，对于 $i=0,1,\\dots,B_\\theta$；$\\phi$ 区间的边界为 $\\phi_j = j\\,\\Delta\\phi$，其中 $\\Delta\\phi = 2\\pi/B_\\phi$，对于 $j=0,1,\\dots,B_\\phi$。对所有区间使用半开区间 $[\\theta_i,\\theta_{i+1})$ 和 $[\\phi_j,\\phi_{j+1})$，但每个维度中的最后一个区间在右侧是闭合的，以包含端点 $\\theta=\\pi$ 和 $\\phi=2\\pi$。\n\n为了检验均匀性，令 $O_{i,j}$ 表示区间 $(i,j)$ 中的观测频数，令 $E_{i,j}$ 表示在均匀表面测度下的期望频数。期望频数从第一性原理得到，即通过对区间区域上的曲面面积元进行积分，并用总表面积进行归一化。也就是说，区间 $(i,j)$ 的期望概率是该区间的表面积与 $4\\pi$ 的比值，而 $E_{i,j}$ 等于此概率乘以生成的总点数 $N$。使用 Pearson 卡方统计量\n$$\n\\chi^2 = \\sum_{i=0}^{B_\\theta-1}\\sum_{j=0}^{B_\\phi-1} \\frac{\\left(O_{i,j}-E_{i,j}\\right)^2}{E_{i,j}},\n$$\n求和仅对 $E_{i,j}  0$ 的区间进行。自由度为 $k-1$，其中 $k$ 是 $E_{i,j}  0$ 的区间数量。对于给定的显著性水平 $\\alpha \\in (0,1)$，如果 $\\chi^2 \\leq q$，则接受均匀表面分布的原假设，其中 $q$ 是具有 $k-1$ 个自由度的卡方分布的 $(1-\\alpha)$-分位数。\n\n你的程序必须对每个测试用例，使用给定的整数种子初始化的伪随机数生成器，在单位球面上精确生成 $N$ 个点，按照 $\\phi \\in [0,2\\pi)$ 的约定计算每个点的 $\\theta$ 和 $\\phi$，按规定构建二维直方图，按描述从第一性原理计算 $E_{i,j}$，评估 $\\chi^2$，确定给定 $\\alpha$ 的临界值 $q$，并报告一个指示 $\\chi^2 \\leq q$ 是否成立的布尔值。\n\n角度单位要求：报告和计算的所有角度均以弧度为单位。\n\n测试套件规范：\n- 用例 1：seed $= 12345$， $N = 40000$， $B_\\theta = 10$， $B_\\phi = 20$， $\\alpha = 0.01$。\n- 用例 2：seed $= 54321$， $N = 1280$， $B_\\theta = 8$， $B_\\phi = 16$， $\\alpha = 0.05$。\n- 用例 3：seed $= 20231102$， $N = 50000$， $B_\\theta = 2$， $B_\\phi = 3$， $\\alpha = 0.01$。\n- 用例 4：seed $= 777$， $N = 100000$， $B_\\theta = 18$，$B_\\phi = 36$， $\\alpha = 0.05$。\n\n要求的最终输出格式：你的程序应生成一行输出，其中包含按顺序排列的测试用例的布尔结果，形式为逗号分隔的列表，并用方括号括起来，不含空格。例如，包含四个布尔值的输出必须如下所示：\n[True,False,True,True]。", "solution": "该任务要求实现一个统计检验，以验证球面上点的均匀性。这涉及三个主要阶段：根据指定的分布生成点，对它们进行分箱以获得观测频率，并将这些频率与理论推导的期望频率进行比较。\n\n**1. 在球面上生成均匀分布的点**\n一个天真的方法是从它们各自的范围 $[0, \\pi]$ 和 $[0, 2\\pi)$ 的均匀分布中抽样 $\\theta$ 和 $\\phi$，这是不正确的，因为它会导致点在两极附近的密度更高。正确的方法必须考虑曲面面积元 $\\mathrm{d}A = \\sin\\theta\\,\\mathrm{d}\\theta\\,\\mathrm{d}\\phi$。点位于 $(\\theta, \\phi)$ 的概率密度函数 $p(\\theta, \\phi)$ 必须与曲面面积元成正比。在整个球体（总面积 $4\\pi$）上进行归一化，得到联合概率密度函数：\n$$p(\\theta, \\phi) = \\frac{1}{4\\pi}\\sin\\theta, \\quad \\theta \\in [0, \\pi], \\phi \\in [0, 2\\pi)$$\n边缘概率密度通过对另一个变量积分来求得：\n$$p(\\theta) = \\int_0^{2\\pi} p(\\theta, \\phi) \\,\\mathrm{d}\\phi = \\int_0^{2\\pi} \\frac{1}{4\\pi}\\sin\\theta \\,\\mathrm{d}\\phi = \\frac{2\\pi}{4\\pi}\\sin\\theta = \\frac{1}{2}\\sin\\theta$$\n$$p(\\phi) = \\int_0^\\pi p(\\theta, \\phi) \\,\\mathrm{d}\\theta = \\int_0^\\pi \\frac{1}{4\\pi}\\sin\\theta \\,\\mathrm{d}\\theta = \\frac{1}{4\\pi}[-\\cos\\theta]_0^\\pi = \\frac{2}{4\\pi} = \\frac{1}{2\\pi}$$\n由于 $p(\\theta, \\phi) = p(\\theta)p(\\phi)$，变量 $\\theta$ 和 $\\phi$ 是独立的，可以分开抽样。我们使用逆变换采样法。设 $U_1$ 和 $U_2$ 是两个在 $[0,1)$ 上均匀分布的独立随机变量。\n\n对于 $\\phi$，累积分布函数（CDF）为 $F_\\phi(\\phi') = \\int_0^{\\phi'} \\frac{1}{2\\pi} \\mathrm{d}\\phi = \\frac{\\phi'}{2\\pi}$。令 $F_\\phi(\\phi) = U_1$ 可得 $\\phi = 2\\pi U_1$。\n\n对于 $\\theta$，CDF 为 $F_\\theta(\\theta') = \\int_0^{\\theta'} \\frac{1}{2}\\sin\\theta \\mathrm{d}\\theta = \\frac{1}{2}[-\\cos\\theta]_0^{\\theta'} = \\frac{1}{2}(1 - \\cos\\theta')$。令 $F_\\theta(\\theta) = U_2$ 得到 $\\frac{1}{2}(1-\\cos\\theta) = U_2$，可整理为 $\\cos\\theta = 1-2U_2$。由于 $1-2U_2$ 在 $[-1,1]$上是均匀分布的，我们可以等价地使用一个也在 $[-1,1]$ 上均匀分布的变量 $v = 2U_2-1$。因此，我们从 $[-1,1]$ 中均匀生成 $\\cos\\theta$，然后求出 $\\theta$：\n$$\\phi = 2\\pi U_1$$\n$$\\theta = \\arccos(2U_2-1)$$\n这个过程生成了 $N$ 个点对 $(\\theta_k, \\phi_k)$，其中 $k=1, \\dots, N$。\n\n**2. 观测频率和期望频率**\n生成的点被分箱到一个大小为 $B_\\theta \\times B_\\phi$ 的二维直方图中。落在由区域 $[\\theta_i, \\theta_{i+1}) \\times [\\phi_j, \\phi_{j+1})$ 定义的区间 $(i,j)$ 内的点的数量，即为观测频率 $O_{i,j}$。\n\n区间 $(i,j)$ 的期望频率 $E_{i,j}$ 是 $N$ 乘以一个点落入该区间的概率。这个概率是该区间的表面积与球体总表面积 $4\\pi$ 的比值。区间 $(i,j)$ 的表面积 $A_{ij}$ 通过对曲面面积元积分来计算：\n$$A_{i,j} = \\int_{\\phi_j}^{\\phi_{j+1}} \\int_{\\theta_i}^{\\theta_{i+1}} \\sin\\theta\\,\\mathrm{d}\\theta\\,\\mathrm{d}\\phi = \\left(\\int_{\\phi_j}^{\\phi_{j+1}} \\mathrm{d}\\phi\\right) \\left(\\int_{\\theta_i}^{\\theta_{i+1}} \\sin\\theta\\,\\mathrm{d}\\theta\\right)$$\n区间边界为 $\\theta_i = i\\Delta\\theta$（其中 $\\Delta\\theta = \\pi/B_\\theta$）和 $\\phi_j = j\\Delta\\phi$（其中 $\\Delta\\phi = 2\\pi/B_\\phi$）。计算该积分得到：\n$$A_{i,j} = \\Delta\\phi \\cdot [-\\cos\\theta]_{\\theta_i}^{\\theta_{i+1}} = \\frac{2\\pi}{B_\\phi} (\\cos\\theta_i - \\cos\\theta_{i+1})$$\n那么期望频数 $E_{i,j}$ 是：\n$$E_{i,j} = N \\cdot \\frac{A_{i,j}}{4\\pi} = N \\cdot \\frac{(2\\pi/B_\\phi) (\\cos\\theta_i - \\cos\\theta_{i+1})}{4\\pi} = \\frac{N}{2B_\\phi}(\\cos(i\\pi/B_\\theta) - \\cos((i+1)\\pi/B_\\theta))$$\n注意 $E_{i,j}$ 与索引 $j$ 无关。此外，因为 $\\cos(x)$在 $[0, \\pi]$ 上是严格递减的，所以对于所有 $i$, $\\cos(i\\pi/B_\\theta) > \\cos((i+1)\\pi/B_\\theta)$，这意味着对于所有区间，$E_{i,j} > 0$。\n\n**3. 卡方拟合优度检验**\n有了观测频数 $O_{i,j}$ 和期望频数 $E_{i,j}$，就可以计算 Pearson 卡方统计量：\n$$\\chi^2 = \\sum_{i=0}^{B_\\theta-1} \\sum_{j=0}^{B_\\phi-1} \\frac{(O_{i,j}-E_{i,j})^2}{E_{i,j}}$$\n区间的数量为 $k = B_\\theta B_\\phi$。由于均匀分布没有从数据中估计的参数，因此 $\\chi^2$ 分布的自由度为 $k-1$。\n将原假设 $H_0$（即点是均匀分布的）与来自 $\\chi^2$ 分布的临界值 $q$ 进行比较检验。对于给定的显著性水平 $\\alpha$，$q$ 是 $(1-\\alpha)$-分位数。如果计算出的 $\\chi^2$ 统计量小于或等于 $q$，我们不拒绝 $H_0$。程序将返回一个布尔值，表示 $\\chi^2 \\leq q$ 是否成立。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef run_case(seed, N, B_theta, B_phi, alpha):\n    \"\"\"\n    Generates points on a unit sphere, performs a chi-squared test for uniformity,\n    and returns the result of the hypothesis test.\n\n    Args:\n        seed (int): The seed for the random number generator.\n        N (int): The total number of points to generate.\n        B_theta (int): The number of bins for the polar angle theta.\n        B_phi (int): The number of bins for the azimuthal angle phi.\n        alpha (float): The significance level for the chi-squared test.\n\n    Returns:\n        bool: True if the null hypothesis of uniformity is accepted, False otherwise.\n    \"\"\"\n    # 1. Generate points using inverse transform sampling\n    # This method correctly generates points uniformly distributed on the sphere's surface.\n    rng = np.random.default_rng(seed)\n    # Generate N random numbers from a uniform distribution on [0, 1)\n    u1 = rng.random(size=N)\n    u2 = rng.random(size=N)\n\n    # Transform uniform variates to spherical coordinates (theta, phi)\n    # phi is uniform in [0, 2*pi)\n    phi = 2 * np.pi * u1\n    # cos(theta) is uniform in [-1, 1]\n    cos_theta = 2 * u2 - 1\n    # theta is in [0, pi]\n    theta = np.arccos(cos_theta)\n    \n    # 2. Compute observed counts O_ij using a 2D histogram\n    theta_edges = np.linspace(0, np.pi, B_theta + 1)\n    phi_edges = np.linspace(0, 2 * np.pi, B_phi + 1)\n    \n    # np.histogram2d bins the data. The returned histogram H[i, j] corresponds\n    # to theta_edges[i] = theta  theta_edges[i+1] and phi_edges[j] = phi  phi_edges[j+1].\n    # The first argument 'x' is theta, second 'y' is phi.\n    # The resulting O_ij matrix has shape (B_theta, B_phi).\n    O_ij, _, _ = np.histogram2d(theta, phi, bins=[theta_edges, phi_edges])\n    \n    # 3. Compute expected counts E_ij from first principles\n    # E_ij is independent of j, so we first compute a 1D array for E_i.\n    i_indices = np.arange(B_theta)\n    delta_theta = np.pi / B_theta\n    theta_i = i_indices * delta_theta\n    theta_i_plus_1 = (i_indices + 1) * delta_theta\n\n    # Analytical formula for expected count in a bin\n    cos_diff = np.cos(theta_i) - np.cos(theta_i_plus_1)\n    E_i_base = (N / (2 * B_phi)) * cos_diff\n    \n    # Expand to a 2D matrix of shape (B_theta, B_phi) to match O_ij\n    E_ij = np.tile(E_i_base, (B_phi, 1)).T\n\n    # 4. Perform the Pearson's chi-squared test\n    # All E_ij are > 0 as cos(x) is strictly decreasing on [0, pi].\n    # The sum is over all bins.\n    squared_diff = (O_ij - E_ij)**2\n    chi_squared_stat = np.sum(squared_diff / E_ij)\n    \n    # Degrees of freedom: k - 1, where k is the number of bins\n    k = B_theta * B_phi\n    dof = k - 1\n    \n    # Critical value q is the (1-alpha) quantile of the chi-squared distribution\n    q = chi2.ppf(1 - alpha, df=dof)\n    \n    # Decision: Accept H0 if chi_squared_stat is not in the critical region\n    return chi_squared_stat = q\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results in the required format.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (seed, N, B_theta, B_phi, alpha)\n        (12345, 40000, 10, 20, 0.01),\n        (54321, 1280, 8, 16, 0.05),\n        (20231102, 50000, 2, 3, 0.01),\n        (777, 100000, 18, 36, 0.05),\n    ]\n\n    results = []\n    for case in test_cases:\n        seed, N, B_theta, B_phi, alpha = case\n        result = run_case(seed, N, B_theta, B_phi, alpha)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # e.g., \"[True,False,True,True]\"\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2433291"}]}