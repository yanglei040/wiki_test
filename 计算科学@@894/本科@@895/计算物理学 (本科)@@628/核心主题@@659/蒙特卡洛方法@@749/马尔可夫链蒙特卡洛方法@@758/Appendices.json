{"hands_on_practices": [{"introduction": "本练习将聚焦于 Metropolis 算法的核心决策步骤：接受概率的计算。通过为一个具体的移动计算这个概率，你将具体理解算法是如何在“移动到更高概率区域”与“探索状态空间”之间进行权衡的。这是构建许多 MCMC 模拟的基础模块 [@problem_id:1371728]。", "problem": "一位数据科学家正在实现一个马尔可夫链蒙特卡洛（MCMC）模拟，以从参数 $x$ 的后验概率分布中抽取样本。目标分布 $\\pi(x)$ 与该参数负绝对值的指数成正比，即 $\\pi(x) \\propto \\exp(-|x|)$。\n\n该科学家使用 Metropolis 算法，并采用对称的提议分布 $q(x'|x)$，其中给定当前状态 $x$ 提议一个新状态 $x'$ 的概率等于给定 $x'$ 提议 $x$ 的概率（即，$q(x'|x) = q(x|x')$）。\n\n假设在模拟的某一步中，链的当前状态是 $x = 1.5$。算法接着提议移动到一个新的候选状态 $x' = 2.0$。\n\n计算此次移动的接受概率。你的答案应该是一个无量纲的实数。将你的最终答案四舍五入到四位有效数字。", "solution": "对于一个从 $x$ 到 $x'$ 的移动，当提议分布为对称的 $q(x'|x)=q(x|x')$ 时，Metropolis 接受概率为\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\frac{\\pi(x')q(x|x')}{\\pi(x)q(x'|x)}\\right)=\\min\\left(1,\\frac{\\pi(x')}{\\pi(x)}\\right).\n$$\n给定目标分布 $\\pi(x)\\propto \\exp(-|x|)$，该比率可简化为\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\frac{\\exp(-|x'|)}{\\exp(-|x|)}=\\exp\\!\\left(-\\left(|x'|-|x|\\right)\\right).\n$$\n当 $x=1.5$ 且 $x'=2.0$ 时，我们有 $|x|=1.5$ 和 $|x'|=2.0$，因此\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\exp\\!\\left(-\\left(2.0-1.5\\right)\\right)=\\exp(-0.5).\n$$\n因此，\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\exp(-0.5)\\right)=\\exp(-0.5).\n$$\n数值上，当四舍五入到四位有效数字时，$\\exp(-0.5)\\approx 0.6065$。", "answer": "$$\\boxed{0.6065}$$", "id": "1371728"}, {"introduction": "尽管 MCMC 方法非常强大，但它们并非万无一失。本实践将探讨一个常见的陷阱：当参数之间存在强相关性时，采样器收敛缓慢。通过分析一个在相关分布上的简化版 Gibbs 采样过程 [@problem_id:1371718]，你将定量地看到高相关性如何严重阻碍采样器有效地探索目标分布，从而为诊断 MCMC 性能提供关键的几何直觉。", "problem": "考虑一个迭代算法，旨在定位一个特定的二维概率密度函数 $p(x, y)$ 的众数。在第 $t$ 次迭代时，算法的状态是平面上的一个点 $(x_t, y_t)$。一次完整的迭代，将状态从 $(x_t, y_t)$ 变换到 $(x_{t+1}, y_{t+1})$，包含两个相继的更新步骤：\n\n1.  首先，将 $x$ 坐标更新为一个值 $x'$，该值使得条件密度 $p(x | y=y_t)$ 最大化，同时保持 $y$ 坐标不变。此时状态变为 $(x', y_t)$。\n2.  接着，将 $y$ 坐标更新为一个值 $y_{t+1}$，该值使得条件密度 $p(y | x=x')$ 最大化，同时保持新的 $x$ 坐标不变。\n\n因此，一次完整迭代后的状态为 $(x_{t+1}, y_{t+1}) = (x', y_{t+1})$。\n\n目标概率分布 $p(x, y)$ 是一个针对两个无量纲变量 $X$ 和 $Y$ 的零均值二元正态分布。其协方差矩阵由下式给出：\n$$ \\Sigma = \\begin{pmatrix} \\sigma^2  \\rho \\sigma^2 \\\\ \\rho \\sigma^2  \\sigma^2 \\end{pmatrix} $$\n其中 $\\sigma > 0$ 是两个变量的标准差，$\\rho$ 是相关系数，满足 $0  \\rho  1$。\n\n对于高斯分布，其条件分布的众数与其均值重合。已知对于此特定的二元正态分布，其条件期望为 $E[X|Y=y] = \\rho y$ 和 $E[Y|X=x] = \\rho x$。\n\n算法在点 $(x_0, y_0) = (A, A)$ 处初始化，其中 $A$ 是一个非零实数常量。\n\n计算比率 $\\frac{D_1^2}{D_0^2}$，其中 $D_0^2$ 是初始点到众数 $(0,0)$ 的欧几里得距离的平方，$D_1^2$ 是算法经过一次完整迭代后，该点到众数的欧几里得距离的平方。将您的答案表示为关于 $\\rho$ 的符号表达式。", "solution": "目标密度是一个零均值的二元正态分布，其协方差矩阵为 $\\Sigma=\\sigma^{2}\\begin{pmatrix}1  \\rho \\\\ \\rho  1\\end{pmatrix}$，且 $0\\rho1$。对于高斯分布，条件众数等于条件均值。给定 $E[X\\mid Y=y]=\\rho y$ 和 $E[Y\\mid X=x]=\\rho x$，算法的更新步骤如下：\n1) 从 $(x_{0},y_{0})=(A,A)$ 开始，保持 $y=y_{0}$ 不变，更新 $x$ 坐标：\n$$x'=\\arg\\max_{x}p(x\\mid y=y_{0})=E[X\\mid Y=y_{0}]=\\rho y_{0}=\\rho A.$$\n2) 保持 $x=x'$ 不变，更新 $y$ 坐标：\n$$y_{1}=\\arg\\max_{y}p(y\\mid x=x')=E[Y\\mid X=x']=\\rho x'=\\rho(\\rho A)=\\rho^{2}A.$$\n经过一次完整迭代后，状态为 $(x_{1},y_{1})=(x',y_{1})=(\\rho A,\\rho^{2}A)$。\n\n初始点到众数 $(0,0)$ 的欧几里得距离的平方为\n$$D_{0}^{2}=x_{0}^{2}+y_{0}^{2}=A^{2}+A^{2}=2A^{2}.$$\n一次迭代后，距离的平方为\n$$D_{1}^{2}=x_{1}^{2}+y_{1}^{2}=(\\rho A)^{2}+(\\rho^{2}A)^{2}=A^{2}\\left(\\rho^{2}+\\rho^{4}\\right).$$\n因此，该比率为\n$$\\frac{D_{1}^{2}}{D_{0}^{2}}=\\frac{A^{2}\\left(\\rho^{2}+\\rho^{4}\\right)}{2A^{2}}=\\frac{\\rho^{2}+\\rho^{4}}{2}=\\frac{\\rho^{2}\\left(1+\\rho^{2}\\right)}{2}.$$", "answer": "$$\\boxed{\\frac{\\rho^{2}+\\rho^{4}}{2}}$$", "id": "1371718"}, {"introduction": "从理论计算到实际应用，这最后一个实践要求你构建一个完整的自适应 MCMC 采样器。在使用 Metropolis 算法时，一个关键的实际挑战是选择合适的提议步长；本练习将指导你使用随机近似的方法实现一个标准的自动化解决方案 [@problem_id:2411370]。这项任务将弥合像细致平衡这样的理论概念与构建稳健计算工具的实际需求之间的差距。", "problem": "实现一个自适应Metropolis随机游走马尔可夫链蒙特卡罗（MCMC）算法，该算法在预烧（burn-in）阶段调整一个标量提议步长，以达到并维持一个接近指定值的目标接受率。目标密度函数除一个归一化常数外是未知的。你的实现必须是一个完整的、可运行的程序，不接受任何输入，并打印所需的输出。该算法必须从基本原理出发进行论证：(i) 基于细致平衡条件的Metropolis-Hastings构造，以及 (ii) 为求解接受率的求根问题而采用的随机近似。目标是设计一个自适应方案，使其仅限于预烧阶段，并且在采样期间不改变平稳分布。\n\n从以下基本原理出发：\n- 具有平稳密度$\\pi(\\boldsymbol{x})$的马尔可夫链的转移核必须满足细致平衡，即对于所有状态$\\boldsymbol{x}$和$\\boldsymbol{y}$，$\\pi(\\boldsymbol{x}) P(\\boldsymbol{x},\\boldsymbol{y}) = \\pi(\\boldsymbol{y}) P(\\boldsymbol{y},\\boldsymbol{x})$。\n- 在使用提议密度$q(\\boldsymbol{y}\\mid \\boldsymbol{x})$的Metropolis-Hastings构造中，必须选择接受概率以使细致平衡成立。\n- 在自适应方案中，预烧期间的参数更新可以看作是使用递减步长来解决形式为$\\mathbb{E}[h(\\theta)] = 0$的方程的随机近似。\n\n你的任务是：\n1) 从细致平衡条件出发，推导对称高斯随机游走提议$q(\\boldsymbol{y}\\mid \\boldsymbol{x}) = \\mathcal{N}(\\boldsymbol{x}, \\sigma^2 \\mathbf{I}_d)$的Metropolis-Hastings接受概率，并在你的代码中实现它。你必须在你的解决方案中从细致平衡出发论证该接受公式，而不依赖任何未经证明的简化公式。\n2) 推导并实现一种Robbins-Monro型随机近似方法，在预烧期内根据一个递减的步长序列，在第$n$次迭代时更新对数步长$\\theta = \\log \\sigma$。目标是驱动期望接受概率趋向目标值$a^\\star$。你的更新必须在对数尺度上进行以保持$\\sigma$的正性，必须使用形式为$\\gamma_n = c/(n+t_0)$（其中$c > 0$和$t_0 \\ge 0$是常数）的递减增益，并且必须严格限制在预烧阶段。在你的解决方案中清楚地说明选择此方法的原因。\n3) 预烧结束后，冻结已调整的$\\sigma$并生成样本。仅计算采样阶段的经验接受率。所有接受率必须以单位区间内的小数形式报告。\n\n你必须在以下测试集上实现并测试你的程序。每个测试都指定了目标分布、维度、初始条件和随机种子。为保证可复现性，请使用指定的种子。所有情况下的目标接受率均为$a^\\star = 0.23$。\n\n- 测试A（一维标准高斯分布）：\n  - 维度 $d = 1$。\n  - 目标对数密度：$\\log \\pi(x) = -\\tfrac{1}{2} x^2$。\n  - 初始位置：$x_0 = 0$。\n  - 初始步长：$\\sigma_0 = 0.001$。\n  - 预烧迭代次数：$N_{\\mathrm{burn}} = 6000$。\n  - 采样迭代次数：$N_{\\mathrm{sample}} = 12000$。\n  - 随机种子：$42$。\n\n- 测试B（五维相关高斯分布）：\n  - 维度 $d = 5$。\n  - 目标密度：$\\pi(\\boldsymbol{x}) \\propto \\exp\\!\\left(-\\tfrac{1}{2}\\boldsymbol{x}^\\top \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{x}\\right)$，其中$\\Sigma_{ij} = \\rho^{|i-j|}$且$\\rho = 0.8$。\n  - 初始位置：$\\boldsymbol{x}_0 = \\boldsymbol{0}$。\n  - 初始步长：$\\sigma_0 = 10$。\n  - 预烧迭代次数：$N_{\\mathrm{burn}} = 8000$。\n  - 采样迭代次数：$N_{\\mathrm{sample}} = 12000$。\n  - 随机种子：$123$。\n\n- 测试C（软化曲率的二维Rosenbrock目标函数）：\n  - 维度 $d = 2$。\n  - 定义势能 $U(x_1,x_2) = 100\\,(x_2 - x_1^2)^2 + (1 - x_1)^2$。\n  - 目标密度：$\\pi(\\boldsymbol{x}) \\propto \\exp\\!\\left(-U(x_1,x_2)/20\\right)$。\n  - 初始位置：$\\boldsymbol{x}_0 = (0,\\,0)$。\n  - 初始步长：$\\sigma_0 = 1$。\n  - 预烧迭代次数：$N_{\\mathrm{burn}} = 12000$。\n  - 采样迭代次数：$N_{\\mathrm{sample}} = 12000$。\n  - 随机种子：$2024$。\n\n算法要求：\n- 使用高斯随机游走提议$\\boldsymbol{y} = \\boldsymbol{x} + \\sigma \\boldsymbol{\\eta}$，其中$\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$。\n- 仅在预烧期间，通过一个Robbins-Monro步骤在每次提议时更新$\\theta_n = \\log \\sigma_n$，步长为$\\gamma_n = c/(n + t_0)$（其中$c$和$t_0$为固定常数），并使用该步骤观察到的接受概率。\n- 预烧结束后，固定$\\sigma$并继续采样，不再进行任何自适应调整。\n- 为保证稳定性，你可以将$\\theta_n$限制在一个较宽的区间内，以使$\\sigma_n$保持有限。\n\n输出规范：\n- 对每个测试，仅计算$N_{\\mathrm{sample}}$次采样迭代的经验接受率。\n- 你的程序必须打印一行，包含一个列表，其中按A、B、C的顺序列出3个接受率，每个接受率四舍五入到三位小数，以小数形式（无百分号）表示，格式严格为：$[\\text{r}_A,\\text{r}_B,\\text{r}_C]$。\n\n此问题不涉及任何物理单位或角度单位。所有数值答案必须是小数。在给定种子的情况下，输出必须是确定性的。最终程序必须是完整的、可直接运行的，无需输入，且不得访问任何外部资源。", "solution": "任务是实现一个自适应Metropolis随机游走马尔可夫链蒙特卡罗（MCMC）算法。该算法必须在预烧（burn-in）阶段调整其标量提议步长$\\sigma$，以达到一个指定的目标接受率$a^\\star$。该算法的理论基础——Metropolis-Hastings接受规则和用于自适应的Robbins-Monro随机近似——必须从第一性原理推导。\n\n### 问题验证\n\n首先，我们验证问题陈述。\n\n#### 步骤1：提取给定信息\n\n- **基本原理**：\n    - 细致平衡：$\\pi(\\boldsymbol{x}) P(\\boldsymbol{x},\\boldsymbol{y}) = \\pi(\\boldsymbol{y}) P(\\boldsymbol{y},\\boldsymbol{x})$。\n    - Metropolis-Hastings (M-H) 构造：转移核$P(\\boldsymbol{x},\\boldsymbol{y})$由提议密度$q(\\boldsymbol{y}\\mid \\boldsymbol{x})$和接受概率$\\alpha(\\boldsymbol{x},\\boldsymbol{y})$构成。\n    - 随机近似：参数更新遵循一个方案，以递减的步长解决$\\mathbb{E}[h(\\theta)] = 0$。\n\n- **任务**：\n    1.  从细致平衡推导对称高斯随机游走提议$q(\\boldsymbol{y}\\mid \\boldsymbol{x}) = \\mathcal{N}(\\boldsymbol{x}, \\sigma^2 \\mathbf{I}_d)$的M-H接受概率。\n    2.  推导并实现一个Robbins-Monro更新规则，用于更新对数步长$\\theta = \\log \\sigma$，以使接受率趋向目标$a^\\star$。更新必须使用增益$\\gamma_n = c/(n+t_0)$且仅限于预烧阶段。\n    3.  实现完整算法，在预烧后固定$\\sigma$，并计算采样阶段的经验接受率。\n\n- **算法要求**：\n    - 提议：高斯随机游走$\\boldsymbol{y} = \\boldsymbol{x} + \\sigma \\boldsymbol{\\eta}$，其中$\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$。\n    - 自适应：仅在预烧期间，通过Robbins-Monro方法更新$\\theta_n = \\log \\sigma_n$，增益为$\\gamma_n = c/(n+t_0)$。\n    - 采样：预烧后固定$\\sigma$。\n    - 目标接受率：所有测试中$a^\\star = 0.23$。\n\n- **测试用例**：\n    - **测试A**：$d=1$，对数密度$\\log \\pi(x) = -\\tfrac{1}{2} x^2$，$x_0 = 0$，$\\sigma_0 = 0.001$，$N_{\\mathrm{burn}} = 6000$，$N_{\\mathrm{sample}} = 12000$，种子$42$。\n    - **测试B**：$d=5$，$\\pi(\\boldsymbol{x}) \\propto \\exp(-\\tfrac{1}{2}\\boldsymbol{x}^\\top \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{x})$，其中$\\Sigma_{ij} = \\rho^{|i-j|}$且$\\rho = 0.8$，$\\boldsymbol{x}_0 = \\boldsymbol{0}$，$\\sigma_0 = 10$，$N_{\\mathrm{burn}} = 8000$，$N_{\\mathrm{sample}} = 12000$，种子$123$。\n    - **测试C**：$d=2$，$\\pi(\\boldsymbol{x}) \\propto \\exp(-U(x_1,x_2)/20)$，其中$U(x_1,x_2) = 100(x_2 - x_1^2)^2 + (1 - x_1)^2$，$\\boldsymbol{x}_0 = (0,0)$，$\\sigma_0 = 1$，$N_{\\mathrm{burn}} = 12000$，$N_{\\mathrm{sample}} = 12000$，种子$2024$。\n\n- **输出规范**：一行包含一个列表，其中有三个接受率，分别对应测试A、B、C，四舍五入到三位小数：$[\\text{r}_A,\\text{r}_B,\\text{r}_C]$。\n\n#### 步骤2：使用提取的给定信息进行验证\n\n根据验证标准对问题进行审查。\n- **科学性**：该问题基于计算统计学和物理学中已确立的基本原理，即MCMC理论、细致平衡和随机近似。目标分布是该领域的标准基准。问题不含伪科学。\n- **良构性**：目标明确，每个测试用例的所有必要参数（维度、目标密度、初始条件、迭代次数、随机种子）都已指定。输出格式定义精确。给定种子后问题是确定性的。预期会有一个唯一的、有意义的解。Robbins-Monro常数$c$和$t_0$的选择留给实现者，这是一个标准的设计决策，而非缺陷。\n- **客观性**：语言技术性强、精确且无歧义。没有主观或基于意见的陈述。\n\n问题是自洽的、一致的且科学上合理的。未发现任何缺陷。\n\n#### 步骤3：结论与行动\n\n问题有效。我们继续进行求解。\n\n### 推导与算法设计\n\n#### 1. Metropolis-Hastings接受概率\n\n目标是构造一个具有平稳分布$\\pi(\\boldsymbol{x})$的马尔可夫链。转移核$P(\\boldsymbol{x}, \\boldsymbol{y})$给出了从状态$\\boldsymbol{x}$移动到$\\boldsymbol{y}$的概率密度，它必须满足细致平衡条件：\n$$\n\\pi(\\boldsymbol{x}) P(\\boldsymbol{x}, \\boldsymbol{y}) = \\pi(\\boldsymbol{y}) P(\\boldsymbol{y}, \\boldsymbol{x})\n$$\n在Metropolis-Hastings框架中，转移是一个两步过程：从一个提议密度$q(\\boldsymbol{y} \\mid \\boldsymbol{x})$中提议一个新状态$\\boldsymbol{y}$，然后以概率$\\alpha(\\boldsymbol{x}, \\boldsymbol{y})$接受它。对于$\\boldsymbol{x} \\neq \\boldsymbol{y}$，转移核为$P(\\boldsymbol{x}, \\boldsymbol{y}) = q(\\boldsymbol{y} \\mid \\boldsymbol{x}) \\alpha(\\boldsymbol{x}, \\boldsymbol{y})$。将此代入细致平衡方程得到：\n$$\n\\pi(\\boldsymbol{x}) q(\\boldsymbol{y} \\mid \\boldsymbol{x}) \\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\pi(\\boldsymbol{y}) q(\\boldsymbol{x} \\mid \\boldsymbol{y}) \\alpha(\\boldsymbol{y}, \\boldsymbol{x})\n$$\n这导致对接受概率比率的以下约束：\n$$\n\\frac{\\alpha(\\boldsymbol{x}, \\boldsymbol{y})}{\\alpha(\\boldsymbol{y}, \\boldsymbol{x})} = \\frac{\\pi(\\boldsymbol{y}) q(\\boldsymbol{x} \\mid \\boldsymbol{y})}{\\pi(\\boldsymbol{x}) q(\\boldsymbol{y} \\mid \\boldsymbol{x})}\n$$\n满足此条件的标准Metropolis接受概率选择是：\n$$\n\\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\min\\left(1, \\frac{\\pi(\\boldsymbol{y}) q(\\boldsymbol{x} \\mid \\boldsymbol{y})}{\\pi(\\boldsymbol{x}) q(\\boldsymbol{y} \\mid \\boldsymbol{x})}\\right)\n$$\n问题指定了一个对称高斯随机游走提议：$\\boldsymbol{y} \\sim \\mathcal{N}(\\boldsymbol{x}, \\sigma^2 \\mathbf{I}_d)$。其提议密度为：\n$$\nq(\\boldsymbol{y} \\mid \\boldsymbol{x}) = \\frac{1}{(2\\pi\\sigma^2)^{d/2}} \\exp\\left(-\\frac{1}{2\\sigma^2} (\\boldsymbol{y}-\\boldsymbol{x})^\\top (\\boldsymbol{y}-\\boldsymbol{x})\\right)\n$$\n由于项$(\\boldsymbol{y}-\\boldsymbol{x})^\\top (\\boldsymbol{y}-\\boldsymbol{x}) = (\\boldsymbol{x}-\\boldsymbol{y})^\\top (\\boldsymbol{x}-\\boldsymbol{y})$，该提议是对称的，即$q(\\boldsymbol{y} \\mid \\boldsymbol{x}) = q(\\boldsymbol{x} \\mid \\boldsymbol{y})$。接受率比率中的提议项相互抵消，得到简化的Metropolis接受概率：\n$$\n\\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\min\\left(1, \\frac{\\pi(\\boldsymbol{y})}{\\pi(\\boldsymbol{x})}\\right)\n$$\n由于目标密度$\\pi(\\boldsymbol{x})$通常只知道到归一化常数为止，我们使用未归一化的密度或更稳定地使用其对数来计算此比率：\n$$\n\\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\min\\left(1, \\exp\\left(\\log\\pi(\\boldsymbol{y}) - \\log\\pi(\\boldsymbol{x})\\right)\\right)\n$$\n这就是要实现的公式。\n\n#### 2. 使用随机近似的自适应步长\n\n目标是调整提议步长$\\sigma$，使得期望接受率与目标值$a^\\star$匹配。令$\\theta = \\log \\sigma$为要调整的参数。更新在预烧阶段执行。我们希望找到函数$g(\\theta) = \\mathbb{E}[\\alpha(\\theta)] - a^\\star$的根，其中$\\alpha(\\theta)$是给定$\\theta$时的接受概率。\n\nRobbins-Monro算法是一种随机求根方法。对于一个函数$g(\\theta)$，我们可以使用迭代方案$\\theta_{n+1} = \\theta_n - \\gamma_n g_n(\\theta_n)$来找到它的根，其中$g_n$是第$n$步对$g$的带噪声观测，而$\\{\\gamma_n\\}$是满足$\\sum \\gamma_n = \\infty$和$\\sum \\gamma_n^2  \\infty$的步长序列。\n\n在我们的情况下，我们在第$n$次迭代观察接受概率$\\alpha_n$，并将其用作我们的带噪声测量。$\\theta_n = \\log\\sigma_n$的更新规则被制定为引导观察到的接受率趋向$a^\\star$：\n$$\n\\theta_{n+1} = \\theta_n + \\gamma_n (\\alpha_n - a^\\star)\n$$\n符号为正，因为如果当前接受率$\\alpha_n$高于目标$a^\\star$，我们需要增加$\\theta$（从而增加$\\sigma$），使提议更大胆，从而降低接受率。反之，如果$\\alpha_n  a^\\star$，我们减小$\\theta$，使提议更保守，从而提高接受率。\n\n步长序列（增益）给定为$\\gamma_n = c/(n + t_0)$，其中$n \\geq 1$。我们将选择$c=1.0$和$t_0=10.0$作为合理的常数，以确保稳定性和有效的自适应。在对数尺度上更新$\\theta = \\log\\sigma$自然地保证了$\\sigma = \\exp(\\theta)$保持为正。\n\n这种自适应方案使得马尔可夫链非齐次。为保证样本是从正确的平稳分布$\\pi(\\boldsymbol{x})$中抽取的，自适应必须在预烧阶段结束后终止。在$N_{\\mathrm{burn}}$次迭代后，步长$\\sigma$被冻结在其最终的适应值，随后的$N_{\\mathrm{sample}}$次迭代则作为标准的齐次Metropolis MCMC算法进行。马尔可夫链的遍历定理保证了从这些样本计算的平均值会收敛到关于$\\pi(\\boldsymbol{x})$的期望。\n\n### 实现计划\n\n算法将在一个函数中实现，该函数接受测试用例的参数。对于从$n=1$到$N_{\\mathrm{burn}} + N_{\\mathrm{sample}}$的每次迭代：\n1.  生成一个提议$\\boldsymbol{y} = \\boldsymbol{x}_{\\text{current}} + \\sigma_n \\boldsymbol{\\eta}$，其中$\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$。\n2.  计算$\\alpha = \\min\\left(1, \\exp\\left(\\log\\pi(\\boldsymbol{y}) - \\log\\pi(\\boldsymbol{x}_{\\text{current}})\\right)\\right)$。\n3.  从$U(0,1)$中抽取一个数$u$。如果$u  \\alpha$，则设置$\\boldsymbol{x}_{\\text{next}} = \\boldsymbol{y}$并记录一次接受。否则，设置$\\boldsymbol{x}_{\\text{next}} = \\boldsymbol{x}_{\\text{current}}$。\n4.  如果$n \\le N_{\\mathrm{burn}}$：\n    - 使用Robbins-Monro步骤更新$\\log \\sigma_n$：$\\log\\sigma_{n+1} = \\log\\sigma_n + \\gamma_n (\\alpha - a^\\star)$。\n    - 为保证鲁棒性，我们会将$\\log\\sigma$裁剪到一个合理的范围，例如$[-10, 10]$。\n5.  如果$n  N_{\\mathrm{burn}}$：\n    - 保持$\\sigma$固定。\n    - 统计接受次数，以计算采样阶段的最终经验接受率。\n\n此过程将应用于三个测试用例中的每一个，使用指定的参数和随机种子。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n\n    def run_adaptive_mcmc(log_target_density, x0, sigma0, d, N_burn, N_sample, seed, a_star, c, t0):\n        \"\"\"\n        Runs the adaptive Metropolis MCMC algorithm for a single test case.\n\n        Args:\n            log_target_density (function): Function that computes the log of the target density.\n            x0 (np.ndarray): Initial position.\n            sigma0 (float): Initial proposal step size.\n            d (int): Dimension of the state space.\n            N_burn (int): Number of burn-in iterations.\n            N_sample (int): Number of sampling iterations.\n            seed (int): Random seed for reproducibility.\n            a_star (float): Target acceptance rate.\n            c (float): Parameter for the Robbins-Monro gain.\n            t0 (float): Parameter for the Robbins-Monro gain.\n        \n        Returns:\n            float: The empirical acceptance rate during the sampling phase.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        \n        x_current = np.array(x0, dtype=float)\n        log_sigma = np.log(sigma0)\n        \n        log_pi_current = log_target_density(x_current)\n        \n        accepted_in_sampling = 0\n        total_iterations = N_burn + N_sample\n\n        for n in range(1, total_iterations + 1):\n            sigma = np.exp(log_sigma)\n            \n            # 1. Propose a new state\n            proposal = x_current + sigma * rng.normal(size=d)\n            \n            # 2. Compute acceptance probability\n            log_pi_proposal = log_target_density(proposal)\n            log_alpha = log_pi_proposal - log_pi_current\n            alpha = min(1.0, np.exp(log_alpha))\n\n            # 3. Accept or reject the proposal\n            if rng.uniform()  alpha:\n                x_current = proposal\n                log_pi_current = log_pi_proposal\n                accepted = True\n            else:\n                accepted = False\n\n            # 4. Adaptation during burn-in\n            if n = N_burn:\n                gamma_n = c / (n + t0)\n                log_sigma = log_sigma + gamma_n * (alpha - a_star)\n                # For stability, constrain log_sigma to a broad interval\n                log_sigma = np.clip(log_sigma, -10.0, 10.0)\n            # 5. Tally acceptances during sampling\n            else:\n                if accepted:\n                    accepted_in_sampling += 1\n                    \n        return accepted_in_sampling / N_sample\n\n    # Common parameters\n    target_acceptance_rate = 0.23\n    # Robbins-Monro parameters (chosen based on common practice)\n    c_rm = 1.0\n    t0_rm = 10.0\n\n    # Test Case A: 1D Standard Gaussian\n    def log_pi_A(x):\n        return -0.5 * x[0]**2\n        \n    rate_A = run_adaptive_mcmc(\n        log_target_density=log_pi_A,\n        x0=[0.0],\n        sigma0=0.001,\n        d=1,\n        N_burn=6000,\n        N_sample=12000,\n        seed=42,\n        a_star=target_acceptance_rate,\n        c=c_rm,\n        t0=t0_rm\n    )\n\n    # Test Case B: 5D Correlated Gaussian\n    d_B = 5\n    rho_B = 0.8\n    sigma_matrix_B = np.array([[rho_B**abs(i - j) for j in range(d_B)] for i in range(d_B)])\n    sigma_inv_B = np.linalg.inv(sigma_matrix_B)\n    def log_pi_B(x):\n        return -0.5 * x @ sigma_inv_B @ x\n\n    rate_B = run_adaptive_mcmc(\n        log_target_density=log_pi_B,\n        x0=np.zeros(d_B),\n        sigma0=10.0,\n        d=d_B,\n        N_burn=8000,\n        N_sample=12000,\n        seed=123,\n        a_star=target_acceptance_rate,\n        c=c_rm,\n        t0=t0_rm\n    )\n\n    # Test Case C: 2D Softened Rosenbrock\n    def log_pi_C(x):\n        U = 100.0 * (x[1] - x[0]**2)**2 + (1.0 - x[0])**2\n        return -U / 20.0\n\n    rate_C = run_adaptive_mcmc(\n        log_target_density=log_pi_C,\n        x0=[0.0, 0.0],\n        sigma0=1.0,\n        d=2,\n        N_burn=12000,\n        N_sample=12000,\n        seed=2024,\n        a_star=target_acceptance_rate,\n        c=c_rm,\n        t0=t0_rm\n    )\n\n    results = [rate_A, rate_B, rate_C]\n    \n    # Format the final output string exactly as specified.\n    results_str = ','.join(f\"{r:.3f}\" for r in results)\n    print(f\"[{results_str}]\")\n\nsolve()\n```", "id": "2411370"}]}