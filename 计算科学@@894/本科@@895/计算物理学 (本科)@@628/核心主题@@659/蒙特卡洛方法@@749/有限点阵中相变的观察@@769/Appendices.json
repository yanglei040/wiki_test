{"hands_on_practices": [{"introduction": "许多物理系统的相变现象都可以用伊辛模型（Ising model）来捕捉其本质。对于小尺寸的晶格，我们可以通过精确枚举所有可能的自旋构型来彻底避免近似，从而直接计算系统的热力学性质。这个练习将引导我们探索一个深刻的问题：系统的拓扑结构如何影响其宏观物理表现 [@problem_id:2422307]。我们将计算并比较两种不同拓扑结构——圆柱体（cylinder）和莫比乌斯带（Möbius strip）——上的伊辛模型的磁化率 $\\chi$，亲身体验边界条件如何对相变行为产生微妙而重要的影响。", "problem": "考虑一个二维伊辛模型，其自旋 $s_{x,y} \\in \\{+1,-1\\}$ 分布在一个矩形 $L_x \\times L_y$ 晶格上，哈密顿量为\n$$\nH(\\{s\\}) \\;=\\; -J \\sum_{\\langle i,j\\rangle} s_i s_j,\n$$\n其中 $J>0$，求和遍历由晶格拓扑结构定义的所有最近邻对。在零外场下进行计算，并使用玻尔兹曼常数 $k_{\\mathrm{B}}=1$ 的单位制。在温度 $T$ 下，一个构型 $\\{s\\}$ 的平衡（正则）概率正比于 $\\exp(-\\beta H)$，其中 $\\beta = 1/T$。总磁化强度为 $M(\\{s\\})=\\sum_{x=0}^{L_x-1}\\sum_{y=0}^{L_y-1} s_{x,y}$，单位自旋的磁化率定义为\n$$\n\\chi(T) \\;=\\; \\frac{\\beta}{N} \\left( \\langle M^2 \\rangle - \\langle M \\rangle^2 \\right),\n$$\n其中 $N=L_x L_y$ 且 $\\langle \\cdot \\rangle$ 表示正则系综平均。\n\n在同一个 $L_x \\times L_y$ 网格上定义两种拓扑结构：\n\n- 圆柱面：$x$ 方向为开放边界，$y$ 方向为周期性边界。最近邻键的集合由以下两类键构成：对所有满足 $0 \\le x < L_x-1$ 和 $0 \\le y < L_y$ 的情况，存在对 $\\big((x,y),(x+1,y)\\big)$；以及对所有 $x$ 和 $y$，存在对 $\\big((x,y),(x, y')\\big)$，其中 $y'=(y+1)\\pmod L_y$。\n\n- 莫比乌斯带：$x$ 方向为开放边界，$y$ 方向为扭曲的周期性边界。最近邻键的集合由以下两类键构成：对所有满足 $0 \\le x < L_x-1$ 和 $0 \\le y < L_y$ 的情况，存在对 $\\big((x,y),(x+1,y)\\big)$；以及对所有 $x$ 和 $y$，存在对 $\\big((x,y),(x', y')\\big)$，其中若 $y+1<L_y$，则 $(x',y')=(x,y+1)$，若 $y+1=L_y$，则 $(x',y')=(L_x-1-x,0)$。\n\n仅使用上述定义（无近似），通过对所有自旋构型求和来精确计算正则系综，从而计算两种拓扑结构的磁化率 $\\chi$。设 $J=1$，并将温度 $T$ 以无量纲单位表示（因为 $k_{\\mathrm{B}}=1$ 且 $J=1$），其中 $\\beta=1/T$。\n\n测试套件：\n对于以下每一组参数 $(L_x,L_y,T)$，计算两个数值：$\\chi_{\\mathrm{Mobius}}(T)$ 和 $\\chi_{\\mathrm{Cylinder}}(T)$。\n\n- 情况 A：$L_x=4$, $L_y=3$, $T=2.30$。\n- 情况 B：$L_x=5$, $L_y=3$, $T=1.80$。\n- 情况 C：$L_x=4$, $L_y=4$, $T=4.00$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个逗号分隔的扁平列表，按\n$$\n\\big[\\chi_{\\mathrm{Mobius}}^{\\mathrm{A}},\\;\\chi_{\\mathrm{Cylinder}}^{\\mathrm{A}},\\;\\chi_{\\mathrm{Mobius}}^{\\mathrm{B}},\\;\\chi_{\\mathrm{Cylinder}}^{\\mathrm{B}},\\;\\chi_{\\mathrm{Mobius}}^{\\mathrm{C}},\\;\\chi_{\\mathrm{Cylinder}}^{\\mathrm{C}}\\big]\n$$\n的顺序排列六个磁化率值，四舍五入到恰好 $6$ 位小数，并用方括号括起来。例如：$[\\chi_1,\\chi_2,\\chi_3,\\chi_4,\\chi_5,\\chi_6]$。", "solution": "问题陈述经评估有效。这是一个在计算统计力学中定义明确的问题，没有科学或逻辑上的缺陷，并为获得唯一解提供了所有必要信息。对于给定的晶格尺寸，所指定的精确枚举方法在计算上是可行的。\n\n单位自旋的磁化率 $\\chi(T)$ 定义为\n$$\n\\chi(T) = \\frac{\\beta}{N} \\left( \\langle M^2 \\rangle - \\langle M \\rangle^2 \\right),\n$$\n其中 $N=L_x L_y$ 是自旋总数，$\\beta = 1/T$（$k_{\\mathrm{B}}=1$），$M$ 是总磁化强度，$\\langle \\cdot \\rangle$ 表示正则系综平均。一个可观测量 $O$ 的正则系综平均由下式给出\n$$\n\\langle O \\rangle = \\frac{\\sum_{\\{s\\}} O(\\{s\\}) e^{-\\beta H(\\{s\\})}}{Z},\n$$\n其中求和遍历所有 $2^N$ 个自旋构型 $\\{s\\}$，$Z = \\sum_{\\{s\\}} e^{-\\beta H(\\{s\\})}$ 是配分函数。\n\n哈密顿量 $H(\\{s\\}) = -J \\sum_{\\langle i,j\\rangle} s_i s_j$ 在全局自旋翻转变换（即所有自旋 $\\{s_k\\}$ 变为 $\\{-s_k\\}$）下保持不变。这对圆柱面和莫比乌斯带拓扑都成立，因为最近邻对的集合是固定的。在此变换下，能量 $H$ 不变，而磁化强度反号，$M \\to -M$。因此，对于每一个磁化强度为 $M$ 的构型，都存在一个磁化强度为 $-M$ 的简并构型。计算 $\\langle M \\rangle$ 的求和可以写成对此类构型对的求和：\n$$\n\\sum_{\\{s\\} \\text{ pairs}} \\left( M e^{-\\beta H} + (-M) e^{-\\beta H} \\right) = 0.\n$$\n因此，对于任何温度，平均磁化强度 $\\langle M \\rangle$ 都严格为零。磁化率的表达式简化为\n$$\n\\chi(T) = \\frac{\\beta}{N} \\langle M^2 \\rangle.\n$$\n为了计算 $\\chi(T)$，我们必须通过对所有 $2^N$ 个自旋构型求和来计算 $\\langle M^2 \\rangle$。这是一种精确枚举方法。算法如下：\n\n1.  对于一个大小为 $N=L_x \\times L_y$ 的给定晶格，存在 $2^N$ 个唯一的自旋构型。我们可以通过将每个构型映射到范围在 $[0, 2^N-1]$ 内的整数 $i$ 来系统地生成它们。第 $k$ 个自旋的状态 $s_k \\in \\{+1, -1\\}$ 由 $i$ 的二进制表示中的第 $k$ 位决定。例如，一个映射可以是 $s_k = 2 \\cdot (i \\text{ 的第 } k \\text{ 位}) - 1$。一维自旋索引 $k \\in [0, N-1]$ 通过 $k = y \\cdot L_x + x$ 映射到二维晶格坐标 $(x,y)$。\n\n2.  定义模型的关键要素是晶格拓扑，它决定了哈密顿量求和中使用的最近邻对 $\\langle i,j \\rangle$ 的集合。我们为每种指定的拓扑生成一个唯一的键的确定性列表。\n    *   对于**圆柱面**拓扑（$L_x \\times L_y$），键定义如下：\n        *   水平连接：对 $((x,y), (x+1,y))$，其中 $0 \\le x < L_x-1$ 且 $0 \\le y < L_y$。\n        *   带周期性边界的垂直连接：对 $((x,y), (x, (y+1) \\pmod{L_y}))$，其中 $0 \\le x < L_x$ 且 $0 \\le y < L_y$。\n    *   对于**莫比乌斯带**拓扑，键为：\n        *   水平连接：与圆柱面相同。\n        *   带扭曲的垂直连接：对 $((x,y), (x,y+1))$，其中 $0 \\le y < L_y-1$；以及一个特定的扭曲连接，用于连接自旋的边界列，将格点 $(x, L_y-1)$ 与格点 $(L_x-1-x, 0)$ 相连，适用于所有 $x \\in [0, L_x-1]$。\n\n3.  建立键列表后，我们遍历所有 $2^N$ 个构型。对于每个构型 $\\{s\\}$，我们计算：\n    *   总磁化强度：$M(\\{s\\}) = \\sum_{k=0}^{N-1} s_k$。\n    *   总能量：$H(\\{s\\}) = -J \\sum_{\\langle i,j \\rangle} s_i s_j$。给定 $J=1$。\n\n4.  然后我们计算遍历所有构型的所需总和：\n    *   配分函数和 $Z_{\\text{sum}} = \\sum_{\\{s\\}} \\exp(-\\beta H(\\{s\\}))$。\n    *   磁化强度二阶矩的和 $S_{M^2} = \\sum_{\\{s\\}} M(\\{s\\})^2 \\exp(-\\beta H(\\{s\\}))$。\n\n5.  如果 $-\\beta H$ 是一个大的正数，计算玻尔兹曼因子 $\\exp(-\\beta H)$ 可能会导致数值溢出。为确保稳定性，我们首先找到所有构型中的最小能量 $H_{\\min} = \\min_{\\{s\\}} H(\\{s\\})$。然后我们计算数值稳定的权重 $w_s = \\exp(-\\beta(H(\\{s\\}) - H_{\\min}))$。因子 $\\exp(\\beta H_{\\min})$ 是 $\\langle M^2 \\rangle$ 的分子和分母中所有项的公因子，因此可以消去：\n    $$\n    \\langle M^2 \\rangle = \\frac{\\sum_{\\{s\\}} M^2(\\{s\\}) w_s}{\\sum_{\\{s\\}} w_s} = \\frac{S_{M^2}}{Z_{\\text{sum}}}.\n    $$\n\n6.  最后，使用简化公式计算磁化率：$\\chi(T) = \\frac{\\beta}{N} \\langle M^2 \\rangle$。\n\n所提供的代码实现了这一精确算法。它为给定的拓扑结构生成所有自旋构型及其对应的磁化强度和能量。然后，它使用这些数据来计算配分函数和以及磁化强度平方的热平均值，从而得到最终的磁化率值。对测试套件中的每组参数和每种拓扑结构，都重复此过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef get_bonds(Lx, Ly, topology):\n    \"\"\"\n    Generates the list of unique nearest-neighbor bonds for a given topology.\n\n    Args:\n        Lx (int): Lattice size in the x-direction.\n        Ly (int): Lattice size in the y-direction.\n        topology (str): 'cylinder' or 'mobius'.\n\n    Returns:\n        list: A list of tuples, where each tuple represents a bond (pair of site indices).\n    \"\"\"\n    bonds = set()\n\n    def add_bond(i, j):\n        bonds.add(tuple(sorted((i, j))))\n\n    def get_idx(x, y):\n        return y * Lx + x\n\n    # Horizontal bonds (common to both topologies)\n    for y in range(Ly):\n        for x in range(Lx - 1):\n            add_bond(get_idx(x, y), get_idx(x + 1, y))\n\n    # Vertical bonds (topology-dependent)\n    if topology == 'cylinder':\n        for x in range(Lx):\n            for y in range(Ly):\n                add_bond(get_idx(x, y), get_idx(x, (y + 1) % Ly))\n    elif topology == 'mobius':\n        for x in range(Lx):\n            # Normal vertical bonds for y < Ly-1\n            for y in range(Ly - 1):\n                add_bond(get_idx(x, y), get_idx(x, y + 1))\n            # Twisted bonds connecting y=Ly-1 to y=0\n            add_bond(get_idx(x, Ly - 1), get_idx(Lx - 1 - x, 0))\n    \n    return list(bonds)\n\ndef calculate_chi(Lx, Ly, T, topology):\n    \"\"\"\n    Computes the magnetic susceptibility per spin for the 2D Ising model\n    by exact enumeration of all spin configurations.\n\n    Args:\n        Lx (int): Lattice size in the x-direction.\n        Ly (int): Lattice size in the y-direction.\n        T (float): Temperature.\n        topology (str): The lattice topology, 'cylinder' or 'mobius'.\n\n    Returns:\n        float: The calculated magnetic susceptibility per spin.\n    \"\"\"\n    N = Lx * Ly\n    beta = 1.0 / T\n    J = 1.0\n    \n    bonds = get_bonds(Lx, Ly, topology)\n    \n    num_configs = 1 << N\n    \n    # 1. Generate all 2^N spin configurations using numpy broadcasting.\n    # Each row is a configuration, each column is a spin site.\n    # The value is +1 or -1.\n    i_vals = np.arange(num_configs, dtype=np.uint32)\n    k_vals = np.arange(N, dtype=np.uint8)\n    spins = (((i_vals[:, None] >> k_vals[None, :]) & 1) * 2 - 1).astype(np.int8)\n\n    # 2. Calculate magnetization M for each configuration.\n    magnetizations = np.sum(spins, axis=1, dtype=np.int32)\n\n    # 3. Calculate energy H for each configuration.\n    energies = np.zeros(num_configs, dtype=np.float64)\n    for idx1, idx2 in bonds:\n        energies -= spins[:, idx1] * spins[:, idx2]\n    energies *= J\n\n    # 4. Compute sums for <M^2> using numerically stable weights.\n    # Find minimum energy to prevent overflow in exp.\n    H_min = np.min(energies)\n    shifted_energies = energies - H_min\n    weights = np.exp(-beta * shifted_energies)\n    \n    # Partition function sum\n    Z_sum = np.sum(weights)\n    \n    # Thermal sum for M^2\n    M2_sum = np.sum(magnetizations**2 * weights)\n    \n    # 5. Calculate susceptibility.\n    # <M> = 0 due to spin-flip symmetry.\n    mean_M2 = M2_sum / Z_sum\n    chi = (beta / N) * mean_M2\n    \n    return chi\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (4, 3, 2.30),  # Case A\n        (5, 3, 1.80),  # Case B\n        (4, 4, 4.00),  # Case C\n    ]\n\n    results = []\n    for Lx, Ly, T in test_cases:\n        chi_mobius = calculate_chi(Lx, Ly, T, 'mobius')\n        chi_cylinder = calculate_chi(Lx, Ly, T, 'cylinder')\n        results.append(chi_mobius)\n        results.append(chi_cylinder)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```", "id": "2422307"}, {"introduction": "在上一个练习的基础上，我们继续使用精确枚举方法来研究伊辛模型，但这次将采用一个更为深刻和优雅的视角：李-杨理论（Lee-Yang theory）。该理论揭示了相变与配分函数在复平面上的零点（称为李-杨零点）之间的惊人联系。在这个实践中，我们将不再通过观察磁化率的峰值来寻找临界温度 $T_c$，而是通过计算配分函数多项式的复数根，找到使这些零点最接近实轴的温度[@problem_id:2422394]。这个方法为我们提供了一个全新的维度来理解和定位相变。", "problem": "您需要实现一个完整、可运行的程序，该程序使用复逸度平面中配分函数的 Lee-Yang 零点，在小型有限晶格上估算二维 (2D) 铁磁 Ising 模型的临界温度 $T_c$。该程序必须枚举自旋构型以将配分函数构建为复逸度 $z$ 的多项式，然后通过定位某个温度来估算 $T_c$，在该温度下，与正实轴角距离最小的 Lee-Yang 零点最接近 $z=1$。所有角度都必须以弧度处理。\n\n请从以下基本定义开始：\n\n- Ising 模型的自旋 $s_i \\in \\{+1,-1\\}$ 分布于线性尺寸为 $L$ 且具有周期性边界条件 (PBC) 的方晶格上。其哈密顿量为\n$$\nH(s;J,h) \\;=\\; -J \\sum_{\\langle i,j\\rangle} s_i s_j \\;-\\; h \\sum_{i=1}^{N} s_i,\n$$\n其中 $N=L^2$，$J>0$ 是铁磁耦合，$\\langle i,j\\rangle$ 表示具有 PBC 的最近邻，而 $h$ 是均匀外磁场。\n\n- 正则配分函数为\n$$\nZ(\\beta,h) \\;=\\; \\sum_{s} e^{-\\beta H(s;J,h)} \\;=\\; \\sum_{s} \\exp\\!\\Big(\\beta J\\sum_{\\langle i,j\\rangle} s_i s_j + \\beta h \\sum_{i=1}^{N} s_i\\Big),\n$$\n其中 $\\beta = 1/T$，玻尔兹曼常数设为 $k_B=1$。\n\n定义复逸度\n$$\nz \\;=\\; e^{-2\\beta h}.\n$$\n通过根据自旋向下（即 $s_i=-1$ 的格点数）的数量 $k$ 对构型进行分组，可以注意到 $\\sum_{i=1}^{N} s_i = N-2k$。于是\n$$\ne^{\\beta h \\sum_i s_i} = e^{\\beta h N}\\, z^{k}.\n$$\n因此\n$$\nZ(\\beta,h) \\;=\\; e^{\\beta h N} \\sum_{k=0}^{N} a_k(\\beta)\\, z^k \\;\\equiv\\; e^{\\beta h N}\\, P_L(z;\\beta),\n$$\n其系数为\n$$\na_k(\\beta) \\;=\\; \\sum_{\\substack{s:\\;\\text{$k$ spins equal } -1}} \\exp\\!\\Big(\\beta J \\sum_{\\langle i,j\\rangle} s_i s_j\\Big).\n$$\nLee-Yang 零点是 $P_L(z;\\beta)$ 在复 $z$ 平面上的根。对于有限晶格，这些是孤立的复数。对于铁磁情况 $J>0$，Lee-Yang 圆定理意味着对于实数 $\\beta>0$，所有零点都位于单位圆 $|z|=1$ 上。\n\n$T_c$ 的估算量：对于固定的 $L$ 和温度 $T$，计算 $P_L(z;\\beta)$ 的所有根 $\\{z_i(T,L)\\}_{i=1}^{N}$ 并定义\n$$\n\\theta_{\\min}(T,L) \\;=\\; \\min_{i} \\big|\\arg(z_i(T,L))\\big|,\n$$\n其中 $\\arg(\\cdot)$ 表示以弧度为单位的复数辐角。定义有限尺寸估算量\n$$\nT_{\\mathrm{est}}(L) \\;=\\; \\operatorname*{arg\\,min}_{T \\in \\mathcal{G}} \\theta_{\\min}(T,L)\n$$\n该估算量在一个给定的有限温度网格 $\\mathcal{G}$ 上进行计算（若出现相同值，则选择较小的 $T$）。此估算量确定了网格中的一个温度，在该温度下，最近的 Lee-Yang 零点最接近正实轴。\n\n实现要求：\n\n- 设置 $J=1$ 和 $k_B=1$。所有温度 $T$ 都是无量纲的。所有角度必须以弧度处理，并在相关情况下作相应解释。\n- 在 $L\\times L$ 晶格上使用周期性边界条件。枚举所有 $2^N$ 个自旋构型以计算系数 $a_k(\\beta)$。对于每个构型，计算最近邻相互作用总和 $\\sum_{\\langle i,j\\rangle} s_i s_j$ 和自旋向下的数量 $k$，并将相应的权重累加到 $a_k(\\beta)$ 中。\n- 构建多项式 $P_L(z;\\beta)=\\sum_{k=0}^{N} a_k(\\beta)\\, z^k$ 并计算其所有复数根。按上述定义计算 $\\theta_{\\min}(T,L)$。\n- 对每个测试用例，扫描所提供的温度网格 $\\mathcal{G}$ 并输出 $T_{\\mathrm{est}}(L)$。\n\n测试套件：\n\n为以下测试用例计算 $T_{\\mathrm{est}}(L)$。每个用例是一个数对 $(L,\\mathcal{G})$：\n\n- 用例 1 (正常路径)：$L=2$，$\\mathcal{G} = [\\,1.5,\\,2.0,\\,2.2,\\,2.3,\\,2.5,\\,3.0\\,]$。\n- 用例 2 (更大晶格)：$L=3$，$\\mathcal{G} = [\\,1.8,\\,2.0,\\,2.1,\\,2.2,\\,2.25,\\,2.3,\\,2.4,\\,2.6\\,]$。\n- 用例 3 (粗糙网格边界)：$L=2$，$\\mathcal{G} = [\\,1.0,\\,4.0\\,]$。\n- 用例 4 (网格包含精确的无限晶格临界温度作为参考点)：$L=3$，$\\mathcal{G} = [\\,2.1,\\,2.2,\\,2.269185,\\,2.3\\,]$。精确的无限晶格值为 $T_c = 2/\\ln(1+\\sqrt{2}) \\approx 2.269185$，此处仅作为一个网格点包含；有限尺寸估算量不一定会选择它。\n\n最终输出格式：\n\n您的程序必须产生单行输出，其中包含四个估算出的温度 $[\\,T_{\\mathrm{est}}^{(1)},T_{\\mathrm{est}}^{(2)},T_{\\mathrm{est}}^{(3)},T_{\\mathrm{est}}^{(4)}\\,]$，顺序与上述用例相同，形式为方括号内以逗号分隔的列表。每个条目必须是该用例中使 $\\theta_{\\min}(T,L)$ 最小化的网格值（浮点数）。例如，如果您的程序找到的最小化网格值是这些值，那么形如 $[2.2,2.25,4.0,2.269185]$ 的输出是可接受的。不应打印任何额外文本。", "solution": "该问题陈述在科学上是合理的、良定的，并为完整的计算求解提供了所有必要的信息。它描述了统计物理学中一种使用 Lee-Yang 零点来估算临界现象的标准方法，并将其应用于有限晶格上的二维 Ising 模型。该方法计算量很大，需要对状态进行完全枚举，但对于指定的小晶格尺寸是可行的。因此，该问题是有效的，并且可以构建一个解。\n\n任务是通过找到配分函数的 Lee-Yang 零点最接近正实轴时的温度，来估算二维铁磁 Ising 模型的临界温度 $T_c$。问题提供了哈密顿量、配分函数 $Z(\\beta, h)$ 及其关于复逸度 $z=e^{-2\\beta h}$ 的多项式形式 $P_L(z;\\beta)$。该多项式的根即为 Lee-Yang 零点。\n\n该方法的核心基于以下步骤：\n1. 对于一个给定尺寸为 $L \\times L$ 的晶格，在特定温度 $T$ 下，我们首先需要计算配分函数多项式 $P_L(z;\\beta) = \\sum_{k=0}^{N} a_k(\\beta) z^k$ 的系数 $a_k(\\beta)$。这里，$N=L^2$ 是总自旋数，$\\beta = 1/T$ (其中 $k_B=1$)，并且 $a_k(\\beta)$ 定义为：\n$$\na_k(\\beta) = \\sum_{\\substack{s:\\;\\text{$k$ spins equal } -1}} \\exp\\left(\\beta J \\sum_{\\langle i,j\\rangle} s_i s_j\\right)\n$$\n其中 $J=1$ 是铁磁耦合常数。该求和遍历所有恰好有 $k$ 个自旋处于 $s_i = -1$ 状态的自旋构型 $s$。\n\n2. 为计算这些系数，我们必须对晶格上所有 $2^N$ 种可能的自旋构型进行完全枚举。对于每种构型：\n    a. 我们识别其自旋态 $s = \\{s_1, s_2, \\ldots, s_N\\}$，其中每个 $s_i \\in \\{+1, -1\\}$。\n    b. 我们计算“向下”自旋的数量，$k = \\sum_{i=1}^N \\frac{1-s_i}{2}$。\n    c. 我们计算构型的总相互作用能，$E_{\\text{int}} = \\sum_{\\langle i,j\\rangle} s_i s_j$。求和遍历在具有周期性边界条件的 $L \\times L$ 晶格上的所有唯一的最近邻对。在二维环形晶格上，这类键的总数为 $2N$。一种计算此和的标准且正确的方法是遍历每个格点 $i$，并对其与“前方”邻居（例如，右方和下方邻居）的相互作用求和。对于坐标为 $(r,c)$ 的格点，这对应于计算 $s_{r,c} s_{r, c+1} + s_{r,c} s_{r+1,c}$，其中所有索引都对 $L$ 取模。对所有 $N$ 个格点求和即可得到总相互作用能之和。\n    d. 当前构型的类玻尔兹曼权重 $\\exp(\\beta J E_{\\text{int}})$ 会被加到相应的系数 $a_k(\\beta)$上。\n\n3. 一旦所有 $2^N$ 种构型都处理完毕，对于所选的温度 $T$，系数数组 $\\{a_k(\\beta)\\}_{k=0}^N$ 就构建完成了。这些系数定义了多项式 $P_L(z;\\beta)$。\n\n4. 接着我们计算该多项式的复数根 $\\{z_i(T,L)\\}$。这是一个标准的数值任务，可以使用成熟的库函数完成，例如 Python 中的 `numpy.roots`。根据 Lee-Yang 圆定理，对于铁磁系统 ($J>0$)，所有这些根都必须位于复逸度平面的单位圆上，即 $|z_i| = 1$。\n\n5. 从这组根中，我们计算有限尺寸估算量 $\\theta_{\\min}(T,L)$，其定义为根的辐角绝对值的最小值：\n$$\n\\theta_{\\min}(T,L) = \\min_{i} \\big|\\arg(z_i(T,L))\\big|\n$$\n其中辐角以弧度计算。这个值表示最接近正实轴 ($z=1$) 的 Lee-Yang 零点的角距离，这在热力学极限下对应于相变的位置。\n\n6. 最后，为了估算给定晶格尺寸 $L$ 的临界温度，我们对所提供网格 $\\mathcal{G}$ 中的每个温度 $T$ 重复步骤 1 到 5。估算的临界温度 $T_{\\mathrm{est}}(L)$ 是网格中能产生 $\\theta_{\\min}(T,L)$ 最小值的那个温度：\n$$\nT_{\\mathrm{est}}(L) = \\operatorname*{arg\\,min}_{T \\in \\mathcal{G}} \\theta_{\\min}(T,L)\n$$\n如果出现值相同的情况，则选择较小的温度。该计算过程将应用于问题中指定的四个测试用例中的每一个。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef _calculate_interaction_energy(spins_flat, L):\n    \"\"\"\n    Calculates the total interaction energy sum for a given spin configuration.\n    The sum is over all nearest-neighbor pairs with periodic boundary conditions.\n    This is E_int = sum_{<i,j>} s_i s_j.\n    \"\"\"\n    N = L * L\n    spins = spins_flat.reshape((L, L))\n    energy_sum = 0\n    for r in range(L):\n        for c in range(L):\n            s_i = spins[r, c]\n            \n            # Interaction with right neighbor\n            s_j_right = spins[r, (c + 1) % L]\n            energy_sum += s_i * s_j_right\n            \n            # Interaction with down neighbor\n            s_j_down = spins[(r + 1) % L, c]\n            energy_sum += s_i * s_j_down\n    return energy_sum\n\ndef _get_polynomial_coeffs(L, T):\n    \"\"\"\n    Computes the coefficients a_k(beta) of the partition function polynomial.\n    \"\"\"\n    J = 1.0\n    beta = 1.0 / T\n    N = L * L\n    \n    # a_k are the coefficients for powers k=0, 1, ..., N\n    coeffs = np.zeros(N + 1, dtype=np.float64)\n\n    # Enumerate all 2^N spin configurations\n    for i in range(2**N):\n        # Generate spin configuration from integer representation\n        # Bit 0 -> spin +1, Bit 1 -> spin -1\n        spins_flat = np.ones(N, dtype=np.int8)\n        k_down_spins = 0\n        \n        temp_i = i\n        for j in range(N):\n            if (temp_i & 1) == 1:\n                spins_flat[j] = -1\n                k_down_spins += 1\n            temp_i >>= 1\n            \n        # Calculate interaction energy\n        energy_sum = _calculate_interaction_energy(spins_flat, L)\n        \n        # Accumulate weight into the corresponding coefficient\n        weight = np.exp(beta * J * energy_sum)\n        coeffs[k_down_spins] += weight\n        \n    return coeffs\n\ndef _estimate_tc_for_case(L, T_grid):\n    \"\"\"\n    Estimates the critical temperature for a single test case (L, T_grid).\n    \"\"\"\n    min_theta = float('inf')\n    T_est = -1.0\n    \n    for T in T_grid:\n        # 1. Compute polynomial coefficients a_k at temperature T\n        coeffs = _get_polynomial_coeffs(L, T)\n        \n        # 2. Find the roots of the polynomial P(z) = sum(a_k * z^k).\n        # np.roots expects coefficients from highest power to lowest.\n        roots = np.roots(coeffs[::-1])\n        \n        # 3. Calculate theta_min for this temperature\n        # Ensure roots are treated as complex numbers for angle calculation.\n        angles = np.angle(roots.astype(np.complex128))\n        theta_m = np.min(np.abs(angles))\n        \n        # 4. Update the estimated Tc if a new minimum theta is found\n        if theta_m < min_theta:\n            min_theta = theta_m\n            T_est = T\n            \n    return T_est\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (2, [1.5, 2.0, 2.2, 2.3, 2.5, 3.0]),\n        (3, [1.8, 2.0, 2.1, 2.2, 2.25, 2.3, 2.4, 2.6]),\n        (2, [1.0, 4.0]),\n        (3, [2.1, 2.2, 2.269185, 2.3]),\n    ]\n\n    results = []\n    for L, T_grid in test_cases:\n        estimated_tc = _estimate_tc_for_case(L, T_grid)\n        results.append(estimated_tc)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "2422394"}, {"introduction": "当系统变得复杂或尺寸增大时，精确枚举将不再可行，我们必须转向随机模拟方法。本练习将我们带到一个跨学科的模型——谢林隔离模型（Schelling segregation model），它源于社会学，但其集体行为展现了与物理系统类似的相变现象。我们的核心任务是成为一名“计算侦探”，通过分析序参量的统计分布，来判断该模型中的相变是一级（不连续）还是二级（连续）的 [@problem_id:2422368]。这个实践将训练我们如何从模拟数据中提取关于相变本质的关键信息，这是计算物理学家的基本功。", "problem": "您将实现并分析一个在有限、周期性的二维方格晶格上的双物种Schelling隔离模型，通过检视一个合适序参数的分布来确定向隔离状态转变的定性阶数。其背景是观察晶格系统中相变的有限尺寸特征。\n\n从以下基本基础开始：\n- 序参数是一个宏观可观测量，它在每个相中取特征性的不同值，从而区分不同的相。对于两种物种在晶格上的隔离，一个自然的选择是每个被占据格点上同类型邻居的平均比例。\n- 在有限系统中，一阶（不连续）相变的特征是在伪临界控制参数下，序参数呈现双峰分布，两个分离良好的峰对应于共存的相；而二阶（连续）相变则表现为单一的、展宽的峰，具有增强的涨落但没有相共存。\n- 晶格上的Schelling模型动力学由局部规则定义并且是马尔可夫性的：一个个体的移动仅取决于当前的构型。\n\n模型规格：\n- 晶格：一个线性尺寸为$L$的周期性方格晶格，共有$L \\times L$个格点，每个格点上要么有一个+1物种个体，一个-1物种个体，或者是一个空位。\n- 占据率：比例为$\\rho$的格点被占据，两种物种尽可能平均分配；剩余比例$1-\\rho$是空位。\n- 邻域：Moore邻域（切比雪夫距离为1的8个最近邻格点的集合），采用周期性边界条件。\n- 局部容忍度：如果一个被占据的格点，其被占据邻居中同类型邻居的比例至少为一个容忍度参数$\\tau \\in [0,1]$，则该格点被称为“满意”。\n- 每轮（sweep）的动力学：\n  1. 计算在当前$\\tau$下的不满意个体集合。\n  2. 如果不存在不满意个体，构型是吸收性的，动力学停止。\n  3. 否则，在一轮中，以随机顺序遍历不满意个体。对于每个这样的个体，将其移动到一个均匀随机选择的空位（无论此移动是否会使其变得满意）。在将所有当前已识别的不满意个体移动一次后，为下一轮重新计算不满意个体的集合。\n  4. 当没有不满意个体或达到最大轮数时停止。\n- 序参数：在动力学结束时，定义隔离序参数$m$为\n  $$ m \\equiv \\frac{1}{N_{\\mathrm{occ}}} \\sum_{i \\in \\text{occupied}} f_i, $$\n  其中$N_{\\mathrm{occ}}$是被占据格点的数量，而$f_i$是格点$i$在其Moore邻域的被占据邻居中同类型邻居的比例。如果一个格点$i$没有被占据的邻居，则设$f_i \\equiv 1/2$，这样孤立的格点在隔离方面是中性的。根据构造，$m \\in [0,1]$，对于一个良好混合的随机构型，$m \\approx 1/2$，而对于一个高度隔离的构型，$m$接近于1。\n\n通过序参数分布进行相变阶数分类：\n- 对于每个参数集，从一个旨在跨越任何假定相变的预设区间$[\\tau_{\\min}, \\tau_{\\max}]$中独立且均匀地抽取$\\tau$。对于每个抽样的$\\tau$，运行一次独立的模拟以获得最终的$m$。收集大小为$R$的样本$\\{m_r\\}_{r=1}^R$。\n- 使用有限尺寸现象学：如果$\\{m_r\\}$的经验分布具有两个清晰分离的峰和它们之间明显的谷，则声明相变为“一阶”；否则声明其为“二阶”。\n- 具体来说，实现一个基于两个测试的定量决策规则：\n  1. 对$\\{m_r\\}$的直方图（使用自动选择的箱数）进行峰分离测试：识别局部最大值；如果存在至少两个峰，计算它们在$m$上的分离度以及它们之间最小值相对于峰高的深度；要求分离度超过选定的阈值且谷足够深。\n  2. Pearson双峰系数$b \\equiv \\dfrac{\\gamma^2 + 1}{\\kappa}$，其中$\\gamma$是样本偏度，$\\kappa$是样本峰度（非超额峰度）。仅当$b$超过参考值$5/9$时，才分类为双峰。\n- 仅当两个测试都表明存在双峰性时，才分类为“一阶”；否则分类为“二阶”。\n\n数值细节和约束：\n- 使用周期性边界条件。\n- 使用具有8个邻居的Moore邻域。\n- 使用无量纲晶格单位（不需要物理单位）。\n- 不涉及角度。\n- 所有的随机选择必须能从提供的种子复现。\n\n您的程序必须是一个单一、完整、可运行的脚本，并且：\n- 实现上述模型和分析。\n- 运行以下参数集测试套件，并将每个分类结果作为一个整数输出在一行上：\n  - 测试1：$L=20$，$\\rho=0.90$，$[\\tau_{\\min},\\tau_{\\max}] = [0.45,0.55]$，$R=60$，最大轮数 $=60$，种子 $=12345$。\n  - 测试2：$L=20$，$\\rho=0.60$，$[\\tau_{\\min},\\tau_{\\max}] = [0.45,0.55]$，$R=60$，最大轮数 $=60$，种子 $=23456$。\n  - 测试3：$L=12$，$\\rho=0.85$，$[\\tau_{\\min},\\tau_{\\max}] = [0.35,0.65]$，$R=80$，最大轮数 $=80$，种子 $=34567$。\n- 对于每个测试，如果相变被分类为一阶，则输出$1$；如果被分类为二阶，则输出$2$。\n\n最终输出格式：\n- 您的程序应产生单行输出，其中包含一个逗号分隔并用方括号括起来的结果列表，例如，对于三个测试按顺序为$\\texttt{[1,2,2]}$。输出必须是整数$1$或$2$，无空格。\n\n实现和性能说明：\n- 您的实现必须使用高效的数组操作进行邻居计数（例如，通过数组移位），以在指定的尺寸和重复次数下保持合理的运行时间。\n- 您的随机数流必须通过每个测试指定的种子来复现；在一个测试内部，确定性地从该测试种子为每次重复派生出独立的子种子。\n- 程序不得要求任何用户输入或外部文件，并且必须严格遵守执行环境和库的限制。", "solution": "对提出的问题进行验证。\n\n**第1步：提取的已知条件**\n- **模型：** 有限、周期性 $L \\times L$ 方格晶格上的双物种Schelling隔离模型。\n- **状态空间：** 格点可被+1物种、-1物种占据，或为空位（记为0）。\n- **参数：**\n    - $L$：线性晶格尺寸。\n    - $\\rho$：被占据格点的比例。\n    - $\\tau$：容忍度参数，一个关于同类型邻居比例的阈值。\n    - $R$：每个测试用例的独立模拟运行次数。\n    - `max_sweeps`：模拟的最大轮数。\n    - `seed`：用于初始化随机数生成器的整数。\n- **邻域：** Moore邻域（8个相邻格点），采用周期性边界条件。\n- **动力学：** 不满意个体（定义为在其被占据邻居中同类型邻居比例小于$\\tau$的个体）被移动。在每一轮中，所有当前的不满意个体按随机顺序依次移动到随机的空位上。如果达到吸收态（没有不满意个体）或在`max_sweeps`之后，过程停止。\n- **序参数：** 隔离序参数$m$是每个个体的同类型邻居的平均比例，$m = \\frac{1}{N_{\\mathrm{occ}}} \\sum_{i \\in \\text{occupied}} f_i$，其中$f_i$是个体$i$的同类型邻居比例。如果一个个体没有邻居，$f_i$定义为$1/2$。\n- **分析方法：** 对每个测试用例，运行$R$次模拟。在每次模拟$r$中，从$[\\tau_{\\min}, \\tau_{\\max}]$中均匀抽取$\\tau_r$，并计算最终的序参数$m_r$。分析收集到的样本$\\{m_r\\}$。\n- **分类规则：** 当且仅当两个测试都表明存在双峰性时，相变被分类为“一阶”（输出$1$）。否则，为“二阶”（输出$2$）。\n    1. **峰分离测试：** $\\{m_r\\}$的直方图必须显示至少两个充分分离且之间有深谷的峰。未提供具体阈值。\n    2. **Pearson双峰系数：** 系数$b = (\\gamma^2 + 1) / \\kappa$必须超过$5/9$，其中$\\gamma$是样本偏度，$\\kappa$是样本峰度。\n- **测试用例：**\n    1. $L=20$, $\\rho=0.90$, $[\\tau_{\\min},\\tau_{\\max}]=[0.45,0.55]$, $R=60$, `max_sweeps`$=60$, `seed`$=12345$。\n    2. $L=20$, $\\rho=0.60$, $[\\tau_{\\min},\\tau_{\\max}]=[0.45,0.55]$, $R=60$, `max_sweeps`$=60$, `seed`$=23456$。\n    3. $L=12$, $\\rho=0.85$, $[\\tau_{\\min},\\tau_{\\max}]=[0.35,0.65]$, $R=80$, `max_sweeps`$=80$, `seed`$=34567$。\n\n**第2步：验证**\n- **科学依据：** 该问题在科学上是合理的。Schelling模型、相变、序参数及其有限尺寸特征是统计物理和计算物理中的标准概念。\n- **适定性：** 该问题大体上是适定的。所有必要的参数和动力学都已指定。在“峰分离测试”中存在一个微小的不明确之处，即没有给出“充分分离”和“深谷”的定量阈值。对于此类性质的问题，这是可接受的模糊程度，因为一个合格的实践者应能定义合理、明确的标准。我将通过制定明确且有原则的阈值来解决此问题。\n- **客观性：** 问题陈述客观，要求进行定量、可复现的分析。\n\n**第3步：结论与行动**\n该问题是**有效的**。关于峰分离测试具体阈值的微小不明确之处将通过明确建立和陈述它们来解决。我现在将提供完整的解决方案。\n\n**解决方案方法论**\n\n该解决方案首先在周期性晶格上实现Schelling模型模拟，然后对序参数分布进行统计分析以对相变进行分类。\n\n**1. 模型实现**\n- **晶格：** 一个$L \\times L$的晶格由一个`numpy`数组表示。格点值为$1$（+1物种）、$-1$（-1物种）和$0$（空位）。初始构型通过在晶格上随机放置由$\\rho$决定的所需数量的个体来创建。两种物种的个体数量尽可能相等。\n- **邻居计数：** 为实现计算效率，每个格点的邻居计数使用向量化操作计算。对于给定的属性（例如，被+1物种占据），会创建一个二进制掩码。然后，通过对该掩码的八个移位版本求和来计算网格上每个格点具有此属性的邻居数，每次移位对应Moore邻域中的一个邻居。这通过`numpy.roll`实现。\n- **动力学：** 模拟在称为“轮”（sweeps）的离散时间步中演进。在每一轮中：\n    1. 为晶格上的每个格点计算同类型邻居集合和总被占据邻居集合。\n    2. 为每个个体计算同类型邻居的比例$f_i$。没有被占据邻居的个体，$f_i=1/2$。\n    3. $f_i < \\tau$的个体被识别为“不满意”。\n    4. 如果没有不满意个体，系统已达到吸收态，此重复的模拟终止。\n    5. 否则，将不满意个体位置的列表进行随机排序。个体按此随机顺序逐一移动。对每个个体，从当前可用的空位中均匀随机选择一个目标空位，然后个体移动到那里。每次单独移动后更新网格。\n    6. 此过程重复进行，直到达到最大轮数。\n\n**2. 序参数计算**\n模拟运行终止后，使用最终构型计算隔离序参数$m$。这是通过为所有$N_{\\mathrm{occ}}$个个体计算同类型邻居的比例$f_i$（同样，对于孤立个体$f_i=1/2$），然后对这些比例求平均值来完成的：$m = \\frac{1}{N_{\\mathrm{occ}}} \\sum_{i} f_i$。\n\n**3. 相变阶数分类**\n对于每个测试用例，执行$R$次独立模拟。对于每次运行，从指定范围$[\\tau_{\\min}, \\tau_{\\max}]$中均匀采样一个容忍度$\\tau$。然后，使用两个测试分析所产生的$R$个最终序参数集合$\\{m_r\\}$的双峰性。\n\n- **测试1：Pearson双峰系数**\n    系数计算为$b = (\\gamma^2 + 1) / \\kappa$。这里，$\\gamma$是样本偏度，$\\kappa$是样本峰度（非超额），从经验分布$\\{m_r\\}$的矩计算得出：\n    $$ \\gamma = \\frac{\\frac{1}{R}\\sum_{r=1}^R (m_r - \\bar{m})^3}{\\left(\\frac{1}{R}\\sum_{r=1}^R (m_r - \\bar{m})^2\\right)^{3/2}}, \\quad \\kappa = \\frac{\\frac{1}{R}\\sum_{r=1}^R (m_r - \\bar{m})^4}{\\left(\\frac{1}{R}\\sum_{r=1}^R (m_r - \\bar{m})^2\\right)^2} $$\n    其中$\\bar{m}$是样本均值。如果$b > 5/9$，则该测试认为分布是双峰的。\n\n- **测试2：峰分离测试**\n    为将定性描述形式化，建立以下定量标准：\n    1. 使用`numpy.histogram`和`'auto'`分箱策略，在区间$[0, 1]$上生成数据$\\{m_r\\}$的直方图。\n    2. 识别直方图计数中的局部最大值（峰）。如果找到少于两个峰，则测试失败。\n    3. 选择最高的两个峰进行分析。设它们的位置为$m_1$和$m_2$，高度为$h_1$和$h_2$。\n    4. 将这两个峰之间的最小直方图计数识别为谷高$h_{\\text{valley}}$。仅当峰之间至少有一个直方图箱时，才认为存在谷。\n    5. 如果同时满足以下两个条件，则宣布为双峰：\n        - **分离度：** 峰中心之间的距离必须显著：$|m_1 - m_2| > 0.2$。\n        - **深度：** 谷必须是明显的：$h_{\\text{valley}} < \\frac{2}{3} \\min(h_1, h_2)$。\n\n仅当Pearson系数测试和峰分离测试都表明存在双峰性时，一个测试用例才被分类为一阶（输出$1$）。否则，它被分类为二阶（输出$2$）。这种联合规则确保了对一阶相变的保守分类。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the Schelling model analysis.\n    \"\"\"\n    test_cases = [\n        {'L': 20, 'rho': 0.90, 'tau_range': [0.45, 0.55], 'R': 60, 'max_sweeps': 60, 'seed': 12345},\n        {'L': 20, 'rho': 0.60, 'tau_range': [0.45, 0.55], 'R': 60, 'max_sweeps': 60, 'seed': 23456},\n        {'L': 12, 'rho': 0.85, 'tau_range': [0.35, 0.65], 'R': 80, 'max_sweeps': 80, 'seed': 34567},\n    ]\n\n    results = []\n    for params in test_cases:\n        classification = run_analysis_for_case(params)\n        results.append(classification)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_analysis_for_case(params):\n    \"\"\"\n    Runs R simulations for a given parameter set and classifies the transition.\n    \"\"\"\n    m_values = []\n    for r in range(params['R']):\n        rep_seed = params['seed'] + r\n        rep_rng = np.random.default_rng(rep_seed)\n        \n        tau = rep_rng.uniform(params['tau_range'][0], params['tau_range'][1])\n        \n        final_m = run_single_simulation(\n            L=params['L'], \n            rho=params['rho'], \n            tau=tau, \n            max_sweeps=params['max_sweeps'], \n            rng=rep_rng\n        )\n        m_values.append(final_m)\n        \n    m_values = np.array(m_values)\n    \n    pearson_bimodal = is_bimodal_pearson(m_values)\n    peak_bimodal = is_bimodal_peaks(m_values)\n    \n    if pearson_bimodal and peak_bimodal:\n        return 1  # First-order\n    else:\n        return 2  # Second-order\n\ndef run_single_simulation(L, rho, tau, max_sweeps, rng):\n    \"\"\"\n    Executes a single run of the Schelling model simulation.\n    \"\"\"\n    grid = initialize_grid(L, rho, rng)\n    \n    for _ in range(max_sweeps):\n        num_like, num_occupied_neighbors = count_neighbors(grid)\n        \n        occupied_mask = (grid != 0)\n        \n        with np.errstate(divide='ignore', invalid='ignore'):\n            f = np.divide(num_like, num_occupied_neighbors, \n                          out=np.full(grid.shape, 0.5, dtype=float), \n                          where=num_occupied_neighbors != 0)\n\n        unhappy_mask = (f < tau) & occupied_mask\n        unhappy_indices = np.argwhere(unhappy_mask)\n\n        if len(unhappy_indices) == 0:\n            break\n\n        rng.shuffle(unhappy_indices)\n        \n        vacant_indices = np.argwhere(grid == 0)\n        num_vacancies = len(vacant_indices)\n\n        if num_vacancies == 0:\n            break\n\n        for agent_pos_tuple in unhappy_indices:\n            agent_pos = tuple(agent_pos_tuple)\n            \n            # Find current vacancies; this is inefficient but correct for sequential moves\n            current_vacancies = np.argwhere(grid == 0)\n            if len(current_vacancies) == 0:\n                continue\n\n            target_idx = rng.choice(len(current_vacancies))\n            target_pos = tuple(current_vacancies[target_idx])\n            \n            # Move agent\n            grid[target_pos], grid[agent_pos] = grid[agent_pos], grid[target_pos]\n\n    # Calculate final order parameter\n    num_like_final, num_occupied_neighbors_final = count_neighbors(grid)\n    occupied_mask_final = (grid != 0)\n    num_occ = np.sum(occupied_mask_final)\n\n    with np.errstate(divide='ignore', invalid='ignore'):\n        f_final = np.divide(num_like_final, num_occupied_neighbors_final,\n                            out=np.full(grid.shape, 0.5, dtype=float),\n                            where=num_occupied_neighbors_final != 0)\n    \n    m = np.sum(f_final[occupied_mask_final]) / num_occ if num_occ > 0 else 0.5\n    return m\n\ndef initialize_grid(L, rho, rng):\n    \"\"\"\n    Initializes the lattice with agents and vacancies.\n    \"\"\"\n    N = L * L\n    N_occ = int(rho * N)\n    N_p1 = N_occ // 2\n    N_m1 = N_occ - N_p1\n    \n    grid_flat = np.zeros(N, dtype=int)\n    grid_flat[:N_p1] = 1\n    grid_flat[N_p1:N_occ] = -1\n    \n    rng.shuffle(grid_flat)\n    return grid_flat.reshape((L, L))\n\ndef count_neighbors(grid):\n    \"\"\"\n    Efficiently counts neighbors using numpy.roll.\n    \"\"\"\n    L = grid.shape[0]\n    \n    shifts = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n\n    p1_mask = (grid == 1)\n    m1_mask = (grid == -1)\n\n    num_neighbors_p1 = np.zeros_like(grid, dtype=int)\n    num_neighbors_m1 = np.zeros_like(grid, dtype=int)\n\n    for dy, dx in shifts:\n        num_neighbors_p1 += np.roll(p1_mask, (dy, dx), axis=(0, 1))\n        num_neighbors_m1 += np.roll(m1_mask, (dy, dx), axis=(0, 1))\n\n    num_like_neighbors = num_neighbors_p1 * p1_mask + num_neighbors_m1 * m1_mask\n    num_occupied_neighbors = num_neighbors_p1 + num_neighbors_m1\n    \n    return num_like_neighbors, num_occupied_neighbors\n\ndef is_bimodal_pearson(data):\n    \"\"\"\n    Calculates Pearson's bimodality coefficient and checks against the threshold.\n    \"\"\"\n    n = len(data)\n    if n < 3: return False\n    \n    mean = np.mean(data)\n    var = np.var(data)\n    if var == 0: return False\n\n    std_dev = np.sqrt(var)\n    skewness = np.mean(((data - mean) / std_dev)**3)\n    kurtosis = np.mean(((data - mean) / std_dev)**4)\n\n    if kurtosis == 0: return False\n\n    b = (skewness**2 + 1) / kurtosis\n    return b > (5/9)\n\ndef is_bimodal_peaks(data, sep_thresh=0.2, depth_thresh=2/3.):\n    \"\"\"\n    Performs a peak-separation test on the data's histogram.\n    \"\"\"\n    counts, bin_edges = np.histogram(data, bins='auto', range=(0.0, 1.0))\n    if np.sum(counts) < 3: return False\n    \n    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2.0\n    \n    peak_indices = []\n    for i in range(1, len(counts) - 1):\n        if counts[i] > counts[i-1] and counts[i] > counts[i+1]:\n            peak_indices.append(i)\n    \n    if len(peak_indices) < 2:\n        return False\n        \n    peak_heights = counts[peak_indices]\n    highest_peak_indices_in_list = np.argsort(peak_heights)[::-1][:2]\n    \n    idx1 = peak_indices[highest_peak_indices_in_list[0]]\n    idx2 = peak_indices[highest_peak_indices_in_list[1]]\n    \n    if idx1 > idx2:\n        idx1, idx2 = idx2, idx1\n        \n    h1, h2 = counts[idx1], counts[idx2]\n    m1, m2 = bin_centers[idx1], bin_centers[idx2]\n    \n    # Valley must have at least one bin between peaks\n    if idx2 <= idx1 + 1:\n        return False\n        \n    valley_height = np.min(counts[idx1+1 : idx2])\n    \n    separation_ok = (m2 - m1) > sep_thresh\n    depth_ok = valley_height < depth_thresh * min(h1, h2)\n    \n    return separation_ok and depth_ok\n\nif __name__ == \"__main__\":\n    solve()\n\n```", "id": "2422368"}]}