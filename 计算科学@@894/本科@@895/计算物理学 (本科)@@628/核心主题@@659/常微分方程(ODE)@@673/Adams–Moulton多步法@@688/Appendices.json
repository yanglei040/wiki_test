{"hands_on_practices": [{"introduction": "隐式方法（如 Adams-Moulton）的一个核心特征是，当应用于非线性微分方程时，每一步都需要求解一个代数方程。这个练习将带你亲身体验这一点。通过将两步 Adams-Moulton 方法应用于经典的逻辑斯谛方程，你将推导出求解下一步数值解 $y_{n+1}$ 所必须满足的代数方程，从而深刻理解“隐式”的含义。[@problem_id:2187830]", "problem": "逻辑斯谛微分方程是描述在有限制条件下种群增长的一个基本模型。其形式为\n$$\ny'(t) = r y(t) \\left(1 - \\frac{y(t)}{K}\\right)\n$$\n其中 $y(t)$ 是时间 $t$ 时的种群数量，$r$ 是内禀增长率，$K$ 是环境承载力。$r$ 和 $K$ 均为正常数。\n\n为了对此方程进行数值求解，可以使用多种方法。两步 Adams-Moulton 方法是一种隐式多步法，其公式定义如下：\n$$\ny_{n+1} = y_n + \\frac{h}{12}(5f_{n+1} + 8f_n - f_{n-1})\n$$\n此处，$h$ 为固定步长，$y_k$ 是在时间 $t_k = t_0 + kh$ 时 $y(t_k)$ 的数值近似值，$f_k$ 是 $f(t_k, y_k)$ 的简写，其中 $f(t, y) = y'(t)$。\n\n由于项 $f_{n+1}$ 依赖于未知值 $y_{n+1}$，将此方法应用于非线性微分方程时，会在每一步产生一个需要求解 $y_{n+1}$ 的非线性代数方程。对于逻辑斯谛方程，这个代数方程是关于 $y_{n+1}$ 的二次方程，可以写成标准形式：\n$$\nA y_{n+1}^2 + B y_{n+1} + C = 0\n$$\n你的任务是确定系数 $A$、$B$ 和 $C$ 的表达式。你的最终答案应为用步长 $h$、逻辑斯谛模型参数 $r$ 和 $K$ 以及先前步骤中的已知值 $y_n$、$f_n$ 和 $f_{n-1}$ 表示的 $A$、$B$ 和 $C$ 的表达式。", "solution": "我们从逻辑斯谛微分方程 $f(t,y)=r y\\left(1-\\frac{y}{K}\\right)=r y-\\frac{r}{K}y^{2}$ 和两步 Adams-Moulton 方法开始\n$$\ny_{n+1}=y_{n}+\\frac{h}{12}\\left(5 f_{n+1}+8 f_{n}-f_{n-1}\\right).\n$$\n代入 $f_{n+1}=f(t_{n+1},y_{n+1})=r y_{n+1}-\\frac{r}{K}y_{n+1}^{2}$ 可得\n$$\ny_{n+1}=y_{n}+\\frac{h}{12}\\left(5\\left(r y_{n+1}-\\frac{r}{K}y_{n+1}^{2}\\right)+8 f_{n}-f_{n-1}\\right).\n$$\n将所有项移到左侧，写出关于 $y_{n+1}$ 的二次方程：\n$$\ny_{n+1}-y_{n}-\\frac{h}{12}\\left(5 r y_{n+1}-5\\frac{r}{K}y_{n+1}^{2}+8 f_{n}-f_{n-1}\\right)=0.\n$$\n合并同类项可得\n$$\n\\frac{5 h r}{12 K}y_{n+1}^{2}+\\left(1-\\frac{5 h r}{12}\\right)y_{n+1}-y_{n}-\\frac{h}{12}\\left(8 f_{n}-f_{n-1}\\right)=0.\n$$\n将其与 $A y_{n+1}^{2}+B y_{n+1}+C=0$ 进行匹配，我们确定\n$$\nA=\\frac{5 h r}{12 K},\\quad B=1-\\frac{5 h r}{12},\\quad C=-y_{n}-\\frac{h}{12}\\left(8 f_{n}-f_{n-1}\\right).\n$$\n这些表达式是用 $h$、$r$、$K$ 以及已知量 $y_{n}$、$f_{n}$ 和 $f_{n-1}$ 来表示的。", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{5 h r}{12 K} & 1-\\frac{5 h r}{12} & -y_{n}-\\frac{h}{12}\\left(8 f_{n}-f_{n-1}\\right)\\end{pmatrix}}$$", "id": "2187830"}, {"introduction": "在掌握了单个方程的应用后，我们将把 Adams-Moulton 方法的应用扩展到耦合微分方程组，这是模拟物理和生物系统时的常见情况。本练习以经典的 Lotka-Volterra 捕食者-被捕食者模型为例。你的任务是构建在每个时间步中必须求解的非线性代数方程组，这对于解决更复杂的现实世界问题至关重要。[@problem_id:2187866]", "problem": "Lotka-Volterra方程是用于描述捕食者-猎物种群动态的经典模型。令$x(t)$表示猎物物种在时间$t$的种群数量，$y(t)$表示捕食者物种在时间$t$的种群数量。该模型由以下耦合非线性常微分方程组描述：\n$$\n\\frac{dx}{dt} = \\alpha x - \\beta xy\n$$\n$$\n\\frac{dy}{dt} = \\delta xy - \\gamma y\n$$\n其中$\\alpha, \\beta, \\delta, \\gamma$是代表相互作用率的正实常数。\n\n我们希望求出该系统的一个近似数值解。令$h$为一个恒定的时间步长，并令$(x_k, y_k)$表示在离散时间点$t_k = kh$时种群$(x(t_k), y(t_k))$的数值近似。\n\n两步Adams-Moulton方法是一种求解一般一阶系统$\\mathbf{y}'(t) = \\mathbf{f}(t, \\mathbf{y}(t))$的隐式多步法。将解从第$n$步推进到第$n+1$步的公式为：\n$$\n\\mathbf{y}_{n+1} = \\mathbf{y}_n + \\frac{h}{12} \\left( 5 \\mathbf{f}_{n+1} + 8 \\mathbf{f}_n - \\mathbf{f}_{n-1} \\right)\n$$\n其中$\\mathbf{y}_k$是$\\mathbf{y}(t_k)$的近似值，而$\\mathbf{f}_k = \\mathbf{f}(t_k, \\mathbf{y}_k)$。\n\n当此方法应用于Lotka-Volterra系统时，在每个时间步长，它会产生一个关于未知状态$(x_{n+1}, y_{n+1})$的耦合非线性代数方程组。假设状态$(x_n, y_n)$和$(x_{n-1}, y_{n-1})$是已知的，以下哪个选项正确表示了为求解$(x_{n+1}, y_{n+1})$所必须解的代数方程组？\n\nA.\n$$\n\\begin{cases}\nx_{n+1} - x_n - \\frac{h}{12} [5(\\alpha x_{n+1} - \\beta x_{n+1}y_{n+1}) + 8(\\alpha x_n - \\beta x_n y_n) - (\\alpha x_{n-1} - \\beta x_{n-1} y_{n-1})] = 0 \\\\\ny_{n+1} - y_n - \\frac{h}{12} [5(\\delta x_{n+1}y_{n+1} - \\gamma y_{n+1}) + 8(\\delta x_n y_n - \\gamma y_n) - (\\delta x_{n-1} y_{n-1} - \\gamma y_{n-1})] = 0\n\\end{cases}\n$$\n\nB.\n$$\n\\begin{cases}\nx_{n+1} - x_n - \\frac{h}{12} [5(\\alpha x_{n+1} - \\beta x_{n+1}y_{n+1}) + 8(\\alpha x_n - \\beta x_n y_n) + (\\alpha x_{n-1} - \\beta x_{n-1} y_{n-1})] = 0 \\\\\ny_{n+1} - y_n - \\frac{h}{12} [5(\\delta x_{n+1}y_{n+1} - \\gamma y_{n+1}) + 8(\\delta x_n y_n - \\gamma y_n) + (\\delta x_{n-1} y_{n-1} - \\gamma y_{n-1})] = 0\n\\end{cases}\n$$\n\nC.\n$$\n\\begin{cases}\nx_{n+1} - x_n - \\frac{h}{2} [3(\\alpha x_n - \\beta x_n y_n) - (\\alpha x_{n-1} - \\beta x_{n-1} y_{n-1})] = 0 \\\\\ny_{n+1} - y_n - \\frac{h}{2} [3(\\delta x_n y_n - \\gamma y_n) - (\\delta x_{n-1} y_{n-1} - \\gamma y_{n-1})] = 0\n\\end{cases}\n$$\n\nD.\n$$\n\\begin{cases}\nx_{n+1} - x_n - \\frac{h}{12} [5(\\alpha x_{n+1} - \\beta x_{n+1}y_{n+1}) - (\\alpha x_n - \\beta x_n y_n) + 8(\\alpha x_{n-1} - \\beta x_{n-1} y_{n-1})] = 0 \\\\\ny_{n+1} - y_n - \\frac{h}{12} [5(\\delta x_{n+1}y_{n+1} - \\gamma y_{n+1}) - (\\delta x_n y_n - \\gamma y_n) + 8(\\delta x_{n-1} y_{n-1} - \\gamma y_{n-1})] = 0\n\\end{cases}\n$$", "solution": "给定用于求解一般一阶系统$\\mathbf{y}'(t)=\\mathbf{f}(t,\\mathbf{y}(t))$的两步Adams-Moulton方法：\n$$\n\\mathbf{y}_{n+1}=\\mathbf{y}_{n}+\\frac{h}{12}\\left(5\\mathbf{f}_{n+1}+8\\mathbf{f}_{n}-\\mathbf{f}_{n-1}\\right),\n$$\n其中$\\mathbf{f}_{k}=\\mathbf{f}(t_{k},\\mathbf{y}_{k})$。对于Lotka-Volterra系统，有$\\mathbf{y}=(x,y)^{T}$且\n$$\n\\mathbf{f}(t,(x,y)^{T})=\\begin{pmatrix}\\alpha x-\\beta xy\\\\ \\delta xy-\\gamma y\\end{pmatrix},\n$$\n该方法按分量应用。由于该系统是自治的，$\\mathbf{f}_{k}$仅依赖于$(x_{k},y_{k})$。将$\\mathbf{f}$代入Adams-Moulton公式可得\n$$\nx_{n+1}=x_{n}+\\frac{h}{12}\\left[5\\left(\\alpha x_{n+1}-\\beta x_{n+1}y_{n+1}\\right)+8\\left(\\alpha x_{n}-\\beta x_{n}y_{n}\\right)-\\left(\\alpha x_{n-1}-\\beta x_{n-1}y_{n-1}\\right)\\right],\n$$\n$$\ny_{n+1}=y_{n}+\\frac{h}{12}\\left[5\\left(\\delta x_{n+1}y_{n+1}-\\gamma y_{n+1}\\right)+8\\left(\\delta x_{n}y_{n}-\\gamma y_{n}\\right)-\\left(\\delta x_{n-1}y_{n-1}-\\gamma y_{n-1}\\right)\\right].\n$$\n将每个方程重写为残差等于零的形式，得到\n$$\nx_{n+1}-x_{n}-\\frac{h}{12}\\left[5\\left(\\alpha x_{n+1}-\\beta x_{n+1}y_{n+1}\\right)+8\\left(\\alpha x_{n}-\\beta x_{n}y_{n}\\right)-\\left(\\alpha x_{n-1}-\\beta x_{n-1}y_{n-1}\\right)\\right]=0,\n$$\n$$\ny_{n+1}-y_{n}-\\frac{h}{12}\\left[5\\left(\\delta x_{n+1}y_{n+1}-\\gamma y_{n+1}\\right)+8\\left(\\delta x_{n}y_{n}-\\gamma y_{n}\\right)-\\left(\\delta x_{n-1}y_{n-1}-\\gamma y_{n-1}\\right)\\right]=0,\n$$\n这与选项 A 匹配。选项 B 中$\\mathbf{f}_{n-1}$项的符号错误，选项 C 是显式两步Adams-Bashforth方法，而选项 D 的系数位置不正确。", "answer": "$$\\boxed{A}$$", "id": "2187866"}, {"introduction": "为了构建高效且可靠的数值求解器，自适应性——即根据所需精度动态调整步长——是关键。这个高级实践将指导你为一个 Adams-Moulton 方法实现步长控制器。通过利用预估-校正对来估计局部误差，你将开发出一个能够自动在解变化剧烈的区域采取小步长 $h_n$，而在解平滑的区域采取大步长的智能求解器。[@problem_id:2371573]", "problem": "您需要设计并实现一个用于预估-校正 Adams–Moulton 方法的自适应步长控制器，其目标是使每单位步长的局部误差低于用户指定的容差。考虑一个由常微分方程 (ODE) $y'(t)=f(t,y)$ 和初始条件 $y(t_0)=y_0$ 定义的初值问题。您将使用二阶隐式梯形法则（一种 Adams–Moulton 方法）作为校正子，并与前向欧拉预估子耦合。每单位步长的局部误差将通过预估子与校正子之差的范数除以当前步长来估计。\n\n出发点（基本依据）：该常微分方程满足以下积分关系\n$$\ny(t_{n+1}) = y(t_n) + \\int_{t_n}^{t_{n+1}} f(s, y(s))\\, ds,\n$$\n其中时间节点为 $t_{n+1}=t_n+h_n$， $h_n$ 是第 $n$ 步的步长。隐式梯形法则通过对 $f$ 进行线性插值来近似该积分，从而得到一个利用 $f(t_n,y_n)$ 和 $f(t_{n+1},y_{n+1})$ 的校正子。为避免求解一个完全隐式的非线性方程，应采用预估-校正方法：显式地预估 $y_{n+1}^p$，然后应用梯形法则，用 $f(t_{n+1},y_{n+1}^p)$ 代替未知的 $f(t_{n+1},y_{n+1}^c)$，校正得到 $y_{n+1}^c$。\n\n将每步误差指标定义为\n$$\ne_n \\equiv \\frac{\\|y_{n+1}^p - y_{n+1}^c\\|}{h_n},\n$$\n其中 $\\|\\cdot\\|$ 是欧几里得范数。自适应控制器必须：\n- 如果 $e_n \\le \\text{tol}$，则接受该步，其中 $\\text{tol} > 0$ 是用户指定的容差，\n- 否则拒绝该步，并用一个更小的 $h_n$ 重试，\n- 根据 $e_n$ 与 $\\text{tol}$ 的比较得出的缩放因子，结合一个严格介于 $0$ 和 $1$ 之间的安全因子以及上下界 $h_{\\min}$ 和 $h_{\\max}$，来调整下一步尝试的步长 $h_n$，\n- 处理最后一步，按需缩短步长，以确保时间 $t$ 恰好落在最终时间 $T$ 上，\n- 对向量使用欧几里得范数，对标量使用绝对值，\n- 如果 $e_n=0$，在边界范围内谨慎地增加步长，\n- 如果 $h_n$ 达到 $h_{\\min}$ 且 $e_n$ 仍然超过容差，则接受该步以避免死锁，同时在后续步骤中继续尝试减小 $e_n$。\n\n在一个单一、完整、可运行的程序中实现此算法。该程序必须包含一个函数，使用所述的自adaptive Adams–Moulton 预估-校正方案，在区间 $[t_0,T]$ 上对任意给定的右端项 $f(t,y)$ 进行积分，并使用初始条件 $y_0$。对 $\\|\\cdot\\|$ 使用欧几里得范数。所有变量都是无量纲的，不需要物理单位。\n\n测试套件。在以下四个测试用例上运行您的求解器：\n\n- 用例 A (标量指数衰减):\n  - $f(t,y) = -2\\,y$,\n  - $t_0 = 0$, $T = 5$,\n  - $y_0 = 1$,\n  - $\\text{tol} = 10^{-5}$,\n  - $h_0 = 0.1$, $h_{\\min} = 10^{-6}$, $h_{\\max} = 1$.\n  - 此用例的输出：最终值 $y(T)$，以浮点数形式表示。\n\n- 用例 B (角频率为 $\\omega$ 的二维谐振子):\n  - 状态 $y = [q,p]^\\top$ 遵循 $q' = p$, $p' = -\\omega^2 q$，其中 $\\omega = 5$,\n  - $t_0 = 0$, $T = 2\\pi/\\omega$,\n  - $y_0 = [1,0]^\\top$,\n  - $\\text{tol} = 10^{-6}$,\n  - $h_0 = 0.05$, $h_{\\min} = 10^{-6}$, $h_{\\max} = 0.2$.\n  - 此用例的输出：最终值 $q(T)$ 和 $p(T)$，以两个浮点数的形式表示，并按此顺序。\n\n- 用例 C (标量逻辑斯谛增长):\n  - $f(t,y) = r\\,y\\,(1 - y/K)$，参数为 $r = 3$, $K=1$,\n  - $t_0 = 0$, $T = 5$,\n  - $y_0 = 0.2$,\n  - $\\text{tol} = 10^{-5}$,\n  - $h_0 = 0.1$, $h_{\\min} = 10^{-6}$, $h_{\\max} = 0.5$.\n  - 此用例的输出：最终值 $y(T)$，以浮点数形式表示。\n\n- 用例 D (边界情况：极严格的容差和很小的终止时间):\n  - $f(t,y) = y$,\n  - $t_0 = 0$, $T = 10^{-3}$,\n  - $y_0 = 1$,\n  - $\\text{tol} = 10^{-10}$,\n  - $h_0 = 10^{-4}$, $h_{\\min} = 10^{-8}$, $h_{\\max} = 10^{-2}$.\n  - 此用例的输出：接受的总步数，以整数形式表示。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果按以下顺序排列\n$$\n[\\;y_A(T),\\; q_B(T),\\; p_B(T),\\; y_C(T),\\; N_D\\;],\n$$\n其中 $y_A(T)$ 是用例 A 的最终值，$q_B(T)$ 和 $p_B(T)$ 是用例 B 的最终位置和动量，$y_C(T)$ 是用例 C 的最终值，$N_D$ 是用例 D 的接受步数。例如，一个有效的打印行如下所示\n$$\n[\\;0.123456,\\;0.99999,\\;-0.00001,\\;0.98765,\\;42\\;].\n$$", "solution": "问题是为一个一阶常微分方程 (ODE) 的初值问题 (IVP) 构建并实现一个数值求解器。该初值问题定义为\n$$\n\\frac{dy}{dt} = f(t,y), \\quad y(t_0) = y_0.\n$$\n该求解器必须采用基于预估-校正方案的自适应步长策略。指定的方案是前向欧拉预估子与二阶 Adams-Moulton 校正子（即隐式梯形法则）的耦合。\n\n其基本原理是常微分方程的积分形式，它将时间 $t_n$ 处的解与 $t_{n+1} = t_n + h_n$ 处的解联系起来：\n$$\ny(t_{n+1}) = y(t_n) + \\int_{t_n}^{t_{n+1}} f(s, y(s)) \\, ds.\n$$\n\n对于从 $t_n$ 到 $t_{n+1}$ 的每一步，指定的预估-校正算法分两个阶段进行：\n\n1.  **预估步**：使用显式前向欧拉方法生成 $t_{n+1}$ 处解的初步估计，记为 $y_{n+1}^p$。该方法假设被积函数 $f(s, y(s))$ 在区间 $[t_n, t_{n+1}]$ 上为常数，且等于其在区间起点的值 $f(t_n, y_n)$，从而近似该积分。\n    $$\n    y_{n+1}^p = y_n + h_n f(t_n, y_n).\n    $$\n    这是一个一阶精度的预估。\n\n2.  **校正步**：使用梯形法则获得一个更精确的校正值 $y_{n+1}^c$。该法则通过由 $f(t_n, y_n)$ 和 $f(t_{n+1}, y_{n+1})$ 之间的线性插值构成的梯形面积来近似积分。为避免求解关于 $y_{n+1}$ 的非线性隐式方程，使用预估值 $y_{n+1}^p$来计算区间末端的函数值 $f(t_{n+1}, y_{n+1}^p)$。\n    $$\n    y_{n+1}^c = y_n + \\frac{h_n}{2} \\left[ f(t_n, y_n) + f(t_{n+1}, y_{n+1}^p) \\right].\n    $$\n    这是一个二阶精度的校正。如果满足误差准则，则接受 $y_{n+1}^c$ 作为该步的最终近似值，即 $y_{n+1} = y_{n+1}^c$。\n\n自适应算法的核心是步长控制器，它依赖于对局部误差的估计。问题为从 $t_n$ 到 $t_{n+1}$ 的步长定义了一个特定的误差指标 $e_n$：\n$$\ne_n = \\frac{\\|y_{n+1}^p - y_{n+1}^c\\|}{h_n},\n$$\n其中 $\\|\\cdot\\|$ 对向量表示欧几里得范数，对标量表示绝对值。必须控制该指标，使其保持在指定的容差 $\\text{tol}$ 以下。\n\n一阶预估子的局部截断误差为 $O(h_n^2)$，而二阶校正子的局部截断误差为 $O(h_n^3)$。预估值与校正值之差 $y_{n+1}^c - y_{n+1}^p$ 是对预估步误差的估计，其阶为 $O(h_n^2)$。\n$$\n\\|y_{n+1}^p - y_{n+1}^c\\| = \\left\\| h_n f_n - \\frac{h_n}{2}(f_n + f(t_n+h_n, y_n+h_n f_n)) \\right\\| \\approx \\left\\| \\frac{h_n^2}{2} y''(t_n) \\right\\|.\n$$\n因此，误差指标 $e_n$ 的阶为 $O(h_n)$：\n$$\ne_n \\approx \\frac{1}{h_n} \\left\\| \\frac{h_n^2}{2} y''(t_n) \\right\\| = \\frac{h_n}{2} \\|y''(t_n)\\|.\n$$\n由于 $e_n \\propto h_n$，为了将步长从 $h_{old}$ 调整为 $h_{new}$，使得新误差 $e_{new}$ 近似于容差 $\\text{tol}$，我们使用关系 $e_{new}/e_{old} \\approx h_{new}/h_{old}$。这得出 $h_{new} \\approx h_{old} (\\text{tol}/e_{old})$。\n\n完整的自适应步长控制逻辑如下：\n\n1.  对于一个从 $t_n$ 到 $t_{n+1}$、建议步长为 $h$ 的步骤，首先要确保积分不会超过最终时间 $T$。实际使用的步长是 $h_{step} = \\min(h, T - t_n)$。\n\n2.  使用 $h_{step}$ 计算 $y_{n+1}^p$ 和 $y_{n+1}^c$。\n\n3.  计算误差指标 $e_n = \\|y_{n+1}^p - y_{n+1}^c\\|/h_{step}$。\n\n4.  **步长接受/拒绝**：\n    -   如果 $e_n \\le \\text{tol}$，则接受该步。新状态为 $(t_{n+1}, y_{n+1}) = (t_n + h_{step}, y_{n+1}^c)$。\n    -   如果 $e_n > \\text{tol}$，则拒绝该步。状态保持为 $(t_n, y_n)$，并且必须计算一个新的、更小的步长 $h$ 来重试该步。\n\n5.  **步长更新**：下一步长 $h_{next}$ 的计算基于当前步的结果。\n    -   使用一个安全因子 $S$ (例如 $S=0.9$) 来提供一个保守的估计。\n    -   更新公式为 $h_{new} = h_{step} \\times S \\times (\\frac{\\text{tol}}{e_n})$。\n    -   如果 $e_n=0$，应谨慎增加步长。一个合理的选择是将缩放因子 $\\text{tol}/e_n$ 设置为一个最大增长因子，例如 $5$。\n    -   为确保稳定性，步长的变化通常是受限的。我们强制要求 $h_{new}/h_{step} \\in [0.2, 5.0]$。\n    -   新的步长被限制在区间 $[h_{min}, h_{max}]$ 内。\n\n6.  **算法流程**：\n    -   如果一个步长被接受，$h_{next}$ 将使用更新规则计算，并用作后续步骤的初始猜测值。\n    -   如果一个步长被拒绝，$h_{next}$ 将被计算并用于*重试*当前步。此循环一直持续到某个步长被接受为止。\n\n7.  **死锁预防**：如果一个步长被拒绝，并且所需的新步长 $h_{next}$ 小于 $h_{min}$，或者当前步长 $h_{step}$ 已经等于 $h_{min}$，算法就会卡住。为防止死锁，使用 $h_{step}=h_{min}$ 计算出的当前结果 $y_{n+1}^c$ 来接受该步。下一步也将从 $h_{min}$ 开始。这是一个务实的选择，以确保算法能继续向前推进，即使误差容差被暂时违反。\n\n通过迭代应用这种自适应步长选取逻辑，积分从 $t_0$ 进行到 $T$，直到 $t_n=T$ 为止。最终的实现将四个指定测试用例的结果汇总到单一输出中。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef adaptive_am2_solver(f, t0, T, y0, tol, h0, h_min, h_max):\n    \"\"\"\n    Integrates an ODE y'(t) = f(t,y) from t0 to T with initial condition y0\n    using an adaptive 2nd-order Adams-Moulton (Trapezoidal) method.\n\n    The predictor is the Forward Euler method. The step size is adapted to keep\n    the local error per unit step below a tolerance.\n    \"\"\"\n    t = t0\n    y = np.asarray(y0, dtype=float)\n    h = h0\n\n    accepted_steps = 0\n    rejected_steps = 0\n\n    # Safety factor for step size update\n    safety_factor = 0.9\n    # Step size change limiters\n    max_growth = 5.0\n    min_shrink = 0.2\n\n    while t  T:\n        # Ensure the last step lands exactly on T\n        if t + h > T:\n            h = T - t\n\n        # Rejection loop for the current step\n        while True:\n            # Check for infinitesimal step size\n            if t + h = t:\n                # Cannot make progress, break from all loops\n                # This can happen if h becomes smaller than machine epsilon relative to t.\n                t = T \n                break\n\n            # Predictor step (Forward Euler)\n            f_current = f(t, y)\n            y_p = y + h * f_current\n\n            # Corrector step (Trapezoidal Rule)\n            y_c = y + (h / 2.0) * (f_current + f(t + h, y_p))\n            \n            # Estimate error\n            if y.ndim == 0: # Scalar case\n                error_norm = np.abs(y_p - y_c)\n            else: # Vector case\n                error_norm = np.linalg.norm(y_p - y_c)\n            \n            # Error per unit step as defined in the problem\n            e_n = error_norm / h if h > 0 else np.inf\n            \n            # Determine if the step is accepted or rejected\n            if e_n = tol:\n                # Step accepted\n                t += h\n                y = y_c\n                accepted_steps += 1\n                \n                # Calculate step size for the next step\n                if e_n == 0:\n                    growth_ratio = max_growth\n                else:\n                    # The update rule is derived from e_n being O(h)\n                    growth_ratio = safety_factor * (tol / e_n)\n                \n                h = h * min(max_growth, max(min_shrink, growth_ratio))\n                h = min(h_max, max(h_min, h))\n                \n                break # Exit rejection loop\n            else:\n                # Step rejected\n                rejected_steps += 1\n                \n                # Propose a smaller step size for retry\n                shrink_ratio = safety_factor * (tol / e_n)\n                h_new = h * min(max_growth, max(min_shrink, shrink_ratio))\n                \n                # Deadlock prevention\n                if h = h_min:\n                    # Current step size is at minimum, but error is too high.\n                    # Accept the step to move on.\n                    t += h\n                    y = y_c\n                    accepted_steps += 1\n                    h = h_min # Continue with h_min\n                    break # Exit rejection loop\n\n                h = max(h_min, h_new)\n\n\n    result = {\n        'y_final': y.item() if y.ndim == 0 else y,\n        'accepted_steps': accepted_steps,\n        'rejected_steps': rejected_steps,\n        'final_time': t\n    }\n    return result\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: scalar exponential decay\n        {\n            'name': 'A',\n            'f': lambda t, y: -2.0 * y,\n            't0': 0.0, 'T': 5.0,\n            'y0': 1.0,\n            'tol': 1e-5,\n            'h0': 0.1, 'h_min': 1e-6, 'h_max': 1.0,\n            'output': 'y_final'\n        },\n        # Case B: two-dimensional harmonic oscillator\n        {\n            'name': 'B',\n            'f': lambda t, y: np.array([y[1], -25.0 * y[0]]),\n            't0': 0.0, 'T': 2.0 * np.pi / 5.0,\n            'y0': np.array([1.0, 0.0]),\n            'tol': 1e-6,\n            'h0': 0.05, 'h_min': 1e-6, 'h_max': 0.2,\n            'output': 'y_final'\n        },\n        # Case C: scalar logistic growth\n        {\n            'name': 'C',\n            'f': lambda t, y: 3.0 * y * (1.0 - y / 1.0),\n            't0': 0.0, 'T': 5.0,\n            'y0': 0.2,\n            'tol': 1e-5,\n            'h0': 0.1, 'h_min': 1e-6, 'h_max': 0.5,\n            'output': 'y_final'\n        },\n        # Case D: edge case\n        {\n            'name': 'D',\n            'f': lambda t, y: y,\n            't0': 0.0, 'T': 1e-3,\n            'y0': 1.0,\n            'tol': 1e-10,\n            'h0': 1e-4, 'h_min': 1e-8, 'h_max': 1e-2,\n            'output': 'accepted_steps'\n        }\n    ]\n\n    results_list = []\n    for case in test_cases:\n        res = adaptive_am2_solver(\n            case['f'], case['t0'], case['T'], case['y0'],\n            case['tol'], case['h0'], case['h_min'], case['h_max']\n        )\n        output_val = res[case['output']]\n        \n        if isinstance(output_val, np.ndarray):\n            results_list.extend(output_val.tolist())\n        else:\n            results_list.append(output_val)\n\n    # Format output for precision and consistency\n    formatted_results = []\n    # Case A, C: float\n    formatted_results.append(f\"{results_list[0]:.6f}\") \n    # Case B: two floats\n    formatted_results.append(f\"{results_list[1]:.6f}\")\n    formatted_results.append(f\"{results_list[2]:.6f}\")\n    # Case C float\n    formatted_results.append(f\"{results_list[3]:.6f}\")\n    # Case D: int\n    formatted_results.append(f\"{results_list[4]}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2371573"}]}