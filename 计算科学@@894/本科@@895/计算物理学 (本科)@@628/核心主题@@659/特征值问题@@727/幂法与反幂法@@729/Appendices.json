{"hands_on_practices": [{"introduction": "理论是基础，但实践才能带来深刻的理解。在我们编写复杂的代码之前，让我们先通过一个概念性的热身练习来建立直觉。我们将分析幂迭代法在一个特殊矩阵——正交投影矩阵——上的单步行为。这个练习将清晰地揭示迭代过程是如何精确地分离出主导特征向量及其对应特征值的。[@problem_id:2427094]", "problem": "设 $v \\in \\mathbb{R}^{n}$ 为一个非零向量，并定义到由 $v$ 张成的一维子空间上的正交投影矩阵为 $P = \\dfrac{v v^{T}}{v^{T} v} \\in \\mathbb{R}^{n \\times n}$。考虑对矩阵 $P$ 应用带标准化的幂迭代法，给定初始向量 $x_{0} \\in \\mathbb{R}^{n}$ 满足 $v^{T} x_{0} \\neq 0$。一次迭代产生 $y_{1} = P x_{0}$ 和标准化后的迭代向量 $x_{1} = \\dfrac{y_{1}}{\\|y_{1}\\|_{2}}$。定义 $x_{1}$ 关于 $P$ 的瑞利商为 $r_{1} = \\dfrac{x_{1}^{T} P x_{1}}{x_{1}^{T} x_{1}}$。确定 $r_{1}$ 的精确值。最终答案必须是单个实数。无需进行四舍五入。", "solution": "该问题要求计算将幂迭代法应用于正交投影矩阵 $P$ 后，第一次迭代结果的瑞利商 $r_{1}$。\n\n首先，我们必须验证问题陈述的有效性。\n给定的条件如下：\n- 一个非零向量 $v \\in \\mathbb{R}^{n}$。\n- 正交投影矩阵 $P = \\dfrac{v v^{T}}{v^{T} v} \\in \\mathbb{R}^{n \\times n}$。\n- 一个初始向量 $x_{0} \\in \\mathbb{R}^{n}$，其性质为 $v^{T} x_{0} \\neq 0$。\n- 第一次未标准化的迭代结果为 $y_{1} = P x_{0}$。\n- 第一次标准化的迭代结果为 $x_{1} = \\dfrac{y_{1}}{\\|y_{1}\\|_{2}}$。\n- 瑞利商为 $r_{1} = \\dfrac{x_{1}^{T} P x_{1}}{x_{1}^{T} x_{1}}$。\n\n该问题科学地基于线性代数和数值分析的原理。正交投影算子、幂迭代法和瑞利商的定义都是标准的。该问题是适定的；条件 $v^{T} x_{0} \\neq 0$ 确保了第一次迭代结果 $y_{1}$ 不是零向量，因此其标准化 $x_{1}$ 是良定义的。该问题是客观的，并包含了唯一解所需的所有信息。因此，该问题被认为是有效的，我们将构建一个解。\n\n目标是计算 $r_{1}$。我们首先分析第一次迭代结果 $x_{1}$ 的结构。\n未标准化的迭代结果 $y_{1}$ 由下式给出：\n$$y_{1} = P x_{0} = \\left(\\dfrac{v v^{T}}{v^{T} v}\\right) x_{0} = \\dfrac{v (v^{T} x_{0})}{v^{T} v}$$\n让我们定义标量 $\\alpha = v^{T} x_{0}$。根据问题陈述，$\\alpha \\neq 0$。同时，我们记标量 $v^{T} v = \\|v\\|_{2}^{2}$。由于 $v$ 是非零向量，所以 $v^{T} v > 0$。\n根据这些定义，$y_{1}$ 的表达式可简化为：\n$$y_{1} = \\dfrac{\\alpha}{v^{T} v} v$$\n该表达式表明 $y_{1}$ 是向量 $v$ 的一个非零标量倍。\n\n接下来，我们对 $y_{1}$ 进行标准化以获得 $x_{1}$。标准化是关于欧几里得范数 $\\| \\cdot \\|_{2}$ 的。\n$y_{1}$ 的范数为：\n$$\\|y_{1}\\|_{2} = \\left\\| \\dfrac{\\alpha}{v^{T} v} v \\right\\|_{2} = \\left| \\dfrac{\\alpha}{v^{T} v} \\right| \\|v\\|_{2} = \\dfrac{|\\alpha|}{v^{T} v} \\sqrt{v^{T} v} = \\dfrac{|\\alpha|}{\\sqrt{v^{T} v}}$$\n现在，我们计算 $x_{1}$：\n$$x_{1} = \\dfrac{y_{1}}{\\|y_{1}\\|_{2}} = \\dfrac{\\frac{\\alpha}{v^{T} v} v}{\\frac{|\\alpha|}{\\sqrt{v^{T} v}}} = \\dfrac{\\alpha}{|\\alpha|} \\dfrac{\\sqrt{v^{T} v}}{v^{T} v} v = \\dfrac{\\alpha}{|\\alpha|} \\dfrac{1}{\\sqrt{v^{T} v}} v$$\n注意到 $\\sqrt{v^{T} v} = \\|v\\|_{2}$，我们可以将 $x_1$ 写成：\n$$x_{1} = \\text{sgn}(\\alpha) \\dfrac{v}{\\|v\\|_{2}}$$\n其中 $\\text{sgn}(\\alpha) = \\frac{\\alpha}{|\\alpha|}$ 是 $\\alpha$ 的符号。这表明 $x_{1}$ 是一个与 $v$ 同向或反向的单位向量。换句话说，$x_{1}$ 位于由 $v$ 张成的一维子空间中。\n\n现在我们必须计算瑞利商 $r_{1} = \\dfrac{x_{1}^{T} P x_{1}}{x_{1}^{T} x_{1}}$。\n根据标准化向量的定义，分母为 $x_{1}^{T} x_{1} = \\|x_{1}\\|_{2}^{2} = 1$。\n因此，瑞利商简化为 $r_{1} = x_{1}^{T} P x_{1}$。\n\n为了计算它，我们首先计算 $P$ 作用于 $x_{1}$ 的结果。\n$$P x_{1} = P \\left( \\text{sgn}(\\alpha) \\dfrac{v}{\\|v\\|_{2}} \\right) = \\text{sgn}(\\alpha) \\dfrac{1}{\\|v\\|_{2}} (P v)$$\n让我们计算 $P v$：\n$$P v = \\left(\\dfrac{v v^{T}}{v^{T} v}\\right) v = \\dfrac{v (v^{T} v)}{v^{T} v} = v$$\n这证实了 $v$ 是投影算子 $P$ 的一个特征向量，其对应的特征值为 $\\lambda = 1$。\n将此结果代回到 $P x_{1}$ 的表达式中：\n$$P x_{1} = \\text{sgn}(\\alpha) \\dfrac{1}{\\|v\\|_{2}} (v) = x_{1}$$\n这表明 $x_{1}$ 也是 $P$ 的一个特征向量，对应于特征值 $\\lambda = 1$。这是预料之中的，因为幂迭代法在单次迭代中就收敛到了与 $P$ 的主特征值 $1$ 相关联的特征向量。$P$ 的特征值为 $1$（特征向量为 $v$）和 $0$（特征空间为 $v$ 的张成空间的正交补）。\n\n最后，我们计算 $r_{1}$：\n$$r_{1} = x_{1}^{T} (P x_{1}) = x_{1}^{T} x_{1}$$\n因为 $x_{1}$ 是一个单位向量，所以 $x_{1}^{T} x_{1} = 1$。\n因此，瑞利商的值为：\n$$r_{1} = 1$$\n只要初始向量 $x_{0}$ 在 $v$ 的方向上有非零分量，这个结果就与 $x_{0}$ 的选择无关。", "answer": "$$\\boxed{1}$$", "id": "2427094"}, {"introduction": "现在是时候动手编写代码了。本练习将幂迭代法和反幂迭代法应用于一个在物理和工程领域中极为常见的矩阵：离散拉普拉斯算子。你将需要实现这两种算法，以找到该系统的最大和最小特征值，它们在物理问题中通常对应着最高和最低的能量模式或振动频率。[@problem_id:2428639]", "problem": "给定一个由实对称正定矩阵组成的族，该矩阵族由矩形上具有齐次狄利克雷边界条件的二维负拉普拉斯算子的有限差分法离散化得到。对于整数 $n_x \\ge 1$ 和 $n_y \\ge 1$，以及正常数边长 $L_x > 0$ 和 $L_y > 0$，定义均匀网格间距 $h_x = L_x/(n_x+1)$ 和 $h_y = L_y/(n_y+1)$。设 $T_x \\in \\mathbb{R}^{n_x \\times n_x}$ 和 $T_y \\in \\mathbb{R}^{n_y \\times n_y}$ 为三对角矩阵\n$$\nT_x = \\frac{1}{h_x^2}\\,\\mathrm{tridiag}(-1,\\,2,\\,-1),\\qquad\nT_y = \\frac{1}{h_y^2}\\,\\mathrm{tridiag}(-1,\\,2,\\,-1),\n$$\n并设 $I_x \\in \\mathbb{R}^{n_x \\times n_x}$ 和 $I_y \\in \\mathbb{R}^{n_y \\times n_y}$ 为单位矩阵。离散算子矩阵 $A \\in \\mathbb{R}^{(n_x n_y) \\times (n_x n_y)}$ 由克罗内克和定义为\n$$\nA = I_y \\otimes T_x \\;+\\; T_y \\otimes I_x.\n$$\n这代表了在矩形 $[0,L_x]\\times[0,L_y]$ 边界上具有齐次狄利克雷边界条件的内部网格点上，负拉普拉斯算子的标准五点差分格式。\n\n令 $n = n_x n_y$，并设 $x_0 \\in \\mathbb{R}^{n}$ 是一个所有分量均为 $1$ 的向量。考虑由 $A$ 和 $x_0$ 构造的以下两个单位向量序列：\n\n1. 定义 $u_0 = x_0/\\|x_0\\|_2$，且对于整数 $t_{\\mathrm{up}} \\ge 1$，为 $k=0,1,\\dots,t_{\\mathrm{up}}-1$ 递归地定义 $u_k$：\n$$\n\\tilde{u}_{k+1} = A u_k,\\qquad u_{k+1} = \\frac{\\tilde{u}_{k+1}}{\\|\\tilde{u}_{k+1}\\|_2}.\n$$\n令 $\\lambda_{\\mathrm{up}}$ 为瑞利商\n$$\n\\lambda_{\\mathrm{up}} = \\frac{u_{t_{\\mathrm{up}}}^\\top A\\,u_{t_{\\mathrm{up}}}}{u_{t_{\\mathrm{up}}}^\\top u_{t_{\\mathrm{up}}}}.\n$$\n\n2. 定义 $w_0 = x_0/\\|x_0\\|_2$，且对于整数 $t_{\\mathrm{low}} \\ge 1$，为 $k=0,1,\\dots,t_{\\mathrm{low}}-1$ 递归地定义 $w_k$：\n$$\n\\tilde{w}_{k+1} \\text{ 是 } A \\tilde{w}_{k+1} = w_k \\text{ 的唯一解},\\qquad w_{k+1} = \\frac{\\tilde{w}_{k+1}}{\\|\\tilde{w}_{k+1}\\|_2}.\n$$\n令 $\\lambda_{\\mathrm{low}}$ 为瑞利商\n$$\n\\lambda_{\\mathrm{low}} = \\frac{w_{t_{\\mathrm{low}}}^\\top A\\,w_{t_{\\mathrm{low}}}}{w_{t_{\\mathrm{low}}}^\\top w_{t_{\\mathrm{low}}}}.\n$$\n\n您的任务是编写一个程序，对下面的每个测试用例，完全按照定义构造矩阵 $A$，使用相同的初始向量 $x_0$ 和指定的迭代次数生成上述两个序列，并输出按规定计算的两个标量 $\\lambda_{\\mathrm{up}}$ 和 $\\lambda_{\\mathrm{low}}$。所有计算都是纯数值和无量纲的；不需要任何物理单位。如果您的方法内部引入了角度，应使用弧度，但本问题不要求使用角度。\n\n测试套件（每个元组为 $(n_x,n_y,L_x,L_y,t_{\\mathrm{up}},t_{\\mathrm{low}})$）：\n- 用例1: $(20,\\,20,\\,1.0,\\,1.0,\\,80,\\,80)$\n- 用例2: $(1,\\,1,\\,1.0,\\,1.0,\\,10,\\,10)$\n- 用例3: $(12,\\,8,\\,2.0,\\,1.0,\\,100,\\,100)$\n\n您的程序必须生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。对于每个测试用例，输出一个双元素列表 $[\\lambda_{\\mathrm{up}},\\lambda_{\\mathrm{low}}]$，两个值都四舍五入到小数点后六位。因此，总输出应为一个包含三个双元素列表的列表，其顺序与上述用例一致，例如：\n$[[\\ell_{1,\\mathrm{up}},\\ell_{1,\\mathrm{low}}],[\\ell_{2,\\mathrm{up}},\\ell_{2,\\mathrm{low}}],[\\ell_{3,\\mathrm{up}},\\ell_{3,\\mathrm{low}}]]$，其中每个 $\\ell$ 是一个保留小数点后六位的小数表示。", "solution": "该问题陈述已经过验证，被认定为有效。它具有科学依据，提法恰当，并为获得唯一的、可验证的解提供了所有必要信息。该问题要求实现两种基本的线性代数数值算法——幂迭代法和反幂迭代法——来寻找代表离散物理算子的矩阵的极值特征值。\n\n矩阵 $A$ 代表在矩形域 $[0, L_x] \\times [0, L_y]$ 上带有齐次狄利克雷边界条件的二维负拉普拉斯算子 $-\\nabla^2 = -(\\partial^2/\\partial x^2 + \\partial^2/\\partial y^2)$ 的五点有限差分离散。该域被离散化为一个 $(n_x+2) \\times (n_y+2)$ 的点网格，其中有 $n_x n_y$ 个内部点。矩阵 $A$ 作用于一个由这些内部点的函数值组成的向量。\n\n将 $A$ 构造为克罗内克和 $A = I_y \\otimes T_x + T_y \\otimes I_x$ 是可分离二维算子的标准数学表述。矩阵 $T_x$ 和 $T_y$ 是一维二阶导数算子 $-d^2/dx^2$ 在各自坐标轴上的缩放离散化。具体来说，矩阵 $\\mathrm{tridiag}(-1, 2, -1)$ 是离散一维拉普拉斯算子的一个缩放版本。由于 $A$ 是对称正定矩阵的和（因为 $T_x$ 和 $T_y$ 是缩放的对角占优M矩阵），$A$ 保证是对称正定的，并拥有实正特征值。\n\n用于计算 $\\lambda_{\\mathrm{up}}$ 的第一个序列是幂迭代法。这种迭代算法将矩阵 $A$ 重复作用于一个向量。对于一个给定的起始向量 $u_0$，若其在对应于主特征值（模最大的特征值）的特征向量方向上具有非零分量，则序列 $u_k = A^k u_0 / \\|A^k u_0\\|_2$ 会收敛到该特征向量。对于正定矩阵 $A$，主特征值就是最大特征值 $\\lambda_{\\max}$。该方法的核心是递推关系 $\\tilde{u}_{k+1} = A u_k$，然后是归一化 $u_{k+1} = \\tilde{u}_{k+1} / \\|\\tilde{u}_{k+1}\\|_2$。经过足够次数的迭代 $t_{\\mathrm{up}}$ 后，向量 $u_{t_{\\mathrm{up}}}$ 是相应特征向量的一个良好近似。\n\n用于计算 $\\lambda_{\\mathrm{low}}$ 的第二个序列是反幂迭代法。这在数学上等价于将幂迭代法应用于逆矩阵 $A^{-1}$。$A^{-1}$ 的特征值是 $A$ 的特征值的倒数。因此，$A^{-1}$ 的最大特征值对应于 $A$ 的最小特征值。迭代步骤需要为 $\\tilde{w}_{k+1}$ 求解线性系统 $A \\tilde{w}_{k+1} = w_k$，这在计算上比显式计算逆矩阵 $A^{-1}$ 并执行矩阵向量乘法更有效。随后的归一化 $w_{k+1} = \\tilde{w}_{k+1} / \\|\\tilde{w}_{k+1}\\|_2$ 完成一次迭代。经过 $t_{\\mathrm{low}}$ 次迭代后，向量 $w_{t_{\\mathrm{low}}}$ 收敛到与 $A$ 的最小特征值 $\\lambda_{\\min}$ 相关的特征向量。\n\n最后，瑞利商 $R_A(v) = (v^\\top A v) / (v^\\top v)$ 在给定一个近似特征向量 $v$ 时，提供了对 $A$ 的一个特征值的估计。对于一个归一化向量 $v$（即 $v^\\top v = \\|v\\|_2^2 = 1$），这简化为 $R_A(v) = v^\\top A v$。问题正确地将 $\\lambda_{\\mathrm{up}}$ 和 $\\lambda_{\\mathrm{low}}$ 定义为最终迭代向量 $u_{t_{\\mathrm{up}}}$ 和 $w_{t_{\\mathrm{low}}}$ 的瑞利商。这些将是 $\\lambda_{\\max}$ 和 $\\lambda_{\\min}$ 的高精度近似值。\n\n算法流程如下：\n1. 对于每个测试用例，定义参数 $n_x$、$n_y$、$L_x$、$L_y$、$t_{\\mathrm{up}}$ 和 $t_{\\mathrm{low}}$。\n2. 计算网格间距 $h_x = L_x / (n_x+1)$ 和 $h_y = L_y / (n_y+1)$。\n3. 按规定构造一维算子矩阵 $T_x \\in \\mathbb{R}^{n_x \\times n_x}$ 和 $T_y \\in \\mathbb{R}^{n_y \\times n_y}$。\n4. 使用克罗内克和 $A = I_y \\otimes T_x + T_y \\otimes I_x$ 构造完整的二维算子矩阵 $A \\in \\mathbb{R}^{(n_x n_y) \\times (n_x n_y)}$。\n5. 计算 $\\lambda_{\\mathrm{up}}$：初始化一个单位向量 $u_0$，并使用幂迭代法的递推公式 $u_{k+1} \\propto A u_k$ 迭代 $t_{\\mathrm{up}}$ 次。然后计算瑞利商 $\\lambda_{\\mathrm{up}} = u_{t_{\\mathrm{up}}}^\\top A u_{t_{\\mathrm{up}}}$。\n6. 计算 $\\lambda_{\\mathrm{low}}$：初始化一个单位向量 $w_0$，并通过求解 $A \\tilde{w}_{k+1} = w_k$ 并归一化 $w_{k+1} = \\tilde{w}_{k+1} / \\|\\tilde{w}_{k+1}\\|_2$ 来迭代 $t_{\\mathrm{low}}$ 次。然后计算瑞利商 $\\lambda_{\\mathrm{low}} = w_{t_{\\mathrm{low}}}^\\top A w_{t_{\\mathrm{low}}}$。\n7. 收集结果并按要求格式化。", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import solve as sp_solve\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test cases by constructing the discrete\n    Laplacian matrix and applying power and inverse power iterations to find\n    approximations of the largest and smallest eigenvalues.\n    \"\"\"\n    test_cases = [\n        (20, 20, 1.0, 1.0, 80, 80),\n        (1, 1, 1.0, 1.0, 10, 10),\n        (12, 8, 2.0, 1.0, 100, 100),\n    ]\n\n    results = []\n    for params in test_cases:\n        nx, ny, Lx, Ly, t_up, t_low = params\n\n        # Grid spacings\n        hx = Lx / (nx + 1)\n        hy = Ly / (ny + 1)\n\n        # Construct 1D tridiagonal matrices\n        diag_x = 2 * np.ones(nx)\n        offdiag_x = -1 * np.ones(nx - 1)\n        Tx = (1 / hx**2) * (np.diag(diag_x) + np.diag(offdiag_x, k=1) + np.diag(offdiag_x, k=-1))\n\n        diag_y = 2 * np.ones(ny)\n        offdiag_y = -1 * np.ones(ny - 1)\n        Ty = (1 / hy**2) * (np.diag(diag_y) + np.diag(offdiag_y, k=1) + np.diag(offdiag_y, k=-1))\n\n        # Identity matrices\n        Ix = np.eye(nx)\n        Iy = np.eye(ny)\n\n        # Construct 2D operator matrix A using Kronecker sum\n        A = np.kron(Iy, Tx) + np.kron(Ty, Ix)\n\n        # Dimension of the system\n        n = nx * ny\n\n        # Initial vector of all ones\n        x0 = np.ones(n)\n\n        # --- Power Iteration for lambda_up ---\n        u = x0 / np.linalg.norm(x0)\n        for _ in range(t_up):\n            u_tilde = A @ u\n            u = u_tilde / np.linalg.norm(u_tilde)\n        \n        # Rayleigh quotient for lambda_up\n        # Since u is a unit vector, u.T @ u = 1\n        lambda_up = u.T @ (A @ u)\n\n        # --- Inverse Iteration for lambda_low ---\n        w = x0 / np.linalg.norm(x0)\n        for _ in range(t_low):\n            # Solve A * w_tilde = w\n            w_tilde = sp_solve(A, w, assume_a='pos')\n            w = w_tilde / np.linalg.norm(w_tilde)\n            \n        # Rayleigh quotient for lambda_low\n        # Since w is a unit vector, w.T @ w = 1\n        lambda_low = w.T @ (A @ w)\n        \n        results.append([lambda_up, lambda_low])\n\n    # Format output\n    results_str = [f\"[{res[0]:.6f},{res[1]:.6f}]\" for res in results]\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```", "id": "2428639"}, {"introduction": "虽然基本的幂迭代和反幂迭代是基础，但更高级的算法能够提供惊人的收敛速度。这个实践将挑战你实现并比较三种方法：标准幂迭代、固定位移的反幂迭代，以及被称为瑞利商迭代 (Rayleigh Quotient Iteration, RQI) 的强大方法。通过观察它们在不同类型矩阵上的表现，你将对瑞利商迭代享有盛誉的三次收敛速度获得切身的体会。[@problem_id:2427128]", "problem": "实现一个算法，使用由 Rayleigh 商给定的可变位移的反迭代法，来近似计算一个实对称矩阵的特征对。对于一个非零向量 $x \\in \\mathbb{R}^n$，将其 Rayleigh 商定义为 $R(x) = \\dfrac{x^\\mathsf{T} A x}{x^\\mathsf{T} x}$。考虑将以下三种迭代方案应用于一个实对称矩阵 $A \\in \\mathbb{R}^{n \\times n}$，给定一个非零初始向量 $x_0 \\in \\mathbb{R}^n$ 和一个公差 $\\varepsilon > 0$：\n\n- 幂迭代：$x_{k+1} \\leftarrow \\dfrac{A x_k}{\\lVert A x_k \\rVert_2}$，其残差范数使用 $\\lambda_k = R(x_k)$ 定义为 $\\lVert A x_k - \\lambda_k x_k \\rVert_2$。\n- 固定位移的反迭代：固定 $\\sigma_0 = R(x_0)$，通过求解 $(A - \\sigma_0 I) y = x_k$ 并设置 $x_{k+1} \\leftarrow \\dfrac{y}{\\lVert y \\rVert_2}$ 来计算 $x_{k+1}$，其残差范数使用 $\\lambda_k = R(x_k)$ 定义为 $\\lVert A x_k - \\lambda_k x_k \\rVert_2$。\n- 使用等于 Rayleigh 商的可变位移的反迭代（Rayleigh 商迭代）：在每次迭代中，计算 $\\sigma_k = R(x_k)$，求解 $(A - \\sigma_k I) y = x_k$，并设置 $x_{k+1} \\leftarrow \\dfrac{y}{\\lVert y \\rVert_2}$，其残差范数使用 $\\lambda_k = R(x_k)$ 定义为 $\\lVert A x_k - \\lambda_k x_k \\rVert_2$。\n\n对于每种方案，当残差范数首次满足 $\\lVert A x_k - \\lambda_k x_k \\rVert_2 \\le \\varepsilon$ 或达到预设的最大迭代次数时停止。所有向量范数均为欧几里得范数，$I$ 表示大小为 $n$ 的单位矩阵。\n\n使用以下测试套件。在所有情况下，设置 $n = 5$，公差 $\\varepsilon = 10^{-10}$，以及最大迭代次数为 $1000$。\n\n- 测试用例 #1 (三对角对称正定矩阵):\n  - 矩阵 $A_1 \\in \\mathbb{R}^{5 \\times 5}$:\n    $$\n    A_1 =\n    \\begin{bmatrix}\n    6 & 2 & 0 & 0 & 0 \\\\\n    2 & 5 & 2 & 0 & 0 \\\\\n    0 & 2 & 4 & 2 & 0 \\\\\n    0 & 0 & 2 & 3 & 2 \\\\\n    0 & 0 & 0 & 2 & 2\n    \\end{bmatrix}.\n    $$\n  - 初始向量 $x_0^{(1)} = \\dfrac{1}{\\sqrt{5}} [1, 1, 1, 1, 1]^\\mathsf{T}$。\n\n- 测试用例 #2 (具有两个非常接近的特征值的对称矩阵):\n  - 定义对角矩阵 $D = \\mathrm{diag}(1, 1 + 10^{-6}, 2, 3, 4)$。\n  - 定义平面旋转，其角度 $\\theta$ 满足 $\\cos \\theta = \\dfrac{4}{5}$ 和 $\\sin \\theta = \\dfrac{3}{5}$，并设置\n    $$\n    Q = \\begin{bmatrix}\n    \\cos \\theta & -\\sin \\theta & 0 & 0 & 0 \\\\\n    \\sin \\theta & \\phantom{-}\\cos \\theta & 0 & 0 & 0 \\\\\n    0 & 0 & 1 & 0 & 0 \\\\\n    0 & 0 & 0 & 1 & 0 \\\\\n    0 & 0 & 0 & 0 & 1\n    \\end{bmatrix}.\n    $$\n  - 矩阵 $A_2 = Q^\\mathsf{T} D Q$。\n  - 初始向量 $x_0^{(2)} = [1, 0, 0, 0, 0]^\\mathsf{T}$。\n\n- 测试用例 #3 (Hilbert 矩阵):\n  - 矩阵 $A_3 \\in \\mathbb{R}^{5 \\times 5}$，其元素为 $(A_3)_{ij} = \\dfrac{1}{i + j - 1}$，其中 $i,j \\in \\{1, 2, 3, 4, 5\\}$。\n  - 初始向量 $x_0^{(3)} = \\dfrac{1}{\\sqrt{5}} [1, -1, 1, -1, 1]^\\mathsf{T}$。\n\n对于每个测试用例，使用相同的 $A$ 和 $x_0$ 独立运行这三种方案，并记录残差范数首次满足 $\\lVert A x_k - \\lambda_k x_k \\rVert_2 \\le \\varepsilon$ 时的最小迭代次数 $k$。如果在最大迭代次数内未收敛，则记录最大迭代次数。\n\n你的程序必须输出一行，其中包含一个由 $9$ 个整数组成的、以逗号分隔的列表，并用方括号括起来，顺序如下：\n$[k_{\\mathrm{RQI}}^{(1)}, k_{\\mathrm{fixed}}^{(1)}, k_{\\mathrm{power}}^{(1)}, k_{\\mathrm{RQI}}^{(2)}, k_{\\mathrm{fixed}}^{(2)}, k_{\\mathrm{power}}^{(2)}, k_{\\mathrm{RQI}}^{(3)}, k_{\\mathrm{fixed}}^{(3)}, k_{\\mathrm{power}}^{(3)}]$，其中 $k_{\\mathrm{RQI}}^{(i)}$ 是对测试用例 $i$ 进行 Rayleigh 商迭代的迭代次数，$k_{\\mathrm{fixed}}^{(i)}$ 是使用固定位移 $\\sigma_0 = R(x_0^{(i)})$ 的反迭代的迭代次数，$k_{\\mathrm{power}}^{(i)}$ 是幂迭代的迭代次数。输出必须是严格符合此格式的一行，除了列表表示结构上必需的字符或空白外，不得包含任何额外字符或空白。", "solution": "经评估，问题陈述有效。其科学依据扎根于数值线性代数的既有原理，特别是求解特征值问题的迭代方法。该问题是适定的 (well-posed)，所有必要的参数、矩阵、初始条件和停止准则都得到了明确且无歧义的定义。语言客观且正式。因此，将提供一个解决方案。\n\n问题要求实现并比较三种迭代算法，以近似计算实对称矩阵 $A$ 的一个特征对 $(\\lambda, v)$，其中 $A v = \\lambda v$。一个特征对由一个特征值 $\\lambda$ 及其对应的特征向量 $v$ 组成。所考虑的方法是幂迭代、固定位移的反迭代，以及可变位移的反迭代，也称为 Rayleigh 商迭代 (RQI)。对于一个实对称矩阵 $A \\in \\mathbb{R}^{n \\times n}$，其所有特征值均为实数，并且存在一个由特征向量构成的标准正交基。Rayleigh 商，对于一个非零向量 $x \\in \\mathbb{R}^n$ 定义为 $R(x) = \\frac{x^\\mathsf{T} A x}{x^\\mathsf{T} x}$，为特征值提供了一个估计。如果 $x$ 是一个特征向量，那么 $R(x)$ 就是对应的精确特征值。对于所有算法，我们从一个初始向量 $x_0$ 开始，生成一个收敛于某个特征向量的向量序列 $\\{x_k\\}$，以及一个收敛于对应特征值的 Rayleigh 商序列 $\\{\\lambda_k = R(x_k)\\}$。\n\n1. **幂迭代**\n\n   幂迭代法是寻找矩阵主特征对的最简单算法，即特征对 $(\\lambda_1, v_1)$，其中 $|\\lambda_1|$ 是所有特征值中模最大的。迭代步骤定义如下：\n    $$\n    x_{k+1} = \\frac{A x_k}{\\lVert A x_k \\rVert_2}\n    $$\n    从一个在主特征向量 $v_1$ 方向上有非零分量的初始向量 $x_0$ 开始，序列 $x_k$ 会收敛到 $v_1$。收敛是线性的，收敛速度由比率 $|\\lambda_2 / \\lambda_1|$ 决定，其中 $\\lambda_2$ 是模第二大的特征值。如果该比率接近于 1，收敛可能会非常慢。在每一步中，特征值由 Rayleigh 商 $\\lambda_k = R(x_k)$ 来近似。\n\n2. **固定位移的反迭代**\n\n   反迭代法是一种寻找与给定偏移量 $\\sigma$ 最接近的特征值所对应的特征对的方法。它将幂迭代法应用于矩阵 $(A - \\sigma I)^{-1}$。$(A - \\sigma I)^{-1}$ 的特征值为 $(\\lambda_i - \\sigma)^{-1}$，其中 $\\lambda_i$ 是 $A$ 的特征值。$(A - \\sigma I)^{-1}$ 的主特征值对应于 $|\\lambda_i - \\sigma|$ 的最小值，这意味着 $\\lambda_i$ 是 $A$ 中最接近 $\\sigma$ 的特征值。迭代步骤为：\n    $$\n    x_{k+1} = \\frac{(A - \\sigma I)^{-1} x_k}{\\lVert (A - \\sigma I)^{-1} x_k \\rVert_2}\n    $$\n   在实践中，我们避免计算矩阵的逆。而是求解线性系统 $(A - \\sigma I) y_k = x_k$ 以得到 $y_k$，然后进行归一化：\n    $$\n    x_{k+1} = \\frac{y_k}{\\lVert y_k \\rVert_2}\n    $$\n   在本问题中，整个过程使用一个固定的位移 $\\sigma_0 = R(x_0)$。收敛是线性的，但其速率取决于 $(A-\\sigma_0 I)^{-1}$ 模最大的两个特征值的比率。如果 $\\sigma_0$ 比其他任何特征值都更接近某个特征值 $\\lambda_j$，那么向特征向量 $v_j$ 的收敛会非常快。\n\n3. **Rayleigh 商迭代 (RQI)**\n\n   Rayleigh 商迭代是反迭代法的一种强大改进，其中位移在每一步都使用当前对特征值的最佳估计——Rayleigh 商进行更新。迭代过程定义如下：\n    1. 计算位移：$\\sigma_k = R(x_k) = \\frac{x_k^\\mathsf{T} A x_k}{x_k^\\mathsf{T} x_k}$。\n    2. 求解 $y_{k+1}$：$(A - \\sigma_k I) y_{k+1} = x_k$。\n    3. 归一化：$x_{k+1} = \\frac{y_{k+1}}{\\lVert y_{k+1} \\rVert_2}$。\n\n   对于对称矩阵，一旦迭代向量 $x_k$ 充分接近某个特征向量，RQI 会表现出三次收敛。这意味着近似值中正确数字的位数在每次迭代后大约增加三倍，从而导致极快的收敛速度。\n\n**停止准则**\n\n对于所有三种方法，当残差向量的范数 $\\lVert A x_k - \\lambda_k x_k \\rVert_2$ 降至指定的公差 $\\varepsilon$ 以下时，迭代终止，其中 $\\lambda_k = R(x_k)$。这个残差衡量了当前的近似对 $( \\lambda_k, x_k )$ 满足特征值方程的程度。首次满足此条件时的迭代次数 $k$ 是所需的输出。如果在最大迭代次数内条件未被满足，则记录该最大次数。\n\n实现将通过定义三个函数来进行，每个算法一个。每个函数将迭代生成向量序列，并在每一步检查停止准则，返回迭代次数。然后将这些函数应用于三个指定的测试用例。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef power_iteration(A, x0, tol, max_iter):\n    \"\"\"\n    Approximates a dominant eigenpair using Power Iteration.\n    \"\"\"\n    x = x0 / np.linalg.norm(x0)\n    for k in range(1, max_iter + 1):\n        # Calculate x_k\n        v = A @ x\n        x_k = v / np.linalg.norm(v)\n\n        # Check residual for x_k\n        # Since x_k is normalized, its L2 norm squared is 1.\n        lam_k = x_k.T @ A @ x_k\n        residual_norm = np.linalg.norm(A @ x_k - lam_k * x_k)\n\n        if residual_norm <= tol:\n            return k\n\n        # Prepare for the next iteration\n        x = x_k\n\n    return max_iter\n\ndef inverse_iteration_fixed_shift(A, x0, tol, max_iter):\n    \"\"\"\n    Approximates an eigenpair using inverse iteration with a fixed shift.\n    The shift is the Rayleigh quotient of the initial vector.\n    \"\"\"\n    # Normalize initial vector for stability, although given vectors are normalized.\n    # The problem specifies sigma0 = R(x0), where x0 is the given initial vector.\n    # Since all given x0 are unit norm, x0.T @ x0 = 1.\n    sigma0 = x0.T @ A @ x0\n    \n    try:\n        M = A - sigma0 * np.eye(A.shape[0])\n    except np.linalg.LinAlgError:\n        return max_iter # Fails if shift is an exact eigenvalue\n\n    x = x0 / np.linalg.norm(x0) # Start iteration with normalized vector\n\n    for k in range(1, max_iter + 1):\n        try:\n            # Solve (A - sigma0*I) y = x_{k-1}\n            y = np.linalg.solve(M, x)\n        except np.linalg.LinAlgError:\n            # Shift is an eigenvalue or matrix is numerically singular\n            return max_iter\n\n        x_k = y / np.linalg.norm(y)\n\n        # Check residual for x_k\n        lam_k = x_k.T @ A @ x_k\n        residual_norm = np.linalg.norm(A @ x_k - lam_k * x_k)\n\n        if residual_norm <= tol:\n            return k\n\n        x = x_k\n\n    return max_iter\n\ndef rayleigh_quotient_iteration(A, x0, tol, max_iter):\n    \"\"\"\n    Approximates an eigenpair using Rayleigh Quotient Iteration.\n    \"\"\"\n    x = x0 / np.linalg.norm(x0)\n    \n    for k in range(1, max_iter + 1):\n        # Update shift at each step using the Rayleigh quotient of x_{k-1}\n        sigma = x.T @ A @ x\n\n        try:\n            M = A - sigma * np.eye(A.shape[0])\n            # Solve (A - sigma_{k-1}*I) y = x_{k-1}\n            y = np.linalg.solve(M, x)\n        except np.linalg.LinAlgError:\n            # If the shift is an eigenvalue, the previous iterate was the eigenvector.\n            # Its residual should be zero or very small.\n            # The loop condition will have caught it in the previous iteration.\n            # This indicates a numerical breakdown or an exact hit.\n            return k-1 if k > 1 else max_iter\n\n        x_k = y / np.linalg.norm(y)\n\n        # Check residual for x_k\n        lam_k = x_k.T @ A @ x_k\n        residual_norm = np.linalg.norm(A @ x_k - lam_k * x_k)\n        \n        if residual_norm <= tol:\n            return k\n\n        x = x_k\n\n    return max_iter\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    n = 5\n    tol = 1e-10\n    max_iter = 1000\n\n    # Test Case 1\n    A1 = np.array([\n        [6, 2, 0, 0, 0],\n        [2, 5, 2, 0, 0],\n        [0, 2, 4, 2, 0],\n        [0, 0, 2, 3, 2],\n        [0, 0, 0, 2, 2]\n    ], dtype=float)\n    x0_1 = np.ones(n) / np.sqrt(n)\n\n    # Test Case 2\n    D = np.diag([1.0, 1.0 + 1e-6, 2.0, 3.0, 4.0])\n    cos_theta = 4.0 / 5.0\n    sin_theta = 3.0 / 5.0\n    Q = np.eye(n)\n    Q[0, 0] = cos_theta\n    Q[0, 1] = -sin_theta\n    Q[1, 0] = sin_theta\n    Q[1, 1] = cos_theta\n    A2 = Q.T @ D @ Q\n    x0_2 = np.zeros(n)\n    x0_2[0] = 1.0\n\n    # Test Case 3\n    A3 = np.fromfunction(lambda i, j: 1 / (i + j + 1), (n, n), dtype=float)\n    x0_3 = np.array([1, -1, 1, -1, 1]) / np.sqrt(n)\n    \n    test_cases = [\n        (A1, x0_1),\n        (A2, x0_2),\n        (A3, x0_3)\n    ]\n\n    results = []\n    for A, x0 in test_cases:\n        k_rqi = rayleigh_quotient_iteration(A, x0, tol, max_iter)\n        k_fixed = inverse_iteration_fixed_shift(A, x0, tol, max_iter)\n        k_power = power_iteration(A, x0, tol, max_iter)\n        \n        results.extend([k_rqi, k_fixed, k_power])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "2427128"}]}