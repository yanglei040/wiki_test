{"hands_on_practices": [{"introduction": "雅可比迭代的收敛性并非理所当然。这个练习将带你探索决定迭代法是否收敛的关键——迭代矩阵的谱半径。通过对几种典型的线性系统进行测试，你将直观地理解谱半径 $\\rho(T_J)$ 如何决定迭代过程能否收敛到正确解，以及其收敛速度的快慢。[@problem_id:2404665]", "problem": "给定形如 $A x = b$ 的方形线性系统，其中 $A \\in \\mathbb{R}^{n \\times n}$ 且 $b \\in \\mathbb{R}^{n}$。定义对角矩阵 $D = \\mathrm{diag}(A)$，线性算子 $T_J = I - D^{-1} A$, 以及向量 $c = D^{-1} b$。考虑以初始向量 $x^{(0)} = 0$ 开始的不动点迭代 $x^{(k+1)} = T_J x^{(k)} + c$。对于下面的每一个系统，计算谱半径 $\\rho(T_J)$，并通过将迭代结果与由 $A x^\\star = b$ 定义的精确解 $x^\\star$ 进行比较来评估收敛行为。\n\n对每个系统，用纯数学术语执行以下步骤：\n1. 计算 $\\rho(T_J)$，其中 $\\rho(T_J) = \\max_i |\\lambda_i(T_J)|$ 且 $\\{\\lambda_i(T_J)\\}$ 是 $T_J$ 的特征值。\n2. 如果 $\\rho(T_J) < 1$，则通过 $x^{(k+1)} = T_J x^{(k)} + c$ 生成序列 $\\{x^{(k)}\\}_{k=0}^{\\infty}$，直到首次达到索引 $k_{\\min}$ 使得相对误差 $\\|x^{(k)} - x^\\star\\|_2 / \\|x^\\star\\|_2 \\le \\varepsilon$ 被满足，其中 $\\varepsilon = 10^{-8}$ 是容差，$\\|\\cdot\\|_2$ 是欧几里得范数。报告这个最小索引 $k_{\\min}$、最终的相对误差 $\\|x^{(k_{\\min})} - x^\\star\\|_2 / \\|x^\\star\\|_2$，以及一个布尔值，如果在最多 $K_{\\max}$ 次迭代内满足容差，则为 $\\,\\mathrm{True}\\,$，否则为 $\\,\\mathrm{False}\\,$。使用 $K_{\\max} = 50000$ 作为迭代上限。\n3. 如果 $\\rho(T_J) \\ge 1$，则不进行迭代。在这种情况下，报告布尔值 $\\,\\mathrm{False}\\,$，将迭代次数设为 $0$，并报告初始猜测 $x^{(0)}$ 的相对误差，即 $\\|x^{(0)} - x^\\star\\|_2 / \\|x^\\star\\|_2$。\n4. 在所有情况下，精确解 $x^\\star$ 是满足 $A x^\\star = b$ 的唯一向量。所有量都是无量纲的。\n\n测试套件：\n- 案例1（平凡标量系统）：$A_1 = [\\,3\\,] \\in \\mathbb{R}^{1 \\times 1}$，$b_1 = [\\,1\\,] \\in \\mathbb{R}^{1}$。\n- 案例2（一维离散拉普拉斯算子，带狄利克雷边界，尺寸 $n$）：对于 $n = 50$，$A_2 \\in \\mathbb{R}^{n \\times n}$ 的主对角线元素为 $2$，第一副对角线和第一超对角线元素为 $-1$，其余元素为零；$b_2 = \\mathbf{1} \\in \\mathbb{R}^{n}$ 所有分量均为 $1$。\n- 案例3（严格对角占优三对角矩阵，尺寸 $n$）：对于 $n = 50$，$A_3 \\in \\mathbb{R}^{n \\times n}$ 的主对角线元素为 $5$，第一副对角线和第一超对角线元素为 $-1$，其余元素为零；$b_3 = \\mathbf{1} \\in \\mathbb{R}^{n}$ 所有分量均为 $1$。\n- 案例4（在此迭代下不收敛）：$A_4 = \\begin{bmatrix} 1 & 2 \\\\ 2 & 1 \\end{bmatrix} \\in \\mathbb{R}^{2 \\times 2}$，$b_4 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} \\in \\mathbb{R}^{2}$。\n\n要求的最终输出格式：\n- 您的程序必须生成单行输出，该输出将四个案例的结果按顺序聚合为一个列表的列表。对于每个案例，输出四元组 $[\\rho(T_J), k, \\text{rel\\_err}, \\text{converged}]$，其中 $\\rho(T_J)$ 和 $\\text{rel\\_err}$ 是四舍五入到六位小数的浮点数，$k$ 是一个整数，$\\text{converged}$ 是一个布尔值，其值恰好为 $\\mathrm{True}$ 或 $\\mathrm{False}$。\n- 单行输出必须是以下形式\n  $[[\\rho_1,k_1,e_1,\\mathrm{flag}_1],[\\rho_2,k_2,e_2,\\mathrm{flag}_2],[\\rho_3,k_3,e_3,\\mathrm{flag}_3],[\\rho_4,k_4,e_4,\\mathrm{flag}_4]]$\n  且该行中任何地方都没有空格。", "solution": "用户提交了一个关于分析 Jacobi 迭代法求解形如 $A x = b$ 的方形线性系统的问题。该任务要求验证问题陈述，如果有效，则提供一个包含理论分析和数值实现的全面解决方案。\n\n### 步骤 1：提取已知条件\n问题提供了以下定义和数据：\n- 一个方形线性系统 $A x = b$，其中 $A \\in \\mathbb{R}^{n \\times n}$ 且 $b \\in \\mathbb{R}^{n}$。\n- 对角矩阵 $D = \\mathrm{diag}(A)$。\n- Jacobi 迭代算子 $T_J = I - D^{-1} A$。\n- 向量 $c = D^{-1} b$。\n- Jacobi 不动点迭代定义为 $x^{(k+1)} = T_J x^{(k)} + c$。\n- 初始向量为 $x^{(0)} = \\mathbf{0}$。\n- $T_J$ 的谱半径为 $\\rho(T_J) = \\max_i |\\lambda_i(T_J)|$，其中 $\\{\\lambda_i(T_J)\\}$ 是 $T_J$ 的特征值。\n- 精确解是满足 $A x^\\star = b$ 的 $x^\\star$。\n- 相对误差的收敛容差为 $\\varepsilon = 10^{-8}$。\n- 相对误差定义为 $\\|x^{(k)} - x^\\star\\|_2 / \\|x^\\star\\|_2$，其中 $\\|\\cdot\\|_2$ 是欧几里得范数。\n- 最大迭代次数为 $K_{\\max} = 50000$。\n- 所有量都是无量纲的。\n\n指定了四个测试案例：\n1.  **案例 1**：$A_1 = [\\,3\\,]$，$b_1 = [\\,1\\,]$。\n2.  **案例 2**：$n = 50$，$A_2$ 是一维离散拉普拉斯矩阵（主对角线元素为 $2$，第一副对角线元素为 $-1$），$b_2 = \\mathbf{1}$。\n3.  **案例 3**：$n = 50$，$A_3$ 是一个严格对角占优三对角矩阵（主对角线元素为 $5$，第一副对角线元素为 $-1$），$b_3 = \\mathbf{1}$。\n4.  **案例 4**：$A_4 = \\begin{bmatrix} 1 & 2 \\\\ 2 & 1 \\end{bmatrix}$，$b_4 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$。\n\n每个案例所需的输出是一个四元组 $[\\rho(T_J), k, \\text{rel\\_err}, \\text{converged}]$。这包括谱半径、迭代次数、最终相对误差以及一个指示是否在 $K_{\\max}$ 次迭代内实现收敛的布尔值。\n\n### 步骤 2：使用提取的已知条件进行验证\n根据验证标准对问题陈述进行评估：\n\n-   **科学依据**：该问题基于 Jacobi 方法，这是数值线性代数和计算物理学中的一个基本迭代算法。谱半径、不动点迭代的收敛准则和矩阵特征值等概念是标准且完善的数学原理。测试案例，特别是离散拉普拉斯算子，是该领域的典型例子。该问题在科学上是合理的。\n-   **适定性**：问题定义清晰。对于每个案例，矩阵 $A$ 都是可逆的，保证了唯一精确解 $x^\\star$ 的存在。对角矩阵 $D$ 也是可逆的，因此 Jacobi 迭代算子 $T_J$ 是良定义的。迭代和终止的条件是明确的。每个案例都存在唯一且有意义的结果。\n-   **客观性**：问题使用精确、客观的数学语言陈述。没有主观论断或含糊不清之处。\n\n该问题没有表现出任何诸如科学上不合理、不可形式化、不完整、矛盾或不可行等缺陷。这是一个标准的、可验证的计算问题。\n\n### 步骤 3：结论与行动\n问题是**有效的**。将提供一个解决方案。\n\n### 基于原理的解决方案\nJacobi 方法是一种用于求解线性系统 $A x = b$ 的不动点迭代。矩阵 $A$ 被分解为 $A = D + L + U$，其中 $D$ 是 $A$ 的对角部分，$L$ 和 $U$ 分别是 $A$ 的严格下三角和上三角部分。方程 $A x = b$ 可以写成 $(D+L+U)x=b$，整理后得到 $Dx = -(L+U)x+b$。假设 $D$ 可逆，这就产生了迭代格式：\n$$x^{(k+1)} = -D^{-1}(L+U)x^{(k)} + D^{-1}b$$\n迭代矩阵是 $T_J = -D^{-1}(L+U)$。由于 $A = D+L+U$，我们可以写出 $L+U = A-D$，所以 $T_J = -D^{-1}(A-D) = -D^{-1}A + D^{-1}D = I - D^{-1}A$。向量是 $c = D^{-1}b$。因此，迭代过程为 $x^{(k+1)} = T_J x^{(k)} + c$。\n\n迭代方法的一个基本定理指出，对于任何初始猜测 $x^{(0)}$，此不动点迭代收敛的充分必要条件是迭代矩阵 $T_J$ 的谱半径小于 $1$，即 $\\rho(T_J) < 1$。\n\n总体流程如下：\n1.  对于每个系统 $(A, b)$，构造迭代矩阵 $T_J = I - D^{-1}A$。\n2.  计算 $T_J$ 的特征值并确定谱半径 $\\rho(T_J)$。\n3.  计算精确解 $x^\\star = A^{-1}b$。\n4.  如果 $\\rho(T_J) \\ge 1$，迭代发散。我们报告谱半径、迭代次数 $k=0$、初始猜测 $x^{(0)}=\\mathbf{0}$ 的相对误差（对于 $x^\\star \\neq \\mathbf{0}$，该误差为 $\\|-x^\\star\\|_2 / \\|x^\\star\\|_2 = 1$），以及一个 `False` 的收敛标志。\n5.  如果 $\\rho(T_J) < 1$，迭代收敛。我们从 $x^{(0)} = \\mathbf{0}$ 开始，并生成序列 $x^{(k+1)} = T_J x^{(k)} + c$，其中 $k=0, 1, 2, \\dots$。在每一步 $k$，我们计算相对误差 $e_k = \\|x^{(k)} - x^\\star\\|_2 / \\|x^\\star\\|_2$。该过程在第一个满足 $e_{k_{min}} \\le 10^{-8}$ 的迭代 $k_{min}$ 处停止。如果到 $k=K_{max}$ 时仍未发生，则终止该过程，并报告在指定限制内未收敛。\n\n**逐案分析：**\n\n**案例 1：** $A_1 = [\\,3\\,], b_1 = [\\,1\\,]$。\n- $D_1 = [\\,3\\,]$, $D_1^{-1} = [\\,1/3\\,]$。\n- $T_J = I - D_1^{-1}A_1 = [\\,1\\,] - [\\,1/3\\,][\\,3\\,] = [\\,0\\,]$。\n- 唯一的特征值是 $0$，所以 $\\rho(T_J) = 0$。\n- 由于 $\\rho(T_J) < 1$，该方法收敛。\n- $x^\\star = A_1^{-1}b_1 = [\\,1/3\\,]$。\n- $c = D_1^{-1}b_1 = [\\,1/3\\,]$。\n- $x^{(0)} = [\\,0\\,]$。\n- $x^{(1)} = T_J x^{(0)} + c = [\\,0\\,][\\,0\\,] + [\\,1/3\\,] = [\\,1/3\\,]$。\n- 该迭代在 $k=1$ 步内精确收敛。相对误差为 $\\|x^{(1)} - x^\\star\\|_2 / \\|x^\\star\\|_2 = 0$。\n\n**案例 2：** $n=50$，$A_2$ 是一维离散拉普拉斯算子。\n- $A_2$是一个三对角矩阵，主对角线元素为 $2$，副对角线和超对角线元素为 $-1$。\n- $D_2 = 2I$，所以 $D_2^{-1} = (1/2)I$。\n- $T_J = I - (1/2)A_2$。该矩阵主对角线元素为 $0$，副对角线和超对角线元素为 $1/2$。\n- 已知这类矩阵的特征值为 $\\lambda_j(T_J) = \\cos\\left(\\frac{j\\pi}{n+1}\\right)$，其中 $j=1, \\dots, n$。\n- 对于 $n=50$，谱半径为 $\\rho(T_J) = \\max_j|\\lambda_j| = \\cos\\left(\\frac{\\pi}{51}\\right)$。\n- 数值上，$\\rho(T_J) \\approx 0.998104$。由于 $\\rho(T_J) < 1$，迭代收敛，但谱半径非常接近 $1$，表明收敛速度很慢。数值实现将找到满足容差所需的精确迭代次数。\n\n**案例 3：** $n=50$，$A_3$ 是一个严格对角占优矩阵。\n- $A_3$是一个三对角矩阵，主对角线元素为 $5$，副对角线和超对角线元素为 $-1$。\n- $D_3 = 5I$，所以 $D_3^{-1} = (1/5)I$。\n- $T_J = I - (1/5)A_3$。该矩阵主对角线元素为 $0$，副对角线和超对角线元素为 $1/5$。\n- 其特征值为 $\\lambda_j(T_J) = \\frac{2}{5}\\cos\\left(\\frac{j\\pi}{n+1}\\right)$，其中 $j=1, \\dots, n$。\n- 对于 $n=50$，谱半径为 $\\rho(T_J) = \\frac{2}{5}\\cos\\left(\\frac{\\pi}{51}\\right)$。\n- 数值上，$\\rho(T_J) \\approx 0.4 \\times 0.998104 \\approx 0.399242$。这个值显著小于 $1$，保证了快速收敛。矩阵 $A_3$ 是严格对角占优的，这是 Jacobi 方法收敛的一个充分条件。\n\n**案例 4：** $A_4 = \\begin{bmatrix} 1 & 2 \\\\ 2 & 1 \\end{bmatrix}$。\n- $D_4 = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} = I$。\n- $T_J = I - D_4^{-1}A_4 = I - A_4 = \\begin{pmatrix} 0 & -2 \\\\ -2 & 0 \\end{pmatrix}$。\n- 特征方程为 $\\det(T_J - \\lambda I) = \\lambda^2 - 4 = 0$，得出特征值为 $\\lambda_1 = -2, \\lambda_2 = 2$。\n- 谱半径为 $\\rho(T_J) = \\max(|-2|, |2|) = 2$。\n- 由于 $\\rho(T_J) \\ge 1$，Jacobi 迭代对该系统不收敛。\n- 精确解为 $x^\\star = A_4^{-1} b_4 = \\begin{pmatrix} -1/3 & 2/3 \\\\ 2/3 & -1/3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1/3 \\\\ 1/3 \\end{pmatrix}$。\n- 初始猜测为 $x^{(0)} = \\mathbf{0}$。相对误差为 $\\|x^{(0)} - x^\\star\\|_2 / \\|x^\\star\\|_2 = \\|-x^\\star\\|_2 / \\|x^\\star\\|_2 = 1.0$。\n\n以下程序实现了此逻辑，以数值方式计算所需的结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Jacobi iteration problem for four specified linear systems.\n    \"\"\"\n    K_max = 50000\n    epsilon = 1e-8\n\n    def solve_case(A, b, K_max, epsilon):\n        \"\"\"\n        Analyzes a single linear system with the Jacobi method.\n\n        Args:\n            A (np.ndarray): The coefficient matrix.\n            b (np.ndarray): The constant vector.\n            K_max (int): Maximum number of iterations.\n            epsilon (float): Convergence tolerance.\n\n        Returns:\n            tuple: A tuple containing (rho_T_J, k, rel_err, converged).\n        \"\"\"\n        n = A.shape[0]\n        \n        # Extract the diagonal of A to form D\n        diag_A = np.diag(A)\n        if np.any(diag_A == 0):\n            # This case is excluded by problem constraints but is a necessary check.\n            raise ValueError(\"Matrix has a zero on its diagonal; Jacobi method is not applicable.\")\n        \n        D = np.diag(diag_A)\n        D_inv = np.diag(1.0 / diag_A) # More efficient than np.linalg.inv for diagonal\n        \n        # Construct the Jacobi iteration matrix T_J\n        T_J = np.identity(n) - D_inv @ A\n        \n        # Compute the spectral radius of T_J\n        eigenvalues = np.linalg.eigvals(T_J)\n        rho_T_J = np.max(np.abs(eigenvalues))\n        \n        # Compute the exact solution x_star\n        x_star = np.linalg.solve(A, b)\n        norm_x_star = np.linalg.norm(x_star, 2)\n        \n        if norm_x_star == 0:\n            # If x_star is the zero vector, the initial guess is exact.\n            return rho_T_J, 0, 0.0, True\n            \n        # Case 1: Iteration is not guaranteed to converge\n        if rho_T_J >= 1:\n            x0 = np.zeros_like(b)\n            # Initial relative error for x^(0) = 0\n            rel_err = np.linalg.norm(x0 - x_star, 2) / norm_x_star\n            return rho_T_J, 0, rel_err, False\n        \n        # Case 2: Iteration converges\n        else:\n            c = D_inv @ b\n            xk = np.zeros_like(b)\n            for k in range(K_max + 1):\n                rel_err = np.linalg.norm(xk - x_star, 2) / norm_x_star\n                \n                # Check for convergence\n                if rel_err <= epsilon:\n                    return rho_T_J, k, rel_err, True\n                \n                # Check if max iterations reached without convergence\n                if k == K_max:\n                    return rho_T_J, k, rel_err, False\n                \n                # Update for next iteration\n                xk = T_J @ xk + c\n        \n        # This part of the code should be unreachable given the logic above.\n        return rho_T_J, K_max, np.nan, False\n\n    # Define the test cases from the problem statement.\n    test_cases = []\n\n    # Case 1: Trivial scalar system\n    A1 = np.array([[3.0]], dtype=float)\n    b1 = np.array([1.0], dtype=float)\n    test_cases.append((A1, b1))\n\n    # Case 2: 1D discrete Laplacian\n    n2 = 50\n    diag2 = np.full(n2, 2.0, dtype=float)\n    off_diag2 = np.full(n2 - 1, -1.0, dtype=float)\n    A2 = np.diag(diag2) + np.diag(off_diag2, k=1) + np.diag(off_diag2, k=-1)\n    b2 = np.ones(n2, dtype=float)\n    test_cases.append((A2, b2))\n\n    # Case 3: Strictly diagonally dominant tridiagonal\n    n3 = 50\n    diag3 = np.full(n3, 5.0, dtype=float)\n    off_diag3 = np.full(n3 - 1, -1.0, dtype=float)\n    A3 = np.diag(diag3) + np.diag(off_diag3, k=1) + np.diag(off_diag3, k=-1)\n    b3 = np.ones(n3, dtype=float)\n    test_cases.append((A3, b3))\n    \n    # Case 4: Non-convergent case\n    A4 = np.array([[1.0, 2.0], [2.0, 1.0]], dtype=float)\n    b4 = np.array([1.0, 1.0], dtype=float)\n    test_cases.append((A4, b4))\n\n    results = []\n    for A, b in test_cases:\n        result = solve_case(A, b, K_max, epsilon)\n        results.append(result)\n\n    # Format the results into the required single-line string.\n    formatted_results = []\n    for rho, k, err, conv in results:\n        # Each sub-list is formatted as a string \"[rho,k,err,conv]\"\n        formatted_results.append(f\"[{rho:.6f},{k},{err:.6f},{str(conv)}]\")\n\n    # The final output is a string representation of a list of these sub-lists.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2404665"}, {"introduction": "在实际应用中，我们无法预知真实解，那么该如何判断迭代何时停止？本练习将解决这一关键问题，通过实现一个基于残差范数的停止准则。更重要的是，它揭示了一个深刻的洞见：小的残差不一定意味着小的误差，而这一现象由系统矩阵的条件数 $\\kappa(A)$ 所主导。[@problem_id:2404697]", "problem": "您的任务是为雅可比迭代实现一个基于残差范数的停止准则，并研究该准则在何种情况下能可靠地替代迭代的真实误差。考虑一个线性方程组 $A x = b$，其中 $A \\in \\mathbb{R}^{n \\times n}$ 是一个方阵，而 $b \\in \\mathbb{R}^{n}$ 是一个向量。雅可比迭代产生一个逼近真解 $x^{\\star}$ 的近似序列 $x^{(k)}$。第 $k$ 次迭代的残差定义为 $r^{(k)} = b - A x^{(k)}$，其欧几里得范数为 $\\lVert r^{(k)} \\rVert_{2}$。您必须实现的停止准则是，一旦 $\\lVert r^{(k)} \\rVert_{2} \\le \\tau$（其中 $\\tau > 0$ 是给定的容差）即终止，或者当达到指定的最大迭代次数时终止。您还必须在终止时（如果未收敛，则在达到迭代次数上限时）计算真实误差范数 $\\lVert x^{(k)} - x^{\\star} \\rVert_{2}$，其中 $x^{\\star}$ 在下面的测试用例中是已知的。\n\n请从基础的线性代数定义和事实出发，特别是方程 $A x = b$、欧几里得范数 $\\lVert \\cdot \\rVert_{2}$ 和残差定义 $r^{(k)} = b - A x^{(k)}$。除这些之外，不要假设任何专门的捷径结果。您应该为具有非零对角线项的通用非奇异矩阵 $A$ 正确实现雅可比迭代，使用初始猜测 $x^{(0)} = 0$。您的实现必须是通用的，并且无需硬编码特定于用例的行为即可适用于每个测试用例。\n\n您的研究必须评估使用残差范数作为真实误差范数的替代指标的可靠性。对于每个测试用例，在终止后，评估布尔语句“朴素可靠”，其定义为 $\\lVert x^{(k)} - x^{\\star} \\rVert_{2} \\le \\tau$；也就是说，判断实际误差是否不大于用作停止阈值的残差容差。同时计算欧几里得范数下的谱条件数 $\\kappa_{2}(A)$，以便将可靠性置于具体情境中分析。\n\n测试套件：\n- 测试用例 $1$ (良态，严格对角占优):\n  - $A_{1} = \\begin{bmatrix} 4 & 1 & 1 \\\\ 1 & 3 & 0 \\\\ 1 & 0 & 2 \\end{bmatrix}$,\n  - $x^{\\star}_{1} = \\begin{bmatrix} 1 \\\\ -2 \\\\ 3 \\end{bmatrix}$,\n  - $b_{1} = A_{1} x^{\\star}_{1}$,\n  - 残差容差 $\\tau_{1} = 10^{-10}$,\n  - 最大迭代次数 $N_{1} = 1000$。\n- 测试用例 $2$ (病态但雅可比迭代收敛):\n  - $A_{2} = \\begin{bmatrix} 1 & 9 \\times 10^{-4} \\\\ 9 \\times 10^{-4} & 10^{-6} \\end{bmatrix}$,\n  - $x^{\\star}_{2} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$,\n  - $b_{2} = A_{2} x^{\\star}_{2}$,\n  - 残差容差 $\\tau_{2} = 10^{-8}$,\n  - 最大迭代次数 $N_{2} = 5000$。\n- 测试用例 $3$ (雅可比迭代发散):\n  - $A_{3} = \\begin{bmatrix} 1 & 2 \\\\ 2 & 1 \\end{bmatrix}$,\n  - $x^{\\star}_{3} = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$,\n  - $b_{3} = A_{3} x^{\\star}_{3}$,\n  - 残差容差 $\\tau_{3} = 10^{-8}$,\n  - 最大迭代次数 $N_{3} = 200$。\n\n对于每个测试用例，使用 $x^{(0)} = 0$ 和停止规则 $\\lVert r^{(k)} \\rVert_{2} \\le \\tau$ 或达到迭代次数上限来运行雅可比迭代。在终止时，计算：\n- 一个收敛布尔值，指示是否在达到上限前满足了 $\\lVert r^{(k)} \\rVert_{2} \\le \\tau$，\n- 一个朴素可靠性布尔值，指示是否满足 $\\lVert x^{(k)} - x^{\\star} \\rVert_{2} \\le \\tau$,\n- 执行的迭代次数 (一个整数)，\n- 最终的残差范数 $\\lVert r^{(k)} \\rVert_{2}$ (一个浮点数)，\n- 最终的误差范数 $\\lVert x^{(k)} - x^{\\star} \\rVert_{2}$ (一个浮点数)，\n- 谱条件数 $\\kappa_{2}(A)$ (一个浮点数)，\n- 放大因子 $\\gamma = \\lVert x^{(k)} - x^{\\star} \\rVert_{2} / \\lVert r^{(k)} \\rVert_{2}$ (一个浮点数，如果分母为 $0$，则定义 $\\gamma = 0$ )。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个逗号分隔的各用例结果列表，无空格，并用方括号括起来。每个用例的结果列表必须严格按照以下顺序排列：\n$[\\text{收敛布尔值},\\text{朴素可靠性布尔值},\\text{迭代次数整数},\\text{残差范数浮点数},\\text{误差范数浮点数},\\text{条件数浮点数},\\text{放大因子浮点数}]$。\n例如，一个有效的整体输出结构是 $[[\\text{True},\\text{False},10,1.0,2.0,3.0,2.0],[\\dots],[\\dots]]$。\n\n不涉及角度。不涉及物理单位。所有数值结果都是无量纲的实数。输出必须是严格按照规定格式的单行文本，只包含布尔值和数字，并使用这些类型的规范文本形式。", "solution": "所提出的问题是有效的。这是一个在数值线性代数领域中定义明确的计算练习，基于已建立的科学原理，没有歧义或矛盾。我们将着手解决。\n\n核心任务是使用雅可比迭代法，对给定的方阵（非奇异）$A \\in \\mathbb{R}^{n \\times n}$ 和向量 $b \\in \\mathbb{R}^{n}$，求解线性方程组 $A x = b$。然后，我们将分析用作停止准则的残差范数与真实误差范数之间的关系。\n\n首先，我们建立雅可比迭代公式。矩阵 $A$ 被分解为其对角部分 $D$、严格下三角部分 $L$ 和严格上三角部分 $U$，使得 $A = D + L + U$。原始方程 $A x = b$ 可以写成 $(D + L + U) x = b$。为了进行迭代求解，我们重新整理该方程：\n$$D x = b - (L + U) x$$\n假设 $A$ 的对角元素都非零，则对角矩阵 $D$ 是可逆的。因此，我们可以定义一个迭代序列 $x^{(k)}$，并期望它收敛到真解 $x^{\\star}$：\n$$x^{(k+1)} = D^{-1} (b - (L + U) x^{(k)})$$\n其中 $k$ 是迭代索引，从初始猜测 $x^{(0)}$ 开始。问题指定 $x^{(0)} = 0$。用分量形式表示，在第 $k+1$ 次迭代中，向量 $x$ 的第 $i$ 个元素的更新规则是：\n$$x_{i}^{(k+1)} = \\frac{1}{A_{ii}} \\left( b_i - \\sum_{j \\neq i} A_{ij} x_j^{(k)} \\right)$$\n这个公式强调了新迭代向量 $x^{(k+1)}$ 的每个分量的计算仅依赖于前一个迭代向量 $x^{(k)}$ 的分量。\n\n雅可比方法的收敛性由雅可比迭代矩阵 $T_J = -D^{-1}(L+U)$ 的谱半径决定。当且仅当谱半径 $\\rho(T_J) < 1$ 时，对于任何初始猜测 $x^{(0)}$，迭代都保证收敛。一个保证收敛的充分但非必要条件是矩阵 $A$ 是严格对角占优的。\n\n问题要求一个基于残差向量欧几里得范数的停止准则。在每次迭代 $k$ 中，残差 $r^{(k)}$ 定义为右端项 $b$ 与将矩阵 $A$ 应用于当前近似解 $x^{(k)}$ 的结果之差：\n$$r^{(k)} = b - A x^{(k)}$$\n当 $\\lVert r^{(k)} \\rVert_{2} \\le \\tau$（其中 $\\tau$ 是给定的容差）或超过最大迭代次数 $N$ 时，迭代终止。\n\n本研究的一个核心部分是理解残差 $r^{(k)}$ 与真实误差 $e^{(k)} = x^{(k)} - x^{\\star}$ 之间的关系。根据真解的定义 $A x^{\\star} = b$，我们可以写出：\n$$r^{(k)} = A x^{\\star} - A x^{(k)} = A (x^{\\star} - x^{(k)}) = -A e^{(k)}$$\n由于 $A$ 是非奇异的，它的逆矩阵 $A^{-1}$ 存在。我们可以用残差来表示误差：\n$$e^{(k)} = -A^{-1} r^{(k)}$$\n对两边取欧几里得范数，并利用诱导矩阵范数的性质（$\\lVert M v \\rVert \\le \\lVert M \\rVert \\lVert v \\rVert$），我们得到一个重要的不等式：\n$$\\lVert e^{(k)} \\rVert_{2} = \\lVert A^{-1} r^{(k)} \\rVert_{2} \\le \\lVert A^{-1} \\rVert_{2} \\lVert r^{(k)} \\rVert_{2}$$\n这个不等式提供了一个基于残差范数的误差范数上界。对称地，从 $r^{(k)} = -A e^{(k)}$，我们有 $\\lVert r^{(k)} \\rVert_{2} \\le \\lVert A \\rVert_{2} \\lVert e^{(k)} \\rVert_{2}$，这给出了误差范数的一个下界：\n$$\\lVert e^{(k)} \\rVert_{2} \\ge \\frac{\\lVert r^{(k)} \\rVert_{2}}{\\lVert A \\rVert_{2}}$$\n将两者结合，得到完整的界定关系：\n$$\\frac{\\lVert r^{(k)} \\rVert_{2}}{\\lVert A \\rVert_{2}} \\le \\lVert e^{(k)} \\rVert_{2} \\le \\lVert A^{-1} \\rVert_{2} \\lVert r^{(k)} \\rVert_{2}$$\n使用残差范数 $\\lVert r^{(k)} \\rVert_{2}$ 作为误差范数 $\\lVert e^{(k)} \\rVert_{2}$ 的替代指标的可靠性，关键取决于 $\\lVert A \\rVert_{2}$ 和 $\\lVert A^{-1} \\rVert_{2}$ 的值。谱条件数 $\\kappa_{2}(A) = \\lVert A \\rVert_{2} \\lVert A^{-1} \\rVert_{2}$ 概括了这种关系。一个大的条件数表示矩阵是病态的，这意味着 $\\lVert A^{-1} \\rVert_{2}$ 可能很大。\n\n如果满足停止准则 $\\lVert r^{(k)} \\rVert_{2} \\le \\tau$，误差界变为：\n$$\\lVert e^{(k)} \\rVert_{2} \\le \\lVert A^{-1} \\rVert_{2} \\tau$$\n问题中定义的“朴素可靠”准则 $\\lVert e^{(k)} \\rVert_{2} \\le \\tau$ 只有在 $\\lVert A^{-1} \\rVert_{2} \\le 1$ 时才能得到保证。对于病态矩阵，$\\lVert A^{-1} \\rVert_{2}$ 可能远大于 $1$，导致真实误差比残差容差 $\\tau$ 大得多。放大因子 $\\gamma = \\lVert e^{(k)} \\rVert_{2} / \\lVert r^{(k)} \\rVert_{2}$ 直接量化了这种效应，我们预期 $\\gamma$ 与 $\\lVert A^{-1} \\rVert_{2}$ 有关。\n\n待实现的算法将对每个测试用例执行以下步骤：\n1. 初始化迭代计数器 $k=0$ 和解向量 $x^{(0)} = 0$。\n2. 从 $k=1$ 到最大迭代次数 $N$ 进行循环。\n3. 在每次迭代中，使用 $x^{(k-1)}$ 和雅可比公式计算下一个近似解 $x^{(k)}$。\n4. 计算残差 $r^{(k)} = b - A x^{(k)}$ 及其欧几里得范数 $\\lVert r^{(k)} \\rVert_{2}$。\n5. 检查是否 $\\lVert r^{(k)} \\rVert_{2} \\le \\tau$。如果为真，则迭代已收敛，终止循环。\n6. 如果循环完成而未达到容差，则表示在 $N$ 次迭代内未实现收敛。\n7. 在终止时（无论是通过收敛还是达到迭代上限），计算以下量：\n    - `converged`：一个布尔值，指示是否达到了容差。\n    - `naive-reliability`：一个布尔值，用于测试 $\\lVert x^{(k)} - x^{\\star} \\rVert_{2} \\le \\tau$。\n    - `iterations`：最终的迭代次数 $k$。\n    - `residual_norm`：$\\lVert r^{(k)} \\rVert_{2}$ 的最终值。\n    - `error_norm`：$\\lVert x^{(k)} - x^{\\star} \\rVert_{2}$ 的最终值。\n    - `condition_number`：矩阵的谱条件数 $\\kappa_{2}(A)$。\n    - `amplification_factor`：比率 $\\gamma = \\lVert e^{(k)} \\rVert_{2} / \\lVert r^{(k)} \\rVert_{2}$。\n\n此程序将应用于所提供的三个测试用例，它们旨在展示不同的行为：一个良态的收敛情况，一个病态但仍收敛的情况，以及一个发散的情况。结果将为残差、误差和条件数之间的理论关系提供经验证据。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy is not needed for this problem specification.\n\ndef run_jacobi_test(A, x_star, tau, N_max):\n    \"\"\"\n    Performs the Jacobi iteration for a given linear system Ax=b.\n\n    Args:\n        A (np.ndarray): The system matrix.\n        x_star (np.ndarray): The true solution vector.\n        tau (float): The residual norm tolerance for stopping.\n        N_max (int): The maximum number of iterations.\n\n    Returns:\n        list: A list containing the seven required result metrics.\n    \"\"\"\n    # Ensure inputs are numpy arrays with float type for precision\n    A = np.array(A, dtype=float)\n    x_star = np.array(x_star, dtype=float)\n    b = A @ x_star  # Calculate b from A and the known true solution\n\n    n = A.shape[0]\n    x_current = np.zeros(n, dtype=float)\n    \n    # Pre-calculate matrices for Jacobi iteration\n    diag_A = np.diag(A)\n    # The problem guarantees non-zero diagonal entries\n    D_inv = np.diag(1.0 / diag_A)\n    R = A - np.diag(diag_A)\n\n    num_iter = 0\n    converged = False\n\n    # The main iteration loop\n    for k in range(1, N_max + 1):\n        num_iter = k\n        \n        # Jacobi update: x_k = D^-1 * (b - (L+U) * x_{k-1})\n        x_next = D_inv @ (b - R @ x_current)\n        x_current = x_next\n        \n        # Calculate residual and its norm for the current iterate\n        r_current = b - A @ x_current\n        r_norm_current = np.linalg.norm(r_current, 2)\n        \n        # Check stopping criterion\n        if r_norm_current <= tau:\n            converged = True\n            break\n    else:\n        # This block executes if the for loop completes without a 'break'\n        converged = False\n        r_current = b - A @ x_current\n        r_norm_current = np.linalg.norm(r_current, 2)\n\n    # Post-iteration calculations\n    error_current = x_current - x_star\n    error_norm_current = np.linalg.norm(error_current, 2)\n\n    naive_reliability = error_norm_current <= tau\n    \n    cond_A = np.linalg.cond(A, 2)\n    \n    if r_norm_current == 0.0:\n        amplification_factor = 0.0\n    else:\n        amplification_factor = error_norm_current / r_norm_current\n        \n    return [\n        converged,\n        naive_reliability,\n        num_iter,\n        float(r_norm_current),\n        float(error_norm_current),\n        float(cond_A),\n        float(amplification_factor)\n    ]\n\ndef solve():\n    \"\"\"\n    Defines the test cases from the problem statement and runs the analysis.\n    \"\"\"\n    # Test case 1 (well-conditioned, strictly diagonally dominant)\n    A1 = [[4, 1, 1], [1, 3, 0], [1, 0, 2]]\n    x_star1 = [1, -2, 3]\n    tau1 = 1e-10\n    N1 = 1000\n\n    # Test case 2 (ill-conditioned but convergent Jacobi)\n    A2 = [[1, 9e-4], [9e-4, 1e-6]]\n    x_star2 = [1, 1]\n    tau2 = 1e-8\n    N2 = 5000\n\n    # Test case 3 (Jacobi diverges)\n    A3 = [[1, 2], [2, 1]]\n    x_star3 = [1, -1]\n    tau3 = 1e-8\n    N3 = 200\n\n    test_cases = [\n        (A1, x_star1, tau1, N1),\n        (A2, x_star2, tau2, N2),\n        (A3, x_star3, tau3, N3),\n    ]\n\n    results = []\n    for case in test_cases:\n        A, x_star, tau, N_max = case\n        result_list = run_jacobi_test(A, x_star, tau, N_max)\n        results.append(result_list)\n\n    # Format the final output string exactly as specified\n    per_case_strings = [f\"[{','.join(map(str, res))}]\" for res in results]\n    final_output = f\"[{','.join(per_case_strings)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```", "id": "2404697"}, {"introduction": "既然存在像 LU 分解这样的直接解法，我们为什么还要使用雅可比迭代法呢？这个最终练习将通过比较两种方法的计算成本，来回答这个根本性问题。通过分析成本如何随问题规模 $N$ 变化，你将理解迭代法在求解科学与工程领域中常见的大型稀疏线性系统时所扮演的关键角色。[@problem_id:2404653]", "problem": "您将研究在求解源于二维泊松问题的模型线性系统时，迭代 Jacobi 方法与直接下上 (LU) 分解之间的算法权衡。考虑一个带有齐次 Dirichlet 边界条件的边值问题，该问题在包含 $N \\times N$ 个内部点的均匀网格上进行离散化，从而产生一个大小为 $M \\times M$ 的线性系统，其中 $M = N^2$。系数矩阵 $A$ 对应于拉普拉斯算子的标准五点差分格式，其对角线上的元素为 $4$，四个直接相邻位置的元素为 $-1$；右侧向量对应于一个经过一致离散化的恒定源 $f \\equiv 1$。所有三角函数中的角度必须以弧度处理。\n\n您必须：\n\n- 为此问题实现一个 Jacobi 迭代求解器，该求解器在给定 $N$ 和一个容差 $\\varepsilon \\in (0,1)$ 的情况下，从零向量开始迭代，直到残差的相对 $\\ell_2$-范数 $\\|r_k\\|_2 / \\|r_0\\|_2$ 小于或等于 $\\varepsilon$ 为止，其中 $r_k = b - A x_k$。该求解器必须对于任何 $N \\ge 2$ 和任何 $\\varepsilon \\in (0,1)$ 都是正确的，并以无量纲量表示。此任务不涉及任何物理单位。\n- 使用标准例程为同一线性系统实现一个直接稠密 LU 分解求解器（注意：此处特意使用稠密形式，而非针对稀疏结构进行优化）。\n- 使用第一性原理的运算计数模型，对于不同的容差 $\\varepsilon$，确定当 Jacobi 方法和稠密 LU 分解都应用于上述二维 $N \\times N$ 内部网格泊松系统时，使得 Jacobi 方法比稠密 LU 分解更快的最小网格尺寸 $N$。将成本模型定义如下：\n  - 令 $M = N^2$ 为未知数的数量。将 Jacobi 的总成本建模为\n    $$\\mathcal{C}_{\\text{J}}(N,\\varepsilon) = M \\times K_{\\text{J}}(N,\\varepsilon),$$\n    其中 $K_{\\text{J}}(N,\\varepsilon)$ 是将相对残差减小到 $\\varepsilon$ 以下所需的 Jacobi 迭代次数。\n  - 将稠密 LU 的总成本建模为\n    $$\\mathcal{C}_{\\text{LU}}(N; r) = r \\left(\\tfrac{2}{3} M^3 + 2 M^2 \\right),$$\n    其中 $r > 0$ 是一个无量纲常数，它反映了相对实现效率和与机器相关的效应（与 Jacobi 相比，较小的 $r$ 意味着每个运算单元的 LU 分解相对更快）。\n  - 为实现本练习的目的，将交叉点 $N^\\star(\\varepsilon,r)$ 定义为满足以下条件的最小整数 $N \\ge 2$：\n    $$\\mathcal{C}_{\\text{J}}(N,\\varepsilon) \\le \\mathcal{C}_{\\text{LU}}(N; r)。$$\n- 您的程序必须通过结合您对 Jacobi 实现的理解和一个基于该模型问题 Jacobi 迭代矩阵谱特性推导出的、有数学依据的 $K_{\\text{J}}(N,\\varepsilon)$ 估计值来计算 $N^\\star(\\varepsilon,r)$。您必须从第一性原理出发进行推理。不要对代码进行计时；请使用指定的成本模型。\n\n测试套件：\n针对以下四个参数对 $(\\varepsilon, r)$ 评估交叉网格尺寸 $N^\\star(\\varepsilon,r)$：\n- $(10^{-6}, 1.0)$,\n- $(10^{-8}, 0.5)$,\n- $(10^{-2}, 2.0)$,\n- $(10^{-12}, 0.25)$.\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个由方括号括起来的、逗号分隔的四个整数列表，其顺序与测试套件中的顺序相同（例如，“[3,4,2,7]”）。不应打印任何其他文本。\n\n注意：\n- 角度必须以弧度为单位。\n- 所有量均为无量纲；不涉及任何物理单位。\n- 每个测试用例的答案都是一个整数。", "solution": "所述问题是数值分析中的一个标准练习，它适定、有科学依据且内部一致。所有给定的数据和定义足以得出一个唯一的解。因此，我们将直接进行推导和求解。\n\n该问题要求比较在单位正方形上求解带有齐次 Dirichlet 边界条件的二维泊松方程 $\\nabla^2 u = f$ 所导出的线性系统 $A\\mathbf{x} = \\mathbf{b}$ 的计算成本。该区域被离散化为一个包含 $N \\times N$ 个内部点的均匀网格。因此，系统的大小为 $M = N^2$。矩阵 $A$ 代表负拉普拉斯算子 $-\\nabla^2$ 的五点有限差分格式，这产生一个对角线上为 $4$，对应于四个最近网格邻居的非对角线位置上为 $-1$ 的矩阵。右侧向量 $\\mathbf{b}$ 对应于一个恒定的源项 $f \\equiv 1$。\n\n问题的核心是根据一个指定的成本模型，找出交叉网格尺寸 $N^\\star$，在该尺寸下，Jacobi 迭代方法在计算上变得比直接稠密 LU 分解更有效。这需要推导出为达到给定容差 $\\varepsilon$ 所需的 Jacobi 迭代次数 $K_{\\text{J}}$ 的解析估计。\n\n首先，我们分析 Jacobi 方法。矩阵 $A$ 被分解为 $A = D - L - U$，其中 $D$ 是 $A$ 的对角部分，$-L$ 和 $-U$ 分别是其严格下三角和上三角部分。对于我们的特定矩阵，$D$ 是一个标量矩阵，$D = 4I_M$，其中 $I_M$ 是大小为 $M$ 的单位矩阵。Jacobi 迭代由以下递推关系定义：\n$$D\\mathbf{x}_{k+1} = (L+U)\\mathbf{x}_k + \\mathbf{b}$$\n这可以重写为 $\\mathbf{x}_{k+1} = D^{-1}(L+U)\\mathbf{x}_k + D^{-1}\\mathbf{b}$。迭代矩阵为 $T_J = D^{-1}(L+U)$。由于 $L+U = D-A$，我们有 $T_J = D^{-1}(D-A) = I_M - D^{-1}A$。给定 $D = 4I_M$，这可以简化为：\n$$T_J = I_M - \\tfrac{1}{4}A$$\n\nJacobi 方法的收敛速率由迭代矩阵的谱半径 $\\rho(T_J)$ 决定，即其特征值的最大绝对值。对于 $N \\times N$ 网格上的二维离散泊松问题，矩阵 $A$ 的特征值是众所周知的：\n$$\\lambda_{p,q}(A) = 4 - 2\\left(\\cos\\left(\\frac{p\\pi}{N+1}\\right) + \\cos\\left(\\frac{q\\pi}{N+1}\\right)\\right) \\quad \\text{for } p,q = 1, 2, \\ldots, N$$\n因此，Jacobi 矩阵 $T_J$ 的特征值为：\n$$\\lambda_{p,q}(T_J) = 1 - \\frac{1}{4}\\lambda_{p,q}(A) = 1 - \\frac{1}{4}\\left[4 - 2\\left(\\cos\\left(\\frac{p\\pi}{N+1}\\right) + \\cos\\left(\\frac{q\\pi}{N+1}\\right)\\right)\\right]$$\n$$\\lambda_{p,q}(T_J) = \\frac{1}{2}\\left(\\cos\\left(\\frac{p\\pi}{N+1}\\right) + \\cos\\left(\\frac{q\\pi}{N+1}\\right)\\right)$$\n谱半径 $\\rho(T_J)$ 对应于模最大的特征值。由于余弦函数的参数位于区间 $(0, \\pi)$ 内，所有特征值都是实数且为正。最大值在参数最小时取得，即 $p=1$ 和 $q=1$ 时：\n$$\\rho(T_J) = \\lambda_{1,1}(T_J) = \\frac{1}{2}\\left(\\cos\\left(\\frac{\\pi}{N+1}\\right) + \\cos\\left(\\frac{\\pi}{N+1}\\right)\\right) = \\cos\\left(\\frac{\\pi}{N+1}\\right)$$\n\n问题指定了一个基于相对残差范数的停止准则：$\\|\\mathbf{r}_k\\|_2 / \\|\\mathbf{r}_0\\|_2 \\le \\varepsilon$，其中 $\\mathbf{r}_k = \\mathbf{b} - A\\mathbf{x}_k$。初始猜测为 $\\mathbf{x}_0 = \\mathbf{0}$，因此 $\\mathbf{r}_0 = \\mathbf{b}$。残差按 $\\mathbf{r}_{k+1} = T_J \\mathbf{r}_k$ 更新，导出 $\\mathbf{r}_k = T_J^k \\mathbf{r}_0$。准则变为 $\\|T_J^k \\mathbf{r}_0\\|_2 / \\|\\mathbf{r}_0\\|_2 \\le \\varepsilon$。\n使用矩阵范数可建立一个标准上界：$\\|T_J^k \\mathbf{r}_0\\|_2 \\le \\|T_J^k\\|_2 \\|\\mathbf{r}_0\\|_2$。由于 $T_J$ 是对称的，$\\|T_J\\|_2 = \\rho(T_J)$，因此 $\\|T_J^k\\|_2 = (\\rho(T_J))^k$。如果 $(\\rho(T_J))^k \\le \\varepsilon$，则条件得到满足。为求解迭代次数 $k$，我们取对数：\n$$k \\ln(\\rho(T_J)) \\le \\ln(\\varepsilon)$$\n由于对于任何有限的 $N \\ge 1$，都有 $\\rho(T_J) < 1$，其对数为负。因此，在相除时必须反转不等号：\n$$k \\ge \\frac{\\ln(\\varepsilon)}{\\ln(\\rho(T_J))}$$\n所需的迭代次数 $K_{\\text{J}}$ 是满足此式的最小整数，即右侧表达式的向上取整。\n$$K_{\\text{J}}(N,\\varepsilon) = \\left\\lceil \\frac{\\ln(\\varepsilon)}{\\ln\\left(\\cos\\left(\\frac{\\pi}{N+1}\\right)\\right)} \\right\\rceil$$\n\n现在我们来构建成本模型。Jacobi 方法的成本给出如下：\n$$\\mathcal{C}_{\\text{J}}(N,\\varepsilon) = M \\times K_{\\text{J}}(N,\\varepsilon) = N^2 \\left\\lceil \\frac{\\ln(\\varepsilon)}{\\ln\\left(\\cos\\left(\\frac{\\pi}{N+1}\\right)\\right)} \\right\\rceil$$\n稠密 LU 分解的成本给出如下：\n$$\\mathcal{C}_{\\text{LU}}(N; r) = r \\left(\\frac{2}{3} M^3 + 2 M^2 \\right) = r \\left(\\frac{2}{3} (N^2)^3 + 2 (N^2)^2 \\right) = r \\left(\\frac{2}{3} N^6 + 2 N^4 \\right)$$\n\n交叉网格尺寸 $N^\\star(\\varepsilon, r)$ 是使 Jacobi 方法变得更快（即 $\\mathcal{C}_{\\text{J}}(N,\\varepsilon) \\le \\mathcal{C}_{\\text{LU}}(N; r)$）的最小整数 $N \\ge 2$。这给出了不等式：\n$$N^2 \\left\\lceil \\frac{\\ln(\\varepsilon)}{\\ln\\left(\\cos\\left(\\frac{\\pi}{N+1}\\right)\\right)} \\right\\rceil \\le r \\left(\\frac{2}{3} N^6 + 2 N^4 \\right)$$\n对于 $N \\ge 1$，我们可以两边除以 $N^2$：\n$$\\left\\lceil \\frac{\\ln(\\varepsilon)}{\\ln\\left(\\cos\\left(\\frac{\\pi}{N+1}\\right)\\right)} \\right\\rceil \\le r \\left(\\frac{2}{3} N^4 + 2 N^2 \\right)$$\n左侧代表迭代次数，其增长近似为 $O(N^2)$，而右侧项的增长为 $O(N^4)$。对于较小的 $N$，Jacobi 成本 $\\mathcal{C}_{\\text{J}} \\approx O(N^4)$ 会超过 LU 成本 $\\mathcal{C}_{\\text{LU}} \\approx O(N^6)$，但由于多项式的高阶增长，LU 成本最终将占据主导地位。我们正在寻找第一个使不等式反转并成立的整数 $N \\ge 2$。\n由于向上取整函数和超越项的存在，这个不等式不易求得 $N$ 的闭式解。然而，我们可以通过从 $N=2$ 开始对整数值 $N$ 进行迭代，并在满足条件的第一个值处停止，从而以计算方式找到解。这些函数是单调的，确保了唯一的交叉点。我们将为测试套件中提供的每个参数对 $(\\varepsilon, r)$ 实现这种搜索。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the crossover grid size N* for which the Jacobi method becomes\n    more efficient than dense LU factorization for a 2D Poisson problem.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1e-6, 1.0),\n        (1e-8, 0.5),\n        (1e-2, 2.0),\n        (1e-12, 0.25),\n    ]\n\n    results = []\n    for epsilon, r_factor in test_cases:\n        n_star = find_crossover_n(epsilon, r_factor)\n        results.append(n_star)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef find_crossover_n(epsilon, r):\n    \"\"\"\n    Searches for the smallest integer N >= 2 that satisfies the crossover condition.\n\n    Args:\n        epsilon (float): The tolerance for the Jacobi solver.\n        r (float): The relative efficiency factor for the LU solver.\n\n    Returns:\n        int: The smallest grid size N for which Jacobi is more efficient.\n    \"\"\"\n    n = 2\n    while True:\n        # Calculate the number of Jacobi iterations, K_J.\n        # The spectral radius of the Jacobi iteration matrix is rho_J = cos(pi / (N+1)).\n        arg_cos = np.pi / (n + 1)\n        \n        # For N >= 2, 0 < arg_cos < pi/2, so cos is in (0, 1) and its log is negative.\n        rho_j = np.cos(arg_cos)\n        k_j = np.ceil(np.log(epsilon) / np.log(rho_j))\n\n        # Calculate the computational cost for Jacobi, C_J.\n        # The system size is M = N*N. Cost model is M * K_J.\n        cost_j = (n**2) * k_j\n\n        # Calculate the computational cost for dense LU, C_LU.\n        # Cost model is r * (2/3 * M^3 + 2 * M^2).\n        m = n**2\n        cost_lu = r * ((2/3) * (m**3) + 2 * (m**2))\n\n        # Check for the crossover condition.\n        if cost_j <= cost_lu:\n            return n\n        \n        n += 1\n\nif __name__ == \"__main__\":\n    solve()\n\n```", "id": "2404653"}]}