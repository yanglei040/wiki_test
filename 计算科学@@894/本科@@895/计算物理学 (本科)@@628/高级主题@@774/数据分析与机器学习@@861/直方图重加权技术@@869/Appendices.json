{"hands_on_practices": [{"introduction": "第一个练习在经典的统计物理背景下，提供了一个多重直方图重加权方法的具体应用。你将使用在仅三个不同温度下测量的二维伊辛模型的蒙特卡洛能量直方图数据，来重建完整的比热曲线 $C(T)$。这项实践将巩固你对 WHAM 如何优化组合数据，以估算远超原始模拟条件的更广泛范围内的热力学性质的理解。[@problem_id:2401585]", "problem": "考虑一个定义在方形晶格上的二维铁磁伊辛模型，晶格线性尺寸为 $L$，采用周期性边界条件，耦合常数 $J=1$，玻尔兹曼常数设为 $k_B=1$。其哈密顿量为 $H = -\\sum_{\\langle ij \\rangle} s_i s_j$，其中 $s_i \\in \\{-1,+1\\}$，求和遍及方形晶格上的所有最近邻自旋对。设 $N=L^2$ 为自旋总数，$N_b=2N$ 为键总数。对于 $L=4$（即 $N=16$）的系统，其所有可能的总能量值为九个：$-32,-24,-16,-8,0,8,16,24,32$（以 $J$ 为单位）。在逆温度为 $\\beta=1/T$ 的正则系综中，观测到能量为 $E$ 的概率为 $p_\\beta(E) \\propto g(E)\\,\\exp(-\\beta E)$，其中 $g(E)$ 是态密度（简并度）。单位自旋比热定义为 $C(T)=\\beta^2\\,\\mathrm{Var}_\\beta(E)/N$。\n\n现给定 $L=4$ 系统在三个不同温度下（一个低于临界温度，一个接近临界温度，一个高于临界温度）通过蒙特卡洛模拟得到的能量统计直方图。每个直方图都按顺序报告了对应于上述九个能量值的计数值。这三个温度及其对应的直方图（每个直方图的总样本数为 $100000$）如下：\n- 温度 $T_1 = 2.0$，计数值（按能量从 $-32$ 到 $32$ 的顺序排列）：$[36000, 42000, 18000, 3000, 800, 100, 60, 30, 10]$。\n- 温度 $T_2 = 2.269$，计数值：$[6000, 14000, 24000, 23000, 17000, 9000, 4000, 2000, 1000]$。\n- 温度 $T_3 = 3.0$，计数值：$[1000, 4000, 9000, 16000, 21000, 20000, 16000, 9000, 4000]$。\n\n请从正则系综的第一性原理出发，在不假设任何关于态密度 $g(E)$ 的先验知识的情况下，使用组方图重加权方法，结合这三个直方图来估计 $g(E)$，然后计算在一系列目标温度下的单位自旋比热 $C(T)$。你的方法必须仅依赖于所提供的直方图，不得使用任何外部数据或进行更多的模拟。你必须：\n- 论证并实现一种统计上可靠的方法，以组合在不同温度下收集的多个直方图，并通过强制其与正则概率保持一致性来推断 $g(E)$（其结果可相差一个乘法常数）。\n- 利用推断出的 $g(E)$，通过对九个能量值进行离散求和，计算在任意目标温度 $T$ 下的配分函数，并评估能量的平均值和方差，从而得到 $C(T)$。\n\n假设所有直方图都来自独立样本（你可以忽略自相关修正）。所有计算均在 $k_B=1$ 和 $J=1$ 的单位制下进行，所要求的输出是单位自旋比热，在此单位制下为无量纲量。\n\n测试集：计算以下目标温度（以 $J$ 为单位）下的 $C(T)$：$[1.8, 2.0, 2.269, 2.5, 3.0, 3.2]$。该温度集合包括一个略低于所提供的最低温度直方图的温度，两个与所提供直方图温度重合的温度，一个接近临界温度的温度，以及两个高于所提供的最高温度直方图的温度。\n\n你的程序必须生成单行输出，包含六个结果，格式为一个用方括号括起来的逗号分隔列表，每个值四舍五入到六位小数（例如，“[0.123456,0.234567,0.345678,0.456789,0.567890,0.678901]”）。所有输出都是在 $k_B=1$ 单位制下的单位自旋比热。", "solution": "所提出的问题在科学上是合理的、内容自洽且提法恰当。它要求应用多重组方图重加权方法来分析二维伊辛模型的模拟数据，这在计算统计物理学中是一种标准且强大的技术。因此，我们将着手进行严谨的求解。\n\n本分析的基础是统计力学中的正则系综。对于一个处于固定逆温度 $\\beta = 1/T$（玻尔兹曼常数 $k_B=1$）的系统，观测到能量为 $E$ 的微观态的概率 $p_\\beta(E)$ 由下式给出：\n$$\np_\\beta(E) = \\frac{g(E) e^{-\\beta E}}{Z(\\beta)}\n$$\n此处，$g(E)$ 是态密度（或简并度），即对应于能量 $E$ 的不同微观态的数量。配分函数 $Z(\\beta)$ 作为归一化常数，其定义为对所有可能能级 $E_i$ 的求和：\n$$\nZ(\\beta) = \\sum_{i} g(E_i) e^{-\\beta E_i}\n$$\n该问题提供了来自 $R=3$ 次独立蒙特卡洛模拟的数据，这些模拟分别在逆温度 $\\beta_j=1/T_j$（$j \\in \\{1, 2, 3\\}$）下进行。对于每次模拟 $j$，我们都得到了一个能量直方图，其中包含在总共 $M_j$ 个样本中观测到能量 $E_i$ 的次数 $n_{ij}$。因此，经验概率为 $n_{ij}/M_j$。这为真实的正则概率提供了一个估计：\n$$\n\\frac{n_{ij}}{M_j} \\approx p_{\\beta_j}(E_i) = \\frac{g(E_i) e^{-\\beta_j E_i}}{Z(\\beta_j)}\n$$\n根据这一关系，可以利用单次模拟 $j$ 的数据推导出态密度 $g(E_i)$ 的一个估计：\n$$\ng(E_i) \\propto \\frac{n_{ij}}{M_j} e^{\\beta_j E_i}\n$$\n其中的比例常数涉及未知的配分函数 $Z(\\beta_j)$。通过结合所有 $R$ 次模拟的数据，可以获得对 $g(E_i)$ 的一个更稳健的估计。实现这一目标的统计最优方法是多重组方图方法，也称为加权组方图分析方法（WHAM）。该方法可以得出一个改进的 $g(E_i)$ 估计，该估计与所有数据集同时保持一致。态密度的组合估计由下式给出：\n$$\ng(E_i) = \\frac{\\sum_{j=1}^{R} n_{ij}}{\\sum_{j=1}^{R} M_j e^{f_j - \\beta_j E_i}}\n$$\n其中参数 $f_j$ 与模拟的无量纲自由能 $F_j = -T_j \\ln Z(\\beta_j)$ 相关，使得 $Z(\\beta_j) \\propto e^{-f_j}$。这些参数必须通过自洽方式确定。将 $g(E_i)$ 的表达式代回到配分函数 $Z(\\beta_k) \\propto e^{-f_k}$ 的定义中，得到以下自洽方程组：\n$$\ne^{-f_k} = \\sum_{i} g(E_i) e^{-\\beta_k E_i} = \\sum_{i} \\frac{\\sum_{j=1}^{R} n_{ij}}{\\sum_{j=1}^{R} M_j e^{f_j - \\beta_j E_i}} e^{-\\beta_k E_i} \\quad \\text{for } k=1, \\dots, R\n$$\n这个包含 $R$ 个未知数 $\\{f_1, \\dots, f_R\\}$ 的 $R$ 个耦合非线性方程组可以通过迭代方法求解。值得注意的是，如果 $\\{f_j\\}$ 是一组解，那么对于任意常数 $C$，$\\{f_j + C\\}$ 也是一组解。这种规范自由度可以通过将其中一个参数设为常数来固定，例如，令 $f_1=0$。为确保数值稳定性，最好使用对数来实现迭代求解，特别是采用 `log-sum-exp` 技巧来处理指数项的求和。\n\n迭代过程如下：\n1. 初始化参数，例如，对所有 $j=1, \\dots, R$，令 $f_j = 0$。\n2. 在每次迭代中，为所有能级 $i$ 计算态密度对数 $\\ln g(E_i)$ 的更新估计值：\n   $$\n   \\ln g(E_i) = \\ln\\left(\\sum_{j=1}^{R} n_{ij}\\right) - \\ln\\left(\\sum_{j=1}^{R} M_j e^{f_j - \\beta_j E_i}\\right)\n   $$\n3. 使用新的 $\\ln g(E_i)$ 重新计算自由能参数：\n   $$\n   f_k^{\\text{new}} = -\\ln\\left(\\sum_i e^{\\ln g(E_i) - \\beta_k E_i}\\right)\n   $$\n4. 对新得到的集合 $\\{f_k^{\\text{new}}\\}$ 进行归一化，例如通过平移所有值使得第一个元素为零：$f_k \\leftarrow f_k^{\\text{new}} - f_1^{\\text{new}}$。\n5. 重复步骤 2-4，直到 $\\{f_j\\}$ 的值收敛到指定的容差范围内。\n\n一旦获得收敛的 $f_j$ 值，我们就得到了 $\\ln g(E_i)$ 的最终估计（其结果可相差一个无关的加法常数）。这使得我们可以在任何目标逆温度 $\\beta_{\\text{target}}$ 下计算任意热力学可观测量。某个量 $A(E)$ 的期望值为：\n$$\n\\langle A \\rangle_{\\beta_{\\text{target}}} = \\frac{\\sum_i A(E_i) g(E_i) e^{-\\beta_{\\text{target}} E_i}}{\\sum_i g(E_i) e^{-\\beta_{\\text{target}} E_i}} = \\frac{\\sum_i A(E_i) e^{\\ln g(E_i) - \\beta_{\\text{target}} E_i}}{\\sum_i e^{\\ln g(E_i) - \\beta_{\\text{target}} E_i}}\n$$\n该问题要求计算单位自旋比热 $C(T)$，其定义为：\n$$\nC(T) = \\frac{\\beta^2}{N} \\text{Var}_\\beta(E) = \\frac{\\beta^2}{N} \\left(\\langle E^2 \\rangle_\\beta - \\langle E \\rangle_\\beta^2\\right)\n$$\n其中 $N=16$ 是自旋数。我们将使用重加权后的态密度，为每个指定的目标温度计算期望值 $\\langle E \\rangle$ 和 $\\langle E^2 \\rangle$，并随后确定 $C(T)$。所提供的数据包括在 $L=4$ 的晶格上，当 $T \\in \\{2.0, 2.269, 3.0\\}$ 时的直方图，以及能级 $E_i \\in \\{-32, -24, -16, -8, 0, 8, 16, 24, 32\\}$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import logsumexp\n\ndef solve():\n    \"\"\"\n    Solves the problem of calculating specific heat using the multiple histogram \n    reweighting method for the 2D Ising model.\n    \"\"\"\n    # Define problem parameters and givens\n    L = 4\n    N_spins = L * L\n    # The nine possible energy levels for the L=4 system\n    energies = np.array([-32, -24, -16, -8, 0, 8, 16, 24, 32], dtype=float)\n\n    # Simulation temperatures and their corresponding inverse temperatures (beta)\n    sim_temps = np.array([2.0, 2.269, 3.0])\n    sim_betas = 1.0 / sim_temps\n\n    # Histogram counts from the three simulations\n    counts = np.array([\n        [36000, 42000, 18000, 3000, 800, 100, 60, 30, 10],      # T=2.0\n        [6000, 14000, 24000, 23000, 17000, 9000, 4000, 2000, 1000], # T=2.269\n        [1000, 4000, 9000, 16000, 21000, 20000, 16000, 9000, 4000]  # T=3.0\n    ], dtype=float)\n\n    num_samples_per_sim = 100000.0\n    R, K = counts.shape  # R = number of simulations, K = number of energy bins\n\n    # Total counts for each energy level, summed across all simulations\n    total_counts_per_energy = np.sum(counts, axis=0)\n    \n    # --- Multiple Histogram Reweighting (WHAM) ---\n    # Iteratively solve for the free-energy-related parameters f_j.\n    # The parameters f are related to the log of the partition functions.\n    f = np.zeros(R)\n\n    # Precompute terms for efficiency\n    beta_E_matrix = np.outer(sim_betas, energies)  # Shape (R, K)\n    log_num_samples = np.log(num_samples_per_sim)\n\n    max_iter = 1000\n    tolerance = 1e-12\n\n    for _ in range(max_iter):\n        f_old = f.copy()\n\n        # Step 1: Calculate the log of the density of states, g(E), using the current f_j.\n        # log g(E_i) = log(sum_j n_ij) - log(sum_j M_j exp(f_j - beta_j E_i))\n        f_broadcast = np.tile(f, (K, 1)).T\n        log_denominators = logsumexp(log_num_samples + f_broadcast - beta_E_matrix, axis=0)\n        log_g = np.log(total_counts_per_energy) - log_denominators\n\n        # Step 2: Update f_k using the self-consistency equation.\n        # exp(-f_k) = sum_i g(E_i) exp(-beta_k E_i)\n        # We work with logs: f_k = -log(sum_i exp(log g_i - beta_k E_i))\n        log_g_broadcast = np.tile(log_g, (R, 1))\n        f_new_unnormalized = -logsumexp(log_g_broadcast - beta_E_matrix, axis=1)\n\n        # Normalize the new f_k to fix the gauge freedom (set f_1 = 0)\n        f = f_new_unnormalized - f_new_unnormalized[0]\n\n        # Check for convergence\n        if np.max(np.abs(f - f_old)) < tolerance:\n            break\n            \n    # The last computed log_g is the final estimate from the converged f_j.\n\n    # --- Calculation of Specific Heat at Target Temperatures ---\n    target_temps = np.array([1.8, 2.0, 2.269, 2.5, 3.0, 3.2])\n    target_betas = 1.0 / target_temps\n\n    results = []\n    for beta in target_betas:\n        # Calculate log of terms in the partition function sum: log(g(E_i)) - beta * E_i\n        w = log_g - beta * energies\n\n        # Use logsumexp trick for numerical stability to compute expectation values\n        w_max = np.max(w)\n        exp_w_shifted = np.exp(w - w_max)\n        \n        # Denominator for expectation values is sum_i exp(w_i - w_max)\n        denominator = np.sum(exp_w_shifted)\n        \n        # Calculate <E>\n        mean_E_numerator = np.sum(energies * exp_w_shifted)\n        mean_E = mean_E_numerator / denominator\n        \n        # Calculate <E^2>\n        mean_E2_numerator = np.sum(energies**2 * exp_w_shifted)\n        mean_E2 = mean_E2_numerator / denominator\n        \n        # Variance of energy\n        var_E = mean_E2 - mean_E**2\n        \n        # Specific heat per spin: C = beta^2 * Var(E) / N\n        C_per_spin = (beta**2 * var_E) / N_spins\n        results.append(C_per_spin)\n\n    # Print the final results in the specified format\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```", "id": "2401585"}, {"introduction": "在看一个具体应用之后，我们现在转向其底层的理论基础。这个问题要求你从第一性原理出发，推导一个广义的重加权公式，该公式用于合并在不同统计系综（例如，正则系综 $NVT$ 和巨正则系综 $\\mu VT$）中进行的模拟数据。掌握这一推导将使你对像 WHAM 和 MBAR 这类现代重加权方法的统计最优性和非凡普适性有更深刻的见解。[@problem_id:2401647]", "problem": "考虑一个固定体积 $V$ 内的全同粒子的经典多粒子系统，其构型 $\\mathbf{x}$ 的势能由 $U(\\mathbf{x})$ 描述。进行了两次独立的模拟：\n\n1. 模拟 $A$ 是在正则系综（粒子数、体积、温度恒定；$NVT$）中进行的，逆温为 $\\beta_{A}$，粒子数固定为 $N_{A}$。它产生了 $M_{A}$ 个独立样本 $\\{\\mathbf{x}_{n}\\}_{n=1}^{M_{A}}$。\n2. 模拟 $B$ 是在巨正则系综（化学势、体积、温度恒定；$\\mu VT$）中进行的，逆温为 $\\beta_{B}$，化学势为 $\\mu_{B}$。它产生了 $M_{B}$ 个粒子数 $N$ 和构型 $\\mathbf{x}$ 的独立样本 $\\{(N_{m},\\mathbf{x}_{m})\\}_{m=1}^{M_{B}}$。\n\n定义未归一化的概率密度\n- 对于模拟 $A$（在联合态空间 $(N,\\mathbf{x})$ 上考察），定义为 $q_{A}(N,\\mathbf{x}) \\equiv \\frac{1}{N!}\\,\\exp\\!\\big(-\\beta_{A} U(\\mathbf{x})\\big)\\,\\delta_{N,N_{A}}$，\n- 对于模拟 $B$，定义为 $q_{B}(N,\\mathbf{x}) \\equiv \\frac{z_{B}^{N}}{N!}\\,\\exp\\!\\big(-\\beta_{B} U(\\mathbf{x})\\big)$，其中活度 $z_{B} \\equiv \\exp(\\beta_{B}\\mu_{B})/\\Lambda_{B}^{3}$，而 $\\Lambda_{B}$ 是在 $\\beta_{B}$ 下的热德布罗意波长，\n- 对于目标巨正则态 $(\\beta_{*},\\mu_{*},V)$，定义为 $q_{*}(N,\\mathbf{x}) \\equiv \\frac{z_{*}^{N}}{N!}\\,\\exp\\!\\big(-\\beta_{*} U(\\mathbf{x})\\big)$，其中 $z_{*} \\equiv \\exp(\\beta_{*}\\mu_{*})/\\Lambda_{*}^{3}$。\n\n设相应的归一化常数（配分函数）为 $Z_{A} \\equiv \\sum_{N}\\int q_{A}(N,\\mathbf{x})\\,\\mathrm{d}\\mathbf{x}$ 和 $\\Xi_{B} \\equiv \\sum_{N}\\int q_{B}(N,\\mathbf{x})\\,\\mathrm{d}\\mathbf{x}$，并定义约化自由能 $f_{A} \\equiv -\\ln Z_{A}$ 和 $f_{B} \\equiv -\\ln \\Xi_{B}$。\n\n仅使用系综平均和概率密度的第一性原理定义，推导一个闭式解析表达式，该表达式结合来自模拟 $A$ 和 $B$ 的所有样本，以估计在目标巨正则态 $(\\beta_{*},\\mu_{*},V)$ 中任意可观测量 $A(N,\\mathbf{x})$ 的期望值 $\\langle A \\rangle_{*}$。你的最终表达式必须明确地用样本集 $\\{(N_{n},\\mathbf{x}_{n})\\}_{n=1}^{M}$（其中 $M \\equiv M_{A}+M_{B}$，且对于模拟 $A$ 的样本有 $N_{n}=N_{A}$）、未归一化密度 $q_{A}$、$q_{B}$、$q_{*}$、样本数 $M_{A}$ 和 $M_{B}$ 以及约化自由能 $f_{A}$ 和 $f_{B}$ 来表示。除了可测性外，不要对 $A(N,\\mathbf{x})$ 作任何特定的函数形式假设。请将你的最终答案表示为单个闭式解析表达式。无需进行数值计算或四舍五入，也无需单位。", "solution": "本题要求推导在目标巨正则系综中，可观测量 $A(N,\\mathbf{x})$ 的期望值 $\\langle A \\rangle_{*}$ 的闭式表达式。该估计量必须以最优方式结合来自两次独立模拟的样本，一次是正则系综（$A$），另一次是巨正则系综（$B$）。推导将从系综平均的基本定义和重要性抽样的原理出发。\n\n在由未归一化概率密度 $q_{*}(N,\\mathbf{x})$ 表征的目标态“$*$”中，可观测量 $A(N,\\mathbf{x})$ 的期望值定义为在粒子数 $N$ 和构型 $\\mathbf{x}$ 的整个态空间上两个积分的比值。我们将复合的积分和求和测度记为 $\\mathrm{d}\\mu(N,\\mathbf{x}) \\equiv \\sum_{N=0}^{\\infty} \\int \\mathrm{d}\\mathbf{x}$。期望值由下式给出：\n$$\n\\langle A \\rangle_{*} = \\frac{\\int A(N,\\mathbf{x}) q_{*}(N,\\mathbf{x}) \\, \\mathrm{d}\\mu(N,\\mathbf{x})}{\\int q_{*}(N,\\mathbf{x}) \\, \\mathrm{d}\\mu(N,\\mathbf{x})}\n$$\n分母是目标态的配分函数，$\\Xi_{*} = \\int q_{*}(N,\\mathbf{x}) \\, \\mathrm{d}\\mu(N,\\mathbf{x})$。\n\n可用的数据包括从正则概率分布 $p_{A}(N,\\mathbf{x}) = Z_{A}^{-1} q_{A}(N,\\mathbf{x})$ 中抽取的 $M_{A}$ 个样本 $\\{\\mathbf{x}_{n}\\}_{n=1}^{M_A}$，以及从巨正则分布 $p_{B}(N,\\mathbf{x}) = \\Xi_{B}^{-1} q_{B}(N,\\mathbf{x})$ 中抽取的 $M_{B}$ 个样本 $\\{(N_{m},\\mathbf{x}_{m})\\}_{m=1}^{M_B}$。这里，$Z_{A} = \\exp(-f_{A})$ 和 $\\Xi_{B} = \\exp(-f_{B})$ 分别是模拟 $A$ 和 $B$ 的归一化常数（配分函数）。对于来自模拟 $A$ 的样本，粒子数固定为 $N_{A}$。我们将这些样本合并成一个包含 $M = M_{A} + M_{B}$ 个样本的集合，记为 $\\{(N_n, \\mathbf{x}_n)\\}_{n=1}^{M}$。\n\n为了估计 $\\langle A \\rangle_{*}$，我们可以采用重要性抽样。最有效的方法是，将所有样本视为从一个能够最佳代表总抽样工作的最优混合分布中抽取的。观测到给定状态 $(N,\\mathbf{x})$ 的概率，与在每次模拟中观测到该状态的概率之和成正比，并按该次模拟的样本数进行加权。这定义了一个有效的、未归一化的抽样密度：\n$$\n\\rho_{\\text{eff}}(N,\\mathbf{x}) \\propto M_{A} p_{A}(N,\\mathbf{x}) + M_{B} p_{B}(N,\\mathbf{x})\n$$\n代入 $p_{A}$ 和 $p_{B}$ 的表达式，我们得到：\n$$\n\\rho_{\\text{eff}}(N,\\mathbf{x}) \\propto M_{A} Z_{A}^{-1} q_{A}(N,\\mathbf{x}) + M_{B} \\Xi_{B}^{-1} q_{B}(N,\\mathbf{x})\n$$\n使用给定的约化自由能 $f_{A} = -\\ln Z_{A}$ 和 $f_{B} = -\\ln \\Xi_{B}$，上式变为：\n$$\n\\rho_{\\text{eff}}(N,\\mathbf{x}) \\propto M_{A} \\exp(f_{A}) q_{A}(N,\\mathbf{x}) + M_{B} \\exp(f_{B}) q_{B}(N,\\mathbf{x})\n$$\n\n我们现在可以通过将被积函数乘以并除以一个与此有效密度成正比的权重函数，来重写 $\\langle A \\rangle_{*}$ 的表达式。设权重函数为 $W(N,\\mathbf{x}) = [M_{A} \\exp(f_{A}) q_{A}(N,\\mathbf{x}) + M_{B} \\exp(f_{B}) q_{B}(N,\\mathbf{x})]^{-1}$。$\\langle A \\rangle_{*}$ 的分子可以写作关于该混合分布的期望值：\n$$\n\\int A(N,\\mathbf{x}) q_{*}(N,\\mathbf{x}) \\, \\mathrm{d}\\mu(N,\\mathbf{x}) = \\int \\frac{A(N,\\mathbf{x}) q_{*}(N,\\mathbf{x})}{W(N,\\mathbf{x})^{-1}} \\, W(N,\\mathbf{x})^{-1} \\, \\mathrm{d}\\mu(N,\\mathbf{x})\n$$\n右侧的积分是函数 $A(N,\\mathbf{x}) q_{*}(N, \\mathbf{x}) W(N, \\mathbf{x})$ 对于一个与 $W(N, \\mathbf{x})^{-1} = \\rho_{\\text{eff}}$ 成正比的分布的期望值。这样的期望值可以通过对所有 $M$ 个收集到的数据点进行样本平均来估计。同样的处理方法也适用于 $\\langle A \\rangle_{*}$ 的分母。\n\n因此，$\\langle A \\rangle_{*}$ 的估计量是两个样本平均值的比值：\n$$\n\\langle A \\rangle_{*} \\approx \\frac{\\sum_{n=1}^{M} A(N_{n}, \\mathbf{x}_{n}) q_{*}(N_{n}, \\mathbf{x}_{n}) W(N_{n}, \\mathbf{x}_{n})}{\\sum_{n=1}^{M} q_{*}(N_{n}, \\mathbf{x}_{n}) W(N_{n}, \\mathbf{x}_{n})}\n$$\n代入权重函数 $W(N_{n}, \\mathbf{x}_{n})$ 的表达式，得到：\n$$\n\\langle A \\rangle_{*} \\approx \\frac{\\sum_{n=1}^{M} \\frac{A(N_{n}, \\mathbf{x}_{n}) q_{*}(N_{n}, \\mathbf{x}_{n})}{M_{A} \\exp(f_{A}) q_{A}(N_{n}, \\mathbf{x}_{n}) + M_{B} \\exp(f_{B}) q_{B}(N_{n}, \\mathbf{x}_{n})}}{\\sum_{n=1}^{M} \\frac{q_{*}(N_{n}, \\mathbf{x}_{n})}{M_{A} \\exp(f_{A}) q_{A}(N_{n}, \\mathbf{x}_{n}) + M_{B} \\exp(f_{B}) q_{B}(N_{n}, \\mathbf{x}_{n})}}\n$$\n这就是最终的闭式表达式。对于合并集中的每个样本 $(N_{n}, \\mathbf{x}_{n})$，我们计算函数 $q_{A}$、$q_{B}$ 和 $q_{*}$，并根据此公式将它们组合起来。对于源自模拟 $A$ 的样本，$N_n=N_A$。对于来自模拟 $B$ 且粒子数 $N_n \\neq N_A$ 的样本，由于其定义中的克罗内克δ函数 $\\delta_{N,N_A}$，项 $q_A(N_n, \\mathbf{x}_n)$ 将为零。该表达式能正确处理所有情况，并根据最大似然估计的原理（此方法，即多态贝内特接受率（MBAR）方法或加权直方图分析法（WHAM）的广义形式，正是基于此原理）优化地组合所有可用数据。题目不要求计算 $f_A$ 和 $f_B$ 的值，而是用它们来表示最终答案，这一点已经做到了。", "answer": "$$\n\\boxed{\\frac{\\sum_{n=1}^{M_{A}+M_{B}} \\frac{A(N_{n}, \\mathbf{x}_{n}) q_{*}(N_{n}, \\mathbf{x}_{n})}{M_{A} \\exp(f_{A}) q_{A}(N_{n}, \\mathbf{x}_{n}) + M_{B} \\exp(f_{B}) q_{B}(N_{n}, \\mathbf{x}_{n})}}{\\sum_{n=1}^{M_{A}+M_{B}} \\frac{q_{*}(N_{n}, \\mathbf{x}_{n})}{M_{A} \\exp(f_{A}) q_{A}(N_{n}, \\mathbf{x}_{n}) + M_{B} \\exp(f_{B}) q_{B}(N_{n}, \\mathbf{x}_{n})}}}\n$$", "id": "2401647"}, {"introduction": "最后的这个实践是一项综合性的挑战，它将综合你的理解，并将其应用于计算化学领域中一个研究级别的问题。你将通过为伞形采样的二维数据实现 WHAM 来构建一个二维自由能面 $F(s_1, s_2)$，其中反应坐标 $(s_1, s_2)$ 是非正交的。这项练习涉及生成模拟数据、构建一个稳健的多维 WHAM 求解器，并将你的结果与解析解进行验证，从而使你具备解决复杂自由能计算问题的技能。[@problem_id:2401621]", "problem": "您的任务是实现一个完整、可复现的程序，当反应坐标非正交时，使用加权直方图分析方法（WHAM）构建二维自由能面。您的实现必须基于统计力学和概率论的第一性原理，并且不得依赖任何专门的 WHAM 库。该程序必须从一个已知的无偏系统中生成合成的伞形抽样数据，使用统计上一致的权重合并直方图，并根据解析参考对结果进行验证。所有能量都必须以 $k_\\mathrm{B} T$ 为单位表示，因此是无量纲的。本问题不涉及角度。最终输出必须是单行文本，其中包含一个浮点数列表，具体格式如下文所述。\n\n您的推导和实现必须基于以下基本原理：\n- 玻尔兹曼分布 $p(\\mathbf{z}) \\propto \\exp\\{-\\beta U(\\mathbf{z})\\}$，其中 $\\beta = 1/(k_\\mathrm{B} T)$，$\\mathbf{z} = (x,y)^\\top$ 表示微观坐标。\n- 带有附加偏置势的伞形抽样原理，该原理通过移动抽样来改善对感兴趣区域的覆盖。\n- 基于统计一致性和最大似然论证的离散直方图重加权。\n\n您必须构建一个模型，其中无偏势能是一个包含耦合项的二维二次型，\n$$\nU_0(\\mathbf{z}) = \\tfrac{1}{2}\\,\\mathbf{z}^\\top \\mathbf{K}\\,\\mathbf{z}, \\quad \\mathbf{K} = \\begin{pmatrix} k_x & k_{xy} \\\\ k_{xy} & k_y \\end{pmatrix},\n$$\n并且反应坐标是线性的、非正交的，\n$$\n\\mathbf{s}(\\mathbf{z}) = \\begin{pmatrix} s_1 \\\\ s_2 \\end{pmatrix} = \\mathbf{A}\\,\\mathbf{z}, \\quad \\mathbf{A} = \\begin{pmatrix} 1 & 0 \\\\ 1 & \\alpha \\end{pmatrix},\n$$\n因此 $s_1 = x$ 且 $s_2 = x + \\alpha y$，其中 $\\alpha \\neq 0$。对于每个伞形窗 $i$，偏置在两个反应坐标上都是谐振的，\n$$\nU^{(i)}_\\mathrm{b}(\\mathbf{s}) = \\tfrac{1}{2}\\,k_1\\,\\big(s_1 - c^{(i)}_1\\big)^2 + \\tfrac{1}{2}\\,k_2\\,\\big(s_2 - c^{(i)}_2\\big)^2.\n$$\n伞形窗 $i$ 中的总偏置能量为 $U_0(\\mathbf{z}) + U^{(i)}_\\mathrm{b}(\\mathbf{s}(\\mathbf{z}))$。由于 $U_0$ 和 $U^{(i)}_\\mathrm{b}$ 都是二次的，且 $\\mathbf{s}$ 是线性的，因此 $\\mathbf{z}$ 中的偏置分布是高斯分布，可以被精确采样。\n\n您的程序必须：\n- 对于每个指定的测试用例，在每个伞形窗 $i$ 中，通过从与 $\\exp\\{-\\beta[U_0(\\mathbf{z}) + U^{(i)}_\\mathrm{b}(\\mathbf{s}(\\mathbf{z}))]\\}$ 成正比的高斯分布中抽样来生成独立样本，并使用给定的随机种子。您必须从第一性原理推导相关的高斯均值和协方差；除了使用您推导出的参数进行多元正态抽样外，不要使用任何黑盒采样器。\n- 使用提供的边界和分箱数量，在均匀网格上离散化 $\\mathbf{s}$ 空间，为 $\\mathbf{s}$ 中的每个伞形窗构建一个独立的二维直方图，然后使用统计上一致的 WHAM 不动点迭代合并直方图，以估计网格上的无偏概率 $P(\\mathbf{s})$。\n- 将 $P(\\mathbf{s})$ 转换为自由能 $F(\\mathbf{s}) = -\\ln P(\\mathbf{s})$（以 $k_\\mathrm{B} T$ 为单位），并平移 $F(\\mathbf{s})$，使其在所有被访问过的网格分箱上的最小值为零。\n- 基于无偏分布在 $\\mathbf{s} = \\mathbf{A}\\mathbf{z}$ 变换下的精确高斯变换，计算解析参考自由能 $F_\\mathrm{ref}(\\mathbf{s})$，并将其平移，使其在相同被访问过的分箱上的最小值为零。\n- 在所有伞形窗中总计数至少达到指定阈值（使用阈值计数 $\\ge 5$）的网格分箱上，计算 $F(\\mathbf{s})$ 和 $F_\\mathrm{ref}(\\mathbf{s})$ 之间的均方根误差（RMSE）。每个测试用例的 RMSE 是一个单一的浮点数。\n\n测试套件。请为以下三种情况实现上述要求。在所有情况下，都使用 $\\beta = 1$（即以 $k_\\mathrm{B} T$ 作为能量单位）和相同的无偏刚度矩阵，\n- 无偏刚度：$\\mathbf{K} = \\begin{pmatrix} 1.5 & 0.3 \\\\ 0.3 & 1.0 \\end{pmatrix}$。\n\n情况 1（理想情形）：\n- 反应坐标非正交性：$\\alpha = 0.5$。\n- 伞形弹簧常数：$k_1 = 4.0$, $k_2 = 2.0$。\n- 伞形中心：$\\{c^{(i)}_1\\} \\in \\{-1.2, 0.0, 1.2\\}$ 和 $\\{c^{(i)}_2\\} \\in \\{-1.2, 0.0, 1.2\\}$，构成一个 $3 \\times 3$ 的伞形窗网格。\n- 每个伞形窗的样本数：$N_i = 4000$（对所有 $i$）。\n- $\\mathbf{s}$ 中的直方图网格：$s_1 \\in [-2.0, 2.0]$，含 $41$ 个分箱；$s_2 \\in [-2.0, 2.0]$，含 $41$ 个分箱。\n- 随机种子：$123$。\n\n情况 2（更强的非正交性和更硬的伞形势）：\n- 反应坐标非正交性：$\\alpha = 0.9$。\n- 伞形弹簧常数：$k_1 = 6.0$, $k_2 = 6.0$。\n- 伞形中心：$\\{c^{(i)}_1\\} \\in \\{-1.8, 0.0, 1.8\\}$ 和 $\\{c^{(i)}_2\\} \\in \\{-1.8, 0.0, 1.8\\}$，构成一个 $3 \\times 3$ 的网格。\n- 每个伞形窗的样本数：$N_i = 1500$（对所有 $i$）。\n- $\\mathbf{s}$ 中的直方图网格：$s_1 \\in [-3.0, 3.0]$，含 $45$ 个分箱；$s_2 \\in [-3.0, 3.0]$，含 $45$ 个分箱。\n- 随机种子：$456$。\n\n情况 3（边界情形，伞形窗和样本数较少）：\n- 反应坐标非正交性：$\\alpha = 0.2$。\n- 伞形弹簧常数：$k_1 = 3.0$, $k_2 = 3.0$。\n- 伞形中心：$\\{c^{(i)}_1\\} \\in \\{-1.2, 1.2\\}$ 和 $\\{c^{(i)}_2\\} \\in \\{-1.2, 1.2\\}$，构成一个 $2 \\times 2$ 的网格。\n- 每个伞形窗的样本数：$N_i = 600$（对所有 $i$）。\n- $\\mathbf{s}$ 中的直方图网格：$s_1 \\in [-2.0, 2.0]$，含 $35$ 个分箱；$s_2 \\in [-2.0, 2.0]$，含 $35$ 个分箱。\n- 随机种子：$789$。\n\n您必须遵守的算法细节：\n- 对于每个伞形窗 $i$ 中的抽样，推导由 $U_0(\\mathbf{z}) + U^{(i)}_\\mathrm{b}(\\mathbf{s}(\\mathbf{z}))$ 所隐含的、形式为 $\\mathcal{N}(\\boldsymbol{\\mu}^{(i)}, \\boldsymbol{\\Sigma}^{(i)})$ 的 $\\mathbf{z}$ 偏置分布的高斯均值和协方差，并使用指定的种子精确抽取 $N_i$ 个样本。\n- 对于每个伞形窗，使用上述确切的分箱边界，在 $(s_1,s_2)$ 空间中构建独立的二维直方图。\n- 在离散网格上实现 WHAM 不动点迭代，求解一组偏移量 $\\{f_i\\}$ 和网格上的无偏概率 $P(\\mathbf{s})$，并使用稳定的数值方法。将 $P(\\mathbf{s})$ 在所有访问过的分箱上归一化，使其总和为 1。\n- 构建 $F(\\mathbf{s}) = -\\ln P(\\mathbf{s})$ 并将其平移，使得在访问过的分箱上 $\\min F = 0$。\n- 构建由无偏高斯分布和线性变换 $\\mathbf{s} = \\mathbf{A}\\mathbf{z}$ 所隐含的解析参考 $F_\\mathrm{ref}(\\mathbf{s})$，并将其平移，使得在相同的访问过的分箱上 $\\min F_\\mathrm{ref} = 0$。\n- 在所有窗口总计数至少为 5 的分箱上，计算 $F(\\mathbf{s})$ 和 $F_\\mathrm{ref}(\\mathbf{s})$ 之间的 RMSE。\n\n最终输出格式：\n- 您的程序必须生成单行输出，其中包含情况 1、2 和 3 各自的 RMSE 值，四舍五入到六位小数，以逗号分隔并用方括号括起，例如：$[0.012345,0.067890,0.123456]$。\n\n执行约束：\n- 程序必须是自包含的，不需要用户输入，也不读取任何外部文件。\n- 使用另行指定的编程语言和库约束。", "solution": "该问题要求实现加权直方图分析方法（WHAM），以从人工生成的伞形抽样数据中重建二维自由能面。反应坐标被指定为底层微观坐标的非正交线性组合。解决方案必须从统计力学的第一性原理推导得出，实现时不得依赖专门的外部 WHAM 库，并需与精确的解析结果进行验证。所有能量都是无量纲的，以 $k_\\mathrm{B} T$ 为单位表示，这等效于设置 $\\beta = (k_\\mathrm{B} T)^{-1} = 1$。\n\n### 1. 理论框架\n\n**1.1. 系统定义**\n系统的无偏势能是笛卡尔坐标 $\\mathbf{z} = (x, y)^\\top$ 的一个二次型：\n$$\nU_0(\\mathbf{z}) = \\frac{1}{2}\\mathbf{z}^\\top \\mathbf{K}\\,\\mathbf{z}\n$$\n其中 $\\mathbf{K}$ 是一个对称正定刚度矩阵。相应的无偏概率分布是一个均值为零、协方差矩阵为 $\\mathbf{\\Sigma_z} = \\mathbf{K}^{-1}$ 的多元正态（高斯）分布：\n$$\np_0(\\mathbf{z}) \\propto \\exp(-U_0(\\mathbf{z})) \\implies \\mathbf{z} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{K}^{-1})\n$$\n\n反应坐标 $\\mathbf{s} = (s_1, s_2)^\\top$ 是 $\\mathbf{z}$ 的一个线性变换：\n$$\n\\mathbf{s}(\\mathbf{z}) = \\mathbf{A}\\,\\mathbf{z}\n$$\n其中 $\\mathbf{A}$ 是一个可逆矩阵，表示反应坐标通常是非正交的。\n\n伞形抽样在一组 $M$ 个模拟窗口中进行，索引为 $i = 1, \\dots, M$。在每个窗口 $i$ 中，添加一个谐振偏置势 $U^{(i)}_\\mathrm{b}(\\mathbf{s})$，以将系统约束在反应坐标空间中的一个中心 $\\mathbf{c}^{(i)} = (c^{(i)}_1, c^{(i)}_2)^\\top$ 附近：\n$$\nU^{(i)}_\\mathrm{b}(\\mathbf{s}) = \\frac{1}{2} (\\mathbf{s} - \\mathbf{c}^{(i)})^\\top \\mathbf{K}_\\mathrm{b} (\\mathbf{s} - \\mathbf{c}^{(i)})\n$$\n其中 $\\mathbf{K}_\\mathrm{b} = \\mathrm{diag}(k_1, k_2)$ 是谐振力常数的对角矩阵。\n\n**1.2. 用于生成数据的偏置分布**\n窗口 $i$ 中的总势能为 $U^{(i)}(\\mathbf{z}) = U_0(\\mathbf{z}) + U^{(i)}_\\mathrm{b}(\\mathbf{s}(\\mathbf{z}))$。为了生成样本，我们必须确定所得概率分布 $p^{(i)}(\\mathbf{z}) \\propto \\exp(-U^{(i)}(\\mathbf{z}))$ 的参数。代入定义，我们得到：\n$$\nU^{(i)}(\\mathbf{z}) = \\frac{1}{2}\\mathbf{z}^\\top \\mathbf{K}\\,\\mathbf{z} + \\frac{1}{2} (\\mathbf{A}\\mathbf{z} - \\mathbf{c}^{(i)})^\\top \\mathbf{K}_\\mathrm{b} (\\mathbf{A}\\mathbf{z} - \\mathbf{c}^{(i)})\n$$\n展开第二项可得：\n$$\nU^{(i)}_\\mathrm{b}(\\mathbf{s}(\\mathbf{z})) = \\frac{1}{2}\\mathbf{z}^\\top (\\mathbf{A}^\\top \\mathbf{K}_\\mathrm{b} \\mathbf{A}) \\mathbf{z} - \\mathbf{z}^\\top (\\mathbf{A}^\\top \\mathbf{K}_\\mathrm{b} \\mathbf{c}^{(i)}) + \\frac{1}{2}(\\mathbf{c}^{(i)})^\\top \\mathbf{K}_\\mathrm{b} \\mathbf{c}^{(i)}\n$$\n合并各项，总势能为：\n$$\nU^{(i)}(\\mathbf{z}) = \\frac{1}{2}\\mathbf{z}^\\top (\\mathbf{K} + \\mathbf{A}^\\top \\mathbf{K}_\\mathrm{b} \\mathbf{A}) \\mathbf{z} - \\mathbf{z}^\\top (\\mathbf{A}^\\top \\mathbf{K}_\\mathrm{b} \\mathbf{c}^{(i)}) + \\mathrm{const.}\n$$\n这是一个高斯分布的指数部分。对于均值为 $\\boldsymbol{\\mu}$、协方差为 $\\mathbf{\\Sigma}$ 的 $\\mathbf{z}$ 的一般高斯密度，其正比于 $\\exp(-\\frac{1}{2}(\\mathbf{z}-\\boldsymbol{\\mu})^\\top\\mathbf{\\Sigma}^{-1}(\\mathbf{z}-\\boldsymbol{\\mu}))$，展开后为 $\\exp(-\\frac{1}{2}\\mathbf{z}^\\top\\mathbf{\\Sigma}^{-1}\\mathbf{z} + \\mathbf{z}^\\top\\mathbf{\\Sigma}^{-1}\\boldsymbol{\\mu} + \\mathrm{const.})$。通过将此形式与 $\\exp(-U^{(i)}(\\mathbf{z}))$进行比较，我们可以确定窗口 $i$ 中偏置分布的逆协方差和均值：\n$$\n\\mathbf{\\Sigma}^{(i)^{-1}} = \\mathbf{K} + \\mathbf{A}^\\top \\mathbf{K}_\\mathrm{b} \\mathbf{A}\n$$\n$$\n\\mathbf{\\Sigma}^{(i)^{-1}} \\boldsymbol{\\mu}^{(i)} = \\mathbf{A}^\\top \\mathbf{K}_\\mathrm{b} \\mathbf{c}^{(i)}\n$$\n求解这些参数可得到窗口 $i$ 中 $\\mathbf{z}$ 的抽样分布：\n$$\n\\mathbf{z} \\sim \\mathcal{N}(\\boldsymbol{\\mu}^{(i)}, \\mathbf{\\Sigma}^{(i)})\n$$\n其协方差为 $\\mathbf{\\Sigma}^{(i)} = (\\mathbf{K} + \\mathbf{A}^\\top \\mathbf{K}_\\mathrm{b} \\mathbf{A})^{-1}$，均值为 $\\boldsymbol{\\mu}^{(i)} = \\mathbf{\\Sigma}^{(i)} (\\mathbf{A}^\\top \\mathbf{K}_\\mathrm{b} \\mathbf{c}^{(i)})$。\n\n**1.3. 解析参考自由能**\n反应坐标 $\\mathbf{s}$ 的无偏分布可以通过高斯变量线性变换的性质得到。由于 $\\mathbf{z} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{K}^{-1})$ 且 $\\mathbf{s} = \\mathbf{A}\\mathbf{z}$，$\\mathbf{s}$ 的分布也是高斯分布，即 $\\mathbf{s} \\sim \\mathcal{N}(\\boldsymbol{\\mu_s}, \\mathbf{\\Sigma_s})$，其均值为 $\\boldsymbol{\\mu_s} = \\mathbf{A}\\boldsymbol{\\mu_z} = \\mathbf{0}$，协方差为 $\\mathbf{\\Sigma_s} = \\mathbf{A} \\mathbf{\\Sigma_z} \\mathbf{A}^\\top = \\mathbf{A} \\mathbf{K}^{-1} \\mathbf{A}^\\top$。\n\n概率密度为 $p(\\mathbf{s}) \\propto \\exp(-\\frac{1}{2}\\mathbf{s}^\\top \\mathbf{\\Sigma_s}^{-1} \\mathbf{s})$。解析自由能定义为 $F(\\mathbf{s}) = -\\ln p(\\mathbf{s})$（以 $k_\\mathrm{B} T$ 为单位）。因此，在忽略一个无关的加性常数的情况下：\n$$\nF_\\mathrm{ref}(\\mathbf{s}) = \\frac{1}{2}\\mathbf{s}^\\top (\\mathbf{A} \\mathbf{K}^{-1} \\mathbf{A}^\\top)^{-1} \\mathbf{s}\n$$\n这提供了理论基准，用于与 WHAM 重建结果进行比较。\n\n**1.4. WHAM 实现**\n来自所有 $M$ 个窗口的数据使用 WHAM 进行合并。反应坐标空间 $\\mathbf{s}$ 被离散化为由索引 $j$ 标记的分箱网格。设 $H_{ij}$ 是从窗口 $i$ 落入分箱 $j$ 的样本数，而 $N_i = \\sum_j H_{ij}$ 是从窗口 $i$ 抽取的总样本数。WHAM 的目标是找到每个分箱 $j$ 的无偏概率 $P_j$ 和每个窗口 $i$ 的无量纲自由能偏移 $f_i$。这些由以下自洽方程确定：\n$$\nP_j = \\frac{\\sum_{i=1}^M H_{ij}}{\\sum_{i=1}^M N_i \\exp(f_i - U^{(i)}_\\mathrm{b}(\\mathbf{s}_j))}\n$$\n$$\n\\exp(-f_i) = \\sum_j P_j \\exp(-U^{(i)}_\\mathrm{b}(\\mathbf{s}_j))\n$$\n其中 $\\mathbf{s}_j$ 是分箱 $j$ 中心的坐标。这些方程通过迭代求解。为保证数值稳定性，计算在对数空间中进行。\n\n迭代过程如下：\n1. 对所有 $i=1, \\dots, M$，初始化 $f_i = 0$。\n2. 重复更新 $\\{f_i\\}$ 和 $\\{P_j\\}$ 直至收敛：\n   a. 对每个被访问过的分箱 $j$（其中 $\\sum_i H_{ij} > 0$），使用当前的 $\\{f_i\\}$ 计算一个未归一化的概率 $P'_j$：\n      $$\n      \\ln P'_j = \\ln\\left(\\sum_i H_{ij}\\right) - \\mathrm{logsumexp}_i(\\ln N_i + f_i - U^{(i)}_\\mathrm{b}(\\mathbf{s}_j))\n      $$\n   b. 在所有被访问过的分箱集合上对概率进行归一化：\n      $$\n      \\ln P_j = \\ln P'_j - \\mathrm{logsumexp}_{k \\in \\text{visited}} (\\ln P'_k)\n      $$\n   c. 使用新的概率 $\\{P_j\\}$ 更新自由能偏移量 $\\{f_i\\}$：\n      $$\n      f_i^{\\text{new}} = -\\mathrm{logsumexp}_{j \\in \\text{visited}} (\\ln P_j - U^{(i)}_\\mathrm{b}(\\mathbf{s}_j))\n      $$\n   d. 为防止数值漂移，固定自由能，例如，$f_i \\leftarrow f_i^{\\text{new}} - f_1^{\\text{new}}$。\n   e. 检查收敛性，例如，要求任何 $f_i$ 的最大绝对变化小于一个小的容差（例如 $10^{-9}$）。\n\n**1.5. 自由能面与误差计算**\n一旦获得收敛的概率 $P_j$，自由能面就计算为 $F_j = -\\ln P_j$。该曲面仅在被访问过的分箱上有定义；否则 $F_j$ 为无穷大。为了进行比较，该曲面被平移，使其在被访问过的分箱上的最小值为零。\n\n解析参考自由能 $F_{\\mathrm{ref}, j}$ 在分箱中心 $\\mathbf{s}_j$ 处进行评估。然后通过减去在相同被访问分箱集合上计算出的最小值来进行平移。这确保了误差计算有一个一致的参考基准。\n\n计算均方根误差（RMSE）以量化重建的准确性。比较仅限于总样本数 $\\sum_i H_{ij}$ 至少为 5 的分箱，以排除统计上不可靠的区域。设 $\\mathcal{J}$ 为此类分箱的集合。RMSE 为：\n$$\n\\text{RMSE} = \\sqrt{\\frac{1}{|\\mathcal{J}|} \\sum_{j \\in \\mathcal{J}} (F_j - F_{\\mathrm{ref}, j})^2}\n$$\n该过程应用于问题陈述中指定的三个测试用例中的每一个。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import logsumexp\n\ndef run_analysis(K_unbiased, alpha, k_bias, c1_centers, c2_centers, n_samples_per_window, s_lims, n_bins, seed):\n    \"\"\"\n    Performs a complete WHAM analysis for a single test case.\n    \"\"\"\n    # 1. Setup system parameters\n    rng = np.random.default_rng(seed)\n    A = np.array([[1, 0], [1, alpha]])\n    K_b = np.diag(k_bias)\n    \n    # Generate the grid of umbrella window centers\n    window_centers = np.array(np.meshgrid(c1_centers, c2_centers)).T.reshape(-1, 2)\n    n_windows = len(window_centers)\n    \n    # Pre-calculate matrices for sampling distribution\n    # These are constant across all windows for this problem\n    # Sigma_inv = K + A.T @ K_b @ A\n    Sigma_inv_biased = K_unbiased + A.T @ K_b @ A\n    Sigma_biased = np.linalg.inv(Sigma_inv_biased)\n    \n    # Setup histogram grid\n    s1_edges = np.linspace(s_lims[0][0], s_lims[0][1], n_bins[0] + 1)\n    s2_edges = np.linspace(s_lims[1][0], s_lims[1][1], n_bins[1] + 1)\n    s1_centers = (s1_edges[:-1] + s1_edges[1:]) / 2.0\n    s2_centers = (s2_edges[:-1] + s2_edges[1:]) / 2.0\n    \n    hist_shape = (n_bins[0], n_bins[1])\n    n_bins_total = n_bins[0] * n_bins[1]\n\n    # All histograms and related data will be stored flattened for easier processing\n    all_histograms = np.zeros((n_windows, n_bins_total))\n    \n    # 2. Generate samples and build histograms\n    for i in range(n_windows):\n        c_i = window_centers[i]\n        \n        # Derive mean of the biased distribution for window i\n        mu_biased = Sigma_biased @ A.T @ K_b @ c_i\n        \n        # Sample from the biased distribution in z-space\n        z_samples = rng.multivariate_normal(mu_biased, Sigma_biased, size=n_samples_per_window)\n        \n        # Transform samples to reaction coordinate space s\n        s_samples = z_samples @ A.T\n        \n        # Build 2D histogram for this window\n        hist, _, _ = np.histogram2d(s_samples[:, 0], s_samples[:, 1], bins=[s1_edges, s2_edges])\n        all_histograms[i, :] = hist.flatten()\n\n    # 3. WHAM Calculation\n    S1_grid, S2_grid = np.meshgrid(s1_centers, s2_centers, indexing='ij')\n    s_coords = np.vstack([S1_grid.ravel(), S2_grid.ravel()]).T\n\n    # Pre-calculate bias energies for all bins and all windows\n    U_bias_all = np.zeros((n_windows, n_bins_total))\n    for i in range(n_windows):\n        c_i = window_centers[i]\n        ds1 = s_coords[:, 0] - c_i[0]\n        ds2 = s_coords[:, 1] - c_i[1]\n        U_bias_all[i, :] = 0.5 * k_bias[0] * ds1**2 + 0.5 * k_bias[1] * ds2**2\n        \n    total_counts = np.sum(all_histograms, axis=0)\n    visited_mask = total_counts > 0\n    \n    counts_visited = total_counts[visited_mask]\n    U_bias_visited = U_bias_all[:, visited_mask]\n    n_samples_per_window_arr = np.full(n_windows, n_samples_per_window)\n\n    f = np.zeros(n_windows)\n    \n    # WHAM fixed-point iteration\n    for iteration in range(2000): # More than enough for convergence\n        f_old = np.copy(f)\n        \n        # Calculate unnormalized probabilities P' in log space\n        log_numer = np.log(counts_visited)\n        \n        arg_logsumexp_i = np.log(n_samples_per_window_arr)[:, np.newaxis] + f[:, np.newaxis] - U_bias_visited\n        log_denom = logsumexp(arg_logsumexp_i, axis=0)\n        \n        log_P_unnorm = log_numer - log_denom\n        \n        # Normalize probabilities P over visited bins\n        log_Z_P = logsumexp(log_P_unnorm)\n        log_P = log_P_unnorm - log_Z_P\n        \n        # Update free energy offsets f\n        arg_logsumexp_j = log_P[np.newaxis, :] - U_bias_visited\n        f = -logsumexp(arg_logsumexp_j, axis=1)\n        f -= f[0] # Anchor the free energies\n        \n        # Check for convergence\n        if np.max(np.abs(f - f_old)) < 1e-9:\n            break\n            \n    # 4. Construct Free Energy Surface (FES)\n    F_wham = np.full(n_bins_total, np.inf)\n    F_wham[visited_mask] = -log_P\n    F_wham -= np.min(F_wham[visited_mask])\n\n    # 5. Construct Analytical Reference FES\n    K_inv_unbiased = np.linalg.inv(K_unbiased)\n    Sigma_s = A @ K_inv_unbiased @ A.T\n    K_s = np.linalg.inv(Sigma_s)\n    \n    F_ref = 0.5 * np.sum((s_coords @ K_s) * s_coords, axis=1)\n    F_ref -= np.min(F_ref[visited_mask])\n    \n    # 6. Calculate RMSE\n    rmse_mask = total_counts >= 5\n    if np.sum(rmse_mask) > 0:\n        diff_sq = (F_wham[rmse_mask] - F_ref[rmse_mask])**2\n        rmse = np.sqrt(np.mean(diff_sq))\n    else:\n        rmse = 0.0 # Or nan, depending on convention for no valid bins.\n        \n    return rmse\n\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the WHAM analysis.\n    \"\"\"\n    K_unbiased = np.array([[1.5, 0.3], [0.3, 1.0]])\n\n    test_cases = [\n        # Case 1\n        {\n            \"alpha\": 0.5, \"k_bias\": [4.0, 2.0],\n            \"c1_centers\": [-1.2, 0.0, 1.2], \"c2_centers\": [-1.2, 0.0, 1.2],\n            \"n_samples_per_window\": 4000,\n            \"s_lims\": [[-2.0, 2.0], [-2.0, 2.0]], \"n_bins\": [41, 41],\n            \"seed\": 123\n        },\n        # Case 2\n        {\n            \"alpha\": 0.9, \"k_bias\": [6.0, 6.0],\n            \"c1_centers\": [-1.8, 0.0, 1.8], \"c2_centers\": [-1.8, 0.0, 1.8],\n            \"n_samples_per_window\": 1500,\n            \"s_lims\": [[-3.0, 3.0], [-3.0, 3.0]], \"n_bins\": [45, 45],\n            \"seed\": 456\n        },\n        # Case 3\n        {\n            \"alpha\": 0.2, \"k_bias\": [3.0, 3.0],\n            \"c1_centers\": [-1.2, 1.2], \"c2_centers\": [-1.2, 1.2],\n            \"n_samples_per_window\": 600,\n            \"s_lims\": [[-2.0, 2.0], [-2.0, 2.0]], \"n_bins\": [35, 35],\n            \"seed\": 789\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        rmse = run_analysis(K_unbiased=K_unbiased, **case)\n        results.append(rmse)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```", "id": "2401621"}]}