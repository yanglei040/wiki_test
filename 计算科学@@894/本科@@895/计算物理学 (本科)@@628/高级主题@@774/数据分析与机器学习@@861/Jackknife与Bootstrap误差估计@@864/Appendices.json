{"hands_on_practices": [{"introduction": "在计算材料科学中，一个常见的任务是通过应力-应变数据来确定材料属性，例如杨氏模量（Young's modulus）。这个练习模拟了这一过程，您将通过对带有噪声的模拟数据进行线性拟合来估计杨氏模量。本练习的核心是使用自举法（bootstrap method）来量化由线性拟合得到的模量的不确定性，这是实验和计算数据分析中的一项基本技能。[@problem_id:2404303]", "problem": "您将执行一项计算物理学任务，需要从拟合的应力-应变曲线的斜率中，估算模拟纳米线的杨氏模量的不确定性。假设在小应变情况下，适用线性弹性理论，应力-应变关系遵循胡克定律 (Hooke’s law)，其中轴向应力与轴向应变成正比，比例常数即为杨氏模量。您将通过在一个具有已知真实模量的线性关系上添加独立同分布的测量噪声，来模拟在给定应变下的应力测量值。您将从这些模拟的($\\text{strain}$, $\\text{stress}$)数据对中，通过零截距线性拟合的斜率来估算杨氏模量。接着，您将使用 bootstrap 方法，通过对数据对进行有放回的重采样并对每个重采样样本重新计算斜率，来估算该斜率的不确定性。您的任务是为几个测试用例实现这一端到端的流程，并报告所估算的杨氏模量的 bootstrap 标准误。所有应力必须以吉帕斯卡 (gigapascal) 为单位表示，应变为无量纲。所有答案必须以吉帕斯卡为单位报告，并精确到小数点后六位。\n\n使用以下基本原理：\n- 小应变范围内的胡克定律 (Hooke's law)：轴向应力 $\\sigma$ 通过杨氏模量 $E$ 与轴向应变 $\\varepsilon$ 成正比。\n- 普通最小二乘法 (Ordinary least squares) 作为从含噪声数据中估计线性关系的标准方法。\n- bootstrap 原理：估计量的抽样分布可以通过从观测数据中进行有放回的重采样，并对每个重采样样本重新计算估计量来近似。\n\n实现一个程序，该程序：\n1. 为每个测试用例生成合成的 $(\\varepsilon_i, \\sigma_i)$ 数据，步骤如下。对于每个用例，在最小应变和最大应变之间（含两端）抽取 $n$ 个线性间隔的应变值，然后使用真实模量计算无噪声的应力，最后向应力值中添加具有指定标准差的独立高斯噪声。使用提供的随机种子以确保可复现性。\n2. 通过使用普通最小二乘法拟合一个零截距的线性模型（即，直线通过原点），从模拟数据中估算杨氏模量 $E$。\n3. 通过从观测到的 $(\\varepsilon_i,\\sigma_i)$ 数据对中有放回地抽取 $n$ 个数据对，对每个重采样样本重新拟合零截距线性模型，并收集 bootstrap 斜率，从而执行非参数 bootstrap 重采样。使用提供的 bootstrap 种子和指定的 bootstrap 重复次数 $B$。\n4. 对每个测试用例，报告斜率估计的 bootstrap 标准误，其定义为 bootstrap 斜率的样本标准差（自由度为 $1$）。以吉帕斯卡为单位报告该标准误，并精确到小数点后六位。\n\n物理和数值单位：\n- 应变 $\\varepsilon$ 是无量纲的。\n- 应力 $\\sigma$ 必须以吉帕斯卡为单位。\n- 杨氏模量 $E$ 必须以吉帕斯卡为单位报告。\n- 所有角度均与本问题无关，无需使用。\n\n测试套件：\n使用以下三种情况。每种情况都指定了真实模量、数据点数量、应变范围、应力噪声水平、bootstrap 重复次数，以及用于数据生成和 bootstrap 重采样的种子。所有数值都应以上述单位进行解释。\n\n- 情况 $1$ (一般情况，中等噪声):\n  - 真实模量 $E_{\\text{true}} = 200$ 吉帕斯卡。\n  - 数据点数量 $n = 25$。\n  - 应变范围 $[\\varepsilon_{\\min}, \\varepsilon_{\\max}] = [0.002, 0.010]$。\n  - 应力噪声标准差 $\\sigma_{\\text{noise}} = 0.5$ 吉帕斯卡。\n  - bootstrap 重复次数 $B = 5000$。\n  - 数据生成种子 $s_{\\text{data}} = 12345$, bootstrap 种子 $s_{\\text{boot}} = 54321$。\n\n- 情况 $2$ (数据点较少，噪声较高):\n  - 真实模量 $E_{\\text{true}} = 70$ 吉帕斯卡。\n  - 数据点数量 $n = 12$。\n  - 应变范围 $[\\varepsilon_{\\min}, \\varepsilon_{\\max}] = [0.005, 0.025]$。\n  - 应力噪声标准差 $\\sigma_{\\text{noise}} = 2.0$ 吉帕斯卡。\n  - bootstrap 重复次数 $B = 5000$。\n  - 数据生成种子 $s_{\\text{data}} = 24680$, bootstrap 种子 $s_{\\text{boot}} = 86420$。\n\n- 情况 $3$ (边界情况，无噪声):\n  - 真实模量 $E_{\\text{true}} = 150$ 吉帕斯卡。\n  - 数据点数量 $n = 8$。\n  - 应变范围 $[\\varepsilon_{\\min}, \\varepsilon_{\\max}] = [0.003, 0.015]$。\n  - 应力噪声标准差 $\\sigma_{\\text{noise}} = 0.0$ 吉帕斯卡。\n  - bootstrap 重复次数 $B = 5000$。\n  - 数据生成种子 $s_{\\text{data}} = 13579$, bootstrap 种子 $s_{\\text{boot}} = 97531$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含对应于上述三个测试用例的三个 bootstrap 标准误（以吉帕斯卡为单位），按所列顺序排列，形式为方括号括起来的逗号分隔列表，每个值都精确到小数点后六位，例如 [$0.123456,0.234567,0.000000]$。", "solution": "问题陈述已经过验证，被认为是有效的。它具有科学依据，提法明确，客观，并包含了推导出唯一、可验证解所需的所有信息。该问题是计算物理学中的一个标准练习，涉及从模拟的含噪声数据中估计物理参数及其不确定性。\n\n任务是计算从应力-应变曲线估算的杨氏模量 $E$ 的标准误。该估计将使用 bootstrap 方法执行。整个流程基于三个核心原理：作为物理模型的胡克定律 (Hooke's law)，用于参数拟合的普通最小二乘法，以及用于不确定性量化的 bootstrap 重采样。\n\n物理模型是胡克定律 (Hooke's law)，该定律指出，对于小形变，轴向应力 $\\sigma$ 与轴向应变 $\\varepsilon$ 呈线性正比关系：\n$$ \\sigma = E \\varepsilon $$\n比例常数 $E$ 即为杨氏模量。该模型表示一条通过原点的直线，因为零应变必须对应零应力。\n\n首先，我们必须为每个测试用例生成合成数据。给定真实模量 $E_{\\text{true}}$、数据点数量 $n$、应变范围 $[\\varepsilon_{\\min}, \\varepsilon_{\\max}]$ 以及应力噪声标准差 $\\sigma_{\\text{noise}}$。对于 $i=1, \\dots, n$，应变值 $\\varepsilon_i$ 是在 $\\varepsilon_{\\min}$ 到 $\\varepsilon_{\\max}$ 之间（含两端）生成的 $n$ 个线性间隔点。相应的应力值 $\\sigma_i$ 通过取胡克定律得出的理想应力 $\\sigma_{i, \\text{true}} = E_{\\text{true}} \\varepsilon_i$，并添加随机噪声 $\\delta_i$ 来模拟测量误差而得到。\n$$ \\sigma_i = E_{\\text{true}} \\varepsilon_i + \\delta_i $$\n噪声项 $\\delta_i$ 是从均值为 $0$、标准差为 $\\sigma_{\\text{noise}}$ 的高斯（正态）分布中抽取的独立同分布随机变量，形式上记为 $\\delta_i \\sim \\mathcal{N}(0, \\sigma_{\\text{noise}}^2)$。使用`数据生成种子` $s_{\\text{data}}$ 来确保此随机过程的可复现性。\n\n接下来，我们必须从生成的包含 $n$ 个数据对 $\\{(\\varepsilon_i, \\sigma_i)\\}_{i=1}^n$ 的数据集中估算杨氏模量。对于通过原点的线性模型 $\\sigma = E \\varepsilon$，普通最小二乘 (OLS) 估计量 $\\hat{E}$ 是使残差平方和 $S(E) = \\sum_{i=1}^{n} (\\sigma_i - E \\varepsilon_i)^2$ 最小化的值。为找到此最小值，我们将 $S(E)$ 对 $E$ 的导数设为零：\n$$ \\frac{dS}{dE} = \\sum_{i=1}^{n} 2(\\sigma_i - E \\varepsilon_i)(-\\varepsilon_i) = 0 $$\n解此方程可得 OLS 估计量：\n$$ \\hat{E} = \\frac{\\sum_{i=1}^{n} \\varepsilon_i \\sigma_i}{\\sum_{i=1}^{n} \\varepsilon_i^2} $$\n此公式给出了约束通过原点的直线的最佳拟合斜率。\n\n问题的核心是估算该估计量 $\\hat{E}$ 的不确定性。我们使用非参数 bootstrap 方法。原始数据集 $\\{(\\varepsilon_i, \\sigma_i)\\}_{i=1}^n$ 被视为一个经验分布。我们对 $B$ 次 bootstrap 重复进行以下步骤，在本问题中 $B=5000$：\n1. 通过从原始数据集中有放回地抽取 $n$ 个数据对来生成一个*bootstrap 样本*。设这个新样本为 $\\{(\\varepsilon_j^*, \\sigma_j^*)\\}_{j=1}^n$。\n2. 对此 bootstrap 样本，使用相同的 OLS 公式计算模量的 bootstrap 估计值 $\\hat{E}^*$：\n    $$ \\hat{E}^* = \\frac{\\sum_{j=1}^{n} \\varepsilon_j^* \\sigma_j^*}{\\sum_{j=1}^{n} (\\varepsilon_j^*)^2} $$\n3. 存储该值 $\\hat{E}^*$。\n\n重复此过程 $B$ 次后，我们得到一个包含 $B$ 个 bootstrap 估计值的集合 $\\{\\hat{E}_1^*, \\hat{E}_2^*, \\dots, \\hat{E}_B^*\\}$。该集合可作为我们估计量 $\\hat{E}$ 的抽样分布的经验近似。`bootstrap 种子` $s_{\\text{boot}}$ 确保了此重采样过程同样是可复现的。\n\n最后，我们计算 bootstrap 标准误 $\\text{SE}_{\\text{boot}}(\\hat{E})$，即 bootstrap 估计值的样本标准差。它是我们估计值 $\\hat{E}$ 中统计不确定性的度量。根据规定使用 $B-1$ 自由度的公式为：\n$$ \\text{SE}_{\\text{boot}}(\\hat{E}) = \\sqrt{\\frac{1}{B-1} \\sum_{b=1}^{B} (\\hat{E}_b^* - \\bar{E}^*)^2} $$\n其中 $\\bar{E}^* = \\frac{1}{B} \\sum_{b=1}^{B} \\hat{E}_b^*$ 是 bootstrap 估计值的均值。\n\n一个需要特别考虑的情况是情况 3，其中 $\\sigma_{\\text{noise}} = 0.0$. 在这种情况下，初始数据点完全落在直线 $\\sigma = E_{\\text{true}} \\varepsilon$ 上。任何 bootstrap 样本都将由同样落在这条精确直线上的点组成。因此，每个 bootstrap 斜率估计值 $\\hat{E}_b^*$ 在解析上都将等于 $E_{\\text{true}}$。一组恒定值的标准差精确为 $0$。因此，对于这种情况，bootstrap 标准误必须为 $0.000000$. 这可以作为对算法逻辑的验证性检查。\n\n实现将通过为指定的三个测试用例中的每一个执行这整个流程，并按要求格式化最终的标准误来进行。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all given test cases.\n    It calculates the bootstrap standard error for Young's modulus estimates\n    and prints the results in the specified format.\n    \"\"\"\n    test_cases = [\n        # Case 1 (general case, moderate noise)\n        (200.0, 25, [0.002, 0.010], 0.5, 5000, 12345, 54321),\n        # Case 2 (fewer points, higher noise)\n        (70.0, 12, [0.005, 0.025], 2.0, 5000, 24680, 86420),\n        # Case 3 (boundary case, no noise)\n        (150.0, 8, [0.003, 0.015], 0.0, 5000, 13579, 97531),\n    ]\n\n    results = []\n    for case in test_cases:\n        E_true, n, strain_range, sigma_noise, B, s_data, s_boot = case\n\n        # Step 1: Generate synthetic (strain, stress) data\n        # Use the data-generation seed for reproducibility.\n        rng_data = np.random.default_rng(s_data)\n        \n        strains = np.linspace(strain_range[0], strain_range[1], n)\n        stress_true = E_true * strains\n        noise = rng_data.normal(loc=0.0, scale=sigma_noise, size=n)\n        stress_obs = stress_true + noise\n\n        # Step 2: Perform nonparametric bootstrap resampling\n        # Use the bootstrap seed for reproducibility.\n        rng_boot = np.random.default_rng(s_boot)\n        bootstrap_slopes = np.zeros(B)\n        \n        # Original data indices for resampling\n        data_indices = np.arange(n)\n\n        for i in range(B):\n            # Create a bootstrap sample by sampling indices with replacement.\n            boot_indices = rng_boot.choice(data_indices, size=n, replace=True)\n            strains_boot = strains[boot_indices]\n            stress_boot = stress_obs[boot_indices]\n            \n            # Estimate the slope (Young's modulus) for the bootstrap sample\n            # using the OLS formula for a zero-intercept model.\n            sum_x_squared = np.sum(strains_boot**2)\n            \n            # This check prevents division by zero, although it is not expected\n            # to occur with the given problem inputs.\n            if sum_x_squared == 0:\n                slope_b = 0.0\n            else:\n                slope_b = np.sum(strains_boot * stress_boot) / sum_x_squared\n            \n            bootstrap_slopes[i] = slope_b\n            \n        # Step 3: Compute the bootstrap standard error\n        # The standard error is the standard deviation of the bootstrap slopes.\n        # ddof=1 specifies the use of N-1 in the denominator for sample std dev.\n        std_error = np.std(bootstrap_slopes, ddof=1)\n        results.append(std_error)\n\n    # Final print statement in the exact required format.\n    # The f-string format specifier '{:.6f}' rounds to 6 decimal places.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```", "id": "2404303"}, {"introduction": "虽然自举法功能强大，但刀切法（jackknife method）是另一个关键的重采样工具。本练习将其应用于统计力学领域，从模拟产生的能量涨落中计算热容（heat capacity）等物理性质。此题目的一个关键点是引入了处理物理模拟中常见的时间相关数据的*块刀切法*（block jackknife），这对于分析来自真实模拟的时间序列数据至关重要。[@problem_id:2404291]", "problem": "您的任务是构建一个完整、可运行的程序，该程序使用Jackknife方法根据合成的正则系综能量时间序列来估计定容热容的统计误差。请从以下基本原理开始：在正则系综中，定容热容（简写为CV）满足将热响应与能量涨落联系起来的涨落-耗散关系。具体来说，如果 $E$ 表示能量，$\\langle \\cdot \\rangle$ 表示系综平均，那么在玻尔兹曼常数 $k_B=1$ 的单位制中，定容热容 $C_V$ 遵循一个将 $C_V$ 与能量涨落和绝对温度 $T$ 联系起来的恒等式。在产生有限能量时间序列的数值模拟中，期望值由样本平均值来近似。您的任务是通过能量涨落路径，从能量时间序列中估计 $C_V$，然后使用Jackknife方法估计该 $C_V$ 估计量的标准误。\n\n您的程序必须实现以下功能：\n\n- 使用正则系综的涨落-耗散关系来构建定容热容的估计量。使用样本能量时间序列来产生所需的平均值。所有量均采用约化单位处理，其中 $k_B=1$，因此报告的 $C_V$ 为 $C_V/k_B$，是无量纲的。\n\n- 为独立样本实现删一（留一法）Jackknife，为相关时间序列实现分块Jackknife。在分块Jackknife中，将时间序列划分为大小相等的连续、不重叠的块，并通过每次删除一整个块来形成Jackknife重抽样样本。如果时间序列的长度 $N$ 不是块大小 $b$ 的整数倍，则在形成 $\\lfloor N/b \\rfloor$ 个完整块后忽略尾部数据。使用标准的Jackknife构造方法来获得热容估计量的标准误（Jackknife方差估计的平方根）的Jackknife估计。对于分块Jackknife，Jackknife重抽样样本的数量等于块的数量，并应用相同的标准Jackknife方差构造方法。\n\n- 最终输出必须是Jackknife标准误（每个测试用例一个），每个都表示为浮点数。因为我们在 $k_B=1$ 的约化单位下工作，所以输出是无量纲的。\n\n合成数据生成（测试套件）：\n\n您的程序必须使用指定的随机种子和模型在内部生成以下三个能量时间序列。使用一个按规定进行确定性种子设置的伪随机数生成器，以确保结果是可复现的。\n\n- 测试用例1（独立同分布数据，“理想路径”）：在温度 $T=1$ 时，从均值为 $\\mu=0$、标准差为 $\\sigma=2$ 的正态分布中生成 $N=400$ 个能量值。使用种子 $314159$。使用留一法Jackknife，即块大小 $b=1$。\n\n- 测试用例2（小样本边界）：在温度 $T=1$ 时，从均值为 $\\mu=0.3$、标准差为 $\\sigma=1$ 的正态分布中生成 $N=8$ 个能量值。使用种子 $271828$。使用留一法Jackknife，即块大小 $b=1$。\n\n- 测试用例3（强相关时间序列）：通过参数为 $\\phi=0.9$ 的平稳一阶自回归过程（简写为AR(1)）生成 $N=1000$ 个能量值，其中新息噪声 $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma_\\varepsilon^2)$ 且 $\\sigma_\\varepsilon=1$。通过从AR(1)过程的平稳分布中抽样来初始化 $E_0$。然后对于 $t=1,\\dots,N-1$，演化 $E_t=\\phi E_{t-1}+\\varepsilon_t$。使用温度 $T=1$ 和种子 $424242$。使用分块Jackknife，块大小 $b=20$。\n\n计算细节和限制：\n\n- 对于每个时间序列，使用样本平均值通过能量涨落路径计算热容估计量，单位为 $k_B=1$。然后计算该估计量的Jackknife标准误。对于分块Jackknife，将数据划分为大小为 $b$ 的连续块，如果最后有剩余能量值，则忽略这 $N - b \\lfloor N/b \\rfloor$ 个值。确保至少形成2个Jackknife重抽样样本；否则，标准误是未定义的，且程序在提供的测试套件上不得失败。\n\n- 角度单位不适用。除了所述的约化单位外，不需要其他物理单位；报告无量纲数。\n\n要求的最终输出格式：\n\n- 您的程序应产生单行输出，其中包含三个Jackknife标准误（按测试用例1、2、3的顺序），形式为一个用方括号括起来的逗号分隔列表，每个数字四舍五入到恰好6位小数，例如 `[0.123456,0.234567,0.345678]`。\n\n您的解决方案必须是自包含的，不需要任何输入，并严格遵循指定的种子和参数。唯一允许的库是Python标准库和列出的数值库。", "solution": "用户要求一个程序，用于从合成的时间序列数据中计算定容热容 $C_V$ 的Jackknife标准误。这需要应用统计力学和计算统计学的原理。\n\n首先，我们必须形式化热容的估计量。在正则系综中，配分函数由 $Z = \\sum_{i} \\exp(-\\beta E_i)$ 给出，其中 $E_i$ 表示微观态 $i$ 的能量，$\\beta = (k_B T)^{-1}$ 是逆温度，$T$ 是绝对温度，$k_B$ 是玻尔兹曼常数。根据问题说明，我们在约化单位中操作，其中 $k_B=1$，使得 $\\beta = 1/T$。能量的系综平均 $\\langle E \\rangle$ 由配分函数得到：\n$$\n\\langle E \\rangle = -\\frac{\\partial \\ln Z}{\\partial \\beta}\n$$\n定容热容 $C_V$ 定义为平均能量对温度的导数：\n$$\nC_V = \\frac{\\partial \\langle E \\rangle}{\\partial T}\n$$\n通过应用链式法则，$\\frac{\\partial}{\\partial T} = \\frac{\\partial \\beta}{\\partial T} \\frac{\\partial}{\\partial \\beta} = -\\frac{1}{k_B T^2} \\frac{\\partial}{\\partial \\beta}$，并设置 $k_B=1$，我们发现：\n$$\nC_V = -\\frac{1}{T^2} \\frac{\\partial \\langle E \\rangle}{\\partial \\beta} = -\\frac{1}{T^2} \\frac{\\partial}{\\partial \\beta} \\left( -\\frac{\\partial \\ln Z}{\\partial \\beta} \\right) = \\frac{1}{T^2} \\frac{\\partial^2 \\ln Z}{\\partial \\beta^2}\n$$\n进行微分得到热容的涨落-耗散定理：\n$$\nC_V = \\frac{1}{T^2} \\left( \\langle E^2 \\rangle - \\langle E \\rangle^2 \\right) = \\frac{\\text{Var}(E)}{T^2}\n$$\n其中 $\\text{Var}(E)$ 是能量的方差。对于一个包含 $N$ 个能量测量值的有限时间序列 $\\{E_i\\}_{i=1}^N$，系综平均 $\\langle \\cdot \\rangle$ 被其样本估计量替代。因此，$C_V$ 的估计量，记作 $\\hat{\\theta}$，为：\n$$\n\\hat{\\theta} = \\frac{1}{T^2} \\left[ \\left(\\frac{1}{N}\\sum_{i=1}^N E_i^2\\right) - \\left(\\frac{1}{N}\\sum_{i=1}^N E_i\\right)^2 \\right]\n$$\n\n其次，我们使用Jackknife方法来估计 $\\hat{\\theta}$ 的统计误差。Jackknife是一种重抽样技术，它提供了估计量方差的估计值。\n\n对于独立同分布（i.i.d.）数据，例如测试用例1和2中的数据，我们使用删一Jackknife。这等同于块大小为 $b=1$ 的分块Jackknife。给定一个大小为 $N$ 的样本，我们创建 $N$ 个Jackknife重抽样样本。第 $j$ 个重抽样估计量 $\\hat{\\theta}_{(j)}$ 是通过对移除了第 $j$ 个观测值的样本应用估计量公式计算得出的。然后，Jackknife方差计算如下：\n$$\n\\widehat{\\text{Var}}_{\\text{jack}}(\\hat{\\theta}) = \\frac{N-1}{N} \\sum_{j=1}^N \\left(\\hat{\\theta}_{(j)} - \\hat{\\theta}_{(\\cdot)}\\right)^2\n$$\n其中 $\\hat{\\theta}_{(\\cdot)} = \\frac{1}{N} \\sum_{j=1}^N \\hat{\\theta}_{(j)}$ 是Jackknife重抽样样本的均值。\n\n对于相关的时间序列数据，如测试用例3中所示，删一法是不合适的，因为它未能保留相关性结构，导致对真实方差的低估。正确的方法是分块Jackknife。将长度为 $N$ 的时间序列划分为 $L = \\lfloor N/b \\rfloor$ 个大小为 $b$ 的不重叠块。块大小 $b$ 理想情况下应大于序列的自相关时间。通过每次删除一整个块来形成Jackknife重抽样样本。分块Jackknife方差的公式是类似的，只是有 $L$ 个重抽样样本而不是 $N$ 个：\n$$\n\\widehat{\\text{Var}}_{\\text{block-jack}}(\\hat{\\theta}) = \\frac{L-1}{L} \\sum_{j=1}^L \\left(\\hat{\\theta}_{(j)} - \\hat{\\theta}_{(\\cdot)}\\right)^2\n$$\n其中 $\\hat{\\theta}_{(j)}$ 是从移除了第 $j$ 个块的样本中计算出的估计量，而 $\\hat{\\theta}_{(\\cdot)}$ 是这 $L$ 个重抽样样本的均值。在两种情况下，标准误都是估计方差的平方根，即 $\\hat{\\sigma} = \\sqrt{\\widehat{\\text{Var}}}$。\n\n对于每个测试用例，实现将执行以下操作：\n1.  **数据生成**：根据指定的模型（正态或AR(1)）和参数（$N, T, \\mu, \\sigma, \\phi, \\sigma_\\varepsilon$）以及给定的随机种子，生成一个能量时间序列 $\\{E_i\\}_{i=1}^N$。对于AR(1)过程 $E_t = \\phi E_{t-1} + \\varepsilon_t$，初始值 $E_0$ 从其平稳分布中抽取，该分布为 $\\mathcal{N}(0, \\sigma_E^2)$，其方差为 $\\sigma_E^2 = \\sigma_\\varepsilon^2 / (1-\\phi^2)$。\n2.  **分块**：将数据划分为 $L = \\lfloor N/b \\rfloor$ 个大小为 $b$ 的块。尾部任何剩余的数据点都将被丢弃。\n3.  **重抽样计算**：对于 $L$ 个块中的每一个，从移除了该块的数据集中计算一个Jackknife重抽样估计量 $\\hat{\\theta}_{(j)}$。这可以通过预先计算每个块的能量总和与能量平方总和来高效地完成。\n4.  **误差估计**：使用这组 $L$ 个重抽样样本 $\\{\\hat{\\theta}_{(j)}\\}_{j=1}^L$ 来计算Jackknife方差，并随后计算标准误。\n\n该程序将此过程应用于所有三个具有特定参数的测试用例：\n-   **用例1**：i.i.d.数据，其中 $N=400, T=1$，来自 $\\mathcal{N}(\\mu=0, \\sigma=2)$。块大小 $b=1$，因此 $L=400$。\n-   **用例2**：小型 i.i.d. 样本，其中 $N=8, T=1$，来自 $\\mathcal{N}(\\mu=0.3, \\sigma=1)$。块大小 $b=1$，因此 $L=8$。\n-   **用例3**：相关的AR(1)数据，其中 $N=1000, T=1, \\phi=0.9$，新息噪声来自 $\\mathcal{N}(0, 1)$。块大小为 $b=20$，因此 $L = \\lfloor 1000/20 \\rfloor = 50$。\n\n最终结果是这三种不同物理情景下的标准误。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of estimating the jackknife standard error for the\n    constant-volume heat capacity from synthetic energy time series.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"id\": 1, \"type\": \"iid\", \"N\": 400, \"mu\": 0.0, \"sigma\": 2.0, \"T\": 1.0, \n            \"seed\": 314159, \"block_size\": 1\n        },\n        {\n            \"id\": 2, \"type\": \"iid\", \"N\": 8, \"mu\": 0.3, \"sigma\": 1.0, \"T\": 1.0, \n            \"seed\": 271828, \"block_size\": 1\n        },\n        {\n            \"id\": 3, \"type\": \"ar1\", \"N\": 1000, \"phi\": 0.9, \"sigma_eps\": 1.0, \"T\": 1.0, \n            \"seed\": 424242, \"block_size\": 20\n        },\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        rng = np.random.default_rng(case[\"seed\"])\n        \n        # Step 1: Generate a synthetic energy time series\n        if case[\"type\"] == \"iid\":\n            energies = rng.normal(loc=case[\"mu\"], scale=case[\"sigma\"], size=case[\"N\"])\n        elif case[\"type\"] == \"ar1\":\n            N = case[\"N\"]\n            phi = case[\"phi\"]\n            sigma_eps = case[\"sigma_eps\"]\n            \n            # Variance of the stationary distribution of AR(1) process\n            var_E_stationary = sigma_eps**2 / (1 - phi**2)\n            \n            # Initialize E_0 from the stationary distribution\n            E0 = rng.normal(loc=0, scale=np.sqrt(var_E_stationary))\n            \n            # Generate innovations\n            epsilons = rng.normal(loc=0, scale=sigma_eps, size=N - 1)\n            \n            # Generate the AR(1) time series\n            energies = np.zeros(N)\n            energies[0] = E0\n            for t in range(1, N):\n                energies[t] = phi * energies[t-1] + epsilons[t-1]\n        \n        # Step 2: Implement the jackknife error estimation\n        N = len(energies)\n        b = case[\"block_size\"]\n        T = case[\"T\"]\n        \n        # Number of blocks\n        L = N // b\n        \n        # Truncate the time series to be a multiple of the block size\n        truncated_energies = energies[:L * b]\n        \n        # Reshape data into blocks for efficient computation\n        blocks_E = truncated_energies.reshape((L, b))\n        \n        # Pre-compute sums over blocks\n        block_sums_E = np.sum(blocks_E, axis=1)\n        block_sums_E2 = np.sum(blocks_E**2, axis=1)\n        \n        # Total sums for the entire (truncated) dataset\n        total_sum_E = np.sum(block_sums_E)\n        total_sum_E2 = np.sum(block_sums_E2)\n        \n        # Size of each jackknife replicate sample\n        N_rep = (L - 1) * b\n        \n        replicates_cv = np.zeros(L)\n        \n        # Step 3: Compute jackknife replicates of the C_V estimator\n        for i in range(L):\n            # Sums for the sample with block i removed\n            sum_E_rep = total_sum_E - block_sums_E[i]\n            sum_E2_rep = total_sum_E2 - block_sums_E2[i]\n            \n            # Means for the replicate sample\n            mean_E_rep = sum_E_rep / N_rep\n            mean_E2_rep = sum_E2_rep / N_rep\n            \n            # C_V estimator for replicate i\n            # C_V = ( <E^2> - <E>^2 ) / T^2\n            cv_rep = (mean_E2_rep - mean_E_rep**2) / (T**2)\n            replicates_cv[i] = cv_rep\n        \n        # Step 4: Compute jackknife variance and standard error\n        # Jackknife variance: Var_jack = (L-1)/L * sum( (theta_i - theta_mean)^2 )\n        mean_replicates = np.mean(replicates_cv)\n        jackknife_var = ((L - 1) / L) * np.sum((replicates_cv - mean_replicates)**2)\n        jackknife_stderr = np.sqrt(jackknife_var)\n        \n        results.append(jackknife_stderr)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```", "id": "2404291"}, {"introduction": "在代码中应用了重采样方法之后，理解其底层的计算机制也同样重要。这个练习将带您深入探讨刀切法的力学原理，您需要为一个特殊的估计量（中程数，midrange）从第一性原理出发，逐步推导其偏差（bias）和标准误差（standard error）。这个更偏理论的练习将巩固您对刀切法工作原理的基础理解，并揭示其在处理非平滑估计量时的特性。[@problem_id:2404332]", "problem": "在一个计算物理实验中，一个一维探测器记录了被限制在中心 $c$ 未知的矩形陷阱区域内的中性原子的撞击位置。陷阱势确保了撞击位置 $X$ 在某个半宽 $w > 0$ 的区间 $[c - w, c + w]$上均匀分布。通过单次实验运行，您获得了 $n = 9$ 个独立的位置测量值\n$$\nx_1 = -1.02,\\; x_2 = -0.83,\\; x_3 = -0.50,\\; x_4 = -0.12,\\; x_5 = 0.05,\\; x_6 = 0.31,\\; x_7 = 0.47,\\; x_8 = 0.88,\\; x_9 = 1.20.\n$$\n为了估计中心 $c$，您考虑使用中程数估计量\n$$\n\\hat{\\theta} = \\frac{\\max(x_1,\\dots,x_n) + \\min(x_1,\\dots,x_n)}{2}.\n$$\n仅使用刀切法的基础定义（即留一法重抽样和由此产生的留一法估计），从第一性原理出发，推导 $\\hat{\\theta}$ 偏差的刀切法估计和 $\\hat{\\theta}$ 标准误的刀切法估计。然后计算它们对于上述数据集的数值。\n\n将您的最终结果以包含 $[\\hat{b}_{\\mathrm{jack}}, \\hat{s}_{\\mathrm{jack}}]$ 这两个数的单行向量形式报告，其中 $\\hat{b}_{\\mathrm{jack}}$ 是刀切法偏差估计，$\\hat{s}_{\\mathrm{jack}}$ 是刀切法标准误。将两个数值都四舍五入到四位有效数字。最终数值中不需要物理单位。", "solution": "对问题陈述进行验证。\n\n**步骤1：提取给定信息**\n- **物理系统**：一个一维探测器记录中性原子的撞击位置。\n- **分布**：撞击位置 $X$ 是一个随机变量，在区间 $[c - w, c + w]$ 上均匀分布，其中 $c$ 是未知中心，$w > 0$ 是半宽。\n- **数据集**：提供了一组 $n = 9$ 个独立测量值：$x_1 = -1.02, x_2 = -0.83, x_3 = -0.50, x_4 = -0.12, x_5 = 0.05, x_6 = 0.31, x_7 = 0.47, x_8 = 0.88, x_9 = 1.20$。\n- **估计量**：中心 $c$ 的估计量是中程数，由 $\\hat{\\theta} = \\frac{\\max(x_1,\\dots,x_n) + \\min(x_1,\\dots,x_n)}{2}$ 给出。\n- **任务**：从第一性原理出发，推导并计算 $\\hat{\\theta}$ 偏差的刀切法估计和 $\\hat{\\theta}$ 标准误的刀切法估计。\n- **报告要求**：最终结果必须是一个行向量 $[\\hat{b}_{\\mathrm{jack}}, \\hat{s}_{\\mathrm{jack}}]$，其数值四舍五入到四位有效数字。\n\n**步骤2：使用提取的信息进行验证**\n- **科学依据**：该问题在科学上是合理的。它提出了一个简化但合理的实验物理情境（粒子俘获和探测），并建议使用一种标准的、成熟的统计技术（刀切法重抽样）进行分析。均匀分布是一个有效且常见的概率模型。\n- **适定性**：该问题是适定的。它提供了所有必要的信息：一个特定的数据集、一个明确定义的估计量以及一种指定的统计方法。其目标——计算偏差和标准误的估计——是明确的。\n- **客观性**：问题以精确、客观的语言陈述，没有主观看法或含糊之处。\n\n**步骤3：结论与行动**\n该问题是有效的。它具有科学依据，是适定的、客观的，并包含足够的信息以获得唯一解。开始求解。\n\n刀切法是一种重抽样技术，用于估计一个估计量的偏差和标准误。按要求从第一性原理进行推导。\n\n设完整数据集为 $X = \\{x_1, x_2, \\dots, x_n\\}$，其中 $n=9$。参数 $\\theta=c$ 的估计量为 $\\hat{\\theta} = \\hat{\\theta}(X)$。\n给定的估计量是中程数：\n$$\n\\hat{\\theta} = \\frac{x_{(n)} + x_{(1)}}{2}\n$$\n其中 $x_{(1)} = \\min(x_1, \\dots, x_n)$ 和 $x_{(n)} = \\max(x_1, \\dots, x_n)$ 是样本的顺序统计量。\n\n首先，我们计算全样本的估计量 $\\hat{\\theta}$ 的值。通过检查数据，我们发现：\n$x_{(1)} = -1.02$\n$x_{(n)} = x_{(9)} = 1.20$\n因此，全样本估计值为：\n$$\n\\hat{\\theta} = \\frac{1.20 + (-1.02)}{2} = \\frac{0.18}{2} = 0.09\n$$\n刀切法过程需要计算留一估计值。设 $X_{(i)}$ 是移除了第 $i$ 个观测值 $x_i$ 后的数据集。相应的估计值为 $\\hat{\\theta}_{(i)} = \\hat{\\theta}(X_{(i)})$。共有 $n=9$ 个这样的估计值。\n\n估计量 $\\hat{\\theta}$ 仅依赖于样本的最小值和最大值。设排序后的样本为 $x_{(1)} < x_{(2)} < \\dots < x_{(n)}$。\n- 如果我们移除一个不是极值的观测值 $x_j$ (即 $x_{(1)} < x_j < x_{(n)}$），则子样本的最小值和最大值仍然是 $x_{(1)}$ 和 $x_{(n)}$。对于给定的数据集，这对从 $x_{(2)} = -0.83$ 到 $x_{(8)} = 0.88$ 的 $n-2 = 7$ 个数据点都成立。对于这些点，留一估计值不变：\n$$\n\\hat{\\theta}_{(i)} = \\frac{x_{(n)} + x_{(1)}}{2} = \\hat{\\theta} = 0.09 \\quad \\text{对于 } i \\in \\{2, 3, 4, 5, 6, 7, 8\\}\n$$\n- 如果我们移除样本的最小值 $x_{(1)} = -1.02$，则新的最小值是第二小的值 $x_{(2)} = -0.83$，而最大值保持为 $x_{(9)} = 1.20$。\n$$\n\\hat{\\theta}_{(1)} = \\frac{x_{(9)} + x_{(2)}}{2} = \\frac{1.20 + (-0.83)}{2} = \\frac{0.37}{2} = 0.185\n$$\n- 如果我们移除样本的最大值 $x_{(9)} = 1.20$，则新的最大值是第二大的值 $x_{(8)} = 0.88$，而最小值保持为 $x_{(1)} = -1.02$。\n$$\n\\hat{\\theta}_{(9)} = \\frac{x_{(8)} + x_{(1)}}{2} = \\frac{0.88 + (-1.02)}{2} = \\frac{-0.14}{2} = -0.07\n$$\n留一估计值的集合是：$\\{0.185, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, -0.07\\}$。\n\n偏差的刀切法估计 $\\hat{b}_{\\mathrm{jack}}$ 是从这些留一估计值的均值推导出来的。$\\hat{\\theta}$ 的偏差 $B(\\hat{\\theta}) = E[\\hat{\\theta}] - \\theta$ 可以用 $(n-1)(\\bar{\\theta}_{(\\cdot)} - \\hat{\\theta})$ 来近似，其中 $\\bar{\\theta}_{(\\cdot)}$ 是 $\\hat{\\theta}_{(i)}$ 值的均值。\n$$\n\\hat{b}_{\\mathrm{jack}} = (n-1)(\\bar{\\theta}_{(\\cdot)} - \\hat{\\theta})\n$$\n其中 $\\bar{\\theta}_{(\\cdot)} = \\frac{1}{n} \\sum_{i=1}^n \\hat{\\theta}_{(i)}$。\n首先，我们计算 $\\bar{\\theta}_{(\\cdot)}$：\n$$\n\\sum_{i=1}^9 \\hat{\\theta}_{(i)} = \\hat{\\theta}_{(1)} + \\hat{\\theta}_{(9)} + 7 \\times \\hat{\\theta} = 0.185 + (-0.07) + 7 \\times 0.09 = 0.115 + 0.63 = 0.745\n$$\n$$\n\\bar{\\theta}_{(\\cdot)} = \\frac{0.745}{9} \\approx 0.082777...\n$$\n现在，我们计算偏差估计：\n$$\n\\hat{b}_{\\mathrm{jack}} = (9-1) \\left(\\frac{0.745}{9} - 0.09\\right) = 8 \\left(\\frac{0.745 - 0.81}{9}\\right) = 8 \\left(\\frac{-0.065}{9}\\right) = \\frac{-0.52}{9} \\approx -0.057777...\n$$\n四舍五入到四位有效数字，$\\hat{b}_{\\mathrm{jack}} = -0.05778$。\n\n$\\hat{\\theta}$ 的标准误的刀切法估计，记为 $\\hat{s}_{\\mathrm{jack}}$，是从留一估计值的方差推导出来的。$\\hat{\\theta}$ 的刀切法方差估计是：\n$$\n\\hat{s}_{\\mathrm{jack}}^2 = \\widehat{\\mathrm{Var}}_{\\mathrm{jack}}(\\hat{\\theta}) = \\frac{n-1}{n} \\sum_{i=1}^n (\\hat{\\theta}_{(i)} - \\bar{\\theta}_{(\\cdot)})^2\n$$\n这个公式来自于“伪值” $\\psi_i = n\\hat{\\theta} - (n-1)\\hat{\\theta}_{(i)}$ 的样本方差，因为其均值的标准误被当作 $\\hat{\\theta}$ 的标准误。\n我们计算平方差之和：\n$$\n\\sum_{i=1}^9 (\\hat{\\theta}_{(i)} - \\bar{\\theta}_{(\\cdot)})^2 = (\\hat{\\theta}_{(1)} - \\bar{\\theta}_{(\\cdot)})^2 + (\\hat{\\theta}_{(9)} - \\bar{\\theta}_{(\\cdot)})^2 + \\sum_{i \\in \\{2..8\\}} (\\hat{\\theta}_{(i)} - \\bar{\\theta}_{(\\cdot)})^2\n$$\n使用数值：\n$$\n(0.185 - \\frac{0.745}{9})^2 + (-0.07 - \\frac{0.745}{9})^2 + 7 \\times (0.09 - \\frac{0.745}{9})^2\n$$\n$$\n\\approx (0.185 - 0.082778)^2 + (-0.07 - 0.082778)^2 + 7 \\times (0.09 - 0.082778)^2\n$$\n$$\n\\approx (0.102222)^2 + (-0.152778)^2 + 7 \\times (0.007222)^2\n$$\n$$\n\\approx 0.01044938 + 0.02334105 + 7 \\times 0.000052157\n$$\n$$\n\\approx 0.01044938 + 0.02334105 + 0.00036510\n$$\n$$\n\\sum_{i=1}^9 (\\hat{\\theta}_{(i)} - \\bar{\\theta}_{(\\cdot)})^2 \\approx 0.03415553\n$$\n现在，我们计算方差估计：\n$$\n\\hat{s}_{\\mathrm{jack}}^2 = \\frac{9-1}{9} \\times 0.03415553 = \\frac{8}{9} \\times 0.03415553 \\approx 0.03036047\n$$\n标准误是方差的平方根：\n$$\n\\hat{s}_{\\mathrm{jack}} = \\sqrt{0.03036047} \\approx 0.1742426\n$$\n四舍五入到四位有效数字，$\\hat{s}_{\\mathrm{jack}} = 0.1742$。\n\n最终结果是包含刀切法偏差和标准误估计的行向量。", "answer": "$$\n\\boxed{\\begin{pmatrix} -0.05778 & 0.1742 \\end{pmatrix}}\n$$", "id": "2404332"}]}