{"hands_on_practices": [{"introduction": "我们从一个经典的物理问题开始：确定单摆的周期。本练习将探讨摆长和当地重力加速度 $g$ 中的不确定性（这两者可能相关）如何传播到计算周期的不确定性中 [@problem_id:2448343]。通过应用一阶泰勒级数近似，你将学到一种估算非线性模型输出不确定性的基本技术。", "problem": "编写一个完整的程序，对于一个理想的小角度单摆，量化当摆长和当地重力加速度联合不确定且相关时，其振荡周期的不确定性。周期由映射 $T:\\mathbb{R}_{>0}^{2}\\to\\mathbb{R}_{>0}$ 建模，定义为 $T(L,g)=2\\pi\\sqrt{L/g}$。假设输入向量 $(L,g)$ 服从联合正态分布，其均值向量为 $(\\mu_L,\\mu_g)$，标准差为 $(\\sigma_L,\\sigma_g)$，相关系数为 $\\rho\\in[-1,1]$。对于每组参数，通过将 $T$ 在 $(\\mu_L,\\mu_g)$ 附近线性化，确定周期均值的一阶近似及其相应的一阶标准差。所有周期值和标准差均以秒为单位，四舍五入到 $6$ 位小数。\n\n使用以下测试集，其中 $L$ 的单位是米， $g$ 的单位是米每平方秒，每个元组为 $(\\mu_L,\\sigma_L,\\mu_g,\\sigma_g,\\rho)$：\n- 测试 1：$(1.000,0.005,9.80665,0.020,0.000)$。\n- 测试 2：$(2.000,0.010,9.81000,0.050,0.900)$。\n- 测试 3：$(0.500,0.002,9.78000,0.030,-0.900)$。\n- 测试 4：$(1.500,0.000001,9.81000,0.000001,0.000)$。\n\n你的程序应生成一行输出，包含一个用方括号括起来的逗号分隔列表形式的结果。每个测试用例的结果本身必须是一个包含两个元素的列表，分别是近似的平均周期和相应的一阶标准差，两者都以秒为单位，并四舍五入到 $6$ 位小数。例如，整体输出格式必须为 $[[\\mu_{T,1},\\sigma_{T,1}],[\\mu_{T,2},\\sigma_{T,2}],[\\mu_{T,3},\\sigma_{T,3}],[\\mu_{T,4},\\sigma_{T,4}]]$，不含任何额外文本。", "solution": "问题陈述已经过严格验证，被认为是科学上可靠、适定且客观的。它为使用既定的物理学和统计学原理进行不确定性量化提供了一个完整且一致的设置。因此，我们可以着手求解。\n\n该问题要求量化单摆周期 $T$ 的不确定性，其中 $T$ 是摆长 $L$ 和当地重力加速度 $g$ 的非线性函数。该映射关系如下：\n$$\nT(L, g) = 2\\pi\\sqrt{\\frac{L}{g}}\n$$\n输入参数 $(L, g)$ 被视为一个二元随机变量，服从联合正态分布，其均值向量为 $\\boldsymbol{\\mu} = (\\mu_L, \\mu_g)^T$，协方差矩阵为 $\\Sigma$。协方差矩阵由标准差 $\\sigma_L$ 和 $\\sigma_g$ 以及相关系数 $\\rho$ 定义：\n$$\n\\Sigma = \\begin{pmatrix} \\sigma_L^2 & \\rho \\sigma_L \\sigma_g \\\\ \\rho \\sigma_L \\sigma_g & \\sigma_g^2 \\end{pmatrix}\n$$\n我们的任务是求出周期 $T$ 的均值 $\\mu_T$ 和标准差 $\\sigma_T$ 的一阶近似。这可以通过应用不确定性传播定律来实现，该定律基于函数 $T(L, g)$ 在均值 $(\\mu_L, \\mu_g)$ 附近的一阶 Taylor 级数展开。\n\n首先，输出均值 $\\mu_T$ 的一阶近似就是函数在输入均值处的取值。这是期望值 Taylor 展开中的零阶项。在此一阶方法中，涉及函数 Hessian 矩阵的高阶项被忽略。\n$$\n\\mu_T \\approx T(\\mu_L, \\mu_g) = 2\\pi\\sqrt{\\frac{\\mu_L}{\\mu_g}}\n$$\n我们将在均值处的这个取值表示为 $T_0 = T(\\mu_L, \\mu_g)$。\n\n接下来，我们确定输出方差 $\\sigma_T^2$ 的一阶近似。对于一般函数 $Y = f(X_1, X_2)$，其方差由下式给出：\n$$\n\\sigma_Y^2 \\approx \\left(\\frac{\\partial f}{\\partial X_1}\\right)^2 \\sigma_{X_1}^2 + \\left(\\frac{\\partial f}{\\partial X_2}\\right)^2 \\sigma_{X_2}^2 + 2 \\left(\\frac{\\partial f}{\\partial X_1}\\right) \\left(\\frac{\\partial f}{\\partial X_2}\\right) \\text{Cov}(X_1, X_2)\n$$\n其中偏导数在均值 $(\\mu_{X_1}, \\mu_{X_2})$ 处求值。\n\n对于我们的特定函数 $T(L, g) = 2\\pi L^{1/2} g^{-1/2}$，我们必须计算其关于 $L$ 和 $g$ 的偏导数。\n关于 $L$ 的偏导数是：\n$$\n\\frac{\\partial T}{\\partial L} = 2\\pi \\left(\\frac{1}{2} L^{-1/2} g^{-1/2}\\right) = \\pi \\frac{1}{\\sqrt{Lg}}\n$$\n关于 $g$ 的偏导数是：\n$$\n\\frac{\\partial T}{\\partial g} = 2\\pi L^{1/2} \\left(-\\frac{1}{2} g^{-3/2}\\right) = -\\pi \\frac{\\sqrt{L}}{g\\sqrt{g}} = -\\pi \\frac{\\sqrt{L}}{\\sqrt{g^3}}\n$$\n通过将这些导数与 $T_0$ 联系起来，可以简化在均值点 $(\\mu_L, \\mu_g)$ 处的求值过程：\n$$\n\\left. \\frac{\\partial T}{\\partial L} \\right|_{(\\mu_L, \\mu_g)} = \\pi \\frac{1}{\\sqrt{\\mu_L \\mu_g}} = \\left(2\\pi\\sqrt{\\frac{\\mu_L}{\\mu_g}}\\right) \\left(\\frac{1}{2\\mu_L}\\right) = \\frac{T_0}{2\\mu_L}\n$$\n$$\n\\left. \\frac{\\partial T}{\\partial g} \\right|_{(\\mu_L, \\mu_g)} = -\\pi \\frac{\\sqrt{\\mu_L}}{\\sqrt{\\mu_g^3}} = \\left(2\\pi\\sqrt{\\frac{\\mu_L}{\\mu_g}}\\right) \\left(-\\frac{1}{2\\mu_g}\\right) = -\\frac{T_0}{2\\mu_g}\n$$\n现在，将这些灵敏度系数代入方差传播公式。协方差项为 $\\text{Cov}(L, g) = \\rho\\sigma_L\\sigma_g$。\n$$\n\\sigma_T^2 \\approx \\left(\\frac{T_0}{2\\mu_L}\\right)^2 \\sigma_L^2 + \\left(-\\frac{T_0}{2\\mu_g}\\right)^2 \\sigma_g^2 + 2\\left(\\frac{T_0}{2\\mu_L}\\right)\\left(-\\frac{T_0}{2\\mu_g}\\right)(\\rho\\sigma_L\\sigma_g)\n$$\n提出公因子后得到：\n$$\n\\sigma_T^2 \\approx \\frac{T_0^2}{4} \\left[ \\frac{\\sigma_L^2}{\\mu_L^2} + \\frac{\\sigma_g^2}{\\mu_g^2} - 2\\rho\\frac{\\sigma_L\\sigma_g}{\\mu_L\\mu_g} \\right]\n$$\n这个表达式可以用相对标准差（变异系数）$c_L = \\sigma_L/\\mu_L$ 和 $c_g = \\sigma_g/\\mu_g$ 写得更简洁：\n$$\n\\sigma_T^2 \\approx \\frac{T_0^2}{4} \\left[ c_L^2 + c_g^2 - 2\\rho c_L c_g \\right]\n$$\n一阶标准差 $\\sigma_T$ 是方差的平方根：\n$$\n\\sigma_T \\approx \\sqrt{\\sigma_T^2} = \\frac{T_0}{2} \\sqrt{ \\left(\\frac{\\sigma_L}{\\mu_L}\\right)^2 + \\left(\\frac{\\sigma_g}{\\mu_g}\\right)^2 - 2\\rho \\left(\\frac{\\sigma_L}{\\mu_L}\\right) \\left(\\frac{\\sigma_g}{\\mu_g}\\right) }\n$$\n这个最终公式提供了所需的振荡周期的一阶标准差。实现的算法如下：\n1. 对于每个测试用例 $(\\mu_L, \\sigma_L, \\mu_g, \\sigma_g, \\rho)$，首先计算近似平均周期 $T_0 = 2\\pi\\sqrt{\\mu_L/\\mu_g}$。\n2. 计算 $L$ 和 $g$ 的相对标准差。\n3. 将这些值代入推导出的 $\\sigma_T$ 公式中。\n4. 将 $T_0$ 和 $\\sigma_T$ 都四舍五入到指定的 $6$ 位小数。\n这个过程将针对所有提供的测试用例实施。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes first-order approximations for the mean and standard deviation\n    of a pendulum's period given uncertain inputs.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each tuple is (mu_L, sigma_L, mu_g, sigma_g, rho).\n    test_cases = [\n        (1.000, 0.005, 9.80665, 0.020, 0.000),\n        (2.000, 0.010, 9.81000, 0.050, 0.900),\n        (0.500, 0.002, 9.78000, 0.030, -0.900),\n        (1.500, 0.000001, 9.81000, 0.000001, 0.000),\n    ]\n\n    results = []\n    for case in test_cases:\n        mu_L, sigma_L, mu_g, sigma_g, rho = case\n\n        # Step 1: Calculate the first-order approximation for the mean period (T_0)\n        # mu_T is approximated by T(mu_L, mu_g)\n        mu_T = 2 * np.pi * np.sqrt(mu_L / mu_g)\n\n        # Step 2: Calculate the first-order standard deviation of the period\n        # Formula derived from first-order Taylor expansion (propagation of uncertainty)\n        # sigma_T = (T_0 / 2) * sqrt( (sigma_L/mu_L)^2 + (sigma_g/mu_g)^2 - 2*rho*(sigma_L/mu_L)*(sigma_g/mu_g) )\n        \n        # Avoid division by zero, though problem constraints ensure mu_L and mu_g > 0\n        if mu_L == 0 or mu_g == 0:\n            # This case is not expected based on the problem description\n            sigma_T = float('inf')\n        else:\n            rel_std_L = sigma_L / mu_L\n            rel_std_g = sigma_g / mu_g\n            \n            variance_term = (rel_std_L**2) + (rel_std_g**2) - (2 * rho * rel_std_L * rel_std_g)\n            \n            # The term inside sqrt must be non-negative.\n            # It represents the variance of a linear combination of correlated variables\n            # and is guaranteed to be non-negative.\n            if variance_term < 0:\n                # This could happen due to floating point inaccuracies, clamp to 0\n                variance_term = 0\n\n            sigma_T = (mu_T / 2) * np.sqrt(variance_term)\n\n        # Step 3: Round results to 6 decimal places\n        mu_T_rounded = round(mu_T, 6)\n        sigma_T_rounded = round(sigma_T, 6)\n        \n        results.append([mu_T_rounded, sigma_T_rounded])\n\n    # Final print statement in the exact required format.\n    # Convert the list of lists to the specified string format\n    # e.g., [[val1, val2],[val3, val4]]\n    result_str = \",\".join(map(str, results))\n    print(f\"[{result_str}]\")\n\nsolve()\n```", "id": "2448343"}, {"introduction": "在基本不确定性传播的基础上，下一个练习将解决一个更高级的问题：哪些不确定性输入最为重要？你将分析一个真实的管道压降流体动力学模型，并使用基于方差的全局敏感性分析来确定是流体粘度还是管道粗糙度主导了预测结果的不确定性 [@problem_id:2448383]。本练习介绍了一种强大的蒙特卡洛方法，用于将输出方差归因于不同的输入不确定性来源。", "problem": "一个水平、等温、稳定、不可压缩、充分发展的两种不互溶牛顿流体在圆形管道中的流动，通过均相混合物近似进行建模。设流体$1$的密度为$\\rho_1$、动力黏度为$\\mu_1$，流体$2$的密度为$\\rho_2$、动力黏度为$\\mu_2$。管道长度为$L$，直径为$D$，内部绝对粗糙度均匀为$\\varepsilon$。体积流量为$Q$，流体$1$的体积分数为$\\phi \\in [0,1]$（因此流体$2$的体积分数为$1-\\phi$）。重力和加速度效应被忽略。目标是对于给定的参数集和不确定性，量化黏度的不确定性或粗糙度的不确定性哪一个对压降不确定性的贡献更大。\n\n使用的模型定义：\n- 混合物密度：$\\rho_m = \\phi \\,\\rho_1 + (1-\\phi)\\,\\rho_2$。\n- 混合物动力黏度（线性体积混合）：$\\mu_m = \\phi \\,\\mu_1 + (1-\\phi)\\,\\mu_2$。\n- 平均速度：$U_m = \\dfrac{4Q}{\\pi D^2}$。\n- 雷诺数：$\\mathrm{Re} = \\dfrac{\\rho_m U_m D}{\\mu_m}$。\n- Darcy–Weisbach摩擦系数$f$：\n  - 层流区：若 $\\mathrm{Re} &lt; 2300$，则 $f = \\dfrac{64}{\\mathrm{Re}}$。\n  - 湍流区：若 $\\mathrm{Re} \\ge 2300$，使用Haaland关联式\n    $$\\frac{1}{\\sqrt{f}} = -1.8 \\log_{10}\\!\\left[\\left(\\frac{\\varepsilon/D}{3.7}\\right)^{1.11} + \\frac{6.9}{\\mathrm{Re}}\\right].$$\n- 压降：$$\\Delta P = f \\,\\frac{L}{D}\\,\\frac{\\rho_m U_m^2}{2}。$$\n\n不确定性输入：\n- $\\mu_1 \\sim \\text{Uniform}([0.02,\\,0.10])$，单位为$\\mathrm{Pa\\cdot s}$。\n- $\\mu_2 \\sim \\text{Uniform}([0.0008,\\,0.0015])$，单位为$\\mathrm{Pa\\cdot s}$。\n- $\\varepsilon \\sim \\text{Uniform}([10^{-5},\\,10^{-3}])$，单位为$\\mathrm{m}$。\n假设$\\mu_1$、$\\mu_2$和$\\varepsilon$是相互独立的。\n\n所有其他参数都是确定性的，并在下面的每个测试案例中指定。热物理属性固定为$\\rho_1 = 850\\,\\mathrm{kg/m^3}$和$\\rho_2 = 1000\\,\\mathrm{kg/m^3}$。\n\n待比较的敏感度量：\n- 令$Y = \\Delta P(\\mu_1,\\mu_2,\\varepsilon)$为建模的压降。对于输入的一个子集$S$，定义一阶方差贡献\n  $$C_S = \\frac{\\mathrm{Var}\\!\\left(\\mathbb{E}[Y \\mid S]\\right)}{\\mathrm{Var}(Y)},$$\n  其中方差和期望是关于$(\\mu_1,\\mu_2,\\varepsilon)$的联合分布计算的。\n- 当$S = \\{\\mu_1,\\mu_2\\}$时定义$C_{\\text{visc}}$，当$S = \\{\\varepsilon\\}$时定义$C_{\\text{rough}}$。\n\n任务：\n对于每个测试案例，计算$C_{\\text{visc}}$和$C_{\\text{rough}}$，并返回一个布尔值，指示$C_{\\text{visc}} > C_{\\text{rough}}$是否成立。\n\n测试套件（所有量都必须使用国际单位制）：\n- 案例1：$L=100$ $\\mathrm{m}$，$D=0.05$ $\\mathrm{m}$，$Q=0.002$ $\\mathrm{m^3/s}$，$\\phi=0.5$。\n- 案例2：$L=150$ $\\mathrm{m}$，$D=0.15$ $\\mathrm{m}$，$Q=0.03$ $\\mathrm{m^3/s}$，$\\phi=0.5$。\n- 案例3：$L=200$ $\\mathrm{m}$，$D=0.20$ $\\mathrm{m}$，$Q=0.12$ $\\mathrm{m^3/s}$，$\\phi=0.2$。\n- 案例4：$L=80$ $\\mathrm{m}$，$D=0.04$ $\\mathrm{m}$，$Q=0.0004$ $\\mathrm{m^3/s}$，$\\phi=0.8$。\n\n要求的最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的、由逗号分隔的布尔值列表，且不含空格。如果对于测试案例$i$，$C_{\\text{visc}} > C_{\\text{rough}}$成立，则第$i$个条目必须为True，否则为False。例如，一个有效的输出格式是“[True,False,True,False]”。", "solution": "问题陈述经过验证，被认为是有效的。它在科学上基于流体力学和不确定性量化的既定原则，问题提法适定，规定完整且客观。所有模型、参数和分布都已明确定义，从而可以得到唯一且可验证的数值解。因此，我将着手提供一个完整的解决方案。\n\n该问题要求比较黏度参数$(\\mu_1, \\mu_2)$和管道粗糙度参数$(\\varepsilon)$对计算出的压降$\\Delta P$总不确定性的贡献。这是一个基于方差的全局敏感度分析问题。待比较的量$C_{\\text{visc}}$和$C_{\\text{rough}}$分别是黏度参数组$S_{\\text{visc}} = \\{\\mu_1, \\mu_2\\}$和粗糙度参数$S_{\\text{rough}} = \\{\\varepsilon\\}$的一阶Sobol'指数。\n\n压降模型$Y = \\Delta P(\\mu_1, \\mu_2, \\varepsilon)$是其输入的非线性函数，涉及层流和湍流流态之间的条件切换，以及用于湍流摩擦系数的隐式非线性关联式（Haaland方程）。直接通过解析积分计算所需的方差和条件期望是不可行的。因此，数值蒙特卡洛（MC）方法是合适的工具。\n\n任务的核心是计算条件期望的方差，$V_S = \\mathrm{Var}(\\mathbb{E}[Y \\mid S])$，针对两组输入参数$S = S_{\\text{visc}}$和$S = S_{\\text{rough}}$。比较$C_{\\text{visc}} > C_{\\text{rough}}$等同于比较分子$V_{\\text{visc}} > V_{\\text{rough}}$，因为它们共享相同的分母，即总方差$\\mathrm{Var}(Y)$。\n\n我们将使用一个稳健且高效的蒙特卡洛估计器来计算$V_S$。步骤如下：\n1.  生成两个独立的$N \\times 3$随机样本矩阵$\\mathbf{A}$和$\\mathbf{B}$，其中每一行都是从其指定的均匀分布中抽取的$(\\mu_1, \\mu_2, \\varepsilon)$样本。$N$是样本数量，选择足够大的值以确保收敛（例如，$N=2^{18}$）。\n2.  对矩阵$\\mathbf{A}$中的样本评估正向模型$\\Delta P = \\text{model}(\\mu_1, \\mu_2, \\varepsilon)$，得到输出向量$\\mathbf{Y}_A$。该向量的均值$\\hat{\\mathbb{E}}[Y] = \\frac{1}{N}\\sum_{j=1}^N \\mathbf{Y}_{A,j}$提供了压降期望值的估计。我们将此估计的平方表示为$f_0^2$。\n3.  为了估计$V_{\\text{rough}} = \\mathrm{Var}(\\mathbb{E}[Y \\mid \\varepsilon])$，我们构建第三个矩阵$\\mathbf{C}_{\\text{rough}}$，其$\\mu_1$和$\\mu_2$列来自矩阵$\\mathbf{B}$，而$\\varepsilon$列来自矩阵$\\mathbf{A}$。\n4.  对$\\mathbf{C}_{\\text{rough}}$评估模型以获得输出向量$\\mathbf{Y}_{C_{\\text{rough}}}$。然后方差估计如下：\n    $$V_{\\text{rough}} \\approx \\frac{1}{N} \\sum_{j=1}^N \\mathbf{Y}_{A,j} \\cdot \\mathbf{Y}_{C_{\\text{rough}},j} - f_0^2$$\n    当$N \\to \\infty$时，此估计器收敛于$\\mathrm{Var}(\\mathbb{E}[Y \\mid \\varepsilon])$。\n5.  为了估计$V_{\\text{visc}} = \\mathrm{Var}(\\mathbb{E}[Y \\mid \\mu_1, \\mu_2])$，我们构建第四个矩阵$\\mathbf{C}_{\\text{visc}}$，其$\\mu_1$和$\\mu_2$列来自矩阵$\\mathbf{A}$，而$\\varepsilon$列来自矩阵$\\mathbf{B}$。\n6.  对$\\mathbf{C}_{\\text{visc}}$评估模型以获得$\\mathbf{Y}_{C_{\\text{visc}}}$。然后方差估计如下：\n    $$V_{\\text{visc}} \\approx \\frac{1}{N} \\sum_{j=1}^N \\mathbf{Y}_{A,j} \\cdot \\mathbf{Y}_{C_{\\text{visc}},j} - f_0^2$$\n    此估计器收敛于$\\mathrm{Var}(\\mathbb{E}[Y \\mid \\mu_1, \\mu_2])$。\n7.  对于每个测试案例，我们计算$V_{\\text{visc}}$和$V_{\\text{rough}}$，并确定是否$V_{\\text{visc}} > V_{\\text{rough}}$。\n\n正向模型实现$\\Delta P(\\mu_1, \\mu_2, \\varepsilon)$是使用NumPy构建的向量化函数，以提高计算效率。它首先计算混合物性质（$\\rho_m, \\mu_m$）和雷诺数（$\\mathrm{Re}$）。对$\\mathrm{Re}$进行条件检查，将流动分为层流（$\\mathrm{Re} < 2300$）和湍流（$\\mathrm{Re} \\ge 2300$）区。相应地计算Darcy摩擦系数$f$。对于湍流区，Haaland关联式以一种可以显式求解$f$的形式给出，从而避免了迭代数值求根过程的需要：\n$$f = \\left(\\frac{1}{-1.8 \\log_{10}\\!\\left[\\left(\\frac{\\varepsilon/D}{3.7}\\right)^{1.11} + \\frac{6.9}{\\mathrm{Re}}\\right]}\\right)^2$$\n最后，使用Darcy-Weisbach方程计算压降$\\Delta P$。对四个指定的测试案例中的每一个都重复此整个过程。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the uncertainty quantification problem for the given test cases.\n    \"\"\"\n\n    # Define deterministic physical constants\n    RHO1 = 850.0  # kg/m^3\n    RHO2 = 1000.0 # kg/m^3\n    RE_TRANSITION = 2300.0\n\n    # Define uncertain parameter distributions (Uniform)\n    MU1_RANGE = [0.02, 0.10]    # Pa.s\n    MU2_RANGE = [0.0008, 0.0015] # Pa.s\n    EPS_RANGE = [1e-5, 1e-3]   # m\n\n    def evaluate_model(mu1_samples, mu2_samples, eps_samples, L, D, Q, phi):\n        \"\"\"\n        Vectorized evaluation of the pressure drop model.\n        \n        Args:\n            mu1_samples (np.array): Samples for viscosity of fluid 1.\n            mu2_samples (np.array): Samples for viscosity of fluid 2.\n            eps_samples (np.array): Samples for pipe roughness.\n            L (float): Pipe length.\n            D (float): Pipe diameter.\n            Q (float): Volumetric flow rate.\n            phi (float): Volume fraction of fluid 1.\n            \n        Returns:\n            np.array: Calculated pressure drop for each sample.\n        \"\"\"\n        # Mixture properties. rho_m is constant for a given case.\n        rho_m = phi * RHO1 + (1.0 - phi) * RHO2\n        mu_m = phi * mu1_samples + (1.0 - phi) * mu2_samples\n        \n        # Flow properties. U_m is constant for a given case.\n        U_m = (4.0 * Q) / (np.pi * D**2)\n        Re = rho_m * U_m * D / mu_m\n        \n        # Darcy friction factor\n        f = np.empty_like(Re)\n        \n        # Laminar flow regime\n        laminar_mask = Re < RE_TRANSITION\n        if np.any(laminar_mask):\n            f[laminar_mask] = 64.0 / Re[laminar_mask]\n            \n        # Turbulent flow regime\n        turbulent_mask = ~laminar_mask\n        if np.any(turbulent_mask):\n            eps_D_ratio = eps_samples[turbulent_mask] / D\n            Re_turb = Re[turbulent_mask]\n            \n            # Haaland correlation solved explicitly for f\n            log_term = np.log10((eps_D_ratio / 3.7)**1.11 + 6.9 / Re_turb)\n            f[turbulent_mask] = (-1.8 * log_term)**-2.0\n            \n        # Pressure drop (Darcy-Weisbach equation)\n        delta_P = f * (L / D) * (rho_m * U_m**2) / 2.0\n        \n        return delta_P\n\n    def compute_variances(params, N, rng):\n        \"\"\"\n        Computes the variance components V_visc and V_rough using Monte Carlo.\n        \"\"\"\n        L, D, Q, phi = params\n        \n        # Generate two independent sets of uniform random numbers in [0, 1]\n        A_uniform = rng.random(size=(N, 3))\n        B_uniform = rng.random(size=(N, 3))\n        \n        # Helper to scale uniform samples to their physical ranges\n        def scale_samples(uniform_samples):\n            mu1 = MU1_RANGE[0] + uniform_samples[:, 0] * (MU1_RANGE[1] - MU1_RANGE[0])\n            mu2 = MU2_RANGE[0] + uniform_samples[:, 1] * (MU2_RANGE[1] - MU2_RANGE[0])\n            eps = EPS_RANGE[0] + uniform_samples[:, 2] * (EPS_RANGE[1] - EPS_RANGE[0])\n            return mu1, mu2, eps\n\n        # Create physical sample matrices A and B\n        mu1_A, mu2_A, eps_A = scale_samples(A_uniform)\n        mu1_B, mu2_B, eps_B = scale_samples(B_uniform)\n\n        # Evaluate model for matrix A to estimate the mean\n        Y_A = evaluate_model(mu1_A, mu2_A, eps_A, L, D, Q, phi)\n        f0_sq = np.mean(Y_A)**2\n        \n        # Construct C matrices and evaluate model outputs\n        # C_rough matrix: mu from B, eps from A. Used to estimate V_rough.\n        Y_C_rough = evaluate_model(mu1_B, mu2_B, eps_A, L, D, Q, phi)\n        # C_visc matrix: mu from A, eps from B. Used to estimate V_visc.\n        Y_C_visc = evaluate_model(mu1_A, mu2_A, eps_B, L, D, Q, phi)\n        \n        # Estimate the variance of conditional expectations\n        V_rough = np.mean(Y_A * Y_C_rough) - f0_sq\n        V_visc = np.mean(Y_A * Y_C_visc) - f0_sq\n        \n        return V_visc, V_rough\n\n    # Define the test cases from the problem statement\n    test_cases = [\n        # (L, D, Q, phi)\n        (100.0, 0.05, 0.002, 0.5),\n        (150.0, 0.15, 0.03, 0.5),\n        (200.0, 0.20, 0.12, 0.2),\n        (80.0, 0.04, 0.0004, 0.8),\n    ]\n\n    results = []\n    # N must be large enough for convergence of the MC estimators\n    N = 2**18\n    # Use a fixed seed for reproducible results\n    rng = np.random.default_rng(seed=123)\n    \n    for case in test_cases:\n        V_visc, V_rough = compute_variances(case, N, rng)\n        results.append(V_visc > V_rough)\n        \n    # Format the final output as a comma-separated list of booleans\n    # The map(str,...) is used to convert boolean True/False to string \"True\"/\"False\"\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2448383"}, {"introduction": "现在，我们将从“正向”不确定性量化转向“反向”问题，使用一个离散系统（元胞自动机）作为清晰的范例。你将通过实现一个贝叶斯分析来解决一个反向问题：根据一个单一的、带噪声的最终状态，推断出控制元胞自动机演化的最可能规则 [@problem_id:2448360]。这个练习让你亲手实践贝叶斯的核心概念，如先验、似然和后验概率。", "problem": "给定一个格子长度为 $L$、具有周期性边界条件的一维、二元状态、半径为$1$的元胞自动机。元胞自动机规则是来自 Wolfram 基本规则集的一个元素 $r \\in \\{0,1,\\dots,255\\}$。对于任意规则 $r$，定义局部更新函数 $f_r:\\{0,1\\}^3 \\to \\{0,1\\}$ 如下。将 $r$ 写成一个 8 位二进制字符串 $(b_7,b_6,b_5,b_4,b_3,b_2,b_1,b_0)$，其中每个 $b_k \\in \\{0,1\\}$ 且 $r = \\sum_{k=0}^{7} b_k 2^k$。对于一个邻域 $(\\ell,c,\\rho) \\in \\{0,1\\}^3$，其输出位由 $f_r(\\ell,c,\\rho) = b_{4\\ell + 2c + \\rho}$ 给出。设自动机在离散时间 $t$ 的状态为 $\\mathbf{x}^{(t)} \\in \\{0,1\\}^L$，通过\n$$\nx^{(t+1)}_i = f_r\\!\\bigl(x^{(t)}_{i-1},\\,x^{(t)}_{i},\\,x^{(t)}_{i+1}\\bigr), \\quad i \\in \\{0,1,\\dots,L-1\\},\n$$\n进行同步更新，其中周期性边界条件为 $x^{(t)}_{-1} \\equiv x^{(t)}_{L-1}$ 和 $x^{(t)}_{L} \\equiv x^{(t)}_{0}$。\n\n从一个已知的初始状态 $\\mathbf{x}^{(0)}$ 经过 $T$ 个时间步后，你观测到一个带噪声的最终状态 $\\tilde{\\mathbf{y}} \\in \\{0,1\\}^L$。观测噪声模型是独立位翻转：以真实的最终状态 $\\mathbf{y} = \\mathbf{x}^{(T)}$ 为条件，每个位以概率 $p \\in [0,1]$ 独立翻转。也就是说，对于每个位点 $i$，\n$$\n\\mathbb{P}\\!\\left(\\tilde{y}_i \\mid y_i\\right) =\n\\begin{cases}\n1-p, & \\text{若 } \\tilde{y}_i = y_i,\\\\\np, & \\text{若 } \\tilde{y}_i \\neq y_i.\n\\end{cases}\n$$\n假设在规则集 $\\{0,1,\\dots,255\\}$ 上服从均匀先验。使用贝叶斯定理，为每个候选规则 $r$ 计算后验概率 $\\mathbb{P}(r \\mid \\tilde{\\mathbf{y}}, \\mathbf{x}^{(0)}, T, p)$（可忽略一个共同的归一化常数），并确定最大后验规则索引 $r_{\\mathrm{MAP}}$。如果出现后验概率相同的情况，则选择最小的规则索引。\n\n你的程序必须严格按照上述说明实现此概率模型，并为下面提供的每个测试用例返回单个整数 $r_{\\mathrm{MAP}}$。\n\n测试集。对于每个用例，所有向量均按 $\\bigl[x_0,x_1,\\dots,x_{L-1}\\bigr]$ 的顺序排列。\n\n- 用例 A (一般情况)：$L = 8$，$T = 3$，$p = 0.1$，初始状态 $\\mathbf{x}^{(0)} = [\\,0,0,0,1,0,0,0,0\\,]$，观测状态 $\\tilde{\\mathbf{y}} = [\\,0,1,0,1,0,1,0,0\\,]$。\n- 用例 B (确定性观测, $T=1$)：$L = 8$，$T = 1$，$p = 0$，初始状态 $\\mathbf{x}^{(0)} = [\\,1,0,1,0,1,0,1,0\\,]$，观测状态 $\\tilde{\\mathbf{y}} = [\\,0,1,0,1,0,1,0,1\\,]$。\n- 用例 C (无信息噪声)：$L = 5$，$T = 2$，$p = 0.5$，初始状态 $\\mathbf{x}^{(0)} = [\\,0,0,1,0,0\\,]$，观测状态 $\\tilde{\\mathbf{y}} = [\\,1,1,1,1,1\\,]$。\n- 用例 D (无演化, $T=0$)：$L = 7$，$T = 0$，$p = 0.2$，初始状态 $\\mathbf{x}^{(0)} = [\\,1,1,0,0,1,0,0\\,]$，观测状态 $\\tilde{\\mathbf{y}} = [\\,1,0,0,0,1,0,0\\,]$。\n\n最终输出格式。你的程序应生成单行输出，其中包含用例 A、B、C 和 D 的四个整数结果，按此顺序排列，形式为逗号分隔的列表，并用方括号括起来，例如，“[1,2,3,4]”。输出行中不允许有空格。所有量都是无量纲的，如果存在角度，则必须以弧度为单位；但此处未使用角度。要求的输出仅为整数。", "solution": "我们从第一性原理出发构建贝叶斯推断问题。一个具有周期性边界条件的一维、二元状态、半径为$1$的元胞自动机，通过一个由 Wolfram 规则索引 $r \\in \\{0,1,\\dots,255\\}$ 决定的确定性局部规则 $f_r:\\{0,1\\}^3 \\to \\{0,1\\}$ 进行演化。将 $r$ 写成二进制形式 $(b_7,b_6,\\dots,b_0)$，其中 $b_k \\in \\{0,1\\}$ 且 $r = \\sum_{k=0}^{7} b_k 2^k$，则局部更新为 $f_r(\\ell,c,\\rho) = b_{4\\ell+2c+\\rho}$，其中 $(\\ell,c,\\rho)$ 是邻域的左、中、右位。对于长度为 $L$ 的格子，全局同步更新为\n$$\nx^{(t+1)}_i = f_r\\!\\bigl(x^{(t)}_{i-1},\\,x^{(t)}_{i},\\,x^{(t)}_{i+1}\\bigr), \\quad i=0,1,\\dots,L-1,\n$$\n其中周期性边界条件为 $x^{(t)}_{-1}=x^{(t)}_{L-1}$ 和 $x^{(t)}_{L}=x^{(t)}_{0}$。给定一个初始构型 $\\mathbf{x}^{(0)} \\in \\{0,1\\}^L$ 和一个时间范围 $T \\in \\mathbb{N}_0$，在规则 $r$ 下预测的无噪声最终状态是通过 $T$ 次更新迭代得到的 $\\mathbf{y}_r = \\mathbf{x}^{(T)}$。\n\n观测模型指明，观测向量 $\\tilde{\\mathbf{y}}$ 是从真实的最终状态 $\\mathbf{y}_r$ 通过以概率 $p \\in [0,1]$ 进行的独立位翻转生成的。因此，规则 $r$ 的似然函数为\n$$\n\\mathcal{L}(r) = \\mathbb{P}(\\tilde{\\mathbf{y}} \\mid r, \\mathbf{x}^{(0)}, T, p) = \\prod_{i=0}^{L-1} \\left[(1-p)\\,\\mathbb{I}\\{\\tilde{y}_i = y_{r,i}\\} + p\\,\\mathbb{I}\\{\\tilde{y}_i \\neq y_{r,i}\\}\\right].\n$$\n令 $m_r$ 为匹配数，即 $m_r = \\sum_{i=0}^{L-1} \\mathbb{I}\\{\\tilde{y}_i = y_{r,i}\\}$，则不匹配数为 $L - m_r$。因为在给定 $\\mathbf{y}_r$ 的条件下，各个位是独立同分布的，所以似然函数简化为\n$$\n\\mathcal{L}(r) = (1-p)^{m_r} \\, p^{L - m_r},\n$$\n其中对于 $p \\in \\{0,1\\}$ 有极限约定：当 $p=0$ 时，如果 $m_r=L$ 则似然为 $1$，否则为 $0$；当 $p=1$ 时，如果 $m_r=0$ 则似然为 $1$，否则为 $0$。\n\n假设均匀先验 $\\mathbb{P}(r) = 1/256$，贝叶斯定理给出后验概率\n$$\n\\mathbb{P}(r \\mid \\tilde{\\mathbf{y}}, \\mathbf{x}^{(0)}, T, p) = \\frac{\\mathcal{L}(r)\\,\\mathbb{P}(r)}{\\sum_{r'=0}^{255} \\mathcal{L}(r')\\,\\mathbb{P}(r')} \\propto \\mathcal{L}(r).\n$$\n因此，最大后验 (MAP) 估计为\n$$\nr_{\\mathrm{MAP}} \\in \\arg\\max_{r \\in \\{0,\\dots,255\\}} \\mathcal{L}(r),\n$$\n并通过选择最小的 $r$ 来打破平局。为避免当 $p \\in (0,1)$ 且 $L$ 中等大小时出现数值下溢，计算应通过对数似然进行，\n$$\n\\log \\mathcal{L}(r) = m_r \\log(1-p) + (L - m_r) \\log p,\n$$\n并对 $p \\in \\{0,1\\}$ 的相应极限情况进行显式处理。\n\n基于原理的算法设计：\n- 对于每个测试用例，枚举所有 256 个规则 $r$。\n- 对于每个 $r$，使用局部规则 $f_r$ 和周期性边界条件，从 $\\mathbf{x}^{(0)}$ 开始，通过迭代同步更新 $T$ 次来计算 $\\mathbf{y}_r$。\n- 计算 $m_r$ 作为满足 $y_{r,i} = \\tilde{y}_i$ 的索引 $i \\in \\{0,\\dots,L-1\\}$ 的数量。\n- 使用上述表达式计算 $\\log \\mathcal{L}(r)$，并通过其极限处理 $p=0$ 和 $p=1$ 的情况。\n- 选择使 $\\log \\mathcal{L}(r)$ 最大化的 $r$；如果多个规则在精确或数值容差范围内达到相同的值，则选择最小的 $r$。\n\n测试集中的边界情况如下所示：\n- 用例 A 中 $p = 0.1 \\in (0,1)$ 且 $T=3$，代表一个典型的推断场景。\n- 用例 B 中 $p = 0$ 且 $T=1$。在这种情况下，只有产生精确匹配 $\\mathbf{y}_r = \\tilde{\\mathbf{y}}$ 的规则才具有非零似然。对于给定的初始模式 $\\mathbf{x}^{(0)} = [\\,1,0,1,0,1,0,1,0\\,]$，在时间 $t=0$ 时出现的邻域仅为 $\\{010, 101\\}$。观测到的 $\\tilde{\\mathbf{y}} = [\\,0,1,0,1,0,1,0,1\\,]$ 施加了约束 $f_r(0,1,0) = 0$ 和 $f_r(1,0,1) = 1$。与这两个输出一致的最小规则 $r$ 是通过设置 $b_{2} = 0$ 和 $b_{5} = 1$ 以及所有其他 $b_k = 0$ 得到的，即 $r = 2^5 = 32$。\n- 用例 C 中 $p = 0.5$。对于任何 $r$，$\\log \\mathcal{L}(r) = L \\log(0.5)$ 是一个常数，因此后验是均匀的，打破平局的规则选择 $r_{\\mathrm{MAP}} = 0$。\n- 用例 D 中 $T = 0$。对于所有规则 $r$，预测的最终状态都等于初始状态，因此似然仅取决于 $\\mathbf{x}^{(0)}$ 和 $\\tilde{\\mathbf{y}}$，而与 $r$ 无关，所以后验是均匀的。打破平局的规则选择 $r_{\\mathrm{MAP}} = 0$。\n\n程序枚举所有规则，按上述方法计算对数似然，应用打破平局的规则，并在一行中无空格地打印四个整数 $[r_{\\mathrm{MAP},A}, r_{\\mathrm{MAP},B}, r_{\\mathrm{MAP},C}, r_{\\mathrm{MAP},D}]$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef rule_to_table(rule_index: int) -> np.ndarray:\n    \"\"\"\n    Convert a Wolfram elementary cellular automaton rule index (0..255)\n    into a lookup table of length 8, where table[k] is the output bit\n    for neighborhood with decimal code k = 4*left + 2*center + right.\n    \"\"\"\n    # Bits b0..b7 where b_k is (rule_index >> k) & 1\n    table = np.array([(rule_index >> k) & 1 for k in range(8)], dtype=np.uint8)\n    return table\n\ndef evolve_once(state: np.ndarray, table: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Perform one synchronous update of a 1D binary CA with periodic boundary\n    conditions using the provided rule table.\n    \"\"\"\n    # Periodic neighbors using numpy roll\n    left = np.roll(state, 1)\n    center = state\n    right = np.roll(state, -1)\n    # Neighborhood code: 4*left + 2*center + right\n    codes = (left << 2) | (center << 1) | right\n    next_state = table[codes]\n    return next_state\n\ndef evolve(state0: np.ndarray, rule_index: int, T: int) -> np.ndarray:\n    \"\"\"\n    Evolve the CA for T steps from initial state0 under rule_index.\n    \"\"\"\n    state = state0.copy()\n    if T <= 0:\n        return state\n    table = rule_to_table(rule_index)\n    for _ in range(T):\n        state = evolve_once(state, table)\n    return state\n\ndef log_likelihood(observed: np.ndarray, predicted: np.ndarray, p: float) -> float:\n    \"\"\"\n    Compute log-likelihood under independent bit-flip model with probability p.\n    Handle limiting cases p=0 and p=1 exactly.\n    \"\"\"\n    L = observed.size\n    matches = int(np.sum(observed == predicted))\n    mismatches = L - matches\n    if p == 0.0:\n        return 0.0 if mismatches == 0 else float(\"-inf\")\n    if p == 1.0:\n        return 0.0 if matches == 0 else float(\"-inf\")\n    # General case 0 < p < 1\n    return matches * np.log(1.0 - p) + mismatches * np.log(p)\n\ndef map_rule_for_case(L: int, T: int, p: float, x0_list, yobs_list) -> int:\n    \"\"\"\n    Compute the MAP rule index (0..255) for the given case parameters,\n    using uniform prior and tie-breaking by smallest index.\n    \"\"\"\n    x0 = np.array(x0_list, dtype=np.uint8)\n    yobs = np.array(yobs_list, dtype=np.uint8)\n    assert x0.size == L and yobs.size == L\n    best_rule = 0\n    best_loglike = float(\"-inf\")\n    tol = 1e-12\n    for r in range(256):\n        ypred = evolve(x0, r, T)\n        ll = log_likelihood(yobs, ypred, p)\n        if ll > best_loglike + tol:\n            best_loglike = ll\n            best_rule = r\n        elif abs(ll - best_loglike) <= tol and r < best_rule:\n            best_rule = r\n    return best_rule\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case: (L, T, p, x0, y_obs)\n    test_cases = [\n        (8, 3, 0.1, [0,0,0,1,0,0,0,0], [0,1,0,1,0,1,0,0]),  # Case A\n        (8, 1, 0.0, [1,0,1,0,1,0,1,0], [0,1,0,1,0,1,0,1]),  # Case B\n        (5, 2, 0.5, [0,0,1,0,0],       [1,1,1,1,1]),        # Case C\n        (7, 0, 0.2, [1,1,0,0,1,0,0],   [1,0,0,0,1,0,0]),    # Case D\n    ]\n\n    results = []\n    for L, T, p, x0, yobs in test_cases:\n        result = map_rule_for_case(L, T, p, x0, yobs)\n        results.append(result)\n\n    # Final print statement in the exact required format: no spaces.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2448360"}]}