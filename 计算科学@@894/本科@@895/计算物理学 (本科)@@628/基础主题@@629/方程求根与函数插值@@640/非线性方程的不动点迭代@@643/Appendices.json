{"hands_on_practices": [{"introduction": "理论和实践之间的桥梁始于理解如何构建有效的迭代格式。本练习将引导你为同一个非线性方程设计多个不动点迭代方案，每个方案都针对其一个特定根。通过调整一个关键参数，你将亲手揭示如何将一个基本的迭代方法提升至二次收敛，这是牛顿法等高效算法的核心思想。[@problem_id:2393364]", "problem": "在计算工程中，不动点迭代是求解由控制方程离散化产生的非线性代数方程的基本方法。考虑标量非线性方程\n$$\nf(x) = x^{3} - 6x^{2} + 11x - 6 = 0,\n$$\n该方程在 $x = 1$、$x = 2$ 和 $x = 3$ 处有三个单实根。对于每个根 $r_{k} \\in \\{1, 2, 3\\}$，构造一个松弛形式的不动点迭代\n$$\nx_{n+1} = g_{k}(x_{n}), \\quad g_{k}(x) = x - \\alpha_{k}\\, f(x),\n$$\n其中常数参数 $\\alpha_{k}$ 的选择应使得迭代在目标根 $r_{k}$ 附近至少是二阶收敛的。然后，确定分别对应于 $r_{1} = 1$、$r_{2} = 2$ 和 $r_{3} = 3$ 的 $\\alpha_{1}$、$\\alpha_{2}$ 和 $\\alpha_{3}$ 的精确值，并计算\n$$\nS = \\alpha_{1} + \\alpha_{2} + \\alpha_{3}.\n$$\n请以单个精确值的形式给出 $S$。无需进行舍入。", "solution": "在尝试求解之前，对问题陈述进行验证。\n\n步骤1：提取已知条件。\n提供的信息如下：\n- 非线性标量方程为 $f(x) = x^{3} - 6x^{2} + 11x - 6 = 0$。\n- 该方程有三个单实根：$r_{1} = 1$，$r_{2} = 2$ 和 $r_{3} = 3$。\n- 为每个根 $r_k$ 给出了一个不动点迭代格式：$x_{n+1} = g_{k}(x_{n})$。\n- 迭代函数被定义为松弛形式：$g_{k}(x) = x - \\alpha_{k}\\, f(x)$。\n- 参数 $\\alpha_{k}$ 的选择必须使得迭代在相应根 $r_{k}$ 附近至少是二阶收敛的。\n- 目标是计算总和 $S = \\alpha_{1} + \\alpha_{2} + \\alpha_{3}$。\n\n步骤2：使用提取的已知条件进行验证。\n对问题的有效性进行评估：\n- **科学依据：** 该问题植根于数值方法的基本理论，特别是不动点迭代及其收敛准则。收敛阶（线性、二次等）的概念是计算科学与工程中的一个标准课题。该问题在科学上是合理的。\n- **适定性：** 该问题提供了明确的目标和充分的信息。“至少二阶收敛”的条件对迭代函数的导数施加了特定的数学约束，这使得每个参数 $\\alpha_{k}$ 能够被唯一确定。该问题是适定的。\n- **客观性：** 该问题使用精确的数学语言陈述，没有歧义、主观性或个人观点。\n\n该问题没有表现出任何诸如科学上不合理、不完整、矛盾或歧义等缺陷。它是数值分析中的一个标准的、可形式化的问题。\n\n步骤3：结论与行动。\n该问题被认为是有效的。将推导解答。\n\n问题的核心在于分析不动点迭代 $x_{n+1} = g(x_{n})$ 的收敛速度。如果 $r$ 是 $g(x)$ 的一个不动点（即 $g(r) = r$），并且迭代函数在 $r$ 的一个邻域内是压缩映射，那么不动点迭代收敛于根 $r$。收敛阶由在不动点 $r$ 处计算的 $g(x)$ 的导数决定。\n\n为使迭代局部地至少是二阶收敛，迭代函数的一阶导数在不动点处必须为零。即，$g'(r) = 0$。如果满足此条件，$g(x)$ 在 $r$ 点的泰勒级数展开为：\n$$\ng(x) = g(r) + g'(r)(x-r) + \\frac{g''(r)}{2!}(x-r)^{2} + O((x-r)^{3})\n$$\n在 $g(r)=r$ 和 $g'(r)=0$ 的条件下，上式变为：\n$$\ng(x) - r = \\frac{g''(r)}{2}(x-r)^{2} + O((x-r)^{3})\n$$\n令 $e_{n} = x_{n} - r$ 为第 $n$ 次迭代的误差。则 $x_{n} = r + e_{n}$，且 $x_{n+1} = g(x_{n})$。\n$$\ne_{n+1} = x_{n+1} - r = g(x_{n}) - r = g(r + e_{n}) - r = \\frac{g''(r)}{2} e_{n}^{2} + O(e_{n}^{3})\n$$\n这种关系，即第 $n+1$ 步的误差与第 $n$ 步误差的平方成正比，正是二次收敛的定义，前提是 $g''(r) \\neq 0$。“至少二次收敛”这个条件要求 $g'(r)=0$。\n\n对于每个根 $r_k$，迭代函数为 $g_{k}(x) = x - \\alpha_{k} f(x)$。首先，我们确认每个根 $r_k$ 都是 $g_k(x)$ 的不动点。根据定义，$f(r_k) = 0$，所以 $g_{k}(r_{k}) = r_{k} - \\alpha_{k} f(r_{k}) = r_{k} - \\alpha_{k}(0) = r_{k}$。这对 $\\alpha_k$ 的任何选择都成立。\n\n为确保至少二次收敛，我们必须强制执行条件 $g_{k}'(r_{k}) = 0$。我们首先计算 $g_{k}(x)$ 的导数：\n$$\ng_{k}'(x) = \\frac{d}{dx} \\left( x - \\alpha_{k} f(x) \\right) = 1 - \\alpha_{k} f'(x)\n$$\n在根 $r_k$ 处对此求值并令其为零，可得：\n$$\ng_{k}'(r_{k}) = 1 - \\alpha_{k} f'(r_{k}) = 0\n$$\n解出 $\\alpha_{k}$，我们发现所需的值为：\n$$\n\\alpha_{k} = \\frac{1}{f'(r_{k})}\n$$\n这假设 $f'(r_k) \\neq 0$，根据问题陈述，对于单根这是成立的。\n\n接下来，我们必须计算给定函数 $f(x) = x^{3} - 6x^{2} + 11x - 6$ 的导数：\n$$\nf'(x) = \\frac{d}{dx} \\left( x^{3} - 6x^{2} + 11x - 6 \\right) = 3x^{2} - 12x + 11\n$$\n现在，我们可以为三个根中的每一个计算 $\\alpha_k$ 的值。\n\n对于根 $r_{1} = 1$：\n$$\nf'(1) = 3(1)^{2} - 12(1) + 11 = 3 - 12 + 11 = 2\n$$\n因此，参数 $\\alpha_{1}$ 是：\n$$\n\\alpha_{1} = \\frac{1}{f'(1)} = \\frac{1}{2}\n$$\n\n对于根 $r_{2} = 2$：\n$$\nf'(2) = 3(2)^{2} - 12(2) + 11 = 3(4) - 24 + 11 = 12 - 24 + 11 = -1\n$$\n因此，参数 $\\alpha_{2}$ 是：\n$$\n\\alpha_{2} = \\frac{1}{f'(2)} = \\frac{1}{-1} = -1\n$$\n\n对于根 $r_{3} = 3$：\n$$\nf'(3) = 3(3)^{2} - 12(3) + 11 = 3(9) - 36 + 11 = 27 - 36 + 11 = 2\n$$\n因此，参数 $\\alpha_{3}$ 是：\n$$\n\\alpha_{3} = \\frac{1}{f'(3)} = \\frac{1}{2}\n$$\n\n最后，问题要求计算总和 $S = \\alpha_{1} + \\alpha_{2} + \\alpha_{3}$：\n$$\nS = \\frac{1}{2} + (-1) + \\frac{1}{2} = 1 - 1 = 0\n$$\n$S$ 的值恰好为 $0$。", "answer": "$$\\boxed{0}$$", "id": "2393364"}, {"introduction": "在掌握了二次收敛的基础后，一个自然的问题是：我们能否构建收敛更快的迭代方法？这个实践挑战你设计并实现一个具有三阶（立方）收敛速度的迭代格式——哈雷方法（Halley's method）。它将深化你对收敛阶数与迭代函数导数之间关系的理解，并让你体验在算法复杂性与收敛效率之间进行权衡。[@problem_id:2394865]", "problem": "你需要构造并应用一个具有三阶收敛性的不动点迭代格式，以逼近一个非线性方程的实根。设一个实值函数表示为 $f(x)$，其中 $x \\in \\mathbb{R}$。不动点迭代是形如 $x_{n+1} = g(x_n)$ 的任意映射，其中 $g(x)$ 是某个函数。你的任务是设计一个函数 $g(x)$，使其产生一个局部收敛阶为 $3$ 的不动点迭代，用于求解 $f(x)=0$ 的单根情况，然后将其应用于下面的测试集。\n\n正确性和收敛性分析的假设：$f$ 在所求根 $\\alpha$ 的邻域内至少三阶连续可微，且满足 $f(\\alpha) = 0$ 和 $f'(\\alpha) \\neq 0$。\n\n终止条件：当 $|f(x_n)| \\leq 10^{-12}$ 或 $|x_{n+1} - x_n| \\leq 10^{-12}$ 满足其一，或在最多 $50$ 次迭代后，你的迭代必须停止，以先发生者为准。如果你的迭代达到了最大迭代次数而未满足精度阈值，则返回最后一次得到的迭代值。\n\n所有三角函数和指数函数的求值中，角度必须使用弧度制。\n\n测试集：对于每种情况，使用指定的 $f(x)$ 及其解析导数 $f'(x)$ 和 $f''(x)$、给定的初始猜测值 $x_0$ 以及上述终止条件。\n- 情况 $1$（“理想路径”）：$f_1(x) = \\cos(x) - x$，$f_1'(x) = -\\sin(x) - 1$，$f_1''(x) = -\\cos(x)$，初始值 $x_0 = 0.5$。\n- 情况 $2$（远离初值）：$f_2(x) = x^3 - 2$，$f_2'(x) = 3 x^2$，$f_2''(x) = 6 x$，初始值 $x_0 = 10.0$。\n- 情况 $3$（中等非线性）：$f_3(x) = e^x - 3 x$，$f_3'(x) = e^x - 3$，$f_3''(x) = e^x$，初始值 $x_0 = 0.0$。\n\n数值输出要求：你的程序必须为每种情况计算一个满足终止条件的近似根，然后将所有三个近似值以逗号分隔的列表形式，用方括号括起来，单行输出。每个近似值必须四舍五入到 $10$ 位小数。例如，你的输出格式必须严格符合\n$[r_1,r_2,r_3]$\n的形式，其中每个 $r_k$ 是一个小数点后恰有 $10$ 位数字的十进制数。\n\n你的程序不得读取任何输入。它必须严格按照指定格式生成一行输出，其中包含按上述顺序列出的三种情况的结果。", "solution": "该问题要求构造并应用一个不动点迭代格式 $x_{n+1} = g(x_n)$，该格式具有三阶（立方）收敛速度，用于寻找非线性方程 $f(x)=0$ 的一个单根 $\\alpha$。单根由条件 $f(\\alpha)=0$ 和 $f'(\\alpha) \\neq 0$ 定义。\n\n首先，我们必须推导迭代函数 $g(x)$。不动点法的收敛阶由迭代函数 $g(x)$ 在不动点 $\\alpha$ 处的导数决定。对于三阶收敛，我们要求 $g(\\alpha)=\\alpha$，并且它的一阶和二阶导数在根处为零，而三阶导数不为零：\n$$g'(\\alpha) = 0$$\n$$g''(\\alpha) = 0$$\n$$g'''(\\alpha) \\neq 0$$\n\n一个著名的高阶求根方法族是 Householder 方法。用于三阶收敛的方法通常被称为 Halley 方法。我们可以通过考虑 $f(x)$ 在当前迭代点 $x_n$ 附近的泰勒级数展开，并保留到二阶项来近似修正步长 $\\delta_n = x_{n+1} - x_n$，从而推导出其公式。\n根 $\\alpha$ 满足 $f(\\alpha)=0$。将 $f$ 在 $x_n$ 附近展开：\n$$f(\\alpha) = 0 \\approx f(x_n) + f'(x_n)(\\alpha - x_n) + \\frac{f''(x_n)}{2}(\\alpha - x_n)^2$$\n令 $\\delta = \\alpha - x_n$。该方程变为关于 $\\delta$ 的二次方程：\n$$f(x_n) + f'(x_n)\\delta + \\frac{f''(x_n)}{2}\\delta^2 \\approx 0$$\n为了获得 $\\delta$ 的一个更精确的近似值，我们可以将来自 Newton 方法的一阶近似 $\\delta \\approx -f(x_n)/f'(x_n)$ 代入二阶项中：\n$$f(x_n) + f'(x_n)\\delta + \\frac{f''(x_n)}{2} \\left( -\\frac{f(x_n)}{f'(x_n)} \\right)^2 \\approx 0$$\n求解 $\\delta$：\n$$f'(x_n)\\delta \\approx -f(x_n) - \\frac{f''(x_n) [f(x_n)]^2}{2 [f'(x_n)]^2}$$\n$$\\delta \\approx -\\frac{f(x_n)}{f'(x_n)} - \\frac{f''(x_n) [f(x_n)]^2}{2 [f'(x_n)]^3}$$\n这就产生了一个迭代公式。然而，一种更常见且数值上更稳定的形式，即 Halley 方法，是通过将泰勒展开式重写为 $\\delta$ 的近似式来推导的：\n$$f'(x_n)\\delta \\approx -f(x_n) - \\frac{f''(x_n)}{2}\\delta^2$$\n两边同除以 $f'(x_n)$ 得到 $\\delta \\approx -\\frac{f(x_n)}{f'(x_n)} - \\frac{f''(x_n)}{2f'(x_n)}\\delta^2$。这是一个关于 $\\delta$ 的隐式方程。对此方程的一种迭代方法是从 $\\delta_0=0$ 开始，计算 $\\delta_1 = -f(x_n)/f'(x_n)$，即 Newton 步长。然后 $\\delta_2 = \\frac{-f(x_n)}{f'(x_n) - \\frac{f''(x_n)}{2}\\delta_1}$。这是启发该结构的几种方式之一。\n\nHalley 迭代的标准形式是：\n$$x_{n+1} = x_n - \\frac{2 f(x_n) f'(x_n)}{2 [f'(x_n)]^2 - f(x_n) f''(x_n)}$$\n这定义了迭代函数 $g(x)$：\n$$g(x) = x - \\frac{2 f(x) f'(x)}{2 [f'(x)]^2 - f(x) f''(x)}$$\n通过对误差项 $\\epsilon_{n+1} = x_{n+1} - \\alpha$ 进行泰勒展开可以正式证明，该方法满足 $\\epsilon_{n+1} \\propto \\epsilon_n^3$，从而证实了它对于单根的三阶收敛性，前提是 $f$ 足够光滑（至少是 $C^3$）。\n\n求解每个函数根的算法如下：\n1.  用 $n=0$ 和给定的初始值 $x_0$ 初始化迭代。\n2.  对于 $n = 0, 1, 2, \\dots$ 直至最多 $49$ 次迭代：\n    a. 设当前迭代值为 $x_n$。\n    b. 计算 $f(x_n)$、$f'(x_n)$ 和 $f''(x_n)$。\n    c. 检查第一个终止条件：如果 $|f(x_n)| \\leq 10^{-12}$，则迭代成功。结果为 $x_n$。终止。\n    d. 计算修正项的分母：$D_n = 2 [f'(x_n)]^2 - f(x_n) f''(x_n)$。如果 $D_n$ 接近于零，方法可能会失败；然而，问题的假设排除了在单根附近出现这种情况。\n    e. 计算下一个迭代值：$x_{n+1} = x_n - \\frac{2 f(x_n) f'(x_n)}{D_n}$。\n    f. 检查第二个终止条件：如果 $|x_{n+1} - x_n| \\leq 10^{-12}$，则迭代成功。结果为 $x_{n+1}$。终止。\n    g. 设置 $x_n \\leftarrow x_{n+1}$ 以更新到下一次迭代。\n3.  如果循环在 $50$ 次迭代后（$n=49$ 是计算 $x_{50}$ 的最后一步）仍未满足任一终止条件，则过程停止。结果是最后计算出的迭代值 $x_{50}$。\n\n此过程被应用于问题陈述中指定的三个测试案例。最终的数值结果按要求四舍五入到 $10$ 位小数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and applies a cubically convergent fixed-point iteration scheme (Halley's method)\n    to find the roots of three specified nonlinear equations.\n    \"\"\"\n\n    def solve_with_halley(f, fp, fpp, x0, tol=1e-12, max_iter=50):\n        \"\"\"\n        Applies Halley's method to find a root of f(x)=0.\n\n        Args:\n            f: The function f(x).\n            fp: The first derivative f'(x).\n            fpp: The second derivative f''(x).\n            x0: The initial guess.\n            tol: The tolerance for termination.\n            max_iter: The maximum number of iterations.\n\n        Returns:\n            The approximate root.\n        \"\"\"\n        x_n = float(x0)\n\n        for _ in range(max_iter):\n            f_val = f(x_n)\n            \n            # Termination criterion 1: |f(x_n)| <= tol\n            if abs(f_val) <= tol:\n                return x_n\n\n            fp_val = fp(x_n)\n            fpp_val = fpp(x_n)\n\n            # Denominator of Halley's method correction term\n            denominator = 2.0 * fp_val**2 - f_val * fpp_val\n\n            # Prevent division by zero, though unlikely for these problems\n            if abs(denominator) < 1e-15:\n                # Method fails, return the last valid iterate\n                return x_n\n\n            # Halley's iteration formula\n            x_n_plus_1 = x_n - (2.0 * f_val * fp_val) / denominator\n\n            # Termination criterion 2: |x_{n+1} - x_n| <= tol\n            if abs(x_n_plus_1 - x_n) <= tol:\n                return x_n_plus_1\n\n            x_n = x_n_plus_1\n        \n        # Return the last iterate if max_iter is reached\n        return x_n\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"f\": lambda x: np.cos(x) - x,\n            \"fp\": lambda x: -np.sin(x) - 1.0,\n            \"fpp\": lambda x: -np.cos(x),\n            \"x0\": 0.5\n        },\n        {\n            \"f\": lambda x: x**3 - 2.0,\n            \"fp\": lambda x: 3.0 * x**2,\n            \"fpp\": lambda x: 6.0 * x,\n            \"x0\": 10.0\n        },\n        {\n            \"f\": lambda x: np.exp(x) - 3.0 * x,\n            \"fp\": lambda x: np.exp(x) - 3.0,\n            \"fpp\": lambda x: np.exp(x),\n            \"x0\": 0.0\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Main logic to calculate the result for one case goes here.\n        root = solve_with_halley(\n            f=case[\"f\"],\n            fp=case[\"fp\"],\n            fpp=case[\"fpp\"],\n            x0=case[\"x0\"],\n            tol=1e-12,\n            max_iter=50\n        )\n        results.append(root)\n\n    # Format results to 10 decimal places and create the final output string.\n    formatted_results = [f\"{r:.10f}\" for r in results]\n    final_output = f\"[{','.join(formatted_results)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```", "id": "2394865"}, {"introduction": "在实际应用中，我们有时不得不使用收敛较慢的线性收敛迭代。此时，我们该如何提升效率呢？本练习介绍了一种强大的“后处理”技术——艾特肯（Aitken）$\\Delta^2$ 加速法，它能在不改变原迭代过程的情况下，从生成的一系列近似解中推断出更精确的结果。通过这个练习，你将学会如何从理论上推导该方法，并用它来显著加速一个缓慢收敛的序列。[@problem_id:2394839]", "problem": "您的任务是构造并分析一个不动点迭代，该迭代收敛于2的自然对数（记为 $\\,\\ln(2)\\,$），然后使用 Aitken's delta-squared（记为 $\\Delta^2$）方法加速收敛。从方程 $\\,e^{x} = 2\\,$ 的不动点形式出发，这意味着映射 $\\,g(x)\\,$ 的一个不动点是期望值 $\\,x^\\star = \\ln(2)\\,$。考虑由 $\\,\\lambda\\,$ 参数化的一族不动点迭代，\n$$\ng_{\\lambda}(x) = x - \\lambda\\,(e^{x} - 2),\n$$\n以及迭代过程 $\\,x_{n+1} = g_{\\lambda}(x_n)\\,$，其中 $\\,n \\ge 0\\,$。假设在不动点 $\\,x^\\star\\,$ 附近，收敛条件（具体为 $\\,|g'_{\\lambda}(x^\\star)| < 1\\,$）成立，并利用这一点来证明线性误差行为，以此作为设计加速方法的起点。\n\n您的任务是：\n- 对于一个线性收敛序列 $\\,\\{s_n\\}\\,$，基于几何误差模型假设 $\\,s_n = s + C r^n\\,$（其中 $\\,|r|<1\\,$），推导 Aitken's delta-squared（$\\Delta^2$）加速公式。不要使用或引用任何预先推导出的加速公式；相反，应通过消除冗余参数，来获得一个用三个连续迭代项表示的显式加速估计量。明确说明该变换定义良好的条件。\n- 设计一个鲁棒的算法，该算法：\n  1. 为映射 $\\,g_{\\lambda}(x)\\,$ 生成不动点序列 $\\,\\{x_n\\}\\,$。\n  2. 使用您推导的 $\\Delta^2$ 表达式，根据最后三个可用的迭代值，构成一个加速估计。\n  3. 检测并安全地处理 $\\Delta^2$ 分母的绝对值趋近于零（例如，小于一个容差）的边缘情况，在这种情况下，您的算法必须返回最新的未加速迭代值作为加速输出。\n  4. 通过绝对误差 $\\,|x - \\ln(2)|\\,$ 来量化精度，该误差无单位。最终输出中的所有误差值必须四舍五入到小数点后恰好 $\\,12\\,$ 位。\n\n实现要求：\n- 您必须实现一个完整的、可运行的程序，对一个指定的测试套件执行上述步骤。不允许用户输入。\n- 对每个测试用例，迭代必须精确执行 $\\,N+2\\,$ 步，以便最后三个迭代值 $\\,x_N, x_{N+1}, x_{N+2}\\,$ 可用于构建对应于索引 $\\,N\\,$ 的单个 $\\Delta^2$ 加速估计。\n- 对每个测试用例，计算两个浮点数：\n  1. 使用 $\\,x_{N+2}\\,$ 的未加速估计的绝对误差。\n  2. 由 $\\,x_{N}, x_{N+1}, x_{N+2}\\,$ 构建的 $\\Delta^2$ 加速估计的绝对误差。\n- 最终输出格式：您的程序应生成单行输出，其中包含一个扁平列表中的所有结果，形式为方括号内由逗号分隔的列表。各项必须严格按以下顺序出现\n  $$[E_{1,\\mathrm{plain}},E_{1,\\mathrm{acc}},E_{2,\\mathrm{plain}},E_{2,\\mathrm{acc}},E_{3,\\mathrm{plain}},E_{3,\\mathrm{acc}},E_{4,\\mathrm{plain}},E_{4,\\mathrm{acc}}],$$\n  其中 $\\,E_{i,\\mathrm{plain}}\\,$ 是测试 $\\,i\\,$ 的未加速绝对误差，$\\,E_{i,\\mathrm{acc}}\\,$ 是其加速绝对误差。每个条目必须四舍五入到小数点后恰好 $\\,12\\,$ 位。\n\n测试套件：\n- 使用 $\\,\\ln(2)\\,$ 作为参考值，由自然对数函数计算得出（以弧度为单位）。\n- 使用以下 （$\\lambda, x_0, N$） 三元组：\n  1. （$\\,0.05,\\; 0.0,\\; 50\\,$）\n  2. （$\\,0.01,\\; 0.0,\\; 200\\,$）\n  3. （$\\,0.49,\\; 0.0,\\; 10\\,$）\n  4. （$\\,0.99,\\; 0.0,\\; 200\\,$）\n\n科学和数值考虑：\n- 从不动点收敛条件 $\\,|g'_{\\lambda}(x^\\star)|<1\\,$ 出发，证明线性收敛性并引出几何误差模型，然后通过消除未知数从第一性原理推导加速规则。\n- 本问题不涉及物理单位。由于自然对数和指数函数的定义，所有涉及的角度（如果相关）都以弧度为单位。\n- 通过为 $\\Delta^2$ 分母检查引入一个小的正容差 $\\,\\tau\\,$（例如，可接受值为 $\\,\\tau = 10^{-14}\\,$）来确保您的算法具有数值稳定性。\n\n您的最终程序必须计算并以以上描述的精确格式打印所需的单行输出。", "solution": "经审阅，该问题是迭代法数值分析中的一个标准练习。它有效、自洽，并存在唯一、明确的求解路径。我们将着手进行所需的推导和算法构建。\n\n问题是求解方程 $f(x) = e^x - 2 = 0$ 的根，即 $x^\\star = \\ln(2)$。我们给定了一个不动点映射族，\n$$\ng_{\\lambda}(x) = x - \\lambda(e^x - 2)\n$$\n迭代序列定义为 $x_{n+1} = g_{\\lambda}(x_n)$，其中 $n \\ge 0$。此映射的不动点 $x^\\star$ 满足 $x^\\star = g_{\\lambda}(x^\\star)$，这意味着 $x^\\star = x^\\star - \\lambda(e^{x^\\star} - 2)$，因此 $e^{x^\\star} - 2 = 0$。确实，当 $\\lambda \\neq 0$ 时，$g_{\\lambda}(x)$ 的不动点就是 $f(x)$ 的根。\n\n为使迭代收敛到不动点 $x^\\star$，映射 $g_{\\lambda}(x)$ 必须在 $x^\\star$ 的一个邻域内是压缩映射。收敛条件由压缩映射定理给出，要求 $|g'_{\\lambda}(x^\\star)| < 1$。$g_{\\lambda}(x)$ 的导数是：\n$$\ng'_{\\lambda}(x) = \\frac{d}{dx} \\left( x - \\lambda(e^x - 2) \\right) = 1 - \\lambda e^x\n$$\n在不动点 $x^\\star = \\ln(2)$ 处计算该导数：\n$$\ng'_{\\lambda}(x^\\star) = 1 - \\lambda e^{\\ln(2)} = 1 - 2\\lambda\n$$\n因此，收敛条件为 $|1 - 2\\lambda| < 1$。该不等式等价于 $-1 < 1 - 2\\lambda < 1$，可简化为 $-2 < -2\\lambda < 0$。两边同除以 $-2$ 并反转不等号，得到 $0 < \\lambda < 1$。所有提供的测试用例都使用此范围内的 $\\lambda$ 值，从而保证了收敛性。\n\n当 $g'_{\\lambda}(x^\\star) \\neq 0$ 时，收敛是线性的。步 $n+1$ 的误差 $e_{n+1} = x_{n+1} - x^\\star$ 与步 $n$ 的误差 $e_n = x_n - x^\\star$ 通过 $g_{\\lambda}(x_n)$ 在 $x^\\star$ 附近的泰勒展开相关联：\n$$\nx_{n+1} = g_{\\lambda}(x_n) \\approx g_{\\lambda}(x^\\star) + g'_{\\lambda}(x^\\star)(x_n - x^\\star)\n$$\n$$\nx_{n+1} - x^\\star \\approx g'_{\\lambda}(x^\\star)(x_n - x^\\star) \\implies e_{n+1} \\approx r \\cdot e_n\n$$\n其中 $r = g'_{\\lambda}(x^\\star) = 1 - 2\\lambda$ 是渐近收敛率。该关系意味着对于大的 $n$，误差呈几何级数行为：$e_n \\approx C r^n$（其中 $C$ 为某个常数）。这证明了将几何误差模型作为 Aitken's $\\Delta^2$ 方法基础的合理性。\n\n我们现在推导 Aitken's $\\Delta^2$ 加速公式。设 $\\{s_n\\}$ 是一个收敛到极限 $s$ 的序列。对于大的 $n$，我们将该序列建模为：\n$$\ns_n = s + C r^n, \\quad |r|<1\n$$\n我们为三个连续项 $s_n$、$s_{n+1}$ 和 $s_{n+2}$ 写出此模型：\n$$\ns_n - s = C r^n \\quad (1)\n$$\n$$\ns_{n+1} - s = C r^{n+1} \\quad (2)\n$$\n$$\ns_{n+2} - s = C r^{n+2} \\quad (3)\n$$\n我们的目标是消除未知参数 $C$ 和 $r$，以求得 $s$ 的一个改进估计。我们引入前向差分算子 $\\Delta s_k = s_{k+1} - s_k$。\n$$\n\\Delta s_n = s_{n+1} - s_n = (s_{n+1} - s) - (s_n - s) = C r^{n+1} - C r^n = C r^n (r - 1)\n$$\n$$\n\\Delta s_{n+1} = s_{n+2} - s_{n+1} = (s_{n+2} - s) - (s_{n+1} - s) = C r^{n+2} - C r^{n+1} = C r^{n+1} (r - 1)\n$$\n将这些差分相除可以消除 $C$：\n$$\n\\frac{\\Delta s_{n+1}}{\\Delta s_n} = \\frac{C r^{n+1} (r - 1)}{C r^n (r - 1)} = r\n$$\n这就提供了一个对收敛率 $r$ 的估计。现在，根据方程 $(1)$ 和 $(2)$，我们有 $s_{n+1} - s = r(s_n - s)$。代入我们对 $r$ 的表达式：\n$$\ns_{n+1} - s = \\left(\\frac{s_{n+2} - s_{n+1}}{s_{n+1} - s_n}\\right) (s_n - s)\n$$\n这是一个关于未知极限 $s$ 的方程。我们来解出 $s$：\n$$\n(s_{n+1} - s)(s_{n+1} - s_n) = (s_{n+2} - s_{n+1})(s_n - s)\n$$\n$$\ns_{n+1}(s_{n+1} - s_n) - s(s_{n+1} - s_n) = s_n(s_{n+2} - s_{n+1}) - s(s_{n+2} - s_{n+1})\n$$\n$$\ns \\left( (s_{n+2} - s_{n+1}) - (s_{n+1} - s_n) \\right) = s_n(s_{n+2} - s_{n+1}) - s_{n+1}(s_{n+1} - s_n)\n$$\n$$\ns (s_{n+2} - 2s_{n+1} + s_n) = s_n s_{n+2} - s_n s_{n+1} - s_{n+1}^2 + s_n s_{n+1} = s_n s_{n+2} - s_{n+1}^2\n$$\n在分母非零的情况下，$s$ 的加速估计为：\n$$\ns = \\frac{s_n s_{n+2} - s_{n+1}^2}{s_{n+2} - 2s_{n+1} + s_n}\n$$\n如果 $s_n$ 很大，这个公式容易出现相消误差。通过将其重写为以下形式，可以得到一个数值上更鲁棒的形式：\n$$\ns = s_n - \\frac{(s_{n+1} - s_n)^2}{s_{n+2} - 2s_{n+1} + s_n} = s_n - \\frac{(\\Delta s_n)^2}{\\Delta^2 s_n}\n$$\n其中 $\\Delta^2 s_n = \\Delta(\\Delta s_n) = \\Delta s_{n+1} - \\Delta s_n$ 是二阶前向差分。这就是 Aitken's $\\Delta^2$ 公式。我们将此公式应用于序列 $\\{x_n\\}$，方法是令 $s_k = x_k$。我们记为 $x'_{N}$ 的加速估计由迭代值 $x_N$、$x_{N+1}$ 和 $x_{N+2}$ 构成：\n$$\nx'_{N} = x_N - \\frac{(x_{N+1} - x_N)^2}{x_{N+2} - 2x_{N+1} + x_N}\n$$\n该表达式有明确定义的充要条件是分母 $x_{N+2} - 2x_{N+1} + x_N \\neq 0$。在浮点运算中，我们必须检查分母的绝对值是否小于某个容差 $\\tau > 0$，例如 $\\tau = 10^{-14}$。如果 $|x_{N+2} - 2x_{N+1} + x_N| < \\tau$，则该变换在数值上不稳定或未明确定义，我们应返回最新的未加速迭代值 $x_{N+2}$ 作为结果。\n\n算法如下：\n对于每个给定的测试用例 $(\\lambda, x_0, N)$：\n1. 设定固定参考值 $x^\\star = \\ln(2)$。\n2. 用 $x_0$ 初始化迭代序列。\n3. 使用映射 $x_{n+1} = x_n - \\lambda(e^{x_n} - 2)$ 生成后续的 $N+2$ 个迭代值 $x_1, \\dots, x_{N+2}$。存储所有迭代值直到 $x_{N+2}$。\n4. 计算未加速的绝对误差：$E_{\\mathrm{plain}} = |x_{N+2} - x^\\star|$。\n5. 检索加速所需的最后三个迭代值：$x_N, x_{N+1}, x_{N+2}$。\n6. 计算 Aitken 公式的分母：$d = x_{N+2} - 2x_{N+1} + x_N$。\n7. 如果 $|d| < 10^{-14}$，则将加速估计值设为 $x_{\\mathrm{acc}} = x_{N+2}$。\n8. 否则，计算加速估计值 $x_{\\mathrm{acc}} = x_N - (x_{N+1} - x_N)^2 / d$。\n9. 计算加速的绝对误差：$E_{\\mathrm{acc}} = |x_{\\mathrm{acc}} - x^\\star|$。\n10. 将两个误差值 $E_{\\mathrm{plain}}$ 和 $E_{\\mathrm{acc}}$ 四舍五入到小数点后 $12$ 位并存储它们。\n最后，将所有测试用例计算出的所有误差值汇编成一个单一的扁平列表，并以指定格式打印。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs and analyzes a fixed-point iteration for ln(2), accelerates it\n    using Aitken's delta-squared method, and computes the errors for a suite\n    of test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (lambda, x0, N)\n        (0.05, 0.0, 50),\n        (0.01, 0.0, 200),\n        (0.49, 0.0, 10),\n        (0.99, 0.0, 200),\n    ]\n\n    # The exact value of the fixed point, ln(2)\n    x_star = np.log(2)\n    \n    # Tolerance for the denominator in Aitken's formula\n    tau = 1.0e-14\n\n    results = []\n    \n    for case in test_cases:\n        lambda_val, x0, N = case\n        \n        # 1. Generate the fixed-point sequence {x_n}\n        # We need N+3 points in the sequence (x_0, x_1, ..., x_{N+2})\n        # This requires N+2 iteration steps.\n        iterates = [x0]\n        current_x = x0\n        for _ in range(N + 2):\n            # Fixed-point iteration: x_{n+1} = g(x_n) = x_n - lambda * (exp(x_n) - 2)\n            current_x = current_x - lambda_val * (np.exp(current_x) - 2)\n            iterates.append(current_x)\n            \n        # The last three iterates for acceleration are x_N, x_{N+1}, x_{N+2}\n        x_N = iterates[N]\n        x_N_plus_1 = iterates[N + 1]\n        x_N_plus_2 = iterates[N + 2]\n        \n        # 2. Compute the absolute error of the unaccelerated estimate\n        # The latest unaccelerated estimate is x_{N+2}\n        error_plain = abs(x_N_plus_2 - x_star)\n        \n        # 3. Form the accelerated estimate using Aitken's delta-squared method\n        denominator = x_N_plus_2 - 2 * x_N_plus_1 + x_N\n        \n        # 4. Detect and handle the edge case of a small denominator\n        if abs(denominator) < tau:\n            # If denominator is too small, use the unaccelerated estimate\n            x_accelerated = x_N_plus_2\n        else:\n            numerator = (x_N_plus_1 - x_N)**2\n            x_accelerated = x_N - numerator / denominator\n            \n        # 5. Compute the absolute error of the accelerated estimate\n        error_accelerated = abs(x_accelerated - x_star)\n        \n        # 6. Format results to exactly 12 decimal places\n        results.append(f\"{error_plain:.12f}\")\n        results.append(f\"{error_accelerated:.12f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2394839"}]}