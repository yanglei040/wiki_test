{"hands_on_practices": [{"introduction": "我们的实践之旅始于计算博弈论的基石：混合策略纳什均衡。在许多战略互动中，确定性的行动（纯策略）无法形成稳定的均衡，因为参与者总有动机偏离。这个练习将引导你通过一个关于科研策略选择的直观场景，亲手计算出使得对手在不同选择间保持无差异的概率，从而揭示在不确定性下的理性决策是如何形成的。[@problem_id:2381493]", "id": "2381493", "problem": "考虑一个两名（$2$）科学家之间的静态、同时行动博弈。每位科学家选择两种行动之一：安全（$S$）或冒险（$R$）。收益以科研积分单位来衡量。环境如下。\n\n- 如果一位科学家选择 $S$，无论另一位科学家的选择如何，他都将获得 $s = 3$ 的保证收益。\n- 如果恰好一名科学家选择 $R$ 而另一名选择 $S$，选择 $R$ 的科学家有 $\\theta = 0.12$ 的成功概率实现一项价值为 $B = 30$ 的重大突破。如果突破发生，选择 $R$ 的科学家获得 $B$；否则获得 $0$。选择 $S$ 的科学家仍然获得 $s$。\n- 如果两名科学家都选择 $R$，则在此期间最多只有一项突破。当两人都选择 $R$ 时，发生突破的概率为 $\\varphi = 0.18$。如果发生突破，恰好其中一名科学家会因此获得声誉，由于对称性，每人的概率均等。获得声誉的科学家得到 $B$，另一人得到 $0$。如果没有发生突破，两人都得到 $0$。\n\n假设收益和概率是共同知识，并且两名科学家都是期望收益最大化者。令 $p^{*}$ 表示在此博弈中，每位科学家选择 $R$ 的对称混合策略纳什均衡（NE）概率。\n\n求 $p^{*}$ 的值。请以精确形式（例如，最简分数）给出答案。不要包含单位。", "solution": "对问题陈述进行验证。\n\n步骤 1：提取已知条件。\n- 参与者（科学家）数量：$2$。\n- 参与者行动：安全（$S$），冒险（$R$）。\n- 行动 $S$ 的收益：保证为 $s = 3$。\n- 行动组合 $(R,S)$ 的结果：选择 $R$ 的科学家有 $\\theta = 0.12$ 的成功概率实现一项价值为 $B = 30$ 的突破。成功时收益为 $B$，失败时为 $0$。选择 $S$ 的科学家获得 $s$。\n- 行动组合 $(R,R)$ 的结果：一次突破的总概率为 $\\varphi = 0.18$。如果发生突破，一名科学家以 $0.5$ 的概率获得声誉并得到 $B = 30$。另一人得到 $0$。如果没有突破，两人都得到 $0$。\n- 假设：参与者是期望收益最大化者，博弈结构是共同知识。\n- 目标：求解对称混合策略纳什均衡（NE）概率 $p^{*}$，即科学家选择行动 $R$ 的概率。\n\n步骤 2：使用提取的已知条件进行验证。\n- 该问题具有科学依据。这是博弈论的一个标准应用，特别是在一个完全信息的静态博弈中计算纳什均衡。期望收益最大化和混合策略的概念是该领域的基础。\n- 该问题是适定的。它提供了定义收益结构所需的所有必要参数（$s$、$\\theta$、$B$、$\\varphi$），并要求计算一个具体的可计算量（$p^{*}$）。在有限博弈中，混合策略纳什均衡的存在性由 Nash 定理保证。\n- 该问题是客观的。所有术语都经过了数学上的精确定义。没有主观或含糊的陈述。\n- 该问题的设定是自洽且一致的。所提供的数据中不存在矛盾。\n\n步骤 3：结论和行动。\n此问题被认定为有效。将提供完整解答。\n\n为了确定对称混合策略纳什均衡，我们必须首先构建这个两人博弈的收益矩阵。设参与者为科学家 $1$ 和科学家 $2$。行动为 $S$（安全）和 $R$（冒险）。收益矩阵的条目 $(u_1, u_2)$ 分别代表科学家 $1$ 和科学家 $2$ 的期望收益。\n\n1.  行动组合 $(S, S)$：两名科学家都选择安全。\n    根据问题描述，如果一名科学家选择 $S$，他将获得 $s=3$ 的保证收益。\n    因此，$u_1(S, S) = 3$ 且 $u_2(S, S) = 3$。收益对为 $(3, 3)$。\n\n2.  行动组合 $(R, S)$：科学家 $1$ 选择冒险，科学家 $2$ 选择安全。\n    - 科学家 $1$（$R$）有 $\\theta = 0.12$ 的成功概率实现价值为 $B = 30$ 的突破。其期望收益为 $E[u_1(R, S)] = \\theta \\times B + (1 - \\theta) \\times 0 = 0.12 \\times 30 = 3.6$。\n    - 科学家 $2$（$S$）获得保证收益 $s = 3$。\n    收益对为 $(3.6, 3)$。\n\n3.  行动组合 $(S, R)$：科学家 $1$ 选择安全，科学家 $2$ 选择冒险。\n    - 根据与 $(R, S)$ 情况的对称性，科学家 $1$（$S$）获得 $s = 3$。\n    - 科学家 $2$（$R$）的期望收益为 $E[u_2(S, R)] = \\theta \\times B = 3.6$。\n    收益对为 $(3, 3.6)$。\n\n4.  行动组合 $(R, R)$：两名科学家都选择冒险。\n    - 单一突破发生的总概率为 $\\varphi = 0.18$。如果发生，每位科学家有 $0.5$ 的概率获得声誉。\n    - 科学家 $1$ 获得突破声誉的概率为 $0.5 \\times \\varphi = 0.5 \\times 0.18 = 0.09$。\n    - 科学家 $1$ 的期望收益为 $E[u_1(R, R)] = (0.5 \\times \\varphi) \\times B + (1 - 0.5 \\times \\varphi) \\times 0 = 0.09 \\times 30 = 2.7$。\n    - 根据对称性，科学家 $2$ 的期望收益相同：$E[u_2(R, R)] = 2.7$。\n    收益对为 $(2.7, 2.7)$。\n\n该博弈的范式表述由以下收益矩阵给出，其中科学家 $1$ 是行参与者，科学家 $2$ 是列参与者：\n$$\n\\begin{array}{c|cc}\n & S & R \\\\\n\\hline\nS & (3, 3) & (3, 3.6) \\\\\nR & (3.6, 3) & (2.7, 2.7) \\\\\n\\end{array}\n$$\n\n问题要求解对称混合策略纳什均衡，其中每位科学家以概率 $p^{*}$ 选择 $R$，以概率 $1 - p^{*}$ 选择 $S$。在混合策略均衡中，参与者在进行随机选择的纯策略之间必须是无差异的。\n\n让我们考虑科学家 $1$。假设科学家 $2$ 以概率 $p^{*}$ 选择 $R$，以概率 $1 - p^{*}$ 选择 $S$。为了使科学家 $1$ 愿意在 $S$ 和 $R$ 之间进行混合，选择 $S$ 的期望收益必须等于选择 $R$ 的期望收益。\n\n科学家 $1$ 选择 $S$ 的期望收益为：\n$E[u_1(S)] = p^{*} \\cdot u_1(S, R) + (1 - p^{*}) \\cdot u_1(S, S) = p^{*} \\cdot 3 + (1 - p^{*}) \\cdot 3 = 3$。\n这与问题所述的选择 $S$ 的保证收益 $s=3$ 一致。\n\n科学家 $1$ 选择 $R$ 的期望收益为：\n$E[u_1(R)] = p^{*} \\cdot u_1(R, R) + (1 - p^{*}) \\cdot u_1(R, S) = p^{*} \\cdot (2.7) + (1 - p^{*}) \\cdot (3.6)$。\n\n令期望收益相等，定义了无差异条件：\n$E[u_1(S)] = E[u_1(R)]$\n$$3 = 2.7 p^{*} + 3.6(1 - p^{*})$$\n$$3 = 2.7 p^{*} + 3.6 - 3.6 p^{*}$$\n$$3 - 3.6 = 2.7 p^{*} - 3.6 p^{*}$$\n$$-0.6 = -0.9 p^{*}$$\n$$p^{*} = \\frac{0.6}{0.9} = \\frac{6}{9}$$\n将分数化简为最简形式，得到：\n$$p^{*} = \\frac{2}{3}$$\n由于博弈是对称的，对科学家 $2$ 进行同样的计算会得到相同的均衡概率。因此，在对称混合策略纳什均衡中，每位科学家以概率 $p^{*} = \\frac{2}{3}$ 选择冒险行动。", "answer": "$$\n\\boxed{\\frac{2}{3}}\n$$"}, {"introduction": "在掌握了双人博弈的基本分析后，我们将视野扩大到由大量个体组成的“人口博弈”。这类博弈对于理解技术采纳、社会规范形成等宏观现象至关重要。通过分析一个关于农民选择生产技术的模型，你将学会如何确定系统可能存在的多个稳定状态（均衡），并计算出引导整个群体转向更优结果所需的最小政策干预（补贴）。[@problem_id:2381176]", "id": "2381176", "problem": "一个由总数为单位1的相同农民组成的连续体，在两种生产技术之间进行选择：一种是可持续的高产技术，表示为策略 $S$；另一种是常规的低产技术，表示为策略 $C$。设 $x \\in [0,1]$ 表示采纳 $S$ 的人口比例。当人口比例为 $x$ 时，一位采纳 $S$ 的农民的每期收益为\n$$\n\\pi_{S}(x) \\;=\\; Y_{H} \\;-\\; c \\;+\\; b\\,x \\;+\\; s,\n$$\n而一位采纳 $C$ 的农民的每期收益为\n$$\n\\pi_{C}(x) \\;=\\; Y_{L} \\;+\\; a\\,(1 - x).\n$$\n此处，$Y_{H} > Y_{L}$ 是两种技术的基准产量，$c > 0$ 是 $S$ 的私人采纳成本，$a > 0$ 和 $b > 0$ 反映了技术特定的策略互补性，$s \\ge 0$ 是仅支付给 $S$ 采纳者的每位农民补贴。假设在 $s = 0$ 时，该博弈表现出协调激励，即\n$$\n\\left(Y_{H} - Y_{L}\\right) - c - a \\;<\\; 0 \\;<\\; \\left(Y_{H} - Y_{L}\\right) - c + b.\n$$\n\n考虑在 $[0,1]$ 上由这些收益函数诱导的对称种群博弈。设对称纳什均衡 (NE) 为任何 $x^{\\ast} \\in [0,1]$，使得在给定 $x^{\\ast}$ 的情况下，没有农民可以通过单方面改变策略来增加其收益。\n\n确定最小阈值补贴 $s_{\\mathrm{bar}}$（以原始参数 $Y_{H}$、$Y_{L}$、$c$、$a$、$b$ 的闭式解析表达式表示），使得对于任何 $s > s_{\\mathrm{bar}}$，诱导的博弈都有唯一的对称纳什均衡 $x^{\\ast} = 1$（所有农民都采纳 $S$）。您的最终答案必须是单个闭式表达式。不需要数值近似。", "solution": "首先验证问题。给定条件如下：\n- 策略 $S$ 的收益：$\\pi_{S}(x) = Y_{H} - c + b x + s$\n- 策略 $C$ 的收益：$\\pi_{C}(x) = Y_{L} + a(1 - x)$\n- 参数：$Y_{H} > Y_{L}$，$c > 0$，$a > 0$，$b > 0$，$s \\ge 0$。\n- 采纳 $S$ 的人口比例：$x \\in [0, 1]$。\n- $s=0$ 时的条件：$(Y_{H} - Y_{L}) - c - a < 0 < (Y_{H} - Y_{L}) - c + b$。\n\n这个问题是计算博弈论中一个适定性问题，具体涉及技术采纳动态。它具有科学依据，是自洽的，且没有歧义。因此，可以推导出解决方案。\n\n对称纳什均衡 (NE) 是指在 $[0, 1]$ 上的一个种群份额 $x^{\\ast}$，在此份额下，没有单个农民有单方面改变策略的动机。三种可能的对称纳什均衡类型的条件是：\n1.  角点均衡 $x^{\\ast} = 0$，即所有农民都选择策略 $C$。如果单个农民转向 $S$ 不会获得更高的收益，即 $\\pi_{S}(0) \\le \\pi_{C}(0)$，那么这就是一个纳什均衡。\n2.  角点均衡 $x^{\\ast} = 1$，即所有农民都选择策略 $S$。如果单个农民转向 $C$ 不会获得更高的收益，即 $\\pi_{C}(1) \\le \\pi_{S}(1)$，那么这就是一个纳什均衡。\n3.  内部均衡 $x^{\\ast} \\in (0, 1)$，即比例为 $x^{\\ast}$ 的农民选择 $S$，比例为 $1-x^{\\ast}$ 的农民选择 $C$。这要求农民对两种策略无差异，因此他们的收益必须相等：$\\pi_{S}(x^{\\ast}) = \\pi_{C}(x^{\\ast})$。\n\n为了系统地分析这些条件，我们定义收益差函数 $\\Delta\\pi(x) = \\pi_{S}(x) - \\pi_{C}(x)$。\n$$\n\\Delta\\pi(x) = (Y_{H} - c + bx + s) - (Y_{L} + a(1 - x))\n$$\n$$\n\\Delta\\pi(x) = (Y_{H} - Y_{L} - c - a + s) + (a + b)x\n$$\n由于 $a > 0$ 和 $b > 0$，和 $a+b$ 严格为正。因此，$\\Delta\\pi(x)$ 是 $x$ 的一个严格递增线性函数。\n\n纳什均衡条件可以用 $\\Delta\\pi(x)$ 表示：\n- $x^{\\ast} = 0$ 是纳什均衡当且仅当 $\\Delta\\pi(0) \\le 0$。\n- $x^{\\ast} = 1$ 是纳什均衡当且仅当 $\\Delta\\pi(1) \\ge 0$。\n- 内部纳什均衡 $x^{\\ast} \\in (0, 1)$ 存在，当且仅当 $\\Delta\\pi(x^{\\ast}) = 0$。因为 $\\Delta\\pi(x)$ 是单调的，所以如果这样的 $x^{\\ast}$ 存在，它就是唯一的。其在 $(0, 1)$ 内存在的条件是 $\\Delta\\pi(0)$ 和 $\\Delta\\pi(1)$ 符号相反，具体来说是 $\\Delta\\pi(0) < 0$ 且 $\\Delta\\pi(1) > 0$。\n\n目标是找到最小补贴 $s_{\\mathrm{bar}}$，使得对于任何 $s > s_{\\mathrm{bar}}$，唯一的对称纳什均衡是 $x^{\\ast}=1$。\n为了使 $x^{\\ast}=1$ 成为唯一的纳什均衡，无论人口比例 $x$ 如何，策略 $S$ 都必须优于策略 $C$。这意味着对于所有的 $x \\in [0, 1]$，都有 $\\pi_{S}(x) > \\pi_{C}(x)$，或者等价地，对于所有的 $x \\in [0, 1]$，都有 $\\Delta\\pi(x) > 0$。\n由于 $\\Delta\\pi(x)$ 是 $x$ 的严格递增函数，这个条件成立当且仅当该函数在区间 $[0, 1]$ 上的最小值（出现在 $x=0$ 处）为正。\n因此，$x^{\\ast}=1$ 成为唯一纳什均衡的条件是 $\\Delta\\pi(0) > 0$。\n\n让我们计算 $\\Delta\\pi(0)$：\n$$\n\\Delta\\pi(0) = (Y_{H} - Y_{L} - c - a + s)\n$$\n$x^{\\ast}=1$ 均衡唯一性的条件变为：\n$$\nY_{H} - Y_{L} - c - a + s > 0\n$$\n对补贴 $s$ 求解这个不等式：\n$$\ns > a + c - (Y_{H} - Y_{L})\n$$\n这个不等式定义了使 $x^{\\ast}=1$ 成为唯一纳什均衡的所有补贴 $s$ 的值。问题要求的是最小阈值补贴 $s_{\\mathrm{bar}}$，使得对于任何 $s > s_{\\mathrm{bar}}$，这种唯一性都成立。这个阈值是不等式的下界。\n$$\ns_{\\mathrm{bar}} = a + c - (Y_{H} - Y_{L})\n$$\n我们必须验证这一分析是否与问题的假设一致。对于 $s=0$ 的初始条件，即 $(Y_{H} - Y_{L}) - c - a < 0$，意味着 $a + c - (Y_{H} - Y_{L}) > 0$。这证实了 $s_{\\mathrm{bar}}$ 是一个正值补贴，这在经济上是合理的。对于任何 $s > s_{\\mathrm{bar}}$，都有 $\\Delta\\pi(0) > 0$。由于 $\\Delta\\pi(x)$ 是递增的，因此对于所有 $x \\in [0, 1]$，都有 $\\Delta\\pi(x) > 0$。\n这意味着：\n- $x^{\\ast}=0$ 不是一个纳什均衡，因为 $\\Delta\\pi(0) > 0$。\n- 不存在内部纳什均衡，因为 $\\Delta\\pi(x)$ 在 $[0, 1]$ 上永远不为零。\n- $x^{\\ast}=1$ 是一个纳什均衡，因为 $\\Delta\\pi(1) > \\Delta\\pi(0) > 0$。\n\n因此，对于任何 $s > s_{\\mathrm{bar}}$，唯一存在的纳什均衡是 $x^{\\ast} = 1$。最小的此类阈值恰好是这个值 $s_{\\mathrm{bar}}$。\n该表达式可以写为 $a + c + Y_L - Y_H$。", "answer": "$$\n\\boxed{a + c - (Y_{H} - Y_{L})}\n$$"}, {"introduction": "最后，我们将探索计算博弈论中一个更强大且更贴近现实应用的概念——相关均衡（Correlated Equilibrium），它允许参与者通过一个共同的信号来协调行动。这个练习将挑战你为一个城市交通网络构建一个博弈模型，并将其转化为一个线性规划问题来求解。你将学习如何利用优化工具找到最大化社会总福利的相关均衡，这集中体现了将理论博弈模型与现代计算方法相结合的强大威力。[@problem_id:2381200]", "id": "2381200", "problem": "考虑一个有限标准型协调博弈，该博弈为一个正交城市网络中的信号交叉口网格建模。交叉口位于一个有 $R$ 行和 $C$ 列的矩形网格上，因此共有 $N = R \\times C$ 个参与者。每个参与者 $i \\in \\{0,1,\\dots,N-1\\}$ 对应一个交叉口，并选择两种信号相位（行动）之一 $a_i \\in \\{0,1\\}$。其中，$a_i = 0$ 表示南北向入口获得绿灯相位，$a_i = 1$ 表示东西向入口获得绿灯相位。相邻交叉口之间的每个无向路段都承载着一个外生的、非负的需求。对于连接 $(r,c)$ 和 $(r+1,c)$ 的每个垂直路段，其需求由 $V[r,c] \\ge 0$ 给出。对于连接 $(r,c)$ 和 $(r,c+1)$ 的每个水平路段，其需求由 $H[r,c] \\ge 0$ 给出。对于一个固定的标量参数 $\\alpha \\in [0,1]$，一个路段对其端点交叉口的实际贡献取决于两个邻接的交叉口是否调整其相位以一致服务于该路段。具体而言，对于一个位于网格坐标 $(r,c)$、行动为 $a_i$ 的交叉口 $i$ 以及一个通过需求为 $d \\ge 0$ 的路段相连的邻近交叉口 $j$：\n- 如果路段是垂直的且 $a_i = 0$，那么当 $a_j = 0$ 时，该路段对交叉口 $i$ 收益的贡献等于 $d$；当 $a_j = 1$ 时，贡献等于 $\\alpha \\cdot d$。如果 $a_i = 1$，则该垂直路段的贡献为 $0$。\n- 如果路段是水平的且 $a_i = 1$，那么当 $a_j = 1$ 时，该路段对交叉口 $i$ 收益的贡献等于 $d$；当 $a_j = 0$ 时，贡献等于 $\\alpha \\cdot d$。如果 $a_i = 0$，则该水平路段的贡献为 $0$。\n\n在行动组合 $a = (a_0,\\dots,a_{N-1})$ 下，参与者 $i$ 的收益函数 $u_i(a)$ 是根据上述规则，所有与 $i$ 邻接的路段贡献的总和。行动组合 $a$ 的社会福利定义为 $W(a) = \\sum_{i=0}^{N-1} u_i(a)$。\n\n相关均衡（CE）是一个满足激励相容性的行动组合上的概率分布 $p$。根据 Robert Aumann 引入的相关均衡定义，如果对于每个参与者 $i$ 和每对行动 $s,t \\in \\{0,1\\}$，都满足以下条件，则 $p$ 是一个相关均衡：\n$$\n\\sum_{a_{-i}} p(s,a_{-i}) \\big( u_i(s,a_{-i}) - u_i(t,a_{-i}) \\big) \\ge 0,\n$$\n其中 $a_{-i}$ 表示除参与者 $i$ 之外所有其他参与者的行动。\n\n您的任务是构建并求解一个线性规划，以计算一个相关均衡 $p$，该均衡在满足相关均衡约束、单纯形约束（对所有 $a$ 有 $p(a) \\ge 0$ 和 $\\sum_a p(a) = 1$）以及上述模型特定收益结构的条件下，最大化期望社会福利 $\\mathbb{E}_p[W(a)] = \\sum_{a} p(a) W(a)$。\n\n实现一个程序，该程序：\n- 枚举所有行动组合 $a \\in \\{0,1\\}^N$。\n- 根据上述原始定义，为每个参与者 $i$ 和每个行动组合 $a$ 计算 $u_i(a)$，不使用任何预设均衡属性的简化公式。\n- 构建一个以每个行动组合 $a$ 的 $p(a)$ 为变量的线性规划，以在相关均衡约束下最大化期望社会福利。\n- 对线性规划进行数值求解。\n- 对于每个指定的测试用例，返回最优期望社会福利 $\\max_{p \\in \\text{CE}} \\mathbb{E}_p[W(a)]$，结果为浮点数并四舍五入到 $6$ 位小数。\n\n测试套件。您的程序必须按顺序为以下每个参数集计算结果：\n- 案例 A: $R = 2$, $C = 2$, $\\alpha = 0.4$.\n  - 垂直需求 $V$ 形状为 $(R-1) \\times C = (1) \\times 2$: $V[0,0] = 3.0$, $V[0,1] = 2.0$。\n  - 水平需求 $H$ 形状为 $R \\times (C-1) = 2 \\times (1)$: $H[0,0] = 1.0$, $H[1,0] = 1.5$。\n- 案例 B: $R = 3$, $C = 2$, $\\alpha = 0.7$.\n  - 垂直需求 $V$ 形状为 $(R-1) \\times C = (2) \\times 2$: $V[0,0] = 1.0$, $V[0,1] = 4.0$, $V[1,0] = 2.0$, $V[1,1] = 3.0$。\n  - 水平需求 $H$ 形状为 $R \\times (C-1) = 3 \\times (1)$: $H[0,0] = 5.0$, $H[1,0] = 2.0$, $H[2,0] = 3.0$。\n- 案例 C: $R = 2$, $C = 3$, $\\alpha = 1.0$.\n  - 垂直需求 $V$ 形状为 $(R-1) \\times C = (1) \\times 3$: $V[0,0] = 2.0$, $V[0,1] = 2.5$, $V[0,2] = 1.0$。\n  - 水平需求 $H$ 形状为 $R \\times (C-1) = 2 \\times (2)$: $H[0,0] = 1.0$, $H[0,1] = 3.0$, $H[1,0] = 2.0$, $H[1,1] = 2.0$。\n\n基本依据。仅使用标准型博弈的核心定义、相关均衡的定义以及为确保正确性所需的线性规划对偶性。除给定的收益构造和相关均衡的定义外，不要假设任何额外的结构。\n\n最终输出格式。您的程序应生成单行输出，其中包含三个结果，形式为用方括号括起来的逗号分隔列表（例如，形如“[x,y,z]”的字符串）。每个数字必须使用标准四舍五入规则保留至 $6$ 位小数。不应打印任何其他文本。此问题不涉及单位，也不存在角度。输出列表中唯一可接受的数据类型是浮点数。", "solution": "所提出的问题是计算博弈论中一个明确定义的任务。它要求在网格上进行的一类特定协调博弈中，在相关均衡下可实现的最大期望社会福利。该问题具有科学依据、内容自洽，并且可以通过线性规划进行算法求解。我将提供一个完整的解决方案。\n\n问题的核心是建立并求解一个线性规划（LP）。线性规划旨在优化一个受一组线性等式和不等式约束的线性目标函数。我们的任务是找到所有可能的联合行动（行动组合）集合上的一个概率分布 $p$，该分布在满足相关均衡（CE）条件的同时，能够最大化期望社会福利。\n\n首先，让我们将博弈的组成部分和由此产生的线性规划形式化。\n\n**1. 博弈定义**\n- **参与者：** 一个由 $N = R \\times C$ 个参与者组成的集合，索引为 $i \\in \\{0, 1, \\dots, N-1\\}$。每个参与者 $i$ 位于网格坐标 $(r,c)$ 处，我们可以建立一个一致的映射，如行主序：$i = r \\cdot C + c$。\n- **行动：** 每个参与者 $i$ 选择一个行动 $a_i \\in \\{0, 1\\}$。所有可能的行动组合的集合是 $\\mathcal{A} = \\{0, 1\\}^N$，其大小为 $|\\mathcal{A}| = 2^N$。一个行动组合是一个向量 $a = (a_0, a_1, \\dots, a_{N-1})$。\n- **收益：** 在行动组合 $a$ 下，参与者 $i$ 的收益 $u_i(a)$ 是其相邻路段贡献的总和。规则被精确指定：只有当参与者 $i$ 选择的行动与路段的方向兼容时（南北向为行动0，东西向为行动1），贡献才非零。贡献的大小取决于邻居的行动是否协调，不协调时有一个因子 $\\alpha \\in [0,1]$。\n- **社会福利：** 对于给定的行动组合 $a$，社会福利被定义为所有参与者收益的总和：$W(a) = \\sum_{i=0}^{N-1} u_i(a)$。\n\n**2. 相关均衡与线性规划**\n相关均衡是行动组合集合 $\\mathcal{A}$ 上的一个概率分布 $p$。我们线性规划的变量将是每个 $a \\in \\mathcal{A}$ 的概率 $p(a)$。为方便起见，我们可以对 $2^N$ 个组合进行排序，并将这些概率表示为一个向量 $\\mathbf{p} \\in \\mathbb{R}^{2^N}$。\n\n**目标函数：**\n我们的目标是最大化期望社会福利，这是概率 $p(a)$ 的一个线性函数：\n$$\n\\mathbb{E}_p[W(a)] = \\sum_{a \\in \\mathcal{A}} p(a) W(a)\n$$\n这可以写成向量形式 $\\mathbf{c}^T \\mathbf{p}$，其中向量 $\\mathbf{c}$ 包含每个行动组合 $a$ 的社会福利值 $W(a)$。由于标准的LP求解器通常执行最小化，我们将最小化 $-\\mathbf{c}^T \\mathbf{p}$。\n\n**约束：**\n分布 $p$ 必须满足三组线性约束。\n1.  **相关均衡（激励相容性）约束：** 对于任何参与者 $i$，如果他们被推荐采取行动 $s \\in \\{0,1\\}$，他们必定没有动机单方面偏离到另一个行动 $t = 1-s$。数学上，对于每个参与者 $i \\in \\{0, \\dots, N-1\\}$ 和每对行动 $s, t \\in \\{0,1\\}$ 且 $s \\neq t$：\n    $$\n    \\sum_{a_{-i} \\in \\{0,1\\}^{N-1}} p(s, a_{-i}) \\left( u_i(s, a_{-i}) - u_i(t, a_{-i}) \\right) \\ge 0\n    $$\n    此处，$(s, a_{-i})$ 表示参与者 $i$ 采取行动 $s$ 而其他参与者根据向量 $a_{-i}$ 行动的行动组合。项 $u_i(t, a_{-i})$ 表示参与者 $i$ 在其他人遵循 $a_{-i}$ 中的推荐时，通过偏离到行动 $t$ 所能获得的收益。这给出了 $2N$ 个线性不等式约束。每个都可以写成矩阵不等式 $\\mathbf{A}_{\\text{ub}} \\mathbf{p} \\le \\mathbf{b}_{\\text{ub}}$ 中的一行。\n\n2.  **概率归一化约束：** 所有概率之和必须等于 $1$。\n    $$\n    \\sum_{a \\in \\mathcal{A}} p(a) = 1\n    $$\n    这是一个单一的线性等式约束，表示为 $\\mathbf{A}_{\\text{eq}} \\mathbf{p} = \\mathbf{b}_{\\text{eq}}$。\n\n3.  **非负性约束：** 概率不能为负。\n    $$\n    p(a) \\ge 0 \\quad \\forall a \\in \\mathcal{A}\n    $$\n    这些是对我们变量的简单下界，$\\mathbf{p} \\ge \\mathbf{0}$。\n\n**3. 算法实现**\n每个测试用例的求解需要以下步骤：\n1.  **枚举：** 系统地生成所有 $2^N$ 个行动组合。一个简单的方法是遍历从 $0$ 到 $2^N - 1$ 的整数，并使用其 $N$ 位二进制表示来代表每个组合。我们必须在这些整数和行动组合之间保持一致的映射。\n2.  **收益计算：** 对于 $2^N$ 个组合中的每一个，计算每个参与者 $i$ 的收益 $u_i(a)$。这涉及到遍历每个参与者，识别他们在网格上的邻居，并根据参与者及其邻居的行动应用指定的收益规则。对给定组合的这些个体收益求和，即可得到社会福利 $W(a)$。这一步填充了目标函数向量 $\\mathbf{c}$，并为构建CE约束提供了必要的值。\n3.  **LP构建：** 基于计算出的收益构建LP的矩阵和向量：\n    -   目标向量 $\\mathbf{c}$ 由社会福利值的负数构成，即对于第 $j$ 个组合 $a_j$，有 $c_j = -W(a_j)$。\n    -   填充CE约束矩阵 $\\mathbf{A}_{\\text{ub}}$（$2N \\times 2^N$）和向量 $\\mathbf{b}_{\\text{ub}}$（全为零）。对于每个参与者 $i$ 和从行动 $s$ 到 $t$ 的潜在偏离，我们构成一个约束行。对于该行中的变量 $p(a)$，其系数仅在 $a_i = s$ 时非零，其值为 $-\\left(u_i(a) - u_i(a|_{a_i=t})\\right)$，其中 $a|_{a_i=t}$ 是参与者 $i$ 的行动切换为 $t$ 后的行动组合。\n    -   等式约束矩阵 $\\mathbf{A}_{\\text{eq}}$ 是一个全为1的单行矩阵（$1 \\times 2^N$），而 $\\mathbf{b}_{\\text{eq}}$ 是标量 $1$。\n4.  **求解器执行：** 使用一个数值线性规划求解器，例如 `scipy.optimize` 库中的 `linprog` 函数，找到最优解向量 $\\mathbf{p}^*$。最大期望社会福利是求解器返回的最小值的负数。\n\n这种系统性的方法将福利最大化相关均衡的理论定义正确地转化为一个可解的计算问题，同时严格遵守问题定义，不对解的结构做任何无根据的假设。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import linprog\n\ndef solve():\n    \"\"\"\n    Main function to define and run all test cases.\n    \"\"\"\n    test_cases = [\n        # Case A: R=2, C=2, alpha=0.4\n        {\n            \"R\": 2, \"C\": 2, \"alpha\": 0.4,\n            \"V\": np.array([[3.0, 2.0]]),\n            \"H\": np.array([[1.0], [1.5]])\n        },\n        # Case B: R=3, C=2, alpha=0.7\n        {\n            \"R\": 3, \"C\": 2, \"alpha\": 0.7,\n            \"V\": np.array([[1.0, 4.0], [2.0, 3.0]]),\n            \"H\": np.array([[5.0], [2.0], [3.0]])\n        },\n        # Case C: R=2, C=3, alpha=1.0\n        {\n            \"R\": 2, \"C\": 3, \"alpha\": 1.0,\n            \"V\": np.array([[2.0, 2.5, 1.0]]),\n            \"H\": np.array([[1.0, 3.0], [2.0, 2.0]])\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_case(case[\"R\"], case[\"C\"], case[\"alpha\"], case[\"V\"], case[\"H\"])\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\ndef solve_case(R, C, alpha, V, H):\n    \"\"\"\n    Solves a single instance of the correlated equilibrium problem.\n    \"\"\"\n    N = R * C\n    M = 1 << N  # Number of action profiles, 2^N\n\n    # Helper maps for grid coordinates and player indices\n    coord_to_idx = {(r, c): r * C + c for r in range(R) for c in range(C)}\n    idx_to_coord = {i: (r, c) for (r, c), i in coord_to_idx.items()}\n\n    # Step 1: Enumerate all profiles\n    # The integer j from 0 to M-1 represents a profile.\n    # The k-th bit of j is the action of player k.\n    \n    # Step 2: Compute payoffs and social welfare for each profile\n    payoffs = np.zeros((N, M))\n    social_welfare = np.zeros(M)\n\n    for j in range(M):\n        # j is the integer representation of the action profile\n        profile = tuple((j >> i) & 1 for i in range(N))\n        current_total_payoff = 0.0\n        \n        for i in range(N):\n            r, c = idx_to_coord[i]\n            action_i = profile[i]\n            player_payoff = 0.0\n\n            # Contribution from North-South (vertical) segments\n            if action_i == 0:\n                # Neighbor Up (North)\n                if r > 0:\n                    neighbor_idx = coord_to_idx[(r - 1, c)]\n                    action_j = profile[neighbor_idx]\n                    demand = V[r - 1, c]\n                    player_payoff += demand if action_j == 0 else alpha * demand\n                # Neighbor Down (South)\n                if r < R - 1:\n                    neighbor_idx = coord_to_idx[(r + 1, c)]\n                    action_j = profile[neighbor_idx]\n                    demand = V[r, c]\n                    player_payoff += demand if action_j == 0 else alpha * demand\n            \n            # Contribution from East-West (horizontal) segments\n            elif action_i == 1:\n                # Neighbor Left (West)\n                if c > 0:\n                    neighbor_idx = coord_to_idx[(r, c - 1)]\n                    action_j = profile[neighbor_idx]\n                    demand = H[r, c - 1]\n                    player_payoff += demand if action_j == 1 else alpha * demand\n                # Neighbor Right (East)\n                if c < C - 1:\n                    neighbor_idx = coord_to_idx[(r, c + 1)]\n                    action_j = profile[neighbor_idx]\n                    demand = H[r, c]\n                    player_payoff += demand if action_j == 1 else alpha * demand\n            \n            payoffs[i, j] = player_payoff\n            current_total_payoff += player_payoff\n        \n        social_welfare[j] = current_total_payoff\n\n    # Step 3: Construct the linear program\n    # Objective function: maximize sum(W(a) * p(a)) => minimize -sum(W(a) * p(a))\n    c = -social_welfare\n\n    # Inequality constraints (CE): A_ub * x <= b_ub\n    num_ce_constraints = 2 * N\n    A_ub = np.zeros((num_ce_constraints, M))\n    b_ub = np.zeros(num_ce_constraints)\n    \n    constraint_idx = 0\n    for i in range(N):  # For each player\n        for s in range(2): # For recommended action s\n            t = 1 - s      # The alternative action\n            for j in range(M): # For each profile j\n                if ((j >> i) & 1) == s:\n                    # k is the index of the profile where player i deviates to t\n                    k = j ^ (1 << i)\n                    # Regret for deviating\n                    regret = payoffs[i, j] - payoffs[i, k]\n                    # The constraint is sum(p(a)*(u_i(a)-u_i(a'))) >= 0\n                    # For linprog (<= form): sum(p(a)*-(u_i(a)-u_i(a'))) <= 0\n                    A_ub[constraint_idx, j] = -regret\n            constraint_idx += 1\n\n    # Equality constraint (sum of probabilities is 1): A_eq * x = b_eq\n    A_eq = np.ones((1, M))\n    b_eq = np.array([1])\n\n    # Bounds for variables p(a) >= 0\n    bounds = (0, None)\n\n    # Step 4: Solve the LP\n    res = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')\n\n    if not res.success:\n        raise RuntimeError(f\"Linear program solver failed for R={R}, C={C}. Message: {res.message}\")\n\n    # The result is -res.fun because we minimized the negative of the welfare\n    return -res.fun\n\nsolve()\n```"}]}