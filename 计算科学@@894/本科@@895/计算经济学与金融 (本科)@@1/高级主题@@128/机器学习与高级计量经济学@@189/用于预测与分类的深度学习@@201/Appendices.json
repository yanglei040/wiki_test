{"hands_on_practices": [{"introduction": "掌握深度学习的第一步是理解一个训练好的模型如何处理信息。本练习聚焦于“前向传播”过程，即追踪一个输入向量 $x$ 如何通过一个简单神经网络的各个层。通过手动执行矩阵运算和应用非线性激活函数这些基本操作 [@problem_id:2387288]，您将具体地理解模型如何将原始数据转化为概率性预测，从而揭开“黑箱”的神秘面纱。", "id": "2387288", "problem": "您将处理一个二元分类任务，其背景源于计算经济学和金融学中的公司治理分析。每个样本代表公司行为准则的一个章节，该章节被编码为一个实值特征向量，总结了每个章节中概念类别的归一化频率。目标是分类某个章节是否表明内部控制存在潜在弱点。\n\n模型定义：\n- 设输入为一个向量 $x \\in \\mathbb{R}^{8}$，其分量是以下八个概念类别的归一化频率（无单位，在 $[0,1]$ 区间内），顺序如下：举报人报告清晰度、礼品政策严格性、利益冲突控制、审计委员会独立性、职责分离、关联方交易监督、豁免或例外频率、模糊语言频率。\n- 考虑一个带单隐藏层的前馈模型，使用修正线性单元（ReLU）激活函数和逻辑输出。定义\n$$\nh(x) = \\phi\\!\\left(W_1 x + b_1\\right) \\in \\mathbb{R}^{4}, \\quad \\phi(z)_i = \\max\\{0, z_i\\},\n$$\n$$\nz_2(x) = W_2^\\top h(x) + b_2 \\in \\mathbb{R}, \\quad p(x) = \\sigma\\!\\left(z_2(x)\\right) = \\frac{1}{1 + e^{-z_2(x)}} \\in (0,1).\n$$\n类别预测为：如果 $p(x) \\geq 0.5$，则 $\\hat{y}(x) = 1$；否则 $\\hat{y}(x) = 0$。\n- 参数是固定的，由以下公式给出\n$$\nW_1 =\n\\begin{bmatrix}\n-0.1 & -0.1 & -0.1 & -0.1 & -0.1 & -0.1 & 0.6 & 0.6 \\\\\n0.4 & 0.4 & 0.3 & 0.3 & 0.3 & 0.3 & -0.2 & -0.2 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0.8 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0.8 & 0\n\\end{bmatrix},\n\\quad\nb_1 =\n\\begin{bmatrix}\n-0.1 \\\\ -0.05 \\\\ -0.2 \\\\ -0.2\n\\end{bmatrix},\n$$\n$$\nW_2 =\n\\begin{bmatrix}\n0.8 \\\\ -0.6 \\\\ 0.5 \\\\ 0.5\n\\end{bmatrix},\n\\quad\nb_2 = 0.\n$$\n\n任务：\n- 对于下面测试集中的每个测试输入 $x$，使用上述模型计算 $p(x)$ 和类别预测 $\\hat{y}(x)$。您必须仅输出整数形式的类别预测。\n\n测试集（每个 $x$ 是 $\\mathbb{R}^{8}$ 的一个元素，其条目在 $[0,1]$ 区间内）：\n- $x^{(1)} = [\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.0,\\, 0.0 \\,]$\n- $x^{(2)} = [\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.9,\\, 0.9 \\,]$\n- $x^{(3)} = [\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0 \\,]$\n- $x^{(4)} = [\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5 \\,]$\n- $x^{(5)} = [\\, 0.2,\\, 0.2,\\, 0.2,\\, 0.2,\\, 0.2,\\, 0.2,\\, 1.0,\\, 0.0 \\,]$\n\n覆盖性设计：\n- 该测试集包括一个具有强控制信号且无风险信号的案例，一个具有弱控制和强风险信号的案例，一个输入为零向量的边界案例，一个混合的中等案例，以及一个低控制且激活了单一风险因素的案例。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，且不含空格。例如，如果五个预测是 $\\hat{y}^{(1)},\\ldots,\\hat{y}^{(5)} \\in \\{0,1\\}$，则应精确打印“[y1,y2,y3,y4,y5]”。", "solution": "问题陈述需经过验证。\n\n**第 1 步：提取已知条件**\n\n- **输入**：特征向量 $x \\in \\mathbb{R}^{8}$，其分量在 $[0,1]$ 区间内。\n- **模型架构**：一个单隐藏层前馈网络。\n- **隐藏层**：\n  $$h(x) = \\phi\\!\\left(W_1 x + b_1\\right) \\in \\mathbb{R}^{4}$$\n  其中 $\\phi(z)_i = \\max\\{0, z_i\\}$ 是修正线性单元（ReLU）激活函数。\n- **输出层**：\n  $$z_2(x) = W_2^\\top h(x) + b_2 \\in \\mathbb{R}$$\n  $$p(x) = \\sigma\\!\\left(z_2(x)\\right) = \\frac{1}{1 + e^{-z_2(x)}} \\in (0,1)$$\n- **分类规则**：\n  $$\\hat{y}(x) = 1 \\text{ 如果 } p(x) \\geq 0.5$$\n  $$\\hat{y}(x) = 0 \\text{ 如果 } p(x) < 0.5$$\n- **参数**：\n  $$\n  W_1 =\n  \\begin{bmatrix}\n  -0.1 & -0.1 & -0.1 & -0.1 & -0.1 & -0.1 & 0.6 & 0.6 \\\\\n  0.4 & 0.4 & 0.3 & 0.3 & 0.3 & 0.3 & -0.2 & -0.2 \\\\\n  0 & 0 & 0 & 0 & 0 & 0 & 0 & 0.8 \\\\\n  0 & 0 & 0 & 0 & 0 & 0 & 0.8 & 0\n  \\end{bmatrix},\n  \\quad\n  b_1 =\n  \\begin{bmatrix}\n  -0.1 \\\\ -0.05 \\\\ -0.2 \\\\ -0.2\n  \\end{bmatrix}\n  $$\n  $$\n  W_2 =\n  \\begin{bmatrix}\n  0.8 \\\\ -0.6 \\\\ 0.5 \\\\ 0.5\n  \\end{bmatrix},\n  \\quad\n  b_2 = 0\n  $$\n- **测试集**：\n  - $x^{(1)} = [\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.0,\\, 0.0 \\,]^\\top$\n  - $x^{(2)} = [\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.9,\\, 0.9 \\,]^\\top$\n  - $x^{(3)} = [\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0 \\,]^\\top$\n  - $x^{(4)} = [\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5 \\,]^\\top$\n  - $x^{(5)} = [\\, 0.2,\\, 0.2,\\, 0.2,\\, 0.2,\\, 0.2,\\, 0.2,\\, 1.0,\\, 0.0 \\,]^\\top$\n- **任务**：为测试集中的每个输入向量计算 $\\hat{y}(x)$。\n\n**第 2 步：使用提取的已知条件进行验证**\n\n根据既定标准对问题进行评估。\n- **科学基础**：该问题描述了一个标准的前馈神经网络，这是机器学习和深度学习中的一个基本模型。数学运算（矩阵乘法、ReLU激活、逻辑S形函数）是标准且正确的。应用背景是合理的。\n- **适定性**：问题是完全指定的。所有参数（$W_1, b_1, W_2, b_2$）、输入向量（$x^{(i)}$）和函数（$\\phi, \\sigma$）都已明确定义。所有矩阵和向量的维度都是一致的。例如，$W_1$ 是 $4 \\times 8$，而 $x$ 是 $8 \\times 1$，得到一个 $4 \\times 1$ 的结果，这与 $b_1$ 的维度相匹配。每个测试用例都存在唯一、稳定的解。\n- **客观性**：问题以精确、定量的术语陈述，没有歧义或主观论断。\n\n**第 3 步：结论与行动**\n\n该问题是**有效的**。它科学合理、适定、客观，并且不包含任何矛盾或缺失的信息。可以推导出严谨的解决方案。\n\n**求解推导**\n\n分类规则 $\\hat{y}(x) = 1$ (如果 $p(x) \\geq 0.5$) 等价于根据对数几率(logit) $z_2(x)$ 的符号进行分类。由于逻辑函数 $\\sigma(z)$ 是单调递增的且 $\\sigma(0) = 0.5$，条件 $p(x) \\geq 0.5$ 等价于 $z_2(x) \\geq 0$。我们将为每个测试用例计算 $z_2(x)$。\n\n计算步骤如下：\n1. 计算隐藏层的预激活向量：$z_1 = W_1 x + b_1$。\n2. 按分量应用 ReLU 激活函数：$h = \\phi(z_1) = \\max\\{0, z_1\\}$。\n3. 计算对数几率（输出的预激活）：$z_2 = W_2^\\top h + b_2$。\n4. 确定类别：如果 $z_2 \\geq 0$，则 $\\hat{y} = 1$；如果 $z_2 < 0$，则 $\\hat{y} = 0$。\n\n**案例 1: $x^{(1)} = [\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.0,\\, 0.0 \\,]^\\top$**\n$z_1^{(1)} = W_1 x^{(1)} + b_1 = \\begin{bmatrix} -0.1(6 \\times 0.9) - 0.1 \\\\ 0.4(2 \\times 0.9) + 0.3(4 \\times 0.9) - 0.05 \\\\ 0 - 0.2 \\\\ 0 - 0.2 \\end{bmatrix} = \\begin{bmatrix} -0.54 - 0.1 \\\\ 1.8 - 0.05 \\\\ -0.2 \\\\ -0.2 \\end{bmatrix} = \\begin{bmatrix} -0.64 \\\\ 1.75 \\\\ -0.2 \\\\ -0.2 \\end{bmatrix}$\n$h^{(1)} = \\phi(z_1^{(1)}) = [\\, 0, 1.75, 0, 0 \\,]^\\top$\n$z_2^{(1)} = W_2^\\top h^{(1)} + b_2 = 0.8(0) - 0.6(1.75) + 0.5(0) + 0.5(0) + 0 = -1.05$\n由于 $z_2^{(1)} = -1.05 < 0$，预测值为 $\\hat{y}^{(1)} = 0$。\n\n**案例 2: $x^{(2)} = [\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.9,\\, 0.9 \\,]^\\top$**\n$z_1^{(2)} = W_1 x^{(2)} + b_1 = \\begin{bmatrix} -0.1(6 \\times 0.1) + 0.6(2 \\times 0.9) - 0.1 \\\\ 0.4(2 \\times 0.1) + 0.3(4 \\times 0.1) - 0.2(2 \\times 0.9) - 0.05 \\\\ 0.8(0.9) - 0.2 \\\\ 0.8(0.9) - 0.2 \\end{bmatrix} = \\begin{bmatrix} -0.06 + 1.08 - 0.1 \\\\ 0.2 - 0.36 - 0.05 \\\\ 0.72 - 0.2 \\\\ 0.72 - 0.2 \\end{bmatrix} = \\begin{bmatrix} 0.92 \\\\ -0.21 \\\\ 0.52 \\\\ 0.52 \\end{bmatrix}$\n$h^{(2)} = \\phi(z_1^{(2)}) = [\\, 0.92, 0, 0.52, 0.52 \\,]^\\top$\n$z_2^{(2)} = W_2^\\top h^{(2)} + b_2 = 0.8(0.92) - 0.6(0) + 0.5(0.52) + 0.5(0.52) + 0 = 0.736 + 0.26 + 0.26 = 1.256$\n由于 $z_2^{(2)} = 1.256 > 0$，预测值为 $\\hat{y}^{(2)} = 1$。\n\n**案例 3: $x^{(3)} = [\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0 \\,]^\\top$**\n$z_1^{(3)} = W_1 x^{(3)} + b_1 = W_1 \\cdot 0 + b_1 = b_1 = [\\, -0.1, -0.05, -0.2, -0.2 \\,]^\\top$\n$h^{(3)} = \\phi(z_1^{(3)}) = [\\, 0, 0, 0, 0 \\,]^\\top$\n$z_2^{(3)} = W_2^\\top h^{(3)} + b_2 = W_2^\\top \\cdot 0 + 0 = 0$\n由于 $z_2^{(3)} = 0$，条件 $z_2 \\geq 0$ 满足。预测值为 $\\hat{y}^{(3)} = 1$。\n\n**案例 4: $x^{(4)} = [\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5 \\,]^\\top$**\n$z_1^{(4)} = W_1 x^{(4)} + b_1 = \\begin{bmatrix} (-0.1 \\times 6 + 0.6 \\times 2) \\times 0.5 - 0.1 \\\\ (0.4 \\times 2 + 0.3 \\times 4 - 0.2 \\times 2) \\times 0.5 - 0.05 \\\\ 0.8 \\times 0.5 - 0.2 \\\\ 0.8 \\times 0.5 - 0.2 \\end{bmatrix} = \\begin{bmatrix} (0.6) \\times 0.5 - 0.1 \\\\ (2.0 - 0.4) \\times 0.5 - 0.05 \\\\ 0.4 - 0.2 \\\\ 0.4 - 0.2 \\end{bmatrix} = \\begin{bmatrix} 0.3 - 0.1 \\\\ 1.6 \\times 0.5 - 0.05 \\\\ 0.2 \\\\ 0.2 \\end{bmatrix} = \\begin{bmatrix} 0.2 \\\\ 0.8 - 0.05 \\\\ 0.2 \\\\ 0.2 \\end{bmatrix} = \\begin{bmatrix} 0.2 \\\\ 0.75 \\\\ 0.2 \\\\ 0.2 \\end{bmatrix}$\n$h^{(4)} = \\phi(z_1^{(4)}) = [\\, 0.2, 0.75, 0.2, 0.2 \\,]^\\top$\n$z_2^{(4)} = W_2^\\top h^{(4)} + b_2 = 0.8(0.2) - 0.6(0.75) + 0.5(0.2) + 0.5(0.2) + 0 = 0.16 - 0.45 + 0.1 + 0.1 = -0.09$\n由于 $z_2^{(4)} = -0.09 < 0$，预测值为 $\\hat{y}^{(4)} = 0$。\n\n**案例 5: $x^{(5)} = [\\, 0.2,\\, 0.2,\\, 0.2,\\, 0.2,\\, 0.2,\\, 0.2,\\, 1.0,\\, 0.0 \\,]^\\top$**\n$z_1^{(5)} = W_1 x^{(5)} + b_1 = \\begin{bmatrix} (-0.1 \\times 6 \\times 0.2) + 0.6(1.0) + 0.6(0) - 0.1 \\\\ (0.4 \\times 2 \\times 0.2 + 0.3 \\times 4 \\times 0.2) - 0.2(1.0) - 0.2(0) - 0.05 \\\\ 0.8(0) - 0.2 \\\\ 0.8(1.0) - 0.2 \\end{bmatrix} = \\begin{bmatrix} -0.12 + 0.6 - 0.1 \\\\ (0.16 + 0.24) - 0.2 - 0.05 \\\\ -0.2 \\\\ 0.8 - 0.2 \\end{bmatrix} = \\begin{bmatrix} 0.38 \\\\ 0.4 - 0.2 - 0.05 \\\\ -0.2 \\\\ 0.6 \\end{bmatrix} = \\begin{bmatrix} 0.38 \\\\ 0.15 \\\\ -0.2 \\\\ 0.6 \\end{bmatrix}$\n$h^{(5)} = \\phi(z_1^{(5)}) = [\\, 0.38, 0.15, 0, 0.6 \\,]^\\top$\n$z_2^{(5)} = W_2^\\top h^{(5)} + b_2 = 0.8(0.38) - 0.6(0.15) + 0.5(0) + 0.5(0.6) + 0 = 0.304 - 0.09 + 0.3 = 0.514$\n由于 $z_2^{(5)} = 0.514 > 0$，预测值为 $\\hat{y}^{(5)} = 1$。\n\n最终的预测列表为 $[0, 1, 1, 0, 1]$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the class predictions for a given set of input vectors\n    using a predefined one-hidden-layer neural network.\n    \"\"\"\n    \n    # Define the model parameters as numpy arrays.\n    W1 = np.array([\n        [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, 0.6, 0.6],\n        [0.4, 0.4, 0.3, 0.3, 0.3, 0.3, -0.2, -0.2],\n        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8],\n        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0]\n    ])\n\n    b1 = np.array([-0.1, -0.05, -0.2, -0.2])\n\n    W2 = np.array([0.8, -0.6, 0.5, 0.5])\n    \n    # b2 is given as 0.0\n    b2 = 0.0\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        np.array([0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.0, 0.0]),\n        np.array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.9, 0.9]),\n        np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n        np.array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]),\n        np.array([0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1.0, 0.0]),\n    ]\n\n    results = []\n    for x in test_cases:\n        # Step 1: Calculate the pre-activation of the hidden layer.\n        # W1 is (4, 8), x is (8,). The result z1 is (4,).\n        z1 = W1 @ x + b1\n\n        # Step 2: Apply the ReLU activation function.\n        # np.maximum performs an element-wise maximum.\n        h = np.maximum(0, z1)\n\n        # Step 3: Calculate the pre-activation of the output layer (logit).\n        # W2.T is (4,), h is (4,). The result z2 is a scalar.\n        z2 = W2.T @ h + b2\n\n        # Step 4: Determine the class prediction.\n        # The classification rule is y_hat = 1 if p(x) >= 0.5, which is equivalent\n        # to z2(x) >= 0.\n        y_hat = 1 if z2 >= 0 else 0\n        \n        results.append(y_hat)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}, {"introduction": "在理解了模型如何做出预测之后，下一个合乎逻辑的问题是模型的参数（如权重 $w$ 和偏置 $b$）是如何从数据中学习的。本实践将您从执行预测带入到进行训练的阶段。这个练习 [@problem_id:2387257] 将指导您从零开始实现核心的优化算法——批量梯度下降，来训练一个多项式逻辑回归模型，从而真正理解深度学习中的“学习”是如何发生的。", "id": "2387257", "problem": "您面临一个简化的、完全指定的、列表式分类问题，该问题旨在建模以下问题：在给定时间，在一组有限的候选国家中，哪一个最有可能成为下一个加入特定贸易集团的国家，其判断完全基于经济和政治整合度的数值指标。每个候选国家由一个固定长度的特征向量表示，该向量包含归一化的整合度度量。您将把此任务作为一个概率分类任务来处理，使用一个单层模型，该模型为每个候选者分配一个标量分数，将分数转换为候选集上的概率分布，并通过最大化观测到的过去结果的联合似然来进行训练。\n\n从以下基本原理出发：对于一组针对 $n$ 个互斥结果的分数 $\\{s_k\\}_{k=1}^{n}$，其分类概率分布由归一化指数映射（softmax）定义，参数通过最大化似然（等效于最小化负对数似然）来估计。目标函数应包含对参数的标准 $\\ell_2$ 惩罚项。训练算法应使用从第一性原理推导出的基于梯度的优化方法。\n\n数学设置：\n\n- 对于每个具有 $n_t$ 个候选国家的训练事件 $t$，有一个特征矩阵 $X_t \\in \\mathbb{R}^{n_t \\times d}$，其中每一行 $x_{t,k} \\in \\mathbb{R}^{d}$ 代表候选者 $k$ 的 $d$ 维特征向量，以及一个观测索引 $y_t \\in \\{0,1,\\dots,n_t-1\\}$，表示在该事件中实际下一个加入的国家。\n- 使用单层线性评分模型 $s_{t,k} = w^\\top x_{t,k} + b$，其参数为 $w \\in \\mathbb{R}^{d}$ 和 $b \\in \\mathbb{R}$，并通过对 $n_t$ 个候选者应用 softmax 映射来定义事件 $t$ 的模型隐含概率。\n- 所有训练事件的总目标函数是负对数似然之和加上一个对 $w$ 的 $\\ell_2$ 惩罚项（系数为 $\\lambda > 0$），不对 $b$ 进行正则化。\n\n您的任务：\n\n1) 从上述基本原理出发，根据似然定义和链式法则，明确地推导出实现参数 $w$ 和 $b$ 的基于梯度的学习规则所需的表达式，不要使用捷径。\n\n2) 使用固定步长的批量梯度下降法实现一个训练程序。对 softmax 使用数值稳定的计算方法。训练过程必须是确定性的，不得依赖任何随机性。\n\n3) 在下方指定的训练集上完成训练后，在提供的测试集（训练中未使用的候选集）上评估训练好的模型，方法是计算每个测试用例中预测概率最高的候选者的索引（从零开始）。\n\n数据规格：\n\n- 每个特征向量的维度：$d = 5$。\n- 特征语义和范围（仅供解释；程序会将其视为纯数字）：\n  - $x_1$: 与该贸易集团的归一化贸易份额，范围在 $[0,1]$，\n  - $x_2$: 归一化的关税政策整合度，范围在 $[0,1]$，\n  - $x_3$: 归一化的人均国内生产总值整合度，范围在 $[0,1]$，\n  - $x_4$: 归一化的民主与治理相似度，范围在 $[0,1]$，\n  - $x_5$: 归一化的外交政策投票相似度，范围在 $[0,1]$。\n\n训练事件（每个事件是一个候选者矩阵，后跟观测到的加入索引）：\n- 事件 1 ($n_1 = 3$)：\n  - 候选者：\n    - $[0.60, 0.70, 0.50, 0.60, 0.65]$\n    - $[0.40, 0.50, 0.60, 0.50, 0.45]$\n    - $[0.80, 0.80, 0.70, 0.70, 0.80]$\n  - 观测索引 $y_1 = 2$。\n- 事件 2 ($n_2 = 2$)：\n  - 候选者：\n    - $[0.30, 0.40, 0.50, 0.40, 0.40]$\n    - $[0.70, 0.60, 0.60, 0.80, 0.70]$\n  - 观测索引 $y_2 = 1$。\n- 事件 3 ($n_3 = 4$)：\n  - 候选者：\n    - $[0.20, 0.30, 0.40, 0.40, 0.30]$\n    - $[0.50, 0.60, 0.50, 0.50, 0.60]$\n    - $[0.90, 0.90, 0.90, 0.80, 0.85]$\n    - $[0.70, 0.50, 0.70, 0.60, 0.65]$\n  - 观测索引 $y_3 = 2$。\n\n超参数：\n- 学习率 $\\eta = 0.10$，\n- 正则化系数 $\\lambda = 10^{-3}$，\n- 全批量迭代次数（轮次）$T = 2000$。\n\n测试集（用于评估的候选集；每个测试用例输出一个整数）：\n- 测试用例 1 ($n = 3$)：\n  - $[0.65, 0.70, 0.55, 0.60, 0.60]$\n  - $[0.50, 0.50, 0.55, 0.45, 0.50]$\n  - $[0.75, 0.80, 0.75, 0.75, 0.82]$\n- 测试用例 2 ($n = 2$)：\n  - $[0.35, 0.45, 0.55, 0.50, 0.48]$\n  - $[0.60, 0.55, 0.50, 0.70, 0.60]$\n- 测试用例 3 ($n = 4$)：\n  - $[0.55, 0.60, 0.60, 0.60, 0.60]$\n  - $[0.60, 0.55, 0.55, 0.55, 0.55]$\n  - $[0.65, 0.65, 0.65, 0.65, 0.65]$\n  - $[0.50, 0.50, 0.50, 0.50, 0.50]$\n- 测试用例 4 ($n = 3$)：\n  - $[0.00, 0.00, 0.00, 0.00, 0.00]$\n  - $[0.20, 0.20, 0.20, 0.20, 0.20]$\n  - $[0.10, 0.10, 0.10, 0.10, 0.10]$\n\n最终输出规格：\n- 您的程序应使用指定的超参数在提供的训练事件上进行训练，然后生成一行输出，其中包含四个测试用例的预测索引（从零开始），格式为用方括号括起来的逗号分隔列表，例如 $[a,b,c,d]$，其中 $a$、$b$、$c$、$d$ 根据测试用例的大小分别为 $\\{0,1,2,3\\}$ 中的整数。", "solution": "所提出的问题是一个适定的、具有科学依据的分类任务，可以使用标准的多项式逻辑回归模型来解决。其有效性已得到确认，并从第一性原理推导出一个解决方案。\n\n核心任务是训练一个带有参数 $w \\in \\mathbb{R}^{d}$ 和 $b \\in \\mathbb{R}$ 的线性模型，以预测集合中的哪个候选者最有可能加入一个贸易集团。训练通过使用批量梯度下降法最小化一个正则化的负对数似然目标函数来执行。\n\n假设有 $N$ 个训练事件，由 $t \\in \\{1, 2, \\dots, N\\}$ 索引。对于每个事件 $t$，我们有一组 $n_t$ 个候选国家，其特征由一个矩阵 $X_t \\in \\mathbb{R}^{n_t \\times d}$ 表示。每一行 $x_{t,k} \\in \\mathbb{R}^{d}$ 是候选者 $k \\in \\{0, 1, \\dots, n_t-1\\}$ 的特征向量。观测结果是加入国家的索引 $y_t$。\n\n在事件 $t$ 中，候选者 $k$ 的分数由以下线性函数给出：\n$$s_{t,k} = w^\\top x_{t,k} + b$$\n\n候选者 $k$ 被选中的概率通过 softmax 函数建模，该函数将分数归一化为 $n_t$ 个候选者上的一个概率分布：\n$$P_{t,k} \\equiv P(y=k | X_t, w, b) = \\frac{\\exp(s_{t,k})}{\\sum_{j=0}^{n_t-1} \\exp(s_{t,j})}$$\n\n目标是通过最大化观测到训练数据 $\\{y_t\\}_{t=1}^N$ 的联合似然来找到参数 $w$ 和 $b$。这等同于最小化总负对数似然 $L_{NLL}$。我们为权重向量 $w$ 添加一个 $\\ell_2$ 正则化项以防止过拟合。总目标函数 $L(w,b)$ 为：\n$$L(w, b) = L_{NLL} + L_{REG} = \\left( \\sum_{t=1}^{N} L_t(w, b) \\right) + \\frac{\\lambda}{2} \\|w\\|^2_2$$\n其中 $\\lambda > 0$ 是正则化系数， $L_t$ 是单个事件 $t$ 的负对数似然：\n$$L_t(w,b) = -\\log(P_{t, y_t})$$\n代入分数和概率的表达式，我们可以将 $L_t$ 写为：\n$$L_t = -\\log\\left(\\frac{\\exp(s_{t,y_t})}{\\sum_{j=0}^{n_t-1} \\exp(s_{t,j})}\\right) = -s_{t,y_t} + \\log\\left(\\sum_{j=0}^{n_t-1} \\exp(s_{t,j})\\right)$$\n\n为了使用梯度下降法训练模型，我们必须计算总目标函数 $L$ 关于参数 $w$ 和 $b$ 的偏导数。参数 $\\theta$ 的梯度更新规则是 $\\theta \\leftarrow \\theta - \\eta \\nabla_{\\theta} L$，其中 $\\eta$ 是学习率。\n\n首先，我们推导关于权重向量 $w$ 的梯度。正则化项的梯度很简单：\n$$\\frac{\\partial}{\\partial w} \\left(\\frac{\\lambda}{2} w^\\top w\\right) = \\lambda w$$\n负对数似然的梯度是每个事件梯度的总和：$\\frac{\\partial L_{NLL}}{\\partial w} = \\sum_{t=1}^N \\frac{\\partial L_t}{\\partial w}$。让我们使用链式法则来求单个事件 $t$ 的梯度。对于 $w$ 的第 $i$ 个分量，记为 $w_i$：\n$$\\frac{\\partial L_t}{\\partial w_i} = \\sum_{k=0}^{n_t-1} \\frac{\\partial L_t}{\\partial s_{t,k}} \\frac{\\partial s_{t,k}}{\\partial w_i}$$\n分数 $s_{t,k}$ 关于 $w_i$ 的导数是：\n$$\\frac{\\partial s_{t,k}}{\\partial w_i} = \\frac{\\partial}{\\partial w_i} \\left(\\sum_{l=1}^{d} w_l (x_{t,k})_l + b\\right) = (x_{t,k})_i$$\n损失 $L_t$ 关于分数 $s_{t,k}$ 的导数是：\n$$\\frac{\\partial L_t}{\\partial s_{t,k}} = \\frac{\\partial}{\\partial s_{t,k}} \\left(-s_{t,y_t} + \\log\\left(\\sum_{j=0}^{n_t-1} \\exp(s_{t,j})\\right)\\right) = -\\delta_{k, y_t} + \\frac{\\exp(s_{t,k})}{\\sum_{j=0}^{n_t-1} \\exp(s_{t,j})} = P_{t,k} - \\delta_{k, y_t}$$\n其中 $\\delta_{k, y_t}$ 是克罗内克 δ (Kronecker delta)，如果 $k=y_t$ 则为 $1$，否则为 $0$。\n\n结合这些部分，$L_t$ 关于 $w_i$ 的梯度是：\n$$\\frac{\\partial L_t}{\\partial w_i} = \\sum_{k=0}^{n_t-1} (P_{t,k} - \\delta_{k, y_t}) (x_{t,k})_i$$\n以向量形式表示，事件 $t$ 的梯度是：\n$$\\frac{\\partial L_t}{\\partial w} = \\sum_{k=0}^{n_t-1} (P_{t,k} - \\delta_{k, y_t}) x_{t,k} = X_t^\\top (p_t - e_{y_t})$$\n其中 $p_t$ 是概率向量 $\\{P_{t,k}\\}_{k=0}^{n_t-1}$，$e_{y_t}$ 是真实标签 $y_t$ 的独热编码向量。\n\n$w$ 的总梯度是所有训练事件的梯度之和加上正则化梯度：\n$$\\nabla_w L(w,b) = \\left( \\sum_{t=1}^{N} \\sum_{k=0}^{n_t-1} (P_{t,k} - \\delta_{k, y_t}) x_{t,k} \\right) + \\lambda w$$\n\n接下来，我们推导关于偏置项 $b$ 的梯度。正则化项不依赖于 $b$。我们再次使用链式法则：\n$$\\frac{\\partial L_t}{\\partial b} = \\sum_{k=0}^{n_t-1} \\frac{\\partial L_t}{\\partial s_{t,k}} \\frac{\\partial s_{t,k}}{\\partial b}$$\n分数关于 $b$ 的导数很简单：\n$$\\frac{\\partial s_{t,k}}{\\partial b} = \\frac{\\partial}{\\partial b} (w^\\top x_{t,k} + b) = 1$$\n因此，$L_t$ 关于 $b$ 的梯度是：\n$$\\frac{\\partial L_t}{\\partial b} = \\sum_{k=0}^{n_t-1} (P_{t,k} - \\delta_{k, y_t}) (1) = \\sum_{k=0}^{n_t-1} P_{t,k} - \\sum_{k=0}^{n_t-1} \\delta_{k, y_t} = 1 - 1 = 0$$\n这是不正确的。求和是针对误差项的。$\\sum_{k=0}^{n_t-1} P_{t,k} - \\sum_{k=0}^{n_t-1} \\delta_{k, y_t} = 1 - 1 = 0$。让我重新核对一下。啊，我对 $\\frac{\\partial L_t}{\\partial b}$ 的推导是正确的，误差之和 $(P_{t,k}-\\delta_{k,y_t})$ 确实是所使用的。$\\sum P_{t,k} - \\sum \\delta_{k,y_t} = 1-1=0$ 的推理在算术上是正确的，但这些项是在对 $t$ 求和以获得总梯度时使用的。单个事件的梯度是预测概率与目标概率之差的总和。\n让我重述一下。\n$$\\frac{\\partial L_t}{\\partial b} = \\sum_{k=0}^{n_t-1} (P_{t,k} - \\delta_{k, y_t})$$\n$b$ 在所有事件上的总梯度是：\n$$\\nabla_b L(w,b) = \\sum_{t=1}^{N} \\frac{\\partial L_t}{\\partial b} = \\sum_{t=1}^{N} \\sum_{k=0}^{n_t-1} (P_{t,k} - \\delta_{k, y_t})$$\n在训练期间，该项不保证为零，只有在达到完美最优解时才为零。\n\n批量梯度下降算法初始化参数 $w$ 和 $b$（例如，初始化为零），并对它们进行 $T$ 轮的迭代更新：\n$$w^{(i+1)} = w^{(i)} - \\eta \\nabla_w L(w^{(i)}, b^{(i)})$$\n$$b^{(i+1)} = b^{(i)} - \\eta \\nabla_b L(w^{(i)}, b^{(i)})$$\n为了数值稳定性，softmax 函数通过平移分数来计算：$s_k \\to s_k - \\max_j(s_j)$。这可以防止在对大分数进行指数运算时发生溢出，同时保持最终的概率不变。\n\n在使用学习率 $\\eta=0.10$ 和正则化系数 $\\lambda=10^{-3}$ 进行 $T=2000$ 次迭代后，最终的参数 $(w,b)$ 被用来对测试用例进行预测。对于每个测试用例，我们计算所有候选者的分数，并选择分数最高的候选者的索引。", "answer": "完整的、可运行的 Python 3 代码如下。导入的库必须符合指定的执行环境。\n```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the listwise classification problem using batch gradient descent.\n    \"\"\"\n    # 1. Define problem data and hyperparameters\n    d = 5\n    eta = 0.10\n    lambda_reg = 1e-3\n    T = 2000\n\n    train_events = [\n        (np.array([\n            [0.60, 0.70, 0.50, 0.60, 0.65],\n            [0.40, 0.50, 0.60, 0.50, 0.45],\n            [0.80, 0.80, 0.70, 0.70, 0.80]\n        ]), 2),\n        (np.array([\n            [0.30, 0.40, 0.50, 0.40, 0.40],\n            [0.70, 0.60, 0.60, 0.80, 0.70]\n        ]), 1),\n        (np.array([\n            [0.20, 0.30, 0.40, 0.40, 0.30],\n            [0.50, 0.60, 0.50, 0.50, 0.60],\n            [0.90, 0.90, 0.90, 0.80, 0.85],\n            [0.70, 0.50, 0.70, 0.60, 0.65]\n        ]), 2)\n    ]\n\n    test_cases = [\n        np.array([\n            [0.65, 0.70, 0.55, 0.60, 0.60],\n            [0.50, 0.50, 0.55, 0.45, 0.50],\n            [0.75, 0.80, 0.75, 0.75, 0.82]\n        ]),\n        np.array([\n            [0.35, 0.45, 0.55, 0.50, 0.48],\n            [0.60, 0.55, 0.50, 0.70, 0.60]\n        ]),\n        np.array([\n            [0.55, 0.60, 0.60, 0.60, 0.60],\n            [0.60, 0.55, 0.55, 0.55, 0.55],\n            [0.65, 0.65, 0.65, 0.65, 0.65],\n            [0.50, 0.50, 0.50, 0.50, 0.50]\n        ]),\n        np.array([\n            [0.00, 0.00, 0.00, 0.00, 0.00],\n            [0.20, 0.20, 0.20, 0.20, 0.20],\n            [0.10, 0.10, 0.10, 0.10, 0.10]\n        ])\n    ]\n\n    # 2. Initialize model parameters\n    w = np.zeros(d)\n    b = 0.0\n\n    # 3. Training with Batch Gradient Descent\n    for _ in range(T):\n        grad_w_total = np.zeros(d)\n        grad_b_total = 0.0\n\n        # Loop over all training events to compute the full batch gradient\n        for X_t, y_t in train_events:\n            n_t = X_t.shape[0]\n\n            # Calculate scores: s = Xw + b\n            scores = X_t @ w + b\n            \n            # Numerically stable softmax to compute probabilities\n            scores_stable = scores - np.max(scores)\n            exp_scores = np.exp(scores_stable)\n            probs = exp_scores / np.sum(exp_scores)\n\n            # Create one-hot encoded target vector\n            target = np.zeros(n_t)\n            target[y_t] = 1.0\n            \n            # Calculate the error term (p - y_onehot)\n            error = probs - target\n            \n            # Calculate gradient contribution from this event\n            grad_w_t = X_t.T @ error\n            grad_b_t = np.sum(error)\n            \n            # Accumulate gradients for the batch\n            grad_w_total += grad_w_t\n            grad_b_total += grad_b_t\n            \n        # Add regularization gradient for w (L2 penalty)\n        grad_w_total += lambda_reg * w\n        \n        # Update parameters using the batch gradient\n        w -= eta * grad_w_total\n        b -= eta * grad_b_total\n\n    # 4. Evaluation on test suite\n    results = []\n    for X_test in test_cases:\n        # Calculate scores for the test case\n        scores = X_test @ w + b\n        # Prediction is the index of the highest score\n        predicted_index = np.argmax(scores)\n        results.append(predicted_index)\n\n    # 5. Print the final results in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}, {"introduction": "在牢固掌握了预测和训练的基础后，我们现在可以处理一个更真实、更复杂的挑战：金融时间序列预测。本实践将一个现代深度学习模型（LSTM）与一个经典的计量经济学基准模型（GARCH）进行比较。通过在一个合成数据集上实施和比较这两种截然不同的方法 [@problem_id:2387303]，您将学会批判性地评估模型性能，并理解深度学习架构在捕捉复杂依赖关系（如市场情绪等外部因素的影响）方面的特定优势。", "id": "2387303", "problem": "您必须编写一个完整、可运行的程序，对于一个指定的合成数据生成过程，比较广义自回归条件异方差（GARCH）模型与长短期记忆（LSTM）模型在单步向前预测每日比特币波动率方面的表现。形式上，波动率由次日的平方收益率作为代理变量。您的程序必须生成数据，仅使用训练部分来拟合两个模型，在固定的测试部分上生成样本外预测，评估均方误差，并为每个测试案例判断哪个模型表现更优。\n\n数据生成过程遵循以下步骤。对于每个测试案例，存在一个情绪过程 $\\{s_t\\}$ 和一个收益率过程 $\\{r_t\\}$。情绪遵循一个一阶自回归过程演化：\n$$ s_t = \\phi s_{t-1} + \\epsilon_t, \\quad \\epsilon_t \\sim \\mathcal{N}(0,\\sigma_\\epsilon^2), \\quad s_0 = 0. $$\n条件方差过程为\n$$ h_t = \\omega + \\alpha r_{t-1}^2 + \\beta h_{t-1} + \\gamma \\cdot \\max(s_{t-1},0)^2, $$\n约定 $r_{-1}=0$ 且 $s_{-1}=0$。收益率遵循一个条件高斯模型\n$$ r_t = \\sqrt{h_t}\\, z_t, \\quad z_t \\sim \\mathcal{N}(0,1). $$\n所有随机性必须由为每个测试案例指定的固定种子生成。您必须生成一个长度为 $N$ 的序列，将其分割成长度为 $N_{\\text{train}}$ 的训练前缀和长度为 $N_{\\text{test}} = N - N_{\\text{train}}$ 的测试后缀，并构建 $N_{\\text{test}}$ 个单步向前预测目标 $\\{y_{t+1}\\}_{t=t_0}^{t_1}$，其中 $y_{t+1}=r_{t+1}^2$，预测起始点 $t$ 的范围覆盖了最后 $N_{\\text{test}}$ 个样本内时间点。\n\n您必须实现并比较以下模型：\n\n1) 广义自回归条件异方差（GARCH）基准模型：GARCH$(1,1)$ 条件方差模型为\n$$ h_t = \\omega + \\alpha r_{t-1}^2 + \\beta h_{t-1}, $$\n其中 $\\omega > 0$，$\\alpha \\ge 0$，$\\beta \\ge 0$，且 $\\alpha+\\beta < 1$。在训练数据上，基于高斯准似然假设，通过最大似然法拟合 $(\\omega,\\alpha,\\beta)$，并使用递归计算 $\\{h_t\\}$。使用拟合的参数为测试期计算单步向前方差预测：\n$$ \\widehat{y}^{\\text{GARCH}}_{t+1} = \\widehat{\\omega} + \\widehat{\\alpha} r_t^2 + \\widehat{\\beta} \\widehat{h}_t, $$\n其中 $\\widehat{h}_t$ 是在时间 $t$ 的滤波条件方差。在测试目标上评估均方误差，\n$$ \\text{MSE}_{\\text{GARCH}} = \\frac{1}{N_{\\text{test}}} \\sum_{t=t_0}^{t_1} \\left(\\widehat{y}^{\\text{GARCH}}_{t+1} - y_{t+1}\\right)^2. $$\n\n2) 包含情绪指标的长短期记忆（LSTM）预测模型：长短期记忆（LSTM）是一种循环神经网络单元，其在时间 $t$ 的方程如下定义，其中隐藏状态维度为 $H$，输入特征向量为 $x_t \\in \\mathbb{R}^d$：\n$$ i_t = \\sigma(W_i x_t + U_i h_{t-1} + b_i), $$\n$$ f_t = \\sigma(W_f x_t + U_f h_{t-1} + b_f), $$\n$$ o_t = \\sigma(W_o x_t + U_o h_{t-1} + b_o), $$\n$$ g_t = \\tanh(W_g x_t + U_g h_{t-1} + b_g), $$\n$$ c_t = f_t \\odot c_{t-1} + i_t \\odot g_t, \\quad h_t = o_t \\odot \\tanh(c_t), $$\n其中 $\\sigma(u)=1/(1+e^{-u})$ 是逻辑S型函数，$\\odot$ 表示逐元素乘法，$W_{\\cdot} \\in \\mathbb{R}^{H\\times d}$，$U_{\\cdot} \\in \\mathbb{R}^{H\\times H}$，且 $b_{\\cdot} \\in \\mathbb{R}^H$。使用大小为 $W$ 的固定长度历史窗口，输入为 $x_t = [r_t, s_t]^\\top \\in \\mathbb{R}^2$，初始状态为 $h_{t-W}=0$ 和 $c_{t-W}=0$。在处理完以时间 $t$ 结尾的窗口后，通过以下方式生成一个非负标量预测：\n$$ \\widehat{y}^{\\text{LSTM}}_{t+1} = \\log\\left(1 + \\exp\\left(v^\\top h_t + b_y\\right)\\right), $$\n其中 $v \\in \\mathbb{R}^H$ 且 $b_y \\in \\mathbb{R}$。通过最小化训练窗口上的均方误差来拟合参数 $\\{W_{\\cdot},U_{\\cdot},b_{\\cdot},v,b_y\\}$，\n$$ \\min \\ \\frac{1}{N_{\\text{train}}-W} \\sum_{t=W-1}^{N_{\\text{train}}-2} \\left(\\widehat{y}^{\\text{LSTM}}_{t+1} - r_{t+1}^2\\right)^2. $$\n然后使用相同的窗口化方法计算测试期内的单步向前预测，并评估\n$$ \\text{MSE}_{\\text{LSTM}} = \\frac{1}{N_{\\text{test}}} \\sum_{t=t_0}^{t_1} \\left(\\widehat{y}^{\\text{LSTM}}_{t+1} - y_{t+1}\\right)^2. $$\n\n您的程序必须实现以下包含三个案例的固定测试套件，根据上述公式生成数据，并对所有随机性使用指定的种子：\n\n- 案例A（有预测性的情绪）：$N=220$，$N_{\\text{train}}=170$，$\\phi=0.8$，$\\sigma_\\epsilon=0.5$，$\\omega=2.5\\times 10^{-5}$，$\\alpha=0.08$，$\\beta=0.86$，$\\gamma=1.5\\times 10^{-4}$，种子 $=12345$，窗口长度 $W=10$，隐藏状态维度 $H=6$，输入维度 $d=2$。\n- 案例B（无情绪效应，持续性波动）：$N=220$，$N_{\\text{train}}=170$，$\\phi=0.8$，$\\sigma_\\epsilon=0.5$，$\\omega=8\\times 10^{-6}$，$\\alpha=0.08$，$\\beta=0.90$，$\\gamma=0$，种子 $=54321$，窗口长度 $W=10$，隐藏状态维度 $H=6$，输入维度 $d=2$。\n- 案例C（近乎恒定的波动率）：$N=220$，$N_{\\text{train}}=170$，$\\phi=0.8$，$\\sigma_\\epsilon=0.5$，$\\omega=4\\times 10^{-4}$，$\\alpha=0$，$\\beta=0$，$\\gamma=0$，种子 $=202311$，窗口长度 $W=10$，隐藏状态维度 $H=6$，输入维度 $d=2$。\n\n您的程序必须为每个案例生成一个决策：如果该案例中 $\\text{MSE}_{\\text{LSTM}} < \\text{MSE}_{\\text{GARCH}}$，则输出整数 $1$，否则输出 $0$。将三个决策汇总到一行输出中，该行包含一个用方括号括起来的逗号分隔列表，并按 A, B, C 的固定顺序排列。例如，输出可能为\n$$ [1,0,1]. $$\n\n不涉及物理单位。不使用角度。如果您选择计算中间百分比，请不要打印它们；仅打印所需的整数。最终打印的行必须与指定格式完全匹配。", "solution": "该问题要求在综合生成的数据上，对广义自回归条件异方差（GARCH）模型和长短期记忆（LSTM）网络进行单步向前波动率预测的比较分析。波动率由平方收益率 $r_{t+1}^2$ 作为代理。该分析必须针对三个指定的测试案例进行。我的任务是实现完整的流程：数据生成、模型拟合、预测和评估，并根据均方误差（MSE）标准确定在每个案例中哪个模型表现更优。\n\n我们首先将数据生成过程（DGP）形式化。DGP 由两个相互关联的随机过程组成：一个情绪过程 $\\{s_t\\}$ 和一个收益率过程 $\\{r_t\\}$。\n\n情绪 $s_t$ 遵循一个一阶自回归（AR(1)）过程：\n$$ s_t = \\phi s_{t-1} + \\epsilon_t, \\quad \\text{with } s_0 = 0 $$\n其中创新项 $\\epsilon_t$ 是从正态分布 $\\mathcal{N}(0, \\sigma_\\epsilon^2)$ 中抽取的独立同分布（i.i.d.）样本。\n\n收益率序列 $\\{r_t\\}$ 是由一个时变条件方差 $h_t$ 生成的。该方差过程是一个 GARCH($1,1$) 模型，并增加了一个代表正向情绪 $s_{t-1}$ 的项：\n$$ h_t = \\omega + \\alpha r_{t-1}^2 + \\beta h_{t-1} + \\gamma \\cdot \\max(s_{t-1}, 0)^2 $$\n该过程以 $r_{-1}=0$ 和 $s_{-1}=0$ 的约定进行初始化。假设 $h_{-1}=0$，初始方差则为 $h_0 = \\omega$。收益率随后从一个条件高斯分布中抽取：\n$$ r_t = \\sqrt{h_t} z_t, \\quad \\text{where } z_t \\sim \\mathcal{N}(0, 1) \\text{ i.i.d.} $$\n对于每个测试案例，生成一个长度为 $N$ 的数据序列，然后将其分割成大小为 $N_{\\text{train}}$ 的训练集和大小为 $N_{\\text{test}} = N - N_{\\text{train}}$ 的测试集。\n\n第一个模型是标准的 GARCH($1,1$) 模型。它将条件方差指定为：\n$$ h_t = \\omega + \\alpha r_{t-1}^2 + \\beta h_{t-1} $$\n参数 $(\\omega, \\alpha, \\beta)$ 是通过在训练数据 $\\{r_t\\}_{t=0}^{N_{\\text{train}}-1}$ 上最大化高斯准对数似然函数来估计的。待最大化的对数似然函数是：\n$$ \\mathcal{L}(\\omega, \\alpha, \\beta) = \\sum_{t=1}^{N_{\\text{train}}-1} \\left( -\\frac{1}{2}\\log(2\\pi) - \\frac{1}{2}\\log(h_t) - \\frac{r_t^2}{2h_t} \\right) $$\n$h_t$ 的递归通过将 $h_0$ 设置为训练收益率的样本方差来初始化。参数必须满足约束条件 $\\omega > 0$, $\\alpha \\ge 0$, $\\beta \\ge 0$, 以及 $\\alpha+\\beta < 1$。我们使用序列最小二乘规划（SLSQP）算法来完成这个有约束的优化任务。一旦参数 $(\\widehat{\\omega}, \\widehat{\\alpha}, \\widehat{\\beta})$ 被估计出来，就为测试期生成单步向前预测。$t$ 时刻对 $t+1$ 时刻的预测即为条件方差：\n$$ \\widehat{y}^{\\text{GARCH}}_{t+1} = \\widehat{h}_{t+1} = \\widehat{\\omega} + \\widehat{\\alpha} r_t^2 + \\widehat{\\beta} \\widehat{h}_t $$\n其中 $\\widehat{h}_t$ 是使用估计参数计算出的在时间 $t$ 的滤波方差。\n\n第二个模型是长短期记忆（LSTM）网络。LSTM 单元根据当前输入 $x_t$ 和前一时刻的状态 $(c_{t-1}, h_{t-1})$ 来更新其细胞状态 $c_t$ 和隐藏状态 $h_t$。输入向量为 $x_t = [r_t, s_t]^\\top \\in \\mathbb{R}^2$。LSTM 方程组如下：\n\\begin{align*}\ni_t &= \\sigma(W_i x_t + U_i h_{t-1} + b_i) & \\text{（输入门）} \\\\\nf_t &= \\sigma(W_f x_t + U_f h_{t-1} + b_f) & \\text{（遗忘门）} \\\\\no_t &= \\sigma(W_o x_t + U_o h_{t-1} + b_o) & \\text{（输出门）} \\\\\ng_t &= \\tanh(W_g x_t + U_g h_{t-1} + b_g) & \\text{（细胞输入）} \\\\\nc_t &= f_t \\odot c_{t-1} + i_t \\odot g_t & \\text{（细胞状态）} \\\\\nh_t &= o_t \\odot \\tanh(c_t) & \\text{（隐藏状态）}\n\\end{align*}\n其中 $\\sigma$ 是 sigmoid 函数，$\\tanh$ 是双曲正切函数，$\\odot$ 是逐元素乘法。该模型处理一个大小为 $W$ 的固定大小的过去观测窗口。来自窗口的最终隐藏状态 $h_t$ 通过一个输出层来生成一个非负预测：\n$$ \\widehat{y}^{\\text{LSTM}}_{t+1} = \\log\\left(1 + \\exp\\left(v^\\top h_t + b_y\\right)\\right) $$\n这个函数被称为 softplus 函数。通过最小化训练数据上的均方误差来拟合完整的 LSTM 参数集 $\\theta = \\{W_{\\cdot}, U_{\\cdot}, b_{\\cdot}, v, b_y\\}$：\n$$ \\text{MSE}_{\\text{train}} = \\frac{1}{N_{\\text{train}}-W} \\sum_{t=W-1}^{N_{\\text{train}}-2} \\left(\\widehat{y}^{\\text{LSTM}}_{t+1} - r_{t+1}^2\\right)^2 $$\n这个非凸优化问题使用一种基于梯度的方法（L-BFGS-B）来求解。所需的梯度通过时间反向传播（BPTT）算法进行解析计算。参数初始化采用 Glorot 均匀初始化以帮助收敛。\n\n对于这两个模型，在训练数据上拟合后，都在测试集上评估其性能。测试期涉及进行 $N_{\\text{test}}$ 次单步向前预测。预测起始点为 $t = N_{\\text{train}}-1, \\ldots, N-2$，相应的目标是 $y_{t+1} = r_{t+1}^2$。为每个模型计算均方误差：\n$$ \\text{MSE} = \\frac{1}{N_{\\text{test}}} \\sum_{t=N_{\\text{train}}-1}^{N-2} \\left(\\widehat{y}_{t+1} - r_{t+1}^2\\right)^2 $$\n每个测试案例的最终决策是通过比较两个 MSE 值来确定的。如果 $\\text{MSE}_{\\text{LSTM}} < \\text{MSE}_{\\text{GARCH}}$，则赋值为 $1$，否则为 $0$。对所有三个指定的案例重复此过程。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass LSTMModel:\n    \"\"\"\n    Implementation of a single-layer LSTM for time series forecasting.\n    \"\"\"\n    def __init__(self, d, H, W, random_seed):\n        self.d = d  # Input dimension\n        self.H = H  # Hidden dimension\n        self.W = W  # Window size\n        self.rng = np.random.default_rng(random_seed)\n        \n        # Initialize parameters\n        self.params = self._initialize_params()\n\n    def _initialize_params(self):\n        # Glorot initialization\n        limit_w = np.sqrt(6 / (self.d + self.H))\n        limit_u = np.sqrt(6 / (self.H + self.H))\n        limit_v = np.sqrt(6 / (self.H + 1))\n\n        params = {\n            'W_i': self.rng.uniform(-limit_w, limit_w, (self.H, self.d)),\n            'U_i': self.rng.uniform(-limit_u, limit_u, (self.H, self.H)),\n            'b_i': np.zeros(self.H),\n            'W_f': self.rng.uniform(-limit_w, limit_w, (self.H, self.d)),\n            'U_f': self.rng.uniform(-limit_u, limit_u, (self.H, self.H)),\n            'b_f': np.zeros(self.H),\n            'W_o': self.rng.uniform(-limit_w, limit_w, (self.H, self.d)),\n            'U_o': self.rng.uniform(-limit_u, limit_u, (self.H, self.H)),\n            'b_o': np.zeros(self.H),\n            'W_g': self.rng.uniform(-limit_w, limit_w, (self.H, self.d)),\n            'U_g': self.rng.uniform(-limit_u, limit_u, (self.H, self.H)),\n            'b_g': np.zeros(self.H),\n            'v': self.rng.uniform(-limit_v, limit_v, self.H),\n            'b_y': np.zeros(1)\n        }\n        return params\n\n    def _unravel_params(self, param_vec):\n        p = self.params\n        d, H = self.d, self.H\n        s = 0\n        p['W_i'] = param_vec[s:s+H*d].reshape(H, d); s += H*d\n        p['U_i'] = param_vec[s:s+H*H].reshape(H, H); s += H*H\n        p['b_i'] = param_vec[s:s+H]; s += H\n        p['W_f'] = param_vec[s:s+H*d].reshape(H, d); s += H*d\n        p['U_f'] = param_vec[s:s+H*H].reshape(H, H); s += H*H\n        p['b_f'] = param_vec[s:s+H]; s += H\n        p['W_o'] = param_vec[s:s+H*d].reshape(H, d); s += H*d\n        p['U_o'] = param_vec[s:s+H*H].reshape(H, H); s += H*H\n        p['b_o'] = param_vec[s:s+H]; s += H\n        p['W_g'] = param_vec[s:s+H*d].reshape(H, d); s += H*d\n        p['U_g'] = param_vec[s:s+H*H].reshape(H, H); s += H*H\n        p['b_g'] = param_vec[s:s+H]; s += H\n        p['v'] = param_vec[s:s+H]; s += H\n        p['b_y'] = param_vec[s:s+1]; s += 1\n        return p\n\n    def _ravel_params(self):\n        return np.concatenate([p.ravel() for p in self.params.values()])\n\n    def _forward(self, x_window):\n        p = self.params\n        H = self.H\n        \n        # Cache for BPTT\n        cache = {\n            'h_states': { -1: np.zeros(H) },\n            'c_states': { -1: np.zeros(H) },\n            'gates': {},\n            'inputs': x_window,\n        }\n        \n        for t in range(self.W):\n            x_t = x_window[t]\n            h_prev = cache['h_states'][t - 1]\n            c_prev = cache['c_states'][t - 1]\n\n            i_t = self._sigmoid(p['W_i'] @ x_t + p['U_i'] @ h_prev + p['b_i'])\n            f_t = self._sigmoid(p['W_f'] @ x_t + p['U_f'] @ h_prev + p['b_f'])\n            o_t = self._sigmoid(p['W_o'] @ x_t + p['U_o'] @ h_prev + p['b_o'])\n            g_t = np.tanh(p['W_g'] @ x_t + p['U_g'] @ h_prev + p['b_g'])\n            \n            c_t = f_t * c_prev + i_t * g_t\n            h_t = o_t * np.tanh(c_t)\n\n            cache['h_states'][t] = h_t\n            cache['c_states'][t] = c_t\n            cache['gates'][t] = {'i': i_t, 'f': f_t, 'o': o_t, 'g': g_t, 'tanh_c': np.tanh(c_t)}\n\n        h_final = cache['h_states'][self.W - 1]\n        out_arg = p['v'] @ h_final + p['b_y']\n        y_hat = self._softplus(out_arg)\n        cache['out_arg'] = out_arg\n        \n        return y_hat, cache\n\n    def _objective_and_grad(self, param_vec, X_train, Y_train):\n        self.params = self._unravel_params(param_vec)\n        p = self.params\n        d, H = self.d, self.H\n        num_windows = len(X_train)\n        \n        total_mse = 0\n        \n        grad = {k: np.zeros_like(v) for k, v in self.params.items()}\n\n        for i in range(num_windows):\n            x_window, y_true = X_train[i], Y_train[i]\n            y_hat, cache = self._forward(x_window)\n            \n            total_mse += (y_hat - y_true)**2\n            \n            # BPTT\n            dL_dy = 2 * (y_hat - y_true)\n            \n            # Gradient of output layer\n            dL_da = dL_dy * self._sigmoid(cache['out_arg'])\n            grad['v'] += dL_da * cache['h_states'][self.W - 1]\n            grad['b_y'] += dL_da\n            \n            # Backpropagate to final hidden state\n            dh_next = dL_da * p['v']\n            dc_next = np.zeros(H)\n            \n            # Loop backwards through time\n            for t in reversed(range(self.W)):\n                h_t = cache['h_states'][t]\n                c_t = cache['c_states'][t]\n                c_prev = cache['c_states'][t-1]\n                h_prev = cache['h_states'][t-1]\n                x_t = cache['inputs'][t]\n                gates = cache['gates'][t]\n\n                dh = dh_next\n                dc = dc_next + dh * gates['o'] * (1 - gates['tanh_c']**2)\n                \n                # Gradients of gates from cell state\n                di = dc * gates['g']\n                df = dc * c_prev\n                do = dh * gates['tanh_c']\n                dg = dc * gates['i']\n\n                # Gradients of gate pre-activations\n                da_i = di * gates['i'] * (1 - gates['i'])\n                da_f = df * gates['f'] * (1 - gates['f'])\n                da_o = do * gates['o'] * (1 - gates['o'])\n                da_g = dg * (1 - gates['g']**2)\n\n                # Parameter gradients\n                grad['W_i'] += np.outer(da_i, x_t)\n                grad['W_f'] += np.outer(da_f, x_t)\n                grad['W_o'] += np.outer(da_o, x_t)\n                grad['W_g'] += np.outer(da_g, x_t)\n\n                grad['U_i'] += np.outer(da_i, h_prev)\n                grad['U_f'] += np.outer(da_f, h_prev)\n                grad['U_o'] += np.outer(da_o, h_prev)\n                grad['U_g'] += np.outer(da_g, h_prev)\n\n                grad['b_i'] += da_i\n                grad['b_f'] += da_f\n                grad['b_o'] += da_o\n                grad['b_g'] += da_g\n                \n                # Gradients for previous states\n                dh_next = p['U_i'].T @ da_i + p['U_f'].T @ da_f + p['U_o'].T @ da_o + p['U_g'].T @ da_g\n                dc_next = dc * gates['f']\n            \n        avg_mse = total_mse / num_windows\n        avg_grad_vec = np.concatenate([v.ravel() for v in grad.values()]) / num_windows\n\n        return avg_mse, avg_grad_vec\n\n    def fit(self, all_r, all_s):\n        W = self.W\n        N_train = len(all_r)\n        \n        # Create training windows and targets\n        X_train = np.array([np.stack((all_r[i:i+W], all_s[i:i+W]), axis=1) for i in range(N_train - W)])\n        Y_train = all_r[W:N_train]**2\n\n        objective_fn = lambda p: self._objective_and_grad(p, X_train, Y_train)[0]\n        grad_fn = lambda p: self._objective_and_grad(p, X_train, Y_train)[1]\n\n        res = minimize(\n            objective_fn,\n            self._ravel_params(),\n            method='L-BFGS-B',\n            jac=grad_fn,\n            options={'maxiter': 100}\n        )\n        self.params = self._unravel_params(res.x)\n\n    def predict_mse(self, all_r, all_s, N_train):\n        W = self.W\n        N = len(all_r)\n        \n        mse = 0\n        forecasts = []\n        targets = []\n        for t in range(N_train - 1, N - 1):\n            x_window = np.stack((all_r[t-W+1:t+1], all_s[t-W+1:t+1]), axis=1)\n            y_hat, _ = self._forward(x_window)\n            y_true = all_r[t+1]**2\n            mse += (y_hat - y_true)**2\n            forecasts.append(y_hat)\n            targets.append(y_true)\n            \n        return mse / len(targets)\n    \n    @staticmethod\n    def _sigmoid(x): return 1 / (1 + np.exp(-x))\n    @staticmethod\n    def _softplus(x): return np.log(1 + np.exp(x))\n\n\ndef generate_data(N, params, seed):\n    rng = np.random.default_rng(seed)\n    phi, sigma_eps, omega, alpha, beta, gamma = params\n    \n    epsilons = rng.normal(0, sigma_eps, size=N)\n    zs = rng.normal(0, 1, size=N)\n    \n    s = np.zeros(N)\n    h = np.zeros(N)\n    r = np.zeros(N)\n    \n    s[0] = 0\n    h[0] = omega\n    r[0] = np.sqrt(h[0]) * zs[0]\n    \n    for t in range(1, N):\n        s[t] = phi * s[t-1] + epsilons[t]\n        h[t] = omega + alpha * r[t-1]**2 + beta * h[t-1] + gamma * max(s[t-1], 0)**2\n        h[t] = max(h[t], 1e-9) # Ensure positivity\n        r[t] = np.sqrt(h[t]) * zs[t]\n        \n    return r, s\n\ndef garch_loglike(params, r_train):\n    omega, alpha, beta = params\n    N_train = len(r_train)\n    \n    h = np.zeros(N_train)\n    h[0] = np.var(r_train)\n    \n    for t in range(1, N_train):\n        h[t] = omega + alpha * r_train[t-1]**2 + beta * h[t-1]\n        if h[t] <= 0: return 1e9 # Penalize invalid parameters\n    \n    loglikelihood = -np.sum(-0.5 * np.log(2 * np.pi * h[1:]) - 0.5 * r_train[1:]**2 / h[1:])\n    return loglikelihood\n\ndef fit_and_eval_garch(r, N_train):\n    r_train = r[:N_train]\n    \n    # Fit GARCH(1,1)\n    cons = ({'type': 'ineq', 'fun': lambda x: 1 - x[1] - x[2]})\n    bnds = ((1e-9, None), (0, 1), (0, 1))\n    initial_params = [np.var(r_train) * 0.1, 0.1, 0.8]\n    \n    res = minimize(garch_loglike, initial_params, args=(r_train,),\n                   method='SLSQP', bounds=bnds, constraints=cons)\n    omega_hat, alpha_hat, beta_hat = res.x\n    \n    # Evaluate on test set\n    N = len(r)\n    h_filtered = np.zeros(N)\n    h_filtered[0] = np.var(r_train)\n    for t in range(1, N):\n        h_filtered[t] = omega_hat + alpha_hat * r[t-1]**2 + beta_hat * h_filtered[t-1]\n\n    forecasts = omega_hat + alpha_hat * r[N_train-1:N-1]**2 + beta_hat * h_filtered[N_train-1:N-1]\n    targets = r[N_train:]**2\n    \n    mse_garch = np.mean((forecasts - targets)**2)\n    return mse_garch\n\n\ndef solve():\n    test_cases = [\n        # Case A: Predictive sentiment\n        {'phi': 0.8, 'sigma_eps': 0.5, 'omega': 2.5e-5, 'alpha': 0.08, 'beta': 0.86, 'gamma': 1.5e-4, 'seed': 12345, 'W': 10, 'H': 6},\n        # Case B: No sentiment effect\n        {'phi': 0.8, 'sigma_eps': 0.5, 'omega': 8e-6, 'alpha': 0.08, 'beta': 0.90, 'gamma': 0.0, 'seed': 54321, 'W': 10, 'H': 6},\n        # Case C: Nearly constant volatility\n        {'phi': 0.8, 'sigma_eps': 0.5, 'omega': 4e-4, 'alpha': 0.0, 'beta': 0.0, 'gamma': 0.0, 'seed': 202311, 'W': 10, 'H': 6},\n    ]\n\n    N = 220\n    N_train = 170\n    d = 2\n    \n    results = []\n    \n    for case in test_cases:\n        params_dgp = (case['phi'], case['sigma_eps'], case['omega'],\n                      case['alpha'], case['beta'], case['gamma'])\n        \n        # Generate data\n        r, s = generate_data(N, params_dgp, case['seed'])\n        r_train, s_train = r[:N_train], s[:N_train]\n        \n        # Fit and evaluate GARCH\n        mse_garch = fit_and_eval_garch(r, N_train)\n        \n        # Fit and evaluate LSTM\n        # Use a fixed seed for LSTM initialization for reproducibility\n        lstm = LSTMModel(d=d, H=case['H'], W=case['W'], random_seed=case['seed'] + 1)\n        lstm.fit(r_train, s_train)\n        mse_lstm = lstm.predict_mse(r, s, N_train)\n\n        results.append(1 if mse_lstm < mse_garch else 0)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```"}]}