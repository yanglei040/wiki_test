{"hands_on_practices": [{"introduction": "在超阈值（POT）方法的实际应用中，阈值 $u$ 的选择是一个关键步骤，它直接影响到模型估计的准确性。这个选择本质上是在偏差和方差之间进行权衡：过低的阈值会违反极值理论的渐近假设，从而引入偏差；而过高的阈值则会导致尾部数据过少，从而增大估计量的方差。本练习旨在通过一个具体的计算任务，让你亲身体验并量化这种敏感性。你将对一个模拟的金融时间序列，在不同分位数上选取阈值，并观察估计出的尾部指数 $ξ$ 如何随之变化，从而深刻理解阈值选择在极值分析中的核心地位。[@problem_id:2418694]", "id": "2418694", "problem": "考虑一个合成的每日对数收益率序列，其旨在为尾部风险分析近似标准普尔500指数（S&amp;P 500）每日收益率的分布特征。设每日对数收益率表示为 $R_t$，$t = 1, \\dots, n$，并定义 $R_t = \\mu + \\sigma \\cdot T_\\nu$，其中 $T_\\nu$ 是一个自由度为 $\\nu$、位置为 $0$、单位尺度的学生 $t$ 分布随机变量。使用 $n = 6000$，$\\mu = 0$，$\\sigma = 0.01$，$\\nu = 5$，以及一个固定的伪随机数生成器种子 $s = 20240517$ 以确保可复现性。定义损失为 $L_t = -R_t$。\n\n对于任意阈值 $u$，将超出量定义为 $Y_i = L_i - u$，适用于所有满足 $L_i > u$ 的索引 $i$。在超阈值峰值（POT）模型下，假设超出量 $Y_i$ 服从一个广义帕累托分布（GPD），其尾部指数为 $\\xi$，尺度为 $\\beta$。\n\n您的任务是通过计算在下述测试套件中每个阈值下，从超过 $u$ 的超出量中获得的 $\\xi$ 的估计值，来量化所估计的尾部指数 $\\xi$ 对阈值 $u$ 选择的敏感性。对于每个阈值，将 $u$ 设置为给定分位数水平 $q$ 下损失 $L_t$ 的经验 $q$-分位数。\n\n测试套件（用于阈值的分位数水平）：$q \\in \\{0.80, 0.90, 0.95, 0.975, 0.99, 0.995, 0.999\\}$。\n\n对于测试套件中的每个 $q$，计算对应的 $\\xi$ 估计值（一个实数）。最终输出要求为单行文本，其中包含按指定顺序排列的各阈值的结果，四舍五入到 $6$ 位小数，并以逗号分隔的列表形式置于方括号内。例如，包含三个结果的输出应形如 $[x_1,x_2,x_3]$，其中每个 $x_j$ 是一个四舍五入到 $6$ 位小数的十进制数。\n\n您的程序必须生成单行输出，其中包含格式和顺序完全符合要求的估计值，不得包含任何额外文本。不涉及物理单位。不涉及角度。不涉及百分比。答案必须是实值浮点数。", "solution": "提交分析的问题陈述被认为是有效的。它提出了一个在计算金融领域中定义明确、有科学依据的问题，具体涉及极值理论（EVT）中的超阈值峰值（POT）方法的应用。所有参数和条件都已明确，从而可以得到一个唯一且可复现的解。该方法论基于已确立的统计学原理。\n\n问题的核心在于应用 Pickands–Balkema–de Haan 定理。该定理假定，对于一大类具有重尾的分布，超过一个足够高阈值的超出量的条件分布会收敛于一个广义帕累托分布（GPD）。所指定的数据模型 $R_t = \\mu + \\sigma \\cdot T_\\nu$ 是此类重尾过程的一个典型例子，其中 $T_\\nu$ 是一个自由度为 $\\nu$ 的学生 $t$ 分布随机变量。对于自由度为 $\\nu$ 的学生 $t$ 分布，理论上的 GPD 尾部指数为 $\\xi = 1/\\nu$。在本问题中，$\\nu=5$，因此尾部指数的理论期望值为 $\\xi = 1/5 = 0.2$。本练习旨在从有限样本中估计该参数，并观察其对阈值选择的敏感性。\n\n计算流程如下：\n\n1.  **数据生成**：创建一个合成数据集来模拟金融损失。从一个自由度为 $\\nu=5$、位置为 $0$、单位尺度的学生 $t$ 分布中生成一个包含 $n=6000$ 个点的样本。这些点（表示为 $T_t$）使用给定的参数 $\\mu=0$ 和 $\\sigma=0.01$ 转换为对数收益率 $R_t = \\mu + \\sigma \\cdot T_t$。相应的损失则定义为 $L_t = -R_t$。使用固定种子 $s=20240517$ 确保了所生成数据的绝对可复现性。\n\n2.  **阈值选择**：问题要求分析对阈值 $u$ 的敏感性。为此，根据生成的损失数据 $L_t$ 的经验分位数选择一系列阈值。对于测试套件 $\\{0.80, 0.90, 0.95, 0.975, 0.99, 0.995, 0.999\\}$ 中的每个分位数水平 $q$，阈值 $u$ 被设置为满足 $P(L_t \\le u) = q$ 的值。\n\n3.  **超出量计算**：对每个阈值 $u$，都编制一个超出量集合。这些值是 $Y_i = L_i - u$，适用于所有严格大于 $u$ 的观测值 $L_i$。这组 $Y_i$ 值代表了将要拟合 GPD 的数据。\n\n4.  **GPD参数估计**：GPD 的尾部指数 $\\xi$ 是根据超出量序列 $\\{Y_i\\}$ 估计的。估计此参数的标准且最可靠的方法是最大似然估计（MLE），本例将采用此方法。GPD 由一个形状参数（尾部指数 $\\xi$）和一个尺度参数 $\\beta$ 来表征。根据 POT 模型，超出量本质上是正数，因此 GPD 的位置参数理论上为 $0$。在拟合过程中强制执行此约束（在 `scipy` 实现中使用 `floc=0`），以提高估计的稳定性和理论正确性。MLE 过程计算出使观测到的超出量数据的概率最大化的 $\\xi$ 值。\n\n从阈值选择到 GPD 拟合的整个过程，对测试套件中的每个分位数水平 $q$ 都会重复一遍。所得到的估计尾部指数序列 $\\hat{\\xi}(q)$ 展示了阈值选择对尾部风险度量的实际影响。预计随着 $q$ 接近 $1$，阈值 $u$ 会增加，GPD 近似会变得更加准确，并且估计值 $\\hat{\\xi}$ 应收敛于理论值 $0.2$。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import t, genpareto\n\ndef solve():\n    \"\"\"\n    Computes the sensitivity of the GPD tail index estimate to the threshold choice\n    for a synthetic financial loss series based on the Peaks-Over-Threshold method.\n    \"\"\"\n    # --- Problem Parameters ---\n    n = 6000\n    mu = 0.0\n    sigma = 0.01\n    nu = 5.0\n    seed = 20240517\n    \n    # --- Test Suite ---\n    # The quantile levels for threshold selection define the test cases.\n    test_cases = [0.80, 0.90, 0.95, 0.975, 0.99, 0.995, 0.999]\n    \n    # --- Data Generation ---\n    # Use a specific random number generator for reproducibility as per problem statement.\n    rng = np.random.default_rng(seed)\n    \n    # Generate random variates from Student's t-distribution with nu degrees of freedom.\n    # T_nu is a standard t-distribution (location=0, scale=1).\n    T_nu = t.rvs(df=nu, size=n, random_state=rng)\n    \n    # Calculate log-returns R_t and losses L_t based on the generated variates.\n    R_t = mu + sigma * T_nu\n    L_t = -R_t\n    \n    # --- Main Logic: POT Analysis for each threshold ---\n    results = []\n    for q in test_cases:\n        # 1. Set the threshold 'u' as the empirical q-quantile of the losses.\n        u = np.quantile(L_t, q)\n        \n        # 2. Identify all losses exceeding the threshold and compute the exceedance values.\n        # Exceedances are defined as Y_i = L_i - u for all L_i > u.\n        exceedances = L_t[L_t > u] - u\n        \n        # 3. Fit a Generalized Pareto Distribution (GPD) to the exceedances.\n        # We use Maximum Likelihood Estimation (MLE), as implemented in scipy.\n        # The POT model implies a location parameter of 0 for exceedances, which we fix\n        # using the 'floc=0' argument for theoretical consistency and numerical stability.\n        # The 'c' shape parameter returned by the fit corresponds to the tail index 'xi'.\n        xi, _, _ = genpareto.fit(exceedances, floc=0)\n        \n        results.append(xi)\n\n    # --- Final Output Formatting ---\n    # The problem requires the results to be rounded to 6 decimal places and\n    # formatted as a comma-separated list within square brackets.\n    formatted_results = [f'{r:.6f}' for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nif __name__ == '__main__':\n    solve()\n```"}, {"introduction": "极值理论（EVT）的一个强大应用是检验金融市场的风险结构是否随时间发生了变化，例如在重大金融危机前后。本练习将引导你完成一个完整的统计推断流程，以回答“市场的尾部风险是否在危机后变得更重”这类实际问题。你将不再仅仅是估计参数，而是要学习如何使用这些估计值进行严格的假设检验。通过对两个模拟时期（危机前和危机后）的尾部指数 $ξ$ 进行比较，并运用沃尔德检验（Wald test）来判断其差异的统计显著性，你将掌握一套用于识别金融数据结构性变化的实用工具。[@problem_id:2418723]", "id": "2418723", "problem": "考虑代表金融市场危机前和危机后时期的两个独立模拟日对数回报率样本。峰值超越阈值（peaks-over-threshold）框架假设，对于一个高阈值 $u$，超额量 $Y = X - u \\mid X > u$ 的条件分布近似为广义帕累托分布（Generalized Pareto Distribution, GPD），其形状参数为 $\\xi$，尺度参数为 $\\beta$。参数为 $(\\xi,\\beta)$ 的广义帕累托分布（GPD）的支撑集在 $\\xi \\ge 0$ 时为 $y \\ge 0$，在 $\\xi < 0$ 时为 $0 \\le y < -\\beta/\\xi$。其累积分布函数为\n$$\nF(y \\mid \\xi,\\beta) = \n\\begin{cases}\n1 - \\left(1 + \\dfrac{\\xi y}{\\beta}\\right)^{-1/\\xi}, & \\xi \\ne 0, \\\\\n1 - \\exp\\!\\left(-\\dfrac{y}{\\beta}\\right), & \\xi = 0,\n\\end{cases}\n\\quad \\text{for } \\beta > 0.\n$$\n在 GPD 模型下，超额量 $(y_1,\\dots,y_k)$ 的有限样本负对数似然函数为\n$$\n\\ell(\\xi,\\beta; y_{1:k}) =\n\\begin{cases}\nk \\log \\beta + \\left(1+\\dfrac{1}{\\xi}\\right)\\displaystyle\\sum_{i=1}^k \\log\\!\\left(1 + \\dfrac{\\xi y_i}{\\beta}\\right), & \\xi \\ne 0, \\\\\nk \\log \\beta + \\dfrac{1}{\\beta}\\displaystyle\\sum_{i=1}^k y_i, & \\xi = 0,\n\\end{cases}\n$$\n受制于支撑集约束 $1 + \\xi y_i/\\beta > 0$（对所有 $i$）和 $\\beta > 0$。最大似然估计量 $(\\hat{\\xi},\\hat{\\beta})$ 被定义为最小化 $\\ell(\\xi,\\beta; y_{1:k})$ 的任意参数对。观测信息矩阵是在 $(\\hat{\\xi},\\hat{\\beta})$ 处求值的 $\\ell$ 的 Hessian 矩阵，其逆矩阵近似于 $(\\hat{\\xi},\\hat{\\beta})$ 的协方差矩阵；特别地，$\\hat{\\xi}$ 的近似方差是该逆矩阵的 $(1,1)$ 项。\n\n您将使用显著性水平 $\\alpha = 0.05$ 的双边瓦尔德检验（Wald test）来检验形状（尾部指数）参数在危机前和危机后时期之间是否发生了变化：\n$$\nH_0: \\ \\xi_{\\text{pre}} = \\xi_{\\text{post}}\n\\quad \\text{versus} \\quad\nH_1: \\ \\xi_{\\text{pre}} \\ne \\xi_{\\text{post}}.\n$$\n设 $\\hat{\\xi}_{\\text{pre}}$ 和 $\\hat{\\xi}_{\\text{post}}$ 分别为从各自样本中得到的最大似然估计量，其近似标准误 $s_{\\text{pre}}$和 $s_{\\text{post}}$ 从观测信息协方差矩阵中获得。瓦尔德统计量为\n$$\nZ = \\dfrac{\\hat{\\xi}_{\\text{pre}} - \\hat{\\xi}_{\\text{post}}}{\\sqrt{s_{\\text{pre}}^2 + s_{\\text{post}}^2}},\n$$\n如果 $|Z| \\ge z_{1-\\alpha/2}$，则拒绝 $H_0$，其中 $z_{1-\\alpha/2}$ 是标准正态分布的 $(1-\\alpha/2)$ 分位数。\n\n每个时期的数据生成方式如下。固定一个基准阈值水平 $u_0 = 0$ 和一个尾部混合概率 $p_{\\text{tail}} \\in (0,1)$。通过连接以下部分生成 $n$ 个独立观测值：\n- 大小为 $n - m$ 的“主体”部分，其中 $m = \\lfloor p_{\\text{tail}} n \\rceil$，从支撑集为 $(-\\infty, u_0]$ 的连续分布中抽取；此处使用 $[-3, u_0]$ 上的均匀分布。\n- 大小为 $m$ 的“尾部”部分，构造为 $u_0 + Y$，其中 $Y$ 是独立的 GPD$(\\xi,\\beta)$ 随机变量，其参数 $(\\xi,\\beta)$ 为该时期指定的值。\n\n对于每个时期和测试用例，将阈值 $u$ 设置为模拟样本的经验 $q$-分位数，其中 $q=0.9$。将超额量定义为所有 $X_i > u$ 的 $Y_i = X_i - u$。\n\n您的程序必须对下面的每个测试用例执行以下操作：\n1. 使用指定的参数和独立的随机种子，模拟危机前和危机后的样本。\n2. 为每个时期分别计算分位数水平 $q = 0.9$ 处的经验阈值 $u$。\n3. 形成各自阈值以上的超额量 $Y_i$。\n4. 通过在支撑集约束下最小化精确的有限样本负对数似然函数 $\\ell(\\xi,\\beta; y_{1:k})$，为每个时期计算最大似然估计量 $(\\hat{\\xi},\\hat{\\beta})$。\n5. 使用最大似然估计量处的观测信息矩阵的逆矩阵，为每个时期近似 $\\hat{\\xi}$ 的标准误。\n6. 在显著性水平 $\\alpha = 0.05$ 下，执行 $H_0: \\xi_{\\text{pre}} = \\xi_{\\text{post}}$ 的双边瓦尔德检验。\n7. 输出一个布尔值，指示尾部指数是否存在统计上显著的变化（如果拒绝 $H_0$，则输出 true；否则输出 false）。\n\n测试套件（每个元组按 $(\\text{seed}_{\\text{pre}}, \\text{seed}_{\\text{post}}, n_{\\text{pre}}, n_{\\text{post}}, \\xi_{\\text{pre}}, \\beta_{\\text{pre}}, \\xi_{\\text{post}}, \\beta_{\\text{post}})$ 的顺序对应一个测试用例），共同参数为 $u_0 = 0$, $p_{\\text{tail}} = 0.25$, $q = 0.9$ 和 $\\alpha = 0.05$：\n- 案例 A: $(12345, 54321, 5000, 5000, 0.2, 1.0, 0.6, 1.0)$。\n- 案例 B: $(111, 222, 4000, 4000, 0.2, 1.0, 0.2, 1.0)$。\n- 案例 C: $(333, 444, 6000, 6000, 0.01, 1.0, 0.0, 1.0)$。\n- 案例 D: $(555, 666, 6000, 6000, -0.15, 1.2, 0.15, 1.2)$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表内容为按测试用例顺序排列的结果，例如：“[true,false,true,false]”。布尔值必须全部为小写。", "solution": "该问题要求执行一项统计假设检验，以确定由广义帕累托分布（GPD）建模的金融回报率的尾部行为是否在两个时期之间发生了变化。这是极值理论（Extreme Value Theory, EVT）在量化金融中的一个标准应用。验证过程确认了问题陈述在科学上是合理的、定义明确的，并包含得出唯一、可验证解所需的所有必要信息。\n\n解决方案系统地按以下步骤进行：数据模拟、通过最大似然法进行参数估计，以及使用瓦尔德检验进行假设检验。\n\n**1. 数据模拟和预处理**\n\n每个时期（危机前和危机后）的数据都是从一个混合分布中生成的，该分布被设计为具有特定的尾部行为。对于一个大小为 $n$ 的样本，比例为 $p_{\\text{tail}}$ 的数据点构成“尾部”，从 GPD 中抽取。其余的点构成分布的“主体”。\n\n-   **主体（Body）**：从 $[-3, u_0]$ 上的均匀分布中抽取 $n - m$ 个样本，其中 $m = \\lfloor p_{\\text{tail}} n \\rceil$，基准阈值为 $u_0 = 0$。\n-   **尾部（Tail）**：生成 $m$ 个样本，形式为 $u_0 + Y_i$，其中 $Y_i$ 是独立的 GPD$(\\xi, \\beta)$ 随机变量。\n\n要从 GPD$(\\xi, \\beta)$ 生成一个随机变量 $Y$，我们使用逆变换采样法。分位数函数 $F^{-1}(p)$ 是通过对 GPD 累积分布函数（CDF）$F(y)$ 求逆得出的。给定一个均匀随机变量 $U \\sim U(0,1)$，一个 GPD 变量 $Y$ 按如下方式生成：\n$$\nY = F^{-1}(U) = \n\\begin{cases}\n\\dfrac{\\beta}{\\xi} \\left( (1-U)^{-\\xi} - 1 \\right), & \\xi \\ne 0, \\\\\n-\\beta \\log(1-U), & \\xi = 0.\n\\end{cases}\n$$\n由于 $1-U$ 也服从 $(0,1)$ 上的均匀分布，这等效于在表达式中直接使用 $U$。\n\n在模拟完完整样本 $X = \\{X_1, \\dots, X_n\\}$ 后，我们应用峰值超越阈值（POT）方法。我们将样本的经验 $q$-分位数（其中 $q=0.9$）设为高阈值 $u$。然后将超额量定义为所有 $X_i > u$ 对应的正值 $Y_i = X_i - u$。这些超额量构成了拟合 GPD 模型的数据集。\n\n**2. 最大似然估计 (MLE)**\n\n对于每个时期，GPD 的参数 $(\\xi, \\beta)$ 是通过最大化对数似然函数，或等效地，最小化负对数似然函数 $\\ell(\\xi, \\beta)$ 来估计的。对于一组 $k$ 个超额量 $\\{y_1, \\dots, y_k\\}$，负对数似然函数由下式给出：\n$$\n\\ell(\\xi,\\beta; y_{1:k}) =\n\\begin{cases}\nk \\log \\beta + \\left(1+\\dfrac{1}{\\xi}\\right)\\displaystyle\\sum_{i=1}^k \\log\\!\\left(1 + \\dfrac{\\xi y_i}{\\beta}\\right), & \\xi \\ne 0, \\\\\nk \\log \\beta + \\dfrac{1}{\\beta}\\displaystyle\\sum_{i=1}^k y_i, & \\xi = 0.\n\\end{cases}\n$$\n这个最小化过程是一个数值优化问题。当 $\\xi \\to 0$ 时，$\\xi \\ne 0$ 的函数形式收敛于 $\\xi = 0$ 的函数形式。为确保数值稳定性，我们通过一个条件分支来实现目标函数，对接近零的 $\\xi$ 值（例如，$|\\xi| < 10^{-8}$）使用其极限形式。\n\n最小化受以下约束：$\\beta > 0$，并且为了使对数项有意义，对所有超额量 $y_i$ 都有 $1 + \\xi y_i/\\beta > 0$。当 $\\xi < 0$ 时，后一个约束意味着 $y_i < -\\beta/\\xi$。这些约束在目标函数内部强制执行，如果违反约束，则返回一个大值（代表无穷大），从而有效地创建一个屏障，引导优化器走向有效的参数空间。优化过程使用 `scipy.optimize.minimize` 提供的 Broyden–Fletcher–Goldfarb–Shanno (BFGS) 算法执行。\n\n**3. 标准误近似**\n\n根据最大似然估计（MLE）的大样本理论，估计量 $(\\hat{\\xi}, \\hat{\\beta})$ 的渐近协方差矩阵可以通过观测信息矩阵 $I(\\hat{\\xi}, \\hat{\\beta})$ 的逆矩阵来近似。观测信息矩阵是在最大似然估计（MLE）处求值的负对数似然函数的 Hessian 矩阵：\n$$\n\\text{Cov}(\\hat{\\xi}, \\hat{\\beta}) \\approx [I(\\hat{\\xi}, \\hat{\\beta})]^{-1} = \\left[ \\nabla^2 \\ell(\\hat{\\xi}, \\hat{\\beta}) \\right]^{-1}.\n$$\nBFGS 算法作为一种拟牛顿法，在其过程中会计算 Hessian 矩阵逆矩阵的近似值。这个近似值可以从优化结果中直接获得。形状参数估计量的方差 $\\text{Var}(\\hat{\\xi})$，由该逆 Hessian 矩阵的左上角元素近似。相应的标准误是其平方根：\n$$\ns_{\\hat{\\xi}} = \\sqrt{\\left( [I(\\hat{\\xi}, \\hat{\\beta})]^{-1} \\right)_{1,1}}.\n$$\n\n**4. 参数相等的瓦尔德检验**\n\n为了检验尾部指数没有变化的假设 $H_0: \\xi_{\\text{pre}} = \\xi_{\\text{post}}$（备择假设为 $H_1: \\xi_{\\text{pre}} \\ne \\xi_{\\text{post}}$），我们使用双边瓦尔德检验。该检验统计量由来自两个独立样本（危机前和危机后）的最大似然估计量（MLEs）及其标准误构造而成：\n$$\nZ = \\dfrac{\\hat{\\xi}_{\\text{pre}} - \\hat{\\xi}_{\\text{post}}}{\\sqrt{s_{\\text{pre}}^2 + s_{\\text{post}}^2}}.\n$$\n在原假设下，统计量 $Z$ 服从渐近标准正态分布 $N(0,1)$。在显著性水平 $\\alpha$ 下，如果观测统计量的绝对值 $|Z|$ 超过临界值 $z_{1-\\alpha/2}$，我们就拒绝 $H_0$。临界值 $z_{1-\\alpha/2}$ 是标准正态分布的 $(1-\\alpha/2)$-分位数。对于 $\\alpha = 0.05$，临界值为 $z_{0.975} \\approx 1.96$。\n\n整个流程被封装在一个程序中，该程序遍历所提供的测试用例，对每个用例执行模拟、估计和检验，并报告是否拒绝原假设。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the GPD tail index comparison.\n    \"\"\"\n    test_cases = [\n        # (seed_pre, seed_post, n_pre, n_post, xi_pre, beta_pre, xi_post, beta_post)\n        (12345, 54321, 5000, 5000, 0.2, 1.0, 0.6, 1.0),\n        (111, 222, 4000, 4000, 0.2, 1.0, 0.2, 1.0),\n        (333, 444, 6000, 6000, 0.01, 1.0, 0.0, 1.0),\n        (555, 666, 6000, 6000, -0.15, 1.2, 0.15, 1.2),\n    ]\n\n    common_params = {\n        'u0': 0.0,\n        'p_tail': 0.25,\n        'q': 0.9,\n        'alpha': 0.05,\n    }\n\n    results = []\n    for case in test_cases:\n        seed_pre, seed_post, n_pre, n_post, xi_pre, beta_pre, xi_post, beta_post = case\n        \n        # Fit pre-crisis period\n        xi_hat_pre, se_pre = fit_gpd_for_period(\n            seed_pre, n_pre, xi_pre, beta_pre, common_params\n        )\n        \n        # Fit post-crisis period\n        xi_hat_post, se_post = fit_gpd_for_period(\n            seed_post, n_post, xi_post, beta_post, common_params\n        )\n        \n        # Perform Wald test\n        wald_statistic = (xi_hat_pre - xi_hat_post) / np.sqrt(se_pre**2 + se_post**2)\n        critical_value = norm.ppf(1 - common_params['alpha'] / 2)\n        \n        reject_h0 = np.abs(wald_statistic) >= critical_value\n        results.append(str(reject_h0).lower())\n\n    print(f\"[{','.join(results)}]\")\n\ndef fit_gpd_for_period(seed, n, xi, beta, params):\n    \"\"\"\n    Simulates data and fits a GPD model for a single period.\n    Returns the estimated shape parameter and its standard error.\n    \"\"\"\n    X = simulate_data(seed, n, xi, beta, params['p_tail'], params['u0'])\n    \n    u = np.quantile(X, params['q'])\n    Y = X[X > u] - u\n    \n    # It's possible, though unlikely, that there are no exceedances\n    if len(Y) == 0:\n        raise ValueError(\"No exceedances found for GPD fitting.\")\n\n    # Objective function: negative log-likelihood for GPD\n    def nll_gpd(p, y_data):\n        _xi, _beta = p\n        \n        # Constraint: beta > 0\n        if _beta <= 1e-6:\n            return np.inf\n            \n        # Support constraint: 1 + xi*y/beta > 0\n        terms = 1 + _xi * y_data / _beta\n        if np.any(terms <= 0):\n            return np.inf\n\n        k = len(y_data)\n        \n        if abs(_xi) < 1e-8:\n            # Case xi -> 0 (Exponential distribution)\n            neg_log_lik = k * np.log(_beta) + np.sum(y_data) / _beta\n        else:\n            # Case xi != 0\n            log_of_terms = np.log(terms)\n            neg_log_lik = k * np.log(_beta) + (1 + 1/_xi) * np.sum(log_of_terms)\n\n        if not np.isfinite(neg_log_lik):\n            return np.inf\n            \n        return neg_log_lik\n\n    # Initial guess for optimization\n    initial_guess = [0.1, np.std(Y) if len(Y) > 1 else 1.0]\n\n    # Run optimizer to find MLE\n    res = minimize(\n        nll_gpd,\n        initial_guess,\n        args=(Y,),\n        method='BFGS',\n        options={'gtol': 1e-8}\n    )\n\n    if not res.success:\n        # A failed optimization might require more robust initial values or optimizer choice\n        # For this problem, we assume `BFGS` with this initial guess suffices.\n        pass\n\n    xi_hat, _ = res.x\n    \n    # Approximate variance from the inverse Hessian\n    var_xi = res.hess_inv[0, 0]\n    \n    # Handle potential numerical instability if variance is negative\n    if var_xi < 0:\n        # This shouldn't happen with BFGS, which maintains a positive definite Hess approx.\n        # But as a safeguard:\n        var_xi = np.abs(var_xi)\n\n    se_xi = np.sqrt(var_xi)\n    \n    return xi_hat, se_xi\n\ndef simulate_data(seed, n, xi, beta, p_tail, u0):\n    \"\"\"\n    Generates a sample from the mixture distribution.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    m = int(round(p_tail * n))\n    n_body = n - m\n    \n    # Generate the \"body\" of the distribution\n    body = rng.uniform(-3.0, u0, size=n_body)\n    \n    # Generate the \"tail\" using GPD inverse transform sampling\n    U = rng.uniform(size=m)\n    if abs(xi) < 1e-8:\n        tail_excess = -beta * np.log(U)\n    else:\n        tail_excess = (beta / xi) * (np.power(U, -xi) - 1)\n        \n    tail = u0 + tail_excess\n    \n    return np.concatenate((body, tail))\n\nif __name__ == \"__main__\":\n    solve()\n```"}, {"introduction": "理论模型往往假设数据来自一个单一、纯粹的分布，但现实世界的金融数据可能更为复杂，可能由多种不同的潜在过程混合而成。这个练习将向你展示如何利用超阈值（POT）方法的特性，来诊断和识别这种潜在的数据混合现象。其核心原理是，对于一个纯粹的重尾分布，在不同的高阈值下估计出的尾部指数 $ξ$ 应该是相对稳定的。然而，如果数据是一个由不同尾部行为的分布混合而成，估计出的 $ξ$ 将会随着阈值的变化而系统性地漂移。通过构建一个检测统计量来捕捉这种不稳定性，本练习让你学会将POT方法作为一个精密的诊断工具，以揭示数据背后隐藏的结构。[@problem_id:2418705]", "id": "2418705", "problem": "一位金融风险分析师正在使用“超阈峰值 (Peaks-Over-Threshold, POT)”框架来研究极端投资组合损失的分布。设 $X$ 表示一个严格为正的损失随机变量。假设 $X$ 由两个帕累托分布的混合生成，这两个分布具有共同的尺度参数 $m$ 和尾部指数 $\\alpha_{1}$ 和 $\\alpha_{2}$。具体来说，$X$ 以概率 $w$ 服从尾部指数为 $\\alpha_{1}$ 的帕累托分布，以概率 $1-w$ 服从尾部指数为 $\\alpha_{2}$ 的帕累托分布。对于 $x \\ge m$，尺度为 $m$、尾部指数为 $\\alpha$ 的帕累托分布的累积分布函数为 $F(x) = 1 - \\left(\\frac{m}{x}\\right)^{\\alpha}$。根据此混合分布，独立同分布地生成一个大小为 $n$ 的样本。\n\n对于阈值 $u \\ge m$，在 $X > u$ 的条件下，定义超出量随机变量 $Y = X - u$。在超阈峰值 (POT) 方法下，$Y$ 的分布由广义帕累托分布 (Generalized Pareto Distribution, GPD) 建模，其形状参数为 $\\xi$，尺度参数为 $\\beta$，密度函数由下式给出：\n$$\nf_{Y}(y \\mid \\xi, \\beta) = \\begin{cases}\n\\frac{1}{\\beta} \\left(1 + \\xi \\frac{y}{\\beta}\\right)^{-\\left(1+\\frac{1}{\\xi}\\right)}, & \\text{若 } \\xi \\ne 0, \\ y \\ge 0, \\ 1 + \\xi \\frac{y}{\\beta} > 0, \\\\\n\\frac{1}{\\beta} \\exp\\left(-\\frac{y}{\\beta}\\right), & \\text{若 } \\xi = 0, \\ y \\ge 0,\n\\end{cases}\n$$\n其中 $\\beta > 0$。GPD 下独立超出量 $y_{1}, \\ldots, y_{k}$ 的对数似然函数为：\n$$\n\\ell(\\xi, \\beta; y_{1}, \\ldots, y_{k}) = \\begin{cases}\n- k \\log \\beta - \\left(1 + \\frac{1}{\\xi}\\right) \\sum_{i=1}^{k} \\log \\left( 1 + \\xi \\frac{y_{i}}{\\beta} \\right), & \\text{若 } \\xi \\ne 0, \\\\\n- k \\log \\beta - \\frac{1}{\\beta} \\sum_{i=1}^{k} y_{i}, & \\text{若 } \\xi = 0.\n\\end{cases}\n$$\n\n考虑一个基于分位数的阈值网格点。对于给定的样本 $x_{1}, \\ldots, x_{n}$，令 $u(q)$表示经验 $q$-分位数，对于有限的分位数集合 $Q = \\{q_{1}, \\ldots, q_{J}\\}$，定义超出量集合 $E(q_{j}) = \\{ x_{i} - u(q_{j}) : x_{i} > u(q_{j}) \\}$。对于每个 $q_{j} \\in Q$，将最大似然估计量 $(\\hat{\\xi}(q_{j}), \\hat{\\beta}(q_{j}))$ 定义为在满足定义域约束的所有 $\\xi \\in \\mathbb{R}$ 和 $\\beta > 0$ 上，$\\ell(\\xi, \\beta; E(q_{j}))$ 的任何最大化者。\n\n定义检测统计量\n$$\nS = \\max_{q \\in Q} \\hat{\\xi}(q) - \\min_{q \\in Q} \\hat{\\xi}(q).\n$$\n给定一个容差 $\\tau > 0$，如果 $S > \\tau$，则声明检测到混合分布；如果 $S \\le \\tau$，则声明未检测到混合分布。\n\n实现一个程序，对以下每个指定的测试用例，执行以下任务：从指定的帕累托混合分布中模拟一个独立同分布的样本 $x_{1}, \\ldots, x_{n}$，为每个 $q \\in Q$ 计算阈值 $u(q)$，计算超出量集合 $E(q)$，为每个 $q \\in Q$ 计算最大似然估计量 $\\hat{\\xi}(q)$ 和 $\\hat{\\beta}(q)$，计算 $S$，最后输出一个布尔值，该值表示是否根据规则 $S > \\tau$ 检测到混合分布。\n\n使用以下固定的参数值测试套件、通用阈值网格点和检测容差：\n\n- 阈值分位数网格点：$Q = \\{0.90, 0.94, 0.96, 0.97, 0.98\\}$。\n- 检测容差：$\\tau = 0.12$。\n- 所有帕累托分量的尺度参数：$m = 1.0$。\n- 测试用例（每个用例是一个元组 $(n, m, w, \\alpha_{1}, \\alpha_{2}, \\text{seed})$）：\n    1. $(150000, 1.0, 1.0, 3.0, 5.0, 1729)$，\n    2. $(150000, 1.0, 0.6, 2.0, 5.0, 2718)$，\n    3. $(150000, 1.0, 0.9, 3.0, 3.6, 31415)$。\n\n为确保可复现性，模拟中使用的均匀分布必须在每个测试用例中用提供的种子进行播种。对于从参数为 $(m, \\alpha)$ 的帕累托分布中抽样，使用逆变换法 $X = m U^{-1/\\alpha}$，其中 $U$ 是 $(0,1)$ 上的一个均匀分布随机变量。\n\n你的程序应该生成单行输出，其中包含检测结果，格式为一个由方括号括起来的、逗号分隔的布尔值列表（例如，“[True,False,True]”），其顺序与测试用例的顺序相同。", "solution": "所提出的问题是在计算统计学应用于量化金融领域中的一个有效练习。它在科学上基于极值理论 (Extreme Value Theory, EVT)，问题定义良定，所有必要的参数和过程都有明确规定，并且其表述是客观的。我们将继续提供解决方案。\n\n该问题背后的基本原理是 Pickands–Balkema–de Haan 定理。该定理指出，对于广义的随机变量，超过一个足够高的阈值 $u$ 的超出量分布可以用广义帕累托分布 (GPD) 来近似。这个极限 GPD 的形状参数 $\\xi$ 与基础分布的尾部行为直接相关。\n\n对于一个标准的帕累托分布，其累积分布函数 (CDF) 为 $F(x) = 1 - (m/x)^{\\alpha}$（当 $x \\ge m$），超过高阈值 $u$ 的超出量服从一个形状参数为 $\\xi = 1/\\alpha$ 的 GPD。一个关键特性是，对于纯帕累托分布，只要 $u$ 足够高，这个形状参数 $\\xi$ 就是恒定的，不依赖于阈值 $u$ 的选择。\n\n该问题研究的是两个帕累托分布的混合。该混合分布的累积分布函数由下式给出：\n$$ F_{\\text{mix}}(x) = w \\left(1 - \\left(\\frac{m}{x}\\right)^{\\alpha_1}\\right) + (1-w) \\left(1 - \\left(\\frac{m}{x}\\right)^{\\alpha_2}\\right) = 1 - \\left[ w \\left(\\frac{m}{x}\\right)^{\\alpha_1} + (1-w) \\left(\\frac{m}{x}\\right)^{\\alpha_2} \\right] $$\n其生存函数为 $P(X > x) = 1 - F_{\\text{mix}}(x) = w (m/x)^{\\alpha_1} + (1-w) (m/x)^{\\alpha_2}$。对于大的 $x$，具有较小 $\\alpha$（即更重的尾部）的项将占主导地位。因此，超出量的 GPD 极限形状参数为 $\\xi = 1/\\min(\\alpha_1, \\alpha_2)$。然而，对于那些高但未达到极端极限的阈值，第二个分量的存在会影响超出量的分布。这导致了一个随阈值 $u$ 变化的“有效”形状参数 $\\hat{\\xi}(u)$。统计量 $S = \\max_{q \\in Q} \\hat{\\xi}(q) - \\min_{q \\in Q} \\hat{\\xi}(q)$ 被设计用来检测这种变化，这种变化可作为指示这是一个混合分布而非单一纯帕累托分布的指标。如果变化量 $S$ 超过某个容差 $\\tau$，我们就声明检测到了混合分布。\n\n解决此问题的算法如下：\n\n1.  **数据模拟**：对于每个测试用例，我们从指定的混合分布中生成一个大小为 $n$ 的样本。通过一组成功概率为 $w$ 的伯努利试验来决定每个数据点从哪个帕累托分量中抽样。样本本身使用帕累托分布的逆变换法生成：$X = m U^{-1/\\alpha}$，其中 $U$ 是在 $(0,1)$ 上均匀分布的随机变量。使用有种子的随机数生成器以确保可复现性。\n\n2.  **阈值与超出量计算**：对于指定网格点 $Q = \\{0.90, 0.94, 0.96, 0.97, 0.98\\}$ 中的每个分位数水平 $q$，我们首先计算模拟数据的经验分位数，它将作为阈值 $u(q)$。然后，我们找出所有超过此阈值的数据点 $x_i$，并计算相应的超出量 $y_i = x_i - u(q)$。这就构成了每个 $q$ 对应的超出量集合 $E(q)$。\n\n3.  **GPD 参数估计**：对于每个超出量集合 $E(q)$，我们估计 GPD 的参数 $(\\xi, \\beta)$。这通过最大化 GPD 对数似然函数来实现。问题要求我们对超出量 $Y = X-u$ 进行建模，这意味着 GPD 的位置参数固定为 $0$。该估计是一个数值优化问题，将由 `scipy.stats.genpareto.fit` 函数处理，并将位置参数固定（`floc=0`）。此函数返回形状参数 $\\hat{\\xi}(q)$ 和尺度参数 $\\hat{\\beta}(q)$ 的最大似然估计 (MLEs)。\n\n4.  **统计量计算与决策**：获得所有 $q \\in Q$ 的估计形状参数 $\\hat{\\xi}(q)$ 后，我们计算检测统计量 $S = \\max_{q \\in Q} \\hat{\\xi}(q) - \\min_{q \\in Q} \\hat{\\xi}(q)$。然后将该值与检测容差 $\\tau = 0.12$ 进行比较。如果 $S > \\tau$，则检测到混合分布（输出 `True`）；否则，未检测到（输出 `False`）。\n\n此过程将应用于三个测试用例中的每一个。\n-   **情形1**：$(w=1.0, \\alpha_1=3.0, \\alpha_2=5.0)$。由于 $w=1.0$，这是一个 $\\alpha=3.0$ 的单一帕累托分布。我们预期估计的 $\\hat{\\xi}(q)$ 对于所有高分位数都将是稳定的，并接近 $1/3.0 \\approx 0.333$。因此我们预计 $S \\le \\tau$。\n-   **情形2**：$(w=0.6, \\alpha_1=2.0, \\alpha_2=5.0)$。这是一个重尾（$\\alpha_1=2.0$）和较轻尾（$\\alpha_2=5.0$）分布的混合。分量的理论 $\\xi$ 值分别为 $1/2.0=0.5$ 和 $1/5.0=0.2$。我们预期 $\\hat{\\xi}(q)$ 在阈值范围内会有显著变化，从而导致一个较大的 $S$。因此我们预计 $S > \\tau$。\n-   **情形3**：$(w=0.9, \\alpha_1=3.0, \\alpha_2=3.6)$。这是一个混合分布，但两个尾部指数非常接近。理论 $\\xi$ 值分别为 $1/3.0 \\approx 0.333$ 和 $1/3.6 \\approx 0.278$。$\\hat{\\xi}(q)$ 的变化预计会很小，可能不足以超过容差 $\\tau=0.12$。因此我们预计 $S \\le \\tau$。\n\n实现将遵循这一逻辑。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import genpareto\n\ndef solve():\n    \"\"\"\n    Solves the problem of detecting Pareto mixtures using the Peaks-Over-Threshold method.\n    \"\"\"\n\n    # Define fixed parameters for the analysis\n    Q = [0.90, 0.94, 0.96, 0.97, 0.98]\n    tau = 0.12\n    \n    # Define the test cases as per the problem statement\n    test_cases = [\n        # (n, m, w, alpha1, alpha2, seed)\n        (150000, 1.0, 1.0, 3.0, 5.0, 1729),\n        (150000, 1.0, 0.6, 2.0, 5.0, 2718),\n        (150000, 1.0, 0.9, 3.0, 3.6, 31415),\n    ]\n\n    results = []\n\n    for n, m, w, alpha1, alpha2, seed in test_cases:\n        # 1. Simulate data from the Pareto mixture distribution\n        rng = np.random.default_rng(seed)\n        \n        # Generate Bernoulli trials to decide which component to sample from\n        mixture_indicators = rng.random(size=n) < w\n        \n        # Generate uniform samples for inversion method\n        uniform_samples = rng.random(size=n)\n        \n        sample = np.zeros(n)\n        \n        # Sample from the first Pareto component for indices where indicator is True\n        idx1 = mixture_indicators\n        count1 = np.sum(idx1)\n        if count1 > 0:\n            sample[idx1] = m * (uniform_samples[idx1])**(-1/alpha1)\n            \n        # Sample from the second Pareto component for the remaining indices\n        idx2 = ~mixture_indicators\n        count2 = n - count1\n        if count2 > 0:\n            sample[idx2] = m * (uniform_samples[idx2])**(-1/alpha2)\n\n        estimated_xis = []\n\n        # 2. Iterate through the quantile grid to perform POT analysis\n        for q in Q:\n            # Calculate threshold u(q)\n            threshold = np.quantile(sample, q)\n            \n            # Find excesses over the threshold\n            excesses = sample[sample > threshold] - threshold\n            \n            # Ensure there are enough excesses for estimation\n            # A small number of excesses can lead to unstable estimates.\n            # At least 2 are required for fitting.\n            if len(excesses) < 2:\n                # If not enough data, we cannot estimate, so we skip this quantile.\n                # In this problem setup with n=150000, this is highly unlikely.\n                continue\n                \n            # 3. Fit GPD to excesses using Maximum Likelihood Estimation\n            # floc=0 fixes the location parameter to 0, as we are modeling y = x - u.\n            # The function returns shape (xi), location (loc), and scale (beta).\n            try:\n                xi, _, _ = genpareto.fit(excesses, floc=0)\n                estimated_xis.append(xi)\n            except Exception:\n                # In case of optimization failure, skip this quantile.\n                # scipy's optimizer can fail on difficult data.\n                continue\n        \n        if not estimated_xis:\n            # If no estimates could be made, mixture detection is inconclusive/fails.\n            # For this problem, we'll mark it as not detected.\n            S = 0.0\n        else:\n            # 4. Compute the detection statistic S\n            S = np.max(estimated_xis) - np.min(estimated_xis)\n        \n        # 5. Apply the detection rule\n        is_mixture_detected = S > tau\n        results.append(is_mixture_detected)\n\n    # Format and print the final output\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}]}