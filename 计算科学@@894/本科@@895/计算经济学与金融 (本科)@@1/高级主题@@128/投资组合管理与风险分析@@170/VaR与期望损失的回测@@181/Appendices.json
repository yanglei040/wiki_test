{"hands_on_practices": [{"introduction": "风险模型的回测不仅仅是检查违规的频率。一个模型可能在平均意义上正确预测了违规次数，但在每次违规发生时，实际损失可能远超风险价值（VaR）的预测。本练习旨在通过构建一个能够通过Kupiec非条件覆盖检验，但其尾部损失巨大的合成数据集，来揭示这一 VaR 回测中的关键盲点 [@problem_id:2374206]。这个实践将帮助你直观地理解为何仅依赖于频率检验是不够的，并突显了预期短缺（$ES$）作为风险度量的重要性。", "id": "2374206", "problem": "您需要通过构建合成的盈亏（P&amp;L）数据和一个特意错误设定的VaR模型，来论证使用风险价值（VaR）进行回测的局限性。该模型需满足无条件覆盖检验，同时隐藏了对于期望亏损（ES）而言显而易见的极端尾部严重性。您必须实现一个完整的程序，从第一性原理出发，产生确定性的输出。\n\n使用的基本定义：\n- 损失由序列 $\\{L_t\\}_{t=1}^T$ 表示，其中 $L_t \\ge 0$ 表示时间 $t$ 的损失。\n- 尾部概率水平为 $\\alpha \\in (0,1)$ 的风险价值（VaR）是满足 $\\mathbb{P}(L_t \\le v_\\alpha) \\ge 1 - \\alpha$ 的最小阈值 $v_\\alpha$。当一个模型提供了一个一步向前VaR预测序列 $\\{v_t\\}_{t=1}^T$ 时，在时间 $t$ 发生的违规是事件 $L_t > v_t$。\n- 超额指标为 $I_t = \\mathbf{1}\\{L_t > v_t\\}$。在正确的无条件覆盖下，序列 $\\{I_t\\}$ 是一个成功概率为 $\\alpha$ 的独立同分布伯努利过程。\n- 水平为 $\\alpha$ 的期望亏损（ES）是在损失超过VaR阈值的条件下，损失的条件期望：$\\mathrm{ES}_\\alpha = \\mathbb{E}[L_t \\mid L_t > v_\\alpha]$。\n- Kupiec无条件覆盖似然比（LR）检验比较了在原假设违规概率为 $\\alpha$ 下的伯努利似然与在最大似然估计 $\\hat{p}$ 下的似然。原假设是无条件违规率等于 $\\alpha$。LR统计量渐近服从自由度为1的 $\\chi^2$ 分布，您必须据此计算一个 $p$-值，并确定检验在0.05的显著性水平上是否未能拒绝原假设。\n\n您的任务：\n1. 对于每个提供的测试用例，构建一个合成的损失序列 $\\{L_t\\}_{t=1}^T$ 和一个恒定的VaR预测序列 $\\{v_t\\}_{t=1}^T$（其中 $v_t \\equiv v$），使得：\n   - 恰好有 $x = \\alpha T$ 个时间点是违规，在这些违规时间点上 $L_t = 10 v$。\n   - 所有其他时间点为非违规，此时 $L_t = 0.5 v$。\n   - 注意：所有数学实体，包括 $10$、$0.5$ 和 $x$，都必须在您的构建中作为约束来遵守。\n2. 根据构建的 $\\{L_t\\}$ 和 $\\{v_t\\}$，为每种情况计算超额指标 $\\{I_t\\}$ 和违规次数 $x = \\sum_{t=1}^T I_t$。\n3. 对每种情况，仅基于伯努利似然原理和自由度为1的渐近 $\\chi^2$ 分布，实现Kupiec无条件覆盖似然比检验。使用此检验计算 $p$-值和一个布尔值，该布尔值指示检验在0.05的显著性水平上是否未能拒绝原假设。\n4. 为每种情况计算实现的期望亏损比率，定义为当 $x \\ge 1$ 时，$M = \\left(\\frac{1}{x} \\sum_{t=1}^T I_t L_t\\right) / v$。在您的构建中，该比率应揭示相对于模型VaR水平的系统性尾部严重性。\n5. 您的实现必须是确定性的，并且不得依赖任何外部随机性。\n\n测试套件：\n您必须在以下参数集 $(T,\\alpha,v)$ 上运行您的程序，其中 $T$ 是长度，$\\alpha$ 是小数形式的违规概率， $v$ 是恒定的VaR水平：\n- 情况A：$(T,\\alpha,v) = (1000, 0.01, 1.0)$\n- 情况B：$(T,\\alpha,v) = (250, 0.04, 2.0)$\n- 情况C：$(T,\\alpha,v) = (200, 0.055, 0.5)$\n- 情况D（小样本覆盖检查）：$(T,\\alpha,v) = (20, 0.1, 3.0)$\n\n对于每种情况，按此确切顺序输出包含三个项目的列表：\n- 一个布尔值，指示Kupiec检验在0.05的显著性水平上是否未能拒绝。\n- Kupiec检验的 $p$-值，为浮点数。\n- 实现的期望亏损比率 $M$，为浮点数。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个按情况划分的结果列表，每个情况的结果是一个按上述顺序排列的三元素列表。例如，最终的单行应如下所示：\n- $[\\,[\\text{True}, 1.0, 10.0], [\\text{True}, 0.9999, 10.0]\\,]$\n- 您的代码必须精确打印包含此列表的一行，不得有其他文本。\n\n重要实现说明：\n- 将违规视为 $L_t > v_t$，其中损失和VaR均为非负。\n- 确保在每个测试用例中 $x = \\alpha T$ 均为整数。不要随机安排违规的位置；一个简单的确定性放置是可以接受的。\n- Kupiec决策使用0.05的显著性水平。\n- 角度和物理单位不适用。百分比必须表示为小数，给定的 $\\alpha$ 值已满足此要求。", "solution": "所述问题是有效的。它在科学上基于金融风险管理的原则，特别是风险模型的回测。所有的定义和约束都是适定的、完整的、一致的，从而可以得到一个唯一且有意义的解。任务是构建一个特定的场景，以说明与期望亏损（$ES$）相比，风险价值（$VaR$）的一个已知局限性。\n\n目标是创建一个合成的盈亏（$P\\&L$）历史，由损失序列 $\\{L_t\\}_{t=1}^T$ 表示，以及一个相应的一步向前$VaR$预测序列 $\\{v_t\\}_{t=1}^T$。这种构造必须是特意错误设定的，以致于$VaR$模型能通过一个标准的回测——Kupiec无条件覆盖检验——同时隐藏对尾部损失幅度的严重低估，这是一个基于$ES$的指标会暴露的缺陷。\n\n首先，我们处理每个给定测试用例（参数三元组 $(T, \\alpha, v)$）的合成数据构建。$T$ 是总时间期数，$\\alpha$ 是目标违规概率，而 $v$ 是恒定的$VaR$预测水平。\n\n问题规定了一个恒定的$VaR$预测：\n$$ v_t = v \\quad \\forall t \\in \\{1, \\dots, T\\} $$\n\n时间 $t$ 的违规或超额定义为事件 $L_t > v_t$。该构造要求违规总数 $x$ 必须恰好为 $x = \\alpha T$。对于所提供的测试用例，这个乘积是一个整数。为确保确定性，我们可以将这 $x$ 次违规放在时间序列的开始，从 $t=1$ 到 $t=x$。\n\n损失值的具体规定如下：\n- 对于违规期（$t \\in \\{1, \\dots, x\\}$）：$L_t = 10v$。这满足违规条件 $L_t > v$，因为 $v$ 必须为正。\n- 对于非违规期（$t \\in \\{x+1, \\dots, T\\}$）：$L_t = 0.5v$。这不构成违规，因为 $0.5v \\ngtr v$。\n\n因此，超额指标序列 $\\{I_t\\}_{t=1}^T$ 为：$t \\in \\{1, \\dots, x\\}$ 时 $I_t = 1$，$t \\in \\{x+1, \\dots, T\\}$ 时 $I_t = 0$。\n\n接下来，我们执行Kupiec无条件覆盖似然比（$LR$）检验。原假设 $H_0$ 是违规的真实概率为 $p = \\alpha$。该检验统计量基于比较在 $H_0$ 下观测数据的似然与在最大似然估计 $\\hat{p} = x/T$ 下的似然。$LR$ 统计量由以下公式给出：\n$$ LR_{uc} = 2 \\ln \\left( \\frac{L(\\hat{p})}{L(\\alpha)} \\right) = 2 \\ln \\left( \\frac{\\hat{p}^x (1 - \\hat{p})^{T-x}}{\\alpha^x (1-\\alpha)^{T-x}} \\right) $$\n该表达式可以重写为：\n$$ LR_{uc} = 2 \\left[ x \\ln\\left(\\frac{\\hat{p}}{\\alpha}\\right) + (T-x) \\ln\\left(\\frac{1-\\hat{p}}{1-\\alpha}\\right) \\right] $$\n根据我们的特定构造，违规次数为 $x = \\alpha T$。因此，经验违规率为 $\\hat{p} = x/T = (\\alpha T)/T = \\alpha$。将 $\\hat{p} = \\alpha$ 代入 $LR_{uc}$ 公式，得到：\n$$ LR_{uc} = 2 \\left[ (\\alpha T) \\ln\\left(\\frac{\\alpha}{\\alpha}\\right) + (T-\\alpha T) \\ln\\left(\\frac{1-\\alpha}{1-\\alpha}\\right) \\right] = 2 \\left[ (\\alpha T) \\ln(1) + T(1-\\alpha) \\ln(1) \\right] = 0 $$\n因此，$LR_{uc}$ 统计量恒等于零。该统计量渐近服从自由度为1的卡方分布 $\\chi^2(1)$。检验的 $p$-值是观测到至少与计算出的统计量一样极端的检验统计量的概率，即 $P(\\chi^2(1) \\ge LR_{uc})$。当 $LR_{uc}=0$ 时，$p$-值为：\n$$ p\\text{-值} = \\int_0^\\infty f(z; 1) dz = 1 $$\n其中 $f(z; 1)$ 是 $\\chi^2(1)$ 分布的概率密度函数。如果 $p$-值低于显著性水平（给定为0.05），则拒绝原假设。由于 $1.0 > 0.05$，我们无条件地未能拒绝所有测试用例的原假设。$VaR$模型完美地通过了覆盖检验。\n\n最后，我们使用实现的期望亏损比率 $M$来分析模型在尾部损失幅度方面的表现。这被定义为违规日的经验平均损失与$VaR$水平的比率：\n$$ M = \\frac{\\frac{1}{x} \\sum_{t=1}^T I_t L_t}{v} $$\n总和 $\\sum_{t=1}^T I_t L_t$ 表示所有 $x$ 个违规日的总损失。根据我们的构造，在这些日子里，每天的损失是 $L_t = 10v$。所以，总和为 $x \\cdot 10v$。违规日的平均损失是：\n$$ \\frac{1}{x} \\sum_{t=1}^T I_t L_t = \\frac{x \\cdot 10v}{x} = 10v $$\n这是经验性或实现的期望亏损。那么比率 $M$ 是：\n$$ M = \\frac{10v}{v} = 10 $$\n这个在所有测试用例中都恒定的结果，揭示了该模型的关键缺陷。当违规发生时，所产生的损失平均是$VaR$阈值的10倍。一个简单的覆盖检验对于损失分布尾部这种系统性的、严重的风险低估是盲目的。这证明了像$ES$这样的一致性风险度量的优越性，它不仅考虑了尾部损失的频率，还考虑了其严重性。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Solves the problem of demonstrating VaR backtesting limitations.\n    For each test case, it computes the Kupiec test result and the realized ES ratio.\n    \"\"\"\n    test_cases = [\n        # (T, alpha, v)\n        (1000, 0.01, 1.0),\n        (250, 0.04, 2.0),\n        (200, 0.055, 0.5),\n        (20, 0.1, 3.0),\n    ]\n\n    results = []\n    significance_level = 0.05\n\n    for T, alpha, v in test_cases:\n        # Per problem statement, x = alpha * T is an integer for all test cases.\n        # This setup is deterministic.\n        x = int(T * alpha)\n        \n        # 1. Kupiec Unconditional Coverage Test\n        # The null hypothesis is that the violation probability is alpha.\n        # The test statistic LR_uc = 2 * ln(L(p_hat) / L(alpha)).\n        # By construction, the observed violation rate p_hat = x / T = alpha.\n        # This forces the LR statistic to be 0 and the p-value to be 1.\n        # We implement the full formula for formal verification.\n\n        lr_stat = 0.0\n        if x == 0:\n            # log(p_hat) term is undefined, but limit of p_hat*log(p_hat) is 0.\n            # LR = 2* T * log(1/(1-alpha))\n            lr_stat = 2 * (T * np.log(1 / (1 - alpha)))\n        elif x == T:\n            # log(1-p_hat) term is undefined.\n            # LR = 2 * T * log(1/alpha)\n            lr_stat = 2 * (T * np.log(1 / alpha))\n        else:\n            p_hat = x / T\n            # Due to problem design, p_hat is exactly alpha.\n            # np.log(p_hat / alpha) will be np.log(1.0) = 0.\n            # The formula is robust to minor floating point inaccuracies if any existed.\n            term1 = x * np.log(p_hat / alpha)\n            term2 = (T - x) * np.log((1 - p_hat) / (1 - alpha))\n            lr_stat = 2 * (term1 + term2)\n\n        # p-value from chi-squared distribution with 1 degree of freedom\n        p_value = float(chi2.sf(lr_stat, df=1))\n\n        # Decision: Fail to reject H0 if p-value is not less than significance level\n        k_test_fails_to_reject = p_value >= significance_level\n\n        # 2. Realized Expected Shortfall Ratio (M)\n        # M = (average loss on violation days) / VaR\n        # Loss on violation days is L_t = 10 * v\n        # Average loss is therefore (x * 10 * v) / x = 10 * v\n        # M = (10 * v) / v = 10\n        es_ratio = 0.0\n        if x > 0:\n            # The calculation is analytically 10, as shown in the solution notes.\n            # Average loss conditional on violation = 10 * v\n            # Ratio M = (10 * v) / v\n            es_ratio = 10.0\n        # The problem statement defines M for x >= 1, so no else case is needed\n        # for the given test suite.\n\n        results.append([k_test_fails_to_reject, p_value, es_ratio])\n\n    # Final print statement must match the specified format exactly.\n    # The format from the template is f\"[{','.join(map(str, results))}]\"\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}, {"introduction": "一个稳健的风险模型不仅应准确预测违规的频率，还应确保这些违规事件是独立发生的，没有可预测的模式。本练习将探讨当 VaR 违规事件表现出系统性模式（例如，总是发生在每周的某一天）时会发生什么 [@problem_id:2374172]。通过应用 Christoffersen 的条件覆盖框架，你将学会如何检测这种时间上的依赖性，并理解为何独立性假设是评估风险模型有效性的一个不可或缺的维度。", "id": "2374172", "problem": "您的任务是构建和评估一个风险价值 (VaR) 例外过程，该过程在指定的概率水平上具有正确的无条件覆盖，但表现出系统性的时机。考虑一个交易日历，该日历包含一个重复的五天工作周，其中日期用整数标记，星期一为第 $0$ 天，星期二为第 $1$ 天，星期三为第 $2$ 天，星期四为第 $3$ 天，星期五为第 $4$ 天。令 $T$ 表示总交易日数，索引为 $t \\in \\{0,1,\\ldots,T-1\\}$，并令 $\\alpha \\in (0,1)$ 表示名义 VaR 例外概率水平。定义 VaR 例外指示序列 $\\{I_t\\}_{t=0}^{T-1}$ 为 $I_t \\in \\{0,1\\}$，其中 $I_t=1$ 表示第 $t$ 天是一个 VaR 例外，否则 $I_t=0$。待评估的模型必须同时满足以下两个属性：\n- 在 $T$ 天内的总例外数恰好等于 $\\alpha T$。\n- 所有例外仅在星期一发生。\n\n假设第一个观测值的起始星期已知，记为 $s \\in \\{0,1,2,3,4\\}$，其中 $s=0$ 对应于星期一。时刻 $t$ 的星期为 $(s+t) \\bmod 5$。该模型应精确地将 $\\alpha T$ 个例外放置在样本中最早的那些星期一，对这些星期一的索引 $t$ 令 $I_t=1$，其余则令 $I_t=0$。您可以假设 $\\alpha T$ 是一个整数，并且样本中的星期一数量至少为 $\\alpha T$。\n\n将序列 $\\{I_t\\}$ 置于 Christoffersen 的回测框架下进行检验，该框架包括：\n- 无条件覆盖假设，即例外概率等于 $\\alpha$。\n- 独立性假设，即例外在时间上是独立的。\n- 条件覆盖假设，即无条件覆盖和独立性联合成立。\n\n使用在 Christoffersen 框架中定义的似然比统计量，并为每个检验报告以下内容：\n- 无条件覆盖的似然比统计量，记为 $LR_{\\mathrm{uc}}$。\n- 独立性的似然比统计量，记为 $LR_{\\mathrm{ind}}$。\n- 条件覆盖统计量 $LR_{\\mathrm{cc}} = LR_{\\mathrm{uc}} + LR_{\\mathrm{ind}}$。\n- 相应的 $p$ 值，在卡方分布下计算，自由度对于 $LR_{\\mathrm{uc}}$ 为 $1$，对于 $LR_{\\mathrm{ind}}$ 为 $1$，对于 $LR_{\\mathrm{cc}}$ 为 $2$。\n- 在显著性水平 $\\delta=0.05$ 下，对每个原假设的二元拒绝决策，以十进制数表示。\n\n您的程序必须为以下参数三元组 $(T,\\alpha,s)$ 的测试集实现此构建和分析：\n- 测试 $1$：$(T,\\alpha,s) = (500, 0.05, 0)$。\n- 测试 $2$：$(T,\\alpha,s) = (495, 0.20, 3)$。\n- 测试 $3$：$(T,\\alpha,s) = (100, 0.10, 1)$。\n- 测试 $4$：$(T,\\alpha,s) = (500, 0.01, 4)$。\n- 测试 $5$：$(T,\\alpha,s) = (250, 0.04, 2)$。\n\n对于每个测试，按以下顺序输出一个包含九个值的列表：\n$[LR_{\\mathrm{uc}}, p_{\\mathrm{uc}}, LR_{\\mathrm{ind}}, p_{\\mathrm{ind}}, LR_{\\mathrm{cc}}, p_{\\mathrm{cc}}, \\text{reject}_{\\mathrm{uc}}, \\text{reject}_{\\mathrm{ind}}, \\text{reject}_{\\mathrm{cc}}]$，其中 $p_{\\mathrm{uc}}$、$p_{\\mathrm{ind}}$ 和 $p_{\\mathrm{cc}}$ 是 $p$ 值，而 $\\text{reject}_{\\mathrm{uc}}$、$\\text{reject}_{\\mathrm{ind}}$、$\\text{reject}_{\\mathrm{cc}}$ 是布尔值，表示在 $\\delta=0.05$ 水平上是否拒绝。\n\n最终输出格式：您的程序应生成单行输出，其中包含所有五个测试的结果，格式为此类九元素列表的逗号分隔列表，并用方括号括起来，例如 $[\\ldots]$。所有概率必须以小数表示，而非百分号。", "solution": "我们从第一性原理出发，形式化 VaR 例外指示序列和 Christoffersen 检验。令 $T \\in \\mathbb{N}$ 为交易日数，$\\alpha \\in (0,1)$ 为名义例外概率。为 $t \\in \\{0,1,\\ldots,T-1\\}$ 定义指示符 $I_t \\in \\{0,1\\}$，其构建规则如下：\n- 计算对应星期一的索引集为 $\\mathcal{M} = \\{t \\in \\{0,\\ldots,T-1\\} : (s+t) \\bmod 5 = 0\\}$，其中 $s \\in \\{0,1,2,3,4\\}$ 是第一个观测值所在的星期，$0$ 代表星期一。\n- 令 $K = \\alpha T$。根据假设，$K$ 是一个整数且 $|\\mathcal{M}| \\ge K$。\n- 对于 $\\mathcal{M}$ 中按 $t$ 升序排列的前 $K$ 个元素，设置 $I_t = 1$，对于所有其他索引，设置 $I_t = 0$。这确保了所有例外都发生在星期一，且总例外数等于 $\\alpha T$。\n\nChristoffersen 的无条件覆盖检验考虑假设\n$H_0^{\\mathrm{uc}}: \\mathbb{P}(I_t=1) = \\alpha$，\n该假设声明例外概率等于 $\\alpha$。令 $N_1 = \\sum_{t=0}^{T-1} I_t$ 且 $N_0 = T - N_1$。在 $H_0^{\\mathrm{uc}}$ 下，对于成功概率为 $\\alpha$ 的独立伯努利试验，其似然为\n$$\nL_0^{\\mathrm{uc}} = (1-\\alpha)^{N_0} \\alpha^{N_1}.\n$$\n无约束似然（在 $\\pi \\in [0,1]$ 上最大化）在 $\\hat{\\pi} = N_1/T$ 处达到，得到\n$$\nL_1^{\\mathrm{uc}} = (1-\\hat{\\pi})^{N_0} \\hat{\\pi}^{N_1}.\n$$\n似然比统计量为\n$$\nLR_{\\mathrm{uc}} = -2 \\left[ \\ln L_0^{\\mathrm{uc}} - \\ln L_1^{\\mathrm{uc}} \\right]\n= 2 \\left[ N_1 \\ln\\left(\\frac{N_1}{\\alpha T}\\right) + N_0 \\ln\\left(\\frac{N_0}{(1-\\alpha)T}\\right) \\right],\n$$\n约定形式为 $0 \\cdot \\ln(0)$ 的项被视为 $0$。在 $H_0^{\\mathrm{uc}}$ 下，$LR_{\\mathrm{uc}}$ 渐近服从自由度为 $1$ 的卡方分布。\n\n独立性检验考虑序列 $\\{I_t\\}$ 中的一阶马尔可夫依赖性。定义在 $t=1,\\ldots,T-1$ 上的转移计数：\n- $N_{ij} = \\#\\{t \\in \\{1,\\ldots,T-1\\} : I_{t-1}=i, I_t=j\\}$ 对于 $i,j \\in \\{0,1\\}$。\n令 $N_{0\\cdot} = N_{00} + N_{01}$ 且 $N_{1\\cdot} = N_{10} + N_{11}$。在无约束一阶马尔可夫备择假设下，最大似然估计量为\n$$\n\\hat{p}_{01} = \\frac{N_{01}}{N_{0\\cdot}} \\ \\text{ if } N_{0\\cdot} > 0, \\quad\n\\hat{p}_{11} = \\frac{N_{11}}{N_{1\\cdot}} \\ \\text{ if } N_{1\\cdot} > 0,\n$$\n如果分母为零，则进行自然的边界处理。无约束对数似然为\n$$\n\\ln L_1^{\\mathrm{ind}} = N_{00}\\ln(1-\\hat{p}_{01}) + N_{01}\\ln(\\hat{p}_{01}) + N_{10}\\ln(1-\\hat{p}_{11}) + N_{11}\\ln(\\hat{p}_{11}),\n$$\n其中任何系数为零的项均被视为零。在独立性原假设下，具有共同的成功概率 $\\pi$，基于转移的最大似然估计量为\n$$\n\\hat{\\pi} = \\frac{N_{01} + N_{11}}{N_{00} + N_{01} + N_{10} + N_{11}} = \\frac{N_{01} + N_{11}}{T-1},\n$$\n受约束的对数似然为\n$$\n\\ln L_0^{\\mathrm{ind}} = (N_{00}+N_{10})\\ln(1-\\hat{\\pi}) + (N_{01}+N_{11})\\ln(\\hat{\\pi}).\n$$\n独立性似然比统计量为\n$$\nLR_{\\mathrm{ind}} = -2\\left[\\ln L_0^{\\mathrm{ind}} - \\ln L_1^{\\mathrm{ind}}\\right],\n$$\n在独立性原假设下，该统计量渐近服从自由度为 $1$ 的卡方分布。\n\n条件覆盖统计量结合了这两个部分：\n$$\nLR_{\\mathrm{cc}} = LR_{\\mathrm{uc}} + LR_{\\mathrm{ind}},\n$$\n在联合原假设下，该统计量渐近服从自由度为 $2$ 的卡方分布。\n\n对于每个测试用例 $(T,\\alpha,s)$，我们按规定构建 $\\{I_t\\}$，计算 $N_1$、$N_0$ 和转移计数 $N_{ij}$，然后使用具有相应自由度的卡方分布的生存函数，评估 $LR_{\\mathrm{uc}}$、$LR_{\\mathrm{ind}}$ 和 $LR_{\\mathrm{cc}}$ 及其 $p$ 值。通过将每个 $p$ 值与 $\\delta = 0.05$ 进行比较来做出拒绝决策。因为构造精确地强制了 $N_1 = \\alpha T$，我们得到 $\\hat{\\pi} = \\alpha$，因此对于所有测试用例，$LR_{\\mathrm{uc}}$ 恒等于 $0$，这意味着在任何常规水平上都不会拒绝无条件覆盖假设。然而，将所有例外集中在星期一会引发相对于日历时间的序列相关性，这种相关性可由独立性检验通过不同的转移概率检测出来，特别是 $\\hat{p}_{11} = 0$（无连续例外）和 $\\hat{p}_{01} > 0$，这会增加 $LR_{\\mathrm{ind}}$ 并通常导致对独立性和条件覆盖假设的拒绝，特别是当 $T$ 和 $\\alpha T$ 增大时。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef build_monday_exception_series(T: int, alpha: float, start_day: int) -> np.ndarray:\n    \"\"\"\n    Construct an exception indicator series I_t of length T such that:\n    - Exactly K = alpha*T exceptions occur (assumed integer),\n    - All exceptions occur on Mondays (weekday index 0),\n    - The first observation has weekday 'start_day' in {0,..,4}.\n    \"\"\"\n    K = int(round(alpha * T))\n    I = np.zeros(T, dtype=int)\n    monday_indices = [t for t in range(T) if ((start_day + t) % 5) == 0]\n    if K > len(monday_indices):\n        raise ValueError(\"Not enough Mondays to place all exceptions.\")\n    # Place exceptions on the earliest Mondays\n    for t in monday_indices[:K]:\n        I[t] = 1\n    return I\n\ndef safe_log(x: float) -> float:\n    \"\"\"Natural log with handling for x in {0,1} when multiplied by zero counts later.\"\"\"\n    # We will never call log(0) multiplied by positive coefficient if model is set correctly\n    # But to be safe, cap x in (0,1) open interval with tiny epsilon\n    eps = 1e-16\n    if x <= 0.0:\n        x = eps\n    elif x >= 1.0:\n        x = 1.0 - eps\n    return np.log(x)\n\ndef lr_uc(I: np.ndarray, alpha: float) -> float:\n    \"\"\"\n    Christoffersen's unconditional coverage LR statistic.\n    LR_uc = 2 * [ N1*ln(N1/(alpha*T)) + N0*ln(N0/((1-alpha)*T)) ] with 0*ln(0)=0.\n    \"\"\"\n    T = I.size\n    N1 = int(I.sum())\n    N0 = T - N1\n    # Handle 0*ln(0) -> 0 via conditional terms\n    term1 = 0.0 if N1 == 0 else N1 * np.log(N1 / (alpha * T))\n    term0 = 0.0 if N0 == 0 else N0 * np.log(N0 / ((1.0 - alpha) * T))\n    LR = 2.0 * (term1 + term0)\n    # Numerical cleanup: LR cannot be negative\n    return float(max(LR, 0.0))\n\ndef lr_ind(I: np.ndarray) -> float:\n    \"\"\"\n    Christoffersen's independence LR statistic based on 2x2 transition counts.\n    \"\"\"\n    # Compute transitions\n    I_prev = I[:-1]\n    I_curr = I[1:]\n    N00 = int(np.sum((I_prev == 0) & (I_curr == 0)))\n    N01 = int(np.sum((I_prev == 0) & (I_curr == 1)))\n    N10 = int(np.sum((I_prev == 1) & (I_curr == 0)))\n    N11 = int(np.sum((I_prev == 1) & (I_curr == 1)))\n\n    N0dot = N00 + N01\n    N1dot = N10 + N11\n    Ntrans = N0dot + N1dot  # equals len(I)-1\n\n    # Unrestricted MLEs with boundary handling\n    p01_hat = 0.0 if N0dot == 0 else N01 / N0dot\n    p11_hat = 0.0 if N1dot == 0 else N11 / N1dot\n\n    # Log-likelihood under alternative (Markov)\n    ll1 = 0.0\n    if N00 > 0:\n        ll1 += N00 * safe_log(1.0 - p01_hat)\n    if N01 > 0:\n        ll1 += N01 * safe_log(p01_hat)\n    if N10 > 0:\n        ll1 += N10 * safe_log(1.0 - p11_hat)\n    if N11 > 0:\n        ll1 += N11 * safe_log(p11_hat)\n\n    # Restricted MLE under independence\n    pi_hat = 0.0 if Ntrans == 0 else (N01 + N11) / Ntrans\n    ll0 = 0.0\n    if (N00 + N10) > 0:\n        ll0 += (N00 + N10) * safe_log(1.0 - pi_hat)\n    if (N01 + N11) > 0:\n        ll0 += (N01 + N11) * safe_log(pi_hat)\n\n    LR = -2.0 * (ll0 - ll1)\n    return float(max(LR, 0.0))\n\ndef analyze_case(T: int, alpha: float, start_day: int, sig: float = 0.05):\n    I = build_monday_exception_series(T, alpha, start_day)\n    LR_uc = lr_uc(I, alpha)\n    LR_ind = lr_ind(I)\n    LR_cc = LR_uc + LR_ind\n\n    # p-values from chi-square distributions\n    p_uc = chi2.sf(LR_uc, df=1)\n    p_ind = chi2.sf(LR_ind, df=1)\n    p_cc = chi2.sf(LR_cc, df=2)\n\n    reject_uc = p_uc < sig\n    reject_ind = p_ind < sig\n    reject_cc = p_cc < sig\n\n    return LR_uc, p_uc, LR_ind, p_ind, LR_cc, p_cc, reject_uc, reject_ind, reject_cc\n\ndef format_result(result_tuple):\n    # Format floats to 6 decimals, booleans as True/False\n    formatted = []\n    for i, v in enumerate(result_tuple):\n        if isinstance(v, float):\n            formatted.append(f\"{v:.6f}\")\n        elif isinstance(v, (np.floating,)):\n            formatted.append(f\"{float(v):.6f}\")\n        elif isinstance(v, (bool, np.bool_)):\n            formatted.append(\"True\" if bool(v) else \"False\")\n        else:\n            formatted.append(str(v))\n    return \"[\" + \",\".join(formatted) + \"]\"\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case is (T, alpha, start_day)\n    test_cases = [\n        (500, 0.05, 0),  # Test 1\n        (495, 0.20, 3),  # Test 2\n        (100, 0.10, 1),  # Test 3\n        (500, 0.01, 4),  # Test 4\n        (250, 0.04, 2),  # Test 5\n    ]\n\n    results = []\n    for case in test_cases:\n        T, alpha, start_day = case\n        result = analyze_case(T, alpha, start_day, sig=0.05)\n        results.append(format_result(result))\n\n    # Final print statement in the exact required format: a single line with a list of lists\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"}, {"introduction": "在模型构建中，一个常见且微妙的错误是“前视偏差”（look-ahead bias），即在预测时无意中使用了未来的信息。这个练习将引导你进入一个更真实的 GARCH 过程模拟环境，以量化这种“幽灵特征”对回测结果的误导性影响 [@problem_id:2374186]。通过比较一个正确构建的基准模型和一个带有前视偏差的模型，你将亲手计算并看到后者在各项回测指标上虚假的“优越性”，从而深刻理解在金融建模中进行严格样本外测试和保持数据完整性的重要性。", "id": "2374186", "problem": "您将实现并比较两种用于风险价值（Value-at-Risk, VaR）和预期亏损（expected shortfall, ES）的滚动高斯风险模型，并量化包含“幽灵特征”（来自未来的信息）对标准回测结果的影响。所有计算都将在由指定的条件异方差过程生成的合成回报序列上执行。您的程序必须是自包含的，产生确定性的结果，并如下文规定输出一个浮点数列表。\n\n定义与假设：\n- 令 $\\alpha \\in (0,1)$ 表示VaR和预期亏损的尾部概率水平。\n- 时间 $t$ 的单步回报为 $r_t$。负值代表损失。\n- 在条件均值为零、条件标准差为 $\\sigma_t$ 的高斯模型下，$\\alpha$-分位数（左尾）为 $q_\\alpha = \\Phi^{-1}(\\alpha)$，其中 $\\Phi^{-1}(\\cdot)$ 是标准正态分布的逆累积分布函数。条件VaR预测为 $\\widehat{\\text{VaR}}_t = q_\\alpha \\sigma_t$。\n- 预期亏损是尾部条件期望。对于标准正态随机变量 $Z$，其截断均值满足 $\\mathbb{E}[Z \\mid Z \\le q_\\alpha] = -\\varphi(q_\\alpha)/\\alpha$，其中 $\\varphi(\\cdot)$ 是标准正态概率密度函数。因此，ES预测为 $\\widehat{\\text{ES}}_t = \\sigma_t \\, \\mathbb{E}[Z \\mid Z \\le q_\\alpha] = -\\sigma_t \\, \\varphi(q_\\alpha)/\\alpha$。\n- VaR回测使用超限指标 $I_t = \\mathbf{1}\\{r_t < \\widehat{\\text{VaR}}_t\\}$。在正确校准下，无条件覆盖意味着 $I_t$ 是独立同分布的伯努利随机变量，成功概率为 $\\alpha$。在长度为 $n$ 的回测样本中，令 $x = \\sum_{t=1}^n I_t$ 表示超限次数。无条件覆盖假设的似然比统计量等于\n$$\n\\text{LR}_{\\text{uc}} = 2\\left[ x \\ln\\left(\\frac{x/n}{\\alpha}\\right) + (n-x)\\ln\\left(\\frac{1 - x/n}{1-\\alpha}\\right)\\right],\n$$\n约定当 $x=0$ 时 $x \\ln(x/n)$ 为 $0$，当 $x=n$ 时 $(n-x)\\ln(1 - x/n)$ 为 $0$。在零假设下，$\\text{LR}_{\\text{uc}}$ 渐近服从自由度为 $1$ 的 $\\chi^2$ 分布。经验命中率为 $\\widehat{p} = x/n$。\n- 一个在 $\\alpha$ 水平上对分位数严格一致的评分函数是“检验损失” $\\ell_t^{Q} = \\left(\\alpha - I_t\\right)\\left(r_t - \\widehat{\\text{VaR}}_t\\right)$，其样本均值 $\\overline{\\ell}^{Q}$ 对于校准良好的分位数预测应该很小。\n- 一种简单的ES回测诊断方法是比较实现尾部条件均值与超限日的平均ES预测。定义实现亏损为 $\\overline{r}_{\\text{tail}} = \\frac{1}{x}\\sum_{t: I_t=1} r_t$（仅当 $x \\ge 1$ 时有定义），以及超限日对应的平均ES预测为 $\\overline{\\widehat{\\text{ES}}}_{\\text{tail}} = \\frac{1}{x}\\sum_{t: I_t=1} \\widehat{\\text{ES}}_t$。绝对ES偏差为 $|\\overline{\\widehat{\\text{ES}}}_{\\text{tail}} - \\overline{r}_{\\text{tail}}|$。\n\n待比较的模型：\n- 基准模型（正确时序）：在时间 $t$，使用最近的 $W$ 个过去回报 $\\{r_{t-W},\\dots,r_{t-1}\\}$ 组成的长度为 $W$ 的滚动窗口的样本标准差来估计 $\\sigma_t$。\n- 幽灵特征模型（前视偏差）：在时间 $t$，错误地使用一个包含当前回报的滚动窗口，即 $\\{r_{t-W+1},\\dots,r_t\\}$，来估计 $\\sigma_t$。这使用了相对于决策点而言的未来信息，在真实的预测中是禁止的，但此处有意包含它以量化其影响。\n\n数据生成过程：\n- 回报由一个条件均值为零的高斯广义自回归条件异方差（GARCH($1,1$)）过程生成：\n$$\n\\sigma_t^2 = \\omega + \\alpha_G r_{t-1}^2 + \\beta_G \\sigma_{t-1}^2,\\quad r_t = \\sigma_t \\, z_t,\\quad z_t \\sim \\mathcal{N}(0,1),\n$$\n给定参数 $\\omega > 0$，$\\alpha_G \\ge 0$ 和 $\\beta_G \\ge 0$ 满足 $\\alpha_G + \\beta_G < 1$ 以确保协方差平稳性。当 $\\alpha_G = 0$ 和 $\\beta_G = 0$ 时，该过程简化为方差为 $\\omega$ 的独立同分布高斯回报。当 $\\alpha_G + \\beta_G < 1$ 时，将 $\\sigma_0^2$ 初始化为无条件方差 $\\omega/(1 - \\alpha_G - \\beta_G)$，否则为了数值稳定性，将其初始化为 $\\omega$。\n\n为每个模型计算的回测指标：\n- 命中率绝对误差: $|\\widehat{p} - \\alpha|$。\n- 无条件覆盖似然比统计量: $\\text{LR}_{\\text{uc}}$。\n- 平均分位数检验损失: $\\overline{\\ell}^{Q}$。\n- 绝对ES偏差: $|\\overline{\\widehat{\\text{ES}}}_{\\text{tail}} - \\overline{r}_{\\text{tail}}|$。\n\n要求的比较输出：\n对于下述每个测试案例，按此顺序计算以下四个差值（基准模型减去幽灵模型）：\n$D_1 =$ 命中率绝对误差减少量 $= |\\widehat{p}_{\\text{base}} - \\alpha| - |\\widehat{p}_{\\text{ghost}} - \\alpha|$，\n$D_2 =$ 无条件覆盖似然比减少量 $= \\text{LR}_{\\text{uc, base}} - \\text{LR}_{\\text{uc, ghost}}$，\n$D_3 =$ 分位数检验损失减少量 $= \\overline{\\ell}^{Q}_{\\text{base}} - \\overline{\\ell}^{Q}_{\\text{ghost}}$，\n$D_4 =$ ES绝对偏差减少量 $= |\\overline{\\widehat{\\text{ES}}}_{\\text{tail, base}} - \\overline{r}_{\\text{tail, base}}| - |\\overline{\\widehat{\\text{ES}}}_{\\text{tail, ghost}} - \\overline{r}_{\\text{tail, ghost}}|$。\n\n任何 $D_j$ 的正值都表明，幽灵特征模型在该指标上看起来“更好”，这将是虚假的，因为它非法地使用了未来信息。\n\n测试套件：\n实现以下四个测试案例。对于每个案例，使用提供的伪随机数生成器种子模拟回报以确保确定性，然后使用指定的滚动窗口长度 $W$ 和水平 $\\alpha$ 计算指标。所有 $\\alpha$ 值必须作为小数处理，而不是百分比。\n\n- 案例A（异方差，强持续性）：$T = 4000$，$\\omega = 10^{-6}$，$\\alpha_G = 0.05$，$\\beta_G = 0.94$，$W = 250$，$\\alpha = 0.01$，种子 $= 1729$。\n- 案例B（异方差，中等持续性，较短样本）：$T = 2000$，$\\omega = 10^{-6}$，$\\alpha_G = 0.15$，$\\beta_G = 0.80$，$W = 100$，$\\alpha = 0.05$，种子 $= 2718$。\n- 案例C（独立同分布高斯，边缘案例）：$T = 4000$，$\\omega = 10^{-4}$，$\\alpha_G = 0.00$，$\\beta_G = 0.00$，$W = 250$，$\\alpha = 0.01$，种子 $= 3141$。\n- 案例D（边界：小窗口）：$T = 1500$，$\\omega = 10^{-6}$，$\\alpha_G = 0.10$，$\\beta_G = 0.85$，$W = 30$，$\\alpha = 0.02$，种子 $= 1618$。\n\n最终输出格式：\n- 您的程序应生成单行输出，包含一个由方括号括起来的、逗号分隔的16个浮点数列表，顺序为 $[D_{1,A},D_{2,A},D_{3,A},D_{4,A},D_{1,B},D_{2,B},D_{3,B},D_{4,B},D_{1,C},D_{2,C},D_{3,C},D_{4,C},D_{1,D},D_{2,D},D_{3,D},D_{4,D}]$，其中下标表示测试案例。每个浮点数必须四舍五入到6位小数。不得打印任何其他文本。\n\n数值说明：\n- 滚动标准差应使用分母为 $(W-1)$ 的无偏样本方差。\n- 计算截断正态量时，使用 $q_\\alpha = \\Phi^{-1}(\\alpha)$ 和 $\\mathbb{E}[Z \\mid Z \\le q_\\alpha] = -\\varphi(q_\\alpha)/\\alpha$。\n- 无条件覆盖似然比 $\\text{LR}_{\\text{uc}}$ 使用上述针对 $x=0$ 或 $x=n$ 的约定，以避免未定义的对数。", "solution": "该问题陈述已经过严格验证，被认为是有效的。它在科学上基于金融计量经济学的原理，问题设定良好且客观。它为比较两种风险模型的计算实验提供了一套完整且一致的要求。其目标是量化前视偏差（“幽灵特征”）对风险价值（VaR）和预期亏损（ES）标准回测指标的影响。\n\n解决方案将分四个连续阶段进行开发：\n1.  根据指定的GARCH($1$,$1$)过程模拟金融回报数据。\n2.  实现两种滚动窗口波动率模型：一个正确设定的基准模型和一个有缺陷的幽灵特征模型。\n3.  计算VaR和ES预测，然后为每个模型计算四个不同的回测性能指标。\n4.  计算两种模型在这些指标上的差异，以量化从前视偏差中获得的虚假性能提升。\n\n**第一阶段：数据生成过程**\n\n合成回报序列 $\\{r_t\\}$ 由高斯GARCH($1$,$1$)过程生成。条件方差 $\\sigma_t^2$ 和回报 $r_t$ 由下式给出：\n$$\n\\sigma_t^2 = \\omega + \\alpha_G r_{t-1}^2 + \\beta_G \\sigma_{t-1}^2\n$$\n$$\nr_t = \\sigma_t z_t, \\quad \\text{其中} \\quad z_t \\sim \\mathcal{N}(0,1) \\quad \\text{i.i.d.}\n$$\n该过程在时间 $t=0$ 初始化。对于平稳过程，其中 $\\alpha_G + \\beta_G < 1$，初始方差 $\\sigma_0^2$ 设置为无条件方差 $\\sigma^2 = \\omega / (1 - \\alpha_G - \\beta_G)$。如果 $\\alpha_G + \\beta_G \\ge 1$，则将 $\\sigma_0^2$ 设置为 $\\omega$。\n对于每个测试案例，使用特定的伪随机数生成器种子生成一个包含 $T$ 个回报的序列 $\\{r_0, r_1, \\dots, r_{T-1}\\}$，以确保结果的确定性和可复现性。\n\n**第二阶段：风险模型设定与预测**\n\n使用两种模型来预测单步条件标准差 $\\sigma_t$。预测在从 $t=W$ 到 $t=T-1$ 的回测期间进行，其中 $W$ 是滚动窗口大小，总共有 $n = T-W$ 个观测值。两种模型都使用滚动窗口中回报的无偏样本标准差（分母为 $W-1$）来估计 $\\sigma_t$。\n\n- **基准模型（正确时序）：** 对时间 $t$ 的预测，表示为 $\\sigma_{t, \\text{base}}$，是使用在时间 $t-1$ 可获得的 $W$ 个最新*过去*回报计算的：\n$$ \\sigma_{t, \\text{base}} = \\text{StDev}(\\{r_{t-W}, r_{t-W+1}, \\dots, r_{t-1}\\}) $$\n- **幽灵特征模型（前视偏差）：** 对时间 $t$ 的预测，表示为 $\\sigma_{t, \\text{ghost}}$，是使用一个错误地包含了当前回报 $r_t$ 的窗口计算的：\n$$ \\sigma_{t, \\text{ghost}} = \\text{StDev}(\\{r_{t-W+1}, r_{t-W+2}, \\dots, r_t\\}) $$\n\n对于给定的尾部概率 $\\alpha$，模型 $m \\in \\{\\text{base, ghost}\\}$ 的VaR和ES预测为：\n$$ \\widehat{\\text{VaR}}_{t,m} = q_\\alpha \\sigma_{t,m}, \\quad \\text{其中} \\quad q_\\alpha = \\Phi^{-1}(\\alpha) $$\n$$ \\widehat{\\text{ES}}_{t,m} = -\\frac{\\varphi(q_\\alpha)}{\\alpha} \\sigma_{t,m} $$\n这里，$\\Phi^{-1}(\\cdot)$ 是标准正态分布的逆累积分布函数（分位数函数），$\\varphi(\\cdot)$ 是其概率密度函数。为提高效率，常数 $q_\\alpha$ 和ES的乘数会预先计算。\n\n**第三阶段：回测指标**\n\n对于每个模型，我们使用四个指标在大小为 $n=T-W$ 的回测样本上评估其预测质量。当 $r_t < \\widehat{\\text{VaR}}_t$ 时记录一次VaR超限，由 $I_t = \\mathbf{1}\\{r_t < \\widehat{\\text{VaR}}_t\\}$ 表示。超限总次数为 $x = \\sum_{i=1}^n I_t$。\n\n1.  **命中率绝对误差：** 衡量经验超限频率 $\\widehat{p} = x/n$ 与目标水平 $\\alpha$ 的偏离：\n$$ |\\widehat{p} - \\alpha| $$\n2.  **无条件覆盖似然比 ($\\text{LR}_{\\text{uc}}$)：** 检验假设 $\\mathbb{E}[I_t] = \\alpha$。该统计量为：\n$$ \\text{LR}_{\\text{uc}} = 2\\left[ x \\ln\\left(\\frac{x/n}{\\alpha}\\right) + (n-x)\\ln\\left(\\frac{1 - x/n}{1-\\alpha}\\right)\\right] $$\n严格遵守为 $x=0$ 或 $x=n$ 指定的约定以处理对数项。\n3.  **平均分位数检验损失 ($\\overline{\\ell}^{Q}$)：** 一种对分位数严格一致的评分函数。值越低越好。\n$$ \\overline{\\ell}^{Q} = \\frac{1}{n}\\sum_{t=1}^{n} (\\alpha - I_t)(r_t - \\widehat{\\text{VaR}}_t) $$\n4.  **绝对ES偏差：** 衡量超限日平均预测ES与同一些日子的平均实现回报之间的差异。\n$$ |\\overline{\\widehat{\\text{ES}}}_{\\text{tail}} - \\overline{r}_{\\text{tail}}| $$\n其中 $\\overline{r}_{\\text{tail}} = \\frac{1}{x}\\sum_{t: I_t=1} r_t$ 和 $\\overline{\\widehat{\\text{ES}}}_{\\text{tail}} = \\frac{1}{x}\\sum_{t: I_t=1} \\widehat{\\text{ES}}_t$。如果 $x=0$（无超限），则偏差定义为 $0$，因为没有尾部事件可供评估。\n\n**第四阶段：比较分析与最终输出**\n\n分析的核心是对两种模型的直接比较。对于四个测试案例（A、B、C、D）中的每一个，我们计算基准模型和幽灵特征模型的四个指标。最终要求的输出是这些指标的差值，计算方式为（基准模型指标）-（幽灵模型指标）：\n\n- $D_1 = |\\widehat{p}_{\\text{base}} - \\alpha| - |\\widehat{p}_{\\text{ghost}} - \\alpha|$\n- $D_2 = \\text{LR}_{\\text{uc, base}} - \\text{LR}_{\\text{uc, ghost}}$\n- $D_3 = \\overline{\\ell}^{Q}_{\\text{base}} - \\overline{\\ell}^{Q}_{\\text{ghost}}$\n- $D_4 = |\\overline{\\widehat{\\text{ES}}}_{\\text{tail, base}} - \\overline{r}_{\\text{tail, base}}| - |\\overline{\\widehat{\\text{ES}}}_{\\text{tail, ghost}} - \\overline{r}_{\\text{tail, ghost}}|$\n\n任何 $D_j$ 的正值都表明幽灵特征模型由于使用了未来信息而在性能上出现了虚假的提升。对所有四个测试案例执行该过程，产生16个标量值，这些值将被格式化为所要求的单行输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Implements and compares two rolling Gaussian risk models (VaR and ES),\n    quantifying the effect of 'ghost features' (look-ahead bias) on backtesting outcomes.\n    \"\"\"\n\n    test_cases = [\n        # Case A (heteroskedastic, strong persistence)\n        {'T': 4000, 'omega': 1e-6, 'alpha_G': 0.05, 'beta_G': 0.94, 'W': 250, 'alpha': 0.01, 'seed': 1729},\n        # Case B (heteroskedastic, moderate persistence, shorter sample)\n        {'T': 2000, 'omega': 1e-6, 'alpha_G': 0.15, 'beta_G': 0.80, 'W': 100, 'alpha': 0.05, 'seed': 2718},\n        # Case C (independent and identically distributed Gaussian, edge case)\n        {'T': 4000, 'omega': 1e-4, 'alpha_G': 0.00, 'beta_G': 0.00, 'W': 250, 'alpha': 0.01, 'seed': 3141},\n        # Case D (boundary: small window)\n        {'T': 1500, 'omega': 1e-6, 'alpha_G': 0.10, 'beta_G': 0.85, 'W': 30, 'alpha': 0.02, 'seed': 1618},\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        T, omega, alpha_G, beta_G, W, alpha, seed = case.values()\n        \n        # 1. Generate GARCH(1,1) return series\n        rng = np.random.default_rng(seed)\n        z = rng.normal(size=T)\n        \n        returns = np.zeros(T)\n        sigma2 = np.zeros(T)\n\n        if alpha_G + beta_G < 1.0:\n            sigma2_uncond = omega / (1.0 - alpha_G - beta_G)\n        else:\n            sigma2_uncond = omega\n        \n        sigma2[0] = sigma2_uncond\n        returns[0] = np.sqrt(sigma2[0]) * z[0]\n\n        for t in range(1, T):\n            sigma2[t] = omega + alpha_G * returns[t-1]**2 + beta_G * sigma2[t-1]\n            returns[t] = np.sqrt(sigma2[t]) * z[t]\n        \n        # 2. Setup for backtesting\n        backtest_returns = returns[W:]\n        n_backtest = T - W\n        \n        q_alpha = norm.ppf(alpha)\n        es_multiplier = -norm.pdf(q_alpha) / alpha\n\n        # 3. Calculate metrics for both models\n        models = ['base', 'ghost']\n        metrics_all = {}\n\n        for model_type in models:\n            var_forecasts = np.zeros(n_backtest)\n            es_forecasts = np.zeros(n_backtest)\n            \n            for i in range(n_backtest):\n                t_current = W + i\n                if model_type == 'base':\n                    window = returns[t_current - W : t_current]\n                else: # ghost model\n                    window = returns[t_current - W + 1 : t_current + 1]\n                \n                sigma_t = np.std(window, ddof=1)\n                var_forecasts[i] = q_alpha * sigma_t\n                es_forecasts[i] = es_multiplier * sigma_t\n            \n            # --- Compute all 4 metrics ---\n            \n            # Exceedances\n            I = backtest_returns < var_forecasts\n            x = np.sum(I)\n            \n            # Metric 1: Hit-rate absolute error\n            p_hat = x / n_backtest\n            hit_rate_error = np.abs(p_hat - alpha)\n\n            # Metric 2: LR_uc\n            lr_uc = 0.0\n            if x > 0 and x < n_backtest :\n                term1 = x * np.log(p_hat / alpha)\n                term2 = (n_backtest - x) * np.log((1 - p_hat) / (1 - alpha))\n                lr_uc = 2 * (term1 + term2)\n            elif x == 0 and n_backtest > 0:\n                lr_uc = 2 * (n_backtest * np.log(1 / (1-alpha)))\n            elif x == n_backtest and n_backtest > 0:\n                 lr_uc = 2 * (n_backtest * np.log(1 / alpha))\n\n            # Metric 3: Average quantile check loss\n            avg_check_loss = np.mean((alpha - I) * (backtest_returns - var_forecasts))\n            \n            # Metric 4: Absolute ES bias\n            abs_es_bias = 0.0\n            if x > 0:\n                realized_shortfall = np.mean(backtest_returns[I])\n                mean_es_on_exceedance = np.mean(es_forecasts[I])\n                abs_es_bias = np.abs(mean_es_on_exceedance - realized_shortfall)\n                \n            metrics_all[model_type] = (hit_rate_error, lr_uc, avg_check_loss, abs_es_bias)\n\n        # 4. Compute differences (baseline - ghost)\n        base_metrics = metrics_all['base']\n        ghost_metrics = metrics_all['ghost']\n        diffs = [base_metrics[j] - ghost_metrics[j] for j in range(4)]\n        results.extend(diffs)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```"}]}