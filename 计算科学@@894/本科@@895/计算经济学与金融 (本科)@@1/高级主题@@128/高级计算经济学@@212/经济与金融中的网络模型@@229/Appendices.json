{"hands_on_practices": [{"introduction": "金融市场是由相互关联的资产构成的复杂系统。尽管相关性矩阵捕捉了这些互动，但它们往往过于密集，难以直观解读。本练习将引导您应用网络理论中的一个强大工具——最小生成树 (Minimum Spanning Tree, MST)，来过滤密集的市场信息，揭示其核心的“骨架”结构。通过这个实践，您将学会如何将金融数据（相关性）转化为网络表示，并利用 MST 识别关键关系和结构性变化，例如在市场崩盘前后发生的变化，这是将网络分析应用于现实世界金融数据的基本技能。[@problem_id:2413946]", "id": "2413946", "problem": "您需要设计并实现一个程序，该程序根据相关性数据构建股票市场的网络表示，并利用经济学和金融学中网络模型的核心概念，比较市场崩盘前后的结构。您必须从基本原理出发，避免使用任何临时或未经证实的捷径。仅可使用以下事实：对于标准化的收益向量，其内积对应于皮尔逊积矩相关系数；由内积导出的欧几里得距离构成一个度量。在此基础上，推导一个从相关性到距离的有效变换，该变换在相关性上严格递减并满足度量公理，然后计算由此得到的完全加权图的最小生成树 (MST)。\n\n任务详述：\n- 输入是隐式的，以相关性矩阵测试套件的形式在下方给出。每个矩阵 $\\boldsymbol{\\rho} = (\\rho_{ij})$ 都是对称的，且对所有 $i$ 都有 $\\rho_{ii} = 1$，代表在特定时期（市场崩盘前或后）资产标准化收益之间的成对皮尔逊积矩相关系数。没有单独的数据输入；您的程序必须嵌入并使用下面提供的矩阵。\n- 步骤 $1$：仅使用以下基本事实：对于中心化的、单位方差的向量，其内积等于它们的皮尔逊相关性，且欧几里得范数可导出一个度量。基于此，推导一个关于 $\\rho_{ij}$ 的有效函数 $d_{ij}$，使其在资产集合上构成一个度量距离，并且是 $\\rho_{ij}$ 的严格递减函数。您的程序必须实现您推导出的距离。\n- 步骤 $2$：对于每个给定的相关性矩阵，在资产集上构建完全加权图，其中资产 $i$ 和 $j$ 之间的权重等于推导出的距离 $d_{ij}$。计算该图的最小生成树 (MST)。可使用任何正确的算法，例如 Kruskal 算法或 Prim 算法。为确保在边权重完全相等时结果的确定性，按无序对 $(i,j)$（其中 $i < j$）的字典序来打破平局。\n- 步骤 $3$：对于测试套件中的每个市场，计算：\n  - MST 总权重，定义为 $n$ 个资产的 MST 中 $n-1$ 条边权重之和。\n  - MST 的图直径，定义为 MST 中任意两个节点之间最短路径上的最大边数，即所有节点对之间无权最短路径长度的最大值。\n  - 对于每个市场，计算崩盘前 MST 和崩盘后 MST 之间的共同边数，将边计为基于零的索引的无序对 $\\{i,j\\}$。\n- 输出：对于每个市场，输出元组 $[w_{\\text{pre}}, w_{\\text{post}}, c, \\delta_{\\text{pre}}, \\delta_{\\text{post}}]$，其中 $w_{\\text{pre}}$ 和 $w_{\\text{post}}$ 分别是崩盘前后的 MST 总权重，每个都四舍五入到 $6$ 位小数；$c$ 是共同边的整数数量；$\\delta_{\\text{pre}}$ 和 $\\delta_{\\text{post}}$ 分别是崩盘前后的整数直径。您的程序应生成单行输出，其中包含一个以逗号分隔的列表，该列表用方括号括起来，并按照测试套件给出的顺序汇总所有市场的结果，例如：$[[w_{\\text{pre},1}, w_{\\text{post},1}, c_1, \\delta_{\\text{pre},1}, \\delta_{\\text{post},1}],[w_{\\text{pre},2}, w_{\\text{post},2}, c_2, \\delta_{\\text{pre},2}, \\delta_{\\text{post},2}]]$。\n\n测试套件：\n- 市场 $\\mathcal{A}$（五个资产，索引从 $0$ 到 $4$）：\n  - 崩盘前相关性矩阵 $\\boldsymbol{\\rho}^{\\text{pre}}_{\\mathcal{A}}$：\n  $$\n  \\begin{bmatrix}\n  1 & 0.82 & 0.31 & 0.27 & 0.14 \\\\\n  0.82 & 1 & 0.24 & 0.33 & 0.12 \\\\\n  0.31 & 0.24 & 1 & 0.78 & 0.58 \\\\\n  0.27 & 0.33 & 0.78 & 1 & 0.52 \\\\\n  0.14 & 0.12 & 0.58 & 0.52 & 1\n  \\end{bmatrix}\n  $$\n  - 崩盘后相关性矩阵 $\\boldsymbol{\\rho}^{\\text{post}}_{\\mathcal{A}}$：\n  $$\n  \\begin{bmatrix}\n  1 & 0.88 & 0.72 & 0.62 & 0.40 \\\\\n  0.88 & 1 & 0.64 & 0.71 & 0.42 \\\\\n  0.72 & 0.64 & 1 & 0.85 & 0.70 \\\\\n  0.62 & 0.71 & 0.85 & 1 & 0.68 \\\\\n  0.40 & 0.42 & 0.70 & 0.68 & 1\n  \\end{bmatrix}\n  $$\n- 市场 $\\mathcal{B}$（四个资产，索引从 $0$ 到 $3$）：\n  - 崩盘前相关性矩阵 $\\boldsymbol{\\rho}^{\\text{pre}}_{\\mathcal{B}}$：\n  $$\n  \\begin{bmatrix}\n  1 & 0.60 & -0.20 & 0.10 \\\\\n  0.60 & 1 & 0.05 & -0.25 \\\\\n  -0.20 & 0.05 & 1 & 0.40 \\\\\n  0.10 & -0.25 & 0.40 & 1\n  \\end{bmatrix}\n  $$\n  - 崩盘后相关性矩阵 $\\boldsymbol{\\rho}^{\\text{post}}_{\\mathcal{B}}$：\n  $$\n  \\begin{bmatrix}\n  1 & 0.82 & 0.10 & 0.30 \\\\\n  0.82 & 1 & 0.20 & -0.05 \\\\\n  0.10 & 0.20 & 1 & 0.65 \\\\\n  0.30 & -0.05 & 0.65 & 1\n  \\end{bmatrix}\n  $$\n\n附加要求：\n- 索引是基于零的整数 $0,1,2,\\dots$。\n- 此问题中没有物理单位。\n- 将 $w_{\\text{pre}}$ 和 $w_{\\text{post}}$ 精确四舍五入到 $6$ 位小数。将 $\\delta_{\\text{pre}}$、$\\delta_{\\text{post}}$ 和 $c$ 报告为整数，不进行四舍五入。\n- 您的程序必须是自包含的，并按照上述规定精确地生成一行格式为 $[[\\cdot],[\\cdot]]$ 的输出，除了逗号和括号外，不得有多余的空格或附加文本。", "solution": "问题陈述经评估有效。它在经济物理学领域有科学依据，问题定义明确且客观。它基于应用于金融数据的网络理论的既定原则，提出了一个标准的、可形式化的任务。我们开始进行求解。\n\n解答按规定分三步构建。首先，从相关系数推导出距离度量。其次，详细说明了根据此度量构建最小生成树 (MST) 的算法。第三，描述了计算所需网络属性的流程。\n\n**步骤 1：距离度量的推导**\n\n问题要求从相关系数 $\\rho_{ij}$ 推导出一个距离函数 $d_{ij}$，该函数需满足度量公理，并且是 $\\rho_{ij}$ 的严格递减函数。该推导必须基于两个基本原则：\n$1$. 对于一组资产，在内积空间中存在相应的标准化收益向量 $\\mathbf{v}_i$，它们是单位向量，即 $\\|\\mathbf{v}_i\\|^2 = \\langle \\mathbf{v}_i, \\mathbf{v}_i \\rangle = \\rho_{ii} = 1$，且它们的内积是皮尔逊相关系数，$\\langle \\mathbf{v}_i, \\mathbf{v}_j \\rangle = \\rho_{ij}$。\n$2$. 由内积导出的欧几里得距离 $d(\\mathbf{v}_i, \\mathbf{v}_j) = \\|\\mathbf{v}_i - \\mathbf{v}_j\\|$ 是一个有效的度量。\n\n我们首先展开两个此类向量 $\\mathbf{v}_i$ 和 $\\mathbf{v}_j$ 之间欧几里得距离的平方：\n$$\nd(\\mathbf{v}_i, \\mathbf{v}_j)^2 = \\|\\mathbf{v}_i - \\mathbf{v}_j\\|^2\n$$\n根据内积导出的范数的定义：\n$$\n\\|\\mathbf{v}_i - \\mathbf{v}_j\\|^2 = \\langle \\mathbf{v}_i - \\mathbf{v}_j, \\mathbf{v}_i - \\mathbf{v}_j \\rangle\n$$\n利用内积的双线性性质，上式展开为：\n$$\n\\langle \\mathbf{v}_i, \\mathbf{v}_i \\rangle - 2\\langle \\mathbf{v}_i, \\mathbf{v}_j \\rangle + \\langle \\mathbf{v}_j, \\mathbf{v}_j \\rangle\n$$\n代入前提条件 $\\|\\mathbf{v}_i\\|^2 = 1$ 和 $\\langle \\mathbf{v}_i, \\mathbf{v}_j \\rangle = \\rho_{ij}$：\n$$\nd(\\mathbf{v}_i, \\mathbf{v}_j)^2 = 1 - 2\\rho_{ij} + 1 = 2(1 - \\rho_{ij})\n$$\n取平方根，得到作为 $\\rho_{ij}$ 函数的距离函数 $d_{ij}$：\n$$\nd_{ij} = \\sqrt{2(1 - \\rho_{ij})}\n$$\n我们必须验证此函数 $d_{ij}$ 是一个度量，并且在 $\\rho_{ij}$ 上严格递减。\n\n度量公理的验证：\n- **非负性**：由于 $\\rho_{ij} \\in [-1, 1]$，项 $1 - \\rho_{ij}$ 的范围在 $[0, 2]$ 内。因此，$d_{ij}$ 是实数且非负。$d_{ij} \\ge 0$。\n- **不可分者同一性**：$d_{ij} = 0 \\iff 2(1 - \\rho_{ij}) = 0 \\iff \\rho_{ij} = 1$。这对应于完全相关的资产，在此向量表示中意味着 $\\mathbf{v}_i = \\mathbf{v}_j$。对于 $i \\neq j$，我们假设 $\\rho_{ij} < 1$，因此 $d_{ij} > 0$。同时，$d_{ii} = \\sqrt{2(1 - \\rho_{ii})} = \\sqrt{2(1 - 1)} = 0$。\n- **对称性**：相关性矩阵是对称的，$\\rho_{ij} = \\rho_{ji}$。因此，$d_{ij} = \\sqrt{2(1 - \\rho_{ij})} = \\sqrt{2(1 - \\rho_{ji})} = d_{ji}$。\n- **三角不等式**：$d_{ik} \\le d_{ij} + d_{jk}$。此不等式成立，因为 $d_{ij}$ 正是欧几里得空间中向量之间的欧几里得距离，而三角不等式是该空间的一个基本属性。\n\n单调性验证：\n为确认 $d_{ij}$ 在 $\\rho_{ij}$ 上严格递减，我们考察其对 $\\rho$ 的一阶导数：\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}\\rho} \\left( \\sqrt{2(1 - \\rho)} \\right) = -\\frac{1}{\\sqrt{2(1 - \\rho)}}\n$$\n对于 $\\rho < 1$，分母为实数且为正，因此导数严格为负。这证实了推导出的距离 $d_{ij}$ 是相关性 $\\rho_{ij}$ 的严格递减函数。因此，函数 $d_{ij} = \\sqrt{2(1 - \\rho_{ij})}$ 是要使用的正确度量。\n\n**步骤 2：最小生成树的构建**\n\n对于每个相关性矩阵 $\\boldsymbol{\\rho}$，我们构建一个完全加权图 $G = (V, E)$，其中顶点集 $V$ 代表资产，任意两个顶点 $i$ 和 $j$ 之间边的权重由距离 $d_{ij}$ 给出。该图的最小生成树 (MST) 是一个子图，它以最小的可能边权重之和连接所有顶点，且不包含任何环路。\n\n我们将使用 Kruskal 算法来计算 MST。该算法操作如下：\n$1$. 创建一个包含图中所有边的列表，每条边表示为元组 $(w, u, v)$，其中 $w$是权重 $d_{uv}$，$u, v$ 是顶点索引且 $u < v$。对于一个有 $n$ 个资产的图，共有 $\\binom{n}{2} = \\frac{n(n-1)}{2}$ 条这样的边。\n$2$. 对此边列表按权重升序排序。为确保确定性，权重相等时按顶点对 $(u,v)$ 的字典序打破平局。对于两条权重相同的边，字典序较小的 $(u, v)$ 对所对应的边被优先选择。\n$3$. 初始化一个并查集 (Disjoint Set Union, DSU) 数据结构，其中每个顶点初始时在各自的集合中。\n$4$. 遍历排序后的边列表。对于每条边 $(w, u, v)$：\n    - 使用 DSU 的 `find` 操作检查顶点 $u$ 和 $v$ 是否属于同一个集合。\n    - 如果不属于，则该边不会形成环路。将此边添加到 MST 中，并使用 DSU 的 `union` 操作合并包含 $u$ 和 $v$ 的集合。\n$5$. 当 $n-1$ 条边被添加到 MST 后，算法终止。\n\n**步骤 3：网络属性的计算**\n\n对每个市场的崩盘前和崩盘后两种情况构建好 MST 后，我们计算以下属性：\n\n- **MST 总权重 ($w$)：** 这是 MST 中所有边权重的总和。对于一个边集为 $E_{\\text{MST}}$ 的 MST，其总权重为 $w = \\sum_{\\{i,j\\} \\in E_{\\text{MST}}} d_{ij}$。该值需为崩盘前 ($w_{\\text{pre}}$) 和崩盘后 ($w_{\\text{post}}$) 的 MST 分别计算，并四舍五入到 $6$ 位小数。\n\n- **MST 直径 ($\\delta$)：** 树的直径是其任意两个节点之间最长最短路径的长度。路径长度按边数（无权）计算。我们使用以下标准的两遍式算法来计算它：\n    $1$. 构建 MST 的邻接表表示。\n    $2$. 从任意节点 $s$ 开始执行一次广度优先搜索 (BFS)，找到离它最远的节点 $u$。\n    $3$. 从节点 $u$ 开始执行第二次 BFS，找到离它最远的节点 $v$。从 $u$ 到 $v$ 的距离就是树的直径。\n    该值需为崩盘前 ($\\delta_{\\text{pre}}$) 和崩盘后 ($\\delta_{\\text{post}}$) 的 MST 分别计算。\n\n- **共同边数 ($c$)：** 这是一个整数值，表示崩盘前 MST 和崩盘后 MST 边集的交集大小。边被视作基于零的索引的无序对 $\\{i, j\\}$。通过将每条边规范地表示为元组 $(i, j)$ （其中 $i < j$），我们可以找到两个 MST 边集的交集。\n\n将这些步骤系统地应用于测试套件中提供的每个市场的数据，以生成最终输出。", "answer": "```python\nimport numpy as np\nimport math\n\n# No other libraries are permitted as per instructions.\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    It processes each market's pre- and post-crash correlation matrices,\n    computes the required metrics, and prints the formatted result.\n    \"\"\"\n\n    class DSU:\n        \"\"\"A simple Disjoint Set Union data structure for Kruskal's algorithm.\"\"\"\n        def __init__(self, n):\n            self.parent = list(range(n))\n            self.num_sets = n\n\n        def find(self, i):\n            \"\"\"Find the representative of the set containing element i with path compression.\"\"\"\n            if self.parent[i] == i:\n                return i\n            self.parent[i] = self.find(self.parent[i])\n            return self.parent[i]\n\n        def union(self, i, j):\n            \"\"\"Merge the sets containing elements i and j.\"\"\"\n            root_i = self.find(i)\n            root_j = self.find(j)\n            if root_i != root_j:\n                self.parent[root_i] = root_j\n                self.num_sets -= 1\n                return True\n            return False\n\n    def get_mst_diameter(n, mst_edges):\n        \"\"\"\n        Computes the diameter of a tree (given as an MST edge list).\n        The diameter is the longest shortest path between any two nodes.\n        Path length is the number of edges.\n        \"\"\"\n        if n <= 1:\n            return 0\n        \n        adj = [[] for _ in range(n)]\n        for u, v in mst_edges:\n            adj[u].append(v)\n            adj[v].append(u)\n\n        def bfs(start_node):\n            \"\"\"Performs a BFS to find the farthest node and distance from a start node.\"\"\"\n            distances = [-1] * n\n            queue = [(start_node, 0)]\n            distances[start_node] = 0\n            \n            head = 0\n            farthest_node = start_node\n            max_dist = 0\n\n            while head < len(queue):\n                u, dist = queue[head]\n                head += 1\n\n                if dist > max_dist:\n                    max_dist = dist\n                    farthest_node = u\n\n                for v in adj[u]:\n                    if distances[v] == -1:\n                        distances[v] = dist + 1\n                        queue.append((v, dist + 1))\n            \n            return farthest_node, max_dist\n\n        # 1. First BFS from an arbitrary node (0) to find one endpoint of a diameter.\n        node_u, _ = bfs(0)\n        # 2. Second BFS from that endpoint to find the actual diameter.\n        _, diameter = bfs(node_u)\n        \n        return diameter\n\n    def process_correlation_matrix(rho_matrix):\n        \"\"\"\n        Takes a correlation matrix and returns MST properties:\n        total weight, diameter, and the set of edges.\n        \"\"\"\n        n = rho_matrix.shape[0]\n        \n        # Step 1: Derive distance and create a list of edges with weights.\n        # d_ij = sqrt(2 * (1 - rho_ij))\n        # The tie-breaking is handled by sorting on (weight, u, v).\n        edges = []\n        for i in range(n):\n            for j in range(i + 1, n):\n                rho_ij = rho_matrix[i, j]\n                # Defensive check for floating point inaccuracies leading to rho > 1\n                if rho_ij > 1.0:\n                    rho_ij = 1.0\n                dist = math.sqrt(2.0 * (1.0 - rho_ij))\n                edges.append((dist, i, j))\n        \n        # Sort edges: primary key is weight, secondary keys are i then j.\n        edges.sort()\n\n        # Step 2: Compute MST using Kruskal's algorithm.\n        dsu = DSU(n)\n        mst_edges = []\n        mst_weight = 0.0\n        \n        for dist, u, v in edges:\n            if dsu.union(u, v):\n                mst_edges.append((u, v))\n                mst_weight += dist\n                if len(mst_edges) == n - 1:\n                    break\n        \n        # Step 3: Compute MST diameter.\n        mst_diameter = get_mst_diameter(n, mst_edges)\n        \n        # Return canonical representation of edges (sorted tuples) for comparison\n        mst_edge_set = {tuple(sorted(edge)) for edge in mst_edges}\n\n        return mst_weight, mst_diameter, mst_edge_set\n\n    # Test suite provided in the problem description.\n    test_cases = [\n        # Market A\n        {\n            \"name\": \"Market A\",\n            \"pre\": np.array([\n                [1.00, 0.82, 0.31, 0.27, 0.14],\n                [0.82, 1.00, 0.24, 0.33, 0.12],\n                [0.31, 0.24, 1.00, 0.78, 0.58],\n                [0.27, 0.33, 0.78, 1.00, 0.52],\n                [0.14, 0.12, 0.58, 0.52, 1.00]\n            ]),\n            \"post\": np.array([\n                [1.00, 0.88, 0.72, 0.62, 0.40],\n                [0.88, 1.00, 0.64, 0.71, 0.42],\n                [0.72, 0.64, 1.00, 0.85, 0.70],\n                [0.62, 0.71, 0.85, 1.00, 0.68],\n                [0.40, 0.42, 0.70, 0.68, 1.00]\n            ])\n        },\n        # Market B\n        {\n            \"name\": \"Market B\",\n            \"pre\": np.array([\n                [1.00, 0.60, -0.20, 0.10],\n                [0.60, 1.00, 0.05, -0.25],\n                [-0.20, 0.05, 1.00, 0.40],\n                [0.10, -0.25, 0.40, 1.00]\n            ]),\n            \"post\": np.array([\n                [1.00, 0.82, 0.10, 0.30],\n                [0.82, 1.00, 0.20, -0.05],\n                [0.10, 0.20, 1.00, 0.65],\n                [0.30, -0.05, 0.65, 1.00]\n            ])\n        }\n    ]\n\n    result_strings = []\n    \n    for market_data in test_cases:\n        w_pre, d_pre, edges_pre = process_correlation_matrix(market_data[\"pre\"])\n        w_post, d_post, edges_post = process_correlation_matrix(market_data[\"post\"])\n        \n        # Calculate number of common edges\n        common_edges_count = len(edges_pre.intersection(edges_post))\n        \n        # Format the result tuple for this market\n        w_pre_str = f\"{w_pre:.6f}\"\n        w_post_str = f\"{w_post:.6f}\"\n        \n        market_result_str = (\n            f\"[{w_pre_str},{w_post_str},{common_edges_count},\"\n            f\"{d_pre},{d_post}]\"\n        )\n        result_strings.append(market_result_str)\n\n    # Print the final output in the exact required format\n    final_output = f\"[{','.join(result_strings)}]\"\n    print(final_output)\n\nsolve()\n```"}, {"introduction": "金融领域的一个核心议题是系统性风险，即单个机构的失败可能通过网络引发连锁反应。因此，识别具有系统重要性的机构对于风险管理至关重要。本练习运用著名的网络中心性指标 PageRank 来量化金融网络中节点的重要性，并模拟一个通过移除这些关键节点来观察网络完整性所受影响的“压力测试”。完成此练习后，您将掌握一种评估网络韧性并识别系统重要性金融机构的先进方法，这在现代金融监管和风险管理中是一项至关重要的任务。[@problem_id:2413880]", "id": "2413880", "problem": "考虑一个有向加权金融网络，由一个邻接矩阵 $W \\in \\mathbb{R}_{\\ge 0}^{n \\times n}$ 表示，其元素为 $W_{ij}$，其中 $W_{ij}$ 表示从节点 $i$ 到节点 $j$ 的非负敞口权重。设第 $t$ 步的活跃节点集合为 $V_t \\subseteq \\{0,1,\\dots,n-1\\}$，且 $|V_t| = m_t$。对于任何活跃集合 $V_t$，定义行随机转移矩阵 $P^{(t)} \\in \\mathbb{R}^{m_t \\times m_t}$ 如下：\n- 对每个活跃节点 $i \\in V_t$，令 $s_i^{(t)} = \\sum_{j \\in V_t} W_{ij}$，\n- 若 $s_i^{(t)} > 0$，则对 $j \\in V_t$ 设 $P_{ij}^{(t)} = W_{ij} / s_i^{(t)}$，\n- 若 $s_i^{(t)} = 0$（一个悬挂节点），则对所有 $j \\in V_t$ 设 $P_{ij}^{(t)} = 1/m_t$。\n\n固定一个阻尼因子 $d \\in (0,1)$。第 $t$ 步的 PageRank 向量 $\\pi^{(t)} \\in \\mathbb{R}^{m_t}$ 定义为以下方程的唯一解：\n$$\n\\pi^{(t)} = (1-d)\\frac{\\mathbf{1}}{m_t} + d \\left(P^{(t)}\\right)^\\top \\pi^{(t)},\n$$\n并满足归一化条件 $\\sum_{i \\in V_t} \\pi^{(t)}_i = 1$ 且对于所有 $i \\in V_t$ 都有 $\\pi^{(t)}_i \\ge 0$。\n\n定义一个压力测试序列如下。初始化 $V_0 = \\{0,1,\\dots,n-1\\}$。在每一步 $t \\in \\{0,1,2,\\dots\\}$：\n1. 在由 $V_t$ 诱导的子网络上计算 $\\pi^{(t)}$。\n2. 选择 $v_t \\in \\arg\\max_{i \\in V_t} \\pi^{(t)}_i$；若出现平局，则选择在 $\\{0,1,\\dots,n-1\\}$ 中索引最小的节点。\n3. 移除所选节点：$V_{t+1} = V_t \\setminus \\{v_t\\}$。\n\n对于任何活跃集合 $V_t$，定义其诱导子图的无向版本：若 $W_{ij} > 0$ 或 $W_{ji} > 0$ 且 $i,j \\in V_t$，则在 $i$ 和 $j$ 之间放置一条无向边。设 $C^{(t)}$ 为此无向子图的最大弱连通分量的大小（节点数），其中孤立节点计为大小为 1 的分量，空图的分量大小为 0。\n\n给定一个初始网络 $(W, n)$、一个阻尼因子 $d \\in (0,1)$ 和一个阈值 $\\theta \\in (0,1]$，定义失效时间\n$$\nk^\\star = \\min \\left\\{ t \\in \\{0,1,\\dots,n\\} \\,:\\, C^{(t)} \\le \\theta \\cdot n \\right\\}.\n$$\n如果初始网络已满足 $C^{(0)} \\le \\theta \\cdot n$，则 $k^\\star = 0$。每个测试用例所需的输出是整数 $k^\\star$。\n\n您的任务是编写一个程序，对于下述每个测试用例，根据上述定义计算出相应的整数 $k^\\star$。在每一步中，必须在当前的活跃集合 $V_t$ 上重新计算 PageRank 中心性。最大化集合中的平局情况，必须通过选择在 $\\{0,1,\\dots,n-1\\}$ 中拥有最小原始索引的节点来解决。\n\n测试套件（每个用例指定了 $n$、权重为1的 $W$ 的非零边、阻尼因子 $d$ 和阈值 $\\theta$）：\n- 用例 A：\n  - $n = 4$，\n  - 权重为1的非零有向边：$(1,0)$、$(2,0)$、$(3,0)$，所有其他项为0，\n  - $d = 0.85$，\n  - $\\theta = 0.5$。\n- 用例 B：\n  - $n = 5$，\n  - 权重为1的有向环：$(0,1)$、$(1,2)$、$(2,3)$、$(3,4)$、$(4,0)$，\n  - $d = 0.85$，\n  - $\\theta = 0.6$。\n- 用例 C：\n  - $n = 6$，\n  - 权重为1的完全有向网络，其中所有 $i \\ne j$ 的有序对 $(i,j)$ 上权重为1，对角线上为0，\n  - $d = 0.9$，\n  - $\\theta = 0.5$。\n- 用例 D：\n  - $n = 5$，\n  - 两个权重为1的弱连通分量：$(0,1)$、$(1,0)$、$(2,3)$、$(3,4)$，所有其他项为0，\n  - $d = 0.85$，\n  - $\\theta = 0.8$。\n\n最终输出格式：您的程序应生成单行输出，其中包含四个整数 $[k_A,k_B,k_C,k_D]$ 的结果，按用例 A、B、C、D 的顺序排列，以逗号分隔，并用方括号括起来，例如 $[1,2,3,4]$。不应打印任何额外文本。", "solution": "该问题陈述已经过验证，被认为是科学上合理、定义明确、客观且计算上可行的。它描述了一个有向网络上的离散时间节点移除过程，其中每一步选择移除的节点由其 PageRank 中心性确定。当网络的结构完整性（通过其最大弱连通分量的大小来衡量）低于指定阈值时，该过程终止。\n\n解决方案是对该压力测试序列的直接模拟。模拟从步骤 $t=0$ 开始迭代进行，最多到 $t=n$。在每一步 $t$，网络的状态由活跃节点集合 $V_t$ 定义。执行以下计算序列。\n\n首先，评估主要终止准则。这需要计算 $C^{(t)}$，即由活跃节点 $V_t$ 诱导的子图的最大弱连通分量的大小。从活跃节点概念上构建一个无向图，如果原始权重矩阵 $W$ 满足 $W_{ij} > 0$ 或 $W_{ji} > 0$，则在节点 $i, j \\in V_t$ 之间存在一条边。使用标准的图遍历算法（如广度优先搜索 (BFS) 或深度优先搜索 (DFS)）来找到该无向图的连通分量的大小。这些大小的最大值即为 $C^{(t)}$。如果 $C^{(t)} \\le \\theta \\cdot n$，则过程终止，失效时间为 $k^\\star = t$。\n\n如果未满足终止条件，则模拟继续进行，以确定要移除的下一个节点。这需要计算由 $V_t$ 诱导的子网络的 PageRank 向量 $\\pi^{(t)}$。设 $m_t = |V_t|$ 为活跃节点的数量。行随机转移矩阵 $P^{(t)} \\in \\mathbb{R}^{m_t \\times m_t}$ 根据所提供的规则构建。对于一个有指向 $V_t$ 中其他节点的出链的节点 $i \\in V_t$，其在 $P^{(t)}$ 中对应的行通过其出度权重和 $s_i^{(t)} = \\sum_{j \\in V_t} W_{ij}$ 进行归一化。对于悬挂节点（$s_i^{(t)}=0$），对应的行为均匀分布，即对所有 $j \\in V_t$ 都有 $P_{ij}^{(t)} = 1/m_t$。\n\nPageRank 向量 $\\pi^{(t)}$ 是以下线性系统的解：\n$$\n\\left(I - d \\left(P^{(t)}\\right)^\\top\\right) \\pi^{(t)} = (1-d)\\frac{\\mathbf{1}}{m_t}\n$$\n其中 $I$ 是 $m_t \\times m_t$ 的单位矩阵，$d \\in (0,1)$ 是阻尼因子，$\\mathbf{1}$ 是全一向量。该系统是非奇异的，对于 $\\pi^{(t)}$ 存在唯一的非负解，可以使用标准的线性方程求解器进行数值求解。\n\n接下来，选择要移除的节点 $v_t$。$v_t$ 是 $V_t$ 中 PageRank 分数最高的节点。形式上，$v_t$ 从集合 $\\arg\\max_{i \\in V_t} \\pi^{(t)}_i$ 中选择。如果多个节点共享最高的 PageRank 分数，则通过从集合 $\\{0, 1, \\dots, n-1\\}$ 中选择具有最小原始索引的节点来打破平局。\n\n最后，通过移除所选节点来更新下一步的活跃节点集：$V_{t+1} = V_t \\setminus \\{v_t\\}$。然后模拟进入步骤 $t+1$。对每个测试用例重复这整个过程，直到确定相应的 $k^\\star$。", "answer": "```python\nimport numpy as np\n\ndef get_largest_wcc_size(W, active_nodes):\n    \"\"\"\n    Computes the size of the largest weakly connected component (WCC).\n    An undirected graph is formed on the active_nodes, with an edge (i, j)\n    if W[i,j] > 0 or W[j,i] > 0.\n    \"\"\"\n    m = len(active_nodes)\n    if m == 0:\n        return 0\n\n    # Map from original node index to its index in the active_nodes list (0 to m-1)\n    node_to_idx = {node: i for i, node in enumerate(active_nodes)}\n    \n    # Adjacency list for the undirected version of the subgraph\n    adj = [[] for _ in range(m)]\n    has_edges = False\n    for i in range(m):\n        for j in range(i + 1, m):\n            u, v = active_nodes[i], active_nodes[j]\n            if W[u, v] > 0 or W[v, u] > 0:\n                adj[i].append(j)\n                adj[j].append(i)\n                has_edges = True\n\n    # If no edges, all nodes are isolated components of size 1\n    if not has_edges:\n        return 1\n\n    visited = [False] * m\n    max_size = 0\n    for i in range(m):\n        if not visited[i]:\n            current_size = 0\n            q = [i]\n            visited[i] = True\n            head = 0\n            while head < len(q):\n                u_idx = q[head]\n                head += 1\n                current_size += 1\n                for v_idx in adj[u_idx]:\n                    if not visited[v_idx]:\n                        visited[v_idx] = True\n                        q.append(v_idx)\n            max_size = max(max_size, current_size)\n    return max_size\n\ndef compute_pagerank(W_full, active_nodes, d):\n    \"\"\"\n    Computes the PageRank vector for the subgraph induced by active_nodes.\n    \"\"\"\n    m = len(active_nodes)\n    if m == 0:\n        return np.array([])\n\n    # Create the submatrix of W corresponding to active nodes\n    W_sub = W_full[np.ix_(active_nodes, active_nodes)]\n    \n    # Calculate row sums for normalization\n    row_sums = W_sub.sum(axis=1)\n    \n    P = np.zeros((m, m))\n    \n    # Handle non-dangling nodes\n    non_dangling_mask = row_sums > 0\n    if np.any(non_dangling_mask):\n      P[non_dangling_mask] = W_sub[non_dangling_mask] / row_sums[non_dangling_mask, np.newaxis]\n\n    # Handle dangling nodes\n    dangling_mask = ~non_dangling_mask\n    if np.any(dangling_mask):\n        P[dangling_mask] = 1.0 / m\n        \n    # Solve the linear system (I - d*P^T) * pi = (1-d)/m * 1\n    I = np.identity(m)\n    A = I - d * P.T\n    b = (1.0 - d) / m * np.ones(m)\n    \n    pi = np.linalg.solve(A, b)\n    return pi\n\ndef solve_case(n, W, d, theta):\n    \"\"\"\n    Runs the stress-testing simulation for a single test case.\n    \"\"\"\n    active_nodes = list(range(n))\n    threshold_size = theta * n\n    \n    for t in range(n + 1):\n        # 1. Compute largest WCC size C^(t)\n        C_t = get_largest_wcc_size(W, active_nodes)\n        \n        # 2. Check failure condition\n        if C_t <= threshold_size:\n            return t\n        \n        # 3. Compute PageRank\n        pi = compute_pagerank(W, active_nodes, d)\n        \n        # 4. Select node to remove\n        max_pi = -1.0\n        # Find the maximum PageRank value\n        if pi.size > 0:\n            max_pi = np.max(pi)\n\n        # Find all nodes that achieve this maximum value\n        candidates = []\n        for i, p_val in enumerate(pi):\n            if np.isclose(p_val, max_pi):\n                candidates.append(active_nodes[i])\n        \n        # Tie-break by choosing the smallest original index\n        node_to_remove = min(candidates)\n        \n        # 5. Update active set\n        active_nodes.remove(node_to_remove)\n    \n    # This part should not be reached given the problem constraints\n    # C^{(n)} = 0, so the loop will always find a k* <= n.\n    return n\n\ndef solve():\n    \"\"\"\n    Defines test cases and computes the failure time k* for each.\n    \"\"\"\n    # Case A\n    n_A = 4\n    W_A = np.zeros((n_A, n_A))\n    W_A[1, 0] = 1\n    W_A[2, 0] = 1\n    W_A[3, 0] = 1\n    d_A = 0.85\n    theta_A = 0.5\n    \n    # Case B\n    n_B = 5\n    W_B = np.zeros((n_B, n_B))\n    edges_B = [(0, 1), (1, 2), (2, 3), (3, 4), (4, 0)]\n    for i, j in edges_B:\n        W_B[i, j] = 1\n    d_B = 0.85\n    theta_B = 0.6\n    \n    # Case C\n    n_C = 6\n    W_C = np.ones((n_C, n_C)) - np.identity(n_C)\n    d_C = 0.9\n    theta_C = 0.5\n    \n    # Case D\n    n_D = 5\n    W_D = np.zeros((n_D, n_D))\n    edges_D = [(0, 1), (1, 0), (2, 3), (3, 4)]\n    for i, j in edges_D:\n        W_D[i, j] = 1\n    d_D = 0.85\n    theta_D = 0.8\n\n    test_cases = [\n        (n_A, W_A, d_A, theta_A),\n        (n_B, W_B, d_B, theta_B),\n        (n_C, W_C, d_C, theta_C),\n        (n_D, W_D, d_D, theta_D),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, W, d, theta = case\n        k_star = solve_case(n, W, d, theta)\n        results.append(k_star)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}, {"introduction": "前面的练习分析了给定的网络结构，但这些网络从何而来？经济和金融网络是个体参与者战略决策的产物。本练习引入一个网络形成博弈模型，其中个体需要在中心性带来的收益与建立和维护连接的成本之间进行权衡。通过模拟，您将观察到一个稳定的网络结构如何从这些微观层面的激励中涌现出来。这个实践将带您从静态分析走向网络形成的动态世界，深入理解个体层面的经济权衡如何塑造金融和社交网络的宏观拓扑结构。[@problem_id:2413938]", "id": "2413938", "problem": "考虑一个静态网络形成博弈，其中有一个由 $N=\\{0,1,\\dots,n-1\\}$ 索引的有限代理人集合。一个（简单、无向）网络由一组无序链接 $G \\subseteq \\{\\{i,j\\} \\mid i,j \\in N, i \\neq j\\}$ 表示，等价地，由一个元素在 $\\{0,1\\}$ 中且对角线为零的对称邻接矩阵表示。对于任何网络 $G$，定义代理人 $i$ 和 $j$ 之间的最短路径距离 $d_G(i,j)$ 为连接 $i$ 和 $j$ 的路径上的最小链接数；如果不存在路径，则 $d_G(i,j)=+\\infty$。代理人 $i$ 在网络 $G$ 中的度为 $\\deg_i(G)=|\\{j \\in N \\setminus \\{i\\} \\mid \\{i,j\\} \\in G\\}|$。\n\n每个代理人 $i$ 获得的收益与其归一化调和中心性成正比，并为每条关联的链接支付线性成本。具体来说，对于参数 $B>0$ 和 $c>0$，代理人 $i$ 在网络 $G$ 中的效用为\n$$\nu_i(G)=B \\cdot C_i(G)-c \\cdot \\deg_i(G),\n$$\n其中归一化调和中心性为\n$$\nC_i(G)=\\frac{1}{n-1}\\sum_{\\substack{j \\in N \\\\ j \\neq i}} \\frac{1}{d_G(i,j)},\n$$\n约定当 $d_G(i,j)=+\\infty$ 时，$\\frac{1}{d_G(i,j)}=0$。\n\n该博弈从空网络 $G=\\varnothing$ 开始，通过短视、双方同意的调整进行演化，过程如下。考虑所有满足 $0 \\le i < j \\le n-1$ 的无序对 $(i,j)$ 按字典顺序排列的有序列表。删除步骤允许任何现有的链接 $\\{i,j\\}\\in G$ 被单方面移除，前提是该移除能严格增加至少一个端点的效用；即，如果 $u_i(G \\setminus \\{\\{i,j\\}\\})>u_i(G)$ 或 $u_j(G \\setminus \\{\\{i,j\\}\\})>u_j(G)$，则链接 $\\{i,j\\}$ 被删除。添加步骤允许任何不存在的链接 $\\{i,j\\}\\notin G$ 被添加，前提是该添加能弱增加两个端点的效用，并严格增加至少一个端点的效用；即，如果 $u_i(G \\cup \\{\\{i,j\\}\\})\\ge u_i(G)$ 且 $u_j(G \\cup \\{\\{i,j\\}\\})\\ge u_j(G)$，并且 $u_i(G \\cup \\{\\{i,j\\}\\})>u_i(G)$ 或 $u_j(G \\cup \\{\\{i,j\\}\\})>u_j(G)$ 之一成立，则链接 $\\{i,j\\}$ 被添加。在每一轮中，按字典顺序处理删除操作，应用第一个满足所述条件的变化（如果有的话），然后重新开始删除扫描；当没有删除操作适用时，按字典顺序处理添加操作，应用第一个满足所述条件的变化（如果有的话），然后从删除操作重新开始。当对所有删除和添加操作的完整遍历没有产生任何变化时，该过程终止。最终的网络在所述规则下是双方稳定的。\n\n你的任务是实现一个程序，对于下面测试套件中的每个参数三元组 $(n,B,c)$，从空网络开始，执行上述调整过程直到终止，然后返回最终网络中的链接总数，即基数 $|G|$。\n\n测试套件：\n- 案例 A（理想路径，密集结果）：$(n,B,c)=(4,1.0,0.1)$。\n- 案例 B（中等成本，稀疏轮辐式结果）：$(n,B,c)=(6,1.0,0.15)$。\n- 案例 C（高成本，空网络结果）：$(n,B,c)=(5,1.0,0.26)$。\n- 案例 D（$n=5$ 的完全网络在删除无差异时的边界条件）：$(n,B,c)=(5,1.0,0.125)$。\n\n最终输出格式：\n- 你的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔的整数列表，其顺序与测试套件相同。例如，输出应类似于 $[x_A,x_B,x_C,x_D]$，其中 $x_A$ 是案例 A 的 $|G|$，$x_B$ 是案例 B 的 $|G|$，$x_C$ 是案例 C 的 $|G|$，以及 $x_D$ 是案例 D 的 $|G|$。", "solution": "该问题要求模拟一个短视、双方同意的网络形成博弈，以找出在几组参数下，最终稳定网络中的链接数量。对问题陈述的验证证实了它在科学上植根于网络形成的经济学理论，是适定的、客观的，并且其算法描述足够详细，可以得到唯一解。因此，我们可以着手设计和实现一个计算解决方案。\n\n解决方案的核心是一个确定性模拟，该模拟严格遵守所描述的演化动态。我们的实现围绕以下组件构建：\n\n**1. 网络表示**\n具有 $n$ 个代理人的网络 $G$ 由一个 $n \\times n$ 的对称邻接矩阵表示，也记为 $G$，其中如果链接 $\\{i,j\\}$ 存在，则 $G_{ij} = 1$，否则 $G_{ij} = 0$。对角线元素始终为 $0$。\n\n**2. 辅助计算**\n在评估代理人效用之前，必须从当前网络 $G$ 计算出两个主要量：\n\n- **所有对最短路径 (APSP)：** 最短路径距离矩阵 $D$（其中 $D_{ij} = d_G(i,j)$）是基础。我们使用 Floyd-Warshall 算法计算该矩阵，该算法在 `scipy.sparse.csgraph.shortest_path` 函数中有高效实现。此函数通过分配无限距离来正确处理不连通的分量。\n\n- **代理人效用：** 对于每个代理人 $i \\in N$，其效用 $u_i(G)$ 根据指定公式计算：\n$$u_i(G) = B \\cdot C_i(G) - c \\cdot \\deg_i(G)$$\n度 $\\deg_i(G) = \\sum_{j=0}^{n-1} G_{ij}$ 是邻接矩阵第 $i$ 行的总和。归一化调和中心性 $C_i(G)$ 计算如下：\n$$C_i(G) = \\frac{1}{n-1}\\sum_{j \\in N, j \\neq i} \\frac{1}{d_G(i,j)}$$\n这使用预先计算的 APSP 矩阵 $D$ 进行计算。约定 $\\frac{1}{+\\infty} = 0$ 通过浮点数运算自然处理。\n\n**3. 网络动态模拟**\n模拟从空网络 $G=\\varnothing$ 开始，并迭代进行，直到达到稳定状态。该过程由一个主循环控制，只要在一轮完整的删除和添加操作中对网络进行了任何更改，该循环就会继续。\n\n- **字典顺序：** 所有潜在链接 $\\{i,j\\}$ 都按照满足 $0 \\le i < j \\le n-1$ 的对 $(i,j)$ 的字典顺序进行考虑。此有序列表是预先计算的。\n\n- **删除阶段：** 算法首先尝试删除链接。它进入一个子循环，扫描所有当前存在的链接。对于找到的第一个满足删除标准的链接——即，其移除严格增加了至少一个端点的效用（对于 $k=i$ 或 $k=j$，$u_k(G \\setminus \\{\\{i,j\\}\\}) > u_k(G)$）——该链接被移除，并且删除扫描立即从链接对列表的开头重新开始。只有当对所有现有链接的完整扫描没有产生任何删除时，此阶段才完成。\n\n- **添加阶段：** 当且仅当删除阶段结束时没有发生任何变化，算法才进入添加阶段。它对所有不存在的链接执行一次扫描。找到的第一个满足双方同意标准的链接——即，其添加弱增加了两个端点的效用，并对至少一个端点严格增加其效用（对于 $k \\in \\{i,j\\}$，$u_k(G \\cup \\{\\{i,j\\}\\}) \\ge u_k(G)$ 且至少对于一个 $k$ 是严格不等式）——被添加到网络中。\n\n- **重启与终止：** 如果添加了一个链接，整个过程将从新修改的网络上的删除阶段重新开始。当经过删除阶段和随后的添加阶段的完整遍历后，网络结构没有发生任何修改时，模拟终止。最终生成的网络在指定规则下是双方稳定的。\n\n**4. 最终结果**\n对于测试套件中提供的每个参数三元组 $(n,B,c)$，执行模拟，并计算和存储最终网络中的链接总数 $|G| = \\frac{1}{2} \\sum_{i,j} G_{ij}$。最终输出将这些结果汇总到一个列表中。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse.csgraph import shortest_path\n\ndef calculate_utility(agent_idx, adj_matrix, B, c, n, distances):\n    \"\"\"Calculates the utility for a single agent.\"\"\"\n    degree = np.sum(adj_matrix[agent_idx])\n    \n    dist_row = distances[agent_idx]\n    \n    # The sum is over j != agent_idx.\n    # We handle division by zero (for d(i,i)=0) and infinity cleanly.\n    with np.errstate(divide='ignore'):\n        inv_distances = 1.0 / dist_row\n    \n    inv_distances[np.isinf(inv_distances)] = 0.0\n    inv_distances[agent_idx] = 0.0 # Exclude self from sum\n    \n    # n-1 is always positive for n>1\n    closeness = np.sum(inv_distances) / (n - 1)\n    \n    utility = B * closeness - c * degree\n    return utility\n\ndef run_simulation(n, B, c):\n    \"\"\"\n    Runs the network formation simulation for a given set of parameters.\n    \"\"\"\n    adj = np.zeros((n, n), dtype=np.int8)\n    pairs = [(i, j) for i in range(n) for j in range(i + 1, n)]\n\n    while True:\n        network_changed_in_round = False\n\n        # --- Deletion Phase ---\n        # A deletion restarts the deletion scan. This is handled by the inner while loop.\n        while True:\n            deletion_made_in_scan = False\n            \n            # Pre-calculate current utilities before scanning for deletions\n            current_distances = shortest_path(csgraph=adj, directed=False)\n            current_utilities = {k: calculate_utility(k, adj, B, c, n, current_distances) for k in range(n)}\n            \n            for i, j in pairs:\n                if adj[i, j] == 1:\n                    # Tentatively delete the link\n                    adj[i, j] = adj[j, i] = 0\n                    \n                    new_distances = shortest_path(csgraph=adj, directed=False)\n                    util_i_new = calculate_utility(i, adj, B, c, n, new_distances)\n                    util_j_new = calculate_utility(j, adj, B, c, n, new_distances)\n                    \n                    # Check deletion condition (strict unilateral improvement)\n                    if util_i_new > current_utilities[i] or util_j_new > current_utilities[j]:\n                        # Deletion is confirmed. The adj matrix is already updated.\n                        network_changed_in_round = True\n                        deletion_made_in_scan = True\n                        break  # Restart deletion scan\n                    else:\n                        # Revert the deletion\n                        adj[i, j] = adj[j, i] = 1\n            \n            if not deletion_made_in_scan:\n                break # Exit deletion phase sub-loop\n\n        # --- Addition Phase ---\n        # An addition restarts the entire process, starting from deletions.\n        # This is handled by the outer while loop.\n        addition_made_in_scan = False\n        \n        # Pre-calculate current utilities before scanning for additions\n        current_distances = shortest_path(csgraph=adj, directed=False)\n        current_utilities = {k: calculate_utility(k, adj, B, c, n, current_distances) for k in range(n)}\n        \n        for i, j in pairs:\n            if adj[i, j] == 0:\n                # Tentatively add the link\n                adj[i, j] = adj[j, i] = 1\n                \n                new_distances = shortest_path(csgraph=adj, directed=False)\n                util_i_new = calculate_utility(i, adj, B, c, n, new_distances)\n                util_j_new = calculate_utility(j, adj, B, c, n, new_distances)\n\n                # Check addition condition (weak bilateral improvement, strict for at least one)\n                if (util_i_new >= current_utilities[i] and util_j_new >= current_utilities[j]) and \\\n                   (util_i_new > current_utilities[i] or util_j_new > current_utilities[j]):\n                    # Addition is confirmed. The adj matrix is already updated.\n                    network_changed_in_round = True\n                    addition_made_in_scan = True\n                    break # Restart entire process from deletions\n                else:\n                    # Revert the addition\n                    adj[i, j] = adj[j, i] = 0\n\n        # --- Termination Check ---\n        if not network_changed_in_round:\n            break # Stable network found\n\n    return int(np.sum(adj) // 2)\n\n\ndef solve():\n    \"\"\"\n    Main function to run simulations for all test cases and print results.\n    \"\"\"\n    test_cases = [\n        (4, 1.0, 0.1),    # Case A\n        (6, 1.0, 0.15),   # Case B\n        (5, 1.0, 0.26),   # Case C\n        (5, 1.0, 0.125),  # Case D\n    ]\n\n    results = []\n    for params in test_cases:\n        n, B, c = params\n        num_links = run_simulation(n, B, c)\n        results.append(num_links)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}]}