{"hands_on_practices": [{"introduction": "理论上讨论“维度灾难”可能感觉有些抽象。这个动手实践将通过一个具体的金融计算问题——为五维度的“一篮子”期权定价，让你亲身体验这一概念。通过构建全张量积网格和 Smolyak 稀疏网格，你将直接见证后者如何在保持可比精度的同时，有效地抑制计算成本的指数级增长 [@problem_id:2396782]。这个练习是理解稀疏网格核心优势的绝佳起点。", "id": "2396782", "problem": "考虑一个在风险中性 Black–Scholes 框架下，针对由 $d$ 种风险资产组成的一篮子编写的欧式看涨期权。设 $S_i(0)$ 表示资产 $i$ 的初始价格，$r$ 为恒定无风险利率，$\\sigma_i$ 为资产 $i$ 的波动率，$T$ 为到期时间。在风险中性测度下，资产 $i$ 的期末价格由下式给出\n$$\nS_i(T) = S_i(0)\\,\\exp\\!\\Big( \\big(r - \\tfrac{1}{2}\\sigma_i^2\\big)T + \\sigma_i \\sqrt{T}\\, Z_i \\Big),\n$$\n其中 $Z_i$ 是独立的标准正态随机变量。该一篮子看涨期权的收益为\n$$\n\\Pi = \\max\\!\\Big(\\frac{1}{d}\\sum_{i=1}^{d} S_i(T) - K,\\, 0\\Big),\n$$\n执行价格为 $K$。时刻 $0$ 的无套利价格为\n$$\nV_0 = e^{-rT}\\,\\mathbb{E}\\big[\\Pi\\big].\n$$\n\n您的任务是使用高斯求积近似计算 $d=5$ 情况下的 $V_0$，并通过比较全张量积高斯求积与基于相同一维法则构建的 Smolyak 稀疏网格，来数值上展示维度灾难。\n\n您必须从第一性原理出发，将标准正态分布下的 $d$ 维期望转化为高斯-埃尔米特求积。回顾一维的 $n$ 阶高斯-埃尔米特求积法则，\n$$\n\\int_{-\\infty}^{\\infty} e^{-x^2} f(x)\\,dx \\approx \\sum_{j=1}^{n} w_j f(x_j),\n$$\n其中 $x_j$ 是节点，$w_j$ 是权重。证明对于一个标准正态随机变量 $Z$，\n$$\n\\mathbb{E}[g(Z)] = \\frac{1}{\\sqrt{\\pi}}\\int_{-\\infty}^{\\infty} e^{-x^2}\\, g\\!\\big(\\sqrt{2}\\,x\\big)\\,dx,\n$$\n并将此推广到 $d$ 个独立的标准正态变量，以证明使用一维高斯-埃尔米特法则的 $d$ 维张量积的合理性。使用此方法生成：\n\n- 一个每个维度有 $n$ 个节点（总节点数为 $n^d$）的 $d$ 维张量积高斯-埃尔米特求积。\n- 一个基于相同的一维高斯-埃尔米特族 $\\{Q_\\ell\\}_{\\ell \\ge 1}$ 构建的各向同性水平为 $L$ 的 Smolyak 稀疏网格，其中一维阶数为 $m(\\ell) = 2\\ell - 1$。使用索引集为\n$$\n\\mathcal{I}(L,d) = \\big\\{\\boldsymbol{\\ell}\\in \\mathbb{N}^d : 1 \\le \\ell_k, \\ \\ |\\boldsymbol{\\ell}|_1 \\le L + d - 1 \\big\\},\n$$\n且系数为\n$$\nc(\\boldsymbol{\\ell}) = (-1)^{L + d - 1 - |\\boldsymbol{\\ell}|_1}\\binom{d-1}{L + d - 1 - |\\boldsymbol{\\ell}|_1}\n$$\n的 Smolyak 组合公式。此处，$Q_{\\ell}$ 表示阶数为 $m(\\ell)$ 的一维高斯-埃尔米特法则，而 $d$ 维算子是张量积 $\\bigotimes_{k=1}^d Q_{\\ell_k}$。\n\n基于上述基础，设计一个算法，该算法：\n- 通过在每个维度上进行变量替换 $z = \\sqrt{2}\\,x$，将期望映射到高斯-埃尔米特加权积分。\n- 对 $d$ 维正确应用归一化因子 $\\pi^{-d/2}$。\n- 构建张量网格和 Smolyak 稀疏网格，并在所有必需的节点上评估折现后的收益。\n- 计算每种方法的函数求值次数，作为计算成本的代理指标。\n\n测试套件。实现以下两个计算测试用例和一个比较任务：\n\n- 情况 A (顺畅路径, $d=5$):\n  - 参数: $S_0 = (100,\\, 90,\\, 110,\\, 95,\\, 105)$, $\\sigma = (0.2,\\, 0.25,\\, 0.15,\\, 0.3,\\, 0.18)$, $r = 0.02$, $T = 1.0$, $K = 100$.\n  - 每个维度有 $n=3$ 个节点的张量积高斯-埃尔米特求积。\n  - 各向同性水平 $L=3$ 且一维阶数 $m(\\ell) = 2\\ell - 1$ 的 Smolyak 稀疏网格。\n  - 通过每个维度有 $n_{\\text{ref}}=9$ 个节点的张量积高斯-埃尔米特求积计算的高精度参考值。\n  - 需要计算的输出：\n    - 张量积近似相对于参考值的绝对误差（浮点数）。\n    - 稀疏网格近似相对于参考值的绝对误差（浮点数）。\n    - 张量积的节点数（整数）。\n    - 稀疏网格的节点数（整数），取为 Smolyak 组合中所有组成项的张量积大小之和。\n\n- 情况 B (零波动率的边界条件, $d=5$):\n  - 参数：与情况 A 相同的 $S_0$, $r$, $T$, $K$，但 $\\sigma = (0,\\,0,\\,0,\\,0,\\,0)$。\n  - 精确价格由确定性值给出\n    $$\n    V_0^{\\text{det}} = e^{-rT}\\,\\max\\!\\Big(\\frac{1}{d}\\sum_{i=1}^{d} S_i(0)\\,e^{rT} - K,\\, 0\\Big) = \\max\\!\\Big(\\frac{1}{d}\\sum_{i=1}^{d} S_i(0) - K e^{-rT},\\, 0\\Big).\n    $$\n  - 验证 $n=3$ 的张量积求积和 $L=3$ 的稀疏网格是否都在 $10^{-10}$ 的绝对容差内与 $V_0^{\\text{det}}$ 匹配。输出一个布尔值，表示两者是否都通过测试。\n\n- 效率比较：\n  - 对于情况 A，输出一个布尔值，表示稀疏网格是否在使用的节点严格少于张量积的情况下，取得了小于或等于张量积误差的绝对误差。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表条目必须按顺序为：\n- 情况 A 的张量积绝对误差（浮点数）。\n- 情况 A 的稀疏网格绝对误差（浮点数）。\n- 情况 A 的张量积节点数（整数）。\n- 情况 A 的稀疏网格节点数（整数）。\n- 情况 B 的边界条件检查（布尔值）。\n- 情况 A 的效率比较检查（布尔值）。\n\n例如，输出格式必须为\n$$\n[\\text{err\\_tensor},\\text{err\\_sparse},\\text{nodes\\_tensor},\\text{nodes\\_sparse},\\text{boundary\\_ok},\\text{efficiency\\_ok}],\n$$\n其中两个误差为十进制数，两个节点计数为整数，最后两个条目为布尔值。不应打印任何额外文本。", "solution": "我们从欧式衍生品的风险中性定价原理开始：在时刻 $T$ 的收益 $\\Pi$ 在时刻 $0$ 的价格 $V_0$ 由 $V_0 = e^{-rT}\\,\\mathbb{E}[\\Pi]$ 给出，其中期望是在风险中性测度下计算的。在 Black–Scholes 框架下，对于独立的标准正态变量 $Z_i \\sim \\mathcal{N}(0,1)$，期末资产价值为\n$$\nS_i(T) = S_i(0)\\,\\exp\\!\\Big( \\big(r - \\tfrac{1}{2}\\sigma_i^2\\big)T + \\sigma_i \\sqrt{T}\\, Z_i \\Big),\n$$\n一篮子看涨期权的收益为\n$$\n\\Pi = \\max\\!\\Big(\\frac{1}{d}\\sum_{i=1}^{d} S_i(T) - K,\\, 0\\Big).\n$$\n因此，\n$$\nV_0 = e^{-rT}\\,\\mathbb{E}\\left[\\max\\!\\Big(\\frac{1}{d}\\sum_{i=1}^{d} S_i(0)\\,\\exp\\!\\big( \\big(r - \\tfrac{1}{2}\\sigma_i^2\\big)T + \\sigma_i \\sqrt{T}\\, Z_i \\big) - K,\\, 0\\Big)\\right].\n$$\n\n为了与高斯-埃尔米特求积建立联系，我们将标准正态定律下的期望转换为带有高斯-埃尔米特权重的积分。对于单个标准正态随机变量 $Z \\sim \\mathcal{N}(0,1)$ 和一个合适的测试函数 $g$，我们有\n$$\n\\mathbb{E}[g(Z)] = \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2} g(z)\\,dz.\n$$\n通过变量替换 $z = \\sqrt{2}\\,x$（因此 $dz = \\sqrt{2}\\,dx$），可以得到\n$$\n\\mathbb{E}[g(Z)] = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} e^{-(\\sqrt{2}x)^2/2} g(\\sqrt{2}x)\\,\\sqrt{2}\\,dx = \\frac{1}{\\sqrt{\\pi}}\\int_{-\\infty}^{\\infty} e^{-x^2} g(\\sqrt{2}\\,x)\\,dx.\n$$\n在 $d$ 维空间中，对于独立的标准正态变量 $\\boldsymbol{Z} = (Z_1,\\dots,Z_d)$，其联合密度可以分解，通过逐分量应用变量替换，我们得到\n$$\n\\mathbb{E}[g(\\boldsymbol{Z})] = \\frac{1}{\\pi^{d/2}} \\int_{\\mathbb{R}^d} e^{-\\|\\boldsymbol{x}\\|_2^2}\\, g(\\sqrt{2}\\,\\boldsymbol{x})\\, d\\boldsymbol{x}.\n$$\n因此，$d$ 维高斯-埃尔米特张量积求积得出\n$$\n\\mathbb{E}[g(\\boldsymbol{Z})] \\approx \\frac{1}{\\pi^{d/2}} \\sum_{j_1=1}^{n}\\cdots \\sum_{j_d=1}^{n} \\Big(\\prod_{k=1}^{d} w_{j_k}\\Big)\\, g\\!\\Big(\\sqrt{2}\\,x_{j_1},\\dots,\\sqrt{2}\\,x_{j_d}\\Big),\n$$\n其中 $(x_{j},w_{j})$ 是与权重 $e^{-x^2}$ 相关联的 $n$ 阶一维高斯-埃尔米特节点和权重。\n\n将此应用于一篮子期权的收益，我们定义\n$$\ng(\\boldsymbol{z}) = \\max\\!\\Big(\\frac{1}{d}\\sum_{i=1}^{d} S_i(0)\\,\\exp\\!\\big( \\big(r - \\tfrac{1}{2}\\sigma_i^2\\big)T + \\sigma_i \\sqrt{T}\\, z_i \\big) - K,\\, 0\\Big),\n$$\n价格的近似值为\n$$\nV_0 \\approx e^{-rT}\\,\\frac{1}{\\pi^{d/2}} \\sum_{j_1=1}^{n}\\cdots \\sum_{j_d=1}^{n} \\Big(\\prod_{k=1}^{d} w_{j_k}\\Big)\\, g\\!\\Big(\\sqrt{2}\\,x_{j_1},\\dots,\\sqrt{2}\\,x_{j_d}\\Big).\n$$\n\n这个张量积法则使用 $n^d$ 次函数求值。对于 $d=5$，节点数以 $n^5$ 的速度增长，这正是维度灾难的一种体现：即使 $n$ 的适度增加也会导致成本的指数级增长。\n\n为了缓解这个问题，我们考虑一个由相同的一维高斯-埃尔米特族构建的 Smolyak 稀疏网格。设 $Q_{\\ell}$ 表示水平 $\\ell \\in \\mathbb{N}$ 下阶数为 $m(\\ell)=2\\ell-1$ 的一维高斯-埃尔米特求积。对于 $d$ 维的各向同性水平 $L \\in \\mathbb{N}$，Smolyak 算子为\n$$\nA(L,d) = \\sum_{\\boldsymbol{\\ell}\\in \\mathcal{I}(L,d)} c(\\boldsymbol{\\ell}) \\bigotimes_{k=1}^{d} Q_{\\ell_k},\n$$\n其索引集为\n$$\n\\mathcal{I}(L,d) = \\big\\{\\boldsymbol{\\ell}\\in \\mathbb{N}^d : 1 \\le \\ell_k,\\ \\ |\\boldsymbol{\\ell}|_1 \\le L + d - 1\\big\\},\n$$\n组合系数为\n$$\nc(\\boldsymbol{\\ell}) = (-1)^{L + d - 1 - |\\boldsymbol{\\ell}|_1}\\binom{d-1}{L + d - 1 - |\\boldsymbol{\\ell}|_1}.\n$$\n由此产生的期望的稀疏网格近似为\n$$\n\\mathbb{E}[g(\\boldsymbol{Z})] \\approx \\frac{1}{\\pi^{d/2}} \\sum_{\\boldsymbol{\\ell}\\in \\mathcal{I}(L,d)} c(\\boldsymbol{\\ell}) \\sum_{j_1=1}^{m(\\ell_1)} \\cdots \\sum_{j_d=1}^{m(\\ell_d)} \\left(\\prod_{k=1}^{d} w_{j_k}^{(\\ell_k)}\\right) g\\!\\Big(\\sqrt{2}\\,x_{j_1}^{(\\ell_1)},\\dots,\\sqrt{2}\\,x_{j_d}^{(\\ell_d)}\\Big),\n$$\n其中 $(x_j^{(\\ell)}, w_j^{(\\ell)})$ 是阶数为 $m(\\ell)$ 的一维高斯-埃尔米特节点和权重。注意，这种组合利用了与张量积相同的一维法则，但通过 Smolyak 系数混合了不同阶数的张量积。计算成本是所有 $\\boldsymbol{\\ell} \\in \\mathcal{I}(L,d)$ 的张量积大小 $\\prod_{k=1}^d m(\\ell_k)$ 的总和；对于可比的精度，这个成本在维度 $d$ 上的增长比 $n^d$ 更为温和。\n\n算法设计：\n\n- 通过一个稳定的正交多项式生成器，预先计算所有所需阶数的一维高斯-埃尔米特节点和权重。这些节点和权重能精确地对最高 $2n-1$ 次的多项式乘以 $e^{-x^2}$ 进行积分，并且权重之和等于 $\\sqrt{\\pi}$，从而确保了对常数被积函数的精确性。\n- 通过构建一维节点和权重的笛卡尔积，应用 $\\sqrt{2}$ 缩放以映射到标准正态变量，并乘以权重乘积来实现张量积求积。将累加和乘以 $\\pi^{-d/2}$ 和 $e^{-rT}$。\n- 通过遍历 $\\mathcal{I}(L,d)$ 中的所有多重索引 $\\boldsymbol{\\ell}$ 来实现 Smolyak 稀疏网格，计算组合系数 $c(\\boldsymbol{\\ell})$，对每个 $\\boldsymbol{\\ell}$ 使用第 $k$ 维的 $m(\\ell_k)$ 个点构成张量网格，评估并累加带有相同归一化因子的加权贡献。将计算工作量计为所有 $\\boldsymbol{\\ell}$ 的张量大小之和。\n- 对于 $\\sigma_i = 0$ 的边界情况，期末价格是确定性的，$S_i(T) = S_i(0)e^{rT}$，因此精确价格是 $V_0^{\\text{det}} = \\max\\!\\big(\\frac{1}{d}\\sum_i S_i(0) - K e^{-rT}, 0\\big)$。因为高斯-埃尔米特法则能精确积分常数，所以张量积和稀疏网格近似都应该在舍入误差范围内与该值匹配。\n\n测试套件实现：\n\n- 情况 A: $d=5$, $S_0=(100,90,110,95,105)$, $\\sigma=(0.2,0.25,0.15,0.3,0.18)$, $r=0.02$, $T=1.0$, $K=100$。计算：\n  - 使用张量 $n_{\\text{ref}}=9$ 的参考值。\n  - 使用张量 $n=3$；记录绝对误差和节点数 $3^5$。\n  - 使用 $L=3$ 和 $m(\\ell)=2\\ell-1$ 的 Smolyak；记录相对于参考值的绝对误差以及作为 $\\mathcal{I}(L,d)$ 上张量大小总和的稀疏网格节点数。\n- 情况 B: 与情况 A 相同，但 $\\sigma=\\boldsymbol{0}$。验证张量 $n=3$ 和稀疏 $L=3$ 的结果是否都在 $10^{-10}$ 的容差内与 $V_0^{\\text{det}}$ 匹配。\n- 效率比较：对于情况 A，检查稀疏网格是否在节点数严格少于张量积的情况下，实现了小于或等于张量积的误差。\n\n程序将生成一行输出：\n$[\\text{err\\_tensor},\\text{err\\_sparse},\\text{nodes\\_tensor},\\text{nodes\\_sparse},\\text{boundary\\_ok},\\text{efficiency\\_ok}]$,\n其中条目如上定义。此设计通过张量网格的 $n^5$ 缩放展示了维度灾难，并将其与 Smolyak 稀疏网格进行对比，后者使用相同的一维高斯-埃尔米特族，以显著更少的函数求值次数获得了有竞争力的精度。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom numpy.polynomial.hermite import hermgauss\nimport math\nfrom itertools import product\n\ndef gh_rule(n):\n    # One-dimensional Gauss-Hermite nodes and weights for weight e^{-x^2}\n    x, w = hermgauss(n)\n    return x, w\n\ndef basket_payoff(Z, S0, sigmas, r, T, K):\n    # Z: shape (N, d)\n    d = Z.shape[1]\n    S0 = np.asarray(S0, dtype=float)\n    sigmas = np.asarray(sigmas, dtype=float)\n    mu = (r - 0.5 * sigmas**2) * T\n    sgsqrtT = sigmas * math.sqrt(T)\n    # exponent per point and dimension\n    exponents = mu + sgsqrtT * Z  # shape (N, d)\n    ST = S0 * np.exp(exponents)   # broadcasting over (N, d)\n    avg = np.mean(ST, axis=1)\n    payoff = np.maximum(avg - K, 0.0)\n    return payoff\n\ndef tensor_gauss_hermite_price(S0, sigmas, r, T, K, n):\n    d = len(S0)\n    x, w = gh_rule(n)\n    # Build tensor grid via meshgrid\n    grids_x = np.meshgrid(*([x]*d), indexing='ij')\n    grids_w = np.meshgrid(*([w]*d), indexing='ij')\n    # Flatten\n    X_cols = [g.ravel() for g in grids_x]  # list length d, each shape (n**d,)\n    W_arrays = [gw.ravel() for gw in grids_w]\n    # Product weights\n    W_prod = np.ones_like(W_arrays[0])\n    for Wa in W_arrays:\n        W_prod *= Wa\n    # Map to standard normals: Z = sqrt(2) * x\n    Z = np.sqrt(2.0) * np.column_stack(X_cols)  # shape (N, d)\n    payoff = basket_payoff(Z, S0, sigmas, r, T, K)\n    # Normalization factor for d-dim expectation\n    factor = math.pi ** (-d / 2.0)\n    expectation = factor * np.sum(W_prod * payoff)\n    price = math.exp(-r * T) * expectation\n    nodes = n ** d\n    return price, nodes\n\ndef generate_multi_indices_sum_d(s, d, min_level=1):\n    # Generate all tuples of length d of positive integers >= min_level with sum s\n    # Use recursive backtracking\n    result = []\n    def backtrack(prefix, remaining, k):\n        if k == d - 1:\n            last = remaining\n            if last >= min_level:\n                result.append(tuple(prefix + [last]))\n            return\n        # Each component at least min_level\n        min_val = min_level\n        # Remaining must allow at least min_level for remaining dims\n        max_val = remaining - (d - k - 1) * min_level\n        for val in range(min_val, max_val + 1):\n            backtrack(prefix + [val], remaining - val, k + 1)\n    backtrack([], s, 0)\n    return result\n\ndef smolyak_sparse_price(S0, sigmas, r, T, K, L):\n    d = len(S0)\n    # Precompute 1D rules for levels 1..(L + d - 1) because indices can reach that in sum, but each component level is bounded by sum\n    # However, for efficiency we build on demand and cache by level\n    rule_cache = {}\n    def one_d_rule_for_level(level):\n        if level not in rule_cache:\n            n = 2 * level - 1\n            rule_cache[level] = gh_rule(n)\n        return rule_cache[level]\n\n    total_nodes_cost = 0\n    factor = math.pi ** (-d / 2.0)\n    acc = 0.0\n    # Iterate sums s from d to L + d - 1\n    for s in range(d, L + d):\n        # Binomial coefficient for all multi-indices with |ell|_1 = s\n        comb_coeff = math.comb(d - 1, L + d - 1 - s)\n        sign = -1 if ((L + d - 1 - s) % 2 == 1) else 1\n        c_s = sign * comb_coeff\n        if c_s == 0:\n            continue\n        # All multi-indices with sum s\n        for ell in generate_multi_indices_sum_d(s, d, min_level=1):\n            # Build per-dimension nodes and weights at levels in ell\n            x_list = []\n            w_list = []\n            n_points_list = []\n            for lev in ell:\n                xk, wk = one_d_rule_for_level(lev)\n                x_list.append(xk)\n                w_list.append(wk)\n                n_points_list.append(len(xk))\n            # Tensor product for this multi-index\n            grids_x = np.meshgrid(*x_list, indexing='ij')\n            grids_w = np.meshgrid(*w_list, indexing='ij')\n            # Flatten\n            X_cols = [g.ravel() for g in grids_x]\n            W_arrays = [gw.ravel() for gw in grids_w]\n            # Product weights\n            W_prod = np.ones_like(W_arrays[0])\n            for Wa in W_arrays:\n                W_prod *= Wa\n            # Map to Z\n            Z = np.sqrt(2.0) * np.column_stack(X_cols)\n            payoff = basket_payoff(Z, S0, sigmas, r, T, K)\n            contrib = factor * np.sum(W_prod * payoff)\n            acc += c_s * contrib\n            # Cost accumulation: number of nodes in this tensor product\n            nodes_this = 1\n            for npt in n_points_list:\n                nodes_this *= npt\n            total_nodes_cost += nodes_this\n    price = math.exp(-r * T) * acc\n    return price, total_nodes_cost\n\ndef solve():\n    # Define the test cases from the problem statement.\n\n    # Case A parameters\n    S0 = [100.0, 90.0, 110.0, 95.0, 105.0]\n    sigmas_A = [0.2, 0.25, 0.15, 0.3, 0.18]\n    r = 0.02\n    T = 1.0\n    K = 100.0\n    d = len(S0)\n\n    # Reference with tensor n_ref=9\n    price_ref, nodes_ref = tensor_gauss_hermite_price(S0, sigmas_A, r, T, K, n=9)\n\n    # Tensor with n=3\n    price_tensor, nodes_tensor = tensor_gauss_hermite_price(S0, sigmas_A, r, T, K, n=3)\n    err_tensor = abs(price_tensor - price_ref)\n\n    # Sparse grid with L=3\n    price_sparse, nodes_sparse = smolyak_sparse_price(S0, sigmas_A, r, T, K, L=3)\n    err_sparse = abs(price_sparse - price_ref)\n\n    # Case B: zero volatility boundary\n    sigmas_B = [0.0, 0.0, 0.0, 0.0, 0.0]\n    # Deterministic price\n    mean_S0 = sum(S0) / d\n    price_det = max(mean_S0 - K * math.exp(-r * T), 0.0)\n\n    price_tensor_B, _ = tensor_gauss_hermite_price(S0, sigmas_B, r, T, K, n=3)\n    price_sparse_B, _ = smolyak_sparse_price(S0, sigmas_B, r, T, K, L=3)\n\n    tol = 1e-10\n    boundary_ok = (abs(price_tensor_B - price_det) <= tol) and (abs(price_sparse_B - price_det) <= tol)\n\n    # Efficiency comparison for Case A\n    efficiency_ok = (err_sparse <= err_tensor) and (nodes_sparse < nodes_tensor)\n\n    results = [\n        float(err_tensor),\n        float(err_sparse),\n        int(nodes_tensor),\n        int(nodes_sparse),\n        bool(boundary_ok),\n        bool(efficiency_ok),\n    ]\n\n    # Final print statement in the exact required format.\n    # Ensure default Python representation for floats and booleans.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}, {"introduction": "和张量积方法相比，稀疏网格的优势是显著的，但与广泛应用的蒙特卡洛方法相比又如何呢？这个练习将引导你在一个公平的舞台上比较这两种方法 [@problem_id:2432650]。你将通过一个思想实验，确定一个“盈亏平衡点”——即在多少次函数求值后，确定性的 Smolyak 求积方法能够超越蒙特卡洛模拟的概率性收敛。这个过程将帮助你理解不同高维积分方法之间的权衡，以及稀疏网格在处理光滑函数时的效率。", "id": "2432650", "problem": "要求您设计并实现一个程序，对于一个光滑、不可分离的被积函数，该程序能够确定在稀疏网格节点（Smolyak 求积点）上进行函数求值所需的最小次数，以使其性能优于使用相同数量样本的 Monte Carlo 估计器。背景设定为在超立方体上进行积分，并使用一个典范的嵌套一维求积法则作为 Smolyak 构造的基础模块。所有角度均以弧度为单位。\n\n设积分域为 $d$ 维超立方体 $[-1,1]^d$，被积函数定义如下\n$$\nf(\\mathbf{x}) \\equiv \\cos\\!\\Big(\\sum_{i=1}^{d} x_i\\Big), \\quad \\mathbf{x} = (x_1,\\dots,x_d) \\in [-1,1]^d.\n$$\n我们关注的体积分为\n$$\nI_d \\equiv \\int_{[-1,1]^d} f(\\mathbf{x})\\, d\\mathbf{x}.\n$$\n您的程序必须基于嵌套的一维 Clenshaw–Curtis 法则构建各向同性的 Smolyak 求积法则，并将其绝对积分误差与使用相同函数求值次数 $N$ 的 Monte Carlo 估计器的均方根误差进行比较。\n\n需要使用的基本依据和定义：\n- $n$ 阶一维 Clenshaw–Curtis 节点的公式为\n$$\nx_j = \\cos\\!\\Big(\\frac{\\pi j}{n-1}\\Big), \\quad j=0,1,\\dots,n-1,\n$$\n约定当 $n=1$ 时，单个节点为 $x_0=1$。Clenshaw–Curtis 权重 $w_j$ 由其对于前 $n$ 个第一类 Chebyshev 多项式的精确性唯一确定，即，对于 $k=0,1,\\dots,n-1$，\n$$\n\\sum_{j=0}^{n-1} w_j\\, T_k(x_j) = \\int_{-1}^{1} T_k(x)\\,dx,\n$$\n其中 $T_k(x)$ 是由 $T_k(\\cos\\theta)=\\cos(k\\theta)$ 定义的 Chebyshev 多项式。等式右侧具有已知值\n$$\n\\int_{-1}^{1} T_0(x)\\,dx = 2,\\quad \\int_{-1}^{1} T_k(x)\\,dx = \\begin{cases} \\dfrac{2}{1-k^2}, & k \\text{ 为偶数},\\, k\\ge 2,\\\\ 0, & k \\text{ 为奇数}. \\end{cases}\n$$\n通过求解每个一维法则的线性方程组，使用这些等式来确定权重 $w_j$。\n- 对于一维层级 $\\ell \\in \\mathbb{N}$，使用嵌套增长规则：求积 $K_\\ell$ 具有 $m(\\ell)$ 个点，其中\n$$\nm(1)=1,\\quad m(\\ell)=2^{\\ell-1}+1 \\text{ for } \\ell\\ge 2,\n$$\n这为 Clenshaw–Curtis 求积法生成了嵌套节点。\n- 对于维度 $d$ 和非负整数 Smolyak 层级 $s$，通过标准的组合 (Smolyak) 公式定义 Smolyak 求积 $A(s,d)$\n$$\nA(s,d) f = \\sum_{\\mathbf{i}\\in\\mathbb{N}^d:\\, \\|\\mathbf{i}\\|_1 \\le s+d} \\left[ (-1)^{\\,s+d-\\|\\mathbf{i}\\|_1}\\binom{d-1}{\\,s+d-\\|\\mathbf{i}\\|_1} \\prod_{k=1}^{d} K_{i_k} \\right] f,\n$$\n其中 $K_{i_k}$ 是层级为 $i_k$ 的一维求积，$\\|\\mathbf{i}\\|_1 = \\sum_{k=1}^{d} i_k$，并且如果二项式系数的下参数在 $\\{0,1,2,\\dots\\}$ 范围之外，则其值取为零。请通过以下步骤字面实现此公式：构建一维法则的张量积，对不同项中相同节点位置的权重求和，然后对加权函数值求和以生成 Smolyak 近似值。$A(s,d)$ 中不同节点的数量是在合并相同位置及其组合权重后的唯一节点计数；将此计数表示为 $N_{\\text{SG}}(s,d)$。\n- 使用 $N$ 个样本的 $I_d$ 的 Monte Carlo 估计器是 $f(\\mathbf{X})$ 样本均值的 $2^d$ 倍，其中 $\\mathbf{X}$ 在 $[-1,1]^d$ 上均匀分布。其均方根误差等于 $2^d \\sqrt{\\operatorname{Var}(f(\\mathbf{X}))/N}$。对于 $f(\\mathbf{x})=\\cos(\\sum_{i=1}^d x_i)$ 和在 $[-1,1]^d$ 上均匀分布的 $\\mathbf{X}$，您必须使用独立性和特征函数从第一性原理精确计算 $\\operatorname{Var}(f(\\mathbf{X}))$。\n\n您的程序必须：\n- 推导并使用 $I_d$ 的闭式表达式。\n- 在 $[-1,1]^d$ 上的均匀分布下，推导并使用 $\\operatorname{Var}(f(\\mathbf{X}))$ 的闭式表达式。\n- 对于每个测试用例维度 $d$，在 Smolyak 层级 $s\\in\\{0,1,2,\\dots,s_{\\max}\\}$（其中 $s_{\\max}=8$）上进行搜索，并确定满足绝对求积误差\n$$\nE_{\\text{SG}}(s,d) \\equiv \\left|A(s,d)f - I_d\\right|\n$$\n小于或等于使用相同函数求值次数 $N_{\\text{SG}}(s,d)$ 的 Monte Carlo 均方根误差的最小 $s$ 值：\n$$\nE_{\\text{SG}}(s,d) \\le 2^{d} \\sqrt{\\frac{\\operatorname{Var}(f(\\mathbf{X}))}{N_{\\text{SG}}(s,d)}}.\n$$\n如果在 $s_{\\max}$ 范围内不存在这样的 $s$，则该测试用例返回 $-1$。\n- 将“函数求值次数”定义为在合并跨张量积的重合节点后，稀疏网格中不同节点的数量。\n\n测试套件：\n- 用例 A：$d=1$（一维边界检查）。\n- 用例 B：$d=2$（典型用例）。\n- 用例 C：$d=5$（高维用例）。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含三个结果，形式为用方括号括起来的逗号分隔列表（例如，“[3,7,129]”）。每个条目必须是对于测试套件中相应的 $d$，达到上述标准的最小稀疏网格不同节点数 $N_{\\text{SG}}(s,d)$，如果在 $s_{\\max}$ 范围内未找到，则为 $-1$。\n\n所有角度必须以弧度为单位。不涉及物理单位。所有数值答案必须表示为整数。输出必须与确切的格式规范相匹配。", "solution": "所述问题具有科学依据，提法恰当且客观。它概述了数值分析中的一项标准任务：针对特定的多维积分，比较稀疏网格求积与 Monte Carlo 方法的效率。所有的定义和公式，尽管包含了一个针对求积法则基准情形的特殊约定，但都是明确且数学上一致的。因此，我将继续提供完整的解决方案。\n\n问题要求我们找到各向同性 Smolyak 稀疏网格的最小节点数 $N_{\\text{SG}}(s,d)$，在该节点数下，绝对积分误差小于使用相同函数求值次数的 Monte Carlo 估计的均方根（RMS）误差。这必须在维度 $d=1, 2, 5$ 和 Smolyak 层级 $s$ 从 0 搜索到 8 的条件下确定。\n\n首先，我们必须推导积分真值和被积函数方差的必要解析表达式，这些表达式将作为我们数值方法的基准。\n\n**1. 积分的解析值**\n\n需要计算的积分为\n$$\nI_d = \\int_{[-1,1]^d} \\cos\\Big(\\sum_{i=1}^{d} x_i\\Big)\\, d\\mathbf{x}.\n$$\n使用 Euler 公式 $\\cos(\\theta) = \\operatorname{Re}(e^{i\\theta})$，积分可以重写为\n$$\nI_d = \\operatorname{Re}\\left( \\int_{[-1,1]^d} \\exp\\left(i \\sum_{k=1}^{d} x_k\\right) d\\mathbf{x} \\right).\n$$\n指数的和是指数的乘积。根据 Fubini 定理，多维积分变成了多个一维积分的乘积：\n$$\nI_d = \\operatorname{Re}\\left( \\prod_{k=1}^{d} \\int_{-1}^{1} e^{ix_k} dx_k \\right).\n$$\n一维积分是初等的：\n$$\n\\int_{-1}^{1} e^{ix} dx = \\left[\\frac{e^{ix}}{i}\\right]_{-1}^{1} = \\frac{e^i - e^{-i}}{i} = 2 \\frac{e^i - e^{-i}}{2i} = 2\\sin(1).\n$$\n由于 $2\\sin(1)$ 是一个实值常数，积分 $I_d$ 只是这个值对维度 $d$ 的幂：\n$$\nI_d = (2\\sin(1))^d.\n$$\n\n**2. 被积函数的解析方差**\n\n被积函数 $f(\\mathbf{X}) = \\cos(\\sum_{k=1}^d X_k)$ 的方差为 $\\operatorname{Var}(f(\\mathbf{X})) = E[f(\\mathbf{X})^2] - (E[f(\\mathbf{X})])^2$，其中 $X_k$ 是服从 Uniform$(-1, 1)$ 分布的独立同分布随机变量。\n\n$f(\\mathbf{X})$ 的期望是\n$$\nE[f(\\mathbf{X})] = \\frac{1}{\\text{Vol}([-1,1]^d)} \\int_{[-1,1]^d} f(\\mathbf{x}) d\\mathbf{x} = \\frac{I_d}{2^d} = \\left(\\frac{2\\sin(1)}{2}\\right)^d = (\\sin(1))^d.\n$$\n平方函数的期望 $E[f(\\mathbf{X})^2]$ 通过在超立方体上对 $f(\\mathbf{x})^2$ 积分计算：\n$$\nE[f(\\mathbf{X})^2] = \\frac{1}{2^d} \\int_{[-1,1]^d} \\cos^2\\Big(\\sum_{k=1}^{d} x_k\\Big) d\\mathbf{x}.\n$$\n使用恒等式 $\\cos^2(\\theta) = \\frac{1+\\cos(2\\theta)}{2}$，我们得到\n$$\nE[f(\\mathbf{X})^2] = \\frac{1}{2^d} \\int_{[-1,1]^d} \\frac{1}{2}\\left(1 + \\cos\\Big(2\\sum_{k=1}^{d} x_k\\Big)\\right) d\\mathbf{x} = \\frac{1}{2^{d+1}} \\left( \\int_{[-1,1]^d} 1\\,d\\mathbf{x} + \\int_{[-1,1]^d} \\cos\\Big(\\sum_{k=1}^{d} 2x_k\\Big) d\\mathbf{x} \\right).\n$$\n第一个积分是体积 $2^d$。第二个积分与 $I_d$ 的计算类似：\n$$\n\\int_{[-1,1]^d} \\cos\\Big(\\sum_{k=1}^{d} 2x_k\\Big) d\\mathbf{x} = \\operatorname{Re}\\left( \\prod_{k=1}^{d} \\int_{-1}^{1} e^{i2x_k} dx_k \\right).\n$$\n一维积分的计算结果为 $\\int_{-1}^1 e^{i2x} dx = [\\frac{e^{i2x}}{2i}]_{-1}^1 = \\frac{e^{i2}-e^{-i2}}{2i} = \\sin(2)$。因此，多维积分为 $(\\sin(2))^d$。\n代回后，我们得到二阶矩：\n$$\nE[f(\\mathbf{X})^2] = \\frac{1}{2^{d+1}} \\left( 2^d + (\\sin(2))^d \\right) = \\frac{1}{2} + \\frac{1}{2}\\left(\\frac{\\sin(2)}{2}\\right)^d.\n$$\n最终，方差为：\n$$\n\\operatorname{Var}(f(\\mathbf{X})) = \\left[\\frac{1}{2} + \\frac{1}{2}\\left(\\frac{\\sin(2)}{2}\\right)^d\\right] - \\left((\\sin(1))^d\\right)^2 = \\frac{1}{2} + \\frac{1}{2}\\left(\\frac{\\sin(2)}{2}\\right)^d - (\\sin(1))^{2d}.\n$$\n\n**3. 数值求积方案**\n\n任务的核心是构建 Smolyak 稀疏网格并评估其性能。\n\n**3.1. 一维 Clenshaw-Curtis 法则**\n对于每个层级 $\\ell \\in \\mathbb{N}$，都构造一个具有 $n=m(\\ell)$ 个点的一维求积法则 $K_\\ell$。点的数量遵循嵌套增长规则 $m(1)=1$ 和 $m(\\ell)=2^{\\ell-1}+1$（对于 $\\ell \\ge 2$）。节点为 $x_j = \\cos(\\frac{\\pi j}{n-1})$（$j=0, \\dots, n-1$），并有明确但不同寻常的约定：当 $n=1$ 时，单个节点为 $x_0=1$。\n每个法则的权重 $w_j$ 通过对前 $n$ 个 Chebyshev 多项式 $T_k(x)$ 强制精确性来找到，这需要求解一个 $n \\times n$ 的线性系统：\n$$\n\\sum_{j=0}^{n-1} w_j T_k(x_j) = \\int_{-1}^{1} T_k(x) dx \\quad \\text{for } k=0, \\dots, n-1.\n$$\n矩阵元素为 $A_{kj} = T_k(x_j) = \\cos(k \\arccos(x_j)) = \\cos(k \\frac{\\pi j}{n-1})$。右侧向量包含已知的 Chebyshev 多项式的积分。为了效率，这些法则被预先计算并缓存。\n\n**3.2. Smolyak 稀疏网格构造**\n维度为 $d$、层级为 $s$ 的 Smolyak 求积法则 $A(s,d)$ 使用组合公式构建：\n$$\nA(s,d) f = \\sum_{\\mathbf{i} \\in \\mathbb{N}^d,\\, s+1 \\le \\|\\mathbf{i}\\|_1 \\le s+d} c(\\mathbf{i}) \\left( \\bigotimes_{k=1}^{d} K_{i_k} \\right) f,\n$$\n其中 $\\|\\mathbf{i}\\|_1 = \\sum_{k=1}^d i_k$，系数为 $c(\\mathbf{i}) = (-1)^{s+d-\\|\\mathbf{i}\\|_1}\\binom{d-1}{s+d-\\|\\mathbf{i}\\|_1}$，而 $\\bigotimes_{k=1}^d K_{i_k}$ 是一维法则的张量积。求和仅限于二项式系数非零的多重指标 $\\mathbf{i}$，这对应于 $s+1 \\le \\|\\mathbf{i}\\|_1 \\le s+d$。\n\n算法流程如下：\n1. 遍历所有有效的多重指标 $\\mathbf{i}$。\n2. 对于每个 $\\mathbf{i}$，计算系数 $c(\\mathbf{i})$。\n3. 构造张量积网格。此网格中的一个点是节点的 $d$-元组 $(\\xi_1, \\dots, \\xi_d)$，其中 $\\xi_k$ 是来自 $K_{i_k}$ 的一个节点。其对应的权重是各个一维权重的乘积。\n4. 将每个张量积点的权重乘以系数 $c(\\mathbf{i})$。\n5. 将这些点及其缩放后的权重累加到一个全局字典中，其中键是节点坐标（作为元组），值是总的权重和。使用字典可以自然地合并出现在多个张量积项中的点。\n\n遍历所有 $\\mathbf{i}$ 后，该字典代表完整的稀疏网格。不同节点的数量 $N_{\\text{SG}}(s,d)$ 是此字典中的条目数。积分近似值为 $\\sum_{\\mathbf{x}, W} W \\cdot f(\\mathbf{x})$。\n\n**4. 比较准则**\n\n对于测试套件中的每个维度 $d$，我们从 $0$ 到 $s_{\\max}=8$ 遍历 Smolyak 层级 $s$。对于每个 $(s,d)$，我们计算稀疏网格近似值 $A(s,d)f$ 及其绝对误差 $E_{\\text{SG}}(s,d) = |A(s,d)f - I_d|$。我们还计算节点数 $N_{\\text{SG}}(s,d)$。将其与相同求值次数的 Monte Carlo 均方根误差进行比较：\n$$\nE_{\\text{MC}}(N_{\\text{SG}}) = 2^d \\sqrt{\\frac{\\operatorname{Var}(f(\\mathbf{X}))}{N_{\\text{SG}}(s,d)}}.\n$$\n找到第一个满足 $E_{\\text{SG}}(s,d) \\le E_{\\text{MC}}(N_{\\text{SG}})$ 的层级 $s$，并记录相应的节点数 $N_{\\text{SG}}(s,d)$。如果在 $s_{\\max}$ 范围内未找到这样的层级，则结果为 $-1$。对所有测试用例重复此过程。", "answer": "```python\nimport numpy as np\nfrom scipy.special import comb\nimport math\nfrom itertools import product\nimport sys\n\n# Set a higher recursion limit for multi-index generation, which can be deep for d=5.\nsys.setrecursionlimit(2500)\n\n# Global caches for memoization to speed up repeated computations.\n_1d_rules_cache = {}\n_compositions_cache = {}\n\ndef get_1d_rule(level: int):\n    \"\"\"\n    Computes or retrieves from cache the Clenshaw-Curtis nodes and weights for a given level.\n    \"\"\"\n    if level in _1d_rules_cache:\n        return _1d_rules_cache[level]\n\n    if level == 1:\n        # Per problem statement: n=1, node is 1.\n        # Weight w_0 from w_0 * T_0(1) = integral(T_0) = 2. Since T_0(x)=1, w_0=2.\n        nodes = np.array([1.0])\n        weights = np.array([2.0])\n        _1d_rules_cache[level] = (nodes, weights)\n        return nodes, weights\n\n    n = 2**(level - 1) + 1\n    \n    # Nodes are the extrema of Chebyshev polynomials.\n    j = np.arange(n)\n    nodes = np.cos(math.pi * j / (n - 1))\n\n    # Right-hand side of the linear system for weights.\n    b = np.zeros(n)\n    b[0] = 2.0\n    for k in range(2, n, 2):\n        b[k] = 2.0 / (1.0 - k**2)\n\n    # Matrix A where A_kj = T_k(x_j) = cos(k*j*pi/(n-1)).\n    k_vals = np.arange(n)\n    A = np.cos(np.outer(k_vals, j * math.pi / (n - 1)))\n    \n    # Solve for weights.\n    weights = np.linalg.solve(A, b)\n    \n    _1d_rules_cache[level] = (nodes, weights)\n    return nodes, weights\n\ndef generate_compositions(n: int, k: int):\n    \"\"\"\n    Generates all compositions of integer k into n parts (each part >= 1), with memoization.\n    \"\"\"\n    if (n, k) in _compositions_cache:\n        return _compositions_cache[(n, k)]\n\n    if n == 1:\n        return [(k,)] if k >= 1 else []\n    if k < n:\n        return []\n\n    res = []\n    for i in range(1, k - (n - 1) + 1):\n        for rest in generate_compositions(n - 1, k - i):\n            res.append((i,) + rest)\n    \n    _compositions_cache[(n, k)] = res\n    return res\n\ndef get_smolyak_grid(s: int, d: int):\n    \"\"\"\n    Constructs the Smolyak sparse grid for a given level s and dimension d.\n    Returns a dictionary mapping node coordinates to their combined weights.\n    \"\"\"\n    grid_points = {}  # {node_tuple: weight}\n\n    # The sum is effectively over multi-indices i where s+1 <= sum(i) <= s+d\n    # because the combinatorial coefficient is zero otherwise.\n    for norm_i in range(s + 1, s + d + 1):\n        c = (-1)**(s + d - norm_i) * comb(d - 1, s + d - norm_i, exact=True)\n        if c == 0:\n            continue\n            \n        compositions = generate_compositions(d, norm_i)\n        \n        for i_tuple in compositions:\n            rules_for_i = [get_1d_rule(level) for level in i_tuple]\n            \n            # Use itertools.product to form tensor product points and weights\n            node_indices_ranges = [range(len(r[0])) for r in rules_for_i]\n            \n            for index_tuple in product(*node_indices_ranges):\n                node_coords = tuple(rules_for_i[k][0][index_tuple[k]] for k in range(d))\n                \n                weight_prod = 1.0\n                for k in range(d):\n                    weight_prod *= rules_for_i[k][1][index_tuple[k]]\n                \n                total_weight = c * weight_prod\n                grid_points[node_coords] = grid_points.get(node_coords, 0.0) + total_weight\n                \n    return grid_points\n\ndef f(x: tuple):\n    \"\"\"The integrand function.\"\"\"\n    return np.cos(np.sum(x))\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the entire process.\n    \"\"\"\n    test_cases = [1, 2, 5]\n    s_max = 8\n    results = []\n\n    for d in test_cases:\n        # Pre-calculated analytical values for the integral and variance\n        I_d = (2 * math.sin(1))**d\n        var_f = 0.5 + 0.5 * (math.sin(2) / 2)**d - (math.sin(1))**(2 * d)\n        \n        found_n = -1\n        \n        for s in range(s_max + 1):\n            smolyak_grid = get_smolyak_grid(s, d)\n            \n            if not smolyak_grid:\n                continue\n\n            n_sg = len(smolyak_grid)\n            \n            integral_approx = 0.0\n            for node, weight in smolyak_grid.items():\n                integral_approx += weight * f(node)\n            \n            e_sg = abs(integral_approx - I_d)\n            e_mc_rms = (2**d) * math.sqrt(var_f / n_sg)\n            \n            if e_sg <= e_mc_rms:\n                found_n = n_sg\n                break\n        \n        results.append(found_n)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```"}, {"introduction": "标准的稀疏网格平等地对待函数定义域的每一个区域，但对于具有局部复杂行为的函数，这种做法可能效率不高。这项高级实践将挑战你构建一个“智能化”的自适应网格，它能根据函数自身的特性，自动地在最需要的区域进行加密 [@problem_id:2432623]。你将实现一种基于分层余量大小的加密策略，从而高效地捕捉函数的陡峭梯度、局部峰值甚至“扭结”等特征，这代表了从应用固定公式到设计动态算法的进阶。", "id": "2432623", "problem": "您的任务是设计并实现一个基于 Smolyak 构造的自适应稀疏网格插值器，该插值器在超立方体域 $[0,1]^d$ 上使用分层分片线性（帽状）基函数。该算法必须使用分层盈余系数的绝对值作为加密指标，来自适应地加密网格。您的实现必须是一个完整、可运行的程序，该程序能够为一组定义的测试套件计算指定的量化输出。\n\n所需的算法元素必须源自以下基础：\n- 一维分层基函数的核心定义：对于层级 $l \\in \\mathbb{N}$ 和奇数索引 $i \\in \\{1,3,\\dots,2^l - 1\\}$，定义一维节点 $x_{l,i} = i / 2^l$ 和帽状基函数\n$$\n\\varphi_{l,i}(x) = \\max\\left(1 - 2^l \\left| x - \\frac{i}{2^l} \\right|, 0\\right).\n$$\n- 多维张量基：对于 $d \\in \\mathbb{N}$、多层级 $\\boldsymbol{l} = (l_1,\\dots,l_d)$ 和多重索引 $\\boldsymbol{i} = (i_1,\\dots,i_d)$（其中每个 $i_j \\in \\{1,3,\\dots,2^{l_j}-1\\}$），节点为 $\\boldsymbol{x}_{\\boldsymbol{l},\\boldsymbol{i}} = (i_1 2^{-l_1},\\dots,i_d 2^{-l_d})$，基函数可分解为\n$$\n\\Phi_{\\boldsymbol{l},\\boldsymbol{i}}(\\boldsymbol{x}) = \\prod_{j=1}^d \\varphi_{l_j,i_j}(x_j).\n$$\n- 分层插值：给定一个多重索引 $(\\boldsymbol{l},\\boldsymbol{i})$ 的集合 $\\mathcal{A}$，插值函数为\n$$\n\\mathcal{I} f(\\boldsymbol{x}) = \\sum_{(\\boldsymbol{l},\\boldsymbol{i}) \\in \\mathcal{A}} \\alpha_{\\boldsymbol{l},\\boldsymbol{i}} \\, \\Phi_{\\boldsymbol{l},\\boldsymbol{i}}(\\boldsymbol{x}),\n$$\n其中分层盈余系数通过递归定义为\n$$\n\\alpha_{\\boldsymbol{l},\\boldsymbol{i}} = f\\!\\left(\\boldsymbol{x}_{\\boldsymbol{l},\\boldsymbol{i}}\\right) - \\mathcal{I}_{\\text{prev}} f\\!\\left(\\boldsymbol{x}_{\\boldsymbol{l},\\boldsymbol{i}}\\right),\n$$\n其中 $\\mathcal{I}_{\\text{prev}}$ 表示由所有先前添加的、在向下闭合意义上对应于严格更粗糙节点的基函数所构成的插值函数。\n\n您的自适应算法必须：\n1. 使用层级为 $\\boldsymbol{l} = (1,\\dots,1)$、索引为 $\\boldsymbol{i} = (1,\\dots,1)$ 的单个内部节点进行初始化，计算其分层盈余，并将其插入到一个以盈余绝对值为键的自适应队列中。\n2. 迭代地从队列中选择绝对盈余最大的节点，并通过添加其允许的子节点来对其进行加密。沿坐标 $j$ 的子节点将 $l_j$ 增加 1，并将 $i_j$ 替换为 $\\{2 i_j - 1, 2 i_j + 1\\}$ 中的一个，同时保持所有其他坐标不变。对于每个新添加的子节点，使用当前的插值函数计算其分层盈余，并将该子节点插入队列。\n3. 当所有当前可用节点的最大绝对盈余低于给定容差 $ \\tau > 0$，或已达到指定的网格点最大数量 $N_{\\max}$ 时，算法终止。\n\n请使用此算法为以下测试套件构建插值函数，并为每种情况在指定的验证网格上计算最大绝对插值误差。所有角度（如适用）必须以弧度为单位进行解释。\n\n对于每个测试，定义：\n- 维度 $d$。\n- 目标函数 $f : [0,1]^d \\to \\mathbb{R}$。\n- 容差 $\\tau$ 和上限 $N_{\\max}$。\n- 一个验证网格，由每个维度上开区间 $(0,1)$ 内的 $m$ 个等距点的笛卡尔积构成，具体位置为 $x_k = \\frac{k}{m+1}$，其中 $k = 1,2,\\dots,m$。\n- 需要计算的最终输出：实际使用的网格点数（一个整数）和在验证网格上的最大绝对误差（一个浮点数），即：\n$$\nE_{\\max} = \\max_{\\boldsymbol{x} \\in \\mathcal{G}_m} \\left| f(\\boldsymbol{x}) - \\mathcal{I} f(\\boldsymbol{x}) \\right|.\n$$\n\n测试套件：\n- 情况 A（理想路径，三维平滑可分函数）：\n  - $d = 3$.\n  - $f(\\boldsymbol{x}) = \\exp\\!\\left(0.5\\,x_1 - 0.3\\,x_2 + 0.2\\,x_3\\right)$.\n  - $\\tau = 10^{-3}$, $N_{\\max} = 500$.\n  - 验证网格参数 $m = 9$.\n- 情况 B（二维各向异性局部高斯凸起）：\n  - $d = 2$.\n  - $f(\\boldsymbol{x}) = \\exp\\!\\left(-40 \\sum_{j=1}^2 (x_j - c_j)^2\\right)$ 其中 $\\boldsymbol{c} = (0.2, 0.8)$.\n  - $\\tau = 5 \\times 10^{-4}$, $N_{\\max} = 600$.\n  - 验证网格参数 $m = 25$.\n- 情况 C（一维非平滑绝对值拐点）：\n  - $d = 1$.\n  - $f(x) = |x - 0.3|$.\n  - $\\tau = 2 \\times 10^{-4}$, $N_{\\max} = 300$.\n  - 验证网格参数 $m = 200$.\n- 情况 D（带轻微振荡的四维平滑函数）：\n  - $d = 4$.\n  - $f(\\boldsymbol{x}) = \\prod_{j=1}^4 \\left(1 + 0.1\\,x_j\\right) + 0.01 \\sum_{j=1}^4 \\sin(2\\pi x_j)$，角度以弧度为单位。\n  - $\\tau = 2 \\times 10^{-3}$, $N_{\\max} = 400$.\n  - 验证网格参数 $m = 7$.\n\n实现约束和最终输出格式：\n- 您的程序必须是独立完整的，且不得读取任何输入。它必须实现上述自适应稀疏网格插值算法，并为每个测试用例计算数对 $(N, E_{\\max})$，其中 $N$ 是终止时实际使用的网格点数。\n- 您的程序应生成单行输出，其中包含一个扁平、逗号分隔的 Python 列表中的所有结果，格式为 [N_A,E_A,N_B,E_B,N_C,E_C,N_D,E_D]，其中 $N_\\cdot$ 是整数，$E_\\cdot$ 是浮点数。误差值必须以十进制数（而非分数）报告，并且存在的角度必须以弧度为单位进行解释。", "solution": "问题陈述已经过验证，被认为是合理的。它具有科学依据、提法恰当且客观。它提出了一个明确的任务：设计并实现一个基于 Smolyak 构造、使用分片线性分层基的自适应稀疏网格插值算法。其定义、算法步骤和测试用例都规定得足够严谨，能够得到唯一且可验证的解。\n\n目标是为函数 $f: [0,1]^d \\to \\mathbb{R}$ 构建一个自适应稀疏网格插值。定义域是 $d$ 维超立方体 $[0,1]^d$。该插值方案建立在分片线性“帽状”函数的分层基之上。\n\n在一维情况下，对于给定的层级 $l \\in \\mathbb{N} = \\{1, 2, 3, \\dots\\}$，在 $x_{l,i} = i / 2^l$ 处为奇数索引 $i \\in \\{1, 3, \\dots, 2^l - 1\\}$ 定义了一组节点。与每个这样的节点相关联的是一个帽状基函数：\n$$\n\\varphi_{l,i}(x) = \\max\\left(1 - 2^l \\left| x - x_{l,i} \\right|, 0\\right)\n$$\n该基函数仅在区间 $(0,1)$ 的内部定义，这意味着最终的插值函数在边界上将为零。\n\n对于一个 $d$ 维问题，基函数是通过张量积构造形成的。分层网格中的一个点由多层级 $\\boldsymbol{l} = (l_1, \\dots, l_d) \\in \\mathbb{N}^d$ 和多重索引 $\\boldsymbol{i} = (i_1, \\dots, i_d)$ 来标识，其中每个分量 $i_j$ 是满足 $1 \\le i_j \\le 2^{l_j}-1$ 的奇数。对应的网格节点为 $\\boldsymbol{x}_{\\boldsymbol{l},\\boldsymbol{i}} = (x_{l_1,i_1}, \\dots, x_{l_d,i_d})$，多维基函数为：\n$$\n\\Phi_{\\boldsymbol{l},\\boldsymbol{i}}(\\boldsymbol{x}) = \\prod_{j=1}^d \\varphi_{l_j,i_j}(x_j)\n$$\n\n稀疏网格插值 $\\mathcal{I}f(\\boldsymbol{x})$ 是针对选定的多重索引集合 $\\mathcal{A}$ 的这些基函数的线性组合：\n$$\n\\mathcal{I} f(\\boldsymbol{x}) = \\sum_{(\\boldsymbol{l},\\boldsymbol{i}) \\in \\mathcal{A}} \\alpha_{\\boldsymbol{l},\\boldsymbol{i}} \\, \\Phi_{\\boldsymbol{l},\\boldsymbol{i}}(\\boldsymbol{x})\n$$\n系数 $\\alpha_{\\boldsymbol{l},\\boldsymbol{i}}$ 是分层盈余，通过递归定义。对于一个被添加到网格中的新点 $\\boldsymbol{x}_{\\boldsymbol{l},\\boldsymbol{i}}$，其盈余是真实函数值与由所有先前包含的、更粗糙的点所构建的插值函数值之间的差：\n$$\n\\alpha_{\\boldsymbol{l},\\boldsymbol{i}} = f(\\boldsymbol{x}_{\\boldsymbol{l},\\boldsymbol{i}}) - \\sum_{(\\boldsymbol{l}',\\boldsymbol{i}') \\in \\mathcal{A}_{\\text{prev}}} \\alpha_{\\boldsymbol{l}',\\boldsymbol{i}'} \\, \\Phi_{\\boldsymbol{l}',\\boldsymbol{i}'}(\\boldsymbol{x}_{\\boldsymbol{l},\\boldsymbol{i}})\n$$\n\n指定任务的核心是算法的自适应性。自适应性由分层盈余的绝对值驱动，这些盈余值充当误差指标。算法按以下步骤进行：\n\n$1$. 初始化：过程始于最粗糙层级上的单个内部节点，由多层级 $\\boldsymbol{l} = (1, \\dots, 1)$ 和多重索引 $\\boldsymbol{i} = (1, \\dots, 1)$ 指定。这对应于点 $\\boldsymbol{x} = (0.5, \\dots, 0.5)$。其盈余就是 $\\alpha_{\\boldsymbol{l},\\boldsymbol{i}} = f(\\boldsymbol{x}_{\\boldsymbol{l},\\boldsymbol{i}})$，因为初始插值函数为零。该点及其盈余被添加到网格和优先队列中，该队列按盈余的绝对值大小排序。\n\n$2$. 迭代加密：算法进入一个循环，直到满足终止条件。在每次迭代中：\n   a. 选择：从优先队列中选择并移除具有最大绝对盈余 $|\\alpha|$ 的网格点 $(\\boldsymbol{l}_{\\text{p}}, \\boldsymbol{i}_{\\text{p}})$。这是用于加密的父点。\n   b. 加密：通过生成父点的允许子节点来加密网格。对于每个维度 $j \\in \\{1, \\dots, d\\}$，会生成两个子节点。子节点的多层级通过将父节点在维度 $j$ 的层级加 1 得到，即 $l'_j = l_j+1$ 且对于 $k \\neq j$ 有 $l'_k = l_k$。新层级 $l'_j$ 对应的索引 $i'_j$ 由 $\\{2i_j-1, 2i_j+1\\}$ 给出，而对于 $k \\neq j$ 有 $i'_k=i_k$。\n   c. 更新：对于每个新生成的子点，使用上述公式计算其分层盈余，其中求和遍及当前网格中的所有点。将新点及其盈余添加到网格数据结构中，并插入到优先队列中。\n\n$3$. 终止：如果满足以下两个条件之一，迭代过程将停止：\n   a. 优先队列中的最大绝对盈余低于指定的容差 $\\tau$。\n   b. 网格中的总点数达到定义的最大值 $N_{\\max}$。\n\n终止后，算法构建了一个稀疏网格和相应的插值函数 $\\mathcal{I}f(\\boldsymbol{x})$。最后一步是评估其精度。这是通过在预定义的验证网格 $\\mathcal{G}_m$ 上计算最大绝对误差 $E_{\\max}$ 来完成的：\n$$\nE_{\\max} = \\max_{\\boldsymbol{x} \\in \\mathcal{G}_m} \\left| f(\\boldsymbol{x}) - \\mathcal{I} f(\\boldsymbol{x}) \\right|\n$$\n验证网格 $\\mathcal{G}_m$ 是每个维度在 $(0,1)$ 区间内的 $m$ 个等距点的笛卡尔积。\n\n该实现将包含一个主驱动函数，该函数会遍历指定的测试用例。对于每种情况，一个专用的求解器函数将执行自适应算法。关键数据结构将包括一个用于存储网格点及其关联数据（盈余、坐标）的字典，以及一个来自 Python `heapq` 模块的最小堆，用作优先队列。将实现辅助函数来评估一维和多维基函数以及整个插值函数。每个测试用例的最终输出将是网格中使用的点数 $N$ 和计算出的最大误差 $E_{\\max}$。", "answer": "```python\nimport numpy as np\nimport heapq\nimport itertools\nimport math\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the adaptive sparse grid solver for each.\n    \"\"\"\n\n    # --- Test Case Definitions ---\n    # Case A: Smooth separable function\n    def f_A(x):\n        return np.exp(0.5 * x[0] - 0.3 * x[1] + 0.2 * x[2])\n\n    # Case B: Anisotropic localized Gaussian bump\n    def f_B(x):\n        c = np.array([0.2, 0.8])\n        return np.exp(-40.0 * np.sum((x - c)**2))\n\n    # Case C: Non-smooth absolute value kink\n    def f_C(x):\n        return np.abs(x[0] - 0.3)\n\n    # Case D: Smooth function with mild oscillation\n    def f_D(x):\n        prod_term = np.prod(1.0 + 0.1 * x)\n        sin_term = 0.01 * np.sum(np.sin(2.0 * np.pi * x))\n        return prod_term + sin_term\n        \n    test_cases = [\n        {'d': 3, 'f': f_A, 'tau': 1e-3, 'n_max': 500, 'm': 9},\n        {'d': 2, 'f': f_B, 'tau': 5e-4, 'n_max': 600, 'm': 25},\n        {'d': 1, 'f': f_C, 'tau': 2e-4, 'n_max': 300, 'm': 200},\n        {'d': 4, 'f': f_D, 'tau': 2e-3, 'n_max': 400, 'm': 7}\n    ]\n\n    results = []\n    for case in test_cases:\n        N, E_max = solve_case(case['d'], case['f'], case['tau'], case['n_max'], case['m'])\n        results.extend([N, E_max])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef solve_case(d, f, tau, n_max, m):\n    \"\"\"\n    Solves a single adaptive sparse grid interpolation problem.\n    \"\"\"\n    \n    # Memoization caches for basis function calculations\n    phi_1d_cache = {}\n    phi_multi_d_cache = {}\n\n    def phi_1d(x, l, i):\n        \"\"\"Evaluates the 1D hierarchical hat basis function.\"\"\"\n        cache_key = (x, l, i)\n        if cache_key in phi_1d_cache:\n            return phi_1d_cache[cache_key]\n\n        # Using 1 << l which is equivalent to 2**l for integers\n        val = max(0.0, 1.0 - abs((1 << l) * x - i))\n        phi_1d_cache[cache_key] = val\n        return val\n\n    def phi_multi_d(x_vec, l_vec, i_vec):\n        \"\"\"Evaluates the multidimensional tensor-product basis function.\"\"\"\n        cache_key = (tuple(x_vec), l_vec, i_vec)\n        if cache_key in phi_multi_d_cache:\n            return phi_multi_d_cache[cache_key]\n        \n        prod = 1.0\n        for j in range(d):\n            prod *= phi_1d(x_vec[j], l_vec[j], i_vec[j])\n        phi_multi_d_cache[cache_key] = prod\n        return prod\n\n    def evaluate_interpolant(x_vec, grid_points):\n        \"\"\"Evaluates the sparse grid interpolant at a point x_vec.\"\"\"\n        total = 0.0\n        for (l_vec, i_vec), data in grid_points.items():\n            alpha = data['surplus']\n            basis_val = phi_multi_d(x_vec, l_vec, i_vec)\n            total += alpha * basis_val\n        return total\n\n    grid_points = {}\n    priority_queue = []\n\n    # 1. Initialize with the first point\n    l0 = tuple([1] * d)\n    i0 = tuple([1] * d)\n    \n    x0 = tuple(i / (1 << l) for l, i in zip(l0, i0))\n    f_val = f(np.array(x0))\n    alpha0 = f_val  # I_prev is 0\n    \n    grid_points[(l0, i0)] = {'surplus': alpha0, 'coords': x0}\n    heapq.heappush(priority_queue, (-abs(alpha0), l0, i0))\n\n    # 2. Main adaptive loop\n    while priority_queue:\n        if len(grid_points) >= n_max:\n            break\n        \n        neg_abs_alpha_max, _, _ = priority_queue[0]\n        if -neg_abs_alpha_max < tau:\n            break\n\n        # Pop parent point with largest surplus\n        _, l_parent, i_parent = heapq.heappop(priority_queue)\n\n        # Generate and add children\n        for j in range(d):  # Dimension to refine\n            l_child_list = list(l_parent)\n            l_child_list[j] += 1\n            l_child = tuple(l_child_list)\n            \n            i_child_val_1 = 2 * i_parent[j] - 1\n            i_child_val_2 = 2 * i_parent[j] + 1\n            \n            for i_child_val in [i_child_val_1, i_child_val_2]:\n                if len(grid_points) >= n_max:\n                    break\n\n                i_child_list = list(i_parent)\n                i_child_list[j] = i_child_val\n                i_child = tuple(i_child_list)\n\n                if (l_child, i_child) in grid_points:\n                    continue\n                \n                # Calculate surplus for the new child point\n                x_child = tuple(i / (1 << l) for l, i in zip(l_child, i_child))\n                f_val_child = f(np.array(x_child))\n                \n                # Clear evaluation caches for new point evaluation\n                phi_1d_cache.clear()\n                phi_multi_d_cache.clear()\n                \n                I_prev_at_child = evaluate_interpolant(x_child, grid_points)\n                alpha_child = f_val_child - I_prev_at_child\n\n                # Add child to grid and priority queue\n                grid_points[(l_child, i_child)] = {'surplus': alpha_child, 'coords': x_child}\n                heapq.heappush(priority_queue, (-abs(alpha_child), l_child, i_child))\n            \n            if len(grid_points) >= n_max:\n                break\n    \n    # Final number of grid points used\n    N = len(grid_points)\n\n    # 3. Error calculation on validation grid\n    axis_pts = (np.arange(1, m + 1, dtype=float)) / (m + 1.0)\n    validation_grid = itertools.product(*([axis_pts] * d))\n    \n    max_error = 0.0\n    for x_val_tuple in validation_grid:\n        x_val = np.array(x_val_tuple)\n        f_true = f(x_val)\n        \n        phi_1d_cache.clear()\n        phi_multi_d_cache.clear()\n        \n        f_interp = evaluate_interpolant(x_val, grid_points)\n        max_error = max(max_error, abs(f_true - f_interp))\n            \n    return N, max_error\n\nif __name__ == \"__main__\":\n    solve()\n\n```"}]}