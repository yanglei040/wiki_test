{"hands_on_practices": [{"introduction": "我们从一个经典的离散时间线性二次（LQ）最优控制问题开始动手实践。这个练习将模拟一个水库在一年内的最优管理策略，目标是在满足用水需求和最小化成本的同时，在期末达到一个特定的蓄水量以用于防洪。通过这个直观的例子，你将学习到打靶法的核心机制：如何将一个两点边值问题（TPBVP）转化为一个根查找问题，并通过调整初始协态变量（或称影子价格）的值来“射击”，直到精确命中终端状态约束 [@problem_id:2429166]。这个练习旨在为你构建从一阶条件出发，实现一个完整打靶法求解器的基础编程能力。", "id": "2429166", "problem": "考虑在 $T$ 个月的规划期内对单个水库进行离散时间最优管理，其中 $T=12$。水库在第 $t$ 月初的蓄水量表示为 $s_t$，在第 $t$ 月期间的控制释放量为 $r_t$，其中 $t \\in \\{0,1,\\ldots,T-1\\}$。月度入流量 $I_t$ 和目标需水量 $D_t$ 是外生且已知的。一个恒定的月度蒸发损失因子 $e \\in [0,1)$ 作用于存量。蓄水量的动态由以下线性运动定律定义：\n$$\ns_{t+1} = (1 - e) s_t + I_t - r_t,\n$$\n给定初始蓄水量 $s_0$。为防洪需要，期末蓄水量必须满足一个硬边界条件：\n$$\ns_T = S^\\star.\n$$\n规划者旨在最小化跨期二次损失：\n$$\n\\sum_{t=0}^{T-1} \\left( \\tfrac{1}{2}\\alpha \\, (r_t - D_t)^2 + \\tfrac{1}{2}\\beta \\, s_t^2 \\right),\n$$\n其中 $\\alpha > 0$ 和 $\\beta \\ge 0$ 是给定权重。释放量 $r_t$ 是不受约束的实数，代表净控制出流量（正值）或净抽入量（负值），这使得问题保持为线性二次形式，并确保对于给定的损失和动态存在唯一的内部最优点。\n\n您的任务是为此有限期、离散时间的动态优化问题实现一个单次打靶法。使用动态优化的基本原理构建一阶必要条件，并确定一个合适的未知边界值进行打靶。然后，设计一个稳健的区间求根程序来调整该未知数，以便期末蓄水量约束 $s_T = S^\\star$ 能够以高数值精度得到满足。在满足边界条件后，评估给定参数下的最小化目标值。\n\n数值实现要求：\n- 使用单次打靶方法，选择一个未知的标量边界值，以允许您向前模拟状态和控制。使用区间求根法调整此未知数，直到期末约束 $s_T = S^\\star$ 在严格的容差内得到满足。\n- 向前模拟必须是稳定的，并且应能处理任何 $e \\in [0,1)$ 的情况。\n- 每个测试用例的最终答案必须是最小化的目标函数值（以实数形式表示）。\n\n测试套件：\n- 情况 A（一般情况）：$T = 12$，$\\alpha = 2.0$，$\\beta = 0.1$，$e = 0.02$，$s_0 = 30.0$，$S^\\star = 40.0$，$I = [22.0, 18.0, 15.0, 12.0, 10.0, 8.0, 7.0, 8.0, 10.0, 12.0, 16.0, 24.0]$，$D = [16.0, 16.5, 17.0, 17.5, 18.0, 19.0, 20.0, 19.5, 18.5, 17.5, 17.0, 16.5]$。\n- 情况 B（无蒸发和精确平衡的边界情况）：$T = 12$，$\\alpha = 10.0$，$\\beta = 0.0$，$e = 0.0$，$s_0 = 50.0$，$S^\\star = 50.0$，$I = [10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0]$，$D = [10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0]$。\n- 情况 C（具有较高蒸发、较强存量惩罚和较小初始存量的边缘权衡情况）：$T = 12$，$\\alpha = 0.5$，$\\beta = 0.2$，$e = 0.05$，$s_0 = 5.0$，$S^\\star = 8.0$，$I = [5.0, 4.0, 3.5, 3.0, 2.5, 2.5, 2.8, 3.2, 3.5, 4.0, 4.5, 5.0]$，$D = [3.0, 3.2, 3.5, 3.8, 4.0, 4.2, 4.5, 4.2, 4.0, 3.8, 3.5, 3.2]$。\n\n最终输出规范：\n- 您的程序应产生单行输出，其中包含情况 A、B 和 C 的最小化目标值，按此顺序以方括号括起来的逗号分隔列表形式显示，每个值都四舍五入到六位小数（例如，$[x_A,x_B,x_C]$）。", "solution": "用户提供的问题是一个适定的、离散时间、有限期的线性二次动态优化问题。它要求实现一个单次打靶法，以找到管理水库的最优控制策略，并计算相应的最小化目标函数值。\n\n该问题是有效的，因为它在科学上基于最优控制理论，在数学上是一致的、完备的和客观的。因此，我们可以开始求解。\n\n### 步骤 1：理论构建\n\n问题是在控制序列 $\\{r_t\\}_{t=0}^{T-1}$ 上最小化目标函数 $J$：\n$$\nJ = \\sum_{t=0}^{T-1} \\left( \\frac{1}{2}\\alpha (r_t - D_t)^2 + \\frac{1}{2}\\beta s_t^2 \\right)\n$$\n受状态动态约束：\n$$\ns_{t+1} = (1 - e) s_t + I_t - r_t, \\quad \\text{for } t=0, \\ldots, T-1\n$$\n以及边界条件：\n$$\ns_0 = \\text{given}, \\quad s_T = S^\\star\n$$\n\n为了推导最优性的一阶必要条件，我们使用离散时间哈密顿方法。在时间 $t$ 的哈密顿量定义为：\n$$\nH_t = \\frac{1}{2}\\alpha (r_t - D_t)^2 + \\frac{1}{2}\\beta s_t^2 + \\lambda_{t+1} \\left( (1 - e)s_t + I_t - r_t \\right)\n$$\n其中 $\\lambda_{t+1}$ 是与状态 $s_{t+1}$ 相关联的协态变量（影子价格）。\n\n一阶必要条件由离散系统的 Pontryagin 最小值原理推导得出：\n1.  **控制最优性条件**：控制 $r_t$ 必须在每个时间 $t$ 最小化哈密顿量。\n    $$\n    \\frac{\\partial H_t}{\\partial r_t} = \\alpha (r_t - D_t) - \\lambda_{t+1} = 0 \\implies r_t = D_t + \\frac{1}{\\alpha}\\lambda_{t+1}\n    $$\n2.  **协态动态方程**：协态的演化由下式给出：\n    $$\n    \\lambda_t = \\frac{\\partial H_t}{\\partial s_t} = \\beta s_t + (1 - e)\\lambda_{t+1}\n    $$\n3.  **状态动态方程**（如题所述）：\n    $$\n    s_{t+1} = (1 - e)s_t + I_t - r_t\n    $$\n4.  **横截性条件**：由于初始状态 $s_0$ 是固定的，且期末状态 $s_T$ 也是固定的，因此对应的协态值 $\\lambda_0$ 和 $\\lambda_T$ 是自由的。\n\n这组方程构成了一个两点边值问题 (TPBVP)，因为我们在开始 ($s_0$) 和结束 ($s_T$) 处都有状态的条件，而状态和协态的动态方程是耦合的，并且沿时间反向演化（状态向前，协态向后）。\n\n### 步骤 2：单次打靶法设计\n\n单次打靶法将 TPBVP 转换为一个初值问题 (IVP)。我们选择一个未知的初始值，通过对动态方程进行积分来“打靶”向前推演，然后调整我们的初始猜测，直到满足期末条件。\n\n打靶变量的一个自然选择是协态的初始值 $\\lambda_0$。如果 $\\lambda_0$ 已知，我们就可以向前模拟整个系统。\n\n给定 $\\lambda_0$ 的一个猜测值，向前模拟过程如下：\n以 $s_t = s_0$ 和 $\\lambda_t = \\lambda_0$ 初始化。对于 $t = 0, 1, \\ldots, T-1$：\n1.  从协态方程解出 $\\lambda_{t+1}$：\n    $$\n    \\lambda_{t+1} = \\frac{\\lambda_t - \\beta s_t}{1 - e}\n    $$\n    这是良定义的，因为问题指定了 $e \\in [0, 1)$。\n2.  使用 $\\lambda_{t+1}$ 找到最优控制 $r_t$：\n    $$\n    r_t = D_t + \\frac{1}{\\alpha}\\lambda_{t+1}\n    $$\n3.  使用 $r_t$ 找到下一个状态 $s_{t+1}$：\n    $$\n    s_{t+1} = (1 - e)s_t + I_t - r_t\n    $$\n4.  为下一次迭代更新状态和协态：设置 $s_t \\to s_{t+1}$ 和 $\\lambda_t \\to \\lambda_{t+1}$。\n\n这个模拟过程定义了一个函数，它将初始猜测 $\\lambda_0$ 映射到最终的期末状态，我们将其表示为 $s_T(\\lambda_0)$。我们的目标是找到特定的值 $\\lambda_0^*$，以满足期末约束：\n$$\ns_T(\\lambda_0^*) = S^\\star\n$$\n这是一个关于残差函数 $f(\\lambda_0)$ 的求根问题：\n$$\nf(\\lambda_0) = s_T(\\lambda_0) - S^\\star = 0\n$$\n\n### 步骤 3：使用区间法求根\n\n问题要求使用一种区间求根法。我们将使用二分法，该方法是稳健的，并且如果找到了初始区间，则保证收敛。一个区间是指一个区间 $[\\lambda_a, \\lambda_b]$，其中 $f(\\lambda_a)$ 和 $f(\\lambda_b)$ 异号。\n\n为确保二分法有效，我们必须分析 $f(\\lambda_0)$ 的单调性。对模拟方程关于 $\\lambda_0$ 求导，我们可以证明对于所有 $t>0$（只要 $\\alpha > 0$），$\\frac{ds_T}{d\\lambda_0} < 0$。这意味着 $s_T(\\lambda_0)$ 以及 $f(\\lambda_0)$ 是关于 $\\lambda_0$ 的严格单调递减函数。此性质保证了唯一根的存在，并简化了寻找区间的过程。\n\n二分算法的步骤如下：\n1.  建立一个初始区间 $[\\lambda_{low}, \\lambda_{high}]$，使得 $f(\\lambda_{low}) > 0$ 且 $f(\\lambda_{high}) < 0$。可以系统地扩展区间的初始猜测，直到它包含根为止。\n2.  迭代地缩小区间：\n    a. 计算中点 $\\lambda_{mid} = (\\lambda_{low} + \\lambda_{high}) / 2$。\n    b. 计算 $f(\\lambda_{mid})$。\n    c. 如果 $f(\\lambda_{mid}) > 0$，根必定位于 $[\\lambda_{mid}, \\lambda_{high}]$。设置 $\\lambda_{low} = \\lambda_{mid}$。\n    d. 如果 $f(\\lambda_{mid}) < 0$，根必定位于 $[\\lambda_{low}, \\lambda_{mid}]$。设置 $\\lambda_{high} = \\lambda_{mid}$。\n3.  重复此过程，直到区间宽度 $(\\lambda_{high} - \\lambda_{low})$ 小于指定的容差。根则由最终区间的中点近似得到。\n\n### 步骤 4：最终计算\n\n一旦最优初始协态 $\\lambda_0^*$ 被足够精确地找到，我们就使用这个值执行一次最终的向前模拟。在此模拟过程中，我们计算最优状态路径 $\\{s_t^*\\}_{t=0}^{T-1}$ 和最优控制路径 $\\{r_t^*\\}_{t=0}^{T-1}$。然后，通过对每期成本求和计算得出最小化目标函数值：\n$$\nJ^* = \\sum_{t=0}^{T-1} \\left( \\frac{1}{2}\\alpha (r_t^* - D_t)^2 + \\frac{1}{2}\\beta (s_t^*)^2 \\right)\n$$\n这个值是每个测试用例的最终结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the reservoir management problem for all test cases.\n    \"\"\"\n    # Test suite:\n    # (T, alpha, beta, e, s0, S_star, I, D)\n    test_cases = [\n        (\n            12, 2.0, 0.1, 0.02, 30.0, 40.0,\n            np.array([22.0, 18.0, 15.0, 12.0, 10.0, 8.0, 7.0, 8.0, 10.0, 12.0, 16.0, 24.0]),\n            np.array([16.0, 16.5, 17.0, 17.5, 18.0, 19.0, 20.0, 19.5, 18.5, 17.5, 17.0, 16.5]),\n        ),\n        (\n            12, 10.0, 0.0, 0.0, 50.0, 50.0,\n            np.array([10.0] * 12),\n            np.array([10.0] * 12),\n        ),\n        (\n            12, 0.5, 0.2, 0.05, 5.0, 8.0,\n            np.array([5.0, 4.0, 3.5, 3.0, 2.5, 2.5, 2.8, 3.2, 3.5, 4.0, 4.5, 5.0]),\n            np.array([3.0, 3.2, 3.5, 3.8, 4.0, 4.2, 4.5, 4.2, 4.0, 3.8, 3.5, 3.2]),\n        ),\n    ]\n\n    results = []\n    for case_params in test_cases:\n        obj_val = solve_single_case(*case_params)\n        results.append(f\"{obj_val:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef solve_single_case(T, alpha, beta, e, s0, S_star, I, D):\n    \"\"\"\n    Solves a single instance of the dynamic optimization problem using a single-shooting method.\n    \n    Args:\n        T (int): Planning horizon.\n        alpha (float): Weight on control deviation.\n        beta (float): Weight on state deviation.\n        e (float): Evaporation factor.\n        s0 (float): Initial storage.\n        S_star (float): Target terminal storage.\n        I (np.array): Inflow vector.\n        D (np.array): Demand vector.\n\n    Returns:\n        float: The minimized objective function value.\n    \"\"\"\n\n    one_minus_e = 1.0 - e\n\n    def forward_simulation(lambda0):\n        \"\"\"\n        Simulates the system dynamics forward given an initial co-state lambda0.\n        Returns the terminal state s_T and the accumulated objective value.\n        \"\"\"\n        s = s0\n        lam = lambda0\n        total_objective = 0.0\n\n        for t in range(T):\n            # Add cost associated with state s_t\n            total_objective += 0.5 * beta * s**2\n\n            # Calculate co-state lambda_{t+1}\n            lam_next = (lam - beta * s) / one_minus_e\n\n            # Calculate control r_t\n            r = D[t] + lam_next / alpha\n            \n            # Add cost associated with control r_t\n            total_objective += 0.5 * alpha * (r - D[t])**2\n\n            # Calculate next state s_{t+1}\n            s_next = one_minus_e * s + I[t] - r\n            \n            # Update for next iteration\n            s = s_next\n            lam = lam_next\n\n        return s, total_objective\n\n    def residual_function(lambda0):\n        \"\"\"\n        Calculates the residual s_T(lambda0) - S_star. This is the function\n        for which we a find a root.\n        \"\"\"\n        s_T, _ = forward_simulation(lambda0)\n        return s_T - S_star\n\n    # --- Bracketed Root-Finding (Bisection Method) ---\n\n    # 1. Find a bracket [low, high] for lambda0\n    low, high = -100.0, 100.0\n    f_low = residual_function(low)\n    f_high = residual_function(high)\n\n    # Expand the bracket if the root is not contained\n    expansion_iter = 0\n    while f_low * f_high > 0 and expansion_iter < 20:\n        if abs(f_low) < abs(f_high):\n            low *= 2.0\n            f_low = residual_function(low)\n        else:\n            high *= 2.0\n            f_high = residual_function(high)\n        expansion_iter += 1\n\n    if f_low * f_high > 0:\n        raise RuntimeError(\"Failed to find a bracket for the root.\")\n\n    # The function s_T(lambda0) is monotonically decreasing.\n    # We ensure f(low) > 0 and f(high) < 0.\n    if f_low < f_high:\n        low, high = high, low\n        f_low, f_high = f_high, f_low\n\n    # 2. Bisection to find the root\n    tol = 1e-12\n    max_iter = 100\n    for _ in range(max_iter):\n        mid = (low + high) / 2.0\n        if high - low < tol:\n            break\n        \n        f_mid = residual_function(mid)\n\n        if abs(f_mid) < tol:\n            low = high = mid\n            break\n        \n        # As s_T(lambda0) is decreasing, so is the residual function.\n        # If f_mid > 0, the root is in the upper half of the interval.\n        if f_mid > 0:\n            low = mid\n        else:\n            high = mid\n            \n    lambda0_optimal = (low + high) / 2.0\n\n    # 3. Final calculation with the optimal lambda0\n    _, final_objective = forward_simulation(lambda0_optimal)\n\n    return final_objective\n\n# The script should be runnable \"as is\"\nif __name__ == \"__main__\":\n    solve()\n\n```"}, {"introduction": "在掌握了离散时间模型后，我们将把打靶法的应用扩展到连续时间领域。这个练习探讨了一个关于如何最优地使用抗生素以控制医院内耐药性病原体演化的问题 [@problem_id:2429165]。你将应用庞特里亚金极大值原理来推导系统的必要条件，这些条件表现为一组常微分方程（ODEs）。由于该系统是线性的，本练习将引导你使用叠加原理（principle of superposition），这是一种极其高效和优雅的数值技巧，可以一步到位地求解出正确的初始协态变量，而无需迭代。这个实践不仅展示了打靶法在不同时间域的通用性，也为你的数值工具箱增添了一项高级技术。", "id": "2429165", "problem": "考虑以下以固定终端状态的边值问题形式给出的二次最优控制问题。标量状态 $R(t)$ 表示在时间 $t$ 医院中耐药病原体的份额，标量控制 $u(t)$ 表示抗生素使用强度。其动力学是线性的，由下式给出\n$$\\dot{R}(t) = \\theta u(t) - \\delta R(t), \\quad R(0) = R_0,$$\n其中 $\\theta > 0$ 是抗生素使用对耐药性的边际效应，$\\delta > 0$ 是在没有使用抗生素的情况下耐药性的自然衰减率。目标是最小化二次折扣成本泛函\n$$J[u] = \\int_0^T \\frac{1}{2}\\left(u(t)^2 + q R(t)^2\\right)\\,dt,$$\n约束条件为在固定的终端时间 $T$ 达到目标耐药水平 $R(T) = R_T$。假设所有参数均为常数，且 $\\theta > 0$、$\\delta > 0$、$q > 0$、$T > 0$，并具有给定的初始值 $R_0$ 和终端值 $R_T$。没有控制界限。\n\n您的任务是编写一个完整、可运行的程序，该程序：\n- 使用庞特里亚金极大值原理，从第一性原理推导出可实现的必要条件系统，并使用打靶法，通过恰当选择初始协态，来数值上强制满足终端条件 $R(T) = R_T$。\n- 使用正向积分和对未知初始协态的求根更新来求解所得到的两点边值问题。您的实现必须是完全自包含的，并且不得要求任何用户输入。\n- 对于每个测试用例，返回最优初始控制 $u(0)$ 和最小化的目标值 $J$。\n\n您可以假定已知以下基本知识：庞特里亚金极大值原理的定义、最优控制问题的哈密顿量的定义、将必要条件与协态联系起来的欧拉-拉格朗日逻辑，以及标准的常微分方程求解概念。您不得假定为该特定问题量身定制的专门公式；在实现数值方法之前，必须从定义开始推导必要条件。\n\n数值规格：\n- 使用正向打靶法。将初始协态 $\\lambda(0)$ 视为一个待求的未知数，以便在哈密顿系统的正向解下，状态能够达到终端目标 $R(T) = R_T$。您必须将终端状态条件的强制执行精度控制在 $10^{-8}$ 的绝对容差内。\n- 对常微分方程使用鲁棒的时间积分器，并对 $\\lambda(0)$ 使用数值稳定的更新。数值实现必须在给定的测试套件上保持稳定。\n\n测试套件：\n- 情况 A：$T = 10.0$，$R_0 = 0.1$，$R_T = 0.2$，$\\theta = 0.8$，$\\delta = 0.05$，$q = 0.4$。\n- 情况 B：$T = 0.5$，$R_0 = 0.2$，$R_T = 0.21$，$\\theta = 1.0$，$\\delta = 0.1$，$q = 0.7$。\n- 情况 C：$T = 5.0$，$R_0 = 0.3$，$R_T = 0.15$，$\\theta = 1.2$，$|delta = 0.3$，$q = 0.2$。\n\n答案规格：\n- 对于每个测试用例，计算最优初始控制 $u(0)$ 和最小化的目标值 $J$。将这两个数字表示为四舍五入到恰好 $6$ 位小数的十进制浮点值。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的结果列表。每个测试用例的结果必须是 $[u(0), J]$ 顺序的一个双元素列表。对于以上三个测试用例，要求的格式是\n\"[ [u0_A,J_A], [u0_B,J_B], [u0_C,J_C] ]\"，但在每对内部的逗号后或对与对之间没有空格。具体来说，您的程序必须精确地打印单行，格式如下\n\"[[u0_A,J_A],[u0_B,J_B],[u0_C,J_C]]\"\n其中每个符号都被替换为四舍五入到 $6$ 位小数的相应十进制数。\n\n该问题中没有物理单位。该问题中不出现角度。任何地方都不得使用百分比；所有结果都必须是十进制数。", "solution": "所呈现的问题是一个具有固定终端状态的连续时间有限时域线性二次最优控制问题。通过应用庞特里亚金极大值原理推导必要条件系统来获得解，这会得到一个两点边值问题 (TPBVP)。然后使用正向打靶法对该 TPBVP 进行数值求解。\n\n首先，我们从第一性原理建立理论基础。状态变量是 $R(t)$，控制变量是 $u(t)$。状态动力学由下式给出\n$$ \\dot{R}(t) = \\theta u(t) - \\delta R(t), \\quad R(0) = R_0 $$\n目标是最小化成本泛函\n$$ J[u] = \\int_0^T \\frac{1}{2}\\left(u(t)^2 + q R(t)^2\\right)\\,dt $$\n并满足终端约束 $R(T) = R_T$。\n\n为了应用庞特里亚金极大值原理，我们引入协态（或称伴随）变量 $\\lambda(t)$ 并定义哈密顿量 $H$：\n$$ H(R, u, \\lambda) = \\frac{1}{2}(u(t)^2 + q R(t)^2) + \\lambda(t)(\\theta u(t) - \\delta R(t)) $$\n最优轨迹 $(R^*(t), u^*(t))$ 的必要条件由状态方程、协态方程和最优性条件给出。\n\n$1$. 状态方程：\n$$ \\dot{R}^*(t) = \\frac{\\partial H}{\\partial \\lambda} = \\theta u^*(t) - \\delta R^*(t) $$\n这就恢复了具有初始条件 $R^*(0) = R_0$ 和终端条件 $R^*(T) = R_T$ 的系统动力学。\n\n$2$. 协态方程：\n$$ \\dot{\\lambda}^*(t) = -\\frac{\\partial H}{\\partial R} = -(q R^*(t) - \\delta \\lambda^*(t)) = -q R^*(t) + \\delta \\lambda^*(t) $$\n由于终端状态 $R(T)$ 是固定的，因此对 $\\lambda^*(T)$ 没有横截条件；其值不受限制。\n\n$3$. 最优性条件：\n在每个时间 $t \\in [0, T]$，哈密顿量必须相对于控制 $u(t)$ 最小化。由于控制是无约束的，我们通过将 $H$ 对 $u$ 的一阶导数置零来找到最小值：\n$$ \\frac{\\partial H}{\\partial u} = u^*(t) + \\theta \\lambda^*(t) = 0 $$\n这得出了以协态表示的最优控制律：\n$$ u^*(t) = -\\theta \\lambda^*(t) $$\n二阶导数 $\\frac{\\partial^2 H}{\\partial u^2} = 1 > 0$ 证实了此条件对应于一个最小值。\n\n将最优控制律代回到状态和协态方程中，得到一个关于 $R(t)$ 和 $\\lambda(t)$ 的包含两个耦合线性常微分方程 (ODE) 的系统：\n$$ \\dot{R}(t) = -\\delta R(t) - \\theta^2 \\lambda(t) $$\n$$ \\dot{\\lambda}(t) = -q R(t) + \\delta \\lambda(t) $$\n这些方程受边界条件 $R(0) = R_0$ 和 $R(T) = R_T$ 的约束。这构成了一个两点边值问题。\n\n为了求解这个 TPBVP，我们采用正向打靶法。未知的初始条件是初始协态，我们记为 $p = \\lambda(0)$。目标是找到 $p$ 的值，使得如果我们从 $(R(0), \\lambda(0)) = (R_0, p)$ 开始对 ODE 系统进行正向积分，解满足 $R(T) = R_T$。\n\n由于 ODE 系统的线性，我们可以应用叠加原理来高效地求解 $p$。$R(t)$ 的解可以表示为一个齐次解（由 $R_0$ 驱动）和一个特解（由 $p$ 驱动）的线性组合。设 $(R_h(t), \\lambda_h(t))$ 是初始条件为 $(R_h(0), \\lambda_h(0)) = (R_0, 0)$ 的 ODE 系统的解，并设 $(R_p(t), \\lambda_p(t))$ 是初始条件为 $(R_p(0), \\lambda_p(0)) = (0, 1)$ 的解。从 $(R_0, p)$ 开始的通解则由下式给出：\n$$ R(t) = R_h(t) + p \\cdot R_p(t) $$\n为了满足终端条件 $R(T) = R_T$，我们必须有：\n$$ R_T = R_h(T) + p \\cdot R_p(T) $$\n求解未知的初始协态 $p$ 可得：\n$$ p = \\lambda(0) = \\frac{R_T - R_h(T)}{R_p(T)} $$\n这提供了一种找到正确 $\\lambda(0)$ 的直接方法。数值步骤如下：\n$1$. 以初始条件 $(R_0, 0)$ 对 ODE 系统从 $t=0$ 到 $t=T$ 进行数值积分，以求得 $R_h(T)$。\n$2$. 以初始条件 $(0, 1)$ 对同一系统从 $t=0$ 到 $t=T$ 进行数值积分，以求得 $R_p(T)$。\n$3$. 使用上述公式计算所需的初始协态 $\\lambda(0) = p$。\n\n在完全确定了正确的初始条件 $(R(0), \\lambda(0)) = (R_0, p)$ 后，就可以计算最小化的目标值 $J$。$J$ 的被积函数是 $\\frac{1}{2}(u(t)^2 + qR(t)^2) = \\frac{1}{2}(\\theta^2 \\lambda(t)^2 + qR(t)^2)$。为了计算该积分，我们用一个表示累积成本的第三个状态变量 $V(t)$ 来增广 ODE 系统：\n$$ \\dot{V}(t) = \\frac{1}{2}(\\theta^2 \\lambda(t)^2 + q R(t)^2), \\quad V(0) = 0 $$\n通过以初始条件 $(R(0), \\lambda(0), V(0)) = (R_0, p, 0)$ 对增广的三维系统从 $t=0$到$t=T$ 进行积分，可获得最小化的目标值 $J = V(T)$。最优初始控制由 $u(0) = -\\theta \\lambda(0) = -\\theta p$ 给出。此过程将为每个提供的测试用例实现。", "answer": "```python\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef solve():\n    \"\"\"\n    Solves the quadratic optimal control problem for three test cases\n    using a forward shooting method based on the principle of superposition.\n    \"\"\"\n    # Test cases as provided in the problem statement.\n    # Format: (T, R0, RT, theta, delta, q)\n    test_cases = [\n        (10.0, 0.1, 0.2, 0.8, 0.05, 0.4),  # Case A\n        (0.5, 0.2, 0.21, 1.0, 0.1, 0.7),  # Case B\n        (5.0, 0.3, 0.15, 1.2, 0.3, 0.2),  # Case C\n    ]\n\n    results = []\n\n    for case in test_cases:\n        T, R0, RT, theta, delta, q = case\n\n        # Pre-compute squared parameters for efficiency in the ODE integrators.\n        theta_sq = theta**2\n\n        # Define the Hamiltonian ODE system for R(t) and lambda(t).\n        def hamiltonian_system(t, y):\n            \"\"\"\n            Represents the system d(y)/dt = A*y, where y = [R, lambda].\n            \"\"\"\n            R, lam = y\n            R_dot = -delta * R - theta_sq * lam\n            lam_dot = -q * R + delta * lam\n            return [R_dot, lam_dot]\n\n        # Use high-precision tolerances for the numerical integration to ensure\n        # the terminal condition is met accurately.\n        atol = 1e-12\n        rtol = 1e-12\n        \n        # --- Shooting Method using Superposition ---\n\n        # 1. Integrate for the homogeneous part of the solution, driven by R0.\n        #    Initial conditions: [R(0), lambda(0)] = [R0, 0].\n        y0_h = [R0, 0.0]\n        sol_h = solve_ivp(\n            hamiltonian_system, [0, T], y0_h, atol=atol, rtol=rtol\n        )\n        R_h_T = sol_h.y[0, -1]\n\n        # 2. Integrate for the particular part of the solution, driven by lambda(0).\n        #    Initial conditions: [R(0), lambda(0)] = [0, 1].\n        y0_p = [0.0, 1.0]\n        sol_p = solve_ivp(\n            hamiltonian_system, [0, T], y0_p, atol=atol, rtol=rtol\n        )\n        R_p_T = sol_p.y[0, -1]\n        \n        if abs(R_p_T) < 1e-10:\n            raise RuntimeError(\n                \"Shooting method failed: R_p(T) is near zero, \"\n                \"indicating lambda(0) has no influence on R(T).\"\n            )\n\n        # 3. Compute the correct initial costate lambda(0) such that R(T) = RT.\n        #    From linearity: RT = R_h(T) + lambda_0 * R_p(T)\n        lambda_0 = (RT - R_h_T) / R_p_T\n\n        # --- Final Calculation ---\n\n        # The optimal initial control is derived from the optimal lambda_0.\n        u0_opt = -theta * lambda_0\n\n        # Define the augmented system including the cost functional integral V(t).\n        def augmented_system(t, y):\n            \"\"\"\n            Represents the system for [R, lambda, V], where V is the accumulated cost.\n            \"\"\"\n            R, lam, V = y\n            R_dot = -delta * R - theta_sq * lam\n            lam_dot = -q * R + delta * lam\n            V_dot = 0.5 * (theta_sq * lam**2 + q * R**2)\n            return [R_dot, lam_dot, V_dot]\n\n        # 4. Integrate the full system forward with the correct initial conditions\n        #    [R(0), lambda(0), V(0)] to find the optimal trajectory and cost.\n        y0_final = [R0, lambda_0, 0.0]\n        sol_final = solve_ivp(\n            augmented_system, [0, T], y0_final, atol=atol, rtol=rtol\n        )\n\n        # The minimized total cost J is the value of V(T).\n        J_opt = sol_final.y[2, -1]\n        \n        # Verify terminal condition is met within the specified tolerance of 1e-8.\n        R_T_final = sol_final.y[0, -1]\n        if abs(R_T_final - RT) > 1e-8:\n             raise RuntimeError(\n                f\"Terminal condition not met. Error: {abs(R_T_final - RT)}\"\n            )\n\n        # Append the formatted results for the current test case.\n        # Results are rounded to 6 decimal places as specified.\n        results.append(f\"[{u0_opt:.6f},{J_opt:.6f}]\")\n\n    # Print the final output in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"}, {"introduction": "前面的练习处理的都是“表现良好”的光滑模型，但在现实世界的经济建模中，我们经常会遇到更为复杂的情况。这个概念性练习将挑战你思考打靶法的局限性：当模型的目标函数（例如，效用函数）在某一点不可微时会发生什么？[@problem_id:2429232]。这种“扭结”（kink）常见于行为经济学模型中，它可能导致基于梯度的求解器（如牛顿法）失效。通过分析这个问题，你将深入理解算法的稳健性问题，并认识到在面对非光滑问题时，诸如二分法之类的稳健求根方法的重要性。这并非一个编程任务，而是一次批判性思维的锻炼，旨在培养你作为一名严谨的计算经济学研究者所应具备的审慎分析能力。", "id": "2429232", "problem": "考虑一个确定性的有限期离散时间消费储蓄问题，期限长度为 $T \\in \\mathbb{N}$，其中一个代表性行为人选择序列 $\\{c_t,k_{t+1}\\}_{t=0}^{T-1}$ 来最大化\n$$\n\\sum_{t=0}^{T-1} \\beta^t u(c_t),\n$$\n受资源约束\n$$\nc_t + k_{t+1} = A k_t^{\\alpha} + (1-\\delta) k_t \\quad \\text{对所有 } t \\in \\{0,1,\\dots,T-1\\},\n$$\n以及边界条件 $k_0 = \\bar{k}_0 > 0$ 和 $k_T = \\bar{k}_T > 0$ 的限制。参数为 $\\beta \\in (0,1)$, $A > 0$, $\\alpha \\in (0,1)$ 和 $\\delta \\in (0,1)$。消费必须满足对所有 $t$ 都有 $c_t > 0$。每期效用函数在参考水平 $c_{\\mathrm{ref}} > 0$ 处有一个拐点，其形式为\n$$\nu(c) =\n\\begin{cases}\nB_1 \\dfrac{c^{1-\\sigma}}{1-\\sigma}, & \\text{若 } c < c_{\\mathrm{ref}},\\\\\n[8pt]\nB_2 \\dfrac{c^{1-\\sigma}}{1-\\sigma} + K, & \\text{若 } c \\ge c_{\\mathrm{ref}},\n\\end{cases}\n$$\n其中 $\\sigma > 0$ 且 $\\sigma \\ne 1$，$B_1 > B_2 > 0$，常数 $K$ 的选择使得 $u(c)$ 在 $c_{\\mathrm{ref}}$ 处连续。生产函数 $f(k) = A k^{\\alpha}$ 是严格凹且可微的，而 $u(c)$ 是严格递增且凹的，但在 $c_{\\mathrm{ref}}$ 处不可微。\n\n采用一种“打靶”法来满足终端条件 $k_T = \\bar{k}_T$，通过猜测一个初始消费 $c_0$ 并将均衡条件向前递推以获得 $k_T(c_0)$，定义残差映射\n$$\nF(c_0) \\equiv k_T(c_0) - \\bar{k}_T.\n$$\n一个标准的牛顿型更新使用\n$$\nc_0^{(n+1)} = c_0^{(n)} - \\frac{F(c_0^{(n)})}{F'(c_0^{(n)})},\n$$\n其中 $F'(c_0^{(n)})$ 在可用时通过解析方法获得，或通过数值敏感性计算获得。\n\n关于这种打靶算法在存在带拐点效用函数时的性能，以下哪些陈述最为准确？\n\nA. 如果模拟的消费路径在某个时期穿过 $c_{\\mathrm{ref}}$，则映射 $F(c_0)$ 在相应的 $c_0$ 处可能不可微，因此牛顿更新可能会变得无定义或在这些迭代点附近表现出不稳定的振荡。\n\nB. 因为目标函数是凹的且约束是光滑的，所以残差映射 $F$ 是严格凸且连续可微的，这意味着从任何初始猜测开始，牛顿法都能全局收敛。\n\nC. 将诸如二分法或 regula falsi 等区间求根法的变体应用于 $F(c_0)$，并在区间端点维持异号，这种方法对拐点更为稳健，尽管其收敛通常是线性的而非二次的。\n\nD. 在 $c_{\\mathrm{ref}}$ 附近的一个小邻域内，用一个二次连续可微的近似替换 $u(c)$，可以恢复 $F$ 的光滑性和牛顿型打靶法的局部二次收敛性，但代价是在计算出的策略中引入了可控的近似误差。\n\nE. 拐点使得一阶最优性条件在任何地方都无效，因此任何基于这些条件的打靶方法，无论进行何种数值修改，都是不适用的。", "solution": "对问题陈述进行验证。\n\n### 步骤 1：提取已知条件\n- **目标函数**：选择 $\\{c_t, k_{t+1}\\}_{t=0}^{T-1}$ 以最大化 $\\sum_{t=0}^{T-1} \\beta^t u(c_t)$。\n- **资源约束**：$c_t + k_{t+1} = A k_t^{\\alpha} + (1-\\delta) k_t$ 对所有 $t \\in \\{0,1,\\dots,T-1\\}$。\n- **边界条件**：$k_0 = \\bar{k}_0 > 0$ 和 $k_T = \\bar{k}_T > 0$。\n- **参数**：期限 $T \\in \\mathbb{N}$，贴现因子 $\\beta \\in (0,1)$，生产率因子 $A > 0$，产出弹性 $\\alpha \\in (0,1)$，折旧率 $\\delta \\in (0,1)$。\n- **消费约束**：对所有 $t$ 都有 $c_t > 0$。\n- **效用函数**：\n$$\nu(c) =\n\\begin{cases}\nB_1 \\dfrac{c^{1-\\sigma}}{1-\\sigma}, & \\text{若 } c < c_{\\mathrm{ref}},\\\\\nB_2 \\dfrac{c^{1-\\sigma}}{1-\\sigma} + K, & \\text{若 } c \\ge c_{\\mathrm{ref}},\n\\end{cases}\n$$\n参数为 $\\sigma > 0$，$\\sigma \\ne 1$，$B_1 > B_2 > 0$，$c_{\\mathrm{ref}} > 0$。\n- **效用属性**：$u(c)$ 在 $c_{\\mathrm{ref}}$ 处连续，严格递增，凹，但在 $c_{\\mathrm{ref}}$ 处不可微。\n- **生产函数**：$f(k) = A k^{\\alpha}$ 是严格凹且可微的。\n- **打靶算法定义**：\n    - 残差映射：$F(c_0) \\equiv k_T(c_0) - \\bar{k}_T$，其中 $k_T(c_0)$ 是从一个初始猜测 $c_0$ 向前迭代得到的终端资本。\n    - 牛顿型更新：$c_0^{(n+1)} = c_0^{(n)} - \\frac{F(c_0^{(n)})}{F'(c_0^{(n)})}$。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题描述了一个标准的有限期新古典增长模型，这是动态宏观经济学的基石。效用函数是一个分段的 CRRA (恒定相对风险规避) 函数，这引入了一个拐点。这是行为经济学中研究的对参考依赖型偏好进行建模的一种合理方式。所有参数都在标准的经济学范围内定义。\n\n- **科学依据**：该模型在计算经济学和金融学中是科学合理的、成熟的模型。\n- **适定性**：该动态优化问题是适定的。目标函数 $u(c)$ 是凹的（如下所示），且约束集是凸的。所提出的问题与特定求解算法（打靶法）的数值性质有关，这是一个标准课题。\n- **客观性**：问题以精确的数学语言陈述。\n\n我们来验证 $u(c)$ 的性质。\n$c_{\\mathrm{ref}}$ 处的连续性要求 $B_1 \\frac{c_{\\mathrm{ref}}^{1-\\sigma}}{1-\\sigma} = B_2 \\frac{c_{\\mathrm{ref}}^{1-\\sigma}}{1-\\sigma} + K$，这决定了常数 $K$ 为 $K = (B_1 - B_2) \\frac{c_{\\mathrm{ref}}^{1-\\sigma}}{1-\\sigma}$。这是一个有效的定义。\n边际效用为：\n$$\nu'(c) =\n\\begin{cases}\nB_1 c^{-\\sigma}, & \\text{若 } c < c_{\\mathrm{ref}},\\\\\nB_2 c^{-\\sigma}, & \\text{若 } c > c_{\\mathrm{ref}}.\n\\end{cases}\n$$\n由于 $B_1 > B_2 > 0$ 且 $c_{\\mathrm{ref}} > 0$，导数在 $c_{\\mathrm{ref}}$ 处的左极限是 $\\lim_{c \\to c_{\\mathrm{ref}}^{-}} u'(c) = B_1 c_{\\mathrm{ref}}^{-\\sigma}$，右极限是 $\\lim_{c \\to c_{\\mathrm{ref}}^{+}} u'(c) = B_2 c_{\\mathrm{ref}}^{-\\sigma}$。因为 $B_1 > B_2$，我们有 $\\lim_{c \\to c_{\\mathrm{ref}}^{-}} u'(c) > \\lim_{c \\to c_{\\mathrm{ref}}^{+}} u'(c)$。一个连续函数其导数的向下跳跃证实了该函数是凹的，并且在该点不可微。\n二阶导数为 $u''(c) = -B_i \\sigma c^{-\\sigma-1} < 0$ 对 $c \\ne c_{\\mathrm{ref}}$ 成立，这也支持了凹性。\n\n问题表述是完整的、一致的，并且有科学依据。它没有违反任何验证标准。\n\n### 步骤 3：结论与行动\n问题有效。将推导解答。\n\n### 推导与选项分析\n动态优化问题的核心是欧拉方程，它代表了跨期最优性的一阶条件。对于一个可微的效用函数，它是：\n$$ u'(c_t) = \\beta u'(c_{t+1}) (f'(k_{t+1}) + 1 - \\delta) $$\n其中 $f'(k) = \\alpha A k^{\\alpha-1}$。由于 $u(c)$ 在 $c_{\\mathrm{ref}}$ 处存在拐点，导数 $u'(c)$ 在该点没有定义。因此，最优性条件必须使用次微分 $\\partial u(c)$ 来表示，它是所有次梯度的集合。\n- 若 $c \\ne c_{\\mathrm{ref}}$，则 $\\partial u(c) = \\{u'(c)\\}$。\n- 若 $c = c_{\\mathrm{ref}}$，则 $\\partial u(c) = [B_2 c_{\\mathrm{ref}}^{-\\sigma}, B_1 c_{\\mathrm{ref}}^{-\\sigma}]$。\n\n欧拉方程推广为一个包含关系：\n$$ \\frac{\\partial u(c_{t+1})}{\\beta(f'(k_{t+1}) + 1 - \\delta)} \\cap \\partial u(c_t) \\ne \\emptyset $$\n打靶算法的工作原理是：猜测一个初始消费 $c_0$，然后使用资源约束和欧拉方程随时间向前迭代，以确定路径 $\\{c_t, k_{t+1}\\}_{t=1}^{T-1}$。\n具体来说，给定 $c_t$ 和 $k_t$：\n1. 找到 $k_{t+1} = f(k_t) + (1-\\delta)k_t - c_t$。\n2. 确定时间 $t$ 的边际效用，它是一个值 $p_t \\in \\partial u(c_t)$。对于 $c_t \\ne c_{\\mathrm{ref}}$，$p_t = u'(c_t)$。\n3. 根据欧拉方程，时间 $t+1$ 的目标边际效用是一个值 $p_{t+1} = p_t / [\\beta(f'(k_{t+1}) + 1 - \\delta)]$。\n4. 找到 $c_{t+1}$ 使得 $p_{t+1} \\in \\partial u(c_{t+1})$。这意味着 $c_{t+1}$ 是通过次微分映射的逆（我们称之为 $(\\partial u)^{-1}$）找到的。\n\n映射 $y \\mapsto (\\partial u)^{-1}(y)$ 是适定且连续的。然而，由于次微分 $\\partial u(c_{\\mathrm{ref}})$ 是一个区间，逆映射 $(\\partial u)^{-1}(y)$ 在 $y \\in [B_2 c_{\\mathrm{ref}}^{-\\sigma}, B_1 c_{\\mathrm{ref}}^{-\\sigma}]$ 上将是平坦的。它在该区域内不可微（其导数为 0），并且其导数在该区域的端点处不连续。\n\n函数 $F(c_0) = k_T(c_0) - \\bar{k}_T$ 是通过将这些步骤复合 $T-1$ 次构建的。算子 $(\\partial u)^{-1}$ 的不可微性会通过这种复合传播。如果对于某一个猜测 $c_0^*$，所得到的消费路径 $\\{c_t(c_0^*)\\}_{t=1}^{T-1}$ 包含一个元素 $c_t(c_0^*) = c_{\\mathrm{ref}}$，那么映射 $c_0 \\mapsto k_T(c_0)$ 将在 $c_0^*$ 处继承不可微性。\n\n基于此理解，我们评估每个选项。\n\n**A. 如果模拟的消费路径在某个时期穿过 $c_{\\mathrm{ref}}$，则映射 $F(c_0)$ 在相应的 $c_0$ 处可能不可微，因此牛顿更新可能会变得无定义或在这些迭代点附近表现出不稳定的振荡。**\n这一陈述是我们分析的直接结果。映射 $F(c_0)$ 是建立在消费路径的逐步计算之上的。如前所述，如果对于某个 $c_0$，路径在某个时间 $t$ 达到 $c_{\\mathrm{ref}}$，则函数 $c_{t+1}(c_t, k_{t+1})$（它使用了逆边际效用函数 $(u')^{-1}$）的解析形式会发生变化。这在映射 $c_0 \\mapsto k_T(c_0)$ 中引入了一个拐点。牛顿法需要导数 $F'(c_0)$，而它在这样的拐点处不存在。试图在这样的点附近使用牛顿法，例如用有限差分近似来计算导数，将会得到高度变化的导数估计值，从而导致不稳定的步长、振荡或无法找到根。\n**结论：正确。**\n\n**B. 因为目标函数是凹的且约束是光滑的，所以残差映射 $F$ 是严格凸且连续可微的，这意味着从任何初始猜测开始，牛顿法都能全局收敛。**\n这个陈述包含几个谬误。目标函数的凹性和约束的光滑性是优化问题的性质，并不能保证打靶算法中残差函数 $F(c_0)$ 的数值性质。如前所述，效用函数 $u(c)$ 中的拐点使得映射 $F(c_0)$ 在某些点上不可微。因此，它不可能是连续可微的。此外，即使 $F$ 是 $C^1$ 的且是凸的，没有更强的条件，牛顿法的全局收敛也无法保证。\n**结论：错误。**\n\n**C. 将诸如二分法或 regula falsi 等区间求根法的变体应用于 $F(c_0)$，并在区间端点维持异号，这种方法对拐点更为稳健，尽管其收敛通常是线性的而非二次的。**\n函数 $F(c_0) = k_T(c_0) - \\bar{k}_T$ 是 $c_0$ 的一个连续函数，因为其构建过程中的所有操作都是连续的。像二分法这样的区间方法只需要函数的连续性，而不需要可微性。因此，它们不受拐点引起的问题的影响。众所周知，这类方法比牛顿法更稳健。其代价是收敛速度较慢：二分法的收敛是线性的，而牛顿法在满足其假设时是二次收敛的。这个陈述准确地描述了一种有效且稳健的替代策略。通常可以找到一个区间 $[c_{0,a}, c_{0,b}]$，因为 $k_T(c_0)$ 是 $c_0$ 的递减函数：一个非常低的 $c_0$ 会导致高储蓄和 $k_T > \\bar{k}_T$ ($F>0$)，而一个非常高的 $c_0$ 会耗尽资本，导致 $k_T < \\bar{k}_T$ ($F<0$)。\n**结论：正确。**\n\n**D. 在 $c_{\\mathrm{ref}}$ 附近的一个小邻域内，用一个二次连续可微的近似替换 $u(c)$，可以恢复 $F$ 的光滑性和牛顿型打靶法的局部二次收敛性，但代价是在计算出的策略中引入了可控的近似误差。**\n这描述了“平滑拐点”的方法，这是计算分析中的一种标准技术。通过在一个围绕 $c_{\\mathrm{ref}}$ 的小区间内用一个光滑的近似函数 $u_{\\text{approx}}(c)$（例如，一个多项式）替换不可微的函数 $u(c)$，从而创建了一个新问题。对于这个新问题，边际效用 $u'_{\\text{approx}}(c)$ 及其逆是光滑的（$C^1$ 或更好）。因此，修改后问题的残差映射 $F_{\\text{approx}}(c_0)$ 变得足够光滑，使得牛顿法适用并表现出其特有的局部二次收敛性。所获得的解是针对近似问题的，它与原始问题相差一个小的、可控的量。该陈述准确地描述了处理此问题的一种复杂而实用的方法。\n**结论：正确。**\n\n**E. 拐点使得一阶最优性条件在任何地方都无效，因此任何基于这些条件的打靶方法，无论进行何种数值修改，都是不适用的。**\n这一断言是明显错误的。一阶条件并没有“无效”。它们通过使用次梯度的概念被推广，从而得到一个欧拉包含关系，而不是欧拉方程。这个框架在数学上是严谨的，并为非光滑凸优化问题提供了正确的最优性条件。打靶方法可以被调整以处理这些推广的条件，尽管它们会面临选项 A、C 和 D 中描述的数值挑战。声称条件“在任何地方都”无效也是不正确的；在远离拐点的地方，标准的欧拉方程完全成立。\n**结论：错误。**\n\n综上所述，陈述 A、C 和 D 都是对带拐点效用函数的数值影响以及处理策略的准确描述。", "answer": "$$\\boxed{ACD}$$"}]}