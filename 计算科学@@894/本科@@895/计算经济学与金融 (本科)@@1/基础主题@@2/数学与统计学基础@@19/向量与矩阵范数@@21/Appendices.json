{"hands_on_practices": [{"introduction": "矩阵的2-范数是衡量其“拉伸”向量能力的一个核心指标，但它的计算并非显而易见。这个实践将引导你从第一性原理出发，通过幂迭代法设计一个算法来估算矩阵的2-范数。通过这个过程，你不仅能掌握一种核心的数值计算技术，还能深刻理解矩阵2-范数、最大奇异值以及 $A^\\top A$ 矩阵最大特征值之间的内在联系。[@problem_id:2449590]", "id": "2449590", "problem": "要求您设计并实现一个确定性程序，该程序使用基于幂迭代的算法，仅从向量和矩阵范数的基本定义以及对称矩阵特征值的基本性质出发，来估计实矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的诱导矩阵 $2$-范数 $\\lVert A \\rVert_2$。您的目标是推导、论证并编码一个算法，该算法不依赖于显式构造任何超出标准矩阵向量乘法的矩阵乘积，并且对方法阵和矩形矩阵均有效。\n\n需要完成的任务：\n1. 从诱导矩阵 $2$-范数的核心定义 $\\lVert A \\rVert_2 = \\sup_{\\mathbf{x} \\neq \\mathbf{0}} \\frac{\\lVert A \\mathbf{x} \\rVert_2}{\\lVert \\mathbf{x} \\rVert_2}$ 以及对于任何实矩阵 $A$，矩阵 $A^\\top A$ 都是对称半正定的这一事实出发，推导出一个迭代格式。该格式通过重复应用 $A \\mathbf{x}$ 和 $A^\\top \\mathbf{y}$ 形式的矩阵向量乘法来估计 $\\lVert A \\rVert_2$，而无需显式构造 $A^\\top A$。您的推导必须基于这些定义和性质，并应包含一个基于估计值变化的明确停止准则。\n2. 将推导出的算法实现为一个完整的、可运行的程序。该算法必须：\n   - 使用 $\\mathbb{R}^n$ 中的一个确定性非零向量进行初始化，在 $\\ell_2$ 意义下对其进行归一化，并在每次迭代中仅使用 $A \\mathbf{x}$ 和 $A^\\top \\mathbf{y}$ 操作。\n   - 当连续两次迭代中估计范数的相对变化小于容差 $\\varepsilon = 10^{-10}$ 时，或当达到最大迭代次数 $10^4$ 次时终止，以先发生者为准。\n   - 鲁棒地处理边界情况 $A = 0$，得出估计值 $\\lVert A \\rVert_2 = 0$。\n   - 返回 $\\lVert A \\rVert_2$ 的一个非负估计值。\n3. 您的程序必须评估以下矩阵测试套件，并按指定格式报告估计的范数：\n   - 情况 1 (方形、对称正定):\n     $$A_1 = \\begin{bmatrix} 3 & 1 \\\\ 1 & 3 \\end{bmatrix}.$$\n   - 情况 2 (方形、高度非正规):\n     $$A_2 = \\begin{bmatrix} 1 & 10 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0.1 \\end{bmatrix}.$$\n   - 情况 3 (高矩形):\n     $$A_3 = \\begin{bmatrix} 1 & 2 \\\\ 0 & 1 \\\\ 2 & 0 \\\\ 0 & 0 \\end{bmatrix}.$$\n   - 情况 4 (宽矩形):\n     $$A_4 = \\begin{bmatrix} 1 & 0 & 2 & 0 \\\\ 0 & 1 & 0 & 1 \\end{bmatrix}.$$\n   - 情况 5 (零矩阵):\n     $$A_5 = \\begin{bmatrix} 0 & 0 & 0 \\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}.$$\n   - 情况 6 (方形、具有接近的多个主导奇异值):\n     $$A_6 = \\begin{bmatrix} 1 & 0 \\\\ 0 & 0.999 \\end{bmatrix}.$$\n4. 最终输出格式：您的程序应生成单行输出，其中包含六个估计范数的结果，按 $A_1$ 到 $A_6$ 的顺序，以逗号分隔的列表形式，并用方括号括起来。每个值必须四舍五入到 $8$ 位小数。例如，一个有效的输出格式是\n   $$[\\text{v}_1,\\text{v}_2,\\text{v}_3,\\text{v}_4,\\text{v}_5,\\text{v}_6],$$\n   其中每个 $\\text{v}_i$ 是一个四舍五入到 $8$ 位的小数。不应打印额外的文本或行。\n\n实现约束：\n- 程序必须完全自包含，不需要用户输入，并且仅使用 Python 标准库和允许的库。\n- 本问题不使用角度。\n- 不涉及物理单位。", "solution": "该问题要求推导并实现一个迭代算法，以估计实矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的诱导矩阵 $2$-范数 $\\lVert A \\rVert_2$。推导过程必须基于基本原理，并避免显式构造如 $A^\\top A$ 这样的矩阵乘积。\n\n首先对问题陈述进行验证。\n\n**步骤 1：提取给定条件**\n- **定义**：诱导矩阵 $2$-范数定义为 $\\lVert A \\rVert_2 = \\sup_{\\mathbf{x} \\neq \\mathbf{0}} \\frac{\\lVert A \\mathbf{x} \\rVert_2}{\\lVert \\mathbf{x} \\rVert_2}$。\n- **性质**：对于任何实矩阵 $A$，矩阵 $A^\\top A$ 都是对称半正定的。\n- **算法目标**：推导一个仅使用 $A \\mathbf{x}$ 和 $A^\\top \\mathbf{y}$ 形式的矩阵向量乘法的迭代格式来估计 $\\lVert A \\rVert_2$。\n- **实现约束**：\n  - **初始化**：使用 $\\mathbb{R}^n$ 中的一个确定性、已归一化的非零向量。\n  - **停止准则**：当范数估计值的相对变化小于容差 $\\varepsilon = 10^{-10}$ 或达到最大迭代次数 $10^4$ 次时终止。\n  - **边界情况**：正确处理零矩阵 $A = 0$，得出估计值 $0$。\n  - **返回值**：函数必须返回 $\\lVert A \\rVert_2$ 的一个非负估计值。\n- **测试套件**：提供了六个矩阵（$A_1$ 到 $A_6$）用于评估。\n- **输出格式**：单行输出，包含六个估计范数的逗号分隔列表，四舍五入到 $8$ 位小数，并用方括号括起来。\n\n**步骤 2：使用提取的给定条件进行验证**\n1.  **有科学依据**：该问题基于诱导 $2$-范数的标准定义及其与 $A^\\top A$ 最大特征值的基本关系。所提出的方法——幂迭代，是数值线性代数中用于寻找主特征值的经典且科学上合理的算法。该问题牢固地建立在已有的数学原理之上。\n2.  **适定的**：该问题是适定的。它要求估计一个唯一定义的数学量（$\\lVert A \\rVert_2$）。算法的终止由最大迭代次数限制和收敛准则保证。\n3.  **客观的**：问题以精确、客观的数学语言陈述，没有歧义或主观陈述。\n4.  **缺陷分析**：\n    - **科学或事实上的不健全性**：无。前提是正确的。\n    - **无法形式化或不相关**：无。该问题是计算工程和数值分析中的一个标准任务，直接涉及向量和矩阵范数。\n    - **不完整或矛盾的设置**：无。所有必要组件都已指定：目标、方法约束、终止准则和测试案例。\n    - **不切实际或不可行**：无。该算法是实用的，并且测试矩阵是标准示例。\n    - **不适定或结构不良**：无。结构清晰，从理论推导到实现都有指导。\n    - **超出科学可验证性范围**：无。算法的正确性及其结果的准确性可以通过与已知的解析解或标准库函数（例如，奇异值分解）进行对比来验证。\n\n**步骤 3：结论和行动**\n该问题被判定为 **有效**。将提供一个完整的、有理有据的解决方案。\n\n**推导与算法设计**\n\n出发点是矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的诱导矩阵 $2$-范数的定义：\n$$\n\\lVert A \\rVert_2 = \\sup_{\\mathbf{x} \\in \\mathbb{R}^n, \\mathbf{x} \\neq \\mathbf{0}} \\frac{\\lVert A \\mathbf{x} \\rVert_2}{\\lVert \\mathbf{x} \\rVert_2}\n$$\n由于范数总是非负的，我们可以考虑其平方：\n$$\n\\lVert A \\rVert_2^2 = \\left( \\sup_{\\mathbf{x} \\neq \\mathbf{0}} \\frac{\\lVert A \\mathbf{x} \\rVert_2}{\\lVert \\mathbf{x} \\rVert_2} \\right)^2 = \\sup_{\\mathbf{x} \\neq \\mathbf{0}} \\frac{\\lVert A \\mathbf{x} \\rVert_2^2}{\\lVert \\mathbf{x} \\rVert_2^2}\n$$\n使用欧几里得范数的定义 $\\lVert \\mathbf{v} \\rVert_2^2 = \\mathbf{v}^\\top \\mathbf{v}$，我们可以将表达式重写为：\n$$\n\\lVert A \\rVert_2^2 = \\sup_{\\mathbf{x} \\neq \\mathbf{0}} \\frac{(A \\mathbf{x})^\\top (A \\mathbf{x})}{\\mathbf{x}^\\top \\mathbf{x}} = \\sup_{\\mathbf{x} \\neq \\mathbf{0}} \\frac{\\mathbf{x}^\\top A^\\top A \\mathbf{x}}{\\mathbf{x}^\\top \\mathbf{x}}\n$$\n该表达式是矩阵 $B = A^\\top A$ 的瑞利商。线性代数中的一个基本定理指出，对称矩阵的瑞利商的上确界是其最大特征值 $\\lambda_{\\text{max}}$。矩阵 $B = A^\\top A$ 确实是对称的（因为 $(A^\\top A)^\\top = A^\\top (A^\\top)^\\top = A^\\top A$）并且是半正定的。因此，我们得到了关键关系：\n$$\n\\lVert A \\rVert_2^2 = \\lambda_{\\text{max}}(A^\\top A)\n$$\n这意味着诱导矩阵 $2$-范数是 $A^\\top A$ 的最大特征值的平方根：\n$$\n\\lVert A \\rVert_2 = \\sqrt{\\lambda_{\\text{max}}(A^\\top A)}\n$$\n根据定义，值 $\\sqrt{\\lambda_{\\text{max}}(A^\\top A)}$ 也是 $A$ 的最大奇异值，记为 $\\sigma_1(A)$。\n\n问题现在简化为在不显式计算矩阵 $A^\\top A$ 的情况下找到 $\\lambda_{\\text{max}}(A^\\top A)$。这可以通过使用**幂迭代**法来实现。幂法是一种迭代算法，用于找到最大模的特征值（即主特征值）及其对应的特征向量。对于像 $A^\\top A$ 这样的对称半正定矩阵，所有特征值都是实数且非负，因此最大模特征值就是 $\\lambda_{\\text{max}}$。\n\n矩阵 $B$ 的标准幂迭代过程如下：\n1.  从一个非零向量 $\\mathbf{v}_0$ 开始。\n2.  对 $k = 1, 2, \\dots$ 进行迭代：$\\mathbf{v}_k = \\frac{B \\mathbf{v}_{k-1}}{\\lVert B \\mathbf{v}_{k-1} \\rVert_2}$。\n向量序列 $\\{\\mathbf{v}_k\\}$ 会收敛到对应于 $\\lambda_{\\text{max}}(B)$ 的特征向量，前提是初始向量 $\\mathbf{v}_0$ 在该特征向量方向上具有非零分量。\n\n在我们的情况中，$B = A^\\top A$。迭代步骤是 $\\mathbf{v}_k \\propto (A^\\top A) \\mathbf{v}_{k-1}$。按照要求，我们通过将乘法执行为两个连续的矩阵向量乘积来避免构造 $A^\\top A$：\n1.  首先，计算 $\\mathbf{y}_{k-1} = A \\mathbf{v}_{k-1}$。\n2.  然后，计算 $\\mathbf{x}_k = A^\\top \\mathbf{y}_{k-1}$。\n因此，核心更新是 $\\mathbf{x}_k = A^\\top (A \\mathbf{v}_{k-1})$。下一个归一化向量是 $\\mathbf{v}_k = \\mathbf{x}_k / \\lVert \\mathbf{x}_k \\rVert_2$。\n\n我们还需要在每次迭代中估计 $\\lambda_{\\text{max}}(A^\\top A)$。这可以利用当前的特征向量估计 $\\mathbf{v}_{k-1}$ 从瑞利商中获得：\n$$\n\\lambda_k \\approx \\frac{\\mathbf{v}_{k-1}^\\top (A^\\top A) \\mathbf{v}_{k-1}}{\\mathbf{v}_{k-1}^\\top \\mathbf{v}_{k-1}}\n$$\n由于 $\\mathbf{v}_{k-1}$ 是一个单位向量（$\\lVert \\mathbf{v}_{k-1} \\rVert_2 = 1$），其分母为 $1$。分子变为：\n$$\n\\mathbf{v}_{k-1}^\\top A^\\top A \\mathbf{v}_{k-1} = (A \\mathbf{v}_{k-1})^\\top (A \\mathbf{v}_{k-1}) = \\mathbf{y}_{k-1}^\\top \\mathbf{y}_{k-1} = \\lVert \\mathbf{y}_{k-1} \\rVert_2^2\n$$\n所以，在第 $k$ 次迭代中最大特征值的估计值为 $\\lambda_k = \\lVert A \\mathbf{v}_{k-1} \\rVert_2^2$。\n因此，矩阵 $2$-范数的估计值 $\\sigma_k = \\sqrt{\\lambda_k}$ 就简化为：\n$$\n\\sigma_k = \\lVert A \\mathbf{v}_{k-1} \\rVert_2 = \\lVert \\mathbf{y}_{k-1} \\rVert_2\n$$\n这提供了一种在每次迭代中更新范数估计值的简单而高效的方法。\n\n**最终算法：**\n设 $A$ 是一个 $m \\times n$ 的矩阵。设容差 $\\varepsilon = 10^{-10}$，最大迭代次数 $K_{\\text{max}} = 10^4$。\n\n1.  **处理平凡情况**：如果 $n=0$，则定义域为空，因此 $\\lVert A \\rVert_2 = 0$。\n2.  **初始化**：\n    - 选择一个确定性的非零起始向量 $\\mathbf{v}_0 \\in \\mathbb{R}^n$。一个标准的选择是全一向量。\n    - 将其归一化：$\\mathbf{v} \\leftarrow \\frac{\\mathbf{v}_0}{\\lVert \\mathbf{v}_0 \\rVert_2}$。\n    - 初始化范数估计值，例如 $\\sigma_{\\text{new}} \\leftarrow 0$。\n3.  **迭代**：对 $k=1, \\dots, K_{\\text{max}}$：\n    a.  存储上一次的估计值：$\\sigma_{\\text{old}} \\leftarrow \\sigma_{\\text{new}}$。\n    b.  应用第一次矩阵向量乘法：$\\mathbf{y} \\leftarrow A \\mathbf{v}$。\n    c.  更新范数估计值：$\\sigma_{\\text{new}} \\leftarrow \\lVert \\mathbf{y} \\rVert_2$。\n    d.  **检查收敛性**：如果 $k>1$ 且 $|\\sigma_{\\text{new}} - \\sigma_{\\text{old}}| < \\varepsilon \\cdot \\sigma_{\\text{new}}$，则跳出循环。\n    e.  **处理零矩阵情况**：如果 $\\sigma_{\\text{new}} = 0$，这意味着 $\\mathbf{y}=\\mathbf{0}$。即 $A\\mathbf{v}=\\mathbf{0}$。该矩阵可能是奇异的，或者是零矩阵。算法正确地得出 $\\sigma_{\\text{new}} = 0$ 并应终止。我们可以跳出循环。\n    f. 应用第二次矩阵向量乘法：$\\mathbf{x} \\leftarrow A^\\top \\mathbf{y}$。\n    g.  将结果向量归一化用于下一次迭代：$\\mathbf{v} \\leftarrow \\frac{\\mathbf{x}}{\\lVert \\mathbf{x} \\rVert_2}$。如果 $\\lVert \\mathbf{x} \\rVert_2 = 0$，则跳出循环。这种情况发生在 $\\mathbf{y}$ 处于 $A^\\top$ 的零空间中，对于 $\\mathbf{y}=A\\mathbf{v}$ 这意味着 $A\\mathbf{v}=\\mathbf{0}$，从而正确地得到范数为 $0$。\n4.  **返回**：最终估计值 $\\sigma_{\\text{new}}$。\n\n该算法仅使用矩阵向量乘法，遵守所有约束，并能正确估计 $\\lVert A \\rVert_2$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef estimate_induced_2_norm(A, tol=1e-10, max_iter=10000):\n    \"\"\"\n    Estimates the induced matrix 2-norm (largest singular value) of a real matrix A\n    using the power iteration method.\n\n    The algorithm iteratively computes v_k = A^T * A * v_{k-1} without explicitly\n    forming the matrix A^T*A. The norm is estimated as ||A*v_k||_2.\n\n    Args:\n        A (np.ndarray): The input matrix, m x n.\n        tol (float): The relative tolerance for convergence.\n        max_iter (int): The maximum number of iterations.\n\n    Returns:\n        float: The estimated induced 2-norm of A.\n    \"\"\"\n    # Get matrix dimensions\n    m, n = A.shape\n\n    # Handle the edge case of a matrix with zero columns.\n    if n == 0:\n        return 0.0\n\n    # Initialize with a deterministic non-zero vector in R^n.\n    # A vector of ones is a standard deterministic choice.\n    # The power method might fail if this initial vector is orthogonal\n    # to the dominant eigenvector of A^T*A. In practice, for general\n    # matrices and with finite-precision arithmetic, this is rare.\n    v = np.ones(n)\n    v /= np.linalg.norm(v)\n\n    norm_est = 0.0\n\n    for _ in range(max_iter):\n        norm_est_prev = norm_est\n\n        # First matrix-vector product: y = A*v\n        y = A @ v\n\n        # Update the norm estimate: ||A||_2 approx ||y||_2\n        norm_est = np.linalg.norm(y)\n\n        # Check for convergence using relative change.\n        # This check is safe because for a non-zero matrix, norm_est converges\n        # to a positive value.\n        if norm_est > 0 and abs(norm_est - norm_est_prev) < tol * norm_est:\n            break\n        \n        # Handle the case where A is the zero matrix or v is in the null space of A.\n        if norm_est == 0:\n            return 0.0\n\n        # Second matrix-vector product: x = A^T*y\n        x = A.T @ y\n        \n        # Normalize the vector for the next iteration.\n        norm_x = np.linalg.norm(x)\n\n        # If norm_x is zero, the iteration has converged to the null space.\n        if norm_x == 0:\n            break\n            \n        v = x / norm_x\n\n    return norm_est\n\n\ndef solve():\n    \"\"\"\n    Defines the test cases, runs the norm estimation, and prints the results.\n    \"\"\"\n    \n    A1 = np.array([[3.0, 1.0], \n                   [1.0, 3.0]])\n\n    A2 = np.array([[1.0, 10.0, 0.0],\n                   [0.0, 1.0, 0.0],\n                   [0.0, 0.0, 0.1]])\n\n    A3 = np.array([[1.0, 2.0],\n                   [0.0, 1.0],\n                   [2.0, 0.0],\n                   [0.0, 0.0]])\n\n    A4 = np.array([[1.0, 0.0, 2.0, 0.0],\n                   [0.0, 1.0, 0.0, 1.0]])\n\n    A5 = np.array([[0.0, 0.0, 0.0],\n                   [0.0, 0.0, 0.0],\n                   [0.0, 0.0, 0.0]])\n\n    A6 = np.array([[1.0, 0.0],\n                   [0.0, 0.999]])\n                   \n    test_cases = [A1, A2, A3, A4, A5, A6]\n\n    results = []\n    for A in test_cases:\n        norm_estimate = estimate_induced_2_norm(A, tol=1e-10, max_iter=10000)\n        results.append(f\"{norm_estimate:.8f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"}, {"introduction": "在金融和经济分析中，我们常常需要从复杂的多变量数据中提取最关键的驱动因素。这个练习将矩阵范数（特别是弗罗贝尼乌斯范数）用作一个强大的工具，通过寻找一个给定资产回报矩阵的最佳秩一近似，来构建一个单因子金融模型。这个过程将奇异值分解（SVD）的理论与实际的降维和模型解释问题联系起来，让你亲身体验如何用数学工具简化并理解复杂的金融现象。[@problem_id:2447261]", "id": "2447261", "problem": "考虑一个资产收益矩阵 $R \\in \\mathbb{R}^{n \\times T}$，其中行对应 $n$ 个资产，列对应 $T$ 个时间周期。所有收益都以小数形式表示（例如，条目 $0.01$ 表示 $0.01$ 的小数形式收益）。矩阵 $A$ 的弗罗贝尼乌斯范数定义为 $\\lVert A \\rVert_{F} = \\sqrt{\\sum_{i,j} A_{ij}^{2}}$。在弗罗贝尼乌斯范数下，与 $R$ 最接近的秩为1的矩阵是求解以下问题的任意矩阵 $X$\n$$\n\\min_{X \\in \\mathbb{R}^{n \\times T}} \\ \\lVert R - X \\rVert_{F} \\quad \\text{subject to} \\quad \\operatorname{rank}(X) \\le 1.\n$$\n任何秩为1的矩阵都可以写成 $X = b f^{\\top}$ 的形式，其中 $b \\in \\mathbb{R}^{n}$ 且 $f \\in \\mathbb{R}^{T}$。在单因子金融模型的背景下，$b$ 可以解释为资产载荷向量，$f$ 可以解释为因子收益时间序列。为了使 $(b,f)$ 唯一，我们施加归一化条件 $\\lVert f \\rVert_{2} = 1$ 以及符号约定，即 $f$ 的第一个非零条目为非负数。如果 $R$ 是零矩阵（所有条目均为 $0$），则定义 $b$ 为 $\\mathbb{R}^{n}$ 中的零向量，$f$ 为 $\\mathbb{R}^{T}$ 中的第一个标准基向量。\n\n对于下方的每个测试用例，执行以下操作：\n- 在上述归一化和符号约定下，计算弗罗贝尼乌斯范数下与 $R$ 最接近的秩为1的矩阵 $R_{1}$，表示为 $R_{1} = b f^{\\top}$。\n- 计算残差弗罗贝尼乌斯范数 $\\lVert R - R_{1} \\rVert_{F}$。\n- 计算 $R_{1}$ 所解释的方差份额 $s$ 为\n$$\ns = \\begin{cases}\n\\frac{\\lVert R_{1} \\rVert_{F}^{2}}{\\lVert R \\rVert_{F}^{2}}, & \\text{if } \\lVert R \\rVert_{F} \\ne 0, \\\\\n0, & \\text{if } \\lVert R \\rVert_{F} = 0.\n\\end{cases}\n$$\n\n将每个数值输出四舍五入到六位小数。对于每个测试用例，输出一个单一列表\n$$\n[\\ \\lVert R - R_{1} \\rVert_{F},\\ s,\\ b_{1},\\ldots,b_{n},\\ f_{1},\\ldots,f_{T}\\ ],\n$$\n其中 $b_{i}$ 是 $b$ 的条目，$f_{j}$ 是 $f$ 的条目。您的程序应生成单行输出，其中包含所有测试用例的结果，形式为这些单个测试用例列表的逗号分隔列表，并包含在一对方括号内。\n\n测试套件：\n- 测试用例 1（一般情况，带有小噪声的秩为1结构）。令 $R \\in \\mathbb{R}^{3 \\times 4}$ 为\n$$\nR = \\begin{bmatrix}\n0.006 & -0.0105 & 0.0078 & -0.0002 \\\\\n-0.0023 & 0.0044 & -0.0031 & 0.0002 \\\\\n0.0012 & -0.0021 & 0.002 & -0.0003\n\\end{bmatrix}.\n$$\n- 测试用例 2（边界情况，零矩阵）。令 $R \\in \\mathbb{R}^{2 \\times 3}$ 为\n$$\nR = \\begin{bmatrix}\n0 & 0 & 0 \\\\\n0 & 0 & 0\n\\end{bmatrix}.\n$$\n- 测试用例 3（精确秩为1的情况）。令 $R \\in \\mathbb{R}^{4 \\times 3}$ 为\n$$\nR = \\begin{bmatrix}\n0.0006 & -0.0003 & 0.00015 \\\\\n0.0002 & -0.0001 & 0.00005 \\\\\n-0.0004 & 0.0002 & -0.0001 \\\\\n0 & 0 & 0\n\\end{bmatrix}.\n$$\n\n最终输出格式：\n- 单行输出，包含一个含三个项目（每个测试用例一个）的列表，其中每个项目是上面描述的列表。例如，该行应如下所示\n$$\n[ [\\ \\cdots\\ ],[\\ \\cdots\\ ],[\\ \\cdots\\ ] ].\n$$\n所有数字必须四舍五入到六位小数，并且收益必须作为小数（而非百分比）处理。", "solution": "该问题要求找到给定资产收益矩阵 $R \\in \\mathbb{R}^{n \\times T}$ 的最近似秩-1逼近，并计算相关的金融度量。这是线性代数中的一个经典问题，其解由 Eckart-Young-Mirsky 定理给出。该定理指出，矩阵 $R$ 在弗罗贝尼乌斯范数下的最佳秩-k逼近由截断的奇异值分解（SVD）给出。\n\n首先，我们将矩阵 $R$ 的 SVD 定义为：\n$$\nR = U \\Sigma V^{\\top}\n$$\n其中 $U \\in \\mathbb{R}^{n \\times n}$ 和 $V \\in \\mathbb{R}^{T \\times T}$ 是正交矩阵（$U^{\\top}U = I_n$, $V^{\\top}V = I_T$），$\\Sigma \\in \\mathbb{R}^{n \\times T}$ 是一个包含按非增顺序排列的奇异值 $\\sigma_i$ 的矩形对角矩阵：$\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_{\\min(n,T)} \\ge 0$。$U$ 的列，表示为 $u_i$，是左奇异向量；$V$ 的列，表示为 $v_i$，是右奇异向量。\n\nEckart-Young-Mirsky 定理明确指出，最小化问题\n$$\n\\min_{X} \\lVert R - X \\rVert_{F} \\quad \\text{subject to} \\quad \\operatorname{rank}(X) \\le 1\n$$\n的解是由最大奇异值 $\\sigma_1$ 及其对应的奇异向量 $u_1$ 和 $v_1$ 构造的矩阵 $R_1$：\n$$\nR_1 = \\sigma_1 u_1 v_1^{\\top}\n$$\n这个矩阵 $R_1$ 是 $R$ 的最近似秩-1逼近。\n\n问题要求我们将 $R_1$ 表示为单因子模型的形式，$R_1 = b f^{\\top}$，其中 $b \\in \\mathbb{R}^{n}$ 是资产载荷向量，$f \\in \\mathbb{R}^{T}$ 是因子收益时间序列。为确保表示的唯一性，施加了两个条件：\n1. 归一化：因子时间序列的欧几里得范数必须为1，即 $\\lVert f \\rVert_2 = 1$。\n2. 符号约定：$f$ 的第一个非零条目必须为非负数。\n\n我们可以将 SVD 分量与因子 $b$ 和 $f$ 联系起来。由 $R_1 = \\sigma_1 u_1 v_1^{\\top}$ 和 $R_1 = b f^{\\top}$，并且知道 SVD 的奇异向量已经是归一化的（$\\lVert u_1 \\rVert_2 = 1$，$\\lVert v_1 \\rVert_2 = 1$），我们可以做出如下识别：\n$$\nf \\propto v_1 \\quad \\text{and} \\quad b \\propto u_1\n$$\n为满足归一化条件 $\\lVert f \\rVert_2 = 1$，我们可以设置 $f = v_1$ 和 $b = \\sigma_1 u_1$。然而，SVD 分量 $(u_1, v_1)$ 的唯一性仅在同时改变符号的情况下成立，即 $(u_1, v_1)$ 和 $(-u_1, -v_1)$ 都产生相同的矩阵 $R_1$。我们必须使用符号约定来解决这种模糊性。\n\n我们定义一个临时因子向量 $f_{\\text{temp}} = v_1$。我们找到 $f_{\\text{temp}}$ 的第一个非零元素。如果此元素为负，我们必须翻转两个向量的符号。我们定义一个符号乘数 $\\alpha \\in \\{-1, 1\\}$。\n$$\n\\alpha = \\begin{cases}\n-1 & \\text{如果 } v_1 \\text{ 的第一个非零元素为负} \\\\\n+1 & \\text{否则}\n\\end{cases}\n$$\n唯一的因子则由以下方式给出：\n$$\nf = \\alpha v_1\n$$\n$$\nb = \\alpha \\sigma_1 u_1\n$$\n这个构造满足 $R_1 = b f^{\\top} = (\\alpha \\sigma_1 u_1)(\\alpha v_1)^{\\top} = \\alpha^2 \\sigma_1 u_1 v_1^{\\top} = \\sigma_1 u_1 v_1^{\\top}$，以及 $\\lVert f \\rVert_2 = \\lVert \\alpha v_1 \\rVert_2 = |\\alpha|\\lVert v_1 \\rVert_2=1$，并符合 $f$ 的符号约定。\n\n问题为零矩阵 $R=0_{n \\times T}$ 指定了一个特殊情况。在这种情况下，所有奇异值都为零。问题明确定义 $b$ 为 $\\mathbb{R}^n$ 中的零向量，$f$ 为 $\\mathbb{R}^T$ 中的第一个标准基向量，即 $f = e_1 = [1, 0, \\dots, 0]^{\\top}$。这得到 $R_1=0 \\cdot e_1^\\top = 0$。\n\n接下来，我们计算所需的度量：\n1. 残差弗罗贝尼乌斯范数 $\\lVert R - R_{1} \\rVert_{F}$。SVD 的性质表明，矩阵的弗罗贝尼乌斯范数的平方是其奇异值平方的和：$\\lVert R \\rVert_{F}^{2} = \\sum_i \\sigma_i^2$。秩-1逼近的误差是 SVD 和中剩余部分的弗罗贝尼乌斯范数。\n$$\n\\lVert R - R_{1} \\rVert_{F} = \\left\\lVert \\left(\\sum_{i=1}^{\\min(n,T)} \\sigma_i u_i v_i^{\\top}\\right) - \\sigma_1 u_1 v_1^{\\top} \\right\\rVert_{F} = \\left\\lVert \\sum_{i=2}^{\\min(n,T)} \\sigma_i u_i v_i^{\\top} \\right\\rVert_{F}\n$$\n由于奇异向量的正交性，这可以简化为：\n$$\n\\lVert R - R_{1} \\rVert_{F} = \\sqrt{\\sum_{i=2}^{\\min(n,T)} \\sigma_i^2} = \\sqrt{\\lVert R \\rVert_F^2 - \\sigma_1^2}\n$$\n对于一个精确秩为1的矩阵 $R$，除 $\\sigma_1$ 外的所有奇异值都为零，因此残差范数为 $0$。\n\n2. 方差解释份额 $s$。 这是逼近方差与原始数据方差的比率。\n$$\ns = \\frac{\\lVert R_{1} \\rVert_{F}^{2}}{\\lVert R \\rVert_{F}^{2}}\n$$\n我们知道 $\\lVert R \\rVert_F^2 = \\sum_i \\sigma_i^2$。逼近的范数是 $\\lVert R_1 \\rVert_F = \\lVert \\sigma_1 u_1 v_1^{\\top} \\rVert_F = \\sigma_1$。因此，$\\lVert R_1 \\rVert_F^2 = \\sigma_1^2$。解释的份额是：\n$$\ns = \\frac{\\sigma_1^2}{\\sum_i \\sigma_i^2}\n$$\n如果 $R$ 是零矩阵，则 $\\lVert R \\rVert_F = 0$，并且问题定义 $s=0$。\n\n总体算法如下：\n1. 对于给定的矩阵 $R$，首先检查它是否为零矩阵。如果是，则使用为 $b$ 和 $f$ 提供的定义，并计算 $\\lVert R - R_1 \\rVert_F = 0$ 和 $s=0$。\n2. 如果 $R$ 不是零矩阵，计算其SVD以找到 $\\sigma_i$、$u_1$ 和 $v_1$。\n3. 对 $v_1$ 应用符号约定以确定符号乘数 $\\alpha$。\n4. 计算 $b = \\alpha \\sigma_1 u_1$ 和 $f = \\alpha v_1$。\n5. 计算残差范数 $\\lVert R - R_{1} \\rVert_{F} = \\sqrt{\\sum_{i \\ge 2} \\sigma_i^2}$。\n6. 计算解释的份额 $s = \\sigma_1^2 / (\\sum_i \\sigma_i^2)$。\n7. 将所有数值结果整理到一个列表中，每个数字都四舍五入到六位小数。\n\n此过程将应用于每个测试用例。", "answer": "```python\nimport numpy as np\n\ndef solve_case(R):\n    \"\"\"\n    Computes the rank-1 approximation and related metrics for a given matrix R.\n\n    Args:\n        R (np.ndarray): The input matrix.\n\n    Returns:\n        list: A list containing the residual norm, explained share, \n              factor loadings (b), and factor returns (f).\n    \"\"\"\n    n, T = R.shape\n    \n    # Handle the boundary case of a zero matrix\n    if np.allclose(R, 0):\n        residual_norm = 0.0\n        explained_share = 0.0\n        b = np.zeros(n)\n        f = np.zeros(T)\n        f[0] = 1.0\n        \n        result_list = [residual_norm, explained_share] + b.tolist() + f.tolist()\n        return [np.round(x, 6) for x in result_list]\n\n    # Compute the full SVD\n    # Use full_matrices=False for efficiency\n    U, s_vals, Vh = np.linalg.svd(R, full_matrices=False)\n    \n    # Extract the components for the rank-1 approximation\n    sigma1 = s_vals[0]\n    u1 = U[:, 0]\n    v1 = Vh[0, :]\n    \n    # Apply sign convention: first non-zero entry of f must be non-negative\n    # Find the index of the first non-zero element with a small tolerance\n    try:\n        first_nonzero_idx = np.nonzero(np.abs(v1) > 1e-12)[0][0]\n        sign_multiplier = np.sign(v1[first_nonzero_idx])\n        # A sign of 0 can occur if the value is extremely small. Default to 1.\n        if sign_multiplier == 0:\n            sign_multiplier = 1.0\n    except IndexError:\n        # This case (v1 is all zeros) should not happen if R is not a zero matrix.\n        sign_multiplier = 1.0\n        \n    f = v1 * sign_multiplier\n    b = u1 * sigma1 * sign_multiplier\n    \n    # Compute the residual Frobenius norm\n    R_norm_fro_sq = np.sum(s_vals**2)\n    residual_norm_sq = R_norm_fro_sq - sigma1**2\n    # Clamp to zero to avoid negative due to floating point inaccuracies\n    residual_norm = np.sqrt(max(0, residual_norm_sq))\n    \n    # Compute the explained share of variation\n    if R_norm_fro_sq == 0:\n        explained_share = 0.0\n    else:\n        explained_share = sigma1**2 / R_norm_fro_sq\n    \n    # Assemble the final list of results\n    result_list = [residual_norm, explained_share] + b.tolist() + f.tolist()\n    \n    # Round all numerical outputs to six decimal places\n    rounded_results = [np.round(x, 6) for x in result_list]\n    \n    return rounded_results\n\ndef solve():\n    \"\"\"\n    Defines test cases and solves them, printing the final output.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1: general case\n        np.array([\n            [0.006, -0.0105, 0.0078, -0.0002],\n            [-0.0023, 0.0044, -0.0031, 0.0002],\n            [0.0012, -0.0021, 0.002, -0.0003]\n        ]),\n        # Test Case 2: boundary case (zero matrix)\n        np.array([\n            [0.0, 0.0, 0.0],\n            [0.0, 0.0, 0.0]\n        ]),\n        # Test Case 3: exact rank-1 case\n        np.array([\n            [0.0006, -0.0003, 0.00015],\n            [0.0002, -0.0001, 0.00005],\n            [-0.0004, 0.0002, -0.0001],\n            [0.0, 0.0, 0.0]\n        ])\n    ]\n\n    all_results = []\n    for R in test_cases:\n        all_results.append(solve_case(R))\n    \n    # Format the final output string as a list of lists.\n    # Convert rounded numbers to strings to ensure proper formatting e.g., '0.0'\n    outer_list = []\n    for res_list in all_results:\n        # Format each number to 6 decimal places, handling -0.0 cases.\n        formatted_list = [f\"{x:.6f}\" if x == 0.0 else str(x) for x in res_list]\n        inner_list_str = '[' + ','.join(formatted_list) + ']'\n        outer_list.append(inner_list_str)\n    \n    final_output_str = '[' + ','.join(outer_list) + ']'\n    \n    print(final_output_str)\n\nsolve()\n```"}, {"introduction": "在求解经济模型中无处不在的线性方程组 $Ax=b$ 时，我们不仅关心解的存在性，更关心解的稳定性。这个数值实验旨在揭示一个关键概念：矩阵的“病态”程度如何影响解的精度。你将通过计算一个“误差放大系数”，亲眼见证一个微小的输入误差（例如，在经济数据 $b$ 中的测量误差）是如何被一个病态矩阵 $A$ 放大，从而导致解 $x$ 产生巨大偏差的。这项实践对于培养在计算工作中对数值稳定性的警觉性至关重要。[@problem_id:2449583]", "id": "2449583", "problem": "设计并实现一个完整的、可运行的程序，通过一个数值实验来证明：对于一个病态矩阵 $A$，向量 $b$ 中的微小相对误差可能导致线性方程组 $A x = b$ 的解 $x$ 出现巨大的相对误差。该实验必须严格基于基本原理：范数、相对误差和线性求解的定义。所有量必须使用向量和矩阵的 $2$-范数。对于每个指定的测试用例，程序必须计算定义如下的放大因子 $r$\n$$\nr \\;=\\; \\frac{\\|x_{\\epsilon} - x^\\star\\|_{2} / \\|x^\\star\\|_{2}}{\\|\\delta b\\|_{2} / \\|b\\|_{2}},\n$$\n其中，$x^\\star$ 是对应于未受扰动右端项 $b$ 的精确解，$\\delta b$ 是 $b$ 的一个扰动，$x_{\\epsilon}$ 是 $A x = b + \\delta b$ 的解。对于每个测试用例，程序必须使用以下实验设置：\n- 设 $x^\\star$ 为 $\\mathbb{R}^n$ 中的向量，其所有分量均为 $1$。\n- 设 $b = A x^\\star$。\n- 设扰动方向 $v \\in \\mathbb{R}^n$ 的分量定义为 $v_i = \\frac{(-1)^{i-1}}{\\sqrt{n}}$，其中 $i = 1, \\dots, n$，因此 $\\|v\\|_2 = 1$。\n- 设 $\\delta b = \\epsilon \\, \\|b\\|_2 \\, v$，其中 $\\epsilon$ 是为该测试规定的相对扰动大小。\n- 设 $x_{\\epsilon}$ 是 $A x = b + \\delta b$ 的解。\n\n您的程序必须为每个测试用例计算放大因子 $r$（一个浮点数）。测试用例集如下，每个用例均由其编号标识，并按所列顺序执行：\n- 用例 1：$A$ 是 Hilbert 矩阵 $H \\in \\mathbb{R}^{5 \\times 5}$，其元素为 $H_{ij} = \\frac{1}{i + j - 1}$，其中 $i, j \\in \\{1,\\dots,5\\}$，且 $\\epsilon = 10^{-8}$。\n- 用例 2：$A$ 是 Hilbert 矩阵 $H \\in \\mathbb{R}^{10 \\times 10}$，其元素为 $H_{ij} = \\frac{1}{i + j - 1}$，其中 $i, j \\in \\{1,\\dots,10\\}$，且 $\\epsilon = 10^{-8}$。\n- 用例 3：$A$ 是单位矩阵 $I \\in \\mathbb{R}^{8 \\times 8}$，且 $\\epsilon = 10^{-8}$。\n- 用例 4：$A \\in \\mathbb{R}^{2 \\times 2}$ 由下式给出\n$$\nA = \\begin{bmatrix}\n1 & 1 \\\\\n1 & 1 + 10^{-10}\n\\end{bmatrix},\n$$\n且 $\\epsilon = 10^{-12}$。\n\n所有范数都必须是 $2$-范数。不涉及物理单位。不使用角度。不得使用百分比；所有比率和大小都必须表示为十进制浮点数。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[r1,r2,r3,r4]”）。每个条目必须是对应测试用例的放大因子 $r$，四舍五入到 6 位有效数字，并按用例 1 到 4 的顺序排列。", "solution": "该实验是根据线性代数的基本原理和基于范数的误差分析来设计的。我们考虑一个具有精确数据的线性系统 $A x = b$ 及其扰动后的对应系统 $A x = b + \\delta b$。对于给定的矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 和一个精确解向量 $x^\\star \\in \\mathbb{R}^n$，我们定义 $b = A x^\\star$。然后，我们按如下方式构建一个具有指定相对大小 $\\epsilon$ 的扰动 $\\delta b$。设 $v \\in \\mathbb{R}^n$ 的分量为 $v_i = \\frac{(-1)^{i-1}}{\\sqrt{n}}$，其中 $i = 1, \\dots, n$。根据构造，这个 $v$ 满足 $\\|v\\|_2 = 1$：\n$$\n\\|v\\|_2^2 = \\sum_{i=1}^n \\left(\\frac{1}{\\sqrt{n}}\\right)^2 = \\frac{n}{n} = 1.\n$$\n我们设 $\\delta b = \\epsilon \\, \\|b\\|_2 \\, v$。那么 $b$ 中的相对扰动恰好为 $\\frac{\\|\\delta b\\|_2}{\\|b\\|_2} = \\epsilon$，因为\n$$\n\\|\\delta b\\|_2 = \\epsilon \\, \\|b\\|_2 \\, \\|v\\|_2 = \\epsilon \\, \\|b\\|_2.\n$$\n设 $x_\\epsilon$ 表示扰动系统 $A x = b + \\delta b$ 的解。解的误差为\n$$\nx_\\epsilon - x^\\star = A^{-1}\\,(b+\\delta b) - A^{-1} b = A^{-1}\\,\\delta b.\n$$\n因此，$x$ 的相对误差为\n$$\n\\frac{\\|x_\\epsilon - x^\\star\\|_2}{\\|x^\\star\\|_2} = \\frac{\\|A^{-1}\\,\\delta b\\|_2}{\\|x^\\star\\|_2}.\n$$\n程序为每个用例报告的放大因子 $r$ 为\n$$\nr = \\frac{\\|x_{\\epsilon} - x^\\star\\|_{2} / \\|x^\\star\\|_{2}}{\\|\\delta b\\|_{2} / \\|b\\|_{2}}.\n$$\n根据范数性质和矩阵 $2$-范数的定义，我们可以将此放大作用与矩阵 $2$-范数下的条件数 $\\kappa_2(A) = \\|A\\|_2 \\, \\|A^{-1}\\|_2$ 联系起来。具体来说，使用 $\\|A^{-1} \\delta b\\|_2 \\le \\|A^{-1}\\|_2 \\, \\|\\delta b\\|_2$ 和 $\\|b\\|_2 = \\|A x^\\star\\|_2 \\le \\|A\\|_2 \\, \\|x^\\star\\|_2$，我们得到\n$$\n\\frac{\\|x_\\epsilon - x^\\star\\|_2}{\\|x^\\star\\|_2} \\le \\|A^{-1}\\|_2 \\, \\|\\delta b\\|_2 \\,\\frac{1}{\\|x^\\star\\|_2}\n\\le \\|A^{-1}\\|_2 \\, \\|A\\|_2 \\, \\frac{\\|\\delta b\\|_2}{\\|b\\|_2} = \\kappa_2(A) \\, \\frac{\\|\\delta b\\|_2}{\\|b\\|_2}.\n$$\n因此\n$$\nr \\le \\kappa_2(A).\n$$\n这个不等式表明，解的相对误差最大可被放大到约等于条件数的大小。对于良态矩阵，如单位矩阵 $I$，我们有 $\\kappa_2(I) = 1$，因此 $r$ 应当接近于 $1$。对于病态矩阵，如 Hilbert 矩阵，其 $\\kappa_2(A)$ 非常大，即使一个很小的 $\\epsilon$ 也可能导致 $x$ 中出现一个巨大的相对误差，从而产生一个很大的 $r$。\n\n该测试套件涵盖了以下几种情况：\n- 用例 1 使用一个尺寸为 5 的 Hilbert 矩阵，该矩阵是病态的，但尺寸适中。\n- 用例 2 使用一个尺寸为 10 的 Hilbert 矩阵，该矩阵病态程度更高，通常会产生更大的放大因子 $r$。\n- 用例 3 使用一个尺寸为 8 的单位矩阵，该矩阵是完美条件的，因此 $r$ 应约等于 1。\n- 用例 4 使用一个近奇异的 $2 \\times 2$ 矩阵，其一个元素的值相差 $10^{-10}$，这会产生非常大的放大作用。\n\n对于每个用例，程序构建 $x^\\star$、$b$、单位范数扰动方向 $v$、使用指定 $\\epsilon$ 的扰动 $\\delta b$，求解 $x_\\epsilon$，计算相对误差，并报告四舍五入到 6 位有效数字的 $r$。最终输出为一行，按顺序包含列表 $[r_1, r_2, r_3, r_4]$。这个过程直接且清晰地展示了 $A$ 的病态性如何将 $b$ 中的微小相对扰动放大为解 $x$ 中的巨大相对误差。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef hilbert(n: int) -> np.ndarray:\n    # H[i,j] = 1 / (i + j + 1) with zero-based i,j; but use one-based formula directly\n    i = np.arange(1, n + 1).reshape(-1, 1)\n    j = np.arange(1, n + 1).reshape(1, -1)\n    return 1.0 / (i + j - 1.0)\n\ndef alternating_unit_vector(n: int) -> np.ndarray:\n    # v_i = (-1)^(i-1) / sqrt(n), i = 1..n\n    signs = (-1.0) ** np.arange(n)\n    v = signs / np.sqrt(n)\n    # Ensure unit norm numerically\n    return v / np.linalg.norm(v, 2)\n\ndef amplification_factor(A: np.ndarray, eps: float) -> float:\n    n = A.shape[0]\n    x_star = np.ones(n, dtype=float)\n    b = A @ x_star\n    nb = np.linalg.norm(b, 2)\n    if nb == 0.0:\n        # Degenerate, but not expected with provided tests; return NaN-like large value\n        return float('nan')\n    v = alternating_unit_vector(n)\n    delta_b = eps * nb * v\n    b_tilde = b + delta_b\n    # Solve for perturbed solution\n    x_tilde = np.linalg.solve(A, b_tilde)\n    # Relative errors\n    rel_b = np.linalg.norm(delta_b, 2) / nb\n    rel_x = np.linalg.norm(x_tilde - x_star, 2) / np.linalg.norm(x_star, 2)\n    # Amplification factor\n    return rel_x / rel_b\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case is a tuple: (A_matrix, epsilon)\n    A1 = hilbert(5)\n    eps1 = 1e-8\n\n    A2 = hilbert(10)\n    eps2 = 1e-8\n\n    A3 = np.eye(8, dtype=float)\n    eps3 = 1e-8\n\n    A4 = np.array([[1.0, 1.0],\n                   [1.0, 1.0 + 1e-10]], dtype=float)\n    eps4 = 1e-12\n\n    test_cases = [\n        (A1, eps1),\n        (A2, eps2),\n        (A3, eps3),\n        (A4, eps4),\n    ]\n\n    results = []\n    for A, eps in test_cases:\n        r = amplification_factor(A, eps)\n        # Round to 6 significant digits\n        if np.isnan(r) or np.isinf(r):\n            results.append(\"nan\")\n        else:\n            results.append(f\"{r:.6g}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"}]}