{"hands_on_practices": [{"introduction": "中心极限定理是概率论的基石，它揭示了大量独立随机变量之和的分布会趋向于正态分布。本练习将通过一个直观的多项选择测试模型，模拟学生得分的累积过程，让你亲手验证伯努利试验之和如何汇聚成经典的钟形曲线。通过计算标准化得分与标准正态分布之间的柯尔莫可洛夫-斯米尔诺夫（Kolmogorov-Smirnov）距离，你将学会一种量化评估CLT近似效果的重要方法。[@problem_id:2405591]", "id": "2405591", "problem": "考虑一个理想化的多项选择测试环境。一名学生回答一份包含 $Q$ 个独立问题的试卷。每个问题提供 $c$ 个选项，其中只有一个是正确的。对于每个问题，学生或者以概率 $k$ 知道答案（这种情况下，选择正确答案的概率为 $1$），或者以概率 $1-k$ 不知道答案（这种情况下，学生在 $c$ 个选项中均匀猜测，选择正确答案的概率为 $1/c$）。设 $X_i$ 为问题 $i$ 回答正确的指示变量，其中 $i \\in \\{1,\\dots,Q\\}$。正确答案的总数（即测试得分）为 $S_Q = \\sum_{i=1}^{Q} X_i$。对于每个固定的三元组 $(Q,c,k)$，每个问题的正确概率为 $p = k + (1-k)/c$，因此 $X_i$ 是参数为 $p$ 的独立同分布的伯努利随机变量。定义标准化分数为 $Z_Q = \\dfrac{S_Q - Q p}{\\sqrt{Q p (1-p)}}$。\n\n根据中心极限定理 (CLT)，当 $Q \\to \\infty$ 时，$Z_Q$ 的分布近似于标准正态分布。您的任务是执行一次蒙特卡洛计算，通过使用 Kolmogorov–Smirnov (KS) 距离比较 $Z_Q$ 的经验分布与标准正态分布，来评估在有限样本中此近似的准确性。\n\n对于下面列出的每个测试用例，您必须：\n- 根据上述模型，生成 $N$ 个独立的 $S_Q$ 抽样，每个测试用例的抽样数量为 $N = 80000$。\n- 对所有随机数生成过程使用固定的随机种子 $20240517$，以确保所有测试用例之间的结果具有可复现性。\n- 根据模拟的 $S_Q$ 抽样计算标准化分数 $Z_Q$ 的经验累积分布函数 (empirical CDF) $F_N$。\n- 计算 Kolmogorov–Smirnov 距离 $D_N = \\sup_{x \\in \\mathbb{R}} \\left| F_N(x) - \\Phi(x) \\right|$，其中 $\\Phi$ 是标准正态累积分布函数。\n\n为每个测试用例报告一个实数，即上面定义的 $D_N$ 值。所有报告的数值输出均以十进制形式表示（不使用任何百分比符号）。\n\n参数值测试套件：\n- 用例 1（一般情况）：$(Q,c,k) = (100,4,0.6)$。\n- 用例 2（小聚合边界）：$(Q,c,k) = (5,4,0.6)$。\n- 用例 3（对称成功概率，大聚合）：$(Q,c,k) = (400,2,0.0)$。\n- 用例 4（稀有成功概率，大聚合）：$(Q,c,k) = (400,20,0.0)$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含四个用例的结果，按顺序以逗号分隔的列表形式，并用方括号括起来。例如 $[d_1,d_2,d_3,d_4]$，其中每个 $d_j$ 是用例 $j \\in \\{1,2,3,4\\}$ 计算出的 Kolmogorov–Smirnov 距离 $D_N$。", "solution": "问题陈述已经过严格验证，并被认为是合理的。这是一个计算统计学中定义明确的问题，其基础是概率论的基本原理，特别是中心极限定理 (CLT)。任务是使用蒙特卡洛模拟，数值评估一个标准化的伯努利随机变量之和向标准正态分布收敛的速度。\n\n该模型描述了一份包含 $Q$ 个问题的测试的总分 $S_Q$。每个问题 $i$ 以固定的概率 $p$ 被正确回答，因此结果是一个独立的伯努利试验 $X_i \\sim \\text{Bernoulli}(p)$。概率 $p$ 由全概率公式推导得出：\n$$\np = P(\\text{correct}) = P(\\text{correct} | \\text{knows})P(\\text{knows}) + P(\\text{correct} | \\text{guesses})P(\\text{guesses})\n$$\n根据给定的参数，这等于 $p = (1) \\cdot k + (1/c) \\cdot (1-k)$，可简化为 $p = k + (1-k)/c$。\n\n总分 $S_Q = \\sum_{i=1}^{Q} X_i$ 是 $Q$ 个独立同分布 (i.i.d.) 伯努利随机变量的和。因此，$S_Q$ 服从二项分布，$S_Q \\sim \\text{Binomial}(Q, p)$。$S_Q$ 的期望值（均值）为 $E[S_Q] = Qp$，其方差为 $\\text{Var}(S_Q) = Qp(1-p)$。\n\n中心极限定理断言，当 $Q \\to \\infty$ 时，标准化分数\n$$\nZ_Q = \\frac{S_Q - E[S_Q]}{\\sqrt{\\text{Var}(S_Q)}} = \\frac{S_Q - Qp}{\\sqrt{Qp(1-p)}}\n$$\n的分布趋近于标准正态分布 $\\mathcal{N}(0,1)$。该问题要求使用 Kolmogorov-Smirnov (KS) 距离对有限 $Q$ 值下此近似进行定量评估。\n\n计算流程如下：\n$1$. 对于由三元组 $(Q, c, k)$ 指定的每个测试用例，首先计算成功概率 $p = k + (1-k)/c$。\n$2$. 通过从分布 $S_Q \\sim \\text{Binomial}(Q, p)$ 中生成 $N = 80000$ 个独立的总分样本 $\\{s_1, s_2, \\dots, s_N\\}$ 来执行蒙特卡洛模拟。这在计算上比模拟 $N \\times Q$ 次独立的伯努利试验更有效率。使用固定的随机种子 $20240517$ 以确保结果的可复现性。\n$3$. 将每个模拟分数 $s_j$ 标准化，以获得标准化分数的样本 $\\{z_1, z_2, \\dots, z_N\\}$，其中每个 $z_j$ 的计算公式为：\n$$\nz_j = \\frac{s_j - Qp}{\\sqrt{Qp(1-p)}}\n$$\n$4$. 计算标准化样本 $\\{z_j\\}$ 的经验累积分布函数 (ECDF) 与标准正态分布的理论 CDF $\\Phi(x)$ 之间的 Kolmogorov-Smirnov 距离 $D_N$。ECDF 由 $F_N(x) = \\frac{1}{N}\\sum_{j=1}^{N} \\mathbb{I}(z_j \\le x)$ 给出，其中 $\\mathbb{I}$ 是指示函数。KS 距离定义为：\n$$\nD_N = \\sup_{x \\in \\mathbb{R}} |F_N(x) - \\Phi(x)|\n$$\n对四个测试用例中的每一个都计算此距离。`scipy.stats.kstest` 函数为此计算提供了一个直接且数值稳定的实现。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import kstest\n\ndef solve():\n    \"\"\"\n    Computes the Kolmogorov-Smirnov distance between the empirical distribution\n    of a standardized test score and the standard normal distribution for several\n    test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (100, 4, 0.6),   # Case 1: general case\n        (5, 4, 0.6),     # Case 2: small aggregation boundary\n        (400, 2, 0.0),   # Case 3: symmetric success probability, large aggregation\n        (400, 20, 0.0),  # Case 4: rare success probability, large aggregation\n    ]\n\n    # Simulation parameters\n    N_draws = 80000\n    seed = 20240517\n\n    # Initialize a random number generator with the specified seed for reproducibility.\n    rng = np.random.default_rng(seed)\n\n    results = []\n    for case in test_cases:\n        Q, c, k = case\n\n        # Step 1: Calculate the per-question correctness probability 'p'.\n        # p = k + (1-k)/c\n        p = k + (1.0 - k) / c\n\n        # Step 2: Generate N draws of the total score S_Q from a Binomial distribution.\n        # S_Q ~ Binomial(Q, p)\n        # Using rng.binomial is more efficient than simulating Q Bernoulli trials N times.\n        s_q_samples = rng.binomial(n=Q, p=p, size=N_draws)\n\n        # Step 3: Compute the standardized scores Z_Q.\n        # Z_Q = (S_Q - E[S_Q]) / sqrt(Var(S_Q))\n        # E[S_Q] = Q * p\n        # Var(S_Q) = Q * p * (1-p)\n        mean_s_q = Q * p\n        std_dev_s_q = np.sqrt(Q * p * (1.0 - p))\n        \n        # Avoid division by zero if variance is zero (p=0 or p=1).\n        # In such a case, S_Q is constant and Z_Q is not well-defined. The KS distance\n        # would be maximal, but the problem cases avoid this scenario.\n        if std_dev_s_q == 0:\n            # This case is not expected based on problem description,\n            # but as a matter of robust implementation, it should be handled.\n            # a constant variable's CDF is a step function. The distance to a\n            # continuous CDF like the normal a distance of 0.5.\n            ks_distance = 0.5\n        else:\n            z_q_samples = (s_q_samples - mean_s_q) / std_dev_s_q\n\n            # Step 4: Compute the Kolmogorov-Smirnov distance D_N.\n            # kstest compares the empirical CDF of the sample with the theoretical\n            # standard normal CDF ('norm'). It returns the KS statistic and the p-value.\n            # We only need the statistic, which corresponds to D_N.\n            ks_statistic, _ = kstest(z_q_samples, 'norm')\n            ks_distance = ks_statistic\n        \n        results.append(ks_distance)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}, {"introduction": "虽然中心极限定理应用广泛，但其“有限方差”的核心前提常常在现实金融市场中被打破，因为极端市场事件会导致数据呈现“重尾”分布。本练习将引导你探索中心极限定理的边界，通过模拟以重尾特性著称的帕累托（Pareto）分布，来检验当方差甚至均值无穷大时会发生什么。通过亲眼见证定理的失效以及标准化样本均值的发散行为，你将深刻理解在处理金融风险时识别和妥善建模重尾现象的至关重要性。[@problem_id:2405635]", "id": "2405635", "problem": "考虑从I型帕累托分布中抽取的独立同分布随机变量 $X_1, X_2, \\dots, X_n$，其尺度参数为 $x_m = 1$，尾部指数（形状）参数为 $\\alpha > 0$。对于 $x \\ge 1$，其累积分布函数为 $F(x) = 1 - x^{-\\alpha}$。一个经过充分检验的事实是，当且仅当 $\\alpha > 1$ 时，存在有限均值，此时总体均值为 $\\mu = \\dfrac{\\alpha}{\\alpha - 1}$；当且仅当 $\\alpha > 2$ 时，存在有限方差。大数定律（LLN）要求样本均值要收敛于总体均值，必须存在有限均值。中心极限定理（CLT）要求标准化的样本均值要依分布收敛于标准正态分布，必须存在有限均值和有限非零方差。\n\n您的任务是设计并实现一个计算实验，通过模拟检验在帕累托分布中当 $\\alpha \\le 2$ 时中心极限定理的失效情况，方法是检查标准化样本均值的分布；并展示当均值无限（$\\alpha \\le 1$）时的爆炸性尺度变化。该问题是为计算经济学和金融学领域构建的，在这些领域中，重尾的收益和损失分布使得用于风险聚合的高斯近似方法失效。\n\n您必须从上述基本定义出发，并且除了这些经过充分检验的事实之外，不使用任何快捷公式来实现以下内容：\n\n1. 对于每个 $\\alpha \\in \\{1.5, 2.0\\}$ 和每个样本量 $n \\in \\{200, 1000, 3000\\}$，模拟 $R = 4000$ 次独立重复实验。每次实验从 $x_m = 1$ 的帕累托($\\alpha$)分布中抽取大小为 $n$ 的样本。使用逆变换采样法，该方法基于以下事实：如果 $U \\sim \\text{Uniform}(0,1)$，则 $X = U^{-1/\\alpha}$ 服从 $x_m=1$ 的I型帕累托($\\alpha$)分布。对于每次重复实验，计算学生化均值\n$$\nT_{n} \\;=\\; \\frac{\\sqrt{n}\\,\\big(\\overline{X}_n - \\mu\\big)}{S_n},\n$$\n其中 $\\mu = \\frac{\\alpha}{\\alpha-1}$ 是真实均值（当 $\\alpha > 1$ 时存在），$\\overline{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i$ 是样本均值，而 $S_n$ 是除数为 $n-1$ 的样本标准差。使用 $R$ 个 $T_n$ 的值，计算与标准正态分布的 Kolmogorov–Smirnov 距离，\n$$\nD_{n} \\;=\\; \\sup_{x \\in \\mathbb{R}} \\Big| \\widehat{F}_{T_n}(x) - \\Phi(x) \\Big|,\n$$\n其中 $\\widehat{F}_{T_n}$ 是 $R$ 个 $T_n$ 实现值的经验分布函数，而 $\\Phi$ 是标准正态累积分布函数。报告每对 $(\\alpha, n)$ 的 $D_n$ 值。\n\n2. 对于 $\\alpha = 0.8$（无限均值）的情况，对每个 $n \\in \\{200, 1000, 3000\\}$，模拟 $R = 4000$ 次独立重复实验，并计算所有重复实验中绝对缩放样本均值的中位数，\n$$\nM_n \\;=\\; \\operatorname{median}\\Big( \\big| \\sqrt{n}\\,\\overline{X}_n \\big| \\Big),\n$$\n然后计算布尔指标\n$$\n\\text{INC} \\;=\\; \\big( M_{200} < M_{1000} \\big) \\land \\big( M_{1000} < M_{3000} \\big),\n$$\n该指标用于检验 $\\sqrt{n}\\,\\overline{X}_n$ 的典型量级是否随 $n$ 严格增长。这种增长表明序列 $\\{\\sqrt{n}\\,\\overline{X}_n\\}$ 不是紧的，因此不能收敛于标准正态分布。\n\n为确保科学真实性，请对所有模拟使用相同的随机种子 $s = 123456$，以使结果可复现。对每个 $(\\alpha,n)$ 组合使用 $R = 4000$ 次重复实验。您可以分批生成样本以控制内存使用，但结果必须与给定种子和规范所蕴含的结果完全一致。\n\n测试套件和要求输出：\n- 使用上述参数集，即：\n  - 对于 $\\alpha = 1.5$：$n \\in \\{200, 1000, 3000\\}$，报告三个值 $D_{200}$、$D_{1000}$、$D_{3000}$。\n  - 对于 $\\alpha = 2.0$：$n \\in \\{200, 1000, 3000\\}$，报告三个值 $D_{200}$、$D_{1000}$、$D_{3000}$。\n  - 对于 $\\alpha = 0.8$：$n \\in \\{200, 1000, 3000\\}$，报告布尔值 $\\text{INC}$ 和三个中位数 $M_{200}$、$M_{1000}$、$M_{3000}$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须按以下顺序排列\n$$\n\\big[ D_{200}^{(\\alpha=1.5)}, D_{1000}^{(\\alpha=1.5)}, D_{3000}^{(\\alpha=1.5)}, D_{200}^{(\\alpha=2.0)}, D_{1000}^{(\\alpha=2.0)}, D_{3000}^{(\\alpha=2.0)}, \\text{INC}^{(\\alpha=0.8)}, M_{200}^{(\\alpha=0.8)}, M_{1000}^{(\\alpha=0.8)}, M_{3000}^{(\\alpha=0.8)} \\big].\n$$\n所有报告的 $D_n$ 和 $M_n$ 必须是实数（浮点数），$\\text{INC}$ 必须是布尔值。不涉及单位。不涉及角度。输出必须是指定格式的单行文本。", "solution": "问题陈述已提交以供验证。\n\n**第1步：提取给定条件**\n- 独立同分布（i.i.d.）随机变量：$X_1, X_2, \\dots, X_n$。\n- 分布：I型帕累托分布，尺度参数 $x_m = 1$，尾部指数（形状）参数 $\\alpha > 0$。\n- 累积分布函数（CDF）：对于 $x \\ge 1$，$F(x) = 1 - x^{-\\alpha}$。\n- 矩的存在性：\n    - 当且仅当（iff）$\\alpha > 1$ 时，存在有限均值，总体均值为 $\\mu = \\dfrac{\\alpha}{\\alpha - 1}$。\n    - 当且仅当 $\\alpha > 2$ 时，存在有限方差。\n- 大数定律（LLN）：要求存在有限均值。\n- 中心极限定理（CLT）：要求存在有限均值和有限非零方差。\n- 模拟方法：逆变换采样，若 $U \\sim \\text{Uniform}(0,1)$，则 $X = U^{-1/\\alpha}$。\n- 模拟参数：\n    - 重复次数：$R = 4000$。\n    - 随机种子：$s = 123456$。\n- 任务1：\n    - 参数：$\\alpha \\in \\{1.5, 2.0\\}$ 和 $n \\in \\{200, 1000, 3000\\}$。\n    - 统计量：学生化均值 $T_{n} = \\frac{\\sqrt{n}\\,\\big(\\overline{X}_n - \\mu\\big)}{S_n}$，其中 $\\overline{X}_n$ 是样本均值，$S_n$ 是除数为 $n-1$ 的样本标准差。\n    - 度量：Kolmogorov–Smirnov 距离 $D_{n} = \\sup_{x \\in \\mathbb{R}} \\big| \\widehat{F}_{T_n}(x) - \\Phi(x) \\big|$，其中 $\\widehat{F}_{T_n}$ 是 $T_n$ 的经验分布函数，$\\Phi(x)$ 是标准正态累积分布函数。\n- 任务2：\n    - 参数：$\\alpha = 0.8$。\n    - 样本量：$n \\in \\{200, 1000, 3000\\}$。\n    - 统计量：$M_n = \\operatorname{median}\\Big( \\big| \\sqrt{n}\\,\\overline{X}_n \\big| \\Big)$（在 $R$ 次重复实验中计算）。\n    - 度量：布尔指标 $\\text{INC} = \\big( M_{200} < M_{1000} \\big) \\land \\big( M_{1000} < M_{3000} \\big)$。\n- 输出格式：单个逗号分隔列表：$\\big[ D_{200}^{(\\alpha=1.5)}, D_{1000}^{(\\alpha=1.5)}, D_{3000}^{(\\alpha=1.5)}, D_{200}^{(\\alpha=2.0)}, D_{1000}^{(\\alpha=2.0)}, D_{3000}^{(\\alpha=2.0)}, \\text{INC}^{(\\alpha=0.8)}, M_{200}^{(\\alpha=0.8)}, M_{1000}^{(\\alpha=0.8)}, M_{3000}^{(\\alpha=0.8)} \\big]$。\n\n**第2步：使用提取的给定条件进行验证**\n根据验证标准对问题进行评估。\n- **科学依据**：该问题坚实地建立在中心极限定理、大数定律等已确立的统计理论以及帕累托分布等重尾分布的性质之上。使用蒙特卡洛模拟来研究估计量的渐近行为是计算统计学和计量经济学中的标准严谨方法。\n- **定义明确**：问题没有歧义。所有参数（$\\alpha, n, R, s$）、统计量（$T_n, M_n$）和度量（$D_n, \\text{INC}$）都得到了精确定义。过程以算法形式描述，这会导向一个唯一的、可验证的数值结果。\n- **客观性**：问题以精确、客观的数学和计算语言陈述，不含任何主观性或观点。\n\n**第3步：结论与行动**\n该问题是**有效的**。这是一个在统计学中格式良好、定义明确的计算实验。将构建一个解决方案。\n\n**解决方案推导**\n\n此问题的核心是中心极限定理（CLT），它是统计学的基石。经典的CLT指出，对于具有有限均值 $\\mu$ 和有限方差 $\\sigma^2 > 0$ 的独立同分布随机变量 $\\{X_i\\}$，标准化的样本均值依分布收敛于标准正态分布：\n$$\n\\frac{\\overline{X}_n - \\mu}{\\sigma/\\sqrt{n}} \\xrightarrow{d} \\mathcal{N}(0,1) \\quad \\text{as} \\quad n \\to \\infty\n$$\n该问题要求通过模拟来展示当这些条件不被满足时会发生什么，特别是在帕累托分布中，其尾部厚重程度由参数 $\\alpha$ 控制。\n\n**模拟的理论背景**\n\n1.  **情况 $\\alpha \\in \\{1.5, 2.0\\}$（有限均值，无限方差）：**\n    对于这些 $\\alpha$ 值，均值存在（当 $\\alpha=1.5$ 时 $\\mu=3$；当 $\\alpha=2.0$ 时 $\\mu=2$），但方差是无限的。标准CLT不适用。取而代之的是广义CLT，它指出这类变量的和，在经过适当的中心化和缩放后，会收敛到一个非正态的稳定分布。学生化均值 $T_n = \\sqrt{n}(\\overline{X}_n - \\mu)/S_n$ 的渐近分布也不是正态的，因为样本标准差 $S_n$ 不会收敛到一个常数。计算与标准正态CDF $\\Phi(x)$ 的 Kolmogorov-Smirnov 距离 $D_n$ 的目的，是量化这种向正态性收敛的失败。我们预期即使对于大的 $n$，$D_n$ 仍会显著大于零，从而显示出持续的非正态特性。\n\n2.  **情况 $\\alpha = 0.8$（无限均值）：**\n    对于 $\\alpha < 1$，帕累托分布的均值是无限的。这是对CLT条件更严重的违反；甚至大数定律也失效了。样本均值 $\\overline{X}_n$ 不会收敛到任何常数。稳定分布理论指出，对于 $\\alpha \\in (0, 2)$，和 $\\sum X_i$ 的增长与 $n^{1/\\alpha}$ 成比例。因此，样本均值 $\\overline{X}_n = n^{-1}\\sum X_i$ 的增长与 $n^{1/\\alpha - 1}$ 成比例。所研究的项 $\\sqrt{n}\\,\\overline{X}_n$ 因此应该随 $n$ 按 $n^{1/2} \\cdot n^{1/\\alpha-1} = n^{1/\\alpha - 1/2}$ 的比例缩放。对于 $\\alpha=0.8$，这是 $n^{1/0.8-0.5} = n^{1.25-0.5} = n^{0.75}$。由于指数为正，这个量预计会随 $n$ 增长。该模拟通过计算其量级的中位数 $M_n$ 来检验这一点，并验证对于所选的样本量，$M_n$ 是 $n$ 的严格递增函数。这为当总体均值不存在时样本均值的爆炸性特性提供了计算证据。\n\n**实施计划**\n\n模拟将使用 Python 的 `numpy` 库进行高效的向量化计算，并使用 `scipy` 进行 Kolmogorov-Smirnov 检验。\n\n1.  **初始化**：将使用种子 $s=123456$ 初始化一个随机数生成器，以确保可复现性。\n\n2.  **第1部分：计算 $\\alpha \\in \\{1.5, 2.0\\}$ 的 $D_n$**：\n    对于每对 $(\\alpha, n)$，我们执行 $R=4000$ 次重复实验。\n    a. 生成一个 $R \\times n$ 的均匀随机数矩阵 $U \\sim \\text{Uniform}(0,1)$。\n    b. 使用逆变换法将此矩阵转换为帕累托分布的变量：$X = U^{-1/\\alpha}$。\n    c. 对 $R$ 行中的每一行计算样本均值 $\\overline{X}_n$ 和样本标准差 $S_n$（分母为 $n-1$，即 `ddof=1`），从而为每个统计量得到 $R$ 个值。\n    d. 计算真实均值 $\\mu = \\alpha/(\\alpha-1)$。\n    e. 计算 $R$ 个学生化均值 $T_n = \\sqrt{n}(\\overline{X}_n - \\mu) / S_n$ 的实现值。\n    f. 通过比较 $R$ 个T值的经验分布与标准正态分布的CDF $\\Phi(x)$，计算 Kolmogorov-Smirnov 统计量 $D_n$。这可以通过 `scipy.stats.kstest` 完成。\n\n3.  **第2部分：计算 $\\alpha=0.8$ 的 $M_n$ 和 $\\text{INC}$**：\n    对于每个 $n \\in \\{200, 1000, 3000\\}$：\n    a. 生成一个 $R \\times n$ 的帕累托变量矩阵，其中 $\\alpha=0.8$。\n    b. 对 $R$ 行中的每一行计算样本均值 $\\overline{X}_n$。\n    c. 对每次重复实验计算统计量 $|\\sqrt{n}\\,\\overline{X}_n|$。\n    d. 找到这 $R$ 个值的中位数以获得 $M_n$。\n    e. 在计算出 $M_{200}$、$M_{1000}$ 和 $M_{3000}$ 后，根据严格不等式条件评估布尔指标 $\\text{INC}$。\n\n4.  **输出**：将按指定顺序收集计算出的值，并以所需格式打印。这种严谨的、向量化的方法确保了正确性和计算效率。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import kstest, norm\n\ndef solve():\n    \"\"\"\n    Performs a computational experiment to test the failure of the Central Limit Theorem\n    for Pareto distributions with heavy tails.\n    \"\"\"\n    # Define simulation parameters from the problem statement.\n    seed = 123456\n    R = 4000\n    rng = np.random.default_rng(seed)\n\n    all_results = []\n\n    # Part 1: Test convergence to Normal for alpha > 1\n    # Cases where mean is finite, but variance is infinite.\n    alphas_part1 = [1.5, 2.0]\n    n_values_part1 = [200, 1000, 3000]\n\n    for alpha in alphas_part1:\n        # The true mean exists for alpha > 1.\n        mu = alpha / (alpha - 1.0)\n        for n in n_values_part1:\n            # Generate R samples of size n in a vectorized manner.\n            # U ~ Uniform(0,1)\n            uniform_samples = rng.uniform(size=(R, n))\n            # X = U^(-1/alpha) gives Pareto(alpha) with x_m=1\n            pareto_samples = uniform_samples**(-1.0 / alpha)\n\n            # Compute sample means and standard deviations for each of the R replications.\n            sample_means = np.mean(pareto_samples, axis=1)\n            # Use ddof=1 for sample standard deviation (n-1 divisor).\n            sample_std_devs = np.std(pareto_samples, axis=1, ddof=1)\n\n            # Compute the Studentized mean T_n for each replication.\n            # Handle the unlikely case of S_n = 0.\n            T_n_values = np.full(R, np.nan)\n            valid_indices = sample_std_devs > 0\n            T_n_values[valid_indices] = np.sqrt(n) * (sample_means[valid_indices] - mu) / sample_std_devs[valid_indices]\n            \n            # Filter out any potential NaN values before the KS test.\n            T_n_values = T_n_values[~np.isnan(T_n_values)]\n\n            # Compute the Kolmogorov-Smirnov distance to the standard normal distribution.\n            # The 'statistic' attribute of the result is the D_n value.\n            ks_result = kstest(T_n_values, norm.cdf)\n            D_n = ks_result.statistic\n            all_results.append(D_n)\n\n    # Part 2: Test explosive scaling for alpha < 1\n    # Case where mean is infinite.\n    alpha_part2 = 0.8\n    n_values_part2 = [200, 1000, 3000]\n    medians = []\n\n    for n in n_values_part2:\n        # Generate R samples of size n.\n        uniform_samples = rng.uniform(size=(R, n))\n        pareto_samples = uniform_samples**(-1.0 / alpha_part2)\n\n        # Compute sample means for each replication.\n        sample_means = np.mean(pareto_samples, axis=1)\n\n        # Compute the absolute scaled sample mean for each replication.\n        abs_scaled_means = np.abs(np.sqrt(n) * sample_means)\n\n        # Compute the median of these values across replications.\n        M_n = np.median(abs_scaled_means)\n        medians.append(M_n)\n\n    # Compute the boolean indicator for strict growth of the median.\n    INC = (medians[0] < medians[1]) and (medians[1] < medians[2])\n\n    all_results.append(INC)\n    all_results.extend(medians)\n\n    # Final print statement in the exact required format.\n    # str() of a boolean is 'True' or 'False', which is a valid representation.\n    output_str_list = [str(r) for r in all_results]\n    print(f\"[{','.join(output_str_list)}]\")\n\nsolve()\n```"}]}