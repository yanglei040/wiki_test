{"hands_on_practices": [{"introduction": "理论知识需要通过实践来巩固。要真正理解浮点数的精度限制，最好的方法莫过于亲手探索其边界。本练习将指导你通过算法，而非直接查询预定义常量，来找出最小的、在计算上可以与1区分开的正利率$r$，这个值本质上就是相对于1的机器精度（machine epsilon）。通过这个过程，你将对计算机如何存储和处理数字建立起深刻而直观的认识。[@problem_id:2394219]", "id": "2394219", "problem": "你的任务是编写一个完整、可运行的程序，以确定在单精度浮点算术中，有限精度算术如何影响小利率的可检测性。在国际电工委员会 (IEC) 和电气与电子工程师协会 (IEEE) 的浮点算术标准 (IEEE 754) 的单精度模型（基数为$2$，采用向最近偶数舍入规则）下进行操作，并将利率视为纯小数（不带百分号）。在此模型中，$1$ 附近的可表示数是离散分布的。一个利率 $r$ 在单位尺度上与 $0$ 在计算上可区分，当且仅当将 $r$ 加到 $1$ 的单精度计算结果严格大于 $1$。你的目标是仅使用遵循单精度语义的浮点运算，稳健地推断出满足条件的最小 $r \\gt 0$。\n\n使用的基本原则：\n- IEEE 754 单精度算术使用基数$2$和固定精度，并将结果舍入到最接近的可表示值，若出现平局则朝向偶数尾数解析。你可以将此舍入规则、舍入的单调性以及次正规数的存在视为经过充分检验的事实。\n\n限制条件：\n- 所有旨在反映单精度行为的加法、乘法和除法都必须在单精度下执行。不要依赖解析公式来获得答案。而是应基于 IEEE 754 舍入模型实现一种算法搜索，以找到满足 $1 + r$ 的单精度计算结果严格大于 $1$ 的最小 $r \\gt 0$。\n- 将利率表示为小数（例如，百分之五写作 $0.05$）。不需要单位。\n\n需要实现的必做任务：\n1. 计算满足 $1 + r$ 的单精度结果严格大于 $1$ 的最小利率 $r \\gt 0$。使用完全由单精度运算驱动的迭代减半（二分法风格）方法：从一个单精度 $r$ 开始，不断减小 $r$，直到将其一半加到 $1$ 上不再使 $1$ 在单精度下增大；当减半时仍然能使 $1$ 增大的最后一个 $r$ 即为所求值。\n2. 通过检查对于步骤1中得到的 $r_{\\min}$，$1 + \\frac{r_{\\min}}{2}$ 的单精度结果等于 $1$ 来验证边界条件。\n3. 交叉检验计算出的 $r_{\\min}$ 是否与从可信的单精度浮点元数据源获得的、$1$ 紧邻其上的单精度间距相匹配。\n4. 确认将最小的正单精度次正规数 $s$ 加到 $1$ 上，其单精度结果等于 $1$。\n5. 应用金融检验：对于在时间 $T = 360$ 时收到的一笔大小为 $C = 1$ 的单笔支付（可解释为月，但不需要单位），在单精度下计算差值 $\\frac{1}{(1 + r_{\\min})^{T}} - 1$ 并返回这个单一数值。将该值报告为小数（而非百分数）。\n\n测试套件与预期输出：\n- 程序必须按顺序计算以下五个输出，并将它们聚合到一个列表中：\n  - 情况 A（理想路径）：任务1中得到的 $r_{\\min}$ 值，以浮点数形式表示。\n  - 情况 B（边界条件）：一个布尔值，表示在单精度下 $1 + \\frac{r_{\\min}}{2} = 1$ 是否成立。\n  - 情况 C（一致性）：一个布尔值，表示 $r_{\\min}$ 是否等于 $1$ 紧邻其上的单精度元数据间距。\n  - 情况 D（边界情况）：一个布尔值，表示对于最小正次正规数 $s$，在单精度下 $1 + s = 1$ 是否成立。\n  - 情况 E（应用）：$\\frac{1}{(1 + r_{\\min})^{360}} - 1$ 的值，以浮点数形式表示，且完全在单精度下计算。\n\n最终输出格式：\n- 你的程序应生成一行输出，其中包含用方括号括起来的、以逗号分隔的结果列表（例如，$[result\\_A,result\\_B,result\\_C,result\\_D,result\\_E]$）。该列表必须按顺序精确包含上述五个值。所有与任务1到5相关的浮点算术都必须在单精度下执行，并且所有比较都必须反映单精度结果。所有输出都必须报告为普通数字或布尔值，不带单位和百分号。", "solution": "该问题要求在涉及小利率的金融计算背景下，研究有限精度算术的局限性，特别是 IEEE 754 单精度标准。核心任务是确定与 $1$ 相加时在计算上可与 $0$ 区分的最小正利率 $r$（表示为 $r_{\\min}$）。这等效于找到最小的正单精度数 $r_{\\min}$，使得浮点运算 $fl(1 + r_{\\min})$ 产生的结果严格大于 $1$。然后，我们将使用这个值执行几项验证检查和一次简单的金融计算。\n\n在 IEEE 754 单精度浮点数（binary32）标准中，一个数由1个符号位、1个8位偏置指数和1个23位小数部分表示。一个规格化数的形式为 $(-1)^S \\times 2^{E-127} \\times (1.f)_{2}$，其中 $S$ 是符号位，$E$ 是指数，$f$ 是小数部分。\n\n数字 $1.0$ 在此系统中可以精确表示。其符号为 $0$，无偏指数为 $0$（因此偏置指数 $E$ 为 $127$），小数部分全为零。其尾数（significand）隐式为 $1.0$。下一个更大的可表示数具有相同的指数，但将小数部分的最后一位加一。这个数是 $1 + 2^{-23}$。因此，$1.0$ 与下一个可表示数之间的间隙为 $2^{-23}$。这个量被称为“末位单位”（Unit in the Last Place），或称 $ulp(1.0)$。根据默认的“向最近偶数舍入”规则，任何加到 $1.0$ 上的正数 $x < ulp(1.0)/2 = 2^{-24}$ 都将被向下舍入回 $1.0$。如果 $x = 2^{-24}$，则出现平局，结果会舍入到“偶数”尾数，即 $1.0$ 的尾数。因此，使 $fl(1 + r_{\\min}) > 1$ 的最小数 $r_{\\min}$ 必须是 $ulp(1.0) = 2^{-23}$。\n\n问题要求通过算法发现此值，而非通过解析推导。\n\n**任务1：$r_{\\min}$ 的算法计算**\n\n我们被要求使用迭代搜索来找到 $r_{\\min}$。该搜索必须找到满足 $fl(1+r) > 1$ 的最小数 $r$。所描述的方法是2的幂次下降，我们通过从候选值 $r = 1.0$ 开始并不断将其减半来实现。其逻辑是找到一个值 $r$，使得 $fl(1 + r) > 1$ 但 $fl(1 + r/2) = 1$。这可以通过一个循环来实现，只要将当前候选值 $r$ 的一半加到 $1$ 上仍能产生大于 $1$ 的结果，该循环就继续进行。所有算术都必须在单精度下执行。\n\n设 $r_0 = 1.0_{f32}$。我们生成一个序列 $r_{k+1} = r_k / 2.0_{f32}$。只要 $fl(1.0_{f32} + fl(r_k / 2.0_{f32})) > 1.0_{f32}$，循环就继续。当条件不满足时，当前的 $r_k$ 就是我们所求的 $r_{\\min}$。\n\n**任务2：验证边界条件**\n\n根据任务1的构造，$r_{\\min}$ 是序列 $1, 1/2, 1/4, \\dots$ 中使 $fl(1+r_{\\min})>1$ 的最小值。算法在 $fl(1 + r_{\\min}/2) = 1$ 时精确终止。此项检查用于确认我们的算法正确地识别了相对于 $1$ 的机器精度边界。我们将计算 $fl(1.0_{f32} + fl(r_{\\min} / 2.0_{f32}))$ 并验证其等于 $1.0_{f32}$。\n\n**任务3：与浮点元数据交叉检验**\n\n我们通过算法确定的 $r_{\\min}$ 值，应与称为单精度机器ε（machine epsilon）的基本机器常数相同，即从 $1.0$ 到下一个更大的可表示浮点数之间的距离。标准数值库提供了访问此值的途径。我们将把计算出的 $r_{\\min}$ 与 `numpy.spacing(numpy.float32(1.0))` 的值进行比较，这是 $ulp(1.0)$ 的一个可信来源。这证实了我们算法和理解的正确性。\n\n**任务4：使用最小次正规数的边界情况**\n\n次正规数（或非规格化数）用于表示比最小规格化数更小的值，填补了 $0$ 和 $\\pm 2^{E_{min}}$ 之间的空白。最小的正单精度次正规数（我们称之为 $s$）是 $2^{-149}$。这个值比 $r_{\\min} = 2^{-23}$ 小得非常多。当我们计算 $fl(1.0 + s)$ 时，结果会舍入到最接近的可表示数。由于 $s \\ll r_{\\min}/2$，和 $1.0 + s$ 与 $1.0$ 的距离远小于其与下一个可表示数 $1.0 + r_{\\min}$ 的距离。因此，浮点加法的结果必须是 $1.0$。这个任务验证了我们对浮点加法中如何处理极小数的理解。\n\n**任务5：应用金融检验**\n\n这个任务要求我们计算这个最小利率 $r_{\\min}$ 在很长一段时间内的影响。我们必须计算一个金融表达式的值，$D = \\frac{1}{(1 + r_{\\min})^T} - 1$，其中时间周期 $T$ 是 $360$（例如，30年期中的月份数）。所有运算都必须以单精度执行。这表明，即使是计算上可检测到的最小利率，在复利作用下，也会导致与零利率情景相比产生可测量的偏差。运算顺序如下：\n1.  计算 $v_1 = fl(1.0_{f32} + r_{\\min})$。\n2.  计算 $v_2 = fl(v_1^{360.0_{f32}})$。这是一个重复乘法或库中的幂函数，全部在单精度下进行。\n3.  计算 $v_3 = fl(1.0_{f32} / v_2)$。\n4.  计算最终结果 $D = fl(v_3 - 1.0_{f32})$。\n结果将是一个小的负数，表示对于时间 $T=360$ 处的现金流，其现值贴现因子与 $1$ 的偏差。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Performs a series of tasks related to single-precision floating-point\n    arithmetic and its application in finance, adhering to strict computational\n    and formatting rules.\n    \"\"\"\n\n    # Define single-precision constants to ensure all arithmetic is performed\n    # in the correct domain.\n    one_f32 = np.float32(1.0)\n    two_f32 = np.float32(2.0)\n\n    # --- Task 1: Compute the smallest rate r_min > 0 ---\n    # We are looking for the smallest r > 0 such that 1 + r > 1 in single precision.\n    # The problem specifies a bisection-style search. We start with r=1 and\n    # repeatedly halve it until adding r/2 to 1 no longer produces a result > 1.\n    # At that point, the current r is the minimal value, r_min.\n    r = one_f32\n    while (one_f32 + (r / two_f32)) > one_f32:\n        r = r / two_f32\n    r_min = r\n    result_A = r_min\n\n    # --- Task 2: Verify the boundary condition ---\n    # Check that adding half of r_min to 1 results in 1, confirming r_min is\n    # the minimal representable increment.\n    is_boundary_correct = (one_f32 + (r_min / two_f32)) == one_f32\n    result_B = is_boundary_correct\n\n    # --- Task 3: Cross-check with floating-point metadata ---\n    # Compare r_min with the value of ULP(1.0) (unit in the last place) for\n    # single precision, also known as machine epsilon relative to 1.\n    # np.spacing(1.0) gives the distance between 1.0 and the next larger float.\n    spacing_at_one = np.spacing(one_f32)\n    is_consistent = (r_min == spacing_at_one)\n    result_C = is_consistent\n\n    # --- Task 4: Confirm edge case with smallest subnormal number ---\n    # The smallest positive single-precision number is np.finfo.tiny.\n    # Adding this to 1 should result in 1 due to rounding.\n    s_subnormal = np.finfo(np.float32).tiny\n    is_subnormal_rounded = (one_f32 + s_subnormal) == one_f32\n    result_D = is_subnormal_rounded\n\n    # --- Task 5: Applied finance check ---\n    # Compute the discount factor deviation over 360 periods using r_min.\n    # All calculations must be performed in single precision.\n    T = np.float32(360.0)\n    one_plus_r_min = one_f32 + r_min\n    # The power operation must also respect single precision.\n    # numpy's ** operator on float32 types maintains float32 precision.\n    compounded_factor = one_plus_r_min ** T\n    inverse_factor = one_f32 / compounded_factor\n    finance_result = inverse_factor - one_f32\n    result_E = finance_result\n\n    # Aggregate results into a list for final output.\n    results = [\n        result_A,\n        result_B,\n        result_C,\n        result_D,\n        result_E\n    ]\n\n    # Final print statement in the exact required format.\n    # The map(str, ...) converts each element, including booleans, to its\n    # string representation ('True', 'False', or the number as a string).\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}, {"introduction": "理解了计算的极限之后，我们将探讨这些极限如何导致实际计算中的错误。当两个几乎相等的数相减时，其结果的有效数字可能会大量丢失，这种现象被称为“灾难性抵消”（catastrophic cancellation）。本练习通过一个经典的概率计算问题，清晰地揭示了这一陷阱：你将比较两种在理论上完全等价的计算方法，并亲眼见证一个看似无害的减法操作如何导致巨大的数值误差。[@problem_id:2394200]", "id": "2394200", "problem": "您的任务是研究在假设回报呈正态分布的模型背景下，计算一个概率密度函数下一个非常窄区间的面积时出现的数值精度损失问题。令 $f(x)$ 为标准正态概率密度函数，由 $f(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right)$ 给出；令 $F(x)$ 为其累积分布函数，定义为 $F(x) = \\int_{-\\infty}^{x} f(t)\\,dt$。对于给定的满足 $a < b$ 的数对 $(a,b)$，区间 $(a,b]$ 内的理论概率质量既是 $F(b) - F(a)$，也是 $\\int_{a}^{b} f(x)\\,dx$。\n\n将您的编程环境所使用的浮点运算的机器 epsilon $\\varepsilon$ 定义为在该运算中使 $1 + \\varepsilon > 1$ 成立的最小正实数。\n\n对于下述每个测试用例（给出的 $(a,b)$ 值），计算：\n- 相对差异 $\\delta = \\frac{\\left| \\left(F(b) - F(a)\\right) - \\int_{a}^{b} f(x)\\,dx \\right|}{\\int_{a}^{b} f(x)\\,dx}$。\n- 比率 $\\rho = \\delta / \\varepsilon$。\n\n测试套件（所有数字均为实数值）：\n- $(a,b) = (0.0, 0.1)$\n- $(a,b) = (0.0, 10^{-8})$\n- $(a,b) = (0.0, 10^{-12})$\n- $(a,b) = (5.0, 5.0 + 10^{-4})$\n- $(a,b) = (8.0, 8.0 + 10^{-6})$\n- $(a,b) = (-12.0, -12.0 + 10^{-3})$\n\n您的程序必须生成单行输出，其中包含一个聚合了所有结果的列表，顺序如下：对于上述序列中的每个测试用例，先输出 $\\delta$ 值，然后输出 $\\rho$ 值，从而得到一个长度为 12 的扁平列表。格式必须是方括号括起来的逗号分隔列表，例如 $[\\delta_1,\\rho_1,\\delta_2,\\rho_2,\\dots,\\delta_6,\\rho_6]$。所有输出都必须是实数；不涉及单位，也不需要角度单位。如果概念上出现百分比，必须表示为小数。", "solution": "所述问题是有效的。这是一个数值分析领域中适定 (well-posed) 的练习，它基于概率论和浮点计算的既定原则。其目标是展示并量化数值精度损失现象，特别是灾难性抵消，这是科学计算和金融计算中的一个关键考虑因素。\n\n让我们从理论基础开始。该问题定义了在标准正态分布下，区间 $(a, b]$ 上的概率质量的两种计算量。第一种源自累积分布函数 (CDF) $F(x)$，即差值 $P_1 = F(b) - F(a)$。第二种是概率密度函数 (PDF) $f(x)$ 在该区间上的直接定积分：$P_2 = \\int_{a}^{b} f(x)\\,dx$。根据微积分基本定理，由于 $F'(x) = f(x)$，这两个量在解析上是等价的。即 $F(b) - F(a) = \\int_{a}^{b} f(x)\\,dx$。\n\n然而，在有限精度运算的世界里，解析等价性不保证计算等价性。问题的核心在于当区间很窄时（即 $b$ 非常接近 $a$ 时）对 $P_1$ 的数值计算。在这种情况下，$F(b)$ 将非常接近 $F(a)$。标准的浮点数，例如 Python 中使用的 IEEE 754 双精度格式，将一个值存储为符号、尾数（有效数）和指数。尾数包含固定数量的有效数字。当两个大小几乎相等的数相减时，它们尾数的前导数字会相互抵消。例如，如果我们有 $x = 1.23456789$ 和 $y = 1.23456700$，差值 $x-y = 0.00000089$。结果的有效数字位数远少于原始操作数。这种相对精度的损失被称为灾难性抵消。当 $b \\approx a$ 时，计算 $F(b) - F(a)$ 很容易受到这种误差的影响。\n\n为了量化此误差，我们需要一个高精度的参考值。PDF 的直接数值积分 $P_2$ 就用于此目的。高质量的数值求积算法，例如在 `scipy.integrate.quad` 中实现的算法，被设计为数值稳定的。它们通过对区间 $[a, b]$ 中许多小切片的面积求和来运作。这个过程避免了两个大的、几乎相等的数的直接相减，因此提供的结果通常能精确到接近机器精度的水平。因此，我们将把数值积分得到的值视为我们的精确参考值。\n\n该问题要求计算两个指标。第一个是相对差异，定义为\n$$\n\\delta = \\frac{\\left| \\left(F(b) - F(a)\\right) - \\int_{a}^{b} f(x)\\,dx \\right|}{\\int_{a}^{b} f(x)\\,dx}\n$$\n这衡量了减法方法相对于我们更精确的基于积分的参考值的相对误差。第二个指标是比率 $\\rho = \\delta / \\varepsilon$，其中 $\\varepsilon$ 是机器 epsilon。机器 epsilon 是在浮点运算中使 $1 + \\varepsilon > 1$ 成立的最小数；它代表了数值表示的相对精度的基本限制。因此，比率 $\\rho$ 对观察到的误差进行了归一化，告诉我们我们的计算误差与这个基本限制相比差了多少倍。$\\rho \\approx 1$ 的值表示数值稳定的计算，而大的 $\\rho$ 值则表示严重的精度损失。\n\n对测试用例的分析揭示了这种效应的细微差别：\n1.  对于分布均值附近的区间（例如 $(0.0, 10^{-8})$），$F(a)$ 和 $F(b)$ 都接近 0.5。将它们相减会产生灾难性抵消。\n2.  对于远右尾的区间（例如 $(8.0, 8.0 + 10^{-6})$），$F(a)$ 和 $F(b)$ 都非常接近 1。同样，将它们相减会导致灾难性抵消和一个非常大的 $\\rho$ 值。\n3.  有趣的是，对于远左尾的区间（例如 $(-12.0, -12.0 + 10^{-3})$），$F(a)$ 和 $F(b)$ 都是非常小且接近 0 的正数。两个小数相减不会遭受同样的灾难性抵消问题，因为它们的相对精度得以保持。在这种情况下，我们预期 $\\rho$ 会很小，接近 1。\n\n要实现的算法如下：\n1.  获取双精度浮点数的机器 epsilon $\\varepsilon$。在 Python/NumPy 中，这是 `np.finfo(float).eps`。\n2.  对于每个测试用例对 $(a, b)$：\n    a. 使用 `scipy.stats.norm.cdf` 计算 $V_{\\text{sub}} = F(b) - F(a)$。\n    b. 使用 `scipy.integrate.quad` 和 `scipy.stats.norm.pdf` 计算参考值 $V_{\\text{int}} = \\int_{a}^{b} f(x)\\,dx$。\n    c. 计算 $\\delta = |V_{\\text{sub}} - V_{\\text{int}}| / V_{\\text{int}}$。\n    d. 计算 $\\rho = \\delta / \\varepsilon$。\n3.  将所有计算出的 $\\delta$ 和 $\\rho$ 值聚合到一个列表中，并按要求格式化。\n这个过程将被编码到所提供的 Python 脚本中。", "answer": "```python\nimport numpy as np\nimport scipy.stats\nimport scipy.integrate\n\ndef solve():\n    \"\"\"\n    Computes numerical discrepancy and error ratios for calculating probability\n    mass in a thin interval under the standard normal distribution.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0.0, 0.1),\n        (0.0, 1e-8),\n        (0.0, 1e-12),\n        (5.0, 5.0 + 1e-4),\n        (8.0, 8.0 + 1e-6),\n        (-12.0, -12.0 + 1e-3),\n    ]\n\n    # Get the machine epsilon for standard double-precision floats.\n    machine_epsilon = np.finfo(float).eps\n\n    results = []\n    for a, b in test_cases:\n        # Method 1: Subtraction of CDF values.\n        # This method is prone to catastrophic cancellation when a is close to b.\n        val_subtraction = scipy.stats.norm.cdf(b) - scipy.stats.norm.cdf(a)\n\n        # Method 2: Numerical integration of the PDF.\n        # This is used as the high-accuracy reference \"true\" value.\n        # The function to integrate is the standard normal PDF.\n        pdf_func = scipy.stats.norm.pdf\n        val_integral, _ = scipy.integrate.quad(pdf_func, a, b)\n\n        # The relative discrepancy, delta, measures the relative error of the\n        # subtraction method compared to the more accurate integration method.\n        # A check for val_integral == 0.0 is prudent, though not expected for\n        # these non-zero width intervals where the pdf is positive.\n        if val_integral == 0.0:\n            # If the true integral is zero, the discrepancy is zero only if\n            # the subtraction method also yields zero. Otherwise, it's infinite.\n            delta = 0.0 if val_subtraction == 0.0 else np.inf\n        else:\n            delta = np.abs(val_subtraction - val_integral) / val_integral\n\n        # The ratio, rho, normalizes the discrepancy by the machine epsilon,\n        # quantifying the severity of the numerical error in a standard way.\n        rho = delta / machine_epsilon\n\n        results.extend([delta, rho])\n\n    # Final print statement must produce a single line with the specified format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}, {"introduction": "最后，我们将理论知识应用于一个更复杂的真实金融场景，弥合教科书示例与实际金融建模之间的鸿沟。在本练习中，你将为一种浮动利率债券定价，并发现对估值公式的“天真”实现会因精度损失而失败。通过推导和实现一个数值上更稳健的替代算法，你将学到一项至关重要的技能：如何重构数学公式，以创建能够抵御浮点运算固有局限性的稳健程序。[@problem_id:2394271]", "id": "2394271", "problem": "要求您编写一个完整的、可运行的程序，在风险中性估值下对浮动利率债券进行定价，同时揭示浮点精度和机器ε对计算的影响。请基于风险中性测度下贴现现金流的第一性原理进行：现值等于所有付息日的贴现预期现金流之和，加上贴现的本金偿还。请使用以下基本原理。\n1. 风险中性测度下的现值：现值等于现金流之和乘以相应的贴现因子。\n2. 第 $i$ 期的浮动利率票息等于 $(L_i + m)\\,\\alpha_i\\,N$，其中 $L_i$ 是给定的第 $i$ 期的远期利率，$m$ 是每次重置时增加的固定利差，$\\alpha_i$ 是该期的应计分数，$N$ 是名义本金。\n3. 当贴现因子由单利计息的远期利率 $L_i$ 和应计分数 $\\alpha_i$ 构建时，它们满足递归关系 $D_0 = 1$ 和 $D_i = \\dfrac{D_{i-1}}{1 + L_i \\alpha_i}$（对于 $i = 1,\\dots,T$），其中 $D_i$ 是到时间点 $i$ 的贴现因子，$T$ 是总期数。\n4. 于是，现值为 $PV = N \\left( \\sum_{i=1}^{T} (L_i + m)\\,\\alpha_i\\,D_i + D_T \\right)$，其中 $D_i$ 通过上述递归获得，$D_T$ 用于贴现本金 $N$ 的赎回。\n\n您的任务是实现两种数值上不同的现值计算方法：\n- 一种直接在每次票息计算中使用 $(L_i + m)$ 的朴素估值法。\n- 一种代数上等价的估值法，通过使用实数算术中有效的恒等式重新排列各项，来避免将一个非常小的数与一个大得多的数相加；具体来说，计算利差的贡献时，不要先将其加到 $L_i$ 上。两种方法都必须使用相同的贴现因子 $D_i$。\n\n您的程序必须执行以下测试套件，每个测试用例都由名义本金 $N$、利差 $m$、远期利率列表或规则 $\\{L_i\\}_{i=1}^T$ 以及应计分数列表 $\\{\\alpha_i\\}_{i=1}^T$ 完全指定。在所有情况下，用于估值的贴现因子 $D_i$ 都必须通过递归 $D_0 = 1$，$D_i = \\dfrac{D_{i-1}}{1 + L_i \\alpha_i}$（对于 $i = 1,\\dots,T$）从给定的 $L_i$ 和 $\\alpha_i$ 导出。\n\n测试用例A（正常路径，利差不可忽略）：\n- $N = 1{,}000{,}000$。\n- $T = 8$，季度应计：所有 $i$ 的 $\\alpha_i = 0.25$。\n- 远期利率：$L = [0.021,\\, 0.022,\\, 0.0235,\\, 0.024,\\, 0.025,\\, 0.026,\\, 0.027,\\, 0.028]$。\n- 利差：$m = 0.0005$。\n\n测试用例B（利差远低于典型利率附近的舍入单位；说明浮点精度造成的损失）：\n- $N = 1{,}000{,}000{,}000$。\n- $T = 8$，季度应计：所有 $i$ 的 $\\alpha_i = 0.25$。\n- 远期利率：使用与测试用例A相同的列表。\n- 利差：$m = 1 \\times 10^{-20}$。\n\n测试用例C（边界情况：零利差）：\n- $N = 2{,}000{,}000$。\n- $T = 8$，季度应计：所有 $i$ 的 $\\alpha_i = 0.25$。\n- 远期利率：$L = [0.018,\\, 0.019,\\, 0.0195,\\, 0.020,\\, 0.0205,\\, 0.021,\\, 0.0215,\\, 0.022]$。\n- 利差：$m = 0$。\n\n测试用例D（多期，远期利率小且逐渐变化；利差微小但不为零）：\n- $N = 100{,}000{,}000$。\n- $T = 40$，季度应计：所有 $i$ 的 $\\alpha_i = 0.25$。\n- 远期利率由规则 $L_i = 0.015 + 0.0001\\,i$ 给出（对于 $i = 1,\\dots,40$）。\n- 利差：$m = 1 \\times 10^{-12}$。\n\n您的程序必须为每个测试用例计算：\n- 朴素现值 $PV_{\\text{naive}} = N \\left( \\sum_{i=1}^{T} (L_i + m)\\,\\alpha_i\\,D_i + D_T \\right)$。\n- 另一种备选现值 $PV_{\\text{stable}}$，其计算不将 $m$ 与 $L_i$ 在票息项内相加，同时在精确算术中遵循代数等价性并使用相同的 $D_i$。\n- 绝对差值 $\\lvert PV_{\\text{naive}} - PV_{\\text{stable}} \\rvert$。\n\n此问题不涉及物理单位。所有利率必须视为小数，而不是百分比。不涉及角度。最终输出格式必须是单行，包含一个用方括号括起来的逗号分隔列表，按顺序串联四个测试用例的三元组：$[PV_{\\text{naive}}^{(A)}, PV_{\\text{stable}}^{(A)}, \\lvert \\cdot \\rvert^{(A)}, PV_{\\text{naive}}^{(B)}, PV_{\\text{stable}}^{(B)}, \\lvert \\cdot \\rvert^{(B)}, PV_{\\text{naive}}^{(C)}, PV_{\\text{stable}}^{(C)}, \\lvert \\cdot \\rvert^{(C)}, PV_{\\text{naive}}^{(D)}, PV_{\\text{stable}}^{(D)}, \\lvert \\cdot \\rvert^{(D)}]$。", "solution": "对问题进行验证。\n\n步骤1：提取已知条件。\n- 风险中性测度下的现值（$PV$）是贴现现金流的总和。\n- 第 $i$ 期的浮动利率票息由公式 $C_i = (L_i + m)\\,\\alpha_i\\,N$ 给出，其中 $L_i$ 是远期利率，$m$ 是利差，$\\alpha_i$ 是应计分数，$N$ 是名义本金。\n- 贴现因子 $D_i$ 由递归 $D_0 = 1$ 和 $D_i = \\dfrac{D_{i-1}}{1 + L_i \\alpha_i}$（对于 $i = 1,\\dots,T$）导出。\n- 使用朴素估值法的现值是 $PV_{\\text{naive}} = N \\left( \\sum_{i=1}^{T} (L_i + m)\\,\\alpha_i\\,D_i + D_T \\right)$。\n- 任务是实现这种朴素方法和一种代数上等价但数值上更稳定的方法（$PV_{\\text{stable}}$），该方法避免在求和内部直接将 $m$ 加到 $L_i$ 上。\n- 程序必须为四个测试用例计算 $PV_{\\text{naive}}$、$PV_{\\text{stable}}$ 和绝对差值 $\\lvert PV_{\\text{naive}} - PV_{\\text{stable}} \\rvert$。\n- 测试用例A：$N = 1,000,000$，$T = 8$，所有 $i$ 的 $\\alpha_i = 0.25$，$L = [0.021, 0.022, 0.0235, 0.024, 0.025, 0.026, 0.027, 0.028]$，$m = 0.0005$。\n- 测试用例B：$N = 1,000,000,000$，$T = 8$，所有 $i$ 的 $\\alpha_i = 0.25$，$L$ 与测试用例A相同，$m = 1 \\times 10^{-20}$。\n- 测试用例C：$N = 2,000,000$，$T = 8$，所有 $i$ 的 $\\alpha_i = 0.25$，$L = [0.018, 0.019, 0.0195, 0.020, 0.0205, 0.021, 0.0215, 0.022]$，$m = 0$。\n- 测试用例D：$N = 100,000,000$，$T = 40$，所有 $i$ 的 $\\alpha_i = 0.25$，$L_i = 0.015 + 0.0001 \\cdot i$（对于 $i = 1,\\dots,40$），$m = 1 \\times 10^{-12}$。\n- 最终输出格式必须是表示列表的单行字符串，包含串联的结果。\n\n步骤2：使用提取的已知条件进行验证。\n- 该问题在科学上基于金融数学和计算科学的原理。浮动利率票据的估值和浮点算术误差的分析是标准课题。\n- 该问题是适定的。每个测试用例的所有参数和公式都已明确给出，从而可以得到一个唯一的、可计算的解。\n- 该问题是客观的，使用清晰、明确的技术语言陈述。\n- 设定完整且一致，没有缺失信息或矛盾之处。\n- 这些参数虽然是为了说明数值效应（例如，$m = 1 \\times 10^{-20}$）而选择的，但对于一个计算问题是有效的，不代表物理上的不可能性。\n- 结构是合理的，需要推导一个数值稳定的公式，这是数值分析中的一种标准技术。\n\n步骤3：结论与行动。\n问题有效。将开发一个完整的解决方案。\n\n问题的核心是比较两种计算浮动利率债券现值的方法。\n\n方法1：朴素估值法\n第一种方法是所提供公式的直接实现：\n$$\nPV_{\\text{naive}} = N \\left( \\sum_{i=1}^{T} (L_i + m)\\,\\alpha_i\\,D_i + D_T \\right)\n$$\n在这里，对于每个票息期 $i$，在乘法之前，利差 $m$ 被加到远期利率 $L_i$ 上。当 $m$ 远小于 $L_i$ 时，这种加法可能导致浮点精度损失。例如，在标准的双精度算术（IEEE $754$）中，其精度约为 $15$–$17$ 位十进制数，如果 $L_i \\approx 10^{-2}$ 且 $m = 10^{-20}$，则和 $L_i + m$ 在计算上将与 $L_i$ 无法区分。这种现象被称为吸收或灾难性抵消，其中较小的数字实际上被丢失了。\n\n方法2：稳定估值法\n为了构建一个更稳定的方法，我们必须重新排列公式，以避免将 $m$ 直接加到 $L_i$ 上。我们从相同的现值表达式开始，并应用在实数算术中精确的代数变换。\n$$\nPV = N \\left( \\sum_{i=1}^{T} (L_i + m)\\,\\alpha_i\\,D_i + D_T \\right)\n$$\n我们在求和内部展开各项：\n$$\nPV = N \\left( \\sum_{i=1}^{T} L_i\\alpha_i D_i + \\sum_{i=1}^{T} m\\alpha_i D_i + D_T \\right)\n$$\n这种重排将涉及 $L_i$ 的计算与利差 $m$ 的贡献分离开来。为了进一步简化和增强数值稳定性，我们分析 $\\sum_{i=1}^{T} L_i\\alpha_i D_i$ 这一项。贴现因子由递归 $D_i = \\frac{D_{i-1}}{1 + L_i \\alpha_i}$ 定义。重新整理此式可得 $D_i(1 + L_i \\alpha_i) = D_{i-1}$，进而导出 $D_i + L_i \\alpha_i D_i = D_{i-1}$。这提供了关键的恒等式：\n$$\nL_i \\alpha_i D_i = D_{i-1} - D_i\n$$\n将此恒等式代入求和中，会得到一个伸缩级数：\n$$\n\\sum_{i=1}^{T} L_i \\alpha_i D_i = \\sum_{i=1}^{T} (D_{i-1} - D_i) = (D_0 - D_1) + (D_1 - D_2) + \\dots + (D_{T-1} - D_T) = D_0 - D_T\n$$\n根据定义，$D_0 = 1$。因此，求和简化为：\n$$\n\\sum_{i=1}^{T} L_i \\alpha_i D_i = 1 - D_T\n$$\n现在，我们将此结果代回到展开的 $PV$ 表达式中：\n$$\nPV = N \\left( (1 - D_T) + m \\sum_{i=1}^{T} \\alpha_i D_i + D_T \\right)\n$$\n$D_T$ 项相互抵消，得到最终的、数值稳定的公式：\n$$\nPV_{\\text{stable}} = N \\left( 1 + m \\sum_{i=1}^{T} \\alpha_i D_i \\right)\n$$\n这个公式更优越，因为它完全避免了 $L_i$ 和 $m$ 的相加。利差的总贡献是单独计算的，方法是先将贴现的应计分数求和，然后乘以 $m$。这保留了微小利差项的精度，确保其对最终价格的贡献不会因浮点算术的限制而丢失。\n\n每个测试用例的实现将按以下步骤进行：\n1.  确定参数 $N$、$m$、$T$ 以及 $L_i$ 和 $\\alpha_i$ 的数组。\n2.  使用指定的递归计算 $i=0, \\dots, T$ 的贴现因子数组 $D_i$。\n3.  使用第一个公式计算 $PV_{\\text{naive}}$。\n4.  使用推导出的第二个公式计算 $PV_{\\text{stable}}$。\n5.  计算两个结果之间的绝对差值。\n此过程将对所有四个测试用例执行，并将结果格式化为所需的输出字符串。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the floating-rate bond valuation problem for all test cases\n    and prints the results in the specified format.\n    \"\"\"\n\n    def generate_test_cases():\n        \"\"\"\n        Generates and returns the test cases as a list of dictionaries.\n        \"\"\"\n        # Test Case A\n        case_a = {\n            \"N\": 1_000_000.0,\n            \"T\": 8,\n            \"alpha\": np.full(8, 0.25),\n            \"L\": np.array([0.021, 0.022, 0.0235, 0.024, 0.025, 0.026, 0.027, 0.028]),\n            \"m\": 0.0005\n        }\n\n        # Test Case B\n        case_b = {\n            \"N\": 1_000_000_000.0,\n            \"T\": 8,\n            \"alpha\": np.full(8, 0.25),\n            \"L\": np.array([0.021, 0.022, 0.0235, 0.024, 0.025, 0.026, 0.027, 0.028]),\n            \"m\": 1e-20\n        }\n\n        # Test Case C\n        case_c = {\n            \"N\": 2_000_000.0,\n            \"T\": 8,\n            \"alpha\": np.full(8, 0.25),\n            \"L\": np.array([0.018, 0.019, 0.0195, 0.020, 0.0205, 0.021, 0.0215, 0.022]),\n            \"m\": 0.0\n        }\n\n        # Test Case D\n        T_d = 40\n        L_d = np.array([0.015 + 0.0001 * (i + 1) for i in range(T_d)])\n        case_d = {\n            \"N\": 100_000_000.0,\n            \"T\": T_d,\n            \"alpha\": np.full(T_d, 0.25),\n            \"L\": L_d,\n            \"m\": 1e-12\n        }\n\n        return [case_a, case_b, case_c, case_d]\n\n    def calculate_pvs(N, m, L, alpha):\n        \"\"\"\n        Calculates the present value of a floating-rate bond using two different methods.\n\n        Args:\n            N (float): Notional amount.\n            m (float): Margin.\n            L (np.ndarray): Array of forward rates.\n            alpha (np.ndarray): Array of accrual fractions.\n\n        Returns:\n            tuple: A tuple containing (pv_naive, pv_stable, abs_diff).\n        \"\"\"\n        T = len(L)\n        \n        # Calculate discount factors D_i for i=0,...,T\n        # D_0 = 1, D_i = D_{i-1} / (1 + L_i * alpha_i)\n        D = np.empty(T + 1, dtype=np.float64)\n        D[0] = 1.0\n        for i in range(1, T + 1):\n            D[i] = D[i - 1] / (1.0 + L[i - 1] * alpha[i - 1])\n        \n        # We need discount factors D_1, ..., D_T for the sums\n        D_coupon_periods = D[1:]\n\n        # Method 1: Naive PV calculation\n        # PV_naive = N * ( sum_{i=1 to T} (L_i + m) * alpha_i * D_i + D_T )\n        coupon_sum_naive = np.sum((L + m) * alpha * D_coupon_periods)\n        pv_naive = N * (coupon_sum_naive + D[T])\n\n        # Method 2: Stable PV calculation\n        # PV_stable = N * ( 1 + m * sum_{i=1 to T} alpha_i * D_i )\n        margin_sum_stable = np.sum(alpha * D_coupon_periods)\n        pv_stable = N * (1.0 + m * margin_sum_stable)\n\n        # Absolute difference\n        abs_diff = np.abs(pv_naive - pv_stable)\n\n        return pv_naive, pv_stable, abs_diff\n\n    test_cases = generate_test_cases()\n    results = []\n    \n    for case in test_cases:\n        pv_naive, pv_stable, abs_diff = calculate_pvs(\n            N=case[\"N\"], \n            m=case[\"m\"], \n            L=case[\"L\"], \n            alpha=case[\"alpha\"]\n        )\n        results.extend([pv_naive, pv_stable, abs_diff])\n\n    # Format the final output as a comma-separated list in a single line.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}]}