{"hands_on_practices": [{"introduction": "弱式有效市场假说的基石是过去的价格变动无法用于预测未来价格。第一个实践练习将让你通过实施和应用关键的可预测性统计检验，来直接验证这一原则。通过生成和分析你自己模拟的数据，你将获得区分随机、不可预测过程与包含可预测模式过程的实践经验。[@problem_id:2389249]", "id": "2389249", "problem": "考虑一个区块链在等时间间隔内的每字节平均交易费用的离散时间序列。设严格为正的费用水平由 $f_t$ 表示，其中时间索引 $t \\in \\{0,1,2,\\dots,n\\}$，并定义对数费用为 $y_t = \\ln(f_t)$。单步对数回报率为 $r_t = y_t - y_{t-1}$，其中 $t \\in \\{1,2,\\dots,n\\}$。根据弱式有效市场假说（EMH），过程 $\\{r_t\\}$ 是一个关于由过去值生成的信息集的鞅差序列，这意味着 $E[r_t \\mid \\mathcal{I}_{t-1}] = 0$ 并且无法从 $\\{r_{t-1}, r_{t-2}, \\dots\\}$ 进行线性预测（即零线性可预测性）。等价地，在弱式有效市场假说下，$\\{r_t\\}$ 的所有非零滞后自相关均为零，并且基于 $r_{t-1}$ 的 $r_t$ 的最佳线性单步向前预测器的斜率为零。\n\n您的任务是编写一个完整程序，针对以下每个测试用例，根据指定的数据生成过程模拟一个费用序列 $\\{f_t\\}$，计算回报率序列 $\\{r_t\\}$，然后在给定的显著性水平下将该序列分类为弱式有效或无效。一个序列当且仅当以下两个属性都在给定的显著性水平 $\\alpha$ 下得到数据支持时，才必须被分类为弱式有效：(i) 所有滞后 $m$ 阶以内的自相关均为零的联合原假设未被拒绝，以及 (ii) 基于 $r_{t-1}$ 的 $r_t$ 最佳线性预测器中的斜率系数为零的原假设未被拒绝。否则，将该序列分类为非弱式有效。\n\n模拟应按以下方式进行。对于每个测试用例，将初始水平固定为 $f_0 = 100.0$。对于所有随机模拟，使用固定的随机种子 $123456$ 以确保结果是可复现的。有两种过程设定：\n- 对数费用的随机游走（记作 RW）：$y_t = y_{t-1} + \\varepsilon_t$，其中 $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$ 对所有 $t$ 独立，这意味着 $r_t = \\varepsilon_t$。\n- 回报率的一阶自回归（记作 AR1）：$r_t = \\phi r_{t-1} + \\varepsilon_t$，其中 $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$ 对所有 $t$ 独立，且 $y_t = y_{t-1} + r_t$。对于此情况，在收集 $n$ 个保留观测值之前，使用 200 步的“预烧期”（burn-in）并丢弃这些数据，以近似 $\\{r_t\\}$ 的平稳性。对于 RW，不需要预烧期。\n\n对于每个测试用例，在模拟了 $\\{f_t\\}$ 并计算了 $\\{r_t\\}$ 之后，应用在高斯鞅差新息的原假设下的有效统计决策规则，以确定是否在显著性水平 $\\alpha$ 下拒绝这两个属性中的每一个。使用以下测试套件，其中每个用例由元组 $(S, n, \\sigma, \\phi, \\alpha, m)$ 给出，当 $S=\\text{RW}$ 时忽略 $\\phi$：\n- 用例 A: $(\\text{RW},\\, 500,\\, 0.02,\\, 0.0,\\, 0.01,\\, 10)$\n- 用例 B: $(\\text{AR1},\\, 500,\\, 0.02,\\, 0.35,\\, 0.01,\\, 10)$\n- 用例 C: $(\\text{AR1},\\, 80,\\, 0.03,\\, 0.0,\\, 0.01,\\, 8)$\n- 用例 D: $(\\text{AR1},\\, 500,\\, 0.02,\\, -0.5,\\, 0.01,\\, 10)$\n\n您的程序必须输出一行，按顺序包含用例 A 到 D 的四个布尔分类结果，使用方括号括起来、无空格的逗号分隔列表的精确格式，其中每个条目为 True 或 False。例如，要求的格式类似于 [True,False,True,False]。", "solution": "根据弱式有效市场假说（EMH），对数费用的增量 $r_t = y_t - y_{t-1}$ 构成一个关于自然信息流的鞅差序列（MDS）。形式上，这表示为 $E[r_t \\mid \\mathcal{I}_{t-1}] = 0$ 对所有 $t$ 成立，其中 $\\mathcal{I}_{t-1}$ 是由过去观测值生成的 $\\sigma$-代数。该陈述的两个可操作性推论是：(i) 非零滞后的自相关函数为零，以及 (ii) 基于 $r_{t-1}$ 的 $r_t$ 的最佳线性预测器斜率为零。\n\n数据生成。对于随机游走（RW）设定，对数费用遵循 $y_t = y_{t-1} + \\varepsilon_t$，其中 $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$ 且 $r_t = \\varepsilon_t$。对于一阶自回归（AR1）设定，回报率遵循 $r_t = \\phi r_{t-1} + \\varepsilon_t$，其中 $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$ 且 $y_t = y_{t-1} + r_t$。在所有情况下，费用水平为 $f_t = \\exp(y_t)$ 以确保其为正。对于 AR1，通过生成一个 200 步的“预烧期”（burn-in）并丢弃这些数据来缓解初始化效应，这样当 $|\\phi| &lt; 1$ 时，保留的 $n$ 个观测值近似服从平稳分布。所有随机抽样均使用固定的种子 $123456$ 生成，以确保可复现性。\n\n检验属性 (i)：滞后 $m$ 阶以内的联合零自相关。给定一个样本 $\\{r_t\\}_{t=1}^n$，定义中心化回报率 $\\tilde{r}_t = r_t - \\bar{r}$，其中 $\\bar{r} = \\frac{1}{n}\\sum_{t=1}^n r_t$。滞后 $k$ 阶的样本自协方差为 $\\hat{\\gamma}_k = \\frac{1}{n}\\sum_{t=k+1}^n \\tilde{r}_t \\tilde{r}_{t-k}$，滞后零阶的自协方差为 $\\hat{\\gamma}_0 = \\frac{1}{n}\\sum_{t=1}^n \\tilde{r}_t^2$。滞后 $k$ 阶的样本自相关为 $\\hat{\\rho}_k = \\hat{\\gamma}_k / \\hat{\\gamma}_0$。一个将这些自相关汇总至滞后 $m$ 阶的综合统计量是 Ljung–Box 统计量\n$$\nQ = n(n+2)\\sum_{k=1}^m \\frac{\\hat{\\rho}_k^2}{n-k}.\n$$\n在滞后 1 到 $m$ 阶自相关为零且条件同方差的原假设下，$Q$ 渐近服从 $\\chi^2_m$ 分布。决策规则是计算 $p$ 值 $p_{\\text{LB}} = 1 - F_{\\chi^2_m}(Q)$，如果 $p_{\\text{LB}} &lt; \\alpha$，则拒绝原假设。\n\n检验属性 (ii)：最佳线性单步向前预测器中的零斜率。考虑线性模型\n$$\nr_t = \\beta_0 + \\beta_1 r_{t-1} + \\varepsilon_t^{\\ast}, \\quad t=2,\\dots,n,\n$$\n通过普通最小二乘法（OLS）进行估计。设 $X$ 是一个 $(n-1)\\times 2$ 矩阵，包含一列 1 和一列滞后回报率 $r_{t-1}$，设 $y$ 是一个 $(n-1)\\times 1$ 的同期回报率 $r_t$ 向量。OLS 估计量为 $\\hat{\\beta} = (X^{\\top}X)^{-1}X^{\\top}y$。残差方差为 $\\hat{\\sigma}^2 = \\frac{1}{n-1-2}\\sum_{t=2}^n \\hat{\\varepsilon}_t^2$，其中 $\\hat{\\varepsilon}_t = r_t - \\hat{\\beta}_0 - \\hat{\\beta}_1 r_{t-1}$。$\\hat{\\beta}_1$ 的估计方差是 $\\hat{\\sigma}^2 (X^{\\top}X)^{-1}$ 的 $(2,2)$ 元素，记作 $\\widehat{\\mathrm{Var}}(\\hat{\\beta}_1)$。检验统计量为\n$$\nt = \\frac{\\hat{\\beta}_1}{\\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\beta}_1)}},\n$$\n在原假设 $H_0:\\beta_1=0$ 和条件同方差正态误差下，该统计量服从自由度为 $n-3$ 的 Student t 分布。双边 $p$ 值为 $p_{\\text{REG}} = 2\\left(1 - F_{t_{n-3}}(|t|)\\right)$。如果 $p_{\\text{REG}} &lt; \\alpha$，则拒绝原假设。\n\n分类规则。对于每个用例，在给定的 $\\alpha$ 水平下计算 $p_{\\text{LB}}$ 和 $p_{\\text{REG}}$。当且仅当两个原假设都未被拒绝时，即 $p_{\\text{LB}} \\ge \\alpha$ 且 $p_{\\text{REG}} \\ge \\alpha$ 时，才将序列分类为弱式有效。\n\n测试套件参数。每个测试用例由 $(S, n, \\sigma, \\phi, \\alpha, m)$ 指定，当 $S=\\text{RW}$ 时忽略 $\\phi$，并且所有模拟都使用 $f_0=100.0$ 和固定的种子 $123456$：\n- 用例 A: $(\\text{RW},\\, 500,\\, 0.02,\\, 0.0,\\, 0.01,\\, 10)$，代表对数费用是随机游走，其增量为独立同分布的高斯分布，这在期望意义上满足弱式有效市场假说。\n- 用例 B: $(\\text{AR1},\\, 500,\\, 0.02,\\, 0.35,\\, 0.01,\\, 10)$，代表正自相关的回报率，这因其线性可预测性而违反了弱式有效市场假说。\n- 用例 C: $(\\text{AR1},\\, 80,\\, 0.03,\\, 0.0,\\, 0.01,\\, 8)$，代表样本量较小的不相关回报率，作为一个边界类型的用例。\n- 用例 D: $(\\text{AR1},\\, 500,\\, 0.02,\\, -0.5,\\, 0.01,\\, 10)$，代表负自相关的回报率，这因其线性可预测性而违反了弱式有效市场假说。\n\n最终输出格式。您的程序应生成单行输出，其中包含用例 A 到 D 的四个布尔结果，格式为方括号括起来、无空格的逗号分隔列表，例如：[True,False,True,False]。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2, t as student_t\n\ndef ljung_box_pvalue(returns: np.ndarray, m: int) -> float:\n    \"\"\"\n    Compute the Ljung-Box Q statistic p-value for autocorrelations up to lag m.\n    returns: 1D array of returns r_t\n    m: maximum lag to include\n    \"\"\"\n    r = returns.astype(float)\n    n = r.shape[0]\n    if n <= m + 1:\n        # Not enough data; return p-value of 0 to force non-acceptance.\n        return 0.0\n    r_centered = r - r.mean()\n    gamma0 = np.dot(r_centered, r_centered) / n\n    if gamma0 <= 0:\n        # Degenerate variance: treat as non-acceptance.\n        return 0.0\n    Q = 0.0\n    for k in range(1, m + 1):\n        num = np.dot(r_centered[k:], r_centered[:-k]) / n\n        rho_k = num / gamma0\n        Q += rho_k * rho_k / (n - k)\n    Q *= n * (n + 2)\n    p_val = 1.0 - chi2.cdf(Q, df=m)\n    # Numerical guard\n    if p_val < 0.0:\n        p_val = 0.0\n    if p_val > 1.0:\n        p_val = 1.0\n    return p_val\n\ndef ols_predictability_pvalue(returns: np.ndarray) -> float:\n    \"\"\"\n    Test H0: beta1 = 0 in the regression r_t = beta0 + beta1 * r_{t-1} + e_t.\n    Returns the two-sided p-value based on Student t with n-3 degrees of freedom.\n    \"\"\"\n    r = returns.astype(float)\n    n = r.shape[0]\n    # Need at least 3 observations to compute t-stat with df = n-3 >= 1\n    if n < 4:\n        return 0.0\n    y = r[1:]\n    x = r[:-1]\n    X = np.column_stack([np.ones_like(x), x])\n    XtX = X.T @ X\n    # Check for invertibility\n    try:\n        XtX_inv = np.linalg.inv(XtX)\n    except np.linalg.LinAlgError:\n        return 0.0\n    beta_hat = XtX_inv @ (X.T @ y)\n    residuals = y - X @ beta_hat\n    dof = y.shape[0] - X.shape[1]\n    if dof <= 0:\n        return 0.0\n    rss = float(residuals.T @ residuals)\n    sigma2_hat = rss / dof\n    var_beta = sigma2_hat * XtX_inv\n    se_beta1 = np.sqrt(max(var_beta[1, 1], 0.0))\n    if se_beta1 == 0.0:\n        # No variability; return 0 p-value to avoid false acceptance\n        return 0.0\n    t_stat = beta_hat[1] / se_beta1\n    # Two-sided p-value\n    p_val = 2.0 * (1.0 - student_t.cdf(abs(t_stat), df=dof))\n    # Numerical guard\n    if p_val < 0.0:\n        p_val = 0.0\n    if p_val > 1.0:\n        p_val = 1.0\n    return p_val\n\ndef simulate_series(case, rng: np.random.Generator):\n    \"\"\"\n    Simulate fee levels and returns based on the specified test case.\n    case: tuple (S, n, sigma, phi, alpha, m)\n    rng: numpy Generator for reproducibility\n    Returns: returns array r of length n\n    \"\"\"\n    S, n, sigma, phi, alpha, m = case\n    y0 = np.log(100.0)  # initial log-fee\n    if S == \"RW\":\n        # Random walk in log fees: y_t = y_{t-1} + e_t\n        eps = rng.normal(loc=0.0, scale=sigma, size=n)\n        r = eps  # returns are the innovations\n        # Form y and f if needed (not used directly for tests)\n        # y = y0 + np.cumsum(r)\n        return r\n    elif S == \"AR1\":\n        # AR(1) in returns with burn-in for stationarity\n        burn = 200\n        total = n + burn\n        eps = rng.normal(loc=0.0, scale=sigma, size=total)\n        r_full = np.empty(total, dtype=float)\n        r_full[0] = eps[0]\n        for t in range(1, total):\n            r_full[t] = phi * r_full[t - 1] + eps[t]\n        r = r_full[burn:]\n        return r\n    else:\n        raise ValueError(\"Unknown specification S: {}\".format(S))\n\ndef classify_efficiency(case, rng: np.random.Generator) -> bool:\n    \"\"\"\n    Classify a single test case as weak-form efficient (True) or not (False).\n    \"\"\"\n    S, n, sigma, phi, alpha, m = case\n    r = simulate_series(case, rng)\n    # Property (i): joint zero autocorrelations up to lag m\n    p_lb = ljung_box_pvalue(r, m)\n    # Property (ii): zero slope in linear predictability\n    p_reg = ols_predictability_pvalue(r)\n    # Efficient if both nulls are not rejected at level alpha\n    return (p_lb >= alpha) and (p_reg >= alpha)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\"RW\", 500, 0.02, 0.0, 0.01, 10),     # Case A\n        (\"AR1\", 500, 0.02, 0.35, 0.01, 10),   # Case B\n        (\"AR1\", 80, 0.03, 0.0, 0.01, 8),      # Case C\n        (\"AR1\", 500, 0.02, -0.5, 0.01, 10),   # Case D\n    ]\n\n    rng = np.random.default_rng(123456)\n\n    results = []\n    for case in test_cases:\n        result = classify_efficiency(case, rng)\n        results.append(result)\n\n    # Final print statement in the exact required format: booleans without spaces.\n    print(\"[\" + \",\".join(\"True\" if r else \"False\" for r in results) + \"]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"}, {"introduction": "尽管普适的统计检验提供了对市场效率的宏观视角，但金融研究已经识别出一些被称为“异象”的特定且持续的模式。本实践练习将聚焦于其中最著名的一个：动量效应。你将学习如何构建一个量化交易策略来捕捉动量效应，并且至关重要的是，学习如何在风险调整的基础上评估其表现，并在不同的假设市场中比较其强度。[@problem_id:2389238]", "id": "2389238", "problem": "您将执行一项与“动量”异象背景下的有效市场假说 (EMH) 相关的正式测试任务。对于一项资产，其逐期简单收益率的时间序列为 $\\{r_t\\}_{t=1}^T$，表示为十进制小数（例如，百分之一的收益率记为 $0.01$），定义一个回顾窗口为 $L \\in \\mathbb{N}$ 的动量信号和一个波动率调整后的强度指标，如下所示。\n\n- 对于每个时间索引 $t$，$t \\in \\{L+1, \\ldots, T\\}$，定义回顾期总和 $b_t = \\sum_{i=1}^{L} r_{t-i}$ 和信号\n$$\ns_t = \n\\begin{cases}\n+1, & \\text{if } b_t &gt; 0, \\\\\n-1, & \\text{if } b_t &lt; 0, \\\\\n0, & \\text{if } b_t = 0.\n\\end{cases}\n$$\n- 在时间 $t$ 的已实现动量策略收益为 $x_t = s_t \\cdot r_t$。\n- 令 $N = T - L$ 表示非预热期观测值的数量。定义样本均值 $\\mu = \\frac{1}{N} \\sum_{t=L+1}^{T} x_t$ 和总体标准差 $\\sigma = \\sqrt{\\frac{1}{N} \\sum_{t=L+1}^{T} (x_t - \\mu)^2}$。定义波动率调整后的强度（一种类似夏普比率的逐期指标）为\n$$\nS =\n\\begin{cases}\n\\mu / \\sigma, & \\text{if } \\sigma &gt; 0, \\\\\n0, & \\text{if } \\sigma = 0.\n\\end{cases}\n$$\n\n对于每个测试用例，您会获得两个等长的收益率序列：一个代表加密货币，另一个代表传统股票指数。对于每个测试用例，使用相同的 $L$ 计算 $S_{\\text{crypto}}$ 和 $S_{\\text{equity}}$。使用容差 $\\varepsilon = 10^{-12}$，将强度比较结果分类为一个整数：\n- 如果 $S_{\\text{crypto}} &gt; S_{\\text{equity}} + \\varepsilon$（加密货币更强），则输出 $1$\n- 如果 $\\lvert S_{\\text{crypto}} - S_{\\text{equity}} \\rvert \\le \\varepsilon$（在容差范围内相等），则输出 $0$\n- 如果 $S_{\\text{crypto}} &lt; S_{\\text{equity}} - \\varepsilon$（加密货币更弱），则输出 $-1$\n\n所有收益率都是无量纲的，必须作为十进制小数处理，而不是百分比。不使用角度。您的程序必须生成单行输出，其中包含所有测试用例的结果，格式为方括号内以逗号分隔的列表，例如，“[1,0,-1]”。\n\n测试套件：\n- 测试用例 1（理想路径，波动率调整后加密货币动量更强），$L = 2$：\n    - 加密货币收益率 $r^{(C)}$: $(0.02, 0.015, 0.018, 0.017, -0.005, 0.02, 0.019, 0.018, 0.017, 0.016, 0.015, 0.014)$，\n    - 股票收益率 $r^{(E)}$: $(0.005, -0.006, 0.004, -0.005, 0.003, -0.004, 0.002, -0.003, 0.001, -0.002, 0.001, -0.001)$。\n- 测试用例 2（构造相等），$L = 3$：\n    - 加密货币收益率 $r^{(C)}$: $(0.01, -0.005, 0.012, 0.0, 0.008, -0.004, 0.009, -0.003, 0.007, -0.002)$，\n    - 股票收益率 $r^{(E)}$: $(0.01, -0.005, 0.012, 0.0, 0.008, -0.004, 0.009, -0.003, 0.007, -0.002)$。\n- 测试用例 3（加密货币更弱；股票呈趋势性而加密货币交替波动），$L = 2$：\n    - 加密货币收益率 $r^{(C)}$: $(0.03, -0.025, 0.03, -0.025, 0.03, -0.025, 0.03, -0.025)$，\n    - 股票收益率 $r^{(E)}$: $(0.008, 0.009, 0.01, 0.011, 0.012, 0.013, 0.012, 0.011)$。\n- 测试用例 4（边界情况：零波动率），$L = 1$：\n    - 加密货币收益率 $r^{(C)}$: $(0.0, 0.0, 0.0, 0.0)$，\n    - 股票收益率 $r^{(E)}$: $(0.0, 0.0, 0.0, 0.0)$。\n- 测试用例 5（边界情况：最小有效样本），$L = 2$：\n    - 加密货币收益率 $r^{(C)}$: $(0.01, -0.01, 0.02)$，\n    - 股票收益率 $r^{(E)}$: $(0.01, -0.01, 0.02)$。\n\n您的程序应生成单行输出，其中包含结果，格式为方括号内以逗号分隔的列表（例如，“[result1,result2,result3,result4,result5]”）。", "solution": "所述问题已经过严格验证，并被证实是有效的。它在计算金融领域具有科学依据，特别是关于有效市场假说的检验。其定义在数学上是精确的，所提供的数据是自洽且一致的，目标是清晰且可形式化的。不存在矛盾、歧义或违反科学原则之处。因此，我们可以着手构建一个解决方案。\n\n主要目标是为两个给定的资产收益率时间序列（一个用于加密货币，一个用于股票指数）计算一个波动率调整后的动量强度指标（记为 $S$），并对它们进行比较。整个过程将被封装在一个为严格和可重复分析而设计的计算框架内。\n\n解决方案的核心是一个函数，该函数用于为单个收益率序列 $\\{r_t\\}_{t=1}^T$ 和一个指定的回顾窗口 $L \\in \\mathbb{N}$ 计算强度指标 $S$。算法流程如下：\n\n1.  输入是收益率的时间序列（我们表示为一个数值数组）和整数回顾窗口大小 $L$。总时间周期数为 $T$。\n\n2.  计算在非预热期内进行，即时间索引 $t$ 从 $L+1$ 到 $T$。对于每个这样的 $t$，我们首先计算回顾期总和 $b_t$，其定义为前 $L$ 个收益率的总和：\n    $$\n    b_t = \\sum_{i=1}^{L} r_{t-i}\n    $$\n    此操作等同于对收益率序列应用一个滑动窗口求和滤波器。\n\n3.  根据 $b_t$ 的符号，生成一个动量信号 $s_t$。该信号指导策略采取多头 ($+1$)、空头 ($-1$) 或中性 ($0$) 头寸。信号定义为：\n    $$\n    s_t = \\text{sgn}(b_t) = \n    \\begin{cases}\n    +1, & \\text{if } b_t > 0, \\\\\n    -1, & \\text{if } b_t < 0, \\\\\n    0, & \\text{if } b_t = 0.\n    \\end{cases}\n    $$\n\n4.  在时间 $t$ 的已实现动量策略收益（记为 $x_t$）是信号与在时间 $t$ 的实际资产收益率的乘积：\n    $$\n    x_t = s_t \\cdot r_t\n    $$\n    这一步有效地实施了交易策略：从信号方向上的持续运动中获利。\n\n5.  对所有 $t \\in \\{L+1, \\ldots, T\\}$ 重复此过程，生成一个包含 $N = T - L$ 个策略收益的序列 $\\{x_t\\}$。\n\n6.  根据这个策略收益序列，我们计算其样本均值 $\\mu$ 和总体标准差 $\\sigma$。它们由标准公式给出：\n    $$\n    \\mu = \\frac{1}{N} \\sum_{t=L+1}^{T} x_t\n    $$\n    $$\n    \\sigma = \\sqrt{\\frac{1}{N} \\sum_{t=L+1}^{T} (x_t - \\mu)^2}\n    $$\n    题目明确要求使用总体标准差（$1/N$ 归一化）。\n\n7.  最后，计算波动率调整后的强度 $S$。它是一个类似夏普比率的指标，定义为平均策略收益除以其波动率。为零波动率的情况定义了一个特殊条件：\n    $$\n    S =\n    \\begin{cases}\n    \\mu / \\sigma, & \\text{if } \\sigma > 0, \\\\\n    0, & \\text{if } \\sigma = 0.\n    \\end{cases}\n    $$\n    当且仅当所有策略收益 $x_t$ 都相同时，才会出现 $\\sigma=0$ 的情况。这包括 $N=1$ 的边界情况，此时标准差必然为 $0$。\n\n主程序结构遍历每个提供的测试用例。对于每个用例，它调用上述函数两次：一次用于加密货币收益率 $r^{(C)}$ 以计算 $S_{\\text{crypto}}$，另一次用于股票收益率 $r^{(E)}$ 以计算 $S_{\\text{equity}}$。\n\n然后使用数值容差 $\\varepsilon = 10^{-12}$ 对这两个强度指标进行比较，以处理浮点运算的限制。比较得出一个整数分类：\n-   $1$ 如果 $S_{\\text{crypto}} > S_{\\text{equity}} + \\varepsilon$\n-   $-1$ 如果 $S_{\\text{crypto}} < S_{\\text{equity}} - \\varepsilon$\n-   $0$ 如果 $|S_{\\text{crypto}} - S_{\\text{equity}}| \\le \\varepsilon$\n\n将所有测试用例的这些整数结果收集起来，并按照问题陈述中指定的格式化为单个输出字符串。该实现将利用 `numpy` 库中的例程来进行高效的数组操作和统计计算。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by calculating and comparing the volatility-adjusted\n    momentum strength for given asset return series.\n    \"\"\"\n\n    test_cases = [\n        # Test case 1\n        {\n            \"L\": 2,\n            \"r_crypto\": np.array([0.02, 0.015, 0.018, 0.017, -0.005, 0.02, 0.019, 0.018, 0.017, 0.016, 0.015, 0.014]),\n            \"r_equity\": np.array([0.005, -0.006, 0.004, -0.005, 0.003, -0.004, 0.002, -0.003, 0.001, -0.002, 0.001, -0.001]),\n        },\n        # Test case 2\n        {\n            \"L\": 3,\n            \"r_crypto\": np.array([0.01, -0.005, 0.012, 0.0, 0.008, -0.004, 0.009, -0.003, 0.007, -0.002]),\n            \"r_equity\": np.array([0.01, -0.005, 0.012, 0.0, 0.008, -0.004, 0.009, -0.003, 0.007, -0.002]),\n        },\n        # Test case 3\n        {\n            \"L\": 2,\n            \"r_crypto\": np.array([0.03, -0.025, 0.03, -0.025, 0.03, -0.025, 0.03, -0.025]),\n            \"r_equity\": np.array([0.008, 0.009, 0.01, 0.011, 0.012, 0.013, 0.012, 0.011]),\n        },\n        # Test case 4\n        {\n            \"L\": 1,\n            \"r_crypto\": np.array([0.0, 0.0, 0.0, 0.0]),\n            \"r_equity\": np.array([0.0, 0.0, 0.0, 0.0]),\n        },\n        # Test case 5\n        {\n            \"L\": 2,\n            \"r_crypto\": np.array([0.01, -0.01, 0.02]),\n            \"r_equity\": np.array([0.01, -0.01, 0.02]),\n        },\n    ]\n\n    def calculate_strength(returns: np.ndarray, L: int) -> float:\n        \"\"\"\n        Calculates the volatility-adjusted strength (S) for a given series of returns.\n        \n        Args:\n            returns: A numpy array of asset returns.\n            L: The lookback window size.\n\n        Returns:\n            The calculated strength metric S.\n        \"\"\"\n        T = len(returns)\n        if T <= L:\n            # Not enough data for any non-warmup observation.\n            return 0.0\n\n        strategy_returns = []\n        # Loop from t = L+1 to T (using 0-based indexing for t from L to T-1)\n        for t in range(L, T):\n            # Calculate lookback sum b_t = sum of returns from t-L to t-1\n            lookback_sum = np.sum(returns[t-L:t])\n            \n            # Determine signal s_t\n            signal = np.sign(lookback_sum)\n            \n            # Calculate realized momentum return x_t\n            realized_return = signal * returns[t]\n            strategy_returns.append(realized_return)\n\n        x = np.array(strategy_returns)\n        \n        # N is the number of non-warmup observations\n        N = len(x)\n        if N == 0:\n            return 0.0\n            \n        mu = np.mean(x)\n        # sigma is the population standard deviation (ddof=0 is the default in numpy.std)\n        sigma = np.std(x)\n\n        if sigma > 0:\n            S = mu / sigma\n        else:\n            S = 0.0\n            \n        return S\n\n    results = []\n    epsilon = 1e-12\n\n    for case in test_cases:\n        L = case[\"L\"]\n        r_crypto = case[\"r_crypto\"]\n        r_equity = case[\"r_equity\"]\n\n        s_crypto = calculate_strength(r_crypto, L)\n        s_equity = calculate_strength(r_equity, L)\n\n        if s_crypto > s_equity + epsilon:\n            results.append(1)\n        elif s_crypto < s_equity - epsilon:\n            results.append(-1)\n        else:\n            results.append(0)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}, {"introduction": "除了短期可预测性之外，市场是否可能拥有“长期记忆”？最后一个实践练习将介绍赫斯特指数（Hurst exponent），一个用于检测时间序列中长程依赖的强大工具。通过在专门生成的数据上实施经典的重标极差（R/S）分析，你将探索如何区分无记忆的随机游走（$H=0.5$）与具有持久记忆的过程——这是对有效市场假说一个更微妙但更深刻的挑战。[@problem_id:2389272]", "id": "2389272", "problem": "考虑使用赫斯特指数 (Hurst exponent) 检验有效市场假说 (Efficient Market Hypothesis, EMH)。EMH 假说认为，在一个信息有效的市场中，条件期望收益为零，且收益序列不存在长程相关性。在此背景下，我们将通过算法从模拟的收益序列中估计赫斯特指数 $H$，并用它来分类标的市场是否“随机性较弱”，操作化定义为 $H > 0.5$。\n\n基本原理：\n- 在 EMH 假说下，对数收益率的一个典型模型是独立同分布的高斯噪声。累积后，对数价格遵循由布朗运动驱动的鞅的离散时间形式。对于这类序列，赫斯特指数满足 $H = 0.5$。\n- 赫斯特指数 $H$ 可以通过重标极差 (R/S) 统计量来估计。对于一个零均值序列 $\\{x_t\\}_{t=1}^n$，令 $Y_j = \\sum_{i=1}^j (x_i - \\bar{x})$。定义极差 $R(n) = \\max_{1 \\le j \\le n} Y_j - \\min_{1 \\le j \\le n} Y_j$ 和样本标准差 $S(n) = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\bar{x})^2}$。对于长记忆过程，重标极差的期望值满足 $\\mathbb{E}[R(n)/S(n)] \\propto n^H$ 的标度关系。因此，通过绘制不同 $n$ 对应的 $\\log(R(n)/S(n))$ 与 $\\log(n)$ 的关系图，并拟合一条最小二乘直线，其斜率即为 $H$ 的估计值。\n\n模拟设计：\n- 为了在一个受控的、纯数学的环境中检验商品与股票的差异，我们使用参数为 $\\text{ARFIMA}(0,d,0)$ 的自回归分数阶积分移动平均 (Autoregressive Fractionally Integrated Moving Average, ARFIMA) 模型来模拟收益序列。这会产生收益序列\n$$\nr_t \\;=\\; \\sum_{k=0}^{t} w_k \\,\\varepsilon_{t-k}, \\quad \\varepsilon_t \\sim \\mathcal{N}(0,1),\n$$\n其分数阶积分权重由以下公式递归定义：\n$$\nw_0 = 1, \\quad w_k = w_{k-1}\\,\\frac{k-1 + d}{k} \\text{ for } k \\ge 1.\n$$\n对于 $\\text{ARFIMA}(0,d,0)$ 模型，长记忆参数 $d$ 通过 $H = d + 0.5$ 与赫斯特指数相关联。因此，$d = 0$ 对应于 $H = 0.5$ (无长程相关性)，$d > 0$ 对应于持续性 ($H > 0.5$)，而 $d < 0$ 对应于反持续性 ($H < 0.5$)。这种构造是一个经过充分检验且广泛用于长记忆建模的模型，并且是一个纯数学的设定。\n\n待实现的估计器：\n- 给定收益序列 $\\{r_t\\}_{t=1}^{T}$，在多个块大小 $n$（在给定 $T$ 的可行范围内使用 2 的幂）上计算 R/S 统计量，对于每个 $n$，聚合所有不重叠块的 $\\log(R(n)/S(n))$ 的均值，然后通过对 $\\log(R(n)/S(n))$ 与 $\\log(n)$ 进行最小二乘拟合，将所得直线的斜率作为 $H$ 的估计值。分类：当且仅当 $H > 0.5$ 时，判定为“随机性较弱”。\n\n角度单位与物理单位：不适用。\n\n测试套件与答案规范：\n请实现您的程序，以生成以下合成收益序列，为每个序列估计 $H$ 值，然后为每个序列输出一个布尔值，以指示 $H$ 是否大于 0.5。\n\n- 案例 A (类股票，有效市场)：$T = 2048$, $d = 0$, 种子 = 12345。\n- 案例 B (类商品，持续性)：$T = 2048$, $d = 0.2$, 种子 = 24680。\n- 案例 C (类商品，反持续性)：$T = 2048$, $d = -0.2$, 种子 = 13579。\n- 案例 D (类股票，短样本边界)：$T = 256$, $d = 0$, 种子 = 424242。\n- 案例 E (边界附近的弱持续性)：$T = 2048$, $d = 0.05$, 种子 = 2023。\n\n科学真实性说明：\n- $\\text{ARFIMA}(0,d,0)$ 模型是一种标准的长记忆模型；当 $d = 0$ 时，它简化为与 EMH 一致的独立高斯收益。$d > 0$ 的值会引入持续性，$d < 0$ 的值会引入反持续性，从而提供受控的比较。R/S 估计器是一种经典的、从第一性原理出发评估长记忆的非参数方法。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个由方括号括起来的、逗号分隔的结果列表。输出必须按 [案例 A, 案例 B, 案例 C, 案例 D, 案例 E] 的顺序列出布尔值。例如：“[False,True,False,False,True]”。", "solution": "我们推导并实现了一个基于原理的赫斯特指数 $H$ 的估计器，并将其应用于旨在从长程相关性角度代表类股票和类商品行为的模拟收益序列。该设计从有效市场假说 (EMH) 和经典时间序列定义出发。\n\n基本原理：\n1. 有效市场假说 (EMH)：在一个信息有效的市场中，条件期望收益为零，且收益在长时期内不表现出可预测的结构。与 EMH 一致的标准数学模型是均值为零的独立同分布高斯收益 $\\{\\varepsilon_t\\}$。将其聚合为价格，会得到一个类似于布朗运动的离散时间鞅，其特征为 $H = 0.5$。\n\n2. 通过重标极差标度法计算赫斯特指数：对于一个序列 $\\{x_t\\}_{t=1}^n$，定义累积离差 $Y_j = \\sum_{i=1}^j (x_i - \\bar{x})$。重标极差为\n$$\n\\frac{R(n)}{S(n)} \\;=\\; \\frac{\\max_{1\\le j\\le n} Y_j - \\min_{1\\le j\\le n} Y_j}{\\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\bar{x})^2}}.\n$$\n对于具有平稳增量的自相似过程，$\\mathbb{E}[R(n)/S(n)] \\propto n^H$。取对数后，$\\log \\mathbb{E}[R(n)/S(n)] = \\text{常数} + H \\log n$。因此，对不同 $n$ 值的 $\\log(R(n)/S(n))$ 与 $\\log n$ 进行最小二乘拟合，可以估计出 $H$。\n\n3. 长记忆数据生成过程：自回归分数阶积分移动平均模型 $\\text{ARFIMA}(0,d,0)$ 是一种经典的、经过广泛验证的、以纯数学方式编码长程相关性的方法。设新息为 $\\varepsilon_t \\sim \\mathcal{N}(0,1)$，分数阶差分参数为 $d$，则收益可以写成分数阶移动平均的形式\n$$\nr_t = \\sum_{k=0}^{t} w_k \\,\\varepsilon_{t-k},\n$$\n其中权重满足\n$$\nw_0 = 1, \\qquad w_k = w_{k-1}\\,\\frac{k - 1 + d}{k} \\quad \\text{for } k \\ge 1.\n$$\n该表示实现了 $(1 - L)^{-d}\\varepsilon_t$，其中 $L$ 是滞后算子，其在零频率附近的渐近谱密度表现为 $f(\\lambda) \\sim C |\\lambda|^{-2d}$（其中 $C$ 为某个常数），这是长记忆的标志。对于 $\\text{ARFIMA}(0,d,0)$ 模型，赫斯特指数通过 $H = d + 0.5$ 与 $d$ 相关联。\n因此，$d = 0$ 意味着 $H = 0.5$（无长程相关性，与 EMH 一致），$d > 0$ 意味着 $H > 0.5$（持续性或“随机性较弱”），而 $d < 0$ 意味着 $H < 0.5$（反持续性或均值回归）。\n\n算法设计：\n- 步骤 1：对于每个测试案例，使用指定的 $T$、$d$ 和随机种子，通过 $\\text{ARFIMA}(0,d,0)$ 模型生成一个收益序列 $\\{r_t\\}_{t=1}^{T}$。权重 $\\{w_k\\}$ 通过递推公式 $w_0 = 1, w_k = w_{k-1}\\frac{k-1+d}{k}$ 计算。通过将 $\\{\\varepsilon_t\\}$ 与 $\\{w_k\\}$ 进行卷积来构造该序列；为提高计算效率和数值稳定性，使用基于快速傅里叶变换 (FFT) 的卷积。这维持了一个纯数学的设置，并通过固定的种子保证了可复现性。\n- 步骤 2：使用重标极差法从 $\\{r_t\\}$ 中估计赫斯特指数 $H$。将序列划分为大小为 $n$ 的不重叠块，其中块大小 $n$ 在一个网格中选取，该网格由 2 的幂组成，满足 $n \\in \\{2^3, 2^4, \\dots\\}$ 且 $n$ 与 $T$ 相比不能太大（为保证稳定性，最大取到大约 $T/8$）。对于每个 $n$，计算所有块的 $\\log(R(n)/S(n))$ 的平均值。通过最小二乘法对数据点对 $(\\log n, \\log \\overline{R(n)/S(n)})$ 进行线性拟合；所得直线的斜率即为估计值 $\\widehat{H}$。\n- 步骤 3：当且仅当 $\\widehat{H} > 0.5$ 时，将每个序列分类为“随机性较弱”。\n\n工作原理：\n- 在 EMH 假说下 ($d = 0$)，随着 $T$ 增大，$\\widehat{H}$ 会集中在 0.5 附近，反映了长记忆的缺失。当 $d > 0$ 时，长记忆特性意味着对数-对数 R/S 图会向上倾斜，从而得到 $\\widehat{H} > 0.5$。反之，对于 $d < 0$，该图会向下倾斜，导致 $\\widehat{H} < 0.5$。\n- 该方法直接源于长记忆过程的标度性质，除了 R/S 分析和 ARFIMA 权重的定义属性外，不依赖任何捷径公式。\n\n测试套件详情：\n- 案例 A：$T = 2048$, $d = 0$, 种子 = 12345 (类股票，与 EMH 一致)。\n- 案例 B：$T = 2048$, $d = 0.2$, 种子 = 24680 (类商品，持续性)。\n- 案例 C：$T = 2048$, $d = -0.2$, 种子 = 13579 (类商品，反持续性)。\n- 案例 D：$T = 256$, $d = 0$, 种子 = 424242 (短样本类股票边界)。\n- 案例 E：$T = 2048$, $d = 0.05$, 种子 = 2023 ($H = 0.5$ 边界附近的弱持续性)。\n\n预期定性结果：\n- 案例 A 和案例 D 应产生接近 0.5 的 $\\widehat{H}$，根据“$H > 0.5$”规则，输出 False。\n- 案例 B 应得到显著大于 0.5 的 $\\widehat{H}$，输出 True。\n- 案例 C 应得到小于 0.5 的 $\\widehat{H}$，输出 False。\n- 案例 E 应得到略大于 0.5 的 $\\widehat{H}$，输出 True，从而测试在边界附近的判别能力。\n\n程序输出规范：\n- 输出单行，包含一个用方括号括起来的、逗号分隔的布尔值列表，顺序为 [案例 A, 案例 B, 案例 C, 案例 D, 案例 E]，编码了对每个案例“$H > 0.5$”的决策。不应打印任何额外文本。\n\n这个端到端的设计从 EMH 作为基本概念开始，采用经过充分检验的长记忆模型生成数据，并使用经典的重标极差法来估计和分类 $H$，其方式是完全自洽且可通过计算验证的。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef fractional_integration_weights(d: float, n: int) -> np.ndarray:\n    \"\"\"\n    Compute fractional integration weights w_k for k=0..n-1\n    using the recursion: w_0 = 1, w_k = w_{k-1} * (k-1 + d) / k.\n    \"\"\"\n    w = np.empty(n, dtype=float)\n    w[0] = 1.0\n    for k in range(1, n):\n        w[k] = w[k - 1] * ((k - 1) + d) / k\n    return w\n\ndef arfima0d0_returns(n: int, d: float, seed: int) -> np.ndarray:\n    \"\"\"\n    Generate ARFIMA(0,d,0) returns via FFT-based convolution of white noise\n    with fractional integration weights.\n\n    r_t = sum_{k=0}^t w_k * eps_{t-k}\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    eps = rng.normal(loc=0.0, scale=1.0, size=n)\n    w = fractional_integration_weights(d, n)\n\n    # Convolution via FFT to compute r = w * eps (causal, length n)\n    conv_len = 1\n    target_len = 2 * n - 1\n    # Next power of two for efficiency\n    while conv_len < target_len:\n        conv_len <<= 1\n\n    E = np.fft.rfft(eps, n=conv_len)\n    W = np.fft.rfft(w, n=conv_len)\n    r_full = np.fft.irfft(E * W, n=conv_len)\n    r = r_full[:n]\n\n    return r\n\ndef hurst_rs(x: np.ndarray) -> float:\n    \"\"\"\n    Estimate Hurst exponent H using the Rescaled Range (R/S) method.\n    Works on a one-dimensional numpy array x (e.g., returns).\n    \"\"\"\n    x = np.asarray(x, dtype=float)\n    N = x.size\n\n    # Choose window sizes as powers of 2: 8 up to N//8 (inclusive if power-of-two)\n    scales = []\n    n = 8\n    while n <= max(8, N // 8):\n        scales.append(n)\n        n *= 2\n\n    log_n = []\n    log_RS = []\n\n    for n in scales:\n        K = N // n  # number of non-overlapping blocks\n        if K < 1:\n            continue\n        RS_vals = []\n        for k in range(K):\n            seg = x[k * n:(k + 1) * n]\n            m = seg.mean()\n            y = np.cumsum(seg - m)\n            R = y.max() - y.min()\n            S = seg.std(ddof=1)\n            if S > 0:\n                RS_vals.append(R / S)\n        if len(RS_vals) > 0:\n            log_n.append(np.log(n))\n            log_RS.append(np.log(np.mean(RS_vals)))\n\n    if len(log_n) < 2:\n        # Not enough scales to fit a line; return NaN\n        return float(\"nan\")\n\n    # Linear fit: log(R/S) = a + H * log(n)\n    slope, _ = np.polyfit(log_n, log_RS, 1)\n    return float(slope)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (label, T, d, seed)\n    test_cases = [\n        (\"Case A: equity-like, efficient\", 2048, 0.0, 12345),\n        (\"Case B: commodity-like, persistent\", 2048, 0.2, 24680),\n        (\"Case C: commodity-like, anti-persistent\", 2048, -0.2, 13579),\n        (\"Case D: equity-like, short sample\", 256, 0.0, 424242),\n        (\"Case E: mild persistence near boundary\", 2048, 0.05, 2023),\n    ]\n\n    results = []\n    for _label, T, d, seed in test_cases:\n        returns = arfima0d0_returns(T, d, seed)\n        H = hurst_rs(returns)\n        # Classification: less random if H > 0.5\n        is_less_random = (H > 0.5)\n        results.append(is_less_random)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join('True' if r else 'False' for r in results)}]\")\n\nsolve()\n```"}]}