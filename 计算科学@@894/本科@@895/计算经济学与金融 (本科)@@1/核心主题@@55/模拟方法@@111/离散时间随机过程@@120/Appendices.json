{"hands_on_practices": [{"introduction": "在金融领域，公司的信用评级会随着其经营状况动态变化。我们可以将这些评级（如 'AAA', 'AA', 'BBB'）看作一个系统的离散状态，而评级之间的转换则可以用马尔可夫链来完美地建模。[@problem_id:2388997] 这个练习将指导你如何从观测到的评级变化序列中估计状态转移矩阵 $P$，并进一步计算出系统在长期来看的稳定状态分布 $\\pi$，这对于风险评估和金融稳定性的理解至关重要。", "id": "2388997", "problem": "考虑一个离散时间的信用评级系统，该系统被建模为在有限状态空间上的一阶马尔可夫链。状态空间有序表示为 $S=\\{\\text{AAA},\\text{AA},\\text{A},\\text{BBB},\\text{Default}\\}$，我们分别将其索引为 $0,1,2,3,4$。您观测到一个时间有序的评级序列 $\\{X_t\\}_{t=0}^{T}$，其取值于 $S$。令 $N_{ij}$ 表示在观测序列中从状态 $i$ 到状态 $j$ 的一步转移计数，即 $N_{ij}=\\#\\{t \\in \\{0,\\ldots,T-1\\}\\,:\\,X_t=i,\\,X_{t+1}=j\\}$。\n\n您必须使用伪计数 $\\alpha=1$ 的 Laplace 平滑最大似然估计来估计 $5\\times 5$ 的转移概率矩阵 $P=\\left[P_{ij}\\right]$。具体而言，对于每个 $i\\in\\{0,1,2,3,4\\}$ 和 $j\\in\\{0,1,2,3,4\\}$，定义\n$$\n\\widehat{P}_{ij}=\\frac{N_{ij}+\\alpha}{\\sum_{k=0}^{4} N_{ik}+5\\alpha},\n$$\n其中 $\\alpha=1$。这会得到一个元素严格为正的行随机矩阵。\n\n计算长期（平稳）分布 $\\pi$，它是满足以下条件的唯一非负元素行向量\n$$\n\\pi \\widehat{P}=\\pi,\\quad \\sum_{i=0}^{4}\\pi_i=1.\n$$\n以指定状态顺序 $[\\pi_{\\text{AAA}},\\pi_{\\text{AA}},\\pi_{\\text{A}},\\pi_{\\text{BBB}},\\pi_{\\text{Default}}]$ 的十进制数列表形式报告平稳分布，每个数值四舍五入到六位小数。\n\n使用以下观测序列的测试套件（每个序列是 $S$ 中的标签列表）：\n\n- 测试用例 1（包含升级和降级的一般情况）：\n  $[\\text{BBB},\\text{A},\\text{AA},\\text{AAA},\\text{AA},\\text{A},\\text{BBB},\\text{A},\\text{AA},\\text{AAA},\\text{AA},\\text{A},\\text{BBB},\\text{A},\\text{AA},\\text{AAA},\\text{AA},\\text{A},\\text{BBB},\\text{Default},\\text{A},\\text{AA},\\text{AAA},\\text{AA},\\text{A},\\text{BBB},\\text{A},\\text{AA},\\text{AAA},\\text{AA},\\text{A},\\text{BBB}]$。\n\n- 测试用例 2（信息最少的边界情况）：\n  $[\\text{A},\\text{A}]$。\n\n- 测试用例 3（评级集中于高级别的边缘情况）：\n  $[\\text{AAA},\\text{AA},\\text{AAA},\\text{AAA},\\text{AA},\\text{A},\\text{AAA},\\text{AAA},\\text{AAA},\\text{AA},\\text{A},\\text{AAA},\\text{AAA},\\text{AAA},\\text{AAA},\\text{AAA}]$。\n\n对于每个测试用例，您必须：\n1. 对所有条目使用 $\\alpha=1$ 构建平滑估计量 $\\widehat{P}$。\n2. 计算满足 $\\pi \\widehat{P}=\\pi$ 和 $\\sum_i \\pi_i=1$ 的平稳分布 $\\pi$。\n3. 将 $\\pi$ 的每个分量四舍五入到六位小数。\n\n最终输出格式：您的程序应生成单行输出，其中包含所有三个测试用例的结果，格式为一个由方括号括起来的逗号分隔列表，其中每个元素本身是按指定状态顺序排列的平稳分布的列表表示。例如，一个可接受的格式是\n$[\\,[\\pi^{(1)}_{\\text{AAA}},\\ldots,\\pi^{(1)}_{\\text{Default}}],[\\pi^{(2)}_{\\text{AAA}},\\ldots,\\pi^{(2)}_{\\text{Default}}],[\\pi^{(3)}_{\\text{AAA}},\\ldots,\\pi^{(3)}_{\\text{Default}}]\\,]$，\n每个数字都四舍五入到六位小数。此问题中没有物理单位、角度或百分比；所有输出都必须是十进制数。", "solution": "所提出的问题是计算统计学和随机过程领域一个有效的练习。它具有科学依据，提法明确且客观。我们将给出完整的解答。\n\n该问题要求我们估计一个离散时间一阶马尔可夫链的平稳分布。状态空间给定为 $S=\\{\\text{AAA}, \\text{AA}, \\text{A}, \\text{BBB}, \\text{Default}\\}$，我们将分别用整数 $i \\in \\{0, 1, 2, 3, 4\\}$ 对其进行索引。我们得到一个观测时间序列 $\\{X_t\\}_{t=0}^{T}$。\n\n首先，我们必须估计转移概率矩阵，记为 $P = [P_{ij}]$，其中 $P_{ij} = \\mathbb{P}(X_{t+1}=j | X_t=i)$。问题指定使用 Laplace 平滑最大似然估计量。这是一种贝叶斯估计方法，其中对转移矩阵的各行施加了狄利克雷先验。对于给定的行 $i$，概率向量 $[P_{i0}, \\dots, P_{i4}]$ 上的先验是一个集中度参数为 $\\alpha$ 的对称狄利克雷分布。\n\n令 $N_{ij}$ 为序列中从状态 $i$ 到状态 $j$ 观测到的一步转移数量。平滑估计量 $\\widehat{P}_{ij}$ 的公式给出为：\n$$\n\\widehat{P}_{ij} = \\frac{N_{ij} + \\alpha}{\\sum_{k=0}^{4} N_{ik} + |S|\\alpha}\n$$\n其中 $|S|$ 是状态数，即 $5$。问题指定伪计数 $\\alpha=1$。令 $N_i = \\sum_{k=0}^{4} N_{ik}$ 为观测到的从状态 $i$ 出发的总转移数。该估计量简化为：\n$$\n\\widehat{P}_{ij} = \\frac{N_{ij} + 1}{N_i + 5}\n$$\n这个过程确保了估计的转移矩阵 $\\widehat{P}$ 中的每个元素都是严格为正的，即对于所有 $i, j \\in S$，都有 $\\widehat{P}_{ij} > 0$。一个转移矩阵所有元素都为正的马尔可夫链被称为正则马尔可夫链。有限状态空间上的正则马尔可夫链的一个关键性质是它是遍历的，并且拥有唯一的平稳分布。\n\n平稳分布是一个行向量 $\\pi = [\\pi_0, \\pi_1, \\pi_2, \\pi_3, \\pi_4]$，它满足两个条件：\n$1.$ $\\pi \\widehat{P} = \\pi$\n$2.$ $\\sum_{i=0}^{4} \\pi_i = 1$\n\n第一个条件 $\\pi \\widehat{P} = \\pi$ 意味着 $\\pi$ 是矩阵 $\\widehat{P}$ 的一个左特征向量，其对应的特征值为 $\\lambda=1$。这可以改写为一个齐次线性方程组：\n$$\n\\pi (\\widehat{P} - I) = \\mathbf{0}\n$$\n其中 $I$ 是 $5 \\times 5$ 的单位矩阵，$\\mathbf{0}$ 是一个零行向量。以转置形式表示，即为 $(\\widehat{P}^T - I^T) \\pi^T = \\mathbf{0}^T$，或者更简单地写为 $(\\widehat{P}^T - I) \\pi^T = \\mathbf{0}$。\n\n由于 $\\lambda=1$ 是任何行随机矩阵的特征值，矩阵 $(\\widehat{P}^T - I)$ 是奇异的，其零空间是非平凡的。对于正则马尔可夫链，对应于 $\\lambda=1$ 的特征空间维数为 1。因此，方程组 $(\\widehat{P}^T - I) \\pi^T = \\mathbf{0}$ 的解空间维数为 1。为了找到唯一的平稳分布 $\\pi$，我们必须施加归一化条件 $\\sum_{i=0}^{4} \\pi_i = 1$。\n\n在数值上，我们可以通过构造一个线性方程组来求解。我们从 $(\\widehat{P}^T - I) \\pi^T = \\mathbf{0}$ 中取出前 $|S|-1=4$ 个线性方程，并加上归一化方程。令 $A$ 是一个矩阵，其前 4 行是 $(\\widehat{P}^T - I)$ 的前 4 行，其最后一行是全 1 向量。令 $b$ 是一个前 4 个元素为 0、最后一个元素为 1 的列向量。待解的方程组是：\n$$\nA \\pi^T = b\n$$\n解由 $\\pi^T = A^{-1}b$ 给出。解的存在性和唯一性由 $\\widehat{P}$ 的正则性保证。\n\n我们将对三个测试用例中的每一个应用此过程。\n\n**步骤 1：状态映射与转移计数**\n对于每个测试序列，我们将字符串标签映射到整数索引 $\\{0, 1, 2, 3, 4\\}$。然后，我们遍历长度为 $T+1$ 的序列来计算 $T$ 次转移，并填充 $5 \\times 5$ 的计数矩阵 $N = [N_{ij}]$。\n\n**步骤 2：转移矩阵估计**\n使用计数矩阵 $N$ 和 $\\alpha=1$，我们通过公式 $\\widehat{P}_{ij} = (N_{ij} + 1) / (N_i + 5)$ 计算平滑转移矩阵 $\\widehat{P}$。\n\n**步骤 3：平稳分布计算**\n我们如上所述，从 $\\widehat{P}^T$ 构造矩阵 $A$ 并构造向量 $b = [0, 0, 0, 0, 1]^T$。然后我们使用标准的线性代数求解器求解线性方程组 $A \\pi^T = b$ 以得到 $\\pi^T$。\n\n**步骤 4：格式化**\n按要求将结果向量 $\\pi$ 的分量四舍五入到六位小数。最终输出是一个列表，其中包含每个测试用例的四舍五入后的平稳分布向量。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n\n    state_map = {'AAA': 0, 'AA': 1, 'A': 2, 'BBB': 3, 'Default': 4}\n    num_states = len(state_map)\n    alpha = 1.0\n\n    test_cases = [\n        ['BBB','A','AA','AAA','AA','A','BBB','A','AA','AAA','AA','A','BBB','A','AA','AAA','AA','A','BBB','Default','A','AA','AAA','AA','A','BBB','A','AA','AAA','AA','A','BBB'],\n        ['A','A'],\n        ['AAA','AA','AAA','AAA','AA','A','AAA','AAA','AAA','AA','A','AAA','AAA','AAA','AAA','AAA']\n    ]\n\n    all_results = []\n\n    for sequence in test_cases:\n        # Step 1: Count transitions\n        counts = np.zeros((num_states, num_states), dtype=int)\n        int_sequence = [state_map[s] for s in sequence]\n        \n        for i in range(len(int_sequence) - 1):\n            from_state = int_sequence[i]\n            to_state = int_sequence[i+1]\n            counts[from_state, to_state] += 1\n\n        # Step 2: Estimate smoothed transition matrix P_hat\n        p_hat = np.zeros((num_states, num_states), dtype=float)\n        row_totals = np.sum(counts, axis=1)\n        \n        for i in range(num_states):\n            denominator = row_totals[i] + num_states * alpha\n            for j in range(num_states):\n                numerator = counts[i, j] + alpha\n                p_hat[i, j] = numerator / denominator\n\n        # Step 3: Compute the stationary distribution pi\n        # We need to solve pi * P_hat = pi, or pi * (P_hat - I) = 0,\n        # which is equivalent to (P_hat^T - I^T) * pi^T = 0^T.\n        # Let A = P_hat^T - I. We solve for the null space of A.\n        # We replace the last equation with the normalization condition sum(pi) = 1.\n        \n        A = (p_hat.T - np.identity(num_states))\n        A[-1, :] = 1.0  # Last row is for sum(pi_i) = 1\n        \n        b = np.zeros(num_states)\n        b[-1] = 1.0  # Corresponds to sum(pi_i) = 1\n        \n        try:\n            # Solve the linear system A * pi^T = b\n            pi = np.linalg.solve(A, b)\n            \n            # Ensure non-negativity and re-normalize for robustness\n            pi[pi < 0] = 0\n            pi /= np.sum(pi)\n\n        except np.linalg.LinAlgError:\n            # Fallback for singular matrix if something unexpected happens\n            # For a regular P_hat, this shouldn't be reached.\n            # We can use eigenvector method as a backup.\n            # Find the right eigenvector of P_hat.T for eigenvalue 1\n            eigenvalues, eigenvectors = np.linalg.eig(p_hat.T)\n            # Find the eigenvector corresponding to eigenvalue 1\n            idx = np.argmin(np.abs(eigenvalues - 1.0))\n            pi = np.real(eigenvectors[:, idx])\n            # Normalize to get the probability distribution\n            pi = pi / np.sum(pi)\n\n        # Step 4: Round and format the result\n        rounded_pi = np.round(pi, 6).tolist()\n        all_results.append(rounded_pi)\n\n    # Final print statement in the exact required format.\n    # The default str() representation of a list of lists works. e.g., [[...], [...]]\n    print(str(all_results).replace(\" \", \"\"))\n\n\nsolve()\n```"}, {"introduction": "任何一个随机过程的演变，都可以被看作是一个可预测的趋势和一个纯粹随机的“意外”或“新闻”的总和。杜布-迈耶（Doob-Meyer）分解定理为这一直观想法提供了严格的数学基础，其中不可预测的部分是一个鞅（martingale），这是金融理论中“公平游戏”的核心概念。[@problem_id:2388954] 在这个练习中，你将对一个常见的自回归（AR(1)）过程 $X_t$ 进行这种分解，从而亲手分离出其可预测成分 $A_t$ 和鞅成分 $M_t$，深刻理解时间序列的内在结构。", "id": "2388954", "problem": "给定一个离散时间、实值的适应过程，该过程由一个1阶自回归（AR(1)）模型定义。对于每个测试用例，该过程由参数 $\\mu$、$\\phi$、$\\sigma$、一个初始值 $X_0$ 和一个时间范围 $T$ 指定。其动态过程为\n$$\nX_t \\;=\\; \\mu \\;+\\; \\phi\\,X_{t-1} \\;+\\; \\varepsilon_t,\\quad t=1,2,\\dots,T,\n$$\n其中 $\\{\\varepsilon_t\\}_{t\\ge 1}$ 是独立同分布的高斯新息，且 $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$，滤是自然滤 $\\mathcal{F}_t=\\sigma(X_0,\\varepsilon_1,\\dots,\\varepsilon_t)$。\n\n对于每个测试用例：\n- 使用指定的参数和给定的随机种子初始化伪随机数生成器，模拟一条样本路径 $\\{X_t\\}_{t=0}^T$。将 $\\varepsilon_t$ 作为均值为0、标准差为 $\\sigma$ 的独立高斯随机变量进行抽取。\n- 数值计算 $\\{X_t\\}$ 的离散时间Doob–Meyer（Doob）分解，得到过程 $\\{M_t\\}$ 和 $\\{A_t\\}$，使得\n$$\nX_t \\;=\\; X_0 \\;+\\; M_t \\;+\\; A_t,\\quad M_0=0,\\;A_0=0,\n$$\n其中 $\\{M_t\\}$ 是关于 $\\{\\mathcal{F}_t\\}$ 的鞅，$\\{A_t\\}$ 是关于 $\\{\\mathcal{F}_t\\}$ 的可预测过程。\n- 报告该测试用例的一对终值 $[A_T, M_T]$。\n\n测试套件：\n- 用例1（一般非鞅）：$\\mu=0.5$，$\\phi=0.8$，$\\sigma=1.0$， $X_0=0.7$， $T=12$， 种子 $=314159$。\n- 用例2（鞅边界）：$\\mu=0.0$，$\\phi=1.0$，$\\sigma=0.8$， $X_0=1.2$， $T=10$， 种子 $=271828$。\n- 用例3（确定性边缘情况）：$\\mu=0.1$，$\\phi=0.9$，$\\sigma=0.0$， $X_0=-0.3$， $T=15$， 种子 $=42$。\n- 用例4（带漂移的单位根）：$\\mu=-0.2$，$\\phi=1.0$，$\\sigma=0.5$， $X_0=0.0$， $T=8$， 种子 $=7$。\n\n你的程序必须：\n- 对每个用例，使用提供的种子精确模拟一条路径。\n- 计算与关于自然滤的离散时间Doob分解定义一致的终值 $A_T$ 和 $M_T$。\n- 将报告的每个数字四舍五入到六位小数。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表。每个元素必须是对应测试用例的双元素列表 $[A_T, M_T]$，顺序与上文相同。例如，整体输出应类似于\n\"[ [a1,m1],[a2,m2],[a3,m3],[a4,m4] ]\"\n但每个 $a_i$ 和 $m_i$ 都需替换为相应的四舍五入后的数值。", "solution": "在尝试给出解决方案之前，需对问题陈述进行验证。\n\n### 步骤1：提取已知条件\n- **过程动态**：一个离散时间1阶自回归（AR(1)）模型由 $X_t = \\mu + \\phi X_{t-1} + \\varepsilon_t$ 给出，其中 $t=1, 2, \\dots, T$。\n- **初始值**：过程从一个给定值 $X_0$ 开始。\n- **新息**：$\\{\\varepsilon_t\\}_{t \\ge 1}$ 是一个独立同分布（i.i.d.）随机变量序列，且 $\\varepsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$。\n- **滤**：自然滤为 $\\mathcal{F}_t = \\sigma(X_0, \\varepsilon_1, \\dots, \\varepsilon_t)$。\n- **分解**：过程 $\\{X_t\\}$ 将被分解为 $X_t = X_0 + M_t + A_t$，其中 $\\{M_t\\}$ 是一个鞅，$\\{A_t\\}$ 是一个关于 $\\{\\mathcal{F}_t\\}$ 的可预测过程，且 $M_0 = A_0 = 0$。\n- **任务**：对于给定的样本路径，找出终值 $[A_T, M_T]$。\n- **测试用例**：\n    - 用例1：$\\mu=0.5$, $\\phi=0.8$, $\\sigma=1.0$, $X_0=0.7$, $T=12$, 种子 $=314159$。\n    - 用例2：$\\mu=0.0$, $\\phi=1.0$, $\\sigma=0.8$, $X_0=1.2$, $T=10$, 种子 $=271828$。\n    - 用例3：$\\mu=0.1$, $\\phi=0.9$, $\\sigma=0.0$, $X_0=-0.3$, $T=15$, 种子 $=42$。\n    - 用例4：$\\mu=-0.2$, $\\phi=1.0$, $\\sigma=0.5$, $X_0=0.0$, $T=8$, 种子 $=7$。\n- **输出要求**：报告每个用例的 $[A_T, M_T]$，数值四舍五入到六位小数，并采用指定的列表的列表格式。\n\n### 步骤2：使用提取的已知条件进行验证\n- **科学依据**：该问题建立在离散时间随机过程的基本概念之上。AR(1)模型是线性随机过程的典型例子，而Doob-Meyer分解是鞅论的基石定理。该问题在科学和数学上是合理的。\n- **适定性**：该问题是适定的。对于任何适应过程，Doob-Meyer分解是唯一的。所有参数，包括每次模拟的随机种子，都已指定，确保所需的计算能得出一个单一、可验证的结果。\n- **客观性**：问题以精确、客观的数学语言陈述，没有歧义或主观内容。\n\n### 步骤3：结论与行动\n该问题有效。这是一个基于既定数学原理、定义明确的计算任务。将提供解决方案。\n\n### 基于原理的解决方案设计\n\n对于一个离散时间适应过程 $\\{X_t\\}_{t \\ge 0}$，Doob-Meyer分解指出，它可以唯一地写成 $X_t = X_0 + M_t + A_t$，其中 $\\{M_t\\}_{t \\ge 0}$ 是一个鞅，$\\{A_t\\}_{t \\ge 0}$ 是一个可预测过程，且 $M_0 = A_0 = 0$。\n\n该分解是根据过程增量 $\\Delta X_t = X_t - X_{t-1}$ 构建的。每个增量被分解为其可预测部分和一个鞅差：\n$$\n\\Delta X_t = \\Delta A_t + \\Delta M_t\n$$\n其中 $\\Delta A_t = A_t - A_{t-1}$ 且 $\\Delta M_t = M_t - M_{t-1}$。\n\n根据定义，可预测过程的增量 $\\Delta A_t$ 是过程增量在前一时刻信息下的条件期望：\n$$\n\\Delta A_t = \\mathbb{E}[\\Delta X_t | \\mathcal{F}_{t-1}] = \\mathbb{E}[X_t - X_{t-1} | \\mathcal{F}_{t-1}]\n$$\n鞅分量的增量 $\\Delta M_t$ 是增量中的新息或“意外”部分：\n$$\n\\Delta M_t = \\Delta X_t - \\Delta A_t = (X_t - X_{t-1}) - \\mathbb{E}[X_t - X_{t-1} | \\mathcal{F}_{t-1}]\n$$\n根据构造，$\\mathbb{E}[\\Delta M_t | \\mathcal{F}_{t-1}] = 0$，这是鞅差序列的定义属性。\n\n对于给定的AR(1)过程，$X_t = \\mu + \\phi X_{t-1} + \\varepsilon_t$，其增量为：\n$$\n\\Delta X_t = X_t - X_{t-1} = (\\mu + \\phi X_{t-1} + \\varepsilon_t) - X_{t-1} = \\mu + (\\phi - 1)X_{t-1} + \\varepsilon_t\n$$\n我们现在计算条件期望以求得 $\\Delta A_t$：\n$$\n\\Delta A_t = \\mathbb{E}[\\mu + (\\phi - 1)X_{t-1} + \\varepsilon_t | \\mathcal{F}_{t-1}]\n$$\n利用期望的线性性质和条件期望的属性：\n1.  $\\mu$ 是一个常数，所以 $\\mathbb{E}[\\mu | \\mathcal{F}_{t-1}] = \\mu$。\n2.  $X_{t-1}$ 在时刻 $t-1$ 是已知的，因此它是 $\\mathcal{F}_{t-1}$-可测的。所以 $\\mathbb{E}[(\\phi - 1)X_{t-1} | \\mathcal{F}_{t-1}] = (\\phi - 1)X_{t-1}$。\n3.  新息 $\\varepsilon_t$ 独立于过去的滤 $\\mathcal{F}_{t-1} = \\sigma(X_0, \\varepsilon_1, \\dots, \\varepsilon_{t-1})$ 且均值为零。因此，$\\mathbb{E}[\\varepsilon_t | \\mathcal{F}_{t-1}] = \\mathbb{E}[\\varepsilon_t] = 0$。\n\n综合这些结果，可得出可预测过程的增量：\n$$\n\\Delta A_t = \\mu + (\\phi - 1)X_{t-1}\n$$\n鞅的增量则为：\n$$\n\\Delta M_t = \\Delta X_t - \\Delta A_t = (\\mu + (\\phi - 1)X_{t-1} + \\varepsilon_t) - (\\mu + (\\phi - 1)X_{t-1}) = \\varepsilon_t\n$$\n由于 $A_0 = M_0 = 0$，终值 $A_T$ 和 $M_T$ 分别是其各自增量从 $t=1$到 $T$ 的总和：\n$$\nA_T = \\sum_{t=1}^T \\Delta A_t = \\sum_{t=1}^T (\\mu + (\\phi - 1)X_{t-1})\n$$\n$$\nM_T = \\sum_{t=1}^T \\Delta M_t = \\sum_{t=1}^T \\varepsilon_t\n$$\n\n### 算法步骤\n对于每个测试用例，数值解法包括以下步骤：\n1.  初始化参数：$\\mu, \\phi, \\sigma, X_0, T$ 和随机种子。\n2.  使用种子初始化伪随机数生成器。从分布 $\\mathcal{N}(0, \\sigma^2)$ 生成 $T$ 个新息的完整序列 $\\{\\varepsilon_t\\}_{t=1}^T$。\n3.  初始化一个大小为 $T+1$ 的数组用于路径 $\\{X_t\\}$，并设 $X[0] = X_0$。初始化终值累加器，$A_T = 0.0$ 和 $M_T = 0.0$。\n4.  从 $t=1$ 到 $T$ 迭代：\n    a. 获取当前步骤的新息 $\\varepsilon_t$。\n    b. 计算 $X_t = \\mu + \\phi X_{t-1} + \\varepsilon_t$。\n    c. 计算可预测增量 $\\Delta A_t = \\mu + (\\phi - 1)X_{t-1}$。\n    d. 将此增量加到累加器上：$A_T \\leftarrow A_T + \\Delta A_t$。\n    e. 将鞅增量 $\\varepsilon_t$ 加到其累加器上：$M_T \\leftarrow M_T + \\varepsilon_t$。请注意，这也可以在循环结束后通过对所有新息求和一次性计算。\n5.  循环结束后，将 $A_T$ 和 $M_T$ 的最终值四舍五入到六位小数。\n6.  存储数对 $[A_T, M_T]$ 并按规定格式化收集到的结果。\n该步骤正确实现了推导出的分解，并生成了所需的输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Simulates AR(1) processes and computes the terminal values of their\n    Doob-Meyer decomposition components.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'mu': 0.5, 'phi': 0.8, 'sigma': 1.0, 'X0': 0.7, 'T': 12, 'seed': 314159},\n        {'mu': 0.0, 'phi': 1.0, 'sigma': 0.8, 'X0': 1.2, 'T': 10, 'seed': 271828},\n        {'mu': 0.1, 'phi': 0.9, 'sigma': 0.0, 'X0': -0.3, 'T': 15, 'seed': 42},\n        {'mu': -0.2, 'phi': 1.0, 'sigma': 0.5, 'X0': 0.0, 'T': 8, 'seed': 7},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        mu = case['mu']\n        phi = case['phi']\n        sigma = case['sigma']\n        X0 = case['X0']\n        T = case['T']\n        seed = case['seed']\n\n        # 1. Initialize RNG and generate all innovations\n        rng = np.random.default_rng(seed)\n        epsilons = rng.normal(loc=0.0, scale=sigma, size=T)\n\n        # 2. Initialize path array and terminal value accumulators\n        x_path = np.zeros(T + 1)\n        x_path[0] = X0\n        \n        A_T = 0.0\n\n        # 3. Simulate the path and compute the predictable component A_T\n        # The martingale component M_T is simply the sum of all innovations.\n        for t in range(1, T + 1):\n            # The t-th innovation corresponds to index t-1 in the epsilons array\n            epsilon_t = epsilons[t - 1]\n            x_prev = x_path[t - 1]\n            \n            # Update the process\n            x_path[t] = mu + phi * x_prev + epsilon_t\n            \n            # Increment for the predictable part A_t\n            # delta_A_t = E[X_t - X_{t-1} | F_{t-1}] = mu + (phi - 1) * X_{t-1}\n            delta_A_t = mu + (phi - 1) * x_prev\n            A_T += delta_A_t\n\n        # The martingale part M_T is the sum of innovations\n        M_T = np.sum(epsilons)\n        \n        # 4. Round to six decimal places as required\n        A_T_rounded = round(A_T, 6)\n        M_T_rounded = round(M_T, 6)\n        \n        results.append([A_T_rounded, M_T_rounded])\n\n    # 5. Format the final output string as a compact list of lists\n    # Each sublist [a, m] is formatted to ensure fixed precision and no spaces\n    string_parts = []\n    for res_pair in results:\n        a_str = f\"{res_pair[0]:.6f}\"\n        m_str = f\"{res_pair[1]:.6f}\"\n        string_parts.append(f\"[{a_str},{m_str}]\")\n        \n    final_output = f\"[{','.join(string_parts)}]\"\n\n    print(final_output)\n\nsolve()\n```"}, {"introduction": "在许多经济和金融问题中，我们最关心的变量（如资产的“真实”价值或个人的“真实”能力 $\\theta_t$）往往是不可直接观测的，我们能看到的只是充满噪声的信号（如市场价格或比赛数据 $y_t$）。卡尔曼滤波器（Kalman filter）是一种强大的递归算法，专门用于从这些嘈杂的观测中实时追踪这类隐藏状态。[@problem_id:2389012] 这个练习通过一个直观的体育分析案例，让你亲手实现卡尔曼滤波器，学习它如何巧妙地结合模型预测与新数据的证据，来估计一个动态变化的潜在能力。", "id": "2389012", "problem": "考虑一个单一隐藏状态，代表一名篮球运动员在一系列比赛中潜在的投篮能力。在每个离散时间步 $t \\in \\{1,2,\\dots,T\\}$，该运动员投篮 $n_t$ 次，命中 $m_t$ 次。当 $n_t \\gt 0$ 时，定义观测投篮命中率为 $y_t = m_t / n_t$；当 $n_t = 0$ 时，将 $y_t$ 视为缺失值。使用以下线性高斯状态空间模型对隐藏能力和观测值进行建模：\n- 隐藏状态动态：$ \\theta_t = \\mu + \\phi \\left(\\theta_{t-1} - \\mu\\right) + w_t $，其中 $w_t \\sim \\mathcal{N}(0,q)$。\n- 观测方程 (当 $n_t \\gt 0$ 时)：$ y_t = \\theta_t + v_t $，其中 $v_t \\sim \\mathcal{N}(0, R_t)$。\n\n假设 $R_t$ 已知，并通过一个受二项式采样启发的样本均值方差近似法来依赖于 $n_t$：$ R_t = \\bar{p}(1-\\bar{p}) / n_t $，其中 $\\bar{p}$ 是一个固定的参考概率。当 $n_t = 0$ 时，将观测值视为缺失，并且只执行状态预测步骤（不进行更新）。所有概率和方差必须表示为小数（例如，写作 $0.45$ 而不是 $45\\%$）。\n\n给定以下固定参数：\n- 长期均值：$\\mu = 0.45$。\n- 自回归系数：$\\phi = 0.90$。\n- 状态新息方差：$q = 0.0005$。\n- 用于观测方差的参考概率：$\\bar{p} = 0.45$（在 $R_t$ 中使用此值）。\n- 初始状态的先验分布：$\\theta_0 \\sim \\mathcal{N}(m_0, P_0)$，其中 $m_0 = 0.45$ 且 $P_0 = 0.01$。\n\n从先验 $(m_0, P_0)$ 开始，实现递归滤波过程。在每个时间点 $t$，该过程计算状态及其方差的一步向前预测，然后（如果 $n_t \\gt 0$）使用上述线性高斯模型和观测值 $y_t$ 对其进行更新。如果 $n_t = 0$，则跳过更新步骤，并将预测值作为该时期的滤波状态向前传递。\n\n您的任务是编写一个完整的程序，该程序：\n1. 为上述指定的模型实现所述的时变方差卡尔曼滤波器。\n2. 在以下每个比赛测试集上运行该滤波器（每个测试集是一个 $(m_t, n_t)$ 对的序列）：\n   - 测试用例 A (中等尝试次数，结果多样)：\n     - $[(5,11), (4,10), (7,12), (6,14), (2,6), (8,15), (3,8), (6,12), (7,16), (5,9)]$。\n   - 测试用例 B (高尝试次数，结果相对稳定)：\n     - $[(9,20), (10,22), (8,18), (11,24), (12,25), (9,19), (10,21), (12,26), (11,24), (13,28)]$。\n   - 测试用例 C (部分比赛尝试次数为零；将其视为缺失观测值)：\n     - $[(0,0), (3,5), (0,0), (4,4), (0,0), (2,10), (0,0), (5,10)]$。\n   - 测试用例 D (结果和尝试次数波动较大)：\n     - $[(1,2), (0,5), (7,10), (1,12), (9,10), (0,3), (6,15), (2,2), (0,8), (10,12)]$。\n3. 对于每个测试用例，输出处理序列中最后一场比赛后的最终滤波后验均值 $\\hat{\\theta}_T$ 和方差 $P_T$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个测试用例的结果本身必须是一个双元素列表 $[\\hat{\\theta}_T, P_T]$，其中两个值都四舍五入到恰好六位小数。例如，整体输出应如下所示：\n- $[[\\hat{\\theta}_T^{(A)}, P_T^{(A)}],[\\hat{\\theta}_T^{(B)}, P_T^{(B)}],[\\hat{\\theta}_T^{(C)}, P_T^{(C)}],[\\hat{\\theta}_T^{(D)}, P_T^{(D)}]]$，\n打印为单行。\n\n角度单位不适用。百分比必须以小数形式表示，不能使用百分号。本问题中没有物理单位。", "solution": "该问题要求实现卡尔曼滤波器，这是一种用于从一系列带噪声的测量中估计线性动态系统隐藏状态的递归算法。该系统将篮球运动员的投篮能力 $\\theta_t$ 建模为一个随时间演变的潜在状态。\n\n首先，我们在线性高斯状态空间模型的框架内对问题进行形式化。该模型由两个方程组成：状态转移方程和观测方程。\n\n系统的状态是运动员在时间 $t$ 的投篮能力，用标量 $\\theta_t$ 表示。该状态的演变由一个一阶自回归过程 AR($1$) 描述，该过程会向长期均值 $\\mu$ 进行均值回归。\n\n状态方程：\n隐藏状态动态由下式给出：\n$$ \\theta_t = \\mu + \\phi \\left(\\theta_{t-1} - \\mu\\right) + w_t $$\n可以将其重排为标准线性形式：\n$$ \\theta_t = \\phi \\theta_{t-1} + (1 - \\phi)\\mu + w_t $$\n其中：\n- $\\theta_t$ 是时间 $t$ 的状态。\n- $\\phi$ 是自回归系数，决定了状态的持续性。给定值为 $\\phi=0.90$。\n- $\\mu$ 是过程的长期均值，给定值为 $\\mu=0.45$。\n- $w_t$ 是过程噪声，假定为白噪声过程，$w_t \\sim \\mathcal{N}(0, q)$，其中 $q$ 是状态新息方差，给定值为 $q=0.0005$。\n\n观测方程：\n时间 $t$ 的观测值是运动员的观测投篮命中率 $y_t = m_t / n_t$，其中 $m_t$ 是 $n_t$ 次尝试中的命中次数。该观测值仅在 $n_t > 0$ 时可用。该观测值被建模为对真实潜在能力 $\\theta_t$ 的带噪声测量。\n$$ y_t = \\theta_t + v_t $$\n其中：\n- $y_t$ 是时间 $t$ 的观测值。\n- $v_t$ 是测量噪声，假定为白噪声过程，$v_t \\sim \\mathcal{N}(0, R_t)$。方差 $R_t$ 是时变的。\n\n测量噪声方差 $R_t$ 是基于二项分布中样本比例的方差来近似的。给定 $n_t$ 次试验，样本比例 $y_t$ 的方差约为 $p(1-p)/n_t$。问题指定使用一个固定的参考概率 $\\bar{p}=0.45$ 进行此计算：\n$$ R_t = \\frac{\\bar{p}(1 - \\bar{p})}{n_t} = \\frac{0.45(1 - 0.45)}{n_t} = \\frac{0.2475}{n_t} $$\n这种表示法使 $R_t$ 成为时变方差，因为它取决于每场比赛的投篮次数 $n_t$。当 $n_t$ 较大时，$R_t$ 较小，反映了对观测值的置信度更高。\n\n卡尔曼滤波器为估计状态的后验分布 $p(\\theta_t | y_{1:t})$ 提供了一个递归解。由于模型是线性和高斯的，这个后验分布也是高斯分布，并且可以由其均值 $\\hat{\\theta}_{t|t}$ 和方差 $P_{t|t}$ 完全表征。\n\n滤波过程从初始状态的先验分布 $\\theta_0 \\sim \\mathcal{N}(m_0, P_0)$ 开始，给定参数为 $m_0 = 0.45$ 和 $P_0 = 0.01$。在每个时间步 $t=1, 2, \\dots, T$，算法执行两个步骤：预测步骤和更新步骤。\n\n设时间 $t-1$ 的滤波后验分布为 $\\mathcal{N}(\\hat{\\theta}_{t-1|t-1}, P_{t-1|t-1})$。\n\n步骤 1：预测（时间更新）\n在此步骤中，我们基于截至时间 $t-1$ 的所有信息来预测时间 $t$ 的状态分布。计算预测（先验）均值 $\\hat{\\theta}_{t|t-1}$ 和方差 $P_{t|t-1}$。\n\n对状态方程取期望：\n$$ \\hat{\\theta}_{t|t-1} = \\mathbb{E}[\\phi \\theta_{t-1} + (1 - \\phi)\\mu + w_t | y_{1:t-1}] = \\phi \\hat{\\theta}_{t-1|t-1} + (1 - \\phi)\\mu $$\n预测误差的方差为：\n$$ P_{t|t-1} = \\text{Var}(\\theta_t - \\hat{\\theta}_{t|t-1}) = \\text{Var}(\\phi(\\theta_{t-1} - \\hat{\\theta}_{t-1|t-1}) + w_t) $$\n由于误差 $(\\theta_{t-1} - \\hat{\\theta}_{t-1|t-1})$ 与过程噪声 $w_t$ 不相关，方差相加：\n$$ P_{t|t-1} = \\phi^2 \\text{Var}(\\theta_{t-1} - \\hat{\\theta}_{t-1|t-1}) + \\text{Var}(w_t) = \\phi^2 P_{t-1|t-1} + q $$\n\n步骤 2：更新（测量更新）\n此步骤使用时间 $t$ 的新观测值 $y_t$ 来修正预测。仅当有可用观测值（即 $n_t > 0$）时才执行此步骤。\n\n首先，我们计算新息，即实际观测值 $y_t$ 与其预测值之间的差异：\n$$ \\tilde{y}_t = y_t - \\mathbb{E}[y_t | y_{1:t-1}] = y_t - \\mathbb{E}[\\theta_t + v_t | y_{1:t-1}] = y_t - \\hat{\\theta}_{t|t-1} $$\n新息的方差，或称新息协方差，为：\n$$ S_t = \\text{Var}(\\tilde{y}_t) = \\text{Var}((\\theta_t - \\hat{\\theta}_{t|t-1}) + v_t) = P_{t|t-1} + R_t $$\n最优卡尔曼增益 $K_t$ 决定了根据新息对预测进行多大程度的调整。它的计算旨在最小化后验误差方差：\n$$ K_t = \\frac{\\text{Cov}(\\theta_t, \\tilde{y}_t)}{\\text{Var}(\\tilde{y}_t)} = \\frac{\\text{Cov}(\\theta_t, \\theta_t - \\hat{\\theta}_{t|t-1} + v_t)}{S_t} = \\frac{P_{t|t-1}}{S_t} = \\frac{P_{t|t-1}}{P_{t|t-1} + R_t} $$\n更新后（后验）的状态均值是预测均值和观测值的加权平均：\n$$ \\hat{\\theta}_{t|t} = \\hat{\\theta}_{t|t-1} + K_t \\tilde{y}_t = \\hat{\\theta}_{t|t-1} + K_t (y_t - \\hat{\\theta}_{t|t-1}) $$\n更新后（后验）的误差方差为：\n$$ P_{t|t} = (1 - K_t) P_{t|t-1} $$\n\n处理缺失观测值：\n如果 $n_t = 0$，则观测值 $y_t$ 缺失。在这种情况下，无法执行更新。时间 $t$ 状态的最佳估计就是上一步的预测值。因此，时间 $t$ 的后验分布被设置为其先验分布：\n$$ \\hat{\\theta}_{t|t} = \\hat{\\theta}_{t|t-1} $$\n$$ P_{t|t} = P_{t|t-1} $$\n\n对每个测试用例，整体算法实现如下：\n1. 使用先验均值 $\\hat{\\theta}_{0|0} = m_0 = 0.45$ 和方差 $P_{0|0} = P_0 = 0.01$ 初始化滤波器。\n2. 对于每个时间步 $t=1, \\dots, T$：\n   a. 执行预测步骤，计算 $\\hat{\\theta}_{t|t-1}$ 和 $P_{t|t-1}$。\n   b. 检查是否 $n_t > 0$：\n      i. 如果为真，计算 $y_t = m_t / n_t$ 和 $R_t = \\bar{p}(1-\\bar{p}) / n_t$。执行更新步骤，计算 $\\hat{\\theta}_{t|t}$ 和 $P_{t|t}$。\n      ii. 如果为假，跳过更新，并设置 $\\hat{\\theta}_{t|t} = \\hat{\\theta}_{t|t-1}$ 和 $P_{t|t} = P_{t|t-1}$。\n3. 处理完整个序列后的最终值 $\\hat{\\theta}_{T|T}$ 和 $P_{T|T}$ 即为每个测试用例所要求的输出。", "answer": "```python\nimport numpy as np\n\ndef run_kalman_filter(data, mu, phi, q, p_bar, m0, P0):\n    \"\"\"\n    Implements the Kalman filter for the given state-space model.\n\n    Args:\n        data (list of tuples): A sequence of (m_t, n_t) pairs.\n        mu (float): Long-run mean of the state process.\n        phi (float): Autoregressive coefficient of the state process.\n        q (float): State innovation variance.\n        p_bar (float): Reference probability for observation variance.\n        m0 (float): Prior mean of the initial state.\n        P0 (float): Prior variance of the initial state.\n\n    Returns:\n        tuple: A tuple containing the final filtered posterior mean and variance.\n    \"\"\"\n    # Initialize the filtered state mean and variance with the prior\n    theta_filt = m0\n    P_filt = P0\n    \n    # Pre-calculate the numerator for the observation variance R_t\n    obs_var_numerator = p_bar * (1.0 - p_bar)\n\n    # Iterate through each time step (game)\n    for m_t, n_t in data:\n        # --- 1. Prediction Step ---\n        # Predict the next state mean\n        theta_pred = phi * theta_filt + mu * (1.0 - phi)\n        # Predict the next state variance\n        P_pred = phi**2 * P_filt + q\n\n        # --- 2. Update Step ---\n        # Check if there is an observation (n_t > 0)\n        if n_t > 0:\n            # Calculate the observation y_t\n            y_t = m_t / n_t\n            # Calculate the time-varying observation variance R_t\n            R_t = obs_var_numerator / n_t\n            \n            # Calculate the innovation covariance S_t\n            S_t = P_pred + R_t\n            \n            # Calculate the optimal Kalman gain K_t\n            K_t = P_pred / S_t\n            \n            # Update the state mean\n            theta_filt = theta_pred + K_t * (y_t - theta_pred)\n            \n            # Update the state variance\n            P_filt = (1.0 - K_t) * P_pred\n        else:\n            # If observation is missing (n_t = 0), the posterior is the prior\n            theta_filt = theta_pred\n            P_filt = P_pred\n            \n    return theta_filt, P_filt\n\ndef solve():\n    \"\"\"\n    Main function to define parameters, run test cases, and print results.\n    \"\"\"\n    # Fixed model parameters\n    mu = 0.45\n    phi = 0.90\n    q = 0.0005\n    p_bar = 0.45\n    \n    # Prior for the initial state\n    m0 = 0.45\n    P0 = 0.01\n\n    # Define the test cases from the problem statement\n    test_cases = [\n        # Test case A\n        [(5, 11), (4, 10), (7, 12), (6, 14), (2, 6), (8, 15), (3, 8), (6, 12), (7, 16), (5, 9)],\n        # Test case B\n        [(9, 20), (10, 22), (8, 18), (11, 24), (12, 25), (9, 19), (10, 21), (12, 26), (11, 24), (13, 28)],\n        # Test case C\n        [(0, 0), (3, 5), (0, 0), (4, 4), (0, 0), (2, 10), (0, 0), (5, 10)],\n        # Test case D\n        [(1, 2), (0, 5), (7, 10), (1, 12), (9, 10), (0, 3), (6, 15), (2, 2), (0, 8), (10, 12)]\n    ]\n\n    results = []\n    # Process each test case\n    for data in test_cases:\n        theta_T, P_T = run_kalman_filter(data, mu, phi, q, p_bar, m0, P0)\n        # Format the result for the current test case as a string\n        # with values rounded to six decimal places, enclosed in brackets.\n        results.append(f\"[{theta_T:.6f}, {P_T:.6f}]\")\n\n    # Final print statement in the exact required format.\n    # The output is a single line: a list of lists.\n    print(f\"[{','.join(results)}]\")\n\n# Execute the main function\nsolve()\n```"}]}