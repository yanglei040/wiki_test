{"hands_on_practices": [{"introduction": "随机游走 Metropolis 算法是 MCMC 方法的基石，但其性能表现有赖于精细的调校。本练习旨在深入探讨如何选择提议步长，这是一个决定算法如何探索后验分布的关键参数。通过分析步长过大或过小所带来的后果，你将建立起关于接受率与样本自相关性之间权衡的关键直觉，这对于运行高效的模拟至关重要。[@problem_id:2408760]", "id": "2408760", "problem": "考虑在一个基于似然的资产定价模型中，对一个标量结构参数 $\\theta$ 进行贝叶斯估计。其真后验密度 $\\pi(\\theta)$ 是单峰且大致呈钟形的。您运行一个随机游走Metropolis马尔可夫链蒙特卡洛 (MCMC) 算法，该算法使用对称高斯提议，\n$$\n\\theta' \\,=\\, \\theta_t \\,+\\, \\varepsilon, \\quad \\varepsilon \\sim \\mathcal{N}(0, s^2),\n$$\n其接受概率为\n$$\n\\alpha(\\theta_t,\\theta') \\,=\\, \\min\\!\\left\\{\\,1,\\, \\frac{\\pi(\\theta')}{\\pi(\\theta_t)} \\,\\right\\}。\n$$\n对于在平稳状态下两次独立的长度为 $T$ 的长运行，您分别选择 (i) 相对于后验曲率过大的提议尺度 $s$，以及 (ii) 相对于后验曲率过小的提议尺度 $s$。令 $\\rho(k)$ 表示马尔可夫链 $\\{\\theta_t\\}_{t=1}^T$ 的滞后$k$阶自相关函数 (ACF)，其定义为\n$$\n\\rho(k) \\,=\\, \\frac{\\mathrm{Cov}(\\theta_t, \\theta_{t+k})}{\\mathrm{Var}(\\theta_t)}, \\quad k \\in \\{1,2,\\ldots\\}。\n$$\n在这两种机制下，哪种说法最能刻画经验ACF和接受率的定性行为，以及由此对有效样本量产生的影响？\n\nA. 在两种机制下，$\\rho(1)$ 都很大且为正，并随 $k$ 的增加而缓慢衰减，但接受率不同：当 $s$ 过大时，接受率非常低，马尔可夫链呈现重复状态；当 $s$ 過小時，接受率非常高，但連續狀態非常接近。在这两种情况下，积分自相关时间都很长，有效样本量都很小，只有在 $s$ 取中间值时情况才会改善。\n\nB. 当 $s$ 过大时，马尔可夫链频繁地来回跳跃，导致 $\\rho(1)$ 为负；当 $s$ 过小时，大部分移动都被接受，因此对于所有 $k \\ge 1$，$\\rho(k) \\approx 0$，有效样本量达到最大。\n\nC. 当 $s$ 极大时，ACF衰减最快，因为大的跳跃会使马尔可夫链去相关，并且在这种情况下接受率很高，从而导致最大的有效样本量。\n\nD. 对于平稳运行，ACF $\\rho(k)$ 不受 $s$ 选择的影响；只有预烧期长度受 $s$ 的影响。\n\nE. 对于对称提议，任何 $s$ 值的接受率都等于0.5，这意味着在不同 $s$ 选择下观测到的 $\\rho(k)$ 差异是由蒙特卡洛误差引起的，而不是步长选择的结果。", "solution": "问题要求对随机游走Metropolis (RWM) 算法在两种极端的提议尺度 $s$ 选择下的性能进行定性分析。该性能通过接受率、生成链的自相关函数 (ACF) 以及由此产生的有效样本量 (ESS) 来刻画。\n\n任何马尔可夫链蒙特卡洛 (MCMC) 算法的目标都是生成一个抽样序列 $\\{\\theta_t\\}_{t=1}^T$，其分布收敛于一个目标分布，在本例中即后验分布 $\\pi(\\theta)$。为了使从此链中得到的估计量（例如后验均值 $\\frac{1}{T}\\sum_{t=1}^T \\theta_t$）精确，我们需要一个大的有效样本量。ESS 定义为\n$$\n\\text{ESS} = \\frac{T}{1 + 2\\sum_{k=1}^{\\infty} \\rho(k)} = \\frac{T}{\\tau}\n$$\n其中 $T$ 是名义样本量，而 $\\tau = 1 + 2\\sum_{k=1}^{\\infty} \\rho(k)$ 是积分自相关时间 (IAT)。为了在固定链长 $T$ 的情况下最大化ESS，必须最小化IAT。当自相关 $\\rho(k)$ 很小并且随着滞后 $k$ 的增加而快速衰减至零时，就可以实现这一点。因此，采样器的效率与链中的持续性成反比。\n\nRWM算法使用一个提议 $\\theta' = \\theta_t + \\varepsilon$ (其中 $\\varepsilon \\sim \\mathcal{N}(0, s^2)$)。参数 $s$ 是一个决定算法效率的关键调节参数。让我们来分析指定的两种机制。\n\n情况 (i)：提议尺度 $s$ 过大。\n在这种机制下，提议的跳跃 $\\varepsilon$ 很大。由于目标后验分布 $\\pi(\\theta)$ 是单峰且呈钟形的，它将其质量集中在众数周围一个相对较小的区域内。从当前状态 $\\theta_t$（在平稳状态下，该状态很可能处于后验密度高的区域）进行一次大跳跃，将极有可能使提议 $\\theta'$ 落入分布的尾部，那里的 $\\pi(\\theta')$ 非常小。\n因此，接受比率 $\\frac{\\pi(\\theta')}{\\pi(\\theta_t)}$ 将远小于1。所以接受概率 $\\alpha(\\theta_t, \\theta') = \\min\\{1, \\frac{\\pi(\\theta')}{\\pi(\\theta_t)}\\}$ 将会非常低。\n大多数提议都被拒绝，这意味着链在许多连续的迭代中都停留在当前状态：$\\theta_{t+1} = \\theta_t$。这种“卡住”的行为导致了连续状态之间极高的正相关性。因此，滞后1阶自相关 $\\rho(1)$ 将非常接近1，并且整个ACF $\\rho(k)$ 将极其缓慢地衰减。这导致了非常大的IAT和非常小的ESS。链对后验空间的探索效率非常低。\n\n情况 (ii)：提议尺度 $s$ 过小。\n在这种机制下，提议的跳跃 $\\varepsilon$ 很小。提议 $\\theta'$ 将非常接近当前状态 $\\theta_t$。只要后验密度 $\\pi(\\theta)$ 是连续的（这是一个标准假设），$\\pi(\\theta')$ 就会非常接近 $\\pi(\\theta_t)$。\n接受比率 $\\frac{\\pi(\\theta')}{\\pi(\\theta_t)}$ 将非常接近1。因此，接受概率 $\\alpha(\\theta_t, \\theta')$ 将会非常高，当 $s \\to 0$ 时趋近于1。\n尽管大多数提议都被接受，但每一步都非常微小。链在参数空间中的移动就像一个缓慢的扩散过程。$\\theta_{t+1}$ 与 $\\theta_t$ 只有微小的差异。这再次意味着连续状态是高度相关的。滞后1阶自相关 $\\rho(1)$ 也将非常接近1，ACF $\\rho(k)$ 将非常缓慢地衰减。这也导致了大的IAT和小的ESS。链对后验空间的探索效率非常低，但这与情况(i)的原因不同。\n\n总而言之，提议尺度 $s$ 的两个极端都对采样效率有害。最高效率（最小的IAT，最大的ESS）是在一个中间的 $s$ 值下实现的，该值平衡了接受率和步长，使链能够有效地探索后验分布的整个支撑集。对于像这样的一维问题，已知最优接受率大约为 $0.44$。\n\n现在，我们来评估所给的选项。\n\nA. 在两种机制下，$\\rho(1)$ 都很大且为正，并随 $k$ 的增加而缓慢衰减，但接受率不同：当 $s$ 过大时，接受率非常低，马尔可夫链呈现重复状态；当 $s$ 过小时，接受率非常高，但连续状态非常接近。在这两种情况下，积分自相关时间都很长，有效样本量都很小，只有在 $s$ 取中间值时情况才会改善。\n该陈述准确地总结了如上所述的两种机制下的行为。它正确地指出了高正自相关是共同的病态表现，但正确地区分了其机制：对于大的 $s$ 是低接受率和“卡住”，对于小的 $s$ 是高接受率但步长微小。它正确地得出结论，两种情况都会导致较差的ESS，而ESS在中间的 $s$ 值处得到优化。该陈述与MCMC的理论一致。\n结论：**正确**。\n\nB. 当 $s$ 过大时，马尔可夫链频繁地来回跳跃，导致 $\\rho(1)$ 为负；当 $s$ 过小时，大部分移动都被接受，因此对于所有 $k \\ge 1$，$\\rho(k) \\approx 0$，有效样本量达到最大。\n该陈述在多个方面都不正确。首先，对于RWM，大的 $s$ 不会导致“来回跳跃”和负的 $\\rho(1)$。它会导致拒绝和停在原地，从而产生高的*正*自相关。负自相关更像是其他采样器（如Gibbs或具有特定参数化设置的HMC）的特征。其次，对于小的 $s$，链移动缓慢，因此对于小的 $k$，$\\theta_t$和$\\theta_{t+k}$高度相关，这意味着 $\\rho(k)$ 接近1，而不是0。这会最小化，而不是最大化有效样本量。\n结论：**不正确**。\n\nC. 当 $s$ 极大时，ACF衰减最快，因为大的跳跃会使马尔可夫链去相关，并且在这种情况下接受率很高，从而导致最大的有效样本量。\n该陈述在事实上是错误的。当 $s$ 极大时，接受率是极*低*的，而不是高的。虽然一次成功的大的跳跃是去相关的，但链的行为被更频繁发生的拒绝事件所主导。结果是一条慢混合链，其ACF衰减非常缓慢，而不是最快。这导致最小的、而不是最大的ESS。\n结论：**不正确**。\n\nD. 对于平稳运行，ACF $\\rho(k)$ 不受 $s$ 选择的影响；只有预烧期长度受 $s$ 的影响。\n这在根本上是错误的。提议尺度 $s$ 定义了马尔可夫链的转移核。虽然平稳分布 $\\pi(\\theta)$ 不受 $s$ 的影响（根据M-H算法的构造），但链的动态特性，如其收敛速度和在平稳状态下的自相关结构，都严重依赖于 $s$。调节 $s$ 正是为了优化这些由ACF衡量的动态特性。\n结论：**不正确**。\n\nE. 对于对称提议，任何 $s$ 值的接受率都等于0.5，这意味着在不同 $s$ 选择下观测到的 $\\rho(k)$ 差异是由蒙特卡洛误差引起的，而不是步长选择的结果。\n这个陈述是错误的。接受率不是一个常数0.5。它通过比率 $\\pi(\\theta')/\\pi(\\theta_t)$ 成为提议尺度 $s$ 的函数。关于最优接受率有著名的理论文献，这些最优值不是0.5（例如，高维时约为0.234，一维时约为0.44），但这些是通过*调节* $s$ 来实现的*目标*，而不是固定的常数。观测到的 $\\rho(k)$ 的差异是选择 $s$ 的直接且真实的结果。\n结论：**不正确**。\n\n基于这一严谨的分析，只有选项A对该现象提供了正确且完整的描述。", "answer": "$$\\boxed{A}$$"}, {"introduction": "当我们运行 MCMC 链后，如何判断它们是否已真正收敛到目标分布？Gelman-Rubin 诊断（或称 $\\hat{R}$ 指标）是为此目的而广泛使用的工具，但它并非万无一失。本练习提出了一个重要的思想实验，揭示了该诊断在何种情况下会产生误导，即它可能无法检测到多条链同时陷入复杂后验分布的同一局部模式中。理解这一潜在陷阱对于培养稳健评估 MCMC 收敛性所必需的批判性思维至关重要。[@problem_id:2408731]", "id": "2408731", "problem": "考虑一个计算经济学和金融学中的贝叶斯估计问题，其中一个标量结构参数 $\\theta$ 仅通过 $\\theta^{2}$ 进入似然函数（例如，因子定价方程中符号不定的载荷），从而产生一个对称、分离良好的双峰后验分布\n$$\np(\\theta \\mid y) \\;=\\; \\tfrac{1}{2}\\,\\mathcal{N}\\!\\left(+\\mu,\\sigma^{2}\\right)\\;+\\;\\tfrac{1}{2}\\,\\mathcal{N}\\!\\left(-\\mu,\\sigma^{2}\\right),\n$$\n其中 $\\mu>0$，$\\sigma>0$，且 $\\mu/\\sigma$ 很大，因此两个模态被很好地分离开。\n\n假设运行了 $m$ 条独立的马尔可夫链蒙特卡洛（MCMC）链，每条链在预烧期（burn-in）后长度为 $n$，使用的核（kernel）在一个模态内混合迅速，但极少穿越模态之间的低后验概率区域。所有链都在 $+\\mu$ 附近初始化，并且在有限的运行时间内，从未访问另一个模态。因此，在预烧期后，可以认为各链之间的抽样是独立的，并且每条链内的抽样是来自 $\\mathcal{N}\\!\\left(\\mu,\\sigma^{2}\\right)$ 的独立同分布。\n\n令 $\\bar{\\theta}_{j\\cdot}$ 表示链 $j\\in\\{1,\\dots,m\\}$ 的样本均值，$s_{j}^{2}$ 表示链 $j$ 的样本方差，$\\bar{\\theta}_{\\cdot\\cdot}$ 表示所有链的总均值。Gelman–Rubin 潜在尺度缩减因子（PSRF），也称为 Gelman–Rubin 诊断，定义为\n$$\nW \\;=\\; \\frac{1}{m}\\sum_{j=1}^{m} s_{j}^{2},\\qquad\nB \\;=\\; \\frac{n}{m-1}\\sum_{j=1}^{m}\\left(\\bar{\\theta}_{j\\cdot}-\\bar{\\theta}_{\\cdot\\cdot}\\right)^{2},\n$$\n$$\n\\widehat{\\operatorname{Var}}^{+} \\;=\\; \\frac{n-1}{n}\\,W \\;+\\; \\frac{1}{n}\\,B,\\qquad\n\\hat{R} \\;=\\; \\sqrt{\\frac{\\widehat{\\operatorname{Var}}^{+}}{W}}.\n$$\n\n当 $m$ 固定且上述所有假设均成立时，随着 $n\\to\\infty$，关于 $\\hat{R}$ 的哪个陈述是正确的？\n\nA. $\\hat{R}$ 依概率收敛于 $1$，尽管链没有探索整个后验支撑集，因此该诊断未能检测出多模态问题。\n\nB. 因为第二个模态未被访问，$\\hat{R}$ 收敛到 $\\sqrt{2}$，因此该诊断正确地指出了不收敛。\n\nC. 随着 $n$ 的增长，$\\hat{R}$ 发散到 $+\\infty$，因为 $B$ 随 $n$ 线性增长。\n\nD. $\\hat{R}$ 收敛到 $0$，因为对于大的 $n$，$W$ 主导 $B$。", "solution": "必须首先验证问题陈述的科学合理性和一致性。\n\n**步骤1：提取已知条件**\n\n-   **后验分布：** $p(\\theta \\mid y) = \\frac{1}{2}\\,\\mathcal{N}(+\\mu,\\sigma^{2}) + \\frac{1}{2}\\,\\mathcal{N}(-\\mu,\\sigma^{2})$，其中 $\\theta$ 是一个标量参数，$\\mu > 0$，$\\sigma > 0$，且 $\\mu/\\sigma$ 很大。\n-   **MCMC 模拟：** $m$ 条独立的链，每条链在预烧期后长度为 $n$。\n-   **链的行为：** 所有链都在 $+\\mu$ 附近初始化并停留在此处。每条链 $j \\in \\{1, \\dots, m\\}$ 的抽样可被视为来自 $\\mathcal{N}(\\mu, \\sigma^2)$ 的独立同分布（i.i.d.）。\n-   **统计量：**\n    -   链内均值：$\\bar{\\theta}_{j\\cdot} = \\frac{1}{n}\\sum_{i=1}^{n}\\theta_{ji}$。\n    -   链内样本方差：$s_{j}^{2} = \\frac{1}{n-1}\\sum_{i=1}^{n}(\\theta_{ji}-\\bar{\\theta}_{j\\cdot})^{2}$。\n    -   总均值：$\\bar{\\theta}_{\\cdot\\cdot} = \\frac{1}{m}\\sum_{j=1}^{m}\\bar{\\theta}_{j\\cdot}$。\n    -   平均链内方差：$W = \\frac{1}{m}\\sum_{j=1}^{m} s_{j}^{2}$。\n    -   链间方差因子：$B = \\frac{n}{m-1}\\sum_{j=1}^{m}(\\bar{\\theta}_{j\\cdot}-\\bar{\\theta}_{\\cdot\\cdot})^{2}$。\n    -   估计的后验方差：$\\widehat{\\operatorname{Var}}^{+} = \\frac{n-1}{n}\\,W + \\frac{1}{n}\\,B$。\n    -   潜在尺度缩减因子（PSRF）：$\\hat{R} = \\sqrt{\\frac{\\widehat{\\operatorname{Var}}^{+}}{W}}$。\n-   **问题：** 确定当 $m$ 固定时，随着 $n\\to\\infty$，$\\hat{R}$ 的行为。\n\n**步骤2：使用提取的已知条件进行验证**\n\n该问题具有科学依据。它描述了 MCMC 采样器在多模态后验分布背景下一种常见且重要的失效模式。Gelman-Rubin 诊断（$\\hat{R}$）是评估 MCMC 收敛性的标准工具，其在这种情景下的潜在失效是计算统计学中有据可查的课题。为 $W$、$B$、$\\widehat{\\operatorname{Var}}^{+}$ 和 $\\hat{R}$ 所提供的定义是标准的。该设置是自洽的、数学上适定的且客观的。它在特定假设下，对一个统计量的渐近行为提出了一个明确的问题。\n\n**步骤3：结论与行动**\n\n问题有效。将推导解答。\n\n**推导**\n\n目标是求出当 $m$ 固定时，随着 $n \\to \\infty$，$\\hat{R}$ 的极限。$\\hat{R}$ 的表达式可以重写为：\n$$\n\\hat{R} = \\sqrt{\\frac{\\frac{n-1}{n}\\,W + \\frac{1}{n}\\,B}{W}} = \\sqrt{\\frac{n-1}{n} + \\frac{B}{nW}}\n$$\n我们必须确定 $W$ 和 $B/n$ 的依概率极限。\n\n1.  **链内方差 $W$ 的极限：**\n    对每条链 $j$，抽样 $\\{\\theta_{j1}, \\dots, \\theta_{jn}\\}$ 是来自 $\\mathcal{N}(\\mu, \\sigma^2)$ 的独立同分布。样本方差 $s_j^2$ 是总体方差的一致估计量。根据大数定律，当 $n \\to \\infty$ 时：\n    $$\n    s_j^2 \\xrightarrow{p} \\operatorname{Var}(\\theta) = \\sigma^2\n    $$\n    其中 $\\xrightarrow{p}$ 表示依概率收敛。\n    由于 $W$ 是 $m$ 个这样的一致估计量的平均值（$m$ 固定），它也是 $\\sigma^2$ 的一致估计量：\n    $$\n    W = \\frac{1}{m}\\sum_{j=1}^{m} s_{j}^{2} \\xrightarrow{p} \\frac{1}{m}\\sum_{j=1}^{m} \\sigma^2 = \\sigma^2\n    $$\n\n2.  **链间方差项 $B/n$ 的极限：**\n    统计量 $B$ 由 $B = \\frac{n}{m-1}\\sum_{j=1}^{m}(\\bar{\\theta}_{j\\cdot}-\\bar{\\theta}_{\\cdot\\cdot})^{2}$ 给出。我们关心 $B/n$ 的行为：\n    $$\n    \\frac{B}{n} = \\frac{1}{m-1}\\sum_{j=1}^{m}\\left(\\bar{\\theta}_{j\\cdot}-\\bar{\\theta}_{\\cdot\\cdot}\\right)^{2}\n    $$\n    这是链均值 $\\{\\bar{\\theta}_{1\\cdot}, \\dots, \\bar{\\theta}_{m\\cdot}\\}$ 的样本方差。\n    对每条链 $j$，$\\bar{\\theta}_{j\\cdot}$ 是来自 $\\mathcal{N}(\\mu, \\sigma^2)$ 的 $n$ 次独立同分布抽样的样本均值。根据大数定律，当 $n \\to \\infty$ 时：\n    $$\n    \\bar{\\theta}_{j\\cdot} \\xrightarrow{p} E[\\theta] = \\mu\n    $$\n    总均值 $\\bar{\\theta}_{\\cdot\\cdot} = \\frac{1}{m}\\sum_{j=1}^{m}\\bar{\\theta}_{j\\cdot}$ 也依概率收敛于 $\\mu$。\n    因此，对每个 $j$，差值 $(\\bar{\\theta}_{j\\cdot}-\\bar{\\theta}_{\\cdot\\cdot}) \\xrightarrow{p} (\\mu - \\mu) = 0$。\n    由于这对求和中的所有项都成立且 $m$ 是固定的，整个和收敛到 $0$：\n    $$\n    \\frac{B}{n} = \\frac{1}{m-1}\\sum_{j=1}^{m}\\left(\\bar{\\theta}_{j\\cdot}-\\bar{\\theta}_{\\cdot\\cdot}\\right)^{2} \\xrightarrow{p} 0\n    $$\n\n3.  **$\\hat{R}$ 的极限：**\n    现在我们可以整合出 $\\hat{R}^2$ 的极限。当 $n \\to \\infty$ 时：\n    -   $\\frac{n-1}{n} \\to 1$。\n    -   $W \\xrightarrow{p} \\sigma^2$。\n    -   $B/n \\xrightarrow{p} 0$。\n    \n    对 $\\hat{R}^2$ 的表达式应用 Slutsky 定理：\n    $$\n    \\hat{R}^2 = \\frac{n-1}{n} + \\frac{B/n}{W} \\xrightarrow{p} 1 + \\frac{0}{\\sigma^2} = 1\n    $$\n    由于平方根函数在 $1$ 处是连续的，我们可以应用连续映射定理：\n    $$\n    \\hat{R} = \\sqrt{\\hat{R}^2} \\xrightarrow{p} \\sqrt{1} = 1\n    $$\n\n**解释与选项评估**\n\n分析表明 $\\hat{R}$ 收敛于 $1$。在实践中，$\\hat{R} \\approx 1$ 被用作一个诊断标准，以宣告 MCMC 链已收敛到目标平稳分布。\n\n然而，在所描述的情景中，链显然未能正确收敛。它们只探索了双峰后验分布的一个模态。后验 $p(\\theta|y)$ 的真实方差是 $\\operatorname{Var}(\\theta) = E[\\theta^2] - (E[\\theta])^2 = (\\sigma^2 + \\mu^2) - 0^2 = \\sigma^2 + \\mu^2$。因为 $\\mu/\\sigma$ 很大，这个真实方差远大于 $\\sigma^2$。\n\n估计的方差 $\\widehat{\\operatorname{Var}}^{+} = \\frac{n-1}{n}W + \\frac{1}{n}B$ 依概率收敛于 $\\sigma^2$。该估计量严重低估了真实的后验方差。Gelman-Rubin 诊断将这个有缺陷的总方差估计（$\\widehat{\\operatorname{Var}}^{+}$）与有缺陷的链内方差估计（$W$）进行比较，发现它们渐近地相同（$\\sigma^2$），并得出结论其比率为 $1$。这表明了收敛，从而掩盖了 MCMC 采样器未能探索整个后验支撑集的关键性失败。\n\n**逐项分析**\n\nA. **$\\hat{R}$ 依概率收敛于 $1$，尽管链没有探索整个后验支撑集，因此该诊断未能检测出多模态问题。**\n这一陈述与我们的推导完全一致。$\\hat{R}$ 收敛于 $1$，而这个结果错误地表明了收敛，因此未能指出采样器无法找到位于 $-\\mu$ 的模态。**正确**。\n\nB. **因为第二个模态未被访问，$\\hat{R}$ 收敛到 $\\sqrt{2}$，因此该诊断正确地指出了不收敛。**\n极限是 $1$，而不是 $\\sqrt{2}$。极限的前提是错误的。**错误**。\n\nC. **随着 $n$ 的增长，$\\hat{R}$ 发散到 $+\\infty$，因为 $B$ 随 $n$ 线性增长。**\n我们的分析表明 $B/n \\xrightarrow{p} 0$。这意味着 $B$ 不随 $n$ 线性增长。实际上，$B$ 在分布上收敛于一个均值为 $\\sigma^2$ 的随机变量，并且不发散。因此，$\\hat{R}$ 不发散。**错误**。\n\nD. **$\\hat{R}$ 收敛到 $0$，因为对于大的 $n$，$W$ 主导 $B$。**\n$\\hat{R}$ 的极限是 $1$，而不是 $0$。$\\hat{R}^2$ 中的主导项是 $\\frac{n-1}{n}$，其趋近于 $1$。涉及 $B$ 的项消失了，但这并不会使总极限趋于 $0$。**错误**。", "answer": "$$\\boxed{A}$$"}, {"introduction": "本实践旨在连接抽象的 MCMC 理论与在金融经济学中的具体应用。你将使用 Metropolis-Hastings 算法来估计相对风险规避系数（$\\gamma$），这是消费资本资产定价模型中的一个核心参数。这个练习提供了一个完整的动手流程，从指定包含似然和先验的贝叶斯模型，到实现采样器并在经济背景下解释后验结果，最终展示了如何运用 MCMC 从数据中提取关于不可观测经济力量的有价值的洞见。[@problem_id:2408673]", "id": "2408673", "problem": "编写一个完整、可运行的程序，使用马尔可夫链蒙特卡洛（MCMC）方法，在一个基于消费的资产定价框架中，为代表性代理人估计相对风险厌恶系数 $ \\gamma $。从跨期优化的核心一阶条件出发，该条件在常数相对风险厌恶（CRRA）偏好下导出了资产回报的欧拉方程：随机折现因子为 $ m_{t+1} = \\beta \\left( \\dfrac{C_{t+1}}{C_t} \\right)^{-\\gamma} $，无套利条件为 $ \\mathbb{E}_t \\left[ m_{t+1} R_{t+1} \\right] = 1 $，其中 $ \\beta \\in (0,1) $ 是一个折现因子，$ C_t $ 是消费，$ R_{t+1} $ 是在时间 $ t+1 $ 可观测到的总回报率。为了将此条件与有限样本的含噪数据联系起来，我们为欧拉残差假设一个加性的正态度量方程，\n$$\n\\beta \\, G_t^{-\\gamma} \\, R_{t+1} - 1 = \\varepsilon_t, \\quad \\varepsilon_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,\\sigma^2),\n$$\n其中 $ G_t = \\dfrac{C_{t+1}}{C_t} $ 表示消费总增长率，$ \\sigma^2 $ 是一个已知的方差参数。假设 $ \\gamma $ 的先验分布为Gamma分布，其形状参数为 $ k $，尺度参数为 $ \\theta $，即 $ \\gamma \\sim \\text{Gamma}(k,\\theta) $，支撑集为 $ (0,\\infty) $。使用Metropolis–Hastings算法，对对数参数 $ z = \\log \\gamma $ 进行随机游走，从而在给定样本 $ \\{(G_t,R_{t+1})\\}_{t=1}^T $ 的条件下，从 $ \\gamma $ 的后验分布中抽样。提议的生成方式为 $ z' = z + \\eta $，其中 $ \\eta \\sim \\mathcal{N}(0,s^2) $ 是在对数尺度上生成的。\n\n你的程序必须：\n- 对每个测试用例，使用下述指定的数据生成过程（DGP）模拟合成数据 $ (G_t, R_{t+1}) $。\n- 结合由度量方程所蕴含的高斯似然和 $ \\gamma $ 的Gamma先验，构建后验核。\n- 在 $ z $ 空间中运行Metropolis–Hastings采样器（等价于对 $ \\gamma $ 进行对数正态随机游走），并在舍弃预烧期样本后，计算 $ \\gamma $ 的后验均值估计。\n- 仅使用指定的随机种子以确保可复现性。\n\n每个测试用例的数据生成过程（DGP）：\n- 生成消费增长率 $ G_t = \\exp(\\mu_c + \\sigma_c \\epsilon_t) $，其中 $ \\epsilon_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,1) $。\n- 生成度量误差 $ \\varepsilon_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,\\sigma_e^2) $。\n- 逐期强制执行含噪的欧拉方程以生成回报率：\n$$\nR_{t+1} = \\frac{1 + \\varepsilon_t}{\\beta \\, G_t^{-\\gamma_{\\text{true}}}}.\n$$\n每个测试用例的所有抽样都必须使用指定的种子。为确保确定性的可复现性，用给定的种子初始化一个伪随机数生成器用于模拟 $ G_t $ 和 $ R_{t+1} $，并用种子加上 $ +\\,10{,}000 $ 初始化第二个伪随机数生成器用于Metropolis–Hastings的提议。本问题中没有物理单位。\n\n对数参数的后验目标：\n- 定义 $ z = \\log \\gamma $。$ z $ 的目标密度与在 $ \\gamma = e^z $ 处评估的Gamma先验密度、残差的高斯似然以及由变量替换引入的雅可比项 $ e^z $ 的乘积成正比。您必须基于 $ z $ 的对数后验来实现Metropolis–Hastings接受准则。\n\n测试套件：\n对于以下三种情况，请使用提供的设置模拟数据并运行采样器。请完全按照下面给出的确切值进行操作。\n\n- 情况 A（理想路径）：\n    - 种子 $ = 7 $\n    - 样本大小 $ T = 200 $\n    - 真实风险厌恶系数 $ \\gamma_{\\text{true}} = 2.0 $\n    - 消费增长参数 $ \\mu_c = 0.01 $, $ \\sigma_c = 0.02 $\n    - 折现因子 $ \\beta = 0.99 $\n    - 度量标准差 $ \\sigma_e = 0.01 $\n    - $ \\gamma $ 的先验：Gamma 形状参数 $ k = 2.0 $，尺度参数 $ \\theta = 1.0 $\n    - Metropolis–Hastings：链长 $ N = 16000 $，预烧期 $ B = 4000 $，对数尺度提议标准差 $ s = 0.12 $\n\n- 情况 B（较低风险厌恶，数据噪声较大）：\n    - 种子 $ = 101 $\n    - 样本大小 $ T = 120 $\n    - 真实风险厌恶系数 $ \\gamma_{\\text{true}} = 0.5 $\n    - 消费增长参数 $ \\mu_c = 0.005 $, $ \\sigma_c = 0.015 $\n    - 折现因子 $ \\beta = 0.99 $\n    - 度量标准差 $ \\sigma_e = 0.02 $\n    - $ \\gamma $ 的先验：Gamma 形状参数 $ k = 1.5 $，尺度参数 $ \\theta = 1.0 $\n    - Metropolis–Hastings：链长 $ N = 16000 $，预烧期 $ B = 4000 $，对数尺度提议标准差 $ s = 0.15 $\n\n- 情况 C（较高风险厌恶，重尾先验）：\n    - 种子 $ = 2025 $\n    - 样本大小 $ T = 200 $\n    - 真实风险厌恶系数 $ \\gamma_{\\text{true}} = 5.0 $\n    - 消费增长参数 $ \\mu_c = 0.01 $, $ \\sigma_c = 0.02 $\n    - 折现因子 $ \\beta = 0.99 $\n    - 度量标准差 $ \\sigma_e = 0.01 $\n    - $ \\gamma $ 的先验：Gamma 形状参数 $ k = 2.0 $，尺度参数 $ \\theta = 2.0 $\n    - Metropolis–Hastings：链长 $ N = 16000 $，预烧期 $ B = 4000 $，对数尺度提议标准差 $ s = 0.12 $\n\n要求输出：\n- 对每种情况，使用预烧期后保留的抽样计算 $ \\gamma $ 的后验均值。\n- 将每个后验均值四舍五入到恰好三位小数。\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$ [x_1,x_2,x_3] $）。\n\n不允许也不需要用户输入。程序必须是自包含的，并且在指定的种子和设置下是确定性的。最终输出为浮点数。通过严格遵守上述DGP和贝叶斯构建方法来确保科学真实性。", "solution": "所提出的问题是计算经济学中结构模型贝叶斯估计的一个适定练习。它具有科学依据，内部一致，并为获得唯一的、可验证的解提供了所有必要信息。因此，我们可以进行推导和实现。\n\n其基本经济关系是具有常数相对风险厌恶（CRRA）偏好的代表性代理人的欧拉方程。效用函数为 $u(C) = \\frac{C^{1-\\gamma}}{1-\\gamma}$，其中 $\\gamma > 0$ 是相对风险厌恶系数。代理人进行最优跨期消费和资产配置的一阶条件意味着无套利条件 $\\mathbb{E}_t [m_{t+1} R_{t+1}] = 1$ 成立，其中 $R_{t+1}$ 是资产的总回报率，$m_{t+1}$ 是随机折现因子（SDF）。对于CRRA效用，SDF由 $m_{t+1} = \\beta \\left( \\frac{C_{t+1}}{C_t} \\right)^{-\\gamma}$ 给出，其中 $\\beta \\in (0,1)$ 是主观折现因子。定义消费总增长率为 $G_t = C_{t+1}/C_t$，该条件变为 $\\mathbb{E}_t[\\beta G_t^{-\\gamma} R_{t+1}] = 1$。\n\n为了使该模型在有限的含噪数据集 $D = \\{(G_t, R_{t+1})\\}_{t=1}^T$ 上具有实证可操作性，我们采用指定的度量方程：\n$$\n\\beta \\, G_t^{-\\gamma} \\, R_{t+1} - 1 = \\varepsilon_t, \\quad \\varepsilon_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0, \\sigma_e^2)\n$$\n其中 $\\sigma_e^2$ 是欧拉方程误差的已知方差。此设定意味着观测数据服从高斯似然。对于给定的 $\\gamma$，单个观测值 $(G_t, R_{t+1})$ 的似然是在残差 $\\varepsilon_t$ 处评估的均值为 $0$、方差为 $\\sigma_e^2$ 的正态随机变量的概率密度。因此，整个样本的对数似然为：\n$$\n\\log L(\\gamma | D) = C_L - \\frac{1}{2\\sigma_e^2} \\sum_{t=1}^T \\left( \\beta G_t^{-\\gamma} R_{t+1} - 1 \\right)^2\n$$\n其中 $C_L$ 是一个不依赖于 $\\gamma$ 的常数。\n\n我们将对 $\\gamma$ 进行贝叶斯推断。$\\gamma$ 的先验分布被指定为Gamma分布，$\\gamma \\sim \\text{Gamma}(k,\\theta)$，其概率密度函数为：\n$$\np(\\gamma|k, \\theta) = \\frac{1}{\\Gamma(k)\\theta^k} \\gamma^{k-1} e^{-\\gamma/\\theta}, \\quad \\text{for } \\gamma > 0\n$$\n对数先验（不含加法常数）为：\n$$\n\\log p(\\gamma|k,\\theta) = C_p + (k-1)\\log\\gamma - \\frac{\\gamma}{\\theta}\n$$\n根据贝叶斯定理，$\\gamma$ 的后验密度与似然和先验的乘积成正比，即 $p(\\gamma| D) \\propto L(\\gamma|D) p(\\gamma|k,\\theta)$。因此，对数后验与它们的对数之和成正比：\n$$\n\\log p(\\gamma|D) \\propto (k-1)\\log\\gamma - \\frac{\\gamma}{\\theta} - \\frac{1}{2\\sigma_e^2} \\sum_{t=1}^T \\left( \\beta G_t^{-\\gamma} R_{t+1} - 1 \\right)^2\n$$\n\n估计将使用Metropolis-Hastings算法进行。为了满足 $\\gamma > 0$ 的约束，我们进行变量替换，令 $z = \\log\\gamma \\in (-\\infty, \\infty)$，这意味着 $\\gamma = e^z$。变换后参数 $z$ 的后验密度由 $p(z|D) = p(\\gamma=e^z|D) \\left| \\frac{d\\gamma}{dz} \\right|$ 给出。该变换的雅可比行列式为 $\\left| \\frac{d(e^z)}{dz} \\right| = e^z$。因此，$z$ 的对数后验为：\n$$\n\\log p(z|D) \\propto \\log p(\\gamma=e^z|D) + \\log(e^z) = \\log p(\\gamma=e^z|D) + z\n$$\n将 $\\gamma = e^z$ 代入我们关于 $\\gamma$ 的对数后验表达式中，并加上雅可比项 $z$，即可得到我们采样器的目标对数密度：\n$$\n\\pi(z) \\equiv \\log p(z|D) \\propto (k-1)z - \\frac{e^z}{\\theta} - \\frac{1}{2\\sigma_e^2} \\sum_{t=1}^T \\left( \\beta G_t^{-e^z} R_{t+1} - 1 \\right)^2 + z\n$$\n化简后，我们得到必须评估的核的最终形式：\n$$\n\\pi(z) \\propto kz - \\frac{e^z}{\\theta} - \\frac{1}{2\\sigma_e^2} \\sum_{t=1}^T \\left( \\beta R_{t+1} G_t^{-e^z} - 1 \\right)^2\n$$\n带有随机游走提议的Metropolis-Hastings算法实现如下：\n1. 在 $z^{(0)}$ 处初始化链。一个合理的起始点是先验均值的对数，即 $z^{(0)} = \\log(k\\theta)$。\n2. 对于每一步 $i=1, \\dots, N$：\n    a. 从对称提议分布中提议一个新状态 $z'$：$z' = z^{(i-1)} + \\eta$，其中 $\\eta \\sim \\mathcal{N}(0, s^2)$。\n    b. 计算接受率 $A = \\frac{p(z'|D)}{p(z^{(i-1)}|D)}$。在对数形式下，即为 $\\log A = \\pi(z') - \\pi(z^{(i-1)})$。\n    c. 以概率 $\\alpha = \\min(1, A)$ 接受提议（设 $z^{(i)} = z'$）。否则，拒绝提议（设 $z^{(i)} = z^{(i-1)}$）。\n3. 所得序列 $\\{\\gamma^{(i)} = e^{z^{(i)}}\\}_{i=1}^N$ 是从 $\\gamma$ 的后验分布中得到的一组抽样。\n4. 舍弃初始的预烧期样本 $\\{ \\gamma^{(i)} \\}_{i=1}^B$ 后，$\\gamma$ 的后验均值通过剩余抽样的样本均值来估计：\n$$\n\\hat{\\mathbb{E}}[\\gamma|D] = \\frac{1}{N-B} \\sum_{i=B+1}^N \\gamma^{(i)}\n$$\n此过程将应用于三个测试用例中的每一个，使用根据指定的数据生成过程生成的合成数据，并为数据生成和MCMC采样使用不同的随机数生成器种子以确保可复现性。最终结果是每种情况下 $\\gamma$ 的后验均值，并四舍五入到指定的精度。", "answer": "```python\nimport numpy as np\n\ndef estimate_gamma(params):\n    \"\"\"\n    Simulates data and estimates the risk aversion coefficient gamma using MCMC.\n    \"\"\"\n    # Unpack parameters for conciseness\n    seed = params['seed']\n    T = params['T']\n    gamma_true = params['gamma_true']\n    mu_c = params['mu_c']\n    sigma_c = params['sigma_c']\n    beta = params['beta']\n    sigma_e = params['sigma_e']\n    k = params['k']\n    theta = params['theta']\n    N = params['N']\n    B = params['B']\n    s = params['s']\n\n    # 1. Data-Generating Process (DGP)\n    # Initialize a dedicated pseudo-random number generator for data simulation\n    rng_dgp = np.random.default_rng(seed)\n    \n    # Generate consumption growth G_t\n    eps_c = rng_dgp.standard_normal(T)\n    G = np.exp(mu_c + sigma_c * eps_c)\n    \n    # Generate returns R_{t+1} from the noisy Euler equation\n    eps_r = rng_dgp.normal(loc=0.0, scale=sigma_e, size=T)\n    R = (1.0 + eps_r) / (beta * G**(-gamma_true))\n\n    # Pre-calculate log(G) for efficiency in the sampler\n    G_log = np.log(G)\n\n    # 2. Define the Log-Posterior Kernel for z = log(gamma)\n    # The kernel is the log-posterior density up to an additive constant.\n    # log p(z|D) is proportional to:\n    # kz - exp(z)/theta - (1/(2*sigma_e^2)) * sum( (beta*R*G**(-exp(z)) - 1)**2 )\n    def log_posterior_kernel(z):\n        # Handle cases where z might lead to numerical instability\n        if np.isneginf(z): # Corresponds to gamma=0, which has zero prior probability\n            return -np.inf\n        \n        gamma = np.exp(z)\n        \n        if np.isinf(gamma): # z is too large, exp(z) overflows\n            return -np.inf\n        \n        # Log-prior for z (from Gamma prior on gamma + Jacobian term)\n        # log_prior is proportional to k*z - exp(z)/theta\n        log_prior = k * z - gamma / theta\n        \n        # Log-likelihood\n        # G**(-gamma) is numerically more stable as exp(-gamma * log(G))\n        residuals = beta * R * np.exp(-gamma * G_log) - 1.0\n        log_likelihood = -0.5 * np.sum(residuals**2) / (sigma_e**2)\n        \n        return log_prior + log_likelihood\n\n    # 3. Metropolis-Hastings Sampler\n    # Initialize a second PRNG for the MCMC proposals, as specified\n    rng_mcmc = np.random.default_rng(seed + 10000)\n    \n    # Sensible initial value from the prior mean\n    z_current = np.log(k * theta)\n    log_post_current = log_posterior_kernel(z_current)\n\n    gamma_chain = np.empty(N)\n\n    for i in range(N):\n        # Propose a new state using a random walk on the log-scale\n        z_proposal = z_current + rng_mcmc.normal(loc=0.0, scale=s)\n        \n        # Evaluate the log posterior at the proposal\n        log_post_proposal = log_posterior_kernel(z_proposal)\n        \n        # Calculate the log of the acceptance ratio\n        log_alpha = log_post_proposal - log_post_current\n        \n        # Accept or reject the proposal\n        if np.log(rng_mcmc.uniform()) < log_alpha:\n            z_current = z_proposal\n            log_post_current = log_post_proposal\n        \n        # Store the current state of the chain (in terms of gamma)\n        gamma_chain[i] = np.exp(z_current)\n\n    # 4. Compute Posterior Mean\n    # Discard the burn-in samples and compute the mean of the rest\n    posterior_mean = np.mean(gamma_chain[B:])\n    \n    return posterior_mean\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        { # Case A\n            \"seed\": 7, \"T\": 200, \"gamma_true\": 2.0, \"mu_c\": 0.01, \"sigma_c\": 0.02,\n            \"beta\": 0.99, \"sigma_e\": 0.01, \"k\": 2.0, \"theta\": 1.0,\n            \"N\": 16000, \"B\": 4000, \"s\": 0.12\n        },\n        { # Case B\n            \"seed\": 101, \"T\": 120, \"gamma_true\": 0.5, \"mu_c\": 0.005, \"sigma_c\": 0.015,\n            \"beta\": 0.99, \"sigma_e\": 0.02, \"k\": 1.5, \"theta\": 1.0,\n            \"N\": 16000, \"B\": 4000, \"s\": 0.15\n        },\n        { # Case C\n            \"seed\": 2025, \"T\": 200, \"gamma_true\": 5.0, \"mu_c\": 0.01, \"sigma_c\": 0.02,\n            \"beta\": 0.99, \"sigma_e\": 0.01, \"k\": 2.0, \"theta\": 2.0,\n            \"N\": 16000, \"B\": 4000, \"s\": 0.12\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = estimate_gamma(case)\n        results.append(result)\n\n    # Format the output as a comma-separated list of floats with 3 decimal places\n    # enclosed in square brackets, with no trailing whitespace.\n    output_str = f\"[{','.join([f'{res:.3f}' for res in results])}]\"\n    print(output_str)\n\nsolve()\n```"}]}