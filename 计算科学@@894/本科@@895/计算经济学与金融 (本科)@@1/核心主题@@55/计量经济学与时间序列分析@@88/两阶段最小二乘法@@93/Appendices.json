{"hands_on_practices": [{"introduction": "要掌握两阶段最小二乘法（2SLS），第一步是理解其底层的计算机制。这个练习将引导你通过矩阵代数从头开始实现 2SLS 估计量，这是一个基础但至关重要的技能。你将处理一个经典的计量经济学场景——估计医院质量对患者死亡率的影响，并运用不同的数据集来探索恰好识别 (just-identified) 和过度识别 (over-identified) 的情况，从而巩固你对 2SLS 核心原理的理解 [@problem_id:2445014]。", "id": "2445014", "problem": "考虑一个关于患者治疗结果的计量经济模型，其中医院质量的内生性度量通过偏向最近医院的救护车调度协议来进行工具变量处理。设结构方程为\n$$\ny_i \\;=\\; \\alpha \\;+\\; \\beta\\,x_i \\;+\\; \\gamma\\,w_i \\;+\\; u_i,\n$$\n其中，$y_i$ 是患者 $i$ 的一个标量结果（死亡率指标），$x_i$ 是衡量医院质量的标量内生回归量，$w_i$ 是一个标量外生控制变量（患者协变量），而 $u_i$ 是不可观测的误差。模型通过截距参数 $\\alpha$ 包含了一个常数项。正交性条件由满足以下条件的工具变量 $z_i$ 定义：\n$$\n\\mathbb{E}\\!\\left[z_i\\,u_i\\right] \\;=\\; 0,\n$$\n其中 $z_i$ 包括所有外生回归量以及从救护车调度规则中得出的排他性工具变量。\n\n定义回归量矩阵 $X \\in \\mathbb{R}^{n \\times k}$，其列为 $[\\,\\mathbf{1},\\,w,\\,x\\,]$，以及工具变量矩阵 $Z \\in \\mathbb{R}^{n \\times L}$，其由 $[\\,\\mathbf{1},\\,w,\\,\\text{排他性工具变量}\\,]$ 堆叠而成。对于下述每个测试用例，计算由正交性条件所蕴含的系数 $\\beta$（$x$ 的系数）的两阶段最小二乘法 (TSLS) 估计值，即通过将 $X$ 和 $y$ 投影到 $Z$ 的列空间上所定义的线性工具变量估计量获得的值。您必须将截距和外生控制变量 $w$ 视为包含在 $X$ 和 $Z$ 两者中。\n\n您的程序必须针对每个测试用例实现 $x$ 上的 TSLS 系数的计算，并仅报告每个用例的该系数值。\n\n测试套件：\n\n- 用例 A（恰好识别，相关工具变量）：$n = 8$。使用\n  - $w = [\\,0.20,\\,-0.10,\\,0.00,\\,0.50,\\,-0.30,\\,0.10,\\,-0.40,\\,0.30\\,]$,\n  - $x = [\\,2.00,\\,3.70,\\,2.20,\\,3.90,\\,1.80,\\,3.40,\\,2.10,\\,3.60\\,]$,\n  - 排他性工具变量 $z^{(1)} = [\\,0,\\,1,\\,0,\\,1,\\,0,\\,1,\\,0,\\,1\\,]$,\n  - $y = [\\,0.156,\\,0.020,\\,0.098,\\,0.076,\\,0.108,\\,0.054,\\,0.102,\\,0.038\\,]$.\n  此处，$Z = [\\,\\mathbf{1},\\,w,\\,z^{(1)}\\,]$ 且 $X = [\\,\\mathbf{1},\\,w,\\,x\\,]$。\n\n- 用例 B（弱但有效的工具变量）：$n = 8$。使用\n  - $w = [\\,0.20,\\,-0.10,\\,0.00,\\,0.50,\\,-0.30,\\,0.10,\\,-0.40,\\,0.30\\,]$,\n  - $x = [\\,2.90,\\,3.10,\\,3.00,\\,3.20,\\,2.90,\\,3.10,\\,2.95,\\,3.05\\,]$,\n  - 排他性工具变量 $z^{(1)} = [\\,0,\\,1,\\,0,\\,1,\\,1,\\,0,\\,0,\\,1\\,]$,\n  - $y = [\\,0.097,\\,0.051,\\,0.070,\\,0.113,\\,0.042,\\,0.072,\\,0.046,\\,0.081\\,]$.\n  此处，$Z = [\\,\\mathbf{1},\\,w,\\,z^{(1)}\\,]$ 且 $X = [\\,\\mathbf{1},\\,w,\\,x\\,]$。\n\n- 用例 C（过度识别，两个排他性工具变量）：$n = 10$。使用\n  - $w = [\\,0.00,\\,0.20,\\,-0.20,\\,0.50,\\,-0.10,\\,0.30,\\,-0.40,\\,0.10,\\,-0.30,\\,0.40\\,]$,\n  - $x = [\\,3.80,\\,3.50,\\,2.20,\\,4.00,\\,2.40,\\,3.70,\\,1.90,\\,3.40,\\,2.10,\\,3.90\\,]$,\n  - 排他性工具变量：\n    - $z^{(1)} = [\\,1,\\,1,\\,0,\\,1,\\,0,\\,1,\\,0,\\,1,\\,0,\\,1\\,]$,\n    - $z^{(2)} = [\\,0.80,\\,0.60,\\,-0.70,\\,0.90,\\,-0.50,\\,0.70,\\,-0.90,\\,0.50,\\,-0.60,\\,0.80\\,]$,\n  - $y = [\\,0.022,\\,0.066,\\,0.082,\\,0.070,\\,0.098,\\,0.062,\\,0.094,\\,0.054,\\,0.100,\\,0.028\\,]$.\n  此处，$Z = [\\,\\mathbf{1},\\,w,\\,z^{(1)},\\,z^{(2)}\\,]$ 且 $X = [\\,\\mathbf{1},\\,w,\\,x\\,]$。\n\n每个用例的计算目标：\n\n- 使用基于将 $X$ 和 $y$ 投影到 $Z$ 的列空间上的定义，计算 $\\beta$ 的 TSLS 估计值。\n- 仅返回 $\\beta$ 的标量估计值。\n\n最终输出规格：\n\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个测试用例对应一个浮点数，按用例 A、用例 B、用例 C 的顺序排列。\n- 每个数字必须四舍五入到六位小数。\n- 例如，包含三个结果的输出必须类似于 $[b_A,b_B,b_C]$，其中每个 $b_{\\cdot}$ 是一个四舍五入到六位小数的浮点数。", "solution": "所提供的问题陈述已经过验证，并被确定为有效。它在已建立的计量经济学理论中具有科学依据，问题设定适定，有足够的计算数据，且表述客观。未发现任何妨碍得出严谨解法的缺陷。\n\n该问题要求在线性结构模型中计算系数 $\\beta$ 的两阶段最小二乘法 ($TSLS$) 估计值：\n$$\ny_i \\;=\\; \\alpha \\;+\\; \\gamma\\,w_i \\;+\\; \\beta\\,x_i \\;+\\; u_i\n$$\n此处，$y_i$ 是结果，$x_i$ 是内生回归量，$w_i$ 是外生控制变量，$u_i$ 是观测值 $i$ 的误差项。以矩阵形式，该模型写作 $y = X\\mathbf{b} + u$，其中 $y \\in \\mathbb{R}^{n}$ 是结果向量，$X \\in \\mathbb{R}^{n \\times k}$ 是回归量矩阵，$\\mathbf{b} \\in \\mathbb{R}^{k}$ 是系数向量，$u \\in \\mathbb{R}^{n}$ 是不可观测误差向量。\n\n根据问题规定，回归量矩阵为 $X = [\\begin{matrix} \\mathbf{1} & w & x \\end{matrix}]$，其中 $\\mathbf{1}$ 是对应截距 $\\alpha$ 的全一向量，$w$ 是对应系数 $\\gamma$ 的外生协变量向量，$x$ 是对应系数 $\\beta$ 的内生回归量向量。因此，回归量的数量为 $k=3$，待估计的系数向量为 $\\mathbf{b} = [\\alpha, \\gamma, \\beta]^T$。\n\n$x$ 的内生性意味着其值与误差项 $u$ 相关，具体而言，$\\mathbb{E}[x_i u_i] \\neq 0$。这种相关性违反了普通最小二乘法 ($OLS$) 的一个关键假设，使得 $\\mathbf{b}$ 的 $OLS$ 估计量有偏且不一致。$TSLS$ 方法通过使用一组工具变量来克服这个问题，这些工具变量收集在矩阵 $Z \\in \\mathbb{R}^{n \\times L}$ 中，它们与内生回归量 $x$ 相关，但与误差项 $u$ 不相关。这由正交性条件 $\\mathbb{E}[Z^T u] = 0$ 来体现。矩阵 $Z$ 由模型中已有的所有外生变量（截距和 $w$，称为内含工具变量）以及一个或多个称为排他性工具变量的附加变量组成。\n\n顾名思义，$TSLS$ 过程可以概念化为两个阶段。\n\n第一阶段：从内生回归量中清除误差项的影响。这通过将回归量矩阵 $X$ 投影到由工具变量矩阵 $Z$ 的列所张成的线性空间上实现。到 $Z$ 的列空间上的正交投影矩阵由下式给出：\n$$\nP_Z = Z(Z^T Z)^{-1}Z^T\n$$\n由此投影得到的 $X$ 的预测值，记为 $\\hat{X}$，计算如下：\n$$\n\\hat{X} = P_Z X\n$$\n这些拟合值 $\\hat{X}$ 是 $Z$ 中工具变量的线性组合，因此与误差项 $u$ 渐近不相关。\n\n第二阶段：使用结果变量 $y$ 和投影后的回归量 $\\hat{X}$ 进行 $OLS$ 回归。此回归得到的系数向量即为 $TSLS$ 估计量 $\\hat{\\mathbf{b}}_{\\text{TSLS}}$：\n$$\n\\hat{\\mathbf{b}}_{\\text{TSLS}} = (\\hat{X}^T \\hat{X})^{-1} \\hat{X}^T y\n$$\n为了得到直接的计算公式，我们代入 $\\hat{X} = P_Z X$。利用投影矩阵是对称的 ($P_Z^T = P_Z$) 和幂等的 ($P_Z P_Z = P_Z$) 性质，我们简化估计量的各组成部分：\n$$\n\\hat{X}^T \\hat{X} = (P_Z X)^T (P_Z X) = X^T P_Z^T P_Z X = X^T P_Z X\n$$\n以及\n$$\n\\hat{X}^T y = (P_Z X)^T y = X^T P_Z^T y = X^T P_Z y\n$$\n这导出了 $TSLS$ 估计量的一般表达式：\n$$\n\\hat{\\mathbf{b}}_{\\text{TSLS}} = (X^T P_Z X)^{-1} (X^T P_Z y)\n$$\n通过代入 $P_Z$ 的定义，我们得到用于计算的完整公式：\n$$\n\\hat{\\mathbf{b}}_{\\text{TSLS}} = \\left( X^T Z(Z^T Z)^{-1}Z^T X \\right)^{-1} \\left( X^T Z(Z^T Z)^{-1}Z^T y \\right)\n$$\n这个单一公式对恰好识别的情况（工具变量数量 $L$ 等于回归量数量 $k$）和过度识别的情况 ($L > k$) 都有效。\n\n对于所提供的每个测试用例，我们根据数据构造向量 $y$ 以及矩阵 $X$ 和 $Z$。然后，我们应用推导出的公式来计算系数向量 $\\hat{\\mathbf{b}}_{\\text{TSLS}} = [\\hat{\\alpha}, \\hat{\\gamma}, \\hat{\\beta}]^T$。要求的结果是标量估计值 $\\hat{\\beta}$，即该向量的第三个元素。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the TSLS estimate of the coefficient beta for each test case.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"name\": \"Case A\",\n            \"n\": 8,\n            \"w\": np.array([0.20, -0.10, 0.00, 0.50, -0.30, 0.10, -0.40, 0.30]),\n            \"x\": np.array([2.00, 3.70, 2.20, 3.90, 1.80, 3.40, 2.10, 3.60]),\n            \"excluded_instruments\": [\n                np.array([0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0])\n            ],\n            \"y\": np.array([0.156, 0.020, 0.098, 0.076, 0.108, 0.054, 0.102, 0.038]),\n        },\n        {\n            \"name\": \"Case B\",\n            \"n\": 8,\n            \"w\": np.array([0.20, -0.10, 0.00, 0.50, -0.30, 0.10, -0.40, 0.30]),\n            \"x\": np.array([2.90, 3.10, 3.00, 3.20, 2.90, 3.10, 2.95, 3.05]),\n            \"excluded_instruments\": [\n                np.array([0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n            ],\n            \"y\": np.array([0.097, 0.051, 0.070, 0.113, 0.042, 0.072, 0.046, 0.081]),\n        },\n        {\n            \"name\": \"Case C\",\n            \"n\": 10,\n            \"w\": np.array([0.00, 0.20, -0.20, 0.50, -0.10, 0.30, -0.40, 0.10, -0.30, 0.40]),\n            \"x\": np.array([3.80, 3.50, 2.20, 4.00, 2.40, 3.70, 1.90, 3.40, 2.10, 3.90]),\n            \"excluded_instruments\": [\n                np.array([1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]),\n                np.array([0.80, 0.60, -0.70, 0.90, -0.50, 0.70, -0.90, 0.50, -0.60, 0.80]),\n            ],\n            \"y\": np.array([0.022, 0.066, 0.082, 0.070, 0.098, 0.062, 0.094, 0.054, 0.100, 0.028]),\n        },\n    ]\n\n    def compute_tsls_beta(y, w, x, excluded_instruments, n):\n        \"\"\"\n        Computes the TSLS estimate for the coefficient on x.\n\n        The formula is beta_hat_tsls = (X'Z(Z'Z)^-1 Z'X)^-1 X'Z(Z'Z)^-1 Z'y\n        \"\"\"\n        # Reshape vectors to be column vectors for matrix operations\n        y_col = y.reshape(-1, 1)\n        w_col = w.reshape(-1, 1)\n        x_col = x.reshape(-1, 1)\n        \n        # Construct the regressor matrix X = [1, w, x]\n        ones = np.ones((n, 1))\n        X = np.hstack((ones, w_col, x_col))\n\n        # Construct the instrument matrix Z = [1, w, excluded_instruments...]\n        z_parts = [ones, w_col]\n        for z_ex in excluded_instruments:\n            z_parts.append(z_ex.reshape(-1, 1))\n        Z = np.hstack(z_parts)\n\n        # Apply the TSLS formula\n        # Let's compute parts of the formula for clarity\n        # We use np.linalg.solve(A, B) for X = A^-1 B for better numerical stability\n        \n        # Compute projection matrix part: Pz = Z @ inv(Z'Z) @ Z'\n        # A more stable way than forming Pz explicitly is to use its components.\n        try:\n            ZTZ_inv = np.linalg.inv(Z.T @ Z)\n        except np.linalg.LinAlgError:\n            # Handle cases where Z'Z is singular.\n            return np.nan\n\n        # First part of the formula: X' * P_Z\n        # X_T_PZ = X.T @ Z @ ZTZ_inv @ Z.T\n        # This can be computed more efficiently.\n        \n        # Term inside the inverse: A = X'Z(Z'Z)^-1 Z'X\n        XZ_term = X.T @ Z\n        A = XZ_term @ ZTZ_inv @ XZ_term.T\n\n        # Term for the y part: B = X'Z(Z'Z)^-1 Z'y\n        Zy_term = Z.T @ y_col\n        B = XZ_term @ ZTZ_inv @ Zy_term\n        \n        # b_hat = inv(A) @ B\n        try:\n            b_hat = np.linalg.solve(A, B)\n        except np.linalg.LinAlgError:\n            # Handle cases where the matrix for the second stage is singular.\n            return np.nan\n\n        # The coefficient beta is the third element (index 2)\n        beta_hat = b_hat[2, 0]\n        return beta_hat\n\n    results = []\n    for case in test_cases:\n        beta_estimate = compute_tsls_beta(\n            case[\"y\"],\n            case[\"w\"],\n            case[\"x\"],\n            case[\"excluded_instruments\"],\n            case[\"n\"]\n        )\n        results.append(f\"{beta_estimate:.6f}\")\n    \n    # Format and print the final output as specified.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"}, {"introduction": "在掌握了 2SLS 的一般形式后，让我们来看一个其在实践中非常直观且强大的应用。本练习将 2SLS 与回归断点设计（Regression Discontinuity Design, RDD）联系起来，利用毫厘之差的选举结果作为准随机工具变量。通过这个练习，你将看到在二元工具变量的特定情况下，复杂的 2SLS 公式如何简化为直观的 Wald 估计量，即两组间结果差异与处理差异的比率，这将极大地加深你对工具变量如何分离外生变异的理解 [@problem_id:2445017]。", "id": "2445017", "problem": "给定三个独立的数据集，每个数据集代表经历过票数非常接近的选举的辖区的截面数据。对于辖区 $i$，令 $y_i$ 表示一个我们感兴趣结果的变化量，$D_i$ 表示一个财政政策变量的变化量，而 $m_i$ 表示在任者的得票率优势（定义为在任者的得票份额减去挑战者的得票份额）。定义二元指示变量 $Z_i$ 为：如果 $m_i &lt; 0$，则 $Z_i = 1$；否则 $Z_i = 0$。假设在零点附近一个极窄的带宽内，$m_i$ 的符号是准随机的，因此 $Z_i$ 可作为 $D_i$ 的有效工具变量。考虑以下线性结构关系\n$$\ny_i = \\beta D_i + \\gamma \\cdot 1 + u_i,\n$$\n其中 $1$ 是截距项回归量，$\\beta$ 和 $\\gamma$ 是未知系数，$u_i$ 是一个不可观测的扰动项。假设正交性条件\n$$\n\\mathbb{E}[u_i] = 0 \\quad \\text{and} \\quad \\mathbb{E}[Z_i u_i] = 0,\n$$\n因此工具变量集是 $\\{1, Z_i\\}$ 的生成空间，且 $D_i$ 可能是内生的。对于每个数据集，只包含满足 $\\lvert m_i \\rvert \\le \\tau$ 的观测值，其中 $\\tau$ 是一个给定的非负阈值。\n\n对于下方的每个数据集，计算满足上述模型及工具变量 $\\{1, Z_i\\}$ 所隐含的样本正交性条件的唯一 $\\beta$ 值。您的程序必须仅使用所提供的数组为每个数据集计算此值。不允许使用外部输入。最终所需的输出是实数。\n\n测试套件（每个数据集提供 $(\\tau, (m_i)_i, (D_i)_i, (y_i)_i)$）：\n\n- 数据集 1：\n  - $\\tau = 0.020$,\n  - $m = (-0.010,\\,-0.015,\\,-0.008,\\,0.012,\\,0.005,\\,0.017)$,\n  - $D = (5.0,\\,5.0,\\,5.0,\\,1.0,\\,2.0,\\,3.0)$,\n  - $y = (10.0,\\,10.0,\\,10.0,\\,2.0,\\,4.0,\\,6.0)$.\n\n- 数据集 2：\n  - $\\tau = 0.010$,\n  - $m = (-0.004,\\,-0.003,\\,-0.001,\\,0.006,\\,0.009,\\,0.002)$,\n  - $D = (2.6,\\,2.6,\\,2.6,\\,2.5,\\,2.5,\\,2.5)$,\n  - $y = (5.0,\\,5.0,\\,5.0,\\,4.8,\\,4.8,\\,4.8)$.\n\n- 数据集 3：\n  - $\\tau = 0.015$,\n  - $m = (-0.010,\\,0.005,\\,0.007,\\,0.008,\\,0.012)$,\n  - $D = (4.0,\\,3.0,\\,3.0,\\,3.0,\\,3.0)$,\n  - $y = (8.5,\\,6.0,\\,6.0,\\,6.0,\\,6.0)$.\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表，每个数字四舍五入到六位小数。例如，如果计算出的三个值是 $a$、$b$ 和 $c$，则应精确打印 $[a,b,c]$ 这一行，其中 $a$、$b$ 和 $c$ 均四舍五入至六位小数。不得打印任何其他文本。", "solution": "所给问题要求在一个具有潜在内生回归量的线性模型中，计算一个结构参数 $\\beta$。估计需要使用工具变量法（IV）进行，对于一个恰好识别的系统，这是一种两阶段最小二乘法（2SLS）的特殊应用。\n\n首先，我们来对问题进行形式化描述。给定结果变量 $y_i$ 作为策略变量 $D_i$ 函数的结构方程：\n$$\ny_i = \\beta D_i + \\gamma \\cdot 1 + u_i\n$$\n此处，$\\beta$ 和 $\\gamma$ 是我们感兴趣的参数，$1$ 代表截距项的回归量，$u_i$ 是一个不可观测的扰动项。变量 $D_i$ 可能是内生的，意味着它可能与 $u_i$ 相关。\n\n为解决此内生性问题，我们获得了一个工具变量 $Z_i$。该工具变量是一个二元指示变量，源自在任者的得票率优势 $m_i$，定义为：如果 $m_i < 0$，则 $Z_i = 1$；否则 $Z_i = 0$。问题提供了允许进行一致性估计的基本正交性条件：\n$$\n\\mathbb{E}[u_i] = 0 \\quad \\text{and} \\quad \\mathbb{E}[Z_i u_i] = 0\n$$\n这些总体矩条件表明，扰动项 $u_i$ 与常数项以及工具变量 $Z_i$ 不相关。因此，工具变量集是 $\\{1, Z_i\\}$ 的生成空间。\n\n任务是找到满足这些正交性条件的样本模拟(sample analogues)的 $\\beta$ 值。这些样本矩条件是：\n$$\n\\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{\\beta} D_i - \\hat{\\gamma}) = 0 \\\\\n\\frac{1}{N} \\sum_{i=1}^{N} Z_i (y_i - \\hat{\\beta} D_i - \\hat{\\gamma}) = 0\n$$\n其中 $N$ 是观测值的数量，$\\hat{\\beta}$ 和 $\\hat{\\gamma}$ 是 $\\beta$ 和 $\\gamma$ 的估计量。\n\n这是一个包含两个未知数 $\\hat{\\beta}$ 和 $\\hat{\\gamma}$ 的二元线性方程组。我们可以解这个方程组来推导出 $\\hat{\\beta}$ 的显式公式。\n从第一个方程，我们可以用 $\\hat{\\beta}$ 来表示 $\\hat{\\gamma}$：\n$$\n\\hat{\\gamma} = \\bar{y} - \\hat{\\beta} \\bar{D}\n$$\n其中 $\\bar{y} = \\frac{1}{N}\\sum y_i$ 和 $\\bar{D} = \\frac{1}{N}\\sum D_i$ 是样本均值。\n将 $\\hat{\\gamma}$ 的这个表达式代入第二个方程得到：\n$$\n\\sum_{i=1}^{N} Z_i (y_i - \\hat{\\beta} D_i - (\\bar{y} - \\hat{\\beta} \\bar{D})) = 0 \\\\\n\\sum_{i=1}^{N} Z_i (y_i - \\bar{y}) - \\hat{\\beta} \\sum_{i=1}^{N} Z_i (D_i - \\bar{D}) = 0\n$$\n求解 $\\hat{\\beta}$ 可得到通用 IV 估计量公式：\n$$\n\\hat{\\beta}_{IV} = \\frac{\\sum_{i=1}^{N} Z_i (y_i - \\bar{y})}{\\sum_{i=1}^{N} Z_i (D_i - \\bar{D})} = \\frac{\\widehat{\\text{Cov}}(Z, y)}{\\widehat{\\text{Cov}}(Z, D)}\n$$\n其中 $\\widehat{\\text{Cov}}(X, V)$ 表示变量 $X$ 和 $V$ 之间的样本协方差。当且仅当分母非零，$\\widehat{\\text{Cov}}(Z, D) \\neq 0$ 时，存在唯一解，这就是工具变量相关性条件。\n\n鉴于工具变量 $Z_i$ 是二元的，该估计量可简化为沃尔德估计量（Wald estimator）。令 $N_1$ 为 $Z_i=1$ 的观测值数量，$N_0$ 为 $Z_i=0$ 的观测值数量。沃尔德估计量是根据工具变量定义的两组之间，平均结果的差异与平均处理效应的差异之比：\n$$\n\\hat{\\beta}_{Wald} = \\frac{\\mathbb{E}[y | Z=1] - \\mathbb{E}[y | Z=0]}{\\mathbb{E}[D | Z=1] - \\mathbb{E}[D | Z=0]}\n$$\n其样本模拟为：\n$$\n\\hat{\\beta} = \\frac{\\bar{y}_{Z=1} - \\bar{y}_{Z=0}}{\\bar{D}_{Z=1} - \\bar{D}_{Z=0}}\n$$\n其中 $\\bar{y}_{Z=j}$ 和 $\\bar{D}_{Z=j}$ 是 $Z_i=j$ 的观测值子组中 $y_i$ 和 $D_i$ 的样本均值。这个公式在计算上更为直接，将用于后续计算。\n\n问题规定，对于每个数据集，只使用满足 $|m_i| \\le \\tau$ 的观测值。对于所提供的所有三个数据集，每个数据点都满足此条件，因此没有观测值被丢弃。\n\n**数据集 1：**\n- $\\tau = 0.020$\n- $m = (-0.010, -0.015, -0.008, 0.012, 0.005, 0.017)$\n- $D = (5.0, 5.0, 5.0, 1.0, 2.0, 3.0)$\n- $y = (10.0, 10.0, 10.0, 2.0, 4.0, 6.0)$\n\n工具变量向量为 $Z = (1, 1, 1, 0, 0, 0)$。\n对于 $Z_i=1$ 的组（前3个观测值）：\n- $\\bar{y}_{Z=1} = \\frac{10.0 + 10.0 + 10.0}{3} = 10.0$\n- $\\bar{D}_{Z=1} = \\frac{5.0 + 5.0 + 5.0}{3} = 5.0$\n对于 $Z_i=0$ 的组（后3个观测值）：\n- $\\bar{y}_{Z=0} = \\frac{2.0 + 4.0 + 6.0}{3} = 4.0$\n- $\\bar{D}_{Z=0} = \\frac{1.0 + 2.0 + 3.0}{3} = 2.0$\n$\\beta$ 的估计值为：\n$$\n\\hat{\\beta}_1 = \\frac{10.0 - 4.0}{5.0 - 2.0} = \\frac{6.0}{3.0} = 2.0\n$$\n\n**数据集 2：**\n- $\\tau = 0.010$\n- $m = (-0.004, -0.003, -0.001, 0.006, 0.009, 0.002)$\n- $D = (2.6, 2.6, 2.6, 2.5, 2.5, 2.5)$\n- $y = (5.0, 5.0, 5.0, 4.8, 4.8, 4.8)$\n\n工具变量向量为 $Z = (1, 1, 1, 0, 0, 0)$。\n对于 $Z_i=1$ 的组：\n- $\\bar{y}_{Z=1} = \\frac{5.0 + 5.0 + 5.0}{3} = 5.0$\n- $\\bar{D}_{Z=1} = \\frac{2.6 + 2.6 + 2.6}{3} = 2.6$\n对于 $Z_i=0$ 的组：\n- $\\bar{y}_{Z=0} = \\frac{4.8 + 4.8 + 4.8}{3} = 4.8$\n- $\\bar{D}_{Z=0} = \\frac{2.5 + 2.5 + 2.5}{3} = 2.5$\n$\\beta$ 的估计值为：\n$$\n\\hat{\\beta}_2 = \\frac{5.0 - 4.8}{2.6 - 2.5} = \\frac{0.2}{0.1} = 2.0\n$$\n\n**数据集 3：**\n- $\\tau = 0.015$\n- $m = (-0.010, 0.005, 0.007, 0.008, 0.012)$\n- $D = (4.0, 3.0, 3.0, 3.0, 3.0)$\n- $y = (8.5, 6.0, 6.0, 6.0, 6.0)$\n\n工具变量向量为 $Z = (1, 0, 0, 0, 0)$。\n对于 $Z_i=1$ 的组（第1个观测值）：\n- $\\bar{y}_{Z=1} = 8.5$\n- $\\bar{D}_{Z=1} = 4.0$\n对于 $Z_i=0$ 的组（后4个观测值）：\n- $\\bar{y}_{Z=0} = \\frac{6.0 + 6.0 + 6.0 + 6.0}{4} = 6.0$\n- $\\bar{D}_{Z=0} = \\frac{3.0 + 3.0 + 3.0 + 3.0}{4} = 3.0$\n$\\beta$ 的估计值为：\n$$\n\\hat{\\beta}_3 = \\frac{8.5 - 6.0}{4.0 - 3.0} = \\frac{2.5}{1.0} = 2.5\n$$\n三个数据集计算出的 $\\beta$ 值分别为 $2.0$、$2.0$ 和 $2.5$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the instrumental variables (IV) estimate of beta for three datasets.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"tau\": 0.020,\n            \"m\": np.array([-0.010, -0.015, -0.008, 0.012, 0.005, 0.017]),\n            \"D\": np.array([5.0, 5.0, 5.0, 1.0, 2.0, 3.0]),\n            \"y\": np.array([10.0, 10.0, 10.0, 2.0, 4.0, 6.0]),\n        },\n        {\n            \"tau\": 0.010,\n            \"m\": np.array([-0.004, -0.003, -0.001, 0.006, 0.009, 0.002]),\n            \"D\": np.array([2.6, 2.6, 2.6, 2.5, 2.5, 2.5]),\n            \"y\": np.array([5.0, 5.0, 5.0, 4.8, 4.8, 4.8]),\n        },\n        {\n            \"tau\": 0.015,\n            \"m\": np.array([-0.010, 0.005, 0.007, 0.008, 0.012]),\n            \"D\": np.array([4.0, 3.0, 3.0, 3.0, 3.0]),\n            \"y\": np.array([8.5, 6.0, 6.0, 6.0, 6.0]),\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        tau, m, D, y = case[\"tau\"], case[\"m\"], case[\"D\"], case[\"y\"]\n\n        # Filter the data based on the threshold tau.\n        # For the given problem, all data points satisfy the condition,\n        # but this step ensures correctness for a general case.\n        inclusion_mask = np.abs(m) <= tau\n        m_filtered = m[inclusion_mask]\n        D_filtered = D[inclusion_mask]\n        y_filtered = y[inclusion_mask]\n\n        # Construct the binary instrument Z, where Z=1 if m < 0.\n        Z = (m_filtered < 0).astype(int)\n\n        # Identify the two groups based on the instrument value.\n        Z_is_1_mask = (Z == 1)\n        Z_is_0_mask = (Z == 0)\n\n        # Separate the y and D vectors into two groups.\n        y_group_1 = y_filtered[Z_is_1_mask]\n        y_group_0 = y_filtered[Z_is_0_mask]\n        D_group_1 = D_filtered[Z_is_1_mask]\n        D_group_0 = D_filtered[Z_is_0_mask]\n\n        # The problem statement guarantees a unique solution exists,\n        # which implies both groups are non-empty and the denominator of the\n        # Wald estimator is non-zero.\n        \n        # Calculate the mean of y and D for each group.\n        y_mean_1 = np.mean(y_group_1)\n        y_mean_0 = np.mean(y_group_0)\n        D_mean_1 = np.mean(D_group_1)\n        D_mean_0 = np.mean(D_group_0)\n\n        # Calculate beta using the Wald estimator formula.\n        beta = (y_mean_1 - y_mean_0) / (D_mean_1 - D_mean_0)\n\n        results.append(beta)\n\n    # Format the final output as a comma-separated list of values\n    # rounded to six decimal places, enclosed in square brackets.\n    output_str = \",\".join([f\"{res:.6f}\" for res in results])\n    print(f\"[{output_str}]\")\n\nsolve()\n```"}]}