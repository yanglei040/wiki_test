{"hands_on_practices": [{"introduction": "向量自回归 (VAR) 模型的一个核心用途是捕捉经济系统随时间演变的动态特性。然而，模型的动态行为是否能准确反映现实，很大程度上取决于模型设定的正确性。这个练习旨在通过一个具体的例子，展示模型误设（misspecification）的后果：当一个具有内在振荡行为的真实二阶自回归 (AR(2)) 过程被一个错误的一阶模型 (AR(1)) 来近似时，我们将会看到近似模型得出的动态响应是完全错误的。通过计算并比较真实与估计的脉冲响应函数 (Impulse Response Functions, IRFs)，你将亲身体会到正确选择模型阶数对于理解系统对冲击的反应是何等重要 [@problem_id:2447477]。", "id": "2447477", "problem": "给定一个由二阶自回归定义的平稳单变量数据生成过程\n$$ y_t = 0.9\\,y_{t-1} - 0.8\\,y_{t-2} + \\epsilon_t, $$\n其中创新项满足 $$\\epsilon_t \\sim \\text{i.i.d. } \\mathcal{N}(0,1)$$ 且跨时间独立。设初始条件为 $$y_{-1}=0 \\text{ 和 } y_0=0$$。考虑使用一阶向量自回归 (VAR) 模型（对于单变量，该模型简化为一阶自回归）来近似此过程的动态，即模型形式如下\n$$ y_t = a\\,y_{t-1} + u_t, $$\n该模型无截距项，且 $$u_t$$ 为一个残差项。\n\n您的任务如下，所有任务都需在单个程序内完成：\n\n1. 模拟。对于每个测试用例，使用上述指定参数，从给定的二阶自回归过程中模拟 $$T+B$$ 个观测值，其中 $$B$$ 是一个预烧期（burn-in）长度。舍弃前 $$B$$ 个观测值，保留最后的 $$T$$ 个观测值用于分析。\n\n2. 估计。对于每个保留的样本，通过最小化保留样本上的一步向前预测误差的平方和，来估计一阶向量自回归 (VAR(1)) 的系数 $$a$$，即找到\n$$ \\hat{a} \\in \\arg\\min_{a \\in \\mathbb{R}} \\sum_{t=1}^{T-1} \\left(y_{t+1} - a\\,y_t\\right)^2. $$\n\n3. 脉冲响应。对于每个测试用例和一个指定的时期 $$H \\in \\mathbb{N}$$，计算：\n   - 在时期 $$h=1,2,\\dots,H$$ 上，真实的二阶自回归模型的一个标准差脉冲响应序列。该序列由移动平均系数 $$\\{\\psi_h\\}_{h \\ge 0}$$ 递归定义，满足\n     $$ \\psi_0 = 1,\\quad \\psi_1 = 0.9,\\quad \\psi_h = 0.9\\,\\psi_{h-1} - 0.8\\,\\psi_{h-2}\\ \\text{for all}\\ h \\ge 2. $$\n     在时期 $$h$$ 的脉冲响应为 $$\\psi_h$$。\n   - 在时期 $$h=1,2,\\dots,H$$ 上，估计的一阶向量自回归模型的脉冲响应序列，定义为 $$\\theta_h = \\hat{a}^{\\,h}$$，并约定 $$\\theta_0=1.$$\n\n4. 误导性动态指标。对于每个测试用例，计算在时期集合 $$\\{1,2,\\dots,H\\}$$ 中，估计的 VAR(1) 脉冲响应的符号与真实脉冲响应的符号不同的时期的比例。使用符号函数 $$\\operatorname{sgn}:\\mathbb{R}\\to\\{-1,0,1\\}$$，其定义为\n$$ \\operatorname{sgn}(x)=\\begin{cases}1&\\text{if }x>0,\\\\0&\\text{if }x=0,\\\\-1&\\text{if }x&lt;0.\\end{cases} $$\n令 $$m(H)$$ 表示满足 $$\\operatorname{sgn}(\\theta_h) \\neq \\operatorname{sgn}(\\psi_h)$$ 的索引 $$h \\in \\{1,\\dots,H\\}$$ 的数量。所需的指标是以下比例\n$$ \\frac{m(H)}{H}. $$\n\n5. 输出规格。您的程序必须输出单行内容，该行包含一个由方括号括起来的逗号分隔列表，其中每个测试用例对应一个浮点数，即比例 $$m(H)/H$$ 的值，四舍五入到六位小数。\n\n所有测试用例统一使用的模拟细节：\n- 预烧期长度 $$B=500$$。\n- 创新项方差等于 $$1$$。\n- 保留的样本大小 $$T$$ 和时期 $$H$$ 在下面的每个测试用例中指定。\n- 在推理中可能出现的任何角度，都不需要在输出中体现，也无需单位。不涉及任何物理单位。\n\n测试套件。为以下参数值运行您的程序：\n- 测试用例 1: $$T=5000$$ 且 $$H=12$$。\n- 测试用例 2: $$T=100$$ 且 $$H=12$$。\n- 测试用例 3: $$T=2000$$ 且 $$H=1$$。\n- 测试用例 4: $$T=2000$$ 且 $$H=30$$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个方括号括起来的逗号分隔列表，结果按上述测试用例的顺序列出，例如 $$[r_1,r_2,r_3,r_4]$$，其中每个 $$r_i$$ 是对应测试用例的比例 $$m(H)/H$$，四舍五入到六位小数。", "solution": "问题陈述已被验证，并被确定为一项有效、有科学依据且良构的计算计量经济学练习。它通过用一阶自回归模型 AR($1$) 近似二阶自回归过程 AR($2$)，来探讨模型设定错误的后果。所有参数和步骤都已明确指定。通过分析其特征多项式 $\\lambda(z) = 1 - 0.9 z + 0.8 z^2$，可以确认真实 AR($2$) 过程 $y_t = 0.9\\,y_{t-1} - 0.8\\,y_{t-2} + \\epsilon_t$ 的平稳性。$\\lambda(z)=0$ 的根为 $z = \\frac{0.9 \\pm i\\sqrt{2.39}}{1.6}$，其模为 $\\sqrt{1.25}$。由于该模大于 1，根位于单位圆之外，这证实了该过程确实是平稳的，与问题陈述一致。\n\n该解决方案需要进行一项蒙特卡洛模拟研究。对于每个测试用例，该过程包括四个主要步骤：模拟真实过程，估计近似模型的参数，计算两个模型的脉冲响应函数，以及计算一个指标来量化它们动态特性上的差异。\n\n**步骤 1：模拟 AR(2) 过程**\n数据生成过程由以下随机差分方程定义：\n$$ y_t = 0.9\\,y_{t-1} - 0.8\\,y_{t-2} + \\epsilon_t $$\n其中创新项 $\\epsilon_t$ 是独立同分布的标准正态随机变量，即 $\\epsilon_t \\sim \\mathcal{N}(0,1)$。该过程以条件 $y_{-1}=0$ 和 $y_0=0$ 初始化。对于每个由样本大小 $T$ 和时期 $H$ 定义的测试用例，将生成一个总长度为 $T+B$ 的时间序列，其中 $B=500$ 是指定的预烧期。舍弃前 $B$ 个观测值，以确保分析是在能够代表该过程平稳分布的样本上进行的，从而减轻任意初始条件的影响。模拟从 $t=1$ 开始，使用给定的递归关系迭代进行：\n- $y_1 = 0.9\\,y_0 - 0.8\\,y_{-1} + \\epsilon_1 = \\epsilon_1$\n- $y_2 = 0.9\\,y_1 - 0.8\\,y_0 + \\epsilon_2 = 0.9\\,y_1 + \\epsilon_2$\n- ...对于后续的时间步直到 $t = T+B$ 也是如此。\n\n**步骤 2：估计 AR(1) 系数**\n更复杂的 AR($2$) 过程将由一个更简单的 AR($1$) 模型来近似，该模型是单变量 VAR($1$) 的一个特例，形式如下：\n$$ y_t = a\\,y_{t-1} + u_t $$\n系数 $a$ 是通过在保留样本上最小化一步向前预测误差的平方和，使用普通最小二乘法 (OLS) 估计的。设保留的样本表示为 $\\{z_t\\}_{t=1}^T$，其中 $z_t$ 对应于模拟值 $y_{B+t}$。优化问题是找到能解出以下方程的 $\\hat{a}$：\n$$ \\hat{a} = \\arg\\min_{a \\in \\mathbb{R}} \\sum_{t=1}^{T-1} (z_{t+1} - a\\,z_t)^2 $$\n这是一个标准的回归问题，其 OLS 估计量 $\\hat{a}$ 具有众所周知的闭式解：\n$$ \\hat{a} = \\frac{\\sum_{t=1}^{T-1} z_t z_{t+1}}{\\sum_{t=1}^{T-1} z_t^2} $$\n这个估计出的系数 $\\hat{a}$，代表了仅基于最近一次观测值的最佳线性预测系数。\n\n**步骤 3：脉冲响应函数 (IRF) 计算**\nIRF 描述了系统在响应其某个创新项的单个、暂时性冲击后的演变过程。\n- **真实 IRF：** 对于真实的 AR($2$) 过程， $y_{t+h}$ 对一个单位冲击 $\\epsilon_t=1$ 的响应由 Wold 移动平均表示 $y_t = \\sum_{j=0}^{\\infty} \\psi_j \\epsilon_{t-j}$ 中的系数 $\\psi_h$ 给出。这些系数根据问题的定义递归计算：\n  - $\\psi_0 = 1$\n  - $\\psi_1 = 0.9$\n  - $\\psi_h = 0.9\\,\\psi_{h-1} - 0.8\\,\\psi_{h-2}$ for all integers $h \\ge 2$.\n特征多项式的复数根意味着真实的 IRF, $\\{\\psi_h\\}_{h>0}$，将是一个阻尼正弦波，其符号会发生振荡。对于每个指定的时期 $H$，计算响应序列 $\\{\\psi_h\\}_{h=1}^H$。\n\n- **估计的 IRF：** 对于估计的 AR($1$) 模型，在时期 $h$ 的脉冲响应由 $\\theta_h$ 给出：\n  - $\\theta_h = \\hat{a}^h$\n该 IRF 是一个简单的几何序列。如果 $|\\hat{a}| < 1$ 且 $\\hat{a}>0$，其行为是向零单调衰减；如果 $|\\hat{a}|<1$ 且 $\\hat{a}<0$，则是振荡衰减。使用步骤 2 中估计的系数 $\\hat{a}$ 来计算序列 $\\{\\theta_h\\}_{h=1}^H$。\n\n**步骤 4：误导性动态指标**\n核心任务是量化简化的 AR(1) 模型在多大程度上对系统的动态响应提供了定性上不正确的预测。脉冲响应的符号是一个基本的定性特征，它表明在一次正向冲击之后，变量预期会高于还是低于其长期均值。真实 IRF 和估计 IRF 之间的符号差异揭示了简化模型未能捕捉到真实动态。该指标定义为时期 $h \\in \\{1, 2, \\dots, H\\}$ 中符号不同的比例：\n$$ \\text{Metric} = \\frac{m(H)}{H} = \\frac{1}{H} \\sum_{h=1}^{H} \\mathbf{1}_{\\{\\operatorname{sgn}(\\theta_h) \\neq \\operatorname{sgn}(\\psi_h)\\}} $$\n其中 $\\mathbf{1}_{\\{\\cdot\\}}$ 表示指示函数，当其参数为真时取值为 1，否则为 0；$\\operatorname{sgn}(\\cdot)$ 是标准符号函数。为每个测试用例计算此指标。\n\n算法实现将精确遵循这四个步骤。我们开发了一个 Python 脚本来为整个测试用例套件自动化整个流程，从数据模拟到最终指标计算，并确保严格遵守输出格式。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of comparing AR(2) dynamics with an AR(1) approximation.\n    \"\"\"\n\n    # --- Problem Parameters ---\n    test_cases = [\n        (5000, 12),  # T, H for case 1\n        (100, 12),   # T, H for case 2\n        (2000, 1),   # T, H for case 3\n        (2000, 30),  # T, H for case 4\n    ]\n    B = 500  # Burn-in length\n    ar2_coeffs = (0.9, -0.8) # Coefficients for y_{t-1} and y_{t-2}\n    \n    # Store results for each test case\n    results = []\n\n    for T, H in test_cases:\n        # --- 1. Simulation ---\n        # Simulate T+B observations from the AR(2) process.\n        total_len = T + B\n        eps = np.random.normal(loc=0.0, scale=1.0, size=total_len)\n        y = np.zeros(total_len)\n\n        # Initial conditions y_{-1}=0, y_0=0\n        # t=1 (index 0): y[0] = 0.9*y_0 - 0.8*y_{-1} + eps[0] = eps[0]\n        if total_len > 0:\n            y[0] = eps[0]\n        \n        # t=2 (index 1): y[1] = 0.9*y[0] - 0.8*y_0 + eps[1] = 0.9*y[0] + eps[1]\n        if total_len > 1:\n            y[1] = ar2_coeffs[0] * y[0] + eps[1]\n        \n        # for t=3, .. N (index 2 to N-1)\n        for t in range(2, total_len):\n            y[t] = ar2_coeffs[0] * y[t-1] + ar2_coeffs[1] * y[t-2] + eps[t]\n\n        # Discard burn-in period to get the retained sample\n        y_retained = y[B:]\n\n        # --- 2. Estimation ---\n        # Estimate the AR(1) coefficient 'a' using OLS.\n        # The model is y_{t+1} = a*y_t + u_t\n        # dependent variable: y_retained[1:]\n        # independent variable: y_retained[:-1]\n        y_reg_dep = y_retained[1:]\n        y_reg_indep = y_retained[:-1]\n        \n        # OLS formula: a_hat = (X'Y) / (X'X)\n        numerator = np.dot(y_reg_indep, y_reg_dep)\n        denominator = np.dot(y_reg_indep, y_reg_indep)\n\n        a_hat = 0.0 if denominator == 0 else numerator / denominator\n\n        # --- 3. Impulse Responses ---\n        # True AR(2) IRF\n        psi = np.zeros(H + 1)\n        if H >= 0:\n            psi[0] = 1.0\n        if H >= 1:\n            psi[1] = ar2_coeffs[0]\n        for h in range(2, H + 1):\n            psi[h] = ar2_coeffs[0] * psi[h-1] + ar2_coeffs[1] * psi[h-2]\n        \n        # We need IRF for horizons h=1, ..., H\n        psi_true = psi[1:]\n\n        # Estimated AR(1) IRF\n        # theta_h = a_hat^h for h=1, ..., H\n        horizons = np.arange(1, H + 1)\n        theta_est = np.power(a_hat, horizons)\n\n        # --- 4. Misleading-Dynamics Metric ---\n        # Count horizons where signs of IRFs differ\n        m_H = 0\n        for h in range(H):\n            if np.sign(theta_est[h]) != np.sign(psi_true[h]):\n                m_H += 1\n        \n        metric = m_H / H if H > 0 else 0.0\n        results.append(metric)\n\n    # --- 5. Output Specification ---\n    # Print results in the required format\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"}, {"introduction": "在经济学中，我们不仅关心预测，更关心变量之间的关系，例如“$X$ 的变化是否能预测 $Y$ 的变化？” 格兰杰因果检验 (Granger causality test) 是回答此类问题的标准工具。然而，统计上的显著性并不等同于真实的因果关系，一个常见的陷阱是“遗漏变量偏误” (omitted variable bias)。本练习将引导你模拟一个系统，其中两个观测变量 $X_t$ 和 $Y_t$ 本无直接的格兰杰因果联系，但它们都受到一个共同的、未被观测的潜在变量 $Z_t$ 的驱动。通过在一个忽略了 $Z_t$ 的双变量 VAR 模型中进行检验，你将揭示这种遗漏变量如何凭空制造出虚假的因果关系，这对于培养严谨的计量经济学思维至关重要 [@problem_id:2447550]。", "id": "2447550", "problem": "给定一个由潜在变量驱动的三元线性数据生成过程，其旨在说明向量自回归 (VAR) 估计中的遗漏变量偏误。向量自回归 (VAR) 是一个线性随机差分方程系统，用于描述多个时间序列的联合动态。考虑由以下方程生成的三个过程 $\\{Z_t\\}$、$\\{X_t\\}$ 和 $\\{Y_t\\}$：\n$$Z_t = \\rho_Z Z_{t-1} + u_t,$$\n$$X_t = \\phi_X X_{t-1} + b_X Z_{t-1} + e_t,$$\n$$Y_t = \\phi_Y Y_{t-1} + b_Y Z_{t-1} + v_t,$$\n其中，$u_t$、$e_t$ 和 $v_t$ 是相互独立、序列独立、均值为零的高斯冲击，其方差分别为 $\\sigma_u^2$、$\\sigma_e^2$ 和 $\\sigma_v^2$。在全信息三元系统中，$X_t$ 不构成对 $Y_t$ 的格兰杰因果，因为在 $Y_t$ 的运动规律中没有直接引入 $X_t$ 的滞后项。格兰杰因果的定义如下：如果 $X_t$ 的过去值在 $Y_t$ 和所有其他相关过程的过去值所包含的信息之外，能够改进对 $Y_t$ 提前一期的均方预测，则称过程 $X_t$ 对过程 $Y_t$ 构成格兰杰因果。\n\n然而，在实践中，潜在过程 $Z_t$ 被遗漏，研究者仅对 $(X_t, Y_t)$ 估计一个二元 VAR 模型。您的任务是证明这种遗漏如何在估计的二元系统中引致伪格兰杰因果关系。\n\n基本原理：\n- 使用基于线性可预测性的格兰杰因果定义，以及作为在高斯-马尔可夫条件下最佳线性无偏估计量的普通最小二乘法 (OLS) 估计。普通最小二乘法 (OLS) 依赖于求解正规方程以最小化残差平方和。\n- 对于高斯扰动下的嵌套线性模型，从残差平方和推导出的经典F检验为基于费雪-斯内德克分布 (F) 的线性排除性约束在有限样本容量下提供了有效的检验。\n\n说明：\n- 对于下方的每个测试用例，使用指定的参数从三元系统模拟数据。使用 $B = 300$ 的预烧期 (burn-in) 观测值，这些值在分析前被丢弃，以减轻初始化效应。将 $Z_0$、$X_0$ 和 $Y_0$ 初始化为 $0$。\n- 对于预烧期后的观测二元数据 $(X_t, Y_t)$，通过 OLS 逐方程地估计一个包含截距项的 $p = 1$ 阶二元 VAR 模型。\n- 在 $Y$ 方程中，检验在观测的二元系统中“$X$ 不对 $Y$ 构成格兰杰因果”的原假设。该原假设施加了 $Y$ 方程中 $X$ 的所有 $p$ 个滞后项的系数都等于 $0$ 的约束。通过比较非受限 $Y$ 方程（包含 $X$ 的滞后项）与受限 $Y$ 方程（不含 $X$ 的滞后项），构建标准的嵌套模型 F 统计量。使用费雪-斯内德克分布的累积分布函数计算 $p$ 值，其分子和分母自由度由排除性约束的数量和非受限残差自由度所决定。当且仅当 $p$ 值严格小于显著性水平 $\\alpha = 0.05$ 时，拒绝原假设。\n- 对于每个测试用例，输出一个布尔值，指示在观测的二元 VAR 中，“$X$ 不对 $Y$ 构成格兰杰因果”的原假设是否被拒绝。\n\n测试套件：\n- 案例 1 (高潜在持续性；检测伪关系的“理想路径”)：\n  - $T = 1000$, $p = 1$, $\\alpha = 0.05$, $\\rho_Z = 0.95$, $\\phi_X = 0.2$, $\\phi_Y = 0.2$, $b_X = 1.5$, $b_Y = 1.5$, $\\sigma_u = 0.5$, $\\sigma_e = 0.5$, $\\sigma_v = 0.5$, seed $= 123456$。\n- 案例 2 (潜在白噪声；从 $X_{t-1}$ 到 $Y_t$ 的伪可预测性最小的边界情况)：\n  - $T = 600$, $p = 1$, $\\alpha = 0.05$, $\\rho_Z = 0.0$, $\\phi_X = 0.4$, $\\phi_Y = 0.6$, $b_X = 1.0$, $b_Y = 1.0$, $\\sigma_u = 1.0$, $\\sigma_e = 1.0$, $\\sigma_v = 1.0$, seed $= 20231102$。\n- 案例 3 (小样本；低统计功效和抽样变异性的边缘情况)：\n  - $T = 120$, $p = 1$, $\\alpha = 0.05$, $\\rho_Z = 0.9$, $\\phi_X = 0.6$, $\\phi_Y = 0.6$, $b_X = 1.2$, $b_Y = 0.8$, $\\sigma_u = 0.8$, $\\sigma_e = 0.8$, $\\sigma_v = 0.8$, seed $= 7$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表内容为按上述用例顺序列出的结果。每个条目都是一个布尔值，对应于“$X$ 不对 $Y$ 构成格兰杰因果”的原假设是否被拒绝。例如，包含三个用例的输出应如下所示：`[{\\rm True},{\\rm False},{\\rm True}]`。", "solution": "该问题要求研究向量自回归 (VAR) 模型中因遗漏变量偏误而产生的伪格兰杰因果现象。我们获得了一个三元线性随机过程，该过程由两个观测变量 $X_t$ 和 $Y_t$ 以及一个未观测到的（潜在的）共同驱动因素 $Z_t$ 组成。任务是在指定的参数集下模拟该系统，并在一个遗漏了 $Z_t$ 的错误设定的二元 VAR 模型中，检验从 $X_t$ 到 $Y_t$ 的格兰杰因果关系。\n\n数据生成过程 (DGP) 由以下方程组定义：\n$$Z_t = \\rho_Z Z_{t-1} + u_t$$\n$$X_t = \\phi_X X_{t-1} + b_X Z_{t-1} + e_t$$\n$$Y_t = \\phi_Y Y_{t-1} + b_Y Z_{t-1} + v_t$$\n其中，$u_t$、$e_t$ 和 $v_t$ 是相互独立、序列不相关、均值为 $0$ 且方差分别为 $\\sigma_u^2$、$\\sigma_e^2$ 和 $\\sigma_v^2$ 的高斯白噪声过程。\n\n在这个真实的结构模型中，$Y_t$ 的演变仅取决于其自身的滞后项 $Y_{t-1}$ 和潜在过程的滞后项 $Z_{t-1}$。在 $Y_t$ 的方程中，没有包含 $X_t$ 滞后项的项。因此，在全三元系统的背景下，$X_t$ 不对 $Y_t$ 构成格兰杰因果。\n\n然而，计量经济学家观测不到 $Z_t$，于是转而对观测数据 $(X_t, Y_t)$ 估计一个 $p=1$ 阶的二元 VAR 模型。在这个错误设定的模型中，$Y_t$ 的方程为：\n$$Y_t = c_Y + \\beta_{Y,1} Y_{t-1} + \\beta_{X,1} X_{t-1} + \\epsilon_t$$\n其中 $\\epsilon_t$ 是新的误差项。从 $X_t$ 到 $Y_t$ 的格兰杰因果检验就是对原假设 $H_0: \\beta_{X,1} = 0$ 的检验。\n\n如果我们拒绝此原假设，伪格兰杰因果关系就会出现，其原因并非 $X_{t-1}$ 对 $Y_t$ 具有真正的预测能力（在以 $Y_{t-1}$ 为条件后），而是因为模型的设定有误。这是一个典型的遗漏变量偏误案例。如果包含的回归量 $X_{t-1}$ 与被遗漏的变量 $Z_{t-1}$ 相关，那么 $\\beta_{X,1}$ 的普通最小二乘法 (OLS) 估计量（记为 $\\hat{\\beta}_{X,1}$）就会产生偏误，因为 $Z_{t-1}$ 是错误设定的回归中真实误差项的一部分。\n\n$Y_t$ 的真实模型可以表示为 $Y_t = \\phi_Y Y_{t-1} + (b_Y Z_{t-1} + v_t)$。当我们估计二元模型时，项 $b_Y Z_{t-1}$ 被遗漏并成为误差项 $\\epsilon_t$ 的一部分。要使 OLS 估计量 $\\hat{\\beta}_{X,1}$ 产生偏误，必须满足两个条件：\n1. 遗漏变量 $Z_{t-1}$ 必须是 $Y_t$ 的一个决定因素。在我们的 DGP 中，如果 $b_Y \\neq 0$，此条件成立。\n2. 遗漏变量 $Z_{t-1}$ 必须与包含的回归量 $X_{t-1}$ 相关，即 $\\mathrm{Cov}(X_{t-1}, Z_{t-1}) \\neq 0$。\n\n我们来分析这个协方差，假设过程是平稳的。根据 DGP，我们有 $X_{t-1} = \\phi_X X_{t-2} + b_X Z_{t-2} + e_{t-1}$ 和 $Z_{t-1} = \\rho_Z Z_{t-2} + u_{t-1}$。计算 $X_{t-1}$ 和 $Z_{t-1}$ 的协方差（并假设均值为零），我们发现：\n$$\\mathrm{E}[X_{t-1} Z_{t-1}] = \\mathrm{E}[(\\phi_X X_{t-2} + b_X Z_{t-2} + e_{t-1})(\\rho_Z Z_{t-2} + u_{t-1})]$$\n由于冲击的独立性，该式简化为：\n$$\\mathrm{E}[X_{t-1} Z_{t-1}] = \\phi_X \\rho_Z \\mathrm{E}[X_{t-2}Z_{t-2}] + b_X \\rho_Z \\mathrm{E}[Z_{t-2}^2]$$\n设 $\\Gamma_{XZ} = \\mathrm{E}[X_t Z_t]$ 和 $\\gamma_Z(0) = \\mathrm{E}[Z_t^2]$。在稳态下，我们有 $\\Gamma_{XZ} = \\phi_X \\rho_Z \\Gamma_{XZ} + b_X \\rho_Z \\gamma_Z(0)$，这意味着 $\\Gamma_{XZ} = \\frac{b_X \\rho_Z}{1 - \\phi_X \\rho_Z} \\gamma_Z(0)$。\n由于 $\\gamma_Z(0) = \\sigma_u^2 / (1 - \\rho_Z^2) > 0$，协方差 $\\mathrm{Cov}(X_{t-1}, Z_{t-1})$ 非零当且仅当 $b_X \\neq 0$ 且 $\\rho_Z \\neq 0$。\n\n因此，当 $b_X \\neq 0$、$b_Y \\neq 0$ 且 $\\rho_Z \\neq 0$ 时，预计会产生从 $X_t$ 到 $Y_t$ 的伪格兰杰因果关系。回归量 $X_{t-1}$ 充当了遗漏变量 $Z_{t-1}$ 的代理变量，其系数 $\\beta_{X,1}$ 会虚假地捕捉到 $Z_{t-1}$ 对 $Y_t$ 的影响。如果 $\\rho_Z=0$，$Z_t$ 是白噪声，那么 $Z_{t-1}$ 与 $X_{t-1}$ 不相关，从而打破了产生偏误的机制。\n\n具体步骤是为每个案例执行一次假设检验。我们生成 $T+B$ 个数据点，并丢弃前 $B=300$ 个作为预烧期。在剩余的 $T$ 个观测值上，我们使用 OLS 估计二元 VAR(1) 的 $Y$ 方程。这需要 $T-1$ 个有效观测值。非受限模型是 $Y_t = c + \\beta_1 Y_{t-1} + \\beta_2 X_{t-1} + \\epsilon_t$，而在 $H_0: \\beta_2=0$ 下的受限模型是 $Y_t = c' + \\beta'_1 Y_{t-1} + \\epsilon'_t$。\n\n我们使用来自两个回归的残差平方和 ($RSS$) 计算 F 统计量：\n$$F = \\frac{(RSS_R - RSS_U) / q}{RSS_U / (N_{reg} - k)}$$\n此处，$RSS_R$ 和 $RSS_U$ 分别是受限模型和非受限模型的残差平方和。回归观测的数量是 $N_{reg} = T-1$。约束的数量是 $q=1$。非受限模型中的参数数量是 $k=3$（截距项、$Y$ 的一个滞后项、$X$ 的一个滞后项）。F分布的自由度，分子为 $q=1$，分母为 $N_{reg} - k = (T-1) - 3 = T-4$。\n\np值是根据 $F_{1, T-4}$ 分布的累积分布函数 (CDF) 计算得出的。如果在显著性水平 $\\alpha=0.05$ 下，p值小于 $0.05$，则拒绝原假设。\n\n- 案例 1：潜在变量（$\\rho_Z = 0.95$）具有高持续性，且样本量较大（$T=1000$）。产生伪因果关系的所有条件都得到了强有力的满足。预计原假设将被拒绝。\n- 案例 2：潜在变量是白噪声（$\\rho_Z = 0.0$）。遗漏变量偏误的机制不存在。除非发生 I 型错误，否则检验不应拒绝原假设。\n- 案例 3：潜在变量具有高持续性（$\\rho_Z = 0.9$），但样本量较小（$T=120$）。偏误是存在的，但检验的统计功效可能不足以检测到它。结果将展示偏误大小与样本量之间的相互作用。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import f as f_dist\n\ndef solve():\n    \"\"\"\n    Main function to run test cases for spurious Granger causality.\n    \"\"\"\n    test_cases = [\n        # Case 1 (high latent persistence)\n        {\n            \"T\": 1000, \"p\": 1, \"alpha\": 0.05, \"rho_Z\": 0.95, \"phi_X\": 0.2, \"phi_Y\": 0.2,\n            \"b_X\": 1.5, \"b_Y\": 1.5, \"sigma_u\": 0.5, \"sigma_e\": 0.5, \"sigma_v\": 0.5,\n            \"seed\": 123456\n        },\n        # Case 2 (latent white noise)\n        {\n            \"T\": 600, \"p\": 1, \"alpha\": 0.05, \"rho_Z\": 0.0, \"phi_X\": 0.4, \"phi_Y\": 0.6,\n            \"b_X\": 1.0, \"b_Y\": 1.0, \"sigma_u\": 1.0, \"sigma_e\": 1.0, \"sigma_v\": 1.0,\n            \"seed\": 20231102\n        },\n        # Case 3 (small sample)\n        {\n            \"T\": 120, \"p\": 1, \"alpha\": 0.05, \"rho_Z\": 0.9, \"phi_X\": 0.6, \"phi_Y\": 0.6,\n            \"b_X\": 1.2, \"b_Y\": 0.8, \"sigma_u\": 0.8, \"sigma_e\": 0.8, \"sigma_v\": 0.8,\n            \"seed\": 7\n        }\n    ]\n\n    results = []\n    for case_params in test_cases:\n        result = run_granger_test(case_params)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_granger_test(params):\n    \"\"\"\n    Simulates data and performs the Granger causality F-test for a single case.\n\n    Args:\n        params (dict): A dictionary of parameters for the simulation and test.\n\n    Returns:\n        bool: True if the null hypothesis is rejected, False otherwise.\n    \"\"\"\n    # Unpack parameters\n    T = params[\"T\"]\n    p = params[\"p\"]\n    alpha = params[\"alpha\"]\n    rho_Z = params[\"rho_Z\"]\n    phi_X = params[\"phi_X\"]\n    phi_Y = params[\"phi_Y\"]\n    b_X = params[\"b_X\"]\n    b_Y = params[\"b_Y\"]\n    sigma_u = params[\"sigma_u\"]\n    sigma_e = params[\"sigma_e\"]\n    sigma_v = params[\"sigma_v\"]\n    seed = params[\"seed\"]\n    \n    B = 300  # Burn-in period\n    T_total = T + B\n\n    # Set seed for reproducibility\n    np.random.seed(seed)\n\n    # Generate shocks\n    u = np.random.normal(0, sigma_u, T_total)\n    e = np.random.normal(0, sigma_e, T_total)\n    v = np.random.normal(0, sigma_v, T_total)\n\n    # Initialize time series arrays\n    Z = np.zeros(T_total)\n    X = np.zeros(T_total)\n    Y = np.zeros(T_total)\n\n    # Simulate the trivariate system\n    for t in range(1, T_total):\n        Z[t] = rho_Z * Z[t-1] + u[t]\n        X[t] = phi_X * X[t-1] + b_X * Z[t-1] + e[t]\n        Y[t] = phi_Y * Y[t-1] + b_Y * Z[t-1] + v[t]\n\n    # Discard burn-in period\n    X_sample = X[B:]\n    Y_sample = Y[B:]\n\n    # Prepare data for regression (VAR order p=1)\n    # Effective sample size for regression is T-p\n    y_vec = Y_sample[p:]\n    N_reg = len(y_vec)\n\n    # Regressors for the unrestricted model: intercept, Y_lag1, X_lag1\n    X_unrestricted = np.vstack([\n        np.ones(N_reg),\n        Y_sample[p-1:-1],\n        X_sample[p-1:-1]\n    ]).T\n\n    # Regressors for the restricted model: intercept, Y_lag1\n    X_restricted = np.vstack([\n        np.ones(N_reg),\n        Y_sample[p-1:-1]\n    ]).T\n\n    # OLS estimation via np.linalg.lstsq\n    # lstsq returns: coefficients, residuals (sum of squares), rank, singular values\n    # We only need the residual sum of squares (RSS)\n    _, rss_unrestricted, _, _ = np.linalg.lstsq(X_unrestricted, y_vec, rcond=None)\n    _, rss_restricted, _, _ = np.linalg.lstsq(X_restricted, y_vec, rcond=None)\n    \n    # lstsq returns RSS as a one-element array, so we extract the float\n    rss_u = rss_unrestricted[0]\n    rss_r = rss_restricted[0]\n\n    # Compute the F-statistic\n    q = X_unrestricted.shape[1] - X_restricted.shape[1]\n    k_unrestricted = X_unrestricted.shape[1]\n    df_num = q\n    df_den = N_reg - k_unrestricted\n    \n    # Check for df_den > 0 to avoid division by zero\n    if df_den <= 0:\n        return False # Cannot perform test\n\n    F_statistic = ((rss_r - rss_u) / df_num) / (rss_u / df_den)\n\n    # Compute the p-value using the survival function (1 - CDF)\n    p_value = f_dist.sf(F_statistic, dfn=df_num, dfd=df_den)\n\n    # Reject null if p-value is less than the significance level\n    return p_value < alpha\n\n# Run the simulation and print the results\nsolve()\n```"}, {"introduction": "预测是 VAR 模型在宏观经济和金融领域最广泛的应用之一。在实践中，我们常常面临一个选择：是使用一个包含更多滞后项、更复杂的模型，还是一个更简洁、更节约参数的模型？这背后是“偏误-方差权衡” (bias-variance tradeoff) 的经典问题，而检验模型好坏的最终标准是其在真实世界中的预测能力。这个动手实践将让你扮演应用计量经济学家的角色，通过一场“预测竞赛”，在一个包含不同真实数据生成过程的模拟环境中，构建并评估不同阶数的 VAR 模型（VAR(1) 和 VAR(4)）以及一个简单的随机游走基准模型的样本外 (out-of-sample) 预测表现。这对于掌握实用的时间序列分析技能是一次绝佳的锻炼 [@problem_id:2447495]。", "id": "2447495", "problem": "您的任务是构建一个完全可复现的计算实验，以比较三种多元汇率模型的样本外单步预测性能：一阶向量自回归（VAR）模型、四阶向量自回归（VAR）模型以及水平随机游走模型。该实验必须以一个完整的程序实现。\n\n请从以下基本定义开始。一个 $k$ 维的 $p$ 阶向量自回归（VAR）模型定义为\n$$\n\\mathbf{y}_t = \\mathbf{c} + \\sum_{i=1}^{p} \\mathbf{A}_i \\mathbf{y}_{t-i} + \\mathbf{u}_t,\n$$\n其中 $\\mathbf{y}_t \\in \\mathbb{R}^k$ 是变量向量，$\\mathbf{c} \\in \\mathbb{R}^k$ 是一个截距项，$\\mathbf{A}_i \\in \\mathbb{R}^{k \\times k}$ 是自回归系数矩阵，$\\mathbf{u}_t \\sim \\mathcal{N}(\\mathbf{0}, \\boldsymbol{\\Sigma})$ 是一个零均值高斯新息，其正定协方差矩阵为 $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{k \\times k}$。VAR模型中参数的普通最小二乘（OLS）估计量是通过最小化所有方程的残差平方和得到的，这等价于求解通过堆叠回归变量和响应变量所隐含的多元最小二乘问题。\n\n请按如下方式实施和评估模型。\n\n1. 需实施的估计原则。对于每个阶数 $p \\in \\{1,4\\}$ 的模型，仅使用训练样本通过普通最小二乘法（OLS）估计参数。通过堆叠截距项和滞后值 $\\{\\mathbf{y}_{t-1}, \\ldots, \\mathbf{y}_{t-p}\\}$ 来构建回归变量矩阵 $\\mathbf{X}$，并通过从训练窗口末尾向后推 $p$ 个滞后期来堆叠 $\\mathbf{y}_t$ 以构建响应矩阵 $\\mathbf{Y}$。求解最小二乘问题以获得系数估计值。使用这些固定的估计值在测试样本上生成单步预测，预测时始终以实现序列中的实际滞后值为条件（在测试期间不重新估计或更新参数）。\n\n2. 随机游走基准。水平随机游走预测定义为 $\\widehat{\\mathbf{y}}_{t+1|t} = \\mathbf{y}_t$，适用于测试样本中的每个预测起点。\n\n3. 预测损失度量。对于每个模型，计算在测试窗口中对所有变量和所有样本外预测起点进行汇总的均方根预测误差（RMSFE）：\n$$\n\\mathrm{RMSFE} = \\sqrt{\\frac{1}{H k} \\sum_{h=1}^{H} \\left\\|\\mathbf{y}_{T_{\\text{train}}+h} - \\widehat{\\mathbf{y}}_{T_{\\text{train}}+h|T_{\\text{train}}+h-1}\\right\\|_2^2},\n$$\n其中 $k$ 是 $\\mathbf{y}_t$ 的维度，$H$ 是样本外单步预测的数量，$\\|\\cdot\\|_2$ 是欧几里得范数。\n\n4. 数据生成。使用以下的数据生成过程（DGP），指定的参数，训练长度 $T_{\\text{train}}$，测试长度 $T_{\\text{test}}$，以及给定协方差矩阵的高斯新息，模拟三个独立的二元（$k=2$）人工对数汇率数据集。对于每个数据集，模拟总长度为 $T_{\\text{burn}} + T_{\\text{train}} + T_{\\text{test}}$ 的观测值，并丢弃前 $T_{\\text{burn}}$ 个作为“烧入期”(burn-in)。为了保证可复现性，请严格使用给定的种子。矩阵和向量的所有条目都是实数。\n\n- 测试案例 1 (真实模型为 VAR(1)，平稳):\n  - 维度: $k=2$。\n  - 种子: $314159$。\n  - 参数: $\\mathbf{c} = \\begin{bmatrix}0 \\\\ 0\\end{bmatrix}$,\n    $\\mathbf{A}_1 = \\begin{bmatrix}0.65 & 0.20 \\\\ -0.10 & 0.55\\end{bmatrix}$。\n  - 新息协方差: $\\boldsymbol{\\Sigma} = \\begin{bmatrix}0.010 & 0.003 \\\\ 0.003 & 0.015\\end{bmatrix}$。\n  - 样本大小: $T_{\\text{burn}} = 100$, $T_{\\text{train}} = 300$, $T_{\\text{test}} = 100$。\n\n- 测试案例 2 (真实模型为 VAR(4)，平稳):\n  - 维度: $k=2$。\n  - 种子: $271828$。\n  - 参数: $\\mathbf{c} = \\begin{bmatrix}0 \\\\ 0\\end{bmatrix}$,\n    $\\mathbf{A}_1 = \\begin{bmatrix}0.55 & 0.00 \\\\ 0.05 & 0.45\\end{bmatrix}$,\n    $\\mathbf{A}_2 = \\begin{bmatrix}-0.25 & 0.06 \\\\ 0.00 & -0.15\\end{bmatrix}$,\n    $\\mathbf{A}_3 = \\begin{bmatrix}0.12 & 0.00 \\\\ 0.02 & 0.10\\end{bmatrix}$,\n    $\\mathbf{A}_4 = \\begin{bmatrix}-0.06 & 0.00 \\\\ 0.00 & -0.04\\end{bmatrix}$。\n  - 新息协方差: $\\boldsymbol{\\Sigma} = \\begin{bmatrix}0.020 & -0.004 \\\\ -0.004 & 0.012\\end{bmatrix}$。\n  - 样本大小: $T_{\\text{burn}} = 100$, $T_{\\text{train}} = 300$, $T_{\\text{test}} = 100$。\n\n- 测试案例 3 (真实模型为水平随机游走，非平稳):\n  - 维度: $k=2$。\n  - 种子: $161803$。\n  - 参数: $\\mathbf{c} = \\begin{bmatrix}0 \\\\ 0\\end{bmatrix}$,\n    $\\mathbf{A}_1 = \\mathbf{I}_2$ ($2 \\times 2$ 单位矩阵)，且对于所有 $i \\ge 2$, $\\mathbf{A}_i = \\mathbf{0}$。\n  - 新息协方差: $\\boldsymbol{\\Sigma} = \\begin{bmatrix}0.005 & 0.0015 \\\\ 0.0015 & 0.004\\end{bmatrix}$。\n  - 样本大小: $T_{\\text{burn}} = 100$, $T_{\\text{train}} = 300$, $T_{\\text{test}} = 100$。\n\n5. 程序要求。您的程序必须：\n  - 使用给定的种子精确地模拟每个数据集。\n  - 仅在训练样本上使用普通最小二乘法 (OLS) 估计一个带截距项的 VAR(1) 和一个 VAR(4) 模型。\n  - 使用固定的估计参数和实际的滞后值，在测试样本上生成单步预测。\n  - 根据上述定义，为三个模型（VAR(1)、VAR(4)、随机游走）中的每一个计算均方根预测误差 (RMSFE)。\n  - 对于每个测试案例，根据 RMSFE 确定最佳模型的索引，使用以下索引约定：$0$ 代表 VAR(1)，$1$ 代表 VAR(4)，$2$ 代表随机游走。\n\n6. 最终输出格式。您的程序应生成单行输出，包含一个由三个元素（每个测试案例一个）组成的逗号分隔列表，并用方括号括起来。每个元素本身必须是一个包含四个值的列表，顺序为 $\\left[\\text{best\\_index}, \\mathrm{RMSFE}_{\\text{VAR}(1)}, \\mathrm{RMSFE}_{\\text{VAR}(4)}, \\mathrm{RMSFE}_{\\text{RW}}\\right]$。将所有 RMSFE 打印为保留小数点后六位的小数，并将最佳索引打印为整数。例如，整体输出应类似于\n$[\\,[b_1,r_{1,1},r_{4,1},r_{\\mathrm{rw},1}]\\,,\\,[b_2,r_{1,2},r_{4,2},r_{\\mathrm{rw},2}]\\,,\\,[b_3,r_{1,3},r_{4,3},r_{\\mathrm{rw},3}]\\,]$,\n其中 $b_i \\in \\{0,1,2\\}$ 且 $r_{\\cdot,i}$ 是四舍五入到六位小数的浮点数。\n\n此问题不涉及任何物理单位或角度。所有数值答案必须严格按照上述格式单行打印。", "solution": "该问题陈述是有效的。它提出了一个在时间序列计量经济学领域中定义明确且自成体系的计算实验。所有参数、模型和评估标准都以足够的精度进行了规定，以确保能够得到一个唯一且可复现的解。其基本原理是计算经济学和金融学领域的标准方法。该任务要求实施一项模拟研究，以比较向量自回归（VAR）模型与随机游走基准的预测性能。\n\n对于每个测试案例，该方法分四个不同阶段进行：数据生成、模型估计、样本外预测和性能评估。\n\n1. 数据生成\n对于每个测试案例，从一个 $p_{\\text{true}}$\n阶向量自回归模型中模拟一个总长度为 $T_{\\text{total}} = T_{\\text{burn}} + T_{\\text{train}} + T_{\\text{test}}$ 的二元时间序列 $\\mathbf{y}_t \\in \\mathbb{R}^2$：\n$$\n\\mathbf{y}_t = \\mathbf{c} + \\sum_{i=1}^{p_{\\text{true}}} \\mathbf{A}_i \\mathbf{y}_{t-i} + \\mathbf{u}_t\n$$\n在这里，$\\mathbf{c}$ 是截距向量，$\\mathbf{A}_i$ 是 $k \\times k$ 的系数矩阵，$\\mathbf{u}_t$ 是从多元正态分布 $\\mathcal{N}(\\mathbf{0}, \\boldsymbol{\\Sigma})$ 中抽取的创新向量。该过程初始化为，当 $t < p_{\\text{true}}$ 时，$\\mathbf{y}_t = \\mathbf{0}$。为确保可复现性，随机数生成器使用了特定的种子。前 $T_{\\text{burn}} = 100$ 个观测值被丢弃，以减轻初始条件的影响。剩余数据被分成长度为 $T_{\\text{train}} = 300$ 的训练样本和长度为 $T_{\\text{test}} = 100$ 的测试样本。\n\n2. 模型估计\n使用训练样本估计两个候选模型：一个VAR(1)模型和一个VAR(4)模型。估计通过普通最小二乘法（OLS）进行。对于一个通用的VAR($p$)模型，其中 $p \\in \\{1, 4\\}$，我们将系统表述为多元回归：\n$$\n\\mathbf{Y} = \\mathbf{X} \\mathbf{B}^\\top + \\mathbf{U}\n$$\n响应矩阵 $\\mathbf{Y}$ 是通过堆叠观测向量 $\\mathbf{y}_t^\\top$（其中 $t = p, \\dots, T_{\\text{train}}-1$）构建的。其维度为 $(T_{\\text{train}} - p) \\times k$。回归变量矩阵 $\\mathbf{X}$ 是通过堆叠相应的回归变量向量 $\\mathbf{x}_t^\\top = [1, \\mathbf{y}_{t-1}^\\top, \\ldots, \\mathbf{y}_{t-p}^\\top]$（对于相同的时间索引）构建的。其维度为 $(T_{\\text{train}} - p) \\times (1 + kp)$。矩阵 $\\mathbf{B} = [\\mathbf{c}, \\mathbf{A}_1, \\ldots, \\mathbf{A}_p]$ 包含了所有模型系数，其维度为 $k \\times (1 + kp)$。OLS估计值 $\\widehat{\\mathbf{B}}$ 通过求解正规方程得到，可表示为：\n$$\n\\widehat{\\mathbf{B}}^\\top = (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{Y}\n$$\n在数值上，这通过更稳定的方法（如QR分解）来求解，正如标准线性代数库中所实现的那样，即在系统 $\\mathbf{X} \\widehat{\\mathbf{B}}^\\top = \\mathbf{Y}$ 中求解 $\\widehat{\\mathbf{B}}^\\top$。估计出的系数 $\\widehat{\\mathbf{B}}$ 是固定的，并用于整个预测活动。\n\n3. 预测\n在测试样本的整个期间内生成单步预测，预测起点从 $t = T_{\\text{train}}$ 到 $t = T_{\\text{train}} + T_{\\text{test}} - 1$。\n- 对于VAR($p$)模型，在时间 $t$ 对 $\\mathbf{y}_{t+1}$ 做出的预测是：\n$$\n\\widehat{\\mathbf{y}}_{t+1|t} = \\widehat{\\mathbf{c}} + \\sum_{i=1}^{p} \\widehat{\\mathbf{A}}_i \\mathbf{y}_{t+1-i}\n$$\n该计算使用训练阶段得到的固定估计系数 $\\widehat{\\mathbf{c}}$ 和 $\\widehat{\\mathbf{A}}_i$，以及时间序列中滞后项 $\\mathbf{y}_{t}, \\mathbf{y}_{t-1}, \\dots$ 的*实际*观测值。\n- 对于随机游走（RW）基准模型，预测就是最近的观测值：\n$$\n\\widehat{\\mathbf{y}}_{t+1|t} = \\mathbf{y}_t\n$$\n\n4. 评估\n每个模型（VAR(1)、VAR(4)、RW）的性能都使用均方根预测误差（RMSFE）进行评估。该指标汇总了测试样本中所有 $k$ 个变量和所有 $H = T_{\\text{test}}$ 个预测期内的预测误差：\n$$\n\\mathrm{RMSFE} = \\sqrt{\\frac{1}{H k} \\sum_{h=1}^{H} \\left\\|\\mathbf{y}_{T_{\\text{train}}+h} - \\widehat{\\mathbf{y}}_{T_{\\text{train}}+h|T_{\\text{train}}+h-1}\\right\\|_2^2}\n$$\n其中 $\\|\\cdot\\|_2^2$ 是向量预测误差的平方欧几里得范数。RMSFE最低的模型被认为是该特定数据集的最佳模型。程序为三个模型中的每一个计算该值，并根据其索引确定表现最好的一个：$0$ 代表VAR(1)，$1$ 代表VAR(4)，$2$ 代表随机游走。最终输出是所有三个指定测试案例的这些结果的汇总。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the computational experiment for three test cases.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"k\": 2,\n            \"seed\": 314159,\n            \"c\": np.array([0.0, 0.0]),\n            \"A_matrices\": [\n                np.array([[0.65, 0.20], [-0.10, 0.55]])\n            ],\n            \"Sigma\": np.array([[0.010, 0.003], [0.003, 0.015]]),\n            \"T_burn\": 100, \"T_train\": 300, \"T_test\": 100,\n        },\n        {\n            \"k\": 2,\n            \"seed\": 271828,\n            \"c\": np.array([0.0, 0.0]),\n            \"A_matrices\": [\n                np.array([[0.55, 0.00], [0.05, 0.45]]),\n                np.array([[-0.25, 0.06], [0.00, -0.15]]),\n                np.array([[0.12, 0.00], [0.02, 0.10]]),\n                np.array([[-0.06, 0.00], [0.00, -0.04]]),\n            ],\n            \"Sigma\": np.array([[0.020, -0.004], [-0.004, 0.012]]),\n            \"T_burn\": 100, \"T_train\": 300, \"T_test\": 100,\n        },\n        {\n            \"k\": 2,\n            \"seed\": 161803,\n            \"c\": np.array([0.0, 0.0]),\n            \"A_matrices\": [np.identity(2)],\n            \"Sigma\": np.array([[0.005, 0.0015], [0.0015, 0.004]]),\n            \"T_burn\": 100, \"T_train\": 300, \"T_test\": 100,\n        }\n    ]\n\n    results_all_cases = []\n\n    for case in test_cases:\n        y_full = _simulate_var(\n            k=case[\"k\"],\n            p_true=len(case[\"A_matrices\"]),\n            c=case[\"c\"],\n            A_matrices=case[\"A_matrices\"],\n            Sigma=case[\"Sigma\"],\n            T_total=case[\"T_burn\"] + case[\"T_train\"] + case[\"T_test\"],\n            seed=case[\"seed\"]\n        )\n        \n        y = y_full[case[\"T_burn\"]:]\n        y_train = y[:case[\"T_train\"]]\n\n        # Estimate VAR(1) and VAR(4) models\n        B_hat_1 = _estimate_var(y_train, p=1)\n        B_hat_4 = _estimate_var(y_train, p=4)\n\n        # Evaluate performance\n        rmsfe_var1 = _forecast_and_evaluate(y, case[\"T_train\"], p=1, B_hat=B_hat_1, model_type='VAR')\n        rmsfe_var4 = _forecast_and_evaluate(y, case[\"T_train\"], p=4, B_hat=B_hat_4, model_type='VAR')\n        rmsfe_rw = _forecast_and_evaluate(y, case[\"T_train\"], p=0, B_hat=None, model_type='RW')\n        \n        rmsfes = [rmsfe_var1, rmsfe_var4, rmsfe_rw]\n        best_index = int(np.argmin(rmsfes))\n\n        # Format results for the current case\n        case_result_str = f'[{best_index},' + ','.join([f'{r:.6f}' for r in rmsfes]) + ']'\n        results_all_cases.append(case_result_str)\n\n    # Final print statement\n    print(f\"[{','.join(results_all_cases)}]\")\n\ndef _simulate_var(k, p_true, c, A_matrices, Sigma, T_total, seed):\n    \"\"\"Simulates data from a VAR(p) process.\"\"\"\n    rng = np.random.default_rng(seed)\n    y = np.zeros((T_total, k))\n    u = rng.multivariate_normal(np.zeros(k), Sigma, size=T_total)\n\n    for t in range(p_true, T_total):\n        y_t = c.copy()\n        for i in range(1, p_true + 1):\n            y_t += A_matrices[i-1] @ y[t-i]\n        y[t] = y_t + u[t]\n    return y\n\ndef _estimate_var(y_train, p):\n    \"\"\"Estimates a VAR(p) model with an intercept using OLS.\"\"\"\n    T_train, k = y_train.shape\n    num_obs = T_train - p\n    \n    Y = y_train[p:]\n    X = np.zeros((num_obs, 1 + k * p))\n    \n    for t in range(p, T_train):\n        regressor_row = [1.0]\n        for i in range(1, p + 1):\n            regressor_row.extend(y_train[t - i])\n        X[t - p, :] = regressor_row\n    \n    B_T, _, _, _ = np.linalg.lstsq(X, Y, rcond=None)\n    \n    return B_T.T\n\ndef _forecast_and_evaluate(y, T_train, p, B_hat, model_type):\n    \"\"\"Generates one-step-ahead forecasts and computes RMSFE.\"\"\"\n    T_total, k = y.shape\n    T_test = T_total - T_train\n    \n    squared_errors_sum = 0.0\n\n    for h in range(T_test):\n        # Forecast origin is t = T_train + h - 1\n        t = T_train + h - 1\n        actual_y = y[t + 1]\n\n        if model_type == 'RW':\n            forecast_y = y[t]\n        elif model_type == 'VAR':\n            x_t = [1.0]\n            for i in range(p):\n                x_t.extend(y[t - i])\n            x_t_vec = np.array(x_t)\n            forecast_y = B_hat @ x_t_vec\n        else:\n            raise ValueError(\"Unknown model_type\")\n\n        forecast_error = actual_y - forecast_y\n        squared_errors_sum += np.sum(forecast_error**2)\n    \n    rmsfe = np.sqrt(squared_errors_sum / (T_test * k))\n    return rmsfe\n\nif __name__ == \"__main__\":\n    solve()\n```"}]}