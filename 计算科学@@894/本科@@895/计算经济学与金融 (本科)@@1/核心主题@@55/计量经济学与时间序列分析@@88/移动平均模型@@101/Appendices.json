{"hands_on_practices": [{"introduction": "移动平均模型是捕捉时间序列中短期记忆的有力工具。这个练习将最简单的一阶移动平均（$MA(1)$）模型置于一个引人入胜的背景下——检验篮球中的 “手感火热” 现象，这直观地对应于正自相关性。通过模拟一个 $MA(1)$ 过程并对其自相关性进行假设检验，您将动手实践移动平均模型参数与其所产生的时间序列属性之间的基本联系。[@problem_id:2412526]", "id": "2412526", "problem": "你得到一个单变量离散时间序列，它代表一名篮球运动员每场比赛得分与其长期平均得分的偏差。设时间指数 $t$ 处的偏差表示为 $y_t$。假设 $y_t$ 服从一阶移动平均 (MA) 模型，记为移动平均 (MA)(1)，定义如下：\n$$\ny_t = \\varepsilon_t + \\theta \\varepsilon_{t-1},\n$$\n其中 $\\{\\varepsilon_t\\}$ 是一个独立同分布序列，满足 $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$，且 $\\theta \\in \\mathbb{R}$ 是一个常数。\n\n“手感火热”效应定义为 $y_t$ 中存在正的一阶序列相关性，这对应于中心化序列的正滞后1阶自相关。对于下方的每个测试用例，你必须确定数据是否在单侧显著性水平 $\\alpha$ 下为“手感火热”效应提供了证据。\n\n对于每个测试用例，你必须：\n- 使用指定的参数 $(N,\\theta,\\sigma^2)$ 和随机数种子，模拟一个实现 $\\{y_t\\}_{t=1}^N$。\n- 将 $y_t$ 视为与长期平均值的偏差，并使用中心化序列（减去样本均值）来评估一阶序列相关性。\n- 判断在显著性水平 $\\alpha$ 下是否存在“手感火热”效应的证据。\n\n你必须使用以下测试套件。对于每个用例，在模拟前使用给定的整数随机种子初始化你的随机数生成器：\n- 用例 1: $N=400$, $\\theta=0.8$, $\\sigma^2=9$, $\\alpha=0.05$, 种子 $=1729$。\n- 用例 2: $N=400$, $\\theta=0.0$, $\\sigma^2=9$, $\\alpha=0.05$, 种子 $=31415$。\n- 用例 3: $N=400$, $\\theta=-0.8$, $\\sigma^2=9$, $\\alpha=0.05$, 种子 $=271828$。\n- 用例 4: $N=30$, $\\theta=0.6$, $\\sigma^2=9$, $\\alpha=0.05$, 种子 $=123456$。\n- 用例 5: $N=2$, $\\theta=0.7$, $\\sigma^2=9$, $\\alpha=0.05$, 种子 $=7$。\n\n你的程序应产生一行输出，其中包含一个布尔值列表，按上述顺序列出每个用例的测试决策，如果数据在水平 $\\alpha$ 下为“手感火热”效应提供了证据，则布尔值为 $True$，否则为 $False$。输出必须是单行，格式严格为\n\"[result1,result2,result3,result4,result5]\".", "solution": "对问题陈述进行验证。\n\n**步骤1：提取给定信息**\n- 单变量离散时间序列 $\\{y_t\\}$ 服从一阶移动平均模型 MA(1)：$y_t = \\varepsilon_t + \\theta \\varepsilon_{t-1}$。\n- $\\{\\varepsilon_t\\}$ 是一个独立同分布 (i.i.d.) 序列，满足 $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$。\n- “手感火热”效应被定义为 $y_t$ 中存在正的一阶序列相关性，对应于正的滞后1阶自相关。\n- 任务是在单侧显著性水平 $\\alpha$ 下检验此效应。\n- 过程包括：模拟一个序列 $\\{y_t\\}_{t=1}^N$，通过减去样本均值将其中心化，然后执行假设检验。\n- 测试用例：\n    - 用例 1: $N=400$, $\\theta=0.8$, $\\sigma^2=9$, $\\alpha=0.05$, 种子$=1729$。\n    - 用例 2: $N=400$, $\\theta=0.0$, $\\sigma^2=9$, $\\alpha=0.05$, 种子$=31415$。\n    - 用例 3: $N=400$, $\\theta=-0.8$, $\\sigma^2=9$, $\\alpha=0.05$, 种子$=271828$。\n    - 用例 4: $N=30$, $\\theta=0.6$, $\\sigma^2=9$, $\\alpha=0.05$, 种子$=123456$。\n    - 用例 5: $N=2$, $\\theta=0.7$, $\\sigma^2=9$, $\\alpha=0.05$, 种子$=7$。\n\n**步骤2：使用提取的给定信息进行验证**\n根据科学依据、良构性（well-posedness）和客观性标准对问题进行评估。\n\n- **科学依据**：该问题基于时间序列分析中的标准 MA(1) 模型，这是计量经济学和统计学的核心课题。自相关、假设检验和显著性水平等概念是基本的统计学原理。“手感火热”概念提供了一个主题背景，但被严格定义为一个可检验的统计属性。该问题在科学上是合理的。\n- **良构性**：该问题为可复现的时间序列模拟提供了所有必要的参数（$N, \\theta, \\sigma^2$）和随机种子。它清晰地规定了任务：在给定的显著性水平 $\\alpha$ 下对正自相关进行单侧假设检验。过程是明确的。对于给定的检验自相关的标准统计方法，每个测试用例都存在唯一解。\n- **客观性**：问题使用精确、客观的数学语言陈述。它避免了主观或模糊的术语。\n\n问题未违反任何无效性条件。用例5中 $N=2$ 是一个极端但有效的统计情景。对于大小为 $N=2$ 的样本，样本自相关在代数上是固定的，这是该统计量的一个可证明的属性，而不是问题表述中的缺陷。因此，该问题被认定为有效。\n\n**步骤3：结论与行动**\n问题有效。将提供完整解决方案。\n\n**理论框架与方法论**\n\n给定的时间序列 $\\{y_t\\}$ 由一个一阶移动平均过程生成，记为 MA(1)：\n$$\ny_t = \\varepsilon_t + \\theta \\varepsilon_{t-1}\n$$\n其中 $\\varepsilon_t$ 是一个白噪声过程，满足 $\\varepsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$。该过程的理论一阶自相关系数 $\\rho_1$ 由下式给出：\n$$\n\\rho_1 = \\frac{\\text{Cov}(y_t, y_{t-1})}{\\text{Var}(y_t)} = \\frac{\\theta}{1+\\theta^2}\n$$\n“手感火热”效应被定义为正的一阶序列相关性，这转化为对 $\\rho_1 > 0$ 的统计检验。假设检验的公式如下：\n- 零假设 $H_0: \\rho_1 = 0$（无一阶自相关）。\n- 备择假设 $H_A: \\rho_1 > 0$（正一阶自相关）。\n\n该检验在模拟数据 $\\{y_t\\}_{t=1}^N$ 上进行。检验统计量是样本滞后1阶自相关系数 $\\hat{\\rho}_1$，根据中心化序列 $\\tilde{y}_t = y_t - \\bar{y}$（其中 $\\bar{y}$ 是样本均值）计算得出。$\\hat{\\rho}_1$ 的公式为：\n$$\n\\hat{\\rho}_1 = \\frac{\\sum_{t=2}^{N} (y_t - \\bar{y})(y_{t-1} - \\bar{y})}{\\sum_{t=1}^{N} (y_t - \\bar{y})^2}\n$$\n在零假设 $H_0$ 下，对于足够大的样本量 $N$，$\\hat{\\rho}_1$ 的分布可以近似为正态分布：\n$$\n\\hat{\\rho}_1 \\approx \\mathcal{N}\\left(0, \\frac{1}{N}\\right)\n$$\n由此，我们构建一个标准化检验统计量 $Z = \\hat{\\rho}_1 \\sqrt{N}$，在 $H_0$ 下，它服从标准正态分布 $Z \\sim \\mathcal{N}(0, 1)$。\n\n对于显著性水平为 $\\alpha$ 的单侧检验，如果观测到的检验统计量超过临界值 $z_{1-\\alpha}$（即标准正态分布的 $(1-\\alpha)$-分位数），我们则拒绝零假设 $H_0$。决策规则是：\n$$\n\\text{Reject } H_0 \\text{ if } \\hat{\\rho}_1 \\sqrt{N} > z_{1-\\alpha}\n$$\n这种大样本近似适用于 $N$ 较大的情况（例如，$N=400$）。对于较小的 $N$，其准确性会下降。对于 $N=30$ 的情况，它仍被认为是可接受的。对于 $N=2$ 的情况，该近似效果很差。然而，对于 $N=2$，分析表明，对于任意两个不同的点 $y_1, y_2$，样本自相关固定为 $\\hat{\\rho}_1 = -1/2$。负的样本自相关永远不能为正的总体自相关提供证据。因此，对于 $N=2$，我们总是无法拒绝 $H_0: \\rho_1 = 0$ 而支持 $H_A: \\rho_1 > 0$。\n\n每个测试用例的步骤如下：\n1. 设置随机种子以保证可复现性。\n2. 从 $\\mathcal{N}(0, \\sigma^2)$ 生成一个包含 $N+1$ 个独立同分布随机变量的序列 $\\{\\varepsilon_t\\}_{t=0}^N$。\n3. 构建长度为 $N$ 的 MA(1) 序列 $\\{y_t\\}_{t=1}^N$。\n4. 计算样本均值 $\\bar{y}$ 并对序列进行中心化。\n5. 计算样本自相关 $\\hat{\\rho}_1$。如果分母为零（对于连续数据，其发生概率为零），则说明没有变异，因此没有相关性的证据。\n6. 计算检验统计量 $Z = \\hat{\\rho}_1 \\sqrt{N}$。\n7. 从标准正态分布中确定临界值 $z_{1-\\alpha}$。\n8. 如果 $Z > z_{1-\\alpha}$，则有“手感火热”效应的证据 (True)；否则，没有 (False)。", "answer": "```python\n# language: Python\n# version: 3.12\n# libraries:\n#   name: numpy\n#   version: 1.23.5\n#   name: scipy\n#   version: 1.11.4\n\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the Moving Average (MA)(1) model.\n    \"\"\"\n\n    def analyze_hot_hand(N, theta, sigma_sq, alpha, seed):\n        \"\"\"\n        Simulates an MA(1) series and tests for positive first-order autocorrelation.\n\n        Args:\n            N (int): The length of the time series.\n            theta (float): The MA(1) parameter.\n            sigma_sq (float): The variance of the white noise term.\n            alpha (float): The significance level for the one-sided test.\n            seed (int): The random seed for reproducibility.\n\n        Returns:\n            bool: True if there is evidence of a hot hand, False otherwise.\n        \"\"\"\n        # 1. Set the random seed\n        np.random.seed(seed)\n\n        sigma = np.sqrt(sigma_sq)\n\n        # 2. Generate N+1 white noise terms to produce a series of length N\n        # We need eps_0, ..., eps_N to compute y_1, ..., y_N\n        eps = np.random.normal(loc=0.0, scale=sigma, size=N + 1)\n\n        # 3. Construct the MA(1) series y_t = eps_t + theta * eps_{t-1}\n        # The resulting series 'y' has length N, corresponding to t=1,...,N\n        y = eps[1:] + theta * eps[:-1]\n\n        # 4. Center the series by subtracting the sample mean\n        y_mean = np.mean(y)\n        y_centered = y - y_mean\n        \n        # 5. Compute the sample lag-1 autocorrelation coefficient, rho_hat_1\n        # Denominator of rho_hat_1: sum of squared deviations\n        denominator = np.sum(y_centered**2)\n        \n        # If variance is zero, all y_t are identical.\n        # Autocorrelation is undefined, and there is no evidence of dependence.\n        if denominator == 0.0:\n            return False\n\n        # Numerator of rho_hat_1: sum of cross-products of lagged centered values\n        # y_centered[1:] corresponds to (y_2-y_bar), ..., (y_N-y_bar)\n        # y_centered[:-1] corresponds to (y_1-y_bar), ..., (y_{N-1}-y_bar)\n        numerator = np.sum(y_centered[1:] * y_centered[:-1])\n        \n        rho_hat_1 = numerator / denominator\n\n        # For N <= 1, autocorrelation is not well-defined.\n        if N <= 1:\n            return False\n\n        # 6. Compute the test statistic Z = rho_hat_1 * sqrt(N)\n        # This is based on the large-sample approximation.\n        test_statistic = rho_hat_1 * np.sqrt(N)\n        \n        # 7. Determine the critical value for a one-sided test\n        # This is the (1-alpha) quantile of the standard normal distribution.\n        critical_value = norm.ppf(1 - alpha)\n        \n        # 8. Perform the test: reject H0 if test_statistic > critical_value\n        return test_statistic > critical_value\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N, theta, sigma^2, alpha, seed)\n        (400, 0.8, 9.0, 0.05, 1729),\n        (400, 0.0, 9.0, 0.05, 31415),\n        (400, -0.8, 9.0, 0.05, 271828),\n        (30, 0.6, 9.0, 0.05, 123456),\n        (2, 0.7, 9.0, 0.05, 7),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, theta, sigma_sq, alpha, seed = case\n        result = analyze_hot_hand(N, theta, sigma_sq, alpha, seed)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}, {"introduction": "在理解了移动平均模型的内在属性之后，下一步是将其应用于实际的预测任务中。本练习将 $MA(3)$ 模型作为一个用户正常消费行为的基准模型，用以设计一个信用卡欺诈检测算法。通过顺序计算一步向前预测并识别异常大的预测误差，您将学会如何利用移动平均模型进行异常检测，并深刻理解模型的“新息”（innovation）——即预测误差——在识别偏离常规模式的事件中所扮演的关键角色。[@problem_id:2412539]", "id": "2412539", "problem": "给定一个形式化模型，用于描述单个用户的正常信用卡消费行为，该模型为一个三阶移动平均（MA(3)）时间序列。MA(3)模型由弱平稳性和序列不相关的创新项条件下的线性时间序列的核心概率结构定义：一个标量过程 $\\{y_t\\}$ 满足 $y_t = \\mu + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\theta_3 \\varepsilon_{t-3}$，其中 $\\mu$ 是一个恒定均值，$\\{\\varepsilon_t\\}$ 是一个零均值、序列不相关、方差为 $\\sigma^2$ 的创新序列，而 $\\theta_1,\\theta_2,\\theta_3$ 是实数系数。在此模型和迭代期望定律下，单步预测 $E[y_t \\mid \\mathcal{F}_{t-1}]$ 在所有 $\\mathcal{F}_{t-1}$-可测的预测量中，能最小化均方预测误差，其中 $\\mathcal{F}_{t-1}$ 是由 $\\{y_s: s \\le t-1\\}$ 生成的sigma-代数。如果在时间 $t$ 的一笔交易导致了相对于创新项方差而言较大的单步预测误差，则该交易被标记为潜在欺诈。您必须设计一个算法，在每个时间点 $t$，根据MA(3)结构从 $\\mathcal{F}_{t-1}$ 中生成单步预测，计算由此产生的预测误差，用已知的标准差 $\\sigma$ 对其进行标准化，并且如果标准化误差的绝对值超过了以标准差为单位表示的预设阈值 $\\tau$，则标记时间点 $t$。在预测中，任何不可用的过去创新项的条件期望（例如，当 $t \\le 3$ 时）必须按零处理，因为其均值为零且与 $\\mathcal{F}_{t-1}$ 独立。您的算法应仅使用截至前一时间点可用的信息，顺序计算单步预测和由此产生的预测误差。\n\n程序要求：\n1) 输入是硬编码的：您必须为下面定义的固定测试套件实现您的算法。不允许用户输入。不允许访问外部文件或网络。\n2) 对于每个测试用例，给定 $(\\mu, \\boldsymbol{\\theta}, \\sigma^2, \\tau, \\mathbf{y})$，其中 $\\boldsymbol{\\theta} = (\\theta_1,\\theta_2,\\theta_3)$ 且 $\\mathbf{y} = [y_1,\\dots,y_T]$。将所有量视为实数。创新项的标准差为 $\\sigma = \\sqrt{\\sigma^2}$。对于每个时间索引 $t \\in \\{1,\\dots,T\\}$，仅使用 $\\{y_s: s \\le t-1\\}$ 计算由MA(3)结构蕴含的单步预测 $\\widehat{y}_{t \\mid t-1}$，定义预测误差 $e_t = y_t - \\widehat{y}_{t \\mid t-1}$，计算标准化误差 $z_t = e_t / \\sigma$，如果 $|z_t| > \\tau$，则标记时间 $t$。对于每个测试用例，以升序整数列表的形式输出被标记的索引。\n3) 您必须使用以下测试套件：\n- 案例A（具有单次大幅突刺的一般行为）：$\\mu = 100$, $\\boldsymbol{\\theta} = (0.5,-0.2,0.1)$, $\\sigma^2 = 25$, $\\tau = 3$, $\\mathbf{y} = [98,102,99,140,118,95,106,101]$。\n- 案例B（短序列边界情况，早期时间点）：$\\mu = 50$, $\\boldsymbol{\\theta} = (0.7,0.1,-0.4)$, $\\sigma^2 = 4$, $\\tau = 2$, $\\mathbf{y} = [50,56,46]$。\n- 案例C（交替符号参数，临界情况和一次突刺）：$\\mu = 200$, $\\boldsymbol{\\theta} = (-0.4,0.3,-0.2)$, $\\sigma^2 = 16$, $\\tau = 2.5$, $\\mathbf{y} = [205,194,195,180,210,193]$。\n- 案例D（白噪声基线，预计无标记）：$\\mu = 0$, $\\boldsymbol{\\theta} = (0,0,0)$, $\\sigma^2 = 9$, $\\tau = 3$, $\\mathbf{y} = [1,-2,4,-5,6,-3]$。\n- 案例E（连续的大偏差）：$\\mu = 75$, $\\boldsymbol{\\theta} = (0.9,0.4,0.2)$, $\\sigma^2 = 100$, $\\tau = 2.5$, $\\mathbf{y} = [70,120,65,50]$。\n4) 最终输出格式：您的程序应生成单行输出，其中包含一个由逗号分隔的整数列表组成的列表作为结果，用方括号括起来，并且任何地方都没有空格。例如，一个有效的输出形式是 $[[1,3],[2],[]]$。对于给定的测试套件，输出必须是 $[L_A,L_B,L_C,L_D,L_E]$ 形式的单行，其中每个 $L_\\cdot$ 是相应案例的被标记索引列表（按升序排列）。\n\n您的任务是：实现一个完整的、可运行的程序，该程序遵循MA(3)模型定义所蕴含的算法，为整个测试套件计算标记，并以要求的格式精确打印单行聚合输出。所有数值答案都是无量纲的（没有物理单位）。不涉及角度。不使用百分比。每个案例结果唯一可接受的数据类型是整数列表（可能为空）。", "solution": "问题陈述已经过验证，被认定为有效。这是一个在计算时间序列分析领域中提法恰当、有科学依据的问题，基于已建立的移动平均（MA）模型和最优预测理论。所有参数和条件都已完全指定，从而可以得到唯一且可验证的解。\n\n该问题要求为一个被建模为三阶移动平均过程（记为MA(3)）的时间序列 $\\{y_t\\}$ 实现一个异常检测算法。该模型由以下方程定义：\n$$y_t = \\mu + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\theta_3 \\varepsilon_{t-3}$$\n在这里，$\\mu$ 是过程的恒定均值，而 $\\{\\varepsilon_t\\}$ 是一系列序列不相关的随机变量（创新项或扰动项），其均值为 $E[\\varepsilon_t] = 0$，恒定方差为 $Var(\\varepsilon_t) = \\sigma^2$。系数 $\\theta_1, \\theta_2, \\theta_3$ 是模型的实值参数。\n\n任务的核心是为每个时间点 $t \\in \\{1, 2, \\dots, T\\}$ 计算单步预测 $\\widehat{y}_{t \\mid t-1}$。该预测是在给定截至时间 $t-1$ 的可用信息下的 $y_t$ 的条件期望，这些信息由sigma-代数 $\\mathcal{F}_{t-1} = \\sigma(\\{y_s: s \\le t-1\\})$ 表示。条件期望是最小化均方预测误差的预测量。\n预测计算如下：\n$$\\widehat{y}_{t \\mid t-1} = E[y_t \\mid \\mathcal{F}_{t-1}] = E[\\mu + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\theta_3 \\varepsilon_{t-3} \\mid \\mathcal{F}_{t-1}]$$\n根据期望的线性性质和条件期望的性质，上式变为：\n$$\\widehat{y}_{t \\mid t-1} = E[\\mu \\mid \\mathcal{F}_{t-1}] + E[\\varepsilon_t \\mid \\mathcal{F}_{t-1}] + \\theta_1 E[\\varepsilon_{t-1} \\mid \\mathcal{F}_{t-1}] + \\theta_2 E[\\varepsilon_{t-2} \\mid \\mathcal{F}_{t-1}] + \\theta_3 E[\\varepsilon_{t-3} \\mid \\mathcal{F}_{t-1}]$$\n让我们评估每一项：\n1. 由于 $\\mu$ 是常数，因此 $E[\\mu \\mid \\mathcal{F}_{t-1}] = \\mu$。\n2. 根据定义，创新项 $\\varepsilon_t$ 无法从过去的信息中预测。因此，其在给定过去信息下的条件期望等于其无条件均值，$E[\\varepsilon_t \\mid \\mathcal{F}_{t-1}] = E[\\varepsilon_t] = 0$。\n3. 对于 $k > 0$ 的过去创新项 $\\varepsilon_{t-k}$，我们必须确定在时间 $t-1$ 它们是否已知。模型方程可以被改写，用当前观测值和过去的创新项来表示当前的创新项：\n$$\\varepsilon_t = y_t - \\mu - \\theta_1 \\varepsilon_{t-1} - \\theta_2 \\varepsilon_{t-2} - \\theta_3 \\varepsilon_{t-3}$$\n这种关系允许对创新序列进行递归计算。给定观测值 $\\{y_s: s \\le t-1\\}$，可以确定 $\\{\\varepsilon_s: s \\le t-1\\}$ 的值。因此，对于 $k \\in \\{1, 2, 3\\}$，创新项 $\\varepsilon_{t-k}$ 关于 $\\mathcal{F}_{t-1}$ 是可测的，其条件期望就是其自身的值：$E[\\varepsilon_{t-k} \\mid \\mathcal{F}_{t-1}] = \\varepsilon_{t-k}$。\n\n然而，这仅在 $\\varepsilon_{t-k}$ 的值可以被计算时才成立。对于早期的时步（例如，$t=1$），所需的过去创新项 $\\varepsilon_0, \\varepsilon_{-1}, \\varepsilon_{-2}$ 无法由从 $y_1$ 开始的观测序列确定。问题陈述正确地指明，任何不可用的过去创新项的条件期望必须按其无条件均值0处理。这是初始化预测函数的标准处理方法。\n\n综合这些事实，预测方程为：\n$$\\widehat{y}_{t \\mid t-1} = \\mu + \\theta_1 \\varepsilon_{t-1}^* + \\theta_2 \\varepsilon_{t-2}^* + \\theta_3 \\varepsilon_{t-3}^*$$\n其中，如果 $\\varepsilon_{t-k}$ 的值已从先前的观测中计算得出，则 $\\varepsilon_{t-k}^* = \\varepsilon_{t-k}$，否则 $\\varepsilon_{t-k}^* = 0$。\n\n单步预测误差为 $e_t = y_t - \\widehat{y}_{t \\mid t-1}$。代入 $\\widehat{y}_{t \\mid t-1}$ 的表达式并使用 $y_t$ 的模型定义：\n$$e_t = (\\mu + \\varepsilon_t + \\sum_{k=1}^{3} \\theta_k \\varepsilon_{t-k}) - (\\mu + \\sum_{k=1}^{3} \\theta_k \\varepsilon_{t-k}) = \\varepsilon_t$$\n这证实了预测误差恰好是时间 $t$ 的创新项。这是一个基本结果。因此，算法必须迭代计算创新序列。\n\n算法按以下步骤进行：\n1. 初始化创新项的历史记录。对于时间 $t \\le 0$，创新项是未知的，因此我们使用其期望值0。\n2. 对于从1到$T$的每个时间步 $t$：\n    a. 确定预测所需的过去创新项 $\\varepsilon_{t-1}, \\varepsilon_{t-2}, \\varepsilon_{t-3}$。如果历史记录太短，则对缺失值使用0。\n    b. 计算单步预测：$\\widehat{y}_{t \\mid t-1} = \\mu + \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\theta_3 \\varepsilon_{t-3}$。\n    c. 使用当前观测值 $y_t$ 计算当前创新项：$\\varepsilon_t = y_t - \\widehat{y}_{t \\mid t-1}$。\n    d. 存储新计算出的 $\\varepsilon_t$ 以用于后续预测。\n    e. 计算标准化误差 $z_t = \\varepsilon_t / \\sigma$，其中 $\\sigma = \\sqrt{\\sigma^2}$。\n    f. 如果 $|z_t| > \\tau$（其中 $\\tau$ 是给定的阈值），则将索引 $t$（使用从1开始的索引）记录为被标记。\n3. 将所有测试用例的被标记索引列表整理成指定的输出格式。\n这个顺序过程正确地实现了MA(3)模型下的预测和异常检测逻辑。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the MA(3) fraud detection problem for a fixed test suite.\n    \"\"\"\n    test_cases = [\n        # Case A: General behavior with a single large spike\n        {\n            'mu': 100.0, 'theta': (0.5, -0.2, 0.1), 'sigma2': 25.0, 'tau': 3.0,\n            'y': [98.0, 102.0, 99.0, 140.0, 118.0, 95.0, 106.0, 101.0]\n        },\n        # Case B: Short series edge case, early times\n        {\n            'mu': 50.0, 'theta': (0.7, 0.1, -0.4), 'sigma2': 4.0, 'tau': 2.0,\n            'y': [50.0, 56.0, 46.0]\n        },\n        # Case C: Alternating-sign parameters, borderline and one spike\n        {\n            'mu': 200.0, 'theta': (-0.4, 0.3, -0.2), 'sigma2': 16.0, 'tau': 2.5,\n            'y': [205.0, 194.0, 195.0, 180.0, 210.0, 193.0]\n        },\n        # Case D: White noise baseline, no flags expected\n        {\n            'mu': 0.0, 'theta': (0.0, 0.0, 0.0), 'sigma2': 9.0, 'tau': 3.0,\n            'y': [1.0, -2.0, 4.0, -5.0, 6.0, -3.0]\n        },\n        # Case E: Back-to-back large deviations\n        {\n            'mu': 75.0, 'theta': (0.9, 0.4, 0.2), 'sigma2': 100.0, 'tau': 2.5,\n            'y': [70.0, 120.0, 65.0, 50.0]\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        mu = case['mu']\n        theta1, theta2, theta3 = case['theta']\n        sigma = np.sqrt(case['sigma2'])\n        tau = case['tau']\n        y_series = case['y']\n\n        eps_history = []\n        flagged_indices = []\n\n        for t_idx, y_t in enumerate(y_series):\n            # Time t is 1-based\n            t = t_idx + 1\n\n            # Get past innovations, using 0 for unavailable history\n            eps_tm1 = eps_history[t_idx - 1] if t_idx - 1 >= 0 else 0.0\n            eps_tm2 = eps_history[t_idx - 2] if t_idx - 2 >= 0 else 0.0\n            eps_tm3 = eps_history[t_idx - 3] if t_idx - 3 >= 0 else 0.0\n\n            # Compute the one-step-ahead forecast\n            y_hat = mu + theta1 * eps_tm1 + theta2 * eps_tm2 + theta3 * eps_tm3\n\n            # Compute the current innovation (forecast error)\n            eps_t = y_t - y_hat\n            eps_history.append(eps_t)\n\n            # Standardize the error\n            z_t = eps_t / sigma\n\n            # Check if it exceeds the threshold\n            if abs(z_t) > tau:\n                flagged_indices.append(t)\n        \n        all_results.append(flagged_indices)\n\n    # Format the final output string exactly as required (no spaces)\n    result_strings = [f\"[{','.join(map(str, r))}]\" for r in all_results]\n    final_output = f\"[{','.join(result_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```"}, {"introduction": "在现实世界的金融建模中，我们通常无法预先知道模型的真实参数，而必须从数据中进行估计。这个综合性练习将引导您完成一个计量经济学家的完整工作流程：面对一个未知的时间序列，您需要估计一个 $MA(5)$ 模型的参数，然后进行至关重要的模型诊断，以检验模型的设定是否合理。通过实施从模型估计（条件平方和法）到残差分析（检验序列相关性）的全过程，您将掌握评估和验证时间序列模型的关键技能。[@problem_id:2412549]", "id": "2412549", "problem": "在此计算经济学和金融学的背景下，您需要为移动平均 (MA) 模型实现一个端到端的估算和诊断检验流程。该流程必须完全自包含，并产生单行可验证的输出。您的程序必须仅从第一性原理和核心定义出发，实现以下内容。\n\n考虑一个单变量时间序列 $\\{x_t\\}_{t=1}^T$，代表每日股票指数的对数回报率。在有效市场中，每日回报率的常规均值模型使用 $q$ 阶移动平均过程 (MA($q$)) 来描述均值动态：对于 $q \\in \\mathbb{N}$，MA($q$) 模型为\n$$\nx_t \\;=\\; \\mu \\;+\\; \\epsilon_t \\;+\\; \\theta_1 \\epsilon_{t-1} \\;+\\; \\cdots \\;+\\; \\theta_q \\epsilon_{t-q},\n$$\n其中 $\\mu \\in \\mathbb{R}$ 是无条件均值，$\\{\\epsilon_t\\}$ 是一个独立同分布的白噪声序列，满足 $E[\\epsilon_t] = 0$ 和 $\\operatorname{Var}(\\epsilon_t) = \\sigma^2 \\in \\mathbb{R}_{+}$，并且 $\\boldsymbol{\\theta}=(\\theta_1,\\ldots,\\theta_q) \\in \\mathbb{R}^q$。在有效市场中，一步向前预测误差（即估计的创新项）应该是不可预测的，这意味着从 $\\hat{\\epsilon}_t$ 对 $\\hat{\\epsilon}_{t+1}$ 没有线性预测能力。\n\n您的任务是：\n- 对每个给定的数据集，使用条件平方和 (CSS) 方法拟合一个 MA($5$) 模型。CSS 的定义是通过模型恒等式递归计算残差，并对参数最小化残差平方和。具体来说，给定初始条件 $\\hat{\\epsilon}_t = 0$（对于 $t \\le 0$），定义\n$$\n\\hat{\\epsilon}_t(\\mu, \\boldsymbol{\\theta}) \\;=\\; x_t \\;-\\; \\mu \\;-\\; \\sum_{j=1}^{5} \\theta_j \\hat{\\epsilon}_{t-j}(\\mu, \\boldsymbol{\\theta}),\n$$\n并在 $(\\mu, \\boldsymbol{\\theta}) \\in \\mathbb{R}^{6}$ 上最小化 $\\sum_{t=1}^{T} \\hat{\\epsilon}_t(\\mu, \\boldsymbol{\\theta})^2$。\n- 在估计参数并从拟合的 MA($5$) 模型中构建出估计的一步向前创新项 $\\{\\hat{\\epsilon}_t\\}$ 后，使用普通最小二乘 (OLS) 回归将 $\\hat{\\epsilon}_{t+1}$ 对一个常数项和 $\\hat{\\epsilon}_t$ 进行回归，以检验原假设，即 $\\hat{\\epsilon}_t$ 对 $\\hat{\\epsilon}_{t+1}$ 没有线性预测能力：\n$$\n\\hat{\\epsilon}_{t+1} \\;=\\; \\alpha \\;+\\; \\beta \\hat{\\epsilon}_t \\;+\\; u_{t+1}.\n$$\n在原假设 $H_0: \\beta = 0$ 下，基于常规的 OLS $t$ 统计量（其自由度为 $T-2$）计算 $\\beta$ 的双边 p 值。使用显著性水平 $\\alpha_{\\text{test}} = 0.05$。\n- 对每个数据集，按照以下约定报告一个布尔决策：如果在 $\\alpha_{\\text{test}}$ 水平上未能拒绝 $H_0$（解释为“残差是不可预测的”），则输出 $\\text{True}$；如果拒绝 $H_0$（解释为“残差对 $\\hat{\\epsilon}_{t+1}$ 具有预测能力”），则输出 $\\text{False}$。\n\n您必须遵守的基本依据和约束条件：\n- 仅使用白噪声的定义、MA($q$) 模型的定义以及通过模型恒等式构建 CSS 残差作为估计算法主干。不要使用预先构建的时间序列估计黑箱。\n- OLS 回归及其 $t$ 检验必须遵循标准的线性回归原理，其中 $t$ 统计量根据估计的斜率系数及其标准误计算，并相应地计算双边 p 值。\n- 此问题中没有物理单位。不出现角度单位。不应打印任何百分比。\n\n测试套件：\n模拟四个数据集，以模拟 S&amp;P $500$ 的每日回报率，其日波动率在 $1\\%$ 的现实量级上。对于每种情况，模拟一个创新序列 $\\{w_t\\}$，其中 $w_t \\sim \\mathcal{N}(0,\\sigma^2)$，$\\sigma = 0.01$，并为了一般性，将过程构建为自回归移动平均 (ARMA) 模型：\n$$\nx_t - \\mu \\;=\\; \\phi (x_{t-1} - \\mu) \\;+\\; w_t \\;+\\; \\sum_{j=1}^{5} \\theta_j w_{t-j},\n$$\n初始条件为 $x_0 = \\mu$ 和 $w_t = 0$（对于 $t \\le 0$）。这将 MA($5$) 作为 $\\phi = 0$ 的特例嵌套在内。对每个数据集，使用以下参数：\n\n- 情况 1（基线 MA($5$)，“有效”均值模型）：\n  - 随机种子 $= 202311$，长度 $T = 900$，$\\mu = 0$，$\\phi = 0$，$\\boldsymbol{\\theta} = (0.4, -0.3, 0.2, -0.1, 0.05)$，$\\sigma = 0.01$。\n- 情况 2（带温和自回归的 ARMA($1,5$)，如果仅拟合 MA($5$) 则模型设定错误）：\n  - 随机种子 $= 202312$，长度 $T = 900$，$\\mu = 0$，$\\phi = 0.3$，$\\boldsymbol{\\theta} = (0.4, -0.3, 0.2, -0.1, 0.05)$，$\\sigma = 0.01$。\n- 情况 3（白噪声均值动态，MA($0$)）：\n  - 随机种子 $= 202313$，长度 $T = 600$，$\\mu = 0$，$\\phi = 0$，$\\boldsymbol{\\theta} = (0, 0, 0, 0, 0)$，$\\sigma = 0.01$。\n- 情况 4（具有中等持续性的纯自回归 AR($1$)，如果仅拟合 MA($5$) 则模型设定错误）：\n  - 随机种子 $= 202314$，长度 $T = 250$，$\\mu = 0$，$\\phi = 0.6$，$\\boldsymbol{\\theta} = (0, 0, 0, 0, 0)$，$\\sigma = 0.01$。\n\n您的程序必须：\n- 使用给定的随机种子和参数，完全按照规定模拟每个数据集。\n- 对每个数据集通过 CSS 方法拟合一个 MA($5$) 模型，以获得 $\\{\\hat{\\epsilon}_t\\}$。\n- 在 $\\hat{\\epsilon}_{t+1}$ 对一个常数和 $\\hat{\\epsilon}_t$ 的回归中，使用显著性水平为 $\\alpha_{\\text{test}} = 0.05$ 的双边检验来执行 $H_0: \\beta = 0$ 的 OLS 检验，并按描述形成决策。\n- 生成单行输出，其中包含一个 Python 风格的布尔值列表，按情况 1,2,3,4 的顺序排列，例如 $[\\,\\text{True},\\text{False},\\text{True},\\text{False}\\,]$。\n\n您的程序必须是一个完整、可运行的脚本，并且不得需要任何用户输入或外部文件。最终输出格式必须是严格的一行，即一个由方括号括起来、逗号分隔的布尔值列表。", "solution": "问题陈述已经过严格评估，并被认为是有效的。它具有科学依据、提法得当且客观。它为时间序列计量经济学中的一个标准练习提供了完整且一致的指令集：移动平均 (MA) 模型的估计及其残差的诊断性检验。该过程要求从第一性原理实现，这是对基础理解的严格考验。注意到的唯一微小不一致之处——为 $t$ 检验指定的自由度为 $T-2$ 而不是对长度为 $T$ 的时间序列进行简单回归时的规范自由度 $T-3$——被解释为一条直接且明确的指令，而非一个使问题失效的缺陷。我们按照规定继续进行解答。\n\n解决方案分为三个主要阶段构建：\n1.  根据指定的自回归移动平均 (ARMA) 过程模拟时间序列数据。\n2.  使用条件平方和 (CSS) 方法为每个数据集估计一个 5 阶移动平均模型，即 MA(5)。\n3.  使用基于普通最小二乘 (OLS) 回归的检验，对估计模型的残差进行一阶序列自相关诊断性检验。\n\n**1. 时间序列模拟**\n\n问题要求从一个一般的 ARMA(1,5) 过程中生成四个数据集。时间序列 $\\{x_t\\}$ 的模型由下式给出：\n$$\nx_t - \\mu \\;=\\; \\phi (x_{t-1} - \\mu) \\;+\\; w_t \\;+\\; \\sum_{j=1}^{5} \\theta_j w_{t-j}\n$$\n其中 $\\mu$ 是均值，$\\phi$ 是自回归系数，$\\boldsymbol{\\theta} = (\\theta_1, \\ldots, \\theta_5)$ 是移动平均系数，$\\{w_t\\}$ 是一个高斯白噪声过程，满足 $w_t \\sim \\mathcal{N}(0, \\sigma^2)$。模拟从初始条件 $x_0 = \\mu$ 和 $w_t = 0$（对于 $t \\le 0$）开始。对于四个指定的参数集中的每一个，都递归地生成数据 $\\{x_t\\}_{t=1}^T$。这种设置允许在模型正确设定（情况 1 和 3）和模型设定错误（情况 2 和 4）两种条件下，检验 MA(5) 估计过程的性能。\n\n**2. 通过条件平方和 (CSS) 进行 MA(5) 估计**\n\n对于每个模拟的时间序列 $\\{x_t\\}_{t=1}^T$，我们拟合一个 MA(5) 模型：\n$$\nx_t \\;=\\; \\mu \\;+\\; \\epsilon_t \\;+\\; \\sum_{j=1}^{5} \\theta_j \\epsilon_{t-j}\n$$\n待估计的参数是均值 $\\mu$ 和 MA 系数 $\\boldsymbol{\\theta} = (\\theta_1, \\ldots, \\theta_5)$。估计通过最小化条件平方和 (CSS) 来执行。这涉及递归地计算模型的残差 $\\{\\hat{\\epsilon}_t\\}$ 并最小化其平方和。\n\n残差通过重排模型方程定义：\n$$\n\\hat{\\epsilon}_t(\\mu, \\boldsymbol{\\theta}) \\;=\\; x_t \\;-\\; \\mu \\;-\\; \\sum_{j=1}^{5} \\theta_j \\hat{\\epsilon}_{t-j}(\\mu, \\boldsymbol{\\theta})\n$$\n为了开始递归，我们施加初始条件 $\\hat{\\epsilon}_t = 0$（对于所有 $t \\le 0$）。要最小化的目标函数是残差平方和：\n$$\nS(\\mu, \\boldsymbol{\\theta}) = \\sum_{t=1}^{T} \\hat{\\epsilon}_t(\\mu, \\boldsymbol{\\theta})^2\n$$\n这是一个关于 6 个参数 $(\\mu, \\theta_1, \\ldots, \\theta_5)$ 的非线性优化问题。我们采用一个数值拟牛顿优化算法（具体为 `scipy.optimize` 中可用的 L-BFGS-B）来找到使 $S(\\mu, \\boldsymbol{\\theta})$ 最小化的参数估计值 $(\\hat{\\mu}, \\hat{\\boldsymbol{\\theta}})$。一旦找到这些估计值，就计算出最终的估计创新项序列，或称残差，即 $\\{\\hat{\\epsilon}_t\\}_{t=1}^T$。\n\n**3. 残差自相关的诊断性检验**\n\n一个正确设定和估计的时间序列模型所留下的残差，应该从其自身的过去是不可预测的；也就是说，它们应近似一个白噪声过程。为了检验这一点，我们考察在时间 $t$ 的估计创新项 $\\hat{\\epsilon}_t$ 是否对时间 $t+1$ 的创新项 $\\hat{\\epsilon}_{t+1}$ 具有任何线性预测能力。这通过一个 OLS 回归进行检验：\n$$\n\\hat{\\epsilon}_{t+1} \\;=\\; \\alpha \\;+\\; \\beta \\hat{\\epsilon}_t \\;+\\; u_{t+1}, \\quad t = 1, \\ldots, T-1\n$$\n无一阶序列自相关的原假设是 $H_0: \\beta = 0$。我们计算 OLS 估计值 $\\hat{\\beta}$ 及其相关的 $t$ 统计量。\n\n$\\beta$ 的 OLS 估计值是向量 $\\hat{\\mathbf{b}} = (\\hat{\\alpha}, \\hat{\\beta})'$ 的一个分量，由下式给出：\n$$\n\\hat{\\mathbf{b}} = (X'X)^{-1}X'Y\n$$\n其中 $Y$ 是因变量向量 $(\\hat{\\epsilon}_2, \\ldots, \\hat{\\epsilon}_T)'$，而 $X$ 是设计矩阵，其行为 $(1, \\hat{\\epsilon}_t)$，其中 $t=1, \\ldots, T-1$。\n\n$\\hat{\\beta}$ 的 $t$ 统计量计算如下：\n$$\nt_{\\hat{\\beta}} = \\frac{\\hat{\\beta}}{\\text{s.e.}(\\hat{\\beta})}\n$$\n标准误 $\\text{s.e.}(\\hat{\\beta})$ 是估计的系数协方差矩阵 $\\hat{\\sigma}_u^2 (X'X)^{-1}$ 中相应对角元素的平方根。回归误差的方差 $\\sigma_u^2$ 通过 $s_u^2 = \\frac{1}{N_{\\text{reg}}-2} \\sum u_t^2$ 来估计，其中 $N_{\\text{reg}}=T-1$ 是回归中的观测数量，而 $u_t$ 是 OLS 残差。\n\n然后我们为这个 $t$ 统计量计算一个双边 $p$ 值。根据问题的明确指令，我们使用具有 $T-2$ 个自由度的学生 t 分布。\n\n最终决策通过将 $p$ 值与显著性水平 $\\alpha_{\\text{test}} = 0.05$ 进行比较来做出：\n- 如果 $p$-value $\\ge 0.05$，我们未能拒绝原假设 $H_0$。这表明残差是序列不相关的，并且模型在这个维度上是充分的。输出为 `True`。\n- 如果 $p$-value $< 0.05$，我们拒绝 $H_0$。这表明残差中存在显著的序列相关，暗示模型设定错误。输出为 `False`。\n\n这个完整的流程被应用于四个模拟数据集中的每一个，并且布尔决策序列作为最终答案报告。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Main function to run the entire estimation and testing pipeline for all test cases.\n    \"\"\"\n    # Define the test cases as per the problem statement.\n    test_cases = [\n        {\n            \"name\": \"Case 1: MA(5)\",\n            \"seed\": 202311, \"T\": 900, \"mu\": 0.0, \"phi\": 0.0,\n            \"theta\": np.array([0.4, -0.3, 0.2, -0.1, 0.05]), \"sigma\": 0.01\n        },\n        {\n            \"name\": \"Case 2: ARMA(1,5)\",\n            \"seed\": 202312, \"T\": 900, \"mu\": 0.0, \"phi\": 0.3,\n            \"theta\": np.array([0.4, -0.3, 0.2, -0.1, 0.05]), \"sigma\": 0.01\n        },\n        {\n            \"name\": \"Case 3: MA(0) / White Noise\",\n            \"seed\": 202313, \"T\": 600, \"mu\": 0.0, \"phi\": 0.0,\n            \"theta\": np.array([0.0, 0.0, 0.0, 0.0, 0.0]), \"sigma\": 0.01\n        },\n        {\n            \"name\": \"Case 4: AR(1)\",\n            \"seed\": 202314, \"T\": 250, \"mu\": 0.0, \"phi\": 0.6,\n            \"theta\": np.array([0.0, 0.0, 0.0, 0.0, 0.0]), \"sigma\": 0.01\n        }\n    ]\n    \n    alpha_test = 0.05\n    results = []\n\n    for case in test_cases:\n        # Step 1: Simulate time series data\n        x_t = simulate_arma_process(\n            T=case[\"T\"], mu=case[\"mu\"], phi=case[\"phi\"], \n            theta=case[\"theta\"], sigma=case[\"sigma\"], seed=case[\"seed\"]\n        )\n        \n        # Step 2: Fit an MA(5) model and get residuals\n        residuals = estimate_ma_and_get_residuals(x_t, q=5)\n        \n        # Step 3: Perform diagnostic test on residuals\n        decision = perform_diagnostic_test(residuals, alpha_test)\n        results.append(decision)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\ndef simulate_arma_process(T, mu, phi, theta, sigma, seed):\n    \"\"\"\n    Simulates an ARMA(1, q) process given parameters.\n    \"\"\"\n    np.random.seed(seed)\n    q = len(theta)\n    \n    # Generate white noise innovations\n    w = np.random.normal(loc=0.0, scale=sigma, size=T)\n    \n    # Initialize the time series array\n    x = np.zeros(T)\n    \n    # Create padded arrays for past values\n    x_padded = np.concatenate((np.full(1, mu), x)) # x_padded[t] corresponds to x_{t-1}\n    w_padded = np.concatenate((np.zeros(q), w)) # w_padded[t+q] corresponds to w_t\n    \n    for t_idx in range(T): # t_idx from 0 to T-1\n        # In math notation, this corresponds to t = t_idx + 1\n        \n        # AR term: phi * (x_{t-1} - mu)\n        ar_term = phi * (x_padded[t_idx] - mu)\n        \n        # MA term: sum_{j=1 to q} theta_j * w_{t-j}\n        ma_term = 0\n        for j in range(q): # j from 0 to q-1\n            # lag j+1, theta_{j+1}, w_{t-(j+1)}\n            ma_term += theta[j] * w_padded[t_idx + q - (j + 1)]\n            \n        x[t_idx] = mu + ar_term + w[t_idx] + ma_term\n        x_padded[t_idx+1] = x[t_idx]\n        \n    return x\n\ndef estimate_ma_and_get_residuals(x, q):\n    \"\"\"\n    Estimates an MA(q) model using CSS and returns the residuals.\n    \"\"\"\n    # Objective function for CSS minimization\n    def css_objective(params, x_data, q_order):\n        T = len(x_data)\n        mu = params[0]\n        theta = params[1:]\n        eps_hat = np.zeros(T)\n        \n        for i in range(T): # i from 0 to T-1, corresponds to time t=i+1\n            ma_term = 0\n            for j in range(q_order): # j from 0 to q-1, corresponds to lag j+1\n                idx = i - (j + 1)\n                if idx >= 0:\n                    ma_term += theta[j] * eps_hat[idx]\n            eps_hat[i] = x_data[i] - mu - ma_term\n        \n        return np.sum(eps_hat**2)\n\n    # Initial guess for parameters (mu, theta_1, ..., theta_q)\n    initial_params = np.zeros(q + 1)\n    \n    # Minimize the CSS\n    opt_result = minimize(\n        css_objective, \n        initial_params, \n        args=(x, q),\n        method='L-BFGS-B'\n    )\n    \n    # Get estimated parameters\n    estimated_params = opt_result.x\n    \n    # Compute final residuals with estimated parameters\n    T = len(x)\n    mu_hat = estimated_params[0]\n    theta_hat = estimated_params[1:]\n    residuals = np.zeros(T)\n    for i in range(T):\n        ma_term = 0\n        for j in range(q):\n            idx = i - (j + 1)\n            if idx >= 0:\n                ma_term += theta_hat[j] * residuals[idx]\n        residuals[i] = x[i] - mu_hat - ma_term\n        \n    return residuals\n\ndef perform_diagnostic_test(eps_hat, alpha_level):\n    \"\"\"\n    Tests H0: beta=0 in eps_{t+1} = alpha + beta*eps_t + u_{t+1}.\n    Returns True if we fail to reject H0, False otherwise.\n    \"\"\"\n    T = len(eps_hat)\n    \n    # Prepare data for OLS regression\n    y = eps_hat[1:]       # eps_{t+1} for t=1,...,T-1\n    x_reg = eps_hat[:-1]  # eps_t for t=1,...,T-1\n    \n    N_reg = len(y) # Number of observations in regression, T-1\n    \n    # Add a constant (intercept) to the regressor\n    X_reg = np.vstack([np.ones(N_reg), x_reg]).T\n    \n    # OLS estimator: (X'X)^{-1}X'y\n    try:\n        XTX_inv = np.linalg.inv(X_reg.T @ X_reg)\n        b_hat = XTX_inv @ X_reg.T @ y\n    except np.linalg.LinAlgError:\n        # Handle cases of perfect multicollinearity (unlikely with this data)\n        return True # Cannot reject H0 if test cannot be performed\n\n    beta_hat = b_hat[1]\n    \n    # Calculate t-statistic\n    ols_residuals = y - X_reg @ b_hat\n    \n    # Estimate variance of regression error term u\n    # Degrees of freedom for residual variance is N_reg - number of parameters (2)\n    df_residual = N_reg - 2\n    if df_residual <= 0:\n        return True # Not enough data to perform test\n    \n    s2_u = np.sum(ols_residuals**2) / df_residual\n    \n    # Covariance matrix of beta estimates\n    var_b_hat = s2_u * XTX_inv\n    se_beta_hat = np.sqrt(var_b_hat[1, 1])\n    \n    if se_beta_hat == 0:\n        return True # Avoid division by zero\n        \n    t_stat = beta_hat / se_beta_hat\n    \n    # Calculate p-value using t-distribution\n    # As per problem, degrees of freedom is T-2\n    df_test = T - 2\n    p_value = 2 * t.sf(np.abs(t_stat), df=df_test)\n    \n    # Decision rule\n    return p_value >= alpha_level\n\nif __name__ == \"__main__\":\n    solve()\n\n```"}]}