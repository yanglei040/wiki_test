{"hands_on_practices": [{"introduction": "模型选择的核心在于模型的拟合优度与复杂性之间的权衡。本练习通过一个生物学背景下的假设场景，让你亲手计算和比较两个模型的贝叶斯信息准则 (BIC)。通过这个基础计算，你将直观地理解 BIC 是如何通过对参数数量的惩罚来倾向于选择更简洁有效的模型，即使一个更复杂的模型可能具有更高的似然值 [@problem_id:1447591]。", "id": "1447591", "problem": "一位系统生物学家正在研究一种特定细菌菌株在波动的营养环境中的种群动态。人们提出了两个相互竞争的数学模型，即模型 A 和模型 B，来描述细菌的生长。该生物学家进行了一项实验，并收集了一个时间序列数据集，其中包含 $n=200$ 个细菌种群密度的测量值。\n\n模型 A 是一个较简单的模型，有 $k_A = 3$ 个可调参数。将此模型与实验数据拟合后，发现似然函数的自然对数最大值为 $\\ln(\\mathcal{L}_A) = -180.5$。\n\n模型 B 是一个更复杂的模型，它包含了额外的动态特性，总共有 $k_B = 5$ 个可调参数。将此模型与相同的数据集拟合，得到的最大自然对数似然值为 $\\ln(\\mathcal{L}_B) = -177.0$。\n\n为了在惩罚复杂度的同时判断哪个模型能被数据更好地支持，研究人员使用了贝叶斯信息准则 (BIC)。BIC 使用以下公式计算：\n$$BIC = k \\ln(n) - 2 \\ln(\\mathcal{L})$$\n其中 $k$ 是模型中的参数数量，$n$ 是数据点的数量，而 $\\ln(\\mathcal{L})$ 是最大自然对数似然值。BIC 分数较低的模型被认为能更好地拟合数据。\n\n为了量化一个模型优于另一个模型的证据，请计算差值 $\\Delta BIC = BIC_{B} - BIC_{A}$。请将您的 $\\Delta BIC$ 答案表示为一个实数，并四舍五入到三位有效数字。", "solution": "对于一个参数数量为 $k$、样本大小为 $n$、最大对数似然值为 $\\ln(\\mathcal{L})$ 的模型，其贝叶斯信息准则为\n$$\nBIC = k \\ln(n) - 2 \\ln(\\mathcal{L}).\n$$\n对于模型 A，其参数为 $k_{A} = 3$，$n = 200$，以及 $\\ln(\\mathcal{L}_{A}) = -180.5$，\n$$\nBIC_{A} = 3 \\ln(200) - 2(-180.5) = 3 \\ln(200) + 361.\n$$\n对于模型 B，其参数为 $k_{B} = 5$，$n = 200$，以及 $\\ln(\\mathcal{L}_{B}) = -177.0$，\n$$\nBIC_{B} = 5 \\ln(200) - 2(-177.0) = 5 \\ln(200) + 354.\n$$\n其差值为\n$$\n\\Delta BIC = BIC_{B} - BIC_{A} = \\left(5 \\ln(200) + 354\\right) - \\left(3 \\ln(200) + 361\\right) = 2 \\ln(200) - 7.\n$$\n对 $\\ln(200)$ 进行数值计算：\n$$\n\\ln(200) = \\ln(2) + 2 \\ln(10) \\approx 0.6931471806 + 2 \\times 2.302585093 \\approx 5.298317367.\n$$\n因此，\n$$\n\\Delta BIC \\approx 2 \\times 5.298317367 - 7 = 10.596634734 - 7 = 3.596634734.\n$$\n四舍五入到三位有效数字得到 $3.60$。", "answer": "$$\\boxed{3.60}$$"}, {"introduction": "在金融和经济学的实证研究中，我们经常需要决定模型的函数形式，例如，一个变量的影响是线性的还是非线性的。本练习将带你进入一个经典的计算金融问题：对CEO薪酬建模，并使用赤池信息准则 (AIC) 和贝叶斯信息准则 (BIC) 来判断是否需要包含公司规模的二次项。你将通过编写代码来模拟数据、估计模型并进行选择，从而深入了解这些准则在不同样本量和信号强度下的实际表现 [@problem_id:2410451]。", "id": "2410451", "problem": "您的任务是设计并实现一个程序，在公司金融背景下，使用信息准则评估在为首席执行官（CEO）薪酬建模时，公司规模的二次项是否为必要的非线性项。请完全在基于高斯线性模型的统计框架内进行，并从基本原理出发进行论证。\n\n考虑以下设置。对于每个测试用例，按如下方式生成一个合成观测数据集。对于观测索引 $i \\in \\{1,\\dots,n\\}$，定义一个回归量 $x_i$，表示公司规模的对数，其独立地从均值为 $\\mu_x$、方差为 $\\sigma_x^2$ 的正态分布中抽取；以及一个误差项 $\\varepsilon_i$，其独立地从均值为 $0$、方差为 $\\sigma^2$ 的正态分布中抽取。因变量 $y_i$ 表示CEO薪酬的对数。数据生成过程为\n$$\ny_i = \\beta_0 + \\beta_1 x_i + \\beta_2 x_i^2 + \\varepsilon_i.\n$$\n您将比较关于 $y_i$ 条件均值的两个候选模型：\n- 线性模型 $\\mathcal{M}_{\\mathrm{L}}$: $y_i = \\alpha_0 + \\alpha_1 x_i + u_i$，\n- 二次模型 $\\mathcal{M}_{\\mathrm{Q}}$: $y_i = \\gamma_0 + \\gamma_1 x_i + \\gamma_2 x_i^2 + v_i$，\n在每个模型中，误差项均独立同分布，服从均值为 $0$、方差未知的正态分布。\n\n您的任务：\n- 对于每个模型，从高斯线性模型下独立高斯误差的联合密度出发，推导最大化对数似然。使用此结果，并根据最大化对数似然和自由参数数量，利用赤池信息准则（Akaike Information Criterion, AIC）和贝叶斯信息准则（Bayesian Information Criterion, BIC）关于最大化对数似然和自由参数数量的标准定义，来计算信息准则。通篇使用自然对数。\n- 通过求解在同方差性假设下使高斯对数似然最大化的参数值，为每个模型实现最大似然估计。您必须将方差参数计为一个自由参数。\n- 对于每个测试用例，分别根据AIC和BIC选择偏好的模型，即选择准则值较小的模型。\n\n实现细节与常量：\n- 对所有测试用例使用以下固定的超参数：$\\beta_0 = 1.0$，$\\beta_1 = 0.4$，$\\mu_x = 3.0$，$\\sigma_x = 0.6$。\n- 不同测试用例中变化的参数是样本量 $n$、二次项系数 $\\beta_2$ 和误差标准差 $\\sigma$。\n- 随机性与可复现性：\n  - 使用基础种子 $s_0 = 20240517$。\n  - 对于索引为 $j \\in \\{0,1,2,3,4\\}$ 的测试用例，将种子设置为 $s_j = s_0 + j$。\n  - 对于每个测试用例，使用种子 $s_j$ 独立地抽取 $x_i \\sim \\mathcal{N}(\\mu_x,\\sigma_x^2)$ 和 $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$。\n- 对于所有与似然相关的计算，使用自然对数，并对每个模型将方差参数视为未知，并从数据中估计。\n\n测试套件：\n- 用例 1：$(n,\\beta_2,\\sigma) = (100,0.15,0.3)$。\n- 用例 2：$(n,\\beta_2,\\sigma) = (80,0.0,0.3)$。\n- 用例 3：$(n,\\beta_2,\\sigma) = (25,0.08,0.35)$。\n- 用例 4：$(n,\\beta_2,\\sigma) = (400,0.03,0.3)$。\n- 用例 5：$(n,\\beta_2,\\sigma) = (150,0.05,0.8)$。\n\n覆盖性设计：\n- 此套件包括一个真实线性情况（$\\beta_2 = 0$），中等和小样本量的明显非线性情况，一个二次项系数虽小但非零的大样本情况，以及一个二次信号可能被噪声淹没的高噪声情况。\n\n要求的输出：\n- 对于按顺序 $j = 1,2,3,4,5$ 的每个测试用例，计算两个编码为整数的决策：\n  - AIC决策：如果偏好 $\\mathcal{M}_{\\mathrm{L}}$，输出 $0$；如果偏好 $\\mathcal{M}_{\\mathrm{Q}}$，输出 $1$。\n  - BIC决策：如果偏好 $\\mathcal{M}_{\\mathrm{L}}$，输出 $0$；如果偏好 $\\mathcal{M}_{\\mathrm{Q}}$，输出 $1$。\n- 您的程序应生成单行输出，其中包含所有决策，形式为方括号括起来的逗号分隔列表，顺序为 $[\\text{AIC}_1,\\text{BIC}_1,\\text{AIC}_2,\\text{BIC}_2,\\text{AIC}_3,\\text{BIC}_3,\\text{AIC}_4,\\text{BIC}_4,\\text{AIC}_5,\\text{BIC}_5]$。每个条目必须是等于 $0$ 或 $1$ 的整数。\n\n角度单位不适用。不需要物理单位。所有对数必须是自然对数。", "solution": "我们从高斯线性模型和信息准则的定义入手。\n\n统计模型与似然：\n- 在一个通用线性模型下，回归量收集在设计矩阵 $X \\in \\mathbb{R}^{n \\times p}$ 中，参数为 $\\theta = (\\beta,\\sigma^2)$（其中 $\\beta \\in \\mathbb{R}^p$ 且 $\\sigma^2 > 0$），观测值为 $y \\in \\mathbb{R}^{n}$，模型为 $y = X \\beta + \\varepsilon$，其中 $\\varepsilon_i \\overset{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,\\sigma^2)$。\n- 给定 $\\theta$ 时 $y$ 的联合密度为\n$$\nf(y \\mid \\theta) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\!\\left( -\\frac{(y_i - x_i^\\top \\beta)^2}{2\\sigma^2} \\right),\n$$\n其中 $x_i^\\top$ 表示 $X$ 的第 $i$ 行。\n- 对数似然为\n$$\n\\ell(\\beta,\\sigma^2; y, X) = -\\frac{n}{2} \\log(2\\pi) - \\frac{n}{2} \\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y_i - x_i^\\top \\beta)^2.\n$$\n\n最大似然估计：\n- 将 $\\ell$ 对 $\\beta$ 求导并将梯度设为零，得到一阶条件\n$$\nX^\\top X \\, \\hat{\\beta} = X^\\top y,\n$$\n其解（假设 $X^\\top X$ 可逆）是普通最小二乘估计量\n$$\n\\hat{\\beta} = (X^\\top X)^{-1} X^\\top y.\n$$\n- 代入 $\\hat{\\beta}$，残差平方和为\n$$\n\\mathrm{RSS} = \\sum_{i=1}^{n} (y_i - x_i^\\top \\hat{\\beta})^2.\n$$\n- 将 $\\ell$ 对 $\\sigma^2$ 求导并设为零，得到\n$$\n\\frac{\\partial \\ell}{\\partial \\sigma^2} = -\\frac{n}{2\\sigma^2} + \\frac{1}{2(\\sigma^2)^2} \\mathrm{RSS} = 0 \\quad \\Rightarrow \\quad \\hat{\\sigma}^2 = \\frac{\\mathrm{RSS}}{n}.\n$$\n- 则最大化对数似然为\n$$\n\\ell(\\hat{\\beta},\\hat{\\sigma}^2; y, X) = -\\frac{n}{2} \\left[ \\log(2\\pi) + 1 + \\log\\!\\left(\\frac{\\mathrm{RSS}}{n}\\right) \\right],\n$$\n这是通过将 $\\hat{\\sigma}^2 = \\mathrm{RSS}/n$ 代入 $\\ell$ 得到的。\n\n信息准则：\n- 赤池信息准则（Akaike Information Criterion, AIC）是根据最大化对数似然和自由参数的数量定义的。用 $p$ 表示回归系数的数量，并包括方差参数，因此自由参数的总数为 $k = p + 1$。对于带截距和一个斜率的线性模型（$p = 2$），$k_{\\mathrm{L}} = 3$。对于带截距和两个斜率的二次模型（$p = 3$），$k_{\\mathrm{Q}} = 4$。设最大化对数似然为 $\\ell(\\hat{\\theta})$，则 AIC 为\n$$\n\\mathrm{AIC} = 2k - 2 \\, \\ell(\\hat{\\theta}).\n$$\n- 贝叶斯信息准则（Bayesian Information Criterion, BIC），也称为 Schwarz 准则，定义为\n$$\n\\mathrm{BIC} = (\\log n) \\, k - 2 \\, \\ell(\\hat{\\theta}).\n$$\n- 对于这两种准则，值越小表示模型越优。\n\n每个测试用例的算法步骤：\n- 给定输入 $(n,\\beta_2,\\sigma)$ 和固定的 $(\\beta_0,\\beta_1,\\mu_x,\\sigma_x)$，使用指定的种子独立生成 $x_i \\sim \\mathcal{N}(\\mu_x,\\sigma_x^2)$ 和 $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$。构造 $y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 x_i^2 + \\varepsilon_i$。\n- 构建设计矩阵：\n  - 线性模型：$X_{\\mathrm{L}} = [\\mathbf{1}, x] \\in \\mathbb{R}^{n \\times 2}$，\n  - 二次模型：$X_{\\mathrm{Q}} = [\\mathbf{1}, x, x^{\\circ 2}] \\in \\mathbb{R}^{n \\times 3}$，其中 $x^{\\circ 2}$ 表示逐元素平方。\n- 对于每个模型，通过最小二乘法计算 $\\hat{\\beta}$，计算 $\\mathrm{RSS}$，计算 $\\hat{\\sigma}^2 = \\mathrm{RSS}/n$，然后使用以下公式计算最大化对数似然\n$$\n\\ell(\\hat{\\theta}) = -\\frac{n}{2} \\left[ \\log(2\\pi) + 1 + \\log\\!\\left(\\frac{\\mathrm{RSS}}{n}\\right) \\right].\n$$\n- 使用上述定义以及 $k_{\\mathrm{L}} = 3$ 和 $k_{\\mathrm{Q}} = 4$ 计算 $\\mathrm{AIC}$ 和 $\\mathrm{BIC}$，并使用自然对数。\n- 选择准则值较小的模型。将决策编码为：线性模型 $\\mathcal{M}_{\\mathrm{L}}$ 为 $0$，二次模型 $\\mathcal{M}_{\\mathrm{Q}}$ 为 $1$。\n\n对所提供套件的定性预期：\n- 在 $\\beta_2 = 0$ 的真实线性情况下，AIC 和 BIC 通常都会偏好 $\\mathcal{M}_{\\mathrm{L}}$。\n- 当 $\\beta_2$ 中等且 $n$ 不太小時，两种准则通常会偏好 $\\mathcal{M}_{\\mathrm{Q}}$。\n- 对于小样本 $n$ 和弱的二次信号，AIC 可能会偏好 $\\mathcal{M}_{\\mathrm{Q}}$，而 BIC 由于其更强的、与样本量相关的惩罚项，可能会偏好 $\\mathcal{M}_{\\mathrm{L}}$。\n- 对于大样本 $n$ 和一个虽小但非零的 $\\beta_2$，两种准则都倾向于检测到非线性并选择 $\\mathcal{M}_{\\mathrm{Q}}$。\n- 在高噪声情况下，由于信噪比有限，这些准则可能会偏好 $\\mathcal{M}_{\\mathrm{L}}$。\n\n程序将为五个测试用例实现这些步骤，对 $j \\in \\{0,1,2,3,4\\}$ 使用种子 $s_j = 20240517 + j$，并将决策以单一列表 $[\\text{AIC}_1,\\text{BIC}_1,\\dots,\\text{AIC}_5,\\text{BIC}_5]$ 的形式打印出来。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef mle_loglikelihood_and_ic(X, y, k):\n    \"\"\"\n    Compute MLE maximized log-likelihood under Gaussian errors for linear model y = X b + e\n    and the AIC/BIC given number of free parameters k (including variance).\n    \"\"\"\n    n = y.shape[0]\n    # Solve least squares for beta_hat\n    beta_hat, residuals, rank, s = np.linalg.lstsq(X, y, rcond=None)\n    # Compute residuals explicitly for numerical robustness\n    resid = y - X @ beta_hat\n    RSS = float(np.dot(resid, resid))\n    # Guard against degenerate RSS\n    RSS = max(RSS, 1e-12)\n    # MLE sigma^2 = RSS / n\n    sigma2_hat = RSS / n\n    # Maximized log-likelihood under Gaussian errors:\n    # ll = -n/2 * [log(2*pi) + 1 + log(RSS/n)]\n    ll = -0.5 * n * (np.log(2.0 * np.pi) + 1.0 + np.log(RSS / n))\n    # Information criteria\n    aic = 2.0 * k - 2.0 * ll\n    bic = np.log(n) * k - 2.0 * ll\n    return ll, aic, bic\n\ndef simulate_case(n, beta2, sigma, seed, beta0=1.0, beta1=0.4, mu_x=3.0, sig_x=0.6):\n    rng = np.random.default_rng(seed)\n    x = rng.normal(loc=mu_x, scale=sig_x, size=n)\n    eps = rng.normal(loc=0.0, scale=sigma, size=n)\n    y = beta0 + beta1 * x + beta2 * (x ** 2) + eps\n    return x, y\n\ndef select_model(x, y):\n    n = y.shape[0]\n    # Design matrices\n    X_lin = np.column_stack((np.ones(n), x))\n    X_quad = np.column_stack((np.ones(n), x, x**2))\n    # Number of free parameters includes variance\n    k_lin = 2 + 1  # intercept + slope + variance\n    k_quad = 3 + 1  # intercept + 2 slopes + variance\n    # Compute log-likelihood and ICs\n    ll_L, aic_L, bic_L = mle_loglikelihood_and_ic(X_lin, y, k_lin)\n    ll_Q, aic_Q, bic_Q = mle_loglikelihood_and_ic(X_quad, y, k_quad)\n    # Decisions: 0 for linear, 1 for quadratic\n    aic_choice = 0 if aic_L < aic_Q else 1\n    bic_choice = 0 if bic_L < bic_Q else 1\n    return aic_choice, bic_choice\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (n, beta2, sigma)\n    test_cases = [\n        (100, 0.15, 0.3),\n        (80, 0.0, 0.3),\n        (25, 0.08, 0.35),\n        (400, 0.03, 0.3),\n        (150, 0.05, 0.8),\n    ]\n    base_seed = 20240517\n\n    results = []\n    for j, (n, beta2, sigma) in enumerate(test_cases):\n        seed = base_seed + j\n        x, y = simulate_case(n=n, beta2=beta2, sigma=sigma, seed=seed)\n        aic_choice, bic_choice = select_model(x, y)\n        results.append(int(aic_choice))\n        results.append(int(bic_choice))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"}, {"introduction": "金融和经济时间序列数据常常会因为政策变动、技术冲击或市场危机而发生“结构性突变”。这个高级练习要求你解决一个更具挑战性的任务：在一个合成的时间序列中识别未知的结构突变点。通过系统地测试所有可能的突变点并为每个点建立一个模型，你将应用 AIC 和 BIC 来确定最佳模型，从而找出最可能发生变化的时间点，或判断数据中是否根本不存在突变 [@problem_id:2410416]。", "id": "2410416", "problem": "给定一个单变量时间序列，该序列由一个线性模型生成，在未知的时间指数处，该模型的回归函数可能存在一个结构性断点。设时间指数为 $t \\in \\{1,2,\\dots,T\\}$。数据生成过程为\n$$\ny_t =\n\\begin{cases}\n\\alpha_1 + \\beta_1 t + \\varepsilon_t, & \\text{若 } t \\le \\tau_0, \\\\\n\\alpha_2 + \\beta_2 t + \\varepsilon_t, & \\text{若 } t > \\tau_0,\n\\end{cases}\n$$\n其中 $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$ 是独立同分布的高斯扰动项。真实断点指数为 $\\tau_0 \\in \\{0,1,2,\\dots,T-1\\}$，其中 $\\tau_0=0$ 表示不存在结构性断点，数据对所有 $t$ 均遵循单一线性模型 $y_t=\\alpha+\\beta t+\\varepsilon_t$。\n\n对于任何候选分割指数 $\\tau \\in \\{1,2,\\dots,T-1\\}$，定义分段线性模型\n$$\ny_t =\n\\begin{cases}\n\\tilde{\\alpha}_1 + \\tilde{\\beta}_1 t + u_t, & \\text{若 } t \\le \\tau, \\\\\n\\tilde{\\alpha}_2 + \\tilde{\\beta}_2 t + u_t, & \\text{若 } t > \\tau,\n\\end{cases}\n$$\n其中 $u_t \\sim \\mathcal{N}(0,\\tilde{\\sigma}^2)$ 是独立同分布的。该模型的参数向量有 $k_{\\text{br}}=5$ 个自由参数（两个截距、两个斜率和一个方差）。无断点模型是 $y_t=\\tilde{\\alpha}+\\tilde{\\beta} t + u_t$，有 $k_{\\text{nb}}=3$ 个自由参数（一个截距、一个斜率和一个方差）。对于任何通过普通最小二乘法 (OLS) 拟合的模型，令 $\\widehat{\\text{SSR}}$ 为其在所有 $T$ 个观测值上的残差平方和。在高斯扰动假设下，最大化对数似然为\n$$\n\\ell = -\\frac{T}{2}\\left[\\log(2\\pi) + 1 + \\log\\left(\\frac{\\widehat{\\text{SSR}}}{T}\\right)\\right].\n$$\n定义 Akaike 信息准则 (AIC) 和 Bayesian 信息准则 (BIC) 如下\n$$\n\\text{AIC} = 2k - 2\\ell, \\quad \\text{BIC} = k \\log(T) - 2\\ell,\n$$\n其中 $k$ 是模型的自由参数数量。\n\n任务：对于下方的每个测试用例，使用提供的随机种子以保证可复现性，从指定的数据生成过程中模拟一次实现 $\\{(t,y_t)\\}_{t=1}^T$。考虑候选分割指数 $\\tau$ 的集合，该集合被限制在区间 $[\\lceil \\lambda_{\\min} T \\rceil, \\lfloor \\lambda_{\\max} T \\rfloor]$ 内，并强制分割点两侧的每个分段至少有 $m_{\\min}=5$ 个观测值。此外，将无断点模型也作为一个候选模型（在输出中用 $\\tau=0$ 表示此候选模型）。对于每个候选模型，拟合相应的 OLS 模型，计算 $\\widehat{\\text{SSR}}$，评估 $\\ell$、$\\text{AIC}$ 和 $\\text{BIC}$，并选择在所有候选模型中使每个准则最小化的 $\\tau$。将 AIC 和 BIC 选择的断点指数报告为整数，其中 $\\tau=0$ 表示选择了无断点模型。\n\n正确性评估：对于给定的测试用例，其真实断点指数为 $\\tau_0$，容差为 $d$，所选断点指数 $\\widehat{\\tau}$ 的正确性定义如下。如果 $\\tau_0>0$，则当 $|\\widehat{\\tau}-\\tau_0|\\le d$ 时正确性为 $\\text{True}$，否则为 $\\text{False}$。如果 $\\tau_0=0$，则当 $\\widehat{\\tau}=0$ 时正确性为 $\\text{True}$，否则为 $\\text{False}$。\n\n角度单位不适用。不涉及物理单位。所有输出必须是指定的整数或布尔值。\n\n测试套件：对于每一行，参数为 $(T,\\tau_0,\\alpha_1,\\beta_1,\\alpha_2,\\beta_2,\\sigma,\\text{seed},\\lambda_{\\min},\\lambda_{\\max},d)$。\n\n- 用例 $1$：$(200,100,0.0,0.2,0.0,0.8,0.5,123,0.15,0.85,2)$。\n- 用例 $2$：$(200,100,0.0,0.2,0.0,0.22,2.0,456,0.15,0.85,5)$。\n- 用例 $3$：$(60,9,1.0,0.1,3.0,0.1,0.3,789,0.15,0.85,1)$。\n- 用例 $4$：$(150,0,2.0,0.3,2.0,0.3,1.0,321,0.15,0.85,0)$。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。对于每个测试用例，输出一个列表 $[\\widehat{\\tau}_{\\text{AIC}},\\widehat{\\tau}_{\\text{BIC}},\\text{correct}_{\\text{AIC}},\\text{correct}_{\\text{BIC}}]$，其中 $\\widehat{\\tau}_{\\text{AIC}}$ 和 $\\widehat{\\tau}_{\\text{BIC}}$ 是整数（$0$ 表示选择无断点模型），而 $\\text{correct}_{\\text{AIC}}$ 和 $\\text{correct}_{\\text{BIC}}$ 是布尔值。因此，打印的单行必须类似于\n$$\n\\big[ [\\cdot,\\cdot,\\cdot,\\cdot], [\\cdot,\\cdot,\\cdot,\\cdot], [\\cdot,\\cdot,\\cdot,\\cdot], [\\cdot,\\cdot,\\cdot,\\cdot] \\big],\n$$\n其中点由四个测试用例按顺序计算出的值替换。", "solution": "所提出的问题是使用 Akaike 信息准则 (AIC) 和 Bayesian 信息准则 (BIC) 来识别单变量时间序列中的潜在结构性断点。该问题定义明确，其科学基础是标准的计量经济学和统计学理论，并包含了获得唯一解所需的所有信息。因此，该问题被认为是有效的。我们着手进行求解。\n\n任务的核心是模型选择。对于给定的时间序列，我们必须评估一组候选模型，并根据两个不同的准则选择最能描述数据的一个。候选模型包括一个单一线性趋势模型（“无断点”模型）和一系列分段线性趋势模型，每个模型由不同的断点 $\\tau$ 定义。\n\n我们首先将该过程形式化。\n\n**1. 数据生成**\n\n对于每个测试用例，我们根据指定的数据生成过程 (DGP) 模拟一个长度为 $T$ 的时间序列 $\\{y_t\\}_{t=1}^T$：\n$$\ny_t =\n\\begin{cases}\n\\alpha_1 + \\beta_1 t + \\varepsilon_t, & \\text{if } t \\le \\tau_0, \\\\\n\\alpha_2 + \\beta_2 t + \\varepsilon_t, & \\text{if } t > \\tau_0,\n\\end{cases}\n$$\n其中 $\\varepsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$ 是独立同分布的正态随机变量。时间指数 $t$ 是从 $1$ 到 $T$ 的整数序列。为每个用例提供了特定的随机种子，以确保生成的噪声项 $\\varepsilon_t$ 的可复现性。$\\tau_0=0$ 的情况表示不存在结构性断点，数据由单一线性模型 $y_t = \\alpha_1 + \\beta_1 t + \\varepsilon_t$ 为所有 $t$ 生成。\n\n**2. 候选模型与估计**\n\n我们必须评估一组候选模型。该集合包括无断点模型和所有有效的单断点模型。\n\n**a) 无断点模型 ($\\tau=0$)**\n\n该模型是基于整个样本的简单线性回归：\n$$\ny_t = \\tilde{\\alpha} + \\tilde{\\beta} t + u_t, \\quad t=1, \\dots, T\n$$\n参数 $(\\tilde{\\alpha}, \\tilde{\\beta})$ 通过最小化残差平方和 (SSR) 使用普通最小二乘法 (OLS) 进行估计。令观测向量为 $\\mathbf{y} = [y_1, \\dots, y_T]^T$，设计矩阵为大小为 $T \\times 2$ 的 $\\mathbf{X}_{\\text{nb}}$：\n$$\n\\mathbf{X}_{\\text{nb}} = \\begin{pmatrix} 1 & 1 \\\\ 1 & 2 \\\\ \\vdots & \\vdots \\\\ 1 & T \\end{pmatrix}\n$$\n系数向量 $\\mathbf{b} = [\\tilde{\\alpha}, \\tilde{\\beta}]^T$ 的 OLS 估计量为 $\\hat{\\mathbf{b}} = (\\mathbf{X}_{\\text{nb}}^T \\mathbf{X}_{\\text{nb}})^{-1} \\mathbf{X}_{\\text{nb}}^T \\mathbf{y}$。由此产生的残差平方和为 $\\widehat{\\text{SSR}}_{\\text{nb}} = (\\mathbf{y} - \\mathbf{X}_{\\text{nb}}\\hat{\\mathbf{b}})^T (\\mathbf{y} - \\mathbf{X}_{\\text{nb}}\\hat{\\mathbf{b}})$。该模型有 $k_{\\text{nb}}=3$ 个自由参数：$\\tilde{\\alpha}$、$\\tilde{\\beta}$ 和扰动项的方差 $\\tilde{\\sigma}^2$。\n\n**b) 单断点模型 ($\\tau > 0$)**\n\n对于每个候选断点 $\\tau$，模型定义为：\n$$\ny_t =\n\\begin{cases}\n\\tilde{\\alpha}_1 + \\tilde{\\beta}_1 t + u_t, & \\text{if } t \\le \\tau, \\\\\n\\tilde{\\alpha}_2 + \\tilde{\\beta}_2 t + u_t, & \\text{if } t > \\tau,\n\\end{cases}\n$$\n这等同于在两个子样本上拟合两个独立的线性回归：一个针对 $t \\in \\{1, \\dots, \\tau\\}$，另一个针对 $t \\in \\{\\tau+1, \\dots, T\\}$。\n对于第一段，我们有 $\\mathbf{y}_1 = [y_1, \\dots, y_\\tau]^T$ 和设计矩阵 $\\mathbf{X}_1(\\tau)$。\n对于第二段，我们有 $\\mathbf{y}_2 = [y_{\\tau+1}, \\dots, y_T]^T$ 和设计矩阵 $\\mathbf{X}_2(\\tau)$。\n令每个分段的 SSR 分别为 $\\widehat{\\text{SSR}}_1(\\tau)$ 和 $\\widehat{\\text{SSR}}_2(\\tau)$。在 $\\tau$ 处有断点的模型的总残差平方和是两者之和：$\\widehat{\\text{SSR}}_{\\text{br}}(\\tau) = \\widehat{\\text{SSR}}_1(\\tau) + \\widehat{\\text{SSR}}_2(\\tau)$。该模型有 $k_{\\text{br}}=5$ 个自由参数：两个截距 $(\\tilde{\\alpha}_1, \\tilde{\\alpha}_2)$、两个斜率 $(\\tilde{\\beta}_1, \\tilde{\\beta}_2)$ 和一个共同方差 $\\tilde{\\sigma}^2$。\n\n候选断点 $\\tau$ 的集合是受限的。指数 $\\tau$ 必须在区间 $[\\lceil \\lambda_{\\min} T \\rceil, \\lfloor \\lambda_{\\max} T \\rfloor]$ 内。此外，每个回归分段必须至少包含 $m_{\\min}$ 个观测值。这施加了约束条件 $\\tau \\ge m_{\\min}$ 和 $T-\\tau \\ge m_{\\min}$，等价于 $\\tau \\le T - m_{\\min}$。因此，$\\tau$ 的最终搜索范围是：\n$$\n\\tau \\in \\left[ \\max(\\lceil \\lambda_{\\min} T \\rceil, m_{\\min}), \\min(\\lfloor \\lambda_{\\max} T \\rfloor, T - m_{\\min}) \\right]\n$$\n\n**3. 模型选择准则**\n\n对于每个候选模型（由 $\\tau \\in \\{0\\} \\cup \\{\\text{有效断点指数}\\}$ 标识），我们计算其 AIC 和 BIC 值。首先，我们使用模型在所有 $T$ 个观测值上的 $\\widehat{\\text{SSR}}$ 来计算最大化对数似然 $\\ell$：\n$$\n\\ell = -\\frac{T}{2}\\left[\\log(2\\pi) + 1 + \\log\\left(\\frac{\\widehat{\\text{SSR}}}{T}\\right)\\right]\n$$\n然后，AIC 和 BIC 计算如下：\n$$\n\\text{AIC} = 2k - 2\\ell\n$$\n$$\n\\text{BIC} = k \\log(T) - 2\\ell\n$$\n其中 $k$ 是模型的参数数量（$k_{\\text{nb}}=3$ 或 $k_{\\text{br}}=5$）。\n\n通过找到使相应准则最小化的模型来选择最优断点。\n$$\n\\widehat{\\tau}_{\\text{AIC}} = \\underset{\\tau \\in \\text{candidates}}{\\operatorname{argmin}} \\text{ AIC}(\\tau)\n$$\n$$\n\\widehat{\\tau}_{\\text{BIC}} = \\underset{\\tau \\in \\text{candidates}}{\\operatorname{argmin}} \\text{ BIC}(\\tau)\n$$\n\n**4. 正确性评估**\n\n最后，根据真实断点指数 $\\tau_0$ 评估所选断点指数 $\\widehat{\\tau}_{\\text{AIC}}$ 和 $\\widehat{\\tau}_{\\text{BIC}}$ 的正确性。\n- 如果 $\\tau_0 > 0$（存在断点），则当 $|\\widehat{\\tau} - \\tau_0| \\le d$ 时，估计值 $\\widehat{\\tau}$ 是正确的，其中 $d$ 是给定的容差。\n- 如果 $\\tau_0 = 0$（不存在断点），则仅当 $\\widehat{\\tau} = 0$ 时，估计是正确的。\n\n对于提供的每个测试用例，都应执行这整个过程。最终输出必须结构化为列表的列表，其中每个内部列表包含一个测试用例的四个指定结果：$[\\widehat{\\tau}_{\\text{AIC}}, \\widehat{\\tau}_{\\text{BIC}}, \\text{correct}_{\\text{AIC}}, \\text{correct}_{\\text{BIC}}]$。", "answer": "```python\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Solves the structural break detection problem for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        # (T, tau_0, alpha_1, beta_1, alpha_2, beta_2, sigma, seed, lambda_min, lambda_max, d)\n        (200, 100, 0.0, 0.2, 0.0, 0.8, 0.5, 123, 0.15, 0.85, 2),\n        (200, 100, 0.0, 0.2, 0.0, 0.22, 2.0, 456, 0.15, 0.85, 5),\n        (60, 9, 1.0, 0.1, 3.0, 0.1, 0.3, 789, 0.15, 0.85, 1),\n        (150, 0, 2.0, 0.3, 2.0, 0.3, 1.0, 321, 0.15, 0.85, 0),\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        T, tau_0, alpha_1, beta_1, alpha_2, beta_2, sigma, seed, lambda_min, lambda_max, d = case\n        \n        # for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # 1. Data Generation\n        t_all = np.arange(1, T + 1)\n        y = np.zeros(T)\n        errors = rng.normal(0, sigma, T)\n\n        if tau_0 == 0:\n            y = alpha_1 + beta_1 * t_all + errors\n        else:\n            mask_1 = t_all <= tau_0\n            mask_2 = t_all > tau_0\n            y[mask_1] = alpha_1 + beta_1 * t_all[mask_1] + errors[mask_1]\n            y[mask_2] = alpha_2 + beta_2 * t_all[mask_2] + errors[mask_2]\n\n        candidate_results = []\n        \n        # 2. Candidate Models Evaluation\n        \n        # Helper function for OLS to get SSR\n        def get_ssr(y_seg, t_seg):\n            if len(y_seg) < 2: return np.inf\n            X_seg = np.vstack([np.ones_like(t_seg), t_seg]).T\n            # np.linalg.lstsq returns sum of squared residuals as the second element\n            ssr = np.linalg.lstsq(X_seg, y_seg, rcond=None)[1]\n            if not ssr: # empty if perfect fit\n                return 0.0\n            return ssr[0]\n\n        # Helper function for Info Criteria calculation\n        def get_criteria(ssr, k, T_val):\n            if ssr <= 0: # Avoid log(0)\n                # This would imply a perfect fit, log-likelihood is effectively infinite\n                return np.inf, np.inf\n            logL = -T_val / 2 * (np.log(2 * np.pi) + 1 + np.log(ssr / T_val))\n            aic = 2 * k - 2 * logL\n            bic = k * np.log(T_val) - 2 * logL\n            return aic, bic\n\n        # a) No-Break Model (tau=0)\n        k_nb = 3\n        ssr_nb = get_ssr(y, t_all)\n        aic_nb, bic_nb = get_criteria(ssr_nb, k_nb, T)\n        candidate_results.append({'tau': 0, 'aic': aic_nb, 'bic': bic_nb})\n        \n        # b) Single-Break Models (tau > 0)\n        k_br = 5\n        m_min = 5\n        tau_min_search = max(math.ceil(lambda_min * T), m_min)\n        tau_max_search = min(math.floor(lambda_max * T), T - m_min)\n\n        for tau in range(tau_min_search, tau_max_search + 1):\n            y1, t1 = y[:tau], t_all[:tau]\n            y2, t2 = y[tau:], t_all[tau:]\n            \n            ssr1 = get_ssr(y1, t1)\n            ssr2 = get_ssr(y2, t2)\n            \n            ssr_br = ssr1 + ssr2\n            aic_br, bic_br = get_criteria(ssr_br, k_br, T)\n            candidate_results.append({'tau': tau, 'aic': aic_br, 'bic': bic_br})\n\n        # 3. Model Selection\n        best_aic_model = min(candidate_results, key=lambda x: x['aic'])\n        best_bic_model = min(candidate_results, key=lambda x: x['bic'])\n        \n        tau_hat_aic = best_aic_model['tau']\n        tau_hat_bic = best_bic_model['tau']\n\n        # 4. Correctness Evaluation\n        def check_correctness(tau_hat, tau_true, d_tol):\n            if tau_true == 0:\n                return tau_hat == 0\n            else:\n                return abs(tau_hat - tau_true) <= d_tol\n\n        correct_aic = check_correctness(tau_hat_aic, tau_0, d)\n        correct_bic = check_correctness(tau_hat_bic, tau_0, d)\n        \n        all_results.append([tau_hat_aic, tau_hat_bic, bool(correct_aic), bool(correct_bic)])\n\n    # Final print statement in the exact required format.\n    # Convert manually to avoid spaces introduced by default str(list)\n    result_str = '[' + ','.join(f\"[{r[0]},{r[1]},{r[2]},{r[3]}]\" for r in all_results) + ']'\n    print(result_str.replace('True', 'true').replace('False', 'false'))\n\nsolve()\n```"}]}