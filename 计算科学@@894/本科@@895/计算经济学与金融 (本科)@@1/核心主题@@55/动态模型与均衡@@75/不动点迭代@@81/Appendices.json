{"hands_on_practices": [{"introduction": "理论是实践的基石。在深入研究不动点迭代的计算实现之前，理解其收敛速度的决定因素至关重要。本练习将通过一个具体的计算任务，帮助你掌握如何评估和比较不同迭代格式的效率。通过直接计算两个不同迭代函数 $g(x)$ 的收敛率，你将学会如何从理论上判断哪种迭代格式能更快地逼近问题的解，这为后续在经济和金融建模中选择或设计高效算法奠定了坚实的基础 [@problem_id:2214069]。", "id": "2214069", "problem": "方程 $f(x) = e^x - 2x - 1 = 0$ 在 $x=0$ 处有一个平凡根，并有一个唯一的正根，我们记为 $\\alpha$。为了对此正根 $\\alpha$ 进行数值近似，提出了两种不同的不动点迭代方案。\n\n方案 A 由迭代函数 $g_A(x) = \\frac{e^x - 1}{2}$ 定义。\n方案 B 由迭代函数 $g_B(x) = \\ln(2x+1)$ 定义。\n\n一个不动点迭代方法的局部行为，即其是收敛于根还是发散于根，由其渐进速率常数来表征。对于一个迭代函数 $g(x)$ 和一个根 $\\alpha$，该常数由 $C = |g'(\\alpha)|$ 给出。$C < 1$ 的值表示收敛，而 $C > 1$ 表示发散。\n\n设方案 A 和方案 B 在根 $\\alpha$ 处的速率常数分别为 $C_A = |g'_A(\\alpha)|$ 和 $C_B = |g'_B(\\alpha)|$。\n\n已知正根为 $\\alpha \\approx 1.256431$，计算比率 $R = \\frac{C_A}{C_B}$ 的数值。\n\n将最终答案四舍五入到四位有效数字。", "solution": "给定 $f(x)=\\exp(x)-2x-1$，其正根为 $\\alpha$。两种不动点迭代由 $g_{A}(x)=\\frac{\\exp(x)-1}{2}$ 和 $g_{B}(x)=\\ln(2x+1)$ 定义。对于收敛到 $\\alpha$ 的不动点迭代 $x_{n+1}=g(x_{n})$，其渐进速率常数为 $C=|g'(\\alpha)|$。\n\n计算导数：\n$$\ng_{A}'(x)=\\frac{1}{2}\\exp(x), \\quad g_{B}'(x)=\\frac{2}{2x+1}.\n$$\n因此，\n$$\nC_{A}=|g_{A}'(\\alpha)|=\\frac{1}{2}\\exp(\\alpha), \\quad C_{B}=|g_{B}'(\\alpha)|=\\frac{2}{2\\alpha+1}.\n$$\n比率为\n$$\nR=\\frac{C_{A}}{C_{B}}=\\frac{\\frac{1}{2}\\exp(\\alpha)}{\\frac{2}{2\\alpha+1}}=\\frac{\\exp(\\alpha)\\,(2\\alpha+1)}{4}.\n$$\n因为 $\\alpha$ 满足 $f(\\alpha)=0$，我们有 $\\exp(\\alpha)-2\\alpha-1=0$，因此 $\\exp(\\alpha)=2\\alpha+1$。代入得，\n$$\nR=\\frac{(2\\alpha+1)^{2}}{4}.\n$$\n使用 $\\alpha\\approx 1.256431$，\n$$\n2\\alpha+1=2(1.256431)+1=3.512862,\n$$\n$$\n(2\\alpha+1)^{2}=(3.512862)^{2}=12.340199431044,\n$$\n$$\nR\\approx \\frac{12.340199431044}{4}=3.085049857761.\n$$\n四舍五入到四位有效数字，得到 $R\\approx 3.085$。", "answer": "$$\\boxed{3.085}$$"}, {"introduction": "在掌握了收敛率的理论分析后，下一步便是将理论付诸实践。本练习要求你编写代码，实现并比较两种用于求解平方根的迭代方法：一种是特殊构造的不动点迭代，另一种则是大名鼎鼎的牛顿法。通过在不同参数下运行你的程序，你将亲眼见证并量化二次收敛（如牛顿法）相比于线性收敛的巨大优势，深刻理解为何某些算法在实际应用中备受青睐 [@problem_id:2393795]。", "id": "2393795", "problem": "考虑非线性方程 $f(x;A)=x^2-A=0$，其中参数 $A>0$。对于每个参数对 $(A,x_0)$，定义两个从 $x_0$ 开始的迭代序列 $\\{x_k^{(F)}\\}_{k\\geq 0}$ 和 $\\{x_k^{(N)}\\}_{k\\geq 0}$ 如下：\n1. 序列 $F$：对于 $k\\geq 0$，\n$$\nx_{k+1}^{(F)} \\equiv x_k^{(F)} - \\lambda(A)\\,\\big((x_k^{(F)})^2 - A\\big),\n$$\n其中 $\\lambda(A)\\equiv \\dfrac{1}{2\\sqrt{A}}$。\n2. 序列 $N$：对于 $k\\geq 0$ 且 $x_k^{(N)}\\neq 0$，\n$$\nx_{k+1}^{(N)} \\equiv x_k^{(N)} - \\dfrac{(x_k^{(N)})^2 - A}{2\\,x_k^{(N)}}.\n$$\n\n对于每个序列和每个测试用例，迭代直至残差满足\n$$\n\\left| (x_k)^2 - A \\right| \\leq \\varepsilon,\n$$\n其中容差 $\\varepsilon = 10^{-12}$，或直至迭代次数超过 $N_{\\max}=10^5$。报告每个序列和每个测试用例达到容差所需的迭代次数。如果在 $N_{\\max}$ 次迭代内未能达到容差，则该序列和测试用例报告整数 $N_{\\max}+1$。\n\n测试集：\n- 用例 1：$A=2$，$x_0=1$。\n- 用例 2：$A=10^{-8}$，$x_0=1$。\n- 用例 3：$A=10^{6}$，$x_0=1$。\n- 用例 4：$A=\\dfrac{1}{4}$，$x_0=10^{-2}$。\n- 用例 5：$A=10$，$x_0=20$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果按以下顺序排列\n$$\n\\big[n_F^{(1)},n_N^{(1)},n_F^{(2)},n_N^{(2)},n_F^{(3)},n_N^{(3)},n_F^{(4)},n_N^{(4)},n_F^{(5)},n_N^{(5)}\\big],\n$$\n其中 $n_F^{(i)}$ 和 $n_N^{(i)}$ 分别是序列 $F$ 和序列 $N$ 在测试用例 $i\\in\\{1,2,3,4,5\\}$ 上的迭代次数。所有报告值必须为整数。不涉及物理单位。不涉及角度。请勿使用百分号；不需要任何百分比。", "solution": "提交分析的问题陈述经过严格验证。\n\n**步骤 1：提取的已知条件**\n- 方程：$f(x; A) = x^2 - A = 0$，参数 $A > 0$。\n- 序列 F：$x_{k+1}^{(F)} = x_k^{(F)} - \\lambda(A)\\,\\big((x_k^{(F)})^2 - A\\big)$，其中 $\\lambda(A) = \\frac{1}{2\\sqrt{A}}$。\n- 序列 N：$x_{k+1}^{(N)} = x_k^{(N)} - \\frac{(x_k^{(N)})^2 - A}{2\\,x_k^{(N)}}$，对于 $x_k^{(N)} \\neq 0$。\n- 初始条件：两个序列都从给定的 $x_0$ 开始。\n- 停止准则：当残差 $| (x_k)^2 - A | \\leq \\varepsilon$ 时，序列迭代终止。\n- 容差：$\\varepsilon = 10^{-12}$。\n- 最大迭代次数：$N_{\\max} = 10^5$。\n- 未收敛报告：如果在 $N_{\\max}$ 次迭代内未达到容差，则报告的迭代次数为 $N_{\\max}+1$。\n- 测试用例：\n    1. $(A, x_0) = (2, 1)$\n    2. $(A, x_0) = (10^{-8}, 1)$\n    3. $(A, x_0) = (10^6, 1)$\n    4. $(A, x_0) = (\\frac{1}{4}, 10^{-2})$\n    5. $(A, x_0) = (10, 20)$\n\n**步骤 2：使用提取的已知条件进行验证**\n该问题具有科学依据，是适定 (well-posed) 且客观的。它描述了应用于计算平方根这一特定问题的两种标准求根数值方法。序列 N 正是应用于函数 $f(x) = x^2 - A$ 的 Newton-Raphson 方法。序列 F 是一种不动点迭代法，其松弛参数 $\\lambda(A)$ 经过特殊选择。这两种方法都是数值分析的基石。所有参数、条件和步骤都得到了明确无误的定义。该问题不违反任何基本原理，不是不完整或矛盾的，并且在计算上是可行的。\n\n**步骤 3：结论与行动**\n该问题是 **有效的**。将提供一个解决方案。\n\n**理论分析与求解方法**\n\n该问题要求实现并比较两种迭代方案，以找到 $x^2 - A = 0$ 的正根，即 $x^* = \\sqrt{A}$。两种方案都是形式为 $x_{k+1} = g(x_k)$ 的不动点迭代实例。\n\n**序列 N：Newton 法**\n迭代由下式给出\n$$x_{k+1}^{(N)} = x_k^{(N)} - \\dfrac{(x_k^{(N)})^2 - A}{2\\,x_k^{(N)}} \\equiv g_N(x_k^{(N)}).$$\n这是经典的 Newton-Raphson 方法，应用于函数 $f(x) = x^2 - A$，使用更新公式 $x_{k+1} = x_k - f(x_k)/f'(x_k)$。迭代函数为 $g_N(x) = \\frac{1}{2}(x + \\frac{A}{x})$。\n不动点方法的收敛性由迭代函数的导数决定。\n$$g_N'(x) = \\frac{d}{dx} \\left[ \\frac{1}{2}\\left(x + \\frac{A}{x}\\right) \\right] = \\frac{1}{2}\\left(1 - \\frac{A}{x^2}\\right).$$\n在不动点 $x^* = \\sqrt{A}$ 处，导数为 $g_N'(\\sqrt{A}) = \\frac{1}{2}(1 - \\frac{A}{(\\sqrt{A})^2}) = 0$。由于一阶导数为零，收敛至少是二次的。对于任意初始猜测值 $x_0 > 0$，算术-几何平均值（AM-GM）不等式确保 $x_1 = \\frac{1}{2}(x_0 + \\frac{A}{x_0}) \\ge \\sqrt{x_0 \\cdot \\frac{A}{x_0}} = \\sqrt{A}$。对于 $k \\ge 1$，所有后续迭代值 $x_k$ 都将大于或等于 $\\sqrt{A}$，并单调递减收敛到 $\\sqrt{A}$。因此，对于 $A > 0$ 和 $x_0 > 0$，Newton 法是全局收敛的。\n\n**序列 F：一种特殊的不动点迭代**\n迭代由下式给出\n$$x_{k+1}^{(F)} = x_k^{(F)} - \\frac{1}{2\\sqrt{A}}\\left((x_k^{(F)})^2 - A\\right) \\equiv g_F(x_k^{(F)}).$$\n此迭代的不动点满足 $(x^*)^2 - A = 0$，因此 $x^* = \\pm\\sqrt{A}$。这种方法不寻常，因为迭代参数 $\\lambda(A) = 1/(2\\sqrt{A})$ 需要先验地知道精确解 $\\sqrt{A}$。我们按照规定进行，假设此值是给定的。迭代函数的导数为\n$$g_F'(x) = \\frac{d}{dx} \\left[ x - \\frac{1}{2\\sqrt{A}}(x^2 - A) \\right] = 1 - \\frac{x}{\\sqrt{A}}.$$\n在正不动点 $x^* = \\sqrt{A}$ 处，我们有 $g_F'(\\sqrt{A}) = 1 - \\frac{\\sqrt{A}}{\\sqrt{A}} = 0$。这也意味着至少是二次收敛。然而，与 Newton 法不同，其收敛不是全局的。不动点迭代的局部收敛条件是 $|g'(x)| < 1$。对于序列 F，这意味着\n$$|1 - x/\\sqrt{A}| < 1 \\implies -1 < 1 - x/\\sqrt{A} < 1 \\implies -2 < -x/\\sqrt{A} < 0 \\implies 0 < x/\\sqrt{A} < 2.$$\n因此，仅当迭代值 $x_k$ 位于区间 $(0, 2\\sqrt{A})$ 内时，序列 F 才保证收敛到 $\\sqrt{A}$。如果初始猜测值 $x_0$ 落在此范围之外，则该序列预计会发散。\n\n**数值实现**\n为每个序列和每个测试用例 $(A, x_0)$ 实现了一个数值程序。迭代次数 $k$ 初始化为 0。将残差 $|(x_k)^2 - A|$ 与容差 $\\varepsilon = 10^{-12}$ 进行比较。\n1.  初始化 $k=0$ 并将当前迭代值设为 $x_0$。\n2.  检查是否满足 $|x_0^2 - A| \\le \\varepsilon$。如果满足，则过程终止并返回 $k=0$。\n3.  如果不满足，则运行一个从 $k=1$ 到 $N_{\\max}$ 的循环。在循环的每一步中，使用序列 F 或序列 N 的相应公式计算下一个迭代值 $x_k$。\n4.  然后检查残差 $|x_k^2 - A|$。如果它满足容差，则循环终止并返回当前迭代次数 $k$。\n5.  如果循环完成所有 $N_{\\max}$ 次迭代仍未满足容差，则返回值 $N_{\\max} + 1$，表示未在允许的迭代次数内收敛。\n所有计算均使用标准双精度浮点运算执行。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the given problem by implementing and comparing two iterative schemes\n    for finding the square root of a number.\n    \"\"\"\n    # Define constants from the problem statement.\n    EPSILON = 1e-12\n    N_MAX = 100000\n\n    def solve_f(A, x0):\n        \"\"\"\n        Calculates sqrt(A) using Sequence F (specialized fixed-point iteration).\n        \n        Args:\n            A (float): The parameter A > 0.\n            x0 (float): The initial guess.\n\n        Returns:\n            int: The number of iterations required for convergence, or N_MAX + 1.\n        \"\"\"\n        x = float(x0)\n        A_f = float(A)\n        \n        # Pre-calculate lambda(A). This requires the true sqrt(A).\n        lambda_A = 1.0 / (2.0 * np.sqrt(A_f))\n\n        # Check initial guess (k=0 iterations).\n        if abs(x**2 - A_f) <= EPSILON:\n            return 0\n\n        for k in range(1, N_MAX + 1):\n            x = x - lambda_A * (x**2 - A_f)\n            if abs(x**2 - A_f) <= EPSILON:\n                return k\n        \n        return N_MAX + 1\n\n    def solve_n(A, x0):\n        \"\"\"\n        Calculates sqrt(A) using Sequence N (Newton's method).\n        \n        Args:\n            A (float): The parameter A > 0.\n            x0 (float): The initial guess.\n\n        Returns:\n            int: The number of iterations required for convergence, or N_MAX + 1.\n        \"\"\"\n        x = float(x0)\n        A_f = float(A)\n\n        # Check initial guess (k=0 iterations).\n        if abs(x**2 - A_f) <= EPSILON:\n            return 0\n            \n        for k in range(1, N_MAX + 1):\n            # Division by zero is a potential issue for Newton's method in general,\n            # but will not occur for this problem's test cases (x0 > 0, A > 0).\n            if x == 0.0:\n                return N_MAX + 1\n            x = x - (x**2 - A_f) / (2.0 * x)\n            if abs(x**2 - A_f) <= EPSILON:\n                return k\n        \n        return N_MAX + 1\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (A, x0)\n        (2, 1),\n        (1e-8, 1),\n        (1e6, 1),\n        (1/4, 1e-2),\n        (10, 20)\n    ]\n\n    results = []\n    for A_val, x0_val in test_cases:\n        n_f = solve_f(A_val, x0_val)\n        n_n = solve_n(A_val, x0_val)\n        results.extend([n_f, n_n])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}, {"introduction": "在经济和金融模型中，我们常常会遇到收敛缓慢的迭代过程，尤其是在贴现因子 $\\beta$ 接近 $1$ 的情况下。面对这种情况，我们该如何提升计算效率呢？本练习将向你介绍一种强大的技术——艾特肯（Aitken）$\\Delta^2$ 加速法。通过在一个经典的资产定价模型背景下实现并应用此方法，你不仅能学会一项高级的数值技巧，还能体会到在解决实际经济问题时，算法优化的重要性与巨大价值 [@problem_id:2393814]。", "id": "2393814", "problem": "考虑一个具有恒定股息的永续年金的线性资产定价问题。在一个风险中性、单周期模型中，对于具有恒定股息 $d$ 和贴现因子 $\\beta$ 的统一公债，其在时间 $0$ 的价格 $p$ 的无套利定价约束意味着价格满足不动点关系 $p = g(p)$，其中 $g(p)$ 是 $\\mathbb{R}$ 上的自映射。具体来说，在恒定贴现因子 $\\beta$（满足 $|\\beta| &lt; 1$）和恒定股息 $d$ 的条件下，该映射为 $g(p) = d + \\beta p$。映射 $g$ 是 $\\mathbb{R}$ 上的一个压缩映射，其模为 $|\\beta|$，因此不动点迭代 $p_{k+1} = g(p_k)$ 对于任何初始猜测 $p_0 \\in \\mathbb{R}$ 都会线性收敛到唯一的不动点。本练习的目的是实现并比较基本不动点迭代与一种基于 Aitken $\\Delta^2$ 过程的加速方案。该加速方案结合三个连续的迭代值来为一个线性收敛的序列加速。\n\n你的任务是：\n- 从第一性原理出发，为映射 $g(p) = d + \\beta p$ 实现基本的不动点迭代。\n- 推导并实现一个 Aitken $\\Delta^2$ 加速步骤，该步骤使用基本不动点迭代产生的三个连续迭代值来构造一个加速后的迭代值。你的实现必须具有数值鲁棒性：如果加速步骤所需的分母为零或数值上过小（可能导致除法不稳定），则在该周期中跳过加速，继续使用基本不动点迭代产生的未加速的迭代值。\n- 使用绝对不动点残差 $|g(x) - x|$ 作为停止准则。当 $|g(x) - x| \\le \\text{tol}$ 时停止，其中 $\\text{tol} > 0$ 是给定的容差。\n\n需要强制执行的实现细节：\n- 对于基本的不动点迭代，每次应用 $g$ 计为一次函数求值。报告迭代次数（在此情况下等于函数求值次数）。\n- 对于 Aitken 加速过程，将计算组织成周期。在每个周期中，从当前 $x_0$ 开始，通过基本映射 $g$ 生成两个连续的迭代值 $x_1$ 和 $x_2$，然后从 $(x_0, x_1, x_2)$ 计算一个加速后的迭代值。函数求值的计数必须包括生成 $x_1$ 和 $x_2$ 的两次求值，再加上一次为了计算加速后迭代值残差的求值（即，求值 $g(x_{\\text{acc}})$）。因此，一个成功的加速周期通常使用三次 $g$ 的求值。如果由于数值安全原因跳过加速，仍需对所选的迭代值计算残差并计入该次求值。持续循环，直到满足残差容差或达到最大周期数。\n- 对两种方法都使用绝对不動點残差 $|g(x) - x|$ 和给定的容差 $\\text{tol}$ 作为终止条件。对基本迭代的次数和 Aitken 周期的次数分别使用相同的最大迭代上限 $N_{\\max}$。\n\n测试套件：\n对于下面的每个参数元组 $(\\beta, d, p_0, \\text{tol}, N_{\\max})$，运行两种方法并收集结果。\n\n1. $(\\beta, d, p_0, \\text{tol}, N_{\\max}) = (0.9, 1.0, 0.0, 10^{-12}, 10000)$\n2. $(\\beta, d, p_0, \\text{tol}, N_{\\max}) = (0.99, 1.0, 0.0, 10^{-12}, 10000)$\n3. $(\\beta, d, p_0, \\text{tol}, N_{\\max}) = (-0.8, 1.0, 0.0, 10^{-12}, 10000)$\n4. $(\\beta, d, p_0, \\text{tol}, N_{\\max}) = (0.0, 2.0, 5.0, 10^{-12}, 10000)$\n\n对于每个测试用例，生成一个包含以下六个条目的列表：\n- 基本迭代返回的近似不动点（浮点数）。\n- 执行的基本迭代总次数（整数）。\n- 基本方法中的函数求值总次数（整数）。\n- Aitken 加速过程返回的近似不动点（浮点数）。\n- 执行的 Aitken 周期总次数（整数）。\n- Aitken 方法中的函数求值总次数（整数）。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个由四个内部列表（每个测试用例一个）组成的逗号分隔列表，并用方括号括起来。每个内部列表必须按上述顺序包含六个条目。所有浮点数必须四舍五入到 $12$ 位小数。例如，输出应类似于 $[[x_{11},x_{12},\\dots],[x_{21},x_{22},\\dots],\\dots]$，并包含此问题测试用例的精确值。\n- 不应打印任何额外文本。", "solution": "所提出的问题是计算经济学中的一个明确定义的练习，特别是在资产定价方面，它结合了数值分析中关于加速不动点迭代收敛速度的标准问题。对问题陈述的验证证实了它具有科学依据、数学上一致且计算上是可行的。因此，我们将着手提供一个完整的解决方案。\n\n问题的核心是找到由以下公式定义的映射 $g: \\mathbb{R} \\to \\mathbb{R}$ 的不动点 $p^*$：\n$$ g(p) = d + \\beta p $$\n其中 $p$ 是永续年金的价格，$d$ 是恒定股息，$\\beta$ 是恒定贴现因子，满足 $|\\beta| < 1$。不动点 $p^*$ 代表了资产的无套利均衡价格。从解析上讲，通过求解方程 $p = d + \\beta p$ 可以轻易找到解：\n$$ p(1 - \\beta) = d \\implies p^* = \\frac{d}{1 - \\beta} $$\n这个解析解可作为我们数值方法的基准。条件 $|\\beta| < 1$ 确保了映射 $g(p)$ 是 $\\mathbb{R}$ 上的一个压缩映射，其压缩因子为 $|\\beta|$。根据 Banach 不动点定理，这保证了唯一不动点的存在，以及基本不动点迭代从任何起点 $p_0 \\in \\mathbb{R}$ 出发都会收敛。\n\n我们将实现并比较两种寻找此不动点的方法。\n\n**方法 1：基本不动点迭代**\n\n这是压缩映射原理最直接的应用。从一个初始猜测 $p_0$ 开始，我们使用递推关系生成一个序列 $\\{p_k\\}_{k=0}^\\infty$：\n$$ p_{k+1} = g(p_k) = d + \\beta p_k $$\n迭代持续进行，直到绝对不动点残差小于指定的容差 $\\text{tol} > 0$。停止准则由 $|g(p_k) - p_k| \\le \\text{tol}$ 给出。然而，为了保持迭代次数与函数求值次数相等，我们检查条件 $|p_{k+1} - p_k| \\le \\text{tol}$，这是等价的。\n\n算法如下：\n1. 初始化 $p \\leftarrow p_0$，$k \\leftarrow 0$。\n2. 对于 $k = 1, 2, \\dots, N_{\\max}$：\n   a. 计算 $p_{\\text{new}} = g(p)$。\n   b. 计算残差：$R = |p_{\\text{new}} - p|$。\n   c. 更新迭代值：$p \\leftarrow p_{\\text{new}}$。\n   d. 如果 $R \\le \\text{tol}$，终止迭代并返回 $p$ 作为解。迭代次数和函数求值次数均为 $k$。\n3. 如果循环完成但未收敛，则该过程失败。\n此方法的收敛速度是线性的，每一步的误差大约减少一个因子 $|\\beta|$。当 $|\\beta|$ 接近 $1$ 时，收敛会变得极其缓慢，这促使我们使用加速技术。\n\n**方法 2：Aitken $\\Delta^2$ 加速**\n\nAitken $\\Delta^2$ 过程是一种加速线性收敛序列收敛速度的方法。给定序列的三个连续项 $(x_n, x_{n+1}, x_{n+2})$，可以构造一个对极限的更好估计 $x'_n$。\n\n让我们推导这个公式。对于一个线性收敛到极限 $x^*$ 的序列 $\\{x_n\\}$，我们有 $x_{n+1} - x^* \\approx c(x_n - x^*)$，其中某个常数 $c$ 满足 $|c|<1$。这意味着 $(x_{n+1} - x_n) \\approx (c-1)(x_n - x^*)$。通过从此式中表达出 $x_n - x^*$ 并代回 $x_{n+1} - x^* \\approx c(x_n-x^*)$，我们可以解出 $x^*$。一个更直接的代数操作可以得到标准公式。令 $\\Delta$ 为前向差分算子，即 $\\Delta x_n = x_{n+1} - x_n$。加速后的迭代值由以下公式给出：\n$$ x'_n = x_n - \\frac{(\\Delta x_n)^2}{\\Delta^2 x_n} = x_n - \\frac{(x_{n+1} - x_n)^2}{(x_{n+2} - x_{n+1}) - (x_{n+1} - x_n)} = x_n - \\frac{(x_{n+1} - x_n)^2}{x_{n+2} - 2x_{n+1} + x_n} $$\n如果 $x_{n+2} - 2x_{n+1} + x_n \\approx 0$，分母可能为零或数值不稳定。一个鲁棒的实现必须检查这种情况。\n\n计算被组织成周期。在每个周期内，从一个点 $x_0$ 开始：\n1. 生成两个标准的不动点迭代值：$x_1 = g(x_0)$ 和 $x_2 = g(x_1)$。这需要两次函数求值。\n2. 计算分母 $D = x_2 - 2x_1 + x_0$。\n3. 为了数值稳定性，如果 $|D|$ 小于一个小阈值（例如 $10^{-16}$），我们认为加速步骤不安全。在这种情况下，我们放弃加速并继续使用未加速的迭代值，将下一个点设置为 $x_{\\text{next}} \\leftarrow x_2$。\n4. 如果分母是安全的，计算加速后的迭代值：$x_{\\text{acc}} = x_0 - (x_1 - x_0)^2 / D$，并设置 $x_{\\text{next}} \\leftarrow x_{\\text{acc}}$。\n5. 检查停止准则。这需要第三次函数求值来计算新点的残差：$R = |g(x_{\\text{next}}) - x_{\\text{next}}|$。\n6. 下一个周期从新的点 $x_0 \\leftarrow x_{\\text{next}}$ 开始。\n因此，每个周期需要三次函数求值。该过程持续进行，直到 $R \\le \\text{tol}$ 或达到最大周期数 $N_{\\max}$。\n\n我们现在开始实现这两种算法，并将其应用于指定的测试套件。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and compares basic fixed-point iteration and Aitken-accelerated\n    iteration for an asset-pricing problem.\n    \"\"\"\n\n    test_cases = [\n        (0.9, 1.0, 0.0, 1e-12, 10000),\n        (0.99, 1.0, 0.0, 1e-12, 10000),\n        (-0.8, 1.0, 0.0, 1e-12, 10000),\n        (0.0, 2.0, 5.0, 1e-12, 10000),\n    ]\n\n    all_results = []\n\n    for beta, d, p0, tol, n_max in test_cases:\n        \n        # Define the mapping function g(p)\n        g = lambda p: d + beta * p\n\n        # --- Method 1: Basic Fixed-Point Iteration ---\n        p_basic = p0\n        evals_basic = 0\n        iters_basic = 0\n        for i in range(1, n_max + 1):\n            p_next = g(p_basic)\n            evals_basic += 1\n            iters_basic += 1\n            \n            residual = abs(p_next - p_basic)\n            p_basic = p_next\n            \n            if residual <= tol:\n                break\n        \n        # --- Method 2: Aitken's Delta^2 Acceleration ---\n        p_aitken = p0\n        evals_aitken = 0\n        cycles_aitken = 0\n        denominator_threshold = 1e-16 # For numerical stability\n\n        for k in range(1, n_max + 1):\n            cycles_aitken += 1\n            \n            x0 = p_aitken\n            \n            # Step 1: Generate two standard iterates\n            x1 = g(x0)\n            x2 = g(x1)\n            evals_aitken += 2\n            \n            # Step 2 & 3: Compute denominator and check for stability\n            denominator = x2 - 2 * x1 + x0\n            \n            p_next = 0.0\n            if abs(denominator) < denominator_threshold:\n                # Skip acceleration, proceed with standard iterate\n                p_next = x2\n            else:\n                # Step 4: Compute accelerated iterate\n                numerator = (x1 - x0)**2\n                p_next = x0 - numerator / denominator\n            \n            # Step 5: Check stopping criterion\n            g_p_next = g(p_next)\n            evals_aitken += 1\n            residual = abs(g_p_next - p_next)\n            \n            p_aitken = p_next\n            \n            if residual <= tol:\n                break\n        \n        case_results = [\n            p_basic, \n            iters_basic, \n            evals_basic,\n            p_aitken, \n            cycles_aitken, \n            evals_aitken\n        ]\n        all_results.append(case_results)\n\n    # Final print statement in the exact required format.\n    formatted_results = []\n    for res in all_results:\n        p_b, i_b, e_b, p_a, c_a, e_a = res\n        s = f\"[{p_b:.12f},{i_b},{e_b},{p_a:.12f},{c_a},{e_a}]\"\n        formatted_results.append(s)\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"}]}