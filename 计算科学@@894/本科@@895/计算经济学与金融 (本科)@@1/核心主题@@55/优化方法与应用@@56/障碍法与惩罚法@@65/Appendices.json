{"hands_on_practices": [{"introduction": "罚函数法的核心思想是“序列化”，即将一个复杂的约束问题转化为一系列不断加权的无约束子问题。这个练习将带你亲手实现这一过程，并探索一个关键的效率技巧：热启动（warm-starting）。通过比较从同一起点“冷启动”每个子问题与利用前一个子问题的解来“热启动”下一个子问题，你将直观地量化并理解为何热启动是实际应用中不可或缺的策略 [@problem_id:2423453]。", "id": "2423453", "problem": "您需要实现一个用于解决约束优化问题的序列二次罚函数法，并通过实验量化温启动（即复用前一个子问题的解作为下一个惩罚参数的初始猜测值）所带来的益处。请实现一个带有回溯 Armijo 线搜索的基于梯度的求解器，用以最小化一系列无约束的惩罚子问题。对于一个固定的惩罚参数序列 $\\{\\rho_k\\}_{k=1}^K$（其中 $\\rho_1 &lt; \\rho_2 &lt; \\dots &lt; \\rho_K$），请对每个测试案例比较两种策略：(i) 从相同的初始点冷启动每个子问题，以及 (ii) 从子问题 $k$ 计算出的最小化点温启动子问题 $k+1$。报告加速因子，其定义为在整个惩罚序列中，冷启动所用的梯度下降迭代总次数与温启动所用的梯度下降迭代总次数之比。\n\n使用的基本原理和定义：\n- 一个约束最小化问题具有目标函数 $f:\\mathbb{R}^n\\to\\mathbb{R}$，不等式约束 $g_i(x)\\le 0$（其中 $i\\in\\{1,\\dots,m\\}$），以及等式约束 $h_j(x)=0$（其中 $j\\in\\{1,\\dots,p\\}$）。\n- 对于不等式，经典的二次罚函数应用于其违规量，形式为 $\\max\\{0, g_i(x)\\}^2$；对于等式，形式为 $h_j(x)^2$。\n- 对于给定的 $\\rho&gt;0$，惩罚子问题是最小化\n$$\n\\Phi_\\rho(x)=f(x)+\\rho\\left(\\sum_{i=1}^m \\max\\{0,g_i(x)\\}^2+\\sum_{j=1}^p h_j(x)^2\\right).\n$$\n- 使用带有回溯 Armijo 准则的梯度下降法：给定当前点 $x$、梯度 $\\nabla\\Phi_\\rho(x)$、初始步长 $t_0$、缩减因子 $\\beta\\in(0,1)$ 和 Armijo 参数 $c\\in(0,1)$，从序列 $\\{t_0, \\beta t_0, \\beta^2 t_0,\\dots\\}$ 中选择满足以下条件的最大 $t$：\n$$\n\\Phi_\\rho(x - t \\nabla \\Phi_\\rho(x)) \\le \\Phi_\\rho(x) - c\\,t\\,\\|\\nabla \\Phi_\\rho(x)\\|_2^2.\n$$\n- 当 $\\|\\nabla \\Phi_\\rho(x)\\|_2\\le \\varepsilon$ 时，停止内部求解器。\n\n实现要求：\n- 严格按照上述定义实现二次罚函数法和带有回溯 Armijo 线搜索的梯度下降法。\n- 对于不等式约束，在罚函数值及其梯度中均使用 $\\max\\{0,\\cdot\\}$ 结构，仅处理正向违规量。对于等式约束，惩罚其残差的平方。\n- 使用惩罚序列 $\\rho\\in\\{10,10^2,10^3\\}$，即 $\\rho \\in \\{10,100,1000\\}$。\n- 对所有子问题，使用梯度容差 $\\varepsilon=10^{-6}$、Armijo 参数 $c=10^{-4}$、缩减因子 $\\beta=\\tfrac{1}{2}$ 和初始步长 $t_0=1$。将每个子问题的最大梯度迭代次数限制在 $N_{\\max}=10^4$。\n- 统计使一个子问题收敛所需的外部梯度下降迭代次数（每次线搜索后被接受的步），不要单独计算线搜索的回溯步数。\n\n测试套件：\n实现并求解以下三个二维测试案例。在每个案例中，返回加速因子\n$$\nS=\\frac{N_{\\mathrm{cold}}}{N_{\\mathrm{warm}}},\n$$\n其中 $N_{\\mathrm{cold}}$ 是从指定初始点冷启动每个子问题时，在所有惩罚参数上累加的梯度下降迭代总次数；$N_{\\mathrm{warm}}$ 是从前一个子问题的解温启动每个子问题时的总次数。\n\n- 案例 $\\mathbf{A}$ (带有一个有效线性不等式约束的凸二次问题)：\n  - 目标函数：$f(x,y)=(x-1)^2+2\\,(y+2)^2$。\n  - 不等式约束：$g_1(x,y)=1-x-y\\le 0$。\n  - 无等式约束。\n  - 初始点：$x_0=(0,0)$。\n\n- 案例 $\\mathbf{B}$ (带有一个等式约束的凸二次问题)：\n  - 目标函数：$f(x,y)=(x-3)^2+(y-1)^2$。\n  - 等式约束：$h_1(x,y)=x-y=0$。\n  - 无不等式约束。\n  - 初始点：$x_0=(0,0)$。\n\n- 案例 $\\mathbf{C}$ (带有一个曲线不等式约束的凸二次问题)：\n  - 目标函数：$f(x,y)=(x+2)^2+y^2$。\n  - 不等式约束：$g_1(x,y)=x^2+y^2-1\\le 0$。\n  - 无等式约束。\n  - 初始点：$x_0=(0,0)$。\n\n输出规格：\n- 对每个案例，计算如上定义的加速因子 $S$。\n- 您的程序应产生单行输出，其中包含三个加速因子，格式为方括号括起来的逗号分隔列表，顺序为 $\\left[S_A,S_B,S_C\\right]$，其中 $S_A$ 对应案例 $\\mathbf{A}$，$S_B$ 对应案例 $\\mathbf{B}$，$S_C$ 对应案例 $\\mathbf{C}$。例如，输出形式为 $\\left[\\text{result}_1,\\text{result}_2,\\text{result}_3\\right]$，其中包含数值。\n- 将每个加速因子表示为浮点数。您可以在内部进行四舍五入，但打印出的值必须是标准十进制浮点数。\n\n不涉及物理单位。不使用角度。不使用百分比。\n\n最终程序必须是自包含的，不需要任何输入，并遵守指定的运行时环境。正确性将通过以下方式进行评估：验证实现是否遵循定义，以及温启动是否产生严格更少或至少不更多的迭代次数，从而为指定案例生成有意义的加速因子。输出必须是严格遵循指定格式的单行。", "solution": "该问题要求实现一个序列二次罚函数法来求解约束优化问题。任务的核心是比较一系列无约束子问题的两种初始化策略（冷启动策略与温启动策略）的计算效率。效率通过一个加速因子来量化，该因子被定义为梯度下降总迭代次数的比率。\n\n约束优化问题的一般形式是最小化目标函数 $f(x)$，其受限于一组不等式约束 $g_i(x) \\le 0$（其中 $i \\in \\{1, \\dots, m\\}$）和等式约束 $h_j(x) = 0$（其中 $j \\in \\{1, \\dots, p\\}$），其中 $x \\in \\mathbb{R}^n$。\n\n二次罚函数法通过求解一系列无约束最小化问题来逼近该问题的解。对于给定的惩罚参数 $\\rho > 0$，通过向原始目标函数中添加惩罚约束违规的项来构造惩罚目标函数 $\\Phi_\\rho(x)$。惩罚函数的具体形式是：\n$$\n\\Phi_\\rho(x) = f(x) + \\rho \\left( \\sum_{i=1}^m \\left(\\max\\{0, g_i(x)\\}\\right)^2 + \\sum_{j=1}^p \\left(h_j(x)\\right)^2 \\right)\n$$\n然后，该函数 $\\Phi_\\rho(x)$ 相对于 $x$ 进行最小化。通过对一个递增的惩罚参数序列 $\\rho_1 < \\rho_2 < \\dots < \\rho_K$ 求解这个无约束问题，最小化点序列 $x^*(\\rho_k)$ 将收敛到原始约束问题的解。\n\n为了最小化每个无约束子问题 $\\min_x \\Phi_\\rho(x)$，需要一种基于梯度的方法。惩罚目标函数的梯度 $\\nabla \\Phi_\\rho(x)$ 是使用链式法则推导出来的。对于不等式约束项 $P_i(x) = \\rho (\\max\\{0, g_i(x)\\})^2$，其梯度为 $\\nabla P_i(x) = 2 \\rho \\max\\{0, g_i(x)\\} \\nabla g_i(x)$。对于等式约束项 $Q_j(x) = \\rho (h_j(x))^2$，其梯度为 $\\nabla Q_j(x) = 2 \\rho h_j(x) \\nabla h_j(x)$。将这些与目标函数的梯度结合起来，完整的梯度是：\n$$\n\\nabla \\Phi_\\rho(x) = \\nabla f(x) + 2\\rho \\left( \\sum_{i=1}^m \\max\\{0, g_i(x)\\} \\nabla g_i(x) + \\sum_{j=1}^p h_j(x) \\nabla h_j(x) \\right)\n$$\n无约束最小化是使用梯度下降法执行的。从点 $x_k$ 开始，通过沿负梯度方向移动来找到下一个点 $x_{k+1}$：\n$$\nx_{k+1} = x_k - t \\nabla \\Phi_\\rho(x_k)\n$$\n步长 $t > 0$ 由采用 Armijo 条件的回溯线搜索确定。对于给定的下降方向 $d_k = -\\nabla \\Phi_\\rho(x_k)$，我们寻求序列 $\\{t_0, \\beta t_0, \\beta^2 t_0, \\dots\\}$ 中满足以下条件的最大 $t$：\n$$\n\\Phi_\\rho(x_k + t d_k) \\le \\Phi_\\rho(x_k) + c \\, t \\, \\nabla \\Phi_\\rho(x_k)^T d_k\n$$\n使用 $d_k = -\\nabla \\Phi_\\rho(x_k)$，这可以简化为问题陈述中给出的形式：\n$$\n\\Phi_\\rho(x_k - t \\nabla \\Phi_\\rho(x_k)) \\le \\Phi_\\rho(x_k) - c \\, t \\, \\|\\nabla \\Phi_\\rho(x_k)\\|_2^2\n$$\n算法迭代直到梯度的范数低于指定的容差 $\\varepsilon$，即 $\\|\\nabla \\Phi_\\rho(x)\\|_2 \\le \\varepsilon$。该求解器的参数是固定的：初始步长 $t_0=1$、Armijo 参数 $c=10^{-4}$、缩减因子 $\\beta=0.5$ 和梯度范数容差 $\\varepsilon=10^{-6}$。每个子问题的最大迭代次数上限为 $N_{\\max}=10^4$。\n\n实验在惩罚参数序列 $\\rho \\in \\{10, 100, 1000\\}$ 上比较两种策略：\n1. **冷启动 (Cold-Start)**：每个针对 $\\rho_k$ 的子问题都从相同的起始点 $x_0$ 初始化。总迭代次数 $N_{\\mathrm{cold}}$ 是独立求解每个子问题所需迭代次数的总和。\n2. **温启动 (Warm-Start)**：第一个子问题（针对 $\\rho_1=10$）从 $x_0$ 初始化。后续每个针对 $\\rho_{k+1}$ 的子问题都使用从前一个 $\\rho_k$ 子问题获得的解进行初始化。总迭代次数 $N_{\\mathrm{warm}}$ 是此序列中所有迭代次数的总和。\n\n温启动的基本原理是，解 $x^*(\\rho_k)$ 有望成为 $\\Phi_{\\rho_{k+1}}(x)$ 最小化点的一个良好初始猜测，特别是当 $\\rho_{k+1}$ 不比 $\\rho_k$ 大很多时。这应能导致更快的收敛。性能增益通过加速因子 $S = N_{\\mathrm{cold}} / N_{\\mathrm{warm}}$ 来衡量。\n\n实现将按以下步骤进行：为每个测试案例的目标函数、约束函数及其各自的梯度定义 Python 函数。一个通用的求解器函数将执行带有 Armijo 线搜索的梯度下降。一个顶层函数将管理惩罚参数序列，应用冷启动和温启动策略，计算每种策略的总迭代次数，并计算加速比。对所有三个提供的测试案例重复此过程。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the specified test cases and print the results.\n    \"\"\"\n    \n    # --- Solver Parameters ---\n    SOLVER_PARAMS = {\n        'epsilon': 1e-6,\n        'c_armijo': 1e-4,\n        'beta': 0.5,\n        't0': 1.0,\n        'n_max': 10000\n    }\n    PENALTY_PARAMS = [10.0, 100.0, 1000.0]\n\n    # --- Test Case Definitions ---\n    \n    # Case A: (x-1)^2 + 2(y+2)^2, s.t. 1-x-y <= 0\n    case_A = {\n        'f': lambda x: (x[0] - 1.0)**2 + 2.0 * (x[1] + 2.0)**2,\n        'grad_f': lambda x: np.array([2.0 * (x[0] - 1.0), 4.0 * (x[1] + 2.0)]),\n        'g': [lambda x: 1.0 - x[0] - x[1]],\n        'grad_g': [lambda x: np.array([-1.0, -1.0])],\n        'h': [],\n        'grad_h': [],\n        'x0': np.array([0.0, 0.0])\n    }\n\n    # Case B: (x-3)^2 + (y-1)^2, s.t. x-y = 0\n    case_B = {\n        'f': lambda x: (x[0] - 3.0)**2 + (x[1] - 1.0)**2,\n        'grad_f': lambda x: np.array([2.0 * (x[0] - 3.0), 2.0 * (x[1] - 1.0)]),\n        'g': [],\n        'grad_g': [],\n        'h': [lambda x: x[0] - x[1]],\n        'grad_h': [lambda x: np.array([1.0, -1.0])],\n        'x0': np.array([0.0, 0.0])\n    }\n    \n    # Case C: (x+2)^2 + y^2, s.t. x^2+y^2-1 <= 0\n    case_C = {\n        'f': lambda x: (x[0] + 2.0)**2 + x[1]**2,\n        'grad_f': lambda x: np.array([2.0 * (x[0] + 2.0), 2.0 * x[1]]),\n        'g': [lambda x: x[0]**2 + x[1]**2 - 1.0],\n        'grad_g': [lambda x: np.array([2.0 * x[0], 2.0 * x[1]])],\n        'h': [],\n        'grad_h': [],\n        'x0': np.array([0.0, 0.0])\n    }\n\n    test_cases = [case_A, case_B, case_C]\n    \n    def get_penalized_funcs(case, rho):\n        \"\"\"Creates the penalized function and its gradient for a given case and rho.\"\"\"\n        \n        def phi(x):\n            f_val = case['f'](x)\n            g_sum = sum(max(0, g_func(x))**2 for g_func in case['g'])\n            h_sum = sum(h_func(x)**2 for h_func in case['h'])\n            return f_val + rho * (g_sum + h_sum)\n\n        def grad_phi(x):\n            grad_f_val = case['grad_f'](x)\n            \n            grad_g_sum = np.zeros_like(x)\n            for g_func, grad_g_func in zip(case['g'], case['grad_g']):\n                g_val = g_func(x)\n                if g_val > 0:\n                    grad_g_sum += 2.0 * g_val * grad_g_func(x)\n\n            grad_h_sum = np.zeros_like(x)\n            for h_func, grad_h_func in zip(case['h'], case['grad_h']):\n                h_val = h_func(x)\n                grad_h_sum += 2.0 * h_val * grad_h_func(x)\n                \n            return grad_f_val + rho * (grad_g_sum + grad_h_sum)\n        \n        return phi, grad_phi\n\n    def gradient_descent(phi, grad_phi, x_init, params):\n        \"\"\"\n        Performs gradient descent with backtracking Armijo line search.\n        \"\"\"\n        x = np.copy(x_init)\n        n_iters = 0\n        \n        for k in range(params['n_max']):\n            grad = grad_phi(x)\n            grad_norm_sq = np.dot(grad, grad)\n\n            if np.sqrt(grad_norm_sq) <= params['epsilon']:\n                break\n            \n            # Backtracking line search\n            t = params['t0']\n            phi_x = phi(x)\n            \n            while True:\n                x_new = x - t * grad\n                phi_new = phi(x_new)\n                armijo_check = phi_x - params['c_armijo'] * t * grad_norm_sq\n                \n                if phi_new <= armijo_check:\n                    break\n                t *= params['beta']\n            \n            x = x_new\n            n_iters += 1\n        \n        return x, n_iters\n\n    def run_penalty_method(case, solver_params, penalty_params):\n        \"\"\"\n        Runs the full sequential penalty method for a case,\n        calculating iterations for both cold and warm starts.\n        \"\"\"\n        # Cold start\n        total_iters_cold = 0\n        for rho in penalty_params:\n            phi, grad_phi = get_penalized_funcs(case, rho)\n            _, n_iters = gradient_descent(phi, grad_phi, case['x0'], solver_params)\n            total_iters_cold += n_iters\n            \n        # Warm start\n        total_iters_warm = 0\n        x_warm = np.copy(case['x0'])\n        for rho in penalty_params:\n            phi, grad_phi = get_penalized_funcs(case, rho)\n            x_sol, n_iters = gradient_descent(phi, grad_phi, x_warm, solver_params)\n            total_iters_warm += n_iters\n            x_warm = x_sol\n            \n        if total_iters_warm == 0:\n             # This case should not happen in this problem, but is a safeguard.\n             # If cold is also 0, speedup is 1. If cold > 0, speedup is \"infinite\".\n            return 1.0 if total_iters_cold == 0 else float('inf')\n            \n        return float(total_iters_cold) / float(total_iters_warm)\n\n    results = []\n    for case in test_cases:\n        speedup = run_penalty_method(case, SOLVER_PARAMS, PENALTY_PARAMS)\n        results.append(speedup)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}, {"introduction": "在金融工程中，许多复杂的优化算法都要求从一个满足所有约束的“可行”投资组合出发。本练习将罚函数法置于一个实际的金融场景中：寻找一个满足预算、风险、收益和持仓限制的初始投资组合。你将通过最小化一个聚合了所有约束违反度的“惩罚”函数，来系统地寻找一个可行解，这展示了罚函数法作为一种强大的“第一阶段”（Phase I）工具的实际应用价值 [@problem_id:2374527]。", "id": "2374527", "problem": "考虑构建一个满足一系列经济和金融约束的初始投资组合向量的任务。令 $n \\in \\mathbb{N}$ 表示资产数量，令 $\\mu \\in \\mathbb{R}^n$ 为预期收益向量，$\\Sigma \\in \\mathbb{R}^{n \\times n}$ 为一个对称正定的收益协方差矩阵。令 $u \\in \\mathbb{R}^n$ 为权重分量的上限向量。投资组合权重为 $w \\in \\mathbb{R}^n$。需要满足的约束条件如下：\n- 预算等式：$\\sum_{i=1}^n w_i = 1$。\n- 下限（无卖空）：对所有 $i \\in \\{1,\\dots,n\\}$，$w_i \\ge 0$。\n- 上限：对所有 $i \\in \\{1,\\dots,n\\}$，$w_i \\le u_i$。\n- 要求预期收益：$\\mu^\\top w \\ge R_{\\text{target}}$。\n- 风险上限：$w^\\top \\Sigma w \\le V_{\\max}$。\n\n将不等式函数定义为规范形式 $g(w) \\le 0$，等式函数定义为 $h(w) = 0$：\n- $g_{\\text{ret}}(w) = R_{\\text{target}} - \\mu^\\top w$，\n- $g_{\\text{var}}(w) = w^\\top \\Sigma w - V_{\\max}$，\n- $g_{\\text{lo},i}(w) = -w_i$，对每个 $i \\in \\{1,\\dots,n\\}$，\n- $g_{\\text{up},i}(w) = w_i - u_i$，对每个 $i \\in \\{1,\\dots,n\\}$，\n- $h_{\\text{bud}}(w) = \\mathbf{1}^\\top w - 1$，其中 $\\mathbf{1}$ 是 $\\mathbb{R}^n$ 中的全一向量。\n\n对于任意罚参数 $\\rho > 0$，定义优值函数\n$$\nM_\\rho(w) \\;=\\; \\rho \\left( \\sum_{i=1}^n \\bigl(\\max\\{0, g_{\\text{lo},i}(w)\\}\\bigr)^2 \\;+\\; \\sum_{i=1}^n \\bigl(\\max\\{0, g_{\\text{up},i}(w)\\}\\bigr)^2 \\;+\\; \\bigl(\\max\\{0, g_{\\text{ret}}(w)\\}\\bigr)^2 \\;+\\; \\bigl(\\max\\{0, g_{\\text{var}}(w)\\}\\bigr)^2 \\;+\\; \\bigl(h_{\\text{bud}}(w)\\bigr)^2 \\right) \\;+\\; \\lambda \\,\\|w\\|_2^2,\n$$\n其中 $\\lambda > 0$ 是一个固定的正则化参数，$\\|\\cdot\\|_2$ 表示欧几里得范数。\n\n对于给定的容差 $\\tau > 0$，将在任意 $w$ 处的最大约束违反量定义为\n$$\n\\mathrm{vio}(w) \\;=\\; \\max\\!\\left( \\left| h_{\\text{bud}}(w) \\right|, \\;\\max\\{0, g_{\\text{ret}}(w)\\}, \\;\\max\\{0, g_{\\text{var}}(w)\\}, \\;\\max_{i=1,\\dots,n}\\max\\{0, g_{\\text{lo},i}(w)\\}, \\;\\max_{i=1,\\dots,n}\\max\\{0, g_{\\text{up},i}(w)\\} \\right).\n$$\n\n对于下方的每个测试实例，您的程序必须产出一个向量 $w$，该向量能近似最小化某个从序列 $\\{10^1, 10^2, 10^3, 10^4, 10^5, 10^6\\}$ 中选取的 $\\rho$ 值下的 $M_\\rho(w)$，然后报告在得到的 $w$ 处的 $\\mathrm{vio}(w)$ 值。对于每个测试实例，从序列中选择能使 $\\mathrm{vio}(w) \\le \\tau$ 成立的最小 $\\rho$（如果存在）；若不存在这样的 $\\rho$ 能使 $\\mathrm{vio}(w) \\le \\tau$ 成立，则报告在最大 $\\rho = 10^6$ 下达到的 $\\mathrm{vio}(w)$。使用固定容差 $\\tau = 10^{-6}$ 和正则化参数 $\\lambda = 10^{-8}$。\n\n测试套件：\n- 测试用例 A：\n  - $n = 3$，\n  - $\\mu = [\\,0.06,\\; 0.10,\\; 0.14\\,]$,\n  - $\\Sigma = \\begin{bmatrix} 0.010 & 0.002 & 0.001 \\\\ 0.002 & 0.020 & 0.003 \\\\ 0.001 & 0.003 & 0.030 \\end{bmatrix}$,\n  - $u = [\\,0.8,\\; 0.8,\\; 0.8\\,]$,\n  - $R_{\\text{target}} = 0.09$,\n  - $V_{\\max} = 0.025$。\n- 测试用例 B：\n  - $n = 3$，\n  - $\\mu = [\\,0.03,\\; 0.05,\\; 0.07\\,]$,\n  - $\\Sigma = \\begin{bmatrix} 0.008 & 0.001 & 0.0005 \\\\ 0.001 & 0.012 & 0.001 \\\\ 0.0005 & 0.001 & 0.015 \\end{bmatrix}$,\n  - $u = [\\,0.8,\\; 0.8,\\; 0.8\\,]$,\n  - $R_{\\text{target}} = 0.07$,\n  - $V_{\\max} = 0.05$。\n- 测试用例 C：\n  - $n = 4$，\n  - $\\mu = [\\,0.05,\\; 0.08,\\; 0.12,\\; 0.04\\,]$,\n  - $\\Sigma = \\begin{bmatrix}\n  0.005 & 0.001 & 0.001 & 0.0005 \\\\\n  0.001 & 0.010 & 0.002 & 0.001 \\\\\n  0.001 & 0.002 & 0.020 & 0.0015 \\\\\n  0.0005 & 0.001 & 0.0015 & 0.004\n  \\end{bmatrix}$,\n  - $u = [\\,0.6,\\; 0.6,\\; 0.5,\\; 1.0\\,]$,\n  - $R_{\\text{target}} = 0.08$,\n  - $V_{\\max} = 0.012$。\n\n所有测试实例的初始条件：使用任意确定性的 $w^{(0)} \\in \\mathbb{R}^n$；例如，使用分量为 $w^{(0)}_i = 1/n$ 的等权重向量 $w^{(0)}$。\n\n你的程序必须在单行中输出三个测试用例的最大约束违反量，格式必须完全如下：一个包含三个浮点数的列表，每个浮点数四舍五入到小数点后恰好六位，并用逗号分隔，方括号括起，按测试用例 A、B、C 的顺序排列。例如，输出行必须形如 $[v_A,v_B,v_C]$，其中 $v_A$、$v_B$、$v_C$ 均为四舍五入到六位小数的浮点数。不得打印任何额外文本。", "solution": "该问题要求找到一个投资组合权重向量 $w \\in \\mathbb{R}^n$，该向量满足一组线性和二次的等式及不等式约束。这是一个计算金融中的可行性问题。为找到这样的向量，所提出的方法是罚函数法，它将约束问题转化为一系列无约束优化问题。\n\n该方法的核心是构建一个必须被最小化的优值函数 $M_\\rho(w)$。对于给定的罚参数 $\\rho > 0$，该函数定义为：\n$$\nM_\\rho(w) \\;=\\; \\rho \\cdot P(w) \\;+\\; \\lambda \\,\\|w\\|_2^2\n$$\n其中 $P(w)$ 是惩罚项，$\\lambda \\|w\\|_2^2$ 是正则化项。惩罚项聚合了所有约束的违反量：\n$$\nP(w) \\;=\\; \\sum_{j} \\bigl(\\max\\{0, g_j(w)\\}\\bigr)^2 \\;+\\; \\sum_{k} \\bigl(h_k(w)\\bigr)^2\n$$\n此处，$g_j(w) \\le 0$ 是不等式约束，$h_k(w) = 0$ 是等式约束。问题陈述为该投资组合问题明确定义了这些约束：\n- 不等式：$g_{\\text{ret}}(w) = R_{\\text{target}} - \\mu^\\top w$，$g_{\\text{var}}(w) = w^\\top \\Sigma w - V_{\\max}$，$g_{\\text{lo},i}(w) = -w_i$ 和 $g_{\\text{up},i}(w) = w_i - u_i$。\n- 等式：$h_{\\text{bud}}(w) = \\mathbf{1}^\\top w - 1$。\n\n函数 $M_\\rho(w)$ 是一个无约束的连续可微 ($C^1$) 函数。其性质至关重要。定义约束的函数 $g_j(w)$ 和 $h_k(w)$ 要么是仿射的，要么（在 $g_{\\text{var}}(w)$ 的情况下）是凸的，因为协方差矩阵 $\\Sigma$ 是正定的。函数 $\\max\\{0, \\cdot\\}$ 是凸且非递减的。一个凸函数与一个非负、非递减、凸函数（如对于 $x \\ge 0$ 的 $x \\mapsto x^2$）的复合会保持凸性。因此，每一项 $\\bigl(\\max\\{0, g_j(w)\\}\\bigr)^2$ 都是凸的。类似地，一个仿射函数的平方 $\\bigl(h_k(w)\\bigr)^2$ 也是凸的。由于正则化项 $\\lambda \\|w\\|_2^2$ 对于 $\\lambda > 0$ 是强凸的，优值函数 $M_\\rho(w)$ 作为包含一个强凸项的非负凸函数之和，其本身也是强凸的。这是一个关键性质，因为它保证了对于任何给定的 $\\rho > 0$，$M_\\rho(w)$ 都有一个唯一的全局极小值点。\n\n为了用数值方法找到这个极小值点，我们可以采用一种基于梯度的优化算法。Broyden–Fletcher–Goldfarb–Shanno (BFGS) 算法是解决这个无约束 $C^1$ 最小化问题的合适选择。为使该算法高效且准确，我们必须提供优值函数的解析梯度 $\\nabla M_\\rho(w)$。利用链式法则，梯度为：\n$$\n\\nabla M_\\rho(w) = 2\\rho \\left( \\sum_{j} \\max\\{0, g_j(w)\\} \\nabla g_j(w) \\;+\\; \\sum_{k} h_k(w) \\nabla h_k(w) \\right) \\;+\\; 2\\lambda w\n$$\n各个约束函数的梯度很容易计算：\n- $\\nabla g_{\\text{lo},i}(w) = -e_i$（其中 $e_i$ 是第 $i$ 个标准基向量）\n- $\\nabla g_{\\text{up},i}(w) = e_i$\n- $\\nabla g_{\\text{ret}}(w) = -\\mu$\n- $\\nabla g_{\\text{var}}(w) = 2 \\Sigma w$（因为 $\\Sigma$ 是对称的）\n- $\\nabla h_{\\text{bud}}(w) = \\mathbf{1}$（全一向量）\n\n将这些代入 $\\nabla M_\\rho(w)$ 的表达式，就得到了一个可以进行数值实现的完整梯度向量公式。\n\n根据问题规定，总体流程如下：\n1.  用等权重向量 $w^{(0)}_i = 1/n$ 初始化投资组合。\n2.  遍历指定的罚参数序列 $\\rho \\in \\{10^1, 10^2, \\dots, 10^6\\}$。\n3.  在每次迭代中，使用 BFGS 算法数值求解无约束最小化问题 $w^* = \\arg\\min_w M_\\rho(w)$，从上一次迭代的解开始（一种热启动策略）。\n4.  为当前 $\\rho$ 找到最优的 $w^*$ 后，计算问题陈述中定义的最大约束违反量 $\\mathrm{vio}(w^*)$。\n5.  如果 $\\mathrm{vio}(w^*) \\le \\tau = 10^{-6}$，则当前测试用例的流程终止，此违反量即为结果。\n6.  如果未达到容差，则继续使用下一个更大的 $\\rho$ 值。如果循环完成仍未达到容差，则报告最后一步（$\\rho = 10^6$时）的违反量。\n\n这种系统化的方法确保了，如果在给定的 $\\rho$ 序列内能找到一个解，我们将找到满足所需精度的可行解；否则，我们将报告对应于最高惩罚的“尽力而为”的解。由于所有测试用例的可行域都是非空的，我们预期该算法能找到满足容差 $\\tau$ 的解。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Main solver function to run all test cases and print the final results.\n    \"\"\"\n    \n    # Global parameters as specified in the problem\n    LAMBDA = 1e-8\n    TAU = 1e-6\n    RHO_SEQUENCE = np.array([1e1, 1e2, 1e3, 1e4, 1e5, 1e6])\n\n    # Test cases data\n    test_cases = [\n        # Case A\n        {\n            \"n\": 3,\n            \"mu\": np.array([0.06, 0.10, 0.14]),\n            \"Sigma\": np.array([[0.010, 0.002, 0.001],\n                               [0.002, 0.020, 0.003],\n                               [0.001, 0.003, 0.030]]),\n            \"u\": np.array([0.8, 0.8, 0.8]),\n            \"R_target\": 0.09,\n            \"V_max\": 0.025,\n            \"lambda\": LAMBDA,\n            \"tau\": TAU\n        },\n        # Case B\n        {\n            \"n\": 3,\n            \"mu\": np.array([0.03, 0.05, 0.07]),\n            \"Sigma\": np.array([[0.008, 0.001, 0.0005],\n                               [0.001, 0.012, 0.001],\n                               [0.0005, 0.001, 0.015]]),\n            \"u\": np.array([0.8, 0.8, 0.8]),\n            \"R_target\": 0.07,\n            \"V_max\": 0.05,\n            \"lambda\": LAMBDA,\n            \"tau\": TAU\n        },\n        # Case C\n        {\n            \"n\": 4,\n            \"mu\": np.array([0.05, 0.08, 0.12, 0.04]),\n            \"Sigma\": np.array([[0.005, 0.001, 0.001, 0.0005],\n                               [0.001, 0.010, 0.002, 0.001],\n                               [0.001, 0.002, 0.020, 0.0015],\n                               [0.0005, 0.001, 0.0015, 0.004]]),\n            \"u\": np.array([0.6, 0.6, 0.5, 1.0]),\n            \"R_target\": 0.08,\n            \"V_max\": 0.012,\n            \"lambda\": LAMBDA,\n            \"tau\": TAU\n        }\n    ]\n\n    results = []\n    for case_params in test_cases:\n        violation = solve_one_case(case_params, RHO_SEQUENCE)\n        # Format to exactly 6 digits after the decimal point\n        results.append(f\"{violation:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\ndef get_constraint_values(w, params):\n    \"\"\"Calculates the values of all constraint functions.\"\"\"\n    mu, Sigma, u, R_target, V_max = params['mu'], params['Sigma'], params['u'], params['R_target'], params['V_max']\n    \n    g_lo = -w\n    g_up = w - u\n    g_ret = R_target - mu.dot(w)\n    g_var = w.dot(Sigma.dot(w)) - V_max\n    h_bud = np.sum(w) - 1.0\n    \n    return g_lo, g_up, g_ret, g_var, h_bud\n\ndef merit_function(w, rho, params):\n    \"\"\"Calculates the value of the merit function M_rho(w).\"\"\"\n    lam = params['lambda']\n    g_lo, g_up, g_ret, g_var, h_bud = get_constraint_values(w, params)\n    \n    p_lo = np.maximum(0, g_lo)\n    p_up = np.maximum(0, g_up)\n    p_ret = np.maximum(0, g_ret)\n    p_var = np.maximum(0, g_var)\n    \n    penalty_term = np.sum(p_lo**2) + np.sum(p_up**2) + p_ret**2 + p_var**2 + h_bud**2\n    regularization_term = lam * np.sum(w**2)\n    \n    return rho * penalty_term + regularization_term\n\ndef merit_gradient(w, rho, params):\n    \"\"\"Calculates the gradient of the merit function M_rho(w).\"\"\"\n    n, mu, Sigma, lam = params['n'], params['mu'], params['Sigma'], params['lambda']\n    g_lo, g_up, g_ret, g_var, h_bud = get_constraint_values(w, params)\n    \n    p_lo = np.maximum(0, g_lo)\n    p_up = np.maximum(0, g_up)\n    p_ret = np.maximum(0, g_ret)\n    p_var = np.maximum(0, g_var)\n    \n    # Gradient of penalty term for lo/up bounds\n    grad_bounds = p_up - p_lo # component-wise\n    \n    # Gradient of penalty term for return\n    grad_ret = p_ret * (-mu)\n    \n    # Gradient of penalty term for variance\n    grad_var = p_var * (2 * Sigma.dot(w))\n    \n    # Gradient of penalty term for budget\n    grad_bud = h_bud * np.ones(n)\n    \n    # Combine all gradient components\n    grad = 2 * rho * (grad_bounds + grad_ret + grad_var + grad_bud)\n    \n    # Add gradient of regularization term\n    grad += 2 * lam * w\n    \n    return grad\n\ndef calculate_violation(w, params):\n    \"\"\"Calculates the maximum constraint violation vio(w).\"\"\"\n    g_lo, g_up, g_ret, g_var, h_bud = get_constraint_values(w, params)\n    \n    vio_lo = np.max(np.maximum(0, g_lo))\n    vio_up = np.max(np.maximum(0, g_up))\n    vio_ret = np.maximum(0, g_ret)\n    vio_var = np.maximum(0, g_var)\n    vio_bud = np.abs(h_bud)\n    \n    return np.max([vio_lo, vio_up, vio_ret, vio_var, vio_bud])\n\ndef solve_one_case(params, rho_sequence):\n    \"\"\"Solves a single test case using the penalty method.\"\"\"\n    n = params['n']\n    tau = params['tau']\n    w0 = np.ones(n) / n\n    final_violation = -1.0\n    \n    for rho in rho_sequence:\n        res = minimize(\n            fun=merit_function,\n            x0=w0,\n            args=(rho, params),\n            method='BFGS',\n            jac=merit_gradient,\n            options={'gtol': 1e-9} \n        )\n        \n        w_opt = res.x\n        final_violation = calculate_violation(w_opt, params)\n        \n        if final_violation <= tau:\n            break\n        \n        w0 = w_opt # Warm start for the next iteration\n        \n    return final_violation\n\nif __name__ == '__main__':\n    solve()\n```"}, {"introduction": "真实世界的决策往往涉及复杂的权衡，而不仅仅是满足硬性约束。这个综合性练习将挑战你运用多种工具来构建一个精细的优化模型，模拟一个学生在学习效益、时间限制和“填鸭式学习”的负面影响之间的权衡。你将结合使用对数壁垒函数来处理严格的边界约束，以及不同类型的罚函数来处理软约束和不期望的行为，从而掌握将这些方法灵活组合以解决复杂经济问题的能力 [@problem_id:2374575]。", "id": "2374575", "problem": "考虑一个时间分配问题，学生选择每日学习时长，以平衡学习效益与填鸭式学习的成本。设决策变量为每日学习时长 $x_t$，其中 $t \\in \\{1,\\dots,T\\}$，且每天 $x_t \\in (0,M)$。学生的每日学习效益被建模为一个凹的增函数 $u_t(x_t) = b_t \\log(1 + x_t)$，其中 $b_t > 0$ 代表第 $t$ 天的生产力权重。一天的填鸭式学习会受到一个凸的“平方合页”(squared hinge)惩罚，形式为 $\\rho \\max\\{0, x_t - h\\}^2$，其中 $h > 0$ 是填鸭式学习的阈值，$\\rho > 0$ 是惩罚权重。\n\n为强制执行定义域 $x_t \\in (0,M)$（对每个 $t$），使用参数为 $\\mu > 0$ 的对数障碍函数；为鼓励总学习目标 $\\sum_{t=1}^T x_t \\approx S$，使用权重为 $\\eta > 0$ 的二次惩罚。定义非约束最小化目标\n$$\nf(x) \\;=\\; -\\sum_{t=1}^T b_t \\log(1 + x_t) \\;+\\; \\rho \\sum_{t=1}^T \\max\\{0, x_t - h\\}^2 \\;-\\; \\mu \\sum_{t=1}^T \\left[\\log x_t + \\log(M - x_t)\\right] \\;+\\; \\eta\\left(\\sum_{t=1}^T x_t - S\\right)^2,\n$$\n并求解\n$$\n\\min_{x \\in (0,M)^T} \\; f(x).\n$$\n\n您的任务是编写一个完整的、可运行的程序，对于下面的每个测试用例，该程序近似最小化关于 $x = (x_1,\\dots,x_T)$ 的 $f(x)$，并返回得到的每日时长向量。程序必须实现一种基于梯度的方法，并带有线搜索，通过严格保持在界限内来维持可行性 $x_t \\in (0,M)$。当梯度的无穷范数低于 $10^{-6}$ 或达到 $20000$ 次迭代上限时，程序应终止，以先到者为准。为保证数值稳定性，您可以假设一个内部边界，即强制 $x_t \\in [\\varepsilon, M - \\varepsilon]$，其中 $\\varepsilon$ 是一个小的正数 $\\varepsilon \\in (0,10^{-6}]$。\n\n对于每个测试用例，输出优化后的向量 $x^\\star$，四舍五入到小数点后4位。最终输出必须是单行，包含一个列表的列表，每个内部列表对应一个测试用例，并按所给顺序排列。不应打印任何额外文本。\n\n测试套件（每个用例指定 $(T, b, S, M, h, \\mu, \\rho, \\eta)$）：\n- 用例 1：$T = 7$，$b = [1,1,1,1,1,1,1]$，$S = 21$，$M = 10$，$h = 4$，$\\mu = 10^{-3}$，$\\rho = 1.0$，$\\eta = 5.0$。\n- 用例 2：$T = 5$，$b = [1.0,1.5,0.8,1.2,0.7]$，$S = 25$，$M = 10$，$h = 5$，$\\mu = 10^{-3}$，$\\rho = 0.5$，$\\eta = 10.0$。\n- 用例 3：$T = 4$，$b = [1,1,1,1]$，$S = 35$，$M = 10$，$h = 6$，$\\mu = 10^{-6}$，$\\rho = 0.1$，$\\eta = 2.0$。\n- 用例 4：$T = 6$，$b = [0.9,1.4,0.6,1.1,1.3,0.7]$，$S = 30$，$M = 12$，$h = 4$，$\\mu = 10^{-3}$，$\\rho = 5.0$，$\\eta = 15.0$。\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含一个列表的列表形式的结果，每个内部列表包含 $T$ 个优化后的每日时长，四舍五入到小数点后4位，例如 $[[x_{1,1},\\dots,x_{1,T_1}],[x_{2,1},\\dots],\\dots]$，其中 $x_{i,j}$ 表示测试用例 $i$ 中的第 $j$ 天。不需要空格，但允许使用。", "solution": "所述问题是有效的。这是一个基于既定数学原理的适定（well-posed）优化问题。目标是在凸域 $x \\in (0,M)^T$ 上最小化函数 $f(x)$。函数 $f(x)$ 是几项之和。我们来逐一分析。\n学习效益项 $-\\sum_{t=1}^T b_t \\log(1 + x_t)$ 是凸的，因为 $\\log(z)$ 是一个凹函数，这使得 $-\\log(z)$ 成为凸函数，而凸函数之和仍然是凸函数（$b_t > 0$）。\n填鸭式学习惩罚项 $\\rho \\sum_{t=1}^T \\max\\{0, x_t - h\\}^2$ 是凸的。函数 $g(z) = z^2$ 对于 $z \\ge 0$ 是凸的且非递减，而 $h(z) = \\max\\{0, z\\}$ 是凸的。因此，复合函数 $g(h(z))$ 是凸的。\n对数障碍项 $-\\mu \\sum_{t=1}^T [\\log x_t + \\log(M - x_t)]$ 是一个标准的、严格凸的障碍函数，用于强制执行定义域约束。\n总学习目标惩罚项 $\\eta(\\sum_{t=1}^T x_t - S)^2$ 是凸的，因为它是凸二次函数 $z^2$ 与一个仿射函数的复合。\n由于目标函数 $f(x)$ 是凸函数之和，且对数障碍项保证了其严格凸性，因此 $f(x)$ 是一个严格凸函数。在凸集上对严格凸函数进行最小化会得到唯一解。因此，该问题在科学上是合理且适定的。\n\n为解决这个非约束最小化问题，我们将实现一个带有回溯线搜索（backtracking line search）的梯度下降算法。该方法是合适的，因为目标函数 $f(x)$ 在其定义域 $(0,M)^T$ 上是连续可微的。\n\n梯度下降的核心原理是通过沿负梯度方向（即目标函数的最速下降方向）前进一步，来迭代更新当前解 $x^{(k)}$。更新规则为：\n$$\nx^{(k+1)} = x^{(k)} + s_k p^{(k)}\n$$\n其中 $p^{(k)} = -\\nabla f(x^{(k)})$ 是搜索方向，$s_k > 0$ 是步长。\n\n目标函数由下式给出：\n$$\nf(x) = -\\sum_{t=1}^T b_t \\log(1 + x_t) + \\rho \\sum_{t=1}^T \\max\\{0, x_t - h\\}^2 - \\mu \\sum_{t=1}^T \\left[\\log x_t + \\log(M - x_t)\\right] + \\eta\\left(\\sum_{t=1}^T x_t - S\\right)^2\n$$\n为计算搜索方向，我们必须首先推导 $f(x)$ 的梯度 $\\nabla f(x)$。梯度的第 $t$ 个分量 $\\frac{\\partial f}{\\partial x_t}$ 是各项偏导数之和：\n$$\n(\\nabla f(x))_t = \\frac{\\partial}{\\partial x_t}f(x) = -\\frac{b_t}{1 + x_t} + 2\\rho \\max\\{0, x_t - h\\} - \\mu \\left( \\frac{1}{x_t} - \\frac{1}{M - x_t} \\right) + 2\\eta \\left(\\sum_{j=1}^T x_j - S\\right)\n$$\n平方合页项 $\\max\\{0, x_t - h\\}^2$ 关于 $x_t$ 的导数是 $2 \\max\\{0, x_t - h\\}$，它对所有 $x_t$ 都是连续的。\n\n步长 $s_k$ 由回溯线搜索过程确定。这至关重要，原因有二：确保目标函数值在每一步都有充分的下降，以及维持可行性，即将 $x^{(k+1)}$ 保持在定义域 $(0,M)^T$ 内。线搜索从一个初始步长（例如 $s=1$）开始，并以因子 $\\beta \\in (0,1)$ 迭代地减小它，直到满足两个条件：\n1.  **可行性**：新点 $x_{new} = x^{(k)} + s p^{(k)}$ 必须严格位于定义域内部。为了数值稳定性，我们强制 $x_t \\in [\\varepsilon, M - \\varepsilon]$，其中 $\\varepsilon > 0$ 是一个小的常数。\n2.  **Armijo 条件**：该步必须使目标函数有充分的下降。这通过以下条件进行验证：\n    $$\n    f(x^{(k)} + s p^{(k)}) \\le f(x^{(k)}) + \\alpha s (\\nabla f(x^{(k)}))^T p^{(k)}\n    $$\n    其中 $\\alpha \\in (0, 0.5)$ 是一个控制参数。由于 $p^{(k)} = -\\nabla f(x^{(k)})$，该条件简化为 $f(x_{new}) \\le f(x^{(k)}) - \\alpha s ||\\nabla f(x^{(k)})||_2^2$。\n\n算法流程如下：\n1.  初始化 $x^{(0)}$ 为一个可行点，例如，对所有 $t=1,...,T$，$x_t^{(0)} = S/T$，并将其裁剪到可行范围 $[\\varepsilon, M-\\varepsilon]$ 内。设置迭代计数器 $k=0$。\n2.  对于 $k=0, 1, 2, \\dots$ 直至最大迭代次数：\n    a.  计算梯度 $\\nabla f(x^{(k)})$。\n    b.  检查收敛性：如果无穷范数 $||\\nabla f(x^{(k)})||_\\infty$ 低于一个容差 $\\tau$（例如 $10^{-6}$），则终止并返回 $x^{(k)}$。\n    c.  设置搜索方向 $p^{(k)} = -\\nabla f(x^{(k)})$。\n    d.  执行回溯线搜索以找到合适的步长 $s_k$。\n    e.  更新解：$x^{(k+1)} = x^{(k)} + s_k p^{(k)}$。\n3.  如果达到最大迭代次数，算法终止并返回最后计算的解。\n该过程保证收敛到严格凸目标函数的唯一最小化子。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function that processes all test cases.\n    \"\"\"\n    \n    # --- Algorithm Parameters ---\n    MAX_ITER = 20000\n    TOL = 1e-6\n    # Epsilon for numerical stability at boundaries\n    EPS = 1e-7\n    # Backtracking line search parameters\n    ALPHA = 0.3\n    BETA = 0.8\n    # --------------------------\n\n    def objective_function(x, b, S, M, h, mu, rho, eta):\n        \"\"\"\n        Computes the value of the objective function f(x).\n        \"\"\"\n        # Barrier terms implicitly handle domain, but we can return inf for robustness\n        if np.any(x <= 0) or np.any(x >= M):\n            return np.inf\n            \n        term1_benefit = -np.sum(b * np.log(1 + x))\n        term2_cramming = rho * np.sum(np.maximum(0, x - h)**2)\n        term3_barrier = -mu * np.sum(np.log(x) + np.log(M - x))\n        term4_target = eta * (np.sum(x) - S)**2\n        \n        return term1_benefit + term2_cramming + term3_barrier + term4_target\n\n    def gradient(x, b, S, M, h, mu, rho, eta):\n        \"\"\"\n        Computes the gradient of the objective function f(x).\n        \"\"\"\n        grad = np.zeros_like(x)\n        \n        grad_term1 = -b / (1 + x)\n        grad_term2 = 2 * rho * np.maximum(0, x - h)\n        grad_term3 = -mu * (1/x - 1/(M - x))\n        grad_term4 = 2 * eta * (np.sum(x) - S)\n        \n        grad = grad_term1 + grad_term2 + grad_term3 + grad_term4\n        return grad\n\n    def optimize_case(T, b, S, M, h, mu, rho, eta):\n        \"\"\"\n        Performs gradient descent with backtracking line search for a single case.\n        \"\"\"\n        # Initialize x to a feasible starting point\n        x = np.full(T, S / T)\n        x = np.clip(x, EPS, M - EPS)\n        \n        for k in range(MAX_ITER):\n            grad_x = gradient(x, b, S, M, h, mu, rho, eta)\n            \n            # Check for convergence using the infinity norm of the gradient\n            if np.linalg.norm(grad_x, ord=np.inf) < TOL:\n                break\n                \n            # Set search direction (steepest descent)\n            p = -grad_x\n            \n            # --- Backtracking Line Search ---\n            s = 1.0\n            f_x = objective_function(x, b, S, M, h, mu, rho, eta)\n            grad_dot_p = np.dot(grad_x, p)\n\n            while True:\n                x_new = x + s * p\n                \n                # 1. Feasibility Check (stay within stable interior domain)\n                if np.any(x_new <= EPS) or np.any(x_new >= M - EPS):\n                    s *= BETA\n                    continue\n                \n                # 2. Armijo Condition (sufficient decrease)\n                f_x_new = objective_function(x_new, b, S, M, h, mu, rho, eta)\n                if f_x_new <= f_x + ALPHA * s * grad_dot_p:\n                    break  # Step size is acceptable\n                \n                s *= BETA\n                # Failsafe to prevent excessive shrinking of step size\n                if s < 1e-15:\n                    break\n            \n            if s < 1e-15:\n                # If step size becomes too small, terminate to avoid stalling\n                break\n\n            # Update solution\n            x = x + s * p\n            \n        return x\n\n    # --- Test Cases ---\n    test_cases = [\n        # (T, b, S, M, h, mu, rho, eta)\n        (7, np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), 21.0, 10.0, 4.0, 1e-3, 1.0, 5.0),\n        (5, np.array([1.0, 1.5, 0.8, 1.2, 0.7]), 25.0, 10.0, 5.0, 1e-3, 0.5, 10.0),\n        (4, np.array([1.0, 1.0, 1.0, 1.0]), 35.0, 10.0, 6.0, 1e-6, 0.1, 2.0),\n        (6, np.array([0.9, 1.4, 0.6, 1.1, 1.3, 0.7]), 30.0, 12.0, 4.0, 1e-3, 5.0, 15.0),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        T, b, S, M, h, mu, rho, eta = case\n        x_star = optimize_case(T, b, S, M, h, mu, rho, eta)\n        # Round the final vector to 4 decimal places and convert to a list\n        rounded_result = list(np.round(x_star, 4))\n        all_results.append(rounded_result)\n\n    # Format the final output string as a list of lists.\n    # str() on a list produces the desired bracketed, comma-separated format.\n    # Ex: str([1.23, 4.56]) -> '[1.23, 4.56]'\n    output_str = f\"[{','.join(map(str, all_results))}]\"\n    print(output_str)\n\nsolve()\n```"}]}