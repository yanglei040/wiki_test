{"hands_on_practices": [{"introduction": "在我们着手编写算法代码之前，理解其理论基础和局限性至关重要。这个练习 [@problem_id:2421149] 探讨了一种常见的策略：通过最小化误差函数 $(g(x)-c)^2$ 来求解方程 $g(x)=c$。通过分析这种方法，你将深刻理解单峰性（unimodality）对于黄金分割法成功收敛的必要性，并学会识别该算法可能失败的潜在陷阱。", "id": "2421149", "problem": "一位计算工程领域的工程师需要在一个闭区间 $[a,b]$ 上求解标量方程 $g(x)=c$。为此，该工程师建议使用黄金分割搜索法 (GSS) 在 $[a,b]$上最小化残差平方 $f(x)=(g(x)-c)^2$。假设 $g$ 在 $[a,b]$ 上连续，并在 $(a,b)$ 上至少一次可微。选择所有关于此方法的有效性及其与局部最小值相关的陷阱的正确陈述。\n\nA. 如果 $g$ 在 $[a,b]$ 上是连续且严格单调的，并且 $c\\in g([a,b])$，那么 $f(x)$ 在 $[a,b]$ 上是单峰的，在 $g(x)=c$ 的唯一解处有一个唯一的全局最小值点，因此在任何包含该解的区间 $[a,b]$ 上对 $f$ 应用GSS将返回一个根。\n\nB. $f(x)$ 唯一的驻点是 $g(x)=c$ 的解。\n\nC. 如果 $g$ 在 $[a,b]$ 上非单调，那么 $f(x)$ 可以在 $g'(x)=0$ 且 $g(x)\\neq c$ 的点上存在局部最小值，因此在这样的区间上对 $f$ 运行 GSS 可能会收敛到一个非根的局部最小值点，这取决于初始区间。\n\nD. 如果 $c\\notin g([a,b])$，那么在 $[a,b]$ 上用 GSS 最小化 $f$ 不会产生 $g(x)=c$ 的根；相反，它将收敛到 $[a,b]$ 中的一个点（可能是端点），其残差不为零。\n\nE. 对于任何可微的 $g$，对残差进行平方会使得 $f(x)$ 在 $[a,b]$上是凸的，因此不存在虚假的局部最小值，并且只要在实数轴上任何地方存在根，GSS 总能找到一个根。", "solution": "评估问题陈述的有效性。\n\n**步骤1：提取已知条件**\n- 待解方程：$g(x) = c$\n- 定义域：闭区间 $[a, b]$\n- 建议方法：最小化函数 $f(x) = (g(x) - c)^2$\n- 优化算法：黄金分割搜索法 (GSS)\n- $g(x)$ 的性质：\n    - 在 $[a, b]$ 上连续\n    - 在 $(a, b)$ 上至少一次可微\n- 任务：评估关于此方法的有效性及其陷阱的陈述。\n\n**步骤2：使用提取的已知条件进行验证**\n- **科学依据：** 该问题描述了数值分析中的一种标准技术：将求根问题重构为最小化问题。函数、概念（连续性、可微性、单调性、单峰性）和算法（GSS）在数学和计算工程中都有明确的定义。该方法在科学上是有效的。\n- **适定性：** 该问题提供了足够的信息，可以根据给定的 $g(x)$ 的性质来分析函数 $f(x)$ 的数学性质。选项中提出的问题是精确的，可以用数学的严谨性来回答。\n- **客观性：** 问题和待评估的陈述是客观的，没有主观论断。它们的正确性可以通过数学证明或反例来确定。\n\n该问题没有违反任何无效性标准。它是科学合理的、适定的、客观的并且可以形式化。\n\n**步骤3：结论和行动**\n问题有效。将推导完整的解答。\n\n**核心原理推导**\n\n该问题建议通过最小化残差平方函数 $f(x) = (g(x) - c)^2$ 来找到 $g(x) = c$ 的根。$f(x)$ 的全局最小值出现在 $f(x) = 0$ 的地方，这当且仅当 $g(x) = c$ 时成立。因此，$f(x)$ 的全局最小值点恰好是 $g(x) = c$ 的根。\n\n黄金分割搜索法 (GSS) 是一种算法，它能保证在一个区间上找到一个函数的最小值，当且仅当该函数在该区间上是**单峰**的。一个函数在一个区间上是单峰的，如果它在该区间内只有一个局部最小值。如果一个函数有多个局部最小值（即不是单峰的），GSS 可能会收敛到一个非全局最小值的局部最小值，这取决于初始搜索区间。\n\n为了理解 GSS 在 $f(x)$ 上的行为，我们必须分析 $f(x)$ 的驻点，这些驻点决定了它的局部最小值和最大值。使用链式法则，$f(x)$ 的一阶导数是：\n$$ f'(x) = 2(g(x) - c) \\cdot g'(x) $$\n$f(x)$ 的驻点是使 $f'(x) = 0$ 的 $x$ 值。这当且仅当：\n$$ g(x) - c = 0 \\quad \\text{或} \\quad g'(x) = 0 $$\n时发生。这表明 $f(x)$ 的驻点由两个集合组成：\n1. $g(x) = c$ 的根。\n2. $g(x)$ 本身的驻点。\n\n后一类点，即 $g'(x)=0$ 但 $g(x) \\neq c$ 的点，可能会在 $f(x)$ 中引入“虚假”的局部最小值，而这些点并不是原方程的根。\n\n要确定一个驻点 $x_0$ 是否为局部最小值，我们可以检查其二阶导数 $f''(x_0)$：\n$$ f''(x) = 2(g'(x))^2 + 2(g(x) - c)g''(x) $$\n在一个驻点 $x_0$ 处，如果 $g'(x_0) = 0$ 且 $g(x_0) \\neq c$，则二阶导数简化为：\n$$ f''(x_0) = 2(g(x_0) - c)g''(x_0) $$\n要使 $x_0$ 成为 $f$ 的局部最小值点，我们需要 $f''(x_0) > 0$。这个条件是可以满足的，如选项 C 的分析所示。\n\n**逐项分析**\n\n**A. 如果 $g$ 在 $[a,b]$ 上是连续且严格单调的，并且 $c\\in g([a,b])$，那么 $f(x)$ 在 $[a,b]$ 上是单峰的，在 $g(x)=c$ 的唯一解处有一个唯一的全局最小值点，因此在任何包含该解的区间 $[a,b]$ 上对 $f$ 应用GSS将返回一个根。**\n\n如果 $g(x)$ 在 $[a,b]$ 上是连续且严格单调的，并且 $c$ 在此区间上属于 $g$ 的值域，那么根据介值定理，在 $[a,b]$ 中保证存在唯一解 $x^*$ 使得 $g(x^*) = c$。在该点，$f(x^*) = (g(x^*) - c)^2 = 0$。由于对所有 $x$ 都有 $f(x) \\ge 0$，所以 $x^*$ 是一个全局最小值点。\n\n因为 $g(x)$ 是严格单调的，$g'(x)$ 在 $(a, b)$ 上符号不变且不为零（可能在不构成 $g$ 局部极值的孤立点上为零）。使 $f'(x) = 2(g(x) - c)g'(x)$ 为零的唯一方式是 $g(x) - c = 0$，这只在 $x = x^*$ 时发生。因此，$f(x)$ 在区间内只有一个驻点。\n我们假设 $g(x)$ 是严格递增的，所以 $g'(x) > 0$。\n- 对于 $x < x^*$，$g(x) < g(x^*) = c$，因此 $g(x) - c < 0$。于是 $f'(x) = 2(\\text{负})(\\text{正}) < 0$。\n- 对于 $x > x^*$，$g(x) > g(x^*) = c$，因此 $g(x) - c > 0$。于是 $f'(x) = 2(\\text{正})(\\text{正}) > 0$。\n这表明 $f(x)$ 在 $x < x^*$ 时递减，在 $x > x^*$ 时递增。因此，$f(x)$ 在 $[a,b]$ 上是单峰的，其唯一最小值点在 $x^*$。GSS 是为单峰函数设计的，将正确地收敛到这个唯一的最小值点。\n结论：**正确**。\n\n**B. $f(x)$ 唯一的驻点是 $g(x)=c$ 的解。**\n\n如上所推导，$f(x)$ 的驻点出现在 $f'(x) = 2(g(x) - c) g'(x) = 0$ 时。当 $g(x) = c$ 或 $g'(x) = 0$ 时，该方程成立。如果存在一个点 $x_0$，使得 $g(x)$ 在该点有局部极值（因此 $g'(x_0) = 0$）且 $g(x_0) \\neq c$，那么 $x_0$ 是 $f(x)$ 的一个驻点，但不是 $g(x) = c$ 的解。例如，设 $g(x) = x^2$ 且 $c=4$。解为 $x=\\pm 2$。需要最小化的函数是 $f(x) = (x^2 - 4)^2$。其导数为 $f'(x) = 2(x^2 - 4)(2x) = 4x(x-2)(x+2)$。驻点为 $x=0$、$x=2$ 和 $x=-2$。点 $x=0$ 是 $f(x)$ 的一个驻点，因为 $g'(0)=0$，但 $g(0) = 0 \\neq 4$，所以它不是一个解。\n结论：**不正确**。\n\n**C. 如果 $g$ 在 $[a,b]$ 上非单调，那么 $f(x)$ 可以在 $g'(x)=0$ 且 $g(x)\\neq c$ 的点上存在局部最小值，因此在这样的区间上对 $f$ 运行 GSS 可能会收敛到一个非根的局部最小值点，这取决于初始区间。**\n\n如果 $g(x)$ 在 $[a,b]$ 上非单调，则在 $(a,b)$ 中必然存在至少一个点 $x_0$ 使得 $g'(x_0)=0$。这个点是 $f(x)$ 的一个驻点。我们必须检查它是否可能是一个局部最小值。如一般推导中所示，$f''(x_0) = 2(g(x_0) - c)g''(x_0)$。我们可以使它为正。\n考虑 $g(x) = x^3 - 4x$。那么 $g'(x) = 3x^2 - 4$，在 $x_0 = \\pm 2/\\sqrt{3}$ 处为零。我们选择 $x_0 = 2/\\sqrt{3}$。在此点，$g(x)$ 有一个局部最小值：$g(2/\\sqrt{3}) = (8/3\\sqrt{3}) - (8/\\sqrt{3}) = -16/(3\\sqrt{3})$ 并且 $g''(x) = 6x$，所以 $g''(2/\\sqrt{3}) = 12/\\sqrt{3} > 0$。\n我们找一个 $c < g(x_0)$ 的根。例如，令 $c = -6$。方程为 $x^3-4x = -6$。需要最小化的函数是 $f(x)=(x^3-4x+6)^2$。存在一个实数根 $x^*$（例如，$g(-3)=-15$, $g(-2)=0$，所以根在-3和-2之间）。\n在 $g(x)$ 的驻点 $x_0=2/\\sqrt{3}$ 处，我们有 $g(x_0) = -16/(3\\sqrt{3}) \\approx -3.078$，这不等于 $c=-6$。在 $x_0$ 处 $f(x)$ 的二阶导数是 $f''(x_0) = 2(g(x_0)-c)g''(x_0) = 2(-16/(3\\sqrt{3}) - (-6)) (12/\\sqrt{3}) = 2(-3.078+6)(6.928) > 0$。\n所以，$x_0 = 2/\\sqrt{3}$ 是 $f(x)$ 的一个局部最小值点。由于 $f(x_0) = (g(x_0)-c)^2 > 0$ 而全局最小值为 $f(x^*)=0$，因此 $f(x)$ 不是单峰的。如果 GSS 从一个包含 $x_0$ 但不包含 $x^*$ 的区间（例如 $[0,2]$）开始，它可能会收敛到局部最小值点 $x_0$，而这个点不是 $g(x)=c$ 的根。\n结论：**正确**。\n\n**D. 如果 $c\\notin g([a,b])$，那么在 $[a,b]$ 上用 GSS 最小化 $f$ 不会产生 $g(x)=c$ 的根；相反，它将收敛到 $[a,b]$ 中的一个点（可能是端点），其残差不为零。**\n\n前提是在区间 $[a,b]$ 上，$c$ 不在 $g(x)$ 的值域内。这意味着在 $[a,b]$ 中不存在 $x$ 使得 $g(x) = c$。因此，在区间内不存在根。函数 $f(x) = (g(x) - c)^2$ 因此对所有 $x \\in [a,b]$ 都是严格正的。作为一个在紧集 $[a,b]$ 上的连续函数，$f(x)$ 必须在该区间上达到一个全局最小值，并且这个最小值将大于零。这个最小值出现的点 $x_{min}$ 代表了在 $[a,b]$ 上对解的最佳“最小二乘”近似。\n由于不存在根，GSS 无法产生一个根。它会做的是搜索 $f(x)$ 的最小值。GSS 迭代地缩小搜索区间。假设它收敛（随着区间缩小，它会的），它将收敛到初始区间内对应于 $f(x)$ 最小值的一个点。由于 $f(x)$ 的最小值是严格正的，找到的点将具有非零的残差，即 $f(x_{min}) > 0$。如果 $f(x)$ 在 $[a,b]$ 上是单调的，这样的最小值可能出现在端点。该陈述准确地描述了结果是一个最小二乘解，而不是一个根。\n结论：**正确**。\n\n**E. 对于任何可微的 $g$，对残差进行平方会使得 $f(x)$ 在 $[a,b]$上是凸的，因此不存在虚假的局部最小值，并且只要在实数轴上任何地方存在根，GSS 总能找到一个根。**\n\n这个陈述有几个不正确的论点。\n1. **凸性**：$f(x)$ 通常不是凸的。如上所示，$f''(x) = 2(g'(x))^2 + 2(g(x) - c)g''(x)$。第二项 $2(g(x) - c)g''(x)$ 可以是负的，并且其绝对值可能大到足以使 $f''(x) < 0$。举一个反例，设 $g(x) = \\sin(x)$ 且 $c=0$。那么 $f(x) = \\sin^2(x)$。$f''(x) = 2\\cos(2x)$，当 $x \\in (\\pi/4, 3\\pi/4)$ 时为负，所以 $f(x)$ 在此区间上不是凸的。\n2. **无虚假局部最小值**：如选项 C 的论证所示，当 $g(x)$ 非单调时，虚假（非根）的局部最小值可以也确实存在。凸性是单峰性的一个充分（但非必要）条件。由于 $f(x)$ 并非总是凸的，所以不存在虚假最小值的说法是错误的。\n3. **总能找到任何地方的根**：GSS 是一种局部搜索方法，它被限制在其初始搜索区间 $[a, b]$ 内。它没有机制去寻找位于该区间之外的根。\n这个陈述的每一部分都是错误的。\n结论：**不正确**。", "answer": "$$\\boxed{ACD}$$"}, {"introduction": "现在，让我们将理论付诸实践，从零开始实现黄金分割搜索算法。这个练习 [@problem_id:2398550] 将指导你完成一个经典应用：通过最大化其对数密度函数，来寻找贝塔（Beta）概率分布的众数（mode，即最可能出现的值）。这将巩固你对黄金分割法如何在不需要任何导数信息的情况下，逐步缩小范围以寻找最优点位的理解。", "id": "2398550", "problem": "您的任务是实现一个黄金分割搜索（GSS）程序，以数值计算在一维计量经济学情景中出现的单峰概率密度函数的众数。在许多计算经济学和金融问题中，需要通过最大化一维似然或后验密度，来定位参数模型下某一参数或潜变量的最可能值。对于参数 $ \\alpha $ 和 $ \\beta $ 满足 $ \\alpha > 1 $ 且 $ \\beta > 1 $ 的贝塔分布，其概率密度函数的支撑集在区间 $ [0,1] $ 上，并且是单峰的。众数是密度函数达到其最大值的点 $ x^\\star \\in [0,1] $。\n\n使用的基本原理：\n- 众数的定义：对于闭区间 $ [a,b] $ 上的密度函数 $ f(x) $，众数是一个点 $ x^\\star \\in [a,b] $，使得对于所有 $ x \\in [a,b] $，都有 $ f(x^\\star) \\ge f(x) $。\n- 单峰性：如果存在唯一的 $ x^\\star \\in (a,b) $，使得函数 $ f $ 在 $ [a,x^\\star] $ 上严格递增，并在 $ [x^\\star,b] $ 上严格递减，则称 $ f $ 在 $ [a,b] $ 上是单峰的。\n- 单调变换保持 argmax 不变：如果 $ g $ 是严格递增函数，且 $ \\ell(x) = g(f(x)) $，那么 $ \\arg\\max_{x \\in [a,b]} f(x) = \\arg\\max_{x \\in [a,b]} \\ell(x) $。\n\n任务：\n1. 从基本原理出发，实现一个鲁棒的黄金分割搜索（GSS）算法，用于在闭区间 $ [a,b] $ 上最大化一个连续单峰函数，且不使用任何导数信息。您的设计必须确保数值稳定性，并避免在定义域之外对函数求值。\n2. 将您的 GSS 实现应用于参数为 $ \\alpha > 1 $，$ \\beta > 1 $ 的贝塔分布。为避免数值下溢并移除不必要的常数，请最大化对数密度（可相差一个加性常数）：\n   - 对于 $ x \\in (0,1) $，定义 $ \\ell(x) = (\\alpha - 1)\\log(x) + (\\beta - 1)\\log(1 - x) $。注意，减去 $ \\log B(\\alpha,\\beta) $ 是不必要的，因为它不影响最大值点。\n   - 由于 $ \\log(0) $ 未定义，请将搜索限制在闭区间 $ [\\varepsilon, 1 - \\varepsilon] $ 内，其中 $ \\varepsilon = 10^{-12} $。\n3. 使用基于绝对区间宽度的终止规则：当 $ b - a \\le \\tau $ 时停止，其中 $ \\tau $ 是给定的容差。返回中点 $ (a + b)/2 $ 作为数值最大值点。\n\n不涉及角度单位。没有物理单位。所有数值输出必须是浮点数。\n\n测试套组：\n您必须在以下五个参数集上评估您的实现，每个参数集都定义了一个单峰贝塔分布：\n- 情况 $ 1 $: $ (\\alpha,\\beta) = (5,2) $。\n- 情况 $ 2 $: $ (\\alpha,\\beta) = (2.5,3.5) $。\n- 情况 $ 3 $: $ (\\alpha,\\beta) = (1.1,1.1) $。\n- 情况 $ 4 $: $ (\\alpha,\\beta) = (20,20) $。\n- 情况 $ 5 $: $ (\\alpha,\\beta) = (1000.5,1.1) $。\n\n覆盖性设计：\n- 情况 $ 1 $ 是一个右偏分布，其内部众数远离边界。\n- 情况 $ 2 $ 是中度偏斜的，用于测试一般性能。\n- 情况 $ 3 $ 近乎平坦但仍是单峰的，用于测试当 $ \\alpha,\\beta \\downarrow 1 $ 时数值的稳定性。\n- 情况 $ 4 $ 是峰值尖锐且对称的，用于测试最大值点附近曲率较高时的收敛性。\n- 情况 $ 5 $ 的众数非常接近右边界，用于测试在支撑集边缘附近的鲁棒性。\n\n实现要求：\n- 搜索区间端点使用 $ \\varepsilon = 10^{-12} $，容差使用 $ \\tau = 10^{-12} $。\n- 所有计算都应以浮点数执行。\n- 每种情况的最终答案应为估计的众数，每个众数都四舍五入到恰好六位小数。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔的结果列表。例如，如果有三个结果 $ r_1 $、$ r_2 $、$ r_3 $，输出格式必须为 $ [r_1,r_2,r_3] $。对于这个问题中的五个测试用例，请打印 $ [m_1,m_2,m_3,m_4,m_5] $，其中 $ m_i $ 是第 $ i $ 个用例的估计众数，每个都四舍五入到六位小数。", "solution": "所述问题已根据科学合理性、形式可指定性和客观性标准进行验证。\n\n**步骤1：提取的已知条件**\n- **目标**：实现黄金分割搜索（GSS）算法，以数值计算单峰概率密度函数的众数。\n- **目标函数**：对于参数 $\\alpha > 1$ 和 $\\beta > 1$，最大化贝塔分布的对数密度函数 $\\ell(x) = (\\alpha - 1)\\log(x) + (\\beta - 1)\\log(1 - x)$。\n- **搜索域**：闭区间 $[\\varepsilon, 1 - \\varepsilon]$，其中 $\\varepsilon = 10^{-12}$。\n- **算法**：黄金分割搜索，从基本原理出发实现，不使用导数信息。\n- **终止标准**：当区间宽度 $b - a$ 小于或等于指定的容差 $\\tau = 10^{-12}$ 时，搜索终止。\n- **算法输出**：最终区间的中点 $(a + b) / 2$。\n- **测试用例（$(\\alpha, \\beta)$ 的参数集）**：\n    1.  $(5, 2)$\n    2.  $(2.5, 3.5)$\n    3.  $(1.1, 1.1)$\n    4.  $(20, 20)$\n    5.  $(1000.5, 1.1)$\n- **输出格式**：单行输出，包含一个用方括号括起来的五个估计众数的逗号分隔列表，每个众数都四舍五入到六位小数。\n\n**步骤2：使用提取的已知条件进行验证**\n- **科学与事实的合理性**：该问题在科学上是合理的。贝塔分布是一种标准的概率分布。对于 $\\alpha > 1$ 和 $\\beta > 1$，其密度在区间 $(0, 1)$ 上确实是单峰的。其众数可由解析式 $x^\\star = (\\alpha - 1) / (\\alpha + \\beta - 2)$ 给出，这证实了内部众数的存在性和唯一性。使用对数密度 $\\ell(x)$ 进行最大化是一种标准且有效的数值技术，因为对数是严格单调递增变换，它能保持最大值点（argmax）的位置不变。黄金分割搜索是寻找单峰函数极值的正确且标准的无导数算法。\n- **适定性**：该问题是适定的。它指定了单峰目标函数、封闭搜索区间、明确的终止条件以及所有必要的参数。这些条件保证了所提出的算法可以收敛到的唯一解的存在。\n- **完整性与一致性**：问题陈述是完整且自洽的。它提供了实现和测试所需的所有数据。所提供的信息中没有矛盾之处。所有测试用例都满足条件 $\\alpha > 1, \\beta > 1$。搜索区间 $[\\varepsilon, 1-\\varepsilon]$ 正确地避免了对数函数在边界 $0$ 和 $1$ 处的奇点。\n\n**步骤3：结论与行动**\n该问题是有效的。这是计算统计学和计量经济学中一个标准且定义明确的问题。可以构建一个严谨的解决方案。\n\n**求解推导**\n\n任务是找到使贝塔分布的概率密度函数（PDF）$f(x; \\alpha, \\beta)$（对于 $x \\in [0, 1]$）最大化的值 $x^\\star$。\n$$\nf(x; \\alpha, \\beta) = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{B(\\alpha, \\beta)}\n$$\n其中 $B(\\alpha, \\beta)$ 是贝塔函数，作为归一化常数。众数 $x^\\star$ 定义为 $x^\\star = \\arg\\max_{x \\in [0,1]} f(x; \\alpha, \\beta)$。\n\n由于对数是严格递增函数，最大化 $f(x)$ 等价于最大化其对数 $\\log(f(x))$。这种变换在数值计算上是有利的，因为它将乘积转换为求和，并减轻了因密度值非常小而可能出现的下溢问题。\n$$\n\\log(f(x; \\alpha, \\beta)) = (\\alpha - 1)\\log(x) + (\\beta - 1)\\log(1-x) - \\log(B(\\alpha, \\beta))\n$$\n项 $\\log(B(\\alpha, \\beta))$ 是一个关于 $x$ 的常数，可以舍弃而不影响最大值点的位置。因此，问题正确地简化为最大化函数 $\\ell(x):$\n$$\n\\ell(x) = (\\alpha - 1)\\log(x) + (\\beta - 1)\\log(1 - x)\n$$\n条件 $\\alpha > 1$ 和 $\\beta > 1$ 确保 $\\ell(x)$ 在区间 $(0, 1)$ 上是严格凹的，因此是单峰的。该函数在 $x=0$ 和 $x=1$ 处未定义，因此搜索被正确地限制在一个稍小的闭区间 $[\\varepsilon, 1 - \\varepsilon]$ 内，其中 $\\varepsilon$ 是一个小的正常数。\n\n黄金分割搜索（GSS）是一种迭代算法，旨在寻找给定区间上单峰函数的极值。其主要优点是无需导数和保证线性的收敛速度。该算法通过维护一个已知包含最大值点的区间 $[a, b]$ 来工作。\n\n该算法的核心依赖于黄金比例 $\\phi = \\frac{1 + \\sqrt{5}}{2} \\approx 1.618034$。其倒数为 $\\psi = 1/\\phi = \\frac{\\sqrt{5} - 1}{2} \\approx 0.618034$。在每一步中，在当前区间 $[a, b]$ 内选择两个内部点 $c$ 和 $d$，使得 $a < c < d < b$。这些点被对称地放置以保持黄金比例：\n$$\nc = a + (1-\\psi)(b-a) = a + \\psi^2(b-a) \\approx a + 0.382(b-a)\n$$\n$$\nd = a + \\psi(b-a) \\approx a + 0.618(b-a)\n$$\n在这些点上对函数 $\\ell(x)$ 求值，得到 $\\ell(c)$ 和 $\\ell(d)$。根据比较结果，缩小搜索区间：\n1.  如果 $\\ell(c) > \\ell(d)$，根据单峰性，最大值点必定位于区间 $[a, d]$ 内。因此区间更新为：$[a', b'] = [a, d]$。\n2.  如果 $\\ell(d) \\ge \\ell(c)$，最大值点必定位于区间 $[c, b]$ 内。因此区间更新为：$[a', b'] = [c, b]$。\n\nGSS 的一个关键特性是其效率。当区间缩小时，旧的内部点之一会成为新区间的一个内部点，从而每次迭代节省一次函数求值。\n- 情况1：如果新区间是 $[a, d]$，新的内部点将是 $c' = a + \\psi^2(d-a)$ 和 $d' = a + \\psi(d-a)$。可以证明，旧点 $c$ 变成了新点 $d'$，即 $d' = a + \\psi(d-a) = a + \\psi \\cdot \\psi(b-a) = a + \\psi^2(b-a) = c$。因此，我们设置 $b \\leftarrow d$，$d \\leftarrow c$，并且只需要计算新的 $c$。\n- 情况2：如果新区间是 $[c, b]$，旧点 $d$ 变成了新点 $c'$。因此，我们设置 $a \\leftarrow c$，$c \\leftarrow d$，并且只需要计算新的 $d$。\n\n这个迭代过程持续进行，直到区间宽度 $b - a$ 小于指定的容差 $\\tau$。最大值点的最终估计值是最终区间的中点 $(a + b)/2$。\n\n该算法实现如下：\n1.  初始化搜索区间 $[a, b] = [\\varepsilon, 1 - \\varepsilon]$，其中 $\\varepsilon = 10^{-12}$。\n2.  定义常数 $\\psi = (\\sqrt{5} - 1)/2$ 和 $\\psi^2$。\n3.  计算初始内部点 $c = a + \\psi^2(b-a)$ 和 $d = a + \\psi(b-a)$。\n4.  对函数 $\\ell(c)$ 和 $\\ell(d)$ 求值。\n5.  进入一个循环，只要 $b - a > \\tau$ 就继续。\n6.  在循环内部，比较 $\\ell(c)$ 和 $\\ell(d)$ 并如上所述缩小区间 $[a,b]$，重用一个点及其函数值，并且只计算一个新点及其函数值。\n7.  循环终止后，返回 $(a+b)/2$ 作为结果。\n此过程将应用于所提供的五个测试用例中的每一个。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the mode of Beta distributions using Golden-Section Search.\n    \n    This function implements the entire process as specified:\n    1. Defines the test cases for Beta distribution parameters (alpha, beta).\n    2. Uses a robust Golden-Section Search (GSS) implementation to find the mode.\n    3. The GSS maximizes the log-density function to ensure numerical stability.\n    4. Collects the results, formats them as required, and prints them.\n    \"\"\"\n\n    def golden_section_search(f, a, b, tol=1e-12):\n        \"\"\"\n        Finds the maximum of a unimodal function f on a closed interval [a, b]\n        using the Golden-Section Search algorithm.\n\n        Args:\n            f: The unimodal function to maximize.\n            a: The lower bound of the interval.\n            b: The upper bound of the interval.\n            tol: The tolerance for the interval width to terminate the search.\n\n        Returns:\n            The estimated x-value of the maximum.\n        \"\"\"\n        # Golden ratio constants\n        inv_phi = (np.sqrt(5) - 1) / 2  # 1/phi, approx 0.618\n        inv_phi_sq = inv_phi**2         # 1/phi^2, approx 0.382\n\n        # Initialize the interior points\n        h = b - a\n        c = a + inv_phi_sq * h\n        d = a + inv_phi * h\n        \n        # Evaluate function at interior points\n        f_c = f(c)\n        f_d = f(d)\n\n        while (b - a) > tol:\n            if f_c > f_d:\n                # The maximum is in the interval [a, d]\n                b = d\n                d = c\n                f_d = f_c\n                h = b - a\n                c = a + inv_phi_sq * h\n                f_c = f(c)\n            else:\n                # The maximum is in the interval [c, b]\n                a = c\n                c = d\n                f_c = f_d\n                h = b - a\n                d = a + inv_phi * h\n                f_d = f(d)\n        \n        # Return the midpoint of the final interval\n        return (a + b) / 2\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (5, 2),        # Case 1\n        (2.5, 3.5),    # Case 2\n        (1.1, 1.1),    # Case 3\n        (20, 20),      # Case 4\n        (1000.5, 1.1)  # Case 5\n    ]\n\n    # Constants for the search\n    epsilon = 1e-12\n    tolerance = 1e-12\n    \n    search_interval_a = epsilon\n    search_interval_b = 1 - epsilon\n    \n    results = []\n    \n    for alpha, beta in test_cases:\n        # Define the log-density function (up to an additive constant)\n        # for the Beta distribution with parameters alpha and beta.\n        # This is the function to be maximized.\n        log_density = lambda x: (alpha - 1) * np.log(x) + (beta - 1) * np.log(1 - x)\n        \n        # Find the mode using Golden-Section Search\n        mode_estimate = golden_section_search(\n            log_density, \n            search_interval_a, \n            search_interval_b, \n            tolerance\n        )\n        \n        results.append(mode_estimate)\n\n    # Final print statement in the exact required format.\n    # Each result is rounded to six decimal places.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```"}, {"introduction": "最后的这个实践 [@problem_id:2398577] 将在一个复杂的真实世界金融工程场景中，展示黄金分割搜索的强大威力。你将运用你实现的黄金分割搜索算法，来校准期权定价的基石——Merton跳跃扩散模型中的一个关键参数。此任务突显了数值优化在使理论模型与市场数据对齐这一量化金融基本活动中的不可或缺性。", "id": "2398577", "problem": "编写一个完整、可运行的程序，该程序使用黄金分割搜索 (Golden-Section Search, GSS) 算法，通过最小化模型价格与价外欧式看涨期权的合成市场价格之间的定价误差平方和，来校准 Merton 跳跃-扩散模型中的跳跃强度参数 $\\lambda$。您的程序必须从第一性原理出发实现定价模型和单变量优化器，并且不得依赖任何外部优化器。\n\n基本原理：\n- 在风险中性测度下，行权价为 $K$、到期日为 $T$ 的欧式看涨期权价格由风险中性期望 $C = e^{-r T} \\mathbb{E}\\left[(S_T - K)^{+}\\right]$ 给出。\n- 在 Merton 跳跃-扩散模型中，资产在风险中性测度下的动态过程为\n$$\n\\frac{dS_t}{S_{t^-}} = \\left(r - q - \\lambda k\\right)\\,dt + \\sigma\\, dW_t + (J - 1)\\, dN_t,\n$$\n其中 $r$ 是连续复利无风险利率，$q$ 是连续股息率，$\\sigma$ 是扩散波动率，$N_t$ 是强度为 $\\lambda$ 的泊松过程，$J$ 是跳跃幅度，且 $\\ln J \\sim \\mathcal{N}(\\mu_J,\\sigma_J^2)$。跳跃补偿项为 $k = \\mathbb{E}[J - 1] = e^{\\mu_J + \\tfrac{1}{2}\\sigma_J^2} - 1$。\n- 以 $N_T = n$ 为条件，可以得到对数正态分布的泊松混合，从而得出看涨期权价格的封闭式混合表示，形式为 Black–Scholes 项的加权和。\n\n需要实现的定价模型：\n- 定义 $k = e^{\\mu_J + \\tfrac{1}{2}\\sigma_J^2} - 1$，有效净漂移 $b(\\lambda) = r - q - \\lambda k$，以及每次跳跃的缩放因子 $s_J = 1 + k = e^{\\mu_J + \\tfrac{1}{2}\\sigma_J^2}$。\n- 对每个非负整数 $n$，定义条件方差参数\n$$\n\\sigma_n = \\sqrt{\\sigma^2 + \\frac{n\\,\\sigma_J^2}{T}},\n$$\n和调整后的即期价格\n$$\nS_n = S_0\\, s_J^{\\,n}.\n$$\n- 泊松权重为\n$$\n\\pi_n(\\lambda) = e^{-\\lambda T}\\frac{(\\lambda T)^n}{n!}.\n$$\n- 具有有效净漂移 $b(\\lambda)$ 的 Black–Scholes (BS) 看涨期权价格为\n$$\nC_{\\text{BS}}(S,K,r,q,\\sigma_n,T;b) = S\\,e^{-qT}\\,\\Phi(d_1) - K\\,e^{-rT}\\,\\Phi(d_2),\n$$\n其中\n$$\nd_1 = \\frac{\\ln\\left(\\frac{S}{K}\\right) + \\left(b + \\tfrac{1}{2}\\sigma_n^2\\right)T}{\\sigma_n \\sqrt{T}}, \\quad d_2 = d_1 - \\sigma_n \\sqrt{T},\n$$\n$\\Phi(\\cdot)$ 是标准正态累积分布函数。\n- Merton 看涨期权价格为\n$$\nC_{\\text{Merton}}(\\lambda; S_0, K, r, q, \\sigma, \\mu_J, \\sigma_J, T) = \\sum_{n=0}^{\\infty} \\pi_n(\\lambda)\\, C_{\\text{BS}}(S_n, K, r, q, \\sigma_n, T; b(\\lambda)).\n$$\n- 对于数值实现，通过以下方式截断无穷级数：\n  - 对 $n = 0,1,2,\\dots$ 进行求和，直到增量泊松权重 $\\pi_n(\\lambda)$ 低于 $10^{-12}$，或者\n  - 达到硬上限 $n_{\\max} = 50$，\n  以先发生者为准。\n\n校准目标：\n- 给定一组价外行权价 $\\{K_i\\}_{i=1}^m$ 和相应的市场看涨期权价格 $\\{C^{\\text{mkt}}_i\\}_{i=1}^m$，定义目标函数\n$$\nJ(\\lambda) = \\sum_{i=1}^m \\left( C_{\\text{Merton}}(\\lambda; S_0, K_i, r, q, \\sigma, \\mu_J, \\sigma_J, T) - C^{\\text{mkt}}_i \\right)^2.\n$$\n- 通过使用黄金分割搜索在闭区间 $\\lambda \\in [0, 3]$ 上最小化 $J(\\lambda)$ 来校准 $\\lambda$。当区间长度小于 $10^{-6}$ 或迭代次数达到 $200$ 次后终止，以先发生者为准。\n\n数值细节：\n- 使用 $\\Phi(x) = \\tfrac{1}{2}\\left(1 + \\operatorname{erf}\\left(\\tfrac{x}{\\sqrt{2}}\\right)\\right)$。\n- 所有期权均为欧式看涨期权，且测试套件中的所有行权价均为严格价外：$K > S_0$。\n- 不得使用任何随机性；所有数值必须确定性地计算。\n\n测试套件：\n对于以下每种情况，首先使用给定的“真实”$\\lambda$ 和指定的数值设置评估 Merton 价格，以生成合成的市场价格。然后，舍弃该真实值，并应用您的校准程序从合成的市场价格中恢复 $\\widehat{\\lambda}$。\n\n- 情况 A (理想路径)：\n  - $S_0 = 100.0$, $r = 0.02$, $q = 0.0$, $T = 0.75$,\n  - $\\sigma = 0.20$, $\\mu_J = -0.10$, $\\sigma_J = 0.25$,\n  - 行权价 $K \\in \\{105.0, 110.0, 120.0\\}$,\n  - 真实 $\\lambda_{\\text{true}} = 0.60$.\n\n- 情况 B (边界情况，无跳跃)：\n  - $S_0 = 100.0$, $r = 0.01$, $q = 0.0$, $T = 1.00$,\n  - $\\sigma = 0.15$, $\\mu_J = -0.20$, $\\sigma_J = 0.30$,\n  - 行权价 $K \\in \\{102.0, 110.0, 125.0\\}$,\n  - 真实 $\\lambda_{\\text{true}} = 0.00$.\n\n- 情况 C (更高跳跃活动性)：\n  - $S_0 = 100.0$, $r = 0.03$, $q = 0.0$, $T = 2.00$,\n  - $\\sigma = 0.18$, $\\mu_J = 0.05$, $\\sigma_J = 0.20$,\n  - 行权价 $K \\in \\{105.0, 115.0, 130.0, 150.0\\}$,\n  - 真实 $\\lambda_{\\text{true}} = 1.20$.\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含三种情况下校准后的强度，形式为逗号分隔的列表并用方括号括起，每个值按 A、B、C 的顺序四舍五入到六位小数。例如，输出必须如下所示\n$$\n[\\widehat{\\lambda}_A,\\widehat{\\lambda}_B,\\widehat{\\lambda}_C],\n$$\n其中每个 $\\widehat{\\lambda}$ 都四舍五入到 $6$ 位小数（无单位）。", "solution": "该问题已经过严格验证，被认为是有效的。其公式科学地基于 Merton 跳跃-扩散模型，这是金融工程领域的标准模型。该问题的陈述非常清晰，为确定性优化任务提供了一套完整且内部一致的定义、参数和数值程序。目标以数学精度陈述，没有歧义或主观内容。获得唯一解所需的所有组件均已提供。\n\n任务是校准 Merton 跳跃-扩散模型的跳跃强度参数 $\\lambda$。这通过最小化一个目标函数 $J(\\lambda)$ 来完成，该函数代表由模型生成的期权价格与一组合成的市场价格之间的差异平方和。优化被限制在区间 $\\lambda \\in [0, 3]$ 内，并且必须使用黄金分割搜索 (GSS) 算法执行，且算法需从第一性原理实现。\n\n问题的核心涉及两个主要组件的实现：Merton 定价模型和 GSS 优化器。\n\n首先，我们按照规定实现欧式看涨期权的定价模型。Merton 价格 $C_{\\text{Merton}}$ 是 Black-Scholes 类型期权价格的加权和，这些期权价格以期权有效期 $T$ 内发生的跳跃次数 $n$ 为条件。价格由下式给出：\n$$\nC_{\\text{Merton}}(\\lambda) = \\sum_{n=0}^{\\infty} \\pi_n(\\lambda)\\, C_{\\text{BS}}(S_n, K, r, q, \\sigma_n, T; b(\\lambda))\n$$\n泊松权重 $\\pi_n(\\lambda)$ 代表发生 $n$ 次跳跃的概率，为：\n$$\n\\pi_n(\\lambda) = e^{-\\lambda T}\\frac{(\\lambda T)^n}{n!}\n$$\n条件 Black-Scholes 成分 $C_{\\text{BS}}$ 是为调整后的即期价格 $S_n = S_0\\, s_J^{\\,n}$ 和条件波动率 $\\sigma_n = \\sqrt{\\sigma^2 + n\\,\\sigma_J^2/T}$ 定义的。每次跳跃的缩放因子为 $s_J = e^{\\mu_J + \\frac{1}{2}\\sigma_J^2}$。该成分的价格由下式给出：\n$$\nC_{\\text{BS}} = S_n\\,e^{-qT}\\,\\Phi(d_1) - K\\,e^{-rT}\\,\\Phi(d_2)\n$$\n其参数 $d_1$ 和 $d_2$ 依赖于有效净漂移 $b(\\lambda) = r - q - \\lambda k$，其中 $k = s_J - 1$ 。$d_1$ 的具体公式为：\n$$\nd_1 = \\frac{\\ln\\left(\\frac{S_n}{K}\\right) + \\left(b(\\lambda) + \\tfrac{1}{2}\\sigma_n^2\\right)T}{\\sigma_n \\sqrt{T}}\n$$\n且 $d_2 = d_1 - \\sigma_n \\sqrt{T}$。标准正态累积分布函数 $\\Phi(\\cdot)$ 使用误差函数 $\\operatorname{erf}(\\cdot)$ 计算，即 $\\Phi(x) = \\frac{1}{2}\\left(1 + \\operatorname{erf}\\left(\\frac{x}{\\sqrt{2}}\\right)\\right)$。在数值实现中，无穷级数被截断。求和从 $n=0, 1, 2, \\dots$ 开始，当项的泊松权重 $\\pi_n(\\lambda)$ 低于容差 $10^{-12}$ 时，或当已包含最多 $n_{\\max}=50$ 项时终止，以先发生者为准。使用稳健的迭代方法 $\\pi_n(\\lambda) = \\pi_{n-1}(\\lambda) \\cdot \\frac{\\lambda T}{n}$ 来计算泊松权重，以避免大阶乘导致的数值溢出。\n\n其次，我们定义校准目标函数 $J(\\lambda)$，作为在一组具有不同行权价 $\\{K_i\\}_{i=1}^m$ 的 $m$ 个期权上的误差平方和 (SSE)：\n$$\nJ(\\lambda) = \\sum_{i=1}^m \\left( C_{\\text{Merton}}(\\lambda; K_i) - C^{\\text{mkt}}_i \\right)^2\n$$\n其中 $C^{\\text{mkt}}_i$ 是给定的合成市场价格。\n\n第三，我们实现黄金分割搜索 (GSS) 算法来最小化 $J(\\lambda)$。GSS 是一种无导数优化方法，用于通过迭代地缩小搜索区间来寻找单峰函数的极值。搜索从区间 $[a, b] = [0, 3]$ 开始。选择两个内部点 $c$ 和 $d$，根据黄金分割比 $\\phi = (1+\\sqrt{5})/2 \\approx 1.618$ 来分割区间。\n$$\nc = b - \\frac{b-a}{\\phi} \\quad \\text{和} \\quad d = a + \\frac{b-a}{\\phi}\n$$\n在这些点上评估目标函数。如果 $J(c) < J(d)$，则最小值必定位于区间 $[a, d]$ 内，因此新的搜索区间变为 $[a, d]$。否则，如果 $J(c) \\ge J(d)$，则新区间变为 $[c, b]$。此过程在每一步都将区间长度缩小因子 $1/\\phi$，保证了收敛性。当区间长度 $|b-a|$ 小于容差 $10^{-6}$ 或达到最大迭代次数 $200$ 次时，算法终止。最终区间的中心点 $(a+b)/2$ 作为校准后的估计值 $\\widehat{\\lambda}$ 返回。\n\n整个过程首先是为每个测试案例生成合成市场价格 $C^{\\text{mkt}}_i$，方法是在给定的“真实”强度 $\\lambda_{\\text{true}}$ 下评估指定的 $C_{\\text{Merton}}$ 函数。然后，概念上舍弃这个真实值，并使用 GSS 算法通过最小化 $J(\\lambda)$ 来找到最能重现这些合成价格的 $\\widehat{\\lambda}$。对所有指定的测试案例重复此过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import erf\n\n# Define a global constant for the Golden Ratio.\nGR = (1 + np.sqrt(5)) / 2\n\ndef norm_cdf(x):\n    \"\"\"\n    Computes the standard normal cumulative distribution function using the error function.\n    All mathematical entities must be in LaTeX: Phi(x) = 1/2 * (1 + erf(x/sqrt(2))).\n    \"\"\"\n    return 0.5 * (1 + erf(x / np.sqrt(2)))\n\ndef merton_bs_component(S, K, r, q, T, sigma_n, b):\n    \"\"\"\n    Computes a single Black-Scholes-like component of the Merton price series,\n    using the specific functional form provided in the problem statement.\n    \"\"\"\n    if sigma_n <= 0 or T <= 0:\n        return np.maximum(0, S - K) if S > K else 0.0\n\n    d1 = (np.log(S / K) + (b + 0.5 * sigma_n**2) * T) / (sigma_n * np.sqrt(T))\n    d2 = d1 - sigma_n * np.sqrt(T)\n    price = S * np.exp(-q * T) * norm_cdf(d1) - K * np.exp(-r * T) * norm_cdf(d2)\n    return price\n\ndef merton_price(lambda_val, S0, K, r, q, T, sigma, mu_J, sigma_J):\n    \"\"\"\n    Calculates the Merton jump-diffusion model call option price. The infinite sum\n    is truncated based on the Poisson weight or a maximum number of terms.\n    \"\"\"\n    # Jump-related parameters, constant with respect to lambda\n    k = np.exp(mu_J + 0.5 * sigma_J**2) - 1\n    s_J = 1 + k\n    \n    # Lambda-dependent effective drift\n    b = r - q - lambda_val * k\n    \n    total_price = 0.0\n    lambda_T = lambda_val * T\n    \n    n_max = 50\n    weight_tol = 1e-12\n\n    # Term for n=0 jumps (pure diffusion component)\n    poisson_weight = np.exp(-lambda_T)\n    sigma_0 = sigma\n    component_price_0 = merton_bs_component(S0, K, r, q, T, sigma_0, b)\n    total_price += poisson_weight * component_price_0\n    \n    # Terms for n=1 to n_max jumps\n    for n in range(1, n_max + 1):\n        poisson_weight *= lambda_T / n\n        if poisson_weight < weight_tol:\n            break\n        \n        sigma_n = np.sqrt(sigma**2 + n * sigma_J**2 / T)\n        S_n = S0 * (s_J**n)\n        \n        component_price = merton_bs_component(S_n, K, r, q, T, sigma_n, b)\n        total_price += poisson_weight * component_price\n        \n    return total_price\n\ndef objective_function(lambda_val, S0, r, q, T, sigma, mu_J, sigma_J, strikes, market_prices):\n    \"\"\"\n    Calculates the sum of squared errors (SSE) between model prices and market prices.\n    This is the function to be minimized.\n    \"\"\"\n    sse = 0.0\n    for i in range(len(strikes)):\n        model_price = merton_price(lambda_val, S0, strikes[i], r, q, T, sigma, mu_J, sigma_J)\n        sse += (model_price - market_prices[i])**2\n    return sse\n\ndef golden_section_search(f, a, b, tol=1e-6, max_iter=200):\n    \"\"\"\n    Performs Golden-Section Search to find the minimum of a univariate function 'f'\n    on the interval [a, b].\n    \"\"\"\n    inv_phi = 1 / GR\n    \n    # Initialize interior points\n    c = b - inv_phi * (b - a)\n    d = a + inv_phi * (b - a)\n    \n    fc = f(c)\n    fd = f(d)\n    \n    for _ in range(max_iter):\n        if abs(b - a) < tol:\n            break\n            \n        if fc < fd:\n            b = d\n            d = c\n            fd = fc\n            c = b - inv_phi * (b - a)\n            fc = f(c)\n        else:\n            a = c\n            c = d\n            fc = fd\n            d = a + inv_phi * (b - a)\n            fd = f(d)\n            \n    return (a + b) / 2\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite, calibrate lambda for each case, and print results.\n    \"\"\"\n    test_cases = [\n        # Case A: Happy path\n        {'S0': 100.0, 'r': 0.02, 'q': 0.0, 'T': 0.75, 'sigma': 0.20,\n         'mu_J': -0.10, 'sigma_J': 0.25, 'strikes': [105.0, 110.0, 120.0],\n         'lambda_true': 0.60},\n        # Case B: Boundary case, no jumps\n        {'S0': 100.0, 'r': 0.01, 'q': 0.0, 'T': 1.00, 'sigma': 0.15,\n         'mu_J': -0.20, 'sigma_J': 0.30, 'strikes': [102.0, 110.0, 125.0],\n         'lambda_true': 0.00},\n        # Case C: Higher jump activity\n        {'S0': 100.0, 'r': 0.03, 'q': 0.0, 'T': 2.00, 'sigma': 0.18,\n         'mu_J': 0.05, 'sigma_J': 0.20, 'strikes': [105.0, 115.0, 130.0, 150.0],\n         'lambda_true': 1.20}\n    ]\n    \n    calibrated_lambdas = []\n    \n    for case in test_cases:\n        # 1. Generate synthetic market prices using the true lambda\n        market_prices = [\n            merton_price(case['lambda_true'], case['S0'], K, case['r'], case['q'], case['T'],\n                         case['sigma'], case['mu_J'], case['sigma_J'])\n            for K in case['strikes']\n        ]\n\n        # 2. Define objective function for this case, capturing all parameters except lambda\n        obj_func = lambda l: objective_function(\n            l, case['S0'], case['r'], case['q'], case['T'], case['sigma'],\n            case['mu_J'], case['sigma_J'], case['strikes'], market_prices\n        )\n\n        # 3. Run Golden-Section Search to find the calibrated lambda\n        lambda_hat = golden_section_search(obj_func, a=0.0, b=3.0, tol=1e-6, max_iter=200)\n        calibrated_lambdas.append(lambda_hat)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{l:.6f}' for l in calibrated_lambdas])}]\")\n\nsolve()\n```"}]}