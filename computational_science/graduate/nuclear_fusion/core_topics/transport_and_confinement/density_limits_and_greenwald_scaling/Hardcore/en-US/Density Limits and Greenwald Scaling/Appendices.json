{
    "hands_on_practices": [
        {
            "introduction": "The Greenwald density limit provides a critical operational boundary for tokamaks, but understanding its physical basis requires linking this global parameter to the internal plasma transport dynamics. This practice challenges you to do just that, by calculating the steady-state density profile that arises from a foundational diffusion-pinch transport model when the line-averaged density is set to the Greenwald limit . You will see firsthand how parameters like collisionality directly influence the density \"peaking,\" providing a concrete link between kinetic theory and macroscopic plasma profiles.",
            "id": "3694558",
            "problem": "A large-aspect-ratio circular tokamak has major radius $R = 1.6 \\, \\text{m}$ and minor radius $a = 0.45 \\, \\text{m}$. The toroidal plasma current is $I_p = 1.30 \\, \\text{MA}$. The electron temperature is spatially uniform at $T_e = 3.0 \\, \\text{keV}$, the effective charge is $Z_{\\text{eff}} = 1$, and the Coulomb logarithm is $\\ln \\Lambda = 17$. Assume axisymmetry and steady-state particle balance with negligible volumetric particle sources in $0 < r < a$.\n\nThe particle flux is modeled by a one-dimensional radial transport closure,\n$$\n\\Gamma_n(r) \\equiv -D \\, \\frac{d n}{d r} + V_p \\, n,\n$$\nwhere $n(r)$ is the density profile, $D > 0$ is a spatially constant turbulent diffusivity, and $V_p$ is an inward neoclassical pinch velocity of the parametric form\n$$\nV_p = - D \\, \\frac{C_p \\, \\nu_*}{a},\n$$\nwith $C_p = 0.9$ a dimensionless constant. The electron collisionality $\\nu_*$ is to be evaluated at mid-radius $r = a/2$ using\n$$\n\\nu_* = \\frac{\\nu_{ei} \\, q \\, R}{\\epsilon^{3/2} \\, v_{\\text{th},e}},\n\\quad\n\\epsilon = \\frac{r}{R},\n\\quad\nv_{\\text{th},e} = \\sqrt{\\frac{2 k_B T_e}{m_e}},\n$$\nwhere $q = 2.2$ is the safety factor, $k_B$ is the Boltzmann constant, $m_e$ is the electron mass, and $\\nu_{ei}$ is the electron-ion collision frequency given in commonly used engineering form by\n$$\n\\nu_{ei} = 2.91 \\times 10^{-6} \\, n_e \\, Z_{\\text{eff}} \\, \\ln \\Lambda \\, T_e^{-3/2},\n$$\nwith $n_e$ in $\\text{cm}^{-3}$ and $T_e$ in $\\text{eV}$. For the purpose of evaluating $\\nu_{ei}$, take $n_e$ equal to the radius-averaged density at the operational limit.\n\nDefine the radius-averaged density by\n$$\nn_{avg} = \\frac{1}{a} \\int_{0}^{a} n(r) \\, dr.\n$$\nAssume the device operates at the empirical density limit so that its radius-averaged density $n_{avg}$ equals the limiting value corresponding to the given $I_p$ and $a$.\n\nUnder these assumptions, derive the steady-state $n(r)$ implied by the transport model, compute the collisionality $\\nu_*$ at $r = a/2$, and determine the central density $n(0)$ consistent with the radius-averaged density being at the operational limit. Express your final answer for $n(0)$ in units of $10^{20} \\, \\text{m}^{-3}$ and round to three significant figures.",
            "solution": "The solution proceeds in four main steps: 1) determine the radius-averaged density $n_{avg}$ from the operational limit; 2) derive the functional form of the density profile $n(r)$ from the steady-state transport equation; 3) calculate the collisionality $\\nu_*$ which sets the profile shape; and 4) use the definition of $n_{avg}$ to find the central density $n(0)$.\n\n**1. Radius-averaged Density at the Operational Limit**\nThe problem states the device operates at the empirical density limit, which is taken to be the Greenwald limit, $n_G$. The radius-averaged density $n_{avg}$ is therefore equal to $n_G$.\n$$ n_{avg} = n_G = \\frac{I_p [\\text{MA}]}{\\pi (a [\\text{m}])^2} $$\nThe units of this formula for $n_G$ are $10^{20} \\, \\text{m}^{-3}$. Given $I_p = 1.30 \\, \\text{MA}$ and $a = 0.45 \\, \\text{m}$:\n$$ n_{avg} = \\frac{1.30}{\\pi (0.45)^2} = \\frac{1.30}{\\pi (0.2025)} \\approx 2.04353 \\times 10^{20} \\, \\text{m}^{-3} $$\n\n**2. Steady-State Density Profile**\nIn steady state with negligible particle sources for $0 < r < a$, the particle continuity equation $\\frac{1}{r}\\frac{d}{dr}(r \\Gamma_n) = 0$ implies that the radial flux $\\Gamma_n(r)$ must be zero. A non-zero flux would lead to a singularity at $r=0$.\n$$ \\Gamma_n(r) = -D \\, \\frac{dn}{dr} + V_p \\, n = 0 $$\nSubstituting the given expression for the pinch velocity, $V_p = - D \\, \\frac{C_p \\, \\nu_*}{a}$:\n$$ -D \\, \\frac{dn}{dr} - D \\, \\frac{C_p \\, \\nu_*}{a} \\, n = 0 $$\nSince $D > 0$, we can divide by $-D$:\n$$ \\frac{dn}{dr} + \\left( \\frac{C_p \\, \\nu_*}{a} \\right) n = 0 $$\nThe problem specifies that $\\nu_*$ is evaluated at $r=a/2$ and used to define the pinch velocity. This implies $\\nu_*$ is treated as a constant for solving the profile shape. Let the constant peaking parameter be $\\alpha_n = \\frac{C_p \\, \\nu_*(a/2)}{a}$. The differential equation is $\\frac{dn}{dr} = -\\alpha_n n$. This is a separable equation with the solution:\n$$ n(r) = n(0) \\exp(-\\alpha_n r) = n(0) \\exp\\left(-\\frac{C_p \\, \\nu_*(a/2)}{a} r\\right) $$\nwhere $n(0)$ is the central density at $r=0$. This is the functional form of the density profile.\n\n**3. Collisionality Calculation**\nTo determine the profile shape, we must compute $\\nu_*(a/2)$. This requires several intermediate calculations.\nFirst, we compute the electron-ion collision frequency, $\\nu_{ei}$. The formula requires $n_e$ in $\\text{cm}^{-3}$ and $T_e$ in $\\text{eV}$. We use $n_e = n_{avg}$.\n$$ n_{avg} \\approx 2.04353 \\times 10^{20} \\, \\text{m}^{-3} = 2.04353 \\times 10^{14} \\, \\text{cm}^{-3} $$\n$$ T_e = 3.0 \\, \\text{keV} = 3000 \\, \\text{eV} $$\nWith $Z_{\\text{eff}} = 1$ and $\\ln\\Lambda = 17$:\n$$ \\nu_{ei} = (2.91 \\times 10^{-6}) \\times (2.04353 \\times 10^{14}) \\times (1) \\times (17) \\times (3000)^{-3/2} $$\n$$ \\nu_{ei} \\approx (1.0108 \\times 10^{10}) \\times (3000)^{-1.5} \\approx (1.0108 \\times 10^{10}) \\times (6.0858 \\times 10^{-6}) \\approx 61517.4 \\, \\text{s}^{-1} $$\nNext, we compute the electron thermal velocity $v_{\\text{th},e}$ with $T_e=3000 \\, \\text{eV}$. Note $k_B T_e = 3000 \\, \\text{eV} \\approx 4.8065 \\times 10^{-16} \\, \\text{J}$.\n$$ v_{\\text{th},e} = \\sqrt{\\frac{2 k_B T_e}{m_e}} = \\sqrt{\\frac{2 \\times (4.8065 \\times 10^{-16} \\, \\text{J})}{9.1094 \\times 10^{-31} \\, \\text{kg}}} \\approx 3.2486 \\times 10^7 \\, \\text{m/s} $$\nNow we evaluate the collisionality $\\nu_*$ at $r=a/2$. The inverse aspect ratio at this location is $\\epsilon = \\frac{a/2}{R} = \\frac{0.45}{2 \\times 1.6} = 0.140625$.\n$$ \\nu_*(a/2) = \\frac{\\nu_{ei} \\, q \\, R}{\\epsilon^{3/2} \\, v_{\\text{th},e}} = \\frac{(61517.4 \\, \\text{s}^{-1}) \\times (2.2) \\times (1.6 \\, \\text{m})}{(0.140625)^{3/2} \\times (3.2486 \\times 10^7 \\, \\text{m/s})} $$\n$$ \\nu_*(a/2) \\approx \\frac{216781}{0.052734 \\times 3.2486 \\times 10^7} \\approx \\frac{216781}{1.7130 \\times 10^6} \\approx 0.12655 $$\nThis is the value of the collisionality at mid-radius.\n\n**4. Central Density Calculation**\nThe peaking factor for the density profile is related to a dimensionless parameter $\\alpha_n a$:\n$$ \\alpha_n a = C_p \\, \\nu_*(a/2) = 0.9 \\times 0.12655 \\approx 0.113895 $$\nWe relate the central density $n(0)$ to the radius-averaged density $n_{avg}$ using the given definition:\n$$ n_{avg} = \\frac{1}{a} \\int_{0}^{a} n(r) \\, dr = \\frac{1}{a} \\int_{0}^{a} n(0) \\exp(-\\alpha_n r) \\, dr $$\n$$ n_{avg} = \\frac{n(0)}{a} \\left[ -\\frac{1}{\\alpha_n} \\exp(-\\alpha_n r) \\right]_0^a = \\frac{n(0)}{a\\alpha_n} (1 - \\exp(-a\\alpha_n)) $$\nSolving for $n(0)$:\n$$ n(0) = n_{avg} \\frac{a\\alpha_n}{1 - \\exp(-a\\alpha_n)} $$\nSubstituting the values for $n_{avg}$ and $a\\alpha_n$:\n$$ n(0) = (2.04353 \\times 10^{20} \\, \\text{m}^{-3}) \\times \\frac{0.113895}{1 - \\exp(-0.113895)} $$\n$$ n(0) \\approx (2.04353 \\times 10^{20}) \\times \\frac{0.113895}{1 - 0.89235} = (2.04353 \\times 10^{20}) \\times (1.0580) $$\n$$ n(0) \\approx 2.1619 \\times 10^{20} \\, \\text{m}^{-3} $$\nThe problem asks for the answer in units of $10^{20} \\, \\text{m}^{-3}$, rounded to three significant figures.\n$$ n(0) \\approx 2.16 \\times 10^{20} \\, \\text{m}^{-3} $$\nThe final numerical answer is $2.16$.",
            "answer": "$$\n\\boxed{2.16}\n$$"
        },
        {
            "introduction": "While textbook formulas like the basic Greenwald scaling provide a useful starting point, real-world predictive models are forged from the rigorous analysis of experimental data. In this practice, you will step into the role of a data scientist in fusion research, using statistical regression and Monte Carlo methods to derive a more nuanced density limit scaling law from a set of tokamak discharge data . This exercise emphasizes the critical importance of uncertainty quantification, demonstrating how to propagate measurement errors to create not just a single prediction, but a full predictive distribution for assessing operational risk.",
            "id": "3694567",
            "problem": "You are given a dataset of measured line-averaged density limits for several tokamak discharges along with corresponding machine and plasma parameters. The educational context is nuclear fusion, and the topic is density limits in relation to Greenwald-type scaling. The aim is to build a principled empirical regression from first principles in a way that quantifies uncertainty from measurement noise, and then use the inferred scaling to make predictions for new operating points with conservative uncertainty bounds.\n\nStart from the following physics basis and definitions that are appropriate for Magnetohydrodynamics (MHD). Use each as a foundational principle or definition, not as a shortcut formula for the target scaling:\n- Ampère’s law in magnetostatics: $\\nabla \\times \\mathbf{B} = \\mu_0 \\mathbf{J}$ relates plasma current density to the magnetic field.\n- The toroidal plasma current $I_p$ produces poloidal magnetic field, affecting magnetohydrodynamic stability, current profiles, and confinement.\n- The line-averaged density $n$ in a toroidal plasma reflects particle inventory and transport, and is limited by stability and operational constraints tied to current and geometry.\n- Geometric parameters such as minor radius $a$ and elongation $\\kappa$ enter the effective cross-sectional area and shaping, while toroidal field $B_T$ affects confinement and transport; these motivate a separable, dimensionally consistent power-law regression ansatz without prescribing any particular exponent values.\n\nBased on these principles, assume a separable, positive, power-law model for the empirical density limit,\n$$\nn_{\\text{lim}} = C \\, I_p^{\\alpha} \\, a^{\\beta} \\, B_T^{\\gamma} \\, \\kappa^{\\delta},\n$$\nwhere $C$ is a positive normalization constant and $(\\alpha,\\beta,\\gamma,\\delta)$ are real exponents to be inferred from data; $I_p$ is the toroidal plasma current in $\\mathrm{A}$, $a$ is the minor radius in $\\mathrm{m}$, $B_T$ is the toroidal magnetic field in $\\mathrm{T}$, and $\\kappa$ is the dimensionless elongation. Take natural logarithms to obtain a linear model in the unknown parameters. Your program must perform a weighted linear regression in log-space and quantify uncertainty by Monte Carlo sampling of the measurement uncertainties. Predictive checks must then be made against conservative bounds derived from the inferred posterior distribution of the scaling.\n\nData specification. The dataset consists of $12$ discharges with measured quantities and fractional standard deviations (assume independent, zero-mean Gaussian measurement noise on each quantity). For each discharge, you are given $(I_p, a, B_T, \\kappa, n_{\\text{lim}})$ along with $(s_I, s_a, s_B, s_\\kappa, s_n)$, where the $s$-values are fractional standard deviations. All densities $n_{\\text{lim}}$ are given in $\\mathrm{m}^{-3}$.\n\nUse the following dataset in your program:\n- Discharge $1$: $(I_p,a,B_T,\\kappa,n_{\\text{lim}}) = (7.0\\times 10^{5},\\,0.48,\\,2.4,\\,1.72,\\,4.75\\times 10^{20})$, $(s_I,s_a,s_B,s_\\kappa,s_n) = (0.03,\\,0.02,\\,0.03,\\,0.02,\\,0.10)$.\n- Discharge $2$: $(1.2\\times 10^{6},\\,0.55,\\,2.8,\\,1.65,\\,6.26\\times 10^{20})$, $(0.03,\\,0.02,\\,0.03,\\,0.02,\\,0.10)$.\n- Discharge $3$: $(2.0\\times 10^{6},\\,0.60,\\,3.0,\\,1.80,\\,9.27\\times 10^{20})$, $(0.03,\\,0.02,\\,0.03,\\,0.02,\\,0.10)$.\n- Discharge $4$: $(3.5\\times 10^{6},\\,0.65,\\,3.5,\\,1.90,\\,1.465\\times 10^{21})$, $(0.03,\\,0.02,\\,0.03,\\,0.02,\\,0.10)$.\n- Discharge $5$: $(5.0\\times 10^{6},\\,0.70,\\,4.0,\\,1.95,\\,1.882\\times 10^{21})$, $(0.03,\\,0.02,\\,0.03,\\,0.02,\\,0.10)$.\n- Discharge $6$: $(9.0\\times 10^{5},\\,0.40,\\,2.2,\\,1.60,\\,8.31\\times 10^{20})$, $(0.03,\\,0.02,\\,0.03,\\,0.02,\\,0.10)$.\n- Discharge $7$: $(1.8\\times 10^{6},\\,0.50,\\,2.6,\\,1.75,\\,1.153\\times 10^{21})$, $(0.03,\\,0.02,\\,0.03,\\,0.02,\\,0.10)$.\n- Discharge $8$: $(7.0\\times 10^{6},\\,0.80,\\,5.0,\\,2.00,\\,2.134\\times 10^{21})$, $(0.03,\\,0.02,\\,0.03,\\,0.02,\\,0.10)$.\n- Discharge $9$: $(1.0\\times 10^{7},\\,0.78,\\,5.3,\\,1.85,\\,3.12\\times 10^{21})$, $(0.03,\\,0.02,\\,0.03,\\,0.02,\\,0.10)$.\n- Discharge $10$: $(1.2\\times 10^{7},\\,0.90,\\,5.3,\\,1.95,\\,2.888\\times 10^{21})$, $(0.03,\\,0.02,\\,0.03,\\,0.02,\\,0.10)$.\n- Discharge $11$: $(5.0\\times 10^{5},\\,0.30,\\,2.5,\\,1.50,\\,8.18\\times 10^{20})$, $(0.03,\\,0.02,\\,0.03,\\,0.02,\\,0.10)$.\n- Discharge $12$: $(3.0\\times 10^{6},\\,0.55,\\,3.2,\\,1.75,\\,1.653\\times 10^{21})$, $(0.03,\\,0.02,\\,0.03,\\,0.02,\\,0.10)$.\n\nAlgorithmic requirements and uncertainty quantification:\n- Transform the model to log-space via the natural logarithm to obtain a linear relationship in the parameters $(\\ln C,\\alpha,\\beta,\\gamma,\\delta)$.\n- Perform a weighted linear regression where the weights are $w_i = 1/s_{n,i}^2$ applied to the log-density residuals. Treat uncertainties in the predictors by Monte Carlo sampling:\n  - For each Monte Carlo replicate, sample each measured quantity $x \\in \\{I_p,a,B_T,\\kappa,n_{\\text{lim}}\\}$ from a Gaussian distribution with mean equal to the measured value and standard deviation equal to its fractional standard deviation times its mean, and reject or clip negative draws to a small positive number as needed for physical plausibility.\n  - Use the sampled values to construct the weighted design matrix and response in log-space, and solve the weighted least squares problem for that replicate.\n- Use $N = 3000$ independent Monte Carlo replicates with a fixed pseudorandom seed to guarantee determinism.\n- From the collection of coefficient samples, obtain a posterior-like empirical distribution for $(\\ln C,\\alpha,\\beta,\\gamma,\\delta)$ and propagate it to predictions.\n\nTest suite and outputs:\n- Predict $n_{\\text{lim}}$ for the following three operating points and compare a proposed operating density $n_{\\text{op}}$ to a conservative bound:\n  - Test case $1$: $(I_p,a,B_T,\\kappa,n_{\\text{op}}) = (2.5\\times 10^{6},\\,0.62,\\,3.1,\\,1.85,\\,1.0\\times 10^{21})$.\n  - Test case $2$ (edge case, small minor radius): $(7.0\\times 10^{5},\\,0.22,\\,2.1,\\,1.60,\\,1.2\\times 10^{21})$.\n  - Test case $3$ (high-current, large device): $(1.2\\times 10^{7},\\,0.95,\\,5.2,\\,2.00,\\,3.0\\times 10^{21})$.\n- For each test case, compute the empirical distribution of $n_{\\text{lim}}$ across the $N$ Monte Carlo coefficient samples. Report the median prediction for $n_{\\text{lim}}$ and a boolean that is $\\mathrm{True}$ if $n_{\\text{op}}$ is strictly less than the conservative $q_{0.05}$ quantile of the predicted $n_{\\text{lim}}$ distribution, and $\\mathrm{False}$ otherwise.\n- Physical units: express each predicted $n_{\\text{lim}}$ in $\\mathrm{m}^{-3}$.\n- Rounding: round each predicted $n_{\\text{lim}}$ to $3$ significant figures.\n- Final output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the exact order $[\\text{n1},\\text{n2},\\text{n3},\\text{b1},\\text{b2},\\text{b3}]$, where $\\text{n1}$, $\\text{n2}$, $\\text{n3}$ are the rounded median predictions for the three test cases in $\\mathrm{m}^{-3}$, and $\\text{b1}$, $\\text{b2}$, $\\text{b3}$ are the corresponding booleans as defined above.",
            "solution": "The objective is to develop an empirical power-law scaling model for the tokamak density limit, $n_{\\text{lim}}$, based on a provided dataset of experimental measurements. The model's parameters will be inferred using a regression analysis that rigorously accounts for measurement uncertainties in all quantities through a Monte Carlo simulation. This inferred scaling will then be used to predict density limits for new operating points and evaluate their operational viability against a conservative uncertainty bound.\n\nThe analysis begins with the physically motivated power-law ansatz for the density limit, $n_{\\text{lim}}$, as a function of the toroidal plasma current $I_p$, minor radius $a$, toroidal magnetic field $B_T$, and plasma elongation $\\kappa$:\n$$\nn_{\\text{lim}} = C \\, I_p^{\\alpha} \\, a^{\\beta} \\, B_T^{\\gamma} \\, \\kappa^{\\delta}\n$$\nHere, $C$ is a positive constant, and $\\alpha$, $\\beta$, $\\gamma$, and $\\delta$ are the scaling exponents to be determined. The choice of these predictor variables is grounded in magnetohydrodynamic (MHD) principles. $I_p$ is central to plasma confinement and stability as per Ampère's law, $\\nabla \\times \\mathbf{B} = \\mu_0 \\mathbf{J}$. The geometric parameters $a$ and $\\kappa$ define the plasma cross-section, which influences current density and particle transport. The toroidal field $B_T$ is a primary factor in confining charged particles.\n\nTo facilitate a linear regression, we transform the model by taking the natural logarithm of both sides:\n$$\n\\ln(n_{\\text{lim}}) = \\ln(C) + \\alpha \\ln(I_p) + \\beta \\ln(a) + \\gamma \\ln(B_T) + \\delta \\ln(\\kappa)\n$$\nThis equation is linear in the unknown parameters $\\mathbf{p} = [\\ln(C), \\alpha, \\beta, \\gamma, \\delta]^T$. For a dataset of $M$ measurements (in this case, $M=12$), we can express the relationship in matrix form as $\\mathbf{y} = \\mathbf{X}\\mathbf{p}$, where $\\mathbf{y}$ is the $M \\times 1$ vector of observed $\\ln(n_{\\text{lim},i})$ values, and $\\mathbf{X}$ is the $M \\times 5$ design matrix. Each row $i$ of $\\mathbf{X}$ corresponds to an observation and has the form $[1, \\ln(I_{p,i}), \\ln(a_i), \\ln(B_{T,i}), \\ln(\\kappa_i)]$.\n\nA key challenge is that all measured quantities, not just the response variable $n_{\\text{lim}}$, are subject to experimental uncertainty. To properly propagate these uncertainties into the inferred parameters and subsequent predictions, a Monte Carlo approach is employed as specified. We generate $N=3000$ replicate datasets. For each replicate, every measured value $x_i$ (where $x \\in \\{I_p, a, B_T, \\kappa, n_{\\text{lim}}\\}$) is sampled from a Gaussian distribution with a mean equal to its measured value and a standard deviation given by the product of its mean and its specified fractional standard deviation, $s_x$. To maintain physical plausibility, any non-positive samples are clipped to a small positive value.\n\nFor each of the $N$ sampled datasets, we construct the corresponding log-space design matrix $\\mathbf{X}_k$ and response vector $\\mathbf{y}_k$ (where $k$ is the replicate index from $1$ to $N$). The problem specifies performing a weighted least squares (WLS) regression for each replicate, with weights given by $w_i = 1/s_{n,i}^2$. The variance of the log-transformed density, $\\text{Var}(\\ln(n_{\\text{lim},i}))$, can be approximated by first-order error propagation as $(\\Delta n_{\\text{lim},i} / n_{\\text{lim},i})^2 = s_{n,i}^2$. Thus, the weights are the inverse variances of the log-transformed response variable. In this specific problem, the fractional standard deviation for density, $s_n$, is constant ($s_n=0.10$) for all $12$ data points. Consequently, the weight matrix $\\mathbf{W}$ is a diagonal matrix where all diagonal elements are equal, i.e., $\\mathbf{W} = (1/s_n^2)\\mathbf{I}$, where $\\mathbf{I}$ is the identity matrix. The WLS solution for the parameters, $\\mathbf{p}_k = (\\mathbf{X}_k^T\\mathbf{W}\\mathbf{X}_k)^{-1}\\mathbf{X}_k^T\\mathbf{W}\\mathbf{y}_k$, simplifies to the ordinary least squares (OLS) solution, $\\mathbf{p}_k = (\\mathbf{X}_k^T\\mathbf{X}_k)^{-1}\\mathbf{X}_k^T\\mathbf{y}_k$. This OLS problem is solved efficiently for each replicate using a standard numerical linear algebra routine, yielding a parameter sample $\\mathbf{p}_k$.\n\nThis process results in an ensemble of $N=3000$ parameter vectors, $\\{\\mathbf{p}_k\\}_{k=1}^N$, which forms an empirical distribution that represents the uncertainty in the model parameters. To make a prediction for a new operating point $(I_{p,\\text{test}}, a_{\\text{test}}, B_{T,\\text{test}}, \\kappa_{\\text{test}})$, we first construct its log-space feature vector, $\\mathbf{x}_{\\text{test}} = [1, \\ln(I_{p,\\text{test}}), \\ln(a_{\\text{test}}), \\ln(B_{T,\\text{test}}), \\ln(\\kappa_{\\text{test}})]^T$. We then generate a distribution of $N$ predicted log-density values by taking the dot product $\\ln(n_{\\text{lim},k}) = \\mathbf{x}_{\\text{test}}^T \\mathbf{p}_k$ for each parameter sample $\\mathbf{p}_k$. Exponentiating these values, $n_{\\text{lim},k} = \\exp(\\ln(n_{\\text{lim},k}))$, yields the predictive distribution for the density limit.\n\nThe final predicted value for $n_{\\text{lim}}$ is taken as the median of this distribution, a robust estimator of central tendency. To provide a conservative assessment of operational safety, we compute the 5th percentile, $q_{0.05}$, of the predictive distribution. A proposed operating density, $n_{\\text{op}}$, is considered to meet the conservative criterion if it is strictly less than this lower bound ($n_{\\text{op}} < q_{0.05}$). This method provides not only a point estimate but also a principled quantification of the predictive uncertainty, essential for risk assessment in physics and engineering applications. The procedure is implemented deterministically using a fixed pseudorandom seed.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef round_to_sf(x, sf):\n    \"\"\"\n    Rounds a number to a specified number of significant figures.\n    \"\"\"\n    if x == 0:\n        return 0.0\n    # Calculate the position of the most significant digit.\n    # The number of digits to round to is sf - 1 - floor(log10(|x|)).\n    # e.g., for 12345 and sf=3, log10 is ~4.09, floor is 4.\n    # sf-1-4 = 3-1-4 = -2. round(12345, -2) -> 12300.\n    # e.g., for 0.012345 and sf=3, log10 is ~-1.9, floor is -2.\n    # sf-1-(-2) = 3-1+2 = 4. round(0.012345, 4) -> 0.0123.\n    return round(x, sf - 1 - int(np.floor(np.log10(abs(x)))))\n\ndef solve():\n    \"\"\"\n    Performs Monte Carlo based power-law regression for tokamak density limits.\n    \"\"\"\n    # Fixed seed for reproducibility as required by the problem.\n    SEED = 123\n    N_REPLICATES = 3000\n    rng = np.random.default_rng(seed=SEED)\n\n    # Dataset: (I_p, a, B_T, k, n_lim), (s_I, s_a, s_B, s_k, s_n)\n    # The data is structured as mean values followed by fractional standard deviations.\n    dataset = np.array([\n        # Mean values [I_p (A), a (m), B_T (T), k, n_lim (m^-3)]\n        [7.0e5, 0.48, 2.4, 1.72, 4.75e20],\n        [1.2e6, 0.55, 2.8, 1.65, 6.26e20],\n        [2.0e6, 0.60, 3.0, 1.80, 9.27e20],\n        [3.5e6, 0.65, 3.5, 1.90, 1.465e21],\n        [5.0e6, 0.70, 4.0, 1.95, 1.882e21],\n        [9.0e5, 0.40, 2.2, 1.60, 8.31e20],\n        [1.8e6, 0.50, 2.6, 1.75, 1.153e21],\n        [7.0e6, 0.80, 5.0, 2.00, 2.134e21],\n        [1.0e7, 0.78, 5.3, 1.85, 3.12e21],\n        [1.2e7, 0.90, 5.3, 1.95, 2.888e21],\n        [5.0e5, 0.30, 2.5, 1.50, 8.18e20],\n        [3.0e6, 0.55, 3.2, 1.75, 1.653e21],\n        # Fractional std devs [s_I, s_a, s_B, s_k, s_n]\n        [0.03, 0.02, 0.03, 0.02, 0.10],\n        [0.03, 0.02, 0.03, 0.02, 0.10],\n        [0.03, 0.02, 0.03, 0.02, 0.10],\n        [0.03, 0.02, 0.03, 0.02, 0.10],\n        [0.03, 0.02, 0.03, 0.02, 0.10],\n        [0.03, 0.02, 0.03, 0.02, 0.10],\n        [0.03, 0.02, 0.03, 0.02, 0.10],\n        [0.03, 0.02, 0.03, 0.02, 0.10],\n        [0.03, 0.02, 0.03, 0.02, 0.10],\n        [0.03, 0.02, 0.03, 0.02, 0.10],\n        [0.03, 0.02, 0.03, 0.02, 0.10],\n        [0.03, 0.02, 0.03, 0.02, 0.10],\n    ])\n    \n    # Split the dataset for clarity\n    means = dataset[:12, :]\n    frac_stds = dataset[12:, :]\n    # Since frac stds are constant for all discharges, we can simplify\n    frac_stds = frac_stds[0, :] * np.ones_like(means)\n    stds = means * frac_stds\n    \n    param_samples = []\n    \n    for _ in range(N_REPLICATES):\n        # Sample data from Gaussian distributions\n        sampled_data = rng.normal(loc=means, scale=stds)\n        \n        # Clip to a small positive number to avoid log(0) or log(-)\n        sampled_data = np.maximum(sampled_data, 1e-12)\n        \n        I_p, a, B_T, kappa, n_lim = sampled_data.T\n        \n        # Construct the linear model in log-space: y = Xp\n        # y = log(n_lim)\n        # X = [1, log(I_p), log(a), log(B_T), log(kappa)]\n        # p = [log(C), alpha, beta, gamma, delta]\n        y_k = np.log(n_lim)\n        X_k = np.vstack([\n            np.ones(means.shape[0]),\n            np.log(I_p),\n            np.log(a),\n            np.log(B_T),\n            np.log(kappa)\n        ]).T\n        \n        # Perform OLS. As per problem description, WLS simplifies to OLS\n        # because the weights are constant for all data points.\n        params, _, _, _ = np.linalg.lstsq(X_k, y_k, rcond=None)\n        param_samples.append(params)\n        \n    param_samples = np.array(param_samples) # Shape: (N_REPLICATES, 5)\n\n    # Test cases: (I_p, a, B_T, k, n_op)\n    test_cases = [\n        (2.5e6, 0.62, 3.1, 1.85, 1.0e21),\n        (7.0e5, 0.22, 2.1, 1.60, 1.2e21),\n        (1.2e7, 0.95, 5.2, 2.00, 3.0e21),\n    ]\n\n    median_predictions = []\n    boolean_checks = []\n\n    for case in test_cases:\n        I_p_test, a_test, B_T_test, k_test, n_op = case\n        \n        # Construct the feature vector for the test case in log-space\n        x_test_log = np.array([1.0, np.log(I_p_test), np.log(a_test), np.log(B_T_test), np.log(k_test)])\n        \n        # Predict log(n_lim) for all parameter samples\n        log_n_lim_preds = param_samples @ x_test_log\n        \n        # Transform back to n_lim\n        n_lim_preds = np.exp(log_n_lim_preds)\n        \n        # Calculate median prediction and q_0.05 quantile\n        median_n_lim = np.median(n_lim_preds)\n        q05_n_lim = np.quantile(n_lim_preds, 0.05)\n        \n        # Round median to 3 significant figures\n        rounded_median = round_to_sf(median_n_lim, 3)\n        median_predictions.append(f\"{rounded_median:.2e}\".replace(\"e+0\", \"e+\"))\n\n        # Check if operating density is below the conservative bound\n        is_safe = n_op < q05_n_lim\n        boolean_checks.append(is_safe)\n        \n    # Combine results and format the final output string\n    final_output_list = median_predictions + boolean_checks\n    print(f\"[{','.join(map(str, final_output_list))}]\")\n\nsolve()\n```"
        }
    ]
}