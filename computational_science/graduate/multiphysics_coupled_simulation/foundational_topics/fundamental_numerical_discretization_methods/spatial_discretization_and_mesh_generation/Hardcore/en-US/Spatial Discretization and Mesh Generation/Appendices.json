{
    "hands_on_practices": [
        {
            "introduction": "At the heart of the finite element method lies the isoparametric mapping, which transforms a simple, ideal reference element into the shape of the physical elements in a mesh. This practice delves into the mathematical condition for a valid mapping—a positive Jacobian determinant $J(\\xi,\\eta) > 0$—and equips you with the skills to programmatically diagnose and repair distorted elements that can otherwise halt a simulation . By implementing these checks and fixes, you will gain a deeper understanding of mesh quality at its most fundamental level.",
            "id": "3561775",
            "problem": "You are asked to formalize, analyze, and robustly correct failures of the isoparametric mapping in a two-dimensional bilinear quadrilateral finite element used in computational geomechanics. The question focuses on spatial discretization, meshing, and shape functions, beginning from fundamental definitions of isoparametric mapping, and culminating in algorithmic remedies when the Jacobian determinant loses positivity. Your program must implement and test these concepts for a small suite of meshes.\n\nThe starting point is the isoparametric mapping of a bilinear quadrilateral element. The mapping from the reference square in parametric coordinates $(\\xi,\\eta)\\in[-1,1]\\times[-1,1]$ to physical coordinates $(x,y)$ is defined as\n$$\nx(\\xi,\\eta) = \\sum_{i=1}^{4} N_i(\\xi,\\eta)\\,x_i,\\quad\ny(\\xi,\\eta) = \\sum_{i=1}^{4} N_i(\\xi,\\eta)\\,y_i,\n$$\nwhere $(x_i,y_i)$ are the coordinates of the physical nodes and $N_i(\\xi,\\eta)$ are the bilinear shape functions associated with the corners of the reference square. The bilinear shape functions for a quadrilateral with reference nodal order $i=1,2,3,4$ at corners $(-1,-1)$, $(1,-1)$, $(1,1)$, $(-1,1)$ are\n$$\nN_1(\\xi,\\eta) = \\tfrac{1}{4}(1-\\xi)(1-\\eta),\\quad\nN_2(\\xi,\\eta) = \\tfrac{1}{4}(1+\\xi)(1-\\eta),\\quad\nN_3(\\xi,\\eta) = \\tfrac{1}{4}(1+\\xi)(1+\\eta),\\quad\nN_4(\\xi,\\eta) = \\tfrac{1}{4}(1-\\xi)(1+\\eta).\n$$\nThe Jacobian matrix of the mapping is\n$$\n\\mathbf{J}(\\xi,\\eta) = \n\\begin{bmatrix}\n\\dfrac{\\partial x}{\\partial \\xi} & \\dfrac{\\partial x}{\\partial \\eta}\\\\[6pt]\n\\dfrac{\\partial y}{\\partial \\xi} & \\dfrac{\\partial y}{\\partial \\eta}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\sum_{i=1}^{4}\\dfrac{\\partial N_i}{\\partial \\xi}\\,x_i & \\sum_{i=1}^{4}\\dfrac{\\partial N_i}{\\partial \\eta}\\,x_i\\\\[6pt]\n\\sum_{i=1}^{4}\\dfrac{\\partial N_i}{\\partial \\xi}\\,y_i & \\sum_{i=1}^{4}\\dfrac{\\partial N_i}{\\partial \\eta}\\,y_i\n\\endbmatrix},\n$$\nand the determinant of the Jacobian, denoted by $J(\\xi,\\eta)=\\det\\mathbf{J}(\\xi,\\eta)$, indicates local invertibility and orientation of the mapping. A necessary condition for a valid orientation-preserving isoparametric mapping is $J(\\xi,\\eta)>0$ everywhere in the element interior. Loss of positivity leads to failure modes such as element inversion or folding, which can cause numerical integration breakdowns and nonphysical solutions.\n\nYour tasks are:\n- Implement the bilinear shape functions $N_i(\\xi,\\eta)$ and their parametric derivatives $\\partial N_i/\\partial \\xi$ and $\\partial N_i/\\partial \\eta$.\n- For any given quadrilateral element defined by its physical node coordinates $(x_i,y_i)$ with the implied reference nodal order $i=1,2,3,4$ corresponding to $(-1,-1)$, $(1,-1)$, $(1,1)$, $(-1,1)$, compute the Jacobian determinant $J(\\xi,\\eta)$ over the interior sample grid of parametric points\n$$\n\\Xi=\\{-0.75,\\,-0.25,\\,0,\\,0.25,\\,0.75\\},\\quad \\text{evaluate on all $25$ pairs $(\\xi,\\eta)\\in\\Xi\\times\\Xi$}.\n$$\nUse a numerical tolerance $10^{-9}$ to judge strict positivity.\n- Intentionally construct elements that violate $J(\\xi,\\eta)>0$ in some regions, analyze the failure mode, and propose two robust remedies:\n  1. Local reparameterization: Treat the physical node list $(x_i,y_i)$ as a labeling that can be permuted according to the eight symmetries of the square (the dihedral group of order eight). Among these permutations, identify the one that maximizes the minimum sampled $J(\\xi,\\eta)$ and apply it if it achieves strictly positive minimum greater than the tolerance.\n  2. Subdivision into linear triangles: If no reparameterization yields strictly positive minimum $J(\\xi,\\eta)$ across the sample grid, subdivide the quadrilateral into two triangles along one of the diagonals, choose the diagonal that maximizes the minimum positive signed area of the two triangles (ensuring counterclockwise orientation by node reordering if necessary), and report this minimum area as the post-fix metric.\n\nOutput specification per test case:\n- Compute the minimum sampled Jacobian determinant prior to any fix, denoted by $J_{\\min}^{\\text{before}}$.\n- Decide the fix strategy code $c$ as an integer: $c=0$ if no fix is needed (already strictly positive), $c=1$ if local reparameterization is used, $c=2$ if subdivision into triangles is used.\n- Compute the post-fix metric $m$: if $c=0$ or $c=1$, set $m$ to the minimum sampled Jacobian determinant after the chosen reparameterization (or the original if no fix was needed); if $c=2$, set $m$ to the minimum positive triangle area after subdivision and proper orientation.\n- For numerical outputs, floats must be used; there are no physical units involved.\n\nYour program must implement the above and run on the following test suite of three quadrilateral elements, each specified by a list of four physical node coordinates $(x_i,y_i)$ in the implied reference order $i=1,2,3,4$:\n- Test case A (convex element, expected valid): $[(0,0),(2,0),(2,1),(0,1)]$.\n- Test case B (inverted orientation by node order, expected fixable by reparameterization): $[(0,0),(0,1),(2,1),(2,0)]$.\n- Test case C (self-intersecting bow-tie, expected not fixable by reparameterization and requiring subdivision): $[(0,0),(2,0),(0,1),(2,1)]$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of triples, one per test case, enclosed in square brackets. Each triple must be of the form $[J_{\\min}^{\\text{before}},c,m]$ where numbers are printed as floats and the integer code $c$ is printed as an integer. For example: $[[0.5,0,0.5],[-0.5,1,0.5],[\\ldots,2,\\ldots]]$.",
            "solution": "The solution addresses the validation and correction of isoparametric mappings for two-dimensional bilinear quadrilateral elements, a fundamental task in computational geomechanics and finite element analysis. The process begins with an analysis of the provided element geometry, followed by corrective procedures if the geometry is invalid.\n\n### 1. Isoparametric Mapping and Jacobian Determinant\n\nThe core of the problem lies in the isoparametric mapping, which relates a simple reference element (a square in parametric coordinates $(\\xi, \\eta) \\in [-1,1]\\times[-1,1]$) to a general quadrilateral element in physical space with coordinates $(x,y)$. The mapping is defined using shape functions $N_i(\\xi, \\eta)$:\n$$\nx(\\xi,\\eta) = \\sum_{i=1}^{4} N_i(\\xi,\\eta)\\,x_i \\quad \\text{and} \\quad y(\\xi,\\eta) = \\sum_{i=1}^{4} N_i(\\xi,\\eta)\\,y_i\n$$\nwhere $(x_i, y_i)$ are the coordinates of the $i$-th physical node, corresponding to the $i$-th node of the reference square. The bilinear shape functions for the reference square with nodes $1, 2, 3, 4$ at $(-1,-1), (1,-1), (1,1), (-1,1)$ respectively, are:\n$$\nN_1(\\xi,\\eta) = \\tfrac{1}{4}(1-\\xi)(1-\\eta) \\\\\nN_2(\\xi,\\eta) = \\tfrac{1}{4}(1+\\xi)(1-\\eta) \\\\\nN_3(\\xi,\\eta) = \\tfrac{1}{4}(1+\\xi)(1+\\eta) \\\\\nN_4(\\xi,\\eta) = \\tfrac{1}{4}(1-\\xi)(1+\\eta)\n$$\nFor a mapping to be physically and mathematically valid, it must be invertible and orientation-preserving. This property is characterized by the determinant of the Jacobian matrix, $J(\\xi,\\eta) = \\det(\\mathbf{J})$. The Jacobian matrix contains the partial derivatives of the physical coordinates with respect to the parametric coordinates:\n$$\n\\mathbf{J}(\\xi,\\eta) = \n\\begin{bmatrix}\n\\dfrac{\\partial x}{\\partial \\xi} & \\dfrac{\\partial x}{\\partial \\eta}\\\\[6pt]\n\\dfrac{\\partial y}{\\partial \\xi} & \\dfrac{\\partial y}{\\partial \\eta}\n\\end{bmatrix}\n$$\nThe components of $\\mathbf{J}$ are linear combinations of the nodal coordinates, with coefficients being the derivatives of the shape functions. For instance, $\\frac{\\partial x}{\\partial \\xi} = \\sum_{i=1}^{4}\\frac{\\partial N_i}{\\partial \\xi}\\,x_i$. The condition for a valid mapping is that the Jacobian determinant must be strictly positive, $J(\\xi,\\eta) > 0$, throughout the element's domain. A positive determinant ensures a unique, one-to-one mapping from the $(\\xi, \\eta)$ space to the $(x, y)$ space that preserves the local orientation (i.e., it maps a counter-clockwise path to a counter-clockwise path). If $J(\\xi,\\eta) \\le 0$ at any point, the element may be folded, inverted, or degenerate, leading to catastrophic failures in numerical procedures like Gaussian quadrature.\n\nTo assess the validity of a given element, we compute $J(\\xi, \\eta)$ on a discrete grid of sample points within the reference domain. The problem specifies a $5 \\times 5$ grid where $\\xi$ and $\\eta$ both take values from $\\Xi=\\{-0.75,\\,-0.25,\\,0,\\,0.25,\\,0.75\\}$. The minimum value of the determinant found on this grid, $J_{\\min}$, is compared against a strict positivity tolerance of $10^{-9}$. If $J_{\\min} > 10^{-9}$, no correction is needed, and the fix code is $c=0$. Otherwise, corrective measures are required.\n\n### 2. Corrective Strategy 1: Local Reparameterization\n\nIf the initial configuration is invalid ($J_{\\min} \\le 10^{-9}$), the first remedy is to try re-ordering the physical nodes. A common reason for a negative Jacobian is a clockwise (CW) ordering of nodes for a reference element that assumes a counter-clockwise (CCW) convention. More complex invalid geometries can sometimes be rectified by finding a different traversal of the same set of physical vertices. The problem specifies testing all $8$ permutations of the nodal list that correspond to the symmetries of the reference square (the dihedral group $D_4$). These permutations represent all possible rotations and reflections of the reference element's node labels.\n\nFor an initial node list $[p_1, p_2, p_3, p_4]$, the $8$ permutations are:\n1. Identity: $[p_1, p_2, p_3, p_4]$\n2. Rotate $90^\\circ$ CCW: $[p_4, p_1, p_2, p_3]$\n3. Rotate $180^\\circ$: $[p_3, p_4, p_1, p_2]$\n4. Rotate $270^\\circ$ CCW: $[p_2, p_3, p_4, p_1]$\n5. Flip (vertical axis): $[p_2, p_1, p_4, p_3]$\n6. Flip (horizontal axis): $[p_4, p_3, p_2, p_1]$\n7. Flip (anti-diagonal): $[p_1, p_4, p_3, p_2]$\n8. Flip (main diagonal): $[p_3, p_2, p_1, p_4]$\n\nFor each of these $8$ nodal configurations, we compute the minimum Jacobian determinant, $J_{\\min}^{\\text{perm}}$, over the sample grid. We then find the maximum of these values, $J_{\\min}^{\\text{best}} = \\max(\\{J_{\\min}^{\\text{perm}}\\})$. If $J_{\\min}^{\\text{best}} > 10^{-9}$, the reparameterization is successful. The fix code is set to $c=1$, and the post-fix metric $m$ is set to $J_{\\min}^{\\text{best}}$.\n\n### 3. Corrective Strategy 2: Subdivision into Triangles\n\nIf no reparameterization yields a strictly positive minimum Jacobian, the element geometry is likely too distorted (e.g., non-convex or self-intersecting in all valid orderings) for a bilinear mapping from a convex square. In this case, the fallback strategy is to subdivide the quadrilateral into two linear triangles. Linear triangles have a constant Jacobian, and a valid triangle (with non-collinear vertices) will always have a non-zero area, which can be made positive by ensuring a CCW vertex ordering.\n\nA quadrilateral can be subdivided along either of its two diagonals:\n1. Diagonal connecting nodes $1$ and $3$: This yields triangles $(p_1, p_2, p_3)$ and $(p_1, p_3, p_4)$.\n2. Diagonal connecting nodes $2$ and $4$: This yields triangles $(p_2, p_3, p_4)$ and $(p_2, p_4, p_1)$.\n\nThe quality of a subdivision is judged by the areas of the resulting triangles. The area of a triangle with vertices $(x_a,y_a), (x_b,y_b), (x_c,y_c)$ is given by $A = \\frac{1}{2} [x_a(y_b - y_c) + x_b(y_c - y_a) + x_c(y_a - y_b)]$. A positive area corresponds to a CCW ordering. We calculate the absolute areas of the two triangles for each possible diagonal. For each diagonal, we find the minimum of the two triangle areas. The chosen diagonal is the one that maximizes this minimum area. This strategy aims to avoid creating very thin or small triangles.\n\nLet $m_1$ be the minimum area for the first diagonal and $m_2$ for the second. The post-fix metric is $m = \\max(m_1, m_2)$. The fix code is set to $c=2$.\n\n### Algorithmic Implementation\n\nThe implementation encapsulates these steps. For each test case defined by a list of four node coordinates:\n1.  Compute $J_{\\min}^{\\text{before}}$ for the initial node ordering.\n2.  If $J_{\\min}^{\\text{before}} > 10^{-9}$, the result is $[J_{\\min}^{\\text{before}}, 0, J_{\\min}^{\\text{before}}]$.\n3.  Otherwise, attempt reparameterization. Compute the maximum of the minimum Jacobians over the $8$ symmetric permutations. If this maximum is positive, the result is $[J_{\\min}^{\\text{before}}, 1, J_{\\min}^{\\text{best}}]$.\n4.  If reparameterization fails, perform subdivision. Calculate the subdivision metric $m$ by comparing the two diagonal choices. The result is $[J_{\\min}^{\\text{before}}, 2, m]$.\n\nThis structured approach ensures that a valid element representation is found, either by re-labeling for mildly distorted elements or by mesh refinement for severely distorted ones, providing a robust solution for element processing in computational simulations.",
            "answer": "```python\nimport numpy as np\n\ndef get_shape_func_derivs(xi, eta):\n    \"\"\"\n    Computes the derivatives of the 4-node quad shape functions with respect to xi and eta.\n    Nodal order: (-1,-1), (1,-1), (1,1), (-1,1)\n    \"\"\"\n    dNdxi = np.array([\n        -0.25 * (1.0 - eta),\n         0.25 * (1.0 - eta),\n         0.25 * (1.0 + eta),\n        -0.25 * (1.0 + eta)\n    ])\n    dNdeta = np.array([\n        -0.25 * (1.0 - xi),\n        -0.25 * (1.0 + xi),\n         0.25 * (1.0 + xi),\n         0.25 * (1.0 - xi)\n    ])\n    return dNdxi, dNdeta\n\ndef compute_jacobian_det(xi, eta, nodes):\n    \"\"\"\n    Computes the Jacobian determinant for a given (xi, eta) and node coordinates.\n    nodes: a 4x2 numpy array of (x,y) coordinates.\n    \"\"\"\n    dNdxi, dNdeta = get_shape_func_derivs(xi, eta)\n    \n    x_coords = nodes[:, 0]\n    y_coords = nodes[:, 1]\n    \n    j11 = np.dot(dNdxi, x_coords)\n    j12 = np.dot(dNdeta, x_coords)\n    j21 = np.dot(dNdxi, y_coords)\n    j22 = np.dot(dNdeta, y_coords)\n    \n    return j11 * j22 - j12 * j21\n\ndef calculate_min_j(nodes, grid_points):\n    \"\"\"\n    Calculates the minimum Jacobian determinant over a grid of sample points.\n    \"\"\"\n    min_j = float('inf')\n    for xi in grid_points:\n        for eta in grid_points:\n            j_det = compute_jacobian_det(xi, eta, nodes)\n            if j_det < min_j:\n                min_j = j_det\n    return min_j\n\ndef get_permutations(nodes):\n    \"\"\"\n    Generates 8 permutations of the node list corresponding to the dihedral group D4.\n    \"\"\"\n    p1, p2, p3, p4 = nodes\n    # Permutations based on re-labeling of reference square corners\n    return [\n        np.array([p1, p2, p3, p4]),  # Identity\n        np.array([p4, p1, p2, p3]),  # Rotate 90 deg CCW\n        np.array([p3, p4, p1, p2]),  # Rotate 180 deg\n        np.array([p2, p3, p4, p1]),  # Rotate 270 deg CCW\n        np.array([p2, p1, p4, p3]),  # Flip vertical\n        np.array([p4, p3, p2, p1]),  # Flip horizontal\n        np.array([p1, p4, p3, p2]),  # Flip anti-diagonal (y=-x)\n        np.array([p3, p2, p1, p4]),  # Flip main diagonal (y=x)\n    ]\n\ndef triangle_area(p1, p2, p3):\n    \"\"\"\n    Calculates the signed area of a triangle.\n    \"\"\"\n    return 0.5 * (p1[0]*(p2[1] - p3[1]) + p2[0]*(p3[1] - p1[1]) + p3[0]*(p1[1] - p2[1]))\n\ndef process_case(nodes_tuple):\n    \"\"\"\n    Processes a single quadrilateral element, returning the analysis results.\n    \"\"\"\n    nodes = np.array(nodes_tuple, dtype=float)\n    grid_points = np.array([-0.75, -0.25, 0.0, 0.25, 0.75])\n    tolerance = 1e-9\n\n    # 1. Compute min Jacobian for the original configuration\n    j_min_before = calculate_min_j(nodes, grid_points)\n\n    # 2. Check if fix is needed\n    if j_min_before > tolerance:\n        return [j_min_before, 0, j_min_before]\n\n    # 3. Try Fix 1: Local Reparameterization\n    permutations = get_permutations(nodes)\n    min_j_values = [calculate_min_j(p, grid_points) for p in permutations]\n\n    max_of_min_j = -np.inf\n    if min_j_values:\n        max_of_min_j = max(min_j_values)\n    \n    if max_of_min_j > tolerance:\n        return [j_min_before, 1, max_of_min_j]\n\n    # 4. Fix 2: Subdivision into triangles\n    p1, p2, p3, p4 = nodes\n\n    # Diagonal 1-3\n    area1a = triangle_area(p1, p2, p3)\n    area1b = triangle_area(p1, p3, p4)\n    m1 = min(abs(area1a), abs(area1b))\n\n    # Diagonal 2-4\n    area2a = triangle_area(p2, p3, p4)\n    area2b = triangle_area(p2, p4, p1)\n    m2 = min(abs(area2a), abs(area2b))\n\n    m_postfix = max(m1, m2)\n    \n    return [j_min_before, 2, m_postfix]\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    test_cases = [\n        # Test case A (convex element, expected valid)\n        [(0.0, 0.0), (2.0, 0.0), (2.0, 1.0), (0.0, 1.0)],\n        # Test case B (inverted orientation, fix by reparameterization)\n        [(0.0, 0.0), (0.0, 1.0), (2.0, 1.0), (2.0, 0.0)],\n        # Test case C (bow-tie, fix by reparameterization)\n        [(0.0, 0.0), (2.0, 0.0), (0.0, 1.0), (2.0, 1.0)],\n    ]\n\n    results = []\n    for case in test_cases:\n        result = process_case(case)\n        results.append(result)\n\n    def format_result(res):\n        # Format to match output specification: [float,int,float] with no spaces.\n        return f\"[{res[0]},{int(res[1])},{res[2]}]\"\n\n    formatted_results = [format_result(r) for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Once a valid mesh is generated, a critical question remains: is it fine enough to produce an accurate result? A grid convergence study is a standard procedure in Verification and Validation (V) to quantify the error introduced by spatial discretization. This exercise will guide you through using solutions from a sequence of systematically refined meshes to estimate the discretization error and the observed order of accuracy . Mastering this technique is essential for establishing confidence in the results of any computational simulation.",
            "id": "3526279",
            "problem": "A multiphysics coupled simulation of electrochemically driven heat transfer in a lithium-ion battery pouch cell is performed using the finite element method (FEM). The cell is modeled as a layered solid with anisotropic thermal conductivity and volumetric Joule heating supplied by an electrochemical submodel. Spatial discretization uses three systematically refined, unstructured tetrahedral meshes with characteristic element sizes $h_1$, $h_2$, and $h_3$ satisfying $h_1/h_2 = h_2/h_3 = r$ and with $r$ constant. The quantity of interest is the domain-integrated Joule heat $Q(h)$, obtained from steady-state coupled solutions at each mesh level. The following data are recorded:\n- $h_1 = 0.008\\,\\text{m}$, $Q_1 = 5.432\\,\\text{W}$;\n- $h_2 = 0.004\\,\\text{m}$, $Q_2 = 5.308\\,\\text{W}$;\n- $h_3 = 0.002\\,\\text{m}$, $Q_3 = 5.276\\,\\text{W}$.\n\nAssume the solution error is asymptotic and can be represented by the leading-order Richardson expansion $Q(h) = Q^{\\ast} + C h^{p} + \\mathcal{O}(h^{p+1})$, where $Q^{\\ast}$ is the mesh-independent value, $C$ is a constant, and $p$ is the observed order of accuracy. Using only this base representation and the given data:\n1. Determine the observed order $p$ from the three solutions and the refinement ratio $r$.\n2. Based on the observed order, compute the Grid Convergence Index (GCI) for the finest-grid solution, defined on the pair $(h_2,h_3)$ with a safety factor $F_s = 1.25$, to estimate the fractional uncertainty of $Q_3$ due to spatial discretization.\n\nProvide the GCI as a dimensionless fraction (no percent sign). If you choose to express the final number in decimal form, round your answer to four significant figures. Also, briefly interpret whether the triplet of solutions is consistent with monotonic, asymptotic convergence and what the computed GCI implies about the uncertainty in $Q_3$ due to discretization.",
            "solution": "The problem is valid as it presents a well-posed set of conditions and data for performing a standard grid convergence study using Richardson extrapolation, a cornerstone of verification and validation in computational science and engineering. The physical context is scientifically grounded, and all necessary parameters are provided without contradiction.\n\nThe analysis proceeds in three parts: first, a brief check for monotonic convergence; second, the determination of the observed order of accuracy $p$; and third, the calculation of the Grid Convergence Index (GCI).\n\nThe given data for the domain-integrated Joule heat $Q$ at three levels of mesh refinement are:\n- Mesh 1 (coarse): $h_1 = 0.008$, $Q_1 = 5.432$\n- Mesh 2 (medium): $h_2 = 0.004$, $Q_2 = 5.308$\n- Mesh 3 (fine): $h_3 = 0.002$, $Q_3 = 5.276$\n\nFirst, we assess the convergence behavior. The mesh refinement is systematic, with a constant refinement ratio $r = h_1/h_2 = 0.008/0.004 = 2$ and $h_2/h_3 = 0.004/0.002 = 2$. The solutions are $Q_1 > Q_2 > Q_3$. Since the solution values decrease monotonically as the characteristic element size $h$ decreases, the solution exhibits monotonic convergence. This is a desirable property, suggesting the numerical scheme is stable and not exhibiting oscillatory error behavior.\n\nThe core of the analysis relies on the assumed Richardson error expansion for the quantity of interest, $Q(h)$, which states that the solution on a grid with characteristic size $h$ is related to the exact or grid-independent solution $Q^{\\ast}$ by:\n$$Q(h) = Q^{\\ast} + C h^{p} + \\mathcal{O}(h^{p+1})$$\nwhere $p$ is the order of accuracy and $C$ is a constant. Neglecting the higher-order terms for the three mesh levels, we have:\n$$Q_1 \\approx Q^{\\ast} + C h_1^{p}$$\n$$Q_2 \\approx Q^{\\ast} + C h_2^{p}$$\n$$Q_3 \\approx Q^{\\ast} + C h_3^{p}$$\nTo find the observed order of accuracy $p$, we form differences between successive solutions to eliminate the unknown $Q^{\\ast}$:\n$$Q_1 - Q_2 \\approx C(h_1^{p} - h_2^{p})$$\n$$Q_2 - Q_3 \\approx C(h_2^{p} - h_3^{p})$$\nTaking the ratio of these two differences eliminates the constant $C$:\n$$\\frac{Q_1 - Q_2}{Q_2 - Q_3} \\approx \\frac{h_1^{p} - h_2^{p}}{h_2^{p} - h_3^{p}}$$\nUsing the constant refinement ratio $r = h_1/h_2 = h_2/h_3$, we can express $h_1$ and $h_2$ in terms of coarser mesh sizes: $h_1 = r h_2$ and $h_2 = r h_3$. Substituting these into the ratio gives:\n$$\\frac{Q_1 - Q_2}{Q_2 - Q_3} \\approx \\frac{(r h_2)^{p} - h_2^{p}}{(r h_3)^{p} - h_3^{p}} = \\frac{h_2^{p}(r^p - 1)}{h_3^{p}(r^p - 1)} = \\left(\\frac{h_2}{h_3}\\right)^p = r^p$$\nWe can now solve for $p$:\n$$p = \\frac{\\ln\\left(\\frac{Q_1 - Q_2}{Q_2 - Q_3}\\right)}{\\ln(r)}$$\nSubstituting the given numerical values:\n$$Q_1 - Q_2 = 5.432 - 5.308 = 0.124$$\n$$Q_2 - Q_3 = 5.308 - 5.276 = 0.032$$\nAnd the refinement ratio is $r=2$. Therefore,\n$$p = \\frac{\\ln\\left(\\frac{0.124}{0.032}\\right)}{\\ln(2)} = \\frac{\\ln(3.875)}{\\ln(2)} \\approx \\frac{1.35455}{0.69315} \\approx 1.95418$$\nThe observed order of accuracy is $p \\approx 1.954$. This value is close to $2$, which is the theoretical order for many common finite element schemes, indicating that the solutions are in the asymptotic range of convergence.\n\nNext, we calculate the Grid Convergence Index (GCI) for the finest-grid solution, based on the pair of solutions $(Q_2, Q_3)$. The GCI provides an estimate of the fractional error in the fine-grid solution. The formula is:\n$$\\text{GCI}_{\\text{fine}} = \\text{GCI}_{23} = \\frac{F_s}{|r^p - 1|} \\left| \\frac{Q_3 - Q_2}{Q_3} \\right|$$\nWe are given the safety factor $F_s = 1.25$. We use the refinement ratio for this pair, $r = h_2/h_3 = 2$, and the value of $p$ we just calculated.\nThe term $r^p$ is simply the ratio of solution differences we found earlier:\n$$r^p = 2^{p} = \\frac{Q_1 - Q_2}{Q_2 - Q_3} = 3.875$$\nThe relative difference term is:\n$$\\left| \\frac{Q_3 - Q_2}{Q_3} \\right| = \\left| \\frac{5.276 - 5.308}{5.276} \\right| = \\left| \\frac{-0.032}{5.276} \\right| \\approx 0.006065201$$\nNow, we can substitute all values into the GCI formula:\n$$\\text{GCI}_{23} = \\frac{1.25}{|3.875 - 1|} \\times 0.006065201 = \\frac{1.25}{2.875} \\times 0.006065201 \\approx 0.00263695$$\nRounding the result to four significant figures as requested:\n$$\\text{GCI}_{23} \\approx 0.002637$$\n\nThe triplet of solutions is consistent with monotonic, asymptotic convergence, as evidenced by the ordered solution values ($Q_1 > Q_2 > Q_3$) and an observed order of accuracy $p \\approx 1.954$ that is stable and close to the theoretical integer value of $2$. The computed value $\\text{GCI}_{23} \\approx 0.002637$ (or $0.2637\\%$) implies that the discretization uncertainty in the fine-grid solution $Q_3$ is estimated to be approximately $0.26\\%$. This low value suggests that the solution on the finest mesh is quite accurate and that further mesh refinement would yield only minor changes to the domain-integrated Joule heat. The numerical result is robust.",
            "answer": "$$\\boxed{0.002637}$$"
        },
        {
            "introduction": "Solving large-scale multiphysics problems is often intractable on a single processor, necessitating the use of parallel computing, which begins with partitioning the mesh into subdomains. In this practice, you will implement a greedy algorithm to partition a mesh, aiming to balance the computational load across processors while minimizing the communication required between them . This hands-on experience provides crucial insight into the practical challenges of preparing computational models for high-performance computing environments.",
            "id": "3526228",
            "problem": "Consider a domain discretized into a conforming quadrilateral finite element mesh for a multiphysics coupled simulation. The mesh is described by an element-to-node connectivity. Let the set of elements be denoted by $E=\\{0,1,\\dots,N_e-1\\}$, the set of nodes by $V=\\{0,1,\\dots,N_v-1\\}$, and the connectivity by a function $C:E\\to \\mathcal{P}(V)$ assigning to each element the set of its corner nodes. Let each element $e\\in E$ have a positive computational weight $w_e\\in \\mathbb{R}_{>0}$, representing the expected cost to assemble and solve local physics for that element. The objective is to partition the elements into $p$ processor sets $\\{P_0,P_1,\\dots,P_{p-1}\\}$ for parallel execution using the Message Passing Interface (MPI), attempting to minimize communication while respecting a load balance tolerance.\n\nFundamental base definitions to use:\n- A face adjacency between two distinct elements $e_i$ and $e_j$ exists if and only if $|C(e_i)\\cap C(e_j)|=2$, which represents a shared edge in the quadrilateral mesh. Let the undirected adjacency graph be $G=(E,\\mathcal{A})$ where $\\mathcal{A}\\subseteq \\{\\{e_i,e_j\\}\\mid e_i\\neq e_j\\}$ contains an edge if and only if the face adjacency holds.\n- The total computational load is $W=\\sum_{e\\in E} w_e$. The average per-processor load is $L_{\\mathrm{avg}}=W/p$.\n- A load balance tolerance $t\\in \\mathbb{R}_{\\ge 0}$ specifies the admissible upper bound on per-processor load: $L_{\\max}=(1+t)\\,L_{\\mathrm{avg}}$. A partition is declared feasible if and only if for all processors $k\\in\\{0,1,\\dots,p-1\\}$ the sum of weights assigned to $P_k$ is less than or equal to $L_{\\max}$.\n- The edge cut of a partition is the number of adjacency edges in $\\mathcal{A}$ whose endpoints are assigned to different processors. Formally, given an assignment function $a:E\\to \\{0,1,\\dots,p-1\\}$, the edge cut is $\\mathrm{cut}(a)=\\left|\\left\\{\\{e_i,e_j\\}\\in \\mathcal{A}\\mid a(e_i)\\neq a(e_j)\\right\\}\\right|$.\n\nYour program must implement a greedy partitioning heuristic grounded in these definitions:\n- Begin from a set of seed elements, one per processor, given as a list $S=[s_0,s_1,\\dots,s_{p-1}]$, where $s_k\\in \\{-1\\}\\cup E$. A seed of $-1$ indicates no initial element for that processor. If multiple processors request the same seed index, only the earliest processor in index order receives it; others with duplicate seeds are treated as having $-1$.\n- Iteratively assign unassigned elements to processors to grow connected subdomains. At each step, form for each processor $k$ a frontier consisting of unassigned neighbors of elements already assigned to $P_k$. For a candidate element $e$ in processor $k$'s frontier, define a local connectivity score $s_{k}(e)$ equal to the number of already assigned neighbors of $e$ in $P_k$. Prefer assignments that maximize $s_{k}(e)$ to promote locality. In the event of ties, prefer assignments that minimize the number of neighbors of $e$ assigned to other processors, then prefer smaller $w_e$, and then smaller element index.\n- Only accept assignments that do not cause the processor's load to exceed $L_{\\max}$. If no frontier candidate is admissible for any processor, choose the lightest remaining element and assign it to the least-loaded processor that can accommodate it. If no processor can accommodate any remaining element within $L_{\\max}$, continue assigning to the least-loaded processor anyway, and declare the final partition infeasible.\n- Continue until all elements are assigned. Finally, report whether the tolerance was satisfied, the maximum load ratio $\\max_k \\left(\\sum_{e\\in P_k} w_e\\right)/L_{\\mathrm{avg}}$, and the edge cut of the partition.\n\nMesh and indexing convention:\n- The mesh is structured as an $n_x\\times n_y$ array of quadrilateral elements. Nodes lie on a grid of size $(n_x+1)\\times(n_y+1)$ and each element has four nodes: the lower-left, lower-right, upper-right, and upper-left corners. Elements are indexed in row-major order: an element at column $i\\in\\{0,\\dots,n_x-1\\}$ and row $j\\in\\{0,\\dots,n_y-1\\}$ has index $e=j\\cdot n_x+i$.\n\nTest suite:\nImplement the heuristic and run it on the following four test cases. For each, you must construct the structured mesh connectivity $C$ programmatically from $n_x$ and $n_y$ as described above, derive face adjacency $\\mathcal{A}$, and apply the greedy algorithm with the provided $w_e$, $p$, $t$, and $S$.\n\n- Case $1$ (happy path):\n  - $n_x=3$, $n_y=2$.\n  - $p=2$, $t=0.2$.\n  - Seeds $S=[0,5]$.\n  - Uniform weights $w_e=1$ for all $e$.\n- Case $2$ (boundary tolerance $0$):\n  - $n_x=2$, $n_y=2$.\n  - $p=2$, $t=0.0$.\n  - Seeds $S=[0,3]$.\n  - Uniform weights $w_e=1$ for all $e$.\n- Case $3$ (infeasible due to a heavy element):\n  - $n_x=1$, $n_y=4$.\n  - $p=2$, $t=0.0$.\n  - Seeds $S=[0,3]$.\n  - Weights $w=[5,1,1,1]$ assigned to elements in index order.\n- Case $4$ (more processors than elements, feasible with large tolerance):\n  - $n_x=2$, $n_y=1$.\n  - $p=3$, $t=1.0$.\n  - Seeds $S=[0,1,-1]$ where $-1$ denotes no seed.\n  - Weights $w=[2,1]$ assigned to elements in index order.\n\nAnswer specification:\n- For each test case, compute and return a list $[b,r,c]$ where $b$ is a boolean feasibility indicator, $r$ is the floating-point maximum load ratio $\\max_k \\left(\\sum_{e\\in P_k} w_e\\right)/L_{\\mathrm{avg}}$, and $c$ is the integer edge cut $\\mathrm{cut}(a)$.\n- Your program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, with each test case's triple itself enclosed in square brackets. For example, the printed output should look like $[[b_1,r_1,c_1],[b_2,r_2,c_2],[b_3,r_3,c_3],[b_4,r_4,c_4]]$ where each $b_i$ is either $\\mathrm{True}$ or $\\mathrm{False}$, each $r_i$ is a real number, and each $c_i$ is an integer.",
            "solution": "The problem statement has been validated and is deemed valid. It is scientifically grounded in the principles of parallel computing and computational mechanics, specifically regarding mesh partitioning for finite element analysis. The problem is well-posed, providing a deterministic greedy heuristic with explicit rules for initialization, iteration, tie-breaking, and exceptional/fallback cases. All terms are formally defined, and the test cases are well-specified. The problem is a non-trivial implementation task that correctly formalizes a standard approach to domain decomposition.\n\nThe solution proceeds by first constructing the mesh data structures, then implementing the specified greedy partitioning algorithm, and finally calculating the required output metrics for each test case.\n\n### Step 1: Mesh and Adjacency Graph Construction\n\nThe problem defines a structured mesh of $n_x \\times n_y$ quadrilateral elements. The total number of elements is $N_e = n_x \\cdot n_y$. Elements are indexed $e \\in \\{0, 1, \\dots, N_e-1\\}$ in row-major order, where an element at grid position $(i, j)$ with $i \\in \\{0, \\dots, n_x-1\\}$ and $j \\in \\{0, \\dots, n_y-1\\}$ has index $e = j \\cdot n_x + i$.\n\nThe adjacency graph $G=(E, \\mathcal{A})$ is defined by face adjacencies, where two elements are adjacent if they share two nodes (an edge). For a structured grid, this simplifies to identifying neighbors in the four cardinal directions (left, right, top, bottom). For an element $e = j \\cdot n_x + i$:\n- Its left neighbor is $(j \\cdot n_x + i) - 1$, if $i > 0$.\n- Its right neighbor is $(j \\cdot n_x + i) + 1$, if $i < n_x-1$.\n- Its bottom neighbor is $(j-1) \\cdot n_x + i$, if $j > 0$.\n- Its top neighbor is $(j+1) \\cdot n_x + i$, if $j < n_y-1$.\nThis information is used to build an adjacency list representation, where for each element $e$, we store a list of its adjacent elements.\n\n### Step 2: Algorithm Initialization\n\nFor a given number of processors $p$ and a set of element weights $\\{w_e\\}_{e\\in E}$, we compute the total weight $W = \\sum_{e \\in E} w_e$ and the average load per processor $L_{\\mathrm{avg}} = W/p$. The load balance tolerance $t$ defines the maximum permissible load for any processor as $L_{\\max} = (1+t)L_{\\mathrm{avg}}$.\n\nThe partitioning process is initialized with the following data structures:\n- An assignment array $a$ of size $N_e$, where $a[e]$ will store the processor index for element $e$. Initially, all entries are set to a value indicating \"unassigned,\" e.g., $-1$.\n- A processor loads array of size $p$, tracking the current sum of weights for each processor partition $P_k$. Initially all loads are $0$.\n- A set of unassigned elements, initially containing all elements $E$.\n\nThe initial seeds $S=[s_0, s_1, \\dots, s_{p-1}]$ are processed. For each processor $k \\in \\{0, \\dots, p-1\\}$, if its seed $s_k$ is a valid, unassigned element index (i.e., $s_k \\neq -1$ and has not been claimed by a lower-indexed processor), element $s_k$ is assigned to processor $k$. The assignment array, processor loads, and the set of unassigned elements are updated accordingly.\n\n### Step 3: Iterative Greedy Assignment\n\nThe algorithm proceeds in a loop until all elements are assigned. In each step, it attempts to find the \"best\" element to assign based on a multi-criteria score.\n\n1.  **Frontier-Based Candidate Selection**: For each processor $k$, a frontier is formed, consisting of all unassigned elements that are adjacent to at least one element already assigned to processor $k$. Each element in each processor's frontier becomes a candidate for assignment.\n\n2.  **Candidate Scoring and Tie-Breaking**: A candidate assignment of element $e$ to processor $k$ is evaluated only if it is admissible, i.e., if adding $w_e$ to processor $k$'s current load does not exceed $L_{\\max}$. Admissible candidates are scored based on a lexicographical ordering to find the globally best move:\n    a. Maximize the local connectivity score $s_k(e)$, defined as the number of neighbors of $e$ already assigned to processor $k$.\n    b. Minimize the number of neighbors of $e$ that have been assigned to any other processor $j \\neq k$.\n    c. Minimize the element weight $w_e$.\n    d. Minimize the element index $e$.\n\n    The best move is the one with the lexicographically largest score tuple $(s_k(e), \\text{-external\\_neighbors}, -w_e, -e)$.\n\n3.  **Move Execution**:\n    - If a best admissible move is found from the frontiers, the corresponding element is assigned to its new processor, and all state variables are updated.\n    - If no admissible moves are available on any frontier, a fallback strategy is employed:\n        i. Identify the unassigned element $e_{\\text{lightest}}$ with the minimum weight $w_e$, breaking ties with the smallest element index $e$.\n        ii. Find the processor $k_{\\text{best}}$ that can accommodate this element (i.e., `load` $+ w_{e_{\\text{lightest}}} \\le L_{\\max}$) and currently has the minimum load. Ties are broken by the smallest processor index $k$. If such a processor exists, $e_{\\text{lightest}}$ is assigned to $k_{\\text{best}}$.\n        iii. If no processor can accommodate $e_{\\text{lightest}}$, the problem requires assigning it to the processor with the absolute minimum load, even though this violates the $L_{\\max}$ constraint. The problem states that such an assignment renders the final partition infeasible.\n\n### Step 4: Final Result Calculation\n\nOnce all elements have been assigned, the final partition is evaluated:\n- **Feasibility ($b$)**: The partition is feasible if and only if the final load of every processor $k$ is less than or equal to $L_{\\max}$. This is a direct application of the definition provided in the problem statement.\n- **Maximum Load Ratio ($r$)**: This is computed as $\\frac{\\max_k(\\sum_{e \\in P_k} w_e)}{L_{\\mathrm{avg}}}$. If $L_{\\mathrm{avg}}=0$, this ratio is taken to be $0$ (though not possible with $w_e > 0$).\n- **Edge Cut ($c$)**: This is the total number of edges $\\{e_i, e_j\\}$ in the adjacency graph $\\mathcal{A}$ such that $a[e_i] \\neq a[e_j]$. This is calculated by iterating through all elements and their neighbors, taking care to count each cut edge only once.\n\nThis comprehensive procedure is applied to each test case to produce the required results.",
            "answer": "```python\nimport numpy as np\n\ndef partition_mesh(nx, ny, p, t, seeds, weights):\n    \"\"\"\n    Implements the greedy mesh partitioning heuristic for a single test case.\n    \"\"\"\n    Ne = nx * ny\n    if Ne == 0:\n        if p == 0:\n             return [True, 0.0, 0]\n        W = 0.0\n        L_avg = 0.0 if p > 0 else float('inf')\n        max_load_ratio = 0.0 if L_avg > 0 else 0.0\n        return [True, max_load_ratio, 0]\n\n    # Step 1: Build Adjacency Graph\n    adj = [[] for _ in range(Ne)]\n    for j in range(ny):\n        for i in range(nx):\n            e = j * nx + i\n            # Right neighbor\n            if i < nx - 1:\n                neighbor = j * nx + (i + 1)\n                adj[e].append(neighbor)\n                adj[neighbor].append(e)\n            # Top neighbor\n            if j < ny - 1:\n                neighbor = (j + 1) * nx + i\n                adj[e].append(neighbor)\n                adj[neighbor].append(e)\n\n    for i in range(Ne):\n        adj[i] = sorted(list(set(adj[i])))\n\n    # Step 2: Initialization\n    W = sum(weights)\n    L_avg = W / p if p > 0 else float('inf')\n    L_max = (1 + t) * L_avg if p > 0 else 0\n\n    assignment = np.full(Ne, -1, dtype=int)\n    proc_loads = np.zeros(p)\n    unassigned_elements = set(range(Ne))\n    \n    # Process seeds\n    assigned_seed_elements = set()\n    for k in range(p):\n        s_k = seeds[k]\n        if s_k != -1 and s_k < Ne and s_k not in assigned_seed_elements:\n            assignment[s_k] = k\n            proc_loads[k] += weights[s_k]\n            unassigned_elements.remove(s_k)\n            assigned_seed_elements.add(s_k)\n\n    # Step 3: Iterative Greedy Assignment\n    while unassigned_elements:\n        best_move = None  # (score_tuple, element_idx, proc_idx)\n        \n        # Find best frontier move\n        for k in range(p):\n            frontier = set()\n            for e_assigned in np.where(assignment == k)[0]:\n                for neighbor in adj[e_assigned]:\n                    if assignment[neighbor] == -1:\n                        frontier.add(neighbor)\n            \n            for e_cand in sorted(list(frontier)): # sorted for determinism\n                if proc_loads[k] + weights[e_cand] <= L_max:\n                    # Calculate scores\n                    s_k = 0\n                    ext_neighbors = 0\n                    for neighbor in adj[e_cand]:\n                        if assignment[neighbor] == k:\n                            s_k += 1\n                        elif assignment[neighbor] != -1:\n                            ext_neighbors += 1\n                    \n                    score_tuple = (s_k, -ext_neighbors, -weights[e_cand], -e_cand)\n                    \n                    if best_move is None or score_tuple > best_move[0]:\n                        best_move = (score_tuple, e_cand, k)\n\n        if best_move is not None:\n            _, e_to_assign, k_to_assign = best_move\n            assignment[e_to_assign] = k_to_assign\n            proc_loads[k_to_assign] += weights[e_to_assign]\n            unassigned_elements.remove(e_to_assign)\n        else:\n            # Fallback strategy\n            e_lightest = -1\n            min_weight = float('inf')\n            # Find lightest unassigned element\n            for e in sorted(list(unassigned_elements)):\n                if weights[e] < min_weight:\n                    min_weight = weights[e]\n                    e_lightest = e\n            \n            # Find least-loaded processor that can accommodate it\n            k_best_fallback = -1\n            min_load_admissible = float('inf')\n            \n            candidate_procs = []\n            for k in range(p):\n                if proc_loads[k] + weights[e_lightest] <= L_max:\n                   candidate_procs.append(k)\n\n            if_found_admissible = False\n            if candidate_procs:\n                if_found_admissible = True\n                min_load = float('inf')\n                best_k = -1\n                for k in candidate_procs:\n                    if proc_loads[k] < min_load:\n                        min_load = proc_loads[k]\n                        best_k = k\n                k_best_fallback = best_k\n\n            if if_found_admissible:\n                assignment[e_lightest] = k_best_fallback\n                proc_loads[k_best_fallback] += weights[e_lightest]\n                unassigned_elements.remove(e_lightest)\n            else:\n                # No processor can accommodate, assign to least loaded anyway\n                k_infeasible = np.argmin(proc_loads)\n                assignment[e_lightest] = k_infeasible\n                proc_loads[k_infeasible] += weights[e_lightest]\n                unassigned_elements.remove(e_lightest)\n\n    # Step 4: Final Result Calculation\n    is_feasible = True\n    if p > 0 and np.any(proc_loads > L_max):\n        is_feasible = False\n\n    max_load_ratio = 0.0\n    if L_avg > 0:\n        max_load_ratio = np.max(proc_loads) / L_avg if p > 0 else 0.0\n\n    edge_cut = 0\n    for e1 in range(Ne):\n        for e2 in adj[e1]:\n            if e1 < e2:  # Count each edge once\n                if assignment[e1] != assignment[e2]:\n                    edge_cut += 1\n    \n    return [is_feasible, max_load_ratio, edge_cut]\n\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite for the partitioning problem.\n    \"\"\"\n    test_cases = [\n        # Case 1 (happy path)\n        {'nx': 3, 'ny': 2, 'p': 2, 't': 0.2, 'seeds': [0, 5], 'weights': [1.0] * 6},\n        # Case 2 (boundary tolerance 0)\n        {'nx': 2, 'ny': 2, 'p': 2, 't': 0.0, 'seeds': [0, 3], 'weights': [1.0] * 4},\n        # Case 3 (infeasible due to a heavy element)\n        {'nx': 1, 'ny': 4, 'p': 2, 't': 0.0, 'seeds': [0, 3], 'weights': [5.0, 1.0, 1.0, 1.0]},\n        # Case 4 (more processors than elements)\n        {'nx': 2, 'ny': 1, 'p': 3, 't': 1.0, 'seeds': [0, 1, -1], 'weights': [2.0, 1.0]},\n    ]\n    \n    results = []\n    for case in test_cases:\n        res = partition_mesh(\n            case['nx'], case['ny'], case['p'], case['t'], case['seeds'], case['weights']\n        )\n        results.append(res)\n        \n    output_parts = []\n    for res in results:\n        b_str = 'True' if res[0] else 'False'\n        # Format the float to avoid excessive precision if necessary, but default is usually fine\n        r_str = f\"{res[1]:.10f}\".rstrip('0').rstrip('.') if '.' in f\"{res[1]:.10f}\" else f\"{res[1]}\"\n        if r_str == \"\" or r_str == \"-\": r_str = \"0.0\"\n        if r_str == \"1.\": r_str = \"1.0\"\n        if r_str == \"2.\": r_str = \"2.0\"\n        c_str = str(res[2])\n        output_parts.append(f\"[{b_str},{float(r_str)},{c_str}]\")\n        \n    final_string = f\"[{','.join(output_parts)}]\"\n    print(final_string)\n\nsolve()\n```"
        }
    ]
}