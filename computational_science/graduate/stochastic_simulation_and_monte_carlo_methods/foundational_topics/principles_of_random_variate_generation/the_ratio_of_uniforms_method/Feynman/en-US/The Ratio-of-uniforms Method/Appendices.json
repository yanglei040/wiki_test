{
    "hands_on_practices": [
        {
            "introduction": "To master any new technique, it is essential to begin with a foundational example. This exercise guides you through a complete, from-scratch analysis of the ratio-of-uniforms method applied to the standard normal distribution, which is arguably the most important probability distribution in statistics. By deriving the acceptance set $A$, calculating the dimensions of its minimal bounding rectangle, and computing the resulting acceptance rate, you will solidify your understanding of the core mechanics of this powerful sampling algorithm .",
            "id": "3356654",
            "problem": "Consider the ratio-of-uniforms construction for sampling from an unnormalized target probability density function (PDF) on the real line given by $f(x)\\propto \\exp(-x^{2}/2)$. In the ratio-of-uniforms method, one samples uniformly over a set $A$ in the $(u,v)$-plane and returns $x=v/u$ for $u>0$. Starting only from the defining change of variables $(x,u)\\mapsto (u,v)=(u,ux)$ with $u>0$ and the admissibility condition that ensures the target density is proportional to the marginal density of $x$, do the following:\n\n1. Derive the exact analytic inequality describing the admissible set $A$ in the $(u,v)$-plane for this target.\n2. Determine the tight axis-aligned bounding rectangle of $A$ by computing $\\max u$ and $\\max|v|$.\n3. Compute the exact acceptance probability of the algorithm that proposes uniformly over this bounding rectangle and accepts if and only if the proposed point lies in $A$.\n4. In classical rejection sampling using a Gaussian proposal $q_{\\sigma}(x)=(2\\pi\\sigma^{2})^{-1/2}\\exp(-x^{2}/(2\\sigma^{2}))$ with variance parameter $\\sigma^{2}>0$, find the choice of $\\sigma$ and the minimal majorizing constant $M$ that minimize the rejection bound for the same unnormalized target $f(x)\\propto \\exp(-x^{2}/2)$, and compute the corresponding acceptance probability.\n\nProvide your final answer as a single row matrix (using parentheses notation) containing, in order: the analytic description of $A$, $\\max u$, $\\max|v|$, the acceptance probability from the ratio-of-uniforms bounding-rectangle scheme, and the optimal Gaussian-proposal rejection-sampling acceptance probability. Give exact expressions; do not approximate numerically. No rounding is required, and no physical units are involved. Express angles, if any, in radians.",
            "solution": "The problem is well-posed, scientifically grounded, and contains all necessary information for a unique solution. We will address each of the four parts in sequence. The unnormalized target probability density function is given as $f(x) \\propto \\exp(-x^2/2)$. For definiteness and without loss of generality for the ratio-of-uniforms method, we choose the specific representative $h(x) = \\exp(-x^2/2)$.\n\nFirst, we derive the analytic description of the admissible set $A$. The ratio-of-uniforms method samples points $(u,v)$ uniformly from the set $A$ defined in the $(u,v)$-plane by\n$$ A = \\left\\{ (u, v) \\in \\mathbb{R}^2 \\mid 0 < u \\le \\sqrt{h(v/u)} \\right\\} $$\nSubstituting our choice for $h(x)$, we get:\n$$ 0 < u \\le \\sqrt{\\exp\\left(-\\frac{(v/u)^2}{2}\\right)} $$\nThis simplifies to:\n$$ 0 < u \\le \\exp\\left(-\\frac{v^2}{4u^2}\\right) $$\nSince $u > 0$, we can take the natural logarithm of both sides of the inequality $u \\le \\exp(-v^2/(4u^2))$:\n$$ \\ln(u) \\le -\\frac{v^2}{4u^2} $$\nRearranging to isolate $v^2$:\n$$ v^2 \\le -4u^2 \\ln(u) $$\nFor this inequality to have a solution for $v \\in \\mathbb{R}$, the right-hand side must be non-negative. Since $u^2 > 0$, we require $-4\\ln(u) \\ge 0$, which implies $\\ln(u) \\le 0$. This holds for $u \\in (0, 1]$. Therefore, the set $A$ is described by the conditions:\n$0  u \\le 1 \\land v^2 \\le -4u^2\\ln(u)$\n\nSecond, we determine the tight axis-aligned bounding rectangle of $A$. This requires finding the maximum values of $u$ and $|v|$ over the set $A$.\nFrom the derivation above, the range of $u$ is $(0, 1]$, so the maximum value of $u$ is:\n$$ \\max u = 1 $$\nTo find the maximum value of $|v|$, we need to maximize the expression $\\sqrt{-4u^2 \\ln(u)}$ over the interval $u \\in (0, 1]$. This is equivalent to maximizing its square, the function $g(u) = -4u^2 \\ln(u)$. We find the maximum by taking the derivative with respect to $u$ and setting it to zero:\n$$ g'(u) = \\frac{d}{du}\\left(-4u^2 \\ln(u)\\right) = -4\\left(2u\\ln(u) + u^2\\frac{1}{u}\\right) = -4u(2\\ln(u) + 1) $$\nSetting $g'(u) = 0$ for $u \\in (0, 1]$ implies $2\\ln(u) + 1 = 0$, which gives $\\ln(u) = -1/2$, so $u = \\exp(-1/2)$.\nTo confirm this is a maximum, we can check the second derivative or note that $g'(u)  0$ for $u  \\exp(-1/2)$ and $g'(u)  0$ for $u  \\exp(-1/2)$. The value of $g(u)$ at the endpoints $u \\to 0^+$ and $u=1$ is $0$. Thus, the global maximum occurs at $u = \\exp(-1/2)$.\nThe maximum value of $g(u)$ is:\n$$ g(\\exp(-1/2)) = -4(\\exp(-1/2))^2 \\ln(\\exp(-1/2)) = -4\\exp(-1)\\left(-\\frac{1}{2}\\right) = 2\\exp(-1) $$\nThis is the maximum value of $v^2$. Therefore, the maximum value of $|v|$ is:\n$$ \\max|v| = \\sqrt{2\\exp(-1)} $$\nThe bounding rectangle is $R = [0, 1] \\times [-\\sqrt{2\\exp(-1)}, \\sqrt{2\\exp(-1)}]$.\n\nThird, we compute the acceptance probability of the algorithm. This is the ratio of the area of the set $A$ to the area of the bounding rectangle $R$.\nThe area of the bounding rectangle is:\n$$ \\text{Area}(R) = (\\max u) \\times (2 \\max|v|) = 1 \\cdot 2\\sqrt{2\\exp(-1)} = 2\\sqrt{2\\exp(-1)} $$\nThe area of the set $A$ is given by the integral:\n$$ \\text{Area}(A) = \\iint_A du\\,dv = \\int_0^1 \\left( \\int_{-\\sqrt{-4u^2\\ln(u)}}^{\\sqrt{-4u^2\\ln(u)}} dv \\right) du = \\int_0^1 2\\sqrt{-4u^2\\ln(u)} \\,du = \\int_0^1 4u\\sqrt{-\\ln(u)} \\,du $$\nTo evaluate this integral, we use the substitution $t = -\\ln(u)$, which implies $u = \\exp(-t)$ and $du = -\\exp(-t)dt$. The limits of integration change from $u \\in (0, 1]$ to $t \\in [\\infty, 0)$.\n$$ \\text{Area}(A) = \\int_\\infty^0 4\\exp(-t)\\sqrt{t} (-\\exp(-t)dt) = \\int_0^\\infty 4\\sqrt{t} \\exp(-2t) dt $$\nWe perform another substitution, $s=2t$, so $t=s/2$ and $dt=ds/2$.\n$$ \\text{Area}(A) = \\int_0^\\infty 4\\sqrt{s/2} \\exp(-s) \\frac{ds}{2} = \\frac{4}{\\sqrt{2} \\cdot 2} \\int_0^\\infty s^{1/2} \\exp(-s) ds = \\sqrt{2} \\int_0^\\infty s^{3/2 - 1} \\exp(-s) ds $$\nThe integral is the Gamma function $\\Gamma(3/2)$. Using $\\Gamma(z+1)=z\\Gamma(z)$ and $\\Gamma(1/2)=\\sqrt{\\pi}$, we have $\\Gamma(3/2) = \\frac{1}{2}\\Gamma(1/2) = \\frac{\\sqrt{\\pi}}{2}$.\n$$ \\text{Area}(A) = \\sqrt{2} \\cdot \\frac{\\sqrt{\\pi}}{2} = \\frac{\\sqrt{2\\pi}}{2} $$\nThe acceptance probability $P_{\\text{acc, RoU}}$ is:\n$$ P_{\\text{acc, RoU}} = \\frac{\\text{Area}(A)}{\\text{Area}(R)} = \\frac{\\sqrt{2\\pi}/2}{2\\sqrt{2\\exp(-1)}} = \\frac{\\sqrt{2\\pi}}{4\\sqrt{2}\\sqrt{\\exp(-1)}} = \\frac{\\sqrt{\\pi}}{4}\\sqrt{\\exp(1)} = \\frac{\\sqrt{\\pi \\exp(1)}}{4} $$\n\nFourth, we analyze the rejection sampling scheme. The unnormalized target is $p^*(x) = \\exp(-x^2/2)$. The proposal is the normalized Gaussian density $q_{\\sigma}(x) = (2\\pi\\sigma^2)^{-1/2}\\exp(-x^2/(2\\sigma^2))$ with $\\sigma^20$. Rejection sampling requires finding a constant $M$ such that $p^*(x) \\le Mq_{\\sigma}(x)$ for all $x$. To maximize the acceptance rate, we must find the minimal such $M$.\n$$ M = \\sup_{x \\in \\mathbb{R}} \\frac{p^*(x)}{q_{\\sigma}(x)} = \\sup_{x \\in \\mathbb{R}} \\frac{\\exp(-x^2/2)}{(2\\pi\\sigma^2)^{-1/2}\\exp(-x^2/(2\\sigma^2))} = \\sup_{x \\in \\mathbb{R}} \\sqrt{2\\pi\\sigma^2} \\exp\\left(x^2\\left(\\frac{1}{2\\sigma^2} - \\frac{1}{2}\\right)\\right) $$\nFor $M$ to be finite, the term in the exponent must be non-positive, i.e., $\\frac{1}{2\\sigma^2} - \\frac{1}{2} \\le 0$, which simplifies to $\\sigma^2 \\ge 1$.\nIf $\\sigma^2  1$, the exponent is negative, and the supremum of the expression is achieved at $x=0$, giving $M(\\sigma^2) = \\sqrt{2\\pi\\sigma^2}$.\nIf $\\sigma^2 = 1$, the exponent is zero, and the expression is constant, $M(1) = \\sqrt{2\\pi}$.\nWe want to find the choice of $\\sigma$ that minimizes $M$. The function $M(\\sigma^2) = \\sqrt{2\\pi\\sigma^2}$ for $\\sigma^2 \\ge 1$ is an increasing function of $\\sigma^2$. Therefore, its minimum occurs at the lowest possible value, $\\sigma^2=1$.\nThe optimal choice is $\\sigma=1$, which yields the minimal majorizing constant $M = \\sqrt{2\\pi}$.\nThe acceptance probability for rejection sampling is given by the formula $P_{\\text{acc, RS}} = \\frac{\\int_{-\\infty}^{\\infty} p^*(x) dx}{M}$.\nThe integral of the unnormalized target is a standard Gaussian integral:\n$$ \\int_{-\\infty}^{\\infty} p^*(x) dx = \\int_{-\\infty}^{\\infty} \\exp(-x^2/2) dx = \\sqrt{2\\pi} $$\nThus, the optimal acceptance probability is:\n$$ P_{\\text{acc, RS}} = \\frac{\\sqrt{2\\pi}}{M} = \\frac{\\sqrt{2\\pi}}{\\sqrt{2\\pi}} = 1 $$\nThis result is expected, as choosing $\\sigma=1$ means the proposal distribution is identical to the normalized target distribution, turning rejection sampling into direct sampling.\n\nThe five requested quantities are collected for the final answer.\n1. Analytic description of $A$: $0  u \\le 1 \\land v^2 \\le -4u^2\\ln(u)$\n2. $\\max u$: $1$\n3. $\\max|v|$: $\\sqrt{2\\exp(-1)}$\n4. Acceptance probability (ratio-of-uniforms): $\\frac{\\sqrt{\\pi \\exp(1)}}{4}$\n5. Acceptance probability (rejection sampling): $1$",
            "answer": "$$ \\boxed{ \\pmatrix{ 0  u \\le 1 \\land v^2 \\le -4u^2\\ln(u)  1  \\sqrt{2\\exp(-1)}  \\frac{\\sqrt{\\pi \\exp(1)}}{4}  1 } } $$"
        },
        {
            "introduction": "A key strength of the ratio-of-uniforms method is its adaptability to densities with specific structural properties. This practice explores how the method can be specialized for distributions defined on the positive real line, such as the exponential or gamma distributions, which are common in modeling waiting times or other positive quantities. You will derive a modified \"one-sided\" acceptance set and learn how properties like monotonicity can be exploited to determine the bounding box efficiently , showcasing how theoretical insights lead to practical algorithmic improvements.",
            "id": "3356644",
            "problem": "Let $f$ be a probability density function (pdf) supported on $x \\ge 0$ that is continuous, strictly positive on $(0,\\infty)$, and monotone decreasing on $(0,\\infty)$. Consider the ratio-of-uniforms (RoU) method adapted to the one-sided support via the change of variables $v = u x$ with $u \\ge 0$ and $v \\ge 0$.\n\n1. Starting only from the definition that the RoU acceptance set is the collection of points $(u,v)$ such that the back-transformed $x = v/u$ lies in the support of the target and the inequality $u \\le \\sqrt{f(x)}$ holds, derive a one-sided acceptance set in the $(u,v)$-plane that yields samples $X = V/U$ with density proportional to $f$. Explicitly characterize this acceptance set in terms of $f$ and $x$.\n\n2. Prove that this one-sided acceptance set is contained in a rectangle $[0,U^{\\star}] \\times [0,V^{\\star}]$ for some finite $U^{\\star}$ and $V^{\\star}$, provided that $f(0)$ is finite and $\\sup_{x \\ge 0} x \\sqrt{f(x)}$ is finite. Show that the smallest such bounding constants are\n$$\nU^{\\star} = \\sup_{x \\ge 0} \\sqrt{f(x)}, \n\\qquad\nV^{\\star} = \\sup_{x \\ge 0} x \\sqrt{f(x)}.\n$$\nFurther, use monotonicity to simplify $U^{\\star}$ to $U^{\\star} = \\sqrt{f(0)}$.\n\n3. Suppose, in addition, that the logarithmic derivative of $f$ is bounded for all $x \\ge 0$ as\n$$\n-\\beta \\le \\frac{d}{dx}\\ln f(x) \\le -\\alpha,\n$$\nfor some known $0  \\alpha \\le \\beta  \\infty$, and let $c := f(0) \\in (0,\\infty)$. Using only these bounds and the fact that $f$ is monotone decreasing, derive explicit bounds on $U^{\\star}$ and $V^{\\star}$ that depend only on $c$ and $\\alpha$, and argue that these are tight in the sense that there exist densities consistent with the given information that saturate them.\n\n4. Specialize your expressions to the gamma family with shape parameter equal to one and rate $\\theta  0$, i.e., the exponential pdf $f(x) = \\theta \\exp(-\\theta x)$ on $x \\ge 0$. Compute the pair $(U^{\\star}, V^{\\star})$ as explicit functions of $\\theta$.\n\nProvide your final answer as a single row matrix containing $U^{\\star}$ and $V^{\\star}$ for the gamma family with shape one, in exact closed form. No rounding is required and no units are involved.",
            "solution": "This problem is a valid exercise in the analysis of the ratio-of-uniforms (RoU) sampling method. All parts are well-defined, mathematically sound, and sequentially build upon each other. We proceed with the solution.\n\n1.  Derivation of the one-sided acceptance set.\n\nThe ratio-of-uniforms method generates points $(u,v)$ in a region $\\mathcal{A}$ and then transforms them to samples of the target variable $X$. For a target probability density function $f(x)$ with support on $x \\ge 0$, a one-sided version of the method is used with the transformation $x=v/u$. The acceptance set $\\mathcal{A}$ is defined as the collection of points $(u,v)$ in the plane for which the back-transformed point $x$ lies in the support of the target and an inequality related to $f(x)$ is satisfied.\n\nThe problem provides the following definitions and constraints:\n- The transformation is $x = v/u$, with $u \\ge 0$ and $v \\ge 0$.\n- The support of $f$ is $x \\ge 0$. With $u \\ge 0$ and $v \\ge 0$, the condition $x=v/u \\ge 0$ is automatically satisfied for any $u  0$. The case $u=0$ implies $v=0 \\cdot x = 0$, so the origin $(0,0)$ is a boundary point.\n- The acceptance inequality is $u \\le \\sqrt{f(x)}$.\n\nTo characterize the acceptance set $\\mathcal{A}$ in the $(u,v)$-plane, we substitute $x = v/u$ into the inequality:\n$$\nu \\le \\sqrt{f\\left(\\frac{v}{u}\\right)}\n$$\nSince $u$ is non-negative, we can square both sides of the inequality without changing its direction:\n$$\nu^2 \\le f\\left(\\frac{v}{u}\\right)\n$$\nCombining this with the domain constraints on $u$ and $v$, the acceptance set $\\mathcal{A}$ is explicitly characterized as:\n$$\n\\mathcal{A} = \\left\\{ (u, v) \\mid u \\ge 0, v \\ge 0, \\text{ and } u^2 \\le f\\left(\\frac{v}{u}\\right) \\right\\}\n$$\nIn practice, for sampling, one typically considers $u  0$. The expression using $u^2$ avoids issues with the definition of $v/u$ at $u=0$.\n\n2.  Proof of the bounding rectangle and its minimal size.\n\nThe RoU algorithm requires sampling uniformly from $\\mathcal{A}$. A common way to do this is to enclose $\\mathcal{A}$ in a minimal bounding rectangle $[0, U^{\\star}] \\times [0, V^{\\star}]$ and use rejection sampling. The bounds of this rectangle are given by the suprema of the coordinates over the set $\\mathcal{A}$.\n$$\nU^{\\star} = \\sup_{(u,v) \\in \\mathcal{A}} u \\qquad \\text{and} \\qquad V^{\\star} = \\sup_{(u,v) \\in \\mathcal{A}} v\n$$\nFor any point $(u,v) \\in \\mathcal{A}$, there exists an $x = v/u \\ge 0$ such that $u \\le \\sqrt{f(x)}$. To find the supremum of $u$, we must consider all possible values for the upper bound $\\sqrt{f(x)}$ as $x$ ranges over its support $[0, \\infty)$.\n$$\nU^{\\star} = \\sup \\left\\{ u \\mid \\exists x \\ge 0 \\text{ s.t. } u \\le \\sqrt{f(x)} \\right\\} = \\sup_{x \\ge 0} \\sqrt{f(x)}\n$$\nFor the supremum of $v$, we use the relations $v=ux$ and $u \\le \\sqrt{f(x)}$. For any fixed $x$, the value of $v$ is maximized when $u$ is maximized. Substituting the maximum possible value for $u$ (for a given $x$), which is $\\sqrt{f(x)}$, we find an upper bound for $v$:\n$$\nv = ux \\le x \\sqrt{f(x)}\n$$\nTo find the overall supremum $V^{\\star}$, we must find the supremum of this expression over all possible values of $x \\ge 0$:\n$$\nV^{\\star} = \\sup_{x \\ge 0} \\left( x \\sqrt{f(x)} \\right)\n$$\nThe problem statement provides that $f(0)$ is finite and $\\sup_{x \\ge 0} x\\sqrt{f(x)}$ is finite, which guarantees that $U^{\\star}$ and $V^{\\star}$ are finite.\n\nNow, we use the property that $f$ is monotone decreasing on $(0, \\infty)$ and continuous on $[0, \\infty)$. A continuous, decreasing function on $[0, \\infty)$ achieves its maximum at the left endpoint, $x=0$.\n$$\n\\sup_{x \\ge 0} f(x) = f(0)\n$$\nSince the square root function is monotonically increasing, the supremum of the square root is the square root of the supremum:\n$$\nU^{\\star} = \\sup_{x \\ge 0} \\sqrt{f(x)} = \\sqrt{\\sup_{x \\ge 0} f(x)} = \\sqrt{f(0)}\n$$\nThis simplifies the expression for $U^{\\star}$ as required.\n\n3.  Derivation of bounds from the logarithmic derivative.\n\nWe are given the bounds on the logarithmic derivative of $f(x)$:\n$$\n-\\beta \\le \\frac{d}{dx}\\ln f(x) \\le -\\alpha, \\quad \\text{for } 0  \\alpha \\le \\beta  \\infty\n$$\nLet's use the upper bound $\\frac{d}{dx}\\ln f(x) \\le -\\alpha$. Integrating this inequality from $t=0$ to $t=x$:\n$$\n\\int_0^x \\frac{d}{dt}\\ln f(t) dt \\le \\int_0^x (-\\alpha) dt\n$$\n$$\n\\ln f(x) - \\ln f(0) \\le -\\alpha x\n$$\nGiven $c := f(0)$, this becomes $\\ln(f(x)/c) \\le -\\alpha x$. Exponentiating both sides yields an upper bound on $f(x)$:\n$$\nf(x) \\le c \\exp(-\\alpha x)\n$$\nFrom Part 2, we have the exact expression $U^{\\star} = \\sqrt{f(0)}$. Using $c=f(0)$, we find:\n$$\nU^{\\star} = \\sqrt{c}\n$$\nThis expression depends on $c$ and can be considered a trivial function of $\\alpha$.\n\nTo find a bound on $V^{\\star}$, we use the bound on $f(x)$:\n$$\nV^{\\star} = \\sup_{x \\ge 0} x \\sqrt{f(x)} \\le \\sup_{x \\ge 0} x \\sqrt{c \\exp(-\\alpha x)} = \\sqrt{c} \\sup_{x \\ge 0} \\left( x \\exp\\left(-\\frac{\\alpha x}{2}\\right) \\right)\n$$\nLet $g(x) = x \\exp(-\\frac{\\alpha x}{2})$. To find its supremum, we compute its derivative with respect to $x$:\n$$\ng'(x) = 1 \\cdot \\exp\\left(-\\frac{\\alpha x}{2}\\right) + x \\cdot \\left(-\\frac{\\alpha}{2}\\right) \\exp\\left(-\\frac{\\alpha x}{2}\\right) = \\left(1 - \\frac{\\alpha x}{2}\\right) \\exp\\left(-\\frac{\\alpha x}{2}\\right)\n$$\nSetting $g'(x)=0$ implies $1 - \\frac{\\alpha x}{2} = 0$, which gives a critical point at $x = 2/\\alpha$. Since $g(0)=0$ and $g(x) \\to 0$ as $x \\to \\infty$, this point is a global maximum. The maximum value of $g(x)$ is:\n$$\ng\\left(\\frac{2}{\\alpha}\\right) = \\frac{2}{\\alpha} \\exp\\left(-\\frac{\\alpha}{2} \\cdot \\frac{2}{\\alpha}\\right) = \\frac{2}{\\alpha} \\exp(-1) = \\frac{2}{\\alpha e}\n$$\nTherefore, we obtain the upper bound for $V^{\\star}$:\n$$\nV^{\\star} \\le \\sqrt{c} \\cdot \\frac{2}{\\alpha e} = \\frac{2\\sqrt{c}}{\\alpha e}\n$$\nTo argue that this bound is tight, we must show there exists a function $f(x)$ satisfying all the given conditions for which this bound is achieved. Consider the function $f(x) = c \\exp(-\\alpha x)$.\n- It is a pdf (up to a normalization constant, which doesn't affect the calculation of $U^\\star$ and $V^\\star$ for the RoU method applied to the unnormalized density).\n- It is continuous, positive, and monotone decreasing.\n- $f(0) = c \\exp(0) = c$.\n- Its logarithmic derivative is $\\frac{d}{dx}(\\ln c - \\alpha x) = -\\alpha$. This satisfies $-\\beta \\le -\\alpha \\le -\\alpha$ because we are given $\\alpha \\le \\beta$.\nFor this specific function, the value of $V^{\\star}$ is:\n$$\nV^{\\star} = \\sup_{x \\ge 0} x \\sqrt{c \\exp(-\\alpha x)} = \\sqrt{c} \\sup_{x \\ge 0} x \\exp\\left(-\\frac{\\alpha x}{2}\\right) = \\frac{2\\sqrt{c}}{\\alpha e}\n$$\nSince this value matches the derived upper bound, the bound is tight.\n\n4.  Specialization to the exponential PDF.\n\nWe are given the exponential probability density function $f(x) = \\theta \\exp(-\\theta x)$ for $x \\ge 0$ and $\\theta  0$. We compute $(U^{\\star}, V^{\\star})$ using the general formulas from Part 2.\nFirst, we find $U^{\\star}$:\n$$\nU^{\\star} = \\sqrt{f(0)} = \\sqrt{\\theta \\exp(-\\theta \\cdot 0)} = \\sqrt{\\theta \\cdot 1} = \\sqrt{\\theta}\n$$\nNext, we find $V^{\\star}$:\n$$\nV^{\\star} = \\sup_{x \\ge 0} x \\sqrt{f(x)} = \\sup_{x \\ge 0} x \\sqrt{\\theta \\exp(-\\theta x)} = \\sqrt{\\theta} \\sup_{x \\ge 0} \\left( x \\exp\\left(-\\frac{\\theta x}{2}\\right) \\right)\n$$\nThis maximization problem is identical in form to the one in Part 3, with $\\alpha$ replaced by $\\theta$. The function $x \\exp(-\\frac{\\theta x}{2})$ is maximized at $x=2/\\theta$, and its maximum value is $2/(\\theta e)$.\nSubstituting this result back into the expression for $V^{\\star}$:\n$$\nV^{\\star} = \\sqrt{\\theta} \\cdot \\left( \\frac{2}{\\theta e} \\right) = \\frac{2\\sqrt{\\theta}}{\\theta e} = \\frac{2\\sqrt{\\theta}}{(\\sqrt{\\theta})^2 e} = \\frac{2}{e\\sqrt{\\theta}}\n$$\nThus, for the exponential distribution with rate $\\theta$, the parameters for the minimal bounding rectangle are $(U^{\\star}, V^{\\star}) = (\\sqrt{\\theta}, \\frac{2}{e\\sqrt{\\theta}})$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\sqrt{\\theta}  \\frac{2}{e\\sqrt{\\theta}}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "In practical applications, no single sampling algorithm is universally optimal; the most efficient solutions are often hybrid. This advanced exercise challenges you to build a composite sampler that intelligently combines two different techniques: inverse-CDF sampling for the center of a distribution and the ratio-of-uniforms method for its tails. Your task is to optimize this hybrid approach by minimizing a total cost function, a scenario that mirrors the real-world design of high-performance statistical software and demonstrates how to use the ratio-of-uniforms method as a component in a more sophisticated computational strategy .",
            "id": "3356643",
            "problem": "Consider the target distribution with probability density function $f(x) = \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{x^2}{2}\\right)$ on $\\mathbb{R}$ (the standard normal distribution). The ratio-of-uniforms method constructs a set $A$ in the plane defined by\n$$\nA = \\left\\{(u,v)\\in\\mathbb{R}^2: u gt; 0,\\; u \\le \\sqrt{f\\!\\left(\\frac{v}{u}\\right)}\\right\\}.\n$$\nA draw $(u,v)$ is sampled uniformly from a bounding rectangle that contains $A$, and a value $x$ is accepted if $(u,v)\\in A$, with the output $x=v/u$. Consider a composite sampler that uses inverse-cumulative distribution function (inverse-CDF) sampling in the central region $\\{|x|\\le r\\}$ and ratio-of-uniforms sampling in the tails $\\{|x|gt;r\\}$. The inverse-CDF sampling of the central region uses the conditional distribution truncated to $\\{-r\\le x\\le r\\}$, and the ratio-of-uniforms sampling is restricted to $\\{|x|gt;r\\}$.\n\nAssume the following cost model:\n- Each inverse-CDF sample from the truncated center has a constant cost $c_{\\mathrm{ppf}} gt; 0$.\n- Each proposal in the ratio-of-uniforms scheme has cost $c_{\\mathrm{prop}} gt; 0$, and the expected number of proposals needed for one accepted tail sample equals the reciprocal of the acceptance rate for the tail region.\n\nLet $A_r$ denote the ratio-of-uniforms acceptance set restricted to the tails,\n$$\nA_r = \\left\\{(u,v)\\in A: \\left|\\frac{v}{u}\\right| gt; r\\right\\}.\n$$\nLet $a(r)$ denote the acceptance rate for the tail region, equal to the proportion of the bounding rectangle’s area that lies in $A_r$. Let $p_{\\mathrm{center}}(r)=\\mathbb{P}(|X|\\le r)$ and $p_{\\mathrm{tail}}(r)=1-p_{\\mathrm{center}}(r)$, where $X\\sim \\mathcal{N}(0,1)$ is the target. The expected total cost per composite sample is\n$$\nC(r) = p_{\\mathrm{center}}(r)\\,c_{\\mathrm{ppf}} \\;+\\; p_{\\mathrm{tail}}(r)\\,\\frac{c_{\\mathrm{prop}}}{a(r)}.\n$$\n\nTasks:\n1. Derive the bounding rectangle for $A$ by expressing its $u$-extent and $v$-extent in terms of $f$. Then implement a numerical procedure that approximates $a(r)$ by computing the area fraction of $A_r$ within this rectangle via a uniform grid over $(u,v)$.\n2. Implement the composite sampler:\n   - Center sampling: draw from the truncated central distribution $\\{-r\\le x\\le r\\}$ using inverse-CDF (quantile) transformation of the standard normal cumulative distribution function.\n   - Tail sampling: draw $(u,v)$ uniformly from the bounding rectangle and accept if $(u,v)\\in A$ and $\\left|\\frac{v}{u}\\right|gt;r$, returning $x=v/u$.\n   - Mixture selection: choose center versus tail sampling with probabilities $p_{\\mathrm{center}}(r)$ and $p_{\\mathrm{tail}}(r)$, respectively, to reproduce the target distribution exactly.\n3. Optimize $r$ by minimizing $C(r)$ over a specified interval $[0,R]$ using the acceptance rates $a(r)$ computed from Task 1. Use a deterministic search procedure and report the optimizer $r^\\star$.\n\nUse only the mathematical definitions above, without any shortcut formulas. In particular, do not assume precomputed constants beyond those deducible from $f$. Your program should perform the numerical approximation of $a(r)$ using a uniform grid over the bounding rectangle for $A$ and use the standard normal cumulative distribution function to compute $p_{\\mathrm{center}}(r)$.\n\nTest Suite:\nEvaluate $r^\\star$ for the following parameter sets; for each test case, use a uniform $(u,v)$ grid of the prescribed resolution to compute $a(r)$, and search over $r\\in[0,R]$ with a deterministic grid search over $N_r$ equally spaced points.\n\n- Test case 1: $(c_{\\mathrm{prop}}, c_{\\mathrm{ppf}}, M_u, M_v, R, N_r) = (1.0,\\,1.0,\\,600,\\,1200,\\,3.5,\\,701)$.\n- Test case 2: $(c_{\\mathrm{prop}}, c_{\\mathrm{ppf}}, M_u, M_v, R, N_r) = (1.0,\\,6.0,\\,600,\\,1200,\\,3.5,\\,701)$.\n- Test case 3: $(c_{\\mathrm{prop}}, c_{\\mathrm{ppf}}, M_u, M_v, R, N_r) = (0.2,\\,3.0,\\,600,\\,1200,\\,3.5,\\,701)$.\n- Test case 4: $(c_{\\mathrm{prop}}, c_{\\mathrm{ppf}}, M_u, M_v, R, N_r) = (3.0,\\,0.5,\\,600,\\,1200,\\,3.5,\\,701)$.\n\nHere, $M_u$ is the number of grid points for the $u$-axis, $M_v$ for the $v$-axis, $R$ is the maximum radius for the search interval, and $N_r$ is the number of search points for $r$. For numerical stability in computing $\\frac{v}{u}$, avoid $u=0$ exactly by beginning the $u$-grid at a small positive value.\n\nFinal Output Format:\nYour program should produce a single line of output containing the optimal radii for all test cases as a comma-separated list enclosed in square brackets, with each value rounded to six decimal places (e.g., \"[r1,r2,r3,r4]\") and in the same order as the test cases.",
            "solution": "The user wants me to find the optimal radius $r$ for a composite sampler by minimizing an expected cost function.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n- **Target Distribution PDF:** $f(x) = \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{x^2}{2}\\right)$ for $x \\in \\mathbb{R}$.\n- **Ratio-of-Uniforms Set (A):** $A = \\left\\{(u,v)\\in\\mathbb{R}^2: u  0,\\; u \\le \\sqrt{f\\!\\left(\\frac{v}{u}\\right)}\\right\\}$.\n- **Tail Acceptance Set (A_r):** $A_r = \\left\\{(u,v)\\in A: \\left|\\frac{v}{u}\\right|  r\\right\\}$.\n- **Composite Sampler Structure:**\n    - Center region: $\\{|x|\\le r\\}$, sampled via inverse-CDF.\n    - Tail region: $\\{|x|r\\}$, sampled via ratio-of-uniforms.\n- **Probabilities:** $p_{\\mathrm{center}}(r)=\\mathbb{P}(|X|\\le r)$ and $p_{\\mathrm{tail}}(r)=1-p_{\\mathrm{center}}(r)$, where $X\\sim \\mathcal{N}(0,1)$.\n- **Cost Model:**\n    - Inverse-CDF cost: $c_{\\mathrm{ppf}}  0$.\n    - Ratio-of-uniforms proposal cost: $c_{\\mathrm{prop}}  0$.\n    - Expected total cost: $C(r) = p_{\\mathrm{center}}(r)\\,c_{\\mathrm{ppf}} \\;+\\; p_{\\mathrm{tail}}(r)\\,\\frac{c_{\\mathrm{prop}}}{a(r)}$.\n- **Acceptance Rate (a(r)):** Proportion of the bounding rectangle’s area that lies in $A_r$.\n- **Tasks:**\n    1. Derive the bounding rectangle for $A$ and implement a numerical procedure to approximate $a(r)$ using a uniform grid over $(u,v)$.\n    2. Implement the composite sampler's cost function.\n    3. Optimize $r$ by minimizing $C(r)$ over $[0,R]$ via a grid search.\n- **Test Suite Parameters:**\n    - Test case 1: $(c_{\\mathrm{prop}}, c_{\\mathrm{ppf}}, M_u, M_v, R, N_r) = (1.0,\\,1.0,\\,600,\\,1200,\\,3.5,\\,701)$.\n    - Test case 2: $(c_{\\mathrm{prop}}, c_{\\mathrm{ppf}}, M_u, M_v, R, N_r) = (1.0,\\,6.0,\\,600,\\,1200,\\,3.5,\\,701)$.\n    - Test case 3: $(c_{\\mathrm{prop}}, c_{\\mathrm{ppf}}, M_u, M_v, R, N_r) = (0.2,\\,3.0,\\,600,\\,1200,\\,3.5,\\,701)$.\n    - Test case 4: $(c_{\\mathrm{prop}}, c_{\\mathrm{ppf}}, M_u, M_v, R, N_r) = (3.0,\\,0.5,\\,600,\\,1200,\\,3.5,\\,701)$.\n    - $M_u, M_v$: grid resolution. $R$: max search radius. $N_r$: number of search points for $r$.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientifically Grounded:** The problem is rooted in the established statistical theory of Monte Carlo methods, specifically the ratio-of-uniforms sampling technique, and standard numerical optimization. The target distribution is the standard normal distribution, a fundamental object in probability theory. All concepts are standard and mathematically sound.\n- **Well-Posed:** The problem defines a clear objective function $C(r)$ to be minimized over a specified compact interval $[0,R]$. The function components are well-defined. The numerical procedure for approximation is specified. A unique minimizer is expected to exist and can be found via the prescribed grid search.\n- **Objective:** The problem statement is precise, quantitative, and free of subjective or ambiguous language. All parameters and procedures are clearly defined.\n\n**Step 3: Verdict and Action**\n\nThe problem is valid. It is a well-defined numerical optimization task based on sound principles of computational statistics.\n\n### Solution\n\nThe solution involves three main parts as outlined in the problem: deriving the bounding box for the ratio-of-uniforms method, constructing the cost function $C(r)$, and numerically optimizing $r$ through a grid search.\n\n**1. Bounding Rectangle for Set A**\n\nThe set $A$ is defined by $u  0$ and $u \\le \\sqrt{f(v/u)}$. Let $x = v/u$. The condition is $u \\le \\sqrt{f(x)}$.\n\n- **u-extent:** To find the maximum value of $u$, we must maximize its upper bound, $\\sqrt{f(x)}$. The function $f(x) = \\frac{1}{\\sqrt{2\\pi}}e^{-x^2/2}$ has its maximum at $x=0$, where $f(0) = 1/\\sqrt{2\\pi}$. Therefore, the maximum value of $u$ is:\n$$u_{\\max} = \\sqrt{f(0)} = \\sqrt{\\frac{1}{\\sqrt{2\\pi}}} = (2\\pi)^{-1/4}$$\nThe range for $u$ is $(0, u_{\\max}]$.\n\n- **v-extent:** The variable $v$ is related to $u$ and $x$ by $v=ux$. At the boundary of the set $A$, we have $u = \\sqrt{f(x)}$. Substituting this into the expression for $v$ gives the profile of the boundary in the $(x,v)$ plane:\n$$v(x) = x \\sqrt{f(x)} = x \\left(\\frac{1}{\\sqrt{2\\pi}}e^{-x^2/2}\\right)^{1/2} = x (2\\pi)^{-1/4} e^{-x^2/4}$$\nTo find the extrema of $v$, we differentiate $v(x)$ with respect to $x$ and set the derivative to zero. It is simpler to find the extrema of $g(x) = x e^{-x^2/4}$.\n$$g'(x) = \\frac{d}{dx}\\left(x e^{-x^2/4}\\right) = 1 \\cdot e^{-x^2/4} + x \\cdot \\left(-\\frac{2x}{4}\\right)e^{-x^2/4} = \\left(1 - \\frac{x^2}{2}\\right)e^{-x^2/4}$$\nSetting $g'(x)=0$ gives $1 - x^2/2 = 0$, which implies $x^2=2$, or $x = \\pm\\sqrt{2}$. These are the locations of the extrema.\nThe extreme values are:\n$$v_{\\text{extrema}} = (\\pm\\sqrt{2}) (2\\pi)^{-1/4} e^{-(\\pm\\sqrt{2})^2/4} = \\pm\\sqrt{2} (2\\pi)^{-1/4} e^{-1/2} = \\pm\\sqrt{\\frac{2}{e}}(2\\pi)^{-1/4}$$\nThus, the range for $v$ is $[-v_{\\max}, v_{\\max}]$, where $v_{\\max} = \\sqrt{2/e} \\cdot u_{\\max}$.\nThe minimal bounding rectangle for the set $A$ is $[0, u_{\\max}] \\times [-v_{\\max}, v_{\\max}]$.\n\n**2. Numerical Approximation of Acceptance Rate a(r)**\n\nThe acceptance rate $a(r)$ for the tail region is the ratio of the area of $A_r$ to the area of the bounding rectangle. We approximate this by discretizing the bounding rectangle into a uniform grid of $M_u \\times M_v$ points and counting the fraction of points that fall into $A_r$.\nA grid point $(u_i,v_j)$ is in $A_r$ if it satisfies two conditions:\n1. $u_i \\le \\sqrt{f(v_j/u_i)}$, which is numerically more stable to check as $u_i^2 \\le f(v_j/u_i)$.\n2. $|v_j/u_i|  r$.\n\nLet $N_{\\text{total}} = M_u M_v$ be the total number of grid points and $N_{A_r}$ be the number of grid points satisfying both conditions. The acceptance rate is then approximated as:\n$$a(r) \\approx \\frac{N_{A_r}}{N_{\\text{total}}}$$\n\n**3. Cost Function and Optimization**\n\nThe total expected cost per sample is given by:\n$$C(r) = p_{\\mathrm{center}}(r)\\,c_{\\mathrm{ppf}} \\;+\\; p_{\\mathrm{tail}}(r)\\,\\frac{c_{\\mathrm{prop}}}{a(r)}$$\nThe probabilities are calculated using the standard normal cumulative distribution function (CDF), $\\Phi(\\cdot)$:\n- $p_{\\mathrm{center}}(r) = \\mathbb{P}(|X|\\le r) = \\Phi(r) - \\Phi(-r) = 2\\Phi(r) - 1$.\n- $p_{\\mathrm{tail}}(r) = 1 - p_{\\mathrm{center}}(r) = 2(1 - \\Phi(r))$.\n\nTo find the optimal radius $r^\\star$, we perform a deterministic grid search. We evaluate $C(r)$ for $N_r$ equally spaced values of $r$ in the interval $[0, R]$. The value of $r$ that yields the minimum cost is our optimal radius, $r^\\star$. For computational efficiency, we can first generate the full $(u, v)$ grid, compute the corresponding $x=v/u$ values, and create a boolean mask indicating which points are in the base set $A$. Then, for each $r$ in our search, we can efficiently find $N_{A_r}$ by combining this mask with the tail condition $|x|r$.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef find_optimal_r(c_prop, c_ppf, M_u, M_v, R, N_r):\n    \"\"\"\n    Finds the optimal radius r for the composite sampler by minimizing the cost function.\n\n    Args:\n        c_prop (float): Cost of one ratio-of-uniforms proposal.\n        c_ppf (float): Cost of one inverse-CDF sample from the center.\n        M_u (int): Number of grid points for the u-axis.\n        M_v (int): Number of grid points for the v-axis.\n        R (float): Maximum radius for the r search interval.\n        N_r (int): Number of search points for r.\n\n    Returns:\n        float: The optimal radius r that minimizes the cost.\n    \"\"\"\n    \n    # 1. Define the bounding rectangle for the ratio-of-uniforms set A.\n    # The target PDF is f(x) = 1/sqrt(2*pi) * exp(-x^2/2).\n    # u_max = sqrt(f(0)) = (2*pi)^(-1/4)\n    # v_max = sqrt(2/e) * u_max\n    u_max = (2 * np.pi)**(-0.25)\n    v_max = u_max * np.sqrt(2 / np.e)\n\n    # 2. Create a uniform grid over the bounding rectangle.\n    # Grid points are at the center of each cell to avoid u=0.\n    u_step = u_max / M_u\n    u_vals = np.linspace(u_step / 2.0, u_max - u_step / 2.0, M_u)\n    \n    v_step = 2 * v_max / M_v\n    v_vals = np.linspace(-v_max + v_step / 2.0, v_max - v_step / 2.0, M_v)\n    \n    # Use 'ij' indexing so that u_grid.shape == (M_u, M_v)\n    u_grid, v_grid = np.meshgrid(u_vals, v_vals, indexing='ij')\n\n    # 3. Pre-compute values on the grid that are independent of r.\n    x_grid = v_grid / u_grid\n    \n    # Check the condition u^2 = f(v/u)\n    f_of_x_over_u = (1 / np.sqrt(2 * np.pi)) * np.exp(-x_grid**2 / 2.0)\n    in_A_mask = u_grid**2 = f_of_x_over_u\n    \n    N_total = M_u * M_v\n\n    # 4. Perform grid search for the optimal r.\n    r_vals = np.linspace(0, R, N_r)\n    costs = np.zeros_like(r_vals)\n\n    for i, r in enumerate(r_vals):\n        # Calculate probabilities for center and tail regions.\n        # p_center(r) = P(|X| = r) = Phi(r) - Phi(-r) = 2*Phi(r) - 1\n        p_center = 2 * norm.cdf(r) - 1\n        p_tail = 1 - p_center\n        \n        # Calculate the acceptance rate a(r) for the tail region.\n        # A point is in A_r if it's in A and |x|  r.\n        in_tail_mask = np.abs(x_grid)  r\n        N_Ar = np.sum(in_A_mask  in_tail_mask)\n        a_r = N_Ar / N_total\n        \n        # Calculate the total expected cost C(r).\n        if a_r == 0:\n            # If a_r is 0, the cost is infinite unless p_tail is also 0.\n            if p_tail  1e-15:\n                costs[i] = np.inf\n            else:\n                costs[i] = p_center * c_ppf\n        else:\n            costs[i] = p_center * c_ppf + p_tail * (c_prop / a_r)\n            \n    # Find the r that minimizes the cost.\n    optimal_r_index = np.argmin(costs)\n    optimal_r = r_vals[optimal_r_index]\n    \n    return optimal_r\n\ndef solve():\n    \"\"\"\n    Runs the optimization for all test cases and prints the results.\n    \"\"\"\n    test_cases = [\n        # (c_prop, c_ppf, M_u, M_v, R, N_r)\n        (1.0, 1.0, 600, 1200, 3.5, 701),\n        (1.0, 6.0, 600, 1200, 3.5, 701),\n        (0.2, 3.0, 600, 1200, 3.5, 701),\n        (3.0, 0.5, 600, 1200, 3.5, 701),\n    ]\n\n    results = []\n    for params in test_cases:\n        c_prop, c_ppf, M_u, M_v, R, N_r = params\n        r_star = find_optimal_r(c_prop, c_ppf, M_u, M_v, R, N_r)\n        results.append(r_star)\n        \n    # Format the output as specified: a list of comma-separated values,\n    # rounded to six decimal places.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}