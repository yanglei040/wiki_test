{
    "hands_on_practices": [
        {
            "introduction": "The transition probability matrix, $P$, is the heart of any discrete-time Markov chain, encoding all the rules for movement between states. Before we can analyze a chain's behavior or simulate its path, we must first be able to construct this matrix from a description of the system. This first exercise  provides practice in this fundamental skill, asking you to model a simple two-state system where a memory bit is subject to random flips.",
            "id": "1345199",
            "problem": "A single bit of memory in a satellite's control system is subject to errors caused by cosmic ray interactions. We can model the state of this bit as a stochastic process. The bit can be in one of two states: State 0 (representing the binary value '0') or State 1 (representing the binary value '1').\n\nAt each discrete time step, corresponding to one clock cycle of the onboard computer, the following transitions can occur due to the radiation environment:\n- If the bit is currently in State 0, there is a probability $p_{01}$ that it flips to State 1.\n- If the bit is currently in State 1, there is a probability $p_{10}$ that it flips to State 0.\n\nAssume that these are the only types of state changes possible during a single time step. If a flip does not occur, the bit remains in its current state. Construct the one-step transition probability matrix $P$ for this two-state system. The states in the matrix should be ordered as (State 0, State 1), such that the first row/column corresponds to State 0 and the second row/column corresponds to State 1.",
            "solution": "We model the bit’s state evolution as a discrete-time Markov chain with state space ordered as $(0,1)$. The one-step transition probability matrix $P$ has entries $P_{ij}=\\mathbb{P}(X_{t+1}=j \\mid X_{t}=i)$, so each row must sum to $1$.\n\nFrom the problem:\n- If the current state is $0$, the probability of flipping to $1$ is $p_{01}$, hence the probability of remaining in $0$ is $1-p_{01}$. This gives $P_{00}=1-p_{01}$ and $P_{01}=p_{01}$.\n- If the current state is $1$, the probability of flipping to $0$ is $p_{10}$, hence the probability of remaining in $1$ is $1-p_{10}$. This gives $P_{10}=p_{10}$ and $P_{11}=1-p_{10}$.\n\nTherefore, with rows and columns ordered as $(0,1)$, the transition matrix is\n$$\nP=\\begin{pmatrix}\n1-p_{01} & p_{01} \\\\\np_{10} & 1-p_{10}\n\\end{pmatrix}.\n$$",
            "answer": "$$\\boxed{\\begin{pmatrix}1-p_{01} & p_{01} \\\\ p_{10} & 1-p_{10}\\end{pmatrix}}$$"
        },
        {
            "introduction": "Once the one-step transition matrix $P$ is defined, we can investigate the chain's evolution over multiple steps and its long-term tendencies. The key insight is that the $n$-step transition probabilities are given by the entries of the matrix power $P^n$. This exercise  challenges you to connect the abstract theory of Markov chains with the powerful tools of linear algebra, using diagonalization to find an exact expression for $P^n$ and uncover the chain's convergence to a stationary distribution.",
            "id": "3303948",
            "problem": "Consider a discrete-time Markov chain (DTMC) with finite state space $\\{1,2,3\\}$ and transition matrix $P \\in \\mathbb{R}^{3 \\times 3}$ given by\n$$\nP \\;=\\; \\begin{pmatrix}\n0 & \\frac{1}{2} & \\frac{1}{2} \\\\\n\\frac{1}{2} & 0 & \\frac{1}{2} \\\\\n\\frac{1}{2} & \\frac{1}{2} & 0\n\\end{pmatrix}.\n$$\nAll entries are nonnegative and each row sums to $1$, so $P$ is row-stochastic. By the definition of $n$-step transition probabilities in a DTMC, the $(i,j)$ entry of $P^{n}$ equals the probability of transitioning from state $i$ to state $j$ in $n$ steps. Using only foundational facts—namely, the definition of a DTMC transition matrix, the interpretation of matrix powers $P^{n}$ as $n$-step transition probabilities, and linear-algebraic diagonalization for symmetric matrices—derive a closed-form expression for $P^{n}$ via diagonalization (or Jordan decomposition if needed), and interpret the entries as $n$-step transition probabilities. Your derivation must identify the invariant subspaces associated with the eigenstructure of $P$ and justify how this structure implies the limit behavior of $P^{n}$ as $n \\to \\infty$.\n\nExpress your final answer as the exact symbolic expression for the $(1,3)$ entry of $P^{n}$ as a function of the positive integer $n$. No rounding is required. Do not include units. The final answer must be a single closed-form analytic expression.",
            "solution": "The objective is to find a closed-form expression for the $n$-step transition matrix $P^n$ of the given discrete-time Markov chain. The transition matrix is\n$$\nP = \\begin{pmatrix}\n0 & \\frac{1}{2} & \\frac{1}{2} \\\\\n\\frac{1}{2} & 0 & \\frac{1}{2} \\\\\n\\frac{1}{2} & \\frac{1}{2} & 0\n\\end{pmatrix}.\n$$\nSince $P$ is a real symmetric matrix, it is guaranteed to be diagonalizable by an orthogonal matrix. We will compute $P^n$ using the spectral decomposition of $P$. This involves finding the eigenvalues and corresponding eigenspaces of $P$.\n\nFirst, we find the eigenvalues by solving the characteristic equation $\\det(P - \\lambda I) = 0$, where $I$ is the $3 \\times 3$ identity matrix.\n$$\n\\det \\begin{pmatrix}\n-\\lambda & \\frac{1}{2} & \\frac{1}{2} \\\\\n\\frac{1}{2} & -\\lambda & \\frac{1}{2} \\\\\n\\frac{1}{2} & \\frac{1}{2} & -\\lambda\n\\end{pmatrix} = 0\n$$\n$$\n-\\lambda \\left( \\lambda^2 - \\frac{1}{4} \\right) - \\frac{1}{2} \\left( -\\frac{\\lambda}{2} - \\frac{1}{4} \\right) + \\frac{1}{2} \\left( \\frac{1}{4} + \\frac{\\lambda}{2} \\right) = 0\n$$\n$$\n-\\lambda^3 + \\frac{\\lambda}{4} + \\frac{\\lambda}{4} + \\frac{1}{8} + \\frac{1}{8} + \\frac{\\lambda}{4} = 0\n$$\n$$\n-\\lambda^3 + \\frac{3}{4}\\lambda + \\frac{1}{4} = 0\n$$\nMultiplying by $-4$ gives a monic polynomial:\n$$\n4\\lambda^3 - 3\\lambda - 1 = 0\n$$\nSince $P$ is a stochastic matrix, $\\lambda_1 = 1$ must be an eigenvalue. We verify: $4(1)^3 - 3(1) - 1 = 4 - 3 - 1 = 0$.\nFactoring out $(\\lambda - 1)$, we perform polynomial division, which yields:\n$$\n(\\lambda - 1)(4\\lambda^2 + 4\\lambda + 1) = 0\n$$\nThe quadratic factor is a perfect square: $4\\lambda^2 + 4\\lambda + 1 = (2\\lambda + 1)^2$.\nThus, the characteristic equation is $(\\lambda - 1)(2\\lambda + 1)^2 = 0$.\nThe eigenvalues are $\\lambda_1 = 1$ (with algebraic multiplicity $1$) and $\\lambda_2 = -\\frac{1}{2}$ (with algebraic multiplicity $2$).\n\nNext, we find the eigenspaces for each eigenvalue.\nFor $\\lambda_1 = 1$, we find the null space of $(P - I)$:\n$$\nP - I = \\begin{pmatrix}\n-1 & \\frac{1}{2} & \\frac{1}{2} \\\\\n\\frac{1}{2} & -1 & \\frac{1}{2} \\\\\n\\frac{1}{2} & \\frac{1}{2} & -1\n\\end{pmatrix}\n$$\nRow reduction leads to the system of equations $x_1 = x_2 = x_3$. The eigenspace $E_1$ is spanned by the vector $v_1 = \\begin{pmatrix} 1 & 1 & 1 \\end{pmatrix}^T$. This is the invariant subspace associated with the stationary distribution of the Markov chain.\n\nFor $\\lambda_2 = -\\frac{1}{2}$, we find the null space of $(P + \\frac{1}{2}I)$:\n$$\nP + \\frac{1}{2}I = \\begin{pmatrix}\n\\frac{1}{2} & \\frac{1}{2} & \\frac{1}{2} \\\\\n\\frac{1}{2} & \\frac{1}{2} & \\frac{1}{2} \\\\\n\\frac{1}{2} & \\frac{1}{2} & \\frac{1}{2}\n\\end{pmatrix}\n$$\nThis reduces to the single equation $x_1 + x_2 + x_3 = 0$. This defines a plane through the origin, which is the eigenspace $E_2$. The geometric multiplicity of $\\lambda_2 = -\\frac{1}{2}$ is $2$, matching its algebraic multiplicity. An orthogonal basis for this subspace can be found, for instance, with vectors $v_2 = \\begin{pmatrix} 1 & -1 & 0 \\end{pmatrix}^T$ and $v_3 = \\begin{pmatrix} 1 & 1 & -2 \\end{pmatrix}^T$. This is the transient subspace; any component of an initial distribution in this subspace decays to zero as $n \\to \\infty$.\n\nSince $P$ is diagonalizable, it can be written using its spectral decomposition $P = \\sum_k \\lambda_k \\Pi_k$, where $\\Pi_k$ is the projection matrix onto the eigenspace $E_k$. Then, $P^n$ is given by $P^n = \\sum_k \\lambda_k^n \\Pi_k$.\n$$\nP^n = (1)^n \\Pi_1 + \\left(-\\frac{1}{2}\\right)^n \\Pi_2 = \\Pi_1 + \\left(-\\frac{1}{2}\\right)^n \\Pi_2\n$$\nThe projection matrix $\\Pi_1$ onto the eigenspace $E_1$ (spanned by $v_1$) is given by $\\Pi_1 = \\frac{v_1 v_1^T}{v_1^T v_1}$:\n$$\n\\Pi_1 = \\frac{1}{1^2+1^2+1^2} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} \\begin{pmatrix} 1 & 1 & 1 \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{pmatrix}\n$$\nSince the eigenspaces are orthogonal and span $\\mathbb{R}^3$, we have $\\Pi_1 + \\Pi_2 = I$. Therefore, the projection matrix onto the eigenspace $E_2$ is $\\Pi_2 = I - \\Pi_1$:\n$$\n\\Pi_2 = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} - \\frac{1}{3} \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 2 & -1 & -1 \\\\ -1 & 2 & -1 \\\\ -1 & -1 & 2 \\end{pmatrix}\n$$\nNow we can construct $P^n$:\n$$\nP^n = \\frac{1}{3} \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{pmatrix} + \\left(-\\frac{1}{2}\\right)^n \\frac{1}{3} \\begin{pmatrix} 2 & -1 & -1 \\\\ -1 & 2 & -1 \\\\ -1 & -1 & 2 \\end{pmatrix}\n$$\nCombining these matrices gives the general closed-form expression for $P^n$:\n$$\nP^n = \\frac{1}{3} \\begin{pmatrix}\n1 + 2\\left(-\\frac{1}{2}\\right)^n & 1 - \\left(-\\frac{1}{2}\\right)^n & 1 - \\left(-\\frac{1}{2}\\right)^n \\\\\n1 - \\left(-\\frac{1}{2}\\right)^n & 1 + 2\\left(-\\frac{1}{2}\\right)^n & 1 - \\left(-\\frac{1}{2}\\right)^n \\\\\n1 - \\left(-\\frac{1}{2}\\right)^n & 1 - \\left(-\\frac{1}{2}\\right)^n & 1 + 2\\left(-\\frac{1}{2}\\right)^n\n\\end{pmatrix}\n$$\nAs $n \\to \\infty$, the term $\\left(-\\frac{1}{2}\\right)^n \\to 0$. The limit of the transition matrix is:\n$$\n\\lim_{n \\to \\infty} P^n = \\Pi_1 = \\frac{1}{3} \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{pmatrix}\n$$\nThis demonstrates that the long-term probability of being in any state is $\\frac{1}{3}$, regardless of the starting state. The rows of the limiting matrix correspond to the unique stationary distribution $\\pi = \\begin{pmatrix} \\frac{1}{3} & \\frac{1}{3} & \\frac{1}{3} \\end{pmatrix}$. The existence and uniqueness of this limit for an irreducible, finite-state chain is guaranteed by the Perron-Frobenius theorem, which states that for such a chain, the eigenvalue $1$ has multiplicity $1$ and all other eigenvalues have magnitude strictly less than $1$. Our analysis confirms this, with $|\\lambda_2|=|-\\frac{1}{2}|  1$.\n\nThe problem asks for the specific entry $(P^n)_{1,3}$, the probability of transitioning from state $1$ to state $3$ in $n$ steps. From our derived matrix for $P^n$, this entry is:\n$$\n(P^n)_{1,3} = \\frac{1}{3} \\left(1 - \\left(-\\frac{1}{2}\\right)^n\\right)\n$$\nThis is the required closed-form expression.",
            "answer": "$$\n\\boxed{\\frac{1}{3} \\left(1 - \\left(-\\frac{1}{2}\\right)^{n}\\right)}\n$$"
        },
        {
            "introduction": "A theoretical model of a Markov chain is only the beginning; the real power often comes from our ability to simulate its behavior on a computer. This final practice  brings together theory and application by focusing on the fundamental algorithm for simulating a DTMC's path. You will first prove that any finite DTMC can be realized by a function of its current state and a uniform random number, and then implement this construction, transforming the abstract transition matrix into a concrete simulation engine.",
            "id": "3303994",
            "problem": "Consider a discrete-time Markov chain (DTMC) with a finite state space $S=\\{0,1,\\dots,m-1\\}$ and a transition matrix $P=\\bigl(p_{ij}\\bigr)_{0\\leq i,j\\leq m-1}$, where each row of $P$ is a probability distribution, that is, $p_{ij}\\geq 0$ and $\\sum_{j=0}^{m-1} p_{ij}=1$ for every $i\\in S$. Let $\\{U_n\\}_{n\\geq 0}$ be a sequence of independent and identically distributed (i.i.d.) random variables with $U_n\\sim \\mathrm{Uniform}(0,1)$ and independent of the chain. Prove, from first principles and without assuming any pre-built constructions, that there exists a measurable mapping $F:S\\times[0,1)\\to S$ such that the stochastic recursion $X_{n+1}=F(X_n,U_n)$ realizes the DTMC with transition matrix $P$, meaning that for all $i,j\\in S$,\n$$\\mathbb{P}\\bigl(X_{n+1}=j\\mid X_n=i\\bigr)=p_{ij}.$$\nConstruct $F$ explicitly using cumulative sums of the rows of $P$ and a consistent half-open interval convention on $[0,1)$ that correctly handles boundary values and zero probabilities.\n\nThen, implement the construction algorithmically. Your program must:\n- Accept no input and use only the provided test suite.\n- Represent states as integers in $\\{0,1,\\dots,m-1\\}$.\n- Precompute row-wise cumulative sums of $P$ to define $F$ via the rule that for a given current state $i$ and a value $u\\in[0,1)$, $F(i,u)$ is the smallest $j$ such that $u$ is strictly less than the cumulative sum up to index $j$ in row $i$.\n- Simulate the DTMC for each test case using the given initial state and a deterministic sequence $\\{u_k\\}$ to produce the state sequence $\\{X_1,\\dots,X_T\\}$, where $T$ is the length of the provided $\\{u_k\\}$.\n\nTest suite:\n1. General case, three states:\n   - Transition matrix\n     $$\n     P_1=\\begin{bmatrix}\n     0.3  0.4  0.3 \\\\\n     0.1  0.2  0.7 \\\\\n     0.0  0.5  0.5\n     \\end{bmatrix}.\n     $$\n   - Initial state $X_0=0$.\n   - Uniform sequence $\\{u_k\\}=\\{0.25,\\,0.65,\\,0.05,\\,0.9,\\,0.5\\}$.\n\n2. Boundary handling and deterministic rows, two states:\n   - Transition matrix\n     $$\n     P_2=\\begin{bmatrix}\n     1.0  0.0 \\\\\n     0.0  1.0\n     \\end{bmatrix}.\n     $$\n   - Initial state $X_0=1$.\n   - Uniform sequence $\\{u_k\\}=\\{0.0,\\,0.999999,\\,0.1\\}$.\n\n3. Mixed probabilities, zero entries, and exact boundary values, four states:\n   - Transition matrix\n     $$\n     P_3=\\begin{bmatrix}\n     0.3  0.4  0.0  0.3 \\\\\n     0.0  0.0  1.0  0.0 \\\\\n     0.25  0.25  0.25  0.25 \\\\\n     0.5  0.5  0.0  0.0\n     \\end{bmatrix}.\n     $$\n   - Initial state $X_0=0$.\n   - Uniform sequence $\\{u_k\\}=\\{0.3,\\,0.7,\\,0.25,\\,0.5\\}$.\n\nOutput specification:\n- For each test case, produce the list of simulated states $\\{X_1,\\dots,X_T\\}$ as a list of integers.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each element being the bracketed list for a test case, for example, $\\bigl[[x_{1,1},\\dots,x_{1,T_1}],\\,[x_{2,1},\\dots,x_{2,T_2}],\\,[x_{3,1},\\dots,x_{3,T_3}]\\bigr]$.",
            "solution": "The problem requires a proof from first principles for the existence and construction of a function $F$ that realizes a discrete-time Markov chain (DTMC), followed by an algorithmic implementation to simulate sample paths of the DTMC.\n\n### Part 1: Proof of Existence and Explicit Construction of $F$\n\nLet the finite state space be $S = \\{0, 1, \\dots, m-1\\}$ and the transition matrix be $P = (p_{ij})$, where $p_{ij} = \\mathbb{P}(X_{n+1}=j \\mid X_n=i)$. For each state $i \\in S$, the $i$-th row of $P$, $(p_{i0}, p_{i1}, \\dots, p_{i,m-1})$, is a discrete probability distribution since $p_{ij} \\geq 0$ for all $j \\in S$ and $\\sum_{j=0}^{m-1} p_{ij} = 1$.\n\nWe aim to construct a measurable mapping $F: S \\times [0,1) \\to S$ such that the stochastic process defined by the recursion $X_{n+1} = F(X_n, U_n)$, where $\\{U_n\\}_{n \\geq 0}$ are independent and identically distributed (i.i.d.) random variables with $U_n \\sim \\mathrm{Uniform}(0,1)$, satisfies the Markov property with the given transition probabilities.\n\nThe method used is a form of inverse transform sampling, tailored for a discrete distribution. For each state $i \\in S$, we define a set of cumulative probabilities. Let $c_{i,j}$ be the cumulative sum of probabilities in row $i$ up to state $j$: $c_{i,j} = \\sum_{k=0}^{j} p_{ik}$ for $j \\in \\{0, 1, \\dots, m-1\\}$. For notational convenience, we define $c_{i,-1} = 0$. With this, we have $p_{ij} = c_{i,j} - c_{i,j-1}$ for $j \\in S$. The properties of $P$ ensure that for any fixed $i$, the sequence $(c_{i,0}, c_{i,1}, \\dots, c_{i,m-1})$ is non-decreasing, starts with $c_{i,0} \\geq 0$, and ends with $c_{i,m-1} = 1$.\n\nThese cumulative probabilities partition the interval $[0,1)$ into $m$ subintervals:\n$$ I_{i,j} = [c_{i,j-1}, c_{i,j}) \\quad \\text{for } j \\in \\{0, 1, \\dots, m-1\\}.$$\nThe length of each subinterval $I_{i,j}$, denoted by $\\lambda(I_{i,j})$, is:\n$$ \\lambda(I_{i,j}) = c_{i,j} - c_{i,j-1} = p_{ij}. $$\nThe collection of intervals $\\{I_{i,j}\\}_{j=0}^{m-1}$ forms a partition of $[0,1)$, i.e., they are disjoint and their union is $[0,1)$. If $p_{ij}=0$, the interval $I_{i,j}$ is empty.\n\nNow, we construct the function $F(i,u)$ as prescribed. For a given state $i \\in S$ and a value $u \\in [0,1)$, $F(i,u)$ is defined as the next state $j$. The rule is that $F(i,u) = j$ if and only if $u$ falls into the interval $I_{i,j}$. An equivalent and explicit definition, as given in the problem, is:\n$$ F(i, u) = \\min \\{j \\in S \\mid u  c_{i,j}\\} $$\nThis definition is well-formed because $u \\in [0,1)$ and $c_{i,m-1}=1$, so the set $\\{j \\in S \\mid u  c_{i,j}\\}$ is never empty (it always contains $m-1$).\n\nWe must now prove from first principles that this construction correctly models the DTMC. We need to show that $\\mathbb{P}(X_{n+1} = j \\mid X_n = i) = p_{ij}$.\nFrom the recursive definition $X_{n+1} = F(X_n, U_n)$, we have:\n$$ \\mathbb{P}(X_{n+1} = j \\mid X_n = i) = \\mathbb{P}(F(X_n, U_n) = j \\mid X_n = i). $$\nConditioning on the event $X_n=i$, the expression becomes:\n$$ \\mathbb{P}(F(i, U_n) = j \\mid X_n = i). $$\nSince the sequence $\\{U_n\\}$ is independent of the chain $\\{X_n\\}$, the event $X_n=i$ provides no information about the value of $U_n$. Thus, we can remove the conditioning on $X_n=i$:\n$$ \\mathbb{P}(X_{n+1} = j \\mid X_n = i) = \\mathbb{P}(F(i, U_n) = j). $$\nBy our construction of $F$, the event $F(i, U_n) = j$ is equivalent to the event that $U_n$ falls into the specific interval $I_{i,j}$:\n$$ F(i, U_n) = j \\iff c_{i,j-1} \\le U_n  c_{i,j}. $$\nTherefore, the probability is:\n$$ \\mathbb{P}(X_{n+1} = j \\mid X_n = i) = \\mathbb{P}(c_{i,j-1} \\le U_n  c_{i,j}). $$\nSince $U_n$ follows a Uniform$(0,1)$ distribution, the probability of it lying in any subinterval $[a,b) \\subseteq [0,1)$ is equal to the length of the interval, $b-a$. In our case, the length of the interval $[c_{i,j-1}, c_{i,j})$ is $\\lambda(I_{i,j}) = c_{i,j} - c_{i,j-1} = p_{ij}$.\n$$ \\mathbb{P}(X_{n+1} = j \\mid X_n = i) = p_{ij}. $$\nThis confirms that the stochastic recursion $X_{n+1}=F(X_n, U_n)$ with our constructed $F$ correctly realizes the DTMC with transition matrix $P$.\n\nFinally, the function $F$ is a measurable mapping. For any $j \\in S$, its preimage $F^{-1}(\\{j\\})$ is the set $\\bigcup_{i \\in S} (\\{i\\} \\times I_{i,j})$. Each set $\\{i\\}$ is measurable in the discrete $\\sigma$-algebra on $S$, and each interval $I_{i,j}$ is a Borel set and thus measurable in $[0,1)$. The product $\\{i\\} \\times I_{i,j}$ is a measurable rectangle in the product space $S \\times [0,1)$, and a finite union of such sets is measurable. Thus, $F$ is a measurable function.\n\n### Part 2: Algorithmic Design\n\nThe constructive proof directly informs the simulation algorithm.\n1.  **Preprocessing**: For a given transition matrix $P$ of size $m \\times m$, we first compute the matrix of cumulative sums $C$. The element $C_{i,j}$ is the cumulative sum of the $i$-th row of $P$ up to column $j$, i.e., $C_{i,j} = \\sum_{k=0}^{j} P_{ik}$. This can be efficiently computed for all rows simultaneously.\n2.  **State Transition Function**: The core of the simulation is the implementation of $F(i,u)$. Given the current state $i$ and a uniformly sampled value $u \\in [0,1)$, the next state $j$ is found by applying the rule $j = \\min \\{k \\in S \\mid u  C_{i,k}\\}$. Algorithmically, this means we search for the first index $k$ in the $i$-th row of $C$ for which the value $C_{i,k}$ is strictly greater than $u$.\n3.  **Simulation Loop**:\n    -   Initialize the current state, $X_{current} \\leftarrow X_0$.\n    -   Initialize an empty list `results` to store the generated state sequence.\n    -   For each provided value $u_k$ from the deterministic sequence $\\{u_k\\}$:\n        a.  Identify the row of cumulative probabilities corresponding to the current state: `cum_probs = C[X_current, :]`.\n        b.  Find the next state $X_{next}$ by finding the smallest index $j$ such that $u_k  C_{X_{current}, j}$. This can be implemented efficiently, for example, by finding the index of the first `True` value in the boolean array resulting from the comparison $u_k  C_{X_{current}}$.\n        c.  Append $X_{next}$ to the `results` list.\n        d.  Update the current state: $X_{current} \\leftarrow X_{next}$.\n4.  **Output Formatting**: The generated sequences for all test cases are collected and formatted into the specified single-line string format.\n\nThis design is a direct translation of the proven method, ensuring correctness, and leverages efficient array operations for the search step.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the DTMC simulation problem for a given set of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"P\": np.array([\n                [0.3, 0.4, 0.3],\n                [0.1, 0.2, 0.7],\n                [0.0, 0.5, 0.5]\n            ]),\n            \"X0\": 0,\n            \"u_seq\": [0.25, 0.65, 0.05, 0.9, 0.5]\n        },\n        {\n            \"P\": np.array([\n                [1.0, 0.0],\n                [0.0, 1.0]\n            ]),\n            \"X0\": 1,\n            \"u_seq\": [0.0, 0.999999, 0.1]\n        },\n        {\n            \"P\": np.array([\n                [0.3, 0.4, 0.0, 0.3],\n                [0.0, 0.0, 1.0, 0.0],\n                [0.25, 0.25, 0.25, 0.25],\n                [0.5, 0.5, 0.0, 0.0]\n            ]),\n            \"X0\": 0,\n            \"u_seq\": [0.3, 0.7, 0.25, 0.5]\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        P = case[\"P\"]\n        current_state = case[\"X0\"]\n        u_seq = case[\"u_seq\"]\n        \n        # Precompute row-wise cumulative sums of the transition matrix P.\n        # This creates the matrix C where C[i,j] = sum_{k=0 to j} P[i,k].\n        C = np.cumsum(P, axis=1)\n        \n        state_sequence = []\n        for u in u_seq:\n            # Get the cumulative probabilities for the current state.\n            cum_probs_row = C[current_state, :]\n            \n            # Find the next state. The rule is to find the smallest index j such that\n            # u is strictly less than the cumulative sum up to j.\n            # np.argmax(u  cum_probs_row) finds the index of the first True\n            # value, which corresponds to the smallest j satisfying the condition.\n            next_state = np.argmax(u  cum_probs_row)\n            \n            state_sequence.append(next_state)\n            current_state = next_state\n            \n        all_results.append(state_sequence)\n\n    # Format the final output string to be exactly as specified, without spaces.\n    # E.g., [[0,1,0,2,2],[1,1,1],[1,2,1,2]]\n    result_str_parts = []\n    for res_list in all_results:\n        # Format each inner list like '[0,1,2]'\n        part = '[' + ','.join(map(str, res_list)) + ']'\n        result_str_parts.append(part)\n    \n    # Join the parts and wrap in outer brackets\n    final_output_str = '[' + ','.join(result_str_parts) + ']'\n    \n    # Final print statement in the exact required format.\n    print(final_output_str)\n\nsolve()\n```"
        }
    ]
}