{
    "hands_on_practices": [
        {
            "introduction": "一个优秀的重要性采样方案的核心在于选择一个好的提议分布。本练习将引导你通过一个具体的性能指标——有效样本量（$ESS$）——来量化提议分布的“好坏”。你将通过最大化有效样本量的近似期望，从第一性原理出发，为一个常见且重要的高斯分布场景推导出最优的提议分布参数。这个过程不仅能加深你对重要性采样方差缩减目标的理解，也为你优化更复杂的模型提供了基本思路。",
            "id": "3312707",
            "problem": "考虑一个在 $\\,\\mathbb{R}^{d}\\,$ 上的目标概率密度 $\\,\\pi(x)\\,$，它由一个均值为 $\\,\\mu \\in \\mathbb{R}^{d}\\,$ 且协方差矩阵为正定矩阵 $\\,\\Sigma \\in \\mathbb{R}^{d \\times d}\\,$ 的多元正态分布给出，即 $\\,\\pi(x) = \\mathcal{N}(x;\\mu,\\Sigma)\\,$。对于重要性采样（IS），从一个提议分布族 $\\,q_{\\theta}(x)\\,$ 中抽取 $\\,n\\,$ 个独立样本 $\\,X_{1},\\dots,X_{n}\\,$，该提议分布族也是一个多元正态分布，具有相同的协方差矩阵但带有一个可调的均值参数 $\\,\\theta \\in \\mathbb{R}^{d}\\,$，即 $\\,q_{\\theta}(x) = \\mathcal{N}(x;\\theta,\\Sigma)\\,$。定义重要性采样权重 $\\,w(x) = \\pi(x)/q_{\\theta}(x)\\,$ 以及这 $\\,n\\,$ 个样本的有效样本量（ESS）为\n$$\n\\mathrm{ESS} \\;=\\; \\frac{\\left(\\sum_{i=1}^{n} w(X_{i})\\right)^{2}}{\\sum_{i=1}^{n} w(X_{i})^{2}}.\n$$\n从第一性原理出发——即重要性采样的定义、多元正态分布的性质以及大数定律——推导出一个 $\\,\\mathbb{E}[\\mathrm{ESS}]\\,$ 的解析上易于处理的近似，该近似仅依赖于 $\\,w(X)\\,$ 在 $\\,q_{\\theta}\\,$ 分布下的一阶矩和二阶矩。然后，对于给定的 $\\,\\pi\\,$ 和 $\\,q_{\\theta}\\,$，关于 $\\,\\theta\\,$ 最大化这个易于处理的近似。提供一个该最优化问题的解 $\\,\\theta^{\\star}\\,$ 的单一闭式解析表达式。不需要进行数值评估，也不需要四舍五入。最终答案以无单位形式表示。",
            "solution": "该问题要求我们首先推导有效样本量期望 $\\mathbb{E}[\\mathrm{ESS}]$ 的一个易于处理的近似，然后关于提议参数 $\\theta$ 最大化这个近似。\n\n首先，我们来推导 $\\mathbb{E}[\\mathrm{ESS}]$ 的近似。给定的 ESS 表达式是随机变量总和的比率：\n$$\n\\mathrm{ESS} = \\frac{\\left(\\sum_{i=1}^{n} w(X_{i})\\right)^{2}}{\\sum_{i=1}^{n} w(X_{i})^{2}}\n$$\n其中 $X_i \\sim q_{\\theta}(x)$ 是独立同分布样本。\n我们可以通过将分子和分母分别除以 $n^2$ 和 $n$ 来重写此表达式：\n$$\n\\mathrm{ESS} = n \\frac{\\left(\\frac{1}{n}\\sum_{i=1}^{n} w(X_{i})\\right)^{2}}{\\frac{1}{n}\\sum_{i=1}^{n} w(X_{i})^{2}}\n$$\n根据大数定律，对于大样本量 $n$，样本均值依概率收敛于它们各自的期望：\n$$\n\\frac{1}{n}\\sum_{i=1}^{n} w(X_{i}) \\xrightarrow{p} \\mathbb{E}_{q_{\\theta}}[w(X)]\n$$\n$$\n\\frac{1}{n}\\sum_{i=1}^{n} w(X_{i})^{2} \\xrightarrow{p} \\mathbb{E}_{q_{\\theta}}[w(X)^2]\n$$\n其中期望是关于提议分布 $q_{\\theta}$ 计算的。利用这个收敛性，我们可以构建一个 $\\mathrm{ESS}$ 的近似，当 $n \\to \\infty$ 时，这个近似越来越精确。比率的期望近似为期望的比率。因此，$\\mathbb{E}[\\mathrm{ESS}]$ 的易于处理的近似由下式给出：\n$$\n\\mathbb{E}[\\mathrm{ESS}] \\approx n \\frac{\\left(\\mathbb{E}_{q_{\\theta}}[w(X)]\\right)^{2}}{\\mathbb{E}_{q_{\\theta}}[w(X)^2]}\n$$\n如题目所要求，该表达式仅依赖于权重 $w(X)$ 在 $q_{\\theta}$ 分布下的一阶矩和二阶矩。\n\n接下来，我们必须为指定的分布计算这两个矩。\n一阶矩是重要性采样的一个基本性质：\n$$\n\\mathbb{E}_{q_{\\theta}}[w(X)] = \\int w(x) q_{\\theta}(x) \\, dx = \\int \\frac{\\pi(x)}{q_{\\theta}(x)} q_{\\theta}(x) \\, dx = \\int \\pi(x) \\, dx = 1\n$$\n因为 $\\pi(x)$ 是一个概率密度函数。\n\n现在，我们计算二阶矩 $\\mathbb{E}_{q_{\\theta}}[w(X)^2]$。权重函数是两个多元正态密度的比值：\n$$\nw(x) = \\frac{\\mathcal{N}(x;\\mu,\\Sigma)}{\\mathcal{N}(x;\\theta,\\Sigma)} = \\frac{\\frac{1}{(2\\pi)^{d/2}|\\Sigma|^{1/2}}\\exp\\left(-\\frac{1}{2}(x-\\mu)^T \\Sigma^{-1} (x-\\mu)\\right)}{\\frac{1}{(2\\pi)^{d/2}|\\Sigma|^{1/2}}\\exp\\left(-\\frac{1}{2}(x-\\theta)^T \\Sigma^{-1} (x-\\theta)\\right)}\n$$\n$$\nw(x) = \\exp\\left(-\\frac{1}{2}\\left[(x-\\mu)^T \\Sigma^{-1} (x-\\mu) - (x-\\theta)^T \\Sigma^{-1} (x-\\theta)\\right]\\right)\n$$\n我们来简化指数中的项：\n$$\n(x-\\mu)^T \\Sigma^{-1} (x-\\mu) - (x-\\theta)^T \\Sigma^{-1} (x-\\theta) = (x^T\\Sigma^{-1}x - 2x^T\\Sigma^{-1}\\mu + \\mu^T\\Sigma^{-1}\\mu) - (x^T\\Sigma^{-1}x - 2x^T\\Sigma^{-1}\\theta + \\theta^T\\Sigma^{-1}\\theta)\n$$\n$$\n= 2x^T\\Sigma^{-1}(\\theta-\\mu) + \\mu^T\\Sigma^{-1}\\mu - \\theta^T\\Sigma^{-1}\\theta\n$$\n所以，权重函数 $w(x)$ 的指数部分为：\n$$\n-\\frac{1}{2} [2x^T\\Sigma^{-1}(\\theta-\\mu) + \\mu^T\\Sigma^{-1}\\mu - \\theta^T\\Sigma^{-1}\\theta] = x^T\\Sigma^{-1}(\\mu-\\theta) + \\frac{1}{2}(\\theta^T\\Sigma^{-1}\\theta - \\mu^T\\Sigma^{-1}\\mu)\n$$\n因此，$w(x) = \\exp\\left(x^T\\Sigma^{-1}(\\mu-\\theta) + \\frac{1}{2}(\\theta^T\\Sigma^{-1}\\theta - \\mu^T\\Sigma^{-1}\\mu)\\right)\\)。\n所以，$w(x)^2$ 是：\n$$\nw(x)^2 = \\exp\\left(2x^T\\Sigma^{-1}(\\mu-\\theta) + (\\theta^T\\Sigma^{-1}\\theta - \\mu^T\\Sigma^{-1}\\mu)\\right)\n$$\n二阶矩是在 $q_{\\theta}(x) = \\mathcal{N}(x;\\theta,\\Sigma)$ 下这个量的期望：\n$$\n\\mathbb{E}_{q_{\\theta}}[w(X)^2] = \\int w(x)^2 q_{\\theta}(x) \\, dx\n$$\n$$\n= \\int \\exp\\left(2x^T\\Sigma^{-1}(\\mu-\\theta) + \\theta^T\\Sigma^{-1}\\theta - \\mu^T\\Sigma^{-1}\\mu\\right) \\frac{1}{(2\\pi)^{d/2}|\\Sigma|^{1/2}}\\exp\\left(-\\frac{1}{2}(x-\\theta)^T \\Sigma^{-1} (x-\\theta)\\right) dx\n$$\n我们可以将该积分识别为多元正态分布矩母函数（MGF）的求值。对于一个服从 $\\mathcal{N}(\\theta, \\Sigma)$ 分布的随机向量 $X$，其 MGF 为 $\\mathbb{E}[e^{t^TX}] = \\exp(t^T\\theta + \\frac{1}{2}t^T\\Sigma t)$。\n在我们的例子中，$t = 2\\Sigma^{-1}(\\mu-\\theta)$。积分中的期望部分为：\n$$\n\\mathbb{E}_{q_{\\theta}}[\\exp(2x^T\\Sigma^{-1}(\\mu-\\theta))] = \\exp\\left((2\\Sigma^{-1}(\\mu-\\theta))^T\\theta + \\frac{1}{2}(2\\Sigma^{-1}(\\mu-\\theta))^T\\Sigma(2\\Sigma^{-1}(\\mu-\\theta))\\right)\n$$\n$$\n= \\exp\\left(2(\\mu-\\theta)^T\\Sigma^{-1}\\theta + 2(\\mu-\\theta)^T\\Sigma^{-1}(\\mu-\\theta)\\right)\n$$\n将此结果与常数项 $\\exp(\\theta^T\\Sigma^{-1}\\theta - \\mu^T\\Sigma^{-1}\\mu)$ 相乘，总指数为：\n$$\n(\\theta^T\\Sigma^{-1}\\theta - \\mu^T\\Sigma^{-1}\\mu) + (2\\mu^T\\Sigma^{-1}\\theta - 2\\theta^T\\Sigma^{-1}\\theta) + (2\\mu^T\\Sigma^{-1}\\mu - 4\\mu^T\\Sigma^{-1}\\theta + 2\\theta^T\\Sigma^{-1}\\theta)\n$$\n$$\n= (\\theta^T\\Sigma^{-1}\\theta - 2\\theta^T\\Sigma^{-1}\\theta + 2\\theta^T\\Sigma^{-1}\\theta) + (-\\mu^T\\Sigma^{-1}\\mu + 2\\mu^T\\Sigma^{-1}\\mu) + (2\\mu^T\\Sigma^{-1}\\theta - 4\\mu^T\\Sigma^{-1}\\theta)\n$$\n$$\n= \\theta^T\\Sigma^{-1}\\theta + \\mu^T\\Sigma^{-1}\\mu - 2\\mu^T\\Sigma^{-1}\\theta = (\\theta-\\mu)^T\\Sigma^{-1}(\\theta-\\mu)\n$$\n因此，二阶矩是：\n$$\n\\mathbb{E}_{q_{\\theta}}[w(X)^2] = \\exp\\left((\\theta-\\mu)^T\\Sigma^{-1}(\\theta-\\mu)\\right)\n$$\n现在，将这些矩代回到 $\\mathbb{E}[\\mathrm{ESS}]$ 的近似式中：\n$$\n\\mathbb{E}[\\mathrm{ESS}] \\approx n \\frac{1^2}{\\exp\\left((\\theta-\\mu)^T\\Sigma^{-1}(\\theta-\\mu)\\right)} = n \\exp\\left(-(\\theta-\\mu)^T\\Sigma^{-1}(\\theta-\\mu)\\right)\n$$\n我们最后的任务是关于 $\\theta$ 最大化这个表达式。设目标函数为 $J(\\theta)$：\n$$\nJ(\\theta) = n \\exp\\left(-(\\theta-\\mu)^T\\Sigma^{-1}(\\theta-\\mu)\\right)\n$$\n因为 $n$ 是一个正常数，并且指数函数 $\\exp(z)$ 是严格单调递增的，所以最大化 $J(\\theta)$ 等价于最大化其参数，这又等价于最小化二次型：\n$$\nQ(\\theta) = (\\theta-\\mu)^T\\Sigma^{-1}(\\theta-\\mu)\n$$\n项 $Q(\\theta)$ 是向量 $\\theta$ 和 $\\mu$ 之间马氏距离的平方。矩阵 $\\Sigma$ 是给定的正定协方差矩阵，这意味着其逆矩阵 $\\Sigma^{-1}$ 也是正定的。\n对于任何正定矩阵 $A$ 和任何非零向量 $v$，二次型 $v^T A v$ 是严格为正的。该二次型的最小值为 $0$，当且仅当 $v = 0$ 时取得。\n在我们的情况下，令 $v = \\theta - \\mu$。$Q(\\theta)$ 的最小值为 $0$，这当且仅当以下条件成立时发生：\n$$\n\\theta - \\mu = 0\n$$\n这意味着参数 $\\theta$ 的最优选择是：\n$$\n\\theta^{\\star} = \\mu\n$$\n这个结果在直观上是正确的。有效样本量是采样效率的一种度量。当提议分布 $q_{\\theta}(x)$ 与目标分布 $\\pi(x)$ 完全相同时，效率达到最大化。在这个问题中，两个分布都属于同一分布族 $\\mathcal{N}(\\cdot, \\Sigma)$，因此要使它们相同，就需要将其均值设置为相等，即 $\\theta = \\mu$。在这种情况下，对所有 $x$ 都有 $w(x) = 1$，真实的 ESS 恰好为 $n$，这是其可能的最大值。我们的近似也得出了这个最大值：$J(\\mu) = n \\exp(0) = n$。",
            "answer": "$$ \\boxed{\\mu} $$"
        },
        {
            "introduction": "在掌握了优化提议分布的基本原则之后 ()，是时候将其应用于一个实际且重要的领域：稀有事件模拟。这个练习将引导你为一个稀有事件概率估计问题设计并实现一个高效的重要性采样估计器。你将运用指数倾斜技术推导出最优的提议分布，并通过编写代码将其付诸实践，直观地感受重要性采样相比于朴素蒙特卡洛方法在方差缩减上的巨大优势。",
            "id": "3312679",
            "problem": "考虑独立同分布的随机变量 $X_1, X_2, \\dots, X_n$，每个变量都服从标准正态分布。定义稀有事件概率\n$$\np(n,a) \\equiv \\mathbb{P}\\left\\{\\frac{1}{n}\\sum_{i=1}^n X_i \\ge a\\right\\} = \\mathbb{P}\\left\\{\\sum_{i=1}^n X_i \\ge n a\\right\\}.\n$$\n从期望、概率以及通过 Radon–Nikodým 导数实现的测度变换原理等基本定义出发，推导并实现一个使用重要性抽样 (IS) 的 $p(n,a)$ 估计量。设计必须仅遵循以下经过充分检验的事实：\n- 标准正态随机变量的矩生成函数对任意实数参数 $t$ 都存在，并且其累积量生成函数 $\\psi(t)$ 对所有实数 $t$ 都是有限的。\n- 独立正态随机变量之和仍为正态分布，其均值和方差分别为各独立变量均值和方差之和。\n- 蒙特卡洛方法通过独立样本的经验平均来估计期望。\n\n您必须：\n- 为 $p(n,a)$ 构建一个直接蒙特卡洛估计量（有时称为“粗糙”估计量）。\n- 通过指数倾斜测度变换为 $p(n,a)$ 构建一个重要性抽样估计量，使得稀有事件在抽样分布下变为典型事件。您的推导必须从 Radon–Nikodým 导数定义和累积量生成函数出发，并必须基于累积量生成函数的凸性，使用第一性原理最优性论证来证明倾斜参数选择的合理性。\n- 通过直接对和 $\\sum_{i=1}^n X_i$ 进行抽样，而不是对 $n$ 维向量进行抽样，来高效地实现这两种估计量。明确使用以下事实：如果 $Y_i$ 是均值为 $\\mu$、方差为 $1$ 的独立正态随机变量，那么 $\\sum_{i=1}^n Y_i$ 服从均值为 $n\\mu$、方差为 $n$ 的正态分布。\n\n不涉及物理单位。如果您的推理中出现任何角度，必须以弧度为单位，但此处不需要。最终输出为浮点数。\n\n测试套件：\n- 案例 1：$n=100$， $a=0.5$， 蒙特卡洛样本量 $M=200000$， 随机种子 $s=12345$。\n- 案例 2：$n=100$， $a=0.0$， 蒙特卡洛样本量 $M=100000$， 随机种子 $s=54321$。\n- 案例 3：$n=50$， $a=0.3$， 蒙特卡洛样本量 $M=50000$， 随机种子 $s=2025$。\n- 案例 4：$n=200$， $a=1.0$， 蒙特卡洛样本量 $M=300000$， 随机种子 $s=777$。\n\n要求的最终输出格式：\n您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表。对于每个测试案例，按顺序首先输出粗糙蒙特卡洛估计值，然后输出重要性抽样估计值。也就是说，该单行输出必须如下所示：\n$$\n[\\widehat{p}_{\\text{crude},1},\\widehat{p}_{\\text{IS},1},\\widehat{p}_{\\text{crude},2},\\widehat{p}_{\\text{IS},2},\\widehat{p}_{\\text{crude},3},\\widehat{p}_{\\text{IS},3},\\widehat{p}_{\\text{crude},4},\\widehat{p}_{\\text{IS},4}],\n$$\n其中每个 $\\widehat{p}$ 都是一个浮点数。",
            "solution": "该问题已经过验证，被确定为计算统计学和蒙特卡洛方法领域中一个有效且适定的问题。它具有科学依据、自成体系且客观。因此，我们可以进行完整的推导和求解。\n\n需要估计的量是稀有事件概率\n$$\np(n,a) = \\mathbb{P}\\left\\{\\frac{1}{n}\\sum_{i=1}^n X_i \\ge a\\right\\}\n$$\n其中 $X_1, X_2, \\dots, X_n$ 是独立同分布 (i.i.d.) 的标准正态随机变量，即 $X_i \\sim \\mathcal{N}(0, 1)$。令 $S_n = \\sum_{i=1}^n X_i$。根据正态分布的性质，独立正态随机变量之和也服从正态分布。和的均值是均值之和，$\\mathbb{E}[S_n] = \\sum_{i=1}^n \\mathbb{E}[X_i] = \\sum_{i=1}^n 0 = 0$。和的方差是方差之和，$\\text{Var}(S_n) = \\sum_{i=1}^n \\text{Var}(X_i) = \\sum_{i=1}^n 1 = n$。因此，$S_n \\sim \\mathcal{N}(0, n)$。\n\n该概率可以用 $S_n$ 重写为 $p(n,a) = \\mathbb{P}\\{S_n \\ge na\\}$。这个概率可以表示为一个指示函数的期望，这构成了蒙特卡洛估计的基础：\n$$\np(n,a) = \\mathbb{E}\\left[\\mathbb{I}\\{S_n \\ge na\\}\\right]\n$$\n其中 $\\mathbb{I}\\{\\cdot\\}$ 是指示函数，当条件为真时等于 $1$，否则等于 $0$。期望是关于 $S_n$ 的概率分布计算的，其概率密度函数 (PDF) 为 $f_{S_n}(s) = \\frac{1}{\\sqrt{2\\pi n}} \\exp\\left(-\\frac{s^2}{2n}\\right)$。\n\n**粗糙蒙特卡洛估计量**\n\n粗糙蒙特卡洛方法直接应用大数定律来估计期望。我们从 $S_n$ 的分布 $\\mathcal{N}(0, n)$ 中生成 $M$ 个独立样本，记为 $S_n^{(1)}, S_n^{(2)}, \\dots, S_n^{(M)}$。$p(n,a)$ 的估计量就是这些样本上指示函数的样本均值：\n$$\n\\widehat{p}_{\\text{crude}}(n,a) = \\frac{1}{M}\\sum_{j=1}^M \\mathbb{I}\\left\\{S_n^{(j)} \\ge na\\right\\}\n$$\n该估计量是无偏的，即 $\\mathbb{E}[\\widehat{p}_{\\text{crude}}(n,a)] = p(n,a)$。然而，如果事件 $\\{S_n \\ge na\\}$ 是稀有事件，大多数样本 $S_n^{(j)}$ 将导致 $\\mathbb{I}\\{S_n^{(j)} \\ge na\\} = 0$，从而导致高方差和低效的估计。\n\n**重要性抽样 (IS) 估计量**\n\n重要性抽样的核心思想是改变概率测度，使得稀有事件在新的测度下更频繁地发生。我们引入一个新的带概率密度函数 $g(s)$ 的抽样分布，并重写期望：\n$$\np(n,a) = \\int_{-\\infty}^\\infty \\mathbb{I}\\{s \\ge na\\} f_{S_n}(s) ds = \\int_{-\\infty}^\\infty \\mathbb{I}\\{s \\ge na\\} \\frac{f_{S_n}(s)}{g(s)} g(s) ds = \\mathbb{E}_g\\left[\\mathbb{I}\\{Y \\ge na\\} L(Y)\\right]\n$$\n这里，$Y$ 是一个概率密度函数为 $g(s)$ 的随机变量，$L(s) = \\frac{f_{S_n}(s)}{g(s)}$ 是似然比，也就是原始测度关于新测度的 Radon–Nikodým 导数。\n\nIS 估计量通过从新分布 $g(s)$ 中抽取 $M$ 个样本 $Y^{(1)}, \\dots, Y^{(M)}$ 并计算样本均值来构成：\n$$\n\\widehat{p}_{\\text{IS}}(n,a) = \\frac{1}{M}\\sum_{j=1}^M \\mathbb{I}\\left\\{Y^{(j)} \\ge na\\right\\} L(Y^{(j)})\n$$\n对于任何其支撑集覆盖被积函数非零积分域的 $g(s)$，该估计量也是无偏的。\n\n**指数倾斜与最优参数选择**\n\n为新分布 $g(s)$ 选择原始分布 $f_{S_n}(s)$ 的指数倾斜形式是一个强有力的选择。它由一个倾斜参数 $\\theta$ 定义：\n$$\ng_\\theta(s) = f_{S_n}(s) e^{\\theta s - \\Psi_{S_n}(\\theta)}\n$$\n其中 $\\Psi_{S_n}(\\theta) = \\ln \\mathbb{E}[e^{\\theta S_n}]$ 是 $S_n$ 的累积量生成函数 (CGF)。$e^{-\\Psi_{S_n}(\\theta)}$ 项是归一化常数。由于 $X_i$ 是独立同分布的，$\\Psi_{S_n}(\\theta) = n \\psi(\\theta)$，其中 $\\psi(\\theta)$ 是单个 $X_i \\sim \\mathcal{N}(0, 1)$ 的 CGF。对于一个标准正态变量，其矩生成函数为 $M_X(t) = e^{t^2/2}$，因此其 CGF 为 $\\psi(t) = \\ln(M_X(t)) = t^2/2$。因此，$S_n$ 的 CGF 为 $\\Psi_{S_n}(\\theta) = n\\theta^2/2$。\n\n将 PDF 和 CGF 代入 $g_\\theta(s)$ 的定义中：\n$$\ng_\\theta(s) = \\left[\\frac{1}{\\sqrt{2\\pi n}} e^{-s^2/(2n)}\\right] e^{\\theta s - n\\theta^2/2} = \\frac{1}{\\sqrt{2\\pi n}} \\exp\\left(-\\frac{s^2 - 2n\\theta s + n^2\\theta^2}{2n}\\right) = \\frac{1}{\\sqrt{2\\pi n}} \\exp\\left(-\\frac{(s - n\\theta)^2}{2n}\\right)\n$$\n这是均值为 $n\\theta$、方差为 $n$ 的正态分布的 PDF，即 $Y \\sim \\mathcal{N}(n\\theta, n)$。似然比为 $L(s) = \\frac{f_{S_n}(s)}{g_\\theta(s)} = e^{-\\theta s + \\Psi_{S_n}(\\theta)} = e^{-\\theta s + n\\theta^2/2}$。\n\n$\\theta$ 的最优选择是使 IS 估计量方差最小化的那个。估计量的方差由随机变量 $Z = \\mathbb{I}\\{Y \\ge na\\}L(Y)$ 的二阶矩决定。一个有效的启发式方法（在大偏差理论的背景下是渐近最优的）是选择 $\\theta$ 使得新分布的均值位于事件“最重要”的区域。对于单边事件 $\\{S_n \\ge na\\}$，这对应于将新分布的中心置于事件区域的边界上。\n\n我们将抽样分布的均值设为阈值 $na$：\n$$\n\\mathbb{E}_\\theta[Y] = na\n$$\n指数族的一个基本性质是，倾斜分布的均值是 CGF 的导数：$\\mathbb{E}_\\theta[Y] = \\Psi'_{S_n}(\\theta)$。因此，我们求解方程中的 $\\theta$：\n$$\n\\Psi'_{S_n}(\\theta) = na\n$$\n已知 $\\Psi_{S_n}(\\theta) = n\\theta^2/2$，其导数为 $\\Psi'_{S_n}(\\theta) = n\\theta$。方程变为：\n$$\nn\\theta = na \\implies \\theta = a\n$$\nCGF $\\Psi_{S_n}(\\theta)$ 是严格凸的，因为它的二阶导数 $\\Psi''_{S_n}(\\theta) = n  0$。这种严格凸性保证了方程 $\\Psi'_{S_n}(\\theta) = na$ 对 $\\theta$ 有唯一解。\n\n使用最优参数 $\\theta = a$，我们的 IS 流程如下：\n1.  从分布 $\\mathcal{N}(na, n)$ 中抽取样本 $Y^{(j)}$。\n2.  为每个样本计算似然比：$L(Y^{(j)}) = \\exp\\left(-a Y^{(j)} + na^2/2\\right)$。\n3.  计算估计值：\n    $$\n    \\widehat{p}_{\\text{IS}}(n,a) = \\frac{1}{M}\\sum_{j=1}^M \\mathbb{I}\\left\\{Y^{(j)} \\ge na\\right\\} e^{-a Y^{(j)} + na^2/2}\n    $$\n通过将抽样分布的中心置于事件边界，我们确保了有相当一部分样本（约 50%）会落入事件区域 $\\{Y \\ge na\\}$，与粗糙方法相比，这极大地降低了估计量的方差，尤其是在 $p(n,a)$ 非常小的情况下。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and implements crude Monte Carlo and Importance Sampling estimators\n    for a rare-event probability involving a sum of standard normal variables.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, a, M, random_seed)\n        (100, 0.5, 200000, 12345),\n        (100, 0.0, 100000, 54321),\n        (50, 0.3, 50000, 2025),\n        (200, 1.0, 300000, 777),\n    ]\n\n    results = []\n    for n, a, M, s in test_cases:\n        # Initialize a random number generator with the specified seed for reproducibility.\n        rng = np.random.default_rng(s)\n\n        # The target event is sum(X_i) = n*a.\n        threshold = n * a\n\n        # The sum S_n = sum(X_i) is distributed as Normal(0, n).\n        mean_original = 0.0\n        # The standard deviation is sqrt(n).\n        std_dev = np.sqrt(n)\n\n        # --- Crude Monte Carlo Estimator ---\n        # Generate M samples from the original distribution N(0, n).\n        samples_crude = rng.normal(loc=mean_original, scale=std_dev, size=M)\n        \n        # The estimate is the fraction of samples that fall into the event region.\n        p_crude = np.mean(samples_crude = threshold)\n        results.append(p_crude)\n\n        # --- Importance Sampling (IS) Estimator ---\n        # The optimal tilting parameter is theta = a.\n        theta = a\n\n        # The mean of the IS sampling distribution N(n*theta, n).\n        mean_is = n * theta\n        # The standard deviation is the same, sqrt(n).\n        \n        # Generate M samples from the tilted (IS) distribution.\n        samples_is = rng.normal(loc=mean_is, scale=std_dev, size=M)\n        \n        # Calculate the likelihood ratio for each sample.\n        # L(s) = exp(-theta*s + n*psi(theta)), where psi(theta) = theta^2/2 for N(0,1).\n        # CGF of the sum is n*psi(theta).\n        log_likelihood_ratios = -theta * samples_is + n * theta**2 / 2.0\n        likelihood_ratios = np.exp(log_likelihood_ratios)\n\n        # The IS estimate is the average of the indicator function times the likelihood ratio.\n        # The indicator function is 1 if sample = threshold, and 0 otherwise.\n        indicators = (samples_is = threshold)\n        p_is = np.mean(indicators * likelihood_ratios)\n        results.append(p_is)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "虽然指数倾斜（如前一个练习  所示）是一种强大的技术，但它并非万能。本练习展示了一个指数倾斜方法可能失效的场景，并引入了一种更为稳健的替代方案——输运映射（transport map）。通过严格分析和比较这两种提议分布构建策略，你将学会识别不同方法的适用范围和潜在缺陷，这是成为高级实践者所必备的批判性思维能力。",
            "id": "3312692",
            "problem": "考虑以下在重要性采样（IS）背景下的稀有事件估计问题。设目标分布为位置参数为 $0$、尺度参数为 $1$ 的拉普拉斯分布，其概率密度函数为 $p(x) = \\frac{1}{2}\\exp(-|x|)$，对所有 $x \\in \\mathbb{R}$ 成立。稀有事件为左尾超出 $\\{x \\le -a\\}$，其中 $a  0$ 为一固定值。考虑两种提议分布构建策略：\n\n1. 指数族倾斜：对于一个固定的倾斜参数 $\\theta \\in (-1,0)$，定义提议分布 $q_{\\theta}(x)$ 为 $q_{\\theta}(x) \\propto p(x)\\exp(\\theta x)$，并将其归一化为 $\\mathbb{R}$ 上的概率密度。\n\n2. 变换映射提议：取基础提议分布 $q_{0}$ 为在 $[0,\\infty)$ 上率参数为 $\\lambda  0$ 的指数分布（Exponential$(\\lambda)$），其密度为 $q_{0}(u) = \\lambda \\exp(-\\lambda u)$。定义确定性变换 $T:[0,\\infty) \\to (-\\infty,-a]$ 为 $T(u) = -a - u$，并设 $q_{T} = T_{\\#}q_{0}$ 为由 $T$ 在 $(-\\infty,-a]$ 上导出的推前密度。\n\n你需要比较这两种提议分布构建方法，用于通过重要性采样估计稀有事件概率 $\\mathbb{P}(X \\le -a)$。请从第一性原理和以下基本定义出发：\n\n- 对于一个提议分布 $q$，其重要性采样权重为 $w(x) = \\frac{p(x)}{q(x)}$，定义在 $q$ 的支撑集上。\n- 推前密度 $q_{T} = T_{\\#}q_{0}$ 满足 $q_{T}(x) = q_{0}(u)\\left|\\frac{d u}{d x}\\right|$，其中 $x = T(u)$ 且 $T$ 在其值域上是可微且可逆的。\n- 拉普拉斯分布 Laplace$(0,1)$ 的矩母函数 $M_{X}(\\theta) = \\mathbb{E}[\\exp(\\theta X)]$ 在 $|\\theta|  1$ 时存在，且等于 $M_{X}(\\theta) = \\frac{1}{1 - \\theta^{2}}$。\n\n任务：\n- 使用这些定义，证明对于 $\\theta \\in (-1,0)$，与指数族倾斜 $q_{\\theta}$ 相关的重要性采样权重 $w_{\\theta}(x)$ 在事件 $\\{x \\le -a\\}$ 上是无界的。\n- 对于变换映射提议 $q_{T}$，推导在 $(-\\infty,-a]$ 上的精确重要性采样权重 $w_{T}(x)$，并确定在该事件上的上确界 $\\sup_{x \\le -a} w_{T}(x)$。\n\n以包含 $a$ 和 $\\lambda$ 的精确闭式表达式报告 $\\sup_{x \\le -a} w_{T}(x)$ 的最终答案。无需四舍五入。",
            "solution": "用户希望分析和比较两种不同的重要性采样提议策略，用于估计稀有事件概率 $\\mathbb{P}(X \\le -a)$，其中 $X$ 服从拉普拉斯分布。\n\n### 步骤 1：问题验证\n\n**提取的已知条件：**\n- 目标分布密度：$p(x) = \\frac{1}{2}\\exp(-|x|)$，其中 $x \\in \\mathbb{R}$。\n- 稀有事件：$\\{x \\le -a\\}$，对于固定的 $a  0$。\n- 提议 1（指数倾斜）：$q_{\\theta}(x) \\propto p(x)\\exp(\\theta x)$，对于固定的 $\\theta \\in (-1,0)$。\n- 提议 2（变换映射）：\n    - 基础分布密度：$q_{0}(u) = \\lambda \\exp(-\\lambda u)$，其中 $u \\in [0,\\infty)$，$\\lambda  0$。\n    - 变换映射：$T:[0,\\infty) \\to (-\\infty,-a]$ 定义为 $T(u) = -a - u$。\n    - 提议密度：$q_{T} = T_{\\#}q_{0}$。\n- IS 权重定义：$w(x) = \\frac{p(x)}{q(x)}$。\n- 推前密度公式：$q_{T}(x) = q_{0}(u)\\left|\\frac{d u}{d x}\\right|$，其中 $x = T(u)$。\n- Laplace$(0,1)$ 的矩母函数：$M_{X}(\\theta) = \\mathbb{E}[\\exp(\\theta X)] = \\frac{1}{1 - \\theta^{2}}$，其中 $|\\theta|  1$。\n\n**验证：**\n1.  **科学依据：** 该问题基于概率论和随机模拟的既定原则，特别是重要性采样、拉普拉斯分布、指数倾斜和变换映射。这些概念和定义都是标准的、科学上合理的。\n2.  **适定性：** 任务定义明确：证明一种提议分布的权重是无界的，并为另一种提议分布推导权重及其上确界。给定的信息足以完成这些任务。\n3.  **客观性：** 问题以精确、客观的数学语言陈述。\n4.  **一致性与完整性：** 问题是自洽的。可以使用提供的矩母函数找到 $q_{\\theta}(x)$ 的归一化常数。变换映射提议的所有细节都已指定。没有矛盾之处。\n\n**结论：** 问题有效。我们开始求解。\n\n### 步骤 2：求解推导\n\n求解过程分为两部分，每部分对应一种提议分布构建策略。\n\n**第 1 部分：指数族倾斜提议 $q_{\\theta}(x)$**\n\n首先，我们必须归一化提议密度 $q_{\\theta}(x)$。定义为 $q_{\\theta}(x) \\propto p(x)\\exp(\\theta x)$。归一化常数 $C_{\\theta}$ 是未归一化密度在 $\\mathbb{R}$ 上的积分：\n$$C_{\\theta} = \\int_{-\\infty}^{\\infty} p(x)\\exp(\\theta x) \\,dx$$\n根据定义，该积分是密度为 $p(x)$ 的随机变量 $X$ 在 $\\theta$ 处的矩母函数（MGF）。问题中提供了此 MGF：\n$$C_{\\theta} = M_{X}(\\theta) = \\frac{1}{1 - \\theta^{2}}$$\n这在 $|\\theta|  1$ 时有效，该范围包括了指定的 $\\theta \\in (-1,0)$。\n因此，归一化后的提议密度为：\n$$q_{\\theta}(x) = \\frac{p(x)\\exp(\\theta x)}{C_{\\theta}} = (1 - \\theta^{2})p(x)\\exp(\\theta x)$$\n现在，我们可以计算重要性采样权重 $w_{\\theta}(x)$：\n$$w_{\\theta}(x) = \\frac{p(x)}{q_{\\theta}(x)} = \\frac{p(x)}{(1 - \\theta^{2})p(x)\\exp(\\theta x)} = \\frac{1}{1 - \\theta^{2}}\\exp(-\\theta x)$$\n我们需要证明这些权重在事件 $\\{x \\le -a\\}$ 上是无界的。该事件对应于区间 $(-\\infty, -a]$。我们必须分析当 $x \\to -\\infty$ 时 $w_{\\theta}(x)$ 的行为。\n问题指定 $\\theta \\in (-1,0)$，这意味着 $-\\theta$ 是严格为正的，即 $-\\theta \\in (0,1)$。\n考虑当 $x$ 趋近于 $-\\infty$ 时 $w_{\\theta}(x)$ 的极限：\n$$\\lim_{x \\to -\\infty} w_{\\theta}(x) = \\lim_{x \\to -\\infty} \\frac{1}{1 - \\theta^{2}}\\exp(-\\theta x)$$\n由于 $-\\theta  0$，指数的参数 $-\\theta x$ 在 $x \\to -\\infty$ 时趋近于 $+\\infty$。因此，指数项发散：\n$$\\lim_{x \\to -\\infty} \\exp(-\\theta x) = +\\infty$$\n这意味着权重函数也发散：\n$$\\lim_{x \\to -\\infty} w_{\\theta}(x) = +\\infty$$\n由于函数 $w_{\\theta}(x)$ 是连续的，并且它在区间 $(-\\infty, -a]$ 的一端极限为无穷大，因此它在该区间上是无界的。这表明，对于任何 $\\theta \\in (-1,0)$ 的选择，指数倾斜提议都会导致对指定稀有事件的重要性采样估计量具有无限方差。\n\n**第 2 部分：变换映射提议 $q_{T}(x)$**\n\n首先，我们推导提议密度 $q_T(x) = (T_{\\#}q_0)(x)$。变换映射为 $x = T(u) = -a - u$。基础分布 $q_0$ 的支撑集是 $u \\in [0,\\infty)$，因此 $q_T$ 的支撑集是该集合在 $T$ 下的像，即 $(-\\infty, -a]$。\n为了使用推前公式，我们必须找到逆映射 $u = T^{-1}(x)$ 和此变换的雅可比行列式。\n从 $x = -a - u$，我们得到逆映射：\n$$u = -a - x$$\n导数为 $\\frac{du}{dx} = -1$。雅可比行列式的绝对值为 $\\left|\\frac{du}{dx}\\right| = |-1| = 1$。\n使用推前公式，对于 $x \\in (-\\infty, -a]$：\n$$q_{T}(x) = q_{0}(T^{-1}(x))\\left|\\frac{du}{dx}\\right| = q_{0}(-a-x) \\cdot 1$$\n代入 $q_0(u) = \\lambda \\exp(-\\lambda u)$ 的密度函数中：\n$$q_{T}(x) = \\lambda \\exp(-\\lambda(-a-x)) = \\lambda \\exp(\\lambda a + \\lambda x)$$\n这是 $x \\le -a$ 时的提议密度。对于 $x  -a$，$q_T(x) = 0$。\n\n接下来，我们在 $q_T$ 的支撑集 $(-\\infty, -a]$ 上推导 IS 权重 $w_T(x) = \\frac{p(x)}{q_T(x)}$。在这个区间上，$x$ 是负数，因此目标密度 $p(x)$ 中的绝对值 $|x|$ 等于 $-x$。\n$$p(x) = \\frac{1}{2}\\exp(-(-x)) = \\frac{1}{2}\\exp(x) \\quad \\text{for } x \\le -a$$\n现在我们可以构建权重函数：\n$$w_T(x) = \\frac{p(x)}{q_T(x)} = \\frac{\\frac{1}{2}\\exp(x)}{\\lambda \\exp(\\lambda a + \\lambda x)} = \\frac{1}{2\\lambda} \\exp(x - (\\lambda a + \\lambda x)) = \\frac{1}{2\\lambda} \\exp(-\\lambda a + (1-\\lambda)x)$$\n\n最后，我们确定 $w_T(x)$ 在事件域 $x \\in (-\\infty, -a]$ 上的上确界。$w_T(x)$ 的行为取决于指数中 $x$ 的系数 $(1-\\lambda)$ 的符号。\n- **情况 1：$\\lambda  1$。** 在这种情况下，$1-\\lambda  0$。函数 $w_T(x)$ 与 $\\exp((1-\\lambda)x)$ 成正比。当 $x \\to -\\infty$ 时，参数 $(1-\\lambda)x \\to +\\infty$。因此，$\\lim_{x \\to -\\infty} w_T(x) = +\\infty$。权重是无界的，上确界是无穷大。这样的提议分布对于方差缩减是无用的。\n- **情况 2：$\\lambda \\le 1$。** 在这种情况下，$1-\\lambda \\ge 0$。函数 $\\exp((1-\\lambda)x)$ 是 $x$ 的一个非递减函数。因此，它在区间 $(-\\infty, -a]$ 上的上确界必定出现在右边界，即 $x = -a$。\n\n问题要求给出上确界的表达式。一个重要性采样提议只有在产生的权重有界时才被认为是有效的，这能确保 IS 估计量具有有限方差。这要求上确界是有限的，从而将我们的兴趣限制在 $\\lambda \\le 1$ 的情况。因此，我们计算 $\\lambda$ 在此范围内的上确界。\n对于任何 $\\lambda \\in (0,1]$，上确界在 $x=-a$ 处达到：\n$$\\sup_{x \\le -a} w_{T}(x) = w_{T}(-a) = \\frac{1}{2\\lambda} \\exp(-\\lambda a + (1-\\lambda)(-a))$$\n$$= \\frac{1}{2\\lambda} \\exp(-\\lambda a - a + \\lambda a)$$\n$$= \\frac{1}{2\\lambda} \\exp(-a)$$\n该表达式给出了在此变换映射族中（以 $\\lambda \\in (0,1]$ 为特征）任何有效提议分布的重要性权重的有限上确界。请注意，当 $\\lambda$ 最大化时，即 $\\lambda=1$ 时，此上确界最小化，此时得到最优的常数权重 $w_T(x) = \\frac{1}{2}\\exp(-a)$。\n问题要求以 $a$ 和 $\\lambda$ 的形式给出上确界。提供上确界为有限的情况下的结果，是按要求提供有意义的闭式表达式的唯一方式。",
            "answer": "$$\\boxed{\\frac{\\exp(-a)}{2\\lambda}}$$"
        }
    ]
}