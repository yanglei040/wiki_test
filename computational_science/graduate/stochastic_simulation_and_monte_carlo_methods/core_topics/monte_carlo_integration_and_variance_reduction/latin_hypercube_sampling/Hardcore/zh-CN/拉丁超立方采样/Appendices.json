{
    "hands_on_practices": [
        {
            "introduction": "实践的第一步是掌握拉丁超立方采样（LHS）的基本构造。本练习  将指导你从零开始实现一个可复现的LHS生成器，其核心在于将决定分层结构的排列（permutations）与层内采样的抖动（jitter）分离开来。通过掌握这种分离随机源的实现，你不仅能够生成有效的LHS设计，还能为后续使用重复运行（replicated runs）进行严谨的方差分析打下坚实基础。",
            "id": "3317057",
            "problem": "要求您实现一个自包含的程序，构建一个可复现的拉丁超立方抽样（LHS）生成器，并能够存储和重用底层的排列，以支持重复运行和方差估计。该问题必须基于随机模拟和蒙特卡洛方法的首要原则来解决，并且程序必须确定性地执行。最终输出必须是单行文本，包含所有测试用例的结果，形式为方括号括起来的逗号分隔列表。\n\n基本原理：您必须仅依赖于核心定义和经过充分检验的性质：\n- $d$维单位超立方体是 $[0,1]^d$。\n- $[0,1]$上的均匀随机变量$U$的分布函数为 $F_U(u) = u$，$u \\in [0,1]$。\n- $\\{0,1,\\dots,n-1\\}$上的一个排列是重新排序索引的双射。\n- 分层：将$[0,1]$划分为$n$个等测度的不相交区间，即 $I_k = [k/n,(k+1)/n)$，其中 $k \\in \\{0,1,\\dots,n-1\\}$。\n- 使用固定种子的伪随机数生成是可复现的。\n\n目标构造：一个维度为$d$、大小为$n$的拉丁超立方抽样（LHS）设计，对每个样本在每个维度上使用一个不同的层。具体来说：\n- 对每个维度 $j \\in \\{1,\\dots,d\\}$，选择一个$\\{0,1,\\dots,n-1\\}$的随机排列 $\\pi_j$。\n- 对每个样本索引 $i \\in \\{1,\\dots,n\\}$和维度$j$，定义一个抖动$U_{i,j} \\sim \\text{Uniform}(0,1)$，其在$i$和$j$上独立，且独立于所有排列。\n- 点$X_{i,j} \\in [0,1]$随后按$X_{i,j} = \\left(\\pi_j(i-1)+U_{i,j}\\right)/n$构造，得到样本矩阵$X \\in [0,1]^{n \\times d}$，其性质为在每一列$j$中，每个层$I_k$内恰好有一个点。\n\n可复现性与重复运行：程序必须区分两种随机输入：\n- 一个基础种子，用于确定并存储排列 $\\{\\pi_j\\}_{j=1}^d$。\n- 一个抖动种子，用于确定均匀抖动矩阵 $\\{U_{i,j}\\}$。\n通过存储和重用$\\{\\pi_j\\}$，同时仅改变抖动种子，可以获得保留了层占用情况但在每个层内生成不同点的重复运行。这使得能够在具有公共分层的重复LHS运行中，对蒙特卡洛估计量进行方差估计。\n\n程序要求：\n- 实现一个LHS生成器，在给定$n$、$d$和基础种子时，返回样本和存储的排列。\n- 实现一个重构函数，该函数接收存储的排列和一个抖动种子，并生成一个新的LHS样本，重用完全相同的排列，只改变抖动。\n- 实现一个函数，用于计算函数$f:[0,1]^d \\to \\mathbb{R}$积分的蒙特卡洛估计量。使用简单样本均值$\\hat{\\mu} = \\frac{1}{n}\\sum_{i=1}^n f(X_i)$。\n- 实现一个函数，用于生成多个重复的LHS估计量，可以选择对每个重复使用固定的存储排列，或独立地重新生成排列。对于$R$个重复的估计值$\\{\\hat{\\mu}_r\\}_{r=1}^R$，计算无偏样本方差 $s^2 = \\frac{1}{R-1}\\sum_{r=1}^R (\\hat{\\mu}_r - \\bar{\\mu})^2$，其中$\\bar{\\mu} = \\frac{1}{R}\\sum_{r=1}^R \\hat{\\mu}_r$。\n\n用于方差估计的函数：\n- 定义 $f_1(x) = \\sum_{j=1}^d x_j^2$，其中$x \\in [0,1]^d$。\n- 对于边界情况，仅当$x \\in [0,1]^1$时使用$f_0(x) = x_1$。\n\n测试套件与要求输出：\n您的程序必须实现以下四个测试用例并输出相应的结果：\n\n- 测试 1 (正常路径覆盖性检查):\n  - 参数：$n=5$, $d=3$, 基础种子 $=314159$, 抖动种子 $=271828$。\n  - 任务：生成一个LHS样本，并验证每个维度的分层覆盖是精确的，即对每个维度$j$，多重集$\\{\\lfloor n X_{i,j}\\rfloor : i=1,\\dots,n\\}$等于$\\{0,1,2,3,4\\}$。\n  - 输出：一个布尔值，当且仅当所有三个维度都通过时等于$true$。\n\n- 测试 2 (在重复中使用固定排列进行方差估计):\n  - 参数：$n=50$, $d=4$, 基础种子 $=12345$, 抖动种子 $\\in \\{100,101,102,103,104\\}$ (五个重复使用相同的存储排列)，以及函数$f_1$。\n  - 任务：生成五个重复的LHS样本，重用存储的排列，并计算$\\int_{[0,1]^d} f_1(x)\\,dx$的五个蒙特卡洛估计值的无偏样本方差$s^2$。\n  - 输出：单个浮点数$s^2$。\n\n- 测试 3 (在重复中使用独立排列进行方差比较):\n  - 参数：$n=50$, $d=4$, 基础种子 $\\in \\{200,201,202,203,204\\}$ (五个重复，每次重复使用独立重新生成的排列)，抖动种子与测试2相同，以及函数$f_1$。\n  - 任务：使用独立重新生成的排列，计算五个蒙特卡洛估计值的无偏样本方差$s^2_{\\text{indep}}$，并输出比率$r = s^2_{\\text{fixed}}/s^2_{\\text{indep}}$，其中$s^2_{\\text{fixed}}$来自测试2。\n  - 输出：单个浮点数$r$。\n\n- 测试 4 (边界情况 $n=1$, $d=1$):\n  - 参数：$n=1$, $d=1$, 基础种子 $=777$, 抖动种子 $=888$，以及函数$f_0$。\n  - 任务：生成单点LHS样本并报告样本值$X_{1,1}$。\n  - 输出：一个等于$X_{1,1}$的单个浮点数。\n\n最终输出格式：\n- 您的程序应生成单行输出，包含测试1到4的结果，形式为方括号括起来的逗号分隔列表。列表项必须按测试顺序排列；例如，一个布尔值后跟三个浮点数的列表必须看起来像$[true,0.12345,0.6789,0.2468]$。不应打印任何额外文本。\n\n角度单位：不适用。物理单位：不适用。百分比：不适用。\n\n您的解决方案在描述中必须与语言无关，但在最终答案部分以实际可运行的程序呈现。确保科学真实性、内部一致性，并且所有浮点输出都从指定的种子确定性地派生，因此是可复现的。",
            "solution": "该问题要求从首要原则出发，实现一个可复现的拉丁超立方抽样（LHS）生成器，并强调将层排列的随机化与层内抖动的随机化分离开来的能力。在蒙特卡洛方法中，这种分离对于方差缩减技术至关重要，因为这些技术会使用具有共同随机数（在此情况下为共同分层）的重复样本。\n\n一个维度为$d$、大小为$n$的拉丁超立方样本是单位超立方体$[0,1]^d$中的$n$个点$\\{X_1, X_2, \\dots, X_n\\}$的集合。LHS的核心特性是它对边际分布进行分层。对于每个维度$j \\in \\{1, \\dots, d\\}$，域$[0,1]$被划分为$n$个等长的不相交区间，$I_k = [k/n, (k+1)/n)$，其中$k \\in \\{0, \\dots, n-1\\}$。该抽样设计确保对于每个维度，每个区间内都恰好落入一个样本点。\n\n样本矩阵$X \\in \\mathbb{R}^{n \\times d}$的构造如下。\n首先，对于每个维度$j \\in \\{1, \\dots, d\\}$，我们生成索引集$\\{0, 1, \\dots, n-1\\}$的一个随机排列$\\pi_j$。这$d$个排列定义了样本的分层结构。\n其次，我们生成一个$n \\times d$的抖动值矩阵$U$，其中每个元素$U_{i,j}$都是从$[0,1]$上的均匀分布中抽取的独立随机变量，即$U_{i,j} \\sim \\text{Uniform}(0,1)$。\n\n第$i$个样本点的第$j$个坐标$X_{i,j}$，通过组合排列和抖动来构造：\n$$X_{i,j} = \\frac{\\pi_j(i-1) + U_{i,j}}{n}$$\n在这里，我们将$\\pi_j(i-1)$解释为代表第$j$个排列的数组中的第$i$个元素（对$i$使用1-based索引，因此对应0-based数组索引为$(i-1)$）。这确保了对于任何固定的维度$j$，值集合$\\{\\lfloor n X_{i,j} \\rfloor\\}_{i=1}^n$恰好是集合$\\{0, 1, \\dots, n-1\\}$，从而满足分层属性。\n\n可复现性和方差分析依赖于对随机性来源的控制。该问题指定了两个种子：\n1.  一个`base_seed`，用于控制$d$个排列集合$\\{\\pi_j\\}_{j=1}^d$的生成。\n2.  一个`jitter_seed`，用于控制抖动矩阵$U = \\{U_{i,j}\\}$的生成。\n\n通过固定`base_seed`（从而固定排列），同时对多次运行使用不同的`jitter_seed`，我们生成共享相同分层结构的重复样本。这通常会在估计量的输出之间引入正相关，从而导致平均性能估计量的方差减小。该问题通过比较两种情景下蒙特卡洛估计的方差来检验这一点：\n- **固定排列**：生成一组排列并在所有重复中重用，仅重新抽样抖动。对于许多被积函数，预计这将产生较低的方差。\n- **独立排列**：每个重复都使用一组新的、独立的排列和抖动来生成。这对应于整个LHS实验的标准独立重复。\n\n积分$I = \\int_{[0,1]^d} f(x) \\, dx$的蒙特卡洛估计量是在LHS点上评估的函数值的样本均值：\n$$\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n f(X_i)$$\n给定来自$R$个重复的$R$个此类估计值$\\{\\hat{\\mu}_r\\}_{r=1}^R$，无偏样本方差计算如下：\n$$s^2 = \\frac{1}{R-1} \\sum_{r=1}^R (\\hat{\\mu}_r - \\bar{\\mu})^2$$\n其中$\\bar{\\mu} = \\frac{1}{R} \\sum_{r=1}^R \\hat{\\mu}_r$是这些估计值的均值。\n\n实现将包括使用`numpy`的伪随机数生成器（按规定设置种子）确定性地执行这些步骤的函数。\n\n**测试用例1**直接验证所生成的LHS样本的基本分层属性。对于大小为$n=5$、维度为$d=3$的样本，它检查对于3个维度中的每一个，样本在5个层$[0/5, 1/5), [1/5, 2/5), \\dots, [4/5, 5/5)$中都各包含一个点。\n\n**测试用例2**使用单个`base_seed`（固定排列）和五个不同的`jitter_seed`，计算$R=5$个重复的方差$s^2_{\\text{fixed}}$。这衡量了当仅改变层内随机性时估计量的变异性。\n\n**测试用例3**计算$R=5$个重复的方差$s^2_{\\text{indep}}$，其中每个重复使用独立的`base_seed`和`jitter_seed`。这代表了估计量的总变异性。比率$r = s^2_{\\text{fixed}} / s^2_{\\text{indep}}$量化了通过固定分层实现的方差缩减。对于像$f_1(x) = \\sum_{j=1}^d x_j^2$这样的可加函数，已知LHS特别有效，因此我们预计该比率将小于1。\n\n**测试用例4**检查$n=1$和$d=1$的边界情况。当$n=1$时，唯一的层是$[0,1)$，$\\{0\\}$的唯一排列是$(0)$。公式变为$X_{1,1} = (0 + U_{1,1})/1 = U_{1,1}$。输出就是由`jitter_seed`确定的均匀分布中的单个抽样值。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# from scipy import ... is not used.\n\ndef generate_lhs_permutations(n, d, base_seed):\n    \"\"\"\n    Generates d random permutations of {0, 1, ..., n-1} using a base seed.\n    These permutations define the stratification for the LHS design.\n    \"\"\"\n    base_rng = np.random.default_rng(base_seed)\n    # A list of d arrays, where each array is a permutation of arange(n).\n    permutations = [base_rng.permutation(n) for _ in range(d)]\n    return permutations\n\ndef construct_lhs_sample(permutations, n, d, jitter_seed):\n    \"\"\"\n    Constructs an LHS sample using pre-computed permutations and a jitter seed.\n    \"\"\"\n    jitter_rng = np.random.default_rng(jitter_seed)\n    # Generate an n x d matrix of uniform random numbers for jitter.\n    jitters = jitter_rng.uniform(size=(n, d))\n    \n    # Initialize the sample matrix.\n    sample = np.empty((n, d))\n    \n    # Construct the sample column by column.\n    for j in range(d):\n        perm_j = permutations[j]\n        jitter_j = jitters[:, j]\n        sample[:, j] = (perm_j + jitter_j) / n\n        \n    return sample\n\ndef f1(x):\n    \"\"\"Integrand for Tests 2 and 3: f(x) = sum(x_j^2).\"\"\"\n    # x is an n x d matrix. sum over the second axis (d dimensions).\n    return np.sum(x**2, axis=1)\n\ndef f0(x):\n    \"\"\"Integrand for Test 4: f(x) = x_1.\"\"\"\n    # x is an n x 1 matrix.\n    return x[:, 0]\n\ndef monte_carlo_estimator(func, sample):\n    \"\"\"Computes the Monte Carlo estimate for a given function and sample.\"\"\"\n    f_values = func(sample)\n    return np.mean(f_values)\n\ndef solve():\n    \"\"\"\n    Executes the four test cases and prints the results in the required format.\n    \"\"\"\n    results = []\n\n    # --- Test 1: Happy path coverage check ---\n    n1, d1, base_seed1, jitter_seed1 = 5, 3, 314159, 271828\n    perms1 = generate_lhs_permutations(n1, d1, base_seed1)\n    sample1 = construct_lhs_sample(perms1, n1, d1, jitter_seed1)\n    \n    is_valid_lhs = True\n    expected_strata = np.arange(n1)\n    for j in range(d1):\n        strata_indices = np.floor(n1 * sample1[:, j])\n        if not np.array_equal(np.sort(strata_indices), expected_strata):\n            is_valid_lhs = False\n            break\n    results.append(str(is_valid_lhs).lower())\n\n    # --- Test 2: Variance with fixed permutations ---\n    n2, d2, base_seed2 = 50, 4, 12345\n    jitter_seeds2 = [100, 101, 102, 103, 104]\n    \n    perms2 = generate_lhs_permutations(n2, d2, base_seed2)\n    estimates_fixed = []\n    for js in jitter_seeds2:\n        sample = construct_lhs_sample(perms2, n2, d2, js)\n        estimate = monte_carlo_estimator(f1, sample)\n        estimates_fixed.append(estimate)\n    \n    s2_fixed = np.var(estimates_fixed, ddof=1)\n    results.append(s2_fixed)\n\n    # --- Test 3: Variance with independent permutations and ratio ---\n    n3, d3 = 50, 4\n    base_seeds3 = [200, 201, 202, 203, 204]\n    jitter_seeds3 = [100, 101, 102, 103, 104]\n    \n    estimates_indep = []\n    for bs, js in zip(base_seeds3, jitter_seeds3):\n        perms = generate_lhs_permutations(n3, d3, bs)\n        sample = construct_lhs_sample(perms, n3, d3, js)\n        estimate = monte_carlo_estimator(f1, sample)\n        estimates_indep.append(estimate)\n        \n    s2_indep = np.var(estimates_indep, ddof=1)\n    ratio = s2_fixed / s2_indep\n    results.append(ratio)\n\n    # --- Test 4: Edge case n=1, d=1 ---\n    n4, d4, base_seed4, jitter_seed4 = 1, 1, 777, 888\n    \n    perms4 = generate_lhs_permutations(n4, d4, base_seed4)\n    # perms4 will be [array([0])]\n    sample4 = construct_lhs_sample(perms4, n4, d4, jitter_seed4)\n    # For n=1, sample value X_11 is just the jitter U_11.\n    result4 = sample4[0, 0]\n    results.append(result4)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "理解如何生成LHS样本后，下一个关键问题是：它为何以及在何种情况下优于其他采样方法？本练习  通过一个经典的可加函数 $f(x,y)=x+y$，让你亲手推导并量化LHS相对于二维分层采样的方差改进。这个分析将清晰地揭示LHS在处理可加性占优的被积函数时，其卓越方差缩减能力的理论根源。",
            "id": "3285740",
            "problem": "考虑在单位正方形上，关于两个独立的均匀分布 Uniform$(0,1)$ 随机变量的乘积测度，估计函数 $f(x,y)=x+y$ 的积分 $\\mu$。也就是说，设 $(X,Y)$ 相互独立，其中 $X \\sim \\text{Uniform}(0,1)$ 且 $Y \\sim \\text{Uniform}(0,1)$，并定义 $\\mu = \\mathbb{E}[f(X,Y)]$。您将比较在由函数评估次数量化的固定计算预算下的两种抽样策略。\n\n策略 A：拉丁超立方抽样 (LHS)。抽取 $N$ 个样本 $\\{(X_{i},Y_{\\pi(i)})\\}_{i=1}^{N}$，其中 $\\{X_{i}\\}_{i=1}^{N}$ 相互独立且 $X_{i} \\sim \\text{Uniform}\\!\\left(\\frac{i-1}{N},\\frac{i}{N}\\right)$，$\\{Y_{j}\\}_{j=1}^{N}$ 相互独立且 $Y_{j} \\sim \\text{Uniform}\\!\\left(\\frac{j-1}{N},\\frac{j}{N}\\right)$，$\\pi$ 是独立于抽样的 $\\{1,2,\\dots,N\\}$ 的一个随机排列。估计量是样本均值 $\\hat{\\mu}_{\\text{LHS}}=\\frac{1}{N}\\sum_{i=1}^{N}f\\!\\left(X_{i},Y_{\\pi(i)}\\right)$。\n\n策略 B：在 $m \\times m$ 网格上的二维分层抽样，每层一个样本，其中 $N$ 是一个完全平方数且 $m=\\sqrt{N}$。将 $[0,1]^{2}$ 划分为 $m \\times m$ 个相等的方形单元，并在每个单元内随机均匀地抽取一个点。估计量是样本均值 $\\hat{\\mu}_{\\text{STRAT}}=\\frac{1}{N}\\sum_{k=1}^{N}f\\!\\left(X^{(k)},Y^{(k)}\\right)$，其中 $(X^{(k)},Y^{(k)})$ 在第 $k$ 个单元上均匀分布，且这 $N$ 个单元的抽样是相互独立的。\n\n仅使用期望和方差的基本定义、均匀抽样下坐标的独立性以及区间上均匀分布的性质，推导每个估计量的方差，然后通过比率量化策略 A 相对于策略 B 的改进程度\n$$\\mathcal{R}(N) = \\frac{\\operatorname{Var}\\!\\left(\\hat{\\mu}_{\\text{STRAT}}\\right)}{\\operatorname{Var}\\!\\left(\\hat{\\mu}_{\\text{LHS}}\\right)}$$\n将 $\\mathcal{R}(N)$ 表示为关于 $N$ 的封闭形式解析表达式。根据函数的结构和抽样设计，对结果进行简要解释。您的最终答案必须是 $\\mathcal{R}(N)$ 的单一表达式；无需四舍五入，不涉及单位。",
            "solution": "该问题表述清晰且具有科学依据，因此我们开始求解。\n\n待估计的积分是 $\\mu = \\mathbb{E}[f(X,Y)]$，其中 $f(x,y)=x+y$ 且 $X, Y$ 是服从 $\\text{Uniform}(0,1)$ 分布的独立随机变量。根据期望的线性性质，可得 $\\mu = \\mathbb{E}[X] + \\mathbb{E}[Y] = \\frac{1}{2} + \\frac{1}{2} = 1$。\n\n我们将推导每个估计量 $\\hat{\\mu}_{\\text{STRAT}}$ 和 $\\hat{\\mu}_{\\text{LHS}}$ 的方差，然后计算它们的比率。\n\n### 分层抽样估计量的方差 ($\\operatorname{Var}(\\hat{\\mu}_{\\text{STRAT}})$)\n\n策略 B 使用 $m \\times m$ 网格上的分层抽样，其中 $N=m^2$ 是总样本数。从 $N$ 个方形单元中的每一个单元内均匀抽取一个样本。估计量由下式给出：\n$$ \\hat{\\mu}_{\\text{STRAT}} = \\frac{1}{N} \\sum_{k=1}^{N} f(X^{(k)}, Y^{(k)}) $$\n其中 $(X^{(k)}, Y^{(k)})$ 是从第 $k$ 个单元内均匀抽取的样本。不同单元的抽样是相互独立的。由于这种独立性，估计量的方差为：\n$$ \\operatorname{Var}(\\hat{\\mu}_{\\text{STRAT}}) = \\operatorname{Var}\\left(\\frac{1}{N} \\sum_{k=1}^{N} f(X^{(k)}, Y^{(k)})\\right) = \\frac{1}{N^2} \\sum_{k=1}^{N} \\operatorname{Var}(f(X^{(k)}, Y^{(k)})) $$\n我们将单元表示为 $S_{ij} = [\\frac{i-1}{m}, \\frac{i}{m}] \\times [\\frac{j-1}{m}, \\frac{j}{m}]$，其中 $i,j \\in \\{1, 2, \\dots, m\\}$。从单元 $S_{ij}$ 中抽取的样本 $(X_{ij}, Y_{ij})$ 由两个独立的随机变量组成：$X_{ij} \\sim \\text{Uniform}(\\frac{i-1}{m}, \\frac{i}{m})$ 和 $Y_{ij} \\sim \\text{Uniform}(\\frac{j-1}{m}, \\frac{j}{m})$。\n对于函数 $f(x,y)=x+y$，单元 $S_{ij}$ 内的方差为：\n$$ \\operatorname{Var}(f(X_{ij}, Y_{ij})) = \\operatorname{Var}(X_{ij} + Y_{ij}) $$\n由于 $X_{ij}$ 和 $Y_{ij}$ 相互独立，这变为：\n$$ \\operatorname{Var}(X_{ij} + Y_{ij}) = \\operatorname{Var}(X_{ij}) + \\operatorname{Var}(Y_{ij}) $$\n长度为 $L$ 的区间上的均匀分布的方差是 $\\frac{L^2}{12}$。$X_{ij}$ 和 $Y_{ij}$ 的区间长度均为 $L = \\frac{1}{m}$。\n$$ \\operatorname{Var}(X_{ij}) = \\frac{(1/m)^2}{12} = \\frac{1}{12m^2} $$\n$$ \\operatorname{Var}(Y_{ij}) = \\frac{(1/m)^2}{12} = \\frac{1}{12m^2} $$\n因此，任何单元内的方差为：\n$$ \\operatorname{Var}(f(X_{ij}, Y_{ij})) = \\frac{1}{12m^2} + \\frac{1}{12m^2} = \\frac{2}{12m^2} = \\frac{1}{6m^2} $$\n对于所有 $N=m^2$ 个单元，这个方差都是相同的。我们称之为 $\\sigma_{\\text{cell}}^2$。\n估计量的总方差为：\n$$ \\operatorname{Var}(\\hat{\\mu}_{\\text{STRAT}}) = \\frac{1}{N^2} \\sum_{k=1}^{N} \\sigma_{\\text{cell}}^2 = \\frac{1}{N^2} (N \\cdot \\frac{1}{6m^2}) = \\frac{1}{6Nm^2} $$\n代入 $m^2=N$，我们得到：\n$$ \\operatorname{Var}(\\hat{\\mu}_{\\text{STRAT}}) = \\frac{1}{6N \\cdot N} = \\frac{1}{6N^2} $$\n\n### 拉丁超立方抽样估计量的方差 ($\\operatorname{Var}(\\hat{\\mu}_{\\text{LHS}})$)\n\n策略 A 使用拉丁超立方抽样，样本数为 $N$。估计量为：\n$$ \\hat{\\mu}_{\\text{LHS}} = \\frac{1}{N} \\sum_{i=1}^{N} f(X_i, Y_{\\pi(i)}) = \\frac{1}{N} \\sum_{i=1}^{N} (X_i + Y_{\\pi(i)}) $$\n其中 $X_i \\sim \\text{Uniform}(\\frac{i-1}{N}, \\frac{i}{N})$，$Y_j \\sim \\text{Uniform}(\\frac{j-1}{N}, \\frac{j}{N})$，且 $\\pi$ 是 $\\{1, 2, \\dots, N\\}$ 的一个随机排列。变量集合 $\\{X_i\\}_{i=1}^N$ 和 $\\{Y_j\\}_{j=1}^N$ 相互独立，且与排列 $\\pi$ 独立。\n\n由于函数 $f(x,y)$ 的可加性，估计量可以被拆分：\n$$ \\hat{\\mu}_{\\text{LHS}} = \\frac{1}{N}\\sum_{i=1}^{N} X_i + \\frac{1}{N}\\sum_{i=1}^{N} Y_{\\pi(i)} $$\n第二个和是变量 $\\{Y_1, \\dots, Y_N\\}$ 的一个排列，所以 $\\sum_{i=1}^{N} Y_{\\pi(i)} = \\sum_{j=1}^{N} Y_j$。因此，估计量为：\n$$ \\hat{\\mu}_{\\text{LHS}} = \\left(\\frac{1}{N}\\sum_{i=1}^{N} X_i\\right) + \\left(\\frac{1}{N}\\sum_{j=1}^{N} Y_j\\right) $$\n变量集 $\\{X_i\\}$ 与变量集 $\\{Y_j\\}$ 相互独立。因此，和的方差是方差的和：\n$$ \\operatorname{Var}(\\hat{\\mu}_{\\text{LHS}}) = \\operatorname{Var}\\left(\\frac{1}{N}\\sum_{i=1}^{N} X_i\\right) + \\operatorname{Var}\\left(\\frac{1}{N}\\sum_{j=1}^{N} Y_j\\right) $$\n变量 $X_1, \\dots, X_N$ 是相互独立的。$Y_1, \\dots, Y_N$ 也是如此。\n$$ \\operatorname{Var}\\left(\\frac{1}{N}\\sum_{i=1}^{N} X_i\\right) = \\frac{1}{N^2} \\sum_{i=1}^{N} \\operatorname{Var}(X_i) $$\n对于每个 $i$，$X_i$ 在长度为 $\\frac{1}{N}$ 的区间上均匀分布。其方差为 $\\operatorname{Var}(X_i) = \\frac{(1/N)^2}{12} = \\frac{1}{12N^2}$。\n$$ \\operatorname{Var}\\left(\\frac{1}{N}\\sum_{i=1}^{N} X_i\\right) = \\frac{1}{N^2} \\sum_{i=1}^{N} \\frac{1}{12N^2} = \\frac{1}{N^2} \\left(N \\cdot \\frac{1}{12N^2}\\right) = \\frac{1}{12N^3} $$\n类似地，对于 $Y$ 分量：\n$$ \\operatorname{Var}\\left(\\frac{1}{N}\\sum_{j=1}^{N} Y_j\\right) = \\frac{1}{12N^3} $$\n将这两个方差相加，得到 LHS 估计量的总方差：\n$$ \\operatorname{Var}(\\hat{\\mu}_{\\text{LHS}}) = \\frac{1}{12N^3} + \\frac{1}{12N^3} = \\frac{2}{12N^3} = \\frac{1}{6N^3} $$\n请注意，对于这个可加函数，方差与随机排列 $\\pi$ 无关。\n\n### 方差之比\n\n最后，我们计算比率 $\\mathcal{R}(N) = \\frac{\\operatorname{Var}(\\hat{\\mu}_{\\text{STRAT}})}{\\operatorname{Var}(\\hat{\\mu}_{\\text{LHS}})}$：\n$$ \\mathcal{R}(N) = \\frac{1/(6N^2)}{1/(6N^3)} = \\frac{6N^3}{6N^2} = N $$\n\n对于这个特定问题，LHS 相对于分层抽样的改进因子为 $N$。这一显著改进是由于被积函数 $f(x,y)=x+y$ 的可加结构。LHS 有效地确保了样本在每个轴上的投影被完美地分层到 $N$ 个区间中。这等同于对 $\\mathbb{E}[X]$ 和 $\\mathbb{E}[Y]$ 分别执行两次独立的、各有 $N$ 层的一维分层抽样估计。对于线性函数，这样一个一维估计量的方差尺度为 $O(N^{-3})$。相比之下，$m \\times m$ 分层抽样在每个轴上仅投影到 $m=\\sqrt{N}$ 个层，导致方差尺度为 $O(m^{-4}) = O(N^{-2})$。因此，两个方差之比为 $O(N)$。",
            "answer": "$$\\boxed{N}$$"
        },
        {
            "introduction": "虽然随机LHS在保证一维边际投影的均匀性方面优于简单蒙特卡洛方法，但其高维样本点之间仍可能出现不必要的伪相关（spurious correlations）。本项高级实践  引入了一种通过最小化列间相关性来优化LHS设计的算法。你将实现一个迭代交换方案，主动改善样本的空间填充性（space-filling properties），从而从生成随机LHS迈向构建优化的LHS设计。",
            "id": "3317028",
            "problem": "您的任务是为拉丁超立方采样（LHS）形式化并实现一种相关性最小化方案，该方案适用于高维随机模拟和蒙特卡洛方法。一个在 $m$ 维空间中大小为 $N$ 的拉丁超立方样本（LHS）是一个矩阵 $X \\in \\mathbb{R}^{N \\times m}$，使得对于每一列 $j \\in \\{1,\\dots,m\\}$，其 $N$ 个条目 $X_{1j},\\dots,X_{Nj}$ 占据了由将单位区间 $[0,1]$ 划分为 $N$ 个相等子区间而形成的 $N$ 个不相交的层。一种标准的随机化构造方法为每一行 $i \\in \\{1,\\dots,N\\}$ 和每一列 $j \\in \\{1,\\dots,m\\}$ 分配一个形式为 $(\\pi_j(i) + U_{ij}) / N$ 的值，其中 $\\pi_j$ 是 $\\{0,1,\\dots,N-1\\}$ 的一个排列，而 $U_{ij}$ 是在 $[0,1)$ 上均匀分布的独立同分布随机变量。这确保了每一层在每列中都恰好被占据一次。\n\n对于任意列 $j$，令 $\\mu_j$ 表示样本均值，令 $\\sigma_j$ 表示样本标准差（除数为 $N$）。定义标准化矩阵 $Z \\in \\mathbb{R}^{N \\times m}$ 为 $Z_{ij} = (X_{ij} - \\mu_j)/\\sigma_j$。列 $j$ 和 $k$ 之间的皮尔逊相关系数由下式给出\n$$\nr_{jk} \\;=\\; \\frac{1}{N}\\sum_{i=1}^{N} Z_{ij} Z_{ik}\n$$\n将最小列相关性准则（目标）定义为\n$$\n\\Phi(X) \\;=\\; \\sum_{1 \\le j  k \\le m} \\left| r_{jk} \\right|\n$$\n目标是通过保持 LHS 属性的交换操作来减小 $\\Phi(X)$。\n\n您必须实现以下定向交换算法方案以减少列相关性：\n\n- 初始化：\n  - 使用上述的分层均匀抖动方法，构建一个初始的随机化拉丁超立方样本 $X \\in [0,1]^{N \\times m}$。\n  - 标准化各列以获得 $Z$。\n  - 计算相关矩阵条目 $r_{jk}$ 和 $\\Phi(X)$。\n\n- 迭代定向交换过程：\n  - 在每次迭代中，为每列 $j$ 计算其相关性负担 $s_j = \\sum_{k \\ne j} |r_{jk}|$.\n  - 选择具有最大 $s_c$ 的列 $c$。\n  - 考虑在列 $c$ 中交换两个不同行 $i$ 和 $k$ 的两个条目。这种交换保持了 LHS 属性，因为它在列内排列条目，并且不改变该列所占据的层的多重集。\n  - 在所有可能的行对 $(i,k)$（其中 $1 \\le i  k \\le N$）中，选择在列 $c$ 中能产生 $\\Phi(X)$ 最大严格减小的单次交换。如果没有交换能产生严格减小，则终止过程。否则，执行该交换，更新相关性量，并重复此过程，直到终止或达到最大接受交换次数 $S_{\\max}$。\n\n您的程序必须实现上述算法，并为提供的测试套件中的每组参数返回算法终止后 $\\Phi(X)$ 的最终值。所有随机化必须通过指定的种子使其可复现。\n\n测试套件。对于每种情况，输入为 LHS 大小 $N$、维度 $m$、用于构建 LHS 的生成器的随机种子，以及最大接受交换次数 $S_{\\max}$：\n- 情况 A（通用）：$N = 20$，$m = 5$，种子 $= 314159$，$S_{\\max} = 2000$。\n- 情况 B（边界，一维）：$N = 8$，$m = 1$，种子 $= 271828$，$S_{\\max} = 2000$。\n- 情况 C（更高维度且有迭代上限）：$N = 30$，$m = 10$，种子 $= 424242$，$S_{\\max} = 300$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，顺序为 [情况 A 结果, 情况 B 结果, 情况 C 结果]，其中每个结果是算法终止后 $\\Phi(X)$ 的最终值，表示为小数点后保留六位的小数（例如，$[0.123456,0.000000,0.654321]$）。不应打印任何额外文本。",
            "solution": "该问题要求实现一个特定的迭代算法，以减少拉丁超立方样本（LHS）中的伪相关性。该算法是一种贪婪局部搜索过程，旨在最小化目标函数 $\\Phi(X)$。该函数定义为样本矩阵各列之间成对皮尔逊相关系数绝对值之和。搜索过程通过迭代地交换对总相关性贡献最大的列中的元素对来进行。\n\n解决方案是按照问题陈述中概述的算法步骤来开发的：初始化和迭代定向交换过程。\n\n### 1. 初始化\n\n首先，必须构建一个初始的拉丁超立方样本矩阵 $X \\in \\mathbb{R}^{N \\times m}$。根据问题描述，对于一个在 $m$ 维空间中大小为 $N$ 的样本，每一列 $j \\in \\{1, \\dots, m\\}$ 必须包含来自 $N$ 个不相交层 $[k/N, (k+1)/N)$（其中 $k \\in \\{0, \\dots, N-1\\}$）中的一个值。这是通过随机化的分层抽样过程实现的。\n\n对于每一列 $j$：\n1.  生成整数集合 $\\{0, 1, \\dots, N-1\\}$ 的一个随机排列 $\\pi_j$。这将一个唯一的层索引分配给 $N$ 行中的每一行。\n2.  从 $[0, 1)$ 上的均匀分布中抽取一个包含 $N$ 个独立随机数 $U_{ij}$ 的向量，其中 $i \\in \\{1, \\dots, N\\}$。\n3.  然后，矩阵 $X$ 的第 $j$ 列的条目计算如下：\n    $$\n    X_{ij} = \\frac{\\pi_j(i) + U_{ij}}{N}\n    $$\n这种构造保证了 LHS 属性。所有随机化都使用种子以确保可复现性。\n\n接下来，对样本矩阵 $X$ 进行标准化。对于每一列 $j$，我们计算样本均值 $\\mu_j$ 和样本标准差 $\\sigma_j$（按规定使用除数 $N$）。\n$$\n\\mu_j = \\frac{1}{N}\\sum_{i=1}^{N} X_{ij} \\quad \\text{and} \\quad \\sigma_j = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N} (X_{ij} - \\mu_j)^2}\n$$\n然后通过以下方式获得标准化矩阵 $Z \\in \\mathbb{R}^{N \\times m}$：\n$$\nZ_{ij} = \\frac{X_{ij} - \\mu_j}{\\sigma_j}\n$$\n根据构造，$Z$ 的每一列的均值为 $0$，标准差为 $1$。\n\n任意两列 $j$ 和 $k$ 之间的皮尔逊相关系数 $r_{jk}$ 是从标准化矩阵计算得出的。这些系数的矩阵 $R$ 可以通过矩阵乘法高效计算：\n$$\nr_{jk} = \\frac{1}{N}\\sum_{i=1}^{N} Z_{ij} Z_{ik} \\quad \\implies \\quad R = \\frac{1}{N} Z^T Z\n$$\n请注意，对角线元素 $r_{jj}$ 始终等于 $1$。\n\n最后，计算目标函数 $\\Phi(X)$ 的初始值：\n$$\n\\Phi(X) = \\sum_{1 \\le j  k \\le m} |r_{jk}|\n$$\n这代表了非对角线相关的总幅度，算法旨在将其最小化。对于 $m=1$ 的边缘情况，这个和是空的，其值为 $0$。\n\n### 2. 迭代定向交换过程\n\n该算法的核心是一个迭代循环，它执行贪婪搜索以寻找能减少相关性的交换。循环持续进行，直到找不到进一步的改进或达到最大接受交换次数 $S_{\\max}$。\n\n在每次迭代中，执行以下步骤：\n\n1.  **选择目标列**：识别对目标函数贡献最大的列。每列 $j$ 的“相关性负担” $s_j$ 定义为与所有其他列的绝对相关性之和：\n    $$\n    s_j = \\sum_{k \\neq j} |r_{jk}|\n    $$\n    选择负担最大的列 $c$，即 $c = \\arg\\max_j s_j$，作为优化的目标。\n\n2.  **寻找最佳交换**：算法搜索一对行 $(i, k)$，使得在目标列 $c$ 中交换条目 $X_{ic}$ 和 $X_{kc}$ 能产生 $\\Phi(X)$ 的最大可能严格减小。在单列内交换两个元素会保留该列中的值集，因此其均值 $\\mu_c$ 和标准差 $\\sigma_c$ 保持不变。因此，标准化的值 $Z_{ic}$ 和 $Z_{kc}$ 只是简单地交换。此交换仅影响涉及列 $c$ 的相关性，即 $r_{cl}$（其中 $l \\neq c$）。\n\n    我们来推导当条目 $Z_{ic}$ 和 $Z_{kc}$ 被交换时，相关系数 $r_{cl}$ 的变化。令 $Z'$ 为交换后的矩阵。新的相关性 $r'_{cl}$ 为：\n    $$\n    r'_{cl} = \\frac{1}{N}\\sum_{p=1}^{N} Z'_{pc} Z_{pl} = \\frac{1}{N} \\left( \\sum_{p \\notin \\{i,k\\}} Z_{pc}Z_{pl} + Z_{kc}Z_{il} + Z_{ic}Z_{kl} \\right)\n    $$\n    因此，变化量 $\\Delta r_{cl} = r'_{cl} - r_{cl}$ 为：\n    $$\n    \\Delta r_{cl} = \\frac{1}{N} \\left( (Z_{kc}Z_{il} + Z_{ic}Z_{kl}) - (Z_{ic}Z_{il} + Z_{kc}Z_{kl}) \\right) = \\frac{1}{N} (Z_{kc} - Z_{ic})(Z_{il} - Z_{kl})\n    $$\n    当 $j$ 和 $k$ 都不等于 $c$ 时，相关性 $r_{jk}$ 不受影响。对于在列 $c$ 中行 $i$ 和 $k$ 之间的一次交换，目标函数的总变化 $\\Delta \\Phi$ 为：\n    $$\n    \\Delta \\Phi_{i,k,c} = \\sum_{l \\neq c} \\left( |r_{cl} + \\Delta r_{cl}| - |r_{cl}| \\right)\n    $$\n    算法为所有可能的对 $(i, k)$（其中 $1 \\le i  k \\le N$）计算 $\\Delta \\Phi_{i,k,c}$，并识别出产生最负值（最大减小量）的那个。\n\n3.  **更新状态或终止**：\n    *   如果找到的最佳交换导致了严格减小（$\\Delta \\Phi  0$），则接受该交换。更新矩阵 $Z$ 和 $R$，以及目标函数 $\\Phi$。我们不是重新计算整个矩阵 $R$，而是应用计算出的变化：对于所有 $l \\neq c$，$r_{cl}$ 通过加上对应于最佳交换的 $\\Delta r_{cl}$ 来更新。$\\Phi$ 的值通过加上最佳的 $\\Delta \\Phi$ 来更新。交换计数器递增。\n    *   如果没有交换能产生严格减小（对于所有对，$\\Delta \\Phi \\ge 0$），则对于当前目标列不可能有改进。算法的贪婪性质决定了此时终止。主循环被中断。\n\n该过程重复进行，直到满足其中一个终止条件。然后报告 $\\Phi(X)$ 的最终值。\n\n### 3. 实现与向量化\n\n为了高效地实现这一点，特别是寻找最佳交换的搜索，我们使用向量化。对于选定的列 $c$，我们可以使用 `numpy` 数组操作同时计算所有对 $(i, k)$ 和所有其他列 $l$ 的变化 $\\Delta r_{cl}$。这避免了在 Python 中使用缓慢的嵌套循环。具体来说，对于所有 $N(N-1)/2$ 个行对，计算一个相关性变化矩阵。由此，导出一个 $\\Delta \\Phi$ 值的向量，其最小值确定了最佳交换。然后，基于这个唯一的最佳交换，高效地执行对矩阵 $Z$ 和 $R$ 以及标量 $\\Phi$ 的更新。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and runs the correlation-minimizing LHS algorithm for the given test suite.\n    \"\"\"\n    test_cases = [\n        # (N, m, seed, S_max)\n        (20, 5, 314159, 2000),  # Case A\n        (8, 1, 271828, 2000),   # Case B\n        (30, 10, 424242, 300),  # Case C\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        N, m, seed, S_max = case\n        rng = np.random.default_rng(seed)\n\n        # Handle the trivial 1D case. The objective function sum is empty.\n        if m == 1:\n            results.append(0.0)\n            continue\n\n        # --- 1. Initialization ---\n        \n        # Create the initial Latin Hypercube Sample matrix X\n        X = np.empty((N, m))\n        for j in range(m):\n            perm = rng.permutation(N)\n            u = rng.random(size=N)\n            X[:, j] = (perm + u) / N\n\n        # Standardize the matrix X to get Z\n        mu = np.mean(X, axis=0, keepdims=True)\n        # Use ddof=0 for divisor N as specified\n        sigma = np.std(X, axis=0, ddof=0, keepdims=True)\n        Z = (X - mu) / sigma\n        \n        # Compute the initial correlation matrix R and objective phi\n        R = (Z.T @ Z) / N\n        phi = np.sum(np.abs(np.triu(R, k=1)))\n        \n        # --- 2. Iterative Targeted-Swap Procedure ---\n        \n        num_swaps_accepted = 0\n        for _ in range(S_max):\n            # Select target column 'c' with the highest correlation burden\n            R_abs = np.abs(R)\n            np.fill_diagonal(R_abs, 0)\n            s = np.sum(R_abs, axis=1)\n            c = np.argmax(s)\n            \n            # Find the best swap in column 'c'\n            best_delta_phi = 0.0\n            best_swap_indices = None\n            best_delta_r = None\n\n            # Get all unique row pairs (i, k) where i  k\n            i_indices, k_indices = np.triu_indices(N, k=1)\n            \n            # Vectorized computation of potential changes\n            # For each potential swap (i,k), calculate the change in correlations r_cl\n            Z_col_c = Z[:, c]\n            Z_col_c_diffs = Z_col_c[k_indices] - Z_col_c[i_indices] # Shape: (num_pairs,)\n            \n            Z_row_diffs = Z[i_indices, :] - Z[k_indices, :] # Shape: (num_pairs, m)\n            \n            # Matrix of correlation changes. Shape: (num_pairs, m)\n            # Each row corresponds to a swap (i,k) and contains delta_r_cl for all l.\n            delta_r_matrix = (1 / N) * Z_col_c_diffs[:, np.newaxis] * Z_row_diffs\n            delta_r_matrix[:, c] = 0.0 # Change in r_cc is 0\n            \n            # Calculate the change in phi for each potential swap\n            mask = np.ones(m, dtype=bool)\n            mask[c] = False\n            \n            r_c_vec = R[c, mask]\n            r_c_new_matrix = r_c_vec[np.newaxis, :] + delta_r_matrix[:, mask]\n            \n            delta_phi_vec = np.sum(np.abs(r_c_new_matrix), axis=1) - np.sum(np.abs(r_c_vec))\n            \n            # Find the best swap among all pairs\n            min_idx = np.argmin(delta_phi_vec)\n            current_best_delta_phi = delta_phi_vec[min_idx]\n\n            if current_best_delta_phi  0:\n                best_delta_phi = current_best_delta_phi\n                best_swap_indices = (i_indices[min_idx], k_indices[min_idx])\n                best_delta_r = delta_r_matrix[min_idx, :]\n\n            # If no improvement found, terminate the algorithm\n            if best_swap_indices is None:\n                break\n            \n            # --- 3. Update State ---\n            \n            # Perform the best swap and update all relevant quantities\n            i, k = best_swap_indices\n            \n            # Update phi\n            phi += best_delta_phi\n            \n            # Update standardized matrix Z\n            Z[i, c], Z[k, c] = Z[k, c], Z[i, c]\n            \n            # Update correlation matrix R\n            R[c, :] += best_delta_r\n            R[:, c] = R[c, :]\n            \n            num_swaps_accepted += 1\n\n        results.append(phi)\n\n    # Format output as specified\n    print(f\"[{','.join(f'{res:.6f}' for res in results)}]\")\n\nsolve()\n```"
        }
    ]
}