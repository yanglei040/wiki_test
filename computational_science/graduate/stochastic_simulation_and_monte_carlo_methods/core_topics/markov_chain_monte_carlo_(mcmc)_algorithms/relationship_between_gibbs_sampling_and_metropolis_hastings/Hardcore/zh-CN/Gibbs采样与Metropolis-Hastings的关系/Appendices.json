{
    "hands_on_practices": [
        {
            "introduction": "Metropolis-Hastings (MH) 算法是许多现代马尔可夫链蒙特卡洛（MCMC）方法的核心引擎。本练习将引导你回归第一性原理，从细致平衡条件出发，推导著名的 MH 接受率。此过程将突显提议分布的重要性，尤其是在非对称提议的普遍情况下，为理解更专业的采样器（如吉布斯采样）奠定坚实的理论基础。",
            "id": "3336061",
            "problem": "考虑一个 Metropolis–Hastings (MH) 类型的马尔可夫链蒙特卡罗转移，其设计旨在使实线上的目标分布 $\\,\\pi(x)\\,$ 保持不变。提议机制由一个可能不对称的条件密度 $\\,q(y \\mid x)\\,$ 来表征。接受函数 $\\,a(x,y)\\,$ 满足 $\\,0 \\leq a(x,y) \\leq 1\\,$，其选择应使得马尔可夫链对于 $\\,\\pi\\,$ 是可逆的，从而 $\\,\\pi\\,$ 是其平稳分布。从可逆马尔可夫核的细致平衡原理出发，推导出用 $\\,\\pi\\,$ 和 $\\,q\\,$ 表示的显式 Hastings 接受率 $\\,r(x,y)\\,$，并由此获得接受概率 $\\,a(x,y)\\,$ 的函数形式。\n\n然后，在以下科学上现实的设定中具体化您的推导：\n- 未归一化的目标密度由 $\\,\\tilde{\\pi}(x) = \\exp\\!\\left(-\\frac{1}{4}x^{4} + \\frac{1}{2}x^{2}\\right)\\,$ 给出，该密度在尾部是对数凹的，并且在 $\\,\\mathbb{R}\\,$ 上可积。归一化的 $\\,\\pi(x)\\,$ 与 $\\,\\tilde{\\pi}(x)\\,$ 成正比。\n- 提议分布是一个带漂移的加性高斯随机游走，$\\,q(y \\mid x) = \\mathcal{N}(y; x+\\delta, \\sigma^{2})\\,$，具有固定的漂移 $\\,\\delta \\in \\mathbb{R}\\,$ 和尺度 $\\,\\sigma > 0\\,$。这里 $\\,\\mathcal{N}(y; m, s^{2})\\,$ 表示变量为 $\\,y\\,$、均值为 $\\,m\\,$、方差为 $\\,s^{2}\\,$ 的正态密度。\n\n请为这个特定的 $\\,\\tilde{\\pi}\\,$ 和 $\\,q\\,$ 提供 Hastings 接受率 $\\,r(x,y)\\,$ 的闭式表达式，仅用 $\\,x\\,$, $\\,y\\,$, $\\,\\delta\\,$ 和 $\\,\\sigma\\,$ 表示。最后，从第一性原理出发解释为什么 $\\,q\\,$ 的对称性（例如，在上述提议中 $\\,\\delta=0\\,$）会简化 MH 接受准则，并简要地将这种简化与 Gibbs 抽样的特殊情况联系起来，在 Gibbs 抽样中，提议是从全条件分布中抽取的。\n\n你的最终答案必须是 $\\,r(x,y)\\,$ 的单个闭式解析表达式。无需四舍五入，也不涉及单位。",
            "solution": "支撑 Metropolis–Hastings (MH) 算法的核心原理是细致平衡的概念，这是马尔可夫链的转移核使目标分布 $\\pi(x)$ 保持不变的一个充分条件。对于连续状态空间 $\\mathcal{X}$ 上的离散时间马尔可夫过程，其转移核密度为 $K(y \\mid x)$，关于平稳分布 $\\pi(x)$ 的细致平衡条件由下式给出：\n$$\n\\pi(x) K(y \\mid x) = \\pi(y) K(x \\mid y) \\quad \\forall x,y \\in \\mathcal{X}\n$$\n对该方程关于 $x$ 积分可以表明，如果该条件成立，$\\pi$ 确实是该链的一个平稳分布。\n\nMetropolis–Hastings 算法从两个部分构建转移核 $K(y \\mid x)$：一个由条件密度 $q(y \\mid x)$ 先验指定的提议分布，以及一个接受概率 $a(x,y)$。从状态 $x$ 到新状态 $y$ 的转移分两步进行：首先，通过从 $q(\\cdot \\mid x)$ 中抽样来提议一个候选状态 $y$；其次，以概率 $a(x,y)$ 接受这个提议的移动。对于 $x \\neq y$，从 $x$ 转移到 $y$ 的密度是提议 $y$ 的密度与接受它的概率的乘积：\n$$\nK(y \\mid x) = q(y \\mid x) a(x, y)\n$$\n将此形式代入细致平衡方程，得到：\n$$\n\\pi(x) q(y \\mid x) a(x, y) = \\pi(y) q(x \\mid y) a(y, x)\n$$\n其中 $a(y,x)$ 是接受从 $y$ 到 $x$ 的移动的概率。可以重排这个方程来分离出接受概率的比率：\n$$\n\\frac{a(x, y)}{a(y, x)} = \\frac{\\pi(y) q(x \\mid y)}{\\pi(x) q(y \\mid x)}\n$$\n我们将右侧的量定义为 Hastings 接受率，$r(x,y)$：\n$$\nr(x, y) \\equiv \\frac{\\pi(y) q(x \\mid y)}{\\pi(x) q(y \\mid x)}\n$$\n为了在满足细致平衡条件的同时最大化接受率（从而提高链的效率），我们选择由 Hastings 提议的 $a(x,y)$ 的函数形式：\n$$\na(x, y) = \\min(1, r(x, y))\n$$\n这个选择满足约束条件 $0 \\leq a(x, y) \\leq 1$ 并满足比率条件。例如，如果 $r(x,y) \\geq 1$，则 $a(x,y) = 1$。由此可知 $r(y,x) = 1/r(x,y) \\leq 1$，所以 $a(y,x) = r(y,x)$。比率为 $a(x,y)/a(y,x) = 1/r(y,x) = r(x,y)$，这是正确的。如果 $r(x,y)  1$，一个对称的论证也成立。这就完成了接受概率的一般推导。\n\n现在我们为具体的问题设定进行实例化。未归一化的目标密度是 $\\tilde{\\pi}(x) = \\exp(-\\frac{1}{4}x^4 + \\frac{1}{2}x^2)$，而提议密度是带漂移的高斯分布 $q(y \\mid x) = \\mathcal{N}(y; x+\\delta, \\sigma^2)$。Hastings 接受率 $r(x,y)$ 可以使用未归一化的密度 $\\tilde{\\pi}(x)$ 来计算，因为在 $\\pi(x) = C\\tilde{\\pi}(x)$ 中的任何归一化常数 $C$ 都会在比率 $\\pi(y)/\\pi(x)$ 中被消去。\n$$\nr(x, y) = \\frac{\\tilde{\\pi}(y)}{\\tilde{\\pi}(x)} \\frac{q(x \\mid y)}{q(y \\mid x)}\n$$\n首先，我们计算目标密度的比率：\n$$\n\\frac{\\tilde{\\pi}(y)}{\\tilde{\\pi}(x)} = \\frac{\\exp(-\\frac{1}{4}y^4 + \\frac{1}{2}y^2)}{\\exp(-\\frac{1}{4}x^4 + \\frac{1}{2}x^2)} = \\exp\\left(-\\frac{1}{4}(y^4 - x^4) + \\frac{1}{2}(y^2 - x^2)\\right)\n$$\n接下来，我们计算提议密度的比率。从 $x$到 $y$ 的提议密度是：\n$$\nq(y \\mid x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y - (x+\\delta))^2}{2\\sigma^2}\\right)\n$$\n反向的提议密度，从 $y$到 $x$，是：\n$$\nq(x \\mid y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - (y+\\delta))^2}{2\\sigma^2}\\right)\n$$\n因此，比率为：\n$$\n\\frac{q(x \\mid y)}{q(y \\mid x)} = \\frac{\\exp\\left(-\\frac{(x - y - \\delta)^2}{2\\sigma^2}\\right)}{\\exp\\left(-\\frac{(y - x - \\delta)^2}{2\\sigma^2}\\right)} = \\exp\\left(\\frac{1}{2\\sigma^2} \\left[ (y - x - \\delta)^2 - (x - y - \\delta)^2 \\right] \\right)\n$$\n让我们简化指数中的项。使用恒等式 $A^2 - B^2 = (A-B)(A+B)$：\n$$\n(y - x - \\delta)^2 - (x - y - \\delta)^2 = (-(x-y) - \\delta)^2 - (x-y-\\delta)^2 = ((x-y)+\\delta)^2 - ((x-y)-\\delta)^2\n$$\n$$\n= \\left[ ((x-y)+\\delta) - ((x-y)-\\delta) \\right] \\left[ ((x-y)+\\delta) + ((x-y)-\\delta) \\right]\n$$\n$$\n= [2\\delta] [2(x-y)] = 4\\delta(x-y)\n$$\n将此代回提议比率的指数中，得到：\n$$\n\\frac{4\\delta(x-y)}{2\\sigma^2} = \\frac{2\\delta(x-y)}{\\sigma^2}\n$$\n所以，提议密度的比率为：\n$$\n\\frac{q(x \\mid y)}{q(y \\mid x)} = \\exp\\left(\\frac{2\\delta(x-y)}{\\sigma^2}\\right)\n$$\n最后，我们将目标密度比率和提议密度比率结合起来，得到完整的 Hastings 接受率 $r(x,y)$：\n$$\nr(x, y) = \\exp\\left(-\\frac{1}{4}(y^4 - x^4) + \\frac{1}{2}(y^2 - x^2)\\right) \\exp\\left(\\frac{2\\delta(x-y)}{\\sigma^2}\\right)\n$$\n$$\nr(x, y) = \\exp\\left(-\\frac{1}{4}(y^4 - x^4) + \\frac{1}{2}(y^2 - x^2) + \\frac{2\\delta(x-y)}{\\sigma^2}\\right)\n$$\n这就是针对指定动力学的 Hastings 接受率的闭式表达式。\n\n现在，我们考虑当提议分布 $q$ 是对称的，即对于所有 $x, y$ 都有 $q(y \\mid x) = q(x \\mid y)$ 时发生的简化。在我们的具体例子中，这对应于将漂移设为 $\\delta = 0$。对于对称提议，比率 $q(x \\mid y) / q(y \\mid x)$ 恰好为 $1$。Hastings 接受率于是简化为：\n$$\nr(x,y) = \\frac{\\pi(y)}{\\pi(x)}\n$$\n接受概率变为 $a(x, y) = \\min(1, \\pi(y)/\\pi(x))$。这是原始 Metropolis 算法的接受准则，它是 Metropolis-Hastings 算法的一个特例。这种简化的意义在于，不再需要计算提议密度比率，这在计算上可能并非易事，特别是对于复杂的提议机制。\n\n最后，我们将其与 Gibbs 抽样联系起来。Gibbs 抽样是一种用于从多元分布 $\\pi(\\mathbf{x}) = \\pi(x_1, \\dots, x_d)$ 中抽样的 MCMC 方法。一次 Gibbs 更新包括将一个分量（比如 $x_i$）替换为一个从其全条件分布 $\\pi(x_i \\mid \\mathbf{x}_{-i})$ 中抽取的新值 $x_i'$，其中 $\\mathbf{x}_{-i}$ 表示除 $x_i$ 以外的所有变量。\n我们可以将此过程看作 Metropolis-Hastings 算法的一个特例。从状态 $\\mathbf{x}$ 到新状态 $\\mathbf{x}' = (x_1, \\dots, x_i', \\dots, x_d)$ 的提议是通过从分布 $q(\\mathbf{x}' \\mid \\mathbf{x}) = \\pi(x_i' \\mid \\mathbf{x}_{-i})$ 中抽样得到的。为了找到接受概率，我们计算 Hastings 接受率：\n$$\nr(\\mathbf{x}, \\mathbf{x}') = \\frac{\\pi(\\mathbf{x}')}{\\pi(\\mathbf{x})} \\frac{q(\\mathbf{x} \\mid \\mathbf{x}')}{q(\\mathbf{x}' \\mid \\mathbf{x})}\n$$\n使用条件概率的定义，$\\pi(\\mathbf{x}) = \\pi(x_i \\mid \\mathbf{x}_{-i}) \\pi(\\mathbf{x}_{-i})$。因此，目标密度的比率为：\n$$\n\\frac{\\pi(\\mathbf{x}')}{\\pi(\\mathbf{x})} = \\frac{\\pi(x_i' \\mid \\mathbf{x}_{-i}') \\pi(\\mathbf{x}_{-i}')}{\\pi(x_i \\mid \\mathbf{x}_{-i}) \\pi(\\mathbf{x}_{-i})}\n$$\n由于只有第 $i$ 个分量发生变化，$\\mathbf{x}_{-i}' = \\mathbf{x}_{-i}$，这使得比率简化为：\n$$\n\\frac{\\pi(\\mathbf{x}')}{\\pi(\\mathbf{x})} = \\frac{\\pi(x_i' \\mid \\mathbf{x}_{-i}) \\pi(\\mathbf{x}_{-i})}{\\pi(x_i \\mid \\mathbf{x}_{-i}) \\pi(\\mathbf{x}_{-i})} = \\frac{\\pi(x_i' \\mid \\mathbf{x}_{-i})}{\\pi(x_i \\mid \\mathbf{x}_{-i})}\n$$\n反向提议密度为 $q(\\mathbf{x} \\mid \\mathbf{x}') = \\pi(x_i \\mid \\mathbf{x}_{-i}')$。同样，因为 $\\mathbf{x}_{-i}' = \\mathbf{x}_{-i}$，我们有 $q(\\mathbf{x} \\mid \\mathbf{x}') = \\pi(x_i \\mid \\mathbf{x}_{-i})$。提议比率为：\n$$\n\\frac{q(\\mathbf{x} \\mid \\mathbf{x}')}{q(\\mathbf{x}' \\mid \\mathbf{x})} = \\frac{\\pi(x_i \\mid \\mathbf{x}_{-i})}{\\pi(x_i' \\mid \\mathbf{x}_{-i})}\n$$\n将这两个比率代入 $r(\\mathbf{x}, \\mathbf{x}')$ 的表达式中：\n$$\nr(\\mathbf{x}, \\mathbf{x}') = \\left(\\frac{\\pi(x_i' \\mid \\mathbf{x}_{-i})}{\\pi(x_i \\mid \\mathbf{x}_{-i})}\\right) \\left(\\frac{\\pi(x_i \\mid \\mathbf{x}_{-i})}{\\pi(x_i' \\mid \\mathbf{x}_{-i})}\\right) = 1\n$$\nHastings 接受率恒等于 $1$。因此，接受概率 $a(\\mathbf{x}, \\mathbf{x}') = \\min(1, 1) = 1$。这表明从全条件分布中抽取的提议总是被接受。因此，Gibbs 抽样是 Metropolis-Hastings 算法的一个实例，其中通过巧妙选择提议分布，使得接受概率为 $1$，从而无需显式的拒绝步骤。这是 MH 准则的终极简化。",
            "answer": "$$\n\\boxed{\\exp\\left(-\\frac{1}{4}(y^{4} - x^{4}) + \\frac{1}{2}(y^{2} - x^{2}) + \\frac{2\\delta(x-y)}{\\sigma^{2}}\\right)}\n$$"
        },
        {
            "introduction": "虽然 Metropolis-Hastings 算法具有普遍性，但某些提议分布比其他提议分布更“智能”。本练习将探讨一种“完美”提议，即直接从目标变量的真实满条件分布中进行采样。通过分析经典的二元正态分布案例，你将严格证明这种定义了吉布斯采样的选择，其 MH 接受率恒为1，从而揭示吉布斯采样是 Metropolis-Hastings 框架下一个优雅且高效的特例。",
            "id": "3336066",
            "problem": "设 $\\pi(x_{1}, x_{2})$ 是 $\\mathbb{R}^{2}$ 上的一个目标概率密度，由均值向量为 $0$、协方差矩阵为 $\\Sigma$ 的二元正态分布给出，其中\n$$\n\\Sigma \\;=\\; \\begin{pmatrix} \\sigma_{11}  \\sigma_{12} \\\\ \\sigma_{12}  \\sigma_{22} \\end{pmatrix},\n$$\n其中 $\\sigma_{11}  0$，$\\sigma_{22}  0$，且 $\\sigma_{11}\\sigma_{22} - \\sigma_{12}^{2}  0$。考虑相应的马尔可夫链蒙特卡罗过程，该过程使用全条件分布（吉布斯采样，Gibbs sampling）交替进行坐标更新。从多元正态密度的基本定义和二次型的性质出发，通过显式配方法推导出全条件分布 $\\pi(x_{1} \\mid x_{2})$ 和 $\\pi(x_{2} \\mid x_{1})$，并将其高斯均值和方差表示为 $\\sigma_{11}$、$\\sigma_{22}$、$\\sigma_{12}$、$x_{1}$ 和 $x_{2}$ 的函数。\n\n然后，在 Metropolis-Hastings (MH) 算法框架内，将单坐标 Gibbs 更新解释为一个 Metropolis-Hastings 提议，其中给定 $x_{2}$ 时对 $x_{1}$ 的提议恰好是 $\\pi(\\cdot \\mid x_{2})$，给定 $x_{1}$ 时对 $x_{2}$ 的提议也类似。仅使用 MH 接受概率和条件密度的定义，推导出该提议的精确接受概率（用 $\\pi$ 和提议密度表示），并将其简化为一个对所有状态都成立的数值。\n\n将您的答案以单行矩阵的形式报告，按此顺序包含：\n- $\\pi(x_{1} \\mid x_{2})$ 的均值，\n- $\\pi(x_{1} \\mid x_{2})$ 的方差，\n- $\\pi(x_{2} \\mid x_{1})$ 的均值，\n- $\\pi(x_{2} \\mid x_{1})$ 的方差，\n- 任一坐标更新的 MH 接受概率。\n\n无需四舍五入。最终答案必须是单个闭式解析表达式。",
            "solution": "### 全条件分布的推导\n\n均值为 $\\boldsymbol{\\mu}$、协方差矩阵为 $\\Sigma$ 的多元正态分布的概率密度函数 (PDF) 与以下指数项成正比：\n$$ \\pi(\\mathbf{x}) \\propto \\exp\\left(-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu})^\\top \\Sigma^{-1} (\\mathbf{x}-\\boldsymbol{\\mu})\\right) $$\n在本问题中，状态向量为 $\\mathbf{x} = (x_1, x_2)^\\top$，均值向量为 $\\boldsymbol{\\mu} = (0, 0)^\\top$。协方差矩阵的逆矩阵为：\n$$ \\Sigma^{-1} = \\frac{1}{\\sigma_{11}\\sigma_{22} - \\sigma_{12}^2} \\begin{pmatrix} \\sigma_{22}  -\\sigma_{12} \\\\ -\\sigma_{12}  \\sigma_{11} \\end{pmatrix} $$\n指数中的二次型 $\\mathbf{x}^\\top \\Sigma^{-1} \\mathbf{x}$ 展开为：\n$$ \\mathbf{x}^\\top \\Sigma^{-1} \\mathbf{x} = \\frac{1}{\\det(\\Sigma)} (\\sigma_{22}x_1^2 - 2\\sigma_{12}x_1x_2 + \\sigma_{11}x_2^2) $$\n因此，联合密度为：\n$$ \\pi(x_1, x_2) \\propto \\exp\\left( -\\frac{1}{2\\det(\\Sigma)} (\\sigma_{22}x_1^2 - 2\\sigma_{12}x_1x_2 + \\sigma_{11}x_2^2) \\right) $$\n为了求出全条件分布 $\\pi(x_1 \\mid x_2)$，我们使用关系 $\\pi(x_1 \\mid x_2) \\propto \\pi(x_1, x_2)$，并将所有只涉及 $x_2$ 的项视为常数。我们关注指数中与 $x_1$ 相关的项：\n$$ -\\frac{1}{2\\det(\\Sigma)} (\\sigma_{22}x_1^2 - 2\\sigma_{12}x_1x_2) $$\n通过对 $x_1$ 配方，我们得到：\n$$ \\sigma_{22}x_1^2 - 2\\sigma_{12}x_2 x_1 = \\sigma_{22}\\left(x_1^2 - 2\\frac{\\sigma_{12}}{\\sigma_{22}}x_2 x_1\\right) = \\sigma_{22}\\left(x_1 - \\frac{\\sigma_{12}}{\\sigma_{22}}x_2\\right)^2 - \\frac{\\sigma_{12}^2}{\\sigma_{22}}x_2^2 $$\n将此代回指数，与 $x_1$ 无关的项可被吸收到归一化常数中，得到：\n$$ \\pi(x_1 \\mid x_2) \\propto \\exp\\left( -\\frac{\\sigma_{22}}{2\\det(\\Sigma)} \\left(x_1 - \\frac{\\sigma_{12}}{\\sigma_{22}}x_2\\right)^2 \\right) $$\n这是一个 $x_1$ 的正态分布的核。通过与一般正态密度 $\\exp\\left(-\\frac{(z-\\mu_z)^2}{2\\sigma_z^2}\\right)$ 进行比较，我们确定其均值和方差：\n- **均值**: $E[x_1 \\mid x_2] = \\frac{\\sigma_{12}}{\\sigma_{22}}x_2$\n- **方差**: $\\text{Var}(x_1 \\mid x_2) = \\frac{\\det(\\Sigma)}{\\sigma_{22}} = \\frac{\\sigma_{11}\\sigma_{22} - \\sigma_{12}^2}{\\sigma_{22}} = \\sigma_{11} - \\frac{\\sigma_{12}^2}{\\sigma_{22}}$\n\n由于问题的对称性，我们通过交换下标 $1 \\leftrightarrow 2$ 来找到 $\\pi(x_2 \\mid x_1)$ 的参数：\n- **均值**: $E[x_2 \\mid x_1] = \\frac{\\sigma_{12}}{\\sigma_{11}}x_1$\n- **方差**: $\\text{Var}(x_2 \\mid x_1) = \\sigma_{22} - \\frac{\\sigma_{12}^2}{\\sigma_{11}}$\n\n### Metropolis-Hastings 接受概率的推导\n\nMetropolis-Hastings (MH) 算法的接受概率为：\n$$ \\alpha(x \\to x') = \\min\\left(1, \\frac{\\pi(x') q(x|x')}{\\pi(x) q(x'|x)}\\right) $$\n在我们的例子中，我们考虑对 $x_1$ 进行单坐标吉布斯更新。系统的状态从 $\\mathbf{x}=(x_1, x_2)$ 移动到一个新状态 $\\mathbf{x}'=(x_1', x_2)$。\n根据吉布斯采样的定义，提议分布 $q(\\mathbf{x}' | \\mathbf{x})$ 就是从全条件分布中抽样：\n$$ q(\\mathbf{x}' | \\mathbf{x}) = \\pi(x_1' \\mid x_2) $$\n逆向提议分布 $q(\\mathbf{x} | \\mathbf{x}')$ 遵循相同的规则：\n$$ q(\\mathbf{x} | \\mathbf{x}') = \\pi(x_1 \\mid x_2) $$\n现在我们将这些代入 MH 接受率 $R$ 的表达式中：\n$$ R = \\frac{\\pi(\\mathbf{x}') q(\\mathbf{x}|\\mathbf{x}')}{\\pi(\\mathbf{x}) q(\\mathbf{x}'|\\mathbf{x})} = \\frac{\\pi(x_1', x_2) \\pi(x_1 \\mid x_2)}{\\pi(x_1, x_2) \\pi(x_1' \\mid x_2)} $$\n使用条件概率的定义 $\\pi(A,B) = \\pi(A|B)\\pi(B)$，我们可以重写联合密度：\n$$ \\pi(x_1, x_2) = \\pi(x_1 \\mid x_2) \\pi(x_2) \\quad \\text{以及} \\quad \\pi(x_1', x_2) = \\pi(x_1' \\mid x_2) \\pi(x_2) $$\n将这些表达式代入比率 $R$ 中：\n$$ R = \\frac{\\big(\\pi(x_1' \\mid x_2) \\pi(x_2)\\big) \\cdot \\pi(x_1 \\mid x_2)}{\\big(\\pi(x_1 \\mid x_2) \\pi(x_2)\\big) \\cdot \\pi(x_1' \\mid x_2)} $$\n假设概率密度不为零，分子和分母中的所有项都相互抵消：\n$$ R = \\frac{\\pi(x_1' \\mid x_2) \\pi(x_2) \\pi(x_1 \\mid x_2)}{\\pi(x_1' \\mid x_2) \\pi(x_2) \\pi(x_1 \\mid x_2)} = 1 $$\n因此，接受概率为：\n$$ \\alpha = \\min(1, R) = \\min(1, 1) = 1 $$\n这表明，当使用全条件分布作为提议分布时（即吉布斯采样），Metropolis-Hastings 的接受概率恒为 1。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{\\sigma_{12}}{\\sigma_{22}} x_2  \\sigma_{11} - \\frac{\\sigma_{12}^{2}}{\\sigma_{22}}  \\frac{\\sigma_{12}}{\\sigma_{11}} x_1  \\sigma_{22} - \\frac{\\sigma_{12}^{2}}{\\sigma_{11}}  1\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "在实际的统计模型中，并非所有参数的满条件分布都易于直接采样。本练习将理论与实践相结合，探讨一个常见的贝叶斯逻辑回归模型。你将发现，该模型中一个参数的条件分布是标准形式（适合吉布斯步骤），而另一个则不是，这便催生了“Metropolis-within-Gibbs”混合采样策略。这种强大的技术融合了两种方法的优点，是现代计算统计学的重要基石。",
            "id": "3336126",
            "problem": "考虑一个带有观测值 $\\{(y_{i}, x_{i})\\}_{i=1}^{n}$ 的二元响应模型，其中 $y_{i} \\in \\{0,1\\}$ 且 $x_{i} \\in \\mathbb{R}^{p}$。似然由逻辑斯谛回归给出：\n- $y_{i} \\mid \\beta \\sim \\mathrm{Bernoulli}(\\sigma(x_{i}^{\\top}\\beta))$ 对于 $i=1,\\dots,n$ 独立，其中 $\\sigma(t) = \\frac{1}{1+\\exp(-t)}$。\n\n假设一个带有全局方差超参数的高斯先验：\n- $\\beta \\mid \\tau^{2} \\sim \\mathcal{N}\\!\\left(0, \\tau^{2}\\Sigma_{0}\\right)$，其中 $\\Sigma_{0} \\in \\mathbb{R}^{p \\times p}$ 是已知的正定矩阵，$\\tau^{2}  0$ 未知。\n- $\\tau^{2} \\sim \\mathrm{Inverse\\text{-}Gamma}(a_{0}, b_{0})$，其密度为 $p(\\tau^{2}) = \\dfrac{b_{0}^{a_{0}}}{\\Gamma(a_{0})} (\\tau^{2})^{-(a_{0}+1)} \\exp\\!\\left(-\\dfrac{b_{0}}{\\tau^{2}}\\right)$，对于 $a_{0}  0$ 和 $b_{0}  0$。\n\n任务：\n- 识别此模型中哪些全条件分布有闭合形式，哪些没有。\n- 设计一个 Metropolis-within-Gibbs 采样器，该采样器在 $\\tau^{2}$ 和 $\\beta$ 的更新之间交替进行。\n- 对于 $\\beta$ 的更新，假设您采用高斯随机游走提议 $\\beta^{\\star} \\sim \\mathcal{N}(\\beta, \\Sigma_{\\mathrm{prop}})$，其中 $\\Sigma_{\\mathrm{prop}} \\in \\mathbb{R}^{p \\times p}$ 是一个固定的对称正定矩阵。推导 Metropolis-Hastings 接受概率 $\\alpha(\\beta \\to \\beta^{\\star} \\mid \\tau^{2}, X, y)$ 的一个闭合形式表达式，该表达式是 $(X, y, \\beta, \\beta^{\\star}, \\tau^{2}, \\Sigma_{0})$ 的函数，其中 $X$ 是 $n \\times p$ 的设计矩阵，其行向量为 $x_{i}^{\\top}$。\n\n以接受概率的单一闭合形式解析表达式提供您的最终答案。不要对您的答案进行近似或四舍五入。",
            "solution": "### 解题推导\n\n参数 $(\\beta, \\tau^2)$ 的联合后验分布由贝叶斯定理给出：\n$$p(\\beta, \\tau^2 \\mid y, X) \\propto p(y \\mid \\beta, X) p(\\beta \\mid \\tau^2) p(\\tau^2)$$\n其中 $y = (y_1, \\dots, y_n)^\\top$，$X$ 是 $n \\times p$ 矩阵，其行向量为 $x_i^\\top$。\n\n**任务 1：全条件分布**\n\n我们分析每个参数块 $\\beta$ 和 $\\tau^2$ 的全条件分布。\n\n1.  **$\\beta$ 的全条件分布**：\n    $\\beta$ 的全条件密度与联合后验中涉及 $\\beta$ 的项成正比：\n    $$p(\\beta \\mid \\tau^2, y, X) \\propto p(y \\mid \\beta, X) p(\\beta \\mid \\tau^2)$$\n    似然项是 $p(y \\mid \\beta, X) = \\prod_{i=1}^{n} \\sigma(x_{i}^{\\top}\\beta)^{y_{i}} (1-\\sigma(x_{i}^{\\top}\\beta))^{1-y_{i}}$。先验项是 $p(\\beta \\mid \\tau^2) \\propto \\exp\\left(-\\frac{1}{2\\tau^2}\\beta^\\top\\Sigma_0^{-1}\\beta\\right)$。\n    将它们结合起来得到：\n    $$p(\\beta \\mid \\tau^2, y, X) \\propto \\left( \\prod_{i=1}^{n} \\frac{(\\exp(x_i^\\top\\beta))^{y_i}}{1+\\exp(x_i^\\top\\beta)} \\right) \\exp\\left(-\\frac{1}{2\\tau^2}\\beta^\\top\\Sigma_0^{-1}\\beta\\right)$$\n    逻辑斯谛似然项与高斯先验密度的乘积不会产生一个我们可以直接从中采样的标准、可识别的分布。因此，$\\beta$ 的全条件分布**没有闭合形式**。\n\n2.  **$\\tau^2$ 的全条件分布**：\n    $\\tau^2$ 的全条件分布与涉及 $\\tau^2$ 的项成正比：\n    $$p(\\tau^2 \\mid \\beta, y, X) \\propto p(\\beta \\mid \\tau^2) p(\\tau^2)$$\n    注意，似然 $p(y \\mid \\beta, X)$ 不是 $\\tau^2$ 的函数。\n    先验 $p(\\beta \\mid \\tau^2)$ 的密度是：\n    $$p(\\beta \\mid \\tau^2) = (2\\pi)^{-p/2} |\\tau^2\\Sigma_0|^{-1/2} \\exp\\left(-\\frac{1}{2}\\beta^\\top(\\tau^2\\Sigma_0)^{-1}\\beta\\right) \\propto (\\tau^2)^{-p/2} \\exp\\left(-\\frac{\\beta^\\top\\Sigma_0^{-1}\\beta}{2\\tau^2}\\right)$$\n    超先验 $p(\\tau^2)$ 的密度是：\n    $$p(\\tau^2) \\propto (\\tau^2)^{-(a_0+1)} \\exp\\left(-\\frac{b_0}{\\tau^2}\\right)$$\n    将这两个表达式相乘，得到 $\\tau^2$ 全条件分布的核：\n    $$p(\\tau^2 \\mid \\beta) \\propto (\\tau^2)^{-p/2} \\exp\\left(-\\frac{\\beta^\\top\\Sigma_0^{-1}\\beta}{2\\tau^2}\\right) \\cdot (\\tau^2)^{-(a_0+1)} \\exp\\left(-\\frac{b_0}{\\tau^2}\\right)$$\n    $$p(\\tau^2 \\mid \\beta) \\propto (\\tau^2)^{-(a_0+p/2+1)} \\exp\\left(-\\frac{1}{\\tau^2}\\left(b_0 + \\frac{1}{2}\\beta^\\top\\Sigma_0^{-1}\\beta\\right)\\right)$$\n    这是一个逆伽马分布的核。因此，$\\tau^2$ 的全条件分布**有闭合形式**：\n    $$\\tau^2 \\mid \\beta, y, X \\sim \\mathrm{Inverse\\text{-}Gamma}\\left(a_0 + \\frac{p}{2},\\ b_0 + \\frac{1}{2}\\beta^\\top\\Sigma_0^{-1}\\beta\\right)$$\n\n**任务 2：Metropolis-within-Gibbs 采样器设计**\n\n需要一个混合采样器，它结合了用于 $\\tau^2$ 的 Gibbs 步骤和用于 $\\beta$ 的 Metropolis-Hastings 步骤。设 $(\\beta^{(k)}, (\\tau^2)^{(k)})$ 为链在第 $k$ 次迭代时的状态。到第 $k+1$ 次迭代的更新过程如下：\n\n1.  **$\\tau^2$ 的 Gibbs 步骤**：从其全条件分布中抽样 $(\\tau^2)^{(k+1)}$，给定 $\\beta^{(k)}$ 的当前值：\n    $$(\\tau^2)^{(k+1)} \\sim \\mathrm{Inverse\\text{-}Gamma}\\left(a_0 + \\frac{p}{2}, b_0 + \\frac{1}{2}(\\beta^{(k)})^\\top\\Sigma_0^{-1}\\beta^{(k)}\\right)$$\n2.  **$\\beta$ 的 Metropolis-Hastings 步骤**：使用新抽样的 $(\\tau^2)^{(k+1)}$ 更新 $\\beta$。\n    a. **提议**：从指定的随机游走提议分布中生成一个候选值 $\\beta^\\star$：\n    $$\\beta^\\star \\sim \\mathcal{N}\\left(\\beta^{(k)}, \\Sigma_{\\mathrm{prop}}\\right)$$\n    b. **计算接受概率**：计算接受概率 $\\alpha = \\alpha(\\beta^{(k)} \\to \\beta^\\star \\mid (\\tau^2)^{(k+1)}, y, X)$。推导过程在下一节中详述。\n    c. **接受或拒绝**：生成一个随机数 $u \\sim \\mathrm{Uniform}(0,1)$。如果 $u  \\alpha$，则接受提议：$\\beta^{(k+1)} = \\beta^\\star$。否则，拒绝提议：$\\beta^{(k+1)} = \\beta^{(k)}$。\n\n**任务 3：接受概率的推导**\n\nMetropolis-Hastings 接受概率 $\\alpha(\\beta \\to \\beta^\\star)$ 由以下公式给出：\n$$\\alpha = \\min\\left(1, \\frac{p(\\beta^\\star \\mid \\tau^2, y, X)q(\\beta \\mid \\beta^\\star)}{p(\\beta \\mid \\tau^2, y, X)q(\\beta^\\star \\mid \\beta)}\\right)$$\n这里，目标分布 $p(\\cdot \\mid \\tau^2, y, X)$ 是 $\\beta$ 的全条件分布，而 $q(\\cdot \\mid \\cdot)$ 是提议分布。\n\n提议是一个高斯随机游走，$q(\\beta^\\star \\mid \\beta) = f(\\beta^\\star; \\beta, \\Sigma_{\\mathrm{prop}})$，其中 $f(\\cdot; \\mu, \\Sigma)$ 是多元正态概率密度函数 (PDF)。由于 $\\Sigma_{\\mathrm{prop}}$ 是对称的，正态密度关于其均值是对称的，这意味着 $f(\\beta^\\star; \\beta, \\Sigma_{\\mathrm{prop}}) = f(\\beta; \\beta^\\star, \\Sigma_{\\mathrm{prop}})$。因此，$q(\\beta^\\star \\mid \\beta) = q(\\beta \\mid \\beta^\\star)$，提议比率简化为 1。\n\n接受概率变成目标密度的比率：\n$$\\alpha = \\min\\left(1, \\frac{p(\\beta^\\star \\mid \\tau^2, y, X)}{p(\\beta \\mid \\tau^2, y, X)}\\right)$$\n令 $R$ 表示该比率。由于 $p(\\beta \\mid \\tau^2, y, X) \\propto p(y \\mid \\beta, X) p(\\beta \\mid \\tau^2)$，该比率为：\n$$R = \\frac{p(y \\mid \\beta^\\star, X) p(\\beta^\\star \\mid \\tau^2)}{p(y \\mid \\beta, X) p(\\beta \\mid \\tau^2)}$$\n我们分别评估似然比和先验比。\n\n-   **似然比**：\n    $$p(y \\mid \\beta, X) = \\prod_{i=1}^{n} p(y_i \\mid \\beta, x_i) = \\prod_{i=1}^{n} \\frac{\\exp(y_i x_i^\\top\\beta)}{1+\\exp(x_i^\\top\\beta)}$$\n    该比率为：\n    $$\\frac{p(y \\mid \\beta^\\star, X)}{p(y \\mid \\beta, X)} = \\prod_{i=1}^{n} \\frac{\\exp(y_i x_i^\\top\\beta^\\star) / (1+\\exp(x_i^\\top\\beta^\\star))}{\\exp(y_i x_i^\\top\\beta) / (1+\\exp(x_i^\\top\\beta))} = \\left(\\prod_{i=1}^{n} \\exp(y_i x_i^\\top(\\beta^\\star - \\beta))\\right) \\left(\\prod_{i=1}^{n} \\frac{1+\\exp(x_i^\\top\\beta)}{1+\\exp(x_i^\\top\\beta^\\star)}\\right)$$\n    第一部分可以使用矩阵表示法写为 $\\exp(\\sum_{i=1}^{n} y_i x_i^\\top(\\beta^\\star - \\beta)) = \\exp(y^\\top X(\\beta^\\star - \\beta))$。\n\n-   **先验比**：\n    $$p(\\beta \\mid \\tau^2) \\propto \\exp\\left(-\\frac{1}{2\\tau^2}\\beta^\\top\\Sigma_0^{-1}\\beta\\right)$$\n    该比率为：\n    $$\\frac{p(\\beta^\\star \\mid \\tau^2)}{p(\\beta \\mid \\tau^2)} = \\frac{\\exp\\left(-\\frac{1}{2\\tau^2}(\\beta^\\star)^\\top\\Sigma_0^{-1}\\beta^\\star\\right)}{\\exp\\left(-\\frac{1}{2\\tau^2}\\beta^\\top\\Sigma_0^{-1}\\beta\\right)} = \\exp\\left(-\\frac{1}{2\\tau^2}\\left((\\beta^\\star)^\\top\\Sigma_0^{-1}\\beta^\\star - \\beta^\\top\\Sigma_0^{-1}\\beta\\right)\\right)$$\n    这可以重写为 $\\exp\\left(\\frac{1}{2\\tau^2}\\left(\\beta^\\top\\Sigma_0^{-1}\\beta - (\\beta^\\star)^\\top\\Sigma_0^{-1}\\beta^\\star\\right)\\right)$。\n\n-   **组合比率**：\n    将似然比和先验比相乘得到 $R$：\n    $$R = \\exp\\left(y^\\top X(\\beta^\\star - \\beta)\\right) \\left(\\prod_{i=1}^{n} \\frac{1+\\exp(x_i^\\top\\beta)}{1+\\exp(x_i^\\top\\beta^\\star)}\\right) \\exp\\left(\\frac{1}{2\\tau^2}\\left(\\beta^\\top\\Sigma_0^{-1}\\beta - (\\beta^\\star)^\\top\\Sigma_0^{-1}\\beta^\\star\\right)\\right)$$\n    合并指数项：\n    $$R = \\exp\\left(y^\\top X(\\beta^\\star - \\beta) + \\frac{1}{2\\tau^2}\\left(\\beta^\\top\\Sigma_0^{-1}\\beta - (\\beta^\\star)^\\top\\Sigma_0^{-1}\\beta^\\star\\right)\\right) \\prod_{i=1}^{n} \\frac{1+\\exp(x_i^\\top\\beta)}{1+\\exp(x_i^\\top\\beta^\\star)}$$\n接受概率为 $\\alpha = \\min\\{1, R\\}$。此表达式是给定条件 $(X, y, \\beta, \\beta^{\\star}, \\tau^{2}, \\Sigma_{0})$ 的函数，符合要求。",
            "answer": "$$\\boxed{\\min\\left\\{1, \\exp\\left(y^{\\top}X(\\beta^{\\star} - \\beta) + \\frac{1}{2\\tau^2}\\left(\\beta^{\\top}\\Sigma_{0}^{-1}\\beta - (\\beta^{\\star})^{\\top}\\Sigma_{0}^{-1}\\beta^{\\star}\\right)\\right) \\prod_{i=1}^{n}\\frac{1+\\exp(x_{i}^{\\top}\\beta)}{1+\\exp(x_{i}^{\\top}\\beta^{\\star})}\\right\\}}$$"
        }
    ]
}