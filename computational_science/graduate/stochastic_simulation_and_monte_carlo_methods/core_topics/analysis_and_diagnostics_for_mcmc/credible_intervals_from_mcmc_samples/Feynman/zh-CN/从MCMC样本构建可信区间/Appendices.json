{
    "hands_on_practices": [
        {
            "introduction": "我们从一个基本问题开始：如何从有限的MCMC样本中构建可信区间。即使样本完全独立且来自真实的后验分布，由于次序统计量的离散性，所构建区间的*期望*概率覆盖率也可能不完全等于其*名义*水平。本练习将揭示这种有限样本效应背后的数学原理，并量化名义覆盖率与期望覆盖率之间的差异。",
            "id": "3301098",
            "problem": "一个标量参数 $\\theta$ 有一个连续的后验累积分布函数 $F$，马尔可夫链蒙特卡洛 (MCMC) 采样器已从中在平稳状态下生成了 $m$ 个有效独立样本。将这些样本记为 $Y_{1},\\dots,Y_{m}$，其顺序统计量记为 $Y_{(1)} \\le \\dots \\le Y_{(m)}$。你希望使用有限样本的顺序统计量报告一个名义上 $95\\%$ 的等尾可信区间，并采用以下索引规则：对于尾部概率 $\\alpha = 0.025$，取下端点为 $Y_{(\\ell)}$，其中 $\\ell = \\lceil (m+1)\\alpha \\rceil$；取上端点为 $Y_{(u)}$，其中 $u = \\lfloor (m+1)(1-\\alpha) \\rfloor$。\n\n假设样本是从具有连续 $F$ 的真实后验分布中抽取的独立同分布样本。对于 $m=2000$，计算所报告区间内包含的期望后验概率质量，即计算 $\\mathbb{E}\\!\\left[F\\!\\left(Y_{(u)}\\right) - F\\!\\left(Y_{(\\ell)}\\right)\\right]$。将你的答案四舍五入到四位有效数字。",
            "solution": "用户希望找到由马尔可夫链蒙特卡洛 (MCMC) 样本构建的可信区间的期望后验概率质量。\n\n### 步骤 1：提取已知条件\n- 关注的参数：一个标量参数 $\\theta$。\n- 后验累积分布函数 (CDF)：$F$，是连续的。\n- MCMC 样本：$Y_1, \\dots, Y_m$ 是从 $\\theta$ 的后验分布中抽取的 $m$ 个有效独立样本。\n- 样本的顺序统计量：$Y_{(1)} \\le Y_{(2)} \\le \\dots \\le Y_{(m)}$。\n- 名义可信区间水平：$95\\%$，等尾。\n- 尾部概率：$\\alpha = 0.025$。\n- 区间端点：区间为 $[Y_{(\\ell)}, Y_{(u)}]$。\n- 下端点的索引：$\\ell = \\lceil (m+1)\\alpha \\rceil$。\n- 上端点的索引：$u = \\lfloor (m+1)(1-\\alpha) \\rfloor$。\n- 样本大小：$m=2000$。\n- 假设：样本 $Y_1, \\dots, Y_m$ 是从具有连续 CDF $F$ 的分布中抽取的独立同分布 (i.i.d.) 样本。\n- 目标：计算期望的后验概率质量 $\\mathbb{E}\\!\\left[F\\!\\left(Y_{(u)}\\right) - F\\!\\left(Y_{(\\ell)}\\right)\\right]$。\n- 要求精度：将最终答案四舍五入到四位有效数字。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题在贝叶斯统计和顺序统计量理论的框架内是良定义的。所使用的概念，如后验分布、MCMC、可信区间和顺序统计量，都是标准的。假设 MCMC 抽样是有效的独立样本是理论分析中常见的理想化情况。该问题具有科学依据、客观且自洽。它需要基于已建立的统计理论进行一个具体的、不平凡的计算。没有矛盾、歧义或事实错误。该问题是有效的。\n\n### 步骤 3：推导解答\n我们感兴趣的量是包含在随机区间 $[Y_{(\\ell)}, Y_{(u)}]$ 内的后验概率质量的期望值。该区间的后验概率质量由 $F(Y_{(u)}) - F(Y_{(\\ell)})$ 给出。我们需要计算其期望：\n$$\n\\mathbb{E}\\!\\left[F\\!\\left(Y_{(u)}\\right) - F\\!\\left(Y_{(\\ell)}\\right)\\right]\n$$\n根据期望的线性性质，这等于：\n$$\n\\mathbb{E}\\!\\left[F\\!\\left(Y_{(u)}\\right)\\right] - \\mathbb{E}\\!\\left[F\\!\\left(Y_{(\\ell)}\\right)\\right]\n$$\n问题指出，样本 $Y_1, \\dots, Y_m$ 是从一个具有连续 CDF $F$ 的分布中独立同分布抽取的。我们可以应用概率积分变换。令 $U_i = F(Y_i)$，其中 $i=1, \\dots, m$。概率论中的一个基本结果表明，如果 $Y$ 具有连续的 CDF $F$，那么随机变量 $U = F(Y)$ 服从标准均匀分布，$U \\sim \\text{Uniform}(0,1)$。\n\n因此，$U_1, \\dots, U_m$ 是从 $\\text{Uniform}(0,1)$ 分布中抽取的 $m$ 个独立同分布的随机变量。由于 CDF $F$ 是一个非递减函数，它会保持随机变量的顺序。这意味着，如果 $Y_{(j)}$ 是样本 $\\{Y_i\\}$ 的第 $j$ 个顺序统计量，那么 $F(Y_{(j)})$ 就是变换后样本 $\\{U_i\\}$ 的第 $j$ 个顺序统计量。我们将其记为 $U_{(j)} = F(Y_{(j)})$。\n\n问题现在简化为计算 $\\mathbb{E}[U_{(u)}] - \\mathbb{E}[U_{(\\ell)}]$，其中 $U_{(j)}$ 是来自大小为 $m$ 的 $\\text{Uniform}(0,1)$ 分布样本的第 $j$ 个顺序统计量。\n\n对于一个来自 $\\text{Uniform}(0,1)$ 分布的大小为 $m$ 的样本，第 $j$ 个顺序统计量 $U_{(j)}$ 已知服从贝塔分布。具体来说，$U_{(j)} \\sim \\text{Beta}(j, m-j+1)$。\n服从 $\\text{Beta}(a,b)$ 分布的随机变量 $X$ 的期望值由 $\\mathbb{E}[X] = \\frac{a}{a+b}$ 给出。\n\n将此应用于我们的顺序统计量 $U_{(j)}$，我们有 $a=j$ 和 $b=m-j+1$。其期望为：\n$$\n\\mathbb{E}[U_{(j)}] = \\frac{j}{j + (m-j+1)} = \\frac{j}{m+1}\n$$\n使用这个结果，我们可以计算我们特定索引 $\\ell$ 和 $u$ 的期望值：\n$$\n\\mathbb{E}[F(Y_{(\\ell)})] = \\mathbb{E}[U_{(\\ell)}] = \\frac{\\ell}{m+1}\n$$\n$$\n\\mathbb{E}[F(Y_{(u)})] = \\mathbb{E}[U_{(u)}] = \\frac{u}{m+1}\n$$\n因此，期望的后验概率质量是：\n$$\n\\mathbb{E}\\!\\left[F\\!\\left(Y_{(u)}\\right) - F\\!\\left(Y_{(\\ell)}\\right)\\right] = \\frac{u}{m+1} - \\frac{\\ell}{m+1} = \\frac{u - \\ell}{m+1}\n$$\n现在，我们必须使用给定的公式和值 $m=2000$ 及 $\\alpha=0.025$ 来计算 $\\ell$ 和 $u$ 的值。\n\n首先，计算下索引 $\\ell$：\n$$\n\\ell = \\lceil (m+1)\\alpha \\rceil = \\lceil (2000+1) \\times 0.025 \\rceil = \\lceil 2001 \\times 0.025 \\rceil = \\lceil 50.025 \\rceil = 51\n$$\n接下来，计算上索引 $u$：\n$$\nu = \\lfloor (m+1)(1-\\alpha) \\rfloor = \\lfloor (2000+1)(1 - 0.025) \\rfloor = \\lfloor 2001 \\times 0.975 \\rfloor = \\lfloor 1950.975 \\rfloor = 1950\n$$\n现在，我们将这些索引代入我们计算期望概率质量的表达式中：\n$$\n\\frac{u - \\ell}{m+1} = \\frac{1950 - 51}{2001} = \\frac{1899}{2001}\n$$\n为了得到最终的数值答案，我们进行除法运算并四舍五入到四位有效数字：\n$$\n\\frac{1899}{2001} \\approx 0.949025487...\n$$\n将此值四舍五入到四位有效数字，得到 $0.9490$。\n\n这个结果表明，对于有限样本，使用此特定索引规则构建的名义 $95\\%$ 可信区间的期望覆盖率略低于 $95\\%$。这种差异是由于顺序统计量的离散性以及使用了上取整和下取整函数造成的。",
            "answer": "$$\n\\boxed{0.9490}\n$$"
        },
        {
            "introduction": "在实践中，MCMC采样器并非从其平稳分布开始，这要求我们丢弃一个初始的“预烧期”（burn-in）。选择预烧期的长度涉及一个关键的权衡：丢弃更多样本可以减少来自初始状态的偏差，但这会减少用于估计的样本量，从而增加估计的方差。这个动手编程练习将让你量化这一权衡，并为你提供一种基于最小化均方误差来选择最优预烧期比例的原则性方法。",
            "id": "3301169",
            "problem": "考虑一个一维目标分布，其密度正比于 $p(x) \\propto \\exp\\left(-\\frac{x^2}{2}\\right)$（在归一化之前是一个标准正态密度）。目标是使用由随机游走Metropolis-Hastings (MH) 算法构建的马尔可夫链中的样本，来估计单个参数 $x$ 的对称可信区间，并量化预烧期分数（burn-in fraction）的选择如何影响区间端点的偏差和方差。然后，设计并实现一个用于移除预烧期的偏差-方差最优停止规则。\n\n推导和算法应基于以下基本事实：\n- 当马尔可夫链是遍历的（ergodic）时，其遍历均值收敛于平稳分布下的期望。对于一个具有转移核 $K$ 的马尔可夫链，如果它是几何遍历的并且从任意初始分布开始，那么随着步数的增加，状态的分布会收敛到平稳分布 $\\pi$。\n- 当 $\\pi$ 在归一化常数范围内已知时，具有对称提议密度 $q(y \\mid x) = \\mathcal{N}(x, \\sigma^2)$ 的随机游走Metropolis-Hastings (MH) 算法的接受概率为 $a(x,y) = \\min\\left\\{1, \\frac{\\pi(y)}{\\pi(x)}\\right\\}$。\n- 对于一个固定的可信度水平 $1-\\alpha$（其中 $0 < \\alpha < 1$），对称可信区间由下分位数 $q_{\\ell} = F^{-1}\\left(\\frac{\\alpha}{2}\\right)$ 和上分位数 $q_{u} = F^{-1}\\left(1 - \\frac{\\alpha}{2}\\right)$ 定义，其中 $F$ 是后验分布（此处为目标分布）的累积分布函数。对于标准正态目标分布，$q_{\\ell}$ 和 $q_{u}$ 可以解析地得到。\n- 估计量 $\\hat{\\theta}$ 的均方误差 (mean squared error) 分解为 $\\mathrm{MSE}(\\hat{\\theta}) = \\left(\\mathrm{Bias}(\\hat{\\theta})\\right)^2 + \\mathrm{Var}(\\hat{\\theta})$，其中 $\\mathrm{Bias}(\\hat{\\theta}) = \\mathbb{E}[\\hat{\\theta}] - \\theta$ 且 $\\mathrm{Var}(\\hat{\\theta}) = \\mathbb{E}\\left[(\\hat{\\theta} - \\mathbb{E}[\\hat{\\theta}])^2\\right]$。\n\n定义和要求：\n- 马尔可夫链蒙特卡洛 (MCMC) 指的是一种抽样方法，它构建一个马尔可夫链，其平稳分布是目标分布，从而可以从链的实现中估计期望和分布量。\n- 预烧期分数 $f \\in [0,1)$ 指定在计算估计量之前，丢弃长度为 $N$ 的链的前 $b = \\lfloor f N \\rfloor$ 个样本。\n- 可信区间端点通过从预烧期后的样本计算的经验分位数来估计：对于可信度水平 $1-\\alpha$，其中 $\\alpha$ 表示为小数，下端点估计值 $\\hat{q}_{\\ell}$ 是 $\\frac{\\alpha}{2}$ 处的经验分位数，上端点估计值 $\\hat{q}_{u}$ 是 $1 - \\frac{\\alpha}{2}$ 处的经验分位数。\n- 为了量化在给定预烧期分数 $f$ 下区间端点的偏差和方差，使用 $R$ 个独立同分布的 MCMC 重复实验（每个都有独立的随机种子）来计算 $\\{\\hat{q}_{\\ell}^{(r)}(f), \\hat{q}_{u}^{(r)}(f)\\}_{r=1}^R$。令真实端点为 $q_{\\ell}$ 和 $q_{u}$。将每个端点的经验偏差和经验方差定义为：\n$$\n\\mathrm{Bias}_{\\ell}(f) = \\left(\\frac{1}{R}\\sum_{r=1}^R \\hat{q}_{\\ell}^{(r)}(f)\\right) - q_{\\ell}, \\quad\n\\mathrm{Var}_{\\ell}(f) = \\frac{1}{R}\\sum_{r=1}^R \\left(\\hat{q}_{\\ell}^{(r)}(f) - \\frac{1}{R}\\sum_{s=1}^R \\hat{q}_{\\ell}^{(s)}(f)\\right)^2,\n$$\n对于上端点也类似，\n$$\n\\mathrm{Bias}_{u}(f) = \\left(\\frac{1}{R}\\sum_{r=1}^R \\hat{q}_{u}^{(r)}(f)\\right) - q_{u}, \\quad\n\\mathrm{Var}_{u}(f) = \\frac{1}{R}\\sum_{r=1}^R \\left(\\hat{q}_{u}^{(r)}(f) - \\frac{1}{R}\\sum_{s=1}^R \\hat{q}_{u}^{(s)}(f)\\right)^2.\n$$\n- 提出一个用于预烧期选择的偏差-方差最优停止规则，该规则最小化两个端点的组合均方误差：\n$$\n\\mathrm{Objective}(f;\\lambda) = \\left(\\mathrm{Bias}_{\\ell}(f)\\right)^2 + \\lambda \\, \\mathrm{Var}_{\\ell}(f) + \\left(\\mathrm{Bias}_{u}(f)\\right)^2 + \\lambda \\, \\mathrm{Var}_{u}(f),\n$$\n其中 $\\lambda > 0$ 是一个权衡权重参数，表示方差相对于偏差平方的相对重要性。那么最优预烧期分数为 $f^\\star = \\arg\\min_{f \\in \\mathcal{F}} \\mathrm{Objective}(f;\\lambda)$，在候选分数集合 $\\mathcal{F}$ 上进行优化。\n\n对每次重复实验使用以下随机游走Metropolis-Hastings算法：\n- 在 $x_0$ 处初始化。\n- 对于 $t = 1, \\dots, N$，提议 $y_t \\sim \\mathcal{N}(x_{t-1}, \\sigma^2)$ 并以概率 $a(x_{t-1}, y_t) = \\min\\left(1, \\exp\\left(-\\frac{y_t^2 - x_{t-1}^2}{2}\\right)\\right)$ 接受；如果接受，则设置 $x_t = y_t$；否则 $x_t = x_{t-1}$。将 $x_t$ 记录为第 $t$ 个样本。\n\n实现上述过程，并评估三个测试案例中的最优预烧期分数。对于每个测试案例，从提供的候选集 $\\mathcal{F}$ 中计算 $f^\\star$，并在一行列表中输出三个最优分数。所有量均为无量纲；没有物理单位。\n\n测试套件：\n- 案例1（收敛慢，起始点远）：\n    - 目标：标准正态（如上）。\n    - 链长度：$N = 4000$。\n    - 提议标准差：$\\sigma = 0.05$。\n    - 初始值：$x_0 = 5.0$。\n    - 可信度水平：$1-\\alpha = 0.95$（使用 $\\alpha = 0.05$ 作为小数）。\n    - 候选预烧期分数：$\\mathcal{F} = \\{0.0, 0.1, 0.2, 0.4, 0.6\\}$。\n    - 重复实验次数：$R = 100$。\n    - 权衡权重：$\\lambda = 1.0$。\n    - 随机种子基数：$s = 12345$。\n- 案例2（边界高预烧期选项，同样的慢收敛链）：\n    - 目标：标准正态。\n    - 链长度：$N = 4000$。\n    - 提议标准差：$\\sigma = 0.05$。\n    - 初始值：$x_0 = 5.0$。\n    - 可信度水平：$1-\\alpha = 0.95$（使用 $\\alpha = 0.05$）。\n    - 候选预烧期分数：$\\mathcal{F} = \\{0.7, 0.8, 0.9\\}$。\n    - 重复实验次数：$R = 100$。\n    - 权衡权重：$\\lambda = 1.0$。\n    - 随机种子基数：$s = 54321$。\n- 案例3（混合良好链）：\n    - 目标：标准正态。\n    - 链长度：$N = 4000$。\n    - 提议标准差：$\\sigma = 1.0$。\n    - 初始值：$x_0 = 0.0$。\n    - 可信度水平：$1-\\alpha = 0.95$（使用 $\\alpha = 0.05$）。\n    - 候选预烧期分数：$\\mathcal{F} = \\{0.0, 0.25, 0.5\\}$。\n    - 重复实验次数：$R = 100$。\n    - 权衡权重：$\\lambda = 1.0$。\n    - 随机种子基数：$s = 67890$。\n\n要求的最终输出格式：\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个预烧期分数都报告为四舍五入到两位小数的小数（例如，$[0.20,0.70,0.00]$）。",
            "solution": "所提出的问题要求确定由马尔可夫链蒙特卡洛 (MCMC) 模拟生成的样本的最优预烧期分数。最优性准则被定义为最小化可信区间端点估计量的偏差平方和方差的加权和。该分析探讨了MCMC诊断中的一个基本权衡：丢弃初始样本（预烧期）以减少源于非平稳起始点的偏差，但代价是由于有效样本量减少而导致估计量的方差增加。\n\n该问题的基础在于马尔可夫链的遍历理论。对于一个以平稳分布 $\\pi(x)$ 为目标的MCMC模拟，链状态 $x_t$ 的分布随着步数 $t$ 趋于无穷大而收敛到 $\\pi(x)$。采用随机游走Metropolis-Hastings (MH) 算法来构建这样的链。给定当前状态 $x_{t-1}$，从一个对称提议分布 $q(y \\mid x_{t-1})$ 中提议一个新状态 $y$，在本例中，该分布是以当前状态为中心的正态分布 $\\mathcal{N}(x_{t-1}, \\sigma^2)$。目标分布的概率密度函数 (PDF) 正比于 $p(x) \\propto \\exp\\left(-\\frac{x^2}{2}\\right)$，这是标准正态分布 $\\mathcal{N}(0, 1)$ 的核。提议的状态 $y$ 以概率被接受：\n$$\na(x_{t-1}, y) = \\min\\left\\{1, \\frac{p(y)}{p(x_{t-1})}\\right\\} = \\min\\left\\{1, \\frac{\\exp(-y^2/2)}{\\exp(-x_{t-1}^2/2)}\\right\\} = \\min\\left\\{1, \\exp\\left(-\\frac{y^2 - x_{t-1}^2}{2}\\right)\\right\\}.\n$$\n如果提议被接受，则下一个状态为 $x_t = y$；否则为 $x_t = x_{t-1}$。\n\n目标是估计参数 $x$ 的一个对称 $1-\\alpha$ 可信区间。对于目标分布 $\\mathcal{N}(0, 1)$，该区间的真实端点是分位数 $q_{\\ell} = \\Phi^{-1}(\\alpha/2)$ 和 $q_{u} = \\Phi^{-1}(1 - \\alpha/2)$，其中 $\\Phi^{-1}$ 是标准正態分布的逆累积分布函数 (CDF)。对于指定的可信度水平 $1-\\alpha = 0.95$，我们有 $\\alpha=0.05$。因此，真实端点是 $q_{\\ell} = \\Phi^{-1}(0.025) \\approx -1.96$ 和 $q_{u} = \\Phi^{-1}(0.975) \\approx 1.96$。\n\n这些端点从MCMC样本中估计得到。生成一条总长度为 $N$ 的链。为了减轻来自初始状态 $x_0$（可能位于低概率区域）的偏差，丢棄前 $b = \\lfloor fN \\rfloor$ 个样本，其中 $f$ 是预烧期分数。端点的估计量，表示为 $\\hat{q}_{\\ell}(f)$ 和 $\\hat{q}_{u}(f)$，分别是从剩余的 $N-b$ 个样本计算得到的在水平 $\\alpha/2$ 和 $1-\\alpha/2$ 处的经验分位数。\n\n这些估计量的质量通过其偏差和方差来评估。由于这些量取决于MCMC链的具体实现，我们必须对许多独立的重复实验进行平均。我们生成 $R$ 条独立的链。对于给定的预烧期分数 $f$，我们为每个端点获得 $R$ 个估计值，即 $\\{\\hat{q}_{\\ell}^{(r)}(f)\\}_{r=1}^R$ 和 $\\{\\hat{q}_{u}^{(r)}(f)\\}_{r=1}^R$。然后按指定方式计算经验偏差和方差：\n$$\n\\mathrm{Bias}_{\\ell}(f) = \\left(\\frac{1}{R}\\sum_{r=1}^R \\hat{q}_{\\ell}^{(r)}(f)\\right) - q_{\\ell}\n$$\n$$\n\\mathrm{Var}_{\\ell}(f) = \\frac{1}{R}\\sum_{r=1}^R \\left(\\hat{q}_{\\ell}^{(r)}(f) - \\frac{1}{R}\\sum_{s=1}^R \\hat{q}_{\\ell}^{(s)}(f)\\right)^2\n$$\n对于上端点估计量 $\\hat{q}_{u}$ 也类似。\n\n选择最优预烧期分数 $f^\\star$ 以最小化一个复合目标函数，该函数代表端点估计量的总均方误差 (MSE)，其中方差项带有一个权重因子 $\\lambda$。目标函数为：\n$$\n\\mathrm{Objective}(f;\\lambda) = \\left(\\mathrm{Bias}_{\\ell}(f)\\right)^2 + \\lambda \\, \\mathrm{Var}_{\\ell}(f) + \\left(\\mathrm{Bias}_{u}(f)\\right)^2 + \\lambda \\, \\mathrm{Var}_{u}(f).\n$$\n最优分数 $f^\\star$ 是通过在候选分数 $\\mathcal{F}$ 的离散集合上搜索找到的：\n$$\nf^\\star = \\arg\\min_{f \\in \\mathcal{F}} \\mathrm{Objective}(f;\\lambda).\n$$\n增加 $f$ 通常会减少偏差项，因为更多非平穩的初始样本被移除。然而，这同时减少了用于估计的样本数量，通常会增加方差项。对于给定的 $\\lambda$，最优的 $f^\\star$ 代表了这种权衡中的最佳折衷。\n\n算法流程如下：\n1. 对于每个测试案例，定义参数：链长度 $N$，提议标准差 $\\sigma$，初始值 $x_0$，可信度水平 $\\alpha$，候选分数集 $\\mathcal{F}$，重复实验次数 $R$，权衡权重 $\\lambda$ 和随机种子基数 $s$。\n2. 使用标准正态分布的逆累积分布函数计算真实的分位数端点 $q_{\\ell}$ 和 $q_{u}$。\n3. 生成并存储 $R$ 条独立的MCMC链，每条链长度为 $N$。每条链 $r \\in \\{1, \\dots, R\\}$ 使用 $s+r-1$ 进行种子设定，以确保可复现性和独立性。\n4. 对于每个候选预烧期分数 $f \\in \\mathcal{F}$：\n    a. 确定预烧期样本的数量，$b = \\lfloor fN \\rfloor$。\n    b. 对于 $R$ 条链中的每一条，取从索引 $b$到 $N-1$ 的样本。\n    c. 从这些预烧期后的样本中，为每次重复实验 $r$ 计算经验分位数估计值 $\\hat{q}_{\\ell}^{(r)}(f)$ 和 $\\hat{q}_{u}^{(r)}(f)$。\n    d. 使用每个端点的 $R$ 个估计值集合，根据提供的公式计算经验偏差 $\\mathrm{Bias}_{\\ell}(f)$ 和 $\\mathrm{Bias}_{u}(f)$，以及经验方差 $\\mathrm{Var}_{\\ell}(f)$ 和 $\\mathrm{Var}_{u}(f)$。\n    e. 评估目标函数 $\\mathrm{Objective}(f;\\lambda)$。\n5. 找出产生目标函数最小值的那个分数 $f^\\star \\in \\mathcal{F}$。这就是该测试案例的最优预烧期分数。\n6. 对所有三个测试案例重复此过程，并报告得到的最优分数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef run_mh_chain(N, x0, sigma, rng):\n    \"\"\"\n    Generates a single MCMC chain using the Random-Walk Metropolis-Hastings algorithm.\n\n    Args:\n        N (int): The length of the chain.\n        x0 (float): The initial value.\n        sigma (float): The proposal standard deviation.\n        rng (numpy.random.Generator): The random number generator.\n\n    Returns:\n        numpy.ndarray: The generated MCMC chain of length N.\n    \"\"\"\n    chain = np.zeros(N)\n    chain[0] = x0\n    current_x = x0\n    \n    # We use log-probabilities for numerical stability\n    log_alpha_num_term_current = -0.5 * current_x**2\n\n    for t in range(1, N):\n        proposed_y = rng.normal(loc=current_x, scale=sigma)\n        \n        log_alpha_num_term_proposed = -0.5 * proposed_y**2\n        log_acceptance_ratio = log_alpha_num_term_proposed - log_alpha_num_term_current\n\n        if np.log(rng.uniform())  log_acceptance_ratio:\n            current_x = proposed_y\n            log_alpha_num_term_current = log_alpha_num_term_proposed\n        \n        chain[t] = current_x\n        \n    return chain\n\ndef find_optimal_burn_in(N, sigma, x0, alpha, F_set, R, lambd, seed_base):\n    \"\"\"\n    Finds the optimal burn-in fraction for a given set of MCMC parameters.\n\n    Args:\n        N (int): Chain length.\n        sigma (float): Proposal standard deviation.\n        x0 (float): Initial value.\n        alpha (float): Significance level for credible interval.\n        F_set (list): Candidate burn-in fractions.\n        R (int): Number of replicates.\n        lambd (float): Bias-variance trade-off weight.\n        seed_base (int): Base for random seeds.\n\n    Returns:\n        float: The optimal burn-in fraction from F_set.\n    \"\"\"\n    # True quantiles for a standard normal distribution\n    q_lower_true = norm.ppf(alpha / 2.0)\n    q_upper_true = norm.ppf(1.0 - alpha / 2.0)\n\n    # Generate all R chains first\n    all_chains = np.zeros((R, N))\n    for r in range(R):\n        rng = np.random.default_rng(seed_base + r)\n        all_chains[r, :] = run_mh_chain(N, x0, sigma, rng)\n\n    objective_values = []\n    for f in F_set:\n        b = int(np.floor(f * N))\n        \n        # Ensure there are samples left after burn-in\n        if b >= N:\n          # Assign a very large value to objective if no samples remain\n          objective_values.append(np.inf)\n          continue\n          \n        post_burn_in_samples = all_chains[:, b:]\n\n        # Compute empirical quantiles for all R replicates at once\n        q_lower_estimates = np.quantile(post_burn_in_samples, q=alpha / 2.0, axis=1)\n        q_upper_estimates = np.quantile(post_burn_in_samples, q=1.0 - alpha / 2.0, axis=1)\n\n        # Calculate empirical bias\n        mean_q_lower = np.mean(q_lower_estimates)\n        mean_q_upper = np.mean(q_upper_estimates)\n        bias_l = mean_q_lower - q_lower_true\n        bias_u = mean_q_upper - q_upper_true\n\n        # Calculate empirical variance (using population variance formula, ddof=0)\n        var_l = np.var(q_lower_estimates, ddof=0)\n        var_u = np.var(q_upper_estimates, ddof=0)\n        \n        # Calculate the objective function\n        objective = bias_l**2 + lambd * var_l + bias_u**2 + lambd * var_u\n        objective_values.append(objective)\n\n    # Find the fraction that minimizes the objective function\n    min_idx = np.argmin(objective_values)\n    f_star = F_set[min_idx]\n    \n    return f_star\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Case 1: Slow convergence, far start\n        {\n            \"N\": 4000, \"sigma\": 0.05, \"x0\": 5.0, \"alpha\": 0.05,\n            \"F_set\": [0.0, 0.1, 0.2, 0.4, 0.6], \"R\": 100, \n            \"lambd\": 1.0, \"seed_base\": 12345\n        },\n        # Case 2: Boundary high burn-in options, same slow chain\n        {\n            \"N\": 4000, \"sigma\": 0.05, \"x0\": 5.0, \"alpha\": 0.05,\n            \"F_set\": [0.7, 0.8, 0.9], \"R\": 100,\n            \"lambd\": 1.0, \"seed_base\": 54321\n        },\n        # Case 3: Well-mixed chain\n        {\n            \"N\": 4000, \"sigma\": 1.0, \"x0\": 0.0, \"alpha\": 0.05,\n            \"F_set\": [0.0, 0.25, 0.5], \"R\": 100,\n            \"lambd\": 1.0, \"seed_base\": 67890\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        f_star = find_optimal_burn_in(\n            N=case[\"N\"],\n            sigma=case[\"sigma\"],\n            x0=case[\"x0\"],\n            alpha=case[\"alpha\"],\n            F_set=case[\"F_set\"],\n            R=case[\"R\"],\n            lambd=case[\"lambd\"],\n            seed_base=case[\"seed_base\"]\n        )\n        results.append(f\"{f_star:.2f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "处理自相关的MCMC输出时，一个常见的问题是是否应该通过仅保留每$k$个样本来“稀疏化”马尔可夫链。本练习通过模拟一个自相关的马尔可夫链并比较分位数估计的精度，直接回答了这个问题。通过这个编程练习，你将凭经验验证一个重要的理论结果：在固定的计算预算下，稀疏化会丢弃信息，因此通常会降低而非提高统计精度。",
            "id": "3301155",
            "problem": "考虑一个由 $X_t = \\varphi X_{t-1} + \\sqrt{1 - \\varphi^2}\\,Z_t$ 定义的平稳高斯一阶自回归马尔可夫链，其中 $Z_t \\sim \\mathcal{N}(0,1)$ 独立同分布，且 $X_0 \\sim \\mathcal{N}(0,1)$ 独立于 $\\{Z_t\\}$。对于任意 $t \\ge 0$，该链具有平稳边缘分布 $\\mathcal{N}(0,1)$。令 $F$ 表示平稳累积分布函数，$f$ 表示相应的平稳概率密度函数。对于置信水平 $p \\in (0,1)$，将 $p$-分位数 $x_p$ 定义为 $F(x_p) = p$。对于单变量后验分布，$(1-\\alpha)$ 置信区间的端点是 $p = \\alpha/2$ 和 $p = 1 - \\alpha/2$ 处的分位数，此处取 $\\alpha = 0.05$，即 $p \\in \\{0.025, 0.975\\}$。\n\n目标是量化在固定计算预算下，从马尔可夫链蒙特卡洛（MCMC）样本中估计出的置信区间端点的蒙特卡洛标准误差，并评估抽样稀疏化（thinning）对精度的影响。使用以下基本原理：对于一个几何遍历的马尔可夫链和一个平方可积函数 $h$，马尔可夫链中心极限定理给出\n$$\n\\sqrt{n}\\left(\\frac{1}{n}\\sum_{t=1}^{n} h(X_t) - \\mathbb{E}[h(X)]\\right) \\xrightarrow{d} \\mathcal{N}\\left(0, \\sigma_h^2\\right),\n$$\n其中长期方差为 $\\sigma_h^2 = \\gamma_0 + 2\\sum_{\\ell=1}^{\\infty} \\gamma_\\ell$，且 $\\gamma_\\ell = \\mathrm{Cov}(h(X_t), h(X_{t+\\ell}))$。对于分位数，使用delta方法：当 $h_p(x) = \\mathbf{1}\\{x \\le x_p\\}$ 时，我们有 $\\mathbb{E}[h_p(X)] = p$ 且\n$$\n\\mathrm{MCSE}\\left(\\hat{x}_p\\right) \\approx \\sqrt{\\frac{\\sigma_{h_p}^2}{n\\, f(x_p)^2}},\n$$\n其中 $n$ 是保留的抽样数量，$f(x_p)$ 是在 $x_p$ 处的平稳密度。\n\n在实践中，$\\sigma_{h_p}^2$ 是未知的，必须通过谱（长期方差）估计量从抽样中估计。实现 Bartlett 谱方差估计量，截断参数为 $m = \\lfloor n^{1/3} \\rfloor$，并应用于中心化指示序列 $Y_t = h_p(X_t) - p$：\n$$\n\\widehat{\\sigma}_{h_p}^2 = \\widehat{\\gamma}_0 + 2 \\sum_{\\ell=1}^{m} w_\\ell\\, \\widehat{\\gamma}_\\ell,\n\\quad\nw_\\ell = 1 - \\frac{\\ell}{m+1},\n\\quad\n\\widehat{\\gamma}_\\ell = \\frac{1}{n}\\sum_{t=1}^{n-\\ell} Y_t Y_{t+\\ell}.\n$$\n\n定义稀疏化因子 $k \\in \\mathbb{N}$ 为在消耗相同总转移次数的情况下，仅保留马尔可夫链中每第 $k$ 个抽样；在固定的计算预算 $B$ 下，保留的样本大小为 $n = B/k$。对于稀疏化后的序列，应用相同的谱方差估计量，但此时应用于稀疏化后的指示序列，并使用其自身的截断参数 $m = \\lfloor n^{1/3} \\rfloor$。\n\n任务：\n- 对于每个指定的参数集 $(\\varphi, B, k)$，模拟 $\\mathcal{N}(0,1)$ 平稳自回归链的 $B$ 步。对每种情况，使用未稀疏化的抽样（保留所有 $B$ 个抽样，即 $k=1$）和稀疏化的抽样（保留每第 $k$ 个抽样）来计算每个置信区间端点 $p \\in \\{0.025, 0.975\\}$ 的近似蒙特卡洛标准误差。计算时使用 Bartlett 谱方差估计量，其中保留的样本大小为 $n$，截断参数为 $m = \\lfloor n^{1/3} \\rfloor$。使用平稳密度 $f(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}$ 在真实 $x_p$ 处评估 $f(x_p)$。\n- 对每个参数集，计算比率\n$$\nR_p(\\varphi, B, k) = \\frac{\\mathrm{MCSE}_{\\text{thin}}(p)}{\\mathrm{MCSE}_{\\text{all}}(p)},\n$$\n其中 $\\mathrm{MCSE}_{\\text{thin}}(p)$ 使用大小为 $n = B/k$ 的稀疏化保留样本，而 $\\mathrm{MCSE}_{\\text{all}}(p)$ 使用全部 $B$ 个抽样。\n- 通过为每个参数集返回一个布尔值来汇总证据。如果稀疏化并未提高两个端点的精度，则该值为真，否则为假。这里的“未提高精度”形式化为：对于 $p \\in \\{0.025, 0.975\\}$，均有 $R_p(\\varphi, B, k) \\ge 1 - \\epsilon$ 成立，其中容差 $\\epsilon = 0.02$ 用于解释谱方差的有限样本估计变异性。\n\n定义和约束：\n- 马尔可夫链蒙特卡洛（MCMC）指构建一个马尔可夫链，使其平稳分布等于目标后验分布；此处目标是 $\\mathcal{N}(0,1)$，链是参数为 $\\varphi$ 的自回归链。\n- 计算预算 $B$ 是执行的转移次数；除了整数步长外没有其他单位。\n- 稀疏化因子 $k$ 是一个正整数；$k=1$ 表示不进行稀疏化。\n- 置信区间端点是水平为 $p \\in \\{0.025, 0.975\\}$ 的分位数，以小数形式表示。\n\n实现程序以使用以下参数值测试套件：\n1. $(\\varphi, B, k) = (0.0, 200000, 10)$: 独立抽样，中度稀疏化。\n2. $(\\varphi, B, k) = (0.5, 200000, 10)$: 中度自相关，中度稀疏化。\n3. $(\\varphi, B, k) = (0.95, 200000, 10)$: 高度自相关，中度稀疏化。\n4. $(\\varphi, B, k) = (0.95, 200000, 50)$: 高度自相关，重度稀疏化。\n5. $(\\varphi, B, k) = (0.0, 200000, 1)$: 独立抽样，无稀疏化（基线）。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，\"[result1,result2,...]\"），其中每个条目是与上述参数集顺序对应的布尔值。",
            "solution": "该问题被评估为有效，其科学依据植根于马尔可夫链蒙特卡洛（MCMC）方法理论，问题陈述清晰，定义和参数齐全，且表述客观。因此，我们可以着手提供解答。\n\n目标是实证评估抽样稀疏化对从平稳马尔可夫链估计的置信区间端点的统计精度的影响。一个常见的误解是，抽样稀疏化通过减少自相关来提高精度。然而，在固定的计算预算下（即固定的马尔可夫链总转移次数），稀疏化会丢弃信息，这通常会导致精度下降（即蒙特卡洛标准误差，或MCSE，的增加）。\n\n此评估的方法如下：\n\n1.  **平稳过程模拟**：对于每个参数集 $(\\varphi, B, k)$，我们模拟由 $X_t = \\varphi X_{t-1} + \\sqrt{1 - \\varphi^2}\\,Z_t$ 定义的平稳高斯一阶自回归过程，总共 $B$ 步。该过程从其平稳分布 $X_0 \\sim \\mathcal{N}(0,1)$ 开始初始化，确保整个生成的序列 $\\{X_t\\}_{t=1}^B$ 都来自平稳分布 $\\mathcal{N}(0,1)$。\n\n2.  **样本生成**：从模拟序列中派生出两个样本：\n    *   一个“未稀疏化”或“全部”样本，包含所有 $B$ 个抽样，样本大小为 $n_{\\text{all}} = B$。\n    *   一个“稀疏化”样本，通过从原始序列中选取每第 $k$ 个抽样来创建。其大小为 $n_{\\text{thin}} = B/k$。\n\n3.  **MCSE 估计**：分析的核心是计算分位数估计 $\\hat{x}_p$ 的 MCSE。问题提供了基于 delta 方法应用于马尔可夫链中心极限定理结果的公式：\n    $$\n    \\mathrm{MCSE}\\left(\\hat{x}_p\\right) \\approx \\sqrt{\\frac{\\sigma_{h_p}^2}{n\\, f(x_p)^2}}\n    $$\n    该公式的组成部分是：\n    *   $p \\in \\{0.025, 0.975\\}$：对应于 $95\\%$ 置信区间（$\\alpha=0.05$）的分位数水平。\n    *   $x_p$：真实分位数，$x_p = \\Phi^{-1}(p)$，其中 $\\Phi$ 是标准正态分布的累积分布函数（CDF）。\n    *   $f(x_p)$：标准正态概率密度函数（PDF）在真实分位数 $x_p$ 处的值。\n    *   $n$：样本中的抽样数量（$n_{\\text{all}}$ 或 $n_{\\text{thin}}$）。\n    *   $\\sigma_{h_p}^2$：分位数指示过程的长期方差，其中指示函数为 $h_p(x) = \\mathbf{1}\\{x \\le x_p\\}$。\n\n4.  **长期方差计算**：长期方差 $\\sigma_{h_p}^2$ 必须从马尔可夫链的输出中估计。问题指定使用 Bartlett 谱方差估计量。这涉及创建一个中心化指示序列 $Y_t = h_p(X_t) - p$，然后计算：\n    $$\n    \\widehat{\\sigma}_{h_p}^2 = \\widehat{\\gamma}_0 + 2 \\sum_{\\ell=1}^{m} w_\\ell\\, \\widehat{\\gamma}_\\ell\n    $$\n    其中滞后 $\\ell$ 的样本自协方差为 $\\widehat{\\gamma}_\\ell = \\frac{1}{n}\\sum_{t=1}^{n-\\ell} Y_t Y_{t+\\ell}$，Bartlett 权重为 $w_\\ell = 1 - \\frac{\\ell}{m+1}$，截断滞后为 $m = \\lfloor n^{1/3} \\rfloor$。此计算对每个样本（全部样本和稀疏化样本）独立执行。\n\n5.  **性能比较**：抽样稀疏化的效果通过估计的 MCSE 的比率来量化：\n    $$\n    R_p(\\varphi, B, k) = \\frac{\\mathrm{MCSE}_{\\text{thin}}(p)}{\\mathrm{MCSE}_{\\text{all}}(p)}\n    $$\n    大于 $1$ 的比率表示稀疏化增加了估计误差，从而降低了精度。对每个参数集的最终评估是一个布尔值，如果稀疏化对两个端点均未提供精度改进，则为 `True`，其定义为对于 $p=0.025$ 和 $p=0.975$，均满足 $R_p \\geq 1 - \\epsilon$，其中容差 $\\epsilon=0.02$。\n\n提供的 Python 代码实现了这整个过程。它遍历指定的测试用例，执行 AR(1) 模拟，使用 Bartlett 估计量计算完整样本和稀疏化样本的 MCSE，计算比率，并应用决策规则以生成最终的布尔结果列表。使用固定的随机种子以确保模拟结果是可复现的。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef calculate_mcse(samples, p, x_p, f_at_xp):\n    \"\"\"\n    Calculates the Monte Carlo Standard Error for a quantile estimate using the\n    Bartlett spectral variance estimator.\n    \n    Args:\n        samples (np.ndarray): The MCMC sample draws.\n        p (float): The quantile level.\n        x_p (float): The true value of the quantile.\n        f_at_xp (float): The value of the stationary PDF at the true quantile.\n        \n    Returns:\n        float: The estimated MCSE of the quantile.\n    \"\"\"\n    n = len(samples)\n    if n == 0:\n        return np.inf\n\n    # Form the centered indicator series Y_t = 1{X_t = x_p} - p\n    Y = (samples = x_p).astype(np.float64) - p\n    \n    # Define truncation lag for Bartlett estimator\n    m = int(n**(1/3))\n    \n    # Calculate sample autocovariance at lag 0 (proportional to sample variance)\n    # The problem defines gamma_hat_l with normalization by n.\n    gamma_0_hat = np.sum(Y**2) / n\n    \n    auto_cov_sum = 0.0\n    if m > 0:\n        for l in range(1, m + 1):\n            # Bartlett kernel weight\n            w_l = 1.0 - l / (m + 1.0)\n            \n            # Sample autocovariance at lag l, normalized by n\n            gamma_l_hat = np.sum(Y[:-l] * Y[l:]) / n\n            auto_cov_sum += w_l * gamma_l_hat\n            \n    # Estimate the long-run variance (spectral density at frequency 0)\n    sigma_h_sq_hat = gamma_0_hat + 2 * auto_cov_sum\n    \n    # Calculate MCSE using the formula from the delta method\n    denominator = n * f_at_xp**2\n    if denominator == 0:\n        return np.inf\n        \n    mcse = np.sqrt(sigma_h_sq_hat / denominator)\n    \n    return mcse\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation and comparison for all test cases.\n    \"\"\"\n    # Set a seed for reproducibility of the simulation.\n    np.random.seed(42)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0.0, 200000, 10),\n        (0.5, 200000, 10),\n        (0.95, 200000, 10),\n        (0.95, 200000, 50),\n        (0.0, 200000, 1),\n    ]\n\n    # Define quantile levels and tolerance for the decision rule.\n    p_levels = [0.025, 0.975]\n    epsilon = 0.02\n\n    # Pre-compute true quantiles and density values for the N(0,1) distribution.\n    x_p_values = stats.norm.ppf(p_levels)\n    f_at_x_p_values = stats.norm.pdf(x_p_values)\n\n    results = []\n    \n    for phi, B, k in test_cases:\n        # 1. Simulate the stationary AR(1) chain of length B.\n        X_all = np.zeros(B)\n        x_current = np.random.randn() # Start from stationary distribution X_0 ~ N(0,1)\n        sqrt_term = np.sqrt(1 - phi**2)\n        \n        for i in range(B):\n            Z = np.random.randn()\n            x_current = phi * x_current + sqrt_term * Z\n            X_all[i] = x_current\n            \n        # 2. Prepare the thinned sample by taking every k-th draw.\n        X_thin = X_all[::k]\n\n        # 3. Calculate MCSE for both samples and for both quantile endpoints.\n        mcse_all_list = []\n        mcse_thin_list = []\n\n        for p, x_p, f_at_xp in zip(p_levels, x_p_values, f_at_x_p_values):\n            # MCSE for the full sample (all draws)\n            mcse_all = calculate_mcse(X_all, p, x_p, f_at_xp)\n            mcse_all_list.append(mcse_all)\n            \n            # MCSE for the thinned sample\n            mcse_thin = calculate_mcse(X_thin, p, x_p, f_at_xp)\n            mcse_thin_list.append(mcse_thin)\n\n        # 4. Compute ratios of MCSEs.\n        ratios = np.array(mcse_thin_list) / np.array(mcse_all_list)\n        \n        # 5. Apply the decision rule: True if thinning does not improve precision\n        # for both endpoints, within the given tolerance.\n        decision = np.all(ratios >= 1.0 - epsilon)\n        results.append(decision.item())\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}