{
    "hands_on_practices": [
        {
            "introduction": "理论的学习需要通过具体的计算来加深理解。本练习将引导你手动计算一个简单的双粒子系统在一维标准正态目标分布下的单步 SVGD 更新，从而让你清晰地看到核函数、得分函数以及粒子间相互作用如何共同决定粒子的运动方向和速度。这个基础计算是掌握 SVGD 核心机制的关键一步。",
            "id": "3348310",
            "problem": "考虑斯坦因变分梯度下降 (Stein Variational Gradient Descent, SVGD)，该方法通过在再生核希尔伯特空间 (Reproducing Kernel Hilbert Space, RKHS) 中的速度场输运粒子分布，对 Kullback–Leibler 散度执行泛函梯度下降。在一维情况下，对于一个可微的目标密度 $p(x)$，作用于标量检验函数 $f$ 的斯坦因算子为 $T_{p} f(x) = f^{\\prime}(x) + f(x)\\,\\nabla_{x} \\ln p(x)$。设目标为标准正态密度 $p(x) = \\mathcal{N}(0,1)$，且 RKHS 由带宽参数为 $h > 0$ 的径向基函数 (Radial Basis Function, RBF) 核 $k_{h}(x,x^{\\prime}) = \\exp\\!\\big(-\\frac{(x-x^{\\prime})^{2}}{2 h^{2}}\\big)$ 导出。给定两个初始粒子，其位置为 $x_{1}^{(0)} = -1$ 和 $x_{2}^{(0)} = 2$。使用 SVGD 框架，从斯坦因算子定义和 RKHS 表示性质出发（不假设任何预先给定的闭式更新），推导单次迭代（步长为 $\\epsilon > 0$）的经验 SVGD 粒子更新，然后将更新后的粒子位置 $x_{1}^{(1)}$ 和 $x_{2}^{(1)}$ 计算为 $h$ 和 $\\epsilon$ 的显式解析函数。以精确的闭式形式（无舍入）表达你的最终结果。最终答案必须是一个包含 $x_{1}^{(1}$ 和 $x_{2}^{(1)}$（作为 $h$ 和 $\\epsilon$ 的函数）的单个行向量。",
            "solution": "用户要求推导斯坦因变分梯度下降 (SVGD) 的更新规则，并将其应用于一个特定的双粒子系统。\n\n### 第1步：问题验证\n根据指定标准对问题陈述进行验证。\n\n- **给定条件**：\n    -   方法：斯坦因变分梯度下降 (SVGD)。\n    -   斯坦因算子 (一维)：$T_{p} f(x) = f^{\\prime}(x) + f(x)\\,\\nabla_{x} \\ln p(x)$。\n    -   目标密度：$p(x) = \\mathcal{N}(0,1)$，标准正态分布。\n    -   再生核希尔伯特空间 (RKHS)：由带宽为 $h > 0$ 的径向基函数 (RBF) 核 $k_{h}(x,x^{\\prime}) = \\exp(-\\frac{(x-x^{\\prime})^{2}}{2 h^{2}})$ 导出。\n    -   初始粒子位置：$x_{1}^{(0)} = -1$ 和 $x_{2}^{(0)} = 2$。\n    -   粒子数量：$N=2$。\n    -   迭代步长：$\\epsilon > 0$。\n-   **验证**：\n    -   **科学依据：** 该问题使用了贝叶斯推断、机器学习和泛函分析（SVGD、KL散度、RKHS、Stein方法）中的标准、公认概念。它在科学上是合理的。\n    -   **适定性：** 该问题提供了计算粒子位置唯一单步更新所需的所有信息（目标密度、核函数、初始条件、步长）。\n    -   **客观性：** 该问题以精确的技术语言表述，没有主观或模糊的元素。\n    -   该问题是自洽的、一致的且可行的。\n\n-   **结论**：该问题有效。\n\n### 第2步：SVGD 更新规则的推导\n\nSVGD 的目标是通过对粒子施加一个速度场 $\\phi(x)$，将初始粒子分布 $q_0$ 输运到目标分布 $p$。粒子更新方式为 $x' = x + \\epsilon \\phi(x)$。最优速度场 $\\phi(x)$ 是在每一步中最大程度减小 Kullback–Leibler (KL) 散度 $KL(q_k || p)$ 的那个场。这对应于在 RKHS $\\mathcal{H}$ 中对 KL 散度执行泛函梯度下降。\n\nKL 散度沿 $\\phi$ 方向扰动的方向导数由下式给出：\n$$ \\nabla_{\\phi} KL(q || p) = - \\mathbb{E}_{x \\sim q}[T_p \\phi(x)] $$\n其中 $T_p$ 是斯坦因算子。为了实现最速下降，我们必须选择 $\\phi$ 来最大化 $\\mathbb{E}_{x \\sim q}[T_p \\phi(x)]$，并满足 $\\phi$ 位于 RKHS 单位球内的约束，即 $\\|\\phi\\|_{\\mathcal{H}} \\le 1$。\n\n表达式 $F[\\phi] = \\mathbb{E}_{x \\sim q}[T_p \\phi(x)]$ 是 $\\phi$ 的一个线性泛函。根据 Riesz 表示定理，对于 RKHS 上的任意此类线性泛函，存在唯一的元素 $\\psi_q \\in \\mathcal{H}$，使得对所有 $\\phi \\in \\mathcal{H}$ 都有 $F[\\phi] = \\langle \\phi, \\psi_q \\rangle_{\\mathcal{H}}$。在范数约束下最大化此内积的函数是 $\\phi = \\psi_q / \\|\\psi_q\\|_{\\mathcal{H}}$。因此，最速上升方向由 $\\psi_q$ 给出。\n\n我们可以利用核函数 $k(x, x')$ 的再生性质来找到 $\\psi_q$。对于任意函数 $f \\in \\mathcal{H}$ 和点 $y$，我们有 $f(y) = \\langle f(\\cdot), k(y, \\cdot) \\rangle_{\\mathcal{H}}$。将此应用于 $\\psi_q$：\n$$ \\psi_q(y) = \\langle \\psi_q(\\cdot), k(y, \\cdot) \\rangle_{\\mathcal{H}} $$\n由于内积是对称的，$\\langle f, g \\rangle_{\\mathcal{H}} = \\langle g, f \\rangle_{\\mathcal{H}}$，并且从 $\\psi_q$ 的定义可知，$\\langle k(y, \\cdot), \\psi_q(\\cdot) \\rangle_{\\mathcal{H}} = F[k(y, \\cdot)]$。因此：\n$$ \\psi_q(y) = F[k(y, \\cdot)] = \\mathbb{E}_{x \\sim q}[T_{p,x} k(y, x)] $$\n此处，$T_{p,x}$ 表示斯坦因算子作用于 $k(y,x)$，视其为关于第二个参数 $x$ 的函数。\n对于对称核 $k(y,x) = k(x,y)$，点 $y$ 处的最优速度场为：\n$$ \\phi^*(y) = \\psi_q(y) = \\mathbb{E}_{x \\sim q}[T_{p,x} k(x,y)] = \\mathbb{E}_{x \\sim q}[\\nabla_x k(x,y) + k(x,y) \\nabla_x \\ln p(x)] $$\n在实践中，对 $q$ 的期望通过对当前 $N$ 个粒子 $\\{x_i\\}_{i=1}^N$ 的集合进行经验平均来近似：\n$$ \\phi(y) \\approx \\frac{1}{N} \\sum_{i=1}^N [\\nabla_{x_i} k(x_i, y) + k(x_i, y) \\nabla_{x_i} \\ln p(x_i)] $$\n粒子 $x_j$ 的 SVGD 更新则为 $x_j^{(t+1)} = x_j^{(t)} + \\epsilon \\phi(x_j^{(t)})$，其中速度场在粒子的当前位置 $x_j^{(t)}$ 进行评估：\n$$ \\phi(x_j^{(t)}) = \\frac{1}{N} \\sum_{i=1}^N [\\nabla_{x_i} k(x_i^{(t)}, x_j^{(t)}) + k(x_i^{(t)}, x_j^{(t)}) \\nabla_{x_i} \\ln p(x_i^{(t)})] $$\n\n### 第3步：应用于给定问题\n\n我们将推导出的更新规则应用于问题的具体情况。\n1.  **目标分布**：$p(x) = \\mathcal{N}(0,1) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-\\frac{x^2}{2})$。其对数密度为 $\\ln p(x) = -\\frac{x^2}{2} - \\frac{1}{2}\\ln(2\\pi)$。得分函数（对数密度的梯度）为 $\\nabla_x \\ln p(x) = -x$。\n\n2.  **核函数**：RBF 核为 $k(x, x') = \\exp(-\\frac{(x-x')^2}{2h^2})$。其关于第一个参数的梯度为：\n    $$ \\nabla_x k(x, x') = \\frac{\\partial}{\\partial x} \\exp\\left(-\\frac{(x-x')^2}{2h^2}\\right) = \\exp\\left(-\\frac{(x-x')^2}{2h^2}\\right) \\cdot \\left(-\\frac{2(x-x')}{2h^2}\\right) = -k(x,x') \\frac{x-x'}{h^2} $$\n\n3.  **粒子更新方程**：设迭代 $t=0$ 时的粒子位置为 $\\{x_i^{(0)}\\}_{i=1}^N$。粒子 $x_j^{(0)}$ 的速度场为：\n    $$ \\phi(x_j^{(0)}) = \\frac{1}{N} \\sum_{i=1}^N \\left[ -k(x_i^{(0)}, x_j^{(0)}) \\frac{x_i^{(0)} - x_j^{(0)}}{h^2} + k(x_i^{(0)}, x_j^{(0)}) (-x_i^{(0)}) \\right] $$\n    $$ \\phi(x_j^{(0)}) = \\frac{1}{N} \\sum_{i=1}^N k(x_i^{(0)}, x_j^{(0)}) \\left( -\\frac{x_i^{(0)} - x_j^{(0)}}{h^2} - x_i^{(0)} \\right) $$\n\n4.  **初始条件**：我们有 $N=2$ 个粒子，位于 $x_1^{(0)} = -1$ 和 $x_2^{(0)} = 2$。\n\n5.  **计算 $x_1^{(1)}$ 的更新**：设 $j=1$。\n    $$ \\phi(x_1^{(0)}) = \\frac{1}{2} \\left[ k(x_1^{(0)}, x_1^{(0)}) \\left( -\\frac{x_1^{(0)} - x_1^{(0)}}{h^2} - x_1^{(0)} \\right) + k(x_2^{(0)}, x_1^{(0)}) \\left( -\\frac{x_2^{(0)} - x_1^{(0)}}{h^2} - x_2^{(0)} \\right) \\right] $$\n    我们计算各项：\n    -   $x_1^{(0)} = -1$, $x_2^{(0)} = 2$。\n    -   $k(x_1^{(0)}, x_1^{(0)}) = \\exp(0) = 1$。\n    -   $k(x_2^{(0)}, x_1^{(0)}) = \\exp\\left(-\\frac{(2 - (-1))^2}{2h^2}\\right) = \\exp\\left(-\\frac{9}{2h^2}\\right)$。\n    -   $i=1$ 的项：$1 \\cdot (0 - (-1)) = 1$。\n    -   $i=2$ 的项：$\\exp\\left(-\\frac{9}{2h^2}\\right) \\left( -\\frac{2 - (-1)}{h^2} - 2 \\right) = \\exp\\left(-\\frac{9}{2h^2}\\right) \\left( -\\frac{3}{h^2} - 2 \\right)$。\n    速度为：\n    $$ \\phi(x_1^{(0)}) = \\frac{1}{2} \\left[ 1 - \\left( \\frac{3}{h^2} + 2 \\right) \\exp\\left(-\\frac{9}{2h^2}\\right) \\right] $$\n    更新后的粒子位置为：\n    $$ x_1^{(1)} = x_1^{(0)} + \\epsilon \\phi(x_1^{(0)}) = -1 + \\frac{\\epsilon}{2} \\left[ 1 - \\left( 2 + \\frac{3}{h^2} \\right) \\exp\\left(-\\frac{9}{2h^2}\\right) \\right] $$\n\n6.  **计算 $x_2^{(1)}$ 的更新**：设 $j=2$。\n    $$ \\phi(x_2^{(0)}) = \\frac{1}{2} \\left[ k(x_1^{(0)}, x_2^{(0)}) \\left( -\\frac{x_1^{(0)} - x_2^{(0)}}{h^2} - x_1^{(0)} \\right) + k(x_2^{(0)}, x_2^{(0)}) \\left( -\\frac{x_2^{(0)} - x_2^{(0)}}{h^2} - x_2^{(0)} \\right) \\right] $$\n    我们计算各项：\n    -   $k(x_1^{(0)}, x_2^{(0)}) = \\exp\\left(-\\frac{(-1 - 2)^2}{2h^2}\\right) = \\exp\\left(-\\frac{9}{2h^2}\\right)$。\n    -   $k(x_2^{(0)}, x_2^{(0)}) = 1$。\n    -   $i=1$ 的项：$\\exp\\left(-\\frac{9}{2h^2}\\right) \\left( -\\frac{-1 - 2}{h^2} - (-1) \\right) = \\exp\\left(-\\frac{9}{2h^2}\\right) \\left( \\frac{3}{h^2} + 1 \\right)$。\n    -   $i=2$ 的项：$1 \\cdot (0 - 2) = -2$。\n    速度为：\n    $$ \\phi(x_2^{(0)}) = \\frac{1}{2} \\left[ \\left( \\frac{3}{h^2} + 1 \\right) \\exp\\left(-\\frac{9}{2h^2}\\right) - 2 \\right] $$\n    更新后的粒子位置为：\n    $$ x_2^{(1)} = x_2^{(0)} + \\epsilon \\phi(x_2^{(0)}) = 2 + \\frac{\\epsilon}{2} \\left[ \\left( 1 + \\frac{3}{h^2} \\right) \\exp\\left(-\\frac{9}{2h^2}\\right) - 2 \\right] $$\n    化简得：\n    $$ x_2^{(1)} = 2 - \\epsilon + \\frac{\\epsilon}{2} \\left( 1 + \\frac{3}{h^2} \\right) \\exp\\left(-\\frac{9}{2h^2}\\right) $$\n更新后的粒子位置的最终表达式为：\n$$ x_1^{(1)} = -1 + \\frac{\\epsilon}{2} \\left[ 1 - \\left( 2 + \\frac{3}{h^2} \\right) \\exp\\left(-\\frac{9}{2h^2}\\right) \\right] $$\n$$ x_2^{(1)} = 2 - \\epsilon + \\frac{\\epsilon}{2} \\left( 1 + \\frac{3}{h^2} \\right) \\exp\\left(-\\frac{9}{2h^2}\\right) $$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-1 + \\frac{\\epsilon}{2} \\left( 1 - \\left(2 + \\frac{3}{h^2}\\right) \\exp\\left(-\\frac{9}{2h^2}\\right) \\right) \\quad 2 - \\epsilon + \\frac{\\epsilon}{2} \\left( 1 + \\frac{3}{h^2} \\right) \\exp\\left(-\\frac{9}{2h^2}\\right)\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "SVGD 的一个显著优势是其固有的排斥机制，可以有效防止粒子塌陷到单一模态。本练习将从解析层面探讨这一关键特性，通过推导一个双粒子系统中的吸引力（来自目标分布）与排斥力（来自核函数）之间的平衡条件，你将定量地理解 SVGD 是如何维持粒子多样性并探索多模态分布的。",
            "id": "3348300",
            "problem": "考虑Stein变分梯度下降（SVGD），它由函数梯度流定义，该梯度流输运一组粒子以逼近目标密度 $p(x)$。对于$\\mathbb{R}^{d}$中的一个包含$n$个粒子的有限集合$\\{x_{i}\\}_{i=1}^{n}$，粒子$x_{i}$处的经验SVGD速度为\n$$\n\\phi(x_{i}) \\;=\\; \\frac{1}{n} \\sum_{j=1}^{n} \\Big( k(x_{j},x_{i}) \\,\\nabla \\ln p(x_{j}) \\;+\\; \\nabla_{x_{j}} k(x_{j},x_{i}) \\Big),\n$$\n其中$k(x,y)$是一个正定核，$\\nabla$表示相对于其参数的梯度。在SVGD中，第一项是朝向高密度区域的吸引力，第二项是使粒子散开的排斥力。设核函数为高斯径向基函数（RBF）核 $k(x,y) = \\exp\\!\\big(-\\|x-y\\|^{2}/(2 h^{2})\\big)$，其带宽为$h>0$。\n\n任务A（排斥力的缩放）：在一维（$d=1$）情况下，对于位于$x_{1}$和$x_{2}$处、粒子间距离为$d = |x_{1}-x_{2}|$的$n=2$个粒子，推导$x_{2}$对$x_{1}$速度的成对排斥贡献的大小，该大小是$d$和$h$的函数。你必须用仅包含$d$和$h$的闭合形式来表示它。\n\n任务B（模式坍缩的量化避免）：考虑一维高斯目标$p(x) = \\mathcal{N}(0,\\sigma^{2})$，其方差为$\\sigma^{2} > 0$。将$n=2$个粒子对称地放置在$x_{1}=a$和$x_{2}=-a$处，其中$a>0$。仅使用上述SVGD定义和给定的RBF核，计算$x_{1}$处SVGD速度的径向分量指向外部（即$|a|$增加）的精确条件。然后，求解唯一的临界分离距离$a_{c}(h,\\sigma)$，在该距离下$x_{1}$处的径向SVGD速度恰好为零。你的最终答案必须是$a_{c}(h,\\sigma)$的一个单一闭合形式解析表达式，不含未求值的极限或隐式定义。\n\n答案格式要求：最终答案仅提供$a_{c}(h,\\sigma)$的解析表达式。不包含单位。无需四舍五入。",
            "solution": "用户提供了一个关于Stein变分梯度下降（SVGD）性质的有效问题陈述。该问题具有科学依据，提法恰当，并包含进行严格数学推导所需的所有必要信息。我将给出完整的解答。\n\n该问题分为两个任务。我将按顺序解决它们，以得出临界分离距离$a_{c}(h, \\sigma)$的最终所需表达式。\n\n首先，让我们建立必要的数学组件。\n粒子$x_i$处的SVGD速度由下式给出：\n$$ \\phi(x_{i}) = \\frac{1}{n} \\sum_{j=1}^{n} \\left( k(x_{j},x_{i}) \\nabla \\ln p(x_{j}) + \\nabla_{x_{j}} k(x_{j},x_{i}) \\right) $$\n核函数是一维（$d=1$）高斯RBF核：\n$$ k(x,y) = \\exp\\left(-\\frac{(x-y)^2}{2h^2}\\right) $$\n核函数相对于其第一个参数$x_j$的梯度为：\n$$ \\nabla_{x_{j}} k(x_{j},x_{i}) = \\frac{\\partial}{\\partial x_j} \\exp\\left(-\\frac{(x_j-x_i)^2}{2h^2}\\right) = \\exp\\left(-\\frac{(x_j-x_i)^2}{2h^2}\\right) \\cdot \\left(-\\frac{2(x_j-x_i)}{2h^2}\\right) = -\\frac{x_j-x_i}{h^2} k(x_j,x_i) $$\n\n**任务A：排斥力的缩放**\n\n此任务要求计算粒子$x_2$对粒子$x_1$速度的成对排斥贡献的大小。粒子数为$n=2$。排斥贡献是速度更新中涉及核梯度的部分。对于速度$\\phi(x_1)$，对应于$j=2$的项包含来自$x_2$的排斥力。该贡献由$\\frac{1}{n} \\nabla_{x_2} k(x_2, x_1)$给出。\n\n使用$n=2$和上面计算的导数：\n$$ \\text{$x_2$ 对 $x_1$ 的排斥力} = \\frac{1}{2} \\nabla_{x_2} k(x_2, x_1) = \\frac{1}{2} \\left( -\\frac{x_2-x_1}{h^2} k(x_2, x_1) \\right) = \\frac{x_1-x_2}{2h^2} k(x_1, x_2) $$\n问题要求此项的大小。设$d = |x_1 - x_2|$。核函数$k(x_1, x_2)$恒为正。\n$$ k(x_1, x_2) = \\exp\\left(-\\frac{(x_1-x_2)^2}{2h^2}\\right) = \\exp\\left(-\\frac{d^2}{2h^2}\\right) $$\n因此，大小为：\n$$ \\left| \\frac{x_1-x_2}{2h^2} k(x_1, x_2) \\right| = \\frac{|x_1-x_2|}{2h^2} k(x_1, x_2) = \\frac{d}{2h^2} \\exp\\left(-\\frac{d^2}{2h^2}\\right) $$\n此表达式表示一个粒子对另一个粒子施加的排斥力的大小，它是它们分离距离$d$和核带宽$h$的函数。\n\n**任务B：模式坍缩的量化避免**\n\n此任务要求我们为特定设置找到临界分离距离$a_c(h, \\sigma)$。\n给定的设置为：\n- 维度：$d=1$。\n- 粒子数：$n=2$。\n- 粒子位置：$x_1 = a$ 和 $x_2 = -a$，其中$a > 0$。\n- 目标密度：$p(x) = \\mathcal{N}(0, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)$。\n\n我们首先计算目标对数密度的梯度：\n$$ \\ln p(x) = -\\ln(\\sqrt{2\\pi}\\sigma) - \\frac{x^2}{2\\sigma^2} $$\n$$ \\nabla \\ln p(x) = \\frac{d}{dx} \\ln p(x) = -\\frac{x}{\\sigma^2} $$\n在粒子位置处，我们有：\n$$ \\nabla \\ln p(x_1) = \\nabla \\ln p(a) = -\\frac{a}{\\sigma^2} $$\n$$ \\nabla \\ln p(x_2) = \\nabla \\ln p(-a) = -\\frac{-a}{\\sigma^2} = \\frac{a}{\\sigma^2} $$\n\n接下来，我们计算$x_1 = a$处的SVGD速度。速度表达式为：\n$$ \\phi(x_1) = \\frac{1}{2} \\left[ \\left( k(x_1, x_1) \\nabla\\ln p(x_1) + \\nabla_{x_1} k(x_1, x_1) \\right) + \\left( k(x_2, x_1) \\nabla\\ln p(x_2) + \\nabla_{x_2} k(x_2, x_1) \\right) \\right] $$\n我们计算和中的每一项：\n\n第1项（与自身的相互作用，$j=1$）：\n- $k(x_1, x_1) = k(a,a) = \\exp(0) = 1$.\n- $\\nabla\\ln p(x_1) = -a/\\sigma^2$.\n- $\\nabla_{x_1} k(x_1, x_1) = -\\frac{x_1-x_1}{h^2} k(x_1,x_1) = 0$.\n所以，方括号中的第一项是 $(1 \\cdot (-a/\\sigma^2) + 0) = -a/\\sigma^2$。\n\n第2项（与$x_2$的相互作用，$j=2$）：\n- $x_2 - x_1 = -a - a = -2a$.\n- $k(x_2, x_1) = k(-a, a) = \\exp\\left(-\\frac{(-2a)^2}{2h^2}\\right) = \\exp\\left(-\\frac{2a^2}{h^2}\\right)$.\n- $\\nabla\\ln p(x_2) = a/\\sigma^2$.\n- $\\nabla_{x_2} k(x_2, x_1) = -\\frac{x_2-x_1}{h^2} k(x_2, x_1) = -\\frac{-2a}{h^2} \\exp\\left(-\\frac{2a^2}{h^2}\\right) = \\frac{2a}{h^2} \\exp\\left(-\\frac{2a^2}{h^2}\\right)$.\n所以，方括号中的第二项是：\n$$ \\exp\\left(-\\frac{2a^2}{h^2}\\right) \\cdot \\left(\\frac{a}{\\sigma^2}\\right) + \\frac{2a}{h^2} \\exp\\left(-\\frac{2a^2}{h^2}\\right) = \\exp\\left(-\\frac{2a^2}{h^2}\\right) \\left( \\frac{a}{\\sigma^2} + \\frac{2a}{h^2} \\right) $$\n\n现在，我们组合出$\\phi(x_1)$的完整表达式：\n$$ \\phi(x_1) = \\frac{1}{2} \\left[ -\\frac{a}{\\sigma^2} + \\exp\\left(-\\frac{2a^2}{h^2}\\right) \\left( \\frac{a}{\\sigma^2} + \\frac{2a}{h^2} \\right) \\right] $$\n提出因子$a/2$：\n$$ \\phi(x_1) = \\frac{a}{2} \\left[ -\\frac{1}{\\sigma^2} + \\exp\\left(-\\frac{2a^2}{h^2}\\right) \\left( \\frac{1}{\\sigma^2} + \\frac{2}{h^2} \\right) \\right] $$\n临界分离距离$a_c$定义为速度为零（即$\\phi(x_1) = 0$）时的$a$值。由于给定$a>0$，我们需要方括号中的项为零。设$a = a_c$：\n$$ -\\frac{1}{\\sigma^2} + \\exp\\left(-\\frac{2a_c^2}{h^2}\\right) \\left( \\frac{1}{\\sigma^2} + \\frac{2}{h^2} \\right) = 0 $$\n$$ \\exp\\left(-\\frac{2a_c^2}{h^2}\\right) \\left( \\frac{1}{\\sigma^2} + \\frac{2}{h^2} \\right) = \\frac{1}{\\sigma^2} $$\n$$ \\exp\\left(-\\frac{2a_c^2}{h^2}\\right) = \\frac{1/\\sigma^2}{1/\\sigma^2 + 2/h^2} $$\n为简化右侧，我们通分：\n$$ \\frac{1/\\sigma^2}{(h^2 + 2\\sigma^2)/(\\sigma^2 h^2)} = \\frac{1}{\\sigma^2} \\cdot \\frac{\\sigma^2 h^2}{h^2 + 2\\sigma^2} = \\frac{h^2}{h^2 + 2\\sigma^2} $$\n$a_c$的方程为：\n$$ \\exp\\left(-\\frac{2a_c^2}{h^2}\\right) = \\frac{h^2}{h^2 + 2\\sigma^2} $$\n为了解出$a_c$，我们对两边取自然对数：\n$$ -\\frac{2a_c^2}{h^2} = \\ln\\left(\\frac{h^2}{h^2 + 2\\sigma^2}\\right) $$\n使用属性$\\ln(x/y) = -\\ln(y/x)$：\n$$ \\frac{2a_c^2}{h^2} = \\ln\\left(\\frac{h^2 + 2\\sigma^2}{h^2}\\right) = \\ln\\left(1 + \\frac{2\\sigma^2}{h^2}\\right) $$\n现在，我们求解$a_c^2$：\n$$ a_c^2 = \\frac{h^2}{2} \\ln\\left(1 + \\frac{2\\sigma^2}{h^2}\\right) $$\n因为$a > 0$，我们取正平方根：\n$$ a_c(h, \\sigma) = \\sqrt{\\frac{h^2}{2} \\ln\\left(1 + \\frac{2\\sigma^2}{h^2}\\right)} $$\n这可以写成：\n$$ a_c(h, \\sigma) = h \\sqrt{\\frac{1}{2} \\ln\\left(1 + \\frac{2\\sigma^2}{h^2}\\right)} $$\n这是使得$x_1=a$处SVGD速度为零的唯一临界分离距离。对于$a < a_c$，项$\\exp(-2a^2/h^2)$更大，使得速度为正（向外的排斥力占主导）。对于$a > a_c$，速度为负（朝向$x=0$处模式的吸引力占主导）。",
            "answer": "$$ \\boxed{h \\sqrt{\\frac{1}{2} \\ln\\left(1 + \\frac{2\\sigma^2}{h^2}\\right)}} $$"
        },
        {
            "introduction": "将理论和分析转化为可执行的代码是检验和巩固学习成果的最终环节。本练习要求你从头开始构建一个完整的 SVGD 程序，包括实现核心更新循环、带宽选择策略以及多种收敛准则。通过完成这个编程任务，你将全面掌握 SVGD 的实际应用，并能够将其用于解决具体的贝叶斯推断问题。",
            "id": "3348306",
            "problem": "在随机模拟和蒙特卡洛方法的框架内，构建并分析一个针对对数凹目标分布的一维 Stein 变分梯度下降 (SVGD) 程序。使用以下具有科学依据的基础：Kullback–Leibler 散度 (KL) 的定义、涉及 Langevin–Stein 算子的 Stein 恒等式，以及基于再生核希尔伯特空间 (RKHS) 的变分输运。开发一个完整的、可运行的程序，该程序能对一个具体的对数凹目标族执行 SVGD，实现显式的核选择、有原则的步长策略和明确的收敛准则，然后将这些应用于指定的测试用例套件。\n\n您的任务包括以下几个部分：\n\n1. 从 Kullback–Leibler 散度和 Stein 恒等式的定义出发，使用径向基函数 (RBF) 核，推导出一维目标密度的 SVGD 输运更新。使用以下基础，不提供简化公式：\n   - 提议分布 $q$ 和目标分布 $p$ 之间的 Kullback–Leibler 散度为 $D_{\\mathrm{KL}}(q\\Vert p) = \\int q(x)\\log\\frac{q(x)}{p(x)}\\,dx$。\n   - 得分函数为 $\\nabla_x \\log p(x)$。\n   - 关于 Langevin–Stein 算子的 Stein 恒等式指出，对于具有合适边界行为的光滑函数 $f$，有 $\\mathbb{E}_{x\\sim p}\\left[\\nabla_x \\log p(x)\\,f(x) + \\nabla_x f(x)\\right] = 0$。\n   - 对于一个光滑的正定核 $k(x,y)$ 及其关联的再生核希尔伯特空间 (RKHS)，在 RKHS 中减小 $D_{\\mathrm{KL}}(q\\Vert p)$ 的最速下降方向导出一个输运映射更新，该更新可以从粒子中进行经验近似。\n\n2. 考虑由高斯分布 $p(x) = \\mathcal{N}(\\mu,\\sigma^2)$ 给出的一维对数凹目标族，对于任意实数 $\\mu$ 和正数 $\\sigma$，该分布都是对数凹的。其得分函数为 $\\nabla_x \\log p(x) = -\\frac{x-\\mu}{\\sigma^2}$。\n\n3. 使用径向基函数核 $k(x,y) = \\exp\\!\\left(-\\frac{(x-y)^2}{2h^2}\\right)$，其带宽为 $h>0$。通过当前粒子位置的中位数启发式方法计算 $h$，并由用户指定的正因子 $\\alpha$ 进行缩放。当中位数定义不明确（例如，只有一个粒子）或数值上为零时，默认 $h=\\alpha\\cdot 1.0$。\n\n4. 实现 SVGD，其中在每个粒子位置 $x_i$ 处评估的经验输运场是所有粒子 $\\{x_j\\}$ 的平均值：\n   - 使用针对一维和上述核函数特化的 RKHS 最速下降方向，其中核梯度项是关于核的第一个参数计算的。\n   - 采用步长策略 $\\varepsilon_t = \\varepsilon_0/(1+d\\cdot t)$，其中 $\\varepsilon_0>0$ 和 $d\\ge 0$ 是指定的常数，$t$ 是迭代索引。\n\n5. 精确定义收敛准则，并在运行期间进行检查：\n   - 每次迭代的最大绝对粒子位移 $\\Delta_{\\max}$ 必须低于阈值 $\\tau_{\\mathrm{move}}$。\n   - 经验均值的绝对误差 $|\\bar{x}-\\mu|$ 必须低于阈值 $\\tau_{\\mathrm{mean}}$。\n   - 经验方差的绝对误差 $|\\widehat{\\mathrm{Var}}(x)-\\sigma^2|$ 必须低于阈值 $\\tau_{\\mathrm{var}}$。\n   - 使用相同核的核化 Stein 差异 (KSD) 必须低于阈值 $\\tau_{\\mathrm{ksd}}$。在一维情况下，对于 RBF 核，使用\n     $$\\mathrm{KSD}^2(q,p) = \\mathbb{E}_{x,y\\sim q}\\left[u_p(x,y)\\right],$$\n     其中\n     $$u_p(x,y) = s(x)\\,k(x,y)\\,s(y) + s(x)\\,\\nabla_y k(x,y) + s(y)\\,\\nabla_x k(x,y) + \\nabla_x\\nabla_y k(x,y),$$\n     $$s(x) = \\nabla_x \\log p(x),\\quad k(x,y) = \\exp\\!\\left(-\\frac{(x-y)^2}{2h^2}\\right),$$\n     $$\\nabla_x k(x,y) = \\frac{y-x}{h^2}k(x,y),\\quad \\nabla_y k(x,y) = \\frac{x-y}{h^2}k(x,y),$$\n     $$\\nabla_x\\nabla_y k(x,y) = \\left(\\frac{1}{h^2} - \\frac{(x-y)^2}{h^4}\\right)k(x,y).$$\n     通过粒子集的经验平均来近似期望。为减少计算开销，可以每 $m$ 次迭代评估一次 KSD（$m$ 已指定），并将最后评估的 KSD 值作为收敛检查的当前值。\n\n6. 为每个测试用例使用指定的方案初始化粒子，并通过固定随机种子来确保确定性。对于区间 $[a,b]$ 上的均匀初始化，从 $[a,b]$ 中独立抽取样本。对于正态初始化 $\\mathcal{N}(m,s^2)$，从该正态分布中独立抽取样本。\n\n7. 测试套件。将您的 SVGD 实现应用于以下情况。对于每种情况，运行直到收敛或达到最大迭代次数。为每种情况输出一个布尔值，指示是否在迭代限制内收敛。使用以下参数：\n   - 情况 1 (理想路径):\n     - 目标: $\\mu=1.0$, $\\sigma=1.2$。\n     - 粒子数: $n=50$。\n     - 初始化: 区间 $[-4.0,4.0]$ 上的均匀分布。\n     - 核尺度: $\\alpha=1.0$。\n     - 步长: $\\varepsilon_0=0.3$, $d=0.01$。\n     - 收敛阈值: $\\tau_{\\mathrm{move}}=1.0\\times 10^{-4}$, $\\tau_{\\mathrm{mean}}=0.05$, $\\tau_{\\mathrm{var}}=0.10$, $\\tau_{\\mathrm{ksd}}=0.02$。\n     - KSD 检查周期: $m=10$。\n     - 最大迭代次数: $800$。\n   - 情况 2 (少粒子边界):\n     - 目标: $\\mu=0.0$, $\\sigma=1.0$。\n     - 粒子数: $n=3$。\n     - 初始化: 正态分布 $\\mathcal{N}(3.0,0.5^2)$。\n     - 核尺度: $\\alpha=1.0$。\n     - 步长: $\\varepsilon_0=0.4$, $d=0.02$。\n     - 收敛阈值: $\\tau_{\\mathrm{move}}=1.0\\times 10^{-4}$, $\\tau_{\\mathrm{mean}}=0.05$, $\\tau_{\\mathrm{var}}=0.10$, $\\tau_{\\mathrm{ksd}}=0.05$。\n     - KSD 检查周期: $m=10$。\n     - 最大迭代次数: $900$。\n   - 情况 3 (小带宽压力测试):\n     - 目标: $\\mu=0.5$, $\\sigma=0.7$。\n     - 粒子数: $n=40$。\n     - 初始化: 区间 $[-10.0,10.0]$ 上的均匀分布。\n     - 核尺度: $\\alpha=0.2$。\n     - 步长: $\\varepsilon_0=0.15$, $d=0.015$。\n     - 收敛阈值: $\\tau_{\\mathrm{move}}=1.0\\times 10^{-4}$, $\\tau_{\\mathrm{mean}}=0.05$, $\\tau_{\\mathrm{var}}=0.10$, $\\tau_{\\mathrm{ksd}}=0.03$。\n     - KSD 检查周期: $m=10$。\n     - 最大迭代次数: $1000$。\n   - 情况 4 (宽目标，较大核尺度):\n     - 目标: $\\mu=-2.0$, $\\sigma=3.0$。\n     - 粒子数: $n=60$。\n     - 初始化: 正态分布 $\\mathcal{N}(0.0,5.0^2)$。\n     - 核尺度: $\\alpha=1.5$。\n     - 步长: $\\varepsilon_0=0.25$, $d=0.008$。\n     - 收敛阈值: $\\tau_{\\mathrm{move}}=1.0\\times 10^{-4}$, $\\tau_{\\mathrm{mean}}=0.05$, $\\tau_{\\mathrm{var}}=0.20$, $\\tau_{\\mathrm{ksd}}=0.04$。\n     - KSD 检查周期: $m=10$。\n     - 最大迭代次数: $1200$。\n\n8. 程序输出规范。您的程序应生成单行输出，其中包含上述四个测试用例的收敛结果，格式为方括号内以逗号分隔的布尔值列表（例如，`[True,False,True,True]`）。不应打印任何其他文本。\n\n不涉及物理单位或角度。",
            "solution": "目标是构建一个基于变分推断和 Stein 恒等式的一维 Stein 变分梯度下降 (SVGD) 方法，然后在一系列对数凹目标上实现并测试它。该程序基于以下经过充分检验的基础：Kullback–Leibler 散度 $D_{\\mathrm{KL}}(q\\Vert p)$、Stein 恒等式，以及使用再生核希尔伯特空间 (RKHS) 来定义一个函数类别，在该类别中可以推导出最速下降方向。\n\n1. 基本原理和 SVGD 原则。提议分布 $q$ 和目标分布 $p$ 之间的 Kullback–Leibler 散度为 $D_{\\mathrm{KL}}(q\\Vert p) = \\int q(x)\\log\\frac{q(x)}{p(x)}\\,dx$。关于粒子输运 $x\\mapsto x+\\varepsilon \\phi(x)$ 的 $D_{\\mathrm{KL}}(q\\Vert p)$ 最速下降是通过在无穷小前推 $\\phi$ 下取 KL 散度的一阶变分得到的。使用关于 Langevin–Stein 算子的 Stein 恒等式 $\\mathbb{E}_{x\\sim p}\\left[\\nabla_x \\log p(x)\\,f(x) + \\nabla_x f(x)\\right] = 0$，将 $\\phi$ 限制在由正定核 $k(\\cdot,\\cdot)$ 导出的 RKHS 中，并通过表示定理在该 RKHS 中获得最速下降方向。由此产生的 SVGD 更新场 $\\phi^\\star(\\cdot)$ 为（在 $q$ 下的期望）：\n   $$\\phi^\\star(y) = \\mathbb{E}_{x\\sim q}\\left[k(x,y)\\,\\nabla_x\\log p(x) + \\nabla_x k(x,y)\\right].$$\n   在实践中，使用来自 $q$ 的粒子 $\\{x_j\\}_{j=1}^n$，采用经验近似\n   $$\\phi^\\star(y) \\approx \\frac{1}{n}\\sum_{j=1}^n \\left[k(x_j,y)\\,\\nabla_x\\log p(x_j) + \\nabla_x k(x_j,y)\\right].$$\n   在第 $t$ 次迭代中，对于每个 $x_i$ 的粒子更新步长为 $\\varepsilon_t$：\n   $$x_i \\leftarrow x_i + \\varepsilon_t\\,\\phi^\\star(x_i).$$\n\n2. 针对一维高斯目标的特化。设目标为 $p(x) = \\mathcal{N}(\\mu,\\sigma^2)$，此为对数凹分布。其得分函数为\n   $$s(x) = \\nabla_x \\log p(x) = -\\frac{x-\\mu}{\\sigma^2}.$$\n\n3. 核选择与导数。使用径向基函数 (RBF) 核\n   $$k(x,y) = \\exp\\!\\left(-\\frac{(x-y)^2}{2h^2}\\right),$$\n   其带宽为 $h>0$。在一维情况下，所需的导数为\n   $$\\nabla_x k(x,y) = \\frac{y-x}{h^2}\\,k(x,y),\\qquad \\nabla_y k(x,y) = \\frac{x-y}{h^2}\\,k(x,y),$$\n   $$\\nabla_x\\nabla_y k(x,y) = \\left(\\frac{1}{h^2} - \\frac{(x-y)^2}{h^4}\\right)\\,k(x,y).$$\n   带宽 $h$ 通过当前粒子位置的中位数启发式方法计算：取成对距离平方集合的中位数（不包括对角线），然后设置 $h = \\alpha\\,\\sqrt{\\mathrm{median}}$。如果中位数未定义或数值上为零，则默认为 $h=\\alpha\\cdot 1.0$ 以保持稳定性。\n\n4. 输运场构建和步长策略。对于粒子 $\\{x_j\\}_{j=1}^n$，计算\n   $$\\phi^\\star(x_i) \\approx \\frac{1}{n}\\sum_{j=1}^n \\left[k(x_j,x_i)\\,s(x_j) + \\nabla_x k(x_j,x_i)\\right],$$\n   其向量化形式使用成对核矩阵 $k(x_j,x_i)$ 和关于第一个核参数的导数。步长策略选择为迭代次数的递减函数：\n   $$\\varepsilon_t = \\frac{\\varepsilon_0}{1 + d\\,t},$$\n   其中 $\\varepsilon_0>0$ 和 $d\\ge 0$ 已指定。此选择是一种常见的递减步长，确保稳定性的同时允许初始阶段的快速移动。\n\n5. 收敛准则。如果同时满足以下所有条件，则运行成功终止：\n   - 每次迭代的最大变化量 $\\Delta_{\\max} = \\max_i |x_i^{(t+1)} - x_i^{(t)}|$ 低于 $\\tau_{\\mathrm{move}}$。\n   - 均值误差 $|\\bar{x}-\\mu|$ 低于 $\\tau_{\\mathrm{mean}}$，其中 $\\bar{x}$ 是经验均值。\n   - 方差误差 $|\\widehat{\\mathrm{Var}}(x)-\\sigma^2|$ 低于 $\\tau_{\\mathrm{var}}$，使用除数为 $n$ 的总体方差。\n   - 使用相同核的核化 Stein 差异 (KSD) 低于 $\\tau_{\\mathrm{ksd}}$。KSD 的平方通过 V-统计量计算：\n     $$\\mathrm{KSD}^2(q,p) \\approx \\frac{1}{n^2}\\sum_{j=1}^n\\sum_{i=1}^n u_p(x_j,x_i),$$\n     其中\n     $$u_p(x,y) = s(x)\\,k(x,y)\\,s(y) + s(x)\\,\\nabla_y k(x,y) + s(y)\\,\\nabla_x k(x,y) + \\nabla_x\\nabla_y k(x,y).$$\n   为管理计算成本，每 $m$ 次迭代计算一次 KSD（$m$ 在每个案例中指定），并使用最新值进行收敛检查。如果达到最大迭代次数仍未满足所有准则，则认为运行不收敛。\n\n6. 初始化和确定性。对于 $[a,b]$ 上的均匀初始化，从 $\\mathrm{Uniform}(a,b)$ 中抽取 $n$ 个独立样本。对于正态初始化 $\\mathcal{N}(m,s^2)$，从该正态分布中抽取 $n$ 个独立样本。固定一次随机种子以确保运行的确定性。\n\n7. 测试套件和参数。四个测试用例分别探讨了不同方面：具有中等粒子数的典型情况、粒子极少的边界情况、小带宽尺度的敏感性情况以及宽目标情况。参数（目标、粒子数、初始化、核尺度 $\\alpha$、步长 $\\varepsilon_0$ 和 $d$、阈值 $\\tau_{\\mathrm{move}}$、$\\tau_{\\mathrm{mean}}$、$\\tau_{\\mathrm{var}}$、$\\tau_{\\mathrm{ksd}}$、KSD 检查周期 $m$ 和最大迭代次数）在问题陈述中已明确指定。这些值对于一维 SVGD 来说在科学上是合理的且数值上是稳定的。\n\n8. 输出规范。对于每种情况，生成一个布尔值，指示是否在迭代限制内根据所述准则收敛。将结果汇总为单行，格式为方括号内以逗号分隔的列表，例如 `[True,False,True,True]`。不允许有其他输出。\n\n算法集成：\n- 使用 $s(x) = -\\frac{x-\\mu}{\\sigma^2}$ 计算当前粒子的得分 $s(x)$。\n- 通过带缩放因子 $\\alpha$ 的中位数启发式方法计算带宽 $h$。\n- 组装核矩阵 $K$ 和用于排斥项的导数矩阵 $\\nabla_x k(x_j,x_i) = \\frac{x_i-x_j}{h^2}K_{j,i}$。\n- 通过对所有粒子求平均来计算输运场 $\\phi^\\star(x_i)$。\n- 使用递减步长策略更新粒子。\n- 监控 $\\Delta_{\\max}$、均值和方差误差以及 KSD（周期性地）以判断是否收敛。\n- 重复此过程，直到收敛或达到最大迭代次数。\n\n此设计从第一性原理直接实现 SVGD：输运场源于通过 Stein 恒等式投影到 RKHS 中的 KL 散度泛函梯度，核及其导数是显式的，收敛准则既包括矩匹配，也包括核化 Stein 差异，后者以一种针对所选核的定制方式定量地衡量与目标的接近程度。四个测试用例共同检验了典型性能、粒子稀疏效应、核带宽敏感性以及在宽目标上的行为。",
            "answer": "```python\nimport numpy as np\n\ndef median_bandwidth(x, alpha):\n    n = x.shape[0]\n    if n  2:\n        return alpha * 1.0\n    diffs = x[:, None] - x[None, :]\n    d2 = (diffs ** 2)\n    # Exclude diagonal\n    mask = ~np.eye(n, dtype=bool)\n    vals = d2[mask]\n    # Use positive entries for robustness; fallback if empty or zero median\n    pos_vals = vals[vals > 0]\n    if pos_vals.size == 0:\n        return alpha * 1.0\n    med = np.median(pos_vals)\n    if med = 0 or not np.isfinite(med):\n        return alpha * 1.0\n    h = alpha * np.sqrt(med)\n    # Ensure h is not too small\n    if h  1e-6:\n        h = alpha * 1.0\n    return h\n\ndef svgd_1d_gaussian(mu, sigma, n_particles, init_type, init_params,\n                     alpha, eps0, decay, max_iter,\n                     tol_move, tol_mean, tol_var, tol_ksd,\n                     ksd_every=10, rng=np.random.default_rng(0)):\n    # Initialize particles\n    if init_type == \"uniform\":\n        a, b = init_params\n        x = rng.uniform(low=a, high=b, size=n_particles)\n    elif init_type == \"normal\":\n        m, s = init_params\n        x = rng.normal(loc=m, scale=s, size=n_particles)\n    else:\n        raise ValueError(\"Unknown init_type\")\n\n    def score(x_arr):\n        return -(x_arr - mu) / (sigma ** 2)\n\n    def compute_ksd(x_arr):\n        n = x_arr.shape[0]\n        if n == 0:\n            return np.inf\n        h = median_bandwidth(x_arr, alpha)\n        Xj = x_arr[:, None]\n        Xi = x_arr[None, :]\n        D = Xj - Xi  # D[j,i] = x_j - x_i\n        K = np.exp(- (D ** 2) / (2.0 * (h ** 2)))\n        s = score(x_arr)\n        s_j = s[:, None]\n        s_i = s[None, :]\n        # Correct KSD formula: s(x)s(y)k + s(x)∇_y k + s(y)∇_x k + ∇_x∇_y k\n        # x is j, y is i\n        T1 = s_j * K * s_i\n        grad_k_y = (D / (h ** 2)) * K\n        grad_k_x = (-D / (h ** 2)) * K\n        T2 = s_j * grad_k_y\n        T3 = s_i * grad_k_x\n        mixed = ((1.0 / (h ** 2)) - (D ** 2) / (h ** 4)) * K\n        U = T1 + T2 + T3 + mixed\n        ksd2 = np.sum(U) / (n ** 2)\n        # Numerical guard\n        if ksd2  0:\n            ksd2 = max(ksd2, 0.0)\n        return float(np.sqrt(ksd2))\n\n    converged = False\n    last_ksd = np.inf\n    for t in range(max_iter):\n        h = median_bandwidth(x, alpha)\n        # Pairwise structures\n        Xj = x[:, None]\n        Xi = x[None, :]\n        D = Xj - Xi  # shape (n,n), D[j,i] = x_j - x_i\n        K = np.exp(- (D ** 2) / (2.0 * (h ** 2)))\n        s = score(x)\n        # ∇_xj k(x_j, x_i) wrt first argument: (x_i - x_j)/h^2 * K = -D/h^2 * K\n        grad_term = (-D / (h ** 2)) * K\n        # Transport field at each x_i: average over j\n        phi = (K.T @ s + np.sum(grad_term, axis=0)) / n_particles\n        eps_t = eps0 / (1.0 + decay * t)\n        delta = eps_t * phi\n        x_new = x + delta\n        delta_max = float(np.max(np.abs(delta)))\n        # Moment errors\n        mean_err = float(abs(np.mean(x_new) - mu))\n        var_err = float(abs(np.var(x_new) - (sigma ** 2)))\n        # Periodic KSD\n        if (t % ksd_every) == 0:\n            last_ksd = compute_ksd(x_new)\n        # Check convergence\n        if (delta_max  tol_move) and (mean_err  tol_mean) and (var_err  tol_var) and (last_ksd  tol_ksd):\n            converged = True\n            break\n        x = x_new\n\n    return converged\n\ndef solve():\n    rng = np.random.default_rng(0)\n    test_cases = [\n        {\n            \"mu\": 1.0, \"sigma\": 1.2, \"n_particles\": 50,\n            \"init_type\": \"uniform\", \"init_params\": (-4.0, 4.0),\n            \"alpha\": 1.0, \"eps0\": 0.3, \"decay\": 0.01,\n            \"max_iter\": 800, \"tol_move\": 1.0e-4,\n            \"tol_mean\": 0.05, \"tol_var\": 0.10, \"tol_ksd\": 0.02,\n            \"ksd_every\": 10\n        },\n        {\n            \"mu\": 0.0, \"sigma\": 1.0, \"n_particles\": 3,\n            \"init_type\": \"normal\", \"init_params\": (3.0, 0.5),\n            \"alpha\": 1.0, \"eps0\": 0.4, \"decay\": 0.02,\n            \"max_iter\": 900, \"tol_move\": 1.0e-4,\n            \"tol_mean\": 0.05, \"tol_var\": 0.10, \"tol_ksd\": 0.05,\n            \"ksd_every\": 10\n        },\n        {\n            \"mu\": 0.5, \"sigma\": 0.7, \"n_particles\": 40,\n            \"init_type\": \"uniform\", \"init_params\": (-10.0, 10.0),\n            \"alpha\": 0.2, \"eps0\": 0.15, \"decay\": 0.015,\n            \"max_iter\": 1000, \"tol_move\": 1.0e-4,\n            \"tol_mean\": 0.05, \"tol_var\": 0.10, \"tol_ksd\": 0.03,\n            \"ksd_every\": 10\n        },\n        {\n            \"mu\": -2.0, \"sigma\": 3.0, \"n_particles\": 60,\n            \"init_type\": \"normal\", \"init_params\": (0.0, 5.0),\n            \"alpha\": 1.5, \"eps0\": 0.25, \"decay\": 0.008,\n            \"max_iter\": 1200, \"tol_move\": 1.0e-4,\n            \"tol_mean\": 0.05, \"tol_var\": 0.20, \"tol_ksd\": 0.04,\n            \"ksd_every\": 10\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        res = svgd_1d_gaussian(\n            mu=case[\"mu\"], sigma=case[\"sigma\"], n_particles=case[\"n_particles\"],\n            init_type=case[\"init_type\"], init_params=case[\"init_params\"],\n            alpha=case[\"alpha\"], eps0=case[\"eps0\"], decay=case[\"decay\"],\n            max_iter=case[\"max_iter\"], tol_move=case[\"tol_move\"],\n            tol_mean=case[\"tol_mean\"], tol_var=case[\"tol_var\"], tol_ksd=case[\"tol_ksd\"],\n            ksd_every=case[\"ksd_every\"], rng=rng\n        )\n        results.append(res)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}