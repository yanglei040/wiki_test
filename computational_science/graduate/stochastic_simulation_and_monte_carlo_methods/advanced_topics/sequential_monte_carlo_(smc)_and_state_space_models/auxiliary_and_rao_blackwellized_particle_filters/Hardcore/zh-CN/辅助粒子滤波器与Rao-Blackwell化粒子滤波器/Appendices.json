{
    "hands_on_practices": [
        {
            "introduction": "粒子滤波的一个核心挑战是样本简并问题，即经过几次迭代后，大部分粒子的权重变得微不足道。辅助粒子滤波器 (APF) 通过“向前看”一步，利用未来观测值的信息来指导重采样过程，从而有效缓解此问题。这个练习将指导你为一个具有异方差噪声（即噪声大小依赖于状态）的模型设计并实现一个 APF 。你将通过比较其有效样本量 ($ESS$) 与朴素自举滤波器的 $ESS$，亲手验证 APF 在减少方差和提高估计效率方面的优势。",
            "id": "3290181",
            "problem": "给定一个具有异方差观测的一维状态空间模型。潜状态根据一阶自回归演化，观测是一个被依赖于状态的噪声所破坏的非线性函数。本任务的目的是推导能够预测观测噪声幅度的辅助粒子滤波器（APF）权重，然后实现这些权重并将其有效样本量（ESS）与忽略任何前瞻的朴素自助粒子滤波器进行经验性比较。您的最终程序必须计算在一小组测试集上APF与朴素滤波器的ESS之比，并以指定的单行格式打印结果。\n\n考虑以下模型\n- 状态转移：$x_t \\mid x_{t-1} \\sim \\mathcal{N}(\\varphi x_{t-1}, \\tau^2)$。\n- 观测：$y_t = g(x_t) + \\sigma(x_t)\\,\\eta_t$，其中 $\\eta_t \\sim \\mathcal{N}(0,1)$，$g(x) = x$，$ \\sigma(x) = \\sigma_0 \\left(1 + \\alpha \\lvert x \\rvert \\right)$。\n\n假设在时间 $t-1$ 时对滤波分布的先前粒子近似由具有相等权重 $w_{t-1}^i = 1/N$ 的粒子 $\\{x_{t-1}^i\\}_{i=1}^N$ 组成。您必须：\n\n1. 仅从基本定义和经过充分检验的公式出发，推导出一个有原则的辅助粒子滤波器前瞻方案，该方案能够预测时间 $t$ 时依赖于状态的观测噪声幅度 $ \\sigma(x) $。\n   - 使用带有辅助索引的序贯蒙特卡洛的重要性采样恒等式以及密度的乘法法则。\n   - 使用正态密度 $\\mathcal{N}(\\cdot;\\mu,\\sigma^2)$ 的性质。\n   - 不要使用辅助粒子滤波器的现成公式；展示推导过程，直至得到第一阶段前瞻权重和相关的第二阶段重要性校正。\n\n2. 将您的推导应用于给定的异方差观测模型，其中 $g(x) = x$ 和 $\\sigma(x) = \\sigma_0 (1 + \\alpha \\lvert x \\rvert)$。前瞻方案必须明确地优先考虑那些为 $y_t$ 预测出较小观测方差的粒子。\n\n3. 在给定单个观测 $y_t$ 的情况下，实现两个从时间 $t-1$ 到 $t$ 的单步滤波器：\n   - 一个朴素自助粒子滤波器，它仅使用 $w_{t-1}^i$ 进行重采样，通过转移核进行传播，并根据精确的异方差似然 $p(y_t \\mid x_t^i)$ 进行加权。\n   - 一个辅助粒子滤波器，它使用您推导出的第一阶段前瞻权重 $\\alpha^i$ 来重采样祖先粒子，通过转移核进行传播，并应用正确的第二阶段重要性权重。\n\n4. 对于每个测试用例，计算并返回一个单一数值：比率 $\\mathrm{ESS}_\\mathrm{APF} / \\mathrm{ESS}_\\mathrm{naive}$，其中有效样本量定义为\n$$\n\\mathrm{ESS}(\\{w^i\\}_{i=1}^N) \\equiv \\frac{1}{\\sum_{i=1}^N (\\bar{w}^i)^2},\n\\quad \\bar{w}^i \\equiv \\frac{w^i}{\\sum_{j=1}^N w^j}.\n$$\n\n为了使问题完全明确且可测试，请使用以下测试集。对于每个案例，让 $\\{x_{t-1}^i\\}$ 从自回归的平稳分布中独立抽取，即 $x_{t-1}^i \\sim \\mathcal{N}(0, \\tau^2 / (1 - \\varphi^2))$，并使用相等的先验权重 $w_{t-1}^i = 1/N$。为了可复现性，请为所有采样步骤使用提供的随机种子。\n\n- 测试用例 A（一般异方差，顺利路径）：\n  - $N = 3000$，$\\varphi = 0.9$，$\\tau = 0.5$，$\\sigma_0 = 0.2$，$\\alpha = 0.8$，$y_t = 1.0$，种子 $= 123$。\n\n- 测试用例 B（同方差边界，$\\alpha = 0$）：\n  - $N = 3000$，$\\varphi = 0.9$，$\\tau = 0.5$，$\\sigma_0 = 0.2$，$\\alpha = 0.0$，$y_t = 1.0$，种子 $= 456$。\n\n- 测试用例 C（强异方差和信息丰富的观测）：\n  - $N = 3000$，$\\varphi = 0.95$，$\\tau = 0.3$，$\\sigma_0 = 0.1$，$\\alpha = 1.5$，$y_t = 3.0$，种子 $= 789$。\n\n- 测试用例 D（较少粒子和负观测）：\n  - $N = 1000$，$\\varphi = 0.7$，$\\tau = 1.0$，$\\sigma_0 = 0.3$，$\\alpha = 1.0$，$y_t = -2.0$，种子 $= 2024$。\n\n您的程序必须实现这两种滤波器，为每个案例计算两个ESS值，并生成最终输出，该输出为单行文本，包含按A、B、C、D顺序排列的四个比率的逗号分隔列表，并用方括号括起来，例如 $[r_A,r_B,r_C,r_D]$。每个比率必须是实数。不涉及物理单位。不涉及角度。不使用百分比；请将比率报告为原始小数值。\n\n程序必须是完整且可直接运行的，不需要任何输入，并且不得访问外部文件或网络。它必须严格使用指定的执行环境。对于所提供的参数范围，计算应保持数值稳定。",
            "solution": "我们从状态空间模型的序贯蒙特卡洛基本结构开始。设 $\\{x_{t-1}^i, w_{t-1}^i\\}_{i=1}^N$ 近似滤波分布 $p(x_{t-1} \\mid y_{1:t-1})$。在时间 $t$ 的目标是近似 $p(x_t \\mid y_{1:t}) \\propto p(y_t \\mid x_t) \\int p(x_t \\mid x_{t-1}) p(x_{t-1} \\mid y_{1:t-1}) \\mathrm{d}x_{t-1}$。\n\n自助粒子滤波器根据 $w_{t-1}^i$ 抽取祖先粒子 $I$ 并传播 $x_t \\sim p(x_t \\mid x_{t-1}^I)$，其重要性权重与 $p(y_t \\mid x_t)$ 成正比。辅助粒子滤波器引入一个辅助索引，并通过扩展采样空间然后使用重要性采样来构建一个信息更丰富的提议分布。\n\n重要性采样原理指出，如果 $(I, x_t)$ 上的目标密度为 $\\pi(I, x_t)$，而我们从 $q(I, x_t)$ 中提议，则重要性权重为 $w(I, x_t) \\propto \\pi(I, x_t) / q(I, x_t)$。对于滤波更新，一个方便的目标是\n$$\n\\pi(I, x_t) \\propto w_{t-1}^I \\, p(x_t \\mid x_{t-1}^I) \\, p(y_t \\mid x_t),\n$$\n其关于 $x_t$ 的边缘分布产生了对预测分布的常规混合近似。辅助粒子滤波器构建一个混合提议分布：\n$$\nq(I, x_t) = \\alpha^I \\, q(x_t \\mid x_{t-1}^I, y_t),\n$$\n其中 $\\alpha^i$ 是第一阶段权重，用于预测祖先粒子 $i$ 对观测 $y_t$ 的相关性，而 $q(x_t \\mid x_{t-1}^i, y_t)$ 是对传播后状态的提议分布。相应的重要性权重是\n$$\nw(I, x_t) \\propto \\frac{w_{t-1}^I \\, p(x_t \\mid x_{t-1}^I) \\, p(y_t \\mid x_t)}{\\alpha^I \\, q(x_t \\mid x_{t-1}^I, y_t)}.\n$$\n\n一个有原则且计算上方便的第一阶段权重选择是使用观测似然的确定性前瞻。设 $\\mu_t^i \\equiv \\mathbb{E}[x_t \\mid x_{t-1}^i]$，对于线性高斯转移，这简化为 $\\mu_t^i = \\varphi x_{t-1}^i$。定义一个前瞻分数\n$$\nm^i \\equiv \\tilde{p}(y_t \\mid x_t \\approx \\mu_t^i),\n$$\n其中 $\\tilde{p}$ 是在预测均值处评估的观测似然的近似。然后选择\n$$\n\\alpha^i \\propto w_{t-1}^i \\, m^i, \\quad \\sum_{i=1}^N \\alpha^i = 1.\n$$\n对于此选择，并设提议分布 $q(x_t \\mid x_{t-1}^i, y_t) = p(x_t \\mid x_{t-1}^i)$ 等于转移核，重要性权重简化为\n$$\nw(I, x_t) \\propto \\frac{w_{t-1}^I \\, p(x_t \\mid x_{t-1}^I) \\, p(y_t \\mid x_t)}{\\alpha^I \\, p(x_t \\mid x_{t-1}^I)} = \\frac{w_{t-1}^I \\, p(y_t \\mid x_t)}{\\alpha^I} \\propto \\frac{p(y_t \\mid x_t)}{m^I}.\n$$\n因此，辅助粒子滤波器的步骤如下：\n- 第一阶段：计算 $\\alpha^i \\propto w_{t-1}^i m^i$ 并从 $\\{1,\\dots,N\\}$ 上概率为 $\\{\\alpha^i\\}$ 的分类分布中独立同分布地采样祖先粒子 $I^1,\\dots,I^N$。\n- 第二阶段：传播 $x_t^j \\sim p(x_t \\mid x_{t-1}^{I^j})$ 并分配重要性权重 $w_t^j \\propto p(y_t \\mid x_t^j)/m^{I^j}$，然后归一化。\n\n现在我们将此方法具体应用于给定的异方差观测模型。观测模型是\n$$\ny_t = g(x_t) + \\sigma(x_t)\\,\\eta_t,\\quad \\eta_t \\sim \\mathcal{N}(0,1),\n$$\n其中 $g(x) = x$ 和 $\\sigma(x) = \\sigma_0 (1 + \\alpha \\lvert x \\rvert)$。精确的观测似然是\n$$\np(y_t \\mid x_t) = \\mathcal{N}\\!\\left(y_t; g(x_t), \\sigma^2(x_t)\\right) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma(x_t)} \\exp\\!\\left(-\\frac{(y_t - g(x_t))^2}{2\\,\\sigma^2(x_t)}\\right).\n$$\n为了预测测量质量，我们在预测均值 $\\mu_t^i = \\varphi x_{t-1}^i$ 处评估前瞻分数\n$$\nm^i = \\mathcal{N}\\!\\left(y_t; g(\\mu_t^i), \\sigma^2(\\mu_t^i)\\right) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma(\\mu_t^i)} \\exp\\!\\left(-\\frac{(y_t - g(\\mu_t^i))^2}{2\\,\\sigma^2(\\mu_t^i)}\\right).\n$$\n因为 $\\sigma(\\mu_t^i)$ 随 $\\lvert \\mu_t^i \\rvert$ 变化，这个选择明确地优先考虑那些既能预测 $g(\\mu_t^i)$ 接近 $y_t$ 又具有较小预测观测噪声 $\\sigma(\\mu_t^i)$ 的祖先粒子，从而偏好那些被良好测量的粒子。\n\n朴素自助粒子滤波器使用重采样概率 $\\alpha_\\mathrm{naive}^i \\propto w_{t-1}^i$（此处为均匀分布），通过 $p(x_t \\mid x_{t-1}^i)$ 进行传播，并使用权重 $w_t^j \\propto p(y_t \\mid x_t^j)$。\n\n为了数值稳定性，我们使用对数。对于任何正态密度 $\\mathcal{N}(y;\\mu,\\sigma^2)$，其对数密度为\n$$\n\\log \\mathcal{N}(y;\\mu,\\sigma^2) = -\\frac{1}{2}\\left(\\frac{y - \\mu}{\\sigma}\\right)^2 - \\log \\sigma - \\frac{1}{2} \\log (2\\pi).\n$$\n我们可以计算未归一化的对数权重 $\\ell^j$，然后通过减去最大值并取指数来进行归一化，以避免下溢：\n$$\n\\bar{w}^j = \\frac{\\exp(\\ell^j - \\max_k \\ell^k)}{\\sum_{k=1}^N \\exp(\\ell^k - \\max_k \\ell^k)}.\n$$\n然后计算 $\\mathrm{ESS} = 1/\\sum_j (\\bar{w}^j)^2$。\n\n每个测试用例的算法步骤：\n- 从自回归的平稳分布中独立同分布地采样 $\\{x_{t-1}^i\\}_{i=1}^N$：$x_{t-1}^i \\sim \\mathcal{N}(0, \\tau^2/(1-\\varphi^2))$。\n- 朴素自助滤波器：\n  - 均匀地重采样祖先粒子。\n  - 传播 $x_t^j \\sim \\mathcal{N}(\\varphi x_{t-1}^{I^j}, \\tau^2)$。\n  - 使用异方差的 $\\sigma(x_t^j)$ 计算 $\\log p(y_t \\mid x_t^j)$。\n  - 归一化得到权重并计算 $\\mathrm{ESS}_\\mathrm{naive}$。\n- 辅助粒子滤波器：\n  - 计算 $\\mu_t^i = \\varphi x_{t-1}^i$ 和 $m^i = \\mathcal{N}(y_t; \\mu_t^i, \\sigma^2(\\mu_t^i))$；设置 $\\alpha^i \\propto m^i$。\n  - 从 $\\{\\alpha^i\\}$ 中重采样祖先粒子 $I^j$。\n  - 传播 $x_t^j \\sim \\mathcal{N}(\\varphi x_{t-1}^{I^j}, \\tau^2)$。\n  - 计算 $\\log p(y_t \\mid x_t^j)$ 并减去 $\\log m^{I^j}$ 得到第二阶段权重的对数；归一化得到权重并计算 $\\mathrm{ESS}_\\mathrm{APF}$。\n\n我们报告每个测试用例的比率 $\\mathrm{ESS}_\\mathrm{APF}/\\mathrm{ESS}_\\mathrm{naive}$。\n\n预期结果：\n- 在同方差边界 $\\alpha = 0$ 的情况下，APF 仍然通过 $g(\\mu_t^i)$ 使用均值前瞻，并且可能比朴素重采样表现出适度改进；然而，它不会根据 $\\sigma(x)$ 进行优先排序，因为 $\\sigma(x)$ 是常数。\n- 当 $\\alpha$ 较大或信息丰富的 $y_t$ 位于分布的尾部时，异方差性更加显著；我们预期 APF 会将更多粒子分配给 $y_t$ 附近且 $\\sigma(\\mu_t^i)$ 较小的状态，从而相对于朴素方法增加 $\\mathrm{ESS}$。\n\n最终程序为四个指定的测试用例实现这些步骤，并打印包含四个比率的单行列表格式 $[r_A,r_B,r_C,r_D]$。",
            "answer": "```python\nimport numpy as np\n\ndef normal_logpdf(y, mu, sigma):\n    # Compute log N(y; mu, sigma^2) with vectorized sigma > 0\n    return -0.5 * ((y - mu) / sigma) ** 2 - np.log(sigma) - 0.5 * np.log(2.0 * np.pi)\n\ndef hetero_sigma(x, sigma0, alpha):\n    # sigma(x) = sigma0 * (1 + alpha * |x|)\n    return sigma0 * (1.0 + alpha * np.abs(x))\n\ndef ess_from_logweights(logw):\n    # Normalize log-weights and compute ESS\n    m = np.max(logw)\n    w = np.exp(logw - m)\n    w_sum = np.sum(w)\n    if w_sum == 0.0 or not np.isfinite(w_sum):\n        # Fallback to uniform if numerical issues arise\n        n = len(logw)\n        return float(n)\n    w /= w_sum\n    return 1.0 / np.sum(w * w)\n\ndef sample_stationary_x_prev(N, phi, tau, rng):\n    var = tau**2 / (1.0 - phi**2)\n    return rng.normal(loc=0.0, scale=np.sqrt(var), size=N)\n\ndef naive_bootstrap_step(x_prev, phi, tau, sigma0, alpha, y, rng):\n    N = len(x_prev)\n    # Resample ancestors with equal weights\n    ancestors = rng.integers(low=0, high=N, size=N)  # uniform categorical\n    mu = phi * x_prev[ancestors]\n    x_t = rng.normal(loc=mu, scale=tau, size=N)\n    sig = hetero_sigma(x_t, sigma0, alpha)\n    logw = normal_logpdf(y, mu=x_t, sigma=sig)  # g(x)=x\n    return ess_from_logweights(logw)\n\ndef apf_step(x_prev, phi, tau, sigma0, alpha, y, rng):\n    N = len(x_prev)\n    # Stage-one lookahead using mu_i = phi * x_prev[i], m_i = N(y; mu_i, sigma(mu_i)^2)\n    mu_pred = phi * x_prev\n    sig_pred = hetero_sigma(mu_pred, sigma0, alpha)\n    log_m = normal_logpdf(y, mu=mu_pred, sigma=sig_pred)\n    # Convert to probabilities alpha^i\n    m_max = np.max(log_m)\n    m_weights = np.exp(log_m - m_max)\n    m_sum = np.sum(m_weights)\n    if m_sum == 0.0 or not np.isfinite(m_sum):\n        # Fallback: uniform if numerical issues arise\n        alpha_probs = np.full(N, 1.0 / N)\n    else:\n        alpha_probs = m_weights / m_sum\n    # Resample ancestors according to alpha_probs\n    ancestors = rng.choice(N, size=N, replace=True, p=alpha_probs)\n    # Stage-two: propagate and compute importance weights w ∝ p(y|x_t)/m_{ancestor}\n    mu = phi * x_prev[ancestors]\n    x_t = rng.normal(loc=mu, scale=tau, size=N)\n    sig_xt = hetero_sigma(x_t, sigma0, alpha)\n    loglik = normal_logpdf(y, mu=x_t, sigma=sig_xt)\n    log_m_anc = log_m[ancestors]\n    logw = loglik - log_m_anc\n    return ess_from_logweights(logw)\n\ndef ess_ratio_case(N, phi, tau, sigma0, alpha, y, seed):\n    rng = np.random.default_rng(seed)\n    x_prev = sample_stationary_x_prev(N, phi, tau, rng)\n    ess_naive = naive_bootstrap_step(x_prev, phi, tau, sigma0, alpha, y, rng)\n    ess_apf = apf_step(x_prev, phi, tau, sigma0, alpha, y, rng)\n    # Avoid division by zero\n    if ess_naive == 0.0:\n        return float('inf') if ess_apf > 0.0 else 1.0\n    return ess_apf / ess_naive\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (N, phi, tau, sigma0, alpha, y, seed)\n    test_cases = [\n        (3000, 0.9, 0.5, 0.2, 0.8,  1.0, 123),   # A\n        (3000, 0.9, 0.5, 0.2, 0.0,  1.0, 456),   # B\n        (3000, 0.95, 0.3, 0.1, 1.5, 3.0, 789),   # C\n        (1000, 0.7, 1.0, 0.3, 1.0, -2.0, 2024),  # D\n    ]\n\n    results = []\n    for case in test_cases:\n        N, phi, tau, sigma0, alpha, y, seed = case\n        ratio = ess_ratio_case(N, phi, tau, sigma0, alpha, y, seed)\n        # Round to a reasonable number of decimals for display\n        results.append(f\"{ratio:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "除了改进提议分布，Rao-Blackwellization 是另一种强大的方差缩减技术，尤其适用于具有可解析子结构的模型。当状态空间模型中一部分是条件线性高斯时，我们可以解析地边缘化这部分状态，仅对剩余的非线性/非高斯部分使用粒子滤波。这个练习将带你深入一个切换线性高斯状态空间模型 (SLG-SSM)，并推导出一个混合式平滑器 。你将通过一个具体的数值计算，实践如何将用于离散切换状态的粒子方法与用于连续线性状态的精确卡尔曼平滑相结合，从而构建一个高效的 Rao-Blackwellized 粒子滤波器 (RBPF)。",
            "id": "3290212",
            "problem": "考虑一个切换线性高斯状态空间模型 (SLG-SSM)，其中离散状态过程 $z_{t} \\in \\{1,2\\}$ 控制着连续潜状态 $s_{t} \\in \\mathbb{R}$ 的线性动态。该联合模型由以下基本部分定义：\n\n- 离散状态过程 $\\{z_{t}\\}_{t=0}^{T}$ 是一个齐次一阶马尔可夫链，其初始分布为 $p(z_{0})$，转移矩阵为 $A = [a_{ij}]$，其中 $a_{ij} = p(z_{t} = j \\mid z_{t-1} = i)$。\n- 连续潜动态在以 $z_{t}$ 为条件时是线性高斯的：\n$$\ns_{t} = A_{z_{t}} s_{t-1} + \\eta_{t}, \\quad \\eta_{t} \\sim \\mathcal{N}(0, Q_{z_{t}}).\n$$\n- 观测是条件线性高斯的：\n$$\ny_{t} = H s_{t} + \\epsilon_{t}, \\quad \\epsilon_{t} \\sim \\mathcal{N}(0, R),\n$$\n其中 $H = 1$。\n\n您将在 Rao-Blackwell化粒子滤波器（RBPF；Rao-Blackwell化通过精确条件推断取代了对线性高斯分量的采样）范式下工作，并结合辅助粒子滤波器（APF；辅助提议使用一步前瞻似然）的视角来构建一个混合前向后向平滑器：离散路径 $z_{0:T}$ 使用前向后向方法进行采样，其后向采样权重由线性高斯预测似然提供信息；连续轨迹 $s_{0:T}$ 在采样出的 $z_{0:T}$ 条件下通过卡尔曼平滑进行平滑。\n\n从贝叶斯平滑、隐马尔可夫模型 (HMM) 前向后向分解以及线性高斯滤波与平滑的核心定义出发。为 RBPF 推导一个基于原则的混合前向后向平滑器，该平滑器：\n\n1. 使用由前向状态滤波信息和基于状态条件的线性高斯预测似然 $p(y_{t+1} \\mid y_{0:t}, z_{t})$（这是APF前瞻原则）构建的后向采样权重，从精确平滑分布 $p(z_{0:T} \\mid y_{0:T})$ 中采样 $z_{0:T}$。\n2. 在采样出的 $z_{0:T}$ 条件下，对 $s_{0:T}$ 应用 Rauch–Tung–Striebel (RTS) 卡尔曼平滑。\n3. 使用迭代期望定律，将一个通用泛函 $\\phi(z_{t}, s_{t})$ 的平滑期望表示为一个关于 $z_{t}$ 的分解，其中包含 $s_{t}$ 的基于状态条件的线性高斯矩。\n\n然后，为一个短时间范围实例化并计算一个具体的平滑期望。设 $T=1$，参数为\n- $p(z_{0} = 1) = 0.5$，$p(z_{0} = 2) = 0.5$，\n- $A = \\begin{pmatrix} 0.8  0.2 \\\\ 0.3  0.7 \\end{pmatrix}$，\n- $A_{1} = 1.0$，$Q_{1} = 0.5$；$A_{2} = 0.5$，$Q_{2} = 0.5$，\n- $H = 1$，$R = 0.25$，\n- $s_{0} \\sim \\mathcal{N}(m_{0}, P_{0})$，其中 $m_{0} = 0$ 且 $P_{0} = 1$，\n观测值为 $y_{0} = 0.2$，$y_{1} = 0.3$。\n\n对于泛函 $\\phi(z_{1}, s_{1}) = z_{1} s_{1}$，使用您推导出的混合平滑器，在指定模型下精确计算平滑期望 $\\mathbb{E}[\\phi(z_{1}, s_{1}) \\mid y_{0}, y_{1}]$。将您的最终数值答案四舍五入到四位有效数字。不涉及物理单位。",
            "solution": "问题要求计算泛函 $\\phi(z_1, s_1) = z_1 s_1$ 在给定特定 SLG-SSM 和数据下的平滑期望 $\\mathbb{E}[\\phi(z_1, s_1) \\mid y_0, y_1]$。\n\n首先，我们为混合平滑器建立理论框架。针对 SLG-SSM 的 Rao-Blackwell化滤波器/平滑器的核心思想是解析地边缘化掉连续的线性高斯状态 $s_t$，同时处理离散的非线性切换过程 $z_t$。完整的后验分布 $p(z_{0:T}, s_{0:T} \\mid y_{0:T})$ 可以分解为：\n$$\np(z_{0:T}, s_{0:T} \\mid y_{0:T}) = p(s_{0:T} \\mid z_{0:T}, y_{0:T}) p(z_{0:T} \\mid y_{0:T})\n$$\n在离散路径 $z_{0:T} = \\{z_0, \\dots, z_T\\}$ 的一个特定实现上为条件，该模型变成一个标准的线性高斯状态空间模型。对于这样的模型，连续状态的平滑分布 $p(s_{0:T} \\mid z_{0:T}, y_{0:T})$ 是一个多元高斯分布。其均值和协方差可以通过一次卡尔曼滤波器前向过程和一次 Rauch-Tung-Striebel (RTS) 后向平滑过程精确计算。\n\n剩下的挑战是处理离散路径的后验分布 $p(z_{0:T} \\mid y_{0:T})$。对于大的时间范围 $T$，路径数量 $K^{T+1}$（其中 $K$ 是离散状态的数量）过大，无法进行精确枚举。在这种情况下，使用粒子滤波器（如辅助粒子滤波器）通过采样一组代表性路径来近似该分布。问题文本通过提及 RBPF 和 APF 暗示了这一点。然而，对于给定的 $T=1$ 和 $K=2$ 的问题，路径数量仅为 $2^2=4$。因此，我们可以精确计算每条路径的后验概率，从而无需进行采样。\n\n一个泛函 $\\phi(z_t, s_t)$ 的平滑期望由全期望定律给出：\n$$\n\\mathbb{E}[\\phi(z_t, s_t) \\mid y_{0:T}] = \\mathbb{E}_{z_{0:T} \\mid y_{0:T}} \\left[ \\mathbb{E}_{s_{0:T} \\mid z_{0:T}, y_{0:T}} [\\phi(z_t, s_t)] \\right]\n$$\n对于我们的具体问题，$t=1$，$T=1$，且 $\\phi(z_1, s_1) = z_1 s_1$。该期望变为：\n$$\n\\mathbb{E}[z_1 s_1 \\mid y_{0:1}] = \\sum_{z_0=1}^2 \\sum_{z_1=1}^2 \\mathbb{E}[z_1 s_1 \\mid y_{0:1}, z_0, z_1] p(z_0, z_1 \\mid y_{0:1})\n$$\n由于在内部的条件期望中 $z_0$ 和 $z_1$ 是给定的，这可以简化为：\n$$\n\\mathbb{E}[z_1 s_1 \\mid y_{0:1}] = \\sum_{i=1}^2 \\sum_{j=1}^2 j \\cdot \\mathbb{E}[s_1 \\mid y_{0:1}, z_0=i, z_1=j] \\cdot p(z_0=i, z_1=j \\mid y_{0:1})\n$$\n为了计算这个值，我们需要对四条路径 $(i,j)$ 中的每一条计算两个分量：\n1. 路径的后验概率，$p(z_0=i, z_1=j \\mid y_{0:1})$。\n2. $s_1$ 的平滑均值，$\\mathbb{E}[s_1 \\mid y_{0:1}, z_0=i, z_1=j]$。由于 $t=T=1$，这等价于滤波均值，我们记作 $m_{1|1}^{(i,j)}$。\n\n后验路径概率由贝叶斯法则给出：\n$$\np(z_0=i, z_1=j \\mid y_{0:1}) = \\frac{p(y_{0:1} \\mid z_0=i, z_1=j) p(z_0=i, z_1=j)}{p(y_{0:1})}\n$$\n每条路径 $(i,j)$ 的未归一化权重是 $\\tilde{w}_{i,j} = p(z_0=i, z_1=j, y_{0:1})$。使用概率链式法则：\n$\\tilde{w}_{i,j} = p(y_1 \\mid y_0, z_0=i, z_1=j) p(y_0 \\mid z_0=i) p(z_1=j \\mid z_0=i) p(z_0=i)$。\n项 $p(y_1 \\mid y_0, z_0=i, z_1=j)$ 是沿路径 $(i,j)$ 运行卡尔曼滤波器得到的预测似然。项 $p(y_0 \\mid z_0=i)$ 是第一个观测的似然。\n\n现在我们用给定的参数来实例化计算：\n- $p(z_0=1) = 0.5$，$p(z_0=2) = 0.5$。\n- $A=\\begin{pmatrix} 0.8  0.2 \\\\ 0.3  0.7 \\end{pmatrix}$，所以 $a_{11}=0.8, a_{12}=0.2, a_{21}=0.3, a_{22}=0.7$。\n- 对于 $z_t=1$：$A_1=1.0$，$Q_1=0.5$。\n- 对于 $z_t=2$：$A_2=0.5$，$Q_2=0.5$。\n- $H=1$，$R=0.25$。\n- $s_0$ 的先验：$s_0 \\sim \\mathcal{N}(m_0, P_0)$，其中 $m_0=0$ 且 $P_0=1$。\n- 观测值：$y_0=0.2$，$y_1=0.3$。\n\n**步骤 1：处理观测 $y_0$**\n$s_0$ 的先验分布 $p(s_0)=\\mathcal{N}(s_0; 0, 1)$ 与 $z_0$ 无关。我们使用 $y_0=0.2$ 对 $s_0$ 执行一次卡尔曼更新。\n- 先验均值 $m_{0|-1} = 0$，先验协方差 $P_{0|-1} = 1$。\n- 新息协方差：$S_0 = H P_{0|-1} H^T + R = 1 \\cdot 1 \\cdot 1 + 0.25 = 1.25$。\n- 卡尔曼增益：$K_0 = P_{0|-1} H^T S_0^{-1} = 1 \\cdot 1 \\cdot (1.25)^{-1} = 0.8$。\n- 后验均值：$m_{0|0} = m_{0|-1} + K_0 (y_0 - H m_{0|-1}) = 0 + 0.8(0.2 - 0) = 0.16$。\n- 后验协方差：$P_{0|0} = (I - K_0 H) P_{0|-1} = (1 - 0.8 \\cdot 1) \\cdot 1 = 0.2$。\n后验分布 $p(s_0 \\mid y_0) = \\mathcal{N}(s_0; 0.16, 0.2)$ 对所有路径都是共同的，因为先验与 $z_0$ 无关。我们记 $m_{0|0}^{(i)} = 0.16$ 和 $P_{0|0}^{(i)} = 0.2$ 对于 $i \\in \\{1,2\\}$。\n\n**步骤 2：对每条路径 $(i,j)$ 处理观测 $y_1$**\n我们计算特定路径的滤波均值 $m_{1|1}^{(i,j)}$ 和预测似然 $p(y_1 \\mid y_0, z_0=i, z_1=j)$。由于 $m_{0|0}$ 和 $P_{0|0}$ 是共同的，这些量将只依赖于 $z_1=j$ 的值。\n\n情况 1：$z_1=1$（路径 $(1,1)$ 和 $(2,1)$）\n- 预测步：\n  $m_{1|0}^{(1)} = A_1 m_{0|0} = 1.0 \\cdot 0.16 = 0.16$。\n  $P_{1|0}^{(1)} = A_1 P_{0|0} A_1^T + Q_1 = 1.0^2 \\cdot 0.2 + 0.5 = 0.7$。\n- 使用 $y_1=0.3$ 的更新步：\n  新息协方差：$S_1^{(1)} = H P_{1|0}^{(1)} H^T + R = 0.7 + 0.25 = 0.95$。\n  卡尔曼增益：$K_1^{(1)} = P_{1|0}^{(1)} H^T (S_1^{(1)})^{-1} = 0.7 \\cdot (0.95)^{-1} = \\frac{14}{19}$。\n  后验均值：$m_{1|1}^{(1)} = m_{1|0}^{(1)} + K_1^{(1)}(y_1 - H m_{1|0}^{(1)}) = 0.16 + \\frac{14}{19}(0.3 - 0.16) = \\frac{16}{100} + \\frac{14}{19} \\cdot \\frac{14}{100} = \\frac{4}{25} + \\frac{196}{1900} = \\frac{304+196}{1900} = \\frac{500}{1900} = \\frac{5}{19}$。\n- 预测似然值正比于 $L_1^{(1)} = \\mathcal{N}(y_1; m_{1|0}^{(1)}, S_1^{(1)}) = \\mathcal{N}(0.3; 0.16, 0.95)$。\n\n情况 2：$z_1=2$（路径 $(1,2)$ 和 $(2,2)$）\n- 预测步：\n  $m_{1|0}^{(2)} = A_2 m_{0|0} = 0.5 \\cdot 0.16 = 0.08$。\n  $P_{1|0}^{(2)} = A_2 P_{0|0} A_2^T + Q_2 = 0.5^2 \\cdot 0.2 + 0.5 = 0.05 + 0.5 = 0.55$。\n- 使用 $y_1=0.3$ 的更新步：\n  新息协方差：$S_1^{(2)} = H P_{1|0}^{(2)} H^T + R = 0.55 + 0.25 = 0.80$。\n  卡尔曼增益：$K_1^{(2)} = P_{1|0}^{(2)} H^T (S_1^{(2)})^{-1} = 0.55 \\cdot (0.80)^{-1} = \\frac{11}{16}$。\n  后验均值：$m_{1|1}^{(2)} = m_{1|0}^{(2)} + K_1^{(2)}(y_1 - H m_{1|0}^{(2)}) = 0.08 + \\frac{11}{16}(0.3 - 0.08) = \\frac{8}{100} + \\frac{11}{16} \\cdot \\frac{22}{100} = \\frac{2}{25} + \\frac{242}{1600} = \\frac{128+242}{1600} = \\frac{370}{1600} = \\frac{37}{160}$。\n- 预测似然值正比于 $L_1^{(2)} = \\mathcal{N}(y_1; m_{1|0}^{(2)}, S_1^{(2)}) = \\mathcal{N}(0.3; 0.08, 0.80)$。\n\n**步骤 3：计算路径概率**\n路径 $(i,j)$ 的未归一化权重为 $\\tilde{w}_{i,j} = p(z_0=i) \\cdot a_{ij} \\cdot L_1^{(j)}$。$y_0$ 的似然是公共的，可以省略。\n令 $l_1 = L_1^{(1)}$ 且 $l_2 = L_1^{(2)}$。\n$\\tilde{w}_{1,1} = p(z_0=1) a_{11} l_1 = 0.5 \\cdot 0.8 \\cdot l_1 = 0.4 l_1$。\n$\\tilde{w}_{1,2} = p(z_0=1) a_{12} l_2 = 0.5 \\cdot 0.2 \\cdot l_2 = 0.1 l_2$。\n$\\tilde{w}_{2,1} = p(z_0=2) a_{21} l_1 = 0.5 \\cdot 0.3 \\cdot l_1 = 0.15 l_1$。\n$\\tilde{w}_{2,2} = p(z_0=2) a_{22} l_2 = 0.5 \\cdot 0.7 \\cdot l_2 = 0.35 l_2$。\n\n总权重为 $W = \\tilde{w}_{1,1}+\\tilde{w}_{1,2}+\\tilde{w}_{2,1}+\\tilde{w}_{2,2} = (0.4+0.15)l_1 + (0.1+0.35)l_2 = 0.55 l_1 + 0.45 l_2$。\n路径的后验概率为 $p(z_0=i, z_1=j \\mid y_{0:1}) = \\tilde{w}_{i,j}/W$。\n\n**步骤 4：计算最终期望**\n期望为 $\\mathbb{E}[z_1 s_1 \\mid y_{0:1}] = \\sum_{i,j} j \\cdot \\frac{\\tilde{w}_{i,j}}{W} \\cdot m_{1|1}^{(j)}$。\n$= \\frac{1}{W} \\left( 1 \\cdot \\tilde{w}_{1,1} m_{1|1}^{(1)} + 2 \\cdot \\tilde{w}_{1,2} m_{1|1}^{(2)} + 1 \\cdot \\tilde{w}_{2,1} m_{1|1}^{(1)} + 2 \\cdot \\tilde{w}_{2,2} m_{1|1}^{(2)} \\right)$\n$= \\frac{1}{W} \\left( (\\tilde{w}_{1,1}+\\tilde{w}_{2,1}) m_{1|1}^{(1)} + 2(\\tilde{w}_{1,2}+\\tilde{w}_{2,2}) m_{1|1}^{(2)} \\right)$\n$= \\frac{1}{W} \\left( 0.55 l_1 m_{1|1}^{(1)} + 2 \\cdot 0.45 l_2 m_{1|1}^{(2)} \\right)$\n让我们计算比率 $\\rho = l_2/l_1$：\n$\\rho = \\frac{\\mathcal{N}(0.3; 0.08, 0.80)}{\\mathcal{N}(0.3; 0.16, 0.95)} = \\frac{(2\\pi \\cdot 0.80)^{-1/2} \\exp(-\\frac{0.22^2}{2 \\cdot 0.80})}{(2\\pi \\cdot 0.95)^{-1/2} \\exp(-\\frac{0.14^2}{2 \\cdot 0.95})} = \\sqrt{\\frac{0.95}{0.80}} \\exp\\left(-\\frac{0.0484}{1.6} + \\frac{0.0196}{1.9}\\right)$\n$\\rho = \\sqrt{1.1875} \\exp(-0.03025 + 0.0103157...) = 1.08972... \\times \\exp(-0.0199342...) \\approx 1.08972 \\times 0.98026 \\approx 1.06822$。\n现在，将 $\\rho$ 代入期望表达式，分子和分母同除以 $l_1$：\n$\\mathbb{E}[z_1 s_1 \\mid y_{0:1}] = \\frac{0.55 m_{1|1}^{(1)} + 0.90 \\rho m_{1|1}^{(2)}}{0.55 + 0.45 \\rho}$\n使用 $m_{1|1}^{(1)} = 5/19$ 和 $m_{1|1}^{(2)} = 37/160 = 0.23125$：\n$\\mathbb{E}[z_1 s_1 \\mid y_{0:1}] \\approx \\frac{0.55 \\cdot (5/19) + 0.90 \\cdot 1.06822 \\cdot 0.23125}{0.55 + 0.45 \\cdot 1.06822}$\n$\\approx \\frac{0.144737 + 0.961398 \\cdot 0.23125}{0.55 + 0.480699} \\approx \\frac{0.144737 + 0.222274}{1.030699} \\approx \\frac{0.367011}{1.030699} \\approx 0.356089$。\n四舍五入到四位有效数字，结果是 $0.3561$。\n或者，我们可以先计算边缘概率 $p(z_1=j \\mid y_{0:1})$。\n$p(z_1=1 \\mid y_{0:1}) = \\frac{0.55 l_1}{W} = \\frac{0.55}{0.55+0.45\\rho} \\approx \\frac{0.55}{1.030699} \\approx 0.533616$。\n$p(z_1=2 \\mid y_{0:1}) = \\frac{0.45 l_2}{W} = \\frac{0.45\\rho}{0.55+0.45\\rho} \\approx \\frac{0.480699}{1.030699} \\approx 0.466384$。\n$\\mathbb{E}[z_1 s_1 \\mid y_{0:1}] = 1 \\cdot p(z_1=1 \\mid y_{0:1}) \\cdot m_{1|1}^{(1)} + 2 \\cdot p(z_1=2 \\mid y_{0:1}) \\cdot m_{1|1}^{(2)}$\n$\\approx 0.533616 \\cdot (5/19) + 2 \\cdot 0.466384 \\cdot 0.23125$\n$\\approx 0.140425 + 2 \\cdot 0.107843 \\approx 0.140425 + 0.215686 \\approx 0.356111$。\n结果四舍五入到四位有效数字，是 $0.3561$。",
            "answer": "$$\n\\boxed{0.3561}\n$$"
        },
        {
            "introduction": "掌握了先进的提议和权重更新策略后，我们再来关注粒子滤波算法的一个基础但至关重要的环节：重采样。虽然多项式重采样是最基本和常用的方法，但不同的重采样策略会对估计器的方差产生显著影响。这个练习旨在通过解析和数值计算，深入比较四种不同的重采样方案——多项式、分层、系统和残差重采样——对估计器方差的贡献 。通过为一个具体的例子计算方差，你将直观地理解为何以及何时分层、系统或残差重采样能够提供比标准多项式方法更低的方差，从而进一步优化你的滤波算法。",
            "id": "3290165",
            "problem": "考虑在时刻 $t$ 辅助粒子滤波器 (APF) 的单步更新，其中时刻 $t-1$ 的 $N$ 个粒子由归一化的一阶段辅助权重 $\\{q_{i}\\}_{i=1}^{N}$ 概括，且满足 $\\sum_{i=1}^{N} q_{i} = 1$。假设二阶段提议分布引入的随机性已通过 Rao-Blackwell化 消除（即，每个选定的祖先 $i$ 对滤波期望估计量的贡献被其条件期望 $\\eta_{i} = \\mathbb{E}[\\phi(X_{t}) \\mid \\text{ancestor } i, y_{t}]$ 所取代）。因此，在给定 $\\{q_{i}, \\eta_{i}\\}_{i=1}^{N}$ 的条件下，$\\mathbb{E}[\\phi(X_{t}) \\mid y_{1:t}]$ 的 APF 估计量简化为\n$$\n\\widehat{I}_{N} \\;=\\; \\frac{1}{N} \\sum_{k=1}^{N} \\eta_{A^{(k)}}\n\\;=\\;\n\\frac{1}{N} \\sum_{i=1}^{N} N_{i} \\, \\eta_{i},\n$$\n其中 $A^{(k)}$ 是为第 $k$ 个传播的粒子在一阶段重采样中选择的祖先索引，$N_{i}$ 是祖先 $i$ 被选择的次数（因此 $\\sum_{i=1}^{N} N_{i} = N$）。假设采用无偏重采样方案，使得 $\\mathbb{E}[N_{i} \\mid \\{q_{j}\\}] = N q_{i}$。\n\n你将比较四种无偏的一阶段重采样方案，并推导它们对条件方差 $\\operatorname{Var}(\\widehat{I}_{N} \\mid \\{q_{i}, \\eta_{i}\\})$ 的影响：\n- 多项式重采样：$A^{(k)}$ 独立同分布，且 $\\mathbb{P}(A^{(k)} = i) = q_{i}$。\n- 分层重采样：对于 $k=1,\\dots,N$，独立地抽取 $U_{k} \\sim \\operatorname{Uniform}([(k-1)/N, k/N))$，然后令 $A^{(k)} = F^{-1}(U_{k})$，其中 $F$ 是对应于 $\\{q_{i}\\}$ 的累积分布函数。\n- 系统重采样：抽取单个 $U \\sim \\operatorname{Uniform}([0, 1/N))$ 并令 $U_{k} = U + (k-1)/N$，然后 $A^{(k)} = F^{-1}(U_{k})$。\n- 残差重采样：令 $N_{i}^{\\mathrm{det}} = \\lfloor N q_{i} \\rfloor$, $R = N - \\sum_{i=1}^{N} N_{i}^{\\mathrm{det}}$，并当 $R0$ 时抽取 $(M_{1},\\dots,M_{N}) \\sim \\operatorname{Multinomial}\\!\\left(R; \\bar{q}_{1},\\dots,\\bar{q}_{N}\\right)$，其中 $\\bar{q}_{i} = \\frac{N q_{i} - \\lfloor N q_{i} \\rfloor}{R}$（当 $R=0$ 时，$(M_{i})_{i}$ 退化为零），然后令 $N_{i} = N_{i}^{\\mathrm{det}} + M_{i}$。\n\n从以上定义以及随机变量和与多项式分布的基本方差性质出发。完全在给定 $\\{q_{i}, \\eta_{i}\\}$ 的条件下进行推导，并为每种方案推导出 $\\operatorname{Var}(\\widehat{I}_{N} \\mid \\{q_{i}, \\eta_{i}\\})$ 的表达式。然后，对于 $N = 4$ 的具体实例，\n$$\n(q_{1}, q_{2}, q_{3}, q_{4}) \\;=\\; (0.5,\\, 0.2,\\, 0.2,\\, 0.1),\n\\qquad\n(\\eta_{1}, \\eta_{2}, \\eta_{3}, \\eta_{4}) \\;=\\; (1,\\, 3,\\, -2,\\, 0.5),\n$$\n计算所有四种重采样方案下的条件方差。最后，报告比率\n$$\nR \\;=\\; \\frac{\\operatorname{Var}_{\\mathrm{mult}}(\\widehat{I}_{N} \\mid \\{q_{i}, \\eta_{i}\\})}{\\operatorname{Var}_{\\mathrm{resid}}(\\widehat{I}_{N} \\mid \\{q_{i}, \\eta_{i}\\})}.\n$$\n将你的答案四舍五入到四位有效数字。不需要单位。",
            "solution": "该问题要求在四种不同的一阶段重采样方案下，计算并比较一个经过 Rao-Blackwell 化的辅助粒子滤波器 (APF) 估计量 $\\widehat{I}_{N}$ 的条件方差。该分析在给定一阶段辅助权重 $\\{q_i\\}_{i=1}^N$ 和条件期望 $\\{\\eta_i\\}_{i=1}^N$ 的条件下进行。\n\n估计量由下式给出\n$$\n\\widehat{I}_{N} = \\frac{1}{N} \\sum_{i=1}^{N} N_{i} \\, \\eta_{i}\n$$\n其中 $N_i$ 是祖先 $i$ 的后代数量。需要计算的量是条件方差 $\\operatorname{Var}(\\widehat{I}_{N} \\mid \\{q_{i}, \\eta_{i}\\})$。由于分析是在给定 $\\{\\eta_i\\}$ 的条件下进行的，这些值被视为常数。因此方差为\n$$\n\\operatorname{Var}(\\widehat{I}_{N} \\mid \\{q_{i}, \\eta_{i}\\}) = \\frac{1}{N^2} \\operatorname{Var}\\left(\\sum_{i=1}^{N} N_{i} \\eta_{i}\\right) = \\frac{1}{N^2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\eta_{i} \\eta_{j} \\operatorname{Cov}(N_i, N_j)\n$$\n其中协方差是在给定 $\\{q_i\\}$ 的条件下计算的。我们将为四种指定的重采样方案中的每一种推导这个方差。\n\n给定的数值实例是 $N=4$，权重为 $(q_1, q_2, q_3, q_4) = (0.5, 0.2, 0.2, 0.1)$，条件期望为 $(\\eta_1, \\eta_2, \\eta_3, \\eta_4) = (1, 3, -2, 0.5)$。\n\n**1. 多项式重采样**\n在多项式重采样中，计数向量 $(N_1, \\dots, N_N)$ 服从参数为 $N$ 和 $(q_1, \\dots, q_N)$ 的多项式分布。该分布的标准性质是 $\\operatorname{Var}(N_i) = N q_i(1-q_i)$ 和当 $i \\neq j$ 时 $\\operatorname{Cov}(N_i, N_j) = -N q_i q_j$。\n\n或者，更直接地，$\\widehat{I}_{N} = \\frac{1}{N} \\sum_{k=1}^{N} \\eta_{A^{(k)}}$，其中每个祖先索引 $A^{(k)}$ 是从概率为 $\\{q_i\\}$ 的分类分布中独立同分布地抽取的。由于抽样的独立同分布性质，样本均值的方差为\n$$\n\\operatorname{Var}_{\\mathrm{mult}}(\\widehat{I}_{N}) = \\frac{1}{N} \\operatorname{Var}(\\eta_{A^{(1)}})\n$$\n随机变量 $\\eta_{A^{(1)}}$ 以概率 $q_i$ 取值 $\\eta_i$。其方差由下式给出\n$$\n\\operatorname{Var}(\\eta_{A^{(1)}}) = \\mathbb{E}[(\\eta_{A^{(1)}})^2] - (\\mathbb{E}[\\eta_{A^{(1)}}])^2 = \\sum_{i=1}^N q_i \\eta_i^2 - \\left(\\sum_{i=1}^N q_i \\eta_i\\right)^2\n$$\n所以，多项式重採样的方差是\n$$\n\\operatorname{Var}_{\\mathrm{mult}}(\\widehat{I}_{N}) = \\frac{1}{N} \\left[ \\sum_{i=1}^N q_i \\eta_i^2 - \\left(\\sum_{i=1}^N q_i \\eta_i\\right)^2 \\right]\n$$\n对于给定的数值：\n$\\sum q_i \\eta_i = (0.5)(1) + (0.2)(3) + (0.2)(-2) + (0.1)(0.5) = 0.5 + 0.6 - 0.4 + 0.05 = 0.75$。\n$\\sum q_i \\eta_i^2 = (0.5)(1^2) + (0.2)(3^2) + (0.2)((-2)^2) + (0.1)(0.5^2) = 0.5 + 1.8 + 0.8 + 0.025 = 3.125$。\n$$\n\\operatorname{Var}_{\\mathrm{mult}}(\\widehat{I}_{4}) = \\frac{1}{4} \\left[ 3.125 - (0.75)^2 \\right] = \\frac{1}{4} (3.125 - 0.5625) = \\frac{2.5625}{4} = 0.640625\n$$\n\n**2. 分层重采样**\n对于分层重采样，抽取 $N$ 个独立的均匀随机变量 $U_k \\sim \\operatorname{Uniform}([(k-1)/N, k/N))$。祖先索引为 $A^{(k)} = F^{-1}(U_k)$。由于抽取的 $U_k$ 是独立的，相应的祖先索引 $A^{(k)}$ 也是独立的。因此方差为：\n$$\n\\operatorname{Var}_{\\mathrm{strat}}(\\widehat{I}_{N}) = \\operatorname{Var}\\left(\\frac{1}{N} \\sum_{k=1}^N \\eta_{A^{(k)}}\\right) = \\frac{1}{N^2} \\sum_{k=1}^N \\operatorname{Var}(\\eta_{A^{(k)}})\n$$\n我们为每个 $k=1, \\dots, 4$ 计算 $\\operatorname{Var}(\\eta_{A^{(k)}})$。累积概率为 $C_0=0$, $C_1=0.5$, $C_2=0.7$, $C_3=0.9$, $C_4=1.0$。目标区间为 $I_1=[0, 0.5)$, $I_2=[0.5, 0.7)$, $I_3=[0.7, 0.9)$, $I_4=[0.9, 1.0)$。层为 $S_k=[(k-1)/4, k/4)$。\n\n对于 $k=1$：$S_1 = [0, 0.25)$。$S_1 \\subset I_1$。因此 $A^{(1)}$ 确定为 $1$。$\\eta_{A^{(1)}}=\\eta_1=1$。$\\operatorname{Var}(\\eta_{A^{(1)}})=0$。\n对于 $k=2$：$S_2 = [0.25, 0.5)$。$S_2 \\subset I_1$。因此 $A^{(2)}$ 确定为 $1$。$\\eta_{A^{(2)}}=\\eta_1=1$。$\\operatorname{Var}(\\eta_{A^{(2)}})=0$。\n对于 $k=3$：$S_3 = [0.5, 0.75)$。该层与 $I_2$ 和 $I_3$ 重叠。\n选择祖先 $2$ 的概率是 $\\mathbb{P}(A^{(3)}=2) = N \\cdot \\text{length}(S_3 \\cap I_2) = 4 \\cdot \\text{length}([0.5, 0.7)) = 4 \\cdot 0.2 = 0.8$。\n选择祖先 $3$ 的概率是 $\\mathbb{P}(A^{(3)}=3) = N \\cdot \\text{length}(S_3 \\cap I_3) = 4 \\cdot \\text{length}([0.7, 0.75)) = 4 \\cdot 0.05 = 0.2$。\n$\\mathbb{E}[\\eta_{A^{(3)}}] = 0.8 \\eta_2 + 0.2 \\eta_3 = 0.8(3) + 0.2(-2) = 2.4 - 0.4 = 2$。\n$\\mathbb{E}[\\eta_{A^{(3)}}^2] = 0.8 \\eta_2^2 + 0.2 \\eta_3^2 = 0.8(9) + 0.2(4) = 7.2 + 0.8 = 8$。\n$\\operatorname{Var}(\\eta_{A^{(3)}}) = 8 - 2^2 = 4$。\n对于 $k=4$：$S_4=[0.75, 1.0)$。该层与 $I_3$ 和 $I_4$ 重叠。\n$\\mathbb{P}(A^{(4)}=3) = 4 \\cdot \\text{length}([0.75, 0.9)) = 4 \\cdot 0.15 = 0.6$。\n$\\mathbb{P}(A^{(4)}=4) = 4 \\cdot \\text{length}([0.9, 1.0)) = 4 \\cdot 0.1 = 0.4$。\n$\\mathbb{E}[\\eta_{A^{(4)}}] = 0.6 \\eta_3 + 0.4 \\eta_4 = 0.6(-2) + 0.4(0.5) = -1.2 + 0.2 = -1$。\n$\\mathbb{E}[\\eta_{A^{(4)}}^2] = 0.6 \\eta_3^2 + 0.4 \\eta_4^2 = 0.6(4) + 0.4(0.25) = 2.4 + 0.1 = 2.5$。\n$\\operatorname{Var}(\\eta_{A^{(4)}}) = 2.5 - (-1)^2 = 1.5$。\n总方差：\n$$\n\\operatorname{Var}_{\\mathrm{strat}}(\\widehat{I}_{4}) = \\frac{1}{4^2} (0 + 0 + 4 + 1.5) = \\frac{5.5}{16} = 0.34375\n$$\n\n**3. 系统重采样**\n抽取单个 $U \\sim \\operatorname{Uniform}([0, 1/N))$。这里 $N=4$，所以 $U \\sim \\operatorname{Uniform}([0, 0.25))$。重采样点为 $u_k = U + (k-1)/4$。我们确定计数向量 $(N_1, N_2, N_3, N_4)$ 作为 $U$ 的函数。\n- $u_1=U \\in [0, 0.25)$，$u_2=U+0.25 \\in [0.25, 0.5)$。两者都在 $I_1=[0, 0.5)$ 中。因此，对于任何 $U$，$N_1=2$。\n- $u_3=U+0.5 \\in [0.5, 0.75)$。\n- $u_4=U+0.75 \\in [0.75, 1.0)$。\n令 $X = \\sum_{i=1}^4 N_i \\eta_i$。我们分析在 $U$ 的不同取值范围内 $X$ 的值：\n- 如果 $U \\in [0, 0.15)$（概率 $0.15/0.25=0.6$）：\n  $u_3 \\in [0.5, 0.65) \\subset I_2$，所以 $A^{(3)}=2$。\n  $u_4 \\in [0.75, 0.9) \\subset I_3$，所以 $A^{(4)}=3$。\n  计数：$(N_1,N_2,N_3,N_4)=(2,1,1,0)$。$X = 2\\eta_1+\\eta_2+\\eta_3 = 2(1)+3+(-2)=3$。\n- 如果 $U \\in [0.15, 0.2)$（概率 $0.05/0.25=0.2$）：\n  $u_3 \\in [0.65, 0.7) \\subset I_2$，所以 $A^{(3)}=2$。\n  $u_4 \\in [0.9, 0.95) \\subset I_4$，所以 $A^{(4)}=4$。\n  计数：$(N_1,N_2,N_3,N_4)=(2,1,0,1)$。$X = 2\\eta_1+\\eta_2+\\eta_4 = 2(1)+3+0.5=5.5$。\n- 如果 $U \\in [0.2, 0.25)$（概率 $0.05/0.25=0.2$）：\n  $u_3 \\in [0.7, 0.75) \\subset I_3$，所以 $A^{(3)}=3$。\n  $u_4 \\in [0.95, 1.0) \\subset I_4$，所以 $A^{(4)}=4$。\n  计数：$(N_1,N_2,N_3,N_4)=(2,0,1,1)$。$X = 2\\eta_1+\\eta_3+\\eta_4 = 2(1)+(-2)+0.5=0.5$。\n随机变量 $X$ 具有以下分布：$P(X=3)=0.6$, $P(X=5.5)=0.2$, $P(X=0.5)=0.2$。\n$\\mathbb{E}[X] = 0.6(3) + 0.2(5.5) + 0.2(0.5) = 1.8 + 1.1 + 0.1 = 3$。\n$\\mathbb{E}[X^2] = 0.6(3^2) + 0.2(5.5^2) + 0.2(0.5^2) = 5.4 + 6.05 + 0.05 = 11.5$。\n$\\operatorname{Var}(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2 = 11.5 - 3^2 = 2.5$。\n该估计量的方差是：\n$$\n\\operatorname{Var}_{\\mathrm{syst}}(\\widehat{I}_{4}) = \\frac{1}{4^2} \\operatorname{Var}(X) = \\frac{2.5}{16} = 0.15625\n$$\n\n**4. 残差重采样**\n首先，我们确定确定性计数 $N_i^{\\mathrm{det}} = \\lfloor N q_i \\rfloor$。\n$Nq = (4 \\times 0.5, 4 \\times 0.2, 4 \\times 0.2, 4 \\times 0.1) = (2, 0.8, 0.8, 0.4)$。\n$N^{\\mathrm{det}} = (\\lfloor 2 \\rfloor, \\lfloor 0.8 \\rfloor, \\lfloor 0.8 \\rfloor, \\lfloor 0.4 \\rfloor) = (2, 0, 0, 0)$。\n残差粒子的数量是 $R = N - \\sum N_i^{\\mathrm{det}} = 4 - 2 = 2$。\n残差分数为 $Nq_i-\\lfloor Nq_i \\rfloor = (0, 0.8, 0.8, 0.4)$。\n用于残差多项式抽样的归一化概率为 $\\bar{q}_i = (Nq_i - \\lfloor Nq_i \\rfloor)/R$：\n$\\bar{q} = (0/2, 0.8/2, 0.8/2, 0.4/2) = (0, 0.4, 0.4, 0.2)$。\n总计数为 $N_i = N_i^{\\mathrm{det}} + M_i$，其中 $(M_1, \\dots, M_N) \\sim \\operatorname{Multinomial}(R; \\bar{q})$。\n估计量为 $\\widehat{I}_N = \\frac{1}{N} \\sum_i (N_i^{\\mathrm{det}} + M_i)\\eta_i$。确定性部分对方差没有贡献。\n$$\n\\operatorname{Var}_{\\mathrm{resid}}(\\widehat{I}_{N}) = \\frac{1}{N^2} \\operatorname{Var}\\left(\\sum_{i=1}^N M_i \\eta_i\\right)\n$$\n该和的方差类似于多项式情况，参数为 $R$ 和 $\\bar{q}$：\n$\\operatorname{Var}(\\sum M_i \\eta_i) = R \\left[ \\sum \\bar{q}_i \\eta_i^2 - \\left(\\sum \\bar{q}_i \\eta_i\\right)^2 \\right]$。\n$\\sum \\bar{q}_i \\eta_i = (0)(1) + (0.4)(3) + (0.4)(-2) + (0.2)(0.5) = 1.2 - 0.8 + 0.1 = 0.5$。\n$\\sum \\bar{q}_i \\eta_i^2 = (0)(1^2) + (0.4)(3^2) + (0.4)((-2)^2) + (0.2)(0.5^2) = 0 + 3.6 + 1.6 + 0.05 = 5.25$。\n$\\operatorname{Var}(\\sum M_i \\eta_i) = 2 \\left[ 5.25 - (0.5)^2 \\right] = 2 (5.25 - 0.25) = 2(5) = 10$。\n$$\n\\operatorname{Var}_{\\mathrm{resid}}(\\widehat{I}_{4}) = \\frac{1}{4^2} (10) = \\frac{10}{16} = 0.625\n$$\n\n**最终计算**\n该问题要求计算比率 $R = \\operatorname{Var}_{\\mathrm{mult}}(\\widehat{I}_{N}) / \\operatorname{Var}_{\\mathrm{resid}}(\\widehat{I}_{N})$。\n$$\nR = \\frac{0.640625}{0.625} = 1.025\n$$\n四舍五入到四位有效数字，值为 $1.025$。",
            "answer": "$$\n\\boxed{1.025}\n$$"
        }
    ]
}