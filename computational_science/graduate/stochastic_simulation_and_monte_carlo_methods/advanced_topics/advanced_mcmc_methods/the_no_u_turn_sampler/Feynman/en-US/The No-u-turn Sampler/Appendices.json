{
    "hands_on_practices": [
        {
            "introduction": "Moving from theory to practice is essential for mastering any algorithm. This first exercise is foundational, guiding you through a direct implementation of the core NUTS machinery. By simulating a short Hamiltonian trajectory using the leapfrog integrator and applying the necessary slice and U-turn checks, you will gain a concrete understanding of how NUTS dynamically explores the state space, which is the key to its efficiency .",
            "id": "3355983",
            "problem": "You are given a two-dimensional Gaussian target with mean vector $\\mu \\in \\mathbb{R}^2$ and symmetric positive definite (SPD) precision matrix $\\Sigma^{-1} \\in \\mathbb{R}^{2 \\times 2}$, which induces the potential energy function $U(q)$ defined by\n$$\nU(q) = \\frac{1}{2} (q - \\mu)^{\\top} \\Sigma^{-1} (q - \\mu),\n$$\nand gradient\n$$\n\\nabla U(q) = \\Sigma^{-1} (q - \\mu).\n$$\nIn Hamiltonian Monte Carlo (HMC), a symmetric positive definite mass matrix $M \\in \\mathbb{R}^{2 \\times 2}$ defines the kinetic energy\n$$\nK(p) = \\frac{1}{2} p^{\\top} M^{-1} p,\n$$\nand the Hamiltonian\n$$\nH(q, p) = U(q) + K(p).\n$$\nThe canonical leapfrog integrator with step size $\\epsilon  0$ updates $(q, p)$ by\n$$\np_{\\text{half}} = p - \\frac{\\epsilon}{2} \\nabla U(q), \\quad\nq_{\\text{new}} = q + \\epsilon M^{-1} p_{\\text{half}}, \\quad\np_{\\text{new}} = p_{\\text{half}} - \\frac{\\epsilon}{2} \\nabla U(q_{\\text{new}}).\n$$\n\nConsider the No-U-Turn Sampler (NUTS) tree-building procedure in a single direction $v = +1$ with depth $j = 2$, which, starting from a root state $(q_0, p_0)$, performs $2^j = 4$ forward leapfrog steps, producing $4$ leaf states $(q^{(k)}, p^{(k)})$ for $k \\in \\{1,2,3,4\\}$. Let the slice variable $u$ be constructed deterministically from the root via\n$$\nu = s \\cdot \\exp\\big(-H(q_0, p_0)\\big),\n$$\nwith a given slice factor $s \\in (0, 1)$.\n\nFor each leaf $k$, define the displacement\n$$\n\\Delta q^{(k)} = q^{(k)} - q_0,\n$$\nand perform the No-U-Turn checks using the canonical criterion evaluated against the current bounding states where the minus-end is the root and the plus-end is the leaf:\n$$\n\\text{U-turn}^{(k)} = \\Big( \\Delta q^{(k)} \\cdot p_0  0 \\Big) \\ \\text{or} \\ \\Big( \\Delta q^{(k)} \\cdot p^{(k)}  0 \\Big).\n$$\nAlso determine slice validity at the leaf via\n$$\n\\text{valid}^{(k)} = \\Big( \\exp\\big(-H(q^{(k)}, p^{(k)})\\big) \\ge u \\Big).\n$$\n\nYour task is to implement the above two-level tree construction for a two-dimensional Gaussian target for each of the following parameter sets (test suite), performing exactly $4$ leapfrog steps forward from the root and reporting, for each leaf, its state $(q^{(k)}, p^{(k)})$, its Hamiltonian $H(q^{(k)}, p^{(k)})$, its No-U-Turn check $\\text{U-turn}^{(k)}$, and its slice validity $\\text{valid}^{(k)}$.\n\nUse the following test suite, where each case specifies $(\\mu, \\Sigma^{-1}, M, q_0, p_0, \\epsilon, s)$:\n\n- Case $1$ (happy path, isotropic target and mass):\n  - $\\mu = [0, 0]$\n  - $\\Sigma^{-1} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$\n  - $M = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$\n  - $q_0 = [-0.5, 0.5]$\n  - $p_0 = [0.3, -0.1]$\n  - $\\epsilon = 0.25$\n  - $s = 0.5$\n\n- Case $2$ (anisotropic target and mass, moderate step size):\n  - $\\mu = [0, 0]$\n  - $\\Sigma^{-1} = \\begin{bmatrix} 0.25  0 \\\\ 0  4.0 \\end{bmatrix}$\n  - $M = \\begin{bmatrix} 1.0  0 \\\\ 0  2.0 \\end{bmatrix}$\n  - $q_0 = [1.0, -1.0]$\n  - $p_0 = [-0.2, 0.4]$\n  - $\\epsilon = 0.2$\n  - $s = 0.3$\n\n- Case $3$ (correlated target and off-diagonal mass, small step size; edge-case coverage):\n  - $\\mu = [0, 0]$\n  - $\\Sigma^{-1} = \\begin{bmatrix} 1.0  0.3 \\\\ 0.3  1.5 \\end{bmatrix}$\n  - $M = \\begin{bmatrix} 1.0  0.5 \\\\ 0.5  2.0 \\end{bmatrix}$\n  - $q_0 = [0.7, -2.0]$\n  - $p_0 = [0.8, 0.1]$\n  - $\\epsilon = 0.1$\n  - $s = 0.8$\n\nYour program must compute, for each case, the list of $4$ leaf entries. Each leaf entry must be the list\n$$\n[q^{(k)}_1, q^{(k)}_2, p^{(k)}_1, p^{(k)}_2, H(q^{(k)}, p^{(k)}), \\text{U-turn}^{(k)}, \\text{valid}^{(k)}],\n$$\nwhere $q^{(k)}_1$ and $q^{(k)}_2$ are the components of $q^{(k)}$, and $p^{(k)}_1$ and $p^{(k)}_2$ are the components of $p^{(k)}$.\n\nFinal output format requirement: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The top-level list must contain exactly three elements, one per test case, and each element must be a list of the four leaf entries described above. For example, the printed string must look like\n$$\n[\\text{case1\\_leaves}, \\text{case2\\_leaves}, \\text{case3\\_leaves}],\n$$\nwith no additional text before or after.\n\nNo physical units or angles are involved in this problem. All computations are purely mathematical.",
            "solution": "The problem is valid. It presents a well-defined computational task based on sound principles of Hamiltonian Monte Carlo (HMC) and the No-U-Turn Sampler (NUTS) algorithm. All provided parameters and equations are standard, complete, and consistent. I will now proceed with the solution.\n\nThe core of the problem is to simulate a finite-length Hamiltonian trajectory and evaluate specific criteria at each step. We are given the fundamental components of a Hamiltonian system tailored for sampling from a two-dimensional Gaussian probability distribution.\n\nFirst, we define the mathematical objects. The target probability density is proportional to $\\exp(-U(q))$, where $U(q)$ is the potential energy. For a multivariate Gaussian distribution with mean $\\mu$ and covariance $\\Sigma$ (or precision $\\Sigma^{-1}$), the potential energy is given by the negative log-density, up to an additive constant:\n$$\nU(q) = \\frac{1}{2} (q - \\mu)^{\\top} \\Sigma^{-1} (q - \\mu)\n$$\nThe gradient of the potential energy, required for simulating the dynamics, is:\n$$\n\\nabla U(q) = \\Sigma^{-1} (q - \\mu)\n$$\nThe system's dynamics are augmented with a momentum variable $p$, and a kinetic energy is defined via a mass matrix $M$:\n$$\nK(p) = \\frac{1}{2} p^{\\top} M^{-1} p\n$$\nThe total energy of the system is the Hamiltonian $H(q, p)$, which is the sum of potential and kinetic energies:\n$$\nH(q, p) = U(q) + K(p) = \\frac{1}{2} (q - \\mu)^{\\top} \\Sigma^{-1} (q - \\mu) + \\frac{1}{2} p^{\\top} M^{-1} p\n$$\nHamilton's equations describe the evolution of $(q, p)$ in time, which, in theory, conserves $H(q, p)$. For numerical simulation, we use a symplectic integrator, like the leapfrog integrator, which approximates the solution to Hamilton's equations and exhibits good long-term energy conservation properties. A single step of the leapfrog integrator with step size $\\epsilon$ is defined by three stages:\n1.  A half-step update of momentum: $p_{\\text{half}} = p - \\frac{\\epsilon}{2} \\nabla U(q)$\n2.  A full-step update of position: $q_{\\text{new}} = q + \\epsilon M^{-1} p_{\\text{half}}$\n3.  A final half-step update of momentum: $p_{\\text{new}} = p_{\\text{half}} - \\frac{\\epsilon}{2} \\nabla U(q_{\\text{new}})$\n\nThe problem requires us to simulate a trajectory of $2^j = 2^2 = 4$ leapfrog steps forward in time, starting from an initial state $(q_0, p_0)$. This generates a sequence of $4$ leaf states, $(q^{(k)}, p^{(k)})$ for $k \\in \\{1, 2, 3, 4\\}$, where $(q^{(k)}, p^{(k)})$ is the state after $k$ leapfrog steps.\n\nFor each leaf, we must perform two checks related to the NUTS algorithm.\nFirst, we determine a slice variable $u$. This is a threshold used to ensure that the sampler explores regions of sufficiently high probability. It is computed from the initial state's energy:\n$$\nu = s \\cdot \\exp\\big(-H(q_0, p_0)\\big)\n$$\nwhere $s \\in (0, 1)$ is a given random factor, here supplied deterministically. A state $(q, p)$ is considered valid with respect to the slice if $\\exp(-H(q, p)) \\ge u$, which is equivalent to $H(q, p) \\le H(q_0, p_0) - \\log s$. We check this for each leaf:\n$$\n\\text{valid}^{(k)} = \\Big( \\exp\\big(-H(q^{(k)}, p^{(k)})\\big) \\ge u \\Big)\n$$\nSecond, the No-U-Turn condition is designed to stop the trajectory-building process when the path starts to turn back on itself, which would lead to inefficient exploration. The problem specifies a simplified check where each leaf state $(q^{(k)}, p^{(k)})$ is compared against the root state $(q_0, p_0)$. The displacement vector from the root is $\\Delta q^{(k)} = q^{(k)} - q_0$. A U-turn is detected if the trajectory is moving towards the origin of the trajectory's displacement, either at the start or the end of the segment. Mathematically, this is:\n$$\n\\text{U-turn}^{(k)} = \\Big( (\\Delta q^{(k)} \\cdot p_0)  0 \\Big) \\ \\text{or} \\ \\Big( (\\Delta q^{(k)} \\cdot p^{(k)})  0 \\Big)\n$$\nwhere $\\cdot$ denotes the standard dot product. Note that $p_0$ is the initial momentum, indicating the initial direction of travel for the trajectory segment from $q_0$.\n\nThe overall algorithm for each test case is as follows:\n1.  Initialize the parameters: $\\mu, \\Sigma^{-1}, M, q_0, p_0, \\epsilon, s$.\n2.  Compute the inverse mass matrix $M^{-1}$.\n3.  Calculate the initial Hamiltonian $H(q_0, p_0)$ and the slice variable $u$.\n4.  Initialize the current state $(q_{curr}, p_{curr}) = (q_0, p_0)$.\n5.  Iterate $k$ from $1$ to $4$:\n    a. Apply one leapfrog step to $(q_{curr}, p_{curr})$ to obtain the new state, which we label $(q^{(k)}, p^{(k)})$.\n    b. Update $(q_{curr}, p_{curr}) = (q^{(k)}, p^{(k)})$ for the next iteration.\n    c. Calculate the Hamiltonian $H(q^{(k)}, p^{(k)})$.\n    d. Calculate the displacement $\\Delta q^{(k)} = q^{(k)} - q_0$.\n    e. Evaluate the U-turn condition $\\text{U-turn}^{(k)}$.\n    f. Evaluate the slice validity condition $\\text{valid}^{(k)}$.\n    g. Store the resulting list $[q^{(k)}_1, q^{(k)}_2, p^{(k)}_1, p^{(k)}_2, H(q^{(k)}, p^{(k)}), \\text{U-turn}^{(k)}, \\text{valid}^{(k)}]$ for the current leaf $k$.\n6.  Collect the results for the $4$ leaves into a list for the current test case.\n7.  Repeat for all test cases and format the final output as specified.\n\nAll vector and matrix operations will be implemented using the `numpy` library. The inverse of $M$ is computed via `numpy.linalg.inv`, and matrix-vector products use the `@` operator.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy is not needed for this problem.\n\ndef solve():\n    \"\"\"\n    Implements the NUTS tree-building procedure for a 2D Gaussian target.\n    For each test case, it performs 4 forward leapfrog steps and computes\n    metrics for each of the 4 leaf states.\n    \"\"\"\n    \n    test_cases = [\n        # Case 1\n        {\n            \"mu\": np.array([0.0, 0.0]),\n            \"Sigma_inv\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"M\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"q0\": np.array([-0.5, 0.5]),\n            \"p0\": np.array([0.3, -0.1]),\n            \"epsilon\": 0.25,\n            \"s\": 0.5,\n        },\n        # Case 2\n        {\n            \"mu\": np.array([0.0, 0.0]),\n            \"Sigma_inv\": np.array([[0.25, 0.0], [0.0, 4.0]]),\n            \"M\": np.array([[1.0, 0.0], [0.0, 2.0]]),\n            \"q0\": np.array([1.0, -1.0]),\n            \"p0\": np.array([-0.2, 0.4]),\n            \"epsilon\": 0.2,\n            \"s\": 0.3,\n        },\n        # Case 3\n        {\n            \"mu\": np.array([0.0, 0.0]),\n            \"Sigma_inv\": np.array([[1.0, 0.3], [0.3, 1.5]]),\n            \"M\": np.array([[1.0, 0.5], [0.5, 2.0]]),\n            \"q0\": np.array([0.7, -2.0]),\n            \"p0\": np.array([0.8, 0.1]),\n            \"epsilon\": 0.1,\n            \"s\": 0.8,\n        },\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        mu = case[\"mu\"]\n        Sigma_inv = case[\"Sigma_inv\"]\n        M = case[\"M\"]\n        q0 = case[\"q0\"]\n        p0 = case[\"p0\"]\n        epsilon = case[\"epsilon\"]\n        s = case[\"s\"]\n        \n        M_inv = np.linalg.inv(M)\n\n        def grad_U(q_vec):\n            return Sigma_inv @ (q_vec - mu)\n\n        def U(q_vec):\n            diff = q_vec - mu\n            return 0.5 * diff.T @ Sigma_inv @ diff\n\n        def K(p_vec):\n            return 0.5 * p_vec.T @ M_inv @ p_vec\n\n        def H(q_vec, p_vec):\n            return U(q_vec) + K(p_vec)\n\n        def leapfrog(q_curr, p_curr):\n            p_half = p_curr - (epsilon / 2.0) * grad_U(q_curr)\n            q_new = q_curr + epsilon * (M_inv @ p_half)\n            p_new = p_half - (epsilon / 2.0) * grad_U(q_new)\n            return q_new, p_new\n\n        # Initial calculations\n        H0 = H(q0, p0)\n        u = s * np.exp(-H0)\n\n        case_leaves = []\n        q_current, p_current = q0, p0\n        \n        # Perform 4 leapfrog steps\n        for _ in range(4):\n            q_k, p_k = leapfrog(q_current, p_current)\n            \n            # Update current state for the next iteration\n            q_current, p_current = q_k, p_k\n\n            # Calculate metrics for the leaf\n            H_k = H(q_k, p_k)\n            delta_q_k = q_k - q0\n            \n            # U-Turn check\n            uturn_check = (np.dot(delta_q_k, p0)  0) or (np.dot(delta_q_k, p_k)  0)\n            \n            # Slice validity check\n            valid_slice = (np.exp(-H_k) = u)\n            \n            leaf_entry = [\n                q_k[0], q_k[1], \n                p_k[0], p_k[1], \n                H_k, \n                uturn_check, \n                valid_slice\n            ]\n            case_leaves.append(leaf_entry)\n            \n        all_results.append(case_leaves)\n\n    # Custom string formatting to match the output requirements precisely\n    def format_list(item):\n        if isinstance(item, list):\n            return f\"[{','.join(map(format_list, item))}]\"\n        if isinstance(item, bool):\n            return str(item)\n        if isinstance(item, float):\n            return f\"{item:.8f}\" # Use a reasonable precision\n        return str(item)\n\n    # The problem asks for a string representation that `str()` on a list would produce.\n    # The provided print statement in the problem skeleton does this.\n    # Let's use it directly.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "A crucial component of NUTS is its stopping criterion, which prevents the sampler from wasting computation on trajectories that have begun to retrace their steps. This practice demonstrates that a naive U-turn check based on standard Euclidean geometry can fail in the presence of strong anisotropy in the target distributionâ€”a common challenge in complex models. By constructing a clear counterexample, you will see why a generalized test that accounts for the problem's geometry via the mass matrix $M$ is necessary for robust performance .",
            "id": "3355985",
            "problem": "Consider a separable Hamiltonian system used in Hamiltonian Monte Carlo (HMC) for sampling from a Gaussian target. The target has a quadratic potential energy $U(\\theta) = \\tfrac{1}{2} \\theta^\\top \\Lambda \\theta$ where $\\Lambda$ is a positive-definite precision matrix, and the kinetic energy is $K(p) = \\tfrac{1}{2} p^\\top M^{-1} p$ where $M$ is a positive-definite mass matrix. The Hamiltonian equations are $d\\theta/dt = M^{-1} p$ and $dp/dt = -\\Lambda \\theta$. For diagonal $M$ and $\\Lambda$, each coordinate evolves independently as a harmonic oscillator. The No-U-Turn Sampler (NUTS) uses a stopping rule to prevent backtracking along the simulated trajectory. The classical Euclidean NUTS rule checks the sign of inner products between the trajectory displacement and the endpoint momenta. In strongly anisotropic settings (for example, when $M$ has entries with vastly different magnitudes), this Euclidean rule can fail to detect actual backtracking because it does not account for how the mass matrix scales the physical velocity. Your task is to construct a counterexample demonstrating such a failure and to implement a generalized stopping test that uses the physical velocity implied by the mass matrix.\n\nStarting from the fundamental definitions above, implement the following steps in a complete, runnable program:\n\n1. Use the exact solution of the linear Hamiltonian system for diagonal $M$ and diagonal $\\Lambda$ to compute the endpoints of a symmetric trajectory segment. Let $\\omega_i = \\sqrt{\\Lambda_i / M_i}$ denote the angular frequency for the $i$-th coordinate. For a given initial state $(\\theta_0, p_0)$ and integration time $T$ (interpreted in radians as the argument to trigonometric functions), define the endpoints $(\\theta^+, p^+)$ at time $+T$ and $(\\theta^-, p^-)$ at time $-T$. Also define the displacement $\\Delta \\theta = \\theta^+ - \\theta^-$. Your program must compute these quantities exactly for diagonal $M$ and diagonal $\\Lambda$.\n\n2. Implement two stopping tests:\n   - The Euclidean NUTS stopping test: declare \"stop\" if either of the inner products $\\Delta \\theta^\\top p^+$ or $\\Delta \\theta^\\top p^-$ is strictly negative.\n   - The generalized $M$-weighted stopping test: declare \"stop\" if either of the inner products $\\Delta \\theta^\\top M^{-1} p^+$ or $\\Delta \\theta^\\top M^{-1} p^-$ is strictly negative. This test uses the physical velocity $v = M^{-1} p$ rather than the raw momentum.\n\n3. Construct a scientifically sound counterexample where strong anisotropy in $M$ causes the Euclidean test to fail to prevent backtracking while the $M$-weighted test correctly detects it. Use the following parameter values for the counterexample:\n   - $M = \\mathrm{diag}(10^{-4}, 1)$,\n   - $\\Lambda = \\mathrm{diag}(1, 1)$,\n   - $\\theta_0 = [1, 1]^\\top$,\n   - $p_0 = [0.01, 1.262]^\\top$,\n   - $T = \\pi / (2 \\cdot 100)$.\n\n   Angles inside trigonometric functions must be in radians. These values are chosen to produce highly disparate angular frequencies, specifically $\\omega_1 = 100$ and $\\omega_2 = 1$, which induce strong anisotropy in the dynamics.\n\n4. Provide two additional test cases to ensure coverage:\n   - Isotropic \"happy path\" case where $M = \\mathrm{diag}(1, 1)$ and $\\Lambda = \\mathrm{diag}(1, 1)$ with moderate $T$ and initial state, demonstrating that the Euclidean and $M$-weighted tests agree:\n     - $M = \\mathrm{diag}(1, 1)$,\n     - $\\Lambda = \\mathrm{diag}(1, 1)$,\n     - $\\theta_0 = [0.3, -0.8]^\\top$,\n     - $p_0 = [0.7, 0.2]^\\top$,\n     - $T = 0.7$.\n   - Edge case with extreme anisotropy but momentum aligned with the slow dimension only (so both tests agree and do not stop due to very short integration time):\n     - $M = \\mathrm{diag}(10^{-6}, 1)$,\n     - $\\Lambda = \\mathrm{diag}(1, 1)$,\n     - $\\theta_0 = [0.0, 1.0]^\\top$,\n     - $p_0 = [0.0, 0.1]^\\top$,\n     - $T = 0.01$.\n\n5. For each test case, your program must compute and return a list of three booleans:\n   - The Euclidean stopping decision (true if the Euclidean test says to stop, false otherwise),\n   - The $M$-weighted stopping decision (true if the generalized test says to stop, false otherwise),\n   - A failure flag that is true if and only if the Euclidean test does not stop while the $M$-weighted test does stop.\n\n6. Final output format: Your program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, with each test case result itself formatted as a bracketed, comma-separated list of booleans. For example, the output should look like $[[\\text{False},\\text{True},\\text{True}],[\\text{False},\\text{False},\\text{False}],[\\text{False},\\text{False},\\text{False}]]$ for three test cases.\n\nNo user input should be read. Angles inside trigonometric functions must be in radians and any numerical values used must be treated as dimensionless. All computations must be exact with respect to the closed-form solution for diagonal $M$ and diagonal $\\Lambda$; do not use numerical integrators in this program.",
            "solution": "The problem requires the implementation and comparison of two stopping criteria for the No-U-Turn Sampler (NUTS), an algorithm used in Hamiltonian Monte Carlo (HMC). The context is sampling from a multivariate Gaussian distribution, for which the Hamiltonian dynamics have a closed-form solution. We must demonstrate a scenario where the standard Euclidean stopping criterion fails, while a generalized, mass-matrix-aware criterion succeeds.\n\nFirst, we establish the theoretical foundation. The system is defined by a potential energy $U(\\theta) = \\frac{1}{2} \\theta^\\top \\Lambda \\theta$ and a kinetic energy $K(p) = \\frac{1}{2} p^\\top M^{-1} p$. The matrices $\\Lambda$ (precision) and $M$ (mass) are given as positive-definite and diagonal. The Hamiltonian is $H(\\theta, p) = U(\\theta) + K(p)$. Hamilton's equations of motion are:\n$$\n\\frac{d\\theta}{dt} = \\frac{\\partial H}{\\partial p} = M^{-1} p\n$$\n$$\n\\frac{dp}{dt} = -\\frac{\\partial H}{\\partial \\theta} = -\\Lambda \\theta\n$$\nSince $M$ and $\\Lambda$ are diagonal, with elements $M_i$ and $\\Lambda_i$ respectively, the system decouples into a set of independent equations for each coordinate $i$:\n$$\n\\frac{d\\theta_i}{dt} = \\frac{p_i}{M_i}\n$$\n$$\n\\frac{dp_i}{dt} = -\\Lambda_i \\theta_i\n$$\nBy differentiating the first equation with respect to time $t$ and substituting the second, we obtain the equation for a simple harmonic oscillator for each coordinate $\\theta_i$:\n$$\n\\frac{d^2\\theta_i}{dt^2} = \\frac{1}{M_i}\\frac{dp_i}{dt} = -\\frac{\\Lambda_i}{M_i}\\theta_i\n$$\nLetting $\\omega_i = \\sqrt{\\Lambda_i / M_i}$ be the angular frequency for the $i$-th coordinate, the equation becomes $\\ddot{\\theta}_i + \\omega_i^2 \\theta_i = 0$. The exact solution to this system, given initial conditions $(\\theta_{i,0}, p_{i,0})$ at $t=0$, is a rotation in phase space:\n$$\n\\theta_i(t) = \\theta_{i,0} \\cos(\\omega_i t) + \\frac{p_{i,0}}{M_i \\omega_i} \\sin(\\omega_i t)\n$$\n$$\np_i(t) = p_{i,0} \\cos(\\omega_i t) - M_i \\omega_i \\theta_{i,0} \\sin(\\omega_i t)\n$$\nUsing the relation $\\omega_i = \\sqrt{\\Lambda_i / M_i}$, we can write $M_i \\omega_i = \\sqrt{M_i \\Lambda_i}$. The solutions can be expressed as:\n$$\n\\begin{pmatrix} \\theta_i(t) \\\\ p_i(t) \\end{pmatrix} = \\begin{pmatrix} \\cos(\\omega_i t)  \\frac{1}{\\sqrt{M_i\\Lambda_i}}\\sin(\\omega_i t) \\\\ -\\sqrt{M_i\\Lambda_i}\\sin(\\omega_i t)  \\cos(\\omega_i t) \\end{pmatrix} \\begin{pmatrix} \\theta_{i,0} \\\\ p_{i,0} \\end{pmatrix}\n$$\nThe NUTS algorithm builds a balanced binary tree of trajectory segments to explore the state space. It stops extending the trajectory when a U-turn is detected. A symmetric trajectory segment is defined by integrating from an initial state $(\\theta_0, p_0)$ forward and backward in time by an amount $T$. This yields a leftmost point $(\\theta^-, p^-) = (\\theta(-T), p(-T))$ and a rightmost point $(\\theta^+, p^+) = (\\theta(T), p(T))$. The span of the trajectory segment is the vector $\\Delta \\theta = \\theta^+ - \\theta^-$.\n\nThe stopping criteria are designed to detect when the trajectory starts to double back on itself.\n1.  **Euclidean NUTS stopping test:** This test checks if the trajectory is expanding. It stops if the momentum at either endpoint points back towards the start of the segment. Mathematically, it declares a stop if:\n    $$\n    (\\Delta \\theta)^\\top p^+  0 \\quad \\text{or} \\quad (\\Delta \\theta)^\\top p^-  0\n    $$\n2.  **Generalized $M$-weighted stopping test:** In anisotropic settings (where elements of $M$ vary significantly), the momentum $p$ is not aligned with the physical velocity $v = d\\theta/dt$. The correct physical quantity to check is the velocity. The generalized test uses $v = M^{-1}p$ in the inner product. It declares a stop if:\n    $$\n    (\\Delta \\theta)^\\top (M^{-1}p^+)  0 \\quad \\text{or} \\quad (\\Delta \\theta)^\\top (M^{-1}p^-)  0\n    $$\n    When $M$ is a scalar multiple of the identity matrix, $M = cI$, this test is equivalent to the Euclidean test, as $M^{-1}p = (1/c)p$. However, in strongly anisotropic cases, they can produce different results.\n\nThe program will implement the exact analytical solution for $\\theta(t)$ and $p(t)$ for the three given test cases. For each case, it will compute the trajectory endpoints $(\\theta^\\pm, p^\\pm)$, the displacement $\\Delta \\theta$, and apply both stopping tests. The primary counterexample is constructed such that a high-frequency coordinate completes a half-turn ($\\omega_1 T = \\pi/2$), causing its momentum $p_1$ to reverse. Due to a very small mass $M_1$, the magnitude of $p_1$ is small. The Euclidean inner product is dominated by the other, slow-moving coordinate, and fails to detect the reversal. The $M$-weighted test scales $p_1$ by the large $M_1^{-1}$, revealing the large negative physical velocity $v_1$ and correctly signaling a stop. The other two cases serve as controls, one for an isotropic system and one for an anisotropic system where the dynamics do not trigger a stop.\n\nThe final output will be a list of lists, where each inner list contains three boolean values corresponding to the outcomes of the Euclidean test, the $M$-weighted test, and a failure flag which is true if the former fails while the latter succeeds.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import constants  # Only for np.pi, not strictly necessary but adheres to library list.\n\ndef solve():\n    \"\"\"\n    Solves the problem by analyzing three test cases for the NUTS stopping criteria.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: Counterexample\n        {\n            \"M_diag\": np.array([1e-4, 1.0]),\n            \"Lambda_diag\": np.array([1.0, 1.0]),\n            \"theta0\": np.array([1.0, 1.0]),\n            \"p0\": np.array([0.01, 1.262]),\n            \"T\": np.pi / (2.0 * 100.0),\n        },\n        # Case 2: Isotropic \"happy path\"\n        {\n            \"M_diag\": np.array([1.0, 1.0]),\n            \"Lambda_diag\": np.array([1.0, 1.0]),\n            \"theta0\": np.array([0.3, -0.8]),\n            \"p0\": np.array([0.7, 0.2]),\n            \"T\": 0.7,\n        },\n        # Case 3: Aligned edge case\n        {\n            \"M_diag\": np.array([1e-6, 1.0]),\n            \"Lambda_diag\": np.array([1.0, 1.0]),\n            \"theta0\": np.array([0.0, 1.0]),\n            \"p0\": np.array([0.0, 0.1]),\n            \"T\": 0.01,\n        },\n    ]\n\n    results = []\n    for params in test_cases:\n        # Step 1: Compute trajectory endpoints using the exact solution.\n        theta_plus, p_plus, theta_minus, p_minus = solve_hamiltonian(\n            params[\"theta0\"], params[\"p0\"], params[\"M_diag\"], params[\"Lambda_diag\"], params[\"T\"]\n        )\n\n        # Step 2: Implement and run the stopping tests.\n        delta_theta = theta_plus - theta_minus\n        \n        # Euclidean test\n        dot_plus_euc = np.dot(delta_theta, p_plus)\n        dot_minus_euc = np.dot(delta_theta, p_minus)\n        stop_euc = (dot_plus_euc  0) or (dot_minus_euc  0)\n\n        # M-weighted test\n        M_inv_diag = 1.0 / params[\"M_diag\"]\n        v_plus = M_inv_diag * p_plus\n        v_minus = M_inv_diag * p_minus\n        \n        dot_plus_m_w = np.dot(delta_theta, v_plus)\n        dot_minus_m_w = np.dot(delta_theta, v_minus)\n        stop_m_weighted = (dot_plus_m_w  0) or (dot_minus_m_w  0)\n\n        # Step 3: Determine the failure flag.\n        failure = (not stop_euc) and stop_m_weighted\n        \n        results.append([stop_euc, stop_m_weighted, failure])\n    \n    # Final print statement in the exact required format.\n    # The str() representation of a list of lists is '[[], [], []]'\n    # which we can manipulate to match the required output format.\n    formatted_output = str(results).replace(\" \", \"\")\n    print(formatted_output)\n\ndef solve_hamiltonian(theta0, p0, M_diag, Lambda_diag, T):\n    \"\"\"\n    Computes the exact solution of the Hamiltonian system for diagonal M and Lambda.\n\n    Args:\n        theta0 (np.ndarray): Initial position vector.\n        p0 (np.ndarray): Initial momentum vector.\n        M_diag (np.ndarray): Diagonal elements of the mass matrix M.\n        Lambda_diag (np.ndarray): Diagonal elements of the precision matrix Lambda.\n        T (float): Integration time.\n\n    Returns:\n        tuple: A tuple containing (theta+, p+, theta-, p-).\n    \"\"\"\n    # Angular frequencies\n    omega = np.sqrt(Lambda_diag / M_diag)\n    \n    # Precompute trigonometric terms for t = T\n    cos_omega_T = np.cos(omega * T)\n    sin_omega_T = np.sin(omega * T)\n    \n    # Scaling factor for momentum term in theta's solution\n    mom_scaling = 1.0 / (M_diag * omega) # which is 1.0 / np.sqrt(M_diag * Lambda_diag)\n    \n    # Scaling factor for position term in p's solution\n    pos_scaling = M_diag * omega # which is np.sqrt(M_diag * Lambda_diag)\n\n    # Calculate state at t = +T\n    theta_plus = theta0 * cos_omega_T + p0 * mom_scaling * sin_omega_T\n    p_plus = p0 * cos_omega_T - theta0 * pos_scaling * sin_omega_T\n\n    # Calculate state at t = -T\n    # cos(-x) = cos(x), sin(-x) = -sin(x)\n    theta_minus = theta0 * cos_omega_T - p0 * mom_scaling * sin_omega_T\n    p_minus = p0 * cos_omega_T + theta0 * pos_scaling * sin_omega_T\n    \n    return theta_plus, p_plus, theta_minus, p_minus\n\nsolve()\n```"
        },
        {
            "introduction": "An elegant algorithm on paper can fail in practice if not implemented with care for the nuances of finite-precision arithmetic. This exercise addresses a critical implementation detail within the NUTS slice sampling procedure, where large values of the Hamiltonian $H(q, p)$ can cause numerical underflow. You will explore a hypothetical scenario where this leads to incorrect behavior and derive the standard, stable solution that operates in the logarithmic domain, a vital technique for building robust scientific software .",
            "id": "3356001",
            "problem": "Consider the No-U-Turn Sampler (NUTS), an adaptive extension of Hamiltonian Monte Carlo (HMC). In Hamiltonian Monte Carlo (HMC), one works with the joint density over position and momentum variables proportional to $\\exp(-H(\\mathbf{q},\\mathbf{p}))$, where $H(\\mathbf{q},\\mathbf{p})$ is the Hamiltonian. A common acceptance mechanism in NUTS uses a slice variable $u$ drawn uniformly from $(0,\\exp(-H(\\mathbf{q}_{0},\\mathbf{p}_{0})))$, where $(\\mathbf{q}_{0},\\mathbf{p}_{0})$ denotes the initial state of the trajectory. The slice test is the requirement that $u \\leq \\exp(-H(\\mathbf{q},\\mathbf{p}))$ for a proposed state $(\\mathbf{q},\\mathbf{p})$ along the trajectory.\n\nIn finite-precision arithmetic (IEEE 754 double precision), values of $\\exp(-H)$ can underflow to zero when $H$ is large, and implementations that compute ratios such as $\\exp(-H(\\mathbf{q},\\mathbf{p}))/\\exp(-H(\\mathbf{q}_{0},\\mathbf{p}_{0}))$ may yield the indeterminate form $0/0$, which is not-a-number and can be incorrectly flagged as a divergence even when the exact mathematical test should accept.\n\nUsing the following concrete numerical scenario:\n- Let $H(\\mathbf{q}_{0},\\mathbf{p}_{0}) = 1000$ and $H(\\mathbf{q},\\mathbf{p}) = 1001.5$.\n- Let $U \\sim \\text{Uniform}(0,1)$ and assume a specific draw $U = 0.2$.\n\nPerform the following:\n1. Explain, using the slice test setup, why computing $u = U \\exp(-H(\\mathbf{q}_{0},\\mathbf{p}_{0}))$ and testing $u \\leq \\exp(-H(\\mathbf{q},\\mathbf{p}))$ can fail under finite precision in this scenario, even though the exact acceptance decision based on the underlying mathematics is determinate.\n2. Derive from first principles a numerically stable slice test that avoids computing $\\exp(-H)$ by working in the logarithmic domain. Express the test in terms of $\\ln U$, $H(\\mathbf{q},\\mathbf{p})$, and $H(\\mathbf{q}_{0},\\mathbf{p}_{0})$.\n3. For the provided numerical values, compute the stable test statistic $T = \\ln U + H(\\mathbf{q},\\mathbf{p}) - H(\\mathbf{q}_{0},\\mathbf{p}_{0})$.\n\nRound your final numeric answer for $T$ to ten significant figures. No physical units are required because all quantities are dimensionless. Your final answer must be the single rounded value of $T$.",
            "solution": "The problem statement is scientifically grounded, well-posed, and objective. It addresses a real and important numerical stability issue in the implementation of sophisticated Monte Carlo methods like the No-U-Turn Sampler (NUTS). All necessary data and definitions are provided, and there are no contradictions. Thus, the problem is valid and a solution can be constructed.\n\nThe problem is divided into three parts, which will be addressed in order.\n\n### Part 1: Failure of the Naive Slice Test\n\nThe slice sampling mechanism in Hamiltonian Monte Carlo (HMC) and its variants like NUTS is designed to maintain the detailed balance condition with respect to the target distribution. The state of the system is described by position $\\mathbf{q}$ and momentum $\\mathbf{p}$, with a Hamiltonian $H(\\mathbf{q},\\mathbf{p})$. The target probability density is proportional to $\\exp(-H(\\mathbf{q},\\mathbf{p}))$.\n\nA slice variable $u$ is introduced, drawn from a uniform distribution on the interval $(0, \\exp(-H(\\mathbf{q}_{0},\\mathbf{p}_{0})))$, where $(\\mathbf{q}_{0},\\mathbf{p}_{0})$ is the initial state of the trajectory. This is equivalent to first drawing a standard uniform random variable $U \\sim \\text{Uniform}(0,1)$ and then setting $u = U \\exp(-H(\\mathbf{q}_{0},\\mathbf{p}_{0}))$.\n\nA proposed state $(\\mathbf{q},\\mathbf{p})$ along the simulated Hamiltonian trajectory is considered valid if it lies within the slice, which is defined by the condition $u \\leq \\exp(-H(\\mathbf{q},\\mathbf{p}))$. Substituting the expression for $u$, the acceptance condition is:\n$$U \\exp(-H(\\mathbf{q}_{0},\\mathbf{p}_{0})) \\leq \\exp(-H(\\mathbf{q},\\mathbf{p}))$$\n\nLet's analyze this condition using finite-precision arithmetic (specifically, IEEE 754 double precision) with the given numerical values: $H(\\mathbf{q}_{0},\\mathbf{p}_{0}) = 1000$ and $H(\\mathbf{q},\\mathbf{p}) = 1001.5$.\n\nIn IEEE 754 double precision, the smallest positive normalized number is approximately $2.225 \\times 10^{-308}$. The natural logarithm of this number is $\\ln(2.225 \\times 10^{-308}) \\approx -708.4$. Any number smaller than this, such as $\\exp(-x)$ for $x  708.4$, will underflow to zero.\n\nFor the initial state, we need to compute $\\exp(-H(\\mathbf{q}_{0},\\mathbf{p}_{0})) = \\exp(-1000)$. Since $-1000  -708.4$, this value underflows to $0$ in double-precision arithmetic.\n$$ \\exp(-1000) \\to 0.0 $$\n\nFor the proposed state, we need to compute $\\exp(-H(\\mathbf{q},\\mathbf{p})) = \\exp(-1001.5)$. Since $-1001.5  -708.4$, this value also underflows to $0$.\n$$ \\exp(-1001.5) \\to 0.0 $$\n\nWith the given draw $U=0.2$, the naive finite-precision implementation of the slice test becomes:\n$$ 0.2 \\times \\exp(-1000) \\leq \\exp(-1001.5) $$\n$$ 0.2 \\times 0.0 \\leq 0.0 $$\n$$ 0.0 \\leq 0.0 $$\nThis inequality is true, so the proposed state is accepted.\n\nNow, let's examine the exact mathematical condition. It is equivalent to $U \\leq \\exp(H(\\mathbf{q}_{0},\\mathbf{p}_{0}) - H(\\mathbf{q},\\mathbf{p}))$.\n$$ 0.2 \\leq \\exp(1000 - 1001.5) $$\n$$ 0.2 \\leq \\exp(-1.5) $$\nSince $\\exp(-1.5) \\approx 0.22313016$, the condition is $0.2 \\leq 0.22313016$, which is true.\n\nIn this specific case, both the naive and the exact tests yield the same result (acceptance). However, the failure of the naive method lies in its indiscriminate behavior. Consider a different proposed state with a much higher Hamiltonian, say $H(\\mathbf{q}',\\mathbf{p}') = 2000$.\nThe naive finite-precision test would be:\n$$ 0.2 \\times \\exp(-1000) \\leq \\exp(-2000) \\implies 0.0 \\leq 0.0 $$\nThis is true, leading to acceptance.\nHowever, the exact mathematical test would be:\n$$ 0.2 \\leq \\exp(1000 - 2000) = \\exp(-1000) $$\nSince $\\exp(-1000)$ is an exceedingly small positive number, the condition $0.2 \\leq \\exp(-1000)$ is false. The state should be rejected.\n\nThe failure is thus that the naive implementation accepts *any* state for which $\\exp(-H)$ underflows, completely failing to penalize states with high energy (large $H$) as required by the algorithm. This breaks the detailed balance condition and leads to an incorrect sampler. The alternative form mentioned in the problem, computing a ratio $\\exp(-H)/\\exp(-H_0)$, would lead to the indeterminate form $0/0$, which is also an implementation failure.\n\n### Part 2: Derivation of the Numerically Stable Test\n\nTo avoid the numerical underflow associated with the explicit computation of $\\exp(-H)$, we can work in the logarithmic domain. The acceptance condition is:\n$$U \\exp(-H(\\mathbf{q}_{0},\\mathbf{p}_{0})) \\leq \\exp(-H(\\mathbf{q},\\mathbf{p}))$$\nSince $U$, $\\exp(-H_{0})$, and $\\exp(-H)$ are all strictly positive quantities, we can take the natural logarithm of both sides of the inequality without changing its direction. The natural logarithm function $\\ln(x)$ is monotonically increasing for $x0$.\n$$ \\ln\\left(U \\exp(-H(\\mathbf{q}_{0},\\mathbf{p}_{0}))\\right) \\leq \\ln\\left(\\exp(-H(\\mathbf{q},\\mathbf{p}))\\right) $$\nUsing the logarithm property $\\ln(ab) = \\ln(a) + \\ln(b)$, the left side becomes:\n$$ \\ln(U) + \\ln\\left(\\exp(-H(\\mathbf{q}_{0},\\mathbf{p}_{0}))\\right) \\leq \\ln\\left(\\exp(-H(\\mathbf{q},\\mathbf{p}))\\right) $$\nUsing the property $\\ln(\\exp(x)) = x$, we simplify both sides:\n$$ \\ln(U) - H(\\mathbf{q}_{0},\\mathbf{p}_{0}) \\leq -H(\\mathbf{q},\\mathbf{p}) $$\nThis inequality is the numerically stable slice test. It involves the Hamiltonians $H$ and $H_0$ and the logarithm of the uniform variate $\\ln(U)$, none of which suffer from the underflow issue seen with the exponential function. The numbers involved ($1000$, $1001.5$, and $\\ln(0.2)$) are well within the representable range of standard floating-point types.\n\nTo match the test statistic $T$ given in the problem, we can rearrange the inequality by moving all terms to one side:\n$$ \\ln(U) + H(\\mathbf{q},\\mathbf{p}) - H(\\mathbf{q}_{0},\\mathbf{p}_{0}) \\leq 0 $$\nThis shows that the stable test is to compute the statistic $T = \\ln(U) + H(\\mathbf{q},\\mathbf{p}) - H(\\mathbf{q}_{0},\\mathbf{p}_{0})$ and accept the proposed state if and only if $T \\leq 0$.\n\n### Part 3: Computation of the Test Statistic\n\nWe are asked to compute the value of the stable test statistic $T$ for the given numerical scenario.\nThe formula is:\n$$ T = \\ln U + H(\\mathbf{q},\\mathbf{p}) - H(\\mathbf{q}_{0},\\mathbf{p}_{0}) $$\nThe provided values are:\n- $U = 0.2$\n- $H(\\mathbf{q}_{0},\\mathbf{p}_{0}) = 1000$\n- $H(\\mathbf{q},\\mathbf{p}) = 1001.5$\n\nSubstituting these values into the expression for $T$:\n$$ T = \\ln(0.2) + 1001.5 - 1000 $$\n$$ T = \\ln(0.2) + 1.5 $$\nThe natural logarithm of $0.2$ is:\n$$ \\ln(0.2) \\approx -1.60943791243410037 $$\nNow, we compute $T$:\n$$ T \\approx -1.60943791243410037 + 1.5 $$\n$$ T \\approx -0.10943791243410037 $$\nThe problem requires rounding the result to ten significant figures. The first ten significant figures are $1, 0, 9, 4, 3, 7, 9, 1, 2, 4$. The eleventh significant figure is $3$. Since $3  5$, we round down (i.e., truncate).\n$$ T \\approx -0.1094379124 $$\nFor the stable test, since $T \\approx -0.1094379124 \\leq 0$, the proposed state is correctly accepted, matching the conclusion from the exact mathematical analysis.",
            "answer": "$$ \\boxed{-0.1094379124} $$"
        }
    ]
}