{
    "hands_on_practices": [
        {
            "introduction": "这项练习是理解最优尺度理论的基石。我们将从第一性原理出发，处理一个多维高斯目标分布的经典情况。通过解决这个问题，您将证明一个核心结论：为了最大化采样效率，提议分布的协方差矩阵形状应与目标分布的协方差矩阵成比例，并推导出实现理想接受率（约$0.234$）所需的最优尺度参数 。",
            "id": "3325167",
            "problem": "考虑在马尔可夫链蒙特卡洛（MCMC）方法中的随机游走Metropolis（RWM）算法，其目标分布为一个$d$维高斯分布，密度为 $\\pi(x) \\propto \\exp\\!\\big(-\\tfrac{1}{2} x^{\\top} \\Sigma^{-1} x\\big)$，即 $\\mathcal{N}(0,\\Sigma)$，其中 $\\Sigma$ 是一个对称正定协方差矩阵。提议的形式为 $Y = X + \\xi$，其中 $\\xi \\sim \\mathcal{N}(0,C)$，接受概率为 $\\alpha(X,Y) = \\min\\!\\big\\{1, \\exp\\!\\big(\\log \\pi(Y) - \\log \\pi(X)\\big)\\big\\}$。定义期望平方跳跃距离（ESJD）为\n$$\n\\mathrm{ESJD}(C) = \\mathbb{E}\\Big[ \\|Y - X\\|^{2} \\, \\mathbf{1}\\{\\text{move accepted}\\} \\Big],\n$$\n其中期望是关于平稳分布 $\\pi$ 和提议机制计算的，$\\mathbf{1}\\{\\cdot\\}$ 表示指示函数。\n\n(a) 使用基本原理（线性变换和旋转不变性），证明在差一个标量缩放因子的意义下，通过选择与目标协方差成正比的提议协方差（即 $C$ 与 $\\Sigma$ 成正比），可以使ESJD最大化。\n\n(b) 现在将注意力集中于高维小步长机制，其中提议的形式为\n$$\nY = X + \\frac{l}{\\sqrt{d}} \\, \\Sigma^{1/2} Z, \\quad Z \\sim \\mathcal{N}(0,I_{d}),\n$$\n其中 $l  0$ 是一个无量纲步长参数。针对此机制下的高斯目标，推导渐近接受率 $\\alpha(l)$（用 $l$ 表示），并确定能达到标准目标接受率 $0.234$ 的 $l$ 值。将你的最终数值 $l$ 四舍五入到四位有效数字。你的最终答案必须是单个实数 $l$。",
            "solution": "该问题包含两部分。(a)部分要求证明对于以多元高斯分布为目标分布的随机游走Metropolis（RWM）采样器，其最优提议协方差的性质。(b)部分要求在高维机制下推导渐近接受率，并计算能产生特定接受率的步长参数 $l$。\n\n### (a)部分：最优提议协方差\n\n目标是通过选择提议协方差矩阵 $C$ 来最大化期望平方跳跃距离（ESJD），其定义为\n$$\n\\mathrm{ESJD}(C) = \\mathbb{E}\\Big[ \\|Y - X\\|^{2} \\, \\mathbf{1}\\{\\text{move accepted}\\} \\Big] = \\mathbb{E}\\Big[ \\|Y - X\\|^{2} \\, \\alpha(X,Y) \\Big]\n$$\n期望是关于平稳分布 $X \\sim \\pi = \\mathcal{N}(0,\\Sigma)$ 和提议 $Y = X + \\xi$（其中 $\\xi \\sim \\mathcal{N}(0,C)$）计算的。接受概率为 $\\alpha(X,Y) = \\min\\{1, \\pi(Y)/\\pi(X)\\}$。\n\n我们利用线性变换和旋转不变性的原理来解决这个问题。核心思想是将问题变换到一个目标分布呈球对称的空间，从而简化分析。\n\n1.  **线性变换（白化）：**\n    令 $\\Sigma^{1/2}$ 为 $\\Sigma$ 的对称正定平方根。我们通过线性变换 $x' = \\Sigma^{-1/2}x$ 定义一组新的坐标。如果 $X \\sim \\mathcal{N}(0, \\Sigma)$，那么变换后的变量 $X' = \\Sigma^{-1/2}X$ 服从标准多元正态分布，$X' \\sim \\mathcal{N}(0, I_d)$，其中 $I_d$ 是 $d \\times d$ 单位矩阵。$X'$ 的概率密度为 $\\pi'(x') \\propto \\exp(-\\frac{1}{2} x'^{\\top}x')$，这是球对称的（即在旋转下不变）。\n\n2.  **变换后的提议：**\n    提议机制 $Y = X + \\xi$ 被变换到新的坐标系中。令 $Y' = \\Sigma^{-1/2}Y$ 和 $\\xi' = \\Sigma^{-1/2}\\xi$。\n    $$\n    Y' = \\Sigma^{-1/2}(X+\\xi) = \\Sigma^{-1/2}X + \\Sigma^{-1/2}\\xi = X' + \\xi'\n    $$\n    由于 $\\xi \\sim \\mathcal{N}(0, C)$，变换后的新息项 $\\xi'$ 也服从正态分布，其均值为 $\\mathbb{E}[\\xi'] = \\Sigma^{-1/2}\\mathbb{E}[\\xi] = 0$，协方差为\n    $$\n    C' = \\mathrm{Cov}(\\xi') = \\mathbb{E}[\\xi' \\xi'^{\\top}] = \\mathbb{E}[\\Sigma^{-1/2}\\xi (\\Sigma^{-1/2}\\xi)^{\\top}] = \\Sigma^{-1/2} \\mathbb{E}[\\xi\\xi^{\\top}] \\Sigma^{-1/2} = \\Sigma^{-1/2}C\\Sigma^{-1/2}\n    $$\n    因此，在白化空间中，提议为 $Y' = X' + \\xi'$，其中 $\\xi' \\sim \\mathcal{N}(0, C')$。\n\n3.  **接受概率的不变性：**\n    接受概率 $\\alpha(X,Y)$ 取决于密度比 $\\pi(Y)/\\pi(X)$。我们用变换后的变量来表示它：\n    $$\n    \\log\\left(\\frac{\\pi(Y)}{\\pi(X)}\\right) = -\\frac{1}{2}Y^{\\top}\\Sigma^{-1}Y - \\left(-\\frac{1}{2}X^{\\top}\\Sigma^{-1}X\\right) = -\\frac{1}{2}(Y'^{\\top}Y' - X'^{\\top}X') = -\\frac{1}{2}(\\|Y'\\|^2 - \\|X'\\|^2)\n    $$\n    因此，接受概率 $\\alpha$ 仅取决于白化空间中状态和提议的欧几里得范数的平方。\n\n4.  **旋转对称性论证：**\n    使用RWM算法从标准正态目标 $\\mathcal{N}(0, I_d)$ 进行高效采样的问题，现在是变换后提议协方差 $C'$ 的一个函数。目标分布 $\\mathcal{N}(0, I_d)$ 在任何正交变换（旋转）$O$ 下都是不变的。也就是说，如果 $X' \\sim \\mathcal{N}(0,I_d)$，那么 $OX' \\sim \\mathcal{N}(0,I_d)$。\n\n    ESJD是采样器效率的一个度量。我们将白化空间中的ESJD，$\\mathrm{ESJD}'(C') = \\mathbb{E}\\left[ \\|Y' - X'\\|^2 \\alpha(X',Y') \\right]$，作为效率的衡量标准。在这个空间中的整个采样问题是旋转对称的。如果某个提议协方差 $C'_{\\text{opt}}$ 能最大化这个效率度量（对于一个固定的尺度，例如 $\\det(C')=\\text{constant}$），那么它的任何旋转版本 $O C'_{\\text{opt}} O^{\\top}$ 也必须是最优的。这是因为提议的旋转不会影响从球对称目标进行采样的效率。\n\n    如果我们假设协方差矩阵存在一个唯一的最优形状，那么它必须在所有旋转下保持不变。也就是说，对于所有正交矩阵 $O$，都有 $C'_{\\text{opt}} = O C'_{\\text{opt}} O^{\\top}$。根据舒尔引理 (Schur's Lemma)，一个与所有正交矩阵都可交换的矩阵必须是单位矩阵的标量倍数。因此，白化空间中的最优提议协方差必须形如 $C'_{\\text{opt}} = c I_d$，其中 $c  0$ 是某个标量。对于各向同性的目标，各向同性的提议是最优的。\n\n5.  **变换回原始空间：**\n    既然已经确定 $C'$ 的最优选择是 $c I_d$，我们就可以找到原始空间中对应的最优 $C$：\n    $$\n    C' = \\Sigma^{-1/2} C \\Sigma^{-1/2} = c I_d\n    $$\n    用 $\\Sigma^{1/2}$ 左乘，用 $\\Sigma^{1/2}$ 右乘，我们得到：\n    $$\n    \\Sigma^{1/2}(\\Sigma^{-1/2} C \\Sigma^{-1/2})\\Sigma^{1/2} = \\Sigma^{1/2}(c I_d)\\Sigma^{1/2}\n    $$\n    $$\n    I_d C I_d = c \\Sigma^{1/2}\\Sigma^{1/2}\n    $$\n    $$\n    C = c \\Sigma\n    $$\n    这表明，为了最大化由ESJD衡量的采样器效率，提议协方差 $C$ 必须与目标协方差 $\\Sigma$ 成正比。\n\n### (b)部分：渐近接受率和最优步长\n\n给定高维（$d \\to \\infty$）小步长机制下的提议形式：\n$$\nY = X + \\frac{l}{\\sqrt{d}} \\Sigma^{1/2} Z, \\quad Z \\sim \\mathcal{N}(0,I_{d})\n$$\n接受概率为 $\\alpha(X,Y) = \\min\\{1, \\exp(\\Delta E)\\}$，其中 $\\Delta E = \\log \\pi(Y) - \\log \\pi(X)$。\n\n1.  **$\\Delta E$的推导：**\n    如(a)部分所示，$\\Delta E = -\\frac{1}{2}(\\|Y'\\|^2 - \\|X'\\|^2)$，其中 $X' = \\Sigma^{-1/2}X$ 且 $Y' = \\Sigma^{-1/2}Y$。\n    白化空间中的提议是 $Y' = X' + \\frac{l}{\\sqrt{d}} Z$。\n    将此代入 $\\Delta E$ 的表达式中：\n    $$\n    \\Delta E = -\\frac{1}{2}\\left(\\left\\|X' + \\frac{l}{\\sqrt{d}} Z\\right\\|^2 - \\|X'\\|^2\\right)\n    $$\n    $$\n    = -\\frac{1}{2}\\left(\\|X'\\|^2 + 2\\frac{l}{\\sqrt{d}} X'^{\\top}Z + \\frac{l^2}{d}\\|Z\\|^2 - \\|X'\\|^2\\right)\n    $$\n    $$\n    = -\\frac{l}{\\sqrt{d}} X'^{\\top}Z - \\frac{l^2}{2d}\\|Z\\|^2\n    $$\n\n2.  **渐近行为 ($d \\to \\infty$)：**\n    我们分析 $\\Delta E$ 的极限分布。\n    - 变量 $X'$ 服从 $\\mathcal{N}(0,I_d)$ 分布，因为我们处于平稳机制中。其分量 $X'_i$ 是独立同分布的 $\\mathcal{N}(0,1)$。根据大数定律 (LLN)，$\\frac{1}{d}\\|X'\\|^2 = \\frac{1}{d}\\sum_{i=1}^d (X'_i)^2 \\xrightarrow{p} \\mathbb{E}[(X'_1)^2] = 1$。\n    - 类似地，$Z \\sim \\mathcal{N}(0,I_d)$，所以根据大数定律，$\\frac{1}{d}\\|Z\\|^2 \\xrightarrow{p} 1$。\n    - 考虑项 $W_d = \\frac{1}{\\sqrt{d}}X'^{\\top}Z = \\frac{1}{\\sqrt{d}}\\sum_{i=1}^d X'_i Z_i$。在给定 $X'$ 的条件下，$W_d$ 是一个正态随机变量，均值为 $0$，方差为 $\\frac{1}{d} \\sum_{i=1}^d (X'_i)^2 \\mathrm{Var}(Z_i) = \\frac{1}{d}\\|X'\\|^2$。由于当 $d \\to \\infty$ 时 $\\frac{1}{d}\\|X'\\|^2 \\xrightarrow{p} 1$，$W_d$ 的条件分布收敛于标准正态分布 $\\mathcal{N}(0,1)$。这意味着 $W_d$ 的无条件分布也收敛于 $\\mathcal{N}(0,1)$。我们用 $\\mathcal{G}$ 表示这个极限标准正态变量。\n\n    将这些渐近结果代入 $\\Delta E$ 的表达式中：\n    $$\n    \\Delta E \\xrightarrow{\\mathcal{D}} -l\\mathcal{G} - \\frac{l^2}{2}\n    $$\n    $\\Delta E$ 的极限分布是一个均值为 $-l^2/2$、方差为 $l^2$ 的正态分布。\n\n3.  **渐近接受率 $\\alpha(l)$：**\n    渐近接受率是接受概率关于 $\\Delta E$ 极限分布的期望：\n    $$\n    \\alpha(l) = \\mathbb{E}_{\\mathcal{G}}\\left[\\min\\left\\{1, \\exp\\left(-l\\mathcal{G} - \\frac{l^2}{2}\\right)\\right\\}\\right]\n    $$\n    令 $\\phi(g)$ 为 $\\mathcal{G} \\sim \\mathcal{N}(0,1)$ 的概率密度函数。\n    当指数为负时，表达式 $\\exp(-l\\mathcal{G} - l^2/2)$ 小于1，即 $-l\\mathcal{G} - l^2/2  0$，可简化为 $\\mathcal{G}  -l/2$（因为 $l0$）。\n    我们可以将期望积分拆分为：\n    $$\n    \\alpha(l) = \\int_{-\\infty}^{-l/2} 1 \\cdot \\phi(g) \\,dg + \\int_{-l/2}^{\\infty} \\exp\\left(-lg - \\frac{l^2}{2}\\right) \\phi(g) \\,dg\n    $$\n    第一个积分是标准正态分布的累积分布函数（CDF），即 $\\Phi(-l/2)$。\n    对于第二个积分，我们代入 $\\phi(g) = \\frac{1}{\\sqrt{2\\pi}}\\exp(-g^2/2)$：\n    $$\n    \\int_{-l/2}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-lg - \\frac{l^2}{2} - \\frac{g^2}{2}\\right) \\,dg\n    $$\n    我们在指数部分进行配方：$-(\\frac{g^2}{2} + lg + \\frac{l^2}{2}) = -\\frac{1}{2}(g^2 + 2lg + l^2) = -\\frac{1}{2}(g+l)^2$。\n    积分变为：\n    $$\n    \\int_{-l/2}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{(g+l)^2}{2}\\right) \\,dg\n    $$\n    令 $u = g+l$，则 $du=dg$。积分下限变为 $-l/2 + l = l/2$。\n    $$\n    \\int_{l/2}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{u^2}{2}\\right) \\,du = 1 - \\Phi(l/2)\n    $$\n    利用正态分布的对称性，$1 - \\Phi(z) = \\Phi(-z)$，该积分等于 $\\Phi(-l/2)$。\n    合并两部分，渐近接受率为：\n    $$\n    \\alpha(l) = \\Phi(-l/2) + \\Phi(-l/2) = 2\\Phi(-l/2)\n    $$\n\n4.  **求解 $l$：**\n    题目要求我们找到使标准接受率达到 $0.234$ 的 $l$ 值。\n    $$\n    \\alpha(l) = 2\\Phi(-l/2) = 0.234\n    $$\n    $$\n    \\Phi(-l/2) = \\frac{0.234}{2} = 0.117\n    $$\n    为求解 $l$，我们使用标准正态分布的逆累积分布函数 $\\Phi^{-1}$：\n    $$\n    -l/2 = \\Phi^{-1}(0.117)\n    $$\n    $$\n    l = -2 \\Phi^{-1}(0.117)\n    $$\n    使用统计计算器或软件，我们找到分位数函数的值 $\\Phi^{-1}(0.117) \\approx -1.19015$。\n    因此，\n    $$\n    l \\approx -2 \\times (-1.19015) = 2.3803\n    $$\n    四舍五入到四位有效数字，我们得到 $l \\approx 2.380$。",
            "answer": "$$\\boxed{2.380}$$"
        },
        {
            "introduction": "理论推导为我们提供了渐近接受率 $a(l)$ 和算法“速度函数” $h(l)$ 的表达式，但数值实现能够让我们更直观地理解它们之间的权衡。这项练习要求您编写程序来计算和可视化这些函数，并通过网格搜索找到最大化采样器效率的最优尺度参数 $l$。最大化这个速度函数是至关重要的，因为它与最小化蒙特卡洛估计量的渐近方差直接相关，从而使我们的估计更精确 。",
            "id": "3325139",
            "problem": "考虑马尔可夫链蒙特卡罗 (MCMC) 中的随机游走 Metropolis (RWM) 算法，其目标分布为 $d$ 维标准正态分布，各坐标独立同分布，其密度表示为 $\\pi_d(\\mathbf{x}) \\propto \\exp\\!\\left(-\\frac{1}{2}\\lVert \\mathbf{x} \\rVert^2\\right)$，其中 $\\mathbf{x} \\in \\mathbb{R}^d$。提议的生成方式为 $\\mathbf{Y} = \\mathbf{X} + s \\mathbf{Z}$，其中 $\\mathbf{Z} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I}_d)$ 且与 $\\mathbf{X}$ 独立，$s = \\frac{l}{\\sqrt{d}}$，$l  0$ 是一个无量纲缩放参数。Metropolis 接受概率为 $\\alpha(\\mathbf{X}, \\mathbf{Y}) = \\min\\!\\left\\{1, \\frac{\\pi_d(\\mathbf{Y})}{\\pi_d(\\mathbf{X})}\\right\\}$，且该算法在平稳状态下运行，此时 $\\mathbf{X} \\sim \\pi_d$。\n\n定义渐近接受率函数 $a(l)$ 为在平稳状态下，当 $d \\to \\infty$ 时期望接受概率的极限；定义渐近速度函数 $h(l)$ 为当 $d \\to \\infty$ 时期望平方跳跃距离的极限（经过适当缩放以捕捉扩散极限）。$a(l)$ 和 $h(l)$ 都是无量纲缩放参数 $l$ 的函数。\n\n从上述基本定义（目标分布、提议机制和接受概率）出发，在不使用任何预先给定的优化公式的情况下，推导在高维极限 $d \\to \\infty$ 下出现的 $a(l)$ 和 $h(l)$ 的表达式。然后，实现一个程序，对不同 $l$ 值的这些函数进行数值评估，并找出使 $h(l)$ 最大化的 $l$ 值。最后，通过数值方法确认，在该最大化 $l$ 值下的接受率接近常数 $0.234$。\n\n您的程序必须：\n- 在指定的 $l$ 网格上计算 $a(l)$ 和 $h(l)$。\n- 通过网格搜索找到使 $h(l)$ 最大化的 $l$。\n- 报告在最大化 $l$ 时的接受率。\n- 为指定的接近度或不等式条件提供布尔确认。\n\n测试套件：\n对于以下每种情况，在指定的区间和点数上执行网格搜索，计算在使该网格上 $h(l)$ 最大化的 $l^\\star$ 处的接受率 $a(l^\\star)$，并返回指定的结果。\n\n1. 情况 A（宽范围搜索）：$l \\in [0.01, 10.0]$，使用 $5001$ 个均匀间隔的点。返回接受率 $a(l^\\star)$（浮点数），以及一个布尔值，判断 $\\lvert a(l^\\star) - 0.234 \\rvert \\leq 0.01$ 是否成立。\n2. 情况 B（小步长机制）：$l \\in [0.001, 0.3]$，使用 $1000$ 个点。返回接受率 $a(l^\\star)$（浮点数），以及一个布尔值，判断 $a(l^\\star) \\geq 0.5$ 是否成立。\n3. 情况 C（大步长机制）：$l \\in [5.0, 15.0]$，使用 $1000$ 个点。返回接受率 $a(l^\\star)$（浮点数），以及一个布尔值，判断 $a(l^\\star) \\leq 0.05$ 是否成立。\n4. 情况 D（聚焦搜索）：$l \\in [0.05, 5.0]$，使用 $2000$ 个点。返回接受率 $a(l^\\star)$（浮点数），以及一个布尔值，判断 $\\lvert a(l^\\star) - 0.234 \\rvert \\leq 0.005$ 是否成立。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，按情况 A–D 的顺序排列结果：$[a_A,\\text{close}_A,a_B,\\text{cond}_B,a_C,\\text{cond}_C,a_D,\\text{close}_D]$，其中每个 $a_\\cdot$ 是一个浮点数，每个 $\\text{close}_\\cdot$ 或 $\\text{cond}_\\cdot$ 是一个布尔值。本问题不涉及物理单位或角度。",
            "solution": "用户提供的问题经评估有效。这是一个定义明确、有科学依据的问题，源于马尔可夫链蒙特卡罗方法领域，具体涉及高维随机游走 Metropolis 算法的最优缩放问题。该问题是自洽的，没有矛盾或含糊之处。我现在将进行正式的推导和求解。\n\n目标是推导针对 $d$ 维标准正态分布的随机游走 Metropolis (RWM) 算法的接受率 $a(l)$ 和缩放速度函数 $h(l)$ 的渐近形式，然后对速度进行数值优化。\n\n设 $\\mathbb{R}^d$ 上的目标分布为 $\\pi_d(\\mathbf{x}) = (2\\pi)^{-d/2} \\exp(-\\frac{1}{2}\\lVert \\mathbf{x} \\rVert^2)$。提议由当前状态 $\\mathbf{X}$ 生成，即 $\\mathbf{Y} = \\mathbf{X} + s \\mathbf{Z}$，其中 $\\mathbf{Z} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I}_d)$，步长为 $s = l/\\sqrt{d}$，缩放参数 $l  0$。假设算法处于平稳状态，因此当前状态 $\\mathbf{X}$ 是从目标分布中抽取的样本，即 $\\mathbf{X} \\sim \\pi_d$。\n\nMetropolis 接受概率由 $\\alpha(\\mathbf{X}, \\mathbf{Y}) = \\min\\left\\{1, \\frac{\\pi_d(\\mathbf{Y})}{\\pi_d(\\mathbf{X})}\\right\\}$ 给出。密度比为：\n$$\n\\frac{\\pi_d(\\mathbf{Y})}{\\pi_d(\\mathbf{X})} = \\frac{\\exp(-\\frac{1}{2}\\lVert \\mathbf{Y} \\rVert^2)}{\\exp(-\\frac{1}{2}\\lVert \\mathbf{X} \\rVert^2)} = \\exp\\left(-\\frac{1}{2}(\\lVert \\mathbf{Y} \\rVert^2 - \\lVert \\mathbf{X} \\rVert^2)\\right)\n$$\n我们分析指数中的项 $\\lVert \\mathbf{Y} \\rVert^2 - \\lVert \\mathbf{X} \\rVert^2$。代入提议表达式：\n$$\n\\lVert \\mathbf{Y} \\rVert^2 = \\left\\lVert \\mathbf{X} + \\frac{l}{\\sqrt{d}}\\mathbf{Z} \\right\\rVert^2 = \\left(\\mathbf{X} + \\frac{l}{\\sqrt{d}}\\mathbf{Z}\\right)^T\\left(\\mathbf{X} + \\frac{l}{\\sqrt{d}}\\mathbf{Z}\\right) = \\lVert \\mathbf{X} \\rVert^2 + \\frac{2l}{\\sqrt{d}}\\mathbf{X}^T\\mathbf{Z} + \\frac{l^2}{d}\\lVert \\mathbf{Z} \\rVert^2\n$$\n因此，差值为：\n$$\n\\lVert \\mathbf{Y} \\rVert^2 - \\lVert \\mathbf{X} \\rVert^2 = \\frac{2l}{\\sqrt{d}}\\mathbf{X}^T\\mathbf{Z} + \\frac{l^2}{d}\\lVert \\mathbf{Z} \\rVert^2\n$$\n为了找到当 $d \\to \\infty$ 时的渐近行为，我们检查每一项。\n第一项涉及 $\\mathbf{X}^T\\mathbf{Z} = \\sum_{i=1}^d X_i Z_i$。由于 $\\mathbf{X} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I}_d)$ 和 $\\mathbf{Z} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I}_d)$ 是独立的，它们的分量 $X_i$ 和 $Z_i$ 是独立同分布的标准正态随机变量。乘积的期望为 $\\mathbb{E}[X_i Z_i] = \\mathbb{E}[X_i]\\mathbb{E}[Z_i] = 0 \\cdot 0 = 0$。方差为 $\\text{Var}(X_i Z_i) = \\mathbb{E}[(X_i Z_i)^2] - (\\mathbb{E}[X_i Z_i])^2 = \\mathbb{E}[X_i^2]\\mathbb{E}[Z_i^2] = 1 \\cdot 1 = 1$。\n根据中心极限定理，归一化和依分布收敛于一个标准正态随机变量：\n$$\n\\frac{1}{\\sqrt{d}}\\mathbf{X}^T\\mathbf{Z} = \\frac{1}{\\sqrt{d}}\\sum_{i=1}^d X_i Z_i \\xrightarrow{\\mathcal{D}} W \\sim \\mathcal{N}(0, 1) \\quad \\text{as } d \\to \\infty\n$$\n\n第二项涉及 $\\lVert \\mathbf{Z} \\rVert^2 = \\sum_{i=1}^d Z_i^2$。这是 $d$ 个独立同分布的随机变量 $Z_i^2$ 的和，其中 $Z_i \\sim \\mathcal{N}(0,1)$，因此 $\\mathbb{E}[Z_i^2] = 1$。根据大数定律：\n$$\n\\frac{1}{d}\\lVert \\mathbf{Z} \\rVert^2 = \\frac{1}{d}\\sum_{i=1}^d Z_i^2 \\xrightarrow{p} \\mathbb{E}[Z_1^2] = 1 \\quad \\text{as } d \\to \\infty\n$$\n其中 $\\xrightarrow{p}$ 表示依概率收敛。\n\n令 $\\Delta_d = -\\frac{1}{2}(\\lVert \\mathbf{Y} \\rVert^2 - \\lVert \\mathbf{X} \\rVert^2)$。代入各分量的极限：\n$$\n\\Delta_d = -\\frac{1}{2}\\left(\\frac{2l}{\\sqrt{d}}\\mathbf{X}^T\\mathbf{Z} + \\frac{l^2}{d}\\lVert \\mathbf{Z} \\rVert^2\\right) \\xrightarrow{\\mathcal{D}} -lW - \\frac{l^2}{2} \\quad \\text{as } d \\to \\infty\n$$\n接受概率 $\\alpha_d = \\min\\{1, \\exp(\\Delta_d)\\}$ 是 $\\Delta_d$ 的连续函数。根据连续映射定理，其极限分布为：\n$$\n\\alpha_d \\xrightarrow{\\mathcal{D}} \\alpha(l, W) = \\min\\left\\{1, \\exp\\left(-lW - \\frac{l^2}{2}\\right)\\right\\}\n$$\n渐近接受率 $a(l)$ 是这个极限随机变量关于 $W \\sim \\mathcal{N}(0,1)$ 的期望：\n$$\na(l) = \\mathbb{E}_W\\left[\\min\\left\\{1, \\exp\\left(-lW - \\frac{l^2}{2}\\right)\\right\\}\\right]\n$$\n当指数为负时，即 $-lW - l^2/2  0$ 时，最小值内的表达式小于 1，对于 $l0$ 这等价于 $W  -l/2$。我们在实数线上对期望进行分段：\n$$\na(l) = \\int_{-\\infty}^{-l/2} 1 \\cdot \\phi(w) \\,dw + \\int_{-l/2}^{\\infty} \\exp\\left(-lw - \\frac{l^2}{2}\\right) \\phi(w) \\,dw\n$$\n其中 $\\phi(w) = (2\\pi)^{-1/2}\\exp(-w^2/2)$ 是标准正态概率密度函数（PDF）。\n第一个积分是标准正态累积分布函数（CDF）的定义，即 $\\Phi(-l/2)$。\n对于第二个积分，我们对指数进行配方：\n$$\n-lw - \\frac{l^2}{2} - \\frac{w^2}{2} = -\\frac{1}{2}(w^2 + 2lw + l^2) = -\\frac{1}{2}(w+l)^2\n$$\n积分变为：\n$$\n\\int_{-l/2}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{(w+l)^2}{2}\\right) \\,dw\n$$\n令 $u = w+l$，则 $du = dw$。积分下限变为 $-l/2 + l = l/2$。根据正态分布的对称性，该积分为 $\\int_{l/2}^{\\infty} \\phi(u) \\,du = 1 - \\Phi(l/2) = \\Phi(-l/2)$。\n结合这两个部分，我们得到渐近接受率：\n$$\na(l) = \\Phi(-l/2) + \\Phi(-l/2) = 2\\Phi(-l/2)\n$$\n\n接下来，我们定义渐近速度函数 $h(l)$。这是算法效率的一种度量，定义为（经过缩放的）期望平方跳跃距离（ESJD）。跳跃是 $\\mathbf{X}_{k+1} - \\mathbf{X}_k$。如果提议被接受，则为 $\\mathbf{Y} - \\mathbf{X} = s\\mathbf{Z}$；如果被拒绝，则为 $\\mathbf{0}$。\n$$\n\\text{ESJD}_d = \\mathbb{E}[\\lVert \\mathbf{X}_{k+1} - \\mathbf{X}_k \\rVert^2] = \\mathbb{E}[\\alpha(\\mathbf{X}, \\mathbf{Y}) \\lVert s\\mathbf{Z} \\rVert^2]\n$$\n此处，$\\mathbf{X}$ 是平稳状态下的状态。由于 $\\mathbf{Z}$ 与 $\\mathbf{X}$ 独立，我们可以分离期望：\n$$\n\\text{ESJD}_d = \\mathbb{E}[\\alpha(\\mathbf{X}, \\mathbf{Y})] \\cdot \\mathbb{E}[s^2 \\lVert \\mathbf{Z} \\rVert^2] = \\mathbb{E}[\\alpha(\\mathbf{X}, \\mathbf{Y})] \\cdot \\frac{l^2}{d} \\cdot d = l^2 \\mathbb{E}[\\alpha(\\mathbf{X}, \\mathbf{Y})]\n$$\n量 $\\mathbb{E}[\\alpha(\\mathbf{X}, \\mathbf{Y})]$ 是有限维度 $d$ 的期望接受率。在极限 $d \\to \\infty$ 下，它收敛于 $a(l)$。因此，极限 ESJD，我们称之为速度函数 $h(l)$，是：\n$$\nh(l) = l^2 a(l) = 2l^2\\Phi(-l/2)\n$$\n这个函数 $h(l)$ 代表了在提出大方差提议（大的 $l^2$）和使其被接受（大的 $a(l)$）之间的权衡。为了优化 RWM 算法在高维下的性能，必须找到使 $h(l)$ 最大化的 $l$ 值，记为 $l^\\star$。这个优化问题通常通过数值方法求解。相应的接受率 $a(l^\\star)$ 是此类问题的一个通用常数，已知约为 $0.234$。\n\n计算任务是实现函数 $a(l)$ 和 $h(l)$，在指定的 $l$ 区间上执行网格搜索，找到 $h(l)$ 的近似最大化因子 $l^\\star$，并报告接受率 $a(l^\\star)$ 以及其他指定的逻辑条件。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Analyzes the optimal scaling of the Random-Walk Metropolis algorithm.\n\n    This function implements the derived asymptotic acceptance rate a(l) and\n    speed function h(l) for the RWM algorithm in high dimensions. It performs\n    a grid search to find the scaling parameter l that maximizes the speed\n    for different regimes, and reports the corresponding acceptance rates\n    and boolean checks as per the problem specification.\n    \"\"\"\n    \n    # Test cases defined in the problem statement\n    # Each case is a tuple: (l_min, l_max, num_points, check_type, check_value, check_tol)\n    # check_type: 1 for |a - val| = tol, 2 for a >= val, 3 for a = val\n    test_cases = [\n        # Case A: Wide search\n        (0.01, 10.0, 5001, 1, 0.234, 0.01),\n        # Case B: Small-step regime\n        (0.001, 0.3, 1000, 2, 0.5, None),\n        # Case C: Large-step regime\n        (5.0, 15.0, 1000, 3, 0.05, None),\n        # Case D: Focused search\n        (0.05, 5.0, 2000, 1, 0.234, 0.005),\n    ]\n\n    results = []\n\n    for case in test_cases:\n        l_min, l_max, num_points, check_type, check_val, check_tol = case\n\n        # Create the grid of l values\n        l_grid = np.linspace(l_min, l_max, num_points, dtype=np.float64)\n\n        # Calculate the asymptotic acceptance rate a(l)\n        # a(l) = 2 * Phi(-l/2), where Phi is the standard normal CDF.\n        a_values = 2.0 * norm.cdf(-l_grid / 2.0)\n\n        # Calculate the asymptotic speed function h(l)\n        # h(l) = l^2 * a(l)\n        h_values = l_grid**2 * a_values\n\n        # Find the index of the maximum value of h(l) on the grid\n        idx_max = np.argmax(h_values)\n\n        # Get the acceptance rate at the l that maximizes h(l)\n        a_star = a_values[idx_max]\n        results.append(a_star)\n\n        # Perform the boolean check for the current case\n        if check_type == 1:\n            # Check if |a_star - check_val| = check_tol\n            condition_met = np.abs(a_star - check_val) = check_tol\n        elif check_type == 2:\n            # Check if a_star >= check_val\n            condition_met = a_star >= check_val\n        elif check_type == 3:\n            # Check if a_star = check_val\n            condition_met = a_star = check_val\n        \n        results.append(condition_met)\n\n    # Format the results into the required string format\n    # [a_A, close_A, a_B, cond_B, a_C, cond_C, a_D, close_D]\n    final_output_str = f\"[{','.join(map(str, results))}]\"\n    print(final_output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "标准的最优尺度理论通常假设提议分布具有有限方差（如高斯分布）。本次练习将挑战这一假设，引导您探索当使用重尾的柯西分布作为提议分布时会发生什么。您将分析并确定在这种情况下如何调整提议尺度以防止接受率退化到$0$或$1$，从而揭示提议分布的尾部行为如何从根本上改变必要的尺度定律 。",
            "id": "3325133",
            "problem": "考虑一个随机游走 Metropolis (RWM) 算法，其目标分布为 $d$ 维乘积标准正态分布，密度为 $\\pi_{d}(x) \\propto \\exp\\!\\left(-\\|x\\|^{2}/2\\right)$，其中 $x \\in \\mathbb{R}^{d}$ 且 $\\|x\\|$ 表示欧几里得范数。提议的形式为 $Y = X + s_{d} Z$，其中 $X \\sim \\pi_{d}$ 是当前状态，$Z = (Z_{1},\\dots,Z_{d})$ 的分量是独立同分布的标准柯西分布随机变量，并且 $s_{d}  0$ 是一个与维度相关的尺度参数。Metropolis 步骤的接受概率为\n$$\n\\alpha(X,Y) = \\min\\!\\left\\{1, \\frac{\\pi_{d}(Y)}{\\pi_{d}(X)}\\right\\}.\n$$\n假设链处于平稳状态，因此 $X \\sim \\pi_{d}$ 且 $X$ 与 $Z$ 独立。定义期望平方跳跃距离 (ESJD) 为\n$$\n\\mathrm{ESJD}_{d}(s_{d}) := \\mathbb{E}\\!\\left[\\|Y - X\\|^{2} \\, \\alpha(X,Y)\\right] = \\mathbb{E}\\!\\left[s_{d}^{2} \\, \\|Z\\|^{2} \\, \\alpha\\!\\left(X, X + s_{d} Z\\right)\\right].\n$$\n\n假设 $s_{d}$ 参数化为 $s_{d} = \\ell \\, d^{-a}$，其中 $\\ell \\in (0,\\infty)$ 为某个固定常数，指数 $a \\in \\mathbb{R}$。仅使用 Metropolis 接受机制的基本定义和关于重尾分布的成熟结论（例如标准柯西定律的渐近尾部行为），确定唯一的指数 $a$，以防止在大 $d$ 极限下出现退化接受，即接受概率不收敛于 $0$ 或 $1$。然后，在此尺度下，确定指数 $b$，使得当 $d \\to \\infty$ 时，$\\mathrm{ESJD}_{d}(s_{d})$ 的尺度与 $d^{b}$ 相当。\n\n最终答案仅报告数对 $(a,b)$，格式为行矩阵。无需数值舍入。",
            "solution": "用户希望我解决一个关于随机游走 Metropolis (RWM) 算法最优尺度的问题。该问题涉及确定两个与算法在高维环境下的行为相关的尺度指数 $a$ 和 $b$。\n\n### 步骤 1：验证问题陈述\n\n首先，我将按照要求的程序验证问题陈述。\n\n**1. 提取已知条件：**\n- 目标分布：$d$ 维乘积标准正态分布，$\\pi_{d}(x) \\propto \\exp(-\\|x\\|^{2}/2)$，对于 $x \\in \\mathbb{R}^{d}$。\n- 提议机制：$Y = X + s_{d} Z$。\n- 当前状态：$X \\sim \\pi_{d}$。\n- 提议噪声：$Z = (Z_{1},\\dots,Z_{d})$，其中 $Z_i$ 是独立同分布 (i.i.d.) 的标准柯西随机变量。\n- 尺度参数：$s_{d}  0$。\n- 接受概率：$\\alpha(X,Y) = \\min\\{1, \\frac{\\pi_{d}(Y)}{\\pi_{d}(X)}\\}$。\n- 平稳性假设：$X \\sim \\pi_{d}$ 且 $X$ 与 $Z$ 独立。\n- 关注量：期望平方跳跃距离 (ESJD)，定义为 $\\mathrm{ESJD}_{d}(s_{d}) = \\mathbb{E}[\\|Y - X\\|^{2} \\alpha(X,Y)] = \\mathbb{E}[s_{d}^{2} \\|Z\\|^{2} \\alpha(X, X + s_{d} Z)]$。\n- 尺度参数化：$s_{d} = \\ell d^{-a}$，其中固定常数 $\\ell \\in (0,\\infty)$，指数 $a \\in \\mathbb{R}$。\n- **目标 1：** 确定唯一的指数 $a$，确保接受概率在 $d \\to \\infty$ 时不收敛到 $0$ 或 $1$。\n- **目标 2：** 在确定的 $a$ 值下，找到指数 $b$，使得当 $d$ 很大时，$\\mathrm{ESJD}_{d}(s_{d})$ 的尺度为 $d^{b}$。\n\n**2. 验证分析：**\n- **科学依据：** 该问题设置在马尔可夫链蒙特卡洛 (MCMC) 方法的背景下，这是现代统计学和计算科学的基石。目标分布（标准多维正态分布）和提议机制（使用柯西增量的随机游走）是标准的，尽管选择柯西分布比高斯分布少见，并且由于其重尾特性而引入了特定的技术挑战。高维极限下的最优尺度和非退化接受率的概念是 MCMC 理论的核心研究课题。该问题在科学上和数学上都是合理的。\n- **适定性：** 问题清晰地定义了目标、算法和要分析的量。它要求基于一个明确定义的渐近准则（非退化极限）来确定特定的指数。这种结构导向一个唯一且有意义的解。\n- **客观性：** 问题以精确、形式化的数学语言陈述，没有任何主观性或歧义。\n- **结论：** 问题是有效的。这是一个在随机模拟领域内适定、有科学依据且形式化陈述的问题。我将着手解决它。\n\n### 步骤 2：推导尺度指数 $a$\n\n接受概率由 $\\alpha(X, Y) = \\min\\{1, R\\}$ 给出，其中密度比 $R$ 为：\n$$R = \\frac{\\pi_{d}(Y)}{\\pi_{d}(X)} = \\frac{\\exp(-\\|Y\\|^2/2)}{\\exp(-\\|X\\|^2/2)} = \\exp\\left(-\\frac{1}{2}(\\|Y\\|^2 - \\|X\\|^2)\\right)$$\n代入 $Y = X + s_{d}Z$，平方范数的变化为：\n$$ \\|Y\\|^2 - \\|X\\|^2 = \\|X + s_{d}Z\\|^2 - \\|X\\|^2 = (\\|X\\|^2 + 2s_d(X \\cdot Z) + s_d^2\\|Z\\|^2) - \\|X\\|^2 = 2s_d(X \\cdot Z) + s_d^2\\|Z\\|^2 $$\n因此，比率 $R$ 中指数函数的参数为：\n$$ \\Delta_d := -\\frac{1}{2}(2s_d(X \\cdot Z) + s_d^2\\|Z\\|^2) = -s_d(X \\cdot Z) - \\frac{1}{2}s_d^2\\|Z\\|^2 $$\n为使接受概率在 $(0, 1)$ 内有一个非退化的极限，当 $d \\to \\infty$ 时，量 $\\Delta_d$ 必须在分布上收敛到一个非退化的随机变量。我们必须分析 $\\Delta_d$ 中两项的渐近行为。\n\n1.  **$\\|Z\\|^2$ 的分析：**\n    分量 $Z_i$ 是独立同分布的标准柯西变量。平方 $W_i = Z_i^2$ 具有重尾。标准柯西变量的尾概率对于大的 $z$ 是 $P(|Z_1|  z) \\sim 2/(\\pi z)$。因此，对于 $w  0$：\n    $$ P(W_1  w) = P(|Z_1|  \\sqrt{w}) \\sim \\frac{2}{\\pi\\sqrt{w}} $$\n    这是一个指数为 $-1/2$ 的正则变化尾。对于具有指数为 $-\\beta$ (其中 $\\beta \\in (0, 2)$) 的正则变化尾的独立同分布随机变量之和，其和的尺度为 $d^{1/\\beta}$。这里 $\\beta = 1/2$，所以尺度为 $d^{1/(1/2)} = d^2$。更形式化地说，$\\|Z\\|^2 = \\sum_{i=1}^d Z_i^2$ 处于指数为 $1/2$ 的稳定律的吸引域中，我们有如下尺度关系：\n    $$ \\frac{1}{d^2} \\|Z\\|^2 \\xrightarrow{\\mathcal{D}} W $$\n    其中 $W$ 是一个正的 $1/2$-稳定随机变量。这意味着 $\\|Z\\|^2 = O_p(d^2)$。\n\n2.  **$X \\cdot Z$ 的分析：**\n    该项为 $X \\cdot Z = \\sum_{i=1}^d X_i Z_i$。加数 $U_i = X_iZ_i$ 是独立同分布的，$X_i \\sim \\mathcal{N}(0,1)$ 和 $Z_i \\sim \\text{Cauchy}(0,1)$ 是独立的。我们通过以 $X=(X_1, \\dots, X_d)$ 为条件来分析这个和。$cZ_1$ 的特征函数是 $\\exp(-|c| |t|)$。\n    $$ \\mathbb{E}[\\exp(it(X \\cdot Z)) | X=x] = \\mathbb{E}\\left[\\exp\\left(it \\sum x_i Z_i\\right)\\right] = \\prod_{i=1}^d \\mathbb{E}[\\exp(itx_i Z_i)] = \\prod_{i=1}^d \\exp(-|t x_i|) = \\exp\\left(-|t|\\sum_{i=1}^d |x_i|\\right) $$\n    这是尺度参数为 $\\sum_{i=1}^d |x_i|$ 的柯西分布的特征函数。根据大数定律，当 $d \\to \\infty$ 时：\n    $$ \\frac{1}{d} \\sum_{i=1}^d |X_i| \\xrightarrow{p} \\mathbb{E}[|X_1|] = \\int_{-\\infty}^{\\infty} |x| \\frac{e^{-x^2/2}}{\\sqrt{2\\pi}} dx = 2 \\int_{0}^{\\infty} x \\frac{e^{-x^2/2}}{\\sqrt{2\\pi}} dx = \\sqrt{\\frac{2}{\\pi}} $$\n    所以，对于大的 $d$，$X \\cdot Z$ 的行为类似于一个尺度参数为 $d$ 阶的柯西随机变量。这意味着 $X \\cdot Z = O_p(d)$。\n\n现在，将 $s_d = \\ell d^{-a}$ 和数量级代入 $\\Delta_d$：\n$$ \\Delta_d = -(\\ell d^{-a}) O_p(d) - \\frac{1}{2}(\\ell^2 d^{-2a}) O_p(d^2) = -\\ell O_p(d^{1-a}) - \\frac{\\ell^2}{2} O_p(d^{2-2a}) $$\n由于 $d^{2-2a} = (d^{1-a})^2$，两项都以 $d$ 的相同次幂进行缩放。为了使 $\\Delta_d$ 收敛到一个非退化的随机变量，其数量级必须是 $O_p(1)$。这要求 $d$ 的指数为零。\n$$ 1-a=0 \\implies a=1 $$\n如果 $a1$，$\\Delta_d \\to 0$ 且接受概率收敛到 $1$。如果 $a1$，$\\Delta_d$ 在概率上收敛到 $-\\infty$，且接受概率收敛到 $0$。因此，唯一能产生非平凡极限的尺度是 $a=1$。\n\n### 步骤 3：推导尺度指数 $b$\n\n当 $a=1$ 时，尺度参数为 $s_d = \\ell/d$。期望平方跳跃距离 (ESJD) 为：\n$$ \\mathrm{ESJD}_d = \\mathbb{E}[s_d^2 \\|Z\\|^2 \\alpha(X, X+s_d Z)] $$\n代入 $s_d = \\ell/d$ 并重新整理：\n$$ \\mathrm{ESJD}_d = \\left(\\frac{\\ell}{d}\\right)^2 \\mathbb{E}[\\|Z\\|^2 \\alpha(X, Z)] = \\ell^2 \\mathbb{E}\\left[\\frac{\\|Z\\|^2}{d^2} \\cdot \\alpha(X, Z)\\right] $$\n我们现在分析当 $d \\to \\infty$ 时期望内部各项的渐近行为。\n从步骤2我们知道，归一化的平方范数 $\\|Z\\|^2/d^2$ 在分布上收敛到一个正的 $1/2$-稳定随机变量 $W$：\n$$ W_d := \\frac{\\|Z\\|^2}{d^2} \\xrightarrow{\\mathcal{D}} W $$\n同样，对数密度比 $\\Delta_d = -s_d(X \\cdot Z) - \\frac{1}{2}s_d^2\\|Z\\|^2$ 变为：\n$$ \\Delta_d = -\\ell \\left(\\frac{X \\cdot Z}{d}\\right) - \\frac{\\ell^2}{2} \\left(\\frac{\\|Z\\|^2}{d^2}\\right) $$\n当 $d \\to \\infty$ 时，第一项 $\\frac{X \\cdot Z}{d}$ 收敛于一个柯西类型的分布，而第二项 $\\frac{\\|Z\\|^2}{d^2}$ 收敛于稳定变量 $W$。因此，$\\Delta_d$ 在分布上收敛到一个非退化的随机变量 $\\Delta_\\infty$。\n接受概率 $\\alpha(X, Z) = \\min\\{1, \\exp(\\Delta_d)\\}$ 是 $\\Delta_d$ 的连续函数，因此它也依分布收敛到一个非退化的极限 $\\alpha_\\infty = \\min\\{1, \\exp(\\Delta_\\infty)\\}$。\n$$ \\alpha_d := \\alpha(X, Z) \\xrightarrow{\\mathcal{D}} \\alpha_\\infty $$\n整个被积函数 $Q_d = \\frac{\\|Z\\|^2}{d^2} \\cdot \\alpha(X, Z)$ 是两个依分布收敛的随机变量的乘积（虽然它们不是独立的）。根据斯卢茨基定理的推广，乘积 $Q_d$ 依分布收敛于 $Q_\\infty = W \\cdot \\alpha_\\infty$。\n$$ Q_d \\xrightarrow{\\mathcal{D}} Q_\\infty $$\n为了使期望的极限等于极限的期望，即 $\\lim_{d\\to\\infty} \\mathbb{E}[Q_d] = \\mathbb{E}[Q_\\infty]$，我们需要证明 $\\{Q_d\\}$ 序列是一致可积的。由于 $\\alpha(X,Z)$ 总是有界的（$0 \\leq \\alpha \\leq 1$），我们只需要关注 $\\|Z\\|^2/d^2$ 的行为。因为 $\\|Z\\|^2/d^2$ 依分布收敛，其各阶矩也收敛（这是一个关于稳定分布收敛的较强结果，在此我们可以合理假设其成立）。这保证了一致可积性。\n因此，$\\mathrm{ESJD}_d$ 收敛到一个与 $d$ 无关的正常数：\n$$ \\lim_{d\\to\\infty} \\mathrm{ESJD}_d = \\ell^2 \\mathbb{E}[Q_\\infty] = \\ell^2 \\mathbb{E}[W \\cdot \\alpha_\\infty] = \\text{常数}  0 $$\n这表明，对于大的 $d$，$\\mathrm{ESJD}_d$ 的尺度为 $d^0$。因此，尺度指数是 $b=0$。\n\n### 步骤 4：最终答案\n\n尺度参数的指数是 $a=1$。ESJD 的渐近尺度指数是 $b=0$。数对为 $(a,b) = (1,0)$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1  0\n\\end{pmatrix}\n}\n$$"
        }
    ]
}