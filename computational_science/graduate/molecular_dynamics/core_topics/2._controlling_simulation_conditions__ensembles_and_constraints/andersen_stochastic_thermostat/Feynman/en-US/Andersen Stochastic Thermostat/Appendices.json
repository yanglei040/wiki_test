{
    "hands_on_practices": [
        {
            "introduction": "The cornerstone of the Andersen thermostat is its ability to enforce a target temperature by stochastically resampling particle velocities from the correct thermal distribution. This exercise guides you through the fundamental implementation of this process, starting from the first principles of the Maxwell-Boltzmann distribution for particles with varying masses. By coding the velocity sampler and implementing a rigorous chi-square statistical test, you will gain hands-on experience in both generating and validating the canonical ensemble, a critical skill for any simulation practitioner.",
            "id": "3395469",
            "problem": "You are to design and implement an explicit sampling and verification procedure for the Andersen stochastic thermostat in molecular dynamics. The task consists of two parts: (i) sampling Maxwell–Boltzmann velocities for particles with heterogeneous masses, and (ii) implementing a statistically rigorous test that verifies whether sampled velocity components have the correct variance implied by thermodynamic equilibrium. Your final output must be produced by a single complete program as specified below.\n\nThe foundation of the task must be derived from first principles. Use the canonical ensemble at fixed temperature as the base. Begin from the fundamental facts that, for a single particle of mass $m$ at absolute temperature $T$, the canonical momentum distribution factorizes, and each Cartesian velocity component $v_{\\alpha}$ for $\\alpha \\in \\{x,y,z\\}$ is independent with a Gaussian density proportional to $\\exp\\!\\big(-\\beta \\tfrac{1}{2} m v_{\\alpha}^{2}\\big)$, where $\\beta = 1/(k_{B} T)$ and $k_{B}$ is the Boltzmann constant. Do not assume any pre-derived sampling formula beyond these principles. Justify every step of your algorithmic design using these principles.\n\nYou must incorporate the Andersen stochastic thermostat process. In the Andersen thermostat, each particle undergoes stochastic collisions according to a Poisson process of rate $\\nu$ (collisions per second). Over a discrete time step of duration $\\Delta t$, the probability that a particle experiences at least one collision is $p = 1 - \\exp(-\\nu \\Delta t)$. If a collision occurs, the particle’s Cartesian velocity components are instantaneously re-drawn from the Maxwell–Boltzmann distribution at the target temperature $T$; otherwise, the velocity remains unchanged.\n\nYour program must:\n- Implement a function that samples velocities for $N$ particles with heterogeneous masses, i.e., distinct $m_{i}$ for $i=1,\\dots,N$, at temperature $T$. Use three dimensions unless otherwise specified by a test. The sample for particle $i$ must have independent components with zero mean and variance $k_{B} T / m_{i}$.\n- Implement a single-step Andersen thermostat update that, given the current velocities, applies independent Bernoulli collisions with probability $p = 1 - \\exp(-\\nu \\Delta t)$ to each particle. For collided particles, reassign their velocities from the Maxwell–Boltzmann distribution corresponding to their own masses and the target temperature $T$.\n- Implement a statistical test that verifies the variance condition implied by the Maxwell–Boltzmann distribution. Specifically, given a sample of velocities $\\{v_{i,\\alpha}\\}$, masses $\\{m_{i}\\}$, and a temperature $T$, define the standardized components $z_{i,\\alpha} = v_{i,\\alpha} \\sqrt{m_{i}/(k_{B} T)}$. Under the correct Maxwell–Boltzmann distribution, the $z_{i,\\alpha}$ are independent standard normal random variables. Therefore, the statistic\n$$\nS = \\sum_{i=1}^{N} \\sum_{\\alpha=1}^{d} z_{i,\\alpha}^{2}\n$$\nhas a chi-square distribution with $dN$ degrees of freedom under the null hypothesis that the variance equals $k_{B} T / m_{i}$. Your test must implement a two-sided chi-square acceptance criterion at a user-specified significance level $\\alpha$ by checking whether $S$ lies between the $\\alpha/2$ and $1-\\alpha/2$ quantiles of the chi-square distribution with $dN$ degrees of freedom.\n\nUnits:\n- Masses $m_{i}$ must be provided in kilograms $\\mathrm{kg}$.\n- Temperature $T$ must be in kelvin $\\mathrm{K}$.\n- Boltzmann constant $k_{B}$ must be used in the value $k_{B} = 1.380649 \\times 10^{-23}\\,\\mathrm{J/K}$.\n- The algorithm must output velocities in meters per second $\\mathrm{m/s}$.\n- Time step $\\Delta t$ must be in seconds $\\mathrm{s}$, and collision rate $\\nu$ in $\\mathrm{s}^{-1}$.\n\nYour program must run the following test suite. For each test case, return a boolean indicating whether the chi-square variance test accepts the null hypothesis at significance level $\\alpha = 0.05$.\n\n- Test case $1$ (heterogeneous masses, general case):\n  - $N = 2000$, $d = 3$.\n  - Temperature $T = 300\\,\\mathrm{K}$.\n  - Masses are independently drawn with equal probability from the set $\\{28, 40, 84\\}$ unified atomic mass units, converted to kilograms by multiplying each atomic mass unit by $1.66053906660 \\times 10^{-27}\\,\\mathrm{kg}$. That is, available masses are $28\\,\\mathrm{u}$, $40\\,\\mathrm{u}$, and $84\\,\\mathrm{u}$ in $\\mathrm{kg}$.\n  - Sample fresh Maxwell–Boltzmann velocities and perform the chi-square variance test.\n  - Use a fixed random seed to ensure determinism.\n\n- Test case $2$ (moderate sample size with wide mass heterogeneity):\n  - $N = 90$, $d = 3$.\n  - Temperature $T = 1000\\,\\mathrm{K}$.\n  - Masses are linearly spaced between $1\\,\\mathrm{u}$ and $100\\,\\mathrm{u}$ across the $N$ particles, converted to $\\mathrm{kg}$.\n  - Sample fresh Maxwell–Boltzmann velocities and perform the chi-square variance test.\n  - Use a fixed random seed to ensure determinism.\n\n- Test case $3$ (Andersen thermostat thermalization over multiple steps):\n  - $N = 1000$, $d = 3$.\n  - Temperature $T = 500\\,\\mathrm{K}$.\n  - Masses are drawn independently and uniformly from the interval $[10\\,\\mathrm{u}, 50\\,\\mathrm{u}]$, converted to $\\mathrm{kg}$.\n  - Initialize all velocities to zero.\n  - Apply $100$ Andersen steps with collision rate $\\nu = 2 \\times 10^{14}\\,\\mathrm{s}^{-1}$ and time step $\\Delta t = 1 \\times 10^{-15}\\,\\mathrm{s}$.\n  - Perform the chi-square variance test on the final velocities.\n  - Use a fixed random seed to ensure determinism.\n\n- Test case $4$ (negative control to detect incorrect variance):\n  - $N = 1500$, $d = 2$.\n  - Temperature $T = 400\\,\\mathrm{K}$.\n  - All masses equal to $20\\,\\mathrm{u}$ in $\\mathrm{kg}$.\n  - Sample Maxwell–Boltzmann velocities and then multiply all velocity components by a factor of $1.5$.\n  - Perform the chi-square variance test; it should reject the null hypothesis with high probability.\n  - Use a fixed random seed to ensure determinism.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $[r_{1},r_{2},r_{3},r_{4}]$, where each $r_{i}$ is a boolean indicating the acceptance or rejection of the variance test for test case $i$.\n\nYour program must be entirely self-contained and require no input. All random choices must be controlled by explicit fixed seeds to ensure deterministic output. The only permitted libraries are the Python standard library, NumPy, and SciPy.",
            "solution": "The task is to design and implement a procedure for sampling particle velocities from a Maxwell–Boltzmann distribution and to verify the correctness of the sample using a statistical test based on the chi-square distribution. This procedure is central to the Andersen stochastic thermostat used in molecular dynamics simulations. The entire process, from sampling to verification, will be derived from the principles of statistical mechanics.\n\n### 1. Theoretical Foundation: Maxwell–Boltzmann Velocity Distribution\n\nIn the canonical ensemble, a system of $N$ particles in volume $V$ is in thermal contact with a heat bath at a constant absolute temperature $T$. The probability of finding the system in a microstate with energy $E$ is proportional to the Boltzmann factor, $\\exp(-\\beta E)$, where $\\beta = 1/(k_{B} T)$ and $k_{B}$ is the Boltzmann constant.\n\nFor a classical system of non-interacting particles (or where potential energy is independent of momentum), the total kinetic energy is the sum of individual particle kinetic energies, $E_K = \\sum_{i=1}^{N} \\frac{\\mathbf{p}_i^2}{2m_i}$, where $\\mathbf{p}_i = m_i \\mathbf{v}_i$ is the momentum of particle $i$ with mass $m_i$. The phase space probability distribution for momenta factorizes, meaning the momentum of each particle is independent of the others. Furthermore, for a single particle, the distribution for each Cartesian component of momentum is independent. The probability density for a single velocity component, say $v_{i,\\alpha}$ for particle $i$ and component $\\alpha \\in \\{x,y,z\\}$, is derived from the kinetic energy term $\\frac{1}{2} m_i v_{i,\\alpha}^2$.\n\nThe probability density function (PDF) for $v_{i,\\alpha}$ is given by:\n$$\nf(v_{i,\\alpha}) \\propto \\exp\\left(-\\beta \\frac{1}{2} m_i v_{i,\\alpha}^2\\right) = \\exp\\left(-\\frac{m_i v_{i,\\alpha}^2}{2 k_B T}\\right)\n$$\nThis is the functional form of a Gaussian (normal) distribution with a mean of $\\mu = 0$ and a variance of $\\sigma^2$. A general Gaussian PDF is $N(\\mu, \\sigma^2) \\propto \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$. By comparing the two forms, we identify the mean as $\\mu=0$ and the variance as:\n$$\n\\sigma_{i}^2 = \\frac{k_B T}{m_i}\n$$\nThus, at thermal equilibrium, each Cartesian velocity component $v_{i,\\alpha}$ of a particle with mass $m_i$ is an independent random variable drawn from a normal distribution $N(0, k_B T / m_i)$.\n\n### 2. Algorithmic Design: Velocity Sampling\n\nTo sample a velocity component $v_{i,\\alpha}$ from the distribution $N(0, k_B T / m_i)$, we can use the property that if $Z$ is a standard normal random variable, $Z \\sim N(0,1)$, then $X = \\mu + \\sigma Z$ is a normal random variable $X \\sim N(\\mu, \\sigma^2)$. In our case, $\\mu=0$ and $\\sigma_i = \\sqrt{k_B T / m_i}$. Therefore, a sample for $v_{i,\\alpha}$ can be generated as:\n$$\nv_{i,\\alpha} = \\sqrt{\\frac{k_B T}{m_i}} \\times Z_{i,\\alpha}\n$$\nwhere each $Z_{i,\\alpha}$ is an independent sample from the standard normal distribution $N(0,1)$. Computationally, standard normal variates can be efficiently generated using established algorithms (e.g., Box-Muller transform, Ziggurat algorithm), which are readily available in numerical libraries like `numpy`.\n\nThe sampling procedure for a system of $N$ particles in $d$ dimensions is as follows:\n1.  For each particle $i=1, \\dots, N$ with mass $m_i$, calculate its velocity standard deviation $\\sigma_i = \\sqrt{k_B T / m_i}$.\n2.  Generate a matrix of $N \\times d$ independent random numbers from the standard normal distribution $N(0,1)$. Let this matrix be $\\mathbf{Z}$, with elements $Z_{i,\\alpha}$.\n3.  The velocity matrix $\\mathbf{V}$ with elements $v_{i,\\alpha}$ is then computed by scaling each row corresponding to particle $i$ by its respective $\\sigma_i$. In practice, this can be done by element-wise multiplication of the matrix $\\mathbf{Z}$ with a column vector of standard deviations broadcast across the dimensions.\n\n### 3. Algorithmic Design: Andersen Thermostat\n\nThe Andersen thermostat maintains the temperature of a system by modeling stochastic collisions with a virtual heat bath. The process is modeled as a series of independent events for each particle.\n- Over a small time step $\\Delta t$, each particle has a probability $p$ of undergoing a \"collision\". These collision events follow a Poisson process with a given rate $\\nu$. The probability of at least one collision occurring in $\\Delta t$ is $p = 1 - \\exp(-\\nu \\Delta t)$.\n- If a particle is selected for a collision, its velocity is discarded and replaced with a new velocity drawn from the Maxwell–Boltzmann distribution at the target temperature $T$, using the sampling procedure described above.\n- If a particle is not selected, its velocity evolves according to the system's dynamics (which, in the context of only applying the thermostat, means its velocity remains unchanged).\n\nA single step of the Andersen thermostat algorithm proceeds as follows:\n1.  For each particle $i=1, \\dots, N$, draw a random number $u_i$ from a uniform distribution on $[0,1)$.\n2.  If $u_i  p$, where $p = 1 - \\exp(-\\nu \\Delta t)$, particle $i$ is marked for collision.\n3.  For all marked particles, resample their velocities $\\mathbf{v}_i = (v_{i,x}, v_{i,y}, v_{i,z})$ from the Maxwell–Boltzmann distribution $N(0, k_B T / m_i)$ for each component, as detailed in Section 2.\n4.  Velocities of unmarked particles remain unchanged.\n\n### 4. Statistical Verification: Chi-Square Test for Variance\n\nTo verify that the sampled velocities correctly obey the Maxwell–Boltzmann statistics, we can test if the variance of the velocity components matches the theoretical value $\\sigma_i^2 = k_B T / m_i$. A robust way to do this is a chi-square test.\n\nFirst, we standardize the sampled velocity components. A standardized variable is created by subtracting the mean and dividing by the standard deviation. For a velocity component $v_{i,\\alpha}$, the corresponding standardized variable $z_{i,\\alpha}$ is:\n$$\nz_{i,\\alpha} = \\frac{v_{i,\\alpha} - \\mu_i}{\\sigma_i} = \\frac{v_{i,\\alpha} - 0}{\\sqrt{k_B T/m_i}} = v_{i,\\alpha} \\sqrt{\\frac{m_i}{k_B T}}\n$$\nUnder the null hypothesis that $v_{i,\\alpha}$ is correctly drawn from $N(0, k_B T / m_i)$, each $z_{i,\\alpha}$ is an independent standard normal random variable, $z_{i,\\alpha} \\sim N(0,1)$.\n\nThe square of a standard normal variable, $z_{i,\\alpha}^2$, follows a chi-square distribution with one degree of freedom, $\\chi^2(1)$. The sum of $k$ independent $\\chi^2(1)$ variables follows a chi-square distribution with $k$ degrees of freedom, $\\chi^2(k)$. We can form a test statistic $S$ by summing the squares of all standardized components across all $N$ particles and all $d$ dimensions:\n$$\nS = \\sum_{i=1}^{N} \\sum_{\\alpha=1}^{d} z_{i,\\alpha}^{2}\n$$\nUnder the null hypothesis, $S$ follows a chi-square distribution with $df = N \\times d$ degrees of freedom.\n\nThe statistical test is performed as follows:\n1.  Specify a significance level $\\alpha$ (e.g., $\\alpha=0.05$). This represents the probability of rejecting the null hypothesis when it is true (Type I error).\n2.  For a two-sided test, we find the critical values that enclose the central $1-\\alpha$ portion of the $\\chi^2(df)$ probability mass. These are the quantiles (or percent-point functions) at probabilities $\\alpha/2$ and $1-\\alpha/2$. Let these be $C_{low} = \\chi^2_{df}(\\alpha/2)$ and $C_{high} = \\chi^2_{df}(1-\\alpha/2)$.\n3.  Calculate the statistic $S$ from the velocity sample.\n4.  The null hypothesis is accepted if $S$ falls within the acceptance region: $C_{low} \\le S \\le C_{high}$. Otherwise, it is rejected. Rejection implies that the sample variance is statistically distinguishable from the theoretical variance.\n\nThis verification procedure is powerful because it aggregates information from the entire sample into a single statistic whose theoretical distribution is known, allowing for a rigorous quantitative check.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the Andersen thermostat simulation.\n    \"\"\"\n    \n    # Define physical constants\n    K_B = 1.380649e-23  # Boltzmann constant in J/K\n    U_TO_KG = 1.66053906660e-27  # Unified atomic mass unit to kg\n\n    def sample_maxwell_boltzmann(masses, T, d, rng):\n        \"\"\"\n        Samples velocities from the Maxwell-Boltzmann distribution.\n\n        Args:\n            masses (np.ndarray): Array of particle masses (kg), shape (N,).\n            T (float): Temperature (K).\n            d (int): Number of dimensions.\n            rng (np.random.Generator): NumPy random number generator.\n\n        Returns:\n            np.ndarray: Array of sampled velocities (m/s), shape (N, d).\n        \"\"\"\n        N = masses.shape[0]\n        # Calculate standard deviation for velocity for each particle\n        # sigma_i = sqrt(k_B * T / m_i)\n        # masses array has shape (N,), so need to reshape for broadcasting\n        sigma = np.sqrt(K_B * T / masses)\n        \n        # Generate standard normal random numbers\n        Z = rng.standard_normal(size=(N, d))\n        \n        # Scale by standard deviation. sigma has shape (N,), reshape to (N, 1)\n        # to broadcast across d dimensions.\n        velocities = Z * sigma[:, np.newaxis]\n        return velocities\n\n    def andersen_step(velocities, masses, T, nu, dt, d, rng):\n        \"\"\"\n        Performs a single step of the Andersen thermostat.\n\n        Args:\n            velocities (np.ndarray): Current velocities, shape (N, d).\n            masses (np.ndarray): Particle masses, shape (N,).\n            T (float): Temperature (K).\n            nu (float): Collision frequency (s^-1).\n            dt (float): Timestep (s).\n            d (int): Number of dimensions.\n            rng (np.random.Generator): NumPy random number generator.\n\n        Returns:\n            np.ndarray: Updated velocities after the thermostat step.\n        \"\"\"\n        N = masses.shape[0]\n        p_collision = 1.0 - np.exp(-nu * dt)\n        \n        # Determine which particles collide\n        collision_mask = rng.random(size=N)  p_collision\n        \n        num_collided = np.sum(collision_mask)\n        \n        if num_collided > 0:\n            # Get masses of particles that collide\n            collided_masses = masses[collision_mask]\n            \n            # Resample velocities for these particles\n            new_velocities = sample_maxwell_boltzmann(collided_masses, T, d, rng)\n            \n            # Update the velocities array\n            velocities[collision_mask] = new_velocities\n            \n        return velocities\n\n    def chi_square_variance_test(velocities, masses, T, alpha):\n        \"\"\"\n        Performs a chi-square test to verify the variance of velocity components.\n\n        Args:\n            velocities (np.ndarray): Sampled velocities, shape (N, d).\n            masses (np.ndarray): Particle masses, shape (N,).\n            T (float): Temperature (K).\n            alpha (float): Significance level for the test.\n\n        Returns:\n            bool: True if the test is accepted, False otherwise.\n        \"\"\"\n        N, d = velocities.shape\n        df = N * d\n        \n        # Standardize the velocity components\n        # z_i_alpha = v_i_alpha * sqrt(m_i / (k_B * T))\n        scaling_factors = np.sqrt(masses / (K_B * T))\n        z = velocities * scaling_factors[:, np.newaxis]\n        \n        # Calculate the chi-square statistic S\n        S = np.sum(z**2)\n        \n        # Determine the acceptance region from the chi-square distribution\n        lower_bound = chi2.ppf(alpha / 2, df)\n        upper_bound = chi2.ppf(1 - alpha / 2, df)\n        \n        return lower_bound = S = upper_bound\n\n    results = []\n    alpha = 0.05\n\n    # --- Test Case 1 ---\n    rng1 = np.random.default_rng(seed=1)\n    N1, d1, T1 = 2000, 3, 300.0\n    mass_options_u = np.array([28.0, 40.0, 84.0])\n    mass_options_kg = mass_options_u * U_TO_KG\n    masses1 = rng1.choice(mass_options_kg, size=N1)\n    velocities1 = sample_maxwell_boltzmann(masses1, T1, d1, rng1)\n    results.append(chi_square_variance_test(velocities1, masses1, T1, alpha))\n\n    # --- Test Case 2 ---\n    rng2 = np.random.default_rng(seed=2)\n    N2, d2, T2 = 90, 3, 1000.0\n    masses_u2 = np.linspace(1.0, 100.0, N2)\n    masses2 = masses_u2 * U_TO_KG\n    velocities2 = sample_maxwell_boltzmann(masses2, T2, d2, rng2)\n    results.append(chi_square_variance_test(velocities2, masses2, T2, alpha))\n\n    # --- Test Case 3 ---\n    rng3 = np.random.default_rng(seed=3)\n    N3, d3, T3 = 1000, 3, 500.0\n    masses_u3 = rng3.uniform(10.0, 50.0, size=N3)\n    masses3 = masses_u3 * U_TO_KG\n    velocities3 = np.zeros((N3, d3))  # Initialize at rest\n    nu3, dt3 = 2e14, 1e-15\n    num_steps = 100\n    for _ in range(num_steps):\n        velocities3 = andersen_step(velocities3, masses3, T3, nu3, dt3, d3, rng3)\n    results.append(chi_square_variance_test(velocities3, masses3, T3, alpha))\n\n    # --- Test Case 4 (Negative Control) ---\n    rng4 = np.random.default_rng(seed=4)\n    N4, d4, T4 = 1500, 2, 400.0\n    mass4_u = 20.0\n    masses4 = np.full(N4, mass4_u * U_TO_KG)\n    velocities4_correct = sample_maxwell_boltzmann(masses4, T4, d4, rng4)\n    velocities4_incorrect = velocities4_correct * 1.5\n    results.append(chi_square_variance_test(velocities4_incorrect, masses4, T4, alpha))\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Translating the continuous-time theory of stochastic collisions into a discrete-time simulation algorithm requires careful consideration of the underlying probability. A naive implementation that allows at most one collision per time step can fail when the collision frequency is high. This practice delves into this challenge, requiring you to analyze the probability of multiple collisions and implement a correct algorithmic scheme based on sampling from the Poisson distribution, ensuring your thermostat remains accurate across a wide range of parameters.",
            "id": "3395478",
            "problem": "Consider the Andersen stochastic thermostat, in which each particle undergoes stochastic \"collisions\" with a heat bath that instantaneously reassign its velocity according to the Maxwell–Boltzmann distribution. In the continuous-time formulation, these collision events for a single particle are modeled as a Poisson process with rate parameter $\\nu$ (events per unit time). Over a finite integration time step of length $\\Delta t$, let $\\lambda = \\nu \\Delta t$ denote the dimensionless mean number of collisions per particle per step. Many discrete-time implementations employ a per-step Bernoulli scheme that allows at most one collision per step, with a probability chosen as either $\\lambda$ or $1 - e^{-\\lambda}$, and consequently cannot represent multiple collisions in a single time step when $\\lambda$ is not small.\n\nStarting from the definition of a Poisson process and fundamental probability rules, derive an expression for the probability that a given particle undergoes multiple collisions (two or more) within a single time step of length $\\Delta t$. Then, propose a mathematically principled modification to the per-step scheme that correctly captures multiple collisions when $\\lambda$ is not small, and specify how to algorithmically realize this modification in a discrete-time integrator for molecular dynamics using the Andersen thermostat. Your proposal must include how to sample the number of collisions per step and, conditional on that number, how to sample the collision times within the time step.\n\nTo make the problem numerically concrete and algorithmically testable, implement the following in a complete, runnable program:\n\n1. For each specified test value of $\\lambda$, compute the analytically derived probability of two or more collisions within one step for a single particle.\n2. For each specified test value of $\\lambda$, perform a Monte Carlo simulation of $N_{\\text{steps}}$ independent steps using the modified per-step scheme you propose, in which the number of collisions per step is drawn according to the correct distribution implied by the Poisson process. Estimate the probability of observing two or more collisions in a single step by the fraction of steps with two or more collisions.\n3. For each specified test value of $\\lambda$, also compute the absolute error incurred by a linearized per-step Bernoulli scheme that uses $p_{\\text{lin}} = \\min\\{\\lambda, 1\\}$ for the probability of at least one collision, compared against the true probability of at least one collision. Report this error as a separate diagnostic to quantify the discrepancy in the \"at least one collision\" event when using the linearized scheme.\n\nAll quantities in this task are dimensionless. Express all reported probabilities in decimal form rounded to six decimal places.\n\nTest suite:\n- Case 1: $\\lambda = 0.0$.\n- Case 2: $\\lambda = 10^{-3}$.\n- Case 3: $\\lambda = 0.2$.\n- Case 4: $\\lambda = 1.0$.\n- Case 5: $\\lambda = 5.0$.\n- Case 6: $\\lambda = 20.0$.\n\nFor the Monte Carlo simulation, use $N_{\\text{steps}} = 100000$ independent steps for each case to estimate the probability of multiple collisions.\n\nFinal output format:\n- For each test case, produce a list containing four floats: $[p_{\\ge 2}^{\\text{analytic}}, p_{\\ge 2}^{\\text{Monte Carlo}}, \\lvert p_{\\ge 2}^{\\text{Monte Carlo}} - p_{\\ge 2}^{\\text{analytic}} \\rvert, \\lvert p_{\\ge 1}^{\\text{lin}} - p_{\\ge 1}^{\\text{true}} \\rvert]$, where $p_{\\ge 2}^{\\text{analytic}}$ is the analytically derived probability of two or more collisions, $p_{\\ge 2}^{\\text{Monte Carlo}}$ is the Monte Carlo estimate from the modified scheme, and the last two terms are absolute errors as defined above. Your program should produce a single line of output containing the results for all cases as a comma-separated list of these per-case lists, with no spaces, enclosed in square brackets. For example: `[[c1],[c2],[c3]]`, where each `[ci]` is the four-float list for case $i$.",
            "solution": "The problem statement is valid. It is scientifically grounded in the principles of statistical mechanics and the theory of stochastic processes as applied to molecular dynamics simulations. It is well-posed, objective, and contains all necessary information to derive a unique and meaningful solution.\n\nThe core of the problem is to address a common simplification in discrete-time implementations of the Andersen thermostat. In the continuous-time limit, particle collisions with the heat bath are a Poisson process. A naive discrete implementation might use a Bernoulli trial with probability $p \\approx \\lambda = \\nu \\Delta t$ for a collision within a time step $\\Delta t$, which is only accurate for $\\lambda \\ll 1$ and fundamentally disallows the possibility of multiple collisions within a single step. The task requires deriving the correct probability for multiple collisions and proposing a modified algorithm that respects the underlying Poisson statistics.\n\n**1. Analytical Derivation of the Probability of Multiple Collisions**\n\nThe number of collision events, $k$, for a specific particle in a time interval of length $\\Delta t$, governed by a Poisson process with rate $\\nu$, follows a Poisson distribution. The mean of this distribution is $\\lambda = \\nu \\Delta t$. The probability mass function (PMF) is given by:\n$$ P(k; \\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!}, \\quad \\text{for } k \\in \\{0, 1, 2, \\dots\\} $$\nThe event of \"multiple collisions\" corresponds to $k \\ge 2$. We can calculate the probability of this event, $p_{\\ge 2}$, by using the complement rule: the probability of two or more collisions is $1$ minus the probability of fewer than two collisions (i.e., zero or one collision).\n$$ p_{\\ge 2}^{\\text{analytic}} = P(k \\ge 2) = 1 - P(k  2) = 1 - [P(k=0) + P(k=1)] $$\nUsing the PMF, we find the probabilities for $k=0$ and $k=1$:\n$$ P(k=0) = \\frac{\\lambda^0 e^{-\\lambda}}{0!} = e^{-\\lambda} $$\n$$ P(k=1) = \\frac{\\lambda^1 e^{-\\lambda}}{1!} = \\lambda e^{-\\lambda} $$\nSubstituting these into the expression for $p_{\\ge 2}^{\\text{analytic}}$ yields the final analytical formula:\n$$ p_{\\ge 2}^{\\text{analytic}} = 1 - (e^{-\\lambda} + \\lambda e^{-\\lambda}) = 1 - e^{-\\lambda}(1 + \\lambda) $$\nThis expression gives the exact probability that a particle undergoes two or more stochastic collisions within a time step $\\Delta t$.\n\n**2. Proposed Algorithmic Modification for the Andersen Thermostat**\n\nTo correctly implement the Andersen thermostat in a discrete-time integrator, the Bernoulli scheme must be replaced with a procedure that draws from the correct Poisson distribution.\n\n**Core Proposal:**\nAt the beginning of each time step $\\Delta t$, for each particle in the system, the number of collisions $k$ it will undergo during that step must be sampled from a Poisson distribution with mean $\\lambda$:\n$$ k \\sim \\text{Poisson}(\\lambda) $$\nThe subsequent action depends on the value of $k$:\n- If $k = 0$, the particle is not coupled to the heat bath during this time step. Its velocity evolves solely according to the deterministic forces calculated from the system's potential energy function.\n- If $k \\ge 1$, the particle has experienced at least one collision with the heat bath. The effect of an Andersen collision is to replace the particle's velocity with a new one drawn from the Maxwell-Boltzmann distribution for the target temperature $T$. Since each such resampling event is independent of the particle's prior velocity, the net effect of any number of collisions $k \\ge 1$ within the step is equivalent to the effect of the *last* collision. Therefore, if $k \\ge 1$, the particle's velocity is reset exactly once by drawing a new velocity from the thermal distribution.\n\nThis scheme correctly captures the probability of thermalization, $P(k \\ge 1) = 1 - P(k=0) = 1 - e^{-\\lambda}$, while also allowing for the correct statistical counting of multiple-collision events.\n\n**Algorithmic Realization and Sampling of Collision Times:**\nFor many MD applications, the simple update rule above is sufficient. However, the problem additionally asks for a specification on sampling the collision times, which is relevant for more advanced integrators or the study of time-correlation functions. A fundamental property of the homogeneous Poisson process states that, conditional on $k$ events occurring in an interval, the times of these events are independently and uniformly distributed over that interval.\n\nA more rigorous (though computationally more intensive) algorithmic realization is as follows:\n1.  For a given particle, draw the number of collisions $k \\sim \\text{Poisson}(\\lambda)$.\n2.  If $k  0$, draw $k$ collision times, $\\tau_1, \\tau_2, \\dots, \\tau_k$, as independent samples from a uniform distribution over the time step interval, i.e., $\\tau_j \\sim U(0, \\Delta t)$.\n3.  Sort these times to get an ordered sequence of events: $0  t_{(1)}  t_{(2)}  \\dots  t_{(k)}  \\Delta t$.\n4.  Subdivide the integration step $\\Delta t$ into $k+1$ sub-intervals: $[0, t_{(1)}], [t_{(1)}, t_{(2)}], \\dots, [t_{(k)}, \\Delta t]$.\n5.  Integrate the deterministic equations of motion over each sub-interval. At the boundary of each sub-interval (i.e., at each time $t_{(j)}$), apply a stochastic collision by resampling the particle's velocity from the Maxwell-Boltzmann distribution before proceeding with the integration of the next sub-interval.\n\nFor the purpose of the Monte Carlo simulation required by the problem, which is to estimate the probability $p_{\\ge 2}$, only the first step of this detailed algorithm is necessary: sampling $k$ from the Poisson distribution.\n\n**3. Numerical quantities to be calculated**\n\nWe will implement the following calculations for each test value of $\\lambda$:\n1.  **$p_{\\ge 2}^{\\text{analytic}}$**: The analytical probability of two or more collisions, calculated using the formula $p_{\\ge 2}^{\\text{analytic}} = 1 - e^{-\\lambda}(1 + \\lambda)$.\n2.  **$p_{\\ge 2}^{\\text{Monte Carlo}}$**: A Monte Carlo estimate of this probability. This is obtained by drawing $N_{\\text{steps}} = 100000$ samples from a Poisson distribution with mean $\\lambda$ and computing the fraction of samples for which $k \\ge 2$.\n3.  **$\\lvert p_{\\ge 2}^{\\text{Monte Carlo}} - p_{\\ge 2}^{\\text{analytic}} \\rvert$**: The absolute error between the Monte Carlo estimate and the exact analytical result, which quantifies the statistical error of the simulation.\n4.  **$\\lvert p_{\\ge 1}^{\\text{lin}} - p_{\\ge 1}^{\\text{true}} \\rvert$**: The absolute error of a linearized Bernoulli scheme for the probability of *at least one* collision. This diagnostic quantity is defined as $\\lvert \\min(\\lambda, 1) - (1 - e^{-\\lambda}) \\rvert$. Here, $p_{\\ge 1}^{\\text{lin}} = \\min(\\lambda, 1)$ represents the naive, linear approximation, while $p_{\\ge 1}^{\\text{true}} = 1 - e^{-\\lambda}$ is the true probability of at least one collision. This error highlights the inadequacy of the linear approximation, especially for larger $\\lambda$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Andersen thermostat problem by deriving analytical probabilities,\n    running Monte Carlo simulations, and calculating associated errors.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        0.0,\n        1e-3,\n        0.2,\n        1.0,\n        5.0,\n        20.0,\n    ]\n\n    N_steps = 100000\n    # Use a seeded random number generator for reproducibility of the MC result.\n    # A specific seed is not required by the problem, but it's good practice.\n    rng = np.random.default_rng(seed=42)\n\n    all_results = []\n    for lam in test_cases:\n        # 1. Analytically derived probability of two or more collisions\n        # p_ge2_analytic = 1 - (exp(-lambda) + lambda * exp(-lambda))\n        #                = 1 - exp(-lambda) * (1 + lambda)\n        if lam == 0.0:\n            p_ge2_analytic = 0.0\n        else:\n            p_ge2_analytic = 1.0 - np.exp(-lam) * (1.0 + lam)\n\n        # 2. Monte Carlo simulation of the modified per-step scheme\n        # Draw N_steps samples from Poisson(lambda)\n        collisions_per_step = rng.poisson(lam=lam, size=N_steps)\n        # Count steps with 2 or more collisions\n        multi_collision_steps = np.sum(collisions_per_step >= 2)\n        # Estimate the probability\n        p_ge2_mc = multi_collision_steps / N_steps\n\n        # 3. Absolute error between Monte Carlo and analytical probability\n        err_mc_analytic = np.abs(p_ge2_mc - p_ge2_analytic)\n\n        # 4. Absolute error of the linearized Bernoulli scheme for P(k>=1)\n        # p_ge1_lin = min(lambda, 1)\n        p_ge1_lin = min(lam, 1.0)\n        # p_ge1_true = 1 - P(k=0) = 1 - exp(-lambda)\n        p_ge1_true = 1.0 - np.exp(-lam)\n        err_lin = np.abs(p_ge1_lin - p_ge1_true)\n\n        # Format results to six decimal places\n        case_result = [\n            round(p_ge2_analytic, 6),\n            round(p_ge2_mc, 6),\n            round(err_mc_analytic, 6),\n            round(err_lin, 6)\n        ]\n        all_results.append(case_result)\n\n    # Final print statement in the exact required format: [[c1],[c2],...]\n    # Using repr() on the list of lists and removing spaces gives the desired format.\n    output_str = repr(all_results).replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "An effective thermostat must maintain the correct temperature, but its interaction with the system inevitably perturbs the natural dynamics. To understand this trade-off, this practice asks you to analytically investigate the effect of the Andersen thermostat on a simple model system: the harmonic oscillator. By deriving and solving the equation for the velocity autocorrelation function, you will see precisely how the stochastic collisions introduce a damping effect, providing deep insight into how this thermostat alters time-dependent properties of a simulated system.",
            "id": "3395497",
            "problem": "Consider a one-dimensional harmonic oscillator of mass $m$ and angular frequency $\\omega$ coupled to an Andersen stochastic thermostat at absolute temperature $T$. In the Andersen scheme, collisions occur as a Poisson process with rate $\\nu$, and at each collision the instantaneous velocity is replaced by an independent draw from the Maxwell–Boltzmann distribution at temperature $T$; positions are unaffected at collisions. Between collisions, the dynamics obey Newton’s equations $\\dot{x}=v$ and $\\dot{v}=-\\omega^{2}x$. Let the system be initially sampled from the canonical equilibrium distribution at temperature $T$. Define the velocity autocorrelation function (VACF) $C_{vv}(t) \\equiv \\langle v(t)\\,v(0)\\rangle$, where angle brackets denote the equilibrium ensemble average. Starting only from Newton’s equations between collisions, the renewal property of the Poisson collision process, and the canonical equilibrium factorization of $x$ and $v$ for the harmonic oscillator, derive a closed ordinary differential equation for $C_{vv}(t)$ and solve it with physically correct initial conditions to obtain an explicit expression for $C_{vv}(t)$ that is valid for all real, nonnegative $\\nu$ and $\\omega$. Also determine, from first principles, the parameter regime in which the VACF exhibits damped oscillations in time, expressed as an inequality involving $\\nu$ and $\\omega$. Express your final answer as a single analytic expression for $C_{vv}(t)$ in terms of $t$, $\\omega$, $\\nu$, $m$, $k_B$, and $T$ only. Do not include any inequalities in the final answer.",
            "solution": "The problem statement is critically validated before attempting a solution.\n\n### Step 1: Extract Givens\n- **System**: A one-dimensional harmonic oscillator.\n- **Parameters**: Mass $m$, angular frequency $\\omega$.\n- **Thermostat**: Andersen stochastic thermostat at absolute temperature $T$.\n- **Collision Dynamics**: Collisions are a Poisson process with rate $\\nu$. At each collision, the velocity is replaced by a draw from the Maxwell–Boltzmann distribution at temperature $T$. Position is unaffected.\n- **Inter-collision Dynamics**: Between collisions, the system evolves via Newton’s equations: $\\dot{x}=v$ and $\\dot{v}=-\\omega^{2}x$.\n- **Initial Condition**: The system is initially sampled from the canonical equilibrium distribution at temperature $T$.\n- **Quantity to be calculated**: The velocity autocorrelation function (VACF), defined as $C_{vv}(t) \\equiv \\langle v(t)\\,v(0)\\rangle$, where $\\langle \\dots \\rangle$ denotes the equilibrium ensemble average.\n- **Tasks**:\n  1. Derive a closed ordinary differential equation for $C_{vv}(t)$.\n  2. Solve the ODE to find an explicit expression for $C_{vv}(t)$ valid for all real, nonnegative $\\nu$ and $\\omega$.\n  3. Determine the parameter regime for which the VACF exhibits damped oscillations.\n- **Final Answer specification**: A single analytic expression for $C_{vv}(t)$ in terms of $t$, $\\omega$, $\\nu$, $m$, $k_B$, and $T$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem describes a harmonic oscillator coupled to an Andersen thermostat, which is a standard and well-established model in statistical mechanics and molecular dynamics simulations for studying canonical ensemble dynamics. The underlying principles (Newtonian mechanics, Poisson processes, Maxwell-Boltzmann statistics) are fundamental to physics. The setup is scientifically sound.\n- **Well-Posed**: The problem is clearly defined with all necessary parameters ($m, \\omega, T, \\nu$) and initial conditions (canonical equilibrium). The goal is to derive and solve a differential equation for a well-defined physical quantity, the VACF. A unique and meaningful solution is expected to exist.\n- **Objective**: The problem is stated using precise, objective, and formal scientific language. It is free of ambiguity, subjectivity, or non-scientific claims.\n- **Completeness and Consistency**: The problem provides a self-contained and consistent set of conditions. The description of the Andersen thermostat dynamics and the initial state of the system is sufficient to proceed with the derivation.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. It is scientifically sound, well-posed, objective, and self-contained. The solution process can now proceed.\n\n### Derivation of the Governing Equation\nThe velocity autocorrelation function (VACF) is defined as $C_{vv}(t) = \\langle v(t)v(0) \\rangle$. We will derive a differential equation for $C_{vv}(t)$ by considering its evolution over an infinitesimal time interval $dt$.\n\nThe time evolution of the velocity $v(t)$ is governed by a hybrid dynamics. In any interval $[t, t+dt]$, a collision occurs with probability $\\nu dt$, and no collision occurs with probability $1-\\nu dt$.\n\nLet's evaluate $C_{vv}(t+dt)$:\n$C_{vv}(t+dt) = \\langle v(t+dt)v(0) \\rangle$\nWe compute the expectation by conditioning on whether a collision occurs in $[t, t+dt]$.\n$v(t+dt) =\n\\begin{cases}\nv(t) + \\dot{v}(t)dt + O(dt^2)  \\text{with probability } 1-\\nu dt \\quad (\\text{no collision}) \\\\\nv'  \\text{with probability } \\nu dt \\quad (\\text{collision})\n\\end{cases}$\nHere, $v'$ is a new velocity drawn from the Maxwell–Boltzmann distribution at temperature $T$. This distribution is symmetric, so its mean is zero, $\\langle v' \\rangle = 0$. Crucially, $v'$ is independent of the system's history, including $v(0)$.\n\nThe expectation is the sum of contributions from these two possibilities:\n$\\langle v(t+dt)v(0) \\rangle = (1-\\nu dt) \\langle (v(t)+\\dot{v}(t)dt)v(0) \\rangle + \\nu dt \\langle v'v(0) \\rangle$\nUsing the independence of $v'$ and $v(0)$, we have $\\langle v'v(0) \\rangle = \\langle v' \\rangle \\langle v(0) \\rangle = 0$.\nSo, dropping terms of order $dt^2$ and higher:\n$C_{vv}(t+dt) = (1-\\nu dt) (\\langle v(t)v(0) \\rangle + \\langle \\dot{v}(t)v(0) \\rangle dt) = C_{vv}(t) - \\nu C_{vv}(t)dt + \\langle \\dot{v}(t)v(0) \\rangle dt$\nRearranging and taking the limit $dt \\to 0$:\n$\\frac{dC_{vv}}{dt} = \\lim_{dt\\to 0} \\frac{C_{vv}(t+dt)-C_{vv}(t)}{dt} = -\\nu C_{vv}(t) + \\langle \\dot{v}(t)v(0) \\rangle$\n\nLet's define a cross-correlation function $C_{\\dot{v}v}(t) = \\langle \\dot{v}(t)v(0) \\rangle$. The equation becomes:\n$$ \\frac{dC_{vv}(t)}{dt} = -\\nu C_{vv}(t) + C_{\\dot{v}v}(t) \\quad (*)$$\n\nTo close the system, we need an equation for the time evolution of $C_{\\dot{v}v}(t)$.\n$C_{\\dot{v}v}(t) = \\langle \\dot{v}(t)v(0) \\rangle = \\langle (-\\omega^2 x(t)) v(0) \\rangle = -\\omega^2 \\langle x(t)v(0) \\rangle = -\\omega^2 C_{xv}(t)$\nNow let's find the derivative of $C_{\\dot{v}v}(t)$:\n$\\frac{dC_{\\dot{v}v}(t)}{dt} = -\\omega^2 \\frac{dC_{xv}(t)}{dt} = -\\omega^2 \\frac{d}{dt}\\langle x(t)v(0) \\rangle$\n\nThe position $x(t)$ is continuous. Its time evolution is always given by $\\dot{x}(t)=v(t)$, irrespective of collisions (which only affect $v$ discontinuously and leave $x$ unchanged). Therefore,\n$\\frac{d}{dt}\\langle x(t)v(0) \\rangle = \\langle \\dot{x}(t)v(0) \\rangle = \\langle v(t)v(0) \\rangle = C_{vv}(t)$\nThus, we obtain the second equation:\n$$ \\frac{dC_{\\dot{v}v}(t)}{dt} = -\\omega^2 C_{vv}(t) \\quad (**) $$\n\nNow we have a closed system of two linear first-order ordinary differential equations. We can combine them into a single second-order ODE for $C_{vv}(t)$. Differentiating equation $(*)$ with respect to $t$:\n$\\frac{d^2C_{vv}(t)}{dt^2} = -\\nu \\frac{dC_{vv}(t)}{dt} + \\frac{dC_{\\dot{v}v}(t)}{dt}$\nSubstituting equation $(**)$ into this gives:\n$\\frac{d^2C_{vv}(t)}{dt^2} = -\\nu \\frac{dC_{vv}(t)}{dt} - \\omega^2 C_{vv}(t)$\n\nThis is the desired closed ODE for the VACF:\n$$ \\frac{d^2C_{vv}(t)}{dt^2} + \\nu \\frac{dC_{vv}(t)}{dt} + \\omega^2 C_{vv}(t) = 0 $$\n\n### Initial Conditions\nTo solve this ODE, we need two initial conditions, $C_{vv}(0)$ and $\\dot{C}_{vv}(0)$.\n1.  $C_{vv}(0) = \\langle v(0)^2 \\rangle$. The system is in canonical equilibrium at temperature $T$. The equipartition theorem states that each quadratic degree of freedom in the Hamiltonian contributes $\\frac{1}{2} k_B T$ to the average energy. For the kinetic energy $\\frac{1}{2}mv^2$, we have $\\langle \\frac{1}{2}mv(0)^2 \\rangle = \\frac{1}{2}k_B T$. This gives:\n    $$ C_{vv}(0) = \\langle v(0)^2 \\rangle = \\frac{k_B T}{m} $$\n2.  $\\dot{C}_{vv}(0) = \\left. \\frac{dC_{vv}(t)}{dt} \\right|_{t=0}$. From equation $(*)$ at $t=0$:\n    $\\dot{C}_{vv}(0) = -\\nu C_{vv}(0) + C_{\\dot{v}v}(0)$\n    $C_{\\dot{v}v}(0) = \\langle \\dot{v}(0)v(0) \\rangle = \\langle (-\\omega^2 x(0))v(0) \\rangle = -\\omega^2\\langle x(0)v(0) \\rangle$.\n    For a harmonic oscillator in canonical equilibrium, the joint probability distribution $P(x,v)$ is proportional to $\\exp(-(\\frac{1}{2}m\\omega^2x^2 + \\frac{1}{2}mv^2)/k_B T)$, which is a product of functions of $x$ and $v$. Thus, position and velocity are statistically independent. Since the potential is symmetric, $\\langle x(0) \\rangle = 0$. Therefore, $\\langle x(0)v(0) \\rangle = \\langle x(0) \\rangle \\langle v(0) \\rangle = 0$. This implies $C_{\\dot{v}v}(0)=0$.\n    The initial derivative is then:\n    $$ \\dot{C}_{vv}(0) = -\\nu C_{vv}(0) = -\\frac{\\nu k_B T}{m} $$\n\n### Solution of the ODE\nWe solve $\\ddot{C} + \\nu\\dot{C} + \\omega^2 C = 0$ with $C(0)=\\frac{k_B T}{m}$ and $\\dot{C}(0)=-\\frac{\\nu k_B T}{m}$.\nThe characteristic equation is $r^2 + \\nu r + \\omega^2 = 0$, with roots:\n$r_{1,2} = \\frac{-\\nu \\pm \\sqrt{\\nu^2 - 4\\omega^2}}{2} = -\\frac{\\nu}{2} \\pm \\sqrt{\\frac{\\nu^2}{4} - \\omega^2}$\n\nThe form of the solution depends on the sign of the discriminant $\\Delta = \\nu^2 - 4\\omega^2$.\n\n**Case 1: Underdamped ($\\nu  2\\omega$)**\nThe roots are complex conjugates: $r_{1,2} = -\\frac{\\nu}{2} \\pm i\\Omega'$, where $\\Omega' = \\sqrt{\\omega^2 - \\frac{\\nu^2}{4}}$.\nThe general solution is $C_{vv}(t) = e^{-\\nu t/2}(A\\cos(\\Omega' t) + B\\sin(\\Omega' t))$.\nApplying initial conditions:\n$C_{vv}(0) = A = \\frac{k_B T}{m}$.\n$\\dot{C}_{vv}(0) = -\\frac{\\nu}{2}A + B\\Omega' = -\\frac{\\nu k_B T}{m}$.\n$-\\frac{\\nu}{2}\\frac{k_B T}{m} + B\\Omega' = -\\frac{\\nu k_B T}{m} \\implies B\\Omega' = -\\frac{\\nu}{2}\\frac{k_B T}{m} \\implies B = -\\frac{\\nu}{2\\Omega'}\\frac{k_B T}{m}$.\nThe solution is:\n$C_{vv}(t) = \\frac{k_B T}{m} e^{-\\nu t/2} \\left( \\cos(\\Omega' t) - \\frac{\\nu}{2\\Omega'} \\sin(\\Omega' t) \\right)$.\n\n**Case 2: Overdamped ($\\nu  2\\omega$)**\nThe roots are real and distinct: $r_{1,2} = -\\frac{\\nu}{2} \\pm \\Omega$, where $\\Omega = \\sqrt{\\frac{\\nu^2}{4} - \\omega^2}$.\nThe solution is $C_{vv}(t) = \\frac{k_B T}{m} e^{-\\nu t/2} \\left( \\cosh(\\Omega t) - \\frac{\\nu}{2\\Omega} \\sinh(\\Omega t) \\right)$. This can be obtained from the underdamped solution by substituting $\\Omega' = i\\Omega$ and using $\\cos(i\\theta)=\\cosh(\\theta)$, $\\sin(i\\theta)=i\\sin h(\\theta)$.\n\n**Case 3: Critically damped ($\\nu = 2\\omega$)**\nThe roots are real and repeated: $r_1=r_2=-\\frac{\\nu}{2}=-\\omega$.\nThe general solution is $C_{vv}(t) = (A+Bt)e^{-\\nu t/2}$.\n$C_{vv}(0) = A = \\frac{k_B T}{m}$.\n$\\dot{C}_{vv}(0) = B - \\frac{\\nu}{2}A = -\\frac{\\nu k_B T}{m}$.\n$B - \\frac{\\nu}{2}\\frac{k_B T}{m} = -\\nu\\frac{k_B T}{m} \\implies B=-\\frac{\\nu}{2}\\frac{k_B T}{m}$.\nThe solution is $C_{vv}(t) = \\frac{k_B T}{m} (1-\\frac{\\nu}{2}t)e^{-\\nu t/2}$. This is also the limit of the under- and overdamped solutions as $\\Omega, \\Omega' \\to 0$.\n\nFor all real, nonnegative $\\nu$ and $\\omega$, a single analytic expression can be written using the underdamped form, with the understanding that the functions are defined via analytic continuation for complex arguments (or by taking the appropriate limit in the critical case).\n\n### Condition for Damped Oscillations\nDamped oscillations occur when the solution contains sinusoidal terms, which corresponds to the underdamped case. The condition for this is that the roots of the characteristic equation are complex, which requires the discriminant to be negative:\n$\\nu^2 - 4\\omega^2  0 \\implies \\nu^2  4\\omega^2$.\nSince $\\nu$ and $\\omega$ are nonnegative, this gives the inequality:\n$$ \\nu  2\\omega $$\nThis is the parameter regime in which the VACF exhibits damped oscillations.\n\nThe single analytic expression that covers all cases is:\n$$ C_{vv}(t) = \\frac{k_B T}{m} e^{-\\frac{\\nu t}{2}} \\left[ \\cos\\left(t\\sqrt{\\omega^2 - \\frac{\\nu^2}{4}}\\right) - \\frac{\\nu}{2\\sqrt{\\omega^2 - \\frac{\\nu^2}{4}}} \\sin\\left(t\\sqrt{\\omega^2 - \\frac{\\nu^2}{4}}\\right) \\right] $$\nThis expression is to be interpreted using $\\cosh$ and $\\sinh$ if the argument of the square root is negative, and as a limit if the argument is zero.",
            "answer": "$$ \\boxed{ \\frac{k_B T}{m} \\exp\\left(-\\frac{\\nu t}{2}\\right) \\left( \\cos\\left(t\\sqrt{\\omega^2 - \\frac{\\nu^2}{4}}\\right) - \\frac{\\nu}{2\\sqrt{\\omega^2 - \\frac{\\nu^2}{4}}} \\sin\\left(t\\sqrt{\\omega^2 - \\frac{\\nu^2}{4}}\\right) \\right) } $$"
        }
    ]
}