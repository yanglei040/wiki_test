{
    "hands_on_practices": [
        {
            "introduction": "This first practice grounds the abstract concept of temperature in a concrete physical context. A successful simulated annealing protocol must begin at a temperature high enough to allow the system to overcome the most significant energy barriers in the conformational landscape. This exercise  will guide you through the process of calculating the necessary starting temperature based on known barrier heights and a desired probability of crossing, providing a rational basis for designing an effective annealing schedule.",
            "id": "3445992",
            "problem": "A model peptide has three side-chain dihedral angles whose transitions between rotameric states are dominated by torsional barriers. The barrier heights, defined as the energy increase required to reach the transition state relative to the current rotamer minimum, are measured as $\\Delta E_{\\chi_1} = 12 \\ \\mathrm{kJ/mol}$, $\\Delta E_{\\chi_2} = 18 \\ \\mathrm{kJ/mol}$, and $\\Delta E_{\\chi_3} = 25 \\ \\mathrm{kJ/mol}$. Consider a simulated annealing protocol for conformational search within molecular dynamics that employs the Metropolis acceptance rule with symmetric proposals for dihedral rotations. \n\nUse the following fundamental principles:\n- The Metropolis acceptance probability for a proposed move that increases the energy by $\\Delta U$ at temperature $T$ is $p_{\\mathrm{acc}} = \\exp(-\\Delta U/(k_B T))$, where $k_B$ is the Boltzmann constant.\n- When barrier heights are specified per mole, the relevant thermal factor is the molar gas constant $R$ defined by $R = N_A k_B$, so that the acceptance probability for crossing a molar barrier $\\Delta E$ is $p(T) = \\exp(-\\Delta E/(R T))$.\n- For $N$ statistically independent proposals at fixed temperature, each with success probability $p(T)$, the probability of at least one successful crossing in the block is $P_{\\mathrm{block}} = 1 - (1 - p(T))^{N}$.\n\nAssume that proposal independence across the barrier at fixed $T$ is a reasonable approximation within a block of $N = 100$ proposals. For each barrier $\\Delta E_{\\chi_i}$, compute the temperature $T_i$ at which the probability of crossing the barrier at least once in $N = 100$ proposals satisfies $P_{\\mathrm{block}} = 0.10$. Then, design a geometric cooling schedule $T_k = T_0 \\alpha^k$ with $0 < \\alpha < 1$ and integer $k \\geq 0$ that starts at a temperature $T_0$ sufficient to visit the highest barrier and then reduces in stages to facilitate visiting all rotamers associated with $\\chi_2$ and $\\chi_1$ before quenching.\n\nFinally, determine the minimal initial temperature $T_0$ (in Kelvin) that guarantees the highest barrier $\\Delta E_{\\chi_3}$ is crossed with $P_{\\mathrm{block}} = 0.10$ over $N = 100$ proposals. Express the final $T_0$ in Kelvin and round your answer to four significant figures.",
            "solution": "The problem statement is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\nThe verbatim givens extracted from the problem statement are as follows:\n-   Peptide side-chain torsional barrier heights: $\\Delta E_{\\chi_1} = 12 \\ \\mathrm{kJ/mol}$, $\\Delta E_{\\chi_2} = 18 \\ \\mathrm{kJ/mol}$, and $\\Delta E_{\\chi_3} = 25 \\ \\mathrm{kJ/mol}$.\n-   The protocol is simulated annealing using the Metropolis acceptance rule.\n-   Metropolis acceptance probability for an energy increase $\\Delta U$ at temperature $T$: $p_{\\mathrm{acc}} = \\exp(-\\Delta U/(k_B T))$.\n-   Boltzmann constant is denoted $k_B$.\n-   Acceptance probability for a molar barrier $\\Delta E$: $p(T) = \\exp(-\\Delta E/(R T))$, with the molar gas constant $R = N_A k_B$.\n-   Number of statistically independent proposals in a block: $N = 100$.\n-   Probability of at least one successful crossing in a block of $N$ proposals: $P_{\\mathrm{block}} = 1 - (1 - p(T))^{N}$.\n-   Target probability for at least one crossing: $P_{\\mathrm{block}} = 0.10$.\n-   Geometric cooling schedule form: $T_k = T_0 \\alpha^k$ for $0 < \\alpha < 1$ and integer $k \\geq 0$.\n-   Objective: Determine the minimal initial temperature $T_0$ (in Kelvin) for the highest barrier, $\\Delta E_{\\chi_3}$, to be crossed with $P_{\\mathrm{block}} = 0.10$, rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed for validity:\n-   **Scientifically Grounded**: The problem is firmly rooted in the principles of statistical mechanics and computational chemistry. The concepts of torsional energy barriers, simulated annealing, the Metropolis-Hastings algorithm, and the Boltzmann distribution are cornerstones of molecular dynamics and conformational analysis. All provided equations and principles are standard and correct.\n-   **Well-Posed**: The problem is well-posed. It provides a clear objective (calculate $T_0$) with all necessary mathematical relationships and numerical values to achieve a unique, meaningful solution. The context provided about the full cooling schedule serves to define the role of $T_0$ but does not introduce ambiguity, as the final task is explicitly isolated.\n-   **Objective**: The problem is stated in precise, quantitative, and unbiased language.\n-   **Consistency and Completeness**: The problem is self-contained and internally consistent. Although the value of the molar gas constant $R$ is not explicitly provided, it is a universal physical constant, and its use is standard practice in such problems. The problem does not contain contradictory constraints.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. It is a standard, well-defined problem in physical chemistry or biophysics. A complete solution will now be derived.\n\nThe main objective is to determine the initial temperature $T_0$ of a simulated annealing schedule. This temperature must be high enough to allow the system to overcome the highest energy barrier, $\\Delta E_{\\chi_3}$, with a specified probability. The condition is that the probability of at least one successful crossing in a block of $N=100$ proposals is $P_{\\mathrm{block}} = 0.10$.\n\nThe probability of at least one successful crossing, $P_{\\mathrm{block}}$, is related to the single-trial success probability, $p(T)$, by the given formula:\n$$P_{\\mathrm{block}} = 1 - (1 - p(T))^{N}$$\n\nWe are given $P_{\\mathrm{block}} = 0.10$ and $N = 100$. We can rearrange this equation to solve for the required single-trial probability, $p(T_0)$:\n$$1 - P_{\\mathrm{block}} = (1 - p(T_0))^{N}$$\n$$(1 - P_{\\mathrm{block}})^{1/N} = 1 - p(T_0)$$\n$$p(T_0) = 1 - (1 - P_{\\mathrm{block}})^{1/N}$$\n\nThe single-trial probability of accepting a move that increases the energy by the barrier height $\\Delta E$ is given by the Metropolis criterion, adapted for molar energies:\n$$p(T) = \\exp\\left(-\\frac{\\Delta E}{R T}\\right)$$\n\nEquating the two expressions for $p(T_0)$, we have:\n$$\\exp\\left(-\\frac{\\Delta E}{R T_0}\\right) = 1 - (1 - P_{\\mathrm{block}})^{1/N}$$\n\nTo solve for $T_0$, we take the natural logarithm of both sides:\n$$-\\frac{\\Delta E}{R T_0} = \\ln\\left(1 - (1 - P_{\\mathrm{block}})^{1/N}\\right)$$\n\nFinally, we isolate $T_0$:\n$$T_0 = -\\frac{\\Delta E}{R \\ln\\left(1 - (1 - P_{\\mathrm{block}})^{1/N}\\right)}$$\n\nThis is the general formula for the temperature required to cross a barrier $\\Delta E$. The problem specifies that $T_0$ is the initial temperature, designed to be high enough to traverse the highest energy barrier, which is $\\Delta E_{\\chi_3} = 25 \\ \\mathrm{kJ/mol}$.\n\nWe substitute the given values into this derived expression:\n-   $\\Delta E = \\Delta E_{\\chi_3} = 25 \\ \\mathrm{kJ/mol} = 2.5 \\times 10^4 \\ \\mathrm{J/mol}$\n-   $N = 100$\n-   $P_{\\mathrm{block}} = 0.10$\n-   The molar gas constant, $R$, is a fundamental constant. We will use its CODATA value, $R \\approx 8.314462618 \\ \\mathrm{J \\cdot mol^{-1} \\cdot K^{-1}}$.\n\nThe expression for $T_0$ becomes:\n$$T_0 = -\\frac{2.5 \\times 10^4}{R \\ln\\left(1 - (1 - 0.10)^{1/100}\\right)}$$\n$$T_0 = -\\frac{2.5 \\times 10^4}{R \\ln\\left(1 - (0.9)^{0.01}\\right)}$$\n\nNow, we perform the numerical calculation.\nFirst, the term in the logarithm:\n$$(0.9)^{0.01} \\approx 0.99894709$$\n$$1 - (0.9)^{0.01} \\approx 1 - 0.99894709 = 0.00105291$$\nThe natural logarithm of this value is:\n$$\\ln(0.00105291) \\approx -6.85549$$\nSubstituting this into the equation for $T_0$:\n$$T_0 = -\\frac{2.5 \\times 10^4 \\ \\mathrm{J/mol}}{8.31446 \\ \\mathrm{J \\cdot mol^{-1} \\cdot K^{-1}} \\times (-6.85549)}$$\n$$T_0 = \\frac{2.5 \\times 10^4}{8.31446 \\times 6.85549} \\ \\mathrm{K}$$\n$$T_0 = \\frac{2.5 \\times 10^4}{56.9935} \\ \\mathrm{K}$$\n$$T_0 \\approx 438.647 \\ \\mathrm{K}$$\n\nThe problem requires the answer to be rounded to four significant figures.\n$$T_0 \\approx 438.6 \\ \\mathrm{K}$$\nThis is the minimal initial temperature required for the simulated annealing protocol to ensure that the highest conformational barrier can be crossed with the specified probability.",
            "answer": "$$\\boxed{438.6}$$"
        },
        {
            "introduction": "Real-world energy landscapes are often complicated by misleading local minima, which can be reinforced by noisy or inaccurate experimental data used as restraints. This practice  presents a computational model to explore a critical failure mode of simulated annealing: kinetic trapping. By simulating the competition between the desired global rearrangement and over-commitment to a restraint-favored local minimum, you will investigate how the cooling rate can determine the success or failure of a conformational search.",
            "id": "3446033",
            "problem": "Consider a one-dimensional coarse-grained conformational coordinate $x \\in \\mathbb{R}$ for a macromolecule undergoing simulated annealing. The configurational energy is modeled as\n$$\nU(x,t) \\;=\\; U_0(x) \\;+\\; w(t)\\,R(x),\n$$\nwhere $U_0(x)$ is a native double-well potential representing global basins and $R(x)$ is a quadratic restraint that encodes noisy experimental restraints. The native double-well is\n$$\nU_0(x) \\;=\\; a\\,(x^2 - 1)^2 + \\delta\\,x,\n$$\nwith $a>0$ and a small tilt $\\delta<0$ that makes $x\\approx -1$ the lower-energy global basin and $x\\approx +1$ the higher-energy non-native basin. The restraint is\n$$\nR(x) \\;=\\; (x - x_r)^2,\n$$\nwith a target $x_r$ located at the non-native basin $x_r = +1$, intentionally modeling a noisy or misassigned restraint that favors the wrong basin.\n\nThe simulated annealing temperature schedule is exponential,\n$$\nT(t) \\;=\\; T_0\\,\\exp\\!\\left(-\\frac{t}{\\tau_{\\text{cool}}}\\right),\n$$\nwhere $T_0>0$ is the initial temperature and $\\tau_{\\text{cool}}>0$ is the cooling timescale. The restraint weight $w(t)$ tightens over time following\n$$\nw(t) \\;=\\; w_0 \\;+\\; b_w\\left( 1 - \\exp\\!\\left(-\\frac{t}{\\tau_{\\text{rest}}}\\right)\\right),\n$$\nwhere $w_0\\ge 0$ is the initial weight, $b_w>0$ is the total increase, and $\\tau_{\\text{rest}}>0$ is the restraint-tightening timescale. This concurrent tightening is a common feature of practical protocols.\n\nWe model the competition between two processes:\n- Rearrangement from the restraint-favored non-native basin to the global basin, with an instantaneous rate\n$$\nk_{\\text{rearr}}(t) \\;=\\; \\nu_r \\,\\exp\\!\\left(-\\frac{\\Delta E_{\\text{eff}}(t)}{T(t)}\\right),\n$$\nwhere $\\nu_r>0$ is an attempt frequency and $\\Delta E_{\\text{eff}}(t)$ is an effective barrier from the non-native basin $x\\approx +1$ to the saddle $x\\approx 0$ under the current restraint weight,\n$$\n\\Delta E_{\\text{eff}}(t) \\;=\\; \\big[U_0(0) - U_0(+1)\\big] \\;+\\; w(t)\\,\\big[R(0) - R(+1)\\big].\n$$\n- Over-commitment to satisfying the noisy restraint within the non-native basin, represented as a competing event with instantaneous rate\n$$\nk_{\\text{commit}}(t) \\;=\\; c\\,w(t),\n$$\nwhere $c>0$ is a proportionality constant reflecting faster local relaxation as restraints tighten. This term captures how tightening noisy restraints can lock the trajectory into the wrong basin.\n\nAssume independent competing exponential clocks for these two processes. The probability that rearrangement occurs before restraint over-commitment by time $t=N$ (in discrete Monte Carlo steps, treated here as unit timesteps) is then\n$$\nP_{\\text{rearr}}(N) \\;=\\; \\int_0^N k_{\\text{rearr}}(t)\\,\\exp\\!\\left(-\\int_0^t \\big[k_{\\text{rearr}}(u) + k_{\\text{commit}}(u)\\big]\\,du\\right)\\,dt.\n$$\nThis representation follows from standard properties of competing inhomogeneous Poisson processes and provides a tractable approximation to the stochastic simulated annealing dynamics when focusing on the timing of the first event among competing processes.\n\nYour task is to implement a program that, for specified parameters, computes $P_{\\text{rearr}}(N)$ by numerically approximating the integrals as discrete sums with unit time steps. Use the following fixed parameters, chosen to be scientifically plausible and internally consistent:\n- Native double-well parameters: $a = 20.0$, $\\delta = -0.25$.\n- Restraint target: $x_r = +1.0$.\n- Restraint schedule parameters: $w_0 = 0.0$, $b_w = 12.0$, $\\tau_{\\text{rest}} = 200.0$.\n- Annealing parameters: $T_0 = 3.0$.\n- Rates: $\\nu_r = 0.3$, $c = 0.01$.\nAll quantities are in nondimensional Monte Carlo units. Time $t$ and the horizon $N$ are measured in Monte Carlo steps.\n\nDefine the effective barrier pieces explicitly from the double-well and restraint:\n- Saddle and non-native basin values satisfy $x_{\\text{saddle}} = 0$ and $x_{\\text{non-native}} = +1$, so\n$$\n\\Delta E_0 \\equiv U_0(0) - U_0(+1) = a - \\delta,\n$$\nand\n$$\n\\Delta R \\equiv R(0) - R(+1) = (0-1)^2 - (1-1)^2 = 1.\n$$\nHence,\n$$\n\\Delta E_{\\text{eff}}(t) = \\Delta E_0 + w(t)\\,\\Delta R = (a - \\delta) + w(t).\n$$\n\nTest Suite:\nCompute $P_{\\text{rearr}}(N)$ for the following three cases, designed to probe different timescale regimes of cooling versus rearrangement and restraint tightening:\n- Case $1$ (happy path): $\\tau_{\\text{cool}} = 100.0$, $N = 4000$.\n- Case $2$ (overly slow cooling with extended schedule): $\\tau_{\\text{cool}} = 1000.0$, $N = 20000$.\n- Case $3$ (extremely fast quench): $\\tau_{\\text{cool}} = 1.0$, $N = 4000$.\n\nFor each case, your program should evaluate $P_{\\text{rearr}}(N)$ as a float. The final output format must be a single line containing a comma-separated list of the three probabilities enclosed in square brackets, for example, $[p_1,p_2,p_3]$, where $p_i$ are the computed floats in standard Python string formatting. There are no physical units to report because all quantities are nondimensional Monte Carlo steps and energies in reduced units.\n\nYour implementation must be robust and numerically stable, using simple Riemann-sum discretization of the integrals at unit timesteps:\n$$\nP_{\\text{rearr}}(N) \\approx \\sum_{t=0}^{N-1} k_{\\text{rearr}}(t)\\,\\exp\\!\\left(-\\sum_{u=0}^{t-1}\\big[k_{\\text{rearr}}(u)+k_{\\text{commit}}(u)\\big]\\right).\n$$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[p_1,p_2,p_3]$).",
            "solution": "The problem presented is a well-defined and scientifically grounded exercise in modeling stochastic processes, specifically within the context of simulated annealing for macromolecular conformational search. It is self-contained, with all necessary parameters and functional forms provided, and poses a clear computational task. The model, while simplified, captures the essential competition between exploring the conformational space to find a global energy minimum and becoming kinetically trapped in a local minimum favored by potentially erroneous external restraints. The problem is valid and admits a direct numerical solution.\n\nThe core of the problem is to compute the probability, $P_{\\text{rearr}}(N)$, that a desired conformational rearrangement occurs before an undesired \"over-commitment\" to a non-native state within a total simulation time of $N$ steps. This scenario is modeled as a competition between two independent, time-inhomogeneous Poisson processes.\n\nThe total configurational energy of the system is given by $U(x,t) = U_0(x) + w(t)R(x)$, where $x$ is a one-dimensional conformational coordinate.\n\nThe intrinsic energy component, $U_0(x) = a(x^2 - 1)^2 + \\delta x$, is a double-well potential with parameters $a=20.0$ and $\\delta=-0.25$. The negative tilt $\\delta$ establishes the basin near $x \\approx -1$ as the global minimum (native state) and the basin near $x \\approx +1$ as a higher-energy local minimum (non-native state).\n\nThe restraint component is $R(x) = (x - x_r)^2$, with the target $x_r = +1.0$ deliberately placed at the non-native minimum. The strength of this restraint is modulated by a time-dependent weight, $w(t) = w_0 + b_w\\left( 1 - \\exp(-t/\\tau_{\\text{rest}})\\right)$. With parameters $w_0=0.0$, $b_w=12.0$, and $\\tau_{\\text{rest}}=200.0$, the restraint starts at zero strength and increases over time, progressively favoring the incorrect basin.\n\nThe simulated annealing protocol is defined by an exponential cooling schedule for the temperature, $T(t) = T_0\\exp(-t/\\tau_{\\text{cool}})$, with an initial temperature of $T_0=3.0$. The cooling timescale, $\\tau_{\\text{cool}}$, is varied across the test cases.\n\nThe competition is between two processes with instantaneous rates:\n1.  Rearrangement from the non-native to the native state, an activated process with an Arrhenius-like rate:\n    $$\n    k_{\\text{rearr}}(t) = \\nu_r \\exp\\left(-\\frac{\\Delta E_{\\text{eff}}(t)}{T(t)}\\right)\n    $$\n    Here, $\\nu_r = 0.3$ is an attempt frequency. The effective activation barrier, $\\Delta E_{\\text{eff}}(t)$, is the energy difference between the saddle point ($x \\approx 0$) and the non-native minimum ($x \\approx +1$) under the influence of the current restraint. The problem provides the simplified expression:\n    $$\n    \\Delta E_{\\text{eff}}(t) = (a - \\delta) + w(t)\n    $$\n    This is derived from $\\Delta E_0 = U_0(0) - U_0(+1) = a - \\delta$ and $\\Delta R = R(0) - R(+1) = 1$. The term $w(t)$ shows that the tightening restraint increases the barrier to escape the non-native basin.\n\n2.  Over-commitment to the non-native state, a trapping process whose rate is modeled as being proportional to the restraint strength:\n    $$\n    k_{\\text{commit}}(t) = c\\,w(t)\n    $$\n    with proportionality constant $c = 0.01$. This phenomenological term reflects the idea that stronger restraints lead to faster local relaxation and thus a higher chance of becoming locked in the wrong state.\n\nThe probability that rearrangement occurs before over-commitment by time $N$ is given by the standard formula for the first passage time probability in competing Poisson processes:\n$$\nP_{\\text{rearr}}(N) = \\int_0^N k_{\\text{rearr}}(t) \\exp\\left(-\\int_0^t \\left[k_{\\text{rearr}}(u) + k_{\\text{commit}}(u)\\right] du\\right) dt\n$$\nThe exponential term represents the \"survival probability,\" i.e., the probability that neither event has occurred by time $t$. The term $k_{\\text{rearr}}(t)$ is the probability density of the rearrangement event occurring at time $t$. The integral sums these probabilities over the entire interval $[0, N]$.\n\nThe task is to compute this quantity using a numerical approximation where the integrals are replaced by sums over discrete time steps of size $\\Delta t=1$:\n$$\nP_{\\text{rearr}}(N) \\approx \\sum_{t=0}^{N-1} k_{\\text{rearr}}(t) \\exp\\left(-\\sum_{u=0}^{t-1} \\left[k_{\\text{rearr}}(u) + k_{\\text{commit}}(u)\\right]\\right)\n$$\nThis calculation is performed for three different test cases varying $\\tau_{\\text{cool}}$ and $N$. An efficient implementation avoids a nested loop structure, which would be of $O(N^2)$ complexity. Instead, we can pre-calculate the time-dependent rates for all $t \\in [0, N-1]$ as vectors. Let $K(t) = k_{\\text{rearr}}(t) + k_{\\text{commit}}(t)$. The inner sum, $\\sum_{u=0}^{t-1} K(u)$, can be efficiently computed for all $t$ by first calculating the vector of $K(t)$ values and then using a cumulative sum operation. The final result is then the sum of the terms $k_{\\text{rearr}}(t) \\exp(-\\sum_{u=0}^{t-1} K(u))$. This vectorized approach has a time complexity of $O(N)$, which is suitable for the specified values of $N$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_prearr(tau_cool, N, a, delta, w0, bw, tau_rest, T0, nu_r, c):\n    \"\"\"\n    Computes the probability of rearrangement P_rearr(N) using numerical discretization.\n\n    Args:\n        tau_cool (float): Cooling timescale.\n        N (int): Total number of Monte Carlo steps.\n        a (float): Parameter for the native double-well potential.\n        delta (float): Tilt parameter for the native double-well potential.\n        w0 (float): Initial restraint weight.\n        bw (float): Total increase in restraint weight.\n        tau_rest (float): Restraint-tightening timescale.\n        T0 (float): Initial temperature.\n        nu_r (float): Attempt frequency for rearrangement.\n        c (float): Proportionality constant for the commitment rate.\n\n    Returns:\n        float: The calculated probability P_rearr(N).\n    \"\"\"\n    # Use float64 for better precision in numerical sums and exponents.\n    t_steps = np.arange(N, dtype=np.float64)\n\n    # Calculate time-dependent temperature and restraint weight schedules\n    T_t = T0 * np.exp(-t_steps / tau_cool)\n    w_t = w0 + bw * (1.0 - np.exp(-t_steps / tau_rest))\n\n    # Calculate the effective energy barrier\n    # delta_E_eff(t) = (a - delta) + w(t)\n    delta_E0 = a - delta\n    delta_E_eff_t = delta_E0 + w_t\n\n    # Calculate the instantaneous rates for rearrangement and commitment\n    # The argument to np.exp is negative, so overflow is not a concern.\n    # Underflow to zero is handled correctly and is physically meaningful.\n    k_rearr_t = nu_r * np.exp(-delta_E_eff_t / T_t)\n    k_commit_t = c * w_t\n\n    # Total rate of any event occurring\n    K_t = k_rearr_t + k_commit_t\n\n    # The discrete approximation for the probability is:\n    # Sum_{t=0}^{N-1} k_rearr(t) * exp(-Sum_{u=0}^{t-1} K(u))\n    # We can compute this efficiently using vectorization.\n\n    # 1. Compute the inner sum for the survival probability exponent.\n    # inner_sum_at_t corresponds to Sum_{u=0}^{t-1} K(u)\n    inner_sum = np.zeros_like(K_t)\n    # np.cumsum(K_t) at index `i` is sum up to `i`. We need sum up to `i-1`.\n    inner_sum[1:] = np.cumsum(K_t[:-1])\n\n    # 2. Compute the survival probability S(t) = exp(-inner_sum_at_t)\n    survival_prob_t = np.exp(-inner_sum)\n\n    # 3. Compute the full term to be summed at each time step t\n    # This is k_rearr(t) * S(t), which is the probability density of\n    # rearranging at time t, given no event occurred before t.\n    summand_t = k_rearr_t * survival_prob_t\n\n    # 4. Sum all terms to get the total probability over the horizon N\n    # The time step Delta_t is 1, so it's a direct sum.\n    total_prob = np.sum(summand_t)\n\n    return total_prob\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define the fixed parameters from the problem statement.\n    # All quantities are in nondimensional Monte Carlo units.\n    a = 20.0\n    delta = -0.25\n    w0 = 0.0\n    bw = 12.0\n    tau_rest = 200.0\n    T0 = 3.0\n    nu_r = 0.3\n    c = 0.01\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (tau_cool, N)\n    test_cases = [\n        (100.0, 4000),   # Case 1: happy path\n        (1000.0, 20000), # Case 2: overly slow cooling with extended schedule\n        (1.0, 4000),     # Case 3: extremely fast quench\n    ]\n\n    results = []\n    for tau_cool, N in test_cases:\n        p_rearr = calculate_prearr(tau_cool, N, a, delta, w0, bw, tau_rest, T0, nu_r, c)\n        results.append(p_rearr)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Simulated annealing can be driven by different underlying dynamics, most commonly Molecular Dynamics (MD) or Monte Carlo (MC) simulations. While both aim to find low-energy states, the paths they take through the conformational space can differ significantly due to the presence of inertia in MD. This advanced practice  involves a comparative study of SA-MD and SA-MC, where you will use the rigorous framework of committor analysis to quantify how effectively each method identifies the true transition state region, revealing the subtle but important influence of the underlying simulation engine.",
            "id": "3446006",
            "problem": "You are asked to design and compare two simulated annealing strategies for exploring a two-dimensional conformational landscape, and to quantify a dynamical bias via committor analysis. The comparison must be performed on a toy two-dimensional potential energy surface that has multiple minima and saddle points. The final output must be produced by a single, complete, runnable program.\n\nConstruct a smooth two-dimensional potential energy function $V(x,y)$ and its gradient $\\nabla V(x,y)$ on $\\mathbb{R}^2$ starting from a standard parametric form that is known to generate multiple minima and saddle points. Use the following well-tested Müller–Brown construction with an overall energy scale factor $s$:\n$$\nV(x,y) \\equiv s \\sum_{i=1}^{4} A_i \\exp\\left(a_i (x-x_i)^2 + b_i (x-x_i)(y-y_i) + c_i (y-y_i)^2\\right),\n$$\nwith constants\n$$\nA = \\left[-200,-100,-170,15\\right],\\quad a=\\left[-1,-1,-6.5,0.7\\right],\\quad b=\\left[0,0,11,0.6\\right],\\quad c=\\left[-10,-10,-6.5,0.7\\right],\n$$\nand\n$$\nx_0=\\left[1,0,-0.5,-1\\right],\\quad y_0=\\left[0,0.5,1.5,1\\right].\n$$\nSet the energy scale to $s = 0.05$. Compute the gradient by analytic differentiation. All energies are in arbitrary units and Boltzmann's constant is $k_{\\mathrm{B}}=1$.\n\nDefine two basins $A$ and $B$ as disks in the plane, specified by centers and a radius. Use\n$$\n\\mathbf{r}_A=\\begin{bmatrix}-0.558\\\\1.442\\end{bmatrix},\\quad \\mathbf{r}_B=\\begin{bmatrix}0.623\\\\0.028\\end{bmatrix},\\quad r_{\\mathrm{basin}}=0.20,\n$$\nso that a point $\\mathbf{r}$ is in basin $A$ if $\\|\\mathbf{r}-\\mathbf{r}_A\\|_2<r_{\\mathrm{basin}}$ and in basin $B$ if $\\|\\mathbf{r}-\\mathbf{r}_B\\|_2<r_{\\mathrm{basin}}$. Initialize all runs at $\\mathbf{r}_A$ with an added independent Gaussian perturbation of standard deviation $\\sigma_{\\mathrm{init}}=0.02$ in each coordinate.\n\nImplement two simulated annealing strategies that generate paths $\\{\\mathbf{r}_k\\}_{k=0}^{N-1}$ while the scalar temperature $T_k$ follows a geometric cooling schedule. Let the number of annealing steps be $N$, the initial and final temperatures be $T_0$ and $T_f$, and define\n$$\nT_k = T_0 \\left(\\frac{T_f}{T_0}\\right)^{\\frac{k}{N-1}},\\quad k=0,1,\\ldots,N-1.\n$$\n\nStrategy $1$ (SA-MD, simulated annealing via molecular dynamics): Use underdamped Langevin dynamics with unit mass $m=1$ and friction coefficient $\\gamma$ integrated by a standard splitting scheme. At each annealing step $k$, with time step $\\Delta t$, apply the sequence\n- Half-kick: $\\mathbf{v}\\leftarrow \\mathbf{v} + \\frac{\\Delta t}{2m}\\mathbf{F}(\\mathbf{r})$ with $\\mathbf{F}=-\\nabla V$.\n- Ornstein–Uhlenbeck (thermostat): $\\mathbf{v} \\leftarrow c\\,\\mathbf{v} + \\sqrt{(1-c^2)T_k/m}\\,\\boldsymbol{\\eta}$ with $c=\\exp(-\\gamma \\Delta t)$ and $\\boldsymbol{\\eta}$ a standard normal vector in $\\mathbb{R}^2$.\n- Drift: $\\mathbf{r}\\leftarrow \\mathbf{r} + \\Delta t\\,\\mathbf{v}$.\n- Half-kick: $\\mathbf{v}\\leftarrow \\mathbf{v} + \\frac{\\Delta t}{2m}\\mathbf{F}(\\mathbf{r})$.\nStart velocities from the Maxwell–Boltzmann distribution at temperature $T_0$, that is, each component is sampled from $\\mathcal{N}(0,T_0/m)$.\n\nStrategy $2$ (SA-MC, simulated annealing via Monte Carlo): Use a Metropolis–Hastings random walk at temperature $T_k$. At step $k$, propose $\\mathbf{r}'=\\mathbf{r} + s_k \\boldsymbol{\\xi}$ where $\\boldsymbol{\\xi}$ is a standard normal vector in $\\mathbb{R}^2$ and $s_k = s_0 \\sqrt{T_k/T_0}$. Accept the proposal with probability $\\min\\{1,\\exp[-(V(\\mathbf{r}')-V(\\mathbf{r}))/T_k]\\}$, otherwise stay at $\\mathbf{r}$.\n\nFor each simulated annealing path, define a candidate transition-state point as follows. Identify the index $k^\\star$ of the maximum potential energy along the path,\n$$\nk^\\star = \\arg\\max_{0\\le k<N} V(\\mathbf{r}_k),\n$$\nand set $\\mathbf{r}_{\\mathrm{TS}}=\\mathbf{r}_{k^\\star}$. From this candidate point, estimate the committor to basin $B$ at a reference temperature $T_{\\mathrm{ref}}$ as the probability to hit $B$ before $A$ under overdamped Langevin dynamics with unit mobility $\\mu=1$,\n$$\nd\\mathbf{r}_t = -\\mu \\nabla V(\\mathbf{r}_t)\\,dt + \\sqrt{2\\mu T_{\\mathrm{ref}}}\\,d\\mathbf{W}_t,\n$$\ndiscretized by the Euler–Maruyama scheme with time step $\\delta t$ until first hitting either basin $A$ or $B$ or until a maximum number of steps is reached (in that last case, continue integrating until a basin is reached or the cap is hit; if the cap is hit, report the hit as whichever basin is closest at that time to ensure a definitive boolean outcome). For each $\\mathbf{r}_{\\mathrm{TS}}$, perform $M$ independent trials and define the empirical committor\n$$\n\\hat{p}_B(\\mathbf{r}_{\\mathrm{TS}}) = \\frac{1}{M}\\sum_{m=1}^M \\mathbf{1}\\{\\text{trial } m \\text{ reaches } B \\text{ before } A\\}.\n$$\nDefine the committor bias for that path as $b=|\\hat{p}_B(\\mathbf{r}_{\\mathrm{TS}})-\\tfrac{1}{2}|$.\n\nFor each test case described below, generate an ensemble of simulated annealing paths for each strategy, compute the committor bias $b$ for each path, and report the mean committor bias for each strategy. Finally, for each test case, output a single integer defined as follows: output $0$ if the SA-MD ensemble mean bias is strictly smaller than the SA-MC ensemble mean bias, output $1$ if the SA-MC ensemble mean bias is strictly smaller than the SA-MD ensemble mean bias, and output $-1$ otherwise. The final output line must be a single list whose entries are exactly these integers for the listed test cases.\n\nUse the following fixed numerical parameters, expressed in the stated units:\n- Simulated annealing common parameters: number of annealing steps $N=700$, initial temperature $T_0=0.40$, final temperature $T_f=0.020$, initialization noise standard deviation $\\sigma_{\\mathrm{init}}=0.020$.\n- SA-MD integrator parameters: time step $\\Delta t=0.010$, mass $m=1$, friction coefficient $\\gamma$ as specified in the test suite case.\n- SA-MC proposal scale: base scale $s_0=0.15$ so that $s_k=s_0 \\sqrt{T_k/T_0}$.\n- Committor estimation parameters: reference temperature $T_{\\mathrm{ref}}=0.060$, Euler–Maruyama time step $\\delta t=0.0040$, maximum number of committor integration steps per trial $N_{\\max}=4000$, number of trials per transition-state point $M=24$.\n- Basin geometry: basin radius $r_{\\mathrm{basin}}=0.20$.\n\nThe test suite contains three cases, each defined by a random seed for reproducibility and by a friction coefficient $\\gamma$ for SA-MD:\n- Case $1$: seed $7$, $\\gamma=1.0$.\n- Case $2$: seed $11$, $\\gamma=0.3$.\n- Case $3$: seed $23$, $\\gamma=3.0$.\n\nYour program must perform, for each test case, an ensemble of $5$ independent runs for SA-MD and $5$ independent runs for SA-MC, each starting from basin $A$ as specified. For random number generation, use the provided case seed and derive distinct seeds for different runs and strategies in a reproducible manner.\n\nFinal output format requirement: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $[0,1,-1]$, where the entries correspond, in order, to the three test cases stated above. No other text should be printed. No physical units conversion is required beyond the dimensionless specification given here. All angles, if any, should be treated as dimensionless since none are used here. All fractional answers must be printed as integers according to the above rule, so no percentages appear anywhere in the output.",
            "solution": "The problem requires a comparative analysis of two simulated annealing (SA) strategies—one based on molecular dynamics (SA-MD) and another on Monte Carlo (SA-MC)—for their effectiveness in identifying transition state (TS) regions on a complex potential energy surface (PES). The quality of the identified candidate TS points is quantified using the committor probability, a rigorous concept from statistical mechanics for characterizing reaction coordinates and transition states.\n\nFirst, we must formally define the environment for our computational experiment. The conformational landscape is described by a two-dimensional Müller-Brown potential energy surface, a standard benchmark for such studies. The function $V(x,y)$ is given by:\n$$\nV(x,y) = s \\sum_{i=1}^{4} A_i \\exp\\left(a_i (x-x_i)^2 + b_i (x-x_i)(y-y_i) + c_i (y-y_i)^2\\right)\n$$\nwhere the parameters $s, A_i, a_i, b_i, c_i, x_i, y_i$ are provided constants. The force on a particle at position $\\mathbf{r} = [x, y]^T$ is the negative gradient of the potential, $\\mathbf{F}(\\mathbf{r}) = -\\nabla V(\\mathbf{r})$, which we compute analytically for use in the dynamics simulations. Let the argument of the exponential for the $i$-th term be $E_i(x,y)$. The partial derivatives are:\n$$\n\\frac{\\partial V}{\\partial x} = s \\sum_{i=1}^{4} A_i e^{E_i(x,y)} \\left( 2a_i(x-x_i) + b_i(y-y_i) \\right)\n$$\n$$\n\\frac{\\partial V}{\\partial y} = s \\sum_{i=1}^{4} A_i e^{E_i(x,y)} \\left( b_i(x-x_i) + 2c_i(y-y_i) \\right)\n$$\nWe define two stable states, basin $A$ and basin $B$, as circular regions in the $(x,y)$ plane: a point $\\mathbf{r}$ is in basin $A$ if $\\|\\mathbf{r}-\\mathbf{r}_A\\| < r_{\\mathrm{basin}}$ and in basin $B$ if $\\|\\mathbf{r}-\\mathbf{r}_B\\| < r_{\\mathrm{basin}}$, where $\\mathbf{r}_A$, $\\mathbf{r}_B$, and $r_{\\mathrm{basin}}$ are given. All simulations are initiated from a random point in the immediate vicinity of the basin $A$ center, $\\mathbf{r}_A$.\n\nThe core of the method is simulated annealing, an optimization heuristic that mimics the process of annealing in metallurgy. A system is initialized at a high temperature $T_0$ and slowly cooled to a low final temperature $T_f$. The temperature $T_k$ at step $k$ of $N$ total steps follows a geometric cooling schedule:\n$$\nT_k = T_0 \\left(\\frac{T_f}{T_0}\\right)^{\\frac{k}{N-1}}, \\quad k=0, 1, \\ldots, N-1.\n$$\nAt high temperatures, the system has sufficient thermal energy to overcome potential barriers, allowing for broad exploration of the conformational space. As the temperature decreases, the system is more likely to settle into low-energy regions. The path traced during this process, $\\{\\mathbf{r}_k\\}_{k=0}^{N-1}$, may cross the primary energy barriers between stable states.\n\nWe compare two distinct algorithms for generating this path:\n\nStrategy 1: Simulated Annealing via Molecular Dynamics (SA-MD). This approach uses a physics-based model of motion. The particle's trajectory is governed by the underdamped Langevin equation, which models a particle of mass $m$ subject to a potential force, a frictional drag proportional to velocity, and a stochastic force from a heat bath. We integrate these dynamics using a robust splitting integrator known as g-BAOAB. For each time step $\\Delta t$ at temperature $T_k$, the position $\\mathbf{r}$ and velocity $\\mathbf{v}$ are updated via the sequence:\n1.  Velocity half-kick: $\\mathbf{v} \\leftarrow \\mathbf{v} + \\frac{\\Delta t}{2m}\\mathbf{F}(\\mathbf{r})$.\n2.  Thermostat: $\\mathbf{v} \\leftarrow c\\,\\mathbf{v} + \\sqrt{(1-c^2)T_k/m}\\,\\boldsymbol{\\eta}$, where $c=\\exp(-\\gamma \\Delta t)$, $\\gamma$ is the friction coefficient, and $\\boldsymbol{\\eta}$ is a vector of independent standard normal random variates. This step couples the system to the heat bath, adjusting the velocity to be consistent with the target temperature $T_k$.\n3.  Position drift: $\\mathbf{r} \\leftarrow \\mathbf{r} + \\Delta t\\,\\mathbf{v}$.\n4.  Velocity half-kick: $\\mathbf{v} \\leftarrow \\mathbf{v} + \\frac{\\Delta t}{2m}\\mathbf{F}(\\mathbf{r})$.\nSA-MD exploration is influenced by inertia; the system has \"memory\" of its direction of motion. The friction coefficient $\\gamma$ modulates this behavior, with low $\\gamma$ corresponding to more persistent, ballistic motion and high $\\gamma$ approaching diffusive motion.\n\nStrategy 2: Simulated Annealing via Monte Carlo (SA-MC). This approach operates directly on the configuration space without considering momentum. At each step $k$, a trial move is proposed from the current position $\\mathbf{r}$ to a new position $\\mathbf{r}' = \\mathbf{r} + s_k \\boldsymbol{\\xi}$, where $\\boldsymbol{\\xi}$ is a standard normal random vector and $s_k$ is a temperature-dependent step size, $s_k = s_0 \\sqrt{T_k/T_0}$. This trial move is accepted or rejected based on the Metropolis criterion: the move is accepted with probability $P_{\\text{acc}} = \\min\\{1, \\exp(-\\Delta V/T_k)\\}$, where $\\Delta V = V(\\mathbf{r}') - V(\\mathbf{r})$. If the move is rejected, the system remains at $\\mathbf{r}$. This algorithm ensures that the system's configurations will eventually sample the Boltzmann distribution at temperature $T_k$. Exploration is purely probabilistic and local.\n\nAfter generating a path via either SA-MD or SA-MC, we identify a candidate for the transition state. An ideal transition path between basins $A$ and $B$ will cross the dividing surface between them at a point of maximum potential energy. We thus select the point of highest potential energy along the SA trajectory, $\\mathbf{r}_{\\mathrm{TS}} = \\mathbf{r}_{k^\\star}$ where $k^\\star = \\arg\\max_{0\\le k<N} V(\\mathbf{r}_k)$, as our candidate TS point.\n\nThe quality of this candidate is assessed by computing its committor probability to basin $B$, denoted $p_B(\\mathbf{r}_{\\mathrm{TS}})$. The committor $p_B(\\mathbf{r})$ is the probability that a trajectory initiated at $\\mathbf{r}$ will reach basin $B$ before reaching basin $A$. A \"perfect\" transition state lies on the separatrix where this probability is exactly $1/2$. We empirically estimate $p_B(\\mathbf{r}_{\\mathrm{TS}})$ by launching $M$ independent simulation trials from $\\mathbf{r}_{\\mathrm{TS}}$. These trial trajectories follow overdamped Langevin dynamics at a fixed reference temperature $T_{\\text{ref}}$, governed by the stochastic differential equation $d\\mathbf{r}_t = -\\mu \\nabla V(\\mathbf{r}_t)\\,dt + \\sqrt{2\\mu T_{\\text{ref}}}\\,d\\mathbf{W}_t$. Each trial is run until it enters either basin $A$ or $B$. The empirical committor $\\hat{p}_B(\\mathbf{r}_{\\mathrm{TS}})$ is the fraction of these $M$ trials that reach basin $B$ first. We quantify the deviation from an ideal TS by the committor bias, $b = |\\hat{p}_B(\\mathbf{r}_{\\mathrm{TS}}) - 1/2|$. A lower bias indicates a better TS candidate.\n\nThe final step is to perform this entire procedure for an ensemble of an equal number of SA-MD and SA-MC runs for each test case. By comparing the ensemble average of the committor bias, $\\bar{b}_{\\mathrm{MD}}$ and $\\bar{b}_{\\mathrm{MC}}$, we can determine which strategy, on average, is more effective at locating the true transition state region under the specified conditions. A result of $0$ indicates SA-MD is superior (lower bias), $1$ indicates SA-MC is superior, and $-1$ indicates no significant difference. This provides a quantitative comparison of a dynamics-based versus a statistics-based search strategy.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    # Final print statement in the exact required format.\n    # Note: scipy is not needed as erf is not required for standard normal generation.\n    np.set_printoptions(precision=15)\n\n    # Define the Müller-Brown potential\n    class MullerBrown:\n        def __init__(self):\n            self.s = 0.05\n            self.A = np.array([-200, -100, -170, 15])\n            self.a = np.array([-1, -1, -6.5, 0.7])\n            self.b = np.array([0, 0, 11, 0.6])\n            self.c = np.array([-10, -10, -6.5, 0.7])\n            self.x0 = np.array([1, 0, -0.5, -1])\n            self.y0 = np.array([0, 0.5, 1.5, 1])\n\n        def potential(self, r):\n            x, y = r[0], r[1]\n            val = 0.0\n            for i in range(4):\n                dx = x - self.x0[i]\n                dy = y - self.y0[i]\n                exp_arg = self.a[i] * dx**2 + self.b[i] * dx * dy + self.c[i] * dy**2\n                val += self.A[i] * np.exp(exp_arg)\n            return self.s * val\n\n        def gradient(self, r):\n            x, y = r[0], r[1]\n            grad_x, grad_y = 0.0, 0.0\n            for i in range(4):\n                dx = x - self.x0[i]\n                dy = y - self.y0[i]\n                exp_arg = self.a[i] * dx**2 + self.b[i] * dx * dy + self.c[i] * dy**2\n                exp_val = np.exp(exp_arg)\n                \n                d_exp_arg_dx = 2 * self.a[i] * dx + self.b[i] * dy\n                d_exp_arg_dy = self.b[i] * dx + 2 * self.c[i] * dy\n\n                grad_x += self.A[i] * exp_val * d_exp_arg_dx\n                grad_y += self.A[i] * exp_val * d_exp_arg_dy\n            \n            return self.s * np.array([grad_x, grad_y])\n\n    # Shared parameters\n    PES = MullerBrown()\n    R_A = np.array([-0.558, 1.442])\n    R_B = np.array([0.623, 0.028])\n    R_BASIN = 0.20\n    R_BASIN_SQ = R_BASIN**2\n\n    N_SA = 700\n    T0 = 0.40\n    TF = 0.020\n    SIGMA_INIT = 0.020\n    ENSEMBLE_SIZE = 5\n\n    # Committor parameters\n    T_REF = 0.060\n    DT_COMMIT = 0.0040\n    N_MAX_COMMIT = 4000\n    M_COMMIT = 24\n    MU = 1.0\n\n    # SA-MD parameters\n    DT_MD = 0.010\n    M_MD = 1.0\n\n    # SA-MC parameters\n    S0_MC = 0.15\n\n    # Simulated annealing cooling schedule\n    temps = T0 * (TF/T0)**(np.arange(N_SA) / (N_SA - 1))\n\n    # --- Committor Estimation ---\n    def estimate_committor(r_ts, rng):\n        hits_B = 0\n        sqrt_term = np.sqrt(2 * MU * T_REF * DT_COMMIT)\n\n        for _ in range(M_COMMIT):\n            r = np.copy(r_ts)\n            hit = None\n            for _ in range(N_MAX_COMMIT):\n                grad = PES.gradient(r)\n                noise = rng.normal(0, 1, size=2)\n                r -= MU * grad * DT_COMMIT + sqrt_term * noise\n                \n                dist_sq_A = np.sum((r - R_A)**2)\n                if dist_sq_A < R_BASIN_SQ:\n                    hit = 'A'\n                    break\n                \n                dist_sq_B = np.sum((r - R_B)**2)\n                if dist_sq_B < R_BASIN_SQ:\n                    hit = 'B'\n                    break\n            \n            if hit == 'B':\n                hits_B += 1\n            elif hit is None: # Tie-breaker\n                dist_sq_A = np.sum((r - R_A)**2)\n                dist_sq_B = np.sum((r - R_B)**2)\n                if dist_sq_B < dist_sq_A:\n                    hits_B += 1\n        \n        return hits_B / M_COMMIT\n\n    # --- SA Strategies ---\n    def run_sa_md(gamma, rng):\n        r = R_A + rng.normal(0, SIGMA_INIT, size=2)\n        v = rng.normal(0, np.sqrt(T0 / M_MD), size=2)\n        \n        path = np.zeros((N_SA, 2))\n        path[0] = r\n        potentials = np.zeros(N_SA)\n        potentials[0] = PES.potential(r)\n\n        c = np.exp(-gamma * DT_MD)\n        c_factor_sqrt = np.sqrt((1 - c**2) / M_MD)\n        dt_over_2m = DT_MD / (2 * M_MD)\n\n        for k in range(N_SA - 1):\n            T_k = temps[k]\n            \n            # g-BAOAB integrator\n            force = -PES.gradient(r)\n            v += dt_over_2m * force\n            \n            v = c * v + np.sqrt(T_k) * c_factor_sqrt * rng.normal(0, 1, size=2)\n            \n            r += DT_MD * v\n            \n            force = -PES.gradient(r)\n            v += dt_over_2m * force\n            \n            path[k+1] = r\n            potentials[k+1] = PES.potential(r)\n        \n        k_star = np.argmax(potentials)\n        r_ts = path[k_star]\n        pB = estimate_committor(r_ts, rng)\n        return np.abs(pB - 0.5)\n\n    def run_sa_mc(rng):\n        r = R_A + rng.normal(0, SIGMA_INIT, size=2)\n        v_current = PES.potential(r)\n\n        path = np.zeros((N_SA, 2))\n        path[0] = r\n        potentials = np.zeros(N_SA)\n        potentials[0] = v_current\n\n        step_scales = S0_MC * np.sqrt(temps / T0)\n\n        for k in range(N_SA - 1):\n            T_k = temps[k]\n            s_k = step_scales[k]\n            \n            r_prime = r + rng.normal(0, s_k, size=2)\n            v_prime = PES.potential(r_prime)\n            \n            delta_v = v_prime - v_current\n            \n            if delta_v < 0 or rng.random() < np.exp(-delta_v / T_k):\n                r = r_prime\n                v_current = v_prime\n            \n            path[k+1] = r\n            potentials[k+1] = v_current\n            \n        k_star = np.argmax(potentials)\n        r_ts = path[k_star]\n        pB = estimate_committor(r_ts, rng)\n        return np.abs(pB - 0.5)\n\n    # --- Main Loop ---\n    test_cases = [\n        (7, 1.0),\n        (11, 0.3),\n        (23, 3.0),\n    ]\n\n    results = []\n    \n    for seed, gamma in test_cases:\n        master_rng = np.random.default_rng(seed)\n        md_seeds = master_rng.integers(0, 2**32, size=ENSEMBLE_SIZE)\n        mc_seeds = master_rng.integers(0, 2**32, size=ENSEMBLE_SIZE)\n\n        md_biases = []\n        for run_seed in md_seeds:\n            rng = np.random.default_rng(run_seed)\n            bias = run_sa_md(gamma, rng)\n            md_biases.append(bias)\n        \n        mc_biases = []\n        for run_seed in mc_seeds:\n            rng = np.random.default_rng(run_seed)\n            bias = run_sa_mc(rng)\n            mc_biases.append(bias)\n        \n        mean_md_bias = np.mean(md_biases)\n        mean_mc_bias = np.mean(mc_biases)\n\n        if mean_md_bias < mean_mc_bias:\n            results.append(0)\n        elif mean_mc_bias < mean_md_bias:\n            results.append(1)\n        else:\n            results.append(-1)\n            \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}