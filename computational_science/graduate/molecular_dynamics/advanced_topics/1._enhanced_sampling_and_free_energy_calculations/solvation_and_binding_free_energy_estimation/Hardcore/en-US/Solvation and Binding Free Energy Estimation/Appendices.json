{
    "hands_on_practices": [
        {
            "introduction": "At the heart of many free energy calculations lies the principle of thermodynamic integration (TI), which connects microscopic simulation data to macroscopic thermodynamic properties. This exercise guides you through the process of taking the ensemble-averaged derivative of the potential, $\\langle \\partial U / \\partial \\lambda \\rangle$, and integrating it to obtain the free energy difference, $\\Delta G$. You will develop a practical algorithm for this integration, including the crucial step of propagating statistical uncertainties from your simulation data.",
            "id": "3447320",
            "problem": "You are studying solvation or binding free energy differences via thermodynamic integration in molecular dynamics. Consider a system with a differentiable coupling parameter $\\lambda \\in [0,1]$ that modulates the potential energy function $U(\\mathbf{x};\\lambda)$ over configurations $\\mathbf{x}$. The Helmholtz free energy $A(\\lambda)$ is defined by the partition function with inverse temperature $\\beta = 1/(k_{\\mathrm{B}} T)$ as $A(\\lambda) = -\\beta^{-1} \\ln Z(\\lambda)$ with $Z(\\lambda) = \\int \\exp\\{-\\beta U(\\mathbf{x};\\lambda)\\} \\, d\\mathbf{x}$. You are given sampled ensemble averages $\\langle \\partial U/\\partial \\lambda \\rangle_{\\lambda_i}$ at discrete $\\lambda$ values with associated uncertainties and, in one case, a non-diagonal covariance capturing cross-correlations between estimates at different $\\lambda$ values.\n\nTask 1 (derivation): Starting from the fundamental definition of the Helmholtz free energy $A(\\lambda)$ and well-accepted thermodynamic identities from statistical mechanics, derive an expression that relates a free energy difference $\\Delta G$ over a $\\lambda$ interval to an integral over an ensemble average of a derivative of the potential energy with respect to $\\lambda$. Derive how to approximate this integral on an arbitrary, strictly increasing grid $\\{\\lambda_i\\}_{i=0}^{N-1}$ using a composite quadrature rule that:\n- Uses a locally quadratic interpolatory rule on nonoverlapping triplets $(\\lambda_i,\\lambda_{i+1},\\lambda_{i+2})$ whenever possible, integrating the unique quadratic Lagrange interpolant over $[\\lambda_i,\\lambda_{i+2}]$.\n- Falls back to the trapezoidal rule on a single interval $[\\lambda_i,\\lambda_{i+1}]$ when a triplet is not available (for example, when a leftover pair remains at the end or when the total number of intervals is odd).\nYour derivation should show that the overall estimator can be written as a single linear functional of the data values, i.e., as a weighted sum $\\widehat{\\Delta G} = \\sum_{i=0}^{N-1} w_i \\, y_i$ where $y_i \\equiv \\langle \\partial U/\\partial \\lambda \\rangle_{\\lambda_i}$ and the weights $w_i$ depend only on the $\\lambda$ grid and the chosen composite quadrature.\n\nTask 2 (uncertainty propagation): Derive an expression for the variance of $\\widehat{\\Delta G}$ under two scenarios:\n- If only independent standard errors $s_i$ are available at each $\\lambda_i$, show how to compute $\\mathrm{Var}(\\widehat{\\Delta G})$ using the quadrature weights and the $s_i$.\n- If a full covariance matrix $\\mathbf{C}$ with entries $C_{ij}$ is available, show how to compute $\\mathrm{Var}(\\widehat{\\Delta G})$ using $\\mathbf{C}$ and the quadrature weights.\n\nTask 3 (algorithm): Design an algorithm that, given arbitrary strictly increasing $\\{\\lambda_i\\}$, the corresponding $y_i$, and either standard errors $s_i$ or a full covariance matrix $\\mathbf{C}$, constructs the composite-quadtrature weights $\\{w_i\\}$ by:\n- Partitioning the grid from the smallest to the largest $\\lambda$ into nonoverlapping triplets where possible, applying the quadratic Lagrange rule on each triplet to contribute weights to the three involved indices, and then\n- Applying the trapezoidal rule on any leftover final interval if needed.\nThen compute $\\widehat{\\Delta G}$ and its standard error from these weights and uncertainties. Your algorithm must sort the input $\\lambda$ values if they are not provided in ascending order and must apply the same permutation consistently to $y_i$ and either $s_i$ or $\\mathbf{C}$. Assume all $\\lambda$ are distinct.\n\nImplementation and testing requirements:\n- Units: Each $y_i$ is given in $\\mathrm{kJ/mol}$, $\\lambda$ is dimensionless, and therefore your $\\widehat{\\Delta G}$ must be reported in $\\mathrm{kJ/mol}$. All uncertainties and standard errors must be reported in $\\mathrm{kJ/mol}$. Express the final results in $\\mathrm{kJ/mol}$ and round each reported float to $6$ decimal places.\n- Angle units do not apply in this problem.\n- Your program must implement the algorithm above and evaluate the following four test cases. For each test case, compute and report a pair of floats: first $\\widehat{\\Delta G}$ in $\\mathrm{kJ/mol}$ and then its standard error in $\\mathrm{kJ/mol}$, both rounded to $6$ decimal places.\n\nTest suite:\n- Test case $1$ (uniform grid, quadratic signal):\n  - $\\lambda = [\\,0.0,\\,0.25,\\,0.5,\\,0.75,\\,1.0\\,]$.\n  - $y_i = 2 + 3\\lambda_i - \\lambda_i^2$ for each $\\lambda_i$.\n  - $s_i = 0.05$ for all $i$.\n  - No cross-covariances are provided; treat measurement errors as independent.\n- Test case $2$ (nonuniform grid with correlated errors):\n  - $\\lambda = [\\,0.0,\\,0.1,\\,0.4,\\,0.9,\\,1.0\\,]$.\n  - $y_i = 1.5 + 0.5\\lambda_i + 2\\lambda_i^2$ for each $\\lambda_i$.\n  - Standard errors: $s = [\\,0.08,\\,0.10,\\,0.07,\\,0.09,\\,0.08\\,]$.\n  - Use a full covariance matrix $\\mathbf{C}$ with diagonal entries $C_{ii} = s_i^2$, off-diagonals between adjacent points given by $C_{i,i+1} = C_{i+1,i} = \\rho_1 s_i s_{i+1}$ with $\\rho_1 = 0.3$, off-diagonals between second neighbors given by $C_{i,i+2} = C_{i+2,i} = \\rho_2 s_i s_{i+2}$ with $\\rho_2 = 0.1$, and all other off-diagonals equal to $0$.\n- Test case $3$ (two-point boundary case):\n  - $\\lambda = [\\,0.0,\\,1.0\\,]$.\n  - $y = [\\,1.0,\\,3.0\\,]$.\n  - $s = [\\,0.2,\\,0.2\\,]$.\n  - No cross-covariances are provided; treat measurement errors as independent.\n- Test case $4$ (odd number of intervals, nonuniform grid, smooth non-polynomial signal):\n  - $\\lambda = [\\,0.0,\\,0.05,\\,0.2,\\,0.6,\\,0.85,\\,1.0\\,]$.\n  - $y_i = 2 + \\sin(\\pi \\lambda_i)$ for each $\\lambda_i$, where $\\pi$ is the circle constant.\n  - $s = [\\,0.05,\\,0.06,\\,0.04,\\,0.05,\\,0.07,\\,0.05\\,]$.\n  - No cross-covariances are provided; treat measurement errors as independent.\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain, in order, for test cases $1$ through $4$, the estimated free energy difference and its standard error for each case. For example, the output must look like\n  - $[g_1,e_1,g_2,e_2,g_3,e_3,g_4,e_4]$,\nwhere each $g_i$ and $e_i$ is a float rounded to $6$ decimal places, in $\\mathrm{kJ/mol}$.",
            "solution": "The problem is valid as it is scientifically grounded in statistical mechanics, mathematically well-posed, and all necessary data and definitions are provided for a unique solution.\n\n### Task 1: Derivation of the Free Energy Estimator\n\nThe fundamental relationship for thermodynamic integration is derived from the definition of the Helmholtz free energy, $A(\\lambda)$, as a function of a coupling parameter $\\lambda$. The free energy is related to the canonical partition function $Z(\\lambda)$ at an inverse temperature $\\beta = 1/(k_{\\mathrm{B}} T)$:\n$$A(\\lambda) = -\\frac{1}{\\beta} \\ln Z(\\lambda)$$\nwhere $Z(\\lambda) = \\int \\exp\\{-\\beta U(\\mathbf{x};\\lambda)\\} \\, d\\mathbf{x}$ is the integral over all configurational states $\\mathbf{x}$ of the system with potential energy $U(\\mathbf{x};\\lambda)$.\n\nTo find the free energy difference, we first differentiate $A(\\lambda)$ with respect to $\\lambda$:\n$$ \\frac{dA(\\lambda)}{d\\lambda} = -\\frac{1}{\\beta Z(\\lambda)} \\frac{dZ(\\lambda)}{d\\lambda} $$\nThe derivative of the partition function is:\n$$ \\frac{dZ(\\lambda)}{d\\lambda} = \\int \\frac{\\partial}{\\partial\\lambda} e^{-\\beta U(\\mathbf{x};\\lambda)} \\, d\\mathbf{x} = \\int \\left(-\\beta \\frac{\\partial U(\\mathbf{x};\\lambda)}{\\partial\\lambda}\\right) e^{-\\beta U(\\mathbf{x};\\lambda)} \\, d\\mathbf{x} $$\nSubstituting this back into the expression for $dA/d\\lambda$:\n$$ \\frac{dA(\\lambda)}{d\\lambda} = -\\frac{1}{\\beta Z(\\lambda)} \\int \\left(-\\beta \\frac{\\partial U}{\\partial\\lambda}\\right) e^{-\\beta U(\\mathbf{x};\\lambda)} \\, d\\mathbf{x} = \\frac{\\int \\frac{\\partial U}{\\partial\\lambda} e^{-\\beta U(\\mathbf{x};\\lambda)} \\, d\\mathbf{x}}{\\int e^{-\\beta U(\\mathbf{x};\\lambda)} \\, d\\mathbf{x}} $$\nThe right-hand side is the definition of the canonical ensemble average of the quantity $\\partial U/\\partial \\lambda$ at the given value of $\\lambda$. Therefore, we arrive at the central identity:\n$$ \\frac{dA(\\lambda)}{d\\lambda} = \\left\\langle \\frac{\\partial U}{\\partial \\lambda} \\right\\rangle_{\\lambda} $$\nThe total free energy difference $\\Delta G$ between $\\lambda=0$ and $\\lambda=1$ is obtained by integrating this derivative. (We use $\\Delta G$ as specified in the problem, noting it is equivalent to $\\Delta A$ in an NVT ensemble). Let $y(\\lambda) = \\langle \\partial U/\\partial \\lambda \\rangle_{\\lambda}$.\n$$ \\Delta G = A(1) - A(0) = \\int_0^1 \\frac{dA(\\lambda)}{d\\lambda} \\, d\\lambda = \\int_0^1 \\left\\langle \\frac{\\partial U}{\\partial \\lambda} \\right\\rangle_{\\lambda} \\, d\\lambda = \\int_0^1 y(\\lambda) d\\lambda $$\nWe are given samples of this function, $y_i = y(\\lambda_i)$, at a set of discrete points $\\{\\lambda_i\\}_{i=0}^{N-1}$. The task is to numerically approximate this integral using a specific composite quadrature rule. The overall integral is the sum of integrals over non-overlapping segments of the grid. The rule is to process the grid by grouping adjacent intervals in pairs, which corresponds to using triplets of points $(\\lambda_i, \\lambda_{i+1}, \\lambda_{i+2})$, and applying a quadratic interpolatory rule. If an odd number of intervals results in a final, single interval $[\\lambda_{N-2}, \\lambda_{N-1}]$, the trapezoidal rule is used.\n\n**Quadratic Rule on a Triplet $(\\lambda_i, \\lambda_{i+1}, \\lambda_{i+2})$**\nFor three non-collinear points $(\\lambda_i, y_i)$, $(\\lambda_{i+1}, y_{i+1})$, and $(\\lambda_{i+2}, y_{i+2})$, there exists a unique quadratic polynomial $P_2(\\lambda)$ that passes through them. The integral of $y(\\lambda)$ over $[\\lambda_i, \\lambda_{i+2}]$ is approximated by integrating this polynomial. The result is a weighted sum of the function values $y_i$, $y_{i+1}$, and $y_{i+2}$. For non-uniformly spaced abscissas, let $h_1 = \\lambda_{i+1} - \\lambda_i$ and $h_2 = \\lambda_{i+2} - \\lambda_{i+1}$. The integral of the Lagrange interpolating polynomial is given by:\n$$ \\int_{\\lambda_i}^{\\lambda_{i+2}} P_2(\\lambda) \\, d\\lambda = w'_{i} y_i + w'_{i+1} y_{i+1} + w'_{i+2} y_{i+2} $$\nwhere the weights are:\n$$ w'_{i} = \\frac{h_1+h_2}{6h_1 h_2} h_2(2h_1-h_2) $$\n$$ w'_{i+1} = \\frac{h_1+h_2}{6h_1 h_2} (h_1+h_2)^2 $$\n$$ w'_{i+2} = \\frac{h_1+h_2}{6h_1 h_2} h_1(2h_2-h_1) $$\nThe sum of these weights is $w'_i+w'_{i+1}+w'_{i+2} = h_1+h_2 = \\lambda_{i+2}-\\lambda_i$, the length of the integration subinterval.\n\n**Trapezoidal Rule on a Pair $(\\lambda_i, \\lambda_{i+1})$**\nIf a single interval $[\\lambda_i, \\lambda_{i+1}]$ remains, we use the trapezoidal rule, which approximates the integral by the area of a trapezoid:\n$$ \\int_{\\lambda_i}^{\\lambda_{i+1}} y(\\lambda) \\, d\\lambda \\approx \\frac{\\lambda_{i+1}-\\lambda_i}{2}(y_i + y_{i+1}) = w'_{i} y_i + w'_{i+1} y_{i+1} $$\nwhere the weight contributions are $w'_{i} = w'_{i+1} = (\\lambda_{i+1}-\\lambda_i)/2$.\n\n**Composite Rule and Linear Functional Form**\nThe total integral approximation, $\\widehat{\\Delta G}$, is the sum of the results from applying these rules to the partitioned grid. For example, on a grid with $N$ points and $M=N-1$ intervals, we iterate from $i=0$ with a step of $2$. For each $i$ where $i+2 < N$, we apply the quadratic rule to the triplet $(\\lambda_i, \\lambda_{i+1}, \\lambda_{i+2})$, adding the calculated contributions to a global weights vector. If $M$ is odd, a final interval $[\\lambda_{N-2}, \\lambda_{N-1}]$ remains, to which we apply the trapezoidal rule.\nThe total estimated free energy is:\n$$ \\widehat{\\Delta G} = \\sum_{\\text{sub-integrals}} (\\text{local weighted sum of } y_k) $$\nSince each $y_k$ may contribute to one or two adjacent sub-integrals (e.g., $y_2$ in $\\int_{\\lambda_0}^{\\lambda_2}$ and $\\int_{\\lambda_2}^{\\lambda_4}$), the process can be formulated as computing a single set of weights $\\{w_i\\}$ such that:\n$$ \\widehat{\\Delta G} = \\sum_{i=0}^{N-1} w_i y_i $$\nEach $w_i$ is the sum of all contributions from the local rules that involve the point $(\\lambda_i, y_i)$. This demonstrates that the estimator is a linear functional of the data values $\\{y_i\\}$.\n\n### Task 2: Uncertainty Propagation\n\nThe estimator $\\widehat{\\Delta G}$ is a linear combination of the measured quantities $y_i$, which are random variables. Let $\\mathbf{w} = [w_0, \\dots, w_{N-1}]^T$ be the vector of weights and $\\mathbf{y} = [y_0, \\dots, y_{N-1}]^T$ be the vector of measurements. The estimator is $\\widehat{\\Delta G} = \\mathbf{w}^T \\mathbf{y}$.\n\n**General Case: Full Covariance Matrix**\nThe variance of a linear combination of correlated random variables is given by the general formula:\n$$ \\mathrm{Var}(\\widehat{\\Delta G}) = \\mathrm{Var}(\\mathbf{w}^T \\mathbf{y}) = \\mathbf{w}^T \\mathbf{C} \\mathbf{w} $$\nwhere $\\mathbf{C}$ is the covariance matrix of $\\mathbf{y}$, with entries $C_{ij} = \\mathrm{Cov}(y_i, y_j)$. In expanded form, this is:\n$$ \\mathrm{Var}(\\widehat{\\Delta G}) = \\sum_{i=0}^{N-1} \\sum_{j=0}^{N-1} w_i C_{ij} w_j $$\n\n**Special Case: Independent Errors**\nIf the measurement errors at each $\\lambda_i$ are independent, the covariance matrix $\\mathbf{C}$ is diagonal. The off-diagonal elements are zero, $C_{ij} = 0$ for $i \\neq j$. The diagonal elements are the variances of each measurement, $C_{ii} = \\mathrm{Var}(y_i) = s_i^2$, where $s_i$ is the standard error of $y_i$.\nIn this case, the double summation for the variance simplifies significantly:\n$$ \\mathrm{Var}(\\widehat{\\Delta G}) = \\sum_{i=0}^{N-1} \\sum_{j=0}^{N-1} w_i (\\delta_{ij} s_j^2) w_j = \\sum_{i=0}^{N-1} w_i^2 s_i^2 $$\nThe standard error of the estimate $\\widehat{\\Delta G}$ is in both cases the square root of the variance, $\\sigma_{\\widehat{\\Delta G}} = \\sqrt{\\mathrm{Var}(\\widehat{\\Delta G})}$.\n\n### Task 3: Algorithm Design\n\nThe algorithm computes $\\widehat{\\Delta G}$ and its standard error given a set of points $\\{\\lambda_i\\}$, corresponding values $\\{y_i\\}$, and uncertainties (either standard errors $\\{s_i\\}$ or a covariance matrix $\\mathbf{C}$).\n\n1.  **Input Sorting**: Given the inputs $\\lambda = \\{\\lambda_i\\}$, $y = \\{y_i\\}$, and uncertainties, first ensure the data is ordered by $\\lambda$. Compute the permutation `p` that sorts $\\lambda$ in ascending order. Apply this permutation to $\\lambda$, $y$, and the uncertainties (either the vector $s$ or both rows and columns of matrix $\\mathbf{C}$). Let the sorted data be denoted $\\lambda^{\\text{s}}, y^{\\text{s}}, s^{\\text{s}}, \\mathbf{C}^{\\text{s}}$. Let $N$ be the number of data points.\n\n2.  **Weight Calculation**: Initialize a vector of weights $w$ of size $N$ to all zeros. Iterate through the grid from the beginning, processing intervals in pairs.\n    - Let a counter `i` start at $0$.\n    - While `i + 2 < N`, we can form a triplet $(\\lambda^{\\text{s}}_i, \\lambda^{\\text{s}}_{i+1}, \\lambda^{\\text{s}}_{i+2})$.\n        - Calculate the step sizes $h_1 = \\lambda^{\\text{s}}_{i+1} - \\lambda^{\\text{s}}_i$ and $h_2 = \\lambda^{\\text{s}}_{i+2} - \\lambda^{\\text{s}}_{i+1}$.\n        - Calculate the weight contributions $w'_i, w'_{i+1}, w'_{i+2}$ for this triplet using the quadratic rule formulas from Task 1.\n        - Add these contributions to the global weights: $w_i \\leftarrow w_i + w'_i$, $w_{i+1} \\leftarrow w_{i+1} + w'_{i+1}$, $w_{i+2} \\leftarrow w_{i+2} + w'_{i+2}$.\n        - Increment the counter: `i \\leftarrow i + 2`.\n    - After the loop, if the total number of intervals ($N-1$) was odd, one interval, $[\\lambda^{\\text{s}}_{N-2}, \\lambda^{\\text{s}}_{N-1}]$, will be left. This corresponds to `i == N-2`.\n        - Calculate the step size $\\Delta\\lambda = \\lambda^{\\text{s}}_{N-1} - \\lambda^{\\text{s}}_{N-2}$.\n        - Apply the trapezoidal rule: add $\\Delta\\lambda/2$ to both $w_{N-2}$ and $w_{N-1}$.\n\n3.  **Free Energy Estimation**: Compute the estimated free energy difference by taking the dot product of the final weights vector and the sorted values vector:\n    $$ \\widehat{\\Delta G} = \\sum_{i=0}^{N-1} w_i y^{\\text{s}}_i $$\n\n4.  **Uncertainty Estimation**: Calculate the variance of the estimate.\n    - If independent standard errors $s^{\\text{s}}$ are provided:\n      $$ \\mathrm{Var}(\\widehat{\\Delta G}) = \\sum_{i=0}^{N-1} w_i^2 (s^{\\text{s}}_i)^2 $$\n    - If a covariance matrix $\\mathbf{C}^{\\text{s}}$ is provided:\n      $$ \\mathrm{Var}(\\widehat{\\Delta G}) = \\mathbf{w}^T \\mathbf{C}^{\\text{s}} \\mathbf{w} $$\n    - The standard error is $\\sigma_{\\widehat{\\Delta G}} = \\sqrt{\\mathrm{Var}(\\widehat{\\Delta G})}$.\n\n5.  **Output**: Return the calculated $\\widehat{\\Delta G}$ and its standard error $\\sigma_{\\widehat{\\Delta G}}$, formatted as required.",
            "answer": "```python\nimport numpy as np\n\ndef calculate_free_energy(lambdas, y_values, uncertainties):\n    \"\"\"\n    Calculates the free energy difference and its uncertainty using a custom\n    composite quadrature rule.\n\n    Args:\n        lambdas (np.ndarray): 1D array of lambda values.\n        y_values (np.ndarray): 1D array of <dU/dl> values.\n        uncertainties (np.ndarray): Either a 1D array of standard errors\n                                   or a 2D covariance matrix.\n\n    Returns:\n        tuple[float, float]: A tuple containing the estimated free energy\n                             difference and its standard error.\n    \"\"\"\n    # Step 1: Input Sorting\n    if not isinstance(lambdas, np.ndarray):\n        lambdas = np.array(lambdas, dtype=float)\n    if not isinstance(y_values, np.ndarray):\n        y_values = np.array(y_values, dtype=float)\n    if not isinstance(uncertainties, np.ndarray):\n        uncertainties = np.array(uncertainties, dtype=float)\n\n    p = np.argsort(lambdas)\n    l_sorted = lambdas[p]\n    y_sorted = y_values[p]\n    \n    is_cov_matrix = uncertainties.ndim == 2\n    if is_cov_matrix:\n        C_sorted = uncertainties[p, :][:, p]\n    else:\n        s_sorted = uncertainties[p]\n\n    N = len(l_sorted)\n    if N < 2:\n        return 0.0, 0.0\n\n    # Step 2: Weight Calculation\n    weights = np.zeros(N)\n    i = 0\n    while i + 2 < N:\n        # Triplet of points for quadratic rule\n        l_i, l_ip1, l_ip2 = l_sorted[i], l_sorted[i+1], l_sorted[i+2]\n        \n        h1 = l_ip1 - l_i\n        h2 = l_ip2 - l_ip1\n        \n        if h1 <= 0 or h2 <= 0:\n            raise ValueError(\"Lambda values must be strictly increasing.\")\n\n        common_factor = (h1 + h2) / (6.0 * h1 * h2)\n        \n        w_i_contrib = common_factor * h2 * (2 * h1 - h2)\n        w_ip1_contrib = common_factor * (h1 + h2)**2\n        w_ip2_contrib = common_factor * h1 * (2 * h2 - h1)\n        \n        weights[i] += w_i_contrib\n        weights[i+1] += w_ip1_contrib\n        weights[i+2] += w_ip2_contrib\n        \n        i += 2\n\n    if i == N - 2:\n        # Leftover final interval for trapezoidal rule\n        l_i, l_ip1 = l_sorted[i], l_sorted[i+1]\n        delta_l = l_ip1 - l_i\n        weights[i] += delta_l / 2.0\n        weights[i+1] += delta_l / 2.0\n\n    # Step 3: Free Energy Estimation\n    delta_g = np.dot(weights, y_sorted)\n\n    # Step 4: Uncertainty Estimation\n    if is_cov_matrix:\n        variance = weights.T @ C_sorted @ weights\n    else:\n        variance = np.sum(weights**2 * s_sorted**2)\n    \n    std_error = np.sqrt(variance)\n\n    return delta_g, std_error\n\ndef solve():\n    # Test Case 1\n    l1 = np.array([0.0, 0.25, 0.5, 0.75, 1.0])\n    y1 = 2 + 3*l1 - l1**2\n    s1 = np.full_like(l1, 0.05)\n    g1, e1 = calculate_free_energy(l1, y1, s1)\n\n    # Test Case 2\n    l2 = np.array([0.0, 0.1, 0.4, 0.9, 1.0])\n    y2 = 1.5 + 0.5*l2 + 2*l2**2\n    s2 = np.array([0.08, 0.10, 0.07, 0.09, 0.08])\n    N2 = len(l2)\n    C2 = np.zeros((N2, N2))\n    rho1 = 0.3\n    rho2 = 0.1\n    for i in range(N2):\n        for j in range(N2):\n            if i == j:\n                C2[i, j] = s2[i]**2\n            elif abs(i - j) == 1:\n                C2[i, j] = rho1 * s2[i] * s2[j]\n            elif abs(i - j) == 2:\n                C2[i, j] = rho2 * s2[i] * s2[j]\n    g2, e2 = calculate_free_energy(l2, y2, C2)\n\n    # Test Case 3\n    l3 = np.array([0.0, 1.0])\n    y3 = np.array([1.0, 3.0])\n    s3 = np.array([0.2, 0.2])\n    g3, e3 = calculate_free_energy(l3, y3, s3)\n\n    # Test Case 4\n    l4 = np.array([0.0, 0.05, 0.2, 0.6, 0.85, 1.0])\n    y4 = 2 + np.sin(np.pi * l4)\n    s4 = np.array([0.05, 0.06, 0.04, 0.05, 0.07, 0.05])\n    g4, e4 = calculate_free_energy(l4, y4, s4)\n\n    results = [round(v, 6) for v in [g1, e1, g2, e2, g3, e3, g4, e4]]\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Calculating the absolute binding free energy via the \"double-decoupling\" method introduces a unique challenge: how to keep the non-interacting ligand from diffusing away from the binding site. This is typically solved by applying restraints, but the act of restraining the ligand itself has a free energy cost that must be analytically calculated and removed. This practice  will guide you through the first-principles derivation of this crucial correction, highlighting the difference between simple and more rigorous approximations for the complex coordinate systems involved.",
            "id": "3447410",
            "problem": "Consider the double-decoupling approach to binding free energy estimation for a rigid ligand in a rigid binding site within classical statistical mechanics. Focus on the configurational contribution of restraints that keep a noninteracting ligand localized to a binding pose during decoupling. The ligand is treated as a rigid body whose relative pose to the receptor is parameterized by one intermolecular distance $r$, two polar angles $\\theta_A$ and $\\theta_B$, and three dihedral angles $\\phi_1$, $\\phi_2$, and $\\phi_3$. The thermodynamic quantity of interest is the reversible work to apply restraints to the noninteracting ligand relative to a reference state defined by a standard concentration. Use the canonical ensemble for classical systems and define the per-mole inverse temperature as $\\beta = 1/(R T)$, where $R$ is the universal gas constant and $T$ is the absolute temperature. Assume all energies are classical potential energies and that the restraints are quadratic (harmonic) in their respective coordinates about specified reference values.\n\nStarting only from the following foundational base:\n- The canonical configurational integral weights configurations by $\\exp(-\\beta U)$, where $U$ is the potential energy.\n- The translational volume per molecule at the standard concentration $c^0$ is $V^0 = 1/(c^0 N_A)$, where $N_A$ is Avogadro's number. For $c^0 = 1$ mol/L, $V^0$ must be used in $\\mathrm{nm}^3$.\n- The total measure of the rotation group for a rigid body is $8 \\pi^2$.\n- For a one-dimensional harmonic degree of freedom $x$ with quadratic energy $U(x) = \\tfrac{1}{2} k (x - x_0)^2$, the curvature $k$ determines the Gaussian weight in the configurational integral.\n\nTasks:\n1) Derive, from first principles, the restraint free energy to apply a purely translational, isotropic harmonic potential $U(\\mathbf{r}) = \\tfrac{1}{2} k_t \\lVert \\mathbf{r} \\rVert^2$ that confines the ligand’s center-of-mass near the origin but does not restrain its orientation. Express the result as a function of $k_t$, $T$, $R$, and $V^0$. The free energy must be expressed in $\\mathrm{kJ/mol}$.\n\n2) Derive, from first principles, the restraint free energy to apply a set of six harmonic restraints of the Boresch type on the rigid-body pose defined by one distance $r$, two polar angles $\\theta_A$ and $\\theta_B$, and three dihedrals $\\phi_1$, $\\phi_2$, and $\\phi_3$. The harmonic energy is $U = \\tfrac{1}{2} k_r (r - r_0)^2 + \\tfrac{1}{2} k_{\\theta A} (\\theta_A - \\theta_{A0})^2 + \\tfrac{1}{2} k_{\\theta B} (\\theta_B - \\theta_{B0})^2 + \\sum_{i=1}^3 \\tfrac{1}{2} k_{\\phi i} (\\phi_i - \\phi_{i0})^2$. You must obtain two analytic corrections:\n   - A narrow-variance (Laplace) approximation in which the measure factor for the change of variables, $r^2 \\sin \\theta_A \\sin \\theta_B$, is evaluated at the restrained pose $(r_0,\\theta_{A0},\\theta_{B0})$.\n   - An improved analytic correction that integrates the full Gaussian weights of the harmonic restraints exactly while taking the expectation of the Jacobian factor under the independent Gaussian distributions implied by the harmonic restraining potentials.\n\n3) Implement a program that computes:\n   - The translational-harmonic restraint free energy for three test stiffnesses $k_t$.\n   - For three Boresch-restraint parameter sets, compute the difference (absolute value) between the Laplace-approximation correction and the improved analytic correction derived in Task $2$.\n\nAll energies must be reported in $\\mathrm{kJ/mol}$. Distances must be in $\\mathrm{nm}$, angles in $\\mathrm{rad}$, and stiffnesses in $\\mathrm{kJ \\, mol^{-1} \\, nm^{-2}}$ for translational springs and $\\mathrm{kJ \\, mol^{-1} \\, rad^{-2}}$ for angular springs. Use $T = 300$ $\\mathrm{K}$, $R = 8.314462618 \\times 10^{-3}$ $\\mathrm{kJ \\, mol^{-1} \\, K^{-1}}$, $c^0 = 1$ $\\mathrm{mol/L}$, and $N_A = 6.02214076 \\times 10^{23}$ $\\mathrm{mol^{-1}}$. Convert $V^0$ to $\\mathrm{nm}^3$.\n\nTest suite:\n- Translational-harmonic cases: $k_t \\in \\{100, 1000, 10000\\}$ with units $\\mathrm{kJ \\, mol^{-1} \\, nm^{-2}}$.\n- Boresch cases (all $k$ in $\\mathrm{kJ \\, mol^{-1}}$ and appropriate units, all angles in $\\mathrm{rad}$, distances in $\\mathrm{nm}$):\n  - Case A: $r_0 = 0.5$, $k_r = 5000$, $\\theta_{A0} = 1.6$, $\\theta_{B0} = 1.3$, $k_{\\theta A} = 1000$, $k_{\\theta B} = 800$, $k_{\\phi 1} = 200$, $k_{\\phi 2} = 200$, $k_{\\phi 3} = 200$.\n  - Case B: $r_0 = 0.4$, $k_r = 20000$, $\\theta_{A0} = 1.2$, $\\theta_{B0} = 2.1$, $k_{\\theta A} = 5000$, $k_{\\theta B} = 5000$, $k_{\\phi 1} = 1000$, $k_{\\phi 2} = 1000$, $k_{\\phi 3} = 1000$.\n  - Case C: $r_0 = 0.6$, $k_r = 3000$, $\\theta_{A0} = 0.2$, $\\theta_{B0} = 2.94$, $k_{\\theta A} = 1500$, $k_{\\theta B} = 1500$, $k_{\\phi 1} = 150$, $k_{\\phi 2} = 150$, $k_{\\phi 3} = 150$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with the first three entries being the three translational-harmonic restraint free energies (in the order of $k_t = 100$, $1000$, $10000$), followed by the three absolute differences (in $\\mathrm{kJ/mol}$) between the Laplace and improved analytic Boresch corrections for Cases A, B, C, respectively. For example, the output must look like $[x_1,x_2,x_3,x_4,x_5,x_6]$ where each $x_i$ is a float.",
            "solution": "The free energy change $\\Delta G$ associated with a thermodynamic process is related to the ratio of the final (restrained) and initial (reference) canonical partition functions, $Q_{restr}$ and $Q_{ref}$, by the fundamental relation of statistical mechanics:\n$$ \\Delta G = -R T \\ln \\left( \\frac{Q_{restr}}{Q_{ref}} \\right) = -\\frac{1}{\\beta} \\ln \\left( \\frac{Q_{restr}}{Q_{ref}} \\right) $$\nwhere $\\beta = 1/(RT)$ is the per-mole inverse temperature, $R$ is the universal gas constant, and $T$ is the absolute temperature. We are calculating the work to apply restraints, starting from a reference state of a non-interacting ligand.\n\nThe reference state is a single ligand molecule free to translate within a standard volume $V^0 = 1/(c^0 N_A)$ and free to rotate over all possible orientations. The volume of the rotation group for a rigid body is $8\\pi^2$. The reference configurational integral is the product of the translational and rotational volumes:\n$$ Q_{ref} = \\int_{V^0} d\\mathbf{r} \\int d\\Omega = V^0 \\cdot 8\\pi^2 $$\nwhere $\\mathbf{r}$ represents the translational coordinates and $\\Omega$ the orientational coordinates.\n\nThe restrained state has a potential energy function $U_{restr}$ applied. The configurational integral for this state is:\n$$ Q_{restr} = \\int e^{-\\beta U_{restr}} d\\mathbf{r} d\\Omega $$\nThe integral is taken over all accessible positions and orientations.\n\nThe standard volume $V^0$ corresponding to a standard concentration $c^0 = 1$ mol/L must be expressed in $\\mathrm{nm}^3$. Given $N_A = 6.02214076 \\times 10^{23}$ mol$^{-1}$ and $1$ L $= 10^{24}$ nm$^3$:\n$$ V^0 = \\frac{1 \\text{ L}}{N_A} = \\frac{10^{24} \\text{ nm}^3}{6.02214076 \\times 10^{23}} \\approx 1.660539 \\text{ nm}^3 $$\n\n**Task 1: Isotropic Translational Harmonic Restraint**\n\nFor this task, the restraint potential acts only on the ligand's center-of-mass position $\\mathbf{r}=(x,y,z)$ and is given by $U_{restr}(\\mathbf{r}) = \\frac{1}{2} k_t \\lVert \\mathbf{r} \\rVert^2 = \\frac{1}{2} k_t (x^2 + y^2 + z^2)$. The potential is independent of orientation.\nThe restrained configurational integral is:\n$$ Q_{restr} = \\int e^{-\\beta U_{restr}(\\mathbf{r})} d\\mathbf{r} \\int d\\Omega $$\nThe orientational integral yields $8\\pi^2$. The translational integral separates into three identical one-dimensional Gaussian integrals:\n$$ \\int e^{-\\frac{1}{2}\\beta k_t (x^2+y^2+z^2)} dx dy dz = \\left( \\int_{-\\infty}^{\\infty} e^{-\\frac{1}{2}\\beta k_t x^2} dx \\right)^3 $$\nUsing the standard result for a Gaussian integral $\\int_{-\\infty}^{\\infty} e^{-ax^2} dx = \\sqrt{\\pi/a}$, with $a = \\frac{1}{2} \\beta k_t$, we get:\n$$ \\int_{-\\infty}^{\\infty} e^{-\\frac{1}{2}\\beta k_t x^2} dx = \\sqrt{\\frac{\\pi}{\\frac{1}{2}\\beta k_t}} = \\sqrt{\\frac{2\\pi}{\\beta k_t}} $$\nThe three-dimensional translational integral is therefore $(\\frac{2\\pi}{\\beta k_t})^{3/2}$.\nSo, the restrained configurational integral is:\n$$ Q_{restr} = 8\\pi^2 \\left( \\frac{2\\pi}{\\beta k_t} \\right)^{3/2} $$\nThe restraint free energy $\\Delta G_{trans}$ is then:\n$$ \\Delta G_{trans} = -\\frac{1}{\\beta} \\ln \\left( \\frac{Q_{restr}}{Q_{ref}} \\right) = -\\frac{1}{\\beta} \\ln \\left( \\frac{8\\pi^2 (2\\pi / (\\beta k_t))^{3/2}}{8\\pi^2 V^0} \\right) = -\\frac{1}{\\beta} \\ln \\left( \\frac{1}{V^0} \\left( \\frac{2\\pi}{\\beta k_t} \\right)^{3/2} \\right) $$\n$$ \\Delta G_{trans} = \\frac{1}{\\beta} \\ln \\left( V^0 \\left( \\frac{\\beta k_t}{2\\pi} \\right)^{3/2} \\right) = RT \\ln \\left( V^0 \\left( \\frac{k_t}{2\\pi RT} \\right)^{3/2} \\right) $$\nThis is the final expression for the translational restraint free energy.\n\n**Task 2: Boresch-type Harmonic Restraints**\n\nHere, six harmonic restraints are applied on a set of internal coordinates: distance $r$, angles $\\theta_A, \\theta_B$, and dihedrals $\\phi_1, \\phi_2, \\phi_3$. The potential is $U_{restr} = \\sum_{i=1}^6 \\frac{1}{2} k_i (\\xi_i - \\xi_{i0})^2$, where $\\xi_i$ are the six coordinates.\nThe differential volume element for these coordinates includes a Jacobian factor $J = r^2 \\sin\\theta_A \\sin\\theta_B$. The configurational integral is:\n$$ Q_{restr} = \\int (r^2 \\sin\\theta_A \\sin\\theta_B) e^{-\\beta U_{restr}} dr d\\theta_A d\\theta_B d\\phi_1 d\\phi_2 d\\phi_3 $$\nSince the potential $U_{restr}$ is a sum of independent terms, we can write the integral as an expectation value. Let $p(\\xi_1, ..., \\xi_6) = \\prod_{i=1}^6 p(\\xi_i)$ be the probability distribution defined by the harmonic potential, where each $p(\\xi_i)$ is a Gaussian distribution with mean $\\xi_{i0}$ and variance $\\sigma_i^2 = RT/k_i$.\n$$ Q_{restr} = \\left( \\prod_{i=1}^6 \\int e^{-\\frac{1}{2}\\beta k_i (\\xi_i - \\xi_{i0})^2} d\\xi_i \\right) \\langle r^2 \\sin\\theta_A \\sin\\theta_B \\rangle_{U_{restr}} $$\nThe product of integrals is $Q_{harm} = \\prod_{i=1}^6 \\sqrt{2\\pi/(\\beta k_i)} = (\\frac{2\\pi RT}{k_{prod}})^{1/2}$ where $k_{prod}=\\prod k_i^{1/3}$ is not useful here. We get $Q_{harm} = \\sqrt{(2\\pi/\\beta)^6 / (k_r k_{\\theta A} k_{\\theta B} k_{\\phi 1} k_{\\phi 2} k_{\\phi 3})}$. Let's keep the product form.\nThe restraint free energy is:\n$$ \\Delta G_{restr} = -\\frac{1}{\\beta} \\ln \\left( \\frac{Q_{harm} \\langle r^2 \\sin\\theta_A \\sin\\theta_B \\rangle}{8\\pi^2 V^0} \\right) = \\Delta G_{ideal} + \\Delta G_{corr} $$\nwhere $\\Delta G_{ideal} = -RT \\ln \\left( \\frac{Q_{harm}}{8\\pi^2 V^0} \\right)$ and the correction term is $\\Delta G_{corr} = -RT \\ln \\langle r^2 \\sin\\theta_A \\sin\\theta_B \\rangle$. We are asked to derive two approximations for this correction term.\n\n**Laplace Approximation:**\nThis method assumes the restraints are stiff, so the Jacobian can be evaluated at the equilibrium position $(r_0, \\theta_{A0}, \\theta_{B0})$ and treated as a constant:\n$$ \\langle r^2 \\sin\\theta_A \\sin\\theta_B \\rangle \\approx r_0^2 \\sin\\theta_{A0} \\sin\\theta_{B0} $$\nThe correction free energy is then:\n$$ \\Delta G_{corr}^{Laplace} = -RT \\ln(r_0^2 \\sin\\theta_{A0} \\sin\\theta_{B0}) $$\n\n**Improved Analytic Correction:**\nThis method computes the expectation value by averaging over the Gaussian distributions of the independent coordinates:\n$$ \\langle r^2 \\sin\\theta_A \\sin\\theta_B \\rangle = \\langle r^2 \\rangle_r \\langle \\sin\\theta_A \\rangle_{\\theta_A} \\langle \\sin\\theta_B \\rangle_{\\theta_B} $$\nFor a variable $\\xi \\sim \\mathcal{N}(\\xi_0, \\sigma^2)$, with $\\sigma^2=RT/k$:\n1. The expectation of $r^2$ is $\\langle r^2 \\rangle = \\sigma_r^2 + r_0^2 = (RT/k_r) + r_0^2$. This uses the property $E[X^2] = Var(X) + (E[X])^2$ for a random variable $X$.\n2. The expectation of $\\sin\\theta$ is $\\langle \\sin\\theta \\rangle = \\sin(\\theta_0) e^{-\\sigma_\\theta^2/2} = \\sin(\\theta_0) \\exp(-RT/(2k_\\theta))$. This result stems from the characteristic function of the normal distribution.\nCombining these results:\n$$ \\langle r^2 \\sin\\theta_A \\sin\\theta_B \\rangle = \\left(r_0^2 + \\frac{RT}{k_r}\\right) \\sin(\\theta_{A0})\\sin(\\theta_{B0}) \\exp\\left(-\\frac{RT}{2}\\left(\\frac{1}{k_{\\theta A}} + \\frac{1}{k_{\\theta B}}\\right)\\right) $$\nThe improved correction free energy is:\n$$ \\Delta G_{corr}^{improved} = -RT \\ln \\left[ \\left(r_0^2 + \\frac{RT}{k_r}\\right) \\sin(\\theta_{A0})\\sin(\\theta_{B0}) \\exp\\left(-\\frac{RT}{2}\\left(\\frac{1}{k_{\\theta A}} + \\frac{1}{k_{\\theta B}}\\right)\\right) \\right] $$\n\n**Difference between Corrections:**\nThe problem requires computing the absolute difference $|\\Delta G_{corr}^{Laplace} - \\Delta G_{corr}^{improved}|$.\n$$ \\Delta G_{corr}^{Laplace} - \\Delta G_{corr}^{improved} = -RT \\ln(r_0^2 \\sin\\theta_{A0} \\sin\\theta_{B0}) - (-RT \\ln \\langle r^2 \\sin\\theta_A \\sin\\theta_B \\rangle) $$\n$$ = -RT \\ln \\left( \\frac{r_0^2 \\sin\\theta_{A0} \\sin\\theta_{B0}}{\\langle r^2 \\sin\\theta_A \\sin\\theta_B \\rangle} \\right) $$\nSubstituting the expression for the expectation value and simplifying:\n$$ = -RT \\ln \\left( \\frac{r_0^2}{r_0^2 + \\frac{RT}{k_r}} \\frac{1}{\\exp\\left(-\\frac{RT}{2}\\left(\\frac{1}{k_{\\theta A}} + \\frac{1}{k_{\\theta B}}\\right)\\right)} \\right) $$\n$$ = -RT \\left[ \\ln\\left(\\frac{r_0^2}{r_0^2 + \\frac{RT}{k_r}}\\right) + \\frac{RT}{2}\\left(\\frac{1}{k_{\\theta A}} + \\frac{1}{k_{\\theta B}}\\right) \\right] $$\n$$ = RT \\ln\\left(\\frac{r_0^2 + \\frac{RT}{k_r}}{r_0^2}\\right) - \\frac{(RT)^2}{2}\\left(\\frac{1}{k_{\\theta A}} + \\frac{1}{k_{\\theta B}}\\right) $$\n$$ = RT \\ln\\left(1 + \\frac{RT}{k_r r_0^2}\\right) - \\frac{(RT)^2}{2}\\left(\\frac{1}{k_{\\theta A}} + \\frac{1}{k_{\\theta B}}\\right) $$\nThe program will compute the absolute value of this quantity for the given test cases.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates restraint free energies based on derivations from classical statistical mechanics.\n\n    Task 1: Computes the free energy to apply an isotropic translational harmonic\n            restraint on a ligand, relative to a standard concentration state.\n\n    Task 2 & 3: Computes the absolute difference between two analytic approximations\n                (Laplace and improved) for the Boresch-type restraint correction free energy.\n    \"\"\"\n    # Define physical and chemical constants as specified in the problem.\n    R = 8.314462618e-3  # Universal gas constant in kJ mol^-1 K^-1\n    T = 300.0           # Absolute temperature in K\n    NA = 6.02214076e23  # Avogadro's number in mol^-1\n    # c0 = 1.0          # Standard concentration in mol/L, implicitly used in V0 calculation\n\n    # Calculate the product RT for frequent use.\n    RT = R * T\n\n    # Calculate the standard volume V^0 per molecule in nm^3 for c^0 = 1 mol/L.\n    # 1 L = 1 dm^3 = 10^-3 m^3.\n    # 1 m = 10^9 nm, so 1 m^3 = 10^27 nm^3.\n    # Therefore, 1 L = 10^24 nm^3.\n    # V^0 = 1 / (c^0 * N_A) in liters/molecule. For c^0=1 mol/L, V^0 = (1 L) / N_A.\n    liters_to_nm3_conversion_factor = 1e24\n    V0 = liters_to_nm3_conversion_factor / NA  # in nm^3\n\n    results = []\n\n    # === Part 1: Translational-harmonic restraint free energy ===\n    \n    # Formula derived: ΔG_trans = RT * ln( V^0 * (k_t / (2*pi*RT))^(3/2) )\n    kt_cases = [100.0, 1000.0, 10000.0]  # units: kJ mol^-1 nm^-2\n    \n    for kt in kt_cases:\n        term_inside_power = kt / (2.0 * np.pi * RT)\n        term_in_log = V0 * np.power(term_inside_power, 1.5)\n        delta_g_trans = RT * np.log(term_in_log)\n        results.append(delta_g_trans)\n\n    # === Part 2: Difference between Boresch correction approximations ===\n    \n    # The Boresch-type restraint parameters for the three test cases.\n    # Each tuple contains: (r0, kr, k_thetaA, k_thetaB)\n    # Units: r0 (nm), kr (kJ mol^-1 nm^-2), k_thetaA/B (kJ mol^-1 rad^-2)\n    # Note: Boresch case parameters given in problem statement do not include r0, thetaA0, thetaB0 for the\n    # difference calculation, but they are needed for the full correction term. The difference derivation\n    # shows that thetaA0 and thetaB0 drop out IF they are not 0 or pi. r0 remains.\n    boresch_cases = [\n        # Case A: r0 = 0.5, kr = 5000, k_thetaA = 1000, k_thetaB = 800\n        (0.5, 5000.0, 1000.0, 800.0),\n        # Case B: r0 = 0.4, kr = 20000, k_thetaA = 5000, k_thetaB = 5000\n        (0.4, 20000.0, 5000.0, 5000.0),\n        # Case C: r0 = 0.6, kr = 3000, k_thetaA = 1500, k_thetaB = 1500\n        (0.6, 3000.0, 1500.0, 1500.0),\n    ]\n\n    # Formula for the difference D = ΔG_corr_Laplace - ΔG_corr_improved\n    # D = RT * ln(1 + RT/(k_r * r_0^2)) - (RT^2)/2 * (1/k_thetaA + 1/k_thetaB)\n    # The final result required is the absolute value |D|.\n    \n    for r0, kr, k_thetaA, k_thetaB in boresch_cases:\n        # First term of the difference expression\n        log_argument = 1.0 + RT / (kr * r0**2)\n        term1 = RT * np.log(log_argument)\n        \n        # Second term of the difference expression\n        inverse_k_sum = (1.0 / k_thetaA) + (1.0 / k_thetaB)\n        term2 = (RT**2 / 2.0) * inverse_k_sum\n        \n        # Calculate the difference and take its absolute value\n        difference = abs(term1 - term2)\n        results.append(difference)\n\n    # Print the final results in the specified single-line format.\n    # The list contains three free energies and three absolute differences.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A calculated free energy value provides a powerful measure of a process's spontaneity, but it doesn't tell the whole story. By determining the free energy at several different temperatures, we can dissect it into its underlying enthalpic ($\\Delta H$) and entropic ($\\Delta S$) contributions, revealing the physical driving forces of the process. In this final practice , you will use data from a hypothetical temperature series to perform this thermodynamic decomposition, employing weighted least-squares fitting and rigorous uncertainty propagation to gain deeper insight into the system's behavior.",
            "id": "3447345",
            "problem": "You are given temperature-dependent solvation or binding free energy measurements, denoted by $\\Delta G(T)$, with measurement uncertainties, across the range of $290 \\,\\mathrm{K}$ to $320 \\,\\mathrm{K}$. Assume a thermodynamic model appropriate for molecular dynamics analysis in which the change in heat capacity $\\Delta C_p$ is constant over the considered temperature range. Starting from the fundamental thermodynamic definitions, and expressing the temperature dependence relative to a reference temperature $T_0 = 300 \\,\\mathrm{K}$, you must fit the parameters implicit in the model from $\\Delta G(T)$ data using Weighted Least Squares (WLS), and then compute the enthalpy change $\\Delta H$ and entropy change $\\Delta S$ at $T = 298 \\,\\mathrm{K}$, together with their propagated standard uncertainties derived from the parameter covariance matrix.\n\nYour derivation must start from the fundamental base comprising:\n- The definition of Gibbs free energy: $\\Delta G(T) = \\Delta H(T) - T \\, \\Delta S(T)$.\n- The definition of heat capacity change: $\\Delta C_p = \\frac{d \\Delta H}{dT}$ and consistency with entropy via $T \\frac{d \\Delta S}{dT} = \\Delta C_p$.\n\nYou must implement a WLS fit to the model implied by these relations. The WLS is defined as minimizing $\\sum_i w_i \\left[\\Delta G(T_i) - \\text{model}(T_i)\\right]^2$ where $w_i = 1/\\sigma_i^2$ and $\\sigma_i$ are the reported standard deviations of the $\\Delta G(T_i)$ measurements. From the fit, estimate $\\Delta H(298 \\,\\mathrm{K})$ and $\\Delta S(298 \\,\\mathrm{K})$ and their standard uncertainties by linear propagation through the fitted parameter covariance matrix.\n\nAll energies must be reported in $\\mathrm{kJ/mol}$, all entropies in $\\mathrm{kJ/(mol\\,K)}$, and all temperatures in $\\mathrm{K}$. Express the final numerical outputs rounded to six decimal places.\n\nTest suite:\n- Case A (general case with nonzero $\\Delta C_p$):\n  - $T_0 = 300 \\,\\mathrm{K}$\n  - Temperature points $T = [290, 295, 300, 305, 310, 315, 320] \\,\\mathrm{K}$\n  - Measured $\\Delta G(T)$ in $\\mathrm{kJ/mol}$: $[-7.620200, -7.305000, -7.000000, -6.705000, -6.419700, -6.144268, -5.878458]$\n  - Uncertainties $\\sigma$ in $\\mathrm{kJ/mol}$: $[0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10]$\n- Case B (boundary case with $\\Delta C_p \\approx 0$):\n  - $T_0 = 300 \\,\\mathrm{K}$\n  - Temperature points $T = [290, 295, 300, 305, 310, 315, 320] \\,\\mathrm{K}$\n  - Measured $\\Delta G(T)$ in $\\mathrm{kJ/mol}$: $[-9.200000, -9.100000, -9.000000, -8.900000, -8.800000, -8.700000, -8.600000]$\n  - Uncertainties $\\sigma$ in $\\mathrm{kJ/mol}$: $[0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]$\n- Case C (edge case with fewer points and larger uncertainties):\n  - $T_0 = 300 \\,\\mathrm{K}$\n  - Temperature points $T = [290, 295, 300, 305] \\,\\mathrm{K}$\n  - Measured $\\Delta G(T)$ in $\\mathrm{kJ/mol}$: $[-7.933725, -7.958440, -8.000000, -8.058293]$\n  - Uncertainties $\\sigma$ in $\\mathrm{kJ/mol}$: $[0.50, 0.40, 0.50, 0.60]$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case result is a list of four floats in the order $[\\Delta H(298\\,\\mathrm{K}), \\sigma_{\\Delta H(298\\,\\mathrm{K})}, \\Delta S(298\\,\\mathrm{K}), \\sigma_{\\Delta S(298\\,\\mathrm{K})}]$, all rounded to six decimal places. For example, the output format must look like: \"[[hA,sig_hA,sA,sig_sA],[hB,sig_hB,sB,sig_sB],[hC,sig_hC,sC,sig_sC]]\" with the required numerical values substituted.",
            "solution": "The objective is to determine the enthalpy change $\\Delta H$ and entropy change $\\Delta S$ at a specific target temperature, $T_{target} = 298\\,\\mathrm{K}$, from a set of temperature-dependent Gibbs free energy measurements, $\\Delta G(T_i)$. The analysis assumes a constant change in heat capacity, $\\Delta C_p$, over the experimental temperature range. The problem will be solved by first deriving the functional form of $\\Delta G(T)$, then fitting its parameters using Weighted Least Squares (WLS), and finally propagating the uncertainties from the fit to the desired quantities, $\\Delta H(T_{target})$ and $\\Delta S(T_{target})$.\n\n**1. Derivation of the Thermodynamic Model for $\\Delta G(T)$**\n\nThe derivation begins with the fundamental thermodynamic relations provided:\nThe change in enthalpy, $\\Delta H$, and entropy, $\\Delta S$, with temperature are governed by the change in heat capacity, $\\Delta C_p$:\n$$\n\\frac{d \\Delta H}{dT} = \\Delta C_p\n$$\n$$\n\\frac{d \\Delta S}{dT} = \\frac{\\Delta C_p}{T}\n$$\nAssuming $\\Delta C_p$ is constant over the temperature range of interest, we can integrate these equations from a reference temperature $T_0$ to an arbitrary temperature $T$:\n$$\n\\int_{\\Delta H(T_0)}^{\\Delta H(T)} d(\\Delta H') = \\int_{T_0}^{T} \\Delta C_p \\, dT' \\implies \\Delta H(T) = \\Delta H(T_0) + \\Delta C_p (T - T_0)\n$$\n$$\n\\int_{\\Delta S(T_0)}^{\\Delta S(T)} d(\\Delta S') = \\int_{T_0}^{T} \\frac{\\Delta C_p}{T'} \\, dT' \\implies \\Delta S(T) = \\Delta S(T_0) + \\Delta C_p \\ln\\left(\\frac{T}{T_0}\\right)\n$$\nFor convenience, let's denote $\\Delta H_0 \\equiv \\Delta H(T_0)$ and $\\Delta S_0 \\equiv \\Delta S(T_0)$. The Gibbs free energy is defined as $\\Delta G(T) = \\Delta H(T) - T \\Delta S(T)$. Substituting the expressions for $\\Delta H(T)$ and $\\Delta S(T)$ yields:\n$$\n\\Delta G(T) = [\\Delta H_0 + \\Delta C_p (T - T_0)] - T [\\Delta S_0 + \\Delta C_p \\ln(T/T_0)]\n$$\nTo formulate a linear model suitable for fitting, we express $\\Delta H_0$ in terms of the free energy at the reference temperature, $\\Delta G_0 \\equiv \\Delta G(T_0) = \\Delta H_0 - T_0 \\Delta S_0$. This gives $\\Delta H_0 = \\Delta G_0 + T_0 \\Delta S_0$. Substituting this into the equation for $\\Delta G(T)$:\n$$\n\\Delta G(T) = (\\Delta G_0 + T_0 \\Delta S_0) - T \\Delta S_0 + \\Delta C_p (T - T_0) - T \\Delta C_p \\ln(T/T_0)\n$$\nRearranging the terms to group the parameters to be fitted ($\\Delta G_0$, $\\Delta S_0$, $\\Delta C_p$):\n$$\n\\Delta G(T) = \\Delta G_0 - (T - T_0)\\Delta S_0 + \\Delta C_p \\left[ (T - T_0) - T \\ln\\left(\\frac{T}{T_0}\\right) \\right]\n$$\nThis is the final model equation, which is linear in the three parameters $\\Delta G_0$, $\\Delta S_0$, and $\\Delta C_p$.\n\n**2. Weighted Least Squares (WLS) Formulation**\n\nThe model can be expressed in matrix form as $\\mathbf{y} = \\mathbf{Xp}$, where $\\mathbf{y}$ is the vector of observed $\\Delta G(T_i)$ values, $\\mathbf{p}$ is the vector of parameters, and $\\mathbf{X}$ is the design matrix.\nFor $N$ data points, these are:\n$$\n\\mathbf{y} = \\begin{bmatrix} \\Delta G(T_1) \\\\ \\vdots \\\\ \\Delta G(T_N) \\end{bmatrix}, \\quad\n\\mathbf{p} = \\begin{bmatrix} \\Delta G_0 \\\\ \\Delta S_0 \\\\ \\Delta C_p \\end{bmatrix}\n$$\nThe $i$-th row of the design matrix $\\mathbf{X}$ corresponds to the coefficients of the parameters for the $i$-th measurement at temperature $T_i$:\n$$\n\\mathbf{X}_i = \\begin{bmatrix} 1 & -(T_i - T_0) & (T_i - T_0) - T_i \\ln(T_i/T_0) \\end{bmatrix}\n$$\nThe WLS method minimizes the weighted sum of squared residuals, $\\chi^2 = (\\mathbf{y} - \\mathbf{Xp})^T \\mathbf{W} (\\mathbf{y} - \\mathbf{Xp})$, where $\\mathbf{W}$ is the diagonal weight matrix with entries $W_{ii} = 1/\\sigma_i^2$, and $\\sigma_i$ is the measurement uncertainty for $\\Delta G(T_i)$.\nThe solution for the parameter vector $\\mathbf{p}$ is given by the normal equations:\n$$\n\\mathbf{p} = (\\mathbf{X}^T \\mathbf{W} \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{W} \\mathbf{y}\n$$\nThe covariance matrix of the fitted parameters, $\\mathbf{C_p}$, is the inverse of the Hessian matrix of $\\chi^2$:\n$$\n\\mathbf{C_p} = (\\mathbf{X}^T \\mathbf{W} \\mathbf{X})^{-1}\n$$\n\n**3. Calculation of Target Quantities and Uncertainty Propagation**\n\nThe goal is to compute $\\Delta H(T_{target})$ and $\\Delta S(T_{target})$ at $T_{target} = 298\\,\\mathrm{K}$ and their standard uncertainties. We first express these quantities as linear functions of the fitted parameters $\\mathbf{p} = [\\Delta G_0, \\Delta S_0, \\Delta C_p]^T$.\n\nFor enthalpy at $T_{target}$:\n$$\n\\Delta H(T_{target}) = \\Delta H_0 + \\Delta C_p (T_{target} - T_0) = (\\Delta G_0 + T_0 \\Delta S_0) + \\Delta C_p (T_{target} - T_0)\n$$\nThis is a linear combination of the fitted parameters:\n$$\n\\Delta H(T_{target}) = \\begin{bmatrix} 1 & T_0 & T_{target} - T_0 \\end{bmatrix} \\begin{bmatrix} \\Delta G_0 \\\\ \\Delta S_0 \\\\ \\Delta C_p \\end{bmatrix} = \\mathbf{j}_H^T \\mathbf{p}\n$$\nwhere $\\mathbf{j}_H = [1, T_0, T_{target} - T_0]^T$ is the Jacobian vector of $\\Delta H(T_{target})$ with respect to the parameters.\n\nFor entropy at $T_{target}$:\n$$\n\\Delta S(T_{target}) = \\Delta S_0 + \\Delta C_p \\ln(T_{target}/T_0)\n$$\nThis is also a linear combination of the fitted parameters:\n$$\n\\Delta S(T_{target}) = \\begin{bmatrix} 0 & 1 & \\ln(T_{target}/T_0) \\end{bmatrix} \\begin{bmatrix} \\Delta G_0 \\\\ \\Delta S_0 \\\\ \\Delta C_p \\end{bmatrix} = \\mathbf{j}_S^T \\mathbf{p}\n$$\nwhere $\\mathbf{j}_S = [0, 1, \\ln(T_{target}/T_0)]^T$ is the corresponding Jacobian vector.\n\nThe variance for a quantity $F = \\mathbf{j}^T \\mathbf{p}$ is given by the error propagation formula $\\sigma_F^2 = \\mathbf{j}^T \\mathbf{C_p} \\mathbf{j}$. Applying this to our target quantities:\nThe variance of $\\Delta H(T_{target})$ is:\n$$\n\\sigma_{\\Delta H}^2 = \\mathbf{j}_H^T \\mathbf{C_p} \\mathbf{j}_H\n$$\nThe variance of $\\Delta S(T_{target})$ is:\n$$\n\\sigma_{\\Delta S}^2 = \\mathbf{j}_S^T \\mathbf{C_p} \\mathbf{j}_S\n$$\nThe standard uncertainties, $\\sigma_{\\Delta H}$ and $\\sigma_{\\Delta S}$, are the square roots of these variances.\n\nThe computational procedure is:\n1.  For each test case, construct the vector of measurements $\\mathbf{y}$ and the weight matrix $\\mathbf{W}$ from the given $\\Delta G_i$ and $\\sigma_i$.\n2.  Construct the design matrix $\\mathbf{X}$ using the temperature points $T_i$ and the reference temperature $T_0 = 300\\,\\mathrm{K}$.\n3.  Solve for the parameter vector $\\mathbf{p}$ and the covariance matrix $\\mathbf{C_p}$.\n4.  Calculate the values of $\\Delta H(298\\,\\mathrm{K})$ and $\\Delta S(298\\,\\mathrm{K})$ using the fitted parameters.\n5.  Construct the Jacobian vectors $\\mathbf{j}_H$ and $\\mathbf{j}_S$ for $T_{target} = 298\\,\\mathrm{K}$.\n6.  Calculate the variances $\\sigma_{\\Delta H}^2$ and $\\sigma_{\\Delta S}^2$ and take their square roots to find the standard uncertainties.\nAll energies are in units of $\\mathrm{kJ/mol}$ and entropies in $\\mathrm{kJ/(mol \\cdot K)}$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to process test cases and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"T\": [290, 295, 300, 305, 310, 315, 320],\n            \"dG\": [-7.620200, -7.305000, -7.000000, -6.705000, -6.419700, -6.144268, -5.878458],\n            \"sigma\": [0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10]\n        },\n        {\n            \"T\": [290, 295, 300, 305, 310, 315, 320],\n            \"dG\": [-9.200000, -9.100000, -9.000000, -8.900000, -8.800000, -8.700000, -8.600000],\n            \"sigma\": [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]\n        },\n        {\n            \"T\": [290, 295, 300, 305],\n            \"dG\": [-7.933725, -7.958440, -8.000000, -8.058293],\n            \"sigma\": [0.50, 0.40, 0.50, 0.60]\n        }\n    ]\n\n    T0 = 300.0  # Reference temperature in K\n    T_target = 298.0  # Target temperature in K\n\n    results = []\n    for case in test_cases:\n        T_arr = np.array(case[\"T\"])\n        dG_arr = np.array(case[\"dG\"])\n        sigma_arr = np.array(case[\"sigma\"])\n\n        result = fit_thermo_model(T_arr, dG_arr, sigma_arr, T0, T_target)\n        results.append(result)\n\n    # Format the output string as per problem specification.\n    case_results_str = []\n    for res in results:\n        case_results_str.append(\n            f\"[{res[0]:.6f},{res[1]:.6f},{res[2]:.6f},{res[3]:.6f}]\"\n        )\n    \n    print(f\"[{','.join(case_results_str)}]\")\n\ndef fit_thermo_model(T, dG, sigma, T0, T_target):\n    \"\"\"\n    Performs a Weighted Least Squares fit to the thermodynamic model and propagates uncertainties.\n\n    Args:\n        T (np.ndarray): Array of temperatures in K.\n        dG (np.ndarray): Array of measured Gibbs free energies in kJ/mol.\n        sigma (np.ndarray): Array of uncertainties for dG in kJ/mol.\n        T0 (float): Reference temperature in K.\n        T_target (float): Target temperature for calculation in K.\n\n    Returns:\n        tuple: A tuple containing (dH_target, sigma_dH, dS_target, sigma_dS) at T_target.\n    \"\"\"\n    # 1. Construct the design matrix X\n    # The model is dG(T) = dG0 - (T-T0)*dS0 + dCp*[(T-T0) - T*ln(T/T0)]\n    # Parameters p = [dG0, dS0, dCp]\n    num_points = len(T)\n    X = np.zeros((num_points, 3))\n    \n    # Using np.errstate to handle the case T=T0 for the log term, where the result is 0.\n    with np.errstate(divide='ignore', invalid='ignore'):\n        col0 = np.ones(num_points)\n        col1 = -(T - T0)\n        # The third column's expression is zero when T = T0\n        col2 = (T - T0) - T * np.log(T / T0)\n        col2[T == T0] = 0.0\n\n    X[:, 0] = col0\n    X[:, 1] = col1\n    X[:, 2] = col2\n\n    # 2. Construct the weight matrix W (as a vector for efficiency)\n    w = 1.0 / (sigma**2)\n\n    # 3. Solve the normal equations for parameters and covariance matrix\n    # p = (X^T W X)^-1 X^T W y\n    # Cov(p) = (X^T W X)^-1\n    XT_W = X.T * w  # Broadcasting w to rows of X.T\n    XT_W_X = XT_W @ X\n    \n    # Parameter covariance matrix\n    Cp = np.linalg.inv(XT_W_X)\n    \n    XT_W_y = XT_W @ dG\n    \n    # Best-fit parameters\n    p = Cp @ XT_W_y\n    dG0, dS0, dCp = p\n\n    # 4. Calculate target quantities (dH and dS at T_target)\n    # dH(T) = dG0 + T0*dS0 + (T-T0)*dCp\n    dH_target = dG0 + T0 * dS0 + (T_target - T0) * dCp\n    \n    # dS(T) = dS0 + dCp*ln(T/T0)\n    # Handle the case where T_target might be T0, for which ln(1)=0\n    log_term_S = np.log(T_target / T0) if T_target != T0 else 0.0\n    dS_target = dS0 + dCp * log_term_S\n\n    # 5. Propagate uncertainties\n    # Variance(F) = j^T * Cov(p) * j\n    \n    # Jacobian for dH(T_target) w.r.t p=[dG0, dS0, dCp]\n    jH = np.array([1.0, T0, T_target - T0])\n    \n    # Jacobian for dS(T_target) w.r.t p=[dG0, dS0, dCp]\n    jS = np.array([0.0, 1.0, log_term_S])\n\n    # Calculate variances\n    var_dH = jH.T @ Cp @ jH\n    var_dS = jS.T @ Cp @ jS\n\n    # Standard uncertainties are the square roots of the variances\n    sigma_dH = np.sqrt(var_dH)\n    sigma_dS = np.sqrt(var_dS)\n    \n    return dH_target, sigma_dH, dS_target, sigma_dS\n\n# Execute the main function when the script is run\nsolve()\n```"
        }
    ]
}