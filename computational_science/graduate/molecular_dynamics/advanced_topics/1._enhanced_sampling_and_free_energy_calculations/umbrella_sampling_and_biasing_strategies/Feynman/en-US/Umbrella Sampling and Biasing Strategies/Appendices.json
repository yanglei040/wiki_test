{
    "hands_on_practices": [
        {
            "introduction": "The power of umbrella sampling lies in applying an external bias potential to steer a simulation along a chosen reaction coordinate. This exercise bridges the gap between the abstract concept of a biasing potential, $U_b(s)$, and its physical implementation within a molecular dynamics engine. By calculating the forces exerted on individual atoms from the gradient of the potential, you will gain a concrete understanding of how these computational 'springs' guide the system's exploration of its energy landscape. ",
            "id": "3458759",
            "problem": "An umbrella sampling simulation in molecular dynamics (MD) biases a single collective variable (CV) defined as the distance between two atoms labeled $1$ and $2$, $s = |\\mathbf{r}_{1} - \\mathbf{r}_{2}|$. The bias potential is harmonic with stiffness $k = 50\\,\\mathrm{kcal\\,mol^{-1}\\,Å^{-2}}$ and center $s_{0} = 5\\,\\mathrm{Å}$. At temperature $T = 300\\,\\mathrm{K}$, the instantaneous value of the CV is $s = 6\\,\\mathrm{Å}$. Using fundamental definitions relating forces to potential gradients and the chain rule, first determine the magnitude of the bias force on the CV at this $s$. Then, translate this CV force to the atomic forces on atoms $1$ and $2$ using the gradient of $s$ with respect to the atomic positions. Denote by $\\boldsymbol{e}_{12}$ the unit vector pointing from atom $2$ to atom $1$, that is, $\\boldsymbol{e}_{12} = (\\mathbf{r}_{1} - \\mathbf{r}_{2})/|\\mathbf{r}_{1} - \\mathbf{r}_{2}|$. Express the final answer as a single row containing three entries: the scalar magnitude of the bias force on the CV, followed by the vector atomic force on atom $1$, and the vector atomic force on atom $2$, respectively. Report the forces in $\\mathrm{kcal\\,mol^{-1}\\,Å^{-1}}$. Round the scalar magnitude and the numerical coefficients multiplying $\\boldsymbol{e}_{12}$ to four significant figures. State your final answer in the specified order as a single analytic expression.",
            "solution": "The problem is valid as it is scientifically grounded, well-posed, and objective. It describes a standard scenario in computational chemistry and molecular dynamics, using fundamental principles of classical mechanics. All necessary data are provided, and there are no contradictions.\n\nThe collective variable (CV) is defined as the distance between atoms $1$ and $2$, $s = |\\mathbf{r}_{1} - \\mathbf{r}_{2}|$. The system is subjected to a harmonic bias potential centered at $s_{0} = 5\\,\\mathrm{Å}$ with a force constant $k = 50\\,\\mathrm{kcal\\,mol^{-1}\\,Å^{-2}}$. The form of this potential is:\n$$V_{bias}(s) = \\frac{1}{2} k (s - s_0)^2$$\nThe instantaneous value of the CV is given as $s = 6\\,\\mathrm{Å}$. The temperature $T = 300\\,\\mathrm{K}$ is contextual information typical for a molecular dynamics simulation but is not required for calculating the instantaneous mechanical force from a conservative potential.\n\nFirst, we determine the force acting along the collective variable, $F_s$. This force is the negative derivative of the bias potential with respect to the CV, $s$:\n$$F_s = -\\frac{dV_{bias}(s)}{ds}$$\nSubstituting the expression for the harmonic potential, we get:\n$$F_s = -\\frac{d}{ds} \\left[ \\frac{1}{2} k (s - s_0)^2 \\right] = -k (s - s_0)$$\nNow, we substitute the given numerical values: $k = 50\\,\\mathrm{kcal\\,mol^{-1}\\,Å^{-2}}$, $s_0 = 5\\,\\mathrm{Å}$, and $s = 6\\,\\mathrm{Å}$.\n$$F_s = -(50\\,\\mathrm{kcal\\,mol^{-1}\\,Å^{-2}}) (6\\,\\mathrm{Å} - 5\\,\\mathrm{Å}) = -(50\\,\\mathrm{kcal\\,mol^{-1}\\,Å^{-2}}) (1\\,\\mathrm{Å})$$\n$$F_s = -50\\,\\mathrm{kcal\\,mol^{-1}\\,Å^{-1}}$$\nThe problem asks for the magnitude of this force, which is:\n$$|F_s| = |-50\\,\\mathrm{kcal\\,mol^{-1}\\,Å^{-1}}| = 50\\,\\mathrm{kcal\\,mol^{-1}\\,Å^{-1}}$$\nRounding to four significant figures as required, the magnitude is $50.00\\,\\mathrm{kcal\\,mol^{-1}\\,Å^{-1}}$.\n\nNext, we translate this scalar force on the CV into vector forces on the individual atoms, $\\mathbf{F}_1$ and $\\mathbf{F}_2$. The force on an atom $i$ due to the bias potential is the negative gradient of the potential with respect to the atom's coordinate vector $\\mathbf{r}_i$:\n$$\\mathbf{F}_i = -\\nabla_{\\mathbf{r}_i} V_{bias}(s(\\mathbf{r}_1, \\mathbf{r}_2))$$\nUsing the chain rule, this can be expressed as:\n$$\\mathbf{F}_i = \\left(-\\frac{dV_{bias}}{ds}\\right) (\\nabla_{\\mathbf{r}_i} s) = F_s (\\nabla_{\\mathbf{r}_i} s)$$\nWe need to compute the gradients of the CV $s = |\\mathbf{r}_1 - \\mathbf{r}_2|$ with respect to $\\mathbf{r}_1$ and $\\mathbf{r}_2$.\nFor atom $1$:\n$$\\nabla_{\\mathbf{r}_1} s = \\nabla_{\\mathbf{r}_1} |\\mathbf{r}_1 - \\mathbf{r}_2| = \\frac{\\mathbf{r}_1 - \\mathbf{r}_2}{|\\mathbf{r}_1 - \\mathbf{r}_2|}$$\nThis is the definition of the unit vector $\\boldsymbol{e}_{12}$ provided in the problem statement.\n$$\\nabla_{\\mathbf{r}_1} s = \\boldsymbol{e}_{12}$$\nFor atom $2$:\n$$\\nabla_{\\mathbf{r}_2} s = \\nabla_{\\mathbf{r}_2} |\\mathbf{r}_1 - \\mathbf{r}_2| = -\\frac{\\mathbf{r}_1 - \\mathbf{r}_2}{|\\mathbf{r}_1 - \\mathbf{r}_2|} = -\\boldsymbol{e}_{12}$$\nNow, we can write the expressions for the atomic forces:\n$$\\mathbf{F}_1 = F_s (\\nabla_{\\mathbf{r}_1} s) = F_s \\boldsymbol{e}_{12}$$\n$$\\mathbf{F}_2 = F_s (\\nabla_{\\mathbf{r}_2} s) = -F_s \\boldsymbol{e}_{12}$$\nIt is worth noting that $\\mathbf{F}_1 + \\mathbf{F}_2 = \\mathbf{0}$, which is consistent with Newton's third law for internal forces, ensuring no net force is applied to the center of mass of the two-atom system.\n\nSubstituting the calculated value $F_s = -50\\,\\mathrm{kcal\\,mol^{-1}\\,Å^{-1}}$:\n$$\\mathbf{F}_1 = (-50\\,\\mathrm{kcal\\,mol^{-1}\\,Å^{-1}}) \\boldsymbol{e}_{12}$$\n$$\\mathbf{F}_2 = -(-50\\,\\mathrm{kcal\\,mol^{-1}\\,Å^{-1}}) \\boldsymbol{e}_{12} = (50\\,\\mathrm{kcal\\,mol^{-1}\\,Å^{-1}}) \\boldsymbol{e}_{12}$$\nThe negative sign for $F_s$ indicates a restorative force, as the distance $s=6\\,\\mathrm{Å}$ is greater than the potential minimum $s_0=5\\,\\mathrm{Å}$. The force $\\mathbf{F}_1$ points in the direction opposite to $\\boldsymbol{e}_{12}$ (from atom $1$ towards atom $2$), and the force $\\mathbf{F}_2$ points in the direction of $\\boldsymbol{e}_{12}$ (from atom $2$ towards atom $1$), thus pulling the atoms together.\n\nRounding the numerical coefficients to four significant figures, we get:\nThe magnitude of the force on the CV is $50.00\\,\\mathrm{kcal\\,mol^{-1}\\,Å^{-1}}$.\nThe force on atom $1$ is $\\mathbf{F}_1 = -50.00\\,\\boldsymbol{e}_{12}\\,\\mathrm{kcal\\,mol^{-1}\\,Å^{-1}}$.\nThe force on atom $2$ is $\\mathbf{F}_2 = 50.00\\,\\boldsymbol{e}_{12}\\,\\mathrm{kcal\\,mol^{-1}\\,Å^{-1}}$.\n\nThe final answer requires these three quantities in a single row matrix, in the specified order and without units.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n50.00 & -50.00 \\, \\boldsymbol{e}_{12} & 50.00 \\, \\boldsymbol{e}_{12}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "A successful umbrella sampling study depends critically on the strategic placement of biasing potentials. If windows are too far apart, the resulting probability distributions will not overlap sufficiently, making it impossible to reconstruct a continuous free energy profile. This practice delves into the design principles of an umbrella sampling 'ladder', guiding you to determine the required number and optimal spacing of windows to ensure robust statistical overlap for accurate analysis. ",
            "id": "3458824",
            "problem": "In Molecular Dynamics (MD) simulations employing Umbrella Sampling (US), consider a one-dimensional reaction coordinate $s$ biased by identical harmonic umbrellas centered at positions $\\{s_{0}^{(i)}\\}$ with a common force constant $k$. The system is at temperature $T$ in the canonical ensemble. Assume each window’s sampled histogram along $s$ is well-approximated by the equilibrium probability density function (PDF) determined by its harmonic bias, and define the histogram overlap between two adjacent windows $i$ and $i+1$ as the Overlap Coefficient (the integral of the pointwise minimum of the two PDFs). Starting from the canonical ensemble with Boltzmann weighting and the harmonic bias construction, derive the standard deviation $\\sigma$ of the distribution in a single window and the maximum allowable spacing $d_{\\max}$ between adjacent window centers that guarantees at least $0.3$ overlap coefficient between neighboring window histograms. Then, determine the minimum number of windows $N$ required to cover the interval $s \\in [3,10]\\,\\mathrm{Å}$ inclusively when all centers are equally spaced by $d \\le d_{\\max}$.\n\nUse the temperature $T = 300\\,\\mathrm{K}$, force constant $k = 20\\,\\mathrm{kcal\\,mol^{-1}\\,Å^{-2}}$, and Boltzmann constant per mole $k_{B} = 1.9872041 \\times 10^{-3}\\,\\mathrm{kcal\\,mol^{-1}\\,K^{-1}}$. Express the standard deviation $\\sigma$ in $\\mathrm{Å}$ and round it to three significant figures. Report the number of windows $N$ as the smallest integer satisfying the overlap criterion. Your final answer must be the ordered pair $\\big(\\sigma, N\\big)$ written as a row matrix in the order stated.",
            "solution": "The problem is evaluated as valid according to the specified criteria. It is scientifically grounded in the principles of statistical mechanics and molecular dynamics, well-posed with a clear objective and sufficient information, and free of any disqualifying flaws. I will now proceed with the solution.\n\nThe problem asks for the standard deviation $\\sigma$ of the sampled distribution in a single umbrella window and the minimum number of windows $N$ to cover a specified interval on a reaction coordinate $s$.\n\nFirst, we determine the standard deviation $\\sigma$. The system is in the canonical ensemble at temperature $T$. The biasing potential for a single umbrella window $i$ centered at $s_{0}^{(i)}$ is given by the harmonic function:\n$$\nU_{\\text{bias}}^{(i)}(s) = \\frac{1}{2} k \\left(s - s_{0}^{(i)}\\right)^2\n$$\nwhere $k$ is the force constant. The total potential energy along the reaction coordinate is the sum of the unbiased potential (Potential of Mean Force, PMF), $U_{0}(s)$, and the biasing potential, $U(s) = U_{0}(s) + U_{\\text{bias}}^{(i)}(s)$.\n\nThe equilibrium probability density function (PDF) for observing the system at coordinate $s$ in this biased window is given by the Boltzmann distribution:\n$$\nP_{i}(s) \\propto \\exp\\left(-\\frac{U(s)}{k_{B} T}\\right) = \\exp\\left(-\\frac{U_{0}(s) + \\frac{1}{2} k \\left(s - s_{0}^{(i)}\\right)^2}{k_{B} T}\\right)\n$$\nwhere $k_B$ is the Boltzmann constant. The problem states that we can assume the sampled histogram is well-approximated by the PDF determined solely by the harmonic bias. This implies that within the narrow region sampled by a single window, the underlying PMF $U_{0}(s)$ can be treated as approximately constant. Under this standard approximation, $U_0(s) \\approx C$, and the PDF simplifies to:\n$$\nP_{i}(s) \\propto \\exp\\left(-\\frac{k \\left(s - s_{0}^{(i)}\\right)^2}{2 k_{B} T}\\right)\n$$\nThis is the functional form of a Gaussian (normal) distribution. A standard Gaussian PDF is written as:\n$$\nf(s; \\mu, \\sigma^2) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(s-\\mu)^2}{2\\sigma^2}\\right)\n$$\nBy comparing the exponents of $P_i(s)$ and $f(s; \\mu, \\sigma^2)$, we can identify the mean $\\mu = s_{0}^{(i)}$ and the variance $\\sigma^2$.\n$$\n\\frac{\\left(s - s_{0}^{(i)}\\right)^2}{2 \\sigma^2} = \\frac{k \\left(s - s_{0}^{(i)}\\right)^2}{2 k_{B} T}\n$$\nThis equality implies:\n$$\n\\frac{1}{\\sigma^2} = \\frac{k}{k_{B} T} \\quad \\implies \\quad \\sigma^2 = \\frac{k_{B} T}{k}\n$$\nThe standard deviation $\\sigma$ is therefore:\n$$\n\\sigma = \\sqrt{\\frac{k_{B} T}{k}}\n$$\nWe are given the values $T = 300\\,\\mathrm{K}$, $k = 20\\,\\mathrm{kcal\\,mol^{-1}\\,Å^{-2}}$, and $k_{B} = 1.9872041 \\times 10^{-3}\\,\\mathrm{kcal\\,mol^{-1}\\,K^{-1}}$. The thermal energy is:\n$$\nk_{B} T = (1.9872041 \\times 10^{-3}\\,\\mathrm{kcal\\,mol^{-1}\\,K^{-1}}) \\times (300\\,\\mathrm{K}) \\approx 0.596161\\,\\mathrm{kcal\\,mol^{-1}}\n$$\nNow, we can calculate $\\sigma$:\n$$\n\\sigma = \\sqrt{\\frac{0.596161\\,\\mathrm{kcal\\,mol^{-1}}}{20\\,\\mathrm{kcal\\,mol^{-1}\\,Å^{-2}}}} = \\sqrt{0.029808}\\,\\mathrm{Å} \\approx 0.17265\\,\\mathrm{Å}\n$$\nRounding to three significant figures as requested, we get $\\sigma \\approx 0.173\\,\\mathrm{Å}$.\n\nNext, we determine the maximum allowable spacing $d_{\\max}$ between adjacent window centers. The Overlap Coefficient (OC) between two adjacent windows, $i$ and $i+1$, with centers separated by a distance $d = |s_{0}^{(i+1)} - s_{0}^{(i)}|$, is the integral of the pointwise minimum of their PDFs, $P_i(s)$ and $P_{i+1}(s)$. Both PDFs are Gaussian distributions with the same standard deviation $\\sigma$. Let the centers be at $-d/2$ and $d/2$ for simplicity. The intersection of the two Gaussians occurs at $s=0$. The overlap integral is:\n$$\nOC = \\int_{-\\infty}^{\\infty} \\min(P_i(s), P_{i+1}(s)) ds = \\int_{-\\infty}^{0} P_{i+1}(s) ds + \\int_{0}^{\\infty} P_i(s) ds\n$$\nDue to symmetry, the two integrals are equal. We can write $OC = 2 \\int_{0}^{\\infty} P_i(s) ds$. This calculation is standard and yields a result in terms of the complementary error function, $\\text{erfc}(x)$:\n$$\nOC(d, \\sigma) = \\text{erfc}\\left(\\frac{d}{2\\sqrt{2}\\sigma}\\right)\n$$\nWe are given that the minimum required overlap is $0.3$. The maximum spacing $d_{\\max}$ is found by setting $OC = 0.3$:\n$$\n0.3 = \\text{erfc}\\left(\\frac{d_{\\max}}{2\\sqrt{2}\\sigma}\\right)\n$$\nTo solve for $d_{\\max}$, we take the inverse complementary error function ($\\text{erfc}^{-1}$) of both sides:\n$$\n\\text{erfc}^{-1}(0.3) = \\frac{d_{\\max}}{2\\sqrt{2}\\sigma}\n$$\nUsing a numerical library or calculator, $\\text{erfc}^{-1}(0.3) \\approx 0.73287$.\n$$\nd_{\\max} = 2\\sqrt{2}\\sigma \\times \\text{erfc}^{-1}(0.3) \\approx 2\\sqrt{2} \\times (0.17265\\,\\mathrm{Å}) \\times 0.73287 \\approx 0.35787\\,\\mathrm{Å}\n$$\nFinally, we determine the minimum number of windows $N$ required to cover the interval $s \\in [3, 10]\\,\\mathrm{Å}$. The total length of the reaction coordinate to be sampled is $L = 10\\,\\mathrm{Å} - 3\\,\\mathrm{Å} = 7\\,\\mathrm{Å}$. To cover the interval inclusively with equally spaced windows, we place the first window center at $s_0^{(1)} = 3\\,\\mathrm{Å}$ and the last at $s_0^{(N)} = 10\\,\\mathrm{Å}$. With $N$ windows, there are $N-1$ intervals of spacing $d$. The total length spanned by the centers is:\n$$\nL = (N-1)d\n$$\nTo ensure sufficient overlap, the spacing $d$ must not exceed the maximum allowable spacing $d_{\\max}$:\n$$\nd \\le d_{\\max}\n$$\nSubstituting $d = L/(N-1)$, we get:\n$$\n\\frac{L}{N-1} \\le d_{\\max} \\quad \\implies \\quad N-1 \\ge \\frac{L}{d_{\\max}}\n$$\nThis gives the condition for the minimum number of windows:\n$$\nN \\ge \\frac{L}{d_{\\max}} + 1\n$$\nPlugging in the values for $L$ and $d_{\\max}$:\n$$\nN \\ge \\frac{7\\,\\mathrm{Å}}{0.35787\\,\\mathrm{Å}} + 1 \\approx 19.5599 + 1 = 20.5599\n$$\nSince $N$ must be an integer, the smallest number of windows that satisfies this condition is $N=21$.\n\nThe required values are the standard deviation $\\sigma$ rounded to three significant figures and the minimum integer number of windows $N$.\n$\\sigma = 0.173\\,\\mathrm{Å}$\n$N = 21$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 0.173 & 21 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Once biased simulations are complete, the crucial task is to remove the influence of the artificial potentials to recover the true underlying physics. This hands-on coding exercise demonstrates the fundamental reweighting principle at the heart of methods like the Weighted Histogram Analysis Method (WHAM). By processing biased histograms, you will implement the mathematical procedure to unbias your data and reconstruct the unbiased probability distribution, which is the direct precursor to the potential of mean force. ",
            "id": "3458771",
            "problem": "You are given discrete reaction coordinate bins $\\{s_i\\}_{i=1}^N$, a biased histogram $h_b(s_i)$ of counts collected under a known bias potential $U_b(s_i)$, and a constant temperature $T$ in Kelvin. The task is to recover the unbiased discrete Probability Mass Function (PMF) $p(s_i)$ over the bins by properly reweighting the biased histogram, starting from the canonical ensemble under the Boltzmann distribution and the definition of biasing. The solution must derive the appropriate unnormalized estimator and then produce a normalized PMF across the discrete bins.\n\nFundamental base:\n- In the canonical ensemble at temperature $T$, the Boltzmann distribution implies that the probability of microstate $x$ with energy $U(x)$ is proportional to $\\exp(-\\beta U(x))$, where $\\beta = \\frac{1}{k_\\mathrm{B} T}$ and $k_\\mathrm{B}$ is the Boltzmann constant.\n- When a bias potential $U_b(s)$ is applied along a collective variable $s$, the sampled distribution along $s$ under the bias is altered according to the Boltzmann factor and can be related to the unbiased distribution.\n\nDefinitions and requirements:\n- Let $k_\\mathrm{B} = 0.00831446261815324$ in units of kilojoules per mole per Kelvin ($\\mathrm{kJ\\,mol^{-1}\\,K^{-1}}$), so that if $U_b(s)$ is given in kilojoules per mole ($\\mathrm{kJ\\,mol^{-1}}$) and $T$ in Kelvin, then $\\beta$ has units of mol kJ$^{-1}$.\n- The discrete PMF $p(s_i)$ must satisfy $\\sum_{i=1}^N p(s_i) = 1$. The PMF is dimensionless (no physical units).\n- You must compute an unnormalized estimate for the unbiased distribution over bins from the given $h_b(s_i)$ and $U_b(s_i)$, and then normalize it to obtain $p(s_i)$.\n\nNumerical and algorithmic constraints:\n- Handle bins with zero counts $h_b(s_i) = 0$ correctly in a way that is consistent with probability theory.\n- Avoid numerical overflow or underflow when computing exponentials; design the algorithm to be stable for large-magnitude values of $\\beta U_b(s_i)$.\n\nTest suite specification:\nFor each test case, $h_b(s_i)$ is a list of nonnegative integers, $U_b(s_i)$ is a list of real numbers in $\\mathrm{kJ\\,mol^{-1}}$, and $T$ is a positive real number in Kelvin. Your program must process all test cases and produce their PMFs.\n\n- Test case $1$ (happy path):\n  - $T = 300$ K\n  - $h_b(s) = [100, 120, 80, 60, 40, 20]$\n  - $U_b(s) = [5.0, 2.0, 0.0, 2.0, 5.0, 8.0]$ $\\mathrm{kJ\\,mol^{-1}}$\n\n- Test case $2$ (bins with zero counts and both negative and positive biases):\n  - $T = 300$ K\n  - $h_b(s) = [0, 50, 0, 10, 0]$\n  - $U_b(s) = [-2.0, -1.0, 0.0, 1.0, 2.0]$ $\\mathrm{kJ\\,mol^{-1}}$\n\n- Test case $3$ (high temperature reduces the impact of bias):\n  - $T = 1200$ K\n  - $h_b(s) = [10, 20, 30, 40, 50]$\n  - $U_b(s) = [0.0, 4.0, 8.0, 4.0, 0.0]$ $\\mathrm{kJ\\,mol^{-1}}$\n\n- Test case $4$ (low temperature increases the impact of bias; potential for extreme reweighting):\n  - $T = 50$ K\n  - $h_b(s) = [500, 10, 10, 500]$\n  - $U_b(s) = [10.0, 0.0, 0.0, 10.0]$ $\\mathrm{kJ\\,mol^{-1}}$\n\nFinal output format:\n- Your program should produce a single line of output containing the PMFs for all test cases as a comma-separated list of lists enclosed in square brackets, with each inner list containing the PMF values for one test case in bin order. Each PMF value must be printed as a float with $6$ decimal places, and there must be no extra spaces. For example: $[[p_{1,1},p_{1,2},\\dots],[p_{2,1},\\dots],\\dots]$.",
            "solution": "The problem is valid. It presents a standard, well-posed task in computational statistical mechanics: recovering an unbiased probability distribution from biased simulation data. All provided information is scientifically sound, self-contained, and sufficient to derive a unique, meaningful solution.\n\nThe objective is to determine the unbiased Probability Mass Function (PMF), denoted as $p(s_i)$, over a set of discrete reaction coordinate bins $\\{s_i\\}_{i=1}^N$, given a biased histogram of counts $h_b(s_i)$, a known bias potential $U_b(s_i)$ for each bin, and a constant temperature $T$.\n\nThe derivation begins with the fundamental principles of the canonical ensemble in statistical mechanics. The probability $P(x)$ of a system being in a specific microstate $x$ with energy $U(x)$ is given by the Boltzmann distribution:\n$$\nP(x) = \\frac{1}{Z} e^{-\\beta U(x)}\n$$\nwhere $\\beta = \\frac{1}{k_\\mathrm{B} T}$ is the inverse thermal energy, $k_\\mathrm{B}$ is the Boltzmann constant, and $Z$ is the canonical partition function, which normalizes the distribution.\n\nThe probability of finding the system within a particular bin $s_i$ of a collective variable $s$ is obtained by integrating over all microstates $x$ for which $s(x)=s_i$. The unbiased PMF $p(s_i)$ is therefore proportional to this integral:\n$$\np(s_i) \\propto \\int_{s(x)=s_i} e^{-\\beta U(x)} dx\n$$\nIn a biased simulation, an external potential $U_b(s)$ is applied. The total energy of a microstate $x$ becomes $U_{total}(x) = U(x) + U_b(s(x))$. The probability of observing a microstate $x$ in this biased ensemble, $P_b(x)$, is:\n$$\nP_b(x) \\propto e^{-\\beta (U(x) + U_b(s(x)))} = e^{-\\beta U(x)} e^{-\\beta U_b(s(x))}\n$$\nThe corresponding biased PMF, $p_b(s_i)$, is found by integrating over the relevant microstates. Since for any given bin $s_i$, the bias potential $U_b(s_i)$ is constant, its Boltzmann factor can be taken outside the integral:\n$$\np_b(s_i) \\propto \\int_{s(x)=s_i} e^{-\\beta U(x)} e^{-\\beta U_b(s_i)} dx = e^{-\\beta U_b(s_i)} \\int_{s(x)=s_i} e^{-\\beta U(x)} dx\n$$\nThe remaining integral is proportional to the unbiased probability $p(s_i)$. This establishes the core relationship between the biased and unbiased probability distributions:\n$$\np_b(s_i) \\propto p(s_i) e^{-\\beta U_b(s_i)}\n$$\nTo find the unbiased PMF $p(s_i)$, we can rearrange this equation:\n$$\np(s_i) \\propto p_b(s_i) e^{\\beta U_b(s_i)}\n$$\nIn a molecular dynamics simulation, the biased probability $p_b(s_i)$ is estimated from the histogram of observed counts $h_b(s_i)$. For a sufficiently long simulation, the number of counts in a bin is proportional to the probability of that bin: $h_b(s_i) \\propto p_b(s_i)$. Substituting this into the previous relation, we obtain an unnormalized estimate for the unbiased PMF, which we denote as $\\tilde{p}(s_i)$:\n$$\n\\tilde{p}(s_i) = h_b(s_i) e^{\\beta U_b(s_i)}\n$$\nTo obtain the final, correctly normalized PMF, $p(s_i)$, we must divide this unnormalized estimate by its sum over all $N$ bins. This sum acts as the normalization constant $Z_{norm}$:\n$$\nZ_{norm} = \\sum_{j=1}^{N} \\tilde{p}(s_j) = \\sum_{j=1}^{N} h_b(s_j) e^{\\beta U_b(s_j)}\n$$\nThe normalized PMF is then given by:\n$$\np(s_i) = \\frac{\\tilde{p}(s_i)}{Z_{norm}} = \\frac{h_b(s_i) e^{\\beta U_b(s_i)}}{\\sum_{j=1}^{N} h_b(s_j) e^{\\beta U_b(s_j)}}\n$$\nThis formula correctly handles bins with zero counts; if $h_b(s_i)=0$, then $p(s_i)=0$, reflecting that this state was not observed and its probability is estimated as zero.\n\nFor numerical implementation, the term $e^{\\beta U_b(s_i)}$ can cause overflow if the exponent $\\beta U_b(s_i)$ is large and positive. To ensure numerical stability, we can exploit the fact that multiplying the numerator and denominator by a constant does not change the result. A standard technique is to shift the exponents. Let $E_i = \\beta U_b(s_i)$. We find the maximum value of this exponent over all bins that were actually sampled (i.e., where $h_b(s_i) > 0$), let's call it $E_{\\max} = \\max_{j | h_b(s_j)>0} \\{E_j\\}$. We then reformulate the calculation as:\n$$\np(s_i) = \\frac{h_b(s_i) e^{E_i} e^{-E_{\\max}}}{\\sum_{j=1}^{N} h_b(s_j) e^{E_j} e^{-E_{\\max}}} = \\frac{h_b(s_i) e^{E_i - E_{\\max}}}{\\sum_{j=1}^{N} h_b(s_j) e^{E_j - E_{\\max}}}\n$$\nIn this numerically robust form, the exponent $E_j - E_{\\max}$ is always less than or equal to $0$ for all sampled bins, which confines the value of the exponential term to the range $(0, 1]$ and effectively prevents overflow. If all histogram counts are zero, the total number of samples is zero, and the normalization constant becomes zero. In this case, the PMF is undefined, and the algorithm should return a vector of zeros, as no probability can be assigned to any bin.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the unbiased Probability Mass Function (PMF) from biased histograms\n    for a series of test cases.\n    \"\"\"\n    # Define the Boltzmann constant in kJ mol^-1 K^-1\n    K_B = 0.00831446261815324\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"T\": 300, # K\n            \"h_b\": [100, 120, 80, 60, 40, 20],\n            \"U_b\": [5.0, 2.0, 0.0, 2.0, 5.0, 8.0], # kJ mol^-1\n        },\n        {\n            \"T\": 300, # K\n            \"h_b\": [0, 50, 0, 10, 0],\n            \"U_b\": [-2.0, -1.0, 0.0, 1.0, 2.0], # kJ mol^-1\n        },\n        {\n            \"T\": 1200, # K\n            \"h_b\": [10, 20, 30, 40, 50],\n            \"U_b\": [0.0, 4.0, 8.0, 4.0, 0.0], # kJ mol^-1\n        },\n        {\n            \"T\": 50, # K\n            \"h_b\": [500, 10, 10, 500],\n            \"U_b\": [10.0, 0.0, 0.0, 10.0], # kJ mol^-1\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        T = case[\"T\"]\n        h_b = np.array(case[\"h_b\"], dtype=np.float64)\n        U_b = np.array(case[\"U_b\"], dtype=np.float64)\n\n        # If there are no counts at all, the PMF is undefined.\n        # Returning zeros is a consistent interpretation.\n        if np.sum(h_b) == 0:\n            pmf = np.zeros_like(h_b)\n            results.append(pmf.tolist())\n            continue\n\n        # Calculate inverse thermal energy, beta\n        beta = 1.0 / (K_B * T)\n\n        # Calculate the log of the reweighting factors\n        log_reweight_factors = beta * U_b\n\n        # For numerical stability, find the maximum of the log factors\n        # only over the bins that were actually sampled (h_b > 0).\n        sampled_indices = np.where(h_b > 0)\n        max_log_factor = np.max(log_reweight_factors[sampled_indices])\n\n        # Shift the log factors to prevent numerical overflow in the exponentiation.\n        # The largest exponent will now be 0, leading to a max reweighting factor of 1.\n        stable_log_factors = log_reweight_factors - max_log_factor\n\n        # Calculate the final reweighting factors\n        reweighting_factors = np.exp(stable_log_factors)\n\n        # Apply reweighting to get unnormalized unbiased counts/probabilities\n        unbiased_counts = h_b * reweighting_factors\n\n        # Normalize to get the final Probability Mass Function (PMF)\n        total_unbiased_count = np.sum(unbiased_counts)\n        pmf = unbiased_counts / total_unbiased_count\n\n        results.append(pmf.tolist())\n\n    # Format the final output string according to the specified format.\n    # e.g., [[0.123456,0.876544],[...]]\n    outer_list_str = []\n    for res_list in results:\n        inner_list_str = \",\".join([f\"{val:.6f}\" for val in res_list])\n        outer_list_str.append(f\"[{inner_list_str}]\")\n    \n    final_output_str = f\"[{','.join(outer_list_str)}]\"\n    print(final_output_str)\n\nsolve()\n```"
        }
    ]
}