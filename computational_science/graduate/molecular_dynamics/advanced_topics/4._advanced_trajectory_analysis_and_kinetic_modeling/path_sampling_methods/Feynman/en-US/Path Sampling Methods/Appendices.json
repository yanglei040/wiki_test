{
    "hands_on_practices": [
        {
            "introduction": "The Milestoning method is a powerful strategy for simulating rare events by decomposing a complex process into a series of shorter, more manageable transitions between predefined interfaces, or \"milestones\". This exercise focuses on the final step of a Milestoning calculation: reconstructing the global kinetics from the local data. You will use fundamental probabilistic reasoning to derive and solve the backward master equation for the Mean First Passage Time (MFPT), demonstrating how local exit times and transition probabilities are pieced together to determine a macroscopic timescale . This practice is essential for understanding the theoretical foundation that allows Milestoning to bridge vastly different time and length scales.",
            "id": "3434778",
            "problem": "Consider an overdamped molecular system at thermal equilibrium, modeled by a one-dimensional reaction coordinate with a milestoning discretization. Four milestones partition the coordinate into three cells, with labels $i \\in \\{0,1,2,3\\}$. The reactant set is milestone $A$ at $i=0$, and the product set is milestone $B$ at $i=3$. Under the standard milestoning assumptions (Markov renewal property at milestones and local equilibration on each milestone), define the mean first passage time (MFPT) $T_i$ as the expected time to reach $B$ when starting from milestone $i$. On each non-absorbing milestone $i \\in \\{0,1,2\\}$, infinitesimal trajectories initiated from the local stationary density restricted to milestone $i$ produce the following data:\n- The mean local exit time $\\tau_i$ (the expected time to hit any neighboring milestone starting from milestone $i$).\n- The conditional exit probabilities $p_{ij}$ for transitioning from milestone $i$ to a neighboring milestone $j$ at the next exit.\n\nAssume only nearest-neighbor exits occur and that $B$ is absorbing. The measured quantities are:\n- For milestone $i=0$: $\\tau_0 = 8 \\text{ ps}$ and $p_{01} = 1$.\n- For milestone $i=1$: $\\tau_1 = 12 \\text{ ps}$, $p_{10} = 0.35$, and $p_{12} = 0.65$.\n- For milestone $i=2$: $\\tau_2 = 15 \\text{ ps}$, $p_{21} = 0.25$, and $p_{23} = 0.75$.\n- For milestone $i=3$: $B$ is absorbing, so $T_3 = 0$ and there are no exits.\n\nStarting from the definitions above, and using only fundamental probabilistic reasoning (in particular, the law of total expectation) together with the Markov renewal assumption at milestones, derive from first principles the linear system satisfied by the MFPTs $T_i$ for $i \\in \\{0,1,2\\}$, and then solve this system to obtain $T_0$, the MFPT from $A$ to $B$.\n\nExpress the final MFPT $T_0$ in nanoseconds (ns). Round your answer to four significant figures.",
            "solution": "The problem is scientifically grounded, well-posed, objective, self-contained, and consistent. It describes a standard application of the milestoning method for calculating the mean first passage time (MFPT) of a process on a one-dimensional reaction coordinate. All necessary data are provided, and the probabilistic relationships are consistent. The task is to derive and solve the backward master equations for the MFPTs. The problem is valid.\n\nThe central principle for solving this problem is the application of the law of total expectation to the process of reaching the product state $B$ (milestone $i=3$) starting from an intermediate milestone $i$. The milestoning framework assumes that the process is a Markov renewal process at the milestones. This means that once a trajectory reaches a milestone, its future evolution is independent of how it arrived there.\n\nLet $T_i$ be the mean first passage time to reach the product state $B$ (milestone $3$) starting from a uniform stationary distribution on milestone $i$. A trajectory starting from milestone $i$ will first evolve within the cell associated with $i$ for a certain duration, until it hits a neighboring milestone $j$. The average duration of this first step is the mean local exit time, $\\tau_i$. The trajectory then arrives at milestone $j$ with a probability $p_{ij}$. Due to the Markov renewal property, the remaining expected time to reach $B$ from milestone $j$ is simply $T_j$.\n\nBy the law of total expectation, we can express $T_i$ as the sum of the mean time for the first exit and the expected time from the next milestone onward, averaged over all possible exits:\n$T_i = (\\text{mean time for first exit from cell } i) + (\\text{expected remaining time to reach } B)$\nMathematically, this is expressed as:\n$$T_i = \\tau_i + \\sum_{j} p_{ij} T_j$$\nwhere the sum is over all milestones $j$ that are neighbors of $i$. This set of equations is known as the backward master equation for the MFPTs.\n\nWe are given a system with four milestones, $i \\in \\{0, 1, 2, 3\\}$. Milestone $i=0$ is the reactant state $A$, and milestone $i=3$ is the absorbing product state $B$. The boundary condition for the absorbing state is $T_3 = 0$, as the time to reach $B$ starting from $B$ is zero. We need to find the MFPTs $T_0$, $T_1$, and $T_2$ for the non-absorbing milestones.\n\nThe given data are:\n- For milestone $i=0$: $\\tau_0 = 8 \\text{ ps}$, $p_{01} = 1$.\n- For milestone $i=1$: $\\tau_1 = 12 \\text{ ps}$, $p_{10} = 0.35$, $p_{12} = 0.65$.\n- For milestone $i=2$: $\\tau_2 = 15 \\text{ ps}$, $p_{21} = 0.25$, $p_{23} = 0.75$.\n\nWe can now write the specific equations for each non-absorbing milestone:\n\nFor milestone $i=2$: The neighbors are $j=1$ and $j=3$.\n$$T_2 = \\tau_2 + p_{21}T_1 + p_{23}T_3$$\nSubstituting the given values and $T_3=0$:\n$$T_2 = 15 + (0.25)T_1 + (0.75)(0)$$\n$$T_2 = 15 + 0.25 T_1 \\quad (1)$$\n\nFor milestone $i=1$: The neighbors are $j=0$ and $j=2$.\n$$T_1 = \\tau_1 + p_{10}T_0 + p_{12}T_2$$\nSubstituting the given values:\n$$T_1 = 12 + 0.35 T_0 + 0.65 T_2 \\quad (2)$$\n\nFor milestone $i=0$: The only neighbor is $j=1$.\n$$T_0 = \\tau_0 + p_{01}T_1$$\nSubstituting the given values:\n$$T_0 = 8 + (1)T_1$$\n$$T_0 = 8 + T_1 \\quad (3)$$\n\nWe now have a system of three linear equations with three unknowns ($T_0, T_1, T_2$). We can solve this system by substitution.\n\nFrom equation $(3)$, we can express $T_1$ in terms of $T_0$:\n$$T_1 = T_0 - 8$$\n\nSubstitute this expression for $T_1$ into equation $(1)$ to find $T_2$ in terms of $T_0$:\n$$T_2 = 15 + 0.25(T_0 - 8)$$\n$$T_2 = 15 + 0.25 T_0 - 2$$\n$$T_2 = 13 + 0.25 T_0$$\n\nNow, substitute the expressions for $T_1$ and $T_2$ in terms of $T_0$ into equation $(2)$:\n$$T_1 = 12 + 0.35 T_0 + 0.65 T_2$$\n$$T_0 - 8 = 12 + 0.35 T_0 + 0.65 (13 + 0.25 T_0)$$\n\nNow, we solve this equation for $T_0$. First, expand the right-hand side:\n$$T_0 - 8 = 12 + 0.35 T_0 + (0.65)(13) + (0.65)(0.25) T_0$$\n$$T_0 - 8 = 12 + 0.35 T_0 + 8.45 + 0.1625 T_0$$\n\nGroup the terms with $T_0$ and the constant terms:\n$$T_0 - 8 = (12 + 8.45) + (0.35 + 0.1625) T_0$$\n$$T_0 - 8 = 20.45 + 0.5125 T_0$$\n\nRearrange the equation to isolate $T_0$:\n$$T_0 - 0.5125 T_0 = 20.45 + 8$$\n$$(1 - 0.5125) T_0 = 28.45$$\n$$0.4875 T_0 = 28.45$$\n\nFinally, solve for $T_0$:\n$$T_0 = \\frac{28.45}{0.4875}$$\n$$T_0 \\approx 58.35897435... \\text{ ps}$$\n\nThe problem requires the final answer to be in nanoseconds (ns) and rounded to four significant figures.\nWe use the conversion $1 \\text{ ns} = 1000 \\text{ ps}$.\n$$T_0 (\\text{ns}) = \\frac{T_0 (\\text{ps})}{1000} = \\frac{58.35897435...}{1000} = 0.05835897435... \\text{ ns}$$\n\nRounding this value to four significant figures: The first four significant figures are $5$, $8$, $3$, $5$. The next digit is $8$, which is greater than or equal to $5$, so we round up the last significant digit.\n$$T_0 \\approx 0.05836 \\text{ ns}$$",
            "answer": "$$\\boxed{0.05836}$$"
        },
        {
            "introduction": "The field of rare event simulation features a diverse ecosystem of algorithms, including Transition Path Sampling (TPS) and Weighted Ensemble (WE), each with unique operational mechanics. A crucial question is whether these different methods sample the same underlying physical reality. This exercise tasks you with verifying the equivalence of the reactive path ensembles generated by TPS and WE for a simple, exactly solvable system . By implementing both algorithms and comparing their results to a first-principles analytical solution, you will gain invaluable hands-on insight into how these methods work and build confidence in their shared theoretical underpinnings.",
            "id": "3434777",
            "problem": "Consider a discrete-time, one-dimensional, nearest-neighbor Markov chain modeling overdamped diffusion across metastable sets with absorbing boundaries. The state space is $\\{0,1,2,\\dots,M\\}$, where state $0$ is the source set $\\mathcal{A}$ and state $M$ is the target set $\\mathcal{B}$. At each time step, a walker at interior state $i \\in \\{1,\\dots,M-1\\}$ moves to $i+1$ with probability $p$ and to $i-1$ with probability $q$, where $q = 1 - p$, and transitions from $0$ and $M$ are absorbing. Define a path observable $f(\\text{path})$ to be the total number of visits to a particular interior state $k \\in \\{1,\\dots,M-1\\}$ along a trajectory from its initial state until absorption. For a starting interior state $i \\in \\{1,\\dots,M-1\\}$, the transition-path ensemble is defined by conditioning the path distribution on eventual absorption in $\\mathcal{B}$ before absorption in $\\mathcal{A}$.\n\nYour objectives, based on fundamental principles of Markov chains and unbiased sampling, are as follows:\n\n- Starting from the definition of path probabilities in discrete-time Markov processes, the characterization of absorbing sets, and conditioning on events via the Doob $h$-transform, derive an exact expression for the conditional expectation $\\mathbb{E}[f(\\text{path}) \\mid \\text{absorb in } \\mathcal{B}]$ for the random walk described above. The derivation and the algorithm must start from first principles (transition probabilities and conditioning) without assuming any specialized formulas beyond standard Markov chain and linear algebra results. Express all mathematical entities using LaTeX.\n\n- Implement two estimators of $\\langle f(\\text{path}) \\rangle$ under matched boundary conditions:\n  1. A Transition Path Sampling (TPS)-like estimator that generates complete trajectories starting from $i$, discards those that absorb in $\\mathcal{A}$, and averages $f(\\text{path})$ over accepted trajectories that absorb in $\\mathcal{B}$.\n  2. A Weighted Ensemble (WE) estimator that maintains a fixed number of walkers per interior state bin by splitting and pruning with conserved statistical weights, propagates walkers according to the unbiased dynamics until absorption, and estimates the conditional expectation $\\mathbb{E}[f(\\text{path}) \\mid \\text{absorb in } \\mathcal{B}]$ as the ratio of the total weight times the path observable accumulated on trajectories that absorb in $\\mathcal{B}$ to the total weight absorbed into $\\mathcal{B}$.\n\n- Demonstrate equivalence (in the long-time limit) of the TPS and WE path ensembles by comparing $\\langle f(\\text{path}) \\rangle$ computed by both methods to the exact conditional expectation derived from first principles. Your numerical implementation must use scientifically sound parameters and must ensure that boundary conditions, starting distribution, and dynamics are matched across the two estimators.\n\nAll quantities are dimensionless.\n\nTest Suite:\nImplement the program to evaluate the following three parameter sets, each specified by $(M,p,i,k,T,K,N)$ where $T$ is the maximum number of propagation steps for the Weighted Ensemble estimator, $K$ is the target number of walkers per interior state bin in the Weighted Ensemble, and $N$ is the number of independent trajectories in the TPS-like estimator:\n\n- Case $1$: $(M,p,i,k,T,K,N) = (12,\\,0.55,\\,3,\\,6,\\,3000,\\,40,\\,30000)$.\n- Case $2$: $(M,p,i,k,T,K,N) = (12,\\,0.50,\\,4,\\,9,\\,4000,\\,60,\\,40000)$.\n- Case $3$: $(M,p,i,k,T,K,N) = (18,\\,0.52,\\,1,\\,9,\\,5000,\\,60,\\,50000)$.\n\nRequired Output:\nFor each case, compute three quantities: the TPS-like estimate, the WE estimate, and the exact conditional expectation. Return a boolean indicating equivalence if both the absolute difference between the TPS-like and WE estimates and the absolute differences between each estimator and the exact conditional expectation are strictly less than a tolerance $\\varepsilon = 0.03$. Your program should produce a single line of output containing the three booleans as a comma-separated list enclosed in square brackets (e.g., $\\texttt{[True,True,False]}$).\n\nFinal Output Format:\nYour program should produce exactly one line, formatted as a Python list of three booleans: $\\texttt{[b_1,b_2,b_3]}$, where each $b_j$ corresponds to Case $j$ as described above.",
            "solution": "The problem asks for the derivation of an exact formula for the conditional expectation of a path observable on a 1D lattice, and for its comparison with two numerical estimators: a Transition Path Sampling (TPS)-like method and a Weighted Ensemble (WE) method.\n\n### Part 1: Exact Analytical Derivation\n\nThe system is a one-dimensional discrete-time random walk on the states $\\{0, 1, \\dots, M\\}$. States $0$ and $M$ are absorbing, representing sets $\\mathcal{A}$ and $\\mathcal{B}$ respectively. For any interior state $j \\in \\{1, \\dots, M-1\\}$, the transition probabilities are $P(j \\to j+1) = p$ and $P(j \\to j-1) = q = 1-p$. The path observable $f(\\text{path})$ is the total number of visits to a specific interior state $k$. We seek the conditional expectation $\\mathbb{E}[f(\\text{path}) \\mid X_0=i, \\text{absorb in } \\mathcal{B}]$, where the walk starts at an interior state $i$.\n\n**1. Committor Probability**\n\nFirst, we define the committor probability, $h_j$, as the probability that a walk starting at state $j$ is absorbed at state $M$ before being absorbed at state $0$. The boundary conditions are $h_0 = 0$ and $h_M = 1$. For any interior state $j$, conditioning on the first step yields the recurrence relation:\n$$h_j = p \\cdot h_{j+1} + q \\cdot h_{j-1}$$\nThis is a second-order linear homogeneous difference equation, $p h_{j+1} - h_j + q h_{j-1} = 0$. The characteristic equation is $p\\lambda^2 - \\lambda + q = 0$, which has roots $\\lambda_1 = 1$ and $\\lambda_2 = q/p$.\n\nLet $\\rho = q/p$.\nIf $p \\neq 0.5$ (i.e., $\\rho \\neq 1$), the general solution is $h_j = C_1(1)^j + C_2(\\rho)^j$. Applying the boundary conditions $h_0 = C_1 + C_2 = 0$ and $h_M = C_1 + C_2\\rho^M = 1$, we solve for $C_1$ and $C_2$ to find:\n$$h_j = \\frac{\\rho^j - 1}{\\rho^M - 1}$$\nIf $p = 0.5$ (i.e., $\\rho = 1$), the characteristic equation has a double root at $\\lambda=1$. The general solution is $h_j = C_1(1)^j + C_2 j(1)^j = C_1 + C_2 j$. The boundary conditions $h_0 = C_1 = 0$ and $h_M = C_2 M = 1$ give:\n$$h_j = \\frac{j}{M}$$\nThe case for $p=0.5$ can also be obtained by taking the limit $\\rho \\to 1$ of the general formula using L'HÃ´pital's rule.\n\n**2. The Conditioned Process and Relation to the Green's Function**\n\nWe are interested in the ensemble of paths that start at $i$ and end at $M$. The properties of this conditioned process can be described by a new Markov chain, obtained via the Doob $h$-transform. The transition probabilities $P'_{jk}$ of this conditioned process are given by $P'_{jk} = P_{jk} h_k / h_j$.\n\nLet $E_i(k)$ be the expected number of visits to state $k$ starting from state $i$ in this conditioned process. We wish to compute $E_i(k)$. A more direct approach is to relate this conditional expectation to properties of the original, unconditioned process.\n\nThe conditional expectation can be written as:\n$$E_i(k) = \\mathbb{E}[f \\mid \\text{absorb at } M] = \\frac{\\mathbb{E}[f \\cdot \\mathbf{1}_{\\{\\text{absorb at } M\\}}]}{P(\\text{absorb at } M)}$$\nThe denominator is simply the committor probability $h_i$. The numerator is the expectation of the observable multiplied by an indicator function for the event of absorption at $M$. Let $f = \\sum_{t=0}^{\\tau-1} \\delta_{X_t, k}$, where $\\tau$ is the absorption time.\n$$\n\\mathbb{E}[f \\cdot \\mathbf{1}_{\\{\\text{absorb at } M\\}} \\mid X_0=i] = \\mathbb{E}\\left[\\left(\\sum_{t=0}^{\\tau-1} \\delta_{X_t, k}\\right) \\mathbf{1}_{\\{\\text{absorb at } M\\}} \\mid X_0=i\\right]\n$$\nBy linearity of expectation and the Markov property:\n$$\n\\sum_{t=0}^{\\tau-1} \\mathbb{E}[\\delta_{X_t, k} \\cdot \\mathbf{1}_{\\{\\text{absorb at } M\\}} \\mid X_0=i] = \\sum_{t=0}^{\\tau-1} P(X_t=k \\text{ and absorb at } M \\mid X_0=i)\n$$\n$$\n= \\sum_{t=0}^{\\tau-1} P(X_t=k \\mid X_0=i) \\cdot P(\\text{absorb at } M \\mid X_t=k)\n$$\nThe second term in the product is simply $h_k$. Thus the expression becomes:\n$$\nh_k \\sum_{t=0}^{\\tau-1} P(X_t=k \\mid X_0=i) = h_k \\cdot \\mathbb{E}\\left[\\sum_{t=0}^{\\tau-1} \\delta_{X_t, k} \\mid X_0=i\\right]\n$$\nThe term in the expectation is the total number of visits to state $k$ in the original, unconditioned random walk starting from $i$ before absorption at either $0$ or $M$. Let's denote this quantity by $G_{ik}$, which is the discrete Green's function for the process on the finite domain with absorbing boundaries.\nSo, $\\mathbb{E}[f \\cdot \\mathbf{1}_{\\{\\text{absorb at } M\\}} \\mid X_0=i] = G_{ik} h_k$.\nFinally, the conditional expectation is:\n$$E_i(k) = \\frac{G_{ik} h_k}{h_i}$$\n\n**3. The Green's Function $G_{ik}$**\n\nThe Green's function $G_{jk}$ is the solution to the difference equation for the expected number of visits:\n$$G_{jk} - (p G_{j+1, k} + q G_{j-1, k}) = \\delta_{jk}$$\nwith boundary conditions $G_{0k} = G_{Mk} = 0$. This is equivalent to solving $p G_{j+1, k} - G_{jk} + q G_{j-1, k} = -\\delta_{jk}$.\n\nThe solution can be constructed using homogeneous solutions, similar to the committor calculation.\nFor $p=0.5$:\n$$G_{ik} = \\begin{cases} \\frac{2i(M-k)}{M}  i \\le k \\\\ \\frac{2k(M-i)}{M}  i \\ge k \\end{cases}$$\nFor $p \\neq 0.5$ (with $\\rho=q/p$):\n$$G_{ik} = \\begin{cases} \\frac{(\\rho^k-\\rho^M)(\\rho^i-1)}{(q-p)\\rho^k(\\rho^M-1)}  i \\le k \\\\ \\frac{(\\rho^k-1)(\\rho^i-\\rho^M)}{(q-p)\\rho^k(\\rho^M-1)}  i \\ge k \\end{cases}$$\n\n**4. Final expression for $E_i(k)$**\n\nCombining the expressions for $G_{ik}$, $h_k$, and $h_i$ gives the final result.\n\nIf $p=0.5$:\n- For $i \\le k$: $E_i(k) = \\frac{2i(M-k)/M \\cdot k/M}{i/M} = \\frac{2k(M-k)}{M}$.\n- For $i  k$: $E_i(k) = \\frac{2k(M-i)/M \\cdot k/M}{i/M} = \\frac{2k^2(M-i)}{Mi}$.\n\nIf $p \\neq 0.5$:\n- For $i \\le k$: $E_i(k) = \\frac{G_{ik}h_k}{h_i} = \\frac{(\\rho^k-\\rho^M)(\\rho^i-1)}{(q-p)\\rho^k(\\rho^M-1)} \\frac{(\\rho^k-1)/(\\rho^M-1)}{(\\rho^i-1)/(\\rho^M-1)} = \\frac{(\\rho^k-\\rho^M)(\\rho^k-1)}{(q-p)\\rho^k(\\rho^M-1)}$.\n- For $i  k$: $E_i(k) = \\frac{G_{ik}h_k}{h_i} = \\frac{(\\rho^k-1)(\\rho^i-\\rho^M)}{(q-p)\\rho^k(\\rho^M-1)} \\frac{(\\rho^k-1)/(\\rho^M-1)}{(\\rho^i-1)/(\\rho^M-1)} = \\frac{(\\rho^k-1)^2(\\rho^i-\\rho^M)}{(q-p)\\rho^k(\\rho^M-1)(\\rho^i-1)}$.\n\nA key insight is that for $i \\le k$, the expected number of visits $E_i(k)$ is independent of the starting position $i$. This is because any path starting at $i \\le k$ and conditioned to reach $M$ must first reach state $k$. By the strong Markov property, the expected number of visits to $k$ from that point onward is independent of the history before reaching $k$. Therefore, $E_i(k) = E_k(k)$ for all $i \\le k$. Our derived formulas confirm this.\n\nThese expressions provide the exact analytical values against which the numerical estimators are compared.",
            "answer": "```python\nimport numpy as np\n\n# A helper class for Weighted Ensemble walkers\nclass Walker:\n    \"\"\"A simple class to hold walker data for the WE simulation.\"\"\"\n    def __init__(self, position, weight, visits_k):\n        self.position = position\n        self.weight = weight\n        self.visits_k = visits_k\n\ndef exact_solver(M, p, i, k):\n    \"\"\"\n    Computes the exact conditional expectation E[visits to k | start at i, absorb at M].\n    The derivation is based on relating the conditional expectation to the unconditioned\n    process's Green's function G_ik and committor probabilities h_i, h_k.\n    E_i(k) = (G_ik * h_k) / h_i.\n    \"\"\"\n    if not (1 = i  M and 1 = k  M):\n        raise ValueError(\"i and k must be interior states.\")\n\n    if p == 0.5:\n        if i = k:\n            # For i = k, E_i(k) = E_k(k) = G_kk\n            # G_kk for p=0.5 is 2k(M-k)/M\n            return (2.0 * k * (M - k)) / M\n        else:  # i  k\n            h_i = i / M\n            h_k = k / M\n            G_ik = (2.0 * k * (M - i)) / M\n            if h_i == 0: return np.nan\n            return (G_ik * h_k) / h_i\n    else:\n        rho = (1.0 - p) / p\n        q = 1.0 - p\n        \n        if np.isclose(rho, 1.0): # Fallback for floating point inaccuracy\n             if i = k:\n                return (2.0 * k * (M - k)) / M\n             else:\n                h_i = i / M\n                h_k = k / M\n                G_ik = (2.0 * k * (M - i)) / M\n                if h_i == 0: return np.nan\n                return (G_ik * h_k) / h_i\n\n        rho_M = rho**M\n        rho_k = rho**k\n        \n        if i = k:\n            # For i = k, E_i(k) = E_k(k) = G_kk\n            num = (rho_k - rho_M) * (rho_k - 1.0)\n            den = (q - p) * rho_k * (rho_M - 1.0)\n            if den == 0: return np.nan\n            return num / den\n        else:  # i  k\n            rho_i = rho**i\n            \n            # Denominator of Green's function\n            g_den = (q - p) * rho_k * (rho_M - 1.0)\n            if g_den == 0: return np.nan\n            \n            # Green's function G_ik for i  k\n            g_num = (rho_k - 1.0) * (rho_i - rho_M)\n            G_ik = g_num / g_den\n            \n            # Committor probabilities h_i and h_k\n            h_den = rho_M - 1.0\n            if h_den == 0: return np.nan\n            h_i = (rho_i - 1.0) / h_den\n            h_k = (rho_k - 1.0) / h_den\n            \n            if h_i == 0: return np.nan\n            return (G_ik * h_k) / h_i\n\n\ndef tps_solver(M, p, i, k, N):\n    \"\"\"\n    Computes the conditional expectation using a brute-force TPS-like estimator.\n    It generates N independent trajectories and averages the observable over those that\n    reach the target state M before the source state 0.\n    \"\"\"\n    accepted_visits = []\n    \n    for _ in range(N):\n        pos = i\n        visits = 1 if pos == k else 0\n        # Set a max number of steps to prevent infinite loops in pathological cases\n        for _ in range(100*M*M): \n            if np.random.rand()  p:\n                pos += 1\n            else:\n                pos -= 1\n\n            if pos == 0:\n                # Absorbed at A, reject path\n                break\n            \n            if pos == M:\n                # Absorbed at B, accept path\n                if pos == k: # The absorption state could be k\n                    visits += 1\n                accepted_visits.append(visits)\n                break\n            \n            if pos == k:\n                visits += 1\n        else:\n            # Trajectory did not terminate, can be ignored or handled. We ignore.\n            pass\n\n\n    if not accepted_visits:\n        return 0.0\n    \n    return np.mean(accepted_visits)\n\ndef we_solver(M, p, i, k, T, K):\n    \"\"\"\n    Computes the conditional expectation using a Weighted Ensemble (WE) estimator.\n    Walkers are propagated with unbiased dynamics. After each step, walkers in each\n    bin are resampled to a fixed number K, conserving total weight.\n    \"\"\"\n    # Bins for interior states {1, ..., M-1}\n    bins = [[] for _ in range(M + 1)]\n\n    # Initial state: K walkers at state i, each with weight 1/K\n    initial_visits = 1 if i == k else 0\n    for _ in range(K):\n        bins[i].append(Walker(i, 1.0 / K, initial_visits))\n    \n    total_weight_in_bins = 1.0\n    \n    # Accumulators for the final calculation\n    total_f_weight_in_B = 0.0\n    total_weight_in_B = 0.0\n\n    for _ in range(T):\n        if total_weight_in_bins  1e-9:\n            break\n\n        # List to hold walkers after one step of propagation\n        next_bins = [[] for _ in range(M + 1)]\n        \n        # --- Propagation Step ---\n        for j in range(1, M):\n            for walker in bins[j]:\n                new_pos = walker.position + 1 if np.random.rand()  p else walker.position - 1\n                new_visits = walker.visits_k + 1 if new_pos == k else walker.visits_k\n\n                if new_pos == 0:\n                    # Absorbed at A, weight flux is lost\n                    continue\n                elif new_pos == M:\n                    # Absorbed at B, accumulate weight and observable*weight\n                    total_weight_in_B += walker.weight\n                    total_f_weight_in_B += walker.weight * new_visits\n                else:\n                    # Moved to another interior bin\n                    new_walker = Walker(new_pos, walker.weight, new_visits)\n                    next_bins[new_pos].append(new_walker)\n        \n        bins = next_bins\n\n        # --- Resampling (Splitting/Merging) Step ---\n        total_weight_in_bins = 0.0\n        for j in range(1, M):\n            n_walkers = len(bins[j])\n            if n_walkers == 0:\n                continue\n\n            bin_total_weight = sum(w.weight for w in bins[j])\n            \n            if n_walkers != K:\n                walker_weights = [w.weight for w in bins[j]]\n                \n                if bin_total_weight  0:\n                    probs = [w / bin_total_weight for w in walker_weights]\n                else:\n                    probs = None # Uniform sampling if total weight is zero\n\n                chosen_indices = np.random.choice(n_walkers, size=K, p=probs, replace=True)\n                \n                new_walkers_in_bin = []\n                # New walkers have their attributes copied from parents, but weight is redistributed\n                new_weight = bin_total_weight / K\n                for index in chosen_indices:\n                    parent = bins[j][index]\n                    child = Walker(parent.position, new_weight, parent.visits_k)\n                    new_walkers_in_bin.append(child)\n                bins[j] = new_walkers_in_bin\n\n            total_weight_in_bins += sum(w.weight for w in bins[j])\n\n    if total_weight_in_B == 0:\n        return 0.0\n        \n    return total_f_weight_in_B / total_weight_in_B\n\ndef solve():\n    test_cases = [\n        # (M, p, i, k, T, K, N)\n        (12, 0.55, 3, 6, 3000, 40, 30000),\n        (12, 0.50, 4, 9, 4000, 60, 40000),\n        (18, 0.52, 1, 9, 5000, 60, 50000),\n    ]\n\n    results = []\n    tolerance = 0.03\n\n    for case in test_cases:\n        M, p, i, k, T, K, N = case\n        \n        exact_val = exact_solver(M, p, i, k)\n        tps_val = tps_solver(M, p, i, k, N)\n        we_val = we_solver(M, p, i, k, T, K)\n\n        is_equivalent = (\n            abs(tps_val - we_val)  tolerance and\n            abs(tps_val - exact_val)  tolerance and\n            abs(we_val - exact_val)  tolerance\n        )\n        results.append(is_equivalent)\n\n    # Format output as a Python list of booleans\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Advanced path sampling methods like Forward Flux Sampling (FFS) and Milestoning rely on a reaction coordinate to define progress from reactants to products, with the ideal choice being the committor probability $q(x)$. However, the committor is rarely known in advance and must be estimated from finite simulation data, introducing statistical noise. This exercise delves into a subtle but critical consequence of this reality: the systematic bias that arises in kinetic calculations when interfaces are defined using an estimated committor . By analyzing how sampling error in $q(x)$ translates into a biased rate constant, you will develop a sophisticated understanding of the sources of error in path sampling and the importance of statistical rigor in complex simulations.",
            "id": "3434732",
            "problem": "Consider a molecular system undergoing overdamped reversible dynamics confined to a one-dimensional reaction coordinate $x \\in [0,1]$ at thermal equilibrium. Let $A$ be the metastable set at $x=0$ and $B$ the metastable set at $x=1$. The fundamental path sampling object is the committor function $q(x)$, defined as the probability that a trajectory starting at $x$ reaches $B$ before $A$. In this one-dimensional reversible setting with a monotonic reaction coordinate and appropriate boundary conditions, the exact committor is $q(x) \\in [0,1]$ and is strictly increasing in $x$.\n\nOptimal milestones for Milestoning and related path sampling methods are the level sets (iso-committors) $\\lambda_i = \\{ x \\mid q(x) = c_i \\}$ with $0 = c_0  c_1  \\cdots  c_M = 1$. For Forward Flux Sampling (FFS), the exact rate constant from $A$ to $B$ can be expressed as $k_{AB} = \\Phi_A^0 \\, P(B \\mid \\text{first crossing of } \\lambda_1)$, where $\\Phi_A^0$ is the steady flux of trajectories from $A$ into the region beyond $\\lambda_1$ per unit time, and $P(B \\mid \\text{first crossing of } \\lambda_1)$ is the probability that those trajectories subsequently reach $B$ before returning to $A$. Under ideal iso-committor milestones and a Markovian entrance distribution consistent with equilibrium, this conditional probability equals the committor value at the milestone, so $P(B \\mid \\text{first crossing of } \\lambda_1) = c_1$, yielding $k_{AB} = \\Phi_A^0 c_1$.\n\nIn practice, the committor $q(x)$ is estimated from finite samples by initializing $N$ independent short trajectories at $x$ and recording whether each reaches $B$ before $A$. The estimator $\\hat{q}(x)$ is the sample mean of these Bernoulli outcomes, so it is unbiased with conditional variance $\\mathrm{Var}[\\hat{q}(x) \\mid x] = q(x)(1 - q(x))/N$. When milestones are defined using the estimated committor, i.e., $\\hat{\\lambda}_i = \\{ x \\mid \\hat{q}(x) = c_i \\}$, the selection of states satisfying $\\hat{q}(x) = c_i$ induces a systematic bias in the true committor of selected states due to the heteroscedastic sampling noise. As a result, the FFS estimate $\\hat{k}_{AB} = \\Phi_A^0 \\, \\mathbb{E}[q(x) \\mid \\hat{q}(x) = c_1]$ is biased relative to $k_{AB}$.\n\nStarting from the definition of the committor and the sampling model described above, derive from first principles an approximation for the bias $\\mathbb{E}[\\hat{k}_{AB}] - k_{AB}$ in terms of the variance function $\\mathrm{Var}[\\hat{q}(x) \\mid x]$. Specifically, show that under a locally uniform prior for $q(x)$ over $[0,1]$ and a Gaussian approximation to the Binomial sampling noise, the leading-order bias in the true committor conditioned on an observed level $\\hat{q} = c$ satisfies\n$$\n\\mathbb{E}[q \\mid \\hat{q} = c] - c \\approx -\\tfrac{1}{2} \\, \\frac{d}{dq} \\mathrm{Var}[\\hat{q} \\mid q]\\bigg|_{q=c},\n$$\nand therefore the rate bias satisfies\n$$\n\\mathbb{E}[\\hat{k}_{AB}] - k_{AB} \\approx -\\tfrac{1}{2} \\, \\Phi_A^0 \\, \\frac{d}{dq} \\mathrm{Var}[\\hat{q} \\mid q]\\bigg|_{q=c_1}.\n$$\nUse $\\Phi_A^0 = 1$ in units of $\\mathrm{s}^{-1}$ for numerical evaluation, so the bias is expressed in $\\mathrm{s}^{-1}$.\n\nTo make the problem fully quantitative and testable, adopt the Gaussian likelihood approximation for the estimator $\\hat{q}$ given the true $q$,\n$$\n\\hat{q} \\mid q \\sim \\mathcal{N}\\!\\left(q, \\, v(q)\\right), \\quad v(q) = \\frac{q(1-q)}{N},\n$$\nand assume a locally uniform prior density for $q$ over $[0,1]$. Then the exact conditional expectation under this approximation can be written as\n$$\n\\mathbb{E}[q \\mid \\hat{q} = c] = \\frac{\\int_0^1 q \\, \\frac{1}{\\sqrt{2\\pi v(q)}} \\exp\\!\\left(-\\frac{(c - q)^2}{2 v(q)}\\right) \\, dq}{\\int_0^1 \\frac{1}{\\sqrt{2\\pi v(q)}} \\exp\\!\\left(-\\frac{(c - q)^2}{2 v(q)}\\right) \\, dq},\n$$\nfrom which the exact bias $\\mathbb{E}[q \\mid \\hat{q} = c] - c$ can be computed numerically by quadrature and then multiplied by $\\Phi_A^0 = 1\\,\\mathrm{s}^{-1}$ to obtain the bias in the rate constant.\n\nYour task is to implement a program that, for each test case $(c, N)$, computes the exact Gaussian-approximation bias in the estimated rate $\\hat{k}_{AB}$ using the integral representation above. Express each result in $\\mathrm{s}^{-1}$ as a float.\n\nTest Suite:\n- Case 1: $c = 0.20$, $N = 25$.\n- Case 2: $c = 0.50$, $N = 25$.\n- Case 3: $c = 0.80$, $N = 25$.\n- Case 4: $c = 0.10$, $N = 10$.\n- Case 5: $c = 0.90$, $N = 10$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3]\"), in the order of the test cases above. Each value must be the computed bias in $\\mathrm{s}^{-1}$ for the corresponding case, with no additional text.",
            "solution": "The problem is assessed as valid. It is scientifically grounded in the principles of statistical mechanics and path sampling theory, specifically addressing a known source of systematic bias in methods like Forward Flux Sampling (FFS). The problem is well-posed, providing a clear theoretical derivation task followed by a quantitative calculation with all necessary formulas, parameters, and a Gaussian noise model. The language is objective and precise. The setup is self-contained and free from contradictions, making it a suitable and solvable problem in computational physics.\n\nThe solution proceeds in two parts. First, the requested analytical derivation for the leading-order bias is presented. Second, the numerical implementation for calculating the exact bias under the specified Gaussian approximation is described, which forms the basis for the final code.\n\n### Derivation of the Approximate Bias\n\nWe are asked to derive an approximation for the bias $\\mathbb{E}[q \\mid \\hat{q} = c] - c$. This quantity represents the systematic shift in the expected true committor value, $q$, when we select states based on their estimated committor value, $\\hat{q}$, being equal to a specific constant $c$.\n\nWe begin with Bayes' theorem for the posterior probability density of the true committor $q$, given the observed estimate $\\hat{q} = c$:\n$$\np(q \\mid \\hat{q}=c) = \\frac{p(\\hat{q}=c \\mid q) \\, p(q)}{\\int_0^1 p(\\hat{q}=c \\mid q') \\, p(q') \\, dq'}\n$$\nThe problem specifies a locally uniform prior for $q$, so we can treat $p(q)$ as a constant over the region where the likelihood $p(\\hat{q}=c \\mid q)$ is non-negligible. The likelihood is given by a Gaussian approximation:\n$$\np(\\hat{q}=c \\mid q) \\sim \\mathcal{N}(c; q, v(q)) = \\frac{1}{\\sqrt{2\\pi v(q)}} \\exp\\left(-\\frac{(c - q)^2}{2v(q)}\\right)\n$$\nwhere $v(q) = \\mathrm{Var}[\\hat{q} \\mid q] = \\frac{q(1-q)}{N}$.\n\nThe posterior is therefore proportional to the likelihood:\n$$\np(q \\mid \\hat{q}=c) \\propto \\frac{1}{\\sqrt{v(q)}} \\exp\\left(-\\frac{(c - q)^2}{2v(q)}\\right)\n$$\nThe expected value of $q$ given $\\hat{q}=c$ is $\\mathbb{E}[q \\mid \\hat{q}=c] = \\int_0^1 q \\, p(q \\mid \\hat{q}=c) \\, dq$. For large sample sizes $N$, the variance $v(q)$ is small, and the posterior distribution becomes sharply peaked. In this limit, the mean of the posterior can be approximated by its mode, $q^*$. The mode is found by maximizing the log-posterior, $L(q) = \\log p(q \\mid \\hat{q}=c)$.\n$$\nL(q) = -\\frac{(c - q)^2}{2v(q)} - \\frac{1}{2}\\log v(q) + \\text{constant}\n$$\nTo find the maximum, we set the derivative with respect to $q$ to zero:\n$$\n\\frac{dL}{dq} = -\\frac{-2(c-q)v(q) - (c-q)^2 v'(q)}{2v(q)^2} - \\frac{v'(q)}{2v(q)} = 0\n$$\nwhere $v'(q) = \\frac{dv}{dq}$. Simplifying this expression gives:\n$$\n\\frac{c-q}{v(q)} + \\frac{(c-q)^2 v'(q)}{2v(q)^2} - \\frac{v'(q)}{2v(q)} = 0\n$$\nMultiplying by $2v(q)^2$ yields:\n$$\n2(c-q)v(q) + (c-q)^2 v'(q) - v'(q)v(q) = 0\n$$\nWe seek the solution $q=q^*$. As $N \\rightarrow \\infty$, $v(q) \\rightarrow 0$, and the posterior becomes concentrated around $q=c$. We can thus expect $q^*$ to be close to $c$. Let's rearrange the equation to solve for $(c-q^*)$:\n$$\n(c-q^*) = \\frac{v(q^*)v'(q^*)}{2v(q^*) + (c-q^*)v'(q^*)}\n$$\nFor large $N$, $(c-q^*)$ is small. We can approximate the expression by neglecting terms of second order or higher in $(c-q^*)$. The denominator can be approximated as $2v(q^*)$.\n$$\nc-q^* \\approx \\frac{v(q^*)v'(q^*)}{2v(q^*)} = \\frac{1}{2}v'(q^*)\n$$\nSince $q^* \\approx c$, we can further approximate $v'(q^*)$ with $v'(c)$.\n$$\nc-q^* \\approx \\frac{1}{2}v'(c) \\implies q^* \\approx c - \\frac{1}{2}v'(c)\n$$\nThe bias is $\\mathbb{E}[q \\mid \\hat{q}=c] - c \\approx q^* - c$. Substituting our approximation for $q^*$:\n$$\n\\mathbb{E}[q \\mid \\hat{q}=c] - c \\approx \\left(c - \\frac{1}{2}v'(c)\\right) - c = -\\frac{1}{2}v'(c)\n$$\nThis is the desired result:\n$$\n\\mathbb{E}[q \\mid \\hat{q} = c] - c \\approx -\\frac{1}{2} \\, \\frac{d}{dq} \\mathrm{Var}[\\hat{q} \\mid q]\\bigg|_{q=c}\n$$\nThe bias in the rate constant, $\\mathbb{E}[\\hat{k}_{AB}] - k_{AB}$, follows directly. Given $k_{AB} = \\Phi_A^0 c_1$ and the definition of the estimated rate as what the problem statement denotes $\\hat{k}_{AB} = \\Phi_A^0 \\, \\mathbb{E}[q(x) \\mid \\hat{q}(x) = c_1]$, the bias is:\n$$\n\\mathbb{E}[\\hat{k}_{AB}] - k_{AB} = \\Phi_A^0 \\left( \\mathbb{E}[q \\mid \\hat{q} = c_1] - c_1 \\right) \\approx -\\frac{1}{2} \\Phi_A^0 \\, \\frac{d}{dq} \\mathrm{Var}[\\hat{q} \\mid q]\\bigg|_{q=c_1}\n$$\n\n### Numerical Calculation of the Exact Bias\n\nThe second part of the task is to compute the bias numerically using the exact integral representation provided, which is derived from the same Bayesian framework without the Laplace approximation. The bias is given by $\\mathbb{E}[q \\mid \\hat{q} = c] - c$, where:\n$$\n\\mathbb{E}[q \\mid \\hat{q} = c] = \\frac{\\int_0^1 q \\, p(\\hat{q}=c \\mid q) \\, dq}{\\int_0^1 p(\\hat{q}=c \\mid q) \\, dq}\n$$\nThe integrands for the numerator and denominator are, respectively:\n$$\nI_\\text{num}(q; c, N) = q \\, \\frac{1}{\\sqrt{2\\pi v(q)}} \\exp\\left(-\\frac{(c - q)^2}{2v(q)}\\right)\n$$\n$$\nI_\\text{den}(q; c, N) = \\frac{1}{\\sqrt{2\\pi v(q)}} \\exp\\left(-\\frac{(c - q)^2}{2v(q)}\\right)\n$$\nwith $v(q) = q(1-q)/N$. The final rate bias is this quantity multiplied by $\\Phi_A^0 = 1 \\, \\mathrm{s}^{-1}$.\n\nThe numerical implementation will use the `scipy.integrate.quad` function to perform the required numerical integrations over the domain $q \\in [0, 1]$. Special care must be taken at the endpoints $q=0$ and $q=1$, where $v(q)=0$. For any $c \\in (0, 1)$, as $q$ approaches $0$ or $1$, the term $(c-q)^2$ remains positive while $v(q)$ goes to zero, causing the argument of the exponential, $-(c-q)^2 / (2v(q))$, to approach $-\\infty$. Consequently, the integrands correctly evaluate to $0$ at the boundaries. Our implementation will handle this to avoid division-by-zero errors.\n\nThe calculation will be performed for each $(c, N)$ pair in the test suite. Based on a symmetry analysis of the integrals, we can predict that the bias for a given $c$ is the negative of the bias for $1-c$ (i.e., $B(c, N) = -B(1-c, N)$), and the bias at $c=0.5$ is exactly zero. These properties provide a robust check on the correctness of the numerical implementation.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import quad\nfrom scipy.constants import pi\n\ndef solve():\n    \"\"\"\n    Computes the systematic bias in FFS rate estimates due to noisy\n    committor values for a set of test cases.\n    \"\"\"\n\n    def calculate_bias(c, N):\n        \"\"\"\n        Calculates the exact bias under the Gaussian likelihood approximation\n        using numerical quadrature.\n\n        The bias is defined as E[q | q_hat = c] - c.\n        The rate bias is then Phi_A^0 * (E[q | q_hat = c] - c), where Phi_A^0 = 1.\n\n        Args:\n            c (float): The target committor value for the milestone.\n            N (int): The number of trajectories used to estimate the committor.\n\n        Returns:\n            float: The computed bias in the rate constant.\n        \"\"\"\n        # The case c=0.5 can be solved by symmetry. The posterior distribution\n        # p(q|q_hat=0.5) is symmetric around q=0.5, so its mean is 0.5.\n        # Thus, the bias is exactly 0.\n        if c == 0.5:\n            return 0.0\n\n        def likelihood(q, c_val, N_val):\n            \"\"\"\n            Computes the Gaussian likelihood p(q_hat=c | q).\n            \"\"\"\n            # The variance v(q) = q(1-q)/N goes to 0 at q=0 and q=1.\n            # For c in (0,1), the exponent -(c-q)^2/(2v(q)) goes to -inf,\n            # so the likelihood is 0. This check prevents division by zero.\n            if q = 0.0 or q = 1.0:\n                return 0.0\n            \n            var = q * (1.0 - q) / N_val\n            \n            # This second check is for numerical stability, though the first\n            # one should handle it.\n            if var = 0.0:\n                return 0.0\n\n            prefactor = 1.0 / np.sqrt(2.0 * pi * var)\n            exponent = -((c_val - q)**2) / (2.0 * var)\n            \n            return prefactor * np.exp(exponent)\n\n        def numerator_integrand(q, c_val, N_val):\n            \"\"\"Integrand for the numerator of the expectation E[q].\"\"\"\n            return q * likelihood(q, c_val, N_val)\n\n        def denominator_integrand(q, c_val, N_val):\n            \"\"\"Integrand for the denominator (normalization constant).\"\"\"\n            return likelihood(q, c_val, N_val)\n\n        # Use scipy.integrate.quad for numerical integration.\n        # The 'args' tuple passes the additional parameters c and N to the integrands.\n        num, num_err = quad(numerator_integrand, 0, 1, args=(c, N))\n        den, den_err = quad(denominator_integrand, 0, 1, args=(c, N))\n\n        # The denominator should be non-zero for any valid c in (0,1) and N0.\n        if den == 0.0:\n            return np.nan # Should not be reached with the given test cases.\n\n        expected_q = num / den\n        committor_bias = expected_q - c\n\n        # Given Phi_A^0 = 1 s^-1, the rate bias is numerically equal to the committor bias.\n        rate_bias = committor_bias\n        \n        return rate_bias\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0.20, 25),  # Case 1\n        (0.50, 25),  # Case 2\n        (0.80, 25),  # Case 3\n        (0.10, 10),  # Case 4\n        (0.90, 10),  # Case 5\n    ]\n\n    results = []\n    for c_val, N_val in test_cases:\n        result = calculate_bias(c_val, N_val)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}