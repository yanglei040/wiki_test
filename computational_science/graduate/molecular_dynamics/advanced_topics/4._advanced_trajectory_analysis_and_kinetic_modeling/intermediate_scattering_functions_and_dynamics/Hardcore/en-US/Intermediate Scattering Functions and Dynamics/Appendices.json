{
    "hands_on_practices": [
        {
            "introduction": "Our exploration of hands-on practices begins with the foundational case of an ideal gas. This first exercise  guides you through deriving the Self Intermediate Scattering Function (SISF) from first principles, connecting Newtonian kinematics and Maxwell-Boltzmann statistics to an exact analytical solution. By establishing this benchmark, you will gain a concrete understanding of how microscopic particle motion directly shapes the functional form of the SISF.",
            "id": "3418495",
            "problem": "Consider a three-dimensional ideal gas of identical point particles of mass $m$ at thermal equilibrium at absolute temperature $T$. The particle dynamics are governed by Newton's laws with no interparticle forces. The Self Intermediate Scattering Function (SISF), denoted $F_s(\\mathbf{k},t)$, is defined from first principles as the ensemble average over particles and time origins of the complex phase generated by the displacement, namely\n$$\nF_s(\\mathbf{k},t) = \\left\\langle \\exp\\left(i\\,\\mathbf{k}\\cdot\\left[\\mathbf{r}(t+\\tau)-\\mathbf{r}(\\tau)\\right]\\right)\\right\\rangle_{\\text{particles},\\,\\tau}.\n$$\nFor an isotropic system, physical observables depend only on the magnitude $k=\\lVert\\mathbf{k}\\rVert$. The isotropic average over the wavevector shell of radius $k$ (the $k$-shell) is the average of $F_s(\\mathbf{k},t)$ over all directions $\\hat{\\mathbf{k}}=\\mathbf{k}/k$ on the unit sphere at fixed $k$, which yields an isotropically averaged SISF denoted $\\overline{F_s}(k,t)$.\n\nUsing only the fundamental laws and core definitions provided above, and well-tested facts about equilibrium velocity statistics, write a program that computes the isotropically averaged SISF $\\overline{F_s}(k,t)$ for the three-dimensional ideal gas described. The computation must start from the definition of $F_s(\\mathbf{k},t)$ and correctly implement the isotropic average over the $k$-shell. The gas is in thermal equilibrium, so the particle velocities are distributed according to the Maxwell–Boltzmann distribution consistent with the specified $m$ and $T$.\n\nUnits and numerical requirements:\n- Use the International System of Units (SI) throughout. Mass $m$ in kilograms (kg), temperature $T$ in kelvin (K), time $t$ in seconds (s), and wavevector magnitude $k$ in inverse meters ($\\text{m}^{-1}$).\n- The Boltzmann constant $k_B$ must be taken as $k_B = 1.380649\\times 10^{-23}\\,\\text{J/K}$.\n- The SISF $\\overline{F_s}(k,t)$ is dimensionless. Your program must output values rounded to six decimal places.\n\nTest suite:\nCompute $\\overline{F_s}(k,t)$ for the following four parameter sets:\n1. $m = 39.948\\,\\text{atomic mass units}$ converted to kilograms, $T=300\\,\\text{K}$, $t=1.0\\times 10^{-12}\\,\\text{s}$, $k=5.0\\times 10^{9}\\,\\text{m}^{-1}$.\n2. $m = 39.948\\,\\text{atomic mass units}$ converted to kilograms, $T=300\\,\\text{K}$, $t=1.0\\times 10^{-12}\\,\\text{s}$, $k=0.0\\,\\text{m}^{-1}$.\n3. $m = 39.948\\,\\text{atomic mass units}$ converted to kilograms, $T=300\\,\\text{K}$, $t=0.0\\,\\text{s}$, $k=5.0\\times 10^{9}\\,\\text{m}^{-1}$.\n4. $m = 39.948\\,\\text{atomic mass units}$ converted to kilograms, $T=300\\,\\text{K}$, $t=1.0\\times 10^{-9}\\,\\text{s}$, $k=1.0\\times 10^{10}\\,\\text{m}^{-1}$.\n\nAtomic mass unit must be converted using $1\\,\\text{atomic mass unit} = 1.66053906660\\times 10^{-27}\\,\\text{kg}$.\n\nDesign for coverage:\n- Case 1 is a general nontrivial scenario in the picosecond and sub–Ångström regime typical for scattering experiments.\n- Case 2 is a $k=0$ boundary, which probes normalization and isotropic averaging at zero wavevector.\n- Case 3 is a $t=0$ boundary, which probes normalization at zero time.\n- Case 4 is a large-time and large-wavevector limit, which probes strong dephasing behavior.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list of four floats enclosed in square brackets, each rounded to six decimal places in the exact order of the test suite above. For example, an output line must look like\n$$\n[\\text{value}_1,\\text{value}_2,\\text{value}_3,\\text{value}_4].\n$$",
            "solution": "The user has requested the derivation and computation of the isotropically averaged Self Intermediate Scattering Function (SISF), denoted $\\overline{F_s}(k,t)$, for a three-dimensional ideal gas. The problem is scientifically valid, well-posed, and contains all necessary information for a unique solution. We proceed by deriving the expression for $\\overline{F_s}(k,t)$ from first principles as stipulated.\n\nThe SISF, $F_s(\\mathbf{k},t)$, is defined as the ensemble average:\n$$\nF_s(\\mathbf{k},t) = \\left\\langle \\exp\\left(i\\,\\mathbf{k}\\cdot\\left[\\mathbf{r}(t+\\tau)-\\mathbf{r}(\\tau)\\right]\\right)\\right\\rangle_{\\text{particles},\\,\\tau}\n$$\nwhere $\\mathbf{r}(t)$ is the position of a particle at time $t$, $\\mathbf{k}$ is the wavevector, and the average is taken over all particles and time origins $\\tau$.\n\nFor an ideal gas, there are no interparticle forces. According to Newton's first law, each particle moves with a constant velocity $\\mathbf{v}$. The trajectory of a particle is given by $\\mathbf{r}(t) = \\mathbf{r}(0) + \\mathbf{v}t$. The displacement of a particle over a time interval $t$ is therefore:\n$$\n\\Delta\\mathbf{r}(t) = \\mathbf{r}(t+\\tau) - \\mathbf{r}(\\tau) = \\left(\\mathbf{r}(\\tau) + \\mathbf{v}t\\right) - \\mathbf{r}(\\tau) = \\mathbf{v}t\n$$\nThis displacement is independent of the initial position $\\mathbf{r}(\\tau)$ and the time origin $\\tau$. Substituting this into the definition of $F_s(\\mathbf{k},t)$, the average over $\\tau$ becomes trivial, and the expression simplifies to:\n$$\nF_s(\\mathbf{k},t) = \\left\\langle \\exp\\left(i\\,\\mathbf{k}\\cdot(\\mathbf{v}t)\\right)\\right\\rangle_{\\text{particles}}\n$$\nFor a system in thermal equilibrium, the ensemble average over particles is equivalent to an average over the velocity distribution of the particles. Let $P(\\mathbf{v})$ be the velocity probability distribution function. The SISF is then given by the integral:\n$$\nF_s(\\mathbf{k},t) = \\int \\exp\\left(i\\,t\\,\\mathbf{k}\\cdot\\mathbf{v}\\right) P(\\mathbf{v}) \\, d^3\\mathbf{v}\n$$\nThe system is an ideal gas at absolute temperature $T$. The particle velocities follow the three-dimensional Maxwell–Boltzmann distribution:\n$$\nP(\\mathbf{v}) = \\left(\\frac{m}{2\\pi k_B T}\\right)^{3/2} \\exp\\left(-\\frac{m |\\mathbf{v}|^2}{2 k_B T}\\right)\n$$\nwhere $m$ is the particle mass and $k_B$ is the Boltzmann constant. $P(\\mathbf{v})$ is a product of three independent Gaussian distributions for each velocity component, $v_x$, $v_y$, and $v_z$:\n$$\nP(\\mathbf{v}) = P_1(v_x) P_1(v_y) P_1(v_z) \\quad \\text{with} \\quad P_1(v_j) = \\left(\\frac{m}{2\\pi k_B T}\\right)^{1/2} \\exp\\left(-\\frac{m v_j^2}{2 k_B T}\\right)\n$$\nThe dot product in the exponential is $\\mathbf{k}\\cdot\\mathbf{v} = k_x v_x + k_y v_y + k_z v_z$. The integral for $F_s(\\mathbf{k},t)$ separates into a product of three one-dimensional integrals:\n$$\nF_s(\\mathbf{k},t) = \\left(\\int_{-\\infty}^{\\infty} e^{i t k_x v_x} P_1(v_x) dv_x\\right) \\left(\\int_{-\\infty}^{\\infty} e^{i t k_y v_y} P_1(v_y) dv_y\\right) \\left(\\int_{-\\infty}^{\\infty} e^{i t k_z v_z} P_1(v_z) dv_z\\right)\n$$\nEach integral is the Fourier transform of a Gaussian function. Let's evaluate one such integral for a generic component $j \\in \\{x, y, z\\}$:\n$$\nI_j = \\int_{-\\infty}^{\\infty} \\exp(i t k_j v_j) \\left(\\frac{m}{2\\pi k_B T}\\right)^{1/2} \\exp\\left(-\\frac{m v_j^2}{2 k_B T}\\right) dv_j\n$$\nThis is a standard Gaussian integral of the form $\\int_{-\\infty}^{\\infty} e^{-ax^2+bx} dx = \\sqrt{\\pi/a} e^{b^2/(4a)}$. Here, $a = \\frac{m}{2k_B T}$ and $b = i t k_j$. The integral evaluates to:\n$$\nI_j = \\left(\\frac{m}{2\\pi k_B T}\\right)^{1/2} \\sqrt{\\frac{2\\pi k_B T}{m}} \\exp\\left(\\frac{(i t k_j)^2}{4(m / (2 k_B T))}\\right) = \\exp\\left(-\\frac{t^2 k_j^2 k_B T}{2m}\\right)\n$$\nMultiplying the results for the three components ($j=x,y,z$):\n$$\nF_s(\\mathbf{k},t) = \\exp\\left(-\\frac{t^2 k_x^2 k_B T}{2m}\\right) \\exp\\left(-\\frac{t^2 k_y^2 k_B T}{2m}\\right) \\exp\\left(-\\frac{t^2 k_z^2 k_B T}{2m}\\right)\n$$\n$$\nF_s(\\mathbf{k},t) = \\exp\\left(-\\frac{(k_x^2+k_y^2+k_z^2) k_B T}{2m} t^2\\right) = \\exp\\left(-\\frac{k^2 k_B T}{2m} t^2\\right)\n$$\nwhere $k = \\lVert\\mathbf{k}\\rVert = \\sqrt{k_x^2+k_y^2+k_z^2}$. This result shows that for an ideal gas, $F_s(\\mathbf{k},t)$ depends only on the magnitude $k$ of the wavevector, not its direction. The function is inherently isotropic.\n\nThe isotropically averaged SISF, $\\overline{F_s}(k,t)$, is defined as the average of $F_s(\\mathbf{k},t)$ over all directions of $\\mathbf{k}$ for a fixed magnitude $k$. Since $F_s(\\mathbf{k},t)$ does not depend on the direction of $\\mathbf{k}$, averaging it over all directions does not change its value.\n$$\n\\overline{F_s}(k,t) = \\frac{1}{4\\pi} \\int_{\\text{unit sphere}} F_s(\\mathbf{k},t) \\, d\\Omega = \\frac{1}{4\\pi} \\int_{\\text{unit sphere}} \\exp\\left(-\\frac{k^2 k_B T}{2m} t^2\\right) \\, d\\Omega\n$$\nThe integrand is constant over the sphere of integration, so it can be factored out:\n$$\n\\overline{F_s}(k,t) = \\exp\\left(-\\frac{k^2 k_B T}{2m} t^2\\right) \\left(\\frac{1}{4\\pi} \\int d\\Omega\\right) = \\exp\\left(-\\frac{k^2 k_B T}{2m} t^2\\right) \\left(\\frac{4\\pi}{4\\pi}\\right)\n$$\nThus, the final expression for the isotropically averaged SISF for a three-dimensional ideal gas is:\n$$\n\\overline{F_s}(k,t) = \\exp\\left(-\\frac{k^2 t^2 k_B T}{2m}\\right)\n$$\nThis is a Gaussian decay in both $k$ and $t$. This formula will be implemented to compute the values for the specified test cases. The parameters $m$, $T$, $k$, $t$ and the constant $k_B$ are given. The mass $m$ is provided in atomic mass units (u) and must be converted to kilograms (kg) using the given conversion factor.\n\nThe analytical expression handles the boundary cases naturally. For $t=0$, the argument of the exponential is $0$, so $\\overline{F_s}(k,0) = e^0 = 1$, which is the correct normalization condition reflecting zero displacement at zero time. For $k=0$, the argument is also $0$, so $\\overline{F_s}(0,t) = 1$, which corresponds to probing infinitely large length scales where finite particle displacements have no effect. In the limit of large $k$ or $t$, the function decays to $0$, representing complete dephasing.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Validates the problem, derives the formula for the isotropically averaged\n    Self Intermediate Scattering Function (SISF) for an ideal gas, and\n    computes it for a given set of test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (mass in u, temperature in K, time in s, wavevector magnitude in m^-1)\n    test_cases = [\n        (39.948, 300.0, 1.0e-12, 5.0e9),\n        (39.948, 300.0, 1.0e-12, 0.0),\n        (39.948, 300.0, 0.0, 5.0e9),\n        (39.948, 300.0, 1.0e-9, 1.0e10),\n    ]\n\n    results = []\n    for case in test_cases:\n        m_u, T, t, k = case\n        result = compute_sisf(m_u, T, t, k)\n        results.append(result)\n\n    # Format the final output string as a comma-separated list of floats\n    # enclosed in square brackets, with each value rounded to six decimal places.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef compute_sisf(m_u: float, T: float, t: float, k: float) -> float:\n    \"\"\"\n    Computes the isotropically averaged Self Intermediate Scattering Function\n    for a 3D ideal gas.\n\n    The formula is: F_s(k, t) = exp(-(k^2 * t^2 * k_B * T) / (2 * m))\n\n    Args:\n        m_u (float): Mass of the particle in atomic mass units (u).\n        T (float): Absolute temperature in Kelvin (K).\n        t (float): Time in seconds (s).\n        k (float): Wavevector magnitude in inverse meters (m^-1).\n\n    Returns:\n        float: The dimensionless value of the SISF.\n    \"\"\"\n    # Physical constants in SI units\n    k_B = 1.380649e-23  # Boltzmann constant in J/K\n    amu_to_kg = 1.66053906660e-27  # Conversion factor from u to kg\n\n    # Convert mass from atomic mass units to kilograms\n    m_kg = m_u * amu_to_kg\n\n    # The formula is well-behaved for t=0 or k=0, both leading to an exponent of 0.\n    # Explicitly checking for these boundary conditions is good practice but not\n    # strictly necessary for the correctness of this specific formula.\n    if t == 0.0 or k == 0.0:\n        return 1.0\n\n    # Calculate the argument of the exponential function.\n    # The expression is rearranged for numerical stability, although for the given\n    # parameters, a direct calculation would also be safe.\n    exponent = - (k**2 * t**2 * k_B * T) / (2.0 * m_kg)\n\n    # The exponential of a very large negative number will correctly underflow to 0.0\n    sisf_value = np.exp(exponent)\n    \n    return sisf_value\n\n# Execute the main function\nsolve()\n\n```"
        },
        {
            "introduction": "Having established an analytical benchmark, we now turn to the practical challenge of computing the intermediate scattering function from raw simulation data. This exercise  introduces a cornerstone of dynamics analysis: the use of the Fast Fourier Transform (FFT) to efficiently calculate time correlation functions via the Wiener-Khinchin theorem. You will generate a synthetic trajectory and implement this powerful algorithm, bridging the gap between particle positions and the coherent ISF.",
            "id": "3418516",
            "problem": "You are tasked with designing and implementing an efficient algorithm to compute the coherent intermediate scattering function from a discrete Molecular Dynamics (MD) trajectory, using the Fast Fourier Transform (FFT). The coherent intermediate scattering function quantifies the time correlation of density fluctuations at a specified wavevector, and is a central quantity for connecting microscopic dynamics to scattering observables.\n\nBegin from the following fundamental base:\n\n- The microscopic number density is defined by $$\\rho(\\mathbf{r},t) = \\sum_{j=1}^{N} \\delta\\!\\left(\\mathbf{r} - \\mathbf{r}_j(t)\\right),$$ where $N$ is the number of particles, and $\\mathbf{r}_j(t)$ is the position of particle $j$ at time $t$.\n\n- The density mode at wavevector $\\mathbf{k}$ is defined by $$\\rho_{\\mathbf{k}}(t) = \\sum_{j=1}^{N} \\exp\\!\\left(i \\mathbf{k}\\cdot\\mathbf{r}_j(t)\\right).$$\n\n- The coherent intermediate scattering function is defined by $$F(\\mathbf{k},t) = \\frac{1}{N} \\left\\langle \\rho_{\\mathbf{k}}(t_0+t)\\,\\rho_{\\mathbf{k}}(t_0)^{\\ast} \\right\\rangle_{t_0},$$ where $\\langle\\cdot\\rangle_{t_0}$ denotes an average over time origins $t_0$, and ${}^{\\ast}$ denotes complex conjugation. For a stationary process, this is a time-autocorrelation function of the complex time series $\\rho_{\\mathbf{k}}(t)$.\n\n- For an ideal gas undergoing independent Brownian motion, each particle’s displacement component is a Gaussian random variable with zero mean and variance $2 D t$ along each Cartesian axis (where $D$ is the diffusion coefficient in $\\mathrm{m}^2/\\mathrm{s}$). In this case, and for any nonzero wavevector magnitude $k = \\|\\mathbf{k}\\|$, the theoretically expected coherent intermediate scattering function equals the self intermediate scattering function and is $$F(\\mathbf{k},t) = \\exp\\!\\left(-D k^2 t\\right) \\quad \\text{for } k > 0.$$ For the special case $k=0$, one has $$\\rho_{\\mathbf{0}}(t) = N \\quad \\Rightarrow \\quad F(\\mathbf{0},t) = \\frac{1}{N} \\langle N \\cdot N \\rangle = N.$$\n\nYour goals are:\n\n1. Implement an efficient algorithm to compute $F(\\mathbf{k},t)$ from a discrete time series $\\{\\rho_{\\mathbf{k}}(n \\Delta t)\\}_{n=0}^{T-1}$ using the discrete Wiener–Khinchin theorem and the Fast Fourier Transform (FFT). For a finite discrete time series $r_n = \\rho_{\\mathbf{k}}(n \\Delta t)$ with $n \\in \\{0,1,\\dots,T-1\\}$, define the linear autocorrelation\n$$C_m = \\sum_{n=0}^{T-1-m} r_{n+m}\\,r_n^{\\ast}, \\quad m \\in \\{0,1,\\dots,T-1\\}.$$\nShow how to compute $\\{C_m\\}$ via zero-padding and FFT so as to avoid circular convolution. Then obtain\n$$F(\\mathbf{k},m \\Delta t) = \\frac{1}{N}\\,\\frac{C_m}{T-m}$$\nas the unbiased time-origin averaged coherent intermediate scattering function.\n\n2. Generate synthetic MD trajectories for particles undergoing independent Brownian motion in three dimensions. Use a cubic domain of side length $L$ with independent and identically distributed initial particle positions uniformly sampled from $[0,L]^3$ to ensure randomized initial phases. At each discrete time step $\\Delta t$, update positions by adding independent Gaussian increments with zero mean and standard deviation $\\sqrt{2 D \\Delta t}$ along each axis. Use a fixed wavevector $\\mathbf{k}$ aligned with the $x$-axis with magnitude $k$ (the direction choice is arbitrary but must be fixed).\n\n3. For each test case, compute $F(\\mathbf{k},t)$ using your FFT-based algorithm and compare to the theoretical expectation:\n   - If $k > 0$, compare to $$F_{\\mathrm{theory}}(t) = \\exp\\!\\left(-D k^2 t\\right).$$\n   - If $k = 0$, compare to $$F_{\\mathrm{theory}}(t) = N.$$\n   Compute the maximum relative error over lags $m$ for which $F_{\\mathrm{theory}}(m \\Delta t) \\geq \\theta$ (a threshold to avoid numerical instability when the expected value is extremely small). For $k=0$, use all lags since $F_{\\mathrm{theory}}$ is constant. Use the relative error definition\n   $$\\varepsilon_m = \\frac{\\left|F(\\mathbf{k},m \\Delta t) - F_{\\mathrm{theory}}(m \\Delta t)\\right|}{\\left|F_{\\mathrm{theory}}(m \\Delta t)\\right|}.$$\n\n4. For each test case, return a boolean indicating whether the maximum relative error over the prescribed lags is strictly less than the specified tolerance.\n\nScientific realism and units:\n\n- Positions must be in meters ($\\mathrm{m}$).\n- Time must be in seconds ($\\mathrm{s}$).\n- Diffusion coefficient $D$ must be in square meters per second ($\\mathrm{m}^2/\\mathrm{s}$).\n- Wavevector magnitude $k$ must be in inverse meters ($\\mathrm{m}^{-1}$).\n\nTest suite:\n\nImplement your program to evaluate the following three test cases. Use the given parameters exactly, and treat $L$ as the side length of the initial uniform position distribution. Use a fixed pseudorandom seed per test case for reproducibility. In all cases, the wavevector is $\\mathbf{k} = (k,0,0)$.\n\n- Test case $1$ (general case, nonzero wavevector):\n  - $N = 1024$\n  - $T = 2048$\n  - $\\Delta t = 1\\times 10^{-12}\\ \\mathrm{s}$\n  - $D = 2\\times 10^{-9}\\ \\mathrm{m}^2/\\mathrm{s}$\n  - $k = 2\\times 10^{9}\\ \\mathrm{m}^{-1}$\n  - $L = 1\\times 10^{-6}\\ \\mathrm{m}$\n  - threshold $\\theta = 1\\times 10^{-3}$ (dimensionless)\n  - tolerance $= 2\\times 10^{-1}$ (dimensionless)\n  - seed $= 123$\n\n- Test case $2$ (boundary case, zero wavevector):\n  - $N = 512$\n  - $T = 1024$\n  - $\\Delta t = 1\\times 10^{-12}\\ \\mathrm{s}$\n  - $D = 1\\times 10^{-9}\\ \\mathrm{m}^2/\\mathrm{s}$\n  - $k = 0$\n  - $L = 1\\times 10^{-6}\\ \\mathrm{m}$\n  - threshold $\\theta = 0$ (dimensionless)\n  - tolerance $= 1\\times 10^{-10}$ (dimensionless)\n  - seed $= 456$\n\n- Test case $3$ (small sample size and moderate wavevector):\n  - $N = 256$\n  - $T = 512$\n  - $\\Delta t = 5\\times 10^{-12}\\ \\mathrm{s}$\n  - $D = 1\\times 10^{-9}\\ \\mathrm{m}^2/\\mathrm{s}$\n  - $k = 1\\times 10^{9}\\ \\mathrm{m}^{-1}$\n  - $L = 1\\times 10^{-6}\\ \\mathrm{m}$\n  - threshold $\\theta = 1\\times 10^{-3}$ (dimensionless)\n  - tolerance $= 3\\times 10^{-1}$ (dimensionless)\n  - seed $= 789$\n\nFinal output format specification:\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $$[r_1,r_2,r_3]$$), where each $r_i$ is a boolean indicating whether the corresponding test case met its tolerance criterion. No other output is permitted.",
            "solution": "The problem is assessed as valid. It is scientifically grounded in the principles of statistical mechanics and signal processing, well-posed with a clear objective and sufficient data, and objective in its language. We may therefore proceed with a solution.\n\nThe task is to compute the coherent intermediate scattering function, $F(\\mathbf{k},t)$, from a simulated molecular dynamics trajectory and verify the result against a known theoretical model. The overall process involves three main stages: first, generating a synthetic trajectory for particles undergoing independent Brownian motion; second, calculating the time series of the collective density mode, $\\rho_{\\mathbf{k}}(t)$; and third, computing the time-autocorrelation of this series using an efficient Fast Fourier Transform (FFT) based method to obtain $F(\\mathbf{k},t)$.\n\n**1. Generation of Brownian Motion Trajectories**\n\nThe physical model is an ideal gas of $N$ non-interacting particles in three dimensions. The dynamics of each particle $j$ is independent and governed by Brownian motion. The position of particle $j$ at time $t$ is denoted by $\\mathbf{r}_j(t)$. The simulation starts at time $t=0$ and proceeds for $T$ discrete time steps of duration $\\Delta t$.\n\nThe initial positions, $\\{\\mathbf{r}_j(0)\\}_{j=1}^N$, are drawn from an independent and identical uniform distribution within a cubic volume of side length $L$. That is, for each particle $j$, its initial coordinates $(x_j(0), y_j(0), z_j(0))$ are sampled from $U(0, L)$. This randomization of initial positions ensures that the initial phases in the density mode calculation are decorrelated.\n\nThe trajectory is propagated using the discrete-time update rule for Brownian motion. The displacement of a particle over a time interval $\\Delta t$ is a random vector whose Cartesian components are independent Gaussian random variables with mean $0$ and variance $2D\\Delta t$, where $D$ is the diffusion coefficient. Thus, the position at step $n+1$ is updated from the position at step $n$ as:\n$$ \\mathbf{r}_j((n+1)\\Delta t) = \\mathbf{r}_j(n\\Delta t) + \\Delta\\mathbf{r}_j(n) $$\nwhere each component of the displacement vector $\\Delta\\mathbf{r}_j(n)$ is drawn from a normal distribution $\\mathcal{N}(0, \\sigma^2)$ with standard deviation $\\sigma = \\sqrt{2D\\Delta t}$.\n\n**2. Computation of the Density Mode Time Series**\n\nThe coherent intermediate scattering function is the autocorrelation of the density mode, $\\rho_{\\mathbf{k}}(t)$, defined as:\n$$ \\rho_{\\mathbf{k}}(t) = \\sum_{j=1}^{N} \\exp\\!\\left(i \\mathbf{k}\\cdot\\mathbf{r}_j(t)\\right) $$\nFor our generated discrete trajectory $\\{\\mathbf{r}_j(n\\Delta t)\\}$, we compute a discrete complex-valued time series $r_n = \\rho_{\\mathbf{k}}(n\\Delta t)$ for $n \\in \\{0, 1, \\dots, T-1\\}$. The problem specifies a wavevector $\\mathbf{k}$ aligned with the $x$-axis, $\\mathbf{k} = (k, 0, 0)$. The dot product simplifies to $\\mathbf{k}\\cdot\\mathbf{r}_j(t) = k\\,x_j(t)$, where $x_j(t)$ is the $x$-component of the position of particle $j$. The time series is therefore:\n$$ r_n = \\rho_{\\mathbf{k}}(n\\Delta t) = \\sum_{j=1}^{N} \\exp\\!\\left(i k\\,x_j(n\\Delta t)\\right) $$\n\n**3. FFT-Based Autocorrelation (Wiener–Khinchin Theorem)**\n\nThe problem requires computing the linear autocorrelation of the time series $\\{r_n\\}_{n=0}^{T-1}$, defined as:\n$$ C_m = \\sum_{n=0}^{T-1-m} r_{n+m}\\,r_n^{\\ast}, \\quad m \\in \\{0, 1, \\dots, T-1\\} $$\nDirect computation of this sum for all $m$ would be an $\\mathcal{O}(T^2)$ operation. A more efficient $\\mathcal{O}(T\\log T)$ approach is to use the Wiener–Khinchin theorem, which relates the autocorrelation function to the power spectral density via the Fourier transform. For discrete signals, care must be taken to compute the *linear* autocorrelation, not the *circular* one that arises from the periodicity of the Discrete Fourier Transform (DFT).\n\nThe correct procedure involves zero-padding the signal:\n1.  Let the original time series be $r = \\{r_0, r_1, \\dots, r_{T-1}\\}$.\n2.  Create a new signal $r'$ of length $M$ by padding $r$ with zeros. To ensure the result is a linear correlation, the padded length $M$ must be at least $2T-1$. For computational efficiency with FFT algorithms, $M$ is typically chosen as the next highest power of $2$, or more generally, a \"smooth\" number (highly composite). We will choose $M$ such that $M \\ge 2T-1$.\n3.  Compute the DFT of the padded signal: $R' = \\mathcal{F}(r')$.\n4.  Compute the power spectral density (PSD) by taking the squared magnitude of each component of $R'$: $S_k = |R'_k|^2 = R'_k \\cdot (R'_k)^{\\ast}$.\n5.  Compute the inverse DFT of the PSD: $C' = \\mathcal{F}^{-1}(S)$.\nThe first $T$ elements of the resulting series $C'$ are the desired linear autocorrelation values $\\{C_m\\}_{m=0}^{T-1}$.\n\n**4. Final Calculation and Error Analysis**\n\nFrom the computed autocorrelation sums $\\{C_m\\}$, the unbiased estimator for the coherent intermediate scattering function is calculated for each lag time $m\\Delta t$:\n$$ F(\\mathbf{k}, m\\Delta t) = \\frac{1}{N} \\frac{C_m}{T-m} $$\nThis computed function is then compared to the theoretical expectation for an ideal gas of Brownian particles.\n-   For a non-zero wavevector magnitude $k > 0$, the theoretical function is an exponential decay:\n    $$ F_{\\mathrm{theory}}(t) = \\exp(-Dk^2t) $$\n-   For the special case $k=0$, the dot product $\\mathbf{k}\\cdot\\mathbf{r}_j(t)$ is always $0$, so $\\rho_{\\mathbf{0}}(t) = \\sum_j e^0 = N$. The function becomes constant:\n    $$ F_{\\mathrm{theory}}(t) = \\frac{1}{N}\\langle N \\cdot N^{\\ast} \\rangle = N $$\n\nThe relative error $\\varepsilon_m$ is computed at each lag $m$:\n$$ \\varepsilon_m = \\frac{|F(\\mathbf{k}, m\\Delta t) - F_{\\mathrm{theory}}(m\\Delta t)|}{|F_{\\mathrm{theory}}(m\\Delta t)|} $$\nThe maximum relative error is then found over a relevant range of lags. For $k>0$, this range includes all lags $m$ for which the theoretical function has not decayed below a threshold $\\theta$, i.e., $F_{\\mathrm{theory}}(m\\Delta t) \\ge \\theta$. This avoids numerical instabilities from dividing by very small numbers. For $k=0$, $F_{\\mathrm{theory}}$ is a large constant, so all lags are used. Finally, this maximum relative error is compared against a specified tolerance to determine the boolean outcome for each test case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.fft import fft, ifft, next_fast_len\n\ndef run_test_case(N, T, dt, D, k, L, theta, tolerance, seed):\n    \"\"\"\n    Runs a single test case for computing the coherent intermediate scattering function.\n    \n    Args:\n        N (int): Number of particles.\n        T (int): Number of time steps.\n        dt (float): Time step duration in seconds.\n        D (float): Diffusion coefficient in m^2/s.\n        k (float): Wavevector magnitude in 1/m.\n        L (float): Side length of the initial distribution box in meters.\n        theta (float): Threshold for theoretical F(k,t) to consider in error analysis.\n        tolerance (float): Tolerance for maximum relative error.\n        seed (int): Seed for the pseudorandom number generator.\n        \n    Returns:\n        bool: True if the max relative error is less than the tolerance, False otherwise.\n    \"\"\"\n    # 1. Set seed for reproducibility\n    rng = np.random.default_rng(seed)\n\n    # 2. Generate trajectory for independent Brownian motion\n    positions = np.zeros((T, N, 3))\n    # Initial positions are uniformly distributed in a cube of side L\n    positions[0, :, :] = rng.uniform(0, L, size=(N, 3))\n    \n    # Propagate positions using Gaussian increments\n    std_dev = np.sqrt(2 * D * dt)\n    for t_idx in range(T - 1):\n        displacements = rng.normal(0, std_dev, size=(N, 3))\n        positions[t_idx + 1] = positions[t_idx] + displacements\n        # For an ideal gas model, no periodic boundary conditions are applied.\n\n    # 3. Compute the density mode time series, rho_k(t)\n    # The wavevector is k_vec = (k, 0, 0), so k.r = k * x-position.\n    if k == 0:\n        # For k=0, exp(i*0) = 1, so rho_k(t) is a constant sum of 1s, which is N.\n        rho_k_t = np.full(T, float(N), dtype=np.complex128)\n    else:\n        # General case: rho_k(t) = sum_j exp(i * k * r_j_x(t))\n        # Vectorized calculation over all time steps and particles.\n        k_dot_r = k * positions[:, :, 0]  # Shape (T, N)\n        rho_k_t = np.sum(np.exp(1j * k_dot_r), axis=1)  # Shape (T,)\n\n    # 4. Compute the linear autocorrelation using the Wiener-Khinchin theorem via FFT\n    # Pad the signal to a length >= 2*T - 1 to avoid circular convolution effects.\n    # next_fast_len finds an efficient length for FFT.\n    n_padded = next_fast_len(2 * T - 1)\n    \n    # FFT of the zero-padded signal\n    rho_k_fft = fft(rho_k_t, n=n_padded)\n    \n    # Power spectral density is the squared magnitude of the FFT\n    psd = np.abs(rho_k_fft)**2\n    \n    # Inverse FFT of the PSD gives the autocorrelation function\n    autocorr_raw = ifft(psd)\n    \n    # The first T elements of the result correspond to the desired linear autocorrelation C_m.\n    # The result should be real; the imaginary part is numerical noise.\n    C_m = np.real(autocorr_raw[:T])\n\n    # 5. Compute the unbiased estimator for F(k,t)\n    # F(k, m*dt) = (1/N) * C_m / (T - m)\n    # The denominator (T-m) is the number of samples for each lag m.\n    denominators = np.arange(T, 0, -1)\n    F_computed = (1 / N) * (C_m / denominators)\n\n    # 6. Compute the theoretical F(k,t) for comparison\n    times = np.arange(T) * dt\n    if k > 0:\n        F_theory = np.exp(-D * k**2 * times)\n    else:  # k == 0\n        F_theory = np.full(T, float(N))\n        \n    # 7. Compute relative error and check against tolerance\n    # The denominator np.abs(F_theory) is always positive here.\n    relative_error = np.abs(F_computed - F_theory) / np.abs(F_theory)\n\n    # Select the lags over which to evaluate the error based on the threshold theta.\n    if k > 0:\n        # For k>0, consider only lags where the theoretical value is significant.\n        valid_indices = np.where(F_theory >= theta)[0]\n        # If the function decays so fast that no points are above threshold,\n        # we can default to checking lag 0, which is always 1.0.\n        if len(valid_indices) == 0:\n            valid_indices = [0]\n    else: # k == 0\n        # For k=0, the theoretical value is constant, so all lags are used.\n        valid_indices = np.arange(T)\n        \n    max_rel_error = np.max(relative_error[valid_indices])\n\n    return max_rel_error < tolerance\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Test case 1: General case, nonzero wavevector\n        {'N': 1024, 'T': 2048, 'dt': 1e-12, 'D': 2e-9, 'k': 2e9, 'L': 1e-6, \n         'theta': 1e-3, 'tolerance': 2e-1, 'seed': 123},\n        # Test case 2: Boundary case, zero wavevector\n        {'N': 512, 'T': 1024, 'dt': 1e-12, 'D': 1e-9, 'k': 0, 'L': 1e-6, \n         'theta': 0, 'tolerance': 1e-10, 'seed': 456},\n        # Test case 3: Small sample size and moderate wavevector\n        {'N': 256, 'T': 512, 'dt': 5e-12, 'D': 1e-9, 'k': 1e9, 'L': 1e-6, \n         'theta': 1e-3, 'tolerance': 3e-1, 'seed': 789},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_test_case(**case)\n        results.append(result)\n\n    # Format the final output as a single line: [True,True,False]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "In our final practice, we leverage the computed scattering function to probe a fundamental physical principle. This exercise  challenges you to numerically verify the classical $f$-sum rule, which relates the second frequency moment of the dynamic structure factor $S(q, \\omega)$ to the system's thermal energy. Through this process, you will not only appreciate the deep physical content encoded in $S(q, \\omega)$ but also confront the critical numerical artifacts, such as aliasing and truncation, that can arise in spectral analysis.",
            "id": "3418532",
            "problem": "Consider a classical monatomic fluid at thermal equilibrium probed by elastic density fluctuations. Let the intermediate scattering function (ISF) be defined by $F(\\mathbf{q}, t) = N^{-1} \\langle \\rho(\\mathbf{q}, t)\\rho(-\\mathbf{q}, 0) \\rangle$, where $\\rho(\\mathbf{q}, t)$ is the spatial Fourier mode of the microscopic number density, $\\mathbf{q}$ is the wavevector with magnitude $q = \\|\\mathbf{q}\\|$, and $\\langle \\cdot \\rangle$ denotes an ensemble average. Define the dynamic structure factor by the Fourier transform $S(\\mathbf{q}, \\omega) = (2\\pi)^{-1} \\int_{-\\infty}^{\\infty} \\mathrm{d}t\\, e^{i \\omega t} F(\\mathbf{q}, t)$, and define the static structure factor by $S(\\mathbf{q}) = F(\\mathbf{q}, 0)$. The classical $f$-sum rule asserts a relationship between the second frequency moment of $S(\\mathbf{q}, \\omega)$ and the thermal velocity scale.\n\nYour task is to implement a test of the $f$-sum rule using synthesized Molecular Dynamics (MD) time series that exactly embody ideal-gas ballistic dynamics with Maxwell–Boltzmann velocities. In this ideal monatomic case, one may construct $F(q, t)$ from Newtonian kinematics and Maxwell–Boltzmann statistics at temperature $T$ and mass $m$; then $S(q, \\omega)$ follows from the Fourier transform. From these, numerically approximate $\\int_{-\\infty}^{\\infty} \\omega^{2} S(q, \\omega)\\, \\mathrm{d}\\omega$ by discrete quadrature on a frequency grid obtained via a discrete Fourier transform of a time-sampled $F(q, t)$. Compare the numerically estimated left-hand side to the right-hand side $(q^{2} k_{\\mathrm{B}} T/m)\\, S(q)$, where $k_{\\mathrm{B}}$ is the Boltzmann constant. Report the relative error for specified discretization settings and discuss, in your solution reasoning, the conditions under which numerical discretization violates the $f$-sum rule.\n\nUse the following foundational and well-tested starting points only: Newtonian kinematics for non-interacting particles, the Maxwell–Boltzmann velocity distribution for a monatomic ideal gas at equilibrium, the definition of the intermediate scattering function and dynamic structure factor given above, and standard properties of Fourier transforms. Do not assume any result about the $f$-sum rule beyond its statement; instead, connect it back to these definitions.\n\nPhysical and numerical units and conventions to use throughout:\n- Use $q$ in inverse meters ($\\mathrm{m}^{-1}$), $t$ in seconds ($\\mathrm{s}$), angular frequency $\\omega$ in radians per second ($\\mathrm{rad}\\,\\mathrm{s}^{-1}$), mass $m$ in kilograms ($\\mathrm{kg}$), temperature $T$ in kelvins ($\\mathrm{K}$), and $k_{\\mathrm{B}}$ in joules per kelvin ($\\mathrm{J}\\,\\mathrm{K}^{-1}$).\n- The Fourier transform convention is $S(q,\\omega) = (2\\pi)^{-1} \\int_{-\\infty}^{\\infty} \\mathrm{d}t\\, e^{i \\omega t} F(q,t)$.\n- The static structure factor is $S(q) = F(q,0)$.\n\nAlgorithmic specification for the numerical test:\n- Synthesize $F(q,t)$ for an ideal monatomic gas at equilibrium at temperature $T$ and particle mass $m$ and a given wavevector magnitude $q$ using Newtonian kinematics and Maxwell–Boltzmann statistics. Then, sample $F(q,t)$ uniformly on a time grid $t_{n} = (n - N/2)\\,\\Delta t$ for $n = 0, 1, \\ldots, N-1$, apply a chosen window function $w_{n}$ to obtain sampled data $G_{n} = F(q,t_{n})\\, w_{n}$, and compute a discrete Fourier transform to obtain a numerical approximation to $S(q,\\omega)$, denoted $\\widehat{S}(q,\\omega_{k})$ on a uniform angular-frequency grid $\\omega_{k}$.\n- Use the discrete quadrature $\\sum_{k} \\omega_{k}^{2}\\, \\widehat{S}(q,\\omega_{k})\\, \\Delta \\omega$ to approximate $\\int \\omega^{2} S(q,\\omega)\\, \\mathrm{d}\\omega$, where $\\Delta \\omega$ is the uniform angular-frequency spacing implied by the discrete Fourier transform. Ensure the scaling is consistent with the $S(q,\\omega)$ definition given above and the grid spacing used.\n- Compare this numerical left-hand side to the right-hand side $(q^{2} k_{\\mathrm{B}} T/m) S(q)$ using $S(q)=F(q,0)$, and report the relative error $(\\mathrm{LHS} - \\mathrm{RHS})/\\mathrm{RHS}$.\n\nTest suite:\nUse the following four test cases with fixed physical parameters and varying discretizations. For all cases, use $k_{\\mathrm{B}} = 1.380649\\times 10^{-23}\\,\\mathrm{J}\\,\\mathrm{K}^{-1}$, $m = 39.948\\times 1.66053906660\\times 10^{-27}\\,\\mathrm{kg}$, $T = 300\\,\\mathrm{K}$, and $q = 1.0\\times 10^{9}\\,\\mathrm{m}^{-1}$. The window \"rectangular\" means $w_{n} = 1$ for all $n$, and the window \"Hann\" means $w_{n} = \\tfrac{1}{2}\\left(1 - \\cos\\left(2\\pi n/(N-1)\\right)\\right)$ for $n \\in \\{0,\\ldots,N-1\\}$.\n\n- Case $1$ (well-resolved, rectangular window): $N = 4096$, $\\Delta t = 1.0\\times 10^{-13}\\,\\mathrm{s}$, rectangular window.\n- Case $2$ (insufficient Nyquist frequency due to large time step): $N = 4096$, $\\Delta t = 2.0\\times 10^{-12}\\,\\mathrm{s}$, rectangular window.\n- Case $3$ (short total time and coarse frequency resolution): $N = 256$, $\\Delta t = 1.0\\times 10^{-13}\\,\\mathrm{s}$, rectangular window.\n- Case $4$ (Hann window modifies the time signal): $N = 4096$, $\\Delta t = 1.0\\times 10^{-13}\\,\\mathrm{s}$, Hann window.\n\nRequired final output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the four cases above. Each entry must be the relative error for that case as a floating-point number (dimensionless). For example, an output of the form $[x_{1},x_{2},x_{3},x_{4}]$, where each $x_{i}$ is the relative error for case $i$.",
            "solution": "The problem requires a numerical test of the classical $f$-sum rule for an ideal monatomic gas. The validation process confirms that the problem is scientifically sound, well-posed, and contains all necessary information. We may therefore proceed with a solution.\n\nThe solution involves three main parts:\n1.  An analytical derivation of the intermediate scattering function $F(q, t)$ for an ideal gas, which serves as the basis for the synthesized time series.\n2.  An analytical verification of the $f$-sum rule for this system to establish the exact theoretical relationship being tested.\n3.  A numerical implementation that computes the second frequency moment of the dynamic structure factor from the synthesized $F(q, t)$ and compares it to the theoretical prediction, followed by an analysis of the numerical errors observed in the specified test cases.\n\n**1. Analytical Form of the Intermediate Scattering Function for an Ideal Gas**\n\nThe intermediate scattering function (ISF) is defined as $F(\\mathbf{q}, t) = N^{-1} \\langle \\rho(\\mathbf{q}, t)\\rho(-\\mathbf{q}, 0) \\rangle$, where $\\rho(\\mathbf{q}, t) = \\sum_{j=1}^{N} e^{-i\\mathbf{q}\\cdot\\mathbf{r}_j(t)}$ is a Fourier component of the density. For an ideal gas, particle positions and velocities are uncorrelated. Consequently, the cross-terms ($j \\neq k$) in the expansion of $F(\\mathbf{q}, t)$ vanish for a homogeneous system, and the sum simplifies to an average over a single particle's trajectory: $F(\\mathbf{q}, t) = \\langle e^{-i\\mathbf{q}\\cdot(\\mathbf{r}(t) - \\mathbf{r}(0))} \\rangle$.\n\nParticles in an ideal gas undergo ballistic motion, so $\\mathbf{r}(t) = \\mathbf{r}(0) + \\mathbf{v}t$. The displacement is $\\mathbf{r}(t) - \\mathbf{r}(0) = \\mathbf{v}t$. The ISF becomes an average over the velocity distribution:\n$$F(\\mathbf{q}, t) = \\langle e^{-i\\mathbf{q}\\cdot\\mathbf{v}t} \\rangle$$\nThe average is performed over the Maxwell-Boltzmann velocity distribution for a monatomic gas of mass $m$ at temperature $T$:\n$$P(\\mathbf{v}) = \\left(\\frac{m}{2\\pi k_{\\mathrm{B}} T}\\right)^{3/2} \\exp\\left(-\\frac{m |\\mathbf{v}|^2}{2 k_{\\mathrm{B}} T}\\right)$$\nThe average is the characteristic function of this Gaussian distribution. By aligning one axis (e.g., $v_z$) with $\\mathbf{q}$, the integral separates and can be solved by completing the square or recognizing it as a Fourier transform of a Gaussian. The result, which depends only on the magnitude $q = |\\mathbf{q}|$, is:\n$$F(q, t) = \\exp\\left(-\\frac{q^2 k_{\\mathrm{B}} T}{2m} t^2\\right)$$\nThis Gaussian function of time is the exact ISF for an ideal gas. The static structure factor is $S(q) = F(q, 0) = 1$, a known result for a non-interacting system.\n\n**2. Analytical Verification of the $f$-Sum Rule**\n\nThe $f$-sum rule relates the second frequency moment of the dynamic structure factor $S(q, \\omega)$ to thermal properties:\n$$\\int_{-\\infty}^{\\infty} \\omega^{2} S(q, \\omega)\\, \\mathrm{d}\\omega = \\frac{q^{2} k_{\\mathrm{B}} T}{m} S(q)$$\nWith $S(q)=1$ for our ideal gas, the right-hand side (RHS) is $\\frac{q^{2} k_{\\mathrm{B}} T}{m}$.\n\nThe left-hand side (LHS) can be calculated using the moment theorem of Fourier transforms. Given the problem's convention $S(q, \\omega) = (2\\pi)^{-1} \\int_{-\\infty}^{\\infty} e^{i \\omega t} F(q, t) \\mathrm{d}t$, the second moment is related to the second derivative of $F(q, t)$ at $t=0$:\n$$\\int_{-\\infty}^{\\infty} \\omega^{2} S(q, \\omega)\\, \\mathrm{d}\\omega = i^2 \\frac{\\mathrm{d}^2 F(q, t)}{\\mathrm{d}t^2}\\bigg|_{t=0} = -\\frac{\\mathrm{d}^2 F(q, t)}{\\mathrm{d}t^2}\\bigg|_{t=0}$$\nLet us define $\\alpha = \\frac{q^2 k_{\\mathrm{B}} T}{2m}$, so $F(q, t) = e^{-\\alpha t^2}$. The derivatives are:\n$$\\frac{\\mathrm{d}F}{\\mathrm{d}t} = -2\\alpha t e^{-\\alpha t^2}$$\n$$\\frac{\\mathrm{d}^2F}{\\mathrm{d}t^2} = (-2\\alpha + 4\\alpha^2 t^2) e^{-\\alpha t^2}$$\nEvaluating at $t=0$ gives $\\frac{\\mathrm{d}^2F}{\\mathrm{d}t^2}\\big|_{t=0} = -2\\alpha$.\nTherefore, the LHS is $-(-2\\alpha) = 2\\alpha = 2\\left(\\frac{q^2 k_{\\mathrm{B}} T}{2m}\\right) = \\frac{q^2 k_{\\mathrm{B}} T}{m}$.\nThe LHS equals the RHS, so the $f$-sum rule is satisfied analytically.\n\n**3. Numerical Test and Error Analysis**\n\nThe task is to numerically evaluate the LHS and compare it to the analytical RHS. The numerical procedure specified is:\n1.  Sample the function $G(t) = F(q, t)w(t)$ on a discrete time grid $t_n = (n-N/2)\\Delta t$.\n2.  Compute its discrete Fourier transform (DFT), $\\tilde{G}_k$.\n3.  Use the DFT to approximate the Fourier integral $\\tilde{G}(\\omega) \\approx \\Delta t \\cdot \\tilde{G}_k$ (up to phase factors handled by `fftshift`).\n4.  Approximate the integral $\\int \\omega^2 S(q,\\omega) \\mathrm{d}\\omega$ using a discrete sum over the DFT frequencies $\\omega_k$.\n\nThe relationship between the continuous Fourier transform and the DFT, along with the specified definition of $S(q,\\omega)$, leads to the following formula for the numerically estimated LHS:\n$$LHS_{\\text{num}} = \\frac{1}{N} \\sum_{k=0}^{N-1} \\omega_k^2 \\tilde{G}_k$$\nwhere $\\tilde{G}_k$ is the DFT of the time-centered, windowed signal $G_n$, and $\\omega_k$ are the corresponding angular frequencies from the DFT. The relative error is then $(\\mathrm{LHS}_{\\text{num}} - \\mathrm{RHS}) / \\mathrm{RHS}$.\n\nThe specified test cases are designed to expose common pitfalls in numerical signal processing:\n\n-   **Case 1 (Baseline):** With a large number of points $N$ and a small time step $\\Delta t$, the time-domain signal $F(q,t)$ is well-sampled out to times where its amplitude is negligible. This minimizes both aliasing (due to small $\\Delta t$) and truncation/leakage (due to large total time $N\\Delta t$). The frequency resolution is fine. We expect the numerical error to be very small.\n\n-   **Case 2 (Aliasing):** The time step $\\Delta t = 2.0 \\times 10^{-12}\\,\\mathrm{s}$ is larger than the characteristic decay time of $F(q,t)$, which is $\\tau = \\sqrt{2m/(q^2 k_{\\mathrm{B}} T)} \\approx 1.79 \\times 10^{-12}\\,\\mathrm{s}$. This violates the Nyquist sampling criterion, as the Nyquist frequency $\\omega_{\\text{Nyq}} = \\pi/\\Delta t$ is comparable to the spectral width of $S(q,\\omega)$. Spectral power from frequencies $|\\omega| > \\omega_{\\text{Nyq}}$ is \"folded\" into the sampled frequency range. Because the sum rule integral weights the spectrum by $\\omega^2$, the high-frequency components are critical. Aliasing maps these large contributions to lower frequencies, where they are weighted by a smaller $\\omega^2$, leading to a significant underestimation of the integral and a large negative error.\n\n-   **Case 3 (Poor Frequency Resolution):** The number of points $N=256$ is small, leading to a short total time span $T_{\\text{tot}} = N\\Delta t$. This results in a coarse frequency grid, as the frequency resolution is $\\Delta\\omega = 2\\pi/T_{\\text{tot}}$. The function $\\omega^2 S(q,\\omega)$ is sampled at only a few points, making the discrete sum a poor approximation (quadrature error) of the continuous integral. This leads to a noticeable, though not catastrophic, error.\n\n-   **Case 4 (Windowing):** Applying a non-rectangular window, such as the Hann window, modifies the signal. Multiplication in the time domain corresponds to convolution in the frequency domain. The computed spectrum is a convolution of the true $S(q,\\omega)$ and the Fourier transform of the window function, $\\tilde{w}(\\omega)$. The second moment of this convolved spectrum is the sum of the second moments of the original spectra: $M_2(G) = M_2(F) + M_2(w)$, assuming proper normalization. The physical moment is $M_2(F) = -F''(0)$. The window contributes an additional term $M_2(w) = -w''(0)$. The numerical test therefore computes $-F''(0)w(0) - F(0)w''(0)$, instead of just $-F''(0)$. This introduces a systematic error dependent on the window's value and second derivative at $t=0$. For the specified Hann window and time grid, this results in a small but distinct positive error.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a numerical test of the f-sum rule for an ideal gas\n    based on synthesized intermediate scattering function data.\n    \"\"\"\n    \n    # Physical and numerical parameters from the problem statement.\n    test_cases = [\n        # Case 1: Well-resolved, rectangular window\n        {'N': 4096, 'dt': 1.0e-13, 'window_name': 'rectangular'},\n        # Case 2: Insufficient Nyquist frequency (aliasing)\n        {'N': 4096, 'dt': 2.0e-12, 'window_name': 'rectangular'},\n        # Case 3: Short total time (poor frequency resolution)\n        {'N': 256, 'dt': 1.0e-13, 'window_name': 'rectangular'},\n        # Case 4: Hann window modifies the time signal\n        {'N': 4096, 'dt': 1.0e-13, 'window_name': 'hann'},\n    ]\n\n    # Fixed physical constants\n    k_B = 1.380649e-23  # Boltzmann constant in J/K\n    m_u = 1.66053906660e-27  # Atomic mass unit in kg\n    \n    # System parameters for Argon at 300K\n    m = 39.948 * m_u  # Mass of Argon atom in kg\n    T = 300.0  # Temperature in K\n    q = 1.0e9  # Wavevector magnitude in m^-1\n\n    # Analytically calculate the right-hand side (RHS) of the f-sum rule.\n    # For an ideal gas, the static structure factor S(q) = 1.\n    rhs_analytical = (q**2 * k_B * T) / m\n\n    results = []\n    \n    for case in test_cases:\n        N = case['N']\n        dt = case['dt']\n        window_name = case['window_name']\n        \n        # 1. Define time and frequency grids\n        # Time grid is centered at t=0, as per problem spec\n        t = (np.arange(N) - N / 2) * dt\n        # Angular frequencies from np.fft.fftfreq correspond to the output of np.fft.fft\n        omega = 2 * np.pi * np.fft.fftfreq(N, d=dt)\n\n        # 2. Synthesize the intermediate scattering function F(q,t) for an ideal gas\n        alpha = (q**2 * k_B * T) / (2 * m)\n        F_t = np.exp(-alpha * t**2)\n\n        # 3. Apply the specified window function\n        if window_name == 'rectangular':\n            w = np.ones(N)\n        elif window_name == 'hann':\n            # Per problem spec: w_n = 0.5 * (1 - cos(2*pi*n/(N-1))) for n in {0..N-1}\n            n_idx = np.arange(N)\n            w = 0.5 * (1 - np.cos(2 * np.pi * n_idx / (N - 1)))\n        \n        # Windowed time-domain signal\n        G_t = F_t * w\n\n        # 4. Compute the Discrete Fourier Transform (DFT)\n        # The signal G_t is defined on a centered time grid [-T/2, T/2).\n        # To use np.fft.fft, which assumes a grid [0, T), we must rearrange\n        # the signal using np.fft.ifftshift.\n        G_shifted_for_fft = np.fft.ifftshift(G_t)\n        dft_G = np.fft.fft(G_shifted_for_fft)\n\n        # 5. Numerically evaluate the LHS of the sum rule via discrete quadrature\n        # The second moment integral is approximated by a sum over discrete frequencies.\n        # The derivation in the solution text shows this simplifies to:\n        # LHS_numerical = (1/N) * sum(omega_k^2 * DFT(G)_k)\n        summand = omega**2 * dft_G\n        \n        # G_t is a real-valued function with near-perfect even symmetry. Its DFT\n        # should be real-valued. We take np.real to discard negligible\n        # imaginary components from floating-point inaccuracies.\n        lhs_numerical = np.real(np.sum(summand)) / N\n\n        # 6. Calculate the relative error\n        relative_error = (lhs_numerical - rhs_analytical) / rhs_analytical\n        results.append(relative_error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}