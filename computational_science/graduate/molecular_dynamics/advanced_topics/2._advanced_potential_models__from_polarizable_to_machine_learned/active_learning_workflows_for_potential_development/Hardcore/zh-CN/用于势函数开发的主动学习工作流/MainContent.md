## 引言
在原子尺度模拟领域，精确且高效的[原子间势](@entry_id:177673)函数是连接理论模型与宏观可观测现象的桥梁。传统的从头计算方法，如密度泛函理论（DFT），虽能提供高保真度的能量与力，但其高昂的计算成本限制了模拟的时间与空间尺度。另一方面，经典的经验[力场](@entry_id:147325)虽然计算速度快，却往往在精度和跨场景泛化能力上有所欠缺。近年来，[机器学习原子间势](@entry_id:751582)函数（MLIPs）的出现，为在保持量子精度的同时实现大规模模拟带来了革命性的可能。然而，构建一个高质量的MLIP面临着一个核心瓶颈：如何以最低的成本，创建一个既全面又包含关键物理信息的训练数据集？

本文聚焦于解决这一挑战的先进方法——用于[势函数](@entry_id:176105)开发的主动学习工作流。[主动学习](@entry_id:157812)并非简单地随机收集数据，而是构建一个智能的“认知引擎”，通过迭代式地识别并查询模型最不确定的区域，以最经济的方式获取最有价值的信息，从而系统性地、数据高效地构建出覆盖广阔构型空间的可靠[势函数](@entry_id:176105)。

为了全面掌握这一强大工具，本文将分为三个核心章节。在“原理与机制”中，我们将剖析[主动学习](@entry_id:157812)工作流的基础架构、核心的物理对称性原理以及[不确定性量化](@entry_id:138597)的机制。接着，在“应用与跨学科连接”中，我们将展示如何将这些原理应用于[计算材料科学](@entry_id:145245)、化学和物理学中的具体问题，从预测基本的[热力学性质](@entry_id:146047)到模拟复杂的[化学反应](@entry_id:146973)。最后，通过一系列精心设计的“动手实践”案例，读者将有机会将理论知识转化为解决实际问题的能力。通过这一系统性的学习路径，本文旨在为读者揭示主动学习如何成为下一代原子尺度模拟的基石。

## 原理与机制

在介绍章节之后，我们现在深入探讨驱动原子势函数开发的[主动学习](@entry_id:157812)工作流的核心科学原理和运行机制。本章将系统地剖析构成这些复杂工作流的基本组件，阐明其背后的理论基础，并探讨在实际应用中确保其鲁棒性和高效性的关键挑战与解决方案。

### 基础三要素：学习器、采样器与神谕

任何用于[势函数](@entry_id:176105)开发的主动学习工作流，其核心都可以解构为三个相互协作的关键组件：**学习器 (Learner)**、**采样器 (Sampler)** 和 **神谕 (Oracle)**。理解这三者的角色和它们之间的信息流动，是掌握整个流程的第一步 。

**学习器**是[机器学习原子间势](@entry_id:751582) (MLIP) 模型本身。它是一个[参数化](@entry_id:272587)的函数 $U(\mathbf{R}; \theta)$，旨在以远低于从头计算的成本，高精度地预测给定原子构型 $\mathbf{R}$ 的[势能](@entry_id:748988)及其梯度（即力）。在[主动学习](@entry_id:157812)的背景下，学习器除了提供能量和力的预测值之外，还必须具备一个至关重要的能力：**量化自身预测的不确定性**。这种[不确定性度量](@entry_id:152963)，例如预测[方差](@entry_id:200758) $\sigma_{\theta}(\mathbf{R})$，是识别模型知识边界、指导后续探索的关键信号。

**采样器**通常是一个[分子动力学](@entry_id:147283) (MD) 引擎。它的核心任务是根据[牛顿第二定律](@entry_id:274217) $m_i \ddot{\mathbf{r}}_i(t) = \mathbf{F}_i(t)$ 来演化原子体系的轨迹。在[主动学习](@entry_id:157812)工作流中，驱动模拟的力 $\mathbf{F}_i$ 并非来自昂贵的[量子化学](@entry_id:140193)计算，而是直接由学习器（即当前的 MLIP）提供：$\mathbf{F}_i(t) = -\nabla_{\mathbf{r}_i} U(\mathbf{R}(t); \theta)$。因此，采样器充当了一个行动机制，它在学习器当前“假设”的[势能面](@entry_id:147441)上探索[构型空间](@entry_id:149531)，生成新的、可能具有[信息量](@entry_id:272315)的原子[排列](@entry_id:136432)。

**神谕**是高保真度的参考方法，通常是[密度泛函理论](@entry_id:139027) (DFT) 或其他高精度的[量子化学](@entry_id:140193)计算方法。它的角色是为学习器选定的、模型不确定的构型提供“基准真相”(ground truth) 标签。当学习器请求对某个构型 $\mathbf{R}_q$ 进行标记时，神谕会执行一次精确但耗时的计算，返回其[势能](@entry_id:748988) $E^{\mathrm{DFT}}(\mathbf{R}_q)$ 和原子受力 $\mathbf{F}^{\mathrm{DFT}}(\mathbf{R}_q)$。这些高质量的数据点是学习器赖以改进自身的唯一信息来源。

这三者构成了一个动态的[反馈回路](@entry_id:273536)：学习器指导采样器探索，采样器产生候选构型，学习器识别出其中最不确定的构型，神谕为这些构型提供精确标签，最终学习器利用这些新标签更新自身模型，从而在下一次循环中做出更准确的预测和更明智的探索。

### [主动学习](@entry_id:157812)循环：一个认知引擎

主动学习工作流的闭环过程不仅是一个计算流程，更是一个遵循[科学方法](@entry_id:143231)论的**认知循环 (epistemic cycle)**。我们可以将其映射到经典的“假设-实验-证据-更新”的认知框架中，这有助于我们从更深层次理解其运行逻辑 。

1.  **假设 (Hypothesis)**：在循环的第 $t$ 步，学习器的当前状态构成了我们的“假设”。在一个贝叶斯框架下，这个假设表现为模型参数 $\theta$ 的[后验概率](@entry_id:153467)[分布](@entry_id:182848) $p(\theta | \mathcal{D}_t)$，其中 $\mathcal{D}_t$ 是截至目前已收集到的所有带标签数据集。这个[分布](@entry_id:182848)体现了我们基于已有数据对真实[势能面](@entry_id:147441)的全部认知和不确定性。

2.  **行动 (Action) 与实验 (Experiment)**：基于当前的假设，我们采取行动。采样器（MD 模拟）使用从[后验分布](@entry_id:145605)中得到的一个或一组[势函数](@entry_id:176105)（例如，通过最大后验估计 $\hat{\theta}_t$ 或从后验中采样得到的模型集成）来生成原子轨迹 $\mathbf{R}(t)$。这个过程本身就是一个计算实验，它探索在当前物理模型下系统可能访问的区域。

3.  **证据收集 (Evidence Gathering)**：在实验过程中，学习器持续评估其对新构型的不确定性。当不确定性超过某个阈值时，一个“提问”决策被触发。这些被选中的构型 $\mathbf{R}_q$ 被发送给神谕。神谕返回的高保真标签 $y_q$（即能量和/或力）构成了新的“证据”。这些证据是模型前所未见的，对于修正其认知至关重要。

4.  **更新 (Update)**：学习器将新证据（即新标记的数据点 $(\mathbf{R}_q, y_q)$）并入其知识库，形成新的数据集 $\mathcal{D}_{t+1} = \mathcal{D}_t \cup \{(\mathbf{R}_q, y_q)\}$。然后，通过[贝叶斯法则](@entry_id:275170) $p(\theta | \mathcal{D}_{t+1}) \propto p(y_q | \mathbf{R}_q, \theta) p(\theta | \mathcal{D}_t)$ 更新后验分布，或者通过[优化算法](@entry_id:147840)（如最小化损失函数）来更新模型参数。这个过程 refining 了我们的假设，使其更接近真相。

这个循环不断重复，每一次迭代都旨在通过最有策略性的方式获取信息，以最快的速度减少模型对真实[势能面](@entry_id:147441)的[认知不确定性](@entry_id:149866)，从而实现数据高效的势函数开发。

### 核心原理一：对称性与表示

在讨论如何学习[势能面](@entry_id:147441)之前，我们必须首先理解[势能面](@entry_id:147441)本身固有的物理对称性。在没有外场的情况下，一个孤立体系的总[势能](@entry_id:748988)必须满足**平移不变性**、**[旋转不变性](@entry_id:137644)**和**同种粒子[置换不变性](@entry_id:753356)**。这意味着，将整个体系在空间中平移或旋转，或者交换任意两个同种原子的标签，体系的[势能](@entry_id:748988)都应当保持不变。

为了构建一个物理上忠实的模型，学习器必须从其架构层面就严格遵守这些对称性。这通常通过两种主流方式实现：**不变性描述符 (invariant descriptors)** 和 **[等变性](@entry_id:636671)架构 (equivariant architectures)**。

#### 不变性描述符

这种方法的思想是在将原[子环](@entry_id:154194)境信息输入到标准机器学习模型（如[神经网](@entry_id:276355)络）之前，先将其转换为一组满足所有对称性要求的[特征向量](@entry_id:151813)，即**描述符** $\phi(\mathbf{R})$ 。

- **[平移不变性](@entry_id:195885)**：通过仅使用相对于中心原子的邻居原子坐标（即相对位置向量 $\mathbf{r}_{ij} = \mathbf{r}_j - \mathbf{r}_i$）来构建描述符，可以自然地满足[平移不变性](@entry_id:195885)。

- **[旋转不变性](@entry_id:137644)**：描述符必须是基于这些相对位置向量构造的标量，这些标量在旋转操作下保持不变。例如，原子间距离 $r_{ij} = |\mathbf{r}_{ij}|$、键角 $\theta_{ijk}$（由 $\mathbf{r}_{ij} \cdot \mathbf{r}_{ik}$ 得到）和二面角都是[旋转不变量](@entry_id:170459)。

- **[置换不变性](@entry_id:753356)**：对于中心原子的所有同种邻居，描述符的构造方式必须对它们的顺序不敏感。这通常通过对每个邻居的贡献进行求和或取平均来实现。

**[原子中心对称函数](@entry_id:174796) (Atom-Centered Symmetry Functions, ACSF)** 正是这一思想的典型例子。它们由两体项（依赖于距离 $r_{ij}$）和[三体](@entry_id:265960)项（依赖于距离和角度 $\theta_{ijk}$）构成，并通过对所有邻居求和来保证[置换不变性](@entry_id:753356)。另一个强大的例子是**原子位置光滑重叠 (Smooth Overlap of Atomic Positions, SOAP)** 方法  。SOAP 首先在每个原子周围构建一个高斯模糊的原子密度场，然后将其用[球谐函数展开](@entry_id:188485)。通过计算这些展开系数的[功率谱](@entry_id:159996)，可以得到一个对旋转不变的[特征向量](@entry_id:151813)，再通过对不同物种的贡献进行处理，同样满足了[置换不变性](@entry_id:753356)。这类方法，包括基于[双谱](@entry_id:158545)（bispectrum）系数的谱邻近分析势 (SNAP)，都是通过精心设计，将物理对称性硬编码到模型的输入特征中。

#### [等变性](@entry_id:636671)架构

近年来，一个更先进的[范式](@entry_id:161181)是构建**[等变性](@entry_id:636671) (equivariance)** [神经网](@entry_id:276355)络，特别是满足三维[特殊欧几里得群](@entry_id:139383) $\mathrm{SE}(3)$ [等变性](@entry_id:636671)的[图神经网络 (GNNs)](@entry_id:750014) 。

与不变性（输入变换，输出不变）不同，**[等变性](@entry_id:636671)**意味着当输入进行某种变换时，输出会以一种可预测的、相应的方式进行变换。例如，对于力矢量 $\mathbf{F}$，它必须是旋转等变的：如果构型旋转了 $R$，那么力矢量也应该旋转 $R$，即 $\mathbf{F}(R\mathbf{R}) = R \mathbf{F}(\mathbf{R})$。

$\mathrm{SE}(3)$-[等变网络](@entry_id:143881)通过特殊设计的卷积层（或[消息传递](@entry_id:751915)层），使其内部处理的特征（可以是标量、矢量或更高阶的张量）在网络每一层都能正确地随着旋转进行变换。最终，为了得到不变的能量标量，网络可以通过对等变矢量进行[点积](@entry_id:149019)或求范数等操作来构造不变的原子能量贡献，然后求和。同时，网络的矢量输出可以被直接用作力的预测，因为它们天生就满足力的[等变性](@entry_id:636671)要求。

这两种方法都能确保模型尊重底层的物理对称性。[不变性](@entry_id:140168)描述符方法将对称性问题在前处理阶段解决，允许使用更通用的机器学习模型。而[等变性](@entry_id:636671)架构则将对称性约束融入到学习过程本身，通常被认为能更有效地利用几何信息，并能同时、一致地预测能量和力。

### 核心原理二：不确定性的核心作用

[主动学习](@entry_id:157812)的“主动”之处，正在于它利用模型的不确定性来智能地指导[数据采集](@entry_id:273490)。为了有效做到这一点，我们必须首先精确区分两种性质截然不同的不确定性：**认知不确定性 (epistemic uncertainty)** 和 **[偶然不确定性](@entry_id:154011) (aleatoric uncertainty)** 。

**[认知不确定性](@entry_id:149866)**源于模型知识的局限性。当训练数据稀疏或不具[代表性](@entry_id:204613)时，许多不同的模型参数 $\boldsymbol{\theta}$ 都能很好地拟合现有数据，但在数据稀疏的区域，这些模型的预测会产生分歧。这种[分歧](@entry_id:193119)，即认知不确定性，反映了模型“不知道自己不知道”的程度。它是可以通过增加[信息量](@entry_id:272315)大的新数据点来**减少**的。因此，**[认知不确定性](@entry_id:149866)是[主动学习](@entry_id:157812)旨在解决和利用的核心目标**。

**偶然不确定性**则源于数据生成过程中的内在随机性或噪声。即使我们拥有一个完美的模型（即参数 $\boldsymbol{\theta}$ 已知），预测结果仍然会存在波动。例如，DFT计算的收敛噪声、有限温度MD模拟中对真实[势能面](@entry_id:147441)的采样波动等，都属于偶然不确定性。这种不确定性是系统或测量方法固有的，通常无法通过增加更多同类数据点来消除。在[主动学习](@entry_id:157812)中，我们应当避免被偶然不确定性高的区域所误导，因为在这些区域反复采样并不能有效地提升模型对基础物理规律的认知。

在贝叶斯视角下，总预测[方差](@entry_id:200758)可以分解为这两部分。给定[新构型](@entry_id:199611) $\mathbf{R}$，总预测[方差](@entry_id:200758) $\mathrm{Var}[y | \mathbf{R}, \mathcal{D}]$ 近似等于[认知不确定性](@entry_id:149866)与[偶然不确定性](@entry_id:154011)之和：
$$
\mathrm{Var}[y | \mathbf{R}, \mathcal{D}] \approx \underbrace{\mathrm{Var}_{\theta \sim p(\theta|\mathcal{D})}(\mathbb{E}[y | \mathbf{R}, \theta])}_{\text{认知不确定性}} + \underbrace{\mathbb{E}_{\theta \sim p(\theta|\mathcal{D})}(\mathrm{Var}[y | \mathbf{R}, \theta])}_{\text{偶然不确定性}}
$$
主动学习的目标是选择新的 $\mathbf{R}$，使得第一项（认知不确定性）最大化。

#### 量化[认知不确定性](@entry_id:149866)

在实践中，精确计算贝叶斯后验并分解[方差](@entry_id:200758)是极其困难的，尤其对于深度神经网络势函数 (NNP)。因此，研究人员开发了多种实用的近似方法来估计[认知不确定性](@entry_id:149866) ：

- **[深度集成](@entry_id:636362) (Deep Ensembles)**：这是目前最可靠和广泛使用的方法之一。它通过训练多个（例如 $M=5$ 或更多）结构相同但从不同随机[权重初始化](@entry_id:636952)和不同数据批次顺序开始训练的模型。对于一个新的构型，这 $M$ 个模型会给出 $M$ 个不同的预测。这些预测值之间的[方差](@entry_id:200758)，即 $\mathrm{Var}_{m \in \mathcal{M}} f_m(\mathbf{R})$，就作为认知不确定性的一个强大代理。这种方法被认为可以有效地探索参数空间中的多个不同模式。

- **[蒙特卡洛](@entry_id:144354) Dropout (MC Dropout)**：这是一种计算成本更低的近似[贝叶斯推断](@entry_id:146958)的方法。在一个使用了 Dropout 层的[神经网](@entry_id:276355)络中，我们可以在**测试阶段**也保持 Dropout 开启，并对同一个输入进行多次（例如 $T$ 次）随机[前向传播](@entry_id:193086)。由于每次传播中被“丢弃”的神经元不同，我们会得到一组不同的预测结果。这些结果的[方差](@entry_id:200758)同样可以用来近似认知不确定性。理论上，MC Dropout 被证明是在对一个特定的变分[分布](@entry_id:182848)进行近似贝叶斯推断。

这两种方法都旨在通过模型预测的分歧程度来量化认知不确定性，从而为主动学习的“提问”环节提供决策依据。

### 采集机制：从不确定性到行动

拥有了不确定性的度量后，我们还需要一个明确的策略来决定下一步应该标记哪个构型。这个策略由**[采集函数](@entry_id:168889) (acquisition function)** $a(\mathbf{R})$ 定义，学习器会选择使该函数最大化的构型作为下一个查询点。

#### 基于不确定性的采集

最直观的策略是直接选择模型最不确定的点，即**最大[方差](@entry_id:200758)采集** 。
$$
a_{\text{VAR}}(\mathbf{R}) = \sigma_{\text{ep}}^2(\mathbf{R})
$$
这里的 $\sigma_{\text{ep}}^2(\mathbf{R})$ 就是通过集成或MC Dropout等方法估计的认知不确定性。这种策略的理论依据是，在模型最无知的区域添加数据点，能最快地填补知识空白，从而降低模型的全局误差。

#### 基于多样性的采集

另一种重要的策略是**基于多样性的采集**，它不依赖于模型的预测或不确定性，而是纯粹从几何角度出发，力求使已标记的数据点在构型空间（或更准确地说，在描述符空间）中[分布](@entry_id:182848)得尽可能均匀。一个典型的例子是**最远点采样 (Farthest Point Sampling, FPS)** ：
$$
a_{\text{FPS}}(\mathbf{R}) = \min_{i \in \{1, \dots, n\}} \|\phi(\mathbf{R}) - \phi(\mathbf{R}_i)\|_2
$$
该策略选择的构型，其描述符 $\phi(\mathbf{R})$ 与所有现有训练数据点的描述符距离都最远。这相当于贪婪地减小训练集的**覆盖半径 (covering radius)**，即确保构型空间中没有“巨大”的未探索空洞。

#### 策略比较与主动学习的优势

[不确定性采样](@entry_id:635527)和多样性采样各有优劣，在不同场景下适用：

- 在主动学习的**早期阶段**，当数据量很少时，模型本身（包括其[不确定性估计](@entry_id:191096)）可能非常不可靠。此时，模型无关的、稳健的 FPS 策略通常更受青睐，因为它能快速建立一个覆盖广泛的初始训练集，为后续更精细的探索打下基础 。
- 当模型经过初步训练，其[不确定性估计](@entry_id:191096)变得较为可靠时，最大[方差](@entry_id:200758)等[不确定性采样](@entry_id:635527)策略通常能更高效地降低[模型误差](@entry_id:175815)。

那么，为什么主动学习通常优于简单的被动[随机采样](@entry_id:175193)呢？从[统计学习理论](@entry_id:274291)的角度看，对于一个光滑的[势能面](@entry_id:147441)，模型的[泛化误差](@entry_id:637724)（在未见数据上的表现）与训练数据点的覆盖程度密切相关。通过像 FPS 或[不确定性采样](@entry_id:635527)这样智能地放置数据点，[主动学习](@entry_id:157812)能够比[随机采样](@entry_id:175193)更快地减小在重要区域（例如，由[玻尔兹曼分布](@entry_id:142765)决定的高概率区域）的**填充距离 (fill distance)**，从而以更少的查询次数达到相同的精度水平，即在固定的计算预算下获得更低的**[泛化误差](@entry_id:637724)** 。

### 实践挑战与机制优化

理论上的主动学习循环看似完美，但在实际应用中会遇到诸多挑战。成功的实践需要在工作流中加入额外的机制来应对这些问题。

#### 挑战一：不确定性的失准

我们用作代理的[认知不确定性](@entry_id:149866)估计（如集成[方差](@entry_id:200758)）并非总是完美的。它们可能存在系统性的高估或低估，即**失准 (miscalibration)**。一个失准的代理会误导采集决策。因此，对不确定性进行**校准 (calibration)** 至关重要 。

一个有效的校准测试是在一个留出的[验证集](@entry_id:636445)上进行的。例如，我们可以检查名义上的[置信区间](@entry_id:142297)（如 $\hat{\mu}(x) \pm 1.96 \hat{\sigma}(x)$）是否包含了真实的标签值。如果一个声称的 $95\%$ 置信区间在验证集上实际只包含了 $70\%$ 的数据，那么这个[不确定性估计](@entry_id:191096)就是过分自信的（即 $\hat{\sigma}$ 太小）。另一个实用的检查是计算[标准化](@entry_id:637219)的[均方根误差](@entry_id:170440)，一个校准良好的模型应该满足：
$$
\frac{1}{N_{\text{val}}} \sum_{i=1}^{N_{\text{val}}} \frac{(y_i - \hat{\mu}(x_i))^2}{\hat{\sigma}_{\text{pred}}^2(x_i)} \approx 1
$$
如果这个比率偏离 $1$，可以通过后处理方法（如[方差](@entry_id:200758)缩放）来校正不确定性的尺度。

#### 挑战二：对代理的“[过拟合](@entry_id:139093)”

一个更微妙的问题是，学习器可能会“[过拟合](@entry_id:139093)”到不确定性代理本身，特别是当代理函数错误地混淆了认知和[偶然不确定性](@entry_id:154011)时 。例如，如果[采集函数](@entry_id:168889)是简单的总[方差](@entry_id:200758) $\sigma_{\text{ep}}^2 + \sigma_{\text{al}}^2$，并且在某些构型区域，偶然不确定性 $\sigma_{\text{al}}^2$ 的变化远大于认知不确定性 $\sigma_{\text{ep}}^2$，那么学习器就会被误导去反复采样那些本质上“嘈杂”的区域，而这些区域的[信息增益](@entry_id:262008)可能很低。这种现象被称为**“追逐噪声” (chasing noise)**。

为了解决这个问题，可以采取以下优化措施：

1.  **采用更优的[采集函数](@entry_id:168889)**：放弃简单的[方差](@entry_id:200758)最大化，转而使用更具信息论基础的[采集函数](@entry_id:168889)，如**[信息增益](@entry_id:262008) (information gain)**。[信息增益](@entry_id:262008)近似于 $\log(1 + \sigma_{\text{ep}}^2 / \sigma_{\text{al}}^2)$，它自然地偏好认知不确定性相对于偶然不确定性较高的区域。

2.  **加入探索奖励 (Exploration Bonus)**：为了防止学习器“短视”地聚焦于已知的少数不确定区域，而忽略了广阔的未知空间，可以在[采集函数](@entry_id:168889)中加入一个**探索奖励项**。这个奖励项通常与[新构型](@entry_id:199611)到现有[训练集](@entry_id:636396)的距离成正比，如 $d(x) = \min_{x' \in \mathcal{D}} \|x-x'\|_M$，其中 $M$ 是[质量矩阵](@entry_id:177093)。这使得[采集函数](@entry_id:168889)在[信息增益](@entry_id:262008)和空间覆盖度之间取得平衡。
    $$
    a(x) = \underbrace{\frac{1}{2}\log\left(1 + \frac{\hat{\sigma}_{\text{ep}}^2(x)}{\hat{\sigma}_{\text{al}}^2(x)}\right)}_{\text{信息增益}} + \underbrace{\lambda d(x)}_{\text{探索奖励}}
    $$

#### 挑战三：模拟的稳定性

在“在线”或“在飞” (on-the-fly) 的[主动学习](@entry_id:157812)中，[势函数](@entry_id:176105)在 MD 模拟过程中被动态更新。这种突变可能导致严重的数值问题 。当一个新的、可能更“硬” (stiffer) 的[势函数](@entry_id:176105)被换上时，原有的[积分时间步长](@entry_id:162921) $\Delta t$ 可能不再适用，导致能量急剧不守恒，甚至模拟崩溃。

一个稳健的解决方案是引入**检查点与回滚 (checkpointing and rollback)** 机制。其工作原理如下：
1.  **设置检查点**：在准备更新[势函数](@entry_id:176105)时，保存当前的系统状态（位置、速度）和模拟参数（旧[势函数](@entry_id:176105)、时间步长）。
2.  **试运行**：使用新[势函数](@entry_id:176105)和当前时间步长，从检查点开始进行一个短暂的（例如几十步）试探性模拟。
3.  **监控稳定性**：在试运行期间，严格监控总能量的守恒情况。计算相对于试运行初始能量的最大相对漂移 $D_{\max}$。
4.  **决策**：
    - **接受**：如果[能量漂移](@entry_id:748982)在预设的容忍度 $\tau$ 之内 ($D_{\max} \le \tau$)，则认为更新是安全的，正式接受新[势函数](@entry_id:176105)。
    - **回滚与重试**：如果[能量漂移](@entry_id:748982)超标或模拟发散，则认为更新不安全。此时，系统状态**回滚**到检查点，并减小时间步长（例如 $\Delta t' = \gamma \Delta t, \gamma  1$），然后重新进行试运行。
    - **拒绝**：如果经过数次回滚和减小时间步长后，更新仍然无法通过稳定性测试，则最终**拒绝**此次[势函数](@entry_id:176105)更新，恢复使用旧的[势函数](@entry_id:176105)和参数继续模拟。

这种机制有效地耦合了学习器和采样器，确保了学习过程不会以牺牲物理模拟的完整性和稳定性为代价。它体现了在复杂多尺度问题中，将机器学习与传统物理建模相结合时必须考虑的严谨性和务实性。