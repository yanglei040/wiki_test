{
    "hands_on_practices": [
        {
            "introduction": "The foundation of microcanonical molecular dynamics lies in Hamilton's equations, which possess a crucial geometric property articulated by Liouville's theorem: the flow preserves volume in phase space. This practice provides a direct numerical experience with this principle by tasking you with comparing different numerical integrators . By computing the Jacobian determinant of the one-step flow map, you will discover why symplectic methods like Velocity Verlet are fundamental tools for stable long-time simulations, unlike their non-symplectic counterparts.",
            "id": "3435418",
            "problem": "Consider a Hamiltonian system for Molecular Dynamics (MD), where the phase space state is $x = (q, p) \\in \\mathbb{R}^{2N}$ with coordinates $q \\in \\mathbb{R}^{N}$ and momenta $p \\in \\mathbb{R}^{N}$. The Hamiltonian is $H(q,p) = \\sum_{i=1}^{N} \\frac{p_i^2}{2 m_i} + V(q)$ with masses $m_i > 0$ and a smooth potential $V(q)$. The exact Hamiltonian flow map $\\Phi_t : \\mathbb{R}^{2N} \\to \\mathbb{R}^{2N}$ evolves the state $x(t) = \\Phi_t(x(0))$ under Hamilton's equations $\\dot{q}_i = \\partial H / \\partial p_i$ and $\\dot{p}_i = -\\partial H / \\partial q_i$. Liouville’s theorem states that the phase-space volume is preserved by the exact flow, equivalently the Jacobian determinant $J(t) = \\det(D \\Phi_t(x))$ satisfies $J(t) = 1$ for all $t$. In microcanonical MD (constant energy), one commonly uses numerical integrators to approximate $\\Phi_{\\Delta t}$ for a small time step $\\Delta t$. In a discretized setting, the one-step map $\\Phi_{\\Delta t}$ may or may not exactly preserve phase-space volume, depending on whether the integrator is symplectic.\n\nYour task is to write a complete program that numerically estimates, at each time step, the Jacobian determinant $J = \\det(D \\Phi_{\\Delta t}(x))$ of the discrete one-step flow map around the current state $x$, using central finite differences, and then computes the maximum absolute deviation $\\max_{n} |J_n - 1|$ over a fixed number of steps. You must implement three one-step integrators: velocity Verlet (symplectic), classical fourth-order Runge–Kutta, and forward Euler (both non-symplectic in general). For each integrator and potential specified below, you will simulate the discrete dynamics for a fixed number of steps and report the maximum absolute deviation from unity of the per-step Jacobian determinant.\n\nUse dimensionless units throughout. The Jacobian matrix $D \\Phi_{\\Delta t}(x) \\in \\mathbb{R}^{2N \\times 2N}$ must be estimated numerically by central finite differences: for a small perturbation size $\\varepsilon > 0$ and the canonical basis vectors $e_j \\in \\mathbb{R}^{2N}$, estimate the $j$-th column by\n$$\n[D \\Phi_{\\Delta t}(x)]_{\\cdot j} \\approx \\frac{\\Phi_{\\Delta t}(x + \\varepsilon e_j) - \\Phi_{\\Delta t}(x - \\varepsilon e_j)}{2 \\varepsilon}.\n$$\nThen compute $J = \\det(D \\Phi_{\\Delta t}(x))$ using a standard determinant routine. At each time step $n$, record $|J_n - 1|$, update the state $x \\leftarrow \\Phi_{\\Delta t}(x)$, and continue.\n\nThe system is defined by Hamilton’s equations $\\dot{q} = p / m$ and $\\dot{p} = -\\nabla V(q)$, where division $p/m$ is elementwise for $p \\in \\mathbb{R}^{N}$ and $m \\in \\mathbb{R}^{N}$. Implement the following potentials $V(q)$ and their gradients $\\nabla V(q)$:\n\n- Harmonic oscillator in $1$ dimension: $V(q) = \\tfrac{1}{2} k q^2$ with gradient $\\nabla V(q) = k q$.\n- Coupled harmonic in $2$ dimensions: $V(q_1,q_2) = \\tfrac{1}{2} k (q_1^2 + q_2^2) + \\alpha q_1 q_2$ with gradient $\\nabla V(q) = (k q_1 + \\alpha q_2, k q_2 + \\alpha q_1)$.\n- Quartic-plus-quadratic in $1$ dimension: $V(q) = \\tfrac{1}{2} k q^2 + \\tfrac{1}{4} \\lambda q^4$ with gradient $\\nabla V(q) = k q + \\lambda q^3$.\n\nImplement the following one-step integrators for the state $x = (q,p)$:\n\n- Velocity Verlet: $p_{n+\\frac{1}{2}} = p_n - \\frac{\\Delta t}{2} \\nabla V(q_n)$, $q_{n+1} = q_n + \\Delta t \\, p_{n+\\frac{1}{2}}/m$, $p_{n+1} = p_{n+\\frac{1}{2}} - \\frac{\\Delta t}{2} \\nabla V(q_{n+1})$.\n- Classical fourth-order Runge–Kutta applied to the first-order system $\\dot{q} = p/m$, $\\dot{p} = -\\nabla V(q)$.\n- Forward Euler: $q_{n+1} = q_n + \\Delta t \\, p_n/m$, $p_{n+1} = p_n - \\Delta t \\, \\nabla V(q_n)$.\n\nFor numerical stability and accuracy, use central finite differences with a small step $\\varepsilon$ for the Jacobian estimation of the one-step map at the current state.\n\nTest Suite:\nYou must implement the following four test cases and, for each case, compute the single scalar output $\\max_{0 \\le n < N_{\\text{steps}}} |J_n - 1|$, where $J_n$ is the Jacobian determinant estimated at step $n$.\n\n- Case $1$: $N = 1$, $m = 1$, harmonic potential with $k = 1$, velocity Verlet integrator, $\\Delta t = 0.01$, $N_{\\text{steps}} = 1000$, initial state $(q_0, p_0) = (1.0, 0.0)$, finite difference $\\varepsilon = 10^{-8}$.\n- Case $2$: $N = 1$, $m = 1$, harmonic potential with $k = 1$, classical fourth-order Runge–Kutta integrator, $\\Delta t = 0.05$, $N_{\\text{steps}} = 200$, initial state $(q_0, p_0) = (1.0, 0.0)$, finite difference $\\varepsilon = 10^{-8}$.\n- Case $3$: $N = 2$, $m = (1, 1)$, coupled harmonic potential with $k = 1$, $\\alpha = 0.1$, velocity Verlet integrator, $\\Delta t = 0.01$, $N_{\\text{steps}} = 500$, initial state $(q_0, p_0) = ((0.5, -0.5), (0.0, 0.0))$, finite difference $\\varepsilon = 10^{-8}$.\n- Case $4$: $N = 1$, $m = 1$, quartic-plus-quadratic potential with $k = 1$, $\\lambda = 0.5$, forward Euler integrator, $\\Delta t = 0.01$, $N_{\\text{steps}} = 300$, initial state $(q_0, p_0) = (0.2, 0.5)$, finite difference $\\varepsilon = 10^{-8}$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases $1$ through $4$. Each entry must be a floating-point number equal to the maximum absolute deviation from unity of the per-step Jacobian determinant over the specified number of steps for that test case. For example, the output format must be of the form $[r_1,r_2,r_3,r_4]$ where each $r_i$ is a float computed by your program.",
            "solution": "The problem requires a numerical investigation into the phase-space volume-preservation properties of three different numerical integration schemes used in molecular dynamics. According to Liouville's theorem for Hamiltonian systems, the exact time evolution flow $\\Phi_t$ is volume-preserving. This means the determinant of its Jacobian matrix, $J(t) = \\det(D\\Phi_t)$, is identically equal to $1$ for all time $t$. Numerical integrators provide an approximation to this flow over a small time step, $\\Phi_{\\Delta t}$. Integrators that exactly preserve this property, i.e., for which the one-step map has a Jacobian determinant of $1$, are called symplectic. This property is crucial for the long-term stability and accuracy of molecular dynamics simulations, particularly in the microcanonical ensemble where total energy should be conserved.\n\nThis solution will implement the specified integrators and numerically estimate the Jacobian determinant of their one-step maps at each step of a simulation. The primary metric of interest is the maximum absolute deviation of this determinant from unity, $\\max_{n} |J_n - 1|$, over a trajectory of a specified number of steps, $N_{\\text{steps}}$.\n\n### State Representation and Jacobian Estimation\nThe state of a system with $N$ degrees of freedom is represented by a vector $x = (q, p) \\in \\mathbb{R}^{2N}$, where $q \\in \\mathbb{R}^N$ are the generalized coordinates and $p \\in \\mathbb{R}^N$ are the conjugate momenta. For implementation, this state is stored as a single flat array of length $2N$.\n\nThe Jacobian of the one-step map, $D\\Phi_{\\Delta t}(x)$, is a $2N \\times 2N$ matrix. We estimate this matrix using the central finite difference method. For each canonical basis vector $e_j \\in \\mathbb{R}^{2N}$ (where $e_j$ has a $1$ at index $j$ and $0$s elsewhere), the $j$-th column of the Jacobian matrix is approximated by:\n$$\n[D \\Phi_{\\Delta t}(x)]_{\\cdot j} \\approx \\frac{\\Phi_{\\Delta t}(x + \\varepsilon e_j) - \\Phi_{\\Delta t}(x - \\varepsilon e_j)}{2 \\varepsilon}\n$$\nHere, $\\Phi_{\\Delta t}$ represents the action of one of the numerical integrators for a time step $\\Delta t$, and $\\varepsilon$ is a small perturbation parameter. Once the full Jacobian matrix is constructed column by column, its determinant $J = \\det(D \\Phi_{\\Delta t}(x))$ is computed using a standard numerical linear algebra routine.\n\n### Hamiltonian System and Potentials\nThe system dynamics are governed by a Hamiltonian of the form $H(q,p) = K(p) + V(q)$, which is separable into a kinetic energy term $K(p) = \\sum_{i=1}^{N} \\frac{p_i^2}{2 m_i}$ and a potential energy term $V(q)$. The equations of motion are given by Hamilton's equations:\n$$\n\\dot{q} = \\frac{\\partial H}{\\partial p} = \\frac{p}{m} \\quad \\text{and} \\quad \\dot{p} = -\\frac{\\partial H}{\\partial q} = -\\nabla V(q)\n$$\nThe specific potentials and their gradients required for the test cases are:\n1.  **Harmonic Oscillator ($N=1$):**\n    $V(q) = \\frac{1}{2} k q^2$\n    $\\nabla V(q) = k q$\n\n2.  **Coupled Harmonic Oscillators ($N=2$):**\n    $V(q_1, q_2) = \\frac{1}{2} k (q_1^2 + q_2^2) + \\alpha q_1 q_2$\n    $\\nabla V(q) = \\begin{pmatrix} k q_1 + \\alpha q_2 \\\\ k q_2 + \\alpha q_1 \\end{pmatrix}$\n\n3.  **Quartic-plus-Quadratic Potential ($N=1$):**\n    $V(q) = \\frac{1}{2} k q^2 + \\frac{1}{4} \\lambda q^4$\n    $\\nabla V(q) = k q + \\lambda q^3$\n\n### Numerical Integrators\nThree one-step integrators, $\\Phi_{\\Delta t}$, are implemented to advance the state from $x_n = (q_n, p_n)$ to $x_{n+1} = (q_{n+1}, p_{n+1})$.\n\n1.  **Velocity Verlet:** This is a second-order, symplectic integrator for separable Hamiltonians. Its symplecticity implies that the Jacobian determinant of its exact map (without floating-point errors) is $1$. The update rules are:\n    $$\n    p_{n+\\frac{1}{2}} = p_n - \\frac{\\Delta t}{2} \\nabla V(q_n) \\\\\n    q_{n+1} = q_n + \\Delta t \\, \\frac{p_{n+\\frac{1}{2}}}{m} \\\\\n    p_{n+1} = p_{n+\\frac{1}{2}} - \\frac{\\Delta t}{2} \\nabla V(q_{n+1})\n    $$\n\n2.  **Classical Fourth-Order Runge–Kutta (RK4):** This is a general-purpose, high-order, but non-symplectic integrator. For an autonomous system $\\dot{y} = f(y)$, the update rule is:\n    $$\n    k_1 = \\Delta t \\cdot f(y_n) \\\\\n    k_2 = \\Delta t \\cdot f(y_n + \\frac{1}{2} k_1) \\\\\n    k_3 = \\Delta t \\cdot f(y_n + \\frac{1}{2} k_2) \\\\\n    k_4 = \\Delta t \\cdot f(y_n + k_3) \\\\\n    y_{n+1} = y_n + \\frac{1}{6}(k_1 + 2k_2 + 2k_3 + k_4)\n    $$\n    In our case, the state is $y=x=(q,p)$, and the derivative function is $f(x) = (\\frac{p}{m}, -\\nabla V(q))$. Although RK4 is highly accurate for a single step, its non-symplecticity leads to a Jacobian determinant not equal to $1$.\n\n3.  **Forward Euler:** This is a first-order, explicit, and non-symplectic integrator. It is simple but generally not suitable for long-term Hamiltonian dynamics due to its poor stability and energy conservation properties. Its update rules are:\n    $$\n    q_{n+1} = q_n + \\Delta t \\, \\frac{p_n}{m} \\\\\n    p_{n+1} = p_n - \\Delta t \\, \\nabla V(q_n)\n    $$\n    This method is expected to show significant deviation from volume preservation.\n\n### Simulation and Analysis Algorithm\nFor each of the four test cases, the following procedure is executed:\n1.  Initialize the state $x_0 = (q_0, p_0)$, simulation parameters ($\\Delta t, N_{\\text{steps}}, \\varepsilon$), and system properties ($m$, potential parameters).\n2.  Select the appropriate integrator $\\Phi_{\\Delta t}$ and gradient function $\\nabla V(q)$.\n3.  Initialize a variable `max_deviation = 0`.\n4.  Loop for $n$ from $0$ to $N_{\\text{steps}}-1$:\n    a.  At the current state $x_n$, construct the Jacobian matrix $D\\Phi_{\\Delta t}(x_n)$ using the central finite difference formula.\n    b.  Compute its determinant, $J_n = \\det(D\\Phi_{\\Delta t}(x_n))$.\n    c.  Update `max_deviation` with $\\max(\\text{max\\_deviation}, |J_n - 1|)$.\n    d.  Advance the state to the next step: $x_{n+1} = \\Phi_{\\Delta t}(x_n)$.\n5.  After the loop terminates, the final value of `max_deviation` is the result for the test case.\n\nThe expected results are that for the symplectic velocity Verlet integrator (Cases 1 and 3), the computed deviation will be on the order of machine precision, resulting from floating-point arithmetic and the finite difference approximation error. For the non-symplectic RK4 and Forward Euler integrators (Cases 2 and 4), the deviation is expected to be significantly larger, reflecting the intrinsic volume-distorting nature of these algorithms.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import linalg # numpy.linalg.det is sufficient\n\n# --- Potential Gradients ---\n\ndef harmonic_gradient(q, k):\n    \"\"\"Gradient of the 1D harmonic potential.\"\"\"\n    return k * q\n\ndef coupled_harmonic_gradient(q, k, alpha):\n    \"\"\"Gradient of the 2D coupled harmonic potential.\"\"\"\n    q1, q2 = q\n    grad1 = k * q1 + alpha * q2\n    grad2 = k * q2 + alpha * q1\n    return np.array([grad1, grad2])\n\ndef quartic_gradient(q, k, lam):\n    \"\"\"Gradient of the 1D quartic-plus-quadratic potential.\"\"\"\n    return k * q + lam * q**3\n\n# --- Numerical Integrators (One-Step Maps) ---\n\ndef velocity_verlet(x, N, dt, m, grad_V_func):\n    \"\"\"Velocity Verlet integrator for one time step.\"\"\"\n    q = x[:N]\n    p = x[N:]\n    \n    p_half = p - (dt / 2.0) * grad_V_func(q)\n    q_new = q + dt * p_half / m\n    p_new = p_half - (dt / 2.0) * grad_V_func(q_new)\n    \n    return np.concatenate((q_new, p_new))\n\ndef forward_euler(x, N, dt, m, grad_V_func):\n    \"\"\"Forward Euler integrator for one time step.\"\"\"\n    q = x[:N]\n    p = x[N:]\n    \n    q_new = q + dt * p / m\n    p_new = p - dt * grad_V_func(q)\n    \n    return np.concatenate((q_new, p_new))\n\ndef rk4(x, N, dt, m, grad_V_func):\n    \"\"\"Classical fourth-order Runge-Kutta integrator for one time step.\"\"\"\n    \n    def f(state):\n        _q = state[:N]\n        _p = state[N:]\n        return np.concatenate((_p / m, -grad_V_func(_q)))\n\n    k1 = dt * f(x)\n    k2 = dt * f(x + 0.5 * k1)\n    k3 = dt * f(x + 0.5 * k2)\n    k4 = dt * f(x + k3)\n    \n    x_new = x + (k1 + 2*k2 + 2*k3 + k4) / 6.0\n    return x_new\n\n# --- Jacobian Estimation ---\n\ndef estimate_jacobian_determinant(one_step_map, x, N, eps):\n    \"\"\"\n    Estimates the Jacobian determinant of a one-step map using central finite differences.\n    - one_step_map: A function representing the integrator, Phi_dt(x).\n    - x: The current state vector [q, p].\n    - N: The number of spatial dimensions.\n    - eps: The finite difference perturbation size.\n    \"\"\"\n    dim = 2 * N\n    jacobian_matrix = np.zeros((dim, dim))\n    \n    for j in range(dim):\n        x_plus = x.copy()\n        x_minus = x.copy()\n        \n        x_plus[j] += eps\n        x_minus[j] -= eps\n        \n        phi_plus = one_step_map(x_plus)\n        phi_minus = one_step_map(x_minus)\n        \n        # This is the j-th column of the Jacobian\n        jacobian_matrix[:, j] = (phi_plus - phi_minus) / (2.0 * eps)\n        \n    return np.linalg.det(jacobian_matrix)\n\n# --- Simulation Runner ---\n\ndef run_simulation(case):\n    \"\"\"\n    Runs a single simulation case and computes the max Jacobian determinant deviation.\n    \"\"\"\n    N = case['N']\n    m = np.array(case['m'])\n    q0 = np.array(case['q0'])\n    p0 = np.array(case['p0'])\n    dt = case['dt']\n    n_steps = case['n_steps']\n    eps = case['eps']\n    \n    # Set up integrator function\n    integrators = {\n        'verlet': velocity_verlet,\n        'rk4': rk4,\n        'euler': forward_euler\n    }\n    integrator_func = integrators[case['integrator_name']]\n    \n    # Set up potential gradient function with its parameters\n    if case['potential_name'] == 'harmonic':\n        grad_V_func = lambda q: harmonic_gradient(q, k=case['params']['k'])\n    elif case['potential_name'] == 'coupled_harmonic':\n        grad_V_func = lambda q: coupled_harmonic_gradient(q, k=case['params']['k'], alpha=case['params']['alpha'])\n    elif case['potential_name'] == 'quartic':\n        grad_V_func = lambda q: quartic_gradient(q, k=case['params']['k'], lam=case['params']['lambda'])\n\n    # Create the one-step map as a function of state only\n    one_step_map = lambda state: integrator_func(state, N, dt, m, grad_V_func)\n\n    # Main simulation loop\n    x = np.concatenate((q0, p0))\n    max_deviation = 0.0\n    \n    for _ in range(n_steps):\n        # Estimate Jacobian determinant at the current state x\n        J_n = estimate_jacobian_determinant(one_step_map, x, N, eps)\n        \n        # Update max deviation\n        deviation = abs(J_n - 1.0)\n        if deviation > max_deviation:\n            max_deviation = deviation\n            \n        # Advance the state for the next step\n        x = one_step_map(x)\n        \n    return max_deviation\n\n# --- Main Solver ---\ndef solve():\n    \"\"\"\n    Defines and runs the test cases specified in the problem statement.\n    \"\"\"\n    test_cases = [\n        {\n            'N': 1, 'm': [1.0], 'potential_name': 'harmonic', 'params': {'k': 1.0},\n            'integrator_name': 'verlet', 'dt': 0.01, 'n_steps': 1000,\n            'q0': [1.0], 'p0': [0.0], 'eps': 1e-8\n        },\n        {\n            'N': 1, 'm': [1.0], 'potential_name': 'harmonic', 'params': {'k': 1.0},\n            'integrator_name': 'rk4', 'dt': 0.05, 'n_steps': 200,\n            'q0': [1.0], 'p0': [0.0], 'eps': 1e-8\n        },\n        {\n            'N': 2, 'm': [1.0, 1.0], 'potential_name': 'coupled_harmonic', 'params': {'k': 1.0, 'alpha': 0.1},\n            'integrator_name': 'verlet', 'dt': 0.01, 'n_steps': 500,\n            'q0': [0.5, -0.5], 'p0': [0.0, 0.0], 'eps': 1e-8\n        },\n        {\n            'N': 1, 'm': [1.0], 'potential_name': 'quartic', 'params': {'k': 1.0, 'lambda': 0.5},\n            'integrator_name': 'euler', 'dt': 0.01, 'n_steps': 300,\n            'q0': [0.2], 'p0': [0.5], 'eps': 1e-8\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_simulation(case)\n        results.append(result)\n\n    # Format the output as specified\n    print(f\"[{','.join(f'{r:.16f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "With a reliable symplectic integrator in hand, we can explore the intricate structure of phase space for systems with interesting dynamics. This exercise uses the classic double-well potential—a model for chemical reactions—to introduce the concept of the separatrix: a phase-space surface that partitions trajectories into qualitatively different futures . By simulating particles with initial conditions near this critical boundary, you will map out the \"basins of attraction\" for being trapped in either well versus roaming freely, gaining an intuitive feel for how a trajectory's ultimate fate is encoded in its starting point.",
            "id": "3435429",
            "problem": "Consider a single classical particle of unit mass in one spatial dimension moving in a symmetric double-well potential under Hamiltonian dynamics. The Hamiltonian is $H(x,p) = \\dfrac{p^2}{2} + V(x)$ with $m=1$ and the potential $V(x) = \\dfrac{(x^2 - 1)^2}{4}$. All quantities are nondimensional; no physical units are used. The equations of motion follow from Newton's second law and Hamilton's equations, namely $\\dot{x} = \\dfrac{\\partial H}{\\partial p}$ and $\\dot{p} = -\\dfrac{\\partial H}{\\partial x}$. The phase space separatrix divides initial conditions that remain trapped in a single well from those that traverse between the two wells. Your goal is to identify the separatrix by fundamental principles and then numerically map the long-time fate of trajectories as a function of initial conditions across this boundary.\n\nTasks:\n- Starting from the definitions, determine the phase space separatrix energy by identifying stationary points of $V(x)$ through $V'(x) = 0$, classifying their stability via $V''(x)$, and using the Hamiltonian at the unstable stationary point to define the separatrix energy $E_{\\mathrm{sep}}$. Do not use any pre-known or shortcut formulas; determine the stationary points and their nature directly from $V(x)$.\n- Implement a symplectic time integrator based on first principles (for example, the velocity-Verlet scheme derived from Hamilton's equations) to evolve trajectories from specified initial conditions $(x_0,p_0)$ over a long time. Use a fixed time step $\\Delta t = 10^{-3}$ and integrate up to total time $T = 200$.\n- For each trajectory, classify its long-time fate solely from the simulated time series as follows. Let $f_L$ be the fraction of steps with $x(t) < 0$ and $f_R$ the fraction with $x(t) > 0$, ignoring steps where $|x(t)|$ is within a small buffer $\\delta_x = 10^{-3}$ around the separatrix coordinate $x=0$. If the trajectory remains within a tiny neighborhood of the saddle (detected by $\\max_t |x(t)| < \\delta_x$ and $\\max_t |p(t)| < \\delta_p$ with $\\delta_p = 10^{-6}$), classify it as separatrix-stuck. Otherwise, if $f_L > 0.95$ and $f_R < 0.05$, classify it as left-well trapped; if $f_R > 0.95$ and $f_L < 0.05$, classify it as right-well trapped; else classify it as roaming between wells.\n- Encode the classification as an integer code $c$ for each trajectory: left-well trapped $c=-1$, right-well trapped $c=+1$, roaming $c=0$, separatrix-stuck $c=2$.\n\nTest suite:\nSimulate the following initial conditions $(x_0,p_0)$, expressed as ordered pairs of real numbers: \n$(-1.2,0.0)$, $(1.2,0.0)$, $(0.0,1.0)$, $(0.0,0.0)$, $(0.01,0.0)$, $(-0.01,0.0)$, $(0.01,0.2)$.\nThese cases collectively probe a happy-path trapped case in each well, an above-barrier roaming case, the exact saddle, and near-separatrix sensitivity on both sides.\n\nFinal output specification:\nYour program should produce a single line of output containing the classification results for the test suite, in the same order as listed above, as a comma-separated list of integers enclosed in square brackets (for example, $[c_1,c_2,\\dots]$). No additional text should be printed. All computations are to be performed in nondimensional form as stated above. The required output is unitless and contains only integers. Angles are not involved in this problem. The only acceptable outputs are booleans, integers, floats, or lists thereof; here, the required output is a list of integers.",
            "solution": "The problem requires an analysis and numerical simulation of a particle's motion in a one-dimensional double-well potential. The solution proceeds in three stages: first, an analytical characterization of the system's key features, such as equilibrium points and the separatrix energy; second, the formulation of a suitable numerical integration scheme; and third, the implementation of a classification algorithm to determine the long-term fate of trajectories.\n\nThe system is described by the Hamiltonian $H(x,p) = \\frac{p^2}{2m} + V(x)$, with mass $m=1$ and potential $V(x) = \\frac{1}{4}(x^2 - 1)^2$. All quantities are dimensionless. The equations of motion are derived from Hamilton's equations:\n$$ \\dot{x} = \\frac{\\partial H}{\\partial p} = \\frac{p}{m} = p $$\n$$ \\dot{p} = -\\frac{\\partial H}{\\partial x} = -\\frac{dV}{dx} $$\n\nFirst, we must determine the phase space separatrix, which is defined by the energy level of the unstable equilibrium points (saddle points in phase space). We find the equilibrium positions by identifying the stationary points of the potential $V(x)$, where the force $F(x) = -V'(x)$ is zero.\nThe potential is $V(x) = \\frac{1}{4}(x^4 - 2x^2 + 1)$.\nThe first derivative is:\n$$ V'(x) = \\frac{d}{dx} \\left[ \\frac{1}{4}(x^4 - 2x^2 + 1) \\right] = \\frac{1}{4}(4x^3 - 4x) = x^3 - x $$\nSetting $V'(x)=0$ to find the stationary points:\n$$ x^3 - x = x(x^2 - 1) = x(x-1)(x+1) = 0 $$\nThe stationary points are located at $x = -1$, $x = 0$, and $x = +1$.\n\nTo classify the stability of these points, we examine the second derivative of the potential, $V''(x)$:\n$$ V''(x) = \\frac{d}{dx}(x^3 - x) = 3x^2 - 1 $$\nWe evaluate $V''(x)$ at each stationary point:\n- At $x = -1$: $V''(-1) = 3(-1)^2 - 1 = 2 > 0$. This indicates a local potential minimum, corresponding to a stable equilibrium.\n- At $x = +1$: $V''(+1) = 3(1)^2 - 1 = 2 > 0$. This also indicates a local potential minimum, a stable equilibrium.\n- At $x = 0$: $V''(0) = 3(0)^2 - 1 = -1 < 0$. This indicates a local potential maximum, corresponding to an unstable equilibrium.\n\nThe separatrix is the trajectory that passes through the unstable equilibrium point. In phase space, this point is $(x,p) = (0,0)$, as the particle must be at rest at the peak of the potential barrier. The energy of this trajectory defines the separatrix energy, $E_{\\mathrm{sep}}$:\n$$ E_{\\mathrm{sep}} = H(0,0) = \\frac{0^2}{2} + V(0) = \\frac{(0^2 - 1)^2}{4} = \\frac{1}{4} = 0.25 $$\nTrajectories with total energy $E < E_{\\mathrm{sep}}$ are confined to one of the potential wells, while trajectories with $E > E_{\\mathrm{sep}}$ can roam between the two wells. Trajectories with $E = E_{\\mathrm{sep}}$ lie on the separatrix itself.\n\nTo simulate the trajectories, we employ a symplectic integrator, specifically the velocity-Verlet algorithm, which is well-suited for long-term integration of Hamiltonian systems due to its good energy conservation properties. For a particle of mass $m=1$, the algorithm is derived from a Taylor expansion of the position and consists of the following steps for a time step $\\Delta t$:\n1. Update the position: $x(t + \\Delta t) = x(t) + p(t)\\Delta t + \\frac{1}{2} F(x(t)) \\Delta t^2$.\n2. Compute the force at the new position: $F(x(t + \\Delta t)) = -V'(x(t + \\Delta t))$.\n3. Update the momentum: $p(t + \\Delta t) = p(t) + \\frac{1}{2} [F(x(t)) + F(x(t + \\Delta t))] \\Delta t$.\nHere, the force is $F(x) = -V'(x) = -(x^3 - x) = x - x^3$. The simulation will run from $t=0$ to $T=200$ with a time step of $\\Delta t = 10^{-3}$.\n\nFinally, each simulated trajectory, represented by the time series $\\{x(t_i), p(t_i)\\}$, must be classified. The classification is performed according to a prescribed set of rules.\nFirst, we check if the trajectory is \"stuck\" at the saddle point $(0,0)$. This is the case if the maximum absolute position and momentum values throughout the simulation are below specified thresholds: $\\max_t |x(t)| < \\delta_x$ and $\\max_t |p(t)| < \\delta_p$, where $\\delta_x = 10^{-3}$ and $\\delta_p = 10^{-6}$. If so, the trajectory is assigned the code $c=2$.\n\nIf the trajectory is not stuck, we analyze its distribution across the two potential wells. We calculate the fraction of time steps the particle spends in the left well ($x(t) < 0$) and the right well ($x(t) > 0$), ignoring any steps where the particle is within a small buffer zone around the origin, i.e., $|x(t)| \\le \\delta_x$. Let $N_L$ be the count of steps where $x(t) < -\\delta_x$, and $N_R$ be the count where $x(t) > \\delta_x$. The total number of relevant steps is $N_{total} = N_L + N_R$. The fractions are then $f_L = N_L / N_{total}$ and $f_R = N_R / N_{total}$.\nThe classification is then:\n- Left-well trapped ($c=-1$): If $f_L > 0.95$ and $f_R < 0.05$.\n- Right-well trapped ($c=+1$): If $f_R > 0.95$ and $f_L < 0.05$.\n- Roaming ($c=0$): Otherwise.\n\nThe following Python code implements this entire procedure, applying it to the specified suite of initial conditions and producing the required output format.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of classifying trajectories in a double-well potential.\n    \"\"\"\n\n    def run_simulation(x0, p0, dt, T):\n        \"\"\"\n        Integrates a trajectory using the velocity-Verlet algorithm.\n        \n        Args:\n            x0 (float): Initial position.\n            p0 (float): Initial momentum.\n            dt (float): Time step.\n            T (float): Total integration time.\n\n        Returns:\n            tuple: A tuple containing arrays for the position and momentum trajectories.\n        \"\"\"\n        num_steps = int(T / dt)\n        x = float(x0)\n        p = float(p0)\n        \n        x_traj = np.zeros(num_steps + 1)\n        p_traj = np.zeros(num_steps + 1)\n        x_traj[0] = x\n        p_traj[0] = p\n        \n        def force(pos):\n            \"\"\"Calculates the force F(x) = -V'(x) = x - x^3.\"\"\"\n            return pos - pos**3\n\n        for i in range(num_steps):\n            F_current = force(x)\n            # Update position\n            x_next = x + p * dt + 0.5 * F_current * dt**2\n            # Update force\n            F_next = force(x_next)\n            # Update momentum\n            p_next = p + 0.5 * (F_current + F_next) * dt\n            \n            x = x_next\n            p = p_next\n            \n            x_traj[i+1] = x\n            p_traj[i+1] = p\n            \n        return x_traj, p_traj\n\n    def classify_trajectory(x_traj, p_traj):\n        \"\"\"\n        Classifies a trajectory based on its long-term behavior.\n\n        Args:\n            x_traj (np.array): Array of position values over time.\n            p_traj (np.array): Array of momentum values over time.\n\n        Returns:\n            int: Classification code (-1, 1, 0, or 2).\n        \"\"\"\n        delta_x = 1e-3\n        delta_p = 1e-6\n\n        # Rule 1: Check for separatrix-stuck condition\n        if np.max(np.abs(x_traj))  delta_x and np.max(np.abs(p_traj))  delta_p:\n            return 2\n\n        # Rules 2-4: Analyze well-trapping vs. roaming\n        # Ignore points within the buffer zone |x| = delta_x\n        relevant_x_points = x_traj[np.abs(x_traj) > delta_x]\n        \n        if relevant_x_points.size == 0:\n            # Trajectory stayed entirely within the x buffer but didn't meet the 'stuck'\n            # momentum requirement. This is an edge case, but most consistent to classify\n            # as roaming, as it is neither definitively left nor right trapped.\n            return 0\n            \n        count_L = np.sum(relevant_x_points  0)\n        count_R = np.sum(relevant_x_points > 0)\n        count_total = relevant_x_points.size\n\n        f_L = count_L / count_total\n        f_R = count_R / count_total\n\n        if f_L > 0.95 and f_R  0.05:\n            return -1  # Left-well trapped\n        elif f_R > 0.95 and f_L  0.05:\n            return 1   # Right-well trapped\n        else:\n            return 0   # Roaming\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (-1.2, 0.0),\n        (1.2, 0.0),\n        (0.0, 1.0),\n        (0.0, 0.0),\n        (0.01, 0.0),\n        (-0.01, 0.0),\n        (0.01, 0.2),\n    ]\n\n    # Simulation parameters\n    dt = 1e-3\n    T = 200.0\n\n    results = []\n    for x0, p0 in test_cases:\n        x_trajectory, p_trajectory = run_simulation(x0, p0, dt, T)\n        classification = classify_trajectory(x_trajectory, p_trajectory)\n        results.append(classification)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "This final practice delves into the sophisticated world of geometric integrators, highlighting that preserving phase-space volume is not the only possible design goal. Here, you will derive and analyze an integrator that, for the harmonic oscillator, exactly preserves the total energy—a property that standard symplectic methods only approximate . This exercise reveals a subtle but profound trade-off: perfect energy conservation is achieved at the expense of a predictable error in the oscillation's phase, underscoring that the choice of integrator involves a deliberate decision about which physical invariants are most critical to maintain.",
            "id": "3435368",
            "problem": "You are asked to design and analyze a one-step numerical integrator for the one-dimensional harmonic oscillator that exactly preserves the Hamiltonian energy and to quantify long-time phase-space fidelity in terms of phase precession. The context is molecular dynamics phase space dynamics and trajectories. The harmonic oscillator is defined by the Hamiltonian\n$$\nH(x,p) = \\frac{p^2}{2 m} + \\frac{k x^2}{2},\n$$\nwith mass $m$ (in $\\mathrm{kg}$), stiffness $k$ (in $\\mathrm{N}/\\mathrm{m}$), position $x$ (in $\\mathrm{m}$), and momentum $p$ (in $\\mathrm{kg}\\cdot\\mathrm{m}/\\mathrm{s}$). The exact flow preserves both $H$ and the phase-space ellipse and advances the phase at constant angular frequency\n$$\n\\omega = \\sqrt{\\frac{k}{m}}\n$$\n(in $\\mathrm{rad}/\\mathrm{s}$). Your task is to derive, implement, and evaluate an energy-preserving integrator from first principles.\n\nDesign requirement for the integrator:\n- Start from Hamilton’s equations,\n$$\n\\dot{x} = \\frac{\\partial H}{\\partial p} = \\frac{p}{m}, \\qquad \\dot{p} = -\\frac{\\partial H}{\\partial x} = -k x,\n$$\nand the canonical compact form\n$$\n\\dot{y} = J \\nabla H(y), \\quad \\text{where } y = \\begin{bmatrix} x \\\\ p \\end{bmatrix}, \\quad J = \\begin{bmatrix} 0  1 \\\\ -1  0 \\end{bmatrix}.\n$$\n- Use the Average Vector Field (AVF) discrete gradient construction, which for a general Hamiltonian $H$ defines the step from $y_n$ to $y_{n+1}$ with time step $h$ (in $\\mathrm{s}$) by\n$$\n\\frac{y_{n+1} - y_n}{h} = \\int_0^1 J \\nabla H\\!\\left((1-\\xi)\\, y_n + \\xi\\, y_{n+1}\\right)\\, d\\xi.\n$$\n- Specialize this to the harmonic oscillator Hamiltonian above and derive the resulting practical one-step method.\n\nAnalysis requirements:\n- Prove from first principles that for the harmonic oscillator the resulting method preserves the Hamiltonian $H$ exactly for any time step $h$.\n- Show that the one-step map is a linear phase-space rotation with a discrete angular advance per step $\\varphi$ that depends on $h$ and $\\omega$, and derive a closed-form expression for $\\varphi$ and the corresponding modified frequency\n$$\n\\tilde{\\omega} = \\frac{\\varphi}{h}.\n$$\n- Define the phase at time $t$ as the angle in the scaled phase-space coordinates, and define the phase precession error over a total integration time $T$ (in $\\mathrm{s}$) as the principal value in the interval $[-\\pi,\\pi]$ (in $\\mathrm{rad}$) of\n$$\n\\Delta\\theta(T) = N \\left(\\varphi - \\omega h \\right), \\quad \\text{where } N = \\frac{T}{h} \\in \\mathbb{N}.\n$$\nUse the wrap-to-principal-branch operation\n$$\n\\mathrm{wrap}_{[-\\pi,\\pi]}(\\alpha) = \\left((\\alpha + \\pi) \\bmod 2\\pi \\right) - \\pi,\n$$\nwith all angles in radians.\n\nTest suite and required outputs:\n- For each test case, compute two quantities:\n  $1.$ The maximum absolute Hamiltonian drift over the interval $[0,T]$,\n  $$\n  \\max_{0 \\le n \\le N} \\left| H(x_n,p_n) - H(x_0,p_0) \\right|,\n  $$\n  expressed in $\\mathrm{J}$ (Joules).\n  $2.$ The final principal phase precession error $\\Delta\\theta(T)$, expressed in radians.\n- Express the Hamiltonian drift in $\\mathrm{J}$ and the phase error in radians. Angles must be in radians. Round both outputs for each test to $12$ decimal places.\n- You must not perform step-by-step forward simulation to estimate the phase drift. Instead, use your derived closed-form expressions for the per-step angular advance $\\varphi$ and the modified frequency $\\tilde{\\omega}$ to compute $\\Delta\\theta(T)$ directly. You may use the exact structure of your derived map to conclude the Hamiltonian drift.\n\nUse the following four test cases (all units are in the International System of Units):\n- Test $1$: $m = 1$, $k = 1$, $x_0 = 1$, $p_0 = 0$, $h = 0.1$, $T = 1000$.\n- Test $2$: $m = 1.5$, $k = 400$, $x_0 = 0.02$, $p_0 = 0.1$, $h = 0.0005$, $T = 0.5$.\n- Test $3$: $m = 2$, $k = 8$, $x_0 = 1$, $p_0 = 1$, $h = 1.0$, $T = 1000$.\n- Test $4$: $m = 1$, $k = (2\\pi)^2$, $x_0 = 0.1$, $p_0 = 0$, $h = 0.7$, $T = 7000$.\n\nProgram input and output specification:\n- There is no input. Hard-code the test cases above in your program.\n- Your program should compute, for each test in order, the pair of numbers\n  $[\\text{max\\_abs\\_Hamiltonian\\_drift\\_J}, \\text{final\\_phase\\_precession\\_error\\_rad}]$,\n  rounded to $12$ decimal places.\n- Your program should produce a single line of output containing the results for all four tests concatenated into one flat list in the exact order\n  $[\\text{drift}_1,\\text{phase}_1,\\text{drift}_2,\\text{phase}_2,\\text{drift}_3,\\text{phase}_3,\\text{drift}_4,\\text{phase}_4]$,\n  printed as a comma-separated list enclosed in square brackets, for example\n  $[a_1,a_2,\\dots,a_8]$.",
            "solution": "The user provides a valid problem statement.\n\nThe task is to derive, implement, and analyze a one-step numerical integrator for the one-dimensional harmonic oscillator based on the Average Vector Field (AVF) method. The analysis involves proving exact energy conservation and quantifying the phase error.\n\n### 1. Derivation of the AVF Integrator\n\nThe Hamiltonian for the harmonic oscillator is $H(x,p) = \\frac{p^2}{2m} + \\frac{kx^2}{2}$.\nHamilton's equations in compact form are $\\dot{y} = J \\nabla H(y)$, where $y = [x, p]^T$ and $J = \\begin{bmatrix} 0  1 \\\\ -1  0 \\end{bmatrix}$. The gradient of the Hamiltonian is:\n$$\n\\nabla H(y) = \\begin{bmatrix} \\partial H / \\partial x \\\\ \\partial H / \\partial p \\end{bmatrix} = \\begin{bmatrix} kx \\\\ p/m \\end{bmatrix} = \\begin{bmatrix} k  0 \\\\ 0  1/m \\end{bmatrix} \\begin{bmatrix} x \\\\ p \\end{bmatrix} = S y\n$$\nwhere $S$ is a symmetric matrix.\n\nThe AVF integrator is defined by the update rule from $y_n$ to $y_{n+1}$ over a time step $h$:\n$$\n\\frac{y_{n+1} - y_n}{h} = \\int_0^1 J \\nabla H((1-\\xi)y_n + \\xi y_{n+1}) \\, d\\xi\n$$\nSince $\\nabla H(y) = Sy$ is linear in $y$, the integrand is also linear in $\\xi$. The integral can be evaluated exactly:\n$$\n\\int_0^1 J S ((1-\\xi)y_n + \\xi y_{n+1}) \\, d\\xi = J S \\int_0^1 ((1-\\xi)y_n + \\xi y_{n+1}) \\, d\\xi = J S \\left(\\frac{y_n + y_{n+1}}{2}\\right)\n$$\nThis is a property of the trapezoidal rule, which is exact for linear functions. The update rule simplifies to what is known as the implicit midpoint rule (when written in a certain form) or a trapezoidal rule on the Hamiltonian system:\n$$\n\\frac{y_{n+1} - y_n}{h} = J S \\left(\\frac{y_n + y_{n+1}}{2}\\right)\n$$\nExpanding this into components $y=[x, p]^T$:\n$$\n\\frac{1}{h} \\begin{bmatrix} x_{n+1} - x_n \\\\ p_{n+1} - p_n \\end{bmatrix} = \\begin{bmatrix} 0  1 \\\\ -1  0 \\end{bmatrix} \\begin{bmatrix} k  0 \\\\ 0  1/m \\end{bmatrix} \\frac{1}{2} \\begin{bmatrix} x_n + x_{n+1} \\\\ p_n + p_{n+1} \\end{bmatrix} = \\frac{1}{2} \\begin{bmatrix} 0  1/m \\\\ -k  0 \\end{bmatrix} \\begin{bmatrix} x_n + x_{n+1} \\\\ p_n + p_{n+1} \\end{bmatrix}\n$$\nThis gives two coupled linear equations:\n$$\nx_{n+1} - x_n = \\frac{h}{2m}(p_n + p_{n+1})\n$$\n$$\np_{n+1} - p_n = -\\frac{kh}{2}(x_n + x_{n+1})\n$$\n\n### 2. Proof of Exact Energy Conservation\n\nWe wish to show that $H(x_{n+1}, p_{n+1}) = H(x_n, p_n)$.\nLet's compute the difference $H_{n+1} - H_n$:\n$$\nH_{n+1} - H_n = \\left(\\frac{p_{n+1}^2}{2m} + \\frac{kx_{n+1}^2}{2}\\right) - \\left(\\frac{p_n^2}{2m} + \\frac{kx_n^2}{2}\\right)\n$$\n$$\n= \\frac{1}{2m}(p_{n+1}^2 - p_n^2) + \\frac{k}{2}(x_{n+1}^2 - x_n^2)\n$$\nUsing the difference of squares factorization, $a^2 - b^2 = (a-b)(a+b)$:\n$$\n= \\frac{1}{2m}(p_{n+1} - p_n)(p_{n+1} + p_n) + \\frac{k}{2}(x_{n+1} - x_n)(x_{n+1} + x_n)\n$$\nNow, substitute the expressions for $(p_{n+1} - p_n)$ and $(x_{n+1} - x_n)$ from the integrator's equations:\n$$\n= \\frac{1}{2m}\\left(-\\frac{kh}{2}(x_n + x_{n+1})\\right)(p_n + p_{n+1}) + \\frac{k}{2}\\left(\\frac{h}{2m}(p_n + p_{n+1})\\right)(x_n + x_{n+1})\n$$\n$$\n= -\\frac{kh}{4m}(x_n + x_{n+1})(p_n + p_{n+1}) + \\frac{kh}{4m}(p_n + p_{n+1})(x_n + x_{n+1}) = 0\n$$\nThus, $H_{n+1} - H_n = 0$, which proves that the Hamiltonian is exactly conserved for any time step $h$. As a consequence, the maximum absolute Hamiltonian drift $\\max_{0 \\le n \\le N} |H(x_n,p_n) - H(x_0,p_0)|$ is exactly $0$.\n\n### 3. Phase Space Analysis and Phase Error\n\nTo analyze the phase space trajectory, it is convenient to use scaled coordinates in which the exact trajectories are circles. Let the natural frequency be $\\omega = \\sqrt{k/m}$. We introduce a scaled momentum $\\bar{p} = p/(m\\omega)$. The exact equations of motion become:\n$$\n\\dot{x} = \\frac{p}{m} = \\omega \\bar{p}\n$$\n$$\n\\dot{\\bar{p}} = \\frac{\\dot{p}}{m\\omega} = \\frac{-kx}{m\\omega} = \\frac{-m\\omega^2 x}{m\\omega} = -\\omega x\n$$\nThis system describes a clockwise circular motion in the $(x, \\bar{p})$ plane with angular frequency $\\omega$.\n\nLet's rewrite the integrator equations in terms of $(x, \\bar{p})$. Substituting $p = m\\omega\\bar{p}$:\n$$\nx_{n+1} - x_n = \\frac{h}{2m}(m\\omega \\bar{p}_n + m\\omega \\bar{p}_{n+1}) = \\frac{\\omega h}{2}(\\bar{p}_n + \\bar{p}_{n+1})\n$$\n$$\nm\\omega(\\bar{p}_{n+1} - \\bar{p}_n) = -\\frac{kh}{2}(x_n + x_{n+1}) \\implies \\bar{p}_{n+1} - \\bar{p}_n = -\\frac{m\\omega^2 h}{2 m\\omega}(x_n + x_{n+1}) = -\\frac{\\omega h}{2}(x_n + x_{n+1})\n$$\nLet $\\alpha = \\omega h / 2$. The equations are:\n$$\nx_{n+1} - \\alpha \\bar{p}_{n+1} = x_n + \\alpha \\bar{p}_n\n$$\n$$\n\\alpha x_{n+1} + \\bar{p}_{n+1} = \\bar{p}_n - \\alpha x_n\n$$\nIn matrix form, with $z_n = [x_n, \\bar{p}_n]^T$:\n$$\n\\begin{bmatrix} 1  -\\alpha \\\\ \\alpha  1 \\end{bmatrix} z_{n+1} = \\begin{bmatrix} 1  \\alpha \\\\ -\\alpha  1 \\end{bmatrix} z_{n}\n$$\nThe one-step map is $z_{n+1} = M' z_n$, where $M' = \\left(\\begin{smallmatrix} 1  -\\alpha \\\\ \\alpha  1 \\end{smallmatrix}\\right)^{-1} \\left(\\begin{smallmatrix} 1  \\alpha \\\\ -\\alpha  1 \\end{smallmatrix}\\right)$.\n$$\nM' = \\frac{1}{1+\\alpha^2} \\begin{bmatrix} 1  \\alpha \\\\ -\\alpha  1 \\end{bmatrix} \\begin{bmatrix} 1  \\alpha \\\\ -\\alpha  1 \\end{bmatrix} = \\frac{1}{1+\\alpha^2} \\begin{bmatrix} 1-\\alpha^2  2\\alpha \\\\ -2\\alpha  1-\\alpha^2 \\end{bmatrix}\n$$\nThis is a rotation matrix $\\begin{pmatrix} \\cos\\varphi  \\sin\\varphi \\\\ -\\sin\\varphi  \\cos\\varphi \\end{pmatrix}$ for a clockwise rotation angle $\\varphi$. By comparison, we identify:\n$$\n\\cos\\varphi = \\frac{1-\\alpha^2}{1+\\alpha^2}, \\qquad \\sin\\varphi = \\frac{2\\alpha}{1+\\alpha^2}\n$$\nThese are the half-angle tangent identities, where $\\tan(\\varphi/2) = \\alpha$.\nSo, the discrete angular advance per step $\\varphi$ is given by:\n$$\n\\varphi = 2 \\arctan(\\alpha) = 2 \\arctan\\left(\\frac{\\omega h}{2}\\right)\n$$\nThe modified frequency is $\\tilde{\\omega} = \\varphi/h$. The exact angular advance would be $\\omega h$. The phase error per step is $\\varphi - \\omega h$. For a total integration time $T$ with $N=T/h$ steps, the total phase precession error is:\n$$\n\\Delta\\theta_{total} = N (\\varphi - \\omega h) = \\frac{T}{h} \\left( 2 \\arctan\\left(\\frac{\\omega h}{2}\\right) - \\omega h \\right)\n$$\nThe problem requires the principal value of this error in the interval $[-\\pi, \\pi]$, which is computed using the provided wrapping function: $\\mathrm{wrap}_{[-\\pi,\\pi]}(\\alpha) = ((\\alpha + \\pi) \\pmod{2\\pi}) - \\pi$.\n\n### 4. Implementation Strategy\n\nFor each test case, we perform the following calculations:\n1.  **Maximum Hamiltonian Drift**: Based on the proof in Section 2, this is exactly $0.0\\,\\mathrm{J}$.\n2.  **Final Phase Precession Error**:\n    a. Given $m, k, h, T$, calculate $\\omega = \\sqrt{k/m}$.\n    b. Compute the total phase error using the derived formula: $\\Delta\\theta_{total} = (T/h) \\left( 2 \\arctan(\\omega h/2) - \\omega h \\right)$.\n    c. Apply the wrapping function to $\\Delta\\theta_{total}$ to find the principal value $\\Delta\\theta(T)$.\n    d. Round the result to $12$ decimal places.\n\nThe results for all test cases are then collected and printed in the specified flat list format.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes Hamiltonian drift and phase precession error for a one-step\n    energy-preserving integrator for the 1D harmonic oscillator.\n    \"\"\"\n\n    # Test cases in SI units: (m, k, x0, p0, h, T)\n    test_cases = [\n        # Test 1: m=1, k=1, x0=1, p0=0, h=0.1, T=1000\n        (1.0, 1.0, 1.0, 0.0, 0.1, 1000.0),\n        # Test 2: m=1.5, k=400, x0=0.02, p0=0.1, h=0.0005, T=0.5\n        (1.5, 400.0, 0.02, 0.1, 0.0005, 0.5),\n        # Test 3: m=2, k=8, x0=1, p0=1, h=1.0, T=1000\n        (2.0, 8.0, 1.0, 1.0, 1.0, 1000.0),\n        # Test 4: m=1, k=(2pi)^2, x0=0.1, p0=0, h=0.7, T=7000\n        (1.0, (2 * np.pi)**2, 0.1, 0.0, 0.7, 7000.0),\n    ]\n\n    results = []\n\n    for m, k, x0, p0, h, T in test_cases:\n        # 1. Hamiltonian Drift\n        # Based on the first-principles derivation, the AVF integrator exactly\n        # conserves the quadratic Hamiltonian of the harmonic oscillator.\n        # Thus, the drift is identically zero.\n        max_abs_hamiltonian_drift = 0.0\n        \n        # 2. Final Phase Precession Error\n        # The analytical solution is used, not a forward simulation.\n        \n        # Angular frequency (rad/s)\n        omega = np.sqrt(k / m)\n        \n        # Number of steps\n        # Given that N = T/h is an integer for all test cases.\n        N = T / h\n\n        # Per-step angular advance of the numerical method (rad)\n        phi_numerical = 2 * np.arctan(omega * h / 2)\n        \n        # Per-step angular advance of the exact dynamics (rad)\n        phi_exact = omega * h\n        \n        # Total accumulated phase error over interval T (rad)\n        total_phase_error = N * (phi_numerical - phi_exact)\n        \n        # Wrap the error to the principal branch [-pi, pi]\n        # The Python '%' operator corresponds to the definition of 'mod'\n        # required for the wrapping function for both positive and negative numbers.\n        final_phase_precession_error = \\\n            (total_phase_error + np.pi) % (2 * np.pi) - np.pi\n            \n        # Append the rounded results to the list\n        results.append(round(max_abs_hamiltonian_drift, 12))\n        results.append(round(final_phase_precession_error, 12))\n\n    # Print the final output in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}