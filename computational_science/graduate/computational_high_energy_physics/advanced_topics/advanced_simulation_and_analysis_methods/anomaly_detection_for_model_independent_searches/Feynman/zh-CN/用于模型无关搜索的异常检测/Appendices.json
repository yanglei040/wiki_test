{
    "hands_on_practices": [
        {
            "introduction": "在进行无模型新物理寻找时，我们常常需要在大范围的参数空间中扫描，以寻找潜在的异常信号。这种扫描行为会引入一个被称为“别处观看效应”（Look-Elsewhere Effect）的统计学挑战。本练习将引导你亲手计算并校正这一效应，通过应用Bonferroni和Šidák校正方法，将局部$p$值转化为全局显著性，这是任何无模型探索中解释结果所必需的基本技能。",
            "id": "3504747",
            "problem": "在对连续不变质量谱进行的模型无关异常寻找中，执行滑动窗口扫描以识别局域超出，而不预设特定的信号模型。考虑一个扫描，它评估 $K = 100$ 个不相交的窗口，每个窗口都给出一个局域单边 $p$ 值，用于检验“仅有本底”的原假设与“本底加局域超出”的备择假设。观测到的最小局域 $p$ 值为 $p_{\\min} = 10^{-4}$。假设局域检验经过校准，使得在原假设下，每个窗口的局域 $p$ 值在 $[0,1]$ 上均匀分布，并且不同不相交窗口间的检验是相互独立的。\n\n从 $p$ 值和族系误差率（FWER）的基本定义出发，并利用概率的互补法则以及 Boole 不等式（并集上限），推导在以下两种情况下，在 $K$ 个窗口中观测到至少一个与最小局域 $p$ 值一样极端的涨落的全局 $p$ 值：\n\n- Bonferroni 修正，它在任意依赖关系下提供有效的 FWER 控制。\n- Šidák 修正，它在独立性条件下提供精确的 FWER。\n\n然后，对于每种修正，通过求解 $Z = \\Phi^{-1}(1 - p_{\\mathrm{global}})$，使用标准正态累积分布函数 $\\Phi$ 将每个全局 $p$ 值转换为一个单边高斯等效显著性 $Z$（以标准差 $\\sigma$ 为单位）。\n\n将最终的 $Z$ 值四舍五入到四位有效数字并报告。最终数值结果需以上文定义的 $\\sigma$ 为单位表示。在最终的方框答案中不要包含单位。",
            "solution": "用户提供了一个问题陈述，在尝试解答之前必须对其进行验证。\n\n### 步骤 1：提取已知条件\n-   不相交窗口数：$K = 100$\n-   观测到的最小局域单边 $p$ 值：$p_{\\min} = 10^{-4}$\n-   原假设是“仅有本底”。\n-   在原假设下，每个窗口的局域 $p$ 值在 $[0,1]$ 上均匀分布。\n-   不同不相交窗口间的检验是相互独立的。\n-   任务 1：推导 Bonferroni 修正和 Šidák 修正的全局 $p$ 值，$p_{\\mathrm{global}}$。\n-   任务 2：通过关系式 $Z = \\Phi^{-1}(1 - p_{\\mathrm{global}})$ 将每个 $p_{\\mathrm{global}}$ 转换为单边高斯等效显著性 $Z$，其中 $\\Phi$ 是标准正态累积分布函数（CDF）。\n-   任务 3：将最终的 $Z$ 值四舍五入到四位有效数字。\n\n### 步骤 2：使用提取的已知条件进行验证\n1.  **科学依据**：该问题在统计学及其在高能物理中的应用方面有坚实的基础。$p$ 值、“别处观看效应”、Bonferroni 修正、Šidák 修正和高斯显著性等概念是该领域模型无关寻找的标准工具。\n2.  **定义明确**：该问题定义清晰，提供了所有必要信息。关于独立性和原假设下局域 $p$ 值均匀分布的假设都已明确陈述，这使得问题有唯一且有意义的解。\n3.  **客观性**：语言精确、量化，没有任何主观或模棱两可的术语。\n4.  **完整性**：问题是自洽的。它提供了检验次数 $K$、观测到的最小局域 $p$ 值 $p_{\\min}$ 以及必要的统计假设。\n5.  **现实性**：所描述的场景是实验粒子物理中异常寻找的一个简化但现实的表示。提供的值是合理的。\n6.  **其他缺陷**：该问题既不琐碎也非同义反复。它要求正确推导和应用已有的统计公式。它不是比喻性的，并且直接切题。\n\n### 步骤 3：结论和行动\n问题有效。现在开始解题过程。\n\n全局 $p$ 值，$p_{\\mathrm{global}}$，旨在解决“别处观看效应”或多重检验问题。它被定义为，在全局原假设下（即在 $K$ 个窗口中均不存在信号），观测到至少一个局域 $p$ 值小于或等于实际找到的最小值 $p_{\\min}$ 的概率。设 $P_1, P_2, \\ldots, P_K$ 为代表 $K$ 个窗口局域 $p$ 值的随机变量。全局 $p$ 值是这些局域 $p$ 值的最小值小于或等于 $p_{\\min}$ 这一事件的概率：\n$$p_{\\mathrm{global}} = P(\\min_{i=1, \\ldots, K} P_i \\le p_{\\min})$$\n这等价于至少一个局域 $p$ 值小于或等于 $p_{\\min}$ 的事件并集的概率。设 $A_i$ 为事件 $P_i \\le p_{\\min}$。那么：\n$$p_{\\mathrm{global}} = P\\left(\\bigcup_{i=1}^{K} A_i\\right)$$\n在原假设下，每个 $P_i$ 在 $[0,1]$ 上均匀分布，因此 $P(A_i) = P(P_i \\le p_{\\min}) = p_{\\min}$。\n\n**1. Bonferroni 修正**\n\nBonferroni 修正源自 Boole 不等式，也称为并集上限。对于任意一组事件 $A_1, \\ldots, A_K$，该不等式指出，它们并集的概率不大于它们各自概率的总和：\n$$P\\left(\\bigcup_{i=1}^{K} A_i\\right) \\le \\sum_{i=1}^{K} P(A_i)$$\n这个上限成立，而无论事件之间存在何种依赖结构。将其应用于我们的问题，我们得到全局 $p$ 值的一个上限：\n$$p_{\\mathrm{global}} \\le \\sum_{i=1}^{K} P(P_i \\le p_{\\min}) = \\sum_{i=1}^{K} p_{\\min} = K \\cdot p_{\\min}$$\nBonferroni 修正后的 $p$ 值被定义为这个上限，通常以 1 为上限：\n$$p_{\\mathrm{global, Bonf}} = \\min(1, K \\cdot p_{\\min})$$\n这提供了一个保守的估计，保证在任何期望水平 $\\alpha$ 下对族系误差率（FWER）的控制。\n对于给定的值 $K=100$ 和 $p_{\\min}=10^{-4}$：\n$$p_{\\mathrm{global, Bonf}} = 100 \\times 10^{-4} = 10^{-2} = 0.01$$\n由于 $0.01  1$，最小值函数不起作用。\n\n**2. Šidák 修正**\n\nŠidák 修正提供了一个在各检验相互独立的假设下的精确全局 $p$ 值，这一假设在问题中已明确说明。推导始于概率的互补法则。“至少一个 $P_i \\le p_{\\min}$”的补集是“所有 $P_i  p_{\\min}$”。\n$$p_{\\mathrm{global}} = P(\\min_{i} P_i \\le p_{\\min}) = 1 - P(\\forall i, P_i  p_{\\min})$$\n因为各项检验是独立的，所以联合事件的概率是各个独立事件概率的乘积：\n$$P(\\forall i, P_i  p_{\\min}) = \\prod_{i=1}^{K} P(P_i  p_{\\min})$$\n由于在原假设下每个 $P_i$ 在 $[0,1]$ 上均匀分布，概率 $P(P_i  p_{\\min})$ 为：\n$$P(P_i  p_{\\min}) = 1 - P(P_i \\le p_{\\min}) = 1 - p_{\\min}$$\n将此代回，我们得到独立性条件下的精确全局 $p$ 值，即 Šidák 修正：\n$$p_{\\mathrm{global, Šidák}} = 1 - (1 - p_{\\min})^K$$\n对于给定的值 $K=100$ 和 $p_{\\min}=10^{-4}$：\n$$p_{\\mathrm{global, Šidák}} = 1 - (1 - 10^{-4})^{100} = 1 - (0.9999)^{100}$$\n\n**3. 转换为显著性 $Z$**\n\n显著性 $Z$ 是通过对标准正态累积分布函数 $\\Phi$ 求逆得到的。它是标准正态分布上的一个值，该分布从 $Z$ 到无穷大的尾部积分等于 $p$ 值。这由关系式 $p_{\\mathrm{global}} = 1 - \\Phi(Z)$ 给出，重新整理可得 $Z = \\Phi^{-1}(1 - p_{\\mathrm{global}})$。\n\n对于 Bonferroni 修正：\n$$Z_{\\mathrm{Bonf}} = \\Phi^{-1}(1 - p_{\\mathrm{global, Bonf}}) = \\Phi^{-1}(1 - 0.01) = \\Phi^{-1}(0.99)$$\n使用标准统计表或计算软件，$\\Phi^{-1}(0.99) \\approx 2.32634787$。\n\n对于 Šidák 修正：\n$$Z_{\\mathrm{Šidák}} = \\Phi^{-1}(1 - p_{\\mathrm{global, Šidák}}) = \\Phi^{-1}\\left(1 - \\left[1 - (1 - p_{\\min})^K\\right]\\right) = \\Phi^{-1}\\left((1 - p_{\\min})^K\\right)$$\n$$Z_{\\mathrm{Šidák}} = \\Phi^{-1}\\left((1 - 10^{-4})^{100}\\right) = \\Phi^{-1}\\left((0.9999)^{100}\\right)$$\n数值计算得，$(0.9999)^{100} \\approx 0.990049833$。\n$$Z_{\\mathrm{Šidák}} = \\Phi^{-1}(0.990049833) \\approx 2.3283592$$\n\n**4. 最终数值结果**\n\n问题要求将最终的 $Z$ 值四舍五入到四位有效数字。\n-   Bonferroni 显著性：$Z_{\\mathrm{Bonf}} \\approx 2.32634787 \\rightarrow 2.326$。\n-   Šidák 显著性：$Z_{\\mathrm{Šidák}} \\approx 2.3283592 \\rightarrow 2.328$。\n\nBonferroni 修正提供了真实 $p$ 值的一个保守上限，导致其 $p$ 值略大，因此显著性略小于精确的 Šidák 修正，而后者因检验的独立性在此适用。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2.326  2.328\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "从普适的统计校正方法过渡到具体的参数估计任务，许多高能物理分析始于对分箱数据（即直方图）的处理。本练习将介绍一种强大的统计方法——期望最大化（Expectation-Maximization, EM）算法，用于在已知背景和异常信号形状模板的情况下，估计数据样本中异常信号所占的比例。这是一个经典的半监督学习问题，它构成了连接纯统计方法与更复杂机器学习模型的桥梁。",
            "id": "3504732",
            "problem": "给定一个从高能对撞机实验中汇总的、跨越离散区间的事件计数直方图。工作假设是，观测到的分布是一个已知本底形状和一个可能存在的、具有不同形状的微小污染（异常）的混合体。设事件总数为 $N$，区间索引为 $i \\in \\{1,\\dots,K\\}$，本底模板为 $\\{b_i\\}_{i=1}^K$ 且 $\\sum_{i=1}^K b_i = 1$，异常模板为 $\\{s_i\\}_{i=1}^K$ 且 $\\sum_{i=1}^K s_i = 1$。该混合模型假设一个事件落入区间 $i$ 的概率为\n$$\np_i(\\epsilon) = (1-\\epsilon)\\,b_i + \\epsilon\\,s_i,\n$$\n其中 $\\epsilon \\in [0,1]$ 是待估计的未知污染分数。观测数据是计数 $\\{n_i\\}_{i=1}^K$，且 $\\sum_{i=1}^K n_i = N$。假设这些计数是参数为 $N$ 和概率为 $\\{p_i(\\epsilon)\\}_{i=1}^K$ 的多项式随机变量的实现。\n\n从多项式似然的定义开始，\n$$\n\\mathcal{L}(\\epsilon) \\propto \\prod_{i=1}^K p_i(\\epsilon)^{n_i},\n$$\n及其对数似然，\n$$\n\\ell(\\epsilon) = \\sum_{i=1}^K n_i \\log p_i(\\epsilon),\n$$\n推导一个期望最大化（EM；Expectation-Maximization）算法来估计 $\\epsilon$。该推导应使用潜变量表述，其中为每个事件分配一个未观测到的指示符，以表明它来自本底还是污染。使用EM算法最大化关于潜变量当前后验的期望完全数据对数似然这一原则。从第一性原理出发，证明得到的 $\\epsilon$ 不动点更新与在混合模型下最大化观测数据似然是一致的。最后，推导在最大似然估计 $\\hat{\\epsilon}$ 处的观测费雪信息，其定义为\n$$\n\\mathcal{I}_{\\text{obs}}(\\hat{\\epsilon}) \\equiv -\\left.\\frac{\\partial^2 \\ell(\\epsilon)}{\\partial \\epsilon^2}\\right|_{\\epsilon=\\hat{\\epsilon}},\n$$\n并用它来报告不确定度估计 $\\sigma_\\epsilon = \\sqrt{1 / \\mathcal{I}_{\\text{obs}}(\\hat{\\epsilon})}$。如果 $\\mathcal{I}_{\\text{obs}}(\\hat{\\epsilon}) = 0$，则将 $\\sigma_\\epsilon$ 定义为 $+\\infty$。\n\n你的任务是编写一个完整的程序，该程序：\n- 实现EM过程来估计 $\\epsilon$，仅使用分箱计数和模板 $\\{b_i\\}$ 与 $\\{s_i\\}$，其中E步的响应度要为分箱数据一致地计算，M步更新 $\\epsilon$。\n- 迭代直到收敛，对 $\\epsilon$ 使用绝对容差 $\\tau = 10^{-12}$ 或最多 $10{,}000$ 次迭代，以先达到的为准。\n- 在收敛的 $\\hat{\\epsilon}$ 处计算观测费雪信息，并按上述定义报告 $\\sigma_\\epsilon$。\n- 为每个测试用例生成一个包含两个元素的列表 $[\\hat{\\epsilon}, \\sigma_\\epsilon]$ 作为结果，其中两个条目都是四舍五入到六位小数的小数（无百分号）。\n\n使用以下测试套件，每个测试用例由 $(\\{n_i\\}, \\{b_i\\}, \\{s_i\\}, \\epsilon_0)$ 指定，其中 $\\epsilon_0$ 是EM迭代的初始值：\n\n- 测试用例 $1$ (正常情况，中度污染，平滑的 $b$ 和尖峰的 $s$):\n  - $\\{n_i\\} = \\{143, 121, 98, 76, 40, 22\\}$\n  - $\\{b_i\\} = \\{0.30, 0.25, 0.20, 0.15, 0.07, 0.03\\}$\n  - $\\{s_i\\} = \\{0.05, 0.10, 0.15, 0.20, 0.25, 0.25\\}$\n  - $\\epsilon_0 = 0.02$\n\n- 测试用例 $2$ (边界情况，无污染，仅本底计数):\n  - $\\{n_i\\} = \\{100, 200, 300, 250, 150\\}$\n  - $\\{b_i\\} = \\{0.10, 0.20, 0.30, 0.25, 0.15\\}$\n  - $\\{s_i\\} = \\{0.05, 0.05, 0.10, 0.30, 0.50\\}$\n  - $\\epsilon_0 = 0.01$\n\n- 测试用例 $3$ (低信息情况，$s$ 接近 $b$):\n  - $\\{n_i\\} = \\{113, 112, 112, 112, 112, 112, 127\\}$\n  - $\\{b_i\\} = \\{0.14, 0.14, 0.14, 0.14, 0.14, 0.14, 0.16\\}$\n  - $\\{s_i\\} = \\{0.15, 0.14, 0.14, 0.14, 0.14, 0.14, 0.15\\}$\n  - $\\epsilon_0 = 0.05$\n\n- 测试用例 $4$ (边缘支持情况，本底有一个零概率区间):\n  - $\\{n_i\\} = \\{12, 180, 291, 117\\}$\n  - $\\{b_i\\} = \\{0.00, 0.30, 0.50, 0.20\\}$\n  - $\\{s_i\\} = \\{0.40, 0.30, 0.20, 0.10\\}$\n  - $\\epsilon_0 = 0.02$\n\n你的程序应生成一行输出，其中包含一个用方括号括起来的、逗号分隔的列表作为结果，每个测试用例的结果本身也是一个双元素列表。例如，输出格式必须为\n$$\n\\big[ [\\hat{\\epsilon}_1,\\sigma_{\\epsilon,1}], [\\hat{\\epsilon}_2,\\sigma_{\\epsilon,2}], [\\hat{\\epsilon}_3,\\sigma_{\\epsilon,3}], [\\hat{\\epsilon}_4,\\sigma_{\\epsilon,4}] \\big],\n$$\n所有数值条目都四舍五入到六位小数，并以小数形式表示。",
            "solution": "用户提供了一个在统计推断领域中定义明确的问题。该问题具有科学依据、内容完整且客观。唯一解所需的所有参数和数据均已提供。因此，该问题是有效的，将提供一个解决方案。\n\n### 理论推导\n\n该问题要求基于观测到的分箱计数 $\\{n_i\\}_{i=1}^K$ 来估计混合模型中的污染分数 $\\epsilon$。一个事件落入区间 $i$ 的概率模型是 $p_i(\\epsilon) = (1-\\epsilon)b_i + \\epsilon s_i$，其中 $\\{b_i\\}$ 和 $\\{s_i\\}$ 分别是已知的本底和异常概率模板。假设数据 $\\{n_i\\}$ 服从一个总计数为 $N = \\sum_{i=1}^K n_i$、概率为 $\\{p_i(\\epsilon)\\}$ 的多项式分布。\n\n#### 1. 期望最大化（EM）算法\n\nEM算法是一种在具有潜变量的统计模型中寻找参数最大似然估计的迭代方法。\n\n**潜变量表述**：对于 $N$ 个独立事件中的每一个，我们为 $j=1, \\dots, N$ 引入一个潜指示变量 $Z_j \\in \\{0, 1\\}$。$Z_j=1$ 表示该事件源于异常组分，而 $Z_j=0$ 表示它源于本底组分。先验概率为 $P(Z_j=1) = \\epsilon$。观测数据是每个事件的区间索引 $X_j \\in \\{1, \\dots, K\\}$。分箱计数为 $n_i = \\sum_{j=1}^N \\mathbb{I}(X_j=i)$，其中 $\\mathbb{I}(\\cdot)$ 是指示函数。\n\n**完全数据对数似然**：完全数据由数据对 $\\{(X_j, Z_j)\\}_{j=1}^N$ 组成。完全数据的似然函数为：\n$$ \\mathcal{L}_{\\text{comp}}(\\epsilon) = \\prod_{j=1}^N P(X_j, Z_j | \\epsilon) = \\prod_{j=1}^N \\left[ (1-\\epsilon) b_{X_j} \\right]^{1-Z_j} \\left[ \\epsilon s_{X_j} \\right]^{Z_j} $$\n对应的对数似然是：\n$$ \\ell_{\\text{comp}}(\\epsilon) = \\sum_{j=1}^N \\left[ (1-Z_j)\\log(1-\\epsilon) + Z_j\\log(\\epsilon) \\right] + \\sum_{j=1}^N \\left[ (1-Z_j)\\log(b_{X_j}) + Z_j\\log(s_{X_j}) \\right] $$\n忽略不依赖于 $\\epsilon$ 的项，我们有：\n$$ \\ell_{\\text{comp}}(\\epsilon) \\propto \\left(\\sum_{j=1}^N (1-Z_j)\\right) \\log(1-\\epsilon) + \\left(\\sum_{j=1}^N Z_j\\right) \\log(\\epsilon) $$\n设 $N_s = \\sum_{j=1}^N Z_j$ 为异常事件的总数（未观测到）。则 $\\sum_{j=1}^N (1-Z_j) = N - N_s$。\n$$ \\ell_{\\text{comp}}(\\epsilon) \\propto (N - N_s) \\log(1-\\epsilon) + N_s \\log(\\epsilon) $$\n\n**E步（期望）**：在E步中，我们计算完全数据对数似然关于潜变量 $Z$ 在给定观测数据 $X$ 和当前参数估计 $\\epsilon^{(t)}$ 条件下的后验分布的期望。这就是 $Q$ 函数：\n$$ Q(\\epsilon | \\epsilon^{(t)}) = E_{Z|X, \\epsilon^{(t)}}[\\ell_{\\text{comp}}(\\epsilon)] $$\n这简化为计算 $N_s$ 的期望：\n$$ N_s^{(t)} = E[N_s | X, \\epsilon^{(t)}] = E\\left[\\sum_{j=1}^N Z_j \\middle| X, \\epsilon^{(t)}\\right] = \\sum_{j=1}^N E[Z_j | X_j, \\epsilon^{(t)}] $$\n期望 $E[Z_j | X_j, \\epsilon^{(t)}]$ 是在观测到事件 $j$ 落入区间 $X_j$ 的条件下，该事件为异常的后验概率。这就是“响应度” $r_i^{(t)}$：\n$$ r_i^{(t)} \\equiv P(Z_j=1 | X_j=i, \\epsilon^{(t)}) = \\frac{P(X_j=i|Z_j=1)P(Z_j=1|\\epsilon^{(t)})}{P(X_j=i|\\epsilon^{(t)})} = \\frac{s_i \\epsilon^{(t)}}{(1-\\epsilon^{(t)})b_i + \\epsilon^{(t)}s_i} = \\frac{\\epsilon^{(t)} s_i}{p_i(\\epsilon^{(t)})} $$\n期望的异常事件总数是所有观测事件的响应度之和，按区间分组后为：\n$$ N_s^{(t)} = \\sum_{i=1}^K n_i r_i^{(t)} $$\n于是 $Q$ 函数为：\n$$ Q(\\epsilon | \\epsilon^{(t)}) = (N - N_s^{(t)}) \\log(1-\\epsilon) + N_s^{(t)} \\log(\\epsilon) + \\text{常数} $$\n\n**M步（最大化）**：在M步中，我们关于 $\\epsilon$ 最大化 $Q(\\epsilon | \\epsilon^{(t)})$ 以找到下一个估计值 $\\epsilon^{(t+1)}$。\n$$ \\frac{\\partial Q}{\\partial \\epsilon} = -\\frac{N - N_s^{(t)}}{1-\\epsilon} + \\frac{N_s^{(t)}}{\\epsilon} = 0 $$\n解出 $\\epsilon$ 得到：\n$$ \\epsilon^{(t+1)} = \\frac{N_s^{(t)}}{N} = \\frac{1}{N} \\sum_{i=1}^K n_i r_i^{(t)} $$\n代入 $r_i^{(t)}$ 的表达式，得到最终的更新规则：\n$$ \\epsilon^{(t+1)} = \\frac{1}{N} \\sum_{i=1}^K n_i \\frac{\\epsilon^{(t)} s_i}{(1-\\epsilon^{(t)})b_i + \\epsilon^{(t)}s_i} $$\n这个迭代过程保证了在每一步中观测数据的对数似然都不会减少。\n\n#### 2. 与最大似然估计的一致性\n\n观测数据的对数似然（除去一个常数）为：\n$$ \\ell(\\epsilon) = \\sum_{i=1}^K n_i \\log p_i(\\epsilon) = \\sum_{i=1}^K n_i \\log((1-\\epsilon)b_i + \\epsilon s_i) $$\n为了找到最大似然估计（MLE）$\\hat{\\epsilon}$，我们将其一阶导数（得分函数）设为零：\n$$ \\frac{\\partial \\ell}{\\partial \\epsilon} = \\sum_{i=1}^K n_i \\frac{s_i - b_i}{p_i(\\epsilon)} = 0 $$\n我们可以用另一种形式重写这个导数。因为 $p_i(\\epsilon) = (1-\\epsilon)b_i + \\epsilon s_i$，我们有 $s_i = (p_i(\\epsilon) - (1-\\epsilon)b_i) / \\epsilon$。一个更有用的恒等式是 $s_i - b_i = (s_i - p_i(\\epsilon)) / (1-\\epsilon)$。利用这个恒等式：\n$$ \\frac{\\partial \\ell}{\\partial \\epsilon} = \\sum_{i=1}^K \\frac{n_i}{p_i(\\epsilon)} \\frac{s_i - p_i(\\epsilon)}{1-\\epsilon} = \\frac{1}{1-\\epsilon} \\left( \\sum_{i=1}^K \\frac{n_i s_i}{p_i(\\epsilon)} - \\sum_{i=1}^K \\frac{n_i p_i(\\epsilon)}{p_i(\\epsilon)} \\right) = \\frac{1}{1-\\epsilon} \\left( \\sum_{i=1}^K \\frac{n_i s_i}{p_i(\\epsilon)} - N \\right) $$\n对于 $\\epsilon \\in (0,1)$，将导数设为零意味着 $\\sum_{i=1}^K \\frac{n_i s_i}{p_i(\\hat{\\epsilon})} = N$。\n\n现在，考虑EM更新规则的一个不动点 $\\hat{\\epsilon}$，其中 $\\hat{\\epsilon} = \\epsilon^{(t+1)} = \\epsilon^{(t)}$：\n$$ \\hat{\\epsilon} = \\frac{1}{N} \\sum_{i=1}^K n_i \\frac{\\hat{\\epsilon} s_i}{p_i(\\hat{\\epsilon})} $$\n对于 $\\hat{\\epsilon} \\in (0,1)$，我们可以两边除以 $\\hat{\\epsilon}$：\n$$ 1 = \\frac{1}{N} \\sum_{i=1}^K \\frac{n_i s_i}{p_i(\\hat{\\epsilon})} \\implies \\sum_{i=1}^K \\frac{n_i s_i}{p_i(\\hat{\\epsilon})} = N $$\n这恰好是观测数据对数似然的临界点条件。因此，EM算法的任何内部不动点都对应于对数似然函数的一个驻点，从而证明了一致性。\n\n#### 3. 观测费雪信息和不确定度\n\n观测费雪信息定义为对数似然的二阶导数的负值，在MLE $\\hat{\\epsilon}$ 处求值：\n$$ \\mathcal{I}_{\\text{obs}}(\\hat{\\epsilon}) = -\\left.\\frac{\\partial^2 \\ell(\\epsilon)}{\\partial \\epsilon^2}\\right|_{\\epsilon=\\hat{\\epsilon}} $$\n我们计算二阶导数：\n$$ \\frac{\\partial^2 \\ell}{\\partial \\epsilon^2} = \\frac{\\partial}{\\partial \\epsilon} \\left( \\sum_{i=1}^K n_i \\frac{s_i - b_i}{p_i(\\epsilon)} \\right) = \\sum_{i=1}^K n_i (s_i - b_i) \\left( -\\frac{1}{p_i(\\epsilon)^2} \\right) \\frac{\\partial p_i(\\epsilon)}{\\partial \\epsilon} $$\n因为 $\\frac{\\partial p_i(\\epsilon)}{\\partial \\epsilon} = s_i - b_i$，我们得到：\n$$ \\frac{\\partial^2 \\ell}{\\partial \\epsilon^2} = - \\sum_{i=1}^K n_i \\frac{(s_i - b_i)^2}{p_i(\\epsilon)^2} $$\n因此，观测费雪信息为：\n$$ \\mathcal{I}_{\\text{obs}}(\\hat{\\epsilon}) = \\sum_{i=1}^K n_i \\frac{(s_i - b_i)^2}{((1-\\hat{\\epsilon})b_i + \\hat{\\epsilon} s_i)^2} $$\n估计值 $\\hat{\\epsilon}$ 的不确定度由克拉默-拉奥下限（Cramér-Rao lower bound）给出，它近似于观测费雪信息平方根的倒数：\n$$ \\sigma_\\epsilon = \\sqrt{1 / \\mathcal{I}_{\\text{obs}}(\\hat{\\epsilon})} $$\n如果 $\\mathcal{I}_{\\text{obs}}(\\hat{\\epsilon}) = 0$，这发生在对所有 $n_i0$ 的区间都有 $s_i=b_i$ 的情况，此时参数 $\\epsilon$ 是不可识别的，不确定度 $\\sigma_\\epsilon$ 为无穷大。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the contamination fraction epsilon and its uncertainty using an EM algorithm\n    for a set of test cases.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        (\n            np.array([143, 121, 98, 76, 40, 22]),\n            np.array([0.30, 0.25, 0.20, 0.15, 0.07, 0.03]),\n            np.array([0.05, 0.10, 0.15, 0.20, 0.25, 0.25]),\n            0.02\n        ),\n        # Test case 2\n        (\n            np.array([100, 200, 300, 250, 150]),\n            np.array([0.10, 0.20, 0.30, 0.25, 0.15]),\n            np.array([0.05, 0.05, 0.10, 0.30, 0.50]),\n            0.01\n        ),\n        # Test case 3\n        (\n            np.array([113, 112, 112, 112, 112, 112, 127]),\n            np.array([0.14, 0.14, 0.14, 0.14, 0.14, 0.14, 0.16]),\n            np.array([0.15, 0.14, 0.14, 0.14, 0.14, 0.14, 0.15]),\n            0.05\n        ),\n        # Test case 4\n        (\n            np.array([12, 180, 291, 117]),\n            np.array([0.00, 0.30, 0.50, 0.20]),\n            np.array([0.40, 0.30, 0.20, 0.10]),\n            0.02\n        ),\n    ]\n\n    TOL = 1e-12\n    MAX_ITER = 10000\n    \n    results_str = []\n\n    for n, b, s, eps0 in test_cases:\n        N = np.sum(n)\n        eps = float(eps0)\n\n        for _ in range(MAX_ITER):\n            eps_old = eps\n            \n            # Mixture probability for each bin\n            p = (1.0 - eps) * b + eps * s\n            \n            # The EM update can be written in a numerically stable form that avoids\n            # explicitly calculating the responsibilities, which can be unstable if eps is small.\n            # eps_new = (1/N) * sum(n_i * r_i) = (1/N) * sum(n_i * eps * s_i / p_i)\n            #           = (eps/N) * sum(n_i * s_i / p_i)\n            \n            # To handle cases where p_i might be zero, we use np.divide to return 0 for 0/0.\n            # This is correct as if p_i=0, n_i must also be 0 for a non-infinite log-likelihood,\n            # so the contribution to the sum is 0.\n            sum_term = np.sum(np.divide(n * s, p, out=np.zeros_like(p), where=p!=0))\n            \n            eps = eps * sum_term / N\n            \n            # Constrain epsilon to the valid range [0, 1] to handle potential floating point inaccuracies.\n            # The update rule theoretically preserves this property.\n            eps = max(0.0, min(1.0, eps))\n            \n            if abs(eps - eps_old)  TOL:\n                break\n        \n        eps_hat = eps\n        \n        # Calculate Observed Fisher Information\n        p_hat = (1.0 - eps_hat) * b + eps_hat * s\n        diff_s_b = s - b\n        \n        # Terms for the Fisher information sum: n_i * ((s_i - b_i) / p_hat_i)^2\n        # Use np.divide for numerical stability, similar to the EM step.\n        numer = n * (diff_s_b**2)\n        denom = p_hat**2\n        fisher_terms = np.divide(numer, denom, out=np.zeros_like(numer), where=denom!=0)\n        \n        fisher_info = np.sum(fisher_terms)\n        \n        sigma_eps = 0.0\n        if fisher_info > 1e-30:  # Use a small threshold to avoid division by zero\n            sigma_eps = (1.0 / fisher_info)**0.5\n        else:\n            sigma_eps = float('inf')\n\n        results_str.append(f\"[{eps_hat:.6f},{sigma_eps:.6f}]\")\n\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "现代异常检测方法通常为每个物理事件提供一个单一的异常分数，这大大提升了搜索的灵敏度。然而，为了让这些分数具有物理意义并指导后续分析，我们必须理解事件的哪个部分导致其被判定为异常。本节的高级编程练习将带领你实现一个基于积分梯度（Integrated Gradients）的归因方法，来定位事件中的异常组分，这不仅是验证模型有效性的关键步骤，也是解释机器学习模型预测、发掘新物理现象的重要工具。",
            "id": "3504728",
            "problem": "给定一个用于计算高能物理中模型无关搜索的事件级异常分数的公式。每个事件表示为由 $N$ 个组分（粒子）组成的列表，每个组分都具有一个四维矢量 $(E, p_x, p_y, p_z)$。本问题中所有量均为无量纲的标准化特征，因此无需进行物理单位转换。为符合物理真实性，每个组分均被视为无质量，因此在任何修改其动量的操作后，必须满足 $E = \\sqrt{p_x^2 + p_y^2 + p_z^2}$。\n\n令 $x \\in \\mathbb{R}^{D}$ 表示串联的事件矢量，其中 $D = 4N$，其顺序为 $[E_1,p_{x,1},p_{y,1},p_{z,1},\\dots,E_N,p_{x,N},p_{y,N},p_{z,N}]^\\top$。通过矩阵 $U \\in \\mathbb{R}^{D\\times 4}$ 的列来定义一个背景子空间，其列是指标矢量 $u_E, u_{p_x}, u_{p_y}, u_{p_z}$，其中每个 $u$ 在对应于其坐标类型的所有粒子位置上的条目为 $1$，其他位置为 $0$。到 $U$ 的列空间上的正交投影为\n$$\nP \\equiv U (U^\\top U)^{-1} U^\\top.\n$$\n定义异常分数\n$$\ns(x) \\equiv \\|(I - P)x\\|_2^2,\n$$\n即与背景子空间正交的残差的平方范数。\n\n您必须提出并实现一种归因方法，通过计算 $s(x)$ 相对于输入 $x$ 的积分梯度来定位事件中的异常组分。使用从零基线 $x_0 = 0$ 到输入 $x$ 的直线路径，以及每个分量 $i$ 的积分梯度的标准路径积分定义，\n$$\n\\mathrm{IG}_i(x) \\equiv (x_i - x_{0,i}) \\int_{0}^{1} \\frac{\\partial s\\big(x_0 + \\alpha (x - x_0)\\big)}{\\partial x_i}\\, d\\alpha.\n$$\n通过对每个组分 $i$ 的四个分量求和来聚合其归因值，\n$$\na_i \\equiv \\sum_{j \\in \\{E,p_x,p_y,p_z\\}} \\mathrm{IG}_{(i,j)}(x).\n$$\n\n使用两项测试来验证忠实性。\n\n1) 反事实移除：按 $a_i$（最高值）选出前 $k$ 个组分的索引，通过将其四维矢量设置为零矢量来移除它们，然后重新计算 $s(x)$。同样，移除后 $k$ 个组分并重新计算 $s(x)$。定义移除下降分数\n$$\n\\Delta_{\\mathrm{top}} \\equiv \n\\begin{cases}\n\\dfrac{s(x) - s(x_{\\text{remove-top-}k})}{s(x)},  \\text{if } s(x) > 0, \\\\\n0,  \\text{if } s(x) = 0,\n\\end{cases}\n\\quad\n\\Delta_{\\mathrm{bottom}} \\equiv \n\\begin{cases}\n\\dfrac{s(x) - s(x_{\\text{remove-bottom-}k})}{s(x)},  \\text{if } s(x) > 0, \\\\\n0,  \\text{if } s(x) = 0,\n\\end{cases}\n$$\n报告移除优势 $\\Delta_{\\mathrm{adv}} \\equiv \\Delta_{\\mathrm{top}} - \\Delta_{\\mathrm{bottom}}$。\n\n2) 粒子四维矢量的因果扰动：选择归因值最高的组分索引 $i^\\star \\equiv \\arg\\max_i a_i$ 和归因值最低的组分索引 $i_\\mathrm{min} \\equiv \\arg\\min_i a_i$。对于其中每一个，通过将三维动量 $\\vec{p} = (p_x,p_y,p_z)$ 缩放为 $(1-\\epsilon)\\,\\vec{p}$（给定 $\\epsilon > 0$）来对其施加一个小的因果扰动，然后设置其能量为 $E \\leftarrow \\|\\vec{p}\\|_2$ 以保持无质量条件。重新计算异常分数 $s(x_{\\text{perturb-top}})$ 和 $s(x_{\\text{perturb-bottom}})$，并定义扰动效价比\n$$\nR \\equiv \n\\frac{\\max\\big(s(x) - s(x_{\\text{perturb-top}}),\\, 0\\big) + \\delta}\n{\\max\\big(s(x) - s(x_{\\text{perturb-bottom}}),\\, 0\\big) + \\delta},\n$$\n使用固定的稳定常数 $\\delta = 10^{-12}$ 以避免除以零。更大的 $R$ 值表示，相比于对归因值最低的组分进行等效扰动，减小归因值最高的组分的动量能更有效地降低异常分数。\n\n此外，验证完备性属性\n$$\n\\sum_{i=1}^{D} \\mathrm{IG}_i(x) \\stackrel{?}{=} s(x) - s(x_0),\n$$\n并报告一个布尔值，指示 $|\\sum_i \\mathrm{IG}_i(x) - s(x)| \\leq 10^{-9}$ 是否成立。\n\n您的程序必须在以下测试套件上实现上述归因和验证。对于每个测试用例，首先通过提供的三维动量计算 $E_i = \\sqrt{p_{x,i}^2 + p_{y,i}^2 + p_{z,i}^2}$ 来构建事件的四维矢量，然后按规定顺序串联形成 $x$。使用 $\\epsilon = 0.1$。\n\n测试套件：\n- 案例1（正常路径）：$N=3$，$k=1$。三维动量：\n  - 粒子1：$(p_x,p_y,p_z) = (2.0, 0.1, 9.75)$，\n  - 粒子2：$(p_x,p_y,p_z) = (2.1, -0.2, 9.6)$，\n  - 粒子3：$(p_x,p_y,p_z) = (0.5, 6.0, 1.0)$。\n- 案例2（分数为零的边界情况）：$N=2$，$k=1$。三维动量：\n  - 粒子1：$(p_x,p_y,p_z) = (1.0, 2.0, 3.0)$，\n  - 粒子2：$(p_x,p_y,p_z) = (1.0, 2.0, 3.0)$。\n- 案例3（具有多个异常组分的边缘情况）：$N=4$，$k=2$。三维动量：\n  - 粒子1：$(p_x,p_y,p_z) = (3.0, 0.2, 2.0)$，\n  - 粒子2：$(p_x,p_y,p_z) = (3.2, -0.1, 1.9)$，\n  - 粒子3：$(p_x,p_y,p_z) = (0.0, 5.0, 0.5)$，\n  - 粒子4：$(p_x,p_y,p_z) = (-0.5, -4.5, 0.4)$。\n\n最终输出格式：\n您的程序必须输出一行，其中包含一个扁平列表，按顺序汇总三个案例的结果。对于每个案例，输出三元组\n$[\\text{completeness\\_ok},\\, \\Delta_{\\mathrm{adv}},\\, R]$，\n并将三个三元组串联成一个扁平列表。具体而言，您的输出必须是以下形式的一行\n$[\\text{b}_1,\\Delta_{\\mathrm{adv},1},R_1,\\text{b}_2,\\Delta_{\\mathrm{adv},2},R_2,\\text{b}_3,\\Delta_{\\mathrm{adv},3},R_3]$，\n其中每个 $\\text{b}_i$ 是一个布尔值，每个 $\\Delta_{\\mathrm{adv},i}$ 和 $R_i$ 是一个浮点数。",
            "solution": "用户要求我解决一个计算高能物理领域的问题，涉及异常检测、归因和验证。\n\n### 步骤1：问题验证\n\n我已仔细审阅了问题陈述。给定条件如下：\n- 将粒子事件表示为一组四维矢量和一个串联矢量 $x$ 的方法。\n- 无质量条件 $E = \\|\\vec{p}\\|_2$。\n- 通过矩阵 $U$ 中的指标矢量定义背景子空间的方法。\n- 正交投影矩阵的公式 $P = U(U^\\top U)^{-1}U^\\top$。\n- 异常分数 $s(x) = \\|(I-P)x\\|_2^2$ 的定义。\n- 使用零基线的积分梯度（IG）归因公式。\n- 组分级归因值 $a_i$ 的聚合方法。\n- 两项验证测试：反事实移除和因果扰动，以及 $\\Delta_{\\mathrm{adv}}$ 和 $R$ 的明确公式。\n- 一项验证测试：IG 的完备性属性。\n- 所有必需的参数（$\\epsilon=0.1, \\delta=10^{-12}$）和一个包含三个案例的完整测试套件。\n- 精确的输出格式。\n\n该问题具有科学依据，它将线性代数、矢量微积分和机器学习可解释性中已有的概念应用于一个简化但合理的物理场景。问题定义明确，所有定义和数据均已提供，确保存在唯一的可计算解。所有术语都是客观且精确定义的。未发现科学、形式或逻辑上的缺陷。问题有效。\n\n### 步骤2：推导与简化\n\n在实现之前，我将简化数学表达式以创建一个高效的算法。\n\n矩阵 $U \\in \\mathbb{R}^{4N \\times 4}$ 由四个正交的列向量 $u_k$ 组成，其中 $k \\in \\{E, p_x, p_y, p_z\\}$。每个向量有 $N$ 个条目为1，其余为0。内积为 $u_k^\\top u_j = N \\delta_{kj}$，其中 $\\delta_{kj}$ 是克罗内克δ。\n因此，$U^\\top U = N \\cdot I_4$，其中 $I_4$ 是 $4 \\times 4$ 单位矩阵。\n其逆矩阵为 $(U^\\top U)^{-1} = \\frac{1}{N} I_4$。\n投影矩阵简化为 $P = U (\\frac{1}{N} I_4) U^\\top = \\frac{1}{N} U U^\\top$。\n\n$P$ 对事件矢量 $x$ 的作用可以通过首先计算 $U^\\top x$ 来理解。此乘积得到一个 $4 \\times 1$ 的矢量，分别包含所有能量、所有 $p_x$、所有 $p_y$ 和所有 $p_z$ 分量的总和（即事件的总四维动量）。\n令 $\\bar{v} = (\\bar{E}, \\bar{p}_x, \\bar{p}_y, \\bar{p}_z)$ 为 $N$ 个组分的平均四维动量。那么矢量 $Px$ 是一个事件矢量，其中每个组分的四维动量都被替换为这个平均四维动量。\n\n因此，矢量 $(I-P)x = x - Px$ 是偏差的事件矢量，其中每个组分的四维矢量被替换为其与平均四维矢量的偏差：$(E_i - \\bar{E}, p_{x,i} - \\bar{p}_x, \\dots)$。\n异常分数 $s(x) = \\|(I-P)x\\|_2^2$ 是这些偏差四维矢量平方范数的总和。它衡量了事件内四维动量的内部方差。\n$s(x) = \\sum_{i=1}^N \\left( (E_i - \\bar{E})^2 + (p_{x,i} - \\bar{p}_x)^2 + (p_{y,i} - \\bar{p}_y)^2 + (p_{z,i} - \\bar{p}_z)^2 \\right)$。\n\n对于归因，积分梯度的积分可以解析求解。分数函数是一个二次型，$s(y) = y^\\top (I-P) y$。其梯度为 $\\nabla s(y) = 2(I-P)y$。\n使用路径 $\\gamma(\\alpha) = \\alpha x$（因为基线 $x_0=0$），IG 公式变为：\n$$\n\\mathrm{IG}_i(x) = x_i \\int_0^1 \\frac{\\partial s(\\alpha x)}{\\partial(\\alpha x_i)} d\\alpha\n$$\n积分内的项是 $s$ 在 $\\alpha x$ 处的梯度的第 $i$ 个分量，即 $(2(I-P)(\\alpha x))_i = 2\\alpha((I-P)x)_i$。\n积分计算结果为：\n$$\n\\mathrm{IG}_i(x) = x_i \\cdot \\left( ((I-P)x)_i \\int_0^1 2\\alpha d\\alpha \\right) = x_i \\cdot ((I-P)x)_i \\cdot [\\alpha^2]_0^1 = x_i ((I-P)x)_i\n$$\n积分梯度矢量就是输入矢量 $x$ 和残差矢量 $(I-P)x$ 的逐元素乘积。\n\n完备性属性 $\\sum_{i} \\mathrm{IG}_i(x) = s(x)$ 直接从此简化形式得出：\n$$\n\\sum_i \\mathrm{IG}_i(x) = \\sum_i x_i ((I-P)x)_i = x^\\top (I-P)x\n$$\n由于 $P$ 是一个投影矩阵，$I-P$ 是对称且幂等的，所以 $s(x) = x^\\top (I-P)^\\top (I-P)x = x^\\top (I-P)x$。该属性在解析上成立，任何偏差都将归因于浮点误差。\n\n组分归因值 $a_j$ 是该粒子 IG 分量的总和，也就是该粒子的四维矢量与其与平均四维矢量偏差的点积。\n\n### 步骤3：算法实现\n\n解决方案将使用 Python 的 `numpy` 库来实现。\n1.  一个主循环遍历所有测试用例。\n2.  对于每个用例，调用一个 `process_case` 函数。\n3.  在 `process_case` 内部：\n    a. 根据给定的三维动量构建初始事件矢量 $x$，通过 $E = \\|\\vec{p}\\|_2$ 计算能量。\n    b. 根据上述简化公式定义辅助函数 `compute_s` 和 `compute_ig_vector`。它们对一个扁平化的事件矢量和粒子数 $N$ 进行操作。\n    c. 计算初始分数 $s(x)$ 和组分归因值 $\\{a_i\\}$。\n    d. 检查完备性属性。\n    e. 通过对归因值排序，确定前 $k$ 个和后 $k$ 个组分的索引。\n    f. 对于移除测试，通过将相应的四维矢量置零来创建两个新矢量 $x_{\\text{remove-top-}k}$ 和 $x_{\\text{remove-bottom-}k}$。计算它们的分数，并计算 $\\Delta_{\\mathrm{adv}}$。\n    g. 对于扰动测试，将归因值最高和最低的组分的动量按 $(1-\\epsilon)$ 缩放，重新计算它们的能量以保持无质量条件，并创建两个新的事件矢量。计算它们的分数，并计算比率 $R$。\n    h. 函数返回三元组 `(completeness_ok, delta_adv, R)`。\n4.  将所有用例的结果汇总到一个列表中，并按指定格式打印。\n\n这种结构化方法确保了问题的所有要求都得到精确满足。",
            "answer": "```python\nimport numpy as np\n\ndef compute_s(x_flat: np.ndarray, n_particles: int) - float:\n    \"\"\"Computes the anomaly score s(x) for a flattened event vector.\"\"\"\n    if n_particles == 0:\n        return 0.0\n    \n    four_vectors = x_flat.reshape(n_particles, 4)\n    \n    avg_four_vec = np.mean(four_vectors, axis=0)\n    devs = four_vectors - avg_four_vec\n    s = np.sum(devs**2)\n    return float(s)\n\ndef compute_ig_vector(x_flat: np.ndarray, n_particles: int) - np.ndarray:\n    \"\"\"Computes the vector of Integrated Gradients.\"\"\"\n    if n_particles == 0:\n        return np.zeros_like(x_flat)\n        \n    four_vectors = x_flat.reshape(n_particles, 4)\n    avg_four_vec = np.mean(four_vectors, axis=0)\n    \n    # The vector Px has the average four-vector repeated for each particle.\n    avg_vec_tiled = np.tile(avg_four_vec, n_particles)\n    \n    # Residual vector (I-P)x\n    residual_vec = x_flat - avg_vec_tiled\n    \n    # IG(x) = x element-wise-product (I-P)x\n    ig_vec = x_flat * residual_vec\n    return ig_vec\n\ndef process_case(three_momenta, k, epsilon, delta):\n    \"\"\"Processes a single test case to compute validation metrics.\"\"\"\n    \n    n_particles = len(three_momenta)\n    if n_particles == 0:\n        return True, 0.0, 1.0\n\n    # Step 1: Construct the input vector x from three-momenta\n    four_vectors_list = []\n    for p_vec_tuple in three_momenta:\n        p_vec = np.array(p_vec_tuple, dtype=np.float64)\n        energy = np.linalg.norm(p_vec)\n        four_vectors_list.append(np.concatenate(([energy], p_vec)))\n    \n    four_vectors = np.array(four_vectors_list)\n    x = four_vectors.flatten()\n\n    # Step 2: Calculate original anomaly score\n    s_x = compute_s(x, n_particles)\n\n    # Step 3: Compute Integrated Gradients and constituent attributions\n    ig_vector = compute_ig_vector(x, n_particles)\n    attributions = np.sum(ig_vector.reshape(n_particles, 4), axis=1)\n\n    # Step 4: Verify completeness property\n    completeness_ok = np.abs(np.sum(ig_vector) - s_x)  1e-9\n\n    # Find ranked indices for attributions\n    sorted_indices = np.argsort(attributions)\n\n    # Step 5: Faithfulness Test 1: Counterfactual removals\n    top_k_indices = sorted_indices[-k:]\n    bottom_k_indices = sorted_indices[:k]\n\n    x_rem_top = x.copy()\n    for idx in top_k_indices:\n        x_rem_top[idx*4:(idx+1)*4] = 0.0\n    s_rem_top = compute_s(x_rem_top, n_particles)\n\n    x_rem_bot = x.copy()\n    for idx in bottom_k_indices:\n        x_rem_bot[idx*4:(idx+1)*4] = 0.0\n    s_rem_bot = compute_s(x_rem_bot, n_particles)\n\n    if s_x > 1e-12:\n        delta_top = (s_x - s_rem_top) / s_x\n        delta_bottom = (s_x - s_rem_bot) / s_x\n    else:\n        delta_top = 0.0\n        delta_bottom = 0.0\n    \n    delta_adv = delta_top - delta_bottom\n\n    # Step 6: Faithfulness Test 2: Causal perturbations\n    i_star = sorted_indices[-1]\n    i_min = sorted_indices[0]\n\n    # Perturb top-attributed constituent\n    x_pert_top_4vecs = four_vectors.copy()\n    p_vec_top = x_pert_top_4vecs[i_star, 1:4]\n    p_vec_top_pert = (1.0 - epsilon) * p_vec_top\n    x_pert_top_4vecs[i_star, 1:4] = p_vec_top_pert\n    x_pert_top_4vecs[i_star, 0] = np.linalg.norm(p_vec_top_pert)\n    s_pert_top = compute_s(x_pert_top_4vecs.flatten(), n_particles)\n\n    # Perturb bottom-attributed constituent\n    x_pert_bot_4vecs = four_vectors.copy()\n    p_vec_bot = x_pert_bot_4vecs[i_min, 1:4]\n    p_vec_bot_pert = (1.0 - epsilon) * p_vec_bot\n    x_pert_bot_4vecs[i_min, 1:4] = p_vec_bot_pert\n    x_pert_bot_4vecs[i_min, 0] = np.linalg.norm(p_vec_bot_pert)\n    s_pert_bot = compute_s(x_pert_bot_4vecs.flatten(), n_particles)\n\n    numerator = np.maximum(s_x - s_pert_top, 0) + delta\n    denominator = np.maximum(s_x - s_pert_bot, 0) + delta\n    R = numerator / denominator\n\n    return completeness_ok, delta_adv, R\n\ndef solve():\n    \"\"\"Main function to run all test cases and print results.\"\"\"\n    test_cases = [\n        {\n            \"momenta\": [(2.0, 0.1, 9.75), (2.1, -0.2, 9.6), (0.5, 6.0, 1.0)],\n            \"k\": 1,\n        },\n        {\n            \"momenta\": [(1.0, 2.0, 3.0), (1.0, 2.0, 3.0)],\n            \"k\": 1,\n        },\n        {\n            \"momenta\": [(3.0, 0.2, 2.0), (3.2, -0.1, 1.9), (0.0, 5.0, 0.5), (-0.5, -4.5, 0.4)],\n            \"k\": 2,\n        },\n    ]\n\n    epsilon = 0.1\n    delta = 1e-12\n    \n    results = []\n    for case in test_cases:\n        res_tuple = process_case(case[\"momenta\"], case[\"k\"], epsilon, delta)\n        results.extend(res_tuple)\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}