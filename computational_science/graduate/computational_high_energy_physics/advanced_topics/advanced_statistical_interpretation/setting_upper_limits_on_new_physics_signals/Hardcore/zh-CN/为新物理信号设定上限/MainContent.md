## 引言
在高能物理的前沿探索中，寻找超出标准模型的新物理现象是核心驱动力之一。然而，当实验数据中未出现明确的发现信号时，一个同样重要甚至更为常见的任务是：为潜在的新物理信号强度设定一个严格的置信上限。这个过程并非简单地宣告“我们什么都没看到”，而是要精确地量化我们的实验“看得有多清楚”，并对我们未能观测到的现象的规模给出一个统计上稳健的界限。这引出了一个核心问题：我们如何在一个充满统计涨落和实验不确定性的复杂环境中，做出科学上无懈可击的排除性论断？本文旨在系统性地解答这一问题，为读者提供一套完整的理论框架和实用指南。

在接下来的内容中，我们将分三个层次展开：首先，在“原理与机制”一章中，我们将深入[统计推断](@entry_id:172747)的核心，从构建[似然函数](@entry_id:141927)出发，详细阐述处理系统不确定性的剖面化方法，并重点介绍CLs准则等现代[高能物理](@entry_id:181260)中标准的[假设检验](@entry_id:142556)工具。其次，在“应用与交叉学科联系”一章中，我们将理论与实践相结合，探讨如何在真实的物理分析中构建复杂模型，例如组合多个测量通道、利用控制区约束背景，以及处理各类相关的不确定性。最后，通过“动手实践”部分，读者将有机会通过解决具体问题来巩固和应用所学知识。本指南将带领您从基本的统计概念走向能够独立理解和评价前沿物理研究中置信上限设定的高级应用。

## 原理与机制

本章旨在深入探讨为新物理信号设定上限所涉及的核心统计原理与机制。我们将从构建统计模型的基础——[似然函数](@entry_id:141927)——出发，系统地介绍如何处理系统不确定性，并详细阐述用于[假设检验](@entry_id:142556)和[置信区间](@entry_id:142297)构建的关键方法。我们的讨论将涵盖现代高能物理分析中两种主要的频率主义方法：基于[剖面似然比](@entry_id:753793)的方法（包括CLs准则）和Feldman-Cousins统一方法。最后，我们还将对频率主义的剖面化方法与贝叶斯主义的[边缘化](@entry_id:264637)方法进行概念性比较。

### [统计模型](@entry_id:165873)：[似然函数](@entry_id:141927)

在寻找新物理现象的粒子物理实验中，最基本的分析类型是**计数实验** (counting experiment)。其目标是将在预定义信号区域内观测到的事件数与理论模型预测进行比较。为了进行严格的[统计推断](@entry_id:172747)，我们首先需要一个能够描述数据与其背后物理模型参数之间关系的数学框架，这个框架的核心就是**似然函数 (likelihood function)**。

假设我们进行一个单通道计数实验，观测到的事件数为 $n$。我们预期这些事件来自两个独立的来源：我们寻找的新物理**信号 (signal)** 和已知的**本底 (background)** 过程。模型的参数包括一个非负的**信号强度参数 (signal strength parameter)** $\mu$，它用于缩放标称的信号产额 $s$（定义为 $\mu=1$ 时的预期信号事件数），以及一个本底产额 $b$。因此，预期的总事件数是 $\mu s + b$。

[粒子碰撞](@entry_id:160531)等量子过程是离散且随机的。在给定的时间或积分亮度下，某一特定类型的事件发生的次数可以很好地由**[泊松分布](@entry_id:147769) (Poisson distribution)** 描述。因此，我们可以合理地假设信号事件数 $N_s$ 和本底事件数 $N_b$ 是遵循[泊松分布](@entry_id:147769)的[独立随机变量](@entry_id:273896)，其均值分别为 $\mathbb{E}[N_s] = \mu s$ 和 $\mathbb{E}[N_b] = b$。

实验中观测到的总事件数 $n$ 是这两个过程实现的总和，即[随机变量](@entry_id:195330) $N = N_s + N_b$ 的一次观测。泊松分布的一个基本性质是其可加性：两个独立的泊松[随机变量](@entry_id:195330)之和仍然是一个泊松[随机变量](@entry_id:195330)，其均值为两者均值之和。因此，总事件数 $N$ 服从均值为 $\lambda = \mu s + b$ 的[泊松分布](@entry_id:147769)：
$N \sim \text{Poisson}(\mu s + b)$

似然函数 $L(\mu, b)$ 被定义为在给定模型参数（此处为 $\mu$ 和 $b$）下观测到特定数据（此处为 $n$）的概率。它在数值上等于相应[概率质量函数](@entry_id:265484)的值：
$L(\mu, b) = P(N=n | \mu, b) = \frac{(\mu s + b)^n \exp(-(\mu s + b))}{n!}$

这个表达式通常被简记为 $\text{Poisson}(n | \mu s + b)$。这种形式的[似然函数](@entry_id:141927)被称为**扩展[似然函数](@entry_id:141927) (extended likelihood)**，因为总事件数 $n$ 本身是一个[随机变量](@entry_id:195330)，其[期望值](@entry_id:153208)依赖于我们感兴趣的参数。这个模型的有效性建立在一系列基本假设之上：信号和本底事件独立地服从泊松统计；观测到的总数是两者之和；并且分析仅使用总计数，而不涉及每个事件的内部特征（如能量或角度）。对于更复杂的分析，例如多箱点分析 (binned analysis)，总似然函数是各个独立的箱点（bins）的泊松似然的乘积。

### 整合系统不确定性：[讨厌参数](@entry_id:171802)

在实际分析中，诸如本底产额 $b$ 或信号效率（已包含在 $s$ 中）等参数并非完美已知。这些不确定性被称为**系统不确定性 (systematic uncertainties)**，并通过引入**[讨厌参数](@entry_id:171802) (nuisance parameters)**，通常记为 $\theta$，来进行建模。例如，一个具有不确定性的本底产额可以被写成 $\theta b_0$，其中 $b_0$ 是标称值，而 $\theta$ 是一个围绕 $1$ 波动的[讨厌参数](@entry_id:171802)。

这些[讨厌参数](@entry_id:171802)的值通常通过**[辅助测量](@entry_id:143842) (auxiliary measurements)** 来约束，例如在信号预期可以忽略的**控制区 (control regions)** 中进行测量。一个常见的做法是假设对 $\theta$ 的测量服从**[高斯分布](@entry_id:154414) (Gaussian distribution)**。假设我们对 $\theta$ 的一次[辅助测量](@entry_id:143842)给出的观测值是 $\theta_0$，其[标准差](@entry_id:153618)为 $\sigma$。那么，这个约束可以表示为一个高斯概率密度函数，它作为[似然函数](@entry_id:141927)的一个额外因子。

因此，包含[讨厌参数](@entry_id:171802)的[联合似然](@entry_id:750952)函数是主测量似然与所有约束项[似然](@entry_id:167119)的乘积。对于我们带有一个高斯约束的[讨厌参数](@entry_id:171802) $\theta$ 的计数实验，[联合似然](@entry_id:750952)函数形如：
$L(\mu, \theta) = L_{\text{main}}(n | \mu, \theta) \times L_{\text{constraint}}(\theta_0 | \theta)$
$L(\mu, \theta) = \left[ \frac{(\mu s + \theta b_0)^n \exp(-(\mu s + \theta b_0))}{n!} \right] \times \left[ \frac{1}{\sqrt{2\pi}\sigma} \exp\left( -\frac{(\theta - \theta_0)^2}{2\sigma^2} \right) \right]$

在[对数似然函数](@entry_id:168593) $\ell(\mu, \theta) = \ln L(\mu, \theta)$ 中，高斯约束项表现为一个加法“惩罚项”：
$\ell(\mu, \theta) = n \ln(\mu s + \theta b_0) - (\mu s + \theta b_0) - \frac{(\theta - \theta_0)^2}{2\sigma^2} + \text{const.}$
这个二次惩罚项使得 $\theta$ 的值偏离其测量中心值 $\theta_0$ 时，对数似然会减小，惩罚的强度由 $\sigma$ 的大小决定。$\sigma$ 越小，约束越强。

### [频率主义推断](@entry_id:749593)中[讨厌参数](@entry_id:171802)的处理：剖面化

在频率主义统计框架中，为了对感兴趣的参数（如 $\mu$）进行推断，必须处理掉[讨厌参数](@entry_id:171802)（如 $\theta$）。一种强大的主流技术是**剖面化 (profiling)**。

剖面化的核心思想是，对于每一个固定的 $\mu$ 值，我们通过最大化似然函数来找到最“适配”的[讨厌参数](@entry_id:171802) $\theta$ 的值。这个在给定 $\mu$ 条件下最大化[似然](@entry_id:167119)的 $\theta$ 值被称为 $\theta$ 的**条件[最大似然估计](@entry_id:142509) (conditional Maximum Likelihood Estimate, MLE)**，记为 $\hat{\hat{\theta}}(\mu)$ 。
$\hat{\hat{\theta}}(\mu) = \underset{\theta}{\operatorname{arg\,max}} \, L(\mu, \theta)$

将这个条件MLE代回原始似然函数，我们便得到了一个仅依赖于 $\mu$ 的函数，即**[剖面似然](@entry_id:269700)函数 (profile likelihood function)**：
$L_p(\mu) = L(\mu, \hat{\hat{\theta}}(\mu))$

剖面化过程体现了一种**[方差](@entry_id:200758)-偏倚权衡 (variance-bias trade-off)** 。考虑[讨厌参数](@entry_id:171802) $\theta$ 的约束强度 $\sigma$ 的影响：
-   当 $\sigma \to 0$ 时（强约束），$\theta$ 被有效地固定在它的测量值 $\theta_0$。这减少了由 $\theta$ 的不确定性引入的 $\mu$ 估计量的**[方差](@entry_id:200758)**。然而，如果[辅助测量](@entry_id:143842)本身是有偏的（即 $\theta_0$ 不等于 $\theta$ 的真实值 $\theta^\star$），这种强约束会阻止模型进行调整，从而在 $\mu$ 的估计中引入一个无法随数据量增加而消除的**偏倚 (bias)**。
-   当 $\sigma \to \infty$ 时（无约束），[辅助测量](@entry_id:143842)不提供任何信息。模型在拟合主测量数据时可以自由调整 $\theta$。这消除了来自约束的偏倚，但代价是 $\mu$ 和 $\theta$ 之间可能存在的高度相关性，导致 $\mu$ [估计量的方差](@entry_id:167223)急剧增大。

因此，剖面化通过在每个 $\mu$ 点上重新优化[讨厌参数](@entry_id:171802)，在数据自身（主测量）提供的关于 $\theta$ 的信息和外部约束（[辅助测量](@entry_id:143842)）提供的信息之间取得平衡。

### 基于[剖面似然比](@entry_id:753793)的假设检验

[剖面似然](@entry_id:269700)函数是构建[检验统计量](@entry_id:167372)以进行假设检验的基础。在现代高能物理中，最常用的[检验统计量](@entry_id:167372)是**[剖面似然比](@entry_id:753793) (profile likelihood ratio, PLR)**，定义为 ：
$\lambda(\mu) = \frac{L_p(\mu)}{L(\hat{\mu}, \hat{\theta})} = \frac{L(\mu, \hat{\hat{\theta}}(\mu))}{L(\hat{\mu}, \hat{\theta})}$

这里的分母 $L(\hat{\mu}, \hat{\theta})$ 是似然函数在所有参数（包括 $\mu$ 和 $\theta$）下的[全局最大值](@entry_id:174153)，其中 $(\hat{\mu}, \hat{\theta})$ 是无条件[最大似然估计](@entry_id:142509)。由于分子是在参数空间的一个[子空间](@entry_id:150286)上最大化的[似然](@entry_id:167119)，而分母是[全局最大值](@entry_id:174153)，因此该比率的值域为 $0 \lt \lambda(\mu) \le 1$。

为了方便处理，我们通常使用[检验统计量](@entry_id:167372) $t_\mu = -2 \ln \lambda(\mu)$。根据**[威尔克斯定理](@entry_id:169826) (Wilks' Theorem)**，在大样本极限下，如果模型被正确指定，并且被检验的参数 $\mu$ 的真实值位于其允许范围的内部，那么 $t_\mu$ 的[抽样分布](@entry_id:269683)将近似为一个自由度等于被固定参数数量的**卡方分布 ($\chi^2$ distribution)**。在此例中，我们固定了1个参数（$\mu$），所以 $t_\mu \sim \chi^2_1$。值得注意的是，如果模型被错误指定（例如，[讨厌参数](@entry_id:171802)的约束是有偏的），这个[渐近性质](@entry_id:177569)可能不成立，从而影响覆盖性质 。

对于特定的物理问题，如发现新信号或设定排除上限，我们需要构建**单边 (one-sided)** 的[检验统计量](@entry_id:167372)：

-   **发现新信号 (Discovery)**：目的是检验**仅本底假设 ($\mu=0$)**。我们只关心数据是否出现了超出本底预期的“向上”涨落。因此，定义发现统计量 $q_0$ ：
    $q_0 = \begin{cases} -2 \ln \lambda(0)  & \text{if } \hat{\mu} \ge 0 \\ 0  & \text{if } \hat{\mu}  0 \end{cases}$
    如果数据的最佳拟合 $\hat{\mu}$ 为负（一个无物理意义的向下落），这并不构成反对 $\mu=0$ 假设的证据，因此 $q_0$ 被设为0。

-   **设定上限 (Setting Limits)**：目的是检验一个特定的**信号假设 ($\mu  0$)**。我们关心的是数据是否与这样一个信号的存在“不兼容”，即出现了“向下”的落。因此，定义用于设定上限的统计量 $q_\mu$ ：
    $q_\mu = \begin{cases} -2 \ln \lambda(\mu)   \text{if } 0 \le \hat{\mu} \le \mu \\ 0   \text{if } \hat{\mu}  \mu \end{cases}$
    如果数据的最佳拟合 $\hat{\mu}$ 甚至超过了我们正在检验的 $\mu$ 值，这显然不构成反对该 $\mu$ 值的证据，因此 $q_\mu$ 被设为0。

由于物理边界 $\mu \ge 0$ 的存在，这些单边[检验统计量](@entry_id:167372)的[渐近分布](@entry_id:272575)不再是简单的 $\chi^2_1$ 分步。根据**切尔诺夫定理 (Chernoff's Theorem)**，它们的[分布](@entry_id:182848)是**[混合分布](@entry_id:276506)**：有一半的概率[质量集中](@entry_id:175432)在 $0$ 处（对应于 $\hat{\mu}$ 落在“非证据”一侧的情况），另一半则遵循 $\chi^2_1$ [分布](@entry_id:182848)。即其概率密度函数为 $f(q_\mu) = \frac{1}{2}\delta(q_\mu) + \frac{1}{2}f_{\chi^2_1}(q_\mu)$ 。这个精确的[渐近分布](@entry_id:272575)对于计算p值和校准[置信区间](@entry_id:142297)至关重要。

### 设定上限：CLs方法

有了[检验统计量](@entry_id:167372) $q_\mu$ 及其[分布](@entry_id:182848)，我们就可以计算**p值 (p-value)**，即在给定假设下，观测到与该假设同等或更不相容结果的概率。对于检验信号强度为 $\mu$ 的假设，p值定义为：
$p_\mu = P(q_\mu \ge q_{\mu, \text{obs}} | \text{hypothesis } \mu)$
其中 $q_{\mu, \text{obs}}$ 是从真实观测数据中计算出的检验统计量的值。这个p值在文献中常被称为 $CL_{s+b}$（信号+本底假设的[置信水平](@entry_id:182309)）。

一个朴素的频率主义方法是：如果 $p_\mu = CL_{s+b}$ 小于某个阈值 $\alpha$（例如 $0.05$），则在 $1-\alpha$ 的[置信水平](@entry_id:182309)上排除该信号假设 $\mu$。然而，这种方法存在一个严重问题：在实验灵敏度不足的情况下（例如，本底预期很高而信号预期很低），一次偶然的本底向下落就可能导致 $p_\mu$ 变得很小，从而“排除”一个我们实际上根本没有能力探测到的信号。这被称为**伪排除 (spurious exclusion)** 。

为了解决这个问题，[高能物理](@entry_id:181260)界广泛采用了**CLs方法**。该方法引入了另一个量 $CL_b$，它是在**仅本底假设 ($\mu=0$)** 下，观测到与信号假设同等或更不相容结果的概率：
$CL_b = P(q_\mu \ge q_{\mu, \text{obs}} | \text{hypothesis } \mu=0)$

然后，定义修正后的[检验统计量](@entry_id:167372) **CLs**：
$CL_s = \frac{CL_{s+b}}{CL_b}$

排除判据被修改为 $CL_s \le \alpha$。这种修正的逻辑如下  ：
-   当出现一次本底向下落时，观测结果不仅与信号+本底假设不符（$CL_{s+b}$ 小），也与仅本底假设不符（$CL_b$ 也很小）。
-   在这种情况下，$CL_s$ 的值由于除以了一个小数 $CL_b$ 而被“抬高”了，从而变得不再显著小于 $\alpha$，进而避免了伪排除。
-   相反，在实验灵敏度很高的区域，任何与信号假设不符的数据（小的 $CL_{s+b}$）都不太可能是仅本底过程能产生的（$CL_b \to 1$），因此 $CL_s \approx CL_{s+b}$。这意味着CLs方法在需要时是保守的，但在有足够[统计功效](@entry_id:197129)时又能恢复到标准频率主义测试的灵敏度。

最终，某个[置信水平](@entry_id:182309)（例如 $95\%$）下的信号强度**上限 (upper limit)** $\mu_{\text{up}}$ 就是通过求解方程 $CL_s(\mu_{\text{up}}) = 0.05$ 得到的 $\mu$ 值。

### 另一种频率主义方法：Feldman-Cousins构造

在基于[剖面似然比](@entry_id:753793)的方法之外，还有另一种重要的频率主义方法来构建置信区间，即**Feldman-Cousins (FC)统一方法**。此方法基于**奈曼置信带 (Neyman confidence belt)** 的[构造原理](@entry_id:141667)，旨在提供具有正确**覆盖 (coverage)** 特性且从不产生空区间的[置信区间](@entry_id:142297)，并能自然地从双边区间过渡到单边上限。

FC方法的核心步骤如下 ：
1.  **定义排序准则**：对于每一个固定的参数值 $\mu$，我们需要一种方法来对所有可能的观测结果 $n$ 进行排序，从“最可能”到“最不可能”。FC方法使用的排序准则是一个似然比：
    $R(n | \mu) = \frac{L(n | \mu)}{L(n | \hat{\mu}(n))}$
    这里的 $L(n|\mu)$ 是给定 $\mu$ 时观测到 $n$ 的[似然](@entry_id:167119)，而分母 $L(n|\hat{\mu}(n))$ 是对于这个特定的观测值 $n$，在所有物理允许的参数值中能够达到的[最大似然](@entry_id:146147)。$\hat{\mu}(n)$ 是 $\mu$ 的**受物理边界约束的[最大似然估计](@entry_id:142509)**，对于泊松过程，$\hat{\mu}(n) = \max(0, n-b)$ 。$R(n|\mu)$ 越大的观测值 $n$ 被认为与假设 $\mu$ 越兼容。

2.  **构建接受域**：对于每一个 $\mu$ 值，我们从 $R$ 值最大的 $n$ 开始，逐个将观测结果加入**接受域 (acceptance region)** $C(\mu)$，直到该区域内所有 $n$ 的总概率 $\sum_{n \in C(\mu)} P(n | \mu)$ 至少达到预设的[置信水平](@entry_id:182309) $1-\alpha$。

3.  **反演置信带**：所有 $(\mu, C(\mu))$ 对的集合构成了奈曼置信带。对于一个具体的实验观测值 $n_{\text{obs}}$，其对应的[置信区间](@entry_id:142297)就是所有接受域包含 $n_{\text{obs}}$ 的 $\mu$ 值的集合：$\{\mu | n_{\text{obs}} \in C(\mu)\}$。该区间的上界即为 $\mu$ 的上限 。

FC方法的一个关键优点是它通过排序准则的设计，保证了置信区间永远不会为空 。这是因为对于任何观测值 $n_{\text{obs}}$，其物理最佳拟合值 $\hat{\mu}(n_{\text{obs}})$ 一定会被包含在最终的置信区间内。此外，当观测结果与仅本底假设相容时（例如，观测到的事件数小于预期的本[底数](@entry_id:754020)），该方法会自动生成一个单边上限（例如 $[0, \mu_{\text{up}}]$），而在观测到显著信号时，则会生成一个双边区间。这种平滑过渡是其被称为“统一方法”的原因 。

### 概念比较：剖面化 vs. [边缘化](@entry_id:264637)

处理[讨厌参数](@entry_id:171802)的频率主义“剖面化”方法有一个重要的概念对应物，即**贝叶斯 (Bayesian)** 统计中的**[边缘化](@entry_id:264637) (marginalization)**。

-   **剖面化 (Profiling)**：对于每个感兴趣的参数值 $\mu$，通过**最大化**似然函数来选择[讨厌参数](@entry_id:171802) $\theta$ 的“最佳”值 $\hat{\hat{\theta}}(\mu)$。
-   **边缘化 (Marginalization)**：通过在[讨厌参数](@entry_id:171802) $\theta$ 的整个空间上进行**积分**，并用其[先验概率](@entry_id:275634)密度 $\pi(\theta)$ 进行加权，来消除 $\theta$。这会得到 $\mu$ 的边缘后验概率密度 $p(\mu | \text{data})$。

这两种方法在特定条件下会得出相似的结论，但在其他情况下则可能产生显著差异 ：

-   **相似性**：在大样本极限下，如果似然函数可以很好地被一个多维高斯函数近似（即[对数似然](@entry_id:273783)是二次型），并且为[讨厌参数](@entry_id:171802)选择的[贝叶斯先验](@entry_id:183712)与频率主义约束项在功能上一致，那么剖面化和[边缘化](@entry_id:264637)通常会得到数值上非常接近的 $\mu$ 上限。这是因为积分和最大化在一个高斯峰上会指向相同的位置。

-   **差异性**：在小样本统计区域，或者当参数估计接近物理边界（如 $\mu=0$）时，似然函数的非高斯特性会变得非常重要。此时，[威尔克斯定理](@entry_id:169826)等[渐近理论](@entry_id:162631)失效，频率主义方法的校准变得困难。而贝叶斯方法虽然在数学上仍然定义良好，但其结果可能对先验的选择变得敏感。因此，在这种低计数、边界效应显著的 régime 中，两种方法得出的上限可能存在实质性差异 。

总之，[剖面似然](@entry_id:269700)和CLs方法构成了当前高能物理领域设定排除上限的标准频率主义工具箱。它们提供了一套经过充分检验的、稳健的程序来处理统计和系统不确定性。与此同时，理解像Feldman-Cousins这样的替代方法以及与贝叶斯方法的深刻概念联系，对于全面掌握新物理探索中的[统计推断](@entry_id:172747)艺术至关重要。