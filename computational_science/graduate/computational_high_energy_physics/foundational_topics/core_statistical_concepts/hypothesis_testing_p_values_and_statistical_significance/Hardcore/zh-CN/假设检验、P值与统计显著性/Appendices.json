{
    "hands_on_practices": [
        {
            "introduction": "这个练习将我们带回到假设检验的基础。我们将处理一个粒子物理学中的现实问题：通过测量电荷不对称性来检验CP破坏。核心教学目标是从第一性原理出发，推导出一个精确的$p$值，并学习如何通过构建条件检验来巧妙地消除讨厌的参数（如未知的探测效率和事例率）。",
            "id": "3517328",
            "problem": "在一项于强子对撞机上寻找重味衰变道中电荷-宇称（CP）破坏的搜索中，一项分析对重建到电荷共轭末态的衰变进行计数，得到观测计数 $N^{+}$ 和 $N^{-}$。CP不对称性估计量定义为 $A=\\frac{N^{+}-N^{-}}{N^{+}+N^{-}}$。假设在粒子产生和衰变层面，衰变到两种电荷共轭末态的衰变数由独立的泊松过程生成，其均值分别为 $\\frac{\\mu(1+A_{0})}{2}$ 和 $\\frac{\\mu(1-A_{0})}{2}$，其中 $\\mu>0$ 是一个未知的总率参数，$A_{0}$ 是真实的物理CP不对称性。每个产生的衰变都以一个共同的探测效率 $\\epsilon\\in(0,1]$ 被独立地重建，该效率未知且可能随时间变化，但在与这些计数相关的数据采集期间是恒定的。不存在本底。\n\n你的任务是使用精确的有限样本分布，检验原假设 $H_{0}:A_{0}=0$ 相对于一个双边备择假设。将未知的探测效率 $\\epsilon$ 视为一个讨厌参数，并使用适合计算高能物理的、基于似然的论证，通过剖析（profiling）来消除 $\\epsilon$。在 $H_{0}$ 下，基于 $|A|$（等价于 $|N^{+}-N^{-}|$）的极端性构建一个检验。从关于泊松过程、独立的伯努利探测以及给定总和时一个泊松分量的条件分布的第一性原理出发，推导出一个精确的、闭式的双边p值表达式，记为 $p(A)$，该表达式是在对 $\\epsilon$ 进行剖析后，作为观测到的 $A$ 和总计数 $N=N^{+}+N^{-}$ 的函数。\n\n你的最终答案必须是关于 $p(A)$ 的一个单一闭式解析表达式，用 $A$ 和 $N$ 表示。不要提供任何数值计算或近似，也不要包含物理单位。清晰地定义你引入的任何符号。双边p值必须使用 $H_{0}$ 下的精确分布构建，并且必须通过包含所有相对于 $|A|$ 而言至少与观测结果一样极端的结果来正确考虑数据的离散性。",
            "solution": "用户希望在一个计数实验中，推导用于检验无电荷-宇称（CP）不对称性（$H_0: A_0=0$）这一原假设的精确双边p值。\n\n### 步骤1：观测计数的统计模型\n\n设 $n^{+}$ 和 $n^{-}$ 是衰变到电荷共轭末态的真实衰变数。根据问题描述，它们是从泊松分布中抽取的独立随机变量：\n$$ n^{+} \\sim \\text{Pois}\\left(\\lambda^{+} = \\frac{\\mu(1+A_{0})}{2}\\right) $$\n$$ n^{-} \\sim \\text{Pois}\\left(\\lambda^{-} = \\frac{\\mu(1-A_{0})}{2}\\right) $$\n此处，$\\mu$ 是总产生率，$A_0$ 是真实的物理不对称性。\n\n这些衰变中的每一个都以一个共同的效率 $\\epsilon \\in (0,1]$ 被探测到。对任何单个衰变的观测都是一次独立的伯努利试验。泊松分布的一个已知性质是，如果我们用一个伯努利过程对其进行抽样（这个过程称为“稀疏化”），得到的计数分布也是泊松分布。因此，观测到的计数 $N^{+}$ 和 $N^{-}$ 也是具有修正均值的独立泊松随机变量：\n$$ N^{+} \\sim \\text{Pois}\\left(\\mu_{+} = \\epsilon \\lambda^{+} = \\frac{\\epsilon\\mu(1+A_{0})}{2}\\right) $$\n$$ N^{-} \\sim \\text{Pois}\\left(\\mu_{-} = \\epsilon \\lambda^{-} = \\frac{\\epsilon\\mu(1-A_{0})}{2}\\right) $$\n我们的可观测量 $N^{+}$ 和 $N^{-}$ 的模型依赖于感兴趣的参数 $A_0$ 以及两个讨厌参数 $\\mu$ 和 $\\epsilon$。我们可以将这两个讨厌参数合并成一个未知的总观测率 $\\mu_{\\text{obs}} = \\epsilon \\mu$。那么均值即为 $\\mu_{\\pm} = \\frac{\\mu_{\\text{obs}}(1\\pm A_0)}{2}$。\n\n### 步骤2：通过条件检验消除讨厌参数\n\n问题要求在消除讨厌参数 $\\epsilon$（并引申到 $\\mu$）后，使用精确的有限样本分布进行检验。在这种情况下，实现这一目标的标准且严谨的方法（问题中也明确建议了）是构建一个以总观测事件数 $N = N^{+} + N^{-}$ 为条件的检验。\n\n两个独立泊松变量之和也是一个泊松变量。因此，总计数 $N$ 服从均值为 $\\mu_{+}+\\mu_{-}$ 的泊松分布：\n$$ \\mu_{+}+\\mu_{-} = \\frac{\\mu_{\\text{obs}}(1+A_{0})}{2} + \\frac{\\mu_{\\text{obs}}(1-A_{0})}{2} = \\mu_{\\text{obs}} $$\n所以，$N \\sim \\text{Pois}(\\mu_{\\text{obs}})$。\n\n我们现在推导在总计数 $N=k_{tot}$ 的条件下，$N^{+}$ 的分布。对于任何可能的计数 $k \\in \\{0, 1, ..., k_{tot}\\}$，条件概率为：\n$$ P(N^{+} = k | N^{+} + N^{-} = k_{tot}) = \\frac{P(N^{+} = k \\text{ and } N^{-} = k_{tot}-k)}{P(N^{+} + N^{-} = k_{tot})} $$\n由于独立性，这等于：\n$$ P(N^{+} = k | N = k_{tot}) = \\frac{P(N^{+} = k) P(N^{-} = k_{tot}-k)}{P(N = k_{tot})} $$\n代入泊松概率质量函数（PMF）：\n$$ P(N^{+} = k | N = k_{tot}) = \\frac{\\left(\\frac{\\mu_{+}^{k} e^{-\\mu_{+}}}{k!}\\right) \\left(\\frac{\\mu_{-}^{k_{tot}-k} e^{-\\mu_{-}}}{(k_{tot}-k)!}\\right)}{\\frac{(\\mu_{+}+\\mu_{-})^{k_{tot}} e^{-(\\mu_{+}+\\mu_{-})}}{k_{tot}!}} $$\n指数项相互抵消。重新整理各项可得：\n$$ P(N^{+} = k | N = k_{tot}) = \\frac{k_{tot}!}{k!(k_{tot}-k)!} \\frac{\\mu_{+}^{k} \\mu_{-}^{k_{tot}-k}}{(\\mu_{+}+\\mu_{-})^{k_{tot}}} = \\binom{k_{tot}}{k} \\left(\\frac{\\mu_{+}}{\\mu_{+}+\\mu_{-}}\\right)^{k} \\left(1 - \\frac{\\mu_{+}}{\\mu_{+}+\\mu_{-}}\\right)^{k_{tot}-k} $$\n这是二项分布 $\\text{Binomial}(k_{tot}, p)$ 的概率质量函数（PMF）。其成功概率 $p$ 为：\n$$ p = \\frac{\\mu_{+}}{\\mu_{+}+\\mu_{-}} = \\frac{\\frac{\\mu_{\\text{obs}}(1+A_{0})}{2}}{\\mu_{\\text{obs}}} = \\frac{1+A_{0}}{2} $$\n至关重要的是，这个概率 $p$ 只依赖于我们感兴趣的参数 $A_0$，而不依赖于讨厌参数 $\\mu_{\\text{obs}} = \\epsilon \\mu$。因此，通过以总观测事件数 $N$ 为条件，我们成功地构建了一个独立于未知率和效率的检验框架。\n\n### 步骤3：构建p值\n\n原假设为 $H_{0}: A_{0}=0$。在 $H_0$ 下，二项分布的概率变为 $p_0 = \\frac{1+0}{2} = \\frac{1}{2}$。因此，在原假设下，$N^{+}$ 在总计数 $N$ 条件下的分布为：\n$$ (N^{+} | N, H_0) \\sim \\text{Binomial}\\left(N, \\frac{1}{2}\\right) $$\n该检验基于观测到的CP不对称性估计量 $A = \\frac{N^{+}-N^{-}}{N^{+}+N^{-}}$ 的极端性。我们可以用 $N^{+}$ 和固定的总计数 $N$ 来表示 $A$：\n$$ A = \\frac{N^{+} - (N-N^{+})}{N} = \\frac{2N^{+} - N}{N} $$\n因此，$|A|$ 的极端性等价于 $|2N^{+} - N|$ 的极端性，这又等价于检验 $N^{+}$ 的值是否远离其在 $H_0$ 下的期望值，即 $E[N^{+}|N, H_0] = N \\times p_0 = \\frac{N}{2}$。\n\n双边p值是在 $H_0$ 下计算得到的，观测到至少与实际观测结果一样极端的结果的概率。设观测到的计数为 $N^{+}_{\\text{obs}}$。该观测值的极端性由其与均值的距离 $|N^{+}_{\\text{obs}} - N/2|$ 来衡量。p值是所有可能的结果 $k$（对于随机变量 $N^{+}$）的概率之和，这些结果与均值的距离至少与观测值一样远：\n$$ p = P_{H_0}\\left(\\left|N^{+} - \\frac{N}{2}\\right| \\ge \\left|N^{+}_{\\text{obs}} - \\frac{N}{2}\\right| \\Big| N\\right) $$\n我们可以用观测到的不对称性 $A$ 和总计数 $N$ 来表示观测到的计数 $N^{+}_{\\text{obs}}$：\n$$ AN = 2N^{+}_{\\text{obs}} - N \\implies N^{+}_{\\text{obs}} = \\frac{N(1+A)}{2} $$\n将此代入极端性条件中：\n$$ \\left|N^{+}_{\\text{obs}} - \\frac{N}{2}\\right| = \\left|\\frac{N(1+A)}{2} - \\frac{N}{2}\\right| = \\left|\\frac{NA}{2}\\right| = \\frac{N|A|}{2} $$\n所以，一个结果 $k$ 至少与观测结果一样极端的条件是 $\\left|k - \\frac{N}{2}\\right| \\ge \\frac{N|A|}{2}$。\n\np值是所有满足此条件的 $k$ 的二项概率之和：\n$$ p(A) = \\sum_{k=0}^{N} P(N^{+}=k | N, H_0) \\cdot I\\left(\\left|k - \\frac{N}{2}\\right| \\ge \\frac{N|A|}{2}\\right) $$\n其中 $I(\\cdot)$ 是指示函数，当其参数为真时值为1，否则为0。代入二项概率 $P(N^{+}=k | N, H_0) = \\binom{N}{k}(\\frac{1}{2})^{N}$：\n$$ p(A) = \\sum_{k=0}^{N} \\binom{N}{k} \\left(\\frac{1}{2}\\right)^{N} I\\left(\\left|k - \\frac{N}{2}\\right| \\ge \\frac{N|A|}{2}\\right) $$\n这个表达式可以写作：\n$$ p(A) = \\left(\\frac{1}{2}\\right)^{N} \\sum_{k=0}^{N} \\binom{N}{k} I\\left(\\left|k - \\frac{N}{2}\\right| \\ge \\frac{N|A|}{2}\\right) $$\n这就是最终的、精确的、用于计算双边p值的闭式表达式。根据要求，它是观测到的不对称性 $A$ 和总计数 $N$ 的函数。这个有限和被认为是闭式形式，因为它不涉及极限、积分或递归。",
            "answer": "$$ \\boxed{ \\left(\\frac{1}{2}\\right)^{N} \\sum_{k=0}^{N} \\binom{N}{k} I\\left(\\left|k - \\frac{N}{2}\\right| \\ge \\frac{N|A|}{2}\\right) } $$"
        },
        {
            "introduction": "尽管精确检验是理想的，但物理学家们常常依赖于渐近近似的强大功能和便利性，例如源自Wilks定理的方法。这个动手实践将让你扮演一个批判性的科学家角色，使用蒙特卡洛模拟来检验这些方法的实际性能。你将专门探索它们在物理边界附近的挑战性低计数区间的行为，并量化“欠覆盖”（undercoverage）这一重要现象，即置信区间包含真实值的频率低于其名义置信水平。",
            "id": "3517351",
            "problem": "您的任务是量化一个信号强度参数的渐近剖面似然置信区间的经验覆盖率。这个实验是计算高能物理中典型的低计数统计计数实验。考虑一个简单的搜索通道，其具有单个计数区间的测量，其中观测值 $n$ 服从均值为 $\\mu = s + b$ 的泊松分布，其中 $s \\ge 0$ 是非负信号产额，$b \\ge 0$ 是已知的本底产额。单次观测的似然函数为 $L(n \\mid s) \\propto (s + b)^{n} e^{-(s+b)}$，相应的对数似然函数为 $\\ell(n \\mid s) = n \\log(s+b) - (s+b)$（忽略不依赖于 $s$ 的加法常数）。最大似然估计 (MLE) 满足 $\\hat{s} = \\max(0, n - b)$。剖面似然比为 $\\lambda(s) = L(n \\mid s) / L(n \\mid \\hat{s})$，相应的似然比检验统计量为 $q(s) = -2 \\log \\lambda(s) = 2 [\\ell(n \\mid \\hat{s}) - \\ell(n \\mid s)]$。根据 Wilks 定理，在正则性条件下和渐近区域内，对于固定的 $s$，$q(s)$ 在分布上收敛于自由度为一的卡方分布。\n\n在实践中，在低计数且存在非负边界 $s \\ge 0$ 的情况下，通过反演检验 $q(s) \\le c_{\\alpha}$（其中 $c_{\\alpha}$ 是自由度为一的卡方分布的 $(1 - \\alpha)$ 分位数）所构建的双边渐近置信区间可能会出现覆盖不足。您的任务是使用蒙特卡洛模拟来根据真实信号 $s$ 的函数，凭经验测量这些渐近区间在低计数下的覆盖率。\n\n您的程序必须从第一性原理出发实现以下内容：\n- 具有已知本底 $b$ 和非负信号强度 $s$ 的单次计数实验的泊松模型。\n- 剖面似然比检验统计量 $q(s) = 2 [\\ell(n \\mid \\hat{s}) - \\ell(n \\mid s)]$，其中 $\\hat{s} = \\max(0, n - b)$。\n- 渐近反演规则，该规则将双边集合 $\\{ s \\ge 0 : q(s) \\le c_{\\alpha} \\}$ 定义为 $s$ 的 $(1 - \\alpha)$ 置信区间，其中 $c_{\\alpha}$ 是自由度为一的 $(1 - \\alpha)$ 卡方临界值。\n- 对于给定的观测计数 $n$、本底 $b$ 和水平 $\\alpha$，通过求解 $q(s) = c_{\\alpha}$ 来数值确定区间的下端点和上端点，并满足 $s \\ge 0$ 的约束。不允许使用任何封闭形式的快捷方法；需在 $q(s) - c_{\\alpha}$ 上使用单调区间法和求根法，并正确处理边界 $s = 0$。\n- 蒙特卡洛覆盖率估计：对于给定的真实 $s$ 和 $b$，模拟 $N$ 次独立观测 $n \\sim \\text{Poisson}(s + b)$，为每个观测到的 $n$ 计算渐近区间，并将经验覆盖率计算为真实值 $s$ 落在所构建区间内（包括端点）的模拟次数所占的比例。为保证可复现性，请使用固定的随机种子 $123456$。\n\n您的推导和实现只能基于以下基本要素：独立计数的泊松似然函数、剖面似然比的定义及其渐近卡方行为（Wilks 定理），以及最大似然估计的基本性质。请勿使用任何预先制表的区间公式或特定于问题的启发式方法。\n\n测试套件：\n实现并运行以下三个测试用例。对于每个用例，按所列顺序报告指定网格中每个 $s$ 值的经验覆盖率。\n\n- 用例 A（极低本底）：本底 $b = 0.5$，名义置信水平 $1 - \\alpha = 0.95$（即 $\\alpha = 0.05$），信号网格 $s \\in \\{0.0, 0.2, 0.5, 1.0, 2.0\\}$，蒙特卡洛重复次数 $N = 4000$。\n- 用例 B（中等本底）：本底 $b = 3.0$，名义置信水平 $1 - \\alpha = 0.95$（即 $\\alpha = 0.05$），信号网格 $s \\in \\{0.0, 1.0, 2.0, 5.0\\}$，蒙特卡洛重复次数 $N = 4000$。\n- 用例 C（无本底，边界主导）：本底 $b = 0.0$，名义置信水平 $1 - \\alpha = 0.90$（即 $\\alpha = 0.10$），信号网格 $s \\in \\{0.0, 0.5, 1.0\\}$，蒙特卡洛重复次数 $N = 6000$。\n\n最终输出格式：\n您的程序应生成一行输出，其中包含一个包含在方括号中的逗号分隔列表形式的结果。每个测试用例的结果本身应该是一个浮点数经验覆盖率的列表，与该用例的 $s$ 网格相对应。例如，输出应类似于 $[[c_{A,1}, c_{A,2}, \\dots],[c_{B,1}, \\dots],[c_{C,1}, \\dots]]$，其中每个 $c_{\\cdot,\\cdot}$ 是一个表示为小数的 $[0,1]$ 范围内的浮点数。不应打印任何其他文本。",
            "solution": "该问题要求在一个单计数区间的泊松计数实验中，对通过剖面似然比方法导出的渐近置信区间的覆盖性质进行经验验证。任务的核心是执行蒙特卡洛模拟，以量化所构建的置信区间包含信号参数 $s$ 真实值的频率，特别是在渐近近似可能不太准确的低计数区域。\n\n该解决方案从第一性原理出发，遵循一系列逻辑步骤：定义统计模型，构建检验统计量，推导置信区间构建过程，并实现蒙特卡洛模拟以评估其性能。\n\n**1. 统计模型和似然函数**\n\n实验在一个计数区间中观测到 $n$ 个事件。该计数值假定服从泊松分布，其均值 $\\mu$ 是一个未知的非负信号产额 $s \\ge 0$ 和一个已知的非负本底产额 $b \\ge 0$ 的和。\n观测到 $n$ 个事件的概率由泊松概率质量函数给出：\n$$ P(n \\mid s, b) = \\frac{(s+b)^n e^{-(s+b)}}{n!} $$\n对于固定的观测值 $n$，参数 $s$ 的似然函数与此概率成正比：\n$$ L(s \\mid n) \\propto (s+b)^n e^{-(s+b)} $$\n在计算上，使用对数似然函数 $\\ell(s \\mid n) = \\log L(s \\mid n)$ 更为方便。忽略不依赖于 $s$ 的项，我们得到：\n$$ \\ell(s \\mid n) = n \\log(s+b) - (s+b) $$\n$s$ 的最大似然估计 (MLE)，记为 $\\hat{s}$，是在物理约束 $s \\ge 0$ 下最大化 $\\ell(s \\mid n)$ 的 $s$ 值。通过将导数 $\\frac{d\\ell}{ds} = \\frac{n}{s+b} - 1$ 设为零，我们发现无约束估计量为 $s = n-b$。结合边界条件 $s \\ge 0$，MLE 为：\n$$ \\hat{s} = \\max(0, n-b) $$\n\n**2. 剖面似然比检验统计量**\n\n为了构建 $s$ 的置信区间，我们使用剖面似然比检验。检验统计量 $q(s)$ 将一个假设的 $s$ 值下的似然与最大可能似然（即在 $\\hat{s}$ 处的似然）进行比较。剖面似然比 $\\lambda(s)$ 定义为：\n$$ \\lambda(s) = \\frac{L(s \\mid n)}{L(\\hat{s} \\mid n)} $$\n检验统计量 $q(s)$ 则由下式给出：\n$$ q(s) = -2 \\log \\lambda(s) = -2 (\\ell(s \\mid n) - \\ell(\\hat{s} \\mid n)) $$\n代入对数似然函数的表达式，得到：\n$$ q(s) = 2 \\left[ (n \\log(\\hat{s}+b) - (\\hat{s}+b)) - (n \\log(s+b) - (s+b)) \\right] $$\n根据 Wilks 定理，在大样本（渐近）极限下，对于固定的真实值 $s$，$q(s)$ 的分布收敛于自由度为一的卡方（$\\chi^2$）分布，对应于单个感兴趣的参数。\n\n**3. 通过检验反演构建置信区间**\n\n$s$ 的 $(1-\\alpha)$ 置信区间是通过“反演”假设检验来构建的。该区间由所有使得原假设 $H_0: s=s_0$ 在显著性水平 $\\alpha$ 下不被拒绝的 $s_0$ 值组成。该检验的拒绝域是 $q(s_0) > c_\\alpha$，其中 $c_\\alpha$ 是 $\\chi^2_1$ 分布的 $(1-\\alpha)$ 分位数（即 $P(\\chi^2_1 \\le c_\\alpha) = 1-\\alpha$）。因此，接受域，也就是置信区间，是满足以下条件的所有 $s$ 值的集合：\n$$ \\{ s \\ge 0 \\mid q(s) \\le c_\\alpha \\} $$\n该区间的端点 $s_{\\text{low}}$ 和 $s_{\\text{up}}$ 通过求解方程得到：\n$$ q(s) - c_\\alpha = 0 $$\n由于 $q(s)$ 通常不是一个简单的函数，其根必须通过数值方法找到。算法设计如下：\n- **求根函数**：我们定义一个函数 $f(s) = q(s) - c_\\alpha$，我们需要寻找它的根。\n- **下界 $s_{\\text{low}}$**：函数 $q(s)$ 在 $s=\\hat{s}$ 处有最小值 $q(\\hat{s}) = 0$。如果 $\\hat{s}=0$，则最小值在边界处，因此区间必须从 $s_{\\text{low}}=0$ 开始。如果 $\\hat{s} > 0$，我们在边界 $s=0$ 处评估 $q(s)$。如果 $q(0) \\le c_\\alpha$，则边界包含在区间内，因此 $s_{\\text{low}}=0$。如果 $q(0) > c_\\alpha$，则在 $(0, \\hat{s})$ 内必定存在一个根 $s_{\\text{low}}$。这个根通过在区间 $[0, \\hat{s}]$ 上使用区间法（如 Brent 方法）进行数值求解。\n- **上界 $s_{\\text{up}}$**：对于 $s > \\hat{s}$，函数 $q(s)$ 是单调递增的。上界 $s_{\\text{up}}$ 是 $f(s)=0$ 在 $s > \\hat{s}$ 区域的根。为了找到这个根，我们首先建立一个区间 $[\\ s_a, s_b ]$ 使得 $f(s_a)  0$ 且 $f(s_b) > 0$。我们可以设置 $s_a = \\hat{s}$（因为 $f(\\hat{s}) = -c_\\alpha  0$）。然后，我们通过从一个合理的猜测开始（例如，$s_{\\text{guess}} = \\hat{s} + \\sqrt{\\hat{s}+b+1}$）并扩展搜索范围（例如，通过将步长加倍）来寻找一个合适的 $s_b$，直到 $f(s_b) > 0$。一旦找到区间，就使用相同的数值求根器。\n\n**4. 用于经验覆盖率的蒙特卡洛模拟**\n\n模拟的目的是检查名义置信水平 $(1-\\alpha)$ 是否与该过程产生包含 $s$ 真实值的区间的实际比例相匹配。这个比例就是经验覆盖率。对于由真实信号 $s_{\\text{true}}$、本底 $b$ 和置信水平 $(1-\\alpha)$ 定义的每个测试用例，其过程如下：\n1. 固定参数 $s_{\\text{true}}$、$b$ 和 $\\alpha$。预先计算临界值 $c_\\alpha$。\n2. 使用固定的种子初始化随机数生成器以保证可复现性。\n3. 重复 $N$ 次（进行 $N$ 次蒙特卡洛“玩具”实验）：\n    a. 通过从均值为 $\\mu_{\\text{true}} = s_{\\text{true}} + b$ 的泊松分布中抽样，生成单个伪观测值 $n$。\n    b. 对于这个生成的 $n$，使用前一节中描述的数值过程计算置信区间 $[s_{\\text{low}}, s_{\\text{up}}]$。\n    c. 检查真实信号值是否在此计算出的区间内：$s_{\\text{low}} \\le s_{\\text{true}} \\le s_{\\text{up}}$。\n4. 经验覆盖率是成功“覆盖”（来自步骤 3c）的总次数除以总重复次数 $N$。\n5. 对于每个测试用例中指定网格中的每个 $s_{\\text{true}}$ 值，重复此过程。\n\n最终的 Python 实现将这些步骤封装到不同的函数中：一个用于对数似然函数，一个用于构建检验统计量 $q(s)$，一个用于为给定观测值计算置信区间，以及一个主模拟函数用于在多次重复中计算经验覆盖率。这种模块化设计直接反映了基于原理的推导过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\nfrom scipy.optimize import brentq\n\n# Define global seed for reproducibility as required by the problem\nSEED = 123456\n\ndef log_likelihood(s, n, b):\n    \"\"\"Computes the log-likelihood l(s|n) = n*log(s+b) - (s+b).\"\"\"\n    mu = s + b\n    # Use a small epsilon to avoid log(0) issues when s+b is effectively zero\n    if mu = 1e-15:\n        if n == 0:\n            return 0.0\n        else:\n            return -np.inf  # Effectively infinite -log(L)\n    return n * np.log(mu) - mu\n\ndef get_q_s_and_s_hat(n, b):\n    \"\"\"Returns a function for the test statistic q(s) and the MLE s_hat.\"\"\"\n    s_hat = max(0.0, n - b)\n    ll_s_hat = log_likelihood(s_hat, n, b)\n\n    def q_s(s):\n        \"\"\"Computes q(s) = 2 * (l(s_hat) - l(s)).\"\"\"\n        if s  0:\n            # For root finder robustness, signal strength s must be non-negative\n            return np.inf\n        \n        ll_s = log_likelihood(s, n, b)\n        if not np.isfinite(ll_s):\n            return np.inf # If log_likelihood is -inf, q becomes +inf\n            \n        test_statistic = 2 * (ll_s_hat - ll_s)\n        # By definition q(s) >= 0. Floating point precision might result in a small negative value.\n        return max(0.0, test_statistic)\n        \n    return q_s, s_hat\n\ndef compute_interval(n, b, c_alpha):\n    \"\"\"\n    Computes the (1-alpha) confidence interval [s_low, s_up] for a given\n    observation n, background b, and critical value c_alpha.\n    \"\"\"\n    q_s, s_hat = get_q_s_and_s_hat(n, b)\n\n    def root_func(s):\n        return q_s(s) - c_alpha\n\n    # --- Lower bound s_low ---\n    s_low = 0.0\n    # A root for the lower bound only exists if s_hat > 0 and q(0) > c_alpha.\n    if s_hat > 1e-9:\n        if root_func(0.0) > 1e-9: # Add tolerance for FP comparison\n            try:\n                # The root is between 0 and s_hat. brentq requires opposite signs.\n                # root_func(0) > 0 and root_func(s_hat) = -c_alpha  0\n                s_low = brentq(root_func, 0.0, s_hat)\n            except ValueError:\n                # Fallback for rare numerical precision issues at the boundaries.\n                if abs(root_func(0.0))  1e-9: s_low = 0.0\n                elif abs(root_func(s_hat))  1e-9: s_low = s_hat\n                else: s_low = 0.0\n\n    # --- Upper bound s_up ---\n    # The upper root is always > s_hat. Start search for a bracket [s_a, s_b].\n    s_a = s_hat\n    \n    # Find an upper search bracket s_b where root_func(s_b) > 0.\n    # The step size should scale with the expected width. sqrt(s_hat+b) ~ sqrt(n) is a good choice.\n    step = np.sqrt(s_hat + b + 1.0)\n    s_b = s_hat + step\n    \n    # Exponentially increase search range until bracket is found.\n    max_bracket_iters = 30\n    for _ in range(max_bracket_iters):\n        if root_func(s_b) > 0:\n            break\n        step *= 2.0\n        s_b = s_hat + step\n    else: # This else executes if the for-loop completes without a break.\n        return s_low, np.inf\n\n    try:\n        s_up = brentq(root_func, s_a, s_b)\n    except ValueError:\n        # Fallback for rare numerical precision issues at the boundaries.\n        if abs(root_func(s_a))  1e-9: s_up = s_a\n        elif abs(root_func(s_b))  1e-9: s_up = s_b\n        else: s_up = s_b\n    \n    return s_low, s_up\n\n\ndef run_mc_for_coverage(s_true_grid, b, alpha, N, rng):\n    \"\"\"\n    Runs the Monte Carlo simulation to estimate empirical coverage.\n    \"\"\"\n    c_alpha = chi2.ppf(1.0 - alpha, df=1)\n    coverages = []\n\n    for s_true in s_true_grid:\n        mu_true = s_true + b\n        \n        # Generate all toy observations at once for efficiency\n        observations = rng.poisson(lam=mu_true, size=N)\n        \n        coverage_count = 0\n        for n_obs in observations:\n            s_low, s_up = compute_interval(n_obs, b, c_alpha)\n            # Check if the true signal value is within the computed interval\n            if s_low = s_true = s_up:\n                coverage_count += 1\n        \n        coverages.append(coverage_count / N)\n    \n    return coverages\n\n\ndef solve():\n    \"\"\"\n    Defines test cases, runs the solver, and prints the final result in the specified format.\n    \"\"\"\n    test_cases = [\n        # Case A: very low background\n        {'b': 0.5, 'alpha': 0.05, 's_grid': [0.0, 0.2, 0.5, 1.0, 2.0], 'N': 4000},\n        # Case B: moderate background\n        {'b': 3.0, 'alpha': 0.05, 's_grid': [0.0, 1.0, 2.0, 5.0], 'N': 4000},\n        # Case C: no background, boundary-dominated\n        {'b': 0.0, 'alpha': 0.10, 's_grid': [0.0, 0.5, 1.0], 'N': 6000},\n    ]\n\n    # Initialize the random number generator with the specified seed for reproducibility\n    rng = np.random.default_rng(SEED)\n    \n    all_results = []\n    for case in test_cases:\n        results = run_mc_for_coverage(\n            s_true_grid=case['s_grid'],\n            b=case['b'],\n            alpha=case['alpha'],\n            N=case['N'],\n            rng=rng\n        )\n        all_results.append(results)\n\n    # Required output format: [[c_A_1,...],[c_B_1,...],[c_C_1,...]]\n    # Using str() on a list of lists produces this format but with spaces, which are then removed.\n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n\n```"
        },
        {
            "introduction": "在揭示了标准渐近区间在物理边界附近的局限性之后，我们现在转向高能物理学界广泛采用的解决方案：Feldman-Cousins统一方法。这个练习将指导你实现这一精巧的方法，它通过采用一种特殊的似然比排序原则来保证正确的覆盖范围。完成此实践后，你将深刻理解如何构建和解释统计上稳健的置信区间，这是寻找新物理现象的一项关键技能。",
            "id": "3517293",
            "problem": "考虑一个在高能物理计算中常见的计数实验，其中观测到的事件数 $n \\in \\{0,1,2,\\dots\\}$ 来自一个平均值为 $\\mu = s + b$ 的泊松过程。信号强度 $s$ 是一个未知的非负参数，受物理边界 $s \\ge 0$ 的约束，而本底 $b \\ge 0$ 是已知的。目标是研究统一的 Feldman–Cousins (FC) 置信区间在边界 $s \\ge 0$ 附近的覆盖范围，并将观测到的边界行为与 FC 构造固有的排序属性联系起来。\n\n定义与要求：\n- 数据模型为 $N \\sim \\mathrm{Poisson}(s + b)$。\n- 对于每个假设的 $s \\ge 0$，为 $n \\in \\{0,1,2,\\dots\\}$ 定义似然函数 $L(n \\mid s) \\propto (s+b)^n e^{-(s+b)}$。\n- 令 $\\hat{s}(n)$ 表示在约束 $s \\ge 0$ 下，给定 $n$ 时 $s$ 的有约束最大似然估计（maximum likelihood estimate, MLE）。对于已知的 $b$ 的泊松模型，该估计为 $\\hat{s}(n) = \\max\\{0, n - b\\}$。\n- Feldman–Cousins (FC) 统一排序使用似然比\n$$\nR(n; s) \\equiv \\frac{L(n \\mid s)}{L\\bigl(n \\mid \\hat{s}(n)\\bigr)},\n$$\n并且对于每个固定的 $s$，通过将结果 $n$ 按 $R(n; s)$ 从大到小排序，并不断纳入结果直到在 $N \\sim \\mathrm{Poisson}(s + b)$ 下的累积概率达到或超过目标置信水平 (CL)，来构造一个接受域 $\\mathcal{A}_s \\subset \\{0,1,2,\\dots\\}$。如果在纳入阈值处有多个结果共享相同的似然比值（即值相同），则将整个值相同的组都包括进来，以避免任意的平局处理。这样可以产生一个非随机化的接受域，其在 $s$ 下的概率至少为目标置信水平。\n- 对于一个观测值 $n_{\\mathrm{obs}}$，FC 构造报告的置信集是所有其接受域 $\\mathcal{A}_s$ 包含 $n_{\\mathrm{obs}}$ 的 $s$ 的集合。\n- 在固定的真实信号 $s_0$ 处的覆盖率，是指从一个抽样 $N \\sim \\mathrm{Poisson}(s_0 + b)$ 构造出的 FC 区间包含 $s_0$ 的长期概率。通过对位于 $s_0$ 接受域中的计数结果的概率进行求和来精确计算此覆盖率。不要使用蒙特卡洛模拟。通过选择一个足够大的求和上限 $n_{\\max}$ 来截断无限泊松和，使得被忽略的泊松尾部概率最多为 $10^{-15}$；在代码中用数值方式证明此截断的合理性，并确保接受域的构造考虑了截断边界处的平局，从而使最终覆盖率的绝对误差在 $10^{-12}$ 以内。\n\n任务：\n1. 实现一个程序，对于每个测试用例 $(s_0, b, \\mathrm{CL})$，根据上述排序规则构造 FC 接受域 $\\mathcal{A}_{s_0}$，并计算覆盖率\n$$\n\\mathrm{Cov}(s_0; b, \\mathrm{CL}) = \\sum_{n \\in \\mathcal{A}_{s_0}} \\Pr\\{N=n \\mid s_0 + b\\},\n$$\n使用精确的泊松概率，并在必要时通过对数来对下溢进行数值安全的处理。使用确定性的平局处理规则，即在阈值处包括所有共享相同似然比的结果，以确保非随机化覆盖率至少达到目标置信水平。\n2. 通过以下方式确保科学真实性和数值稳健性：\n   - 使用 $R(n; s_0)$ 的完整排序来构造接受域，在比率对数的 $10^{-12}$ 数值容差范围内对完全相等的比率进行分组。\n   - 在 $n_{\\max}$ 处截断泊松分布的支撑集，使得在 $N \\sim \\mathrm{Poisson}(s_0 + b)$ 下被忽略的尾部概率最多为 $10^{-15}$，并为 $n_{\\max}$ 添加一个小的整数安全余量，以保证没有值相同的组在边界处被人为分割。\n   - 验证所构造的接受集的累积概率至少为目标 $\\mathrm{CL}$（容差为 $10^{-12}$）；如果不满足，则自适应地增加 $n_{\\max}$ 直到满足此条件。\n3. 在你的解决方案报告中，解释排序规则如何与边界条件 $s \\ge 0$ 相互作用，以及为什么这会导致在 $s \\approx 0$ 附近出现特征性的覆盖行为。\n\n测试套件：\n为以下参数集 $(s_0, b, \\mathrm{CL})$ 计算覆盖率，其中所有数字均为实数，并以小数形式给出：\n- $(0.0, 3.0, 0.90)$\n- $(0.1, 3.0, 0.90)$\n- $(0.5, 3.0, 0.90)$\n- $(1.0, 3.0, 0.90)$\n- $(0.0, 0.5, 0.90)$\n- $(0.0, 3.0, 0.95)$\n- $(3.0, 3.0, 0.90)$\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含测试套件的覆盖率值，顺序与测试套件相同，四舍五入到小数点后六位，形式为逗号分隔的列表并用方括号括起来，例如 $\\texttt{[0.912345,0.901234,\\dots]}$。\n- 无需报告物理单位。不涉及角度。所有报告的覆盖率值必须是小数。",
            "solution": "该问题要求计算一个带已知本底的泊松过程中 Feldman-Cousins (FC) 置信区间的覆盖率，特别关注信号参数 $s=0$ 物理边界附近的行为。解决方案涉及精确实现用于接受域的 FC 构造方法，并解释其背后的统计原理。\n\n### 基于原理的设计\n\n问题的核心在于为给定的信号假设 $s_0$ 构建接受域 $\\mathcal{A}_s$。此构造过程由 Feldman-Cousins 排序原理主导，该原理基于似然比对可能的观测结果 $n$ 进行排序。\n\n1.  **模型与似然函数**：观测到的事件数 $n$ 服从泊松分布，其平均值为 $\\mu = s + b$，其中 $s$ 是信号强度，$b$ 是已知本底。概率质量函数 (PMF) 为 $P(n \\mid s, b) = \\frac{e^{-(s+b)}(s+b)^n}{n!}$。对于固定的观测值 $n$，似然函数作为 $s$ 的函数为 $L(n \\mid s) \\propto (s+b)^n e^{-(s+b)}$。\n\n2.  **排序原理**：FC 方法对于一个固定的假设信号 $s$，使用似然比来对结果 $n$ 进行排序：\n    $$\n    R(n; s) = \\frac{L(n \\mid s)}{L(n \\mid \\hat{s}(n))}\n    $$\n    其中 $\\hat{s}(n)$ 是观测值 $n$ 对应的 $s$ 的最大似然估计 (MLE)，受物理约束 $s \\ge 0$ 的限制。对于泊松平均值 $\\mu = s+b$，$\\mu$ 的无约束 MLE 是 $n$，这导致 $s$ 的无约束估计为 $n-b$。结合约束 $s \\ge 0$，得到有约束的 MLE：\n    $$\n    \\hat{s}(n) = \\max\\{0, n - b\\}\n    $$\n    比率的分母 $L(n \\mid \\hat{s}(n))$ 代表了在最佳拟合的物理允许假设下数据 $n$ 的似然。一个较大的比率 $R(n; s)$ 表示，与最佳可能解释相比，假设的 $s$ 能够相对较好地解释数据 $n$。\n\n3.  **比率的数值计算**：为了保持数值稳定性，我们使用该比率的对数进行计算。似然函数中与 $1/n!$ 成比例的项被消去，剩下：\n    $$\n    \\log R(n; s) = \\log\\left( \\frac{(s+b)^n e^{-(s+b)}}{(\\hat{s}(n)+b)^n e^{-(\\hat{s}(n)+b)}} \\right) = n \\log\\left(\\frac{s+b}{\\hat{s}(n)+b}\\right) - (s - \\hat{s}(n))\n    $$\n    令 $\\mu_0 = s_0 + b$ 为假设的平均值，$\\hat{\\mu}(n) = \\hat{s}(n) + b = \\max\\{b, n\\}$ 为观测值 $n$ 的最佳拟合平均值。对于一个检验假设 $s_0$，其对数似然比为：\n    $$\n    \\log R(n; s_0) = n \\log\\left(\\frac{\\mu_0}{\\hat{\\mu}(n)}\\right) - (\\mu_0 - \\hat{\\mu}(n))\n    $$\n    只要 $\\mu_0  0$ 且 $b \\ge 0$（这意味着对于所提供的测试用例 $\\hat{\\mu}(n)  0$），这种形式就是稳健的。\n\n4.  **构建接受域 $\\mathcal{A}_{s_0}$**：\n    a.  **为 $n$ 定义一个搜索空间**：泊松分布定义在所有 $n \\in \\{0, 1, 2, \\dots\\}$上。我们必须截断这个无限集合。我们找到一个整数 $n_{\\max}$，使得尾部概率 $\\sum_{n=n_{\\max}+1}^{\\infty} P(n \\mid s_0, b) \\le 10^{-15}$。这可以通过使用泊松分布的逆生存函数找到。为 $n_{\\max}$ 添加一个小的安全余量，以确保在截断点处任何具有相同排序值的组不会被人为地分割。\n    b.  **对结果进行排序**：对于从 $0$ 到 $n_{\\max}$ 的每个整数 $n$，我们计算对数似然比 $\\log R(n; s_0)$。\n    c.  **按排序值分组和排序**：我们识别出 $\\log R(n; s_0)$ 的唯一值（在 $10^{-12}$ 的数值容差内），并按降序对这些唯一的排序值进行排序。\n    d.  **累积概率**：我们遍历排序后的排序值。对于每个排序值，我们收集所有共享该排序值的 $n$ 值。我们将它们对应的泊松概率之和 $P(n \\mid s_0, b)$ 添加到一个运行中的累积概率中。我们将所有这些 $n$ 值添加到接受域 $\\mathcal{A}_{s_0}$ 中。一旦累积概率达到或超过目标置信水平 (CL)，该过程即停止。平局处理规则要求包含阈值排序处的所有结果组，这确保了覆盖率至少为 CL。\n\n5.  **计算覆盖率**：对于一个真实信号 $s_0$，其覆盖率是指一次实验产生的结果 $n$ 落入接受域 $\\mathcal{A}_{s_0}$ 的概率。根据构造，这恰好是上一步中计算出的最终累积概率。\n    $$\n    \\mathrm{Cov}(s_0; b, \\mathrm{CL}) = \\sum_{n \\in \\mathcal{A}_{s_0}} P(N=n \\mid s_0 + b)\n    $$\n\n### 与边界条件 $s \\ge 0$ 的相互作用\n\nFC 过程在物理边界 $s=0$ 附近的独特行为是排序规则与有约束最大似然估计 $\\hat{s}(n)$ 相互作用的直接结果。\n\n-   **在边界处 ($s_0=0$)**：假设是信号不存在。假设的平均值为 $\\mu_0 = b$。\n    -   对于观测到的计数 $n \\le b$，最佳拟合信号为 $\\hat{s}(n) = \\max\\{0, n-b\\} = 0$。最佳拟合假设与零假设（$s=0$）相同。\n    -   因此，对于所有 $n \\le \\lfloor b \\rfloor$，似然比为 $R(n; s_0=0) = 1$。\n    -   这造成了大规模的排序相同：所有结果 $n \\in \\{0, 1, \\dots, \\lfloor b \\rfloor\\}$ 都具有最高可能的排序。\n    -   根据平局处理规则，$\\mathcal{A}_{s_0=0}$ 的构造必须首先包含这整组结果。初始的累积概率是 $\\sum_{n=0}^{\\lfloor b \\rfloor} P(n \\mid b)$。如果这个和小于置信水平 CL，则根据排序添加更多的结果（其中 $n  b$，其 $R  1$），直到超过 CL。\n    -   由于在第一步就加入了一大块概率质量，最终的累积概率——即覆盖率——通常会显著大于名义上的 CL。这种效应被称为过度覆盖。\n\n-   **远离边界 ($s_0 > 0$)**：即使对于一个非常小的正信号 $s_0  0$，完全相同的排序也被打破。\n    -   假设的平均值为 $\\mu_0 = s_0 + b$。\n    -   对于 $n \\le b$，我们仍然有 $\\hat{s}(n) = 0$。对数似然比变为 $\\log R(n; s_0) = n\\log\\left(\\frac{s_0+b}{b}\\right) - s_0$。由于 $\\log((s_0+b)/b)0$，这是一个关于 $n$ 的严格递减线性函数。\n    -   结果 $n=0, 1, \\dots, \\lfloor b \\rfloor$ 现在被唯一地排序：$n=0$ 最高，其次是 $n=1$，依此类推。\n    -   接受域可以通过逐个添加结果来构建。这种更细的粒度允许累积概率在更接近名义 CL 的地方停止。\n    -   结果是，对于 $s_0  0$ 的覆盖率会从 $s_0=0$ 时的过度覆盖急剧下降到一个非常接近（但保证至少为）CL 的值。\n\n这种行为展示了 Feldman-Cousins 方法的关键特征：它自动地从边界处的单侧区间（在此处防止错误地排除 $s=0$）过渡到远离边界的双侧区间，从而在整个参数空间提供正确的覆盖率，而不会出现“翻转问题”。在 $s=0$ 处的过度覆盖是在边界处严格执行频率学派的覆盖原则，同时避免为低 $n$ 值产生空置信集所付出的代价。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\nfrom collections import defaultdict\n\ndef solve():\n    \"\"\"\n    Computes the coverage of Feldman-Cousins confidence intervals for a Poisson\n    process with known background, for a suite of test cases.\n    \"\"\"\n    \n    # Test cases: (s0, b, CL)\n    test_cases = [\n        (0.0, 3.0, 0.90),\n        (0.1, 3.0, 0.90),\n        (0.5, 3.0, 0.90),\n        (1.0, 3.0, 0.90),\n        (0.0, 0.5, 0.90),\n        (0.0, 3.0, 0.95),\n        (3.0, 3.0, 0.90),\n    ]\n\n    results = []\n    for s0, b, cl in test_cases:\n        coverage = compute_fc_coverage(s0, b, cl)\n        results.append(f\"{coverage:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef compute_fc_coverage(s0, b, cl):\n    \"\"\"\n    Calculates the exact coverage for a given signal hypothesis s0, background b,\n    and confidence level CL.\n\n    Args:\n        s0 (float): The true (hypothesized) signal strength.\n        b (float): The known background.\n        cl (float): The target confidence level.\n\n    Returns:\n        float: The exact coverage probability.\n    \"\"\"\n    mu0 = s0 + b\n    \n    # Determine the upper limit for n summation.\n    # We choose n_max such that the omitted Poisson tail probability is at most 1e-15.\n    # P(N > n_max) = 1 - P(N = n_max), so we want P(N = n_max) >= 1 - 1e-15.\n    # The Percent Point Function (ppf) is the inverse of the CDF.\n    if mu0 > 0:\n        n_max_crit = stats.poisson.ppf(1 - 1e-15, mu0)\n    else: # Handle mu0=0 case (only n=0 has non-zero probability)\n        n_max_crit = 5\n        \n    # Add a safety margin to ensure no tied group is split at the boundary.\n    # This also helps satisfy the a-posteriori check on coverage >= CL.\n    n_max = int(n_max_crit) + 20\n    \n    n_values = np.arange(0, n_max + 1)\n\n    # Calculate the constrained MLE for s and the corresponding mean mu_hat.\n    s_hat = np.maximum(0, n_values - b)\n    mu_hat = s_hat + b  # This is equivalent to np.maximum(b, n_values)\n\n    # Calculate the log of the likelihood ratio R(n; s0) for ordering.\n    # log R = n*log(mu0/mu_hat) - (mu0-mu_hat)\n    # Handle mu_hat=0: occurs only if b=0 and n=0. Test cases have b > 0 or s0 > 0.\n    log_mu0 = np.log(mu0) if mu0 > 0 else -np.inf\n    # Use np.where to avoid log(0) warnings for mu_hat\n    log_mu_hat = np.where(mu_hat > 0, np.log(mu_hat), -np.inf)\n    \n    log_R = n_values * (log_mu0 - log_mu_hat) - (mu0 - mu_hat)\n\n    # Get the Poisson probabilities for each n under the hypothesis s0.\n    poisson_probs = stats.poisson.pmf(n_values, mu0)\n\n    # Group outcomes n by their rank (log_R value) to handle ties correctly.\n    # A tolerance of 1e-12 is used as per the problem description.\n    # We group by rounding the log_R value to a certain precision.\n    tie_tolerance = 1e-12\n    # Using integer casting after scaling is a robust way to group floats.\n    scaled_log_R = np.round(log_R / tie_tolerance).astype(np.int64)\n    \n    # Use a dictionary to group probabilities by their rank (scaled_log_R value).\n    # defaultdict is convenient for this.\n    ranked_prob_groups = defaultdict(float)\n    for i in range(len(n_values)):\n        rank_val = scaled_log_R[i]\n        ranked_prob_groups[rank_val] += poisson_probs[i]\n        \n    # Sort the ranks in descending order.\n    sorted_ranks = sorted(ranked_prob_groups.keys(), reverse=True)\n\n    # Build the acceptance region by adding groups of tied ranks\n    # until the cumulative probability exceeds the confidence level.\n    cumulative_prob = 0.0\n    for rank in sorted_ranks:\n        prob_of_group = ranked_prob_groups[rank]\n        if cumulative_prob  cl and not np.isclose(cumulative_prob, cl):\n            cumulative_prob += prob_of_group\n        else:\n            # This is the final group to add, but it was already added in the\n            # previous iteration if it crossed the threshold. Or if we start above.\n            # A cleaner logic is:\n            # Add the group, then check if we should stop.\n            break\n\n    # Reworking the loop for clarity and correctness\n    cumulative_prob = 0.0\n    for rank in sorted_ranks:\n        prob_of_group = ranked_prob_groups[rank]\n        # Always add the next highest ranked group, then check if we are done.\n        cumulative_prob += prob_of_group\n        if cumulative_prob >= cl - 1e-12: # Use tolerance for float comparison\n            break\n            \n    # The final cumulative probability is the coverage.\n    # A check ensures that the implementation correctly yields coverage >= CL.\n    assert cumulative_prob >= cl - 1e-12, f\"Coverage {cumulative_prob} is less than CL {cl}\"\n    \n    return cumulative_prob\n\nsolve()\n```"
        }
    ]
}