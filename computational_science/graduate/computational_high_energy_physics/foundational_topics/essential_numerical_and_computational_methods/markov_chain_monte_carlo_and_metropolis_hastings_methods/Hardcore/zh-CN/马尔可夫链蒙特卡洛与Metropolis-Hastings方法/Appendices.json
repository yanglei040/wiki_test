{
    "hands_on_practices": [
        {
            "introduction": "本练习将探讨随机游走 Metropolis 算法在高维空间中的行为，这是现代物理模型中的常见情景。我们将使用一个多维高斯分布作为后验分布在其峰值附近的简化但功能强大的模型。该练习  将指导您推导提议步长的最优缩放关系，揭示一个关键见解：为使算法保持高效，提议宽度必须随着维度的增加而缩小。理解这种缩放关系是为复杂高维问题构建高效 MCMC 采样器的第一步。",
            "id": "3521310",
            "problem": "考虑一个高维参数向量 $\\boldsymbol{\\theta}\\in\\mathbb{R}^{d}$，该向量源于计算高能物理中对撞机分析里的一个白化后验。其中，对数后验在其众数处的局部曲率已被用来变换坐标，使得目标分布近似为标准正态分量的乘积。也就是说，目标密度为\n$$\n\\pi_{d}(\\boldsymbol{x}) \\propto \\prod_{i=1}^{d} \\exp\\!\\left(-\\frac{x_{i}^{2}}{2}\\right),\n$$\n其中 $\\boldsymbol{x}\\in\\mathbb{R}^{d}$ 表示白化坐标。使用基于 Metropolis-Hastings (MH) 方法的马尔可夫链蒙特卡洛 (MCMC) 算法对 $\\pi_{d}$ 进行采样，其提议为随机游走高斯提议：\n$$\n\\boldsymbol{x}' \\sim \\mathcal{N}\\!\\left(\\boldsymbol{x},\\,\\sigma^{2}\\,\\boldsymbol{I}_{d}\\right),\n$$\n其中 $\\boldsymbol{I}_{d}$ 是 $d \\times d$ 单位矩阵，$\\sigma0$ 是标量提议标准差。设 Metropolis-Hastings 接受概率由其核心规则定义：对于当前状态 $\\boldsymbol{x}$ 和提议状态 $\\boldsymbol{x}'$，接受概率为\n$$\na(\\boldsymbol{x},\\boldsymbol{x}') \\equiv \\min\\!\\left\\{1,\\,\\exp\\!\\Big(\\ln\\pi_{d}(\\boldsymbol{x}')-\\ln\\pi_{d}(\\boldsymbol{x})\\Big)\\right\\}。\n$$\n\n在 $d\\to\\infty$ 的情形下，采用标准的非退化尺度标度假设 $\\sigma = \\ell/\\sqrt{d}$，其中 $\\ell0$ 是一个无量纲步长参数，并假设链在 $\\pi_{d}$ 下具有平稳性，且当前状态与提议增量之间相互独立。\n\n严格从上述定义和假设出发，除了中心极限定理和正态分布的性质外，不引入任何未经检验的捷径，执行以下任务：\n\n- 在 $d\\to\\infty$ 的极限下，推导渐近接受概率作为 $\\ell$ 的函数（记为 $\\alpha(\\ell)$）的显式表达式。\n\n- 定义每个坐标的期望平方跳跃距离，\n$$\n\\mathrm{ESJD}_{j} \\equiv \\mathbb{E}\\!\\left[\\,(x'_{j}-x_{j})^{2}\\,\\mathbf{1}\\{ \\text{proposal accepted} \\}\\,\\right],\n$$\n对于固定的坐标索引 $j\\in\\{1,\\dots,d\\}$。在提议尺度 $\\sigma=\\ell/\\sqrt{d}$ 下，推导 $\\mathrm{ESJD}_{j}$ 如何随 $d$ 缩放，并表示出其对 $\\ell$ 的依赖关系。\n\n- 确定使 $\\mathrm{ESJD}_{j}$ 关于 $\\ell$ 最大化的值 $\\ell^{\\star}0$，并推导出相应的最优提议尺度 $\\sigma^{\\star}$ 作为 $d$ 的显式函数。\n\n- 数值计算 $\\ell^{\\star}$ 以及在 $\\ell^{\\star}$ 处 $\\mathrm{ESJD}_{j}$ 的领头阶系数，将所有报告的数值常数四舍五入到四位有效数字。将您的最终答案表示为数对 $\\big(\\sigma^{\\star},\\,\\mathrm{ESJD}_{j}\\text{ scaling}\\big)$。\n\n最终答案不带单位。如果报告数值，请四舍五入到四位有效数字。",
            "solution": "首先根据指定标准对问题陈述进行验证。\n\n### 问题验证\n\n#### 步骤1：提取已知条件\n- 目标概率密度：$\\pi_{d}(\\boldsymbol{x}) \\propto \\prod_{i=1}^{d} \\exp(-x_{i}^{2}/2)$，对于 $\\boldsymbol{x}\\in\\mathbb{R}^{d}$。\n- Metropolis-Hastings 的提议分布：随机游走高斯提议，$\\boldsymbol{x}' \\sim \\mathcal{N}(\\boldsymbol{x}, \\sigma^{2}\\boldsymbol{I}_{d})$，其中 $\\boldsymbol{I}_{d}$ 是 $d \\times d$ 单位矩阵，$\\sigma0$。\n- 接受概率：$a(\\boldsymbol{x},\\boldsymbol{x}') \\equiv \\min\\{1, \\exp(\\ln\\pi_{d}(\\boldsymbol{x}')-\\ln\\pi_{d}(\\boldsymbol{x}))\\}$。\n- 渐近情形：极限 $d\\to\\infty$。\n- 提议尺度标度假设：$\\sigma = \\ell/\\sqrt{d}$，其中 $\\ell0$。\n- 假设：马尔可夫链处于平稳状态，意味着当前状态 $\\boldsymbol{x}$ 根据 $\\pi_{d}(\\boldsymbol{x})$ 分布。当前状态 $\\boldsymbol{x}$ 与提议增量 $\\boldsymbol{z} = \\boldsymbol{x}' - \\boldsymbol{x}$ 相互独立。\n- 关注量：每个坐标的期望平方跳跃距离，$\\mathrm{ESJD}_{j} \\equiv \\mathbb{E}[(x'_{j}-x_{j})^{2}\\,\\mathbf{1}\\{ \\text{proposal accepted} \\}]$。\n- 任务：\n    1. 当 $d\\to\\infty$ 时，推导作为 $\\ell$ 的函数的渐近接受概率 $\\alpha(\\ell)$。\n    2. 推导 $\\mathrm{ESJD}_{j}$ 随 $d$ 的缩放关系及其对 $\\ell$ 的依赖性。\n    3. 找到最大化 $\\mathrm{ESJD}_{j}$ 的值 $\\ell^{\\star}$ 以及相应的最优 $\\sigma^{\\star}$。\n    4. 数值计算 $\\ell^{\\star}$ 和在最优值处 $\\mathrm{ESJD}_{j}$ 的领头阶系数，四舍五入到四位有效数字。\n    5. 将最终答案表示为数对 $(\\sigma^{\\star}, \\mathrm{ESJD}_{j}\\text{ scaling})$。\n\n#### 步骤2：使用提取的已知条件进行验证\n- **科学依据：** 该问题是马尔可夫链蒙特卡洛方法理论中一个经典且基础重要的课题，具体涉及高维随机游走 Metropolis 算法的最优尺度问题。该设置（高斯目标，高斯提议）可作为 MCMC 算法在更一般、复杂的后验分布上局部行为的典范模型。分析过程牢固地植根于概率论、统计学和中心极限定理。\n- **良构性：** 问题是良构的，所有必要的函数、参数和假设都有明确定义，可以为所求量推导出唯一、有意义的解。\n- **客观性：** 问题以精确、客观的数学语言陈述，没有歧义或主观论断。\n- **完整性和一致性：** 问题是自洽的，所有提供的信息在内部是一致的。\n\n#### 步骤3：结论与行动\n该问题有效。它是计算统计学和物理学中一个非平凡的练习，可以从已知条件严格求解。现在开始求解过程。\n\n### 解的推导\n\n#### 渐近接受概率 $\\alpha(\\ell)$\n目标密度为 $\\pi_{d}(\\boldsymbol{x}) \\propto \\exp(-\\frac{1}{2}\\sum_{i=1}^{d} x_i^2) = \\exp(-\\frac{1}{2}\\|\\boldsymbol{x}\\|^2)$。未归一化的对数后验是 $\\ln\\pi_{d}(\\boldsymbol{x}) = -\\frac{1}{2}\\|\\boldsymbol{x}\\|^2 + C$，其中 $C$ 是一个常数。从 $\\boldsymbol{x}$ 移动到 $\\boldsymbol{x}'$ 的对数后验变化为\n$$\n\\Delta E = \\ln\\pi_{d}(\\boldsymbol{x}') - \\ln\\pi_{d}(\\boldsymbol{x}) = -\\frac{1}{2}(\\|\\boldsymbol{x}'\\|^2 - \\|\\boldsymbol{x}\\|^2)。\n$$\n提议为 $\\boldsymbol{x}' = \\boldsymbol{x} + \\boldsymbol{z}$，其中增量 $\\boldsymbol{z} \\sim \\mathcal{N}(\\boldsymbol{0}, \\sigma^2\\boldsymbol{I}_d)$。将此代入 $\\Delta E$：\n$$\n\\Delta E = -\\frac{1}{2}(\\|\\boldsymbol{x} + \\boldsymbol{z}\\|^2 - \\|\\boldsymbol{x}\\|^2) = -\\frac{1}{2}(\\|\\boldsymbol{x}\\|^2 + 2\\boldsymbol{x}\\cdot\\boldsymbol{z} + \\|\\boldsymbol{z}\\|^2 - \\|\\boldsymbol{x}\\|^2) = -\\left(\\boldsymbol{x}\\cdot\\boldsymbol{z} + \\frac{1}{2}\\|\\boldsymbol{z}\\|^2\\right)。\n$$\n根据平稳性假设，当前状态 $\\boldsymbol{x}$ 从目标分布中抽取，即一个 $d$ 维的标准多元正态分布，$\\boldsymbol{x} \\sim \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{I}_d)$，因此 $x_i \\sim \\mathcal{N}(0,1)$ 是独立同分布（i.i.d.）的。提议增量的分量是 $z_i \\sim \\mathcal{N}(0, \\sigma^2)$，也是 i.i.d. 的。\n\n我们分析在 $d\\to\\infty$ 极限下，使用尺度 $\\sigma = \\ell/\\sqrt{d}$ 时 $\\Delta E$ 中的两项。\n1.  项 $\\|\\boldsymbol{z}\\|^2 = \\sum_{i=1}^d z_i^2$。其期望值为 $\\mathbb{E}[\\|\\boldsymbol{z}\\|^2] = \\sum_{i=1}^d \\mathbb{E}[z_i^2] = d\\sigma^2 = d(\\ell^2/d) = \\ell^2$。根据大数定律，当 $d\\to\\infty$ 时，i.i.d. 变量之和依概率收敛到其期望值，因此 $\\|\\boldsymbol{z}\\|^2 \\to \\ell^2$。\n2.  项 $\\boldsymbol{x}\\cdot\\boldsymbol{z} = \\sum_{i=1}^d x_i z_i$。这是 $d$ 个 i.i.d. 随机变量 $Y_i = x_i z_i$ 的和。由于 $\\boldsymbol{x}$ 和 $\\boldsymbol{z}$ 是独立的，$\\mathbb{E}[Y_i] = \\mathbb{E}[x_i]\\mathbb{E}[z_i] = 0$。方差为 $\\mathbb{Var}(Y_i) = \\mathbb{E}[Y_i^2] - (\\mathbb{E}[Y_i])^2 = \\mathbb{E}[x_i^2]\\mathbb{E}[z_i^2] = (1)(\\sigma^2) = \\ell^2/d$。\n    和的方差为 $\\mathbb{Var}(\\boldsymbol{x}\\cdot\\boldsymbol{z}) = \\sum_{i=1}^d \\mathbb{Var}(Y_i) = d(\\ell^2/d) = \\ell^2$。\n    根据中心极限定理，当 $d\\to\\infty$ 时，$\\boldsymbol{x}\\cdot\\boldsymbol{z}$ 的分布收敛到一个均值为 0、方差为 $\\ell^2$ 的正态分布。因此，$\\boldsymbol{x}\\cdot\\boldsymbol{z} \\to W \\sim \\mathcal{N}(0, \\ell^2)$。\n\n结合这些结果，$\\Delta E$ 依分布收敛到一个随机变量 $V$：\n$$\nV = -\\left(W + \\frac{1}{2}\\ell^2\\right) \\sim \\mathcal{N}\\left(-\\frac{\\ell^2}{2}, \\ell^2\\right)。\n$$\n渐近接受率 $\\alpha(\\ell)$ 是 $\\min\\{1, \\exp(V)\\}$ 的期望。\n$$\n\\alpha(\\ell) = \\mathbb{E}[\\min\\{1, \\exp(V)\\}] = \\int_{-\\infty}^{\\infty} \\min\\{1, \\exp(v)\\} p(v) dv,\n$$\n其中 $p(v)$ 是 $V \\sim \\mathcal{N}(-\\ell^2/2, \\ell^2)$ 的密度。令 $V = -\\ell^2/2 + \\ell Z$，其中 $Z \\sim \\mathcal{N}(0,1)$。期望变为：\n$$\n\\alpha(\\ell) = \\mathbb{E}_Z[\\min\\{1, \\exp(-\\ell^2/2 + \\ell Z)\\}] = \\int_{-\\infty}^{\\infty} \\min\\{1, \\exp(-\\ell^2/2 + \\ell z)\\} \\phi(z) dz,\n$$\n其中 $\\phi(z) = (2\\pi)^{-1/2}\\exp(-z^2/2)$。当 $-\\ell^2/2 + \\ell z > 0$ 时，即 $z > \\ell/2$ 时，项 $\\exp(-\\ell^2/2 + \\ell z) > 1$。我们在 $z=\\ell/2$ 处分割积分：\n$$\n\\alpha(\\ell) = \\int_{-\\infty}^{\\ell/2} \\exp(-\\ell^2/2 + \\ell z) \\phi(z) dz + \\int_{\\ell/2}^{\\infty} 1 \\cdot \\phi(z) dz.\n$$\n第一个积分是：\n$$\n\\int_{-\\infty}^{\\ell/2} \\exp(-\\ell^2/2 + \\ell z) \\frac{1}{\\sqrt{2\\pi}}\\exp(-z^2/2) dz = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\ell/2} \\exp\\left(-\\frac{1}{2}(z^2 - 2\\ell z + \\ell^2)\\right) dz = \\int_{-\\infty}^{\\ell/2} \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{(z-\\ell)^2}{2}\\right) dz.\n$$\n令 $u = z-\\ell$。积分变为 $\\int_{-\\infty}^{-\\ell/2} \\phi(u) du = \\Phi(-\\ell/2)$，其中 $\\Phi$ 是标准正态累积分布函数（CDF）。\n第二个积分是 $\\int_{\\ell/2}^{\\infty} \\phi(z) dz = 1 - \\Phi(\\ell/2)$。\n因此，$\\alpha(\\ell) = \\Phi(-\\ell/2) + 1 - \\Phi(\\ell/2)$。利用对称性质 $\\Phi(-x) = 1 - \\Phi(x)$，我们得到：\n$$\n\\alpha(\\ell) = 2(1 - \\Phi(\\ell/2)) = 2\\Phi(-\\ell/2).\n$$\n\n#### 期望平方跳跃距离 $\\mathrm{ESJD}_{j}$\n我们关注的量是 $\\mathrm{ESJD}_{j} = \\mathbb{E}[(x'_{j}-x_{j})^{2}\\,\\mathbf{1}\\{ \\text{proposal accepted} \\}]$。\n令 $\\boldsymbol{z} = \\boldsymbol{x}'-\\boldsymbol{x}$。则 $x'_j-x_j = z_j$。接受事件取决于 $\\Delta E = -\\sum_{k=1}^d (x_k z_k + z_k^2/2)$。在 $d\\to\\infty$ 的极限下，任何单个分量（如 $z_j$）对求和的贡献变得可以忽略不计。因此，随机变量 $z_j^2$ 与接受事件变得独立。这使我们能够解耦期望：\n$$\n\\mathrm{ESJD}_{j} \\approx \\mathbb{E}[z_j^2] \\cdot \\mathbb{E}[\\mathbf{1}\\{ \\text{proposal accepted} \\}] = \\mathbb{E}[z_j^2] \\cdot \\mathbb{E}[a(\\boldsymbol{x}, \\boldsymbol{x}')].\n$$\n我们有 $\\mathbb{E}[z_j^2] = \\mathbb{Var}(z_j) = \\sigma^2$。第二项是平均接受率，在大 $d$ 极限下为 $\\alpha(\\ell)$。\n代入 $\\sigma = \\ell/\\sqrt{d}$ 和 $\\alpha(\\ell)$ 的表达式：\n$$\n\\mathrm{ESJD}_{j} \\approx \\sigma^2 \\alpha(\\ell) = \\frac{\\ell^2}{d} \\cdot 2(1 - \\Phi(\\ell/2))。\n$$\n$\\mathrm{ESJD}_{j}$ 按 $1/d$ 缩放。对 $\\ell$ 的依赖关系通过函数 $f(\\ell) = 2\\ell^2(1 - \\Phi(\\ell/2))$ 体现。\n\n#### 优化与数值评估\n为了关于 $\\ell$ 最大化 $\\mathrm{ESJD}_{j}$，我们必须为 $\\ell0$ 最大化 $f(\\ell)$。我们求 $f(\\ell)$ 的导数并令其为零。\n$$\n\\frac{df}{d\\ell} = \\frac{d}{d\\ell} \\left[ 2\\ell^2(1 - \\Phi(\\ell/2)) \\right] = 4\\ell(1 - \\Phi(\\ell/2)) + 2\\ell^2 \\left(-\\phi(\\ell/2) \\cdot \\frac{1}{2}\\right) = 4\\ell(1 - \\Phi(\\ell/2)) - \\ell^2\\phi(\\ell/2)。\n$$\n对于 $\\ell0$ 设 $\\frac{df}{d\\ell}=0$，得到最优性条件：\n$$\n4(1 - \\Phi(\\ell/2)) - \\ell\\phi(\\ell/2) = 0。\n$$\n这是一个关于最优值 $\\ell^{\\star}$ 的超越方程。令 $x = \\ell/2$。方程为 $2(1-\\Phi(x)) = x\\phi(x)$。该方程必须进行数值求解。其解为 $x^{\\star} \\approx 1.1906$，由此可得：\n$$\n\\ell^{\\star} = 2x^{\\star} \\approx 2 \\times 1.1906 = 2.3812。\n$$\n四舍五入到四位有效数字，$\\ell^{\\star} \\approx 2.381$。\n相应的最优提议尺度 $\\sigma^{\\star}$ 为：\n$$\n\\sigma^{\\star} = \\frac{\\ell^{\\star}}{\\sqrt{d}} = \\frac{2.381}{\\sqrt{d}}。\n$$\n在最优值处 $\\mathrm{ESJD}_{j}$ 的领头阶系数是 $f(\\ell^{\\star})/d$。系数本身是 $f(\\ell^{\\star}) = 2(\\ell^{\\star})^2(1 - \\Phi(\\ell^{\\star}/2))$。\n从最优性条件可知，$1 - \\Phi(\\ell^{\\star}/2) = \\frac{\\ell^{\\star}}{4}\\phi(\\ell^{\\star}/2)$。将其代入 $f(\\ell^{\\star})$：\n$$\nf(\\ell^{\\star}) = 2(\\ell^{\\star})^2 \\left(\\frac{\\ell^{\\star}}{4}\\phi(\\ell^{\\star}/2)\\right) = \\frac{(\\ell^{\\star})^3}{2}\\phi(\\ell^{\\star}/2)。\n$$\n使用 $\\ell^{\\star} \\approx 2.3812$：\n$$\nf(\\ell^{\\star}) \\approx \\frac{(2.3812)^3}{2} \\phi\\left(\\frac{2.3812}{2}\\right) = \\frac{13.515}{2} \\phi(1.1906)。\n$$\n其中 $\\phi(1.1906) = \\frac{1}{\\sqrt{2\\pi}}\\exp(-(1.1906)^2/2) \\approx 0.19634$。\n$$\nf(\\ell^{\\star}) \\approx 6.7575 \\times 0.19634 \\approx 1.3268。\n$$\n四舍五入到四位有效数字，系数为 $1.327$。\n因此，在最优值处 $\\mathrm{ESJD}_j$ 的尺度关系是 $\\frac{1.327}{d}$。\n\n最终答案要求给出数对 $(\\sigma^{\\star}, \\mathrm{ESJD}_{j}\\text{ scaling})$。\n- $\\sigma^{\\star} = \\frac{2.381}{\\sqrt{d}}$\n- $\\mathrm{ESJD}_{j}\\text{ scaling} = \\frac{1.327}{d}$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{2.381}{\\sqrt{d}}  \\frac{1.327}{d} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "基于从特定高斯案例中获得的见解，本练习将深入探讨一个关于高维 MCMC 效率的更通用、更强大的结论。在这里，我们将考虑更广泛的一类目标分布，这些分布可以表示为独立同分布分量的乘积。该练习  要求您推导著名的随机游走 Metropolis 算法的渐近最优接受率，该接受率约为 $0.234$。这个理论基准不仅仅是一个数学上的奇趣点；在目标分布复杂的实际应用中，它为调节 MCMC 采样器提供了至关重要的实用指南。",
            "id": "3521352",
            "problem": "考虑一个在 $\\mathbb{R}^{d}$ 上的高维目标分布，它可以分解为乘积形式 $\\pi_{d}(x) = \\prod_{i=1}^{d} f(x_{i})$，其中 $f$ 是一个对数二阶连续可微的一维概率密度函数。定义 $g(x) = \\frac{d}{dx} \\ln f(x)$，并假设 Fisher 信息 $I = \\mathbb{E}_{X \\sim f}\\!\\left[g(X)^{2}\\right]$ 是有限的，且 $\\mathbb{E}_{X \\sim f}\\!\\left[g'(X)\\right]$ 存在。使用 Metropolis-Hastings (MH) 随机游走提议 $Y = X + \\sigma Z$，其中 $X \\in \\mathbb{R}^{d}$ 是当前状态，$Z \\sim \\mathcal{N}(0, I_{d})$ 是一个标准多元正态分布，$\\sigma$ 是一个标量步长。接受概率由标准 MH 法则给出：$\\alpha(X,Y) = \\min\\!\\left\\{1, \\frac{\\pi_{d}(Y)}{\\pi_{d}(X)}\\right\\}$。\n\n你的任务是分析随机游走 Metropolis 算法在高维极限 $d \\to \\infty$ 下的渐进行为，具体是在 $\\sigma = \\frac{l}{\\sqrt{d}}$（对于固定的 $l  0$）的标度机制下。假设算法处于平稳状态，$X \\sim \\pi_{d}$。仅从核心定义和熟知的事实（Metropolis-Hastings 接受法则、$\\ln f$ 的泰勒展开、中心极限定理，以及对光滑 $f$ 成立的分部积分恒等式 $\\mathbb{E}\\!\\left[g'(X)\\right] + \\mathbb{E}\\!\\left[g(X)^{2}\\right] = 0$）出发，执行以下步骤：\n\n1. 推导对数接受率的高维极限，并证明它依分布收敛到一个高斯位移。利用这个结果，得到极限平均接受概率 $\\alpha(l)$ 作为 $l$ 和 Fisher 信息 $I$ 的函数的闭式表达式。\n\n2. 采用马尔可夫链蒙特卡洛 (MCMC) 中常用的扩散极限思想，将算法的效率定义为与期望平方跳跃距离成正比，并在该标度机制下将其简化为 $S(l) = C \\, l^{2} \\alpha(l)$ 形式的函数，其中 $C  0$ 是一个与 $l$ 无关的常数。确定使 $S(l)$ 最大化的 $l$。\n\n3. 从最优化的 $l$ 推导出在 $d \\to \\infty$ 极限下相应的渐进最优接受率 $\\alpha^{\\star}$。提供 $\\alpha^{\\star}$ 的数值，四舍五入到三位有效数字。将最终答案表示为无单位的纯数。",
            "solution": "问题要求分析随机游走 Metropolis-Hastings 算法在高维极限 $d \\to \\infty$ 下的行为。我们将按要求分三步进行：首先，推导极限平均接受概率；其次，找到最优标度参数；第三，计算相应的最优接受率。\n\n**第 1 部分：极限平均接受概率**\n\n目标分布为 $\\pi_{d}(x) = \\prod_{i=1}^{d} f(x_{i})$，提议为 $Y = X + \\sigma Z$，其中 $Z \\sim \\mathcal{N}(0, I_d)$。提议密度是对称的，$q(Y|X) = q(X|Y)$，因此 Metropolis-Hastings 接受概率为 $\\alpha(X,Y) = \\min\\!\\left\\{1, \\frac{\\pi_{d}(Y)}{\\pi_{d}(X)}\\right\\}$。我们关心的是当 $d \\to \\infty$ 时，对数接受率 $\\Delta = \\ln\\left(\\frac{\\pi_{d}(Y)}{\\pi_{d}(X)}\\right)$ 的行为。\n\n鉴于目标的乘积形式，对数比率是一个和式：\n$$\n\\Delta = \\ln\\left(\\frac{\\prod_{i=1}^{d} f(Y_{i})}{\\prod_{i=1}^{d} f(X_{i})}\\right) = \\sum_{i=1}^{d} \\left( \\ln f(Y_{i}) - \\ln f(X_{i}) \\right)\n$$\n每个分量的提议为 $Y_i = X_i + \\sigma Z_i$，其中 $Z_i \\sim \\mathcal{N}(0,1)$ 是独立的。我们处于标度机制 $\\sigma = \\frac{l}{\\sqrt{d}}$（对于某个常数 $l  0$）。由于当 $d \\to \\infty$ 时 $\\sigma \\to 0$，我们可以对 $\\ln f(Y_i)$ 在 $X_i$ 附近进行泰勒展开：\n$$\n\\ln f(Y_i) = \\ln f(X_i) + (Y_i - X_i) \\left.\\frac{d}{dx}\\ln f(x)\\right|_{x=X_i} + \\frac{1}{2}(Y_i - X_i)^2 \\left.\\frac{d^2}{dx^2}\\ln f(x)\\right|_{x=X_i} + O((Y_i-X_i)^3)\n$$\n令 $g(x) = \\frac{d}{dx}\\ln f(x)$。展开式变为：\n$$\n\\ln f(Y_i) - \\ln f(X_i) = (\\sigma Z_i) g(X_i) + \\frac{1}{2}(\\sigma Z_i)^2 g'(X_i) + O(\\sigma^3)\n$$\n将此代入 $\\Delta$ 的和式中，并使用 $\\sigma = l/\\sqrt{d}$：\n$$\n\\Delta = \\sum_{i=1}^{d} \\left[ \\frac{l}{\\sqrt{d}} Z_i g(X_i) + \\frac{l^2}{2d} Z_i^2 g'(X_i) + O\\left(d^{-3/2}\\right) \\right]\n$$\n$$\n\\Delta = \\frac{l}{\\sqrt{d}} \\sum_{i=1}^{d} Z_i g(X_i) + \\frac{l^2}{2d} \\sum_{i=1}^{d} Z_i^2 g'(X_i) + O\\left(d^{-1/2}\\right)\n$$\n我们在 $d \\to \\infty$ 的极限下分析这两个和式。假设算法处于平稳状态，因此当前状态 $X$ 从 $\\pi_d$ 中抽取，这意味着分量 $X_i$ 是从 $f$ 中抽取的独立同分布 (i.i.d.) 的样本。$Z_i$ 项是 i.i.d. 的 $\\mathcal{N}(0,1)$ 变量，且与 $X_i$ 独立。\n\n令 $W_i = Z_i g(X_i)$。$W_i$ 是独立同分布的随机变量。我们计算它们的均值和方差。$g(X_i)$ 的期望是 $\\mathbb{E}[g(X_i)] = \\int_{-\\infty}^{\\infty} g(x)f(x)dx = \\int_{-\\infty}^{\\infty} f'(x)dx = [f(x)]_{-\\infty}^{\\infty} = 0$，因为 $f$ 是一个概率密度函数。因此，$\\mathbb{E}[W_i] = \\mathbb{E}[Z_i]\\mathbb{E}[g(X_i)] = 0 \\cdot 0 = 0$。方差是 $\\text{Var}(W_i) = \\mathbb{E}[W_i^2] - (\\mathbb{E}[W_i])^2 = \\mathbb{E}[Z_i^2 g(X_i)^2] = \\mathbb{E}[Z_i^2]\\mathbb{E}[g(X_i)^2] = 1 \\cdot I = I$，其中 $I$ 是 Fisher 信息。\n$\\Delta$ 中的第一项是 $T_1 = l \\left( \\frac{1}{\\sqrt{d}} \\sum_{i=1}^{d} W_i \\right)$。根据中心极限定理，$\\frac{1}{\\sqrt{d}} \\sum_{i=1}^{d} W_i \\xrightarrow{d} \\mathcal{N}(0, I)$。因此，$T_1 \\xrightarrow{d} \\mathcal{N}(0, l^2 I)$。\n\n第二项是 $T_2 = \\frac{l^2}{2} \\left( \\frac{1}{d} \\sum_{i=1}^{d} Z_i^2 g'(X_i) \\right)$。根据大数定律，该平均值依概率收敛于其期望：\n$$\n\\frac{1}{d} \\sum_{i=1}^{d} Z_i^2 g'(X_i) \\xrightarrow{p} \\mathbb{E}[Z_i^2 g'(X_i)] = \\mathbb{E}[Z_i^2]\\mathbb{E}[g'(X_i)] = 1 \\cdot \\mathbb{E}[g'(X_i)]\n$$\n使用给定的恒等式 $\\mathbb{E}[g'(X)] + \\mathbb{E}[g(X)^2] = 0$，我们有 $\\mathbb{E}[g'(X_i)] = -\\mathbb{E}[g(X_i)^2] = -I$。\n因此，$T_2 \\xrightarrow{p} \\frac{l^2}{2} (-I) = -\\frac{1}{2}l^2 I$。\n\n根据 Slutsky 定理，$\\Delta = T_1 + T_2 + O(d^{-1/2})$ 的极限分布是 $T_1$ 和 $T_2$ 极限的和：\n$$\n\\Delta \\xrightarrow{d} \\mathcal{N}\\left(-\\frac{1}{2}l^2 I, l^2 I\\right)\n$$\n极限下的平均接受概率为 $\\alpha(l) = \\mathbb{E}[\\min(1, \\exp(\\Delta_{\\infty}))]$，其中 $\\Delta_{\\infty} \\sim \\mathcal{N}\\left(-\\frac{1}{2}l^2 I, l^2 I\\right)$。令 $\\Delta_{\\infty} = -\\frac{1}{2}l^2 I + l\\sqrt{I} \\zeta$，其中 $\\zeta \\sim \\mathcal{N}(0,1)$。其期望为：\n$$\n\\alpha(l) = \\int_{-\\infty}^{\\infty} \\min(1, \\exp(-\\frac{1}{2}l^2 I + l\\sqrt{I}\\zeta)) \\phi(\\zeta) d\\zeta\n$$\n其中 $\\phi(\\zeta)$ 是标准正态概率密度函数 (PDF)。当指数部分为负时，即 $l\\sqrt{I}\\zeta  \\frac{1}{2}l^2 I$（简化为 $\\zeta  \\frac{l\\sqrt{I}}{2}$）时，项 $\\exp(-\\frac{1}{2}l^2 I + l\\sqrt{I}\\zeta)$ 小于 1。\n$$\n\\alpha(l) = \\int_{-\\infty}^{l\\sqrt{I}/2} \\exp(-\\frac{1}{2}l^2 I + l\\sqrt{I}\\zeta) \\phi(\\zeta) d\\zeta + \\int_{l\\sqrt{I}/2}^{\\infty} 1 \\cdot \\phi(\\zeta) d\\zeta\n$$\n第二个积分是尾部概率 $P(\\zeta  l\\sqrt{I}/2) = 1 - \\Phi(l\\sqrt{I}/2) = \\Phi(-l\\sqrt{I}/2)$，其中 $\\Phi$ 是标准正态累积分布函数 (CDF)。\n对于第一个积分，被积函数是 $\\exp(-\\frac{1}{2}l^2 I) \\exp(l\\sqrt{I}\\zeta) \\frac{1}{\\sqrt{2\\pi}}\\exp(-\\frac{\\zeta^2}{2}) = \\frac{1}{\\sqrt{2\\pi}}\\exp(-\\frac{1}{2}(\\zeta-l\\sqrt{I})^2)$。\n积分变为 $\\int_{-\\infty}^{l\\sqrt{I}/2} \\frac{1}{\\sqrt{2\\pi}} \\exp(-\\frac{1}{2}(\\zeta-l\\sqrt{I})^2) d\\zeta$。令 $u = \\zeta-l\\sqrt{I}$。该积分为 $\\int_{-\\infty}^{-l\\sqrt{I}/2} \\phi(u) du = \\Phi(-l\\sqrt{I}/2)$。\n因此，$\\alpha(l) = \\Phi(-l\\sqrt{I}/2) + \\Phi(-l\\sqrt{I}/2) = 2\\Phi(-l\\sqrt{I}/2)$。\n\n**第 2 部分：MCMC 效率的优化**\n\n采样器的效率被认为与期望平方跳跃距离成正比，$S(l) \\propto \\mathbb{E}[\\alpha(X,Y) \\|Y-X\\|^2]$。在高维极限下，接受概率 $\\alpha(X,Y)$ 收敛到上面推导出的确定性值 $\\alpha(l)$。跳跃向量为 $Y-X = \\sigma Z = \\frac{l}{\\sqrt{d}}Z$。平方跳跃距离为 $\\|Y-X\\|^2 = \\frac{l^2}{d}\\|Z\\|^2 = \\frac{l^2}{d}\\sum_{i=1}^d Z_i^2$。期望平方跳跃距离为 $\\mathbb{E}[\\|Y-X\\|^2] = \\frac{l^2}{d} \\sum_{i=1}^d \\mathbb{E}[Z_i^2] = \\frac{l^2}{d} \\cdot d = l^2$。\n因此，效率函数与 $l^2 \\alpha(l)$ 成正比。我们寻求最大化 $S(l) = l^2 \\alpha(l) = 2l^2 \\Phi(-l\\sqrt{I}/2)$。为简化起见，令 $k = l\\sqrt{I}$，我们对 $k0$ 最大化 $f(k) \\propto k^2 \\Phi(-k/2)$。\n我们将导数设为零：$\\frac{d}{dk} \\left(k^2 \\Phi(-k/2)\\right) = 0$。\n$$\n2k \\Phi(-k/2) + k^2 \\cdot \\phi(-k/2) \\cdot \\left(-\\frac{1}{2}\\right) = 0\n$$\n由于 $k0$，我们可以除以 $k$。使用 $\\phi(-u)=\\phi(u)$：\n$$\n2 \\Phi(-k/2) - \\frac{k}{2} \\phi(k/2) = 0\n$$\n令 $x = k/2 = l\\sqrt{I}/2$，最优 $l$ 的条件由以下超越方程的解给出：\n$$\n2\\Phi(-x) = x\\phi(x)\n$$\n该方程隐式地定义了最优标度参数 $l$。\n\n**第 3 部分：渐进最优接受率**\n\n最优接受率 $\\alpha^\\star$ 对应于在第 2 部分中找到的最优标度参数 $l^\\star$ 处的 $\\alpha(l)$ 值。\n从第 1 部分可知，接受率为 $\\alpha(l) = 2\\Phi(-l\\sqrt{I}/2)$。\n在最优点，我们有 $\\alpha^\\star = 2\\Phi(-l^\\star\\sqrt{I}/2)$。\n从第 2 部分可知，最优性条件是 $2\\Phi(-l^\\star\\sqrt{I}/2) = \\frac{l^\\star\\sqrt{I}}{2} \\phi(l^\\star\\sqrt{I}/2)$。\n令 $x^\\star = l^\\star\\sqrt{I}/2$，我们可以将最优接受率写为：\n$$\n\\alpha^\\star = x^\\star \\phi(x^\\star)\n$$\n其中 $x^\\star$ 是 $2\\Phi(-x) = x\\phi(x)$ 的正解。该方程必须通过数值方法求解。令 $h(x) = x\\phi(x) - 2\\Phi(-x)$。使用数值求根方法（例如 Newton 法），我们发现解为 $x^\\star \\approx 1.1906$。\n现在我们可以计算最优接受率的数值：\n$$\n\\alpha^\\star = x^\\star\\phi(x^\\star) = x^\\star \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{(x^\\star)^2}{2}\\right)\n$$\n代入 $x^\\star \\approx 1.1906$：\n$$\n\\alpha^\\star \\approx 1.1906 \\cdot \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{1.1906^2}{2}\\right) \\approx 1.1906 \\cdot \\frac{1}{2.5066} \\exp(-0.70877) \\approx 1.1906 \\cdot 0.39894 \\cdot 0.49220 \\approx 0.23377\n$$\n四舍五入到三位有效数字，最优接受率为 $0.234$。",
            "answer": "$$\n\\boxed{0.234}\n$$"
        },
        {
            "introduction": "许多物理参数本身是受约束的，例如分支比，它们必须为正且总和为一。本练习旨在解决使用 Metropolis-Hastings 从此类受约束参数空间进行抽样的挑战。我们将探索一种强大的技术：将受约束的变量重新参数化到一个无约束的空间中，在这里可以轻松应用标准 MCMC 提议（如高斯随机游走）。该练习  侧重于推导此变换的雅可比行列式，这是一个修正目标密度并确保采样保持精确性的关键组成部分。这项技能对于许多高能物理分析中的贝叶斯推断是必不可少的。",
            "id": "3521320",
            "problem": "在高能对撞机实验中，一个重中性共振衰变为 $d$ 个独占衰变道。设分支比向量为 $b = (b_1, b_2, \\dots, b_d)$，其被约束在单位单纯形上，因此对于所有 $i$ 都有 $b_i  0$ 且 $\\sum_{i=1}^{d} b_i = 1$。您观测到来自 $N = \\sum_{i=1}^{d} n_i$ 次衰变的计数 $n_1, n_2, \\dots, n_d$，并使用多项分布 $L(n \\mid b) \\propto \\prod_{i=1}^{d} b_i^{n_i}$ 对似然进行建模，其先验为狄利克雷分布 $p(b) \\propto \\prod_{i=1}^{d} b_i^{a_i - 1}$，其中超参数 $a_i  0$ 是固定的。您希望在遵守单纯形约束的同时，使用马尔可夫链蒙特卡洛（MCMC）方法，特别是 Metropolis-Hastings (MH) 方法，从后验分布 $\\pi_Y(b \\mid n) \\propto L(n \\mid b) p(b)$ 中进行采样。\n\n为了构建一个无约束的参数化，考虑从单纯形到 $\\mathbb{R}^{d-1}$ 的加性对数比逻辑变换，定义为\n$$\nz_i = \\ln\\!\\left(\\frac{b_i}{b_d}\\right), \\quad i = 1, 2, \\dots, d-1,\n$$\n其逆映射为\n$$\nb_i(z) = \\frac{\\exp(z_i)}{1 + \\sum_{k=1}^{d-1} \\exp(z_k)}, \\quad i = 1, \\dots, d-1, \\qquad\nb_d(z) = \\frac{1}{1 + \\sum_{k=1}^{d-1} \\exp(z_k)}.\n$$\n您设计了一个 MH 方案，该方案通过在 $\\mathbb{R}^{d-1}$ 上的对称高斯随机游走 $q(z' \\mid z)$ 在无约束空间中进行提议，然后映射回 $b' = b(z')$ 以在物理空间中进行评估。根据变量替换公式，$z$-空间中的目标密度为\n$$\n\\pi_Z(z \\mid n) \\propto \\pi_Y(b(z) \\mid n) \\left| \\det\\!\\left(\\frac{\\partial b}{\\partial z}\\right) \\right|,\n$$\n其中 $\\frac{\\partial b}{\\partial z}$ 表示逆映射 $z \\mapsto (b_1, \\dots, b_{d-1})$ 的 $(d-1) \\times (d-1)$ 雅可比矩阵。\n\n从 Metropolis-Hastings 接受准则和概率密度变量替换定理的基本定义出发，推导所需的雅可比因子 $\\left| \\det\\!\\left(\\frac{\\partial b}{\\partial z}\\right) \\right|$，并将其表示为关于 $b_1, \\dots, b_d$ 的闭式表达式。将您的最终答案表示为单个解析表达式。不需要数值近似。",
            "solution": "该问题要求推导从受约束的单纯形空间到无约束的欧几里得空间进行变量替换时的雅可比因子 $\\left| \\det\\left(\\frac{\\partial b}{\\partial z}\\right) \\right|$。当在无约束空间中提议移动时，该因子对于正确构建 Metropolis-Hastings 接受概率至关重要。\n\n设无约束变量的向量为 $z = (z_1, z_2, \\dots, z_{d-1}) \\in \\mathbb{R}^{d-1}$。问题定义了从该空间映射回分支比向量 $b = (b_1, b_2, \\dots, b_d)$ 的前 $d-1$ 个分量的映射。向量 $b$ 位于 $(d-1)$-单纯形 $\\mathcal{S}^{d-1}$ 上，其定义为对于所有 $i=1, \\dots, d$ 都有 $b_i  0$ 且 $\\sum_{i=1}^{d} b_i = 1$。逆映射由以下公式给出：\n$$\nb_i(z) = \\frac{\\exp(z_i)}{1 + \\sum_{k=1}^{d-1} \\exp(z_k)}, \\quad i = 1, \\dots, d-1\n$$\n$$\nb_d(z) = \\frac{1}{1 + \\sum_{k=1}^{d-1} \\exp(z_k)}\n$$\n需要计算的量是雅可比矩阵 $J = \\frac{\\partial b}{\\partial z}$ 的行列式的绝对值，其中 $J$ 是一个 $(d-1) \\times (d-1)$ 矩阵，其元素为 $J_{ij} = \\frac{\\partial b_i}{\\partial z_j}$，对于 $i, j \\in \\{1, 2, \\dots, d-1\\}$。\n\n首先，我们计算偏导数 $J_{ij}$。我们定义分母为 $S(z) = 1 + \\sum_{k=1}^{d-1} \\exp(z_k)$。从所给的映射定义中，我们可以建立 $b_i$ 和 $S$ 之间的直接关系。\n注意到对于 $i=1, \\dots, d-1$，有 $b_d = 1/S$ 和 $b_i = b_d \\exp(z_i)$。这意味着 $\\exp(z_i) = b_i/b_d$。\n我们可以验证 $S(z)$ 的一致性：\n$$\nS(z) = 1 + \\sum_{k=1}^{d-1} \\exp(z_k) = 1 + \\sum_{k=1}^{d-1} \\frac{b_k}{b_d} = \\frac{b_d + \\sum_{k=1}^{d-1} b_k}{b_d} = \\frac{\\sum_{k=1}^{d} b_k}{b_d} = \\frac{1}{b_d}\n$$\n这证实了 $b_i = \\exp(z_i) / S = \\exp(z_i) b_d$。\n\n现在，我们使用商法则计算对于 $i, j \\in \\{1, \\dots, d-1\\}$ 的偏导数 $\\frac{\\partial b_i}{\\partial z_j}$。\n\n情况 1：$i = j$。\n$$\n\\frac{\\partial b_i}{\\partial z_i} = \\frac{\\partial}{\\partial z_i} \\left( \\frac{\\exp(z_i)}{S(z)} \\right) = \\frac{\\frac{\\partial \\exp(z_i)}{\\partial z_i} S(z) - \\exp(z_i) \\frac{\\partial S(z)}{\\partial z_i}}{S(z)^2}\n$$\n由于 $\\frac{\\partial S(z)}{\\partial z_i} = \\exp(z_i)$，我们有：\n$$\n\\frac{\\partial b_i}{\\partial z_i} = \\frac{\\exp(z_i) S(z) - \\exp(z_i) \\exp(z_i)}{S(z)^2} = \\frac{\\exp(z_i)}{S(z)} - \\left( \\frac{\\exp(z_i)}{S(z)} \\right)^2\n$$\n代入 $b_i = \\exp(z_i)/S(z)$，我们得到：\n$$\n\\frac{\\partial b_i}{\\partial z_i} = b_i - b_i^2 = b_i(1 - b_i)\n$$\n\n情况 2：$i \\neq j$。\n$$\n\\frac{\\partial b_i}{\\partial z_j} = \\frac{\\partial}{\\partial z_j} \\left( \\frac{\\exp(z_i)}{S(z)} \\right) = \\frac{0 \\cdot S(z) - \\exp(z_i) \\frac{\\partial S(z)}{\\partial z_j}}{S(z)^2}\n$$\n由于 $\\frac{\\partial S(z)}{\\partial z_j} = \\exp(z_j)$，我们有：\n$$\n\\frac{\\partial b_i}{\\partial z_j} = \\frac{-\\exp(z_i) \\exp(z_j)}{S(z)^2} = - \\left( \\frac{\\exp(z_i)}{S(z)} \\right) \\left( \\frac{\\exp(z_j)}{S(z)} \\right)\n$$\n代入 $b_i = \\exp(z_i)/S(z)$ 和 $b_j = \\exp(z_j)/S(z)$，我们得到：\n$$\n\\frac{\\partial b_i}{\\partial z_j} = -b_i b_j\n$$\n\n因此，雅可比矩阵 $J$ 的元素为：\n$$\nJ_{ij} = \\frac{\\partial b_i}{\\partial z_j} =\n\\begin{cases}\nb_i(1 - b_i)  \\text{if } i = j \\\\\n-b_i b_j  \\text{if } i \\neq j\n\\end{cases}\n$$\n这可以紧凑地写作 $J_{ij} = \\delta_{ij} b_i - b_i b_j$，其中 $\\delta_{ij}$ 是克罗内克δ函数。\n\n我们现在计算这个 $(d-1) \\times (d-1)$ 矩阵 $J$ 的行列式。我们可以从每一行 $i$ 中提出因子 $b_i$：\n$$\nJ = \n\\begin{pmatrix}\nb_1(1-b_1)  -b_1 b_2  \\dots  -b_1 b_{d-1} \\\\\n-b_2 b_1  b_2(1-b_2)  \\dots  -b_2 b_{d-1} \\\\\n\\vdots  \\vdots  \\ddots  \\vdots \\\\\n-b_{d-1} b_1  -b_{d-1} b_2  \\dots  b_{d-1}(1-b_{d-1})\n\\end{pmatrix}\n$$\n令 $D = \\text{diag}(b_1, b_2, \\dots, b_{d-1})$。我们可以写作 $J = D \\cdot M$，其中 $M$ 是元素为 $M_{ij} = \\delta_{ij} - b_j$ 的矩阵。\n$$\nM = \n\\begin{pmatrix}\n1-b_1  -b_2  \\dots  -b_{d-1} \\\\\n-b_1  1-b_2  \\dots  -b_{d-1} \\\\\n\\vdots  \\vdots  \\ddots  \\vdots \\\\\n-b_1  -b_2  \\dots  1-b_{d-1}\n\\end{pmatrix}\n$$\n$J$ 的行列式为 $\\det(J) = \\det(D) \\det(M)$。\n对角矩阵 $D$ 的行列式就是其对角元素的乘积：\n$$\n\\det(D) = \\prod_{i=1}^{d-1} b_i\n$$\n为了求 $M$ 的行列式，我们注意到 $M$ 的形式为 $I - uv^T$，其中 $I$ 是 $(d-1) \\times (d-1)$ 的单位矩阵， $u$ 是一个全为1的列向量，$u = (1, 1, \\dots, 1)^T$，$v$ 是前 $d-1$ 个分支比的列向量，$v = (b_1, b_2, \\dots, b_{d-1})^T$。\n$$\nuv^T = \\begin{pmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix} \\begin{pmatrix} b_1  b_2  \\dots  b_{d-1} \\end{pmatrix} = \\begin{pmatrix}\nb_1  b_2  \\dots  b_{d-1} \\\\\nb_1  b_2  \\dots  b_{d-1} \\\\\n\\vdots  \\vdots  \\ddots  \\vdots \\\\\nb_1  b_2  \\dots  b_{d-1}\n\\end{pmatrix}\n$$\n矩阵 $M$ 确实是 $I - uv^T$。根据矩阵行列式引理，对于任意向量 $u, v$，我们有 $\\det(I - uv^T) = 1 - v^T u$。\n在我们的例子中，\n$$\nv^T u = \\begin{pmatrix} b_1  b_2  \\dots  b_{d-1} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix} = \\sum_{k=1}^{d-1} b_k\n$$\n因此，$M$ 的行列式为：\n$$\n\\det(M) = 1 - \\sum_{k=1}^{d-1} b_k\n$$\n使用单纯形约束 $\\sum_{k=1}^{d} b_k = 1$，我们可以用 $b_d$ 来表示这个结果：\n$$\n1 - \\sum_{k=1}^{d-1} b_k = b_d\n$$\n所以，$\\det(M) = b_d$。\n\n结合这些结果，雅可比矩阵 $J$ 的行列式为：\n$$\n\\det(J) = \\det(D) \\det(M) = \\left( \\prod_{i=1}^{d-1} b_i \\right) b_d\n$$\n这给出了所有 $d$ 个分支比的乘积：\n$$\n\\det(J) = \\prod_{i=1}^{d} b_i\n$$\n最后一步是根据概率密度变量替换公式的要求取绝对值。问题陈述了对于所有 $i$ 都有 $b_i  0$。因此，乘积 $\\prod_{i=1}^{d} b_i$ 是严格为正的。\n因此，所需的雅可比因子是：\n$$\n\\left| \\det\\left(\\frac{\\partial b}{\\partial z}\\right) \\right| = \\left| \\prod_{i=1}^{d} b_i \\right| = \\prod_{i=1}^{d} b_i\n$$\n这就是用分支比 $b_1, \\dots, b_d$ 表示的雅可比行列式的闭式表达式。",
            "answer": "$$\\boxed{\\prod_{i=1}^{d} b_i}$$"
        }
    ]
}