{
    "hands_on_practices": [
        {
            "introduction": "To numerically enforce the solenoidal constraint $\\nabla \\cdot \\mathbf{B} = 0$, many modern schemes introduce auxiliary fields that transport divergence errors as waves. This practice explores the fundamental behavior of these \"cleaning waves\" within a simplified hyperbolic cleaning model . By deriving the reflection coefficient at a domain boundary, you will gain a crucial, first-principles understanding of how boundary conditions can be designed to effectively manage the flow of divergence error out of the simulation domain, preventing unphysical reflections.",
            "id": "3506849",
            "problem": "In ideal Magnetohydrodynamics (MHD), the induction equation implies that the magnetic field $ \\mathbf{B} $ must remain solenoidal, i.e., $ \\nabla \\cdot \\mathbf{B} = 0 $. Constrained Transport (CT) discretizations enforce a discrete version of this solenoidal constraint. To mitigate numerical errors and transport divergence away from the domain, many computational astrophysics schemes augment the induction equation with hyperbolic divergence cleaning (Dedner-type without damping), introducing a scalar cleaning field $ \\psi $ coupled to $ \\mathbf{B} $ through a linear subsystem with cleaning wave speed $ c_{h} $:\n$$\n\\frac{\\partial \\mathbf{B}}{\\partial t} + \\nabla \\psi = \\mathbf{0}, \\quad\n\\frac{\\partial \\psi}{\\partial t} + c_{h}^{2} \\nabla \\cdot \\mathbf{B} = 0.\n$$\nConsider a one-dimensional half-space $ x \\geq 0 $ with outward unit normal in the $ -\\hat{\\mathbf{x}} $ direction, where the only nonzero component of the magnetic field is the normal component $ B_{x}(x,t) $, and only divergence cleaning dynamics act (no fluid advection or resistive effects). The subsystem reduces to\n$$\n\\frac{\\partial B_{x}}{\\partial t} + \\frac{\\partial \\psi}{\\partial x} = 0, \\quad\n\\frac{\\partial \\psi}{\\partial t} + c_{h}^{2} \\frac{\\partial B_{x}}{\\partial x} = 0.\n$$\nAt the boundary $ x = 0 $, to ensure compatibility with the CT update of face-centered $ B_{x} $ and to control the influx of divergence, impose a linear impedance-like boundary relation between the cleaning field and the normal magnetic field,\n$$\n\\psi(0,t) = \\lambda \\, c_{h} \\, B_{x}(0,t),\n$$\nwhere $ \\lambda \\in \\mathbb{R} $ is a constant. A leftward-propagating (toward the boundary) divergence-cleaning wave is incident from the interior with normal magnetic field amplitude $ A_{\\mathrm{i}} $, and the boundary generates a rightward-propagating reflected cleaning wave with normal magnetic field amplitude $ A_{\\mathrm{r}} $. Using only the subsystem above and the boundary relation, derive a closed-form analytical expression for the reflection coefficient\n$$\nR_{B} \\equiv \\frac{A_{\\mathrm{r}}}{A_{\\mathrm{i}}},\n$$\nas a function of $ \\lambda $. Express the final answer as a single closed-form analytical expression. No numerical rounding is required, and no units are to be included in the final answer.",
            "solution": "The problem requires the derivation of the reflection coefficient for a divergence-cleaning wave at a boundary. The physical system is described by a set of one-dimensional linear hyperbolic partial differential equations.\n\nThe governing equations for the normal component of the magnetic field, $B_x(x,t)$, and the scalar cleaning field, $\\psi(x,t)$, in the domain $x \\geq 0$ are given as:\n$$\n\\frac{\\partial B_{x}}{\\partial t} + \\frac{\\partial \\psi}{\\partial x} = 0 \\label{eq:1}\n$$\n$$\n\\frac{\\partial \\psi}{\\partial t} + c_{h}^{2} \\frac{\\partial B_{x}}{\\partial x} = 0 \\label{eq:2}\n$$\nwhere $c_h$ is the constant cleaning wave speed.\n\nAt the boundary $x=0$, an impedance-like condition is imposed:\n$$\n\\psi(0,t) = \\lambda \\, c_{h} \\, B_{x}(0,t) \\label{eq:3}\n$$\nwhere $\\lambda$ is a real constant.\n\nThis system of equations describes wave propagation. We can analyze it by diagonalizing the system to find the characteristic variables (Riemann invariants). First, we write the system in matrix form. Let $\\mathbf{u} = \\begin{pmatrix} B_x \\\\ \\psi \\end{pmatrix}$. The system is $\\frac{\\partial \\mathbf{u}}{\\partial t} + A \\frac{\\partial \\mathbf{u}}{\\partial x} = \\mathbf{0}$, where the matrix $A$ is:\n$$\nA = \\begin{pmatrix} 0 & 1 \\\\ c_{h}^{2} & 0 \\end{pmatrix}\n$$\nThe eigenvalues $\\nu$ of $A$ give the characteristic speeds of the waves. They are found by solving the characteristic equation $\\det(A - \\nu I) = 0$:\n$$\n\\det \\begin{pmatrix} -\\nu & 1 \\\\ c_{h}^{2} & -\\nu \\end{pmatrix} = (-\\nu)(-\\nu) - (1)(c_{h}^{2}) = \\nu^{2} - c_{h}^{2} = 0\n$$\nThe eigenvalues are $\\nu_{1,2} = \\pm c_h$. These correspond to right-propagating ($+c_h$) and left-propagating ($-c_h$) waves, respectively.\n\nThe corresponding right eigenvectors $\\mathbf{r}$ are found by solving $(A - \\nu I)\\mathbf{r} = \\mathbf{0}$.\nFor $\\nu_1 = +c_h$:\n$$\n\\begin{pmatrix} -c_h & 1 \\\\ c_{h}^{2} & -c_h \\end{pmatrix} \\begin{pmatrix} r_1 \\\\ r_2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} \\implies -c_h r_1 + r_2 = 0 \\implies \\mathbf{r}_1 = \\begin{pmatrix} 1 \\\\ c_h \\end{pmatrix}\n$$\nFor $\\nu_2 = -c_h$:\n$$\n\\begin{pmatrix} c_h & 1 \\\\ c_{h}^{2} & c_h \\end{pmatrix} \\begin{pmatrix} r_1 \\\\ r_2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} \\implies c_h r_1 + r_2 = 0 \\implies \\mathbf{r}_2 = \\begin{pmatrix} 1 \\\\ -c_h \\end{pmatrix}\n$$\nThe characteristic variables, or Riemann invariants, are linear combinations of the state variables $B_x$ and $\\psi$ that remain constant along the characteristic curves. They correspond to the projections of the state vector $\\mathbf{u}$ onto the left eigenvectors. Let's define two new variables, $\\mathcal{W}_{\\mathrm{R}}$ and $\\mathcal{W}_{\\mathrm{L}}$, representing the rightward and leftward moving waves.\nBased on the eigenvectors, the relationships within each wave are:\n- For a right-moving wave: $\\delta\\psi = c_h \\delta B_x$.\n- For a left-moving wave: $\\delta\\psi = -c_h \\delta B_x$.\n\nThis allows us to decompose the total fields $B_x$ and $\\psi$ into left-moving (incident, subscript 'i') and right-moving (reflected, subscript 'r') components:\n$$\nB_x(x,t) = B_{\\mathrm{i}}(x,t) + B_{\\mathrm{r}}(x,t)\n$$\n$$\n\\psi(x,t) = \\psi_{\\mathrm{i}}(x,t) + \\psi_{\\mathrm{r}}(x,t)\n$$\nwhere $B_{\\mathrm{i}}$ and $\\psi_{\\mathrm{i}}$ are functions of $(x+c_h t)$, and $B_{\\mathrm{r}}$ and $\\psi_{\\mathrm{r}}$ are functions of $(x-c_h t)$.\nFrom the eigenvector analysis, we have the relations:\n$$\n\\psi_{\\mathrm{i}}(x,t) = -c_h B_{\\mathrm{i}}(x,t)\n$$\n$$\n\\psi_{\\mathrm{r}}(x,t) = +c_h B_{\\mathrm{r}}(x,t)\n$$\nThus, the total field for $\\psi$ can be written as:\n$$\n\\psi(x,t) = -c_h B_{\\mathrm{i}}(x,t) + c_h B_{\\mathrm{r}}(x,t)\n$$\nNow, we apply the boundary condition at $x=0$:\n$$\n\\psi(0,t) = \\lambda c_h B_x(0,t)\n$$\nSubstitute the decomposed forms of $B_x$ and $\\psi$ into this condition:\n$$\n-c_h B_{\\mathrm{i}}(0,t) + c_h B_{\\mathrm{r}}(0,t) = \\lambda c_h \\left( B_{\\mathrm{i}}(0,t) + B_{\\mathrm{r}}(0,t) \\right)\n$$\nAssuming $c_h \\neq 0$, we can divide by $c_h$:\n$$\n-B_{\\mathrm{i}}(0,t) + B_{\\mathrm{r}}(0,t) = \\lambda \\left( B_{\\mathrm{i}}(0,t) + B_{\\mathrm{r}}(0,t) \\right)\n$$\nThis equation must hold for all time $t$. We can rearrange the terms to solve for the reflected wave component $B_{\\mathrm{r}}(0,t)$ in terms of the incident wave component $B_{\\mathrm{i}}(0,t)$.\n$$\nB_{\\mathrm{r}}(0,t) - \\lambda B_{\\mathrm{r}}(0,t) = B_{\\mathrm{i}}(0,t) + \\lambda B_{\\mathrm{i}}(0,t)\n$$\n$$\nB_{\\mathrm{r}}(0,t) (1 - \\lambda) = B_{\\mathrm{i}}(0,t) (1 + \\lambda)\n$$\nSolving for $B_{\\mathrm{r}}(0,t)$, provided $\\lambda \\neq 1$:\n$$\nB_{\\mathrm{r}}(0,t) = \\left( \\frac{1+\\lambda}{1-\\lambda} \\right) B_{\\mathrm{i}}(0,t)\n$$\nThis relation connects the value of the reflected wave function to the value of the incident wave function at the boundary for all time. The amplitudes $A_{\\mathrm{r}}$ and $A_{\\mathrm{i}}$ are the characteristic scaling factors for the wave profiles. The ratio of the functions' values at the boundary is equal to the ratio of their amplitudes.\n$$\n\\frac{A_{\\mathrm{r}}}{A_{\\mathrm{i}}} = \\frac{B_{\\mathrm{r}}(0,t)}{B_{\\mathrm{i}}(0,t)}\n$$\nThe reflection coefficient $R_B$ is defined as this ratio:\n$$\nR_{B} \\equiv \\frac{A_{\\mathrm{r}}}{A_{\\mathrm{i}}} = \\frac{1+\\lambda}{1-\\lambda}\n$$\nThis is the required closed-form analytical expression for the reflection coefficient as a function of $\\lambda$.",
            "answer": "$$\\boxed{\\frac{1+\\lambda}{1-\\lambda}}$$"
        },
        {
            "introduction": "In any practical magnetohydrodynamics simulation, numerical errors will inevitably introduce some level of spurious magnetic divergence. Before these errors can be corrected, they must first be accurately identified and quantified. This hands-on coding exercise  guides you in constructing a vital diagnostic tool to monitor the discrete $\\nabla \\cdot \\mathbf{B}$ and to establish criteria for triggering corrective actions. Mastering this skill is a prerequisite for developing robust MHD codes that can handle complex phenomena like shocks and turbulence.",
            "id": "3506882",
            "problem": "You are asked to construct and test a computational diagnostic for spurious divergence-induced accelerations in ideal magnetohydrodynamics (MHD). The diagnostic must be based on first principles and implemented on a uniform Cartesian grid. The goal is to define a proxy acceleration that quantifies numerical violations of Gauss’s law for magnetism and to design threshold criteria that trigger local divergence cleaning or mesh refinement.\n\nStarting from Gauss’s law for magnetism, which states that the magnetic field must satisfy $\\nabla \\cdot \\mathbf{B} = 0$ in the continuum, you will derive and implement discrete diagnostics on a uniform two-dimensional grid. Use only the following fundamental base and well-tested facts as starting points:\n\n- Maxwell’s equation (Gauss’s law for magnetism): $\\nabla \\cdot \\mathbf{B} = 0$.\n- Uniform Cartesian grid with spacings $\\Delta x$ and $\\Delta y$.\n- Smooth fields admit Taylor expansions; central finite differences can approximate first derivatives to second-order accuracy in the interior; one-sided differences provide first-order boundary closures.\n- The magnetic field magnitude is $|\\mathbf{B}| = \\sqrt{B_x^2 + B_y^2}$.\n- A spurious monopole-like force appears in the discrete momentum equation when $\\nabla \\cdot \\mathbf{B} \\neq 0$; a commonly used proxy for the resulting acceleration is proportional to $-(\\nabla \\cdot \\mathbf{B}) \\mathbf{B}$ up to a constant.\n\nYour tasks are:\n\n- Derive and implement a second-order accurate finite-difference approximation to $\\nabla \\cdot \\mathbf{B}$ on a uniform grid in the interior using central stencils, and a consistent one-sided approximation on the boundaries.\n- From this discrete divergence, define and implement a dimensionless normalized divergence indicator $\\varepsilon$ that scales with resolution as $\\varepsilon \\sim h |\\nabla \\cdot \\mathbf{B}| / (|\\mathbf{B}| + B_{\\mathrm{floor}})$, where $h$ is a characteristic cell size and $B_{\\mathrm{floor}}$ is a small regularization constant to prevent division by zero. Choose $h = \\min(\\Delta x, \\Delta y)$ and consider $B_{\\mathrm{floor}}$ as a given parameter.\n- Define and compute the proxy spurious acceleration vector $\\mathbf{f}_{\\mathrm{div}} \\propto -(\\nabla \\cdot \\mathbf{B}) \\mathbf{B}$.\n- Design boolean triggers for cleaning and refinement from local diagnostics:\n  - A cleaning trigger $T_{\\mathrm{clean}}$ is set to true if $\\varepsilon > \\theta_{\\mathrm{clean}}$.\n  - A refinement trigger $T_{\\mathrm{ref}}$ is set to true if either $\\varepsilon > \\theta_{\\mathrm{ref}}$ or $|\\nabla \\cdot \\mathbf{B}| > \\phi_{\\mathrm{abs}}$.\n  Use given thresholds $\\theta_{\\mathrm{clean}}$, $\\theta_{\\mathrm{ref}}$, and $\\phi_{\\mathrm{abs}}$.\n\nYou must implement a program that, for each test case below, computes:\n- The maximum value of $\\varepsilon$ over the grid, denoted $\\varepsilon_{\\max}$ (unitless).\n- The total number of cells where $T_{\\mathrm{clean}}$ is true (integer count).\n- The total number of cells where $T_{\\mathrm{ref}}$ is true (integer count).\n\nReport $\\varepsilon_{\\max}$ rounded to six decimal places. All quantities in this problem are to be treated as unitless (dimensionless). Angles, where relevant, must be interpreted in radians.\n\nDiscrete operators and boundary conditions:\n- Use a uniform two-dimensional grid of size $N_x \\times N_y$ with spacings $\\Delta x$ and $\\Delta y$.\n- Use second-order central finite differences to approximate $\\partial B_x/\\partial x$ and $\\partial B_y/\\partial y$ at interior cells.\n- Use consistent first-order one-sided finite differences at the domain boundaries.\n\nThresholds and regularization:\n- Use $\\theta_{\\mathrm{clean}} = 0.2$, $\\theta_{\\mathrm{ref}} = 0.6$, $\\phi_{\\mathrm{abs}} = 0.8$, and $B_{\\mathrm{floor}} = 10^{-6}$.\n\nTest suite:\nProvide results for the following four test cases. In all cases, the grid is cell-centered and $\\mathbf{B}$ is given at the cell centers.\n\n- Test case A (smooth, nearly divergence-free by construction): $N_x = 33$, $N_y = 33$, domain $x \\in [0, 2\\pi]$, $y \\in [0, 2\\pi]$, so that $\\Delta x = 2\\pi/(N_x - 1)$ and $\\Delta y = 2\\pi/(N_y - 1)$. Define a stream function $\\psi(x,y) = \\sin(k_x x) \\sin(k_y y)$ with $k_x = 2$ and $k_y = 3$. Construct $\\mathbf{B}$ from $\\psi$ via $B_x = \\partial \\psi/\\partial y$ and $B_y = -\\partial \\psi/\\partial x$ evaluated analytically at the cell centers.\n- Test case B (monopole-like interface): $N_x = 9$, $N_y = 9$, $\\Delta x = 1$, $\\Delta y = 1$. Define $B_x(i,j) = 1$ for all indices with $i \\ge \\lceil N_x/2 \\rceil$ and $B_x(i,j) = 0$ otherwise; set $B_y(i,j) = 0$ for all cells. Here $i$ and $j$ are zero-based indices in code, but your derivation must be independent of indexing conventions.\n- Test case C (near-vacuum noise): $N_x = 7$, $N_y = 7$, $\\Delta x = 1$, $\\Delta y = 1$. Define $B_x$ and $B_y$ as independent small-amplitude fields with deterministic pseudorandom values uniformly distributed in $[-10^{-12}, 10^{-12}]$, produced by a fixed pseudorandom seed. Use $B_{\\mathrm{floor}} = 10^{-6}$ as above.\n- Test case D (strong uniform field with localized perturbation): $N_x = 17$, $N_y = 17$, $\\Delta x = 1$, $\\Delta y = 1$. Define $B_x(i,j) = 5$ for all cells. Define $B_y(i,j) = 0$ for all cells initially, then add a step in $y$: for all cells with $j \\ge \\lfloor N_y/2 \\rfloor$, set $B_y(i,j) \\leftarrow B_y(i,j) + 1$, leaving other cells unchanged.\n\nFor each test case, compute and return a list containing three items $[\\varepsilon_{\\max}, n_{\\mathrm{clean}}, n_{\\mathrm{ref}}]$, where $n_{\\mathrm{clean}}$ is the number of cells with $T_{\\mathrm{clean}}$ true, and $n_{\\mathrm{ref}}$ is the number of cells with $T_{\\mathrm{ref}}$ true. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case result is itself a list. For example, you should print a line of the form\n\"[[eA,ncA,nrA],[eB,ncB,nrB],[eC,ncC,nrC],[eD,ncD,nrD]]\"\nwith no spaces, where $eX$ are floats rounded to six decimal places and $ncX$, $nrX$ are integers.",
            "solution": "The objective is to construct and test a computational diagnostic for spurious magnetic divergence in numerical magnetohydrodynamics (MHD). This involves deriving and implementing discrete operators on a uniform Cartesian grid to quantify violations of Gauss's law for magnetism, $\\nabla \\cdot \\mathbf{B} = 0$, and to establish criteria for corrective actions like divergence cleaning or mesh refinement.\n\n### Step 1: Discretization of the Divergence Operator\n\nThe divergence of a magnetic field $\\mathbf{B} = (B_x, B_y)$ in two dimensions is given by the continuum expression:\n$$ \\nabla \\cdot \\mathbf{B} = \\frac{\\partial B_x}{\\partial x} + \\frac{\\partial B_y}{\\partial y} $$\nWe are tasked with discretizing this operator on a uniform cell-centered Cartesian grid defined by points $(x_i, y_j) = (i\\Delta x, j\\Delta y)$ for integer indices $i \\in [0, N_x-1]$ and $j \\in [0, N_y-1]$. The field components $B_x(i, j)$ and $B_y(i, j)$ are known at these cell centers.\n\nFor interior grid cells, where $0 < i < N_x-1$ and $0 < j < N_y-1$, we employ a second-order accurate central finite difference scheme. The partial derivatives are approximated as:\n$$ \\left(\\frac{\\partial B_x}{\\partial x}\\right)_{i,j} \\approx \\frac{B_x(i+1, j) - B_x(i-1, j)}{2 \\Delta x} $$\n$$ \\left(\\frac{\\partial B_y}{\\partial y}\\right)_{i,j} \\approx \\frac{B_y(i, j+1) - B_y(i, j-1)}{2 \\Delta y} $$\nThe discrete divergence at an interior cell $(i,j)$ is therefore:\n$$ (\\nabla \\cdot \\mathbf{B})_{i,j} \\approx \\frac{B_x(i+1, j) - B_x(i-1, j)}{2 \\Delta x} + \\frac{B_y(i, j+1) - B_y(i, j-1)}{2 \\Delta y} $$\n\nFor cells on the domain boundary, a first-order accurate one-sided difference is required for the derivative normal to that boundary, while the tangential derivative can still use a central stencil. For example, at a cell on the left boundary ($i=0$) but not at a corner ($0 < j < N_y-1$), the approximation becomes:\n$$ (\\nabla \\cdot \\mathbf{B})_{0,j} \\approx \\underbrace{\\frac{B_x(1, j) - B_x(0, j)}{\\Delta x}}_{\\text{1st-order forward}} + \\underbrace{\\frac{B_y(0, j+1) - B_y(0, j-1)}{2 \\Delta y}}_{\\text{2nd-order central}} $$\nAt a corner, for example the bottom-left corner ($i=0, j=0$), both derivatives must be approximated with first-order forward differences:\n$$ (\\nabla \\cdot \\mathbf{B})_{0,0} \\approx \\frac{B_x(1, 0) - B_x(0, 0)}{\\Delta x} + \\frac{B_y(0, 1) - B_y(0, 0)}{\\Delta y} $$\nAnalogous backward-difference stencils are used for the top and right boundaries. This mixed-accuracy scheme is a standard approach for discretizing derivatives on a bounded grid.\n\n### Step 2: Diagnostic Indicators and Triggers\n\nFrom the computed discrete divergence, $(\\nabla \\cdot \\mathbf{B})_{i,j}$, we define several diagnostic quantities.\n\nThe primary diagnostic is the dimensionless normalized divergence indicator, $\\varepsilon$, defined as:\n$$ \\varepsilon_{i,j} = \\frac{h |(\\nabla \\cdot \\mathbf{B})_{i,j}|}{|\\mathbf{B}|_{i,j} + B_{\\mathrm{floor}}} $$\nHere, $h = \\min(\\Delta x, \\Delta y)$ is a characteristic cell size, which makes $\\varepsilon$ a measure of the divergence error relative to the grid scale. $|\\mathbf{B}|_{i,j} = \\sqrt{B_x(i,j)^2 + B_y(i,j)^2}$ is the local magnetic field magnitude. The normalization by $|\\mathbf{B}|$ makes $\\varepsilon$ a relative error metric, which is often more meaningful than the absolute divergence. The constant $B_{\\mathrm{floor}}$ is a small positive number ($10^{-6}$ in this problem) that regularizes the expression, preventing division by zero or spuriously large values of $\\varepsilon$ in regions where the magnetic field is vanishingly weak (near-vacuum).\n\nBased on the values of $\\varepsilon$ and $|\\nabla \\cdot \\mathbf{B}|$, we define two boolean triggers for numerical control:\n\n1.  **Cleaning Trigger ($T_{\\mathrm{clean}}$):** This trigger indicates the need for a local divergence cleaning operation (e.g., using a hyperbolic or elliptic cleaning scheme). It is activated when the normalized divergence exceeds a moderate threshold:\n    $$ T_{\\mathrm{clean}} \\text{ is true if } \\varepsilon > \\theta_{\\mathrm{clean}} $$\n    For this problem, $\\theta_{\\mathrm{clean}} = 0.2$.\n\n2.  **Refinement Trigger ($T_{\\mathrm{ref}}$):** This trigger signals a more severe problem, suggesting that the local grid resolution may be insufficient to resolve the field structure, necessitating adaptive mesh refinement (AMR). It is activated by either a very large normalized divergence or a large absolute divergence:\n    $$ T_{\\mathrm{ref}} \\text{ is true if } (\\varepsilon > \\theta_{\\mathrm{ref}}) \\lor (|\\nabla \\cdot \\mathbf{B}| > \\phi_{\\mathrm{abs}}) $$\n    For this problem, $\\theta_{\\mathrm{ref}} = 0.6$ and $\\phi_{\\mathrm{abs}} = 0.8$.\n\n### Step 3: Computational Procedure\n\nThe overall algorithm proceeds as follows for each test case:\n1.  **Grid and Field Setup:** An $N_x \\times N_y$ grid is defined with spacings $\\Delta x$ and $\\Delta y$. The magnetic field components $B_x$ and $B_y$ are populated on this grid according to the specific test case definition.\n2.  **Divergence Calculation:** The discrete divergence, $(\\nabla \\cdot \\mathbf{B})_{i,j}$, is computed for all cells using the mixed-stencil finite difference scheme described above.\n3.  **Diagnostic Calculation:** The field magnitude $|\\mathbf{B}|_{i,j}$ and the normalized divergence $\\varepsilon_{i,j}$ are computed for all cells.\n4.  **Trigger Evaluation:** The boolean conditions for $T_{\\mathrm{clean}}$ and $T_{\\mathrm{ref}}$ are evaluated at each cell, yielding two boolean arrays.\n5.  **Result Aggregation:** The final outputs are computed from the full-grid diagnostic arrays:\n    - The maximum value of the normalized divergence, $\\varepsilon_{\\max} = \\max_{i,j}(\\varepsilon_{i,j})$.\n    - The total number of cells requiring cleaning, $n_{\\mathrm{clean}} = \\sum_{i,j} T_{\\mathrm{clean}}(i,j)$.\n    - The total number of cells requiring refinement, $n_{\\mathrm{ref}} = \\sum_{i,j} T_{\\mathrm{ref}}(i,j)$.\n\nThis procedure is applied to each of the four specified test cases, which are designed to probe the diagnostic's response to different field configurations: a smooth, analytically divergence-free field; a sharp discontinuity emulating a magnetic monopole; a near-vacuum region with random noise; and a step function in one field component superposed on a strong, uniform background field.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases for MHD divergence diagnostics.\n    \"\"\"\n\n    def compute_diagnostics(Nx, Ny, Bx, By, dx, dy):\n        \"\"\"\n        Computes divergence diagnostics for a given magnetic field on a Cartesian grid.\n\n        Args:\n            Nx (int): Number of grid points in x.\n            Ny (int): Number of grid points in y.\n            Bx (np.ndarray): 2D array of the x-component of the magnetic field.\n            By (np.ndarray): 2D array of the y-component of the magnetic field.\n            dx (float): Grid spacing in x.\n            dy (float): Grid spacing in y.\n\n        Returns:\n            list: A list containing [eps_max, n_clean, n_ref].\n        \"\"\"\n        # Define given thresholds and regularization constant\n        theta_clean = 0.2\n        theta_ref = 0.6\n        phi_abs = 0.8\n        B_floor = 1e-6\n        \n        # Characteristic cell size\n        h = min(dx, dy)\n\n        # Compute partial derivatives using a second-order central difference\n        # for the interior and a first-order one-sided difference at the boundaries.\n        # numpy.gradient implements this exact scheme.\n        # For an array of shape (Nx, Ny) with 'ij' indexing,\n        # axis=0 corresponds to the x-axis (index i) and axis=1 to the y-axis (index j).\n        d_Bx_dx = np.gradient(Bx, dx, axis=0)\n        d_By_dy = np.gradient(By, dy, axis=1)\n\n        # Compute divergence of B\n        div_B = d_Bx_dx + d_By_dy\n\n        # Compute magnetic field magnitude\n        B_mag = np.sqrt(Bx**2 + By**2)\n\n        # Compute dimensionless normalized divergence indicator epsilon\n        epsilon = h * np.abs(div_B) / (B_mag + B_floor)\n        \n        # Calculate maximum epsilon over the grid\n        eps_max = np.max(epsilon)\n\n        # Evaluate cleaning and refinement triggers\n        T_clean = epsilon > theta_clean\n        T_ref = (epsilon > theta_ref) | (np.abs(div_B) > phi_abs)\n\n        # Count the number of cells where triggers are true\n        n_clean = np.sum(T_clean)\n        n_ref = np.sum(T_ref)\n\n        return [round(eps_max, 6), int(n_clean), int(n_ref)]\n\n    results = []\n\n    # Test Case A: Smooth, nearly divergence-free field\n    Nx_A, Ny_A = 33, 33\n    x_A = np.linspace(0, 2 * np.pi, Nx_A)\n    y_A = np.linspace(0, 2 * np.pi, Ny_A)\n    dx_A, dy_A = x_A[1] - x_A[0], y_A[1] - y_A[0]\n    xx_A, yy_A = np.meshgrid(x_A, y_A, indexing='ij')\n    kx, ky = 2, 3\n    Bx_A = ky * np.sin(kx * xx_A) * np.cos(ky * yy_A)\n    By_A = -kx * np.cos(kx * xx_A) * np.sin(ky * yy_A)\n    results.append(compute_diagnostics(Nx_A, Ny_A, Bx_A, By_A, dx_A, dy_A))\n\n    # Test Case B: Monopole-like interface\n    Nx_B, Ny_B = 9, 9\n    dx_B, dy_B = 1.0, 1.0\n    Bx_B = np.zeros((Nx_B, Ny_B))\n    i_step_B = int(np.ceil(Nx_B / 2.0)) # For Nx=9, ceil(4.5)=5. 0-indexed: 5,6,7,8\n    Bx_B[i_step_B:, :] = 1.0\n    By_B = np.zeros((Nx_B, Ny_B))\n    results.append(compute_diagnostics(Nx_B, Ny_B, Bx_B, By_B, dx_B, dy_B))\n\n    # Test Case C: Near-vacuum noise\n    Nx_C, Ny_C = 7, 7\n    dx_C, dy_C = 1.0, 1.0\n    rng = np.random.default_rng(seed=0)\n    Bx_C = rng.uniform(-1e-12, 1e-12, size=(Nx_C, Ny_C))\n    By_C = rng.uniform(-1e-12, 1e-12, size=(Nx_C, Ny_C))\n    results.append(compute_diagnostics(Nx_C, Ny_C, Bx_C, By_C, dx_C, dy_C))\n\n    # Test Case D: Strong uniform field with localized perturbation\n    Nx_D, Ny_D = 17, 17\n    dx_D, dy_D = 1.0, 1.0\n    Bx_D = np.full((Nx_D, Ny_D), 5.0)\n    By_D = np.zeros((Nx_D, Ny_D))\n    j_step_D = int(np.floor(Ny_D / 2.0)) # For Ny=17, floor(8.5)=8. 0-indexed: 8,...,16\n    By_D[:, j_step_D:] += 1.0\n    results.append(compute_diagnostics(Nx_D, Ny_D, Bx_D, By_D, dx_D, dy_D))\n    \n    # Format the final output string\n    # e.g., [[1.0,2,3],[4.0,5,6]]\n    output_str = f\"[{','.join(str(r).replace(' ', '') for r in results)}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "Once divergence errors are detected, a developer must choose a method to remove them, often facing a trade-off between accuracy and computational expense. This practice directly addresses this critical decision by comparing two workhorse algorithms: the instantaneous (but global) projection method and the iterative (but local) Generalized Lagrange Multiplier (GLM) scheme . By implementing and evaluating both methods on a challenging field configuration, you will develop a practical understanding of their respective strengths and weaknesses, a key insight for optimizing MHD simulations for performance and accuracy.",
            "id": "3506842",
            "problem": "You are to implement and compare two divergence-cleaning strategies for the magnetic field in Magnetohydrodynamics (MHD): a spectral projection method and a Generalized Lagrange Multiplier (GLM) cleaning method. The comparison must be made in terms of accuracy, measured by the post-cleaning discrete divergence norm, and computational cost, modeled by simple operation counts. All quantities are dimensionless.\n\nThe fundamental base for this problem is the divergence-free constraint from Maxwell’s equations in MHD, namely that the magnetic field satisfies $\\nabla \\cdot \\mathbf{B} = 0$. In practice, numerical schemes in shock-dominated flows can violate this constraint, leading to a nonzero discrete divergence that must be cleaned. Two widely used strategies are:\n\n- A projection method that enforces the constraint by solving a Poisson equation for a potential $\\phi$ and projecting $\\mathbf{B}$ via $\\mathbf{B} \\leftarrow \\mathbf{B} - \\nabla \\phi$.\n- A Generalized Lagrange Multiplier (GLM) method that introduces an auxiliary scalar field $\\psi$ and couples it hyperbolically and parabolically to $\\nabla \\cdot \\mathbf{B}$ to damp and advect divergence.\n\nYou must implement both methods on a periodic two-dimensional square domain $[0,1) \\times [0,1)$, discretized with a uniform grid of $N_x \\times N_y$ cells, with $\\Delta x = 1/N_x$ and $\\Delta y = 1/N_y$. The comparison shall be executed for a set of prescribed test cases.\n\nField construction for shock-dominated pre-cleaning state:\n- Construct a synthetic pre-cleaning magnetic field $\\mathbf{B}^*$ that mimics a shock-dominated situation by combining a smooth solenoidal component and a controlled non-solenoidal component:\n  - Let $\\psi(x,y) = A \\sin(2\\pi x)\\sin(2\\pi y)$ with $A = 0.1$.\n  - Let $\\phi_{\\text{shock}}(x,y) = s \\tanh\\left(\\frac{x - 1/2}{w}\\right)$, where $s$ controls shock severity and $w$ controls shock thickness.\n  - Define\n    $$\n    B_x^*(x,y) = \\frac{\\partial \\psi}{\\partial y}(x,y) + \\frac{\\partial \\phi_{\\text{shock}}}{\\partial x}(x,y), \\quad\n    B_y^*(x,y) = -\\frac{\\partial \\psi}{\\partial x}(x,y),\n    $$\n    so that $\\nabla \\cdot \\mathbf{B}^* = \\nabla^2 \\phi_{\\text{shock}}$ is nonzero and concentrated at the shock. Derivatives appearing in the construction of $\\mathbf{B}^*$ must be computed analytically:\n    $$\n    \\frac{\\partial \\psi}{\\partial y} = A \\sin(2\\pi x)\\, 2\\pi \\cos(2\\pi y), \\quad\n    \\frac{\\partial \\psi}{\\partial x} = A\\, 2\\pi \\cos(2\\pi x)\\, \\sin(2\\pi y),\n    $$\n    $$\n    \\frac{\\partial \\phi_{\\text{shock}}}{\\partial x} = \\frac{s}{w} \\operatorname{sech}^2\\!\\left(\\frac{x - 1/2}{w}\\right), \\quad \\frac{\\partial \\phi_{\\text{shock}}}{\\partial y} = 0.\n    $$\n\nDiscrete diagnostics:\n- Use second-order central differences with periodic wrapping to define the discrete divergence of a grid field $\\mathbf{B}$:\n  $$\n  (\\nabla \\cdot \\mathbf{B})_{i,j} = \\frac{B_{x,i+1,j} - B_{x,i-1,j}}{2\\Delta x} + \\frac{B_{y,i,j+1} - B_{y,i,j-1}}{2\\Delta y}.\n  $$\n- Define the discrete $L^2$ divergence norm as\n  $$\n  E(\\mathbf{B}) = \\sqrt{\\frac{1}{N_x N_y} \\sum_{i,j} \\left[(\\nabla \\cdot \\mathbf{B})_{i,j}\\right]^2 }.\n  $$\n\nMethod 1: Spectral projection (Poisson solve):\n- Compute a scalar potential $\\phi$ on the periodic grid by solving\n  $$\n  \\nabla^2 \\phi = \\nabla \\cdot \\mathbf{B}^*\n  $$\n  with zero-mean condition for $\\phi$ (i.e., the Fourier mode at zero wavenumber set to zero). Implement this solve spectrally using the Fast Fourier Transform (FFT): in Fourier space, for wavenumbers $k_x = 2\\pi n_x$ and $k_y = 2\\pi n_y$, solve\n  $$\n  \\widehat{\\phi}(\\mathbf{k}) = -\\frac{\\widehat{\\nabla \\cdot \\mathbf{B}^*}(\\mathbf{k})}{k_x^2 + k_y^2} \\quad \\text{for} \\quad \\mathbf{k} \\neq \\mathbf{0}, \\quad \\widehat{\\phi}(\\mathbf{0}) = 0,\n  $$\n  and obtain $\\nabla \\phi$ spectrally via multiplication by $\\mathrm{i}\\mathbf{k}$ and inverse FFTs. The cleaned field is\n  $$\n  \\mathbf{B}^{\\mathrm{proj}} = \\mathbf{B}^* - \\nabla \\phi.\n  $$\n- Cost model for the projection method: use a count of FFT operations. Assume that computing the projection requires $n_{\\mathrm{FFT}} = 4$ two-dimensional FFTs. The cost per two-dimensional FFT is modeled as\n  $$\n  C_{\\mathrm{FFT}} = \\gamma \\, N_x N_y \\, \\log_2(N_x N_y),\n  $$\n  where $\\gamma$ is a positive constant. Thus the total cost is\n  $$\n  \\text{Cost}_{\\mathrm{proj}} = n_{\\mathrm{FFT}} \\, C_{\\mathrm{FFT}}.\n  $$\n\nMethod 2: GLM cleaning (Generalized Lagrange Multiplier):\n- Initialize $\\psi = 0$. For $m$ substeps, perform the explicit update\n  $$\n  \\psi^{n+1} = \\psi^n - \\Delta t \\, c_h^2 \\, (\\nabla \\cdot \\mathbf{B}^n) - \\Delta t \\, \\frac{c_h^2}{c_p^2} \\, \\psi^n,\n  $$\n  $$\n  \\mathbf{B}^{n+1} = \\mathbf{B}^n - \\Delta t \\, \\nabla \\psi^{n+1},\n  $$\n  where $c_h$ is the hyperbolic cleaning speed, $c_p$ is the parabolic damping parameter, and $\\nabla$ is discretized by second-order central differences with periodic wrapping (consistent with the divergence operator above). Set the number of substeps to\n  $$\n  m = \\lceil c_h \\rceil,\n  $$\n  and choose the substep size\n  $$\n  \\Delta t = \\mathrm{CFL} \\cdot \\frac{\\min(\\Delta x,\\Delta y)}{\\max(c_h, 10^{-8})},\n  $$\n  with $\\mathrm{CFL} = 0.8$. The cleaned field after $m$ substeps is denoted $\\mathbf{B}^{\\mathrm{glm}}$.\n- Cost model for the GLM method: count local stencil operations. Assume each substep costs\n  $$\n  C_{\\mathrm{local}} = \\beta \\, N_x N_y\n  $$\n  operations, so the total cost is\n  $$\n  \\text{Cost}_{\\mathrm{glm}} = m \\, C_{\\mathrm{local}}.\n  $$\n\nComparison metric and decision rule:\n- Define an absolute accuracy tolerance\n  $$\n  \\tau = 10^{-3}.\n  $$\n- For each method, compute the post-cleaning divergence norms $E(\\mathbf{B}^{\\mathrm{proj}})$ and $E(\\mathbf{B}^{\\mathrm{glm}})$, and the costs $\\text{Cost}_{\\mathrm{proj}}$ and $\\text{Cost}_{\\mathrm{glm}}$ using the models above with $\\gamma$ and $\\beta$ specified below.\n- Determine which method dominates according to the following rule:\n  - If exactly one method achieves $E \\le \\tau$, select that method.\n  - If both methods achieve $E \\le \\tau$, select the one with the lower cost.\n  - If neither method achieves $E \\le \\tau$, select the one with the smaller $E$; if $E$ is equal within a relative tolerance of $10^{-6}$, select the one with lower cost.\n- Encode the selection per test case as an integer:\n  - Output $1$ if the projection method is selected.\n  - Output $-1$ if the GLM method is selected.\n  - Output $0$ if the tie-breaking leads to no strict preference (only applicable when both methods have equal $E$ within the relative tolerance and equal cost under the cost model).\n\nConstants for the cost model:\n- Use $\\gamma = 5.0$ and $\\beta = 20.0$.\n\nTest suite:\nImplement the program to execute exactly the following five test cases, where each tuple is $(N_x, N_y, s, w, c_h, c_p)$:\n- Case $1$: $(128, 128, 1.0, 0.02, 1.0, 1.0)$\n- Case $2$: $(128, 128, 3.0, 0.01, 1.0, 1.0)$\n- Case $3$: $(256, 256, 1.0, 0.02, 1.0, 1.0)$\n- Case $4$: $(128, 128, 1.0, 0.02, 5.0, 1.0)$\n- Case $5$: $(64, 64, 0.5, 0.05, 0.5, 1.0)$\n\nRequired final output:\n- Your program should produce a single line of output containing the results as a comma-separated list of integers enclosed in square brackets, in the same order as the test cases, for example, \"[$r_1, r_2, r_3, r_4, r_5$]\". No other output is permitted.",
            "solution": "The problem requires the implementation and comparison of two distinct numerical methods for enforcing the divergence-free constraint, $\\nabla \\cdot \\mathbf{B} = 0$, in Magnetohydrodynamics (MHD) on a two-dimensional periodic domain. The methods to be compared are a spectral projection method and a Generalized Lagrange Multiplier (GLM) cleaning scheme. The comparison is based on post-cleaning accuracy, measured by a discrete divergence norm, and computational cost, estimated through simplified operational models.\n\nFirst, we establish the computational domain and the initial state. The domain is a periodic square $[0,1) \\times [0,1)$ discretized by a uniform grid of $N_x \\times N_y$ cells, with grid spacings $\\Delta x = 1/N_x$ and $\\Delta y = 1/N_y$. The cell centers are located at $(x_i, y_j) = ((i+0.5)\\Delta x, (j+0.5)\\Delta y)$ for $i \\in \\{0, \\dots, N_x-1\\}$ and $j \\in \\{0, \\dots, N_y-1\\}$.\n\nThe initial, pre-cleaning magnetic field, denoted $\\mathbf{B}^*$, is analytically defined to contain both a solenoidal (divergence-free) part and a non-solenoidal part, mimicking numerical errors from a shock. It is constructed from a vector potential $\\psi(x,y) = A \\sin(2\\pi x)\\sin(2\\pi y)$ and a scalar potential $\\phi_{\\text{shock}}(x,y) = s \\tanh\\left(\\frac{x - 1/2}{w}\\right)$, with $A=0.1$. The components are:\n$$\nB_x^*(x,y) = \\frac{\\partial \\psi}{\\partial y}(x,y) + \\frac{\\partial \\phi_{\\text{shock}}}{\\partial x}(x,y) = 2\\pi A \\sin(2\\pi x) \\cos(2\\pi y) + \\frac{s}{w} \\operatorname{sech}^2\\!\\left(\\frac{x - 1/2}{w}\\right)\n$$\n$$\nB_y^*(x,y) = -\\frac{\\partial \\psi}{\\partial x}(x,y) = -2\\pi A \\cos(2\\pi x) \\sin(2\\pi y)\n$$\nThe divergence of this field is analytically $\\nabla \\cdot \\mathbf{B}^* = \\nabla^2\\phi_{\\text{shock}}$, which is non-zero.\n\nThe accuracy of each cleaning method is quantified by the discrete $L^2$ norm of the divergence of the cleaned field, defined as:\n$$\nE(\\mathbf{B}) = \\sqrt{\\frac{1}{N_x N_y} \\sum_{i,j} \\left[(\\nabla \\cdot \\mathbf{B})_{i,j}\\right]^2 }\n$$\nThe discrete divergence operator $(\\nabla \\cdot \\mathbf{B})_{i,j}$ is approximated using second-order central differences with periodic boundary conditions:\n$$\n(\\nabla \\cdot \\mathbf{B})_{i,j} = \\frac{B_{x,i+1,j} - B_{x,i-1,j}}{2\\Delta x} + \\frac{B_{y,i,j+1} - B_{y,i,j-1}}{2\\Delta y}\n$$\n\n**Method 1: Spectral Projection**\n\nThe principle of the projection method is to decompose the initial field $\\mathbf{B}^*$ into a divergence-free part and the gradient of a scalar potential, $\\mathbf{B}^* = \\mathbf{B}^{\\mathrm{proj}} + \\nabla \\phi$. To make the cleaned field $\\mathbf{B}^{\\mathrm{proj}}$ divergence-free (i.e., $\\nabla \\cdot \\mathbf{B}^{\\mathrm{proj}} = 0$), the potential $\\phi$ must satisfy the Poisson equation:\n$$\n\\nabla^2 \\phi = \\nabla \\cdot \\mathbf{B}^*\n$$\nOn a periodic domain, this equation is efficiently solved in Fourier space. Taking the Fourier transform yields:\n$$\n-(k_x^2 + k_y^2) \\widehat{\\phi}(\\mathbf{k}) = \\widehat{\\nabla \\cdot \\mathbf{B}^*}(\\mathbf{k})\n$$\nwhere $\\mathbf{k}=(k_x, k_y)$ is the wavenumber vector, with components $k_x = 2\\pi n_x$ and $k_y = 2\\pi n_y$ for integer mode numbers $n_x, n_y$. The solution for the Fourier coefficients of the potential is:\n$$\n\\widehat{\\phi}(\\mathbf{k}) = -\\frac{\\widehat{\\nabla \\cdot \\mathbf{B}^*}(\\mathbf{k})}{k_x^2 + k_y^2} \\quad \\text{for} \\quad \\mathbf{k} \\neq \\mathbf{0}\n$$\nFor $\\mathbf{k} = \\mathbf{0}$, the denominator is zero. A unique solution for $\\phi$ is obtained by imposing the zero-mean condition, $\\widehat{\\phi}(\\mathbf{0}) = 0$.\n\nThe implementation consistently uses the spectral method for all derivatives. First, the Fourier transforms of $B_x^*$ and $B_y^*$ are computed. Then, the divergence is computed in Fourier space via $\\widehat{\\nabla \\cdot \\mathbf{B}^*} = i k_x \\widehat{B_x^*} + i k_y \\widehat{B_y^*}$. After solving for $\\widehat{\\phi}$, the gradient $\\nabla \\phi$ is also found spectrally: $\\widehat{\\nabla\\phi} = i\\mathbf{k}\\widehat{\\phi}$. The components of $\\nabla\\phi$ are then recovered via inverse Fourier transforms. The cleaned field is $\\mathbf{B}^{\\mathrm{proj}} = \\mathbf{B}^* - \\nabla\\phi$. This entire procedure requires two forward Fast Fourier Transforms (FFTs) for $\\mathbf{B}^*$ and two inverse FFTs for $\\nabla\\phi$, confirming the given parameter $n_{\\mathrm{FFT}} = 4$. The computational cost is modeled as:\n$$\n\\text{Cost}_{\\mathrm{proj}} = n_{\\mathrm{FFT}} \\, \\gamma \\, N_x N_y \\, \\log_2(N_x N_y)\n$$\nwith $\\gamma = 5.0$.\n\n**Method 2: Generalized Lagrange Multiplier (GLM)**\n\nThe GLM method introduces an auxiliary scalar field, $\\psi$, which is coupled to the magnetic field. The system of equations is designed to transport divergence errors out of the domain at a speed $c_h$ and simultaneously damp them on a timescale related to a parameter $c_p$. The iterative update scheme for a single cleaning sweep is given by:\n$$\n\\psi^{n+1} = \\psi^n - \\Delta t \\, c_h^2 \\, (\\nabla \\cdot \\mathbf{B}^n) - \\Delta t \\, \\frac{c_h^2}{c_p^2} \\, \\psi^n\n$$\n$$\n\\mathbf{B}^{n+1} = \\mathbf{B}^n - \\Delta t \\, \\nabla \\psi^{n+1}\n$$\nStarting with $\\psi^0 = 0$ and $\\mathbf{B}^0 = \\mathbf{B}^*$, this scheme is applied for a total of $m = \\lceil c_h \\rceil$ substeps. The time step $\\Delta t$ is determined by a Courant-Friedrichs-Lewy (CFL) condition:\n$$\n\\Delta t = \\mathrm{CFL} \\cdot \\frac{\\min(\\Delta x,\\Delta y)}{\\max(c_h, 10^{-8})}\n$$\nwith $\\mathrm{CFL} = 0.8$. The discrete gradient $\\nabla$ and divergence $\\nabla \\cdot$ operators are implemented using second-order central differences, consistent with the diagnostic calculation. The cost, based on local stencil operations, is modeled as:\n$$\n\\text{Cost}_{\\mathrm{glm}} = m \\, \\beta \\, N_x N_y\n$$\nwith $\\beta = 20.0$.\n\n**Comparison and Decision**\n\nFor each test case, both methods are executed to obtain the cleaned fields $\\mathbf{B}^{\\mathrm{proj}}$ and $\\mathbf{B}^{\\mathrm{glm}}$, their respective divergence norms $E(\\mathbf{B}^{\\mathrm{proj}})$ and $E(\\mathbf{B}^{\\mathrm{glm}})$, and their costs $\\text{Cost}_{\\mathrm{proj}}$ and $\\text{Cost}_{\\mathrm{glm}}$. A decision is made based on a pre-defined rule set involving an accuracy tolerance $\\tau = 10^{-3}$:\n1.  If one method is accurate ($E \\le \\tau$) and the other is not, the accurate one is chosen.\n2.  If both are accurate, the one with the lower cost is chosen.\n3.  If neither is accurate, the one with the lower divergence norm $E$ is chosen. A tie in $E$ (within a relative tolerance of $10^{-6}$) is broken by choosing the lower-cost method.\n\nThe final choice is encoded as $1$ for the projection method, $-1$ for the GLM method, and $0$ for a perfect tie in both accuracy (within tolerance) and cost.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and compares spectral projection and GLM divergence cleaning methods for MHD.\n    \"\"\"\n\n    # --- Problem Constants ---\n    A = 0.1\n    GAMMA = 5.0\n    BETA = 20.0\n    CFL = 0.8\n    TAU = 1e-3\n    REL_TOL_E = 1e-6\n\n    # --- Test Suite ---\n    test_cases = [\n        # (Nx, Ny, s, w, ch, cp)\n        (128, 128, 1.0, 0.02, 1.0, 1.0),\n        (128, 128, 3.0, 0.01, 1.0, 1.0),\n        (256, 256, 1.0, 0.02, 1.0, 1.0),\n        (128, 128, 1.0, 0.02, 5.0, 1.0),\n        (64, 64, 0.5, 0.05, 0.5, 1.0),\n    ]\n\n    def calculate_divergence(Bx, By, dx, dy):\n        \"\"\"Computes discrete divergence using 2nd-order central differences.\"\"\"\n        d_Bx_dx = (np.roll(Bx, -1, axis=1) - np.roll(Bx, 1, axis=1)) / (2 * dx)\n        d_By_dy = (np.roll(By, -1, axis=0) - np.roll(By, 1, axis=0)) / (2 * dy)\n        return d_Bx_dx + d_By_dy\n\n    def calculate_gradient(phi, dx, dy):\n        \"\"\"Computes discrete gradient using 2nd-order central differences.\"\"\"\n        d_phi_dx = (np.roll(phi, -1, axis=1) - np.roll(phi, 1, axis=1)) / (2 * dx)\n        d_phi_dy = (np.roll(phi, -1, axis=0) - np.roll(phi, 1, axis=0)) / (2 * dy)\n        return d_phi_dx, d_phi_dy\n\n    def run_projection_method(B_star_x, B_star_y, Nx, Ny, dx, dy):\n        \"\"\"Implements the spectral projection method.\"\"\"\n        # Wavenumbers\n        kx = 2 * np.pi * np.fft.fftfreq(Nx, d=dx)\n        ky = 2 * np.pi * np.fft.fftfreq(Ny, d=dy)\n        kx_grid, ky_grid = np.meshgrid(kx, ky)\n        k_squared = kx_grid**2 + ky_grid**2\n\n        # FFT of initial field\n        B_hat_x = np.fft.fft2(B_star_x)\n        B_hat_y = np.fft.fft2(B_star_y)\n\n        # Spectral divergence\n        div_B_hat = 1j * kx_grid * B_hat_x + 1j * ky_grid * B_hat_y\n\n        # Solve for phi in Fourier space\n        phi_hat = np.zeros_like(div_B_hat)\n        non_zero_k = k_squared != 0\n        phi_hat[non_zero_k] = -div_B_hat[non_zero_k] / k_squared[non_zero_k]\n\n        # Spectral gradient of phi\n        grad_phi_x_hat = 1j * kx_grid * phi_hat\n        grad_phi_y_hat = 1j * ky_grid * phi_hat\n\n        # Inverse FFT to get gradient in real space\n        grad_phi_x = np.fft.ifft2(grad_phi_x_hat).real\n        grad_phi_y = np.fft.ifft2(grad_phi_y_hat).real\n\n        # Cleaned field\n        B_proj_x = B_star_x - grad_phi_x\n        B_proj_y = B_star_y - grad_phi_y\n\n        # Diagnostics\n        div_proj = calculate_divergence(B_proj_x, B_proj_y, dx, dy)\n        E_proj = np.sqrt(np.mean(div_proj**2))\n        cost_proj = 4 * GAMMA * Nx * Ny * np.log2(Nx * Ny)\n        \n        return E_proj, cost_proj\n\n    def run_glm_method(B_star_x, B_star_y, Nx, Ny, dx, dy, ch, cp):\n        \"\"\"Implements the GLM cleaning method.\"\"\"\n        # Parameters\n        m = int(np.ceil(ch))\n        dt = CFL * min(dx, dy) / max(ch, 1e-8)\n\n        # Initialization\n        psi = np.zeros((Ny, Nx))\n        Bx = B_star_x.copy()\n        By = B_star_y.copy()\n\n        # Iterative cleaning\n        for _ in range(m):\n            div_B = calculate_divergence(Bx, By, dx, dy)\n            psi_new = psi - dt * ch**2 * div_B - dt * (ch**2 / cp**2) * psi\n            grad_psi_x, grad_psi_y = calculate_gradient(psi_new, dx, dy)\n            Bx_new = Bx - dt * grad_psi_x\n            By_new = By - dt * grad_psi_y\n            \n            psi, Bx, By = psi_new, Bx_new, By_new\n        \n        # Diagnostics\n        B_glm_x, B_glm_y = Bx, By\n        div_glm = calculate_divergence(B_glm_x, B_glm_y, dx, dy)\n        E_glm = np.sqrt(np.mean(div_glm**2))\n        cost_glm = m * BETA * Nx * Ny\n\n        return E_glm, cost_glm\n        \n    results = []\n    for case in test_cases:\n        Nx, Ny, s, w, ch, cp = case\n        \n        # Grid setup\n        dx = 1.0 / Nx\n        dy = 1.0 / Ny\n        x = (np.arange(Nx) + 0.5) * dx\n        y = (np.arange(Ny) + 0.5) * dy\n        xx, yy = np.meshgrid(x, y)\n\n        # Initial field construction\n        B_star_x = (A * 2 * np.pi * np.sin(2 * np.pi * xx) * np.cos(2 * np.pi * yy) + \n                    (s / w) / (np.cosh((xx - 0.5) / w)**2))\n        B_star_y = -A * 2 * np.pi * np.cos(2 * np.pi * xx) * np.sin(2 * np.pi * yy)\n        \n        # Run methods\n        E_proj, cost_proj = run_projection_method(B_star_x, B_star_y, Nx, Ny, dx, dy)\n        E_glm, cost_glm = run_glm_method(B_star_x, B_star_y, Nx, Ny, dx, dy, ch, cp)\n\n        # Comparison logic\n        proj_ok = E_proj = TAU\n        glm_ok = E_glm = TAU\n        \n        result = 0\n        if proj_ok and not glm_ok:\n            result = 1\n        elif not proj_ok and glm_ok:\n            result = -1\n        elif proj_ok and glm_ok:\n            if cost_proj  cost_glm:\n                result = 1\n            elif cost_glm  cost_proj:\n                result = -1\n            else:\n                result = 0\n        else: # Neither is OK\n            if np.isclose(E_proj, E_glm, rtol=REL_TOL_E):\n                if cost_proj  cost_glm:\n                    result = 1\n                elif cost_glm  cost_proj:\n                    result = -1\n                else: \n                    result = 0\n            elif E_proj  E_glm:\n                result = 1\n            else:\n                result = -1\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}