{
    "hands_on_practices": [
        {
            "introduction": "$N$-body simulations model a continuous collisionless fluid, such as dark matter, using a finite number of discrete particles. A fundamental first step is to arrange these particles in a way that faithfully represents a given density field, but this discretization inevitably introduces spurious fluctuations. This practice explores how different particle sampling strategies control the amplitude of these fluctuations . You will implement and compare the noise properties of random Poisson sampling against the highly structured quiet start and jittered lattice methods, gaining crucial insight into how initial conditions are engineered for precision cosmology.",
            "id": "3518281",
            "problem": "Construct a program that quantifies how different particle sampling strategies discretize a uniform collisionless mass distribution on a one-dimensional periodic domain by measuring the amplitude of spurious density fluctuations at prescribed Fourier modes. Work in a dimensionless periodic interval of length $L = 1$. Consider a uniform mass density represented by $N$ equal-mass particles at positions $\\{x_i\\}_{i=1}^N$ with $x_i \\in [0,L)$. Define the complex Fourier amplitude of the discrete density contrast at integer mode index $n \\in \\mathbb{Z}$ as\n$$\n\\delta_k(n) \\equiv \\frac{1}{N}\\sum_{i=1}^N \\exp\\!\\left(-\\mathrm{i}\\,k_n\\,x_i\\right),\\quad k_n \\equiv \\frac{2\\pi n}{L},\n$$\nand define the measured power at mode $n$ as\n$$\nP_\\mathrm{meas}(n) \\equiv \\left|\\delta_k(n)\\right|^2.\n$$\nYou must implement three sampling strategies for the particle positions:\n\n- Poisson sampling (independent and identically distributed uniform sampling): draw $x_i$ independently from the uniform distribution on $[0,L)$.\n- Quiet lattice sampling (also called quiet start): set $x_i = \\left(i-\\tfrac{1}{2}\\right)\\frac{L}{N}$ for $i \\in \\{1,2,\\dots,N\\}$.\n- Jittered lattice sampling with Gaussian displacements: set $x_i = \\left(i-\\tfrac{1}{2}\\right)\\frac{L}{N} + \\varepsilon_i$ where the $\\varepsilon_i$ are independent Gaussian random variables with mean $0$ and variance $\\sigma^2$.\n\nStarting from the fundamental representation of a collisionless system as a sum of Dirac delta functions in configuration space, the periodic Fourier representation on $[0,L)$, and basic properties of independent random variables, derive the following expectations for $n \\neq 0$:\n- For Poisson sampling, the expected power satisfies $ \\mathbb{E}\\!\\left[P_\\mathrm{meas}(n)\\right] = \\frac{1}{N}$.\n- For quiet lattice sampling, $P_\\mathrm{meas}(n) = 0$ for all integers $n$ with $1 \\le n < N$.\n- For jittered lattice sampling with independent Gaussian displacements of variance $\\sigma^2$, the characteristic function of a single displacement is $\\phi(k) = \\exp\\!\\left(-\\tfrac{1}{2}\\sigma^2 k^2\\right)$, and the expected power at mode $n$ is\n$$\n\\mathbb{E}\\!\\left[P_\\mathrm{meas}(n)\\right] = \\frac{1}{N}\\left(1 - \\left|\\phi(k_n)\\right|^2\\right) = \\frac{1}{N}\\left(1 - \\exp\\!\\left(-\\sigma^2 k_n^2\\right)\\right).\n$$\n\nImplement a program that, for each specified test case, constructs $\\{x_i\\}_{i=1}^N$ according to the chosen sampling strategy, computes $P_\\mathrm{meas}(n)$, and also computes the corresponding theoretical prediction $P_\\mathrm{theory}(n)$ based on the formulas above. Use fixed random number generator seeds when randomness is involved to ensure reproducibility.\n\nUse the following test suite, which probes a typical case, exact cancellation in a quiet start, weak jitter, and stronger jitter near the Nyquist-like regime:\n- Case A (Poisson sampling): $N = 1024$, $L = 1$, $n = 1$, random seed $= 7$.\n- Case B (Quiet lattice): $N = 64$, $L = 1$, $n = 1$.\n- Case C (Jittered lattice): $N = 256$, $L = 1$, $n = 3$, $\\sigma = 0.01$, random seed $= 123$.\n- Case D (Jittered lattice): $N = 64$, $L = 1$, $n = 31$, $\\sigma = 0.1$, random seed $= 1$.\n\nFor each case, your program must compute and output two floats: first $P_\\mathrm{meas}(n)$ and then $P_\\mathrm{theory}(n)$ for that case. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as $[\\text{Case A }P_\\mathrm{meas}, \\text{Case A }P_\\mathrm{theory}, \\text{Case B }P_\\mathrm{meas}, \\text{Case B }P_\\mathrm{theory}, \\text{Case C }P_\\mathrm{meas}, \\text{Case C }P_\\mathrm{theory}, \\text{Case D }P_\\mathrm{meas}, \\text{Case D }P_\\mathrm{theory}]$. All quantities are dimensionless and require no physical units. Angles are in radians implicitly through the Fourier phase $k_n x$.",
            "solution": "The problem requires the derivation of the expected power spectrum of spurious density fluctuations for three different particle sampling strategies in a one-dimensional periodic domain, followed by a numerical implementation to verify these theoretical predictions. We begin by presenting the derivations for each case.\n\nThe physical system is a uniform mass distribution on a periodic interval $[0, L)$, discretized into $N$ particles of equal mass. The position of the $i$-th particle is $x_i$. The departure from a perfectly uniform continuum density is quantified by the Fourier components of the particle distribution. The complex amplitude of the density contrast at mode $n$ is defined as\n$$\n\\delta_k(n) \\equiv \\frac{1}{N}\\sum_{i=1}^N \\exp\\!\\left(-\\mathrm{i}\\,k_n\\,x_i\\right)\n$$\nwhere $k_n = \\frac{2\\pi n}{L}$ is the wavenumber for integer mode index $n \\in \\mathbb{Z}$. The power spectrum, $P_\\mathrm{meas}(n)$, is the squared magnitude of this amplitude:\n$$\nP_\\mathrm{meas}(n) \\equiv \\left|\\delta_k(n)\\right|^2 = \\delta_k(n) \\delta_k^*(n)\n$$\nwhere $\\delta_k^*(n)$ is the complex conjugate of $\\delta_k(n)$. We are interested in the expectation value of this power, $\\mathbb{E}\\!\\left[P_\\mathrm{meas}(n)\\right]$, for random sampling methods, or its direct value for deterministic ones. We will consider $n \\neq 0$, as the $n=0$ mode corresponds to the mean density, which is not a fluctuation.\n\n**1. Poisson Sampling**\n\nIn Poisson sampling, the particle positions $\\{x_i\\}_{i=1}^N$ are independent and identically distributed (i.i.d.) random variables drawn from a uniform probability distribution over the interval $[0, L)$. The expectation of the power spectrum is\n$$\n\\mathbb{E}\\!\\left[P_\\mathrm{meas}(n)\\right] = \\mathbb{E}\\!\\left[ \\left( \\frac{1}{N}\\sum_{i=1}^N e^{-\\mathrm{i}k_n x_i} \\right) \\left( \\frac{1}{N}\\sum_{j=1}^N e^{\\mathrm{i}k_n x_j} \\right) \\right] = \\frac{1}{N^2} \\sum_{i=1}^N \\sum_{j=1}^N \\mathbb{E}\\!\\left[ e^{-\\mathrm{i}k_n(x_i - x_j)} \\right]\n$$\nWe separate the double summation into diagonal terms where $i=j$ and off-diagonal terms where $i \\neq j$.\n\nFor the diagonal terms ($i=j$), we have $x_i - x_j = 0$, so $e^{-\\mathrm{i}k_n(x_i - x_j)} = e^0 = 1$. The expectation is $\\mathbb{E}[1] = 1$. There are $N$ such terms. Their contribution to the sum is $N$.\n\nFor the off-diagonal terms ($i \\neq j$), the positions $x_i$ and $x_j$ are independent random variables. Therefore, the expectation of the product is the product of the expectations:\n$$\n\\mathbb{E}\\!\\left[ e^{-\\mathrm{i}k_n(x_i - x_j)} \\right] = \\mathbb{E}\\!\\left[ e^{-\\mathrm{i}k_n x_i} \\right] \\mathbb{E}\\!\\left[ e^{\\mathrm{i}k_n x_j} \\right]\n$$\nFor a random variable $x$ uniformly distributed in $[0, L)$, the expectation of $e^{-\\mathrm{i}k_n x}$ is\n$$\n\\mathbb{E}\\!\\left[ e^{-\\mathrm{i}k_n x} \\right] = \\int_0^L \\frac{1}{L} e^{-\\mathrm{i}k_n x} dx = \\frac{1}{L} \\left[ \\frac{e^{-\\mathrm{i}k_n x}}{-\\mathrm{i}k_n} \\right]_0^L\n$$\nSubstituting $k_n = 2\\pi n / L$ and assuming $n \\neq 0$:\n$$\n\\mathbb{E}\\!\\left[ e^{-\\mathrm{i}k_n x} \\right] = \\frac{1}{L} \\frac{L}{-\\mathrm{i}2\\pi n} \\left( e^{-\\mathrm{i}2\\pi n} - e^0 \\right) = \\frac{1}{-\\mathrm{i}2\\pi n} (1 - 1) = 0\n$$\nSince $\\mathbb{E}[e^{\\mathrm{i}k_n x_j}]$ is also zero, the expectation for every off-diagonal term is $0$. There are $N^2 - N$ such terms.\n\nCombining the diagonal and off-diagonal contributions, the total sum is $N + 0 = N$. The expected power is:\n$$\n\\mathbb{E}\\!\\left[P_\\mathrm{meas}(n)\\right] = \\frac{1}{N^2} (N) = \\frac{1}{N}\n$$\nThis result is the well-known shot noise level for a Poisson distribution of particles.\n\n**2. Quiet Lattice Sampling**\n\nIn quiet lattice (or quiet start) sampling, particles are placed in a regular grid. The positions are deterministic:\n$$\nx_i = \\left(i - \\frac{1}{2}\\right)\\frac{L}{N} \\quad \\text{for } i \\in \\{1, 2, \\dots, N\\}\n$$\nThe complex amplitude $\\delta_k(n)$ is\n$$\n\\delta_k(n) = \\frac{1}{N} \\sum_{i=1}^N \\exp\\!\\left(-\\mathrm{i}k_n x_i\\right) = \\frac{1}{N} \\sum_{i=1}^N \\exp\\!\\left(-\\mathrm{i}\\frac{2\\pi n}{L} \\left(i - \\frac{1}{2}\\right)\\frac{L}{N}\\right) = \\frac{1}{N} \\sum_{i=1}^N \\exp\\!\\left(-\\mathrm{i}\\frac{2\\pi n}{N}\\left(i - \\frac{1}{2}\\right)\\right)\n$$\nWe can factor out a phase term:\n$$\n\\delta_k(n) = \\frac{1}{N} \\exp\\!\\left(\\mathrm{i}\\frac{\\pi n}{N}\\right) \\sum_{i=1}^N \\exp\\!\\left(-\\mathrm{i}\\frac{2\\pi n i}{N}\\right)\n$$\nThe sum is a geometric series. Let $r = \\exp(-\\mathrm{i} \\frac{2\\pi n}{N})$. The sum is $\\sum_{i=1}^N r^i = r + r^2 + \\dots + r^N = r \\frac{1-r^N}{1-r}$. The problem specifies the range $1 \\le n < N$, which ensures that $n$ is not a multiple of $N$. Therefore, $r \\neq 1$. The term $r^N$ is\n$$\nr^N = \\left(\\exp\\!\\left(-\\mathrm{i}\\frac{2\\pi n}{N}\\right)\\right)^N = \\exp(-\\mathrm{i} 2\\pi n) = 1\n$$\nsince $n$ is an integer. The numerator of the sum is $1 - r^N = 1 - 1 = 0$. Consequently, the entire sum is zero.\nThis implies that $\\delta_k(n) = 0$, and therefore the power is\n$$\nP_\\mathrm{meas}(n) = \\left|\\delta_k(n)\\right|^2 = 0\n$$\nfor all integer modes $n$ such that $1 \\le n < N$. This perfect cancellation is the reason this method is called a \"quiet\" start.\n\n**3. Jittered Lattice Sampling**\n\nJittered lattice sampling begins with a quiet lattice and adds small random displacements. The positions are\n$$\nx_i = x_{i,0} + \\varepsilon_i = \\left(i - \\frac{1}{2}\\right)\\frac{L}{N} + \\varepsilon_i\n$$\nwhere the $\\varepsilon_i$ are i.i.d. random variables drawn from a Gaussian distribution with mean $0$ and variance $\\sigma^2$. The analysis of the expected power follows the same initial steps as for Poisson sampling:\n$$\n\\mathbb{E}\\!\\left[P_\\mathrm{meas}(n)\\right] = \\frac{1}{N^2} \\sum_{i=1}^N \\sum_{j=1}^N \\mathbb{E}\\!\\left[ e^{-\\mathrm{i}k_n(x_i - x_j)} \\right]\n$$\nThe expectation term is $\\mathbb{E}\\!\\left[ e^{-\\mathrm{i}k_n(x_{i,0} - x_{j,0})} e^{-\\mathrm{i}k_n(\\varepsilon_i - \\varepsilon_j)} \\right] = e^{-\\mathrm{i}k_n(x_{i,0} - x_{j,0})} \\mathbb{E}\\!\\left[ e^{-\\mathrm{i}k_n(\\varepsilon_i - \\varepsilon_j)} \\right]$.\n\nFor the diagonal terms ($i=j$), $x_{i,0} - x_{j,0} = 0$ and $\\varepsilon_i - \\varepsilon_j = 0$. The term is $1$. There are $N$ such terms.\n\nFor the off-diagonal terms ($i \\neq j$), the displacements $\\varepsilon_i$ and $\\varepsilon_j$ are independent. Thus,\n$$\n\\mathbb{E}\\!\\left[ e^{-\\mathrm{i}k_n(\\varepsilon_i - \\varepsilon_j)} \\right] = \\mathbb{E}\\!\\left[ e^{-\\mathrm{i}k_n \\varepsilon_i} \\right] \\mathbb{E}\\!\\left[ e^{\\mathrm{i}k_n \\varepsilon_j} \\right]\n$$\nThe term $\\mathbb{E}[e^{-\\mathrm{i}k \\varepsilon}]$ is the definition of the characteristic function of the random variable $\\varepsilon$, denoted $\\phi(k)$. So, $\\mathbb{E}[e^{-\\mathrm{i}k_n \\varepsilon_i}] = \\phi(k_n)$ and $\\mathbb{E}[e^{\\mathrm{i}k_n \\varepsilon_j}] = \\phi(-k_n)$. For a real-valued probability distribution, $\\phi(-k) = \\phi^*(k)$, the complex conjugate. Thus, the product is $|\\phi(k_n)|^2$. The expectation for an off-diagonal term becomes $e^{-\\mathrm{i}k_n(x_{i,0} - x_{j,0})} |\\phi(k_n)|^2$.\n\nThe total expectation is:\n$$\n\\mathbb{E}\\!\\left[P_\\mathrm{meas}(n)\\right] = \\frac{1}{N^2} \\left( N + \\sum_{i \\neq j} e^{-\\mathrm{i}k_n(x_{i,0} - x_{j,0})} |\\phi(k_n)|^2 \\right)\n$$\nThe sum over $i \\neq j$ can be rewritten as:\n$$\n\\sum_{i \\neq j} (\\dots) = \\left( \\sum_{i,j} e^{-\\mathrm{i}k_n(x_{i,0} - x_{j,0})} \\right) - \\left( \\sum_{i=j} e^0 \\right) = \\left| \\sum_i e^{-\\mathrm{i}k_n x_{i,0}} \\right|^2 - N\n$$\nFrom the quiet lattice derivation, we know that for $1 \\le n < N$, the sum $\\sum_i e^{-\\mathrm{i}k_n x_{i,0}}$ is zero. Thus, the sum over $i \\neq j$ evaluates to $-N$.\nSubstituting this back, the off-diagonal contribution is $-N|\\phi(k_n)|^2$.\nThe total expected power is:\n$$\n\\mathbb{E}\\!\\left[P_\\mathrm{meas}(n)\\right] = \\frac{1}{N^2} \\left( N - N|\\phi(k_n)|^2 \\right) = \\frac{1}{N}\\left(1 - |\\phi(k_n)|^2\\right)\n$$\nFor a Gaussian displacement $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$, the characteristic function is $\\phi(k) = \\exp(-\\frac{1}{2}\\sigma^2 k^2)$. It is real, so $|\\phi(k_n)|^2 = \\left(\\exp(-\\frac{1}{2}\\sigma^2 k_n^2)\\right)^2 = \\exp(-\\sigma^2 k_n^2)$.\nThis yields the final expression:\n$$\n\\mathbb{E}\\!\\left[P_\\mathrm{meas}(n)\\right] = \\frac{1}{N}\\left(1 - \\exp(-\\sigma^2 k_n^2)\\right)\n$$\nThis derivation confirms the theoretical formulae provided in the problem statement. They form the basis for the subsequent numerical calculations.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes measured and theoretical power of density fluctuations\n    for different particle sampling strategies.\n    \"\"\"\n    test_cases = [\n        {'type': 'poisson', 'N': 1024, 'L': 1.0, 'n': 1, 'seed': 7},\n        {'type': 'quiet', 'N': 64, 'L': 1.0, 'n': 1},\n        {'type': 'jittered', 'N': 256, 'L': 1.0, 'n': 3, 'sigma': 0.01, 'seed': 123},\n        {'type': 'jittered', 'N': 64, 'L': 1.0, 'n': 31, 'sigma': 0.1, 'seed': 1},\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        N = case['N']\n        L = case['L']\n        n = case['n']\n        \n        # Calculate the wavenumber\n        k_n = 2 * np.pi * n / L\n\n        # Generate particle positions based on the sampling strategy\n        if case['type'] == 'poisson':\n            rng = np.random.default_rng(case['seed'])\n            x = L * rng.random(size=N)\n            p_theory = 1.0 / N\n        \n        elif case['type'] == 'quiet':\n            # Particle positions for quiet lattice sampling\n            # x_i = (i - 1/2) * L / N for i = 1, ..., N\n            i = np.arange(1, N + 1)\n            x = (i - 0.5) * L / N\n            p_theory = 0.0\n\n        elif case['type'] == 'jittered':\n            sigma = case['sigma']\n            rng = np.random.default_rng(case['seed'])\n            \n            # Base lattice positions\n            i = np.arange(1, N + 1)\n            x_lattice = (i - 0.5) * L / N\n            \n            # Add Gaussian displacements\n            displacements = rng.normal(loc=0.0, scale=sigma, size=N)\n            \n            # Final positions with periodic boundary conditions\n            x = (x_lattice + displacements) % L\n            \n            p_theory = (1.0 / N) * (1.0 - np.exp(-sigma**2 * k_n**2))\n\n        # Calculate the measured power\n        # delta_k(n) = 1/N * sum(exp(-i * k_n * x_i))\n        # The mean of the complex exponentials is equivalent to the normalized sum\n        delta_k = np.mean(np.exp(-1j * k_n * x))\n        p_meas = np.abs(delta_k)**2\n        \n        results.append(p_meas)\n        results.append(p_theory)\n\n    # Format the final output as a single comma-separated line in brackets\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Once a system of particles is initialized, its evolution is governed by integrating the equations of motion. Given the vast timescales in astrophysics, the long-term stability and accuracy of the chosen time integrator are paramount. This exercise delves into the heart of $N$-body dynamics by implementing and comparing two symplectic integrators: the standard second-order leapfrog and a higher fourth-order splitting method . By applying these methods to orbits in a static potential and measuring their energy error and phase-space volume preservation, you will develop a practical understanding of why symplectic maps are the foundation for robust gravitational simulations.",
            "id": "3518329",
            "problem": "You must implement and compare time integrators for a collisionless tracer in a static, isolated Hernquist halo potential. The system models a single phase-space point evolving under a fixed spherical potential and is a special case of collisionless dynamics as described by the Vlasov equation with a time-independent Poisson-solved field. The base model is Newtonian gravity, with Hamiltonian mechanics and canonical coordinates. Use the following foundational facts without shortcut formulas: \n- Newton's laws state that $d\\boldsymbol{r}/dt = \\boldsymbol{v}$ and $d\\boldsymbol{v}/dt = \\boldsymbol{a}(\\boldsymbol{r})$, where $\\boldsymbol{a}(\\boldsymbol{r})$ is the acceleration field. \n- For a time-independent potential $\\Phi(\\boldsymbol{r})$, the Hamiltonian for a unit-mass particle is $H = T + V = \\tfrac{1}{2}\\lvert \\boldsymbol{v} \\rvert^{2} + \\Phi(\\boldsymbol{r})$. \n- The Hernquist halo potential is $\\Phi(r) = -\\dfrac{G M}{r + a}$ with $r = \\lVert \\boldsymbol{r} \\rVert$; the force is $\\boldsymbol{F}(\\boldsymbol{r}) = -\\nabla \\Phi = -\\dfrac{G M}{(r + a)^{2}} \\dfrac{\\boldsymbol{r}}{r}$. \n- Symplectic splitting arises from decomposing the Hamiltonian flow into exact subflows generated by $T(\\boldsymbol{v})$ and $V(\\boldsymbol{r})$, which, when composed, produce symplectic maps.\n\nYour tasks:\n1. Implement a second-order leapfrog integrator using a kick-drift-kick composition. Derive and code the canonical updates implied by composing the exact flows of $T$ and $V$ over a step of size $h$.\n2. Implement a fourth-order symplectic splitting method obtained by composing second-order kick-drift-kick steps with appropriately chosen scalar coefficients that yield formal fourth-order accuracy. Derive the structure of the composition and justify the choice of coefficients that produce a fourth-order method.\n3. For each method, quantify the long-time energy error scaling by integrating an orbit for a total time $T$ at step sizes $h$ and $h/2$, computing the maximum absolute relative energy deviation over the trajectory with respect to the initial energy $E_{0}$, and reporting the ratio $\\max_{t \\in [0,T]} \\lvert E(t) - E_{0} \\rvert / \\lvert E_{0} \\rvert$ at $h$ divided by the same quantity at $h/2$.\n4. Assess phase-space volume preservation by approximating the Jacobian determinant of the one-step map at the initial condition using finite differences on the six-dimensional $(\\boldsymbol{r}, \\boldsymbol{v})$ space, and reporting the absolute deviation $\\lvert \\det(J) - 1 \\rvert$. Use a sufficiently small perturbation size to capture the local linearization.\n\nUse dimensionless units with $G = 1$, $M = 1$, $a = 1$, and unit mass $m = 1$. Positions are in units of $a$, times are in units of $(a^{3}/G M)^{1/2}$, and velocities are in units of $(G M / a)^{1/2}$. Express all outputs as dimensionless floats.\n\nTest suite:\n- Case $1$ (near-circular orbit at large radius): $\\boldsymbol{r}_{0} = (5, 0, 0)$, $\\boldsymbol{v}_{0} = (0, v_{\\mathrm{circ}}(5), 0)$ where $v_{\\mathrm{circ}}(r) = \\sqrt{ r \\, \\dfrac{G M}{(r + a)^{2}} }$; use $h = 0.02$ and $T = 200$.\n- Case $2$ (radial orbit below escape): $\\boldsymbol{r}_{0} = (2, 0, 0)$, $\\boldsymbol{v}_{0} = (0.5 \\, v_{\\mathrm{esc}}(2), 0, 0)$ where $v_{\\mathrm{esc}}(r) = \\sqrt{ \\dfrac{2 G M}{r + a} }$; use $h = 0.02$ and $T = 200$.\n- Case $3$ (low-angular-momentum center-crossing): $\\boldsymbol{r}_{0} = (0.5, 0, 0)$, $\\boldsymbol{v}_{0} = (-0.2 \\, v_{\\mathrm{circ}}(0.5), 0.2 \\, v_{\\mathrm{circ}}(0.5), 0)$; use $h = 0.02$ and $T = 200$.\n\nFor each case, compute:\n- The energy-error scaling ratio for leapfrog: $\\mathsf{ratio}_{\\mathrm{LF}} = \\dfrac{\\max_{t} \\lvert E_{h}(t) - E_{0} \\rvert / \\lvert E_{0} \\rvert}{\\max_{t} \\lvert E_{h/2}(t) - E_{0} \\rvert / \\lvert E_{0} \\rvert}$.\n- The energy-error scaling ratio for the fourth-order method: $\\mathsf{ratio}_{\\mathrm{S4}}$ defined analogously.\n- The phase-space volume deviation for leapfrog: $\\delta_{\\mathrm{vol, LF}} = \\lvert \\det(J_{\\mathrm{LF}}) - 1 \\rvert$ at one step of size $h$.\n- The phase-space volume deviation for the fourth-order method: $\\delta_{\\mathrm{vol, S4}} = \\lvert \\det(J_{\\mathrm{S4}}) - 1 \\rvert$ at one step of size $h$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the following order for cases $1$, $2$, and $3$: \n$[\\mathsf{ratio}_{\\mathrm{LF},1}, \\mathsf{ratio}_{\\mathrm{S4},1}, \\delta_{\\mathrm{vol, LF},1}, \\delta_{\\mathrm{vol, S4},1}, \\mathsf{ratio}_{\\mathrm{LF},2}, \\mathsf{ratio}_{\\mathrm{S4},2}, \\delta_{\\mathrm{vol, LF},2}, \\delta_{\\mathrm{vol, S4},2}, \\mathsf{ratio}_{\\mathrm{LF},3}, \\mathsf{ratio}_{\\mathrm{S4},3}, \\delta_{\\mathrm{vol, LF},3}, \\delta_{\\mathrm{vol, S4},3}]$.\nAll quantities are floats.\n\nAngles are not required; do not output any angles. There are no physical units to print because all quantities are specified as dimensionless. The answers are numerical floats only. The test suite is self-sufficient and covers a near-circular orbit, a radial orbit, and a low-angular-momentum orbit passing near the center, probing accuracy and volume preservation across qualitatively distinct dynamical regimes.",
            "solution": "The problem requires the implementation and comparison of two symplectic integrators—a second-order leapfrog method and a fourth-order splitting method—for a tracer particle in a static Hernquist potential. The analysis involves quantifying the energy conservation error and the preservation of phase-space volume for several distinct orbits.\n\nThe system is governed by a time-independent Hamiltonian for a particle of unit mass ($m=1$):\n$$\nH(\\boldsymbol{r}, \\boldsymbol{v}) = T(\\boldsymbol{v}) + V(\\boldsymbol{r}) = \\frac{1}{2} |\\boldsymbol{v}|^2 + \\Phi(\\boldsymbol{r})\n$$\nwhere $\\boldsymbol{r}$ is the position vector, $\\boldsymbol{v}$ is the velocity vector, and $\\Phi(\\boldsymbol{r})$ is the gravitational potential. The Hernquist potential is given by:\n$$\n\\Phi(r) = -\\frac{G M}{r + a}\n$$\nwhere $r = \\lVert \\boldsymbol{r} \\rVert$ is the radial distance. In the specified dimensionless units, $G=1$, $M=1$, and $a=1$, so the potential simplifies to $\\Phi(r) = -1/(r+1)$. The equations of motion are Hamilton's equations:\n$$\n\\frac{d\\boldsymbol{r}}{dt} = \\frac{\\partial H}{\\partial \\boldsymbol{v}} = \\boldsymbol{v}\n$$\n$$\n\\frac{d\\boldsymbol{v}}{dt} = -\\frac{\\partial H}{\\partial \\boldsymbol{r}} = -\\nabla\\Phi(\\boldsymbol{r})\n$$\nThe acceleration, $\\boldsymbol{a}(\\boldsymbol{r}) = -\\nabla\\Phi(\\boldsymbol{r})$, is computed from the potential:\n$$\n\\boldsymbol{a}(\\boldsymbol{r}) = -\\frac{d\\Phi}{dr} \\frac{\\boldsymbol{r}}{r} = -\\left( \\frac{d}{dr} \\left(-\\frac{1}{r+1}\\right) \\right) \\frac{\\boldsymbol{r}}{r} = -\\frac{1}{(r+1)^2} \\frac{\\boldsymbol{r}}{r}\n$$\n\nThe formal solution to the equations of motion advances the state vector $\\boldsymbol{z} = (\\boldsymbol{r}, \\boldsymbol{v})$ over a time step $h$ via the exponential of the Lie operator $\\mathcal{L}_H = \\{\\cdot, H\\}$: $\\boldsymbol{z}(t+h) = \\exp(h \\mathcal{L}_H) \\boldsymbol{z}(t)$. Symplectic integrators are constructed by splitting this operator using the Baker-Campbell-Hausdorff (BCH) formula. We split the Hamiltonian into its kinetic, $T$, and potential, $V$, parts. The operator becomes $\\mathcal{L}_H = \\mathcal{L}_T + \\mathcal{L}_V$. The evolution under each part is simple to solve exactly:\n$1$. The flow generated by $T(\\boldsymbol{v})$ for a time $h$, denoted $\\exp(h\\mathcal{L}_T)$, corresponds to $\\dot{\\boldsymbol{r}} = \\boldsymbol{v}$ and $\\dot{\\boldsymbol{v}} = 0$. The exact solution is a \"drift\":\n$$\n\\boldsymbol{r}(t+h) = \\boldsymbol{r}(t) + h \\boldsymbol{v}(t), \\quad \\boldsymbol{v}(t+h) = \\boldsymbol{v}(t)\n$$\n$2$. The flow generated by $V(\\boldsymbol{r})$ for a time $h$, denoted $\\exp(h\\mathcal{L}_V)$, corresponds to $\\dot{\\boldsymbol{r}} = 0$ and $\\dot{\\boldsymbol{v}} = \\boldsymbol{a}(\\boldsymbol{r})$. The exact solution is a \"kick\":\n$$\n\\boldsymbol{r}(t+h) = \\boldsymbol{r}(t), \\quad \\boldsymbol{v}(t+h) = \\boldsymbol{v}(t) + h \\boldsymbol{a}(\\boldsymbol{r}(t))\n$$\nBy composing these exact elementary flows, we construct symplectic numerical integrators.\n\n**$1$. Second-Order Leapfrog (Kick-Drift-Kick) Integrator**\nThe second-order leapfrog method can be derived from Strang splitting. A symmetric composition of the drift and kick operators results in a second-order accurate map. The kick-drift-kick (KDK) formulation is given by:\n$$\n\\mathcal{M}_{\\mathrm{LF}}(h) = \\exp\\left(\\frac{h}{2} \\mathcal{L}_V\\right) \\exp\\left(h \\mathcal{L}_T\\right) \\exp\\left(\\frac{h}{2} \\mathcal{L}_V\\right)\n$$\nApplying this sequence of operators to the state $(\\boldsymbol{r}_n, \\boldsymbol{v}_n)$ at time $t_n$ to find the state at $t_{n+1} = t_n+h$ yields the following algorithmic steps:\n$1$. **First Kick (half-step)**: Apply $\\exp(\\frac{h}{2}\\mathcal{L}_V)$. This updates the velocity using the acceleration at the current position. A temporary velocity $\\boldsymbol{v}_{n+1/2}$ is computed.\n$$\n\\boldsymbol{v}_{n+1/2} = \\boldsymbol{v}_n + \\frac{h}{2} \\boldsymbol{a}(\\boldsymbol{r}_n)\n$$\n$2$. **Drift (full-step)**: Apply $\\exp(h\\mathcal{L}_T)$. This updates the position using the new intermediate velocity.\n$$\n\\boldsymbol{r}_{n+1} = \\boldsymbol{r}_n + h \\boldsymbol{v}_{n+1/2}\n$$\n$3$. **Second Kick (half-step)**: Apply $\\exp(\\frac{h}{2}\\mathcal{L}_V)$. This completes the velocity update using the acceleration at the new position $\\boldsymbol{r}_{n+1}$.\n$$\n\\boldsymbol{v}_{n+1} = \\boldsymbol{v}_{n+1/2} + \\frac{h}{2} \\boldsymbol{a}(\\boldsymbol{r}_{n+1})\n$$\nThis scheme is symmetric, explicit, and second-order accurate, meaning its local truncation error is $\\mathcal{O}(h^3)$.\n\n**$2$. Fourth-Order Symplectic Integrator**\nHigher-order symplectic integrators can be constructed by composing a symmetric second-order method. Let $S_2(h)$ denote the second-order leapfrog map for a step of size $h$. A fourth-order symmetric method, $S_4(h)$, can be constructed as a composition of three second-order steps with specific time steps:\n$$\nS_4(h) = S_2(c_1 h) S_2(c_2 h) S_2(c_1 h)\n$$\nFor the resulting method to be fourth-order accurate, the coefficients $c_1$ and $c_2$ must satisfy a system of equations derived from the BCH expansion. For a symmetric composition, the conditions are:\n$$\n2c_1 + c_2 = 1 \\quad \\text{and} \\quad 2c_1^3 + c_2^3 = 0\n$$\nThe first condition ensures the total time step is $h$. The second condition cancels the third-order error term of the composed map. Solving this system yields:\n$$\nc_1 = \\frac{1}{2 - 2^{1/3}}, \\quad c_2 = \\frac{-2^{1/3}}{2 - 2^{1/3}}\n$$\nAn algorithm for a single fourth-order step of size $h$ is thus to apply the second-order leapfrog step three times in succession with time steps $c_1 h$, $c_2 h$, and $c_1 h$, respectively. This method has a local truncation error of $\\mathcal{O}(h^5)$.\n\n**$3$. Energy Error Scaling**\nFor a Hamiltonian system, energy is an integral of motion. While symplectic integrators do not exactly conserve the true Hamiltonian $H$, they exactly conserve a nearby \"shadow\" Hamiltonian $H'$. This leads to long-term stability and bounded energy fluctuations, rather than secular drift. The global error in energy for an integrator of order $p$ over a fixed time interval $T$ is expected to scale as $\\mathcal{O}(h^p)$. We can verify this numerically. The maximum absolute relative energy error is defined as $\\epsilon_{\\max}(h) = \\max_{t \\in [0,T]} \\lvert E(t) - E_0 \\rvert / \\lvert E_0 \\rvert$. The ratio of this error computed with step sizes $h$ and $h/2$ should be:\n$$\n\\mathsf{ratio} = \\frac{\\epsilon_{\\max}(h)}{\\epsilon_{\\max}(h/2)} \\approx \\frac{C h^p}{C (h/2)^p} = 2^p\n$$\nFor the second-order leapfrog ($p=2$), we expect $\\mathsf{ratio}_{\\mathrm{LF}} \\approx 2^2 = 4$. For the fourth-order method ($p=4$), we expect $\\mathsf{ratio}_{\\mathrm{S4}} \\approx 2^4 = 16$.\n\n**$4$. Phase-Space Volume Preservation**\nLiouville's theorem states that the flow of a Hamiltonian system preserves the volume element in phase space. This means that if we consider a region of initial conditions, its volume remains constant as it evolves in time. This property is mathematically equivalent to the statement that the Jacobian of the flow map has a determinant of unity.\nA numerical integrator is symplectic if and only if the Jacobian of its one-step map $\\mathcal{M}: \\boldsymbol{z}_n \\mapsto \\boldsymbol{z}_{n+1}$ has a determinant of $1$, i.e., $\\det(J) = \\det(\\partial \\boldsymbol{z}_{n+1} / \\partial \\boldsymbol{z}_n) = 1$. The integrators constructed by splitting the Hamiltonian are symplectic by construction. We verify this numerically by computing the Jacobian matrix $J$ for a single step map using central differences on the six-dimensional phase-space vector $\\boldsymbol{z} = (r_x, r_y, r_z, v_x, v_y, v_z)$. The $j$-th column of $J$ is approximated by $(\\mathcal{M}(\\boldsymbol{z}_0 + \\delta \\boldsymbol{e}_j) - \\mathcal{M}(\\boldsymbol{z}_0 - \\delta \\boldsymbol{e}_j)) / (2\\delta)$, where $\\boldsymbol{e}_j$ is the $j$-th standard basis vector and $\\delta$ is a small perturbation. The quantity of interest is the deviation $\\delta_{\\mathrm{vol}} = |\\det(J) - 1|$, which should be on the order of machine floating-point precision for a correct implementation.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and compares second-order and fourth-order symplectic integrators\n    for orbital motion in a Hernquist potential.\n    \"\"\"\n\n    # Dimensionless constants\n    G_const = 1.0\n    M_const = 1.0\n    a_const = 1.0\n\n    # Fourth-order integrator coefficients (Yoshida 1990)\n    cbrt_2 = 2**(1/3)\n    c1 = 1.0 / (2.0 - cbrt_2)\n    c2 = -cbrt_2 / (2.0 - cbrt_2)\n    S4_COEFFS = [c1, c2, c1]\n\n    def acceleration(r_vec):\n        \"\"\"Computes acceleration for a Hernquist potential.\"\"\"\n        r_mag = np.linalg.norm(r_vec)\n        if r_mag == 0.0:\n            return np.zeros(3)\n        # a(r) = - (GM / (r+a)^2) * (r_vec / r)\n        magnitude = - (G_const * M_const) / (r_mag + a_const)**2\n        return magnitude * (r_vec / r_mag)\n\n    def energy(r_vec, v_vec):\n        \"\"\"Computes specific energy for a Hernquist potential.\"\"\"\n        r_mag = np.linalg.norm(r_vec)\n        # H = 0.5*|v|^2 - GM/(r+a)\n        kinetic = 0.5 * np.dot(v_vec, v_vec)\n        potential = - (G_const * M_const) / (r_mag + a_const)\n        return kinetic + potential\n\n    def leapfrog_step(r, v, h):\n        \"\"\"Performs one step of the KDK leapfrog integrator.\"\"\"\n        v_half = v + 0.5 * h * acceleration(r)\n        r_new = r + h * v_half\n        v_new = v_half + 0.5 * h * acceleration(r_new)\n        return r_new, v_new\n\n    def s4_step(r, v, h):\n        \"\"\"Performs one step of the 4th-order symplectic integrator.\"\"\"\n        r_curr, v_curr = r, v\n        for coeff in S4_COEFFS:\n            r_curr, v_curr = leapfrog_step(r_curr, v_curr, h * coeff)\n        return r_curr, v_curr\n\n    def compute_energy_error_max(integrator, r0, v0, h, T):\n        \"\"\"Integrates an orbit and returns the max relative energy error.\"\"\"\n        n_steps = int(round(T / h))\n        r, v = r0.copy(), v0.copy()\n        \n        e0 = energy(r0, v0)\n        \n        max_err = 0.0\n        for _ in range(n_steps):\n            r, v = integrator(r, v, h)\n            e_t = energy(r, v)\n            err = abs((e_t - e0) / e0)\n            if err > max_err:\n                max_err = err\n        return max_err\n\n    def compute_volume_deviation(integrator, r0, v0, h):\n        \"\"\"Computes |det(J) - 1| for the one-step map using finite differences.\"\"\"\n        dim = 6\n        J = np.zeros((dim, dim))\n        z0 = np.concatenate((r0, v0))\n        eps = 1e-8\n\n        # Central difference for Jacobian columns\n        for j in range(dim):\n            z_plus = z0.copy()\n            z_plus[j] += eps\n            \n            z_minus = z0.copy()\n            z_minus[j] -= eps\n\n            r_p, v_p = integrator(z_plus[:3], z_plus[3:], h)\n            z1_p = np.concatenate((r_p, v_p))\n\n            r_m, v_m = integrator(z_minus[:3], z_minus[3:], h)\n            z1_m = np.concatenate((r_m, v_m))\n            \n            J[:, j] = (z1_p - z1_m) / (2 * eps)\n            \n        det_J = np.linalg.det(J)\n        return abs(det_J - 1.0)\n\n\n    # Case 1: Near-circular orbit\n    r1 = 5.0\n    v_circ1 = np.sqrt(r1 * G_const * M_const / (r1 + a_const)**2)\n    r0_1 = np.array([r1, 0.0, 0.0])\n    v0_1 = np.array([0.0, v_circ1, 0.0])\n\n    # Case 2: Radial orbit\n    r2 = 2.0\n    v_esc2 = np.sqrt(2 * G_const * M_const / (r2 + a_const))\n    r0_2 = np.array([r2, 0.0, 0.0])\n    v0_2 = np.array([0.5 * v_esc2, 0.0, 0.0])\n\n    # Case 3: Low-angular-momentum orbit\n    r3 = 0.5\n    v_circ3 = np.sqrt(r3 * G_const * M_const / (r3 + a_const)**2)\n    r0_3 = np.array([r3, 0.0, 0.0])\n    v0_3 = np.array([-0.2 * v_circ3, 0.2 * v_circ3, 0.0])\n\n    test_cases = [\n        (r0_1, v0_1),\n        (r0_2, v0_2),\n        (r0_3, v0_3)\n    ]\n    \n    h = 0.02\n    T = 200.0\n\n    results = []\n    \n    for r0, v0 in test_cases:\n        # Leapfrog analysis\n        e_err_lf_h = compute_energy_error_max(leapfrog_step, r0, v0, h, T)\n        e_err_lf_h2 = compute_energy_error_max(leapfrog_step, r0, v0, h/2, T)\n        ratio_lf = e_err_lf_h / e_err_lf_h2 if e_err_lf_h2 > 0 else 0.0\n        \n        vol_dev_lf = compute_volume_deviation(leapfrog_step, r0, v0, h)\n        \n        # S4 analysis\n        e_err_s4_h = compute_energy_error_max(s4_step, r0, v0, h, T)\n        e_err_s4_h2 = compute_energy_error_max(s4_step, r0, v0, h/2, T)\n        ratio_s4 = e_err_s4_h / e_err_s4_h2 if e_err_s4_h2 > 0 else 0.0\n        \n        vol_dev_s4 = compute_volume_deviation(s4_step, r0, v0, h)\n\n        results.extend([ratio_lf, ratio_s4, vol_dev_lf, vol_dev_s4])\n        \n    print(f\"[{','.join(f'{x:.8f}' for x in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Calculating the gravitational force is the most computationally expensive part of an $N$-body simulation, as the direct summation of pairwise forces scales as $O(N^2)$. The Particle-Mesh (PM) method provides an efficient $O(N \\ln N)$ alternative by solving the Poisson equation on a grid using Fast Fourier Transforms. In this practice, you will implement a PM solver and investigate a critical aspect of its design: the choice of boundary conditions . By contrasting a solver for isolated systems with one assuming periodic boundary conditions, you will directly quantify the spurious forces from periodic images and learn to critically assess the domain of validity for simulations of cosmic structure.",
            "id": "3518246",
            "problem": "You are to implement and compare two Particle-Mesh (PM) gravitational solvers for a collisionless system, differing only in boundary conditions: periodic boundaries using a Fourier-space solution equivalent to Ewald summation, and isolated boundaries using a zero-padded convolution with a softened Green function. The purpose is to quantify spurious image forces that can affect a halo located near the box edges relative to the isolated free-space solution.\n\nStart from the Vlasov-Poisson description of collisionless dynamics. The phase-space distribution function $f(\\boldsymbol{x},\\boldsymbol{v},t)$ evolves according to the collisionless Boltzmann equation (also called the Vlasov equation) and the gravitational potential $\\phi(\\boldsymbol{x},t)$ solves the Poisson equation. In a PM solver, mass density $\\rho(\\boldsymbol{x})$ is discretized on a mesh and the potential $\\phi(\\boldsymbol{x})$ is obtained by solving the Poisson equation. You will implement:\n- A periodic Fourier-space solver that sets the zero-frequency mode to zero (background-subtracted), which is mathematically equivalent to an Ewald-summation treatment of the long-range potential for periodic images.\n- An isolated solver that computes the free-space potential by convolving the density with a softened Green function via zero-padding and Fast Fourier Transform (FFT).\n\nThe density field represents a single Plummer halo:\n- The mass density is given by the Plummer profile $\\,\\rho(\\boldsymbol{x}) = \\dfrac{3 M}{4 \\pi a^3} \\left(1 + \\dfrac{|\\boldsymbol{x}-\\boldsymbol{x}_0|^2}{a^2}\\right)^{-5/2}\\,$, where $M$ is the halo mass, $a$ is the Plummer scale, and $\\boldsymbol{x}_0$ is the halo center.\n- The box is a cube of side length $L$ with a uniform Cartesian mesh of $N \\times N \\times N$ cells at cell-center positions.\n\nDefinitions and constraints:\n- Use gravitational constant $G = 1$.\n- Use side length $L = 1$.\n- Use grid size $N = 48$.\n- Use halo mass $M = 1$.\n- Use Plummer scale $a = 0.05$.\n- Use Green-function softening length $\\epsilon = 2 \\Delta x$, where $\\Delta x = L/N$ is the grid spacing.\n- In the periodic solver, solve the Poisson equation in Fourier space with wavevectors $\\boldsymbol{k} = (k_x,k_y,k_z)$ using $\\phi_{\\boldsymbol{k}} = - 4 \\pi G \\,\\rho_{\\boldsymbol{k}} / |\\boldsymbol{k}|^2$ for $|\\boldsymbol{k}| \\neq 0$ and set $\\phi_{\\boldsymbol{0}} = 0$. Compute acceleration in Fourier space as $\\boldsymbol{a}_{\\boldsymbol{k}} = - i \\boldsymbol{k} \\,\\phi_{\\boldsymbol{k}}$ and inverse transform to real space.\n- In the isolated solver, construct the softened Green function on a zero-padded grid of size $(2N)^3$ by $\\,g(\\boldsymbol{r}) = - \\dfrac{G}{\\sqrt{|\\boldsymbol{r}|^2 + \\epsilon^2}}\\,,$ with the discrete grid coordinates covering $[-N,N)$ cells per axis, and compute $\\,\\phi(\\boldsymbol{x}) \\approx (\\rho \\star g)(\\boldsymbol{x}) \\,\\Delta x^3\\,$ via cyclic convolution on the padded grid using FFT, then extract the potential on the original $N^3$ domain. Compute acceleration by finite differences as $\\boldsymbol{a}(\\boldsymbol{x}) = - \\nabla \\phi(\\boldsymbol{x})$.\n\nError metric to assess spurious image forces:\n- For a massless tracer located at position $\\boldsymbol{x}_{\\mathrm{t}}$, define the isolated acceleration $\\boldsymbol{a}_{\\mathrm{iso}}$ and periodic acceleration $\\boldsymbol{a}_{\\mathrm{per}}$ obtained by trilinear interpolation from the respective acceleration grids.\n- Define the fractional spurious image force as $\\,\\delta = \\dfrac{\\left\\|\\boldsymbol{a}_{\\mathrm{per}} - \\boldsymbol{a}_{\\mathrm{iso}}\\right\\|}{\\left\\|\\boldsymbol{a}_{\\mathrm{iso}}\\right\\|}\\,$.\n\nImplement the following test suite of three cases, each specifying the halo center $\\boldsymbol{x}_0$ and tracer offset $\\boldsymbol{d}$ relative to the halo center, with all coordinates in the box domain. Choose offsets to keep the tracer inside the box:\n- Case $1$ (happy path, halo at box center): $\\boldsymbol{x}_0 = (0.5, 0.5, 0.5)$, $\\boldsymbol{d} = (0.05, 0, 0)$, so $\\boldsymbol{x}_{\\mathrm{t}} = \\boldsymbol{x}_0 + \\boldsymbol{d}$.\n- Case $2$ (halo near a face): $\\boldsymbol{x}_0 = (0.9, 0.5, 0.5)$, $\\boldsymbol{d} = (-0.05, 0, 0)$, so $\\boldsymbol{x}_{\\mathrm{t}} = \\boldsymbol{x}_0 + \\boldsymbol{d}$.\n- Case $3$ (halo near a corner): $\\boldsymbol{x}_0 = (0.95, 0.95, 0.95)$, $\\boldsymbol{d} = (-0.03, -0.03, -0.03)$, so $\\boldsymbol{x}_{\\mathrm{t}} = \\boldsymbol{x}_0 + \\boldsymbol{d}$.\n\nAlgorithmic requirements:\n- Construct the density field on cell centers.\n- For the periodic solver, compute $\\phi_{\\boldsymbol{k}}$ and $\\boldsymbol{a}$ spectrally, applying the zero-mode removal and the appropriate wave number grid.\n- For the isolated solver, compute the padded Green function and perform FFT-based convolution with softening $\\epsilon$, scale by $\\Delta x^3$, extract the potential on the original domain, and compute $\\boldsymbol{a}$ by finite differences.\n- Interpolate the acceleration at $\\boldsymbol{x}_{\\mathrm{t}}$ using trilinear interpolation for both solvers (periodic wrapping for the periodic case; clamping inside the domain for the isolated case).\n\nYour program must output the fractional spurious image force $\\delta$ for each case as real numbers. Because all quantities are dimensionless ($G=L=M=1$), there are no physical units to report.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the three cases, for example $[\\delta_1,\\delta_2,\\delta_3]$.",
            "solution": "The problem is valid as it presents a well-posed, scientifically grounded task in computational astrophysics. All parameters, equations, and algorithms are specified with sufficient clarity to permit a unique and verifiable solution.\n\nThe problem requires a comparison of two Particle-Mesh (PM) solvers for the gravitational potential and acceleration of a single Plummer halo. The core of the PM method lies in solving the Poisson equation, $\\nabla^2\\phi = 4\\pi G \\rho$, on a discrete grid. The two solvers differ in their treatment of boundary conditions, which fundamentally alters the solution method.\n\nFirst, we discretize the mass density of the Plummer halo onto a uniform Cartesian grid. The simulation box has a side length $L=1$ and is divided into $N^3 = 48^3$ cells. The grid spacing is $\\Delta x = L/N$. The mass density $\\rho(\\boldsymbol{x})$ for the Plummer profile, $\\rho(\\boldsymbol{x}) = \\frac{3M}{4\\pi a^2}\\left(1 + \\frac{|\\boldsymbol{x}-\\boldsymbol{x}_0|^2}{a^2}\\right)^{-5/2}$, is evaluated at the center of each grid cell $\\boldsymbol{x}_{ijk}$. Here, $M=1$ is the halo mass and $a=0.05$ is its scale length.\n\n**1. Periodic Boundary Conditions Solver**\n\nThis solver assumes the simulation box is periodically replicated throughout space. This assumption allows for an efficient solution of the Poisson equation using the Fast Fourier Transform (FFT). The Fourier transform of the Poisson equation is algebraic:\n$$\n(-|\\boldsymbol{k}|^2) \\phi_{\\boldsymbol{k}} = 4\\pi G \\rho_{\\boldsymbol{k}} \\implies \\phi_{\\boldsymbol{k}} = -\\frac{4\\pi G \\rho_{\\boldsymbol{k}}}{|\\boldsymbol{k}|^2}\n$$\nwhere $\\phi_{\\boldsymbol{k}}$ and $\\rho_{\\boldsymbol{k}}$ are the Fourier coefficients of the potential and density, respectively, and $\\boldsymbol{k}$ is the wavevector. The discrete wavevectors are given by $\\boldsymbol{k} = (k_x, k_y, k_z)$, where $k_i = 2\\pi n_i/L$ for integers $n_i \\in [-N/2, N/2-1]$.\n\nThe $|\\boldsymbol{k}|^2=0$ (zero-frequency or DC) mode corresponds to the mean potential and requires special handling. As specified, we set $\\phi_{\\boldsymbol{k}=\\boldsymbol{0}} = 0$, which is equivalent to subtracting the mean density of the universe and ensuring the net gravitational force on the box is zero. This treatment is mathematically equivalent to an Ewald summation for the potential from all periodic images.\n\nThe acceleration, $\\boldsymbol{a} = -\\nabla\\phi$, is also computed spectrally. The gradient operator in Fourier space corresponds to multiplication by $i\\boldsymbol{k}$. Thus, the Fourier transform of the acceleration is:\n$$\n\\boldsymbol{a}_{\\boldsymbol{k}} = -i\\boldsymbol{k} \\phi_{\\boldsymbol{k}}\n$$\nThe acceleration field $\\boldsymbol{a}_{\\mathrm{per}}(\\boldsymbol{x})$ is then obtained by applying an inverse FFT to $\\boldsymbol{a}_{\\boldsymbol{k}}$.\n\n**2. Isolated Boundary Conditions Solver**\n\nThis solver computes the free-space potential, treating the halo as an isolated object in an infinite, empty universe. The solution to the Poisson equation in this case is given by the convolution integral:\n$$\n\\phi(\\boldsymbol{x}) = \\int \\rho(\\boldsymbol{x}') g(\\boldsymbol{x} - \\boldsymbol{x}') d^3\\boldsymbol{x}' \\approx \\sum_j \\rho(\\boldsymbol{x}_j) g(\\boldsymbol{x} - \\boldsymbol{x}_j) (\\Delta x)^3\n$$\nwhere $g(\\boldsymbol{r})$ is the Green's function for the potential. To avoid singularities at $\\boldsymbol{r}=0$, a softened Green's function is used:\n$$\ng(\\boldsymbol{r}) = -\\frac{G}{\\sqrt{|\\boldsymbol{r}|^2 + \\epsilon^2}}\n$$\nwith a softening length $\\epsilon = 2\\Delta x$.\n\nThe convolution is computed efficiently using FFTs via the convolution theorem: $\\mathcal{F}\\{\\rho \\star g\\} = \\mathcal{F}\\{\\rho\\} \\cdot \\mathcal{F}\\{g\\}$. To prevent the FFT from computing a cyclic convolution (which would reintroduce periodic artifacts), the density field is zero-padded. The $N^3$ density grid is placed in the corner of a larger $(2N)^3$ grid filled with zeros. The Green's function is also constructed on this larger grid, respecting the wrap-around indexing required for FFT-based convolution. After performing the inverse FFT of the product of the transformed fields, the result is scaled by the cell volume $(\\Delta x)^3$ to approximate the integral. The potential field $\\phi_{\\mathrm{iso}}(\\boldsymbol{x})$ is then extracted from the padded grid, taking the $N^3$ subgrid corresponding to the original simulation domain.\n\nThe acceleration field $\\boldsymbol{a}_{\\mathrm{iso}}(\\boldsymbol{x})$ is then computed by taking the numerical gradient of the potential field, $\\boldsymbol{a} = -\\nabla\\phi$, using a finite-difference scheme.\n\n**3. Error Metric Calculation**\n\nFor each test case, the acceleration vectors $\\boldsymbol{a}_{\\mathrm{per}}$ and $\\boldsymbol{a}_{\\mathrm{iso}}$ must be evaluated at the specific tracer position $\\boldsymbol{x}_{\\mathrm{t}}$. Since $\\boldsymbol{x}_{\\mathrm{t}}$ does not typically coincide with a grid point, trilinear interpolation is used to estimate the acceleration from the values at the $8$ corners of the enclosing grid cell. For the periodic solver, the interpolation handles boundary-crossing by wrapping around the grid indices. For the isolated solver, indices are clamped to remain within the grid domain $[0, N-1]$.\n\nThe fractional spurious image force, $\\delta$, is then calculated as the ratio of the magnitude of the difference between the two acceleration vectors to the magnitude of the more physically accurate isolated acceleration:\n$$\n\\delta = \\frac{\\|\\boldsymbol{a}_{\\mathrm{per}}(\\boldsymbol{x}_{\\mathrm{t}}) - \\boldsymbol{a}_{\\mathrm{iso}}(\\boldsymbol{x}_{\\mathrm{t}})\\|}{\\|\\boldsymbol{a}_{\\mathrm{iso}}(\\boldsymbol{x}_{\\mathrm{t}})\\|}\n$$\nThis metric quantifies the relative error introduced by the periodic boundary assumption, which is expected to be larger when the halo is closer to the box boundaries.",
            "answer": "```python\nimport numpy as np\n\ndef trilinear_interp(field, pos, box_L, periodic=False):\n    \"\"\"\n    Performs trilinear interpolation on a 3D vector field.\n\n    Args:\n        field (np.ndarray): The (N, N, N, 3) vector field on the grid.\n        pos (np.ndarray): The (3,) position vector to interpolate at.\n        box_L (float): The side length of the simulation box.\n        periodic (bool): If True, use periodic boundary conditions.\n    \n    Returns:\n        np.ndarray: The interpolated (3,) vector.\n    \"\"\"\n    N = field.shape[0]\n    dx = box_L / N\n    \n    # Position in grid units, relative to cell centers\n    # A point at position p is at grid coordinate (p/dx - 0.5)\n    # relative to the grid node indices.\n    grid_coord = pos / dx - 0.5\n    \n    # Get lower-left corner index and fractional distance\n    ijk = np.floor(grid_coord).astype(int)\n    t = grid_coord - ijk\n    tx, ty, tz = t\n\n    # Get integer indices of 8 corners\n    i0, j0, k0 = ijk\n    i1, j1, k1 = ijk + 1\n    \n    # Boundary handling\n    if periodic:\n        i0, i1 = i0 % N, i1 % N\n        j0, j1 = j0 % N, j1 % N\n        k0, k1 = k0 % N, k1 % N\n    else: # Clamping\n        i0, i1 = np.clip([i0, i1], 0, N - 1)\n        j0, j1 = np.clip([j0, j1], 0, N - 1)\n        k0, k1 = np.clip([k0, k1], 0, N - 1)\n    \n    # Get field values at the 8 corners\n    v000 = field[i0, j0, k0, :]\n    v100 = field[i1, j0, k0, :]\n    v010 = field[i0, j1, k0, :]\n    v001 = field[i0, j0, k1, :]\n    v110 = field[i1, j1, k0, :]\n    v101 = field[i1, j0, k1, :]\n    v011 = field[i0, j1, k1, :]\n    v111 = field[i1, j1, k1, :]\n\n    # Interpolate along x\n    v_00 = v000 * (1 - tx) + v100 * tx\n    v_10 = v010 * (1 - tx) + v110 * tx\n    v_01 = v001 * (1 - tx) + v101 * tx\n    v_11 = v011 * (1 - tx) + v111 * tx\n    \n    # Interpolate along y\n    v__0 = v_00 * (1 - ty) + v_10 * ty\n    v__1 = v_01 * (1 - ty) + v_11 * ty\n\n    # Interpolate along z\n    return v__0 * (1 - tz) + v__1 * tz\n\ndef solve():\n    \"\"\"\n    Implements and compares periodic and isolated PM solvers.\n    \"\"\"\n    # Define constants and parameters\n    G = 1.0\n    L = 1.0\n    N = 48\n    M = 1.0\n    a = 0.05\n    \n    # Define test cases: (halo_center, tracer_offset)\n    test_cases = [\n        ((0.5, 0.5, 0.5), (0.05, 0.0, 0.0)),\n        ((0.9, 0.5, 0.5), (-0.05, 0.0, 0.0)),\n        ((0.95, 0.95, 0.95), (-0.03, -0.03, -0.03)),\n    ]\n\n    # Derived parameters\n    dx = L / N\n    epsilon = 2.0 * dx\n\n    # --- Pre-computation of grids and kernels ---\n\n    # Real space grid (cell centers) for N^3 box\n    x_1d = (np.arange(N) + 0.5) * dx\n    X, Y, Z = np.meshgrid(x_1d, x_1d, x_1d, indexing='ij')\n\n    # Fourier space wavevectors for N^3 box\n    k_1d = 2 * np.pi * np.fft.fftfreq(N, d=dx)\n    Kx, Ky, Kz = np.meshgrid(k_1d, k_1d, k_1d, indexing='ij')\n    Ksq = Kx**2 + Ky**2 + Kz**2\n\n    # A. Periodic solver potential kernel\n    with np.errstate(divide='ignore', invalid='ignore'):\n        phi_kernel_k_periodic = -4.0 * np.pi * G / Ksq\n    phi_kernel_k_periodic[0, 0, 0] = 0.0\n\n    # B. Isolated solver Green's function\n    Np = 2 * N\n    # Coordinates for convolution kernel on padded grid\n    i_p = np.arange(Np)\n    r_1d_p = np.where(i_p  Np / 2, i_p, i_p - Np) * dx\n    Rx_p, Ry_p, Rz_p = np.meshgrid(r_1d_p, r_1d_p, r_1d_p, indexing='ij')\n    Rsq_p = Rx_p**2 + Ry_p**2 + Rz_p**2\n    \n    green_func = -G / np.sqrt(Rsq_p + epsilon**2)\n    green_func_k = np.fft.fftn(green_func)\n\n    results = []\n    for x0_tuple, d_tuple in test_cases:\n        x0 = np.array(x0_tuple)\n        d = np.array(d_tuple)\n        xt = x0 + d\n\n        # 1. Construct Density Field on the N^3 grid\n        r_sq = (X - x0[0])**2 + (Y - x0[1])**2 + (Z - x0[2])**2\n        rho = (3.0 * M / (4.0 * np.pi * a**3)) * (1.0 + r_sq / a**2)**(-2.5)\n\n        # 2. Periodic Solver\n        rho_k = np.fft.fftn(rho)\n        phi_k = rho_k * phi_kernel_k_periodic\n        \n        ax_k = -1j * Kx * phi_k\n        ay_k = -1j * Ky * phi_k\n        az_k = -1j * Kz * phi_k\n\n        ax_per = np.fft.ifftn(ax_k).real\n        ay_per = np.fft.ifftn(ay_k).real\n        az_per = np.fft.ifftn(az_k).real\n        a_per_grid = np.stack((ax_per, ay_per, az_per), axis=-1)\n\n        # 3. Isolated Solver\n        rho_padded = np.zeros((Np, Np, Np))\n        rho_padded[:N, :N, :N] = rho\n        \n        rho_padded_k = np.fft.fftn(rho_padded)\n        phi_padded_k = rho_padded_k * green_func_k\n        phi_padded = np.fft.ifftn(phi_padded_k).real\n        \n        phi_iso = phi_padded[:N, :N, :N] * (dx**3)\n\n        grad_phi = np.gradient(-phi_iso, dx)\n        a_iso_grid = np.stack(grad_phi, axis=-1)\n\n        # 4. Interpolation and Comparison\n        a_per = trilinear_interp(a_per_grid, xt, L, periodic=True)\n        a_iso = trilinear_interp(a_iso_grid, xt, L, periodic=False)\n\n        # 5. Calculate fractional spurious image force\n        delta = np.linalg.norm(a_per - a_iso) / np.linalg.norm(a_iso)\n        results.append(delta)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n\n```"
        }
    ]
}