{
    "hands_on_practices": [
        {
            "introduction": "松弛法通过将微分方程转化为代数方程组来求解边值问题。本练习将从最简单的情况入手：一个线性二阶边值问题。通过亲手实现一个二阶中心差分格式，您将学习如何将一个连续的微分算子离散化为一个三对角线性系统，这是求解更复杂问题（包括非线性问题）的松弛法中的核心步骤。这个练习 () 为理解和实现高级数值方法奠定了坚实的基础。",
            "id": "3535597",
            "problem": "考虑一个在闭区间上的二阶线性边值问题（Boundary Value Problem (BVP)），由微分算子给出：\n$$-(p(x)\\,y'(x))' + q(x)\\,y(x) = g(x),\\quad x\\in[a,b],$$\n服从 Dirichlet 边值条件\n$$y(a) = \\alpha,\\qquad y(b) = \\beta.$$\n从守恒律形式和导数定义出发，在一个具有 $$N$$ 个等宽子区间（宽度 $$h = \\frac{b-a}{N}$$）和节点 $$x_i = a + i\\,h$$（其中 $$i\\in\\{0,1,\\dots,N\\}$$）的均匀网格上，推导一个二阶精度的有限差分离散。对半网格点 $$x_{i\\pm\\frac{1}{2}} = x_i \\pm \\frac{h}{2}$$ 处的通量 $$p(x)\\,y'(x)$$ 使用中心差分近似，并为内部未知数 $$\\{y_1,y_2,\\dots,y_{N-1}\\}$$ 得到一个三对角线性系统。以数学上精确的方式，指明如何将 Dirichlet 边值条件 $$y_0=\\alpha$$ 和 $$y_N=\\beta$$ 并入系数矩阵和右端向量，以使所得的线性系统保持三对角结构。\n\n实现一个完整的程序，该程序：\n- 为每个测试用例构建具有指定 $$a$$、$$b$$ 和 $$N$$ 的均匀网格。\n- 使用在每个内部节点 $$x_i$$ 上求值的 $$-(p\\,y')' + q\\,y$$ 的二阶中心差分离散，构建三对角系统。\n- 将 Dirichlet 边值条件并入矩阵和右端项，且不引入三对角结构外的非零元素。\n- 使用保持二阶精度的稳定直接法求解内部未知数的三对角系统。\n- 组合包括边界在内的完整解 $$\\{y_0,y_1,\\dots,y_N\\}$$，并计算每个测试用例与已知解析解的最大绝对误差。\n\n该程序应通过将 $$p(x)$$ 视为一个可能非恒定的类扩散系数，将 $$q(x)$$ 视为一个类反应项，来处理计算天体物理学的背景。这二者在恒星结构和辐射流体力学的线性化输运和扩散近似中很常见。然而，问题本身必须以纯数学术语解决。\n\n所有三角函数均使用弧度制。本问题不要求物理单位。\n\n使用以下测试套件，其中 $$g(x)$$ 是通过将算子 $$-(p\\,y')' + q\\,y$$ 应用于所提供的解析解 $$y(x)$$ 来定义的（即 $$g(x) = -\\big(p'(x)\\,y'(x) + p(x)\\,y''(x)\\big) + q(x)\\,y(x)$$)，并且 Dirichlet 边值通过 $$\\alpha = y(a)$$ 和 $$\\beta = y(b)$$ 进行一致性设置：\n- 测试用例 1 (正常路径)：$$a=0$$, $$b=1$$, $$N=200$$, $$p(x)=1$$, $$q(x)=0$$, $$y(x)=\\sin(\\pi x)$$，其中 $$y'(x)=\\pi\\cos(\\pi x)$$ 且 $$y''(x)=-\\pi^2\\sin(\\pi x)$$。\n- 测试用例 2 (变系数扩散和反应)：$$a=0$$, $$b=1$$, $$N=150$$, $$p(x)=1+x$$, $$q(x)=x^2$$, $$y(x)=x(1-x)$$，其中 $$y'(x)=1-2x$$ 且 $$y''(x)=-2$$。\n- 测试用例 3 (带有指数扩散的刚性反应项)：$$a=0$$, $$b=1$$, $$N=400$$, $$p(x)=e^x$$, $$q(x)=1000$$, $$y(x)=\\sin(\\pi x)$$，其中 $$y'(x)=\\pi\\cos(\\pi x)$$ 且 $$y''(x)=-\\pi^2\\sin(\\pi x)$$。\n\n对于每个测试用例，计算最大绝对误差 $$\\max_{0\\le i\\le N}\\,\\lvert y_i - y(x_i)\\rvert$$。\n\n你的程序应产生单行输出，包含一个用方括号括起来的逗号分隔列表（例如，$$[result_1,result_2,result_3]$$），其中每个 $$result_k$$ 是测试用例 $$k$$ 计算出的最大绝对误差，表示为浮点数。",
            "solution": "该问题要求推导并实现一个用于求解守恒律形式的线性二阶边值问题（BVP）的二阶精度有限差分格式。\n\n该 BVP 在区间 $x \\in [a, b]$ 上由微分方程\n$$ -(p(x) y'(x))' + q(x) y(x) = g(x) $$\n定义，并服从 Dirichlet 边值条件\n$$ y(a) = \\alpha, \\quad y(b) = \\beta. $$\n\n我们首先在区间 $[a,b]$ 上建立一个均匀网格。该区间被划分为 $N$ 个等长的子区间，每个子区间的宽度为 $h = (b-a)/N$。这定义了一组 $N+1$ 个离散网格点，或称节点，$x_i = a + i h$，其中 $i = 0, 1, \\dots, N$。在这些节点上，解 $y(x)$ 由值 $y_i \\approx y(x_i)$ 近似。\n\n该方法的核心是在每个内部节点 $x_i$ ($i = 1, \\dots, N-1$) 处，用一个离散近似替换连续微分算子。设通量定义为 $F(x) = p(x) y'(x)$。于是微分方程可以写成 $-F'(x) + q(x) y(x) = g(x)$。\n\n为了保持二阶精度，我们采用中心差分近似。通量的导数 $F'(x_i)$ 在节点 $x_i$ 处使用通量在半网格点 $x_{i \\pm 1/2} = x_i \\pm h/2$ 处的值来近似：\n$$ F'(x_i) \\approx \\frac{F(x_{i+1/2}) - F(x_{i-1/2})}{h}. $$\n这个近似是二阶精度的，即截断误差为 $O(h^2)$。\n\n接下来，我们需要在这些半网格点上近似通量 $F(x)$。我们对导数 $y'(x)$ 使用以这些半网格点为中心的中心差分：\n$$ y'(x_{i+1/2}) \\approx \\frac{y(x_{i+1}) - y(x_i)}{h} \\approx \\frac{y_{i+1} - y_i}{h} $$\n$$ y'(x_{i-1/2}) \\approx \\frac{y(x_i) - y(x_{i-1})}{h} \\approx \\frac{y_i - y_{i-1}}{h} $$\n这些也是导数在中心点处的二阶精度近似。于是，半网格点处的通量通过在这些点上计算系数 $p(x)$ 并使用离散导数来近似：\n$$ F(x_{i+1/2}) \\approx p(x_{i+1/2}) \\left(\\frac{y_{i+1} - y_i}{h}\\right) = p_{i+1/2} \\frac{y_{i+1} - y_i}{h} $$\n$$ F(x_{i-1/2}) \\approx p(x_{i-1/2}) \\left(\\frac{y_i - y_{i-1}}{h}\\right) = p_{i-1/2} \\frac{y_i - y_{i-1}}{h} $$\n\n将这些代入 $-F'(x_i)$ 的近似式，得到二阶导数项的离散形式：\n$$ -(p y')'_i \\approx -\\frac{1}{h} \\left( p_{i+1/2} \\frac{y_{i+1} - y_i}{h} - p_{i-1/2} \\frac{y_i - y_{i-1}}{h} \\right) = \\frac{1}{h^2} \\left( -p_{i-1/2} y_{i-1} + (p_{i-1/2} + p_{i+1/2}) y_i - p_{i+1/2} y_{i+1} \\right). $$\n将此与微分方程中的其他项（在节点 $x_i$ 处计算，即 $q_i y_i = g_i$）结合，我们得到内部节点 $i \\in \\{1, \\dots, N-1\\}$ 的完整有限差分方程：\n$$ \\frac{1}{h^2} \\left( -p_{i-1/2} y_{i-1} + (p_{i-1/2} + p_{i+1/2}) y_i - p_{i+1/2} y_{i+1} \\right) + q_i y_i = g_i. $$\n重新整理此方程，按未知数 $y_{i-1}$、$y_i$ 和 $y_{i+1}$ 分组，得到：\n$$ \\left(-\\frac{p_{i-1/2}}{h^2}\\right) y_{i-1} + \\left(\\frac{p_{i-1/2} + p_{i+1/2}}{h^2} + q_i\\right) y_i + \\left(-\\frac{p_{i+1/2}}{h^2}\\right) y_{i+1} = g_i. $$\n这组关于 $N-1$ 个内部未知数 $\\{y_1, y_2, \\dots, y_{N-1}\\}$ 的 $N-1$ 个线性方程构成一个三对角系统。未知数 $y_0$ 和 $y_N$ 由边界条件给出：$y_0 = \\alpha$ 和 $y_N = \\beta$。\n\n为了构建最终的线性系统 $A \\mathbf{y}_{\\text{int}} = \\mathbf{b}$，其中 $\\mathbf{y}_{\\text{int}} = [y_1, \\dots, y_{N-1}]^T$，我们必须并入边界条件。\n对于第一个内部节点 $i=1$：\n$$ \\left(-\\frac{p_{1/2}}{h^2}\\right) y_0 + \\left(\\frac{p_{1/2} + p_{3/2}}{h^2} + q_1\\right) y_1 + \\left(-\\frac{p_{3/2}}{h^2}\\right) y_2 = g_1. $$\n由于 $y_0 = \\alpha$ 是已知的，我们将包含 $y_0$ 的项移到右边：\n$$ \\left(\\frac{p_{1/2} + p_{3/2}}{h^2} + q_1\\right) y_1 + \\left(-\\frac{p_{3/2}}{h^2}\\right) y_2 = g_1 + \\frac{p_{1/2}}{h^2} \\alpha. $$\n这定义了 $(N-1) \\times (N-1)$ 系统矩阵的第一行和右端向量的第一个元素。\n\n对于最后一个内部节点 $i=N-1$：\n$$ \\left(-\\frac{p_{N-3/2}}{h^2}\\right) y_{N-2} + \\left(\\frac{p_{N-3/2} + p_{N-1/2}}{h^2} + q_{N-1}\\right) y_{N-1} + \\left(-\\frac{p_{N-1/2}}{h^2}\\right) y_N = g_{N-1}. $$\n由于 $y_N = \\beta$ 是已知的，包含 $y_N$ 的项被移到右边：\n$$ \\left(-\\frac{p_{N-3/2}}{h^2}\\right) y_{N-2} + \\left(\\frac{p_{N-3/2} + p_{N-1/2}}{h^2} + q_{N-1}\\right) y_{N-1} = g_{N-1} + \\frac{p_{N-1/2}}{h^2} \\beta. $$\n这定义了系统的最后一行。此过程保留了系数矩阵 $A$ 的三对角结构。\n\n所得的三对角系统使用稳定的直接求解器（例如为带状矩阵优化的 LU 分解算法）求解内部未知数向量 $\\mathbf{y}_{\\text{int}}$。最后，通过组合边界值和计算出的内部值来组合完整的数值解：$\\mathbf{y}_{\\text{num}} = [\\alpha, y_1, \\dots, y_{N-1}, \\beta]^T$。通过计算与已知解析解的最大绝对误差 $\\max_{0 \\le i \\le N} |y_i - y(x_i)|$ 来评估精度。",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import solve_banded\n\ndef solve_bvp_case(case):\n    \"\"\"\n    Solves a single test case for the BVP -(p*y')' + q*y = g.\n\n    Args:\n        case (dict): A dictionary containing all parameters for the test case,\n                     including functions for p, q, and the analytic solution y\n                     and its derivatives.\n\n    Returns:\n        float: The maximum absolute error between the numerical and analytic solutions.\n    \"\"\"\n    # 1. Unpack parameters and set up grid\n    a, b, N = case[\"a\"], case[\"b\"], case[\"N\"]\n    p_func = case[\"p\"]\n    q_func = case[\"q\"]\n    y_analytic_func = case[\"y_analytic\"]\n    \n    # Per the problem statement, construct g(x) from the analytic solution:\n    # g(x) = -(p(x)y'(x))' + q(x)y(x) = -p'(x)y'(x) - p(x)y''(x) + q(x)y(x)\n    p_prime_func = case[\"p_prime\"]\n    y_prime_func = case[\"y_prime\"]\n    y_double_prime_func = case[\"y_double_prime\"]\n    g_func = lambda x: -(p_prime_func(x) * y_prime_func(x) + p_func(x) * y_double_prime_func(x)) + q_func(x) * y_analytic_func(x)\n\n    h = (b - a) / N\n    h2 = h * h\n    # Grid nodes x_0, ..., x_N\n    x_nodes = np.linspace(a, b, N + 1)\n    # Interior nodes x_1, ..., x_{N-1}\n    x_interior = x_nodes[1:-1]\n    # Half-grid points for p(x) evaluation: x_{1/2}, ..., x_{N-1/2}\n    x_half = a + (np.arange(N) + 0.5) * h\n\n    # 2. Assemble the tridiagonal matrix for interior points (N-1 x N-1)\n    # The finite difference equation for an interior node i is:\n    # (-p_{i-1/2}/h^2) y_{i-1} + ((p_{i-1/2}+p_{i+1/2})/h^2 + q_i) y_i + (-p_{i+1/2}/h^2) y_{i+1} = g_i\n    \n    p_half_vals = p_func(x_half)\n    q_interior_vals = q_func(x_interior)\n    \n    # Lower diagonal (for equations corresponding to y_2 to y_{N-1})\n    lower_diag = -p_half_vals[1:-1] / h2\n    \n    # Main diagonal (for equations corresponding to y_1 to y_{N-1})\n    main_diag = (p_half_vals[:-1] + p_half_vals[1:]) / h2 + q_interior_vals\n    \n    # Upper diagonal (for equations corresponding to y_1 to y_{N-2})\n    upper_diag = -p_half_vals[1:-1] / h2\n    \n    # 3. Assemble the Right-Hand Side (RHS) vector\n    rhs = g_func(x_interior)\n    \n    # Get boundary conditions from analytic solution\n    alpha = y_analytic_func(a)\n    beta = y_analytic_func(b)\n    \n    # Incorporate boundary conditions into the RHS vector\n    # For i=1: rhs[0] should be g_1 - (-p_{1/2}/h^2)*alpha\n    rhs[0] += p_half_vals[0] / h2 * alpha\n    \n    # For i=N-1: rhs[-1] should be g_{N-1} - (-p_{N-1/2}/h^2)*beta\n    rhs[-1] += p_half_vals[-1] / h2 * beta\n\n    # 4. Solve the tridiagonal system using a stable direct solver\n    # The `solve_banded` function requires the matrix diagonals in a specific format.\n    # For a tridiagonal matrix, the band description is (l=1, u=1).\n    # The `ab` matrix shape is (3, N-1).\n    # ab[0, 1:] = upper diagonal\n    # ab[1, :] = main diagonal\n    # ab[2, :-1] = lower diagonal\n    ab = np.zeros((3, N - 1))\n    ab[0, 1:] = upper_diag\n    ab[1, :] = main_diag\n    ab[2, :-1] = lower_diag\n    \n    y_interior = solve_banded((1, 1), ab, rhs)\n    \n    # 5. Assemble the full solution and compute the maximum absolute error\n    y_numerical = np.concatenate(([alpha], y_interior, [beta]))\n    y_exact = y_analytic_func(x_nodes)\n    \n    max_abs_error = np.max(np.abs(y_numerical - y_exact))\n    \n    return max_abs_error\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and compute errors.\n    \"\"\"\n    test_cases = [\n        {\n            \"a\": 0.0, \"b\": 1.0, \"N\": 200,\n            \"p\": lambda x: 1.0,\n            \"q\": lambda x: 0.0,\n            \"y_analytic\": lambda x: np.sin(np.pi * x),\n            \"p_prime\": lambda x: 0.0,\n            \"y_prime\": lambda x: np.pi * np.cos(np.pi * x),\n            \"y_double_prime\": lambda x: -np.pi**2 * np.sin(np.pi * x)\n        },\n        {\n            \"a\": 0.0, \"b\": 1.0, \"N\": 150,\n            \"p\": lambda x: 1.0 + x,\n            \"q\": lambda x: x**2,\n            \"y_analytic\": lambda x: x * (1.0 - x),\n            \"p_prime\": lambda x: 1.0,\n            \"y_prime\": lambda x: 1.0 - 2.0 * x,\n            \"y_double_prime\": lambda x: -2.0\n        },\n        {\n            \"a\": 0.0, \"b\": 1.0, \"N\": 400,\n            \"p\": lambda x: np.exp(x),\n            \"q\": lambda x: 1000.0,\n            \"y_analytic\": lambda x: np.sin(np.pi * x),\n            \"p_prime\": lambda x: np.exp(x),\n            \"y_prime\": lambda x: np.pi * np.cos(np.pi * x),\n            \"y_double_prime\": lambda x: -np.pi**2 * np.sin(np.pi * x)\n        }\n    ]\n\n    # Vectorize lambda functions for numpy array inputs\n    for case in test_cases:\n        for key, func in case.items():\n            if callable(func):\n                case[key] = np.vectorize(func)\n\n    results = []\n    for case in test_cases:\n        error = solve_bvp_case(case)\n        results.append(error)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在求解一个模型之后，我们往往更关心解如何依赖于模型的参数，这便是灵敏度分析的范畴。对于拥有大量参数（例如一个参数场 $\\alpha(x)$）的系统，伴随方法是一种计算解的泛函（如打靶法中的残差）梯度的极其高效的技术。本练习 () 将指导您推导并实现一个伴随系统，以计算打靶法残差对一个参数场的泛函导数。掌握伴随方法将为您在求解优化、数据同化和逆问题等高级计算任务时带来巨大的效率优势。",
            "id": "3535529",
            "problem": "给定一个边值问题，其解通过打靶法进行近似。考虑在区间 $x \\in [0,1]$ 上的一个标量场 $y(x)$ 的非线性常微分方程，其辅助变量 $v(x)$ 定义为 $v(x) = \\frac{dy}{dx}$：\n$$\n\\frac{dy}{dx} = v, \\qquad \\frac{dv}{dx} = -\\alpha(x)\\, y^3,\n$$\n其中 $\\alpha(x)$ 是一个给定的参数场。打靶法指定初始条件 $y(0) = y_0$ 和初始斜率 $v(0) = s$，向前积分至 $x=1$，并定义一个标量残差\n$$\nR(\\alpha) = y(1; \\alpha, y_0, s) - y_{\\text{target}},\n$$\n该残差衡量了与期望终端值 $y(1) \\approx y_{\\text{target}}$ 之间的不匹配程度。此处，$y(1; \\alpha, y_0, s)$ 表示在给定参数场 $\\alpha(x)$ 的情况下通过前向积分在 $x=1$ 处得到的 $y$ 值，而 $y_{\\text{target}}$ 是一个给定的目标值。\n\n您的任务是实现一种伴随灵敏度方法，以计算泛函导数 $\\frac{dR}{d\\alpha}$，该导数可理解为将微扰 $\\delta\\alpha(x)$ 映射到 $\\delta R$ 的 Fréchet 导数。该伴随灵敏度方法必须从第一性原理推导得出，通过线性化前向动力学并引入一个在 $x=1$ 具有终端条件的适当伴随系统，从而使得任意方向 $p(x)$ 上的方向导数可以计算为内积 $\\int_0^1 \\left(\\frac{dR}{d\\alpha}(x)\\right) p(x)\\, dx$。您还必须使用有限差分近似计算相同的方向导数，并量化伴随方法结果与有限差分结果之间的差异。最后，您必须报告一个计算优势度量，该度量估计了在使用有限差分与伴随方法在 $G$ 个点的网格上恢复完整梯度场时所需的前向求解相对数量，假设对每个参数自由度使用中心差分。\n\n请基于以下基本原理进行推导和算法设计：\n- 将打靶残差 $R(\\alpha)$ 定义为终端状态 $y(1)$ 的函数。\n- 将初值问题 $\\frac{d\\mathbf{y}}{dx} = \\mathbf{f}(\\mathbf{y}(x), x, \\alpha(x))$ 围绕名义解进行线性化，以获得变分方程 $\\delta \\mathbf{y}$ 的概念。\n- 伴随方法，通过求解一个在 $x$ 上向后求解的伴随常微分方程，将终端泛函导数转换为与伴随场的积分。\n\n在完整的程序中实现以下内容：\n1. 对于每个测试用例，针对给定的 $y_0$、$s$ 和 $\\alpha(x)$ 积分前向系统，以获得 $y(1)$ 和残差 $R(\\alpha)$。\n2. 推导并实现与残差 $R(\\alpha)$ 相关的伴随系统，并在一个包含 $[0,1]$ 上 $G=1001$ 个点的均匀网格 $x_i$（其中 $i=0,\\dots,G-1$）上计算泛函梯度 $\\frac{dR}{d\\alpha}(x)$。\n3. 对于给定的微扰方向 $p(x)$ 和小标量 $\\varepsilon$，计算基于伴随方法得到的方向导数\n$$\nD_{\\text{adj}} = \\int_0^1 \\left(\\frac{dR}{d\\alpha}(x)\\right) p(x)\\, dx,\n$$\n使用网格上的数值求积法。同时，通过两次额外的、使用微扰参数场 $\\alpha_{\\pm}(x) = \\alpha(x) \\pm \\varepsilon p(x)$ 的前向积分，计算中心有限差分近似\n$$\nD_{\\text{fd}} = \\frac{R(\\alpha + \\varepsilon p) - R(\\alpha - \\varepsilon p)}{2 \\varepsilon},\n$$\n4. 报告每个测试用例的绝对差异 $|D_{\\text{adj}} - D_{\\text{fd}}|$。同时报告计算优势度量 $C$，其定义为使用中心有限差分在所有 $G$ 个网格点上计算完整梯度所需的前向积分次数与使用伴随方法所需次数的比率。假设中心有限差分需要 $2G$ 次前向求解，而伴随方法需要一次前向求解和一次伴随求解（两者均与 $G$ 无关），因此 $C = G$。\n\n使用以下测试套件。每个测试用例由元组 $(y_0, s, y_{\\text{target}}, \\text{profile\\_id}, \\text{direction\\_id}, \\varepsilon)$ 指定，其中 $\\alpha(x)$ 和 $p(x)$ 由标识符定义：\n- 参数场分布 $\\alpha(x)$:\n  - $\\text{profile\\_id} = 0$: $\\alpha(x) = 2 + x$。\n  - $\\text{profile\\_id} = 1$: $\\alpha(x) = 0.2 + 0.2 x$。\n  - $\\text{profile\\_id} = 2$: $\\alpha(x) = 5 \\left(1 + x^2\\right)$。\n  - $\\text{profile\\_id} = 3$: $\\alpha(x) = 1$。\n- 方向场 $p(x)$:\n  - $\\text{direction\\_id} = 0$: $p(x) = \\sin(\\pi x)$，其中 $\\pi$ 为圆周率（以弧度计）。\n  - $\\text{direction\\_id} = 1$: $p(x) = x (1 - x)$。\n  - $\\text{direction\\_id} = 2$: $p(x) = \\cos(2 \\pi x)$，角度以弧度计。\n  - $\\text{direction\\_id} = 3$: $p(x) = \\sin(3 \\pi x)$，角度以弧度计。\n\n测试用例：\n- 用例 1: $(1.0, 0.3, 0.7, 0, 0, 1\\times 10^{-5})$。\n- 用例 2: $(1.0, 0.0, 0.5, 1, 1, 1\\times 10^{-5})$。\n- 用例 3: $(0.8, 1.0, 0.1, 2, 2, 1\\times 10^{-6})$。\n- 用例 4: $(1.2, -0.5, 1.2, 3, 3, 1\\times 10^{-5})$。\n\n数值要求：\n- 对所有积分和求积，使用在 $[0,1]$ 上的 $G = 1001$ 个点的均匀网格。\n- 使用一个鲁棒的、具有足够精度的常微分方程积分器来求解非线性动力学和伴随动力学。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须按顺序包含每个测试用例的绝对差异 $|D_{\\text{adj}} - D_{\\text{fd}}|$（浮点数），后跟计算优势度量 $C$（整数）。例如，输出应为 $[e_1,C_1,e_2,C_2,e_3,C_3,e_4,C_4]$ 的形式。",
            "solution": "该问题要求使用伴随灵敏度方法，计算打靶法残差相对于参数场 $\\alpha(x)$ 的泛函导数。伴随导数的正确性需要通过与有限差分近似进行比较来验证，并且需要报告一个计算优势度量。\n\n解决方案的核心在于推导和求解伴随常微分方程（ODE）系统。推导基于以下原理：线性化前向动力学，并使用伴随算子将灵敏度从终端状态映射回沿积分路径分布的参数。\n\n令系统的状态由向量 $\\mathbf{z}(x) = [y(x), v(x)]^T$ 描述。前向动力学由以下一阶 ODE 系统给出：\n$$\n\\frac{d\\mathbf{z}}{dx} = \\mathbf{f}(\\mathbf{z}(x), x, \\alpha(x))\n$$\n其中\n$$\n\\mathbf{f}(\\mathbf{z}, x, \\alpha) = \\begin{pmatrix} v \\\\ -\\alpha(x) y^3 \\end{pmatrix}\n$$\n初始条件为 $\\mathbf{z}(0) = [y_0, s]^T$。打靶残差是终端状态的标量泛函：\n$$\nR(\\alpha) = y(1) - y_{\\text{target}} = \\begin{pmatrix} 1  0 \\end{pmatrix} \\mathbf{z}(1) - y_{\\text{target}}\n$$\n\n为了求 Fréchet 导数 $\\frac{dR}{d\\alpha}$，我们考虑参数场中的一个微小扰动 $\\delta\\alpha(x)$，它会引起状态轨迹的一阶变分 $\\delta\\mathbf{z}(x)$。变分 $\\delta\\mathbf{z}$ 由线性化（或变分）方程控制：\n$$\n\\frac{d(\\delta\\mathbf{z})}{dx} = \\mathbf{J}_{\\mathbf{z}}(x) \\delta\\mathbf{z}(x) + \\mathbf{F}(x) \\delta\\alpha(x)\n$$\n其中 $\\mathbf{J}_{\\mathbf{z}}(x)$ 是 $\\mathbf{f}$ 关于 $\\mathbf{z}$ 的雅可比矩阵，$\\mathbf{F}(x)$ 是 $\\mathbf{f}$ 关于 $\\alpha$ 的导数，两者都沿名义前向解轨迹 $(\\mathbf{z}(x), \\alpha(x))$ 进行评估。\n雅可比矩阵为：\n$$\n\\mathbf{J}_{\\mathbf{z}}(x) = \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{z}} = \\begin{pmatrix} \\frac{\\partial v}{\\partial y}  \\frac{\\partial v}{\\partial v} \\\\ \\frac{\\partial(-\\alpha y^3)}{\\partial y}  \\frac{\\partial(-\\alpha y^3)}{\\partial v} \\end{pmatrix} = \\begin{pmatrix} 0  1 \\\\ -3\\alpha(x)y(x)^2  0 \\end{pmatrix}\n$$\n对 $\\alpha$ 的灵敏度为：\n$$\n\\mathbf{F}(x) = \\frac{\\partial \\mathbf{f}}{\\partial \\alpha} = \\begin{pmatrix} 0 \\\\ -y(x)^3 \\end{pmatrix}\n$$\n初始条件的变分为零，因此 $\\delta\\mathbf{z}(0) = \\mathbf{0}$。残差的变分为 $\\delta R = \\delta y(1) = \\begin{pmatrix} 1  0 \\end{pmatrix} \\delta\\mathbf{z}(1)$。\n\n伴随方法引入了一个伴随状态向量 $\\mathbf{\\lambda}(x) = [\\lambda_y(x), \\lambda_v(x)]^T$。我们试图将 $\\delta R$ 与一个关于 $\\delta\\alpha(x)$ 的积分关联起来。我们从恒等式开始：\n$$\n\\int_0^1 \\mathbf{\\lambda}^T \\left( \\frac{d(\\delta\\mathbf{z})}{dx} \\right) dx = \\int_0^1 \\mathbf{\\lambda}^T (\\mathbf{J}_{\\mathbf{z}} \\delta\\mathbf{z} + \\mathbf{F} \\delta\\alpha) dx\n$$\n对左侧进行分部积分得到：\n$$\n[\\mathbf{\\lambda}^T \\delta\\mathbf{z}]_0^1 - \\int_0^1 \\left( \\frac{d\\mathbf{\\lambda}}{dx} \\right)^T \\delta\\mathbf{z} \\, dx = \\int_0^1 \\mathbf{\\lambda}^T \\mathbf{J}_{\\mathbf{z}} \\delta\\mathbf{z} \\, dx + \\int_0^1 \\mathbf{\\lambda}^T \\mathbf{F} \\delta\\alpha \\, dx\n$$\n使用 $\\delta\\mathbf{z}(0) = \\mathbf{0}$，上式简化为：\n$$\n\\mathbf{\\lambda}(1)^T \\delta\\mathbf{z}(1) = \\int_0^1 \\left( \\left( \\frac{d\\mathbf{\\lambda}}{dx} \\right)^T + \\mathbf{\\lambda}^T \\mathbf{J}_{\\mathbf{z}} \\right) \\delta\\mathbf{z} \\, dx + \\int_0^1 \\mathbf{\\lambda}^T \\mathbf{F} \\delta\\alpha \\, dx\n$$\n伴随方法定义了 $\\mathbf{\\lambda}$ 的动力学，使得包含 $\\delta\\mathbf{z}$ 的积分项为零。这产生了**伴随 ODE 系统**：\n$$\n\\frac{d\\mathbf{\\lambda}}{dx} = -\\mathbf{J}_{\\mathbf{z}}(x)^T \\mathbf{\\lambda}(x)\n$$\n以分量形式表示：\n$$\n\\frac{d}{dx}\\begin{pmatrix} \\lambda_y \\\\ \\lambda_v \\end{pmatrix} = -\\begin{pmatrix} 0  -3\\alpha y^2 \\\\ 1  0 \\end{pmatrix} \\begin{pmatrix} \\lambda_y \\\\ \\lambda_v \\end{pmatrix} = \\begin{pmatrix} 3\\alpha(x)y(x)^2 \\lambda_v(x) \\\\ -\\lambda_y(x) \\end{pmatrix}\n$$\n该 ODE 在 $x$ 上从 $x=1$ 向后积分到 $x=0$。选择在 $x=1$ 处的终端条件，以将表达式与 $\\delta R$ 关联起来：\n$$\n\\mathbf{\\lambda}(1) = \\left( \\frac{\\partial R}{\\partial \\mathbf{z}(1)} \\right)^T = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\n通过这些定义，关系简化为：\n$$\n\\delta R = \\mathbf{\\lambda}(1)^T \\delta\\mathbf{z}(1) = \\int_0^1 \\mathbf{\\lambda}(x)^T \\mathbf{F}(x) \\delta\\alpha(x) \\, dx\n$$\n被积函数是伴随状态与前向灵敏度项的内积。泛函导数 $\\frac{dR}{d\\alpha}(x)$ 是该积分的核：\n$$\n\\frac{dR}{d\\alpha}(x) = \\mathbf{\\lambda}(x)^T \\mathbf{F}(x) = \\begin{pmatrix} \\lambda_y(x)  \\lambda_v(x) \\end{pmatrix} \\begin{pmatrix} 0 \\\\ -y(x)^3 \\end{pmatrix} = -y(x)^3 \\lambda_v(x)\n$$\n因此，在方向 $p(x)$ 上的方向导数为 $D_{\\text{adj}} = \\int_0^1 \\left(\\frac{dR}{d\\alpha}(x)\\right) p(x) dx$。\n\n算法如下：\n1.  **前向传递**：在 $G=1001$ 个点的网格上，从 $x=0$到 $x=1$ 求解前向 ODE 系统以获得 $\\mathbf{z}(x)$。使用密集输出存储解 $y(x)$，以供下一步使用。\n2.  **后向传递**：从 $x=1$ 到 $x=0$ 求解伴随 ODE 系统以获得 $\\mathbf{\\lambda}(x)$，使用终端条件 $\\mathbf{\\lambda}(1)=[1, 0]^T$。系数 $\\alpha(x)y(x)^2$ 需要使用前向传递中存储的解。\n3.  **梯度计算**：在每个网格点 $x_i$，计算梯度 $\\frac{dR}{d\\alpha}(x_i) = -y(x_i)^3 \\lambda_v(x_i)$。\n4.  **伴随导数**：使用梯形法则数值积分梯度与微扰方向 $p(x)$ 的乘积，以获得 $D_{\\text{adj}} = \\int_0^1 \\frac{dR}{d\\alpha}(x) p(x) dx$。\n5.  **有限差分验证**：通过执行两次额外的、使用微扰参数场 $\\alpha_{\\pm}(x) = \\alpha(x) \\pm \\varepsilon p(x)$ 的前向求解，计算中心差分近似 $D_{\\text{fd}} = \\frac{R(\\alpha + \\varepsilon p) - R(\\alpha - \\varepsilon p)}{2 \\varepsilon}$。\n6.  **度量**：报告绝对差异 $|D_{\\text{adj}} - D_{\\text{fd}}|$ 和计算优势 $C$。$C$ 的值由计算量的比率决定。为了在 $G$ 个点的网格上计算梯度，中心差分需要 $2G$ 次前向求解（每个网格点两次）。伴随方法需要一次前向求解和一次后向（伴随）求解，总共 2 次主要积分，且与 $G$ 无关。因此，优势为 $C = \\frac{2G}{2} = G = 1001$。\n\n此过程将对所提供的每个测试用例进行实现。",
            "answer": "```python\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It computes the adjoint and finite-difference derivatives, their discrepancy,\n    and a computational advantage metric.\n    \"\"\"\n    \n    # Define grid and parameters\n    G = 1001\n    X_GRID = np.linspace(0.0, 1.0, G)\n    \n    # Define parameter and direction profiles from the problem statement\n    alpha_profiles = {\n        0: lambda x: 2.0 + x,\n        1: lambda x: 0.2 + 0.2 * x,\n        2: lambda x: 5.0 * (1.0 + x**2),\n        3: lambda x: 1.0,\n    }\n    \n    p_directions = {\n        0: lambda x: np.sin(np.pi * x),\n        1: lambda x: x * (1.0 - x),\n        2: lambda x: np.cos(2.0 * np.pi * x),\n        3: lambda x: np.sin(3.0 * np.pi * x),\n    }\n\n    test_cases = [\n        # (y0, s, y_target, profile_id, direction_id, epsilon)\n        (1.0, 0.3, 0.7, 0, 0, 1e-5),\n        (1.0, 0.0, 0.5, 1, 1, 1e-5),\n        (0.8, 1.0, 0.1, 2, 2, 1e-6),\n        (1.2, -0.5, 1.2, 3, 3, 1e-5),\n    ]\n\n    results = []\n\n    def compute_residual(y0, s, y_target, alpha_func):\n        \"\"\"\n        Solves the forward ODE for a given alpha(x) and returns the residual R.\n        \"\"\"\n        def forward_ode(x, state, afunc):\n            y, v = state\n            return [v, -afunc(x) * y**3]\n\n        sol = solve_ivp(\n            lambda x, state: forward_ode(x, state, alpha_func),\n            [0.0, 1.0], [y0, s], method='Radau', rtol=1e-9, atol=1e-11\n        )\n        y_at_1 = sol.y[0, -1]\n        return y_at_1 - y_target\n\n    for y0, s, y_target, profile_id, direction_id, epsilon in test_cases:\n        alpha_func = alpha_profiles[profile_id]\n        p_func = p_directions[direction_id]\n\n        # --- Adjoint Method ---\n\n        # 1. Forward Pass: Solve for the state y(x), v(x)\n        def forward_ode(x, state, afunc):\n            y, v = state\n            return [v, -afunc(x) * y**3]\n\n        fwd_sol = solve_ivp(\n            lambda x, state: forward_ode(x, state, alpha_func),\n            [0.0, 1.0], [y0, s], dense_output=True, method='Radau', rtol=1e-9, atol=1e-11\n        )\n        y_sol_dense = fwd_sol.sol\n\n        # 2. Backward Pass: Solve the adjoint ODE\n        def adjoint_ode(x, lambda_state):\n            lambda_y, lambda_v = lambda_state\n            # Get y(x) and alpha(x) at the current integration point x\n            y_val = y_sol_dense(x)[0]\n            alpha_val = alpha_func(x)\n            \n            d_lambda_y_dx = 3.0 * alpha_val * y_val**2 * lambda_v\n            d_lambda_v_dx = -lambda_y\n            return [d_lambda_y_dx, d_lambda_v_dx]\n\n        # Integrate backwards from x=1 to x=0\n        adj_sol = solve_ivp(\n            adjoint_ode, [1.0, 0.0], [1.0, 0.0], t_eval=X_GRID[::-1],\n            method='Radau', rtol=1e-9, atol=1e-11\n        )\n\n        # 3. Compute Adjoint-based Directional Derivative (D_adj)\n        # Realign solution with X_GRID (from 0 to 1)\n        y_grid = y_sol_dense(X_GRID)[0]\n        lambda_v_grid = adj_sol.y[1, ::-1]\n\n        # Functional derivative dR/dalpha(x) = -y(x)^3 * lambda_v(x)\n        grad_R_grid = -y_grid**3 * lambda_v_grid\n        p_grid = p_func(X_GRID)\n        \n        # Integrate (dR/dalpha) * p(x)\n        D_adj = np.trapz(grad_R_grid * p_grid, x=X_GRID)\n\n        # --- Finite Difference Method for Verification ---\n        \n        # Define perturbed alpha functions\n        alpha_plus = lambda x: alpha_func(x) + epsilon * p_func(x)\n        alpha_minus = lambda x: alpha_func(x) - epsilon * p_func(x)\n\n        # Compute residuals for perturbed alphas\n        R_plus = compute_residual(y0, s, y_target, alpha_plus)\n        R_minus = compute_residual(y0, s, y_target, alpha_minus)\n        \n        # Central difference approximation\n        D_fd = (R_plus - R_minus) / (2.0 * epsilon)\n\n        # --- Report Metrics ---\n        \n        # Absolute discrepancy between the two methods\n        discrepancy = abs(D_adj - D_fd)\n        \n        # Computational advantage C = G\n        C = G\n\n        results.extend([discrepancy, C])\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}