{
    "hands_on_practices": [
        {
            "introduction": "To understand why an iterative method converges or diverges, we must analyze its core component: the iteration matrix. This first exercise provides a foundational analysis of the Jacobi method by examining its iteration matrix, $T_J$, for the canonical 1D Poisson equation. By deriving the exact eigenvalues of $T_J$, we can precisely quantify how the method's convergence properties are linked to the grid spacing $h$ and the discrete Fourier modes of the error, providing a crucial first step in understanding the strengths and limitations of simple iterative schemes .",
            "id": "3338184",
            "problem": "Consider the one-dimensional pressure Poisson equation arising in incompressible computational fluid dynamics on the interval $\\left[0,1\\right]$ with homogeneous Dirichlet boundary conditions, given by $-u^{\\prime\\prime}(x)=f(x)$ and $u(0)=u(1)=0$. Discretize the domain with $n$ interior grid points at positions $x_{j}=j h$ for $j=1,2,\\dots,n$ and uniform grid spacing $h=\\frac{1}{n+1}$. Use the standard second-order central difference approximation to obtain the linear system $A u=b$, where $A\\in\\mathbb{R}^{n\\times n}$ is tridiagonal with $A=\\frac{1}{h^{2}}\\operatorname{tridiag}(-1,2,-1)$. Let $D$ be the diagonal of $A$, and consider the Jacobi iteration with diagonal preconditioning, whose iteration matrix is $T_{J}=I-D^{-1}A$.\n\nStarting from the discrete operator and boundary conditions, and using only foundational properties of the discrete sine modes associated with homogeneous Dirichlet boundaries on a uniform grid, derive the eigenvalues of $T_{J}$ as functions of the integer mode index $k\\in\\{1,2,\\dots,n\\}$ and the grid spacing $h$. Provide your final result as a single closed-form analytic expression for the $k$-th eigenvalue $\\lambda_{k}(T_{J})$ in terms of $k$ and $h$. No numerical evaluation is required, and no rounding is permitted. Express your final answer without units.",
            "solution": "The problem requires the derivation of the eigenvalues of the Jacobi iteration matrix $T_J$ for the finite difference discretization of the one-dimensional Poisson equation with homogeneous Dirichlet boundary conditions. The derivation will proceed by first determining the eigenvalues and eigenvectors of the discretization matrix $A$, and then using this result to find the eigenvalues of $T_J$.\n\nThe linear system is given by $A u=b$, where the matrix $A \\in \\mathbb{R}^{n \\times n}$ is defined as $A=\\frac{1}{h^{2}}\\operatorname{tridiag}(-1,2,-1)$. The grid spacing is $h=\\frac{1}{n+1}$.\n\nFirst, let us determine the eigenvalues and eigenvectors of the matrix $A$. The structure of $A$ is that of a scaled symmetric Toeplitz matrix. The eigenvectors of such matrices arising from the discretization of the Laplacian with homogeneous Dirichlet boundary conditions are known to be the discrete sine modes. Let us verify this and find the corresponding eigenvalues.\n\nLet the $k$-th eigenvector be $v_k$, where $k \\in \\{1, 2, \\dots, n\\}$. The $j$-th component of this vector is given by $(v_k)_j = \\sin(k \\pi x_j) = \\sin(k \\pi j h)$ for $j=1, 2, \\dots, n$. We need to verify that $A v_k = \\mu_k v_k$ for some scalar eigenvalue $\\mu_k$.\n\nThe action of the matrix $A$ on the vector $v_k$ at the $j$-th component is:\n$$ (A v_k)_j = \\frac{1}{h^2} \\left( - (v_k)_{j-1} + 2 (v_k)_j - (v_k)_{j+1} \\right) $$\nAt the boundaries of the grid ($j=1$ and $j=n$), we must incorporate the homogeneous Dirichlet conditions. The components $(v_k)_0$ and $(v_k)_{n+1}$ correspond to the values at $x=0$ and $x=1$.\n$(v_k)_0 = \\sin(k \\pi \\cdot 0 \\cdot h) = \\sin(0) = 0$.\n$(v_k)_{n+1} = \\sin(k \\pi (n+1) h) = \\sin(k \\pi (n+1) \\frac{1}{n+1}) = \\sin(k \\pi) = 0$ for integer $k$.\nThese are consistent with the boundary conditions $u(0)=0$ and $u(1)=0$.\n\nSubstituting the eigenvector components into the expression for $(A v_k)_j$:\n$$ (A v_k)_j = \\frac{1}{h^2} \\left[ - \\sin(k \\pi (j-1) h) + 2 \\sin(k \\pi j h) - \\sin(k \\pi (j+1) h) \\right] $$\nWe use the trigonometric identity $\\sin(a+b) + \\sin(a-b) = 2 \\sin(a) \\cos(b)$. Let $a = k \\pi j h$ and $b = k \\pi h$. Then:\n$$ \\sin(k \\pi (j+1) h) + \\sin(k \\pi (j-1) h) = 2 \\sin(k \\pi j h) \\cos(k \\pi h) $$\nSubstituting this into the expression for $(A v_k)_j$:\n$$ (A v_k)_j = \\frac{1}{h^2} \\left[ 2 \\sin(k \\pi j h) - \\left( \\sin(k \\pi (j-1) h) + \\sin(k \\pi (j+1) h) \\right) \\right] $$\n$$ (A v_k)_j = \\frac{1}{h^2} \\left[ 2 \\sin(k \\pi j h) - 2 \\sin(k \\pi j h) \\cos(k \\pi h) \\right] $$\n$$ (A v_k)_j = \\frac{1}{h^2} \\left[ 2(1 - \\cos(k \\pi h)) \\right] \\sin(k \\pi j h) $$\nUsing the half-angle identity $1 - \\cos(\\theta) = 2 \\sin^2(\\frac{\\theta}{2})$, we get:\n$$ 2(1 - \\cos(k \\pi h)) = 2 \\left( 2 \\sin^2\\left(\\frac{k \\pi h}{2}\\right) \\right) = 4 \\sin^2\\left(\\frac{k \\pi h}{2}\\right) $$\nThus, we have:\n$$ (A v_k)_j = \\frac{4}{h^2} \\sin^2\\left(\\frac{k \\pi h}{2}\\right) \\sin(k \\pi j h) = \\left( \\frac{4}{h^2} \\sin^2\\left(\\frac{k \\pi h}{2}\\right) \\right) (v_k)_j $$\nThis confirms that $v_k$ is an eigenvector of $A$. The corresponding eigenvalue $\\mu_k$ is:\n$$ \\mu_k = \\frac{4}{h^2} \\sin^2\\left(\\frac{k \\pi h}{2}\\right) $$\nfor each mode index $k \\in \\{1, 2, \\dots, n\\}$.\n\nNext, we analyze the Jacobi iteration matrix, $T_J = I - D^{-1}A$.\nThe matrix $D$ is the diagonal of $A$. From the definition $A=\\frac{1}{h^{2}}\\operatorname{tridiag}(-1,2,-1)$, all diagonal elements are $A_{jj} = \\frac{2}{h^2}$.\nTherefore, $D$ is a scalar multiple of the identity matrix $I$:\n$$ D = \\frac{2}{h^2} I $$\nIts inverse is:\n$$ D^{-1} = \\frac{h^2}{2} I $$\nNow, we can find the eigenvalues of $T_J$. Let $\\lambda_k(T_J)$ be the $k$-th eigenvalue of $T_J$. We apply $T_J$ to an eigenvector $v_k$ of $A$:\n$$ T_J v_k = (I - D^{-1}A) v_k = I v_k - D^{-1} (A v_k) $$\nSince $v_k$ is an eigenvector of $A$ with eigenvalue $\\mu_k$, we have $A v_k = \\mu_k v_k$.\n$$ T_J v_k = v_k - D^{-1} (\\mu_k v_k) = v_k - \\mu_k (D^{-1} v_k) $$\nSubstituting the expression for $D^{-1}$:\n$$ T_J v_k = v_k - \\mu_k \\left(\\frac{h^2}{2} I\\right) v_k = v_k - \\frac{\\mu_k h^2}{2} v_k = \\left(1 - \\frac{\\mu_k h^2}{2}\\right) v_k $$\nThis shows that $v_k$ is also an eigenvector of $T_J$, and the corresponding eigenvalue $\\lambda_k(T_J)$ is given by:\n$$ \\lambda_k(T_J) = 1 - \\frac{\\mu_k h^2}{2} $$\nNow, we substitute the expression for $\\mu_k$:\n$$ \\lambda_k(T_J) = 1 - \\frac{h^2}{2} \\left( \\frac{4}{h^2} \\sin^2\\left(\\frac{k \\pi h}{2}\\right) \\right) $$\nThe terms $h^2$ cancel out:\n$$ \\lambda_k(T_J) = 1 - 2 \\sin^2\\left(\\frac{k \\pi h}{2}\\right) $$\nFinally, we use the trigonometric double-angle identity $\\cos(2\\theta) = 1 - 2\\sin^2(\\theta)$. With $\\theta = \\frac{k \\pi h}{2}$, we obtain:\n$$ \\lambda_k(T_J) = \\cos\\left(2 \\cdot \\frac{k \\pi h}{2}\\right) = \\cos(k \\pi h) $$\nThis is the closed-form analytic expression for the $k$-th eigenvalue of the Jacobi iteration matrix $T_J$ as a function of the mode index $k$ and the grid spacing $h$.",
            "answer": "$$\n\\boxed{\\cos(k \\pi h)}\n$$"
        },
        {
            "introduction": "While simple iterative methods can be used as standalone solvers, their real power in modern CFD is often unlocked when they are used as preconditioners for more sophisticated Krylov subspace methods. This practice explores Jacobi's role as a preconditioner for the Conjugate Gradient (PCG) method applied to a 1D diffusion-reaction problem. You will use the Gershgorin circle theorem to bound the eigenvalues of the preconditioned matrix, thereby estimating the improvement in the system's condition number and predicting the acceleration in solver convergence .",
            "id": "3338122",
            "problem": "Consider the symmetric positive definite linear system arising from a standard second-order centered finite-difference discretization of a steady one-dimensional diffusionâ€“reaction operator on a uniform grid with Dirichlet boundary conditions. The discrete operator on the interior grid points is represented by an $n \\times n$ tridiagonal matrix $A$ with entries $A_{ii} = 2 + \\sigma$ and $A_{i,i\\pm 1} = -1$, where $\\sigma  0$ is a dimensionless parameter determined by the reaction strength and the grid spacing. Let $M = D = \\mathrm{diag}(A)$ denote the Jacobi preconditioner. Although other preconditioners such as Successive Over-Relaxation (SOR) exist, focus here exclusively on the Jacobi preconditioner.\n\n(a) Starting from the Gershgorin circle theorem and the fact that $A$ is symmetric positive definite, derive lower and upper bounds on the eigenvalues of the preconditioned matrix $M^{-1}A$ that depend only on $\\sigma$ (and not on $n$). From these bounds, obtain an explicit upper bound on the spectral condition number $\\kappa(M^{-1}A)$ as a function of $\\sigma$.\n\n(b) Using a well-tested worst-case convergence bound for the Preconditioned Conjugate Gradient (PCG) method (Conjugate Gradient (CG) applied to the left-preconditioned system) in terms of the spectral condition number, determine, for the specific value $\\sigma = 1$, the minimal integer $k$ such that the $A$-norm of the error is guaranteed to be reduced by at least a factor of $10^{-8}$ after $k$ PCG iterations with the Jacobi preconditioner $M = D$, uniformly in $n$.\n\nReport as your final answer only the value of $k$ (no units and no additional text).",
            "solution": "The problem is divided into two parts. Part (a) requires the derivation of bounds on the eigenvalues of the Jacobi-preconditioned matrix and its spectral condition number. Part (b) asks for the minimum number of Preconditioned Conjugate Gradient (PCG) iterations required to achieve a specified error reduction for a given parameter value.\n\nThe linear system involves the $n \\times n$ matrix $A$ defined by its entries:\n$$\nA_{ij} = \\begin{cases}\n2 + \\sigma  \\text{if } i = j \\\\\n-1  \\text{if } |i - j| = 1 \\\\\n0  \\text{otherwise}\n\\end{cases}\n$$\nwhere $\\sigma  0$. The matrix $A$ is symmetric. For $\\sigma  0$, it is also strictly diagonally dominant, which, combined with its symmetry and positive diagonal entries, guarantees that $A$ is positive definite.\n\nThe Jacobi preconditioner is given by the diagonal of $A$, $M = D = \\mathrm{diag}(A)$.\nSince $A_{ii} = 2 + \\sigma$ for all $i=1, \\dots, n$, the preconditioner is $M = (2 + \\sigma)I$, where $I$ is the $n \\times n$ identity matrix. The inverse of the preconditioner is $M^{-1} = \\frac{1}{2 + \\sigma}I$.\n\nThe preconditioned matrix is $M^{-1}A$. Its eigenvalues, which we denote by $\\mu$, determine the convergence of the PCG method.\n\n**(a) Eigenvalue Bounds and Condition Number**\n\nWe are tasked to find bounds on the eigenvalues of $M^{-1}A$ using the Gershgorin circle theorem. Let $\\lambda$ be an eigenvalue of $A$. Then the corresponding eigenvalue of $M^{-1}A = \\frac{1}{2+\\sigma}A$ is $\\mu = \\frac{\\lambda}{2+\\sigma}$. We first find bounds for the eigenvalues $\\lambda$ of $A$.\n\nThe Gershgorin circle theorem states that for a matrix $B \\in \\mathbb{C}^{n \\times n}$, every eigenvalue of $B$ lies within at least one of the Gershgorin disks $D(B_{ii}, R_i)$, where the center is $B_{ii}$ and the radius is $R_i = \\sum_{j \\neq i} |B_{ij}|$. Since $A$ is a real symmetric matrix, its eigenvalues are real, so they lie in the union of the real intervals $[A_{ii} - R_i, A_{ii} + R_i]$.\n\nFor the matrix $A$:\nThe diagonal entries are $A_{ii} = 2 + \\sigma$.\nThe radii of the Gershgorin disks are:\n- For the first and last rows ($i=1$ and $i=n$): $R_1 = |A_{1,2}| = |-1| = 1$ and $R_n = |A_{n,n-1}| = |-1| = 1$. The corresponding intervals are $[(2+\\sigma) - 1, (2+\\sigma) + 1] = [1+\\sigma, 3+\\sigma]$.\n- For the interior rows ($i=2, \\dots, n-1$): $R_i = |A_{i,i-1}| + |A_{i,i+1}| = |-1| + |-1| = 2$. The corresponding intervals are $[(2+\\sigma) - 2, (2+\\sigma) + 2] = [\\sigma, 4+\\sigma]$.\n\nThe set of all eigenvalues of $A$, denoted $\\mathrm{spec}(A)$, is contained in the union of these intervals:\n$$ \\mathrm{spec}(A) \\subseteq [1+\\sigma, 3+\\sigma] \\cup [\\sigma, 4+\\sigma] = [\\sigma, 4+\\sigma] $$\nThis gives us lower and upper bounds for any eigenvalue $\\lambda$ of $A$ that are independent of $n$:\n$$ \\sigma \\le \\lambda \\le 4+\\sigma $$\nFrom this, we have $\\lambda_{\\min}(A) \\ge \\sigma$ and $\\lambda_{\\max}(A) \\le 4+\\sigma$.\n\nThe eigenvalues $\\mu$ of the preconditioned matrix $M^{-1}A$ are given by $\\mu = \\lambda / (2+\\sigma)$. We can now bound these eigenvalues:\n$$ \\mu_{\\min} = \\frac{\\lambda_{\\min}(A)}{2+\\sigma} \\ge \\frac{\\sigma}{2+\\sigma} $$\n$$ \\mu_{\\max} = \\frac{\\lambda_{\\max}(A)}{2+\\sigma} \\le \\frac{4+\\sigma}{2+\\sigma} $$\nThese are the required lower and upper bounds on the eigenvalues of $M^{-1}A$, depending only on $\\sigma$.\n\nThe spectral condition number of the preconditioned matrix is $\\kappa(M^{-1}A) = \\frac{\\mu_{\\max}}{\\mu_{\\min}}$. We can obtain an upper bound for this condition number using our eigenvalue bounds:\n$$ \\kappa(M^{-1}A) \\le \\frac{\\text{upper bound on } \\mu_{\\max}}{\\text{lower bound on } \\mu_{\\min}} = \\frac{(4+\\sigma)/(2+\\sigma)}{\\sigma/(2+\\sigma)} = \\frac{4+\\sigma}{\\sigma} $$\nThis provides an explicit upper bound on the spectral condition number as a function of $\\sigma$, independent of $n$.\n\n**(b) PCG Iteration Count**\n\nThe standard worst-case convergence bound for the PCG method relates the $A$-norm of the error at iteration $k$, $\\|e_k\\|_A$, to the initial error's $A$-norm, $\\|e_0\\|_A$, and the spectral condition number $\\kappa = \\kappa(M^{-1}A)$ of the preconditioned system:\n$$ \\|e_k\\|_A \\le 2 \\left( \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1} \\right)^k \\|e_0\\|_A $$\nWe want to find the minimal integer $k$ such that the error is reduced by a factor of at least $10^{-8}$, i.e., $\\frac{\\|e_k\\|_A}{\\|e_0\\|_A} \\le 10^{-8}$. This requires\n$$ 2 \\left( \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1} \\right)^k \\le 10^{-8} $$\nThe problem specifies $\\sigma = 1$. Using the bound derived in part (a), we find an upper bound on the condition number for this case:\n$$ \\kappa \\le \\frac{4+1}{1} = 5 $$\nTo guarantee the error reduction for any $n$, we must use this worst-case (largest) value for the condition number, $\\kappa = 5$. The inequality becomes:\n$$ 2 \\left( \\frac{\\sqrt{5} - 1}{\\sqrt{5} + 1} \\right)^k \\le 10^{-8} $$\nLet's solve for $k$. First, we isolate the term raised to the power of $k$:\n$$ \\left( \\frac{\\sqrt{5} - 1}{\\sqrt{5} + 1} \\right)^k \\le \\frac{1}{2} \\times 10^{-8} $$\nTaking the natural logarithm of both sides:\n$$ k \\ln\\left( \\frac{\\sqrt{5} - 1}{\\sqrt{5} + 1} \\right) \\le \\ln(0.5 \\times 10^{-8}) $$\nThe term inside the logarithm on the left is less than $1$, so its logarithm is negative. Dividing by it will reverse the inequality sign:\n$$ k \\ge \\frac{\\ln(0.5 \\times 10^{-8})}{\\ln\\left( \\frac{\\sqrt{5} - 1}{\\sqrt{5} + 1} \\right)} $$\nLet's simplify the expressions.\nThe numerator is $\\ln(0.5 \\times 10^{-8}) = \\ln(1/ (2 \\times 10^8)) = -\\ln(2 \\times 10^8) = -(\\ln(2) + 8\\ln(10))$.\nFor the denominator's argument, we rationalize it:\n$$ \\frac{\\sqrt{5} - 1}{\\sqrt{5} + 1} = \\frac{(\\sqrt{5} - 1)(\\sqrt{5} - 1)}{(\\sqrt{5} + 1)(\\sqrt{5} - 1)} = \\frac{5 - 2\\sqrt{5} + 1}{5 - 1} = \\frac{6 - 2\\sqrt{5}}{4} = \\frac{3 - \\sqrt{5}}{2} $$\nThe logarithm in the denominator is $\\ln\\left(\\frac{3-\\sqrt{5}}{2}\\right)$.\nThus, the inequality for $k$ is:\n$$ k \\ge \\frac{-(\\ln(2) + 8\\ln(10))}{\\ln\\left(\\frac{3-\\sqrt{5}}{2}\\right)} $$\nLet's evaluate this expression numerically:\n$\\ln(2) \\approx 0.693147$\n$\\ln(10) \\approx 2.302585$\n$\\sqrt{5} \\approx 2.236068$\nNumerator: $-(\\ln(2) + 8\\ln(10)) \\approx -(0.693147 + 8 \\times 2.302585) = -(0.693147 + 18.42068) = -19.113827$.\nDenominator: $\\ln\\left(\\frac{3-2.236068}{2}\\right) = \\ln\\left(\\frac{0.763932}{2}\\right) = \\ln(0.381966) \\approx -0.962424$.\n$$ k \\ge \\frac{-19.113827}{-0.962424} \\approx 19.8599 $$\nSince $k$ must be an integer, the minimal number of iterations required is the smallest integer greater than or equal to $19.8599$.\n$$ k = 20 $$\nThis result is uniform in $n$ because the condition number bound used was independent of $n$.",
            "answer": "$$\\boxed{20}$$"
        },
        {
            "introduction": "In the context of state-of-the-art solvers like multigrid, simple iterative methods like weighted Jacobi play a specialized role as \"smoothers.\" A smoother's job is not to solve the system, but to efficiently damp high-frequency components of the error. This final exercise uses Local Fourier Analysis (LFA) to analyze the weighted Jacobi method as a smoother for the 2D Poisson problem, guiding you to find the optimal relaxation parameter $\\omega$ that maximizes its smoothing efficiency, which is the key to multigrid performance .",
            "id": "3338167",
            "problem": "Consider the pressure Poisson subproblem in incompressible flow, where the discrete operator is the standard two-dimensional Laplacian on a uniform Cartesian grid of spacing $h$, built from the five-point stencil with central coefficient $4/h^{2}$ and four nearest-neighbor coefficients $-1/h^{2}$. In multigrid preconditioning for computational fluid dynamics, the weighted Jacobi smoother with relaxation parameter $\\omega$ acts on the error $e^{(k)}$ via the iteration $e^{(k+1)} = S_{\\omega} e^{(k)}$, where $S_{\\omega} = I - \\omega D^{-1} A$ and $D$ is the diagonal of $A$. Using Local Fourier Analysis (LFA), treat the grid as infinite and analyze the action of $S_{\\omega}$ on Fourier modes $e^{\\mathrm{i}(\\theta_{x} i + \\theta_{y} j)}$ with frequencies $(\\theta_{x},\\theta_{y}) \\in [-\\pi,\\pi]^{2}$.\n\nStarting from the fundamental definitions of the discrete symbol of $A$ and the iteration matrix $S_{\\omega}$, do the following:\n\n- Derive the Fourier symbol $\\widehat{A}(\\theta_{x},\\theta_{y})$ of the discrete Laplacian $A$.\n- Derive the Fourier symbol $\\widehat{S}_{\\omega}(\\theta_{x},\\theta_{y})$ of the weighted Jacobi error-propagation operator $S_{\\omega}$.\n- Define the high-frequency set corresponding to factor-$2$ coarsening as those modes for which both directional frequencies are high, namely $\\theta_{x} \\in [\\pi/2,\\pi] \\cup [-\\pi,-\\pi/2]$ and $\\theta_{y} \\in [\\pi/2,\\pi] \\cup [-\\pi,-\\pi/2]$. Using this set, compute the smoothing factor $\\mu(\\omega)$, defined as the supremum over the high-frequency set of the magnitude of $\\widehat{S}_{\\omega}(\\theta_{x},\\theta_{y})$.\n- Determine the value of the relaxation parameter $\\omega$ that minimizes $\\mu(\\omega)$ over $\\omega  0$. Briefly explain, in terms of your derived expression, why this choice optimizes high-frequency error damping.\n\nExpress the final answer as the exact value of the optimal $\\omega$ with no rounding and no units.",
            "solution": "The problem asks for the optimal relaxation parameter $\\omega$ for a weighted Jacobi smoother applied to the 2D discrete Laplacian operator, based on a Local Fourier Analysis (LFA) with a specific definition of the high-frequency modes. The validation step confirms the problem is well-posed and scientifically sound. We proceed with the solution by following the specified tasks.\n\nFirst, we derive the Fourier symbol of the discrete Laplacian operator $A$. The operator is defined by the five-point stencil with coefficients $(\\frac{4}{h^2}, -\\frac{1}{h^2}, -\\frac{1}{h^2}, -\\frac{1}{h^2}, -\\frac{1}{h^2})$. Its action on a grid function $u$ at a grid point $(x_i, y_j) = (ih, jh)$ is given by:\n$$ (A u)_{i,j} = \\frac{1}{h^2} (4 u_{i,j} - u_{i+1,j} - u_{i-1,j} - u_{i,j+1} - u_{i,j-1}) $$\nIn Local Fourier Analysis, we analyze the action of the operator on a single Fourier mode, $u_{i,j} = e^{\\mathrm{i}(k_x x_i + k_y y_j)} = e^{\\mathrm{i}(k_x ih + k_y jh)}$. It is conventional to define dimensionless frequencies $\\theta_x = k_x h$ and $\\theta_y = k_y h$, so the mode is $e^{\\mathrm{i}(\\theta_x i + \\theta_y j)}$. The frequencies $\\theta_x, \\theta_y$ are in the range $[-\\pi, \\pi]$. Applying $A$ to this mode yields:\n$$ (A e^{\\mathrm{i}(\\theta_x i + \\theta_y j)})_{i,j} = \\frac{1}{h^2} [4 e^{\\mathrm{i}(\\theta_x i + \\theta_y j)} - e^{\\mathrm{i}(\\theta_x (i+1) + \\theta_y j)} - e^{\\mathrm{i}(\\theta_x (i-1) + \\theta_y j)} - e^{\\mathrm{i}(\\theta_x i + \\theta_y (j+1))} - e^{\\mathrm{i}(\\theta_x i + \\theta_y (j-1))}] $$\nFactoring out the mode $e^{\\mathrm{i}(\\theta_x i + \\theta_y j)}$ from the right-hand side gives:\n$$ (A e^{\\mathrm{i}(\\theta_x i + \\theta_y j)})_{i,j} = \\frac{1}{h^2} [4 - e^{\\mathrm{i}\\theta_x} - e^{-\\mathrm{i}\\theta_x} - e^{\\mathrm{i}\\theta_y} - e^{-\\mathrm{i}\\theta_y}] e^{\\mathrm{i}(\\theta_x i + \\theta_y j)} $$\nUsing Euler's identity $e^{\\mathrm{i}\\phi} + e^{-\\mathrm{i}\\phi} = 2\\cos(\\phi)$, the expression in the brackets simplifies:\n$$ [4 - 2\\cos(\\theta_x) - 2\\cos(\\theta_y)] = 2(1 - \\cos(\\theta_x)) + 2(1 - \\cos(\\theta_y)) $$\nUsing the half-angle trigonometric identity $1 - \\cos(\\phi) = 2\\sin^2(\\frac{\\phi}{2})$, we get:\n$$ 2(2\\sin^2(\\frac{\\theta_x}{2})) + 2(2\\sin^2(\\frac{\\theta_y}{2})) = 4(\\sin^2(\\frac{\\theta_x}{2}) + \\sin^2(\\frac{\\theta_y}{2})) $$\nThe action of $A$ on the Fourier mode is thus a scalar multiplication. This scalar is the Fourier symbol (or eigenvalue) $\\widehat{A}(\\theta_x, \\theta_y)$:\n$$ \\widehat{A}(\\theta_x, \\theta_y) = \\frac{4}{h^2} \\left[ \\sin^2\\left(\\frac{\\theta_x}{2}\\right) + \\sin^2\\left(\\frac{\\theta_y}{2}\\right) \\right] $$\n\nNext, we derive the Fourier symbol of the weighted Jacobi error-propagation operator, $S_{\\omega} = I - \\omega D^{-1} A$. The matrix $D$ is the diagonal of $A$. For the given stencil, the diagonal entry is the coefficient of $u_{i,j}$, which is $D_{ii} = \\frac{4}{h^2}$. On an infinite grid, $D$ can be treated as a scalar operator $D = \\frac{4}{h^2} I$. The Fourier symbol of an algebraic combination of operators is the same algebraic combination of their symbols. The symbol of the identity operator $I$ is $1$, and the symbol of $D^{-1}$ is $(\\frac{4}{h^2})^{-1} = \\frac{h^2}{4}$. Therefore, the symbol of $S_{\\omega}$ is:\n$$ \\widehat{S}_{\\omega}(\\theta_x, \\theta_y) = \\widehat{I} - \\omega \\widehat{D^{-1}} \\widehat{A}(\\theta_x, \\theta_y) $$\n$$ \\widehat{S}_{\\omega}(\\theta_x, \\theta_y) = 1 - \\omega \\left(\\frac{h^2}{4}\\right) \\left( \\frac{4}{h^2} \\left[ \\sin^2\\left(\\frac{\\theta_x}{2}\\right) + \\sin^2\\left(\\frac{\\theta_y}{2}\\right) \\right] \\right) $$\n$$ \\widehat{S}_{\\omega}(\\theta_x, \\theta_y) = 1 - \\omega \\left[ \\sin^2\\left(\\frac{\\theta_x}{2}\\right) + \\sin^2\\left(\\frac{\\theta_y}{2}\\right) \\right] $$\nThis is the amplification factor for the Fourier mode $(\\theta_x, \\theta_y)$ after one iteration of the weighted Jacobi method.\n\nNow, we compute the smoothing factor $\\mu(\\omega)$. The problem defines the high-frequency set for factor-$2$ coarsening as those modes where both directional frequencies are high:\n$$ \\Theta_{HF} = \\{ (\\theta_x, \\theta_y) \\mid (\\theta_x \\in [\\pi/2, \\pi] \\cup [-\\pi, -\\pi/2]) \\land (\\theta_y \\in [\\pi/2, \\pi] \\cup [-\\pi, -\\pi/2]) \\} $$\nDue to the even symmetry of the $\\sin^2$ function, we can simplify the analysis by considering $|\\theta_x| \\in [\\pi/2, \\pi]$ and $|\\theta_y| \\in [\\pi/2, \\pi]$. This implies $|\\theta_x/2| \\in [\\pi/4, \\pi/2]$ and $|\\theta_y/2| \\in [\\pi/4, \\pi/2]$.\nLet $L(\\theta_x, \\theta_y) = \\sin^2(\\frac{\\theta_x}{2}) + \\sin^2(\\frac{\\theta_y}{2})$. The function $\\sin^2(x)$ is monotonically increasing for $x \\in [0, \\pi/2]$. Therefore, for the given range of frequencies:\n$$ \\sin^2\\left(\\frac{|\\theta_x|}{2}\\right) \\in \\left[ \\sin^2\\left(\\frac{\\pi}{4}\\right), \\sin^2\\left(\\frac{\\pi}{2}\\right) \\right] = \\left[ \\left(\\frac{1}{\\sqrt{2}}\\right)^2, 1^2 \\right] = \\left[ \\frac{1}{2}, 1 \\right] $$\n$$ \\sin^2\\left(\\frac{|\\theta_y|}{2}\\right) \\in \\left[ \\frac{1}{2}, 1 \\right] $$\nThe range of the sum $L(\\theta_x, \\theta_y)$ over the set $\\Theta_{HF}$ is therefore:\n$$ L(\\theta_x, \\theta_y) \\in \\left[ \\frac{1}{2} + \\frac{1}{2}, 1 + 1 \\right] = [1, 2] $$\nThe smoothing factor $\\mu(\\omega)$ is the supremum of the magnitude of the amplification factor over this set of modes:\n$$ \\mu(\\omega) = \\sup_{(\\theta_x, \\theta_y) \\in \\Theta_{HF}} |\\widehat{S}_{\\omega}(\\theta_x, \\theta_y)| = \\sup_{L \\in [1, 2]} |1 - \\omega L| $$\nThe function $f(L) = |1 - \\omega L|$ is a linear function of $L$ (for a fixed $\\omega  0$) within the absolute value. The supremum of its magnitude over the interval $[1, 2]$ must be attained at one of the endpoints, $L=1$ or $L=2$.\n$$ \\mu(\\omega) = \\max(|1 - \\omega \\cdot 1|, |1 - \\omega \\cdot 2|) = \\max(|1 - \\omega|, |1 - 2\\omega|) $$\n\nFinally, we determine the optimal value of $\\omega$ that minimizes $\\mu(\\omega)$. We seek to solve the minimax problem:\n$$ \\min_{\\omega  0} \\max(|1 - \\omega|, |1 - 2\\omega|) $$\nThe minimum value of the maximum of two functions often occurs where the functions are equal. We set the magnitudes equal:\n$$ |1 - \\omega| = |1 - 2\\omega| $$\nThis equality holds if either $1 - \\omega = 1 - 2\\omega$, which implies $\\omega = 0$ (a trivial case we disregard as per $\\omega0$), or if $1 - \\omega = -(1 - 2\\omega)$. We solve the second case:\n$$ 1 - \\omega = -1 + 2\\omega $$\n$$ 2 = 3\\omega $$\n$$ \\omega = \\frac{2}{3} $$\nTo confirm this is a minimum, we can analyze the behavior of $\\mu(\\omega)$ around this point. For $\\omega  1/2$, $|1-2\\omega|=2\\omega-1$. For $\\omega1$, $|1-\\omega|=1-\\omega$.\n- If $1/2  \\omega  2/3$, then $3\\omega  2$, so $2\\omega-1  1-\\omega$. Thus, $\\mu(\\omega) = 1-\\omega$, which is a decreasing function of $\\omega$.\n- If $2/3  \\omega  1$, then $3\\omega  2$, so $2\\omega-1  1-\\omega$. Thus, $\\mu(\\omega) = 2\\omega-1$, which is an increasing function of $\\omega$.\nSince $\\mu(\\omega)$ decreases to the left of $\\omega=2/3$ and increases to the right, $\\omega = 2/3$ is indeed the value that minimizes the smoothing factor $\\mu(\\omega)$.\n\nThe reason this choice of $\\omega$ optimizes high-frequency damping is that it balances the damping of the extremal modes in the high-frequency set. The amplification factor is $\\widehat{S}_{\\omega} = 1 - \\omega L$. The quantity $L$ is the eigenvalue of the scaled operator $D^{-1}A$, which ranges from $L_{min}=1$ to $L_{max}=2$ for the specified high-frequency modes. The optimal $\\omega$ ensures that the magnitudes of the amplification factors for these two extremal cases, $|1-\\omega L_{min}|$ and $|1-\\omega L_{max}|$, are equal. For $\\omega = 2/3$, both are equal to $|1-2/3|=1/3$ and $|1-4/3|=1/3$. Any other choice of $\\omega$ would increase the amplification factor for one of these extremal modes, thereby increasing the maximum amplification factor over the entire high-frequency set and resulting in a poorer smoothing factor.\n\nThe optimal value of the relaxation parameter is therefore $\\frac{2}{3}$.",
            "answer": "$$\\boxed{\\frac{2}{3}}$$"
        }
    ]
}