{
    "hands_on_practices": [
        {
            "introduction": "Spectral methods build a bridge between continuous functions and their discrete representations. A crucial part of this bridge is numerical quadrature, which approximates integrals using weighted sums at collocation points. This first practice  challenges you to explore the accuracy of this approximation by relating the continuous energy norm, $\\int_{-1}^{1} |u(x)|^{2} \\, dx$, to its discrete counterpart computed with Clenshaw-Curtis quadrature. By analyzing a simple case where the function $u(x)$ is a single Chebyshev polynomial, you will uncover the precise conditions under which the discrete and continuous energies are identical, a foundational concept for ensuring the fidelity of numerical simulations.",
            "id": "3300679",
            "problem": "In computational fluid dynamics (CFD) on bounded domains, Chebyshev-spectral methods often represent fields in terms of Chebyshev polynomials and measure solution energy by the square of the standard $L^{2}$ norm. Consider the one-dimensional bounded domain $[-1,1]$, and define the continuous energy of a scalar field $u$ by\n$$\nE \\equiv \\|u\\|^{2} = \\int_{-1}^{1} |u(x)|^{2} \\, dx.\n$$\nIn practical spectral collocation, a quadrature-based discrete energy is used. Let the Chebyshev-Gauss-Lobatto (CGL) nodes be $x_{j} = \\cos\\!\\left(\\frac{j\\pi}{N}\\right)$ for $j=0,1,\\dots,N$, and let $\\{w_{j}\\}_{j=0}^{N}$ be the Clenshaw-Curtis (CC) quadrature weights for approximating the unweighted integral $\\int_{-1}^{1} f(x)\\,dx$ via\n$$\nQ_{N}(f) \\equiv \\sum_{j=0}^{N} w_{j}\\, f(x_{j}).\n$$\nDefine the quadrature-based discrete energy by\n$$\nE_{N} \\equiv \\sum_{j=0}^{N} w_{j}\\, |u(x_{j})|^{2}.\n$$\n\nStarting from the definitions of the Chebyshev polynomials of the first kind $T_{m}(x) = \\cos\\!\\left(m\\arccos x\\right)$, the change of variables $x=\\cos\\theta$ that maps $[-1,1]$ to $[0,\\pi]$ with $dx=-\\sin\\theta\\, d\\theta$, and the fundamental orthogonality of trigonometric functions on $[0,\\pi]$, do the following:\n\n1. For $u(x) = T_{m}(x)$ with a fixed integer $m \\ge 1$, compute the exact continuous energy $E$.\n\n2. Using only the structure of Chebyshev expansions and the fact that the Clenshaw-Curtis quadrature with $N+1$ CGL nodes is exact for any algebraic polynomial of degree at most $2N-1$, determine a condition on $N$ (in terms of $m$) under which $E_{N} = E$ for this $u$.\n\n3. Under the condition you found in part 2, provide the common value of $E_{N}$ and $E$ as a single closed-form expression in $m$.\n\nYour final answer must be the closed-form expression from part 3. No units are required. Do not round; provide an exact expression.",
            "solution": "The problem asks for three components: the exact continuous energy $E$ for a specific field $u(x)$, the condition on the number of quadrature points $N+1$ for the discrete energy $E_N$ to equal $E$, and the resulting common value.\n\nFirst, we compute the exact continuous energy $E$ for the scalar field $u(x) = T_{m}(x)$, where $T_m(x)$ is the Chebyshev polynomial of the first kind of degree $m$, and $m$ is a fixed integer with $m \\ge 1$. The continuous energy is defined as:\n$$\nE = \\int_{-1}^{1} |u(x)|^{2} \\, dx = \\int_{-1}^{1} (T_{m}(x))^{2} \\, dx\n$$\nSince $x \\in [-1,1]$, $T_m(x)$ is real-valued, and thus $|T_m(x)|^2 = (T_m(x))^2$.\n\nTo evaluate this integral, we can express the integrand, $(T_m(x))^2$, as a linear combination of Chebyshev polynomials. Using the definition $T_m(x) = \\cos(m\\arccos x)$, we can make the substitution $x = \\cos\\theta$. This gives $T_m(\\cos\\theta) = \\cos(m\\theta)$. The integrand becomes:\n$$\n(T_m(x))^2 \\to (\\cos(m\\theta))^2\n$$\nUsing the trigonometric identity $\\cos^2\\alpha = \\frac{1}{2}(1 + \\cos(2\\alpha))$, we have:\n$$\n(\\cos(m\\theta))^2 = \\frac{1}{2} (1 + \\cos(2m\\theta))\n$$\nRecognizing that $1 = T_0(x)$ and $\\cos(2m\\theta) = T_{2m}(\\cos\\theta) = T_{2m}(x)$, we can write the expansion for $(T_m(x))^2$ in the Chebyshev basis:\n$$\n(T_m(x))^2 = \\frac{1}{2} T_0(x) + \\frac{1}{2} T_{2m}(x)\n$$\nNow we can substitute this back into the integral for $E$:\n$$\nE = \\int_{-1}^{1} \\left( \\frac{1}{2} T_0(x) + \\frac{1}{2} T_{2m}(x) \\right) dx = \\frac{1}{2} \\int_{-1}^{1} T_0(x) \\, dx + \\frac{1}{2} \\int_{-1}^{1} T_{2m}(x) \\, dx\n$$\nWe evaluate each integral separately. For the first integral:\n$$\n\\int_{-1}^{1} T_0(x) \\, dx = \\int_{-1}^{1} 1 \\, dx = [x]_{-1}^{1} = 1 - (-1) = 2\n$$\nFor the second integral, we evaluate the general case $\\int_{-1}^{1} T_k(x) \\, dx$ for an integer $k > 0$. Using the substitution $x = \\cos\\theta$, for which $dx = -\\sin\\theta \\, d\\theta$:\n$$\n\\int_{-1}^{1} T_k(x) \\, dx = \\int_{\\pi}^{0} T_k(\\cos\\theta) (-\\sin\\theta) \\, d\\theta = \\int_{0}^{\\pi} \\cos(k\\theta) \\sin\\theta \\, d\\theta\n$$\nUsing the product-to-sum identity $\\cos A \\sin B = \\frac{1}{2}(\\sin(A+B) - \\sin(A-B))$:\n$$\n\\int_{0}^{\\pi} \\cos(k\\theta) \\sin\\theta \\, d\\theta = \\frac{1}{2} \\int_{0}^{\\pi} \\left( \\sin((k+1)\\theta) - \\sin((k-1)\\theta) \\right) d\\theta\n$$\nFor an integer $n \\neq 0$, $\\int_0^\\pi \\sin(n\\theta) d\\theta = \\left[-\\frac{\\cos(n\\theta)}{n}\\right]_0^\\pi = \\frac{1 - \\cos(n\\pi)}{n} = \\frac{1 - (-1)^n}{n}$.\nIf $k$ is an odd integer greater than $1$, both $k+1$ and $k-1$ are non-zero even integers. In this case, $1 - (-1)^{k+1} = 0$ and $1 - (-1)^{k-1} = 0$, so the integral is $0$. If $k=1$, the integral is $\\frac{1}{2}\\int_0^\\pi \\sin(2\\theta) d\\theta = 0$. So for any odd $k \\ge 1$, the integral is $0$.\nIf $k$ is an even integer ($k \\ge 2$), both $k+1$ and $k-1$ are odd. Thus $1 - (-1)^{k+1} = 2$ and $1 - (-1)^{k-1} = 2$. The integral becomes:\n$$\n\\frac{1}{2} \\left( \\frac{2}{k+1} - \\frac{2}{k-1} \\right) = \\frac{1}{k+1} - \\frac{1}{k-1} = \\frac{(k-1) - (k+1)}{(k+1)(k-1)} = \\frac{-2}{k^2-1}\n$$\nIn our case, we need to evaluate the integral for $k = 2m$. Since $m \\ge 1$, $k=2m$ is an even integer greater than or equal to $2$. Therefore:\n$$\n\\int_{-1}^{1} T_{2m}(x) \\, dx = \\frac{-2}{(2m)^2 - 1} = \\frac{-2}{4m^2 - 1}\n$$\nSubstituting the values of the integrals back into the expression for $E$:\n$$\nE = \\frac{1}{2}(2) + \\frac{1}{2} \\left( \\frac{-2}{4m^2 - 1} \\right) = 1 - \\frac{1}{4m^2 - 1} = \\frac{(4m^2 - 1) - 1}{4m^2 - 1} = \\frac{4m^2 - 2}{4m^2 - 1}\n$$\nThis completes the first part of the problem.\n\nSecond, we determine the condition on $N$ under which the discrete energy $E_N$ equals the continuous energy $E$. The discrete energy $E_N$ is defined by the Clenshaw-Curtis quadrature rule applied to the function $|u(x)|^2$:\n$$\nE_{N} \\equiv \\sum_{j=0}^{N} w_{j}\\, |u(x_{j})|^{2} = Q_N(|u|^2)\n$$\nThe equality $E_N = E$ is equivalent to the statement that the quadrature rule is exact for the integrand, i.e.,\n$$\nQ_N(|u|^2) = \\int_{-1}^{1} |u(x)|^{2} \\, dx\n$$\nThe integrand is $f(x) = |u(x)|^2 = (T_m(x))^2$. As shown earlier, $(T_m(x))^2 = \\frac{1}{2}T_0(x) + \\frac{1}{2}T_{2m}(x)$. Since $T_k(x)$ is an algebraic polynomial of degree $k$, the integrand is an algebraic polynomial of degree $2m$. The problem states that the Clenshaw-Curtis quadrature with $N+1$ nodes is exact for any algebraic polynomial of degree at most $2N-1$. For the quadrature to be exact for our integrand, the degree of the integrand must be less than or equal to the maximum degree for which the rule is exact. This gives the condition:\n$$\n\\text{degree}((T_m(x))^2) \\le 2N-1\n$$\nSince $\\text{degree}((T_m(x))^2) = 2m$, the condition on $N$ is:\n$$\n2m \\le 2N-1\n$$\n\nThird, under this condition, we have $E_N = E$. The question asks for this common value. This is precisely the value of $E$ we computed in the first part. The closed-form expression for this energy, valid for any integer $m \\ge 1$, is:\n$$\nE = E_N = \\frac{4m^2 - 2}{4m^2 - 1}\n$$\nThis is the final required expression.",
            "answer": "$$\\boxed{\\frac{4m^{2}-2}{4m^{2}-1}}$$"
        },
        {
            "introduction": "Having established the principles of quadrature, we now move to solving a full boundary value problem. This practice  guides you through the implementation of a Chebyshev collocation solver for the Poisson equation with Neumann boundary conditions, a common model in fluid dynamics. You will confront a classic challenge in spectral methods: the singular linear system that arises from Neumann conditions, and learn to resolve this rank deficiency using two robust numerical techniques. This exercise is essential for developing the practical skills needed to construct and stabilize spectral solvers.",
            "id": "3300690",
            "problem": "Consider the one-dimensional Poisson equation with homogeneous Neumann boundary conditions on the bounded domain $[-1,1]$,\n$$\n\\frac{d^2 u}{dx^2} = f(x), \\quad x \\in [-1,1], \\quad \\text{with} \\quad \\frac{du}{dx}(-1) = 0, \\quad \\frac{du}{dx}(1) = 0.\n$$\nIn Chebyshev-spectral collocation, use the Chebyshev–Gauss–Lobatto nodes $x_j = \\cos\\left(\\frac{\\pi j}{N}\\right)$ for $j=0,1,\\dots,N$ and the standard Chebyshev first and second differentiation matrices built on these nodes. Construct the collocation linear system as follows: enforce the second derivative relation at the interior points $j=1,\\dots,N-1$ and enforce the Neumann boundary conditions at the endpoints by replacing the first and last rows of the operator with the first-derivative rows evaluated at the endpoints. This yields a square linear system\n$$\nA u = b,\n$$\nwhere $A \\in \\mathbb{R}^{(N+1)\\times(N+1)}$ is formed from the first and second Chebyshev differentiation matrices and $b \\in \\mathbb{R}^{N+1}$ contains the samples $f(x_j)$ at the interior points and zeros at the boundaries corresponding to the homogeneous Neumann boundary conditions. Because of the Neumann boundary conditions, the operator $A$ is rank-deficient with a one-dimensional nullspace spanned by the constant vector; thus, the system is solvable only if $b$ belongs to the range of $A$ and the solution is unique only up to an additive constant.\n\nYour task is to implement two solvers for this system and compare their outputs:\n- A low-rank augmented solver that resolves the rank deficiency by adding a single linear constraint to fix the additive constant. Specifically, augment the system with the constraint $\\sum_{j=0}^{N} u_j = 0$ using a Lagrange multiplier, forming the block system\n$$\n\\begin{pmatrix}\nA & w \\\\\nw^\\top & 0\n\\end{pmatrix}\n\\begin{pmatrix}\nu \\\\\n\\lambda\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nb \\\\\n0\n\\end{pmatrix},\n$$\nwhere $w \\in \\mathbb{R}^{N+1}$ is the vector of all ones and $\\lambda \\in \\mathbb{R}$ is the Lagrange multiplier.\n- A Singular Value Decomposition (SVD) based solver. Compute the singular value decomposition $A = U \\Sigma V^\\top$, project $b$ onto the range of $A$ by removing its component along the left-nullspace vector associated with the smallest singular value, and then compute the minimum-norm solution using the Moore–Penrose pseudoinverse:\n$$\nb_{\\text{proj}} = b - u_0 (u_0^\\top b), \\quad u_{\\text{svd}} = \\sum_{i:\\sigma_i > \\varepsilon} \\frac{U_{\\cdot, i}^\\top b_{\\text{proj}}}{\\sigma_i} V_{\\cdot, i},\n$$\nwhere $u_0$ is the left singular vector corresponding to the smallest singular value $\\sigma_{\\min}$, $\\varepsilon$ is a small threshold, and $U_{\\cdot, i}$, $V_{\\cdot, i}$ denote the $i$-th columns of $U$ and $V$, respectively.\n\nStart from well-tested definitions in Chebyshev-spectral methods: Chebyshev–Gauss–Lobatto nodes, and the known formulas for first and second differentiation matrices on these nodes. Do not use shortcut formulas for the final solutions; derive the collocation system and explain the reasoning for handling rank deficiency. Before solving, ensure solvability by projecting $b$ onto the range of $A$ with respect to the discrete left-nullspace vector obtained from SVD, as in the formula above.\n\nImplement both solvers and compute the following quantities for each test case:\n- The infinity norm of the difference between the two computed solutions, namely $\\|u_{\\text{aug}} - u_{\\text{svd}}\\|_{\\infty}$.\n- The infinity norm of the collocation residual for the SVD-based solution, namely $\\|A u_{\\text{svd}} - b_{\\text{proj}}\\|_{\\infty}$.\n- The maximum absolute boundary derivative residual for the SVD-based solution, namely $\\max\\left\\{\\left|\\left(D^{(1)}_{\\text{row }0}\\right) u_{\\text{svd}}\\right|, \\left|\\left(D^{(1)}_{\\text{row }N}\\right) u_{\\text{svd}}\\right|\\right\\}$, where $D^{(1)}$ is the first Chebyshev differentiation matrix and $D^{(1)}_{\\text{row }0}$ and $D^{(1)}_{\\text{row }N}$ denote its first and last rows.\n\nUse the following test suite, specifying $N$ and $f(x)$ for each case. All trigonometric functions must use radians.\n- Case 1: $N = 32$, $f(x) = \\cos(\\pi x)$.\n- Case 2: $N = 33$, $f(x) = x$.\n- Case 3: $N = 40$, $f(x) = 1$.\n- Case 4: $N = 8$, $f(x) = e^{x}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain the three floats for each test case in order, rounded to eight significant digits: $[\\|u_{\\text{aug}} - u_{\\text{svd}}\\|_{\\infty}^{(1)}, \\|A u_{\\text{svd}} - b_{\\text{proj}}\\|_{\\infty}^{(1)}, \\text{BC}^{(1)}, \\|u_{\\text{aug}} - u_{\\text{svd}}\\|_{\\infty}^{(2)}, \\|A u_{\\text{svd}} - b_{\\text{proj}}\\|_{\\infty}^{(2)}, \\text{BC}^{(2)}, \\|u_{\\text{aug}} - u_{\\text{svd}}\\|_{\\infty}^{(3)}, \\|A u_{\\text{svd}} - b_{\\text{proj}}\\|_{\\infty}^{(3)}, \\text{BC}^{(3)}, \\|u_{\\text{aug}} - u_{\\text{svd}}\\|_{\\infty}^{(4)}, \\|A u_{\\text{svd}} - b_{\\text{proj}}\\|_{\\infty}^{(4)}, \\text{BC}^{(4)}]$, where the superscript denotes the test case index and $\\text{BC}^{(k)}$ is the boundary derivative residual for case $k$.",
            "solution": "This problem requires solving the one-dimensional Poisson equation with homogeneous Neumann boundary conditions, $\\frac{d^2 u}{d x^2} = f(x)$ with $u'(\\pm 1) = 0$, using a Chebyshev spectral collocation method. This boundary value problem is singular: a solution is only defined up to an additive constant, and a solution exists only if the forcing term $f(x)$ satisfies the compatibility condition $\\int_{-1}^1 f(x) dx = u'(1) - u'(-1) = 0$. The exercise compares two numerical techniques for handling the resulting rank-deficient linear system.\n\n#### 1. Chebyshev Spectral Discretization and System Construction\nFirst, we discretize the domain $[-1,1]$ using the $N+1$ Chebyshev-Gauss-Lobatto (CGL) nodes, $x_j = \\cos(\\frac{\\pi j}{N})$ for $j=0, 1, \\dots, N$. The unknown function values $u_j \\approx u(x_j)$ are related to their derivatives via the Chebyshev differentiation matrices $D^{(1)}$ and $D^{(2)}$. The second differentiation matrix $D^{(2)}$ can be computed as the matrix product of $D^{(1)}$ with itself. While the main article text notes that a direct formula for $D^{(2)}$ is more numerically stable for very large $N$, computing it as $(D^{(1)})^2$ is sufficient and common for the moderate values of $N$ used in this exercise.\n\nThe collocation method enforces the governing equations at the grid points to form a linear system $Au=b$.\n- For the interior points ($j=1, \\dots, N-1$), we enforce the Poisson equation: $(D^{(2)}u)_j = f(x_j)$. These equations form rows $1$ through $N-1$ of the system.\n- For the boundary points, we enforce the Neumann conditions. At $x_0=1$, $(D^{(1)}u)_0 = 0$. At $x_N=-1$, $(D^{(1)}u)_N = 0$. These form the first ($j=0$) and last ($j=N$) rows of the system.\nThe resulting matrix $A$ and vector $b$ are constructed by setting $A_{j,\\cdot} = D^{(2)}_{j,\\cdot}$ and $b_j = f(x_j)$ for interior rows, and $A_{j,\\cdot} = D^{(1)}_{j,\\cdot}$ and $b_j = 0$ for boundary rows.\n\n#### 2. Handling Rank Deficiency\nThe resulting matrix $A$ is singular, with a nullspace spanned by the constant vector $w=[1, 1, \\dots, 1]^\\top$. For the system $Au=b$ to have a solution, $b$ must be orthogonal to the left nullspace of $A$. We identify the left null-vector $u_0$ as the left singular vector of $A$ corresponding to the smallest singular value. We then enforce the solvability condition by projecting $b$ onto the range of $A$:\n$$\nb_{\\text{proj}} = b - u_0 (u_0^\\top b)\n$$\nThis projected vector $b_{\\text{proj}}$ is used as the right-hand side for both solvers to ensure a consistent and solvable system.\n\n#### 3. Augmented System Solver\nTo select a unique solution, we add the constraint that the solution has zero mean, which we approximate as $\\sum_{j=0}^N u_j=0$. This is incorporated using a Lagrange multiplier $\\lambda$, leading to an invertible $(N+2) \\times (N+2)$ block system:\n$$\n\\begin{pmatrix} A & w \\\\ w^\\top & 0 \\end{pmatrix} \\begin{pmatrix} u \\\\ \\lambda \\end{pmatrix} = \\begin{pmatrix} b_{\\text{proj}} \\\\ 0 \\end{pmatrix}\n$$\nSolving this system yields the unique solution $u_{\\text{aug}}$ that satisfies both the modified Poisson equation and the zero-sum constraint.\n\n#### 4. SVD-based Solver\nThis method computes the unique solution that has the minimum Euclidean norm, $\\|u\\|_2$. This minimum-norm solution is orthogonal to the nullspace of $A$. Since $\\mathcal{N}(A) = \\text{span}(w)$, this means $w^\\top u=0$, so the solution also has a zero mean (in a weighted sense, which for a uniform vector is the simple sum). Thus, the SVD solver seeks a solution satisfying the same type of uniqueness constraint as the augmented solver. The solution is computed via the Moore-Penrose pseudoinverse $A^+$ as $u_{\\text{svd}} = A^+ b_{\\text{proj}}$. Using the Singular Value Decomposition $A = U \\Sigma V^\\top$, the solution is calculated as:\n$$\nu_{\\text{svd}} = V \\Sigma^+ U^\\top b_{\\text{proj}} = \\sum_{i:\\sigma_i > \\varepsilon} \\frac{U_{\\cdot, i}^\\top b_{\\text{proj}}}{\\sigma_i} V_{\\cdot, i}\n$$\nwhere $\\Sigma^+$ is the pseudoinverse of the diagonal matrix of singular values $\\Sigma$ (reciprocals are taken for non-zero singular values, and zero otherwise), and $\\varepsilon$ is a small threshold to numerically identify the zero singular value. Since both methods find the unique solution with zero mean, we expect $u_{\\text{aug}}$ and $u_{\\text{svd}}$ to be identical up to floating-point precision.\n\nThe implementation will carry out these steps for each test case and compute the three required metrics to compare the accuracy and consistency of the methods.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef chebyshev_diff_matrices(N):\n    \"\"\"\n    Computes Chebyshev-Gauss-Lobatto nodes and differentiation matrices D1, D2.\n    \n    Args:\n        N (int): The number of intervals, resulting in N+1 nodes.\n        \n    Returns:\n        tuple: A tuple (x, D1, D2) containing:\n            - x (ndarray): The N+1 Chebyshev-Gauss-Lobatto nodes.\n            - D1 (ndarray): The (N+1)x(N+1) first differentiation matrix.\n            - D2 (ndarray): The (N+1)x(N+1) second differentiation matrix.\n    \"\"\"\n    if N == 0:\n        return np.array([0.0]), np.array([[0.0]]), np.array([[0.0]])\n\n    j = np.arange(N + 1)\n    x = np.cos(np.pi * j / N)\n\n    # c_bar vector\n    c = np.ones(N + 1)\n    c[0] = 2.0\n    c[-1] = 2.0\n    \n    # Off-diagonal elements of D1\n    c_i = c.reshape(-1, 1)\n    c_j = c.reshape(1, -1)\n    \n    x_i = x.reshape(-1, 1)\n    x_j = x.reshape(1, -1)\n    \n    dX = x_i - x_j\n    np.fill_diagonal(dX, 1e-9) # Avoid division by zero on diagonal\n\n    # Sign matrix for (-1)^(i+j)\n    i_plus_j = np.add.outer(j, j)\n    sign_matrix = np.power(-1.0, i_plus_j)\n\n    D1 = (c_i / c_j) * sign_matrix / dX\n    \n    # Diagonal elements of D1\n    diag = np.zeros(N + 1)\n    diag[1:N] = -x[1:N] / (2.0 * (1.0 - x[1:N]**2))\n    diag[0] = (2.0 * N**2 + 1.0) / 6.0\n    diag[N] = -(2.0 * N**2 + 1.0) / 6.0\n    np.fill_diagonal(D1, diag)\n    \n    # Second derivative matrix\n    D2 = D1 @ D1\n    \n    return x, D1, D2\n\ndef solve_poisson_neumann(N, f_func):\n    \"\"\"\n    Solves the 1D Poisson equation with Neumann BCs using two methods.\n\n    Args:\n        N (int): Number of intervals for Chebyshev discretization.\n        f_func (callable): The forcing function f(x).\n\n    Returns:\n        tuple: A tuple containing the three requested metrics:\n               (diff_norm, resid_norm, bc_resid)\n    \"\"\"\n    # 1. Discretization and System Construction\n    x, D1, D2 = chebyshev_diff_matrices(N)\n    \n    A = D2.copy()\n    A[0, :] = D1[0, :]\n    A[N, :] = D1[N, :]\n    \n    b = np.zeros(N + 1)\n    fx = f_func(x)\n    b[1:N] = fx[1:N]\n\n    # 2. Handle Rank Deficiency: Project b\n    U, S, Vt = np.linalg.svd(A)\n    # The left null vector is the last column of U\n    u0 = U[:, -1]\n    b_proj = b - u0 * np.dot(u0, b)\n\n    # 3. Solver 1: Augmented System\n    M_size = N + 2\n    M = np.zeros((M_size, M_size))\n    w = np.ones(N + 1)\n    M[:N+1, :N+1] = A\n    M[:N+1, -1] = w\n    M[-1, :N+1] = w\n    \n    rhs_aug = np.zeros(M_size)\n    rhs_aug[:N+1] = b_proj\n    \n    sol_aug = np.linalg.solve(M, rhs_aug)\n    u_aug = sol_aug[:-1]\n\n    # 4. Solver 2: SVD-based (Moore-Penrose Pseudoinverse)\n    epsilon = 1e-14\n    \n    # Calculate u_svd = V @ Sigma_pinv @ U.T @ b_proj\n    c = U.T @ b_proj\n    c_mod = c / S\n    c_mod[S  epsilon] = 0.0 # Apply pseudoinverse\n    u_svd = Vt.T @ c_mod\n\n    # 5. Compute Metrics\n    # Metric 1: Infinity norm of the difference between solutions\n    diff_norm = np.linalg.norm(u_aug - u_svd, np.inf)\n\n    # Metric 2: Infinity norm of the collocation residual for SVD\n    resid_norm = np.linalg.norm(A @ u_svd - b_proj, np.inf)\n\n    # Metric 3: Maximum absolute boundary derivative residual for SVD\n    # Note: D1[0,:] is derivative at x=1 and D1[N,:] is at x=-1\n    bc_resid = np.max([np.abs(D1[0, :] @ u_svd), np.abs(D1[N, :] @ u_svd)])\n\n    return diff_norm, resid_norm, bc_resid\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    test_cases = [\n        (32, lambda x: np.cos(np.pi * x)),\n        (33, lambda x: x),\n        (40, lambda x: np.ones_like(x)),\n        (8, lambda x: np.exp(x))\n    ]\n\n    results = []\n    for N, f_func in test_cases:\n        diff, resid, bc_res = solve_poisson_neumann(N, f_func)\n        results.extend([diff, resid, bc_res])\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{r:.8g}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The previous practice addressed boundary conditions by modifying the rows of the linear system. This final exercise  introduces a more elegant and robust strategy: constructing a basis of functions that intrinsically satisfies the boundary conditions from the outset. You will derive a special set of basis functions for the biharmonic operator, $\\frac{d^{4}}{dx^{4}}$, that satisfy clamped boundary conditions ($u=0$, $u'=0$) identically. This Galerkin-type approach is fundamental for developing stable schemes for higher-order equations and offers deeper insight into the structure of function spaces in spectral methods.",
            "id": "3300741",
            "problem": "Consider the one-dimensional biharmonic operator $\\frac{d^{4}}{dx^{4}}$ on the bounded domain $[-1,1]$ with clamped boundary conditions $u(-1)=u(1)=u'(-1)=u'(1)=0$. In the context of computational fluid dynamics (CFD) spectral discretizations on bounded domains, a common source of spurious modes arises when boundary conditions are imposed algebraically on a global polynomial basis. To eliminate such spurious modes, construct a constrained Chebyshev basis that satisfies the clamped boundary conditions identically.\n\nStarting from the definition of the Chebyshev polynomials of the first kind $T_{n}(x) = \\cos(n \\arccos x)$ and the well-tested endpoint identities $T_{n}(1)=1$, $T_{n}(-1)=(-1)^{n}$ together with the derivative relation $T_{n}'(x)=n\\,U_{n-1}(x)$, where $U_{n}(x)$ are Chebyshev polynomials of the second kind with $U_{n}(1)=n+1$ and $U_{n}(-1)=(-1)^{n}(n+1)$, seek, for each integer $k \\geq 0$, a minimal-bandwidth constrained basis function of the form\n$$\n\\psi_{k}(x) = T_{k+4}(x) + \\alpha_{k}\\,T_{k+2}(x) + \\beta_{k}\\,T_{k}(x),\n$$\nwhose coefficients $\\alpha_{k}$ and $\\beta_{k}$ are chosen so that $\\psi_{k}(\\pm 1)=0$ and $\\psi_{k}'(\\pm 1)=0$ hold identically.\n\n(a) Determine the closed-form expressions of $\\alpha_{k}$ and $\\beta_{k}$ in terms of $k$.\n\n(b) Justify that the collection $\\{\\psi_{k}\\}_{k=0}^{\\infty}$ is complete in the Sobolev space $H^{2}_{0}(-1,1)$ (the subspace of $H^{2}(-1,1)$ with zero trace and zero first-derivative trace at the endpoints), by appealing only to fundamental properties of Chebyshev polynomials, the density of polynomials in Sobolev spaces on bounded intervals, and linear-algebraic arguments about spanning and triangular transformations.\n\nExplain briefly why such a basis eliminates spurious boundary modes in spectral discretizations of the biharmonic operator.\n\nProvide your final result for part (a) as a single closed-form analytic expression for $\\psi_{k}(x)$ in terms of $k$ and $T_{n}(x)$. No numerical rounding is required.",
            "solution": "We begin with the definition of the Chebyshev polynomials of the first kind $T_{n}(x) = \\cos(n\\arccos x)$, which implies the endpoint identities $T_{n}(1)=1$ and $T_{n}(-1)=(-1)^{n}$. The derivative relation $T_{n}'(x) = n\\,U_{n-1}(x)$, where $U_{n}(x)$ are Chebyshev polynomials of the second kind, yields the endpoint values $T_{n}'(1) = n\\,U_{n-1}(1) = n \\cdot n = n^{2}$ and $T_{n}'(-1) = n\\,U_{n-1}(-1) = n \\cdot (-1)^{n-1} n = (-1)^{n-1} n^{2}$.\n\nWe seek, for each integer $k \\geq 0$, a constrained basis function of the form\n$$\n\\psi_{k}(x) = T_{k+4}(x) + \\alpha_{k}\\,T_{k+2}(x) + \\beta_{k}\\,T_{k}(x),\n$$\nwith the clamped boundary conditions\n$$\n\\psi_{k}(1)=0,\\quad \\psi_{k}(-1)=0,\\quad \\psi_{k}'(1)=0,\\quad \\psi_{k}'(-1)=0.\n$$\n\nFirst, we enforce the function-value conditions. Using $T_{n}(1)=1$, we have\n$$\n\\psi_{k}(1) = 1 + \\alpha_{k} + \\beta_{k} = 0.\n$$\nUsing $T_{n}(-1)=(-1)^{n}$ and noting that $k$, $k+2$, and $k+4$ share the same parity, we get\n$$\n\\psi_{k}(-1) = (-1)^{k+4} + \\alpha_{k}(-1)^{k+2} + \\beta_{k}(-1)^{k} \n= (-1)^{k}\\big(1 + \\alpha_{k} + \\beta_{k}\\big) = 0,\n$$\nso the $x=-1$ condition is automatically satisfied once $1+\\alpha_{k}+\\beta_{k}=0$ holds. Thus the function-value conditions reduce to a single linear constraint\n$$\n1 + \\alpha_{k} + \\beta_{k} = 0.\n$$\n\nNext, we enforce the derivative conditions. From $T_{n}'(1) = n^{2}$ and $T_{n}'(-1) = (-1)^{n-1} n^{2}$, we compute\n$$\n\\psi_{k}'(1) = (k+4)^{2} + \\alpha_{k} (k+2)^{2} + \\beta_{k} k^{2} = 0,\n$$\nand\n$$\n\\psi_{k}'(-1) = (-1)^{k+3} (k+4)^{2} + \\alpha_{k} (-1)^{k+1} (k+2)^{2} + \\beta_{k} (-1)^{k-1} k^{2}.\n$$\nBecause $(-1)^{k+3} = (-1)^{k+1} = (-1)^{k-1}$, the factor $(-1)^{k-1}$ can be pulled out, yielding\n$$\n\\psi_{k}'(-1) = (-1)^{k-1}\\left[ (k+4)^{2} + \\alpha_{k} (k+2)^{2} + \\beta_{k} k^{2} \\right] = 0,\n$$\nso the condition $\\psi_{k}'(-1)=0$ is equivalent to $\\psi_{k}'(1)=0$. Thus the derivative conditions reduce to the single linear constraint\n$$\n(k+4)^{2} + \\alpha_{k} (k+2)^{2} + \\beta_{k} k^{2} = 0.\n$$\n\nWe therefore have a $2 \\times 2$ linear system for $\\alpha_{k}$ and $\\beta_{k}$:\n$$\n\\begin{cases}\n1 + \\alpha_{k} + \\beta_{k} = 0,\\\\\n(k+4)^{2} + \\alpha_{k} (k+2)^{2} + \\beta_{k} k^{2} = 0.\n\\end{cases}\n$$\nWe solve by eliminating $\\beta_{k}$ from the second equation using $\\beta_{k} = -1 - \\alpha_{k}$:\n\n$$\n(k+4)^{2} + \\alpha_{k} (k+2)^{2} + (-1 - \\alpha_{k}) k^{2} = 0,\n$$\n\nwhich simplifies to\n\n$$\n\\big((k+4)^{2} - k^{2}\\big) + \\alpha_{k} \\big((k+2)^{2} - k^{2}\\big) = 0.\n$$\n\nCompute the differences:\n\n$$\n(k+4)^{2} - k^{2} = 8k + 16,\\qquad (k+2)^{2} - k^{2} = 4k + 4.\n$$\n\nThus\n\n$$\n(8k + 16) + \\alpha_{k} (4k + 4) = 0 \\quad \\Longrightarrow \\quad \\alpha_{k} = -\\frac{8k+16}{4k+4} = -2\\,\\frac{k+2}{k+1}.\n$$\n\nThen\n\n$$\n\\beta_{k} = -1 - \\alpha_{k} = -1 + 2\\,\\frac{k+2}{k+1} = \\frac{k+3}{k+1}.\n$$\n\nTherefore, the constrained basis functions are\n\n$$\n\\psi_{k}(x) = T_{k+4}(x) - 2\\,\\frac{k+2}{k+1}\\,T_{k+2}(x) + \\frac{k+3}{k+1}\\,T_{k}(x), \\qquad k \\geq 0.\n$$\n\nBy construction, $\\psi_{k}(\\pm 1)=0$ and $\\psi_{k}'(\\pm 1)=0$ for every $k \\geq 0$.\n\nWe now justify completeness. Let $V := H^{2}_{0}(-1,1) = \\{ v \\in H^{2}(-1,1) : v(\\pm 1)=0,\\ v'(\\pm 1)=0 \\}$. It is a standard result that algebraic polynomials are dense in $H^{m}(-1,1)$ for any integer $m \\geq 0$ on a compact interval. Moreover, the trace operators $v \\mapsto v(\\pm 1)$ and $v \\mapsto v'(\\pm 1)$ are continuous linear functionals on $H^{2}(-1,1)$. Define a continuous linear “boundary lifting” operator $\\mathcal{B}: \\mathbb{R}^{4} \\to H^{2}(-1,1)$ that maps prescribed endpoint values of a function and its first derivative to a cubic Hermite interpolant $h(x)$ satisfying $h(\\pm 1)$ and $h'(\\pm 1)$ equal to those prescriptions. Given any $f \\in V$, choose polynomials $q_{n}$ approximating $f$ in $H^{2}(-1,1)$. Let $\\gamma(q_{n})$ denote the $4$-tuple of traces $(q_{n}(-1),q_{n}(1),q_{n}'(-1),q_{n}'(1))$, and define $r_{n} := q_{n} - \\mathcal{B}(\\gamma(q_{n}))$. Then $r_{n}$ are polynomials satisfying the clamped traces $r_{n}(\\pm 1)=0$, $r_{n}'(\\pm 1)=0$, and $r_{n} \\to f$ in $H^{2}(-1,1)$ because $\\gamma(q_{n}) \\to \\gamma(f)=0$ and $\\mathcal{B}$ is continuous. Hence the subspace of polynomials obeying the clamped boundary conditions is dense in $V$.\n\nIt remains to show that $\\{\\psi_{k}\\}_{k=0}^{\\infty}$ spans the polynomial subspace with clamped traces. Observe that each $\\psi_{k}$ has leading term $T_{k+4}(x)$ with coefficient $1$, and only involves $T_{k+2}(x)$ and $T_{k}(x)$ of strictly lower degrees. Consequently, with respect to the ordered Chebyshev basis $\\{T_{0},T_{1},\\dots,T_{N}\\}$, the linear transformation mapping the coefficient vector of a constrained polynomial expressed in $\\{\\psi_{0},\\dots,\\psi_{N-4}\\}$ to its Chebyshev coefficient vector is upper triangular with unit diagonal (in the block corresponding to degrees $\\geq 4$). Therefore, $\\{\\psi_{0},\\dots,\\psi_{N-4}\\}$ is a basis of the space of polynomials of degree at most $N$ that satisfy the clamped boundary conditions, by a standard triangularity and dimension-count argument. Passing to the limit $N \\to \\infty$, we conclude that $\\{\\psi_{k}\\}_{k=0}^{\\infty}$ is a complete system in the dense subspace of constrained polynomials, and hence complete in $V$.\n\nFinally, such a basis eliminates spurious boundary modes in spectral discretizations because the boundary conditions are enforced identically at the level of the trial space. The discrete operator thus acts on a subspace where the null space consists only of physically admissible modes, avoiding algebraic inconsistencies and the artificial, poorly conditioned boundary modes that can arise when enforcing multiple boundary conditions a posteriori.\n\nTherefore, the requested closed-form basis functions are\n$$\n\\psi_{k}(x) = T_{k+4}(x) - 2\\,\\frac{k+2}{k+1}\\,T_{k+2}(x) + \\frac{k+3}{k+1}\\,T_{k}(x), \\qquad k \\geq 0.\n$$",
            "answer": "$$\\boxed{\\,\\psi_{k}(x)=T_{k+4}(x)-2\\,\\frac{k+2}{k+1}\\,T_{k+2}(x)+\\frac{k+3}{k+1}\\,T_{k}(x)\\,}$$"
        }
    ]
}