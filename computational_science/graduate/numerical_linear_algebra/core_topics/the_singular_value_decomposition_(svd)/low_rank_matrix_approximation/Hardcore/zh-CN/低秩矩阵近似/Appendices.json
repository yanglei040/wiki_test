{
    "hands_on_practices": [
        {
            "introduction": "一个矩阵能够被低秩矩阵近似的程度，从根本上取决于其奇异值的衰减速度。奇异值衰减得越快，意味着矩阵的“能量”越集中在少数几个主导模式上，因此它就越“接近”一个低秩矩阵。本练习  将通过分析一个具有特定参数化衰减率的矩阵，来精确阐释这一概念，并要求您推导截断奇异值分解（SVD）的近似误差与奇异值衰减率之间的定量关系。",
            "id": "3557759",
            "problem": "设 $A$ 是一个无穷实对角矩阵（等价地，可分希尔伯特空间 $\\ell^{2}$ 上的一个紧算子），其定义为 $A = \\operatorname{diag}(\\sigma_{1}, \\sigma_{2}, \\dots)$，其中奇异值 $\\sigma_{i} = i^{-\\alpha}$ (对于所有整数 $i \\geq 1$ 和一个固定参数 $\\alpha  0$）。设 $A_{k}$ 表示通过将 $A$ 的奇异值分解 (SVD) 截断为其最大的 $k$ 个奇异值而得到的 $A$ 的最佳 $k$ 秩逼近，并设 $\\|\\cdot\\|_{F}$ 表示弗罗贝尼乌斯范数（在无穷维情景下也称为希尔伯特-施密特范数）。\n\n从弗罗贝尼乌斯范数和奇异值分解 (SVD) 的定义出发，并仅使用诸如弗罗贝尼乌斯范数的正交不变性和用于级数的单调积分比较法等基础事实，推导当 $k \\to \\infty$ 时弗罗贝尼乌斯范数误差 $E_{k}(\\alpha) = \\|A - A_{k}\\|_{F}$ 的精确领头阶渐近式，并解释该行为如何依赖于 $\\alpha$。你的推导必须证明领头项中的常数和指数是合理的。\n\n将你的最终答案表示为一个单一的闭式表达式，给出在 $E_{k}(\\alpha)$ 为有限的范围内 $E_{k}(\\alpha)$ 的领头项。无需四舍五入。",
            "solution": "该问题要求在用最佳 $k$ 秩逼近 $A_k$ 逼近无穷对角矩阵 $A$ 时，弗罗贝尼乌斯范数误差 $E_{k}(\\alpha) = \\|A - A_{k}\\|_{F}$ 的领头阶渐近行为。\n\n首先，我们确定矩阵 $A$ 和 $A_k$ 的结构。给定矩阵为 $A = \\operatorname{diag}(\\sigma_{1}, \\sigma_{2}, \\dots)$，其奇异值 $\\sigma_{i} = i^{-\\alpha}$ (对于整数 $i \\ge 1$ 和参数 $\\alpha  0$)。由于值 $\\sigma_i$ 是正的且按降序排列 ($\\sigma_1  \\sigma_2  \\dots  0$)，这种对角表示已经是 $A$ 的奇异值分解 (SVD)。具体来说，如果我们将 $A$ 的 SVD 写为 $A = U \\Sigma V^*$，那么 $U$ 和 $V$ 是希尔伯特空间 $\\ell^2$ 上的单位算子，而 $\\Sigma$ 是对角项为 $\\sigma_i$ 的对角算子。\n\nEckart-Young-Mirsky 定理，当扩展到希尔伯特空间上的紧算子时，指出在任何酉不变范数（包括弗罗贝尼乌斯范数）下，$A$ 的最佳 $k$ 秩逼近是通过截断其 SVD 得到的。这是通过保留最大的 $k$ 个奇异值并将其他值设为零来实现的。因此，最佳 $k$ 秩逼近 $A_k$ 由下式给出：\n$$\nA_k = \\operatorname{diag}(\\sigma_1, \\sigma_2, \\dots, \\sigma_k, 0, 0, \\dots)\n$$\n因此，误差矩阵 $A - A_k$ 为：\n$$\nA - A_k = \\operatorname{diag}(0, \\dots, 0, \\sigma_{k+1}, \\sigma_{k+2}, \\dots)\n$$\n这是一个对角算子，其非零项从第 $(k+1)$ 个位置开始。\n\n接下来，我们计算这个误差矩阵的弗罗贝尼乌斯范数。对于一个对角算子 $D = \\operatorname{diag}(d_1, d_2, \\dots)$，弗罗贝尼乌斯范数（或希尔伯特-施密特范数），记为 $\\|\\cdot\\|_F$，定义为：\n$$\n\\|D\\|_{F} = \\sqrt{\\sum_{i=1}^{\\infty} |d_i|^2}\n$$\n将此定义应用于误差矩阵 $A - A_k$，我们得到误差 $E_k(\\alpha)$：\n$$\nE_k(\\alpha)^2 = \\|A - A_k\\|_{F}^2 = \\sum_{i=k+1}^{\\infty} \\sigma_i^2\n$$\n代入给定的奇异值形式 $\\sigma_i = i^{-\\alpha}$：\n$$\nE_k(\\alpha)^2 = \\sum_{i=k+1}^{\\infty} (i^{-\\alpha})^2 = \\sum_{i=k+1}^{\\infty} i^{-2\\alpha}\n$$\n误差 $E_k(\\alpha)$ 是这个和的平方根：\n$$\nE_k(\\alpha) = \\left( \\sum_{i=k+1}^{\\infty} i^{-2\\alpha} \\right)^{1/2}\n$$\n这个表达式是有限的当且仅当该级数收敛。级数 $\\sum_{i=1}^{\\infty} i^{-p}$ 是一个 p-级数，它收敛当且仅当 $p  1$。在我们的例子中，指数是 $p = 2\\alpha$。因此，总误差 $\\|A\\|_F$ 是有限的，从而尾和 $E_k(\\alpha)^2$ 对所有 $k$ 都有意义，当且仅当 $2\\alpha  1$，即 $\\alpha  \\frac{1}{2}$。问题要求在 $E_k(\\alpha)$ 是有限的区域内的渐近行为，因此我们在 $\\alpha  \\frac{1}{2}$ 的假设下进行。\n\n为了找到当 $k \\to \\infty$ 时 $E_k(\\alpha)$ 的领头阶渐近行为，我们需要逼近和 $S_k(\\alpha) = \\sum_{i=k+1}^{\\infty} i^{-2\\alpha}$。我们使用积分比较法。函数 $f(x) = x^{-2\\alpha}$ 对于 $x \\ge 1$ 是一个正、连续且严格递减的函数。对于任何整数 $i \\ge 1$，我们可以在一个区间上对函数的值进行界定：\n$$\n\\int_{i}^{i+1} x^{-2\\alpha} dx  \\le f(i) = i^{-2\\alpha}  \\le \\int_{i-1}^{i} x^{-2\\alpha} dx\n$$\n将这些不等式从 $i = k+1$ 到 $\\infty$ 求和，我们得到级数 $S_k(\\alpha)$ 的界：\n$$\n\\int_{k+1}^{\\infty} x^{-2\\alpha} dx  \\le \\sum_{i=k+1}^{\\infty} i^{-2\\alpha}  \\le \\int_{k}^{\\infty} x^{-2\\alpha} dx\n$$\n现在我们计算这个积分。由于我们假设了 $2\\alpha  1$，该积分是收敛的：\n$$\n\\int x^{-2\\alpha} dx = \\frac{x^{-2\\alpha+1}}{-2\\alpha+1} + C\n$$\n$$\n\\int_{a}^{\\infty} x^{-2\\alpha} dx = \\left[ \\frac{x^{1-2\\alpha}}{1-2\\alpha} \\right]_{a}^{\\infty} = 0 - \\frac{a^{1-2\\alpha}}{1-2\\alpha} = \\frac{a^{1-2\\alpha}}{2\\alpha-1}\n$$\n将此结果代入我们对 $S_k(\\alpha)$ 的界中：\n$$\n\\frac{(k+1)^{1-2\\alpha}}{2\\alpha-1}  \\le S_k(\\alpha)  \\le \\frac{k^{1-2\\alpha}}{2\\alpha-1}\n$$\n对于大的 $k$，我们有渐近等价关系 $(k+1)^{1-2\\alpha} \\sim k^{1-2\\alpha}$。更正式地：\n$$\n(k+1)^{1-2\\alpha} = k^{1-2\\alpha} \\left(1 + \\frac{1}{k}\\right)^{1-2\\alpha} = k^{1-2\\alpha} \\left(1 + \\frac{1-2\\alpha}{k} + O(k^{-2})\\right)\n$$\n因此，下界和上界都渐近等价于 $\\frac{k^{1-2\\alpha}}{2\\alpha-1}$。根据渐近行为的夹逼定理，该和的领头项为：\n$$\nS_k(\\alpha) = \\sum_{i=k+1}^{\\infty} i^{-2\\alpha} \\sim \\frac{k^{1-2\\alpha}}{2\\alpha-1} \\quad \\text{as } k \\to \\infty\n$$\n记号 $g(k) \\sim h(k)$ 意味着 $\\lim_{k\\to\\infty} g(k)/h(k) = 1$。\n\n现在，我们可以找到误差 $E_k(\\alpha) = \\sqrt{S_k(\\alpha)}$ 的渐近行为：\n$$\nE_k(\\alpha) \\sim \\left( \\frac{k^{1-2\\alpha}}{2\\alpha-1} \\right)^{1/2} = \\frac{(k^{1-2\\alpha})^{1/2}}{\\sqrt{2\\alpha-1}} = \\frac{k^{(1-2\\alpha)/2}}{\\sqrt{2\\alpha-1}}\n$$\n化简指数可得：\n$$\nE_k(\\alpha) \\sim \\frac{1}{\\sqrt{2\\alpha-1}} k^{\\frac{1}{2} - \\alpha}\n$$\n这个表达式给出了当 $k \\to \\infty$ 时误差的领头阶渐近式，它在 $\\alpha  \\frac{1}{2}$ 时有效。常数是 $\\frac{1}{\\sqrt{2\\alpha-1}}$，而 $k$ 的指数是 $\\frac{1}{2} - \\alpha$。\n\n逼近误差的行为依赖于 $\\alpha$：\n- 该分析仅在 $\\alpha  \\frac{1}{2}$ 时有效，因为对于 $\\alpha \\le \\frac{1}{2}$，算子 $A$ 不属于希尔伯特-施密特类（即 $\\|A\\|_F = \\infty$）。\n- $k$ 的指数是 $\\frac{1}{2} - \\alpha$，对于 $\\alpha  \\frac{1}{2}$，该指数为负。这证实了当 $k \\to \\infty$ 时，误差 $E_k(\\alpha)$ 趋于 $0$。\n- 随着 $\\alpha$ 的增加，奇异值衰减得更快。指数 $\\frac{1}{2} - \\alpha$ 变得更负，表明 $k$ 秩逼近的收敛速度更快。\n- 当 $\\alpha$ 从上方趋近临界值 $\\frac{1}{2}$ 时，常数项 $\\frac{1}{\\sqrt{2\\alpha-1}}$ 发散到无穷大，并且收敛率 $k^{\\frac{1}{2} - \\alpha}$ 变得非常慢（指数趋近于 $0$）。这标志着在希尔伯特-施密特类的边界附近，良好的可逼近性失效。",
            "answer": "$$\n\\boxed{\\frac{1}{\\sqrt{2\\alpha-1}} k^{\\frac{1}{2} - \\alpha}}\n$$"
        },
        {
            "introduction": "Eckart-Young-Mirsky 定理保证了截断SVD在谱范数和Frobenius范数下的最优性，但这一保证并不适用于所有范数。在某些应用中，我们可能更关心最小化最大的逐元素误差（即在无穷范数 $\\|\\cdot\\|_{\\infty}$ 下的误差）。本练习  将通过一个具体的反例，构建一个矩阵，证明在无穷范数下，存在比SVD给出的更优的秩-1近似，从而深刻揭示了范数的选择对低秩近似问题解的本质影响。",
            "id": "3557705",
            "problem": "考虑实矩阵 $A$ 的逐元素无穷范数，定义为 $\\|A\\|_{\\infty} = \\max_{i,j} |a_{ij}|$。低秩近似的一种广泛使用的方法是截断奇异值分解 (SVD)，已知该方法在所有秩 $k$ 近似中，能够最小化谱2-范数和弗罗贝尼乌斯范数下的近似误差。然而，对于逐元素无穷范数，截断奇异值分解没有普适的最优性保证。\n\n构造一个 $2 \\times 2$ 矩阵 $A_{\\alpha} = \\begin{pmatrix} 1  0 \\\\ 0  -\\alpha \\end{pmatrix}$，其中参数 $\\alpha \\in (0,1)$，并将注意力限制在秩1近似上。将 $A_{\\alpha}$ 的截断奇异值分解秩1近似 $X_{\\mathrm{svd}}$ 定义为 $\\sigma_{1} u_{1} v_{1}^{\\top}$，其中 $\\sigma_{1}$ 是 $A_{\\alpha}$ 的最大奇异值，$u_{1}, v_{1}$ 是相应的左右奇异向量。\n\n从基本原理出发，并仅使用上述定义，推导以下两者之差的解析表达式：\n- 最小逐元素无穷范数误差 $\\min_{\\operatorname{rank}(X)=1} \\|A_{\\alpha} - X\\|_{\\infty}$，以及\n- 逐元素无穷范数误差 $\\|A_{\\alpha} - X_{\\mathrm{svd}}\\|_{\\infty}$。\n\n您必须证明，对于 $\\alpha \\in (0,1)$，最佳逐元素无穷范数秩1近似与截断奇异值分解近似不一致，然后计算这两个误差之间作为 $\\alpha$ 函数的精确差值。将您的最终答案表示为关于 $\\alpha$ 的单个闭式表达式。无需四舍五入。",
            "solution": "问题要求计算矩阵 $A_{\\alpha}$ 的秩1近似的最小逐元素无穷范数误差与通过截断奇异值分解（SVD）得到的秩1近似误差之间的差值。给定矩阵 $A_{\\alpha} = \\begin{pmatrix} 1  0 \\\\ 0  -\\alpha \\end{pmatrix}$，其中参数 $\\alpha \\in (0,1)$。逐元素无穷范数定义为 $\\|A\\|_{\\infty} = \\max_{i,j} |a_{ij}|$。\n\n首先，我们确定通过截断SVD得到的秩1近似，记为 $X_{\\mathrm{svd}}$，并计算其误差 $\\|A_{\\alpha} - X_{\\mathrm{svd}}\\|_{\\infty}$。\n\n矩阵 $A_{\\alpha}$ 是一个实对角矩阵。它的奇异值是其对角线元素的绝对值。由于 $\\alpha \\in (0,1)$，对角线元素为 $1$ 和 $-\\alpha$。它们的绝对值为 $1$ 和 $\\alpha$。因此，奇异值为 $\\sigma_1 = 1$ 和 $\\sigma_2 = \\alpha$，其中 $\\sigma_1$ 是最大的。\n\n$A_{\\alpha}$ 的SVD为 $A_{\\alpha} = U \\Sigma V^{\\top}$。右奇异向量 $v_i$ 是 $A_{\\alpha}^{\\top} A_{\\alpha}$ 的特征向量，左奇异向量 $u_i$ 是 $A_{\\alpha} A_{\\alpha}^{\\top}$ 的特征向量。\n$$A_{\\alpha}^{\\top} A_{\\alpha} = \\begin{pmatrix} 1  0 \\\\ 0  -\\alpha \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  -\\alpha \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  \\alpha^2 \\end{pmatrix}$$\n特征值为 $\\sigma_1^2 = 1$ 和 $\\sigma_2^2 = \\alpha^2$。\n对应于 $\\sigma_1^2=1$ 的特征向量是 $v_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$。\n相应的左奇异向量是 $u_1 = \\frac{1}{\\sigma_1} A_{\\alpha} v_1 = \\frac{1}{1} \\begin{pmatrix} 1  0 \\\\ 0  -\\alpha \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$。\n\n截断SVD秩1近似为 $X_{\\mathrm{svd}} = \\sigma_{1} u_{1} v_{1}^{\\top}$。\n$$X_{\\mathrm{svd}} = 1 \\cdot \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\begin{pmatrix} 1  0 \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix}$$\n此近似的误差矩阵为：\n$$E_{\\mathrm{svd}} = A_{\\alpha} - X_{\\mathrm{svd}} = \\begin{pmatrix} 1  0 \\\\ 0  -\\alpha \\end{pmatrix} - \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 0  0 \\\\ 0  -\\alpha \\end{pmatrix}$$\n逐元素无穷范数误差为：\n$$\\|A_{\\alpha} - X_{\\mathrm{svd}}\\|_{\\infty} = \\max(|0|, |0|, |0|, |-\\alpha|) = \\alpha$$\n\n接下来，我们求解最小误差 $\\varepsilon_{\\mathrm{opt}} = \\min_{\\operatorname{rank}(X)=1} \\|A_{\\alpha} - X\\|_{\\infty}$。\n设 $X = \\begin{pmatrix} x_{11}  x_{12} \\\\ x_{21}  x_{22} \\end{pmatrix}$ 是一个任意的秩1矩阵，这意味着其行列式为零：$x_{11}x_{22} - x_{12}x_{21} = 0$。\n设 $\\varepsilon = \\|A_{\\alpha} - X\\|_{\\infty}$。这意味着误差矩阵 $E = A_{\\alpha} - X$ 的元素的绝对值以 $\\varepsilon$ 为界：\n$$A_{\\alpha} - X = \\begin{pmatrix} 1 - x_{11}  -x_{12} \\\\ -x_{21}  -\\alpha - x_{22} \\end{pmatrix} = \\begin{pmatrix} e_{11}  e_{12} \\\\ e_{21}  e_{22} \\end{pmatrix}$$\n其中对于所有 $i,j \\in \\{1,2\\}$，都有 $|e_{ij}| \\le \\varepsilon$。\n这给了我们关于 $X$ 的元素的以下约束：\n1.  $|1 - x_{11}| \\le \\varepsilon \\implies 1-\\varepsilon \\le x_{11} \\le 1+\\varepsilon$\n2.  $|-x_{12}| \\le \\varepsilon \\implies -\\varepsilon \\le x_{12} \\le \\varepsilon$\n3.  $|-x_{21}| \\le \\varepsilon \\implies -\\varepsilon \\le x_{21} \\le \\varepsilon$\n4.  $|-\\alpha - x_{22}| \\le \\varepsilon \\implies -\\alpha-\\varepsilon \\le x_{22} \\le -\\alpha+\\varepsilon$\n\n我们寻求最小的 $\\varepsilon \\ge 0$，使得存在满足这些不等式和秩1条件 $x_{11}x_{22} = x_{12}x_{21}$ 的 $x_{ij}$。\n从不等式可知，乘积 $x_{12}x_{21}$ 必须位于区间 $[-\\varepsilon^2, \\varepsilon^2]$ 内。\n对于 $x_{11}$ 和 $x_{22}$，由于 $\\alpha \\in (0,1)$，我们可以假设 $\\varepsilon  1$。那么 $1-\\varepsilon  0$，所以 $x_{11}$ 是正的。此外，$-\\alpha+\\varepsilon = -\\alpha+\\frac{\\alpha}{1+\\alpha} = \\frac{-\\alpha^2}{1+\\alpha}  0$ (因为我们将发现 $\\varepsilon=\\frac{\\alpha}{1+\\alpha}$)，所以 $x_{22}$ 是负的。\n因此，乘积 $x_{11}x_{22}$ 的取值范围包含在区间 $[(1+\\varepsilon)(-\\alpha-\\varepsilon), (1-\\varepsilon)(-\\alpha+\\varepsilon)] = [-(1+\\varepsilon)(\\alpha+\\varepsilon), -(1-\\varepsilon)(\\alpha-\\varepsilon)]$ 中。\n要使解存在，$x_{11}x_{22}$ 的区间和 $x_{12}x_{21}$ 的区间必须重叠。非空交集要求 $x_{11}x_{22}$ 区间的上界大于或等于 $x_{12}x_{21}$ 区间的下界。\n$$-(1-\\varepsilon)(\\alpha-\\varepsilon) \\ge -\\varepsilon^2$$\n两边乘以 $-1$ 并反转不等号，得到：\n$$(1-\\varepsilon)(\\alpha-\\varepsilon) \\le \\varepsilon^2$$\n为了找到可能的最小 $\\varepsilon$，我们考虑此条件的边界情况：\n$$(1-\\varepsilon)(\\alpha-\\varepsilon) = \\varepsilon^2$$\n$$\\alpha - \\varepsilon - \\alpha\\varepsilon + \\varepsilon^2 = \\varepsilon^2$$\n$$\\alpha = \\varepsilon + \\alpha\\varepsilon = \\varepsilon(1+\\alpha)$$\n这给出了最小误差的候选值：\n$$\\varepsilon_{\\mathrm{opt}} = \\frac{\\alpha}{1+\\alpha}$$\n为了证明这确实是最小误差，我们必须证明存在一个达到此误差的秩1矩阵 $X$。当 $\\varepsilon = \\frac{\\alpha}{1+\\alpha}$ 时，$x_{11}x_{22}$ 和 $x_{12}x_{21}$ 的区间在单点 $-\\varepsilon^2$ 处相切。因此，我们必须有 $x_{11}x_{22} = -\\varepsilon^2$ 和 $x_{12}x_{21} = -\\varepsilon^2$。\n让我们构造这样一个矩阵 $X_{\\mathrm{opt}}$。我们要求所有误差项的大小都为 $\\varepsilon_{\\mathrm{opt}}$。\n设 $X_{\\mathrm{opt}} = A_{\\alpha} - E_{\\mathrm{opt}}$，其中 $E_{\\mathrm{opt}}$ 的所有元素的大小都为 $\\varepsilon_{\\mathrm{opt}}$。$E_{\\mathrm{opt}}$ 的一个可能选择是：\n$$E_{\\mathrm{opt}} = \\begin{pmatrix} \\varepsilon_{\\mathrm{opt}}  -\\varepsilon_{\\mathrm{opt}} \\\\ \\varepsilon_{\\mathrm{opt}}  -\\varepsilon_{\\mathrm{opt}} \\end{pmatrix} = \\frac{\\alpha}{1+\\alpha} \\begin{pmatrix} 1  -1 \\\\ 1  -1 \\end{pmatrix}$$\n那么近似矩阵是：\n$$X_{\\mathrm{opt}} = A_{\\alpha} - E_{\\mathrm{opt}} = \\begin{pmatrix} 1  0 \\\\ 0  -\\alpha \\end{pmatrix} - \\frac{\\alpha}{1+\\alpha}\\begin{pmatrix} 1  -1 \\\\ 1  -1 \\end{pmatrix} = \\begin{pmatrix} 1 - \\frac{\\alpha}{1+\\alpha}  \\frac{\\alpha}{1+\\alpha} \\\\ -\\frac{\\alpha}{1+\\alpha}  -\\alpha + \\frac{\\alpha}{1+\\alpha} \\end{pmatrix}$$\n$$X_{\\mathrm{opt}} = \\begin{pmatrix} \\frac{1}{1+\\alpha}  \\frac{\\alpha}{1+\\alpha} \\\\ -\\frac{\\alpha}{1+\\alpha}  \\frac{-\\alpha(1+\\alpha)+\\alpha}{1+\\alpha} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{1+\\alpha}  \\frac{\\alpha}{1+\\alpha} \\\\ -\\frac{\\alpha}{1+\\alpha}  \\frac{-\\alpha^2}{1+\\alpha} \\end{pmatrix}$$\n我们检查该矩阵是否为秩1：\n$$\\det(X_{\\mathrm{opt}}) = \\left(\\frac{1}{1+\\alpha}\\right)\\left(\\frac{-\\alpha^2}{1+\\alpha}\\right) - \\left(\\frac{\\alpha}{1+\\alpha}\\right)\\left(-\\frac{\\alpha}{1+\\alpha}\\right) = \\frac{-\\alpha^2}{(1+\\alpha)^2} + \\frac{\\alpha^2}{(1+\\alpha)^2} = 0$$\n由于行列式为0，所以 $X_{\\mathrm{opt}}$ 是一个秩1矩阵。其误差为 $\\|A_{\\alpha} - X_{\\mathrm{opt}}\\|_{\\infty} = \\|E_{\\mathrm{opt}}\\|_{\\infty} = \\varepsilon_{\\mathrm{opt}} = \\frac{\\alpha}{1+\\alpha}$。这证实了最小误差确实是 $\\frac{\\alpha}{1+\\alpha}$。\n\n问题陈述了最佳逐元素无穷范数秩1近似与SVD近似不一致。我们可以通过比较它们的误差来验证这一点。\nSVD近似的误差：$\\|A_{\\alpha} - X_{\\mathrm{svd}}\\|_{\\infty} = \\alpha$。\n最小误差：$\\min_{\\operatorname{rank}(X)=1} \\|A_{\\alpha} - X\\|_{\\infty} = \\frac{\\alpha}{1+\\alpha}$。\n由于 $\\alpha \\in (0,1)$，我们有 $1+\\alpha  1$，这意味着 $\\frac{1}{1+\\alpha}  1$。因为 $\\alpha  0$，两边乘以 $\\alpha$ 得到 $\\frac{\\alpha}{1+\\alpha}  \\alpha$。\n这证明了在这种情况下，截断SVD在逐元素无穷范数下不能得到最优的秩1近似。\n\n最后一步是计算这两个误差值之间的差值。这自然地被解释为较大的误差减去较小的误差。\n差值 = $\\|A_{\\alpha} - X_{\\mathrm{svd}}\\|_{\\infty} - \\min_{\\operatorname{rank}(X)=1} \\|A_{\\alpha} - X\\|_{\\infty}$\n差值 = $\\alpha - \\frac{\\alpha}{1+\\alpha}$\n差值 = $\\frac{\\alpha(1+\\alpha) - \\alpha}{1+\\alpha} = \\frac{\\alpha + \\alpha^2 - \\alpha}{1+\\alpha} = \\frac{\\alpha^2}{1+\\alpha}$",
            "answer": "$$\\boxed{\\frac{\\alpha^2}{1+\\alpha}}$$"
        },
        {
            "introduction": "现实世界的数据常常被噪声或异常值污染。基于最小化平方误差（对应于Frobenius范数）的标准SVD方法对大幅值的异常值极其敏感，单个异常点就可能严重破坏近似结果的准确性。本练习  生动地展示了这种失效情况，并引入了一种基于最小化绝对误差（$\\ell_1$范数）的替代方法。通过计算并比较两种方法在异常值影响下的“崩溃点”，您将亲身体会到稳健方法在处理受污染数据时的优越性。",
            "id": "3557735",
            "problem": "考虑以下为分离单个大数值离群点对低秩近似的影响而设计的显式数据矩阵族。对于整数 $n \\geq 3$ 和参数 $M \\geq 0$，定义矩阵 $A(M) \\in \\mathbb{R}^{2 \\times n}$ 为\n$$\nA(M) \\;=\\; \\begin{bmatrix}\n0  0  \\cdots  0  M \\\\\n1  1  \\cdots  1  0\n\\end{bmatrix},\n$$\n也就是说，前 $n-1$ 列等于内点向量 $e_{2} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$，最后一列是离群点 $M e_{1} = \\begin{bmatrix} M \\\\ 0 \\end{bmatrix}$。（在没有离群点的情况下）“真实”的潜在低秩结构是秩为 $1$ 的矩阵 $L^{\\star} = e_{2} \\mathbf{1}^{\\top}$，其中 $\\mathbf{1} \\in \\mathbb{R}^{n}$ 是全为 $1$ 的向量。\n\n您将从第一性原理出发，分析两种秩-1 近似策略：\n\n1. 截断奇异值分解 (SVD)：根据 Eckart–Young–Mirsky 定理，Frobenius 范数下的最佳秩-1 近似由 $A(M)$ 的首奇异三元组给出。首左奇异向量是 $A(M) A(M)^{\\top}$ 的主特征向量。\n\n2. 基于 $\\ell_{1}$ 的秩-1 近似：在秩-1 约束下，最小化逐项绝对偏差，\n$$\n\\min_{u \\in \\mathbb{R}^{2},\\, v \\in \\mathbb{R}^{n}} \\;\\sum_{i=1}^{2} \\sum_{j=1}^{n} \\left| A(M)_{ij} - (u v^{\\top})_{ij} \\right| \\quad \\text{约束条件为 } \\|u\\|_{2} = 1.\n$$\n这是一个鲁棒的、逐项的 $\\ell_{1}$ 损失准则。\n\n从奇异值分解 (SVD) 和 $\\ell_{1}$ 目标的定义出发，并仅使用基本的线性代数事实，例如奇异向量与 $A(M) A(M)^{\\top}$ 的特征结构之间的关系，回答以下问题：\n\n(a) 推导 $A(M)$ 的主左奇异向量，作为 $M$ 和 $n$ 的函数，并计算当 $M \\to \\infty$ 时，此向量与真实方向 $e_{2}$ 之间主角的余弦的极限。\n\n(b) 确定精确的量级阈值 $M_{2}(n)$，在该阈值下，截断 SVD 的首左奇异向量从 $e_{2}$ 切换到 $e_{1}$。\n\n(c) 对于基于 $\\ell_{1}$ 的问题，计算两个候选方向 $u = e_{2}$（拟合内点）和 $u = e_{1}$（拟合离群点）在每种情况下对 $v \\in \\mathbb{R}^{n}$ 进行优化后所达到的最优目标值。由此确定基于 $\\ell_{1}$ 的估计器从 $e_{2}$ 切换到 $e_{1}$ 的精确量级阈值 $M_{1}(n)$。\n\n将您的最终答案表示为包含按此顺序排列的三个条目的单行向量：\n$$\n\\left(\\lim_{M \\to \\infty} \\cos \\theta(M),\\; M_{2}(n),\\; M_{1}(n)\\right),\n$$\n其中 $\\theta(M)$ 是 SVD 的首左奇异向量与 $e_{2}$ 之间的角度。无需四舍五入。请仅用 $n$ 以闭合形式表示您的答案。",
            "solution": "用户希望分析两种不同的秩-1 近似方法，用于处理包含单个大离群点的矩阵 $A(M)$。分析必须从第一性原理出发。问题分为三个部分：(a) 分析基于奇异值分解 (SVD) 的近似，(b) 找出 SVD 方法的崩溃阈值，以及 (c) 找出基于 $\\ell_{1}$ 范数的鲁棒方法的崩溃阈值。\n\n首先，我们确定矩阵 $A(M) \\in \\mathbb{R}^{2 \\times n}$ 的结构。前 $n-1$ 列是 $e_{2} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$，最后一列是 $M e_{1} = \\begin{bmatrix} M \\\\ 0 \\end{bmatrix}$。该矩阵明确表示为：\n$$\nA(M) = \\begin{bmatrix}\n0  0  \\cdots  0  M \\\\\n1  1  \\cdots  1  0\n\\end{bmatrix}\n$$\n真实方向被给定为 $e_2$。\n\n(a) 推导 $A(M)$ 的主左奇异向量并计算一个相关的极限。\n\n$A(M)$ 的主左奇异向量是矩阵 $A(M)A(M)^{\\top}$ 的最大特征值对应的特征向量。让我们计算这个 $2 \\times 2$ 的矩阵：\n$$\nA(M)A(M)^{\\top} = \\begin{bmatrix}\n0  0  \\cdots  0  M \\\\\n1  1  \\cdots  1  0\n\\end{bmatrix}\n\\begin{bmatrix}\n0  1 \\\\\n0  1 \\\\\n\\vdots  \\vdots \\\\\n0  1 \\\\\nM  0\n\\end{bmatrix}\n$$\n结果矩阵的项是：\n$(1,1)$ 项是 $A(M)$ 的第一行与自身的点积：$(n-1) \\cdot 0^2 + M^2 = M^2$。\n$(2,2)$ 项是 $A(M)$ 的第二行与自身的点积：$(n-1) \\cdot 1^2 + 0^2 = n-1$。\n非对角项是第一行和第二行的点积：$(n-1) \\cdot (0 \\cdot 1) + (M \\cdot 0) = 0$。\n因此，该矩阵是对角矩阵：\n$$\nA(M)A(M)^{\\top} = \\begin{bmatrix}\nM^2  0 \\\\\n0  n-1\n\\end{bmatrix}\n$$\n对角矩阵的特征值是其对角线元素：$\\lambda_a = M^2$ 和 $\\lambda_b = n-1$。对应的特征向量分别是标准基向量 $e_1 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$ 和 $e_2 = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$。\n\n主左奇异向量，我们记为 $u_{SVD}(M)$，是与最大特征值相关联的特征向量。我们必须比较 $M^2$ 和 $n-1$：\n\\begin{itemize}\n    \\item 如果 $M^2  n-1$（即 $M  \\sqrt{n-1}$ 因为 $M \\geq 0$），则最大特征值为 $n-1$。主左奇异向量是 $u_{SVD}(M) = e_2$。\n    \\item 如果 $M^2 > n-1$（即 $M > \\sqrt{n-1}$），则最大特征值为 $M^2$。主左奇异向量是 $u_{SVD}(M) = e_1$。\n    \\item 如果 $M^2 = n-1$，则特征值相等，此特征值的特征空间是整个 $\\mathbb{R}^2$。任何单位向量都是主左奇异向量。\n\\end{itemize}\n所以，主左奇异向量作为 $M$ 和 $n$ 的函数是：\n$$\nu_{SVD}(M) = \\begin{cases}\ne_2  \\text{如果 } M  \\sqrt{n-1} \\\\\ne_1  \\text{如果 } M > \\sqrt{n-1}\n\\end{cases}\n$$\n问题要求计算当 $M \\to \\infty$ 时，$u_{SVD}(M)$ 与真实方向 $e_2$ 之间的角度 $\\theta(M)$ 的余弦的极限。两个单位向量之间角度的余弦是它们的点积。\n当 $M \\to \\infty$ 时，我们处于 $M > \\sqrt{n-1}$ 的情况。对于任何这样的 $M$，$u_{SVD}(M) = e_1$。因此，\n$$\n\\cos(\\theta(M)) = u_{SVD}(M) \\cdot e_2 = e_1 \\cdot e_2 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\cdot \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = 0\n$$\n因此，极限是：\n$$\n\\lim_{M \\to \\infty} \\cos(\\theta(M)) = \\lim_{M \\to \\infty} 0 = 0\n$$\n\n(b) 确定 SVD 估计器的阈值 $M_2(n)$。\n\nSVD 估计器是主左奇异向量。当 $A(M)A(M)^{\\top}$ 的主导特征值改变时，它从真实方向 $e_2$ 切换到离群点方向 $e_1$。如上所述，这发生在 $M^2 = n-1$ 时。因为 $M \\geq 0$，阈值是 $M = \\sqrt{n-1}$。\n因此，基于 SVD 的近似的切换阈值是：\n$$\nM_2(n) = \\sqrt{n-1}\n$$\n\n(c) 确定基于 $\\ell_1$ 的估计器的阈值 $M_1(n)$。\n\n问题是在 $\\|u\\|_2 = 1$ 的约束下最小化 $J(u,v) = \\|A(M) - uv^{\\top}\\|_{\\ell_1} = \\sum_{i,j} |A_{ij} - (uv^{\\top})_{ij}|$。我们被要求评估两个候选方向 $u=e_2$ 和 $u=e_1$ 的最小代价，并找出其中一个何时优于另一个。\n\n情况 1：$u = e_2 = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$。\n近似为 $uv^{\\top} = e_2 v^{\\top} = \\begin{bmatrix} 0  0  \\cdots  0 \\\\ v_1  v_2  \\cdots  v_n \\end{bmatrix}$。残差矩阵是：\n$$\nA(M) - e_2 v^{\\top} = \\begin{bmatrix}\n0  0  \\cdots  0  M \\\\\n1-v_1  1-v_2  \\cdots  1-v_{n-1}  0-v_n\n\\end{bmatrix}\n$$\n$\\ell_1$ 误差是 $J(e_2, v) = |M| + \\sum_{j=1}^{n-1} |1-v_j| + |v_n|$。为了在 $v \\in \\mathbb{R}^n$ 上最小化此代价，我们可以独立地最小化每一项。当 $v_j=1$（对于 $j=1, \\dots, n-1$）和 $v_n=0$ 时达到最小值。这是因为一组数的中位数可以最小化绝对差之和。$\\{1, 1, \\dots, 1\\}$ 的中位数是 $1$，$\\{0\\}$ 的中位数是 $0$。\n对于 $u=e_2$ 的最小代价是：\n$$\nJ_2 = \\min_v J(e_2, v) = M + \\sum_{j=1}^{n-1} |1-1| + |0| = M\n$$\n（注意：给定 $M \\geq 0$）。\n\n情况 2：$u = e_1 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$。\n近似为 $uv^{\\top} = e_1 v^{\\top} = \\begin{bmatrix} v_1  v_2  \\cdots  v_n \\\\ 0  0  \\cdots  0 \\end{bmatrix}$。残差矩阵是：\n$$\nA(M) - e_1 v^{\\top} = \\begin{bmatrix}\n0-v_1  0-v_2  \\cdots  0-v_{n-1}  M-v_n \\\\\n1  1  \\cdots  1  0\n\\end{bmatrix}\n$$\n$\\ell_1$ 误差是 $J(e_1, v) = \\left(\\sum_{j=1}^{n-1} |-v_j| + |M-v_n|\\right) + \\left(\\sum_{j=1}^{n-1} |1| + |0|\\right)$。\n$J(e_1, v) = \\sum_{j=1}^{n-1} |v_j| + |M-v_n| + (n-1)$。\n为了在 $v$ 上最小化此代价，我们再次独立地最小化各项。当 $v_j=0$（对于 $j=1, \\dots, n-1$）和 $v_n=M$ 时达到最小值。\n对于 $u=e_1$ 的最小代价是：\n$$\nJ_1 = \\min_v J(e_1, v) = \\sum_{j=1}^{n-1} |0| + |M-M| + (n-1) = n-1\n$$\n\n基于 $\\ell_1$ 的估计器将选择导致更低最小代价的方向 $u$。从 $e_2$ 到 $e_1$ 的切换发生在 $J_1$ 小于 $J_2$ 时。阈值是代价相等的地方：\n$$\nJ_1 = J_2 \\implies n-1 = M\n$$\n如果 $M  n-1$，则 $J_2  J_1$，估计器选择 $u=e_2$。如果 $M > n-1$，则 $J_1  J_2$，估计器选择 $u=e_1$。因此，切换阈值为：\n$$\nM_1(n) = n-1\n$$\n\n最终答案是包含按顺序排列的三个所求量的行向量：\n1. $\\lim_{M \\to \\infty} \\cos \\theta(M) = 0$\n2. $M_2(n) = \\sqrt{n-1}$\n3. $M_1(n) = n-1$\n\n基于 SVD 的方法对离群点的平方量级 ($M^2$) 敏感，而基于 $\\ell_1$ 的方法对线性量级 ($M$) 敏感。这使得 $\\ell_1$ 方法明显更鲁棒，因为对于 $n2$ 的情况，其崩溃阈值 $M_1(n)=n-1$ 远大于 SVD 的崩溃阈值 $M_2(n)=\\sqrt{n-1}$。\n\n最终答案组合：$(\\lim_{M \\to \\infty} \\cos \\theta(M), M_2(n), M_1(n)) = (0, \\sqrt{n-1}, n-1)$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 0  \\sqrt{n-1}  n-1 \\end{pmatrix}}\n$$"
        }
    ]
}