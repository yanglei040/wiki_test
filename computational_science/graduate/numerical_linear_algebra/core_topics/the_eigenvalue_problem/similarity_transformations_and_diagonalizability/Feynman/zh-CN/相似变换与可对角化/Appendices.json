{
    "hands_on_practices": [
        {
            "introduction": "一个实数矩阵的可对角化性取决于我们是在实数域 $\\mathbb{R}$ 还是在复数域 $\\mathbb{C}$ 中进行操作。此练习  将引导您构建一个在 $\\mathbb{C}$ 上可对角化但在 $\\mathbb{R}$ 上不可对角化的矩阵，从而揭示这一关键区别。通过这个过程，您将探索实舒尔分解，这是一种在处理具有复共轭特征值的实矩阵时，既实用又数值稳定的替代方案。",
            "id": "3576903",
            "problem": "设 $a \\in \\mathbb{R}$ 且 $b \\in \\mathbb{R}$，其中 $b \\neq 0$。考虑实 $2 \\times 2$ 矩阵\n$$\nB \\;=\\; \\begin{pmatrix} a  b \\\\ -b  a \\end{pmatrix},\n$$\n并设 $S \\in \\mathbb{R}^{2 \\times 2}$ 为任意固定的实可逆矩阵，例如\n$$\nS \\;=\\; \\begin{pmatrix} 1  2 \\\\ 0  1 \\end{pmatrix}.\n$$\n定义\n$$\nA \\;=\\; S B S^{-1}.\n$$\n从相似性、特征值、在 $\\mathbb{R}$ 上和在 $\\mathbb{C}$（复数域）上的可对角化性以及实数版本的舒尔分解的基本定义出发，完成以下任务：\n\n- 证明 $A$ 的特征值为 $a \\pm b i$，在 $\\mathbb{R}$ 上不可对角化，但在 $\\mathbb{C}$ 上可对角化。\n- 将 $A$ 的实舒尔形式表示为单个 $2 \\times 2$ 旋转缩放块，解释为什么它必须具有以下结构\n$$\n\\begin{pmatrix} a  \\gamma \\\\ -\\gamma  a \\end{pmatrix}\n$$\n对于某个 $\\gamma > 0$，并用 $a$ 和 $b$ 表示 $\\gamma$。\n\n最后，计算 $A$ 的最小多项式 $m_A(x)$，它是一个关于 $x$ 的、具有实系数的显式多项式。请以单个闭式解析表达式的形式给出 $m_A(x)$ 的最终答案。本题无需进行数值四舍五入；不要包含任何单位。",
            "solution": "问题陈述在形式上是有效的。它是自洽的、数学上合理的且适定的。我们可以开始求解。\n\n该问题要求分析矩阵 $A = S B S^{-1}$，其中 $a \\in \\mathbb{R}$，$b \\in \\mathbb{R}$ 且 $b \\neq 0$，$B = \\begin{pmatrix} a  b \\\\ -b  a \\end{pmatrix}$，$S$ 是任意实可逆 $2 \\times 2$ 矩阵。\n\n首先，我们讨论 $A$ 的特征值及其在 $\\mathbb{R}$ 和 $\\mathbb{C}$ 上的可对角化性。\n\n根据定义，如果存在一个可逆矩阵 $S$ 使得 $A = S B S^{-1}$，则两个矩阵 $A$ 和 $B$ 是相似的。相似矩阵的一个基本性质是它们具有相同的特征多项式，因此具有相同的特征值。我们可以通过考虑特征值的定义来证明这一点。设 $\\lambda$ 是 $B$ 的一个特征值，其对应的非零特征向量为 $v$。那么，$Bv = \\lambda v$。我们定义一个向量 $w = Sv$。由于 $S$ 是可逆的且 $v \\neq 0$，所以 $w$ 也是一个非零向量。然后我们可以计算 $A$ 对 $w$ 的作用：\n$$\nAw = (SBS^{-1})w = (SBS^{-1})(Sv) = SB(S^{-1}S)v = SBv\n$$\n代入 $Bv = \\lambda v$，我们得到：\n$$\nAw = S(\\lambda v) = \\lambda (Sv) = \\lambda w\n$$\n这表明 $\\lambda$ 也是 $A$ 的一个特征值，其特征向量为 $w$。因此，$A$ 的特征值与 $B$ 的特征值相同。\n\n为了求出 $B$ 的特征值，我们计算其特征多项式 $p_B(\\lambda) = \\det(B - \\lambda I)$：\n$$\np_B(\\lambda) = \\det \\begin{pmatrix} a - \\lambda  b \\\\ -b  a - \\lambda \\end{pmatrix} = (a - \\lambda)^2 - (b)(-b) = (a - \\lambda)^2 + b^2\n$$\n特征值是特征方程 $p_B(\\lambda) = 0$ 的根：\n$$\n(a - \\lambda)^2 + b^2 = 0 \\implies (a - \\lambda)^2 = -b^2 \\implies a - \\lambda = \\pm \\sqrt{-b^2} = \\pm i \\sqrt{b^2} = \\pm i|b|\n$$\n所以，特征值为 $\\lambda = a \\mp i|b|$。特征值集合是 $\\{a + i|b|, a - i|b|\\}$。由于 $b \\neq 0$，所以 $|b| \\neq 0$。问题陈述将特征值表示为 $a \\pm bi$。无论 $b$ 的符号如何，这都是同一组特征值。我们将使用此表示法继续。$B$ 的特征值，也就是 $A$ 的特征值，是 $\\lambda_1 = a + bi$ 和 $\\lambda_2 = a - bi$。\n\n接下来，我们考虑 $A$ 的可对角化性。如果一个矩阵与一个对角矩阵相似，且该对角矩阵的元素来自域 $\\mathbb{F}$，则该矩阵在域 $\\mathbb{F}$ 上是可对角化的。这等价于说，对于底层的向量空间，存在一个由特征向量组成的基。\n一个实矩阵在实数域 $\\mathbb{R}$ 上可对角化的一个必要条件是其所有特征值都必须是实数。$A$ 的特征值是 $a \\pm bi$。因为给定 $b \\in \\mathbb{R}$ 且 $b \\neq 0$，所以特征值的虚部非零。因此，特征值不是实数。所以，矩阵 $A$ 在 $\\mathbb{R}$ 上不可对角化。\n\n现在，我们考虑在复数域 $\\mathbb{C}$ 上的可对角化性。一个 $n \\times n$ 矩阵如果在 $\\mathbb{C}$ 上有 $n$ 个线性无关的特征向量，则它在 $\\mathbb{C}$ 上是可对角化的。一个充分条件是该矩阵有 $n$ 个不同的特征值。矩阵 $A$ 是一个 $2 \\times 2$ 矩阵。其特征值为 $\\lambda_1 = a + bi$ 和 $\\lambda_2 = a - bi$。因为 $b \\neq 0$，所以 $bi \\neq -bi$，因此 $\\lambda_1 \\neq \\lambda_2$。由于 $A$ 是一个具有 $2$ 个不同特征值的 $2 \\times 2$ 矩阵，它保证有 $2$ 个线性无关的特征向量。因此，$A$ 在 $\\mathbb{C}$ 上是可对角化的。\n\n第二，我们分析 $A$ 的实舒尔形式。实舒尔分解定理指出，对于任何实方阵 $A$，存在一个实正交矩阵 $Q$（即 $Q^T Q = I$），使得 $T = Q^T A Q$ 是一个上拟三角矩阵。这个矩阵 $T$ 称为 $A$ 的一个实舒尔形式。其对角块的大小为 $1 \\times 1$（对应实特征值）或 $2 \\times 2$（对应共轭复特征值对）。\n由于矩阵 $A$ 是一个具有一对共轭复特征值 $a \\pm bi$（其中 $b \\neq 0$）的 $2 \\times 2$ 实矩阵，其舒尔实形式 $T$ 必须由一个单一的 $2 \\times 2$ 块组成。这个块 $T$ 与 $A$ 相似（因为 $T = Q^T A Q = Q^{-1} A Q$），因此必须具有相同的特征值 $a \\pm bi$。\n问题提出实舒尔形式具有结构 $C = \\begin{pmatrix} a  \\gamma \\\\ -\\gamma  a \\end{pmatrix}$，对于某个 $\\gamma > 0$。我们通过计算其特征多项式来求出矩阵 $C$ 的特征值：\n$$\n\\det(C - \\lambda I) = \\det \\begin{pmatrix} a - \\lambda  \\gamma \\\\ -\\gamma  a - \\lambda \\end{pmatrix} = (a - \\lambda)^2 + \\gamma^2\n$$\n特征值是 $(a - \\lambda)^2 + \\gamma^2 = 0$ 的根，即 $\\lambda = a \\pm i\\gamma$。\n为了使这些特征值与 $A$ 的特征值 $a \\pm bi$ 相匹配，我们必须有 $\\{a \\pm i\\gamma\\} = \\{a \\pm bi\\}$。这意味着 $\\gamma = |b|$。因为问题指定 $\\gamma > 0$ 且给定 $b \\neq 0$，我们有 $\\gamma = |b|$。因此，$A$ 的一个实舒尔形式具有指定的旋转缩放结构，其中 $\\gamma = |b|$。\n\n最后，我们计算 $A$ 的最小多项式 $m_A(x)$。矩阵 $A$ 的最小多项式是次数最小的唯一首一多项式，当将 $A$ 代入该多项式时，得到零矩阵。最小多项式的根是矩阵的特征值。\n$A$ 的特征值是 $\\lambda_1 = a + bi$ 和 $\\lambda_2 = a - bi$。因此，$m_A(x)$ 必须能被 $(x - \\lambda_1)$ 和 $(x - \\lambda_2)$ 整除。由于我们要求 $m_A(x)$ 具有实系数，它必须能被它们的乘积整除：\n$$\n(x - (a + bi))(x - (a - bi)) = ((x-a) - bi)((x-a) + bi) = (x-a)^2 - (bi)^2 = (x-a)^2 + b^2\n$$\n设这个多项式为 $p(x) = x^2 - 2ax + a^2 + b^2$。这是一个次数为 $2$ 的实系数首一多项式。\n最小多项式 $m_A(x)$ 必须整除特征多项式 $p_A(x)$。我们已经求出 $B$ 的特征多项式为 $p_B(x) = (x-a)^2 + b^2 = x^2 - 2ax + a^2 + b^2$。由于 $A$ 和 $B$ 相似，$p_A(x) = p_B(x)$。\n最小多项式 $m_A(x)$ 的次数必须至少为 $2$，因为一个次数为 $1$ 的实系数多项式会有一个实根，这与 $A$ 的特征值非实数的事实相矛盾。\n由于 $m_A(x)$ 必须整除 $p_A(x)$，且两者次数都为 $2$，并且都是首一多项式，因此它们必须相等。这也是 $A$ 的特征值互不相同的直接结果。对于任何具有不同特征值的矩阵，最小多项式与特征多项式相同。\n因此，$A$ 的最小多项式是：\n$$\nm_A(x) = x^2 - 2ax + a^2 + b^2\n$$\n这是一个具有实系数的 $m_A(x)$ 的单一闭式解析表达式。",
            "answer": "$$\n\\boxed{x^{2} - 2ax + a^{2} + b^{2}}\n$$"
        },
        {
            "introduction": "从理论上讲，一个矩阵要么是可对角化的，要么是不可对角化的，但从数值角度看，情况要微妙得多。一个“几乎”不可对角化的矩阵即使在理论上是可对角化的，其特征系统也可能表现出极端的数值不稳定性。本练习  通过对一个若尔当块进行微扰，从第一性原理出发，严谨地分析了这种现象，揭示了特征向量矩阵的条件数是如何随着扰动变小而急剧恶化的。",
            "id": "3576868",
            "problem": "考虑一个带有$2$阶若尔当块的非正规矩阵的秩$1$扰动。设\n$$\nA \\in \\mathbb{R}^{3 \\times 3}, \\quad A = \\begin{pmatrix} 0  1  0 \\\\ 0  0  0 \\\\ 0  0  3 \\end{pmatrix}, \\quad u = \\begin{pmatrix} 1 \\\\ 2 \\\\ 0 \\end{pmatrix}, \\quad v = \\begin{pmatrix} 3 \\\\ 0 \\\\ 0 \\end{pmatrix},\n$$\n并定义，对于 $\\varepsilon > 0$，\n$$\nA(\\varepsilon) \\coloneqq A + \\varepsilon\\, u v^{\\top}.\n$$\n完全从第一性原理出发：仅使用特征值和特征向量的定义、相似对角化、谱范数（最大奇异值）以及标准的代数运算。不要假设任何现成的扰动理论结果，也不要引用任何未经证明的渐近公式。\n\n对于所有足够小的 $\\varepsilon > 0$，矩阵 $A(\\varepsilon)$ 是可对角化的。定义 $S(\\varepsilon) \\in \\mathbb{R}^{3 \\times 3}$ 是一个矩阵，其列是 $A(\\varepsilon)$ 的右特征向量，并按如下方式归一化：对于与从瑕疵特征值 $0$ 分岔出来的两个特征值相关联的两个特征向量，将每个向量归一化使其第一个分量等于 $1$，并将第三列取为标准基向量 $e_{3}$。在此归一化下，$S(\\varepsilon)$ 是唯一的，并满足 $S(\\varepsilon)^{-1} A(\\varepsilon) S(\\varepsilon)$ 是对角矩阵。\n\n令 $\\kappa_{2}(S(\\varepsilon))$ 表示 $S(\\varepsilon)$ 的谱范数条件数，即 $\\kappa_{2}(S(\\varepsilon)) \\coloneqq \\|S(\\varepsilon)\\|_{2}\\,\\|S(\\varepsilon)^{-1}\\|_{2}$，其中 $\\|\\cdot\\|_{2}$ 是由欧几里得范数诱导的算子范数。\n\n计算当 $\\varepsilon \\to 0^{+}$ 时 $\\kappa_{2}(S(\\varepsilon))$ 的渐近标度中的首项系数 $C$ 的精确值，该系数由以下极限定义：\n$$\nC \\coloneqq \\lim_{\\varepsilon \\to 0^{+}} \\varepsilon^{1/2}\\, \\kappa_{2}(S(\\varepsilon)).\n$$\n你的最终答案必须是单一的封闭形式表达式。不需要四舍五入。",
            "solution": "该问题要求解扰动矩阵 $A(\\varepsilon)$ 的特征向量矩阵 $S(\\varepsilon)$ 的条件数 $\\kappa_{2}(S(\\varepsilon))$ 的渐近标度中的首项系数 $C$。分析将从第一性原理出发。\n\n首先，我们定义矩阵 $A(\\varepsilon)$。给定的矩阵是：\n$$\nA = \\begin{pmatrix} 0  1  0 \\\\ 0  0  0 \\\\ 0  0  3 \\end{pmatrix}, \\quad u = \\begin{pmatrix} 1 \\\\ 2 \\\\ 0 \\end{pmatrix}, \\quad v = \\begin{pmatrix} 3 \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\n秩$1$扰动项是\n$$\n\\varepsilon u v^{\\top} = \\varepsilon \\begin{pmatrix} 1 \\\\ 2 \\\\ 0 \\end{pmatrix} \\begin{pmatrix} 3  0  0 \\end{pmatrix} = \\begin{pmatrix} 3\\varepsilon  0  0 \\\\ 6\\varepsilon  0  0 \\\\ 0  0  0 \\end{pmatrix}.\n$$\n因此，对于 $\\varepsilon > 0$，扰动矩阵 $A(\\varepsilon)$ 是\n$$\nA(\\varepsilon) = A + \\varepsilon u v^{\\top} = \\begin{pmatrix} 3\\varepsilon  1  0 \\\\ 6\\varepsilon  0  0 \\\\ 0  0  3 \\end{pmatrix}.\n$$\n为了找到特征向量矩阵 $S(\\varepsilon)$，我们首先需要 $A(\\varepsilon)$ 的特征值。这些是特征方程 $\\det(A(\\varepsilon) - \\lambda I) = 0$ 的根：\n$$\n\\det \\begin{pmatrix} 3\\varepsilon - \\lambda  1  0 \\\\ 6\\varepsilon  -\\lambda  0 \\\\ 0  0  3 - \\lambda \\end{pmatrix} = 0.\n$$\n沿第三行展开行列式得到：\n$$\n(3 - \\lambda) \\det \\begin{pmatrix} 3\\varepsilon - \\lambda  1 \\\\ 6\\varepsilon  -\\lambda \\end{pmatrix} = (3 - \\lambda) \\big( (-\\lambda)(3\\varepsilon - \\lambda) - 6\\varepsilon \\big) = (3 - \\lambda)(\\lambda^2 - 3\\varepsilon\\lambda - 6\\varepsilon) = 0.\n$$\n特征值是 $\\lambda_3 = 3$ 以及二次方程 $\\lambda^2 - 3\\varepsilon\\lambda - 6\\varepsilon = 0$ 的两个根。使用二次公式，这两个根是：\n$$\n\\lambda_{1,2} = \\frac{3\\varepsilon \\pm \\sqrt{(3\\varepsilon)^2 - 4(1)(-6\\varepsilon)}}{2} = \\frac{3\\varepsilon \\pm \\sqrt{9\\varepsilon^2 + 24\\varepsilon}}{2}.\n$$\n对于足够小的 $\\varepsilon > 0$，判别式 $9\\varepsilon^2 + 24\\varepsilon$ 为正，因此 $\\lambda_1$ 和 $\\lambda_2$ 是实数且不相等。当 $\\varepsilon \\to 0$ 时，$\\lambda_1$ 和 $\\lambda_2$ 都趋近于 $0$，这是 $A$ 的瑕疵特征值。\n\n接下来，我们求相应的特征向量。\n对于 $\\lambda_3 = 3$，特征向量 $x = (x_1, x_2, x_3)^{\\top}$ 满足 $(A(\\varepsilon) - 3I)x = 0$：\n$$\n\\begin{pmatrix} 3\\varepsilon-3  1  0 \\\\ 6\\varepsilon  -3  0 \\\\ 0  0  0 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\n对于小的 $\\varepsilon > 0$，左上角的 $2 \\times 2$ 子矩阵是非奇异的，这意味着 $x_1=0$ 和 $x_2=0$。因此，特征向量的形式为 $(0, 0, x_3)^{\\top}$。问题指定将此特征向量取为标准基向量 $e_3 = (0, 0, 1)^{\\top}$。\n\n对于来自 $\\{\\lambda_1, \\lambda_2\\}$ 的特征值 $\\lambda$，特征向量 $x = (x_1, x_2, x_3)^{\\top}$ 满足 $(A(\\varepsilon) - \\lambda I)x = 0$：\n$$\n\\begin{pmatrix} 3\\varepsilon - \\lambda  1  0 \\\\ 6\\varepsilon  -\\lambda  0 \\\\ 0  0  3 - \\lambda \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\n由于当 $\\varepsilon \\to 0$ 时 $\\lambda_{1,2} \\to 0$，对于小的 $\\varepsilon$，$\\lambda \\neq 3$。第三个方程 $(3-\\lambda)x_3=0$ 意味着 $x_3=0$。前两个方程是：\n$$\n(3\\varepsilon - \\lambda)x_1 + x_2 = 0.\n$$\n$$\n6\\varepsilon x_1 - \\lambda x_2 = 0.\n$$\n问题指定将这两个特征向量归一化，使其第一个分量等于 $1$。设 $x_1 = 1$，第一个方程给出 $x_2 = \\lambda - 3\\varepsilon$。(第二个方程 $6\\varepsilon - \\lambda(\\lambda-3\\varepsilon) = -\\lambda^2+3\\varepsilon\\lambda+6\\varepsilon = 0$ 是满足的，因为 $\\lambda$ 是该多项式的根)。\n因此，对应于 $\\lambda_1$ 和 $\\lambda_2$ 的特征向量是：\n$$\nx_1(\\varepsilon) = \\begin{pmatrix} 1 \\\\ \\lambda_1 - 3\\varepsilon \\\\ 0 \\end{pmatrix}, \\quad x_2(\\varepsilon) = \\begin{pmatrix} 1 \\\\ \\lambda_2 - 3\\varepsilon \\\\ 0 \\end{pmatrix}.\n$$\n特征向量矩阵 $S(\\varepsilon)$ 由这些归一化的特征向量作为列构成：\n$$\nS(\\varepsilon) = \\begin{pmatrix} 1  1  0 \\\\ \\lambda_1 - 3\\varepsilon  \\lambda_2 - 3\\varepsilon  0 \\\\ 0  0  1 \\end{pmatrix}.\n$$\n为了分析条件数，我们研究 $S(\\varepsilon)$ 的奇异值，它们是 $S(\\varepsilon)^{\\top}S(\\varepsilon)$ 特征值的平方根。令 $y_1 = \\lambda_1 - 3\\varepsilon$ 和 $y_2 = \\lambda_2 - 3\\varepsilon$。\n$$\nS(\\varepsilon)^{\\top}S(\\varepsilon) = \\begin{pmatrix} 1  y_1  0 \\\\ 1  y_2  0 \\\\ 0  0  1 \\end{pmatrix} \\begin{pmatrix} 1  1  0 \\\\ y_1  y_2  0 \\\\ 0  0  1 \\end{pmatrix} = \\begin{pmatrix} 1+y_1^2  1+y_1y_2  0 \\\\ 1+y_1y_2  1+y_2^2  0 \\\\ 0  0  1 \\end{pmatrix}.\n$$\n$S(\\varepsilon)^{\\top}S(\\varepsilon)$ 的一个特征值是 $1$。另外两个，我们称之为 $\\mu$，是左上角 $2 \\times 2$ 子矩阵 $M = \\begin{pmatrix} 1+y_1^2  1+y_1y_2 \\\\ 1+y_1y_2  1+y_2^2 \\end{pmatrix}$ 的特征值。特征方程是 $\\mu^2 - \\text{tr}(M)\\mu + \\det(M) = 0$。\n迹是 $\\text{tr}(M) = 2 + y_1^2+y_2^2$。\n行列式是 $\\det(M) = (1+y_1^2)(1+y_2^2) - (1+y_1y_2)^2 = 1+y_1^2+y_2^2+y_1^2y_2^2 - (1+2y_1y_2+y_1^2y_2^2) = y_1^2+y_2^2-2y_1y_2=(y_1-y_2)^2$。\n\n我们需要用 $\\varepsilon$ 来表示这些项。根据 $\\lambda^2 - 3\\varepsilon\\lambda - 6\\varepsilon = 0$ 的韦达定理，我们有 $\\lambda_1+\\lambda_2 = 3\\varepsilon$ 和 $\\lambda_1\\lambda_2 = -6\\varepsilon$。\n$y_1+y_2 = (\\lambda_1-3\\varepsilon)+(\\lambda_2-3\\varepsilon) = (\\lambda_1+\\lambda_2)-6\\varepsilon = 3\\varepsilon-6\\varepsilon = -3\\varepsilon$。\n$y_1y_2 = (\\lambda_1-3\\varepsilon)(\\lambda_2-3\\varepsilon) = \\lambda_1\\lambda_2 - 3\\varepsilon(\\lambda_1+\\lambda_2) + 9\\varepsilon^2 = -6\\varepsilon - 3\\varepsilon(3\\varepsilon) + 9\\varepsilon^2 = -6\\varepsilon$。\n$y_1^2+y_2^2 = (y_1+y_2)^2-2y_1y_2 = (-3\\varepsilon)^2 - 2(-6\\varepsilon) = 9\\varepsilon^2+12\\varepsilon$。\n$(y_1-y_2)^2 = (\\lambda_1-\\lambda_2)^2 = (\\lambda_1+\\lambda_2)^2-4\\lambda_1\\lambda_2 = (3\\varepsilon)^2-4(-6\\varepsilon) = 9\\varepsilon^2+24\\varepsilon$。\n\n所以，$\\text{tr}(M) = 2+12\\varepsilon+9\\varepsilon^2$ 并且 $\\det(M) = 24\\varepsilon+9\\varepsilon^2$。\n$\\mu$ 的特征方程是：\n$$\n\\mu^2 - (2+12\\varepsilon+9\\varepsilon^2)\\mu + (24\\varepsilon+9\\varepsilon^2) = 0.\n$$\n设根为 $\\mu_{max}(\\varepsilon)$ 和 $\\mu_{min}(\\varepsilon)$。当 $\\varepsilon \\to 0^+$ 时，该方程变为 $\\mu^2 - 2\\mu = 0$，其根为 $0$ 和 $2$。因此，$\\lim_{\\varepsilon\\to 0^+} \\mu_{max}(\\varepsilon) = 2$ 且 $\\lim_{\\varepsilon\\to 0^+} \\mu_{min}(\\varepsilon) = 0$。\n\n$S(\\varepsilon)$ 的奇异值为 $\\sigma_i(\\varepsilon) = \\sqrt{\\mu_i}$，其中 $\\mu_i$ 是 $S(\\varepsilon)^\\top S(\\varepsilon)$ 的特征值。三个特征值是 $1$、$\\mu_{max}(\\varepsilon)$ 和 $\\mu_{min}(\\varepsilon)$。对于小的 $\\varepsilon > 0$，我们有 $0  \\mu_{min}(\\varepsilon)  1  \\mu_{max}(\\varepsilon)$。最大和最小奇异值分别是 $\\sigma_{max}(S(\\varepsilon)) = \\sqrt{\\mu_{max}(\\varepsilon)}$ 和 $\\sigma_{min}(S(\\varepsilon)) = \\sqrt{\\mu_{min}(\\varepsilon)}$。\n\n条件数是 $\\kappa_2(S(\\varepsilon)) = \\frac{\\sigma_{max}(S(\\varepsilon))}{\\sigma_{min}(S(\\varepsilon))}$。\n我们有 $\\lim_{\\varepsilon\\to 0^+} \\sigma_{max}(S(\\varepsilon)) = \\lim_{\\varepsilon\\to 0^+} \\sqrt{\\mu_{max}(\\varepsilon)} = \\sqrt{2}$。\n\n为了找到 $\\sigma_{min}(S(\\varepsilon))$ 的渐近行为，我们研究 $\\mu_{min}(\\varepsilon)$。根据 $\\mu$ 的二次方程，根的乘积是常数项：$\\mu_{max}(\\varepsilon)\\mu_{min}(\\varepsilon) = 24\\varepsilon+9\\varepsilon^2$。\n因此，$\\mu_{min}(\\varepsilon) = \\frac{24\\varepsilon+9\\varepsilon^2}{\\mu_{max}(\\varepsilon)}$。\n除以 $\\varepsilon$ 并取 $\\varepsilon \\to 0^+$ 的极限：\n$$\n\\lim_{\\varepsilon\\to 0^+} \\frac{\\mu_{min}(\\varepsilon)}{\\varepsilon} = \\lim_{\\varepsilon\\to 0^+} \\frac{24+9\\varepsilon}{\\mu_{max}(\\varepsilon)} = \\frac{24+0}{2} = 12.\n$$\n这意味着对于小的 $\\varepsilon$，$\\mu_{min}(\\varepsilon) \\sim 12\\varepsilon$。\n所以，$\\sigma_{min}(S(\\varepsilon)) = \\sqrt{\\mu_{min}(\\varepsilon)} \\sim \\sqrt{12\\varepsilon} = 2\\sqrt{3}\\varepsilon^{1/2}$。\n\n现在我们可以计算系数 $C$ 的所需极限：\n$$\nC = \\lim_{\\varepsilon \\to 0^{+}} \\varepsilon^{1/2}\\, \\kappa_{2}(S(\\varepsilon)) = \\lim_{\\varepsilon \\to 0^{+}} \\varepsilon^{1/2} \\frac{\\sigma_{max}(S(\\varepsilon))}{\\sigma_{min}(S(\\varepsilon))}.\n$$\n我们可以将其重新排列为：\n$$\nC = \\frac{\\lim_{\\varepsilon \\to 0^{+}} \\sigma_{max}(S(\\varepsilon))}{\\lim_{\\varepsilon \\to 0^{+}} (\\sigma_{min}(S(\\varepsilon)) / \\varepsilon^{1/2})}.\n$$\n代入我们求得的极限：\n分子是 $\\lim_{\\varepsilon\\to 0^+} \\sigma_{max}(S(\\varepsilon)) = \\sqrt{2}$。\n分母是 $\\lim_{\\varepsilon\\to 0^+} \\frac{\\sigma_{min}(S(\\varepsilon))}{\\varepsilon^{1/2}} = \\lim_{\\varepsilon\\to 0^+} \\frac{\\sqrt{12\\varepsilon+O(\\varepsilon^2)}}{\\varepsilon^{1/2}} = \\sqrt{12} = 2\\sqrt{3}$。\n$$\nC = \\frac{\\sqrt{2}}{2\\sqrt{3}} = \\frac{\\sqrt{2}}{2\\sqrt{3}} \\cdot \\frac{\\sqrt{3}}{\\sqrt{3}} = \\frac{\\sqrt{6}}{6}.\n$$\n首项系数的值是 $\\frac{\\sqrt{6}}{6}$。",
            "answer": "$$\\boxed{\\frac{\\sqrt{6}}{6}}$$"
        },
        {
            "introduction": "在通过理论分析理解了数值不稳定性的根源之后，现在是时候通过实践来亲眼见证它了。这个动手编程练习  旨在建立一个数值实验室，以观察和量化特征向量的脆弱性。通过系统地调整一个矩阵与其对应的有缺陷形式的“接近度”以及扰动的大小，您将直接衡量特征向量对微小变化的敏感性，从而加深对数值稳定性的理解。",
            "id": "3576932",
            "problem": "您需要设计并实现一个数值实验，以探究当对角化在理论上可行，但由于特征向量近似线性相关而导致数值上脆弱时，相似变换的稳定性。该研究必须基于线性代数中相似性和可对角化性的核心定义。一个方阵 $A \\in \\mathbb{R}^{n \\times n}$ 是可对角化的，如果存在一个可逆矩阵 $S \\in \\mathbb{R}^{n \\times n}$ 和一个对角矩阵 $\\Lambda \\in \\mathbb{R}^{n \\times n}$，使得 $A = S \\Lambda S^{-1}$。$S$ 的列是 $A$ 的特征向量，$\\Lambda$ 的对角线元素是对应的特征值。当 $S$ 的列近似线性相关时，在精确计算中 $S$ 的可逆性保持不变，但 $S$ 会变得病态，使得相似变换在 $A$ 受到扰动时数值上不稳定。\n\n构造一个参数化的实 $2 \\times 2$ 矩阵族\n$$\nA(\\delta) = \\begin{bmatrix}\n1  1 \\\\\n0  1+\\delta\n\\end{bmatrix},\n$$ \n参数 $\\delta  0$，并考虑微小的确定性扰动\n$$\nE(\\varepsilon) = \\begin{bmatrix}\n0  0 \\\\\n\\varepsilon  0\n\\end{bmatrix},\n$$ \n参数 $\\varepsilon \\ge 0$，定义 $B(\\delta,\\varepsilon) = A(\\delta) + E(\\varepsilon)$。对于每个三元组 $(\\delta,\\varepsilon,\\tau)$，您必须执行以下计算任务：\n\n1. 对 $A(\\delta)$ 和 $B(\\delta,\\varepsilon)$ 进行数值特征分解，以分别获得特征向量矩阵 $S_A$ 和 $S_B$ 及其特征值。按特征值升序排列特征向量以形成 $S_A$ 和 $S_B$。将每个特征向量归一化为单位欧几里得长度，并通过强制第一个非零项为非负来固定符号，以消除任意的缩放和符号歧义。\n2. 计算 $S_A$ 在矩阵 $2$-范数下的谱条件数，\n$$\n\\kappa_2(S_A) = \\|S_A\\|_2 \\cdot \\|S_A^{-1}\\|_2,\n$$\n其中 $\\|\\cdot\\|_2$ 表示由向量 $2$-范数诱导的算子范数。\n3. 对于来自 $S_A$ 的相应有序和归一化特征向量 $v_i$ 和来自 $S_B$ 的 $w_i$（其中 $i \\in \\{1,2\\}$），计算主角\n$$\n\\theta_i = \\arccos\\!\\left(\\frac{|v_i^\\top w_i|}{\\|v_i\\|_2 \\cdot \\|w_i\\|_2}\\right),\n$$\n以弧度表示，并报告每个三元组 $(\\delta,\\varepsilon,\\tau)$ 的最大角 $\\max\\{\\theta_1,\\theta_2\\}$。\n4. 通过将最大角与阈值 $\\tau$ 进行比较，声明一个布尔值的鲁棒性判定：如果 $\\max\\{\\theta_1,\\theta_2\\} \\le \\tau$，则实验是鲁棒的，否则为非鲁棒。\n\n您的程序必须对以下旨在涵盖不同情形的参数三元组测试套件实现上述操作：\n\n- $(\\delta,\\varepsilon,\\tau) = (10^{-1}, 10^{-8}, 0.05)$,\n- $(\\delta,\\varepsilon,\\tau) = (10^{-4}, 10^{-6}, 0.05)$,\n- $(\\delta,\\varepsilon,\\tau) = (10^{-8}, 10^{-12}, 0.05)$,\n- $(\\delta,\\varepsilon,\\tau) = (10^{-8}, 10^{-8}, 0.05)$,\n- $(\\delta,\\varepsilon,\\tau) = (10^{-6}, 5 \\cdot 10^{-6}, 0.05)$.\n\n所有角度必须以弧度表示。整个测试套件的最终输出必须是单行，由一个顶层列表组成，其中每个元素本身都是一个形式为 $[\\theta_{\\max}, \\kappa_2(S_A), \\text{robust}]$ 的列表，其中 $\\theta_{\\max}$ 是一个浮点数，$\\kappa_2(S_A)$ 是一个浮点数，$\\text{robust}$ 是一个布尔值。您的程序应生成包含结果的单行输出，结果为用方括号括起来的逗号分隔列表（例如，$[[\\theta_1,\\kappa_1,\\text{True}],[\\theta_2,\\kappa_2,\\text{False}]]$）。不允许外部输入；所有参数均按上文给定值固定。",
            "solution": "该问题陈述是有效的。它提出了一个在线性代数中良构的数值实验，基于矩阵理论的既定原则，特别是关于特征系统的可对角化性和稳定性。所有术语都有正式定义，参数完整，任务在计算上是可行的。\n\n目标是研究一个接近亏损（即不可对角化）的矩阵其特征向量的数值稳定性。如果一个矩阵具有重复的特征值和数量不足的线性无关特征向量，则该矩阵是亏损的。所提供的矩阵族 $A(\\delta)$ 被设计为在参数 $\\delta$ 趋近于 $0$ 时趋近于一个亏损矩阵。\n\n该矩阵族由下式给出\n$$ A(\\delta) = \\begin{bmatrix} 1  1 \\\\ 0  1+\\delta \\end{bmatrix}, \\quad \\delta  0 $$\n由于 $A(\\delta)$ 是一个上三角矩阵，其特征值是其对角线元素，即 $\\lambda_{A,1} = 1$ 和 $\\lambda_{A,2} = 1+\\delta$。对于 $\\delta  0$，这些特征值是互不相同的，这保证了 $A(\\delta)$ 是可对角化的。\n\n相应的右特征向量通过求解 $(A(\\delta) - \\lambda I)v = 0$ 找到。\n对于 $\\lambda_{A,1} = 1$：\n$$ (A(\\delta) - 1 \\cdot I)v = \\begin{bmatrix} 0  1 \\\\ 0  \\delta \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} \\implies y=0 $$\n特征向量是 $v_1 = [1, 0]^\\top$ 的任意倍数。\n\n对于 $\\lambda_{A,2} = 1+\\delta$：\n$$ (A(\\delta) - (1+\\delta)I)v = \\begin{bmatrix} -\\delta  1 \\\\ 0  0 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} \\implies -\\delta x + y = 0 $$\n特征向量是 $v_2 = [1, \\delta]^\\top$ 的任意倍数。\n\n当 $\\delta \\to 0$ 时，两个特征值在 $\\lambda=1$ 处汇合。与此同时，特征向量 $v_2$ 趋近于 $v_1$，变得近似线性相关。$v_1$ 和 $v_2$ 之间的夹角约为 $\\delta$ 弧度。\n\n特征向量矩阵 $S_A$ 由归一化和排序后的特征向量构成。按照问题的规定（按特征值升序排列，归一化为单位长度，并固定符号使第一个非零项为非负），我们得到：\n$$ v_1^{\\text{norm}} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}, \\quad v_2^{\\text{norm}} = \\frac{1}{\\sqrt{1+\\delta^2}} \\begin{bmatrix} 1 \\\\ \\delta \\end{bmatrix} $$\n$$ S_A = \\begin{bmatrix} 1  \\frac{1}{\\sqrt{1+\\delta^2}} \\\\ 0  \\frac{\\delta}{\\sqrt{1+\\delta^2}} \\end{bmatrix} $$\n当 $\\delta \\to 0$ 时，该矩阵变得病态，这从其行列式 $\\det(S_A) = \\frac{\\delta}{\\sqrt{1+\\delta^2}}$ 趋近于 $0$ 可以明显看出。条件数 $\\kappa_2(S_A) = \\|S_A\\|_2 \\|S_A^{-1}\\|_2$ 预计对于小的 $\\delta$ 会很大。从解析上可以发现，$\\|S_A^{-1}\\|_2$ 按 $O(1/\\delta)$ 的比例变化，因此 $\\kappa_2(S_A)$ 按 $1/\\delta$ 增长。大的条件数表明特征向量基对扰动敏感。\n\n实验对 $A(\\delta)$ 引入了一个扰动 $E(\\varepsilon)$，得到矩阵：\n$$ B(\\delta, \\varepsilon) = A(\\delta) + E(\\varepsilon) = \\begin{bmatrix} 1  1 \\\\ \\varepsilon  1+\\delta \\end{bmatrix} $$\n任务的核心是对于给定的参数集 $(\\delta, \\varepsilon, \\tau)$，数值计算 $A(\\delta)$ 和 $B(\\delta, \\varepsilon)$ 的特征系统，并量化特征向量的变化。该变化通过相应特征向量之间的最大主角来衡量。\n\n对于每个参数三元组 $(\\delta, \\varepsilon, \\tau)$ 的计算步骤如下：\n1.  构造矩阵 $A(\\delta)$ 和 $B(\\delta, \\varepsilon)$。\n2.  使用标准的特征求解器（例如，来自 NumPy 库）对两个矩阵进行数值计算，得到特征值和特征向量。\n3.  对于每个矩阵，按升序对特征值进行排序，并重新排序相应的特征向量，以构成特征向量矩阵 $S_A$ 和 $S_B$ 的列。\n4.  为保证唯一性，对每个特征向量进行标准化：\n    a. 将向量归一化，使其欧几里得范数为 $1$。\n    b. 如果归一化向量的第一个非零元素为负，则将该向量乘以 $-1$。\n5.  使用矩阵 $2$-范数计算所得矩阵 $S_A$ 的谱条件数：$\\kappa_2(S_A) = \\|S_A\\|_2 \\|S_A^{-1}\\|_2$。\n6.  处理后的矩阵 $S_A = [v_1, v_2]$ 和 $S_B = [w_1, w_2]$ 的列是标准化后的特征向量。计算主角 $\\theta_1 = \\arccos(|v_1^\\top w_1|)$ 和 $\\theta_2 = \\arccos(|v_2^\\top w_2|)$。由于向量是单位范数，取点积的绝对值直接给出角度。必须注意浮点运算，以确保 $\\arccos$ 的参数在有效范围 $[-1, 1]$ 内。\n7.  确定最大角 $\\theta_{\\max} = \\max\\{\\theta_1, \\theta_2\\}$。\n8.  如果 $\\theta_{\\max} \\le \\tau$，则将结果分类为鲁棒，否则为非鲁棒。\n\n该过程将系统地应用于所提供的测试套件，以生成所需的输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_standardized_eigensystem(matrix):\n    \"\"\"\n    Computes eigenvalues and eigenvectors of a matrix, then standardizes them.\n\n    1. Eigenvectors are sorted according to ascending eigenvalues.\n    2. Each eigenvector is normalized to unit L2 norm.\n    3. The sign of each eigenvector is fixed by making its first non-zero\n       element non-negative.\n    \n    Args:\n        matrix (np.ndarray): A square matrix.\n\n    Returns:\n        np.ndarray: The standardized eigenvector matrix S, where columns are\n                    the standardized eigenvectors.\n    \"\"\"\n    eigvals, eigvecs = np.linalg.eig(matrix)\n    \n    # 1. Sort eigenvectors based on ascending eigenvalues\n    sort_indices = np.argsort(eigvals)\n    sorted_eigvecs = eigvecs[:, sort_indices]\n    \n    standardized_S = np.zeros_like(sorted_eigvecs, dtype=float)\n    \n    for i in range(sorted_eigvecs.shape[1]):\n        vec = sorted_eigvecs[:, i]\n        \n        # 2. Normalize to unit Euclidean length\n        norm = np.linalg.norm(vec, 2)\n        if norm  0:\n            vec_normalized = vec / norm\n        else:\n            # Should not happen for eigenvectors, but handle gracefully.\n            vec_normalized = vec\n        \n        # 3. Fix sign by enforcing a non-negative first non-zero entry\n        first_nonzero_indices = np.flatnonzero(np.round(vec_normalized, 15))\n        if first_nonzero_indices.size  0:\n            first_nonzero_idx = first_nonzero_indices[0]\n            if vec_normalized[first_nonzero_idx]  0:\n                vec_normalized *= -1\n        \n        standardized_S[:, i] = vec_normalized\n        \n    return standardized_S\n\ndef solve():\n    \"\"\"\n    Main function to run the numerical experiment for the given test suite.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (delta, epsilon, tau)\n        (1e-1, 1e-8, 0.05),\n        (1e-4, 1e-6, 0.05),\n        (1e-8, 1e-12, 0.05),\n        (1e-8, 1e-8, 0.05),\n        (1e-6, 5e-6, 0.05),\n    ]\n\n    results = []\n    for delta, epsilon, tau in test_cases:\n        # Construct matrices A(delta) and B(delta, epsilon)\n        A_delta = np.array([[1.0, 1.0], \n                             [0.0, 1.0 + delta]], dtype=float)\n        \n        B_delta_eps = np.array([[1.0, 1.0], \n                                [epsilon, 1.0 + delta]], dtype=float)\n\n        # Task 1: Compute standardized eigen-decompositions\n        S_A = compute_standardized_eigensystem(A_delta)\n        S_B = compute_standardized_eigensystem(B_delta_eps)\n        \n        # Task 2: Compute spectral condition number of S_A\n        kappa_2_SA = np.linalg.cond(S_A, 2)\n        \n        # Task 3: Compute maximum principal angle\n        v1, v2 = S_A[:, 0], S_A[:, 1]\n        w1, w2 = S_B[:, 0], S_B[:, 1]\n        \n        # Clip dot product to handle potential floating point inaccuracies\n        dot1 = np.clip(np.abs(v1.T @ w1), -1.0, 1.0)\n        dot2 = np.clip(np.abs(v2.T @ w2), -1.0, 1.0)\n        \n        theta1 = np.arccos(dot1)\n        theta2 = np.arccos(dot2)\n        \n        theta_max = max(theta1, theta2)\n        \n        # Task 4: Declare robustness decision\n        is_robust = theta_max = tau\n        \n        results.append([theta_max, kappa_2_SA, is_robust])\n\n    # Final print statement in the exact required format.\n    # [ [theta_max1, kappa1, robust1], [theta_max2, kappa2, robust2], ... ]\n    sublist_strings = []\n    for res in results:\n        # Format each sublist as a string \"[val1,val2,val3]\"\n        sublist_str = f\"[{res[0]},{res[1]},{res[2]}]\"\n        sublist_strings.append(sublist_str)\n    \n    final_output = f\"[{','.join(sublist_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}