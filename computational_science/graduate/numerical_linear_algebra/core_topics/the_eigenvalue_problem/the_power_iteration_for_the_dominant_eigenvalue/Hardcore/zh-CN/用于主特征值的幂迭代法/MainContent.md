## 引言
在[数值线性代数](@entry_id:144418)领域，求解矩阵的[特征值](@entry_id:154894)和[特征向量](@entry_id:151813)是一个核心问题，它在科学与工程的无数应用中扮演着关键角色。虽然存在许多复杂的算法，但[幂迭代法](@entry_id:148021)（Power Iteration）以其概念上的极致简洁和易于实现而脱颖而出，成为计算矩阵**[主特征值](@entry_id:142677)**（模最大的[特征值](@entry_id:154894)）的基石。然而，这种简洁性背后隐藏着丰富的数学原理、微妙的[收敛条件](@entry_id:166121)以及广泛的应用价值，初学者往往只知其然，而不知其所以然。

本文旨在填补这一认知空白，提供对幂迭代法的全面而深入的剖析。我们将超越简单的算法描述，系统性地回答以下问题：该方法为何能收敛？其成功的数学保证是什么？在何种情况下会失效？以及它如何成为PageRank、主成分分析等前沿应用的核心引擎？

为实现这一目标，本文将分为三个核心部分。在“**原理与机制**”一章中，我们将从第一性原理出发，剖析算法的收敛性、数值稳定性及其与更高级方法（如克雷洛夫子空间法）的联系。接着，在“**应用与跨学科联系**”一章中，我们将展示该方法如何通过巧妙的扩展，应用于数据科学、物理建模、经济分析等多个领域，揭示其强大的实践价值。最后，“**动手实践**”部分将提供具体的编程练习，帮助读者将理论知识转化为实践技能。

现在，让我们首先深入幂迭代法的内部，探索其精妙的原理与机制。

## 原理与机制

本章旨在深入探讨[幂迭代法](@entry_id:148021)的基本原理与核心机制。我们将从其算法的构建开始，系统地阐述其收敛的数学原理，明确其成功应用的条件，并分析导致其失效的各种情况。此外，我们还将讨论实际计算中遇到的数值问题，如[数值稳定性](@entry_id:146550)、舍入误差和[收敛判据](@entry_id:158093)的选择。最后，本章会将[幂迭代法](@entry_id:148021)置于更广阔的[克雷洛夫子空间方法](@entry_id:144111)的背景中，以揭示其与其他更高级算法之间的深刻联系。

### 核心迭代过程

[幂迭代法](@entry_id:148021)的核心思想异常简洁：通过反复将矩阵 $A$ 作用于一个初始向量，来放大与**[主特征值](@entry_id:142677) (dominant eigenvalue)** 相关的分量。一个矩阵 $A \in \mathbb{C}^{n \times n}$ 的[主特征值](@entry_id:142677)是指其所有[特征值](@entry_id:154894)中模最大的那个。

让我们从一个非零的初始向量 $x_0 \in \mathbb{C}^n$ 开始。最基础的迭代形式可以表示为：
$$
y_{k+1} = A x_k
$$
然而，这个朴素的迭代过程存在一个明显的数值问题。如果[主特征值](@entry_id:142677)的模 $|\lambda_1|$ 大于1，向量 $y_k$ 的范数将趋于无穷大，导致计算溢出；反之，如果 $|\lambda_1| < 1$，其范数将趋于零，导致下溢和精度损失。为了解决这个问题，我们在每一步迭代后都对向量进行**归一化 (normalization)**。标准的幂迭代法算法如下：

1.  选择一个非零的初始向量 $x_0$。
2.  对于 $k = 0, 1, 2, \dots$ 进行迭代：
    a. 计算 $y_{k+1} = A x_k$。
    b. 归一化向量：$x_{k+1} = \frac{y_{k+1}}{\|y_{k+1}\|}$，其中 $\|\cdot\|$ 是某个[向量范数](@entry_id:140649)。

通过归一化，我们确保了迭代向量 $x_k$ 的范数保持在一个合理的范围内（例如，对于[2-范数](@entry_id:636114)，$\|x_k\|_2 = 1$），从而避免了数值[溢出](@entry_id:172355)或[下溢](@entry_id:635171)的问题，使算法在有限精度计算中变得可行。

### 收敛原理：模的主导作用

[幂迭代法](@entry_id:148021)为何能收敛到[主特征向量](@entry_id:264358)？其原理根植于向量在[特征基](@entry_id:151409)下的分解。为了清晰地阐述这一点，我们首先假设矩阵 $A \in \mathbb{C}^{n \times n}$ 是**可[对角化](@entry_id:147016)的 (diagonalizable)**，拥有 $n$ 个[线性无关](@entry_id:148207)的[特征向量](@entry_id:151813) $\{v_1, v_2, \dots, v_n\}$，对应的[特征值](@entry_id:154894)为 $\{\lambda_1, \lambda_2, \dots, \lambda_n\}$。

我们进一步假设存在一个唯一的、模严格最大的[主特征值](@entry_id:142677) $\lambda_1$，即：
$$
|\lambda_1| > |\lambda_2| \ge |\lambda_3| \ge \dots \ge |\lambda_n|
$$
由于[特征向量](@entry_id:151813) $\{v_i\}$ 构成 $\mathbb{C}^n$ 的一组基，任意初始向量 $x_0$ 都可以唯一地表示为它们的[线性组合](@entry_id:154743)：
$$
x_0 = c_1 v_1 + c_2 v_2 + \dots + c_n v_n
$$
为了保证收敛，我们要求初始向量在[主特征向量](@entry_id:264358)方向上具有非零分量，即 $c_1 \neq 0$。

现在，我们来考察 $A^k x_0$ 的表达式。根据[特征向量](@entry_id:151813)的定义 $A v_i = \lambda_i v_i$，我们有 $A^k v_i = \lambda_i^k v_i$。因此：
$$
A^k x_0 = A^k \left( \sum_{i=1}^n c_i v_i \right) = \sum_{i=1}^n c_i \lambda_i^k v_i
$$
为了分析当 $k \to \infty$ 时该向量的行为，我们可以提出公因子 $\lambda_1^k$：
$$
A^k x_0 = \lambda_1^k \left( c_1 v_1 + c_2 \left(\frac{\lambda_2}{\lambda_1}\right)^k v_2 + \dots + c_n \left(\frac{\lambda_n}{\lambda_1}\right)^k v_n \right)
$$
由于我们假设 $|\lambda_1| > |\lambda_i|$ 对于所有 $i \ge 2$，比率的模 $|\lambda_i / \lambda_1|$ 严格小于1。因此，当 $k \to \infty$ 时，所有 $(\lambda_i / \lambda_1)^k$ 项都将趋于零。这意味着括号中的求和项会消失：
$$
\lim_{k \to \infty} \sum_{i=2}^n c_i \left(\frac{\lambda_i}{\lambda_1}\right)^k v_i = 0
$$
于是，对于足够大的 $k$，向量 $A^k x_0$ 的方向将越来越接近[主特征向量](@entry_id:264358) $v_1$ 的方向：
$$
A^k x_0 \approx c_1 \lambda_1^k v_1
$$
归一化后的迭代向量 $x_k$ 与 $A^k x_0$ 方向相同，因此 $x_k$ 的方向也收敛于 $v_1$ 的方向。收敛的速率由最大的次级比率 $|\lambda_2 / \lambda_1|$ 决定。这个比率越小，收敛越快。

至关重要的是，上述推导表明，决定哪个特征分量最终胜出的是[特征值](@entry_id:154894)的**模 (modulus)**，而不是其实部 (real part) 或其他任何属性 。一个简单的例子可以很好地说明这一点：考虑[对角矩阵](@entry_id:637782) $A = \operatorname{diag}(-4, 3)$。其[特征值](@entry_id:154894)为 $\lambda_1 = -4$ 和 $\lambda_2 = 3$。按模排序，$|\lambda_1| = 4 > |\lambda_2| = 3$，因此 $-4$ 是[主特征值](@entry_id:142677)。然而，按实部排序，$\Re(\lambda_2) = 3 > \Re(\lambda_1) = -4$。对于一个通用初始向量，[幂迭代法](@entry_id:148021)将收敛到与 $-4$ 关联的[特征向量](@entry_id:151813)（方向可能每步翻转），而不是与 $3$ 关联的[特征向量](@entry_id:151813)。这清晰地证明了模的主导作用。

### 收敛的严格条件

基于上述原理，我们可以总结出标准幂迭代法收敛的三个核心条件：

1.  **存在严格的[主特征值](@entry_id:142677)**：矩阵 $A$ 必须有一个[特征值](@entry_id:154894) $\lambda_1$，其模严格大于所有其他[特征值](@entry_id:154894)的模。即 $|\lambda_1| > |\lambda_i|$ 对于所有 $\lambda_i \neq \lambda_1$。这个条件通常被称为存在**谱隙 (spectral gap)**。[谱半径](@entry_id:138984) $\rho(A)$ 定义为 $\rho(A) = \max_{\lambda \in \Lambda(A)} |\lambda|$，其中 $\Lambda(A)$ 是 $A$ 的[特征值](@entry_id:154894)集合。[主特征值](@entry_id:142677) $\lambda_1$ 就是满足 $|\lambda_1| = \rho(A)$ 且在模上是唯一的那个[特征值](@entry_id:154894) 。

2.  **[主特征值](@entry_id:142677)是单重的**：[主特征值](@entry_id:142677) $\lambda_1$ 必须是**单重的 (simple)**，即其[代数重数](@entry_id:154240)为1。[代数重数](@entry_id:154240)是指[特征值](@entry_id:154894)作为[特征多项式](@entry_id:150909)[根的重数](@entry_id:635479)。如果[主特征值](@entry_id:142677)不是单重的（例如，对应一个尺寸大于1的约当块），迭代向量的方向可能不会收敛到一个固定的[特征向量](@entry_id:151813)，尽管在某些情况下它仍可能收敛到广义[特征空间](@entry_id:638014)中的一个向量 。

3.  **初始向量的有效性**：初始向量 $x_0$ 在[主特征向量](@entry_id:264358) $v_1$ 的方向上必须有非零分量。在可[对角化](@entry_id:147016)的情况下，这意味着 $x_0$ 在[特征基](@entry_id:151409)分解中，$v_1$ 的系数 $c_1$ 必须不为零。在实际应用中，由于舍入误差的存在，随机选择的初始向量几乎总能满足此条件。

### 当收敛失效时：谱圆上的竞争

如果上述[收敛条件](@entry_id:166121)（特别是第一个条件）不满足，[幂迭代法](@entry_id:148021)的行为将变得复杂。失效的核心原因在于：存在多个具有相同最大增长率的特征分量。

**[一般性](@entry_id:161765)失效原理**
一个[特征值](@entry_id:154894) $\lambda_j$ 及其对应的（广义）[特征向量](@entry_id:151813)分量的增长率不仅取决于其模 $|\lambda_j|^k$，还受到其最大约当块尺寸 $s_j$ 的影响。其[渐近增长](@entry_id:637505)率大致为 $|\lambda_j|^k k^{s_j-1}$。[幂迭代](@entry_id:141327)的收敛性取决于是否存在一个**唯一的**“最大主导”[特征值](@entry_id:154894)，即其增长率 $|\lambda_j|^k k^{s_j-1}$ 在所有[特征值](@entry_id:154894)中是最大的。如果存在两个或更多个不同的[特征值](@entry_id:154894)共享这一最大增长率，那么[幂迭代](@entry_id:141327)将无法收敛到一个单一方向 。

**常见失效场景：多个模最大的[特征值](@entry_id:154894)**
最常见的失效情况是存在多个模长等于[谱半径](@entry_id:138984) $\rho(A)$ 的[特征值](@entry_id:154894)。假设 $A$ 是可对角化的，且 $|\lambda_1| = |\lambda_2| = \rho(A)$ 但 $\lambda_1 \neq \lambda_2$，同时所有其他[特征值](@entry_id:154894)的模都严格小于 $\rho(A)$。在这种情况下，对于足够大的 $k$：
$$
A^k x_0 \approx c_1 \lambda_1^k v_1 + c_2 \lambda_2^k v_2
$$
迭代向量的方向将由 $v_1$ 和 $v_2$ 的[线性组合](@entry_id:154743)决定，但组合系数 $c_1 \lambda_1^k$ 和 $c_2 \lambda_2^k$ 之间的比率 $(\lambda_2/\lambda_1)^k$ 不会消失。由于 $|\lambda_2/\lambda_1|=1$，这个比值是一个在复平面单位圆上“旋转”的相位因子。这导致迭代向量 $x_k$ 的方向在[子空间](@entry_id:150286) $\operatorname{span}\{v_1, v_2\}$ 内持续变化，而不会收敛 。

具体来说：
*   如果 $\lambda_1$ 和 $\lambda_2$ 是一对共轭复数（例如，对于实矩阵 $A$），$\lambda_2 = \overline{\lambda_1}$，迭代向量将在由对应实部和虚部张成的二维实[子空间](@entry_id:150286)内**旋转**。
*   如果 $\lambda_1$ 和 $\lambda_2$ 是一对相反实数，$\lambda_2 = -\lambda_1$，迭代向量将渐近地在两个不同方向之间**交替**，形成一个2-周期。

如果矩阵是**正规的 (normal)** ($A^*A=AA^*$)，那么它一定是可对角化的。因此，对于一个具有多个模最大[特征值](@entry_id:154894)的[正规矩阵](@entry_id:185943)，[幂迭代](@entry_id:141327)同样会因为上述原因而失效 。

### 保证收敛：Perron-Frobenius 定理

虽然通用矩阵的收敛性需要满足苛刻条件，但有一类重要的矩阵——非负矩阵——在特定条件下可以保证[幂迭代](@entry_id:141327)的收敛。这由 **Perron-Frobenius 定理** 描述。

一个矩阵 $A \in \mathbb{R}^{n \times n}$ 如果其所有元素 $A_{ij}$ 均非负，则称为**非负矩阵 (nonnegative matrix)**。如果对于任意索引对 $(i, j)$，都存在一条从 $i$ 到 $j$ 的路径（即存在 $k \ge 1$ 使得 $(A^k)_{ij} > 0$），则称该矩阵是**不可约的 (irreducible)**。

Perron-Frobenius 定理对不可约非负矩阵给出了强有力的结论 ：
1.  谱半径 $\rho(A)$ 是一个正的、单重的[特征值](@entry_id:154894)。
2.  存在一个所有分量都为**严格正**的[特征向量](@entry_id:151813) $v$ 与[特征值](@entry_id:154894) $\rho(A)$ 相关联。这个向量被称为**Perron向量**。

然而，仅有不可约性还不足以保证[幂迭代](@entry_id:141327)的收敛，因为它只保证了 $|\lambda| \le \rho(A)$，而没有排除其他模等于 $\rho(A)$ 的[特征值](@entry_id:154894)（例如，矩阵 $\begin{pmatrix} 0  1 \\ 1  0 \end{pmatrix}$ 的[特征值](@entry_id:154894)为 $1$ 和 $-1$）。

为了确保严格的谱隙，我们需要一个更强的条件：**[本原性](@entry_id:145479) (primitivity)**。一个不可约非负矩阵 $A$ 如果被称为是本原的，当且仅当它只有一个模等于 $\rho(A)$ 的[特征值](@entry_id:154894)，即 $\rho(A)$ 本身。一个等价的定义是：存在某个正整数 $k$ 使得 $A^k$ 的所有元素都是严格正的。

对于[本原矩阵](@entry_id:199649)，Perron-Frobenius 定理保证 $\rho(A)$ 是一个严格的[主特征值](@entry_id:142677)，即 $|\lambda| < \rho(A)$ 对于所有其他[特征值](@entry_id:154894) $\lambda$。因此，对于一个[本原矩阵](@entry_id:199649) $A$，从任意一个非负的非零初始向量 $x_0$ 开始的[幂迭代](@entry_id:141327)，都**保证**收敛到唯一的、严格正的Perron向量  。这个强大的理论是许多应用（如Google的[PageRank算法](@entry_id:138392)）的基石。

### 实际实现与数值考量

将幂迭代法从理论转化为可靠的数值代码，需要仔细考虑几个实际问题。

#### 归一化方案的选择

在每次迭代中，我们计算 $y_{k+1} = A x_k$ 并通过 $x_{k+1} = y_{k+1} / \|y_{k+1}\|$ 进行归一化。选择哪种范数会影响算法的数值表现 ：
*   **[2-范数](@entry_id:636114) ($\| \cdot \|_2$)**：$x_{k+1} = y_{k+1} / \sqrt{\sum_i |(y_{k+1})_i|^2}$。这是最符合几何直觉的范数，但其朴素计算涉及平方和，容易在中间步骤产生溢出（如果分量很大）或[下溢](@entry_id:635171)（如果分量很小）。
*   **[1-范数](@entry_id:635854) ($\| \cdot \|_1$)**：$x_{k+1} = y_{k+1} / \sum_i |(y_{k+1})_i|$。它只涉及加法，比朴素的[2-范数](@entry_id:636114)更稳健，但如果向量维数很高且分量较大，总和仍可能溢出。
*   **[无穷范数](@entry_id:637586) ($\| \cdot \|_\infty$)**：$x_{k+1} = y_{k+1} / \max_i |(y_{k+1})_i|$。这在数值上最为稳健，因为它不涉及可能导致[溢出](@entry_id:172355)的累加或乘法。它也能最大限度地保留小分量的信息，减小其下溢为零的风险。

在精确算术中，这些归一化方案产生的迭代向量方向序列是完全相同的，因此[收敛率](@entry_id:146534)也相同。在实践中，高质量的数值库（如BLAS）会使用一种**缩放算法 (scaled algorithm)** 来计算[2-范数](@entry_id:636114)，它首先提出最大分量，从而避免了中间过程的[溢出和下溢](@entry_id:141830)。因此，在良好实现的软件中，各种范数的[数值稳定性](@entry_id:146550)差异不大，选择通常基于其他考量。

此外，我们必须区分两种看似相似的归一化方式 ：
1.  $x_{k+1} = Ax_k / \|Ax_k\|$ (标准方式)
2.  $x_{k+1} = Ax_k / \|x_k\|$

标准方式确保了每一步迭代后的向量 $x_{k+1}$ 的范数都为1，这在数值上是稳定的。而第二种方式，迭代[向量的范数](@entry_id:154882)会趋向于 $|\lambda_1|$。如果 $|\lambda_1|$ 极大或极小，这种方式就会面临溢出或[下溢](@entry_id:635171)的风险。因此，标准方式是数值上更可取的选择。

#### [停止准则](@entry_id:136282)

另一个关键的实际问题是：何时停止迭代？一个可靠的**[停止准则](@entry_id:136282) (stopping criterion)** 至关重要 。常见的选择包括：

*   **迭代向量稳定**：$\|x_k - x_{k-1}\| \le \varepsilon$
*   **瑞利商稳定**：$|\mu_k - \mu_{k-1}| \le \varepsilon$，其中 $\mu_k = \frac{x_k^* A x_k}{x_k^* x_k}$ 是**瑞利商 (Rayleigh quotient)**。
*   **[残差范数](@entry_id:754273)小**：$\|A x_k - \mu_k x_k\| \le \varepsilon$。

对于**[正规矩阵](@entry_id:185943)**，这些准则通常表现相似。但对于**[非正规矩阵](@entry_id:752668) (non-normal matrix)**，情况则大不相同。[瑞利商](@entry_id:137794)可能会在迭代向量 $x_k$ 远非真实[特征向量](@entry_id:151813)时就“过早”稳定下来。例如，对于矩阵 $A_M = \begin{pmatrix} 1  M \\ 0  1/2 \end{pmatrix}$ 和初始向量 $x_0 = [0, 1]^T$，[瑞利商](@entry_id:137794) $\mu_0=1/2$ 恰好是一个精确的[特征值](@entry_id:154894)，但其[残差范数](@entry_id:754273) $\|A_M x_0 - \mu_0 x_0\|$ 等于 $M$，可以任意大。这表明仅依赖瑞利商的稳定性作为[停止准则](@entry_id:136282)是不可靠的。

最可靠的准则是**[残差范数](@entry_id:754273)**。对于一个近似特征对 $(\mu_k, x_k)$，残差 $r_k = A x_k - \mu_k x_k$ 直接衡量了它离满足[特征方程](@entry_id:265849) $Ax=\lambda x$ 的接近程度。小的[残差范数](@entry_id:754273)保证了 $(\mu_k, x_k)$ 是一个具有很小**[后向误差](@entry_id:746645) (backward error)** 的解。值得注意的是，瑞利商 $\mu_k$ 正是那个使得[残差范数](@entry_id:754273) $\|A x_k - \mu x_k\|$ 最小化的标量 $\mu$。因此，基于残差的[停止准则](@entry_id:136282)直接控制了近似解的质量，是通用的首选方案。

### 超越基础：高等现象与方法联系

幂迭代法虽然简单，但它与[数值线性代数](@entry_id:144418)中一些更深层的概念和更强大的算法紧密相连。

#### 瞬态增长与伪谱

对于[非正规矩阵](@entry_id:752668)，即使所有[特征值](@entry_id:154894)的模都小于1（即谱半径 $\rho(A) < 1$），使得 $A^k \to 0$ 在渐近意义上成立，范数 $\|A^k\|$ 也可能在 $k$ 的初始阶段经历巨大的**瞬态增长 (transient growth)**，之后才开始衰减。这种现象会延迟[幂迭代](@entry_id:141327)的收敛。

这种行为无法仅通过[特征值](@entry_id:154894)来预测，而需要借助**[伪谱](@entry_id:138878) ($\epsilon$-pseudospectrum)** 的概念 。$\epsilon$-伪谱 $\Lambda_\epsilon(A)$ 是复平面上的一个区域，其中包含了所有 $A$ 的微小扰动（范数小于 $\epsilon$）可能产生的[特征值](@entry_id:154894)。对于[非正规矩阵](@entry_id:752668)，$\Lambda_\epsilon(A)$ 可能远比其真实的谱 $\Lambda(A)$ 要大。如果伪谱延伸到了谱半径 $\rho(A)$ 之外，例如存在一个 $z \in \Lambda_\epsilon(A)$ 使得 $|z| > \rho(A)$，那么就可能存在一个初始向量，使得 $\|A^k x_0\|$ 在一段时间内表现得像 $|z|^k$ 一样增长，从而掩盖了由 $\rho(A)$ 决定的真实[渐近行为](@entry_id:160836)，延迟了向[主特征向量](@entry_id:264358)的对齐。**[Kreiss 矩阵定理](@entry_id:751059)** 将这种瞬态增长与矩阵的**[预解式](@entry_id:199555)范数 (resolvent norm)** $\lVert (z I - A)^{-1} \rVert$ 的大小联系起来，而后者正是[伪谱](@entry_id:138878)的定义基础。

#### 与[克雷洛夫子空间方法](@entry_id:144111)的关系

幂迭代法可以被看作是更强大的**[克雷洛夫子空间方法](@entry_id:144111) (Krylov subspace methods)** 的一个简化版本 。经过 $k$ 步迭代，所有未归一化的迭代向量都位于一个被称为**[克雷洛夫子空间](@entry_id:751067)** $\mathcal{K}_{k+1}(A, x_0) = \operatorname{span}\{x_0, A x_0, \dots, A^k x_0\}$ 的 $(k+1)$ 维[子空间](@entry_id:150286)中。

幂迭代法只利用了这个[子空间](@entry_id:150286)中的**最后一个向量** $A^k x_0$ 来近似[主特征向量](@entry_id:264358)。而像**[Arnoldi迭代](@entry_id:142368)**（对于[非对称矩阵](@entry_id:153254)）和**[Lanczos迭代](@entry_id:153907)**（对于[对称矩阵](@entry_id:143130)）这样的[克雷洛夫子空间方法](@entry_id:144111)，则会为整个 $\mathcal{K}_{k+1}(A, x_0)$ [子空间](@entry_id:150286)构建一个[正交基](@entry_id:264024)。然后，它们通过**瑞利-里兹过程 (Rayleigh-Ritz procedure)** 在这个[子空间](@entry_id:150286)上寻找对[特征值](@entry_id:154894)的“最佳”近似。

通过利用[子空间](@entry_id:150286)中的全部信息，而不仅仅是最后一个向量，Arnoldi和[Lanczos方法](@entry_id:138510)能够构建出关于[特征值](@entry_id:154894)的更优近似，其[收敛速度](@entry_id:636873)通常远快于[幂迭代](@entry_id:141327)。它们的[误差收敛](@entry_id:137755)行为与切比雪夫多项式在谱上的[最佳逼近问题](@entry_id:139798)相关，这解释了其卓越的收敛性能。

#### 改进与变种

虽然基础的[幂迭代法](@entry_id:148021)只适用于寻找[主特征值](@entry_id:142677)，但通过简单的修改，它可以变得更加灵活：

*   **[位移幂法](@entry_id:156093) (Shifted Power Method)**：将[幂迭代](@entry_id:141327)应用于矩阵 $A - \sigma I$，可以找到 $A$ 的最接近 $\sigma$ 的[特征值](@entry_id:154894)（取决于如何选择 $\sigma$）。
*   **[反幂法](@entry_id:148185) (Inverse Iteration)**：将[幂迭代](@entry_id:141327)应用于 $A^{-1}$，可以找到 $A$ 的**模最小**的[特征值](@entry_id:154894)。这通常与位移相结合，形成**[位移反幂法](@entry_id:143858)**，是寻找指定[特征值](@entry_id:154894)的非常高效的方法。
*   **[子空间迭代](@entry_id:168266) (Subspace Iteration)**：当存在多个模相等的最大[特征值](@entry_id:154894)时，可以使用一个由多个向量组成的块（而不是单个向量）进行迭代。这种**块方法**或[子空间迭代](@entry_id:168266)可以同时找到由这些[特征值](@entry_id:154894)张成的整个[不变子空间](@entry_id:152829) 。

通过理解这些原理和机制，我们不仅掌握了[幂迭代法](@entry_id:148021)本身，也为学习和应用更高级的[特征值算法](@entry_id:139409)奠定了坚实的基础。