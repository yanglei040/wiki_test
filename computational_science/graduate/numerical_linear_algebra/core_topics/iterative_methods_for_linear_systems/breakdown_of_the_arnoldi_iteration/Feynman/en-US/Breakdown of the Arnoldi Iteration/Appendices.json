{
    "hands_on_practices": [
        {
            "introduction": "To truly grasp the Arnoldi iteration, there is no substitute for performing the calculations by hand. This first exercise guides you through the process for a carefully chosen matrix and starting vector, allowing you to see exactly how the orthonormal basis is constructed and how the Hessenberg matrix entries emerge from the Gram-Schmidt orthogonalization. By working through the steps in exact arithmetic, you will directly observe the condition for a \"happy breakdown\" and connect it to the underlying algebraic structure of an invariant subspace .",
            "id": "3535501",
            "problem": "Consider the Arnoldi iteration with exact arithmetic over the real numbers, applied to the matrix-vector pair given by\n$$\nA \\;=\\; \\begin{pmatrix}\n2 & 1 & 0 & 0\\\\\n0 & 2 & 1 & 0\\\\\n0 & 0 & 2 & 0\\\\\n0 & 0 & 0 & 5\n\\end{pmatrix}, \n\\qquad\nv_{1} \\;=\\; \\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix}.\n$$\nWork with the standard Euclidean inner product. Starting from the fundamental definition of the Arnoldi process as repeated Gram–Schmidt orthogonalization of the sequence $A q_{j}$ against the previously constructed orthonormal vectors, construct explicitly the first $3$ Arnoldi steps, producing $q_{1}$, $q_{2}$, $q_{3}$, and the upper Hessenberg entries $h_{i,j}$ for $1 \\le i \\le j+1 \\le 4$. Denote the resulting $4 \\times 3$ Arnoldi matrix by $\\bar{H}_{3} = (h_{i,j})$. Determine whether a breakdown occurs at step $3$, and justify your conclusion from first principles in terms of the invariance of the Krylov subspace generated by $v_{1}$ under $A$. Finally, report the single scalar $h_{4,3}$ in exact form. No rounding is required, and no units are involved. Your final answer must be this single real number.",
            "solution": "The Arnoldi iteration is a procedure to construct an orthonormal basis $\\{q_{1}, q_{2}, \\dots, q_{k}\\}$ for the Krylov subspace $\\mathcal{K}_{k}(A, v_{1}) = \\text{span}\\{v_{1}, Av_{1}, \\dots, A^{k-1}v_{1}\\}$. The process begins by normalizing the initial vector $v_{1}$ to obtain $q_{1}$. Then, for each subsequent step $j=1, 2, \\dots$, the vector $Aq_{j}$ is orthogonalized against the previously constructed orthonormal vectors $\\{q_{1}, \\dots, q_{j}\\}$ using the Gram-Schmidt process.\n\nThe algorithm is defined as follows:\n$1$. Initialize $q_{1} = v_{1} / \\|v_{1}\\|_{2}$.\n$2$. For $j=1, 2, \\dots$:\n    a. Compute the candidate vector $w = Aq_{j}$.\n    b. For $i=1, \\dots, j$, compute the Hessenberg matrix entries $h_{i,j} = q_{i}^{T}w$ and update the candidate vector $w \\leftarrow w - h_{i,j}q_{i}$.\n    c. Compute the next subdiagonal entry $h_{j+1,j} = \\|w\\|_{2}$.\n    d. If $h_{j+1,j} = 0$, the algorithm has a breakdown. Terminate.\n    e. Otherwise, compute the next basis vector $q_{j+1} = w / h_{j+1,j}$.\n\nWe are given the matrix $A$ and starting vector $v_{1}$:\n$$A = \\begin{pmatrix} 2 & 1 & 0 & 0\\\\ 0 & 2 & 1 & 0\\\\ 0 & 0 & 2 & 0\\\\ 0 & 0 & 0 & 5 \\end{pmatrix}, \\qquad v_{1} = \\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix}.$$\nWe use the standard Euclidean inner product, so $q_{i}^{T}q_{j} = \\delta_{ij}$.\n\n**Step 1: Initialization**\nFirst, we normalize the starting vector $v_{1}$.\nThe norm of $v_{1}$ is $\\|v_{1}\\|_{2} = \\sqrt{1^{2} + 1^{2} + 1^{2} + 0^{2}} = \\sqrt{3}$.\nThe first Arnoldi vector is:\n$$q_{1} = \\frac{v_{1}}{\\|v_{1}\\|_{2}} = \\frac{1}{\\sqrt{3}} \\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix}.$$\n\n**Arnoldi Iteration, Step $j=1$**\nWe compute $w = Aq_{1}$:\n$$w = A q_{1} = \\begin{pmatrix} 2 & 1 & 0 & 0\\\\ 0 & 2 & 1 & 0\\\\ 0 & 0 & 2 & 0\\\\ 0 & 0 & 0 & 5 \\end{pmatrix} \\frac{1}{\\sqrt{3}} \\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix} = \\frac{1}{\\sqrt{3}} \\begin{pmatrix} 2(1)+1(1) \\\\ 2(1)+1(1) \\\\ 2(1) \\\\ 0 \\end{pmatrix} = \\frac{1}{\\sqrt{3}} \\begin{pmatrix} 3\\\\ 3\\\\ 2\\\\ 0 \\end{pmatrix}.$$\nNext, we orthogonalize $w$ against $q_{1}$:\n$$h_{1,1} = q_{1}^{T}w = \\left(\\frac{1}{\\sqrt{3}}\\begin{pmatrix} 1 & 1 & 1 & 0 \\end{pmatrix}\\right) \\left(\\frac{1}{\\sqrt{3}}\\begin{pmatrix} 3\\\\ 3\\\\ 2\\\\ 0 \\end{pmatrix}\\right) = \\frac{1}{3}(3+3+2) = \\frac{8}{3}.$$\nThe residual vector is $w_{res} = w - h_{1,1}q_{1}$:\n$$w_{res} = \\frac{1}{\\sqrt{3}}\\begin{pmatrix} 3\\\\ 3\\\\ 2\\\\ 0 \\end{pmatrix} - \\frac{8}{3} \\frac{1}{\\sqrt{3}}\\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix} = \\frac{1}{3\\sqrt{3}}\\left(\\begin{pmatrix} 9\\\\ 9\\\\ 6\\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 8\\\\ 8\\\\ 8\\\\ 0 \\end{pmatrix}\\right) = \\frac{1}{3\\sqrt{3}}\\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix}.$$\nThe subdiagonal element is $h_{2,1} = \\|w_{res}\\|_{2}$:\n$$h_{2,1} = \\left\\|\\frac{1}{3\\sqrt{3}}\\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix}\\right\\|_{2} = \\frac{1}{3\\sqrt{3}}\\sqrt{1^2+1^2+(-2)^2} = \\frac{\\sqrt{6}}{3\\sqrt{3}} = \\frac{\\sqrt{2}\\sqrt{3}}{3\\sqrt{3}} = \\frac{\\sqrt{2}}{3}.$$\nSince $h_{2,1} \\neq 0$, we normalize to find $q_{2}$:\n$$q_{2} = \\frac{w_{res}}{h_{2,1}} = \\frac{\\frac{1}{3\\sqrt{3}}\\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix}}{\\frac{\\sqrt{2}}{3}} = \\frac{1}{\\sqrt{2}\\sqrt{3}}\\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix} = \\frac{1}{\\sqrt{6}}\\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix}.$$\n\n**Arnoldi Iteration, Step $j=2$**\nWe compute $w = Aq_{2}$:\n$$w = A q_{2} = \\begin{pmatrix} 2 & 1 & 0 & 0\\\\ 0 & 2 & 1 & 0\\\\ 0 & 0 & 2 & 0\\\\ 0 & 0 & 0 & 5 \\end{pmatrix} \\frac{1}{\\sqrt{6}} \\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix} = \\frac{1}{\\sqrt{6}} \\begin{pmatrix} 2(1)+1(1) \\\\ 2(1)+1(-2) \\\\ 2(-2) \\\\ 0 \\end{pmatrix} = \\frac{1}{\\sqrt{6}} \\begin{pmatrix} 3\\\\ 0\\\\ -4\\\\ 0 \\end{pmatrix}.$$\nWe orthogonalize $w$ against $q_{1}$ and $q_{2}$:\n$$h_{1,2} = q_{1}^{T}w = \\left(\\frac{1}{\\sqrt{3}}\\begin{pmatrix} 1 & 1 & 1 & 0 \\end{pmatrix}\\right) \\left(\\frac{1}{\\sqrt{6}}\\begin{pmatrix} 3\\\\ 0\\\\ -4\\\\ 0 \\end{pmatrix}\\right) = \\frac{1}{\\sqrt{18}}(3-4) = \\frac{-1}{3\\sqrt{2}} = -\\frac{\\sqrt{2}}{6}.$$\n$$h_{2,2} = q_{2}^{T}w = \\left(\\frac{1}{\\sqrt{6}}\\begin{pmatrix} 1 & 1 & -2 & 0 \\end{pmatrix}\\right) \\left(\\frac{1}{\\sqrt{6}}\\begin{pmatrix} 3\\\\ 0\\\\ -4\\\\ 0 \\end{pmatrix}\\right) = \\frac{1}{6}(3+8) = \\frac{11}{6}.$$\nThe residual vector is $w_{res} = w - h_{1,2}q_{1} - h_{2,2}q_{2}$:\n$$w_{res} = \\frac{1}{\\sqrt{6}}\\begin{pmatrix} 3\\\\ 0\\\\ -4\\\\ 0 \\end{pmatrix} - \\left(-\\frac{1}{3\\sqrt{2}}\\right)\\frac{1}{\\sqrt{3}}\\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix} - \\frac{11}{6}\\frac{1}{\\sqrt{6}}\\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix} = \\frac{1}{6\\sqrt{6}}\\left[6\\begin{pmatrix} 3\\\\ 0\\\\ -4\\\\ 0 \\end{pmatrix} + \\frac{6}{3}\\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix} - 11\\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix}\\right]$$\n$$w_{res} = \\frac{1}{6\\sqrt{6}}\\left[\\begin{pmatrix} 18\\\\ 0\\\\ -24\\\\ 0 \\end{pmatrix} + \\begin{pmatrix} 2\\\\ 2\\\\ 2\\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 11\\\\ 11\\\\ -22\\\\ 0 \\end{pmatrix}\\right] = \\frac{1}{6\\sqrt{6}}\\begin{pmatrix} 9\\\\ -9\\\\ 0\\\\ 0 \\end{pmatrix} = \\frac{9}{6\\sqrt{6}}\\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix} = \\frac{3}{2\\sqrt{6}}\\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix}.$$\nThe subdiagonal element is $h_{3,2} = \\|w_{res}\\|_{2}$:\n$$h_{3,2} = \\left\\|\\frac{3}{2\\sqrt{6}}\\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix}\\right\\|_{2} = \\frac{3}{2\\sqrt{6}}\\sqrt{1^2+(-1)^2} = \\frac{3\\sqrt{2}}{2\\sqrt{6}} = \\frac{3}{2\\sqrt{3}} = \\frac{\\sqrt{3}}{2}.$$\nSince $h_{3,2} \\neq 0$, we normalize to find $q_{3}$:\n$$q_{3} = \\frac{w_{res}}{h_{3,2}} = \\frac{\\frac{3}{2\\sqrt{6}}\\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix}}{\\frac{\\sqrt{3}}{2}} = \\frac{3}{2\\sqrt{6}}\\frac{2}{\\sqrt{3}}\\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix} = \\frac{3}{\\sqrt{18}}\\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix}.$$\n\n**Arnoldi Iteration, Step $j=3$**\nWe compute $w = Aq_{3}$:\n$$w = A q_{3} = \\begin{pmatrix} 2 & 1 & 0 & 0\\\\ 0 & 2 & 1 & 0\\\\ 0 & 0 & 2 & 0\\\\ 0 & 0 & 0 & 5 \\end{pmatrix} \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 2(1)+1(-1) \\\\ 2(-1) \\\\ 0 \\\\ 0 \\end{pmatrix} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1\\\\ -2\\\\ 0\\\\ 0 \\end{pmatrix}.$$\nWe orthogonalize $w$ against $q_{1}, q_{2}, q_{3}$:\n$$h_{1,3} = q_{1}^{T}w = \\left(\\frac{1}{\\sqrt{3}}\\begin{pmatrix} 1 & 1 & 1 & 0 \\end{pmatrix}\\right) \\left(\\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1\\\\ -2\\\\ 0\\\\ 0 \\end{pmatrix}\\right) = \\frac{1}{\\sqrt{6}}(1-2) = -\\frac{1}{\\sqrt{6}} = -\\frac{\\sqrt{6}}{6}.$$\n$$h_{2,3} = q_{2}^{T}w = \\left(\\frac{1}{\\sqrt{6}}\\begin{pmatrix} 1 & 1 & -2 & 0 \\end{pmatrix}\\right) \\left(\\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1\\\\ -2\\\\ 0\\\\ 0 \\end{pmatrix}\\right) = \\frac{1}{\\sqrt{12}}(1-2) = -\\frac{1}{2\\sqrt{3}} = -\\frac{\\sqrt{3}}{6}.$$\n$$h_{3,3} = q_{3}^{T}w = \\left(\\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 & -1 & 0 & 0 \\end{pmatrix}\\right) \\left(\\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1\\\\ -2\\\\ 0\\\\ 0 \\end{pmatrix}\\right) = \\frac{1}{2}(1+2) = \\frac{3}{2}.$$\nThe residual vector is $w_{res} = w - h_{1,3}q_{1} - h_{2,3}q_{2} - h_{3,3}q_{3}$:\n$$w_{res} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1\\\\ -2\\\\ 0\\\\ 0 \\end{pmatrix} - \\left(-\\frac{1}{\\sqrt{6}}\\right)\\frac{1}{\\sqrt{3}}\\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix} - \\left(-\\frac{1}{2\\sqrt{3}}\\right)\\frac{1}{\\sqrt{6}}\\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix} - \\frac{3}{2}\\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix}$$\n$$w_{res} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1\\\\ -2\\\\ 0\\\\ 0 \\end{pmatrix} + \\frac{1}{3\\sqrt{2}}\\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix} + \\frac{1}{6\\sqrt{2}}\\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix} - \\frac{3}{2\\sqrt{2}}\\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix}$$\n$$w_{res} = \\frac{1}{6\\sqrt{2}} \\left[ 6\\begin{pmatrix} 1\\\\ -2\\\\ 0\\\\ 0 \\end{pmatrix} + 2\\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix} + 1\\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix} - 9\\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix} \\right]$$\n$$w_{res} = \\frac{1}{6\\sqrt{2}} \\begin{pmatrix} 6+2+1-9 \\\\ -12+2+1+9 \\\\ 2-2 \\\\ 0 \\end{pmatrix} = \\frac{1}{6\\sqrt{2}} \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}.$$\nThe subdiagonal element is $h_{4,3} = \\|w_{res}\\|_{2}$:\n$$h_{4,3} = \\left\\|\\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\\right\\|_{2} = 0.$$\nSince $h_{4,3} = 0$, a breakdown occurs at step $j=3$. The matrix $\\bar{H}_{3}$ is:\n$$ \\bar{H}_{3} = \\begin{pmatrix} h_{1,1} & h_{1,2} & h_{1,3} \\\\ h_{2,1} & h_{2,2} & h_{2,3} \\\\ 0 & h_{3,2} & h_{3,3} \\\\ 0 & 0 & h_{4,3} \\end{pmatrix} = \\begin{pmatrix} 8/3 & -\\sqrt{2}/6 & -\\sqrt{6}/6 \\\\ \\sqrt{2}/3 & 11/6 & -\\sqrt{3}/6 \\\\ 0 & \\sqrt{3}/2 & 3/2 \\\\ 0 & 0 & 0 \\end{pmatrix}. $$\n\n**Justification for Breakdown**\nThe breakdown of the Arnoldi iteration at step $j$ (i.e., $h_{j+1,j}=0$) is equivalent to the Krylov subspace $\\mathcal{K}_{j}(A, v_{1})$ being an invariant subspace of $A$. That is, $A\\mathcal{K}_{j}(A, v_{1}) \\subseteq \\mathcal{K}_{j}(A, v_{1})$. Here, the breakdown occurs at $j=3$. We must show that $\\mathcal{K}_{3}(A, v_{1})$ is an invariant subspace.\n\nThe matrix $A$ is block upper triangular:\n$$A = \\begin{pmatrix} A_{11} & 0 \\\\ 0 & A_{22} \\end{pmatrix} \\text{ where } A_{11} = \\begin{pmatrix} 2 & 1 & 0 \\\\ 0 & 2 & 1 \\\\ 0 & 0 & 2 \\end{pmatrix} \\text{ and } A_{22} = (5).$$\nThe subspace $S = \\text{span}\\{e_{1}, e_{2}, e_{3}\\}$, where $e_i$ are the standard basis vectors, is an invariant subspace under $A$. Any vector $v = (x, y, z, 0)^{T}$ in $S$ maps to $Av = (2x+y, 2y+z, 2z, 0)^{T}$, which is also in $S$.\nThe starting vector $v_{1} = (1, 1, 1, 0)^{T}$ lies in this $3$-dimensional invariant subspace $S$. Consequently, the entire Krylov sequence $\\{v_{1}, Av_{1}, A^{2}v_{1}, \\dots\\}$ must remain within $S$.\nThe Arnoldi iteration constructs an orthonormal basis for the successively larger Krylov subspaces $\\mathcal{K}_{k}(A, v_{1})$. Since the entire sequence is confined to the $3$-dimensional subspace $S$, the dimension of the Krylov subspace cannot exceed $3$. The vectors $\\{v_{1}, Av_{1}, A^{2}v_{1}\\}$ are linearly independent, so $\\dim(\\mathcal{K}_{3}(A, v_{1})) = 3$. This means $\\mathcal{K}_{3}(A, v_{1}) = S$.\n\nBecause $\\mathcal{K}_{3}(A, v_{1}) = S$ is an invariant subspace, for any vector $u \\in \\mathcal{K}_{3}(A, v_{1})$, the vector $Au$ must also be in $\\mathcal{K}_{3}(A, v_{1})$. The Arnoldi vector $q_{3}$ is in $\\mathcal{K}_{3}(A, v_{1})$, so $Aq_{3}$ must be in $\\mathcal{K}_{3}(A, v_{1}) = \\text{span}\\{q_{1}, q_{2}, q_{3}\\}$. This means $Aq_{3}$ can be written as a linear combination of $q_{1}, q_{2}, q_{3}$.\nThe Arnoldi algorithm computes the residual $w_{res} = Aq_{3} - h_{1,3}q_{1} - h_{2,3}q_{2} - h_{3,3}q_{3}$. Since $\\{q_{1}, q_{2}, q_{3}\\}$ form an orthonormal basis for the space containing $Aq_{3}$, this residual is the result of projecting $Aq_{3}$ onto the orthogonal complement of $\\mathcal{K}_3(A, v_1)$, which must be the zero vector. Thus, $w_{res}=\\mathbf{0}$, which leads to $h_{4,3} = \\|w_{res}\\|_{2} = 0$. This confirms the breakdown from first principles.\n\nThe single scalar requested is $h_{4,3}$. From our calculation, $h_{4,3}=0$.",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "Moving from the idealized world of exact arithmetic to practical implementation requires us to confront the realities of floating-point computation. This coding exercise tasks you with translating the Arnoldi algorithm into a runnable program and implementing a first-pass breakdown detector using a simple tolerance. By testing your code against a variety of scenarios—including cases with exact breakdown, near-breakdown, and no breakdown—you will develop a core understanding of how the theoretical concept of breakdown manifests in a numerical setting .",
            "id": "3535509",
            "problem": "Let $A \\in \\mathbb{R}^{n \\times n}$ be a nonsingular matrix and let $v_1 \\in \\mathbb{R}^n$ be a nonzero starting vector. Consider the Krylov subspace $\\mathcal{K}_m(A, v_1) = \\operatorname{span}\\{v_1, A v_1, A^2 v_1, \\dots, A^{m-1} v_1\\}$, the Euclidean inner product $\\langle x, y \\rangle = x^\\top y$, and the Euclidean norm $\\|x\\|_2 = \\sqrt{x^\\top x}$. The Arnoldi iteration constructs an orthonormal sequence $\\{v_1, v_2, \\dots, v_{m+1}\\}$ and an upper Hessenberg matrix $H_m = (h_{i,j}) \\in \\mathbb{R}^{(m+1)\\times m}$ by orthogonalizing $A v_j$ against the previously constructed vectors:\n1. Initialize $v_1 \\leftarrow v_1 / \\|v_1\\|_2$.\n2. For each integer $j$ with $1 \\le j \\le m$:\n   - Compute $w \\leftarrow A v_j$.\n   - For $i = 1, \\dots, j$, set $h_{i,j} \\leftarrow \\langle v_i, w \\rangle$ and update $w \\leftarrow w - h_{i,j} v_i$.\n   - Set $h_{j+1,j} \\leftarrow \\|w\\|_2$. If $h_{j+1,j} = 0$, then exact breakdown occurs at index $j$.\nWhen computing numerically, near breakdown is to be detected when $h_{j+1,j} \\le \\tau$ for a specified absolute tolerance $\\tau > 0$. In this case, the Arnoldi iteration is terminated and the earliest index $j$ at or below $m$ where $h_{j+1,j} \\le \\tau$ is reported.\n\nYour task is to write a complete, runnable program that:\n- Implements the Arnoldi iteration using the Modified Gram-Schmidt (MGS) orthogonalization to compute $h_{j+1,j}$ values numerically.\n- Detects breakdown at the earliest index $j$ where $h_{j+1,j} \\le \\tau$, for a given $A$, $v_1$, step limit $m$, and tolerance $\\tau$.\n- Returns, for each test case, a list consisting of the earliest breakdown index $j$ (using one-based indexing, and returning $-1$ if no breakdown occurs for all steps $j = 1, \\dots, \\min\\{m, n\\}$), and the list of all computed values $[h_{2,1}, h_{3,2}, \\dots, h_{m+1,m}]$ up to the step where the iteration terminates.\n\nUse the following test suite, which explores distinct behaviors:\n- Test Case 1 (general happy path, no breakdown within $m$): $A = \\operatorname{diag}(1, 2, 3, 4)$, $v_1 = [1, 0.5, -0.3, 0.7]^\\top$, $m = 3$, $\\tau = 10^{-14}$. The matrix is nonsingular, and the step limit is below the ambient dimension.\n- Test Case 2 (exact breakdown at $j = 1$): $A = \\operatorname{diag}(2, 3, 4, 5)$, $v_1 = [1, 0, 0, 0]^\\top$, $m = 4$, $\\tau = 10^{-14}$. Here $v_1$ is an eigenvector, so $h_{2,1} = 0$ exactly.\n- Test Case 3 (exact breakdown at $j = 2$ due to low-dimensional invariant subspace): $A = \\operatorname{diag}(2, 3, 5)$, $v_1 = [1, 1, 0]^\\top$, $m = 3$, $\\tau = 10^{-14}$. The starting vector has support in only two eigenvectors, so the Krylov subspace dimension saturates at $2$.\n- Test Case 4 (boundary dimension case): $A = [3]$, $v_1 = [1]^\\top$, $m = 1$, $\\tau = 10^{-12}$. The space is one-dimensional; breakdown is expected at the first step.\n- Test Case 5 (near breakdown detected by tolerance): $A = \\operatorname{diag}(2, 2.0000001, 5)$, $v_1 = [1, 10^{-9}, 0]^\\top$, $m = 3$, $\\tau = 10^{-12}$. The starting vector is nearly an eigenvector, making $h_{2,1}$ extremely small.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets. Each test case result must be a list of the form $[j, [h_{2,1}, h_{3,2}, \\dots]]$. For example, the output must have the form\n$[[j_1, [\\dots]], [j_2, [\\dots]], \\dots]$,\nwith numerical values represented as standard Python floats and integers.",
            "solution": "The problem of implementing the Arnoldi iteration to detect breakdown is valid. It is scientifically grounded in the established principles of numerical linear algebra, well-posed with a clear and deterministic algorithm, and stated objectively using precise mathematical terminology. The provided test cases explore a range of standard and edge-case behaviors of the algorithm, making the problem a well-defined and non-trivial implementation task.\n\nThe solution will be a Python program that implements the Arnoldi iteration for a given matrix $A$, starting vector $v_1$, maximum number of steps $m$, and breakdown tolerance $\\tau$. The core of the algorithm is the construction of an orthonormal basis for the Krylov subspace $\\mathcal{K}_j(A, v_1)$ for increasing $j$. The process is iterative, and at each step $j$, it generates a new basis vector $v_{j+1}$ that is orthogonal to all previous vectors $\\{v_1, \\dots, v_j\\}$.\n\nThe algorithm proceeds as follows:\n\n1.  **Initialization**: The input starting vector $v_1$ is normalized to have a Euclidean norm of $1$. This normalized vector, which we also call $v_1$, becomes the first vector in our orthonormal basis $V$. The maximum number of iterations is determined by $k_{max} = \\min(m, n)$, since the dimension of the Krylov subspace cannot exceed the dimension of the ambient space $n$.\n\n2.  **Iteration**: For each step $j$ from $1$ to $k_{max}$:\n    a. A new candidate vector $w$ is generated by applying the matrix $A$ to the most recently computed basis vector, $w \\leftarrow A v_j$.\n    b. This vector $w$ is then orthogonalized against all existing basis vectors $\\{v_1, \\dots, v_j\\}$ using the Modified Gram-Schmidt (MGS) procedure. MGS is chosen for its superior numerical stability compared to Classical Gram-Schmidt. In the MGS process, for each $i$ from $1$ to $j$, we compute the projection of the current $w$ onto $v_i$ and immediately subtract it:\n    $$h_{i,j} \\leftarrow \\langle v_i, w \\rangle$$\n    $$w \\leftarrow w - h_{i,j} v_i$$\n    The coefficients $h_{i,j}$ become the entries of an upper Hessenberg matrix $H_m$.\n\n3.  **Breakdown Detection**: After orthogonalizing $w$ against all $v_i$ for $i=1, \\dots, j$, the Euclidean norm of the resulting vector $w$ is computed. This norm is the subdiagonal entry $h_{j+1,j}$ of the Hessenberg matrix.\n    $$h_{j+1,j} \\leftarrow \\|w\\|_2$$\n    A breakdown occurs if this value is zero (exact breakdown) or very small (near breakdown). The condition for termination is $h_{j+1,j} \\le \\tau$. If this condition is met, the iteration stops, and the current step index $j$ is recorded as the breakdown index.\n\n4.  **Continuation**: If $h_{j+1,j} > \\tau$, no breakdown has occurred. The next orthonormal basis vector is obtained by normalizing the residual vector $w$:\n    $$v_{j+1} \\leftarrow w / h_{j+1,j}$$\n    This new vector $v_{j+1}$ is added to the basis, and the iteration proceeds to the next step, $j+1$.\n\n5.  **Termination and Output**: The iteration terminates either when a breakdown is detected at some step $j \\le k_{max}$, or after completing all $k_{max}$ steps without the breakdown condition being met. The program returns a list containing two elements: the 1-based breakdown index $j$ (or $-1$ if no breakdown occurred) and the list of all computed subdiagonal Hessenberg entries $[h_{2,1}, h_{3,2}, \\dots]$ up to the point of termination.\n\nThis procedure will be applied to each test case provided in the problem statement, and the results will be aggregated into a single formatted output string.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for Arnoldi iteration breakdown.\n    This function defines the test cases, invokes the Arnoldi iteration\n    implementation for each case, and prints the results in the required format.\n    \"\"\"\n\n    def perform_arnoldi_breakdown(A_raw, v1_raw, m, tau):\n        \"\"\"\n        Implements the Arnoldi iteration with Modified Gram-Schmidt to detect breakdown.\n\n        Args:\n            A_raw: The matrix A, as a list of lists or numpy array.\n            v1_raw: The starting vector v1, as a list or numpy array.\n            m: The integer step limit.\n            tau: The float absolute tolerance for near breakdown.\n\n        Returns:\n            A list containing the 1-based breakdown index (or -1 if no breakdown)\n            and the list of computed subdiagonal Hessenberg entries h_{j+1,j}.\n        \"\"\"\n        # Ensure data types are consistent and arrays have correct shape for linear algebra.\n        A = np.asarray(A_raw, dtype=np.float64)\n        n = A.shape[0]\n        v1 = np.asarray(v1_raw, dtype=np.float64).reshape(-1, 1)\n\n        # 1. Initialize v1 <- v1 / ||v1||_2.\n        #    The problem statement guarantees a nonzero starting vector.\n        norm_v1 = np.linalg.norm(v1)\n        v = v1 / norm_v1\n        \n        # V will store the generated orthonormal basis vectors {v_1, v_2, ...}.\n        V = [v]\n        h_subdiagonal = []\n        breakdown_index = -1\n        \n        # The number of steps is limited by m and the matrix dimension n.\n        max_steps = min(m, n)\n        \n        if max_steps == 0:\n            return [-1, []]\n        \n        # 2. Loop for each step j from 1 to max_steps.\n        #    j_prob is the 1-based index from the problem statement.\n        for j_prob in range(1, max_steps + 1):\n            j_code = j_prob - 1 # Corresponding 0-based index for list access.\n            \n            # Compute w <- A * v_j\n            w = A @ V[j_code]\n\n            # Modified Gram-Schmidt (MGS) orthogonalization.\n            # Orthogonalize w against all previously computed basis vectors v_1, ..., v_j.\n            for i_code in range(j_code + 1):\n                v_i = V[i_code]\n                # h_ij <- <v_i, w>\n                h_ij = (v_i.T @ w).item()\n                # w <- w - h_ij * v_i\n                w = w - h_ij * v_i\n            \n            # Subdiagonal element h_{j+1, j} is the norm of the resulting vector.\n            h_jplus1_j = np.linalg.norm(w)\n            h_subdiagonal.append(h_jplus1_j)\n            \n            # 3. Breakdown Detection.\n            if h_jplus1_j <= tau:\n                breakdown_index = j_prob # Report 1-based breakdown index.\n                break # Terminate the iteration.\n            \n            # 4. Continuation: Normalize the new vector and add it to the basis.\n            v_next = w / h_jplus1_j\n            V.append(v_next)\n            \n        return [breakdown_index, h_subdiagonal]\n\n    # Define the test suite from the problem statement.\n    test_cases = [\n        # (A, v1, m, tau)\n        (np.diag([1.0, 2.0, 3.0, 4.0]), [1.0, 0.5, -0.3, 0.7], 3, 1e-14),\n        (np.diag([2.0, 3.0, 4.0, 5.0]), [1.0, 0.0, 0.0, 0.0], 4, 1e-14),\n        (np.diag([2.0, 3.0, 5.0]), [1.0, 1.0, 0.0], 3, 1e-14),\n        (np.array([[3.0]]), [1.0], 1, 1e-12),\n        (np.diag([2.0, 2.0000001, 5.0]), [1.0, 1e-9, 0.0], 3, 1e-12)\n    ]\n\n    results = []\n    for case in test_cases:\n        result = perform_arnoldi_breakdown(*case)\n        results.append(result)\n\n    # Format the final output string according to the problem specification.\n    # The string representation of each result list is taken, with spaces removed\n    # for a compact format, and then joined by commas, enclosed in brackets.\n    formatted_results = [str(r).replace(\" \", \"\") for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A simple, fixed tolerance for breakdown detection can be unreliable; a threshold that works for one problem may fail for another with a different scale or properties. This advanced practice challenges you to develop a more robust, adaptive breakdown detector based on a first-principles model of floating-point error propagation. By implementing and comparing a naive fixed threshold against an adaptive one, you will explore the nuances of creating high-quality numerical software and learn how to distinguish a true breakdown from mere computational noise .",
            "id": "3535484",
            "problem": "You are tasked with designing and evaluating a robust breakdown detector for the Arnoldi iteration in the context of Numerical Linear Algebra. Recall that the Arnoldi process for a real matrix constructs an orthonormal basis of the Krylov subspace using a recurrence that, in exact arithmetic, yields a factorization of the form $$A V_k = V_{k+1} \\bar{H}_k,$$ where $A \\in \\mathbb{R}^{n \\times n}$, $V_k \\in \\mathbb{R}^{n \\times k}$ has orthonormal columns, and $\\bar{H}_k \\in \\mathbb{R}^{(k+1) \\times k}$ is upper Hessenberg. The quantity $h_{k+1,k}$ (the subdiagonal element in column $k$ of $\\bar{H}_k$) is equal to the Euclidean norm of the residual vector $w = A v_k - \\sum_{j=1}^{k} h_{j,k} v_j$ after orthogonalization, where $v_k$ is the $k$-th Arnoldi vector. In exact arithmetic, breakdown (also called happy breakdown) occurs if and only if $h_{k+1,k} = 0$.\n\nIn floating-point arithmetic following the Standard for Floating-Point Arithmetic (IEEE 754), computed quantities are perturbed by rounding errors. You will compare a naive fixed absolute threshold against an adaptive threshold informed by a first-principles backward error model of floating-point operations to decide when a computed $h_{k+1,k}$ is sufficiently small to declare breakdown.\n\nYour task is to implement a program that:\n\n- Constructs test matrices $A$ and initial vectors $v_1$ for a set of specified test cases.\n- Runs the Arnoldi iteration up to a specified maximum iteration $m$.\n- Implements two breakdown detectors:\n  1. A naive fixed absolute threshold detector that declares breakdown at step $k$ if the computed $h_{k+1,k} \\le \\tau_{\\mathrm{fix}}$ for a specified fixed threshold $\\tau_{\\mathrm{fix}}$.\n  2. An adaptive detector that declares breakdown at step $k$ using an iteration-dependent threshold $\\theta_k$ derived from the standard floating-point error model and backward error reasoning. The adaptive threshold must be an explicit function of the unit roundoff $u$, a matrix norm of $A$, the norm of $A v_k$, and the norm of the already computed coefficients in the $k$-th Arnoldi column $h_{1:k,k}$. Use a positive scaling constant $c$ to aggregate these contributions. The adaptive threshold must be absolute (not relative) and must not depend on any unknown or problem-specific parameters beyond those listed. The constant $c$ must be taken as a small positive integer.\n\n- Evaluates the detection decision against ground truth for each test case, returning a boolean indicating whether the detector made the correct decision (true) or not (false) for that case. A correct decision means:\n  - If the true Arnoldi process in exact arithmetic exhibits breakdown at some step $k^\\star \\le m$, the detector must declare breakdown at exactly $k^\\star$ (first time) and not earlier or later.\n  - If no exact breakdown occurs for $k \\le m$, the detector must not declare breakdown for any $k \\le m$.\n\nFundamental base to use in your derivation and implementation:\n\n- The standard floating-point model: for basic operations and inner products, the computed result $\\mathrm{fl}(\\cdot)$ satisfies $\\mathrm{fl}(x \\,\\circ\\, y) = (x \\,\\circ\\, y) (1 + \\delta)$ with $|\\delta| \\le u$, where $u$ is the unit roundoff (half the machine epsilon), and summation and inner products incur error amplification that is bounded in terms of the number of floating-point operations and $u$.\n- Basic inequalities for induced matrix norms and Euclidean vector norms.\n- The defining relations of the Arnoldi iteration and breakdown.\n\nTest suite specification (use exactly these matrices and parameters):\n\nFor each test case, construct $A \\in \\mathbb{R}^{n \\times n}$ and an initial vector $v_1 \\in \\mathbb{R}^n$ with $\\|v_1\\|_2 = 1$, as follows.\n\n- For cases with an exact breakdown at a known step, use a block diagonal matrix\n  $$A = \\mathrm{diag}(S_\\varepsilon, I_{n-r}),$$\n  where $S_\\varepsilon \\in \\mathbb{R}^{r \\times r}$ is obtained by taking the strictly upper shift $S$ with ones on the first superdiagonal and zeros elsewhere, and adding a perturbation $\\varepsilon G$ with $G$ a dense matrix with independent standard normal entries. The identity matrix is $I_{n-r}$. Take the initial vector $v_1 = e_1$ (the first standard basis vector). For $\\varepsilon = 0$, the exact Arnoldi process must break down at step $k^\\star = r$ because $S$ is nilpotent of index $r$ and the Krylov subspace has dimension $r$ starting from $e_1$. For $\\varepsilon \\ne 0$, there is no exact breakdown at $k \\le r$.\n- For the case without any special structure, construct an orthogonal matrix $A$ from the $Q R$ decomposition of a dense random matrix with independent standard normal entries; take $A=Q$ with a fixed pseudorandom seed. Use an initial vector with independent standard normal entries, normalized to unit Euclidean norm.\n\nUse the following specific test cases with their parameters:\n\n1. Case A (happy path exact breakdown): $n = 40$, $r = 10$, $\\varepsilon = 0$, $m = 20$. Seed for any randomness: $123$.\n2. Case B (near-breakdown, no exact breakdown): $n = 40$, $r = 10$, $\\varepsilon = 10^{-14}$, $m = 20$. Seed for perturbation $G$: $123$.\n3. Case C (larger size exact breakdown): $n = 200$, $r = 5$, $\\varepsilon = 0$, $m = 15$. Seed: $7$.\n4. Case D (no breakdown): $n = 60$, $m = 25$. Construct $A$ as $Q$ from the $Q R$ decomposition of a dense random matrix with seed $7$, and $v_1$ as a random vector with seed $7$, normalized to unit Euclidean norm.\n5. Case E (immediate breakdown): $n = 30$, $r = 1$, $\\varepsilon = 0$, $m = 5$. Seed: $2024$.\n\nDetector parameters:\n\n- Use a naive fixed threshold $\\tau_{\\mathrm{fix}} = 10^{-12}$.\n- For the adaptive threshold, derive and implement a concrete absolute threshold $\\theta_k$ that depends on the unit roundoff $u$, a matrix norm of $A$, $\\|A v_k\\|_2$, and $\\|h_{1:k,k}\\|_2$, with a small positive integer scaling factor. Use the spectral norm for the matrix norm. Use the Standard for Floating-Point Arithmetic (IEEE 754) double precision unit roundoff.\n\nProgram requirements:\n\n- Implement the Arnoldi iteration without restarts up to $m$ steps for each test case, forming the necessary inner products and orthogonalizations to compute $h_{k+1,k}$ at each step.\n- For each test case, run both detectors and record a boolean indicating whether each detector made the correct decision relative to the ground truth as defined above.\n- Your program should produce a single line of output containing the results as a comma-separated nested list of two lists in Python list syntax: the first list contains the booleans for the naive detector across the five test cases in order, and the second list contains the booleans for the adaptive detector across the same five test cases. For example, an output of the form \"[[true,false,true,false,true],[true,true,true,true,true]]\" would indicate the naive detector was correct on cases $1$, $3$, and $5$, and the adaptive detector was correct on all cases. Use Python boolean literals.\n\nAll quantities are dimensionless; no physical units are involved. Angles are not used. All randomness must be reproducible by setting the specified seeds. The code must be self-contained, must not read input, and must not access the network or any external files.",
            "solution": "The problem requires the design and evaluation of two breakdown detectors for the Arnoldi iteration. A breakdown, specifically a \"happy breakdown,\" occurs in exact arithmetic when the process generates a vector that is already in the span of the previously generated basis vectors for the Krylov subspace. This manifests as the subdiagonal element $h_{k+1,k}$ of the upper Hessenberg matrix $\\bar{H}_k$ becoming zero. In floating-point arithmetic, this exact zero is replaced by a small non-zero value arising from computational rounding errors. The task is to distinguish this computational noise from a genuinely small but non-zero $h_{k+1,k}$ that signifies a near-breakdown but not an exact one.\n\nWe will first implement the Arnoldi iteration using the Modified Gram-Schmidt (MGS) algorithm for orthogonalization. For a given matrix $A \\in \\mathbb{R}^{n \\times n}$ and a starting vector $v_1$ of unit norm, the process iteratively constructs an orthonormal basis $\\{v_1, v_2, \\dots, v_m\\}$ for the Krylov subspace $\\mathcal{K}_m(A, v_1)$ and a matrix $\\bar{H}_m \\in \\mathbb{R}^{(m+1) \\times m}$. At each step $k$ (for $k=1, \\dots, m$):\n1. A new candidate vector is computed: $w = A v_k$.\n2. The vector $w$ is orthogonalized against the existing basis $\\{v_1, \\dots, v_k\\}$: $h_{j,k} = v_j^T w$ and $w \\leftarrow w - h_{j,k} v_j$ for $j=1, \\dots, k$.\n3. The norm of the residual vector is computed: $h_{k+1,k} = \\|w\\|_2$.\n4. If $h_{k+1,k}$ is non-zero, the next basis vector is obtained by normalization: $v_{k+1} = w / h_{k+1,k}$.\n\nThe core of the task is to implement and compare two strategies for deciding if a computed $h_{k+1,k}$ is numerically equivalent to zero.\n\nThe first detector is a naive approach using a fixed absolute threshold, $\\tau_{\\mathrm{fix}}$. Breakdown is declared at step $k$ if the computed $h_{k+1,k} \\le \\tau_{\\mathrm{fix}}$. For this problem, we use $\\tau_{\\mathrm{fix}} = 10^{-12}$. This method is simple but lacks robustness, as the appropriate threshold can vary significantly with the problem's scale (e.g., matrix norm) and the floating-point precision.\n\nThe second detector is an adaptive method based on a first-principles model of floating-point error propagation. The goal is to derive a threshold $\\theta_k$ that approximates the magnitude of the computed $h_{k+1,k}$ when the true value is zero. The computed $h_{k+1,k}$ is the norm of a vector that, in exact arithmetic, would be the zero vector. In floating-point arithmetic, this vector is non-zero due to the accumulation of rounding errors from all operations in the $k$-th Arnoldi step.\n\nTo construct the adaptive threshold $\\theta_k$, we consider the primary sources of error, following the Standard for Floating-Point Arithmetic (IEEE 754), where the unit roundoff is $u$.\n1.  **Matrix-Vector Multiplication**: The computation of $\\mathrm{fl}(A v_k)$ introduces an error. A standard forward error model suggests the error norm is proportional to the norm of the result, i.e., of order $u \\|A v_k\\|_2$. A backward error perspective suggests an error proportional to $u \\|A\\|_2$, which provides a more uniform bound.\n2.  **Modified Gram-Schmidt Orthogonalization**: This phase consists of $k$ inner products and $k$ vector updates (saxpy operations). Each operation contributes a small rounding error. The total accumulated error in the final residual vector depends on the magnitudes of the quantities involved. The coefficients computed, $h_{j,k}$, are central to this. The norm of these coefficients, $\\|h_{1:k,k}\\|_2 = \\left(\\sum_{j=1}^k h_{j,k}^2\\right)^{1/2}$, provides a measure of the magnitude of the projections being subtracted.\n\nThe problem mandates that the adaptive threshold $\\theta_k$ be an explicit function of $u$, the spectral norm $\\|A\\|_2$, $\\|A v_k\\|_2$, and $\\|h_{1:k,k}\\|_2$. A reasonable model aggregates these contributions to form a comprehensive bound on the expected noise level. We propose a linear combination of these norms, scaled by the unit roundoff $u$ and a small positive integer constant $c$:\n$$\n\\theta_k = c \\cdot u \\cdot \\left( \\|A\\|_2 + \\|A v_k\\|_2 + \\|h_{1:k,k}\\|_2 \\right)\n$$\nThis form includes contributions from the overall scale of the operator ($\\|A\\|_2$), the scale of the vector before orthogonalization ($\\|A v_k\\|_2$), and the scale of the projection onto the existing subspace ($\\|h_{1:k,k}\\|_2$). Near breakdown, we have $\\|A v_k\\|_2 \\approx \\|h_{1:k,k}\\|_2$, but including all three terms as requested provides robustness. The constant $c$ is introduced to account for dimensionality factors (e.g., dependencies on $n$ and $k$) and other constants typically present in rigorous error bounds. We choose $c=10$, which is a small integer that provides a safe margin. For double precision, $u = 2^{-53} \\approx 1.11 \\times 10^{-16}$.\n\nThe evaluation of each detector's performance is based on its ability to correctly identify the breakdown step. For each test case, we have a ground truth breakdown step, $k_{true}$. A detector is deemed correct if its first declared breakdown step, $k_{det}$, is equal to $k_{true}$. If no breakdown occurs within the maximum $m$ iterations (i.e., $k_{true} > m$), the detector is correct only if it does not declare a breakdown for any step $k \\le m$. This is enforced by setting $k_{det}=m+1$ if no breakdown is found and checking if $k_{det} = k_{true}$.\n\nThe specified test cases are constructed to probe different scenarios: exact breakdown (Cases A, C, E), near-breakdown (Case B), and no breakdown with a generic matrix (Case D). By comparing the decisions of the naive and adaptive detectors against the known ground truth for these cases, we can objectively evaluate their effectiveness.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Designs and evaluates a naive and an adaptive breakdown detector for the Arnoldi iteration.\n    The program implements the Arnoldi process, two breakdown detection strategies,\n    and evaluates them against a suite of specified test cases.\n    \"\"\"\n\n    # Test suite specification as per the problem description.\n    test_cases = [\n        # k_true_breakdown > m indicates no breakdown is expected within m iterations.\n        {'name': 'A', 'n': 40, 'r': 10, 'eps': 0.0, 'm': 20, 'seed': 123, 'k_true': 10},\n        {'name': 'B', 'n': 40, 'r': 10, 'eps': 1e-14, 'm': 20, 'seed': 123, 'k_true': 21},\n        {'name': 'C', 'n': 200, 'r': 5, 'eps': 0.0, 'm': 15, 'seed': 7, 'k_true': 5},\n        {'name': 'D', 'n': 60, 'r': None, 'eps': None, 'm': 25, 'seed': 7, 'k_true': 26},\n        {'name': 'E', 'n': 30, 'r': 1, 'eps': 0.0, 'm': 5, 'seed': 2024, 'k_true': 1},\n    ]\n\n    # Detector parameters.\n    tau_fix = 1e-12\n    c_adaptive = 10  # A small positive integer scaling constant.\n    u = np.finfo(np.float64).eps / 2  # Unit roundoff for IEEE 754 double precision.\n\n    naive_results = []\n    adaptive_results = []\n\n    for case in test_cases:\n        n, m, seed, k_true = case['n'], case['m'], case['seed'], case['k_true']\n        \n        # --- 1. Construct test matrix A and initial vector v1 ---\n        rng = np.random.default_rng(seed)\n        \n        if case['name'] in ['A', 'B', 'C', 'E']:\n            r, eps = case['r'], case['eps']\n            S = np.diag(np.ones(r - 1), 1)\n            if eps > 0:\n                G = rng.standard_normal((r, r))\n                S_eps = S + eps * G\n            else:\n                S_eps = S\n            \n            A = np.zeros((n, n))\n            A[:r, :r] = S_eps\n            if n > r:\n                A[r:, r:] = np.eye(n - r)\n            \n            v1 = np.zeros(n)\n            v1[0] = 1.0\n        else:  # Case 'D', orthogonal matrix.\n            M = rng.standard_normal((n, n))\n            Q, _ = np.linalg.qr(M)\n            A = Q\n            b = rng.standard_normal(n)\n            v1 = b / np.linalg.norm(b)\n\n        # --- 2. Run Arnoldi iteration with breakdown detection ---\n        # Initialize detected breakdown step to m+1 (meaning no breakdown yet).\n        k_naive_detected = m + 1\n        k_adaptive_detected = m + 1\n        \n        V = np.zeros((n, m + 1))\n        H = np.zeros((m + 1, m))\n        V[:, 0] = v1\n        \n        A_norm = np.linalg.norm(A, 2)\n        \n        naive_broken = False\n        adaptive_broken = False\n\n        for k in range(m):\n            # Arnoldi step k, using Modified Gram-Schmidt.\n            w = A @ V[:, k]\n            Avk_norm = np.linalg.norm(w)\n            \n            for j in range(k + 1):\n                H[j, k] = V[:, j].T @ w\n                w = w - H[j, k] * V[:, j]\n            \n            h_k_plus_1_k = np.linalg.norm(w)\n            H[k + 1, k] = h_k_plus_1_k\n            \n            # --- Breakdown Detectors ---\n            \n            # Naive detector with fixed threshold.\n            if not naive_broken and h_k_plus_1_k <= tau_fix:\n                k_naive_detected = k + 1\n                naive_broken = True\n\n            # Adaptive detector with derived threshold.\n            if not adaptive_broken:\n                h_col_k_norm = np.linalg.norm(H[:k + 1, k])\n                theta_k = c_adaptive * u * (A_norm + Avk_norm + h_col_k_norm)\n                if h_k_plus_1_k <= theta_k:\n                    k_adaptive_detected = k + 1\n                    adaptive_broken = True\n            \n            # Generate next Arnoldi vector if process has not broken down.\n            if h_k_plus_1_k > np.finfo(np.float64).tiny:\n                V[:, k + 1] = w / h_k_plus_1_k\n            else:\n                # If h is numerically zero, the process cannot continue.\n                # Force detection for any detector that hasn't fired yet.\n                if not naive_broken: k_naive_detected = k + 1\n                if not adaptive_broken: k_adaptive_detected = k + 1\n                break\n\n        # --- 3. Evaluate detector correctness ---\n        is_naive_correct = (k_naive_detected == k_true)\n        is_adaptive_correct = (k_adaptive_detected == k_true)\n        \n        naive_results.append(is_naive_correct)\n        adaptive_results.append(is_adaptive_correct)\n\n    # --- 4. Format and print the final output as specified ---\n    naive_str = [str(r).lower() for r in naive_results]\n    adaptive_str = [str(r).lower() for r in adaptive_results]\n    \n    print(f\"[[{','.join(naive_str)}],[{','.join(adaptive_str)}]]\")\n\nsolve()\n\n```"
        }
    ]
}