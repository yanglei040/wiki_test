{
    "hands_on_practices": [
        {
            "introduction": "To master the LDLT factorization for indefinite matrices, we must first understand the building blocks that grant it stability: the $2 \\times 2$ pivots. This exercise invites you to dissect a representative $2 \\times 2$ pivot block from first principles. By calculating its eigenvalues and condition number, you will gain a concrete understanding of how these blocks contribute to the matrix's overall inertia and influence the numerical stability of the factorization process .",
            "id": "3555322",
            "problem": "Consider the real symmetric matrix pivot block that arises in a step of the Lower-Diagonal-Lower-Transpose ($LDL^T$) factorization with symmetric pivoting:\n$$\nP \\;=\\; \\begin{pmatrix} 2  3 \\\\ 3  -1 \\end{pmatrix}.\n$$\nFrom first principles, compute the eigenvalues of $P$ by forming and solving its characteristic polynomial. Using the fundamental definition of inertia (the counts of positive, negative, and zero eigenvalues) and Sylvester’s law of inertia (invariance of inertia under congruence transformations), explain how the signs of the eigenvalues of this $2\\times 2$ pivot block determine the incremental update to the global inertia in an $LDL^T$ factorization with symmetric pivoting, and interpret how those signs influence the conditioning of the local $2\\times 2$ solve associated with $P$ when forming the Schur complement.\n\nLet the $2$-norm condition number of the local solve be defined by\n$$\n\\kappa_{2}(P) \\;=\\; \\|P\\|_{2}\\,\\|P^{-1}\\|_{2},\n$$\nand recall that for a real symmetric matrix, the singular values are the absolute values of the eigenvalues. Provide your final answer as the exact closed-form expression for $\\kappa_{2}(P)$. Do not provide any numerical approximations; no rounding is required.",
            "solution": "The problem is well-posed and scientifically grounded within the field of numerical linear algebra. All data and definitions required for the solution are provided and are internally consistent. The problem asks for the computation of eigenvalues, an explanation of inertia in the context of LDLT factorization, an interpretation of conditioning, and the calculation of a specific condition number for a given $2 \\times 2$ matrix. These are standard, verifiable concepts. Therefore, the problem is valid and I will proceed with a full solution.\n\nThe pivot block under consideration is the real symmetric matrix $P$ given by:\n$$\nP = \\begin{pmatrix} 2  3 \\\\ 3  -1 \\end{pmatrix}\n$$\n\nFirst, we compute the eigenvalues of $P$ by solving the characteristic equation $\\det(P - \\lambda I) = 0$, where $I$ is the $2 \\times 2$ identity matrix and $\\lambda$ represents the eigenvalues.\n$$\nP - \\lambda I = \\begin{pmatrix} 2 - \\lambda  3 \\\\ 3  -1 - \\lambda \\end{pmatrix}\n$$\nThe determinant is:\n$$\n\\det(P - \\lambda I) = (2 - \\lambda)(-1 - \\lambda) - (3)(3) = -2 - 2\\lambda + \\lambda + \\lambda^2 - 9 = \\lambda^2 - \\lambda - 11\n$$\nSetting the characteristic polynomial to zero gives the quadratic equation:\n$$\n\\lambda^2 - \\lambda - 11 = 0\n$$\nUsing the quadratic formula, $\\lambda = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$, with $a=1$, $b=-1$, and $c=-11$:\n$$\n\\lambda = \\frac{1 \\pm \\sqrt{(-1)^2 - 4(1)(-11)}}{2(1)} = \\frac{1 \\pm \\sqrt{1 + 44}}{2} = \\frac{1 \\pm \\sqrt{45}}{2}\n$$\nSimplifying the square root, $\\sqrt{45} = \\sqrt{9 \\times 5} = 3\\sqrt{5}$. The two eigenvalues are:\n$$\n\\lambda_1 = \\frac{1 + 3\\sqrt{5}}{2} \\quad \\text{and} \\quad \\lambda_2 = \\frac{1 - 3\\sqrt{5}}{2}\n$$\n\nNext, we address the concept of inertia and its role in the $LDL^T$ factorization. The inertia of a real symmetric matrix is a triple $(\\nu_+, \\nu_-, \\nu_0)$, where $\\nu_+$ is the number of positive eigenvalues, $\\nu_-$ is the number of negative eigenvalues, and $\\nu_0$ is the number of zero eigenvalues. For our matrix $P$, we determine the signs of its eigenvalues. Since $\\sqrt{5} \\approx 2.236$, $3\\sqrt{5} \\approx 6.708$.\n$$\n\\lambda_1 = \\frac{1 + 3\\sqrt{5}}{2}  0\n$$\n$$\n\\lambda_2 = \\frac{1 - 3\\sqrt{5}}{2}  0\n$$\nSince $P$ has one positive and one negative eigenvalue, and no zero eigenvalues, its inertia is $(1, 1, 0)$.\n\nSylvester's law of inertia states that the inertia of a symmetric matrix $A$ is invariant under a congruence transformation, i.e., for any invertible matrix $S$, the matrix $S^T A S$ has the same inertia as $A$. The $LDL^T$ factorization (with symmetric pivoting) of a large symmetric matrix $A$ produces a decomposition $Q^T A Q = L D L^T$, where $Q$ is a permutation matrix, $L$ is a unit lower triangular matrix, and $D$ is a block diagonal matrix with $1 \\times 1$ or $2 \\times 2$ blocks. The transformation from $D$ to $Q^T A Q$ is a congruence transformation, since $L$ is invertible. Therefore, the inertia of $A$ is equal to the inertia of $D$. The inertia of $D$ is simply the sum of the inertias of its diagonal blocks.\n\nWhen the factorization algorithm selects the $2 \\times 2$ block $P$ as a pivot, this block becomes one of the diagonal blocks of $D$. The incremental update to the global inertia of the original matrix $A$ is the inertia of this pivot block. In this case, processing the block $P$ contributes its inertia of $(1, 1, 0)$ to the total count, meaning it accounts for one positive and one negative eigenvalue of the full matrix $A$.\n\nNow, we interpret the influence of the eigenvalue signs on the conditioning of the local $2 \\times 2$ solve. In a block factorization, forming the Schur complement requires computing terms like $A_{21} P^{-1} A_{12}$, which involves solving linear systems with the pivot block $P$. The stability of this step depends on the condition number of $P$. The $2$-norm condition number is defined as $\\kappa_2(P) = \\|P\\|_2 \\|P^{-1}\\|_2$. For a symmetric matrix, the $2$-norm is its spectral radius (maximum absolute value of its eigenvalues), so $\\|P\\|_2 = \\max_i |\\lambda_i|$. The eigenvalues of $P^{-1}$ are the reciprocals of the eigenvalues of $P$, so $\\|P^{-1}\\|_2 = \\max_i |1/\\lambda_i| = 1/\\min_i |\\lambda_i|$ (for invertible $P$). Thus:\n$$\n\\kappa_2(P) = \\frac{\\max_i |\\lambda_i|}{\\min_i |\\lambda_i|}\n$$\nThe signs of the eigenvalues being opposite ($+$ and $-$) signify that $P$ is an indefinite matrix. This is a common occurrence in $LDL^T$ factorization for general symmetric matrices, and $2 \\times 2$ pivots are chosen precisely to handle the instabilities that would arise from small or zero diagonal entries if only $1 \\times 1$ pivots were allowed. While the signs themselves tell us the matrix is indefinite, it is the ratio of the magnitudes of the eigenvalues that determines the conditioning. A large ratio indicates an ill-conditioned local solve, which can amplify numerical errors during the formation of the Schur complement. Pivoting strategies (like Bunch-Kaufman) are designed to select pivot blocks, such as $P$, that are as well-conditioned as possible, i.e., where the ratio $|\\lambda_{\\max}| / |\\lambda_{\\min}|$ is not excessively large.\n\nFinally, we compute the exact closed-form expression for $\\kappa_2(P)$. We need the absolute values of the eigenvalues:\n$$\n|\\lambda_1| = \\left| \\frac{1 + 3\\sqrt{5}}{2} \\right| = \\frac{1 + 3\\sqrt{5}}{2}\n$$\n$$\n|\\lambda_2| = \\left| \\frac{1 - 3\\sqrt{5}}{2} \\right| = -\\left( \\frac{1 - 3\\sqrt{5}}{2} \\right) = \\frac{3\\sqrt{5} - 1}{2}\n$$\nWe compare the magnitudes to find the maximum and minimum. Clearly, $1 + 3\\sqrt{5}  3\\sqrt{5} - 1$, so $|\\lambda_1|  |\\lambda_2|$.\n$$\n\\max_i |\\lambda_i| = |\\lambda_1| = \\frac{1 + 3\\sqrt{5}}{2}\n$$\n$$\n\\min_i |\\lambda_i| = |\\lambda_2| = \\frac{3\\sqrt{5} - 1}{2}\n$$\nThe condition number is the ratio:\n$$\n\\kappa_2(P) = \\frac{\\frac{1 + 3\\sqrt{5}}{2}}{\\frac{3\\sqrt{5} - 1}{2}} = \\frac{1 + 3\\sqrt{5}}{3\\sqrt{5} - 1}\n$$\nTo simplify, we multiply the numerator and denominator by the conjugate of the denominator, which is $3\\sqrt{5} + 1$:\n$$\n\\kappa_2(P) = \\frac{1 + 3\\sqrt{5}}{3\\sqrt{5} - 1} \\times \\frac{3\\sqrt{5} + 1}{3\\sqrt{5} + 1} = \\frac{(1 + 3\\sqrt{5})(3\\sqrt{5} + 1)}{(3\\sqrt{5} - 1)(3\\sqrt{5} + 1)}\n$$\nThe numerator is $(1 + 3\\sqrt{5})^2 = 1^2 + 2(1)(3\\sqrt{5}) + (3\\sqrt{5})^2 = 1 + 6\\sqrt{5} + 9(5) = 46 + 6\\sqrt{5}$.\nThe denominator is $(3\\sqrt{5})^2 - 1^2 = 9(5) - 1 = 45 - 1 = 44$.\nTherefore, the condition number is:\n$$\n\\kappa_2(P) = \\frac{46 + 6\\sqrt{5}}{44} = \\frac{2(23 + 3\\sqrt{5})}{2(22)} = \\frac{23 + 3\\sqrt{5}}{22}\n$$\nThis is the final exact expression for the condition number.",
            "answer": "$$\n\\boxed{\\frac{23 + 3\\sqrt{5}}{22}}\n$$"
        },
        {
            "introduction": "With an understanding of individual pivots, we can now explore how they function within the complete factorization algorithm. Classical tests for definiteness, like Sylvester's criterion, often fail for indefinite systems or when pivoting reorders the matrix. This problem demonstrates how the LDLT factorization with symmetric pivoting correctly determines a matrix's inertia, even when simpler methods based on leading principal minors are misleading .",
            "id": "3555289",
            "problem": "Consider the real symmetric matrix $A \\in \\mathbb{R}^{4 \\times 4}$ given by\n$$\nA \\;=\\; \\begin{pmatrix}\n0  0  0  3 \\\\\n0  2  1  0 \\\\\n0  1  -1  0 \\\\\n3  0  0  0\n\\end{pmatrix}.\n$$\nA practitioner attempts to reason about definiteness and inertia using leading principal minors while performing a symmetric indefinite factorization with pivoting. In this setting, leading principal minors with respect to the original ordering no longer correspond to the pivot sequence once permutations are introduced, and $2 \\times 2$ pivots invalidate any argument based solely on $1 \\times 1$ leading principal minors.\n\nTasks:\n- Compute the leading principal minors $\\Delta_{k}(A)$ for $k \\in \\{1,2,3,4\\}$ and state their signs.\n- Let $P \\in \\mathbb{R}^{4 \\times 4}$ be the permutation matrix that reorders indices as $(1,4,2,3)$, i.e.,\n$$\nP \\;=\\; \\begin{pmatrix}\n1  0  0  0 \\\\\n0  0  0  1 \\\\\n0  1  0  0 \\\\\n0  0  1  0\n\\end{pmatrix}.\n$$\nForm $B = P^{T} A P$ and compute the leading principal minors $\\Delta_{k}(B)$ for $k \\in \\{1,2,3,4\\}$ and state their signs.\n- Explain, using the computed minors, why an argument that applies Sylvester’s criterion to leading principal minors fails once symmetric pivoting introduces permutations and $2 \\times 2$ pivots.\n- Perform an $LDL^T$ factorization with symmetric permutations of $A$ by factoring $B = P^T A P$ into $B = L D L^T$ where $L$ is unit lower triangular and $D$ is block diagonal with $1 \\times 1$ and $2 \\times 2$ symmetric blocks. Use this to recover the inertia of $A$ (the triple $(n_{+}, n_{-}, n_{0})$ giving the number of positive, negative, and zero eigenvalues), invoking invariance of inertia under congruence.\n  \nExpress the final inertia $(n_{+}, n_{-}, n_{0})$ as a single row matrix. No rounding is required.",
            "solution": "We begin with the foundational facts:\n- For a real symmetric matrix $A$, the inertia is the triple $(n_{+}, n_{-}, n_{0})$ counting its positive, negative, and zero eigenvalues.\n- Sylvester’s criterion asserts that a real symmetric matrix is positive definite if and only if all leading principal minors are positive; this criterion relies on a fixed ordering and $1 \\times 1$ leading pivots.\n- Sylvester’s law of inertia states that the inertia is invariant under real nonsingular congruence transformations. In particular, if $A = S^{T} D S$ with $S$ nonsingular and $D$ symmetric block diagonal (with $1 \\times 1$ and $2 \\times 2$ blocks), then $A$ and $D$ have the same inertia.\n- In symmetric indefinite factorization with pivoting (such as the Bunch–Kaufman family), one computes $P^T A P = L D L^T$ with $P$ a permutation, $L$ unit lower triangular, and $D$ block diagonal with $1 \\times 1$ and $2 \\times 2$ symmetric blocks. The inertia is read off from $D$ by summing the inertia contributions of the blocks.\n\nStep 1: Leading principal minors of $A$.\nThe leading principal minors $\\Delta_{k}(A)$ are determinants of the top-left $k \\times k$ principal submatrices:\n- For $k=1$,\n$$\n\\Delta_{1}(A) \\;=\\; \\det\\begin{pmatrix} 0 \\end{pmatrix} \\;=\\; 0.\n$$\n- For $k=2$,\n$$\n\\Delta_{2}(A) \\;=\\; \\det\\begin{pmatrix} 0  0 \\\\ 0  2 \\end{pmatrix} \\;=\\; 0 \\cdot 2 - 0 \\cdot 0 \\;=\\; 0.\n$$\n- For $k=3$,\n$$\n\\Delta_{3}(A) \\;=\\; \\det\\begin{pmatrix} 0  0  0 \\\\ 0  2  1 \\\\ 0  1  -1 \\end{pmatrix} \\;=\\; 0,\n$$\nsince the first column is entirely zero.\n- For $k=4$,\n$$\n\\Delta_{4}(A) \\;=\\; \\det(A).\n$$\nWe will compute $\\det(A)$ using a permutation that block-diagonalizes $A$ (next step), but note that determinants are invariant under permutation similarity, so $\\det(A) = \\det(P^T A P)$. We will find $\\det(P^T A P) = 27$ below; hence $\\Delta_{4}(A) = 27$.\n\nThus, the signs of leading principal minors of $A$ are $0$, $0$, $0$, and positive.\n\nStep 2: Form $B = P^T A P$ with the given $P$ and compute its leading principal minors.\nThe permutation reorders indices as $(1, 4, 2, 3)$. Compute $B$:\n$$\nB \\;=\\; P^T A P \\;=\\; \\begin{pmatrix}\n0  3  0  0 \\\\\n3  0  0  0 \\\\\n0  0  2  1 \\\\\n0  0  1  -1\n\\end{pmatrix}.\n$$\nThis is block diagonal, with the top-left $2 \\times 2$ block\n$$\nB_{11} \\;=\\; \\begin{pmatrix} 0  3 \\\\ 3  0 \\end{pmatrix},\n$$\nand the bottom-right $2 \\times 2$ block\n$$\nB_{22} \\;=\\; \\begin{pmatrix} 2  1 \\\\ 1  -1 \\end{pmatrix}.\n$$\nNow compute the leading principal minors of $B$:\n- For $k=1$,\n$$\n\\Delta_{1}(B) \\;=\\; 0.\n$$\n- For $k=2$,\n$$\n\\Delta_{2}(B) \\;=\\; \\det\\begin{pmatrix} 0  3 \\\\ 3  0 \\end{pmatrix} \\;=\\; -9,\n$$\nwhich is negative.\n- For $k=3$,\n$$\n\\Delta_{3}(B) \\;=\\; \\det\\begin{pmatrix} 0  3  0 \\\\ 3  0  0 \\\\ 0  0  2 \\end{pmatrix} \\;=\\; \\det\\begin{pmatrix} 0  3 \\\\ 3  0 \\end{pmatrix} \\cdot \\det\\begin{pmatrix} 2 \\end{pmatrix} \\;=\\; (-9) \\cdot 2 \\;=\\; -18,\n$$\nwhich is negative.\n- For $k=4$,\n$$\n\\Delta_{4}(B) \\;=\\; \\det(B) \\;=\\; \\det(B_{11}) \\cdot \\det(B_{22}) \\;=\\; (-9) \\cdot \\det\\begin{pmatrix} 2  1 \\\\ 1  -1 \\end{pmatrix}.\n$$\nCompute\n$$\n\\det\\begin{pmatrix} 2  1 \\\\ 1  -1 \\end{pmatrix} \\;=\\; 2 \\cdot (-1) - 1 \\cdot 1 \\;=\\; -2 - 1 \\;=\\; -3,\n$$\nso\n$$\n\\Delta_{4}(B) \\;=\\; (-9) \\cdot (-3) \\;=\\; 27,\n$$\nwhich is positive, and hence $\\det(A) = \\det(B) = 27$ as stated above.\n\nThus, the signs of leading principal minors of $B$ are $0$, negative, negative, and positive.\n\nStep 3: Why applying Sylvester’s criterion to leading principal minors fails after pivoting.\nSylvester’s criterion characterizes positive definiteness by positivity of all leading principal minors for a fixed ordering. In symmetric indefinite factorization with pivoting, one introduces a permutation $P$ to select numerically stable $1 \\times 1$ or $2 \\times 2$ pivots, and the factorization proceeds on $B = P^T A P$. The pivot sequence thus refers to blocks that are not aligned with the original leading principal minors of $A$. In our example, the factorization begins with a $2 \\times 2$ pivot on the indices $(1,4)$, which is brought to the leading position by $P$. The presence of a $2 \\times 2$ pivot invalidates any incremental reasoning based solely on $1 \\times 1$ leading principal minors, and the signs of $\\Delta_{k}(B)$ show that even for the permuted ordering the first minors are $0$, negative, negative, then positive. Hence, trying to apply Sylvester’s criterion to the leading principal minors encountered along the pivoted order does not provide a valid definiteness or inertia argument: the necessary permutation and block pivots break the direct link between leading principal minors and definiteness tests intended for $1 \\times 1$ pivots without permutations.\n\nStep 4: $LDL^T$ factorization of $B$ and recovery of inertia.\nBecause $B$ is block diagonal with the two $2 \\times 2$ symmetric blocks $B_{11}$ and $B_{22}$ and zeros off-block, a valid symmetric indefinite factorization is\n$$\nB \\;=\\; L D L^T,\n$$\nwith\n$$\nL \\;=\\; I_{4}, \\qquad D \\;=\\; \\operatorname{blkdiag}\\!\\left( \\begin{pmatrix} 0  3 \\\\ 3  0 \\end{pmatrix}, \\begin{pmatrix} 2  1 \\\\ 1  -1 \\end{pmatrix} \\right).\n$$\nThe inertia of $B$ (and hence of $A$) equals the sum of the inertia contributions of these blocks, by Sylvester’s law of inertia and nonsingularity of $L$:\n- For $B_{11} = \\begin{pmatrix} 0  3 \\\\ 3  0 \\end{pmatrix}$, the eigenvalues are $\\lambda = 3$ and $\\lambda = -3$, so its inertia contribution is $(1,1,0)$.\n- For $B_{22} = \\begin{pmatrix} 2  1 \\\\ 1  -1 \\end{pmatrix}$, the trace is $1$ and determinant is $-3$, so the eigenvalues solve $\\lambda^{2} - \\lambda - 3 = 0$, yielding one positive and one negative eigenvalue, i.e., inertia contribution $(1,1,0)$.\n\nTherefore, the inertia of $B$ is $(2,2,0)$, and by congruence invariance, the inertia of $A$ is also\n$$\n(n_{+}, n_{-}, n_{0}) \\;=\\; (2, 2, 0).\n$$\n\nThis explicitly demonstrates that although leading principal minors along a pivoted order do not provide a valid definiteness or inertia argument, the $LDL^T$ factorization with symmetric permutations robustly recovers the correct inertia via the block diagonal $D$.",
            "answer": "$$\\boxed{\\begin{pmatrix} 2  2  0 \\end{pmatrix}}$$"
        },
        {
            "introduction": "The power of the LDLT factorization lies not just in its theoretical elegance but in its guaranteed numerical stability, a feature governed by the pivoting strategy. This advanced practice challenges you to probe the performance limits of the celebrated Bunch-Kaufman pivoting algorithm. By analyzing a carefully constructed matrix family, you will quantify the \"element growth factor\" and connect it directly to the backward error, providing a deep insight into why this method is a cornerstone of modern numerical linear algebra .",
            "id": "3555278",
            "problem": "Consider the Bunch–Kaufman threshold pivoting strategy for the symmetric indefinite $LDL^T$ factorization (where $L$ is unit lower triangular and $D$ is block diagonal with $1 \\times 1$ and $2 \\times 2$ symmetric blocks), with the canonical threshold parameter $\\alpha_{\\star} = \\frac{1 + \\sqrt{17}}{8}$. The decision rule at a step $k$ with current leading column $k$ is: if $|a_{kk}| \\ge \\alpha_{\\star} \\max_{i > k} |a_{ik}|$, accept the $1 \\times 1$ pivot at $k$; otherwise, let $j$ be an index achieving the maximum off-diagonal magnitude in column $k$, i.e., $|a_{kj}| = \\max_{i > k} |a_{ik}|$. If $|a_{jj}| \\ge \\alpha_{\\star} \\max_{i \\neq j} |a_{ij}|$, accept the $1 \\times 1$ pivot at $j$ (after swapping it into the $k$-th position); otherwise accept the $2 \\times 2$ pivot on indices $(k,j)$. Assume ties in choosing $j$ are broken by taking the smallest index.\n\nDefine a two-parameter family of symmetric $3 \\times 3$ matrices depending on real parameters $\\tau$ and $\\beta$:\n$$\nA(\\tau,\\beta) \\;=\\; \\begin{pmatrix}\n\\tau  1  1\\\\\n1  \\tau  1\\\\\n1  1  -\\beta\n\\end{pmatrix},\n$$\nwith $0  \\tau  \\alpha_{\\star}$ and $0  \\beta  \\alpha_{\\star}$. Let the element growth factor for the factorization be defined by\n$$\n\\rho(A) \\;=\\; \\frac{\\max_{i,j,\\;k\\ \\text{throughout the factorization}} |a^{(k)}_{ij}|}{\\max_{i,j} |a_{ij}|},\n$$\nwhere $a^{(k)}_{ij}$ are the entries of the evolving Schur complements generated during the $LDL^T$ factorization under the specified pivoting, starting from $A^{(1)} = A$.\n\nTasks:\n1. Using only the threshold rule above and the structure of $A(\\tau,\\beta)$, determine which pivot the algorithm accepts at the first step and justify it.\n2. Compute the exact value of the element growth factor $\\rho(A(\\tau,\\beta))$ as a function of $\\tau$ and $\\beta$ for this pivot choice, starting from first principles (definitions of Schur complement updates for a $2 \\times 2$ pivot).\n3. By taking the parameters to their extremal values while maintaining the pivoting decisions (i.e., $\\tau \\to 0^{+}$ and $\\beta \\to \\alpha_{\\star}^{-}$), determine the limiting worst-case element growth factor within this family, denoted $\\rho_{\\star} = \\lim_{\\tau \\to 0^{+},\\ \\beta \\to \\alpha_{\\star}^{-}} \\rho(A(\\tau,\\beta))$, in closed form in terms of $\\alpha_{\\star}$.\n4. Under the standard floating-point model $\\mathrm{fl}(x \\circ y) = (x \\circ y)(1 + \\delta)$ with $|\\delta| \\le u$ for arithmetic operation $\\circ \\in \\{+,-,\\times,\\div\\}$, the computed factorization is the exact $LDL^T$ factorization of $A + \\Delta A$. Explain, using normwise reasoning and the definition of the growth factor, how a bound of the form $\\|\\Delta A\\|_{\\infty} / \\|A\\|_{\\infty} \\lesssim C u \\rho(A(\\tau,\\beta))$ arises for some constant $C$ independent of $\\tau$ and $\\beta$, thereby relating $\\rho_{\\star}$ to a worst-case leading-order normwise backward error bound for this family.\n\nProvide as your final answer only the exact closed-form expression for $\\rho_{\\star}$. No numerical rounding is required, and no units are involved. Express your final answer in simplest closed form.",
            "solution": "The problem is well-posed, scientifically grounded in the theory of numerical linear algebra, and contains all necessary information for a unique solution. It is therefore deemed valid.\n\nThe problem asks for an analysis of the Bunch–Kaufman $LDL^T$ factorization for a specified $3 \\times 3$ symmetric matrix family $A(\\tau,\\beta)$.\n\nThe given matrix is:\n$$\nA(\\tau,\\beta) \\;=\\; \\begin{pmatrix}\n\\tau  1  1\\\\\n1  \\tau  1\\\\\n1  1  -\\beta\n\\end{pmatrix}\n$$\nwith parameters satisfying $0  \\tau  \\alpha_{\\star}$ and $0  \\beta  \\alpha_{\\star}$, where $\\alpha_{\\star} = \\frac{1 + \\sqrt{17}}{8}$ is the threshold parameter. The matrix entries at the start of the factorization are $a_{ij}^{(1)} = a_{ij}$.\n\n**Task 1: Determine the first pivot**\n\nThe algorithm starts at step $k=1$. The first column of the matrix is $(\\tau, 1, 1)^T$.\nThe Bunch–Kaufman pivoting strategy first considers a $1 \\times 1$ pivot from the diagonal element $a_{11}^{(1)} = \\tau$. The decision rule is to check if $|a_{11}^{(1)}| \\ge \\alpha_{\\star} \\max_{i > 1} |a_{i1}^{(1)}|$.\n\nHere, $|a_{11}^{(1)}| = |\\tau| = \\tau$. The maximum magnitude of off-diagonal elements in the first column is $\\lambda = \\max_{i > 1} |a_{i1}^{(1)}| = \\max(|a_{21}^{(1)}|, |a_{31}^{(1)}|) = \\max(|1|, |1|) = 1$.\nThe condition becomes $\\tau \\ge \\alpha_{\\star} \\cdot 1$. However, the problem specifies that $0  \\tau  \\alpha_{\\star}$. Thus, the condition is not met, and a $1 \\times 1$ pivot at position $(1,1)$ is rejected.\n\nNext, the algorithm identifies an index $j$ such that $|a_{j1}^{(1)}| = \\lambda = 1$. The candidates are $j=2$ and $j=3$. The tie-breaking rule specifies choosing the smallest index, so we select $j=2$.\n\nThe algorithm now considers using a $1 \\times 1$ pivot from position $(j,j) = (2,2)$ by swapping rows and columns $1$ and $2$. The condition for this is $|a_{22}^{(1)}| \\ge \\alpha_{\\star} \\max_{i \\neq 2} |a_{i2}^{(1)}|$.\nHere, $|a_{22}^{(1)}| = |\\tau| = \\tau$. The maximum magnitude of off-diagonal elements in the second column (which is the $j$-th column) is $\\sigma = \\max_{i \\neq 2} |a_{i2}^{(1)}| = \\max(|a_{12}^{(1)}|, |a_{32}^{(1)}|) = \\max(|1|, |1|) = 1$.\nThe condition becomes $\\tau \\ge \\alpha_{\\star} \\cdot 1$. Again, this is false since $\\tau  \\alpha_{\\star}$.\n\nSince both $1 \\times 1$ pivot options are rejected, the algorithm must choose a $2 \\times 2$ pivot formed by the indices $(k, j) = (1, 2)$. The pivot block is:\n$$\nP \\;=\\; \\begin{pmatrix} a_{11}  a_{12} \\\\ a_{21}  a_{22} \\end{pmatrix} \\;=\\; \\begin{pmatrix} \\tau  1 \\\\ 1  \\tau \\end{pmatrix}\n$$\n\n**Task 2: Compute the element growth factor $\\rho(A(\\tau,\\beta))$**\n\nThe element growth factor is defined as $\\rho(A) = \\frac{\\max_{i,j,k} |a_{ij}^{(k)}|}{\\max_{i,j} |a_{ij}|}$.\nFirst, we find the denominator. The elements of $A = A^{(1)}$ are $\\tau$, $1$, and $-\\beta$. Since $0  \\tau  \\alpha_{\\star}$, $0  \\beta  \\alpha_{\\star}$, and $\\alpha_{\\star} = \\frac{1+\\sqrt{17}}{8} \\approx 0.64$, we have $\\tau1$ and $\\beta1$. Therefore, $\\max_{i,j} |a_{ij}| = 1$.\n\nNext, we find the numerator by computing the elements of the Schur complement $A^{(2)}$. The factorization proceeds by partitioning $A$ according to the $2 \\times 2$ pivot:\n$$\nA \\;=\\; \\begin{pmatrix} A_{11}  A_{12} \\\\ A_{21}  A_{22} \\end{pmatrix} \\;=\\; \\left(\\begin{array}{cc|c} \\tau  1  1 \\\\ 1  \\tau  1 \\\\ \\hline 1  1  -\\beta \\end{array}\\right)\n$$\nwhere $A_{11} = \\begin{pmatrix} \\tau  1 \\\\ 1  \\tau \\end{pmatrix}$, $A_{12} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$, $A_{21} = \\begin{pmatrix} 1  1 \\end{pmatrix}$, and $A_{22} = (-\\beta)$.\n\nThe Schur complement $S$ is the only remaining block $A^{(2)}$ and is given by $S = A_{22} - A_{21} A_{11}^{-1} A_{12}$.\nThe inverse of the pivot $A_{11}$ is:\n$$\nA_{11}^{-1} \\;=\\; \\frac{1}{\\det(A_{11})} \\begin{pmatrix} \\tau  -1 \\\\ -1  \\tau \\end{pmatrix} \\;=\\; \\frac{1}{\\tau^2 - 1} \\begin{pmatrix} \\tau  -1 \\\\ -1  \\tau \\end{pmatrix}\n$$\nNow we compute $S$:\n$$\nS \\;=\\; (-\\beta) - \\begin{pmatrix} 1  1 \\end{pmatrix} \\left( \\frac{1}{\\tau^2 - 1} \\begin{pmatrix} \\tau  -1 \\\\ -1  \\tau \\end{pmatrix} \\right) \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n$$\n$$\nS \\;=\\; (-\\beta) - \\frac{1}{\\tau^2 - 1} \\begin{pmatrix} \\tau-1  \\tau-1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\;=\\; (-\\beta) - \\frac{2(\\tau-1)}{\\tau^2 - 1}\n$$\nSince $\\tau^2 - 1 = (\\tau - 1)(\\tau + 1)$ and $\\tau  \\alpha_{\\star}  1$ implies $\\tau \\neq 1$, we can simplify:\n$$\nS \\;=\\; -\\beta - \\frac{2}{\\tau + 1}\n$$\nThe elements generated during factorization are those of $A^{(1)}$ and $A^{(2)} = (S)$.\nThe maximum magnitude element is $\\max_{i,j,k} |a_{ij}^{(k)}| = \\max(\\max_{i,j} |a^{(1)}_{ij}|, |S|) = \\max(1, |-\\beta - \\frac{2}{\\tau+1}|)$.\nSince $\\beta > 0$ and $\\tau > 0$, we have $|-\\beta - \\frac{2}{\\tau+1}| = \\beta + \\frac{2}{\\tau+1}$.\n\nWe check if $\\beta + \\frac{2}{\\tau+1} > 1$.\nWe are given $0  \\tau  \\alpha_{\\star}$, so $1  \\tau+1  1+\\alpha_{\\star}$. This implies $\\frac{1}{1+\\alpha_{\\star}}  \\frac{1}{\\tau+1}  1$ and $\\frac{2}{1+\\alpha_{\\star}}  \\frac{2}{\\tau+1}  2$.\n$\\alpha_{\\star} = \\frac{1+\\sqrt{17}}{8}  \\frac{1+5}{8} = \\frac{6}{8} = \\frac{3}{4}$. So $1+\\alpha_{\\star}  \\frac{7}{4}$.\n$\\frac{2}{1+\\alpha_{\\star}} > \\frac{2}{7/4} = \\frac{8}{7} > 1$.\nSince $\\frac{2}{\\tau+1} > 1$ and $\\beta > 0$, it is certain that $\\beta + \\frac{2}{\\tau+1} > 1$.\nThus, the maximum magnitude element encountered is $|S|$.\n\nThe growth factor is then:\n$$\n\\rho(A(\\tau,\\beta)) \\;=\\; \\frac{\\beta + \\frac{2}{\\tau+1}}{1} \\;=\\; \\beta + \\frac{2}{\\tau+1}\n$$\n\n**Task 3: Compute the limiting worst-case growth factor $\\rho_{\\star}$**\n\nWe need to compute the limit of $\\rho(A(\\tau,\\beta))$ as the parameters approach their extremal values, $\\tau \\to 0^{+}$ and $\\beta \\to \\alpha_{\\star}^{-}$. The pivoting decision remains the same in these limits.\n$$\n\\rho_{\\star} \\;=\\; \\lim_{\\tau \\to 0^{+},\\ \\beta \\to \\alpha_{\\star}^{-}} \\rho(A(\\tau,\\beta)) \\;=\\; \\lim_{\\tau \\to 0^{+},\\ \\beta \\to \\alpha_{\\star}^{-}} \\left( \\beta + \\frac{2}{\\tau+1} \\right)\n$$\nBy direct substitution:\n$$\n\\rho_{\\star} \\;=\\; \\alpha_{\\star} + \\frac{2}{0+1} \\;=\\; \\alpha_{\\star} + 2\n$$\nSubstituting the value $\\alpha_{\\star} = \\frac{1 + \\sqrt{17}}{8}$:\n$$\n\\rho_{\\star} \\;=\\; \\frac{1 + \\sqrt{17}}{8} + 2 \\;=\\; \\frac{1 + \\sqrt{17}}{8} + \\frac{16}{8} \\;=\\; \\frac{17 + \\sqrt{17}}{8}\n$$\n\n**Task 4: Relation to Backward Error**\n\nThe standard model of floating-point arithmetic implies that the computed $\\hat{L}$ and $\\hat{D}$ factors are the exact factors of a perturbed matrix, $\\hat{L}\\hat{D}\\hat{L}^T = A + \\Delta A$. The goal of backward error analysis is to bound the norm of the perturbation $\\Delta A$. For the Bunch–Kaufman algorithm, a standard result provides a componentwise bound on $\\Delta A$:\n$$\n|\\Delta A| \\;\\le\\; c_n u |A| + \\gamma_{n} u |\\hat{L}||\\hat{D}||\\hat{L}|^T\n$$\nwhere $c_n$ and $\\gamma_n$ are small constants depending on the dimension $n$ ($n=3$ in this case) and $u$ is the unit roundoff. A simplified, but common, normwise bound follows:\n$$\n\\|\\Delta A\\|_{\\infty} \\;\\lesssim\\; C_{n} u \\||\\hat{L}||\\hat{D}||\\hat{L}|^T\\|_{\\infty} \\;\\le\\; C_{n} u \\|\\hat{L}\\|_{\\infty}^2 \\|\\hat{D}\\|_{\\infty}\n$$\nThe threshold pivoting strategy is designed to control the size of the elements in $\\hat{L}$. For this algorithm, the magnitudes of the entries of $L$ are bounded by a constant related to $\\alpha_{\\star}$, so $\\|\\hat{L}\\|_{\\infty}$ is bounded by a modest constant independent of $\\tau$ and $\\beta$.\nThe crucial term is $\\|\\hat{D}\\|_{\\infty}$. The block diagonal matrix $\\hat{D}$ consists of the computed pivots. The magnitudes of the entries of these pivots are bounded by the maximum element magnitude found during the factorization, which is by definition $\\rho(A) \\max_{i,j} |a_{ij}| = \\rho(A) \\|A\\|_{\\infty}$. Thus, $\\|\\hat{D}\\|_{\\infty}$ is on the order of $\\rho(A) \\|A\\|_{\\infty}$.\nCombining these observations, we arrive at the bound:\n$$\n\\|\\Delta A\\|_{\\infty} \\;\\lesssim\\; C u \\rho(A(\\tau,\\beta)) \\|A\\|_{\\infty}\n$$\nDividing by $\\|A\\|_{\\infty}$ yields the relative normwise backward error bound:\n$$\n\\frac{\\|\\Delta A\\|_{\\infty}}{\\|A\\|_{\\infty}} \\;\\lesssim\\; C u \\rho(A(\\tau,\\beta))\n$$\nHere, $C$ is a constant that depends on $n$ but is independent of $\\tau$ and $\\beta$. This shows that the growth factor $\\rho$ is a direct multiplier in the backward error bound. The limiting value $\\rho_{\\star}$ represents the worst-case multiplier for this family of matrices, indicating that even in this case, the algorithm is backward stable as $\\rho_{\\star}$ is a small constant (approx $2.64$).\n\nThe final answer is the exact value of $\\rho_{\\star}$.",
            "answer": "$$\n\\boxed{\\frac{17 + \\sqrt{17}}{8}}\n$$"
        }
    ]
}