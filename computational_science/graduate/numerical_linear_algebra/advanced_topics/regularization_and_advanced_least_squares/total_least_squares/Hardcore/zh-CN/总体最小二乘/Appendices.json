{
    "hands_on_practices": [
        {
            "introduction": "本练习将总体最小二乘法的抽象概念置于一个具体的几何问题中：当两个坐标都存在误差时，如何对数据点进行直线拟合。通过从第一性原理（最小化正交距离）出发推导求解过程，您将把几何直觉与奇异值分解（SVD）这一强大的代数工具联系起来。这项实践将为您理解总体最小二乘法如何处理“变量含误差”（errors-in-variables）模型打下坚实的基础。",
            "id": "3223301",
            "problem": "给定离散的平面数据点集，其中点的 $x$ 坐标和 $y$ 坐标都受到大小相当的测量误差的影响。您的任务是构建一个将直线拟合到这些数据的总体最小二乘法 (TLS) 问题，从第一性原理推导出一个计算上稳定的方法，并将其实现为一个程序，该程序处理指定的测试套件并以精确的格式输出结果。\n\n基本原理与目标。从几何定义出发，平面中的一条直线可以用齐次形式 $a x + b y + c = 0$ 表示，并带有归一化约束 $a^{2} + b^{2} = 1$。由于归一化，从数据点 $(x_{i}, y_{i})$ 到该直线的正交距离由 $\\lvert a x_{i} + b y_{i} + c \\rvert$ 给出。用于拟合两个变量都存在误差的直线的总体最小二乘法目标是，在满足归一化约束的条件下，寻找能够最小化所有点到直线平方正交距离之和的直线参数。这是一个离散的最小二乘问题，其中残差是沿垂直于模型流形的方向而不是沿坐标轴测量的。\n\n推导范围与算法要求。从上述基础出发，推导出约束最小化公式，并利用线性代数将其简化为数值稳定的计算。您的推导不能以总体最小二乘法或正交回归的特定公式作为起点；相反，必须从正交距离的定义和归一化约束开始，并且只使用广为人知的线性代数工具，如特征值问题或奇异值分解 (SVD)。您的最终算法必须：\n- 以齐次形式 $a x + b y + c = 0$ 表示拟合的直线，并满足 $a^{2} + b^{2} = 1$。\n- 强制使用符号约定 $a \\ge 0$，如果 $a = 0$ 则 $b \\ge 0$，以确保唯一性。\n- 确保拟合的直线通过数据的质心 $(\\bar{x}, \\bar{y})$，该质心在归一化约束下最小化正交残差。\n- 为每个数据集计算均方根 (RMS) 正交距离 $r = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (a x_{i} + b y_{i} + c)^{2}}$，其中 $n$ 是点的数量。\n\n测试套件。为以下数据集实现您的算法。每个数据集都是一个有序对 $(x, y)$ 的列表，其中每个数字都以十进制形式显示：\n- 情况 $1$ (带扰动的一般斜率直线): $[(0.02, 1.12), (0.51, 1.93), (0.98, 2.92), (1.48, 4.06), (2.02, 5.01), (2.49, 6.07)]$。\n- 情况 $2$ (近乎垂直的直线): $[(2.95, -1.00), (3.02, 0.50), (3.05, 2.00), (2.97, 3.50), (3.01, 5.00)]$。\n- 情况 $3$ (原点附近的负斜率对称线): $[(-4.00, 2.10), (-2.00, 1.02), (0.00, -0.02), (2.00, -1.05), (4.00, -1.95)]$。\n- 情况 $4$ (两点最小情况): $[(1.00, 1.00), (3.01, 1.99)]$。\n\n数值与输出要求。\n- 使用齐次直线参数 $(a, b, c)$，满足 $a^{2} + b^{2} = 1$ 和所述的符号约定。\n- 对每个数据集，计算并输出四元组 $[a, b, c, r]$，其中 $r$ 是如上定义的 RMS 正交距离。\n- 将最终输出中报告的每个实数四舍五入到恰好 $6$ 位小数。\n- 最终程序输出必须是包含四个情况结果的单行列表，格式必须完全如此（不需要空格，但允许）：一个由逗号分隔的四个四元组列表，并用方括号括起来，例如 $[[a_{1},b_{1},c_{1},r_{1}],[a_{2},b_{2},c_{2},r_{2}],[a_{3},b_{3},c_{3},r_{3}],[a_{4},b_{4},c_{4},r_{4}]]$，其中每个 $a_{k}, b_{k}, c_{k}, r_{k}$ 都四舍五入到 $6$ 位小数。\n- 不涉及角度；不需要物理单位。\n- 不得有外部输入；程序必须能直接运行并打印所需的单行输出。\n\n您的程序应生成一行输出，其中包含一个用方括号括起来的、以逗号分隔的结果列表，每个情况由其自己的列表 $[a, b, c, r]$ 表示，如上所述。",
            "solution": "该问题要求制定并实现一种总体最小二乘法 (TLS)，用于将一条直线拟合到一组数据点 $(x_i, y_i)$，其中两个坐标都存在误差。推导必须从第一性原理出发。\n\n设直线以齐次形式 $a x + b y + c = 0$ 表示。参数 $(a,b)$ 被归一化，使得 $a^2 + b^2 = 1$。在此归一化条件下，从一个点 $(x_i, y_i)$ 到该直线的正交距离为 $d_i = |a x_i + b y_i + c|$。TLS 的目标是找到参数 $a, b, c$，以最小化 $n$ 个数据点的平方正交距离之和：\n$$ \\text{最小化 } S(a, b, c) = \\sum_{i=1}^{n} (a x_i + b y_i + c)^2 \\quad \\text{约束条件为} \\quad g(a, b) = a^2 + b^2 - 1 = 0 $$\n\n为了找到最优参数，我们可以使用微积分。最小值的必要条件是 $S$ 对 $c$ 的偏导数必须为零：\n$$ \\frac{\\partial S}{\\partial c} = \\sum_{i=1}^{n} 2(a x_i + b y_i + c) \\cdot 1 = 0 $$\n$$ \\implies a \\sum_{i=1}^{n} x_i + b \\sum_{i=1}^{n} y_i + \\sum_{i=1}^{n} c = 0 $$\n$$ \\implies a \\left(\\frac{1}{n}\\sum_{i=1}^{n} x_i\\right) + b \\left(\\frac{1}{n}\\sum_{i=1}^{n} y_i\\right) + c = 0 $$\n令 $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$ 和 $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n} y_i$ 为数据点质心的坐标。该条件变为：\n$$ a \\bar{x} + b \\bar{y} + c = 0 $$\n这表明最优直线必须穿过数据的质心 $(\\bar{x}, \\bar{y})$。这使我们能够用 $a$ 和 $b$ 表示 $c$：\n$$ c = -(a \\bar{x} + b \\bar{y}) $$\n将这个 $c$ 的表达式代入目标函数 $S$，我们简化了问题：\n$$ S(a, b) = \\sum_{i=1}^{n} (a x_i + b y_i - (a \\bar{x} + b \\bar{y}))^2 = \\sum_{i=1}^{n} (a(x_i - \\bar{x}) + b(y_i - \\bar{y}))^2 $$\n我们定义中心化坐标 $x'_i = x_i - \\bar{x}$ 和 $y'_i = y_i - \\bar{y}$。最小化问题现在简化为寻找参数 $a$ 和 $b$ 来：\n$$ \\text{最小化 } S(a, b) = \\sum_{i=1}^{n} (a x'_i + b y'_i)^2 \\quad \\text{约束条件为} \\quad a^2 + b^2 = 1 $$\n这个问题可以用线性代数优雅地解决。我们定义一个参数向量 $\\mathbf{u} = \\begin{pmatrix} a \\\\ b \\end{pmatrix}$，因此约束条件为 $\\mathbf{u}^T \\mathbf{u} = 1$。我们还定义一个包含中心化数据点的 $n \\times 2$ 矩阵 $\\mathbf{A}$：\n$$ \\mathbf{A} = \\begin{pmatrix} x'_1 & y'_1 \\\\ x'_2 & y'_2 \\\\ \\vdots & \\vdots \\\\ x'_n & y'_n \\end{pmatrix} $$\n平方和可以写成向量 $\\mathbf{A}\\mathbf{u}$ 的欧几里得范数的平方：\n$$ S = \\| \\mathbf{A}\\mathbf{u} \\|_2^2 = (\\mathbf{A}\\mathbf{u})^T (\\mathbf{A}\\mathbf{u}) = \\mathbf{u}^T \\mathbf{A}^T \\mathbf{A} \\mathbf{u} $$\n问题现在是在约束 $\\mathbf{u}$ 是单位向量的条件下，最小化二次型 $\\mathbf{u}^T (\\mathbf{A}^T \\mathbf{A}) \\mathbf{u}$。矩阵 $\\mathbf{C} = \\mathbf{A}^T \\mathbf{A}$ 是中心化数据的 $2 \\times 2$ 散布矩阵：\n$$ \\mathbf{C} = \\begin{pmatrix} \\sum (x'_i)^2 & \\sum x'_i y'_i \\\\ \\sum x'_i y'_i & \\sum (y'_i)^2 \\end{pmatrix} $$\n这个公式是一个经典的瑞利商问题 (Rayleigh quotient problem)。$\\mathbf{u}^T \\mathbf{C} \\mathbf{u}$ 的最小值是对称矩阵 $\\mathbf{C}$ 的最小特征值，而实现这个最小值的向量 $\\mathbf{u}$ 是相应的特征向量。\n\n一种数值上鲁棒且计算稳定的方法是通过对矩阵 $\\mathbf{A}$ 进行奇异值分解 (SVD)。设 $\\mathbf{A}$ 的 SVD 为 $\\mathbf{A} = \\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^T$，其中 $\\mathbf{U}$ 是一个 $n \\times 2$ 的列正交矩阵，$\\mathbf{\\Sigma}$ 是一个包含奇异值 $\\sigma_1 \\ge \\sigma_2 \\ge 0$ 的 $2 \\times 2$ 对角矩阵，$\\mathbf{V}$ 是一个 $2 \\times 2$ 的正交矩阵，其列 $\\mathbf{v}_1, \\mathbf{v}_2$ 是右奇异向量。\n\n需要最小化的量是 $\\|\\mathbf{A}\\mathbf{u}\\|_2^2$。由于 $\\mathbf{V}$ 是正交的，它的列构成了 $\\mathbb{R}^2$ 的一个标准正交基。任何单位向量 $\\mathbf{u}$ 都可以写成线性组合 $\\mathbf{u} = c_1 \\mathbf{v}_1 + c_2 \\mathbf{v}_2$，其中 $c_1^2 + c_2^2 = 1$。乘积 $\\mathbf{A}\\mathbf{v}_j = \\sigma_j \\mathbf{u}_j$，其中 $\\mathbf{u}_j$ 是 $\\mathbf{U}$ 的第 $j$ 列。\n$$ \\|\\mathbf{A}\\mathbf{u}\\|_2^2 = \\| \\mathbf{A} (c_1 \\mathbf{v}_1 + c_2 \\mathbf{v}_2) \\|_2^2 = \\| c_1 \\mathbf{A}\\mathbf{v}_1 + c_2 \\mathbf{A}\\mathbf{v}_2 \\|_2^2 = \\| c_1 \\sigma_1 \\mathbf{u}_1 + c_2 \\sigma_2 \\mathbf{u}_2 \\|_2^2 $$\n由于 $\\mathbf{u}_1$ 和 $\\mathbf{u}_2$ 是标准正交的，这可以简化为：\n$$ \\|\\mathbf{A}\\mathbf{u}\\|_2^2 = c_1^2 \\sigma_1^2 + c_2^2 \\sigma_2^2 $$\n为了在 $c_1^2 + c_2^2 = 1$ 和 $\\sigma_1 \\ge \\sigma_2$ 的条件下最小化这个表达式，我们必须选择 $c_1 = 0$ 和 $c_2 = 1$。这使得 $\\mathbf{u} = \\mathbf{v}_2$，即对应于最小奇异值 $\\sigma_2$ 的右奇异向量。平方和的最小值为 $S_{min} = \\sigma_2^2$。\n\n因此，算法如下：\n1.  计算 $n$ 个数据点 $(x_i, y_i)$ 的质心 $(\\bar{x}, \\bar{y})$。\n2.  构建行向量为 $(x_i - \\bar{x}, y_i - \\bar{y})$ 的中心化数据矩阵 $\\mathbf{A}$。\n3.  计算 $\\mathbf{A}$ 的 SVD，$\\mathbf{A} = \\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V}^T$。SVD 产生奇异值 $\\sigma_1 \\ge \\sigma_2$ 和矩阵 $\\mathbf{V}^T$。\n4.  最优参数向量 $\\begin{pmatrix} a \\\\ b \\end{pmatrix}$ 是对应于 $\\sigma_2$ 的右奇异向量。该向量是 $\\mathbf{V}$ 的第二列，即 $\\mathbf{V}^T$ 的第二行。\n5.  设 $(a, b)$ 为此向量。为确保唯一性，应用符号约定：如果 $a  0$，或者如果 $a=0$ 且 $b  0$，则将 $a$ 和 $b$ 都取反。\n6.  计算 $c = - (a \\bar{x} + b \\bar{y})$。\n7.  平方正交距离之和为 $S_{min} = \\sigma_2^2$。均方根 (RMS) 正交距离为 $r = \\sqrt{S_{min}/n} = \\sigma_2 / \\sqrt{n}$。\n8.  解是四元组 $[a, b, c, r]$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the total least squares line fitting problem for a suite of test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (general sloped line with perturbations)\n        [(0.02, 1.12), (0.51, 1.93), (0.98, 2.92), (1.48, 4.06), (2.02, 5.01), (2.49, 6.07)],\n        # Case 2 (nearly vertical line)\n        [(2.95, -1.00), (3.02, 0.50), (3.05, 2.00), (2.97, 3.50), (3.01, 5.00)],\n        # Case 3 (negative slope near the origin with symmetry)\n        [(-4.00, 2.10), (-2.00, 1.02), (0.00, -0.02), (2.00, -1.05), (4.00, -1.95)],\n        # Case 4 (two-point minimal case)\n        [(1.00, 1.00), (3.01, 1.99)],\n    ]\n\n    def fit_tls_line(points):\n        \"\"\"\n        Fits a line using Total Least Squares based on SVD.\n        \n        Args:\n            points: A list of (x, y) tuples.\n            \n        Returns:\n            A list [a, b, c, r] representing the line a*x + b*y + c = 0\n            and the RMS orthogonal distance r.\n        \"\"\"\n        data = np.array(points)\n        n = data.shape[0]\n\n        # 1. Compute the centroid of the data\n        centroid = np.mean(data, axis=0)\n        x_bar, y_bar = centroid\n\n        # 2. Form the centered data matrix A\n        centered_data = data - centroid\n\n        # 3. Compute the SVD of the centered data matrix\n        # U: Unitary matrix (left singular vectors)\n        # s: Singular values (sorted in descending order)\n        # Vt: Unitary matrix (right singular vectors, transposed)\n        _, s, Vt = np.linalg.svd(centered_data)\n\n        # 4. The parameters (a, b) are the components of the right singular vector\n        # corresponding to the smallest singular value. This is the last row of Vt.\n        a, b = Vt[1]\n\n        # 5. Apply the sign convention for uniqueness: a >= 0, and if a = 0, then b >= 0.\n        # We use a small tolerance for floating point comparisons.\n        if a  0.0 or (np.isclose(a, 0.0) and b  0.0):\n            a = -a\n            b = -b\n\n        # 6. Compute c using the fact that the line passes through the centroid\n        c = -(a * x_bar + b * y_bar)\n\n        # 7. Compute the RMS orthogonal distance\n        # The smallest singular value is s[1]. The sum of squared distances is s[1]**2.\n        sigma_2 = s[1]\n        r = sigma_2 / np.sqrt(n)\n        \n        return [a, b, c, r]\n\n    results = []\n    for case_data in test_cases:\n        result_quadruple = fit_tls_line(case_data)\n        results.append(result_quadruple)\n    \n    # Format the final output string as specified\n    formatted_results = []\n    for res in results:\n        # Format each number to 6 decimal places.\n        formatted_quad = [f\"{val:.6f}\" for val in res]\n        formatted_results.append(f\"[{','.join(formatted_quad)}]\")\n    \n    final_output = f\"[{','.join(formatted_results)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "总体最小二乘法（TLS）与普通最小二乘法（OLS）等其他回归方法有何关联？本练习将探讨 TLS 的统计学解释，揭示其与主成分分析（PCA）的内在联系。通过使用样本协方差矩阵推导 TLS 解，您将理解 TLS 实质上是在寻找数据方差最大的主方向，从而在所有变量都含有噪声时提供更稳健的拟合。",
            "id": "3173554",
            "problem": "一个实验室记录了两个物理量的成对测量值 $\\{(X_{i}, Y_{i})\\}_{i=1}^{n}$，这两个物理量共同的变化近似呈线性关系，但两者的测量都带有均值为零的加性噪声。假设潜在信号是线性的，且 $X$ 和 $Y$ 中的测量噪声与信号以及彼此之间相互独立，方差有限。研究人员希望通过这些点云拟合一条直线。考虑了两种建模选择：普通最小二乘法（OLS）和总体最小二乘法（TLS）。\n\n- 在普通最小二乘法（OLS）中，模型 $Y = \\beta_{0} + \\beta_{1} X + \\varepsilon$ 假设 $X$ 的测量没有误差，并最小化 $Y$ 的垂直残差。\n- 在总体最小二乘法（TLS）中（也称为变量含误差回归），选择直线以最小化从点到直线的正交距离的平方和，这承认了 $X$ 和 $Y$ 都存在测量噪声。\n\n给定从 $n$ 个观测值计算出的观测数据的中心化样本协方差矩阵，\n$$\n\\mathbf{S} \\;=\\; \\begin{pmatrix}\n3.2  2.4 \\\\\n2.4  5.0\n\\end{pmatrix},\n$$\n其中 $\\mathbf{S}$ 的元素 $s_{xx}$、$s_{xy}$ 和 $s_{yy}$ 分别对应于 $X$ 和 $Y$ 的样本协方差。\n\n任务：\n1. 从 OLS 目标（最小化垂直残差平方和）的定义和一階最优性条件出发，识别关于误差的结构性假设，并用样本矩推导出 OLS 斜率，解释为什么当 $X$ 含有噪声时，OLS 直线可能与最小化正交距离的直线不同。\n2. 从 TLS 目标（最小化正交距离平方和）的定义以及直线方向向量范数为单位长度的要求出发，推导出 TLS 方向可被刻画为样本协方差矩阵 $\\mathbf{S}$ 的一个特征向量。然后将 TLS 斜率表示为该特征向量分量的比率，并用 $\\mathbf{S}$ 的元素及其最大特征值来表达。\n3. 使用给定的 $\\mathbf{S}$，数值计算 TLS 斜率。\n\n将您的 TLS 斜率数值答案四舍五入到四位有效数字。将斜率表示为一个无单位的实数，并在最终答案中只报告 TLS 斜率。",
            "solution": "我们考虑对一个 $X$ 和 $Y$ 都带有测量噪声的点云进行直线拟合。令中心化数据矩阵为 $\\mathbf{Z} \\in \\mathbb{R}^{n \\times 2}$，其中每一行是 $\\mathbf{z}_{i} = (x_{i} - \\bar{x}, y_{i} - \\bar{y})$，样本协方差矩阵为\n$$\n\\mathbf{S} \\;=\\; \\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{z}_{i} \\mathbf{z}_{i}^{\\top}\n\\;=\\;\n\\begin{pmatrix}\ns_{xx}  s_{xy} \\\\\ns_{xy}  s_{yy}\n\\end{pmatrix}.\n$$\n\n第1部分（OLS）：普通最小二乘法（OLS）假设模型为 $Y = \\beta_{0} + \\beta_{1} X + \\varepsilon$，其中 $X$ 被视为非随机变量或无误差测量，残差 $\\varepsilon$ 仅代表 $Y$ 中的噪声。OLS 的目标是\n$$\n\\min_{\\beta_{0}, \\beta_{1}} \\sum_{i=1}^{n} \\left(y_{i} - \\beta_{0} - \\beta_{1} x_{i}\\right)^{2}.\n$$\n对 $\\beta_{0}$ 和 $\\beta_{1}$ 求偏导数并令其为零，得到正规方程。中心化后（因此截距为 $\\beta_{0} = \\bar{y} - \\beta_{1} \\bar{x}$），$\\beta_{1}$ 的一阶条件变为\n$$\n\\sum_{i=1}^{n} (x_{i} - \\bar{x})(y_{i} - \\bar{y}) \\;=\\; \\beta_{1} \\sum_{i=1}^{n} (x_{i} - \\bar{x})^{2}.\n$$\n两边同除以 $n$ 得到\n$$\ns_{xy} \\;=\\; \\beta_{1} s_{xx} \\quad \\Rightarrow \\quad \\beta_{1}^{\\mathrm{OLS}} \\;=\\; \\frac{s_{xy}}{s_{xx}}.\n$$\n这个公式假定 $X$ 的测量没有误差，因此只有 $Y$ 中的垂直残差受到惩罚。当 $X$ 含有噪声时，仅最小化垂直残差会使斜率产生偏差，倾向于低估数据云的真实方向，因此 OLS 直线可能与最小化正交距离的直线有显著差异。\n\n第2部分（TLS）：总体最小二乘法（TLS），也称为变量含误差法，寻求一条能最小化点到直线正交距离平方和的直线，并承认两个坐标都带有噪声。用单位方向向量 $\\mathbf{v} = (v_{x}, v_{y})^{\\top}$（其中 $\\|\\mathbf{v}\\| = 1$）来参数化一条穿过数据质心 $(\\bar{x}, \\bar{y})$ 的直线。对于一个中心化点 $\\mathbf{z}_{i}$，其正交残差是与 $\\mathbf{v}$ 正交的分量：\n$$\n\\mathbf{r}_{i} \\;=\\; \\mathbf{z}_{i} - (\\mathbf{z}_{i}^{\\top}\\mathbf{v})\\,\\mathbf{v},\n\\quad\n\\|\\mathbf{r}_{i}\\|^{2} \\;=\\; \\|\\mathbf{z}_{i}\\|^{2} - (\\mathbf{z}_{i}^{\\top}\\mathbf{v})^{2}.\n$$\nTLS 的目标是\n$$\n\\min_{\\mathbf{v} \\in \\mathbb{R}^{2}} \\sum_{i=1}^{n} \\|\\mathbf{r}_{i}\\|^{2}\n\\quad \\text{subject to} \\quad \\|\\mathbf{v}\\| = 1.\n$$\n由于 $\\sum_{i=1}^{n} \\|\\mathbf{z}_{i}\\|^{2}$ 相对于 $\\mathbf{v}$ 是一个常数，最小化正交距离的平方和等价于最大化沿 $\\mathbf{v}$ 方向的投影方差：\n$$\n\\max_{\\|\\mathbf{v}\\| = 1} \\sum_{i=1}^{n} (\\mathbf{z}_{i}^{\\top}\\mathbf{v})^{2}\n\\;=\\;\n\\max_{\\|\\mathbf{v}\\| = 1} \\mathbf{v}^{\\top} \\left( \\sum_{i=1}^{n} \\mathbf{z}_{i}\\mathbf{z}_{i}^{\\top} \\right) \\mathbf{v}\n\\;=\\;\n\\max_{\\|\\mathbf{v}\\| = 1} \\mathbf{v}^{\\top} (n \\mathbf{S}) \\mathbf{v}.\n$$\n这是一个瑞利商最大化问题，其最大化向量 $\\mathbf{v}$ 是 $\\mathbf{S}$ 对应于其最大特征值 $\\lambda_{1}$ 的特征向量。因此，TLS 方向由以下公式刻画：\n$$\n\\mathbf{S}\\,\\mathbf{v} \\;=\\; \\lambda_{1}\\,\\mathbf{v}, \\quad \\|\\mathbf{v}\\| = 1,\n$$\nTLS 斜率 $m_{\\mathrm{TLS}}$ 是 $\\mathbf{v}$ 分量的比值：\n$$\nm_{\\mathrm{TLS}} \\;=\\; \\frac{v_{y}}{v_{x}}.\n$$\n根据特征向量方程，\n$$\n(s_{xx} - \\lambda_{1}) v_{x} + s_{xy} v_{y} \\;=\\; 0\n\\quad \\Rightarrow \\quad\n\\frac{v_{y}}{v_{x}} \\;=\\; \\frac{\\lambda_{1} - s_{xx}}{s_{xy}}.\n$$\n等价地，\n$$\n\\frac{v_{y}}{v_{x}} \\;=\\; \\frac{s_{xy}}{\\lambda_{1} - s_{yy}},\n$$\n并且对于满足 $\\mathbf{S}$ 特征方程的 $\\lambda_{1}$，这两个表达式是一致的。\n\n第3部分（TLS斜率的数值计算）：对于\n$$\n\\mathbf{S} \\;=\\; \\begin{pmatrix}\n3.2  2.4 \\\\\n2.4  5.0\n\\end{pmatrix},\n$$\n特征值是以下方程的根：\n$$\n\\lambda^{2} - (s_{xx} + s_{yy}) \\lambda + (s_{xx}s_{yy} - s_{xy}^{2}) \\;=\\; 0.\n$$\n计算迹和行列式：\n$$\n\\operatorname{tr}(\\mathbf{S}) \\;=\\; 3.2 + 5.0 \\;=\\; 8.2,\n\\quad\n\\det(\\mathbf{S}) \\;=\\; 3.2 \\cdot 5.0 - 2.4^{2} \\;=\\; 16.0 - 5.76 \\;=\\; 10.24.\n$$\n因此，\n$$\n\\lambda_{1,2} \\;=\\; \\frac{ \\operatorname{tr}(\\mathbf{S}) \\pm \\sqrt{ \\operatorname{tr}(\\mathbf{S})^{2} - 4 \\det(\\mathbf{S}) } }{2}\n\\;=\\;\n\\frac{ 8.2 \\pm \\sqrt{ 67.24 - 40.96 } }{2}\n\\;=\\;\n\\frac{ 8.2 \\pm \\sqrt{ 26.28 } }{2}.\n$$\n较大的特征值是\n$$\n\\lambda_{1} \\;=\\; \\frac{ 8.2 + \\sqrt{26.28} }{2}.\n$$\n在斜率公式中使用此 $\\lambda_{1}$，\n$$\nm_{\\mathrm{TLS}} \\;=\\; \\frac{ \\lambda_{1} - s_{xx} }{ s_{xy} }\n\\;=\\;\n\\frac{ \\frac{ 8.2 + \\sqrt{26.28} }{2} - 3.2 }{ 2.4 }\n\\;=\\;\n\\frac{ 4.1 + \\frac{1}{2}\\sqrt{26.28} - 3.2 }{2.4}\n\\;=\\;\n\\frac{ 0.9 + \\frac{1}{2}\\sqrt{26.28} }{2.4}.\n$$\n数值上，$\\sqrt{26.28} \\approx 5.1265$，因此\n$$\nm_{\\mathrm{TLS}} \\;\\approx\\; \\frac{0.9 + 2.56325}{2.4} \\;=\\; \\frac{3.46325}{2.4} \\;\\approx\\; 1.443.\n$$\n四舍五入到四位有效数字，TLS 斜率为 $1.443$。\n\n作为对比，来自相同数据的 OLS 斜率将是\n$$\n\\beta_{1}^{\\mathrm{OLS}} \\;=\\; \\frac{s_{xy}}{s_{xx}} \\;=\\; \\frac{2.4}{3.2} \\;=\\; 0.75,\n$$\n这个值明显更小，因为 OLS 忽略了 $X$ 中的噪声，仅最小化垂直偏差。TLS 通过最小化正交距离，与数据云的主方向对齐，并在此处产生一个更陡峭的斜率。\n\n要求的最终答案是 TLS 斜率。",
            "answer": "$$\\boxed{1.443}$$"
        },
        {
            "introduction": "虽然直接使用 SVD 在概念上很清晰，但对于大规模或病态问题，我们需要一种数值上更稳健的方法。这项高级实践要求您实现一个基于 Golub-Kahan 双对角化的先进 TLS 求解器，该方法可以避免显式构造如 $D^T D$ 这样可能病态的矩阵乘积。本练习将加深您对数值稳定性以及高效线性代数算法设计的实践理解。",
            "id": "3599775",
            "problem": "考虑一个超定线性系统的总最小二乘（Total Least Squares, TLS）问题。给定实矩阵 $A \\in \\mathbb{R}^{m \\times n}$（其中 $m \\ge n$）和右端向量 $b \\in \\mathbb{R}^{m}$，定义增广数据矩阵 $D = [A\\ b] \\in \\mathbb{R}^{m \\times (n+1)}$。TLS 估计旨在寻找一个向量 $x \\in \\mathbb{R}^{n}$以及扰动 $\\Delta A \\in \\mathbb{R}^{m \\times n}$、$\\Delta b \\in \\mathbb{R}^{m}$，在满足一致性约束的条件下，最小化 Frobenius 范数，即\n$$\n\\min_{\\Delta A, \\Delta b, x} \\ \\|[\\Delta A\\ \\Delta b]\\|_F \\quad \\text{subject to} \\quad (A + \\Delta A)x = b + \\Delta b.\n$$\n您必须设计一个数值稳定的算法来计算 $x$ 的 TLS 估计，该算法需遵循以下约束：\n\n- 该方法必须基于对 $D = [A\\ b]$ 进行 Golub–Kahan 双对角化（通过正交 Householder 变换），然后对得到的双对角矩阵进行部分奇异值分解（Singular Value Decomposition, SVD）。在任何时候都不能构造 $D^T D$。\n- 推导必须从核心定义和事实出发：TLS 的定义、奇异值分解的定义，以及正交变换和 Householder 反射的性质。不得假设任何其他中间公式。\n- 您必须从第一性原理出发，论证您的算法在浮点运算中为何是后向稳定的。\n\n您的程序必须实现此算法，并使用双精度算术在以下测试集上进行评估：\n\n- 测试用例 1（接近一致但带有小扰动的数据）：\n  - 维度：$m = 8$， $n = 3$。\n  - 随机种子：所有随机抽取均使用 $0$。\n  - 生成 $A_{\\text{true}} \\in \\mathbb{R}^{8 \\times 3}$ 和 $x_{\\star} \\in \\mathbb{R}^3$，其元素为独立的标准正态分布。\n  - 设置 $b_{\\text{true}} = A_{\\text{true}} x_{\\star}$。\n  - 构造 $A = A_{\\text{true}} + \\eta_A$ 和 $b = b_{\\text{true}} + \\eta_b$，其中 $\\eta_A$ 和 $\\eta_b$ 的元素是独立的标准正态分布，并乘以 $10^{-3}$。\n  - 根据 $(A,b)$ 计算 TLS 估计 $x_{\\text{TLS}}$。\n  - 输出 $r_1 = \\|x_{\\text{TLS}} - x_{\\star}\\|_2 / \\|x_{\\star}\\|_2$，结果为浮点数。\n\n- 测试用例 2（TLS 解的左正交不变性）：\n  - 使用测试用例 1 中的 $(A,b)$。\n  - 生成一个正交矩阵 $Q \\in \\mathbb{R}^{8 \\times 8}$，方法是对一个 $8 \\times 8$ 的标准正态矩阵进行 QR 分解（其中 $Q$ 是正交的，$R$ 是上三角的），随机种子同样为 $0$。\n  - 根据 $D = [A\\ b]$ 计算 $x_{\\text{TLS}}^{(D)}$，根据 $QD = [QA\\ Qb]$ 计算 $x_{\\text{TLS}}^{(QD)}$。\n  - 输出 $r_2 = \\|x_{\\text{TLS}}^{(D)} - x_{\\text{TLS}}^{(QD)}\\|_2$，结果为浮点数。\n\n- 测试用例 3（精确一致的数据）：\n  - 维度：$m = 6$， $n = 3$。\n  - 随机种子：此测试中所有随机抽取均使用 $123$。\n  - 生成 $A \\in \\mathbb{R}^{6 \\times 3}$ 和 $x_{\\star} \\in \\mathbb{R}^3$，其元素为独立的标准正态分布。\n  - 设置 $b = A x_{\\star}$（无扰动）。\n  - 根据 $(A,b)$ 计算 TLS 估计 $x_{\\text{TLS}}$。\n  - 输出 $r_3 = \\|x_{\\text{TLS}} - x_{\\star}\\|_2 / \\|x_{\\star}\\|_2$，结果为浮点数。\n\n- 测试用例 4（不构造 $D^T D$ 的奇异三元组一致性检查）：\n  - 使用测试用例 1 中的 $D = [A\\ b]$。\n  - 令 $v_{\\min} \\in \\mathbb{R}^{n+1}$ 是通过您的双对角化加双对角矩阵 SVD 流程得到的 $D$ 的最后一个右奇异向量，令 $\\sigma_{\\min}$ 是对应的 $D$ 的最小奇异值。\n  - 输出 $r_4 = \\left|\\|D v_{\\min}\\|_2 - \\sigma_{\\min}\\right|$，结果为浮点数。\n\n最终输出格式：\n\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表，顺序为 $[r_1,r_2,r_3,r_4]$。例如，打印的行必须类似于 $[0.00123,4.56e-07,0.0,1.2e-15]$，无任何附加文本。\n\n所有随机抽取必须使用指定的种子。不涉及角度。没有物理单位。所有输出均为实值浮点标量。您的实现必须是自包含的，且不应需要任何用户输入、外部文件或网络访问。",
            "solution": "我们从核心定义开始。总最小二乘（TLS）问题旨在寻找扰动 $\\Delta A \\in \\mathbb{R}^{m \\times n}$、$\\Delta b \\in \\mathbb{R}^{m}$ 和一个向量 $x \\in \\mathbb{R}^{n}$，它们在满足 $(A + \\Delta A)x = b + \\Delta b$ 的条件下最小化 Frobenius 范数 $\\|[\\Delta A\\ \\Delta b]\\|_F$。令 $D = [A\\ b] \\in \\mathbb{R}^{m \\times (n+1)}$。如果没有扰动，一致性约束可以表示为 $D v = 0$，其中 $v = \\begin{bmatrix} x \\\\ -1 \\end{bmatrix}$。在存在扰动的情况下，问题可以重塑为寻找一个单位向量 $v \\in \\mathbb{R}^{n+1}$ 来最小化 $\\|D v\\|_2$，然后在 $v$ 的最后一个分量非零的情况下通过去齐次化提取 $x$。这根植于以下关于奇异值分解的标准事实。\n\n根据奇异值分解（SVD）的定义，任何实矩阵 $D \\in \\mathbb{R}^{m \\times p}$（其中 $p = n+1$）都允许分解为 $D = U \\Sigma V^T$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{p \\times p}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times p}$ 是对角矩阵，其对角线上的非负元素为 $\\sigma_1 \\ge \\cdots \\ge \\sigma_p \\ge 0$（如有必要，用零填充）。奇异值的变分特征表明\n$$\n\\sigma_p = \\min_{\\|v\\|_2=1} \\|D v\\|_2,\n$$\n其最小化向量 $v$ 等于最后一个右奇异向量 $v_p$（即 $V$ 的最后一列）。因此，如果我们找到对应于 $\\sigma_{\\min} = \\sigma_p$ 的 $v_{\\min} = v_p$，则可以通过将 $v_{\\min}$ 写成 $v_{\\min} = \\alpha \\begin{bmatrix} x \\\\ -1 \\end{bmatrix}$（对于某个非零标量 $\\alpha$）来获得 TLS 估计，这在 $v_{n+1} \\ne 0$ 的情况下得出 $x = - v_{1:n} / v_{n+1}$。\n\n一种数值稳定的计算 $D$ 的最后一个右奇异向量的方法是避免构造 $D^T D$，因为显式构造 $D^T D$ 会使条件数平方，并且已知是数值不稳定的。相反，我们使用 Golub–Kahan 双对角化，通过正交 Householder 变换将 $D$ 简化为上双对角形式，然后计算所得双对角矩阵的 SVD。我们概述算法步骤如下。\n\n1. Householder 双对角化。对于 $D \\in \\mathbb{R}^{m \\times p}$（其中 $p = n+1$），我们从左侧和右侧构造正交 Householder 反射，将 $D$ 简化为双对角形式。具体来说，我们构建一系列作用于行的左反射 $P_j = I - 2 u_j u_j^T$ 和作用于列的右反射 $Q_j = I - 2 w_j w_j^T$，选择单位向量 $u_j$ 和 $w_j$ 使得\n$$\nB = P_k \\cdots P_1 \\, D \\, Q_1 \\cdots Q_k\n$$\n是上双对角矩阵（即非零元素仅出现在主对角线和第一超对角线上），其中 $k = \\min(m,p)$。累积右反射矩阵得到一个正交矩阵 $V = Q_1 \\cdots Q_k \\in \\mathbb{R}^{p \\times p}$。根据 Householder 反射的正交性，我们有 $D = U B V^T$，其中 $U = P_1^T \\cdots P_k^T$ 是正交的。\n\n2. 双对角矩阵的 SVD。计算上双对角矩阵 $B$ 的瘦 SVD，\n$$\nB = \\widehat{U} \\, \\Sigma \\, \\widehat{V}^T,\n$$\n其中 $\\widehat{U} \\in \\mathbb{R}^{m \\times p}$ 具有标准正交列，$\\widehat{V} \\in \\mathbb{R}^{p \\times p}$ 是正交的，$\\Sigma = \\operatorname{diag}(\\sigma_1,\\ldots,\\sigma_p)$ 且 $\\sigma_1 \\ge \\cdots \\ge \\sigma_p \\ge 0$。计算双对角矩阵 SVD 的经典算法（例如，隐式位移 QR 迭代或分治法）是后向稳定的。\n\n3. 组装右奇异向量。由 $D = U B V^T$ 和 $B = \\widehat{U} \\Sigma \\widehat{V}^T$ 可知，$D$ 的一个 SVD 由下式给出\n$$\nD = (U \\widehat{U}) \\, \\Sigma \\, (V \\widehat{V})^T.\n$$\n因此，$D$ 的最后一个右奇异向量是 $v_{\\min} = V \\widehat{v}_{\\min}$，其中 $\\widehat{v}_{\\min}$ 是 $\\widehat{V}$ 的最后一列。由于 $V$ 是正交的，如果 $\\widehat{v}_{\\min}$ 是单位范数，则 $v_{\\min}$ 也是单位范数。\n\n4. 提取 TLS 估计。若 $v_{\\min}$ 的最后一个分量非零，则可将 $v_{\\min}$ 写为 $v_{\\min} = \\alpha \\begin{bmatrix} x \\\\ -1 \\end{bmatrix}$（对于某个非零 $\\alpha$）。去齐次化得到 TLS 估计\n$$\nx_{\\text{TLS}} = -\\frac{v_{1:n}}{v_{n+1}}.\n$$\n如果 $v_{n+1}$ 的绝对值极小，则 TLS 问题是不适定的（最小化方向几乎完全位于列空间坐标中），且去齐次化在数值上不稳定；这对应于 TLS 可解性的一个已知边界。\n\n后向稳定性论证。Householder 反射是正交变换，其在浮点运算中的应用是已知的后向稳定：每次应用都可以解释为对一个轻微扰动的矩阵进行精确应用，扰动大小由机器精度与矩阵范数的乘积的一个小倍数界定。具体来说，如果 $\\mathrm{fl}(P^T D)$ 表示将 Householder 反射 $P$ 应用于 $D$ 的计算结果，则存在一个扰动 $\\Delta$，其满足 $\\|\\Delta\\|_2 = \\mathcal{O}(\\epsilon) \\|D\\|_2$，使得 $\\mathrm{fl}(P^T D) = P^T (D + \\Delta)$，其中 $\\epsilon$ 是单位舍入误差。组合有限次这样的操作保持了 $\\|\\Delta D_{\\text{bidiag}}\\|_2 \\le \\mathrm{poly}(m,p) \\, \\epsilon \\, \\|D\\|_2$ 形式的后向误差界。当使用标准方法（如隐式位移 QR 迭代或分治法）计算时，双对角矩阵的 SVD 也是后向稳定的：计算出的奇异三元组对于一个邻近的双对角矩阵 $\\widehat{B} = B + \\Delta B$ 是精确的，其中 $\\|\\Delta B\\|_2 = \\mathcal{O}(\\epsilon) \\|B\\|_2$。由于左乘和右乘正交矩阵是保范的，组装出的右奇异向量 $v_{\\min}$ 是一个邻近矩阵 $D + \\Delta D$ 的精确的最后一个右奇异向量，其中 $\\|\\Delta D\\|_2 \\le \\mathrm{poly}(m,p) \\, \\epsilon \\, \\|D\\|_2$。只要 $|v_{n+1}|$ 有远离零的下界，最后的去齐次化步骤 $x_{\\text{TLS}} = -v_{1:n}/v_{n+1}$ 就是一个连续映射；因此，只要 TLS 解是适定的，整个算法就是后向稳定的。这种方法刻意避免了构造 $D^T D$，因为这会使条件数平方，并通常会破坏后向稳定性。\n\n程序算法设计。我们实现：\n\n- 一个针对给定向量 $z$ 的 Householder 向量构造器，它返回一个单位向量 $u$，使得 $(I - 2 u u^T) z$ 是第一个标准基向量的倍数。我们从左侧应用这些变换以消除对角线下方的元素，从右侧应用以消除超对角线上方的元素。\n- 将右正交因子 $V$ 累积为右 Householder 反射的乘积。我们不需要累积左正交因子 $U$。\n- 对得到的双对角矩阵 $B$ 进行 SVD 以获得 $\\widehat{V}$ 和奇异值；然后我们构造 $v_{\\min} = V \\widehat{v}_{\\min}$ 并提取 $x_{\\text{TLS}}$。\n- 对于测试用例 4，我们通过计算 $|\\|D v_{\\min}\\|_2 - \\sigma_{\\min}|$ 来验证 $v_{\\min}$ 和 $\\sigma_{\\min}$，对于一个正确计算的奇异三元组，该值应接近于零。\n\n测试集输出：\n\n- $r_1 = \\|x_{\\text{TLS}} - x_{\\star}\\|_2 / \\|x_{\\star}\\|_2$：针对接近一致但带有小扰动的数据。\n- $r_2 = \\|x_{\\text{TLS}}^{(D)} - x_{\\text{TLS}}^{(QD)}\\|_2$：展示左正交不变性。\n- $r_3 = \\|x_{\\text{TLS}} - x_{\\star}\\|_2 / \\|x_{\\star}\\|_2$：针对精确一致的数据。\n- $r_4 = \\left|\\|D v_{\\min}\\|_2 - \\sigma_{\\min}\\right|$：检查奇异三元组的一致性。\n\n所有计算均以双精度完成。程序产生一个单独的方括号行 $[r_1,r_2,r_3,r_4]$。",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import svd\n\ndef householder_vector(x: np.ndarray):\n    \"\"\"\n    Compute a Householder vector v (unit 2-norm) such that\n    (I - 2 v v^T) x = +/- ||x|| e1.\n    Returns v as a 1-D numpy array. If x is the zero vector, returns None.\n    \"\"\"\n    sigma = np.linalg.norm(x)\n    if sigma == 0.0:\n        return None\n    v = x.copy()\n    sign = 1.0 if x[0] >= 0 else -1.0\n    v[0] += sign * sigma\n    v_norm = np.linalg.norm(v)\n    if v_norm == 0.0:\n        return None\n    v /= v_norm\n    return v\n\ndef bidiagonalize_with_V(D: np.ndarray):\n    \"\"\"\n    Perform Golub–Kahan bidiagonalization of D via Householder reflections.\n    Returns B (bidiagonal form) and accumulated right orthogonal factor V,\n    such that D = U * B * V^T for some orthogonal U (not formed).\n    \"\"\"\n    m, p = D.shape\n    B = D.copy().astype(float)\n    V = np.eye(p, dtype=float)\n\n    k = min(m, p)\n    for j in range(k):\n        # Left reflector to zero out entries below the diagonal in column j\n        x_col = B[j:, j]\n        v = householder_vector(x_col)\n        if v is not None:\n            # Apply from the left to B[j:, j:]\n            # B[j:, j:] = (I - 2 v v^T) B[j:, j:]\n            B[j:, j:] -= 2.0 * np.outer(v, v @ B[j:, j:])\n\n        # Right reflector to zero out entries right of the superdiagonal in row j\n        if j  p - 1:\n            x_row = B[j, j+1:]\n            w = householder_vector(x_row)\n            if w is not None:\n                # Apply from the right to B[:, j+1:]\n                # B[:, j+1:] = B[:, j+1:] (I - 2 w w^T)\n                Bw = B[:, j+1:] @ w\n                B[:, j+1:] -= 2.0 * np.outer(Bw, w)\n                # Accumulate into V: V[:, j+1:] = V[:, j+1:] (I - 2 w w^T)\n                Vw = V[:, j+1:] @ w\n                V[:, j+1:] -= 2.0 * np.outer(Vw, w)\n\n    return B, V\n\ndef tls_from_D(D: np.ndarray, atol_den: float = 1e-14):\n    \"\"\"\n    Compute TLS solution x from augmented matrix D = [A b] using:\n    - Bidiagonalization D = U B V^T (only B, V needed),\n    - SVD of bidiagonal B to get last right singular vector,\n    - Back-transform to get v_min, then dehomogenize to x = -v[0:n]/v[n].\n    Returns x_tls, v_min (unit norm), sigma_min.\n    \"\"\"\n    m, p = D.shape\n    # Bidiagonalize D and accumulate right orthogonal factor V\n    B, V = bidiagonalize_with_V(D)\n    # SVD of bidiagonal B\n    # We only need singular values and right singular vectors\n    # Use thin SVD\n    Uhat, s, VhatT = svd(B, full_matrices=False, overwrite_a=False, check_finite=True)\n    Vhat = VhatT.T\n    # Last right singular vector of D\n    v_min = V @ Vhat[:, -1]\n    # Normalize for safety (should already be unit)\n    v_min /= np.linalg.norm(v_min)\n    sigma_min = s[-1]\n    # Dehomogenize\n    denom = v_min[-1]\n    if np.abs(denom)  atol_den:\n        # Ill-posed TLS (no finite solution); return NaNs to indicate failure\n        x_tls = np.full(p-1, np.nan)\n    else:\n        x_tls = -v_min[:-1] / denom\n    return x_tls, v_min, sigma_min\n\ndef solve():\n    results = []\n\n    # Test case 1: near-consistent data with small perturbations\n    rng = np.random.default_rng(0)\n    m1, n1 = 8, 3\n    A_true = rng.standard_normal((m1, n1))\n    x_star = rng.standard_normal(n1)\n    b_true = A_true @ x_star\n    noise_level = 1e-3\n    A1 = A_true + noise_level * rng.standard_normal((m1, n1))\n    b1 = b_true + noise_level * rng.standard_normal(m1)\n    D1 = np.hstack([A1, b1.reshape(-1, 1)])\n    x_tls1, vmin1, smin1 = tls_from_D(D1)\n    rel_err1 = np.linalg.norm(x_tls1 - x_star) / np.linalg.norm(x_star)\n    results.append(rel_err1)\n\n    # Test case 2: left-orthogonal invariance using Q from QR of Gaussian matrix\n    G = rng.standard_normal((m1, m1))\n    Q, _ = np.linalg.qr(G, mode='reduced')\n    D1Q = Q @ D1\n    x_tls1Q, _, _ = tls_from_D(D1Q)\n    diff2 = np.linalg.norm(x_tls1 - x_tls1Q)\n    results.append(diff2)\n\n    # Test case 3: exactly consistent data\n    rng3 = np.random.default_rng(123)\n    m3, n3 = 6, 3\n    A3 = rng3.standard_normal((m3, n3))\n    x3_star = rng3.standard_normal(n3)\n    b3 = A3 @ x3_star\n    D3 = np.hstack([A3, b3.reshape(-1, 1)])\n    x_tls3, _, _ = tls_from_D(D3)\n    rel_err3 = np.linalg.norm(x_tls3 - x3_star) / np.linalg.norm(x3_star)\n    results.append(rel_err3)\n\n    # Test case 4: singular triplet consistency check\n    # Using D1 from test case 1\n    # We already have vmin1 and smin1 from tls_from_D(D1)\n    # Verify that ||D1 vmin1||_2 approximately equals smin1\n    diff4 = abs(np.linalg.norm(D1 @ vmin1) - smin1)\n    results.append(diff4)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}