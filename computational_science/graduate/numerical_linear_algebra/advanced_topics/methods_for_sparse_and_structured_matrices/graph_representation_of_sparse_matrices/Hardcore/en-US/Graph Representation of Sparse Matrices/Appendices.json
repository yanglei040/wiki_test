{
    "hands_on_practices": [
        {
            "introduction": "The sparsity pattern of a general matrix $A$ can be viewed as a directed graph. A fundamental operation in numerical analysis is forming the normal equations matrix, $M = A^{\\top} A$, which is always symmetric. This exercise provides a hands-on exploration of how this algebraic operation transforms the underlying graph structure, creating new adjacencies that reveal second-order relationships like co-citation or shared neighbors . By analyzing the iteration matrix for solving a system with $M$, you will also connect these structural changes to the convergence properties of iterative methods.",
            "id": "3549136",
            "problem": "Consider the sparse matrix $A \\in \\mathbb{R}^{4 \\times 4}$ given by\n$$\nA \\;=\\;\n\\begin{pmatrix}\n0  1  1  0 \\\\\n0  0  0  1 \\\\\n0  0  0  1 \\\\\n1  0  0  0\n\\end{pmatrix}.\n$$\nTreat the nonzero pattern of $A$ as the adjacency structure of a directed graph on $4$ vertices, where $a_{ij} \\neq 0$ represents a directed edge from vertex $i$ to vertex $j$. Note that there are pairs $(i,j)$ with $a_{ij} \\neq 0$ but $a_{ji} = 0$, so the directed graph is not symmetric. Form the normal-equations matrix $M = A^{\\top} A$, which is symmetric positive semidefinite, and consider the Jacobi fixed-point iteration for the linear system $M x = A^{\\top} b$, where $D = \\operatorname{diag}(M)$ denotes the diagonal of $M$. The Jacobi iteration matrix is defined by\n$$\nB \\;=\\; I - D^{-1} M.\n$$\nStarting from first principles and definitions, carry out the following:\n- Compute $M = A^{\\top} A$ explicitly and identify $D$.\n- Compute $B$ explicitly and justify, from the nonzero pattern of $B$, how an undirected adjacency is induced between a pair of vertices that were not directly adjacent (in either direction) in the original directed graph represented by $A$. Provide a clear graph-theoretic interpretation based on shared in-neighbors or co-citations.\n- Compute the spectral radius $\\rho(B)$ of the iteration matrix $B$.\n\nGive your final answer as the single real number $\\rho(B)$. No rounding is required.",
            "solution": "To solve this problem, we will follow the steps outlined in the prompt.\n\n**1. Compute $M = A^{\\top} A$ and identify $D$**\n\nFirst, we write down the matrix $A$ and its transpose $A^{\\top}$:\n$$\nA \\;=\\;\n\\begin{pmatrix}\n0  1  1  0 \\\\\n0  0  0  1 \\\\\n0  0  0  1 \\\\\n1  0  0  0\n\\end{pmatrix}\n\\quad \\implies \\quad\nA^{\\top} \\;=\\;\n\\begin{pmatrix}\n0  0  0  1 \\\\\n1  0  0  0 \\\\\n1  0  0  0 \\\\\n0  1  1  0\n\\end{pmatrix}\n$$\nNext, we compute the product $M = A^{\\top} A$:\n$$\nM \\;=\\;\n\\begin{pmatrix}\n0  0  0  1 \\\\\n1  0  0  0 \\\\\n1  0  0  0 \\\\\n0  1  1  0\n\\end{pmatrix}\n\\begin{pmatrix}\n0  1  1  0 \\\\\n0  0  0  1 \\\\\n0  0  0  1 \\\\\n1  0  0  0\n\\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  1  0 \\\\\n0  1  1  0 \\\\\n0  0  0  2\n\\end{pmatrix}\n$$\nThe diagonal part of $M$ is $D = \\operatorname{diag}(M)$, which is:\n$$\nD \\;=\\;\n\\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  2\n\\end{pmatrix}\n$$\n\n**2. Compute $B$ and provide a graph-theoretic interpretation**\n\nThe Jacobi iteration matrix is $B = I - D^{-1} M$. First, we find $D^{-1}$:\n$$\nD^{-1} \\;=\\;\n\\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  1/2\n\\end{pmatrix}\n$$\nNow we compute $B$:\n$$\nB \\;=\\; I - D^{-1}M \\;=\\;\n\\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  1\n\\end{pmatrix}\n-\n\\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  1/2\n\\end{pmatrix}\n\\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  1  0 \\\\\n0  1  1  0 \\\\\n0  0  0  2\n\\end{pmatrix}\n$$\n$$\nB \\;=\\;\n\\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  1\n\\end{pmatrix}\n-\n\\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  1  0 \\\\\n0  1  1  0 \\\\\n0  0  0  1\n\\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n0   0   0  0 \\\\\n0   0  -1  0 \\\\\n0  -1   0  0 \\\\\n0   0   0  0\n\\endpmatrix}\n$$\nThe nonzero pattern of $B$ has entries at positions $(2,3)$ and $(3,2)$. This corresponds to an undirected adjacency between vertices $2$ and $3$. In the original directed graph of $A$, there is no edge between vertices $2$ and $3$ in either direction. The edge $(2,3)$ in the graph of $M$ (and thus $B$) arises because the entry $M_{23} = \\sum_{k=1}^4 A_{k2} A_{k3}$ is nonzero. In this case, $M_{23} = A_{12}A_{13} = 1 \\cdot 1 = 1$.\nGraph-theoretically, this means that columns $2$ and $3$ of matrix $A$ have a common nonzero row index. Specifically, both column $2$ and column $3$ have a nonzero entry in row $1$. In the directed graph of $A$, this corresponds to vertex $1$ having outgoing edges to both vertex $2$ and vertex $3$. Another interpretation is that vertices $2$ and $3$ share a common \"in-neighbor\" (vertex $1$). In citation network terminology, this would be a \"co-citation\": documents $2$ and $3$ are both cited by document $1$. The matrix $A^{\\top}A$ captures these second-order relationships.\n\n**3. Compute the spectral radius $\\rho(B)$**\n\nThe spectral radius is the maximum absolute value of the eigenvalues of $B$. We find the eigenvalues by solving the characteristic equation $\\det(B - \\lambda I) = 0$.\n$$\n\\det\n\\begin{pmatrix}\n-\\lambda   0   0  0 \\\\\n0   -\\lambda  -1  0 \\\\\n0  -1   -\\lambda  0 \\\\\n0   0   0  -\\lambda\n\\end{pmatrix}\n= 0\n$$\nExpanding the determinant, we get:\n$$\n(-\\lambda) \\cdot \\det \\begin{pmatrix} -\\lambda  -1 \\\\ -1  -\\lambda \\end{pmatrix} \\cdot (-\\lambda) = 0\n$$\n$$\n\\lambda^2 (\\lambda^2 - 1) = 0\n$$\n$$\n\\lambda^2 (\\lambda - 1)(\\lambda + 1) = 0\n$$\nThe eigenvalues are $\\lambda_1=0$ (with multiplicity 2), $\\lambda_2=1$, and $\\lambda_3=-1$.\nThe spectral radius is $\\rho(B) = \\max\\{|\\lambda_i|\\} = \\max\\{|0|, |1|, |-1|\\} = 1$.",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "For sparse matrices, the order in which we number the rows and columns is not merely an aesthetic choice; it has profound consequences for the efficiency of numerical solvers. This practice demonstrates the power of matrix reordering by examining how a permutation of a matrix's graph can dramatically reduce its profile, a key metric related to the cost of sparse factorization . By working through a simple star graph, you will develop a powerful intuition that connects the abstract algebraic concept of profile to the geometric arrangement of nodes in a linear embedding.",
            "id": "3549161",
            "problem": "Let $A \\in \\mathbb{R}^{7 \\times 7}$ be a symmetric sparse matrix whose sparsity pattern corresponds to a star graph on $7$ vertices: vertex $1$ is connected to each of vertices $2,3,4,5,6,7$, and there are no other off-diagonal connections. Concretely, suppose $a_{11},\\ldots,a_{77}$ are nonzero (diagonal structure), and $a_{1k} = a_{k1} \\neq 0$ for $k \\in \\{2,3,4,5,6,7\\}$, with all other off-diagonal entries zero. Consider the identity ordering (rows and columns labeled $1,2,\\ldots,7$) and the permutation $\\pi$ given by $\\pi(1) = 7$ and $\\pi(k) = k - 1$ for $k \\in \\{2,3,4,5,6,7\\}$, which induces the permutation matrix $P \\in \\mathbb{R}^{7 \\times 7}$ and the symmetrically permuted matrix $B = P A P^{\\top}$. Define the profile of a matrix $M$ in an ordering by\n$$\n\\operatorname{prof}(M) \\;=\\; \\sum_{i=1}^{n} \\max\\{\\, i - j \\;:\\; m_{ij} \\neq 0 \\,\\}.\n$$\nStarting only from core definitions of the graph representation of the sparsity pattern and the above profile, compute the reduction\n$$\n\\Delta \\;=\\; \\operatorname{prof}(A) \\;-\\; \\operatorname{prof}(B).\n$$\nAdditionally, justify in words the corresponding effect on edge lengths in a linear embedding of the graph under the two orderings, where each vertex $i$ is embedded at location $i \\in \\mathbb{R}$ and each edge $(i,j)$ has length $|i - j|$. Your final answer must be the single real-valued number $\\Delta$. No rounding is required.",
            "solution": "This problem requires us to compute the profile of a matrix under two different orderings and find the difference. The profile is defined as $\\operatorname{prof}(M) = \\sum_{i=1}^{n} \\max\\{ i - j : m_{ij} \\neq 0 \\}$. This is equivalent to summing, for each row $i$, the distance from the diagonal to the first non-zero element in that row, i.e., $i - \\min\\{j \\mid m_{ij} \\neq 0\\}$.\n\n**1. Calculate the profile of matrix $A$ (identity ordering)**\n\nThe matrix $A$ corresponds to a star graph with vertex 1 as the center. The non-zero entries are on the diagonal ($a_{ii} \\neq 0$) and on the first row and column ($a_{1k}=a_{k1} \\neq 0$ for $k \\in \\{2,\\dots,7\\}$). We compute the profile contribution for each row:\n-   **Row 1:** The non-zero entries are $a_{11}, a_{12}, \\dots, a_{17}$. The first non-zero is in column $j=1$. Contribution: $1 - \\min\\{1, 2, \\dots, 7\\} = 1 - 1 = 0$.\n-   **Row 2:** The non-zero entries are $a_{21}$ and $a_{22}$. The first non-zero is in column $j=1$. Contribution: $2 - \\min\\{1, 2\\} = 2 - 1 = 1$.\n-   **Row 3:** The non-zero entries are $a_{31}$ and $a_{33}$. The first non-zero is in column $j=1$. Contribution: $3 - \\min\\{1, 3\\} = 3 - 1 = 2$.\n-   ...\n-   **Row $i$ ($i > 1$):** The non-zero entries are $a_{i1}$ and $a_{ii}$. The first non-zero is in column $j=1$. Contribution: $i - \\min\\{1, i\\} = i - 1$.\n-   **Row 7:** The non-zero entries are $a_{71}$ and $a_{77}$. The first non-zero is in column $j=1$. Contribution: $7 - \\min\\{1, 7\\} = 7 - 1 = 6$.\n\nThe total profile of $A$ is the sum of these contributions:\n$$\n\\operatorname{prof}(A) = 0 + (2-1) + (3-1) + (4-1) + (5-1) + (6-1) + (7-1) = 0 + 1 + 2 + 3 + 4 + 5 + 6 = 21.\n$$\n\n**2. Calculate the profile of matrix $B$ (permuted ordering)**\n\nThe permutation $\\pi$ re-labels the vertices: the center (vertex 1) is moved to position 7, and the leaves (vertices 2 to 7) are moved to positions 1 to 6. The matrix $B$ is symmetric. Its non-zero off-diagonal entries are $b_{i,7} = b_{7,i} \\neq 0$ for $i \\in \\{1,\\dots,6\\}$. The diagonal entries $b_{ii}$ are also non-zero. We compute the profile contribution for each row of $B$:\n-   **Row $i$ ($1 \\le i \\le 6$):** The non-zero entries are $b_{ii}$ and $b_{i,7}$. The first non-zero is in column $j=i$. Contribution: $i - \\min\\{i, 7\\} = i - i = 0$.\n-   **Row 7:** The non-zero entries are $b_{71}, b_{72}, \\dots, b_{77}$. The first non-zero is in column $j=1$. Contribution: $7 - \\min\\{1, 2, \\dots, 7\\} = 7 - 1 = 6$.\n\nThe total profile of $B$ is the sum of these contributions:\n$$\n\\operatorname{prof}(B) = \\underbrace{0 + 0 + 0 + 0 + 0 + 0}_{\\text{rows } 1 \\text{ to } 6} + 6 = 6.\n$$\n\n**3. Calculate the reduction $\\Delta$ and provide justification**\n\nThe reduction in profile is:\n$$\n\\Delta = \\operatorname{prof}(A) - \\operatorname{prof}(B) = 21 - 6 = 15.\n$$\n\n**Justification:** The profile measures the sum of row-wise lower bandwidths. In a linear embedding, this corresponds to the sum of lengths of \"backward-pointing\" edges. In the original ordering for $A$, the central, high-degree vertex was placed at the beginning. This created long backward edges from every other vertex to vertex 1, resulting in a large profile. The permutation for $B$ is a variant of the Reverse Cuthill-McKee (RCM) algorithm, which aims to reduce bandwidth and profile by placing high-degree nodes at the end of the ordering. By moving the central vertex to the last position, all its connections become \"forward-pointing\" for rows $1$ through $6$, contributing nothing to their profile calculation. The only backward-pointing edges now originate from the last vertex, leading to a much smaller total profile. This demonstrates how a simple reordering based on graph structure can drastically reduce a matrix's profile, which is crucial for reducing the work and storage in sparse factorization methods.",
            "answer": "$$\\boxed{15}$$"
        },
        {
            "introduction": "Real-world problems often yield matrices that are structurally deficient, such as being structurally singular, which prevents a direct solution. This advanced exercise simulates a common engineering and design task: how to minimally modify a matrix to repair such a deficiency while controlling for unintended consequences . You will use the language of graphs—from bipartite matchings to predict rank, to elimination graphs to predict factorization cost—to navigate the critical trade-off between ensuring a matrix has full structural rank and minimizing the fill-in that occurs during its factorization.",
            "id": "3549164",
            "problem": "Consider a sparse matrix $A \\in \\mathbb{R}^{5 \\times 5}$ with row set $\\{r_1,r_2,r_3,r_4,r_5\\}$ and column set $\\{c_1,c_2,c_3,c_4,c_5\\}$. The bipartite graph representation of $A$, denoted $B(A)$, has left part $\\{c_1,c_2,c_3,c_4,c_5\\}$ and right part $\\{r_1,r_2,r_3,r_4,r_5\\}$, with an edge $(c_j,r_i)$ if and only if the structural pattern of $A$ contains a potential nonzero at position $(i,j)$. The nonzero pattern is specified by the following edges in $B(A)$:\n- $c_1$ is adjacent to $r_1$,\n- $c_2$ is adjacent to $r_1$ and $r_2$,\n- $c_3$ is adjacent to $r_2$,\n- $c_4$ is adjacent to $r_3$ and $r_5$,\n- $c_5$ is adjacent to $r_4$ and $r_5$.\n\nUsing only core definitions from numerical linear algebra and graph theory, and without invoking any pre-packaged theorems beyond those definitions, proceed as follows.\n\n1. Starting from the definition that the structural rank of $A$ equals the maximum size of a matching in $B(A)$, determine the minimal number of edge additions to $B(A)$ required to guarantee full structural rank (i.e., structural rank equal to $5$). Restrict attention to adding edges that connect one of the columns in $\\{c_1,c_2,c_3\\}$ to one of the rows in $\\{r_3,r_4,r_5\\}$, and justify minimality.\n\n2. For each such minimal single-edge addition, analyze the trade-off with fill-in during factorization via the following principled model. Consider the pattern of $A^{\\top}A$, whose column intersection graph $G$ has vertices $\\{c_1,c_2,c_3,c_4,c_5\\}$ and an undirected edge $(c_i,c_j)$ if and only if columns $c_i$ and $c_j$ share at least one common row index where both have a potential nonzero. Model Cholesky factorization of $A^{\\top}A$ with the natural elimination ordering $c_1,c_2,c_3,c_4,c_5$. Using the elimination graph framework, where eliminating a vertex adds edges to make its higher-index neighbors a clique, compute the number of fill-in edges $f$ introduced for each candidate single-edge addition identified in part $1$.\n\n3. Define the quantitative trade-off objective $J = \\alpha \\cdot k + \\beta \\cdot f$, where $k$ is the number of added edges and $f$ is the number of fill-in edges computed in part $2$. Take $\\alpha = \\frac{17}{10}$ and $\\beta = \\frac{9}{10}$. Among all minimal single-edge additions from part $1$, select the design that minimizes $J$, and report this minimal value of $J$ as a single real number. Do not use any units and do not express the result as an inequality or equation. If an approximation is not required, present the exact value.",
            "solution": "This problem is broken down into three parts: finding a minimal structural repair for a rank-deficient matrix, analyzing the computational cost (fill-in) of that repair, and making a design decision based on a trade-off objective.\n\n**Part 1: Minimal Edge Additions for Full Structural Rank**\n\nThe structural rank of a matrix is the size of the maximum matching in its bipartite graph $B(A)$. For $A$ to have full structural rank (5), $B(A)$ must have a perfect matching of size 5. We test for this using Hall's condition on the column vertices.\n\nThe neighborhoods of the columns are:\n- $N(c_1) = \\{r_1\\}$\n- $N(c_2) = \\{r_1, r_2\\}$\n- $N(c_3) = \\{r_2\\}$\n- $N(c_4) = \\{r_3, r_5\\}$\n- $N(c_5) = \\{r_4, r_5\\}$\n\nConsider the subset of columns $C' = \\{c_1, c_2, c_3\\}$. The size of this set is $|C'| = 3$. The union of their neighborhoods is $N(C') = N(c_1) \\cup N(c_2) \\cup N(c_3) = \\{r_1\\} \\cup \\{r_1, r_2\\} \\cup \\{r_2\\} = \\{r_1, r_2\\}$. The size of the neighborhood is $|N(C')| = 2$.\nSince $|C'| > |N(C')|$, Hall's condition is violated. The matrix is structurally rank-deficient. The maximum matching size is 4, so the deficiency is 1.\n\nTo repair this, we need to increase the size of $N(C')$. The problem constrains us to add an edge from a column in $C'=\\{c_1,c_2,c_3\\}$ to a row not in $N(C')=\\{r_1, r_2\\}$, i.e., a row in $\\{r_3, r_4, r_5\\}$. Adding any single such edge will fix the violation for this subset (and it can be verified it's sufficient for a perfect matching). Therefore, the minimal number of edge additions is $k=1$. There are $3 \\times 3 = 9$ possible single-edge additions to consider.\n\n**Part 2: Fill-in Analysis**\n\nWe analyze the fill-in for Cholesky factorization of $A^{\\top}A$ using the column intersection graph $G$ and the natural elimination ordering $(c_1, \\dots, c_5)$.\n\nThe initial graph $G_0$ has an edge $(c_i, c_j)$ if columns $c_i$ and $c_j$ share a neighbor in $B(A)$.\n- $N(c_1) \\cap N(c_2) = \\{r_1\\} \\implies$ edge $(c_1, c_2)$.\n- $N(c_2) \\cap N(c_3) = \\{r_2\\} \\implies$ edge $(c_2, c_3)$.\n- $N(c_4) \\cap N(c_5) = \\{r_5\\} \\implies$ edge $(c_4, c_5)$.\nInitial edges of $G$: $E_0 = \\{(c_1, c_2), (c_2, c_3), (c_4, c_5)\\}$.\n\nNow we analyze the fill-in, $f$, for each of the 9 candidate modifications. A modification adds a row to a column's neighborhood, which may add edges to $G$. Fill-in occurs when eliminating a vertex $c_i$ if two of its higher-indexed neighbors are not already connected.\n\n*   **Add edge to $c_1$**:\n    - Add $(c_1, r_3) \\implies$ New edge in G: $(c_1, c_4)$. Elim $c_1$ creates fill $(c_2,c_4)$. Elim $c_2$ creates fill $(c_3,c_4)$. Total $f=2$.\n    - Add $(c_1, r_4) \\implies$ New edge in G: $(c_1, c_5)$. Elim $c_1$ creates fill $(c_2,c_5)$. Elim $c_2$ creates fill $(c_3,c_5)$. Total $f=2$.\n    - Add $(c_1, r_5) \\implies$ New edges in G: $(c_1, c_4), (c_1, c_5)$. Elim $c_1$ creates fill $(c_2,c_4), (c_2,c_5)$. Elim $c_2$ creates fill $(c_3,c_4), (c_3,c_5)$. Total $f=4$.\n*   **Add edge to $c_2$**:\n    - Add $(c_2, r_3) \\implies$ New edge in G: $(c_2, c_4)$. Elim $c_2$ creates fill $(c_3,c_4)$. Total $f=1$.\n    - Add $(c_2, r_4) \\implies$ New edge in G: $(c_2, c_5)$. Elim $c_2$ creates fill $(c_3,c_5)$. Total $f=1$.\n    - Add $(c_2, r_5) \\implies$ New edges in G: $(c_2, c_4), (c_2, c_5)$. Elim $c_2$ creates fill $(c_3,c_4), (c_3,c_5)$. Total $f=2$.\n*   **Add edge to $c_3$**:\n    - Add $(c_3, r_3) \\implies$ New edge in G: $(c_3, c_4)$. Elimination proceeds along the path $c_1-c_2-c_3-c_4-c_5$. No fill. $f=0$.\n    - Add $(c_3, r_4) \\implies$ New edge in G: $(c_3, c_5)$. When we eliminate $c_3$, its only higher-indexed neighbor is $c_5$. No fill. Total $f=0$.\n    - Add $(c_3, r_5) \\implies$ New edges in G: $(c_3, c_4), (c_3, c_5)$. When we eliminate $c_3$, its higher-indexed neighbors are $\\{c_4,c_5\\}$, which are already connected. No fill. $f=0$.\n\nThe fill-in values are: $\\{2, 2, 4\\}$ for adding to $c_1$; $\\{1, 1, 2\\}$ for adding to $c_2$; and $\\{0, 0, 0\\}$ for adding to $c_3$.\n\n**Part 3: Trade-off Minimization**\n\nThe objective is to minimize $J = \\alpha \\cdot k + \\beta \\cdot f$ with $k=1$, $\\alpha = 1.7$, and $\\beta = 0.9$.\n$$ J = 1.7 \\cdot 1 + 0.9 \\cdot f = 1.7 + 0.9f $$\nTo minimize $J$, we must select a design that minimizes the fill-in $f$. From Part 2, the minimum possible fill-in is $f=0$. This is achieved by any of the three modifications involving column $c_3$: adding edge $(c_3, r_3)$, $(c_3, r_4)$, or $(c_3, r_5)$.\n\nFor any of these optimal choices, the value of the objective function is:\n$$ J_{min} = 1.7 + 0.9 \\times 0 = 1.7 $$\nThe minimal value of $J$ is 1.7.",
            "answer": "$$\\boxed{1.7}$$"
        }
    ]
}