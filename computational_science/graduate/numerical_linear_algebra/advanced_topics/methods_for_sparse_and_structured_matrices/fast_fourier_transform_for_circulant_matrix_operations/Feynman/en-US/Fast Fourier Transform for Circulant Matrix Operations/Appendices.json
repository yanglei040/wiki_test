{
    "hands_on_practices": [
        {
            "introduction": "Many powerful algorithms in numerical linear algebra, such as methods for finding dominant eigenvectors or solving linear systems, are iterative in nature, built upon repeated matrix-vector multiplications. This practice explores the power iteration method, a fundamental iterative algorithm. By leveraging the Fast Fourier Transform (FFT) to perform the matrix-vector products for a circulant matrix, you can dramatically accelerate the computation from $O(n^2)$ to $O(n \\log n)$ operations. This exercise  challenges you to derive the spectral properties of a specific circulant matrix from first principles and analyze the convergence of the power method, providing a deep, quantitative link between the matrix's spectrum and the algorithm's performance.",
            "id": "3545359",
            "problem": "Consider an $n \\times n$ real circulant matrix $C$ with $n$ even, defined by its first column $c \\in \\mathbb{R}^{n}$ as $c_{0}=3$, $c_{1}=1$, $c_{n-1}=1$, and $c_{j}=0$ for all other indices $j \\in \\{2,3,\\dots,n-2\\}$. You are tasked with designing a fully explicit randomized estimator of the spectral norm $\\|C\\|_{2}$ and the $2$-norm condition number $\\kappa_{2}(C)$ using a power iteration scheme whose matrix–vector multiplies are implemented with the Fast Fourier Transform (FFT). Begin from foundational definitions: the structure of circulant matrices, the discrete Fourier transform as a unitary change of basis, and the spectral theorem for normal matrices. You must not assume any pre-derived diagonalization formula or shortcut identities; instead, derive all relations from first principles starting from these bases.\n\nYour estimator should:\n- Use a random initial vector $x^{(0)} \\in \\mathbb{R}^{n}$ whose entries are independent and identically distributed with a continuous distribution symmetric about $0$ (for example, standard normal), so that, almost surely, $x^{(0)}$ has nonzero components in every eigenvector direction of $C$.\n- Implement the power iteration $x^{(t+1)} := C x^{(t)} / \\|C x^{(t)}\\|_{2}$ for $t \\geq 0$ to estimate $\\|C\\|_{2}$ via the Rayleigh quotient $r^{(t)} := (x^{(t)})^{\\top} C x^{(t)}$ and, independently, implement the analogous iteration on $C^{-1}$, $y^{(t+1)} := C^{-1} y^{(t)} / \\|C^{-1} y^{(t)}\\|_{2}$, to estimate the smallest eigenvalue of $C$. Both $C$ and $C^{-1}$ multiplies must be performed in $O(n \\log n)$ time via FFT-based diagonalization of $C$.\n- Analyze the asymptotic convergence rate of each iteration in terms of spectral gaps inferred from the eigenvalues $\\lambda_{k}$ of $C$.\n\nUsing only these bases, carry out the following:\n1. Derive the eigenvalues $\\lambda_{k}$ of $C$.\n2. Prove that $C$ is symmetric positive definite, identify $\\|C\\|_{2}$ and the smallest eigenvalue, and conclude $\\kappa_{2}(C)$.\n3. For the power iteration on $C$, derive the asymptotic geometric convergence factor for the angle between $x^{(t)}$ and the dominant eigenvector in terms of the ratio of the second-largest to the largest eigenvalue. Express this factor as a closed-form function of $n$.\n4. For the power iteration on $C^{-1}$, derive the analogous asymptotic geometric convergence factor in terms of the ratio of the smallest to the second-smallest eigenvalue of $C$, again in closed form as a function of $n$.\n5. Report, in closed form, the quadruple consisting of: the exact spectral norm $\\|C\\|_{2}$, the exact condition number $\\kappa_{2}(C)$, the asymptotic geometric convergence factor of the power iteration on $C$, and the asymptotic geometric convergence factor of the power iteration on $C^{-1}$, each expressed purely in terms of $n$ and constants. No rounding is required.\n\nYour final reported answer must be a single row matrix containing these four quantities in the specified order.",
            "solution": "The problem statement is analyzed and found to be valid. It is a well-posed problem in numerical linear algebra that is scientifically grounded, objective, and self-contained. The requirement to derive results from foundational principles is a pedagogical constraint that does not constitute a flaw. We proceed with the solution.\n\nThe problem asks for an analysis of a specific real, even-dimensional circulant matrix $C \\in \\mathbb{R}^{n \\times n}$. The matrix $C$ is defined by its first column vector $c \\in \\mathbb{R}^{n}$, where $c_0 = 3$, $c_1 = 1$, $c_{n-1} = 1$, and $c_j = 0$ for $j \\in \\{2, 3, \\dots, n-2\\}$.\n\n1.  **Derivation of the Eigenvalues of $C$**\n\nA circulant matrix is defined by its first column. The entry $C_{jk}$ is given by $c_{(j-k) \\pmod n}$. The foundational principle for diagonalizing a circulant matrix is that its eigenvectors are the columns of the Discrete Fourier Transform (DFT) matrix. We must derive this from first principles.\n\nLet $\\omega = \\exp(2\\pi i/n)$ be the $n$-th primitive root of unity, where $i = \\sqrt{-1}$. Consider the vectors $v_k \\in \\mathbb{C}^n$ for $k \\in \\{0, 1, \\dots, n-1\\}$, where the $j$-th component of $v_k$ is $(v_k)_j = \\omega^{jk}$. We will show that these are the eigenvectors of $C$.\n\nLet's compute the $j$-th component of the matrix-vector product $C v_k$:\n$$ (C v_k)_j = \\sum_{m=0}^{n-1} C_{jm} (v_k)_m = \\sum_{m=0}^{n-1} c_{(j-m) \\pmod n} \\, \\omega^{mk} $$\nLet $p = (j-m) \\pmod n$. As $m$ iterates from $0$ to $n-1$, $p$ also covers the set $\\{0, 1, \\dots, n-1\\}$. We can express $m$ in terms of $p$ as $m = (j-p) \\pmod n$. Substituting this into the sum:\n$$ (C v_k)_j = \\sum_{p=0}^{n-1} c_p \\, \\omega^{(j-p)k} = \\sum_{p=0}^{n-1} c_p \\, \\omega^{jk} \\omega^{-pk} = \\omega^{jk} \\left( \\sum_{p=0}^{n-1} c_p \\, \\omega^{-pk} \\right) $$\nThe term in the parenthesis is a scalar that depends on $k$ but not on $j$. Let us define this scalar as $\\lambda_k$:\n$$ \\lambda_k = \\sum_{j=0}^{n-1} c_j \\omega^{-jk} $$\nWith this definition, we have $(C v_k)_j = \\lambda_k \\omega^{jk} = \\lambda_k (v_k)_j$. This equation holds for all components $j$, which proves that $v_k$ is an eigenvector of $C$ with the corresponding eigenvalue $\\lambda_k$. The set of eigenvalues $\\{\\lambda_k\\}_{k=0}^{n-1}$ is called the spectrum of $C$.\n\nNow, we substitute the specific values from the vector $c$ into the formula for $\\lambda_k$:\n$$ \\lambda_k = c_0 \\omega^{-0} + c_1 \\omega^{-k} + c_{n-1} \\omega^{-(n-1)k} + \\sum_{j=2}^{n-2} c_j \\omega^{-jk} $$\n$$ \\lambda_k = 3 \\cdot 1 + 1 \\cdot \\omega^{-k} + 1 \\cdot \\omega^{-(n-1)k} + 0 = 3 + \\omega^{-k} + \\omega^{-(n-1)k} $$\nUsing the property $\\omega^n = \\exp(2\\pi i) = 1$, we can simplify $\\omega^{-(n-1)k} = \\omega^{-nk} \\omega^k = (\\omega^n)^{-k} \\omega^k = 1^{-k} \\omega^k = \\omega^k$.\n$$ \\lambda_k = 3 + \\omega^{-k} + \\omega^k $$\nBy Euler's formula, $\\omega^k = \\cos(2\\pi k/n) + i\\sin(2\\pi k/n)$ and $\\omega^{-k} = \\cos(2\\pi k/n) - i\\sin(2\\pi k/n)$. Their sum is $2\\cos(2\\pi k/n)$.\nThus, the eigenvalues of $C$ are:\n$$ \\lambda_k = 3 + 2\\cos\\left(\\frac{2\\pi k}{n}\\right) \\quad \\text{for } k = 0, 1, \\dots, n-1 $$\n\n2.  **Symmetry, Positive Definiteness, Spectral Norm, and Condition Number**\n\nFor a real circulant matrix with first column $c$, symmetry ($C=C^T$) is equivalent to the condition $c_j = c_{n-j}$ for $j=1, \\dots, n-1$. In our case, $c_1=1$ and $c_{n-1}=1$, so the condition holds for $j=1$. For $j \\in \\{2, \\dots, n-2\\}$, we have $c_j=0$. The index $n-j$ is also in $\\{2, \\dots, n-2\\}$ as $n$ is even, implying $n-j \\neq j$, so $c_{n-j}=0$ as well. The condition holds for all $j$, so $C$ is symmetric.\n\nSince $C$ is a real symmetric matrix, its eigenvalues must be real. Our derived expression $\\lambda_k = 3 + 2\\cos(2\\pi k/n)$ is indeed real for all $k$. To check for positive definiteness, we need to show that all eigenvalues are strictly positive. The range of the cosine function is $[-1, 1]$.\nThe maximum value of $\\cos(2\\pi k/n)$ is $1$, occurring at $k=0$. This gives the largest eigenvalue:\n$$ \\lambda_{\\max} = \\lambda_0 = 3 + 2\\cos(0) = 3 + 2 = 5 $$\nThe minimum value of $\\cos(2\\pi k/n)$ is $-1$, occurring at $k=n/2$ (which is an integer since $n$ is even). This gives the smallest eigenvalue:\n$$ \\lambda_{\\min} = \\lambda_{n/2} = 3 + 2\\cos(\\pi) = 3 - 2 = 1 $$\nAll eigenvalues $\\lambda_k$ lie in the interval $[1, 5]$. Since $\\lambda_{\\min} = 1 > 0$, all eigenvalues are positive, and thus the symmetric matrix $C$ is positive definite.\n\nFor a normal matrix (and symmetric matrices are normal), the spectral norm $\\|C\\|_2$ is its spectral radius, i.e., the maximum absolute value of its eigenvalues.\n$$ \\|C\\|_2 = \\max_{k} |\\lambda_k| = \\lambda_{\\max} = 5 $$\nThe $2$-norm condition number $\\kappa_2(C)$ is given by $\\|C\\|_2 \\|C^{-1}\\|_2$. The eigenvalues of $C^{-1}$ are $1/\\lambda_k$. Thus, $\\|C^{-1}\\|_2 = \\max_k |1/\\lambda_k| = 1/\\min_k|\\lambda_k| = 1/\\lambda_{\\min}$.\n$$ \\kappa_2(C) = \\frac{\\lambda_{\\max}}{\\lambda_{\\min}} = \\frac{5}{1} = 5 $$\n\n3.  **Convergence Factor for Power Iteration on $C$**\n\nThe power iteration method $x^{(t+1)} \\propto C x^{(t)}$ converges to the eigenvector corresponding to the eigenvalue with the largest magnitude. The asymptotic geometric convergence factor is the ratio of the magnitudes of the second-largest to the largest eigenvalue. Since all eigenvalues of $C$ are positive, we seek the ratio $\\lambda'/\\lambda_{\\max}$, where $\\lambda'$ is the second-largest eigenvalue.\n\nThe eigenvalues are $\\lambda_k = 3 + 2\\cos(2\\pi k/n)$.\nThe largest eigenvalue is $\\lambda_0 = 5$, which is unique.\nThe function $\\cos(x)$ is strictly decreasing on $[0, \\pi]$. The arguments $2\\pi k/n$ for $k=1$ and $k=n-1$ give the same cosine value: $\\cos(2\\pi/n) = \\cos(2\\pi(n-1)/n) = \\cos(2\\pi - 2\\pi/n)$. This value is the largest one after $\\cos(0)=1$.\nTherefore, the second-largest eigenvalue is degenerate (has multiplicity $2$) and is given by:\n$$ \\lambda' = \\lambda_1 = \\lambda_{n-1} = 3 + 2\\cos\\left(\\frac{2\\pi}{n}\\right) $$\nThe asymptotic geometric convergence factor is:\n$$ \\frac{\\lambda'}{\\lambda_{\\max}} = \\frac{3 + 2\\cos\\left(\\frac{2\\pi}{n}\\right)}{5} $$\n\n4.  **Convergence Factor for Power Iteration on $C^{-1}$**\n\nThe power iteration applied to $C^{-1}$ (i.e., inverse iteration on $C$) converges to the eigenvector of $C^{-1}$ corresponding to its largest-magnitude eigenvalue. This eigenvalue is $1/\\lambda_{\\min}$, where $\\lambda_{\\min}$ is the smallest-magnitude eigenvalue of $C$. The convergence factor is the ratio of the second-largest to the largest magnitude eigenvalue of $C^{-1}$, which is equivalent to the ratio of the smallest to the second-smallest magnitude eigenvalue of $C$.\n\nThe smallest eigenvalue of $C$ is $\\lambda_{\\min} = \\lambda_{n/2} = 1$, which is unique.\nThe second-smallest eigenvalue corresponds to the value of $\\cos(2\\pi k/n)$ closest to $-1$. This occurs for $k=n/2-1$ and $k=n/2+1$.\n$$ \\cos\\left(\\frac{2\\pi(n/2-1)}{n}\\right) = \\cos\\left(\\pi - \\frac{2\\pi}{n}\\right) = -\\cos\\left(\\frac{2\\pi}{n}\\right) $$\n$$ \\cos\\left(\\frac{2\\pi(n/2+1)}{n}\\right) = \\cos\\left(\\pi + \\frac{2\\pi}{n}\\right) = -\\cos\\left(\\frac{2\\pi}{n}\\right) $$\nThe second-smallest eigenvalue, $\\lambda''$, is thus also degenerate and is given by:\n$$ \\lambda'' = \\lambda_{n/2-1} = \\lambda_{n/2+1} = 3 + 2\\left(-\\cos\\left(\\frac{2\\pi}{n}\\right)\\right) = 3 - 2\\cos\\left(\\frac{2\\pi}{n}\\right) $$\nThe asymptotic geometric convergence factor for the inverse iteration is:\n$$ \\frac{\\lambda_{\\min}}{\\lambda''} = \\frac{1}{3 - 2\\cos\\left(\\frac{2\\pi}{n}\\right)} $$\n\n5.  **Final Quadruple of Quantities**\n\nBased on the derivations above, the four requested quantities are:\n1.  Spectral norm $\\|C\\|_2 = 5$.\n2.  Condition number $\\kappa_2(C) = 5$.\n3.  Asymptotic geometric convergence factor for power iteration on $C$: $\\frac{1}{5}\\left(3 + 2\\cos\\left(\\frac{2\\pi}{n}\\right)\\right)$.\n4.  Asymptotic geometric convergence factor for power iteration on $C^{-1}$: $\\frac{1}{3 - 2\\cos\\left(\\frac{2\\pi}{n}\\right)}$.\n\nThese are compiled into a single row matrix as the final answer.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 5 & 5 & \\frac{3 + 2\\cos\\left(\\frac{2\\pi}{n}\\right)}{5} & \\frac{1}{3 - 2\\cos\\left(\\frac{2\\pi}{n}\\right)} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "While the Cooley-Tukey FFT algorithm is famously efficient for sequences whose length is a power of two, many applications in fields like number theory and signal processing require computing the Discrete Fourier Transform (DFT) for prime or other composite lengths. This practice delves into Bluestein's algorithm, an ingenious method that reformulates any DFT as a linear convolution. This allows the computation to be performed efficiently by a standard power-of-two FFT via the convolution theorem. By implementing Bluestein's algorithm , you will not only develop a practical tool but also reinforce your understanding of the profound duality between the DFT and convolution.",
            "id": "3545333",
            "problem": "Let $N \\in \\mathbb{N}$ and let $x \\in \\mathbb{C}^{N}$ denote a length-$N$ sequence. The Discrete Fourier Transform (DFT) is defined by the linear map $X \\in \\mathbb{C}^{N}$ given for each index $n \\in \\{0,1,\\dots,N-1\\}$ by\n$$\nX_n = \\sum_{k=0}^{N-1} x_k \\exp\\!\\left(-\\frac{2\\pi \\mathrm{i}}{N} n k\\right).\n$$\nA circulant matrix $C(g) \\in \\mathbb{C}^{L \\times L}$ generated by a vector $g \\in \\mathbb{C}^{L}$ satisfies the property that its eigenvectors are the columns of the discrete Fourier matrix, and it is diagonalized by the Fast Fourier Transform (FFT), that is,\n$$\nC(g) = F_L^{-1} \\operatorname{diag}(F_L g)\\, F_L,\n$$\nwhere $F_L$ is the $L \\times L$ discrete Fourier transform matrix and $F_L^{-1}$ is its inverse. This property enables efficient circular convolution via FFT.\n\nBluestein’s algorithm (also known as the chirp-z method) reduces the computation of the DFT of length $N$ to a linear convolution of length at most $2N-1$, which can then be realized as a circular convolution of length $L \\ge 2N-1$ using a circulant matrix and computed efficiently via FFT. In this assignment, you must derive a correct implementation of Bluestein’s algorithm for prime-length inputs by reducing the DFT to convolution with a chirp sequence and embedding the linear convolution into a circular one, using the FFT to exploit circulant diagonalization. You must start from the fundamental definitions above and valid algebraic identities; you must not use pre-derived shortcut formulas.\n\nYou must write a complete program that:\n- Implements the DFT directly from its definition using $O(N^2)$ arithmetic, without invoking any optimized FFT routines for this part, to serve as a reference.\n- Implements Bluestein’s algorithm for the DFT for general $N$ (with special attention to the prime cases provided), by reducing the DFT to a linear convolution and then computing that convolution via circular convolution realized by a circulant matrix of length $L$, diagonalized by the FFT.\n- Chooses $L$ as the smallest power of two satisfying $L \\ge 2N-1$ for each test case.\n- Compares the Bluestein-based DFT result with the direct DFT and reports whether the maximum absolute entrywise discrepancy is below a prescribed tolerance.\n\nAll trigonometric functions in the program and in the definitions below must use angles expressed in radians.\n\nUse the following test suite, covering general and edge cases:\n- Test $1$: $N=2$, with $x_0 = 1$ and $x_1 = -\\mathrm{i}$.\n- Test $2$: $N=7$, with $x_0 = 1$ and $x_k = 0$ for all $k \\in \\{1,2,3,4,5,6\\}$.\n- Test $3$: $N=13$, with $x_k = k$ for all $k \\in \\{0,1,2,\\dots,12\\}$.\n- Test $4$: $N=1$, with $x_0 = 42$.\n- Test $5$: $N=29$, with $x_k = \\cos\\!\\left(\\frac{2\\pi k}{N}\\right) + \\mathrm{i}\\,\\sin\\!\\left(\\frac{4\\pi k}{N}\\right)$ for all $k \\in \\{0,1,2,\\dots,28\\}$.\n- Test $6$: $N=17$, with\n$$\nx_k = 0.3\\,\\sin(k) + 0.7\\,\\cos(k) + \\mathrm{i}\\,\\big(0.5\\,\\sin(k^2) - 0.2\\,\\cos(3k)\\big)\n$$\nfor all $k \\in \\{0,1,2,\\dots,16\\}$.\n\nFor each test case, compute the DFT via your Bluestein implementation and via the direct $O(N^2)$ DFT and calculate the maximum absolute difference\n$$\n\\Delta = \\max_{n \\in \\{0,1,\\dots,N-1\\}} \\big| X^{(\\mathrm{Bluestein})}_n - X^{(\\mathrm{Direct})}_n \\big|.\n$$\nUse the tolerance $\\varepsilon = 10^{-12}$ and return a boolean indicating whether $\\Delta < \\varepsilon$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $\\texttt{[result1,result2,\\dots]}$), where each entry is a boolean for the corresponding test case computed as specified above.",
            "solution": "The problem requires the implementation and verification of Bluestein's algorithm for computing the Discrete Fourier Transform (DFT), particularly for prime-length sequences. The solution must be derived from first principles, converting the DFT into a linear convolution, which is then computed via a circular convolution using the Fast Fourier Transform (FFT).\n\nThe DFT of a sequence $x \\in \\mathbb{C}^{N}$ is a sequence $X \\in \\mathbb{C}^{N}$ defined as:\n$$\nX_n = \\sum_{k=0}^{N-1} x_k \\exp\\left(-\\frac{2\\pi \\mathrm{i}}{N} n k\\right), \\quad \\text{for } n \\in \\{0, 1, \\dots, N-1\\}\n$$\nA direct, term-by-term computation of this sum for each $X_n$ requires $O(N)$ operations, leading to a total complexity of $O(N^2)$ for the entire transform. This direct method will serve as our reference for validation.\n\nBluestein's algorithm reformulates the DFT to leverage the computational efficiency of the FFT. The key insight is to express the product $nk$ in the exponent using a quadratic identity, known as a polarization identity:\n$$\n2nk = n^2 + k^2 - (n-k)^2\n$$\nSubstituting this into the exponent of the DFT definition gives:\n$$\nX_n = \\sum_{k=0}^{N-1} x_k \\exp\\left(-\\frac{\\pi \\mathrm{i}}{N} (n^2 + k^2 - (n-k)^2)\\right)\n$$\nWe can factor the exponential term to separate dependencies on $n$, $k$, and $(n-k)$:\n$$\nX_n = \\sum_{k=0}^{N-1} x_k \\exp\\left(-\\frac{\\pi \\mathrm{i} n^2}{N}\\right) \\exp\\left(-\\frac{\\pi \\mathrm{i} k^2}{N}\\right) \\exp\\left(\\frac{\\pi \\mathrm{i} (n-k)^2}{N}\\right)\n$$\nThe term $\\exp(- \\pi \\mathrm{i} n^2 / N)$ is constant with respect to the summation index $k$ and can be factored out:\n$$\nX_n = \\exp\\left(-\\frac{\\pi \\mathrm{i} n^2}{N}\\right) \\sum_{k=0}^{N-1} \\left(x_k \\exp\\left(-\\frac{\\pi \\mathrm{i} k^2}{N}\\right)\\right) \\exp\\left(\\frac{\\pi \\mathrm{i} (n-k)^2}{N}\\right)\n$$\nThis expression now has the form of a linear convolution. Let us define two sequences:\n1.  A pre-chirped input sequence $a$: $a_k = x_k \\exp\\left(-\\frac{\\pi \\mathrm{i} k^2}{N}\\right)$ for $k \\in \\{0, 1, \\dots, N-1\\}$.\n2.  A chirp sequence (the convolution kernel) $h$: $h_j = \\exp\\left(\\frac{\\pi \\mathrm{i} j^2}{N}\\right)$.\n\nWith these definitions, the DFT can be written as:\n$$\nX_n = h_n^* \\sum_{k=0}^{N-1} a_k h_{n-k}\n$$\nwhere $h_n^*$ is the complex conjugate of $h_n$. The summation is precisely the linear convolution of sequences $a$ and $h$, evaluated at index $n$, denoted as $(a * h)_n$. The required values for the index of $h$ range from $n-k = 0-(N-1) = -(N-1)$ to $n-k = (N-1)-0 = N-1$.\n\nThe linear convolution of two sequences of length $N$ can be computed efficiently by embedding it within a circular convolution of a greater length $L$. The length $L$ must be large enough to avoid time-domain aliasing, which means $L \\ge N + N - 1 = 2N - 1$. For optimal FFT performance, $L$ is typically chosen to be a power of two. The problem specifies choosing $L$ as the smallest power of two satisfying $L \\ge 2N-1$.\n\nTo compute the linear convolution using circular convolution, we define two new sequences, $a'$ and $h'$, of length $L$ by zero-padding $a$ and constructing a periodic version of $h$:\n*   $a'_k = a_k$ for $0 \\le k < N$, and $a'_k = 0$ for $N \\le k < L$.\n*   $h'_k = h_k$ for $0 \\le k < N$, and $h'_k = h_{k-L}$ for $L-(N-1) \\le k < L$, and $h'_k = 0$ otherwise. The term $h_{k-L}$ correctly captures the negative indices of the chirp kernel, e.g., $h'_{(L-1)} = h_{-1}$.\n\nThe circular convolution of $a'$ and $h'$ is given by the convolution theorem. As stated in the problem, a circulant matrix is diagonalized by the Fourier matrix, which implies that circular convolution in the time domain is equivalent to element-wise multiplication in the frequency domain. Let $F_L$ and $F_L^{-1}$ be the $L$-point DFT and inverse DFT operators, respectively. The resulting convolution sequence $c$ is:\n$$\nc = F_L^{-1} (F_L(a') \\odot F_L(h'))\n$$\nwhere $\\odot$ denotes element-wise multiplication. The first $N$ elements of this sequence $c$ correspond to the desired linear convolution values, i.e., $c_n = (a * h)_n$ for $n \\in \\{0, 1, \\dots, N-1\\}$.\n\nThe final step is to multiply by the post-chirp factor:\n$$\nX_n = c_n \\cdot h_n^* = c_n \\cdot \\exp\\left(-\\frac{\\pi \\mathrm{i} n^2}{N}\\right)\n$$\nThis completes the derivation of Bluestein's algorithm.\n\nThe full procedure is summarized as follows:\n1.  For a given input sequence $x$ of length $N$, determine the convolution length $L$ as the smallest power of two such that $L \\ge 2N-1$.\n2.  Compute the pre-chirped sequence $a_k = x_k \\exp(-\\pi \\mathrm{i} k^2/N)$ for $k \\in \\{0, \\dots, N-1\\}$.\n3.  Construct the padded kernel sequence $h'$ of length $L$ from the chirp $h_j = \\exp(\\pi \\mathrm{i} j^2/N)$.\n4.  Compute the FFTs of the padded sequence $a'$ and the kernel $h'$: $A' = F_L(a')$ and $H' = F_L(h')$.\n5.  Perform element-wise multiplication in the frequency domain: $C' = A' \\odot H'$.\n6.  Compute the inverse FFT to obtain the convolution result: $c = F_L^{-1}(C')$.\n7.  Extract the first $N$ elements of $c$ and multiply by the post-chirp factor $h_n^*$ to obtain the final DFT result $X_n$.\n\nThis algorithm is compared against a direct $O(N^2)$ implementation of the DFT definition to verify its correctness for the given test cases, using a maximum absolute error tolerance of $\\varepsilon = 10^{-12}$.",
            "answer": "```python\nimport numpy as np\n\ndef direct_dft(x: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Computes the DFT of a sequence x using the direct O(N^2) formula.\n    \"\"\"\n    N = len(x)\n    if N == 0:\n        return np.array([], dtype=np.complex128)\n    \n    n = np.arange(N)\n    k = np.arange(N)\n    \n    # Create the DFT matrix W where W_nk = exp(-2*pi*i*n*k/N)\n    nk = np.outer(n, k)\n    W = np.exp(-2j * np.pi * nk / N)\n    \n    # Compute the DFT via matrix-vector multiplication\n    X = np.dot(W, x)\n    return X\n\ndef bluestein_dft(x: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Computes the DFT of a sequence x using Bluestein's algorithm.\n    \"\"\"\n    N = len(x)\n\n    if N == 0:\n        return np.array([], dtype=np.complex128)\n    \n    # Base case N=1, DFT is identity.\n    if N == 1:\n        return x.copy()\n\n    # Step 1: Determine convolution length L\n    # L must be a power of two such that L >= 2*N - 1\n    M = 2 * N - 1\n    L = 1 << (M - 1).bit_length()\n\n    # Step 2: Create pre-chirped sequence 'a' and pad it to 'a_prime'\n    k = np.arange(N)\n    # The pre-chirp factor is exp(-i*pi*k^2/N)\n    pre_chirp = np.exp(-1j * np.pi * k**2 / N)\n    a = x * pre_chirp\n    \n    a_prime = np.zeros(L, dtype=np.complex128)\n    a_prime[:N] = a\n\n    # Step 3: Create the chirp filter sequence 'h_prime'\n    h_prime = np.zeros(L, dtype=np.complex128)\n    \n    # The kernel is h_k = exp(i*pi*k^2/N). We need it for k in [-(N-1), N-1].\n    # Positive indices part: k in [0, N-1]\n    k_pos = np.arange(N)\n    h_prime[k_pos] = np.exp(1j * np.pi * k_pos**2 / N)\n    \n    # Negative indices part: k in [-(N-1), -1], which are mapped to\n    # indices [L-(N-1), L-1] in the circular convolution.\n    if N > 1:\n        k_neg_indices = np.arange(L - N + 1, L)\n        # The conceptual negative indices are k_neg_indices - L\n        k_neg_values = k_neg_indices - L\n        h_prime[k_neg_indices] = np.exp(1j * np.pi * k_neg_values**2 / N)\n\n    # Step 4-6: Perform convolution via FFT\n    A_prime = np.fft.fft(a_prime)\n    H_prime = np.fft.fft(h_prime)\n    C_prime = A_prime * H_prime\n    c_conv = np.fft.ifft(C_prime)\n\n    # Step 7: Apply post-chirp factor and extract result\n    n = np.arange(N)\n    # The post-chirp factor is exp(-i*pi*n^2/N)\n    post_chirp = np.exp(-1j * np.pi * n**2 / N)\n    X = c_conv[:N] * post_chirp\n    \n    return X\n\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and produce the final output.\n    \"\"\"\n    test_cases = []\n\n    # Test 1: N=2\n    N1 = 2\n    x1 = np.array([1, -1j], dtype=np.complex128)\n    test_cases.append((N1, x1))\n\n    # Test 2: N=7\n    N2 = 7\n    x2 = np.zeros(N2, dtype=np.complex128)\n    x2[0] = 1\n    test_cases.append((N2, x2))\n\n    # Test 3: N=13\n    N3 = 13\n    x3 = np.arange(N3, dtype=np.complex128)\n    test_cases.append((N3, x3))\n\n    # Test 4: N=1\n    N4 = 1\n    x4 = np.array([42], dtype=np.complex128)\n    test_cases.append((N4, x4))\n\n    # Test 5: N=29\n    N5 = 29\n    k5 = np.arange(N5)\n    x5 = np.cos(2 * np.pi * k5 / N5) + 1j * np.sin(4 * np.pi * k5 / N5)\n    test_cases.append((N5, x5))\n\n    # Test 6: N=17\n    N6 = 17\n    k6 = np.arange(N6)\n    x6 = (0.3 * np.sin(k6) + 0.7 * np.cos(k6)) + \\\n         1j * (0.5 * np.sin(k6**2) - 0.2 * np.cos(3 * k6))\n    test_cases.append((N6, x6))\n\n    results = []\n    tolerance = 1e-12\n\n    for N, x in test_cases:\n        X_direct = direct_dft(x)\n        X_bluestein = bluestein_dft(x)\n        \n        # Calculate the maximum absolute entrywise discrepancy\n        delta = np.max(np.abs(X_bluestein - X_direct))\n        \n        # Append boolean result to the list\n        results.append(delta < tolerance)\n    \n    # Print the final result in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "The spectral diagonalization of circulant matrices provides an elegant and efficient way to compute matrix functions, such as the Moore-Penrose pseudoinverse used in solving least-squares problems. In theory, this involves simply inverting the non-zero eigenvalues in the frequency domain. In practice, however, finite-precision arithmetic makes this approach numerically unstable when eigenvalues are close to zero, as small errors become greatly amplified. This advanced practice  guides you to diagnose this instability by measuring the loss of idempotency in a projection operator and then implement and compare two key regularization techniques—spectral truncation and Tikhonov filtering—to restore numerical robustness, a critical skill in modern scientific computing.",
            "id": "3545340",
            "problem": "You are given the task of analyzing the projection operator built from the Moore–Penrose pseudoinverse of a circulant matrix using the Discrete Fourier Transform (DFT) computed by the Fast Fourier Transform (FFT). Work in exact arithmetic would make the projection idempotent, but near-zero spectral values amplify roundoff in finite precision. Your goal is to derive, implement, and quantitatively assess how spectral smallness corrupts idempotency, and to design a frequency-domain regularization that restores approximate idempotency.\n\nFundamental base to use:\n- A circulant matrix $C \\in \\mathbb{C}^{n \\times n}$ generated by a first column $c \\in \\mathbb{C}^{n}$ is unitarily diagonalized by the unitary DFT matrix $F \\in \\mathbb{C}^{n \\times n}$, satisfying $F^{*} F = I$. This yields $C = F^{*} \\,\\mathrm{diag}(\\lambda)\\, F$, where $\\lambda = F c$. \n- The Moore–Penrose pseudoinverse $C^{\\dagger}$ of $C$ is $C^{\\dagger} = F^{*}\\,\\mathrm{diag}(\\mu)\\,F$, where for each $k$ one has $\\mu_{k} = 1/\\lambda_{k}$ when $\\lambda_{k} \\neq 0$ and $\\mu_{k} = 0$ when $\\lambda_{k} = 0$.\n- The projection $P = C^{\\dagger} C$ is idempotent in exact arithmetic, i.e., $P^{2} = P$.\n\nTasks:\n1. Derive from the above base that the projection $P$ is also circulant and unitarily diagonalized by $F$, and relate its spectrum to $\\lambda$. Define $p \\in \\mathbb{C}^{n}$ as the frequency response of $P$ such that $P = F^{*}\\,\\mathrm{diag}(p)\\,F$, and then define an idempotency defect metric using the Frobenius norm,\n   $$\\mathcal{E}(P) \\equiv \\frac{\\lVert P^{2} - P \\rVert_{F}}{\\lVert P \\rVert_{F}},$$\n   and express it purely in terms of $p$ (no explicit dense matrices), using only properties of unitary similarity and the Frobenius norm.\n2. Using the FFT with unitary scaling (i.e., forward transform divided by $\\sqrt{n}$ and inverse multiplied by $\\sqrt{n}$), implement the following three spectral constructions of $p$ and compute the corresponding idempotency defect:\n   - Naive reciprocal with amplified roundoff. Let $\\lambda \\in \\mathbb{C}^{n}$ be obtained from $c$ by the unitary FFT. For each index $k$ with $\\lambda_{k} \\neq 0$, define a perturbed reciprocal\n     $$\\tilde{\\mu}_{k} = \\frac{1}{\\lambda_{k}}\\left(1 + \\delta_{k}\\right),$$\n     where the perturbation $\\delta_{k}$ models amplified roundoff with magnitude inversely proportional to $\\lvert \\lambda_{k} \\rvert$. Use\n     $$\\delta_{k} = \\xi_{k}\\,u\\,\\frac{\\tau}{\\max(\\lvert \\lambda_{k} \\rvert, 10^{-300})},$$\n     with machine unit roundoff $u$ for double precision, a specified threshold parameter $\\tau > 0$, and real $\\xi_{k}$ drawn from a standard normal distribution with a fixed random seed for reproducibility. For $\\lambda_{k} = 0$, set $\\tilde{\\mu}_{k} = 0$. Then set\n     $$\\tilde{p}_{k} = \\tilde{\\mu}_{k}\\,\\lambda_{k}.$$\n     Compute $\\mathcal{E}$ for $p = \\tilde{p}$.\n   - Truncated spectral pseudoinverse (hard thresholding). Define\n     $$\\mu^{(\\tau)}_{k} = \\begin{cases} \\frac{1}{\\lambda_{k}}, & \\lvert \\lambda_{k} \\rvert \\ge \\tau \\\\ 0, & \\lvert \\lambda_{k} \\rvert < \\tau \\end{cases}, \\quad p^{(\\tau)}_{k} = \\mu^{(\\tau)}_{k}\\,\\lambda_{k}.$$\n   - Tikhonov-type smoothing in the frequency domain. Define\n     $$p^{(\\alpha)}_{k} = \\frac{\\lvert \\lambda_{k} \\rvert^{2}}{\\lvert \\lambda_{k} \\rvert^{2} + \\alpha},$$\n     with a given parameter $\\alpha > 0$ (you will use $\\alpha = \\tau^{2}$ in the tests). Compute $\\mathcal{E}$ for $p = p^{(\\alpha)}$.\n3. Implement all computations via the FFT in the frequency domain. Do not form any dense $n \\times n$ matrices. Your idempotency defect must be computed only from the spectral vector $p$ using your result from Task 1.\n4. Test suite. For each of the following four cases, compute and report the triple of idempotency defects $[\\mathcal{E}_{\\mathrm{naive}}, \\mathcal{E}_{\\mathrm{trunc}}, \\mathcal{E}_{\\mathrm{tikh}}]$:\n   - Case A (exact zero mode present): $n=8$, $c = [2,\\,1,\\,0,\\,0,\\,0,\\,0,\\,0,\\,1]^{\\top}$, $\\tau = 1\\times 10^{-8}$, $\\alpha = \\tau^{2}$, use random seed $0$ for the perturbations.\n   - Case B (near-zero mode at frequency $0$): $n=12$, $c = [\\,1,\\,-(1-10^{-12}),\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0\\,]^{\\top}$, $\\tau = 1\\times 10^{-8}$, $\\alpha = \\tau^{2}$, seed $1$.\n   - Case C (discrete second-difference spectrum with many small low frequencies): $n=4096$, $c = [\\,1,\\,-2,\\,1,\\,0,\\,\\ldots,\\,0\\,]^{\\top}$, $\\tau = 1\\times 10^{-5}$, $\\alpha = \\tau^{2}$, seed $2$.\n   - Case D (well-conditioned identity circulant): $n=5$, $c = [\\,1,\\,0,\\,0,\\,0,\\,0\\,]^{\\top}$, $\\tau = 1\\times 10^{-8}$, $\\alpha = \\tau^{2}$, seed $3$.\n   In all cases, interpret $c$ as complex with zero imaginary parts. Angles implicit in the DFT are in radians. Use double-precision arithmetic. For the unit roundoff, take $u = 2^{-53}$.\n5. Final output format. Your program should produce a single line of output containing the results as a comma-separated list of four inner lists, each inner list being the triple for a test case in the order A, B, C, D. For example,\n   $$[ [x_{A},y_{A},z_{A}], [x_{B},y_{B},z_{B}], [x_{C},y_{C},z_{C}], [x_{D},y_{D},z_{D}] ],$$\n   where each symbol is a floating-point number. Do not print any extra text.\n\nNotes:\n- Do not use any dense $n \\times n$ matrices; the derivation in Task 1 must justify how to compute the Frobenius norms directly from spectral data.\n- Your implementation must rely on the Fast Fourier Transform to obtain $\\lambda$ from $c$ with unitary normalization.\n- The answer values have no physical units.",
            "solution": "The problem requires an analysis of the idempotency of a projection operator derived from a circulant matrix. Specifically, we must derive a formula for an idempotency defect metric in the spectral domain and then implement and compare three different numerical strategies for constructing the projection: a naive approach susceptible to roundoff error, a hard-thresholding approach, and a Tikhonov regularization approach.\n\n### Task 1: Derivation of the Idempotency Defect in the Spectral Domain\n\nLet $C \\in \\mathbb{C}^{n \\times n}$ be a circulant matrix generated by its first column $c \\in \\mathbb{C}^n$. It is diagonalized by the unitary Discrete Fourier Transform (DFT) matrix $F \\in \\mathbb{C}^{n \\times n}$ as $C = F^* \\mathrm{diag}(\\lambda) F$, where $\\lambda = F c$ is the vector of eigenvalues (the spectrum) of $C$. The Moore-Penrose pseudoinverse $C^\\dagger$ is given by $C^\\dagger = F^* \\mathrm{diag}(\\mu) F$, where the elements of the spectral vector $\\mu$ are defined as $\\mu_k = 1/\\lambda_k$ if $\\lambda_k \\neq 0$ and $\\mu_k = 0$ if $\\lambda_k = 0$.\n\nThe projection operator onto the range of $C$ is $P = C^\\dagger C$. We can express $P$ in terms of the spectral representations of $C$ and $C^\\dagger$:\n$$\nP = C^\\dagger C = \\left( F^* \\mathrm{diag}(\\mu) F \\right) \\left( F^* \\mathrmdiag(\\lambda) F \\right)\n$$\nSince $F$ is unitary, $F F^* = I$, where $I$ is the identity matrix.\n$$\nP = F^* \\mathrm{diag}(\\mu) (F F^*) \\mathrm{diag}(\\lambda) F = F^* \\mathrm{diag}(\\mu) \\mathrm{diag}(\\lambda) F\n$$\nThe product of two diagonal matrices is a diagonal matrix whose elements are the products of the corresponding diagonal elements. Let $p \\in \\mathbb{C}^n$ be a vector such that $p_k = \\mu_k \\lambda_k$ for each $k$. Then, $\\mathrm{diag}(p) = \\mathrm{diag}(\\mu) \\mathrm{diag}(\\lambda)$, and we have:\n$$\nP = F^* \\mathrm{diag}(p) F\n$$\nThis equation shows that $P$ is also diagonalized by the DFT matrix $F$. A matrix is circulant if and only if it is diagonalized by the DFT matrix. Therefore, $P$ is a circulant matrix, and its spectrum is given by the vector $p$.\n\nIn exact arithmetic, for any $k$:\n- If $\\lambda_k \\neq 0$, then $\\mu_k = 1/\\lambda_k$, so $p_k = (1/\\lambda_k) \\lambda_k = 1$.\n- If $\\lambda_k = 0$, then $\\mu_k = 0$, so $p_k = 0 \\cdot 0 = 0$.\nThus, in exact arithmetic, the spectrum $p$ of the projection $P$ consists only of $0$s and $1$s.\n\nThe idempotency defect is defined as $\\mathcal{E}(P) \\equiv \\frac{\\lVert P^{2} - P \\rVert_{F}}{\\lVert P \\rVert_{F}}$. We need to express this in terms of $p$. A key property of the Frobenius norm is its invariance under unitary transformations: for any matrix $A$ and unitary matrix $U$, $\\lVert U A U^* \\rVert_F = \\lVert A \\rVert_F$.\n\nFirst, consider the term $P^2 - P$:\n$$\nP^2 = \\left( F^* \\mathrm{diag}(p) F \\right) \\left( F^* \\mathrm{diag}(p) F \\right) = F^* \\mathrm{diag}(p)^2 F = F^* \\mathrm{diag}(p^2) F\n$$\nwhere $p^2$ is the element-wise square of the vector $p$.\nThen, the difference is:\n$$\nP^2 - P = F^* \\mathrm{diag}(p^2) F - F^* \\mathrm{diag}(p) F = F^* \\left( \\mathrm{diag}(p^2) - \\mathrm{diag}(p) \\right) F = F^* \\mathrm{diag}(p^2 - p) F\n$$\nUsing the unitary invariance of the Frobenius norm:\n$$\n\\lVert P^2 - P \\rVert_F = \\lVert F^* \\mathrm{diag}(p^2 - p) F \\rVert_F = \\lVert \\mathrm{diag}(p^2 - p) \\rVert_F\n$$\nThe Frobenius norm of a diagonal matrix is the Euclidean ($L_2$) norm of the vector of its diagonal elements.\n$$\n\\lVert \\mathrm{diag}(p^2 - p) \\rVert_F = \\sqrt{\\sum_{k=0}^{n-1} |p_k^2 - p_k|^2} = \\lVert p^2 - p \\rVert_2\n$$\n\nNext, consider the denominator term $\\lVert P \\rVert_F$:\n$$\n\\lVert P \\rVert_F = \\lVert F^* \\mathrm{diag}(p) F \\rVert_F = \\lVert \\mathrm{diag}(p) \\rVert_F = \\sqrt{\\sum_{k=0}^{n-1} |p_k|^2} = \\lVert p \\rVert_2\n$$\n\nCombining the numerator and denominator, we obtain the idempotency defect purely in terms of the spectral vector $p$:\n$$\n\\mathcal{E}(P) = \\frac{\\lVert p^2 - p \\rVert_2}{\\lVert p \\rVert_2}\n$$\nThis formula allows us to compute the defect without forming any dense $n \\times n$ matrices, fulfilling the requirements of the problem. If any $p_k$ deviates from $0$ or $1$ due to numerical error, the numerator $\\lVert p^2 - p \\rVert_2$ becomes non-zero, quantifying the loss of idempotency.\n\n### Computational Strategy and Implementation\n\nThe implementation will strictly follow the derived formula, performing all calculations in the frequency domain.\n\n1.  **Spectrum Calculation:** For each test case, the circulant generator vector $c$ is defined. Its spectrum, $\\lambda$, is computed using the Fast Fourier Transform (FFT) with unitary normalization, as provided by `numpy.fft.fft` with the argument `norm=\"ortho\"`.\n\n2.  **Spectral Constructions:** Three different spectral vectors for the projection, $p$, are constructed:\n    -   **Naive ($\\tilde{p}$):** A perturbed reciprocal $\\tilde{\\mu}$ is computed, modeling roundoff error amplification. The perturbation $\\delta_k = \\xi_k u \\tau / \\max(|\\lambda_k|, 10^{-300})$ is calculated, where $\\xi_k$ is a standard normal random variate, $u=2^{-53}$ is the machine epsilon for double precision, and $\\tau$ is a given threshold. Then, $\\tilde{p}_k = (1/\\lambda_k)(1+\\delta_k)\\lambda_k$ for $\\lambda_k \\neq 0$ and $\\tilde{p}_k=0$ for $\\lambda_k=0$. This construction is designed to fail dramatically for small, non-zero $|\\lambda_k|$.\n    -   **Truncated ($p^{(\\tau)}$):** A hard threshold $\\tau$ is applied. The reciprocal is taken only for eigenvalues with magnitude greater than or equal to $\\tau$; otherwise, it is set to zero. This results in $p_k^{(\\tau)} = 1$ if $|\\lambda_k| \\ge \\tau$ and $p_k^{(\\tau)} = 0$ if $|\\lambda_k| < \\tau$. This method sharply delineates which spectral components are kept, which should result in a spectral vector $p$ composed of values very close to $0$ and $1$, yielding a low idempotency defect.\n    -   **Tikhonov ($p^{(\\alpha)}$):** A smoothing filter is applied, $p_k^{(\\alpha)} = |\\lambda_k|^2 / (|\\lambda_k|^2 + \\alpha)$, where $\\alpha = \\tau^2$. This method transitions smoothly between passing high-magnitude eigenvalues ($p_k \\to 1$) and suppressing low-magnitude ones ($p_k \\to 0$). It introduces a systematic bias, as $p_k$ is never exactly $1$, trading perfect idempotency for numerical stability.\n\n3.  **Defect Calculation:** For each of the three resulting spectral vectors $p$, the idempotency defect $\\mathcal{E}$ is computed using the derived formula $\\mathcal{E}(P) = \\lVert p^2 - p \\rVert_2 / \\lVert p \\rVert_2$. A helper function encapsulates this calculation, using `numpy.linalg.norm` for the $L_2$ vector norms. The case where $\\lVert p \\rVert_2 = 0$ (corresponding to a zero projection matrix) is handled by defining the defect as $0$.\n\nThis strategy is applied to the four specified test cases, each designed to probe a different numerical scenario: a true zero eigenvalue, a near-zero eigenvalue, a spectrum with many small eigenvalues, and a well-conditioned spectrum.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for analyzing the idempotency defect\n    of circulant projection operators.\n    \"\"\"\n\n    def calculate_defect(p: np.ndarray) -> float:\n        \"\"\"\n        Computes the idempotency defect from the projection's spectrum 'p'.\n        E(P) = ||p^2 - p||_2 / ||p||_2\n        \"\"\"\n        norm_p = np.linalg.norm(p)\n        if norm_p == 0.0:\n            # The zero matrix is idempotent, its defect is 0.\n            return 0.0\n        \n        # Element-wise operation for p^2 - p\n        p_err = np.square(p) - p\n        norm_p_err = np.linalg.norm(p_err)\n        \n        return norm_p_err / norm_p\n\n    def compute_defects_for_case(c_vec: np.ndarray, n: int, tau: float, seed: int) -> list[float]:\n        \"\"\"\n        Computes the triple of idempotency defects [naive, truncated, tikhonov]\n        for a given circulant generator vector 'c' and parameters.\n        \"\"\"\n        u = 2**-53\n        alpha = tau**2\n        rng = np.random.default_rng(seed)\n\n        # Ensure c_vec is the correct size and complex type\n        c_full = np.zeros(n, dtype=np.complex128)\n        c_full[:len(c_vec)] = c_vec\n        \n        # Compute spectrum lambda using unitary FFT\n        lambda_vec = np.fft.fft(c_full, norm=\"ortho\")\n        lambda_abs = np.abs(lambda_vec)\n\n        # --- 1. Naive reciprocal with amplified roundoff ---\n        xi = rng.standard_normal(n)\n        # The perturbation delta is real-valued, as per problem spec (real xi_k)\n        delta = xi * u * tau / np.maximum(lambda_abs, 1e-300)\n        \n        mu_tilde = np.zeros_like(lambda_vec)\n        \n        # Handle non-zero and zero lambda_k as per the definition\n        nonzero_mask = lambda_vec != 0\n        mu_tilde[nonzero_mask] = (1.0 / lambda_vec[nonzero_mask]) * (1.0 + delta[nonzero_mask])\n        \n        p_naive = mu_tilde * lambda_vec\n        defect_naive = calculate_defect(p_naive)\n\n        # --- 2. Truncated spectral pseudoinverse (hard thresholding) ---\n        mu_trunc = np.zeros_like(lambda_vec)\n        strong_mask = lambda_abs >= tau\n        mu_trunc[strong_mask] = 1.0 / lambda_vec[strong_mask]\n        \n        p_trunc = mu_trunc * lambda_vec\n        defect_trunc = calculate_defect(p_trunc)\n\n        # --- 3. Tikhonov-type smoothing ---\n        lambda_abs_sq = np.square(lambda_abs)\n        p_tikh = lambda_abs_sq / (lambda_abs_sq + alpha)\n        defect_tikh = calculate_defect(p_tikh)\n\n        return [defect_naive, defect_trunc, defect_tikh]\n\n    # Definition of test cases from the problem statement\n    test_cases = [\n        { # Case A: exact zero mode\n            \"n\": 8,\n            \"c\": np.array([2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]),\n            \"tau\": 1e-8,\n            \"seed\": 0\n        },\n        { # Case B: near-zero mode at frequency 0\n            \"n\": 12,\n            \"c\": np.array([1.0, -(1.0 - 1e-12)]),\n            \"tau\": 1e-8,\n            \"seed\": 1\n        },\n        { # Case C: discrete second-difference with many small frequencies\n            \"n\": 4096,\n            \"c\": np.array([1.0, -2.0, 1.0]),\n            \"tau\": 1e-5,\n            \"seed\": 2\n        },\n        { # Case D: well-conditioned identity circulant\n            \"n\": 5,\n            \"c\": np.array([1.0]),\n            \"tau\": 1e-8,\n            \"seed\": 3\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result_triple = compute_defects_for_case(case[\"c\"], case[\"n\"], case[\"tau\"], case[\"seed\"])\n        all_results.append(result_triple)\n\n    # Format the final output string exactly as required\n    # Creates a list of strings like '[-1.2, 3.4, -5.6]'\n    inner_lists_str = [str(res) for res in all_results] \n    # Joins them with commas and wraps in brackets\n    output_str = f\"[{','.join(inner_lists_str)}]\"\n    \n    # Replace spaces added by str() for a compact representation if needed, \n    # but the example implies spaces are acceptable. Let's match python's default `str` behavior.\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}