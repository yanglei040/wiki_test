{
    "hands_on_practices": [
        {
            "introduction": "The Arnoldi process forms the core of IRAM, iteratively building a Krylov subspace to approximate eigenvectors. This exercise explores a special event called an \"exact breakdown,\" where the process terminates prematurely. By analyzing the Arnoldi relation when the breakdown condition $h_{m+1,m} = 0$ occurs, you will uncover why this is not a failure but a sign of exceptional success, revealing the discovery of a perfect invariant subspace .",
            "id": "3589863",
            "problem": "Consider a large, sparse, nonsymmetric matrix $A \\in \\mathbb{C}^{n \\times n}$ and the Arnoldi process applied to a nonzero starting vector $v_1 \\in \\mathbb{C}^{n}$ to construct an orthonormal basis $V_m = [v_1,\\dots,v_m] \\in \\mathbb{C}^{n \\times m}$ for the Krylov subspace $\\mathcal{K}_m(A,v_1) = \\mathrm{span}\\{v_1, Av_1, \\dots, A^{m-1} v_1\\}$. By the fundamental Arnoldi relations, there exists an upper Hessenberg matrix $H_m \\in \\mathbb{C}^{m \\times m}$ and a scalar $h_{m+1,m} \\in \\mathbb{C}$ such that\n$$\nA V_m \\;=\\; V_m H_m \\;+\\; h_{m+1,m} \\, v_{m+1} e_m^\\top,\n$$\nwhere $e_m \\in \\mathbb{R}^{m}$ is the $m$-th canonical basis vector and $v_{m+1} \\in \\mathbb{C}^{n}$ is the next Arnoldi vector. The case $h_{m+1,m} = 0$ is referred to as exact breakdown.\n\nUsing only the core definitions of the Arnoldi process and Krylov subspaces, and the characterization of exact breakdown via the displayed Arnoldi relation, reason about what $h_{m+1,m} = 0$ implies for the subspace $\\mathrm{span}(V_m)$ and for Ritz pairs, and explain how this situation is interpreted within the Implicitly Restarted Arnoldi Method (IRAM), defined here as a restarting strategy that uses implicit shifted orthogonal transformations (implicit QR steps with shifts) to filter and compress the Krylov subspace without explicitly forming powers of $A$.\n\nSelect all statements that are correct in this setting:\n\nA. If $h_{m+1,m} = 0$, then $A V_m = V_m H_m$, so $\\mathrm{span}(V_m)$ is an $A$-invariant subspace. Consequently, if $H_m y_i = \\theta_i y_i$ for some $y_i \\in \\mathbb{C}^{m}$, the Ritz pair $(\\theta_i, V_m y_i)$ is an exact eigenpair of $A$ with $A (V_m y_i) = \\theta_i (V_m y_i)$. In the Implicitly Restarted Arnoldi Method (IRAM), any subsequent implicit restart with shifts induces only an orthogonal change of basis within $\\mathrm{span}(V_m)$ and the process has effectively converged on that invariant subspace.\n\nB. If $h_{m+1,m} = 0$, then $H_m$ must be diagonal and equal to the restriction of $A$ to $\\mathrm{span}(V_m)$, implying that the Ritz vectors are exactly the canonical basis vectors $e_i$.\n\nC. If $h_{m+1,m} = 0$, then $\\mathcal{K}_m(A,v_1)$ is orthogonal to $A\\,\\mathcal{K}_m(A,v_1)$, which implies that $A$ is normal with respect to the Arnoldi basis and the Arnoldi process must be restarted with a different starting vector to avoid degeneracy.\n\nD. In the Implicitly Restarted Arnoldi Method (IRAM), if $h_{m+1,m} = 0$, choosing shifts at the unwanted Ritz values prevents the implicit QR step from being performed because the zero subdiagonal entry makes $H_m$ nonsimilar to its shifted forms, so the algorithm must increase $m$ to continue.",
            "solution": "The problem asks to analyze the consequences of an exact breakdown in the Arnoldi process, where $h_{m+1,m} = 0$. The premises and definitions provided are standard in numerical linear algebra, making the problem scientifically valid. Let's analyze the situation step by step.\n\n1.  **Implication of Exact Breakdown on the Arnoldi Relation:**\n    The fundamental Arnoldi relation is given as $A V_m = V_m H_m + h_{m+1,m} v_{m+1} e_m^\\top$.\n    If an exact breakdown occurs, $h_{m+1,m} = 0$. The relation simplifies to:\n    $$A V_m = V_m H_m$$\n    This is a crucial result. It means that the action of $A$ on any vector in the basis $V_m$ can be expressed as a linear combination of vectors within that same basis.\n\n2.  **Implication for the Krylov Subspace $\\mathcal{K}_m(A, v_1) = \\mathrm{span}(V_m)$:**\n    The equation $A V_m = V_m H_m$ shows that for any vector $x \\in \\mathrm{span}(V_m)$, the vector $Ax$ is also in $\\mathrm{span}(V_m)$. To see this, let $x = V_m c$ for some coefficient vector $c \\in \\mathbb{C}^m$. Then $Ax = A(V_m c) = (AV_m)c = (V_m H_m)c = V_m (H_m c)$. Since $H_m c$ is just another vector in $\\mathbb{C}^m$, say $d = H_m c$, then $Ax = V_m d$, which is clearly in $\\mathrm{span}(V_m)$.\n    A subspace $\\mathcal{S}$ for which $A\\mathcal{S} \\subseteq \\mathcal{S}$ is, by definition, an **$A$-invariant subspace**. Thus, an exact breakdown signals that the Arnoldi process has found an $m$-dimensional invariant subspace of $A$.\n\n3.  **Implication for Ritz Pairs:**\n    A Ritz pair is of the form $(\\theta_i, u_i)$ where $u_i = V_m y_i$ and $(\\theta_i, y_i)$ is an eigenpair of $H_m$, so $H_m y_i = \\theta_i y_i$. Let's check if this is an eigenpair of $A$:\n    $$A u_i = A (V_m y_i) = (A V_m) y_i$$\n    Using the simplified Arnoldi relation from the breakdown:\n    $$A u_i = (V_m H_m) y_i = V_m (H_m y_i) = V_m (\\theta_i y_i) = \\theta_i (V_m y_i) = \\theta_i u_i$$\n    The equation $A u_i = \\theta_i u_i$ is satisfied exactly. This means that all $m$ Ritz pairs derived from $H_m$ are exact eigenpairs of the original matrix $A$. This is why an exact breakdown is often called a \"lucky breakdown\"—it is a sign of complete success in finding a part of the spectrum.\n\n4.  **Implication for IRAM:**\n    An implicit restart with shifts applies an orthogonal similarity transformation to $H_m$, resulting in $H_m' = Q^* H_m Q$, and transforms the basis to $V_m' = V_m Q$. Since $Q$ is an invertible matrix, the span of the columns of $V_m'$ is the same as the span of the columns of $V_m$. The restart process only performs a change of basis within the already-discovered invariant subspace. The process has effectively converged on this subspace and cannot be extended further.\n\nNow, we evaluate the options:\n\n*   **A. Correct.** This statement accurately summarizes all the points derived above. The condition $h_{m+1,m} = 0$ implies $A V_m = V_m H_m$, which means $\\mathrm{span}(V_m)$ is an $A$-invariant subspace. It correctly states that the Ritz pairs become exact eigenpairs. Finally, it correctly concludes that an implicit restart only changes the basis within this invariant subspace, signifying convergence.\n\n*   **B. Incorrect.** While $H_m = V_m^\\ast A V_m$ is the restriction of $A$ to the subspace, it is not necessarily diagonal. $H_m$ is upper Hessenberg, and a breakdown does not impose further structure on it. The Ritz vectors are $V_m y_i$, not the canonical basis vectors, unless $H_m$ happens to be diagonal and the columns of $V_m$ are eigenvectors.\n\n*   **C. Incorrect.** The condition $h_{m+1,m}=0$ implies invariance ($A\\mathcal{K}_m \\subseteq \\mathcal{K}_m$), not orthogonality ($A\\mathcal{K}_m \\perp \\mathcal{K}_m$). The latter is a much stronger condition that is generally not true. Restarting with a different vector is only necessary if the invariant subspace found does not contain the desired eigenvalues, but the process itself has terminated for the given starting vector.\n\n*   **D. Incorrect.** This statement contains multiple errors. The quantity $h_{m+1,m}$ is not a subdiagonal entry of $H_m$. The implicit QR step is a sequence of similarity transformations and can always be applied to $H_m$. Most importantly, after a breakdown, the Krylov subspace is \"full\" for the given starting vector, and its dimension $m$ cannot be increased.\n\nTherefore, only statement A is correct.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Moving from theory to practice requires implementing robust stopping criteria, as exact convergence is rare. This comprehensive exercise challenges you to build a practical IRAM solver that incorporates a sophisticated a posteriori error estimator to decide when a Ritz pair is \"good enough.\" You will integrate this estimator not only to declare convergence but also to create a smart \"shift acceptance test\" that prevents the restart process from destabilizing already-converged solutions .",
            "id": "3589838",
            "problem": "You are asked to design and implement an a posteriori error estimator for Ritz eigenpairs in the Implicitly Restarted Arnoldi Method (IRAM), and to integrate it into both the stopping rule for convergence and a shift acceptance test during restarts. Your final answer must be a complete, runnable program that computes, for a specified test suite of matrices and IRAM parameters, the number of converged eigenpairs, the maximum a posteriori estimator among the accepted eigenpairs, and the number of rejected shifts due to the shift acceptance test. The output must be a single line containing a nested list as specified below.\n\nStart from the following fundamental base in numerical linear algebra:\n- The Arnoldi factorization: given a matrix $A \\in \\mathbb{C}^{n \\times n}$ and a starting unit vector $v_{1}$, one step of Arnoldi constructs an orthonormal basis $V_{m+1} = [v_{1},\\dots,v_{m+1}] \\in \\mathbb{C}^{n \\times (m+1)}$ and an upper Hessenberg matrix $H \\in \\mathbb{C}^{(m+1) \\times m}$ such that\n$$\nA V_{m} = V_{m+1} \\bar{H},\n$$\nwhere $V_{m}$ consists of the first $m$ columns of $V_{m+1}$ and $\\bar{H}$ is the leading $(m+1) \\times m$ part of $H$ with subdiagonal entry $h_{m+1,m}$.\n- Ritz pairs: if $(\\theta, z)$ is an eigenpair of $H_{m} \\in \\mathbb{C}^{m \\times m}$, then $(\\theta, y)$ with $y = V_{m} z$ is a Ritz pair for $A$ in the Krylov subspace $\\mathcal{K}_{m}(A, v_{1})$; the corresponding residual is $r = A y - \\theta y$ and satisfies\n$$\n\\|r\\|_{2} = |h_{m+1,m}| \\cdot |e_{m}^{\\top} z|,\n$$\nwhere $e_{m} \\in \\mathbb{R}^{m}$ is the $m$-th canonical basis vector.\n- Separation: for a simple target eigenvalue $\\theta$ of a normal matrix $A$, a standard a posteriori bound is\n$$\n\\sin(\\angle(y, \\mathcal{X})) \\le \\frac{\\|r\\|_{2}}{\\operatorname{sep}(\\theta, \\Lambda(A)\\setminus\\{\\theta\\})},\n$$\nwhere $\\mathcal{X}$ is the invariant subspace associated with $\\theta$, and $\\operatorname{sep}(\\theta, \\Lambda(A)\\setminus\\{\\theta\\})$ is the distance from $\\theta$ to the rest of the spectrum. In practice, $\\operatorname{sep}$ is unknown; one replaces it with an estimable proxy from computed Ritz values.\n\nYour task is to:\n- Derive and implement an a posteriori estimator\n$$\n\\eta(\\theta, y) = \\frac{\\|r\\|_{2}}{\\widehat{\\operatorname{sep}}(\\theta)},\n$$\nwhere $\\|r\\|_{2}$ is as above and $\\widehat{\\operatorname{sep}}(\\theta)$ is a computable separation proxy based only on current Ritz values (and any previously “locked” Ritz values).\n- Integrate this estimator into:\n  1. A stopping criterion that declares a Ritz pair $(\\theta, y)$ converged when $\\eta(\\theta, y) \\le \\tau$ for a user-provided tolerance $\\tau$.\n  2. A shift acceptance test for IRAM restarts that rejects a proposed shift $\\mu$ if it is too close to any already accepted “locked” eigenvalue $\\theta_{\\ell}$ relative to the corresponding estimator. Specifically, reject $\\mu$ whenever\n  $$\n  |\\mu - \\theta_{\\ell}| < \\gamma \\cdot \\eta(\\theta_{\\ell}, y_{\\ell}) \\cdot \\widehat{\\operatorname{sep}}_{\\mathrm{guard}}(\\theta_{\\ell}),\n  $$\n  for a fixed guard factor $\\gamma > 0$ and a guard separation proxy $\\widehat{\\operatorname{sep}}_{\\mathrm{guard}}(\\theta_{\\ell})$ derived from available Ritz information. Upon rejection, replace $\\mu$ with a modified shift that moves it at least this guarded distance away, and count the rejection.\n\nAlgorithmic constraints and deliverables:\n- Implement an IRAM-like restarted Arnoldi scheme that:\n  - Builds an Arnoldi factorization of length $m$.\n  - Computes Ritz pairs and residual norms using the Arnoldi relation.\n  - Uses the estimator $\\eta$ to lock converged Ritz pairs, orthogonalizing the Krylov subspace against the locked subspace in subsequent cycles.\n  - Selects $p = m - k$ shifts from the “unwanted” Ritz values according to the choice of largest magnitude targets, applies a restart by filtering the starting vector with the polynomial $\\prod_{j=1}^{p} (A - \\mu_{j} I)$, and enforces the shift acceptance test with rejections counted.\n- Your estimator must be computed as follows:\n  - For each Ritz value $\\theta$, define\n    $$\n    \\widehat{\\operatorname{sep}}(\\theta) = \\min_{\\nu \\in \\mathcal{S}(\\theta)} |\\theta - \\nu|,\n    $$\n    where $\\mathcal{S}(\\theta)$ is the set of all other current Ritz values together with any locked Ritz values, excluding $\\theta$ itself. If $\\mathcal{S}(\\theta)$ is empty, set $\\widehat{\\operatorname{sep}}(\\theta)$ to a tiny positive number to avoid division by zero.\n  - Let $\\|r\\|_{2} = |h_{m+1,m}| \\cdot |e_{m}^{\\top} z|$ for the corresponding eigenvector $z$ of $H_{m}$.\n  - Then $\\eta(\\theta, y) = \\|r\\|_{2} / \\widehat{\\operatorname{sep}}(\\theta)$.\n- Use the estimator in the shift acceptance test with a guard factor $\\gamma = 2$.\n\nImplementation details:\n- Construct three test cases with the following matrices and parameters. All dimensions and parameters are expressed as plain numbers, but all numbers in the mathematical expressions above must be treated symbolically; there are no physical units in this problem.\n  1. Symmetric tridiagonal Laplacian: $A_{1} \\in \\mathbb{R}^{n_{1} \\times n_{1}}$ with $n_{1} = 100$ and\n     $$\n     A_{1} = \\operatorname{tridiag}(-1, 2, -1),\n     $$\n     i.e., $2$ on the diagonal and $-1$ on the first sub- and super-diagonals. Target $k_{1} = 3$ eigenpairs of largest magnitude. Use Arnoldi dimension $m_{1} = 25$, maximum outer restarts $I_{1} = 200$, and tolerance $\\tau_{1} = 10^{-8}$.\n  2. Clustered symmetric diagonal: $A_{2} \\in \\mathbb{R}^{n_{2} \\times n_{2}}$ with $n_{2} = 60$, diagonal entries\n     $$\n     \\operatorname{diag}(1,2,\\dots,57, 29.999, 30.000, 30.001),\n     $$\n     i.e., a cluster of three near the top. Target $k_{2} = 2$ eigenpairs of largest magnitude. Use $m_{2} = 20$, $I_{2} = 200$, and $\\tau_{2} = 10^{-6}$.\n  3. Non-normal upper bidiagonal: $A_{3} \\in \\mathbb{R}^{n_{3} \\times n_{3}}$ with $n_{3} = 80$, diagonal entries linearly spaced from $1$ to $50$, and constant superdiagonal entries equal to $5$. Target $k_{3} = 4$ eigenpairs of largest magnitude. Use $m_{3} = 25$, $I_{3} = 200$, and $\\tau_{3} = 10^{-8}$.\n\nYour program must:\n- For each test case, run the described IRAM-like restarted Arnoldi method with the estimator-driven convergence and shift acceptance. Orthogonalize against locked vectors when present.\n- For each test case, return a list with three entries:\n  1. The integer count of converged eigenpairs at termination (should be at most the target $k$).\n  2. The floating-point value of the maximum estimator $\\max \\eta$ among the locked eigenpairs at termination.\n  3. The integer count of rejected shifts due to the shift acceptance test across all restarts.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of lists enclosed in square brackets, for the three test cases in order. For example:\n\"[ [c1, e1, s1], [c2, e2, s2], [c3, e3, s3] ]\"\nwhere $c_{j}$ is the integer converged count, $e_{j}$ is the float maximum estimator, and $s_{j}$ is the integer rejection count for test case $j$.\n\nNo physical units are involved, so no unit specification is required. Angles are not used. All percentages, if any, must be expressed as decimals or fractions rather than using the percent sign; however, no percentages are required here.",
            "solution": "The task is to design and implement an Implicitly Restarted Arnoldi Method (IRAM) incorporating a specific a posteriori error estimator for both convergence assessment and a shift acceptance test. The solution is structured around the fundamental principles of Krylov subspace methods and eigenvalue computations.\n\n### 1. Arnoldi Factorization\n\nThe foundation of the method is the Arnoldi factorization. For a given matrix $A \\in \\mathbb{C}^{n \\times n}$ and a starting unit vector $v_1 \\in \\mathbb{C}^n$, the Arnoldi iteration constructs an orthonormal basis $V_m = [v_1, v_2, \\dots, v_m]$ for the Krylov subspace $\\mathcal{K}_m(A, v_1) = \\operatorname{span}\\{v_1, Av_1, \\dots, A^{m-1}v_1\\}$. This process simultaneously generates an upper Hessenberg matrix $H_m \\in \\mathbb{C}^{m \\times m}$. After $m$ steps, we obtain the Arnoldi factorization:\n$$A V_m = V_m H_m + h_{m+1,m} v_{m+1} e_m^T$$\nwhere $V_{m+1} = [V_m, v_{m+1}]$, $e_m$ is the $m$-th canonical basis vector in $\\mathbb{R}^m$, and $h_{m+1,m} \\ge 0$ is a scalar. The vectors $v_j$ are generated via a Gram-Schmidt orthogonalization process. Specifically, for $j = 1, \\dots, m$:\n1. Compute $w = A v_j$.\n2. Orthogonalize $w$ against the previous basis vectors $\\{v_1, \\dots, v_j\\}$. For $i=1, \\dots, j$, set $h_{i,j} = v_i^H w$ and update $w \\leftarrow w - h_{i,j} v_i$.\n3. Compute the norm $h_{j+1,j} = \\|w\\|_2$.\n4. If $h_{j+1,j}$ is close to zero (a breakdown), the process may stop. Otherwise, normalize to get the next vector: $v_{j+1} = w / h_{j+1,j}$.\n\n### 2. Ritz Pairs, Residuals, and Error Estimation\n\nThe eigenpairs of the small Hessenberg matrix $H_m$ provide approximations to the eigenpairs of the large matrix $A$. If $(\\theta, z)$ is an eigenpair of $H_m$, i.e., $H_m z = \\theta z$ with $\\|z\\|_2 = 1$, then the pair $(\\theta, y)$ with $y = V_m z$ is called a Ritz pair of $A$. The value $\\theta$ is a Ritz value and $y$ is a Ritz vector.\n\nThe residual $r = Ay - \\theta y$ measures how well the Ritz pair satisfies the eigenvalue equation for $A$. A crucial property of the Arnoldi factorization is that the norm of this residual can be computed cheaply without forming the $n$-dimensional vector $y$:\n$$ \\|r\\|_2 = \\|AV_m z - \\theta V_m z\\|_2 = \\|(V_m H_m + h_{m+1,m} v_{m+1} e_m^T)z - V_m (\\theta z)\\|_2 $$\n$$ \\|r\\|_2 = \\|V_m(H_m z - \\theta z) + h_{m+1,m} v_{m+1} (e_m^T z)\\|_2 = \\|h_{m+1,m} (e_m^T z) v_{m+1}\\|_2 = |h_{m+1,m}| \\cdot |e_m^T z| $$\nThis formula provides the exact residual norm for the Ritz pair.\n\nThe problem requires constructing an a posteriori error estimator $\\eta(\\theta, y)$. This estimator is inspired by bounds on the angle between the Ritz vector and the true invariant subspace, which often involve the separation of the eigenvalue from the rest of the spectrum. We define the estimator as:\n$$ \\eta(\\theta, y) = \\frac{\\|r\\|_2}{\\widehat{\\operatorname{sep}}(\\theta)} $$\nwhere the separation proxy $\\widehat{\\operatorname{sep}}(\\theta)$ is computed from the available Ritz values:\n$$ \\widehat{\\operatorname{sep}}(\\theta) = \\min_{\\nu \\in \\mathcal{S}(\\theta)} |\\theta - \\nu| $$\nThe set $\\mathcal{S}(\\theta)$ comprises all other current Ritz values from the $m \\times m$ analysis, plus any previously computed and \"locked\" eigenvalues. If $\\mathcal{S}(\\theta)$ is empty, $\\widehat{\\operatorname{sep}}(\\theta)$ is set to a small positive constant to prevent division by zero.\n\n### 3. Convergence and Locking\n\nA Ritz pair $(\\theta, y)$ is declared \"converged\" and is \"locked\" if its estimator value is below a given tolerance $\\tau$:\n$$ \\eta(\\theta, y) \\le \\tau $$\nOnce a Ritz pair is locked, its Ritz vector is stored. The subsequent Arnoldi iterations are carried out in a subspace orthogonal to the space spanned by all locked Ritz vectors. This is achieved by explicitly orthogonalizing each new vector $w=Av_j$ against the locked vectors before the standard Gram-Schmidt procedure. Let $W_{\\text{lock}}$ be the matrix whose columns are the locked orthonormalized Ritz vectors. Then the projection is $w \\leftarrow w - W_{\\text{lock}}(W_{\\text{lock}}^H w)$.\n\n### 4. Implicit Restart and Shift Acceptance\n\nIRAM combines the Arnoldi factorization with a restarting mechanism to maintain a fixed-size Krylov subspace, which saves memory and computational cost. After an Arnoldi factorization of size $m$ is built, we seek to distill the most valuable spectral information into a smaller factorization of size $k < m$. This is done by implicitly applying a filter polynomial to the starting vector.\n\nThe process is as follows:\n1.  **Shift Selection**: From the $m$ computed Ritz values, $k$ are identified as \"wanted\" (e.g., those with largest magnitude, as required by the problem) and $p=m-k$ are \"unwanted\". These $p$ unwanted Ritz values, $\\{\\mu_1, \\dots, \\mu_p\\}$, are used as shifts for the implicit QR algorithm.\n2.  **Shift Acceptance Test**: Before using the shifts, each proposed shift $\\mu_j$ is tested. The problem specifies a novel test to prevent shifts from falling too close to already converged \"locked\" eigenvalues $\\theta_\\ell$. A shift $\\mu$ is rejected if for any locked eigenvalue $\\theta_\\ell$:\n    $$ |\\mu - \\theta_\\ell| < \\gamma \\cdot \\eta_\\ell \\cdot \\widehat{\\operatorname{sep}}_{\\mathrm{guard}}(\\theta_\\ell) $$\n    where $\\gamma=2$ is a guard factor, $\\eta_\\ell$ is the stored estimator for the locked pair, and $\\widehat{\\operatorname{sep}}_{\\mathrm{guard}}(\\theta_\\ell)$ is a separation proxy for $\\theta_\\ell$ computed using all Ritz values currently available (both locked and from the latest $m$-step factorization). If a shift is rejected, it is replaced by a modified value that is moved to the boundary of this exclusion region, and a counter for rejected shifts is incremented.\n3.  **QR Chase**: The $p$ (possibly modified) shifts are used to perform $p$ steps of the implicitly shifted QR algorithm on the Hessenberg matrix $H_m$. If $H_m^{(0)} = H_m$, one step with shift $\\mu$ is:\n    $$ H_m^{(j-1)} - \\mu_j I = Q_j R_j \\quad \\implies \\quad H_m^{(j)} = R_j Q_j + \\mu_j I $$\n    The orthogonal transformations are accumulated into a single matrix $Q_{\\text{accum}} = Q_1 Q_2 \\dots Q_p$.\n4.  **Factorization Update**: The QR chase transforms the factorization. The original relation $A V_m = V_m H_m + \\beta v_{m+1} e_m^T$ is updated to a new, smaller factorization of size $k$: $A V'_k = V'_k H'_k + \\beta' v'_{k+1} e_k^T$. The new components are derived from the transformed matrices:\n    -   New basis for the size-$k$ subspace: $V'_k = V_m Q_{\\text{accum}}[:, :k]$\n    -   New size-$k$ Hessenberg matrix: $H'_k = H_m^{(p)}[:k, :k]$\n    -   New residual term scalar: $\\beta' = h'_{k+1,k}$, which is the entry $(k, k-1)$ (0-indexed) of $H_m^{(p)}$.\n    -   New residual vector: $v'_{k+1} = (V_m Q_{\\text{accum}})[:, k]$.\nThis new size-$k$ factorization serves as the starting point for the next Arnoldi expansion cycle.\n\n### 5. Algorithm Summary\n\nThe complete IRAM procedure integrates these components into an iterative loop:\n\n1.  **Initialize**: Start with a random unit vector $v_1$ and an empty set of locked eigenpairs. Set counters to zero.\n2.  **Outer Loop**: Repeat for a maximum number of restarts or until convergence.\n    a. **Arnoldi Expansion**: If the current factorization has size less than $m$, expand it to size $m$ using the Arnoldi process described in Section 1, ensuring orthogonality against any locked vectors.\n    b. **Eigenanalysis**: Compute Ritz pairs $(\\theta_j, y_j)$ from the $m \\times m$ Hessenberg matrix $H_m$.\n    c. **Convergence Check**: For each Ritz pair, compute the residual norm $\\|r_j\\|_2$ and the estimator $\\eta_j$. Identify newly converged pairs where $\\eta_j \\le \\tau$.\n    d. **Locking**: Add newly converged pairs to the locked set. If the number of locked pairs reaches the target $k$, terminate successfully.\n    e. **Restart**: If not converged, prepare for restart.\n        i. Select $p = m - k$ unwanted Ritz values as shifts.\n        ii. Apply the shift acceptance test, modifying shifts and counting rejections as needed.\n        iii. Perform the QR chase on $H_m$ with the chosen shifts to get $H'_m$ and $Q_{\\text{accum}}$.\n        iv. Update the factorization to a new one of size $k$ as described in Section 4. This provides the starting point for the next expansion step.\n3.  **Termination**: When the loop finishes, report the number of converged eigenpairs, the maximum estimator value among them, and the total count of rejected shifts.",
            "answer": "```python\nimport numpy as np\n\ndef run_iram_case(A, k, m, max_restarts, tol):\n    \"\"\"\n    Implements the Implicitly Restarted Arnoldi Method with a custom error estimator.\n\n    Args:\n        A (np.ndarray): The matrix for which to find eigenvalues.\n        k (int): The number of eigenvalues to find.\n        m (int): The dimension of the Arnoldi factorization (m > k).\n        max_restarts (int): The maximum number of restart iterations.\n        tol (float): The convergence tolerance for the estimator.\n\n    Returns:\n        tuple: (number of converged pairs, max estimator value, number of rejected shifts).\n    \"\"\"\n    n = A.shape[0]\n    \n    # Use complex numbers to handle non-symmetric cases\n    locked_V = np.zeros((n, 0), dtype=np.complex128)\n    locked_thetas = []\n    locked_etas = []\n    rejected_shifts = 0\n\n    # Initial Arnoldi factorization of size 1\n    v = np.random.rand(n)\n    if A.dtype != np.complex128:\n        v = v.astype(A.dtype) # match types if possible early\n    v = v / np.linalg.norm(v)\n\n    V = np.zeros((n, m + 1), dtype=np.complex128)\n    H = np.zeros((m + 1, m), dtype=np.complex128)\n    V[:, 0] = v\n    \n    current_m = 0\n\n    for i_restart in range(max_restarts):\n        # 1. Arnoldi expansion from current_m to m\n        start_j = current_m\n        for j in range(start_j, m):\n            w = A @ V[:, j]\n            w = w.astype(np.complex128)\n\n            if locked_V.shape[1] > 0:\n                w -= locked_V @ (locked_V.conj().T @ w)\n\n            # Modified Gram-Schmidt against current Arnoldi vectors\n            for l in range(j + 1):\n                h_lj = V[:, l].conj().T @ w\n                w -= h_lj * V[:, l]\n                H[l, j] = h_lj\n            \n            h_jp1_j = np.linalg.norm(w)\n            H[j + 1, j] = h_jp1_j\n\n            if h_jp1_j  1e-12:  # Breakdown\n                m = j + 1 # Reduce m dynamically\n                H = H[:m+1, :m]\n                V = V[:, :m+1]\n                break\n            \n            V[:, j + 1] = w / h_jp1_j\n        \n        # 2. Eigen-analysis of H_m\n        H_m = H[:m, :m]\n        try:\n            thetas, Z = np.linalg.eig(H_m)\n        except np.linalg.LinAlgError:\n            break # Eigendecomposition failed, terminate\n\n        # 3. Compute estimator and check convergence\n        res_norms = np.abs(H[m, m-1] * Z[m-1, :])\n        all_potential_ritz = list(thetas) + locked_thetas\n        \n        newly_converged_indices = []\n        etas = np.full(m, np.inf, dtype=float)\n\n        for j in range(m):\n            theta_j = thetas[j]\n            is_already_locked = any(np.isclose(theta_j, lt) for lt in locked_thetas)\n            if is_already_locked:\n                continue\n\n            other_vals = [nu for nu in all_potential_ritz if not np.isclose(nu, theta_j)]\n            if not other_vals:\n                sep_j = np.finfo(float).eps\n            else:\n                sep_j = np.min(np.abs(theta_j - np.array(other_vals)))\n            \n            if sep_j > np.finfo(float).eps:\n                etas[j] = res_norms[j] / sep_j\n            \n            if etas[j] = tol:\n                newly_converged_indices.append(j)\n\n        # 4. Locking\n        if newly_converged_indices:\n            sorted_new_indices = sorted(newly_converged_indices, key=lambda j: res_norms[j])\n            \n            \n            can_lock_count = k - len(locked_thetas)\n            for j in sorted_new_indices[:can_lock_count]:\n                theta_j, z_j, eta_j = thetas[j], Z[:, j], etas[j]\n                \n                y_j = V[:, :m] @ z_j\n                y_j /= np.linalg.norm(y_j)\n\n                new_locked_V = np.hstack([locked_V, y_j[:, np.newaxis]])\n                if new_locked_V.shape[1] > 1:\n                    Q_lock, _ = np.linalg.qr(new_locked_V)\n                    locked_V = Q_lock\n                else:\n                    locked_V = new_locked_V\n\n                locked_thetas.append(theta_j)\n                locked_etas.append(eta_j)\n\n        # 5. Termination check\n        if len(locked_thetas) >= k:\n            break\n\n        # 6. Restart Preparation\n        # For largest magnitude, unwanted shifts are smallest magnitude Ritz values.\n        sort_indices = np.argsort(np.abs(thetas))\n        unwanted_indices = sort_indices[:m - k]\n        shifts = thetas[unwanted_indices]\n        \n        # 7. Shift Acceptance Test\n        gamma = 2.0\n        current_ritz_and_locked = list(thetas) + locked_thetas\n        modified_shifts = []\n        for mu in shifts:\n            is_rejected = False\n            for idx_l, theta_l in enumerate(locked_thetas):\n                eta_l = locked_etas[idx_l]\n                \n                other_vals_guard = [nu for nu in current_ritz_and_locked if not np.isclose(nu, theta_l)]\n                if not other_vals_guard:\n                    sep_guard = np.finfo(float).eps\n                else:\n                    sep_guard = np.min(np.abs(theta_l - np.array(other_vals_guard)))\n                \n                if sep_guard  np.finfo(float).eps: continue\n\n                guard_dist = gamma * eta_l * sep_guard\n                if np.abs(mu - theta_l)  guard_dist:\n                    rejected_shifts += 1\n                    direction = mu - theta_l\n                    if np.abs(direction)  1e-12:\n                        direction = 1.0\n                    mu = theta_l + direction / np.abs(direction) * guard_dist\n                    is_rejected = True\n                    break\n            modified_shifts.append(mu)\n        shifts = np.array(modified_shifts)\n\n        # 8. Implicit Restart (QR Chase)\n        H_chase = np.copy(H[:m, :m])\n        Q_accum = np.identity(m, dtype=np.complex128)\n        \n        for mu in shifts:\n            Q_qr, R_qr = np.linalg.qr(H_chase - mu * np.identity(m))\n            H_chase = R_qr @ Q_qr + mu * np.identity(m)\n            Q_accum = Q_accum @ Q_qr\n                \n        # 9. Update Factorization\n        V_old_m = V[:, :m]\n        beta = H[m, m-1]\n        v_m_plus_1 = V[:, m]\n\n        V_k_prime = V_old_m @ Q_accum[:, :k]\n        H_k_prime = H_chase[:k, :k]\n        beta_prime = H_chase[k, k-1]\n        v_kp1_prime = V_old_m @ Q_accum[:, k]\n        \n        V = np.zeros((n, m + 1), dtype=np.complex128)\n        H = np.zeros((m + 1, m), dtype=np.complex128)\n        \n        V[:, :k] = V_k_prime\n        V[:, k] = v_kp1_prime\n        H[:k, :k] = H_k_prime\n        H[k, k - 1] = beta_prime\n        \n        current_m = k\n    \n    num_converged = len(locked_thetas)\n    max_eta = max(locked_etas) if locked_etas else 0.0\n    \n    return num_converged, max_eta, rejected_shifts\n\n\ndef solve():\n    \"\"\"\n    Sets up and runs the three test cases specified in the problem.\n    \"\"\"\n    # Case 1\n    n1 = 100\n    A1 = np.diag(-1 * np.ones(n1 - 1), -1) + np.diag(2 * np.ones(n1), 0) + np.diag(-1 * np.ones(n1 - 1), 1)\n    k1, m1, I1, tau1 = 3, 25, 200, 1e-8\n\n    # Case 2\n    n2 = 60\n    diag_vals2 = list(range(1, 58)) + [29.999, 30.000, 30.001]\n    A2 = np.diag(np.sort(diag_vals2))\n    k2, m2, I2, tau2 = 2, 20, 200, 1e-6\n\n    # Case 3\n    n3 = 80\n    A3 = np.diag(np.linspace(1, 50, n3)) + np.diag(5 * np.ones(n3 - 1), 1)\n    k3, m3, I3, tau3 = 4, 25, 200, 1e-8\n\n    test_cases = [\n        (A1, k1, m1, I1, tau1),\n        (A2, k2, m2, I2, tau2),\n        (A3, k3, m3, I3, tau3),\n    ]\n\n    results = []\n    # Set a seed for reproducibility of the random starting vector.\n    np.random.seed(42)\n    for A, k, m, max_restarts, tol in test_cases:\n        res = run_iram_case(A, k, m, max_restarts, tol)\n        results.append(list(res))\n\n    # Format output as specified\n    result_str = \"[\"\n    for i, res in enumerate(results):\n        c, e, s = res\n        result_str += f\"[{c}, {e}, {s}]\"\n        if i  len(results) - 1:\n            result_str += \", \"\n    result_str += \"]\"\n    print(result_str)\n\nsolve()\n\n```"
        },
        {
            "introduction": "Algorithms that are perfect in exact arithmetic can behave unexpectedly in the finite-precision world of computers. This exercise delves into one of the most classic and subtle challenges in implementing Krylov methods: the gradual loss of orthogonality among the computed basis vectors. You will investigate how this numerical artifact leads to the appearance of spurious, duplicated \"ghost\" eigenvalues and analyze the standard techniques used to diagnose and prevent this phenomenon .",
            "id": "3589891",
            "problem": "Consider a large, sparse, nonsingular matrix $A \\in \\mathbb{C}^{n \\times n}$ and the task of computing the $k$ eigenvalues of $A$ of largest magnitude using the Implicitly Restarted Arnoldi Method (IRAM). In exact arithmetic, the Arnoldi process started from a unit vector $v_1$ produces an orthonormal basis $V_{m+1} = [v_1,\\dots,v_{m+1}] \\in \\mathbb{C}^{n \\times (m+1)}$ and an upper Hessenberg matrix $H_{m+1,m} \\in \\mathbb{C}^{(m+1)\\times m}$ satisfying the Arnoldi relation\n$$\nA V_m \\;=\\; V_{m+1} H_{m+1,m},\n$$\nwith $V_m = [v_1,\\dots,v_m] \\in \\mathbb{C}^{n \\times m}$ and $H_m \\in \\mathbb{C}^{m \\times m}$ denoting the leading principal block of $H_{m+1,m}$. Ritz values are the eigenvalues $\\theta \\in \\mathbb{C}$ of $H_m$, and corresponding Ritz vectors are of the form $V_m y$, where $y \\in \\mathbb{C}^m$ is an eigenvector of $H_m$. The Rayleigh–Ritz condition states that the residual $r = A (V_m y) - \\theta (V_m y)$ is orthogonal to $\\mathcal{K}_m(A, v_1) = \\mathrm{span}\\{v_1, A v_1, \\dots, A^{m-1} v_1\\}$, i.e., $V_m^\\ast r = 0$.\n\nIn floating-point arithmetic with unit roundoff $u$, the computed basis vectors $v_j$ may lose orthogonality so that $V_m^\\ast V_m = I + E$ with a small but nonzero matrix $E \\in \\mathbb{C}^{m \\times m}$ satisfying $\\|E\\| = \\mathcal{O}(u) \\cdot \\mathrm{poly}(m)$. The IRAM algorithm applies an implicit polynomial filter $p(A)$ induced by $s$ shifts to restart the subspace, ideally suppressing undesired components while retaining approximations to the desired invariant subspace.\n\nAnalyze, from first principles of projection methods and floating-point perturbation, how the loss of orthogonality among the Arnoldi vectors affects the distribution of computed Ritz values in IRAM, with particular attention to the emergence of spurious and repeated Ritz values. Select all statements that are correct.\n\nA. In finite precision, loss of orthogonality among the Arnoldi vectors implies that the Ritz pairs computed from $H_m$ are still exactly the eigenpairs of the orthogonal projection of $A$ onto $\\mathcal{K}_m(A,v_1)$, so spurious duplicated Ritz values cannot occur.\n\nB. When $V_m^\\ast V_m = I + E$ with $E \\neq 0$, the computed Ritz values can be interpreted as exact eigenvalues of a nearby generalized Rayleigh–Ritz problem $(V_m^\\ast A V_m,\\, V_m^\\ast V_m)$; near linear dependence in the columns of $V_m$ can allow multiple Ritz vectors to approximate the same invariant subspace of $A$, leading to repeated (ghost) Ritz values.\n\nC. In IRAM, the implicit polynomial filtering ideally damps unwanted components, but loss of orthogonality can allow already converged components to persist or leak back into the restarted subspace, producing ghost Ritz values that duplicate converged eigenvalues; strategies such as selective reorthogonalization or locking mitigate this effect.\n\nD. A reliable practical diagnostic for spurious duplicate Ritz values is that their residual norms $\\|A (V_m y) - \\theta (V_m y)\\|_2$ are much larger than those of genuine Ritz pairs; therefore, large residuals flag spurious duplicates.\n\nE. For normal matrices (in particular, Hermitian matrices), loss of orthogonality cannot create repeated Ritz values in IRAM because the field of values is convex; ghost eigenvalues do not occur for normal $A$.\n\nF. Maintaining full reorthogonalization to keep $V_m$ numerically orthonormal and explicitly locking converged Ritz vectors so that they are kept fixed and orthogonal to the active Krylov basis eliminates the mechanism that creates spurious duplicates in IRAM, in the sense that in exact arithmetic models of these steps, repeated Ritz values due to loss of orthogonality do not arise.\n\nChoose all that apply.",
            "solution": "The problem statement describes the implicitly restarted Arnoldi method (IRAM) for computing a few eigenvalues of a large matrix $A$. It correctly defines the Arnoldi factorization, Ritz pairs, the Rayleigh-Ritz condition, and the issue of loss of orthogonality in finite-precision arithmetic. The core of the problem is to analyze the emergence of spurious or repeated Ritz values (often called \"ghost\" eigenvalues) as a consequence of this loss of orthogonality. The premises are grounded in the standard, well-established theory of numerical linear algebra, particularly the analysis of Krylov subspace methods in floating-point arithmetic. The problem is scientifically sound, well-posed, objective, and provides sufficient context to evaluate the given statements. Therefore, the problem is valid, and we may proceed with the analysis.\n\nThe fundamental principle of the Arnoldi method in exact arithmetic is the construction of an orthonormal basis $V_m$ for the Krylov subspace $\\mathcal{K}_m(A, v_1)$. The Ritz pairs $(\\theta, V_m y)$ are derived from the standard eigenvalue problem for $H_m = V_m^\\ast A V_m$, which represents the orthogonal projection of $A$ onto $\\mathcal{K}_m(A, v_1)$. The defining property is the Galerkin condition: the residual $r = A(V_m y) - \\theta (V_m y)$ is orthogonal to the subspace $\\mathcal{K}_m(A, v_1)$, i.e., $V_m^\\ast r = 0$.\n\nIn finite-precision arithmetic, the computed basis, which we will also denote by $V_m$ for simplicity, is no longer perfectly orthonormal. We have $V_m^\\ast V_m = I + E$, where $E$ is a non-zero matrix whose norm depends on the unit roundoff $u$ and problem parameters. The computed Ritz pairs are still obtained by solving a standard eigenvalue problem for a computed Hessenberg matrix $H_m$. However, the underlying projection is no longer orthogonal. The Galerkin condition $V_m^\\ast (A(V_m y) - \\theta (V_m y)) = 0$ is what the algorithm attempts to enforce. This rearranges to:\n$$\n(V_m^\\ast A V_m) y = \\theta (V_m^\\ast V_m) y\n$$\nThis is a generalized eigenvalue problem for the matrix pencil $(V_m^\\ast A V_m, V_m^\\ast V_m)$. The computed Ritz values $\\theta$ are the eigenvalues of this pencil.\n\nThe phenomenon of \"ghost\" eigenvalues arises directly from this framework. As a Ritz value converges to a true eigenvalue of $A$, the Arnoldi process suffers a catastrophic loss of orthogonality in the basis vectors. Subsequent vectors in the basis tend to develop significant components along the direction of the corresponding converged eigenvector. When IRAM performs a restart, the filtering process is meant to discard unwanted parts of the subspace. However, due to the loss of orthogonality, a component of the converged eigenvector can \"leak\" through the filter and remain in the starting vector for the new cycle. The Arnoldi process then \"rediscovers\" this eigenvector, leading to a second Ritz value converging to the same eigenvalue of $A$. This is the ghost.\n\nWe now evaluate each statement based on these principles.\n\n**A. In finite precision, loss of orthogonality among the Arnoldi vectors implies that the Ritz pairs computed from $H_m$ are still exactly the eigenpairs of the orthogonal projection of $A$ onto $\\mathcal{K}_m(A,v_1)$, so spurious duplicated Ritz values cannot occur.**\n\nThis statement is **Incorrect**. When the basis $V_m$ is not orthonormal, the procedure does not correspond to an orthogonal projection. As derived above, it corresponds to a generalized eigenvalue problem $(V_m^\\ast A V_m) y = \\theta (V_m^\\ast V_m) y$. The matrix of this projection would be $P = V_m (V_m^\\ast V_m)^{-1} V_m^\\ast$, which is an oblique projector, not an orthogonal one. The central claim that spurious duplicates cannot occur is factually wrong; their occurrence is a well-documented artifact of the method in finite precision and is the primary subject of this problem.\n\n**B. When $V_m^\\ast V_m = I + E$ with $E \\neq 0$, the computed Ritz values can be interpreted as exact eigenvalues of a nearby generalized Rayleigh–Ritz problem $(V_m^\\ast A V_m,\\, V_m^\\ast V_m)$; near linear dependence in the columns of $V_m$ can allow multiple Ritz vectors to approximate the same invariant subspace of $A$, leading to repeated (ghost) Ritz values.**\n\nThis statement is **Correct**. It accurately identifies the mathematical framework describing the computed Ritz values in the presence of lost orthogonality: they are the exact eigenvalues of the generalized eigenproblem $(V_m^\\ast A V_m, V_m^\\ast V_m)$. Furthermore, it correctly identifies the consequence of this. Loss of orthogonality implies that the basis vectors $v_j$ are no longer linearly independent in a numerically robust sense. This \"near linear dependence\" is precisely what allows multiple distinct linear combinations of the basis vectors (i.e., multiple Ritz vectors $V_m y_1$, $V_m y_2$) to approximate the same eigenvector of $A$, leading to multiple Ritz values $\\theta_1, \\theta_2$ approximating the same eigenvalue.\n\n**C. In IRAM, the implicit polynomial filtering ideally damps unwanted components, but loss of orthogonality can allow already converged components to persist or leak back into the restarted subspace, producing ghost Ritz values that duplicate converged eigenvalues; strategies such as selective reorthogonalization or locking mitigate this effect.**\n\nThis statement is **Correct**. It provides a precise and accurate description of the dynamics within IRAM that lead to ghost eigenvalues. The implicit restart applies a polynomial filter $p(A)$ to the basis. This is intended to isolate the desired invariant subspace. However, because loss of orthogonality has mixed components of the converged eigenvectors throughout the basis, the filtering is imperfect. A converged component can \"leak\" back into the Krylov subspace after the restart, prompting the Arnoldi process to find it again. This leads to the ghost copy. The statement correctly lists the two primary and effective countermeasures: reorthogonalization (maintaining the orthogonality of the basis, often selectively against converged vectors) and locking (explicitly deflating converged eigenvectors from the computation).\n\n**D. A reliable practical diagnostic for spurious duplicate Ritz values is that their residual norms $\\|A (V_m y) - \\theta (V_m y)\\|_2$ are much larger than those of genuine Ritz pairs; therefore, large residuals flag spurious duplicates.**\n\nThis statement is **Incorrect**. A \"ghost\" eigenvalue is typically a very good approximation of a true eigenvalue of $A$, just as its \"genuine\" counterpart is. Therefore, both the genuine Ritz pair and the ghost Ritz pair will typically have small residual norms, signaling convergence. A large residual norm indicates a poor approximation, i.e., a non-converged Ritz pair, which is a different issue from a ghost. The defining characteristic of a ghost is not a large residual but rather its status as a *duplicate* of another converged Ritz value. In practice, one detects ghosts by looking for clusters of tightly packed Ritz values, all with small residuals. A large residual flags a Ritz value that should be discarded by the IRAM restart filter, not a ghost.\n\n**E. For normal matrices (in particular, Hermitian matrices), loss of orthogonality cannot create repeated Ritz values in IRAM because the field of values is convex; ghost eigenvalues do not occur for normal $A$.**\n\nThis statement is **Incorrect**. The specialization of the Arnoldi method for Hermitian matrices is the Lanczos algorithm. The phenomenon of ghost eigenvalues is famous and well-studied in the context of the Lanczos algorithm. C. C. Paige's seminal 1971 thesis provided the definitive analysis of how loss of orthogonality in the Lanczos algorithm leads to multiple copies of converged eigenvalues. The mechanism is identical to the one described for the general Arnoldi method. The convexity of the field of values (for a normal matrix, this is the convex hull of its eigenvalues) is a property of the exact operator and has no bearing on this floating-point artifact.\n\n**F. Maintaining full reorthogonalization to keep $V_m$ numerically orthonormal and explicitly locking converged Ritz vectors so that they are kept fixed and orthogonal to the active Krylov basis eliminates the mechanism that creates spurious duplicates in IRAM, in the sense that in exact arithmetic models of these steps, repeated Ritz values due to loss of orthogonality do not arise.**\n\nThis statement is **Correct**. It describes the two most effective and theoretically sound strategies for preventing ghost eigenvalues.\n1.  **Full reorthogonalization:** By enforcing $V_m^\\ast V_m = I$ to working precision, the method becomes numerically equivalent to an orthogonal projection. The generalized eigenvalue problem from (B) reduces to a standard eigenvalue problem, and the near-linear dependence that allows for multiple representations of the same eigenvector is eliminated.\n2.  **Explicit locking:** Once a Ritz pair $(\\theta, x)$ has converged, it is \"locked.\" The subsequent IRAM process is constrained to the subspace orthogonal to all locked vectors. This explicitly prevents the algorithm from rediscovering $x$.\nThe qualifier \"in the sense that in exact arithmetic models of these steps\" is crucial and correct. It acknowledges that these are algorithmic procedures which, if performed perfectly, provably eliminate the ghosting mechanism. In practice, they are implemented in finite precision, but they are designed to be stable and work effectively to suppress ghosts to the level of machine error.",
            "answer": "$$\\boxed{BCF}$$"
        }
    ]
}