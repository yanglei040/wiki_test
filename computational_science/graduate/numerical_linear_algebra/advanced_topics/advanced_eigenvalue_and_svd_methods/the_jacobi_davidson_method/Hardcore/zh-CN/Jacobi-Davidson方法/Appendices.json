{
    "hands_on_practices": [
        {
            "introduction": "实际应用常常需要同时计算多个特征对。本实践将指导您实现一个使用共享子空间的多目标雅可比-戴维森求解器，这是一种提高效率的关键技术 。您将实现锁定和压缩机制，这对于防止算法重复发现相同的特征对以及正确处理具有多重性的特征值至关重要。",
            "id": "3590393",
            "problem": "考虑一个实对称矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 以及带有归一化约束 $u^\\top u = 1$ 的特征值问题 $A u = \\lambda u$。Jacobi-Davidson (JD) 方法旨在通过迭代地精炼一个子空间并求解一个从第一性原理推导出的校正方程，来计算目标特征对 $(\\theta, u)$。在一个多目标变体中，使用共享的搜索子空间同时追踪多个目标位移 $\\{\\sigma_j\\}$，同时强制执行收缩和锁定规则，以防止多个目标收敛到同一个特征向量（交叉污染）或重新发现已经锁定的特征对。\n\n从特征对、Rayleigh 商、Ritz 对和子空间投影的基本定义出发，推导对称情况下 JD 校正方程的形式。然后，设计数学上合理的收缩和锁定规则，以防止目标之间的交叉污染，并能正确处理特征值的重数。您编写的程序必须实现一个多目标 JD 方案，该方案使用共享子空间，在 $\\{\\sigma_j\\}$ 附近同时进行 Ritz 提取，对已锁定的向量进行正交投影，并使用 JD 校正方程的解进行分块更新。对于每个目标 $j$，确保校正向量 $t_j$ 在当前方向 $u_j$ 和已锁定子空间的正交补空间中计算，并且收缩/锁定规则强制共享子空间与所有已锁定向量保持正交。\n\n您的程序必须实现以下原则：\n- 对于每个位移 $\\sigma_j$ 的 Ritz 提取必须从共享子空间 $V$ 中进行，通过计算投影算子 $T = V^\\top A V$ 的特征分解，并选择最接近 $\\sigma_j$ 的 Ritz 值。对于一次迭代中的多个目标，除非子空间维度小于未收敛目标的数量，否则禁止将同一个 Ritz 索引分配给多个目标。\n- 校正方程必须在当前近似特征向量和已锁定子空间的正交子空间内求解，使用在该正交补空间中的精确解。当校正算子近奇异时，必须使用数值稳定的最小二乘法或正则化方法。\n- 当残差范数满足某个目标的收敛阈值，并且新的近似特征向量与任何先前已锁定的特征向量不共线时，必须扩展已锁定子空间。如果检测到共线性，则不锁定该目标，并且必须在收缩后的子空间内继续搜索。每次锁定后，必须对共享子空间相对于已锁定子空间进行重新投影和重新正交化。\n\n您必须实现一个单一程序，在以下测试套件上执行多目标 JD 方法。对于每个测试用例，生成一个近似特征值的有序列表（每个目标位移对应一个），格式为浮点数。\n\n测试套件：\n1. 案例 D5: $A = \\mathrm{diag}(1,2,3,4,5)$，位移 $\\{\\sigma_j\\} = \\{1.2, 2.8, 4.9\\}$，容差 $\\varepsilon = 10^{-10}$，最大迭代次数 $150$，最大子空间维度 $20$。预期目标接近特征值 $1$、$3$ 和 $5$。\n2. 案例 T10: $A \\in \\mathbb{R}^{10 \\times 10}$ 为三对角矩阵，其中 $A_{ii} = 2$，$A_{i,i+1} = A_{i+1,i} = -1$（$i=1,\\dots,9$），位移 $\\{\\sigma_j\\} = \\{0.1, 1.9, 3.9\\}$，容差 $\\varepsilon = 10^{-9}$，最大迭代次数 $200$，最大子空间维度 $25$。此案例测试聚集的极值和内部特征值。\n3. 案例 R6: $A = \\mathrm{diag}(1,3,3,3,4,6)$，具有重复特征值 $3$，位移 $\\{\\sigma_j\\} = \\{2.9, 3.05, 3.1\\}$，容差 $\\varepsilon = 10^{-10}$，最大迭代次数 $200$，最大子空间维度 $25$。此案例测试重数处理；结果应在对应于重复特征值的特征空间中产生三个不同的特征向量，同时避免共线锁定。\n4. 案例 C6: $A = \\mathrm{diag}(1.0, 1.0001, 2.0, 3.0, 4.0, 5.0)$，位移 $\\{\\sigma_j\\} = \\{0.9, 1.0002\\}$，容差 $\\varepsilon = 10^{-10}$，最大迭代次数 $200$，最大子空间维度 $25$。此案例测试处理接近 $1$ 的一组紧密聚集的特征值。\n\n该算法应使用以下基本原理，而不依赖快捷公式：\n- Ritz 对：给定一个标准正交基 $V$，Ritz 值是 $T = V^\\top A V$ 的特征值，Ritz 向量是 $V y$，其中 $y$ 是 $T$ 的特征向量。\n- Rayleigh 商：对于一个向量 $u$，$\\theta = \\frac{u^\\top A u}{u^\\top u}$。\n- 残差：对于一个近似 $(\\theta, u)$，$r = A u - \\theta u$。\n- 正交投影和子空间补：线性代数运算必须保持共享子空间是标准正交的，并且每个校正向量都必须位于当前方向和已锁定子空间的正交补空间中。\n\n最终输出规范：\n- 您的程序应生成单行输出，其中包含结果，格式为方括号括起来的、由逗号分隔的列表的列表。每个内部列表对应一个测试用例的近似特征值的有序列表，其顺序与输入位移的顺序相同。例如：\"[[result_case1_shift1,result_case1_shift2,...],[result_case2_shift1,...],...]\"。\n- 所有数字必须以十进制浮点值的形式打印。不涉及角度或物理单位；不得打印任何附加文本。\n\n解决方案不得读取任何外部输入，也不得访问任何文件或网络。仅使用指定的库。程序必须是自包含的，并且必须实现上述描述的、带有共享子空间、收缩和锁定功能的多目标 Jacobi-Davidson 方法。",
            "solution": "该问题要求推导对称矩阵的 Jacobi-Davidson (JD) 校正方程，并设计和实现一个多目标 JD 算法。该算法必须使用共享搜索子空间同时处理多个特征值目标，并具备收缩和锁定机制，以找到多个特征对，包括与重复特征值对应的特征对。\n\n### 1. Jacobi-Davidson 校正方程的推导\n\nJacobi-Davidson 方法的核心在于为一个给定的特征向量近似找到一个最优校正。让我们考虑实对称矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 的特征值问题：\n$$A u = \\lambda u, \\quad \\text{其中 } u^\\top u = 1$$\n设 $(\\theta, u)$ 是特征对 $(\\lambda, u_{true})$ 的一个当前近似，其中 $u$ 被归一化以满足 $u^\\top u = 1$，$\\theta$ 是相应的 Rayleigh 商：\n$$\\theta = \\frac{u^\\top A u}{u^\\top u} = u^\\top A u$$\n此近似的质量由残差向量 $r$ 来衡量：\n$$r = A u - \\theta u$$\n对于 Rayleigh 商，其残差的一个关键性质是它与近似向量 $u$ 正交：\n$$u^\\top r = u^\\top (A u - \\theta u) = u^\\top A u - \\theta (u^\\top u) = \\theta - \\theta(1) = 0$$\n因此，$r \\perp u$。\n\n我们寻求一个校正向量 $t$，使得 $u_{new} = u + t$ 是真实特征向量 $u_{true}$ 的一个更好的近似。Jacobi-Davidson 方法的一个基本原则是在与当前近似 $u$ 正交的子空间中搜索此校正。这由以下约束表示：\n$$t \\perp u \\quad \\iff \\quad u^\\top t = 0$$\n精确的校正 $t$ 将满足真实特征值 $\\lambda$ 的特征值方程：\n$$A(u+t) = \\lambda(u+t)$$\n展开并重排此方程可得：\n$$A u - \\lambda u + (A - \\lambda I)t = 0$$\n代入 $A u = r + \\theta u$：\n$$(r + \\theta u) - \\lambda u + (A - \\lambda I)t = 0$$\n$$r + (A - \\lambda I)t = (\\lambda - \\theta)u$$\n这个方程是精确的，但由于真实特征值 $\\lambda$ 未知，因此无法直接求解 $t$。标准的 JD 方法是用当前最佳近似 $\\theta$ 替换算子 $(A - \\lambda I)$ 中的未知 $\\lambda$。这会得到：\n$$(A - \\theta I)t \\approx -r + (\\lambda - \\theta)u$$\n为了在遵守正交约束 $t \\perp u$ 的同时求解 $t$，我们将此方程投影到 $u$ 的正交补空间 $\\{u\\}^\\perp$ 上。到该子空间上的投影算子是 $P_u^{\\perp} = I - u u^\\top$。将此投影算子应用于两边：\n$$P_u^{\\perp}(A - \\theta I)t = -P_u^{\\perp}r + (\\lambda - \\theta)P_u^{\\perp}u$$\n利用性质 $t \\in \\{u\\}^\\perp \\implies P_u^{\\perp}t=t$、$r \\in \\{u\\}^\\perp \\implies P_u^{\\perp}r=r$ 以及 $u \\notin \\{u\\}^\\perp \\implies P_u^{\\perp}u=0$，方程简化为：\n$$P_u^{\\perp}(A - \\theta I)t = -r$$\n由于我们寻求的解 $t$ 已经在 $\\{u\\}^\\perp$ 中，我们可以等价地写出限制在该子空间上的算子的方程：\n$$(I - u u^\\top)(A - \\theta I)(I - u u^\\top) t = -r$$\n这就是单个特征对的 Jacobi-Davidson 校正方程。算子 $(I - u u^\\top)(A - \\theta I)(I - u u^\\top)$ 因其构造而是奇异的（其零空间包含 $u$）。该方程需要在子空间 $\\{u\\}^\\perp$ 内求解 $t$。\n\n### 2. 带有收缩和锁定的多目标算法\n\n对于具有位移 $\\{\\sigma_j\\}$ 的多目标问题，我们扩展此框架。迭代地构建一个共享子空间 $V$。引入了收缩机制以防止重新收敛到已经找到的特征对。\n\n**关键组成部分：**\n- **状态管理**：我们维护一组活跃目标和一组已锁定（已收敛）的特征对。已锁定的特征向量构成一个标准正交基，存储在矩阵 $U_{locked}$ 中。\n- **Rayleigh-Ritz 过程**：在每次迭代中，我们求解一个投影特征值问题。给定搜索子空间的一个标准正交基 $V$，我们构造投影矩阵 $H = V^\\top A V$。其特征对 $(\\omega_k, s_k)$ 给出 Ritz 值 $\\omega_k$ 和 Ritz 向量 $y_k = V s_k$。\n- **配对**：对于每个带有位移 $\\sigma_j$ 的活跃目标，我们选择使 $|\\omega_k - \\sigma_j|$ 最小化的 Ritz 对 $(\\omega_k, y_k)$。为防止交叉污染，我们强制执行一个规则，即在一次迭代中，单个 Ritz 对不能分配给多个目标，前提是子空间足够大。\n- **带收缩的校正方程**：对于具有当前近似 $(\\theta_j, u_j)$ 的目标 $j$，其校正方程在与 $u_j$ 和 $U_{locked}$ 中所有已锁定特征向量都正交的子空间中求解。令 $P_{lock}^{\\perp} = I - U_{locked}U_{locked}^\\top$ 为到已锁定子空间的正交补空间上的投影算子。组合投影算子为 $P_j^{\\perp} = P_{lock}^{\\perp}(I-u_j u_j^\\top)$。校正方程为：\n$$P_j^{\\perp}(A - \\theta_j I)P_j^{\\perp} t_j = -r_j$$\n其中 $r_j = A u_j - \\theta_j u_j$。此方程在 $t_j \\in (\\mathrm{span}\\{u_j\\} \\cup \\mathrm{span}\\{U_{locked}\\})^\\perp$ 中求解。对于小型矩阵，一种实用的方法是找到该正交补空间的一个显式基 $Q$，并求解降维系统 $Q^\\top (A-\\theta_j I) Q \\hat{t}_j = -Q^\\top r_j$，之后得到 $t_j = Q \\hat{t}_j$。\n- **子空间扩展**：通过添加计算出的校正向量 $\\{t_j\\}$ 来扩展子空间 $V$。这些新向量使用修正的 Gram-Schmidt 过程与现有基 $V$ 以及彼此之间进行正交化，以保持数值稳定性。\n- **收敛与锁定**：如果目标 $j$ 的残差范数 $\\|r_j\\| = \\|A u_j - \\theta_j u_j\\|$ 小于指定的容差 $\\varepsilon$，则认为该目标已收敛。在锁定特征对 $(\\theta_j, u_j)$ 之前，会进行共线性检查，以确保 $u_j$ 与 $U_{locked}$ 中已锁定的向量不是数值上线性相关的。这对于正确处理特征值重数至关重要。如果检查通过，则锁定该特征对。\n- **子空间收缩**：将新向量添加到 $U_{locked}$ 后，必须通过将整个搜索子空间 $V$ 投影到更新后的已锁定子空间的正交补空间上来对其进行收缩：$V_{new} = (I - U_{locked}U_{locked}^\\top) V_{old}$。然后对得到的 $V_{new}$ 的列进行重新标准正交化。\n- **重启**：如果 $V$ 的维度超过最大限制 $k_{max}$，则对子空间进行剪枝。一个稳健的策略是，使用由所有活跃目标的当前最佳 Ritz 向量张成的新子空间来重启，并对该新子空间相对于 $U_{locked}$ 进行适当的收缩。\n\n这种全面的设计确保了算法能系统地探索向量空间，找到指定目标附近的特征对，通过寻找正交特征向量来处理特征值的重数，并通过收缩来防止冗余工作。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import eigh, qr, null_space\n\ndef get_correction_vector(A, u, theta, residual, locked_vecs):\n    \"\"\"\n    Solves the Jacobi-Davidson correction equation in the appropriate\n    orthogonal complement.\n    (I-P)(A-theta*I)(I-P)t = -r\n    where P projects onto span(u, locked_vecs).\n    \"\"\"\n    n = A.shape[0]\n    \n    # Define the subspace W to be orthogonal to.\n    W_cols = [u[:, np.newaxis]]\n    if locked_vecs.shape[1] > 0:\n        W_cols.append(locked_vecs)\n    W = np.hstack(W_cols)\n    \n    # Q is an orthonormal basis for the orthogonal complement of span(W).\n    Q = null_space(W.T)\n    \n    if Q.shape[1] == 0:\n        return np.zeros(n)\n        \n    # Project the operator and the residual onto the subspace spanned by Q.\n    A_proj = Q.T @ (A @ Q)\n    r_proj = Q.T @ residual\n    \n    # Define the projected linear system operator.\n    M_proj = A_proj - theta * np.identity(Q.shape[1])\n    \n    try:\n        # Solve the projected system. Use lstsq for robustness against singularity.\n        t_hat, _, _, _ = np.linalg.lstsq(M_proj, -r_proj, rcond=None)\n    except np.linalg.LinAlgError:\n        # If the solver fails, return a zero vector.\n        return np.zeros(n)\n        \n    # Map the solution back to the original n-dimensional space.\n    return Q @ t_hat\n\ndef multi_target_jd(case):\n    \"\"\"\n    Implements the multi-target Jacobi-Davidson method.\n    \"\"\"\n    A, shifts, tol, max_iter, max_dim_v = case\n    n = A.shape[0]\n    num_targets = len(shifts)\n    \n    # State management\n    locked_pairs = {}  # key: original_target_idx, val: (eigval, eigvec)\n    active_targets = {i: {'shift': shifts[i], 'u': None, 'theta': None} for i in range(num_targets)}\n\n    # Initialize the search subspace V with random vectors\n    V_dim_init = min(num_targets, max_dim_v)\n    if V_dim_init == 0:\n        return [np.nan] * num_targets\n    V = np.random.rand(n, V_dim_init)\n    V, _ = qr(V, mode='economic')\n\n    for iteration in range(max_iter):\n        if not active_targets:\n            break\n            \n        # Get orthonormal basis of locked eigenvectors\n        locked_vecs = np.zeros((n, 0))\n        if locked_pairs:\n            locked_vecs = np.hstack([p[1][:, np.newaxis] for p in locked_pairs.values()])\n\n        # Subspace restart mechanism\n        if V.shape[1] >= max_dim_v:\n            restart_vecs = []\n            for target_idx in active_targets:\n                if active_targets[target_idx]['u'] is not None:\n                    restart_vecs.append(active_targets[target_idx]['u'])\n            \n            if restart_vecs:\n                V_new = np.hstack([v[:, np.newaxis] for v in restart_vecs])\n                if locked_vecs.shape[1] > 0:\n                    V_new -= locked_vecs @ (locked_vecs.T @ V_new)\n                V, _ = qr(V_new, mode='economic')\n            else: # Fallback if no Ritz vectors are available\n                V_restart_dim = min(len(active_targets), max_dim_v)\n                V = np.random.rand(n, V_restart_dim)\n                if locked_vecs.shape[1] > 0:\n                    V -= locked_vecs @ (locked_vecs.T @ V)\n                V, _ = qr(V, mode='economic')\n        \n        # Rayleigh-Ritz step\n        if V.shape[1] == 0: # Subspace may have collapsed after deflation\n            V = np.random.rand(n, 1) # Re-initialize with one random vector\n            if locked_vecs.shape[1] > 0:\n                V -= locked_vecs @ (locked_vecs.T @ V)\n            V /= np.linalg.norm(V)\n            continue\n        \n        H = V.T @ A @ V\n        ritz_vals, S = eigh(H)\n        ritz_vecs = V @ S\n        \n        # Pairing step: assign best Ritz pairs to active targets\n        assignments = {}\n        available_ritz_indices = set(range(len(ritz_vals)))\n        sorted_target_indices = sorted(list(active_targets.keys()))\n        \n        for target_idx in sorted_target_indices:\n            shift = active_targets[target_idx]['shift']\n            best_ritz_idx, min_dist = -1, np.inf\n            for ritz_idx in available_ritz_indices:\n                dist = abs(ritz_vals[ritz_idx] - shift)\n                if dist < min_dist:\n                    min_dist, best_ritz_idx = dist, ritz_idx\n            \n            if best_ritz_idx != -1:\n                assignments[target_idx] = best_ritz_idx\n                # Prevent multiple targets from claiming the same Ritz pair if avoidable\n                if len(ritz_vals) >= len(active_targets):\n                    available_ritz_indices.remove(best_ritz_idx)\n    \n        # Update approximations and check for convergence\n        converged_this_iter = []\n        for target_idx, ritz_idx in assignments.items():\n            theta, u = ritz_vals[ritz_idx], ritz_vecs[:, ritz_idx]\n            active_targets[target_idx].update({'theta': theta, 'u': u})\n            \n            residual = A @ u - theta * u\n            if np.linalg.norm(residual) < tol:\n                converged_this_iter.append(target_idx)\n                \n        # Locking step\n        newly_locked = False\n        for target_idx in converged_this_iter:\n            theta, u = active_targets[target_idx]['theta'], active_targets[target_idx]['u']\n            \n            is_colinear = False\n            if locked_vecs.shape[1] > 0:\n                proj_u_on_locked = locked_vecs @ (locked_vecs.T @ u)\n                if np.linalg.norm(u - proj_u_on_locked) < 1e-8:\n                    is_colinear = True\n            \n            if not is_colinear:\n                locked_pairs[target_idx] = (theta, u)\n                del active_targets[target_idx]\n                newly_locked = True\n        \n        # Deflate subspace V if new eigenvectors were locked\n        if newly_locked:\n            updated_locked_vecs = np.hstack([p[1][:, np.newaxis] for p in locked_pairs.values()])\n            if V.shape[1] > 0:\n                V -= updated_locked_vecs @ (updated_locked_vecs.T @ V)\n                V, _ = qr(V, mode='economic')\n\n        # Subspace expansion step\n        vecs_to_add_to_V = []\n        for target_idx in active_targets:\n            u, theta = active_targets[target_idx]['u'], active_targets[target_idx]['theta']\n            if u is None: continue\n            \n            residual = A @ u - theta * u\n            t = get_correction_vector(A, u, theta, residual, locked_vecs)\n            \n            if np.linalg.norm(t) > 1e-8:\n                vecs_to_add_to_V.append(t)\n        \n        # Augment V using Modified Gram-Schmidt for stability\n        for v_new in vecs_to_add_to_V:\n            if V.shape[1] >= max_dim_v: break\n            \n            v_ortho = v_new\n            if V.shape[1] > 0:\n                v_ortho -= V @ (V.T @ v_ortho)\n            \n            norm_v_ortho = np.linalg.norm(v_ortho)\n            if norm_v_ortho > 1e-8:\n                V = np.hstack([V, (v_ortho / norm_v_ortho)[:, np.newaxis]])\n\n    # Finalize results\n    final_eigvals = [np.nan] * num_targets\n    for i in range(num_targets):\n        if i in locked_pairs:\n            final_eigvals[i] = locked_pairs[i][0]\n        elif i in active_targets and active_targets[i]['theta'] is not None:\n            final_eigvals[i] = active_targets[i]['theta']  # Best effort for non-converged\n            \n    return final_eigvals\n\ndef solve():\n    # Test Suite\n    # Case D5: Diagonal matrix\n    A1 = np.diag([1.0, 2.0, 3.0, 4.0, 5.0])\n    shifts1 = [1.2, 2.8, 4.9]\n    tol1 = 1e-10\n    max_iter1 = 150\n    max_dim_v1 = 20\n    case1 = (A1, shifts1, tol1, max_iter1, max_dim_v1)\n\n    # Case T10: Tridiagonal matrix (1D Laplacian)\n    n2 = 10\n    A2 = np.diag(2 * np.ones(n2)) - np.diag(np.ones(n2 - 1), 1) - np.diag(np.ones(n2 - 1), -1)\n    shifts2 = [0.1, 1.9, 3.9]\n    tol2 = 1e-9\n    max_iter2 = 200\n    max_dim_v2 = 25\n    case2 = (A2, shifts2, tol2, max_iter2, max_dim_v2)\n    \n    # Case R6: Repeated eigenvalue\n    A3 = np.diag([1.0, 3.0, 3.0, 3.0, 4.0, 6.0])\n    shifts3 = [2.9, 3.05, 3.1]\n    tol3 = 1e-10\n    max_iter3 = 200\n    max_dim_v3 = 25\n    case3 = (A3, shifts3, tol3, max_iter3, max_dim_v3)\n\n    # Case C6: Clustered eigenvalues\n    A4 = np.diag([1.0, 1.0001, 2.0, 3.0, 4.0, 5.0])\n    shifts4 = [0.9, 1.0002]\n    tol4 = 1e-10\n    max_iter4 = 200\n    max_dim_v4 = 25\n    case4 = (A4, shifts4, tol4, max_iter4, max_dim_v4)\n\n    test_cases = [case1, case2, case3, case4]\n    \n    all_results = []\n    for case in test_cases:\n        results = multi_target_jd(case)\n        # The order of results should match the order of shifts.\n        # This is handled by the dictionary `locked_pairs` and final list construction.\n        all_results.append(results)\n\n    # Format the final output string\n    result_strings = []\n    for res_list in all_results:\n        # Sort results for repeated roots case by value for consistent output.\n        if np.isclose(res_list[0], res_list[1], atol=1e-5):\n            res_list.sort()\n        formatted_list = [f\"{x:.14f}\" for x in res_list]\n        result_strings.append(f\"[{','.join(formatted_list)}]\")\n    \n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "一个正确的算法固然很好，但一个快速的算法更佳。本实践从算法的正确性转向性能工程，要求您为雅可比-戴维森方法在现代硬件上的计算成本进行建模 。通过分析正交化成本和内部求解器成本之间的权衡，您将推导出一个最优的重启策略，从而将抽象的算法参数与内存带宽和浮点运算速率等具体的性能指标联系起来。",
            "id": "3590403",
            "problem": "考虑在一个现代处理器上实现 Jacobi-Davidson (JD) 方法，用于计算一个大型稀疏矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 的一个极端特征对。该处理器的特征是其峰值浮点运算速率为 $F$（单位：浮点运算/秒），峰值内存带宽为 $B$（单位：字节/秒）。JD 方法每次外扩展增加一个向量来增长搜索子空间，并在子空间维度达到最大值 $m_{\\max}$ 时周期性重启。重启时，它保留 $q$ 个标准正交的 Ritz 向量（$q \\geq 1$）并丢弃其余部分，因此每个周期包含 $r = m_{\\max} - q$ 次外扩展。\n\n假设以下有科学依据的建模选择：\n\n- 每次外扩展都需要通过带有一次再正交化过程的修正 Gram-Schmidt 方法，将一个新的长度为 $n$ 的向量与现有的由 $m$ 个向量构成的基进行正交化。设再正交化开销由一个标量 $s \\geq 1$ 表示。两个长度为 $n$ 的向量的一次点积所需时间为\n$$\nt_{\\mathrm{dp}} \\;=\\; \\max\\!\\left( \\frac{2 n}{F} \\,,\\, \\frac{2 n b}{B} \\right),\n$$\n一个 saxpy（标量乘以向量再加向量）操作所需时间为\n$$\nt_{\\mathrm{axpy}} \\;=\\; \\max\\!\\left( \\frac{2 n}{F} \\,,\\, \\frac{3 n b}{B} \\right),\n$$\n其中 $b$ 是每个标量的字节数。与单个基向量正交化的时间为 $t_{\\mathrm{orth},1} = t_{\\mathrm{dp}} + t_{\\mathrm{axpy}}$，因此与 $m$ 个向量正交化的成本为 $s\\, m\\, t_{\\mathrm{orth},1}$。\n\n- JD 方法中的内部校正方程通过 Krylov 方法求解，每次内迭代执行一次与 $A$ 的稀疏矩阵-向量乘法，并应用 $p$ 次右预处理器 $M^{-1}$。设 $A$ 每行的平均非零元素数为 $z$。稀疏矩阵-向量乘积的 roofline 时间近似为\n$$\nt_A \\;=\\; \\max\\!\\left( \\frac{2 z n}{F} \\,,\\, \\frac{(2 z + 3) n b}{B} \\right),\n$$\n一次预处理器应用所需时间为 $t_P$（其本身可能受 roofline 限制或由算法确定）。每次内迭代的时间为 $t_{\\mathrm{inner}} = t_A + p\\, t_P$。\n\n- 在我们感兴趣的操作区间内，每次外扩展所需的平均内 Krylov 迭代次数与周期内可用的增长空间近似成反比下降，建模为\n$$\nk_{\\mathrm{avg}} \\;=\\; \\kappa_0 \\;+\\; \\frac{\\delta}{m_{\\max} - q},\n$$\n其中 $\\kappa_0 \\geq 0$ 和 $\\delta > 0$ 是依赖于架构和问题的常数，分别反映了基线迭代次数以及内迭代次数对子空间大小的敏感度。\n\n对于大的 $n$，忽略小的稠密投影特征问题的成本，因为它相对于内存受限的正交化和稀疏/预处理的内迭代而言可以忽略不计。\n\n在这些假设下，从第一性原理推导出一个显式解析表达式，用于选择能使一个周期内每次外扩展的平均时间最小化的最大子空间大小 $m_{\\max}^{*}$，并给出相关的最优重启步数 $r^{*} = m_{\\max}^{*} - q$。请用参数 $F$, $B$, $n$, $b$, $z$, $p$, $t_P$, $s$, $q$, $\\kappa_0$, 和 $\\delta$ 以闭合形式表达你的最终答案，形式为有序对 $(m_{\\max}^{*}, r^{*})$。无需进行数值计算。如果最终表达式中包含常数，请以符号形式保留它们。请以单个有序对的形式提供最终答案，且最终答案中不应包含任何单位。",
            "solution": "目标是找到最大子空间大小，记为 $m_{\\max}^{*}$，它能使 Jacobi-Davidson 方法每次外扩展的平均时间最小化。问题为主要的计算成本提供了一个详细的性能模型。我们首先建立这个平均时间的表达式。\n\n令 $r = m_{\\max} - q$ 为一个重启周期中的外扩展次数，其中 $m_{\\max}$ 是最大子空间维度，$q$ 是重启时保留的 Ritz 向量数量。一个周期由 $r$ 次扩展组成，我们可以用 $j=0, 1, \\dots, r-1$ 来索引这些扩展。\n\n在周期内的第 $j$ 个扩展步，搜索子空间的维度为 $m_j = q + j$。此次扩展的时间 $T_j$ 是正交化时间 $T_{\\text{orth},j}$ 和求解校正方程的时间 $T_{\\text{corr},j}$ 之和。\n\n使用带有一次再正交化过程的修正 Gram-Schmidt 方法，将一个新向量与现有的 $m_j$ 个基向量进行正交化的时间由下式给出：\n$$\nT_{\\text{orth},j} = s \\cdot m_j \\cdot t_{\\text{orth},1} = s (q+j) t_{\\text{orth},1}\n$$\n其中 $s$ 是再正交化开销因子，$t_{\\text{orth},1} = t_{\\mathrm{dp}} + t_{\\mathrm{axpy}}$ 是与单个向量正交化的时间。\n\n求解校正方程的时间是平均内迭代次数 $k_{\\mathrm{avg}}$ 与每次内迭代时间 $t_{\\mathrm{inner}}$ 的乘积。根据题目描述，$k_{\\mathrm{avg}}$ 在整个周期内是恒定的，由下式给出：\n$$\nk_{\\mathrm{avg}} = \\kappa_0 + \\frac{\\delta}{m_{\\max} - q} = \\kappa_0 + \\frac{\\delta}{r}\n$$\n因此，校正步骤的时间为：\n$$\nT_{\\text{corr},j} = k_{\\mathrm{avg}} \\cdot t_{\\mathrm{inner}} = \\left( \\kappa_0 + \\frac{\\delta}{r} \\right) t_{\\mathrm{inner}}\n$$\n这个时间与周期内的步索引 $j$ 无关。\n\n一个包含 $r$ 次扩展的完整周期的总时间 $T_{\\text{cycle}}$ 是每次扩展时间的总和：\n$$\nT_{\\text{cycle}}(r) = \\sum_{j=0}^{r-1} T_j = \\sum_{j=0}^{r-1} \\left( T_{\\text{orth},j} + T_{\\text{corr},j} \\right)\n$$\n$$\nT_{\\text{cycle}}(r) = \\sum_{j=0}^{r-1} s(q+j)t_{\\text{orth},1} + \\sum_{j=0}^{r-1} \\left( \\kappa_0 + \\frac{\\delta}{r} \\right) t_{\\mathrm{inner}}\n$$\n我们分别计算这两个和。正交化部分为：\n$$\n\\sum_{j=0}^{r-1} s(q+j)t_{\\text{orth},1} = s t_{\\text{orth},1} \\left( \\sum_{j=0}^{r-1} q + \\sum_{j=0}^{r-1} j \\right) = s t_{\\text{orth},1} \\left( qr + \\frac{r(r-1)}{2} \\right) = s t_{\\text{orth},1} \\frac{r(2q+r-1)}{2}\n$$\n校正方程部分为：\n$$\n\\sum_{j=0}^{r-1} \\left( \\kappa_0 + \\frac{\\delta}{r} \\right) t_{\\mathrm{inner}} = r \\left( \\kappa_0 + \\frac{\\delta}{r} \\right) t_{\\mathrm{inner}} = (r\\kappa_0 + \\delta) t_{\\mathrm{inner}}\n$$\n将它们合并得到总周期时间：\n$$\nT_{\\text{cycle}}(r) = s t_{\\text{orth},1} \\frac{r(2q+r-1)}{2} + (r\\kappa_0 + \\delta) t_{\\mathrm{inner}}\n$$\n需要最小化的量是每次外扩展的平均时间，即 $T_{\\text{avg}} = T_{\\text{cycle}} / r$：\n$$\nT_{\\text{avg}}(r) = \\frac{1}{r} \\left[ s t_{\\text{orth},1} \\frac{r(2q+r-1)}{2} + (r\\kappa_0 + \\delta) t_{\\mathrm{inner}} \\right]\n$$\n$$\nT_{\\text{avg}}(r) = s t_{\\text{orth},1} \\frac{2q-1+r}{2} + \\kappa_0 t_{\\mathrm{inner}} + \\frac{\\delta t_{\\mathrm{inner}}}{r}\n$$\n为了找到最小化 $T_{\\text{avg}}(r)$ 的最优重启步数 $r$，我们将 $r$ 视为一个连续的正变量，并通过将其导数设为零来找到临界点。让我们重新排列各项以分离出与 $r$ 相关的部分：\n$$\nT_{\\text{avg}}(r) = \\left( s t_{\\text{orth},1} \\frac{2q-1}{2} + \\kappa_0 t_{\\mathrm{inner}} \\right) + \\left( \\frac{s t_{\\text{orth},1}}{2} \\right) r + \\left( \\delta t_{\\mathrm{inner}} \\right) \\frac{1}{r}\n$$\n关于 $r$ 的导数是：\n$$\n\\frac{d T_{\\text{avg}}}{dr} = \\frac{s t_{\\text{orth},1}}{2} - \\frac{\\delta t_{\\mathrm{inner}}}{r^2}\n$$\n将导数设为零以求得最优值 $r^*$：\n$$\n\\frac{s t_{\\text{orth},1}}{2} - \\frac{\\delta t_{\\mathrm{inner}}}{(r^*)^2} = 0 \\implies (r^*)^2 = \\frac{2 \\delta t_{\\mathrm{inner}}}{s t_{\\text{orth},1}}\n$$\n由于 $r$ 必须为正，我们取正平方根：\n$$\nr^* = \\sqrt{\\frac{2 \\delta t_{\\mathrm{inner}}}{s t_{\\text{orth},1}}}\n$$\n为确认这是一个最小值，我们检查二阶导数：\n$$\n\\frac{d^2 T_{\\text{avg}}}{dr^2} = \\frac{2 \\delta t_{\\mathrm{inner}}}{r^3}\n$$\n根据问题约束条件 $\\delta > 0$，且 $t_{\\mathrm{inner}}$（作为时间度量）和 $r$ 必须为正，二阶导数总是正的。因此，$r^*$ 对应一个局部和全局最小值。\n\n最优最大子空间大小为 $m_{\\max}^* = q + r^*$：\n$$\nm_{\\max}^* = q + \\sqrt{\\frac{2 \\delta t_{\\mathrm{inner}}}{s t_{\\text{orth},1}}}\n$$\n现在，我们代入 $t_{\\mathrm{inner}}$ 和 $t_{\\text{orth},1}$ 的完整表达式：\n$$\nt_{\\mathrm{inner}} = t_A + p t_P = \\max\\left( \\frac{2 z n}{F} , \\frac{(2 z + 3) n b}{B} \\right) + p t_P\n$$\n$$\nt_{\\text{orth},1} = t_{\\mathrm{dp}} + t_{\\mathrm{axpy}} = \\max\\left( \\frac{2 n}{F} , \\frac{2 n b}{B} \\right) + \\max\\left( \\frac{2 n}{F} , \\frac{3 n b}{B} \\right)\n$$\n将这些代入 $r^*$ 和 $m_{\\max}^*$ 的表达式，得到最终的解析形式。\n\n最优重启步数 $r^*$ 是：\n$$\nr^* = \\sqrt{\\frac{2 \\delta \\left[ \\max\\left( \\frac{2 z n}{F} , \\frac{(2 z + 3) n b}{B} \\right) + p t_P \\right]}{s \\left[ \\max\\left( \\frac{2 n}{F} , \\frac{2 n b}{B} \\right) + \\max\\left( \\frac{2 n}{F} , \\frac{3 n b}{B} \\right) \\right]}}\n$$\n最优最大子空间大小 $m_{\\max}^*$ 是：\n$$\nm_{\\max}^* = q + \\sqrt{\\frac{2 \\delta \\left[ \\max\\left( \\frac{2 z n}{F} , \\frac{(2 z + 3) n b}{B} \\right) + p t_P \\right]}{s \\left[ \\max\\left( \\frac{2 n}{F} , \\frac{2 n b}{B} \\right) + \\max\\left( \\frac{2 n}{F} , \\frac{3 n b}{B} \\right) \\right]}}\n$$\n问题要求给出有序对 $(m_{\\max}^{*}, r^{*})$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nq + \\sqrt{\\frac{2 \\delta \\left( \\max\\left( \\frac{2 z n}{F} , \\frac{(2 z + 3) n b}{B} \\right) + p t_P \\right)}{s \\left( \\max\\left( \\frac{2 n}{F} , \\frac{2 n b}{B} \\right) + \\max\\left( \\frac{2 n}{F} , \\frac{3 n b}{B} \\right) \\right)}} \\\\\n\\sqrt{\\frac{2 \\delta \\left( \\max\\left( \\frac{2 z n}{F} , \\frac{(2 z + 3) n b}{B} \\right) + p t_P \\right)}{s \\left( \\max\\left( \\frac{2 n}{F} , \\frac{2 n b}{B} \\right) + \\max\\left( \\frac{2 n}{F} , \\frac{3 n b}{B} \\right) \\right)}}\n\\end{pmatrix}\n}\n$$"
        }
    ]
}