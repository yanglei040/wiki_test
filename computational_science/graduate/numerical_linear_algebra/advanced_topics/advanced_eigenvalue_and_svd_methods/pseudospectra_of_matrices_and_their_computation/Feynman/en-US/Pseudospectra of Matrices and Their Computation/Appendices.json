{
    "hands_on_practices": [
        {
            "introduction": "This first practice introduces the fundamental \"brute-force\" method for computing pseudospectra. It establishes the core computational task: evaluating the smallest singular value, $\\sigma_{\\min}(A - zI)$, over a grid of points in the complex plane. By implementing this algorithm, you will gain a practical understanding of the definition of pseudospectra and the computational foundation upon which more advanced techniques are built .",
            "id": "3568796",
            "problem": "Let $A \\in \\mathbb{C}^{n \\times n}$ be a square matrix, $I$ the identity matrix, and $z \\in \\mathbb{C}$ a complex variable. The smallest singular value of $A - zI$, denoted $\\sigma_{\\min}(A - zI)$, is a central quantity in the study of pseudospectra. The $\\varepsilon$-pseudospectrum of $A$ is defined as the set of points $z \\in \\mathbb{C}$ for which $\\sigma_{\\min}(A - zI) \\le \\varepsilon$. Singular values arise from the Singular Value Decomposition (SVD), which for a matrix $B \\in \\mathbb{C}^{n \\times n}$ factors $B$ as $B = U \\Sigma V^*$, where $U, V$ are unitary matrices and $\\Sigma$ is diagonal with nonnegative entries $\\sigma_1(B) \\ge \\sigma_2(B) \\ge \\cdots \\ge \\sigma_n(B) \\ge 0$.\n\nStarting from these definitions, design and implement an algorithm that:\n- constructs a rectangular grid in the complex plane defined by real bounds $x_{\\min}, x_{\\max}, y_{\\min}, y_{\\max}$ and integer resolutions $N_x, N_y$;\n- for each grid point $z = x + \\mathrm{i} y$, computes $\\sigma_{\\min}(A - zI)$ using Singular Value Decomposition (SVD);\n- assembles the values $\\sigma_{\\min}(A - zI)$ into a two-dimensional array corresponding to the grid; and\n- provides a clear analysis of the computational complexity in terms of $n$ and the total number of grid points $G := N_x N_y$, together with a discussion of opportunities for parallelization that respect the independence of computations across distinct $z$.\n\nYour program must compute and return specific quantifiable results on the following test suite. For avoidance of ambiguity, every matrix, bound, and grid resolution is explicitly specified, and all required numeric outputs are stated. No physical units or angles are involved in this problem.\n\nTest Suite:\n1. Happy-path non-normal case. Let $A_1 \\in \\mathbb{C}^{5 \\times 5}$ be the nilpotent Jordan block,\n$$\nA_1 = \\begin{bmatrix}\n0 & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 0 & 1 \\\\\n0 & 0 & 0 & 0 & 0\n\\end{bmatrix}.\n$$\nUse a rectangular grid with $x_{\\min} = -0.1$, $x_{\\max} = 0.1$, $y_{\\min} = -0.1$, $y_{\\max} = 0.1$, $N_x = 11$, $N_y = 11$. Compute the minimal value of $\\sigma_{\\min}(A_1 - zI)$ over the grid and return it as a floating-point number.\n\n2. Normal matrix consistency check. Let $A_2 \\in \\mathbb{C}^{4 \\times 4}$ be diagonal,\n$$\nA_2 = \\mathrm{diag}(1,\\,2,\\,3,\\,4).\n$$\nConsider the single-point grid $x_{\\min} = x_{\\max} = 2.5$, $y_{\\min} = y_{\\max} = 0$, $N_x = 1$, $N_y = 1$ so $z = 2.5$. Using SVD, compute $\\sigma_{\\min}(A_2 - zI)$ as a floating-point number. Independently, compute the quantity $d := \\min_{i} |\\lambda_i(A_2) - z|$ using the eigenvalues of $A_2$. Return the absolute difference $|\\sigma_{\\min}(A_2 - zI) - d|$ as a floating-point number.\n\n3. Complexity accounting (SVD call count). Let\n$$\nA_3 = \\begin{bmatrix}\n5 & 1 & 0 \\\\\n0 & -1 & 1 \\\\\n0 & 0 & 2\n\\end{bmatrix} \\in \\mathbb{C}^{3 \\times 3}.\n$$\nUse a rectangular grid with $x_{\\min} = -2$, $x_{\\max} = 2$, $y_{\\min} = -1$, $y_{\\max} = 1$, $N_x = 17$, $N_y = 19$. Return the integer number of SVD computations your algorithm performs to evaluate $\\sigma_{\\min}(A_3 - zI)$ on the entire grid. This must equal the total number of grid points $G = N_x N_y$.\n\n4. Ideal parallelization speedup. For the grid in test case $3$, assume a parallel execution model with $p = 8$ identical processors and negligible overhead, where each evaluation of $\\sigma_{\\min}(A - zI)$ at a grid point is an independent task. Under perfect load balancing, the ideal speedup is defined as $S = \\min(G, p)$ relative to serial execution. Return $S$ as an integer.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results of the four test cases, as a comma-separated list enclosed in square brackets, in the order given above. For example, it should print\n$$\n[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4].\n$$\nAll four entries must be of types as specified: the first two as floating-point numbers, the third as an integer, and the fourth as an integer.",
            "solution": "The problem has been validated and is deemed well-posed, scientifically grounded, and self-contained. It presents a standard task in numerical linear algebraâ€”the computation of the smallest singular value over a grid in the complex plane to map the pseudospectrum of a matrix. All definitions, matrices, and parameters are stated explicitly and unambiguously. We may therefore proceed with a formal solution.\n\nThe objective is to design and implement an algorithm that computes $\\sigma_{\\min}(A - zI)$ for a given matrix $A \\in \\mathbb{C}^{n \\times n}$ at each point $z$ of a specified rectangular grid in the complex plane $\\mathbb{C}$. This grid is defined by real bounds $x_{\\min}$, $x_{\\max}$, $y_{\\min}$, $y_{\\max}$ and integer resolutions $N_x$, $N_y$.\n\n**Algorithm Design**\n\nThe core of the algorithm involves a systematic evaluation over a discrete set of complex numbers.\n\n1.  **Grid Construction**: A rectangular grid of points in the complex plane is constructed. The real components of the grid points, $x_j$, are generated as an arithmetic progression of $N_x$ points from $x_{\\min}$ to $x_{\\max}$. Similarly, the imaginary components, $y_k$, are $N_y$ points from $y_{\\min}$ to $y_{\\max}$. This is achieved using linearly spaced arrays. A grid point $z_{jk}$ is given by $z_{jk} = x_j + \\mathrm{i} y_k$, where $j \\in \\{1, \\dots, N_x\\}$ and $k \\in \\{1, \\dots, N_y\\}$. The total number of points in the grid is $G = N_x N_y$.\n\n2.  **Iterative Computation**: The algorithm iterates through each of the $G$ grid points. For each $z = z_{jk}$, the following steps are performed:\n    a. Form the matrix $B(z) = A - zI$, where $I$ is the $n \\times n$ identity matrix. This is a simple matrix subtraction operation.\n    b. Compute the Singular Value Decomposition (SVD) of $B(z)$. The SVD provides the factorization $B(z) = U \\Sigma V^*$, where $U$ and $V$ are unitary matrices and $\\Sigma$ is a diagonal matrix containing the singular values $\\sigma_i$ on its diagonal, conventionally sorted in non-increasing order: $\\sigma_1 \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_n \\ge 0$.\n    c. The smallest singular value, $\\sigma_{\\min}(B(z)) = \\sigma_n(B(z))$, is extracted. Computationally, this is typically the last element of the array of singular values returned by a standard SVD library function. For efficiency, one should use a variant of the SVD algorithm that computes only the singular values and not the unitary matrices $U$ and $V$, as the latter are not required for this problem.\n\n3.  **Data Assembly**: The computed values of $\\sigma_{\\min}(A - z_{jk}I)$ are stored in a two-dimensional array, say $\\mathcal{S}$, of size $N_y \\times N_x$. The element $\\mathcal{S}_{k,j}$ corresponds to the value computed at $z_{jk} = x_j + \\mathrm{i} y_k$. This matrix $\\mathcal{S}$ represents the landscape of the function $f(z) = \\sigma_{\\min}(A - zI)$ over the specified domain.\n\n**Computational Complexity Analysis**\n\nThe dominant computational cost of this algorithm is the repeated calculation of the SVD.\n- The complexity of computing the SVD of a general $n \\times n$ matrix is $O(n^3)$.\n- This computation is performed once for each of the $G = N_x N_y$ points in the grid.\n- Therefore, the total computational complexity of the algorithm is $O(G \\cdot n^3) = O(N_x N_y n^3)$. The costs of grid generation and matrix subtraction ($O(n^2)$ per point) are negligible compared to the SVD cost for non-trivial $n$.\n\n**Parallelization Opportunities**\n\nA crucial observation is that the computation of $\\sigma_{\\min}(A - z_1 I)$ for a grid point $z_1$ is entirely independent of the computation of $\\sigma_{\\min}(A - z_2 I)$ for any other grid point $z_2$. This property renders the problem \"embarrassingly parallel\".\n\nIn an ideal parallel execution model with $p$ identical processors and zero communication overhead, the $G$ independent tasks (one SVD per grid point) can be distributed among the processors.\n- The total amount of work is proportional to $G$.\n- With $p$ processors, the time required for completion would be proportional to $\\lceil G/p \\rceil$ under perfect load balancing.\n- The ideal speedup $S$ is the ratio of the serial execution time to the parallel execution time. If $p \\le G$, the speedup is approximately $p$. If $p > G$, we cannot utilize more processors than there are tasks, so the speedup is limited by $G$. This leads to the simplified formula for ideal speedup given in the problem: $S = \\min(G, p)$.\n\n**Application to Test Suite**\n\n1.  **Test Case 1**: For matrix $A_1$, a $5 \\times 5$ nilpotent Jordan block, on an $11 \\times 11$ grid over $[-0.1, 0.1] \\times [-0.1, 0.1]$, we must find the minimal $\\sigma_{\\min}$ value. The grid generation includes the point $z=0 + 0\\mathrm{i}$. At this point, we compute $\\sigma_{\\min}(A_1 - 0 \\cdot I) = \\sigma_{\\min}(A_1)$. Matrix $A_1$ is singular (e.g., its last row is all zeros), and a matrix is singular if and only if its smallest singular value is zero. Thus, $\\sigma_{\\min}(A_1) = 0$. Since singular values are always non-negative, the minimum value over the entire grid must be $0.0$.\n\n2.  **Test Case 2**: Matrix $A_2=\\mathrm{diag}(1,2,3,4)$ is a normal matrix. A fundamental property of normal matrices is that for any $z \\in \\mathbb{C}$, $\\sigma_{\\min}(A_2 - zI) = \\min_i |\\lambda_i(A_2) - z|$, where $\\lambda_i(A_2)$ are the eigenvalues of $A_2$.\n    - The eigenvalues of $A_2$ are $\\lambda \\in \\{1, 2, 3, 4\\}$.\n    - The grid is a single point $z = 2.5$.\n    - We compute $d = \\min(|1-2.5|, |2-2.5|, |3-2.5|, |4-2.5|) = \\min(1.5, 0.5, 0.5, 1.5) = 0.5$.\n    - We also compute $\\sigma_{\\min}(A_2 - 2.5I)$. The matrix is $A_2 - 2.5I = \\mathrm{diag}(-1.5, -0.5, 0.5, 1.5)$. Its singular values are the absolute values of its diagonal entries, $\\{1.5, 0.5, 0.5, 1.5\\}$. The smallest is $0.5$.\n    - The absolute difference is $|\\sigma_{\\min}(A_2 - 2.5I) - d| = |0.5 - 0.5| = 0.0$.\n\n3.  **Test Case 3**: The number of SVD computations is identical to the number of grid points, $G$. For a grid with $N_x=17$ and $N_y=19$, the total number of points is $G = 17 \\times 19 = 323$.\n\n4.  **Test Case 4**: Given $G=323$ tasks from test case 3 and $p=8$ processors, the ideal speedup is defined as $S = \\min(G, p)$. Thus, $S = \\min(323, 8) = 8$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_sigma_min_on_grid(A, x_min, x_max, y_min, y_max, Nx, Ny):\n    \"\"\"\n    Computes the smallest singular value of (A - zI) for each z on a grid.\n\n    Args:\n        A (np.ndarray): The input square matrix.\n        x_min, x_max (float): Bounds for the real part of z.\n        y_min, y_max (float): Bounds for the imaginary part of z.\n        Nx, Ny (int): Number of grid points along real and imaginary axes.\n\n    Returns:\n        np.ndarray: A 2D array of sigma_min values.\n    \"\"\"\n    n = A.shape[0]\n    I = np.eye(n, dtype=complex)\n    \n    # Ensure matrix A is complex for subsequent operations\n    A_complex = A.astype(complex)\n\n    x_vals = np.linspace(x_min, x_max, Nx)\n    y_vals = np.linspace(y_min, y_max, Ny)\n    \n    sigma_min_matrix = np.zeros((Ny, Nx))\n\n    for i, y in enumerate(y_vals):\n        for j, x in enumerate(x_vals):\n            z = x + 1j * y\n            B = A_complex - z * I\n            \n            # compute_uv=False is more efficient as we only need singular values.\n            # Singular values are returned in descending order.\n            s = np.linalg.svd(B, compute_uv=False)\n            sigma_min_matrix[i, j] = s[-1]\n            \n    return sigma_min_matrix\n\ndef solve():\n    \"\"\"\n    Solves the four test cases specified in the problem statement.\n    \"\"\"\n    \n    # --- Test Case 1: Happy-path non-normal case ---\n    # Define the 5x5 nilpotent Jordan block A1\n    A1 = np.diag(np.ones(4), k=1)\n    \n    # Grid parameters\n    x_min1, x_max1, y_min1, y_max1 = -0.1, 0.1, -0.1, 0.1\n    Nx1, Ny1 = 11, 11\n    \n    # The grid contains z=0. At z=0, sigma_min(A1-0*I) = sigma_min(A1) = 0\n    # since A1 is singular. As sigma_min is always non-negative, the minimum\n    # value over the grid must be 0. We compute it for rigor.\n    sigma_matrix1 = compute_sigma_min_on_grid(A1, x_min1, x_max1, y_min1, y_max1, Nx1, Ny1)\n    result1 = float(np.min(sigma_matrix1))\n\n    # --- Test Case 2: Normal matrix consistency check ---\n    A2 = np.diag([1, 2, 3, 4])\n    z2 = 2.5 + 0j\n    \n    # Compute sigma_min(A2 - zI) using SVD\n    B2 = A2.astype(complex) - z2 * np.eye(4, dtype=complex)\n    s2 = np.linalg.svd(B2, compute_uv=False)\n    sigma_min_from_svd = s2[-1]\n    \n    # Compute d = min_i |lambda_i(A2) - z|\n    eigenvalues_A2 = np.linalg.eigvals(A2)\n    d = np.min(np.abs(eigenvalues_A2 - z2))\n    \n    result2 = float(np.abs(sigma_min_from_svd - d))\n\n    # --- Test Case 3: Complexity accounting (SVD call count) ---\n    Nx3, Ny3 = 17, 19\n    # The number of SVD calls is the total number of grid points, G = Nx * Ny.\n    result3 = int(Nx3 * Ny3)\n\n    # --- Test Case 4: Ideal parallelization speedup ---\n    # G is the number of tasks from case 3. p is the number of processors.\n    G4 = result3\n    p4 = 8\n    # Ideal speedup S = min(G, p).\n    result4 = int(min(G4, p4))\n\n    # Assemble the final list of results\n    final_results = [result1, result2, result3, result4]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Having mastered the basic grid computation, we now apply this tool to a classic problem that reveals the power of pseudospectral analysis. The companion matrix for the Wilkinson polynomial is famously ill-conditioned, meaning its eigenvalues are extremely sensitive to perturbations, a fact that the spectrum alone does not explain. This exercise will guide you through visualizing the pseudospectra of this matrix to understand geometrically how small perturbations can cause large changes in the eigenvalues .",
            "id": "3568831",
            "problem": "Let $A \\in \\mathbb{C}^{n \\times n}$ be the Frobenius companion matrix of the monic Wilkinson polynomial of degree $n=20$, that is, the polynomial $W_{20}(x) = \\prod_{j=1}^{20} (x - j)$ with real roots at the integers $1,2,\\dots,20$. Consider the minimum singular value function $z \\mapsto \\sigma_{\\min}(A - z I)$, where $I$ is the identity matrix and $z \\in \\mathbb{C}$. The $\\varepsilon$-pseudospectrum of $A$ in the matrix $2$-norm is defined as the set $\\Lambda_{\\varepsilon}(A) = \\{ z \\in \\mathbb{C} : \\sigma_{\\min}(A - z I) \\le \\varepsilon \\}$. This set coincides with the set of $z$ that are eigenvalues of $A + E$ for some perturbation $E$ with $\\|E\\|_2 \\le \\varepsilon$.\n\nStarting from the foundational definitions of singular values, the resolvent norm $\\|(A - zI)^{-1}\\|_2$ when $A - zI$ is invertible, and the definition of $\\varepsilon$-pseudospectra, derive an algorithm to compute discrete approximations to contours of the function $\\sigma_{\\min}(A - zI)$ on rectangular grids in the complex plane. Use these contours to reason about and quantify the extreme sensitivity of the eigenvalues of the Wilkinson companion matrix and its non-normality via the geometry of its pseudospectra. Your algorithm must:\n\n- Construct the Frobenius companion matrix $A$ for the monic polynomial with roots at $1,2,\\dots,20$.\n- For each rectangular grid window, evaluate $\\sigma_{\\min}(A - zI)$ at each grid point $z$.\n- For a given threshold $\\varepsilon$ in each test case, compute:\n  1. The minimum value of $\\sigma_{\\min}(A - zI)$ attained on the grid.\n  2. The fraction of grid points (expressed as a decimal, not a percentage) belonging to $\\Lambda_{\\varepsilon}(A)$, that is, those for which $\\sigma_{\\min}(A - zI) \\le \\varepsilon$.\n  3. The number of connected components (using $4$-neighbor connectivity on the grid graph) of the set of grid points where $\\sigma_{\\min}(A - zI) \\le \\varepsilon$, which serves as a discrete proxy for the connectivity of pseudospectral level sets. Two grid points are considered adjacent if their indices differ by exactly one in either the real or imaginary axis direction.\n\nYour program must implement this algorithm for the following test suite (each window is specified by real and imaginary bounds, grid resolution, and $\\varepsilon$):\n\n- Test case $1$ (cluster of roots near $8,9,10,11,12$):\n  - Real axis bounds: $[7, 12]$.\n  - Imaginary axis bounds: $[-\\tfrac{3}{2}, \\tfrac{3}{2}]$.\n  - Grid resolution: $41 \\times 41$ points.\n  - Threshold: $\\varepsilon = 10^{-6}$.\n\n- Test case $2$ (cluster near the smallest roots $1,2,3$):\n  - Real axis bounds: $[\\tfrac{1}{2}, \\tfrac{7}{2}]$.\n  - Imaginary axis bounds: $[-1, 1]$.\n  - Grid resolution: $41 \\times 41$ points.\n  - Threshold: $\\varepsilon = 10^{-8}$.\n\n- Test case $3$ (tight window around two consecutive roots $10,11$):\n  - Real axis bounds: $[\\tfrac{39}{4}, \\tfrac{45}{4}]$.\n  - Imaginary axis bounds: $[-\\tfrac{3}{4}, \\tfrac{3}{4}]$.\n  - Grid resolution: $41 \\times 41$ points.\n  - Threshold: $\\varepsilon = 10^{-7}$.\n\nScientific realism constraints:\n\n- All quantities are purely mathematical; no physical units apply.\n- Angles, if any arise, are to be in radians, but no angular quantities are required in this problem.\n\nFinal output specification:\n\n- Your program should produce a single line of output containing the results aggregated in the order of the test suite. For each test case, output the three values in the order described above: the minimum $\\sigma_{\\min}$ on the grid for that case, the fraction of points with $\\sigma_{\\min} \\le \\varepsilon$, and the number of connected components. The final output should be a comma-separated list enclosed in square brackets. For example, it should have the form $[\\text{min}_1,\\text{frac}_1,\\text{comp}_1,\\text{min}_2,\\text{frac}_2,\\text{comp}_2,\\text{min}_3,\\text{frac}_3,\\text{comp}_3]$, where each $\\text{min}_k$ is a floating-point number, each $\\text{frac}_k$ is a decimal, and each $\\text{comp}_k$ is an integer.",
            "solution": "The problem requires an analysis of the pseudospectra of the Frobenius companion matrix associated with the Wilkinson polynomial of degree $20$. This analysis serves to computationally demonstrate the extreme sensitivity of the eigenvalues of this highly non-normal matrix. A valid numerical algorithm will be derived and subsequently implemented.\n\nThe fundamental object of study is the $\\varepsilon$-pseudospectrum of a matrix $A \\in \\mathbb{C}^{n \\times n}$, defined for a given $\\varepsilon > 0$ as the set\n$$ \\Lambda_{\\varepsilon}(A) = \\{ z \\in \\mathbb{C} : \\|(A - zI)^{-1}\\|_2 \\ge \\varepsilon^{-1} \\}. $$\nHere, $\\| \\cdot \\|_2$ denotes the matrix $2$-norm (spectral norm). The resolvent norm $\\|(A - zI)^{-1}\\|_2$ is defined for all $z$ not in the spectrum of $A$, $\\Lambda(A)$. A key property connecting the resolvent norm to singular values is that for any square matrix $M$, $\\|M^{-1}\\|_2 = 1/\\sigma_{\\min}(M)$, where $\\sigma_{\\min}(M)$ is the smallest singular value of $M$. This allows for an equivalent and more computationally stable definition of the pseudospectrum, which is valid for all $z \\in \\mathbb{C}$:\n$$ \\Lambda_{\\varepsilon}(A) = \\{ z \\in \\mathbb{C} : \\sigma_{\\min}(A - zI) \\le \\varepsilon \\}. $$\nThis definition includes the eigenvalues themselves, where $\\sigma_{\\min}(A - \\lambda I) = 0$ for any $\\lambda \\in \\Lambda(A)$. The values of the function $z \\mapsto \\sigma_{\\min}(A - zI)$ form a surface over the complex plane, and the $\\varepsilon$-pseudospectrum consists of the regions where this surface dips below the height $\\varepsilon$.\n\nThe algorithmic procedure to solve the problem is as follows:\n\n**1. Construct the Wilkinson Companion Matrix $A$**\n\nThe problem specifies the monic Wilkinson polynomial of degree $n=20$, whose roots are the integers $1, 2, \\dots, 20$:\n$$ W_{20}(x) = \\prod_{j=1}^{20} (x - j). $$\nLet's expand this polynomial into the power basis: $W_{20}(x) = x^{20} + c_{19} x^{19} + \\dots + c_1 x + c_0$. The Frobenius companion matrix $A$ for this polynomial has the form:\n$$ A = \\begin{pmatrix}\n0 & 0 & \\dots & 0 & -c_0 \\\\\n1 & 0 & \\dots & 0 & -c_1 \\\\\n0 & 1 & \\dots & 0 & -c_2 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n0 & 0 & \\dots & 1 & -c_{19}\n\\end{pmatrix} \\in \\mathbb{C}^{20 \\times 20}. $$\nThe characteristic polynomial of this matrix $A$ is precisely $W_{20}(x)$, so its eigenvalues are $\\lambda_j = j$ for $j=1, 2, \\dots, 20$. The coefficients $c_k$ can be computed numerically from the roots.\n\n**2. Evaluate $\\sigma_{\\min}(A-zI)$ on a Grid**\n\nFor each test case, we define a rectangular window in the complex plane with specified real bounds $[x_{\\min}, x_{\\max}]$ and imaginary bounds $[y_{\\min}, y_{\\max}]$. This window is discretized into a grid of $N_x \\times N_y$ points. In this problem, all grids have a resolution of $41 \\times 41$.\nThe grid points are given by $z_{jk} = x_j + \\mathrm{i}y_k$, where\n- $x_j = x_{\\min} + j \\frac{x_{\\max} - x_{\\min}}{N_x - 1}$ for $j=0, 1, \\dots, N_x-1$.\n- $y_k = y_{\\min} + k \\frac{y_{\\max} - y_{\\min}}{N_y - 1}$ for $k=0, 1, \\dots, N_y-1$.\n\nAt each grid point $z_{jk}$, we perform the following steps:\n- Form the shifted matrix $M_{jk} = A - z_{jk}I$.\n- Compute the singular values of $M_{jk}$. The smallest of these is $\\sigma_{\\min}(A - z_{jk}I)$.\n- Store this value in a $N_y \\times N_x$ matrix, $S$, where $S_{kj} = \\sigma_{\\min}(A - z_{jk}I)$.\n\n**3. Analyze the Computed Pseudospectral Data**\n\nThe matrix $S$ of $\\sigma_{\\min}$ values contains all the necessary information to compute the required quantities for each test case.\n\n**a. Minimum $\\sigma_{\\min}$ on the grid:**\nThis is found by taking the minimum value in the entire matrix $S$:\n$$ \\sigma_{\\min}^{\\text{grid}} = \\min_{j,k} S_{kj}. $$\n\n**b. Fraction of points in $\\Lambda_{\\varepsilon}(A)$:**\nFor a given threshold $\\varepsilon$, we identify the grid points belonging to the discrete approximation of the $\\varepsilon$-pseudospectrum. We create a binary mask $B$ where $B_{kj}=1$ if $S_{kj} \\le \\varepsilon$ and $B_{kj}=0$ otherwise. The fraction is the ratio of the number of such points to the total number of grid points:\n$$ f_{\\varepsilon} = \\frac{1}{N_x N_y} \\sum_{k=0}^{N_y-1} \\sum_{j=0}^{N_x-1} B_{kj}. $$\n\n**c. Number of Connected Components:**\nThis requires treating the binary mask $B$ as a grid graph. The vertices of the graph are the grid indices $(k, j)$ for which $B_{kj}=1$. An edge exists between two vertices $(k, j)$ and $(k', j')$ if they are adjacent on the grid, based on $4$-neighbor connectivity, i.e., $|k-k'| + |j-j'|=1$. The task is to count the number of connected components in this graph.\n\nAn effective algorithm for this is to iterate through each cell of the grid. If a cell $(k,j)$ with $B_{kj}=1$ is found that has not yet been visited as part of a component, we increment a component counter. Then, we initiate a graph traversal algorithm, such as Breadth-First Search (BFS) or Depth-First Search (DFS), starting from $(k,j)$ to find and mark all cells belonging to the same component. The process is repeated until all cells have been checked.\n\n- Initialize `count = 0` and a boolean `visited` grid of size $N_y \\times N_x$ to all `false`.\n- For $k$ from $0$ to $N_y-1$:\n    - For $j$ from $0$ to $N_x-1$:\n        - If $B_{kj}=1$ and `visited[k,j]` is `false`:\n            - Increment `count`.\n            - Start a BFS traversal from $(k,j)$:\n                - Create a queue and add $(k,j)$. Mark `visited[k,j]` as `true`.\n                - While the queue is not empty:\n                    - Dequeue a cell $(r,c)$.\n                    - For each of its $4$ neighbors $(r',c')$:\n                        - If the neighbor is within bounds, $B_{r'c'}=1$, and `visited[r',c']` is `false`:\n                            - Mark `visited[r',c']` as `true` and enqueue $(r',c')$.\n\nAfter iterating through all cells, `count` will hold the total number of connected components. This entire procedure is applied to each of the three test cases specified in the problem statement.",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import svdvals\nimport collections\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for pseudospectra analysis.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (cluster of roots near 8,9,10,11,12)\n        {\n            \"real_bounds\": [7.0, 12.0],\n            \"imag_bounds\": [-1.5, 1.5],\n            \"resolution\": (41, 41),\n            \"epsilon\": 1e-6,\n        },\n        # Test case 2 (cluster near smallest roots 1,2,3)\n        {\n            \"real_bounds\": [0.5, 3.5],\n            \"imag_bounds\": [-1.0, 1.0],\n            \"resolution\": (41, 41),\n            \"epsilon\": 1e-8,\n        },\n        # Test case 3 (tight window around two consecutive roots 10,11)\n        {\n            \"real_bounds\": [9.75, 11.25],\n            \"imag_bounds\": [-0.75, 0.75],\n            \"resolution\": (41, 41),\n            \"epsilon\": 1e-7,\n        },\n    ]\n\n    # Pre-compute the companion matrix as it's the same for all cases.\n    n = 20\n    roots = np.arange(1, n + 1, dtype=float)\n    # np.poly gives coefficients of (x-r1)(x-r2)...\n    # For a monic polynomial x^n + c_{n-1}x^{n-1} + ... + c_0,\n    # the coeffs are [1, c_{n-1}, ..., c_0]\n    coeffs = np.poly(roots)\n    # The last column of the companion matrix is [-c_0, -c_1, ..., -c_{n-1}]^T.\n    neg_coeffs = -coeffs[1:][::-1]\n    \n    A = np.diag(np.ones(n - 1), k=-1)\n    A[:, -1] = neg_coeffs\n\n    results = []\n    \n    for case in test_cases:\n        min_sigma, fraction, components = analyze_pseudospectrum(\n            A,\n            case[\"real_bounds\"],\n            case[\"imag_bounds\"],\n            case[\"resolution\"],\n            case[\"epsilon\"],\n        )\n        results.extend([min_sigma, fraction, components])\n\n    # Format the final output string.\n    output_str = f\"[{','.join(f'{val:.8g}' if isinstance(val, float) else str(val) for val in results)}]\"\n    print(output_str)\n\ndef analyze_pseudospectrum(A, real_bounds, imag_bounds, resolution, epsilon):\n    \"\"\"\n    Computes pseudospectral properties for a given matrix A on a specified grid.\n    \"\"\"\n    # 1. Setup grid and evaluate sigma_min\n    nx, ny = resolution\n    x_space = np.linspace(real_bounds[0], real_bounds[1], nx)\n    y_space = np.linspace(imag_bounds[0], imag_bounds[1], ny)\n    \n    sigma_min_grid = np.zeros((ny, nx))\n    identity = np.eye(A.shape[0])\n    \n    for i in range(ny):\n        for j in range(nx):\n            z = x_space[j] + 1j * y_space[i]\n            M = A - z * identity\n            # svdvals returns singular values in descending order. The min is the last.\n            s = svdvals(M)\n            sigma_min_grid[i, j] = s[-1]\n            \n    # 2. Analyze grid data\n    # 2.a. Minimum sigma_min on the grid\n    min_sigma_on_grid = np.min(sigma_min_grid)\n    \n    # 2.b. Fraction of points inside the epsilon-pseudospectrum\n    threshold_mask = sigma_min_grid = epsilon\n    fraction_inside = np.sum(threshold_mask) / (nx * ny)\n    \n    # 2.c. Number of connected components\n    num_components = count_connected_components(threshold_mask)\n    \n    return min_sigma_on_grid, fraction_inside, num_components\n\ndef count_connected_components(mask):\n    \"\"\"\n    Counts connected components in a boolean mask using 4-neighbor connectivity.\n    \"\"\"\n    rows, cols = mask.shape\n    visited = np.zeros_like(mask, dtype=bool)\n    count = 0\n    \n    for r in range(rows):\n        for c in range(cols):\n            if mask[r, c] and not visited[r, c]:\n                count += 1\n                q = collections.deque([(r, c)])\n                visited[r, c] = True\n                while q:\n                    curr_r, curr_c = q.popleft()\n                    # Check 4 neighbors (up, down, left, right)\n                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                        next_r, next_c = curr_r + dr, curr_c + dc\n                        if (0 = next_r  rows and \n                            0 = next_c  cols and \n                            mask[next_r, next_c] and not visited[next_r, next_c]):\n                            visited[next_r, next_c] = True\n                            q.append((next_r, next_c))\n    return count\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "While grid-based plotting provides a qualitative overview, we often need to compute specific quantitative features of the pseudospectrum with high accuracy and efficiency. This advanced practice moves beyond simple plotting to the problem of finding the pseudospectral radius with respect to a given contour, a key value in stability analysis. You will design and compare uniform and adaptive algorithms, exploring concepts of error estimation and optimization in the context of pseudospectral computation .",
            "id": "3568810",
            "problem": "You are given a square complex matrix $A \\in \\mathbb{C}^{n \\times n}$ and a simple closed contour $\\Gamma \\subset \\mathbb{C}$ specified by a $C^{1}$ parameterization $\\gamma:[0,1]\\rightarrow \\mathbb{C}$ with $\\gamma(0)=\\gamma(1)$, and assume that the interior of $\\Gamma$ contains the spectrum of $A$. Let the $\\varepsilon$-pseudospectrum of $A$ in the spectral norm be defined by\n$$\n\\Lambda_{\\varepsilon}(A) \\equiv \\{ z \\in \\mathbb{C} : \\sigma_{\\min}(z I - A) \\le \\varepsilon \\},\n$$\nwhere $\\sigma_{\\min}(B)$ denotes the smallest singular value of a matrix $B$. Consider the critical value\n$$\n\\varepsilon_{\\star} \\equiv \\min_{z \\in \\Gamma} \\sigma_{\\min}(z I - A),\n$$\nwhich is the largest $\\varepsilon$ such that $\\Lambda_{\\varepsilon}(A)$ is contained in the interior of $\\Gamma$. Your tasks are:\n\n1) From first principles, derive and justify the identity\n$$\n\\varepsilon_{\\star} \\;=\\; \\min_{z \\in \\Gamma} \\sigma_{\\min}(z I - A),\n$$\nstarting from the definition of $\\Lambda_{\\varepsilon}(A)$ and the singular-value characterization of the resolvent norm. Explain why $\\varepsilon_{\\star}$ is the largest $\\varepsilon$ such that $\\Lambda_{\\varepsilon}(A) \\subset \\mathrm{int}(\\Gamma)$ under the stated assumptions.\n\n2) Prove that the function $s:\\mathbb{C}\\to \\mathbb{R}_{\\ge 0}$ defined by $s(z) \\equiv \\sigma_{\\min}(z I - A)$ is $1$-Lipschitz with respect to the complex modulus, i.e.,\n$$\n\\big| s(z) - s(w) \\big| \\le |z-w| \\quad \\text{for all } z,w \\in \\mathbb{C}.\n$$\nUse this Lipschitz property together with a Lipschitz constant for $\\gamma$ to derive a computable error bound when $\\varepsilon_{\\star}$ is approximated by sampling $s(z)$ only at a finite set of points on $\\Gamma$.\n\n3) Algorithm design:\n   - Design a uniform-sampling estimator that uses $m \\in \\mathbb{N}$ equispaced parameter values $t_{k} = \\frac{k}{m}$ for $k \\in \\{0,1,\\dots,m-1\\}$, evaluates $s(\\gamma(t_{k}))$, and returns the discrete minimum\n     $$\n     \\varepsilon_{m}^{\\mathrm{unif}} \\equiv \\min_{0 \\le k \\le m-1} \\sigma_{\\min}(\\gamma(t_{k}) I - A).\n     $$\n     Assume $\\gamma$ has a known bound $L_{\\gamma}$ on its speed, i.e., $\\sup_{t \\in [0,1]} |\\gamma'(t)| \\le L_{\\gamma}$. Derive a bound of the form\n     $$\n     0 \\le \\varepsilon_{m}^{\\mathrm{unif}} - \\varepsilon_{\\star} \\le \\frac{L_{\\gamma}}{2 m}.\n     $$\n   - Design an adaptive, derivative-free global minimization algorithm on $[0,1]$ that exploits the Lipschitz minorant\n     $$\n     s(\\gamma(t)) \\ge \\min\\{ s(\\gamma(a)), s(\\gamma(b)) \\} - L_{\\gamma}\\,\\frac{b-a}{2} \\quad \\text{for } t \\in [a,b],\n     $$\n     to refine intervals and certify an approximation $\\varepsilon_{\\mathrm{adp}}$ satisfying\n     $$\n     |\\varepsilon_{\\mathrm{adp}} - \\varepsilon_{\\star}| \\le \\tau,\n     $$\n     for a prescribed tolerance $\\tau  0$.\n\n4) Implementation requirements:\n   - Implement a program that computes $\\varepsilon_{\\star}$ for a given $A$ and $\\Gamma$ in two ways: (i) a high-resolution reference via dense uniform sampling with $M$ points, and (ii) the two algorithms from task $3$ (a coarse uniform-sampling estimator and the adaptive algorithm).\n   - For the contours below, provide $\\gamma$ and a valid bound $L_{\\gamma}$ on $\\sup_{t} |\\gamma'(t)|$:\n     - Circle: $\\gamma(t) = c + R e^{2 \\pi i t}$, with $L_{\\gamma} = 2 \\pi R$.\n     - Axis-aligned square of half-width $a$ centered at $c$: parametrize each side linearly over four equal subintervals; then $L_{\\gamma} = 8 a$.\n   - Compute $\\sigma_{\\min}(z I - A)$ using the singular value decomposition.\n\n5) Test suite:\n   For each test case, assume all eigenvalues of $A$ lie strictly inside the interior of $\\Gamma$ unless otherwise noted. Use the following test cases:\n   - Test case $1$ (non-normal, circle): $A_{1} = \\begin{bmatrix} 1  20 \\\\ 0  1 \\end{bmatrix}$, $\\gamma_{1}(t) = 1 + 1.2 e^{2 \\pi i t}$, $L_{\\gamma_{1}} = 2 \\pi \\cdot 1.2$, coarse $m=64$, dense $M=4096$, adaptive tolerance $\\tau = 10^{-3}$.\n   - Test case $2$ (upper-triangular, circle): $A_{2} = \\begin{bmatrix} -1  0.2  0 \\\\ 0  2  0.3 \\\\ 0  0  3 \\end{bmatrix}$, $\\gamma_{2}(t) = 1 + 3.2 e^{2 \\pi i t}$, $L_{\\gamma_{2}} = 2 \\pi \\cdot 3.2$, coarse $m=96$, dense $M=4096$, adaptive tolerance $\\tau = 10^{-3}$.\n   - Test case 3 (Jordan block, square): $A_{3}$ is the $4 \\times 4$ Jordan block with eigenvalue $0$ and ones on the superdiagonal. The contour $\\gamma_3$ is the square centered at $0$ with half-width $a=1$ (i.e., vertices at $\\pm 1 \\pm i$). Use a parameterization with constant speed, which implies a Lipschitz constant $L_{\\gamma_3} = 8$. Use a coarse sample count of $m=128$, a dense reference count of $M=4096$, and an adaptive tolerance of $\\tau=10^{-3}$.\n\n6) Program output specification:\n   - For each test case, compute the following quantities:\n     - $\\varepsilon_{\\mathrm{ref}}$: dense reference minimum using $M$ samples.\n     - $\\varepsilon_{m}^{\\mathrm{unif}}$: coarse uniform-sampling estimate using $m$ samples.\n     - $e_{\\mathrm{unif}} \\equiv \\varepsilon_{m}^{\\mathrm{unif}} - \\varepsilon_{\\mathrm{ref}}$.\n     - $b_{\\mathrm{unif}} \\equiv \\frac{L_{\\gamma}}{2 m}$.\n     - $p_{\\mathrm{unif}}$: a boolean equal to $\\mathrm{True}$ if $e_{\\mathrm{unif}} \\le b_{\\mathrm{unif}} + 10^{-12}$ and $\\mathrm{False}$ otherwise.\n     - $\\varepsilon_{\\mathrm{adp}}$: adaptive estimate with tolerance $\\tau$.\n     - $e_{\\mathrm{adp}} \\equiv |\\varepsilon_{\\mathrm{adp}} - \\varepsilon_{\\mathrm{ref}}|$.\n     - $p_{\\mathrm{adp}}$: a boolean equal to $\\mathrm{True}$ if $e_{\\mathrm{adp}} \\le \\tau + 10^{-12}$ and $\\mathrm{False}$ otherwise.\n   - Your program should produce a single line of output containing all results for the three test cases in order as a single, flat, comma-separated Python list:\n     $$\n     [\\varepsilon_{\\mathrm{ref}}^{(1)}, \\varepsilon_{m}^{\\mathrm{unif},(1)}, e_{\\mathrm{unif}}^{(1)}, b_{\\mathrm{unif}}^{(1)}, p_{\\mathrm{unif}}^{(1)}, \\varepsilon_{\\mathrm{adp}}^{(1)}, e_{\\mathrm{adp}}^{(1)}, p_{\\mathrm{adp}}^{(1)}, \\varepsilon_{\\mathrm{ref}}^{(2)}, \\dots, p_{\\mathrm{adp}}^{(3)} ].\n     $$\n     No additional text should be printed. All numerical quantities must be printed as floating-point numbers, and all logical indicators as booleans.",
            "solution": "The problem is assessed to be valid as it is scientifically grounded in numerical linear algebra, well-posed, objective, and internally consistent. It presents a standard but comprehensive problem concerning the computation of the pseudospectral radius with respect to a given contour.\n\n### Part 1: Derivation and Justification of $\\varepsilon_{\\star}$\n\nThe $\\varepsilon$-pseudospectrum of a matrix $A \\in \\mathbb{C}^{n \\times n}$ is defined as\n$$\n\\Lambda_{\\varepsilon}(A) \\equiv \\{ z \\in \\mathbb{C} : \\sigma_{\\min}(z I - A) \\le \\varepsilon \\},\n$$\nwhere $\\sigma_{\\min}(B)$ is the smallest singular value of a matrix $B$. For any $z$ that is not an eigenvalue of $A$ (i.e., $z \\notin \\mathrm{spec}(A)$), the matrix $zI-A$ is invertible, and its smallest singular value is related to the spectral norm of its inverse, the resolvent $R(z,A) = (zI-A)^{-1}$, by\n$$\n\\sigma_{\\min}(z I - A) = \\frac{1}{\\|(zI-A)^{-1}\\|_2}.\n$$\nThus, for $z \\notin \\mathrm{spec}(A)$, the condition $\\sigma_{\\min}(z I - A) \\le \\varepsilon$ is equivalent to $\\|(zI-A)^{-1}\\|_2 \\ge 1/\\varepsilon$. For $z \\in \\mathrm{spec}(A)$, $zI-A$ is singular, so $\\sigma_{\\min}(zI-A) = 0$, and the condition holds for any $\\varepsilon \\ge 0$. So, $\\mathrm{spec}(A) \\subseteq \\Lambda_{\\varepsilon}(A)$ for all $\\varepsilon \\ge 0$.\n\nWe are given a simple closed contour $\\Gamma$ whose interior, $\\mathrm{int}(\\Gamma)$, contains the spectrum of $A$. We seek the largest $\\varepsilon$, denoted $\\varepsilon_{\\star}$, such that $\\Lambda_{\\varepsilon}(A)$ is entirely contained in $\\mathrm{int}(\\Gamma)$.\n\nThe function $s(z) \\equiv \\sigma_{\\min}(zI-A)$ is a continuous function of $z \\in \\mathbb{C}$. As a result, the sets $\\Lambda_{\\varepsilon}(A) = s^{-1}([0, \\varepsilon])$ are closed. For $\\varepsilon=0$, $\\Lambda_0(A) = \\mathrm{spec}(A)$, which lies strictly inside $\\Gamma$. As $\\varepsilon$ increases, the sets $\\Lambda_{\\varepsilon}(A)$ are nested, i.e., $\\Lambda_{\\varepsilon_1}(A) \\subseteq \\Lambda_{\\varepsilon_2}(A)$ if $\\varepsilon_1 \\le \\varepsilon_2$. Since these sets expand from $\\mathrm{spec}(A)$, there will be a critical value $\\varepsilon_{\\star}  0$ where $\\Lambda_{\\varepsilon_{\\star}}(A)$ first \"touches\" the boundary $\\Gamma$.\n\nFor any $\\varepsilon  \\varepsilon_{\\star}$, $\\Lambda_{\\varepsilon}(A)$ is strictly contained in $\\mathrm{int}(\\Gamma)$. For any $\\varepsilon  \\varepsilon_{\\star}$, $\\Lambda_{\\varepsilon}(A)$ is no longer contained in $\\mathrm{int}(\\Gamma)$, meaning there is some point $z \\in \\Lambda_{\\varepsilon}(A)$ such that $z \\in \\Gamma$ or $z$ is in the exterior of $\\Gamma$. By the nested property and the continuity of the expansion, the critical transition must occur when a point on the boundary of $\\Lambda_{\\varepsilon_{\\star}}(A)$ coincides with a point on $\\Gamma$.\n\nThe boundary of $\\Lambda_{\\varepsilon}(A)$ is the level set $\\{z \\in \\mathbb{C} : \\sigma_{\\min}(zI-A) = \\varepsilon\\}$. Therefore, for the critical value $\\varepsilon_{\\star}$, there must exist at least one point $z_{\\star} \\in \\Gamma$ that is also on the boundary of $\\Lambda_{\\varepsilon_{\\star}}(A)$. This means $\\sigma_{\\min}(z_{\\star}I-A) = \\varepsilon_{\\star}$.\n\nFurthermore, for $\\Lambda_{\\varepsilon_{\\star}}(A)$ to be contained within $\\mathrm{int}(\\Gamma) \\cup \\Gamma$, every point $z \\in \\Gamma$ must not belong to $\\Lambda_{\\varepsilon'}(A)$ for any $\\varepsilon'  \\varepsilon_{\\star}$. This requires that for all $z \\in \\Gamma$, $\\sigma_{\\min}(zI-A) \\not\\le \\varepsilon'$, which implies $\\sigma_{\\min}(zI-A) \\ge \\varepsilon_{\\star}$ for all $z \\in \\Gamma$.\n\nCombining these two conditions, we must have $\\varepsilon_{\\star} = \\sigma_{\\min}(z_{\\star}I-A)$ for some $z_{\\star} \\in \\Gamma$, and $\\varepsilon_{\\star} \\le \\sigma_{\\min}(zI-A)$ for all $z \\in \\Gamma$. This leads to the conclusion that $\\varepsilon_{\\star}$ is the minimum value of the function $s(z) = \\sigma_{\\min}(zI-A)$ over the compact set $\\Gamma$:\n$$\n\\varepsilon_{\\star} = \\min_{z \\in \\Gamma} \\sigma_{\\min}(z I - A).\n$$\nThis value exists because $s(z)$ is a continuous function and $\\Gamma$ is a compact set.\n\n### Part 2: Lipschitz Continuity\n\nWe want to prove that the function $s(z) \\equiv \\sigma_{\\min}(z I - A)$ is $1$-Lipschitz, i.e., $|s(z) - s(w)| \\le |z-w|$ for all $z,w \\in \\mathbb{C}$.\n\nThis is a direct consequence of Weyl's inequality for singular values. For any two matrices $X, Y \\in \\mathbb{C}^{n \\times n}$, the singular values $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_n$ satisfy\n$$\n|\\sigma_k(X) - \\sigma_k(Y)| \\le \\|X-Y\\|_2 \\quad \\text{for } k=1, \\dots, n,\n$$\nwhere $\\|\\cdot\\|_2$ denotes the spectral norm (the largest singular value).\n\nLet's apply this inequality to our function $s(z)$. Let $X = zI-A$ and $Y = wI-A$. The smallest singular value is $\\sigma_n$, so we are interested in $|\\sigma_n(X) - \\sigma_n(Y)|$. The difference between the matrices is\n$$\nX-Y = (zI-A) - (wI-A) = (z-w)I.\n$$\nThe spectral norm of this difference matrix is\n$$\n\\|(z-w)I\\|_2 = |z-w| \\|I\\|_2 = |z-w| \\cdot 1 = |z-w|.\n$$\nSubstituting this into Weyl's inequality for $k=n$, we obtain\n$$\n|\\sigma_{\\min}(zI - A) - \\sigma_{\\min}(wI - A)| \\le \\|(z-w)I\\|_2 = |z-w|.\n$$\nThis establishes that $s(z)$ is $1$-Lipschitz with respect to the complex modulus.\n\nNow, consider the composition $f(t) = s(\\gamma(t))$, where $\\gamma:[0,1] \\to \\mathbb{C}$ is a $C^1$ parameterization of $\\Gamma$ with $\\sup_{t \\in [0,1]} |\\gamma'(t)| \\le L_{\\gamma}$. The function $\\gamma$ is $L_{\\gamma}$-Lipschitz on $[0,1]$, since for any $t_1, t_2 \\in [0,1]$, the Mean Value Inequality gives\n$$\n|\\gamma(t_1) - \\gamma(t_2)| \\le \\left(\\sup_{\\xi \\in [t_1,t_2]} |\\gamma'(\\xi)|\\right)|t_1-t_2| \\le L_{\\gamma}|t_1-t_2|.\n$$\nSince $s(z)$ is $1$-Lipschitz and $\\gamma(t)$ is $L_{\\gamma}$-Lipschitz, their composition $f(t) = s(\\gamma(t))$ is $L_{\\gamma}$-Lipschitz:\n$$\n|f(t_1) - f(t_2)| = |s(\\gamma(t_1)) - s(\\gamma(t_2))| \\le 1 \\cdot |\\gamma(t_1) - \\gamma(t_2)| \\le L_{\\gamma}|t_1-t_2|.\n$$\nThis Lipschitz property of $f(t)$ is key to deriving error bounds for numerical approximations of $\\varepsilon_{\\star} = \\min_{t \\in [0,1]} f(t)$.\n\n### Part 3: Algorithm Design\n\n#### Uniform-Sampling Estimator\n\nThe uniform-sampling estimator is defined as\n$$\n\\varepsilon_{m}^{\\mathrm{unif}} \\equiv \\min_{0 \\le k \\le m-1} \\sigma_{\\min}(\\gamma(t_{k}) I - A) = \\min_{0 \\le k \\le m-1} f(t_k),\n$$\nwhere $t_k = k/m$ for $k \\in \\{0, \\dots, m-1\\}$. Let $t_{\\star} \\in [0,1]$ be a point where the true minimum is achieved, i.e., $f(t_{\\star}) = \\varepsilon_{\\star}$.\n\nBy construction, $\\varepsilon_{m}^{\\mathrm{unif}}$ is the minimum of $f$ over a finite set of points, while $\\varepsilon_{\\star}$ is the minimum over the entire interval $[0,1]$. Thus, it is clear that $\\varepsilon_{m}^{\\mathrm{unif}} \\ge \\varepsilon_{\\star}$, which means $0 \\le \\varepsilon_{m}^{\\mathrm{unif}} - \\varepsilon_{\\star}$.\n\nTo find an upper bound on the error, we note that the sampling points $t_k$ are equispaced with a distance of $1/m$. For the point $t_{\\star}$, there must exist a sampling point $t_j$ such that their distance is at most half the spacing, i.e., $|t_{\\star} - t_j| \\le \\frac{1}{2m}$.\n\nUsing the $L_{\\gamma}$-Lipschitz property of $f(t)$:\n$$\n|f(t_j) - f(t_{\\star})| \\le L_{\\gamma} |t_j - t_{\\star}| \\le L_{\\gamma} \\frac{1}{2m}.\n$$\nThis implies $f(t_j) - f(t_{\\star}) \\le \\frac{L_{\\gamma}}{2m}$, or $f(t_j) - \\varepsilon_{\\star} \\le \\frac{L_{\\gamma}}{2m}$.\nThe uniform estimator $\\varepsilon_{m}^{\\mathrm{unif}}$ is the minimum over all sampled values, so $\\varepsilon_{m}^{\\mathrm{unif}} \\le f(t_j)$ for any $j$. Therefore,\n$$\n\\varepsilon_{m}^{\\mathrm{unif}} - \\varepsilon_{\\star} \\le f(t_j) - \\varepsilon_{\\star} \\le \\frac{L_{\\gamma}}{2m}.\n$$\nCombining the lower and upper bounds, we have the desired result:\n$$\n0 \\le \\varepsilon_{m}^{\\mathrm{unif}} - \\varepsilon_{\\star} \\le \\frac{L_{\\gamma}}{2m}.\n$$\n\n#### Adaptive, Derivative-Free Minimization Algorithm\n\nThe goal is to find an estimate $\\varepsilon_{\\mathrm{adp}}$ such that $|\\varepsilon_{\\mathrm{adp}} - \\varepsilon_{\\star}| \\le \\tau$ for a given tolerance $\\tau  0$. We will design an algorithm based on the principles of Lipschitz global optimization (related to the Piyavskii-Shubert algorithm).\n\nThe function to minimize is $f(t) = s(\\gamma(t))$ over $t \\in [0,1]$. We know its Lipschitz constant is bounded by $L_{\\gamma}$. The problem provides a specific lower bound on the minimum of $f(t)$ in an interval $[a,b]$:\n$$\n\\min_{t \\in [a,b]} f(t) \\ge \\min\\{ f(a), f(b) \\} - L_{\\gamma}\\,\\frac{b-a}{2}.\n$$\nThis lower bound allows us to prune subintervals that are guaranteed not to contain the global minimum. The algorithm proceeds as follows:\n\n1.  **Initialization**:\n    -   Start with the interval $[0,1]$. Since $\\gamma(0)=\\gamma(1)$, we have $f(0)=f(1)$.\n    -   Evaluate $f(0)$ and set the current best estimate of the minimum to $\\varepsilon_{\\mathrm{current}} = f(0)$.\n    -   Use a min-priority queue to store subintervals to be explored. An item in the queue will be a tuple `(lower_bound, a, b)` representing the interval $[a,b]$ and a certified lower bound for $f(t)$ on it.\n    -   Add the initial interval to the queue: calculate $L_{[0,1]} = f(0) - L_{\\gamma}\\frac{1-0}{2}$ and push `(L_{[0,1]}, 0, 1)` to the queue.\n    -   Maintain a dictionary to memoize evaluated points $(t, f(t))$ to avoid re-computation.\n\n2.  **Iteration**:\n    -   Loop until the termination condition is met.\n    -   Extract the interval $[a,b]$ with the smallest lower bound from the priority queue. Let this global lower bound be $L_{\\mathrm{global}}$.\n    -   **Termination Check**: The true minimum $\\varepsilon_{\\star}$ is bounded by $L_{\\mathrm{global}} \\le \\varepsilon_{\\star} \\le \\varepsilon_{\\mathrm{current}}$. If the gap $\\varepsilon_{\\mathrm{current}} - L_{\\mathrm{global}} \\le \\tau$, the algorithm has succeeded. We can set $\\varepsilon_{\\mathrm{adp}} = \\varepsilon_{\\mathrm{current}}$ and terminate, since $0 \\le \\varepsilon_{\\mathrm{adp}} - \\varepsilon_{\\star} \\le \\tau$.\n    -   **Refinement**: If not terminated, split the interval $[a,b]$ into two sub-intervals by sampling a new point. A simple and effective choice is the midpoint $c = (a+b)/2$.\n    -   Evaluate $f(c)$ and update the current best estimate: $\\varepsilon_{\\mathrm{current}} = \\min(\\varepsilon_{\\mathrm{current}}, f(c))$.\n    -   **Update Queue**: Create two new subintervals, $[a,c]$ and $[c,b]$. For each, calculate its new lower bound using the provided formula and add it to the priority queue.\n        -   For $[a,c]$: $L_{[a,c]} = \\min\\{f(a), f(c)\\} - L_{\\gamma}\\frac{c-a}{2}$. Push `(L_{[a,c]}, a, c)`.\n        -   For $[c,b]$: $L_{[c,b]} = \\min\\{f(c), f(b)\\} - L_{\\gamma}\\frac{b-c}{2}$. Push `(L_{[c,b]}, c, b)`.\n\n3.  **Output**: Return the final certified estimate $\\varepsilon_{\\mathrm{adp}}$. This algorithm is guaranteed to converge because as the interval widths $(b-a)$ decrease, the lower bounds become tighter, eventually reducing the gap $\\varepsilon_{\\mathrm{current}} - L_{\\mathrm{global}}$ below any given $\\tau  0$.",
            "answer": "```python\nimport numpy as np\nimport heapq\n\ndef solve():\n    \"\"\"\n    Main solver function that executes the test cases and prints the results.\n    \"\"\"\n\n    def s(z, A):\n        \"\"\"Computes sigma_min(zI - A).\"\"\"\n        n = A.shape[0]\n        matrix = z * np.identity(n) - A\n        # The singular values are returned in descending order.\n        # We only need the values, not U and Vh.\n        singular_values = np.linalg.svd(matrix, compute_uv=False)\n        return singular_values[-1]\n\n    def uniform_sampler(A, gamma, m):\n        \"\"\"\n        Computes the uniform-sampling estimate of epsilon_star.\n        \"\"\"\n        t_values = np.linspace(0, 1, m, endpoint=False)\n        eps_unif = float('inf')\n        for t in t_values:\n            z = gamma(t)\n            sigma = s(z, A)\n            if sigma  eps_unif:\n                eps_unif = sigma\n        return eps_unif\n\n    def adaptive_sampler(A, gamma, L_gamma, tau):\n        \"\"\"\n        Computes epsilon_star using an adaptive algorithm to a tolerance tau.\n        \"\"\"\n        memo = {}\n        def f(t):\n            if t not in memo:\n                memo[t] = s(gamma(t), A)\n            return memo[t]\n\n        t0, t1 = 0.0, 1.0\n        f0 = f(t0)\n        # For a closed curve gamma(0) = gamma(1), so f(0) = f(1).\n        \n        eps_current = f0\n        \n        # Priority queue stores (lower_bound, a, b)\n        pq = []\n        \n        # Initial interval\n        lower_bound = min(f0, f(t1)) - L_gamma * (t1 - t0) / 2.0\n        heapq.heappush(pq, (lower_bound, t0, t1))\n\n        # Practical limit to prevent infinite loops in edge cases\n        max_iter = 20000\n        for _ in range(max_iter):\n            if not pq:\n                break\n                \n            # Get interval with smallest lower bound\n            current_l_bound, a, b = heapq.heappop(pq)\n            \n            # Check for convergence\n            if eps_current - current_l_bound = tau:\n                return eps_current\n            \n            # Refine the interval by bisecting\n            c = a + (b - a) / 2.0\n            if c in memo: # Should not happen with bisection if a!=b\n                continue\n                \n            fc = f(c)\n            eps_current = min(eps_current, fc)\n            \n            # Get function values at ends (already in memo)\n            fa = memo[a]\n            fb = memo[b]\n            \n            # Push new sub-intervals to the queue\n            lb1 = min(fa, fc) - L_gamma * (c - a) / 2.0\n            heapq.heappush(pq, (lb1, a, c))\n            \n            lb2 = min(fc, fb) - L_gamma * (b - c) / 2.0\n            heapq.heappush(pq, (lb2, c, b))\n\n        # Return best found if convergence not reached within max_iter\n        return eps_current\n    \n    def square_gamma_tc3(t):\n        \"\"\"Constant speed parameterization of a square centered at 0 with half-width 1.\"\"\"\n        c = 0+0j\n        a = 1.0\n        t = t % 1.0\n        # Parameterize CCW starting from (a, -a) = (1, -1)\n        if t  0.25: # Right edge, bottom to top\n            return (c.real + a) + 1j * (c.imag - a + (8*a*t))\n        elif t  0.5: # Top edge, right to left\n            return (c.real + a - (8*a*(t-0.25))) + 1j * (c.imag + a)\n        elif t  0.75: # Left edge, top to bottom\n            return (c.real - a) + 1j * (c.imag + a - (8*a*(t-0.5)))\n        else: # Bottom edge, left to right\n            return (c.real - a + (8*a*(t-0.75))) + 1j * (c.imag - a)\n\n    test_cases = [\n        {\n            \"A\": np.array([[1, 20], [0, 1]], dtype=complex),\n            \"gamma\": lambda t: 1 + 1.2 * np.exp(2j * np.pi * t),\n            \"L_gamma\": 2 * np.pi * 1.2,\n            \"m\": 64, \"M\": 4096, \"tau\": 1e-3\n        },\n        {\n            \"A\": np.array([[-1, 0.2, 0], [0, 2, 0.3], [0, 0, 3]], dtype=complex),\n            \"gamma\": lambda t: 1 + 3.2 * np.exp(2j * np.pi * t),\n            \"L_gamma\": 2 * np.pi * 3.2,\n            \"m\": 96, \"M\": 4096, \"tau\": 1e-3\n        },\n        {\n            \"A\": np.array([[0,1,0,0],[0,0,1,0],[0,0,0,1],[0,0,0,0]], dtype=complex),\n            \"gamma\": square_gamma_tc3,\n            \"L_gamma\": 8.0,\n            \"m\": 128, \"M\": 4096, \"tau\": 1e-3\n        }\n    ]\n    \n    results = []\n    for case in test_cases:\n        A = case[\"A\"]\n        gamma = case[\"gamma\"]\n        L_gamma = case[\"L_gamma\"]\n        m, M, tau = case[\"m\"], case[\"M\"], case[\"tau\"]\n\n        # 1. Reference value from dense uniform sampling\n        eps_ref = uniform_sampler(A, gamma, M)\n        \n        # 2. Coarse uniform sampling\n        eps_m_unif = uniform_sampler(A, gamma, m)\n        e_unif = eps_m_unif - eps_ref\n        b_unif = L_gamma / (2 * m)\n        p_unif = bool(e_unif = b_unif + 1e-12 and e_unif >= -1e-12)\n\n        # 3. Adaptive sampling\n        eps_adp = adaptive_sampler(A, gamma, L_gamma, tau)\n        e_adp = abs(eps_adp - eps_ref)\n        p_adp = bool(e_adp = tau + 1e-12)\n\n        results.extend([\n            eps_ref, eps_m_unif, e_unif, b_unif, p_unif,\n            eps_adp, e_adp, p_adp\n        ])\n\n    formatted_results = []\n    for item in results:\n        if isinstance(item, bool):\n            formatted_results.append(str(item))\n        else:\n            formatted_results.append(f\"{item:.15f}\")\n\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```"
        }
    ]
}