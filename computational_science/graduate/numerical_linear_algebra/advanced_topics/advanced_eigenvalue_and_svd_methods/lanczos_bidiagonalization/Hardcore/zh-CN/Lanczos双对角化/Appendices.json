{
    "hands_on_practices": [
        {
            "introduction": "在实现复杂的算法之前，理解其底层理论至关重要。第一个练习提供了一种直接的方法，利用 Golub-Kahan (GK) 关系推导出 Ritz 三元组残差的简洁公式。掌握此计算可以巩固您对双对角化过程如何生成近似值以及如何衡量其准确性的理解，这对于在任何迭代方法中设定停止准则是必不可少的。",
            "id": "3539929",
            "problem": "考虑一个实矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 和 $k$ 步后的 Golub–Kahan (GK) 双对角化过程，该过程产生标准正交矩阵 $U_k \\in \\mathbb{R}^{m \\times k}$ 和 $V_k \\in \\mathbb{R}^{n \\times k}$，标量 $\\alpha_1,\\dots,\\alpha_k$ 和 $\\beta_1,\\dots,\\beta_k$，以及一个双对角矩阵 $B_k \\in \\mathbb{R}^{k \\times k}$，其对角元素为 $\\alpha_i$，次对角元素为 $\\beta_i$。根据构造，GK 关系式为\n$$\nA V_k = U_k B_k, \\qquad A^{\\top} U_k = V_k B_k^{\\top} + \\beta_k v_{k+1} e_k^{\\top},\n$$\n其中 $v_{k+1} \\in \\mathbb{R}^{n}$ 是与 $V_k$ 的列正交的单位向量，而 $e_k \\in \\mathbb{R}^{k}$ 是第 $k$ 个标准基向量。\n\n设 $B_k$ 的奇异值分解 (SVD) 为 $B_k \\widehat{q}_i = \\widehat{\\sigma}_i \\widehat{p}_i$ 和 $B_k^{\\top} \\widehat{p}_i = \\widehat{\\sigma}_i \\widehat{q}_i$，其中 $\\widehat{\\sigma}_i  0$，$\\widehat{p}_i \\in \\mathbb{R}^{k}$ 和 $\\widehat{q}_i \\in \\mathbb{R}^{k}$ 是标准正交的。对应的 $A$ 的奇异三元组的 Ritz 近似为 $u_i = U_k \\widehat{p}_i$、$v_i = V_k \\widehat{q}_i$ 和 $\\sigma_i \\approx \\widehat{\\sigma}_i$。\n\n一种广泛用于通过 GK 计算奇异值分解 (SVD) 的停止准则是，要求对 $A^{\\top} u_i \\approx \\sigma_i v_i$ 的相对残差小于一个预设的容差。具体来说，第 $i$ 个 Ritz 三元组的相对残差为\n$$\n\\rho_i \\equiv \\frac{\\|A^{\\top} u_i - \\widehat{\\sigma}_i v_i\\|_2}{\\widehat{\\sigma}_i}.\n$$\n\n假设在 $k$ 步之后，对于主导三元组 $i=1$，给定以下量：下一个 GK 次对角系数 $\\beta_k = 1.7 \\times 10^{-9}$，$B_k$ 的左奇异向量的最后一个分量 $e_k^{\\top} \\widehat{p}_1 = 0.45$，以及 Ritz 奇异值 $\\widehat{\\sigma}_1 = 3.2$。仅使用上述 GK 关系式和 $\\rho_1$ 的定义，计算相对残差 $\\rho_1$ 的值。将最终答案四舍五入到四位有效数字。",
            "solution": "用户想要计算 Golub-Kahan (GK) 双对角化 $k$ 步后主导 Ritz 三元组的相对残差 $\\rho_1$。首先对问题进行验证，以确保其科学和数学上的完整性。\n\n### 步骤 1：提取已知条件\n- 一个实矩阵 $A \\in \\mathbb{R}^{m \\times n}$。\n- $k$ 步后的 Golub-Kahan (GK) 双对角化关系式：\n  $$A V_k = U_k B_k$$\n  $$A^{\\top} U_k = V_k B_k^{\\top} + \\beta_k v_{k+1} e_k^{\\top}$$\n- 标准正交矩阵 $U_k \\in \\mathbb{R}^{m \\times k}$ 和 $V_k \\in \\mathbb{R}^{n \\times k}$。\n- $v_{k+1} \\in \\mathbb{R}^{n}$ 是与 $V_k$ 的列正交的单位向量。\n- $e_k \\in \\mathbb{R}^k$ 是第 $k$ 个标准基向量。\n- 双对角矩阵 $B_k \\in \\mathbb{R}^{k \\times k}$。\n- $B_k$ 的第 $i$ 个奇异三元组的 SVD：$B_k \\widehat{q}_i = \\widehat{\\sigma}_i \\widehat{p}_i$ 和 $B_k^{\\top} \\widehat{p}_i = \\widehat{\\sigma}_i \\widehat{q}_i$，其中 $\\widehat{\\sigma}_i  0$。\n- $A$ 的第 $i$ 个三元组的 Ritz 近似：$u_i = U_k \\widehat{p}_i$、$v_i = V_k \\widehat{q}_i$ 和奇异值 $\\sigma_i \\approx \\widehat{\\sigma}_i$。\n- 第 $i$ 个 Ritz 三元组的相对残差的定义：\n  $$\\rho_i \\equiv \\frac{\\|A^{\\top} u_i - \\widehat{\\sigma}_i v_i\\|_2}{\\widehat{\\sigma}_i}$$\n- 主导三元组 ($i=1$) 的给定值：\n  - $\\beta_k = 1.7 \\times 10^{-9}$\n  - $e_k^{\\top} \\widehat{p}_1 = 0.45$\n  - $\\widehat{\\sigma}_1 = 3.2$\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题在科学上基于数值线性代数的成熟理论，特别是用于计算矩阵 SVD 的 Lanczos 双对角化方法（等同于 Golub-Kahan）。所提供的 GK 关系式是标准的。Ritz 向量、Ritz 值和残差的定义是正确的。该问题是适定的，因为它提供了唯一确定所求值所需的所有数据和关系。语言客观而精确。没有矛盾、信息缺失或伪科学主张。在收敛迭代算法的背景下，所提供的数值在物理上和数学上都是合理的。因此，该问题是有效的。\n\n### 步骤 3：结论和行动\n该问题有效。将提供完整的解答。\n\n目标是计算相对残差 $\\rho_1$。我们从其定义开始：\n$$\n\\rho_1 = \\frac{\\|A^{\\top} u_1 - \\widehat{\\sigma}_1 v_1\\|_2}{\\widehat{\\sigma}_1}\n$$\n让我们分析分子中的残差向量，我们将其记为 $r_1$：\n$$\nr_1 = A^{\\top} u_1 - \\widehat{\\sigma}_1 v_1\n$$\nRitz 向量 $u_1$ 定义为 $u_1 = U_k \\widehat{p}_1$。将其代入 $r_1$ 的表达式中：\n$$\nr_1 = A^{\\top} (U_k \\widehat{p}_1) - \\widehat{\\sigma}_1 v_1 = (A^{\\top} U_k) \\widehat{p}_1 - \\widehat{\\sigma}_1 v_1\n$$\n现在，我们使用给定的第二个 GK 关系式 $A^{\\top} U_k = V_k B_k^{\\top} + \\beta_k v_{k+1} e_k^{\\top}$ 来替换项 $(A^{\\top} U_k)$：\n$$\nr_1 = (V_k B_k^{\\top} + \\beta_k v_{k+1} e_k^{\\top}) \\widehat{p}_1 - \\widehat{\\sigma}_1 v_1\n$$\n应用分配律：\n$$\nr_1 = V_k B_k^{\\top} \\widehat{p}_1 + (\\beta_k v_{k+1} e_k^{\\top}) \\widehat{p}_1 - \\widehat{\\sigma}_1 v_1\n$$\n项 $(e_k^{\\top} \\widehat{p}_1)$ 是一个标量，表示向量 $\\widehat{p}_1$ 的第 $k$ 个分量。所以，表达式变为：\n$$\nr_1 = V_k (B_k^{\\top} \\widehat{p}_1) + \\beta_k (e_k^{\\top} \\widehat{p}_1) v_{k+1} - \\widehat{\\sigma}_1 v_1\n$$\n接下来，我们使用 $B_k$ 的 SVD 的性质，具体为 $B_k^{\\top} \\widehat{p}_1 = \\widehat{\\sigma}_1 \\widehat{q}_1$。将其代入方程中：\n$$\nr_1 = V_k (\\widehat{\\sigma}_1 \\widehat{q}_1) + \\beta_k (e_k^{\\top} \\widehat{p}_1) v_{k+1} - \\widehat{\\sigma}_1 v_1\n$$\n第一项可以重写为 $\\widehat{\\sigma}_1 (V_k \\widehat{q}_1)$。根据 Ritz 向量 $v_1 = V_k \\widehat{q}_1$ 的定义，我们有：\n$$\nr_1 = \\widehat{\\sigma}_1 v_1 + \\beta_k (e_k^{\\top} \\widehat{p}_1) v_{k+1} - \\widehat{\\sigma}_1 v_1\n$$\n项 $\\widehat{\\sigma}_1 v_1$ 和 $-\\widehat{\\sigma}_1 v_1$ 相互抵消，留下一个非常简单的残差向量表达式：\n$$\nr_1 = \\beta_k (e_k^{\\top} \\widehat{p}_1) v_{k+1}\n$$\n现在，我们计算该向量的欧几里得范数：\n$$\n\\|r_1\\|_2 = \\| \\beta_k (e_k^{\\top} \\widehat{p}_1) v_{k+1} \\|_2\n$$\n由于 $\\beta_k$ 和 $(e_k^{\\top} \\widehat{p}_1)$ 是标量，我们可以将它们从范数中提出来。GK 过程中的非对角元素 $\\beta_i$ 根据构造是非负的，所以 $|\\beta_k| = \\beta_k$。\n$$\n\\|r_1\\|_2 = \\beta_k |e_k^{\\top} \\widehat{p}_1| \\|v_{k+1}\\|_2\n$$\n问题陈述 $v_{k+1}$ 是一个单位向量，这意味着 $\\|v_{k+1}\\|_2 = 1$。因此，残差的范数为：\n$$\n\\|r_1\\|_2 = \\beta_k |e_k^{\\top} \\widehat{p}_1|\n$$\n最后，我们将此结果代回相对残差 $\\rho_1$ 的公式中：\n$$\n\\rho_1 = \\frac{\\beta_k |e_k^{\\top} \\widehat{p}_1|}{\\widehat{\\sigma}_1}\n$$\n现在我们可以代入给定的数值：$\\beta_k = 1.7 \\times 10^{-9}$，$e_k^{\\top} \\widehat{p}_1 = 0.45$ 和 $\\widehat{\\sigma}_1 = 3.2$。\n$$\n\\rho_1 = \\frac{(1.7 \\times 10^{-9}) |0.45|}{3.2}\n$$\n$$\n\\rho_1 = \\frac{1.7 \\times 0.45 \\times 10^{-9}}{3.2} = \\frac{0.765 \\times 10^{-9}}{3.2}\n$$\n$$\n\\rho_1 = 0.2390625 \\times 10^{-9} = 2.390625 \\times 10^{-10}\n$$\n问题要求答案四舍五入到四位有效数字。该数为 $2.390625 \\times 10^{-10}$。第五位有效数字是 $6$，所以我们将第四位数字向上取整。\n$$\n\\rho_1 \\approx 2.391 \\times 10^{-10}\n$$\n这就是主导 Ritz 三元组的相对残差的值。",
            "answer": "$$\n\\boxed{2.391 \\times 10^{-10}}\n$$"
        },
        {
            "introduction": "从理论走向实践，本练习将指导您实现带有“收缩”（deflation）这一关键实用功能的 Golub-Kahan Lanczos 双对角化（GKLB）算法。您将构建一个能够找到多个主导奇异值的求解器，其方法是“锁定”已收敛的三元组并重启算法以寻找下一个。这种动手实践将教会您如何管理迭代过程、确保正交性，并构建一个解决大规模 SVD 问题的稳健工具。",
            "id": "3539889",
            "problem": "要求您设计并实现一个稳健的数值程序，该程序使用 Golub–Kahan Lanczos 双对角化 (GKLB) 和一种紧缩策略，用于计算实矩形矩阵的一部分主要奇异值。该紧缩策略会锁定已收敛的奇异三元组，并继续以剩余奇异值为目标，同时不损失数值稳定性。目标是生成一个完整的、可运行的程序，该程序能在固定的测试集上执行此任务并报告量化结果。\n\n请从以下原则和核心定义开始：\n\n- 一个实矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的奇异值分解 (SVD) 为 $A = U \\Sigma V^\\top$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 的对角元（即奇异值）为非负且按非增序排列。前 $r = \\operatorname{rank}(A)$ 个奇异值为正。\n\n- 给定一个单位范数起始向量 $v_1 \\in \\mathbb{R}^n$，Golub–Kahan Lanczos 双对角化 (GKLB) 构建两个具有标准正交列的矩阵 $U_k \\in \\mathbb{R}^{m \\times k}$ 和 $V_k \\in \\mathbb{R}^{n \\times k}$，以及一个对角元为 $\\alpha_j$、上对角元为 $\\beta_j$ 的双对角矩阵 $B_k \\in \\mathbb{R}^{k \\times k}$，使得\n  $$\n  A V_k = U_k B_k \\quad \\text{和} \\quad A^\\top U_k = V_k B_k^\\top + \\beta_k v_{k+1} e_k^\\top,\n  $$\n  其中 $e_k \\in \\mathbb{R}^k$ 是第 $k$ 个标准基向量，$v_{k+1} \\in \\mathbb{R}^n$ 是一个单位范数向量。在精确算术中，$U_k$ 和 $V_k$ 的列是标准正交的，但在浮点算术中，需要进行显式再正交化来维持此性质。\n\n- $B_k$ 的奇异值（里兹奇异值）是 $A$ 的奇异值的近似。设 $B_k = \\widehat{U} \\Theta \\widehat{V}^\\top$ 是 $B_k$ 的奇异值分解，其中 $\\Theta = \\operatorname{diag}(\\theta_1,\\dots,\\theta_k)$ 且 $\\theta_1 \\ge \\dots \\ge \\theta_k \\ge 0$。$A$ 对应的里兹奇异向量为 $\\widetilde{u}_i = U_k \\widehat{U} e_i$ 和 $\\widetilde{v}_i = V_k \\widehat{V} e_i$。第 $i$ 个里兹三元组 $(\\theta_i,\\widetilde{u}_i,\\widetilde{v}_i)$ 的残差范数的一个标准界为\n  $$\n  \\| A \\widetilde{v}_i - \\theta_i \\widetilde{u}_i \\|_2 = \\| \\beta_k v_{k+1} e_k^\\top \\widehat{U} e_i \\|_2 = \\beta_k \\left| e_k^\\top \\widehat{U} e_i \\right|.\n  $$\n\n- 一种称为硬锁定的紧缩策略将收敛的里兹三元组从活动子空间中移除，以便后续的 GKLB 步骤能够构建与已锁定奇异向量正交的基。通过对新生成的基向量与当前 GKLB 基和所有先前锁定的奇异向量进行显式完全再正交化来维持稳定性。\n\n任务：\n\n- 实现一个程序，给定矩阵 $A \\in \\mathbb{R}^{m \\times n}$、整数 $k \\ge 2$、要求的奇异值数量 $\\mathrm{nev}$、容差 $\\tau  0$ 以及最大重启周期数，该程序执行以下操作：\n\n  1. 使用一个与所有已锁定的右奇异向量正交的单位范数起始向量，执行 $k$ 步带完全再正交化的 GKLB，以获得 $U_k$、$V_k$、$B_k$ 和耦合标量 $\\beta_k$。使用两遍修正的 Gram–Schmidt 算法，将每个新形成的候选向量与所有现有基向量和所有已锁定向量进行再正交化，以减轻正交性的损失。\n\n  2. 形成奇异值分解 $B_k = \\widehat{U}\\,\\Theta\\,\\widehat{V}^\\top$，计算里兹奇异三元组 $\\{(\\theta_i,\\widetilde{u}_i,\\widetilde{v}_i)\\}$，其中 $\\widetilde{u}_i = U_k \\widehat{U} e_i$ 且 $\\widetilde{v}_i = V_k \\widehat{V} e_i$。\n\n  3. 通过界\n     $$\n     r_i = \\beta_k \\left| e_k^\\top \\widehat{U} e_i \\right| \\le \\tau \\cdot \\max(1, \\theta_i).\n     $$\n     识别收敛的里兹三元组。任何满足此标准的三元组都将被添加到锁定集中，前提是新添加的向量在与先前锁定的向量再正交化后保持数值上线性无关。\n\n  4. 使用与所有已锁定的右奇异向量正交的起始向量继续新的 GKLB 周期，直到至少有 $\\mathrm{nev}$ 个奇异值被锁定或达到最大周期数。\n\n  5. 返回已锁定的奇异值集合（按非增序排序）以及对应的已锁定的左、右奇异向量集合。\n\n- 使用上述算法运行以下测试套件。在所有测试中，假设矩阵为实数矩阵，其条目遵循国际单位制，但最终答案中无需物理单位。所有角度（若有）必须以弧度为单位。所有数值输出必须为实数。对于每个测试，答案应为指定的浮点数或布尔值。对于每个测试用例，设置 $k = 50$，容差 $\\tau = 10^{-8}$，并将最大重启周期数限制为 $50$：\n\n  测试 A (通用衰减谱)：\n  - 维度：$m = 120$，$n = 80$。\n  - 通过计算大小为 $m \\times r$ 和 $n \\times r$ 的稠密高斯随机矩阵的经济尺寸 $QR$ 分解，构建标准正交因子 $U \\in \\mathbb{R}^{m \\times r}$ 和 $V \\in \\mathbb{R}^{n \\times r}$，其中 $r = \\min(m,n)$。\n  - 定义奇异值 $s_j = 50 \\cdot \\rho^{j-1}$，对于 $j = 1,\\dots,r$，其中 $\\rho = 0.93$。\n  - 构成 $A = U \\operatorname{diag}(s) V^\\top$。\n  - 目标是 $\\mathrm{nev} = 8$ 个主要奇异值。\n\n  测试 B (重复的前导奇异值)：\n  - 维度：$m = 80$，$n = 80$，$r = 80$。\n  - 如同测试 A 一样构建 $U \\in \\mathbb{R}^{m \\times r}$ 和 $V \\in \\mathbb{R}^{n \\times r}$。\n  - 定义奇异值 $s_1 = s_2 = s_3 = 20$，以及对于 $j = 4,\\dots,r$，$s_j$ 从 $12$ 线性递减到 $1$。\n  - 构成 $A = U \\operatorname{diag}(s) V^\\top$。\n  - 目标是 $\\mathrm{nev} = 3$ 个主要奇异值。\n\n  测试 C (秩亏矩阵)：\n  - 维度：$m = 60$，$n = 100$，数值秩 $r = 20$。\n  - 如同测试 A 一样构建 $U \\in \\mathbb{R}^{m \\times r}$ 和 $V \\in \\mathbb{R}^{n \\times r}$，但仅有 $r$ 列。\n  - 定义奇异值 $s_j$ 对于 $j = 1,\\dots,r$ 从 $5$ 线性递减到 $1$，并将其余奇异值设为 $0$。\n  - 构成 $A = U \\operatorname{diag}(s) V^\\top$。\n  - 目标是 $\\mathrm{nev} = 10$ 个主要奇异值。\n\n对于每个测试，使用 $A$ 的稠密奇异值分解计算真实的前导奇异值，并将其与计算出的锁定奇异值进行比较。每个测试所需的输出是：\n- 计算出的锁定奇异值与真实的前 $\\mathrm{nev}$ 个奇异值之间的最大绝对误差（一个浮点数）。\n- 一个布尔值，指示锁定的左奇异向量是否在数值上是标准正交的，即 $\\| U_{\\mathrm{lock}}^\\top U_{\\mathrm{lock}} - I \\|_2 \\le 10^{-8}$ 是否成立。\n- 一个布尔值，指示锁定的右奇异向量是否在数值上是标准正交的，即 $\\| V_{\\mathrm{lock}}^\\top V_{\\mathrm{lock}} - I \\|_2 \\le 10^{-8}$ 是否成立。\n\n最终输出格式：\n\n- 您的程序应生成单行输出，其中包含一个方括号内的逗号分隔列表：\n  $$\n  [e_A, oU_A, oV_A, e_B, oU_B, oV_B, e_C, oU_C, oV_C],\n  $$\n  其中 $e_\\cdot$ 是浮点数，$oU_\\cdot, oV_\\cdot$ 是如上定义的布尔值。",
            "solution": "用户提供的问题陈述已经过分析并被认为是有效的。这是一个数值线性代数中的适定问题，描述了使用硬锁定紧缩机制的 Golub-Kahan-Lanczos 双对角化 (GKLB) 算法的实现，用于计算实矩阵的主要奇异值和奇异向量。该描述在科学上是合理的，并提供了一套清晰的需求和测试用例。\n\n本文提出的解决方案实现了指定的算法。该程序的核心是一个迭代过程，它构建一个双对角矩阵，该矩阵的奇异值（称为里兹值）近似于原始矩阵的奇异值。收敛的三元组被“锁定”并从活动子空间中移除，从而使算法能够在后续迭代中有效地针对剩余的未收敛奇异值。\n\n1. Golub-Kahan Lanczos 双对角化 (GKLB) 过程\n\n给定一个实矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 和一个起始向量 $\\boldsymbol{v}_1 \\in \\mathbb{R}^n$ 且 $\\|\\boldsymbol{v}_1\\|_2 = 1$，GKLB 算法迭代生成两个标准正交向量序列，$\\{\\boldsymbol{u}_j\\}_{j=1}^k \\subset \\mathbb{R}^m$ 和 $\\{\\boldsymbol{v}_j\\}_{j=1}^{k+1} \\subset \\mathbb{R}^n$，以及两个正常数序列，$\\{\\alpha_j\\}_{j=1}^k$ 和 $\\{\\beta_j\\}_{j=1}^k$。该过程由以下递推关系控制：\n$$\n\\alpha_j \\boldsymbol{u}_j = A \\boldsymbol{v}_j - \\beta_{j-1} \\boldsymbol{u}_{j-1} \\quad (\\text{with } \\beta_0\\boldsymbol{u}_0 \\equiv \\boldsymbol{0})\n$$\n$$\n\\beta_j \\boldsymbol{v}_{j+1} = A^\\top \\boldsymbol{u}_j - \\alpha_j \\boldsymbol{v}_j\n$$\n其中 $\\alpha_j = \\|A \\boldsymbol{v}_j - \\beta_{j-1} \\boldsymbol{u}_{j-1}\\|_2$ 且 $\\beta_j = \\|A^\\top \\boldsymbol{u}_j - \\alpha_j \\boldsymbol{v}_j\\|_2$。经过 $k$ 步后，这些关系可以表示为矩阵形式：\n$$\nA V_k = U_k B_k\n$$\n$$\nA^\\top U_k = V_k B_k^\\top + \\beta_k \\boldsymbol{v}_{k+1} \\boldsymbol{e}_k^\\top\n$$\n这里，$U_k = [\\boldsymbol{u}_1, \\dots, \\boldsymbol{u}_k] \\in \\mathbb{R}^{m \\times k}$ 和 $V_k = [\\boldsymbol{v}_1, \\dots, \\boldsymbol{v}_k] \\in \\mathbb{R}^{n \\times k}$ 是具有标准正交列的矩阵。$B_k \\in \\mathbb{R}^{k \\times k}$ 是一个上双对角矩阵，其对角元为 $\\alpha_j$，上对角元为 $\\beta_j$。\n\n2. 通过再正交化维持正交性\n\n在有限精度算术中，由原始 Lanczos 递推生成的向量会因舍入误差而迅速失去其相互正交性。这会损害该方法的准确性。为确保稳定性，我们必须执行显式再正交化。按照规定，本实现采用两遍修正的 Gram-Schmidt (MGS) 过程。对于每个新的候选向量（例如 $\\boldsymbol{w} = A\\boldsymbol{v}_j$），通过依次移除其在每个基向量上的投影，使其与所有先前计算的基向量（例如 $U_{j-1}$ 的列）正交。应用此过程两次可显著减轻正交性的损失。\n\n3. 里兹对、收敛与重启\n\n小双对角矩阵 $B_k$ 的奇异三元组可作为 $A$ 的奇异三元组的近似。设 $B_k$ 的 SVD 为 $B_k = \\widehat{U} \\Theta \\widehat{V}^\\top$，其中 $\\Theta = \\operatorname{diag}(\\theta_1, \\dots, \\theta_k)$。$A$ 的近似奇异值，称为里兹值，是标量 $\\theta_i$。相应的近似奇异向量，或称里兹向量，由 $\\widetilde{\\boldsymbol{u}}_i = U_k \\widehat{\\boldsymbol{u}}_i$ 和 $\\widetilde{\\boldsymbol{v}}_i = V_k \\widehat{\\boldsymbol{v}}_i$ 给出。\n\n里兹三元组 $(\\theta_i, \\widetilde{\\boldsymbol{u}}_i, \\widetilde{\\boldsymbol{v}}_i)$ 的收敛性通过残差范数来评估，该范数可以通过界 $r_i = \\beta_k | \\boldsymbol{e}_k^\\top \\widehat{\\boldsymbol{u}}_i |$ 进行有效估计。如果此残差界小于指定的容差，则认为一个里兹三元组已收敛：\n$$\nr_i \\le \\tau \\cdot \\max(1, \\theta_i)\n$$\n这种混合准则对小奇异值 ($\\theta_i  1$) 使用绝对容差，对大奇异值使用相对容差。\n\n整个算法以周期方式运行。在每个周期中，执行 $k$ 步 GKLB。然后，识别并“锁定”收敛的里兹三元组。接着重启该过程，直到找到所需数量的奇异值 $\\mathrm{nev}$。\n\n4. 通过硬锁定进行紧缩\n\n紧缩是从问题中移除已收敛的特征分量或奇异分量的过程，以防止重复发现它们，并使算法能够专注于谱的未收敛部分。此处实现的“硬锁定”策略将收敛的奇异向量显式存储在矩阵 $U_{\\mathrm{lock}}$ 和 $V_{\\mathrm{lock}}$ 中。\n\n在所有后续的 GKLB 周期中，再正交化步骤得到增强：每个新生成的向量不仅要与当前的 Lanczos 基向量正交，还要与 $U_{\\mathrm{lock}}$ 或 $V_{\\mathrm{lock}}$ 中的所有向量正交。每个新周期的起始向量也要与 $V_{\\mathrm{lock}}$ 正交。这确保了算法探索的是一个与已找到的奇异子空间正交的子空间。\n\n此策略的一个关键方面，特别是对于聚集或多重奇异值，是确保新锁定的向量是标准正交的。当一个里兹向量收敛时，在将其添加到锁定集之前，会将其与先前锁定的向量集（包括在同一周期内锁定的向量）进行正交化。此过程使算法能够正确识别与多重奇异值相关的不变子空间的标准正交基。",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import qr, svd, norm\n\n# Use a fixed seed for the random number generator to ensure reproducibility.\nRNG = np.random.default_rng(42)\n\ndef mgs_double_pass(w, basis_matrices):\n    \"\"\"\n    Orthogonalizes a vector w against the columns of matrices in basis_matrices\n    using two passes of the modified Gram-Schmidt algorithm.\n\n    Args:\n        w (np.ndarray): The vector to be orthogonalized.\n        basis_matrices (list of np.ndarray): A list of matrices whose columns form the basis.\n\n    Returns:\n        tuple[np.ndarray, float]: A tuple containing the orthogonalized vector and its norm.\n    \"\"\"\n    w_ortho = w.copy()\n    # First pass of MGS\n    for B in basis_matrices:\n        if B is not None and B.shape[1] > 0:\n            for i in range(B.shape[1]):\n                h = np.dot(B[:, i], w_ortho)\n                w_ortho -= h * B[:, i]\n    # Second pass of MGS\n    for B in basis_matrices:\n        if B is not None and B.shape[1] > 0:\n            for i in range(B.shape[1]):\n                h = np.dot(B[:, i], w_ortho)\n                w_ortho -= h * B[:, i]\n    \n    norm_w_ortho = np.linalg.norm(w_ortho)\n    return w_ortho, norm_w_ortho\n\ndef gklb_deflation_svd(A, k, nev, tol, max_cycles):\n    \"\"\"\n    Computes a subset of the largest singular values and corresponding singular vectors\n    of a real matrix A using Golub-Kahan-Lanczos Bidiagonalization (GKLB) with\n    a hard-locking deflation strategy.\n\n    Args:\n        A (np.ndarray): The matrix for which to compute singular values.\n        k (int): The number of Lanczos steps per cycle (basis size).\n        nev (int): The number of singular values to compute.\n        tol (float): The convergence tolerance.\n        max_cycles (int): The maximum number of restart cycles.\n\n    Returns:\n        tuple[np.ndarray, np.ndarray, np.ndarray]: A tuple containing the locked singular\n        values, left singular vectors, and right singular vectors.\n    \"\"\"\n    m, n = A.shape\n    \n    U_locked = np.zeros((m, 0))\n    V_locked = np.zeros((n, 0))\n    S_locked = []\n\n    num_cycles = 0\n    v_start = RNG.random(size=n)\n    \n    while len(S_locked)  nev and num_cycles  max_cycles:\n        num_cycles += 1\n        \n        v1_ortho, v1_norm = mgs_double_pass(v_start, [V_locked])\n        if v1_norm  tol:\n            v_start = RNG.random(size=n)\n            v1_ortho, v1_norm = mgs_double_pass(v_start, [V_locked])\n            if v1_norm  tol:\n                break\n        \n        v1 = v1_ortho / v1_norm\n        \n        V_k = np.zeros((n, k + 1))\n        U_k = np.zeros((m, k))\n        alphas = np.zeros(k)\n        betas = np.zeros(k)\n        \n        V_k[:, 0] = v1\n        k_eff = k\n\n        for j in range(k):\n            u_raw = A @ V_k[:, j]\n            u_ortho, alpha_j = mgs_double_pass(u_raw, [U_locked, U_k[:, :j]])\n            \n            if alpha_j  1e-12:\n                k_eff = j\n                break\n            \n            alphas[j] = alpha_j\n            U_k[:, j] = u_ortho / alpha_j\n            \n            v_raw = A.T @ U_k[:, j] - alphas[j] * V_k[:, j]\n            v_ortho, beta_j = mgs_double_pass(v_raw, [V_locked, V_k[:, :j+1]])\n\n            betas[j] = beta_j\n            if beta_j  1e-12:\n                k_eff = j + 1\n                break\n            \n            V_k[:, j+1] = v_ortho / beta_j\n        \n        if k_eff == 0: continue\n\n        B_k = np.diag(alphas[:k_eff]) + np.diag(betas[:k_eff-1], 1)\n        \n        try:\n            U_hat, Theta, Vt_hat = svd(B_k)\n        except np.linalg.LinAlgError:\n            v_start = V_k[:, k_eff]\n            continue\n            \n        V_hat = Vt_hat.T\n        \n        residuals = betas[k_eff-1] * np.abs(U_hat[-1, :])\n        sorted_indices = np.argsort(Theta)[::-1]\n        \n        newly_locked_u_cycle = np.zeros((m, 0))\n        newly_locked_v_cycle = np.zeros((n, 0))\n\n        for i in sorted_indices:\n            theta_i = Theta[i]\n            if residuals[i] = tol * max(1.0, theta_i):\n                u_ritz = U_k[:, :k_eff] @ U_hat[:, i]\n                v_ritz = V_k[:, :k_eff] @ V_hat[:, i]\n                \n                u_ortho, u_norm = mgs_double_pass(u_ritz, [U_locked, newly_locked_u_cycle])\n                v_ortho, v_norm = mgs_double_pass(v_ritz, [V_locked, newly_locked_v_cycle])\n                \n                if u_norm > tol and v_norm > tol:\n                    u_new = u_ortho / u_norm\n                    v_new = v_ortho / v_norm\n                    \n                    S_locked.append(theta_i)\n                    if newly_locked_u_cycle.shape[1] == 0:\n                        newly_locked_u_cycle = u_new.reshape(-1, 1)\n                        newly_locked_v_cycle = v_new.reshape(-1, 1)\n                    else:\n                        newly_locked_u_cycle = np.hstack([newly_locked_u_cycle, u_new.reshape(-1, 1)])\n                        newly_locked_v_cycle = np.hstack([newly_locked_v_cycle, v_new.reshape(-1, 1)])\n\n                    if len(S_locked) >= nev:\n                        break\n        \n        if newly_locked_u_cycle.shape[1] > 0:\n            U_locked = np.hstack([U_locked, newly_locked_u_cycle])\n            V_locked = np.hstack([V_locked, newly_locked_v_cycle])\n\n        v_start = V_k[:, k_eff]\n    \n    if len(S_locked) > 0:\n        sorted_indices = np.argsort(S_locked)[::-1]\n        S_locked = np.array(S_locked)[sorted_indices]\n        U_locked = U_locked[:, sorted_indices]\n        V_locked = V_locked[:, sorted_indices]\n\n    return S_locked, U_locked, V_locked\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    k = 50\n    tau = 1e-8\n    max_cycles = 50\n    ortho_tol = 1e-8\n    \n    results = []\n\n    # Test Case A\n    m_a, n_a, nev_a = 120, 80, 8\n    r_a = min(m_a, n_a)\n    U_true_a = qr(RNG.standard_normal(size=(m_a, r_a)), mode='economic')[0]\n    V_true_a = qr(RNG.standard_normal(size=(n_a, r_a)), mode='economic')[0]\n    s_true_a = 50.0 * (0.93 ** np.arange(r_a))\n    A_a = U_true_a @ np.diag(s_true_a) @ V_true_a.T\n    S_locked_a, U_locked_a, V_locked_a = gklb_deflation_svd(A_a, k, nev_a, tau, max_cycles)\n    num_found_a = len(S_locked_a)\n    if num_found_a >= nev_a:\n        err_a = np.max(np.abs(S_locked_a[:nev_a] - s_true_a[:nev_a]))\n        oU_a = norm(U_locked_a[:,:nev_a].T @ U_locked_a[:,:nev_a] - np.eye(nev_a), 2) = ortho_tol\n        oV_a = norm(V_locked_a[:,:nev_a].T @ V_locked_a[:,:nev_a] - np.eye(nev_a), 2) = ortho_tol\n    else: # Should not happen with these parameters, but as a fallback\n        err_a, oU_a, oV_a = -1.0, False, False\n\n    results.extend([err_a, oU_a, oV_a])\n    \n    # Test Case B\n    m_b, n_b, nev_b = 80, 80, 3\n    r_b = min(m_b, n_b)\n    U_true_b = qr(RNG.standard_normal(size=(m_b, r_b)), mode='economic')[0]\n    V_true_b = qr(RNG.standard_normal(size=(n_b, r_b)), mode='economic')[0]\n    s_true_b = np.concatenate(([20.0, 20.0, 20.0], np.linspace(12, 1, r_b - 3)))\n    A_b = U_true_b @ np.diag(s_true_b) @ V_true_b.T\n    S_locked_b, U_locked_b, V_locked_b = gklb_deflation_svd(A_b, k, nev_b, tau, max_cycles)\n    num_found_b = len(S_locked_b)\n    if num_found_b >= nev_b:\n        err_b = np.max(np.abs(S_locked_b[:nev_b] - s_true_b[:nev_b]))\n        oU_b = norm(U_locked_b[:,:nev_b].T @ U_locked_b[:,:nev_b] - np.eye(nev_b), 2) = ortho_tol\n        oV_b = norm(V_locked_b[:,:nev_b].T @ V_locked_b[:,:nev_b] - np.eye(nev_b), 2) = ortho_tol\n    else:\n        err_b, oU_b, oV_b = -1.0, False, False\n\n    results.extend([err_b, oU_b, oV_b])\n    \n    # Test Case C\n    m_c, n_c, nev_c, rank_c = 60, 100, 10, 20\n    U_true_c_rank = qr(RNG.standard_normal(size=(m_c, rank_c)), mode='economic')[0]\n    V_true_c_rank = qr(RNG.standard_normal(size=(n_c, rank_c)), mode='economic')[0]\n    s_true_c = np.linspace(5, 1, rank_c)\n    A_c = U_true_c_rank @ np.diag(s_true_c) @ V_true_c_rank.T\n    S_locked_c, U_locked_c, V_locked_c = gklb_deflation_svd(A_c, k, nev_c, tau, max_cycles)\n    num_found_c = len(S_locked_c)\n    if num_found_c >= nev_c:\n        err_c = np.max(np.abs(S_locked_c[:nev_c] - s_true_c[:nev_c]))\n        oU_c = norm(U_locked_c[:,:nev_c].T @ U_locked_c[:,:nev_c] - np.eye(nev_c), 2) = ortho_tol\n        oV_c = norm(V_locked_c[:,:nev_c].T @ V_locked_c[:,:nev_c] - np.eye(nev_c), 2) = ortho_tol\n    else:\n        err_c, oU_c, oV_c = -1.0, False, False\n\n    results.extend([err_c, oU_c, oV_c])\n    \n    # Format output as specified\n    formatted_results = []\n    for r in results:\n        if isinstance(r, bool):\n            formatted_results.append(str(r).lower())\n        else:\n            formatted_results.append(f\"{r:.6e}\") # Using scientific notation for consistency\n\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在有限精度算术中，Lanczos 过程的优雅性可能会受到一个微妙的数值伪影的影响：由于正交性的丧失而出现虚假的“幽灵”奇异值。这个高级实践挑战您通过比较理论残差和真实残差来诊断这种失效模式，并基于此分析开发一种过滤机制。通过解决这个问题，您将更深刻地体会到 Krylov 子空间方法中的数值稳定性挑战，并学到确保结果可靠性的实用技术。",
            "id": "3554980",
            "problem": "给定一个满足 $m \\geq n$ 的矩形实矩阵 $A \\in \\mathbb{R}^{m \\times n}$，要求您研究当不对右 Lanczos 向量强制正交性时，Golub–Kahan Lanczos 双对角化过程的行为。您需要开发一个有原则的、程序化的失效检测机制，用于检测因 $V_k$ 的列丧失正交性而可能出现的伪奇异值（或“幻影”）Ritz 奇异值。任务是设计一个算法，该算法能 (i) 检测此类失效，(ii) 通过独立的重复运行来确认它们，以及 (iii) 提出一个滤波器，该滤波器移除检测到的伪值，在每个近乎重复的簇中最多保留一个候选项。\n\n使用的基础理论：\n\n- 奇异值分解 (SVD)：对于任意矩阵 $A \\in \\mathbb{R}^{m \\times n}$，存在正交矩阵 $U \\in \\mathbb{R}^{m \\times m}$、$V \\in \\mathbb{R}^{n \\times n}$ 和一个非负对角矩阵 $\\Sigma \\in \\mathbb{R}^{m \\times n}$，使得 $A = U \\Sigma V^{\\top}$。$A$ 的奇异值是 $\\Sigma$ 的对角线元素。\n- Golub–Kahan Lanczos 双对角化过程：给定一个非零起始向量 $b \\in \\mathbb{R}^{m}$ 和一个目标迭代次数 $k \\in \\mathbb{N}$，该过程在精确算术下构造具有正交列的矩阵 $U_{k+1} \\in \\mathbb{R}^{m \\times (k+1)}$ 和 $V_k \\in \\mathbb{R}^{n \\times k}$，以及一个下双对角矩阵 $B_{\\mathrm{tilde}} \\in \\mathbb{R}^{(k+1) \\times k}$，其对角线元素为 $\\alpha_j$，次对角线元素为 $\\beta_{j+1}$，使得\n$$\nA V_k \\;=\\; U_{k+1} B_{\\mathrm{tilde}}.\n$$\n- Ritz 奇异值：$B_{\\mathrm{tilde}}$ 的奇异值是 $A$ 的奇异值在构建的子空间上的投影。它们关联的近似奇异向量是 $U_{k+1} \\widehat{U}_k$ 和 $V_k \\widehat{V}_k$，其中 $B_{\\mathrm{tilde}} = \\widehat{U}_k \\widehat{\\Sigma}_k \\widehat{V}_k^{\\top}$ 是 $B_{\\mathrm{tilde}}$ 的奇异值分解。\n- 预测残差恒等式：对于一个由 $B_{\\mathrm{tilde}}$ 的 SVD 导出的近似奇异三元组 $(\\widehat{\\sigma}_i, \\widehat{u}_i, \\widehat{v}_i)$，在精确算术下，$A \\widehat{v}_i - \\widehat{\\sigma}_i \\widehat{u}_i$ 的残差范数满足\n$$\n\\|A \\widehat{v}_i - \\widehat{\\sigma}_i \\widehat{u}_i\\|_2 \\;=\\; \\beta_{k+1} \\,\\big|\\,[\\widehat{U}_k]_{k+1,i}\\big|,\n$$\n\n问题：\n\n1) 实现 $k$ 步的 Golub–Kahan Lanczos 双对角化，无需重正交化。接受一个非负参数 $\\eta_{\\mathrm{noise}}$，通过在每次归一化之前向每个递推关系中注入小的加性噪声来模拟正交性的丧失，从而建模有限精度效应。使用标准的带每步归一化的三项递推来生成 $U_{k+1}$、$V_k$ 和 $B_{\\mathrm{tilde}}$。\n\n2) 从 $B_{\\mathrm{tilde}} \\in \\mathbb{R}^{(k+1)\\times k}$ 的奇异值分解中计算 Ritz 奇异值 $\\{\\widehat{\\sigma}_i\\}_{i=1}^{\\ell}$，其中 $\\ell = \\min\\{k+1,k\\} = k$。构造相应的近似奇异向量 $\\widehat{u}_i = U_{k+1}\\widehat{U}_k(:,i)$ 和 $\\widehat{v}_i = V_k \\widehat{V}_k(:,i)$。\n\n3) 对每个 $i \\in \\{1,\\dots,\\ell\\}$，计算“投影模型”残差预测值\n$$\n\\rho_i \\;=\\; \\beta_{k+1} \\,\\big|\\,[\\widehat{U}_k]_{k+1,i}\\big|\n$$\n和“真实”残差范数\n$$\nr_i \\;=\\; \\|A \\widehat{v}_i - \\widehat{\\sigma}_i \\widehat{u}_i\\|_2.\n$$\n\n4) 通过 Frobenius 范数量化 $V_k$ 的正交性损失\n$$\n\\delta_V \\;=\\; \\big\\| V_k^{\\top} V_k - I_k \\big\\|_F.\n$$\n当 $\\delta_V$ 很小时，$V_k$ 接近正交；当 $\\delta_V$ 很大时，正交性显著退化。\n\n5) 使用以下原则开发一个幻影检测机制：\n- 通过对 $\\{\\widehat{\\sigma}_i\\}$ 进行排序来对近乎重复的 Ritz 奇异值进行聚类，并将连续间隙至多为相对阈值 $\\tau_{\\mathrm{cluster}} \\cdot \\max\\{1,\\widehat{\\sigma}_i\\}$ 的值分组。\n- 对于每个大小严格大于一的簇，如果同时满足以下两个条件，则将其额外成员（除了最好的那一个之外）标记为“可疑”：\n  - $V_k$ 的正交性损失满足 $\\delta_V > \\tau_{\\mathrm{orth}}$，\n  - 并且真实残差与投影模型预测值不一致，例如，如果 $r_i \\geq \\gamma \\cdot \\rho_i$ 且 $r_i \\geq \\Gamma \\cdot \\min_{j\\ \\text{in cluster}} r_j$，其中 $\\gamma$ 和 $\\Gamma$ 是大于 1 的因子。\n- 通过使用一个轻微扰动的起始向量 $\\widetilde{b} = \\frac{b + \\varepsilon_{\\mathrm{pert}} \\cdot \\xi}{\\|b + \\varepsilon_{\\mathrm{pert}} \\cdot \\xi\\|_2}$（其中 $\\xi$ 是一个具有独立同分布标准正态条目的随机向量）进行重复运行，并验证近乎重复的 Ritz 奇异值簇在相同值附近持续存在（在聚类阈值范围内），来确认可疑的幻影。\n\n6) 提出一个算法滤波器，通过在每个已确认的簇中仅保留具有最小真实残差的成员，并在 Ritz 奇异值的输出列表中丢弃其余成员，来移除检测到的幻影。\n\n您的程序必须实现以上内容，并为每个指定的测试用例返回一个整数计数，该计数表示您的滤波器从第一次运行（扰动前）中移除的 Ritz 奇异值的数量。重复运行的确认仅用作检测辅助，除了移除已确认的幻影外，不改变第一次运行的值。\n\n要实现的测试套件：\n\n- 构造 $A_1 \\in \\mathbb{R}^{80 \\times 60}$ 为 $A_1 = U \\,\\mathrm{diag}(s)\\, V^{\\top}$，其中 $U \\in \\mathbb{R}^{80 \\times 80}$ 和 $V \\in \\mathbb{R}^{60 \\times 60}$ 是从高斯随机矩阵的 QR 分解中的 Q 矩阵中抽取的正交矩阵，且 $s \\in \\mathbb{R}^{60}$ 满足 $s_j = 10 \\cdot 0.9^{j-1}$，对于 $j=1,\\dots,60$。\n- 类似地构造 $A_2 \\in \\mathbb{R}^{80 \\times 60}$，但 $s_1 = 5$， $s_2 = 5$，且对于 $j=3,\\dots,60$，$s_j = 5 \\cdot 0.85^{j-2}$。\n- 使用固定的随机种子以使测试具有确定性。令 $b \\in \\mathbb{R}^{80}$ 是一个具有独立同分布的标准正态条目的随机向量，并将其归一化。\n\n定义以下测试用例，每个用例由一个元组 $(A\\_id, k, \\eta\\_{\\mathrm{noise}}, \\varepsilon\\_{\\mathrm{pert}}, \\tau\\_{\\mathrm{cluster}}, \\tau\\_{\\mathrm{orth}})$ 标识：\n\n- 用例 1：$(A\\_1, 20, 0, 10^{-8}, 10^{-4}, 10^{-8})$。\n- 用例 2：$(A\\_1, 35, 10^{-2}, 10^{-3}, 10^{-3}, 10^{-3})$。\n- 用例 3：$(A\\_1, 5, 0, 10^{-8}, 10^{-4}, 10^{-8})$。\n- 用例 4：$(A\\_2, 25, 0, 10^{-8}, 10^{-4}, 10^{-8})$。\n\n对于所有用例，使用相同的 $b$ 和相同的随机种子来生成所有随机量，对于重复运行，使用指定的 $\\varepsilon\\_{\\mathrm{pert}}$。对于幻影确认，使用两个残差不一致性因子 $\\gamma = 5$ 和 $\\Gamma = 10$，并定义一个绝对残差下限 $\\tau_{\\mathrm{abs}} = 100 \\cdot \\epsilon_{\\mathrm{mach}} \\cdot \\|A\\|_2$，其中 $\\epsilon_{\\mathrm{mach}}$ 是双精度机器精度，$\\|A\\|_2$ 是 $A$ 的算子 2-范数。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，其中每个条目是对应测试用例移除的幻影 Ritz 奇异值的整数数量，顺序与上述四个用例一致（例如，“[0,3,0,0]”）。输出中不需要也不应包含额外的空白，且不应打印任何其他文本。本问题不涉及物理单位，所有数值均为无量纲。不涉及角度。不使用百分比；任何比率都必须表示为十进制值。该程序必须是一个完整的、可运行的 Python 脚本，无需用户输入即可执行所有计算，且仅使用允许的库。",
            "solution": "该问题要求开发一种有原则的算法，以检测和滤除在 Golub-Kahan-Lanczos 双对角化 (GKLB) 过程中因计算出的 Lanczos 向量之间丧失正交性而产生的伪“幻影”Ritz 奇异值。解决方案涉及实现带有模拟正交性丧失的 GKLB 算法，计算 Ritz 值及其相关残差，然后应用多阶段的检测和滤波逻辑。\n\n**1. Golub-Kahan Lanczos 双对角化 (GKLB) 过程与正交性丧失**\n\nGKLB 过程是一种迭代方法，对于给定的矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 和起始向量 $b \\in \\mathbb{R}^m$，它会构造一系列张成 Krylov 子空间的正交向量。在精确算术中，对于 $k$ 次迭代，它会生成具有正交列的矩阵 $U_{k+1} = [u_1, u_2, \\dots, u_{k+1}] \\in \\mathbb{R}^{m \\times (k+1)}$ 和 $V_k = [v_1, v_2, \\dots, v_k] \\in \\mathbb{R}^{n \\times k}$，以及一个下双对角矩阵 $B_{\\mathrm{tilde}} \\in \\mathbb{R}^{(k+1) \\times k}$，使得以下关系成立：\n$$\nA V_k = U_{k+1} B_{\\mathrm{tilde}}\n$$\n$$\nA^{\\top} U_k = V_k B_{\\mathrm{tilde}}(1:k, :) + \\alpha_{k+1} v_{k+1} e_k^{\\top} \\quad \\text{(如果对 } v \\text{ 运行 k+1 步)}\n$$\n在有限精度算术中，随着迭代次数 $k$ 的增加，$U_{k+1}$ 以及更关键的 $V_k$ 的列的正交性会逐渐丧失。这种正交性的丧失是数值赝象（例如，已经收敛到 $A$ 的一个实际奇异值的 Ritz 值出现多个副本）的根本原因。为了模拟这种效应，在归一化步骤之前，将一个由参数 $\\eta_{\\mathrm{noise}}$ 缩放的噪声项引入到递推关系中。具体来说，下一个 Lanczos 向量 $v_j$ 和 $u_{j+1}$ 的未归一化向量会受到加性随机噪声的扰动。\n\n算法按以下步骤进行，从 $u_1 = b / \\|b\\|_2$ 和 $\\beta_1=0$, $v_0=0$ 开始：\n对于 $j = 1, \\dots, k$：\n1. 计算未归一化的右 Lanczos 向量：$r_j = A^{\\top} u_j - \\beta_j v_{j-1}$。\n2. 注入噪声（如果 $\\eta_{\\mathrm{noise}} > 0$）：$\\tilde{r}_j = r_j + \\text{noise}$。\n3. 归一化得到 $B_{\\mathrm{tilde}}$ 的对角元素和新的右向量：$\\alpha_j = \\|\\tilde{r}_j\\|_2$, $v_j = \\tilde{r}_j / \\alpha_j$。\n4. 计算未归一化的左 Lanczos 向量：$p_j = A v_j - \\alpha_j u_j$。\n5. 注入噪声（如果 $\\eta_{\\mathrm{noise}} > 0$）：$\\tilde{p}_j = p_j + \\text{noise}$。\n6. 归一化得到 $B_{\\mathrm{tilde}}$ 的次对角元素和新的左向量：$\\beta_{j+1} = \\|\\tilde{p}_j\\|_2$, $u_{j+1} = \\tilde{p}_j / \\beta_{j+1}$。\n\n计算出的 $V_k$ 矩阵的正交性损失程度通过其与单位矩阵偏差的 Frobenius 范数量化：$\\delta_V = \\| V_k^{\\top} V_k - I_k \\|_F$。一个大的 $\\delta_V$ 表示显著的正交性损失。\n\n**2. Ritz 奇异值与残差分析**\n\n双对角矩阵 $B_{\\mathrm{tilde}}$ 的奇异值，记为 $\\{\\widehat{\\sigma}_i\\}_{i=1}^k$，被称为 Ritz 奇异值。它们用作原始矩阵 $A$ 的奇异值的近似值。设 $B_{\\mathrm{tilde}}$ 的 SVD 为 $B_{\\mathrm{tilde}} = \\widehat{U}_k \\widehat{\\Sigma}_k \\widehat{V}_k^{\\top}$。$A$ 对应的近似奇异向量为 $\\widehat{u}_i = U_{k+1} \\widehat{U}_k(:,i)$ 和 $\\widehat{v}_i = V_k \\widehat{V}_k(:,i)$。\n\n评估 Ritz 对 $(\\widehat{\\sigma}_i, \\widehat{u}_i, \\widehat{v}_i)$ 质量的一个关键工具是其残差范数。在 GKLB 的背景下，我们区分两种残差：\n- **“投影模型”残差预测值**，$\\rho_i = \\beta_{k+1} |[\\widehat{U}_k]_{k+1,i}|$，它源于双对角化结构，在精确算术下成立。\n- **“真实”残差范数**，$r_i = \\|A \\widehat{v}_i - \\widehat{\\sigma}_i \\widehat{u}_i\\|_2$，它衡量近似的实际误差。\n\n在理想情况下（精确算术，完美正交性），$\\rho_i = r_i$。两者之间的显著差异，特别是当 $r_i \\gg \\rho_i$ 时，是由于正交性丧失而导致的数值不稳定性的一个强烈指标。\n\n**3. 幻影检测与滤波机制**\n\n问题的核心是设计一个鲁棒的机制来识别和滤除这些伪 Ritz 值。所提出的方法是一个基于聚类、怀疑、确认和滤波的多阶段过程。\n\n- **步骤 1：聚类。** 幻影值的第一个迹象是在本应是 $A$ 的单个奇异值的地方出现了多个紧密分组的 Ritz 值。因此，我们首先对排序后的 Ritz 值 $\\{\\widehat{\\sigma}_i\\}$ 进行聚类。如果两个相邻的 Ritz 值 $\\widehat{\\sigma}_i$ 和 $\\widehat{\\sigma}_{i+1}$ 的相对间隙小于给定的阈值 $\\tau_{\\mathrm{cluster}}$，即 $\\widehat{\\sigma}_{i+1} - \\widehat{\\sigma}_i \\leq \\tau_{\\mathrm{cluster}} \\cdot \\max\\{1, \\widehat{\\sigma}_i\\}$，则它们属于同一个簇。\n\n- **步骤 2：识别“幻影簇”。** 大小大于一的簇并不自动意味着是伪值；它可能代表了 $A$ 的一个真实的重奇异值或聚集奇异值。幻影是正交性丧失的结果。因此，仅当整体正交性损失显著时，即 $\\delta_V > \\tau_{\\mathrm{orth}}$，一个簇才会被标记为“潜在幻影簇”。\n\n- **步骤 3：通过重复运行进行确认。** 一个潜在的幻影簇仍可能只是特定起始向量 $b$ 的产物。为了确认该簇代表了算法的系统性崩溃，我们执行第二次重复的 GKLB 运行。这次运行使用一个轻微扰动的起始向量 $\\widetilde{b} = (b + \\varepsilon_{\\mathrm{pert}} \\cdot \\xi) / \\|b + \\varepsilon_{\\mathrm{pert}} \\cdot \\xi\\|_2$，其中 $\\xi$ 是一个随机向量。如果在第二次运行中，一簇 Ritz 值在几乎相同的位置重新出现，这就确认了该现象是给定矩阵 $A$ 和迭代次数 $k$ 下算法失效模式的一个鲁棒特征。如果第二次运行中的某个簇的平均值与第一次运行中的某个簇接近（在聚类容差范围内），则认为第一次运行的该簇是“已确认”的。\n\n- **步骤 4：滤波。** 在第一次运行的已确认幻影簇中，我们必须将“最佳”近似与实际的幻影区分开。最佳的 Ritz 对是使真实残差范数 $r_i$ 最小的那一个。该成员被保留。簇中的其他成员是待移除的候选项。如果一个成员的近似质量很差，它就会被标记为幻影并被移除，其质量由两个条件量化：\n    1. 其真实残差显著大于其预测残差：$r_i \\geq \\gamma \\cdot \\rho_i$。\n    2. 其真实残差显著大于其所在簇中的最佳残差：$r_i \\geq \\Gamma \\cdot \\min_{j \\text{ in cluster}} r_j$。\n同时，也使用一个下限 $\\tau_{\\mathrm{abs}} = 100 \\cdot \\epsilon_{\\mathrm{mach}} \\cdot \\|A\\|_2$ 来处理真实残差，以避免标记由浮点噪声引起的极小残差。\n\n最终输出是第一次运行中被识别为幻影并被此过程移除的 Ritz 值的总数。",
            "answer": "```python\nimport numpy as np\n\ndef gklb(A, b, k, eta_noise, rng):\n    \"\"\"\n    Performs Golub-Kahan-Lanczos bidiagonalization for k steps.\n    \"\"\"\n    m, n = A.shape\n    U = np.zeros((m, k + 1))\n    V = np.zeros((n, k))\n    alphas = np.zeros(k)\n    betas = np.zeros(k + 1)\n\n    u_curr = b / np.linalg.norm(b)\n    U[:, 0] = u_curr\n    v_prev = np.zeros(n)\n\n    for j in range(k):\n        # --- Right-vector recurrence ---\n        r_unnorm = A.T @ u_curr - betas[j] * v_prev\n\n        # Inject noise to simulate finite precision\n        if eta_noise > 0:\n            noise_r = eta_noise * rng.standard_normal(size=r_unnorm.shape)\n            r_unnorm += noise_r\n\n        alpha_j = np.linalg.norm(r_unnorm)\n        alphas[j] = alpha_j\n        \n        if alpha_j == 0:\n            # Breakdown\n            k = j\n            U = U[:, :(k+1)]\n            V = V[:, :k]\n            alphas = alphas[:k]\n            betas = betas[:(k+1)]\n            break\n\n        v_curr = r_unnorm / alpha_j\n        V[:, j] = v_curr\n\n        # --- Left-vector recurrence ---\n        p_unnorm = A @ v_curr - alpha_j * u_curr\n\n        # Inject noise\n        if eta_noise > 0:\n            noise_p = eta_noise * rng.standard_normal(size=p_unnorm.shape)\n            p_unnorm += noise_p\n\n        beta_jp1 = np.linalg.norm(p_unnorm)\n        betas[j + 1] = beta_jp1\n\n        if beta_jp1 == 0:\n            # Breakdown\n            k = j + 1\n            U = U[:, :k]\n            V = V[:, :(k-1)] # This case is subtle\n            alphas = alphas[:(k-1)]\n            betas = betas[:k]\n            break\n\n        u_next = p_unnorm / beta_jp1\n        U[:, j + 1] = u_next\n\n        # Update for next iteration\n        u_curr = u_next\n        v_prev = v_curr\n\n    return U, V, alphas, betas, k\n\ndef analyze_gklb_run(A, b, k, eta_noise, rng):\n    \"\"\"\n    Runs GKLB and computes Ritz values, residuals, and orthogonality loss.\n    \"\"\"\n    m, n = A.shape\n    U, V, alphas, betas, final_k = gklb(A, b, k, eta_noise, rng)\n    \n    if final_k == 0:\n        return [], [], [], 0, []\n\n    k = final_k\n    B_tilde = np.zeros((k + 1, k))\n    np.fill_diagonal(B_tilde, alphas)\n    np.fill_diagonal(B_tilde[1:], betas[1:k+1])\n\n    # SVD of B_tilde to get Ritz values\n    try:\n        U_hat, sigma_hat_vals, Vt_hat = np.linalg.svd(B_tilde, full_matrices=True)\n        V_hat = Vt_hat.T\n    except np.linalg.LinAlgError:\n        return [], [], [], 0, []\n\n    # Adjust if k > rank of B_tilde\n    if len(sigma_hat_vals)  k:\n        k_ritz = len(sigma_hat_vals)\n        U_hat = U_hat[:, :k_ritz]\n        V_hat = V_hat[:, :k_ritz]\n    else:\n        k_ritz = k\n    \n    if k_ritz == 0:\n        return [], [], [], 0, []\n\n    # Compute residuals\n    residuals_true = np.zeros(k_ritz)\n    residuals_pred = np.zeros(k_ritz)\n\n    for i in range(k_ritz):\n        v_ritz = V @ V_hat[:, i]\n        u_ritz = U @ U_hat[:, i]\n        residuals_true[i] = np.linalg.norm(A @ v_ritz - sigma_hat_vals[i] * u_ritz)\n        residuals_pred[i] = betas[k] * np.abs(U_hat[k, i])\n\n    # Orthogonality loss\n    delta_V = np.linalg.norm(V.T @ V - np.eye(k), 'fro')\n\n    return sigma_hat_vals, residuals_true, residuals_pred, delta_V, k\n\n\ndef find_clusters(sigmas, tau_cluster):\n    \"\"\"\n    Groups sigma values into clusters based on a relative gap tolerance.\n    Returns a list of clusters, where each cluster is a list of (value, original_index) tuples.\n    \"\"\"\n    if len(sigmas) == 0:\n        return []\n    \n    sorted_indices = np.argsort(sigmas)\n    sorted_sigmas = sigmas[sorted_indices]\n\n    clusters = []\n    if len(sorted_sigmas) > 0:\n        current_cluster = [(sorted_sigmas[0], sorted_indices[0])]\n        for i in range(1, len(sorted_sigmas)):\n            gap = sorted_sigmas[i] - sorted_sigmas[i-1]\n            threshold = tau_cluster * max(1.0, sorted_sigmas[i-1])\n            if gap = threshold:\n                current_cluster.append((sorted_sigmas[i], sorted_indices[i]))\n            else:\n                clusters.append(current_cluster)\n                current_cluster = [(sorted_sigmas[i], sorted_indices[i])]\n        clusters.append(current_cluster)\n    return clusters\n\ndef solve():\n    \"\"\"\n    Main solver function.\n    \"\"\"\n    seed = 42\n    rng = np.random.default_rng(seed)\n    \n    # --- Matrix and vector generation ---\n    m, n = 80, 60\n    \n    # A1\n    U1_rand = rng.standard_normal(size=(m, m))\n    U1, _ = np.linalg.qr(U1_rand)\n    V1_rand = rng.standard_normal(size=(n, n))\n    V1, _ = np.linalg.qr(V1_rand)\n    s1 = 10.0 * (0.9 ** np.arange(n))\n    A1 = U1[:, :n] @ np.diag(s1) @ V1.T\n    \n    # A2\n    U2_rand = rng.standard_normal(size=(m, m))\n    U2, _ = np.linalg.qr(U2_rand)\n    V2_rand = rng.standard_normal(size=(n, n))\n    V2, _ = np.linalg.qr(V2_rand)\n    s2 = np.zeros(n)\n    s2[0], s2[1] = 5.0, 5.0\n    s2[2:] = 5.0 * (0.85 ** np.arange(n-2))\n    A2 = U2[:, :n] @ np.diag(s2) @ V2.T\n\n    matrices = {'A_1': A1, 'A_2': A2}\n    \n    b_base = rng.standard_normal(size=m)\n    b_base /= np.linalg.norm(b_base)\n    \n    # --- Test Cases ---\n    test_cases = [\n        ('A_1', 20, 0, 1e-8, 1e-4, 1e-8),\n        ('A_1', 35, 1e-2, 1e-3, 1e-3, 1e-3),\n        ('A_1', 5, 0, 1e-8, 1e-4, 1e-8),\n        ('A_2', 25, 0, 1e-8, 1e-4, 1e-8),\n    ]\n\n    gamma = 5.0\n    Gamma = 10.0\n    eps_mach = np.finfo(float).eps\n\n    results = []\n    \n    for case in test_cases:\n        A_id, k, eta_noise, eps_pert, tau_cluster, tau_orth = case\n        A = matrices[A_id]\n        \n        tau_abs = 100 * eps_mach * np.linalg.norm(A, 2)\n\n        # Run 1 (Main)\n        sigmas1, r1, rho1, delta_V1, k1 = analyze_gklb_run(A, b_base, k, eta_noise, rng)\n        \n        # Run 2 (Perturbed)\n        xi = rng.standard_normal(size=m)\n        b_pert = (b_base + eps_pert * xi) / np.linalg.norm(b_base + eps_pert * xi)\n        sigmas2, _, _, _, _ = analyze_gklb_run(A, b_pert, k, eta_noise, rng)\n\n        if k1 == 0:\n            results.append(0)\n            continue\n\n        # Cluster results\n        clusters1 = find_clusters(sigmas1, tau_cluster)\n        clusters2 = find_clusters(sigmas2, tau_cluster)\n        \n        removed_ghost_count = 0\n        if delta_V1 > tau_orth:\n            # Orthogonality is lost, check for ghost clusters\n            \n            # Identify persistent clusters\n            confirmed_ghost_clusters = []\n            mean_c2s = [np.mean([s for s, _ in c]) for c in clusters2]\n\n            for c1 in clusters1:\n                if len(c1) > 1:\n                    mean_c1 = np.mean([s for s, _ in c1])\n                    is_persistent = False\n                    for mean_c2 in mean_c2s:\n                        if abs(mean_c1 - mean_c2) = tau_cluster * max(1.0, mean_c1):\n                            is_persistent = True\n                            break\n                    if is_persistent:\n                        confirmed_ghost_clusters.append(c1)\n            \n            # Filter ghosts within confirmed clusters\n            for cluster in confirmed_ghost_clusters:\n                # Find best member (min true residual)\n                min_r_in_cluster = float('inf')\n                best_idx_in_cluster = -1\n                for _, idx in cluster:\n                    if r1[idx]  min_r_in_cluster:\n                        min_r_in_cluster = r1[idx]\n                        best_idx_in_cluster = idx\n\n                # Mark others as ghosts if they meet criteria\n                for _, idx in cluster:\n                    if idx != best_idx_in_cluster:\n                        is_inconsistent = (r1[idx] >= gamma * rho1[idx]) and \\\n                                          (r1[idx] >= Gamma * min_r_in_cluster) and \\\n                                          (r1[idx] > tau_abs)\n                        if is_inconsistent:\n                            removed_ghost_count += 1\n                            \n        results.append(removed_ghost_count)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}