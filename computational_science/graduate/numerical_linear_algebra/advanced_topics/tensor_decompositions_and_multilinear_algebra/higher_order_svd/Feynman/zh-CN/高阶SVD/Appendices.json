{
    "hands_on_practices": [
        {
            "introduction": "理论知识需要通过实践来巩固。本章的第一个练习旨在引导您手动完成一个完整的高阶奇异值分解（Higher-Order SVD, HOSVD）过程。通过处理一个具体的小型三阶张量，您将亲手执行模式展开、矩阵奇异值分解以及核心张量的计算，从而牢固掌握 HOSVD 的核心步骤与内在机制。",
            "id": "1071392",
            "problem": "高阶奇异值分解（HOSVD），也称为Tucker分解，是矩阵SVD到高阶张量的推广。一个$N$阶实值张量 $\\mathcal{A} \\in \\mathbb{R}^{I_1 \\times I_2 \\times \\dots \\times I_N}$ 可以被分解为一个核心张量 $\\mathcal{G} \\in \\mathbb{R}^{R_1 \\times R_2 \\times \\dots \\times R_N}$ 和一组正交因子矩阵 $U^{(n)} \\in \\mathbb{R}^{I_n \\times R_n}$（其中 $n=1, \\dots, N$）。该分解的多线性秩为 $(R_1, \\dots, R_N)$，其中 $R_n \\le I_n$。\n\n该分解使用n-模乘积表示为：\n$$ \\mathcal{A} \\approx \\mathcal{G} \\times_1 U^{(1)} \\times_2 U^{(2)} \\dots \\times_N U^{(N)} $$\n一个张量 $\\mathcal{X} \\in \\mathbb{R}^{I_1 \\times \\dots \\times I_N}$ 与一个矩阵 $M \\in \\mathbb{R}^{J_n \\times I_n}$ 沿着第$n$个模的n-模乘积是一个新的张量 $\\mathcal{Y} = \\mathcal{X} \\times_n M$，其尺寸为 $I_1 \\times \\dots \\times J_n \\times \\dots \\times I_N$，其元素由下式给出：\n$$ (\\mathcal{Y})_{i_1, \\dots, j_n, \\dots, i_N} = \\sum_{k=1}^{I_n} (\\mathcal{X})_{i_1, \\dots, k, \\dots, i_N} (M)_{j_n, k} $$\n\nHOSVD的因子矩阵 $U^{(n)}$ 是通过 $\\mathcal{A}$ 的n-模展开得到的。$\\mathcal{A}$ 的n-模展开，或称矩阵化，记作 $A_{(n)}$，是一个尺寸为 $I_n \\times (I_1 \\dots I_{n-1} I_{n+1} \\dots I_N)$ 的矩阵，其列是 $\\mathcal{A}$ 的n-模纤维。因子矩阵 $U^{(n)}$ 由 $A_{(n)}$ 的前 $R_n$ 个左奇异向量构成，这些向量根据其对应的奇异值按降序排列。\n\n然后，核心张量 $\\mathcal{G}$ 通过将 $\\mathcal{A}$ 投影到由因子矩阵张成的空间上来计算：\n$$ \\mathcal{G} = \\mathcal{A} \\times_1 (U^{(1)})^T \\times_2 (U^{(2)})^T \\dots \\times_N (U^{(N)})^T $$\n\n张量 $\\mathcal{A}$ 的弗罗贝尼乌斯范数由 $\\|\\mathcal{A}\\|_F = \\sqrt{\\sum_{i_1, \\dots, i_N} |a_{i_1 \\dots i_N}|^2}$ 给出。\n\n考虑一个三阶张量 $\\mathcal{A} \\in \\mathbb{R}^{2 \\times 3 \\times 2}$，它由其两个额面切片（通过固定第三个索引得到的矩阵）定义：\n$$ A_1 = \\mathcal{A}(:,:,1) = \\begin{pmatrix} 1  & 0 & 1 \\\\ 0 & 2 & 0 \\end{pmatrix} $$\n$$ A_2 = \\mathcal{A}(:,:,2) = \\begin{pmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 1 \\end{pmatrix} $$\n\n计算从 $\\mathcal{A}$ 的Tucker分解（指定多线性秩为 $(R_1, R_2, R_3) = (1, 2, 1)$）中得到的核心张量 $\\mathcal{G}$ 的弗罗贝尼乌斯范数。",
            "solution": "1. 1-模展开 $A_{(1)}\\in\\mathbb R^{2\\times6}$。按字典序使用排序 $(i_2,i_3)$，\n\n$$\nA_{(1)}=\\begin{pmatrix}\n1 & 0 & 1 & 0 & 1 & 0 \\\\\n0 & 2 & 0 & 1 & 0 & 1\n\\end{pmatrix}.\n$$\n\n则\n\n$$\nA_{(1)}A_{(1)}^T\n=\\begin{pmatrix} 3 & 0 \\\\ 0 & 6 \\end{pmatrix},\n$$\n\n所以最大特征值为 $6$，对应的单位特征向量为 $\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$。因此\n\n$$\nU^{(1)}=\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix},\\;R_1=1.\n$$\n\n\n2. 2-模展开 $A_{(2)}\\in\\mathbb R^{3\\times4}$，按字典序排序 $(i_1,i_3)$，\n\n$$\nA_{(2)}=\\begin{pmatrix} 1 & 0 & 0 & 1 \\\\ 0 & 2 & 1 & 0 \\\\ 1 & 0 & 0 & 1 \\end{pmatrix},\n$$\n\n所以\n\n$$\nA_{(2)}A_{(2)}^T=\\begin{pmatrix} 2 & 0 & 2 \\\\ 0 & 5 & 0 \\\\ 2 & 0 & 2 \\end{pmatrix}.\n$$\n\n其最大的两个特征值为 $5$ 和 $4$，对应的标准正交特征向量为 \n$\\,(0,1,0)^T$ 和 $\\tfrac{1}{\\sqrt{2}}(1,0,1)^T$。因此\n\n$$\nU^{(2)}=\\begin{pmatrix} 0 & \\tfrac{1}{\\sqrt{2}} \\\\ 1 & 0 \\\\ 0 & \\tfrac{1}{\\sqrt{2}} \\end{pmatrix},\\;R_2=2.\n$$\n\n\n3. 3-模展开 $A_{(3)}\\in\\mathbb R^{2\\times6}$，排序 $(i_1,i_2)$，\n\n$$\nA_{(3)}=\\begin{pmatrix} 1 & 0 & 1 & 0 & 2 & 0 \\\\ 0 & 1 & 0 & 1 & 0 & 1 \\end{pmatrix},\n$$\n\n且\n\n$$\nA_{(3)}A_{(3)}^T=\\begin{pmatrix} 6 & 0 \\\\ 0 & 3 \\end{pmatrix}.\n$$\n\n最大特征值为 $6$，对应的特征向量为 $(1,0)^T$，所以\n\n$$\nU^{(3)}=\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix},\\;R_3=1.\n$$\n\n\n4. 核心张量\n$\\displaystyle \\mathcal G\n=\\mathcal A\\times_1U^{(1)T}\\times_2U^{(2)T}\\times_3U^{(3)T}$\n的元素为\n\n$$\nG_{1,1,1}=2,\\quad G_{1,2,1}=0,\n$$\n\n所以 $\\mathcal G\\in\\mathbb R^{1\\times2\\times1}$。\n\n5. 弗罗贝尼乌斯范数\n\n$$\n\\|\\mathcal G\\|_F=\\sqrt{2^2+0^2} =2.\n$$",
            "answer": "$$\\boxed{2}$$"
        },
        {
            "introduction": "掌握了 HOSVD 的基本计算方法后，一个关键的实际问题是如何利用它进行有效的数据近似。近似的质量很大程度上取决于如何选择截断的多线性秩（multilinear rank）。这个练习将引导您从“如何计算”转向“如何应用”，通过编程实现并比较两种不同的秩选择策略，揭示独立按模式截断的潜在缺陷，并理解全局能量保持策略的重要性。",
            "id": "3549407",
            "problem": "考虑一个实数三阶张量 $X \\in \\mathbb{R}^{I \\times J \\times K}$。令 $X_{(n)}$ 表示 $X$ 的模-$n$ 展开，其中 $n \\in \\{1,2,3\\}$，并令 $X_{(n)}$ 的奇异值分解 (Singular Value Decomposition, SVD) 为 $X_{(n)} = U_{(n)} \\Sigma_{(n)} V_{(n)}^{\\top}$，其奇异值 $\\{\\sigma_{n,i}\\}_{i \\ge 1}$ 按非增序排列。$X$ 的高阶奇异值分解 (Higher-Order Singular Value Decomposition, HOSVD) 由正交因子矩阵 $U_1 \\in \\mathbb{R}^{I \\times I}$，$U_2 \\in \\mathbb{R}^{J \\times J}$，$U_3 \\in \\mathbb{R}^{K \\times K}$（分别通过 $X_{(1)}$、$X_{(2)}$ 和 $X_{(3)}$ 的左奇异向量获得）和一个核心张量 $G \\in \\mathbb{R}^{I \\times J \\times K}$ 定义，该核心张量由 $G = X \\times_1 U_1^{\\top} \\times_2 U_2^{\\top} \\times_3 U_3^{\\top}$ 给出，其中 $\\times_n$ 是模-$n$ 张量-矩阵乘积。具有多线性秩 $(r_1,r_2,r_3)$ 的截断 HOSVD 使用 $U_n$ 的前 $r_n$ 列以及 $G$ 的相应子张量来形成近似 $\\widehat{X}^{(r_1,r_2,r_3)}$。\n\n您需要实现并比较两种秩选择策略：\n\n- 逐模碎石图选择（独立截断）：对于给定的阈值 $\\alpha \\in (0,1)$，独立地为每个模 $n \\in \\{1,2,3\\}$ 选择最小的 $r_n$，使得 $\\sum_{i=1}^{r_n} \\sigma_{n,i}^2 \\ge \\alpha \\sum_{i \\ge 1} \\sigma_{n,i}^2$。\n- 联合能量目标（全局选择）：对于给定的目标 $\\beta \\in (0,1)$ 和一个上界元组 $(r_{1,\\max}, r_{2,\\max}, r_{3,\\max})$（其中 $1 \\le r_n \\le r_{n,\\max}$），按字典序搜索所有可行的三元组 $(r_1,r_2,r_3)$，以找到满足捕获的相对弗罗贝尼乌斯能量 $\\| \\widehat{X}^{(r_1,r_2,r_3)} \\|_F^2 / \\| X \\|_F^2 \\ge \\beta$ 的字典序最小的三元组。如果在此界限内不存在这样的三元组，则选择能最大化捕获能量的三元组。\n\n按如下方式构造表现出联合出现的低能量模式的张量。对于每个测试用例，将 $X$ 构建为秩-1 分量之和，其正交因子与规范基向量对齐：\n$$\nX \\;=\\; \\sum_{t=1}^{R} \\lambda_t \\, u_t \\otimes v_t \\otimes w_t,\n$$\n其中 $\\{u_t\\}_{t=1}^R \\subset \\mathbb{R}^I$，$\\{v_t\\}_{t=1}^R \\subset \\mathbb{R}^J$ 和 $\\{w_t\\}_{t=1}^R \\subset \\mathbb{R}^K$ 是正交向量集，对于每个 $t$，这些向量被选为各自空间中相应的标准基向量 $e_t$（例如，$u_t = e_t \\in \\mathbb{R}^I$）。假设所有 $\\lambda_t \\ge 0$。这种构造确保了每个展开 $X_{(n)}$ 的奇异值都等于集合 $\\{\\lambda_t\\}_{t=1}^R$（可能用零填充），而任何由 $t \\ge 2$ 索引的分量仅当所有三个模的秩都满足 $r_1 \\ge t$、$r_2 \\ge t$ 和 $r_3 \\ge t$ 时才能被表示。这测试了独立逐模截断的陷阱，即在任何单个模中都可能丢弃一个联合必需的方向，从而即使一个分量的总能量很显著，也会被整个移除。\n\n实现以下任务：\n\n1. 给定 $X$，通过 $X_{(1)}$、$X_{(2)}$、$X_{(3)}$ 的 SVD 计算 HOSVD 因子 $U_1$、$U_2$、$U_3$，并为指定的 $(r_1,r_2,r_3)$ 构建截断 HOSVD 重建 $\\widehat{X}^{(r_1,r_2,r_3)}$。\n2. 实现逐模碎石图选择，给定 $\\alpha$ 以产生 $(r_1^{\\text{per}}, r_2^{\\text{per}}, r_3^{\\text{per}})$，然后计算相对弗罗贝尼乌斯误差 $e_{\\text{per}} = \\| X - \\widehat{X}^{(r_1^{\\text{per}}, r_2^{\\text{per}}, r_3^{\\text{per}})} \\|_F / \\| X \\|_F$。\n3. 实现联合能量目标选择，给定 $\\beta$ 和界限 $(r_{1,\\max}, r_{2,\\max}, r_{3,\\max})$ 以产生 $(r_1^{\\text{joint}}, r_2^{\\text{joint}}, r_3^{\\text{joint}})$ 和相对弗罗贝尼乌斯误差 $e_{\\text{joint}} = \\| X - \\widehat{X}^{(r_1^{\\text{joint}}, r_2^{\\text{joint}}, r_3^{\\text{joint}})} \\|_F / \\| X \\|_F$。\n4. 对于每个测试用例，还需报告乘积 $d_{\\text{per}} = r_1^{\\text{per}} r_2^{\\text{per}} r_3^{\\text{per}}$ 和 $d_{\\text{joint}} = r_1^{\\text{joint}} r_2^{\\text{joint}} r_3^{\\text{joint}}$ 以量化模型大小。\n\n您的程序必须实现上述任务并运行以下测试套件，严格按照规范使用规范基向量构造 $X$：\n\n- 测试用例 1（联合必需的第二模式，独立截断失败）：$I = 8$，$J = 8$，$K = 8$，$R = 2$，$(\\lambda_1,\\lambda_2) = (1.0, 0.6)$，$\\alpha = 0.85$，$\\beta = 0.95$，$(r_{1,\\max}, r_{2,\\max}, r_{3,\\max}) = (2,2,2)$。\n- 测试用例 2（独立截断足够使用的理想情况）：$I = 8$，$J = 8$，$K = 8$，$R = 2$，$(\\lambda_1,\\lambda_2) = (1.0, 0.4)$，$\\alpha = 0.6$，$\\beta = 0.8$，$(r_{1,\\max}, r_{2,\\max}, r_{3,\\max}) = (2,2,2)$。\n- 测试用例 3（无隐藏模式的边界情况）：$I = 8$，$J = 8$，$K = 8$，$R = 2$，$(\\lambda_1,\\lambda_2) = (1.0, 0.0)$，$\\alpha = 0.99$，$\\beta = 0.99$，$(r_{1,\\max}, r_{2,\\max}, r_{3,\\max}) = (2,2,2)$。\n- 测试用例 4（多个联合必需的低能量模式）：$I = 6$，$J = 6$，$K = 6$，$R = 3$，$(\\lambda_1,\\lambda_2,\\lambda_3) = (1.0, 0.5, 0.5)$，$\\alpha = 0.66$，$\\beta = 0.9$，$(r_{1,\\max}, r_{2,\\max}, r_{3,\\max}) = (3,3,3)$。\n\n最终输出格式。您的程序必须生成一行包含一个数字列表，该列表汇总了四个测试用例的结果，顺序固定为\n$$\n\\big[ e_{\\text{per}}^{(1)},\\; e_{\\text{joint}}^{(1)},\\; d_{\\text{per}}^{(1)},\\; d_{\\text{joint}}^{(1)},\\; e_{\\text{per}}^{(2)},\\; e_{\\text{joint}}^{(2)},\\; d_{\\text{per}}^{(2)},\\; d_{\\text{joint}}^{(2)},\\; e_{\\text{per}}^{(3)},\\; e_{\\text{joint}}^{(3)},\\; d_{\\text{per}}^{(3)},\\; d_{\\text{joint}}^{(3)},\\; e_{\\text{per}}^{(4)},\\; e_{\\text{joint}}^{(4)},\\; d_{\\text{per}}^{(4)},\\; d_{\\text{joint}}^{(4)} \\big],\n$$\n其中每个误差 $e_{\\text{per}}^{(i)}$ 和 $e_{\\text{joint}}^{(i)}$ 四舍五入到 $6$ 位小数，每个 $d_{\\text{per}}^{(i)}$ 和 $d_{\\text{joint}}^{(i)}$ 是一个整数。\n\n您的实现必须是自包含的，并且不需要任何用户输入。除了指定的值外，不需要物理单位、角度单位或百分比，并且所有数值答案都是无单位的实数。程序必须仅依赖于上面定义的标准线性代数运算，无需任何绘图。",
            "solution": "该问题要求实现并比较在三阶张量的高阶奇异值分解 (HOSVD) 中选择多线性秩的两种不同策略。其目标是突显一种场景，在这种场景中，一种常见的启发式方法——独立的逐模秩选择——未能保留重要的结构信息，而这些信息能被一种更全面的联合秩选择方法所捕获。\n\n我们首先形式化张量代数中的必要概念。一个三阶张量是向量空间张量积中的一个元素，我们将其表示为一个三维数组 $X \\in \\mathbb{R}^{I \\times J \\times K}$。\n\n$X$ 的模-$n$ 展开（或矩阵化），记为 $X_{(n)}$，是将张量元素重新排列成一个矩阵的过程。对于 $n=1, 2, 3$，展开如下：\n-   $X_{(1)} \\in \\mathbb{R}^{I \\times JK}$，其中位置 $(i, (j-1)K+k)$ 处的元素是 $X_{ijk}$。\n-   $X_{(2)} \\in \\mathbb{R}^{J \\times IK}$，其中位置 $(j, (k-1)I+i)$ 处的元素是 $X_{ijk}$。\n-   $X_{(3)} \\in \\mathbb{R}^{K \\times IJ}$，其中位置 $(k, (i-1)J+j)$ 处的元素是 $X_{ijk}$。\n\n一个张量 $X \\in \\mathbb{R}^{I_1 \\times \\dots \\times I_N}$ 与一个矩阵 $A \\in \\mathbb{R}^{J_n \\times I_n}$ 的模-$n$ 乘积，记为 $Y = X \\times_n A$，得到一个张量 $Y \\in \\mathbb{R}^{I_1 \\times \\dots \\times J_n \\times \\dots \\times I_N}$。其元素由 $Y_{i_1 \\dots j_n \\dots i_N} = \\sum_{k=1}^{I_n} X_{i_1 \\dots k \\dots i_N} A_{j_n k}$ 给出。\n\n$X$ 的高阶奇异值分解 (HOSVD) 是一种形式为 $X = G \\times_1 U_1 \\times_2 U_2 \\times_3 U_3$ 的分解，其中：\n1.  $U_1 \\in \\mathbb{R}^{I \\times I}$，$U_2 \\in \\mathbb{R}^{J \\times J}$ 和 $U_3 \\in \\mathbb{R}^{K \\times K}$ 是正交因子矩阵。$U_n$ 的列是从模-$n$ 展开的奇异值分解 (SVD) 中获得的左奇异向量：$X_{(n)} = U_n \\Sigma_{(n)} V_n^\\top$。\n2.  $G \\in \\mathbb{R}^{I \\times J \\times K}$ 是核心张量，计算方式为 $G = X \\times_1 U_1^\\top \\times_2 U_2^\\top \\times_3 U_3^\\top$。核心张量 $G$ 捕获了因子矩阵各分量之间的相互作用。由于因子矩阵的正交性，$X$ 和 $G$ 的弗罗贝尼乌斯范数相等，即 $\\|X\\|_F = \\|G\\|_F$。\n\n截断 HOSVD 提供了 $X$ 的一个低秩近似。给定一个多线性秩 $(r_1, r_2, r_3)$，其中 $1 \\le r_n \\le \\text{dim}_n(X)$，我们将因子矩阵截断为其前 $r_n$ 列，得到 $\\tilde{U}_n \\in \\mathbb{R}^{\\text{dim}_n(X) \\times r_n}$，并将核心张量截断为主子张量 $\\tilde{G} = G(1:r_1, 1:r_2, 1:r_3)$。那么近似为 $\\widehat{X}^{(r_1,r_2,r_3)} = \\tilde{G} \\times_1 \\tilde{U}_1 \\times_2 \\tilde{U}_2 \\times_3 \\tilde{U}_3$。\n一个关键性质是，近似的弗罗贝尼乌斯范数的平方等于截断核心张量的弗罗贝尼乌斯范数的平方，即 $\\|\\widehat{X}^{(r_1,r_2,r_3)}\\|_F^2 = \\|\\tilde{G}\\|_F^2$。相对近似误差由 $e = \\|X - \\widehat{X}\\|_F / \\|X\\|_F$ 给出。利用范数保持性质，这可以高效地计算为 $e = \\sqrt{1 - \\|\\widehat{X}\\|_F^2 / \\|X\\|_F^2}$。\n\n问题指定了一种特殊的张量构造方法：$X = \\sum_{t=1}^{R} \\lambda_t \\, u_t \\otimes v_t \\otimes w_t$，其中 $u_t=e_t$，$v_t=e_t$ 和 $w_t=e_t$ 是标准基向量，且 $\\lambda_t \\ge 0$。这会产生一个对角张量，其中唯一的非零项是 $X_{t,t,t} = \\lambda_t$（对于 $t=1, \\dots, R$）。对于这样的张量，其展开 $X_{(n)}$ 的行是正交的。$X_{(n)}$ 的 SVD 产生的因子矩阵 $U_n$ 是单位矩阵（如果 $\\lambda_t$ 未排序，则为置换矩阵），奇异值为 $\\{\\lambda_t\\}_{t=1}^R$。因此，核心张量为 $G=X$。近似 $\\widehat{X}^{(r_1,r_2,r_3)}$ 的弗罗贝尼乌斯范数平方简化为 $\\|\\widehat{X}^{(r_1,r_2,r_3)}\\|_F^2 = \\sum_{t=1}^{\\min(r_1,r_2,r_3)} \\lambda_t^2$，假设 $\\lambda_t$ 是非增序排列的。这种特殊结构使得近似的能量取决于三个秩的最小值，这是测试用例的基础。\n\n两种秩选择策略是：\n1.  **逐模碎石图选择**：该方法独立处理每个模。对于一个阈值 $\\alpha$，它为每个模 $n$ 找到最小的秩 $r_n$，以捕获该模奇异值中至少 $\\alpha$ 的能量：$\\sum_{i=1}^{r_n} \\sigma_{n,i}^2 \\ge \\alpha \\sum_{i \\ge 1} \\sigma_{n,i}^2$。对于所构造的张量，平方奇异值 $\\{\\sigma_{n,i}^2\\}$ 对所有模都是相同的，等于 $\\{\\lambda_t^2\\}$。\n2.  **联合能量目标**：该方法考虑重建张量的总能量。对于一个目标能量分数 $\\beta$，它在给定的界限 $(r_{1,\\max}, r_{2,\\max}, r_{3,\\max})$ 内搜索字典序最小的秩元组 $(r_1, r_2, r_3)$，使得 $\\|\\widehat{X}^{(r_1,r_2,r_3)}\\|_F^2 / \\|X\\|_F^2 \\ge \\beta$。搜索过程通过在嵌套循环中迭代 $r_1, r_2, r_3$ 来进行。对于每个元组，从核心张量高效地计算捕获的能量，并与阈值进行比较。如果没有元组满足条件，则选择最大化捕获能量的那个。\n\n我们将用测试用例 4 来说明这个过程：\n-   给定：$I=J=K=6$，$R=3$，$(\\lambda_1, \\lambda_2, \\lambda_3) = (1.0, 0.5, 0.5)$，$\\alpha=0.66$，$\\beta=0.9$ 和 $r_{\\max}=(3,3,3)$。\n-   张量构造：$X_{111}=1.0, X_{222}=0.5, X_{333}=0.5$（使用基于 1 的索引）。\n-   总能量：$\\|X\\|_F^2 = 1.0^2 + 0.5^2 + 0.5^2 = 1.5$。\n-   任何模的平方奇异值为 $(1.0, 0.25, 0.25)$。平方和的总值为 $1.5$。\n\n-   **逐模选择 ($r^{\\text{per}}$)**：目标能量为 $\\alpha \\sum \\sigma^2 = 0.66 \\times 1.5 = 0.99$。\n    -   对于 $r=1$，累积能量为 $1.0^2=1.0$。因为 $1.0 \\ge 0.99$，所以每个模的最小秩为 $r_n=1$。\n    -   这得到 $r^{\\text{per}} = (1,1,1)$ 和模型大小 $d_{\\text{per}}=1 \\times 1 \\times 1=1$。\n    -   近似 $\\widehat{X}^{(1,1,1)}$ 只捕获了第一个分量。其能量为 $\\lambda_1^2=1.0$。\n    -   相对误差为 $e_{\\text{per}} = \\sqrt{1 - 1.0/1.5} = \\sqrt{1/3} \\approx 0.577350$。\n\n-   **联合能量目标 ($r^{\\text{joint}}$)**：目标相对能量为 $\\beta=0.9$。\n    -   对 $(r_1,r_2,r_3)$ 的搜索按字典序从 $(1,1,1)$ 到 $(3,3,3)$ 进行。\n    -   对于一个元组，捕获的相对能量为 $(\\sum_{t=1}^{\\min(r_1,r_2,r_3)} \\lambda_t^2) / 1.5$。\n    -   对于任何 $\\min(r_1,r_2,r_3)=1$ 的元组，相对能量为 $1.0/1.5 \\approx 0.667  0.9$。\n    -   对于任何 $\\min(r_1,r_2,r_3)=2$ 的元组，相对能量为 $(1.0+0.25)/1.5 \\approx 0.833  0.9$。\n    -   对于任何 $\\min(r_1,r_2,r_3)=3$ 的元组，相对能量为 $(1.0+0.25+0.25)/1.5 = 1.0 \\ge 0.9$。\n    -   满足此条件的字典序第一个元组是 $(3,3,3)$。\n    -   这得到 $r^{\\text{joint}} = (3,3,3)$ 和模型大小 $d_{\\text{joint}}=3 \\times 3 \\times 3=27$。\n    -   近似 $\\widehat{X}^{(3,3,3)}$ 捕获了所有分量。其能量为 $1.5$。\n    -   相对误差为 $e_{\\text{joint}} = \\sqrt{1 - 1.5/1.5} = 0$。\n\n这个案例展示了陷阱：逐模选择被每个模中第一个奇异值的主导地位所误导，选择了秩为 1，丢弃了两个分量并导致了很大的误差。而联合选择正确地识别出，要达到期望的整体近似质量，所有三个秩都必须至少为 3，即使这会导致一个大得多的模型。程序将对所有指定的测试用例执行此逻辑。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import svd\n\ndef construct_tensor(I, J, K, lambdas):\n    \"\"\"Constructs the special diagonal tensor X.\"\"\"\n    X = np.zeros((I, J, K))\n    R = len(lambdas)\n    for t in range(R):\n        if t  I and t  J and t  K:\n            X[t, t, t] = lambdas[t]\n    return X\n\ndef mode_n_unfolding(X, n):\n    \"\"\"Computes the mode-n unfolding of a tensor X.\"\"\"\n    if n == 1:\n        return np.reshape(X, (X.shape[0], -1))\n    elif n == 2:\n        return np.reshape(np.transpose(X, (1, 0, 2)), (X.shape[1], -1))\n    elif n == 3:\n        return np.reshape(np.transpose(X, (2, 0, 1)), (X.shape[2], -1))\n    else:\n        raise ValueError(\"Mode must be 1, 2, or 3 for an order-3 tensor.\")\n\ndef mode_n_product(X, A, n):\n    \"\"\"Computes the mode-n product of a tensor X with a matrix A.\"\"\"\n    # This implementation is for order-3 tensors\n    if n not in [1, 2, 3]:\n        raise ValueError(\"Mode must be 1, 2, or 3.\")\n    \n    # np.tensordot contracts over specified axes. \n    # For X_abc and A_ij, we want to sum over the n-th mode of X and the second dim of A.\n    # X mode-1 (a) is index 0. X mode-2 (b) is index 1. X mode-3 (c) is index 2.\n    res_tensor = np.tensordot(X, A, axes=([n-1], [1]))\n    \n    # The new dimension from A is at the end. We move it to the correct (n-th) position.\n    # The original axes shift. e.g. for n=1, original axes are (1,2) of X.\n    # result shape is (J, K, I_new), need to move I_new to front.\n    return np.moveaxis(res_tensor, -1, n-1)\n\ndef compute_hosvd(X):\n    \"\"\"Computes the HOSVD of a tensor X.\"\"\"\n    dims = X.shape\n    U_factors = []\n    singular_values = []\n\n    for n in range(1, 4):\n        X_n = mode_n_unfolding(X, n)\n        # We need the full U matrix to compute the core tensor G correctly\n        U, s, _ = svd(X_n, full_matrices=True)\n        # Make sure U has the correct dimensions if X_n is skinny\n        if U.shape[1]  dims[n-1]:\n             U_full = np.zeros((dims[n-1], dims[n-1]))\n             U_full[:, :U.shape[1]] = U\n             U = U_full\n        U_factors.append(U)\n\n        s_full = np.zeros(min(X_n.shape))\n        s_full[:len(s)] = s\n        singular_values.append(s_full)\n    \n    U1, U2, U3 = U_factors\n    G = mode_n_product(X, U1.T, 1)\n    G = mode_n_product(G, U2.T, 2)\n    G = mode_n_product(G, U3.T, 3)\n    \n    return U_factors, singular_values, G\n\ndef per_mode_scree_selection(singular_values, alpha):\n    \"\"\"Performs per-mode scree plot based rank selection.\"\"\"\n    ranks = []\n    for s_n in singular_values:\n        s_n_sq = s_n**2\n        total_energy = np.sum(s_n_sq)\n        if total_energy == 0:\n            ranks.append(1)\n            continue\n        \n        cumulative_energy = np.cumsum(s_n_sq)\n        target_energy = alpha * total_energy\n        \n        # Find first rank r where cumulative energy exceeds target\n        # np.where returns a tuple of arrays, we need the first element of the first array\n        r_n_candidates = np.where(cumulative_energy >= target_energy)[0]\n        \n        if len(r_n_candidates) > 0:\n            r_n = r_n_candidates[0] + 1\n        else: # Should not happen if alpha = 1, but for safety\n             r_n = len(s_n)\n        ranks.append(r_n)\n    return tuple(ranks)\n\ndef joint_energy_targeting(G, total_energy_sq, beta, r_max):\n    \"\"\"Performs joint energy targeting rank selection.\"\"\"\n    r1_max, r2_max, r3_max = r_max\n    \n    best_ranks = (1, 1, 1)\n    max_captured_energy = -1.0\n\n    for r1 in range(1, r1_max + 1):\n        for r2 in range(1, r2_max + 1):\n            for r3 in range(1, r3_max + 1):\n                G_trunc = G[:r1, :r2, :r3]\n                captured_energy_sq = np.sum(G_trunc**2)\n\n                if total_energy_sq > 0 and captured_energy_sq / total_energy_sq >= beta:\n                    return (r1, r2, r3)\n                \n                if captured_energy_sq > max_captured_energy:\n                    max_captured_energy = captured_energy_sq\n                    best_ranks = (r1, r2, r3)\n    \n    # This fallback is executed if no rank combination meets the beta threshold\n    return best_ranks\n\ndef calculate_error_and_size(ranks, G, total_energy_sq):\n    \"\"\"Calculates relative Frobenius error and model size for given ranks.\"\"\"\n    r1, r2, r3 = ranks\n    d = r1 * r2 * r3\n    \n    G_trunc = G[:r1, :r2, :r3]\n    captured_energy_sq = np.sum(G_trunc**2)\n    \n    if total_energy_sq == 0:\n        error = 0.0\n    else:\n        # Avoid numerical issues with captured_energy_sq > total_energy_sq\n        ratio = min(1.0, captured_energy_sq / total_energy_sq)\n        error = np.sqrt(1.0 - ratio)\n\n    return error, d\n\ndef solve():\n    test_cases = [\n        # (I, J, K, lambdas, alpha, beta, (r1_max, r2_max, r3_max))\n        (8, 8, 8, (1.0, 0.6), 0.85, 0.95, (2, 2, 2)),\n        (8, 8, 8, (1.0, 0.4), 0.6, 0.8, (2, 2, 2)),\n        (8, 8, 8, (1.0, 0.0), 0.99, 0.99, (2, 2, 2)),\n        (6, 6, 6, (1.0, 0.5, 0.5), 0.66, 0.9, (3, 3, 3)),\n    ]\n\n    all_results = []\n\n    for I, J, K, lambdas, alpha, beta, r_max in test_cases:\n        # 1. Construct tensor and compute total energy\n        X = construct_tensor(I, J, K, lambdas)\n        total_energy_sq = np.sum(X**2)\n\n        # 2. Compute HOSVD\n        U_factors, singular_values, G = compute_hosvd(X)\n\n        # 3. Per-mode scree selection\n        r_per = per_mode_scree_selection(singular_values, alpha)\n        e_per, d_per = calculate_error_and_size(r_per, G, total_energy_sq)\n\n        # 4. Joint energy targeting\n        r_joint = joint_energy_targeting(G, total_energy_sq, beta, r_max)\n        e_joint, d_joint = calculate_error_and_size(r_joint, G, total_energy_sq)\n        \n        # 5. Append results\n        all_results.append(round(e_per, 6))\n        all_results.append(round(e_joint, 6))\n        all_results.append(d_per)\n        all_results.append(d_joint)\n\n    # Final print statement\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在真实的科学与工程计算中，理论上完美的算法必须面对有限精度计算带来的挑战，尤其是在处理病态（ill-conditioned）数据时。本练习将带您深入探讨 HOSVD 的数值稳定性问题。您将通过构造特定的病态张量，来量化由于舍入误差导致的因子矩阵正交性损失和能量不守恒，并学习如何通过再正交化（re-orthogonalization）等技术来缓解这些问题，这对于开发稳健的数值算法至关重要。",
            "id": "3549432",
            "problem": "您需要研究高阶奇异值分解（HOSVD）在模态展开是病态的情况下对有限精度算法的敏感性。设输入为一个三阶张量$\\mathcal{X} \\in \\mathbb{R}^{I \\times J \\times K}$，并以下列基本原理为出发点：矩阵奇异值分解（SVD），正交变换保持弗罗贝尼乌斯范数不变，以及病态会放大小数舍入误差。HOSVD通过对$\\mathcal{X}$的每个模态-n展开$X_{(n)}$应用矩阵SVD来构造正交因子矩阵$U^{(1)} \\in \\mathbb{R}^{I \\times I}$，$U^{(2)} \\in \\mathbb{R}^{J \\times J}$和$U^{(3)} \\in \\mathbb{R}^{K \\times K}$，并通过逐次模态积定义核心张量$\\mathcal{S} = \\mathcal{X} \\times_1 U^{(1)\\top} \\times_2 U^{(2)\\top} \\times_3 U^{(3)\\top}$。在精确计算和精确正交性条件下，$\\mathcal{X}$的弗罗贝尼乌斯范数等于$\\mathcal{S}$的弗罗贝尼乌斯范数。在有限精度下，可能会出现正交性和能量的偏差。\n\n通过对具有近共线因子向量和巨大尺度差异的秩-1分量求和，构造具有受控病态的合成张量$\\mathcal{X}$。具体来说，对于选定的整数$R \\ge 1$，生成向量$a_r \\in \\mathbb{R}^I$，$b_r \\in \\mathbb{R}^J$，$c_r \\in \\mathbb{R}^K$（$r \\in \\{0,1,\\ldots,R-1\\}$），其中$a_0, b_0, c_0$是归一化为单位范数的随机高斯向量；$a_1, b_1, c_1$是根据随机高斯方向$\\delta a, \\delta b, \\delta c$构造为$a_0 + \\epsilon \\,\\delta a, b_0 + \\epsilon \\,\\delta b, c_0 + \\epsilon \\,\\delta c$；对于$r \\ge 2$，使用独立的随机高斯单位向量。使用正尺度$\\sigma_r$形成\n$$\n\\mathcal{X} = \\sum_{r=0}^{R-1} \\sigma_r \\, a_r \\circ b_r \\circ c_r,\n$$\n其中$\\circ$表示外积。在指定的浮点精度（单精度或双精度）下，通过对模态-n展开$X_{(n)}$进行矩阵SVD来实现$U^{(n)}$的计算，并通过逐次模态积计算核心张量$\\mathcal{S}$。为了重新正交化，对每个$U^{(n)}$应用一个数值稳定的基于Householder的QR分解（由标准线性代数例程提供）以获得$\\tilde{U}^{(n)}$，并重新计算核心张量$\\tilde{\\mathcal{S}}$。\n\n对于每个张量和精度，量化：\n- 因子矩阵的正交性损失，由下式计算\n$$\nE_{\\mathrm{orth}} = \\max_{n \\in \\{1,2,3\\}} \\left\\| U^{(n)\\top} U^{(n)} - I \\right\\|_F,\n$$\n其中$\\|\\cdot\\|_F$表示弗罗贝尼乌斯范数，$I$是相应大小的单位矩阵。\n- 核心张量中的能量偏差，由下式计算\n$$\nE_{\\mathrm{energy}} = \\frac{\\left| \\left\\| \\mathcal{S} \\right\\|_F - \\left\\| \\mathcal{X} \\right\\|_F \\right|}{\\left\\| \\mathcal{X} \\right\\|_F}。\n$$\n\n然后，在重新正交化$U^{(n)}$以获得$\\tilde{U}^{(n)}$和$\\tilde{\\mathcal{S}}$后，重复此量化过程。\n\n实现一个单一的程序，该程序：\n- 完全按照描述生成合成张量。\n- 在指定精度下，使用$X_{(n)}$的矩阵SVD计算HOSVD因子矩阵$U^{(n)}$。\n- 使用模态积计算核心张量$\\mathcal{S}$。\n- 在通过QR重新正交化之前和之后，计算误差度量$E_{\\mathrm{orth}}$和$E_{\\mathrm{energy}}$。\n\n使用以下参数集测试套件，以确保覆盖典型、病态和近秩亏场景。每个测试用例以元组$(I,J,K,R,\\epsilon,\\text{scales},\\text{seed},\\text{precision})$的形式给出：\n- 用例1（理想情况，中等条件数）：$(6,5,4,3,10^{-3},[\\;1.0,0.1,0.01\\;],0,\\text{single})$。\n- 用例2（由极端尺度和近共线性导致的严重病态展开）：$(8,8,8,3,10^{-6},[\\;10^{8},10^{-8},10^{4}\\;],1,\\text{single})$。\n- 用例3（近秩亏贡献）：$(3,3,3,2,10^{-9},[\\;1.0,10^{-12}\\;],2,\\text{single})$。\n- 用例4（双精度基线，与用例1相同但为双精度）：$(6,5,4,3,10^{-3},[\\;1.0,0.1,0.01\\;],0,\\text{double})$。\n\n对于每个用例，您的程序必须按顺序输出四个浮点值：\n- 未重新正交化时的$E_{\\mathrm{orth}}$，\n- 重新正交化后的$E_{\\mathrm{orth}}$，\n- 未重新正交化时的$E_{\\mathrm{energy}}$，\n- 重新正交化后的$E_{\\mathrm{energy}}$。\n\n您的程序应生成单行输出，其中包含所有测试用例的结果，格式为方括号括起来的逗号分隔列表，值按用例和度量的顺序连续排列（例如，$[\\;e_{1,1},e_{1,2},e_{1,3},e_{1,4},e_{2,1},\\ldots\\;]$）。不涉及物理单位；不存在角度；所有输出必须是浮点数。",
            "solution": "用户提供的问题已经过严格的验证过程。\n\n### 步骤 1：提取已知条件\n\n- **问题领域**：高阶奇异值分解（HOSVD）的数值稳定性。\n- **输入对象**：一个三阶张量 $\\mathcal{X} \\in \\mathbb{R}^{I \\times J \\times K}$。\n- **HOSVD 定义**：\n    - 模态-n展开：$X_{(n)}$。\n    - 通过对每个$X_{(n)}$进行奇异值分解（SVD）获得的正交因子矩阵$U^{(1)} \\in \\mathbb{R}^{I \\times I}$，$U^{(2)} \\in \\mathbb{R}^{J \\times J}$，$U^{(3)} \\in \\mathbb{R}^{K \\times K}$。\n    - 核心张量：$\\mathcal{S} = \\mathcal{X} \\times_1 U^{(1)\\top} \\times_2 U^{(2)\\top} \\times_3 U^{(3)\\top}$。\n- **理论性质**：在精确计算下，$\\|\\mathcal{X}\\|_F = \\|\\mathcal{S}\\|_F$。\n- **合成张量生成**：\n    - 公式：$\\mathcal{X} = \\sum_{r=0}^{R-1} \\sigma_r \\, a_r \\circ b_r \\circ c_r$，其中$\\circ$是外积。\n    - 因子向量（$a_r, b_r, c_r$）：\n        - 对于$r=0$：归一化的随机高斯向量。\n        - 对于$r=1$：$r=0$向量的扰动版本：$a_1 = a_0 + \\epsilon\\,\\delta a$等，其中$\\delta a$是一个随机高斯方向。\n        - 对于$r \\ge 2$：独立的、归一化的随机高斯向量。\n- **重新正交化**：\n    - 过程：对每个因子矩阵$U^{(n)}$应用基于Householder的QR分解，以获得一个新的、数值上正交的矩阵$\\tilde{U}^{(n)}$。\n    - 重新计算：使用$\\tilde{U}^{(n)}$矩阵计算新的核心张量$\\tilde{\\mathcal{S}}$。\n- **误差度量**：\n    - 正交性损失：$E_{\\mathrm{orth}} = \\max_{n \\in \\{1,2,3\\}} \\left\\| U^{(n)\\top} U^{(n)} - I \\right\\|_F$。\n    - 能量偏差：$E_{\\mathrm{energy}} = \\frac{\\left| \\left\\| \\mathcal{S} \\right\\|_F - \\left\\| \\mathcal{X} \\right\\|_F \\right|}{\\left\\| \\mathcal{X} \\right\\|_F}$。\n- **任务**：\n    1. 实现合成张量的生成。\n    2. 在指定的浮点精度（'single' 或 'double'）下实现HOSVD计算。\n    3. 实现重新正交化步骤。\n    4. 对每个测试用例，计算四个度量（重新正交化前后的$E_{\\mathrm{orth}}$和$E_{\\mathrm{energy}}$）。\n- **测试套件**：\n    - 用例1：$(I,J,K,R,\\epsilon,\\text{scales},\\text{seed},\\text{precision}) = (6,5,4,3,10^{-3},[\\;1.0,0.1,0.01\\;],0,\\text{single})$。\n    - 用例2：$(8,8,8,3,10^{-6},[\\;10^{8},10^{-8},10^{4}\\;],1,\\text{single})$。\n    - 用例3：$(3,3,3,2,10^{-9},[\\;1.0,10^{-12}\\;],2,\\text{single})$。\n    - 用例4：$(6,5,4,3,10^{-3},[\\;1.0,0.1,0.01\\;],0,\\text{double})$。\n\n### 步骤 2：使用提取的已知条件进行验证\n\n- **科学基础**：该问题牢固地植根于数值线性代数和张量分析。HOSVD、SVD、QR分解、浮点运算和数值稳定性都是成熟的科学概念。实验设计是研究算法属性的标准方法。此标准已满足。\n- **良置性**：该问题是良置的。输入通过确定性的生成过程（给定随机种子）明确定义。所需的计算通过算法指定。输出度量由明确的数学公式定义。每个测试用例都存在唯一的解。\n- **客观性**：问题使用精确、客观的数学和算法语言陈述。没有主观因素。\n- **缺陷分析**：\n    1. **科学/事实不准确**：无。前提是正确的。\n    2. **不可形式化/不相关**：无。问题可直接形式化为与HOSVD相关的数值计算。\n    3. **设置不完整/矛盾**：问题是完整且自洽的。术语“随机高斯方向”用于扰动向量在此上下文中是标准术语，解释为分量取自标准正态分布的向量。\n    4. **不现实/不可行**：无。这些计算是标准的，在现代计算机上是可行的。\n    5. **病态/结构不良**：无。问题结构良好。\n    6. **伪深刻/琐碎**：无。该问题需要非凡的实现，并演示了数值分析中的一个核心概念：病态条件的影响以及诸如重新正交化等补救措施的效用。\n    7. **超出科学可验证性范围**：无。结果是可通过计算验证的。\n\n### 步骤 3：结论与行动\n\n问题陈述是**有效的**。将提供解决方案。\n\n任务是研究高阶奇异值分解（HOSVD）应用于其模态展开是病态的张量时的数值敏感性。该分析涉及生成具有受控属性的合成张量，计算它们的HOSVD，并量化在重新正交化步骤之前和之后的数值误差。\n\n首先，我们构造合成张量$\\mathcal{X} \\in \\mathbb{R}^{I \\times J \\times K}$，作为$R$个秩-1张量的和，这个模型被称为CANDECOMP/PARAFAC (CP)分解：\n$$\n\\mathcal{X} = \\sum_{r=0}^{R-1} \\sigma_r \\, (a_r \\circ b_r \\circ c_r)\n$$\n这里，$a_r \\in \\mathbb{R}^I$，$b_r \\in \\mathbb{R}^J$和$c_r \\in \\mathbb{R}^K$是因子向量，$\\sigma_r$是正标量，$\\circ$表示外积。病态条件是通过两种机制引入的。首先，对于$r=1$，因子向量（$a_1, b_1, c_1$）通过关系$a_1 = a_0 + \\epsilon\\,\\delta a$（对于小参数$\\epsilon$）被构造成与$r=0$的向量（$a_0, b_0, c_0$）近共线。这确保了每个模态的因子向量集合至少包含一对近线性相关的向量，这反过来又使得$\\mathcal{X}$的模态展开呈病态。其次，使用差异巨大的尺度$\\sigma_r$加剧了这种病态，因为量级差异巨大的分量相加，可能导致精度损失。\n\n然后计算$\\mathcal{X}$的HOSVD。对于一个三阶张量，这涉及三个主要步骤：\n$1$. 对于每个模态$n \\in \\{1, 2, 3\\}$，张量$\\mathcal{X}$被矩阵化（展开）成一个矩阵$X_{(n)}$。模态-1展开$X_{(1)} \\in \\mathbb{R}^{I \\times (JK)}$将其$\\mathcal{X}$的模态-1纤维（列）排列为其列。对于$X_{(2)} \\in \\mathbb{R}^{J \\times (IK)}$和$X_{(3)} \\in \\mathbb{R}^{K \\times (IJ)}$也是类似。\n$2$. 为每个展开计算完整的奇异值分解（SVD）：$X_{(n)} = U^{(n)} \\Sigma^{(n)} V^{(n)\\top}$。模态-n的因子矩阵是左奇异向量矩阵$U^{(n)}$。在精确计算中，每个$U^{(n)}$都是完全正交的。\n$3$. 核心张量$\\mathcal{S}$是通过将$\\mathcal{X}$投影到由因子矩阵张成的空间上来计算的：\n$$\n\\mathcal{S} = \\mathcal{X} \\times_1 U^{(1)\\top} \\times_2 U^{(2)\\top} \\times_3 U^{(3)\\top}\n$$\n其中$\\times_n$表示模态-n张量-矩阵积。\n\n由于$X_{(n)}$的病态以及有限精度算法的限制，计算出的矩阵$U^{(n)}$可能会偏离完全正交性。我们使用正交性损失来量化这种偏差，定义为正交性条件残差的最大弗罗贝尼乌斯范数：\n$$\nE_{\\mathrm{orth}} = \\max_{n \\in \\{1,2,3\\}} \\left\\| U^{(n)\\top} U^{(n)} - I_n \\right\\|_F\n$$\n其中$I_n$是适当大小的单位矩阵。\n\n此外，HOSVD的一个基本性质是保持弗罗贝尼乌斯范数：$\\|\\mathcal{X}\\|_F = \\|\\mathcal{S}\\|_F$。数值误差可能违反这种“能量”守恒。我们用相对能量偏差来量化这一点：\n$$\nE_{\\mathrm{energy}} = \\frac{\\left| \\left\\| \\mathcal{S} \\right\\|_F - \\left\\| \\mathcal{X} \\right\\|_F \\right|}{\\left\\| \\mathcal{X} \\right\\|_F}\n$$\n\n为减轻正交性的损失，应用了重新正交化过程。将每个计算出的因子矩阵$U^{(n)}$进行数值稳定的QR分解，$U^{(n)} = \\tilde{U}^{(n)}R^{(n)}$，其中$\\tilde{U}^{(n)}$是一个正交矩阵（在机器精度范围内），$R^{(n)}$是上三角矩阵。我们用新正交化的$\\tilde{U}^{(n)}$替换数值上有缺陷的$U^{(n)}$。使用这些新的因子矩阵，计算一个校正的核心张量$\\tilde{\\mathcal{S}}$：\n$$\n\\tilde{\\mathcal{S}} = \\mathcal{X} \\times_1 \\tilde{U}^{(1)\\top} \\times_2 \\tilde{U}^{(2)\\top} \\times_3 \\tilde{U}^{(3)\\top}\n$$\n然后使用$\\tilde{U}^{(n)}$和$\\tilde{\\mathcal{S}}$重新计算误差度量$E_{\\mathrm{orth}}$和$E_{\\mathrm{energy}}$，以评估此修正步骤的有效性。预期重新正交化将大大减少$E_{\\mathrm{orth}}$，而其对$E_{\\mathrm{energy}}$的影响将取决于原始SVD受病态条件扰动的程度。\n\n该实现将对每个指定的测试用例系统地执行这整个过程，涵盖从行为良好到严重病态的场景，并使用单精度和双精度浮点数来突出精度在数值稳定性中的作用。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the HOSVD sensitivity problem for a suite of test cases.\n    \"\"\"\n\n    def unfold(tensor, mode):\n        \"\"\"Unfolds a 3rd-order tensor into a matrix along a specified mode.\"\"\"\n        return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1))\n\n    def mode_n_product(tensor, matrix, mode):\n        \"\"\"Computes the mode-n product of a 3rd-order tensor and a matrix.\"\"\"\n        original_shape = tensor.shape\n        unfolded_tensor = unfold(tensor, mode)\n        \n        # Perform the matrix product\n        product = matrix @ unfolded_tensor\n        \n        # Fold the result back into a tensor\n        new_first_dim = matrix.shape[0]\n        new_shape_list = list(original_shape)\n        new_shape_list[mode] = new_first_dim\n        \n        other_dims = [d for i, d in enumerate(original_shape) if i != mode]\n        \n        # Reshape to have the new dimension first, then the other original dimensions\n        folded_product = np.reshape(product, [new_first_dim] + other_dims)\n        \n        # Move the new dimension back to its original mode position\n        return np.moveaxis(folded_product, 0, mode)\n\n    def generate_tensor(I, J, K, R, epsilon, scales, seed, dtype):\n        \"\"\"Generates a synthetic tensor with controlled properties.\"\"\"\n        rng = np.random.default_rng(seed)\n        \n        a_vecs, b_vecs, c_vecs = [], [], []\n\n        # r = 0\n        a0 = rng.standard_normal(I, dtype=dtype)\n        a0 /= np.linalg.norm(a0)\n        b0 = rng.standard_normal(J, dtype=dtype)\n        b0 /= np.linalg.norm(b0)\n        c0 = rng.standard_normal(K, dtype=dtype)\n        c0 /= np.linalg.norm(c0)\n        a_vecs.append(a0)\n        b_vecs.append(b0)\n        c_vecs.append(c0)\n\n        # r = 1 (if R > 1)\n        if R > 1:\n            delta_a = rng.standard_normal(I, dtype=dtype)\n            delta_b = rng.standard_normal(J, dtype=dtype)\n            delta_c = rng.standard_normal(K, dtype=dtype)\n            a1 = a0 + epsilon * delta_a\n            b1 = b0 + epsilon * delta_b\n            c1 = c0 + epsilon * delta_c\n            a_vecs.append(a1)\n            b_vecs.append(b1)\n            c_vecs.append(c1)\n\n        # r >= 2\n        for _ in range(2, R):\n            ar = rng.standard_normal(I, dtype=dtype)\n            ar /= np.linalg.norm(ar)\n            br = rng.standard_normal(J, dtype=dtype)\n            br /= np.linalg.norm(br)\n            cr = rng.standard_normal(K, dtype=dtype)\n            cr /= np.linalg.norm(cr)\n            a_vecs.append(ar)\n            b_vecs.append(br)\n            c_vecs.append(cr)\n            \n        X = np.zeros((I, J, K), dtype=dtype)\n        for r in range(R):\n            # Using einsum for outer product: a_r o b_r o c_r\n            rank_one_tensor = np.einsum('i,j,k->ijk', a_vecs[r], b_vecs[r], c_vecs[r])\n            X += scales[r] * rank_one_tensor\n            \n        return X.astype(dtype)\n\n    def calculate_errors(X, U_factors, S):\n        \"\"\"Calculates orthogonality and energy errors.\"\"\"\n        dtype = X.dtype\n        dims = X.shape\n        \n        # Orthogonality loss\n        orth_errors = []\n        for n in range(3):\n            U = U_factors[n]\n            Id = np.eye(dims[n], dtype=dtype)\n            err = np.linalg.norm(U.T @ U - Id, 'fro')\n            orth_errors.append(err)\n        E_orth = max(orth_errors)\n        \n        # Energy deviation\n        X_norm = np.linalg.norm(X)\n        S_norm = np.linalg.norm(S)\n        if X_norm == 0:\n             E_energy = 0.0 if S_norm == 0.0 else np.inf\n        else:\n             E_energy = np.abs(S_norm - X_norm) / X_norm\n             \n        return E_orth, E_energy\n\n    test_cases = [\n        (6, 5, 4, 3, 1e-3, [1.0, 0.1, 0.01], 0, 'single'),\n        (8, 8, 8, 3, 1e-6, [1e8, 1e-8, 1e4], 1, 'single'),\n        (3, 3, 3, 2, 1e-9, [1.0, 1e-12], 2, 'single'),\n        (6, 5, 4, 3, 1e-3, [1.0, 0.1, 0.01], 0, 'double'),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        I, J, K, R, epsilon, scales, seed, precision_str = case\n        dtype = np.float32 if precision_str == 'single' else np.float64\n        \n        X = generate_tensor(I, J, K, R, epsilon, np.array(scales, dtype=dtype), seed, dtype)\n        \n        # HOSVD\n        X1_unfold = unfold(X, 0)\n        X2_unfold = unfold(X, 1)\n        X3_unfold = unfold(X, 2)\n        \n        U1, _, _ = np.linalg.svd(X1_unfold, full_matrices=True)\n        U2, _, _ = np.linalg.svd(X2_unfold, full_matrices=True)\n        U3, _, _ = np.linalg.svd(X3_unfold, full_matrices=True)\n        \n        Us = [U1.astype(dtype), U2.astype(dtype), U3.astype(dtype)]\n        \n        # Core tensor\n        S = mode_n_product(X, Us[0].T, 0)\n        S = mode_n_product(S, Us[1].T, 1)\n        S = mode_n_product(S, Us[2].T, 2)\n        \n        # Errors before re-orthogonalization\n        E_orth, E_energy = calculate_errors(X, Us, S)\n        \n        # Re-orthogonalization via QR\n        U_tildes = []\n        for U in Us:\n            Q, _ = np.linalg.qr(U)\n            U_tildes.append(Q.astype(dtype))\n            \n        # Re-computed core tensor\n        S_tilde = mode_n_product(X, U_tildes[0].T, 0)\n        S_tilde = mode_n_product(S_tilde, U_tildes[1].T, 1)\n        S_tilde = mode_n_product(S_tilde, U_tildes[2].T, 2)\n        \n        # Errors after re-orthogonalization\n        E_orth_tilde, E_energy_tilde = calculate_errors(X, U_tildes, S_tilde)\n        \n        all_results.extend([E_orth, E_orth_tilde, E_energy, E_energy_tilde])\n\n    # Format output as a single comma-separated list in brackets\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n\n```"
        }
    ]
}