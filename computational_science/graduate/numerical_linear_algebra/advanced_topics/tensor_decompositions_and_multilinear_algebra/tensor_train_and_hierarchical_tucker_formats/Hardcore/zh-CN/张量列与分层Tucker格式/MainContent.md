## 引言
在[高维数据](@entry_id:138874)的时代，从科学计算到机器学习，许多前沿问题都以[高阶张量](@entry_id:200122)的形式自然出现。然而，直接处理这些张量会遭遇所谓的“维度灾难”——随着维度 $d$ 的增加，存储和计算成本按 $n^d$ 呈指数级增长，很快变得无法承受。幸运的是，现实世界中的高维数据和模型往往并非无结构，而是蕴含着深刻的内在规律，表现为某种形式的“低秩”特性。张量链（Tensor-Train, TT）和层级塔克（Hierarchical Tucker, HT）格式正是为利用这种低秩结构而设计的强大数学工具。

本文旨在系统性地介绍这两种核心的低秩[张量表示](@entry_id:180492)方法，揭示它们如何将看似棘手的高维问题转化为在低维[流形](@entry_id:153038)上的可计算任务。我们将不再局限于理论，而是将原理与应用紧密结合，为读者构建一个从数学基础到实践应用的完整知识框架。

在接下来的内容中，我们将分三步深入探索：
*   在 **“原理与机制”** 一章中，我们将从张量与矩阵的桥梁“[矩阵化](@entry_id:751739)”出发，严格定义 TT 和 HT 格式，探讨它们的存储复杂度、规范自由度以及格式之间的内在联系。
*   在 **“应用与[交叉](@entry_id:147634)学科联系”** 一章中，我们将展示这些格式如何在[求解高维偏微分方程](@entry_id:755056)、分析大规模线性系统、进行概率图[模型推断](@entry_id:636556)和完成[高维数据](@entry_id:138874)补全等任务中发挥关键作用。
*   最后，在 **“动手实践”** 部分，我们提供了一系列精选的练习，引导读者从理论和算法层面加深对模式排序优化、格式性能比较及数值稳定性等核心问题的理解。

现在，让我们从这两种表示方法最根本的数学原理开始。

## 原理与机制

在本章中，我们将深入探讨[张量分解](@entry_id:173366)领域中两种强大的表示方法——张量链（Tensor-Train, TT）和层级塔克（Hierarchical Tucker, HT）格式的数学原理与核心机制。这些方法旨在通过利用[高维数据](@entry_id:138874)中普遍存在的低秩结构，来有效表示和计算[高阶张量](@entry_id:200122)，从而克服所谓的“[维度灾难](@entry_id:143920)”。我们将从连接张量与矩阵的“[矩阵化](@entry_id:751739)”概念出发，逐步构建这两种格式的定义，并探讨它们的性质、存储复杂度和相互关系。

### [矩阵化](@entry_id:751739)：从张量到矩阵的桥梁

直接分析[高阶张量](@entry_id:200122)的[代数结构](@entry_id:137052)是相当困难的。一个核心的策略是将张量“展开”或“[矩阵化](@entry_id:751739)”（matricization），将其重塑为一个矩阵。一旦张量被表示为矩阵，我们就可以运用成熟的[矩阵论](@entry_id:184978)工具，如奇异值分解（SVD）和[矩阵秩](@entry_id:153017)，来分析其结构特性。

一个 $d$ 阶张量 $X \in \mathbb{R}^{n_1 \times \cdots \times n_d}$ 可以通过多种方式进行[矩阵化](@entry_id:751739)。最通用的方法是基于模（mode）索引集 $\{1, \ldots, d\}$ 的任意一个双切分（bipartition） $(S, S^c)$。我们可以将属于 $S$ 的模作为矩阵的行索引，将属于[补集](@entry_id:161099) $S^c$ 的模作为列索引，从而得到一个矩阵 $X_{(S)} \in \mathbb{R}^{(\prod_{i \in S} n_i) \times (\prod_{j \in S^c} n_j)}$。这个过程本质上是对张量元素的一个重新索引，它保持了元素的数值，因此也保持了张量的[弗罗贝尼乌斯范数](@entry_id:143384)（Frobenius norm），即 $\|X\|_{\mathrm{F}} = \|X_{(S)}\|_{\mathrm{F}}$。

这个[矩阵的秩](@entry_id:155507)，$\mathrm{rank}(X_{(S)})$，具有深刻的物理意义。它等于能够精确表示张量 $X$ 的、跨越切分 $(S, S^c)$ 的分离秩（separation rank）。具体而言，$\mathrm{rank}(X_{(S)})$ 是最小的整数 $r$，使得 $X$ 可以写成如下形式 ：
$$
X = \sum_{\ell=1}^{r} A_{\ell} \otimes B_{\ell}
$$
其中 $A_{\ell}$ 是仅依赖于 $S$ 中模的张量，而 $B_{\ell}$ 是仅依赖于 $S^c$ 中模的张量。这揭示了[矩阵秩](@entry_id:153017)直接量化了跨越模切分的相关性。如果 $\mathrm{rank}(X_{(S)})=1$，则张量 $X$ 可以完全分离为 $X = A \otimes B$，这意味着在 $S$ 和 $S^c$ 的模之间没有纠缠或相关性。

对矩阵 $X_{(S)}$ 进行[奇异值分解](@entry_id:138057)（SVD），$X_{(S)} = U \Sigma V^{\top}$，可以得到一组[奇异值](@entry_id:152907) $\{\sigma_i\}$。这些奇异值是衡量跨切分相关性强弱的定量指标。由于范数守恒，我们有 $\|X\|_{\mathrm{F}}^2 = \sum_i \sigma_i^2$，这意味着张量的总“能量”被分配到各个相互正交（不相关）的分量上 。这些[奇异值](@entry_id:152907)的大小谱（spectrum）对于近似一个张量至关重要：如果[奇异值](@entry_id:152907)迅速衰减，说明张量在该切分下具有低秩结构，可以用较小的秩 $r$ 来精确近似。值得注意的是，这些奇异值对于在集合 $S$ 或 $S^c$ 内部进行模的任意[置换](@entry_id:136432)是不变的，因为这种[置换](@entry_id:136432)仅仅对应于对 $X_{(S)}$ 的行或列进行[置换](@entry_id:136432)，这是一种[正交变换](@entry_id:155650)，不改变奇异值 。

对于一个固定的整数 $k$（$1 \le k  d$），一个特别重要的切分是连续切分 $(\{1,\dots,k\}, \{k+1,\dots,d\})$。对应的[矩阵化](@entry_id:751739)记为 $X^{\langle 1:k \rangle}$。它的秩 $r = \mathrm{rank}(X^{\langle 1:k \rangle})$ 是最小的整数，使得张量的任一元素可以表示为一个内部索引求和的形式 ：
$$
X(i_1, \dots, i_d) = \sum_{\alpha=1}^{r} G_1(i_1, \dots, i_k, \alpha) G_2(\alpha, i_{k+1}, \dots, i_d)
$$
其中 $G_1$ 和 $G_2$ 是由矩阵[因式分解](@entry_id:150389)的因子“重塑”而成的张量。这一思想是张量链分解的基础。

### 张量链 (TT) 分解

张量链（TT）格式正是基于上述对模索引进行一系列连续切分的思想构建的。它将一个 $d$ 阶[张量表示](@entry_id:180492)为 $d$ 个小张量（称为“核”）的链式乘积。

#### 定义与结构

一个 $d$ 阶张量 $X \in \mathbb{R}^{n_1 \times \cdots \times n_d}$ 的张量链（TT）分解由一组TT秩 $(r_0, r_1, \ldots, r_d)$ 和 $d$ 个三阶“核”张量 $G_k \in \mathbb{R}^{r_{k-1} \times n_k \times r_k}$ ($k=1, \ldots, d$) 定义。为了表示一个张量（而非张量算子），边界秩必须为1，即 $r_0 = r_d = 1$。

对于每个物理索引 $i_k \in \{1, \ldots, n_k\}$，我们可以从核 $G_k$ 中提取一个矩阵切片 $G_k(i_k) \in \mathbb{R}^{r_{k-1} \times r_k}$。张量 $X$ 的元素 $(i_1, \ldots, i_d)$ 通过以下有序的矩阵乘积链来重构 ：
$$
X(i_1, \dots, i_d) = G_1(i_1) G_2(i_2) \cdots G_d(i_d)
$$
由于 $G_1(i_1)$ 是一个 $1 \times r_1$ 的行向量，而 $G_d(i_d)$ 是一个 $r_{d-1} \times 1$ 的列向量，整个乘积的结果是一个 $1 \times 1$ 的矩阵，即一个标量。这个过程可以用索引符号更明确地表示为：
$$
X(i_1, \dots, i_d) = \sum_{\alpha_1=1}^{r_1} \cdots \sum_{\alpha_{d-1}=1}^{r_{d-1}} G_1(1, i_1, \alpha_1) G_2(\alpha_1, i_2, \alpha_2) \cdots G_d(\alpha_{d-1}, i_d, 1)
$$
这里的内部索引 $\alpha_k$ 被称为“虚拟”或“键合”索引，它们在相邻的核之间被缩并（contracted）。

#### TT秩

[TT分解](@entry_id:756213)的核心参数是TT秩 $r^{\mathrm{TT}}_k$。对于 $k \in \{1, \ldots, d-1\}$，第 $k$ 个TT秩被定义为对张量 $X$ 进行连续切分 $(\{1, \ldots, k\}, \{k+1, \ldots, d\})$ 后得到的矩阵 $X_{\{1,\dots,k\} | \{k+1,\dots,d\}}$ 的秩 ：
$$
r^{\mathrm{TT}}_k = \mathrm{rank}(X_{\{1,\dots,k\} | \{k+1,\dots,d\}})
$$
需要强调的是，TT秩与[塔克分解](@entry_id:182831)中的多线性秩（multilinear ranks）是不同的概念。多线性秩 $r_k^{\text{Tucker}}$ 定义为单模[矩阵化](@entry_id:751739) $X_{(k)}$ 的秩。一般而言，$r^{\mathrm{TT}}_k \neq r_k^{\text{Tucker}}$。然而，在两个极端情况下它们是相等的：$r^{\mathrm{TT}}_1 = r_1^{\text{Tucker}}$ 且 $r^{\mathrm{TT}}_{d-1} = r_d^{\text{Tucker}}$ 。

#### 存储复杂度

TT格式的主要优势在于其显著降低的存储需求。存储一个TT表示的总参数数量是所有核中元素数量的总和。第 $k$ 个核 $G_k$ 包含 $r_{k-1} n_k r_k$ 个参数。因此，总存储量为：
$$
S_{\mathrm{TT}} = \sum_{k=1}^{d} r_{k-1} n_k r_k
$$
考虑到边界条件 $r_0=r_d=1$，这个和可以写作 $n_1 r_1 + \sum_{k=2}^{d-1} r_{k-1} n_k r_k + n_d r_{d-1}$  。

为了更好地理解其伸缩性，我们考虑一个均匀的情形，即所有模的维度均为 $n_k = n$，所有内部TT秩均为 $r_k = r$ ($k=1,\dots,d-1$)。在这种情况下，总参数数量为 ：
$$
S_{\mathrm{uniform}} = nr + (d-2)nr^2 + nr = 2nr + (d-2)nr^2
$$
对于较大的 $d$ 和 $r>1$，其主要伸缩行为是 $O(dnr^2)$。与存储原始稠密张量所需的 $O(n^d)$ 参数相比，这是一个从指数依赖于维度 $d$ 到[线性依赖](@entry_id:185830)的巨大飞跃，前提是TT秩 $r$ 保持在一个适度的范围内。

#### 规范自由度

TT表示不是唯一的。对于任意 $k \in \{1, \ldots, d-1\}$ 和任意可逆矩阵 $Q_k \in \mathbb{R}^{r_k \times r_k}$，我们可以通过以下方式变换相邻的两个核：
$$
\widehat{G}_k(i_k) = G_k(i_k) Q_k, \qquad \widehat{G}_{k+1}(i_{k+1}) = Q_k^{-1} G_{k+1}(i_{k+1})
$$
而保持其他核不变。由于在计算张量元素时，矩阵乘积中会出现 $G_k(i_k) G_{k+1}(i_{k+1})$ 这一项，变换后它变为 $(\cdots G_k(i_k) Q_k)(Q_k^{-1} G_{k+1}(i_{k+1}) \cdots)$。根据矩阵乘法的结合律，中间的 $Q_k Q_k^{-1}$ 项会抵消为[单位矩阵](@entry_id:156724)，从而保持张量 $X$ 本身不变 。这种变换[不变性](@entry_id:140168)被称为**规范自由度**（gauge freedom）。

这种自由度意味着TT核的参数空间存在冗余。给定一组TT秩 $(r_1, \ldots, r_{d-1})$ 的所有张量构成一个代数簇，称为TT[流形](@entry_id:153038)。其维度（即真正的自由参数数量）是核的总参数数量减去[规范变换](@entry_id:176521)群的维度。每个可逆矩阵 $Q_k$ 提供了 $r_k^2$ 个自由度，因此总的自由参数数量为 ：
$$
N_{\text{free}} = \left(\sum_{k=1}^{d} r_{k-1} n_k r_k\right) - \left(\sum_{k=1}^{d-1} r_k^2\right)
$$
这个精确的计数对于高级算法设计和理论分析至关重要。

### 层级塔克 (HT) 格式

TT格式将张量的模按线性链条组织，而层级塔克（HT）格式则将此思想推广到任意的二叉树结构，从而能够更灵活地捕捉不同模之间的层级相关性。

#### 定义与结构

HT格式的定义基于一个**维度树** $\mathcal{T}$。这是一个根二叉树，其叶节点为模索引 $\{1\}, \{2\}, \ldots, \{d\}$，根节点为所有模的集合 $\{1, \ldots, d\}$。树中的每个内部节点 $t$ 都是其两个子节点 $t_\ell, t_r$ 的不交并，即 $t = t_\ell \cup t_r$ 且 $t_\ell \cap t_r = \emptyset$。

HT表示由两类张量构成 ：
1.  **叶矩阵 (Frames)**：每个叶节点 $\{i\}$ 对应一个矩阵 $U^{(i)} \in \mathbb{R}^{n_i \times r_i}$，其中 $r_i$ 是叶节点 $\{i\}$ 的层级秩。
2.  **转移张量 (Transfer Tensors)**：每个内部节点 $t$（设其子节点为 $t_1, t_2$）对应一个三阶张量 $B^{(t)} \in \mathbb{R}^{r_{t_1} \times r_{t_2} \times r_t}$，它将[子空间的基](@entry_id:160685)耦合成父节点的基。根节点的秩 $r_{\text{root}}$ 通常设为1。

HT格式的存储复杂度是所有叶矩阵和转移张量中参数数量的总和 ：
$$
S_{\mathrm{HT}} = \sum_{i=1}^{d} n_i r_i + \sum_{t \in \mathcal{I}} r_{t_1} r_{t_2} r_t
$$
其中 $\mathcal{I}$ 是所有内部节点的集合。

#### HT秩与嵌套[子空间](@entry_id:150286)条件

HT格式最核心和精妙之处在于其**嵌套[子空间](@entry_id:150286)条件**（nested subspace condition）。对于维度树中的每个节点 $t$，我们可以定义一个[矩阵化](@entry_id:751739) $X^{(t)}$，它将属于 $t$ 的模作为行，其余模作为列。该节点的层级秩 $r_t$ 定义为这个矩阵的秩，即 $r_t = \mathrm{rank}(X^{(t)})$。

一个秩为 $\mathbf{r} = \{r_t\}_{t \in \mathcal{T}}$ 的HT[流形](@entry_id:153038)中的张量 $X$ 必须满足以下条件：存在一个[子空间](@entry_id:150286)族 $\{U_t\}_{t \in \mathcal{T}}$，其中 $U_t \subseteq \mathbb{R}^{\prod_{i \in t} n_i}$ 且 $\dim(U_t) = r_t$，使得[矩阵化](@entry_id:751739) $X^{(t)}$ 的值域包含在 $U_t$ 中。最关键的是，这些[子空间](@entry_id:150286)必须满足嵌套关系 ：
$$
U_t \subseteq U_{t_\ell} \otimes U_{t_r}
$$
对于每个内部节点 $t$ 及其子节点 $t_\ell, t_r$。这个条件意味着父节点的基可以由其子[节点基](@entry_id:752522)的[张量积](@entry_id:140694)来表示，这正是层级压缩的来源。它也蕴含了秩的不等式 $r_t \le r_{t_\ell} r_{t_r}$。

### 格式之间的关系与比较

TT、HT和经典的[塔克分解](@entry_id:182831)之间存在着深刻的联系。HT格式提供了一个统一的框架。

- **TT作为HT的特例**：如果维度树 $\mathcal{T}$ 是一条“路径”或“毛毛虫”树（例如，节点 $\{1,2\}$ 的子节点是 $\{1\}$ 和 $\{2\}$，节点 $\{1,2,3\}$ 的子节点是 $\{1,2\}$ 和 $\{3\}$，依此类推），那么HT表示就退化为TT表示 。此时，HT的层级秩对应于TT秩，其存储公式也与TT格式的公式相符。

- **[塔克分解](@entry_id:182831)作为HT的特例**：如果维度树 $\mathcal{T}$ 是一个“星形”树，即根节点直接连接到所有 $d$ 个[叶节点](@entry_id:266134)，那么HT表示就退化为经典的[塔克分解](@entry_id:182831) 。在这种情况下，叶矩阵 $U^{(i)}$ 就是[塔克分解](@entry_id:182831)的因子矩阵，而根节点的转移张量 $B^{(\text{root})}$ 就是[塔克分解](@entry_id:182831)的[核心张量](@entry_id:747891) $G$。叶节点的层级秩 $r_i$ 恰好就是张量的多线性秩，即 $r_i = \mathrm{rank}(X_{(i)})$。

#### 秩的比较

不同格式的秩定义不同，它们之间存在不等式关系。例如，TT秩和多线性（塔克）秩之间的关系为 ：
$$
r^{\mathrm{TT}}_k \le \min\left(\prod_{i=1}^k r_i^{\text{Tucker}}, \prod_{i=k+1}^d r_i^{\text{Tucker}}\right)
$$
此外，TT秩对模的顺序非常敏感。改变模的顺序（例如，从 $1,2,\dots,d$ 变为 $2,1,\dots,d$）通常会得到一组完全不同的TT秩。相比之下，多线性秩的集合在模的任意[置换](@entry_id:136432)下保持不变（只是分量顺序改变）。这说明TT格式隐式地假设了模之间存在一种线性的、有序的相互作用结构。

#### 近似性质的比较

在低秩近似问题中，没有一种格式是普适最优的。最佳格式取决于待近似张量的内在相关性结构。考虑一个假设性的例子可以很好地说明这一点 。

假设我们有一个五阶张量 $\mathcal{X} \in \mathbb{R}^{40 \times 40 \times 40 \times 40 \times 40}$，其范数为 $\|\mathcal{X}\|_F=1$。我们有一个大约9000个参数的存储预算。
- **TT近似**：假设我们发现，对于TT格式的四个连续切分，将奇异值截断在第8个之后，每个切分的误差（被丢弃的[奇异值](@entry_id:152907)平方和）分别为 $0.001, 0.002, 0.002, 0.001$。选择TT秩全为8，即 $(r_1, r_2, r_3, r_4)=(8,8,8,8)$，其存储成本为 $40 \cdot 1 \cdot 8 + 3 \cdot (40 \cdot 8 \cdot 8) + 40 \cdot 8 \cdot 1 = 8320$，符合预算。通过TT-SVD算法，我们可以得到一个近似张量，其平方误差上界为所有截断误差之和，即 $0.001+0.002+0.002+0.001=0.006$。
- **塔克近似**：假设对于每个单模[矩阵化](@entry_id:751739) $X_{(k)}$，将其奇异值截断在第6个之后，误差均为 $0.12$。选择多线性秩全为6，即 $(\rho_1,\dots,\rho_5)=(6,6,6,6,6)$，其存储成本为 $6^5 + 5 \cdot (40 \cdot 6) = 8976$，也符合预算。然而，任何具有此多线性秩的塔克近似，其平方误差必然**不小于**所有单模截断误差中的最大值。这是因为近似张量在每个模上的展开秩不能超过6，因此其与原张量在每个模展开上的差异至少是该模的最佳低秩近似误差。所以，平方误差的下界是 $0.12$。

在这个例子中，对于相似的存储预算，TT近似可以达到远低于 $0.006$ 的误差，而任何塔克近似的误差都至少是 $0.12$。这清楚地表明，当张量的相关性结构与TT格式的线性链结构匹配时，TT可以比塔克格式更有效。反之，如果张量的相关性更“星形”或“全局”，则塔克格式可能更优。HT格式则通过其灵活的树状结构，为在这两种极端之间找到最佳表示提供了可能。