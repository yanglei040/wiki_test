{
    "hands_on_practices": [
        {
            "introduction": "第一个练习为理解左、右和分裂预处理之间的实践差异提供了概念基础。通过分析一个简单的 $2 \\times 2$ 系统 ，你将学习每种策略如何影响真实残差和迭代求解器监控的残差之间的关系，这对设定准确的停止准则具有直接影响。",
            "id": "3555570",
            "problem": "考虑线性系统 $A x = b$，其中\n$$\nA = \\begin{bmatrix}4  1 \\\\ 2  3\\end{bmatrix}, \\quad b = \\begin{bmatrix}1 \\\\ 1\\end{bmatrix},\n$$\n以及 $A$ 的经典三角分裂，将其分为对角、严格下三角和严格上三角部分，$A = D + L + U$，其中\n$$\nD = \\begin{bmatrix}4  0 \\\\ 0  3\\end{bmatrix}, \\quad L = \\begin{bmatrix}0  0 \\\\ 2  0\\end{bmatrix}, \\quad U = \\begin{bmatrix}0  1 \\\\ 0  0\\end{bmatrix}.\n$$\n定义分裂预条件子 $M_L = D + L = \\begin{bmatrix}4  0 \\\\ 2  3\\end{bmatrix}$ 和 $M_R = D + U = \\begin{bmatrix}4  1 \\\\ 0  3\\end{bmatrix}$。考虑针对 $A x = b$ 的三种预处理策略：\n(1) 使用 $M_L$ 进行左预处理，该策略使用系统 $M_L^{-1} A x = M_L^{-1} b$，\n(2) 使用 $M_R$ 进行右预处理，该策略使用系统 $A M_R^{-1} y = b$ 并令 $x = M_R^{-1} y$，\n(3) 分裂预处理，该策略使用系统 $M_L^{-1} A M_R^{-1} z = M_L^{-1} b$ 并令 $x = M_R^{-1} z$。\n\n令 $\\|\\cdot\\|_{\\infty}$ 表示向量无穷范数和诱导的矩阵无穷范数。假设在每种预处理方案中都运行一种 Krylov 子空间迭代法，例如通用最小残差 (GMRES) 方法。在左预处理和分裂预处理中，该方法内部监控的残差是预处理后系统的残差，而在右预处理中，它是相对于原始 $A x = b$ 系统的残差。考虑两个精度目标：\n(i) 绝对后向误差目标 $\\|r\\|_{\\infty} \\le \\tau$，其中 $\\tau = 10^{-6}$，$r = b - A x$ 是真实（未经预处理的）残差，\n以及\n(ii) 相对后向误差目标 $\\|r\\|_{\\infty} / \\|b\\|_{\\infty} \\le \\varepsilon$，其中 $\\varepsilon = 10^{-6}$。\n\n分析在每种策略中应如何选择内部监控残差的停止准则以实现这些目标，以及如何从预处理后的变量中正确恢复物理可行解 $x$。然后，选择下面所有对该测试问题和这些目标有效的陈述。\n\nA. 在使用 $M_R$ 进行右预处理时，该方法的残差等于真实残差 $r = b - A x$，因此要求内部监控的 $\\|r\\|_{\\infty} \\le 10^{-6}$ 可直接强制实现绝对目标；此外，通过 $x = M_R^{-1} y$ 恢复物理可行解。\n\nB. 在使用 $M_L$ 进行左预处理时，确保内部监控的预处理残差 $\\|\\hat{r}\\|_{\\infty} \\le 10^{-6}$（其中 $\\hat{r} = M_L^{-1}(b - A x)$）可以保证 $\\|r\\|_{\\infty} \\le 10^{-6}$，因此不需要进行缩放即可满足绝对目标。\n\nC. 在分裂预处理中，对于系统 $M_L^{-1} A M_R^{-1} z = M_L^{-1} b$，内部监控的残差是 $\\hat{r} = M_L^{-1}(b - A x)$，为确保 $\\|r\\|_{\\infty} \\le \\tau$，只需满足 $\\|\\hat{r}\\|_{\\infty} \\le \\tau / \\|M_L\\|_{\\infty}$ 即可；物理可行解通过 $x = M_R^{-1} z$ 恢复。\n\nD. 对于使用 $M_L$ 进行左预处理的相对后向误差目标 $\\|r\\|_{\\infty} / \\|b\\|_{\\infty} \\le \\varepsilon$，如果方法监控的是 $\\|\\hat{r}\\|_{\\infty} / \\|\\hat{b}\\|_{\\infty}$（其中 $\\hat{b} = M_L^{-1} b$），那么当 $\\|\\hat{r}\\|_{\\infty} / \\|\\hat{b}\\|_{\\infty} \\le \\varepsilon / \\kappa_{\\infty}(M_L)$ 时应停止迭代，其中 $\\kappa_{\\infty}(M_L) = \\|M_L\\|_{\\infty} \\|M_L^{-1}\\|_{\\infty}$；对于此测试问题，$\\kappa_{\\infty}(M_L) = 2.5$。\n\nE. 右预处理会破坏绝对后向误差的测量，因此在指定绝对残差容差时不能使用。\n\nF. 在分裂预处理中，物理可行解必须通过 $x = M_L^{-1} z$ 而非 $x = M_R^{-1} z$ 来恢复；这对于与所监控的残差保持一致性至关重要。\n\n选择所有正确选项。",
            "solution": "用户要求对一个关于求解线性系统的预处理迭代法的问题进行详细分析。主要任务是验证问题陈述的有效性，如果有效，则评估关于不同预处理策略的几个论断。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n\n问题提供了以下信息：\n- 线性系统为 $A x = b$。\n- 矩阵 $A$ 由 $A = \\begin{bmatrix}4  1 \\\\ 2  3\\end{bmatrix}$ 给出。\n- 向量 $b$ 由 $b = \\begin{bmatrix}1 \\\\ 1\\end{bmatrix}$ 给出。\n- $A$ 的三角分裂定义为 $A = D + L + U$，其中：\n  - $D = \\begin{bmatrix}4  0 \\\\ 0  3\\end{bmatrix}$ (对角部分)\n  - $L = \\begin{bmatrix}0  0 \\\\ 2  0\\end{bmatrix}$ (严格下三角部分)\n  - $U = \\begin{bmatrix}0  1 \\\\ 0  0\\end{bmatrix}$ (严格上三角部分)\n- 左预条件子为 $M_L = D + L = \\begin{bmatrix}4  0 \\\\ 2  3\\end{bmatrix}$。\n- 右预条件子为 $M_R = D + U = \\begin{bmatrix}4  1 \\\\ 0  3\\end{bmatrix}$。\n- 考虑了用于 Krylov 子空间方法的三种预处理策略：\n  1.  **左预处理**：求解 $M_L^{-1} A x = M_L^{-1} b$。内部监控的残差是此预处理系统的残差。\n  2.  **右预处理**：求解 $A M_R^{-1} y = b$ 并令 $x = M_R^{-1} y$。内部监控的残差是原始系统的残差 $r = b - A x$。\n  3.  **分裂预处理**：求解 $M_L^{-1} A M_R^{-1} z = M_L^{-1} b$ 并令 $x = M_R^{-1} z$。内部监控的残差是此预处理系统的残差。\n- 使用的范数是无穷范数 $\\|\\cdot\\|_{\\infty}$。\n- 真实（未经预处理的）残差定义为 $r = b - A x$。\n- 考虑了真实残差的两个精度目标：\n  - (i) 绝对后向误差：$\\|r\\|_{\\infty} \\le \\tau$，其中 $\\tau = 10^{-6}$。\n  - (ii) 相对后向误差：$\\|r\\|_{\\infty} / \\|b\\|_{\\infty} \\le \\varepsilon$，其中 $\\varepsilon = 10^{-6}$。\n\n**步骤2：使用提取的已知条件进行验证**\n\n根据验证标准对问题陈述进行分析。\n- **科学上成立**：该问题牢固地建立在数值线性代数的既有理论之上。左预处理、右预处理和分裂预处理是加速 Krylov 子空间方法（如 GMRES）的标准技术。真实残差和预处理残差的概念，以及范数和条件数，都是该领域的基础。\n- **适定性**：该问题是适定的。矩阵 $A$、$M_L$ 和 $M_R$ 都是非奇异的。所提问题是关于不同量之间的形式关系，这些关系在数学上是可推导的。可以进行唯一且有意义的分析。\n- **客观性**：问题以精确、客观、无歧义的数学语言陈述。所有术语均为标准术语或已明确定义。\n- **缺陷分析**：\n  1.  **科学/事实上的不健全**：无。矩阵分裂和定义都是正确的。\n  2.  **非形式化/不相关**：问题是直接可形式化的，并且是预处理主题的核心。\n  3.  **不完整/矛盾的设置**：设置是完整的且内部一致。它提供了所有必要的矩阵、定义和目标。\n  4.  **不现实/不可行**：问题使用了一个简单的 $2 \\times 2$ 系统，这是说明理论概念的常用且有效的方法。\n  5.  **不适定/结构不良**：结构清晰且合乎逻辑，导向一个明确的分析任务。\n  6.  **伪深刻/琐碎**：该问题需要仔细应用范数不等式和预处理的定义，测试的是概念性理解，而非琐碎问题。\n  7.  **超出科学可验证性**：所有论断在数学上都是可验证的。\n\n**步骤3：结论与行动**\n\n问题陈述是**有效的**。可以进行分析。\n\n### 推导与选项分析\n\n令 $x_k$ 为解的第 $k$ 次迭代。真实残差为 $r_k = b - A x_k$。我们分析每种策略下真实残差与监控残差之间的关系。\n\n**策略1：左预处理**\n求解的系统是 $(M_L^{-1} A) x = M_L^{-1} b$。\n迭代方法生成迭代序列 $x_k$ 和相应的监控（预处理）残差\n$$\n\\hat{r}_k = (M_L^{-1} b) - (M_L^{-1} A) x_k = M_L^{-1} (b - A x_k) = M_L^{-1} r_k.\n$$\n由此关系，我们得到 $r_k = M_L \\hat{r}_k$。应用范数，我们得到以下界限：\n$$\n\\|r_k\\|_{\\infty} = \\|M_L \\hat{r}_k\\|_{\\infty} \\le \\|M_L\\|_{\\infty} \\|\\hat{r}_k\\|_{\\infty}\n$$\n以及\n$$\n\\|\\hat{r}_k\\|_{\\infty} = \\|M_L^{-1} r_k\\|_{\\infty} \\le \\|M_L^{-1}\\|_{\\infty} \\|r_k\\|_{\\infty}.\n$$\n\n**策略2：右预处理**\n求解的系统是 $(A M_R^{-1}) y = b$。迭代方法生成迭代序列 $y_k$。物理可行解的迭代为 $x_k = M_R^{-1} y_k$。\n问题陈述指出，监控的残差是原始系统的残差。我们来验证这一点是否一致。变换后系统的残差是 $b - (A M_R^{-1}) y_k$。\n代入 $y_k = M_R x_k$，这变成 $b - (A M_R^{-1}) (M_R x_k) = b - A x_k = r_k$。\n因此，监控的残差确实是真实残差，$\\hat{r}_k = r_k$。这是右预处理的一个关键优势。解通过 $x = M_R^{-1} y$ 恢复。\n\n**策略3：分裂预处理**\n求解的系统是 $(M_L^{-1} A M_R^{-1}) z = M_L^{-1} b$。迭代方法生成迭代序列 $z_k$。物理可行解通过令 $x_k = M_R^{-1} z_k$ 恢复。\n预处理残差为\n$$\n\\hat{r}_k = (M_L^{-1} b) - (M_L^{-1} A M_R^{-1}) z_k = M_L^{-1} (b - A (M_R^{-1} z_k)).\n$$\n代入 $x_k = M_R^{-1} z_k$，我们得到\n$$\n\\hat{r}_k = M_L^{-1} (b - A x_k) = M_L^{-1} r_k.\n$$\n这与左预处理中的关系相同：$r_k = M_L \\hat{r}_k$。\n\n在建立了这些原则之后，我们评估每个选项。\n\n**A. 在使用 $M_R$ 进行右预处理时，该方法的残差等于真实残差 $r = b - A x$，因此要求内部监控的 $\\|r\\|_{\\infty} \\le 10^{-6}$ 可直接强制实现绝对目标；此外，通过 $x = M_R^{-1} y$ 恢复物理可行解。**\n我们对右预处理的分析表明，监控的残差与真实残差相同，即 $r = b - A x$。因此，基于监控残差的停止准则 $\\|\\hat{r}\\|_{\\infty} \\le \\tau$ 直接强制了对真实残差的目标 $\\|r\\|_{\\infty} \\le \\tau$。变量变换被正确地陈述为 $x = M_R^{-1} y$。该陈述完全准确。\n**结论：正确。**\n\n**B. 在使用 $M_L$ 进行左预处理时，确保内部监控的预处理残差 $\\|\\hat{r}\\|_{\\infty} \\le 10^{-6}$（其中 $\\hat{r} = M_L^{-1}(b - A x)$）可以保证 $\\|r\\|_{\\infty} \\le 10^{-6}$，因此不需要进行缩放即可满足绝对目标。**\n真实残差和预处理残差之间的关系是 $r = M_L \\hat{r}$。取范数，$\\|r\\|_{\\infty} \\le \\|M_L\\|_{\\infty} \\|\\hat{r}\\|_{\\infty}$。该陈述意味着 $\\|M_L\\|_{\\infty} \\le 1$。我们来计算 $\\|M_L\\|_{\\infty}$。\n$$\nM_L = \\begin{bmatrix}4  0 \\\\ 2  3\\end{bmatrix}\n$$\n矩阵的无穷范数是最大绝对行和。\n- 第1行和：$|4| + |0| = 4$。\n- 第2行和：$|2| + |3| = 5$。\n因此，$\\|M_L\\|_{\\infty} = 5$。由于 $\\|M_L\\|_{\\infty} > 1$，条件 $\\|\\hat{r}\\|_{\\infty} \\le 10^{-6}$ 仅能保证 $\\|r\\|_{\\infty} \\le 5 \\times 10^{-6}$。它不能保证 $\\|r\\|_{\\infty} \\le 10^{-6}$。实际上，真实残差可能大于监控残差。因此需要进行缩放。\n**结论：不正确。**\n\n**C. 在分裂预处理中，对于系统 $M_L^{-1} A M_R^{-1} z = M_L^{-1} b$，内部监控的残差是 $\\hat{r} = M_L^{-1}(b - A x)$，为确保 $\\|r\\|_{\\infty} \\le \\tau$，只需满足 $\\|\\hat{r}\\|_{\\infty} \\le \\tau / \\|M_L\\|_{\\infty}$ 即可；物理可行解通过 $x = M_R^{-1} z$ 恢复。**\n这个陈述有三个部分。\n1.  **物理可行解恢复**：求解的系统是 $A'z = b'$，其中 $A' = M_L^{-1} A M_R^{-1}$ 且 $b' = M_L^{-1} b$。左乘 $M_L$ 得到 $A M_R^{-1} z = b$。与原始系统 $Ax=b$ 比较，我们发现 $x=M_R^{-1}z$。这是正确的。\n2.  **监控残差**：如前面对分裂预处理的推导，监控的残差 $\\hat{r}$（对于以 $z$ 为变量的系统）与真实残差 $r = b - Ax$ 的关系为 $\\hat{r} = M_L^{-1} r$。该陈述将其表述为 $\\hat{r} = M_L^{-1}(b-Ax)$，这是正确的。\n3.  **停止准则**：由 $r = M_L \\hat{r}$，我们有 $\\|r\\|_{\\infty} = \\|M_L \\hat{r}\\|_{\\infty} \\le \\|M_L\\|_{\\infty} \\|\\hat{r}\\|_{\\infty}$。为确保 $\\|r\\|_{\\infty} \\le \\tau$，强制 $\\|M_L\\|_{\\infty} \\|\\hat{r}\\|_{\\infty} \\le \\tau$ 是充分的，这可以重新排列为 $\\|\\hat{r}\\|_{\\infty} \\le \\tau / \\|M_L\\|_{\\infty}$。这部分也是正确的。\n陈述的所有部分都正确。\n**结论：正确。**\n\n**D. 对于使用 $M_L$ 进行左预处理的相对后向误差目标 $\\|r\\|_{\\infty} / \\|b\\|_{\\infty} \\le \\varepsilon$，如果方法监控的是 $\\|\\hat{r}\\|_{\\infty} / \\|\\hat{b}\\|_{\\infty}$（其中 $\\hat{b} = M_L^{-1} b$），那么当 $\\|\\hat{r}\\|_{\\infty} / \\|\\hat{b}\\|_{\\infty} \\le \\varepsilon / \\kappa_{\\infty}(M_L)$ 时应停止迭代，其中 $\\kappa_{\\infty}(M_L) = \\|M_L\\|_{\\infty} \\|M_L^{-1}\\|_{\\infty}$；对于此测试问题，$\\kappa_{\\infty}(M_L) = 2.5$。**\n让我们分析相对误差的传播。真实的相对残差是 $\\|r\\|_{\\infty} / \\|b\\|_{\\infty}$。监控的相对残差是 $\\|\\hat{r}\\|_{\\infty} / \\|\\hat{b}\\|_{\\infty}$。\n我们有关系式 $r = M_L \\hat{r}$ 和 $b = M_L \\hat{b}$。由此我们得到不等式：\n$\\|r\\|_{\\infty} \\le \\|M_L\\|_{\\infty} \\|\\hat{r}\\|_{\\infty}$\n$\\|\\hat{b}\\|_{\\infty} = \\|M_L^{-1} b\\|_{\\infty} \\le \\|M_L^{-1}\\|_{\\infty} \\|b\\|_{\\infty} \\implies \\|b\\|_{\\infty} \\ge \\frac{\\|\\hat{b}\\|_{\\infty}}{\\|M_L^{-1}\\|_{\\infty}}$。\n结合这些来界定真实的相对误差：\n$$\n\\frac{\\|r\\|_{\\infty}}{\\|b\\|_{\\infty}} \\le \\frac{\\|M_L\\|_{\\infty} \\|\\hat{r}\\|_{\\infty}}{\\|\\hat{b}\\|_{\\infty} / \\|M_L^{-1}\\|_{\\infty}} = \\left(\\|M_L\\|_{\\infty} \\|M_L^{-1}\\|_{\\infty}\\right) \\frac{\\|\\hat{r}\\|_{\\infty}}{\\|\\hat{b}\\|_{\\infty}} = \\kappa_{\\infty}(M_L) \\frac{\\|\\hat{r}\\|_{\\infty}}{\\|\\hat{b}\\|_{\\infty}}.\n$$\n为保证 $\\|r\\|_{\\infty} / \\|b\\|_{\\infty} \\le \\varepsilon$，要求 $\\kappa_{\\infty}(M_L) \\frac{\\|\\hat{r}\\|_{\\infty}}{\\|\\hat{b}\\|_{\\infty}} \\le \\varepsilon$ 是充分的，这意味着对监控的相对残差的停止准则应为 $\\frac{\\|\\hat{r}\\|_{\\infty}}{\\|\\hat{b}\\|_{\\infty}} \\le \\frac{\\varepsilon}{\\kappa_{\\infty}(M_L)}$。这个逻辑是正确的。\n现在，我们计算 $\\kappa_{\\infty}(M_L) = \\|M_L\\|_{\\infty} \\|M_L^{-1}\\|_{\\infty}$。\n我们已经求得 $\\|M_L\\|_{\\infty} = 5$。我们需要 $M_L^{-1}$。\n行列式为 $\\det(M_L) = (4)(3) - (0)(2) = 12$。\n逆矩阵为 $M_L^{-1} = \\frac{1}{12}\\begin{bmatrix}3  0 \\\\ -2  4\\end{bmatrix} = \\begin{bmatrix}1/4  0 \\\\ -1/6  1/3\\end{bmatrix}$。\n逆矩阵的无穷范数是最大绝对行和：\n- 第1行和：$|1/4| + |0| = 1/4 = 0.25$。\n- 第2行和：$|-1/6| + |1/3| = 1/6 + 2/6 = 3/6 = 1/2 = 0.5$。\n所以，$\\|M_L^{-1}\\|_{\\infty} = 1/2$。\n条件数为 $\\kappa_{\\infty}(M_L) = \\|M_L\\|_{\\infty} \\|M_L^{-1}\\|_{\\infty} = 5 \\times (1/2) = 2.5$。\n计算值与陈述中给出的值相符。该陈述的两个部分都正确。\n**结论：正确。**\n\n**E. 右预处理会破坏绝对后向误差的测量，因此在指定绝对残差容差时不能使用。**\n这个陈述与事实恰好相反。如选项A的分析所确立，右预处理中监控的残差就是真实残差。它提供了对后向误差的直接、未受破坏的度量。在三种方法中，它是强制执行真实残差特定容差最可靠的方法。\n**结论：不正确。**\n\n**F. 在分裂预处理中，物理可行解必须通过 $x = M_L^{-1} z$ 而非 $x = M_R^{-1} z$ 来恢复；这对于与所监控的残差保持一致性至关重要。**\n如选项C的分析所推导，求解的系统是 $M_L^{-1} A M_R^{-1} z = M_L^{-1} b$。乘以 $M_L$ 得到 $A (M_R^{-1} z) = b$。与原始系统 $Ax=b$ 比较，正确的变换是 $x = M_R^{-1} z$。该陈述建议 $x = M_L^{-1} z$，这是不正确的。\n**结论：不正确。**",
            "answer": "$$\\boxed{ACD}$$"
        },
        {
            "introduction": "构建一个稳健的预条件子与选择正确的预处理策略同等重要。本练习  探讨了一个常见实际问题：不完全 LU (ILU) 分解在不进行主元选择时的失败。你将亲眼见证为何主元选择是必要的，并推导它对左、右预处理算子所产生的不同数学影响。",
            "id": "3555596",
            "problem": "设 $A \\in \\mathbb{R}^{3 \\times 3}$ 是稀疏矩阵\n$$\nA \\;=\\; \\begin{pmatrix}\n0  1  0 \\\\\n1  0  1 \\\\\n0  1  1\n\\end{pmatrix}.\n$$\n考虑在自然行序下，不进行主元选择，对矩阵 $A$ 执行零填充的不完全LU分解（记为 $\\mathrm{ILU}(0)$），使得不完全因子 $L$ 和 $U$ 分别继承 $A$ 的严格下三角部分和上三角部分的稀疏模式，其中 $L$ 是单位下三角矩阵。定义预处理矩阵 $M$ 为 $M = L U$。\n\n任务：\n1. 仅使用分解和主元选择的基本定义，论证在不进行主元选择的情况下，对 $A$ 进行的 $\\mathrm{ILU}(0)$ 过程是否能保持 $M$ 的非奇异性，并通过分析第一个主元来证明你的结论。\n2. 设 $P \\in \\mathbb{R}^{3 \\times 3}$ 是交换第一行和第二行的置换矩阵。对置换后的矩阵 $P A$ 执行 $\\mathrm{ILU}(0)$ 分解，并构造出满足上述相同稀疏性约束的显式 $L$ 和 $U$，使得 $P A = L U$。定义相应的预处理器 $M := L U$。\n3. 仅使用左预处理和右预处理的定义，分析此主元选择对预处理算子的影响。具体来说，定义左预处理算子 $T_{\\mathrm{left}} := M^{-1} A$ 和右预处理算子 $T_{\\mathrm{right}} := A M^{-1}$，并推导出它们用 $P$ 表示的精确形式。\n4. 计算左预处理算子 $T_{\\mathrm{left}}$ 的行列式。将你的最终答案表示为一个实数。不需要四舍五入。",
            "solution": "我们将按顺序完成所述的四个任务来解决这个问题。\n\n给定的稀疏矩阵是\n$$\nA \\;=\\; \\begin{pmatrix}\n0  1  0 \\\\\n1  0  1 \\\\\n0  1  1\n\\end{pmatrix} \\in \\mathbb{R}^{3 \\times 3}.\n$$\n\n任务1：分析在不进行主元选择的情况下对 $A$ 进行的 $\\mathrm{ILU}(0)$ 分解。\n\n$\\mathrm{ILU}(0)$ 分解构造了一个近似 $M=LU \\approx A$，其中 $L$ 是一个单位下三角矩阵，$U$ 是一个上三角矩阵。$L$ 的稀疏模式被约束为 $A$ 的严格下三角部分的稀疏模式，$U$ 的稀疏模式被约束为 $A$ 的上三角部分的稀疏模式。\n\n对于给定的矩阵 $A$，其严格下三角部分仅在位置 $(2,1)$ 有一个非零元素。其上三角部分（包括对角线）在 $(1,2)$、$(2,1)$、$(2,3)$ 和 $(3,3)$ 有非零元素。等一下，上三角部分当然在 $(1,1)$、$(1,2)$、$(1,3)$、$(2,2)$、$(2,3)$、$(3,3)$ 有元素。稀疏模式约束决定了 $L$ 和 $U$ 中哪些元素可以为非零。\n基于 $A$ 的稀疏性：\n$$\nA = \\begin{pmatrix}\nA_{11}  A_{12}  0 \\\\\nA_{21}  A_{22}  A_{23} \\\\\n0  A_{32}  A_{33}\n\\end{pmatrix}\n$$\n因子 $L$ 和 $U$ 必须具有以下形式：\n$$\nL = \\begin{pmatrix}\n1  0  0 \\\\\nl_{21}  1  0 \\\\\n0  l_{32}  1\n\\end{pmatrix}, \\quad\nU = \\begin{pmatrix}\nu_{11}  u_{12}  0 \\\\\n0  u_{22}  u_{23} \\\\\n0  0  u_{33}\n\\end{pmatrix}\n$$\nILU 分解过程是高斯消元法的一个变种。第一步涉及主元 $A_{11}$。为了计算因子的元素，我们通常会设置 $u_{11} = A_{11}$。在这个问题中，$A_{11} = 0$。\n\n计算不完全分解的算法需要计算乘数 $l_{21}$，即 $l_{21} = A_{21} / u_{11} = A_{21} / A_{11}$。由于 $A_{21}=1$ 且 $A_{11}=0$，这个计算会涉及除以零。因此，在不进行主元选择的情况下，对 $A$ 的 $\\mathrm{ILU}(0)$ 过程在第一步就失败了。\n\n如果分解可以继续进行，预处理器将是 $M = LU$。$M$ 的行列式是 $\\det(M) = \\det(L)\\det(U)$。由于 $L$ 是单位下三角矩阵，所以 $\\det(L)=1$。$U$ 的行列式是其对角元素的乘积，即 $\\det(U) = u_{11} u_{22} u_{33}$。如前所述，算法会设置 $u_{11} = A_{11} = 0$。因此，$\\det(U) = 0$，这意味着 $\\det(M) = 0$。\n奇异的预处理器 $M$ 在计算上是不可取的，因为其逆矩阵 $M^{-1}$ 不存在，这使得求解预处理后的系统变得不可能。\n任务1的结论：由于在位置 $(1,1)$ 处出现零主元，对 $A$ 进行的 $\\mathrm{ILU}(0)$ 过程（不进行主元选择）失败了。这一失败意味着无法形成一个非奇异的预处理器 $M$；如果形式上构造出来，它也将是奇异的，因为它的第一个对角元素 $u_{11}$ 将为零。\n\n任务2：对置换后的矩阵 $PA$ 进行 $\\mathrm{ILU}(0)$ 分解。\n\n交换第一行和第二行的置换矩阵 $P$ 是：\n$$\nP = \\begin{pmatrix}\n0  1  0 \\\\\n1  0  0 \\\\\n0  0  1\n\\end{pmatrix}.\n$$\n置换后的矩阵 $PA$ 是：\n$$\nPA = \\begin{pmatrix}\n0  1  0 \\\\\n1  0  0 \\\\\n0  0  1\n\\end{pmatrix}\n\\begin{pmatrix}\n0  1  0 \\\\\n1  0  1 \\\\\n0  1  1\n\\end{pmatrix} =\n\\begin{pmatrix}\n1  0  1 \\\\\n0  1  0 \\\\\n0  1  1\n\\end{pmatrix}.\n$$\n让我们将这个置换后的矩阵记为 $A' = PA$。我们对 $A'$ 执行 $\\mathrm{ILU}(0)$ 分解。$L$ 和 $U$ 的稀疏模式继承自 $A'$。\n矩阵 $A'$ 的严格下三角部分仅在位置 $(3,2)$ 有非零元素。其上三角部分在 $(1,1), (1,3), (2,2), (3,2), (3,3)$ 有非零元素。等一下，上三角部分是满足 $i \\leq j$ 的位置 $(i,j)$。非零元素位于 $(1,1), (1,3), (2,2), (3,3)$。此外，$A'_{32}=1$。\n因子 $L$ 和 $U$ 对于 $A'$ 将具有以下形式：\n$$\nL = \\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  l_{32}  1\n\\end{pmatrix}, \\quad\nU = \\begin{pmatrix}\nu_{11}  0  u_{13} \\\\\n0  u_{22}  0 \\\\\n0  0  u_{33}\n\\end{pmatrix}\n$$\n因为 $A'_{21}=0, A'_{31}=0, A'_{12}=0, A'_{23}=0$。\n$LU$ 的乘积是：\n$$\nLU = \\begin{pmatrix}\nu_{11}  0  u_{13} \\\\\n0  u_{22}  0 \\\\\n0  l_{32}u_{22}  u_{33}\n\\end{pmatrix}.\n$$\n我们将 $LU$ 的非零元素与 $A'$ 的相应元素相等：\n$$\n\\begin{pmatrix}\nu_{11}  0  u_{13} \\\\\n0  u_{22}  0 \\\\\n0  l_{32}u_{22}  u_{33}\n\\end{pmatrix} =\n\\begin{pmatrix}\n1  0  1 \\\\\n0  1  0 \\\\\n0  1  1\n\\end{pmatrix}.\n$$\n从这个等式中，我们找到系数：\n$u_{11} = 1$\n$u_{13} = 1$\n$u_{22} = 1$\n$l_{32}u_{22} = 1 \\implies l_{32}(1) = 1 \\implies l_{32} = 1$\n$u_{33} = 1$\n\n得到的因子是：\n$$\nL = \\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  1  1\n\\end{pmatrix}, \\quad\nU = \\begin{pmatrix}\n1  0  1 \\\\\n0  1  0 \\\\\n0  0  1\n\\end{pmatrix}.\n$$\n预处理器是 $M=LU$。我们来计算它：\n$$\nM = LU = \\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  1  1\n\\end{pmatrix}\n\\begin{pmatrix}\n1  0  1 \\\\\n0  1  0 \\\\\n0  0  1\n\\end{pmatrix} =\n\\begin{pmatrix}\n1  0  1 \\\\\n0  1  0 \\\\\n0  1  1\n\\end{pmatrix}.\n$$\n我们观察到 $M=PA$。在这种情况下，置换矩阵 $PA$ 的 $\\mathrm{ILU}(0)$ 分解是精确的。\n\n任务3：分析预处理算子。\n\n我们有预处理器 $M = LU = PA$。预处理算子是 $T_{\\mathrm{left}} = M^{-1}A$ 和 $T_{\\mathrm{right}} = AM^{-1}$。\n\n对于右预处理算子 $T_{\\mathrm{right}}$：\n我们代入 $M=PA$：\n$T_{\\mathrm{right}} = A M^{-1} = A (PA)^{-1}$。\n使用性质 $(XY)^{-1} = Y^{-1}X^{-1}$，我们得到：\n$T_{\\mathrm{right}} = A (A^{-1}P^{-1}) = (AA^{-1})P^{-1} = I P^{-1} = P^{-1}$。\n置换矩阵 $P$ 是一个对合矩阵，意味着 $P^2=I$，所以 $P^{-1}=P$。\n因此，右预处理算子恰好是置换矩阵 $P$：\n$T_{\\mathrm{right}} = P^{-1} = P$。\n\n对于左预处理算子 $T_{\\mathrm{left}}$：\n我们代入 $M=PA$：\n$T_{\\mathrm{left}} = M^{-1}A = (PA)^{-1}A$。\n再次使用 $(XY)^{-1} = Y^{-1}X^{-1}$：\n$T_{\\mathrm{left}} = (A^{-1}P^{-1})A = A^{-1}P^{-1}A$。\n使用 $P^{-1}=P$，我们有：\n$T_{\\mathrm{left}} = A^{-1}PA$。\n这表明左预处理算子 $T_{\\mathrm{left}}$ 是置换矩阵 $P$ 的一个相似变换。\n用 $P$（和 $A$）表示的精确形式是 $T_{\\mathrm{right}} = P^{-1}$ 和 $T_{\\mathrm{left}} = A^{-1}P^{-1}A$。\n\n任务4：计算左预处理算子 $T_{\\mathrm{left}}$ 的行列式。\n\n我们使用推导出的形式 $T_{\\mathrm{left}} = A^{-1}P^{-1}A$。矩阵乘积的行列式是它们行列式的乘积：\n$$\n\\det(T_{\\mathrm{left}}) = \\det(A^{-1}P^{-1}A) = \\det(A^{-1}) \\det(P^{-1}) \\det(A).\n$$\n由于 $\\det(A^{-1}) = 1/\\det(A)$ 且 $\\det(P^{-1}) = 1/\\det(P)$，我们有：\n$$\n\\det(T_{\\mathrm{left}}) = \\frac{1}{\\det(A)} \\frac{1}{\\det(P)} \\det(A) = \\frac{1}{\\det(P)}.\n$$\n或者，更简单地说，行列式在相似变换下是不变的：\n$$\n\\det(T_{\\mathrm{left}}) = \\det(A^{-1}(P^{-1})A) = \\det(P^{-1}).\n$$\n矩阵 $P$ 是通过交换单位矩阵 $I$ 的两行（第一行和第二行）得到的。一次行交换会使行列式变号。由于 $\\det(I)=1$，因此 $P$ 的行列式是：\n$$\n\\det(P) = -1.\n$$\n因此，$\\det(P^{-1}) = 1/\\det(P) = 1/(-1) = -1$。\n所以，左预处理算子的行列式是：\n$$\n\\det(T_{\\mathrm{left}}) = -1.\n$$\n这个结果与矩阵 $A$ 无关，只要 $A$ 是可逆的，而它确实是可逆的（$\\det(A) = 0(..) - 1(1-0) + 0(..) = -1 \\neq 0$）。",
            "answer": "$$\n\\boxed{-1}\n$$"
        },
        {
            "introduction": "从理论到实践的转换揭示了与有限精度算术相关的微妙挑战。这个高级练习  专注于左预处理，并要求你展示一个病态的预条件子 $M$ 在计算 $M^{-1}r_k$ 时如何导致精度损失。接着，你将实现一种补偿求和技术来维持真实残差的高精度估计，这是开发稳健数值软件的一项关键技能。",
            "id": "3555547",
            "problem": "考虑在有限精度算术下求解一个带有左预处理的线性系统 $A x = b$。在左预处理中，我们使用广义最小残差方法（GMRES）求解变换后的系统 $M^{-1} A x = M^{-1} b$，其中 GMRES 代表广义最小残差方法（Generalized Minimal Residual method）。Arnoldi 过程为由算子 $K = M^{-1} A$ 作用于预处理残差所生成的 Krylov 子空间构建一个标准正交基。在精确算术中，每次迭代 $k$ 都会最小化预处理残差的范数 $\\|M^{-1} r_k\\|_2$，并且 GMRES 算法通过一个源自 Arnoldi 关系式的小型最小二乘问题来追踪该量。然而，在有限精度算术中，当条件数 $\\kappa(M)$ 很大时，显式计算 $M^{-1} r_k$ 可能会遭受精度损失。\n\n您的任务分为三个部分：\n- 从第一性原理出发，使用作用于算子 $K = M^{-1} A$ 的 Arnoldi 过程和 Givens 旋转来实现左预处理 GMRES，以维持小型最小二乘问题的三角化。初始猜测必须为 $x_0 = 0$，因此 $r_0 = b$。在迭代 $k$ 时，从最小二乘结构中追踪 GMRES 内部对预处理残差范数 $\\|M^{-1} r_k\\|_2$ 的估计，而无需显式地构建 $M^{-1} r_k$。\n- 演示一个有限精度场景，其中显式计算的 $M^{-1} r_k$ 会损失精度。具体做法是，仅在形成残差时，以降低的精度模拟 $M^{-1}$ 的应用。特别地，在计算显式预处理残差范数时，使用单精度算术将 $M^{-1}$ 应用于 $r_k$，而 Arnoldi 过程和 GMRES 代数运算则在双精度下执行。通过计算显式单精度 $\\|M^{-1} r_k\\|_2$ 与 GMRES 追踪的 $\\|M^{-1} r_k\\|_2$ 之间的相对误差来量化这种差异。\n- 提出并实现一种对未预处理残差的补偿更新方法，该方法即使在 $\\kappa(M)$ 很大时也能保持对 $\\|r_k\\|_2$ 的精确追踪。使用基本恒等式 $r_{k+1} = r_k - A \\Delta x_k$，其中 $\\Delta x_k$ 是 GMRES 迭代在第 $k$ 次和第 $k+1$ 次迭代之间的变化量，并应用一种向量形式的补偿求和（Kahan 风格）逐分量地更新 $r_k$，以减少相消误差。通过比较补偿后的 $\\|r_k\\|_2$ 与直接重新计算的 $\\|b - A x_k\\|_2$ 来量化其准确性。\n\n从以下基本依据出发：\n- 残差的定义 $r_k = b - A x_k$。\n- 左预处理算子 $K = M^{-1} A$ 和预处理残差 $\\hat{r}_k = M^{-1} r_k$ 的定义。\n- $K$ 的 Arnoldi 过程关系式，它产生一个标准正交基和一个用于定义 GMRES 迭代的小型上 Hessenberg 线性系统。\n- 线性求解的标准后向误差分析，这意味着当在有限精度算术中应用 $M^{-1}$ 时，计算出的结果是扰动系统 $(M + \\Delta M) z = r_k + \\delta r$ 的精确解，其中相对扰动的大小与单位舍入误差和条件数 $\\kappa(M)$ 成比例。\n\n设计以下实验设置，以确保科学真实性，同时保持自洽性：\n- 将 $A \\in \\mathbb{R}^{n \\times n}$ 构造为 $A = Q^\\top D Q + \\gamma S$，其中 $Q$ 是通过对高斯随机矩阵进行瘦 QR 分解得到的标准正交矩阵， $D$ 是对角矩阵，其条目跨越适度范围以保持 $A$ 的良态， $S$ 是具有小条目的斜对称矩阵， $\\gamma$ 是一个引入轻度非正规性的小标量。\n- 将左预处理器 $M$ 构造为一个对角矩阵，其条目跨越预设范围，使得 $\\kappa(M)$ 取受控值（例如，$10^2$，$10^4$，$10^8$）。这能保持 $M$ 的可逆性，但允许在 $\\kappa(M)$ 增长时探究 $M^{-1} r_k$ 构建中的精度损失。\n- 使用 $x_0 = 0$ 和一个条目从正态分布中抽取的随机向量 $b$。所有量必须是无量纲的，并且所有范数必须是欧几里得范数 $\\|\\cdot\\|_2$。\n\n如下实现未预处理残差的补偿更新：\n- 维护一对向量 $(r^{\\mathrm{comp}}, c)$，其中 $r^{\\mathrm{comp}}$ 是补偿后的残差估计， $c$ 是一个初始为 $0$ 的补偿向量。\n- 在每次迭代中，当 GMRES 最小二乘解向量从 $y_{k-1}$ 变为 $y_k$ 时，使用当前用于算子 $K = M^{-1} A$ 的 Arnoldi 基 $V_k$ 计算 $\\Delta x_k = V_k (y_k - y_{k-1})$，并使用逐分量的补偿求和（Kahan 风格）更新 $r^{\\mathrm{comp}} \\leftarrow r^{\\mathrm{comp}} - A \\Delta x_k$ 以减轻相消。\n\n测试套件和输出规范：\n- 使用三个测试用例，参数为 $(n, \\kappa(M), k_{\\max})$：\n    1. 情况 A：$n = 40$，目标 $\\kappa(M) = 10^2$，$k_{\\max} = 20$。\n    2. 情况 B：$n = 40$，目标 $\\kappa(M) = 10^8$，$k_{\\max} = 20$。\n    3. 情况 C：$n = 40$，目标 $\\kappa(M) = 10^4$，$k_{\\max} = 30$。\n- 对于每种情况，运行左预处理 GMRES $k_{\\max}$ 次迭代，并产生两个浮点数：\n    1. 在最后一次迭代 $k$ 时，显式单精度预处理残差范数 $\\|M^{-1} r_k\\|_2$ 与 GMRES 追踪的预处理残差范数之间的相对误差： $$E_{\\mathrm{hat}} = \\frac{\\left|\\|M^{-1} r_k\\|_2^{\\mathrm{(single)}} - \\|M^{-1} r_k\\|_2^{\\mathrm{(GMRES)}}\\right|}{\\|M^{-1} r_k\\|_2^{\\mathrm{(GMRES)}}}.$$\n    2. 在最后一次迭代 $k$ 时，补偿后的未预处理残差范数与直接重新计算的残差范数之间的相对误差： $$E_{\\mathrm{comp}} = \\frac{\\left|\\|r_k^{\\mathrm{(comp)}}\\|_2 - \\|b - A x_k\\|_2\\right|}{\\|b - A x_k\\|_2}.$$\n- 您的程序应生成单行输出，其中包含一个逗号分隔的列表，该列表封装在方括号中，每个测试用例贡献一个包含两个浮点数的列表。例如，输出的形式应为 $$\\texttt{[[E1\\_hat,E1\\_comp],[E2\\_hat,E2\\_comp],[E3\\_hat,E3\\_comp]]}$$。不应打印任何额外文本。\n\n所有随机抽样必须使用固定的种子以确保可复现性。所有与显式残差形成和 Arnoldi 过程无关的计算都必须使用双精度。用于演示精度损失的 $M^{-1} r_k$ 的显式形成必须在单精度下执行。补偿更新必须通过逐分量补偿求和来实现，且不得使用任何外部高精度库。",
            "solution": "用户提供的问题经评估为**有效**的。这是一个在数值线性代数领域内结构良好、具有科学依据的问题，它要求在特定的有限精度算术条件下，实现并分析左预处理广义最小残差（GMRES）方法。该问题清晰、内部一致，并且需要基于已确立的数值原理进行非平凡的实现。\n\n### 基于原理的解决方案设计\n\n任务是使用左预处理 GMRES 求解线性系统 $A x = b$，其中系统被转换为 $M^{-1} A x = M^{-1} b$。该解决方案涉及三个主要部分：实现核心算法、演示特定的有限精度不稳定性，以及实现一种补偿求和技术以缓解相关的精度问题。\n\n#### 1. 带有 Arnoldi 和 Givens 旋转的左预处理 GMRES\n\nGMRES 方法从一个仿射子空间 $x_0 + \\mathcal{K}_k$ 中找到一个近似解 $x_k$，该解最小化残差的欧几里得范数。对于左预处理系统，算子是 $K = M^{-1} A$，初始残差是 $\\hat{r}_0 = M^{-1} r_0$。设初始猜测为 $x_0 = 0$，则有 $r_0 = b$，因此 $\\hat{r}_0 = M^{-1} b$。GMRES 最小化预处理残差的范数，即 $\\|M^{-1} r_k\\|_2 = \\|M^{-1}(b - A x_k)\\|_2$。\n\n该算法的核心是 Arnoldi 过程，它为 Krylov 子空间 $\\mathcal{K}_{k+1}(K, \\hat{r}_0) = \\text{span}\\{\\hat{r}_0, K\\hat{r}_0, \\dots, K^k \\hat{r}_0\\}$ 生成一个标准正交基 $V_{k+1} = [v_0, v_1, \\dots, v_k]$。该过程产生以下关系：\n$$\nA V_k = V_{k+1} \\bar{H}_k\n$$\n其中 $V_k = [v_0, \\dots, v_{k-1}]$，$V_{k+1} = [v_0, \\dots, v_k]$，$\\bar{H}_k$ 是一个 $(k+1) \\times k$ 的上 Hessenberg 矩阵。实现将使用修正的 Gram-Schmidt 过程，因其具有更优的数值稳定性。\n\nGMRES 迭代 $x_k$ 表示为 $x_k = x_0 + z_k = V_k y_k$，其中 $y_k$ 是一个系数向量。最小化问题变为：\n$$\n\\min_{y_k} \\| \\hat{r}_0 - K z_k \\|_2 = \\min_{y_k} \\| \\beta v_0 - K V_k y_k \\|_2 = \\min_{y_k} \\| \\beta v_0 - V_{k+1} \\bar{H}_k y_k \\|_2\n$$\n其中 $\\beta = \\|\\hat{r}_0\\|_2$ 且 $v_0 = \\hat{r}_0 / \\beta$。由于 $V_{k+1}$ 的列是标准正交的，这等价于求解小型最小二乘问题：\n$$\ny_k = \\arg\\min_{y \\in \\mathbb{R}^k} \\| \\beta e_1 - \\bar{H}_k y \\|_2\n$$\n其中 $e_1 = [1, 0, \\dots, 0]^\\top \\in \\mathbb{R}^{k+1}$。\n\n为了在每次迭代中高效地解决这个问题，我们应用一系列 Givens 旋转 $G_0, G_1, \\dots, G_{k-1}$ 将 $\\bar{H}_k$ 转换为一个上三角矩阵 $R_k$。令 $\\Omega_k = G_{k-1} \\dots G_0$。将 $\\Omega_k$ 应用于最小二乘问题得到：\n$$\n\\min_{y} \\| \\Omega_k (\\beta e_1) - \\Omega_k \\bar{H}_k y \\|_2 = \\min_{y} \\| g_k - \\begin{pmatrix} R_k \\\\ 0 \\end{pmatrix} y \\|_2\n$$\n通过求解三角系统 $R_k y_k = g_k(1:k)$ 可找到解 $y_k$。预处理残差的范数则直接由变换后的右侧向量的最后一个元素的大小给出，即 $\\|M^{-1} r_k\\|_2 = |g_k(k+1)|$。这是 GMRES 追踪的残差范数，其计算无需显式形成 $r_k$ 或 $M^{-1} r_k$。\n\n#### 2. 演示有限精度误差\n\n当预处理器 $M$ 是病态的（即 $\\kappa(M)$ 很大）时，在有限精度算术中显式计算 $\\hat{r}_k = M^{-1} r_k$ 可能会遭受严重的精度损失。对求解 $M z = r_k$ 的标准后向误差分析表明，计算出的解 $\\tilde{z}$ 满足 $(M + \\Delta M) \\tilde{z} = r_k$，其中 $\\|\\Delta M\\| / \\|M\\|$ 与机器精度 $\\epsilon_{\\text{mach}}$ 和 $\\kappa(M)$ 成正比。这意味着计算出的预处理残差可能与真实值相去甚远。\n\n为了演示这一点，我们将在双精度（$\\epsilon_{\\text{mach}} \\approx 10^{-16}$）下执行主要的 GMRES 算法，但当我们需要显式计算 $\\|M^{-1} r_k\\|_2$ 进行比较时，我们将模拟一个精度较低的计算。具体做法是，在执行表示 $M^{-1}$ 作用的除法之前，将未预处理的残差 $r_k$ 和 $M$ 的对角线元素转换为单精度（$\\epsilon_{\\text{mach}} \\approx 10^{-7}$）。然后，将得到的单精度范数 $\\|M^{-1} r_k\\|_2^{\\mathrm{(single)}}$ 与稳定、内部追踪的 GMRES 范数 $\\|M^{-1} r_k\\|_2^{\\mathrm{(GMRES)}}$进行比较。当 $\\kappa(M)$ 很大时，相对误差 $E_{\\mathrm{hat}}$ 预计会很大。\n\n#### 3. 补偿残差更新\n\n一个相关的精度问题是未预处理残差 $r_k$ 的更新。简单地将其更新为 $r_k \\leftarrow r_{k-1} - A \\Delta x_k$ 可能导致灾难性相消，因为对于收敛的方法，$A \\Delta x_k$ 将非常接近 $r_{k-1}$。该问题建议实现一种补偿求和方案，特别是 Kahan 算法的向量形式，来更新残差。\n\n我们维护残差 $r^{\\mathrm{comp}}$ 和一个补偿向量 $c$，两者都初始化为零（$r^{\\mathrm{comp}}$ 最初设置为 $b$）。在每次迭代 $k$ 中，我们首先计算解迭代的变化量 $\\Delta x_k = x_k - x_{k-1}$。更新项是 $u = -A \\Delta x_k$。补偿更新对每个向量分量逐个进行：\n1. $y_{\\text{kahan}} = u - c$\n2. $t = r^{\\mathrm{comp}} + y_{\\text{kahan}}$\n3. $c = (t - r^{\\mathrm{comp}}) - y_{\\text{kahan}}$\n4. $r^{\\mathrm{comp}} = t$\n\n此过程将在 $r^{\\mathrm{comp}}$ 和 $y_{\\text{kahan}}$ 相加期间丢失的低位比特存储到补偿向量 $c$ 中，并在下一次迭代中重新引入它们。这保持了计算出的 $r^{\\mathrm{comp}}$ 的高精度。该方法的准确性通过计算补偿残差的范数 $\\|r_k^{\\mathrm{(comp)}}\\|_2$ 与直接重新计算的残差范数 $\\|b - A x_k\\|_2$（作为高精度基准）之间的相对误差 $E_{\\mathrm{comp}}$ 来评估。\n\n具有受控矩阵结构（$A = Q^\\top D Q + \\gamma S$）和具有指定 $\\kappa(M)$ 的对角预处理器 $M$ 的实验设置为测试这些数值现象提供了一个科学上合理且可复现的环境。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import qr, solve_triangular\n\n# Fixed seed for reproducibility\nRNG = np.random.default_rng(12345)\n\ndef create_problem(n, kappa_M, gamma=1e-2):\n    \"\"\"\n    Constructs the matrix A, preconditioner M, and vector b for the test problem.\n    \"\"\"\n    # Use double precision for construction\n    Z = RNG.standard_normal((n, n), dtype=np.float64)\n    Q, _ = qr(Z, mode='economic')\n    Q = Q.astype(np.float64)\n\n    # D with moderate conditioning (kappa ~ 10)\n    d = np.logspace(0, 1, n, dtype=np.float64)\n    D = np.diag(d)\n\n    # Skew-symmetric S with small entries\n    S_rand = RNG.standard_normal((n, n), dtype=np.float64)\n    S = (S_rand - S_rand.T) / 2.0\n\n    A = Q.T @ D @ Q + gamma * S\n\n    # Diagonal preconditioner M with target condition number\n    m_diag = np.logspace(0, np.log10(kappa_M), n, dtype=np.float64)\n    M = np.diag(m_diag)\n\n    # Right-hand side vector b\n    b = RNG.standard_normal(n, dtype=np.float64)\n\n    return A, M, b\n\ndef kahan_sum(v_sum, v_add, c):\n    \"\"\"\n    Performs a component-wise Kahan summation for two vectors.\n    v_sum = v_sum + v_add\n    \"\"\"\n    y = v_add - c\n    t = v_sum + y\n    c = (t - v_sum) - y\n    v_sum = t\n    return v_sum, c\n\ndef left_gmres(A, M, b, k_max):\n    \"\"\"\n    Implements left-preconditioned GMRES with specified numerical analyses.\n    \"\"\"\n    n = A.shape[0]\n\n    # ---- Initialization ----\n    # x_0 = 0, so r_0 = b\n    r = b.copy()\n    \n    # Compensated residual initialization\n    r_comp = b.copy()\n    c_comp = np.zeros(n, dtype=np.float64)\n    \n    # Preconditioned residual r_hat_0 = M^{-1} r_0. Since M is diagonal, this is an element-wise division.\n    M_diag = np.diag(M)\n    M_inv_r = r / M_diag\n\n    beta = np.linalg.norm(M_inv_r)\n    \n    # Arnoldi basis V and Hessenberg H\n    V = np.zeros((n, k_max + 1), dtype=np.float64)\n    V[:, 0] = M_inv_r / beta\n    H = np.zeros((k_max + 1, k_max), dtype=np.float64)\n    \n    # Givens rotation data\n    cs = np.zeros(k_max, dtype=np.float64)\n    sn = np.zeros(k_max, dtype=np.float64)\n    \n    # RHS for least-squares problem, g\n    g = np.zeros(k_max + 1, dtype=np.float64)\n    g[0] = beta\n    \n    x_prev = np.zeros(n, dtype=np.float64)\n    \n    iterations_run = k_max\n\n    # ---- GMRES Iteration Loop ----\n    for k in range(k_max):\n        # -- Arnoldi Step --\n        # Form w = K * v_k = M^{-1} * A * v_k\n        v_k = V[:, k]\n        Av_k = A @ v_k\n        w = Av_k / M_diag\n\n        # Modified Gram-Schmidt orthogonalization\n        for j in range(k + 1):\n            h_jk = np.dot(V[:, j], w)\n            H[j, k] = h_jk\n            w -= h_jk * V[:, j]\n            \n        H[k + 1, k] = np.linalg.norm(w)\n        \n        # Check for lucky breakdown (exact solution found)\n        if H[k + 1, k]  1e-12:\n            iterations_run = k + 1\n            break\n            \n        V[:, k + 1] = w / H[k + 1, k]\n\n        # -- Update Least-Squares Problem via Givens Rotations --\n        # Apply previous k rotations to the new column of H\n        for j in range(k):\n            h_temp = cs[j] * H[j, k] + sn[j] * H[j + 1, k]\n            H[j + 1, k] = -sn[j] * H[j, k] + cs[j] * H[j + 1, k]\n            H[j, k] = h_temp\n            \n        # Generate and apply new rotation for the current column k\n        h_kk, h_kp1_k = H[k, k], H[k + 1, k]\n        rot_norm = np.sqrt(h_kk**2 + h_kp1_k**2)\n        cs[k] = h_kk / rot_norm\n        sn[k] = h_kp1_k / rot_norm\n        \n        H[k, k] = cs[k] * h_kk + sn[k] * h_kp1_k\n        H[k + 1, k] = 0.0\n        \n        # Apply the new rotation to the RHS vector g\n        g_k = g[k]\n        g[k] = cs[k] * g_k\n        g[k + 1] = -sn[k] * g_k\n\n        # -- Compensated Residual Update --\n        # 1. Solve the LS problem R_k * y_k = g_{1:k+1}\n        R_k = H[:k+1, :k+1]\n        g_sub = g[:k+1]\n        y_k = solve_triangular(R_k, g_sub, check_finite=False)\n        \n        # 2. Compute current solution x_k = V_{k+1} * y_k\n        x_curr = V[:, :k+1] @ y_k\n        \n        # 3. Compute change in solution\n        delta_x = x_curr - x_prev\n        \n        # 4. Update compensated residual using Kahan summation\n        update_term = - (A @ delta_x)\n        r_comp, c_comp = kahan_sum(r_comp, update_term, c_comp)\n        \n        # 5. Store current solution for the next iteration's delta\n        x_prev = x_curr\n\n    # ---- Final Calculations (after k_max or breakdown) ----\n    k_final = iterations_run\n    \n    # Final LS solution y and solution iterate x\n    R_final = H[:k_final, :k_final]\n    g_final = g[:k_final]\n    y_final = solve_triangular(R_final, g_final, check_finite=False)\n    x_final = V[:, :k_final] @ y_final\n\n    # -- Error E_hat: GMRES-tracked vs. explicit single-precision preconditioned residual norm --\n    # 1. GMRES-tracked preconditioned residual norm is |g_{k_final}|\n    norm_res_precond_gmres = abs(g[k_final])\n\n    # 2. Explicitly compute unpreconditioned residual r_k = b - A*x_k in double precision\n    r_final_explicit = b - (A @ x_final)\n    \n    # 3. Compute M^{-1}r_k in single precision to demonstrate error\n    r_final_explicit_sp = r_final_explicit.astype(np.float32)\n    M_diag_sp = M_diag.astype(np.float32)\n    M_inv_r_sp = r_final_explicit_sp / M_diag_sp\n    norm_res_precond_single = np.linalg.norm(M_inv_r_sp)\n    \n    # 4. E_hat relative error\n    E_hat = np.abs(norm_res_precond_single - norm_res_precond_gmres) / norm_res_precond_gmres\n    \n    # -- Error E_comp: Compensated vs. directly recomputed unpreconditioned residual norm --\n    # 1. Norm of the compensated residual\n    norm_r_comp = np.linalg.norm(r_comp)\n    \n    # 2. Norm of the directly recomputed residual (benchmark)\n    norm_r_recomputed = np.linalg.norm(r_final_explicit)\n    \n    # 3. E_comp relative error\n    # Avoid division by zero if residual is zero\n    if norm_r_recomputed  1e-15:\n        E_comp = np.abs(norm_r_comp - norm_r_recomputed)\n    else:    \n        E_comp = np.abs(norm_r_comp - norm_r_recomputed) / norm_r_recomputed\n    \n    return [E_hat, E_comp]\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    test_cases = [\n        (40, 1e2, 20),\n        (40, 1e8, 20),\n        (40, 1e4, 30),\n    ]\n\n    results = []\n    for n, kappa_M, k_max in test_cases:\n        A, M, b = create_problem(n, kappa_M)\n        case_results = left_gmres(A, M, b, k_max)\n        results.append(case_results)\n\n    # Format output as specified: [[E1_hat,E1_comp],[E2_hat,E2_comp],[E3_hat,E3_comp]]\n    # str() on a list gives '[v1, v2]', join with commas, then wrap in brackets.\n    # .replace(\" \", \"\") to remove spaces for exact output matching.\n    output_str = f\"[{','.join(map(str, results))}]\".replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n\n```"
        }
    ]
}