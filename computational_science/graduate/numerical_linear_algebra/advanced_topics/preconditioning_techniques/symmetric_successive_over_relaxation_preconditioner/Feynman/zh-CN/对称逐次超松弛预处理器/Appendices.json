{
    "hands_on_practices": [
        {
            "introduction": "选择一个合适的预处理器需要在多个因素之间进行权衡。这个练习将对称逐次超松弛（SSOR）预处理器与另一种常见方法——不完全Cholesky分解（IC(0)）——进行比较。通过分析它们的代数结构、计算成本和效率，你将学会如何在实际问题中根据矩阵的特性（如带宽）做出明智的选择。",
            "id": "3583768",
            "problem": "考虑一个实对称正定 (SPD) 矩阵 $A \\in \\mathbb{R}^{n \\times n}$，其带宽为 $p$，意味着在给定的自然排序下，当 $\\lvert i - j \\rvert > p$ 时 $a_{ij} = 0$。设标准分裂为 $A = D + L + L^{\\top}$，其中 $D$ 是对角矩阵，$L$ 是严格下三角矩阵。带有松弛因子 $\\omega \\in (0,2)$ 的对称逐次超松弛 (SSOR) 预条件子定义为\n$$\nM_{\\mathrm{SSOR}}(\\omega) = (D + \\omega L) D^{-1} (D + \\omega L^{\\top}),\n$$\n而零填充不完全 Cholesky 分解 (IC(0)) 产生一个下三角因子 $\\widetilde{L}$，它具有与 $L$ 相同的稀疏模式，使得预条件子为 $M_{\\mathrm{IC(0)}} = \\widetilde{L}\\,\\widetilde{L}^{\\top}$。该预条件子是通过执行 Cholesky 分解，同时丢弃超出 $A$ 的稀疏模式的任何填充得到的。\n\n选择关于以下两点的正确陈述：\n(i) $M_{\\mathrm{SSOR}}(\\omega)$ 和 $M_{\\mathrm{IC(0)}}$ 在何种稀疏模式下代数上相同，以及\n(ii) 在例如与预条件共轭梯度 (PCG) 方法一起使用时，SSOR 在设置成本与迭代次数减少方面占优的场景。\n\nA. 在下、上带宽均为 $p$ 的自然排序下，$M_{\\mathrm{SSOR}}(\\omega)$ 和 $M_{\\mathrm{IC(0)}}$ 代数上相同的充要条件是 $p = 0$ (等价于 $L = 0$)，此时两者均退化为对角矩阵 $D$。对于 $p \\ge 1$，它们是不同的。此外，对于具有强对角占优性和非常小带宽 $p$ 的带状 SPD 矩阵，SSOR 的设置成本可以忽略不计，其每次迭代的应用成本为 $\\mathcal{O}(n p)$，这使得当 IC(0) 分解成本 $\\mathcal{O}(n p^{2})$ 仅带来迭代次数的适度减少时，SSOR 更为可取；相反，对于更宽的带宽或较弱的对角占优性，IC(0) 通常能实现更大的迭代次数减少，从而证明其较高的设置成本是合理的。\n\nB. 对于自然排序下的三对角 ($p = 1$) SPD 矩阵，$M_{\\mathrm{SSOR}}(\\omega)$ 和 $M_{\\mathrm{IC(0)}}$ 在 $\\omega = 1$ 时代数上相同；此外，SSOR 通常比 IC(0) 产生更少的迭代次数，而设置成本相当。\n\nC. 对于任何带状 SPD 矩阵和任何保持带宽的排序，都存在 $\\omega \\in (0,2)$ 使得 $M_{\\mathrm{SSOR}}(\\omega) = M_{\\mathrm{IC(0)}}$；此外，随着 $p$ 的增加，SSOR 具有更高的设置成本，但比 IC(0) 产生更大的迭代次数减少。\n\nD. 如果 $A$ 的图是一条路径（三对角情况），则 SSOR 在对角缩放后与 IC(0) 重合；当 $\\omega$ 在接近 $2$ 的最优值下被选择时，SSOR 在设置和迭代减少两方面都占优。",
            "solution": "用户需要对问题陈述进行严格验证，然后是详细的解答和对给定选项的评估。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n- $A \\in \\mathbb{R}^{n \\times n}$ 是一个实对称正定 (SPD) 矩阵。\n- $A$ 的带宽为 $p$，意味着当 $|i - j| > p$ 时 $a_{ij} = 0$。\n- 标准分裂：$A = D + L + L^{\\top}$，其中 $D$ 是对角矩阵，$L$ 是严格下三角矩阵。\n- SSOR 预条件子：$M_{\\mathrm{SSOR}}(\\omega) = (D + \\omega L) D^{-1} (D + \\omega L^{\\top})$，松弛因子 $\\omega \\in (0,2)$。\n- IC(0) 预条件子：$M_{\\mathrm{IC(0)}} = \\widetilde{L}\\,\\widetilde{L}^{\\top}$，其中 $\\widetilde{L}$ 是一个下三角因子，其稀疏模式与 $A$ 的下三角部分（包括对角线）相同。它是通过 Cholesky 分解得到的，并在因子 $\\widetilde{L}$ 中丢弃了填充。\n\n**步骤 2：使用提取的已知条件进行验证**\n- **科学依据：** 该问题牢固地定位于数值线性代数这一成熟领域。SPD 矩阵、带宽、SSOR 预条件子和不完全 Cholesky 分解 (IC(0)) 的定义都是标准的。\n- **良定性：** 问题为比较对象（$M_{\\mathrm{SSOR}}(\\omega)$ 和 $M_{\\mathrm{IC(0)}}$）提供了清晰和标准的定义，并要求找出它们相同的条件以及比较它们的性能权衡。这是一个良定的问题。\n- **客观性：** 定义和问题都以精确、客观的数学语言陈述。\n- **结论：** 问题陈述没有科学缺陷、歧义或矛盾。这是一个有效且良定的问题。\n\n**步骤 3：判定与行动**\n问题是有效的。我将继续推导解答。\n\n### 解答推导\n\n问题要求分析两个方面：(i) $M_{\\mathrm{SSOR}}(\\omega)$ 和 $M_{\\mathrm{IC(0)}}$ 代数上恒等的条件，以及 (ii) 它们的设置成本与迭代减少性能的比较。\n\n#### (i) 代数恒等性：$M_{\\mathrm{SSOR}}(\\omega)$ vs. $M_{\\mathrm{IC(0)}}$\n\n首先，让我们展开 SSOR 预条件子的表达式：\n$$\nM_{\\mathrm{SSOR}}(\\omega) = (D + \\omega L) D^{-1} (D + \\omega L^{\\top}) = (I + \\omega L D^{-1}) (D + \\omega L^{\\top}) = D + \\omega L^{\\top} + \\omega L D^{-1} D + \\omega^2 L D^{-1} L^{\\top}\n$$\n由于 $D^{-1} D = I$，这可以简化为：\n$$\nM_{\\mathrm{SSOR}}(\\omega) = D + \\omega L + \\omega L^{\\top} + \\omega^2 L D^{-1} L^{\\top}\n$$\n\n接下来，我们分析 IC(0) 预条件子 $M_{\\mathrm{IC(0)}} = \\widetilde{L}\\,\\widetilde{L}^{\\top}$ 的结构。零填充不完全 Cholesky 分解算法 (IC(0)) 构建下三角因子 $\\widetilde{L}$，使其具有与 $A$ 的下三角部分相同的稀疏模式。由此产生的预条件子矩阵 $M_{\\mathrm{IC(0)}}$ 的一个关键性质是，它在矩阵 $A$ 的原始稀疏模式上与之匹配。也就是说，如果 $S = \\{(i,j) | a_{ij} \\neq 0\\}$，则对于所有 $(i,j) \\in S$，都有 $(M_{\\mathrm{IC(0)}})_{ij} = a_{ij}$。这可以直接从 IC(0) 算法的定义方程中证明。\n\n要使 $M_{\\mathrm{SSOR}}(\\omega)$ 和 $M_{\\mathrm{IC(0)}}$ 代数上相同，它们必须逐元素相等。一个必要条件是它们在 $A$ 的原始稀疏模式 $S$ 上一致。因此，对于所有 $(i,j) \\in S$，必须有 $(M_{\\mathrm{SSOR}}(\\omega))_{ij} = a_{ij}$。\n\n让我们检查对角元素 $(i,i) \\in S$ 的这个条件。$A$ 的对角元素是 $a_{ii} = d_{ii}$。\n$M_{\\mathrm{SSOR}}(\\omega)$ 的对角元素是：\n$$\n(M_{\\mathrm{SSOR}}(\\omega))_{ii} = d_{ii} + \\omega^2 (L D^{-1} L^{\\top})_{ii}\n$$\n条件 $(M_{\\mathrm{SSOR}}(\\omega))_{ii} = a_{ii} = d_{ii}$ 意味着：\n$$\n\\omega^2 (L D^{-1} L^{\\top})_{ii} = 0\n$$\n由于 $\\omega \\in (0,2)$，我们有 $\\omega \\neq 0$。因此，我们需要 $(L D^{-1} L^{\\top})_{ii} = 0$。该项由以下公式给出：\n$$\n(L D^{-1} L^{\\top})_{ii} = \\sum_{k=1}^{n} (L)_{ik} (D^{-1})_{kk} (L^{\\top})_{ki} = \\sum_{k=1}^{i-1} l_{ik} d_{kk}^{-1} l_{ik} = \\sum_{k=1}^{i-1} \\frac{l_{ik}^2}{d_{kk}}\n$$\n由于 $A$ 是 SPD 矩阵，其对角元素 $d_{kk} = a_{kk}$ 均为正数。和式 $\\sum_{k=1}^{i-1} l_{ik}^2/d_{kk}$ 是非负项之和。它为零的唯一可能是每一项都为零。这要求对于所有 $k < i$，$l_{ik}^2 = 0$。这个条件必须对每个 $i \\in \\{1, \\dots, n\\}$ 都成立。\n这意味着对于所有 $i \\neq j$，$l_{ij} = 0$，即严格下三角部分 $L$ 必须是零矩阵，$L=0$。\n如果 $L=0$，那么 $A=D$ 是一个对角矩阵，对应于带宽 $p=0$。\n\n让我们检查这个条件是否也是充分的。\n如果 $L=0$ ($p=0$)，则 $A=D$。\n- $M_{\\mathrm{SSOR}}(\\omega) = (D + 0) D^{-1} (D + 0) = D$。\n- 对于对角矩阵 $A=D$ 的 IC(0) 分解，因子 $\\widetilde{L}$ 也是对角矩阵，其元素为 $\\widetilde{l}_{ii} = \\sqrt{a_{ii}} = \\sqrt{d_{ii}}$。所以 $\\widetilde{L} = D^{1/2}$。预条件子是 $M_{\\mathrm{IC(0)}} = \\widetilde{L}\\widetilde{L}^{\\top} = D^{1/2} (D^{1/2})^{\\top} = D$。\n所以，如果 $p=0$，$M_{\\mathrm{SSOR}}(\\omega) = M_{\\mathrm{IC(0)}} = D$。\n\n因此，$M_{\\mathrm{SSOR}}(\\omega)$ 和 $M_{\\mathrm{IC(0)}}$ 代数上相同的充要条件是 $L=0$，这等价于 $p=0$。对于任何带宽 $p \\ge 1$ 的带状矩阵，它们是不同的。\n\n#### (ii) 设置成本与迭代减少\n\n让我们分析带宽为 $p$ 的带状矩阵的计算成本和有效性。\n\n**SSOR 预条件子：**\n- **设置成本：** 该预条件子需要矩阵 $D$ 和 $L$，它们可以从 $A$ 中提取而无需算术运算。成本由读取 $A$ 的非零元素决定，即 $\\mathcal{O}(nnz(A))$。对于一个带状矩阵，$nnz(A) \\approx n(2p+1)$，所以设置成本是 $\\mathcal{O}(np)$。\n- **应用成本：** 应用预条件子意味着求解 $M_{\\mathrm{SSOR}}(\\omega) z = r$。这涉及一次用 $(D + \\omega L)$ 的前向代入，一次用 $D^{-1}$ 的对角缩放，以及一次用 $(D + \\omega L^{\\top})$ 的反向代入。由于 $L$ 的带宽为 $p$，两次代入的成本都是 $\\mathcal{O}(np)$。每次迭代的总应用成本是 $\\mathcal{O}(np)$。\n\n**IC(0) 预条件子：**\n- **设置成本：** 这需要计算因子 $\\widetilde{L}$。对于元素 $\\widetilde{l}_{ij}$（其中 $a_{ij} \\neq 0$），该算法涉及两个长度最大为 $p$ 的向量的点积。计算第 $i$ 行大约需要计算 $p$ 个非零元素，每个元素需要高达 $\\mathcal{O}(p)$ 的工作量。对于所有 $n$ 行，总设置成本为 $\\mathcal{O}(np^2)$。\n- **应用成本：** 应用预条件子意味着求解 $M_{\\mathrm{IC(0)}} z = \\widetilde{L}\\widetilde{L}^{\\top}z = r$。这涉及一次用 $\\widetilde{L}$ 的前向代入和一次用 $\\widetilde{L}^{\\top}$ 的反向代入。由于 $\\widetilde{L}$ 与 $L$ 具有相同的稀疏模式（带宽为 $p$），每次求解的成本是 $\\mathcal{O}(np)$。每次迭代的总应用成本是 $\\mathcal{O}(np)$。\n\n**性能比较：**\n- IC(0) 的设置成本比 SSOR 高一个因子 $p$。对于 $p=1$，它们是可比的（$\\mathcal{O}(n)$），但对于更大的 $p$，差异是显著的。\n- 每次迭代的成本对于两者来说是渐近相同的，均为 $\\mathcal{O}(np)$。\n- 在质量方面，$M_{\\mathrm{IC(0)}}$ 通常是比 $M_{\\mathrm{SSOR}}(\\omega)$ 更好的 $A$ 的近似，这意味着预条件矩阵 $M_{\\mathrm{IC(0)}}^{-1}A$ 的条件数更接近于 1。这通常会导致像 PCG 这样的方法收敛所需的迭代次数大幅减少。\n- 它们之间的选择涉及一种权衡。对于 $p$ 很小和/或矩阵 $A$ 强对角占优的问题，两种预条件子都表现良好。如果迭代次数已经很少，或者 IC(0) 只能提供微小的改进，那么 SSOR 极低的设置成本使其具有吸引力。\n- 相反，对于带宽更宽（更大的 $p$）或对角占优性较弱的问题，预条件子的质量至关重要。IC(0) 实现的迭代次数的大幅减少，可以弥补其较高的 $\\mathcal{O}(np^2)$ 设置成本而有余，从而缩短总求解时间。\n\n### 选项评估\n\n**A. 在下、上带宽均为 $p$ 的自然排序下，$M_{\\mathrm{SSOR}}(\\omega)$ 和 $M_{\\mathrm{IC(0)}}$ 代数上相同的充要条件是 $p = 0$ (等价于 $L = 0$)，此时两者均退化为对角矩阵 $D$。对于 $p \\ge 1$ 它们是不同的。此外，对于具有强对角占优性和非常小带宽 $p$ 的带状 SPD 矩阵，SSOR 的设置成本可以忽略不计，其每次迭代的应用成本为 $\\mathcal{O}(n p)$，这使得当 IC(0) 分解成本 $\\mathcal{O}(n p^{2})$ 仅带来迭代次数的适度减少时，SSOR 更为可取；相反，对于更宽的带宽或较弱的对角占优性，IC(0) 通常能实现更大的迭代次数减少，从而证明其较高的设置成本是合理的。**\n- 该陈述与我们在 (i) 和 (ii) 部分的详细分析完全一致。恒等条件是正确的，权衡分析也是准确的。\n- **判定：正确。**\n\n**B. 对于自然排序下的三对角 ($p = 1$) SPD 矩阵，$M_{\\mathrm{SSOR}}(\\omega)$ 和 $M_{\\mathrm{IC(0)}}$ 在 $\\omega = 1$ 时代数上相同；此外，SSOR 通常比 IC(0) 产生更少的迭代次数，而设置成本相当。**\n- 对于 $p=1$，在 Cholesky 分解中不会发生填充，所以 $M_{\\mathrm{IC(0)}}=A$。对于 SSOR，$M_{\\mathrm{SSOR}}(1) = A + L D^{-1} L^{\\top}$。由于 $L \\neq 0$，项 $L D^{-1} L^\\top$ 是一个非零对角矩阵。因此，$M_{\\mathrm{SSOR}}(1) \\neq A = M_{\\mathrm{IC(0)}}$。第一个子句是错误的。由于 $M_{\\mathrm{IC(0)}}=A$，用它进行预处理将问题简化为 $A^{-1}Ax = A^{-1}b$，这在 PCG 中（在精确算术下）1 次迭代即可收敛。SSOR 将需要超过 1 次迭代。因此 SSOR 产生的迭代次数更多，而不是更少。第二个子句是错误的。\n- **判定：错误。**\n\n**C. 对于任何带状 SPD 矩阵和任何保持带宽的排序，都存在 $\\omega \\in (0,2)$ 使得 $M_{\\mathrm{SSOR}}(\\omega) = M_{\\mathrm{IC(0)}}$；此外，随着 $p$ 的增加，SSOR 具有更高的设置成本，但比 IC(0) 产生更大的迭代次数减少。**\n- 第一个子句是错误的。我们的推导表明，只有当 $L=0$ 时，才可能恒等，这与排序无关。\n- 第二个子句也是错误的。SSOR 的设置成本更低（$\\mathcal{O}(np)$ 对比 $\\mathcal{O}(np^2)$），而 IC(0) 通常产生更大的迭代次数减少。该陈述将两个比较都颠倒了。\n- **判定：错误。**\n\n**D. 如果 $A$ 的图是一条路径（三对角情况），则 SSOR 在对角缩放后与 IC(0) 重合；当 $\\omega$ 在接近 $2$ 的最优值下被选择时，SSOR 在设置和迭代减少两方面都占优。**\n- 对角缩放后重合对于任何三对角矩阵来说通常不成立，因为它对矩阵元素施加了通常不被满足的强约束。声称 SSOR 在设置成本上占优，对于 $p=1$ 是错误的，因为成本是可比的（$\\mathcal{O}(n)$）。声称它在迭代减少方面占优，对于任何 $p \\ge 1$ 都是错误的，因为 IC(0) 是一个更强大的预条件子。关于最优 $\\omega$ 接近 $2$ 的说法并非 SSOR 的普遍规律。\n- **判定：错误。**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "标准的SSOR预处理器在整个计算过程中使用一个固定的松弛因子 $\\omega$。然而，对于各向异性的问题，采用更灵活的策略可能更为有效。本练习将探讨一种可变松弛因子的SSOR变体，其中每一行都可以有自己的参数 $\\omega_{i}$，并通过分析一个简单的 $2 \\times 2$ 模型，让你亲手推导如何优化这些参数以改善预处理效果。",
            "id": "3583756",
            "problem": "设 $A \\in \\mathbb{R}^{n \\times n}$ 为对称正定矩阵 (SPD; symmetric positive definite)，其标准分裂为 $A = D - L - L^{\\top}$，其中 $D$ 是具有正对角元的对角矩阵，$L$ 是严格下三角矩阵。考虑可变松弛对称逐次超松弛 (SSOR; symmetric successive over-relaxation) 预条件子\n$$\nM \\;=\\; \\frac{1}{2 - \\bar{\\omega}} \\,\\bigl(D + \\Omega L\\bigr)\\,D^{-1}\\,\\bigl(D + \\Omega L\\bigr)^{\\top},\n$$\n其中 $\\Omega = \\operatorname{diag}(\\omega_{1},\\dots,\\omega_{n})$ 汇集了每行的松弛参数，$\\bar{\\omega}$ 是算术平均值 $\\bar{\\omega} = \\tfrac{1}{n}\\sum_{i=1}^{n} \\omega_{i}$。\n\n1. 从上述 $D$ 和 $L$ 的结构性质出发，推导关于 $\\bar{\\omega}$ 的必要和充分条件，以确保 $M$ 是对称正定矩阵。从第一性原理出发证明每一步，并且除了 $L$ 的严格下三角性和 $D$ 对角元的正性之外，不假设其他性质。\n\n2. 为了分析各向异性，使用 $2 \\times 2$ 模型\n$$\nA \\;=\\; \\begin{pmatrix} d_{1}  &-\\ell \\\\ -\\ell  &d_{2} \\end{pmatrix},\n$$\n其中 $d_{1} > 0$，$d_{2} > 0$ 且 $0 < \\ell^{2} < d_{1} d_{2}$。取相同的分裂 $D = \\operatorname{diag}(d_{1}, d_{2})$，$L = \\begin{pmatrix} 0  &0 \\\\ \\ell  &0 \\end{pmatrix}$，并选择 $\\Omega = \\operatorname{diag}(\\omega_{1}, \\omega_{2})$，其中 $\\bar{\\omega} = (\\omega_{1} + \\omega_{2})/2$。将预条件化算子 $M^{-1}A$ 的特征值表示为矩阵对 $(A, C)$（其中 $C = (D + \\Omega L)D^{-1}(D + \\Omega L)^{\\top}$）的广义特征值，并证明对于此模型，这些特征值是一个二次多项式的根，其系数取决于无量纲各向异性参数 $\\theta = \\ell^{2}/(d_{1} d_{2}) \\in (0,1)$ 和 $\\omega_{2}$。\n\n在容许范围 $0 \\le \\omega_{2} < 2$ 内，确定使 2-范数条件数 $\\kappa_{2}(M^{-1}A)$ 最小的 $\\omega_{2}$ 的选择，并给出所得的最小条件数，表示为关于 $\\theta$ 的闭式解析表达式。只需以该单个闭式表达式的形式提供您的最终答案。无需四舍五入。",
            "solution": "用户提供了一个分为两部分的问题，涉及可变松弛对称逐次超松弛 (SSOR) 预条件子的性质。\n\n### 第 1 部分：预条件子为对称正定 (SPD) 的条件\n\n问题将预条件子 $M$ 定义为\n$$\nM = \\frac{1}{2 - \\bar{\\omega}} (D + \\Omega L) D^{-1} (D + \\Omega L)^{\\top}\n$$\n其中 $A = D - L - L^{\\top}$ 是一个 SPD 矩阵，$D$ 是一个具有正对角元的对角矩阵，$L$ 是一个严格下三角矩阵，$\\Omega$ 是松弛参数 $\\omega_i$ 组成的对角矩阵，$\\bar{\\omega}$ 是 $\\omega_i$ 的算术平均值。我们需要找到使 $M$ 为 SPD 的关于 $\\bar{\\omega}$ 的必要和充分条件。\n\n一个矩阵是 SPD 的，如果它是对称的且其所有特征值均为正，或者等价地，如果它是对称的且对于任何非零向量 $\\mathbf{x} \\in \\mathbb{R}^n$，二次型 $\\mathbf{x}^{\\top} M \\mathbf{x}$ 为正。\n\n首先，我们来检验 $M$ 的对称性。设标量前置因子为 $k = \\frac{1}{2 - \\bar{\\omega}}$，矩阵部分为 $C = (D + \\Omega L) D^{-1} (D + \\Omega L)^{\\top}$。矩阵 $M$ 是对称的当且仅当 $C$ 是对称的。我们来计算 $C$ 的转置：\n$$\nC^{\\top} = \\left( (D + \\Omega L) D^{-1} (D + \\Omega L)^{\\top} \\right)^{\\top}\n$$\n使用性质 $(XYZ)^{\\top} = Z^{\\top}Y^{\\top}X^{\\top}$，我们得到\n$$\nC^{\\top} = \\left( (D + \\Omega L)^{\\top} \\right)^{\\top} (D^{-1})^{\\top} (D + \\Omega L)^{\\top} = (D + \\Omega L) (D^{-1})^{\\top} (D + \\Omega L)^{\\top}\n$$\n由于 $D$ 是一个对角矩阵，其逆 $D^{-1}$ 也是对角矩阵，因此是对称的，所以 $(D^{-1})^{\\top} = D^{-1}$。将其代回得到\n$$\nC^{\\top} = (D + \\Omega L) D^{-1} (D + \\Omega L)^{\\top} = C\n$$\n因此，矩阵 $C$ 是对称的，这意味着对于任何标量 $k$，$M = kC$ 也是对称的。\n\n接下来，我们确立 $M$ 为正定的条件。对于任何非零向量 $\\mathbf{x} \\in \\mathbb{R}^n$，我们考察二次型：\n$$\n\\mathbf{x}^{\\top} M \\mathbf{x} = \\mathbf{x}^{\\top} \\left( \\frac{1}{2 - \\bar{\\omega}} C \\right) \\mathbf{x} = \\frac{1}{2 - \\bar{\\omega}} \\mathbf{x}^{\\top} C \\mathbf{x}\n$$\n我们来分析 $\\mathbf{x}^{\\top} C \\mathbf{x}$ 这一项：\n$$\n\\mathbf{x}^{\\top} C \\mathbf{x} = \\mathbf{x}^{\\top} (D + \\Omega L) D^{-1} (D + \\Omega L)^{\\top} \\mathbf{x}\n$$\n让我们定义一个向量 $\\mathbf{y} = (D + \\Omega L)^{\\top} \\mathbf{x}$。二次型变为：\n$$\n\\mathbf{x}^{\\top} C \\mathbf{x} = \\mathbf{y}^{\\top} D^{-1} \\mathbf{y}\n$$\n问题陈述 $D$ 是一个具有正对角元的对角矩阵，$d_{ii} > 0$。这意味着 $D$ 是一个正定矩阵。因此，其逆 $D^{-1}$ 也是一个具有正对角元 $1/d_{ii} > 0$ 的对角矩阵，因此也是正定的。对于任何非零向量 $\\mathbf{y}$，我们必有 $\\mathbf{y}^{\\top} D^{-1} \\mathbf{y} > 0$。\n\n现在我们需要确保当 $\\mathbf{x}$ 非零时，$\\mathbf{y}$ 也非零。向量 $\\mathbf{y}$ 定义为 $\\mathbf{y} = (D + \\Omega L)^{\\top} \\mathbf{x}$。矩阵 $(D + \\Omega L)^{\\top}$ 是 $D^{\\top} + (\\Omega L)^{\\top} = D + L^{\\top}\\Omega^{\\top}$。由于 $D$ 和 $\\Omega$ 都是对角矩阵，它们是对称的（$D=D^\\top, \\Omega=\\Omega^\\top$），所以这是 $D + L^{\\top}\\Omega$。$D$ 是对角矩阵，$L$ 是严格下三角矩阵，这意味着 $L^{\\top}$ 是严格上三角矩阵。因此，矩阵 $D + L^{\\top}\\Omega$ 是一个上三角矩阵。它的对角元是 $D$ 的对角元，这些对角元都是正的。三角矩阵的行列式是其对角元的乘积，所以 $\\det(D + L^{\\top}\\Omega) = \\prod_{i=1}^n d_{ii} > 0$。由于行列式非零，该矩阵是可逆的。\n因此，如果 $\\mathbf{x} \\neq \\mathbf{0}$，那么 $\\mathbf{y} = (D + \\Omega L)^{\\top} \\mathbf{x} \\neq \\mathbf{0}$。\n\n这就证明了对于所有 $\\mathbf{x} \\neq \\mathbf{0}$，都有 $\\mathbf{y}^{\\top} D^{-1} \\mathbf{y} > 0$。因此，矩阵 $C$ 是正定的。\n\n由于 $M = \\frac{1}{2 - \\bar{\\omega}} C$ 且 $C$ 是正定的，所以 $M$ 的正定性仅取决于标量前置因子 $\\frac{1}{2 - \\bar{\\omega}}$ 的符号。为了使 $M$ 为正定，这个标量必须为正：\n$$\n\\frac{1}{2 - \\bar{\\omega}} > 0\n$$\n这个不等式成立当且仅当分母为正：\n$$\n2 - \\bar{\\omega} > 0 \\quad\\implies\\quad \\bar{\\omega} < 2\n$$\n这就是使 $M$ 为 SPD 的关于 $\\bar{\\omega}$ 的必要和充分条件。\n\n### 第 2 部分：2x2 模型的分析\n\n问题给出了 $2 \\times 2$ 矩阵 $A = \\begin{pmatrix} d_{1}  &-\\ell \\\\ -\\ell  &d_{2} \\end{pmatrix}$，其中 $d_{1} > 0$，$d_{2} > 0$ 且 $0 < \\ell^2 < d_{1} d_{2}$。分裂为 $D = \\operatorname{diag}(d_{1}, d_{2})$，$L = \\begin{pmatrix} 0  &0 \\\\ \\ell  &0 \\end{pmatrix}$。松弛矩阵为 $\\Omega = \\operatorname{diag}(\\omega_{1}, \\omega_{2})$。\n\n我们首先计算矩阵 $C = (D + \\Omega L)D^{-1}(D + \\Omega L)^{\\top}$。\n$$\nD + \\Omega L = \\begin{pmatrix} d_{1}  &0 \\\\ 0  &d_{2} \\end{pmatrix} + \\begin{pmatrix} \\omega_{1}  &0 \\\\ 0  &\\omega_{2} \\end{pmatrix} \\begin{pmatrix} 0  &0 \\\\ \\ell  &0 \\end{pmatrix} = \\begin{pmatrix} d_{1}  &0 \\\\ 0  &d_{2} \\end{pmatrix} + \\begin{pmatrix} 0  &0 \\\\ \\omega_{2}\\ell  &0 \\end{pmatrix} = \\begin{pmatrix} d_{1}  &0 \\\\ \\omega_{2}\\ell  &d_{2} \\end{pmatrix}\n$$\n注意这个矩阵不依赖于 $\\omega_1$。现在，我们计算 $C$：\n$$\n\\begin{align*} C = \\begin{pmatrix} d_{1}  &0 \\\\ \\omega_{2}\\ell  &d_{2} \\end{pmatrix} \\begin{pmatrix} 1/d_{1}  &0 \\\\ 0  &1/d_{2} \\end{pmatrix} \\begin{pmatrix} d_{1}  &\\omega_{2}\\ell \\\\ 0  &d_{2} \\end{pmatrix} \\\\ = \\begin{pmatrix} 1  &0 \\\\ \\omega_{2}\\ell/d_{1}  &1 \\end{pmatrix} \\begin{pmatrix} d_{1}  &\\omega_{2}\\ell \\\\ 0  &d_{2} \\end{pmatrix} \\\\ = \\begin{pmatrix} d_{1}  &\\omega_{2}\\ell \\\\ \\omega_{2}\\ell  &\\frac{(\\omega_{2}\\ell)^2}{d_{1}} + d_{2} \\end{pmatrix} = \\begin{pmatrix} d_{1}  &\\omega_{2}\\ell \\\\ \\omega_{2}\\ell  &d_{2}\\left(1 + \\frac{\\omega_{2}^2\\ell^2}{d_{1}d_{2}}\\right) \\end{pmatrix}\\end{align*}\n$$\n使用无量纲参数 $\\theta = \\ell^2 / (d_{1}d_{2})$，我们得到\n$$\nC = \\begin{pmatrix} d_{1}  &\\omega_{2}\\ell \\\\ \\omega_{2}\\ell  &d_{2}(1 + \\omega_{2}^2\\theta) \\end{pmatrix}\n$$\n预条件化算子 $M^{-1}A$ 的特征值为 $\\lambda$。特征值问题是 $A\\mathbf{x} = \\lambda M \\mathbf{x}$。代入 $M$ 的表达式，我们有 $A\\mathbf{x} = \\lambda \\frac{1}{2 - \\bar{\\omega}} C \\mathbf{x}$。这可以写成 $(2 - \\bar{\\omega}) A\\mathbf{x} = \\lambda C \\mathbf{x}$。矩阵对 $(A, C)$ 的广义特征值 $\\mu$ 是 $A\\mathbf{x} = \\mu C \\mathbf{x}$ 的解。因此，$M^{-1}A$ 的特征值为 $\\lambda = (2 - \\bar{\\omega})\\mu$。\n\n条件数 $\\kappa_{2}(M^{-1}A) = \\frac{\\lambda_{max}}{\\lambda_{min}} = \\frac{(2 - \\bar{\\omega})\\mu_{max}}{(2 - \\bar{\\omega})\\mu_{min}} = \\frac{\\mu_{max}}{\\mu_{min}}$，这正是 $(A, C)$ 的广义特征值问题的条件数。$\\mu$ 的特征多项式是 $\\det(A - \\mu C) = 0$。\n$$\n\\det\\left( \\begin{pmatrix} d_{1}  &-\\ell \\\\ -\\ell  &d_{2} \\end{pmatrix} - \\mu \\begin{pmatrix} d_{1}  &\\omega_{2}\\ell \\\\ \\omega_{2}\\ell  &d_{2}(1 + \\omega_{2}^2\\theta) \\end{pmatrix} \\right) = 0\n$$\n$$\n\\det\\begin{pmatrix} d_{1}(1-\\mu)  &-\\ell - \\mu\\omega_{2}\\ell \\\\ -\\ell - \\mu\\omega_{2}\\ell  &d_{2} - \\mu d_{2}(1 + \\omega_{2}^2\\theta) \\end{pmatrix} = 0\n$$\n$$\nd_{1}d_{2}(1-\\mu)(1 - \\mu(1 + \\omega_{2}^2\\theta)) - \\ell^2(1 + \\mu\\omega_{2})^2 = 0\n$$\n两边除以 $d_{1}d_{2}$ 并使用 $\\theta = \\ell^2/(d_{1}d_{2})$：\n$$\n(1-\\mu)(1 - \\mu - \\mu\\omega_{2}^2\\theta) - \\theta(1 + 2\\mu\\omega_{2} + \\mu^2\\omega_{2}^2) = 0\n$$\n展开并按 $\\mu$ 的幂次合并同类项：\n$$\n1 - \\mu - \\mu\\omega_{2}^2\\theta - \\mu + \\mu^2 + \\mu^2\\omega_{2}^2\\theta - \\theta - 2\\mu\\theta\\omega_{2} - \\mu^2\\theta\\omega_{2}^2 = 0\n$$\n$$\n\\mu^2(1 + \\omega_{2}^2\\theta - \\theta\\omega_{2}^2) - \\mu(2 + \\omega_{2}^2\\theta + 2\\theta\\omega_{2}) + (1-\\theta) = 0\n$$\n$$\n\\mu^2 - \\mu(2 + 2\\theta\\omega_{2} + \\theta\\omega_{2}^2) + (1-\\theta) = 0\n$$\n这就是广义特征值 $\\mu$ 的二次多项式。设其根为 $\\mu_{1}$ 和 $\\mu_{2}$。需要最小化的条件数是 $\\kappa = \\mu_{max}/\\mu_{min}$。\n从该多项式可知，根的和为 $S = \\mu_{1} + \\mu_{2} = 2 + 2\\theta\\omega_{2} + \\theta\\omega_{2}^2$，根的积为 $P = \\mu_{1}\\mu_{2} = 1-\\theta$。因为 $\\theta \\in (0,1)$，所以 $P > 0$。因为对于 $\\omega_2 \\ge 0$，$S > 0$，所以两个根都是正的。\n\n当两个根尽可能接近时，条件数 $\\kappa = \\mu_{max}/\\mu_{min}$ 最小。我们可以将 $\\kappa$ 表示为 $S$ 和 $P$ 的函数。设 $\\mu_{min}, \\mu_{max} = (S \\mp \\sqrt{S^2-4P})/2$。其比值为 $\\kappa = \\frac{S + \\sqrt{S^2-4P}}{S - \\sqrt{S^2-4P}}$。\n为了最小化 $\\kappa$（其中 $\\kappa \\ge 1$），我们需要最小化项 $S = S(\\omega_2)$，因为 $P$ 相对于 $\\omega_2$ 是常数。\n我们需要在区间 $0 \\le \\omega_2 < 2$ 上找到 $S(\\omega_2) = 2 + 2\\theta\\omega_{2} + \\theta\\omega_{2}^2$ 的最小值。\n为了找到最小值，我们计算关于 $\\omega_2$ 的导数：\n$$\n\\frac{dS}{d\\omega_2} = 2\\theta + 2\\theta\\omega_2 = 2\\theta(1+\\omega_2)\n$$\n鉴于 $\\theta \\in (0,1)$ 且 $\\omega_2 \\ge 0$，导数 $\\frac{dS}{d\\omega_2}$ 总是正的。这意味着 $S(\\omega_2)$ 在其定义域 $[0, 2)$ 上是关于 $\\omega_2$ 的严格增函数。因此，$S(\\omega_2)$ 的最小值在区间的下边界处取得，即在 $\\omega_2 = 0$ 处。\n\n为了找到最小条件数，我们在 $\\mu$ 的特征多项式中令 $\\omega_2 = 0$：\n$$\n\\mu^2 - 2\\mu + (1-\\theta) = 0\n$$\n使用二次公式，根为：\n$$\n\\mu = \\frac{2 \\pm \\sqrt{4 - 4(1-\\theta)}}{2} = 1 \\pm \\sqrt{1 - (1-\\theta)} = 1 \\pm \\sqrt{\\theta}\n$$\n所以，$\\mu_{max} = 1 + \\sqrt{\\theta}$ 且 $\\mu_{min} = 1 - \\sqrt{\\theta}$。\n最小条件数是这些特征值的比值：\n$$\n\\kappa_{min} = \\frac{\\mu_{max}}{\\mu_{min}} = \\frac{1 + \\sqrt{\\theta}}{1 - \\sqrt{\\theta}}\n$$",
            "answer": "$$\\boxed{\\frac{1 + \\sqrt{\\theta}}{1 - \\sqrt{\\theta}}}$$"
        },
        {
            "introduction": "理论知识的价值最终体现在解决实际问题的能力上。这个综合性练习将引导你完成从理论到实践的全过程：从第一性原理出发推导SSOR预处理器的代数形式，到编写代码在不同类型的典型问题上通过数值实验寻找最优的松弛因子 $\\omega$。通过这个练习，你将把理论推导、算法设计与诊断以及数值验证融会贯通。",
            "id": "3583782",
            "problem": "给定一个系数矩阵为 $A \\in \\mathbb{R}^{n \\times n}$ 的实对称正定线性系统。考虑矩阵分裂 $A = D + L + U$，其中 $D$ 是 $A$ 的对角部分，$L$ 是其严格下三角部分，$U$ 是其严格上三角部分。对称逐次超松弛（Symmetric Successive Over-Relaxation, SSOR）预条件子使用松弛参数 $\\omega \\in (0, 2)$，由一次前向和一次后向超松弛扫描复合而成。您的任务是推导出一个可用且可证明正确的 SSOR 预条件子的代数形式，建立其在迭代方法中安全使用所必需的性质，并实现实用的参数调优和诊断。\n\n仅从上述分裂和作为由 $\\omega$ 参数化的线性算子的前向与后向超松弛扫描的定义出发，执行以下操作：\n\n1) 推导出一个与一次前向和一次后向超松弛扫描相对应的左预处理矩阵 $M_{\\omega}$ 的代数形式（可相差一个任意正标量倍数）。证明对于任何对称正定矩阵 $A$ 和任意 $\\omega \\in (0, 2)$，矩阵 $M_{\\omega}$ 都是对称正定的。您的推导不得假设任何预先存在的 $M_{\\omega}$ 的封闭形式表达式；它必须从分裂算子的定义以及两次扫描的复合开始。\n\n2) 仅使用对称正定矩阵对和广义特征值的基本性质，证明在 $M_{\\omega}$-内积下的预处理算子的条件数等于 $M_{\\omega}^{-1} A$ 的谱条件数。证明将 $M_{\\omega}$ 乘以任何正标量都不会改变此条件数。由此得出结论：为了调优 $\\omega$，可以忽略 $M_{\\omega}$ 显式公式中的任何正标量因子。\n\n3) 提出一个不依赖于无法获取的问题常数的实用调优目标，并从第一性原理出发证明其合理性。然后，设计一个数值稳定的算法，对于给定的 $\\omega$，通过求解形如 $A x = \\lambda M_{\\omega} x$ 的对称广义特征值问题来计算谱条件数 $\\kappa(M_{\\omega}^{-1} A)$。您的算法应具体说明如何：\n- 从 $A$构造 $D$、$L$ 和 $U$。\n- 使用第 1 部分中选择的代数形式组装 $M_{\\omega}$。\n- 计算对称正定矩阵对 $(A, M_{\\omega})$ 的最小和最大广义特征值，以获得 $\\kappa(M_{\\omega}^{-1} A)$。\n- 通过将 $\\omega$ 限制在一个紧子区间 $[\\omega_{\\min}, \\omega_{\\max}] \\subset (0, 2)$ 内（带有小的安全裕量 $\\omega_{\\min} > 0$ 和 $\\omega_{\\max} < 2$）来防止端点不稳定性。\n- 验证诊断：$M_{\\omega}$ 是对称的（在数值容差范围内），并且是正定的（通过检查其最小特征值严格为正）。\n\n4) 将上述算法实现为一个完整的程序，该程序在 $\\omega \\in [\\omega_{\\min}, \\omega_{\\max}]$ 上执行网格搜索以最小化 $\\kappa(M_{\\omega}^{-1} A)$，并报告最佳的 $\\omega^{\\star}$ 和实现的条件数比率 $\\kappa(M_{\\omega^{\\star}}^{-1} A) / \\kappa(A)$。使用对称广义特征值问题计算 $\\kappa(M_{\\omega}^{-1} A)$，并使用标准对称特征值问题计算 $\\kappa(A)$。\n\n测试套件。您的程序必须对以下三个对称正定矩阵 $A$ 运行调优和诊断，涵盖一个一般情况、一个二维 stencil 情况和一个各向异性缩放情况：\n- 情况 $1$（理想情况）：$n=20$ 的一维泊松矩阵，即对角线上为 $2$，第一副对角线和超对角线上为 $-1$ 的三对角矩阵。\n- 情况 $2$（增加耦合）：$5 \\times 5$ 内部网格上的二维泊松矩阵（因此 $n=25$），采用标准五点 stencil、字典序排序和齐次狄利克雷边界条件。\n- 情况 $3$（显著各向异性缩放）：设 $n=30$，令 $K$ 为情况 $1$ 中的一维泊松矩阵，令 $S = \\mathrm{diag}(s_{1}, \\dots, s_{n})$，其中 $s_{i} = \\exp(\\alpha \\cdot (i-1)/(n-1))$ 且 $\\alpha = 3$。定义 $A = S K S$。\n\n对于所有情况，使用相同的调优网格，其中 $\\omega_{\\min} = 0.05$，$\\omega_{\\max} = 1.95$，以及均匀步长 $\\Delta\\omega = 0.01$。强制执行对称性诊断 $\\lVert M_{\\omega} - M_{\\omega}^{\\mathsf{T}} \\rVert_{\\mathrm{F}} \\leq \\tau$（容差 $\\tau = 10^{-12}$），并通过最小特征值超过 $\\varepsilon = 10^{-12}$ 来验证正定性。\n\n最终输出规范。您的程序必须生成单行输出，其中包含三个测试用例的结果，聚合为一个逗号分隔的列表，并用方括号括起来，每个浮点数四舍五入到恰好 $6$ 位小数，顺序如下：\n- $\\omega_{1}^{\\star}$、$\\rho_{1}$、$\\omega_{2}^{\\star}$、$\\rho_{2}$、$\\omega_{3}^{\\star}$、$\\rho_{3}$，\n其中 $\\omega_{j}^{\\star}$ 是情况 $j$ 的调优松弛参数，$\\rho_{j} = \\kappa(M_{\\omega_{j}^{\\star}}^{-1} A) / \\kappa(A)$ 是情况 $j$ 实现的条件数比率。例如，您的输出必须具有以下确切格式：\n$[\\omega_{1}^{\\star},\\rho_{1},\\omega_{2}^{\\star},\\rho_{2},\\omega_{3}^{\\star},\\rho_{3}]$，\n其中每个数值条目都以小数点后恰好 $6$ 位数字打印。不得打印任何额外文本。",
            "solution": "所提出的问题是关于对称逐次超松弛（SSOR）方法作为对称正定（SPD）线性系统预条件子的理论与应用的综合性练习。它具有科学依据且是适定的，其所有组成部分都可以在数值线性代数领域内形式化。因此，该问题是有效的，我们继续提供一个完整的解决方案。\n\n解决方案分为四个部分，对应于问题陈述中概述的任务。我们从预条件子矩阵的推导和分析开始，然后检验其条件数性质，设计调优算法，最后是实现细节。\n\n### 第 1 部分：SSOR 预条件子矩阵 $M_{\\omega}$ 的推导与性质\n\n给定一个实数 SPD 矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 及其分裂 $A = D + L + U$，其中 $D$ 是 $A$ 的对角部分，$L$ 是其严格下三角部分，$U$ 是其严格上三角部分。由于 $A$ 是对称的，$A = A^{\\mathsf{T}} = (D+L+U)^{\\mathsf{T}} = D^{\\mathsf{T}}+L^{\\mathsf{T}}+U^{\\mathsf{T}}$。因为 $D$ 是对角矩阵，所以 $D=D^{\\mathsf{T}}$，这意味着 $U = L^{\\mathsf{T}}$。松弛参数 $\\omega$ 位于区间 $(0, 2)$ 内。\n\n预处理步骤旨在为系统 $A\\mathbf{z} = \\mathbf{r}$ 计算一个近似解 $\\mathbf{z}$，其中 $\\mathbf{r}$ 是残差向量。预条件子 $M_{\\omega}$ 的定义使得 $\\mathbf{z} = M_{\\omega}^{-1}\\mathbf{r}$。问题将 $M_{\\omega}^{-1}$ 的作用定义为一次前向和一次后向超松弛扫描的复合。\n\n令总更新量为 $\\mathbf{z}$。一次前向 SOR 扫描通过求解 $(D+\\omega L)\\mathbf{z}_{\\text{fwd}} = \\omega \\mathbf{r}$ 来计算中间更新量 $\\mathbf{z}_{\\text{fwd}}$。这个公式对应于将 SOR 迭代法的一步应用于系统 $A\\mathbf{z}=\\mathbf{r}$，初始猜测为 $\\mathbf{z}_0=\\mathbf{0}$。这次前向扫描的算子是 $M_{\\text{fwd}} = \\frac{1}{\\omega}(D+\\omega L)$。\n\n一个完整的 SSOR 步骤包含一次前向扫描，随后是一次后向扫描。令从初始迭代 $\\mathbf{x}_k$ 到下一个迭代 $\\mathbf{x}_{k+1}$ 的更新定义了逆预条件子对残差 $\\mathbf{r}_k = \\mathbf{b} - A\\mathbf{x}_k$ 的作用。\n\n$1$. **前向扫描**：更新量 $\\delta_k = \\mathbf{x}_{k+1/2} - \\mathbf{x}_k$ 是通过对残差方程 $A\\delta_k = \\mathbf{r}_k$ 应用一次前向 SOR 步骤来计算的。这由下式给出：\n$$ (D+\\omega L)\\delta_k = \\omega \\mathbf{r}_k \\implies \\delta_k = \\omega (D+\\omega L)^{-1}\\mathbf{r}_k $$\n中间迭代是 $\\mathbf{x}_{k+1/2} = \\mathbf{x}_k + \\delta_k$。\n\n$2$. **后向扫描**：随后的更新量 $\\eta_k = \\mathbf{x}_{k+1} - \\mathbf{x}_{k+1/2}$ 是通过对新的残差方程 $A\\eta_k = \\mathbf{r}_{k+1/2}$ 应用一次后向 SOR 步骤来计算的，其中 $\\mathbf{r}_{k+1/2} = \\mathbf{b} - A\\mathbf{x}_{k+1/2}$。这由下式给出：\n$$ (D+\\omega U)\\eta_k = \\omega \\mathbf{r}_{k+1/2} \\implies \\eta_k = \\omega (D+\\omega U)^{-1}\\mathbf{r}_{k+1/2} $$\n\n总更新量为 $\\mathbf{x}_{k+1} - \\mathbf{x}_k = \\delta_k + \\eta_k$。我们希望将其表示为 $M_{\\omega}^{-1}\\mathbf{r}_k$ 的形式。\n首先，用 $\\mathbf{r}_k$ 表示 $\\mathbf{r}_{k+1/2}$：\n$$ \\mathbf{r}_{k+1/2} = \\mathbf{b} - A\\mathbf{x}_{k+1/2} = \\mathbf{b} - A(\\mathbf{x}_k + \\delta_k) = (\\mathbf{b}-A\\mathbf{x}_k) - A\\delta_k = \\mathbf{r}_k - A (\\omega (D+\\omega L)^{-1}\\mathbf{r}_k) = (I - \\omega A(D+\\omega L)^{-1})\\mathbf{r}_k $$\n总更新量则为：\n$$ \\mathbf{x}_{k+1} - \\mathbf{x}_k = \\omega(D+\\omega L)^{-1}\\mathbf{r}_k + \\omega(D+\\omega U)^{-1}(I - \\omega A(D+\\omega L)^{-1})\\mathbf{r}_k $$\n这定义了 $M_{\\omega}^{-1}$ 的作用：\n$$ M_{\\omega}^{-1} = \\omega(D+\\omega L)^{-1} + \\omega(D+\\omega U)^{-1} - \\omega^2(D+\\omega U)^{-1}A(D+\\omega L)^{-1} $$\n令 $M_L = \\frac{1}{\\omega}(D+\\omega L)$ 和 $M_U = \\frac{1}{\\omega}(D+\\omega U)$。那么 $A = L+D+U = \\frac{1}{\\omega}(D+\\omega L) + \\frac{1}{\\omega}(D+\\omega U) - \\frac{2-\\omega}{\\omega}D = M_L+M_U - \\frac{2-\\omega}{\\omega}D$。将 $A$ 代入 $M_{\\omega}^{-1}$ 的表达式：\n$$ M_{\\omega}^{-1} = \\omega (M_L^{-1} + M_U^{-1} - M_U^{-1} \\left(M_L+M_U-\\frac{2-\\omega}{\\omega}D\\right) M_L^{-1}) $$\n$$ M_{\\omega}^{-1} = \\omega (M_L^{-1} + M_U^{-1} - M_U^{-1}M_L M_L^{-1} - M_U^{-1}M_U M_L^{-1} + \\frac{2-\\omega}{\\omega}M_U^{-1}D M_L^{-1}) $$\n$$ M_{\\omega}^{-1} = \\omega (M_L^{-1} + M_U^{-1} - M_U^{-1} - M_L^{-1} + \\frac{2-\\omega}{\\omega}M_U^{-1}D M_L^{-1}) $$\n$$ M_{\\omega}^{-1} = (2-\\omega)M_U^{-1}D M_L^{-1} $$\n对此表达式求逆得到 $M_{\\omega}$：\n$$ M_{\\omega} = \\frac{1}{2-\\omega} M_L D^{-1} M_U = \\frac{1}{2-\\omega} \\left(\\frac{1}{\\omega}(D+\\omega L)\\right) D^{-1} \\left(\\frac{1}{\\omega}(D+\\omega U)\\right) = \\frac{1}{\\omega^2(2-\\omega)}(D+\\omega L)D^{-1}(D+\\omega U) $$\n问题允许任意正标量倍数。对于 $\\omega \\in (0, 2)$，因子 $\\frac{1}{\\omega^2(2-\\omega)}$ 是正的。因此我们可以选择其规范代数形式：\n$$ M_{\\omega} = (D+\\omega L) D^{-1} (D+\\omega U) $$\n\n**对称性与正定性的证明：**\n为了证明对于 SPD 矩阵 $A$ 和 $\\omega \\in (0, 2)$，$M_{\\omega}$ 是 SPD 的：\n1.  **对称性**：由于 $A$ 是对称的，$U = L^{\\mathsf{T}}$。我们检查 $M_{\\omega}$ 的转置：\n    $$ M_{\\omega}^{\\mathsf{T}} = ((D+\\omega L)D^{-1}(D+\\omega U))^{\\mathsf{T}} = (D+\\omega U)^{\\mathsf{T}}(D^{-1})^{\\mathsf{T}}(D+\\omega L)^{\\mathsf{T}} $$\n    使用 $D^{\\mathsf{T}}=D$，$U^{\\mathsf{T}}=L$ 和 $L^{\\mathsf{T}}=U$：\n    $$ M_{\\omega}^{\\mathsf{T}} = (D^{\\mathsf{T}}+\\omega U^{\\mathsf{T}})(D^{\\mathsf{T}})^{-1}(D^{\\mathsf{T}}+\\omega L^{\\mathsf{T}}) = (D+\\omega L)D^{-1}(D+\\omega U) = M_{\\omega} $$\n    因此，$M_{\\omega}$ 是对称的。\n\n2.  **正定性**：设 $\\mathbf{x} \\in \\mathbb{R}^n$，$\\mathbf{x} \\neq \\mathbf{0}$。我们必须证明 $\\mathbf{x}^{\\mathsf{T}}M_{\\omega}\\mathbf{x} > 0$。使用 $U=L^\\mathsf{T}$，我们可以写成 $M_\\omega = (D+\\omega L) D^{-1} (D+\\omega L)^\\mathsf{T}$。\n    $$ \\mathbf{x}^{\\mathsf{T}}M_{\\omega}\\mathbf{x} = \\mathbf{x}^{\\mathsf{T}} (D+\\omega L) D^{-1} (D+\\omega L)^{\\mathsf{T}} \\mathbf{x} $$\n    令 $\\mathbf{y} = (D+\\omega L)^{\\mathsf{T}}\\mathbf{x} = (D+\\omega U)\\mathbf{x}$。表达式变为 $\\mathbf{y}^{\\mathsf{T}} D^{-1} \\mathbf{y}$。\n    由于 $A$ 是 SPD 的，其对角元 $d_{ii}$ 全是正的。因此，$D$ 是一个对角线上元素为正的对角矩阵，使其本身及其逆 $D^{-1}$ 都是正定的。\n    这意味着 $\\mathbf{y}^{\\mathsf{T}}D^{-1}\\mathbf{y} \\ge 0$。严格为正要求 $\\mathbf{y} \\neq \\mathbf{0}$。\n    对于一个非零的 $\\mathbf{x}$，$\\mathbf{y} = (D+\\omega U)\\mathbf{x}$ 是否可能为零？矩阵 $(D+\\omega U)$ 是上三角矩阵，其对角元素是 $D$ 的严格正对角元素。对角线元素非零的三角矩阵是可逆的。因此，$(D+\\omega U)\\mathbf{x} = \\mathbf{0}$ 当且仅当 $\\mathbf{x} = \\mathbf{0}$。\n    对于任何 $\\mathbf{x} \\neq \\mathbf{0}$，我们有 $\\mathbf{y} \\neq \\mathbf{0}$，因此 $\\mathbf{x}^{\\mathsf{T}}M_{\\omega}\\mathbf{x} = \\mathbf{y}^{\\mathsf{T}}D^{-1}\\mathbf{y} > 0$。\n    因此，$M_{\\omega}$ 对于任何 SPD 矩阵 $A$ 和任何 $\\omega \\in \\mathbb{R}$ 都是对称且正定的。条件 $\\omega \\in (0, 2)$ 与迭代方法的收敛性质相关，而不是与这种形式的 $M_{\\omega}$ 的 SPD 性质相关。\n\n### 第 2 部分：条件数的性质\n\n预处理后的算子是 $K = M_{\\omega}^{-1} A$。由于 $A$ 和 $M_{\\omega}$ 都是 SPD 的，我们可以分析对称预处理系统，其算子为 $\\tilde{K} = M_{\\omega}^{-1/2} A M_{\\omega}^{-1/2}$。该算子是对称的，其特征值为实数且为正。在 $M_{\\omega}$-内积下的条件数定义为 $\\kappa_{M_\\omega}(K) = \\lambda_{\\max}(\\tilde{K}) / \\lambda_{\\min}(\\tilde{K})$。\n\n$\\tilde{K}$ 的特征值与矩阵对 $(A, M_{\\omega})$ 的广义特征值相同，后者是 $\\det(A - \\lambda M_{\\omega}) = 0$ 的根 $\\lambda$。这是因为 $\\tilde{K} = M_{\\omega}^{-1/2} A M_{\\omega}^{-1/2}$ 与 $M_{\\omega}^{-1}A$ 相似，因为 $M_{\\omega}^{-1}A = M_{\\omega}^{-1/2}(M_{\\omega}^{-1/2} A M_{\\omega}^{-1/2})M_{\\omega}^{1/2}$。因此，$\\text{eig}(\\tilde{K}) = \\text{eig}(M_{\\omega}^{-1}A)$。因此，在 $M_\\omega$-内积下的条件数等于 $M_\\omega^{-1}A$ 的谱条件数：\n$$ \\kappa_{M_\\omega}(M_\\omega^{-1} A) = \\frac{\\lambda_{\\max}(M_\\omega^{-1/2} A M_\\omega^{-1/2})}{\\lambda_{\\min}(M_\\omega^{-1/2} A M_\\omega^{-1/2})} = \\frac{\\lambda_{\\max}(M_\\omega^{-1} A)}{\\lambda_{\\min}(M_\\omega^{-1} A)} = \\kappa(M_\\omega^{-1} A) $$\n\n接下来，我们证明将 $M_{\\omega}$ 乘以一个正标量 $c > 0$ 不会改变这个条件数。设缩放后的预条件子为 $M'_{\\omega} = c M_{\\omega}$。新的预处理算子是 $(M'_{\\omega})^{-1} A = (c M_{\\omega})^{-1} A = \\frac{1}{c} (M_{\\omega}^{-1} A)$。\n如果 $\\lambda$ 是 $M_{\\omega}^{-1}A$ 的一个特征值，其特征向量为 $\\mathbf{x}$，即 $(M_{\\omega}^{-1}A)\\mathbf{x} = \\lambda \\mathbf{x}$，那么对于缩放后的系统，我们有：\n$$ (\\frac{1}{c} M_{\\omega}^{-1} A) \\mathbf{x} = \\frac{1}{c}(\\lambda \\mathbf{x}) = (\\frac{\\lambda}{c}) \\mathbf{x} $$\n新算子的特征值是 $\\lambda' = \\lambda/c$。条件数是最大与最小特征值之比：\n$$ \\kappa((M'_{\\omega})^{-1}A) = \\frac{\\lambda'_{\\max}}{\\lambda'_{\\min}} = \\frac{\\lambda_{\\max}/c}{\\lambda_{\\min}/c} = \\frac{\\lambda_{\\max}}{\\lambda_{\\min}} = \\kappa(M_\\omega^{-1}A) $$\n这显示了对正标量缩放的不变性。\n\n如第 1 部分所述，SSOR 预条件子的完整形式包括一个依赖于 $\\omega$ 的标量因子，即 $c(\\omega) = \\frac{1}{\\omega(2-\\omega)}$（或略有变化的变体）。由于 $\\omega \\in (0, 2)$，该因子始终为正。因为我们旨在最小化的条件数对这个正因子是不变的，所以为了调优 $\\omega$，我们可以合理地忽略它。因此，我们可以在调优过程中使用更简单的形式 $M_{\\omega} = (D+\\omega L) D^{-1} (D+\\omega U)$。\n\n### 第 3 部分：调优目标和算法设计\n\n**调优目标**：对于 SPD 系统，预处理共轭梯度（PCG）方法的收敛速率是一个随着预处理算子条件数减小而减小的函数。因此，一个自然且实用的调优参数 $\\omega$ 的目标是**最小化预处理矩阵的谱条件数 $\\kappa(M_{\\omega}^{-1}A)$**。该目标是可计算的，并直接关系到迭代求解器的性能。\n\n**算法设计**：\n在给定范围 $[\\omega_{\\min}, \\omega_{\\max}]$ 内找到最优 $\\omega^{\\star}$ 的算法如下：\n\n1.  **矩阵分解**：给定矩阵 $A$，构造其分量：\n    - $D$：包含 $A$ 对角线的对角矩阵。\n    - $L$：$A$ 的严格下三角部分。\n    - $U$：$A$ 的严格上三角部分。（对于对称矩阵 $A$，$U=L^\\mathsf{T}$）。\n\n2.  **对 $\\omega$ 进行网格搜索**：在指定的区间 $[\\omega_{\\min}, \\omega_{\\max}]$ 内，以步长 $\\Delta\\omega$ 遍历一组离散的 $\\omega$ 值。\n\n3.  **对于每个 $\\omega$**：\n    a.  **组装 $M_{\\omega}$**：使用推导出的公式构造预条件子矩阵：\n        $$ M_{\\omega} = (D+\\omega L) D^{-1} (D+\\omega U) $$\n        在计算上，首先计算对角矩阵 $D$ 的逆（这是平凡的），然后执行矩阵乘法。\n\n    b.  **诊断**：\n        i.  **对称性检查**：验证计算出的 $M_{\\omega}$ 在数值容差 $\\tau$ 内是对称的。这通过检查 $\\lVert M_{\\omega} - M_{\\omega}^{\\mathsf{T}} \\rVert_{\\mathrm{F}} \\leq \\tau$ 来完成。\n        ii. **正定性检查**：通过计算 $M_{\\omega}$ 的最小特征值 $\\lambda_{\\min}(M_{\\omega})$，并确保它大于一个小的正容差 $\\varepsilon$（即 $\\lambda_{\\min}(M_{\\omega}) > \\varepsilon$），来验证 $M_{\\omega}$ 是正定的。\n\n    c.  **计算条件数**：求解对称正定广义特征值问题 $A\\mathbf{x} = \\lambda M_{\\omega}\\mathbf{x}$ 来找到其特征值 $\\lambda_i$。这比显式地构建 $M_{\\omega}^{-1}A$ 更可取，因为它保留了矩阵对 $(A, M_{\\omega})$ 的对称性和正定性，从而带来更稳定的数值方法。条件数则为：\n        $$ \\kappa(M_{\\omega}^{-1}A) = \\frac{\\max_i \\lambda_i}{\\min_i \\lambda_i} $$\n\n4.  **寻找最优 $\\omega^{\\star}$**：记录迄今为止产生最小 $\\kappa(M_{\\omega}^{-1}A)$ 的 $\\omega$。最终值即为最优参数 $\\omega^{\\star}$。\n\n5.  **计算参考条件数 $\\kappa(A)$**：为了比较，通过求解标准对称特征值问题 $A\\mathbf{x} = \\lambda\\mathbf{x}$ 并计算 $\\kappa(A) = \\lambda_{\\max}(A) / \\lambda_{\\min}(A)$ 来计算原始矩阵 $A$ 的条件数。\n\n6.  **报告比率**：最终的性能指标是比率 $\\rho = \\kappa(M_{\\omega^{\\star}}^{-1}A) / \\kappa(A)$，它量化了预处理带来的改进。\n\n该算法为调优 SSOR 预条件子提供了一个鲁棒且数值稳定的过程。\n\n### 第 4 部分：实现策略\n第 3 部分描述的算法将使用 `numpy` 和 `scipy` 库在 Python 中实现。\n- 三个测试用例的测试矩阵将按如下方式构造：\n    - **情况 1 (一维泊松)**：使用 `numpy.diag` 创建一个大小为 $20 \\times 20$ 的三对角矩阵。\n    - **情况 2 (二维泊松)**：使用 `numpy.kron` 构造一个大小为 $25 \\times 25$ 的块三对角矩阵，以表示 $5 \\times 5$ 网格上的五点 stencil。\n    - **情况 3 (各向异性)**：从一维泊松矩阵 $K$ 和一个对角缩放矩阵 $S$ 构建大小为 $30 \\times 30$ 的矩阵 $A=SKS$。\n- SPD 矩阵的特征值问题（标准和广义）将使用 `scipy.linalg.eigh` 求解，该函数专为此目的设计，高效且准确。\n- 网格搜索将实现为一个简单的循环，遍历一个用于 $\\omega$ 的 `numpy.arange` 数组。\n- 诊断检查和最终输出格式将严格遵循问题规范。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import eigh\n\ndef solve():\n    \"\"\"\n    Performs SSOR parameter tuning for three test cases and prints the results.\n    \"\"\"\n    \n    # Define test parameters\n    omega_min = 0.05\n    omega_max = 1.95\n    delta_omega = 0.01\n    sym_tol = 1e-12\n    pd_tol = 1e-12\n\n    test_cases_params = [\n        {'id': 1, 'n': 20},\n        {'id': 2, 'm': 5}, # 2D case on m x m grid\n        {'id': 3, 'n': 30, 'alpha': 3.0}\n    ]\n\n    final_results = []\n\n    for params in test_cases_params:\n        # 1. Construct the matrix A for the current test case\n        case_id = params['id']\n        if case_id == 1:\n            n = params['n']\n            A = np.diag(2.0 * np.ones(n)) - np.diag(np.ones(n - 1), k=1) - np.diag(np.ones(n - 1), k=-1)\n        elif case_id == 2:\n            m = params['m']\n            n = m * m\n            K_m = np.diag(2.0 * np.ones(m)) - np.diag(np.ones(m - 1), k=1) - np.diag(np.ones(m - 1), k=-1)\n            A = np.kron(np.eye(m), 4.0 * np.eye(m) + K_m) - np.kron(np.diag(np.ones(m-1), k=1), np.eye(m)) - np.kron(np.diag(np.ones(m-1), k=-1), np.eye(m))\n            # The standard 5-point stencil on an m-by-m grid results in a matrix A of size n-by-n, where n=m*m.\n            # Its main diagonal has entries of 4. The off-diagonals have entries of -1.\n            # The following is a more direct way to build the 2D Laplacian matrix.\n            I = np.eye(m)\n            T = np.diag(4*np.ones(m)) - np.diag(np.ones(m-1),-1) - np.diag(np.ones(m-1),1)\n            A = np.kron(I,T) - np.kron(np.diag(np.ones(m-1),1),I) - np.kron(np.diag(np.ones(m-1),-1),I)\n\n        elif case_id == 3:\n            n = params['n']\n            alpha = params['alpha']\n            K_n = np.diag(2.0 * np.ones(n)) - np.diag(np.ones(n - 1), k=1) - np.diag(np.ones(n - 1), k=-1)\n            s_diag = np.exp(alpha * np.arange(n) / (n - 1.0))\n            S = np.diag(s_diag)\n            A = S @ K_n @ S\n        else:\n            raise ValueError(\"Invalid case ID\")\n\n        # 2. Compute reference condition number kappa(A)\n        try:\n            eigvals_A = eigh(A, eigvals_only=True)\n            kappa_A = np.max(eigvals_A) / np.min(eigvals_A)\n        except np.linalg.LinAlgError:\n            # This should not happen for the given SPD matrices\n            raise RuntimeError(f\"Eigendecomposition of A failed for case {case_id}\")\n\n        # 3. Decompose A into D, L, U\n        D_diag = np.diag(A)\n        D = np.diag(D_diag)\n        L = np.tril(A, k=-1)\n        U = np.triu(A, k=1) # Note: U = L.T since A is symmetric.\n\n        # Prepare for grid search\n        omega_grid = np.arange(omega_min, omega_max + 1e-9, delta_omega)\n        best_omega = -1.0\n        min_kappa_preconditioned = float('inf')\n        \n        # 4. Grid search for optimal omega\n        for omega in omega_grid:\n            # 4a. Assemble M_omega\n            D_inv = np.diag(1.0 / D_diag)\n            M_omega = (D + omega * L) @ D_inv @ (D + omega * U)\n\n            # 4b. Diagnostics\n            # Symmetry check\n            sym_error = np.linalg.norm(M_omega - M_omega.T, 'fro')\n            if sym_error > sym_tol:\n                raise RuntimeError(f\"Symmetry check failed for omega={omega}: {sym_error}\")\n            \n            # Positive definiteness check\n            try:\n                min_eig_M = eigh(M_omega, eigvals_only=True, subset_by_index=[0, 0])[0]\n                if min_eig_M <= pd_tol:\n                    raise RuntimeError(f\"PD check failed for omega={omega}: min_eig={min_eig_M}\")\n            except np.linalg.LinAlgError:\n                raise RuntimeError(f\"Eigendecomposition of M_omega failed for omega={omega}\")\n\n            # 4c. Compute condition number kappa(M_inv * A)\n            try:\n                gen_eigvals = eigh(A, b=M_omega, eigvals_only=True)\n                kappa_preconditioned = np.max(gen_eigvals) / np.min(gen_eigvals)\n            except np.linalg.LinAlgError:\n                 raise RuntimeError(f\"Generalized eigendecomposition failed for omega={omega}\")\n\n            # 4d. Update best omega\n            if kappa_preconditioned < min_kappa_preconditioned:\n                min_kappa_preconditioned = kappa_preconditioned\n                best_omega = omega\n\n        # 5. Calculate final ratio\n        kappa_ratio = min_kappa_preconditioned / kappa_A\n        \n        final_results.append(best_omega)\n        final_results.append(kappa_ratio)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{x:.6f}' for x in final_results])}]\")\n\nsolve()\n```"
        }
    ]
}