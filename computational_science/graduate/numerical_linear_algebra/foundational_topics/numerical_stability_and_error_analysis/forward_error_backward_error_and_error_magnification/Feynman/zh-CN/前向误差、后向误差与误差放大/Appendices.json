{
    "hands_on_practices": [
        {
            "introduction": "在深入研究误差放大之前，我们首先需要从根本上理解什么使问题变得“敏感”或“病态”。这项分析性练习将通过一个简单的参数化矩阵族，让您亲身体验矩阵结构如何导致其对扰动的极端敏感性 。您将从第一性原理出发，推导该矩阵的条件数，并观察当矩阵接近奇异时，条件数是如何急剧增长的，从而为后续的实践练习奠定坚实的理论基础。",
            "id": "3547254",
            "problem": "考虑为 $\\epsilon>0$ 定义的参数化实对称矩阵族 $A(\\epsilon) \\in \\mathbb{R}^{2 \\times 2}$：\n$$\nA(\\epsilon)=\\begin{pmatrix}1  1 \\\\ 1  1+\\epsilon\\end{pmatrix}.\n$$\n根据数值线性代数中的基本定义进行计算：\n\n- 矩阵 $2$-范数 $\\Vert A \\Vert_{2}$ 是由欧几里得向量范数诱导的算子范数。\n- $2$-范数条件数是 $\\kappa_{2}(A)=\\Vert A \\Vert_{2}\\,\\Vert A^{-1} \\Vert_{2}$，前提是 $A$ 非奇异。\n\n任务：\n\n(a) 仅使用这些定义和实对称矩阵的谱性质，推导出 $\\kappa_{2}(A(\\epsilon))$ 作为 $\\epsilon$ 函数的闭式表达式。\n\n(b) 确定极限\n$$\nL \\;=\\; \\lim_{\\epsilon\\to 0^{+}} \\epsilon \\kappa_{2}(A(\\epsilon)).\n$$\n此极限 $L$ 是您必须作为最终答案报告的量。\n\n(c) 为了说明小 $\\epsilon$ 的前向误差放大效应，考虑求解线性系统 $A(\\epsilon)\\,x=b(\\epsilon)$，其精确解为 $x^{\\star}=\\begin{pmatrix}1\\\\ 1\\end{pmatrix}$，对应的右侧项为 $b(\\epsilon)=A(\\epsilon)\\,x^{\\star}=\\begin{pmatrix}2\\\\ 2+\\epsilon\\end{pmatrix}$。假设一个计算解 $\\widetilde{x}$ 满足 $A(\\epsilon)\\,\\widetilde{x}=b(\\epsilon)+\\delta b$，其中存在某个扰动 $\\delta b$ 使得 $\\Vert \\delta b \\Vert_{2} / \\Vert b(\\epsilon) \\Vert_{2} = \\eta$，且 $0  \\eta \\ll 1$ 独立于 $\\epsilon$。使用从第一性原理推导出的扰动恒等式，证明当 $\\epsilon\\to 0^{+}$ 时，最坏情况下的相对前向误差的尺度为 $O(\\epsilon^{-1})$，并找出一个能渐近实现此尺度的扰动方向 $\\delta b$。此问题中任何地方都不需要数值舍入。对于 (b) 部分，请将 $L$ 报告为精确值。",
            "solution": "该问题陈述经核实具有科学依据，问题设定良好且客观。这是一个关于矩阵条件数和误差分析的数值线性代数标准问题。所有数据和定义都是自洽且一致的。\n\n(a) 条件数 $\\kappa_{2}(A(\\epsilon))$ 的推导。\n\n矩阵 $A(\\epsilon)$ 如下所示\n$$\nA(\\epsilon)=\\begin{pmatrix}1  1 \\\\ 1  1+\\epsilon\\end{pmatrix}.\n$$\n对于实对称矩阵，矩阵 $2$-范数 $\\Vert A \\Vert_{2}$ 等于其谱半径，即其特征值绝对值的最大值。令 $\\lambda$ 表示 $A(\\epsilon)$ 的一个特征值。特征值是特征方程 $\\det(A(\\epsilon) - \\lambda I) = 0$ 的根。\n$$\n\\det\\begin{pmatrix}1-\\lambda  1 \\\\ 1  1+\\epsilon-\\lambda\\end{pmatrix} = (1-\\lambda)(1+\\epsilon-\\lambda) - 1 = 0\n$$\n$$\n\\lambda^2 - (2+\\epsilon)\\lambda + \\epsilon = 0\n$$\n使用二次公式，特征值为：\n$$\n\\lambda = \\frac{(2+\\epsilon) \\pm \\sqrt{(2+\\epsilon)^2 - 4\\epsilon}}{2} = \\frac{2+\\epsilon \\pm \\sqrt{4+4\\epsilon+\\epsilon^2 - 4\\epsilon}}{2} = \\frac{2+\\epsilon \\pm \\sqrt{4+\\epsilon^2}}{2}\n$$\n当 $\\epsilon  0$ 时，$A(\\epsilon)$ 的迹为 $2+\\epsilon  0$，其行列式为 $\\det(A(\\epsilon)) = 1(1+\\epsilon) - 1(1) = \\epsilon  0$。这意味着 $A(\\epsilon)$ 是正定的，因此两个特征值均为正。我们将它们表示为 $\\lambda_{max}$ 和 $\\lambda_{min}$：\n$$\n\\lambda_{max}(\\epsilon) = \\frac{2+\\epsilon + \\sqrt{4+\\epsilon^2}}{2}\n$$\n$$\n\\lambda_{min}(\\epsilon) = \\frac{2+\\epsilon - \\sqrt{4+\\epsilon^2}}{2}\n$$\n因此，$A(\\epsilon)$ 的 $2$-范数是 $\\Vert A(\\epsilon) \\Vert_2 = \\lambda_{max}(\\epsilon)$。\n\n当 $\\epsilon  0$ 时，矩阵 $A(\\epsilon)$ 是非奇异的。逆矩阵 $A(\\epsilon)^{-1}$ 的特征值是 $A(\\epsilon)$ 特征值的倒数，即 $1/\\lambda_{max}(\\epsilon)$ 和 $1/\\lambda_{min}(\\epsilon)$。由于两个特征值都是正的且 $\\lambda_{max}(\\epsilon)  \\lambda_{min}(\\epsilon)$，我们有 $1/\\lambda_{min}(\\epsilon)  1/\\lambda_{max}(\\epsilon)$。逆矩阵的 $2$-范数是\n$$\n\\Vert A(\\epsilon)^{-1} \\Vert_2 = \\frac{1}{\\lambda_{min}(\\epsilon)}.\n$$\n$2$-范数条件数 $\\kappa_2(A(\\epsilon))$ 定义为 $\\Vert A(\\epsilon) \\Vert_2 \\Vert A(\\epsilon)^{-1} \\Vert_2$。\n$$\n\\kappa_{2}(A(\\epsilon)) = \\frac{\\lambda_{max}(\\epsilon)}{\\lambda_{min}(\\epsilon)} = \\frac{\\frac{2+\\epsilon + \\sqrt{4+\\epsilon^2}}{2}}{\\frac{2+\\epsilon - \\sqrt{4+\\epsilon^2}}{2}}\n$$\n条件数作为 $\\epsilon$ 函数的闭式表达式为：\n$$\n\\kappa_{2}(A(\\epsilon)) = \\frac{2+\\epsilon + \\sqrt{4+\\epsilon^2}}{2+\\epsilon - \\sqrt{4+\\epsilon^2}}\n$$\n\n(b) 极限 $L$ 的确定。\n\n我们需要计算极限 $L = \\lim_{\\epsilon\\to 0^{+}} \\epsilon \\kappa_{2}(A(\\epsilon))$。特征值的一个有用性质是它们的乘积等于矩阵的行列式：$\\lambda_{max}(\\epsilon)\\lambda_{min}(\\epsilon) = \\det(A(\\epsilon)) = \\epsilon$。\n利用这一点，我们可以将条件数重写为：\n$$\n\\kappa_{2}(A(\\epsilon)) = \\frac{\\lambda_{max}(\\epsilon)}{\\lambda_{min}(\\epsilon)} = \\frac{\\lambda_{max}(\\epsilon)}{\\epsilon / \\lambda_{max}(\\epsilon)} = \\frac{(\\lambda_{max}(\\epsilon))^2}{\\epsilon}\n$$\n现在，我们可以计算极限 $L$：\n$$\nL = \\lim_{\\epsilon\\to 0^{+}} \\epsilon \\kappa_{2}(A(\\epsilon)) = \\lim_{\\epsilon\\to 0^{+}} \\epsilon \\left(\\frac{(\\lambda_{max}(\\epsilon))^2}{\\epsilon}\\right) = \\lim_{\\epsilon\\to 0^{+}} (\\lambda_{max}(\\epsilon))^2\n$$\n我们计算当 $\\epsilon \\to 0^{+}$ 时 $\\lambda_{max}(\\epsilon)$ 的极限：\n$$\n\\lim_{\\epsilon\\to 0^{+}} \\lambda_{max}(\\epsilon) = \\lim_{\\epsilon\\to 0^{+}} \\frac{2+\\epsilon + \\sqrt{4+\\epsilon^2}}{2} = \\frac{2+0+\\sqrt{4+0}}{2} = \\frac{2+2}{2} = 2\n$$\n因此，极限 $L$ 是：\n$$\nL = (2)^2 = 4\n$$\n\n(c) 前向误差放大分析。\n\n我们有精确系统 $A(\\epsilon)x^{\\star} = b(\\epsilon)$ 和扰动系统 $A(\\epsilon)\\widetilde{x} = b(\\epsilon) + \\delta b$。解的误差是 $\\delta x = \\widetilde{x} - x^{\\star}$。用第二个方程减去第一个方程得到：\n$$\nA(\\epsilon)(\\widetilde{x} - x^{\\star}) = \\delta b \\implies A(\\epsilon)\\delta x = \\delta b\n$$\n由于 $A(\\epsilon)$ 是非奇异的，$\\delta x = A(\\epsilon)^{-1}\\delta b$。取范数，我们有 $\\Vert \\delta x \\Vert_2 = \\Vert A(\\epsilon)^{-1}\\delta b \\Vert_2 \\le \\Vert A(\\epsilon)^{-1} \\Vert_2 \\Vert \\delta b \\Vert_2$。\n相对前向误差的界如下：\n$$\n\\frac{\\Vert \\delta x \\Vert_2}{\\Vert x^{\\star} \\Vert_2} \\le \\frac{\\Vert A(\\epsilon)^{-1} \\Vert_2 \\Vert \\delta b \\Vert_2}{\\Vert x^{\\star} \\Vert_2}\n$$\n我们可以引入 $\\Vert A(\\epsilon) \\Vert_2$ 和 $\\Vert b(\\epsilon) \\Vert_2 = \\Vert A(\\epsilon)x^{\\star} \\Vert_2$ 将其与条件数联系起来。注意 $\\Vert b(\\epsilon) \\Vert_2 \\le \\Vert A(\\epsilon) \\Vert_2 \\Vert x^{\\star} \\Vert_2$。\n$$\n\\frac{\\Vert \\delta x \\Vert_2}{\\Vert x^{\\star} \\Vert_2} \\le \\Vert A(\\epsilon)^{-1} \\Vert_2 \\Vert A(\\epsilon) \\Vert_2 \\frac{\\Vert \\delta b \\Vert_2}{\\Vert A(\\epsilon)x^{\\star} \\Vert_2} = \\kappa_2(A(\\epsilon)) \\frac{\\Vert \\delta b \\Vert_2}{\\Vert b(\\epsilon) \\Vert_2}\n$$\n已知 $\\Vert \\delta b \\Vert_{2} / \\Vert b(\\epsilon) \\Vert_{2} = \\eta$，该界变为：\n$$\n\\frac{\\Vert \\delta x \\Vert_2}{\\Vert x^{\\star} \\Vert_2} \\le \\kappa_2(A(\\epsilon)) \\eta\n$$\n从 (b) 部分，我们确定了 $\\lim_{\\epsilon\\to 0^{+}} \\epsilon \\kappa_{2}(A(\\epsilon)) = 4$，这意味着对于小的 $\\epsilon  0$，$\\kappa_2(A(\\epsilon)) \\approx 4/\\epsilon$。因此，相对前向误差的界的尺度为：\n$$\n\\frac{\\Vert \\delta x \\Vert_2}{\\Vert x^{\\star} \\Vert_2} \\le O(\\epsilon^{-1})\n$$\n这证明了 $O(\\epsilon^{-1})$ 的尺度关系。\n\n为了找出一个能渐近实现此尺度的扰动方向 $\\delta b$，我们必须找到一个 $\\delta b$ 使得不等式 $\\Vert \\delta x \\Vert_2 \\le \\Vert A(\\epsilon)^{-1} \\Vert_2 \\Vert \\delta b \\Vert_2$ 变为等式。对于对称矩阵，这发生在 $\\delta b$ 是 $A(\\epsilon)^{-1}$ 对应于其最大特征值（即 $\\Vert A(\\epsilon)^{-1} \\Vert_2 = 1/\\lambda_{min}(\\epsilon)$）的特征向量时。这个特征向量与 $A(\\epsilon)$ 对应于特征值 $\\lambda_{min}(\\epsilon)$ 的特征向量相同。令这个特征向量为 $v_{min}$。我们求解 $(A(\\epsilon) - \\lambda_{min}(\\epsilon)I)v_{min} = 0$。\n$$\n\\begin{pmatrix} 1-\\lambda_{min}(\\epsilon)  1 \\\\ 1  1+\\epsilon-\\lambda_{min}(\\epsilon) \\end{pmatrix} \\begin{pmatrix} v_1 \\\\ v_2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\n第一行给出 $(1-\\lambda_{min}(\\epsilon))v_1 + v_2 = 0$。我们可以设 $v_1 = 1$，得到 $v_2 = \\lambda_{min}(\\epsilon) - 1$。\n所以，一个特征向量是 $v_{min}(\\epsilon) = \\begin{pmatrix} 1 \\\\ \\lambda_{min}(\\epsilon) - 1 \\end{pmatrix}$。\n我们分析当 $\\epsilon \\to 0^{+}$ 时这个向量的行为。\n$$\n\\lim_{\\epsilon\\to 0^{+}} \\lambda_{min}(\\epsilon) = \\lim_{\\epsilon\\to 0^{+}} \\frac{2+\\epsilon - \\sqrt{4+\\epsilon^2}}{2} = \\frac{2+0-\\sqrt{4}}{2} = 0\n$$\n因此，分量 $v_2$ 趋近于 $0-1 = -1$。因此，特征向量 $v_{min}(\\epsilon)$ 的渐近方向是\n$$\n\\lim_{\\epsilon\\to 0^{+}} v_{min}(\\epsilon) \\propto \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}\n$$\n在 $\\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$ 方向上的扰动 $\\delta b$，对于足够小的 $\\epsilon$，将与特征向量 $v_{min}(\\epsilon)$ 紧密对齐，导致前向误差被最大程度地放大，并实现 $O(\\epsilon^{-1})$ 的尺度关系。\n当 $\\delta b$ 沿着 $v_{min}(\\epsilon)$ 的方向选择时，我们有等式：$\\frac{\\Vert \\delta x \\Vert_2}{\\Vert x^{\\star} \\Vert_2} = \\eta \\frac{\\Vert b(\\epsilon) \\Vert_2}{\\Vert x^{\\star} \\Vert_2} \\frac{\\Vert A(\\epsilon) \\Vert_2}{\\Vert b(\\epsilon) \\Vert_2} \\kappa_2(A(\\epsilon))$。当 $\\epsilon \\to 0^+$ 时，$\\Vert x^\\star \\Vert_2 = \\sqrt{2}$，$b(\\epsilon) \\to \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix}$，所以 $\\Vert b(\\epsilon) \\Vert_2 \\to \\sqrt{8} = 2\\sqrt{2}$。此外，$\\Vert A(\\epsilon) \\Vert_2 = \\lambda_{max}(\\epsilon) \\to 2$。因子 $\\frac{\\Vert b(\\epsilon) \\Vert_2}{\\Vert x^{\\star} \\Vert_2} \\frac{\\Vert A(\\epsilon) \\Vert_2}{\\Vert b(\\epsilon) \\Vert_2}$ 变为 $\\frac{2}{\\sqrt{8}} \\frac{2\\sqrt{2}}{\\sqrt{2}} = 1$。该表达式趋近于 $\\eta \\kappa_2(A(\\epsilon))$，这证实了该尺度关系。所需的方向是渐近地指向向量 $\\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$ 的方向。",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "在建立了对病态条件的理论理解之后，我们现在可以在实践中观察其影响。本练习要求您编写代码，来度量矩阵求逆这一基本线性代数运算中的误差放大因子 。通过对精心设计的良态和病态矩阵施加微小扰动，您将定量地观察到一个很小的向后误差（输入矩阵的微小变化）如何导致一个巨大的向前误差（其逆矩阵的巨大变化）。",
            "id": "3547191",
            "problem": "设计并实现一个程序，该程序定量地演示对于矩阵求逆映射，微小的向后误差如何产生巨大的向前误差。请在以下设定下进行。\n\n设函数为 $f(A) = A^{-1}$，其中 $A \\in \\mathbb{R}^{n \\times n}$ 为任意可逆方阵。使用矩阵 $2$-范数，其值等于通过奇异值分解（SVD）得到的最大奇异值。对于任何扰动 $\\Delta A$，只要 $A + \\Delta A$ 保持可逆，定义：\n- 相对向后误差 $\\beta = \\frac{\\Vert \\Delta A \\Vert_2}{\\Vert A \\Vert_2}$。\n- 相对向前误差 $\\phi = \\frac{\\Vert (A + \\Delta A)^{-1} - A^{-1} \\Vert_2}{\\Vert A^{-1} \\Vert_2}$。\n- 误差放大因子 $M = \\frac{\\phi}{\\beta}$。\n\n程序必须为每个测试用例构造一个扰动 $\\Delta A$，其具有预设的相对向后误差目标 $\\delta \\in \\mathbb{R}_{0}$。具体方法是设置 $\\Delta A = s J$，其中 $J$ 是尺寸兼容的全一矩阵，$s \\in \\mathbb{R}$ 的选择需使 $\\frac{\\Vert \\Delta A \\Vert_2}{\\Vert A \\Vert_2} = \\delta$。明确地说，你必须确定 $s$ 的值，使得相对向后误差在浮点舍入误差范围内等于给定的目标 $\\delta$。然后，使用上述定义为每个测试用例计算 $M$。所有计算必须在 $\\mathbb{R}$ 中使用标准浮点算术进行。\n\n测试套件：\n- 用例 1（近奇异 $2 \\times 2$）：$A_1 = \\begin{bmatrix} 1  1 \\\\ 1  1 + 10^{-8} \\end{bmatrix}$，$\\delta_1 = 10^{-12}$。\n- 用例 2（良态 $2 \\times 2$）：$A_2 = I_2$，$2 \\times 2$ 单位矩阵，$\\delta_2 = 10^{-8}$。\n- 用例 3（类边界 $2 \\times 2$）：$A_3 = \\begin{bmatrix} 1  1 \\\\ 1  1 + 10^{-6} \\end{bmatrix}$，$\\delta_3 = 3 \\cdot 10^{-7}$。\n- 用例 4（病态对角 $3 \\times 3$）：$A_4 = \\operatorname{diag}(1, 10^{-8}, 1)$，$\\delta_4 = 10^{-10}$。\n\n要求：\n- 对于每个测试用例 $(A, \\delta)$，构造 $\\Delta A = s J$，$J$ 是与 $A$ 尺寸相匹配的全一矩阵，选择 $s$ 使得 $\\frac{\\Vert \\Delta A \\Vert_2}{\\Vert A \\Vert_2} = \\delta$。\n- 通过直接计算 $A + \\Delta A$ 的逆矩阵来数值验证其可逆性。\n- 按规定计算误差放大因子 $M$。\n- 所有地方均使用矩阵 $2$-范数。\n- 不要使用任何随机性；所有计算必须是确定性的。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含四个用例的误差放大因子，形式为逗号分隔的列表并用方括号括起，顺序与上述用例顺序一致。例如，输出必须是如下形式\n$[m_1, m_2, m_3, m_4]$\n其中每个 $m_i$ 是一个浮点数，代表用例 $i$ 的 $M$。不应打印任何额外文本。",
            "solution": "该问题要求对矩阵求逆中的误差放大现象进行定量演示。具体来说，我们必须分析方阵 $A \\in \\mathbb{R}^{n \\times n}$ 的函数 $f(A) = A^{-1}$。分析使用矩阵 $2$-范数进行，记作 $\\Vert \\cdot \\Vert_2$，它对应于矩阵的最大奇异值。\n\n对于给定的可逆矩阵 $A$ 和一个扰动 $\\Delta A$（使得 $A + \\Delta A$ 也可逆），我们有以下定义：\n- 相对向后误差：$\\beta = \\frac{\\Vert \\Delta A \\Vert_2}{\\Vert A \\Vert_2}$。\n- 相对向前误差：$\\phi = \\frac{\\Vert (A + \\Delta A)^{-1} - A^{-1} \\Vert_2}{\\Vert A^{-1} \\Vert_2}$。\n- 误差放大因子：$M = \\frac{\\phi}{\\beta}$。\n\n问题的核心是为给定的矩阵 $A$ 和目标相对向后误差 $\\delta  0$ 构造一个特定的扰动 $\\Delta A$。该扰动定义为 $\\Delta A = s J$，其中 $J$ 是 $n \\times n$ 的全一矩阵，标量 $s \\in \\mathbb{R}$ 的选择需满足条件 $\\beta = \\delta$。\n\n首先，我们确定标量 $s$。约束条件是：\n$$ \\frac{\\Vert \\Delta A \\Vert_2}{\\Vert A \\Vert_2} = \\delta $$\n代入 $\\Delta A = s J$，我们有：\n$$ \\frac{|s| \\Vert J \\Vert_2}{\\Vert A \\Vert_2} = \\delta $$\n为了解出 $s$，我们需要尺寸为 $n \\times n$ 的全一矩阵 $J_n$ 的 $2$-范数。矩阵 $J_n$ 的秩为 $1$，其奇异值为 $\\{n, 0, \\dots, 0\\}$。因此，其最大奇异值，即其 $2$-范数，为 $\\Vert J_n \\Vert_2 = n$。\n将此代入我们关于 $s$ 的方程中：\n$$ \\frac{|s| n}{\\Vert A \\Vert_2} = \\delta \\implies |s| = \\frac{\\delta \\Vert A \\Vert_2}{n} $$\n由于 $s$ 的符号不影响 $\\Delta A$ 的范数，我们可以不失一般性地选择 $s$ 的正值：\n$$ s = \\frac{\\delta \\Vert A \\Vert_2}{n} $$\n这个公式使我们能够为每个测试用例构造所需的精确扰动 $\\Delta A$。\n\n向前误差、向后误差和条件数之间的关系是数值分析的核心。误差放大因子 $M$ 与矩阵 $A$ 关于 $2$-范数的条件数密切相关，条件数定义为 $\\kappa_2(A) = \\Vert A \\Vert_2 \\Vert A^{-1} \\Vert_2$。一个著名的结果表明，对于足够小的扰动，相对向前误差大约由条件数乘以相对向后误差来界定：\n$$ \\phi \\lesssim \\kappa_2(A) \\beta $$\n这意味着误差放大因子 $M = \\phi/\\beta$ 近似等于矩阵的条件数：\n$$ M \\approx \\kappa_2(A) $$\n这个近似为结果提供了理论预期。具有高条件数（即病态矩阵）的矩阵预计会表现出大的误差放大因子，这意味着输入矩阵的微小相对变化可能导致其逆矩阵的巨大相对变化。相反，良态矩阵（其中 $\\kappa_2(A)$ 接近 $1$）不应显著放大误差。\n\n每个测试用例 $(A, \\delta)$ 的总体步骤如下：\n$1$. 确定矩阵 $A$ 的维度 $n$。\n$2$. 使用奇异值分解（SVD）计算 $\\Vert A \\Vert_2$。\n$3$. 计算标量 $s = \\frac{\\delta \\Vert A \\Vert_2}{n}$。\n$4$. 构造扰动 $\\Delta A = s J_n$。\n$5$. 形成扰动后的矩阵 $\\tilde{A} = A + \\Delta A$。\n$6$. 数值计算逆矩阵 $A^{-1}$ 和 $\\tilde{A}^{-1}$。成功计算 $\\tilde{A}^{-1}$ 可作为其可逆性的验证。\n$7$. 计算范数 $\\Vert A^{-1} \\Vert_2$ 和 $\\Vert \\tilde{A}^{-1} - A^{-1} \\Vert_2$。\n$8$. 计算相对向前误差 $\\phi = \\Vert \\tilde{A}^{-1} - A^{-1} \\Vert_2 / \\Vert A^{-1} \\Vert_2$。\n$9$. 根据构造，相对向后误差 $\\beta$ 等于目标 $\\delta$。\n$10$. 计算误差放大因子 $M = \\phi / \\delta$。\n\n我们将此过程应用于四个指定的测试用例。\n\n用例 1：$A_1 = \\begin{bmatrix} 1  1 \\\\ 1  1 + 10^{-8} \\end{bmatrix}$，$\\delta_1 = 10^{-12}$。\n该矩阵是对称的且非常接近奇异，因为其行列式为 $\\det(A_1) = 10^{-8}$。其条件数非常大，$\\kappa_2(A_1) \\approx 4 \\times 10^8$。因此，我们预期误差放大因子 $M_1$ 会非常大。\n\n用例 2：$A_2 = I_2 = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$，$\\delta_2 = 10^{-8}$。\n这是单位矩阵，是完美良态的。其奇异值均为 $1$，所以 $\\Vert A_2 \\Vert_2 = 1$ 且 $\\Vert A_2^{-1} \\Vert_2 = 1$，得出 $\\kappa_2(A_2) = 1$。我们预期误差放大因子 $M_2$ 将接近 $1$。\n\n用例 3：$A_3 = \\begin{bmatrix} 1  1 \\\\ 1  1 + 10^{-6} \\end{bmatrix}$，$\\delta_3 = 3 \\cdot 10^{-7}$。\n与用例 1 类似，该矩阵是病态的，但程度较轻。其行列式为 $10^{-6}$，条件数为 $\\kappa_2(A_3) \\approx 4 \\times 10^6$。我们预期会有一个大的放大因子 $M_3$，量级约为 $10^6$。\n\n用例 4：$A_4 = \\operatorname{diag}(1, 10^{-8}, 1)$，$\\delta_4 = 10^{-10}$。\n这是一个 $3 \\times 3$ 的对角矩阵。其奇异值是其对角线元素的绝对值：$1, 1, 10^{-8}$。最大的是 $1$，最小的是 $10^{-8}$。因此，$\\kappa_2(A_4) = \\sigma_{max}/\\sigma_{min} = 1 / 10^{-8} = 10^8$。该矩阵是高度病态的，我们预期会有一个数量级相似的巨大误差放大因子 $M_4$。\n\n以下程序将确定性地执行这些计算。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the error magnification factor for matrix inversion for a suite of test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (np.array([[1.0, 1.0], [1.0, 1.0 + 1e-8]]), 1e-12),\n        (np.array([[1.0, 0.0], [0.0, 1.0]]), 1e-8),\n        (np.array([[1.0, 1.0], [1.0, 1.0 + 1e-6]]), 3e-7),\n        (np.array([[1.0, 0.0, 0.0], [0.0, 1e-8, 0.0], [0.0, 0.0, 1.0]]), 1e-10)\n    ]\n\n    results = []\n    for A, delta in test_cases:\n        # Step 1: Determine the dimension n of the matrix A.\n        n = A.shape[0]\n\n        # Step 2: Calculate the 2-norm of A.\n        norm_A = np.linalg.norm(A, 2)\n\n        # Step 3: Calculate the scalar s. The 2-norm of an n x n all-ones matrix is n.\n        # We use np.linalg.norm for robustness, though simply using n is correct.\n        J = np.ones_like(A)\n        norm_J = np.linalg.norm(J, 2) \n        s = (delta * norm_A) / norm_J\n        \n        # Step 4: Construct the perturbation Delta_A.\n        Delta_A = s * J\n\n        # Step 5: Form the perturbed matrix A_perturbed.\n        A_perturbed = A + Delta_A\n\n        # Step 6: Compute the inverses.\n        # This implicitly verifies invertibility. If not invertible, a LinAlgError would be raised.\n        inv_A = np.linalg.inv(A)\n        inv_A_perturbed = np.linalg.inv(A_perturbed)\n\n        # Step 7: Calculate relevant norms.\n        norm_inv_A = np.linalg.norm(inv_A, 2)\n        norm_diff_inv = np.linalg.norm(inv_A_perturbed - inv_A, 2)\n\n        # Step 8: Calculate the relative forward error phi.\n        phi = norm_diff_inv / norm_inv_A\n\n        # Step 9: The relative backward error beta is equal to delta by construction.\n        beta = delta\n\n        # Step 10: Compute the error magnification factor M.\n        M = phi / beta\n\n        results.append(M)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{m:.15g}' for m in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "对误差放大的理解不仅仅是学术探讨，它对我们设计和选择算法具有深远的实际意义。最后一个练习将解决一个经典问题：求解线性方程组 $Ax=b$ 时，是应该先计算 $A^{-1}$ 再乘以 $b$，还是直接求解 ？通过一个涉及不同计算精度和精确解的巧妙实验，您将清楚地看到为何直接求解几乎总是更优的选择，尤其是在矩阵 $A$ 病态的情况下，从而巩固从误差分析中学到的实践智慧。",
            "id": "3547212",
            "problem": "考虑一个线性系统 $A x = b$，其中 $A \\in \\mathbb{R}^{n \\times n}$ 且 $b \\in \\mathbb{R}^{n}$。设 $x$ 表示在精确算术下的精确解，$\\hat{x}$ 表示由某种算法在浮点算术中计算出的解。前向误差是计算解的相对误差，定义为 $\\frac{\\Vert \\hat{x} - x \\Vert_{2}}{\\Vert x \\Vert_{2}}$，其中 $\\Vert \\cdot \\Vert_{2}$ 是向量的欧几里得范数。后向误差是相对残差，定义为 $\\frac{\\Vert b - A \\hat{x} \\Vert_{2}}{\\Vert A \\Vert_{2} \\Vert \\hat{x} \\Vert_{2}}$，其中对于矩阵 $A$，$\\Vert A \\Vert_{2}$ 表示由向量 $2$-范数诱导的算子 $2$-范数。条件数 $\\kappa_{2}(A)$ 定义为 $A$ 的最大奇异值与最小奇异值之比，它量化了解对扰动的敏感度。\n\n浮点算术中舍入的一个基本模型假设，对于 $\\circ \\in \\{+, -, \\times, \\div\\}$，一个计算出的基本运算 $\\operatorname{fl}(x \\circ y)$ 满足 $\\operatorname{fl}(x \\circ y) = (x \\circ y)(1 + \\delta)$，其中某个 $\\delta$ 满足 $|\\delta| \\leq u$，$u$ 是单位舍入误差。在此模型下，对于后向稳定算法（如带部分主元的高斯消元法），后向误差通常很小，但前向误差仍可能因问题的条件数而被放大。显式构造逆矩阵 $A^{-1}$ 然后计算 $x = A^{-1} b$ 的操作，已知劣于通过后向稳定求解器直接求解 $A x = b$，特别是对于病态矩阵。这是因为映射 $A \\mapsto A^{-1}$ 本身高度敏感，会在误差传播到与 $b$ 的乘积之前就将其放大。\n\n您的任务是实现一个程序，对求解 $A x = b$ 的两种计算方法进行有原则的比较，使用一个用于探测良态、中度病态、近奇异和经典病态情况的矩阵测试套件：\n\n- 方法 $\\text{inv32}$：以单精度形式构造 $\\hat{A}^{-1}$（将 $A$ 舍入为单精度并在单精度下求逆），然后返回 $\\hat{x}_{\\text{inv32}} = \\hat{A}^{-1} b$（在形成 $\\hat{A}^{-1}$ 后，乘积运算可以在双精度下进行）。\n- 方法 $\\text{solve64}$：使用后向稳定求解器在双精度下直接求解 $A x = b$。\n\n为了能精确计算前向误差，您必须使用精确有理数算术得到 $x$，即通过在有理数域上执行带行主元的高斯消元法，从而将 $x$ 精确地计算为有理数向量，然后再转换为浮点数以进行误差评估。使用以下测试套件，其中 $A$ 和 $b$ 的所有元素都必须首先被视为精确有理数，以获得精确解：\n\n1. 良态对称正定情况：\n   $$A_{1} = \\begin{bmatrix} 4  1  0 \\\\ 1  3  1 \\\\ 0  1  2 \\end{bmatrix}, \\quad b_{1} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}.$$\n2. 节点为 $1, 2, 3, 4$ 的中度病态 Vandermonde 情况：\n   $$A_{2}(i,j) = i^{j-1} \\text{ for } i \\in \\{1,2,3,4\\}, \\ j \\in \\{1,2,3,4\\}, \\quad b_{2} = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}.$$\n3. 带有有理数扰动 $\\varepsilon = 10^{-12}$ 的近奇异 $2 \\times 2$ 情况：\n   $$A_{3} = \\begin{bmatrix} 1  1 \\\\ 1  1 + \\varepsilon \\end{bmatrix}, \\quad b_{3} = \\begin{bmatrix} 2 \\\\ 2 + \\varepsilon \\end{bmatrix}, \\quad \\varepsilon = \\frac{1}{10^{12}}.$$\n   此选择产生的精确解为 $x = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$，即使 $A_{3}$ 近奇异，该解也与一个良态方向对齐。\n4. 经典的 $6$ 维病态 Hilbert 情况：\n   $$A_{4}(i,j) = \\frac{1}{i + j - 1} \\text{ for } i,j \\in \\{1,2,3,4,5,6\\}, \\quad b_{4} = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}.$$\n\n对于每个测试用例，执行以下步骤：\n\n- 使用有理数高斯消元法（带部分主元）对增广系统 $[A \\mid b]$ 进行计算，得到精确解 $x$，其中所有算术运算都在有理数域上精确执行。\n- 计算 $\\hat{x}_{\\text{inv32}}$：将 $A$ 转换为单精度，在单精度下计算其逆矩阵，然后乘以 $b$（其结果在评估时转换为双精度）。\n- 通过在双精度下直接求解 $A x = b$ 来计算 $\\hat{x}_{\\text{solve64}}$。\n- 计算每种方法的前向误差 $\\frac{\\Vert \\hat{x}_{\\text{inv32}} - x \\Vert_{2}}{\\Vert x \\Vert_{2}}$ 和 $\\frac{\\Vert \\hat{x}_{\\text{solve64}} - x \\Vert_{2}}{\\Vert x \\Vert_{2}}$。\n- 计算后向误差 $\\frac{\\Vert b - A \\hat{x}_{\\text{inv32}} \\Vert_{2}}{\\Vert A \\Vert_{2} \\Vert \\hat{x}_{\\text{inv32}} \\Vert_{2}}$ 和 $\\frac{\\Vert b - A \\hat{x}_{\\text{solve64}} \\Vert_{2}}{\\Vert A \\Vert_{2} \\Vert \\hat{x}_{\\text{solve64}} \\Vert_{2}}$ 作为参考（这些不必包含在最终输出中，但必须计算以确保比较的科学真实性）。\n- 定义基于逆矩阵的方法相对于直接求解法的观测前向误差放大因子为\n  $$\\rho = \\frac{\\frac{\\Vert \\hat{x}_{\\text{inv32}} - x \\Vert_{2}}{\\Vert x \\Vert_{2}}}{\\frac{\\Vert \\hat{x}_{\\text{solve64}} - x \\Vert_{2}}{\\Vert x \\Vert_{2}}}.$$\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个浮点数代表一个测试用例的 $\\rho$ 值，顺序与上述列表一致。例如，最终输出格式必须严格如下所示\n$$[\\rho_{1},\\rho_{2},\\rho_{3},\\rho_{4}].$$\n不应打印任何其他文本。不涉及角度。不涉及物理单位。所有计算都必须使用向量 $2$-范数和矩阵算子 $2$-范数（谱范数）。程序必须完全自包含：它必须定义测试套件，计算精确有理数解，执行数值计算，并打印所需的列表。",
            "solution": "任务是比较求解 $A x = b$ 的两种方法的前向误差和后向误差：显式构造 $A^{-1}$ 并与 $b$ 相乘，对比使用后向稳定求解器直接求解系统。此比较应基于原则和定义。\n\n我们从基本定义开始。对于一个计算解 $\\hat{x}$，前向误差为 $\\frac{\\Vert \\hat{x} - x \\Vert_{2}}{\\Vert x \\Vert_{2}}$，其中 $x$ 是精确解。后向误差作为残差质量的度量，为 $\\frac{\\Vert b - A \\hat{x} \\Vert_{2}}{\\Vert A \\Vert_{2} \\Vert \\hat{x} \\Vert_{2}}$。算子 $2$-范数 $\\Vert A \\Vert_{2}$ 是 $A$ 的最大奇异值，条件数 $\\kappa_{2}(A)$ 是最大奇异值与最小奇异值之比。奇异值分解 (singular value decomposition, SVD) 将 $A$ 表示为 $A = U \\Sigma V^{\\top}$，其中 $U$ 和 $V$ 是正交矩阵，$\\Sigma$ 是包含奇异值 $\\sigma_{1} \\geq \\sigma_{2} \\geq \\cdots \\geq \\sigma_{n}  0$ 的对角矩阵。那么 $\\Vert A \\Vert_{2} = \\sigma_{1}$，最小奇异值为 $\\sigma_{n}$。\n\n后向稳定算法产生的 $\\hat{x}$ 满足 $A \\hat{x}$ 等于某个邻近矩阵 $\\tilde{A} = A + \\Delta A$ 的 $b$，其中 $\\frac{\\Vert \\Delta A \\Vert_{2}}{\\Vert A \\Vert_{2}}$ 很小（在单位舍入误差的量级上）。在此模型下，前向误差和后向误差通过条件数相关联，对于适定问题，通常遵循形如 $\\frac{\\Vert \\hat{x} - x \\Vert_{2}}{\\Vert x \\Vert_{2}} \\lesssim \\kappa_{2}(A) \\cdot \\text{(后向误差)}$ 的界。显式计算 $A^{-1}$ 的操作往往比直接求解 $A x = b$ 更差，因为它首先计算一个对象 $A^{-1}$，其相对误差本身被 $\\kappa_{2}(A)$ 放大，随后再乘以 $b$，从而加剧了误差放大，并可能引入与小奇异值相关的方向上的分量。\n\n为了进行科学上可靠且可测试的比较，我们必须以精确解 $x$ 为基准来衡量前向误差。由于浮点算术不能直接提供精确值，我们在精确有理数算术中构造 $x$。这可以通过在有理数域上执行高斯消元法来实现：每个算术运算都使用有理数完成，确保了对于非奇异矩阵 $A$ 的精确解。具体来说，我们用有理数项构建增广矩阵 $[A \\mid b]$，执行行主元选择以避免零主元，并应用消元法化简为行简化阶梯形。所得的最右列即为有理数形式的精确解 $x$，然后可以将其转换为实数以进行范数计算。\n\n每个测试用例的算法步骤：\n\n1. 将 $A$ 和 $b$ 构造为有理数。对于整数项，它们是分母为 $1$ 的分数。对于 Hilbert 矩阵，其元素为有理数 $\\frac{1}{i + j - 1}$，可以精确表示。对于近奇异情况，我们设 $\\varepsilon = \\frac{1}{10^{12}}$。\n2. 对 $[A \\mid b]$ 执行精确的带行主元的高斯消元法：\n   - 对于 $i = 1, \\dots, n$，选择一个主元行 $p \\geq i$，其在第 $i$ 列具有最大绝对值，以避免除以小数；交换行 $i$ 和 $p$。\n   - 通过除以主元元素来归一化第 $i$ 行。\n   - 使用精确算术将所有其他行中第 $i$ 列的元素消为零：对于第 $k$ 行，减去 $\\text{因子} \\times \\text{行 } i$。\n   - 消元完成后，解向量的元素即为最后一列的值。\n3. 将有理数精确解转换为浮点数以进行范数计算。\n4. 计算 $\\hat{x}_{\\text{inv32}}$：\n   - 将 $A$ 转换为单精度，即将每个元素舍入为 $32$ 位浮点数。\n   - 在单精度下计算逆矩阵：$\\hat{A}^{-1}$。\n   - 将 $\\hat{A}^{-1}$ 乘以 $b$（在形成 $\\hat{A}^{-1}$ 后，允许在双精度下进行乘法运算）。\n5. 使用后向稳定的直接求解法在双精度下计算 $\\hat{x}_{\\text{solve64}}$。\n6. 计算两种方法的前向误差：$\\frac{\\Vert \\hat{x}_{\\text{inv32}} - x \\Vert_{2}}{\\Vert x \\Vert_{2}}$ 和 $\\frac{\\Vert \\hat{x}_{\\text{solve64}} - x \\Vert_{2}}{\\Vert x \\Vert_{2}}$。\n7. 计算两种方法的后向误差：$\\frac{\\Vert b - A \\hat{x}_{\\text{inv32}} \\Vert_{2}}{\\Vert A \\Vert_{2} \\Vert \\hat{x}_{\\text{inv32}} \\Vert_{2}}$ 和 $\\frac{\\Vert b - A \\hat{x}_{\\text{solve64}} \\Vert_{2}}{\\Vert A \\Vert_{2} \\Vert \\hat{x}_{\\text{solve64}} \\Vert_{2}}$。这些量提供了背景信息：即使对于病态问题前向误差被放大，直接求解法的后向误差也应该很小，而显式构造逆矩阵会极大地放大前向误差。\n8. 报告基于逆矩阵的方法相对于直接求解法的观测前向误差放大因子：\n   $$\\rho = \\frac{\\frac{\\Vert \\hat{x}_{\\text{inv32}} - x \\Vert_{2}}{\\Vert x \\Vert_{2}}}{\\frac{\\Vert \\hat{x}_{\\text{solve64}} - x \\Vert_{2}}{\\Vert x \\Vert_{2}}}.$$\n\n解释：\n- 对于良态矩阵 $A$，两种方法都应具有小的前向误差，$\\rho$ 应接近 $1$，尽管单精度求逆仍可能使 $\\rho$ 略大于 $1$。\n- 对于中度病态的 $A$，随着求逆的敏感性增加其对舍入的脆弱性，$\\rho$ 可能会增大。\n- 对于近奇异情况，所选的 $b$ 产生一个与稳定方向对齐的精确解，因此尽管矩阵近奇异，直接求解法的前向误差仍可以保持很小。然而，在低精度下显式构造 $A^{-1}$ 可能会引入不稳定方向上的大分量，从而导致较大的 $\\rho$。\n- 对于经典的病态 Hilbert 情况，预计在低精度下基于逆矩阵的方法会表现出灾难性的误差放大，产生非常大的 $\\rho$，尽管直接求解法保持了较小的后向误差。\n\n最终输出必须是列表 $[\\rho_{1}, \\rho_{2}, \\rho_{3}, \\rho_{4}]$，并严格以这种单行、逗号分隔、方括号括起的格式打印。这将为四种情况中的每一种情况产生可量化的浮点数，涵盖了理想情况（良态情况）、中度病态、近奇异的边界情况，以及一个严重病态的边缘案例。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom fractions import Fraction\n\ndef gaussian_elimination_exact(A_frac, b_frac):\n    \"\"\"\n    Solve A x = b exactly using Gaussian elimination over rationals.\n    A_frac: list of lists of Fraction, shape (n, n)\n    b_frac: list of Fraction, length n\n    Returns: list of Fraction x of length n\n    \"\"\"\n    n = len(A_frac)\n    # Build augmented matrix [A | b]\n    M = [row[:] + [b_frac[i]] for i, row in enumerate(A_frac)]\n    # Perform Gaussian elimination with partial pivoting\n    for i in range(n):\n        # Pivot selection: choose row with largest absolute value in column i\n        pivot_row = i\n        pivot_val = abs(M[i][i])\n        for r in range(i+1, n):\n            if abs(M[r][i])  pivot_val:\n                pivot_val = abs(M[r][i])\n                pivot_row = r\n        if pivot_val == 0:\n            raise ValueError(\"Matrix is singular in exact arithmetic.\")\n        # Swap to put pivot_row at i\n        if pivot_row != i:\n            M[i], M[pivot_row] = M[pivot_row], M[i]\n        # Normalize pivot row\n        pivot = M[i][i]\n        # Divide entire row i by pivot\n        for j in range(i, n+1):\n            M[i][j] = M[i][j] / pivot\n        # Eliminate column i in all other rows\n        for k in range(n):\n            if k == i:\n                continue\n            factor = M[k][i]\n            if factor != 0:\n                for j in range(i, n+1):\n                    M[k][j] = M[k][j] - factor * M[i][j]\n    # After elimination, solution is in last column\n    x_frac = [M[i][n] for i in range(n)]\n    return x_frac\n\ndef to_float_matrix(A_frac):\n    \"\"\"Convert a Fraction matrix to a float64 numpy array.\"\"\"\n    n = len(A_frac)\n    m = len(A_frac[0])\n    A = np.zeros((n, m), dtype=np.float64)\n    for i in range(n):\n        for j in range(m):\n            A[i, j] = float(A_frac[i][j])\n    return A\n\ndef to_float_vector(b_frac):\n    \"\"\"Convert a Fraction vector to a float64 numpy array.\"\"\"\n    n = len(b_frac)\n    b = np.zeros(n, dtype=np.float64)\n    for i in range(n):\n        b[i] = float(b_frac[i])\n    return b\n\ndef build_test_cases():\n    cases = []\n    # Case 1: Well-conditioned SPD\n    A1 = [\n        [Fraction(4,1), Fraction(1,1), Fraction(0,1)],\n        [Fraction(1,1), Fraction(3,1), Fraction(1,1)],\n        [Fraction(0,1), Fraction(1,1), Fraction(2,1)],\n    ]\n    b1 = [Fraction(1,1), Fraction(2,1), Fraction(3,1)]\n    cases.append((A1, b1))\n    # Case 2: Vandermonde with nodes 1,2,3,4\n    nodes = [Fraction(1,1), Fraction(2,1), Fraction(3,1), Fraction(4,1)]\n    A2 = []\n    for i in range(4):\n        row = []\n        for j in range(4):\n            # i-th node to the power j\n            row.append(nodes[i] ** j)\n        A2.append(row)\n    b2 = [Fraction(1,1), Fraction(1,1), Fraction(1,1), Fraction(1,1)]\n    cases.append((A2, b2))\n    # Case 3: Nearly singular 2x2 with epsilon = 1/10^12\n    eps = Fraction(1, 10**12)\n    A3 = [\n        [Fraction(1,1), Fraction(1,1)],\n        [Fraction(1,1), Fraction(1,1) + eps],\n    ]\n    b3 = [Fraction(2,1), Fraction(2,1) + eps]\n    cases.append((A3, b3))\n    # Case 4: Hilbert 6x6\n    A4 = []\n    for i in range(1, 7):\n        row = []\n        for j in range(1, 7):\n            row.append(Fraction(1, i + j - 1))\n        A4.append(row)\n    b4 = [Fraction(1,1) for _ in range(6)]\n    cases.append((A4, b4))\n    return cases\n\ndef relative_forward_error(x_hat, x_exact):\n    num = np.linalg.norm(x_hat - x_exact, ord=2)\n    den = np.linalg.norm(x_exact, ord=2)\n    return num / den\n\ndef relative_backward_error(A, x_hat, b):\n    # spectral norm for A\n    A_norm2 = np.linalg.norm(A, ord=2)\n    r = b - A @ x_hat\n    r_norm = np.linalg.norm(r, ord=2)\n    xhat_norm = np.linalg.norm(x_hat, ord=2)\n    return r_norm / (A_norm2 * xhat_norm)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = build_test_cases()\n\n    results = []\n    for A_frac, b_frac in test_cases:\n        # Exact solution via rational elimination\n        x_exact_frac = gaussian_elimination_exact(A_frac, b_frac)\n        x_exact = to_float_vector(x_exact_frac)\n\n        # Convert A and b to float64 for numerical computation\n        A64 = to_float_matrix(A_frac)\n        b64 = to_float_vector(b_frac)\n\n        # Approach inv32: invert A in float32 and multiply by b\n        A32 = A64.astype(np.float32)\n        try:\n            Ainv32 = np.linalg.inv(A32)\n        except np.linalg.LinAlgError:\n            # If singular in float32, set Ainv32 to nan to propagate\n            Ainv32 = np.full_like(A32, np.nan, dtype=np.float32)\n        # Multiply in float64 after casting inverse back to float64\n        x_inv32 = Ainv32.astype(np.float64) @ b64\n\n        # Approach solve64: direct solve in float64\n        try:\n            x_solve64 = np.linalg.solve(A64, b64)\n        except np.linalg.LinAlgError:\n            # If singular (should not happen for given cases), set to nan\n            x_solve64 = np.full_like(b64, np.nan, dtype=np.float64)\n\n        # Compute forward errors\n        fwd_inv32 = relative_forward_error(x_inv32, x_exact)\n        fwd_solve64 = relative_forward_error(x_solve64, x_exact)\n\n        # Compute backward errors (not printed, but computed for scientific context)\n        bwd_inv32 = relative_backward_error(A64, x_inv32, b64)\n        bwd_solve64 = relative_backward_error(A64, x_solve64, b64)\n\n        # Observed forward-error magnification factor relative to direct solve\n        if fwd_solve64 == 0:\n            rho = float('inf')\n        else:\n            rho = fwd_inv32 / fwd_solve64\n\n        # Optionally, one could check or log backward errors to ensure they are small,\n        # but per instructions we only output rho values.\n        results.append(rho)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}