{
    "hands_on_practices": [
        {
            "introduction": "Mastering any mathematical tool begins with its fundamental definition. This first exercise provides straightforward practice in computing the Frobenius norm directly from the elements of a matrix. By working through this calculation, you will build a concrete intuition for the norm as a measure of the matrix's overall \"magnitude.\"",
            "id": "1033975",
            "problem": "Compute the Frobenius norm of the matrix $D = \\begin{bmatrix} 1 & 0 & -1 \\\\ 2 & 1 & 0 \\end{bmatrix}$. The Frobenius norm for a matrix $A \\in \\mathbb{R}^{m \\times n}$ is defined as $\\|A\\|_F = \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n} |a_{ij}|^2}$. Express the result in exact form.",
            "solution": "1. The Frobenius norm of $D\\in\\mathbb{R}^{m\\times n}$ is defined by\n\n$$\n\\|D\\|_F = \\sqrt{\\sum_{i=1}^m\\sum_{j=1}^n |d_{ij}|^2}.\n$$\n\n2. For \n\n$$\nD=\\begin{bmatrix}1 & 0 & -1\\\\2 & 1 & 0\\end{bmatrix},\n$$\n\nthe entries squared sum to\n\n$$\n1^2 + 0^2 + (-1)^2 + 2^2 + 1^2 + 0^2\n=1 + 0 + 1 + 4 + 1 + 0\n=7.\n$$\n\n3. Hence,\n\n$$\n\\|D\\|_F = \\sqrt{7}.\n$$",
            "answer": "$$\\boxed{\\sqrt{7}}$$"
        },
        {
            "introduction": "While the element-wise definition is intuitive, the true power of the Frobenius norm in numerical linear algebra is revealed through its deep connection to singular values. This practice guides you through the derivation of the identity $\\|A\\|_F^2 = \\sum_i \\sigma_i^2$, a cornerstone result linking a matrix's structure to its spectral properties. Understanding this relationship is crucial for applications ranging from low-rank approximation to data analysis .",
            "id": "3547391",
            "problem": "Let $A \\in \\mathbb{R}^{m \\times n}$ have rank $r$ with singular value decomposition (SVD) given by $A = U \\Sigma V^{\\top}$, where $U \\in \\mathbb{R}^{m \\times m}$ and $V \\in \\mathbb{R}^{n \\times n}$ are orthogonal, and $\\Sigma \\in \\mathbb{R}^{m \\times n}$ is diagonal with nonnegative diagonal entries $\\sigma_{1} \\ge \\sigma_{2} \\ge \\cdots \\ge \\sigma_{r} > 0$ followed by zeros. For a fixed integer $k$ satisfying $1 \\le k \\le r$, define the rank-$k$ truncated approximation $A_{k} := U \\Sigma_{k} V^{\\top}$, where $\\Sigma_{k}$ is obtained from $\\Sigma$ by retaining only its top $k$ diagonal entries and setting all other diagonal entries to $0$. \n\nStarting only from fundamental definitions and widely used facts in linear algebra, including:\n- the definition of the Frobenius norm $\\|A\\|_{F} = \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n} a_{ij}^{2}}$,\n- the definition of the trace operator $\\mathrm{trace}(\\cdot)$, and its cyclic invariance $\\mathrm{trace}(XYZ) = \\mathrm{trace}(ZXY)$ whenever products are defined,\n- the orthogonality of $U$ and $V$ so that $U^{\\top} U = I$ and $V^{\\top} V = I$,\n\ndo the following:\n- Explain, via a derivation grounded in these principles, how truncating the SVD from $A$ to $A_{k}$ affects the Frobenius norm, including a justification for a Pythagorean-type decomposition of $\\|A\\|_{F}^{2}$ into a sum of squares associated with $A_{k}$ and the residual $A - A_{k}$.\n- Compute the Frobenius norm $\\|A_{k}\\|_{F}$ explicitly in terms of the singular values $\\sigma_{1}, \\ldots, \\sigma_{r}$ and the truncation level $k$.\n\nYour final answer must be a single closed-form analytic expression in terms of $\\sigma_{1}, \\ldots, \\sigma_{r}$ and $k$. No numerical evaluation is required, and no rounding is necessary. Express the final answer without any units.",
            "solution": "The problem is found to be valid as it is scientifically grounded, well-posed, objective, and internally consistent, representing a standard exercise in numerical linear algebra. We proceed with the derivation as requested.\n\nOur starting point is the relationship between the Frobenius norm of a matrix $A \\in \\mathbb{R}^{m \\times n}$ and the trace operator. The square of the Frobenius norm is defined as the sum of the squares of all its elements:\n$$\n\\|A\\|_{F}^{2} = \\sum_{i=1}^{m} \\sum_{j=1}^{n} a_{ij}^{2}\n$$\nThe trace of a square matrix is the sum of its diagonal elements. Consider the matrix product $A^{\\top} A$, which is an $n \\times n$ matrix. The element in the $j$-th row and $j$-th column of this product is given by:\n$$\n(A^{\\top} A)_{jj} = \\sum_{i=1}^{m} (A^{\\top})_{ji} A_{ij} = \\sum_{i=1}^{m} a_{ij} a_{ij} = \\sum_{i=1}^{m} a_{ij}^{2}\n$$\nThe trace of $A^{\\top} A$ is the sum of these diagonal elements:\n$$\n\\mathrm{trace}(A^{\\top} A) = \\sum_{j=1}^{n} (A^{\\top} A)_{jj} = \\sum_{j=1}^{n} \\sum_{i=1}^{m} a_{ij}^{2}\n$$\nBy comparing this with the definition of the Frobenius norm, we establish the fundamental identity:\n$$\n\\|A\\|_{F}^{2} = \\mathrm{trace}(A^{\\top} A)\n$$\nWe now apply this identity to the singular value decomposition (SVD) of $A$, which is given as $A = U \\Sigma V^{\\top}$. The transpose of $A$ is $A^{\\top} = (U \\Sigma V^{\\top})^{\\top} = V \\Sigma^{\\top} U^{\\top}$. Substituting these into the trace expression:\n$$\n\\|A\\|_{F}^{2} = \\mathrm{trace}( (V \\Sigma^{\\top} U^{\\top}) (U \\Sigma V^{\\top}) )\n$$\nSince $U$ is an orthogonal matrix, $U^{\\top} U = I$, where $I$ is the $m \\times m$ identity matrix. The expression simplifies to:\n$$\n\\|A\\|_{F}^{2} = \\mathrm{trace}(V \\Sigma^{\\top} \\Sigma V^{\\top})\n$$\nUsing the cyclic property of the trace, $\\mathrm{trace}(XYZ) = \\mathrm{trace}(ZXY)$, we can reorder the matrices:\n$$\n\\|A\\|_{F}^{2} = \\mathrm{trace}(V^{\\top} V \\Sigma^{\\top} \\Sigma)\n$$\nSince $V$ is also an orthogonal matrix, $V^{\\top} V = I$, where $I$ is the $n \\times n$ identity matrix. This leads to:\n$$\n\\|A\\|_{F}^{2} = \\mathrm{trace}(\\Sigma^{\\top} \\Sigma)\n$$\nThe matrix $\\Sigma \\in \\mathbb{R}^{m \\times n}$ has non-negative real numbers $\\sigma_i$ on its main diagonal and zeros elsewhere. The matrix $\\Sigma^{\\top} \\Sigma$ is an $n \\times n$ diagonal matrix. Its diagonal entries are the squares of the singular values of $A$. Specifically, $(\\Sigma^{\\top} \\Sigma)_{ii} = \\sigma_{i}^{2}$ for $i=1, \\dots, \\min(m, n)$ and $(\\Sigma^{\\top} \\Sigma)_{ii} = 0$ for $i > \\min(m, n)$. Since the rank of $A$ is $r$, we know $\\sigma_i > 0$ for $i \\le r$ and $\\sigma_i = 0$ for $i > r$. The trace is the sum of these diagonal elements:\n$$\n\\|A\\|_{F}^{2} = \\sum_{i=1}^{r} \\sigma_{i}^{2}\n$$\nThis connects the Frobenius norm to the singular values of the matrix.\n\nNow, we analyze the effect of truncating the SVD. The rank-$k$ approximation is $A_k = U \\Sigma_k V^{\\top}$, and the residual is $A - A_k$. Let's examine the structure of the residual:\n$$\nA - A_k = U \\Sigma V^{\\top} - U \\Sigma_k V^{\\top} = U (\\Sigma - \\Sigma_k) V^{\\top}\n$$\nThe matrix $\\Sigma_k$ is formed by keeping the first $k$ singular values of $\\Sigma$ and setting the rest to zero. Thus, the matrix $\\Sigma - \\Sigma_k$ is a diagonal matrix (in the rectangular sense) whose diagonal entries are $0$ for indices $i=1, \\dots, k$ and $\\sigma_i$ for indices $i = k+1, \\dots, r$. The expression $U (\\Sigma - \\Sigma_k) V^{\\top}$ is the SVD of the residual matrix $A - A_k$, and its singular values are $\\{\\sigma_{k+1}, \\sigma_{k+2}, \\dots, \\sigma_r\\}$.\n\nTo justify the Pythagorean-type decomposition, we consider the square of the Frobenius norm of $A$:\n$$\n\\|A\\|_{F}^{2} = \\|A_k + (A - A_k)\\|_{F}^{2}\n$$\nThe Frobenius norm is induced by the Frobenius inner product, defined as $\\langle X, Y \\rangle_F = \\mathrm{trace}(X^{\\top} Y)$. For such norms, we have the property $\\|X+Y\\|_{F}^{2} = \\|X\\|_{F}^{2} + \\|Y\\|_{F}^{2} + 2\\langle X, Y \\rangle_F$. We need to show that $A_k$ and $A-A_k$ are orthogonal with respect to this inner product, i.e., $\\langle A_k, A - A_k \\rangle_F = 0$.\n$$\n\\langle A_k, A - A_k \\rangle_F = \\mathrm{trace}(A_k^{\\top} (A - A_k))\n$$\nSubstituting the SVD forms:\n$$\nA_k^{\\top}(A - A_k) = (U \\Sigma_k V^{\\top})^{\\top} (U (\\Sigma - \\Sigma_k) V^{\\top}) = (V \\Sigma_k^{\\top} U^{\\top}) (U (\\Sigma - \\Sigma_k) V^{\\top})\n$$\nUsing $U^{\\top} U = I$, this simplifies to $V \\Sigma_k^{\\top} (\\Sigma - \\Sigma_k) V^{\\top}$. Now we take the trace and apply the cyclic property:\n$$\n\\mathrm{trace}(V \\Sigma_k^{\\top} (\\Sigma - \\Sigma_k) V^{\\top}) = \\mathrm{trace}(V^{\\top} V \\Sigma_k^{\\top} (\\Sigma - \\Sigma_k)) = \\mathrm{trace}(\\Sigma_k^{\\top} (\\Sigma - \\Sigma_k))\n$$\nThe matrix product $\\Sigma_k^{\\top} (\\Sigma - \\Sigma_k)$ is a diagonal matrix. Its $i$-th diagonal element is the product of the $i$-th diagonal elements of $\\Sigma_k$ and $\\Sigma - \\Sigma_k$ (after transposing $\\Sigma_k$). The diagonal of $\\Sigma_k$ contains $\\{\\sigma_1, \\dots, \\sigma_k, 0, \\dots\\}$. The diagonal of $\\Sigma-\\Sigma_k$ contains $\\{0, \\dots, 0, \\sigma_{k+1}, \\dots, \\sigma_r, 0, \\dots\\}$. For any index $i$, either the $i$-th entry of $\\Sigma_k$'s diagonal is zero (for $i>k$) or the $i$-th entry of $(\\Sigma-\\Sigma_k)$'s diagonal is zero (for $i \\le k$). Thus, their product is always zero. The matrix $\\Sigma_k^{\\top} (\\Sigma - \\Sigma_k)$ is the zero matrix, and its trace is $0$.\nSince $\\langle A_k, A - A_k \\rangle_F = 0$, the Pythagorean-type relation holds:\n$$\n\\|A\\|_{F}^{2} = \\|A_k\\|_{F}^{2} + \\|A - A_k\\|_{F}^{2}\n$$\nThis decomposition shows that the squared Frobenius norm of $A$ is partitioned between its rank-$k$ approximation and the residual.\n\nFinally, we compute the Frobenius norm of $A_k$ explicitly. The derivation is identical to the one for $\\|A\\|_F$. We use the identity $\\|A_k\\|_{F}^{2} = \\mathrm{trace}(A_k^{\\top} A_k)$.\n$$\n\\|A_k\\|_{F}^{2} = \\mathrm{trace}((U \\Sigma_k V^{\\top})^{\\top} (U \\Sigma_k V^{\\top})) = \\mathrm{trace}(V \\Sigma_k^{\\top} U^{\\top} U \\Sigma_k V^{\\top})\n$$\nUsing $U^{\\top}U = I$ and the cyclic property of the trace with $V^{\\top}V = I$:\n$$\n\\|A_k\\|_{F}^{2} = \\mathrm{trace}(V \\Sigma_k^{\\top} \\Sigma_k V^{\\top}) = \\mathrm{trace}(\\Sigma_k^{\\top} \\Sigma_k)\n$$\nThe matrix $\\Sigma_k^{\\top} \\Sigma_k$ is an $n \\times n$ diagonal matrix with diagonal entries $\\sigma_1^2, \\dots, \\sigma_k^2$, followed by zeros. The trace is the sum of these diagonal entries:\n$$\n\\|A_k\\|_{F}^{2} = \\sum_{i=1}^{k} \\sigma_{i}^{2}\n$$\nTaking the square root gives the Frobenius norm of the rank-$k$ approximation:\n$$\n\\|A_k\\|_{F} = \\sqrt{\\sum_{i=1}^{k} \\sigma_{i}^{2}}\n$$\nThis expression is the final answer sought.",
            "answer": "$$\n\\boxed{\\sqrt{\\sum_{i=1}^{k} \\sigma_{i}^{2}}}\n$$"
        },
        {
            "introduction": "Building upon the connection between the Frobenius norm and singular values, we can now address a fundamental question in numerical stability: how \"far\" is a given full-rank matrix from being singular? This problem  applies the celebrated Eckart–Young–Mirsky theorem to find the smallest perturbation, as measured by the Frobenius norm, that reduces a matrix's rank. This exercise provides a tangible, geometric interpretation of the smallest singular value as a measure of a matrix's robustness against perturbations.",
            "id": "1397974",
            "problem": "In many fields, such as data analysis and control theory, a system's behavior is modeled by a matrix. The rank of this matrix is a fundamental property, and its stability is often related to how much the matrix can be perturbed before its rank changes. The size of such a perturbation can be quantified using various matrix norms.\n\nConsider a linear transformation represented by the matrix $A = \\begin{pmatrix} 3 & 1 \\\\ 0 & 3 \\end{pmatrix}$. This transformation maps vectors in a 2-dimensional space to another 2-dimensional space. The matrix $A$ is of full rank. We are interested in finding the smallest possible perturbation to this matrix that would result in a transformation that is no longer of full rank (i.e., has a rank of 1 or 0).\n\nLet $E$ be a $2 \\times 2$ perturbation matrix. The magnitude of this perturbation is measured by the Frobenius norm, defined as $\\|E\\|_F = \\sqrt{\\sum_{i=1}^2 \\sum_{j=1}^2 |E_{ij}|^2}$.\n\nDetermine the exact value of the minimum Frobenius norm, $\\min \\|E\\|_F$, such that the perturbed matrix $A+E$ has a rank of at most 1. Express your answer as a single, closed-form analytic expression.",
            "solution": "We seek the minimum Frobenius norm of a perturbation $E$ such that $\\operatorname{rank}(A+E) \\leq 1$ for $A=\\begin{pmatrix}3 & 1 \\\\ 0 & 3\\end{pmatrix}$. Equivalently, this is the distance (in Frobenius norm) from $A$ to the set of matrices of rank at most $1$. By the Eckart–Young–Mirsky theorem for unitarily invariant norms, the distance from $A$ to the set of matrices of rank at most $1$ in the Frobenius norm equals the square root of the sum of squares of all singular values of $A$ except the largest one. For a $2 \\times 2$ matrix, this minimum is the smaller singular value $\\sigma_{2}$.\n\nThus, we compute the singular values of $A$. The singular values are the square roots of the eigenvalues of $A^{T}A$. First compute\n$$\nA^{T}A=\\begin{pmatrix}3 & 0 \\\\ 1 & 3\\end{pmatrix}\\begin{pmatrix}3 & 1 \\\\ 0 & 3\\end{pmatrix}\n=\\begin{pmatrix}9 & 3 \\\\ 3 & 10\\end{pmatrix}.\n$$\nLet $\\lambda$ be an eigenvalue of $A^{T}A$. The characteristic polynomial is\n$$\n\\det\\!\\left(\\begin{pmatrix}9 & 3 \\\\ 3 & 10\\end{pmatrix}-\\lambda I\\right)\n=(9-\\lambda)(10-\\lambda)-9\n=\\lambda^{2}-19\\lambda+81.\n$$\nThe discriminant is\n$$\n\\Delta=19^{2}-4\\cdot 81=361-324=37,\n$$\nso the eigenvalues are\n$$\n\\lambda_{\\pm}=\\frac{19\\pm\\sqrt{37}}{2}.\n$$\nTherefore, the singular values are\n$$\n\\sigma_{1}=\\sqrt{\\frac{19+\\sqrt{37}}{2}},\\qquad \\sigma_{2}=\\sqrt{\\frac{19-\\sqrt{37}}{2}}.\n$$\nBy the Eckart–Young–Mirsky theorem for the Frobenius norm, the minimum Frobenius norm of a perturbation $E$ such that $\\operatorname{rank}(A+E)\\leq 1$ equals $\\sigma_{2}$. Hence\n$$\n\\min\\|E\\|_{F}=\\sqrt{\\frac{19-\\sqrt{37}}{2}}.\n$$",
            "answer": "$$\\boxed{\\sqrt{\\frac{19-\\sqrt{37}}{2}}}$$"
        }
    ]
}