{
    "hands_on_practices": [
        {
            "introduction": "GPU的性能核心在于其流式多处理器（SM）的有效利用。占用率（Occupancy）是衡量SM上活动线程束（warps）比例的关键指标，它直接影响到硬件隐藏指令和内存延迟的能力。通过本练习 ()，您将学习如何根据一个计算地球力学内核的资源需求（如寄存器和共享内存）来计算其理论占用率，这是诊断和优化GPU代码性能的第一步。",
            "id": "3529483",
            "problem": "一个用于大规模盆地模型的三维多孔弹性有限元组装核函数被移植到图形处理器（GPU）上，以加速单元级刚度矩阵和耦合矩阵的计算。每个线程更新一个高斯点状态，并在进行线程束同步规约之前，在共享内存中累加贡献值。由于本构更新和张量代数，该核函数每个线程使用 $R_{t}=64$ 个寄存器。每个线程块的暂存区存储形函数梯度、局部矩阵和累加器，每个线程块需要 $S_{b}=48\\ \\mathrm{kB}$ 的共享内存。GPU的每个流式多处理器（SM）的资源限制为：每个SM最多 $R_{\\max}=64\\times 1024$ 个寄存器，每个SM最多 $S_{\\max}=100\\ \\mathrm{kB}$ 共享内存，以及每个SM最多 $T_{\\max}=2048$ 个线程。假设线程以大小为 $W=32$ 的线程束（warp）进行调度，并且核函数以每个线程块 $B_{t}=256$ 个线程启动。假设每个SM上并发线程块的架构上限足够大，对此核函数不构成限制，并且资源分配没有超出所述数量的粒度开销。使用 $1\\ \\mathrm{kB}=1024\\ \\mathrm{B}$。\n\n仅根据以下基本资源约束：(i) 一个SM上所有驻留线程块使用的总寄存器数不能超过 $R_{\\max}$，(ii) 一个SM上所有驻留线程块使用的总共享内存不能超过 $S_{\\max}$，以及 (iii) 一个SM上的总驻留线程数不能超过 $T_{\\max}$，计算每个SM上驻留线程块的最大数量以及由此产生的占用率。将占用率定义为活动线程束数量与每个SM上最大可能线程束数量的比值，并将占用率以精确小数形式表示。最终答案以两个值的形式给出，顺序为：每个SM的最大驻留线程块数，占用率。无需四舍五入，最终答案不应包含单位。",
            "solution": "该问题陈述已经过严格验证，被认为是科学上合理、适定、客观和完整的。所有用于确定GPU流式多处理器（SM）上驻留线程块的最大数量及由此产生的占用率的必要参数均已提供。该问题是GPU性能分析中的一个标准练习，设置在一个合理的计算地球力学背景中。\n\n目标是计算每个SM上并发线程块的最大数量，记为 $N_{B, \\text{max}}$，以及相应的理论占用率 $\\mathcal{O}$。线程块的最大数量受SM有限资源的限制，即寄存器、共享内存和线程调度能力。我们必须分别计算每种资源单独支持的最大线程块数，然后取这些值中的最小值作为总的最大值。\n\n问题给出的已知条件是：\n- 每个线程的寄存器数：$R_{t} = 64$\n- 每个线程块的共享内存：$S_{b} = 48\\ \\mathrm{kB}$\n- 每个线程块的线程数：$B_{t} = 256$\n- 每个SM的最大寄存器数：$R_{\\max} = 64 \\times 1024 = 65536$\n- 每个SM的最大共享内存：$S_{\\max} = 100\\ \\mathrm{kB}$\n- 每个SM的最大线程数：$T_{\\max} = 2048$\n- 线程束大小：$W = 32$\n\n设 $N_B$ 为单个SM上的驻留线程块数。\n\n首先，我们确定可用寄存器总数对 $N_B$ 的限制。一个线程块所需的总寄存器数是每个线程块的线程数与每个线程的寄存器数的乘积：\n$$R_{\\text{block}} = B_{t} \\times R_{t} = 256 \\times 64 = 16384\\ \\text{个寄存器}$$\n$N_B$ 个线程块所需的总寄存器数是 $N_B \\times R_{\\text{block}}$。该值不能超过SM的寄存器容量 $R_{\\max}$。\n$$N_B \\times R_{\\text{block}} \\le R_{\\max}$$\n因此，寄存器文件支持的最大线程块数 $N_{B, \\text{reg}}$ 为：\n$$N_{B, \\text{reg}} = \\left\\lfloor \\frac{R_{\\max}}{R_{\\text{block}}} \\right\\rfloor = \\left\\lfloor \\frac{65536}{16384} \\right\\rfloor = \\lfloor 4 \\rfloor = 4$$\n\n其次，我们确定共享内存容量施加的限制。每个线程块需要 $S_b = 48\\ \\mathrm{kB}$ 的共享内存。$N_B$ 个线程块所需的总共享内存为 $N_B \\times S_b$。该值不能超过SM的共享内存容量 $S_{\\max}$。\n$$N_B \\times S_b \\le S_{\\max}$$\n共享内存支持的最大线程块数 $N_{B, \\text{smem}}$ 为：\n$$N_{B, \\text{smem}} = \\left\\lfloor \\frac{S_{\\max}}{S_b} \\right\\rfloor = \\left\\lfloor \\frac{100\\ \\mathrm{kB}}{48\\ \\mathrm{kB}} \\right\\rfloor = \\lfloor 2.0833... \\rfloor = 2$$\n\n第三，我们确定最大驻留线程数施加的限制。每个线程块包含 $B_t = 256$ 个线程。$N_B$ 个线程块的总线程数为 $N_B \\times B_t$。该值不能超过SM的线程容量 $T_{\\max}$。\n$$N_B \\times B_t \\le T_{\\max}$$\n线程调度器支持的最大线程块数 $N_{B, \\text{threads}}$ 为：\n$$N_{B, \\text{threads}} = \\left\\lfloor \\frac{T_{\\max}}{B_t} \\right\\rfloor = \\left\\lfloor \\frac{2048}{256} \\right\\rfloor = \\lfloor 8 \\rfloor = 8$$\n\n每个SM上驻留线程块的总的最大数量 $N_{B, \\text{max}}$ 是这三个限制中的最小值，因为所有约束必须同时满足。问题陈述指出，每个SM上线程块的架构上限不构成限制。\n$$N_{B, \\text{max}} = \\min(N_{B, \\text{reg}}, N_{B, \\text{smem}}, N_{B, \\text{threads}}) = \\min(4, 2, 8) = 2$$\n因此，最多有 $2$ 个线程块可以驻留在SM上，限制性资源是共享内存。\n\n接下来，我们计算占用率 $\\mathcal{O}$。占用率定义为活动线程束数量与每个SM上最大可能线程束数量的比值。\n$N_{B, \\text{max}}$ 个线程块的活动线程数为：\n$$T_{\\text{active}} = N_{B, \\text{max}} \\times B_t = 2 \\times 256 = 512\\ \\text{个线程}$$\n活动线程束数量是活动线程数除以线程束大小 $W$：\n$$W_{\\text{active}} = \\frac{T_{\\text{active}}}{W} = \\frac{512}{32} = 16\\ \\text{个线程束}$$\n一个SM能支持的最大线程束数量是最大线程数除以线程束大小：\n$$W_{\\max} = \\frac{T_{\\max}}{W} = \\frac{2048}{32} = 64\\ \\text{个线程束}$$\n占用率是这两个数量的比值：\n$$\\mathcal{O} = \\frac{W_{\\text{active}}}{W_{\\max}} = \\frac{16}{64} = \\frac{1}{4}$$\n或者，占用率也可以直接通过活动线程数与最大线程数的比值来计算：\n$$\\mathcal{O} = \\frac{T_{\\text{active}}}{T_{\\max}} = \\frac{N_{B, \\text{max}} \\times B_t}{T_{\\max}} = \\frac{2 \\times 256}{2048} = \\frac{512}{2048} = \\frac{1}{4}$$\n以小数表示，即为 $0.25$。\n\n最终结果是每个SM最多 $2$ 个驻留线程块，占用率为 $0.25$。",
            "answer": "$$\\boxed{\\begin{pmatrix} 2  0.25 \\end{pmatrix}}$$"
        },
        {
            "introduction": "在许多高性能计算应用中，真正的瓶颈并非计算本身，而是将数据从主机（CPU）传输到设备（GPU）的过程。内存类型和传输策略对整体性能有巨大影响。本实践 () 将引导您建立一个性能模型，用以量化分析锁页内存（pinned memory）与分页内存（pageable memory）的差异，并探索如何通过计算与传输的重叠来隐藏数据延迟。",
            "id": "3529491",
            "problem": "考虑一个大规模三维有限元法（FEM）岩土力学模拟中的全局刚度矩阵 $\\mathbf{K}$ 组装过程，其中单元贡献在图形处理器（GPU）上进行累加以加速组装。主机（中央处理器）准备大小为 $S$（单位为吉比字节，GiB）的逐块单元数据，这些数据通过带宽为 $B$（单位为吉比字节/秒，GiB/s）的外围组件快速互连（PCIe）总线传输到设备。传输可以使用页锁定（固定）或可分页的主机内存。当使用固定内存时，设备支持一次主机到设备的传输与一次核函数执行的重叠。假设页锁定主机内存支持直接内存访问（DMA），而可分页主机内存则强制通过带宽为 $H$（GiB/s）的主机内存子系统进行一次中转拷贝。设每次传输的固定延迟对于固定内存为 $L_{\\mathrm{pin}}$，对于可分页内存为 $L_{\\mathrm{pag}}$（单位均为秒）。设GPU核函数处理每块数据块的计算时间为 $C$（单位为秒），流水线中有 $N$ 个数据块。\n\n你必须从第一性原理出发，推导出一个性能模型，并将其实现为一个完整的、可运行的程序，用于预测以下场景的端到端执行时间：\n- 使用固定内存，并在GPU上传输和计算之间进行双缓冲重叠。\n- 使用可分页内存，由于缺乏真正的异步DMA传输，传输和计算之间没有重叠。\n\n你的推导必须仅基于以下核心定义和事实：\n- 带宽的定义，即单位时间内移动的数据量。\n- 一个具有固定延迟和持续吞吐量的传输，其行为类似于一个延迟加上一个摊销的传输时间，该时间由数据量除以持续带宽得出。\n- 一个两级流水线的调度规则，其中阶段持续时间分别为传输时间和计算时间，而重叠将稳态阶段持续时间缩短为两者中的最大值。\n- 可分页传输除了PCIe传输外，还需要在主机内存子系统中进行一次显式的中转拷贝，而固定传输则不需要。\n- 只有在使用固定内存时，传输和计算之间才可能发生重叠。\n\n从这些基础出发，推导出计算以下各项所需的表达式：\n1. 使用固定主机内存时，每个数据块的传输时间，以秒为单位。\n2. 使用可分页主机内存时，每个数据块的传输时间，以秒为单位。\n3. 使用固定内存和双缓冲重叠处理 $N$ 个数据块的总时间，以秒为单位，假设在任何时候只有一个传输与一个核函数执行重叠。\n4. 使用可分页内存且无重叠处理 $N$ 个数据块的总时间，以秒为单位。\n5. 在两级流水线中使用固定内存可实现的稳态重叠分数（以小数表示，而非百分比），定义为在每个稳态阶段中通过重叠消除的非重叠时间的比例。\n6. 一个布尔值指示符，用于判断重叠稳态是否为计算受限，其定义为在使用固定内存的情况下，每个数据块的核函数计算时间是否超过了每个数据块的传输时间。\n\n你的程序必须为每个测试用例计算以下输出：\n- 使用固定内存和重叠的总时间（秒）。\n- 使用可分页内存和无重叠的总时间（秒）。\n- 加速比（无量纲），定义为可分页时间与固定重叠时间的比值。\n- 稳态重叠分数（0到1之间的小数）。\n- 计算受限指示符（布尔值），如果计算在重叠稳态中主导传输，则为真，否则为假。\n\n所有时间必须以秒表示。不使用角度。不要使用百分号；重叠分数必须是小数。将所有浮点输出四舍五入到六位小数。\n\n测试套件：\n使用以下五个测试用例。每个用例是一个元组 $(B, H, S, C, N, L_{\\mathrm{pin}}, L_{\\mathrm{pag}})$，单位为 $(\\mathrm{GiB/s}, \\mathrm{GiB/s}, \\mathrm{GiB}, \\mathrm{s}, \\text{integer}, \\mathrm{s}, \\mathrm{s})$。\n\n- 用例 A（理想情况）：$(12.0, 20.0, 4.0, 0.5, 8, 5\\times 10^{-6}, 3\\times 10^{-5})$。\n- 用例 B（计算受限）：$(24.0, 50.0, 2.0, 2.0, 4, 5\\times 10^{-6}, 3\\times 10^{-5})$。\n- 用例 C（传输受限）：$(12.0, 20.0, 8.0, 0.1, 6, 5\\times 10^{-6}, 3\\times 10^{-5})$。\n- 用例 D（延迟可见的小传输）：$(24.0, 40.0, 0.01, 0.002, 100, 5\\times 10^{-6}, 3\\times 10^{-5})$。\n- 用例 E（平衡边界）：$(12.0, 40.0, 3.6, 0.3, 5, 5\\times 10^{-6}, 3\\times 10^{-5})$。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个Python风格的列表的列表形式的结果。每个内部列表必须按以下顺序排列：\n[total_time_pinned_overlap_seconds, total_time_pageable_seconds, speedup, overlap_fraction, compute_bound_boolean]\n例如：[[...用例 A 的结果...],[...用例 B 的结果...],...]。",
            "solution": "经评估，用户提供的问题是有效的。它在科学上基于高性能计算的原理，问题阐述清晰，参数完整且一致，并且陈述客观。该问题要求从第一性原理推导性能模型，这是计算科学中一个标准且有意义的任务。我们现在将进行推导和求解。\n\n问题的核心是为在GPU加速系统上，使用两种不同的内存管理和调度方案处理 $N$ 个数据块（每个大小为 $S$）所需的总时间建模。我们将从给定的定义中推导出必要的方程。\n\n**1. 逐块传输时间的推导**\n\n数据传输的总时间被建模为固定延迟与一个取决于数据大小和带宽的可变时间之和。\n\n**1.1. 固定内存传输时间 ($T_{\\mathrm{pin}}$)**\n对于页锁定（固定）主机内存，数据传输通过PCIe总线直接从主机RAM到GPU设备内存。这是一个直接内存访问（DMA）操作。\n给定条件：\n- 每个数据块的数据大小：$S$ (GiB)\n- PCIe 带宽：$B$ (GiB/s)\n- 固定内存传输延迟：$L_{\\mathrm{pin}}$ (s)\n\n以带宽 $B$ 移动数据量 $S$ 所需的时间为 $S/B$。一个数据块的总传输时间 $T_{\\mathrm{pin}}$ 是这个数据移动时间与固定延迟之和。\n$$ T_{\\mathrm{pin}} = L_{\\mathrm{pin}} + \\frac{S}{B} $$\n\n**1.2. 可分页内存传输时间 ($T_{\\mathrm{pag}}$)**\n对于可分页主机内存，直接DMA传输是不可行的。数据必须首先从可分页内存区域复制到主机RAM中的一个固定中转缓冲区。然后，该中转缓冲区用于向GPU进行DMA传输。此过程涉及两个串行的数据移动。\n给定条件：\n- 用于中转拷贝的主机内存子系统带宽：$H$ (GiB/s)\n- 用于向GPU传输的PCIe带宽：$B$ (GiB/s)\n- 可分页传输延迟（针对整个两步过程）：$L_{\\mathrm{pag}}$ (s)\n\n主机中转拷贝的时间是 $S/H$。随后的PCIe传输时间是 $S/B$。一个数据块的总传输时间 $T_{\\mathrm{pag}}$ 是这两个串行操作的时间与总延迟之和。\n$$ T_{\\mathrm{pag}} = L_{\\mathrm{pag}} + \\frac{S}{H} + \\frac{S}{B} $$\n\n**2. 总执行时间的推导**\n\n我们现在为两种场景建模处理所有 $N$ 个数据块的端到端时间。\n\n**2.1. 可分页内存（无重叠）**\n在此场景中，数据传输和计算之间没有重叠。对于 $N$ 个数据块中的每一个，传输必须在计算开始前完成。操作是严格顺序的。\n处理单个数据块的时间是其传输时间 $T_{\\mathrm{pag}}$ 和计算时间 $C$ 之和。\n$$ T_{\\mathrm{chunk,pag}} = T_{\\mathrm{pag}} + C $$\n由于这个过程对 $N$ 个数据块重复进行，总时间 $T_{\\mathrm{total,pag}}$ 就是单个数据块时间的 $N$ 倍。\n$$ T_{\\mathrm{total,pag}} = N \\times (T_{\\mathrm{pag}} + C) $$\n\n**2.2. 固定内存（有重叠）**\n此场景使用双缓冲、两级流水线来重叠数据传输和计算。两个阶段是：\n- 阶段1：传输，持续时间 $T_{\\mathrm{pin}}$。\n- 阶段2：计算，持续时间 $C$。\n\n在两级流水线中执行 $N$ 个任务的总时间由“流水线填充”时间、稳态执行和“流水线排空”时间决定。一个更简单等效的模型是计算第一个数据块完成的时间，然后加上剩余 $N-1$ 个数据块从流水线中出来的时间。\n\n第一个数据块被传输（时间 $T_{\\mathrm{pin}}$），然后进行计算（时间 $C$）。这些初始操作是顺序的，耗时 $T_{\\mathrm{pin}} + C$。在第一个数据块进行计算的同时，第二个数据块的传输可以并行进行。后续数据块完成的速率由流水线中最长的阶段决定，即 $\\max(T_{\\mathrm{pin}}, C)$。第一个数据块完全处理完后，对于剩下的 $N-1$ 个数据块，每隔 $\\max(T_{\\mathrm{pin}}, C)$ 秒就会有一个新的数据块完成处理。\n\n总时间 $T_{\\mathrm{total,pin}}$ 可以表示为：\n$$ T_{\\mathrm{total,pin}} = (T_{\\mathrm{pin}} + C) + (N-1) \\times \\max(T_{\\mathrm{pin}}, C) $$\n这可以通过注意到 $T_{\\mathrm{pin}} + C = \\min(T_{\\mathrm{pin}}, C) + \\max(T_{\\mathrm{pin}}, C)$ 来重写。\n$$ T_{\\mathrm{total,pin}} = \\min(T_{\\mathrm{pin}}, C) + \\max(T_{\\mathrm{pin}}, C) + (N-1) \\times \\max(T_{\\mathrm{pin}}, C) $$\n$$ T_{\\mathrm{total,pin}} = \\min(T_{\\mathrm{pin}}, C) + N \\times \\max(T_{\\mathrm{pin}}, C) $$\n这个表达式正确地模拟了总时间：其中一个过程（较短的那个）运行一个周期，而另一个过程（较长的那个，它决定了流水线的时钟频率）实际上运行 $N$ 个周期。\n\n**3. 性能指标的推导**\n\n**3.1. 加速比**\n加速比定义为较慢方法（可分页、无重叠）的执行时间与较快方法（固定、有重叠）的执行时间之比。\n$$ \\text{Speedup} = \\frac{T_{\\mathrm{total,pag}}}{T_{\\mathrm{total,pin}}} $$\n\n**3.2. 稳态重叠分数 ($f_{\\mathrm{overlap}}$)**\n这定义为在每个稳态阶段中，通过重叠消除的非重叠时间的比例。\n- 没有重叠的一个周期时间将是传输和计算之和：$T_{\\mathrm{pin}} + C$。\n- 通过重叠这两个阶段节省的时间是较短阶段的持续时间，它与较长阶段并行运行：$\\min(T_{\\mathrm{pin}}, C)$。\n- 分数是节省时间与非重叠时间之比。\n$$ f_{\\mathrm{overlap}} = \\frac{\\text{节省的时间}}{\\text{非重叠时间}} = \\frac{\\min(T_{\\mathrm{pin}}, C)}{T_{\\mathrm{pin}} + C} $$\n该值范围从0（如果一个阶段持续时间为零）到0.5（如果两个阶段持续时间相等）。\n\n**3.3. 计算受限指示符 ($I_{\\mathrm{compute-bound}}$)**\n此布尔值指示流水线的稳态是否受计算限制。当每个数据块的计算时间 $C$ 大于每个数据块的传输时间 $T_{\\mathrm{pin}}$ 时，就会发生这种情况。流水线是“计算受限”的。\n$$ I_{\\mathrm{compute-bound}} = (C > T_{\\mathrm{pin}}) $$\n\n**待实现的公式摘要：**\n1.  每个数据块的固定内存传输时间：$T_{\\mathrm{pin}} = L_{\\mathrm{pin}} + S/B$\n2.  每个数据块的可分页内存传输时间：$T_{\\mathrm{pag}} = L_{\\mathrm{pag}} + S/H + S/B$\n3.  总固定/重叠时间：$T_{\\mathrm{total,pin}} = N \\times \\max(T_{\\mathrm{pin}}, C) + \\min(T_{\\mathrm{pin}}, C)$\n4.  总可分页/非重叠时间：$T_{\\mathrm{total,pag}} = N \\times (T_{\\mathrm{pag}} + C)$\n5.  加速比：$\\text{Speedup} = T_{\\mathrm{total,pag}} / T_{\\mathrm{total,pin}}$\n6.  重叠分数：$f_{\\mathrm{overlap}} = \\min(T_{\\mathrm{pin}}, C) / (T_{\\mathrm{pin}} + C)$\n7.  计算受限指示符：$I_{\\mathrm{compute-bound}} = (C > T_{\\mathrm{pin}})$\n这些公式将被实现，以解决给定测试用例的问题。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes performance metrics for FEM matrix assembly on a GPU\n    based on a derived performance model.\n    \"\"\"\n    \n    # Test cases as tuples: (B, H, S, C, N, L_pin, L_pag)\n    # B: PCIe bandwidth (GiB/s)\n    # H: Host memory bandwidth (GiB/s)\n    # S: Chunk size (GiB)\n    # C: Kernel compute time per chunk (s)\n    # N: Number of chunks\n    # L_pin: Pinned memory transfer latency (s)\n    # L_pag: Pageable memory transfer latency (s)\n    test_cases = [\n        (12.0, 20.0, 4.0, 0.5, 8, 5e-6, 3e-5),       # Case A\n        (24.0, 50.0, 2.0, 2.0, 4, 5e-6, 3e-5),       # Case B\n        (12.0, 20.0, 8.0, 0.1, 6, 5e-6, 3e-5),       # Case C\n        (24.0, 40.0, 0.01, 0.002, 100, 5e-6, 3e-5),   # Case D\n        (12.0, 40.0, 3.6, 0.3, 5, 5e-6, 3e-5),       # Case E\n    ]\n\n    case_results_str = []\n    for case in test_cases:\n        B, H, S, C, N, L_pin, L_pag = case\n        \n        # 1. Per-chunk transfer time with pinned host memory\n        T_pin = L_pin + S / B\n        \n        # 2. Per-chunk transfer time with pageable host memory\n        T_pag = L_pag + S / H + S / B\n        \n        # 3. Total time with pinned memory and double-buffered overlap\n        # Formula: N * max(T_pin, C) + min(T_pin, C)\n        total_time_pinned_overlap = N * max(T_pin, C) + min(T_pin, C)\n\n        # 4. Total time with pageable memory and no overlap\n        # Formula: N * (T_pag + C)\n        total_time_pageable = N * (T_pag + C)\n        \n        # 5. Speedup factor\n        speedup = total_time_pageable / total_time_pinned_overlap\n        \n        # 6. Steady-state overlap fraction\n        # Formula: min(T_pin, C) / (T_pin + C)\n        # Avoid division by zero, although T_pin and C are positive times.\n        if (T_pin + C)  0:\n            overlap_fraction = min(T_pin, C) / (T_pin + C)\n        else:\n            overlap_fraction = 0.0\n\n        # 7. Compute-bound indicator\n        # True if compute time dominates transfer time in the overlapped case\n        compute_bound = C  T_pin\n        \n        # Format the inner list as a string with specified precision\n        inner_list_str = (\n            f\"[{total_time_pinned_overlap:.6f},\"\n            f\"{total_time_pageable:.6f},\"\n            f\"{speedup:.6f},\"\n            f\"{overlap_fraction:.6f},\"\n            f\"{str(compute_bound).lower()}]\"\n        )\n        case_results_str.append(inner_list_str)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(case_results_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在并行计算中，算法的选择不仅影响执行速度，还可能对数值精度产生深远影响，尤其是在处理浮点数运算时。归约（reduction）操作是并行编程中的一个基本构建块，例如对一个大数组求和。本练习 () 将对比两种经典的并行求和策略——简单的原子操作累加和更复杂的树形归约，从而揭示在GPU加速中性能与数值稳定性之间的重要权衡。",
            "id": "3529502",
            "problem": "考虑在图形处理单元 (GPU) 上对 $n=10^6$ 个非负双精度值进行求和。目标是评估在使用高性能计算 (HPC) 的计算岩土力学中两种典型的累加策略的数值精度和性能：朴素的全局内存原子加法和成对树形归约。从浮点运算法则的基本原理推导最坏情况相对误差，并构建一个定量性能模型来预测预期的速度差异。\n\n从以下既定基础开始：\n- 电气和电子工程师协会 (IEEE) 754 就近舍入浮点模型：对于任意实数 $a$ 和 $b$，一次浮点加法遵循 $\\mathrm{fl}(a+b)=(a+b)(1+\\delta)$，其中 $\\delta$ 是一个满足 $|\\delta|\\leq u$ 的未知实数，而 $u$ 是双精度的单位舍入误差。假设 $u=2^{-53}$。\n- 在此模型下，每次加法都独立进行，并且输入值为非负，因此真实和等于其绝对值之和。\n- 在性能方面，假设 GPU 执行：\n  1. 对单个全局内存位置进行朴素的原子累加，其原子加法速率受吞吐量限制，为 $T_{\\mathrm{atomic}}$ （操作/秒），此外还有加载输入的全局内存负载，其持续带宽为 $B$ （字节/秒）。\n  2. 成对树形归约，它从全局内存中读取所有输入一次，以 $F_{\\mathrm{add}}$ 的吞吐量（浮点加法/秒）执行算术加法，最后每个块执行一次全局内存原子加法，将每块的部分和累加到单个位置。假设块大小为 $s$ 个线程，产生 $N_b=\\lceil n/s\\rceil$ 个块，因此最后有 $N_b$ 次原子加法。\n\n任务：\n1. 使用浮点模型和输入的非负性，推导对 $n$ 个值进行朴素原子累加的最坏情况相对误差界。其中，操作由原子原语以某种未指定的顺序串行化。该界仅用 $n$ 和 $u$ 表示。除舍入模型外，不要假设任何抵消。\n2. 推导应用于 $n$ 个值的成对树形归约（假设为平衡二叉树）的最坏情况相对误差界，仅用 $n$ 和 $u$ 表示。\n3. 使用所描述的性能模型，推导朴素原子累加的总时间和成对树形归约的总时间的符号表达式。令 $t_{\\mathrm{read}}=8n/B$ 表示从全局内存读取 $n$ 个双精度值的时间，$t_{\\mathrm{atomic}}^{\\mathrm{naive}}=n/T_{\\mathrm{atomic}}$ 表示执行 $n$ 次原子加法的时间，$t_{\\mathrm{add}}^{\\mathrm{tree}}=(n-1)/F_{\\mathrm{add}}$ 表示执行 $n-1$ 次算术加法的时间，以及 $t_{\\mathrm{atomic}}^{\\mathrm{tree}}=N_b/T_{\\mathrm{atomic}}$ 表示为累加每块的部分和而执行的 $N_b$ 次原子加法的时间。定义加速比 $S$ 为朴素原子累加时间与树形归约时间之比。比率 $S$ 是无量纲的。\n\n对以下测试套件（所有量均采用国际单位制；双精度值为 $8$ 字节），数值评估最坏情况相对误差界和加速比：\n- 测试用例 A（基准，内存限制区域）：$B=1.0\\times 10^{12}$, $T_{\\mathrm{atomic}}=2.0\\times 10^{8}$, $F_{\\mathrm{add}}=1.0\\times 10^{12}$, $s=256$。\n- 测试用例 B（计算限制区域）：$B=1.0\\times 10^{12}$, $T_{\\mathrm{atomic}}=2.0\\times 10^{8}$, $F_{\\mathrm{add}}=5.0\\times 10^{10}$, $s=256$。\n- 测试用例 C（原子操作限制的边缘情况）：$B=1.0\\times 10^{12}$, $T_{\\mathrm{atomic}}=1.0\\times 10^{7}$, $F_{\\mathrm{add}}=1.0\\times 10^{12}$, $s=256$。\n- 测试用例 D（大块和更快的硬件）：$B=2.0\\times 10^{12}$, $T_{\\mathrm{atomic}}=5.0\\times 10^{8}$, $F_{\\mathrm{add}}=1.5\\times 10^{12}$, $s=1024$。\n\n对于每个测试用例，输出一个包含三个浮点数的列表：\n- 对于 $n=10^6$ 和双精度，朴素原子累加的最坏情况相对误差界。\n- 对于 $n=10^6$ 和双精度，成对树形归约的最坏情况相对误差界。\n- 如上定义的朴素原子累加和成对树形归约之间的加速比 $S$。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，每个元素是对应于一个测试用例的列表，按 A、B、C、D 的顺序排列。例如：“[[err_atomic_A,err_pairwise_A,speedup_A],[err_atomic_B,err_pairwise_B,speedup_B],...]”。所有与时间相关的量（如果计算）必须以秒为单位；加速比是无量纲的。所有输出必须是十进制表示的浮点数。",
            "solution": "问题陈述已经过严格审查，并被确定为**有效**。它在科学上基于数值分析和高性能计算性能建模的既定原则，问题提法良好，信息充分，可得到唯一解，并且表述客观。因此，我们可以继续进行推导和求解。\n\n根据要求，分析分为三个部分：朴素原子累加的最坏情况相对误差的推导，成对树形归约的最坏情况相对误差的推导，以及性能模型和加速比的推导。\n\n**1. 最坏情况相对误差：朴素原子累加**\n\n设要求和的 $n$ 个非负数序列为 $\\{x_1, x_2, \\ldots, x_n\\}$，其中对所有 $i$ 都有 $x_i \\ge 0$。真实和为 $S_n = \\sum_{i=1}^n x_i$。\n\nGPU 上的朴素原子累加意味着线程竞争将其局部值加到存储在全局内存中的单个总和上。原子操作将这些加法串行化，形成一个顺序求和，但顺序是任意的、不确定的。设计算 $k$ 次加法后的运行总和为 $\\hat{S}_k$。该过程由以下递推关系建模：\n$$ \\hat{S}_0 = 0 $$\n$$ \\hat{S}_k = \\mathrm{fl}(\\hat{S}_{k-1} + x_{\\pi(k)}) = (\\hat{S}_{k-1} + x_{\\pi(k)})(1+\\delta_k) \\quad \\text{for } k=1, \\ldots, n $$\n其中 $\\pi$ 是 $\\{1,\\ldots,n\\}$ 的一个任意排列，代表串行化顺序，且 $|\\delta_k| \\le u$，其中 $u=2^{-53}$ 是双精度浮点运算的单位舍入误差。\n\n顺序求和的前向误差分析（例如，Higham 的《数值算法的精度与稳定性》）中的一个标准结果是，最终计算出的和 $\\hat{S}_n$ 受以下公式界定：\n$$ |\\hat{S}_n - S_n| \\le \\gamma_{n-1} \\sum_{i=1}^n |x_i| $$\n其中 $\\gamma_k = \\frac{ku}{1-ku}$。由于所有 $x_i$ 都是非负的，所以 $|x_i|=x_i$ 且 $\\sum |x_i| = S_n$。因此，相对误差的界限为：\n$$ \\frac{|\\hat{S}_n - S_n|}{S_n} \\le \\gamma_{n-1} = \\frac{(n-1)u}{1-(n-1)u} $$\n这个界限对任何求和顺序都成立。对于 $n=10^6$ 和 $u=2^{-53}$，项 $(n-1)u \\approx 10^6 \\times 2^{-53} \\approx 1.11 \\times 10^{-10} \\ll 1$。因此，我们可以使用一阶近似来表示误差界：\n$$ E_{\\text{naive}} = (n-1)u $$\n此界限与数据值（除了其非负性之外）和求和顺序无关，并且如要求的那样，仅取决于 $n$ 和 $u$。\n\n**2. 最坏情况相对误差：成对树形归约**\n\n在成对（或级联）求和中，我们形成一个平衡的加法二叉树。对于 $n$ 个输入，有 $\\lceil \\log_2 n \\rceil$ 个求和层级。在每个层级，输入是来自前一个层级的部分和。\n让我们考虑误差传播。在第一级加法之后，成对的输入被相加。对于任意一对 $(x_i, x_j)$，计算出的和为 $\\mathrm{fl}(x_i+x_j) = (x_i+x_j)(1+\\delta)$，产生的相对误差以 $u$ 为界。随后每次两个部分和相加的结果最多为误差增加一个新的因子 $(1+u)$。\n经过 $k = \\lceil \\log_2 n \\rceil$ 个归约阶段后，最终的和 $\\hat{S}_n$ 将会累积每个阶段的误差。标准分析表明，最终计算出的和 $\\hat{S}_n$ 受以下公式界定：\n$$ |\\hat{S}_n - S_n| \\le \\gamma_k S_n = \\frac{ku}{1-ku} S_n, \\quad \\text{where } k = \\lceil \\log_2 n \\rceil $$\n相对误差由 $\\gamma_k$ 界定。由于对于实际的 $n$ 值，$k u \\ll 1$（$k = \\lceil\\log_2 10^6\\rceil=20$，所以 $ku \\approx 2.22 \\times 10^{-15}$），我们可以使用一阶近似：\n$$ E_{\\text{tree}} = \\lceil \\log_2 n \\rceil u $$\n此界限如要求的那样，仅取决于 $n$ 和 $u$。\n\n**3. 性能模型和加速比**\n\n我们采用一种非重叠性能模型，其中总时间是顺序阶段时间的总和。这与问题的表述一致。\n\n**朴素原子累加的总时间 ($T_{\\mathrm{naive}}$)：**\n该方法涉及从全局内存中读取 $n$ 个值并执行 $n$ 次原子加法。我们将这两个部分的时间相加。\n-   读取 $n$ 个双精度（$8$字节）值的时间：$t_{\\mathrm{read}} = \\frac{8n}{B}$\n-   执行 $n$ 次原子加法的时间：$t_{\\mathrm{atomic}}^{\\mathrm{naive}} = \\frac{n}{T_{\\mathrm{atomic}}}$\n总时间为：\n$$ T_{\\mathrm{naive}} = t_{\\mathrm{read}} + t_{\\mathrm{atomic}}^{\\mathrm{naive}} = \\frac{8n}{B} + \\frac{n}{T_{\\mathrm{atomic}}} $$\n\n**成对树形归约的总时间 ($T_{\\mathrm{tree}}$)：**\n该方法包括三个阶段：读取数据，在块内执行并行归约，以及让每个块使用原子加法将其部分和写入一个全局值。\n-   读取 $n$ 个双精度值的时间：$t_{\\mathrm{read}} = \\frac{8n}{B}$\n-   算术加法的时间（共 $n-1$ 次加法）：$t_{\\mathrm{add}}^{\\mathrm{tree}} = \\frac{n-1}{F_{\\mathrm{add}}}$\n-   来自 $N_b = \\lceil n/s \\rceil$ 个块的最终原子加法时间：$t_{\\mathrm{atomic}}^{\\mathrm{tree}} = \\frac{N_b}{T_{\\mathrm{atomic}}} = \\frac{\\lceil n/s \\rceil}{T_{\\mathrm{atomic}}}$\n总时间为：\n$$ T_{\\mathrm{tree}} = t_{\\mathrm{read}} + t_{\\mathrm{add}}^{\\mathrm{tree}} + t_{\\mathrm{atomic}}^{\\mathrm{tree}} = \\frac{8n}{B} + \\frac{n-1}{F_{\\mathrm{add}}} + \\frac{\\lceil n/s \\rceil}{T_{\\mathrm{atomic}}} $$\n\n**加速比 ($S$)：**\n加速比 $S$ 定义为朴素方法的时间与树形归约方法的时间之比。\n$$ S = \\frac{T_{\\mathrm{naive}}}{T_{\\mathrm{tree}}} = \\frac{\\frac{8n}{B} + \\frac{n}{T_{\\mathrm{atomic}}}}{\\frac{8n}{B} + \\frac{n-1}{F_{\\mathrm{add}}} + \\frac{\\lceil n/s \\rceil}{T_{\\mathrm{atomic}}}} $$\n\n**数值评估**\n给定 $n=10^6$ 和 $u=2^{-53}$。误差界与测试用例无关。\n-   最坏情况相对误差（朴素法）：$E_{\\text{naive}} = (10^6 - 1) \\times 2^{-53} \\approx 1.110222 \\times 10^{-10}$\n-   最坏情况相对误差（树形法）：$E_{\\text{tree}} = \\lceil \\log_2(10^6) \\rceil \\times 2^{-53} = 20 \\times 2^{-53} \\approx 2.220446 \\times 10^{-15}$\n\n对于加速比 $S$，我们为每个测试用例评估该表达式。\n\n**用例 A**：$B=1.0\\times 10^{12}$， $T_{\\mathrm{atomic}}=2.0\\times 10^{8}$， $F_{\\mathrm{add}}=1.0\\times 10^{12}$， $s=256$。\n$N_b = \\lceil 10^6/256 \\rceil = 3907$。\n$T_{\\mathrm{naive}} = \\frac{8 \\cdot 10^6}{10^{12}} + \\frac{10^6}{2 \\cdot 10^8} = 8 \\cdot 10^{-6} + 5 \\cdot 10^{-3} = 0.005008$ s。\n$T_{\\mathrm{tree}} = \\frac{8 \\cdot 10^6}{10^{12}} + \\frac{10^6-1}{10^{12}} + \\frac{3907}{2 \\cdot 10^8} \\approx 8 \\cdot 10^{-6} + 1 \\cdot 10^{-6} + 1.9535 \\cdot 10^{-5} = 2.8535 \\cdot 10^{-5}$ s。\n$S_A = \\frac{0.005008}{2.8535 \\times 10^{-5}} \\approx 175.50$\n\n**用例 B**：$B=1.0\\times 10^{12}$， $T_{\\mathrm{atomic}}=2.0\\times 10^{8}$， $F_{\\mathrm{add}}=5.0\\times 10^{10}$， $s=256$。\n$T_{\\mathrm{naive}} = 0.005008$ s。\n$T_{\\mathrm{tree}} = \\frac{8 \\cdot 10^6}{10^{12}} + \\frac{10^6-1}{5 \\cdot 10^{10}} + \\frac{3907}{2 \\cdot 10^8} \\approx 8 \\cdot 10^{-6} + 2 \\cdot 10^{-5} + 1.9535 \\cdot 10^{-5} = 4.7535 \\cdot 10^{-5}$ s。\n$S_B = \\frac{0.005008}{4.7535 \\times 10^{-5}} \\approx 105.35$\n\n**用例 C**：$B=1.0\\times 10^{12}$， $T_{\\mathrm{atomic}}=1.0\\times 10^{7}$， $F_{\\mathrm{add}}=1.0\\times 10^{12}$， $s=256$。\n$T_{\\mathrm{naive}} = \\frac{8 \\cdot 10^6}{10^{12}} + \\frac{10^6}{10^7} = 8 \\cdot 10^{-6} + 0.1 = 0.100008$ s。\n$T_{\\mathrm{tree}} = \\frac{8 \\cdot 10^6}{10^{12}} + \\frac{10^6-1}{10^{12}} + \\frac{3907}{10^7} \\approx 8 \\cdot 10^{-6} + 1 \\cdot 10^{-6} + 3.907 \\cdot 10^{-4} = 3.997 \\cdot 10^{-4}$ s。\n$S_C = \\frac{0.100008}{3.997 \\times 10^{-4}} \\approx 250.21$\n\n**用例 D**：$B=2.0\\times 10^{12}$， $T_{\\mathrm{atomic}}=5.0\\times 10^{8}$， $F_{\\mathrm{add}}=1.5\\times 10^{12}$， $s=1024$。\n$N_b = \\lceil 10^6/1024 \\rceil = 977$。\n$T_{\\mathrm{naive}} = \\frac{8 \\cdot 10^6}{2 \\cdot 10^{12}} + \\frac{10^6}{5 \\cdot 10^8} = 4 \\cdot 10^{-6} + 2 \\cdot 10^{-3} = 0.002004$ s。\n$T_{\\mathrm{tree}} = \\frac{8 \\cdot 10^6}{2 \\cdot 10^{12}} + \\frac{10^6-1}{1.5 \\cdot 10^{12}} + \\frac{977}{5 \\cdot 10^8} \\approx 4 \\cdot 10^{-6} + 0.666 \\cdot 10^{-6} + 1.954 \\cdot 10^{-6} = 6.6207 \\cdot 10^{-6}$ s。\n$S_D = \\frac{0.002004}{6.6207 \\times 10^{-6}} \\approx 302.68$\n\n这些推导出的值将在以下程序中精确计算。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates worst-case relative errors for two summation algorithms and\n    evaluates a performance speedup ratio based on a given model for four\n    test cases.\n    \"\"\"\n    # Define constants from the problem statement\n    n = 1e6\n    # Unit roundoff for IEEE 754 double precision\n    u = 2**-53\n\n    # Task 1  2: Calculate worst-case relative error bounds\n    # These bounds depend only on n and u, so they are constant for all test cases.\n\n    # Worst-case relative error for naive (sequential) atomic accumulation.\n    # The first-order bound is (n-1)*u.\n    err_atomic = (n - 1) * u\n\n    # Worst-case relative error for pairwise tree reduction.\n    # The first-order bound is ceil(log2(n))*u.\n    err_pairwise = np.ceil(np.log2(n)) * u\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case A (baseline, memory-limited regime)\n        {'B': 1.0e12, 'T_atomic': 2.0e8, 'F_add': 1.0e12, 's': 256},\n        # Test case B (compute-limited regime)\n        {'B': 1.0e12, 'T_atomic': 2.0e8, 'F_add': 5.0e10, 's': 256},\n        # Test case C (atomic-limited edge case)\n        {'B': 1.0e12, 'T_atomic': 1.0e7, 'F_add': 1.0e12, 's': 256},\n        # Test case D (large blocks and faster hardware)\n        {'B': 2.0e12, 'T_atomic': 5.0e8, 'F_add': 1.5e12, 's': 1024},\n    ]\n\n    results = []\n    for case in test_cases:\n        # Unpack parameters for the current test case\n        B = case['B']\n        T_atomic = case['T_atomic']\n        F_add = case['F_add']\n        s = case['s']\n\n        # Task 3: Calculate total time for naive accumulation\n        t_read = 8 * n / B\n        t_atomic_naive = n / T_atomic\n        T_naive = t_read + t_atomic_naive\n\n        # Task 3: Calculate total time for pairwise tree reduction\n        N_b = np.ceil(n / s)\n        t_add_tree = (n - 1) / F_add\n        t_atomic_tree = N_b / T_atomic\n        T_tree = t_read + t_add_tree + t_atomic_tree\n\n        # Task 3: Calculate the speedup ratio S\n        speedup = T_naive / T_tree\n        \n        # Append the list of results for this case\n        results.append([err_atomic, err_pairwise, speedup])\n\n    # Final print statement in the exact required format.\n    # The string representation of a list in Python is \"[item1, item2, ...]\".\n    # Joining these representations with a comma gives the desired format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}