{
    "hands_on_practices": [
        {
            "introduction": "In probabilistic geomechanics, it is crucial that our mathematical models respect physical reality. While distributions like the normal distribution are convenient, they often assign non-zero probability to physically impossible values. This exercise  tackles this issue by demonstrating how to formally truncate a probability distribution to a valid range, using the soil friction angle $\\phi$ as a practical example. You will derive the corrected mean and variance, a fundamental skill for building realistic stochastic models of material parameters.",
            "id": "3553047",
            "problem": "An earth embankment is designed with a granular backfill whose shear strength is modeled by the Mohr–Coulomb criterion. The friction angle $\\,\\phi\\,$ is uncertain and is represented by a normally distributed prior with mean $\\,\\mu\\,$ and standard deviation $\\,\\sigma\\,$, but physics and site characterization constrain $\\,\\phi\\,$ to the admissible interval $[20^\\circ,45^\\circ]$. Consequently, the predictive model adopts the truncated normal distribution of $\\,\\phi\\,$ supported on $[20^\\circ,45^\\circ]$. Let $\\,\\varphi(z)\\,$ and $\\,\\Phi(z)\\,$ denote the standard normal probability density function and cumulative distribution function, respectively. Assume $\\,\\sigma0\\,$ and that $\\,\\mu\\,$ and $\\,\\sigma\\,$ are expressed in degrees so that $\\,(\\phi-\\mu)/\\sigma\\,$ is dimensionless.\n\nStarting from the definitions of the normal probability density function and conditional expectation and variance, and using only the standardization $\\,z=(\\phi-\\mu)/\\sigma\\,$ together with properties of $\\,\\varphi\\,$ and $\\,\\Phi\\,$, derive closed-form expressions for the mean $\\,\\mathbb{E}[\\phi]\\,$ and variance $\\,\\mathrm{Var}[\\phi]\\,$ of the truncated normal model of $\\,\\phi\\,$ on $[20^\\circ,45^\\circ]$ in terms of $\\,\\mu\\,$, $\\,\\sigma\\,$, $\\,\\varphi(\\cdot)$, and $\\,\\Phi(\\cdot)$. Your final expressions must be analytic and must not involve numerical approximation.\n\nExpress $\\,\\mathbb{E}[\\phi]\\,$ in degrees and $\\,\\mathrm{Var}[\\phi]\\,$ in degrees squared. No rounding is required, and you must provide exact expressions.",
            "solution": "The problem is well-posed and scientifically grounded. It requires the derivation of the mean and variance for a truncated normal distribution, a standard procedure in probabilistic modeling applied to a realistic context in geomechanics. We shall proceed with the derivation.\n\nLet the friction angle be a random variable $\\phi$. Its prior distribution is normal with mean $\\mu$ and standard deviation $\\sigma$, having a probability density function (PDF) given by\n$$ f(\\phi) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2}\\left(\\frac{\\phi-\\mu}{\\sigma}\\right)^2\\right) $$\nUsing the definition of the standard normal PDF, $\\varphi(z) = \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{z^2}{2}\\right)$, we can write this as:\n$$ f(\\phi) = \\frac{1}{\\sigma} \\varphi\\left(\\frac{\\phi-\\mu}{\\sigma}\\right) $$\nThe variable $\\phi$ is truncated to the interval $[a, b]$, where $a=20^\\circ$ and $b=45^\\circ$. The PDF of the truncated variable, which we will also denote by $\\phi$ for simplicity, is given by\n$$ f_{\\text{trunc}}(\\phi) = \\frac{f(\\phi)}{\\int_a^b f(x) \\, dx}, \\quad \\text{for } \\phi \\in [a, b] $$\nand $f_{\\text{trunc}}(\\phi) = 0$ otherwise.\n\nThe denominator is the probability that the untruncated variable falls within the interval $[a, b]$. We can calculate this integral using the cumulative distribution function (CDF) of the standard normal distribution, $\\Phi(z) = \\int_{-\\infty}^z \\varphi(t) \\, dt$.\n$$ \\int_a^b f(x) \\, dx = \\int_a^b \\frac{1}{\\sigma} \\varphi\\left(\\frac{x-\\mu}{\\sigma}\\right) \\, dx $$\nLet's use the standardization $z = (x-\\mu)/\\sigma$, which implies $dx = \\sigma \\, dz$. The limits of integration become $\\alpha = (a-\\mu)/\\sigma$ and $\\beta = (b-\\mu)/\\sigma$.\n$$ \\int_a^b f(x) \\, dx = \\int_\\alpha^\\beta \\varphi(z) \\, dz = \\Phi(\\beta) - \\Phi(\\alpha) $$\nThus, the PDF of the truncated variable is:\n$$ f_{\\text{trunc}}(\\phi) = \\frac{\\frac{1}{\\sigma} \\varphi\\left(\\frac{\\phi-\\mu}{\\sigma}\\right)}{\\Phi(\\beta) - \\Phi(\\alpha)} $$\nfor $\\phi \\in [a, b]$, where $a=20^\\circ$ and $b=45^\\circ$. For brevity, let $K = \\Phi(\\beta) - \\Phi(\\alpha)$.\n\nFirst, we derive the mean, $\\mathbb{E}[\\phi]$.\n$$ \\mathbb{E}[\\phi] = \\int_a^b \\phi \\, f_{\\text{trunc}}(\\phi) \\, d\\phi = \\frac{1}{K} \\int_a^b \\phi \\frac{1}{\\sigma} \\varphi\\left(\\frac{\\phi-\\mu}{\\sigma}\\right) \\, d\\phi $$\nUsing the same substitution $z = (\\phi-\\mu)/\\sigma$, we have $\\phi = \\mu + \\sigma z$ and $d\\phi = \\sigma \\, dz$.\n$$ \\mathbb{E}[\\phi] = \\frac{1}{K} \\int_\\alpha^\\beta (\\mu + \\sigma z) \\, \\varphi(z) \\, dz $$\nWe can split the integral into two parts:\n$$ \\mathbb{E}[\\phi] = \\frac{1}{K} \\left[ \\mu \\int_\\alpha^\\beta \\varphi(z) \\, dz + \\sigma \\int_\\alpha^\\beta z \\varphi(z) \\, dz \\right] $$\nThe first integral is $\\int_\\alpha^\\beta \\varphi(z) \\, dz = \\Phi(\\beta) - \\Phi(\\alpha) = K$.\nFor the second integral, we use the property that the derivative of the standard normal PDF is $\\varphi'(z) = -z \\varphi(z)$. Therefore, $\\int z \\varphi(z) \\, dz = \\int -\\varphi'(z) \\, dz = -\\varphi(z) + C$.\n$$ \\int_\\alpha^\\beta z \\varphi(z) \\, dz = [-\\varphi(z)]_\\alpha^\\beta = -\\varphi(\\beta) - (-\\varphi(\\alpha)) = \\varphi(\\alpha) - \\varphi(\\beta) $$\nSubstituting these results back into the expression for $\\mathbb{E}[\\phi]$:\n$$ \\mathbb{E}[\\phi] = \\frac{1}{K} [ \\mu K + \\sigma (\\varphi(\\alpha) - \\varphi(\\beta)) ] = \\mu + \\sigma \\frac{\\varphi(\\alpha) - \\varphi(\\beta)}{\\Phi(\\beta) - \\Phi(\\alpha)} $$\n\nNext, we derive the variance, $\\mathrm{Var}[\\phi] = \\mathbb{E}[\\phi^2] - (\\mathbb{E}[\\phi])^2$. We first need to compute the second moment, $\\mathbb{E}[\\phi^2]$.\n$$ \\mathbb{E}[\\phi^2] = \\int_a^b \\phi^2 \\, f_{\\text{trunc}}(\\phi) \\, d\\phi = \\frac{1}{K} \\int_a^b \\phi^2 \\frac{1}{\\sigma} \\varphi\\left(\\frac{\\phi-\\mu}{\\sigma}\\right) \\, d\\phi $$\nUsing the substitution $\\phi = \\mu + \\sigma z$ again:\n$$ \\mathbb{E}[\\phi^2] = \\frac{1}{K} \\int_\\alpha^\\beta (\\mu + \\sigma z)^2 \\varphi(z) \\, dz = \\frac{1}{K} \\int_\\alpha^\\beta (\\mu^2 + 2\\mu\\sigma z + \\sigma^2 z^2) \\varphi(z) \\, dz $$\nWe split this into three integrals:\n$$ \\mathbb{E}[\\phi^2] = \\frac{1}{K} \\left[ \\mu^2 \\int_\\alpha^\\beta \\varphi(z) \\, dz + 2\\mu\\sigma \\int_\\alpha^\\beta z \\varphi(z) \\, dz + \\sigma^2 \\int_\\alpha^\\beta z^2 \\varphi(z) \\, dz \\right] $$\nWe already know the first two integrals. For the third integral, $\\int z^2 \\varphi(z) \\, dz$, we use integration by parts with $u = z$ and $dv = z \\varphi(z) \\, dz$. Then $du=dz$ and $v = -\\varphi(z)$.\n$$ \\int z^2 \\varphi(z) \\, dz = -z\\varphi(z) - \\int (-\\varphi(z)) \\, dz = -z\\varphi(z) + \\int \\varphi(z) \\, dz = -z\\varphi(z) + \\Phi(z) + C $$\nTherefore, the definite integral is:\n$$ \\int_\\alpha^\\beta z^2 \\varphi(z) \\, dz = [-z\\varphi(z) + \\Phi(z)]_\\alpha^\\beta = (-\\beta\\varphi(\\beta) + \\Phi(\\beta)) - (-\\alpha\\varphi(\\alpha) + \\Phi(\\alpha)) = \\alpha\\varphi(\\alpha) - \\beta\\varphi(\\beta) + K $$\nSubstituting the results of the three integrals into the expression for $\\mathbb{E}[\\phi^2]$:\n$$ \\mathbb{E}[\\phi^2] = \\frac{1}{K} \\left[ \\mu^2 K + 2\\mu\\sigma (\\varphi(\\alpha) - \\varphi(\\beta)) + \\sigma^2 (\\alpha\\varphi(\\alpha) - \\beta\\varphi(\\beta) + K) \\right] $$\n$$ \\mathbb{E}[\\phi^2] = \\mu^2 + 2\\mu\\sigma \\frac{\\varphi(\\alpha) - \\varphi(\\beta)}{K} + \\sigma^2 \\frac{\\alpha\\varphi(\\alpha) - \\beta\\varphi(\\beta)}{K} + \\sigma^2 $$\nNow we compute the variance: $\\mathrm{Var}[\\phi] = \\mathbb{E}[\\phi^2] - (\\mathbb{E}[\\phi])^2$.\n$$ (\\mathbb{E}[\\phi])^2 = \\left( \\mu + \\sigma \\frac{\\varphi(\\alpha) - \\varphi(\\beta)}{K} \\right)^2 = \\mu^2 + 2\\mu\\sigma \\frac{\\varphi(\\alpha) - \\varphi(\\beta)}{K} + \\sigma^2 \\left( \\frac{\\varphi(\\alpha) - \\varphi(\\beta)}{K} \\right)^2 $$\nSubtracting $(\\mathbb{E}[\\phi])^2$ from $\\mathbb{E}[\\phi^2]$:\n$$ \\mathrm{Var}[\\phi] = \\left( \\mu^2 + 2\\mu\\sigma \\frac{\\varphi(\\alpha) - \\varphi(\\beta)}{K} + \\sigma^2 \\frac{\\alpha\\varphi(\\alpha) - \\beta\\varphi(\\beta)}{K} + \\sigma^2 \\right) - \\left( \\mu^2 + 2\\mu\\sigma \\frac{\\varphi(\\alpha) - \\varphi(\\beta)}{K} + \\sigma^2 \\left( \\frac{\\varphi(\\alpha) - \\varphi(\\beta)}{K} \\right)^2 \\right) $$\nThe terms involving $\\mu^2$ and $2\\mu\\sigma$ cancel out, leaving:\n$$ \\mathrm{Var}[\\phi] = \\sigma^2 + \\sigma^2 \\frac{\\alpha\\varphi(\\alpha) - \\beta\\varphi(\\beta)}{K} - \\sigma^2 \\left( \\frac{\\varphi(\\alpha) - \\varphi(\\beta)}{K} \\right)^2 $$\nFactoring out $\\sigma^2$ and substituting back $K = \\Phi(\\beta) - \\Phi(\\alpha)$:\n$$ \\mathrm{Var}[\\phi] = \\sigma^2 \\left[ 1 + \\frac{\\alpha\\varphi(\\alpha) - \\beta\\varphi(\\beta)}{\\Phi(\\beta) - \\Phi(\\alpha)} - \\left( \\frac{\\varphi(\\alpha) - \\varphi(\\beta)}{\\Phi(\\beta) - \\Phi(\\alpha)} \\right)^2 \\right] $$\nThe problem is fully solved. The derived expressions for $\\mathbb{E}[\\phi]$ and $\\mathrm{Var}[\\phi]$ are analytic and expressed in terms of the given parameters and functions. The standardized limits are $\\alpha = (20 - \\mu)/\\sigma$ and $\\beta = (45 - \\mu)/\\sigma$, where $\\mu$ and $\\sigma$ are in degrees. The expression for $\\mathbb{E}[\\phi]$ will have units of degrees, and $\\mathrm{Var}[\\phi]$ will have units of degrees squared, as required.\n\nFinal expressions for $\\mathbb{E}[\\phi]$ and $\\mathrm{Var}[\\phi]$ with $\\alpha = (20-\\mu)/\\sigma$ and $\\beta=(45-\\mu)/\\sigma$:\n\nMean:\n$$ \\mathbb{E}[\\phi] = \\mu + \\sigma \\frac{\\varphi\\left(\\frac{20-\\mu}{\\sigma}\\right) - \\varphi\\left(\\frac{45-\\mu}{\\sigma}\\right)}{\\Phi\\left(\\frac{45-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{20-\\mu}{\\sigma}\\right)} $$\nVariance:\n$$ \\mathrm{Var}[\\phi] = \\sigma^2 \\left[ 1 + \\frac{\\left(\\frac{20-\\mu}{\\sigma}\\right)\\varphi\\left(\\frac{20-\\mu}{\\sigma}\\right) - \\left(\\frac{45-\\mu}{\\sigma}\\right)\\varphi\\left(\\frac{45-\\mu}{\\sigma}\\right)}{\\Phi\\left(\\frac{45-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{20-\\mu}{\\sigma}\\right)} - \\left( \\frac{\\varphi\\left(\\frac{20-\\mu}{\\sigma}\\right) - \\varphi\\left(\\frac{45-\\mu}{\\sigma}\\right)}{\\Phi\\left(\\frac{45-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{20-\\mu}{\\sigma}\\right)} \\right)^2 \\right] $$\nFor the final answer, we use the compact notation with $\\alpha$ and $\\beta$.",
            "answer": "$$ \\boxed{\\begin{pmatrix} \\mu + \\sigma \\frac{\\varphi\\left(\\frac{20-\\mu}{\\sigma}\\right) - \\varphi\\left(\\frac{45-\\mu}{\\sigma}\\right)}{\\Phi\\left(\\frac{45-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{20-\\mu}{\\sigma}\\right)}  \\sigma^2 \\left( 1 + \\frac{\\left(\\frac{20-\\mu}{\\sigma}\\right)\\varphi\\left(\\frac{20-\\mu}{\\sigma}\\right) - \\left(\\frac{45-\\mu}{\\sigma}\\right)\\varphi\\left(\\frac{45-\\mu}{\\sigma}\\right)}{\\Phi\\left(\\frac{45-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{20-\\mu}{\\sigma}\\right)} - \\left( \\frac{\\varphi\\left(\\frac{20-\\mu}{\\sigma}\\right) - \\varphi\\left(\\frac{45-\\mu}{\\sigma}\\right)}{\\Phi\\left(\\frac{45-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{20-\\mu}{\\sigma}\\right)} \\right)^2 \\right) \\end{pmatrix}} $$"
        },
        {
            "introduction": "Soil properties rarely consist of a single uncertain value; they exhibit spatial variability. This practice  moves from a single random variable to a one-dimensional random field, a more realistic model for properties along a borehole or beneath a foundation. By deriving the variance of a spatially averaged property, you will gain deep insight into how the scale of observation $L$ and the intrinsic correlation length $\\ell$ of the soil interact to control uncertainty, a cornerstone concept in geostatistics and upscaling.",
            "id": "3553043",
            "problem": "Consider a second-order stationary scalar random field $E(x)$ representing the spatial variability of a soil stiffness modulus along a one-dimensional profile. Let the mean be $\\mu_{E}$ and the covariance function be $C(h)=\\operatorname{Cov}\\!\\big(E(x),E(x+h)\\big)=\\sigma^{2}\\exp\\!\\big(-|h|/\\ell\\big)$, where $\\sigma^{2}$ is the variance and $\\ell$ is the correlation length. For a finite interval $[0,L]$ of length $L$, define the spatial average $\\bar{E}_{L}$ by\n$$\n\\bar{E}_{L}=\\frac{1}{L}\\int_{0}^{L}E(x)\\,\\mathrm{d}x.\n$$\nUsing only the definitions of variance and covariance for second-order stationary fields and basic properties of integrals, derive a closed-form expression for the variance $\\operatorname{Var}(\\bar{E}_{L})$ in terms of $\\sigma^{2}$, $L$, and $\\ell$ only. Then, based on the derived expression, explain qualitatively how the correlation length $\\ell$ governs the scaling of $\\operatorname{Var}(\\bar{E}_{L})$ with $L$ in the limiting regimes $L\\ll \\ell$ and $L\\gg \\ell$. Provide the final expression for $\\operatorname{Var}(\\bar{E}_{L})$ as your answer. Do not include any units in the final expression.",
            "solution": "The problem is scientifically grounded, well-posed, and objective. It presents a standard task in the stochastic modeling of spatially variable material properties, which is central to probabilistic geomechanics. All necessary definitions and parameters are provided, and no inconsistencies or ambiguities are present. Therefore, a complete solution is warranted.\n\nThe primary objective is to derive an expression for the variance of the spatial average of a second-order stationary random field $E(x)$ over an interval $[0,L]$. The spatial average $\\bar{E}_{L}$ is defined as:\n$$\n\\bar{E}_{L} = \\frac{1}{L}\\int_{0}^{L} E(x)\\,\\mathrm{d}x\n$$\nThe variance of $\\bar{E}_{L}$ is given by the general definition $\\operatorname{Var}(\\bar{E}_{L}) = E[\\bar{E}_{L}^2] - (E[\\bar{E}_{L}])^2$. First, we determine the expected value of $\\bar{E}_{L}$. By linearity of the expectation operator, we can interchange expectation and integration:\n$$\nE[\\bar{E}_{L}] = E\\left[\\frac{1}{L}\\int_{0}^{L} E(x)\\,\\mathrm{d}x\\right] = \\frac{1}{L}\\int_{0}^{L} E[E(x)]\\,\\mathrm{d}x\n$$\nSince the field $E(x)$ is second-order stationary, its mean $E[E(x)]$ is a constant, $\\mu_{E}$, for all $x$.\n$$\nE[\\bar{E}_{L}] = \\frac{1}{L}\\int_{0}^{L} \\mu_{E}\\,\\mathrm{d}x = \\frac{1}{L}(\\mu_{E}L) = \\mu_{E}\n$$\nNow, we express the variance of $\\bar{E}_{L}$ using its definition as a double integral.\n$$\n\\operatorname{Var}(\\bar{E}_{L}) = \\operatorname{Var}\\left(\\frac{1}{L}\\int_{0}^{L} E(x)\\,\\mathrm{d}x\\right) = \\frac{1}{L^2}\\operatorname{Var}\\left(\\int_{0}^{L} E(x)\\,\\mathrm{d}x\\right)\n$$\nThe variance of the integral can be written as:\n$$\n\\operatorname{Var}\\left(\\int_{0}^{L} E(x)\\,\\mathrm{d}x\\right) = E\\left[\\left(\\int_{0}^{L} E(x)\\,\\mathrm{d}x - E\\left[\\int_{0}^{L}E(y)\\,\\mathrm{d}y\\right]\\right)^2\\right]\n$$\nSince $E\\left[\\int_{0}^{L}E(y)\\,\\mathrm{d}y\\right] = L\\mu_{E}$, this becomes:\n$$\nE\\left[\\left(\\int_{0}^{L} (E(x) - \\mu_{E})\\,\\mathrm{d}x\\right)^2\\right] = E\\left[\\left(\\int_{0}^{L} (E(x) - \\mu_{E})\\,\\mathrm{d}x\\right)\\left(\\int_{0}^{L} (E(y) - \\mu_{E})\\,\\mathrm{d}y\\right)\\right]\n$$\n$$\n= E\\left[\\int_{0}^{L}\\int_{0}^{L} (E(x) - \\mu_{E})(E(y) - \\mu_{E})\\,\\mathrm{d}x\\,\\mathrm{d}y\\right]\n$$\nInterchanging expectation and integration gives:\n$$\n\\int_{0}^{L}\\int_{0}^{L} E[(E(x) - \\mu_{E})(E(y) - \\mu_{E})]\\,\\mathrm{d}x\\,\\mathrm{d}y = \\int_{0}^{L}\\int_{0}^{L} \\operatorname{Cov}(E(x), E(y))\\,\\mathrm{d}x\\,\\mathrm{d}y\n$$\nFor a second-order stationary field, the covariance is a function of the separation distance $h = x-y$, so $\\operatorname{Cov}(E(x), E(y)) = C(x-y)$. Therefore, the variance of the average is:\n$$\n\\operatorname{Var}(\\bar{E}_{L}) = \\frac{1}{L^2}\\int_{0}^{L}\\int_{0}^{L} C(x-y)\\,\\mathrm{d}x\\,\\mathrm{d}y\n$$\nThe problem provides the exponential covariance function $C(h) = \\sigma^2 \\exp(-|h|/\\ell)$. Substituting this into the equation:\n$$\n\\operatorname{Var}(\\bar{E}_{L}) = \\frac{\\sigma^2}{L^2}\\int_{0}^{L}\\int_{0}^{L} \\exp\\left(-\\frac{|x-y|}{\\ell}\\right)\\,\\mathrm{d}x\\,\\mathrm{d}y\n$$\nThe double integral can be evaluated efficiently by making a change of variables or by recognizing a general property of such integrals. The integral $\\int_{0}^{L}\\int_{0}^{L} f(|x-y|)\\,\\mathrm{d}x\\,\\mathrm{d}y$ is equivalent to $\\int_{-L}^{L} (L-|z|)f(|z|)\\,\\mathrm{d}z$. Since the integrand is an even function of $z$:\n$$\n\\int_{0}^{L}\\int_{0}^{L} \\exp\\left(-\\frac{|x-y|}{\\ell}\\right)\\,\\mathrm{d}x\\,\\mathrm{d}y = 2\\int_{0}^{L} (L-z)\\exp\\left(-\\frac{z}{\\ell}\\right)\\,\\mathrm{d}z\n$$\nWe evaluate this integral using integration by parts, $\\int u\\,\\mathrm{d}v = uv - \\int v\\,\\mathrm{d}u$. Let $u = L-z$ and $\\mathrm{d}v = \\exp(-z/\\ell)\\,\\mathrm{d}z$. Then $\\mathrm{d}u = -1\\,\\mathrm{d}z$ and $v = -\\ell\\exp(-z/\\ell)$.\n\\begin{align*} 2\\int_{0}^{L} (L-z)\\exp\\left(-\\frac{z}{\\ell}\\right)\\,\\mathrm{d}z = 2\\left(\\Big[(L-z)(-\\ell\\exp(-z/\\ell))\\Big]_{0}^{L} - \\int_{0}^{L} (-\\ell\\exp(-z/\\ell))(-1\\,\\mathrm{d}z)\\right) \\\\ = 2\\left(\\Big[0 - (L)(-\\ell)\\Big] - \\ell\\int_{0}^{L} \\exp(-z/\\ell)\\,\\mathrm{d}z\\right) \\\\ = 2\\left(L\\ell - \\ell\\Big[-\\ell\\exp(-z/\\ell)\\Big]_{0}^{L}\\right) \\\\ = 2\\left(L\\ell - \\ell(-\\ell\\exp(-L/\\ell) - (-\\ell))\\right) \\\\ = 2\\left(L\\ell - \\ell^2(1 - \\exp(-L/\\ell))\\right) \\\\ = 2L\\ell - 2\\ell^2(1 - \\exp(-L/\\ell))\\end{align*}\nSubstituting this result back into the expression for $\\operatorname{Var}(\\bar{E}_{L})$:\n$$\n\\operatorname{Var}(\\bar{E}_{L}) = \\frac{\\sigma^2}{L^2}\\left[2L\\ell - 2\\ell^2\\left(1 - \\exp\\left(-\\frac{L}{\\ell}\\right)\\right)\\right]\n$$\nThis expression can be rearranged into a more insightful form:\n$$\n\\operatorname{Var}(\\bar{E}_{L}) = \\frac{2\\sigma^2 \\ell^2}{L^2}\\left[\\frac{L}{\\ell} - 1 + \\exp\\left(-\\frac{L}{\\ell}\\right)\\right]\n$$\nThis is the required closed-form expression for the variance of the spatial average.\n\nNext, we analyze the scaling of $\\operatorname{Var}(\\bar{E}_{L})$ in two limiting regimes. Let $\\rho = L/\\ell$ be the dimensionless ratio of the averaging length to the correlation length.\n\nCase 1: $L \\ll \\ell$ (averaging length much smaller than correlation length).\nIn this regime, $\\rho \\to 0$. We use the Taylor series expansion for $\\exp(-\\rho)$ around $\\rho=0$:\n$\\exp(-\\rho) = 1 - \\rho + \\frac{\\rho^2}{2!} - \\frac{\\rho^3}{3!} + O(\\rho^4)$.\nSubstituting this into the term in the brackets:\n$$\n\\rho - 1 + \\exp(-\\rho) \\approx \\rho - 1 + \\left(1 - \\rho + \\frac{\\rho^2}{2}\\right) = \\frac{\\rho^2}{2}\n$$\nThe variance becomes:\n$$\n\\operatorname{Var}(\\bar{E}_{L}) \\approx \\frac{2\\sigma^2}{\\rho^2}\\left(\\frac{\\rho^2}{2}\\right) = \\sigma^2\n$$\nQualitatively, when $L$ is very small compared to $\\ell$, the random field $E(x)$ is highly correlated over the interval $[0,L]$. The values of $E(x)$ are nearly constant, so the spatial average $\\bar{E}_{L}$ is approximately equal to a single point value, e.g., $E(0)$. Consequently, the variance of the average approaches the point variance, $\\operatorname{Var}(\\bar{E}_{L}) \\approx \\operatorname{Var}(E(0)) = \\sigma^2$. The averaging provides negligible variance reduction.\n\nCase 2: $L \\gg \\ell$ (averaging length much larger than correlation length).\nIn this regime, $\\rho \\to \\infty$. As $\\rho$ becomes large, the term $\\exp(-\\rho)$ approaches $0$. The term in the brackets becomes approximately $(\\rho - 1)$. Since $\\rho \\gg 1$, this is further approximated by $\\rho$.\n$$\n\\operatorname{Var}(\\bar{E}_{L}) \\approx \\frac{2\\sigma^2 \\ell^2}{L^2}\\left(\\frac{L}{\\ell}\\right) = \\frac{2\\sigma^2\\ell}{L}\n$$\nThe variance scales inversely with the averaging length $L$.\nQualitatively, when $L$ is much larger than $\\ell$, the integral for $\\bar{E}_{L}$ averages over many nearly-independent segments of the random field, where the approximate length of each segment is related to the correlation length $\\ell$. Based on a Central Limit Theorem-type argument, averaging over approximately $N \\approx L/\\ell$ independent blocks would reduce the variance by a factor of $N$. This leads to the scaling $\\operatorname{Var}(\\bar{E}_{L}) \\propto 1/N \\propto \\ell/L$. The constant of proportionality, $2$ in this case, depends on the shape of the covariance function. This significant variance reduction is a key principle in geostatistical estimation and upscaling.",
            "answer": "$$\n\\boxed{\\frac{2\\sigma^2 \\ell^2}{L^2} \\left(\\frac{L}{\\ell} - 1 + \\exp\\left(-\\frac{L}{\\ell}\\right)\\right)}\n$$"
        },
        {
            "introduction": "A key goal of probabilistic modeling is to assess reliability, which often involves estimating the probability of rare failure events. Standard simulation methods are inefficient for such tasks. This hands-on coding exercise  introduces you to the logic of Subset Simulation (SuS), an advanced Monte Carlo technique that transforms a rare event problem into a sequence of more frequent ones. You will design an idealized SuS scheme and analyze its performance, connecting theoretical concepts to the practical challenge of quantifying geotechnical risk.",
            "id": "3553129",
            "problem": "Consider a probabilistic slope stability assessment in which the scalar performance variable $Y$ represents a dimensionless safety margin aggregated from random shear strength and pore pressure contributions. Assume $Y$ is modeled as a Gaussian random variable $Y \\sim \\mathcal{N}(\\mu,\\sigma^2)$, consistent with the Central Limit Theorem (CLT) when many independent contributing uncertainties are present. Failure is defined by the rare-event threshold exceedance $\\{Y \\ge b_L\\}$ with probability $P_f \\approx 10^{-6}$. To estimate $P_f$ using Subset Simulation (SuS), design a nested sequence of intermediate thresholds $\\{b_\\ell\\}_{\\ell=1}^L$ such that the level sets $\\{Y \\ge b_1\\} \\supset \\{Y \\ge b_2\\} \\supset \\dots \\supset \\{Y \\ge b_L\\}$ satisfy a constant conditional exceedance probability $p_0$ at each level, and the product $\\prod_{\\ell=1}^L p_0$ approximates $P_f$. For a given conditional sample size $m$ per level, the SuS estimator of $P_f$ is the product of $L$ sample proportions of exceedances at the designed thresholds.\n\nStarting from fundamental probabilistic definitions, model each within-level exceedance indicator as an independent Bernoulli random variable with success probability $p_0$, so the sample proportions are unbiased estimators of the conditional probabilities. Use this independence idealization as a design surrogate and derive the estimator variance as a function of the conditional sample size $m$, the level count $L$, and the constant conditional probability $p_0$. For the threshold design, use the Gaussian quantile relation to determine $b_\\ell$ such that the unconditional tail probability satisfies $\\mathbb{P}(Y \\ge b_\\ell) = p_0^\\ell$, ensuring that the nested rare-event sequence has the intended tail probabilities.\n\nYour program must:\n- Implement the threshold design for a standardized Gaussian $Y$ with $\\mu=0$ and $\\sigma=1$, computing $b_\\ell$ via the standard normal inverse cumulative distribution function for each level $\\ell=1,\\dots,L$ given $p_0$.\n- Implement the estimator variance computation for the SuS product estimator under the independence surrogate described above, expressed purely in terms of $m$, $L$, and $p_0$.\n- Use the following test suite of parameter sets $(p_0,m,L)$:\n    1. $(0.1,1000,6)$ as a typical rare-event design targeting $P_f \\approx 10^{-6}$.\n    2. $(0.1,200,6)$ to examine increased estimator variance with smaller conditional sample size.\n    3. $(0.1,10000,6)$ to examine reduced variance with larger conditional sample size.\n    4. $(0.2,800,9)$ to examine a different $p_0$ yielding approximately the same target rarity level.\n    5. $(0.05,500,5)$ to examine a more aggressive level probability with fewer levels.\n- Produce as final output a single line containing the estimator variances for the five test cases as a comma-separated list enclosed in square brackets, for example, \"[v1,v2,v3,v4,v5]\". Each entry must be a floating-point number. No other text should be printed.\n\nAll quantities are dimensionless, so no physical units are required. Angles are not involved. Express $p_0$ values as decimals in $(0,1)$.",
            "solution": "The Subset Simulation (SuS) framework estimates a rare-event probability $P_f$ by factorizing it into a product of more probable conditional events. The failure event is $\\{Y \\ge b_L\\}$ for a scalar performance variable $Y$, here modeled as $Y \\sim \\mathcal{N}(\\mu,\\sigma^2)$ due to aggregation of numerous uncertainties consistent with the Central Limit Theorem (CLT). In SuS, we select intermediate thresholds $\\{b_\\ell\\}_{\\ell=1}^L$ to form nested events $\\{Y \\ge b_1\\} \\supset \\dots \\supset \\{Y \\ge b_L\\}$, and design the conditional exceedance probability at each level to be a constant $p_0 \\in (0,1)$. This yields \n$$\nP_f \\approx \\prod_{\\ell=1}^L p_0 = p_0^L,\n$$\nwhich guides the choice of $L$ and $p_0$ such that $p_0^L \\approx 10^{-6}$ for the rare-event slope failure.\n\nThreshold design under the Gaussian model exploits the monotonicity of tail probabilities with thresholds. For a given $p_0$ and level index $\\ell$, the unconditional tail probability requirement $\\mathbb{P}(Y \\ge b_\\ell) = p_0^\\ell$ translates to a quantile equation via the standard normal cumulative distribution function (CDF) $\\Phi(\\cdot)$:\n$$\n\\mathbb{P}(Y \\ge b_\\ell) = 1 - \\Phi\\!\\left(\\frac{b_\\ell - \\mu}{\\sigma}\\right) = p_0^\\ell.\n$$\nSolving for $b_\\ell$ gives\n$$\nb_\\ell = \\mu + \\sigma \\,\\Phi^{-1}\\!\\left(1 - p_0^\\ell\\right),\n$$\nwhere $\\Phi^{-1}(\\cdot)$ denotes the inverse CDF (quantile function) of the standard normal distribution. For a standardized $Y$ with $\\mu=0$ and $\\sigma=1$, this simplifies to \n$$\nb_\\ell = \\Phi^{-1}\\!\\left(1 - p_0^\\ell\\right).\n$$\nThis sequence ensures $\\{Y \\ge b_\\ell\\}$ are nested with prescribed unconditional tail probabilities.\n\nWe now derive the estimator variance as a function of the conditional sample size $m$, the level count $L$, and the constant conditional probability $p_0$. At level $\\ell$, draw $m$ samples and form the indicator variables $I_{\\ell,i}$, where $I_{\\ell,i}=1$ if the $\\ell$th-level condition is satisfied and $0$ otherwise. Under the design surrogate that treats the $I_{\\ell,i}$ as independent and identically distributed Bernoulli random variables with success probability $p_0$, the sample proportion \n$$\n\\hat{p}_\\ell = \\frac{1}{m}\\sum_{i=1}^m I_{\\ell,i}\n$$\nis an unbiased estimator of $p_0$, i.e., $\\mathbb{E}[\\hat{p}_\\ell] = p_0$, with variance \n$$\n\\mathrm{Var}(\\hat{p}_\\ell) = \\frac{p_0(1-p_0)}{m}.\n$$\nThe SuS estimator for the failure probability is the product of the $L$ estimated conditional probabilities, \n$$\n\\hat{P}_f = \\prod_{\\ell=1}^L \\hat{p}_\\ell.\n$$\nAssuming independence across levels for the estimators (a standard design idealization providing a lower bound on variance when Markov Chain Monte Carlo correlations are negligible or effectively controlled), we can compute the variance of the product using the identity for independent random variables $X_1,\\dots,X_L$:\n$$\n\\mathrm{Var}\\!\\left(\\prod_{\\ell=1}^L X_\\ell\\right) = \\prod_{\\ell=1}^L \\mathbb{E}[X_\\ell^2] - \\prod_{\\ell=1}^L \\left(\\mathbb{E}[X_\\ell]\\right)^2.\n$$\nHere $X_\\ell=\\hat{p}_\\ell$, so we require $\\mathbb{E}[\\hat{p}_\\ell^2]$. For a sample proportion of $m$ independent Bernoulli trials with success probability $p_0$, we write\n$$\n\\mathbb{E}[\\hat{p}_\\ell^2] = \\mathrm{Var}(\\hat{p}_\\ell) + \\left(\\mathbb{E}[\\hat{p}_\\ell]\\right)^2 = \\frac{p_0(1-p_0)}{m} + p_0^2.\n$$\nSubstituting yields\n$$\n\\mathrm{Var}(\\hat{P}_f) = \\prod_{\\ell=1}^L \\left(p_0^2 + \\frac{p_0(1-p_0)}{m}\\right) - \\prod_{\\ell=1}^L p_0^2.\n$$\nBecause $p_0$ is constant across levels, this simplifies to\n$$\n\\mathrm{Var}(\\hat{P}_f) = \\left(p_0^2 + \\frac{p_0(1-p_0)}{m}\\right)^L - p_0^{2L}.\n$$\nIt is enlightening to factor $p_0^{2L}$:\n$$\n\\mathrm{Var}(\\hat{P}_f) = p_0^{2L}\\left[\\left(1 + \\frac{1-p_0}{m\\,p_0}\\right)^L - 1\\right],\n$$\nexplicitly showing how the variance scales with $m$ (decreasing as $m$ increases) and with $L$ (increasing with more levels for fixed $m$ and $p_0$). Note that the mean of the estimator is $\\mathbb{E}[\\hat{P}_f]=p_0^L$, consistent with an unbiased product estimator under independence.\n\nAlgorithmic design for the program:\n1. For each test case $(p_0,m,L)$, compute the level thresholds $b_\\ell$ using $b_\\ell=\\Phi^{-1}(1-p_0^\\ell)$ for $\\ell=1,\\dots,L$ with $\\mu=0$, $\\sigma=1$. This validates the threshold design step but does not affect the variance expression under the independence surrogate.\n2. Compute the estimator variance using \n$$\n\\mathrm{Var}(\\hat{P}_f) = \\left(p_0^2 + \\frac{p_0(1-p_0)}{m}\\right)^L - p_0^{2L}.\n$$\n3. Aggregate the variances for the five test cases into a single list and print it as a single line in the required format.\n\nThis approach is grounded in the foundational definitions of Bernoulli trials and properties of independent random variables, connecting the geomechanical rare-event estimation task to a tractable statistical design formula. The Gaussian threshold design aligns with the monotonic mapping from unconditional tail probabilities to quantiles, ensuring a scientifically realistic and self-consistent setup for Subset Simulation in the rare-event regime.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef subset_sim_variance(p0: float, m: int, L: int) - float:\n    \"\"\"\n    Compute the variance of the Subset Simulation estimator under\n    the independence surrogate:\n        Var(P_hat_f) = (p0^2 + p0*(1 - p0)/m)^L - p0^(2L)\n    \"\"\"\n    term = (p0 ** 2) + (p0 * (1.0 - p0) / m)\n    return (term ** L) - (p0 ** (2 * L))\n\ndef design_thresholds_gaussian(p0: float, L: int, mu: float = 0.0, sigma: float = 1.0):\n    \"\"\"\n    Design intermediate thresholds for Y ~ N(mu, sigma^2) such that\n    P(Y = b_l) = p0^l for l = 1..L.\n    Returns a list of thresholds [b_1, ..., b_L].\n    \"\"\"\n    thresholds = []\n    for l in range(1, L + 1):\n        tail_prob = p0 ** l\n        # b_l = mu + sigma * Phi^{-1}(1 - p0^l)\n        bl = mu + sigma * norm.ppf(1.0 - tail_prob)\n        thresholds.append(bl)\n    return thresholds\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case is a tuple: (p0, m, L)\n    test_cases = [\n        (0.1, 1000, 6),   # Typical rare-event design P_f ≈ 1e-6\n        (0.1, 200, 6),    # Smaller m increases variance\n        (0.1, 10000, 6),  # Larger m decreases variance\n        (0.2, 800, 9),    # Different p0, similar rarity\n        (0.05, 500, 5),   # More aggressive p0 with fewer levels\n    ]\n\n    results = []\n    for p0, m, L in test_cases:\n        # Threshold design (computed but not printed, validates the design step)\n        _thresholds = design_thresholds_gaussian(p0, L, mu=0.0, sigma=1.0)\n\n        # Compute variance of the SuS estimator under independence surrogate\n        var_est = subset_sim_variance(p0, m, L)\n        results.append(var_est)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}