{
    "hands_on_practices": [
        {
            "introduction": "Before designing a solution, a good engineer must first understand the problem. This foundational exercise guides you through an exact analysis of the stiffness matrix for a simple one-dimensional elastic bar . By deriving the spectral condition number as a function of mesh refinement, you will discover firsthand how numerical ill-conditioning is an inherent consequence of discretization and gain a fundamental appreciation for why preconditioning is not just an optimization, but a necessity for solving large-scale problems.",
            "id": "3590176",
            "problem": "Consider a one-dimensional ($1$D) prismatic linear elastic bar of length $L$, Young’s modulus $E$, and constant cross-sectional area $A$. The axial displacement field $u(x)$ satisfies the strong form of equilibrium $-\\frac{d}{dx}\\!\\left(EA\\,\\frac{du}{dx}\\right)=f(x)$ together with homogeneous Dirichlet boundary conditions $u(0)=0$ and $u(L)=0$. Discretize the bar using the Galerkin finite element method with $n$ uniform linear elements (each of length $h=L/n$) and standard nodal “hat” shape functions. Assemble the global stiffness matrix $A$ associated with the interior nodal degrees of freedom (there are $n-1$ interior nodes due to the homogeneous Dirichlet boundary conditions). \n\nStarting from the finite element weak form and the definition of the element stiffness for linear shape functions, derive the exact eigenvalues of the assembled stiffness matrix $A$ for this uniform mesh and boundary condition setting. Then, using the definition of the spectral condition number in the Euclidean ($2$-)norm for a symmetric positive definite matrix, $\\kappa_{2}(A)=\\lambda_{\\max}(A)/\\lambda_{\\min}(A)$, provide a closed-form analytic expression for $\\kappa_{2}(A)$ as a function of $n$. \n\nYour final answer must be a single closed-form expression in terms of $n$ only. No rounding is required. Explain how this eigenstructure connects to the performance of iterative solvers such as the Conjugate Gradient (CG) method and motivates preconditioning design, but ensure that the final reported quantity is solely the analytic expression for the condition number as a function of $n$.",
            "solution": "The axial equilibrium of the one-dimensional ($1$D) bar is governed by the strong form $-\\frac{d}{dx}\\!\\left(EA\\,\\frac{du}{dx}\\right)=f(x)$ with homogeneous Dirichlet boundary conditions $u(0)=0$ and $u(L)=0$. For the stiffness analysis and eigenstructure derivation, it is sufficient to consider the homogeneous case $f(x)=0$, since the stiffness matrix $A$ is defined by the bilinear form of the left-hand side operator.\n\nThe Galerkin finite element method with $n$ uniform linear elements partitions the domain into nodes at $x_{j}=j\\,h$ for $j=0,1,\\dots,n$ with $h=L/n$. The interior nodal unknowns are $u_{j}$ for $j=1,\\dots,n-1$, since the boundary values $u_{0}=0$ and $u_{n}=0$ are prescribed by the homogeneous Dirichlet boundary conditions. For a single linear element spanning $\\left[x_{e},x_{e+1}\\right]$, the element stiffness matrix computed from the weak form and linear shape functions is\n$$\nk^{(e)}=\\frac{EA}{h}\\begin{pmatrix}1 & -1 \\\\ -1 & 1\\end{pmatrix}.\n$$\nAssembly over the $n$ elements produces a global stiffness matrix $A$ of size $(n-1)\\times(n-1)$ for the interior degrees of freedom. The resulting matrix has the form\n$$\nA=\\frac{EA}{h}\\,T,\n$$\nwhere $T$ is the tridiagonal Toeplitz matrix\n$$\nT=\\begin{pmatrix}\n2 & -1 & 0 & \\cdots & 0 \\\\\n-1 & 2 & -1 & \\ddots & \\vdots \\\\\n0 & -1 & 2 & \\ddots & 0 \\\\\n\\vdots & \\ddots & \\ddots & \\ddots & -1 \\\\\n0 & \\cdots & 0 & -1 & 2\n\\end{pmatrix}.\n$$\nThis $T$ is the standard discrete Dirichlet Laplacian on a uniform one-dimensional grid with $(n-1)$ interior points.\n\nTo compute the exact eigenvalues of $T$, consider the candidate eigenvectors $v^{(k)}\\in\\mathbb{R}^{n-1}$ for $k=1,2,\\dots,n-1$ with components\n$$\nv^{(k)}_{j}=\\sin\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right),\\quad j=1,2,\\dots,n-1.\n$$\nWe show that $T\\,v^{(k)}=\\lambda_{k}\\,v^{(k)}$ for appropriate $\\lambda_{k}$. Evaluating the action of $T$ on $v^{(k)}$ at index $j$ gives\n$$\n(T\\,v^{(k)})_{j}=-v^{(k)}_{j-1}+2\\,v^{(k)}_{j}-v^{(k)}_{j+1},\n$$\nwith the convention that $v^{(k)}_{0}=0$ and $v^{(k)}_{n}=0$ consistent with the Dirichlet boundary conditions. Using the sine addition formulas,\n$$\nv^{(k)}_{j\\pm 1}=\\sin\\!\\left(\\frac{(j\\pm 1)\\,k\\,\\pi}{n}\\right)=\\sin\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right)\\cos\\!\\left(\\frac{k\\,\\pi}{n}\\right)\\pm\\cos\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right)\\sin\\!\\left(\\frac{k\\,\\pi}{n}\\right),\n$$\nwe obtain\n\\begin{align*}\n(T\\,v^{(k)})_{j}\n&=-\\left[\\sin\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right)\\cos\\!\\left(\\frac{k\\,\\pi}{n}\\right)-\\cos\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right)\\sin\\!\\left(\\frac{k\\,\\pi}{n}\\right)\\right]\\\\\n&\\quad+2\\,\\sin\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right)\\\\\n&\\quad-\\left[\\sin\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right)\\cos\\!\\left(\\frac{k\\,\\pi}{n}\\right)+\\cos\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right)\\sin\\!\\left(\\frac{k\\,\\pi}{n}\\right)\\right]\\\\\n&=2\\,\\sin\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right)-2\\,\\sin\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right)\\cos\\!\\left(\\frac{k\\,\\pi}{n}\\right)\\\\\n&=\\left[2-2\\cos\\!\\left(\\frac{k\\,\\pi}{n}\\right)\\right]\\sin\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right).\n\\end{align*}\nTherefore $v^{(k)}$ is indeed an eigenvector and the corresponding eigenvalue of $T$ is\n$$\n\\lambda_{k}(T)=2-2\\cos\\!\\left(\\frac{k\\,\\pi}{n}\\right)=4\\,\\sin^{2}\\!\\left(\\frac{k\\,\\pi}{2\\,n}\\right),\\quad k=1,2,\\dots,n-1.\n$$\nSince $A=\\frac{EA}{h}\\,T$, the eigenvalues of $A$ are scaled by the factor $\\frac{EA}{h}$:\n$$\n\\lambda_{k}(A)=\\frac{EA}{h}\\,\\lambda_{k}(T)=\\frac{EA}{h}\\,4\\,\\sin^{2}\\!\\left(\\frac{k\\,\\pi}{2\\,n}\\right),\\quad k=1,2,\\dots,n-1.\n$$\nThe spectral condition number in the Euclidean ($2$-)norm for a symmetric positive definite matrix is\n$$\n\\kappa_{2}(A)=\\frac{\\lambda_{\\max}(A)}{\\lambda_{\\min}(A)}.\n$$\nThe minimum eigenvalue occurs at $k=1$ and the maximum at $k=n-1$. Using the trigonometric identity $\\sin\\!\\left(\\frac{(n-1)\\,\\pi}{2\\,n}\\right)=\\sin\\!\\left(\\frac{\\pi}{2}-\\frac{\\pi}{2\\,n}\\right)=\\cos\\!\\left(\\frac{\\pi}{2\\,n}\\right)$, we obtain\n\\begin{align*}\n\\lambda_{\\min}(A)&=\\frac{EA}{h}\\,4\\,\\sin^{2}\\!\\left(\\frac{\\pi}{2\\,n}\\right),\\\\\n\\lambda_{\\max}(A)&=\\frac{EA}{h}\\,4\\,\\sin^{2}\\!\\left(\\frac{(n-1)\\,\\pi}{2\\,n}\\right)=\\frac{EA}{h}\\,4\\,\\cos^{2}\\!\\left(\\frac{\\pi}{2\\,n}\\right).\n\\end{align*}\nHence\n\\begin{align*}\n\\kappa_{2}(A)\n&=\\frac{\\frac{EA}{h}\\,4\\,\\cos^{2}\\!\\left(\\frac{\\pi}{2\\,n}\\right)}{\\frac{EA}{h}\\,4\\,\\sin^{2}\\!\\left(\\frac{\\pi}{2\\,n}\\right)}\n=\\frac{\\cos^{2}\\!\\left(\\frac{\\pi}{2\\,n}\\right)}{\\sin^{2}\\!\\left(\\frac{\\pi}{2\\,n}\\right)}\n=\\cot^{2}\\!\\left(\\frac{\\pi}{2\\,n}\\right).\n\\end{align*}\nThis is an exact closed-form expression in terms of $n$. For large $n$, the small-angle approximation $\\sin\\!\\left(\\frac{\\pi}{2\\,n}\\right)\\approx\\frac{\\pi}{2\\,n}$ and $\\cos\\!\\left(\\frac{\\pi}{2\\,n}\\right)\\approx 1$ yields the asymptotic estimate\n$$\n\\kappa_{2}(A)\\sim\\left(\\frac{2\\,n}{\\pi}\\right)^{2},\n$$\nwhich shows that the condition number grows quadratically with $n$. This growth explains the deterioration of convergence rates for iterative solvers such as the Conjugate Gradient (CG) method on refined meshes and motivates the use of preconditioning techniques (e.g., Jacobi scaling, incomplete Cholesky factorization, or multigrid methods) that aim to cluster the eigenvalues and reduce $\\kappa_{2}$ toward mesh-independent values.",
            "answer": "$$\\boxed{\\cot^{2}\\!\\left(\\frac{\\pi}{2\\,n}\\right)}$$"
        },
        {
            "introduction": "Having established the need for preconditioning, we now shift from diagnosis to design. This practice explores a powerful strategy for building effective preconditioners by using physical intuition to identify and handle a system's \"slowest\" or most problematic modes of response . You will construct a two-grid method for a stratified medium by selecting coarse-level vectors that correspond to physical behaviors like rigid-body motion, a core principle that underpins advanced techniques like algebraic multigrid and domain decomposition.",
            "id": "3552389",
            "problem": "Consider a one-dimensional stratified elastic bar modeled as a chain of springs with two stiffer layers weakly connected across an interface. Let there be $4$ nodal displacement unknowns, denoted by the vector $u \\in \\mathbb{R}^{4}$. The bar is anchored to ground at the two outer nodes by springs of stiffness $1$, interior springs within each stiff layer have stiffness $1$, and the interface spring connecting the two layers has stiffness $\\epsilon$, where $\\epsilon \\in (0,\\infty)$. By the principle of linear elasticity and finite element or finite difference stiffness assembly, the global stiffness matrix $K \\in \\mathbb{R}^{4 \\times 4}$ has the form\n$$\nK \\;=\\;\n\\begin{pmatrix}\n2 & -1 & 0 & 0 \\\\\n-1 & 1+\\epsilon & -\\epsilon & 0 \\\\\n0 & -\\epsilon & 1+\\epsilon & -1 \\\\\n0 & 0 & -1 & 2\n\\end{pmatrix}.\n$$\nYou are to solve the linear system $K u = f$ using a two-grid preconditioned Richardson iteration that uses:\n- a single post-smoothing Richardson step with relaxation parameter $\\omega$, and\n- an exact coarse correction built from a physics-informed coarse space spanned by the following two vectors: the rigid-body translation mode $z_{1} = (1,1,1,1)^{\\top}$ and the layer-wise average difference $z_{2} = (1,1,-1,-1)^{\\top}$.\n\nLet $Z = [z_{1}\\; z_{2}] \\in \\mathbb{R}^{4 \\times 2}$. The two-grid error propagation operator for one sweep is\n$$\nE(\\omega) \\;=\\; \\bigl(I - Z (Z^{\\top} K Z)^{-1} Z^{\\top} K \\bigr)\\, \\bigl(I - \\omega K\\bigr).\n$$\nStarting from the foundational facts that:\n- $K$ is symmetric positive definite, so its spectrum is real and positive,\n- the coarse correction $I - Z (Z^{\\top} K Z)^{-1} Z^{\\top} K$ is the $K$-orthogonal projector onto the $K$-orthogonal complement of $\\operatorname{span}(Z)$, and\n- the optimal Richardson parameter on a subspace with eigenvalues in an interval $[\\lambda_{\\min},\\lambda_{\\max}]$ is $\\omega_{\\mathrm{opt}} = \\tfrac{2}{\\lambda_{\\min} + \\lambda_{\\max}}$ with corresponding spectral radius $\\rho_{\\mathrm{opt}} = \\tfrac{\\lambda_{\\max} - \\lambda_{\\min}}{\\lambda_{\\max} + \\lambda_{\\min}}$,\n\nderive, from first principles, a closed-form expression in terms of $\\epsilon$ for the optimal two-grid asymptotic convergence factor, i.e., the spectral radius of $E(\\omega_{\\mathrm{opt}})$ restricted to the $K$-orthogonal complement of $\\operatorname{span}(Z)$.\n\nExpress your final answer as a single simplified analytic expression in terms of $\\epsilon$. Do not include units. No numerical rounding is required.",
            "solution": "The asymptotic convergence factor is the spectral radius of the error propagation operator $E(\\omega)$. The coarse-grid correction operator, $P_C = I - Z (Z^{\\top} K Z)^{-1} Z^{\\top} K$, is a projector that eliminates any error component in the coarse space $V_c = \\operatorname{span}(Z)$. Therefore, any error vector $v \\in V_c$ is mapped to zero by $E(\\omega)$, and the convergence is governed by the action of $E(\\omega)$ on the $K$-orthogonal complement of $V_c$, which we denote as the fine space $V_f$.\n\nFor an error vector $e \\in V_f$, the coarse-correction projector acts as the identity, $P_C e = e$. Thus, the error propagation operator restricted to $V_f$ is simply the Richardson smoother $(I - \\omega K)|_{V_f}$. The optimal convergence factor for this iteration is given by\n$$ \\rho_{\\mathrm{opt}} = \\frac{\\lambda_{\\max} - \\lambda_{\\min}}{\\lambda_{\\max} + \\lambda_{\\min}}, $$\nwhere $\\lambda_{\\min}$ and $\\lambda_{\\max}$ are the minimum and maximum eigenvalues of the stiffness operator $K$ restricted to the fine space $V_f$. These are the extrema of the Rayleigh quotient $\\frac{v^{\\top}Kv}{v^{\\top}v}$ for all non-zero $v \\in V_f$.\n\nFirst, we characterize the fine space $V_f$. A vector $v \\in \\mathbb{R}^4$ belongs to $V_f$ if it is $K$-orthogonal to the basis vectors of $V_c$, i.e., $v^{\\top}Kz_1 = 0$ and $v^{\\top}Kz_2 = 0$. We compute $Kz_1$ and $Kz_2$:\n$$\nKz_1 = \\begin{pmatrix} 2 & -1 & 0 & 0 \\\\ -1 & 1+\\epsilon & -\\epsilon & 0 \\\\ 0 & -\\epsilon & 1+\\epsilon & -1 \\\\ 0 & 0 & -1 & 2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 1 \\end{pmatrix}, \\quad\nKz_2 = \\begin{pmatrix} 2 & -1 & 0 & 0 \\\\ -1 & 1+\\epsilon & -\\epsilon & 0 \\\\ 0 & -\\epsilon & 1+\\epsilon & -1 \\\\ 0 & 0 & -1 & 2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ -1 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 2\\epsilon \\\\ -2\\epsilon \\\\ -1 \\end{pmatrix}\n$$\nFor a vector $v = (v_1, v_2, v_3, v_4)^{\\top}$, the conditions for being in $V_f$ are:\n1.  $v^{\\top}Kz_1 = v_1 + v_4 = 0 \\implies v_4 = -v_1$.\n2.  $v^{\\top}Kz_2 = v_1 + 2\\epsilon v_2 - 2\\epsilon v_3 - v_4 = 0$.\nSubstituting $v_4 = -v_1$ into the second equation gives $2v_1 + 2\\epsilon(v_2-v_3) = 0$, which simplifies to $v_1 = -\\epsilon(v_2-v_3)$.\n\nThe fine space $V_f$ is two-dimensional. We can find a basis by choosing linearly independent values for $v_2$ and $v_3$:\n-   Let $v_2=1, v_3=0$. Then $v_1 = -\\epsilon$ and $v_4 = \\epsilon$. This gives the basis vector $w_1 = (-\\epsilon, 1, 0, \\epsilon)^{\\top}$.\n-   Let $v_2=0, v_3=1$. Then $v_1 = \\epsilon$ and $v_4 = -\\epsilon$. This gives the basis vector $w_2 = (\\epsilon, 0, 1, -\\epsilon)^{\\top}$.\n\nLet $W = [w_1 \\; w_2]$ be the matrix whose columns form a basis for $V_f$. Any vector $v \\in V_f$ can be written as $v = Wc$ for some coordinate vector $c \\in \\mathbb{R}^2$. The extremal eigenvalues are the eigenvalues of the generalized eigenvalue problem $(W^{\\top}KW)c = \\lambda (W^{\\top}W)c$.\nWe compute the matrices $W^{\\top}W$ and $W^{\\top}KW$:\n$$ W^{\\top}W = \\begin{pmatrix} 1+2\\epsilon^2 & -2\\epsilon^2 \\\\ -2\\epsilon^2 & 1+2\\epsilon^2 \\end{pmatrix} $$\n$$ W^{\\top}KW = \\begin{pmatrix} 4\\epsilon^2+3\\epsilon+1 & -4\\epsilon^2-3\\epsilon \\\\ -4\\epsilon^2-3\\epsilon & 4\\epsilon^2+3\\epsilon+1 \\end{pmatrix} $$\nThe eigenvalues of this pencil are:\n$$ \\lambda_1 = \\frac{(4\\epsilon^2+3\\epsilon+1) - (-4\\epsilon^2-3\\epsilon)}{(1+2\\epsilon^2) - (-2\\epsilon^2)} = \\frac{8\\epsilon^2+6\\epsilon+1}{1+4\\epsilon^2} $$\n$$ \\lambda_2 = \\frac{(4\\epsilon^2+3\\epsilon+1) + (-4\\epsilon^2-3epsilon)}{(1+2\\epsilon^2) + (-2\\epsilon^2)} = \\frac{1}{1} = 1 $$\nSince $\\epsilon>0$, it can be shown that $\\lambda_1 > 1$. Thus, we have the extremal eigenvalues:\n$$ \\lambda_{\\min} = 1, \\qquad \\lambda_{\\max} = \\frac{8\\epsilon^2+6\\epsilon+1}{1+4\\epsilon^2} $$\nFinally, we substitute these into the formula for the optimal convergence factor:\n\\begin{align*}\n\\rho_{\\mathrm{opt}} &= \\frac{\\lambda_{\\max} - \\lambda_{\\min}}{\\lambda_{\\max} + \\lambda_{\\min}} \\\\\n&= \\frac{\\frac{8\\epsilon^2+6\\epsilon+1}{1+4\\epsilon^2} - 1}{\\frac{8\\epsilon^2+6\\epsilon+1}{1+4\\epsilon^2} + 1} = \\frac{8\\epsilon^2+6\\epsilon+1 - (1+4\\epsilon^2)}{8\\epsilon^2+6\\epsilon+1 + (1+4\\epsilon^2)} \\\\\n&= \\frac{4\\epsilon^2+6\\epsilon}{12\\epsilon^2+6\\epsilon+2} = \\frac{2\\epsilon^2+3\\epsilon}{6\\epsilon^2+3\\epsilon+1}\n\\end{align*}",
            "answer": "$$\n\\boxed{\\frac{2\\epsilon^2+3\\epsilon}{6\\epsilon^2+3\\epsilon+1}}\n$$"
        },
        {
            "introduction": "This final practice moves from analytical derivations to a practical, computational setting highly relevant to geomechanics. You will analyze a Schur-complement-based preconditioner for the quasi-static Biot consolidation problem, a canonical model for fluid-saturated porous media . The exercise focuses on assessing the impact of a common computational shortcut—mass lumping—on the preconditioner's optimality, equipping you with the tools to make and justify practical implementation choices in complex multiphysics simulations.",
            "id": "3552383",
            "problem": "Consider the backward-Euler semi-discretization in time and Galerkin discretization in space of the one-dimensional, quasi-static Biot consolidation problem on the unit interval with homogeneous Dirichlet conditions on displacement and homogeneous Neumann conditions on pressure. The resulting linear system at each time step has the symmetric saddle-point structure\n$$\n\\begin{bmatrix}\nA & B^{\\top} \\\\\nB & -C\n\\end{bmatrix}\n\\begin{bmatrix}\nu \\\\\np\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nf \\\\\ng\n\\end{bmatrix},\n$$\nwhere $A \\in \\mathbb{R}^{n_u \\times n_u}$ is the symmetric positive definite (SPD) elasticity block, $B \\in \\mathbb{R}^{n_p \\times n_u}$ is the discrete divergence coupling, and $C \\in \\mathbb{R}^{n_p \\times n_p}$ is the SPD pressure block given by\n$$\nC = \\frac{1}{\\Delta t} M + \\kappa L,\n$$\nwith $\\Delta t > 0$ denoting the time step, $\\kappa > 0$ the nondimensional permeability, $M$ the consistent pressure mass matrix, and $L$ the pressure diffusion (stiffness) matrix. The optimal Schur-complement preconditioner uses the Schur operator\n$$\nS = B A^{-1} B^{\\top} + C.\n$$\nA frequently used approximation replaces $M$ by its row-sum lumped version $M^{\\ell}$, yielding the preconditioner\n$$\n\\tilde{S} = B A^{-1} B^{\\top} + \\tilde{C}, \\quad \\tilde{C} = \\frac{1}{\\Delta t} M^{\\ell} + \\kappa L.\n$$\nYou will assess the impact of mass lumping in the pressure block on the optimality of the Schur preconditioner for large $\\Delta t$ and provide a computable criterion indicating when lumping degrades spectral equivalence.\n\nFundamental base and discrete setting:\n- Use a uniform mesh of $N$ equal elements on $[0,1]$ with mesh size $h = 1/N$. Take continuous, piecewise-linear (also called $P1$) basis functions for both displacement and pressure. Enforce homogeneous Dirichlet boundary conditions on displacement by eliminating the boundary displacement degrees of freedom at $x=0$ and $x=1$, so $n_u = N-1$, while keeping all $N+1$ nodal pressure degrees of freedom so $n_p = N+1$.\n- Assemble the following standard finite element matrices using the core Galerkin definitions:\n  1. Elasticity stiffness $A \\in \\mathbb{R}^{n_u \\times n_u}$ from the bilinear form $\\int_0^1 E \\, u'(x) v'(x) \\, dx$ with modulus set to $E = 1$:\n     local contribution on each element $K_e = [x_e, x_{e+1}]$ is $(1/h) \\begin{bmatrix} 1 & -1 \\\\ -1 & 1 \\end{bmatrix}$, assembled and then restricted to interior displacement nodes.\n  2. Consistent pressure mass matrix $M \\in \\mathbb{R}^{n_p \\times n_p}$ from $\\int_0^1 p(x) q(x) \\, dx$:\n     local contribution $(h/6) \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix}$ assembled over all nodes including boundaries.\n  3. Pressure diffusion matrix $L \\in \\mathbb{R}^{n_p \\times n_p}$ from $\\int_0^1 p'(x) q'(x) \\, dx$:\n     local contribution $(1/h) \\begin{bmatrix} 1 & -1 \\\\ -1 & 1 \\end{bmatrix}$ assembled over all nodes including boundaries, corresponding to homogeneous Neumann boundary conditions.\n  4. Coupling matrix $B \\in \\mathbb{R}^{n_p \\times n_u}$ from the mixed bilinear form $\\int_0^1 (\\nabla \\cdot v) \\, p \\, dx$ in one dimension where $\\nabla \\cdot v = dv/dx$:\n     on each element, with local pressure nodes indexed by $a \\in \\{1,2\\}$ and local displacement nodes indexed by $b \\in \\{1,2\\}$, use\n     $$\n     B_e[a,b] = \\int_{K_e} \\phi_a(x) \\, \\frac{d \\psi_b}{dx}(x) \\, dx = \\begin{bmatrix} -\\tfrac{1}{2} & \\tfrac{1}{2} \\\\ -\\tfrac{1}{2} & \\tfrac{1}{2} \\end{bmatrix}_{a,b},\n     $$\n     then assemble globally, omitting displacement columns associated with boundary nodes at $x=0$ and $x=1$.\n- Define the lumped mass matrix $M^{\\ell}$ as the diagonal matrix of row sums of $M$.\n\nPrinciple-based evaluation target:\n- The exact Schur operator is $S = B A^{-1} B^{\\top} + \\frac{1}{\\Delta t} M + \\kappa L$.\n- The lumped-mass Schur preconditioner is $\\tilde{S} = B A^{-1} B^{\\top} + \\frac{1}{\\Delta t} M^{\\ell} + \\kappa L$.\n- Spectral equivalence is quantified by the generalized eigenvalue problem\n$$\nS x = \\lambda \\, \\tilde{S} x,\n$$\nwhose eigenvalues $\\lambda$ characterize the quality of the preconditioner. Optimality is preserved if the spectrum of $\\tilde{S}^{-1} S$ remains bounded away from $0$ and $\\infty$ independent of $h$, $\\Delta t$, and $\\kappa$.\n- The perturbation introduced by lumping is $\\tilde{S} - S = \\frac{1}{\\Delta t}(M^{\\ell} - M)$. Using the spectral norm bound for symmetric positive definite (SPD) operators, one can show that the eigenvalues of $\\tilde{S}^{-1} S$ lie in the interval $[1 - \\varepsilon, \\, 1 + \\varepsilon]$ with\n$$\n\\varepsilon \\le \\frac{1}{\\Delta t} \\, \\lambda_{\\max}\\!\\left( \\tilde{C}^{-1/2} \\, (M^{\\ell} - M) \\, \\tilde{C}^{-1/2} \\right),\n\\quad \\text{where } \\tilde{C} = \\frac{1}{\\Delta t} M^{\\ell} + \\kappa L.\n$$\nThis bound isolates the roles of $\\Delta t$, $\\kappa$, $h$, and the mass-lumping error through a computable generalized eigenvalue.\n- A practical degradation criterion is therefore: declare that mass lumping degrades spectral equivalence whenever $\\varepsilon \\ge 1/2$, which guarantees that the lower spectral bound $1 - \\varepsilon$ drops below $1/2$. In terms of matrices, this is the condition\n$$\n\\frac{1}{\\Delta t} \\, \\lambda_{\\max}\\!\\left( \\tilde{C} ^{-1/2} \\, (M^{\\ell} - M) \\, \\tilde{C}^{-1/2} \\right) \\ge \\frac{1}{2}.\n$$\nAlgorithmic task:\n- Implement the above assembly on a uniform mesh and compute, for each test case, the generalized eigenvalues of $S x = \\lambda \\, \\tilde{S} x$, along with the bound $\\varepsilon$ and the degradation decision based on the inequality above.\n\nTest suite and parameters:\n- Use $N = 64$ elements so that $h = 1/N$. Set the elastic modulus to $E = 1$ (dimensionless).\n- Evaluate the following four cases to cover the happy path, time-step dominance regimes, and an edge case:\n  1. Case A (small $\\Delta t$): $(\\kappa, \\Delta t) = (1.0, 10^{-4})$.\n  2. Case B (moderate $\\Delta t$): $(\\kappa, \\Delta t) = (1.0, 10^{-2})$.\n  3. Case C (large $\\Delta t$): $(\\kappa, \\Delta t) = (1.0, 1)$.\n  4. Case D (edge case, very low permeability): $(\\kappa, \\Delta t) = (10^{-6}, 10^{-2})$.\n\nQuantities to compute for each case:\n- The minimum and maximum generalized eigenvalues $(\\lambda_{\\min}, \\lambda_{\\max})$ of $S x = \\lambda \\, \\tilde{S} x$.\n- The condition number $\\kappa_{\\text{cond}} = \\lambda_{\\max} / \\lambda_{\\min}$ of the preconditioned operator $\\tilde{S}^{-1} S$.\n- The bound $\\varepsilon = \\frac{1}{\\Delta t} \\, \\lambda_{\\max}\\!\\left( \\tilde{C}^{-1/2} \\, (M^{\\ell} - M) \\, \\tilde{C}^{-1/2} \\right)$.\n- The degradation indicator as an integer defined by\n$$\n\\text{degrade} = \\begin{cases}\n1, & \\text{if } \\varepsilon \\ge \\tfrac{1}{2}, \\\\\n0, & \\text{otherwise}.\n\\end{cases}\n$$\n\nRequired final output format:\n- Your program should produce a single line of output containing a comma-separated list of four sublists, one per test case, each sublist in the form\n$$\n[\\lambda_{\\min}, \\lambda_{\\max}, \\kappa_{\\text{cond}}, \\varepsilon, \\text{degrade}],\n$$\nso the overall output looks like\n$$\n\\big[ [\\cdot,\\cdot,\\cdot,\\cdot,\\cdot], [\\cdot,\\cdot,\\cdot,\\cdot,\\cdot], [\\cdot,\\cdot,\\cdot,\\cdot,\\cdot], [\\cdot,\\cdot,\\cdot,\\cdot,\\cdot] \\big].\n$$\nAll numbers should be printed as floating-point values for $\\lambda_{\\min}$, $\\lambda_{\\max}$, $\\kappa_{\\text{cond}}$, and $\\varepsilon$, and as an integer ($0$ or $1$) for the degradation indicator. No units are required, as this problem is fully nondimensionalized.",
            "solution": "We begin from the standard discrete saddle-point structure for the quasi-static, backward-Euler time discretization of Biot consolidation,\n$$\n\\begin{bmatrix}\nA & B^{\\top} \\\\\nB & -C\n\\end{bmatrix}\n\\begin{bmatrix}\nu \\\\\np\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nf \\\\\ng\n\\end{bmatrix},\n$$\nwhere $A$ is the symmetric positive definite (SPD) stiffness from elasticity, $B$ is the discrete divergence coupling, and $C$ is the SPD pressure block\n$$\nC = \\frac{1}{\\Delta t} M + \\kappa L,\n$$\nwith $M$ the consistent pressure mass matrix and $L$ the pressure diffusion matrix. The Schur complement for the pressure is\n$$\nS = B A^{-1} B^{\\top} + C.\n$$\nA Schur preconditioner of the same algebraic form that lumps the pressure mass uses\n$$\n\\tilde{S} = B A^{-1} B^{\\top} + \\tilde{C}, \\quad \\tilde{C} = \\frac{1}{\\Delta t} M^{\\ell} + \\kappa L,\n$$\nwhere $M^{\\ell}$ is the diagonal matrix of row sums of $M$.\n\nFundamental finite element construction on a uniform mesh:\n- Take a uniform partition of $[0,1]$ into $N$ elements of size $h = 1/N$, and use continuous, piecewise-linear ($P1$) basis functions for displacement and pressure.\n- The elasticity stiffness matrix for displacement with homogeneous Dirichlet boundary conditions at both ends is assembled from the bilinear form $\\int_0^1 u'(x) v'(x) \\, dx$ with local $2 \\times 2$ contribution $(1/h) \\begin{bmatrix} 1 & -1 \\\\ -1 & 1 \\end{bmatrix}$; after eliminating the boundary degrees of freedom, $A \\in \\mathbb{R}^{(N-1)\\times(N-1)}$ is SPD.\n- The pressure mass and stiffness matrices are assembled over all $N+1$ pressure nodes from the core Galerkin definitions:\n  $$\n  M = \\sum_{e=1}^N \\frac{h}{6} \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix}_e, \\qquad\n  L = \\sum_{e=1}^N \\frac{1}{h} \\begin{bmatrix} 1 & -1 \\\\ -1 & 1 \\end{bmatrix}_e,\n  $$\n  where the subscript $e$ indicates assembly into the global matrix at the pressure nodes of element $e$; $L$ corresponds to homogeneous Neumann boundary conditions for pressure and is positive semidefinite, but $C$ is SPD due to the $\\frac{1}{\\Delta t} M$ term.\n- The coupling $B \\in \\mathbb{R}^{(N+1)\\times(N-1)}$ represents the mixed bilinear form $\\int_0^1 (\\nabla \\cdot v) \\, p \\, dx$ in one dimension with local $2 \\times 2$ contribution\n  $$\n  B_e[a,b] = \\int_{K_e} \\phi_a(x) \\, \\frac{d \\psi_b}{dx}(x) \\, dx = \\begin{bmatrix} -\\tfrac{1}{2} & \\tfrac{1}{2} \\\\ -\\tfrac{1}{2} & \\tfrac{1}{2} \\end{bmatrix}_{a,b},\n  $$\n  where the pressure basis $\\{\\phi_a\\}$ and displacement basis $\\{\\psi_b\\}$ are the standard local $P1$ basis functions. Global assembly omits displacement columns at boundary nodes to enforce homogeneous Dirichlet conditions on displacement.\n\nPrinciple-based spectral analysis:\n- By definition, the exact Schur operator is\n  $$\n  S = H + C, \\quad \\text{with } H := B A^{-1} B^{\\top} \\succeq 0.\n  $$\n  The lumped counterpart is\n  $$\n  \\tilde{S} = H + \\tilde{C} = H + \\frac{1}{\\Delta t} M^{\\ell} + \\kappa L.\n  $$\n- The preconditioning quality of $\\tilde{S}$ relative to $S$ is captured by the generalized symmetric positive definite eigenproblem\n  $$\n  S x = \\lambda \\, \\tilde{S} x.\n  $$\n  If all eigenvalues $\\lambda$ remain in a mesh- and parameter-independent interval $[\\underline{\\lambda}, \\overline{\\lambda}] \\subset (0,\\infty)$, the preconditioner is optimal.\n- The perturbation introduced by mass lumping is\n  $$\n  \\tilde{S} - S = \\frac{1}{\\Delta t} (M^{\\ell} - M).\n  $$\n  Since $S$ and $\\tilde{S}$ are SPD, their square roots and inverses are well-defined. Consider\n  $$\n  E := \\tilde{S}^{-1/2} ( \\tilde{S} - S ) \\, \\tilde{S}^{-1/2} = \\frac{1}{\\Delta t} \\, \\tilde{S}^{-1/2} (M^{\\ell} - M) \\tilde{S}^{-1/2}.\n  $$\n  Then $\\tilde{S}^{-1} S = I - E$, so every eigenvalue $\\lambda$ of $\\tilde{S}^{-1} S$ satisfies\n  $$\n  1 - \\|E\\|_2 \\le \\lambda \\le 1 + \\|E\\|_2.\n  $$\n  Using the Löwner order $H \\succeq 0 \\implies \\tilde{S} \\succeq \\tilde{C}$ and the monotonicity of the inverse, we obtain\n  $$\n  \\|E\\|_2 \\le \\frac{1}{\\Delta t} \\left\\| \\tilde{C}^{-1/2} (M^{\\ell} - M) \\tilde{C}^{-1/2} \\right\\|_2 = \\frac{1}{\\Delta t} \\, \\lambda_{\\max}\\!\\left( \\tilde{C}^{-1/2} (M^{\\ell} - M) \\tilde{C}^{-1/2} \\right) =: \\varepsilon.\n  $$\n  This bound is computable by solving the generalized eigenproblem\n  $$\n  (M^{\\ell} - M) \\, y = \\mu \\, \\tilde{C} \\, y, \\quad \\varepsilon = \\frac{1}{\\Delta t} \\, \\max(0, \\mu_{\\max}),\n  $$\n  where taking $\\max(0,\\cdot)$ accounts for the fact that $M^{\\ell} - M$ may have a small negative numerical eigenvalue due to finite precision even if theoretically positive semidefinite. The meaning of $\\varepsilon$ is direct: the spectrum of $\\tilde{S}^{-1} S$ lies within $[1 - \\varepsilon, 1 + \\varepsilon]$.\n- Criterion for degradation: choose a preassigned robustness margin, for example the symmetric interval half-width $1/2$, and declare that mass lumping degrades spectral equivalence whenever\n  $$\n  \\varepsilon \\ge \\frac{1}{2}.\n  $$\n  This ensures that the lower spectral bound $1 - \\varepsilon$ falls below $1/2$, signaling a significant deterioration with potential iteration slow-down. The criterion is fundamental in that it arises from the norm bound on $E$ and does not rely on unproven heuristics.\n\nImpact of large $\\Delta t$:\n- The relative weight of the mass term in $C$ compared to the diffusion term scales like\n  $$\n  \\rho = \\frac{\\|(1/\\Delta t) M\\|}{\\|\\kappa L\\|} \\sim \\frac{(1/\\Delta t) \\, h}{\\kappa / h} = \\frac{h^2}{\\kappa \\, \\Delta t}.\n  $$\n  For large $\\Delta t$ (fixed $h$ and $\\kappa$), $\\rho$ is small; therefore, the lumping perturbation $\\frac{1}{\\Delta t}(M^{\\ell} - M)$ is weak in the $\\tilde{C}$-scaled norm, and $\\varepsilon$ becomes small. Conversely, for small $\\Delta t$ or very small $\\kappa$, the mass term dominates and lumping can significantly affect spectral equivalence.\n\nAlgorithmic realization:\n- Assemble $A$, $B$, $M$, $L$, and $M^{\\ell}$ as described above on a uniform mesh with $N = 64$.\n- For each test case $(\\kappa, \\Delta t)$, form\n  $$\n  H = B A^{-1} B^{\\top}, \\quad C = \\tfrac{1}{\\Delta t} M + \\kappa L, \\quad \\tilde{C} = \\tfrac{1}{\\Delta t} M^{\\ell} + \\kappa L,\n  $$\n  then $S = H + C$ and $\\tilde{S} = H + \\tilde{C}$.\n- Compute the generalized eigenvalues of $S x = \\lambda \\, \\tilde{S} x$, extract $\\lambda_{\\min}$, $\\lambda_{\\max}$, and the condition number $\\kappa_{\\text{cond}} = \\lambda_{\\max} / \\lambda_{\\min}$.\n- Compute $\\varepsilon$ from the generalized eigenvalue problem $(M^{\\ell} - M) y = \\mu \\, \\tilde{C} y$ via $\\varepsilon = \\frac{1}{\\Delta t} \\max(0, \\mu_{\\max})$.\n- Declare degradation if $\\varepsilon \\ge 1/2$.\n- The program prints the results for the four specified cases as a single line containing a list of sublists:\n  $$\n  \\big[ [\\lambda_{\\min}, \\lambda_{\\max}, \\kappa_{\\text{cond}}, \\varepsilon, \\text{degrade}], \\ldots \\big].\n  $$\n\nThis procedure adheres to the foundational definitions of the finite element method, the Schur complement, and spectral norm bounds for symmetric positive definite operators, and delivers a reproducible, quantitative assessment of the impact of mass lumping on Schur preconditioner optimality across regimes including large $\\Delta t$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import eigh\n\ndef assemble_1d_p1_matrices(N: int):\n    \"\"\"\n    Assemble 1D P1 finite element matrices on [0,1] with N uniform elements.\n    Displacement: P1 with homogeneous Dirichlet at both ends -> interior nodes only (size N-1).\n    Pressure: P1 on all N+1 nodes (homogeneous Neumann in L).\n    Returns:\n        A_u: (N-1)x(N-1) SPD elasticity stiffness for displacement\n        B: (N+1)x(N-1) coupling matrix\n        M_p: (N+1)x(N+1) consistent pressure mass matrix\n        L_p: (N+1)x(N+1) pressure diffusion matrix\n        M_lumped: (N+1)x(N+1) lumped (row-sum) pressure mass matrix\n    \"\"\"\n    h = 1.0 / N\n    n_u = N - 1\n    n_p = N + 1\n\n    # Initialize matrices\n    A_u = np.zeros((n_u, n_u), dtype=float)\n    B = np.zeros((n_p, n_u), dtype=float)\n    M_p = np.zeros((n_p, n_p), dtype=float)\n    L_p = np.zeros((n_p, n_p), dtype=float)\n\n    # Local element matrices\n    # For displacement and pressure stiffness: (1/h) * [[1, -1], [-1, 1]]\n    K_loc = (1.0 / h) * np.array([[1.0, -1.0],\n                                  [-1.0, 1.0]], dtype=float)\n    # For pressure mass: (h/6) * [[2, 1], [1, 2]]\n    M_loc = (h / 6.0) * np.array([[2.0, 1.0],\n                                  [1.0, 2.0]], dtype=float)\n    # For coupling B_e: [[-1/2, 1/2], [-1/2, 1/2]]\n    B_loc = np.array([[-0.5, 0.5],\n                      [-0.5, 0.5]], dtype=float)\n\n    # Assemble over elements e = 0..N-1, global nodes (e, e+1)\n    for e in range(N):\n        p_nodes = [e, e + 1]  # pressure nodes\n        u_nodes_full = [e, e + 1]  # displacement nodes including boundaries\n\n        # Assemble pressure M and L\n        for a_local, a_glob in enumerate(p_nodes):\n            for b_local, b_glob in enumerate(p_nodes):\n                M_p[a_glob, b_glob] += M_loc[a_local, b_local]\n                L_p[a_glob, b_glob] += K_loc[a_local, b_local]\n\n        # Assemble displacement A_u on interior nodes only (1..N-1)\n        # Convert global displacement nodes (0..N) to interior indices (0..N-2) if interior\n        u_idx = []\n        for ug in u_nodes_full:\n            if 1 <= ug <= N - 1:\n                u_idx.append(ug - 1)\n            else:\n                u_idx.append(None)\n        # Local contributions to A_u\n        for a_local, a_u in enumerate(u_idx):\n            if a_u is None:\n                continue\n            for b_local, b_u in enumerate(u_idx):\n                if b_u is None:\n                    continue\n                A_u[a_u, b_u] += K_loc[a_local, b_local]\n\n        # Assemble coupling B (pressure rows vs interior displacement columns)\n        for a_local, a_glob in enumerate(p_nodes):\n            for b_local, ug in enumerate(u_nodes_full):\n                if 1 <= ug <= N - 1:\n                    col = ug - 1\n                    B[a_glob, col] += B_loc[a_local, b_local]\n                # If displacement node is boundary, no column exists (Dirichlet elimination)\n\n    # Lumped mass: diagonal with row sums of M_p\n    M_row_sums = np.sum(M_p, axis=1)\n    M_lumped = np.diag(M_row_sums)\n\n    return A_u, B, M_p, L_p, M_lumped\n\ndef schur_blocks(N: int, kappa: float, dt: float):\n    \"\"\"\n    Build Schur operators S and S_tilde for given N, kappa, dt.\n    Returns:\n        S, S_tilde, C, C_tilde, M_p, M_lumped\n    \"\"\"\n    A_u, B, M_p, L_p, M_lumped = assemble_1d_p1_matrices(N)\n    # Compute H = B A^{-1} B^T\n    # Solve A X = B^T for X, then H = B X\n    # Use dense solve as sizes are modest\n    X = np.linalg.solve(A_u, B.T)\n    H = B @ X  # (n_p x n_u) @ (n_u x n_p) -> (n_p x n_p)\n\n    C = (1.0 / dt) * M_p + kappa * L_p\n    C_tilde = (1.0 / dt) * M_lumped + kappa * L_p\n\n    S = H + C\n    S_tilde = H + C_tilde\n\n    return S, S_tilde, C, C_tilde, M_p, M_lumped\n\ndef compute_generalized_spectrum(A: np.ndarray, B: np.ndarray):\n    \"\"\"\n    Solve the symmetric definite generalized eigenvalue problem A x = lambda B x.\n    Returns sorted eigenvalues (ascending).\n    \"\"\"\n    # eigh solves A x = lambda B x for symmetric A and SPD B\n    # Ensure symmetry by symmetrizing small numerical asymmetries\n    A_sym = 0.5 * (A + A.T)\n    B_sym = 0.5 * (B + B.T)\n    w = eigh(A_sym, B_sym, eigvals_only=True)\n    # eigh returns ascending order\n    return w\n\ndef evaluate_case(N: int, kappa: float, dt: float):\n    \"\"\"\n    For given parameters, compute:\n        - min and max generalized eigenvalues of S x = lambda S_tilde x\n        - condition number\n        - epsilon bound = (1/dt) * max_eigenvalue of (M_lumped - M) vs C_tilde\n        - degrade flag: 1 if epsilon >= 0.5 else 0\n    \"\"\"\n    S, S_tilde, C, C_tilde, M, M_lumped = schur_blocks(N, kappa, dt)\n\n    # Generalized eigenvalues of S x = lambda S_tilde x\n    lambdas = compute_generalized_spectrum(S, S_tilde)\n    # Filter any tiny negative numerical eigenvalues (should not occur but guard)\n    lambdas = np.real(lambdas)\n    # Avoid zeros for condition number by clipping to tiny positive\n    lam_min = float(np.min(lambdas))\n    lam_max = float(np.max(lambdas))\n    # Numerical safety: if lam_min <= 0 due to roundoff, adjust minimally\n    if lam_min <= 0:\n        lam_min = float(np.nextafter(0, 1))\n    cond = float(lam_max / lam_min)\n\n    # Epsilon bound from generalized eigenproblem (M_lumped - M) y = mu C_tilde y\n    DeltaM = M_lumped - M\n    # Symmetrize for safety\n    DeltaM = 0.5 * (DeltaM + DeltaM.T)\n    mu_vals = compute_generalized_spectrum(DeltaM, C_tilde)\n    mu_max = float(np.max(mu_vals))\n    # In theory DeltaM >= 0, but numerical issues can yield slight negatives\n    if mu_max < 0:\n        mu_max = 0.0\n    epsilon = float((1.0 / dt) * mu_max)\n\n    degrade = 1 if epsilon >= 0.5 else 0\n\n    return [lam_min, lam_max, cond, epsilon, degrade]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # N = 64, E = 1 implicitly.\n    N = 64\n    test_cases = [\n        # (kappa, dt)\n        (1.0, 1e-4),   # Case A: small dt\n        (1.0, 1e-2),   # Case B: moderate dt\n        (1.0, 1.0),    # Case C: large dt\n        (1e-6, 1e-2),  # Case D: edge case, very low permeability\n    ]\n\n    results = []\n    for kappa, dt in test_cases:\n        res = evaluate_case(N, kappa, dt)\n        results.append(res)\n\n    # Final print statement in the exact required format.\n    # Print as a single line: a list of sublists\n    def fmt_sublist(lst):\n        # Ensure integer for degrade at the end\n        return \"[\" + \",\".join([f\"{x:.12g}\" if i < len(lst) - 1 else f\"{int(x)}\" for i, x in enumerate(lst)]) + \"]\"\n\n    print(\"[\" + \",\".join(fmt_sublist(r) for r in results) + \"]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}