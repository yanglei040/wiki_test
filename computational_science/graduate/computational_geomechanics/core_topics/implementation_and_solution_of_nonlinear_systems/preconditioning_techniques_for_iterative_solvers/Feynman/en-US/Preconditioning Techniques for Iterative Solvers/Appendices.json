{
    "hands_on_practices": [
        {
            "introduction": "Before we can appreciate the solution, we must first understand the problem. This foundational exercise explores why the linear systems arising from finite element analysis are often challenging to solve. By analytically deriving the eigenvalues of the stiffness matrix for a simple one-dimensional elastic bar, you will discover a direct and precise relationship between mesh refinement (increasing $n$) and the degradation of the matrix condition number, $\\kappa(A)$. This analysis provides the fundamental motivation for preconditioning: to counteract the inherent ill-conditioning that arises as we seek more accurate solutions on finer grids .",
            "id": "3590176",
            "problem": "Consider a one-dimensional ($1$D) prismatic linear elastic bar of length $L$, Young’s modulus $E$, and constant cross-sectional area $A$. The axial displacement field $u(x)$ satisfies the strong form of equilibrium $-\\frac{d}{dx}\\!\\left(EA\\,\\frac{du}{dx}\\right)=f(x)$ together with homogeneous Dirichlet boundary conditions $u(0)=0$ and $u(L)=0$. Discretize the bar using the Galerkin finite element method with $n$ uniform linear elements (each of length $h=L/n$) and standard nodal “hat” shape functions. Assemble the global stiffness matrix $A$ associated with the interior nodal degrees of freedom (there are $n-1$ interior nodes due to the homogeneous Dirichlet boundary conditions). \n\nStarting from the finite element weak form and the definition of the element stiffness for linear shape functions, derive the exact eigenvalues of the assembled stiffness matrix $A$ for this uniform mesh and boundary condition setting. Then, using the definition of the spectral condition number in the Euclidean ($2$-)norm for a symmetric positive definite matrix, $\\kappa_{2}(A)=\\lambda_{\\max}(A)/\\lambda_{\\min}(A)$, provide a closed-form analytic expression for $\\kappa_{2}(A)$ as a function of $n$. \n\nYour final answer must be a single closed-form expression in terms of $n$ only. No rounding is required. Explain how this eigenstructure connects to the performance of iterative solvers such as the Conjugate Gradient (CG) method and motivates preconditioning design, but ensure that the final reported quantity is solely the analytic expression for the condition number as a function of $n$.",
            "solution": "The axial equilibrium of the one-dimensional ($1$D) bar is governed by the strong form $-\\frac{d}{dx}\\!\\left(EA\\,\\frac{du}{dx}\\right)=f(x)$ with homogeneous Dirichlet boundary conditions $u(0)=0$ and $u(L)=0$. For the stiffness analysis and eigenstructure derivation, it is sufficient to consider the homogeneous case $f(x)=0$, since the stiffness matrix $A$ is defined by the bilinear form of the left-hand side operator.\n\nThe Galerkin finite element method with $n$ uniform linear elements partitions the domain into nodes at $x_{j}=j\\,h$ for $j=0,1,\\dots,n$ with $h=L/n$. The interior nodal unknowns are $u_{j}$ for $j=1,\\dots,n-1$, since the boundary values $u_{0}=0$ and $u_{n}=0$ are prescribed by the homogeneous Dirichlet boundary conditions. For a single linear element spanning $\\left[x_{e},x_{e+1}\\right]$, the element stiffness matrix computed from the weak form and linear shape functions is\n$$\nk^{(e)}=\\frac{EA}{h}\\begin{pmatrix}1 & -1 \\\\ -1 & 1\\end{pmatrix}.\n$$\nAssembly over the $n$ elements produces a global stiffness matrix $A$ of size $(n-1)\\times(n-1)$ for the interior degrees of freedom. The resulting matrix has the form\n$$\nA=\\frac{EA}{h}\\,T,\n$$\nwhere $T$ is the tridiagonal Toeplitz matrix\n$$\nT=\\begin{pmatrix}\n2 & -1 & 0 & \\cdots & 0 \\\\\n-1 & 2 & -1 & \\ddots & \\vdots \\\\\n0 & -1 & 2 & \\ddots & 0 \\\\\n\\vdots & \\ddots & \\ddots & \\ddots & -1 \\\\\n0 & \\cdots & 0 & -1 & 2\n\\end{pmatrix}.\n$$\nThis $T$ is the standard discrete Dirichlet Laplacian on a uniform one-dimensional grid with $(n-1)$ interior points.\n\nTo compute the exact eigenvalues of $T$, consider the candidate eigenvectors $v^{(k)}\\in\\mathbb{R}^{n-1}$ for $k=1,2,\\dots,n-1$ with components\n$$\nv^{(k)}_{j}=\\sin\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right),\\quad j=1,2,\\dots,n-1.\n$$\nWe show that $T\\,v^{(k)}=\\lambda_{k}\\,v^{(k)}$ for appropriate $\\lambda_{k}$. Evaluating the action of $T$ on $v^{(k)}$ at index $j$ gives\n$$\n(T\\,v^{(k)})_{j}=-v^{(k)}_{j-1}+2\\,v^{(k)}_{j}-v^{(k)}_{j+1},\n$$\nwith the convention that $v^{(k)}_{0}=0$ and $v^{(k)}_{n}=0$ consistent with the Dirichlet boundary conditions. Using the sine addition formulas,\n$$\nv^{(k)}_{j\\pm 1}=\\sin\\!\\left(\\frac{(j\\pm 1)\\,k\\,\\pi}{n}\\right)=\\sin\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right)\\cos\\!\\left(\\frac{k\\,\\pi}{n}\\right)\\pm\\cos\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right)\\sin\\!\\left(\\frac{k\\,\\pi}{n}\\right),\n$$\nwe obtain\n\\begin{align*}\n(T\\,v^{(k)})_{j}\n&=-\\left[\\sin\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right)\\cos\\!\\left(\\frac{k\\,\\pi}{n}\\right)-\\cos\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right)\\sin\\!\\left(\\frac{k\\,\\pi}{n}\\right)\\right]\\\\\n&\\quad+2\\,\\sin\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right)\\\\\n&\\quad-\\left[\\sin\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right)\\cos\\!\\left(\\frac{k\\,\\pi}{n}\\right)+\\cos\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right)\\sin\\!\\left(\\frac{k\\,\\pi}{n}\\right)\\right]\\\\\n&=2\\,\\sin\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right)-2\\,\\sin\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right)\\cos\\!\\left(\\frac{k\\,\\pi}{n}\\right)\\\\\n&=\\left[2-2\\cos\\!\\left(\\frac{k\\,\\pi}{n}\\right)\\right]\\sin\\!\\left(\\frac{j\\,k\\,\\pi}{n}\\right).\n\\end{align*}\nTherefore $v^{(k)}$ is indeed an eigenvector and the corresponding eigenvalue of $T$ is\n$$\n\\lambda_{k}(T)=2-2\\cos\\!\\left(\\frac{k\\,\\pi}{n}\\right)=4\\,\\sin^{2}\\!\\left(\\frac{k\\,\\pi}{2\\,n}\\right),\\quad k=1,2,\\dots,n-1.\n$$\nSince $A=\\frac{EA}{h}\\,T$, the eigenvalues of $A$ are scaled by the factor $\\frac{EA}{h}$:\n$$\n\\lambda_{k}(A)=\\frac{EA}{h}\\,\\lambda_{k}(T)=\\frac{EA}{h}\\,4\\,\\sin^{2}\\!\\left(\\frac{k\\,\\pi}{2\\,n}\\right),\\quad k=1,2,\\dots,n-1.\n$$\nThe spectral condition number in the Euclidean ($2$-)norm for a symmetric positive definite matrix is\n$$\n\\kappa_{2}(A)=\\frac{\\lambda_{\\max}(A)}{\\lambda_{\\min}(A)}.\n$$\nThe minimum eigenvalue occurs at $k=1$ and the maximum at $k=n-1$. Using the trigonometric identity $\\sin\\!\\left(\\frac{(n-1)\\,\\pi}{2\\,n}\\right)=\\sin\\!\\left(\\frac{\\pi}{2}-\\frac{\\pi}{2\\,n}\\right)=\\cos\\!\\left(\\frac{\\pi}{2\\,n}\\right)$, we obtain\n\\begin{align*}\n\\lambda_{\\min}(A)&=\\frac{EA}{h}\\,4\\,\\sin^{2}\\!\\left(\\frac{\\pi}{2\\,n}\\right),\\\\\n\\lambda_{\\max}(A)&=\\frac{EA}{h}\\,4\\,\\sin^{2}\\!\\left(\\frac{(n-1)\\,\\pi}{2\\,n}\\right)=\\frac{EA}{h}\\,4\\,\\cos^{2}\\!\\left(\\frac{\\pi}{2\\,n}\\right).\n\\end{align*}\nHence\n\\begin{align*}\n\\kappa_{2}(A)\n&=\\frac{\\frac{EA}{h}\\,4\\,\\cos^{2}\\!\\left(\\frac{\\pi}{2\\,n}\\right)}{\\frac{EA}{h}\\,4\\,\\sin^{2}\\!\\left(\\frac{\\pi}{2\\,n}\\right)}\n=\\frac{\\cos^{2}\\!\\left(\\frac{\\pi}{2\\,n}\\right)}{\\sin^{2}\\!\\left(\\frac{\\pi}{2\\,n}\\right)}\n=\\cot^{2}\\!\\left(\\frac{\\pi}{2\\,n}\\right).\n\\end{align*}\nThis is an exact closed-form expression in terms of $n$. For large $n$, the small-angle approximation $\\sin\\!\\left(\\frac{\\pi}{2\\,n}\\right)\\approx\\frac{\\pi}{2\\,n}$ and $\\cos\\!\\left(\\frac{\\pi}{2\\,n}\\right)\\approx 1$ yields the asymptotic estimate\n$$\n\\kappa_{2}(A)\\sim\\left(\\frac{2\\,n}{\\pi}\\right)^{2},\n$$\nwhich shows that the condition number grows quadratically with $n$. This growth explains the deterioration of convergence rates for iterative solvers such as the Conjugate Gradient (CG) method on refined meshes and motivates the use of preconditioning techniques (e.g., Jacobi scaling, incomplete Cholesky factorization, or multigrid methods) that aim to cluster the eigenvalues and reduce $\\kappa_{2}$ toward mesh-independent values.",
            "answer": "$$\\boxed{\\cot^{2}\\!\\left(\\frac{\\pi}{2\\,n}\\right)}$$"
        },
        {
            "introduction": "Having established that ill-conditioning is a natural consequence of mesh refinement, we now turn to a classic remedy. This practice provides a hands-on look at the mechanics of constructing an incomplete Cholesky factorization with zero fill-in (IC(0)), a widely used preconditioning technique. By applying the method to a small, illustrative matrix representing a discrete elastic system, you will not only practice the algorithm but also uncover a crucial insight: for tridiagonal systems, IC(0) is an exact factorization, resulting in a perfect preconditioner with a condition number of one. This exercise beautifully demonstrates the ideal goal of preconditioning—transforming a difficult problem into one that is trivial to solve iteratively .",
            "id": "3590218",
            "problem": "Consider the discrete one-dimensional linear elasticity stiffness operator on a uniform mesh with Dirichlet boundary conditions, leading to the symmetric positive definite (SPD) Toeplitz matrix $A \\in \\mathbb{R}^{5 \\times 5}$ given by $A=\\operatorname{tridiag}(-1,2,-1)$. Using the definition of incomplete Cholesky factorization with zero fill (IC(0)) under natural ordering and without any diagonal modification, construct the lower-triangular factor $L$ with the same sparsity pattern as the lower triangle of $A$ and the preconditioner $M = LL^{T}$. Starting from the Cholesky factorization definition for SPD matrices and the sparsity-induced recursion for the bidiagonal $L$, derive the entries of $L$ explicitly. Then, determine the eigenvalues of the preconditioned operator $M^{-1}A$ exactly, and conclude the exact spectral condition number $\\kappa_{2}(M^{-1}A)$.\n\nProvide the exact value of the spectral condition number $\\kappa_{2}(M^{-1}A)$ as your final answer. No rounding is required. Express the final answer as a pure number without units.",
            "solution": "The matrix $A \\in \\mathbb{R}^{5 \\times 5}$ is a symmetric positive definite (SPD) tridiagonal matrix:\n$$\nA = \\begin{pmatrix}\n2 & -1 & 0 & 0 & 0 \\\\\n-1 & 2 & -1 & 0 & 0 \\\\\n0 & -1 & 2 & -1 & 0 \\\\\n0 & 0 & -1 & 2 & -1 \\\\\n0 & 0 & 0 & -1 & 2\n\\end{pmatrix}.\n$$\nThe Incomplete Cholesky factorization with zero fill-in, IC(0), requires the factor $L$ to have the same sparsity pattern as the lower triangle of $A$. Since $A$ is tridiagonal, its lower triangle is bidiagonal. Thus, $L$ must be a lower bidiagonal matrix of the form:\n$$\nL = \\begin{pmatrix}\nl_{11} & 0 & 0 & 0 & 0 \\\\\nl_{21} & l_{22} & 0 & 0 & 0 \\\\\n0 & l_{32} & l_{33} & 0 & 0 \\\\\n0 & 0 & l_{43} & l_{44} & 0 \\\\\n0 & 0 & 0 & l_{54} & l_{55}\n\\end{pmatrix}.\n$$\nThe product $M = LL^T$ for such a bidiagonal $L$ is also a tridiagonal matrix. This means that no \"fill-in\" entries are generated that would need to be discarded. Therefore, for a tridiagonal matrix $A$, the IC(0) factorization is identical to the exact Cholesky factorization, and the resulting preconditioner $M=LL^T$ will be exactly equal to $A$.\n\nWe can verify this by computing the entries of $L$ such that $LL^T = A$.\nEquating the entries of $LL^T$ and $A$:\n*   $l_{11}^2 = A_{11} = 2 \\implies l_{11} = \\sqrt{2}$.\n*   $l_{21}l_{11} = A_{21} = -1 \\implies l_{21} = -1/\\sqrt{2}$.\n*   $l_{21}^2 + l_{22}^2 = A_{22} = 2 \\implies (-1/\\sqrt{2})^2 + l_{22}^2 = 2 \\implies l_{22} = \\sqrt{3/2}$.\n*   $l_{32}l_{22} = A_{32} = -1 \\implies l_{32} = -1/\\sqrt{3/2} = -\\sqrt{2/3}$.\n*   $l_{32}^2 + l_{33}^2 = A_{33} = 2 \\implies (-\\sqrt{2/3})^2 + l_{33}^2 = 2 \\implies l_{33} = \\sqrt{4/3}$.\nThe general recursive relations for $i=2, \\dots, 5$ are $l_{i,i-1} = -1/l_{i-1,i-1}$ and $l_{ii} = \\sqrt{2-l_{i,i-1}^2}$.\n\nSince the IC(0) factor $L$ is computed such that it exactly reproduces $A$ when forming $M=LL^T$, we have $M=A$.\n\nThe preconditioned operator is therefore:\n$$\nM^{-1}A = A^{-1}A = I,\n$$\nwhere $I$ is the $5 \\times 5$ identity matrix.\n\nThe eigenvalues of the identity matrix are all equal to $1$. Thus, $\\lambda_{\\max}(M^{-1}A) = 1$ and $\\lambda_{\\min}(M^{-1}A) = 1$. The spectral condition number is defined as the ratio of the largest to the smallest eigenvalue magnitude for a symmetric (or symmetrizable) positive definite operator:\n$$\n\\kappa_2(M^{-1}A) = \\frac{\\lambda_{\\max}(M^{-1}A)}{\\lambda_{\\min}(M^{-1}A)} = \\frac{1}{1} = 1.\n$$\nThis demonstrates that for a tridiagonal system, IC(0) is a \"perfect\" preconditioner, transforming the system into one that is trivially solved in a single iteration.",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "Real-world geomechanics problems often involve complexities that can defeat simple preconditioning strategies. This advanced practice explores one such challenge: strong material anisotropy, a common feature in layered rock and soil formations. You will use Local Fourier Analysis (LFA), a powerful tool for analyzing iterative methods, to diagnose precisely why a standard point-Jacobi smoother fails to damp high-frequency errors in anisotropic settings. Subsequently, you will construct a more robust line smoother that respects the underlying physics, restoring effective convergence and illustrating a core principle of modern multigrid methods: the most effective preconditioners are those adapted to the physical character of the problem .",
            "id": "3552374",
            "problem": "Consider steady anisotropic diffusion in a layered geomaterial with principal permeabilities aligned to the Cartesian axes, modeled by the operator $-\\nabla \\cdot ( \\mathbf{K} \\nabla u )$ with $\\mathbf{K} = \\operatorname{diag}(K_x, K_y)$, on a rectangular domain discretized by a uniform grid with spacing $h$ in both directions. Assume periodic boundary conditions to enable Local Fourier Analysis (LFA). Let $K_x = 1$ and $K_y = \\epsilon$ with $0 < \\epsilon \\ll 1$, representing an anisotropy ratio $\\kappa = K_x/K_y = 1/\\epsilon$. Using the standard five-point finite-difference discretization, the discrete operator acting on grid function $u_{i,j}$ has the form\n$$\n(Au)_{i,j} = \\frac{1}{h^2}\\Big( 2(1+\\epsilon) u_{i,j} - u_{i-1,j} - u_{i+1,j} - \\epsilon u_{i,j-1} - \\epsilon u_{i,j+1} \\Big).\n$$\nYou will analyze smoothing for high-frequency error components and design an effective line smoother.\n\nTasks:\n1) Starting from the definition of the point-Jacobi iteration $u^{(k+1)} = u^{(k)} + D^{-1}(f - Au^{(k)})$, where $D = \\operatorname{diag}(A)$, derive the error-propagation symbol $\\tilde{S}_J(\\theta_x,\\theta_y)$ by applying $I - D^{-1}A$ to a Fourier mode $e_{i,j} = \\exp(i(\\theta_x i + \\theta_y j))$. Then evaluate the amplification factor for the high-frequency mode with wavenumbers $(\\theta_x,\\theta_y) = (0,\\pi)$. Based on your derived expression, explain its behavior as $\\epsilon \\to 0$, and state whether point-Jacobi adequately smooths this mode.\n\n2) Construct an $x$-line symmetric Gauss–Seidel (GS) smoother as follows: for each row $j$, solve exactly the tridiagonal system in the $x$-direction defined by the $x$-couplings, and sweep forward in $y$ (using newly updated row $j-1$) and then backward in $y$ (using newly updated row $j+1$). Starting from the block form of the discrete equations, derive the LFA error-amplification factor for a generic Fourier mode $e_{i,j} = \\exp(i(\\theta_x i + \\theta_y j))$ after one complete symmetric line-GS sweep. Then evaluate the amplification factor magnitude for the same high-frequency mode $(\\theta_x,\\theta_y) = (0,\\pi)$ with anisotropy ratio $\\kappa = 10^3$ (that is, $\\epsilon = 10^{-3}$). \n\nGive your final answer as the exact value of this amplification factor magnitude; no rounding is required and no units are to be included.",
            "solution": "The problem is well-posed and scientifically grounded, allowing for a complete analysis. We address the two tasks in sequence.\n\nPart 1: Analysis of the Point-Jacobi Smoother\n\nThe point-Jacobi iteration for the linear system $Au = f$ is given by $u^{(k+1)} = u^{(k)} + D^{-1}(f - Au^{(k)})$, where $D$ is the diagonal part of the matrix $A$. The error $e^{(k)} = u - u^{(k)}$ propagates according to the equation $e^{(k+1)} = (I - D^{-1}A) e^{(k)}$. The matrix $S_J = I - D^{-1}A$ is the error propagation matrix for the point-Jacobi method. To perform Local Fourier Analysis (LFA), we analyze the effect of this operator on a single Fourier mode, $e_{i,j} = \\exp(i(\\theta_x i + \\theta_y j))$, where $\\theta_x, \\theta_y \\in [-\\pi, \\pi]$ are the wavenumbers.\n\nThe discrete operator $A$ is given by\n$$\n(Au)_{i,j} = \\frac{1}{h^2}\\Big( 2(1+\\epsilon) u_{i,j} - u_{i-1,j} - u_{i+1,j} - \\epsilon u_{i,j-1} - \\epsilon u_{i,j+1} \\Big).\n$$\nApplying $A$ to the Fourier mode $e_{i,j}$ yields:\n$$\n(Ae)_{i,j} = \\frac{1}{h^2} \\Big( 2(1+\\epsilon) - \\exp(-i\\theta_x) - \\exp(i\\theta_x) - \\epsilon\\exp(-i\\theta_y) - \\epsilon\\exp(i\\theta_y) \\Big) e_{i,j}\n$$\nUsing Euler's formula, $\\exp(i\\phi) + \\exp(-i\\phi) = 2\\cos(\\phi)$, we find the symbol (eigenvalue) $\\tilde{A}(\\theta_x, \\theta_y)$ of the operator $A$:\n$$\n\\tilde{A}(\\theta_x, \\theta_y) = \\frac{1}{h^2} \\Big( 2(1+\\epsilon) - 2\\cos(\\theta_x) - 2\\epsilon\\cos(\\theta_y) \\Big) = \\frac{2}{h^2} \\Big( (1-\\cos(\\theta_x)) + \\epsilon(1-\\cos(\\theta_y)) \\Big).\n$$\nThe diagonal part of $A$, denoted by $D$, is the term that multiplies $u_{i,j}$: $(Du)_{i,j} = \\frac{2(1+\\epsilon)}{h^2} u_{i,j}$. The symbol of $D$ is thus a constant:\n$$\n\\tilde{D} = \\frac{2(1+\\epsilon)}{h^2}.\n$$\nThe error-propagation symbol for point-Jacobi, $\\tilde{S}_J(\\theta_x, \\theta_y)$, is the symbol of $I - D^{-1}A$:\n$$\n\\tilde{S}_J(\\theta_x, \\theta_y) = 1 - \\frac{\\tilde{A}(\\theta_x, \\theta_y)}{\\tilde{D}} = 1 - \\frac{\\frac{2}{h^2} \\Big( (1+\\epsilon) - \\cos(\\theta_x) - \\epsilon\\cos(\\theta_y) \\Big)}{\\frac{2(1+\\epsilon)}{h^2}}.\n$$\nSimplifying the expression, we obtain:\n$$\n\\tilde{S}_J(\\theta_x, \\theta_y) = \\frac{(1+\\epsilon) - \\Big( (1+\\epsilon) - \\cos(\\theta_x) - \\epsilon\\cos(\\theta_y) \\Big)}{1+\\epsilon} = \\frac{\\cos(\\theta_x) + \\epsilon\\cos(\\theta_y)}{1+\\epsilon}.\n$$\nNow, we evaluate this amplification factor for the high-frequency mode with wavenumbers $(\\theta_x, \\theta_y) = (0, \\pi)$. This mode is smooth in the $x$-direction and highly oscillatory in the $y$-direction.\n$$\n\\tilde{S}_J(0, \\pi) = \\frac{\\cos(0) + \\epsilon\\cos(\\pi)}{1+\\epsilon} = \\frac{1 - \\epsilon}{1+\\epsilon}.\n$$\nTo understand the effectiveness of the smoother in the limit of strong anisotropy ($\\epsilon \\to 0$), we examine the behavior of this amplification factor:\n$$\n\\lim_{\\epsilon \\to 0} \\tilde{S}_J(0, \\pi) = \\lim_{\\epsilon \\to 0} \\frac{1 - \\epsilon}{1+\\epsilon} = 1.\n$$\nAn amplification factor of $1$ indicates that the error component corresponding to this mode is not damped at all. Therefore, point-Jacobi is not an adequate smoother for this problem, as its performance degrades catastrophically for modes that are oscillatory in the direction of weak coupling.\n\nPart 2: Analysis of the $x$-line Symmetric Gauss-Seidel Smoother\n\nFor an $x$-line smoother, we group the unknowns by rows (lines). The discrete equations can be written in a block tridiagonal form, $A u = f$. The matrix $A$ can be decomposed as $A = L+D+U$, where $D$ is the block-diagonal matrix whose blocks represent the intra-line couplings, and $L$ and $U$ are the strict block lower and upper triangular matrices representing inter-line couplings.\n$$ A = \\frac{1}{h^2} \\begin{pmatrix} T_x & -\\epsilon I & & \\\\ -\\epsilon I & T_x & -\\epsilon I & \\\\ & \\ddots & \\ddots & \\ddots \\\\ & & -\\epsilon I & T_x \\end{pmatrix} $$\nHere, $T_x$ is the tridiagonal matrix for a single line, with entries $(-1, 2(1+\\epsilon), -1)$. The symbol of the operator $h^2 D$ is the symbol of $T_x$, which we denote $\\tilde{T}_x(\\theta_x)$:\n$$\n\\tilde{T}_x(\\theta_x) = 2(1+\\epsilon) - 2\\cos(\\theta_x) = 4\\sin^2(\\frac{\\theta_x}{2}) + 2\\epsilon.\n$$\nThe symbols for the LFA of the block operators $h^2L$ and $h^2U$ are denoted $\\tilde{L}'(\\theta_y)$ and $\\tilde{U}'(\\theta_y)$:\n$$\n\\tilde{L}'(\\theta_y) = -\\epsilon\\exp(-i\\theta_y), \\quad \\tilde{U}'(\\theta_y) = -\\epsilon\\exp(i\\theta_y).\n$$\nThe symmetric Gauss-Seidel (SGS) smoother consists of a forward sweep followed by a backward sweep. The error propagation operator is $S_{SGS} = (D+U)^{-1}L(D+L)^{-1}U$. The corresponding LFA symbol is:\n$$\n\\tilde{S}_{SGS}(\\theta_x, \\theta_y) = (\\tilde{D}' + \\tilde{U}')^{-1} \\tilde{L}' (\\tilde{D}' + \\tilde{L}')^{-1} \\tilde{U}'.\n$$\nSubstituting the symbols for the block operators (scaled by $h^2$):\n$$\n\\tilde{S}_{SGS}(\\theta_x, \\theta_y) = \\frac{1}{\\tilde{T}_x(\\theta_x) - \\epsilon\\exp(i\\theta_y)} \\cdot \\big(-\\epsilon\\exp(-i\\theta_y)\\big) \\cdot \\frac{1}{\\tilde{T}_x(\\theta_x) - \\epsilon\\exp(-i\\theta_y)} \\cdot \\big(-\\epsilon\\exp(i\\theta_y)\\big).\n$$\n$$\n\\tilde{S}_{SGS}(\\theta_x, \\theta_y) = \\frac{\\epsilon^2}{\\big(\\tilde{T}_x(\\theta_x)-\\epsilon\\exp(i\\theta_y)\\big)\\big(\\tilde{T}_x(\\theta_x)-\\epsilon\\exp(-i\\theta_y)\\big)}.\n$$\nThe denominator is the product of a complex number and its conjugate, which results in its squared magnitude:\n$$\n\\tilde{S}_{SGS}(\\theta_x, \\theta_y) = \\frac{\\epsilon^2}{|\\tilde{T}_x(\\theta_x) - \\epsilon\\exp(i\\theta_y)|^2} = \\frac{\\epsilon^2}{(\\tilde{T}_x(\\theta_x) - \\epsilon\\cos(\\theta_y))^2 + (-\\epsilon\\sin(\\theta_y))^2}.\n$$\n$$\n\\tilde{S}_{SGS}(\\theta_x, \\theta_y) = \\frac{\\epsilon^2}{\\tilde{T}_x(\\theta_x)^2 - 2\\epsilon\\tilde{T}_x(\\theta_x)\\cos(\\theta_y) + \\epsilon^2}.\n$$\nWe are asked to evaluate the magnitude of this factor for the mode $(\\theta_x, \\theta_y) = (0, \\pi)$ with $\\kappa = 10^3$, which means $\\epsilon = 10^{-3}$. First, we evaluate the symbols at the specified wavenumbers.\nFor $\\theta_x = 0$:\n$$\n\\tilde{T}_x(0) = 4\\sin^2(0) + 2\\epsilon = 2\\epsilon.\n$$\nFor $\\theta_y = \\pi$:\n$$\n\\cos(\\pi) = -1.\n$$\nSubstituting these into the expression for $\\tilde{S}_{SGS}$:\n$$\n\\tilde{S}_{SGS}(0, \\pi) = \\frac{\\epsilon^2}{(2\\epsilon)^2 - 2\\epsilon(2\\epsilon)(-1) + \\epsilon^2} = \\frac{\\epsilon^2}{4\\epsilon^2 + 4\\epsilon^2 + \\epsilon^2} = \\frac{\\epsilon^2}{9\\epsilon^2} = \\frac{1}{9}.\n$$\nThis amplification factor is a real, positive constant independent of $\\epsilon$ (and thus $\\kappa$). The magnitude of the amplification factor for the mode $(0, \\pi)$ is therefore $|\\frac{1}{9}| = \\frac{1}{9}$. The specific value of $\\kappa = 10^3$ does not affect this result.",
            "answer": "$$\\boxed{\\frac{1}{9}}$$"
        }
    ]
}