{
    "hands_on_practices": [
        {
            "introduction": "这项实践介绍了多重假设检验这一关键的统计挑战，这是在同时分析数千个基因集（如GO术语或KEGG通路）时普遍存在的问题。通过将Bonferroni和Benjamini-Hochberg程序应用于一个具体的数据集，您将在控制家族性错误率（FWER）和错误发现率（FDR）方面获得实践经验。这个练习是确保任何大规模功能富集分析结果统计严谨性的基础 。",
            "id": "3312231",
            "problem": "一名研究人员使用三种标准化的注释资源对一个差异表达基因列表进行基因集富集分析：基因本体论生物过程（GO BP）、京都基因与基因组百科全书（KEGG）和Reactome通路知识库（Reactome）。对于这些资源中总共 $m=12$ 个候选类别，每个类别都根据标准假设通过单侧超几何富集检验进行测试，得到的原始$p$值（已针对每个检验的组合样本空间进行校正，但未针对跨类别的多重假设进行校正）如下：\n$0.0008$, $0.0015$, $0.0042$, $0.0070$, $0.0110$, $0.0190$, $0.0280$, $0.0370$, $0.0490$, $0.1200$, $0.3300$, $0.6200$。\n\n假设在 $m=12$ 个被检验的类别水平假设中，恰好有 $m_0=9$ 个是真原假设，并且这些原假设的$p$值是独立同分布于 $\\mathrm{Uniform}(0,1)$。\n\n仅使用族系错误率控制和错误发现率控制的第一性原理定义：\n- 计算所有 $m=12$ 个检验的Bonferroni校正$p$值，并确定在族系显著性阈值 $\\alpha_{\\text{FWER}}=0.05$ 下被拒绝的假设数量。\n- 计算所有 $m=12$ 个检验的Benjamini–Hochberg (BH) 校正$p$值，并确定在目标错误发现率 $q=0.10$ 下被拒绝的假设数量。\n\n然后，在指定的独立性和均匀性假设下：\n- 推导在 $\\alpha_{\\text{FWER}}=0.05$ 时，Bonferroni程序的期望错误拒绝数。\n- 推导在 $q=0.10$ 时，Benjamini–Hochberg程序所达到的错误发现比例（错误发现率）的界限。\n\n最后，定义无量纲比较指标\n$$\\rho \\equiv \\frac{E[V_{\\text{Bonf}}]/m}{\\left(\\frac{m_0}{m}\\right) q},$$\n其中 $E[V_{\\text{Bonf}}]$ 是Bonferroni程序下的期望错误拒绝数。精确计算 $\\rho$，并以精确的解析分数形式报告 $\\rho$ 的单一值。不要包含任何单位，也不要四舍五入。",
            "solution": "该问题陈述经评估具有科学依据，表述清晰，客观且自洽。为得出唯一且有意义的解所需的所有数据、定义和假设均已提供。因此，该问题被判定为**有效**。\n\n该问题要求对一组$p$值应用多重假设检验校正（Bonferroni和Benjamini-Hochberg），然后推导并计算相关的统计量。设检验总数为 $m=12$，已按非递减顺序排序的原始$p$值记为 $p_{(i)}$，其中 $i=1, 2, \\dots, 12$。族系显著性阈值为 $\\alpha_{\\text{FWER}}=0.05$，目标错误发现率为 $q=0.10$。给定的真原假设数量为 $m_0=9$。\n\n**1. Bonferroni校正**\n\nBonferroni校正通过调整每个原始$p$值 $p_i$ 来控制族系错误率（FWER）。Bonferroni校正的$p$值 $p_{i, \\text{adj}}^{\\text{Bonf}}$ 定义为：\n$$p_{i, \\text{adj}}^{\\text{Bonf}} = \\min(m \\cdot p_i, 1)$$\n如果一个假设的校正$p$值小于或等于FWER阈值 $\\alpha_{\\text{FWER}}$，则该假设被拒绝。这等同于拒绝任何原始$p$值满足 $p_i \\le \\alpha_{\\text{FWER}} / m$ 的假设。\n\n给定 $m=12$ 和 $\\alpha_{\\text{FWER}}=0.05$，原始$p$值的拒绝阈值为 $0.05/12 \\approx 0.004167$。\n提供的原始$p$值为：\n$p_{(1)} = 0.0008$, $p_{(2)} = 0.0015$, $p_{(3)} = 0.0042$, $p_{(4)} = 0.0070$, $p_{(5)} = 0.0110$, $p_{(6)} = 0.0190$, $p_{(7)} = 0.0280$, $p_{(8)} = 0.0370$, $p_{(9)} = 0.0490$, $p_{(10)} = 0.1200$, $p_{(11)} = 0.3300$, $p_{(12)} = 0.6200$。\n\nBonferroni校正的$p$值计算为 $p_{(i), \\text{adj}}^{\\text{Bonf}} = \\min(12 \\cdot p_{(i)}, 1)$：\n$p_{(1), \\text{adj}}^{\\text{Bonf}} = 12 \\times 0.0008 = 0.0096$\n$p_{(2), \\text{adj}}^{\\text{Bonf}} = 12 \\times 0.0015 = 0.0180$\n$p_{(3), \\text{adj}}^{\\text{Bonf}} = 12 \\times 0.0042 = 0.0504$\n$p_{(4), \\text{adj}}^{\\text{Bonf}} = 12 \\times 0.0070 = 0.0840$\n$p_{(5), \\text{adj}}^{\\text{Bonf}} = 12 \\times 0.0110 = 0.1320$\n$p_{(6), \\text{adj}}^{\\text{Bonf}} = 12 \\times 0.0190 = 0.2280$\n$p_{(7), \\text{adj}}^{\\text{Bonf}} = 12 \\times 0.0280 = 0.3360$\n$p_{(8), \\text{adj}}^{\\text{Bonf}} = 12 \\times 0.0370 = 0.4440$\n$p_{(9), \\text{adj}}^{\\text{Bonf}} = 12 \\times 0.0490 = 0.5880$\n$p_{(10), \\text{adj}}^{\\text{Bonf}} = \\min(12 \\times 0.1200, 1) = \\min(1.44, 1) = 1.0$\n$p_{(11), \\text{adj}}^{\\text{Bonf}} = \\min(12 \\times 0.3300, 1) = \\min(3.96, 1) = 1.0$\n$p_{(12), \\text{adj}}^{\\text{Bonf}} = \\min(12 \\times 0.6200, 1) = \\min(7.44, 1) = 1.0$\n\n为了找到被拒绝的假设数量，我们将每个校正后的$p$值与 $\\alpha_{\\text{FWER}} = 0.05$ 进行比较：\n$p_{(1), \\text{adj}}^{\\text{Bonf}} = 0.0096 \\le 0.05$ (拒绝)\n$p_{(2), \\text{adj}}^{\\text{Bonf}} = 0.0180 \\le 0.05$ (拒绝)\n$p_{(3), \\text{adj}}^{\\text{Bonf}} = 0.0504 > 0.05$ (不拒绝)\n所有后续的校正$p$值也都大于$0.05$。\n因此，Bonferroni程序拒绝了 $2$ 个假设。\n\n**2. Benjamini-Hochberg (BH) 校正**\n\nBenjamini-Hochberg程序控制错误发现率（FDR）。对于第$i$个排序的原始$p$值 $p_{(i)}$，其BH校正$p$值 $p_{(i), \\text{adj}}^{\\text{BH}}$ 是通过一个强制单调性的降步法（step-down）程序计算的。最大原始$p$值的校正值是其本身：$p_{(m), \\text{adj}}^{\\text{BH}}=p_{(m)}$。对于所有其他$p$值，校正是递归进行的：\n$$p_{(i), \\text{adj}}^{\\text{BH}} = \\min\\left(p_{(i+1), \\text{adj}}^{\\text{BH}}, \\frac{m \\cdot p_{(i)}}{i}\\right) \\quad \\text{for } i=m-1, \\dots, 1$$\n这等价于 $p_{(i), \\text{adj}}^{\\text{BH}} = \\min_{j \\ge i}\\left(\\frac{m \\cdot p_{(j)}}{j}\\right)$。\n\n我们来计算BH校正的$p$值：\n$p_{(12), \\text{adj}}^{\\text{BH}} = p_{(12)} = 0.6200$\n$p_{(11), \\text{adj}}^{\\text{BH}} = \\min(p_{(12), \\text{adj}}^{\\text{BH}}, \\frac{12 \\cdot 0.3300}{11}) = \\min(0.6200, 0.3600) = 0.3600$\n$p_{(10), \\text{adj}}^{\\text{BH}} = \\min(p_{(11), \\text{adj}}^{\\text{BH}}, \\frac{12 \\cdot 0.1200}{10}) = \\min(0.3600, 0.1440) = 0.1440$\n$p_{(9), \\text{adj}}^{\\text{BH}} = \\min(p_{(10), \\text{adj}}^{\\text{BH}}, \\frac{12 \\cdot 0.0490}{9}) = \\min(0.1440, 0.0653\\overline{3}) = 0.0653\\overline{3}$\n$p_{(8), \\text{adj}}^{\\text{BH}} = \\min(p_{(9), \\text{adj}}^{\\text{BH}}, \\frac{12 \\cdot 0.0370}{8}) = \\min(0.0653\\overline{3}, 0.0555) = 0.0555$\n$p_{(7), \\text{adj}}^{\\text{BH}} = \\min(p_{(8), \\text{adj}}^{\\text{BH}}, \\frac{12 \\cdot 0.0280}{7}) = \\min(0.0555, 0.0480) = 0.0480$\n$p_{(6), \\text{adj}}^{\\text{BH}} = \\min(p_{(7), \\text{adj}}^{\\text{BH}}, \\frac{12 \\cdot 0.0190}{6}) = \\min(0.0480, 0.0380) = 0.0380$\n$p_{(5), \\text{adj}}^{\\text{BH}} = \\min(p_{(6), \\text{adj}}^{\\text{BH}}, \\frac{12 \\cdot 0.0110}{5}) = \\min(0.0380, 0.0264) = 0.0264$\n$p_{(4), \\text{adj}}^{\\text{BH}} = \\min(p_{(5), \\text{adj}}^{\\text{BH}}, \\frac{12 \\cdot 0.0070}{4}) = \\min(0.0264, 0.0210) = 0.0210$\n$p_{(3), \\text{adj}}^{\\text{BH}} = \\min(p_{(4), \\text{adj}}^{\\text{BH}}, \\frac{12 \\cdot 0.0042}{3}) = \\min(0.0210, 0.0168) = 0.0168$\n$p_{(2), \\text{adj}}^{\\text{BH}} = \\min(p_{(3), \\text{adj}}^{\\text{BH}}, \\frac{12 \\cdot 0.0015}{2}) = \\min(0.0168, 0.0090) = 0.0090$\n$p_{(1), \\text{adj}}^{\\text{BH}} = \\min(p_{(2), \\text{adj}}^{\\text{BH}}, \\frac{12 \\cdot 0.0008}{1}) = \\min(0.0090, 0.0096) = 0.0090$\n\n如果一个假设的BH校正$p$值小于或等于目标FDR $q=0.10$，则该假设被拒绝。\n$p_{(1), \\text{adj}}^{\\text{BH}}$ 到 $p_{(9), \\text{adj}}^{\\text{BH}}$ 都小于或等于 $0.10$。$p_{(10), \\text{adj}}^{\\text{BH}} = 0.1440 > 0.10$。\n因此，Benjamini-Hochberg程序拒绝了 $9$ 个假设。\n\n**3. 期望的错误拒绝数（Bonferroni）**\n\n设 $V_{\\text{Bonf}}$ 为Bonferroni程序下的错误拒绝数（第一类错误）。这些是被错误拒绝的真原假设。设 $H_0$ 为 $m_0$ 个真原假设的集合。\n$$V_{\\text{Bonf}} = \\sum_{i \\in H_0} \\mathbb{I}\\left(p_i \\le \\frac{\\alpha_{\\text{FWER}}}{m}\\right)$$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数。根据期望的线性性质，期望的错误拒绝数为：\n$$E[V_{\\text{Bonf}}] = E\\left[\\sum_{i \\in H_0} \\mathbb{I}\\left(p_i \\le \\frac{\\alpha_{\\text{FWER}}}{m}\\right)\\right] = \\sum_{i \\in H_0} E\\left[\\mathbb{I}\\left(p_i \\le \\frac{\\alpha_{\\text{FWER}}}{m}\\right)\\right] = \\sum_{i \\in H_0} P\\left(p_i \\le \\frac{\\alpha_{\\text{FWER}}}{m}\\right)$$\n在真原假设的$p$值独立同分布于 $\\mathrm{Uniform}(0,1)$ 的假设下，拒绝单个真原假设的概率为 $P(p_i \\le \\frac{\\alpha_{\\text{FWER}}}{m}) = \\frac{\\alpha_{\\text{FWER}}}{m}$。\n由于有 $m_0$ 个这样的假设，期望的错误拒绝数为：\n$$E[V_{\\text{Bonf}}] = m_0 \\cdot \\frac{\\alpha_{\\text{FWER}}}{m}$$\n代入给定值：$m_0=9$，$m=12$，以及 $\\alpha_{\\text{FWER}}=0.05$：\n$$E[V_{\\text{Bonf}}] = 9 \\times \\frac{0.05}{12} = \\frac{9 \\times 0.05}{12} = \\frac{0.45}{12} = 0.0375 = \\frac{3}{80}$$\n\n**4. 错误发现率的界限（Benjamini-Hochberg）**\n\n错误发现率（FDR）定义为所有发现中错误发现的期望比例，即 $E[V/R]$，其中 $V$ 是错误拒绝数，$R$ 是总拒绝数（如果 $R=0$，则 $V/R$ 定义为 $0$）。当应用于水平 $q$ 时，Benjamini-Hochberg程序保证对于独立的检验（如此处假设），FDR是受控的：\n$$\\text{FDR} = E\\left[\\frac{V}{R}\\right] \\le \\frac{m_0}{m}q$$\n问题要求的是该程序所达到的界限。这个界限就是不等式的右侧。\n代入给定值：$m_0=9$，$m=12$，以及 $q=0.10$：\n$$\\text{Bound} = \\frac{9}{12} \\times 0.10 = \\frac{3}{4} \\times 0.10 = 0.75 \\times 0.10 = 0.075 = \\frac{3}{40}$$\n\n**5. 比较指标 $\\rho$ 的计算**\n\n无量纲比较指标 $\\rho$ 定义为：\n$$\\rho \\equiv \\frac{E[V_{\\text{Bonf}}]/m}{\\left(\\frac{m_0}{m}\\right) q}$$\n我们代入第3部分中推导出的 $E[V_{\\text{Bonf}}]$ 的表达式：\n$$E[V_{\\text{Bonf}}] = m_0 \\frac{\\alpha_{\\text{FWER}}}{m}$$\n$\\rho$ 的表达式变为：\n$$\\rho = \\frac{\\left(m_0 \\frac{\\alpha_{\\text{FWER}}}{m}\\right) / m}{\\left(\\frac{m_0}{m}\\right) q} = \\frac{\\frac{m_0 \\alpha_{\\text{FWER}}}{m^2}}{\\frac{m_0 q}{m}}$$\n通过消去项来简化表达式：\n$$\\rho = \\frac{m_0 \\alpha_{\\text{FWER}}}{m^2} \\cdot \\frac{m}{m_0 q} = \\frac{\\alpha_{\\text{FWER}}}{m \\cdot q}$$\n现在，我们使用给定的常数 $\\alpha_{\\text{FWER}}=0.05$，$m=12$，和 $q=0.10$ 来计算 $\\rho$ 的精确值：\n$$\\rho = \\frac{0.05}{12 \\times 0.10} = \\frac{0.05}{1.2} = \\frac{5/100}{12/10} = \\frac{5}{100} \\times \\frac{10}{12} = \\frac{50}{1200} = \\frac{1}{24}$$",
            "answer": "$$\\boxed{\\frac{1}{24}}$$"
        },
        {
            "introduction": "基因本体论（GO）的术语被组织在一个有向无环图（DAG）中，这种结构带来了固有的依赖性，会使富集分析变得复杂。本练习通过一个具体的例子，揭示了朴素的过表征分析（ORA）为何可能产生误导，并引入了一种父子条件方法来修正这种偏差。通过比较两种方法的结果，您将深入理解如何处理GO的层次结构，以获得更精确、更具生物学意义的功能注释 。",
            "id": "3312252",
            "problem": "一个实验室正在将一个小基因集注释到一个基因本体论 (Gene Ontology, GO) 的玩具版有向无环图 (Directed Acyclic Graph, DAG) 上。目标是比较朴素的过表征分析 (Over-Representation Analysis, ORA) 与基于此 DAG 的亲子条件方法，并量化两种方法检出的显著性条目数量的差异。\n\n使用以下科学上合理的设置：\n- 注释的基因全集为 $12$ 个基因，$G = \\{g1, g2, \\dots, g12\\}$。\n- GO DAG 由条目 $\\{T1, T2, T3, T4, T5, T6, T7\\}$ 组成，其亲子关系如下：\n  - $T1$ (根节点)。\n  - $T2$ 是 $T1$ 的子节点。\n  - $T3$ 是 $T1$ 的子节点。\n  - $T4$ 是 $T2$ 的子节点。\n  - $T5$ 是 $T2$ 的子节点。\n  - $T6$ 同时是 $T2$ 和 $T3$ 的子节点 (多父节点条目)。\n  - $T7$ 是 $T1$ 的子节点。\n- 基因被直接注释到以下叶节点条目 (且注释会向上传播至 DAG 中的所有祖先节点)：\n  - $T4$: $\\{g1, g2, g3\\}$。\n  - $T5$: $\\{g4, g5\\}$。\n  - $T6$: $\\{g6, g7, g8, g9\\}$。\n  - $T7$: $\\{g10, g11, g12\\}$。\n  因此，通过传播：\n  - $T2$ 包含 $\\{g1, g2, g3, g4, g5, g6, g7, g8, g9\\}$。\n  - $T3$ 包含 $\\{g6, g7, g8, g9\\}$。\n  - $T1$ 包含所有 $12$ 个基因。\n- 研究列表 (查询集) 为 $L = \\{g1, g6, g7, g8, g9\\}$。\n\n需要执行的任务：\n1. 朴素过表征分析 (ORA)：\n   - 对于每个条目 $T \\in \\{T3, T4, T5, T6\\}$，使用标准的超几何模型计算单侧富集 $p$ 值。其中，总体定义为注释的基因全集 ($N = |T1|$), 条目大小为 $K = |T|$ (包含传播的注释)，列表大小为 $n = |L|$，观察到的重叠为 $k = |L \\cap T|$。使用“至少匹配这么多或更多”的上尾约定。\n2. 亲子方法 (并集变体)：\n   - 对于每个具有父节点 $\\mathrm{Pa}(T)$ 的条目 $T \\in \\{T3, T4, T5, T6\\}$，将条件集 $S_{\\mathrm{parent}}(T)$ 定义为注释到 $T$ 的所有父节点的基因的并集。使用超几何模型计算单侧富集 $p$ 值，但总体限制为 $N' = |S_{\\mathrm{parent}}(T)|$，其中 $K' = |T|$，$n' = |L \\cap S_{\\mathrm{parent}}(T)|$，$k' = |L \\cap T|$。\n3. 多重检验：\n   - 对 $m = 4$ 个被检验的条目 $\\{T3, T4, T5, T6\\}$ 应用 Bonferroni 校正，使用家族错误率 (family-wise error rate) $\\alpha = 0.05$。如果一个条目的未经校正的 $p$ 值至多为 $\\alpha/m$，则该条目被称为显著。\n4. 报告在朴素 ORA 和亲子方法下显著性条目的数量。然后计算定义为“朴素 ORA 计数减去亲子方法计数”的差值。\n\n将最终答案表示为单个整数。无需四舍五入。无需单位。",
            "solution": "问题陈述已经过验证并被认为是有效的。它在计算系统生物学领域具有科学依据，所有必要的数据和定义都已给出且结构良好，并且内部一致。任务是执行并比较两种标准的基因本体论 (GO) 富集分析。\n\n分析过程首先执行朴素的过表征分析 (ORA)，然后进行亲子条件分析。GO 条目的显著性是通过单侧 (上尾) 超几何检验来确定的。从一个大小为 $N$、包含 $K$ 个成功实例的总体中，进行 $n$ 次不放回抽样，观察到至少 $k$ 次成功的概率由以下公式给出：\n$$p = P(X \\ge k) = \\sum_{i=k}^{\\min(n,K)} \\frac{\\binom{K}{i}\\binom{N-K}{n-i}}{\\binom{N}{n}}$$\n我们需要检验 $m=4$ 个条目：$\\{T_3, T_4, T_5, T_6\\}$。在家族错误率为 $\\alpha=0.05$ 的情况下，经过 Bonferroni 校正后，每个未经校正的 $p$ 值的显著性阈值为 $\\frac{\\alpha}{m} = \\frac{0.05}{4} = 0.0125$。如果一个条目的 $p$ 值小于或等于此阈值，则该条目被称为显著。\n\n提供的基因集如下：\n- 基因全集 $G = \\{g_1, g_2, \\dots, g_{12}\\}$。\n- 研究列表 $L = \\{g_1, g_6, g_7, g_8, g_9\\}$。\n- GO 条目注释 (已传播)：\n  - $T_1 = \\{g_1, \\dots, g_{12}\\}$, 所以 $|T_1| = 12$。\n  - $T_2 = \\{g_1, \\dots, g_9\\}$, 所以 $|T_2| = 9$。\n  - $T_3 = \\{g_6, g_7, g_8, g_9\\}$, 所以 $|T_3| = 4$。\n  - $T_4 = \\{g_1, g_2, g_3\\}$, 所以 $|T_4| = 3$。\n  - $T_5 = \\{g_4, g_5\\}$, 所以 $|T_5| = 2$。\n  - $T_6 = \\{g_6, g_7, g_8, g_9\\}$, 所以 $|T_6| = 4$。\n\n### 1. 朴素过表征分析 (ORA)\n\n对于朴素 ORA，总体是整个基因全集 $T_1$。\n- 总体大小: $N = |T_1| = 12$。\n- 列表大小 (抽样次数): $n = |L| = 5$。\n\n我们分析每个条目：\n\n**条目 $T_3$：**\n- 条目大小 (总体中的成功实例): $K = |T_3| = 4$。\n- 观察到的重叠: $k = |L \\cap T_3| = |\\{g_6, g_7, g_8, g_9\\}| = 4$。\n- 参数为 $N=12, K=4, n=5, k=4$。\n- $p$ 值为 $P(X \\ge 4) = P(X=4) = \\frac{\\binom{4}{4}\\binom{12-4}{5-4}}{\\binom{12}{5}} = \\frac{\\binom{4}{4}\\binom{8}{1}}{\\binom{12}{5}}$。\n- $\\binom{12}{5} = \\frac{12 \\cdot 11 \\cdot 10 \\cdot 9 \\cdot 8}{5 \\cdot 4 \\cdot 3 \\cdot 2 \\cdot 1} = 792$。\n- $p_{T_3} = \\frac{1 \\cdot 8}{792} = \\frac{1}{99} \\approx 0.0101$。\n- 由于 $0.0101 \\le 0.0125$，条目 $T_3$ 是**显著的**。\n\n**条目 $T_4$：**\n- 条目大小: $K = |T_4| = 3$。\n- 观察到的重叠: $k = |L \\cap T_4| = |\\{g_1\\}| = 1$。\n- 参数为 $N=12, K=3, n=5, k=1$。\n- $p$ 值为 $P(X \\ge 1) = 1 - P(X=0) = 1 - \\frac{\\binom{3}{0}\\binom{12-3}{5-0}}{\\binom{12}{5}} = 1 - \\frac{\\binom{3}{0}\\binom{9}{5}}{792}$。\n- $\\binom{9}{5} = \\binom{9}{4} = \\frac{9 \\cdot 8 \\cdot 7 \\cdot 6}{4 \\cdot 3 \\cdot 2 \\cdot 1} = 126$。\n- $p_{T_4} = 1 - \\frac{1 \\cdot 126}{792} = \\frac{792 - 126}{792} = \\frac{666}{792} = \\frac{37}{44} \\approx 0.8409$。\n- 由于 $0.8409 > 0.0125$，条目 $T_4$ **不显著**。\n\n**条目 $T_5$：**\n- 条目大小: $K = |T_5| = 2$。\n- 观察到的重叠: $k = |L \\cap T_5| = |\\emptyset| = 0$。\n- 参数为 $N=12, K=2, n=5, k=0$。\n- 我们检验的是过表征 (上尾)。观察值为 $k=0$ 不可能是过表征。$p$ 值为 $P(X \\ge 0) = 1$。\n- 由于 $1 > 0.0125$，条目 $T_5$ **不显著**。\n\n**条目 $T_6$：**\n- 条目大小: $K = |T_6| = 4$。\n- 观察到的重叠: $k = |L \\cap T_6| = |\\{g_6, g_7, g_8, g_9\\}| = 4$。\n- 参数为 $N=12, K=4, n=5, k=4$。这与 $T_3$ 的计算相同。\n- $p_{T_6} = \\frac{1}{99} \\approx 0.0101$。\n- 由于 $0.0101 \\le 0.0125$，条目 $T_6$ 是**显著的**。\n\n在朴素 ORA 方法下，显著性条目的数量为 $2$ (条目 $T_3$ 和 $T_6$）。\n\n### 2. 亲子条件分析\n\n在此，条目 $T$ 的总体被限制在其所有父节点基因的并集中，$S_{\\mathrm{parent}}(T) = \\bigcup_{P \\in \\mathrm{Pa}(T)} P$。\n\n**条目 $T_3$：**\n- 父节点: $\\mathrm{Pa}(T_3)=\\{T_1\\}$。\n- 条件集: $S_{\\mathrm{parent}}(T_3) = T_1$。\n- 这简化为朴素 ORA 的情况。$N'=12, K'=4, n'=5, k'=4$。\n- $p'_{T_3} = \\frac{1}{99} \\approx 0.0101$。\n- 由于 $0.0101 \\le 0.0125$，条目 $T_3$ 是**显著的**。\n\n**条目 $T_4$：**\n- 父节点: $\\mathrm{Pa}(T_4)=\\{T_2\\}$。\n- 条件集: $S_{\\mathrm{parent}}(T_4) = T_2$。\n- 新的总体大小: $N' = |T_2| = 9$。\n- 新的列表: $L \\cap T_2 = \\{g_1, g_6, g_7, g_8, g_9\\} \\cap \\{g_1, \\dots, g_9\\} = L$。\n- 新的列表大小: $n' = |L| = 5$。\n- 条目大小: $K' = |T_4| = 3$。\n- 观察到的重叠: $k' = |L \\cap T_4| = 1$。\n- 参数为 $N'=9, K'=3, n'=5, k'=1$。\n- $p'_{T_4} = P(X \\ge 1) = 1 - P(X=0) = 1 - \\frac{\\binom{3}{0}\\binom{9-3}{5-0}}{\\binom{9}{5}} = 1 - \\frac{\\binom{3}{0}\\binom{6}{5}}{\\binom{9}{5}}$。\n- $\\binom{9}{5} = 126$。$\\binom{6}{5} = 6$。\n- $p'_{T_4} = 1 - \\frac{1 \\cdot 6}{126} = 1 - \\frac{1}{21} = \\frac{20}{21} \\approx 0.9524$。\n- 由于 $0.9524 > 0.0125$，条目 $T_4$ **不显著**。\n\n**条目 $T_5$：**\n- 父节点: $\\mathrm{Pa}(T_5)=\\{T_2\\}$。\n- 条件集是 $T_2$，所以参数为 $N'=9, n'=5$。\n- 条目大小: $K' = |T_5| = 2$。\n- 观察到的重叠: $k' = |L \\cap T_5| = 0$。\n- $p'_{T_5} = P(X \\ge 0) = 1$。\n- 由于 $1 > 0.0125$，条目 $T_5$ **不显著**。\n\n**条目 $T_6$：**\n- 父节点: $\\mathrm{Pa}(T_6)=\\{T_2, T_3\\}$。\n- 条件集: $S_{\\mathrm{parent}}(T_6) = T_2 \\cup T_3$。由于 $T_3$ 是 $T_2$ 的子集 ($T_3 \\subset T_2$)，它们的并集是 $T_2$。\n- 新的总体大小: $N' = |T_2| = 9$。\n- 新的列表大小: $n' = |L \\cap T_2| = 5$。\n- 条目大小: $K' = |T_6| = 4$。\n- 观察到的重叠: $k' = |L \\cap T_6| = 4$。\n- 参数为 $N'=9, K'=4, n'=5, k'=4$。\n- $p'_{T_6} = P(X \\ge 4) = P(X=4) = \\frac{\\binom{4}{4}\\binom{9-4}{5-4}}{\\binom{9}{5}} = \\frac{\\binom{4}{4}\\binom{5}{1}}{\\binom{9}{5}}$。\n- $p'_{T_6} = \\frac{1 \\cdot 5}{126} = \\frac{5}{126} \\approx 0.0397$。\n- 由于 $0.0397 > 0.0125$，条目 $T_6$ **不显著**。\n\n在亲子方法下，显著性条目的数量为 $1$ (仅条目 $T_3$）。\n\n### 3. 比较与最终答案\n\n- 显著性条目数量 (朴素 ORA): $2$。\n- 显著性条目数量 (亲子方法): $1$。\n- 差值定义为“朴素 ORA 计数减去亲子方法计数”。\n- 差值 = $2 - 1 = 1$。",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "功能富集分析的一个常见结果是一长串显著但高度冗余的GO术语列表，这使得结果的解读变得困难。本实践将指导您使用Resnik方法计算GO术语之间的语义相似度，该方法利用了GO层次结构中的信息内容。接着，您将应用这些相似度分数来聚类相关的术语并挑选出一组简洁的代表性术语，这是将复杂的生物学结果总结为条理清晰的叙述的一项关键技能 。",
            "id": "3312268",
            "problem": "给定一个简化的有向无环图 (DAG)，该图模拟了基因本体论 (GO; Gene Ontology) 的一个子集，用于计算功能注释。为了完整性和上下文，京都基因与基因组百科全书 (KEGG) 和 Reactome 是其他的通路资源，但本问题专注于基因本体论 DAG 的语义。该图编码了生物过程分支，其术语用从 $1$ 到 $12$ 的整数标记，每个术语可以有零个或多个父节点。该 DAG 遵循真实路径规则，即对子术语的注释也意味着对其所有祖先术语的注释。本问题要求您根据 Resnik 定义为一组 GO 术语构建一个语义相似度矩阵，将其归一化为距离，然后提出一种带有代表性选择的聚类方法，该方法在减少冗余的同时，保留生物过程的覆盖范围，覆盖范围以叶过程的覆盖度来衡量。所有量和步骤都必须根据下面给出的第一性原理和所提供的数据推导得出；不允许使用外部数据库。\n\n待使用的基本定义：\n- 基因本体论 DAG 由父节点关系指定。每个术语 $t$ 有一个父节点集 $\\mathrm{Pa}(t)$，其祖先集 $\\mathrm{Anc}(t)$ 递归地定义为 $t$ 本身加上其父节点的祖先。该 DAG 是无环的，并且在 $t=1$ 处有一个唯一的根。\n- 真实路径规则将术语 $t$ 的计数 $c(t)$ 定义为对 $t$ 的所有叶子后代（如果 $t$ 本身是叶子，则包括 $t$）的总注释数。总注释计数为 $C=\\sum_{\\ell \\in L}c(\\ell)$，其中 $L$ 是叶术语的集合。\n- 一个术语的概率是 $p(t)=\\frac{c(t)}{C}$，其信息含量 (Information Content) 是 $IC(t)=-\\ln p(t)$，使用自然对数。\n- 对于两个术语 $a$ 和 $b$，信息量最丰富的共同祖先 (Most Informative Common Ancestor, MICA) 是 $\\mathrm{Anc}(a)\\cap \\mathrm{Anc}(b)$ 中具有最大 $IC$ 值的祖先；Resnik 语义相似度为 $s_{\\mathrm{Resnik}}(a,b)=IC(\\mathrm{MICA}(a,b))$。\n- 为了将相似度限制在 $[0,1]$ 区间以便聚类，使用归一化相似度 $s(a,b)=\\frac{s_{\\mathrm{Resnik}}(a,b)}{\\max(IC(a),IC(b))}$，并约定如果 $\\max(IC(a),IC(b))=0$，则 $s(a,b)=0$。\n- 定义距离 $d(a,b)=1-s(a,b)$。\n- 在给定的术语集 $S$ 上构建一个阈值图，如果 $d(a,b)\\le \\theta$（其中 $\\theta$ 是提供的阈值），则用一条无向边连接 $a,b\\in S$。聚类是该阈值图的连通分量。\n\n生物过程的覆盖率：\n- 设 $L$ 为 DAG 的叶节点。任何术语集 $X$ 的叶覆盖集是 $L(X)=\\bigcup_{t\\in X}L(t)$，其中 $L(t)$ 是从 $t$ 沿子节点边可达的叶节点集。\n- 代表集 $R$ 相对于原始集 $S$ 的覆盖率为 $\\gamma(R,S)=\\frac{|L(R)|}{|L(S)|}$，并约定如果 $|L(S)|=0$，则 $\\gamma(R,S)=1$。\n- 代表性选择必须在减少冗余的同时保持覆盖率：最初为每个聚类选择至多一个代表以最大化覆盖率，然后如果需要，可以跨任何聚类贪婪地添加额外的术语，直到 $\\gamma(R,S)\\ge \\alpha$，其中 $\\alpha$ 是以小数形式提供的覆盖率阈值。在一个聚类内，选择能最大化 $|L(\\{t\\})|$ 与 $L(S)$ 交集的初始代表；若出现平局，则选择 $IC$ 较大的，然后选择术语索引较小的。对于后续的贪婪添加，总是选择能使 $|L(R)|$ 边际增长最大的剩余术语；若出现平局，则选择 $IC$ 较大的，然后选择索引较小的。每个测试用例的最终代表列表必须按术语索引升序排序。\n\nDAG 和基础叶注释计数指定如下：\n- 父节点关系（每对 $(u,v)$ 表示 $u$ 是 $v$ 的父节点）：\n  $(1,2)$, $(1,3)$, $(2,4)$, $(2,5)$, $(3,6)$, $(3,7)$, $(3,12)$, $(4,8)$, $(5,9)$, $(6,10)$, $(7,11)$。\n- 叶节点是 $8$, $9$, $10$, $11$, $12$。\n- 基础叶节点注释计数为：\n  $c(8)=50$, $c(9)=70$, $c(10)=120$, $c(11)=90$, $c(12)=80$。\n- 总计数是 $C=50+70+120+90+80$。\n\n您的程序必须：\n1. 通过对其后代的叶节点计数求和，计算所有 $t\\in\\{1,\\ldots,12\\}$ 的 $c(t)$。\n2. 计算所有术语的 $p(t)$ 和 $IC(t)$。\n3. 对于每个测试用例集 $S$，构建归一化的 Resnik 相似度矩阵 $[s(a,b)]_{a,b\\in S}$ 和相应的距离矩阵 $[d(a,b)]_{a,b\\in S}$。\n4. 使用提供的 $\\theta$ 将 $S$ 聚类成阈值图的连通分量。\n5. 如上定义选择代表，以达到至少为 $\\alpha$ 的覆盖率。\n6. 生成最终输出，为包含所有测试用例结果的单行文本，形式为用方括号括起来的逗号分隔列表。每个结果必须是代表该测试用例的已选代表的整数列表，按升序排序。此输出中任何地方都不允许有空格。\n\n测试套件：\n- 测试用例 1：$S=[3,4,5,6,7]$, $\\theta=0.8$, $\\alpha=0.8$。\n- 测试用例 2：$S=[4,6]$, $\\theta=0.5$, $\\alpha=1.0$。\n- 测试用例 3：$S=[3,6,10]$, $\\theta=0.8$, $\\alpha=0.67$。\n- 测试用例 4：$S=[4,4,5,5]$, $\\theta=0.42$, $\\alpha=1.0$。\n\n最终输出格式：\n您的程序应生成单行输出，包含用方括号括起来的逗号分隔列表形式的结果，其中每个元素是相应测试用例的代表术语索引的排序列表。例如，一个有效的输出格式是 $[[a_1,a_2],[b_1],[c_1,c_2,c_3],[d_1]]$。输出不得包含任何空格。",
            "solution": "此问题要求执行一个多步骤算法，该算法模拟了功能基因组学中减少冗余的典型工作流程。解决方案遵循以下步骤：\n1.  **预计算**：首先，处理给定的有向无环图（DAG）结构和叶节点注释计数。计算所有术语的完整注释计数 $c(t)$、概率 $p(t)$ 和信息含量 $IC(t)$。同时，为所有术语预先计算祖先集和叶后代集。\n2.  **相似度与距离计算**：对于每个测试用例中的术语集 $S$，计算所有术语对 $(a, b)$ 之间的 Resnik 语义相似度 $s_{\\mathrm{Resnik}}(a,b)$。然后，根据问题中定义的公式将其归一化为 $s(a,b)$，并转换为距离 $d(a,b) = 1 - s(a,b)$，从而构建距离矩阵。\n3.  **聚类**：使用计算出的距离矩阵和给定的阈值 $\\theta$，构建一个阈值图，其中如果术语间的距离 $d(a,b) \\le \\theta$，则在它们之间创建一条边。图的连通分量即为聚类。\n4.  **代表性选择**：应用一个两阶段过程来选择代表。首先，从每个聚类中选择一个初始代表，该代表能最大化其叶节点覆盖率，并根据 $IC$ 和术语索引进行平局决胜。然后，如果总覆盖率低于阈值 $\\alpha$，则通过贪婪地添加能提供最大边际叶节点覆盖率的剩余术语来迭代地扩充代表集，直到满足覆盖率要求。\n最终，将为每个测试用例选择的代表按升序排序并格式化输出。",
            "answer": "```python\nimport numpy as np\n\nclass GOSimilarityProcessor:\n    \"\"\"\n    Handles GO semantic similarity calculations, clustering, and representative selection.\n    \"\"\"\n    def __init__(self, parent_rels, leaf_counts):\n        self.num_terms = 12\n        self.terms = list(range(1, self.num_terms + 1))\n        self.leaf_counts_base = leaf_counts\n        self.leaves = set(self.leaf_counts_base.keys())\n\n        # Build graph structure\n        self.parents = {t: set() for t in self.terms}\n        self.children = {t: set() for t in self.terms}\n        for u, v in parent_rels:\n            self.parents[v].add(u)\n            self.children[u].add(v)\n\n        # Pre-compute graph properties and information content\n        self._memo_anc = {}\n        self.ancestors = {t: self._get_ancestors(t) for t in self.terms}\n\n        self._memo_ld = {}\n        self.leaf_descendants = {t: self._get_leaf_descendants(t) for t in self.terms}\n        \n        self.counts = self._compute_counts()\n        self.total_count = sum(self.leaf_counts_base.values())\n        self.ic = self._compute_ic()\n\n    def _get_ancestors(self, t):\n        if t in self._memo_anc:\n            return self._memo_anc[t]\n        \n        anc = {t}\n        for p in self.parents.get(t, []):\n            anc.update(self._get_ancestors(p))\n        self._memo_anc[t] = anc\n        return anc\n\n    def _get_leaf_descendants(self, t):\n        if t in self._memo_ld:\n            return self._memo_ld[t]\n        \n        if t in self.leaves:\n            self._memo_ld[t] = {t}\n            return {t}\n        \n        desc_leaves = set()\n        for c in self.children.get(t, []):\n            desc_leaves.update(self._get_leaf_descendants(c))\n        self._memo_ld[t] = desc_leaves\n        return desc_leaves\n\n    def _compute_counts(self):\n        counts = {t: 0 for t in self.terms}\n        for t in self.terms:\n            leaf_desc = self.leaf_descendants[t]\n            if leaf_desc:\n                counts[t] = sum(self.leaf_counts_base[l] for l in leaf_desc)\n        return counts\n\n    def _compute_ic(self):\n        ic = {t: 0.0 for t in self.terms}\n        for t in self.terms:\n            if self.counts[t] > 0 and self.total_count > 0:\n                p_t = self.counts[t] / self.total_count\n                ic[t] = -np.log(p_t)\n        return ic\n\n    def _get_mica(self, t1, t2):\n        common_ancestors = self.ancestors[t1]  self.ancestors[t2]\n        if not common_ancestors:\n            return None\n        \n        max_ic = -1.0\n        mica = None\n        # Iteration order over a set is not guaranteed, but for a unique max, it's fine.\n        for anc in common_ancestors:\n            if self.ic[anc] > max_ic:\n                max_ic = self.ic[anc]\n                mica = anc\n        return mica\n\n    def solve_case(self, S_list, theta, alpha):\n        # Use a sorted set of unique terms from the input list S\n        S = sorted(list(set(S_list)))\n\n        # 1. Compute Distance Matrix\n        dist_matrix = {t1: {t2: 1.0 for t2 in S} for t1 in S}\n        for i in range(len(S)):\n            for j in range(i, len(S)):\n                t1, t2 = S[i], S[j]\n                if t1 == t2:\n                    dist_matrix[t1][t1] = 0.0\n                    continue\n\n                mica = self._get_mica(t1, t2)\n                s_resnik = self.ic.get(mica, 0.0)\n                \n                max_ic_val = max(self.ic[t1], self.ic[t2])\n                s_norm = s_resnik / max_ic_val if max_ic_val > 0 else 0.0\n                \n                dist = 1.0 - s_norm\n                dist_matrix[t1][t2] = dist\n                dist_matrix[t2][t1] = dist\n\n        # 2. Find Clusters via Connected Components of Threshold Graph\n        adj = {t: [] for t in S}\n        for i in range(len(S)):\n            for j in range(i + 1, len(S)):\n                t1, t2 = S[i], S[j]\n                if dist_matrix[t1][t2] = theta:\n                    adj[t1].append(t2)\n                    adj[t2].append(t1)\n\n        visited = set()\n        clusters = []\n        for term in S:\n            if term not in visited:\n                component = []\n                q = [term]\n                visited.add(term)\n                component.append(term)\n                head = 0\n                while head  len(q):\n                    u = q[head]\n                    head += 1\n                    for v in adj[u]:\n                        if v not in visited:\n                            visited.add(v)\n                            q.append(v)\n                            component.append(v)\n                clusters.append(component)\n\n        # 3. Representative Selection\n        L_S = set().union(*(self.leaf_descendants[t] for t in S))\n        \n        if not L_S: # Handle case where S covers no leaves\n            return []\n\n        # Phase 1: Initial Selection\n        R = set()\n        for cluster in clusters:\n            candidates = []\n            for t in cluster:\n                score = len(self.leaf_descendants[t]  L_S)\n                candidates.append((score, self.ic[t], t))\n            \n            # Tie-breaking: 1. score (desc), 2. IC (desc), 3. term index (asc)\n            candidates.sort(key=lambda x: (x[0], x[1], -x[2]), reverse=True)\n            if candidates:\n                best_rep = candidates[0][2]\n                R.add(best_rep)\n\n        # Phase 2: Greedy Addition\n        L_R = set().union(*(self.leaf_descendants[t] for t in R))\n\n        while len(L_R) / len(L_S)  alpha:\n            remaining_terms = [t for t in S if t not in R]\n            if not remaining_terms:\n                break\n            \n            candidates = []\n            for t in remaining_terms:\n                marginal_gain = len(self.leaf_descendants[t] - L_R)\n                candidates.append((marginal_gain, self.ic[t], t))\n            \n            # Tie-breaking: 1. gain (desc), 2. IC (desc), 3. term index (asc)\n            candidates.sort(key=lambda x: (x[0], x[1], -x[2]), reverse=True)\n            \n            if not candidates or candidates[0][0] == 0: # No more progress possible\n                break\n                \n            best_term_to_add = candidates[0][2]\n            R.add(best_term_to_add)\n            L_R.update(self.leaf_descendants[best_term_to_add])\n            \n        return sorted(list(R))\n\ndef solve():\n    # Define problem constants\n    parent_relationships = [\n        (1, 2), (1, 3), (2, 4), (2, 5), (3, 6), (3, 7), (3, 12),\n        (4, 8), (5, 9), (6, 10), (7, 11)\n    ]\n    base_leaf_counts = {8: 50, 9: 70, 10: 120, 11: 90, 12: 80}\n\n    # Initialize the processor once with all static data\n    processor = GOSimilarityProcessor(parent_relationships, base_leaf_counts)\n\n    # Define the test cases\n    test_cases = [\n        {'S': [3, 4, 5, 6, 7], 'theta': 0.8, 'alpha': 0.8},\n        {'S': [4, 6], 'theta': 0.5, 'alpha': 1.0},\n        {'S': [3, 6, 10], 'theta': 0.8, 'alpha': 0.67},\n        {'S': [4, 4, 5, 5], 'theta': 0.42, 'alpha': 1.0},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = processor.solve_case(case['S'], case['theta'], case['alpha'])\n        results.append(result)\n\n    # Format output as specified: [[a1,a2],[b1],[c1,c2,c3],[d1]] with no spaces\n    result_str = \",\".join([str(r).replace(\" \", \"\") for r in results])\n    print(f\"[{result_str}]\")\n\nsolve()\n```"
        }
    ]
}