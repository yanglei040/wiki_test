{
    "hands_on_practices": [
        {
            "introduction": "Negative autoregulation is a cornerstone of biological network design, essential for maintaining homeostasis. This practice builds foundational skills by analyzing the canonical model of a single-gene feedback loop, exploring how the balance between Hill-function-based repression and linear degradation dictates the system's behavior. By deriving and analyzing the steady-state equation, you will prove the existence of a unique, stable set point, solidifying your understanding of how this simple motif achieves robust concentration control .",
            "id": "3345716",
            "problem": "Consider a single-gene negative autoregulatory circuit in which the protein concentration $x(t)$ obeys the ordinary differential equation (ODE) $$\\frac{dx}{dt}=\\frac{\\alpha}{1+\\left(\\frac{x}{K}\\right)^{n}}-\\beta x,$$ where $\\alpha>0$ is a maximal synthesis rate, $K>0$ is a dissociation-like threshold, $n>0$ is the Hill coefficient capturing effective cooperativity of repression, and $\\beta>0$ is a first-order loss rate constant accounting for dilution and degradation. Starting from the definitions of steady state and the standard biochemical interpretation that a steady state equates production and loss fluxes, derive the steady-state condition for $x^{\\ast}$ and reduce it to an equation whose solutions correspond to steady-state concentrations. Without invoking any specialized theorems beyond elementary real analysis, analyze the existence and uniqueness of a biologically relevant steady state $x^{\\ast}>0$ as a function of the parameters $n$, $K$, $\\alpha$, and $\\beta$. Clearly state the parameter conditions under which existence and uniqueness are guaranteed, and identify any parameter regimes (including signs or limiting values) where existence may fail or multiple solutions could, in principle, arise if assumptions are relaxed. Finally, specialize to the noncooperative case $n=1$ and solve explicitly for the unique positive steady state $x^{\\ast}$ in closed form as a function of $\\alpha$, $\\beta$, and $K$. Provide your final answer as a single simplified analytic expression for $x^{\\ast}$ in the case $n=1$ with $\\alpha>0$, $\\beta>0$, and $K>0$. No rounding is required, and no units are necessary in the final expression.",
            "solution": "The problem will be validated before a solution is attempted.\n\n### Step 1: Extract Givens\n- **Governing Equation**: The protein concentration $x(t)$ is described by the ordinary differential equation (ODE) $\\frac{dx}{dt}=\\frac{\\alpha}{1+\\left(\\frac{x}{K}\\right)^{n}}-\\beta x$.\n- **Parameters and Constraints**:\n    - $\\alpha > 0$: maximal synthesis rate.\n    - $K > 0$: dissociation-like threshold.\n    - $n > 0$: Hill coefficient.\n    - $\\beta > 0$: first-order loss rate constant.\n- **Task**:\n    1. Derive the steady-state condition for the steady-state concentration $x^{\\ast}$.\n    2. Reduce this condition to an algebraic equation.\n    3. Analyze the existence and uniqueness of a biologically relevant steady state $x^{\\ast} > 0$ for general parameters.\n    4. State conditions for existence and uniqueness.\n    5. Identify regimes where uniqueness might fail if assumptions are relaxed.\n    6. For the special case $n=1$, solve explicitly for the unique positive steady state $x^{\\ast}$ as a function of $\\alpha$, $\\beta$, and $K$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientific or Factual Soundness**: The problem is scientifically sound. The provided ODE is a canonical model for negative genetic autoregulation, based on Michaelis-Menten-like kinetics generalized by the Hill function. This is a standard and fundamental model in systems biology and biochemical engineering. All parameters have well-defined, standard physical meanings.\n- **Well-Posedness**: The problem is well-posed. It requests the analysis of steady states of a given ODE, which is a standard procedure in dynamical systems theory. The question guides the analysis toward existence and uniqueness, which are central to the study of such systems.\n- **Objectivity**: The language is entirely mathematical and objective.\n- **Completeness and Consistency**: The problem is self-contained. It provides the governing equation and defines all parameters and their constraints ($\\alpha>0, \\beta>0, K>0, n>0$). There are no contradictions.\n- **Realism**: The model is a widely accepted idealization of a biological process. The parameter constraints are physically realistic.\n- **Structure and Clarity**: The problem is clearly structured and its terms are unambiguous.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is a standard, well-posed problem in mathematical biology. I will proceed with the solution.\n\n### Derivation of the Steady-State Condition\nA steady state of a dynamical system is a state in which the system's variables do not change over time. For the protein concentration $x(t)$, this condition is mathematically expressed as $\\frac{dx}{dt} = 0$. Let $x^{\\ast}$ denote the steady-state concentration. Substituting this into the given ODE yields:\n$$\n\\frac{dx}{dt}\\bigg|_{x=x^{\\ast}} = 0 = \\frac{\\alpha}{1+\\left(\\frac{x^{\\ast}}{K}\\right)^{n}}-\\beta x^{\\ast}\n$$\nThis equation can be rearranged to\n$$\n\\frac{\\alpha}{1+\\left(\\frac{x^{\\ast}}{K}\\right)^{n}} = \\beta x^{\\ast}\n$$\nThis is the steady-state condition. It equates the rate of protein synthesis (the left-hand side, a decreasing Hill function) to the rate of protein loss (the right-hand side, a linear function). This aligns perfectly with the biochemical interpretation of a steady state as a balance between production and loss fluxes. The solutions to this algebraic equation correspond to the steady-state concentrations of the system.\n\n### Analysis of Existence and Uniqueness of a Positive Steady State\nTo analyze the existence and uniqueness of a biologically relevant steady state, $x^{\\ast} > 0$, we analyze the intersections of two functions for $x \\ge 0$: the production rate function, $P(x) = \\frac{\\alpha}{1+\\left(\\frac{x}{K}\\right)^{n}}$, and the loss rate function, $L(x) = \\beta x$.\n\nLet's examine the properties of these two functions for $x \\ge 0$:\n1.  **Production Rate, $P(x)$**:\n    - At $x=0$, the production rate is maximal: $P(0) = \\frac{\\alpha}{1+0} = \\alpha$. Since $\\alpha > 0$, $P(0)$ is positive.\n    - As $x \\to \\infty$, the term $(\\frac{x}{K})^n \\to \\infty$ (since $n>0, K>0$), so $P(x) \\to 0$.\n    - The function $P(x)$ is strictly monotonically decreasing for $x > 0$. Its derivative is $P'(x) = \\frac{d}{dx}\\left[\\alpha\\left(1+\\left(\\frac{x}{K}\\right)^{n}\\right)^{-1}\\right] = -\\alpha\\left(1+\\left(\\frac{x}{K}\\right)^{n}\\right)^{-2} \\left(\\frac{nx^{n-1}}{K^n}\\right)$. Since all parameters $\\alpha, n, K$ are positive, and for $x>0$, we have $P'(x) < 0$.\n\n2.  **Loss Rate, $L(x)$**:\n    - At $x=0$, the loss rate is $L(0) = 0$.\n    - The function $L(x)$ is a straight line passing through the origin with a constant positive slope $\\beta$.\n\nTo find the steady states, we seek solutions to $P(x) = L(x)$. Let us define a new function $f(x) = P(x) - L(x) = \\frac{\\alpha}{1+\\left(\\frac{x}{K}\\right)^{n}} - \\beta x$. We are looking for roots of $f(x)=0$ for $x > 0$.\n\n- **Existence**: At $x=0$, we have $f(0) = P(0) - L(0) = \\alpha - 0 = \\alpha > 0$. As $x \\to \\infty$, $P(x) \\to 0$ and $L(x) \\to \\infty$, so $f(x) \\to -\\infty$. Since $f(x)$ is a continuous function for $x \\ge 0$, and it changes sign from positive at $x=0$ to negative for large $x$, the Intermediate Value Theorem guarantees that there must be at least one root $x^{\\ast} > 0$. Therefore, a positive steady state always exists under the given parameter constraints.\n\n- **Uniqueness**: To establish uniqueness, we examine the derivative of $f(x)$:\n$$\nf'(x) = P'(x) - L'(x) = -\\frac{\\alpha n x^{n-1}}{K^n \\left(1+\\left(\\frac{x}{K}\\right)^{n}\\right)^2} - \\beta\n$$\nFor all $x \\ge 0$ and given the constraints $\\alpha>0$, $\\beta>0$, $K>0$, and $n>0$, both terms in the expression for $f'(x)$ are non-positive. The first term is zero at $x=0$ (for $n>1$) or approaches a finite negative value (for $n=1$), and is strictly negative for $x>0$. The second term, $-\\beta$, is a strictly negative constant. Thus, $f'(x) < 0$ for all $x \\ge 0$.\nA function that is continuous and has a strictly negative derivative is strictly monotonically decreasing. A strictly monotonic function can cross any given horizontal line (in this case, the $x$-axis, where $f(x)=0$) at most once.\nSince we have already established that at least one root exists, and we have now shown that at most one root can exist, we conclude that there is a unique positive steady state $x^{\\ast} > 0$.\n\nThis existence and uniqueness are guaranteed for all positive values of the parameters: $\\alpha>0, \\beta>0, K>0, n>0$. There are no further conditions required.\n\nRegarding parameter regimes where multiple solutions could arise: for the specific mathematical model of negative autoregulation provided, $\\frac{dx}{dt} = P(x) - L(x)$, where $P(x)$ is monotonically decreasing and $L(x)$ is monotonically increasing, multiple steady states are not possible. The function $f(x)=P(x)-L(x)$ is strictly decreasing, guaranteeing a unique root. Multiple steady states (bistability) typically require a non-monotonic production function, which often arises from positive feedback loops or cooperative activation motifs, not from simple negative feedback as modeled here. Therefore, under the stated assumptions of the model, no parameter regime leads to multiple steady states.\n\n### Explicit Solution for the Noncooperative Case ($n=1$)\nWe now specialize to the case where $n=1$. The steady-state equation becomes:\n$$\n\\frac{\\alpha}{1+\\frac{x^{\\ast}}{K}} = \\beta x^{\\ast}\n$$\nWe solve for $x^{\\ast} > 0$. Rearranging the equation:\n$$\n\\alpha = \\beta x^{\\ast} \\left(1 + \\frac{x^{\\ast}}{K}\\right)\n$$\n$$\n\\alpha = \\beta x^{\\ast} + \\frac{\\beta}{K} (x^{\\ast})^2\n$$\nThis is a quadratic equation for $x^{\\ast}$. We write it in the standard form $ax^2 + bx + c = 0$:\n$$\n\\frac{\\beta}{K} (x^{\\ast})^2 + \\beta x^{\\ast} - \\alpha = 0\n$$\nWe use the quadratic formula, $x^{\\ast} = \\frac{-b \\pm \\sqrt{b^2-4ac}}{2a}$, with coefficients $a = \\frac{\\beta}{K}$, $b = \\beta$, and $c = -\\alpha$.\n$$\nx^{\\ast} = \\frac{-\\beta \\pm \\sqrt{\\beta^2 - 4\\left(\\frac{\\beta}{K}\\right)(-\\alpha)}}{2\\left(\\frac{\\beta}{K}\\right)}\n$$\n$$\nx^{\\ast} = \\frac{-\\beta \\pm \\sqrt{\\beta^2 + \\frac{4\\alpha\\beta}{K}}}{\\frac{2\\beta}{K}}\n$$\nSince $\\alpha$, $\\beta$, and $K$ are all positive, the discriminant $\\beta^2 + \\frac{4\\alpha\\beta}{K}$ is strictly positive, ensuring two distinct real solutions. We require a biologically relevant solution, meaning $x^{\\ast}>0$.\nThe term under the square root is $\\sqrt{\\beta^2 + \\frac{4\\alpha\\beta}{K}} > \\sqrt{\\beta^2} = |\\beta|$. Since $\\beta>0$, this is $\\sqrt{\\beta^2 + \\frac{4\\alpha\\beta}{K}} > \\beta$.\n\n- The solution with the minus sign in the numerator, $-\\beta - \\sqrt{\\beta^2 + \\frac{4\\alpha\\beta}{K}}$, is negative. Since the denominator $\\frac{2\\beta}{K}$ is positive, this entire solution is negative and therefore not biologically relevant.\n- The solution with the plus sign, $-\\beta + \\sqrt{\\beta^2 + \\frac{4\\alpha\\beta}{K}}$, is positive. This is the unique physically meaningful steady state.\n\nWe take the positive root and simplify the expression:\n$$\nx^{\\ast} = \\frac{-\\beta + \\sqrt{\\beta^2 + \\frac{4\\alpha\\beta}{K}}}{\\frac{2\\beta}{K}} = \\frac{K}{2\\beta} \\left(-\\beta + \\sqrt{\\beta^2\\left(1 + \\frac{4\\alpha}{\\beta K}\\right)}\\right)\n$$\nSince $\\beta > 0$, we can factor it out of the square root:\n$$\nx^{\\ast} = \\frac{K}{2\\beta} \\left(-\\beta + \\beta\\sqrt{1 + \\frac{4\\alpha}{\\beta K}}\\right)\n$$\nFactoring out $\\beta$ from the parenthesis:\n$$\nx^{\\ast} = \\frac{K\\beta}{2\\beta} \\left(-1 + \\sqrt{1 + \\frac{4\\alpha}{\\beta K}}\\right)\n$$\n$$\nx^{\\ast} = \\frac{K}{2} \\left(\\sqrt{1 + \\frac{4\\alpha}{\\beta K}} - 1\\right)\n$$\nThis is the final, simplified analytic expression for the unique positive steady state when $n=1$.",
            "answer": "$$\n\\boxed{\\frac{K}{2} \\left(\\sqrt{1 + \\frac{4\\alpha}{\\beta K}} - 1\\right)}\n$$"
        },
        {
            "introduction": "Building upon the analysis of simple negative feedback, we now introduce a critical feature of biological systems: time delay. Delays in transcription and translation can transform a stabilizing feedback loop into a generator of sustained oscillations, a phenomenon central to biological clocks and cell cycles. This exercise challenges you to perform a linear stability analysis on a delayed differential equation to determine the critical cooperativity, $n_{\\mathrm{crit}}$, at which the system transitions from a stable steady state to periodic behavior .",
            "id": "3345691",
            "problem": "Consider a single-gene negative autoregulatory circuit modeled as a delayed differential equation (DDE): the protein concentration $x(t)$ follows the dynamics\n$$\n\\frac{dx}{dt} = \\frac{\\alpha}{1 + \\left(\\frac{x(t-\\tau)}{K}\\right)^{n}} - \\beta\\, x(t),\n$$\nwhere $\\alpha$ is the maximal synthesis rate, $K$ is the dissociation constant of the repressor, $n$ is the Hill coefficient capturing cooperativity of repression, $\\beta$ is the first-order degradation (and dilution) rate, and $\\tau$ is the effective transcription–translation delay. Assume the system is operated at the half-saturation point by choosing $\\alpha$ such that the unique steady state satisfies $x^{\\ast} = K$ for all $n$.\n\nStarting from small-signal linearization principles, define the dimensionless linearized loop gain as the ratio of the magnitude of the input–output slope of the repressive synthesis term at steady state to the outflow rate $\\beta$, and express this in terms of $n$. Then, using the standard marginal stability condition for delayed negative feedback (with angles measured in radians), assess when the steady state loses linear stability by determining the critical Hill coefficient $n_{\\mathrm{crit}}$ at which a pair of complex-conjugate eigenvalues crosses the imaginary axis. In particular, evaluate $n_{\\mathrm{crit}}$ for the specific delay\n$$\n\\tau = \\frac{3\\pi}{4\\,\\beta}.\n$$\nExpress your final answer for $n_{\\mathrm{crit}}$ as an exact analytical expression. No rounding is required and no units should be included in your final answer.",
            "solution": "The problem is analyzed for validity.\n\n**Step 1: Extract Givens**\n- **Governing Equation:** The protein concentration $x(t)$ is modeled by the delayed differential equation (DDE):\n$$ \\frac{dx}{dt} = \\frac{\\alpha}{1 + \\left(\\frac{x(t-\\tau)}{K}\\right)^{n}} - \\beta\\, x(t) $$\n- **Parameters:**\n    - $\\alpha$: maximal synthesis rate\n    - $K$: dissociation constant\n    - $n$: Hill coefficient\n    - $\\beta$: first-order degradation rate\n    - $\\tau$: transcription–translation delay\n- **Steady State Condition:** The system has a unique steady state $x^{\\ast}$ such that $x^{\\ast} = K$. This is achieved by an appropriate choice of $\\alpha$.\n- **Specific Delay Value:** $\\tau = \\frac{3\\pi}{4\\,\\beta}$.\n- **Task Definition 1:** Define the dimensionless linearized loop gain as the ratio of the magnitude of the input–output slope of the repressive synthesis term at steady state to the outflow rate $\\beta$.\n- **Task Definition 2:** Determine the critical Hill coefficient $n_{\\mathrm{crit}}$ at which the steady state loses linear stability, for the given delay $\\tau$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding:** The problem describes a single-gene negative autoregulatory circuit using a Michaelis-Menten-like formalism with a Hill function for repression and a time delay. This is a canonical and well-established model in computational systems biology (a variant of the Goodwin oscillator). It is scientifically sound and fundamentally important in the study of biological oscillations.\n- **Well-Posedness:** The problem asks for a specific quantity, $n_{\\mathrm{crit}}$, derived from a clearly defined mathematical model and a standard stability analysis procedure (linearization and marginal stability). The constraints and definitions provided are sufficient to determine a unique solution.\n- **Objectivity:** The problem is stated in precise mathematical and scientific language, free of subjective or ambiguous terminology.\n- **Completeness and Consistency:** All necessary parameters and conditions are provided. The condition $x^*=K$ is consistent with the model, as it can be satisfied by setting $\\alpha = 2\\beta K$. The specific value of $\\tau$ is well-defined.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. It is a standard, well-posed problem in theoretical systems biology that is scientifically sound, objective, and self-contained. The solution process may proceed.\n\n**Solution Derivation**\n\nFirst, we determine the relationship between the parameters imposed by the steady-state condition $x^{\\ast} = K$. At steady state, $\\frac{dx}{dt} = 0$, so the governing equation becomes:\n$$ \\frac{\\alpha}{1 + \\left(\\frac{x^{\\ast}}{K}\\right)^{n}} - \\beta\\, x^{\\ast} = 0 $$\nSubstituting $x^{\\ast} = K$:\n$$ \\frac{\\alpha}{1 + \\left(\\frac{K}{K}\\right)^{n}} - \\beta\\, K = 0 $$\n$$ \\frac{\\alpha}{1 + 1} - \\beta\\, K = 0 $$\n$$ \\frac{\\alpha}{2} = \\beta\\, K \\implies \\alpha = 2\\beta K $$\nThis confirms that $\\alpha$ can be set to ensure the steady state is at $x^{\\ast} = K$ for any Hill coefficient $n$.\n\nNext, we linearize the system around this steady state. Let $x(t) = x^{\\ast} + \\delta x(t) = K + \\delta x(t)$. The DDE is of the form $\\frac{dx}{dt} = f(x(t), x(t-\\tau))$. Linearizing gives:\n$$ \\frac{d(\\delta x)}{dt} \\approx \\left.\\frac{\\partial f}{\\partial x(t)}\\right|_{x^{\\ast}} \\delta x(t) + \\left.\\frac{\\partial f}{\\partial x(t-\\tau)}\\right|_{x^{\\ast}} \\delta x(t-\\tau) $$\nThe function is $f(u, v) = \\frac{\\alpha}{1 + (v/K)^n} - \\beta u$. The partial derivatives are:\n$$ \\frac{\\partial f}{\\partial x(t)} = \\frac{\\partial f}{\\partial u} = -\\beta $$\n$$ \\frac{\\partial f}{\\partial x(t-\\tau)} = \\frac{\\partial f}{\\partial v} = \\alpha \\cdot (-1) \\left(1 + \\left(\\frac{v}{K}\\right)^n\\right)^{-2} \\cdot n \\left(\\frac{v}{K}\\right)^{n-1} \\cdot \\frac{1}{K} $$\nEvaluating at the steady state $(u, v) = (x^{\\ast}, x^{\\ast}) = (K, K)$:\n$$ \\left.\\frac{\\partial f}{\\partial x(t)}\\right|_{x^{\\ast}} = -\\beta $$\n$$ \\left.\\frac{\\partial f}{\\partial x(t-\\tau)}\\right|_{x^{\\ast}} = -\\frac{\\alpha n}{K} \\frac{(K/K)^{n-1}}{(1+(K/K)^n)^2} = -\\frac{\\alpha n}{K} \\frac{1}{(1+1)^2} = -\\frac{\\alpha n}{4K} $$\nSubstituting $\\alpha = 2\\beta K$:\n$$ \\left.\\frac{\\partial f}{\\partial x(t-\\tau)}\\right|_{x^{\\ast}} = -\\frac{(2\\beta K)n}{4K} = -\\frac{n\\beta}{2} $$\nThe linearized equation for the perturbation $\\delta x(t)$ is:\n$$ \\frac{d(\\delta x)}{dt} = -\\beta\\, \\delta x(t) - \\frac{n\\beta}{2} \\delta x(t-\\tau) $$\nNow, we find the dimensionless linearized loop gain. This is defined as the ratio of the magnitude of the input-output slope of the synthesis term to the outflow rate. The synthesis term is $S(x_{delay}) = \\frac{\\alpha}{1+(x_{delay}/K)^n}$. Its slope at steady state is what we just calculated as $\\left.\\frac{\\partial f}{\\partial x(t-\\tau)}\\right|_{x^{\\ast}} = -\\frac{n\\beta}{2}$. The magnitude of this slope is $|\\frac{-n\\beta}{2}| = \\frac{n\\beta}{2}$. The outflow rate is $\\beta$.\nThe dimensionless linearized loop gain, which we denote as $G$, is:\n$$ G = \\frac{\\text{magnitude of synthesis slope}}{\\text{outflow rate}} = \\frac{n\\beta/2}{\\beta} = \\frac{n}{2} $$\nTo assess stability, we examine the characteristic equation of the linearized DDE. We propose a solution of the form $\\delta x(t) = C e^{\\lambda t}$. Substituting this into the linearized DDE yields:\n$$ \\lambda C e^{\\lambda t} = -\\beta C e^{\\lambda t} - \\frac{n\\beta}{2} C e^{\\lambda(t-\\tau)} $$\nDividing by $C e^{\\lambda t}$ (for $C \\neq 0$) gives the characteristic equation for the eigenvalues $\\lambda$:\n$$ \\lambda + \\beta + \\frac{n\\beta}{2} e^{-\\lambda\\tau} = 0 $$\nThe loss of stability occurs when a pair of complex-conjugate eigenvalues crosses the imaginary axis. This is the marginal stability condition, where $\\lambda = i\\omega$ for some real frequency $\\omega > 0$. At the point of criticality, the Hill coefficient is $n = n_{\\mathrm{crit}}$.\n$$ i\\omega + \\beta + \\frac{n_{\\mathrm{crit}}\\beta}{2} e^{-i\\omega\\tau} = 0 $$\nUsing Euler's formula $e^{-i\\omega\\tau} = \\cos(\\omega\\tau) - i\\sin(\\omega\\tau)$:\n$$ i\\omega + \\beta + \\frac{n_{\\mathrm{crit}}\\beta}{2} (\\cos(\\omega\\tau) - i\\sin(\\omega\\tau)) = 0 $$\nWe separate this equation into its real and imaginary parts:\nReal part: $\\beta + \\frac{n_{\\mathrm{crit}}\\beta}{2}\\cos(\\omega\\tau) = 0 \\implies \\cos(\\omega\\tau) = -\\frac{2}{n_{\\mathrm{crit}}}$\nImaginary part: $\\omega - \\frac{n_{\\mathrm{crit}}\\beta}{2}\\sin(\\omega\\tau) = 0 \\implies \\sin(\\omega\\tau) = \\frac{2\\omega}{n_{\\mathrm{crit}}\\beta}$\nThe phase lag $\\omega\\tau$ must be in the second quadrant since $n_{\\mathrm{crit}}>0$ implies $\\cos(\\omega\\tau)<0$ and $\\omega, \\beta, n_{\\mathrm{crit}}>0$ implies $\\sin(\\omega\\tau)>0$.\nWe can find the relationship between $\\omega$ and $\\tau$ by dividing the two equations:\n$$ \\tan(\\omega\\tau) = \\frac{\\sin(\\omega\\tau)}{\\cos(\\omega\\tau)} = \\frac{2\\omega/(n_{\\mathrm{crit}}\\beta)}{-2/n_{\\mathrm{crit}}} = -\\frac{\\omega}{\\beta} $$\nThis condition is equivalent to the standard phase condition for delayed negative feedback, $\\omega\\tau + \\arctan(\\omega/\\beta) = \\pi$.\nWe are given the specific delay $\\tau = \\frac{3\\pi}{4\\beta}$. Substituting this into the phase condition $\\tan(\\omega\\tau) = -\\omega/\\beta$:\n$$ \\tan\\left(\\omega \\frac{3\\pi}{4\\beta}\\right) = -\\frac{\\omega}{\\beta} $$\nLet $u = \\omega/\\beta$. The equation becomes a transcendental equation for the dimensionless frequency $u$:\n$$ \\tan\\left(\\frac{3\\pi}{4}u\\right) = -u $$\nWe can find the solution by inspection. Let's test $u=1$:\nLHS: $\\tan\\left(\\frac{3\\pi}{4} \\cdot 1\\right) = \\tan\\left(\\frac{3\\pi}{4}\\right) = -1$.\nRHS: $-1$.\nSince LHS = RHS, $u=1$ is a solution. The function $g(u) = \\tan(\\frac{3\\pi}{4}u) + u$ is strictly increasing in the relevant interval, so this solution is unique.\nThus, the critical frequency of oscillation is $\\omega = 1 \\cdot \\beta = \\beta$.\n\nNow we find $n_{\\mathrm{crit}}$ using the identity $\\sin^2(\\theta) + \\cos^2(\\theta) = 1$:\n$$ \\left(\\frac{2\\omega}{n_{\\mathrm{crit}}\\beta}\\right)^2 + \\left(-\\frac{2}{n_{\\mathrm{crit}}}\\right)^2 = 1 $$\n$$ \\frac{4\\omega^2}{n_{\\mathrm{crit}}^2\\beta^2} + \\frac{4}{n_{\\mathrm{crit}}^2} = 1 $$\n$$ 4\\left(\\frac{\\omega^2}{\\beta^2} + 1\\right) = n_{\\mathrm{crit}}^2 $$\nSubstituting the critical frequency $\\omega=\\beta$:\n$$ n_{\\mathrm{crit}}^2 = 4\\left(\\frac{\\beta^2}{\\beta^2} + 1\\right) = 4(1+1) = 8 $$\nSince the Hill coefficient $n$ must be positive, we take the positive root:\n$$ n_{\\mathrm{crit}} = \\sqrt{8} = 2\\sqrt{2} $$",
            "answer": "$$\\boxed{2\\sqrt{2}}$$"
        },
        {
            "introduction": "Biological systems often achieve remarkable robustness by combining simple motifs into more complex circuits. This practice explores how an incoherent feed-forward loop (IFFL) can work in concert with a negative feedback loop to produce perfect adaptation, allowing a system's output to return to its pre-stimulus level despite sustained changes in input. You will combine analytical derivation with numerical simulation to uncover the tuning conditions required for this sophisticated function, gaining insight into the principles of modular design in regulatory networks .",
            "id": "3345735",
            "problem": "Consider a minimal dynamical model of a gene-regulatory module that combines a saturating negative feedback loop with an incoherent feed-forward loop. The system receives an external input signal $u(t)$ and produces an output $y(t)$. The negative feedback is mediated by an intermediate $x(t)$, and the incoherent feed-forward inhibition is mediated by an intermediate $w(t)$. Assume all regulations are well-described by Hill-type saturation functions and that the dynamics are governed by ordinary differential equations (ODEs), a foundational framework for chemical reaction kinetics under the law of mass action.\n\nThe model is given by the following three coupled ODEs:\n$$\n\\frac{dy}{dt} \\;=\\; \\frac{k_y \\, A(u)}{\\left(1 + \\left(\\frac{x}{K_x}\\right)^n\\right)\\left(1 + \\left(\\frac{w}{K_{\\mathrm{inh}}}\\right)^q\\right)} \\;-\\; \\gamma_y \\, y,\n$$\n$$\n\\frac{dx}{dt} \\;=\\; k_x \\, B(y) \\;-\\; \\gamma_x \\, x,\n$$\n$$\n\\frac{dw}{dt} \\;=\\; k_w \\, H(u) \\;-\\; \\gamma_w \\, w,\n$$\nwhere $A(u)$ is the activation of $y$ by the input $u$, $B(y)$ is the activation of the feedback mediator $x$ by the output $y$, and $H(u)$ is the feed-forward activation of the inhibitor $w$ by the input $u$. The functions $A$, $B$, and $H$ are defined via Hill functions:\n$$\nh(z;K,p) \\;=\\; \\frac{z^p}{K^p + z^p},\n$$\n$$\nA(u) \\;=\\; A_0 \\;+\\; V_a \\, h(u;K_a,p_a), \\quad B(y) \\;=\\; h(y;K_b,m), \\quad H(u) \\;=\\; h(u;K_f,p_f),\n$$\nwith positive parameters $A_0$, $V_a$, $K_a$, $p_a$, $K_b$, $m$, $K_f$, and $p_f$. The feedback nonlinearity exponent is $n > 0$, and the feed-forward inhibition exponent is $q > 0$. All rate constants $k_y$, $k_x$, $k_w$ and degradation rates $\\gamma_y$, $\\gamma_x$, $\\gamma_w$ are positive. The parameter $K_{\\mathrm{inh}} > 0$ scales the feed-forward inhibition.\n\nAssume the input $u(t)$ is a step signal:\n$$\nu(t) \\;=\\; \\begin{cases}\nu_0, & t < 0, \\\\\nu_1 \\;=\\; u_0 + \\Delta u, & t \\ge 0,\n\\end{cases}\n$$\nwith $u_0 > 0$ and $\\Delta u > 0$. Define the steady-state output $y_{\\mathrm{ss}}(u)$ as the unique root of the steady-state equation obtained by setting $\\frac{dy}{dt} = 0$, $\\frac{dx}{dt} = 0$, and $\\frac{dw}{dt} = 0$ under fixed $u$. Because the intermediates relax to steady state as functions of $y$ and $u$, the steady-state condition for $y$ can be written as a scalar implicit equation:\n$$\nF(y,u) \\;\\equiv\\; \\gamma_y \\, y \\;-\\; \\frac{k_y \\, A(u)}{\\left(1 + \\phi(y)\\right)\\left(1 + \\psi(u)\\right)} \\;=\\; 0,\n$$\nwhere\n$$\n\\phi(y) \\;=\\; \\left(\\frac{\\frac{k_x}{\\gamma_x} \\, B(y)}{K_x}\\right)^{n}, \\qquad \\psi(u) \\;=\\; \\left(\\frac{\\frac{k_w}{\\gamma_w} \\, H(u)}{K_{\\mathrm{inh}}}\\right)^{q}.\n$$\n\nDefine perfect adaptation for a step perturbation as $y_{\\mathrm{ss}}(u_1) \\;=\\; y_{\\mathrm{ss}}(u_0)$. In practice, with saturating feedback, perfect adaptation may fail; however, incoherent feed-forward can compensate near a reference input $u_0$ if properly tuned. The objective is to determine whether the incoherent feed-forward motif can counteract the nonlinearities that break perfect adaptation under saturating feedback, and to derive approximate linearization conditions around $u_0$ under which the combined motifs restore adaptation to first order.\n\nTasks:\n- Using only core definitions of steady state ($\\frac{dy}{dt}=\\frac{dx}{dt}=\\frac{dw}{dt}=0$), the implicit function theorem, and small-signal linearization principles, derive the approximate condition at $u_0$ that ensures the first-order sensitivity $\\frac{d y_{\\mathrm{ss}}}{d u}\\big|_{u_0}$ vanishes when the incoherent feed-forward motif is present. Express this condition in terms of $A(u)$, $\\psi(u)$, and their derivatives with respect to $u$ evaluated at $u_0$, without assuming any special form beyond the Hill-function definitions given above. Do not provide any shortcut formulas in the problem statement; the derivation must start from $F(y,u)=0$ and proceed from first principles.\n- Implement a program that, given parameter values, computes $y_{\\mathrm{ss}}(u)$ by solving $F(y,u)=0$ numerically for each fixed $u$. Use the relation $x_{\\mathrm{ss}}(y) \\;=\\; \\frac{k_x}{\\gamma_x} B(y)$ and $w_{\\mathrm{ss}}(u) \\;=\\; \\frac{k_w}{\\gamma_w} H(u)$ when evaluating $\\phi(y)$ and $\\psi(u)$. Your numerical solution must find the physically relevant nonnegative steady state $y_{\\mathrm{ss}}(u) \\ge 0$.\n- Using the derived linearization condition at $u_0$, define the feed-forward inhibition scaling parameter $c$ by setting $q = 1$ and expressing $\\psi(u)$ as $\\psi(u) \\;=\\; c \\, H(u)$; then set $K_{\\mathrm{inh}}$ such that $c \\;=\\; \\left(\\frac{k_w}{\\gamma_w}\\right)\\big/ K_{\\mathrm{inh}}$. For test cases that call for tuning, choose $c$ to satisfy the derived condition at $u_0$. For untuned cases, set $c$ to a specified value.\n- For each test case, compute the normalized adaptation error\n$$\n\\varepsilon \\;=\\; \\frac{y_{\\mathrm{ss}}(u_1) - y_{\\mathrm{ss}}(u_0)}{y_{\\mathrm{ss}}(u_0)},\n$$\nexpressed as a decimal number. Also compute the linearization mismatch at $u_0$,\n$$\n\\delta \\;=\\; \\left.\\left(\\frac{d}{du} \\ln A(u) - \\frac{d}{du} \\ln\\left(1 + \\psi(u)\\right)\\right)\\right|_{u = u_0},\n$$\nexpressed as a decimal number.\n\nYour program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element of the list must be a two-element list of floats $[\\varepsilon, \\delta]$ corresponding to a test case. For example, the output must look like $[[\\varepsilon_1,\\delta_1],[\\varepsilon_2,\\delta_2],\\dots]$.\n\nUse the following parameter values for all test cases unless otherwise specified:\n- $k_y = 2.0$, $\\gamma_y = 1.0$, $A_0 = 0.2$, $V_a = 1.0$, $K_a = 1.0$, $p_a = 2$.\n- $k_x = 1.0$, $\\gamma_x = 1.0$, $K_b = 0.5$, $m = 2$, $K_x = 0.6$, $n = 2$.\n- $k_w = 1.0$, $\\gamma_w = 1.0$, $K_f = 1.0$, $p_f = 2$.\n- Set $q = 1$ and $\\psi(u) = c \\, H(u)$ for all test cases.\n\nDefine the test suite as follows:\n- Test case $1$ (happy path near $u_0$): $u_0 = 0.8$, $\\Delta u = 0.4$, choose $c$ to satisfy the linearization condition at $u_0$.\n- Test case $2$ (no feed-forward): $u_0 = 0.8$, $\\Delta u = 0.4$, set $c = 0.0$.\n- Test case $3$ (overcompensation): $u_0 = 0.8$, $\\Delta u = 0.4$, set $c$ to exactly twice the value used in Test case $1$.\n- Test case $4$ (low-input linear regime, tuned): $u_0 = 0.2$, $\\Delta u = 0.05$, choose $c$ to satisfy the linearization condition at $u_0$.\n- Test case $5$ (high-input saturation, untuned): $u_0 = 5.0$, $\\Delta u = 1.0$, set $c = 0.0$.\n\nAll quantities are dimensionless; no physical units are required. Angles do not appear. Percentages must be expressed as decimals.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the two-float list $[\\varepsilon,\\delta]$ for the corresponding test case, in the order given above.",
            "solution": "The problem requires the derivation of a condition for first-order perfect adaptation in a combined negative feedback and incoherent feed-forward gene regulatory circuit. This condition will then be used to numerically evaluate the system's performance. The derivation must proceed from first principles, namely the steady-state condition and the implicit function theorem.\n\nThe steady-state behavior of the system is governed by the implicit equation $F(y, u) = 0$, where $y$ represents the steady-state output $y_{\\mathrm{ss}}(u)$ for a given input $u$. The equation is:\n$$\nF(y, u) = \\gamma_y y - \\frac{k_y A(u)}{(1 + \\phi(y))(1 + \\psi(u))} = 0\n$$\nHere, $y$ is an implicit function of $u$. To find the sensitivity of the output $y$ with respect to the input $u$, we compute the total derivative of $F$ with respect to $u$:\n$$\n\\frac{dF}{du} = \\frac{\\partial F}{\\partial y} \\frac{dy}{du} + \\frac{\\partial F}{\\partial u} = 0\n$$\nBy the implicit function theorem, the derivative $\\frac{dy}{du}$ is given by:\n$$\n\\frac{dy}{du} = - \\frac{\\partial F / \\partial u}{\\partial F / \\partial y}\n$$\nThe condition for perfect adaptation to first order at a reference input $u_0$ is that the sensitivity vanishes, i.e., $\\frac{dy}{du}\\big|_{u=u_0} = 0$. This requires the numerator of the expression to be zero, provided the denominator is non-zero.\n\nFirst, let us analyze the denominator, $\\frac{\\partial F}{\\partial y}$:\n$$\n\\frac{\\partial F}{\\partial y} = \\frac{\\partial}{\\partial y} \\left( \\gamma_y y - \\frac{k_y A(u)}{(1 + \\phi(y))(1 + \\psi(u))} \\right) = \\gamma_y - \\frac{k_y A(u)}{1 + \\psi(u)} \\frac{\\partial}{\\partial y} \\left( \\frac{1}{1 + \\phi(y)} \\right)\n$$\n$$\n\\frac{\\partial F}{\\partial y} = \\gamma_y + \\frac{k_y A(u)}{1 + \\psi(u)} \\frac{\\phi'(y)}{(1 + \\phi(y))^2}\n$$\nGiven that all parameters and state variables ($y$) are non-negative, and the Hill function $B(y)$ is a monotonically increasing function of $y$, its derivative, and consequently $\\phi'(y)$, are non-negative. Since all rate constants and concentrations are positive, it follows that $\\frac{\\partial F}{\\partial y} > 0$. Therefore, the denominator is non-zero, and the condition for first-order adaptation simplifies to $\\frac{\\partial F}{\\partial u} = 0$ evaluated at $(y_0, u_0)$, where $y_0 = y_{\\mathrm{ss}}(u_0)$.\n\nNext, we compute the numerator, $\\frac{\\partial F}{\\partial u}$:\n$$\n\\frac{\\partial F}{\\partial u} = \\frac{\\partial}{\\partial u} \\left( \\gamma_y y - \\frac{k_y A(u)}{(1 + \\phi(y))(1 + \\psi(u))} \\right)\n$$\nTreating $y$ as a constant during partial differentiation, we get:\n$$\n\\frac{\\partial F}{\\partial u} = - \\frac{k_y}{1 + \\phi(y)} \\frac{\\partial}{\\partial u} \\left( \\frac{A(u)}{1 + \\psi(u)} \\right)\n$$\nUsing the quotient rule for the derivative term:\n$$\n\\frac{\\partial}{\\partial u} \\left( \\frac{A(u)}{1 + \\psi(u)} \\right) = \\frac{A'(u)(1 + \\psi(u)) - A(u)\\psi'(u)}{(1 + \\psi(u))^2}\n$$\nwhere primes denote differentiation with respect to $u$. Setting $\\frac{\\partial F}{\\partial u} = 0$ requires the numerator of this expression to be zero:\n$$\nA'(u)(1 + \\psi(u)) - A(u)\\psi'(u) = 0\n$$\nAssuming $A(u) > 0$ and $1 + \\psi(u) > 0$, which holds for the given model, we can divide by $A(u)(1 + \\psi(u))$ to obtain:\n$$\n\\frac{A'(u)}{A(u)} - \\frac{\\psi'(u)}{1 + \\psi(u)} = 0\n$$\nThis expression can be written using logarithmic derivatives:\n$$\n\\frac{d}{du} \\ln\\left(A(u)\\right) = \\frac{d}{du} \\ln\\left(1 + \\psi(u)\\right)\n$$\nThis is the required first-order condition for perfect adaptation, derived from first principles. It states that for adaptation to occur, the relative sensitivity of the activation function $A(u)$ must be exactly balanced by the relative sensitivity of the feed-forward inhibitory term $(1 + \\psi(u))$.\n\nFor the implementation, we set $q=1$ and define $\\psi(u) = c H(u)$. The condition becomes:\n$$\n\\frac{A'(u_0)}{A(u_0)} = \\frac{c H'(u_0)}{1 + c H(u_0)}\n$$\nSolving for the tuning parameter $c$ yields:\n$$\nA'(u_0)(1 + c H(u_0)) = c A(u_0) H'(u_0) \\implies A'(u_0) = c (A(u_0) H'(u_0) - A'(u_0) H(u_0))\n$$\n$$\nc = \\frac{A'(u_0)}{A(u_0) H'(u_0) - A'(u_0) H(u_0)}\n$$\nThis formula is used to calculate $c$ for the tuned test cases.\n\nThe numerical procedure involves:\n1.  For a given input $u$ and parameter set (including $c$), find the steady-state output $y_{\\mathrm{ss}}(u)$ by numerically solving the root problem $F(y, u, c)=0$ using a robust method such as Brent's method, as the function $F$ is monotonic in $y$.\n2.  Compute the adaptation error $\\varepsilon = (y_{\\mathrm{ss}}(u_1) - y_{\\mathrm{ss}}(u_0)) / y_{\\mathrm{ss}}(u_0)$.\n3.  Compute the linearization mismatch at $u_0$, $\\delta = \\frac{A'(u_0)}{A(u_0)} - \\frac{c H'(u_0)}{1 + c H(u_0)}$. For tuned cases, $\\delta$ is zero by construction. For other cases, its value quantifies the deviation from the ideal adaptation condition.\n\nThese steps are implemented in the provided Python code to evaluate the system's behavior across the specified test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Solves the gene-regulatory model problem by deriving and applying a condition\n    for first-order perfect adaptation. It computes adaptation error and linearization\n    mismatch for several test cases.\n    \"\"\"\n    \n    # Define the common parameter set as a dictionary.\n    params = {\n        'k_y': 2.0, 'gamma_y': 1.0, 'A0': 0.2, 'Va': 1.0, 'Ka': 1.0, 'pa': 2,\n        'k_x': 1.0, 'gamma_x': 1.0, 'Kb': 0.5, 'm': 2, 'Kx': 0.6, 'n': 2,\n        'k_w': 1.0, 'gamma_w': 1.0, 'Kf': 1.0, 'pf': 2,\n        'q': 1 # Fixed as per problem statement\n    }\n\n    # --- Helper Functions ---\n\n    def h(z, K, p):\n        \"\"\"Hill function.\"\"\"\n        if z < 0: return 0.0\n        z_p = z**p\n        K_p = K**p\n        return z_p / (K_p + z_p)\n\n    def A(u, p):\n        \"\"\"Activation function for y.\"\"\"\n        return p['A0'] + p['Va'] * h(u, p['Ka'], p['pa'])\n\n    def A_prime(u, p):\n        \"\"\"Derivative of A(u) with respect to u.\"\"\"\n        if u <= 0: return 0.0\n        num = p['Va'] * p['pa'] * u**(p['pa'] - 1) * p['Ka']**p['pa']\n        den = (p['Ka']**p['pa'] + u**p['pa'])**2\n        return num / den\n\n    def B(y, p):\n        \"\"\"Activation function for x.\"\"\"\n        return h(y, p['Kb'], p['m'])\n\n    def H(u, p):\n        \"\"\"Activation function for w.\"\"\"\n        return h(u, p['Kf'], p['pf'])\n\n    def H_prime(u, p):\n        \"\"\"Derivative of H(u) with respect to u.\"\"\"\n        if u <= 0: return 0.0\n        num = p['pf'] * u**(p['pf'] - 1) * p['Kf']**p['pf']\n        den = (p['Kf']**p['pf'] + u**p['pf'])**2\n        return num / den\n\n    def phi(y, p):\n        \"\"\"Feedback term.\"\"\"\n        val = (p['k_x'] / p['gamma_x'] * B(y, p)) / p['Kx']\n        return val**p['n']\n\n    def psi(u, c, p):\n        \"\"\"Feed-forward term.\"\"\"\n        return c * H(u, p)\n\n    def steady_state_func(y, u, c, p):\n        \"\"\"The function F(y,u)=0 to find the steady-state root y_ss.\"\"\"\n        if y < 0: return -1e9 # Ensure physical domain\n        term1 = p['gamma_y'] * y\n        term2_num = p['k_y'] * A(u, p)\n        term2_den = (1.0 + phi(y, p)) * (1.0 + psi(u, c, p))\n        return term1 - term2_num / term2_den\n    \n    def get_yss(u, c, p):\n        \"\"\"Numerically solves for the steady-state y at a given u and c.\"\"\"\n        # Find a suitable search interval [y_low, y_high].\n        # F(y) is monotonically increasing. F(0) < 0.\n        y_low = 1e-12\n        # An upper bound for y is k_y*(A0+Va)/gamma_y, roughly 2.4. \n        # A search up to 100.0 is more than safe.\n        y_high = 100.0\n        try:\n            return brentq(steady_state_func, y_low, y_high, args=(u, c, p))\n        except ValueError:\n            # This case should not be reached given the function's properties.\n            return np.nan\n            \n    def get_c_tuned(u0, p):\n        \"\"\"Calculates the c parameter for perfect first-order adaptation at u0.\"\"\"\n        A_u0 = A(u0, p)\n        Ap_u0 = A_prime(u0, p)\n        H_u0 = H(u0, p)\n        Hp_u0 = H_prime(u0, p)\n\n        numerator = Ap_u0\n        denominator = A_u0 * Hp_u0 - Ap_u0 * H_u0\n        \n        if np.abs(denominator) < 1e-15:\n            return np.inf  # or handle as an error\n        return numerator / denominator\n    \n    def calculate_delta(u0, c, p):\n        \"\"\"Calculates the linearization mismatch delta.\"\"\"\n        A_u0 = A(u0, p)\n        Ap_u0 = A_prime(u0, p)\n        H_u0 = H(u0, p)\n        Hp_u0 = H_prime(u0, p)\n\n        term1 = Ap_u0 / A_u0 if A_u0 != 0 else 0\n        term2_num = c * Hp_u0\n        term2_den = 1.0 + c * H_u0\n        term2 = term2_num / term2_den if term2_den != 0 else 0\n        \n        return term1 - term2\n\n    # --- Main Logic ---\n\n    # Pre-calculate tuned c values required by test cases\n    c_tuned_case1 = get_c_tuned(0.8, params)\n    c_tuned_case4 = get_c_tuned(0.2, params)\n\n    test_cases = [\n        # (u0, Delta_u, c_value)\n        (0.8, 0.4, c_tuned_case1),        # Case 1: Tuned\n        (0.8, 0.4, 0.0),                  # Case 2: No FFL\n        (0.8, 0.4, 2.0 * c_tuned_case1),  # Case 3: Overcompensation\n        (0.2, 0.05, c_tuned_case4),       # Case 4: Tuned, low input\n        (5.0, 1.0, 0.0),                  # Case 5: Untuned, high input\n    ]\n\n    results = []\n    for u0, delta_u, c in test_cases:\n        u1 = u0 + delta_u\n        \n        yss_u0 = get_yss(u0, c, params)\n        yss_u1 = get_yss(u1, c, params)\n        \n        # Calculate adaptation error epsilon\n        epsilon = (yss_u1 - yss_u0) / yss_u0 if yss_u0 != 0 else np.inf\n        \n        # Calculate linearization mismatch delta\n        delta = calculate_delta(u0, c, params)\n        \n        results.append([epsilon, delta])\n\n    # Format the final output string exactly as required\n    output_str = \"[\" + \",\".join([f\"[{e},{d}]\" for e, d in results]) + \"]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}