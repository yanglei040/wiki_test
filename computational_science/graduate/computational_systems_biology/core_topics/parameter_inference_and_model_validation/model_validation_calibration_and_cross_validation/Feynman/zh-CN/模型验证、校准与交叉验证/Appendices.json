{
    "hands_on_practices": [
        {
            "introduction": "任何模型构建过程的核心步骤都是验证：将模型预测与实验数据进行比较。然而，仅仅目视检查是不够的，我们需要可量化的指标来客观评估模型的性能。这项练习将引导您计算和比较三种广泛使用的验证指标——均方根误差（RMSE）、平均绝对误差（MAE）和时间平均对数评分（time-averaged log score），以评估一个振荡系统的动态模型。通过这项实践，您将亲身体验这些指标如何捕捉模型误差的不同方面，并理解它们在面对模型不确定性和结构性偏差时的各自优势与局限性 。",
            "id": "3327278",
            "problem": "您的任务是，在已知相位移和预测不确定性的情况下，根据观测数据对一个模拟的细胞因子时程模型进行定量验证，并分析不同性能指标的鲁棒性。考虑一个由振荡调控网络生成的单一细胞因子轨迹，在没有噪声的情况下，该轨迹可以用一条正弦平均轨迹来表示。设确定性平均轨迹为 $y_{\\mathrm{true}}(t) = B + A \\sin(\\omega t)$，其中时间 $t \\ge 0$，振幅为 $A$，基线水平为 $B$，角频率为 $\\omega$。观测数据在离散时间点 $t_k = k \\Delta t$（其中 $k \\in \\{0,1,\\dots,T-1\\}$，步长 $\\Delta t$ 固定）上收集。观测数据为 $y_{\\mathrm{obs}}(t_k) = y_{\\mathrm{true}}(t_k) + \\varepsilon_k$，其中 $\\varepsilon_k$ 是独立同分布的高斯扰动，其均值为零，方差为 $\\sigma_{\\mathrm{obs}}^2$。模拟器输出一个相移平均轨迹 $y_{\\mathrm{sim}}(t_k;\\phi) = B + A \\sin(\\omega t_k + \\phi)$，其中 $\\phi$ 是一个相位移。假设模拟器在时间 $t_k$ 的预测分布是单变量正态分布，其均值为 $y_{\\mathrm{sim}}(t_k;\\phi)$，标准差为 $\\sigma_{\\mathrm{pred}}$；即 $y \\mid t_k \\sim \\mathcal{N}(y_{\\mathrm{sim}}(t_k;\\phi), \\sigma_{\\mathrm{pred}}^2)$。角度必须以弧度为单位。\n\n您的程序必须执行以下操作：\n- 使用种子固定为 $314159$ 的伪随机数生成器，通过采样 $\\varepsilon_k \\sim \\mathcal{N}(0,\\sigma_{\\mathrm{obs}}^2)$ 来生成观测轨迹，以确保结果可复现。\n- 对于每个指定的测试用例，在指定的时间索引子集 $k$ 上计算 $y_{\\mathrm{sim}}(t_k;\\phi)$ 和 $y_{\\mathrm{obs}}(t_k)$ 之间的以下指标：\n  1. 均方根误差 (RMSE)：平方误差均值的平方根。\n  2. 平均绝对误差 (MAE)：绝对误差的均值。\n  3. 时间平均对数得分：在选定的时间索引上，基于均值为 $y_{\\mathrm{sim}}(t_k;\\phi)$、标准差为 $\\sigma_{\\mathrm{pred}}$ 的正态模型，其对数预测密度的经验平均值。\n\n使用以下固定设置生成数据：\n- 振幅 $A = 2.0$。\n- 基线 $B = 5.0$。\n- 角频率 $\\omega = 1.0$。\n- 时间步长 $\\Delta t = 0.05$。\n- 时间点数量 $T = 200$。\n- 观测噪声标准差 $\\sigma_{\\mathrm{obs}} = 0.5$。\n- 用于生成 $\\{\\varepsilon_k\\}_{k=0}^{T-1}$ 的随机种子 $314159$。\n\n角度以弧度为单位。本问题中细胞因子浓度没有物理单位，角度必须以弧度处理。不允许使用度数。\n\n测试套件（每个测试用例是一个三元组 $(\\phi, \\sigma_{\\mathrm{pred}}, \\mathcal{K})$，其中 $\\mathcal{K}$ 是要包含的索引子集）：\n- 用例 1：$\\phi = 0.0$, $\\sigma_{\\mathrm{pred}} = 0.5$, $\\mathcal{K} = \\{0,1,\\dots,T-1\\}$ (所有索引)。\n- 用例 2：$\\phi = 0.2$, $\\sigma_{\\mathrm{pred}} = 0.5$, $\\mathcal{K} = \\{0,1,\\dots,T-1\\}$。\n- 用例 3：$\\phi = \\pi$, $\\sigma_{\\mathrm{pred}} = 0.5$, $\\mathcal{K} = \\{0,1,\\dots,T-1\\}$。\n- 用例 4：$\\phi = 0.2$, $\\sigma_{\\mathrm{pred}} = 2.0$, $\\mathcal{K} = \\{0,1,\\dots,T-1\\}$。\n- 用例 5：$\\phi = 0.2$, $\\sigma_{\\mathrm{pred}} = 0.1$, $\\mathcal{K} = \\{0,1,\\dots,T-1\\}$。\n- 用例 6：$\\phi = 0.2$, $\\sigma_{\\mathrm{pred}} = 0.5$, $\\mathcal{K} = \\{0,1,2,3,4\\}$ (仅前五个索引)。\n\n实现说明和要求：\n- 角度必须以弧度为单位。\n- 对于每个用例，仅在指定的索引集 $\\mathcal{K}$ 上计算三个指标。\n- 将每个指标报告为四舍五入到 $6$ 位小数的浮点数。\n- 最终程序输出必须是单行，包含一个长度为 $6$ 的列表，其中每个元素是长度为 $3$ 的列表，对应于相应测试用例的 $\\left[\\mathrm{RMSE}, \\mathrm{MAE}, \\mathrm{AvgLogScore}\\right]$，顺序与上文相同。\n\n您可以无需进一步论证即可使用的基本依据包括：正态分布的性质、绝对值和平方误差的定义，以及经验均值的定义。您必须将时间平均对数得分视为在均值为 $y_{\\mathrm{sim}}(t_k;\\phi)$、标准差为 $\\sigma_{\\mathrm{pred}}$ 的正态模型下，于 $y_{\\mathrm{obs}}(t_k)$ 处评估的对数预测密度的经验平均值。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如，$\\left[\\left[\\cdot,\\cdot,\\cdot\\right],\\dots\\right]$）。",
            "solution": "问题陈述已经过分析，被认为是有效的。它在科学上基于计算建模和统计模型验证的原则，其参数和定义完整且一致，问题提法适定，并且其表述是客观的。可以计算出唯一且可验证的解。\n\n任务是计算三个性能指标（均方根误差、平均绝对误差和时间平均对数得分），以评估一个模拟时间序列模型相对于综合生成的观测轨迹的表现。整个过程分为两个主要阶段：数据生成和指标计算。\n\n首先，我们生成“观测”数据。此操作只执行一次，所有测试用例都使用相同的数据，以确保公平比较。\n离散时间点由 $t_k = k \\Delta t$ 给出，其中 $k \\in \\{0, 1, \\dots, T-1\\}$，点数为 $T=200$，时间步长为 $\\Delta t = 0.05$。\n真实的、无噪声的基础轨迹是一个正弦曲线：\n$$ y_{\\mathrm{true}}(t_k) = B + A \\sin(\\omega t_k) $$\n振幅 $A=2.0$，基线 $B=5.0$，角频率 $\\omega=1.0$。\n观测数据 $y_{\\mathrm{obs}}(t_k)$ 是通过向该真实轨迹添加高斯噪声生成的：\n$$ y_{\\mathrm{obs}}(t_k) = y_{\\mathrm{true}}(t_k) + \\varepsilon_k $$\n其中 $\\varepsilon_k$ 是从均值为 $0$、标准差为 $\\sigma_{\\mathrm{obs}}=0.5$ 的正态分布中抽取的独立同分布随机变量。即 $\\varepsilon_k \\sim \\mathcal{N}(0, \\sigma_{\\mathrm{obs}}^2)$。序列 $\\{\\varepsilon_k\\}_{k=0}^{T-1}$ 的生成是使用一个以固定种子 $314159$ 初始化的伪随机数生成器来执行的，以确保可复现性。\n\n其次，对于指定的六个测试用例中的每一个，我们计算验证指标。一个测试用例由一个三元组 $(\\phi, \\sigma_{\\mathrm{pred}}, \\mathcal{K})$ 定义，其中 $\\phi$ 是模拟器中的相位移，$\\sigma_{\\mathrm{pred}}$ 是模拟器预测分布的标准差，$\\mathcal{K}$ 是计算指标所依据的时间索引子集。\n\n对于给定的相位移 $\\phi$，模拟轨迹为：\n$$ y_{\\mathrm{sim}}(t_k; \\phi) = B + A \\sin(\\omega t_k + \\phi) $$\n对于索引 $k \\in \\mathcal{K}$ 的每个时间点 $t_k$，误差定义为观测值与模拟值之差：\n$$ e_k = y_{\\mathrm{obs}}(t_k) - y_{\\mathrm{sim}}(t_k; \\phi) $$\n令 $N_{\\mathcal{K}} = |\\mathcal{K}|$ 为集合 $\\mathcal{K}$ 中的索引数量。三个指标计算如下：\n\n1.  **均方根误差 (RMSE)**：该指标衡量的是平均平方误差的平方根。\n    $$ \\mathrm{RMSE} = \\sqrt{\\frac{1}{N_{\\mathcal{K}}} \\sum_{k \\in \\mathcal{K}} e_k^2} $$\n\n2.  **平均绝对误差 (MAE)**：该指标衡量的是平均绝对误差。\n    $$ \\mathrm{MAE} = \\frac{1}{N_{\\mathcal{K}}} \\sum_{k \\in \\mathcal{K}} |e_k| $$\n\n3.  **时间平均对数得分**：这是一种评估概率性预测质量的适宜评分规则。它是对数预测概率密度的经验平均值。预测分布为 $\\mathcal{N}(y_{\\mathrm{sim}}(t_k; \\phi), \\sigma_{\\mathrm{pred}}^2)$。正态分布的概率密度函数为 $p(y; \\mu, \\sigma^2) = (2\\pi\\sigma^2)^{-1/2} \\exp(-(y-\\mu)^2 / (2\\sigma^2))$。在观测值 $y_{\\mathrm{obs}}(t_k)$ 处评估的对数密度为：\n    $$ \\log p(y_{\\mathrm{obs}}(t_k)) = \\log \\left( \\frac{1}{\\sqrt{2\\pi\\sigma_{\\mathrm{pred}}^2}} \\exp\\left(-\\frac{(y_{\\mathrm{obs}}(t_k) - y_{\\mathrm{sim}}(t_k; \\phi))^2}{2\\sigma_{\\mathrm{pred}}^2}\\right) \\right) $$\n    $$ = -\\frac{1}{2}\\log(2\\pi\\sigma_{\\mathrm{pred}}^2) - \\frac{e_k^2}{2\\sigma_{\\mathrm{pred}}^2} = -\\log(\\sigma_{\\mathrm{pred}}) - \\frac{1}{2}\\log(2\\pi) - \\frac{e_k^2}{2\\sigma_{\\mathrm{pred}}^2} $$\n    时间平均对数得分是这些值在索引集 $\\mathcal{K}$ 上的均值：\n    $$ \\mathrm{AvgLogScore} = \\frac{1}{N_{\\mathcal{K}}} \\sum_{k \\in \\mathcal{K}} \\left( -\\log(\\sigma_{\\mathrm{pred}}) - \\frac{1}{2}\\log(2\\pi) - \\frac{e_k^2}{2\\sigma_{\\mathrm{pred}}^2} \\right) $$\n    这可以通过提取常数项并识别均方误差 (MSE) 来简化，$\\mathrm{MSE} = \\frac{1}{N_{\\mathcal{K}}} \\sum_{k \\in \\mathcal{K}} e_k^2 = \\mathrm{RMSE}^2$：\n    $$ \\mathrm{AvgLogScore} = -\\log(\\sigma_{\\mathrm{pred}}) - \\frac{1}{2}\\log(2\\pi) - \\frac{\\mathrm{MSE}}{2\\sigma_{\\mathrm{pred}}^2} $$\n\n对于每个测试用例，程序将首先根据 $\\mathcal{K}$ 选择 $y_{\\mathrm{obs}}$ 和 $t$ 的相关子集，然后计算 $y_{\\mathrm{sim}}$，最后使用上述公式计算三个指标。每个得到的指标都四舍五入到 $6$ 位小数。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    # Fixed settings for data generation\n    A = 2.0\n    B = 5.0\n    omega = 1.0\n    delta_t = 0.05\n    T = 200\n    sigma_obs = 0.5\n    seed = 314159\n\n    # Generate the time vector\n    t = np.arange(T) * delta_t\n\n    # Generate the true trajectory\n    y_true = B + A * np.sin(omega * t)\n\n    # Generate the observed trajectory with reproducible noise\n    rng = np.random.default_rng(seed)\n    noise = rng.normal(loc=0.0, scale=sigma_obs, size=T)\n    y_obs = y_true + noise\n\n    # Define the test suite\n    test_cases = [\n        {'phi': 0.0, 'sigma_pred': 0.5, 'K': range(T)},\n        {'phi': 0.2, 'sigma_pred': 0.5, 'K': range(T)},\n        {'phi': np.pi, 'sigma_pred': 0.5, 'K': range(T)},\n        {'phi': 0.2, 'sigma_pred': 2.0, 'K': range(T)},\n        {'phi': 0.2, 'sigma_pred': 0.1, 'K': range(T)},\n        {'phi': 0.2, 'sigma_pred': 0.5, 'K': range(T)[0:5]}\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        phi = case['phi']\n        sigma_pred = case['sigma_pred']\n        # Convert K (which might be a range) to a list of indices for slicing\n        k_indices = np.array(list(case['K']))\n\n        # Select the subset of data based on indices in K\n        t_subset = t[k_indices]\n        y_obs_subset = y_obs[k_indices]\n\n        # Generate the simulated trajectory for the subset\n        y_sim_subset = B + A * np.sin(omega * t_subset + phi)\n\n        # Calculate errors\n        errors = y_obs_subset - y_sim_subset\n\n        # 1. Root Mean Squared Error (RMSE)\n        mse = np.mean(errors**2)\n        rmse = np.sqrt(mse)\n\n        # 2. Mean Absolute Error (MAE)\n        mae = np.mean(np.abs(errors))\n\n        # 3. Time-averaged log score\n        # AvgLogScore = -log(sigma_pred) - 0.5*log(2*pi) - MSE/(2*sigma_pred^2)\n        log_score_term1 = -np.log(sigma_pred)\n        log_score_term2 = -0.5 * np.log(2 * np.pi)\n        log_score_term3 = -mse / (2 * sigma_pred**2)\n        avg_log_score = log_score_term1 + log_score_term2 + log_score_term3\n\n        # Store rounded results\n        case_results = [\n            round(rmse, 6),\n            round(mae, 6),\n            round(avg_log_score, 6)\n        ]\n        all_results.append(case_results)\n\n    # Format the final output string as [[r1,r2,r3],[r1,r2,r3],...]\n    # Using str() on a list adds spaces, so we build the string manually.\n    sublist_strs = []\n    for res_list in all_results:\n        # Format each sublist as \"[v1,v2,v3]\" without spaces\n        sublist_str = f\"[{res_list[0]},{res_list[1]},{res_list[2]}]\"\n        sublist_strs.append(sublist_str)\n    \n    final_output = f\"[{','.join(sublist_strs)}]\"\n\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "一个经过验证的模型不仅能解释现有数据，更应能指导未来的研究。从被动验证到主动设计，灵敏度分析是连接两者的桥梁，它揭示了模型输出对各个参数的依赖程度。在此练习中，您将为一个信号级联反应的常微分方程（ODE）模型推导并实现前向灵敏度方程。利用计算出的灵敏度，您将学会如何确定哪些参数对模型输出影响最大（参数优先级排序），并应用基于费雪信息矩阵（Fisher Information Matrix）的D-最优设计准则，来挑选最具信息量的实验测量时间点 。",
            "id": "3327223",
            "problem": "给定一个由常微分方程描述的最小机理信号级联，其动力学参数未知。您的任务是从第一性原理推导前向灵敏度方程，为该模型实现这些方程，并使用计算出的局部灵敏度来确定参数的优先级，以及通过信息论准则选择信息丰富的测量时间点以进行参数估计。您编写的程序必须为提供的测试套件计算结果，并按下面指定的格式生成单行聚合输出。\n\n从以下基本基础开始：一个由状态方程 $\\dot{x}(t) = f(x(t), \\theta, t)$ 定义的连续可微动力学系统，其中 $x(t) \\in \\mathbb{R}^{n}$ 是状态向量，$\\theta \\in \\mathbb{R}^{p}$ 是常数参数向量，$f$ 对其参数是平滑的。定义局部前向灵敏度矩阵 $S(t) = \\frac{\\partial x(t)}{\\partial \\theta} \\in \\mathbb{R}^{n \\times p}$ 和模型输出 $y(t) \\in \\mathbb{R}^{m}$，其中 $y(t) = h(x(t), \\theta, t)$ 足够平滑。您可以假设测量值受到独立的、零均值的高斯噪声的干扰，每个输出分量和时间点的方差为 $\\sigma^{2}$，并且在离散测量时间 $\\{t_i\\}_{i=1}^{N}$ 的费雪信息矩阵 (FIM) 由输出灵敏度的外积之和给出，并由噪声方差进行白化。\n\n模型定义。考虑一个具有恒定配体输入的三态受体-激酶-报告基因信号级联。令 $x(t) = [x_{1}(t), x_{2}(t), x_{3}(t)]^{\\top}$ 分别表示配体结合受体分数、活化激酶分数和磷酸化报告基因分数。令总受体、激酶和报告基因的丰度为常数 $R_{\\mathrm{tot}}$、$K_{\\mathrm{tot}}$ 和 $P_{\\mathrm{tot}}$。配体浓度是一个恒定的阶跃输入 $L(t) = L_{0}$。动力学模型为\n$$\n\\begin{aligned}\n\\dot{x}_{1} = k_{\\mathrm{on}}\\,L_{0}\\,\\big(R_{\\mathrm{tot}} - x_{1}\\big) - k_{\\mathrm{off}}\\,x_{1}, \\\\\n\\dot{x}_{2} = k_{1}\\,x_{1}\\,\\big(K_{\\mathrm{tot}} - x_{2}\\big) - k_{2}\\,x_{2}, \\\\\n\\dot{x}_{3} = k_{3}\\,x_{2}\\,\\big(P_{\\mathrm{tot}} - x_{3}\\big) - k_{4}\\,x_{3}.\n\\end{aligned}\n$$\n参数向量为 $\\theta = [k_{\\mathrm{on}}, k_{\\mathrm{off}}, k_{1}, k_{2}, k_{3}, k_{4}]^{\\top}$。初始条件为 $x(0) = [0, 0, 0]^{\\top}$。测量输出为磷酸化报告基因，$y(t) = x_{3}(t)$。\n\n程序中要为每个测试用例实现的任务：\n1. 推导并实现与上述模型相关的前向灵敏度方程 $S(t) = \\frac{\\partial x(t)}{\\partial \\theta}$。使用标准结果，即 $S$ 满足一个线性时变矩阵常微分方程 $\\dot{S}(t) = A(t)\\,S(t) + B(t)$，初始条件为 $S(0) = 0$，其中 $A(t) = \\frac{\\partial f}{\\partial x}(x(t), \\theta, t)$ 和 $B(t) = \\frac{\\partial f}{\\partial \\theta}(x(t), \\theta, t)$，并且 $y(t) = C\\,x(t)$，$C = [0,0,1]$，因此 $\\frac{\\partial y}{\\partial \\theta}(t) = C\\,S(t)$。\n2. 对于给定的候选测量时间集 $\\{t_i\\}$，计算这些时间的局部输出灵敏度 $\\frac{\\partial y}{\\partial \\theta}(t_i)$。\n3. 参数优先级排序：对于指定的参数子集 $\\mathcal{J} \\subset \\{0,1,2,3,4,5\\}$，为每个 $j \\in \\mathcal{J}$ 计算一个白化的无量纲分数，定义为\n$$\n\\mathrm{score}_{j} = \\left( \\sum_{i=1}^{N} \\frac{\\big(\\theta_{j}\\,\\frac{\\partial y}{\\partial \\theta_{j}}(t_{i})\\big)^{2}}{\\sigma^{2}} \\right)^{1/2}.\n$$\n报告具有最大分数的全局索引 $j^{\\star} \\in \\mathcal{J}$（平局时取最小索引）。\n4. 通过 D-最优设计进行时间点选择：对于给定的整数 $K \\ge 1$，从候选集中选择 $K$ 个不同的时间索引，以最大化所选时间上关于参数子集 $\\mathcal{J}$ 的费雪信息矩阵的行列式：\n$$\n\\mathcal{F} = \\sum_{i \\in \\mathcal{I}} \\frac{1}{\\sigma^{2}}\\,g(t_{i})\\,g(t_{i})^{\\top},\n$$\n其中 $g(t_{i}) \\in \\mathbb{R}^{|\\mathcal{J}|}$ 是在时间 $t_{i}$ 处限制于 $\\mathcal{J}$ 的输出灵敏度向量，而 $\\mathcal{I}$ 是所选的索引集，满足 $|\\mathcal{I}| = K$。在最大化行列式的索引集中，返回字典序最靠前的一个（数值比较行列式时使用 $10^{-12}$ 的绝对容差）。如果 $K = 1$ 且 $|\\mathcal{J}| > 1$，行列式为零，因为 $\\mathcal{F}$ 的秩为 1；这是可接受的。如果 $K = 1$ 且 $|\\mathcal{J}| = 1$，行列式等于标量费雪信息。\n\n单位：本问题中所有量均为无量纲，且不涉及角度单位。\n\n数值要求：\n- 使用具有足够严格容差的数值稳定方法对 $x(t)$ 和 $S(t)$ 的增广系统进行积分，以确保可复现性。\n- 在输出中对所有参数和时间点索引使用从零开始的索引。\n\n测试套件。您的程序必须运行以下三个测试用例，计算所需的量，并按规定聚合结果。对于每个用例，$R_{\\mathrm{tot}} = 1.0$，$K_{\\mathrm{tot}} = 1.0$，$P_{\\mathrm{tot}} = 1.0$。\n\n- 测试用例 1（一般信息丰富状态）：\n  - 参数 $\\theta = [1.0, 0.2, 0.5, 0.1, 0.7, 0.1]$。\n  - 配体水平 $L_{0} = 1.0$。\n  - 候选时间 $t_{i}$：从 $0$ 到 $40$ 的网格，步长为 $5$，即 $[0, 5, 10, 15, 20, 25, 30, 35, 40]$。\n  - 参数子集 $\\mathcal{J} = \\{0, 2, 4\\}$（即 $k_{\\mathrm{on}}$, $k_{1}$, $k_{3}$）。\n  - 噪声标准差 $\\sigma = 0.05$。\n  - 通过 D-最优性准则选择 $K = 2$ 个时间点。\n\n- 测试用例 2（晚期、信息贫乏状态）：\n  - 参数 $\\theta = [1.0, 1.5, 0.5, 1.0, 0.7, 1.0]$。\n  - 配体水平 $L_{0} = 1.0$。\n  - 候选时间 $t_{i}$：$[50, 100, 150, 200]$。\n  - 参数子集 $\\mathcal{J} = \\{0, 2\\}$（即 $k_{\\mathrm{on}}$, $k_{1}$）。\n  - 噪声标准差 $\\sigma = 0.05$。\n  - 通过 D-最优性准则选择 $K = 2$ 个时间点。\n\n- 测试用例 3（单参数、单时间选择）：\n  - 参数 $\\theta = [1.0, 0.2, 0.5, 0.1, 0.7, 0.1]$。\n  - 配体水平 $L_{0} = 1.0$。\n  - 候选时间 $t_{i}$：从 $0$ 到 $20$ 的网格，步长为 $2$，即 $[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20]$。\n  - 参数子集 $\\mathcal{J} = \\{4\\}$（即仅 $k_{3}$）。\n  - 噪声标准差 $\\sigma = 0.10$。\n  - 通过 D-最优性准则选择 $K = 1$ 个时间点。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表形式的结果。每个测试用例的结果本身必须是一个包含四个项目的列表：\n- 优先参数索引 $j^{\\star}$（一个整数，从零开始，在全局索引集 $\\{0,1,2,3,4,5\\}$ 中）。\n- 第一个选定时间索引（一个整数，从零开始，在该测试用例的候选时间数组内）。\n- 第二个选定时间索引（一个整数，从零开始，在该测试用例的候选时间数组内）；如果 $K=1$，则将其设置为 $-1$。\n- 所选集合的 D-最优行列式值（一个浮点数）。\n\n因此，程序必须精确打印一行格式如下的内容：\n[[j1,t11,t12,det1],[j2,t21,t22,det2],[j3,t31,t32,det3]]",
            "solution": "该问题是计算系统生物学中一个有效且适定的练习，具体通过前向灵敏度分析解决参数可识别性和最优实验设计问题。它在科学上基于化学动力学和信息论（费雪信息）的原理。该模型虽然简化，但代表了一个经典的信号级联，而所需的任务——推导和积分灵敏度方程、计算参数分数以及执行 D-最优实验设计——是该领域中标准且计算上易于处理的方法。为每个测试用例提供了所有必要的数据和约束，并且没有内部矛盾。\n\n解决方案的步骤如下：\n首先，我们推导局部前向灵敏度的控制方程。其次，我们构建一个增广常微分方程（ODE）系统，该系统将原始模型状态与其灵敏度相结合。第三，我们对该系统进行数值积分，以获得在指定时间点的状态和灵敏度轨迹。第四，使用这些灵敏度，我们基于无量纲灵敏度分数进行参数优先级排序。最后，我们通过最大化费雪信息矩阵（FIM）的行列式来选择最优的测量时间点，这一准则被称为 D-最优设计。\n\n**前向灵敏度方程的推导**\n动力学系统由 $\\dot{x}(t) = f(x(t), \\theta)$ 给出，其中状态向量为 $x(t) = [x_{1}(t), x_{2}(t), x_{3}(t)]^{\\top}$，参数向量为 $\\theta = [k_{\\mathrm{on}}, k_{\\mathrm{off}}, k_{1}, k_{2}, k_{3}, k_{4}]^{\\top}$。向量场 $f$ 为：\n$$\nf(x, \\theta) = \\begin{pmatrix}\n\\theta_0 L_0 (R_{\\text{tot}} - x_1) - \\theta_1 x_1 \\\\\n\\theta_2 x_1 (K_{\\text{tot}} - x_2) - \\theta_3 x_2 \\\\\n\\theta_4 x_2 (P_{\\text{tot}} - x_3) - \\theta_5 x_3\n\\end{pmatrix}\n$$\n灵敏度矩阵 $S(t) = \\frac{\\partial x(t)}{\\partial \\theta} \\in \\mathbb{R}^{3 \\times 6}$ 根据矩阵 ODE $\\dot{S}(t) = A(t)S(t) + B(t)$ 演化，初始条件为 $S(0) = 0$。矩阵 $A(t) = \\frac{\\partial f}{\\partial x}$（雅可比矩阵）和 $B(t) = \\frac{\\partial f}{\\partial \\theta}$ 是状态 $x(t)$ 和参数 $\\theta$ 的函数。\n\n雅可比矩阵 $A(t)$ 计算如下：\n$$\nA(t) = \\frac{\\partial f}{\\partial x} = \\begin{pmatrix}\n-\\theta_0 L_0 - \\theta_1  0  0 \\\\\n\\theta_2(K_{\\text{tot}} - x_2(t))  -\\theta_2 x_1(t) - \\theta_3  0 \\\\\n0  \\theta_4(P_{\\text{tot}} - x_3(t))  -\\theta_4 x_2(t) - \\theta_5\n\\end{pmatrix}\n$$\n参数梯度矩阵 $B(t)$ 是一个 $3 \\times 6$ 矩阵，计算如下：\n$$\nB(t) = \\frac{\\partial f}{\\partial \\theta} = \\begin{pmatrix}\nL_0(R_{\\text{tot}} - x_1)  -x_1  0  0  0  0 \\\\\n0  0  x_1(K_{\\text{tot}} - x_2)  -x_2  0  0 \\\\\n0  0  0  0  x_2(P_{\\text{tot}} - x_3)  -x_3\n\\end{pmatrix}\n$$\n为简洁起见，状态依赖项 $x_i(t)$ 显示时省略了参数。\n\n**数值实现**\n为了同时求解 $x(t)$ 和 $S(t)$，我们构建一个增广状态向量 $z(t) = [x(t)^{\\top}, \\mathrm{vec}(S(t))^{\\top}]^{\\top} \\in \\mathbb{R}^{21}$。这个增广系统 $\\dot{z}(t)$ 的动力学由原始状态方程和灵敏度方程定义。然后，使用高保真积分方案（`scipy.integrate.solve_ivp`，具有严格的容差 $rtol=10^{-8}, atol=10^{-10}$）从初始条件 $z(0) = 0$ 开始对这个包含 $21$ 个 ODE 的系统进行数值求解。在指定的候选时间点 $\\{t_i\\}$ 对解进行评估。输出为 $y(t) = x_{3}(t)$，因此关于参数 $\\theta_j$ 的输出灵敏度由 $\\frac{\\partial y}{\\partial \\theta_j}(t) = S_{3j}(t)$ 给出（对状态 $x_3$ 及其对应的灵敏度行使用基于 1 的索引）。\n\n**参数优先级排序**\n对于指定子集 $\\mathcal{J}$ 中的每个参数 $\\theta_j$，计算一个无量纲分数。该分数量化了参数在所有候选时间点上对测量输出 $y(t)$ 的总体影响，并按参数的标称值和测量噪声进行缩放。公式为：\n$$\n\\mathrm{score}_{j} = \\left( \\sum_{i=1}^{N} \\frac{\\big(\\theta_{j}\\,\\frac{\\partial y}{\\partial \\theta_{j}}(t_{i})\\big)^{2}}{\\sigma^{2}} \\right)^{1/2}\n$$\n产生最高分数的参数 $j^{\\star} \\in \\mathcal{J}$ 被确定为最具影响力的参数，因此是精确估计的优先对象。平局通过选择最小的参数索引来解决。\n\n**D-最优时间点选择**\n目标是选择一个包含 $K$ 个测量时间的子集，这些时间点对参数子集 $\\mathcal{J}$ 提供最大的信息量。我们使用 D-最优性准则，该准则旨在最大化费雪信息矩阵 (FIM) $\\mathcal{F}$ 的行列式。更大的行列式对应于更小体积的参数置信椭球，这意味着更精确的参数估计。对于一个时间索引集 $\\mathcal{I}$，其中 $|\\mathcal{I}|=K$，FIM 为：\n$$\n\\mathcal{F} = \\sum_{i \\in \\mathcal{I}} \\frac{1}{\\sigma^{2}}\\,g(t_{i})\\,g(t_{i})^{\\top}\n$$\n这里，$g(t_i) \\in \\mathbb{R}^{|\\mathcal{J}|}$ 是在时间 $t_i$ 评估的、仅限于 $\\mathcal{J}$ 中参数的输出灵敏度向量。我们对候选集中的所有可能的 $K$ 个时间点组合进行组合搜索。对于每种组合，我们计算 $\\det(\\mathcal{F})$ 并确定产生最大行列式的时间索引集。在所选时间点数 $K$ 小于感兴趣参数数量 $|\\mathcal{J}|$ 的情况下，FIM 将是奇异的，其行列式为零。在这种情况下，选择由平局决胜规则确定，该规则指定选择达到最大行列式值的字典序最靠前的索引集。",
            "answer": "```python\nimport numpy as np\nfrom scipy.integrate import solve_ivp\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Main solver function that processes all test cases and prints the final result.\n    \"\"\"\n    R_TOT, K_TOT, P_TOT = 1.0, 1.0, 1.0\n\n    def augmented_ode(t, z, theta, L0):\n        \"\"\"\n        Defines the augmented ODE system for states (x) and sensitivities (S).\n        z: flattened vector [x1, x2, x3, S11, S12, ..., S36]\n        theta: parameter vector [k_on, k_off, k1, k2, k3, k4]\n        \"\"\"\n        x = z[:3]\n        S = z[3:].reshape((3, 6))\n\n        k_on, k_off, k1, k2, k3, k4 = theta\n\n        # State equations (dx/dt)\n        dx1_dt = k_on * L0 * (R_TOT - x[0]) - k_off * x[0]\n        dx2_dt = k1 * x[0] * (K_TOT - x[1]) - k2 * x[1]\n        dx3_dt = k3 * x[1] * (P_TOT - x[2]) - k4 * x[2]\n        dx_dt = np.array([dx1_dt, dx2_dt, dx3_dt])\n\n        # Jacobian matrix A = df/dx\n        A = np.zeros((3, 3))\n        A[0, 0] = -k_on * L0 - k_off\n        A[1, 0] = k1 * (K_TOT - x[1])\n        A[1, 1] = -k1 * x[0] - k2\n        A[2, 1] = k3 * (P_TOT - x[2])\n        A[2, 2] = -k3 * x[1] - k4\n        \n        # Gradient matrix B = df/d_theta\n        B = np.zeros((3, 6))\n        B[0, 0] = L0 * (R_TOT - x[0])\n        B[0, 1] = -x[0]\n        B[1, 2] = x[0] * (K_TOT - x[1])\n        B[1, 3] = -x[1]\n        B[2, 4] = x[1] * (P_TOT - x[2])\n        B[2, 5] = -x[2]\n\n        # Sensitivity equations dS/dt = A*S + B\n        dS_dt = A @ S + B\n\n        dz_dt = np.concatenate((dx_dt, dS_dt.flatten()))\n        return dz_dt\n\n    def solve_for_case(case_params):\n        \"\"\"\n        Processes a single test case.\n        \"\"\"\n        theta, L0, candidate_times, param_subset_J, sigma, K = case_params\n        \n        # 1. Integrate the augmented ODE system\n        ode_func = lambda t, z: augmented_ode(t, z, np.array(theta), L0)\n        z0 = np.zeros(3 + 3 * 6)\n        t_span = (0, max(candidate_times) if candidate_times else 0)\n        \n        if not candidate_times:\n            sol_y = np.array([[] for _ in range(len(z0))])\n        elif t_span[1] == 0:\n            sol_y = np.tile(z0.reshape(-1, 1), (1, len(candidate_times)))\n        else:\n            sol = solve_ivp(\n                ode_func, t_span, z0, t_eval=candidate_times,\n                method='RK45', rtol=1e-8, atol=1e-10\n            )\n            sol_y = sol.y\n\n        # Output sensitivity dy/d_theta = dx3/d_theta is the 3rd row of S (index 2)\n        num_times = len(candidate_times)\n        output_sens = np.zeros((6, num_times))\n        for j in range(6):\n            output_sens[j, :] = sol_y[3 + 2 * 6 + j, :]\n\n        # 2. Parameter prioritization\n        scores = {}\n        max_score = -1.0\n        j_star = -1\n        # Iterate over sorted indices to handle ties correctly (first one wins)\n        for j in sorted(list(param_subset_J)):\n            sens_j_values = output_sens[j, :]\n            theta_j = theta[j]\n            sum_sq = np.sum(((theta_j * sens_j_values) / sigma)**2)\n            current_score = np.sqrt(sum_sq)\n            scores[j] = current_score\n            if current_score > max_score:\n                max_score = current_score\n                j_star = j\n            \n        # 3. Time-point selection by D-optimality\n        num_candidates = len(candidate_times)\n        candidate_indices = range(num_candidates)\n        \n        best_indices = None\n        max_det = -1.0\n        \n        g_all_times = output_sens[list(sorted(list(param_subset_J))), :]\n        \n        for current_indices in combinations(candidate_indices, K):\n            fim_dim = len(param_subset_J)\n            fim = np.zeros((fim_dim, fim_dim))\n            \n            for i_time in current_indices:\n                g_ti = g_all_times[:, i_time]\n                fim += np.outer(g_ti, g_ti)\n            \n            fim /= (sigma**2)\n            current_det = np.linalg.det(fim)\n            \n            if current_det > max_det + 1e-12:\n                max_det = current_det\n                best_indices = current_indices\n        \n        if best_indices is None and K > 0 and num_candidates >= K:\n             best_indices = next(combinations(candidate_indices, K))\n             max_det = 0.0\n\n        t_indices_out = list(best_indices) if best_indices is not None else []\n        if K == 1:\n            t_indices_out.append(-1)\n        \n        return [j_star, t_indices_out[0], t_indices_out[1], max_det]\n\n    test_cases = [\n        # Test case 1\n        ([1.0, 0.2, 0.5, 0.1, 0.7, 0.1], 1.0, list(np.arange(0, 40.1, 5.0)),\n         {0, 2, 4}, 0.05, 2),\n        # Test case 2\n        ([1.0, 1.5, 0.5, 1.0, 0.7, 1.0], 1.0, [50., 100., 150., 200.],\n         {0, 2}, 0.05, 2),\n        # Test case 3\n        ([1.0, 0.2, 0.5, 0.1, 0.7, 0.1], 1.0, list(np.arange(0, 20.1, 2.0)),\n         {4}, 0.10, 1),\n    ]\n\n    results = []\n    for case in test_cases:\n        results.append(solve_for_case(case))\n        \n    print(f\"[{','.join(f'[{r[0]},{r[1]},{r[2]},{r[3]}]' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在现代系统生物学中，模型越来越多地采用贝叶斯框架，将参数和预测视为概率分布而非单一数值。这要求我们采用更高级的验证技术，以评估整个预测分布的质量，而不仅仅是点估计的准确性。这项练习将带您进入贝叶斯模型检验的前沿领域，您将为一个随机基因表达模型实施两种强大的诊断方法：后验预测检验（Posterior Predictive Checks, PPC）和基于仿真的校准（Simulation-Based Calibration, SBC）。通过使用瓦瑟斯坦距离（Wasserstein distance）比较预测分布与观测分布，并分析秩统计量的均匀性，您将学会如何严格评估模型的拟合优度以及贝叶斯推断过程本身的可靠性 。",
            "id": "3327305",
            "problem": "您的任务是为一个随机基因调控网络实施后验预测检验和基于模拟的校准。该网络被建模为信使核糖核酸 (mRNA) 计数的线性生灭过程。该模型假设单个基因以恒定的转录率 $k$ 产生 mRNA，并以速率 $\\gamma$ 降解，起始状态为 $y(0) = 0$。对于在固定时间点 $t$ 的独立细胞观测，生成模型意味着 mRNA 计数 $Y(t)$ 服从一个离散分布。\n\n基本原理和定义：\n- 具有恒定迁入率 $k$ 和线性死亡率 $\\gamma$ 的线性生灭过程是化学动力学中的一个经典随机过程。$Y(t)$ 的均值 $\\mu(t)$ 满足常微分方程 $d\\mu(t)/dt = k - \\gamma \\mu(t)$，其中 $\\mu(0) = 0$，解得 $\\mu(t) = \\frac{k}{\\gamma}\\left(1 - e^{-\\gamma t}\\right)$。\n- 泊松叠加与稀疏特性意味着，具有线性衰减的恒定速率出生过程的综合效应导致计数分布为泊松分布，其均值为 $\\mu(t)$。因此，在该模型下，对于每个固定的 $t$，$Y(t) \\sim \\operatorname{Poisson}(\\mu(t))$。\n- 对于在时间点 $\\{t_i\\}$ 进行的独立观测 $\\{y_i\\}_{i=1}^n$ 且 $\\gamma$ 已知的情况下，$k$ 的似然函数可以分解为 $y_i \\sim \\operatorname{Poisson}(c_i k)$，其中 $c_i = \\frac{1 - e^{-\\gamma t_i}}{\\gamma}$。\n- 在 $k$ 上使用 Gamma 先验，记为 $k \\sim \\operatorname{Gamma}(\\alpha_0, \\beta_0)$（形状-速率参数化），则其后验分布为 $k \\mid \\{y_i,t_i\\} \\sim \\operatorname{Gamma}(\\alpha_0 + \\sum_i y_i, \\beta_0 + \\sum_i c_i)$。\n\n您的任务：\n1) 使用第一Wasserstein距离进行跨时间的后验预测检验。对于下方的每个测试用例，通过使用给定的真实参数从模型中在每个时间点 $t$ 采样指定数量的细胞，生成一个观测数据集。使用 $k$ 上的 Gamma 先验，通过汇集所有时间点的观测数据并使用模型 $y_i \\sim \\operatorname{Poisson}(c_i k)$（其中 $c_i = \\frac{1 - e^{-\\gamma_{\\text{assumed}} t_i}}{\\gamma_{\\text{assumed}}}$）来计算 $k$ 的后验分布。令 $\\hat{k}$ 为后验均值 $\\hat{k} = \\frac{\\alpha_{\\text{post}}}{\\beta_{\\text{post}}}$。将时间点 $t$ 的模型预测分布定义为 $p_{\\text{pred}}(y \\mid t, \\hat{k}) = \\operatorname{Poisson}\\left(\\hat{k}\\,\\frac{1 - e^{-\\gamma_{\\text{assumed}} t}}{\\gamma_{\\text{assumed}}}\\right)$。令 $p_{\\text{obs}}(y \\mid t)$ 为时间点 $t$ 观测样本的经验分布。对于测试用例中的每个 $t$，通过从 $p_{\\text{pred}}(\\cdot \\mid t, \\hat{k})$ 中抽取一个与观测样本大小相同的合成样本，并使用两个样本之间的标准一维Wasserstein距离，来近似一维第一Wasserstein距离 $W\\!\\left(p_{\\text{pred}}(\\cdot \\mid \\hat{k}), p_{\\text{obs}}\\right)$。将该测试用例中所有时间点的这些距离的平均值作为一个浮点数报告。\n\n2) 通过秩统计量进行基于模拟的校准 (SBC)。对于每个测试用例，在转录率上定义一个先验 $k \\sim \\operatorname{Gamma}(\\alpha_0,\\beta_0)$。对 $R$ 次重复执行以下操作：从先验中采样 $k^{(r)}$，使用真实降解率 $\\gamma_{\\text{true}}$ 在指定时间点生成数据集，在假设的 $\\gamma_{\\text{assumed}}$ 和相同的先验下计算后验 $k \\mid \\text{data}$，抽取 $M$ 个独立的后验样本 $\\{\\tilde{k}_m^{(r)}\\}_{m=1}^M$，并计算秩统计量 $r^{(r)} = \\#\\{m : \\tilde{k}_m^{(r)} < k^{(r)}\\}$，对于连续后验，该值位于 $\\{0,1,\\dots,M\\}$ 中。将 $\\{r^{(r)}\\}_{r=1}^R$ 聚合到 $\\{0,\\dots,M\\}$ 上的直方图中，并对离散均匀分布进行卡方拟合优度检验。令 $p_{\\text{SBC}}$ 为得到的p值。对于测试用例中提供的显著性水平 $\\alpha$，如果 $p_{\\text{SBC}} \\ge \\alpha$，则定义校准通过指示符为 $\\text{pass} = \\text{True}$，否则为 $\\text{False}$。为每个用例报告此布尔值。\n\n计算和统计细节：\n- 所有随机数生成必须通过在程序开始时设置固定种子来保证可复现性。\n- 对Gamma分布使用形状-速率参数化。如果您使用的库通过形状-尺度参数化Gamma分布，则必须使用 $\\text{scale} = 1/\\text{rate}$ 进行转换。\n- 一维的第一Wasserstein距离可以使用基于分位数函数积分的标准定义来计算；在代码中，您可以使用任何对一维样本数值上正确的实现，该实现返回一个非负实值。\n\n测试套件：\n实现您的程序以运行以下三个测试用例。对于每个用例，使用指定的 $k_\\star$ 和 $\\gamma_{\\text{true}}$ 为后验预测检验生成一个观测数据集，并使用相同的数据计算后验和 $\\hat{k}$。\n\n- 用例1（模型设定正确，信息丰富）：\n  - $\\gamma_{\\text{true}} = 1.1$\n  - $\\gamma_{\\text{assumed}} = 1.1$\n  - 时间 $t \\in \\{0.2, 0.6, 1.0, 2.0\\}$\n  - 每个时间点的细胞数 $N = 200$\n  - k的先验：$k \\sim \\operatorname{Gamma}(\\alpha_0 = 2.0, \\beta_0 = 0.3)$\n  - 用于后验预测检验的数据生成转录率：$k_\\star = 7.0$\n  - SBC设置：$R = 840$ 次重复，每次重复 $M = 20$ 个后验样本，显著性 $\\alpha = 0.01$\n\n- 用例2（降解率设定错误）：\n  - $\\gamma_{\\text{true}} = 1.1$\n  - $\\gamma_{\\text{assumed}} = 2.2$\n  - 时间 $t \\in \\{0.2, 0.6, 1.0, 2.0\\}$\n  - 每个时间点的细胞数 $N = 200$\n  - k的先验：$k \\sim \\operatorname{Gamma}(\\alpha_0 = 2.0, \\beta_0 = 0.3)$\n  - 用于后验预测检验的数据生成转录率：$k_\\star = 7.0$\n  - SBC设置：$R = 840$，$M = 20$，$\\alpha = 0.01$\n\n- 用例3（边缘情况：小样本和早期时间点）：\n  - $\\gamma_{\\text{true}} = 1.0$\n  - $\\gamma_{\\text{assumed}} = 1.0$\n  - 时间 $t \\in \\{0.05, 0.1, 0.2, 0.4\\}$\n  - 每个时间点的细胞数 $N = 20$\n  - k的先验：$k \\sim \\operatorname{Gamma}(\\alpha_0 = 1.5, \\beta_0 = 0.5)$\n  - 用于后验预测检验的数据生成转录率：$k_\\star = 5.0$\n  - SBC设置：$R = 420$，$M = 20$，$\\alpha = 0.01$\n\n要求的最终输出：\n- 您的程序必须生成单行输出，其中包含一个Python列表。对于每个用例，按顺序追加两个条目：首先是跨时间的平均Wasserstein距离（浮点数）；其次是SBC校准通过指示符（布尔值）。因此，最终输出必须是 `[w1,pass1,w2,pass2,w3,pass3]` 这种确切格式的单行文本，不含任何额外文字，其中 $w1$、$w2$ 和 $w3$ 是浮点数，$pass1$、$pass2$ 和 $pass3$ 是布尔值。",
            "solution": "用户提供了一个在计算系统生物学领域中有效、适定且具有科学依据的问题。任务是为一个基因表达的随机模型实施并应用两种标准的模型验证技术——后验预测检验 (PPC) 和基于模拟的校准 (SBC)。\n\n该模型描述了单个基因在时间 $t$ 的信使核糖核酸 (mRNA) 分子数 $Y(t)$。其动态被建模为一个线性生灭过程，具有恒定的转录（出生）率 $k$ 和一阶降解（死亡）率 $\\gamma$。假设初始状态为零个 mRNA 分子，即 $Y(0)=0$，在任何时间 $t>0$ 的计数 $Y(t)$ 服从泊松分布，$Y(t) \\sim \\operatorname{Poisson}(\\mu(t))$。该分布的均值 $\\mu(t)$ 由平均分子数的常微分方程的解给出，即 $\\mu(t) = \\frac{k}{\\gamma}\\left(1 - e^{-\\gamma t}\\right)$。\n\n对于转录率 $k$ 的贝叶斯推断，使用了共轭先验。给定 $k$ 的一个Gamma先验 $k \\sim \\operatorname{Gamma}(\\alpha_0, \\beta_0)$（其中 $\\alpha_0$ 是形状参数，$\\beta_0$ 是速率参数），以及在相应时间点 $\\{t_i\\}_{i=1}^n$ 的一组独立观测值 $\\{y_i\\}_{i=1}^n$，$k$ 的后验分布也是一个Gamma分布。单个观测值 $y_i$ 的似然是 $\\operatorname{Poisson}(k \\cdot c_i)$，其中 $c_i = \\frac{1 - e^{-\\gamma t_i}}{\\gamma}$ 是一个依赖于时间的常数（假设 $\\gamma$ 已知）。由于Gamma-泊松共轭模型的性质，后验分布由下式给出：\n$$\nk \\mid \\{y_i,t_i\\} \\sim \\operatorname{Gamma}\\left(\\alpha_0 + \\sum_{i=1}^n y_i, \\beta_0 + \\sum_{i=1}^n c_i\\right)\n$$\n我们将后验参数表示为 $\\alpha_{\\text{post}} = \\alpha_0 + \\sum y_i$ 和 $\\beta_{\\text{post}} = \\beta_0 + \\sum c_i$。\n\n实现将包括两个主要部分，对应于指定的两个任务。\n\n**任务1：后验预测检验 (PPC)**\n\nPPC的目标是通过将观测数据与从拟合模型中模拟出的数据进行比较，来评估模型的拟合优度。对于每个测试用例，流程如下：\n$1$. **生成一个“观测”数据集**：对于测试用例中每个指定的时间 $t$，我们使用真实参数 $k_\\star$ 和 $\\gamma_{\\text{true}}$ 计算泊松分布的均值，并从中生成 $N$ 个样本。这模拟了从 $N$ 个独立细胞中收集数据的过程。均值为 $\\mu_{\\text{true}}(t) = \\frac{k_\\star}{\\gamma_{\\text{true}}}\\left(1 - e^{-\\gamma_{\\text{true}} t}\\right)$。\n$2$. **执行贝叶斯推断**：使用步骤1中生成的整个数据集（汇集所有时间点的数据），我们计算 $k$ 的后验分布。此步骤使用指定的先验 $\\operatorname{Gamma}(\\alpha_0, \\beta_0)$ 和假定的降解率 $\\gamma_{\\text{assumed}}$。后验参数为 $\\alpha_{\\text{post}} = \\alpha_0 + \\sum y_i$ 和 $\\beta_{\\text{post}} = \\beta_0 + \\sum_i N \\cdot \\frac{1 - e^{-\\gamma_{\\text{assumed}} t_i}}{\\gamma_{\\text{assumed}}}$。\n$3$. **估计转录率**：转录率的点估计 $\\hat{k}$ 取为后验分布的均值，即 $\\hat{k} = \\alpha_{\\text{post}} / \\beta_{\\text{post}}$。\n$4$. **生成一个“预测”数据集**：对于每个时间 $t$，我们使用估计的参数 $\\hat{k}$ 和假定的降解率 $\\gamma_{\\text{assumed}}$ 从模型中生成一个新的大小为 $N$ 的合成数据集。其分布为 $p_{\\text{pred}}(y \\mid t, \\hat{k}) = \\operatorname{Poisson}\\left(\\hat{k} \\frac{1 - e^{-\\gamma_{\\text{assumed}} t}}{\\gamma_{\\text{assumed}}}\\right)$。\n$5$. **计算差异**：使用第一Wasserstein距离 $W_1$ 来量化每个时间 $t$ 观测数据和预测数据之间的差异。对于由样本 $u = \\{u_j\\}_{j=1}^N$ 和 $v = \\{v_j\\}_{j=1}^N$ 表示的两个一维经验分布，距离计算为 $W_1 = \\frac{1}{N} \\sum_{j=1}^N |u_{(j)} - v_{(j)}|$，其中 $u_{(j)}$ 和 $v_{(j)}$ 是第 $j$ 个顺序统计量（即排序后的样本）。\n$6$. **平均差异**：此任务的最终结果是在所有时间点上计算的Wasserstein距离的平均值。\n\n**任务2：基于模拟的校准 (SBC)**\n\nSBC是一种诊断贝叶斯推断过程中潜在校准错误的方法。它检查后验分布是否平均而言能正确表示参数的不确定性。该过程需要一个模拟循环：\n$1$. **定义先验和模拟参数**：我们使用先验 $k \\sim \\operatorname{Gamma}(\\alpha_0,\\beta_0)$ 和模拟设置（$R$ 次重复，$M$ 个后验样本）。\n$2$. **执行 $R$ 次重复**：对于每次重复 $r=1, \\dots, R$：\n    a. 从先验分布中抽取一个“真实”参数值 $k^{(r)}$：$k^{(r)} \\sim \\operatorname{Gamma}(\\alpha_0, \\beta_0)$。\n    b. 使用这个 $k^{(r)}$ 和真实的降解率 $\\gamma_{\\text{true}}$ 生成一个合成数据集。\n    c. 在这个合成数据集上使用相同的先验和假定的降解率 $\\gamma_{\\text{assumed}}$ 执行贝叶斯推断，以获得后验 $\\operatorname{Gamma}(\\alpha_{\\text{post}}^{(r)}, \\beta_{\\text{post}}^{(r)})$。\n    d. 从该后验分布中抽取 $M$ 个样本 $\\{\\tilde{k}_m^{(r)}\\}_{m=1}^M$。\n    e. 计算秩统计量：$r^{(r)} = \\sum_{m=1}^M \\mathbb{I}(\\tilde{k}_m^{(r)} < k^{(r)})$，其中 $\\mathbb{I}(\\cdot)$ 是指示函数。秩统计量计算了有多少后验样本小于用于生成数据的真实值。\n$3$. **分析秩分布**：一个校准良好的推断过程应产生在整数 $\\{0, 1, \\dots, M\\}$ 上均匀分布的秩。我们收集所有 $R$ 个秩，并形成一个有 $M+1$ 个箱的直方图。\n$4$. **统计检验**：执行卡方 ($\\chi^2$) 拟合优度检验，以检查观测到的秩分布是否与离散均匀分布一致。每个秩的期望频率为 $E = R / (M+1)$。\n$5$. **校准判定**：将 $\\chi^2$ 检验的p值 $p_{\\text{SBC}}$ 与预定义的显著性水平 $\\alpha$ 进行比较。如果 $p_{\\text{SBC}} \\ge \\alpha$，则认为校准“通过”，表明没有显著偏离均匀性。如果“失败” ($p_{\\text{SBC}} < \\alpha$)，则表明推断过程存在校准错误，这在模型设定错误时（例如 $\\gamma_{\\text{assumed}} \\ne \\gamma_{\\text{true}}$）是预期的。\n\n代码将为提供的三个测试用例中的每一个实施这两个程序，并通过使用固定的随机种子来确保可复现性。",
            "answer": "```python\n# A solver agent that generates a solution and final answer for a given problem.\nimport numpy as np\nfrom scipy.stats import chisquare\n\ndef run_posterior_predictive_check(case, rng):\n    \"\"\"\n    Performs the posterior predictive check and computes the average Wasserstein distance.\n    \"\"\"\n    # Unpack case parameters\n    gamma_true = case['gamma_true']\n    gamma_assumed = case['gamma_assumed']\n    times = np.array(case['times'])\n    N = case['N']\n    prior_alpha = case['prior_alpha']\n    prior_beta = case['prior_beta']\n    k_star = case['k_star']\n\n    # 1. Generate an \"observed\" dataset using true parameters\n    observed_data_by_time = {}\n    all_y_obs = []\n    \n    for t in times:\n        mu_true = (k_star / gamma_true) * (1 - np.exp(-gamma_true * t))\n        y_obs_at_t = rng.poisson(mu_true, size=N)\n        observed_data_by_time[t] = y_obs_at_t\n        all_y_obs.extend(y_obs_at_t)\n\n    # 2. Compute posterior using the generated data and assumed gamma\n    sum_y = np.sum(all_y_obs)\n    \n    # Calculate sum c_i for posterior beta\n    c_coeffs = (1 - np.exp(-gamma_assumed * times)) / gamma_assumed\n    sum_c = N * np.sum(c_coeffs)\n\n    alpha_post = prior_alpha + sum_y\n    beta_post = prior_beta + sum_c\n    \n    # 3. Estimate k as posterior mean\n    k_hat = alpha_post / beta_post\n    \n    # 4. Compute Wasserstein distances\n    wasserstein_distances = []\n    for i, t in enumerate(times):\n        # Generate predicted data\n        mu_pred = k_hat * c_coeffs[i]\n        \n        # Guard against non-positive means in edge cases\n        if mu_pred <= 0:\n            y_pred = np.zeros(N, dtype=int)\n        else:\n            y_pred = rng.poisson(mu_pred, size=N)\n        \n        # Retrieve observed data for this time point\n        y_obs_at_t = observed_data_by_time[t]\n        \n        # Calculate 1D Wasserstein distance\n        y_obs_sorted = np.sort(y_obs_at_t)\n        y_pred_sorted = np.sort(y_pred)\n        w_dist = np.mean(np.abs(y_obs_sorted - y_pred_sorted))\n        wasserstein_distances.append(w_dist)\n        \n    return np.mean(wasserstein_distances)\n\ndef run_simulation_based_calibration(case, rng):\n    \"\"\"\n    Performs simulation-based calibration and returns the pass/fail indicator.\n    \"\"\"\n    # Unpack case parameters\n    gamma_true = case['gamma_true']\n    gamma_assumed = case['gamma_assumed']\n    times = np.array(case['times'])\n    N = case['N']\n    prior_alpha = case['prior_alpha']\n    prior_beta = case['prior_beta']\n    R = case['R']\n    M = case['M']\n    alpha_sig = case['alpha_sig']\n\n    ranks = np.zeros(R, dtype=int)\n    \n    # Pre-calculate sum of c_i coefficients, which is constant across replications\n    c_coeffs_assumed = (1 - np.exp(-gamma_assumed * times)) / gamma_assumed\n    sum_c_for_posterior = N * np.sum(c_coeffs_assumed)\n\n    for r in range(R):\n        # 1. Sample k_true from the prior\n        k_true_r = rng.gamma(shape=prior_alpha, scale=1.0/prior_beta)\n        \n        # 2. Generate synthetic data using k_true_r and gamma_true\n        sum_y = 0\n        mean_rates_true = (k_true_r / gamma_true) * (1 - np.exp(-gamma_true * times))\n        for mu_true in mean_rates_true:\n            # Poisson mean must be non-negative\n            if mu_true <= 0: continue\n            y_obs_t = rng.poisson(mu_true, size=N)\n            sum_y += np.sum(y_obs_t)\n            \n        # 3. Compute posterior for k\n        alpha_post = prior_alpha + sum_y\n        beta_post = prior_beta + sum_c_for_posterior\n        \n        # 4. Draw samples from the posterior\n        k_posterior_samples = rng.gamma(shape=alpha_post, scale=1.0/beta_post, size=M)\n        \n        # 5. Compute the rank statistic\n        rank = np.sum(k_posterior_samples < k_true_r)\n        ranks[r] = rank\n        \n    # 6. Perform Chi-squared goodness-of-fit test\n    # Bins are 0, 1, ..., M, for a total of M+1 bins\n    observed_counts = np.bincount(ranks, minlength=M + 1)\n    \n    # Expected count per bin under the uniform hypothesis\n    expected_count = R / (M + 1)\n    \n    _, p_value = chisquare(f_obs=observed_counts, f_exp=expected_count)\n    \n    # 7. Return calibration pass indicator\n    return p_value >= alpha_sig\n\ndef solve():\n    # Set a fixed seed for reproducibility.\n    RNG = np.random.default_rng(seed=12345)\n\n    test_cases = [\n        # Case 1: well-specified model\n        {\n            'gamma_true': 1.1, 'gamma_assumed': 1.1, \n            'times': [0.2, 0.6, 1.0, 2.0], 'N': 200,\n            'prior_alpha': 2.0, 'prior_beta': 0.3, \n            'k_star': 7.0, 'R': 840, 'M': 20, 'alpha_sig': 0.01\n        },\n        # Case 2: misspecified model (gamma is wrong)\n        {\n            'gamma_true': 1.1, 'gamma_assumed': 2.2, \n            'times': [0.2, 0.6, 1.0, 2.0], 'N': 200,\n            'prior_alpha': 2.0, 'prior_beta': 0.3, \n            'k_star': 7.0, 'R': 840, 'M': 20, 'alpha_sig': 0.01\n        },\n        # Case 3: edge case (small samples, early times)\n        {\n            'gamma_true': 1.0, 'gamma_assumed': 1.0, \n            'times': [0.05, 0.1, 0.2, 0.4], 'N': 20,\n            'prior_alpha': 1.5, 'prior_beta': 0.5, \n            'k_star': 5.0, 'R': 420, 'M': 20, 'alpha_sig': 0.01\n        },\n    ]\n\n    final_results = []\n    \n    for case in test_cases:\n        # Task 1: Posterior Predictive Checks\n        avg_w_dist = run_posterior_predictive_check(case, RNG)\n        \n        # Task 2: Simulation-Based Calibration\n        sbc_pass = run_simulation_based_calibration(case, RNG)\n\n        final_results.extend([avg_w_dist, sbc_pass])\n\n    # Format the boolean values to lowercase as per Python's str() behavior\n    formatted_results = [f\"{x:.10f}\" if isinstance(x, float) else str(x).lower() for x in final_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}