{
    "hands_on_practices": [
        {
            "introduction": "The foundation of analyzing any stochastic trajectory is understanding its probability. For a Continuous-Time Markov Chain (CTMC), the likelihood of a specific path is determined by the sequence of reaction events and the time spent between them. This practice  focuses on a crucial component of this likelihood: the integrated hazard, which quantifies the cumulative probability of *not* jumping. You will see how this integral term elegantly reduces to a simple weighted sum, providing a vital building block for advanced parameter inference techniques.",
            "id": "3303233",
            "problem": "In computational systems biology, the stochastic dynamics of a biochemical reaction network can be modeled as a Continuous-Time Markov Chain (CTMC), where the system state $X_t \\in \\mathbb{N}$ is piecewise constant and changes by jumps at random times. The instantaneous total event rate (also called the hazard or intensity) $\\lambda(X_t;\\theta)$ governs the distribution of waiting times and jump events. Consider a single-species network with three reactions: constitutive synthesis, first-order decay, and bimolecular annihilation. The total hazard is modeled as\n$$\n\\lambda(x;\\theta) \\;=\\; \\theta_1 \\;+\\; \\theta_2\\, x \\;+\\; \\theta_3 \\binom{x}{2},\n$$\nwhere $\\theta = (\\theta_1,\\theta_2,\\theta_3)$ are unknown parameters to be estimated from observed trajectories, and $\\binom{x}{2} = \\frac{x(x-1)}{2}$.\n\nA realized jump trajectory on the interval $[0,T]$ with $T = 6.0$ is observed, with jump times $t_0 = 0$, $t_1 = 0.5$, $t_2 = 1.1$, $t_3 = 2.0$, $t_4 = 4.0$, and $t_5 = 6.0$, and with piecewise-constant states $X_s = x_k$ for $s \\in [t_k, t_{k+1})$ given by\n$$\nx_0 = 3,\\quad x_1 = 4,\\quad x_2 = 2,\\quad x_3 = 2,\\quad x_4 = 5.\n$$\n\nStarting from the fundamental definition of the survival function for a time-inhomogeneous jump process and the role of the integrated hazard $\\int_0^T \\lambda(X_s;\\theta)\\,ds$ in the path distribution, derive how the integral reduces under the piecewise-constant property of $X_s$ along the trajectory. Then, implement this reduction for the given trajectory, and simplify the resulting expression to a single closed-form analytic expression in $\\theta_1$, $\\theta_2$, and $\\theta_3$.\n\nYour final answer must be a single analytic expression. No rounding is required, and no physical units are involved.",
            "solution": "We begin from the standard construction of a Continuous-Time Markov Chain (CTMC) path distribution via its hazard (intensity) function. For a time-inhomogeneous jump process with instantaneous total rate $\\lambda(X_t;\\theta)$, the probability that no event occurs in the interval $[0,t]$ conditional on the trajectory of $X_s$ is\n$$\n\\Pr(\\text{no jump in }[0,t] \\mid \\{X_s\\}_{s \\in [0,t]}) \\;=\\; \\exp\\!\\left(-\\int_0^t \\lambda(X_s;\\theta)\\,ds\\right).\n$$\nThis formula follows from the fundamental definition of the survival function for a non-homogeneous Poisson process (NHPP), generalized to a state-dependent intensity through the CTMC framework. The integral $\\int_0^T \\lambda(X_s;\\theta)\\,ds$ is thus the integrated hazard that enters the path likelihood.\n\nIn a CTMC on a countable state space, the sample paths are piecewise constant with jumps at isolated times. Let the jump times be $0 = t_0  t_1  \\dots  t_m  t_{m+1} = T$, and the state be constant between jumps: $X_s = x_k$ for $s \\in [t_k, t_{k+1})$, $k = 0,\\dots,m$. Under this piecewise-constant property, the integrand $\\lambda(X_s;\\theta)$ is constant on each interval $[t_k, t_{k+1})$, equal to $\\lambda(x_k;\\theta)$. Therefore, the integral decomposes as a sum over intervals:\n$$\n\\int_0^T \\lambda(X_s;\\theta)\\,ds\n\\;=\\; \\sum_{k=0}^{m} \\int_{t_k}^{t_{k+1}} \\lambda(x_k;\\theta)\\,ds\n\\;=\\; \\sum_{k=0}^{m} \\lambda(x_k;\\theta)\\,(t_{k+1}-t_k).\n$$\nThis reduction is a direct consequence of the fundamental property of Riemann integration for step functions.\n\nWe now implement this reduction for the given trajectory. The trajectory is specified by $t_0 = 0$, $t_1 = 0.5$, $t_2 = 1.1$, $t_3 = 2.0$, $t_4 = 4.0$, $t_5 = 6.0$ and $x_0 = 3$, $x_1 = 4$, $x_2 = 2$, $x_3 = 2$, $x_4 = 5$. There are $m = 4$ jumps and $m+1 = 5$ intervals. The interval durations are\n$$\n\\Delta_0 = t_1 - t_0 = 0.5,\\quad\n\\Delta_1 = t_2 - t_1 = 0.6,\\quad\n\\Delta_2 = t_3 - t_2 = 0.9,\\quad\n\\Delta_3 = t_4 - t_3 = 2.0,\\quad\n\\Delta_4 = t_5 - t_4 = 2.0,\n$$\nand these sum to $T = 6.0$ as a consistency check.\n\nThe total hazard is\n$$\n\\lambda(x;\\theta) \\;=\\; \\theta_1 \\;+\\; \\theta_2\\, x \\;+\\; \\theta_3 \\binom{x}{2}\n\\;=\\; \\theta_1 \\;+\\; \\theta_2\\, x \\;+\\; \\theta_3 \\,\\frac{x(x-1)}{2}.\n$$\nWe evaluate $\\lambda(x_k;\\theta)$ for each $x_k$:\n- For $x_0 = 3$,\n$$\n\\lambda(3;\\theta) \\;=\\; \\theta_1 \\;+\\; 3\\theta_2 \\;+\\; \\theta_3 \\binom{3}{2}\n\\;=\\; \\theta_1 \\;+\\; 3\\theta_2 \\;+\\; 3\\theta_3.\n$$\n- For $x_1 = 4$,\n$$\n\\lambda(4;\\theta) \\;=\\; \\theta_1 \\;+\\; 4\\theta_2 \\;+\\; \\theta_3 \\binom{4}{2}\n\\;=\\; \\theta_1 \\;+\\; 4\\theta_2 \\;+\\; 6\\theta_3.\n$$\n- For $x_2 = 2$,\n$$\n\\lambda(2;\\theta) \\;=\\; \\theta_1 \\;+\\; 2\\theta_2 \\;+\\; \\theta_3 \\binom{2}{2}\n\\;=\\; \\theta_1 \\;+\\; 2\\theta_2 \\;+\\; \\theta_3.\n$$\n- For $x_3 = 2$,\n$$\n\\lambda(2;\\theta) \\;=\\; \\theta_1 \\;+\\; 2\\theta_2 \\;+\\; \\theta_3.\n$$\n- For $x_4 = 5$,\n$$\n\\lambda(5;\\theta) \\;=\\; \\theta_1 \\;+\\; 5\\theta_2 \\;+\\; \\theta_3 \\binom{5}{2}\n\\;=\\; \\theta_1 \\;+\\; 5\\theta_2 \\;+\\; 10\\theta_3.\n$$\n\nMultiplying by the corresponding durations and summing yields the integrated hazard:\n$$\n\\int_0^{6.0} \\lambda(X_s;\\theta)\\,ds\n\\;=\\; 0.5\\big(\\theta_1 + 3\\theta_2 + 3\\theta_3\\big)\n\\;+\\; 0.6\\big(\\theta_1 + 4\\theta_2 + 6\\theta_3\\big)\n\\;+\\; 0.9\\big(\\theta_1 + 2\\theta_2 + \\theta_3\\big)\n\\;+\\; 2.0\\big(\\theta_1 + 2\\theta_2 + \\theta_3\\big)\n\\;+\\; 2.0\\big(\\theta_1 + 5\\theta_2 + 10\\theta_3\\big).\n$$\nWe collect terms by parameter:\n- Coefficient of $\\theta_1$:\n$$\n0.5 + 0.6 + 0.9 + 2.0 + 2.0 \\;=\\; 6.0.\n$$\n- Coefficient of $\\theta_2$:\n$$\n0.5\\cdot 3 + 0.6\\cdot 4 + 0.9\\cdot 2 + 2.0\\cdot 2 + 2.0\\cdot 5\n\\;=\\; 1.5 + 2.4 + 1.8 + 4.0 + 10.0 \\;=\\; 19.7 \\;=\\; \\frac{197}{10}.\n$$\n- Coefficient of $\\theta_3$:\n$$\n0.5\\cdot 3 + 0.6\\cdot 6 + 0.9\\cdot 1 + 2.0\\cdot 1 + 2.0\\cdot 10\n\\;=\\; 1.5 + 3.6 + 0.9 + 2.0 + 20.0 \\;=\\; 28.0 \\;=\\; 28.\n$$\n\nThus, the integrated hazard simplifies to the closed-form expression\n$$\n\\int_0^{6.0} \\lambda(X_s;\\theta)\\,ds \\;=\\; 6\\,\\theta_1 \\;+\\; \\frac{197}{10}\\,\\theta_2 \\;+\\; 28\\,\\theta_3.\n$$\nThis expression implements the integral term by summing the hazard evaluated at the piecewise-constant states, weighted by the interval durations, as required for distributional analysis of stochastic trajectories in a CTMC.",
            "answer": "$$\\boxed{6\\theta_1+\\frac{197}{10}\\theta_2+28\\theta_3}$$"
        },
        {
            "introduction": "While analyzing a single trajectory is insightful, we often study a system's long-term behavior by simulating it until it reaches a stationary distribution. But how long is long enough? This practice  delves into the theoretical heart of this question by connecting a system's convergence speed to its spectral properties. By deriving a lower bound on the mixing time using the spectral gap, you will gain a fundamental understanding of why some systems equilibrate faster than others and how to reason about the time scales of stochastic decorrelation.",
            "id": "3303209",
            "problem": "A common model for stochastic gene expression dynamics in computational systems biology is a continuous-time, reversible birthâ€“death Markov chain on a finite state space $\\{0,1,\\ldots,N\\}$ with reflecting boundaries, representing, for instance, the count of a molecular species undergoing synthesis and degradation. Let the chain be irreducible with unique stationary distribution $\\pi$, generator $Q$, and transition semigroup $T_t = \\exp(t Q)$. Denote the spectral gap by $\\lambda_1  0$, defined as the smallest positive eigenvalue of $-Q$ acting on functions with mean zero under $\\pi$. Let the total variation (TV) mixing time to $\\epsilon$ be defined by\n$$\nt_{\\mathrm{mix}}(\\epsilon) \\equiv \\inf\\left\\{t \\ge 0 : \\sup_{x \\in \\{0,1,\\ldots,N\\}} \\left\\|T_t(x,\\cdot) - \\pi\\right\\|_{\\mathrm{TV}} \\le \\epsilon \\right\\},\n$$\nwhere for probability measures $\\mu$ and $\\nu$ on $\\{0,1,\\ldots,N\\}$,\n$$\n\\|\\mu - \\nu\\|_{\\mathrm{TV}} \\equiv \\frac{1}{2} \\sum_{i=0}^{N} \\left|\\mu(i) - \\nu(i)\\right|.\n$$\nIn distributional analysis of stochastic trajectories, a key object is the autocorrelation of observables along the stationary trajectory, which for reversible dynamics admits a spectral decomposition where the slowest decaying mode is controlled by $\\lambda_1$. Using only the foundational properties of reversible continuous-time Markov chains, the definition of total variation distance through its dual characterization, and the spectral characterization of $T_t$ via eigenfunctions and eigenvalues, derive a universal lower bound on $t_{\\mathrm{mix}}(\\epsilon)$ that depends only on $\\lambda_1$ and $\\epsilon$. Then, briefly relate this bound to the decorrelation time scale of the slowest mode in trajectory space. \n\nExpress your final lower bound as a single closed-form expression in terms of $\\lambda_1$ and $\\epsilon$. No numerical rounding is required and no units should be included in the final expression.",
            "solution": "The problem is valid as it is scientifically grounded in the theory of Markov chains, well-posed, objective, and self-contained. It presents a standard, non-trivial question in the analysis of stochastic processes. We may proceed with the solution.\n\nThe objective is to derive a universal lower bound on the total variation mixing time, $t_{\\mathrm{mix}}(\\epsilon)$, for a reversible continuous-time Markov chain. The bound should depend only on the spectral gap, $\\lambda_1$, and the mixing threshold, $\\epsilon$. The problem specifies that the derivation should rely on the dual characterization of the total variation distance and the spectral properties of the transition semigroup $T_t$.\n\nLet the state space be $\\mathcal{S} = \\{0, 1, \\ldots, N\\}$. The total variation distance between two probability measures $\\mu$ and $\\nu$ on $\\mathcal{S}$ is given by\n$$\n\\|\\mu - \\nu\\|_{\\mathrm{TV}} = \\frac{1}{2} \\sum_{i=0}^{N} |\\mu(i) - \\nu(i)|.\n$$\nA key tool for connecting this combinatorial definition to spectral theory is the dual characterization of the total variation norm, which states:\n$$\n\\|\\mu - \\nu\\|_{\\mathrm{TV}} = \\sup_{f: \\|\\cdot\\|_{\\infty} \\le 1} \\frac{1}{2} \\left| \\mathbb{E}_{\\mu}[f] - \\mathbb{E}_{\\nu}[f] \\right|,\n$$\nwhere the supremum is taken over all real-valued functions $f$ on $\\mathcal{S}$ with infinity norm $\\|f\\|_{\\infty} = \\sup_{i \\in \\mathcal{S}} |f(i)| \\le 1$.\n\nThe definition of the mixing time is\n$$\nt_{\\mathrm{mix}}(\\epsilon) \\equiv \\inf \\left\\{ t \\ge 0 : d(t) \\le \\epsilon \\right\\},\n$$\nwhere $d(t) \\equiv \\sup_{x \\in \\mathcal{S}} \\|T_t(x, \\cdot) - \\pi\\|_{\\mathrm{TV}}$. Here, $T_t(x, \\cdot)$ is the probability distribution of the chain at time $t$ having started from state $x$, and $\\pi$ is the unique stationary distribution.\n\nLet us apply the dual characterization to the distance $d(t)$:\n$$\n\\|T_t(x, \\cdot) - \\pi\\|_{\\mathrm{TV}} = \\sup_{f: \\|f\\|_{\\infty} \\le 1} \\frac{1}{2} \\left| \\mathbb{E}_{T_t(x, \\cdot)}[f] - \\mathbb{E}_{\\pi}[f] \\right|.\n$$\nThe expectation $\\mathbb{E}_{T_t(x, \\cdot)}[f]$ is the expectation of $f$ when the state is distributed according to $T_t(x, \\cdot)$. This is precisely the action of the semigroup $T_t$ on the function $f$, evaluated at the starting state $x$:\n$$\n\\mathbb{E}_{T_t(x, \\cdot)}[f] = \\sum_{i=0}^{N} f(i) T_t(x, i) = (T_t f)(x).\n$$\nTherefore, we can write the distance from a starting state $x$ as:\n$$\n\\|T_t(x, \\cdot) - \\pi\\|_{\\mathrm{TV}} = \\sup_{f: \\|f\\|_{\\infty} \\le 1} \\frac{1}{2} \\left| (T_t f)(x) - \\mathbb{E}_{\\pi}[f] \\right|.\n$$\nTo find a lower bound for $d(t) = \\sup_{x \\in \\mathcal{S}} \\|T_t(x, \\cdot) - \\pi\\|_{\\mathrm{TV}}$, it is sufficient to choose a specific, well-behaved test function $f$ and evaluate the expression, as the supremum will be greater than or equal to the value for any particular choice of $f$.\n\nThe chain is reversible, so the generator $Q$ is self-adjoint in the Hilbert space $L^2(\\pi)$ of functions with inner product $\\langle g, h \\rangle_\\pi = \\sum_{i=0}^N g(i) h(i) \\pi(i)$. Consequently, the operator $-Q$ has real, non-negative eigenvalues $0 = \\lambda_0  \\lambda_1 \\le \\lambda_2 \\dots \\le \\lambda_N$. Let $\\phi_0, \\phi_1, \\ldots, \\phi_N$ be the corresponding orthonormal eigenfunctions. The eigenfunction for $\\lambda_0=0$ is the constant function $\\phi_0(i) = 1$. The spectral gap is $\\lambda_1  0$. The action of the semigroup $T_t = \\exp(tQ)$ on an eigenfunction $\\phi_k$ is $T_t \\phi_k = \\exp(-t\\lambda_k) \\phi_k$.\n\nThe slowest decaying non-stationary mode of the system corresponds to the eigenfunction $\\phi_1$ associated with the spectral gap $\\lambda_1$. This makes $\\phi_1$ an excellent candidate for a test function. The eigenfunction $\\phi_1$ is orthogonal to the constant function $\\phi_0$ in $L^2(\\pi)$:\n$$\n\\langle \\phi_1, \\phi_0 \\rangle_\\pi = \\sum_{i=0}^N \\phi_1(i) \\cdot 1 \\cdot \\pi(i) = \\mathbb{E}_{\\pi}[\\phi_1] = 0.\n$$\nThe test function $f$ must satisfy $\\|f\\|_{\\infty} \\le 1$. The eigenfunction $\\phi_1$ is normalized in $L^2(\\pi)$ (i.e., $\\|\\phi_1\\|_{L^2(\\pi)}=1$), but not necessarily in the infinity norm. Let us define a suitable test function $f_1$ by normalizing $\\phi_1$ by its infinity norm:\n$$\nf_1 = \\frac{\\phi_1}{\\|\\phi_1\\|_{\\infty}}.\n$$\nThis function satisfies $\\|f_1\\|_{\\infty} = 1$ and, since $\\mathbb{E}_{\\pi}[\\phi_1]=0$, we also have $\\mathbb{E}_{\\pi}[f_1] = 0$.\n\nSubstituting $f_1$ into the dual formulation provides a lower bound for the TV distance:\n$$\n\\|T_t(x, \\cdot) - \\pi\\|_{\\mathrm{TV}} \\ge \\frac{1}{2} \\left| (T_t f_1)(x) - \\mathbb{E}_{\\pi}[f_1] \\right| = \\frac{1}{2} \\left| T_t \\left( \\frac{\\phi_1}{\\|\\phi_1\\|_{\\infty}} \\right) (x) - 0 \\right|.\n$$\nUsing the linearity of $T_t$ and its action on $\\phi_1$:\n$$\n\\|T_t(x, \\cdot) - \\pi\\|_{\\mathrm{TV}} \\ge \\frac{1}{2\\|\\phi_1\\|_{\\infty}} |(T_t \\phi_1)(x)| = \\frac{1}{2\\|\\phi_1\\|_{\\infty}} |\\exp(-t\\lambda_1) \\phi_1(x)| = \\frac{\\exp(-t\\lambda_1) |\\phi_1(x)|}{2\\|\\phi_1\\|_{\\infty}}.\n$$\nThis inequality holds for any starting state $x$. To get a lower bound for $d(t)$, we take the supremum over all $x \\in \\mathcal{S}$:\n$$\nd(t) = \\sup_{x \\in \\mathcal{S}} \\|T_t(x, \\cdot) - \\pi\\|_{\\mathrm{TV}} \\ge \\sup_{x \\in \\mathcal{S}} \\left( \\frac{\\exp(-t\\lambda_1) |\\phi_1(x)|}{2\\|\\phi_1\\|_{\\infty}} \\right).\n$$\nThe supremum of $|\\phi_1(x)|$ over $x$ is by definition $\\|\\phi_1\\|_{\\infty}$. Thus, we obtain:\n$$\nd(t) \\ge \\frac{\\exp(-t\\lambda_1)}{2\\|\\phi_1\\|_{\\infty}} \\sup_{x \\in \\mathcal{S}} |\\phi_1(x)| = \\frac{\\exp(-t\\lambda_1)}{2\\|\\phi_1\\|_{\\infty}} \\|\\phi_1\\|_{\\infty} = \\frac{1}{2}\\exp(-t\\lambda_1).\n$$\nWe have now established a universal lower bound on the decay of the total variation distance.\n\nBy definition, at $t = t_{\\mathrm{mix}}(\\epsilon)$, we have $d(t_{\\mathrm{mix}}(\\epsilon)) \\le \\epsilon$. Combining this with our lower bound gives:\n$$\n\\frac{1}{2}\\exp(-\\lambda_1 t_{\\mathrm{mix}}(\\epsilon)) \\le d(t_{\\mathrm{mix}}(\\epsilon)) \\le \\epsilon.\n$$\nRearranging this inequality to solve for $t_{\\mathrm{mix}}(\\epsilon)$:\n$$\n\\exp(-\\lambda_1 t_{\\mathrm{mix}}(\\epsilon)) \\le 2\\epsilon\n$$\n$$\n-\\lambda_1 t_{\\mathrm{mix}}(\\epsilon) \\le \\ln(2\\epsilon)\n$$\n$$\n\\lambda_1 t_{\\mathrm{mix}}(\\epsilon) \\ge -\\ln(2\\epsilon) = \\ln\\left(\\frac{1}{2\\epsilon}\\right).\n$$\nThis yields the final lower bound on the mixing time:\n$$\nt_{\\mathrm{mix}}(\\epsilon) \\ge \\frac{1}{\\lambda_1} \\ln\\left(\\frac{1}{2\\epsilon}\\right).\n$$\nThis inequality holds for any $\\epsilon \\in (0, 1)$. For $\\epsilon \\ge 1/2$, the right-hand side is non-positive, which is a trivial bound since time is non-negative.\n\nTo relate this bound to the decorrelation time scale of the slowest mode, we consider the stationary autocorrelation function of an observable $g$. For a mean-zero observable, $\\mathbb{E}_\\pi[g]=0$, this is $C_g(t) = \\mathbb{E}_\\pi[g(X_0) g(X_t)] = \\langle g, T_t g \\rangle_\\pi$. The slowest mode corresponds to the eigenfunction $g=\\phi_1$. Its autocorrelation function is $C_{\\phi_1}(t) = \\langle \\phi_1, T_t \\phi_1 \\rangle_\\pi = \\langle \\phi_1, \\exp(-t\\lambda_1) \\phi_1 \\rangle_\\pi = \\exp(-t\\lambda_1) \\|\\phi_1\\|^2_{L^2(\\pi)} = \\exp(-t\\lambda_1)$. The characteristic time scale $\\tau_1$ for this exponential decay is the time required for the correlation to fall by a factor of $1/e$, which is $\\tau_1 = 1/\\lambda_1$. The lower bound on the mixing time can therefore be expressed as $t_{\\mathrm{mix}}(\\epsilon) \\ge \\tau_1 \\ln\\left(\\frac{1}{2\\epsilon}\\right)$. This shows that the mixing time is fundamentally limited by the decorrelation time of the slowest dynamical mode in the system, scaled by a logarithmic factor depending on the desired proximity to stationarity.",
            "answer": "$$\n\\boxed{\\frac{1}{\\lambda_1} \\ln\\left(\\frac{1}{2\\epsilon}\\right)}\n$$"
        },
        {
            "introduction": "Experimental data is often sparse, providing only snapshots of a system's state at discrete time points. This creates a challenging 'missing data' problem when trying to infer the parameters of an underlying continuous-time model. This practice  introduces a powerful solution: the Expectation-Maximization (EM) algorithm. You will implement this iterative method to find maximum likelihood parameter estimates, learning how to statistically reconstruct the unobserved dynamics between measurements.",
            "id": "3303225",
            "problem": "Consider a two-state continuous-time Markov chain (CTMC) representing a reversible single-species reaction network with two microstates, denoted by state $0$ and state $1$, where the transitions correspond to reaction events $0 \\to 1$ and $1 \\to 0$. The infinitesimal generator matrix is $Q(\\theta)$ with off-diagonal entries $q_{01} = \\theta_1$ and $q_{10} = \\theta_2$, and diagonal entries $q_{00} = -\\theta_1$ and $q_{11} = -\\theta_2$. The parameter vector is $\\theta = (\\theta_1,\\theta_2)$ with $\\theta_1  0$ and $\\theta_2  0$.\n\nYou are given discrete-time, exact state observations of the CTMC at times $t_0  t_1  \\cdots  t_M$ in the form of a sequence of states $x_0, x_1, \\ldots, x_M \\in \\{0,1\\}$. Between observation times, the CTMC evolves unobserved. Assume time-homogeneity and that all times are expressed in the same arbitrary unit; the requested outputs are dimensionless numerical values.\n\nYour task is to implement the Expectation-Maximization (EM) algorithm to estimate $\\theta$ by maximizing the expected complete-data log-likelihood of the unobserved reaction counts and sojourn times under the current posteriors induced by the observed endpoints. The fundamental bases you may invoke are:\n- The definition of a continuous-time Markov chain, its Markov property, and the infinitesimal generator matrix $Q(\\theta)$.\n- The Kolmogorov forward equation with solution $P(t) = \\exp(Q(\\theta) t)$ for the transition probability matrix at time $t$.\n- The complete-data likelihood for CTMC trajectories in terms of reaction counts and sojourn times, together with the fact that the sufficient statistics are the total number of transitions of each type and the total time spent in each state.\n\nYour program must:\n- Derive the EM algorithm updates from the above fundamental bases. In the E-step, compute the posterior expectations of the sufficient statistics (expected number of transitions $0 \\to 1$ and $1 \\to 0$, and expected total sojourn times in states $0$ and $1$) conditioned on the observed endpoints at each interval $[t_k, t_{k+1}]$, using the Markov property and transition probabilities $P(t) = \\exp(Q(\\theta) t)$. Use numerically stable and sound computations for these expectations by integrating over the unobserved intermediate time where necessary.\n- In the M-step, maximize the expected complete-data log-likelihood with respect to $\\theta$, ensuring $\\theta_1  0$ and $\\theta_2  0$.\n\nImplement the EM algorithm with a convergence tolerance and a maximum number of iterations. Use numerical integration when required to evaluate any expectations implied by the E-step. The solution must be deterministic and must not rely on randomization.\n\nTest suite. Run your implementation on the following three test cases. Each test case consists of a list of observation times and a list of observed states:\n- Test case $1$: times $[0.0, 0.5, 1.0, 1.5, 2.0]$, states $[0, 1, 0, 1, 0]$.\n- Test case $2$: times $[0.0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0]$, states $[0, 0, 0, 0, 0, 0, 0, 0, 0]$.\n- Test case $3$: times $[0.0, 1.0, 2.5, 5.0, 9.0]$, states $[1, 1, 0, 0, 1]$.\n\nAlgorithm configuration. For each test case, initialize with $\\theta^{(0)} = (1.0, 1.0)$, use maximum iterations $50$, and a relative tolerance of $10^{-8}$ for convergence of parameters.\n\nOutput specification. For each test case, after convergence (or reaching the iteration limit), output the estimated $\\theta_1$ and $\\theta_2$ in that order. Your program should produce a single line of output containing the results for all test cases concatenated in order as a comma-separated list of floating-point numbers rounded to $6$ decimal places, enclosed in square brackets. For example, the output format must be $[\\theta_{1}^{(1)},\\theta_{2}^{(1)},\\theta_{1}^{(2)},\\theta_{2}^{(2)},\\theta_{1}^{(3)},\\theta_{2}^{(3)}]$, where superscripts indicate the test case index. Do not include physical units in the output.",
            "solution": "The problem requires the implementation of the Expectation-Maximization (EM) algorithm to estimate the parameters $\\theta = (\\theta_1, \\theta_2)$ of a two-state continuous-time Markov chain (CTMC). The estimation is based on a sequence of discrete-time state observations.\n\n### Problem Validation\nThe problem statement is validated as follows:\n- **Givens Extracted**: The model is a two-state CTMC with generator matrix $Q = \\begin{pmatrix} -\\theta_1  \\theta_1 \\\\ \\theta_2  -\\theta_2 \\end{pmatrix}$. Data consists of observed states $x_k$ at times $t_k$. The task is to estimate $\\theta = (\\theta_1, \\theta_2)$ using the EM algorithm, optimizing the expected complete-data log-likelihood. Initial parameters are $\\theta^{(0)}=(1.0, 1.0)$, with a maximum of $50$ iterations and a relative tolerance of $10^{-8}$. Three specific test cases are provided.\n- **Validation Verdict**: The problem is **valid**. It is scientifically sound, resting on the well-established theories of CTMCs and the EM algorithm. It is well-posed, providing all necessary information for a deterministic implementation. The language is objective and precise. It represents a standard, non-trivial problem in statistical inference for stochastic processes, commonly found in computational systems biology.\n\n### Algorithmic Derivation\n\nThe EM algorithm is an iterative procedure for finding maximum likelihood estimates of parameters in statistical models with unobserved (hidden) data. In this context, the complete data would be the full microscopic path of the CTMC between observations, while the observed data are only the states at specific time points.\n\n**1. Complete-Data Log-Likelihood**\n\nIf a full trajectory of the CTMC over a total observation time $T$ were known, the sufficient statistics for estimating $\\theta$ would be:\n- $N_{01}$: The total number of transitions from state $0$ to state $1$.\n- $N_{10}$: The total number of transitions from state $1$ to state $0$.\n- $T_0$: The total time the process spent in state $0$.\n- $T_1$: The total time the process spent in state $1$.\n\nThe complete-data likelihood function $L(\\theta)$ is given by the product of probabilities of the observed events (jumps and sojourns):\n$$ L(\\theta | \\text{complete data}) = (\\theta_1^{N_{01}} e^{-\\theta_1 T_0}) \\cdot (\\theta_2^{N_{10}} e^{-\\theta_2 T_1}) $$\nThe corresponding log-likelihood is:\n$$ \\log L(\\theta) = N_{01} \\log \\theta_1 - \\theta_1 T_0 + N_{10} \\log \\theta_2 - \\theta_2 T_1 $$\n\n**2. The Expectation-Maximization (EM) Algorithm**\n\nThe EM algorithm consists of two steps, repeated until convergence.\n\n**M-step (Maximization):**\nIn the M-step, we maximize the *expected* complete-data log-likelihood, where the expectation is taken with respect to the distribution of the hidden data, conditioned on the observed data and the current parameter estimate $\\theta^{(p)}$. Let $\\mathbb{E}[\\cdot]$ denote this conditional expectation.\n$$ Q(\\theta | \\theta^{(p)}) = \\mathbb{E}[N_{01}] \\log \\theta_1 - \\theta_1 \\mathbb{E}[T_0] + \\mathbb{E}[N_{10}] \\log \\theta_2 - \\theta_2 \\mathbb{E}[T_1] $$\nTo maximize $Q(\\theta|\\theta^{(p)})$, we take partial derivatives with respect to $\\theta_1$ and $\\theta_2$ and set them to zero:\n$$ \\frac{\\partial Q}{\\partial \\theta_1} = \\frac{\\mathbb{E}[N_{01}]}{\\theta_1} - \\mathbb{E}[T_0] = 0 \\implies \\theta_1^{(p+1)} = \\frac{\\mathbb{E}[N_{01}]}{\\mathbb{E}[T_0]} $$\n$$ \\frac{\\partial Q}{\\partial \\theta_2} = \\frac{\\mathbb{E}[N_{10}]}{\\theta_2} - \\mathbb{E}[T_1] = 0 \\implies \\theta_2^{(p+1)} = \\frac{\\mathbb{E}[N_{10}]}{\\mathbb{E}[T_1]} $$\nThese are the intuitive update rules for the parameters.\n\n**E-step (Expectation):**\nThe core of the problem lies in the E-step: computing the conditional expectations of the sufficient statistics. By the Markov property, these expectations can be summed over all observation intervals $[t_k, t_{k+1}]$. For each interval of duration $\\Delta t = t_{k+1} - t_k$, with starting state $i=x_k$ and ending state $j=x_{k+1}$, we need to compute:\n1.  $\\mathbb{E}[T_k | X(0)=i, X(\\Delta t)=j]$: Expected sojourn time in state $k \\in \\{0, 1\\}$.\n2.  $\\mathbb{E}[N_{lm} | X(0)=i, X(\\Delta t)=j]$: Expected number of transitions from state $l$ to $m$.\n\nThese expectations can be derived from the transition probability matrix $P(t) = \\exp(Qt)$. The eigenvalues of $Q$ are $\\lambda_1=0$ and $\\lambda_2=-(\\theta_1+\\theta_2)$. Let $\\lambda = \\theta_1+\\theta_2$. The stationary distribution is $\\pi = (\\pi_0, \\pi_1) = (\\frac{\\theta_2}{\\lambda}, \\frac{\\theta_1}{\\lambda})$. The transition probabilities are:\n$$ P_{ab}(t) = \\pi_b + (\\delta_{ab} - \\pi_b)e^{-\\lambda t} $$\nwhere $\\delta_{ab}$ is the Kronecker delta.\n\nThe conditional expectations are given by expressions involving integrals over the unobserved time. For example, the expected sojourn time in state $k$ is:\n$$ \\mathbb{E}[T_k | \\dots] = \\frac{1}{P_{ij}(\\Delta t)} \\int_0^{\\Delta t} P_{ik}(s)P_{kj}(\\Delta t-s) ds $$\nThe expected number of transitions from $l$ to $m$ is:\n$$ \\mathbb{E}[N_{lm} | \\dots] = \\frac{q_{lm}}{P_{ij}(\\Delta t)} \\int_0^{\\Delta t} P_{il}(s)P_{mj}(\\Delta t-s) ds $$\nwhere $q_{01}=\\theta_1$ and $q_{10}=\\theta_2$.\n\nWhile the problem permits numerical integration, these integrals admit an analytical solution. Let $C_{ij}^{lm}(\\Delta t) = \\int_0^{\\Delta t} P_{il}(s) P_{mj}(\\Delta t-s) ds$. The analytical solution is:\n$$ C_{ij}^{lm}(\\Delta t) = \\Delta t \\left[ \\pi_l \\pi_j + (\\delta_{il}-\\pi_l)(\\delta_{mj}-\\pi_j)e^{-\\lambda\\Delta t} \\right] + \\frac{1-e^{-\\lambda\\Delta t}}{\\lambda} \\left[ \\pi_j\\delta_{il} + \\pi_l\\delta_{mj} - 2\\pi_l\\pi_j \\right] $$\nWith this, the required expectations for a single interval are:\n$$ \\mathbb{E}[T_k | \\dots] = \\frac{C_{ij}^{kk}(\\Delta t)}{P_{ij}(\\Delta t)} $$\n$$ \\mathbb{E}[N_{lm} | \\dots] = q_{lm} \\frac{C_{ij}^{lm}(\\Delta t)}{P_{ij}(\\Delta t)} $$\nAs a consistency check, it can be shown that $\\sum_k \\mathbb{E}[T_k | \\dots] = \\Delta t$.\n\n**Algorithm Implementation Summary:**\n1.  Initialize $\\theta^{(0)} = (1.0, 1.0)$.\n2.  Start iteration $p=0, 1, 2, \\dots$:\n    a. Initialize total expected statistics: $\\mathbb{E}[N_{01}]_{\\text{tot}}$, $\\mathbb{E}[N_{10}]_{\\text{tot}}$, $\\mathbb{E}[T_0]_{\\text{tot}}$, $\\mathbb{E}[T_1]_{\\text{tot}}$ to zero.\n    b. For each observation interval $[t_k, t_{k+1}]$:\n        i. Set $\\Delta t = t_{k+1}-t_k$, $i=x_k$, $j=x_{k+1}$.\n        ii. Using $\\theta^{(p)}$, calculate $\\lambda$, $\\pi$, and $P_{ij}(\\Delta t)$.\n        iii. For each required statistic (e.g., $T_0$, $N_{01}$), calculate the corresponding $C_{ij}^{lm}(\\Delta t)$ and then the conditional expectation.\n        iv. Add these interval expectations to the totals.\n    c. Update parameters using the M-step rules:\n       $\\theta_1^{(p+1)} = \\mathbb{E}[N_{01}]_{\\text{tot}} / \\mathbb{E}[T_0]_{\\text{tot}}$\n       $\\theta_2^{(p+1)} = \\mathbb{E}[N_{10}]_{\\text{tot}} / \\mathbb{E}[T_1]_{\\text{tot}}$\n    d. Check for convergence: if the relative change in the parameter vector $\\theta$ is below the tolerance $10^{-8}$, terminate.\n3.  Output the final converged parameters $\\theta_1$ and $\\theta_2$.\nThe implementation will use numerically stable computations, such as `scipy.special.expm1` for evaluating $(e^x - 1)$, to maintain precision when the argument $x$ is close to zero.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import expm1\n\ndef em_ctmc(times, states, theta_init, max_iter, tol):\n    \"\"\"\n    Estimates the parameters of a two-state Continuous-Time Markov Chain\n    using the Expectation-Maximization (EM) algorithm from discrete observations.\n\n    Args:\n        times (np.ndarray): Array of observation times.\n        states (np.ndarray): Array of observed states (0 or 1).\n        theta_init (np.ndarray): Initial guess for parameters [theta1, theta2].\n        max_iter (int): Maximum number of EM iterations.\n        tol (float): Relative tolerance for convergence.\n\n    Returns:\n        np.ndarray: The estimated parameters [theta1, theta2].\n    \"\"\"\n    theta = np.copy(theta_init)\n\n    for _ in range(max_iter):\n        theta_old = np.copy(theta)\n        \n        total_E_N01 = 0.0\n        total_E_N10 = 0.0\n        total_E_T0 = 0.0\n        total_E_T1 = 0.0\n\n        theta1, theta2 = theta[0], theta[1]\n        \n        # Parameters must be positive definite\n        if theta1 = 0 or theta2 = 0:\n            break\n            \n        lmbda = theta1 + theta2\n        pi0 = theta2 / lmbda\n        pi1 = theta1 / lmbda\n        pi = np.array([pi0, pi1])\n\n        for k in range(len(times) - 1):\n            dt = times[k+1] - times[k]\n            if dt = 0:\n                continue\n\n            i = states[k]  # start_state\n            j = states[k+1] # end_state\n            \n            e_lambda_t = np.exp(-lmbda * dt)\n            \n            # Transition probability P_ij(dt)\n            p_ij = pi[j] + ((1 if i == j else 0) - pi[j]) * e_lambda_t\n            \n            if p_ij = 1e-300: # Effectively zero, skip interval to avoid division by zero\n                continue\n            \n            # This function computes the integral C_{ij}^{lm}(dt) analytically.\n            def compute_C(i_s, j_s, l_s, m_s, dt_s, lmbda_s, pi_s, e_lambda_t_s):\n                delta_il = 1 if i_s == l_s else 0\n                delta_mj = 1 if j_s == m_s else 0\n                \n                term1 = dt_s * (pi_s[l_s] * pi_s[j_s] + (delta_il - pi_s[l_s]) * (delta_mj - pi_s[j_s]) * e_lambda_t_s)\n                \n                # Use expm1 for numerical stability for small lmbda*dt\n                x = -lmbda_s * dt_s\n                if abs(x)  1e-9:\n                    # For small x, (1-e^x)/(-x) approx 1, so (1-e^x)/lmbda approx dt\n                    term2_factor = dt_s\n                else:\n                    # (1 - e^x) / lmbda === -(e^x - 1) / lmbda\n                    term2_factor = -expm1(x) / lmbda_s\n                    \n                term2 = term2_factor * (pi_s[j_s] * delta_il + pi_s[l_s] * delta_mj - 2 * pi_s[l_s] * pi_s[j_s])\n                \n                return term1 + term2\n\n            # E-Step: Compute conditional expectations for the interval\n            # Expected sojourn time in state 0\n            C_ij_00 = compute_C(i, j, 0, 0, dt, lmbda, pi, e_lambda_t)\n            E_T0 = C_ij_00 / p_ij\n            \n            # Expected sojourn time in state 1 (by conservation)\n            E_T1 = dt - E_T0\n\n            # Expected number of transitions 0 - 1\n            C_ij_01 = compute_C(i, j, 0, 1, dt, lmbda, pi, e_lambda_t)\n            E_N01 = theta1 * C_ij_01 / p_ij\n            \n            # Expected number of transitions 1 - 0\n            C_ij_10 = compute_C(i, j, 1, 0, dt, lmbda, pi, e_lambda_t)\n            E_N10 = theta2 * C_ij_10 / p_ij\n\n            # Accumulate totals\n            total_E_T0 += E_T0\n            total_E_T1 += E_T1\n            total_E_N01 += E_N01\n            total_E_N10 += E_N10\n\n        # M-Step: Update parameters\n        # Add a small epsilon to denominators to prevent division by zero in pathological cases\n        epsilon = 1e-300\n        if total_E_T0 > 0:\n            theta[0] = total_E_N01 / total_E_T0\n        \n        if total_E_T1 > 0:\n            theta[1] = total_E_N10 / total_E_T1\n\n        # Convergence check\n        norm_old = np.linalg.norm(theta_old)\n        if norm_old > 0:\n            rel_change = np.linalg.norm(theta - theta_old) / norm_old\n            if rel_change  tol:\n                break\n    \n    return theta\n\ndef solve():\n    \"\"\"\n    Main function to run the algorithm on the defined test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (np.array([0.0, 0.5, 1.0, 1.5, 2.0]), np.array([0, 1, 0, 1, 0])),\n        (np.array([0.0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0]), np.array([0, 0, 0, 0, 0, 0, 0, 0, 0])),\n        (np.array([0.0, 1.0, 2.5, 5.0, 9.0]), np.array([1, 1, 0, 0, 1])),\n    ]\n\n    # Algorithm configuration\n    theta_init = np.array([1.0, 1.0])\n    max_iter = 50\n    tol = 1e-8\n    \n    results = []\n    for times, states in test_cases:\n        estimated_theta = em_ctmc(times, states, theta_init, max_iter, tol)\n        results.extend(estimated_theta)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{x:.6f}' for x in results)}]\")\n\nsolve()\n```"
        }
    ]
}